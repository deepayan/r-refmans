<!DOCTYPE html><html><head><title>Help for package rpql</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {rpql}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#rpql-package'><p>Joint effects selection in GLMMs using regularized PQL</p></a></li>
<li><a href='#build.start.fit'><p>Constructs a start fit for use in the <code>rpql</code> function</p></a></li>
<li><a href='#calc.marglogL'><p>Calculate the marginal log-likelihood for a GLMM fitted using <code>rpql</code></p></a></li>
<li><a href='#gendat.glmm'><p>Simulates datasets based on a Generalized Linear Mixed Model (GLMM).</p></a></li>
<li><a href='#lseq'><p>Generates a sequence of tuning parameters on the log scale</p></a></li>
<li><a href='#nb2'><p>A negative binomial family</p></a></li>
<li><a href='#rpql'><p>Joint effects selection in GLMMs using regularized PQL.</p></a></li>
<li><a href='#rpqlseq'><p>Wrapper function for joint effects selection in GLMMs using regularized PQL.</p></a></li>
<li><a href='#summary.rpql'><p>Summary of GLMM fitted using regularized PQL.</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Title:</td>
<td>Regularized PQL for Joint Selection in GLMMs</td>
</tr>
<tr>
<td>Version:</td>
<td>0.8.1</td>
</tr>
<tr>
<td>Date:</td>
<td>2023-08-01</td>
</tr>
<tr>
<td>Author:</td>
<td>Francis K.C. Hui &lt;francis.hui@gmail.com&gt;, with contributions from Samuel Mueller &lt;samuel.mueller@sydney.edu.au&gt; and A.H. Welsh &lt;Alan.Welsh@anu.edu.au&gt;</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Francis Hui &lt;fhui28@gmail.com&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Performs joint selection in Generalized Linear Mixed Models (GLMMs) using penalized likelihood methods. Specifically, the Penalized Quasi-Likelihood (PQL) is used as a loss function, and penalties are then augmented to perform simultaneous fixed and random effects selection. Regularized PQL avoids the need for integration (or approximations such as the Laplace's method) during the estimation process, and so the full solution path for model selection can be constructed relatively quickly. </td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a></td>
</tr>
<tr>
<td>Imports:</td>
<td>gamlss.dist, lme4, Matrix, MASS, mvtnorm, Rcpp,</td>
</tr>
<tr>
<td>Suggests:</td>
<td>nlme</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp, RcppArmadillo</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-08-19 22:32:35 UTC; fkch</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-08-19 22:50:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='rpql-package'>Joint effects selection in GLMMs using regularized PQL</h2><span id='topic+rpql-package'></span>

<h3>Description</h3>

<p><code>rpql</code> offers fast joint selection of fixed and random effects in Generalized Linear Mixed Model (GLMMs) via regularization. Specifically the penalized quasi-likelihood (PQL, Breslow and Clayton, 1993) is used as a loss function, and penalties are added on to perform fixed and random effects selection e.g., the lasso (Tibshirani, 1996) penalty. This method of joint selection in GLMMs, referred to regularized PQL, is very fast compared to information criterion and hypothesis testing, and has attractive large sample properties (Hui et al., 2016). Its performance however may not be great if the amount of data to estimate each random effect is not large, i.e. the cluster size is not large.
</p>


<h3>Details</h3>


<table>
<tr>
 <td style="text-align: left;">
Package: </td><td style="text-align: left;"> rpql</td>
</tr>
<tr>
 <td style="text-align: left;">
Type: </td><td style="text-align: left;"> Package</td>
</tr>
<tr>
 <td style="text-align: left;">
Version: </td><td style="text-align: left;"> 0.8.1</td>
</tr>
<tr>
 <td style="text-align: left;">
Date: </td><td style="text-align: left;"> 2023-08-01</td>
</tr>
<tr>
 <td style="text-align: left;">
License: </td><td style="text-align: left;"> GPL-2</td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>



<h3>Author(s)</h3>

<p>Francis K.C. Hui &lt;francis.hui@gmail.com&gt;, with contributions from Samuel Mueller &lt;samuel.mueller@sydney.edu.au&gt; and A.H. Welsh &lt;Alan.Welsh@anu.edu.au&gt;
</p>
<p>Maintainer: Francis Hui &lt;fhui28@gmail.com&gt;
</p>


<h3>References</h3>


<ul>
<li><p> Breslow, N. E., and Clayton, D. G. (1993). Approximate inference in generalized linear mixed models. Journal of the American Statistical Association, 88, 9-25.
</p>
</li>
<li><p> Hui, F.K.C., Mueller, S., and Welsh, A.H. (2017). Joint Selection in Mixed Models using Regularized PQL. Journal of the American Statistical Association, 112, 1323-1333.
</p>
</li>
<li><p> Tibshirani, R. (1996). Regression shrinkage and selection via the lasso. Journal of the Royal Statistical Society. Series B (Methodological), 58, 267-288.
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>## Please see examples in help file for the rpql function
</code></pre>

<hr>
<h2 id='build.start.fit'>Constructs a start fit for use in the <code>rpql</code> function</h2><span id='topic+build.start.fit'></span>

<h3>Description</h3>

<p>Takes a GLMM fitted using the <code>lme4</code> package i.e., using either the <code>lmer</code> or <code>glmer</code> functions, and construct a list containing starting values for use in the <code>start</code> argument in main fitting function <code>rpql</code>. It also constructs adaptive lasso weights, which can subsequently be used in the <code>pen.weights</code> arguments in the <code>rpql</code> function, if the adaptive lasso penalty is used for variable selection.</p>


<h3>Usage</h3>

<pre><code class='language-R'>build.start.fit(lme4.fit, id = NULL, gamma = 0, cov.groups = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="build.start.fit_+3A_lme4.fit">lme4.fit</code></td>
<td>
<p>An object of class &quot;lmerMod&quot; or &quot;glmerMod&quot;, obtained when fitting a (G)LMM using the <code>lmer</code> and <code>glmer</code> functions in the <code>lme4</code> package.</p>
</td></tr>
<tr><td><code id="build.start.fit_+3A_id">id</code></td>
<td>
<p>A optional list with each element being a vector of IDs that reference the model matrix in the corresponding element in the list <code>Z</code>. Each vector of IDs <em>must</em> be integers (but not factors). Note this is optional argument as it is only use for non-compulsory formatting purposes in the function.</p>
</td></tr>
<tr><td><code id="build.start.fit_+3A_gamma">gamma</code></td>
<td>
<p>A vector of power parameters, <code class="reqn">\gamma</code>, for use in constructing adaptive lasso weights. Can be a vector of one or two elements. If two elements, then the first and second elements are the power parameter for the fixed and random effect weights respectively. If one element, the same power parameter is used for both fixed and random effect weights. Defaults to 0, in which case the weights are all equal to 1 i.e., it reverts to the unweighted lasso penalty.</p>
</td></tr>
<tr><td><code id="build.start.fit_+3A_cov.groups">cov.groups</code></td>
<td>
<p>A vector specifying if fixed effect coefficients (including the intercept) should be regarded and therefore penalized in groups. For example, if one or more of the fixed effect covariates are factors, then <code>lme4</code> will automatically create dummy variables in the model matrix and estimate coefficients for each level, using one level as the reference. <code>cov.groups</code> is then used to identify all the coefficients that corresponds to that factor, such that all of these coefficients are penalized collectively as a group. Defaults to NULL, in which case it is assumed all coefficients should be treated independently. Please see the details and examples for more details.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is mainly used when: 1) you want to produce good starting values for the main fitting function <code>rpql</code>, and so you fit a saturated (full) GLMM using <code>lme4</code> and use the estimates from there as starting values, and/or 2) you want to obtain adaptive lasso weights of the form <code class="reqn">weight_k = |\tilde{parameter}_k|^{-\gamma}</code>, where <code class="reqn">\gamma &gt; 0</code> is the power parameter and <code class="reqn">\tilde{parameter}_k</code> is the parameter estimate from the saturated model fit. For regularized PQL specifically, this function will construct adaptive lasso weights from the <code>lme4</code> fit as follows: Let <code class="reqn">w^F</code> and <code class="reqn">w^R</code> denote fixed and random effect adaptive weights respectively. Then we have,
</p>
<p style="text-align: center;"><code class="reqn">w^F_k = |\tilde{\beta}_k|^{-\gamma_1}</code>
</p>

<p style="text-align: center;"><code class="reqn">w^R_l = |\tilde{\Sigma}_{ll}|^{-\gamma_2},</code>
</p>

<p>where <code class="reqn">\tilde{\beta}_k</code> is the estimated coefficient for the <code class="reqn">k^{th}</code> fixed effect, <code class="reqn">\tilde{\Sigma}_{ll}</code> is the <code class="reqn">l^{th}</code> diagonal element from the estimated random effects covariance matrix, and <code class="reqn">\gamma</code> is a vector of two power parameters; see Zou (2006) for the adaptive lasso, and Hui et al. (2016) for regularized PQL selection in GLMMs using on adaptive lasso type penalties. 
</p>
<p>If <code>cov.groups</code> is supplied, this means that some of the fixed effects coefficients should be treated and penalized collectively as a group. The most common cases where this is used is when you have factor or categorical variables with more than two levels, or when you have polynomial terms that should be dealt with together. For instance, suppose you have a model matrix consisting of six columns, where first three columns correspond to separate covariates (including the intercept) and the last three columns all correspond to dummy variables created for a factor variable with four levels , e.g. soil moisture with levels dry, moderately moist, very moist, wet. The coefficients from the last three columns should then be penalized together, and so we can set <code>cov.groups = c(1,2,3,4,4,4)</code>.  
</p>
<p>In doing so, the adaptive lasso weights for the grouped coefficients are then constructed differently. Following on from the example above, we have the fixed effect weight for soil moisture defined as
</p>
<p style="text-align: center;"><code class="reqn">w^F = \|\tilde{\beta}\|^{-\gamma_1},</code>
</p>

<p>where <code class="reqn">\| \cdot \|</code> corresponds to the L2-norm and <code class="reqn">\tilde{\beta}</code> are the fixed effect coefficients belonging in the group (three in this case). When entered into the <code>rpql</code> function, an adaptive group lasso (Wang and Leng, 2008) is applied to these set of coefficients, such that they are all encouraged to be shrunk to zero at the same time.
</p>
<p>Of course, after construction the adaptive lasso weights can be manually altered before entering into the main <code>rpql</code> function e.g., if one wants certain fixed and/or random effects to not be penalized.
</p>


<h3>Value</h3>

<p>A list containing the following elements
</p>
<table>
<tr><td><code>fixef</code></td>
<td>
<p>Fixed effect coefficient estimates from <code>lme4.fit</code>.</p>
</td></tr>
<tr><td><code>ranef</code></td>
<td>
<p>A list of random effect predicted coefficients from <code>lme4.fit</code>.</p>
</td></tr>
<tr><td><code>ran.cov</code></td>
<td>
<p>A list of random effects covariance matrices from <code>lme4.fit</code>.</p>
</td></tr>
<tr><td><code>cov.groups</code></td>
<td>
<p>The argument <code>cov.groups</code>. Defaults to <code>NULL</code>.</p>
</td></tr>
<tr><td><code>pen.weights</code></td>
<td>
<p>A list of adaptive lasso weights constructed from <code>lme4.fit</code>. Contains elements <code>pen.weight$fixed</code> and <code>pen.weights$random</code>, which are the weights for the fixed and random effects respectively. Please see details above as to their construction.</p>
</td></tr>
</table>


<h3>Warnings</h3>


<ul>
<li><p> In order to construct sensible starting values and weights, this function should really only be used when <code>lme4.fit</code> is a fit of the saturated GLMM, i.e. all fixed and random effects included. 
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Francis K.C. Hui &lt;francis.hui@gmail.com&gt;, with contributions from Samuel Mueller &lt;samuel.mueller@sydney.edu.au&gt; and A.H. Welsh &lt;Alan.Welsh@anu.edu.au&gt;
</p>
<p>Maintainer: Francis Hui &lt;fhui28@gmail.com&gt;
</p>


<h3>References</h3>


<ul>
<li><p> Hui, F.K.C., Mueller, S., and Welsh, A.H. (2016). Joint Selection in Mixed Models using Regularized PQL. Journal of the American Statistical Association: accepted for publication.
</p>
</li>
<li><p> Wang, H., and Leng, C. (2008). A note on adaptive group lasso. Computational Statistics &amp; Data Analysis, 52, 5277-5286.
</p>
</li>
<li><p> Zou, H. (2006). The adaptive lasso and its oracle properties. Journal of the American statistical association, 101, 1418-1429.
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+rpql">rpql</a></code> for fitting and performing model selection in GLMMs using regularized PQL, which may use the values obtained from <code>build.start.fit</code> for starting values and adaptive lasso weights.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
##-------------------------
## Example 1: Bernoulli GLMM with grouped covariates. 
## Independent cluster model with 50 clusters and equal cluster sizes of 10
## Nine covariates where the last covariate (soil type) is a factor with four levels
##-------------------------
n &lt;- 50; p &lt;- 8; m &lt;- 10
set.seed(123)
X &lt;- data.frame(matrix(rnorm(n*m*p),n*m,p), soil=sample(1:4,size=m*n,replace=TRUE))
X$soil &lt;- factor(X$soil)
X &lt;- model.matrix(~ ., data = X)
colnames(X) &lt;- paste("X",1:ncol(X),sep="")

Z &lt;- X[,1:5] ## Random effects model matrix taken as first five columns
true_betas &lt;- c(-0.1,1,-1,1,-1,1,-1,0,0,0,0,0) 
true_D &lt;- matrix(0,ncol(Z),ncol(Z))
true_D[1:3,1:3] &lt;- matrix(c(9,4.8,0.6,4.8,4,1,0.6,1,1),
	3,3,byrow=TRUE) ## 3 important random effects 

simy &lt;- gendat.glmm(id = list(cluster = rep(1:n,each=m)), X = X, beta = true_betas, 
	Z = list(cluster = Z), D = list(cluster = true_D), family = binomial())

  
## Not run: 
library(lme4)
dat &lt;- data.frame(y = simy$y, simy$X, simy$Z$cluster, simy$id)
fit_satlme4 &lt;- glmer(y ~ X - 1 + (Z - 1 | cluster), data = dat, 
	family = "binomial")
fit_sat &lt;- build.start.fit(fit_satlme4, id = simy$id, gamma = 2, 
	cov.groups = c(1:9,10,10,10)) 

new.fit &lt;- rpql(y = simy$y, X = simy$X, Z = simy$Z, id = simy$id, lambda = 0.01, 
	pen.type = "adl", pen.weights = fit_sat$pen.weights,
	cov.groups = fit_sat$cov.groups, start = fit_sat, family = binomial())  
	
## End(Not run)

</code></pre>

<hr>
<h2 id='calc.marglogL'>Calculate the marginal log-likelihood for a GLMM fitted using <code>rpql</code></h2><span id='topic+calc.marglogL'></span>

<h3>Description</h3>

<p>After fitting and performing joint (fixed and random effects) using regularized PQL, one may then (for one reason or another) want to calculate the marginal likelihood for the (sub)model, possibly on a test dataset for prediction. This is the main purpose of <code>calc.marglogL</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calc.marglogL(new.data, fit, B = 1000)
  </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="calc.marglogL_+3A_new.data">new.data</code></td>
<td>
<p>A list containing the elements <code>new.data$y</code>,  <code>new.data$X</code>,  and <code>new.data$Z</code>. These correspond respectively to the responses, fixed effects model matrix, and random effects model matrices that the marginal log-likelihood is be calculated on. No check is made against the elements in <code>fit</code> to ensure that these are of the correct dimensions compared, and furthermore it is assumed that <code>new.data$Z</code> is a list in the same order as the <code>Z</code> used when fitting the original model via <code>rpql</code>.</p>
</td></tr>
<tr><td><code id="calc.marglogL_+3A_fit">fit</code></td>
<td>
<p>An object of class <code>pqrl</code>. In the least, <code>fit</code> should be a list containing the elements <code>fit$family</code> for the family, e.g. gaussian(), poisson(), <code>fit$fixef</code> for the estimated vector of fixed effects, <code>fit$ran.cov</code> which is a list of estimated random effects covariance matrices. If appropriate, <code>fit</code> may also contain the elements <code>fit$phi</code> for the estimated variance parameter in normal, lognormal, and negative binomial GLMMs, <code>fit$shape</code> for the estimated shape parameter used in Gamma GLMMs, <code>fit$trial.size</code> for the trial size(s) for binomial GLMMs, and <code>fit$zeroprob</code> for the estimated probability of a structural zero in ZIP GLMMs.</p>
</td></tr>
<tr><td><code id="calc.marglogL_+3A_b">B</code></td>
<td>
<p>A positive integer for the number of random effects examples to generate, when performing Monte-Carlo integration. Defaults to 1000.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Regularized PQL performs penalized joint (fixed and random effects) selection for GLMMs, where the penalized quasi-likelihood (PQL, Breslow and Clayton, 1993) is used the loss function. After fitting, one may then wish to calculate the marginal log-likelihood for the (sub)model, defined as 
</p>
<p style="text-align: center;"><code class="reqn">\ell = \log\left(\int f(\bm{y}; \bm{\beta}, \bm{b}, \phi) f(\bm{b}; \bm{\Sigma}) d\bm{b}\right),</code>
</p>

<p>where <code class="reqn">f(\bm{y}; \bm{\beta}, \bm{b}, \phi)</code> denotes the conditional likelihood of the responses <code class="reqn">\bm{y}</code> given the fixed effects <code class="reqn">\bm{\beta}</code>, random effects <code class="reqn">\bm{b}</code>, and nuisance parameters <code class="reqn">\phi</code> if appropriate, and <code class="reqn">f(\bm{b}; \bm{\Sigma})</code> is the multivariate normal distribution for the random effects, with covariance matrix <code class="reqn">\bm{\Sigma}</code>. <code>calc.marglogL</code> calculates the above marginal likelihood using Monte-Carlo integration.
</p>
<p>Admittedly, this function is not really useful for fitting the GLMM <em>per-se</em>: it is never called by the main function <code>rpql</code>, and the marginal likelihood is (approximately) calculated anyway if <code>hybrid.est = TRUE</code> and the final submodel is refitted using <code>lme4</code>. Where the function comes in handy is if you have a validation or test dataset, and you want to calculated the predicted (log) likelihood of the test data given the regularized PQL fit.  
</p>


<h3>Value</h3>

<p>The marginal log-likelihood of <code>new.data</code> given the GLMM in <code>fit</code>.</p>


<h3>Warnings</h3>


<ul>
<li><p> No check is made to see if the dimensions of the elements <code>new.data</code> and <code>fit</code> match, e.g. the number of columns in <code>new.data$X</code> is equal to the number of elements in <code>fit$fixef</code>. Please ensure they are!
</p>
</li>
<li><p> Monte-Carlo integration is computationally intensive especially if <code class="reqn">\bm{y}</code> is long!
</p>
</li></ul>
 


<h3>Author(s)</h3>

<p>Francis K.C. Hui &lt;francis.hui@gmail.com&gt;, with contributions from Samuel Mueller &lt;samuel.mueller@sydney.edu.au&gt; and A.H. Welsh &lt;Alan.Welsh@anu.edu.au&gt;
</p>
<p>Maintainer: Francis Hui &lt;fhui28@gmail.com&gt;
</p>


<h3>References</h3>


<ul>
<li><p> Breslow, N. E., &amp; Clayton, D. G. (1993). Approximate inference in generalized linear mixed models. Journal of the American Statistical Association, 88, 9-25.
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+rpql">rpql</a></code> for fitting and performing model selection in GLMMs using regularized PQL. <code>lme4</code> also approximately calculates the marginal log-likelihood when fitting a GLMM.</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not given
</code></pre>

<hr>
<h2 id='gendat.glmm'>Simulates datasets based on a Generalized Linear Mixed Model (GLMM).</h2><span id='topic+gendat.glmm'></span>

<h3>Description</h3>

<p>Datasets are simulated from a GLMM given a series of inputs including: model matrices <code>X</code> and <code>Z</code> for the fixed and random effects respectively, a set of true fixed effect coefficients <code>beta</code>, a list of true random effect covariance matrices <code>D</code>, the family of response, and some other nusiance parameters if appropriate.
</p>


<h3>Usage</h3>

<pre><code class='language-R'> 
gendat.glmm(id, X, beta, Z, D, trial.size = 1, family = gaussian(), 
  phi = NULL, shape = NULL, zeroprob = NULL, upper.count = Inf)
   </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gendat.glmm_+3A_id">id</code></td>
<td>
<p>A list with each element being a vector of IDs that reference the model matrix in the corresponding element in the list <code>Z</code>. Each vector of IDs <em>must</em> be integers (but not factors).</p>
</td></tr>
<tr><td><code id="gendat.glmm_+3A_x">X</code></td>
<td>
<p>A model matrix of corresponding to the fixed effects. A column of ones should be included if a fixed intercept is to be included in the model.</p>
</td></tr>
<tr><td><code id="gendat.glmm_+3A_beta">beta</code></td>
<td>
<p>A vector of true fixed effect parameters, with the same length as the number of columns in <code>X</code>.</p>
</td></tr>
<tr><td><code id="gendat.glmm_+3A_z">Z</code></td>
<td>
<p>A list with each element being a model matrix for a set of random effects. Each element of <code>Z</code> is referenced by a vector of IDs given by the corresponding element in the list <code>id</code>. Each model matrix (element of <code>Z</code>) should have the same number of rows as the length of <code>y</code>.</p>
</td></tr>
<tr><td><code id="gendat.glmm_+3A_d">D</code></td>
<td>
<p>A list with each element being a symmetric random effects covariance matrix which is used to generate random effects. These random effects are then applied to the corresponding element in the list <code>Z</code>, and are referenced by the corresponding element in the list <code>id</code>.</p>
</td></tr>
<tr><td><code id="gendat.glmm_+3A_trial.size">trial.size</code></td>
<td>
<p>The trial size if <code>family = binomial()</code>. Either takes a single non-zero value or a vector of non-zero values with length the same as the number of rows in <code>X</code>. The latter allows for differing trial sizes across responses. Defaults to 1.</p>
</td></tr> 
<tr><td><code id="gendat.glmm_+3A_family">family</code></td>
<td>
<p>The distribution for the responses in GLMM. The argument must be applied as a object of class &quot;family&quot;. Currently supported arguments include: <code>gaussian()</code>, <code>poisson()</code>, <code>binomial()</code>, <code>Gamma()</code>, <code>nb2()</code> for negative binomial, <code>LOGNO()</code> for log-normal, and <code>ZIP()</code> for zero-inflated Poisson.</p>
</td></tr>
<tr><td><code id="gendat.glmm_+3A_phi">phi</code></td>
<td>
<p>A non-zero value for the true variance parameter <code class="reqn">\sigma^2</code> if <code>family = gaussian()</code>, the true variance parameter <code class="reqn">\sigma^2</code> on the log scale if <code>family = LOGNO()</code>, or the overdispersion parameter if <code>family = nb2()</code>, where the negative binomial variance is parameterized as <code class="reqn">V = \mu + \phi\mu^2</code>. Defaults to NULL.</p>
</td></tr>
<tr><td><code id="gendat.glmm_+3A_shape">shape</code></td>
<td>
<p>A non-zero value for the shape parameter <code class="reqn">a</code> if <code>family = Gamma()</code>, where the variance is parameterized as <code class="reqn">V = \mu^2/a</code>. Defaults to NULL.</p>
</td></tr>
<tr><td><code id="gendat.glmm_+3A_zeroprob">zeroprob</code></td>
<td>
<p>A value between 0 and 1 for the probability of a structural zero if <code>family = ZIP()</code> for zero-inflated Poisson. Defaults to NULL.</p>
</td></tr>
<tr><td><code id="gendat.glmm_+3A_upper.count">upper.count</code></td>
<td>
<p>A non-zero integer which allows the user to control the maximum value of the counts generates for datasets when <code>family = poisson()</code> or <code>nb2()</code>. When the responses are simulated, a <code>while</code> loop is run to ensure that all responses generated are less than or equal to <code>upper.count</code>. Default to <code>Inf</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The relationship between the mean of the responses and covariates in a GLMM is given as follows: For <code class="reqn">i = 1,\ldots,n</code>, where <code class="reqn">n</code> is, equivalently, the number of rows in <code>X</code>, the length of each element in <code>id</code>, and the number of rows in each element of <code>Z</code>, we have
</p>
<p style="text-align: center;"><code class="reqn">g(\mu_{i}) = \bm{x}^T_i \bm{\beta} + \bm{z}^T_{i1} \bm{b}_{i1} + \bm{z}^T_{i2} \bm{b}_{i2} + \ldots,</code>
</p>

<p>where <code class="reqn">g(\cdot)</code> is the link function, <code class="reqn">\mu_i</code> is the mean of the distribution for observation <code class="reqn">i</code>, <code class="reqn">\bm{x}_i</code> is row <code class="reqn">i</code> of the fixed effects model matrix <code>X</code>, and <code class="reqn">\bm{\beta}</code> is the fixed effects coefficients. For the random effects, <code class="reqn">\bm{z}_{i1}</code> is row <code class="reqn">i</code> of the random effects model matrix in the first element of <code>Z</code>, while <code class="reqn">\bm{b}_{i1}</code> is the vector of random effects generated for observation <code class="reqn">i</code> based on the first element of <code>D</code>. The remaining parameters <code class="reqn">\bm{z}_{i2}</code>, <code class="reqn">\bm{b}_{i2}</code> and so on, are defined similarly.
</p>
<p>Having lists for <code>id, Z</code>, and <code>D</code> allows for multiple sets of random effects to be included in the true GLMM. This is analogous to the <code>lme4</code> package, where multiple random effects are permitted in the formula, e.g., <code>(1|creek) + (1|creek:sample)</code>. If the true GLMM contains only one set of random effects, e.g., in longitudinal data, then the three lists will all contain only one element. Cases with multiple sets of random effects include nested and crossed designs, in which case <code>id, Z</code>, and <code>D</code> will have two or more elements. 
</p>
<p>It is recommended that the user think through and design these lists carefully to ensure that they are actually constructing a true GLMM that they want to simulated data from. Yes it takes some getting use too, and we apologize for this =( Please see examples below for some ideas.
</p>
<p>Finally, note that some of the elements of <code>beta</code> can be zero, i.e. truly unimportant fixed effects. Likewise, each element of <code>D</code> can be a random effects covariance matrix containing zero rows and columns, i.e. truly unimportant random effects.
</p>


<h3>Value</h3>

<p>A list containing the following elements
</p>
<table>
<tr><td><code>y</code></td>
<td>
<p>The vector simulated responses.</p>
</td></tr>
<tr><td><code>b</code></td>
<td>
<p>A list with each element being a matrix of random effects simulated from a multivariate normal distribution with mean zero and covariance matrix equal to the corresponding element in the list <code>D</code>. For each element in <code>b</code>, the number of columns of the matrix equals the dimension of corresponding covariance matrix element in <code>D</code>, while the number of rows equals to the number of unique IDs in the corresponding element of the list <code>id</code>.</p>
</td></tr>
<tr><td><code>id</code>, <code>X</code>, <code>Z</code>, <code>beta</code>, <code>D</code>, <code>phi</code>, <code>shape</code>, <code>zeroprob</code>, <code>trial.size</code>, <code>family</code></td>
<td>
<p>Some of the arguments entered into <code>gendat.glmm</code>.</p>
</td></tr>
<tr><td><code>nonzero.beta</code></td>
<td>
<p>A vector indexing the non-zero values of <code>beta</code>, i.e. the truly important fixed effects.</p>
</td></tr>
<tr><td><code>nonzero.b</code></td>
<td>
<p>A list with each element being a vector indexing the non-zero diagonal variances in the corresponding element of the list <code>D</code>, i.e. the truly important random effects.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Francis K.C. Hui &lt;francis.hui@gmail.com&gt;, with contributions from Samuel Mueller &lt;samuel.mueller@sydney.edu.au&gt; and A.H. Welsh &lt;Alan.Welsh@anu.edu.au&gt;
</p>
<p>Maintainer: Francis Hui &lt;fhui28@gmail.com&gt;
</p>


<h3>References</h3>


<ul>
<li><p> Schielzeth, H., &amp; Nakagawa, S. (2013). Nested by design: model fitting and interpretation in a mixed model era. Methods in Ecology and Evolution, 4, 14-24.
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+rpql">rpql</a></code> for fitting and performing model selection in GLMMs using regularized PQL.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
##-------------------------
## Example 1: Linear Mixed Models 
## Independent cluster model with 50 clusters
## Nine covariates including a fixed and random intercept
## Please note the rpql is currently not optimized for LMMs!
##-------------------------
library(mvtnorm)
library(lme4)

n &lt;- 50; m &lt;- 10; p &lt;- 8; 
## Generate rows of a model matrix from a multivariate normal distribution with 
## AR1 covariance structure. 

H &lt;- abs(outer(1:p, 1:p, "-")) 
X &lt;- cbind(1,rmvnorm(n*m,rep(0,p),sigma=0.5^H)); 

Z &lt;- X 
true_betas &lt;- c(1,3,2,1.5,-1,0,0,0,0) ## 5 important fixed effects 
true_D &lt;- matrix(0,p+1,p+1) ## 3 important random effects
true_D[1:3,1:3] &lt;- matrix(c(9,4.8,0.6,4.8,4,1,0.6,1,1),3,3,byrow=TRUE)

simy &lt;- gendat.glmm(id = list(cluster = rep(1:n,each=m)), X = X, beta = true_betas, 
	Z = list(cluster = Z), D = list(cluster = true_D), phi = 1, family = gaussian()) 
## Notice how id, Z, and D all are lists with one element, and that 
## the name of the first element (a generic name "cluster") is the 
## same for all three lists. 
## id is where the action takes place. In particular, id$cluster is 
## designed so that the first m elements correspond to cluster 1, 
## the second m elements correspond to cluster 2, and so forth. 
## In turn, the first m rows of X and Z$cluster correspond 
## to cluster 1, and so on. 

## Not run: 
dat &lt;- data.frame(y = simy$y, simy$X, simy$Z$cluster, simy$id)
fit_satlme4 &lt;- lmer(y ~ X - 1 + (Z - 1 | cluster), data = dat,
	REML = FALSE)
fit_sat &lt;- build.start.fit(fit_satlme4, gamma = 2)


lambda_seq &lt;- lseq(1e-4,1,length=100)
fit &lt;- rpqlseq(y = simy$y, X = simy$X, Z = simy$Z, id = simy$id, 
	family = gaussian(), lambda = lambda_seq, pen.type = "adl", 
	pen.weights = fit_sat$pen.weights, start = fit_sat)

summary(fit$best.fit[[5]])  ## Second of the hybrid ICs
# apply(fit$collect.ics, 2, which.min) ## Look at best fit chosen by different ICs

## End(Not run)

## Please see other examples in help file for the \code{rpql} function.
</code></pre>

<hr>
<h2 id='lseq'>Generates a sequence of tuning parameters on the log scale</h2><span id='topic+lseq'></span>

<h3>Description</h3>

<p>Generates a sequence of tuning parameters <code class="reqn">\lambda</code> that are equally spaced on the log-scale. It may be used as part of constructing a solution path for the main fitting function <code>rpql</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lseq(from, to, length, decreasing = FALSE)
  </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lseq_+3A_from">from</code></td>
<td>
<p>The minimum tuning parameter to start the sequence from.</p>
</td></tr>
<tr><td><code id="lseq_+3A_to">to</code></td>
<td>
<p>The maximum tuning parameter to go to.</p>
</td></tr>
<tr><td><code id="lseq_+3A_length">length</code></td>
<td>
<p>The length of the sequence.</p>
</td></tr>
<tr><td><code id="lseq_+3A_decreasing">decreasing</code></td>
<td>
<p>Should the sequence be in ascending or descending order?</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For joint selection of fixed and random effects in GLMMs, regularized PQL (Hui et al., 2016) works taking the penalized quasi-likelihood (PQL, Breslow and Clayton, 1993) as a loss function, and then sticking on some penalties in order to model variable. The penalties will depend upon one or more tuning parameters <code class="reqn">\lambda &gt; 0</code>, and the typical way this is chosen is to construct a sequence of <code class="reqn">\lambda</code> values, fit the regularized PQL to each one value, and then use a method like information criterion to select the best <code class="reqn">\lambda</code> and hence the best model. Please see the help file for <code><a href="#topic+rpql">rpql</a></code> for more details, and <code>glmnet</code> (Friedman et al., 2010) and <code>ncvreg</code> (Breheny, and Huang, 2011) as examples of other packages that do penalized regression and involve tuning parameter selection.
</p>
<p>The idea of equally spacing the sequence of <code class="reqn">\lambda</code>'s on the log (base 10) scale may not necessary be what you want to do, and one is free to use the standard <code>seq()</code> function for constructing sequences. By equaling spacing them on log-scale, it means that there will be a large concentration of small tuning parameter values, with less large tuning parameter values (analogous to a right skewed distribution). This may be useful if you believe the that most of the penalization/variable selection action takes place on smaller values of <code class="reqn">\lambda</code>.
</p>
<p>It is somewhat of an art form to construct a good sequence of tuning parameter values: the smallest <code class="reqn">\lambda</code> should produce the saturated model if possible, and the largest <code class="reqn">\lambda</code> should shrink most if not all covariates to zero i.e., the null model. Good luck!
</p>


<h3>Value</h3>

<p>A sequence of tuning parameter values of length equal to <code>length</code>.</p>


<h3>Author(s)</h3>

<p>Francis K.C. Hui &lt;francis.hui@gmail.com&gt;, with contributions from Samuel Mueller &lt;samuel.mueller@sydney.edu.au&gt; and A.H. Welsh &lt;Alan.Welsh@anu.edu.au&gt;
</p>
<p>Maintainer: Francis Hui &lt;fhui28@gmail.com&gt;
</p>


<h3>References</h3>


<ul>
<li><p> Breheny, P. and Huang, J. (2011) Coordinate descent algorithms fof nonconvex penalized regression, with applications to biological feature selection. The Annals of Appliedv Statistics, 5, 232-253.
</p>
</li>
<li><p> Breslow, N. E., and Clayton, D. G. (1993). Approximate inference in generalized linear mixed models. Journal of the American Statistical Association, 88, 9-25.
</p>
</li>
<li><p> Friedman, J., Hastie T., and Tibshirani, R. (2010). Regularization Paths for Generalized Linear Models via Coordinate Descent. Journal of Statistical Software, 33, 1-22. URL: http://www.jstatsoft.org/v33/i01/.
</p>
</li>
<li><p> Hui, F.K.C., Mueller, S., and Welsh, A.H. (2016). Joint Selection in Mixed Models using Regularized PQL. Journal of the American Statistical Association: accepted for publication.
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+rpql">rpql</a></code> for fitting and performing model selection in GLMMs using regularized PQL.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Please see examples in help file for the rpql function
</code></pre>

<hr>
<h2 id='nb2'>A negative binomial family</h2><span id='topic+nb2'></span>

<h3>Description</h3>

<p>Since the negative binomial is not a family in base <code>R</code>, an <code>nb2()</code> family has been created which establishes the negative binomial as a family for use in the main <code>rpql</code> function. Only the log link is available at the moment, with the variance parameterized as <code class="reqn">V = \mu + \phi\mu^2</code> where <code class="reqn">\phi</code> is the overdispersion parameter.
</p>


<h3>Usage</h3>

<pre><code class='language-R'> 
nb2()
  </code></pre>


<h3>Details</h3>

<p>Used in the form <code>rpql(y, ..., family = nb2(), ...)</code>.
</p>


<h3>Value</h3>

<p>An object of class &quot;family&quot;
</p>


<h3>Author(s)</h3>

<p>Francis K.C. Hui &lt;francis.hui@gmail.com&gt;, with contributions from Samuel Mueller &lt;samuel.mueller@sydney.edu.au&gt; and A.H. Welsh &lt;Alan.Welsh@anu.edu.au&gt;
</p>
<p>Maintainer: Francis Hui &lt;fhui28@gmail.com&gt;
</p>


<h3>See Also</h3>

<p><code><a href="MASS.html#topic+negative.binomial">negative.binomial</a></code> in the <code>MASS</code> package for another example of a negative.binomial family. 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
## The function is currently defined as follows
nb2 &lt;- function () {
    link &lt;- "log"
    linkfun &lt;- function(mu) log(mu)
    linkinv &lt;- function(eta) pmax(exp(eta), .Machine$double.eps)
    mu.eta &lt;- function(eta) pmax(exp(eta), .Machine$double.eps)
    variance &lt;- function(mu, phi) mu + phi * mu^2
    valideta &lt;- function(eta) TRUE
    validmu &lt;- function(mu) all(mu &gt; 0)
    structure(list(family = "negative.binomial", link = "log", 
        linkfun = linkfun, linkinv = linkinv, mu.eta = mu.eta, 
        variance = variance, valideta = valideta, validmu = validmu, 
        name = link), class = "family")
  }

## End(Not run)  
</code></pre>

<hr>
<h2 id='rpql'>Joint effects selection in GLMMs using regularized PQL.</h2><span id='topic+rpql'></span><span id='topic+rpql.default'></span><span id='topic+print.rpql'></span>

<h3>Description</h3>

<p><code>rpql</code> offers fast joint selection of fixed and random effects in Generalized Linear Mixed Model (GLMMs) via regularization. The penalized quasi-likelihood (PQL) is used as a loss function, and penalties are added on to perform fixed and random effects selection. This method of joint selection in GLMMs, referred to regularized PQL, is fast compared to information criterion and hypothesis testing (Hui et al., 2016). 
</p>
<p>Please note <code>rpql</code> is the core workshops function that performed regularized PQL on a single set of tuning parameters. <code>rpqlseq</code> is a wrapper to permit a sequence of tuning parameter values. The latter is often what users want to use.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rpql(y, ...)
  
## Default S3 method:
rpql(y, X, Z, id, family = gaussian(), trial.size = 1, lambda, 
  pen.type = "lasso", start = NULL, cov.groups = NULL, pen.weights = NULL, 
  hybrid.est = FALSE, offset = NULL, intercept = TRUE, save.data = FALSE, 
  control = list(tol = 1e-4, maxit = 100, trace = FALSE, restarts = 5, 
  scad.a = 3.7, mcp.gamma = 2, lasso.lambda.scale = TRUE, seed = NULL), ...)

## S3 method for class 'rpql'
print(x, ...)
  </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rpql_+3A_y">y</code></td>
<td>
<p>A vector of responses</p>
</td></tr>
<tr><td><code id="rpql_+3A_x">X</code></td>
<td>
<p>A model matrix corresponding to the fixed effects. It should have the same number of rows as the length of <code>y</code>. An intercept column must be included if a fixed intercept is desired.</p>
</td></tr>
<tr><td><code id="rpql_+3A_z">Z</code></td>
<td>
<p>A list with each element being a model matrix for a set of random effects. Each element of <code>Z</code> is referenced by a vector of IDs given by the corresponding element in the list <code>id</code>. Each model matrix (element of <code>Z</code>) should have the same number of rows as the length of <code>y</code>.</p>
</td></tr>
<tr><td><code id="rpql_+3A_id">id</code></td>
<td>
<p>A list with each element being a vector of IDs that reference the model matrix in the corresponding element in the list <code>Z</code>. Each vector of IDs <em>must</em> be integers (but not factors).</p>
</td></tr>
<tr><td><code id="rpql_+3A_x">x</code></td>
<td>
<p>An object for class &quot;rpql&quot;.</p>
</td></tr>
<tr><td><code id="rpql_+3A_family">family</code></td>
<td>
<p>The distribution for the responses in GLMM. The argument must be applied as a object of class &quot;family&quot;. Currently supported arguments include: <code>gaussian()</code>, <code>poisson()</code>, <code>binomial()</code>, <code>Gamma()</code>, <code>nb2()</code> for negative binomial, <code>LOGNO()</code> for log-normal, and <code>ZIP()</code> for zero-inflated Poisson.</p>
</td></tr>
<tr><td><code id="rpql_+3A_trial.size">trial.size</code></td>
<td>
<p>The trial size if <code>family = binomial()</code>. Either takes a single non-zero value or a vector of non-zero values with length the same as the number of rows in <code>X</code>. The latter allows for differing trial sizes across responses. Defaults to 1.</p>
</td></tr> 
<tr><td><code id="rpql_+3A_lambda">lambda</code></td>
<td>
<p>A vector of length one or two specifying the tuning parameters used in regularized PQL. If two elements are supplied, then first and second elements are for the fixed and random effects penalty respectively. If one element, then it is applied to both penalties.</p>
</td></tr>
<tr><td><code id="rpql_+3A_pen.type">pen.type</code></td>
<td>
<p>A vector of one or two strings, specifying the penalty used for variable selection. If two elements are supplied, then first and second strings are the fixed and random effects penalty respectively. If one element, the same type of penalty is used. Currently supported argument include: &quot;<code>lasso</code>&quot; for standard lasso (Tibshirani, 1996), &quot;<code>scad</code>&quot; for SCAD penalty with <code class="reqn">a</code> controlled by <code>control$scad.a</code> (Fan and Li, 2001), &quot;<code>adl</code>&quot; for adaptive lasso (Zou, 06), &quot;<code>mcp</code>&quot; for MC+ penalty with <code class="reqn">\gamma</code> controlled by controlled by <code>control$mcp.gamma</code> (Zhang, 2010). If the adaptive lasso is used, then <code>pen.weights</code> must also be supplied. Defaults to standard lasso penalty for both fixed and random effects.</p>
</td></tr>
<tr><td><code id="rpql_+3A_start">start</code></td>
<td>
<p>A list of starting values. It must contain the following elements: <code>start$fixef</code> as starting values for the fixed effect coefficients, <code>start$ranef</code> which is a list containing matrices of starting values for the random effects coefficients. It may also contain <code>start$D</code> which is a list of matrices to act as starting values for random effects covariance matrices.</p>
</td></tr> 
<tr><td><code id="rpql_+3A_cov.groups">cov.groups</code></td>
<td>
<p>A vector specifying if the columns of <code>X</code> (including the intercept) should be regarded and therefore penalized in groups. For example, if one or more of the fixed effect covariates are factors, then <code>lme4</code> will automatically create dummy variables in the model matrix and estimate coefficients for each level, using one level as the reference. <code>cov.groups</code> is then used to identify all the coefficients that corresponds to that factor, such that all of these coefficients are penalized collectively as a group. Defaults to NULL, in which case it is assumed all coefficients should be treated independently. Please see the details and examples for more details.</p>
</td></tr>
<tr><td><code id="rpql_+3A_pen.weights">pen.weights</code></td>
<td>
<p>A list containing up to two elements for additional (adaptive lasso) weights to be included for penalization. This must be supplied if <code>pen.type</code> has one or both elements set to &quot;adl&quot;, otherwise it is optional. A weights equal to zero implies no penalization is applied to the parameter. The two elements in the list are as follows: for fixed effects, <code>pen.type$fixed</code> should be a vector with length equal to the number of columns in <code>X</code>. For random effects, <code>pen.weights$ran</code> should be a list of the same length as the list <code>Z</code>, where each element in that list is a vector with length equal to the number of columns in the corresponding element of the list <code>Z</code> (recall that each element of <code>Z</code> is a model matrix). Defaults to NULL, in which case there are no weights involved in the penalization.</p>
</td></tr>
<tr><td><code id="rpql_+3A_hybrid.est">hybrid.est</code></td>
<td>
<p>Should a hybrid estimation approach be used? That is, once model selection is performed using regularized PQL, should the submodel be re-estimated using the <code>lme4</code> package, if possible? Defaults to FALSE.</p>
</td></tr>
<tr><td><code id="rpql_+3A_offset">offset</code></td>
<td>
<p>This can be used to specify an <em>a priori</em> known component to be included in the linear predictor during fitting. It should be numeric vector of length equal to <code>y</code>. Defaults to NULL.</p>
</td></tr>
<tr><td><code id="rpql_+3A_intercept">intercept</code></td>
<td>
<p>Is one of the columns of <code>X</code> an intercept term? This is used to indicate the presence of a fixed intercept in the model, which subsequently will NOT be penalized. Defaults to TRUE.</p>
</td></tr>
<tr><td><code id="rpql_+3A_save.data">save.data</code></td>
<td>
<p>Should <code>y, X</code>, and <code>Z</code>, be saved as part of the output? Defaults to FALSE. The data is not saved by default in order to save memory.</p>
</td></tr>
<tr><td><code id="rpql_+3A_control">control</code></td>
<td>
<p>A list controlling the finer details of the rPQL algorithm. These include: 
</p>

<ul>
<li><p><code>tol</code>: Tolerance value for convergence in the regularized PQL to be declared, where convergence is measured as the difference between the estimated parameters in successive iterations. Defaults to a value of 1e-4.
</p>
</li>
<li><p><code>maxit</code>: The maximum number of update iterations for regularized PQL. Defaults to 100.
</p>
</li>
<li><p><code>trace</code>: Should the update estimates of the fixed effect coefficients and that random effect covariance matrices be printed at each iteration? Defaults to FALSE.
</p>
</li>
<li><p><code>restarts</code>: The number of restarts to try in case the algorithm diverges, i.e. the fixed effect coefficients and /or random effects covariance matrices &quot;blow up&quot;. Defaults to a value of 5. Divergence is mostly likely to occur when you have count responses with some extremely large counts in there, in which regularized PQL can throw a hissy fit.
</p>
</li>
<li><p><code>scad.a, mcp.gamma</code>: Controls the <code class="reqn">a</code> and <code class="reqn">\gamma</code> parameters in the SCAD and MC+ penalty respectively. Defaults to <code class="reqn">a = 3.7</code> (Fan and Li, 2001) and <code class="reqn">\gamma = 2</code> (Zhang, 2010) respectively. Please note these parameters are only in use when <code>pen.type</code> involves these penalties.
</p>
</li>
<li><p><code>seed</code>: A seed that can be used if results need to be replicated. Defaults to NULL, in which case a random seed is used.
</p>
</li></ul>

</td></tr>
<tr><td><code id="rpql_+3A_...">...</code></td>
<td>
<p>Not used.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><b>Intro</b>
</p>
<p>Generalized Linear Mixed Models (GLMMs) are an extension of Generalized Linear Models (GLM, see the <code>glm</code> function) to include one or more sets of random effects. For <code class="reqn">i = 1,\ldots,n</code>, where <code class="reqn">n</code> is the length of <code>y</code>, we have 
</p>
<p style="text-align: center;"><code class="reqn">g(\mu_{i}) = \bm{x}^T_i \bm{\beta} + \bm{z}^T_{i1} \bm{b}_{i1} + \bm{z}^T_{i2} \bm{b}_{i2} + \ldots,</code>
</p>

<p>where <code class="reqn">g(\cdot)</code> is the link function, <code class="reqn">\mu_i</code> is the mean of the distribution for observation <code class="reqn">i</code>, <code class="reqn">\bm{x}_i</code> is row <code class="reqn">i</code> of the fixed effects model matrix <code>X</code>, and <code class="reqn">\bm{\beta}</code> is the fixed effects coefficients. For the random effects, <code class="reqn">\bm{z}_{i1}</code> is row <code class="reqn">i</code> of the random effects model matrix in the first element of <code>Z</code>, <code class="reqn">\bm{z}_{i2}</code> is from the second element of <code>Z</code> and so forth. The random effects <code class="reqn">\bm{b}_{i1}</code>, <code class="reqn">\bm{b}_{i2}, \ldots</code> are drawn from a multivariate normal distribution with mean zero and differing covariance matrices <code class="reqn">\bm{D}_1, \bm{D}_2, \ldots</code>.
</p>
<p>Note that having lists for <code>id, Z</code>, allows for multiple sets of random effects to be included in the GLMM. This is analogous to the <code>lme4</code> package, where multiple random effects are permitted in the formula e.g., <code>(1|creek) + (1|creek:sample)</code>. If the GLMM contains only one set of random effects, e.g., in longitudinal data, then the two lists will all contain only one element. Cases where multiple sets of random effects may be used include nested and crossed designs, in which case <code>id, Z</code>, will have two or more elements. It is recommended that the user think through and design these lists carefully to ensure that they are actually constructing the appropriate GLMM of interest. Yes it takes some getting use too, and we apologize for this =( Please see examples below for some ideas.
</p>
<p><b>Regularized PQL</b>
</p>
<p>Regularized PQL is designed as a fast approach to joint selection to GLMMs (Hui et al., 2016). It works by taking the penalized quasi-likelihood (PQL, Breslow and Clayton, 1993) and adding on penalties to perform selection of the fixed and random effects. That is, maximize the regularized PQL function
</p>
<p style="text-align: center;"><code class="reqn">\ell = \sum\limits_{i=1}^n \log(f(y_i | \bm{\beta}, \bm{b}_{i1}, \bm{b}_{i2}, \ldots)) - \frac{1}{2} \sum\limits_{i=1}^n \bm{b}^T_{i1}\bm{D}^{-1}_1 \bm{b}_{i1} - \frac{1}{2} \sum\limits_{i=1}^n \bm{b}^T_{i2}\bm{D}^{-1}_2 \bm{b}_{i2} - \ldots - P_{\lambda}</code>
</p>

<p>where <code class="reqn">P_{\lambda}</code> denotes penalties to shrink the fixed effect <code class="reqn">\bm{\beta}</code> and random effect <code class="reqn">\bm{b}_{i1}</code>, <code class="reqn">\bm{b}_{i2}, \ldots</code> coefficients, which depend on one or more tuning parameters <code class="reqn">\lambda</code>. Like the PQL itself, regularized PQL is a fast approach for estimating GLMMs because it treats the random effects as &quot;fixed&quot; coefficients, and therefore no integration is required. Penalties are then used to shrunk one or more <code class="reqn">\bm{\beta}</code>'s and <code class="reqn">\bm{b}</code>'s to zero, the latter done so in a group-based manner, in order to perform joint selection (see Hui et al., 2016, for details). In short, regularized PQL is able to fit many GLMMs in a relatively short period of time, which in turn facilitates the construction of a solution or regularization path ranging from the null (intercept-only) to the full (saturated) model. A tuning parameter selection method such as information criterion can then be used to pick the select the final subset of fixed and random effects. A few penalty types are available in the package, from which we prefer to use the adaptive LASSO (with weights based on the full model, Zou, 2006) mainly because by having weights, we can avoids have to search through a two-dimensional grid of tuning parameter values.
</p>
<p>Note that if one only wanted to penalize the fixed effects and leave the random effects unpenalized, this can be achieved by setting the second element/s of lambda equal to to e.g., <code>lambda = c(1,0)</code>. Note though that in longitudinal studies, for covariates included as both fixed and random effects, if the random effects is not penalized then neither should the fixed effect. This ensures that no covariates end up being selected in the model as a purely random effects (non-hierarchical shrinkage, Hui et al., 2016). This can be accounted for also setting the corresponding elements of <code>pen.weights$fixed</code> to zero.
</p>
<p><b>AN IMPORTANT NOTE</b> 
</p>
<p>While regularized PQL is relatively fast, it will produce biased estimates of the fixed and random effects parameters for non-normal responses, especially if the amount of data to estimate each random effect is not large e.g., if the number of time points or cluster size is not large. We envision regularized PQL as a method of joint variable selection ONLY, and strongly encourage the user to adopt a hybrid estimation approach (using <code>hybrid.est = TRUE</code>, for instance). That is, once model selection is performed using regularized PQL, the final submodel should be re-estimated using more exact methods like quadrature or MCMC.
</p>
<p>Because regularized PQL treats the random effects as &ldquo;fixed&quot; coefficients and therefore penalizes these, then the random effects covariance matrices <code class="reqn">\bm{D}_1, \bm{D}_2, \ldots</code> are regarded more as nuisance parameters. This is in contrast to traditional maximum likelihood estimation where the random effect coefficients <code class="reqn">\bm{b}_{i1}</code>, <code class="reqn">\bm{b}_{i2}, \ldots</code> are integrated over. As nuisance parameters, regularized PQL employs an iterative estimator based on maximizing the Laplace-approximated marginal log-likelihood, assuming all other parameters are fixed, for estimating the covariance matrix <code class="reqn">\bm{D}_1, \bm{D}_2, \ldots</code>. This iterative estimator was used in Hui et al., (2016) for independent clustered data specifically. When they are multiple sets of random effects, each covariance matrix is estimated conditionally on all others i.e., the random effect coefficients corresponding to all other random effects are held constant. This can be thought of as employing a series of conditional Laplace approximations to obtain updates for <code class="reqn">\bm{D}_1, \bm{D}_2, \ldots</code>.
</p>
<p><b>A not so short discussion about information criterion</b>
</p>
<p>How to choose the tuning parameters for penalized regression is an active area of area of research in statistics (see for instance Zhang et al., 2010, Hui et al., 2014), with the most popular solutions being cross validation and information criteria. That is, a solution path is constructed and the best submodel is then chosen by minimizing the value of the information criterion. Anyway, <code>rpql</code> offers the following information criteria for tuning parameter selection, as available in <code>ics</code> in the output. Please note all of the criteria below use only the first part of the PQL function as the loss function i.e., <code class="reqn">IC = -2\sum\limits_{i=1}^n \log(f(y_i | \bm{\beta}, \bm{b}_{i1}, \bm{b}_{i2}, \ldots)) +</code> model complexity terms. 
</p>

<ol>
<li><p> A AIC-type criterion that penalizes a values of 2 for every non-zero fixed effect coefficient, and, for each set of random effects, penalizes a value of 2 for every non-zero random effect coefficient in that set.
</p>
</li>
<li><p> A BIC-type criterion that penalizes a value of <code class="reqn">\log(n)</code> for every non-zero fixed effect coefficient, and, for each set of random effects, penalizes a value of <code class="reqn">\log(n_c)</code> for every non-zero, unique element in covariance matrix for that set, where <code>n_c</code> denotes the number of clusters corresponding to that random effect.
</p>
</li>
<li><p> A BIC-type criterion that penalizes a value of <code class="reqn">\log(n)</code> for every non-zero fixed effect coefficient, and, for each set of random effects, penalizes a value of <code class="reqn">\log(n)</code> for every non-zero, unique element in covariance matrix for that set. This combination of penalties is the one used in the package <code>lme4</code>. 
</p>
</li>
<li><p> Three hybrid information criteria that penalizes a value <code class="reqn">\log(n)</code> for every non-zero fixed effect coefficient, and, for each set of random effects, penalizes a value of 2/1/0.5 for every non-zero random effect coefficient in that set.
</p>
</li></ol>

<p>Selection consistency for all but the first AIC criteria have been established, although empirically performance may differ. We generally prefer the three hybrid criterion, although it is recommended that the user tries several of them and see how results differ! 
</p>


<h3>Value</h3>

<p>An object of class &quot;rpql&quot; containing the following elements:
</p>
<table>
<tr><td><code>call</code></td>
<td>
<p>The matched call.</p>
</td></tr>
<tr><td><code>fixef</code></td>
<td>
<p>A vector of estimated fixed effect coefficients, <code class="reqn">\beta</code>.</p>
</td></tr>
<tr><td><code>ranef</code></td>
<td>
<p>A list with each element being a matrix of estimated (predicted) random effect coefficients, <code class="reqn">\bm{b}_{i1}</code>, <code class="reqn">\bm{b}_{i2}</code>, and so on.</p>
</td></tr>
<tr><td><code>ran.cov</code></td>
<td>
<p>A list with each element being an estimated random effect covariance matrices, <code class="reqn">\bm{D}_1, \bm{D}_2, \ldots</code>.</p>
</td></tr>
<tr><td><code>logLik</code></td>
<td>
<p>The (unpenalized) PQL likelihood value at convergence.</p>
</td></tr>
<tr><td><code>phi</code>, <code>shape</code>, <code>zeroprob</code></td>
<td>
<p>Estimates of nuisance parameters (if appropriate), including the variance and overdispersion parameter for normal, lognormal and negative binomial families, the shape parameter for the Gamma family, and the probability of a structural zero for zero-inflated Poisson family.</p>
</td></tr>
<tr><td><code>family</code></td>
<td>
<p>The family fitted.</p>
</td></tr>
<tr><td><code>n</code></td>
<td>
<p>The length of <code>y</code>.</p>
</td></tr>
<tr><td><code>id</code></td>
<td>
<p>The <code>id</code> argument.</p>
</td></tr>
<tr><td><code>lambda</code>, <code>pen.type</code></td>
<td>
<p>The tuning parameters and penalties used.</p>
</td></tr>
<tr><td><code>ics</code></td>
<td>
<p>A vector containing the number of estimated parameters in the GLMM (note regularized PQL treats the random effects as &quot;fixed&quot;), and some information criteria. Please see <code>details</code> above for more information.</p>
</td></tr>
<tr><td><code>nonzero.fixef</code></td>
<td>
<p>A vector indexing which of the estimated fixed effect coefficients are non-zero.</p>
</td></tr>
<tr><td><code>nonzero.ranef</code></td>
<td>
<p>A list with each element being a vector indexing which of the estimated random effects are non-zero, i.e. which of the diagonal elements in the corresponding element of <code>ran.cov</code> are non-zero.</p>
</td></tr>
<tr><td><code>hybrid</code></td>
<td>
<p>The estimated fit from <code>lme4</code>, if <code>hybrid.est = TRUE</code>.</p>
</td></tr>
<tr><td><code>y</code>, <code>X</code>, <code>Z</code></td>
<td>
<p>The data the GLMM is fitted to, if <code>save.data = TRUE</code>.</p>
</td></tr>
</table>


<h3>Warnings</h3>


<ul>
<li><p> We strongly recommend you scale your responses (if normally distributed) and any continuous covariates, otherwise <code>rpql</code> like all penalized likelihood methods, may not make much sense!
</p>
</li>
<li><p> Like its standard unpenalized counterpart, regularized PQL can produce very bias parameter estimates in finite samples, especially if you do not have a lot of data to estimate each random effect. We therefore envision regularized PQL as a tool for fast model selection in GLMMs, and strongly recommend you re-estimate the final submodel using more accurate estimation methods i.e., use a hybrid estimation approach, in order to obtain better final parameter estimates and predictions of the random effects.
</p>
</li>
<li><p> If <code>save.data = TRUE</code>, the data you fitted the GLMM is also saved as part of the output, and this can potentially take up a lot of memory. 
</p>
</li>
<li><p> If you are constantly suffering convergence issues with regularized PQL, even after multiple restarts, consider increasing <code>lambda[2]</code> to penalized the random effects more and stabilize the estimation algorithm. You may also want to consider better starting values, in particular, smaller values of <code>start$ranef</code>. Good luck!
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Francis K.C. Hui &lt;francis.hui@gmail.com&gt;, with contributions from Samuel Mueller &lt;samuel.mueller@sydney.edu.au&gt; and A.H. Welsh &lt;Alan.Welsh@anu.edu.au&gt;
</p>
<p>Maintainer: Francis Hui &lt;fhui28@gmail.com&gt;
</p>


<h3>References</h3>


<ul>
<li><p> Breslow, N. E., and Clayton, D. G. (1993). Approximate inference in generalized linear mixed models. Journal of the American Statistical Association, 88, 9-25.
</p>
</li>
<li><p> Fan, J., and Li, R. (2001). Variable selection via nonconcave penalized likelihood and its oracle properties. Journal of the American statistical Association, 96, 1348-1360.
</p>
</li>
<li><p> Hui, F. K. C., Mueller, S., and Welsh, A.H. (2017). Joint Selection in Mixed Models using Regularized PQL. Journal of the American Statistical Association, 112, 1323-1333.
</p>
</li>
<li><p> Hui, F. K. C., Mueller, S., and Welsh, A.H. (2017). Hierarchical Selection of Fixed and Random Effects in Generalized Linear Mixed Models. Statistica Sinica, 27, 501-518.
</p>
</li>
<li><p> Hui, F. K. C., Warton, D. I., and Foster, S. D. (2014). Tuning parameter selection for the adaptive lasso using ERIC. Journal of the American Statistical Association, 110, 262-269.   
</p>
</li>
<li><p> Lin, X., and Breslow, N. E. (1996). Bias correction in generalized linear mixed models with multiple components of dispersion. Journal of the American Statistical Association, 91, 1007-1016.
</p>
</li>
<li><p> Mueller, S., Scealy, J. L., and Welsh, A. H. (2013). Model selection in linear mixed models. Statistical Science, 28, 135-167.
</p>
</li>
<li><p> Tibshirani, R. (1996). Regression shrinkage and selection via the lasso. Journal of the Royal Statistical Society. Series B (Methodological), 58, 267-288.
</p>
</li>
<li><p> Zhang, Y., Li, R., and Tsai, C. L. (2010). Regularization parameter selections via generalized information criterion. Journal of the American Statistical Association, 105, 312-323.
</p>
</li>
<li><p> Zhang, C. H. (2010). Nearly unbiased variable selection under minimax concave penalty. The Annals of Statistics, 38, 894-942.
</p>
</li>
<li><p> Zou, H. (2006). The adaptive lasso and its oracle properties. Journal of the American statistical association, 101, 1418-1429.
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+rpqlseq">rpqlseq</a></code> for the wrapper function that runs <code>rpql</code> multiple times on a sequence of tuning parameter values, <code><a href="#topic+build.start.fit">build.start.fit</a></code> for building <code>start</code> lists from a GLMM fitted using the <code>lme4</code> package, <code><a href="base.html#topic+summary">summary</a></code> for a summary of the regularized PQL fit. For alternative methods of fitting GLMMs, you may also want be check out the packages <code>lme4, nlme, MCMCglmm</code> and <code>glmmADMB</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Please note all examples below use the \code{rpqlseq} wrapper function. 

library(lme4)
library(gamlss.dist)

##-------------------------
## Example 1: Poisson GLMM on simulated data 
## Indepenent cluster model with 30 clusters and equal cluster sizes of 10
## 9 fixed and random effect covariates including a fixed and random intercept
##-------------------------
library(mvtnorm)
set.seed(1)
n &lt;- 30; m &lt;- 10; p &lt;- 8; 
## Generate rows of a model matrix from a multivariate normal distribution 
## with AR1 covariance structure. 

H &lt;- abs(outer(1:p, 1:p, "-")) 
X &lt;- cbind(1,rmvnorm(n*m,rep(0,p),sigma=0.5^H)); 
Z &lt;- X 
true_betas &lt;- c(0.1,1,-1,-1,1,rep(0,p-4)) ## 5 truly important fixed effects
true_D &lt;- matrix(0,ncol(Z),ncol(Z))
true_D[1:3,1:3] &lt;- matrix(c(1,0.6,0.6,0.6,1,0.4,0.6,0.4,1),3,3,byrow=TRUE) 
## 3 important random effects

simy &lt;- gendat.glmm(id = list(cluster=rep(1:n,each=m)), X = X, beta = true_betas, 
	Z = list(cluster=Z), D = list(cluster=true_D), family = poisson()) 

	
## Not run: 
## Construct a solution path using adaptive LASSO for selection 
dat &lt;- data.frame(y = simy$y, simy$X, simy$Z$cluster, simy$id)
fit_satlme4 &lt;- glmer(y ~ X - 1 + (Z - 1 | cluster), data = dat,
	family = "poisson")
fit_sat &lt;- build.start.fit(fit_satlme4, gamma = 2)
## Please see example 3 for another way of constructing the adaptive weights

lambda_seq &lt;- lseq(1e-6,1,length=100)
fit &lt;- rpqlseq(y = simy$y, X = simy$X, Z = simy$Z, id = simy$id, 
	family = poisson(), lambda = lambda_seq, pen.type = "adl", 
	pen.weights = fit_sat$pen.weights, start = fit_sat)

summary(fit$best.fit[[5]]) ## Second of the hybrid ICs
# apply(fit$collect.ics, 2, which.min) ## Look at best fit chosen by different ICs

## Note, if you wanted to penalized the fixed effects only, this can achieved
## by setting fit_sat$pen.weights$random$cluster &lt;- rep(0,ncol(simy$Z$cluster))


## An alternative way to construct the X and Z matrices for input into rpqlseq is as follows:
## Big thanks for Andrew Olney for this suggestion!
XMM &lt;- unname(model.matrix(fit_satlme4)) 
ZMM &lt;- getME(fit_satlme4,"mmList"); names(ZMM) &lt;- "cluster"
lambda_seq &lt;- lseq(1e-6,1,length=100)
fit &lt;- rpqlseq(y = simy$y, X = XMM, Z = ZMM, id = simy$id, 
 	family = poisson(), lambda = lambda_seq, pen.type = "adl", 
	pen.weights = fit_sat$pen.weights, start = fit_sat)
summary(fit$best.fit[[5]]) ## Second of the hybrid ICs

## End(Not run)


##-------------------------
## Example 2: Similar to example 1 but with Bernoulli GLMMs 
## 30 clusters, cluster size of 20
##-------------------------
library(mvtnorm)
set.seed(1)
n &lt;- 30; m &lt;- 20; p &lt;- 8; 
## Generate rows of a model matrix from a multivariate normal distribution 
## with AR1 covariance structure. 

H &lt;- abs(outer(1:p, 1:p, "-")) 
X &lt;- cbind(1,rmvnorm(n*m,rep(0,p),sigma=0.5^H)); 
Z &lt;- X 
true_betas &lt;- c(-0.1,1,-1,1,-1,rep(0,p-4)) ## 5 truly important fixed effects
true_D &lt;- matrix(0,ncol(Z),ncol(Z))
true_D[1:3,1:3] &lt;- diag(c(3,2,1), nrow = 3)
## 3 important random effects

simy &lt;- gendat.glmm(id = list(cluster=rep(1:n,each=m)), X = X, 
  beta = true_betas, Z = list(cluster=Z), D = list(cluster=true_D), family = binomial()) 

	
## Not run: 
## Construct a solution path using adaptive LASSO for selection 
dat &lt;- data.frame(y = simy$y, simy$X, simy$Z$cluster, simy$id)
fit_satlme4 &lt;- glmer(y ~ X - 1 + (Z - 1 | cluster), data = dat, 
	family = "binomial")
fit_sat &lt;- build.start.fit(fit_satlme4, gamma = 2)

lambda_seq &lt;- lseq(1e-6,1,length=100)
best.fit &lt;- list(ics = rep(Inf,6))
fit &lt;- rpqlseq(y = simy$y, X = simy$X, Z = simy$Z, id = simy$id, 
	family = binomial(), lambda = lambda_seq, pen.type = "adl", 
	pen.weights = fit_sat$pen.weights, start = fit_sat)
	
summary(fit$best.fit[[5]]) ## Second of the hybrid ICs
# apply(fit$collect.ics, 2, which.min) ## Look at best fit chosen by different ICs

## An alternative way to construct the X and Z matrices for input into rpqlseq is as follows:
XMM &lt;- unname(model.matrix(fit_satlme4)) 
ZMM &lt;- getME(fit_satlme4,"mmList"); names(ZMM) &lt;- "cluster"
lambda_seq &lt;- lseq(1e-6,1,length=100)
fit &lt;- rpqlseq(y = simy$y, X = XMM, Z = ZMM, id = simy$id, 
 	family = binomial(), lambda = lambda_seq, pen.type = "adl", 
	pen.weights = fit_sat$pen.weights, start = fit_sat)
summary(fit$best.fit[[5]]) ## Second of the hybrid ICs

## End(Not run)


##-------------------------
## Example 3: Bernoulli GLMMs on simulated data
## Nested data with 200 observations in total: split into 10 creeks, 
## 5 samples nested within each creek
##-------------------------
mn &lt;- 100; 
X &lt;- matrix(1,mn,1); 
ids &lt;- list(samples = rep(1:50,each=2), creek = rep(1:10,each=10)) 
## We have two sets of random intercepts only, one for creek and one for 
## samples nested within creek.
Zs &lt;- list(samples = X, creek = X) 

true_betas &lt;- 0.25
true_D &lt;- list(samples = as.matrix(1e-5), creek = as.matrix(0.5)) 
## Please ensure each element of true_D is a matrix

simy &lt;- gendat.glmm(id = ids, X = X, beta = true_betas, Z = Zs, 
	D = true_D, trial.size = 1, family = binomial())

## Not run: 
fit &lt;- rpqlseq(y = simy$y, X = simy$X, Z = simy$Z, id = simy$id, 
	family = binomial(), lambda = lambda_seq, pen.type = "scad")

summary(fit$best.fit[[5]]) ## Second of the hybrid ICs
# apply(fit$collect.ics, 2, which.min) ## Look at best fit chosen by different ICs

## End(Not run)
   

##-------------------------
## Example 4: Linear mixed models on Alfalfa split-plot data
##-------------------------
## Not run: 

library(nlme)
data(Alfalfa)
Alfalfa$Yield &lt;- scale(Alfalfa$Yield)
X &lt;- as.matrix(model.matrix(~ Date, data = Alfalfa)) 
## Note Date is categorical variable!
colnames(X)[1] &lt;- "x1"
Z &lt;- list(BlockVariety = matrix(1,nrow(X),1), Block = matrix(1,nrow(X),1))
## Four samples of each Block*Variety
ids &lt;- list(BlockVariety = rep(1:(nrow(X)/4),each=4), 
	Block = as.numeric(Alfalfa$Block)) 

## How you would fit it in lme4
fit_satlme4 &lt;- lmer(Yield ~ X - 1 + (1|Block/Variety), data = Alfalfa)
fit_sat &lt;- build.start.fit(fit_satlme4, cov.groups = c(1,2,2,2), gamma = 2)

## Construct a solution path using adaptive LASSO for selection
lambda_seq &lt;- lseq(1e-8,2,length=100)
fit &lt;- rpqlseq(y = Alfalfa$Yield, X = X, Z = Z, id = ids, 
	lambda = lambda_seq, cov.groups = c(1,2,2,2), pen.type = "adl", 
	pen.weights = fit_sat$pen.weights, start = fit_sat)

summary(fit$best.fit[[5]]) ## Second of the hybrid ICs
# apply(fit$collect.ics, 2, which.min) ## Look at best fit chosen by different ICs

## End(Not run)


##-------------------------
## Example 5: Linear mixed models on sleep study dataset
##-------------------------

## Not run: 

data(sleepstudy)

## How you fit it in lme4
## Response is scaled so as to avoid large variances and easier intepretation
sleepstudy$Reaction &lt;- scale(sleepstudy$Reaction) 
sleepstudy$Days &lt;- scale(sleepstudy$Days)
fm1 &lt;- lmer(Reaction ~ Days + (Days|Subject), sleepstudy)

## How you fit it using rpql
## Construct a solution path using adaptive LASSO for selection 
X &lt;- cbind(1, sleepstudy$Days)
Z &lt;- list(subject = X)
ids &lt;- list(subject = as.numeric(sleepstudy$Subject))
fit_sat &lt;- build.start.fit(fm1, gamma = 2)

lambda_seq &lt;- lseq(1e-8,1e-1,length=100)
fit &lt;- rpqlseq(y = sleepstudy$Reaction, X = X, Z = Z, id = ids, 
	lambda = lambda_seq, pen.type = "adl", 
	pen.weights = fit_sat$pen.weights, start = fit_sat)

summary(fit$best.fit[[5]]) ## Second of the hybrid ICs
# apply(fit$collect.ics, 2, which.min) ## Look at best fit chosen by different ICs
## Best fit might well be the saturated fit! 
## This is at least consistent with confint(fm1)

## End(Not run)


##-------------------------
## Example 6: GLMM with lognormal responses
## Fixed effects selection only
##-------------------------

## Not run: 

n &lt;- 50; m &lt;- 10; p &lt;- 8; 
H &lt;- abs(outer(1:p, 1:p, "-")) 
X &lt;- cbind(1,rmvnorm(n*m,rep(0,p),sigma=0.5^H)); 
Z &lt;- X[,1:3] ## 3 random effects all of which important
true_betas &lt;- c(0.1,1,-1,-1,1,rep(0,p-4)) ## 5 important fixed effects
true_D &lt;- matrix(0,ncol(Z),ncol(Z))
true_D[1:3,1:3] &lt;- matrix(c(1,0.6,0.6,0.6,1,0.4,0.6,0.4,1),3,3,byrow=TRUE) 

simy &lt;- gendat.glmm(id = list(cluster=rep(1:n,each=m)), X = X, 
	beta = true_betas, Z = list(cluster=Z), D = list(cluster=true_D), 
	family = LOGNO(), phi = 1) 

## We will use the SCAD penalty for fixed effects only with no weights
## Note lognormal mixed models are usually hard to fit by maximum likelihood in R!
## Hence adaptive weights are sightly hard to obtain

## Note also that since random effects are not penalized, then generally 
## the corresponding fixed effect covariates should not be penalized 
## (at least in longitudinal studies), in keeping in line with the 
## hierarchical principle of the effects.
## To account for this in the above, we can use the pen.weights argument 
## to prevent penalization of the first three fixed effect covariates

lambda_seq &lt;- lseq(1e-5,1,length=100)
fit &lt;- rpqlseq(y = simy$y, X = simy$X, Z = simy$Z, id = simy$id, 
  family = LOGNO(), lambda = lambda_seq, pen.type = "scad", 
	pen.weights = list(fixed = rep(c(0,1), c(3,ncol(X)-3))))

summary(fit$best.fit[[3]])  
# apply(fit$collect.ics, 2, which.min) ## Look at best fit chosen by different ICs

## End(Not run)

</code></pre>

<hr>
<h2 id='rpqlseq'>Wrapper function for joint effects selection in GLMMs using regularized PQL.</h2><span id='topic+rpqlseq'></span>

<h3>Description</h3>

<p><code>rpql</code> offers fast joint selection of fixed and random effects in Generalized Linear Mixed Model (GLMMs) via regularization. The penalized quasi-likelihood (PQL) is used as a loss function, and penalties are added on to perform fixed and random effects selection. This method of joint selection in GLMMs, referred to regularized PQL, is fast compared to information criterion and hypothesis testing (Hui et al., 2016). 
</p>
<p><code>rpqlseq</code> is a wrapper function to permit a sequence of tuning parameter values, which wraps around the code workhorse function <code>rpql</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rpqlseq(y, X, Z, id, family = gaussian(), trial.size = 1, lambda, 
  pen.type = "lasso", start = NULL, cov.groups = NULL, pen.weights = NULL, 
  offset = NULL, intercept = TRUE, save.data = FALSE, 
  control = list(tol = 1e-4, maxit = 100, trace = FALSE, restarts = 5, 
  scad.a = 3.7, mcp.gamma = 2, lasso.lambda.scale = TRUE, seed = NULL), ...)

  </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rpqlseq_+3A_y">y</code>, <code id="rpqlseq_+3A_x">X</code>, <code id="rpqlseq_+3A_z">Z</code>, <code id="rpqlseq_+3A_id">id</code>, <code id="rpqlseq_+3A_family">family</code>, <code id="rpqlseq_+3A_trial.size">trial.size</code></td>
<td>
<p>As per the <code>rpql</code> function. Please see the help file for <code>rpql</code> for details on the arguments.</p>
</td></tr>
<tr><td><code id="rpqlseq_+3A_lambda">lambda</code></td>
<td>
<p>Either a vector containing <b>sequence</b> of tuning parameter values, which is applied to both penalties, or two-column matrix containing a <b>sequence</b> of tuning parameter values for the fixed and random effects penalty respectively.</p>
</td></tr>
<tr><td><code id="rpqlseq_+3A_pen.type">pen.type</code>, <code id="rpqlseq_+3A_start">start</code>, <code id="rpqlseq_+3A_cov.groups">cov.groups</code>, <code id="rpqlseq_+3A_pen.weights">pen.weights</code>, <code id="rpqlseq_+3A_offset">offset</code>, <code id="rpqlseq_+3A_intercept">intercept</code>, <code id="rpqlseq_+3A_save.data">save.data</code>, <code id="rpqlseq_+3A_control">control</code></td>
<td>
<p>As per the <code>rpql</code> function. Please see the help file for <code>rpql</code> for details on the arguments.</p>
</td></tr>
<tr><td><code id="rpqlseq_+3A_...">...</code></td>
<td>
<p>Not used.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Please see the help file for <code>rpql</code> for details on how regularized PQL works. <code>rpqlseq</code> is simply a wrapper function to run the core <code>rpql</code> function multiple times, on a sequence of tuning parameter values, in order to construct a regularization path. The best models, based on different information criteria for selecting the best tuning parameter (degree of sparsity) are then returned.
</p>


<h3>Value</h3>

<p>An object of class &quot;rpql&quot; containing the following elements:
</p>
<table>
<tr><td><code>best.fits</code></td>
<td>
<p>A list containing the best fitted models as based on different information criteria used to select the tuning parameter. Each element in this list has the same structure as the output from the <code>rpql</code> function. Please see the <code>rpql</code> function for details on the information criteria available as well as the nature of the output.</p>
</td></tr>
<tr><td><code>collect.ics</code></td>
<td>
<p>A matrix containing the values of various information criteria calculated for the sequence of <code>lambda</code> values supplied. The best fitted models found in <code>best.fits</code> is based off this matrix i.e., each element in <code>best.fits</code> corresponds to a model that was chosen based on minimizing the corresponding information criterion in <code>collect.ics</code>. Please see the <code>rpql</code> function for details on the information criteria available.</p>
</td></tr>
<tr><td><code>lambda</code></td>
<td>
<p>The sequence of tuning parameters considered.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Francis K.C. Hui &lt;francis.hui@gmail.com&gt;, with contributions from Samuel Mueller &lt;samuel.mueller@sydney.edu.au&gt; and A.H. Welsh &lt;Alan.Welsh@anu.edu.au&gt;
</p>
<p>Maintainer: Francis Hui &lt;fhui28@gmail.com&gt;
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rpql">rpql</a></code>, which is the core workhorse function that performed regularized PQL for a single set of tuning parameter values.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Please see examples in help file for the \code{rpql} function for usage.
</code></pre>

<hr>
<h2 id='summary.rpql'>Summary of GLMM fitted using regularized PQL.</h2><span id='topic+summary.rpql'></span><span id='topic+print.summary.rpql'></span>

<h3>Description</h3>

<p>A summary of the results from applying <code>rpql</code>.</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'rpql'
summary(object, ...)

## S3 method for class 'summary.rpql'
print(x,...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.rpql_+3A_object">object</code></td>
<td>
<p>An object of class &quot;rpql&quot;.</p>
</td></tr>
<tr><td><code id="summary.rpql_+3A_x">x</code></td>
<td>
<p>An object of class &quot;rpql&quot;.</p>
</td></tr>
<tr><td><code id="summary.rpql_+3A_...">...</code></td>
<td>
<p>Not used.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list (some of which is printed) containing the following elements:
</p>
<table>
<tr><td><code>Call</code></td>
<td>
<p>The matched call.</p>
</td></tr>
<tr><td><code>fixed</code></td>
<td>
<p>Estimated fixed effects coefficients.</p>
</td></tr>
<tr><td><code>ranef</code></td>
<td>
<p>A list with each element being a matrix of estimated random effects coefficients.</p>
</td></tr>
<tr><td><code>ran.cov</code></td>
<td>
<p>A list with each element being a estimated random effects covariance matrix.</p>
</td></tr>
<tr><td><code>logLik</code></td>
<td>
<p>PQL log-likelihood value at convergence.</p>
</td></tr>
<tr><td><code>family</code></td>
<td>
<p>The <code>family</code> argument, i.e. response type.</p>
</td></tr>
<tr><td><code>pen.type</code>, <code>lambda</code></td>
<td>
<p>Penalties used for selection and the corresponding tuning parameter values.</p>
</td></tr>
<tr><td><code>ics</code></td>
<td>
<p>A vector containing the number of estimated, non-zero parameters, and three information criterion. Please see the help file for <code>rpql</code> for details on these criteria.</p>
</td></tr>
<tr><td><code>id</code></td>
<td>
<p>The <code>id</code> argument, i.e. list of IDs.</p>
</td></tr>
<tr><td><code>nonzero.fixef</code></td>
<td>
<p>A vector indexing which of the estimated fixed effect coefficients are non-zero.</p>
</td></tr>
<tr><td><code>nonzero.ranef</code></td>
<td>
<p>A list with each element being a vector indexing which of the estimated random effects are non-zero, i.e. which of the diagonal elements in the corresponding element of <code>ran.cov</code> are non-zero.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Francis K.C. Hui &lt;francis.hui@gmail.com&gt;, with contributions from Samuel Mueller &lt;samuel.mueller@sydney.edu.au&gt; and A.H. Welsh &lt;Alan.Welsh@anu.edu.au&gt;
</p>
<p>Maintainer: Francis Hui &lt;fhui28@gmail.com&gt;
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rpql">rpql</a></code> for fitting and performing model selection in GLMMs using regularized PQL.</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Please see other examples in help file for the \code{rpql} function.
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
