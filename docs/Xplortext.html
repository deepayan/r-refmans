<!DOCTYPE html><html><head><title>Help for package Xplortext</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {Xplortext}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#Xplortext-package'><p>Textual Analysis</p></a></li>
<li><a href='#ellipseLexCA'><p>Confidence ellipses on textual correspondence analysis graphs</p></a></li>
<li><a href='#LabelTree'><p>Hierarchical words (LabelTree)</p></a></li>
<li><a href='#LexCA'><p>Correspondence Analysis of a Lexical Table from a TextData object (LexCA)</p></a></li>
<li><a href='#LexChar'><p>Characteristic words and documents (LexChar)</p></a></li>
<li><a href='#LexCHCca'><p>Chronological Constrained Hierarchical Clustering on Correspondence Analysis Components (LexCHCca)</p></a></li>
<li><a href='#LexGalt'><p>Correspondence Analysis on a Simple or Multiple Generalized Aggregate Lexical Table (LexGalt)</p></a></li>
<li><a href='#LexHCca'><p>Hierarchical Clustering on Textual Correspondence Analysis Coordinates (LexHCca)</p></a></li>
<li><a href='#open.question'><p>Open.question (data)</p></a></li>
<li><a href='#plot.LexCA'><p>Plot of LexCA objects</p></a></li>
<li><a href='#plot.LexChar'><p>Plot LexChar objects</p></a></li>
<li><a href='#plot.LexCHCca'><p>Plots for Chronological Constrained Hierarchical Clustering from LexCHCca Objects</p></a></li>
<li><a href='#plot.LexGalt'><p>Plot LexGalt objects</p></a></li>
<li><a href='#plot.LexHCca'><p>Plots for Hierarchical Clustering from LexHCca Objects</p></a></li>
<li><a href='#plot.TextData'><p>Plot TextData objects</p></a></li>
<li><a href='#print.LexCA'><p>Print LexCA objects</p></a></li>
<li><a href='#print.LexChar'><p>Print LexChar objects</p></a></li>
<li><a href='#print.TextData'><p>Print TextData objects</p></a></li>
<li><a href='#summary.LexCA'><p>Summary LexCA object</p></a></li>
<li><a href='#summary.LexChar'><p>Summary LexChar object</p></a></li>
<li><a href='#summary.TextData'><p>Summary of TextData objects</p></a></li>
<li><a href='#TextData'><p>Building textual and contextual tables (TextData)</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Title:</td>
<td>Statistical Analysis of Textual Data</td>
</tr>
<tr>
<td>Version:</td>
<td>1.5.3</td>
</tr>
<tr>
<td>Date:</td>
<td>2023-11-09</td>
</tr>
<tr>
<td>Author:</td>
<td>Mónica Bécue-Bertaut, Ramón Alvarez-Esteban, Josep-Anton Sánchez-Espigares, Belchin Kostov</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Ramón Alvarez-Esteban &lt;ramon.alvarez@unileon.es&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Provides a set of functions devoted to multivariate exploratory statistics on textual data. Classical methods such as correspondence analysis and agglomerative hierarchical clustering are available. Chronologically constrained agglomerative hierarchical clustering enriched with labelled-by-words trees is offered. Given a division of the corpus into parts, their characteristic words and documents are identified. Further, accessing to 'FactoMineR' functions is very easy. Two of them are relevant in textual domain. MFA() addresses multiple lexical table allowing applications such as dealing with multilingual corpora as well as simultaneously analyzing both open-ended and closed questions in surveys. See <a href="http://xplortext.unileon.es">http://xplortext.unileon.es</a> for examples.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2.0)]</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 4.3), FactoMineR(&ge; 2.8), ggplot2(&ge; 3.4.2), tm(&ge;
0.7-11)</td>
</tr>
<tr>
<td>Imports:</td>
<td>flexclust(&ge; 1.4-1), flashClust(&ge; 1.01-2), ggdendro(&ge;
0.1.23), ggforce(&ge; 0.4.1), ggrepel(&ge; 0.9.3), plotly(&ge;
4.10.1), graphics(&ge; 4.3.0), gridExtra(&ge; 2.3), MASS(&ge;
7.3-58.4), methods(&ge; 4.3.0), stringi(&ge; 1.7.12), stringr(&ge;
1.5.0), slam(&ge; 0.1-50), stats(&ge; 4.3.0), utils(&ge; 4.3.0),
vegan(&ge; 2.6-4)</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://xplortext.unileon.es">https://xplortext.unileon.es</a></td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.1</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-11-09 17:25:34 UTC; ralve</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-11-09 18:00:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='Xplortext-package'>Textual Analysis</h2><span id='topic+Xplortext-package'></span>

<h3>Description</h3>

<p>Provides a set of functions devoted to multivariate exploratory statistics on textual data.
Classical methods such as correspondence analysis and agglomerative hierarchical clustering are available.
Chronologically constrained agglomerative hierarchical clustering enriched with labelled-by-words trees is offered.
Given a division of the corpus into parts, their characteristic words and documents are identified.
Further, accessing to 'FactoMineR' functions is very easy. Two of them are relevant in textual domain.
MFA() addresses multiple lexical table allowing applications such as dealing with multilingual corpora as well as simultaneously analyzing both open-ended and closed questions in surveys. 
See <a href="https://xplortext.unileon.es">https://xplortext.unileon.es</a> for examples.
</p>


<h3>Details</h3>


<table>
<tr>
 <td style="text-align: left;">
Package: </td><td style="text-align: left;"> Xplortext</td>
</tr>
<tr>
 <td style="text-align: left;">
Type: </td><td style="text-align: left;"> Package</td>
</tr>
<tr>
 <td style="text-align: left;">
Version: </td><td style="text-align: left;"> 1.5.3</td>
</tr>
<tr>
 <td style="text-align: left;">
Date: </td><td style="text-align: left;"> 2023-11-09</td>
</tr>
<tr>
 <td style="text-align: left;">
License: GPL (&gt;=2.0)
</td>
</tr>

</table>



<h3>Author(s)</h3>

<p>Mónica Bécue-Bertaut, Ramón Alvarez-Esteban, Josep-Anton Sánchez-
Espigares, Belchin Kostov<br />
Maintainer: <a href="mailto:ramon.alvarez@unileon.es">ramon.alvarez@unileon.es</a>
</p>


<h3>References</h3>

<p>Bécue, M. (2019). Textual Data Science with R. Chapman &amp; Hall/CRC. <a href="https://doi.org/10.1201/9781315212661">doi:10.1201/9781315212661</a>.
</p>
<p>Husson F., Lê S., Pagès J. (2011). Exploratory Multivariate Analysis by Example Using R. Chapman &amp; Hall/CRC. <a href="https://doi.org/10.1201/b10345">doi:10.1201/b10345</a>.
</p>
<p>Lebart, L., Salem, A., &amp; Berry, L. (1998). Exploring textual data. (D. Kluwer, Ed.).
<a href="https://doi.org/10.1007/978-94-017-1525-6">doi:10.1007/978-94-017-1525-6</a>.
</p>
<p>A website <a href="https://xplortext.unileon.es">https://xplortext.unileon.es</a>
</p>

<hr>
<h2 id='ellipseLexCA'>Confidence ellipses on textual correspondence analysis graphs</h2><span id='topic+ellipseLexCA'></span>

<h3>Description</h3>

<p>Draws confidence ellipses around documents and/or words on a textual CA graph.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ellipseLexCA(object, selWord="ALL", selDoc="ALL", nbsample=100, level.conf=0.95,
    axes=c(1, 2), ncp=NULL, xlim=NULL, ylim=NULL, title=NULL, col.doc="blue",
    col.word="red", col.doc.ell=col.doc, col.word.ell=col.word, cex=1) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ellipseLexCA_+3A_object">object</code></td>
<td>
<p>object of LexCA class</p>
</td></tr>
<tr><td><code id="ellipseLexCA_+3A_selword">selWord</code></td>
<td>
<p>selected words (indexes or names; by default &quot;ALL&quot;); see the details section</p>
</td></tr>
<tr><td><code id="ellipseLexCA_+3A_seldoc">selDoc</code></td>
<td>
<p>selected docs (indexes or names; by default &quot;ALL&quot;); see the details section</p>
</td></tr>
<tr><td><code id="ellipseLexCA_+3A_nbsample">nbsample</code></td>
<td>
<p>number of samples drawn to evaluate the stability of the points</p>
</td></tr>
<tr><td><code id="ellipseLexCA_+3A_level.conf">level.conf</code></td>
<td>
<p>confidence level used to construct the ellipses (by default 0.95)</p>
</td></tr>
<tr><td><code id="ellipseLexCA_+3A_axes">axes</code></td>
<td>
<p>length 2 vector specifying the dimensions to plot</p>
</td></tr>
<tr><td><code id="ellipseLexCA_+3A_ncp">ncp</code></td>
<td>
<p>maximum number of dimension to draw (by default NULL and ncp is the number of dimensions from LexCA object)</p>
</td></tr>
<tr><td><code id="ellipseLexCA_+3A_xlim">xlim</code></td>
<td>
<p>range for the plotted 'x' values, defaulting to the range of the finite values of 'x' (by default NULL)</p>
</td></tr>
<tr><td><code id="ellipseLexCA_+3A_ylim">ylim</code></td>
<td>
<p>range for the plotted 'y' values, defaulting to the range of the finite values of 'y' (by default NULL)</p>
</td></tr>
<tr><td><code id="ellipseLexCA_+3A_title">title</code></td>
<td>
<p>title of the graph (by default NULL and the title is automatically assigned)</p>
</td></tr>
<tr><td><code id="ellipseLexCA_+3A_col.doc">col.doc</code></td>
<td>
<p>color for the documents-points (by default &quot;blue&quot;)</p>
</td></tr>
<tr><td><code id="ellipseLexCA_+3A_col.word">col.word</code></td>
<td>
<p>color for words-points (by default &quot;red&quot;)</p>
</td></tr>
<tr><td><code id="ellipseLexCA_+3A_col.doc.ell">col.doc.ell</code></td>
<td>
<p>color for the ellipses around documents-points (by default the same as col.doc)</p>
</td></tr>
<tr><td><code id="ellipseLexCA_+3A_col.word.ell">col.word.ell</code></td>
<td>
<p>color for the ellipses around words-points (by default the same as col.word)</p>
</td></tr>
<tr><td><code id="ellipseLexCA_+3A_cex">cex</code></td>
<td>
<p>text and symbol size is scaled by cex, in relation to size 1 (by default 1)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The method &quot;multinomial&quot; is used to generate the replicated tables. 
So, the active lexical table contained in the LexCA object (active table) is taken as a reference.
</p>
<p>Then, replicated lexical tables are generated by repeating nbsample times the following process: N (the sum of active table elements) values are drawn from a multinomial distribution with theoretical frequencies equal to the values in the active table cells divided by N. A replicated table is built from each drawing.
</p>
<p>The nbsample documents-rows and/or words-columns of the replicated tables are projected as supplementary documents (rows) and/or supplementary words (columns) on the graph computed from the active lexical table. 
Then, confidence ellipses are drawn around each active element from the nbsample supplementary points.<br />
The replicated samples with empty row-documents and/or word-columns with null frequency are dropped. <br /> 
If over 10% of the total of replicated samples are dropped, the execution is stopped. Information is given through a stop-message.<br />
</p>
<p>The selDoc and selWord arguments allow for selecting the documents and/ or words.<br />
The syntax for these arguments is similar to the one used in plot.LexCA. <br /> 
However they only concern the active elements and selecting the characteristic words is not allowed.
</p>
<p>Some examples follow:
selDoc=c(1:5): the documents 1 to 5 are represented.<br />
selDoc=c(&quot;doc1&quot;,&quot;doc5&quot;): documents with labels doc1 or doc5 are represented.<br />
selWord=c(&quot;word1&quot;,&quot;word3&quot;): words with labels word1 or word3 are represented.<br />
selDoc/selWord = &quot;coord 10&quot;: the 10 documents/words with the highest coordinates on the 2
chosen axes are selected.<br />
selDoc/selWord=&quot;contrib 10&quot;: documents/words with a contribution to the inertia of any of both axes over 10% of the axis inertia are selected.<br />
selDoc/selWord=&quot;cos2 0.85: the documents/words with cos2 over 0.85 (as summed on the 2 axes) are selected.<br />
selDoc =&quot;meta 3&quot;: documents/words with a contribution over 3 times the average document/word contribution on any of both axes are selected.<br />
</p>


<h3>Value</h3>

<p>Returns a LexCA-like map representing the selected points and their confidence ellipses
</p>


<h3>Author(s)</h3>

<p>Monica Bécue-Bertaut, Ramón Alvarez-Esteban <a href="mailto:ramon.alvarez@unileon.es">ramon.alvarez@unileon.es</a>, Josep-Antón Sánchez-Espigares</p>


<h3>References</h3>

<p>Husson F., Lê S., Pagès J. (2011). Exploratory Multivariate Analysis by Example Using R. Chapman &amp; Hall/CRC. <a href="https://doi.org/10.1201/b10345">doi:10.1201/b10345</a>.
</p>
<p>Lebart, L., Piron, M., &amp; Morineau, A. (2006). Statistique exploratoire multidimensionnelle. (Dunod, Ed.).
</p>
<p>Lebart, L., Salem, A., &amp; Berry, L. (1998). Exploring textual data. (Kluwer, Ed.). <a href="https://doi.org/10.1007/978-94-017-1525-6">doi:10.1007/978-94-017-1525-6</a>.
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+LexCA">LexCA</a></code>, <code><a href="#topic+print.LexCA">print.LexCA</a></code>,  <code><a href="#topic+plot.LexCA">plot.LexCA</a></code>, <code><a href="#topic+summary.LexCA">summary.LexCA</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(open.question)
res.TD&lt;-TextData(open.question, var.text=c(9,10), remov.number=TRUE, Fmin=10, Dmin=10,  
  stop.word.tm=TRUE, context.quali=c("Gender","Age_Group","Education"), 
  context.quanti=c("Age"))
res.LexCA&lt;-LexCA(res.TD, graph=FALSE,ncp=8)
ellipseLexCA(res.LexCA, selWord="meta 1",selDoc=NULL, col.word="brown")
ellipseLexCA(res.LexCA, selWord="contrib 10",selDoc=NULL, col.word="brown")
ellipseLexCA(res.LexCA, selWord=c("work","job","money","comfortable"), selDoc=NULL,
  col.word="brown")
ellipseLexCA(res.LexCA, selWord="cos2 0.2", selDoc=NULL, col.word="brown")

## End(Not run)
## Not run: 
data(open.question)
res.TD&lt;-TextData(open.question, var.text=c(9,10), var.agg="Gen_Age", Fmin=10, Dmin=10,
  remov.number=TRUE, stop.word.tm=TRUE)
res.LexCA&lt;-LexCA(res.TD, graph=FALSE)
ellipseLexCA(res.LexCA, selWord=NULL, col.doc="black")
ellipseLexCA(res.LexCA, selWord="meta 3", selDoc=NULL, col.word="brown")
ellipseLexCA(res.LexCA, selWord="contrib 10", selDoc=NULL, col.word="brown")
ellipseLexCA(res.LexCA, selWord=c("work","job","money","comfortable"), selDoc=NULL,
       col.word="brown")
ellipseLexCA(res.LexCA, selWord="cos2 0.2", selDoc=NULL, col.word="brown")    
	
## End(Not run)
</code></pre>

<hr>
<h2 id='LabelTree'>Hierarchical words (LabelTree)</h2><span id='topic+LabelTree'></span>

<h3>Description</h3>

<p>Extracts the hierarchical characteristic words associated to the nodes of a hierarchical tree; the characteristic words of each node are extracted, then each word is associated to the node that it best characterizes.</p>


<h3>Usage</h3>

<pre><code class='language-R'>LabelTree(object, proba=0.05)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="LabelTree_+3A_object">object</code></td>
<td>
<p>object of LexHCca or LexCHCca class</p>
</td></tr>
<tr><td><code id="LabelTree_+3A_proba">proba</code></td>
<td>
<p>threshold on the p-value when the characteristic words are computed (by default 0.05)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a list including:
</p>
<table>
<tr><td><code>hierWord</code></td>
<td>
<p>list of the characteristic words associated to the nodes of a hierarchical tree; 
only the non-empty nodes are included</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Monica Bécue-Bertaut, Ramón Alvarez-Esteban <a href="mailto:ramon.alvarez@unileon.es">ramon.alvarez@unileon.es</a>, Josep-Anton 
Sánchez-Espigares, Belchin Kostov</p>


<h3>References</h3>

<p>Bécue-Bertaut, M., Kostov, B., Morin, A., &amp; Naro, G. (2014). Rhetorical Strategy in Forensic Speeches: 
Multidimensional Statistics-Based Methodology. Journal of Classification,31,85-106. <a href="https://doi.org/10.1007/s00357-014-9148-9">doi:10.1007/s00357-014-9148-9</a>.
</p>
<p>Lebart, L., Salem, A., &amp; Berry, L. (1998). Exploring textual data. (D. Kluwer, Ed.). <a href="https://doi.org/10.1007/978-94-017-1525-6">doi:10.1007/978-94-017-1525-6</a>.
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+LexCA">LexCA</a></code>, <code><a href="#topic+LexCHCca">LexCHCca</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>data(open.question)
res.TD&lt;-TextData(open.question,var.text=c(9,10), var.agg="Age_Group", Fmin=10, Dmin=10,
        stop.word.tm=TRUE)
 res.LexCA&lt;-LexCA(res.TD, graph=FALSE)
 res.LexCHCca&lt;-LexCHCca(res.LexCA, nb.clust=4, min=3)
 res.LabelTree&lt;-LabelTree(res.LexCHCca)
</code></pre>

<hr>
<h2 id='LexCA'>Correspondence Analysis of a Lexical Table from a TextData object (LexCA)</h2><span id='topic+LexCA'></span>

<h3>Description</h3>

<p>Performs Correspondence Analysis on the working lexical table contained in TextData object. Supplementary documents, words, segments, contextual quantitative and qualitative variables can be considered if previously selected in TextData function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LexCA(object, ncp=5, context.sup="ALL", doc.sup=NULL, word.sup=NULL, 
  segment=FALSE, graph=TRUE, axes=c(1, 2), lmd=3, lmw=3)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="LexCA_+3A_object">object</code></td>
<td>
<p>object of TextData class</p>
</td></tr>
<tr><td><code id="LexCA_+3A_ncp">ncp</code></td>
<td>
<p>number of dimensions kept in the results (by default 5)</p>
</td></tr>
<tr><td><code id="LexCA_+3A_context.sup">context.sup</code></td>
<td>
<p>column index(es) or name(s) of the contextual qualitative or quantitative variables among those selected in TextData function (by default &quot;ALL&quot;)</p>
</td></tr>
<tr><td><code id="LexCA_+3A_doc.sup">doc.sup</code></td>
<td>
<p>vector indicating the index(es) or name(s) of the supplementary documents (rows) (by default NULL)</p>
</td></tr>
<tr><td><code id="LexCA_+3A_word.sup">word.sup</code></td>
<td>
<p>vector indicating the index(es) or name(s) of the supplementary words (columns) (by default NULL)</p>
</td></tr>
<tr><td><code id="LexCA_+3A_segment">segment</code></td>
<td>
<p>if TRUE, the repeated segments identified by TextData function will be considered as supplementary columns (by default FALSE)</p>
</td></tr> 
<tr><td><code id="LexCA_+3A_graph">graph</code></td>
<td>
<p>if TRUE, basic graphs are displayed; use plot.LexCA to obtain more graphs (by default TRUE)</p>
</td></tr>
<tr><td><code id="LexCA_+3A_axes">axes</code></td>
<td>
<p>length-2 vector indicating the axes to plot (by default axes=c(1,2))</p>
</td></tr>
<tr><td><code id="LexCA_+3A_lmd">lmd</code></td>
<td>
<p>only the documents whose contribution is over lmd times the average-document-contribution are plotted (by default lmd=3)</p>
</td></tr>
<tr><td><code id="LexCA_+3A_lmw">lmw</code></td>
<td>
<p>only the words whose contribution is over lmw times the average-word-contribution are plotted (by default lmw=3)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In the case of a direct CA, DocTerm is a non-aggregate table and:
</p>

<ol>
<li><p> the contextual quantitative variables are considered as supplementary quantitative columns in CA. 
</p>
</li>
<li><p> the categories of the contextual qualitative variables are considered as supplementary columns in CA.</p>
</li></ol>

<p>In the case of an aggregate CA, DocTerm is an aggregate table and:
</p>

<ol>
<li><p> the contextual quantitative variables are considered as supplementary quantitative columns in CA; the value of an active aggregate-document for a variable is the mean of the values corresponding to
the source-documents belonging to this aggregate-document.
</p>
</li>
<li><p> the categories of the contextual qualitative variables are threatened as supplementary rows in CA; these rows contain the frequency with which each the set of documents belonging to this category has used the different words. </p>
</li></ol>



<h3>Value</h3>

<p>Returns a list including:
</p>
<table>
<tr><td><code>eig</code></td>
<td>
<p>matrix with the eigenvalues, the percentages of inertia and the cumulative percentages of inertia</p>
</td></tr>
<tr><td><code>row</code></td>
<td>
<p>list of matrices with all the results for the documents
(coordinates, square cosines, contributions, inertia)</p>
</td></tr>
<tr><td><code>col</code></td>
<td>
<p>list of matrices with all the results for the words (coordinates, square cosines, contributions, inertia)</p>
</td></tr>
<tr><td><code>row.sup</code></td>
<td>
<p>if row.sup is non-NULL, list of matrices with all the results for the supplementary documents (coordinates, square cosines)</p>
</td></tr>
<tr><td><code>col.sup</code></td>
<td>
<p>if col.sup is non-NULL, list of matrices with all the results for the supplementary words (coordinates, square cosines)</p>
</td></tr>
<tr><td><code>quanti.sup</code></td>
<td>
<p>if quanti.sup is non-NULL, list of matrices containing the results for the supplementary quantitative variables (coordinates, square cosines)</p>
</td></tr>
<tr><td><code>quali.sup</code></td>
<td>
<p>if quali.sup is non-NULL, list of matrices with all the results for the supplementary categorical variables; see section details</p>
</td></tr>
<tr><td><code>meta</code></td>
<td>
<p>list of the documents/words whose contribution is over lmd/lmw times the average document/word contribution</p>
</td></tr>
<tr><td><code>VCr</code></td>
<td>
<p>Cramer's V coefficient</p>
</td></tr>
<tr><td><code>Inertia</code></td>
<td>
<p>total inertia</p>
</td></tr>
<tr><td><code>info</code></td>
<td>
<p>information about the corpus</p>
</td></tr>
<tr><td><code>segment</code></td>
<td>
<p>if segment is TRUE, list of matrices with the results for the repeated segments (coordinates, square cosines)</p>
</td></tr>
<tr><td><code>var.agg</code></td>
<td>
<p>name of the aggregation variable in the case of an aggregate correspondence analysis</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>a list with some statistics</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Ramón Alvarez-Esteban <a href="mailto:ramon.alvarez@unileon.es">ramon.alvarez@unileon.es</a>, Mónica Bécue-Bertaut, Josep-Anton 
Sánchez-Espigares<br /></p>


<h3>References</h3>

<p>Benzécri, J, P. (1981). Pratique de l'analyse des donnees. Linguistique &amp; lexicologie (Vol.3). (P. Dunod., Ed).
</p>
<p>Husson F., Lê S., Pagès J. (2011). Exploratory Multivariate Analysis by Example Using R. Chapman &amp; Hall/CRC. <a href="https://doi.org/10.1201/b10345">doi:10.1201/b10345</a>.
</p>
<p>Lebart, L., Salem, A., &amp; Berry, L. (1998). Exploring textual data. (D. Kluwer, Ed.). <a href="https://doi.org/10.1007/978-94-017-1525-6">doi:10.1007/978-94-017-1525-6</a>.
</p>
<p>Murtagh F. (2005). Correspondence Analysis and Data Coding with R and Java. Chapman &amp; Hall/CRC.
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+TextData">TextData</a></code>, <code><a href="#topic+print.LexCA">print.LexCA</a></code>,  <code><a href="#topic+plot.LexCA">plot.LexCA</a></code>, <code><a href="#topic+summary.LexCA">summary.LexCA</a></code>, <code><a href="#topic+ellipseLexCA">ellipseLexCA</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>data(open.question)
## Not run: 
### non-aggregate CA
res.TD&lt;-TextData(open.question, var.text=c(9,10), Fmin=10, Dmin=10,
        remov.number=TRUE, stop.word.tm=TRUE)
res.LexCA&lt;-LexCA(res.TD, lmd=0, lmw=1)

## End(Not run)

### aggregate CA
res.TD&lt;-TextData(open.question, var.text=c(9,10), var.agg="Age_Group", Fmin=10, Dmin=10,
        remov.number=TRUE, stop.word.tm=TRUE)
res.LexCA&lt;-LexCA(res.TD, lmd=0, lmw=1)
</code></pre>

<hr>
<h2 id='LexChar'>Characteristic words and documents (LexChar)</h2><span id='topic+LexChar'></span>

<h3>Description</h3>

<p>Measure of the association between vocabulary or words and quantitative or qualitative contextual variables.</p>


<h3>Usage</h3>

<pre><code class='language-R'>LexChar(object, proba=0.05, maxCharDoc=10, maxPrnDoc=100, 
              marg.doc="before",  context=NULL, correct=TRUE, nbsample=500,
              seed=12345,...)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="LexChar_+3A_object">object</code></td>
<td>
<p>TextData, DocumentTermMatrix, dataframe or matrix object</p>
</td></tr>
<tr><td><code id="LexChar_+3A_proba">proba</code></td>
<td>
<p>threshold on the p-value used when selecting the characteristic words (by default 0.05)</p>
</td></tr>
<tr><td><code id="LexChar_+3A_maxchardoc">maxCharDoc</code></td>
<td>
<p>maximum number of characteristic source-documents to extract (by default 10). See details</p>
</td></tr>
<tr><td><code id="LexChar_+3A_maxprndoc">maxPrnDoc</code></td>
<td>
<p>maximum length to be printed for a characteristic document (by default 100 characters)</p>
</td></tr>
<tr><td><code id="LexChar_+3A_marg.doc">marg.doc</code></td>
<td>
<p>if after/before, frequencies after/before TextData selection are used as document weighting (by default &quot;before&quot;); 
if before.RW all words under threshold in TextData function are included as a new word named RemovedWords</p>
</td></tr>
<tr><td><code id="LexChar_+3A_context">context</code></td>
<td>
<p>name of quantitative or qualitative variables</p>
</td></tr>
<tr><td><code id="LexChar_+3A_correct">correct</code></td>
<td>
<p>if TRUE, pvalue correction test is applied for quantitative contextual variables (by default TRUE)</p>
</td></tr>
<tr><td><code id="LexChar_+3A_nbsample">nbsample</code></td>
<td>
<p>number of samples drawn to evaluate the pvalues in quantitative contextual variables</p>
</td></tr>
<tr><td><code id="LexChar_+3A_seed">seed</code></td>
<td>
<p>Seed to obtain the same results using permutation tests (by default 12345)</p>
</td></tr>
<tr><td><code id="LexChar_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The lexical table provided by TextData can consider either source-documents or aggregate-documents, in accordance with the value of argument &quot;var.agg&quot; in TextData.
Context cualitative variables allow to aggregate documents by combining the categories of the qualitative variables and the aggregation variable if any.
</p>
<p>Extracting the characteristic words (CharWord) for a too high number of documents is of no interest and time-consuming. 
</p>
<p>In any case, only the first maxPrnDoc characters of each characteristic document are printed (by default 100).
</p>
<p>In the case of the association between words and qualitative variables, the usual characteristic words are provided.
</p>
<p>quali$CharWord provides the qualitative variables (including the aggregation variable) and their categories.
quali$stats provides association statistics for vocabulary and qualitative variables (including the aggregation variable).
quali$CharDoc provides characteristic source-documents for the categories.
quanti$CharWord provides characteristic quantitative variables for each word. If there are aggregation variable and/or qualitative contextual variable, from aggregated lexical table.
quanti$stats provides statistics for vocabulary and quantitative variables. If there are aggregation variable and/or qualitative contextual variable, from aggregated lexical table.
</p>
<p>If the lexical table (object) is not a TextData object, context argument can be columns of the same dataframe.
The aggregate lexical table is constructed from the combinations of the categories of the qualitative variables (including the aggregation variable).
</p>


<h3>Value</h3>

<p>Returns a list including:
</p>
<table>
<tr><td><code>CharWord</code></td>
<td>
<p>characteristic words of all the documents</p>
</td></tr>
<tr><td><code>stats</code></td>
<td>
<p>association statistics of the lexical table</p>
</td></tr>
<tr><td><code>CharDoc</code></td>
<td>
<p>characteristic source-documents of all the aggregate-documents including qualitative contextual variables</p>
</td></tr>
<tr><td><code>Vocab</code></td>
<td>
<p>characteristic quantitative and qualitative variables of the words. CharWord and stats are provided.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Monica Bécue-Bertaut, Ramón Alvarez-Esteban <a href="mailto:ramon.alvarez@unileon.es">ramon.alvarez@unileon.es</a>, Josep-Antón
Sánchez-Espigares, Belchin Kostov</p>


<h3>References</h3>

<p>Lebart, L., Salem, A., &amp; Berry, L. (1998). Exploring textual data. (D. Kluwer, Ed.). <a href="https://doi.org/10.1007/978-94-017-1525-6">doi:10.1007/978-94-017-1525-6</a>.
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+TextData">TextData</a></code>, <code><a href="#topic+print.LexChar">print.LexChar</a></code>, <code><a href="#topic+plot.LexChar">plot.LexChar</a></code>, <code><a href="#topic+summary.LexChar">summary.LexChar</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>data(open.question)
 res.TD&lt;-TextData(open.question, var.text=c(9,10), var.agg="Gen_Edu", Fmin=10, Dmin=10,
                   remov.number=TRUE, stop.word.tm=TRUE)
 res.LexChar &lt;-LexChar(res.TD)
 summary(res.LexChar)
</code></pre>

<hr>
<h2 id='LexCHCca'>Chronological Constrained Hierarchical Clustering on Correspondence Analysis Components (LexCHCca)</h2><span id='topic+LexCHCca'></span>

<h3>Description</h3>

<p>Chronological constrained agglomerative hierarchical clustering on a corpus of documents</p>


<h3>Usage</h3>

<pre><code class='language-R'>LexCHCca (object, nb.clust=0, min=2, max=NULL, nb.par=5, 
 graph=TRUE, proba=0.05, cut.test=FALSE, alpha.test =0.05, description=FALSE,
 nb.desc=5, size.desc=80)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="LexCHCca_+3A_object">object</code></td>
<td>
<p>object of LexCA class</p>
</td></tr>
<tr><td><code id="LexCHCca_+3A_nb.clust">nb.clust</code></td>
<td>
<p>number of clusters only if no test (cut.test=FALSE). If 0 (or &quot;click&quot;), the tree is cut at the level the user clicks on. If -1 (or &quot;auto&quot;), the tree is automatically cut at the suggested level. If a (positive) integer, the tree is cut with nb.clust clusters (by default 0)</p>
</td></tr>
<tr><td><code id="LexCHCca_+3A_min">min</code></td>
<td>
<p>minimum number of clusters. Available only if cut.test=FALSE. (by default 3)</p>
</td></tr>
<tr><td><code id="LexCHCca_+3A_max">max</code></td>
<td>
<p>maximum number of clusters. Available only if cut.test=FALSE. (by default NULL; then max is computed as the minimum between 10 and the number of documents divided by 2)</p>
</td></tr>
<tr><td><code id="LexCHCca_+3A_nb.par">nb.par</code></td>
<td>
<p>number of edited paragons (para) and specific documents labels (dist) (by default 5)</p>
</td></tr>
<tr><td><code id="LexCHCca_+3A_graph">graph</code></td>
<td>
<p>if TRUE, graphs are displayed (by default TRUE)</p>
</td></tr>
<tr><td><code id="LexCHCca_+3A_proba">proba</code></td>
<td>
<p>threshold on the p-value used to describe the clusters (by default 0.05)</p>
</td></tr>
<tr><td><code id="LexCHCca_+3A_cut.test">cut.test</code></td>
<td>
<p>if FALSE (by default), Legendre test is not performed when joining two nodes. This test is used to determine whether two clusters should be joined or not; see details</p>
</td></tr>
<tr><td><code id="LexCHCca_+3A_alpha.test">alpha.test</code></td>
<td>
<p>threshold on the p-value used in selecting aggregation clusters for Legendre test (by default 0.05)</p>
</td></tr>
<tr><td><code id="LexCHCca_+3A_description">description</code></td>
<td>
<p>if TRUE, description of the clusters by the characteristic words/documents, paragon (para), specific documents (dist) and contextual variables if these latter have been selected in the previous LexCA function (by default FALSE)</p>
</td></tr>
<tr><td><code id="LexCHCca_+3A_nb.desc">nb.desc</code></td>
<td>
<p>number of paragons (para) and specific documents (dist) that are edited when describing the clusters (by default 5)</p>
</td></tr>
<tr><td><code id="LexCHCca_+3A_size.desc">size.desc</code></td>
<td>
<p>maximum of characters when editing the paragons (para) and specific documents (dist) to describe the clusters (by default 80)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>LexCHCca starts from the document coordinates issued from a textual correspondence analysis. 
The hierarchical tree is built in such a way that only chronological contiguous nodes can be joined. 
The documents have to be ranked in their chronological order in the source-base (data frame format) before to apply the function (TextData format).
</p>
<p>Legendre test allows to determine whether the fusion between two nodes based on their contiguity lead to a heterogenous new node (no homogeneity-between-clusters).
If Legendre test is applied (cut.test=TRUE), the number of clusters is the number obtained by the test and nb.clust has not effects.
</p>
<p>If no Legendre test is applied (cut.test= FALSE), the number of clusters is determined either a priori or from the constrained hierarchical tree structure.  
</p>
<p>The object $para contains the distance between each document and the centroid of its class.
</p>
<p>The object $dist contains the distance between each document and the centroid of the farthest cluster.
</p>
<p>The results of the description of the clusters and graphs are provided.
</p>


<h3>Value</h3>

<p>Returns a list including:
</p>
<table>
<tr><td><code>data.clust</code></td>
<td>
<p>the active lexical table used in LexCA plus a new column called Clust_ containing the partition</p>
</td></tr>
<tr><td><code>coord.clust</code></td>
<td>
<p>coordinates table issued from CA plus a new column called weigths and another column called Clust_, corresponds to the partition</p>
</td></tr>
<tr><td><code>centers</code></td>
<td>
<p>coordinates of the gravity centers of the clusters</p>
</td></tr>
<tr><td><code>description</code></td>
<td>

<p>$des.word for description of the clusters of documents by their characteristic words, the paragons (des.doc$para) and 
specific documents (des.doc$dist) of each cluster; see details</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>list of internal objects. <code>call$t</code> giving the results for the hierarchical tree</p>
</td></tr>
<tr><td><code>dendro</code></td>
<td>
<p>hclust object. This allows for using the dendrogram in other packages</p>
</td></tr>
<tr><td><code>phases</code></td>
<td>
<p>details of the tracking of the agglomerative hierarchical process. In particular, the cut points (joining documents not allowed) can be identified</p>
</td></tr>
<tr><td><code>sum.squares</code></td>
<td>
<p>sum of squares decomposition for documents and clusters</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Monica Bécue-Bertaut, Ramón Alvarez-Esteban <a href="mailto:ramon.alvarez@unileon.es">ramon.alvarez@unileon.es</a>, Josep-Antón Sánchez-Espigares, 
Belchin Kostov<br /></p>


<h3>References</h3>

<p>Bécue-Bertaut, M., Kostov, B., Morin, A., &amp; Naro, G. (2014). Rhetorical Strategy in Forensic Speeches: Multidimensional Statistics-Based Methodology. Journal of Classification,31, 85-106. <a href="https://doi.org/10.1007/s00357-014-9148-9">doi:10.1007/s00357-014-9148-9</a>.
</p>
<p>Husson F., Lê S., Pagès J. (2017). Exploratory Multivariate Analysis by Example Using R. Chapman &amp; Hall/CRC. <a href="https://doi.org/10.1201/b21874">doi:10.1201/b21874</a>.
</p>
<p>Lebart L. (1978). Programme d'agrégation avec contraintes. Les Cahiers de l'Analyse des Données, 3, pp. 275&ndash;288.
</p>
<p>Legendre, P. &amp; Legendre, L. (1998), Numerical Ecology (2nd ed.), Amsterdam: Elsevier Science.
</p>
<p>Murtagh F. (1985). Multidimensional Clustering Algorithms. Vienna: Physica-Verlag, COMPSTAT Lectures.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+plot.LexCHCca">plot.LexCHCca</a></code>, <code><a href="#topic+LexCA">LexCA</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>data(open.question)
res.TD&lt;-TextData(open.question,var.text=c(9,10), var.agg="Age_Group", Fmin=10, Dmin=10, 
        stop.word.tm=TRUE)
res.LexCA&lt;-LexCA(res.TD, graph=FALSE)
res.ccah&lt;-LexCHCca(res.LexCA, nb.clust=4, min=3)
</code></pre>

<hr>
<h2 id='LexGalt'>Correspondence Analysis on a Simple or Multiple Generalized Aggregate Lexical Table (LexGalt)</h2><span id='topic+LexGalt'></span>

<h3>Description</h3>

<p>Performs an extension of correspondence analysis on either a simple or a multiple generalized aggregated lexical table. In the case of a multiple table, a multiple factor analysis approach is used
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LexGalt(object, context="ALL", conf.ellip =FALSE, nb.ellip = 100, graph=TRUE, 
        axes = c(1, 2), label.group=NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="LexGalt_+3A_object">object</code></td>
<td>
<p>object or list of objects (s) of TextData class (see details)</p>
</td></tr>
<tr><td><code id="LexGalt_+3A_context">context</code></td>
<td>
<p>column index(es) or name(s) of the contextual variables (either qualitative or quantitative) used to build the generalized aggregated lexical table(s). These variables must have been previously selected in TextData function (by default &quot;ALL&quot;)</p>
</td></tr>
<tr><td><code id="LexGalt_+3A_conf.ellip">conf.ellip</code></td>
<td>
<p>computing confidence ellipses (available only in the case of a simple table) (by default FALSE)</p>
</td></tr>
<tr><td><code id="LexGalt_+3A_nb.ellip">nb.ellip</code></td>
<td>
<p>number of samples drawn to evaluate the stability of the points (by default 100) only if conf.ellip= TRUE </p>
</td></tr>
<tr><td><code id="LexGalt_+3A_graph">graph</code></td>
<td>
<p>if TRUE, all several graphs are displayed; use <code><a href="#topic+plot.LexGalt">plot.LexGalt</a></code> to obtain detailed graphs (by default TRUE)</p>
</td></tr>
<tr><td><code id="LexGalt_+3A_axes">axes</code></td>
<td>
<p>length-2 vector indicating the axes to plot (by default axes=c(1,2))</p>
</td></tr>
<tr><td><code id="LexGalt_+3A_label.group">label.group</code></td>
<td>
<p>In the case of analyzing a multiple generalized aggregated lexical table, vector containing the name of the groups (by default, NULL and the group are named GROUP.1, GROUP.2 and so on)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The default &quot;context&quot; argument is &quot;ALL&quot; and may contain qualitative and/or quantitative variables (names or indexes). If both types of variables are included, two independent LexGalt analyses are performed, 
saving the results for the qualitative analysis into an object named SQL (or MQL in the multiple case) and for the quantitative analysis into the SQN object (or MQN in the multiple case). 
</p>
<p>In the multiple case, each TextData object must be created from as many executions of the function TextData as there are tables. They are joined in a list in the call to LexGalt function:
</p>
<p>LexGalt(list(object1,object2,object3),...).
</p>
<p>The variable names of each object in the list must be the same as the name of the variables selected in object1.
</p>


<h3>Value</h3>

<p>Returns a list including an object named SQL if the simple qualitative analysis is performed, SQN for simple quantitative analysis, MQL for multiple qualitative analysis or
MQN for multiple quantitative analysis (see details):
</p>
<table>
<tr><td><code>eig</code></td>
<td>
<p>eigenvalues, percentages of inertia and cumulative percentages of inertia</p>
</td></tr>
<tr><td><code>word</code></td>
<td>
<p>the results for the words (coordinates, square cosine, contributions)</p>
</td></tr>
<tr><td><code>quali.var</code></td>
<td>
<p>results for the categorical variables (coordinates of each categories of each variables, square cosines)</p>
</td></tr>
<tr><td><code>quanti.var</code></td>
<td>
<p>results for the quantitative variables (coordinates, correlation between variables and axes, square cosines)</p>
</td></tr>
<tr><td><code>ellip</code></td>
<td>
<p>coordinates for confidence ellipses (words and categories) are drawn</p>
</td></tr>
<tr><td><code>group</code></td>
<td>
<p>in the case of multiple analysis, results for the groups (coordinates, contributions and square cosines) (MQL or MQN)</p>
</td></tr> 
</table>
<p>Returns the factor maps. The plots may be improved using the plot.LexGalt function. 
</p>


<h3>Author(s)</h3>

<p>Belchin Kostov, Monica Bécue-Bertaut, Ramón Alvarez-Esteban <a href="mailto:ramon.alvarez@unileon.es">ramon.alvarez@unileon.es</a>, Josep-Antón Sánchez-Espigares</p>


<h3>References</h3>

<p>Bécue-Bertaut M. and Pagès J. (2015). Correspondence analysis of textual data involving contextual information: CA-GALT on principal components. Advances in Data Analysis and Classification, vol.(9) 2: 125-142. 
<a href="https://doi.org/10.1007/s11634-014-0171-9">doi:10.1007/s11634-014-0171-9</a>
</p>
<p>Bécue-Bertaut M., Pagès J. and Kostov B. (2014). Untangling the influence of several contextual variables on the respondents' lexical choices. A statistical approach. SORT - Statistics and Operations Research Transactions, vol.(38) 2: 285-302.
</p>
<p>Kostov B. A. (2015). A principal component method to analyse disconnected frequency tables by means of contextual information. (Doctoral dissertation). Retrieved from <a href="http://upcommons.upc.edu/handle/2117/95759">http://upcommons.upc.edu/handle/2117/95759</a>.
</p>
<p>Kostov, B., Bécue-Bertaut, M., &amp; Husson, F. (2015). Correspondence Analysis on Generalised Aggregated Lexical Tables (CA-GALT) in the FactoMineR Package. 
The R Journal, Vol.7, Num.1, 109-117. <a href="https://doi.org/10.32614/RJ-2015-010">doi:10.32614/RJ-2015-010</a>
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+plot.LexGalt">plot.LexGalt</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(open.question)

res.TD&lt;-TextData(open.question,var.text=c(9,10), Fmin=10, Dmin=10,
 context.quali=c("Gender", "Age_Group", "Education"),
 remov.number=TRUE, stop.word.tm=TRUE)

# res.LexGalt &lt;- LexGalt(res.TD, graph=FALSE, conf.ellip =FALSE)
# plot(res.LexGalt, selQualiVar="ALL")

</code></pre>

<hr>
<h2 id='LexHCca'>Hierarchical Clustering on Textual Correspondence Analysis Coordinates (LexHCca)</h2><span id='topic+LexHCca'></span>

<h3>Description</h3>

<p>Agglomerative hierarchical clustering of documents or words issued from correspondence analysis coordinates</p>


<h3>Usage</h3>

<pre><code class='language-R'>LexHCca(x, cluster.CA="docs", nb.clust="click", min=2, max=NULL, kk=Inf, 
   consol=FALSE, iter.max=500, graph=TRUE, description=TRUE, 
   proba=0.05, nb.desc=5, size.desc=80, seed=12345,...)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="LexHCca_+3A_x">x</code></td>
<td>
<p>object of LexCA class</p>
</td></tr>
<tr><td><code id="LexHCca_+3A_cluster.ca">cluster.CA</code></td>
<td>
<p>if &quot;rows&quot; or &quot;docs&quot; cluster analysis is performed on documents; if &quot;columns&quot; or &quot;words&quot;, cluster analysis is performed on words (by default &quot;docs&quot;)</p>
</td></tr>
<tr><td><code id="LexHCca_+3A_nb.clust">nb.clust</code></td>
<td>
<p>number of clusters. If 0 (or &quot;click&quot;), the tree is cut at the level the user clicks on.
If -1 (or &quot;auto&quot;), the tree is automatically cut at the suggested level. 
If a (positive) integer, the tree is cut with nb.clust clusters (by default &quot;click&quot;)</p>
</td></tr>
<tr><td><code id="LexHCca_+3A_min">min</code></td>
<td>
<p>minimum number of clusters (by default 2)</p>
</td></tr>
<tr><td><code id="LexHCca_+3A_max">max</code></td>
<td>
<p>maximum number of clusters (by default NULL, then max is computed as the minimum between 10 and the number of documents divided by 2)</p>
</td></tr>
<tr><td><code id="LexHCca_+3A_kk">kk</code></td>
<td>
<p>in case the user wants to perform a Kmeans clustering previously to the hierarchical clustering (preprocessing step), kk is an integer corresponding to the number of clusters of this previous partition. Further, the hierarchical tree is constructed starting from the nodes of this partition as terminal elements. This is very useful when the number of elements to be classified is very large. By default, the value is Inf and no Kmeans preprocessing is performed</p>
</td></tr>
<tr><td><code id="LexHCca_+3A_consol">consol</code></td>
<td>
<p>if TRUE, a Kmeans consolidation step is performed after the hierarchical clustering (consolidation cannot be performed if kk is used and equals a number) (by default FALSE)</p>
</td></tr>
<tr><td><code id="LexHCca_+3A_iter.max">iter.max</code></td>
<td>
<p>maximum number of iterations in the consolidation step (by default 500)</p>
</td></tr>
<tr><td><code id="LexHCca_+3A_graph">graph</code></td>
<td>
<p>if TRUE, graphs are displayed (by default TRUE)</p>
</td></tr>
<tr><td><code id="LexHCca_+3A_description">description</code></td>
<td>
<p>if TRUE, description of the clusters of documents or words by the axes, the characteristic words in the case of clustering documents or the characteristic documents in the case of clustering words. The documents or words considered as paragon (para) or specific (dist) are identified. In the case of clustering documents, contextual variables also characterize the clusters. These variables have to be selected in LexCA (by default TRUE)</p>
</td></tr>
<tr><td><code id="LexHCca_+3A_proba">proba</code></td>
<td>
<p>threshold on the p-value used in selecting the elements characterizing significantly the clusters (by default 0.05)</p>
</td></tr>
<tr><td><code id="LexHCca_+3A_nb.desc">nb.desc</code></td>
<td>
<p>Maximum of characters when editing the paragons (para) and specific documents (dist) to describe the clusters (by default 80))</p>
</td></tr>
<tr><td><code id="LexHCca_+3A_size.desc">size.desc</code></td>
<td>
<p>text size of edited paragons (para) and specific documents (dist) when describing the clusters of documents (by default 80)</p>
</td></tr>
<tr><td><code id="LexHCca_+3A_seed">seed</code></td>
<td>
<p>Seed to obtain the same results in successive Kmeans (by default 12345)</p>
</td></tr>
<tr><td><code id="LexHCca_+3A_...">...</code></td>
<td>
<p>other arguments from other methods</p>
</td></tr>
</table>


<h3>Details</h3>

<p>LexHCca starts from the documents/words coordinates issued from correspondence analysis axes. 
Euclidean metric and Ward method are used. 
</p>
<p>If the agglomerative clustering starts from many elements (documents or words), it is possible to previously perform a Kmeans partition with kk clusters to further build the tree from these (weighted) kk clusters. 
</p>
<p>The object $para contains the distance between each document and the centroid of its class. 
</p>
<p>The object $dist contains the distance between each document and the centroid of the farthest cluster.
</p>
<p>The results include a thorough description of the clusters. Graphs are provided.
</p>


<h3>Value</h3>

<p>Returns a list including:
</p>
<table>
<tr><td><code>data.clust</code></td>
<td>
<p>the active lexical table used in LexCA plus a new column called Clust_ containing the partition</p>
</td></tr>
<tr><td><code>coord.clust</code></td>
<td>
<p>coordinates table issued from CA plus a new column called Clust_ containing the partition</p>
</td></tr>
<tr><td><code>centers</code></td>
<td>
<p>coordinates of the gravity centers of the clusters</p>
</td></tr> 
<tr><td><code>clust.count</code></td>
<td>
<p>counts of documents/words belonging to each cluster and contribution of the clusters to the variability decomposition</p>
</td></tr>
<tr><td><code>clust.content</code></td>
<td>
<p>list of the document/word labels according to the cluster they belong to</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>list of internal objects. <code>call$t</code> giving the results for the hierarchical tree. See the second reference for more details</p>
</td></tr>
<tr><td><code>description</code></td>
<td>
<p>$desc.axes for description of the clusters by the characteristic axes ($axes) and eta-squared between axes and clusters ($quanti.var).
</p>
<p>$des.cluster.doc for description of the clusters by their characteristic words ($word), supplementary words ($wordsup) and, 
if contextual variables were considered in LexCA, description of the partition/clusters by qualitative ($qualisup) and quantitative ($quantisup) variables, paragons ($para) and specific words ($dist) of each cluster.
</p>
<p>$des.word.doc description of the clusters of words by their characteristic documents ($docs), paragons ($para) and 
specific documents ($dist) of each cluster. 
</p>
</td></tr>
</table>
<p>Returns the hierarchical tree with a barplot of the successive inertia gains, and the 
first CA map of the documents/words. The labels are colored according to the cluster.
</p>


<h3>Author(s)</h3>

<p>Ramón Alvarez-Esteban <a href="mailto:ramon.alvarez@unileon.es">ramon.alvarez@unileon.es</a>, Monica Bécue-Bertaut, Josep-Anton Sánchez-Espigares</p>


<h3>References</h3>

 
<p>Bécue-Bertaut M. Textual Data Science with R. Chapman &amp; Hall/CRC.  <a href="https://doi.org/10.1201/9781315212661">doi:10.1201/9781315212661</a>.
</p>
<p>Husson F., Lê S., Pagès J. (2017). Exploratory Multivariate Analysis by Example Using R. Chapman &amp; Hall/CRC. <a href="https://doi.org/10.1201/b21874">doi:10.1201/b21874</a>.
</p>
<p>Lebart, L., Salem, A., &amp; Berry, L. (1998). Exploring textual data. (D. Kluwer, Ed.). <a href="https://doi.org/10.1007/978-94-017-1525-6">doi:10.1007/978-94-017-1525-6</a>.
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+LexCA">LexCA</a></code>, <code><a href="#topic+plot.LexHCca">plot.LexHCca</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>data(open.question)	
res.TD&lt;-TextData(open.question, var.text=c(9,10), Fmin=10, Dmin=10, stop.word.tm=TRUE,	
        context.quali=c("Gender","Age_Group","Education"), context.quanti=c("Age"))	
res.LexCA&lt;-LexCA(res.TD, graph=FALSE, ncp=8)	
res.hcca&lt;-LexHCca(res.LexCA, graph=FALSE, nb.clust=5)	
</code></pre>

<hr>
<h2 id='open.question'>Open.question (data)</h2><span id='topic+open.question'></span>

<h3>Description</h3>

<p>Extract of the answers provided in a survey designed to better know opinions about what is most important in life.
</p>
<p>Two open-ended questions are included in the questionnaire &quot;What is most important to you in life?&quot; and
&quot;What are other very important things to you? (relaunch of the first question).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(open.question)</code></pre>


<h3>Format</h3>

<p>Data frame with 300 rows and 10 columns. The rows correspond to the respondents. The first 8 columns correspond to socio-demographic variables collected through closed questions: Gender, Age_Group, Age, Education level, Genre crossed with Age, Genre crossed with Education level, Age crossed with Education level and, finally Genre crossed with Education level and Age. Age is a quantitative variable while the other variables are qualitative. The last two columns contain the answers to the open-ended questions. 
</p>

<hr>
<h2 id='plot.LexCA'>Plot of LexCA objects</h2><span id='topic+plot.LexCA'></span>

<h3>Description</h3>

<p>Plots textual correspondence analysis (CA) graphs from a LexCA object. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'LexCA'
plot(x, selDoc="ALL", selWord="ALL", selSeg=NULL, selDocSup=NULL,
  selWordSup=NULL, quanti.sup=NULL, quali.sup=NULL, maxDocs=20, eigen=FALSE, 
  title=NULL, axes=c(1,2), col.doc="blue", col.word="red", col.doc.sup="darkblue", 
  col.word.sup="darkred", col.quanti.sup = "blue", col.quali.sup="darkgreen", 
  col.seg="cyan4", col="grey", cex=1, xlim=NULL, ylim=NULL, shadowtext=FALSE,
  habillage="none", unselect=1, label="all", autoLab=c("auto", "yes", "no"), 
  new.plot=TRUE, graph.type = c("classic", "ggplot"),...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.LexCA_+3A_x">x</code></td>
<td>
<p>object of LexCA class</p>
</td></tr>
<tr><td><code id="plot.LexCA_+3A_seldoc">selDoc</code></td>
<td>
<p>vector with the active documents to plot (indexes, names or rules; see details; by default &quot;ALL&quot;)</p>
</td></tr>
<tr><td><code id="plot.LexCA_+3A_selword">selWord</code></td>
<td>
<p>vector with the active words to plot (indexes, names or rules; see details; by default &quot;ALL&quot;)</p>
</td></tr>
<tr><td><code id="plot.LexCA_+3A_selseg">selSeg</code></td>
<td>
<p>vector with the supplementary repeated segments to plot (indexes, names or rules; see details; by default NULL)</p>
</td></tr>
<tr><td><code id="plot.LexCA_+3A_seldocsup">selDocSup</code></td>
<td>
<p>vector with the supplementary documents to plot (indexes, names or rules; see details; by default NULL)</p>
</td></tr>
<tr><td><code id="plot.LexCA_+3A_selwordsup">selWordSup</code></td>
<td>
<p>vector of the supplementary words to plot (indexes, names or rules; see details; by default NULL)</p>
</td></tr> 
<tr><td><code id="plot.LexCA_+3A_quanti.sup">quanti.sup</code></td>
<td>
<p>vector of the supplementary quantitative variables to plot (indexes, names or rules; see details; by default NULL)</p>
</td></tr>
<tr><td><code id="plot.LexCA_+3A_quali.sup">quali.sup</code></td>
<td>
<p>vector with the supplementary categorical variables/categories to plot (indexes, names or rules; see details; by default NULL). The selected categories (through the variables or directly) are plotted</p>
</td></tr>
<tr><td><code id="plot.LexCA_+3A_maxdocs">maxDocs</code></td>
<td>
<p>limit to the number of active documents in the lexical table when selecting the words to be plotted for being characteristic of the selected documents (by default 20)</p>
</td></tr>
<tr><td><code id="plot.LexCA_+3A_eigen">eigen</code></td>
<td>
<p>if TRUE, the eigenvalues barplot is drawn (by default FALSE); no other elements can be simultaneously selected</p>
</td></tr>
<tr><td><code id="plot.LexCA_+3A_title">title</code></td>
<td>
<p>title of the graph (by default NULL and the title is automatically assigned)</p>
</td></tr>
<tr><td><code id="plot.LexCA_+3A_axes">axes</code></td>
<td>
<p>length-2 vector indicating the axes considered in the graph (by default c(1,2))</p>
</td></tr>
<tr><td><code id="plot.LexCA_+3A_col.doc">col.doc</code></td>
<td>
<p>color for the point-documents (by default &quot;blue&quot;)</p>
</td></tr>
<tr><td><code id="plot.LexCA_+3A_col.word">col.word</code></td>
<td>
<p>color for the point-words (by default &quot;red&quot;)</p>
</td></tr>
<tr><td><code id="plot.LexCA_+3A_col.doc.sup">col.doc.sup</code></td>
<td>
<p>color for the supplementary point-documents (by default &quot;darkblue&quot;)</p>
</td></tr>
<tr><td><code id="plot.LexCA_+3A_col.word.sup">col.word.sup</code></td>
<td>
<p>color for the supplementary point-words (by default &quot;darkred&quot;)</p>
</td></tr>
<tr><td><code id="plot.LexCA_+3A_col.quanti.sup">col.quanti.sup</code></td>
<td>
<p>color for the quanti.sup variables (by default &quot;blue&quot;)</p>
</td></tr>
<tr><td><code id="plot.LexCA_+3A_col.quali.sup">col.quali.sup</code></td>
<td>
<p>color for the categorical supplementary point-categories, (by default &quot;darkgreen&quot;)</p>
</td></tr>
<tr><td><code id="plot.LexCA_+3A_col.seg">col.seg</code></td>
<td>
<p>color for the supplementary point-repeated segments, (by default &quot;cyan4&quot;)</p>
</td></tr>
<tr><td><code id="plot.LexCA_+3A_col">col</code></td>
<td>
<p>color for the bars in the eigenvalues barplot (by default &quot;grey&quot;)</p>
</td></tr>
<tr><td><code id="plot.LexCA_+3A_cex">cex</code></td>
<td>
<p>text and symbol size is scaled by cex, in relation to size 1 (by default 1)</p>
</td></tr>
<tr><td><code id="plot.LexCA_+3A_xlim">xlim</code></td>
<td>
<p>range for 'x' values on the graph, defaulting to the finite values of 'x' range (by default NULL)</p>
</td></tr>
<tr><td><code id="plot.LexCA_+3A_ylim">ylim</code></td>
<td>
<p>range for the 'y' values on the graph, defaulting to the the finite values of 'y' range (by default NULL)</p>
</td></tr>
<tr><td><code id="plot.LexCA_+3A_shadowtext">shadowtext</code></td>
<td>
<p>if TRUE, shadow on the labels (rectangles are written under the labels which may lead to difficulties to modify the graph with another program) (by default FALSE)</p>
</td></tr>
<tr><td><code id="plot.LexCA_+3A_habillage">habillage</code></td>
<td>
<p>index or name of the categorical variable used to differentiate the documents by colors given according to the category; by default &quot;none&quot;)</p>
</td></tr>
<tr><td><code id="plot.LexCA_+3A_unselect">unselect</code></td>
<td>
<p>either a value between 0 and 1 or a color. In the first case, transparency level of the unselected objects (if unselect=1 the transparency is total and the elements are not represented; if unselect=0 the elements are represented as usual but without any label); in the case of a color (e.g. unselect=&quot;grey60&quot;), the non-selected points are given this color (by default 1)</p>
</td></tr>
<tr><td><code id="plot.LexCA_+3A_label">label</code></td>
<td>
<p>a list of character for the variables which are labelled (by default NULL and all the drawn variables are labelled). You can label all the active variables by putting &quot;var&quot; and/or all the supplementary variables by putting &quot;quanti.sup&quot; and/or a list with the names of the variables which should be labelled. Value should be one of &quot;all&quot;, &quot;none&quot;, &quot;row&quot;, &quot;row.sup&quot;, &quot;col&quot;, &quot;col.sup&quot;, &quot;quali.sup&quot; or NULL.</p>
</td></tr>
<tr><td><code id="plot.LexCA_+3A_autolab">autoLab</code></td>
<td>
<p>if autoLab=&quot;auto&quot;, autoLab turns to be equal to &quot;yes&quot; if there are less than 50 elements and equal to &quot;no&quot; otherwise; if &quot;yes&quot;, the labels are moved, as little as possible, to avoid overlapping (time-consuming if many elements); if &quot;no&quot; the labels are placed quickly but may overlap</p>
</td></tr>
<tr><td><code id="plot.LexCA_+3A_new.plot">new.plot</code></td>
<td>
<p>if TRUE, a new graphical device is created (by default FALSE)</p>
</td></tr>
<tr><td><code id="plot.LexCA_+3A_graph.type">graph.type</code></td>
<td>
<p>a string that gives the type of graph used: &quot;ggplot&quot; or &quot;classic&quot; (by default classic)</p>
</td></tr>
<tr><td><code id="plot.LexCA_+3A_...">...</code></td>
<td>
<p>further arguments passed from other methods...</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The argument autoLab = &quot;yes&quot; is time-consuming if many overlapping labels. Furthermore, the visualization of the words cloud can result distorted because of the apparent greater dispersion of the words labels. An alternative would be reducing the character size of the words labels to reduce overlapping (e.g. cex=0.7).
</p>
<p>selDoc, selWord, selSeg, selDocSup, selWordSup, quanti.sup and quali.sup allow for selecting all or part of the elements of the corresponding type, using either labels, indexes or rules.<br />
</p>
<p>The syntax is the same for all types.
</p>
<p>1. Using labels:
</p>
<pre>
selDoc = c("doc1","doc5"): only the documents with labels doc1 and doc5 are plotted.
quali.sup=c("varcateg1","category12"): only the categories (all of them) of 
   categorical variable labeled "varcateg1" and the category labeled "category12"
   are plotted.</pre>
<p>2.- Using indexes:
</p>
<pre>
selDoc = c(1:5): documents 1 to 5 are plotted.
quali.sup=c(1:5,7): categories 1 to 5 and 7 are plotted. The numbering of the
   categories have to be consulted in the LexCA numerical results.</pre>
<p>3.- Using rules:    
Rules are based on the coordinates (coord), the contribution (contrib or meta; concerning only
active elements) or the square cosine (cos2).<br />
Somes examples are given hereafter:
</p>
<pre>
selDoc="coord 10": only the 10 documents with the highest coordinates, as globally
   computed on the 2 axes, are plotted.
selWord="contrib 10": the words with a contribution to the inertia, of any of 
   the 2 axes.
selWord="meta 3": the words with a contribution over 3 times the average word 
   contribution on any of the two axes are plotted. Only active words or documents 
   can be selected.
selDocSup="cos2 .85": the supplementary documents with a cos2 over 0.85, as summed
   on the 2 axes, are plotted.
selWord="char 0.05": only the characteristic words of the documents selected in 
   SelDoc are plotted. The selection of the words follow the rationale used in 
   function LexChar using as limit for the p-value the value given, here.0.05.</pre>


<h3>Author(s)</h3>

<p>Ramón Alvarez-Esteban <a href="mailto:ramon.alvarez@unileon.es">ramon.alvarez@unileon.es</a>, Mónica Bécue-Bertaut, Josep-Antón Sánchez-Espigares</p>


<h3>References</h3>

<p>Husson F., Lê S., Pagés J. (2011). Exploratory Multivariate Analysis by Example Using R. Chapman &amp; Hall/CRC. <a href="https://doi.org/10.1201/b10345">doi:10.1201/b10345</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+LexCA">LexCA</a></code>, <code><a href="#topic+print.LexCA">print.LexCA</a></code>, <code><a href="#topic+summary.LexCA">summary.LexCA</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>data(open.question)
res.TD&lt;-TextData(open.question,var.text=c(9,10), var.agg="Age_Group", Fmin=10, Dmin=10,
        remov.number=TRUE, stop.word.tm=TRUE)
res.CA &lt;- LexCA(res.TD, graph=FALSE)
plot(res.CA, selDoc="contrib 30", selWord="coord 20")
</code></pre>

<hr>
<h2 id='plot.LexChar'>Plot LexChar objects</h2><span id='topic+plot.LexChar'></span>

<h3>Description</h3>

<p>Draws the characteristic and anti-characteristic words of documents from a LexChar object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'LexChar'
plot(x, char.negat=TRUE, col.char.posit="blue", col.char.negat="red",
col.lines="black", theme=theme_bw(), text.size=12, numr=1, numc=2, top=NULL, 
max.posit=15, max.negat=15, type=c("CharWord","quanti","quali"),sel.var.cat="ALL",
txt.var.cat=NULL, sel.words="ALL",...) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.LexChar_+3A_x">x</code></td>
<td>
<p>object of LexChar class</p>
</td></tr>
<tr><td><code id="plot.LexChar_+3A_char.negat">char.negat</code></td>
<td>
<p>if TRUE, the anti-characteristic words are plotted (by default TRUE)</p>
</td></tr>
<tr><td><code id="plot.LexChar_+3A_col.char.posit">col.char.posit</code></td>
<td>
<p>color for the characteristic words (by default &quot;blue&quot;)</p>
</td></tr>
<tr><td><code id="plot.LexChar_+3A_col.char.negat">col.char.negat</code></td>
<td>
<p>color for the anti-characteristic words (by default &quot;red&quot;)</p>
</td></tr>
<tr><td><code id="plot.LexChar_+3A_col.lines">col.lines</code></td>
<td>
<p>color for the lines of barplot (by default &quot;black&quot;)</p>
</td></tr>
<tr><td><code id="plot.LexChar_+3A_theme">theme</code></td>
<td>
<p>used to modify the theme settings by ggplot2 package (by default theme_bw())</p>
</td></tr>
<tr><td><code id="plot.LexChar_+3A_text.size">text.size</code></td>
<td>
<p>size of the font (by default 12)</p>
</td></tr>
<tr><td><code id="plot.LexChar_+3A_numr">numr</code></td>
<td>
<p>number of rows in each multiple graph (by default 1 row)</p>
</td></tr>
<tr><td><code id="plot.LexChar_+3A_numc">numc</code></td>
<td>
<p>number of columns in each multiple graph (by default 2 columns)</p>
</td></tr>
<tr><td><code id="plot.LexChar_+3A_top">top</code></td>
<td>
<p>title of the graph (by default NULL)</p>
</td></tr>
<tr><td><code id="plot.LexChar_+3A_max.posit">max.posit</code></td>
<td>
<p>maximum number of characteristic words (by default 15)</p>
</td></tr>
<tr><td><code id="plot.LexChar_+3A_max.negat">max.negat</code></td>
<td>
<p>maximum number of anti-characteristic words (by default 15)</p>
</td></tr>
<tr><td><code id="plot.LexChar_+3A_type">type</code></td>
<td>
<p>CharWord and draws the characteristic and anti-characteristic words; quanti draws characteristic words for all quantitative variables; quali draws only the words for one qualitative variable  (by default CharWord)</p>
</td></tr>
<tr><td><code id="plot.LexChar_+3A_sel.var.cat">sel.var.cat</code></td>
<td>
<p>name of contextual quantitative and/or qualitative contextual variables</p>
</td></tr>
<tr><td><code id="plot.LexChar_+3A_txt.var.cat">txt.var.cat</code></td>
<td>
<p>new names of each category or quantitative variable (by default NULL</p>
</td></tr>
<tr><td><code id="plot.LexChar_+3A_sel.words">sel.words</code></td>
<td>
<p>words selected to plot if its p-value is less than prob (by default ALL</p>
</td></tr>
<tr><td><code id="plot.LexChar_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods...</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Ramón Alvarez-Esteban <a href="mailto:ramon.alvarez@unileon.es">ramon.alvarez@unileon.es</a>, Monica Bécue-Bertaut, Josep-Anton Sánchez-Espigares</p>


<h3>See Also</h3>

 <p><code><a href="#topic+LexChar">LexChar</a></code>, <code><a href="#topic+print.LexChar">print.LexChar</a></code>, <code><a href="#topic+summary.LexChar">summary.LexChar</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>data(open.question)
res.TD&lt;-TextData(open.question, var.text=c(9,10), var.agg="Gen_Edu", Fmin=10, Dmin=10,
        remov.number=TRUE, stop.word.tm=TRUE)
LD&lt;-LexChar(res.TD,maxCharDoc = 0)
plot(LD)
</code></pre>

<hr>
<h2 id='plot.LexCHCca'>Plots for Chronological Constrained Hierarchical Clustering from LexCHCca Objects</h2><span id='topic+plot.LexCHCca'></span>

<h3>Description</h3>

<p>Plots graphs from LexCHCca results: tree, barplot of the aggregation criterion values and first CA map with the documents colored in accordance with the cluster.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'LexCHCca'
plot(x, axes=c(1, 2), type=c("tree","map","bar"), rect=TRUE, title=NULL, 
  ind.names=TRUE, new.plot=FALSE, max.plot=15, tree.barplot=TRUE,...)  
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.LexCHCca_+3A_x">x</code></td>
<td>
<p>object of LexCHCca class</p>
</td></tr>
<tr><td><code id="plot.LexCHCca_+3A_axes">axes</code></td>
<td>
<p>length-2 vector defining the axes of the CA map to plot (by default (1,2))</p>
</td></tr>
<tr><td><code id="plot.LexCHCca_+3A_type">type</code></td>
<td>
<p>type of graph. &quot;tree&quot; plots the tree; &quot;bar&quot; plots the barplot of the successive 
values of the aggregation criterion (downward reading of the tree); &quot;map&quot; plots the CA map where the individuals 
are colored in accordances with the cluster of belonging (by default &quot;tree&quot;)</p>
</td></tr>
<tr><td><code id="plot.LexCHCca_+3A_rect">rect</code></td>
<td>
<p>if TRUE, when choice=&quot;tree&quot; rectangles are drawn around the clusters (by default TRUE)</p>
</td></tr>
<tr><td><code id="plot.LexCHCca_+3A_title">title</code></td>
<td>
<p>title of the graph. If NULL, a title is automatically defined (by default NULL)</p>
</td></tr>
<tr><td><code id="plot.LexCHCca_+3A_ind.names">ind.names</code></td>
<td>
<p>if TRUE, the document labels are written on the CA map (by default TRUE)</p>
</td></tr>
<tr><td><code id="plot.LexCHCca_+3A_new.plot">new.plot</code></td>
<td>
<p>if TRUE, a new window is opened (by default FALSE)</p>
</td></tr>
<tr><td><code id="plot.LexCHCca_+3A_max.plot">max.plot</code></td>
<td>
<p>maximum of bars in the bar plot of the aggregation criterion (by default 15)</p>
</td></tr>
<tr><td><code id="plot.LexCHCca_+3A_tree.barplot">tree.barplot</code></td>
<td>
<p>if TRUE, the barplot of intra inertia losses is added on the tree graph (by default TRUE)</p>
</td></tr>
<tr><td><code id="plot.LexCHCca_+3A_...">...</code></td>
<td>
<p>further arguments passed from other methods...</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns the chosen plot
</p>


<h3>Author(s)</h3>

<p>Mónica Bécue-Bertaut, Ramón Alvarez-Esteban <a href="mailto:ramon.alvarez@unileon.es">ramon.alvarez@unileon.es</a>, Josep-Anton Sánchez-Espigares</p>


<h3>See Also</h3>

<p><code><a href="#topic+LexCHCca">LexCHCca</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(open.question)
res.TD&lt;-TextData(open.question,var.text=c(9,10), var.agg="Age_Group", Fmin=10, Dmin=10,
        stop.word.tm=TRUE)
res.LexCA&lt;-LexCA(res.TD, graph=FALSE)
res.chcca&lt;-LexCHCca(res.LexCA, nb.clust=4, min=3, graph=FALSE)
plot(res.chcca, type="tree")
plot(res.chcca, type="map")
plot(res.chcca, type="bar", max.plot=5)

## End(Not run)
</code></pre>

<hr>
<h2 id='plot.LexGalt'>Plot LexGalt objects</h2><span id='topic+plot.LexGalt'></span>

<h3>Description</h3>

<p>Plots Generalised Aggregate Lexical Tables (LexGalt) graphs from a LexGalt object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'LexGalt'
plot(x,type="QL", selDoc=NULL, selWord=NULL, selQualiVar=NULL,
  selQuantiVar=NULL, conf.ellip=FALSE, selWordEllip=NULL, selQualiVarEllip=NULL,
  selQuantiVarEllip=NULL, level.conf=0.95, eigen=FALSE, title = NULL, axes = c(1, 2),
  xlim = NULL, ylim = NULL, col.eig="grey", col.doc = "black", col.word = NULL,
  col.quali = "blue", col.quanti = "blue", col="grey", pch = 20, label = TRUE, 
  autoLab = c("auto", "yes", "no"), palette = NULL, unselect = 1, 
  selCov=FALSE, selGroup="ALL", partial=FALSE, plot.group=FALSE, 
  col.group=NULL, label.group=NULL, legend=TRUE, pos.legend="topleft", 
  new.plot = TRUE, cex=1,...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.LexGalt_+3A_x">x</code></td>
<td>
<p>object of LexGalt class</p>
</td></tr>
<tr><td><code id="plot.LexGalt_+3A_type">type</code></td>
<td>
<p>results from a qualitative analysis (type=&quot;QL&quot;) or quantitative analysis (type=&quot;QN&quot;); see details; by default Q)</p>
</td></tr>
<tr><td><code id="plot.LexGalt_+3A_seldoc">selDoc</code></td>
<td>
<p>vector with the documents to plot (indexes, names or rules; see details; by default NULL)</p>
</td></tr>
<tr><td><code id="plot.LexGalt_+3A_selword">selWord</code></td>
<td>
<p>vector with the words to plot (indexes, names or rules (indexes, names or rules; see details; by default NULL)</p>
</td></tr>
<tr><td><code id="plot.LexGalt_+3A_selqualivar">selQualiVar</code></td>
<td>
<p>vector with the categories of categorical variables to plot (indexes, names or rules; see details; by default NULL)</p>
</td></tr>
<tr><td><code id="plot.LexGalt_+3A_selquantivar">selQuantiVar</code></td>
<td>
<p>vector with the numerical variables to plot (indexes, names or rules; see details; by default NULL)</p>
</td></tr>
<tr><td><code id="plot.LexGalt_+3A_conf.ellip">conf.ellip</code></td>
<td>
<p>to drawn confidence ellipses, by default FALSE</p>
</td></tr>
<tr><td><code id="plot.LexGalt_+3A_selwordellip">selWordEllip</code></td>
<td>
<p>vector with the words that defines which ellipses are drawn (indexes, names or rules; see details; by default NULL)</p>
</td></tr>
<tr><td><code id="plot.LexGalt_+3A_selqualivarellip">selQualiVarEllip</code></td>
<td>
<p>vector with the categories of categorical variables which ellipses are drawn (indexes, names or rules; see details; by default NULL)</p>
</td></tr>
<tr><td><code id="plot.LexGalt_+3A_selquantivarellip">selQuantiVarEllip</code></td>
<td>
<p>vector with the numerical variables which ellipses are drawn(indexes, names or rules; see details; by default NULL)</p>
</td></tr>
<tr><td><code id="plot.LexGalt_+3A_level.conf">level.conf</code></td>
<td>
<p>level of confidence used to construct the ellipses; by default 0.95</p>
</td></tr>
<tr><td><code id="plot.LexGalt_+3A_eigen">eigen</code></td>
<td>
<p>if TRUE, the eigenvalues barplot is drawn (by default FALSE); other elements can be simultaneously selected</p>
</td></tr>
<tr><td><code id="plot.LexGalt_+3A_title">title</code></td>
<td>
<p>title of the graph (by default NULL and the title is automatically assigned)</p>
</td></tr>
<tr><td><code id="plot.LexGalt_+3A_axes">axes</code></td>
<td>
<p>length-2 vector indicating the axes considered in the graph; by default c(1,2)</p>
</td></tr>
<tr><td><code id="plot.LexGalt_+3A_xlim">xlim</code></td>
<td>
<p>range for 'x' values on the graph, defaulting to the finite values of 'x' range (by default NULL)</p>
</td></tr>
<tr><td><code id="plot.LexGalt_+3A_ylim">ylim</code></td>
<td>
<p>range for the 'y' values on the graph, defaulting to the the finite values of 'y' range (by default NULL)</p>
</td></tr>
<tr><td><code id="plot.LexGalt_+3A_col.eig">col.eig</code></td>
<td>
<p>value or vector with colors for the bars of eigenvalues (by default &quot;grey&quot;)</p>
</td></tr>
<tr><td><code id="plot.LexGalt_+3A_col.doc">col.doc</code></td>
<td>
<p>color for the point-documents(by default &quot;black&quot;)</p>
</td></tr>
<tr><td><code id="plot.LexGalt_+3A_col.word">col.word</code></td>
<td>
<p>color for the point-words (by default NULL is darkred in simple analysis; see details)</p>
</td></tr>
<tr><td><code id="plot.LexGalt_+3A_col.quali">col.quali</code></td>
<td>
<p>color for the categories of categorical variables (by default &quot;blue&quot;)</p>
</td></tr>
<tr><td><code id="plot.LexGalt_+3A_col.quanti">col.quanti</code></td>
<td>
<p>color for the numerical variables (by default &quot;blue&quot;)</p>
</td></tr>
<tr><td><code id="plot.LexGalt_+3A_col">col</code></td>
<td>
<p>color for the bars in the eigenvalues barplot (by default &quot;grey&quot;)</p>
</td></tr>
<tr><td><code id="plot.LexGalt_+3A_pch">pch</code></td>
<td>
<p>plotting character for coordinates, cf. <code><a href="graphics.html#topic+points">points</a></code> function in the graphics package</p>
</td></tr>
<tr><td><code id="plot.LexGalt_+3A_label">label</code></td>
<td>
<p>a list of character for the elements which are labelled (by default TRUE and all the drawn elements are labelled).</p>
</td></tr>
<tr><td><code id="plot.LexGalt_+3A_autolab">autoLab</code></td>
<td>
<p>if autoLab=&quot;auto&quot;, autoLab turns to be equal to &quot;yes&quot; if there are less than 50 elements and equal to &quot;no&quot; otherwise; if &quot;yes&quot;, the labels are moved, as little as possible, to avoid overlapping (time-consuming if many elements); if &quot;no&quot; the labels are placed quickly but may overlap</p>
</td></tr>
<tr><td><code id="plot.LexGalt_+3A_palette">palette</code></td>
<td>
<p>the color palette used to draw the points. By default colors are chosen. If you want to define the colors : palette=c(&quot;black&quot;, &quot;red&quot;, &quot;blue&quot;); or you can use: palette=rainbow(10), or in black and white for example: palette=gray(seq(0,.9,len=3))</p>
</td></tr>
<tr><td><code id="plot.LexGalt_+3A_unselect">unselect</code></td>
<td>
<p>may be either a value between 0 and 1 that gives the transparency of the unselected objects (if unselect=1 the transparceny is total and the elements are not drawn, if unselect=0 the elements are drawn as usual but without any label) or may be a color (for example unselect=&quot;grey60&quot;)</p>
</td></tr>
<tr><td><code id="plot.LexGalt_+3A_selcov">selCov</code></td>
<td>
<p>a boolean, if TRUE then data are scaled to unit variance (by default TRUE)</p>
</td></tr>
<tr><td><code id="plot.LexGalt_+3A_selgroup">selGroup</code></td>
<td>
<p>vector with the groups to plot if multiple analysis was performed (indexes, names or rules; see details; by default NULL)</p>
</td></tr>
<tr><td><code id="plot.LexGalt_+3A_partial">partial</code></td>
<td>
<p>if TRUE partial elements (results for the groups) are shown, if ALL results for the conjoint analysis are superimposed; by default FALSE</p>
</td></tr>
<tr><td><code id="plot.LexGalt_+3A_plot.group">plot.group</code></td>
<td>
<p>draw a plot comparing the groups in multiple case (by default TRUE)</p>
</td></tr> 
<tr><td><code id="plot.LexGalt_+3A_col.group">col.group</code></td>
<td>
<p>color for the groups if multiple analysis was performed (by default NULL and they are selected from palette)</p>
</td></tr>
<tr><td><code id="plot.LexGalt_+3A_label.group">label.group</code></td>
<td>
<p>a vector containing the new name of the groups. If &quot;BLANK&quot; no labels with the group are added at the end of the drawn elements (by default, NULL and the name of each group is added)</p>
</td></tr>
<tr><td><code id="plot.LexGalt_+3A_legend">legend</code></td>
<td>
<p>show the legend of labels of groups. See <code><a href="graphics.html#topic+legend">legend</a></code> from graphics package (by default TRUE</p>
</td></tr>
<tr><td><code id="plot.LexGalt_+3A_pos.legend">pos.legend</code></td>
<td>
<p>position of the legend of labels of groups. See <code><a href="graphics.html#topic+legend">legend</a></code> from graphics package (by default &quot;topleft&quot;)</p>
</td></tr>
<tr><td><code id="plot.LexGalt_+3A_new.plot">new.plot</code></td>
<td>
<p>if TRUE, a new graphical device is created (by default TRUE)</p>
</td></tr>
<tr><td><code id="plot.LexGalt_+3A_cex">cex</code></td>
<td>
<p>text and symbol size is scaled by cex, in relation to size 1 (by default 1)</p>
</td></tr>
<tr><td><code id="plot.LexGalt_+3A_...">...</code></td>
<td>
<p>further arguments passed from other methods...</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The argument autoLab = &quot;yes&quot; is time-consuming if many overlapping labels. Furthermore, the visualization of the words cloud can result distorted because of the apparent greater dispersion of the words labels. An alternative would be reducing the character size of the words labels to reduce overlapping (e.g. cex=0.7).
</p>
<p>selDoc, selWord, selQualiVar, selQuantiVar, selWordEllip, selQualiVarEllip,
selQuantiVarEllip allow for selecting all or part of the elements of the corresponding type, using either labels, indexes or rules.<br />
</p>
<p>The syntax is the same for all types.
</p>
<p>1. Using labels:
</p>
<pre>
selDoc = c("doc1","doc5"): only the documents with labels doc1 and doc5 are plotted.
selQualiVar=c("category1","category2"): only the categories labeled category1 and
 category2 are plotted.</pre>
<p>2.- Using indexes:
</p>
<pre>
selDoc = c(1:5): documents 1 to 5 are plotted.
quali.sup=c(1:5,7): categories 1 to 5 and 7 are plotted. The numbering of the
   categories have to be consulted in the LexGalt numerical results.</pre>
<p>3.- Using rules:    
Rules are based on the coordinates (coord), the contribution (contrib or meta) or the square cosine (cos2).<br />
Somes examples are given hereafter:
</p>
<pre>
selDoc="coord 10": only the 10 documents with the highest coordinates, as globally
   computed on the 2 axes, are plotted.
selWord="contrib 10": the words with a contribution to the inertia, of any of 
   the 2 axes.
selWord="meta 3": the words with a contribution over 3 times the average word 
   contribution on any of the two axes are plotted.
selWord="cos2 .85": the words with a cos2 over 0.85, as summed
   on the 2 axes, are plotted.
 </pre>
<pre>
col.word by default NULL is "darkred" for simple analysis, if it is null takes
the colors from col.group 
i.e. col.group=c("red","blue"). To select the colors for some words in object res, 
we can use:
str.col.words &lt;- rep("darkred",nrow(res$MQL$word$coord))
str.col.words[which(rownames(res$MQL$word$coord) == "kids")] &lt;- "red"
str.col.words[which(rownames(res$MQL$word$coord) == "friends")] &lt;- "green"
str.col.words[which(rownames(res$MQL$word$coord) == "job")] &lt;- "pink"
plot(res, selGroup=1, selWord=c("friends", "job", "kids", "at"),new.plot=FALSE, 
col.group=c("darkred","blue"), autoLab = "yes", col.word=str.col.words)
</pre> 


<h3>Author(s)</h3>

<p>Belchin Kostov, Monica Bécue-Bertaut, Ramón Alvarez-Esteban <a href="mailto:ramon.alvarez@unileon.es">ramon.alvarez@unileon.es</a>, 
Josep-Antón Sánchez-Espigares</p>


<h3>References</h3>

<p>Bécue-Bertaut M. and Pagès J. (2015). Correspondence analysis of textual data involving contextual information: CA-GALT on principal components. Advances in Data Analysis and Classification, vol.(9) 2: 125-142.
</p>
<p>Bécue-Bertaut M., Pagès J. and Kostov B. (2014). Untangling the influence of several contextual variables on the respondents' lexical choices. A statistical approach. SORT - Statistics and Operations Research Transactions, vol.(38) 2: 285-302.
</p>
<p>Kostov B. A. (2015). A principal component method to analyse disconnected frequency tables by means of contextual information. (Doctoral dissertation). Retrieved from <a href="http://upcommons.upc.edu/handle/2117/95759">http://upcommons.upc.edu/handle/2117/95759</a>.
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+LexGalt">LexGalt</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(open.question)

res.TD&lt;-TextData(open.question,var.text=c(9,10),  Fmin=10, Dmin=10,
 context.quali=c("Gender", "Age_Group", "Education"),
 remov.number=TRUE, stop.word.tm=TRUE)

res.LexGalt &lt;- LexGalt(res.TD, graph=FALSE, nb.ellip =0)
plot(res.LexGalt, selQualiVar="ALL")

## End(Not run)
</code></pre>

<hr>
<h2 id='plot.LexHCca'>Plots for Hierarchical Clustering from LexHCca Objects</h2><span id='topic+plot.LexHCca'></span>

<h3>Description</h3>

<p>Plots graphs from LexHCca results: tree and CA maps with the documents or words colored in accordance with the cluster.</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'LexHCca'
plot(x, type="map", plot=c("points", "labels", "centers"), selClust="ALL",
     selInd="ALL",axes=c(1, 2), theme=theme_bw(), palette=NULL, title=NULL, 
     axis.title=NULL, axis.text=NULL, points=NULL, labels=NULL,centers=NULL, 
     traject=NULL, hull=NULL, xlim=NULL, ylim=NULL, hvline=TRUE,...) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.LexHCca_+3A_x">x</code></td>
<td>
<p>object of LexHCca class</p>
</td></tr>
<tr><td><code id="plot.LexHCca_+3A_type">type</code></td>
<td>
<p>type of graph. &quot;map&quot; plots the CA map where the individuals are colored in accordance with the cluster of belonging (by default); &quot;tree&quot; plots the dendrogram if hierarchical method without consolidation is performed from LexHCca. See details</p>
</td></tr>
<tr><td><code id="plot.LexHCca_+3A_plot">plot</code></td>
<td>
<p>elements to plot for map graph: points, labels, centers, hull or traject; by default &quot;ALL&quot; and points, labels and centers are plotted. Also combinations are allowed, i.e: plot=c(points,centers)</p>
</td></tr>
<tr><td><code id="plot.LexHCca_+3A_selclust">selClust</code></td>
<td>
<p>vector indexes with the numbers of the clusters to plot (by default &quot;ALL&quot;)</p>
</td></tr>
<tr><td><code id="plot.LexHCca_+3A_selind">selInd</code></td>
<td>
<p>vector with the active documents/words to plot (indexes, names or rules; see details; by default &quot;ALL&quot;)</p>
</td></tr>
<tr><td><code id="plot.LexHCca_+3A_axes">axes</code></td>
<td>
<p>length-2 vector indicating the axes of the CA map to plot; by default (1,2)</p>
</td></tr>
<tr><td><code id="plot.LexHCca_+3A_theme">theme</code></td>
<td>
<p>used to modify the theme settings by ggplot2 package (by default theme_bw())</p>
</td></tr>
<tr><td><code id="plot.LexHCca_+3A_palette">palette</code></td>
<td>
<p>color palette used to draw the clusters. As many numbers as clusters. See details</p>
</td></tr>
<tr><td><code id="plot.LexHCca_+3A_title">title</code></td>
<td>
<p>title of the graph. If NULL, a title is automatically defined (by default NULL).
Other parameters can be chosem using a list: text, color, size, family, face, just; See details</p>
</td></tr>
<tr><td><code id="plot.LexHCca_+3A_axis.title">axis.title</code></td>
<td>
<p>axis titles parameters can be used: text.x, text.y, color, size, family, face,
just;  If text.x and text.y are NULL automatic texts are plotted (by default NULL). See details</p>
</td></tr>
<tr><td><code id="plot.LexHCca_+3A_axis.text">axis.text</code></td>
<td>
<p>format of numbers can be chosen: color, size, family, face; See details</p>
</td></tr>
<tr><td><code id="plot.LexHCca_+3A_hvline">hvline</code></td>
<td>
<p>horizontal (intercept.y) and vertical line (intercept.x) added by default at (0,0) position in map. Parameters: intercept.y, intercept.x, linetype (by default &quot;dashed&quot;), color, size, alpha.t</p>
</td></tr>
<tr><td><code id="plot.LexHCca_+3A_points">points</code></td>
<td>
<p>format of points. Parameters: size (if size=0 the points are no plotted), shape (by default 21),
fill (if a color, the same for all the points, if color is NULL palette colors used for the clusters are applied; if more than one color use palette argument; only for shapes from 21 to 25 to fill the point), stroke (controls the edge of the point (by default 0 no edge), border (color of the border, same specifications than fill), alpha.t (by default 1). See geom_point() in ggplot2 library. See details</p>
</td></tr>
<tr><td><code id="plot.LexHCca_+3A_labels">labels</code></td>
<td>
<p>format of labels. Parameters: size (if size=0 the labels are not plotted; by default 4), family, face, hjust, vjust, color.text, alpha.t.text, numbers(if TRUE the label will be replaced by the number of the cluster to which it belongs, by default FALSE), rect (if TRUE a rectangle will be drawn around the label, by default FALSE), color.fill (color into the rectangle, by default FALSE is transparent), alpha.t.fill, force (to do repulsive textual annotations and make it easier to read), max.overlaps (maximum number of overlapped points, by default 10, can be Inf)
set.seed (by default a new seed for each plot draws different positions, for the same seed i.e: set.seed=1234)</p>
</td></tr>
<tr><td><code id="plot.LexHCca_+3A_traject">traject</code></td>
<td>
<p>draws trajectory arrows in accordance with the order of clusters or in the selInd order. Parameters: color (by default blue), linetype (by default 1 solid), space (by default 0 and no space is added from point to arrow, be careful with this value), size (width,by default 1), arrow.length (of the arrow, by default .3), arrow.type (by default &quot;closed&quot;), arrow.angle (by default 30), alpha.t. See geom_segment for details</p>
</td></tr>
<tr><td><code id="plot.LexHCca_+3A_centers">centers</code></td>
<td>
<p>draws the barycenter of the clusters. Parameters: size (by default 5), family, face, color (of the border, only one), fill, alpha.t, labels (string vector with the names of the clusters)</p>
</td></tr>
<tr><td><code id="plot.LexHCca_+3A_hull">hull</code></td>
<td>
<p>draws a hull containing all the elements of each cluster. Parameters: type (ellipse, by default, hull), alpha.t, color, linetype (by default &quot;dotted&quot;))</p>
</td></tr>
<tr><td><code id="plot.LexHCca_+3A_xlim">xlim</code></td>
<td>
<p>pair of values xlim=c(xmin,xmax). If a NA value, this limit is automatically calculated</p>
</td></tr>
<tr><td><code id="plot.LexHCca_+3A_ylim">ylim</code></td>
<td>
<p>pair of values ylim=c(ymin,ymax). If a NA value, this limit is automatically calculated</p>
</td></tr>
<tr><td><code id="plot.LexHCca_+3A_...">...</code></td>
<td>
<p>other arguments from other methods</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Parameter type=&quot;tree&quot; shows the dendrogram
</p>
<pre>
 - if hierarchical cluster without consolidation is performed.
 - if hierarchical cluster with consolidation before the consolidation.
 - if kmeans the hierarchical tree with the output of kmeans.
</pre>
<p>You can make customer dendrograms by accessing the hclust format object located inside the object in
hclust format from object$call$t$tree
</p>
<p>Selection of individuals (documents or words) to plot:
</p>
<p>1. Using labels:
</p>
<pre>
selInd = c("doc1","doc5"): only the documents with labels doc1 and doc5 are plotted.
</pre>
<p>2. Using indexes:
</p>
<pre>
selInd = c(1:5): cases 1 to 5 are plotted.
   </pre>
<p>3. Using rules:
</p>
<pre>
 Rules are based on the coordinates (coord), the contribution (contrib or meta; 
 concerning only active elements) or the square cosine (cos2). </pre>
<p>Somes examples hereafter:
</p>
<pre>
selInd="coord 10": only the 10 cases with the highest coordinates, as globally
   computed on the 2 axes, are plotted.
selInd="contrib 10": the cases with a contribution to the inertia, of any of 
   the 2 axes over 10 percent.
selInd="meta 3": the cases with a contribution over 3 times the average word/document 
   contribution on any of the two axes are plotted.
selInd="cos2 .85": the documents with a cos2 over 0.85, as summed on the 2 axes, 
   are plotted.
</pre>
<p>Parameters can be used in combination, e.g.: title=c(&quot;text&quot;=&quot;CA&quot;, &quot;color&quot;=&quot;red&quot;).
</p>
<p>See grDevices package (The R Graphics Devices and Support for Colours and Fonts).
</p>
<p>palette, the color of the palette used to draw the points. 
By default colors are chosen. If you want to define the colors for three clusters : palette=c(&quot;black&quot;,&quot;red&quot;,&quot;blue&quot;); 
or you can use: palette=palette(rainbow(30)); or in black and white for example: palette=palette(gray(seq(0,.9,len=25))).
</p>
<p>Family Fonts (family). Also see the extrafont package for a much better support of fonts: library(extrafont); font_import(). By default &quot;family&quot;='serif'.
</p>
<p>Face fonts (face). Can be 'plain', 'bold', 'italic', 'bold.italic', 'symbol'. By default 'plain'.
</p>
<p>alpha.t is the level of transparency for some objects. 0 value means full transparency and 1 opacity. By default 1.
</p>
<p>Values for horizontal justification hjust, vertical vjust and both hvjust can be (c,centered or 0.5 if centered; l,left or 0 if left; r, right or 1 if right)
</p>
<pre>
By default in:
* title: text="Clusters on the CA map"; color=black; size=18; familiy=serif; face=plain; 
      hjust=0.5.

* axis titles:  text.x=Dim x (%), text.y=Dim y (%), color=black, size=12, family=serif, 
      face=plain, just=centered.
  
* axis.text: color=black, size=8, family=serif, face=plain.

* hvline: intercept.x=0, intercept.y=0, linetype=dashed, color=gray, size=0.5, alpha.t=1.
  
* points: size=2, shape=21, border:automatic cluster color, fill:automatic cluster color, 
      stroke=0, border: automatic cluster color, alpha.t=1.

* labels: size=4, family=serif, face=plain, hjust=1, vjust=1, color.text=same of points, 
      alpha.t.text=1, numbers=FALSE, rect=FALSE, color.fill=transparent, alpha.t.fill=1,
      force=1, max.overlaps=10.

* traject: color=blue, linetype=solid, space=1, arrow.length=.3, arrow.type= closed, 
      arrow.angle=30, alpha.t=1. 

* centers: size=5, family=serif, face=italic, color, fill=automatic cluster color,
      alpha.t=1, labels=automatic strig vector with the names of the clusters.

* hull: type=ellipse, alpha.t=0.1, color=black, linetype=dotted </pre>


<h3>Author(s)</h3>

<p>Ramón Alvarez-Esteban <a href="mailto:ramon.alvarez@unileon.es">ramon.alvarez@unileon.es</a>, Mónica Bécue-Bertaut, Josep-Anton Sánchez-Espigares</p>


<h3>References</h3>

<p>The Xplortext web site provides several examples at &lt;https://xplortext.unileon.es/?page_id=766&gt;.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+LexHCca">LexHCca</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>data(open.question)
res.TD&lt;-TextData(open.question,var.text=c(9,10), var.agg="Age_Group", Fmin=10, Dmin=10,
        stop.word.tm=TRUE)
res.LexCA&lt;-LexCA(res.TD, graph=FALSE)
res.chcca&lt;-LexHCca(res.LexCA, nb.clust=4, min=3, graph=FALSE)
plot(res.chcca, type="tree")
plot(res.chcca, type="map")
</code></pre>

<hr>
<h2 id='plot.TextData'>Plot TextData objects</h2><span id='topic+plot.TextData'></span>

<h3>Description</h3>

<p>Draws the barcharts of the longest documents, most frequent words and segments from a TextData object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'TextData'
plot(x, ndoc=25, nword=25, nseg=25, sel=NULL, ordFreq=TRUE, 
 stop.word.tm=FALSE, idiom="en", stop.word.user=NULL, theme=theme_bw(), title=NULL,
 xtitle=NULL, col.fill="grey", col.lines="black", text.size=12, freq=NULL, vline=NULL, 
 interact=FALSE, round.dec = 4,...) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.TextData_+3A_x">x</code></td>
<td>
<p>object of TextData class</p>
</td></tr>
<tr><td><code id="plot.TextData_+3A_ndoc">ndoc</code></td>
<td>
<p>number of documents in the barchart (by default 25)</p>
</td></tr>
<tr><td><code id="plot.TextData_+3A_nword">nword</code></td>
<td>
<p>number of words in the barchart  (by default 25)</p>
</td></tr>
<tr><td><code id="plot.TextData_+3A_nseg">nseg</code></td>
<td>
<p>number of segments in the barchart (by default 25)</p>
</td></tr>
<tr><td><code id="plot.TextData_+3A_sel">sel</code></td>
<td>
<p>type of barchart (doc, word or seg for documents, words or repeated segments) (by default NULL and all he graphs are drawn)), see details</p>
</td></tr>
<tr><td><code id="plot.TextData_+3A_ordfreq">ordFreq</code></td>
<td>
<p>if ordFreq=TRUE, glossaries of words and repeated segments, are drawn in frequency order; if ordFreq=FALSE, glossaries are drown in alphabetic order (by default TRUE)</p>
</td></tr>
<tr><td><code id="plot.TextData_+3A_stop.word.tm">stop.word.tm</code></td>
<td>
<p>if TRUE, the tm stopwords (if the words are selected in TextData object) are not considered for the barchart (by default FALSE)</p>
</td></tr>
<tr><td><code id="plot.TextData_+3A_idiom">idiom</code></td>
<td>
<p>declared idiom for the textual column(s) (by default English &quot;en&quot;, see IETF language in package NLP)</p>
</td></tr>
<tr><td><code id="plot.TextData_+3A_stop.word.user">stop.word.user</code></td>
<td>
<p>the user's stopwords (if the words are selected in TextData object) are not considered for the barchart (by default NULL)</p>
</td></tr>
<tr><td><code id="plot.TextData_+3A_theme">theme</code></td>
<td>
<p>theme settings (see ggplot2 package; by default theme_bw())</p>
</td></tr>
<tr><td><code id="plot.TextData_+3A_title">title</code></td>
<td>
<p>title of the graph (by default NULL and the title is automatically assigned)</p>
</td></tr>
<tr><td><code id="plot.TextData_+3A_xtitle">xtitle</code></td>
<td>
<p>x title of the graph (by default NULL and the x title is automatically assigned)</p>
</td></tr>
<tr><td><code id="plot.TextData_+3A_col.fill">col.fill</code></td>
<td>
<p>background color for the barChart bars (by default grey)</p>
</td></tr>
<tr><td><code id="plot.TextData_+3A_col.lines">col.lines</code></td>
<td>
<p>lines color for the barChart bars (by default black)</p>
</td></tr>
<tr><td><code id="plot.TextData_+3A_text.size">text.size</code></td>
<td>
<p>text font size (by default 12)</p>
</td></tr>
<tr><td><code id="plot.TextData_+3A_freq">freq</code></td>
<td>
<p>add frequencies to word and document barplots, see details (by default NULL)</p>
</td></tr>
<tr><td><code id="plot.TextData_+3A_vline">vline</code></td>
<td>
<p>if &quot;YES&quot; or TRUE add vertical line to barplot, see details (by default NULL)</p>
</td></tr>
<tr><td><code id="plot.TextData_+3A_interact">interact</code></td>
<td>
<p>if FALSE a ggplot graph, if TRUE an interactive plotly graph, see details (by default FALSE)</p>
</td></tr>
<tr><td><code id="plot.TextData_+3A_round.dec">round.dec</code></td>
<td>
<p>number of decimals (by default 4)</p>
</td></tr>
<tr><td><code id="plot.TextData_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods...</p>
</td></tr>
</table>


<h3>Details</h3>

<p>freq adds frequencies to barplot (by default NULL). If &quot;YES&quot; or TRUE displays the frequencies at the right of the bars at +5 position.
Numerical values display the frequencies at the right positions (positive values) or at the left (negative values).
</p>
<p>vline adds two vertical line to word and document barplot (by default NULL). If TRUE a first vertical row line is added at mean level computed from the selected items from TextData,
and a second vertical blue line with the frequency mean of words/documents selected to plot in plot.TextData. If row and blue lines are the same, only blue line is shown.
If vline is a number, a line is show with this value.
</p>
<p>Barchart selected in sel argument (doc, word and/or repeated segments) is in ggplot format. 
Barchart is used with geom_bar function of ggplot package. If it is only one element in sel argument the plot can
be saved in ggplot format:  newobject &lt;- plot(TextDataObject,sel=&quot;word&quot;)
</p>
<p>Selection of docs, words or segments can be done by numbers sel=list(type=&quot;doc&quot;, select=c(1,2:4,6)) or names sel= list(type=&quot;doc&quot;, select=c(&quot;M31_55&quot;, &quot;M&gt;55&quot;)).
</p>
<p>If interact, rank for words/docs/segments from TextData selection are shown.
</p>


<h3>Author(s)</h3>

<p>Ramón Alvarez-Esteban <a href="mailto:ramon.alvarez@unileon.es">ramon.alvarez@unileon.es</a>, Mónica Bécue-Bertaut, Josep-Antón Sánchez-Espigares</p>


<h3>See Also</h3>

 <p><code><a href="#topic+TextData">TextData</a></code>, <code><a href="#topic+print.TextData">print.TextData</a></code>,  <code><a href="#topic+summary.TextData">summary.TextData</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'># Non aggregate analysis

 data(open.question)
 res.TD&lt;-TextData(open.question, var.text=c(9,10), remov.number=TRUE, Fmin=10, Dmin=10,  
 stop.word.tm=TRUE, context.quali=c("Gender","Age_Group","Education"), context.quanti=c("Age"))
 plot(res.TD)

# Aggregate analysis
 data(open.question)
 res.TD&lt;-TextData(open.question, var.text=c(9,10), var.agg="Gen_Age", remov.number=TRUE, 
 Fmin=10, Dmin=10, stop.word.tm=TRUE, context.quali=c("Gender","Age_Group","Education"), 
 context.quanti=c("Age"), segment=TRUE)
 plot(res.TD)

</code></pre>

<hr>
<h2 id='print.LexCA'>Print LexCA objects</h2><span id='topic+print.LexCA'></span>

<h3>Description</h3>

<p>Prints the Textual Correspondence Analysis (CA) results from a LexCA object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'LexCA'
print(x, file = NULL, sep=";", ...) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.LexCA_+3A_x">x</code></td>
<td>
<p>object of LexCA class</p>
</td></tr>
<tr><td><code id="print.LexCA_+3A_file">file</code></td>
<td>
<p>a connection, or a character string giving the name of the file to print to (in csv format). If NULL (the default), the results are not printed in a file</p>
</td></tr>
<tr><td><code id="print.LexCA_+3A_sep">sep</code></td>
<td>
<p>character to insert between the objects to print (if the argument file is non-NULL) (by default &quot;;&quot;)</p>
</td></tr>
<tr><td><code id="print.LexCA_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Ramón Alvarez-Esteban <a href="mailto:ramon.alvarez@unileon.es">ramon.alvarez@unileon.es</a>, Mónica Bécue-Bertaut, Josep-Antón Sánchez-Espigares</p>


<h3>See Also</h3>

 <p><code><a href="#topic+LexCA">LexCA</a></code>, <code><a href="#topic+plot.LexCA">plot.LexCA</a></code>, <code><a href="#topic+summary.LexCA">summary.LexCA</a></code>, <code><a href="#topic+TextData">TextData</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>data(open.question)
res.TD&lt;-TextData(open.question,var.text=c(9,10), var.agg="Age_Group", Fmin=10, Dmin=10,
        remov.number=TRUE, stop.word.tm=TRUE)
res.LexCA&lt;-LexCA(res.TD,lmd=0,lmw=1)
print(res.LexCA)
</code></pre>

<hr>
<h2 id='print.LexChar'>Print LexChar objects</h2><span id='topic+print.LexChar'></span>

<h3>Description</h3>

<p>Prints characteristic words and documents from LexChar objects
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'LexChar'
print(x, file = NULL, sep=";", dec=".",  ...) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.LexChar_+3A_x">x</code></td>
<td>
<p>object of LexChar class</p>
</td></tr>
<tr><td><code id="print.LexChar_+3A_file">file</code></td>
<td>
<p>a connection, or a character string giving the name of the file to print to (in csv format). If NULL (the default), the results are not printed in a file</p>
</td></tr>
<tr><td><code id="print.LexChar_+3A_sep">sep</code></td>
<td>
<p>character to insert between the objects to print (if the argument file is non-NULL) (by default &quot;;&quot;)</p>
</td></tr>
<tr><td><code id="print.LexChar_+3A_dec">dec</code></td>
<td>
<p>decimal point (by default &quot;.&quot;)</p>
</td></tr>
<tr><td><code id="print.LexChar_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Ramón Alvarez-Esteban <a href="mailto:ramon.alvarez@unileon.es">ramon.alvarez@unileon.es</a>, Mónica Bécue-Bertaut, Josep-Antón Sánchez-Espigares</p>


<h3>See Also</h3>

 <p><code><a href="#topic+LexChar">LexChar</a></code>, <code><a href="#topic+plot.LexChar">plot.LexChar</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>data(open.question)
res.TD&lt;-TextData(open.question, var.text=c(9,10), var.agg="Gen_Edu", Fmin=10, Dmin=10,
        stop.word.tm=TRUE)
LD&lt;-LexChar(res.TD, maxCharDoc = 0)
print(LD)
</code></pre>

<hr>
<h2 id='print.TextData'>Print TextData objects</h2><span id='topic+print.TextData'></span>

<h3>Description</h3>

<p>Print statistical results for documents, words and segments from TextData objects, in alphabetical and frequency order.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'TextData'
print(x, file = NULL, sep=";", ...) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.TextData_+3A_x">x</code></td>
<td>
<p>object of TextData class</p>
</td></tr>
<tr><td><code id="print.TextData_+3A_file">file</code></td>
<td>
<p>connection, or character string giving the name of the file to print to (in csv format). If NULL (by default value), 
the results are not printed in a file</p>
</td></tr>
<tr><td><code id="print.TextData_+3A_sep">sep</code></td>
<td>
<p>character inserted between the objects to print (if file argument is non-NULL) (by default &quot;;&quot;)</p>
</td></tr>
<tr><td><code id="print.TextData_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Ramón Alvarez-Esteban <a href="mailto:ramon.alvarez@unileon.es">ramon.alvarez@unileon.es</a>, Monica Bécue-Bertaut, Josep-Antón Sánchez-Espigares</p>


<h3>See Also</h3>

 <p><code><a href="#topic+TextData">TextData</a></code>, <code><a href="#topic+plot.TextData">plot.TextData</a></code>,  <code><a href="#topic+summary.TextData">summary.TextData</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>data(open.question)
res.TD&lt;-TextData(open.question, var.text=c(9,10), remov.number=TRUE, Fmin=10, Dmin=10,  
stop.word.tm=TRUE, context.quali=c("Gender","Age_Group","Education"),
   context.quanti=c("Age"))
print(res.TD)
</code></pre>

<hr>
<h2 id='summary.LexCA'>Summary LexCA object</h2><span id='topic+summary.LexCA'></span>

<h3>Description</h3>

<p>Summarizes LexCA objects
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'LexCA'
summary(object, ncp=5, nb.dec = 3, ndoc=10, nword=10, nseg=10, 
 nsup=10, metaDocs=FALSE, metaWords=FALSE, file = NULL, ...)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.LexCA_+3A_object">object</code></td>
<td>
<p>object of LexCA class</p>
</td></tr>
<tr><td><code id="summary.LexCA_+3A_ncp">ncp</code></td>
<td>
<p>number of dimensions to be printed (by default 5)</p>
</td></tr>
<tr><td><code id="summary.LexCA_+3A_nb.dec">nb.dec</code></td>
<td>
<p>number of decimal digits to be printed (by default 3)</p>
</td></tr>
<tr><td><code id="summary.LexCA_+3A_ndoc">ndoc</code></td>
<td>
<p>number of documents whose coordinates are listed (by default 10).
Use ndoc=&quot;ALL&quot; to have the results for all the documents. Use 
ndoc=0 or ndoc=NULL if the results for documents are not wanted.</p>
</td></tr>
<tr><td><code id="summary.LexCA_+3A_nword">nword</code></td>
<td>
<p>number of words whose coordinates are listed (by default 10). 
Use nword=&quot;ALL&quot; to have the results for all the words. Use
nword=0 or nword=NULL if the results for words are not wanted</p>
</td></tr> 
<tr><td><code id="summary.LexCA_+3A_nseg">nseg</code></td>
<td>
<p>number of repeated segments whose coordinates are listed (by default 10). 
Use nseg=&quot;ALL&quot; to have the results for all the segments. Use 
nseg=0 or nseg=NULL if the results for segments are not wanted</p>
</td></tr> 
<tr><td><code id="summary.LexCA_+3A_nsup">nsup</code></td>
<td>
<p>number of supplementary elements whose coordinates are listed (by default 10). 
Use nsup=&quot;ALL&quot; to have the results for all the elements. Use 
nsup=0 or nsup=NULL if the results for the supplementary elements are not wanted</p>
</td></tr>
<tr><td><code id="summary.LexCA_+3A_metadocs">metaDocs</code></td>
<td>
<p>axis by axis, the highest contributive documents are listed, separately for negative-part and positive-part documents; these documents have been identified in LexCA, taking into account lmd value (by default FALSE)</p>
</td></tr>
<tr><td><code id="summary.LexCA_+3A_metawords">metaWords</code></td>
<td>
<p>axis by axis, the highest contributive words are listed, separately for negative-part and positive-part words; these words have been identified in LexCA, taking into account lmw value (by default FALSE)</p>
</td></tr>
<tr><td><code id="summary.LexCA_+3A_file">file</code></td>
<td>
<p>a connection, or a character string naming the file to print to (csv format). If NULL (the default), the results are not printed in a file</p>
</td></tr>
<tr><td><code id="summary.LexCA_+3A_...">...</code></td>
<td>
<p>further arguments passed from other methods</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Ramón Alvarez-Esteban <a href="mailto:ramon.alvarez@unileon.es">ramon.alvarez@unileon.es</a>, Monica Bécue-Bertaut, Josep-Antón Sánchez-Espigares</p>


<h3>See Also</h3>

 <p><code><a href="#topic+LexCA">LexCA</a></code>, <code><a href="#topic+print.LexCA">print.LexCA</a></code>,  <code><a href="#topic+plot.LexCA">plot.LexCA</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>data(open.question)
res.TD&lt;-TextData(open.question, var.text=c(9,10), Fmin=10, Dmin=10, stop.word.tm=TRUE)
res.LexCA&lt;-LexCA(res.TD, lmd=1, lmw=1)
summary(res.LexCA)
</code></pre>

<hr>
<h2 id='summary.LexChar'>Summary LexChar object</h2><span id='topic+summary.LexChar'></span>

<h3>Description</h3>

<p>Summarizes LexChar objects
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'LexChar'
summary(object, CharWord=TRUE, stats=TRUE, CharDoc=TRUE, Vocab=TRUE,
    file = NULL, ...)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.LexChar_+3A_object">object</code></td>
<td>
<p>object of TextData class</p>
</td></tr>
<tr><td><code id="summary.LexChar_+3A_charword">CharWord</code></td>
<td>
<p>if TRUE characteristic words of all the documents are shown (by default TRUE)</p>
</td></tr>
<tr><td><code id="summary.LexChar_+3A_stats">stats</code></td>
<td>
<p>if TRUE association statistics of lexical table are shown (by default TRUE)</p>
</td></tr>
<tr><td><code id="summary.LexChar_+3A_chardoc">CharDoc</code></td>
<td>
<p>if TRUE characteristic source-documents of all the aggregate-documents are shown (by default TRUE)</p>
</td></tr>
<tr><td><code id="summary.LexChar_+3A_vocab">Vocab</code></td>
<td>
<p>if TRUE characteristic quantitative and qualitative variables of the words. CharWord and stats are provide</p>
</td></tr>
<tr><td><code id="summary.LexChar_+3A_file">file</code></td>
<td>
<p>a connection, or a character string naming the file to print to in csv format. If NULL (the default), the results are not printed in a file</p>
</td></tr>
<tr><td><code id="summary.LexChar_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods,...</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Vocab$quali$CharWord provides the qualitative variables and their categories.
Vocab$quali$stats provides association statistics for vocabulary and qualitative variables.
Vocab$quanti$CharWord provides characteristic quantitative variables for each word. This summary.LexChart function provides the characteristic words for each quantitative variable.
Vocab$quali$stats provides statistics for vocabulary and quantitative variables.
</p>


<h3>Author(s)</h3>

<p>Ramón Alvarez-Esteban <a href="mailto:ramon.alvarez@unileon.es">ramon.alvarez@unileon.es</a>, Monica Bécue-Bertaut, Josep-Antón Sánchez-Espigares</p>


<h3>See Also</h3>

 <p><code><a href="#topic+LexChar">LexChar</a></code>, <code><a href="#topic+print.LexChar">print.LexChar</a></code>, <code><a href="#topic+plot.LexChar">plot.LexChar</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>data(open.question)
res.TD&lt;-TextData(open.question, var.text=c(9,10), var.agg="Gen_Edu", Fmin=10, Dmin=10, 
        remov.number=TRUE, stop.word.tm=TRUE)
res.LexChar &lt;- LexChar(res.TD)
summary(res.LexChar)

</code></pre>

<hr>
<h2 id='summary.TextData'>Summary of TextData objects</h2><span id='topic+summary.TextData'></span>

<h3>Description</h3>

<p>Summarizes TextData objects.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'TextData'
summary(object, ndoc=10, nword=50, nseg=50, ordFreq = TRUE, file = NULL, sep=";", 
   info=TRUE,...) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.TextData_+3A_object">object</code></td>
<td>
<p>object of TextData class</p>
</td></tr>
<tr><td><code id="summary.TextData_+3A_ndoc">ndoc</code></td>
<td>
<p>statistical report on the first ndoc documents (by default 10). 
Use ndoc=&quot;ALL&quot; to have the results for all the documents. Use
ndoc=0 or ndoc=NULL if the results on the documents are not wanted </p>
</td></tr> 
<tr><td><code id="summary.TextData_+3A_nword">nword</code></td>
<td>
<p>index of the nword first words (by default 50). 
Use nword=&quot;ALL&quot; to have the complete index. Use
nword=0 or nword=NULL if the results on the words are not wanted </p>
</td></tr> 
<tr><td><code id="summary.TextData_+3A_nseg">nseg</code></td>
<td>
<p>index of the nfirst nseg repeated segments (by default 50). 
Use nseg=&quot;ALL&quot; to have the complete list of segments. Use 
nseg=0 or nseg=NULL if the results on the segments are not wanted </p>
</td></tr> 
<tr><td><code id="summary.TextData_+3A_ordfreq">ordFreq</code></td>
<td>
<p>if ordFreq=TRUE, glossaries of words and repeated segments, are listed in frequency order; 
if ordFreq=FALSE, glossaries are listed  in alphabetic order (by default TRUE)</p>
</td></tr>
<tr><td><code id="summary.TextData_+3A_file">file</code></td>
<td>
<p>a connection, or a character string naming the file to print to in csv format. If NULL (the default), the results are not printed in a file</p>
</td></tr>
<tr><td><code id="summary.TextData_+3A_sep">sep</code></td>
<td>
<p>character string to insert between the objects to print (if the argument file is not NULL) (by default &quot;;&quot;)</p>
</td></tr>
<tr><td><code id="summary.TextData_+3A_info">info</code></td>
<td>
<p>if TRUE the selection criteria of the words are shown(by default TRUE)</p>
</td></tr>
<tr><td><code id="summary.TextData_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods,...</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Ramón Alvarez-Esteban <a href="mailto:ramon.alvarez@unileon.es">ramon.alvarez@unileon.es</a>, Monica Bécue-Bertaut, Josep-Antón Sánchez-Espigares</p>


<h3>See Also</h3>

 <p><code><a href="#topic+TextData">TextData</a></code>, <code><a href="#topic+print.TextData">print.TextData</a></code>,  <code><a href="#topic+plot.TextData">plot.TextData</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'># Non aggregate analysis
data(open.question)
res.TD&lt;-TextData(open.question, var.text=c(9,10), remov.number=TRUE, Fmin=10, Dmin=10,  
 stop.word.tm=TRUE, context.quali=c("Gender","Age_Group","Education"), context.quanti=c("Age"))
summary(res.TD)

# Aggregate analysis and repeated segments
data(open.question)
res.TD&lt;-TextData(open.question, var.text=c(9,10), var.agg="Gen_Age", remov.number=TRUE, 
 Fmin=10, Dmin=10, stop.word.tm=TRUE, context.quali=c("Gender","Age_Group","Education"), 
 context.quanti=c("Age"), segment=TRUE)
summary(res.TD)
</code></pre>

<hr>
<h2 id='TextData'>Building textual and contextual tables (TextData)</h2><span id='topic+TextData'></span>

<h3>Description</h3>

<p>Creates a textual and contextual working-base (TextData format) from a source-base (data frame format).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>TextData(base, var.text=NULL, var.agg=NULL, context.quali=NULL, context.quanti= NULL,
 selDoc="ALL", lower=TRUE, remov.number=TRUE,lminword=1, Fmin=Dmin,Dmin=1, Fmax=Inf,
 stop.word.tm=FALSE, idiom="en", stop.word.user=NULL, segment=FALSE,
 sep.weak="default",
 sep.strong="\u005B()\u00BF?./:\u00A1!=;{}\u005D\u2026", seg.nfreq=10, seg.nfreq2=10,
 seg.nfreq3=10, graph=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="TextData_+3A_base">base</code></td>
<td>
<p>source data frame with at least one textual column</p>
</td></tr>
<tr><td><code id="TextData_+3A_var.text">var.text</code></td>
<td>
<p>vector with index(es) or name(s) of the selected textual column(s) (by default NULL)</p>
</td></tr>
<tr><td><code id="TextData_+3A_var.agg">var.agg</code></td>
<td>
<p>index or name of the aggregation categorical variable (by default NULL)</p>
</td></tr>
<tr><td><code id="TextData_+3A_context.quali">context.quali</code></td>
<td>
<p>vector with index(es) or name(s) of the selected categorical variable(s) (by default NULL)</p>
</td></tr>
<tr><td><code id="TextData_+3A_context.quanti">context.quanti</code></td>
<td>
<p>vector with index(es) or name(s) of the selected quantitative variable(s) (by default NULL)</p>
</td></tr>
<tr><td><code id="TextData_+3A_seldoc">selDoc</code></td>
<td>
<p>vector with index(es) or name(s) of the selected source-documents (rows of the source-base) (by default &quot;ALL&quot;)</p>
</td></tr>
<tr><td><code id="TextData_+3A_lower">lower</code></td>
<td>
<p>if TRUE, the corpus is converted into lowercase (by default TRUE)</p>
</td></tr>
<tr><td><code id="TextData_+3A_remov.number">remov.number</code></td>
<td>
<p>if TRUE, numbers are removed (by default TRUE)</p>
</td></tr>  
<tr><td><code id="TextData_+3A_lminword">lminword</code></td>
<td>
<p>minimum length of a word to be selected (by default 1)</p>
</td></tr>
<tr><td><code id="TextData_+3A_fmin">Fmin</code></td>
<td>
<p>minimum frequency of a word to be selected (by default Dmin)</p>
</td></tr>
<tr><td><code id="TextData_+3A_dmin">Dmin</code></td>
<td>
<p>a word has to be used in at least Dmin source-documents to be selected (by default 1)</p>
</td></tr>
<tr><td><code id="TextData_+3A_fmax">Fmax</code></td>
<td>
<p>maximum frequency of a word to be selected (by default Inf)</p>
</td></tr>
<tr><td><code id="TextData_+3A_stop.word.tm">stop.word.tm</code></td>
<td>
<p>if TRUE, stoplist automatically provided in accordance with the idiom (by default FALSE)</p>
</td></tr>
<tr><td><code id="TextData_+3A_idiom">idiom</code></td>
<td>
<p>declared idiom for the textual column(s) (by default English &quot;en&quot;, see IETF language in package NLP)</p>
</td></tr>
<tr><td><code id="TextData_+3A_stop.word.user">stop.word.user</code></td>
<td>
<p>stoplist provided by the user</p>
</td></tr>
<tr><td><code id="TextData_+3A_segment">segment</code></td>
<td>
<p>if TRUE, the repeated segments are identified (by default FALSE)</p>
</td></tr>
<tr><td><code id="TextData_+3A_sep.weak">sep.weak</code></td>
<td>
<p>string with the characters marking out the terms (by default punctuation characters, space and control). See details</p>
</td></tr>
<tr><td><code id="TextData_+3A_sep.strong">sep.strong</code></td>
<td>
<p>string with the characters marking out the repeated segments (by default &quot;[()??./:?!=+;-]\&quot;)</p>
</td></tr>
<tr><td><code id="TextData_+3A_seg.nfreq">seg.nfreq</code></td>
<td>
<p>minimum frequency of a more-than-three-words-long repeated segment (by default 10)</p>
</td></tr>
<tr><td><code id="TextData_+3A_seg.nfreq2">seg.nfreq2</code></td>
<td>
<p>minimum frequency of a two-words-long repeated segment (by default 10)</p>
</td></tr>
<tr><td><code id="TextData_+3A_seg.nfreq3">seg.nfreq3</code></td>
<td>
<p>minimum frequency of a three-words-long repeated segment (by default 10)</p>
</td></tr>
<tr><td><code id="TextData_+3A_graph">graph</code></td>
<td>
<p>if TRUE, documents, words and repeated segments barcharts are displayed; use plot.TextData to use more options (by default FALSE)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Each row of the source-base is considered as a source-document.
TextData function builds the working-documents-by-words table, submitted to the analysis.
</p>
<p>sep.weak contains the string with the characters marking out the terms (by default punctuation characters, space and control).
Backslash or double backslash are used to start an escape sequence defining special characters. Each special character must by separated the symbol | (or) in sep.weak and sep.strong.
The default is:
<code style="white-space: pre;">&#8288;

sep.weak = ("[%`:_*$&amp;#/^|&lt;=&gt;;'+@.,~?(){}|[[:space:]]|

\u2014|\u002D|\u00A1|\u0021|\u00BF|\u00AB|\u00BB|\u2026|\u0022|\u005D")



&#8288;</code>
Some special characters can be introduced as unicode characters. Back slash (escape contol) is not allowed.
</p>
<p>Information related to context.quanti and context.quali arguments:
</p>

<ol>
<li><p> If numeric, contextual variables can be included in both vectors. The function TextData converts the numeric variable into factor to include it in context.quali vector. This possibility is interesting in some cases. For example, when treating open-ended questions, we can be interested in computing the correlation between the contextual variable &quot;Age&quot; and the axes and, at the same time, to draw the trajectory of the different values of &quot;Age&quot; (year by year) on the CA maps. 
</p>
</li>
<li><p> In the case of one or several columns with textual data not selected in vector var.text, if the argument context.quali is equal to &quot;ALL&quot;, these columns will be considered as categorical variables. 
</p>
</li></ol>

<p>Non-aggregate table versus aggregate table.
</p>
<p>If var.agg=NULL: 
</p>

<ol>
<li><p> The work-documents are the non-empty-source-documents.
</p>
</li>
<li><p> DocTerm: non-aggregate lexical table with:
</p>

<table>
<tr>
 <td style="text-align: left;">
 </td><td style="text-align: left;"> as many rows as non-empty source-documents</td>
</tr>
<tr>
 <td style="text-align: left;">
 </td><td style="text-align: left;"> as many columns as words are selected.
  </td>
</tr>

</table>

</li>
<li><p> context$quali: data frame crossing the non-empty source-documents (rows) and the categorical contextual-variables (columns).
</p>
</li>
<li><p> context$quanti: data frame crossing the non-empty source-documents (rows) and the quantitative contextual-variables (columns).
Both contextual tables can be juxtaposed row-wise to DocTerm table. 
</p>
</li></ol>

<p>If var.agg is NON-NULL:
</p>

<ol>
<li><p> The work-documents are aggregate-documents, issued from aggregating the source-documents depending on the categories of the aggregation variable; the aggregate-documents inherit the names of the corresponding categories.
</p>
</li>
<li><p> DocTerm is an aggregate table with:
</p>

<table>
<tr>
 <td style="text-align: left;">
 </td><td style="text-align: left;"> as many rows as as categories the aggregation variable has</td>
</tr>
<tr>
 <td style="text-align: left;">
 </td><td style="text-align: left;"> as many columns as words are selected.
  </td>
</tr>

</table>

</li>
<li><p> context$quali$qualitable: juxtaposes as many supplementary aggregate tables as categorical contextual variables. Each table has: 
</p>

<table>
<tr>
 <td style="text-align: left;">
 </td><td style="text-align: left;"> as many rows as categories the contextual categorical variable has</td>
</tr>
<tr>
 <td style="text-align: left;">
 </td><td style="text-align: left;"> as many columns as selected words, i.e. as many columns as DocTerm has.
  </td>
</tr>

</table>

</li>
<li><p> context$quali$qualivar: names of categories of the supplementary categorical variables.
</p>
</li>
<li><p> context$quanti: data frame crossing the working aggregate-documents (rows) and the quantitative contextual-variables (columns).
The value for an active aggregate-document is the mean-value of the source-documents belonging to this aggregate-document.
</p>
</li></ol>



<h3>Value</h3>

<p>A list including:
</p>
<table>
<tr><td><code>summGen</code></td>
<td>
<p>general summary</p>
</td></tr>
<tr><td><code>summDoc</code></td>
<td>
<p>document summary</p>
</td></tr>
<tr><td><code>indexW</code></td>
<td>
<p>index of words</p>
</td></tr>
<tr><td><code>DocTerm</code></td>
<td>
<p>working lexical table (non-aggregate or aggregate table depending on var.agg value); 
working-documents by words table in slam package compressed format</p>
</td></tr>
<tr><td><code>context</code></td>
<td>
<p>contextual variables if context.quali or context.quanti are non-NULL; the structure greatly differs 
in accordance with the nature of DocTerm table (non-aggregate/ aggregate), see details</p>
</td></tr>
<tr><td><code>info</code></td>
<td>
<p>information about the selection of words</p>
</td></tr>
<tr><td><code>var.agg</code></td>
<td>
<p>a one-column data frame with the values of the aggregation variable; NULL if non-aggregate analysis</p>
</td></tr>
<tr><td><code>SourceTerm</code></td>
<td>
<p>in the case of DocTerm being an aggregate analysis, the source-documents by words table is kept in 
this data structure, in slam package compressed format</p>
</td></tr>
<tr><td><code>indexS</code></td>
<td>
<p>working-documents by repeated-segments table, in slam package compressed format</p>
</td></tr>
<tr><td><code>remov.docs</code></td>
<td>
<p>vector with the names of the removed empty source-documents</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Ramón Alvarez-Esteban <a href="mailto:ramon.alvarez@unileon.es">ramon.alvarez@unileon.es</a>, Monica Bécue-Bertaut, Josep-Antón Sánchez-Espigares</p>


<h3>References</h3>

<p>Lebart, L., Salem, A., &amp; Berry, L. (1998). Exploring textual data. (D. Kluwer, Ed.). <a href="https://doi.org/10.1007/978-94-017-1525-6">doi:10.1007/978-94-017-1525-6</a>.
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+print.TextData">print.TextData</a></code>, <code><a href="#topic+summary.TextData">summary.TextData</a></code>,  <code><a href="#topic+plot.TextData">plot.TextData</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Non aggregate analysis
data(open.question)
res.TD&lt;-TextData(open.question, var.text=c(9,10), remov.number=TRUE, Fmin=10, Dmin=10,  
 stop.word.tm=TRUE, context.quali=c("Gender","Age_Group","Education"), context.quanti=c("Age"))

# Aggregate analysis and repeated segments
data(open.question)
res.TD&lt;-TextData(open.question, var.text=c(9,10), var.agg="Gen_Age", remov.number=TRUE, 
 Fmin=10, Dmin=10, stop.word.tm=TRUE, context.quali=c("Gender","Age_Group","Education"), 
 context.quanti=c("Age"), segment=TRUE)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
