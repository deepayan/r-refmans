<!DOCTYPE html><html lang="en"><head><title>Help for package slimrec</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {slimrec}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#slimrec-package'><p>slimrec</p></a></li>
<li><a href='#ft_explicit'><p>filmtrust explicit dataset</p></a></li>
<li><a href='#ft_implicit'><p>filmtrust implicit dataset</p></a></li>
<li><a href='#ft_small'><p>filmtrust small dataset</p></a></li>
<li><a href='#slim'><p>slim</p></a></li>
<li><a href='#top_cols'><p>top_cols</p></a></li>
<li><a href='#top_rows'><p>top_rows</p></a></li>
<li><a href='#tune_slim'><p>tune_slim</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Title:</td>
<td>Sparse Linear Method to Predict Ratings and Top-N
Recommendations</td>
</tr>
<tr>
<td>Version:</td>
<td>0.1.0</td>
</tr>
<tr>
<td>Description:</td>
<td>Sparse Linear Method(SLIM) predicts ratings and top-n
    recommendations suited for sparse implicit positive feedback systems. SLIM
    is decomposed into multiple elasticnet optimization problems which are solved
    in parallel over multiple cores. The package is based on "SLIM: Sparse Linear
    Methods for Top-N Recommender Systems" by Xia Ning and George Karypis &lt;<a href="https://doi.org/10.1109%2FICDM.2011.134">doi:10.1109/ICDM.2011.134</a>&gt;.</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.3.3), stats (&ge; 3.3.3)</td>
</tr>
<tr>
<td>Imports:</td>
<td>assertthat (&ge; 0.1), parallel (&ge; 3.3.3), Matrix (&ge; 1.2.8),
glmnet (&ge; 2.0.5), bigmemory (&ge; 4.5.19), pbapply (&ge; 1.3.2)</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>5.0.1</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2017-03-24 20:04:49 UTC; talegari</td>
</tr>
<tr>
<td>Author:</td>
<td>Srikanth KS [aut, cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Srikanth KS &lt;sri.teach@gmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2017-03-25 09:27:15 UTC</td>
</tr>
</table>
<hr>
<h2 id='slimrec-package'>slimrec</h2><span id='topic+slimrec'></span><span id='topic+slimrec-package'></span>

<h3>Description</h3>

<p>Sparse Linear Method to Predict Ratings and Top-N
Reccomendations
</p>


<h3>Details</h3>

<p><strong>Sparse linear method</strong>
(<a href="http://glaros.dtc.umn.edu/gkhome/node/774">DOI:
10.1109/ICDM.2011.134</a>) predicts ratings and top-n recommendations suited
for sparse implicit positive feedback systems. SLIM is decomposed into
multiple elasticnet optimization problems which are solved in parallel over
multiple cores. The package is based on  &quot;SLIM: Sparse Linear Methods for
Top-N Recommender Systems&quot;  by Xia Ning and George Karypis.
</p>
<p>The method predicts ratings of a user for a given item as a linear
combination ratings of all other items provided by the user. The
coefficients for an item are determined elastic-net regression (both L1 and
L2 regularization) over ratings matrix.
</p>
<p>The optimization problem solves:
</p>
<p style="text-align: center;"><code class="reqn">\min_{c_{j,.}} \frac{1}{2} \|a_{j,.} - Ac_{j,.}\|^2_{2} +
  \frac{\beta}{2} \|c_{j,.}\|^2_{2} + \gamma \|c_{j,.}\|_{1}</code>
</p>
<p> subject to
<code class="reqn">c_{j,j} = 0</code> and optional non-negative constraint <code class="reqn">c_{j,.} &gt;= 0</code>
where <code class="reqn">a_{j,.}</code> is the j th column of the input ratings matrix and
<code class="reqn">c_{j,.}</code> is the j th column of the coefficient matrix(to be
determined).
</p>
<p>The method assumes that unknown rating values to be zero. Hence, it is
primarily designed for implicit feeback mechanisms, but not restricted
them. The main use of the ratings is to generate top-n lists of users and
items.
</p>
<p>The package provides three functions: </p>
 <ul>
<li> <p><code>slim</code>: Function
to compute ratings and coefficient matrix for the sparse ratings matrix
using SLIM method. </p>
</li>
<li> <p><code>tune_slim</code>: Function to arrive at an optimal
value of <code>alpha</code> for <code><a href="#topic+slim">slim</a></code>. </p>
</li>
<li> <p><code>top_rows/cols</code>:
Functions to find row/column numbers corresponding the largest values in a
particular column/row of a matrix. This is helpful to generate top-n users
or items as recommendations. </p>
</li></ul>

<p>The package is primarily based on the wonderful package <span class="pkg">glmnet</span> by
Jerome Friedman, Trevor Hastie, Noah Simon, Rob Tibshirani.
</p>
<p>If you intend to use SLIM method for large matrices( around &gt;= 1e7
ratings), this package might be slow enough to be practically useful even
in parallel mode. You might want to look at <span class="pkg">biglasso</span> and other
implementations like <a href="http://librec.net/">librec</a>.
</p>

<hr>
<h2 id='ft_explicit'>filmtrust explicit dataset</h2><span id='topic+ft_explicit'></span>

<h3>Description</h3>

<p>filmtrust explicit dataset
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ft_explicit
</code></pre>


<h3>Format</h3>

<p>A sparse matrix  of class <code>dgCMatrix</code> with 1508 users and 2071
items. A (i,j) th element is rating provided by user i for item j. The
possible ratings are <code>(0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0)</code>. A
(i,j) th element is zero if there is no rating value. There are 35494
ratings ( sparsity = 0.0114 ). Source:
<a href="http://www.librec.net/datasets/filmtrust.zip">librec datasets</a></p>

<hr>
<h2 id='ft_implicit'>filmtrust implicit dataset</h2><span id='topic+ft_implicit'></span>

<h3>Description</h3>

<p>filmtrust implicit dataset
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ft_implicit
</code></pre>


<h3>Format</h3>

<p>A sparse matrix  of class <code>dgCMatrix</code> with 1508 users and 2071
items. A (i,j) th element is rating provided by user i for item j. A
(i,j) th element is zero if there is no rating value. There are 35494
ratings ( sparsity = 0.0114 ). Source:
<a href="http://www.librec.net/datasets/filmtrust.zip">librec datasets</a></p>

<hr>
<h2 id='ft_small'>filmtrust small dataset</h2><span id='topic+ft_small'></span>

<h3>Description</h3>

<p>filmtrust small dataset
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ft_small
</code></pre>


<h3>Format</h3>

<p>A sparse matrix  of class <code>dgCMatrix</code> with 100 users and 1000
items. A (i,j) th element is 1 only if user i has rated item j. A (i,j) th
element is zero if there is no rating value. There are 7780 ratings (
sparsity = 0.778 ). This is a simply <code>ft_implicit[1:100,1:1000]</code>.
Source: <a href="http://www.librec.net/datasets/filmtrust.zip">librec
datasets</a></p>

<hr>
<h2 id='slim'>slim</h2><span id='topic+slim'></span>

<h3>Description</h3>

<p>Compute ratings and coefficient matrix for the sparse ratings
matrix using SLIM
</p>


<h3>Usage</h3>

<pre><code class='language-R'>slim(mat, alpha = 0.5, lambda, nlambda, nonNegCoeff = TRUE, directory,
  coeffMat = FALSE, returnMat = FALSE, computeRMSE = FALSE, nproc = 1L,
  progress = TRUE, check = TRUE, cleanup = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="slim_+3A_mat">mat</code></td>
<td>
<p>(sparse matrix of class 'dgCMatrix') Rating matrix with items
along columns and users along rows.</p>
</td></tr>
<tr><td><code id="slim_+3A_alpha">alpha</code></td>
<td>
<p>(0 &lt;= alpha &lt;= 1) Parameter to decide the relative weightage
between the L1 and L2 penalities. See <a href="glmnet.html#topic+glmnet">glmnet</a> for more
details. This is set by default at <code>0.5</code>.</p>
</td></tr>
<tr><td><code id="slim_+3A_lambda">lambda</code></td>
<td>
<p>(positive real number) Parameter to control shrinkage of
coefficients. See <a href="glmnet.html#topic+glmnet">glmnet</a> for more details. Its advisable not
to provide the lambda value, as the function figures out the optimal value
by itself.</p>
</td></tr>
<tr><td><code id="slim_+3A_nlambda">nlambda</code></td>
<td>
<p>(positive integer) Maximum length of the lambda sequence. See
<a href="glmnet.html#topic+glmnet">glmnet</a> for more details. If <code>nlambda</code> argument is
missing, it will be set to 100L. This is overridden if <code>lambda</code> is
specified.</p>
</td></tr>
<tr><td><code id="slim_+3A_nonnegcoeff">nonNegCoeff</code></td>
<td>
<p>(flag) Whether the regression coefficients should be
non-negative. There are instances where setting to FALSE decreases the
RMSE, but sometimes this could lead to overfitting. Setting
<code>nonNegCoeff</code> is FALSE, helps interpreting coefficients in the case of
implicit feedback. This is set to TRUE by default.</p>
</td></tr>
<tr><td><code id="slim_+3A_directory">directory</code></td>
<td>
<p>(string) A writable directory where a sub-directory is
created at the run time and <code>bigmatrix</code> objects will be written to.
Predicted ratings data is stored in <code>ratingMat</code> file and the
description is written to <code>ratingMat.desc</code> file. If <code>coeffMat</code> is
TRUE, the coefficents matrix is stored in the file <code>coeffMat</code> and the
description is written to <code>coeffMat.desc</code> file. When directory
argument is missing, directory is set via <code>tempdir()</code>.</p>
</td></tr>
<tr><td><code id="slim_+3A_coeffmat">coeffMat</code></td>
<td>
<p>(flag) Whether coeffMat is to be computed. This can be later
used to predict recommendations for users not present in the <code>mat</code>
(although <code>slimrec</code> package does not provide a <code>predict function</code>
). Setting it TRUE increases the computation time. This is set to FALSE by
default.</p>
</td></tr>
<tr><td><code id="slim_+3A_returnmat">returnMat</code></td>
<td>
<p>(flag) Whether the predicted ratings matrix and coefficient
matrix (only if <code>coeffMat</code> is TRUE) to be read into memory as matrices
and delete on disk <code>bigmatrix</code> objects. When output matrices are
large, setting <code>returnMat</code> to TRUE is not advisable. This is set to
FALSE by default.</p>
</td></tr>
<tr><td><code id="slim_+3A_computermse">computeRMSE</code></td>
<td>
<p>(flag) Whether RMSE values have to be computed
corresponding to non-zero values of the <code>mat</code>, both overall and
columnwise.</p>
</td></tr>
<tr><td><code id="slim_+3A_nproc">nproc</code></td>
<td>
<p>(positive integer) Number of parallel processes to be used to
compute coefficients for items. If the machine has <code>k</code> (&gt;1) cores, the
function does not employ more than <code>k - 1</code> cores. This is set to 1L by
default.</p>
</td></tr>
<tr><td><code id="slim_+3A_progress">progress</code></td>
<td>
<p>(flag) If TRUE(default), shows a progress bar and expected
time. This is set to TRUE by default.</p>
</td></tr>
<tr><td><code id="slim_+3A_check">check</code></td>
<td>
<p>(flag) If TRUE(default), ckecks like whether the matrix is
sparse, matrix does not contains NAs, alpha lies between 0 and 1, directory
if specified is writable and so on. This is set to TRUE by default.</p>
</td></tr>
<tr><td><code id="slim_+3A_cleanup">cleanup</code></td>
<td>
<p>(flag) Whether to delete the sub-directory. Note that
<code>returnMat</code>  cannot be set to FALSE when <code>cleanup</code> is TRUE. This
is set to FALSE by default.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><strong>Sparse linear method</strong>
(<a href="http://glaros.dtc.umn.edu/gkhome/node/774">DOI:
10.1109/ICDM.2011.134</a>): The method predicts ratings of a user for a given
item as a linear combination ratings of all other items provided by the
user. The coefficients for an item are determined elastic-net regression
(both L1 and L2 regularization) over ratings matrix.
</p>
<p>The optimization problem solves:
</p>
<p style="text-align: center;"><code class="reqn">\min_{c_{j,.}} \frac{1}{2} \|a_{j,.} - Ac_{j,.}\|^2_{2} +
  \frac{\beta}{2} \|c_{j,.}\|^2_{2} + \gamma \|c_{j,.}\|_{1}</code>
</p>
<p> subject to
<code class="reqn">c_{j,j} = 0</code> and optional non-negative constraint <code class="reqn">c_{j,.} &gt;= 0</code>
where <code class="reqn">a_{j,.}</code> is the j th column of the input ratings matrix and
<code class="reqn">c_{j,.}</code> is the j th column of the coefficient matrix(to be
determined).
</p>
<p>The method assumes that unknown rating values to be zero. Hence, it is
primarily designed for implicit feeback mechanisms, but not restricted
them. The main use of the ratings is to generate top-n lists of users and
items.
</p>
<p><strong>Implementation</strong>: The non-negative ratings data is input as a sparse
matrix of class <code>dgCMatrix</code> without any <code>NA</code>. The items should
constitute columns and users should constitute rows. The elastic-net
regression problem is solved using <code>glmnet</code> package. The coefficients
for each item (a column of the ratings matrix) is computed, in parallel. To
avoid memory overload, the output(s) is written to a disk based bigmatrix
(using <code>bigmemory</code> package). The predicted rating matrix is the
primary output. It is possible to obtain the matrix of coefficients, which
will be helpful later to 'predict' the ratings for users not present in the
ratings matrix. The RMSE may be computed itemwise and for the entire
non-zero values of the ratings matrix. Since, <code>lambda</code> is
auto-adjusted, change in <code>alpha</code> might not have significant impact on
the RMSE. When it is necessary to get the best accuracy, there is a 'tune'
function to arrive at the optimal <code>alpha</code> value by cross-validation.
There are options to read the disk based matrix(s) into memory (as
matrices) and remove the disk based ones.
</p>


<h3>Value</h3>

<p>A list with these elements: </p>

<ul>
<li><p> ratingMat: If <code>returnMat</code> is TRUE, the predicted ratings matrix.
Else, <code>NULL</code>
</p>
</li>
<li><p> coeffMat: If <code>returnMat</code> is TRUE and <code>coeffMat</code> is TRUE,
the coefficient matrix. Else, <code>NULL</code>
</p>
</li>
<li><p> lambdas: When <code>lambda</code> is not specified, a vector(length of
number of columns of <code>mat</code>) of lambda values chosen. When
<code>lambda</code> is specified, it is singleton <code>lambda</code> value.
</p>
</li>
<li><p> columnwiseNonZeroRMSE: If <code>computeRMSE</code> is TRUE, vector of RMSE
for each column. The errors are computed over only non-zero values of the
column of <code>mat</code>. If <code>computeRMSE</code> is FALSE, value is set to
<code>NULL</code>.
</p>
</li>
<li><p> nonZeroRMSE: If <code>computeRMSE</code> is TRUE, RMSE value. The errors
are computed over only non-zero values of the <code>mat</code>. If
<code>computeRMSE</code> is FALSE, value is set to <code>NULL</code>.
</p>
</li>
<li><p> subdir: Path to the sub-directory where output are placed.
</p>
</li>
<li><p> call: function call
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>require("slimrec")
data(ft_small)
temp &lt;- slim(ft_small)
str(temp)

## Not run: 
temp &lt;- slim(mat           = ft_implicit # input sparse ratings matrix
             , alpha       = 0.5         # 0 for ridge, 1 for lasso
             #, lambda                   # suggested not to set lambda
             #, nlambda                  # using default nlambda = 100
             , nonNegCoeff = TRUE        # better accuracy, lower interpretability
             , directory   = td          # dir where output matrices are stored
             , coeffMat    = TRUE        # helpful in 'predict'ing later
             , returnMat   = TRUE        # return matrices in memory
             , computeRMSE = TRUE        # RMSE over rated items
             , nproc       = 2L          # number of concurrent processes
             , progress    = TRUE        # show a progressbar
             , check       = TRUE        # do basic checks on input params
             , cleanup     = FALSE       # keep output matrices on disk
             )
str(temp)
# output ratings matrix would be comparatively denser
predMat &lt;- temp[["ratingMat"]] != 0
sum(predMat)/((dim(predMat)[1])*(dim(predMat)[2]))
# recommend top 5 items for a user 10
top_cols(temp[["ratingMat"]]
         , row = 10
         , k   = 5
         )
# if you intend to avoid recommending 10, 215 and 3
top_cols(temp[["ratingMat"]]
         , row = 10
         , k   = 5
         , ignore = c(10, 215, 3)
         )

## End(Not run)

</code></pre>

<hr>
<h2 id='top_cols'>top_cols</h2><span id='topic+top_cols'></span>

<h3>Description</h3>

<p>Find the column numbers corresponding the largest values in a
particular row of a matrix
</p>


<h3>Usage</h3>

<pre><code class='language-R'>top_cols(mat, row, k = 5, ignore)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="top_cols_+3A_mat">mat</code></td>
<td>
<p>(Sparse matrix of class 'dgCmatrix' or a integer/numeric matrix or
'big.matrix') Rating matrix.</p>
</td></tr>
<tr><td><code id="top_cols_+3A_row">row</code></td>
<td>
<p>(positive integer) Row number in which top columns are to be
selected.</p>
</td></tr>
<tr><td><code id="top_cols_+3A_k">k</code></td>
<td>
<p>(positive integer) Number of column numbers to be recommended. This
might not be strictly adhered to, see Details.</p>
</td></tr>
<tr><td><code id="top_cols_+3A_ignore">ignore</code></td>
<td>
<p>(integer vector) Column numbers to be ignored.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>To find top-n recommendations of a ratings matrix given an item (or
a user).  Although k recommendations are expected to be returned, the
function might sometimes return more or less than k recommendations.
</p>
 <ul>
<li><p> Less: This happens when it is not possible to recommend k
elements. For example, k is larger than the number of elements. </p>
</li>
<li><p> More:
This happens when a few elements have same rating. The function returns the
index corresponding to all the elements which have the same rating. If
ratings were <code>3,2,2,2,3</code>: </p>
 <ul>
<li><p> k = 3: returns
<code>1, 5, 2, 3, 4</code> </p>
</li>
<li><p> k = 2: returns <code>1, 5</code> </p>
</li>
<li><p> k = 1: returns
<code>1, 5</code> </p>
</li></ul>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
temp &lt;- slim(mat           = ft_implicit # input sparse ratings matrix
             , alpha       = 0.5         # 0 for ridge, 1 for lasso
             #, lambda                   # suggested not to set lambda
             #, nlambda                  # using default nlambda = 100
             , nonNegCoeff = TRUE        # better accuracy, lower interpretability
             , directory   = td          # dir where output matrices are stored
             , coeffMat    = TRUE        # helpful in 'predict'ing later
             , returnMat   = TRUE        # return matrices in memory
             , computeRMSE = TRUE        # RMSE over rated items
             , nproc       = 2L          # number of concurrent processes
             , progress    = TRUE        # show a progressbar
             , check       = TRUE        # do basic checks on input params
             , cleanup     = FALSE       # keep output matrices on disk
             )
str(temp)
# output ratings matrix would be comparatively denser
predMat &lt;- temp[["ratingMat"]] != 0
sum(predMat)/((dim(predMat)[1])*(dim(predMat)[2]))
# recommend top 5 items for a user 10
top_cols(temp[["ratingMat"]]
         , row = 10
         , k   = 5
         )
# if you intend to avoid recommending 10, 215 and 3
top_cols(temp[["ratingMat"]]
         , row = 10
         , k   = 5
         , ignore = c(10, 215, 3)
         )

## End(Not run)

</code></pre>

<hr>
<h2 id='top_rows'>top_rows</h2><span id='topic+top_rows'></span>

<h3>Description</h3>

<p>Find the row numbers corresponding the largest values in a
particular column of a matrix
</p>


<h3>Usage</h3>

<pre><code class='language-R'>top_rows(mat, col, k = 5, ignore)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="top_rows_+3A_mat">mat</code></td>
<td>
<p>(Sparse matrix of class 'dgCmatrix' or a integer/numeric matrix or
'big.matrix') Rating matrix.</p>
</td></tr>
<tr><td><code id="top_rows_+3A_col">col</code></td>
<td>
<p>(positive integer) Column number in which top rows are to be
selected.</p>
</td></tr>
<tr><td><code id="top_rows_+3A_k">k</code></td>
<td>
<p>(positive integer) Number of row numbers to be recommended. This
might not be strictly adhered to, see Details.</p>
</td></tr>
<tr><td><code id="top_rows_+3A_ignore">ignore</code></td>
<td>
<p>(integer vector) Row numbers to be ignored.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>To find top-n recommendations of a ratings matrix given an item (or
a user).  Although k recommendations are expected to be returned, the
function might sometimes return more or less than k recommendations.
</p>
 <ul>
<li><p> Less: This happens when it is not possible to recommend k
elements. For example, k is larger than the number of elements. </p>
</li>
<li><p> More:
This happens when a few elements have same rating. The function returns the
index corresponding to all the elements which have the same rating. If
ratings were <code>3,2,2,2,3</code>: </p>
 <ul>
<li><p> k = 3: returns
<code>1, 5, 2, 3, 4</code> </p>
</li>
<li><p> k = 2: returns <code>1, 5</code> </p>
</li>
<li><p> k = 1: returns
<code>1, 5</code> </p>
</li></ul>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
temp &lt;- slim(mat           = ft_implicit # input sparse ratings matrix
             , alpha       = 0.5         # 0 for ridge, 1 for lasso
             #, lambda                   # suggested not to set lambda
             #, nlambda                  # using default nlambda = 100
             , nonNegCoeff = TRUE        # better accuracy, lower interpretability
             , directory   = td          # dir where output matrices are stored
             , coeffMat    = TRUE        # helpful in 'predict'ing later
             , returnMat   = TRUE        # return matrices in memory
             , computeRMSE = TRUE        # RMSE over rated items
             , nproc       = 2L          # number of concurrent processes
             , progress    = TRUE        # show a progressbar
             , check       = TRUE        # do basic checks on input params
             , cleanup     = FALSE       # keep output matrices on disk
             )
str(temp)
# output ratings matrix would be comparatively denser
predMat &lt;- temp[["ratingMat"]] != 0
sum(predMat)/((dim(predMat)[1])*(dim(predMat)[2]))
# recommend top 5 items for a user 10
top_cols(temp[["ratingMat"]]
         , row = 10
         , k   = 5
         )
# if you intend to avoid recommending 10, 215 and 3
top_cols(temp[["ratingMat"]]
         , row = 10
         , k   = 5
         , ignore = c(10, 215, 3)
         )

## End(Not run)

</code></pre>

<hr>
<h2 id='tune_slim'>tune_slim</h2><span id='topic+tune_slim'></span>

<h3>Description</h3>

<p>Arrive at an optimal value of <code>alpha</code> for
<code><a href="#topic+slim">slim</a></code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tune_slim(mat, alphaRange = seq(0, 1, 0.1), nonNegCoeff = TRUE,
  nfold = 5L, seed, directory, nproc = 1L, progress = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="tune_slim_+3A_mat">mat</code></td>
<td>
<p>(sparse matrix of class 'dgCMatrix') Rating matrix with items
along columns and users along rows.</p>
</td></tr>
<tr><td><code id="tune_slim_+3A_alpharange">alphaRange</code></td>
<td>
<p>(numeric vector) A vector of alpha values with 0 &lt;= alpha
&lt;= 1. Default is values 0 to 1, with a difference of 0.1.</p>
</td></tr>
<tr><td><code id="tune_slim_+3A_nonnegcoeff">nonNegCoeff</code></td>
<td>
<p>(flag) Whether the regression coefficients should be
non-negative. Default is TRUE.</p>
</td></tr>
<tr><td><code id="tune_slim_+3A_nfold">nfold</code></td>
<td>
<p>(positive integer) Number of folds for cross-validation. Only
values between(inclusive) 2 and 10 are allowed.</p>
</td></tr>
<tr><td><code id="tune_slim_+3A_seed">seed</code></td>
<td>
<p>(positive integer) Seed to be used to create folds for
cross-validation. If missing, a random integer is chosen. Setting this is
helpful for reproduciing the results. Default is 5.</p>
</td></tr>
<tr><td><code id="tune_slim_+3A_directory">directory</code></td>
<td>
<p>(string) A writable directory where a sub-directory is
created at the run time and <code>bigmatrix</code> objects will be written to.
The sub-directories are deleted at the end. If missing, this is set using
<code>tempdir()</code></p>
</td></tr>
<tr><td><code id="tune_slim_+3A_nproc">nproc</code></td>
<td>
<p>(positive integer) Number of parallel processes to be used to
compute coefficients for items. If the machine has <code>k</code> (&gt;1) cores, the
function does not employ more than <code>k - 1</code> cores. This is set to 1L by
default.</p>
</td></tr>
<tr><td><code id="tune_slim_+3A_progress">progress</code></td>
<td>
<p>(flag) If TRUE(default), shows a progress bar and expected
time. This is set to TRUE by default.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Runs <code>nfold</code> cross-validation to aid determining the optimal
value of <code>alpha</code>(see <code><a href="#topic+slim">slim</a></code> for details). The coefficient
matrix obtained from the training fold is used to predict ratings of the
validation fold. The RMSE is evaluated for non-zero ratings and averaged
over all the folds. Note that coefficient matrix is held in memory while
computing RMSE. <code><a href="#topic+slim">slim</a></code> adjusts <code>lambda</code> while fitting an
elastic-net, hence advantages in searching for optimal <code>alpha</code> might
be limited.
</p>


<h3>Value</h3>

<p>A dataframe with two columns: <code>alpha</code> and <code>error</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require("slimrec")
data(ft_small)
## Not run: 
temp &lt;- tune_slim(ft_small)
temp
temp &lt;- tune_slim(ft_small, alphaRange = c(0, 0.5, 1))
temp
temp &lt;- tune_slim(ft_small, alphaRange = c(0, 0.5, 1), nproc = 2)
temp
temp &lt;- tune_slim(ft_small, nonNegCoeff = FALSE)
temp

## End(Not run)

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
