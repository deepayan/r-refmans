<!DOCTYPE html><html lang="en"><head><title>Help for package bulkreadr</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {bulkreadr}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#bulkreadr-package'><p>bulkreadr: The Ultimate Tool for Reading Data in Bulk</p></a></li>
<li><a href='#+25+26gt+3B+25'><p>Pipe operator</p></a></li>
<li><a href='#convert_to_date'><p>User friendly date parsing function</p></a></li>
<li><a href='#fill_missing_values'><p>Fill missing values in a data frame</p></a></li>
<li><a href='#generate_dictionary'><p>Create a data dictionary from labelled data</p></a></li>
<li><a href='#inspect_na'><p>Summarize missingness in data frame columns</p></a></li>
<li><a href='#look_for'><p>Look for keywords variable names and descriptions in labelled data</p></a></li>
<li><a href='#pull_out'><p>Extract or replace parts of an object</p></a></li>
<li><a href='#read_csv_files_from_dir'><p>Reads all CSV files from a directory</p></a></li>
<li><a href='#read_excel_files_from_dir'><p>Read Excel Workbooks data from a directory</p></a></li>
<li><a href='#read_excel_workbook'><p>Import data from multiple sheets of an Excel workbook</p></a></li>
<li><a href='#read_gsheets'><p>Import data from multiple sheets in Google Sheets</p></a></li>
<li><a href='#read_spss_data'><p>Read SPSS data file</p></a></li>
<li><a href='#read_stata_data'><p>Read Stata data file</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Title:</td>
<td>The Ultimate Tool for Reading Data in Bulk</td>
</tr>
<tr>
<td>Version:</td>
<td>1.1.1</td>
</tr>
<tr>
<td>Description:</td>
<td>Designed to simplify and streamline the process of reading
    and processing large volumes of data in R, this package offers a
    collection of functions tailored for bulk data operations. It enables
    users to efficiently read multiple sheets from Microsoft Excel and
    Google Sheets workbooks, as well as various CSV files from a
    directory. The data is returned as organized data frames, facilitating
    further analysis and manipulation. Ideal for handling extensive data
    sets or batch processing tasks, bulkreadr empowers users to manage
    data in bulk effortlessly, saving time and effort in data preparation
    workflows. Additionally, the package seamlessly works with labelled
    data from SPSS and Stata.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/gbganalyst/bulkreadr">https://github.com/gbganalyst/bulkreadr</a>,
<a href="https://gbganalyst.github.io/bulkreadr/">https://gbganalyst.github.io/bulkreadr/</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/gbganalyst/bulkreadr/issues">https://github.com/gbganalyst/bulkreadr/issues</a></td>
</tr>
<tr>
<td>Depends:</td>
<td>purrr</td>
</tr>
<tr>
<td>Imports:</td>
<td>curl, dplyr, fs, googlesheets4, haven, inspectdf, labelled,
lubridate, magrittr, methods, openxlsx, readr, readxl, rlang,
sjlabelled, stats, stringr, tibble, tidyr</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, googledrive, rmarkdown, testthat (&ge; 3.0.0)</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.1</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-05-26 20:20:21 UTC; ezekiel.ogundepo</td>
</tr>
<tr>
<td>Author:</td>
<td>Ezekiel Ogundepo <a href="https://orcid.org/0000-0003-3974-2733"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cre],
  Ernest Fokoue <a href="https://orcid.org/0000-0002-0748-9166"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [ctb],
  Golibe Ezeechesi [ctb],
  Fatimo Adebanjo [ctb],
  Isaac Ajao [ctb]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Ezekiel Ogundepo &lt;gbganalyst@gmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-05-26 20:40:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='bulkreadr-package'>bulkreadr: The Ultimate Tool for Reading Data in Bulk</h2><span id='topic+bulkreadr'></span><span id='topic+bulkreadr-package'></span>

<h3>Description</h3>

<p><img src="../help/figures/logo.png" style='float: right' alt='logo' width='120' />
</p>
<p>Designed to simplify and streamline the process of reading and processing large volumes of data in R, this package offers a collection of functions tailored for bulk data operations. It enables users to efficiently read multiple sheets from Microsoft Excel and Google Sheets workbooks, as well as various CSV files from a directory. The data is returned as organized data frames, facilitating further analysis and manipulation. Ideal for handling extensive data sets or batch processing tasks, bulkreadr empowers users to manage data in bulk effortlessly, saving time and effort in data preparation workflows. Additionally, the package seamlessly works with labelled data from SPSS and Stata.
</p>


<h3>Author(s)</h3>

<p><strong>Maintainer</strong>: Ezekiel Ogundepo <a href="mailto:gbganalyst@gmail.com">gbganalyst@gmail.com</a> (<a href="https://orcid.org/0000-0003-3974-2733">ORCID</a>)
</p>
<p>Other contributors:
</p>

<ul>
<li><p> Ernest Fokoue <a href="mailto:epfeqa@rit.edu">epfeqa@rit.edu</a> (<a href="https://orcid.org/0000-0002-0748-9166">ORCID</a>) [contributor]
</p>
</li>
<li><p> Golibe Ezeechesi <a href="mailto:golibe.ezeechesi@gmail.com">golibe.ezeechesi@gmail.com</a> [contributor]
</p>
</li>
<li><p> Fatimo Adebanjo <a href="mailto:adebanjofatimo2000@gmail.com">adebanjofatimo2000@gmail.com</a> [contributor]
</p>
</li>
<li><p> Isaac Ajao <a href="mailto:isaacoluwaseyiajao@gmail.com">isaacoluwaseyiajao@gmail.com</a> [contributor]
</p>
</li></ul>



<h3>See Also</h3>

<p>Useful links:
</p>

<ul>
<li> <p><a href="https://github.com/gbganalyst/bulkreadr">https://github.com/gbganalyst/bulkreadr</a>
</p>
</li>
<li> <p><a href="https://gbganalyst.github.io/bulkreadr/">https://gbganalyst.github.io/bulkreadr/</a>
</p>
</li>
<li><p> Report bugs at <a href="https://github.com/gbganalyst/bulkreadr/issues">https://github.com/gbganalyst/bulkreadr/issues</a>
</p>
</li></ul>


<hr>
<h2 id='+25+26gt+3B+25'>Pipe operator</h2><span id='topic++25+3E+25'></span>

<h3>Description</h3>

<p>See <code>magrittr::<a href="magrittr.html#topic+pipe">%&gt;%</a></code> for details.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lhs %&gt;% rhs
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="+2B25+2B26gt+2B3B+2B25_+3A_lhs">lhs</code></td>
<td>
<p>A value or the magrittr placeholder.</p>
</td></tr>
<tr><td><code id="+2B25+2B26gt+2B3B+2B25_+3A_rhs">rhs</code></td>
<td>
<p>A function call using the magrittr semantics.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The result of calling <code>rhs(lhs)</code>.
</p>

<hr>
<h2 id='convert_to_date'>User friendly date parsing function</h2><span id='topic+convert_to_date'></span>

<h3>Description</h3>

<p><code>convert_to_date()</code> parses an input vector into POSIXct date object. It is also powerful to convert from excel date number like <code>42370</code> into date value like <code>2016-01-01</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>convert_to_date(date_num_char, tz = "UTC")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="convert_to_date_+3A_date_num_char">date_num_char</code></td>
<td>
<p>A character or numeric vector of dates</p>
</td></tr>
<tr><td><code id="convert_to_date_+3A_tz">tz</code></td>
<td>
<p>Time zone indicator. If <code>NULL</code> (default), a Date object is
returned. Otherwise a POSIXct with time zone attribute set to <code>tz</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a vector of class Date
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## ** heterogeneous dates **

dates &lt;- c(
  44869, "22.09.2022", NA, "02/27/92", "01-19-2022",
  "13-01-  2022", "2023", "2023-2", 41750.2, 41751.99,
  "11 07 2023", "2023-4"
)

convert_to_date(dates)

</code></pre>

<hr>
<h2 id='fill_missing_values'>Fill missing values in a data frame</h2><span id='topic+fill_missing_values'></span>

<h3>Description</h3>

<p><code>fill_missing_values()</code> is an efficient function that addresses missing
values in a data frame. It uses imputation by function, also known as
column-based imputation, to impute the missing values. For continuous
variables, it supports various methods of imputation, including minimum,
maximum, mean, median, harmonic mean, and geometric mean. For categorical
variables, missing values are replaced with the mode of the column. This
approach ensures accurate and consistent replacements derived from individual
columns, resulting in a complete and reliable dataset for improved analysis
and decision-making.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fill_missing_values(
  df,
  selected_variables = NULL,
  method = c("mean", "min", "max", "median", "harmonic", "geometric")
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fill_missing_values_+3A_df">df</code></td>
<td>
<p>A dataframe to process for missing value imputation.</p>
</td></tr>
<tr><td><code id="fill_missing_values_+3A_selected_variables">selected_variables</code></td>
<td>
<p>An optional character vector of variable names within <code>df</code>
for which missing values should be imputed. If <code>NULL</code> (default), imputation
is applied to all variables in the data frame.</p>
</td></tr>
<tr><td><code id="fill_missing_values_+3A_method">method</code></td>
<td>
<p>A character string specifying the imputation method for
continuous variables. Supported methods are <code>"min"</code>, <code>"max"</code>, <code>"mean"</code>,
<code>"median"</code>, <code>"harmonic"</code>, and <code>"geometric"</code>. The default method is <code>"mean"</code>.
For categorical variables, the <code>mode</code> is always used.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame with missing values imputed according to the specified
<code>method</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(dplyr)

# Assuming 'df' is the dataframe you want to process

df &lt;- tibble::tibble(
Sepal_Length = c(5.2, 5, 5.7, NA, 6.2, 6.7, 5.5),
Petal_Length = c(1.5, 1.4, 4.2, 1.4, NA, 5.8, 3.7),
Petal_Width = c(NA, 0.2, 1.2, 0.2, 1.3, 1.8, NA),
Species = c("setosa", NA, "versicolor", "setosa",
           NA, "virginica", "setosa")
)

# If you do not specify `selected_variables` (i.e., leave it as `NULL`),
# the function will impute missing values for all columns in the dataframe.

result_df_mean &lt;- fill_missing_values(df, method = "mean")

result_df_mean

# If you specify column names, only those columns will be imputed. For
# example, impute for variables `Petal_Length` and `Petal_Width` using
# the geometric mean.

result_df_geomean &lt;- fill_missing_values(df, selected_variables = c
("Petal_Length", "Petal_Width"), method = "geometric")

result_df_geomean

# If you specify column positions, only the columns at those positions will #' # be imputed.

result_df_max &lt;- fill_missing_values(df, selected_variables = c
(2, 3), method = "max")

result_df_max

# Impute missing values (NAs) in a grouped data frame

# You can do that by using the following:

sample_iris &lt;- tibble::tibble(
Sepal_Length = c(5.2, 5, 5.7, NA, 6.2, 6.7, 5.5),
Petal_Length = c(1.5, 1.4, 4.2, 1.4, NA, 5.8, 3.7),
Petal_Width = c(0.3, 0.2, 1.2, 0.2, 1.3, 1.8, NA),
Species = c("setosa", "setosa", "versicolor", "setosa",
           "virginica", "virginica", "setosa")
)

sample_iris %&gt;%
group_by(Species) %&gt;%
group_split() %&gt;%
map_df(fill_missing_values, method = "median")


</code></pre>

<hr>
<h2 id='generate_dictionary'>Create a data dictionary from labelled data</h2><span id='topic+generate_dictionary'></span>

<h3>Description</h3>

<p><code>generate_dictionary()</code> creates a data dictionary from a specified data frame.
This function is particularly useful for understanding and documenting the
structure of your dataset, similar to data dictionaries in Stata or SPSS.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>generate_dictionary(data)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="generate_dictionary_+3A_data">data</code></td>
<td>
<p>a data frame or a survey object</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function returns a tibble (a modern version of R's data frame) with the following columns:
</p>

<ul>
<li> <p><strong>position</strong>: An integer vector indicating the column position in the data frame.
</p>
</li>
<li> <p><strong>variable</strong>: A character vector containing the names of the variables (columns).
</p>
</li>
<li> <p><strong>description</strong>: A character vector with a human-readable description of each variable.
</p>
</li>
<li> <p><strong>column type</strong>: A character vector specifying the data type (e.g., numeric, character) of each variable.
</p>
</li>
<li> <p><strong>missing</strong>: An integer vector indicating the count of missing values for each variable.
</p>
</li>
<li> <p><strong>levels</strong>: A list vector containing the levels for categorical variables, if applicable.
</p>
</li></ul>



<h3>Value</h3>

<p>A tibble representing the data dictionary. Each row corresponds to a variable in the original
data frame, providing detailed information about the variable's characteristics.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Creating a data dictionary from an SPSS file

file_path &lt;- system.file("extdata", "Wages.sav", package = "bulkreadr")

wage_data &lt;- read_spss_data(file = file_path)

generate_dictionary(wage_data)


</code></pre>

<hr>
<h2 id='inspect_na'>Summarize missingness in data frame columns</h2><span id='topic+inspect_na'></span>

<h3>Description</h3>

<p><code>inspect_na()</code> summarizes the rate of missingness in each column of a data frame. For a grouped data frame, the rate of missingness is summarized separately for each group.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>inspect_na(df)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="inspect_na_+3A_df">df</code></td>
<td>
<p>A data frame</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The tibble returned contains the columns:
</p>

<ul>
<li> <p><strong>col_name</strong>, a character vector containing column names of df1.
</p>
</li>
<li> <p><strong>cnt</strong>, an integer vector containing the number of missing values by column.
</p>
</li>
<li> <p><strong>pcnt</strong>, the percentage of records in each columns that is missing.
</p>
</li></ul>



<h3>Value</h3>

<p>A tibble summarizing the count and percentage of columnwise missingness for a data frame.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(dplyr)

# dataframe summary

inspect_na(airquality)

# grouped dataframe summary

airquality %&gt;%
group_by(Month) %&gt;%
 inspect_na()

</code></pre>

<hr>
<h2 id='look_for'>Look for keywords variable names and descriptions in labelled data</h2><span id='topic+look_for'></span>

<h3>Description</h3>

<p>The <code>look_for()</code> function is designed to emulate the functionality of the Stata <code>lookfor</code> command in R. It provides a powerful tool for searching through large datasets, specifically targeting variable names, variable label descriptions, factor levels, and value labels. This function is handy for users working with extensive and complex datasets, enabling them to quickly and efficiently locate the variables of interest.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>look_for(
  data,
  ...,
  labels = TRUE,
  values = TRUE,
  ignore.case = TRUE,
  details = c("basic", "none", "full")
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="look_for_+3A_data">data</code></td>
<td>
<p>a data frame or a survey object</p>
</td></tr>
<tr><td><code id="look_for_+3A_...">...</code></td>
<td>
<p>optional list of keywords, a character string (or several
character strings), which can be formatted as a regular expression suitable
for a <code><a href="base.html#topic+grep">base::grep()</a></code> pattern, or a vector of keywords;
displays all variables if not specified</p>
</td></tr>
<tr><td><code id="look_for_+3A_labels">labels</code></td>
<td>
<p>whether or not to search variable labels (descriptions);
<code>TRUE</code> by default</p>
</td></tr>
<tr><td><code id="look_for_+3A_values">values</code></td>
<td>
<p>whether or not to search within values (factor levels or value
labels); <code>TRUE</code> by default</p>
</td></tr>
<tr><td><code id="look_for_+3A_ignore.case">ignore.case</code></td>
<td>
<p>whether or not to make the keywords case sensitive;
<code>TRUE</code> by default (case is ignored during matching)</p>
</td></tr>
<tr><td><code id="look_for_+3A_details">details</code></td>
<td>
<p>add details about each variable (full details could be time
consuming for big data frames, <code>FALSE</code> is equivalent to <code>"none"</code>
and <code>TRUE</code> to <code>"full"</code>)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tibble data frame featuring the variable position, name and description (if it exists) in the original data frame.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
look_for(iris)

# Look for a single keyword.

look_for(iris, "petal")

look_for(iris, "s")

</code></pre>

<hr>
<h2 id='pull_out'>Extract or replace parts of an object</h2><span id='topic+pull_out'></span>

<h3>Description</h3>

<p><code>pull_out()</code> is similar to <code>[</code>. It acts on vectors, matrices, arrays and lists to extract or replace parts. It is pleasant to use with the magrittr (<code style="white-space: pre;">&#8288;%&gt;%&#8288;</code>) and base (<code style="white-space: pre;">&#8288;|&gt;&#8288;</code>) operators.
</p>


<h3>Value</h3>

<p><code>pull_out()</code> will return an object of the same class as the input object.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
good_choice &lt;- letters %&gt;%
  pull_out(c(5, 2, 1, 4))

good_choice

iris %&gt;%
  pull_out(, 1:4) %&gt;%
  head()

</code></pre>

<hr>
<h2 id='read_csv_files_from_dir'>Reads all CSV files from a directory</h2><span id='topic+read_csv_files_from_dir'></span>

<h3>Description</h3>

<p><code>read_csv_files_from_dir</code> reads all csv files from the <code>"~/data"</code> directory and returns an appended dataframe. The resulting dataframe will be in the same order as the CSV files in the directory.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>read_csv_files_from_dir(dir_path = ".", col_types = NULL, .id = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="read_csv_files_from_dir_+3A_dir_path">dir_path</code></td>
<td>
<p>Path to the directory containing the CSV files.</p>
</td></tr>
<tr><td><code id="read_csv_files_from_dir_+3A_col_types">col_types</code></td>
<td>
<p>One of <code>NULL</code>, a <code><a href="readr.html#topic+cols">cols()</a></code> specification, or
a string. See <code>vignette("readr")</code> for more details.
</p>
<p>If <code>NULL</code>, all column types will be inferred from <code>guess_max</code> rows of the
input, interspersed throughout the file. This is convenient (and fast),
but not robust. If the guessed types are wrong, you'll need to increase
<code>guess_max</code> or supply the correct types yourself.
</p>
<p>Column specifications created by <code><a href="base.html#topic+list">list()</a></code> or <code><a href="readr.html#topic+cols">cols()</a></code> must contain
one column specification for each column. If you only want to read a
subset of the columns, use <code><a href="readr.html#topic+cols_only">cols_only()</a></code>.
</p>
<p>Alternatively, you can use a compact string representation where each
character represents one column:
</p>

<ul>
<li><p> c = character
</p>
</li>
<li><p> i = integer
</p>
</li>
<li><p> n = number
</p>
</li>
<li><p> d = double
</p>
</li>
<li><p> l = logical
</p>
</li>
<li><p> f = factor
</p>
</li>
<li><p> D = date
</p>
</li>
<li><p> T = date time
</p>
</li>
<li><p> t = time
</p>
</li>
<li><p> ? = guess
</p>
</li>
<li><p> _ or - = skip
</p>
</li></ul>

<p>By default, reading a file without a column specification will print a
message showing what <code>readr</code> guessed they were. To remove this message,
set <code>show_col_types = FALSE</code> or set <code>options(readr.show_col_types = FALSE)</code>.</p>
</td></tr>
<tr><td><code id="read_csv_files_from_dir_+3A_.id">.id</code></td>
<td>
<p>The name of a column in which to store the file path. This is
useful when reading multiple input files and there is data in the file
paths, such as the data collection date. If <code>NULL</code> (the default) no extra
column is created.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <a href="tibble.html#topic+tibble-package">tibble</a>. If there is any column type mismatch during data frames row binding, an error will occur. This is because R cannot combine columns of different types. For example, you cannot combine a column of integers with a column of characters.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+read_excel_files_from_dir">read_excel_files_from_dir()</a></code> which reads Excel workbooks data from a directory.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
directory &lt;- system.file("csvfolder",  package = "bulkreadr")

read_csv_files_from_dir(dir_path = directory, .id = "cut")

# Column types mismatch error --------------------------------------
# If the `read_csv_files_from_dir()` function complains about a data type mismatch,
# then set the `col_types` argument to `"c"`.
# This will make all the column types in the resulting dataframe be characters.


</code></pre>

<hr>
<h2 id='read_excel_files_from_dir'>Read Excel Workbooks data from a directory</h2><span id='topic+read_excel_files_from_dir'></span>

<h3>Description</h3>

<p><code>read_excel_files_from_dir()</code> reads all Excel workbooks in the <code>"~/data"</code> directory and returns an appended dataframe.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>read_excel_files_from_dir(dir_path, col_types = NULL, .id = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="read_excel_files_from_dir_+3A_dir_path">dir_path</code></td>
<td>
<p>Path to the directory containing the <code>xls</code>/<code>xlsx</code> files.</p>
</td></tr>
<tr><td><code id="read_excel_files_from_dir_+3A_col_types">col_types</code></td>
<td>
<p>Either <code>NULL</code> to guess all from the spreadsheet or a
character vector containing one entry per column from these options:
&quot;skip&quot;, &quot;guess&quot;, &quot;logical&quot;, &quot;numeric&quot;, &quot;date&quot;, &quot;text&quot; or &quot;list&quot;. If exactly
one <code>col_type</code> is specified, it will be recycled. The content of a cell in
a skipped column is never read and that column will not appear in the data
frame output. A list cell loads a column as a list of length 1 vectors,
which are typed using the type guessing logic from <code>col_types = NULL</code>, but
on a cell-by-cell basis.</p>
</td></tr>
<tr><td><code id="read_excel_files_from_dir_+3A_.id">.id</code></td>
<td>
<p>The name of an optional identifier column. Provide a string to
create an output column that identifies each input. The column will use
names if available, otherwise it will use positions.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <a href="tibble.html#topic+tibble-package">tibble</a>. If there is any column type mismatch during data frames row binding, an error will occur. This is because R cannot combine columns of different types. For example, you cannot combine a column of integers with a column of characters.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+read_excel_workbook">read_excel_workbook()</a></code> which imports data from multiple sheets of an Excel workbook
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
directory &lt;- system.file("xlsxfolder",  package = "bulkreadr")

read_excel_files_from_dir(dir_path = directory, .id = "cut")

# Column types mismatch error --------------------------------------
# If the `read_excel_files_from_dir()` function complains about a data type mismatch,
# then set the `col_types` argument to `"text"`.
# This will make all the column types in the resulting dataframe be characters.


</code></pre>

<hr>
<h2 id='read_excel_workbook'>Import data from multiple sheets of an Excel workbook</h2><span id='topic+read_excel_workbook'></span>

<h3>Description</h3>

<p><code>read_excel_workbook()</code> reads all the data from the sheets of an Excel workbook and return an appended dataframe.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>read_excel_workbook(path, col_types = NULL, .id = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="read_excel_workbook_+3A_path">path</code></td>
<td>
<p>Path to the xls/xlsx file.</p>
</td></tr>
<tr><td><code id="read_excel_workbook_+3A_col_types">col_types</code></td>
<td>
<p>Either <code>NULL</code> to guess all from the spreadsheet or a
character vector containing one entry per column from these options:
&quot;skip&quot;, &quot;guess&quot;, &quot;logical&quot;, &quot;numeric&quot;, &quot;date&quot;, &quot;text&quot; or &quot;list&quot;. If exactly
one <code>col_type</code> is specified, it will be recycled. The content of a cell in
a skipped column is never read and that column will not appear in the data
frame output. A list cell loads a column as a list of length 1 vectors,
which are typed using the type guessing logic from <code>col_types = NULL</code>, but
on a cell-by-cell basis.</p>
</td></tr>
<tr><td><code id="read_excel_workbook_+3A_.id">.id</code></td>
<td>
<p>The name of an optional identifier column. Provide a string to
create an output column that identifies each input. The column will use
names if available, otherwise it will use positions.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <a href="tibble.html#topic+tibble-package">tibble</a>. If there is any column type mismatch during data frames row binding, an error will occur. This is because R cannot combine columns of different types. For example, you cannot combine a column of integers with a column of characters.
</p>


<h3>See Also</h3>

<p><code>read_excel()</code>, which reads a Sheet of an Excel file into a data frame, and <code><a href="#topic+read_gsheets">read_gsheets()</a></code>, which imports data from multiple sheets in a Google Sheets.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
path &lt;- system.file("extdata", "Diamonds.xlsx", package = "bulkreadr", mustWork = TRUE)

read_excel_workbook(path = path, .id = "Year")


# Column types mismatch error --------------------------------------
# If the `read_excel_workbook()` function complains about a data type mismatch,
# then set the `col_types` argument to `"text"`.
# This will make all the column types in the resulting DataFrame be characters.

</code></pre>

<hr>
<h2 id='read_gsheets'>Import data from multiple sheets in Google Sheets</h2><span id='topic+read_gsheets'></span>

<h3>Description</h3>

<p>The <code>read_gsheets()</code> function imports data from multiple sheets in a Google Sheets spreadsheet and appends the resulting dataframes from each sheet together to create a single dataframe. This function is a powerful tool for data analysis, as it allows you to easily combine data from multiple sheets into a single dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>read_gsheets(ss, col_types = NULL, .id = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="read_gsheets_+3A_ss">ss</code></td>
<td>
<p>Something that identifies a Google Sheet:
</p>

<ul>
<li><p> its file id as a string or <code><a href="googledrive.html#topic+drive_id">drive_id</a></code>
</p>
</li>
<li><p> a URL from which we can recover the id
</p>
</li>
<li><p> a one-row <code><a href="googledrive.html#topic+dribble">dribble</a></code>, which is how googledrive
represents Drive files
</p>
</li>
<li><p> an instance of <code>googlesheets4_spreadsheet</code>, which is what <code><a href="googlesheets4.html#topic+gs4_get">gs4_get()</a></code>
returns
</p>
</li></ul>

<p>Processed through <code><a href="googlesheets4.html#topic+as_sheets_id">as_sheets_id()</a></code>.</p>
</td></tr>
<tr><td><code id="read_gsheets_+3A_col_types">col_types</code></td>
<td>
<p>Column types. Either <code>NULL</code> to guess all from the
spreadsheet or a string of readr-style shortcodes, with one character or
code per column. If exactly one <code>col_type</code> is specified, it is recycled.
See Column Specification for more.</p>
</td></tr>
<tr><td><code id="read_gsheets_+3A_.id">.id</code></td>
<td>
<p>The name of an optional identifier column. Provide a string to
create an output column that identifies each input. The column will use
names if available, otherwise it will use positions.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <a href="tibble.html#topic+tibble-package">tibble</a>. If there is any column type mismatch during data frames row binding, an error will occur. This is because R cannot combine columns of different types. For example, you cannot combine a column of integers with a column of characters.
</p>


<h3>See Also</h3>

<p><code>read_sheet()</code> which reads a Google (spread)Sheet into a data frame.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

sheet_id &lt;- "1izO0mHu3L9AMySQUXGDn9GPs1n-VwGFSEoAKGhqVQh0"

read_gsheets(ss = sheet_id, .id = "sheet.name")

# Column types mismatch error --------------------------------------
# If the `read_gsheets()` function complains about a data type mismatch,
# then set the `col_types` argument to `"c"`.
# This will make all the column types in the resulting dataframe be characters.

# For example,


sheet_id &lt;- "1rrjKAV05POre9lDVtHtZePTa8VROf1onVO47cHnhrTU"

try(read_gsheets(ss = sheet_id)) # error, column types mismatch

read_gsheets(ss = sheet_id, col_types = "c")


</code></pre>

<hr>
<h2 id='read_spss_data'>Read SPSS data file</h2><span id='topic+read_spss_data'></span>

<h3>Description</h3>

<p><code>read_spss_data()</code> is designed to seamlessly import data from an SPSS data (<code>.sav</code> or  <code>.zsav</code>) files. It converts labelled variables into factors, a crucial step that enhances the ease of data manipulation and analysis within the R programming environment.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>read_spss_data(file, label = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="read_spss_data_+3A_file">file</code></td>
<td>
<p>The path to the SPSS data file.</p>
</td></tr>
<tr><td><code id="read_spss_data_+3A_label">label</code></td>
<td>
<p>Logical indicating whether to use variable labels as column names (default is FALSE).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tibble containing the data from the SPSS file.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+read_stata_data">read_stata_data()</a></code> which reads Stata data file and converts labelled variables into factors.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Read an SPSS data file without converting variable labels as column names

file_path &lt;- system.file("extdata", "Wages.sav", package = "bulkreadr")

data &lt;- read_spss_data(file = file_path)

data

# Read an SPSS data file and convert variable labels as column names

data &lt;- read_spss_data(file = file_path, label = TRUE)

data

</code></pre>

<hr>
<h2 id='read_stata_data'>Read Stata data file</h2><span id='topic+read_stata_data'></span>

<h3>Description</h3>

<p>Read Stata data file
</p>


<h3>Usage</h3>

<pre><code class='language-R'>read_stata_data(file, label = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="read_stata_data_+3A_file">file</code></td>
<td>
<p>The path to the Stata data file.</p>
</td></tr>
<tr><td><code id="read_stata_data_+3A_label">label</code></td>
<td>
<p>Logical indicating whether to use variable labels as column names (default is FALSE).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame containing the Stata data, with labeled variables converted to factors.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+read_spss_data">read_spss_data()</a></code> which reads SPSS data file and converts labelled variables into factors.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Read Stata data file without converting variable labels as column names

file_path &lt;- system.file("extdata", "Wages.dta", package = "bulkreadr")

data &lt;- read_stata_data(file = file_path)

data

# Read Stata data file and convert variable labels as column names

data &lt;- read_stata_data(file = file_path, label = TRUE)

data

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
