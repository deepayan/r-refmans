<!DOCTYPE html><html><head><title>Help for package MBESS</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {MBESS}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#aipe.smd'><p>Sample size planning for the standardized mean different from the accuracy</p>
in parameter estimation approach</a></li>
<li><a href='#ancova.random.data'><p> Generate random data for an ANCOVA model</p></a></li>
<li><a href='#CFA.1'><p> One-factor confirmatory factor analysis model</p></a></li>
<li><a href='#ci.c'><p> Confidence interval for a contrast in a fixed effects ANOVA</p></a></li>
<li><a href='#ci.c.ancova'><p> Confidence interval for an (unstandardized) contrast in ANCOVA with one covariate</p></a></li>
<li><a href='#ci.cc'>
<p>Confidence interval for the population correlation coefficient</p></a></li>
<li><a href='#ci.cv'><p>Confidence interval for the coefficient of variation</p></a></li>
<li><a href='#ci.omega2'>
<p>Confidence Interval for omega-squared (<code class="reqn">\omega^2</code>) for between-subject fixed-effects ANOVA and ANCOVA designs (and partial omega-squared <code class="reqn">\omega^2_p</code> for between-subject multifactor ANOVA and ANCOVA designs)</p></a></li>
<li><a href='#ci.pvaf'><p>Confidence Interval for the Proportion of Variance Accounted for (in the dependent variable by knowing the levels of the factor)</p></a></li>
<li><a href='#ci.R'><p> Confidence interval for the multiple correlation coefficient</p></a></li>
<li><a href='#ci.R2'><p>Confidence interval for the population squared multiple correlation coefficient</p></a></li>
<li><a href='#ci.rc'><p> Confidence Interval for a Regression Coefficient</p></a></li>
<li><a href='#ci.reg.coef'><p>Confidence interval for a regression coefficient</p></a></li>
<li><a href='#ci.reliability'><p>Confidence Interval for a Reliability Coefficient</p></a></li>
<li><a href='#ci.rmsea'><p>Confidence interval for the population root mean square error of approximation</p></a></li>
<li><a href='#ci.sc'><p> Confidence Interval for a Standardized Contrast in a Fixed Effects ANOVA</p></a></li>
<li><a href='#ci.sc.ancova'><p> Confidence interval for a standardized contrast in ANCOVA with one covariate</p></a></li>
<li><a href='#ci.sm'><p> Confidence Interval for the Standardized Mean</p></a></li>
<li><a href='#ci.smd'><p>Confidence limits for the standardized mean difference.</p></a></li>
<li><a href='#ci.smd.c'><p>Confidence limits for the standardized mean difference using the control</p>
group standard deviation as the divisor.</a></li>
<li><a href='#ci.snr'><p> Confidence Interval for the Signal-To-Noise Ratio</p></a></li>
<li><a href='#ci.src'><p> Confidence Interval for a Standardized Regression Coefficient</p></a></li>
<li><a href='#ci.srsnr'><p> Confidence Interval for the Square Root of the Signal-To-Noise Ratio</p></a></li>
<li><a href='#conf.limits.nc.chisq'><p>Confidence limits for noncentral chi square parameters</p></a></li>
<li><a href='#conf.limits.ncf'><p>Confidence limits for noncentral F parameters</p></a></li>
<li><a href='#conf.limits.nct'><p>Confidence limits for a noncentrality parameter from a t-distribution</p></a></li>
<li><a href='#Cor.Mat.Lomax'><p> Correlation matrix for Lomax (1983) data set</p></a></li>
<li><a href='#Cor.Mat.MM'><p> Correlation matrix for Maruyama &amp; McGarvey (1980) data set</p></a></li>
<li><a href='#cor2cov'><p> Correlation Matrix to Covariance Matrix Conversion</p></a></li>
<li><a href='#covmat.from.cfm'><p> Covariance matrix from confirmatory (single) factor model.</p></a></li>
<li><a href='#cv'><p>Function to calculate the regular (which is also biased) estimate of the coefficient of variation or the unbiased estimate of the coefficient of variation.</p></a></li>
<li><a href='#Expected.R2'><p>Expected value of the squared multiple correlation coefficient</p></a></li>
<li><a href='#F.and.R2.Noncentral.Conversion'><p>Conversion functions from noncentral noncentral values to their corresponding</p>
and vice versa, for those related to the F-test and R Square.</a></li>
<li><a href='#Gardner.LD'><p>The Gardner learning data, which was used by L.R. Tucker</p></a></li>
<li><a href='#HS'><p> Complete Data Set of Holzinger and Swineford's (1939) Study</p></a></li>
<li><a href='#intr.plot'><p>  Regression Surface Containing Interaction</p></a></li>
<li><a href='#intr.plot.2d'><p>Plotting Conditional Regression Lines with Interactions in Two Dimensions</p></a></li>
<li><a href='#MBESS'><p>MBESS</p></a></li>
<li><a href='#mediation'><p> Effect sizes and confidence intervals in a mediation model</p></a></li>
<li><a href='#mediation.effect.bar.plot'><p> Bar plots of mediation effects</p></a></li>
<li><a href='#mediation.effect.plot'><p> Visualizing mediation effects</p></a></li>
<li><a href='#mr.cv'>
<p>Minimum risk point estimation of the population coefficient of variation</p></a></li>
<li><a href='#mr.smd'>
<p>Minimum risk point estimation of the population standardized mean difference</p></a></li>
<li><a href='#power.density.equivalence.md'><p> Density for power of two one-sided tests procedure (TOST) for equivalence</p></a></li>
<li><a href='#power.equivalence.md'><p> Power of Two One-Sided Tests Procedure (TOST) for Equivalence</p></a></li>
<li><a href='#power.equivalence.md.plot'><p> Plot power of Two One-Sided Tests Procedure (TOST) for Equivalence</p></a></li>
<li><a href='#prof.salary'><p>Cohen et. al. (2003)'s professor salary data set</p></a></li>
<li><a href='#s.u'><p>Unbiased estimate of the population standard deviation</p></a></li>
<li><a href='#Sigma.2.SigmaStar'><p>Construct a covariance matrix with specified error of approximation</p></a></li>
<li><a href='#signal.to.noise.R2'><p>Signal to noise using squared multiple correlation coefficient</p></a></li>
<li><a href='#smd'><p>Standardized mean difference</p></a></li>
<li><a href='#smd.c'><p>Standardized mean difference using the control group as the basis of</p>
standardization</a></li>
<li><a href='#ss.aipe.c'><p>Sample size planning for an ANOVA contrast from the Accuracy in Parameter Estimation (AIPE) perspective</p></a></li>
<li><a href='#ss.aipe.c.ancova'><p> Sample size planning for a contrast in randomized ANCOVA from the Accuracy in Parameter Estimation (AIPE) perspective</p></a></li>
<li><a href='#ss.aipe.c.ancova.sensitivity'><p>Sensitivity analysis for sample size planning for the (unstandardized) contrast in randomized ANCOVA</p>
from the Accuracy in Parameter Estimation (AIPE) Perspective</a></li>
<li><a href='#ss.aipe.crd'>
<p>Find target sample sizes for the accuracy in unstandardized conditions means estimation in CRD</p></a></li>
<li><a href='#ss.aipe.crd.es'>
<p>Find target sample sizes for the accuracy in standardized conditions means estimation in CRD</p></a></li>
<li><a href='#ss.aipe.cv'><p>Sample size planning for the coefficient of variation given the goal of Accuracy in Parameter Estimation approach to sample</p>
size planning</a></li>
<li><a href='#ss.aipe.cv.sensitivity'><p>Sensitivity analysis for sample size planning given the Accuracy in Parameter Estimation approach for the coefficient of variation.</p></a></li>
<li><a href='#ss.aipe.pcm'><p>Sample size planning for polynomial change models in longitudinal study</p>
</p></a></li>
<li><a href='#ss.aipe.R2'><p> Sample Size Planning for Accuracy in Parameter Estimation</p>
for the multiple correlation coefficient.</a></li>
<li><a href='#ss.aipe.R2.sensitivity'><p>Sensitivity analysis for sample size planning with the goal of Accuracy in Parameter Estimation (i.e., a narrow observed confidence interval)</p></a></li>
<li><a href='#ss.aipe.rc'><p>Sample size necessary for the accuracy in parameter estimation approach</p>
for an unstandardized regression coefficient of interest</a></li>
<li><a href='#ss.aipe.rc.sensitivity'><p> Sensitivity analysis for sample size planing from the Accuracy in Parameter</p>
Estimation Perspective for the unstandardized regression coefficient</a></li>
<li><a href='#ss.aipe.reg.coef'><p>Sample size necessary for the accuracy in parameter estimation approach for a regression coefficient of interest</p></a></li>
<li><a href='#ss.aipe.reg.coef.sensitivity'><p>Sensitivity analysis for sample size planning from the Accuracy in Parameter Estimation Perspective for the (standardized and unstandardized) regression coefficient</p></a></li>
<li><a href='#ss.aipe.reliability'><p> Sample Size Planning for Accuracy in Parameter Estimation for Reliability Coefficients.</p></a></li>
<li><a href='#ss.aipe.rmsea'><p> Sample size planning for RMSEA in SEM</p></a></li>
<li><a href='#ss.aipe.rmsea.sensitivity'><p>a priori Monte Carlo simulation for sample size planning for RMSEA in SEM</p></a></li>
<li><a href='#ss.aipe.sc'><p>Sample size planning for Accuracy in Parameter Estimation (AIPE) of the standardized contrast in ANOVA</p></a></li>
<li><a href='#ss.aipe.sc.ancova'><p>Sample size planning from the AIPE perspective for standardized ANCOVA contrasts</p></a></li>
<li><a href='#ss.aipe.sc.ancova.sensitivity'><p>Sensitivity analysis for the sample size planning method for standardized ANCOVA contrast</p></a></li>
<li><a href='#ss.aipe.sc.sensitivity'><p>Sensitivity analysis for sample size planning for the standardized ANOVA contrast from</p>
the Accuracy in Parameter Estimation (AIPE) Perspective</a></li>
<li><a href='#ss.aipe.sem.path'><p>Sample size planning for SEM targeted effects</p></a></li>
<li><a href='#ss.aipe.sem.path.sensitiv'><p> a priori Monte Carlo simulation for sample size planning for SEM targeted effects</p></a></li>
<li><a href='#ss.aipe.sm'><p>Sample size planning for Accuracy in Parameter Estimation (AIPE) of the standardized mean</p></a></li>
<li><a href='#ss.aipe.sm.sensitivity'><p>Sensitivity analysis for sample size planning for the standardized mean from the Accuracy in Parameter Estimation (AIPE)</p>
Perspective</a></li>
<li><a href='#ss.aipe.smd'><p>Sample size planning for the standardized mean difference from the</p>
Accuracy in Parameter Estimation (AIPE) perspective</a></li>
<li><a href='#ss.aipe.smd.sensitivity'><p>Sensitivity analysis for sample size given the Accuracy in Parameter Estimation approach for the standardized mean difference.</p></a></li>
<li><a href='#ss.aipe.src'><p> sample size necessary for the accuracy in parameter estimation approach for a standardized regression coefficient of interest</p></a></li>
<li><a href='#ss.aipe.src.sensitivity'><p>Sensitivity analysis for sample size planing from the Accuracy in Parameter</p>
Estimation Perspective for the standardized regression coefficient</a></li>
<li><a href='#ss.power.pcm'><p>Sample size planning for power for polynomial change models</p></a></li>
<li><a href='#ss.power.R2'><p>Function to plan sample size so that the test of the squared multiple correlation coefficient is sufficiently powerful.</p></a></li>
<li><a href='#ss.power.rc'><p>sample size for a targeted regression coefficient</p></a></li>
<li><a href='#ss.power.reg.coef'><p>sample size for a targeted regression coefficient</p></a></li>
<li><a href='#ss.power.sem'>
<p>Sample size planning for structural equation modeling from the power analysis perspective</p></a></li>
<li><a href='#t.and.smd.conversion'><p>Conversion functions for noncentral t-distribution</p></a></li>
<li><a href='#theta.2.Sigma.theta'><p>Compute the model-implied covariance matrix of an SEM model</p></a></li>
<li><a href='#transform_r.Z'><p>Transform a correlation coefficient (r) into the scale of Fisher's <code class="reqn">Z^\prime</code></p></a></li>
<li><a href='#transform_Z.r'>
<p>Transform Fischer's <em>Z</em> into the scale of a correlation coefficient</p></a></li>
<li><a href='#upsilon'>
<p>This function implements the upsilon effect size statistic as described in Lachowicz, Preacher, &amp; Kelley (in press) for mediation.</p></a></li>
<li><a href='#var.ete'>
<p>The Variance of the Estimated Treatment Effect at Selected Covariate Values in a Two-group ANCOVA.</p></a></li>
<li><a href='#Variance.R2'><p>Variance of squared multiple correlation coefficient</p></a></li>
<li><a href='#verify.ss.aipe.R2'><p>Internal MBESS function for verifying the sample size in ss.aipe.R2</p></a></li>
<li><a href='#vit'><p> Visualize individual trajectories</p></a></li>
<li><a href='#vit.fitted'><p>Visualize individual trajectories with fitted curve and quality of fit</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>The MBESS R Package</td>
</tr>
<tr>
<td>Version:</td>
<td>4.9.3</td>
</tr>
<tr>
<td>Date:</td>
<td>2023-10-24</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Ken Kelley &lt;kkelley@nd.edu&gt;</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0), stats</td>
</tr>
<tr>
<td>Imports:</td>
<td>boot, lavaan, MASS, methods, mnormt, nlme, OpenMx, parallel,
sem, semTools</td>
</tr>
<tr>
<td>Suggests:</td>
<td>gsl</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Description:</td>
<td>Implements methods that are useful in designing research studies and analyzing data, with 
	particular emphasis on methods that are developed for or used within the behavioral, 
	educational, and social sciences (broadly defined). That being said, many of the methods 
	implemented within MBESS are applicable to a wide variety of disciplines. MBESS has a 
	suite of functions for a variety of related topics, such as effect sizes, confidence intervals 
	for effect sizes (including standardized effect sizes and noncentral effect sizes), sample size
	planning (from the accuracy in parameter estimation [AIPE], power analytic, equivalence, and 
	minimum-risk point estimation perspectives), mediation analysis, various properties of 
	distributions, and a variety of utility functions. MBESS (pronounced 'em-bes') was originally 
	an acronym for 'Methods for the Behavioral, Educational, and Social Sciences,' but MBESS became
	more general and now contains methods applicable and used in a wide variety of fields and is an 
	orphan acronym, in the sense that what was an acronym is now literally its name. MBESS has 
	greatly benefited from others, see <a href="https://www3.nd.edu/~kkelley/site/MBESS.html">https://www3.nd.edu/~kkelley/site/MBESS.html</a> for a detailed 
	list of those that have contributed and other details.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://www3.nd.edu/~kkelley/site/MBESS.html">https://www3.nd.edu/~kkelley/site/MBESS.html</a></td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-10-25 14:19:29 UTC; kkelley</td>
</tr>
<tr>
<td>Author:</td>
<td>Ken Kelley [aut, cre]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-10-26 07:10:11 UTC</td>
</tr>
</table>
<hr>
<h2 id='aipe.smd'>Sample size planning for the standardized mean different from the accuracy 
in parameter estimation approach</h2><span id='topic+ss.aipe.smd.lower'></span><span id='topic+ss.aipe.smd.upper'></span><span id='topic+ss.aipe.smd.full'></span>

<h3>Description</h3>

<p>A set of functions that <code>ss.aipe.smd</code> calls upon to calculate the appropriate sample size 
for the standardized mean difference such that the expected value of the confidence interval 
is sufficiently narrow.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ss.aipe.smd.full(delta, conf.level, width, ...)
ss.aipe.smd.lower(delta, conf.level, width, ...)
ss.aipe.smd.upper(delta, conf.level, width, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="aipe.smd_+3A_delta">delta</code></td>
<td>
<p>the population value of the standardized mean difference</p>
</td></tr>
<tr><td><code id="aipe.smd_+3A_conf.level">conf.level</code></td>
<td>
<p>the desired degree of confidence (i.e., 1-Type I error rate)</p>
</td></tr>
<tr><td><code id="aipe.smd_+3A_width">width</code></td>
<td>
<p>desired width of the specified (i.e., <code>Lower</code>, <code>Upper</code>, <code>Full</code>) region of the confidence interval</p>
</td></tr>
<tr><td><code id="aipe.smd_+3A_...">...</code></td>
<td>
<p>specify additional parameters in functions these functions call upon</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>n</code></td>
<td>
<p>The necessary sample size <em>per group</em> in order to satisfy the specified goals.</p>
</td></tr>
</table>


<h3>Warning</h3>

<p>The returned value is the sample size <em>per group</em>. Currently only
<code>ss.aipe.smd.full</code> returns the exact value. However, <code>ss.aipe.smd.lower</code> and <code>ss.aipe.smd.upper</code>
provide approximate sample size values.</p>


<h3>Note</h3>

<p>The function <code>ss.aipe.smd</code> is the function users should generally use. The function
<code>ss.aipe.smd</code> calls upon these functions as needed. They can be thought of loosely 
as internal MBESS functions.</p>


<h3>Author(s)</h3>

<p>Ken Kelley (University of Notre Dame; <a href="mailto:KKelley@ND.Edu">KKelley@ND.Edu</a>)</p>


<h3>References</h3>

<p>Cohen, J. (1988). Statistical power analysis for the behavioral sciences (2nd ed.). Hillsdale, NJ: Lawrence Erlbaum.
</p>
<p>Cumming, G. &amp; Finch, S. (2001). A primer on the understanding, use, and calculation of confidence intervals that are
based on central and noncentral distributions, <em>Educational and Psychological Measurement, 61</em>, 532&ndash;574.
</p>
<p>Hedges, L. V. (1981). Distribution theory for Glass's Estimator of effect size and related estimators. <em>Journal of Educational Statistics, 2</em>, 107&ndash;128.
</p>
<p>Kelley, K. (2005). The effects of nonnormal distributions on confidence intervals around the standardized mean
difference: Bootstrap and parametric confidence intervals, <em>Educational and Psychological Measurement, 65</em>, 51&ndash;69.
</p>
<p>Kelley, K., Maxwell, S. E., &amp; Rausch, J. R. (2003). Obtaining Power or Obtaining Precision: Delineating Methods
of Sample-Size Planning, <em>Evaluation and the Health Professions, 26</em>, 258&ndash;287.
</p>
<p>Kelley, K., &amp; Rausch, J. R. (2006). Sample size planning for the standardized mean difference: 
Accuracy in Parameter Estimation via narrow confidence intervals. <em>Psychological Methods, 11(4)</em>, 363&ndash;385.
</p>
<p>Steiger, J. H., &amp; Fouladi, R. T. (1997). Noncentrality interval estimation and the evaluation of
statistical methods. In L. L. Harlow, S. A. Mulaik, &amp; J.H. Steiger (Eds.), <em>What if there were
no significance tests?</em> (pp. 221&ndash;257). Mahwah, NJ: Lawrence Erlbaum.
</p>


<h3>See Also</h3>

<p><code>ss.aipe.smd</code></p>

<hr>
<h2 id='ancova.random.data'> Generate random data for an ANCOVA model </h2><span id='topic+ancova.random.data'></span>

<h3>Description</h3>

<p>Generate random data for a simple (one-response-one-covariate) ANCOVA model considering the covariate as random. Data can be generated in the
contexts of both randomized design (same population covariate mean across groups) and non-randomized 
design (different population covariate means across groups).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ancova.random.data(mu.y, mu.x, sigma.y, sigma.x, rho, J, n, randomized = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ancova.random.data_+3A_mu.y">mu.y</code></td>
<td>
<p> a vector of the population group means of the response variable </p>
</td></tr>
<tr><td><code id="ancova.random.data_+3A_mu.x">mu.x</code></td>
<td>
<p> the population mean of the covariate (in the randomized design context), or a vector of the population group
means of the covariate (in the non-randomized design context) </p>
</td></tr>
<tr><td><code id="ancova.random.data_+3A_sigma.y">sigma.y</code></td>
<td>
<p> the population standard deviation of the response (outcome) variable </p>
</td></tr>
<tr><td><code id="ancova.random.data_+3A_sigma.x">sigma.x</code></td>
<td>
<p> the population standard deviation of the covariate</p>
</td></tr>
<tr><td><code id="ancova.random.data_+3A_rho">rho</code></td>
<td>
<p> the population correlation coefficient between the response and the covariate </p>
</td></tr>
<tr><td><code id="ancova.random.data_+3A_j">J</code></td>
<td>
<p> the number of groups </p>
</td></tr>
<tr><td><code id="ancova.random.data_+3A_n">n</code></td>
<td>
<p> the number of sample size <em>per group</em> </p>
</td></tr>
<tr><td><code id="ancova.random.data_+3A_randomized">randomized</code></td>
<td>
<p> a logical statement of whether randomized design is used</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function uses a multivariate normal distribution to generate the random data; the covariate is considered 
as a random variable in the model. This function uses <code>mvrnorm</code> in the <code>MASS</code> package in an internal function, and
thus it requires the <code>MASS</code> package be installed.
</p>
<p>This function assumes homogeneous covariance matrix among groups, in both the randomized design and
non-randomized design contexts. 
</p>


<h3>Value</h3>

<p>This function returns an <code class="reqn">n</code> by <code class="reqn">J2</code> matrix, where <code class="reqn">n</code> and <code class="reqn">J</code> are as defined 
in the argument. The first <code class="reqn">J</code> columns of the matrix contains the random data for the response, and
the second <code class="reqn">J</code> columns of the matrix contains the random data for the covariate.
</p>


<h3>Author(s)</h3>

<p> Keke Lai (University of California-Merced) and Ken Kelley (University of Notre Dame) &lt;kkelley@nd.edu&gt;</p>


<h3>See Also</h3>

 <p><code>mvrnorm</code> in the <code>MASS</code> package </p>


<h3>Examples</h3>

<pre><code class='language-R'>random.data &lt;- ancova.random.data(mu.y=c(3,5), mu.x=10, sigma.y=1, 
sigma.x=2, rho=.8, J=2, n=20)
</code></pre>

<hr>
<h2 id='CFA.1'> One-factor confirmatory factor analysis model</h2><span id='topic+CFA.1'></span>

<h3>Description</h3>

<p>Returns the MLE estimates and the estimated asymptotic covariance matrix of parameter estimates for one-factor confirmatory factor analysis model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CFA.1(S, N, equal.loading = FALSE, equal.error = FALSE, package="lavaan", 
	se="standard", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CFA.1_+3A_s">S</code></td>
<td>
<p> covariance matrix of the indicators </p>
</td></tr>
<tr><td><code id="CFA.1_+3A_n">N</code></td>
<td>
<p> total sample size </p>
</td></tr>
<tr><td><code id="CFA.1_+3A_equal.loading">equal.loading</code></td>
<td>
<p>logical statement indicating whether the path coefficients are the same</p>
</td></tr>
<tr><td><code id="CFA.1_+3A_equal.error">equal.error</code></td>
<td>
<p> logical statement indicating whether the manifest variables have the same error variances</p>
</td></tr>
<tr><td><code id="CFA.1_+3A_package">package</code></td>
<td>
<p>the package used in confirmatory factor analysis (<code>sem</code> or <code>lavaan</code></p>
</td></tr>
<tr><td><code id="CFA.1_+3A_se">se</code></td>
<td>
<p>See the <code><a href="lavaan.html#topic+cfa">cfa</a></code> and check the <code>se</code> argument</p>
</td></tr>
<tr><td><code id="CFA.1_+3A_...">...</code></td>
<td>
<p>Additional arguments for the <code><a href="lavaan.html#topic+cfa">cfa</a></code> function</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>Model</code></td>
<td>
<p>the factor analysis model specified by the user</p>
</td></tr>
<tr><td><code>Factor.Loadings</code></td>
<td>
<p>factor loadings</p>
</td></tr>
<tr><td><code>Indicator.var</code></td>
<td>
<p>the error variances of the indicator variables</p>
</td></tr>
<tr><td><code>Parameter.cov</code></td>
<td>
<p>the covariance matrix of the parameters</p>
</td></tr>
<tr><td><code>converged</code></td>
<td>
<p><code>TRUE</code> or <code>FALSE</code> statement on if the model converged</p>
</td></tr>
<tr><td><code>package</code></td>
<td>
<p>notes the package used to get the output</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The output will differ slightly, both in form and potentially values, based on which package <span class="pkg">lavaan</span> or <span class="pkg">sem</span> is used.</p>


<h3>Author(s)</h3>

<p> Keke Lai (University of California-Merced) and Ken Kelley (University of Notre Dame)</p>


<h3>See Also</h3>

 <p><code><a href="sem.html#topic+sem">sem</a></code>, <code>covmat.from.cfm</code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
cov.mat&lt;- matrix(
c(1.384, 1.484, 1.988, 2.429, 3.031,
1.484, 2.756, 2.874, 3.588, 4.390,
1.988, 2.874, 4.845, 4.894, 6.080,
2.429, 3.588, 4.894, 6.951, 7.476,
3.031, 4.390, 6.080, 7.476, 10.313), nrow=5)


CFA.1(N=300, S=cov.mat, package="lavaan")

CFA.1(N=300, S=cov.mat, package="sem")


## End(Not run)
</code></pre>

<hr>
<h2 id='ci.c'> Confidence interval for a contrast in a fixed effects ANOVA </h2><span id='topic+ci.c'></span>

<h3>Description</h3>

<p>Function to calculate the exact confidence interval for a contrast in a fixed effects analysis of variance context. This function assumes homogeneity of variance (as does the ANOVA upon which 's.anova' is based).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ci.c(means = NULL, s.anova = NULL, c.weights = NULL, n = NULL, 
N = NULL, Psi = NULL, conf.level = 0.95, alpha.lower = NULL, 
alpha.upper = NULL, df.error = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ci.c_+3A_means">means</code></td>
<td>
<p>a vector of the group means or the means of the particular level of the effect (for fixed effect designs) </p>
</td></tr>
<tr><td><code id="ci.c_+3A_s.anova">s.anova</code></td>
<td>
<p>the standard deviation of the errors from the ANOVA model (i.e., the square root of the mean square error)</p>
</td></tr>
<tr><td><code id="ci.c_+3A_c.weights">c.weights</code></td>
<td>
<p>the contrast weights (choose weights so that the positive <em>c</em>-weights sum to 1 and the negative <em>c</em>-weights sum to -1; i.e., use fractional values not integers).</p>
</td></tr>
<tr><td><code id="ci.c_+3A_n">n</code></td>
<td>
<p> sample sizes <em>per group</em> or level of the particular factor (if length 1 it is assumed that the per group/level sample sizes are equal) </p>
</td></tr>
<tr><td><code id="ci.c_+3A_n">N</code></td>
<td>
<p> total sample size </p>
</td></tr>
<tr><td><code id="ci.c_+3A_psi">Psi</code></td>
<td>
<p> the (unstandardized) contrast effect, obtained by multiplying the <em>j</em>th mean by the jth contrast weight (this is the unstandardized effect) </p>
</td></tr>
<tr><td><code id="ci.c_+3A_conf.level">conf.level</code></td>
<td>
<p> confidence interval coverage (i.e., 1- Type I error rate); default is .95 </p>
</td></tr>
<tr><td><code id="ci.c_+3A_alpha.lower">alpha.lower</code></td>
<td>
<p> Type I error for the lower confidence limit </p>
</td></tr>
<tr><td><code id="ci.c_+3A_alpha.upper">alpha.upper</code></td>
<td>
<p> Type I error for the upper confidence limit</p>
</td></tr>
<tr><td><code id="ci.c_+3A_df.error">df.error</code></td>
<td>
<p> the degrees of freedom for the error. In one-way designs, this is simply <em>N</em>-length (means) and need not be specified; it must be specified if the design has multiple factors. </p>
</td></tr>
<tr><td><code id="ci.c_+3A_...">...</code></td>
<td>
<p> allows one to potentially include parameter values for inner functions </p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns the confidence limits for the contrast: 
</p>
<table>
<tr><td><code>Lower.Conf.Limit.Contrast</code></td>
<td>
<p>the lower confidence limit for the contrast effect</p>
</td></tr>
<tr><td><code>Contrast</code></td>
<td>
<p>the value of the estimated unstandardized contrast effect</p>
</td></tr>
<tr><td><code>Upper.Conf.Limit.Contrast</code></td>
<td>
<p>the upper confidence limit for the contrast effect</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Be sure to use the standard deviation and not the error variance for <code>s.anova</code>, not the square of this value (the error variance) which would come from the source table (i.e., do not use the variance of the error but rather use its square root, the standard deviation).
</p>
<p>Be sure to use fractional <em>c</em>-weights when doing complex contrasts (not integers) to specify <code>c.weights</code>. For example, in an ANCOVA of four groups, if the user wants to compare the mean of group 1 and 2 with the mean of group 3 and 4, <code>c.weights</code> should be specified as c(0.5, 0.5, -0.5, -0.5) rather than c(1, 1, -1, -1). Make sure the sum of the contrast weights is zero.
</p>


<h3>Author(s)</h3>

<p> Ken Kelley (University of Notre Dame; <a href="mailto:KKelley@ND.Edu">KKelley@ND.Edu</a>) </p>


<h3>References</h3>

<p>Kelley, K. (2007). Constructing confidence intervals for standardized effect sizes: Theory, application, and implementation. <em>Journal of Statistical Software, 20</em> (8), 1&ndash;24.
</p>
<p>Steiger, J. H. (2004). Beyond the <em>F</em> Test: Effect size confidence intervals and tests of close fit in the 
analysis of variance and contrast analysis. <em>Psychological Methods, 9</em>, 164&ndash;182.
</p>


<h3>See Also</h3>

 <p><code>conf.limits.nct</code>, <code>ci.sc</code>, <code>ci.src</code>, <code>ci.smd</code>, <code>ci.smd.c</code>, <code>ci.sm</code></p>


<h3>Examples</h3>

<pre><code class='language-R'># Here is a four group example. Suppose that the means of groups 1--4 are 2, 4, 9, 
# and 13, respectively. Further, let the error variance be .64 and thus the standard
# deviation would be .80 (note we use the standard deviation in the function, not the 
# variance). The contrast of interest here is the average of groups 1 and 4 versus the 
# average of groups 2 and 3. 

ci.c(means=c(2, 4, 9, 13), s.anova=.80, c.weights=c(.5, -.5, -.5, .5), 
n=c(3, 3, 3, 3), N=12, conf.level=.95)


# Here is an example with two groups. 
ci.c(means=c(1.6, 0), s.anova=.80, c.weights=c(1, -1), n=c(10, 10), N=20, conf.level=.95)


# An example given by Maxwell and Delaney (2004, pp. 155--171) :
# 24 subjects of mild hypertensives are assigned to one of four treatments: drug 
# therapy, biofeedback, dietary modification, and a treatment combining all the 
# three previous treatments. Subjects' blood pressure is measured two weeks
# after the termination of treatment. Now we want to form a 95% level
# confidence interval for the difference in blood pressure between subjects
# who received drug treatment and those who received biofeedback treatment 

## Drug group's mean = 94; group size=4
## Biofeedback group's mean = 91; group size=6 
## Diet group's mean = 92; group size=5
## Combination group's mean = 83; group size=5
## Mean Square Within (i.e., 'error.variance') = 67.375

ci.c(means=c(94, 91, 92, 83), s.anova=sqrt(67.375), c.weights=c(1, -1, 0, 0), 
n=c(4, 6, 5, 5), N=20, conf.level=.95)

</code></pre>

<hr>
<h2 id='ci.c.ancova'> Confidence interval for an (unstandardized) contrast in ANCOVA with one covariate</h2><span id='topic+ci.c.ancova'></span>

<h3>Description</h3>

<p>To calculate the confidence interval for an unstandardized contrast in the one-covariate ANCOVA.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ci.c.ancova(Psi, adj.means, s.ancova = NULL, c.weights, n,
cov.means, SSwithin.x, conf.level = 0.95, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ci.c.ancova_+3A_psi">Psi</code></td>
<td>
<p> the unstandardized contrast of adjusted means</p>
</td></tr>
<tr><td><code id="ci.c.ancova_+3A_adj.means">adj.means</code></td>
<td>
<p>the vector that contains the adjusted mean of each group on the dependent variable</p>
</td></tr>
<tr><td><code id="ci.c.ancova_+3A_s.ancova">s.ancova</code></td>
<td>
<p>the standard deviation of the errors from the ANCOVA model (i.e., the square root of the mean square error from ANCOVA)</p>
</td></tr>
<tr><td><code id="ci.c.ancova_+3A_c.weights">c.weights</code></td>
<td>
<p> the contrast weights </p>
</td></tr>
<tr><td><code id="ci.c.ancova_+3A_n">n</code></td>
<td>
<p> either a single number that indicates the sample size <em>per group</em> or a vector that contains the
sample size of each group</p>
</td></tr>
<tr><td><code id="ci.c.ancova_+3A_cov.means">cov.means</code></td>
<td>
<p> a vector that contains the group means of the covariate</p>
</td></tr>
<tr><td><code id="ci.c.ancova_+3A_sswithin.x">SSwithin.x</code></td>
<td>
<p> the sum of squares within groups obtained from the summary table for ANOVA on the covariate </p>
</td></tr>
<tr><td><code id="ci.c.ancova_+3A_conf.level">conf.level</code></td>
<td>
<p>the desired confidence interval coverage, (i.e., 1 - Type I error rate)</p>
</td></tr>
<tr><td><code id="ci.c.ancova_+3A_...">...</code></td>
<td>
<p> allows one to potentially include parameter values for inner functions </p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>lower.limit</code></td>
<td>
<p>the lower confidence limit of the (unstandardized) ANCOVA contrast</p>
</td></tr>
<tr><td><code>upper.limit</code></td>
<td>
<p>the upper confidence limit of the (unstandardized) ANCOVA contrast</p>
</td></tr>
</table>


<h3>Note</h3>

 
<p>Be sure to use the standard deviation and not the error variance for <code>s.ancova</code>, not the square of this value which would come from the source table (i.e., do not use the variance of the error but rather use the square root).
</p>
<p>If <code>n</code> receives a single number, that number is considered as the sample size <em>per group</em>. If <code>n</code>
receives a vector, the vector is considered as the sample size of each group.
</p>
<p>Be sure to use fractions not the integers to specify <code>c.weights</code>. For example, in an ANCOVA of four groups, 
if the user wants to compare the mean of group 1 and 2 with the mean of group 3 and 4, <code>c.weights</code> should
be specified as c(0.5, 0.5, -0.5, -0.5) rather than c(1, 1, -1, -1). Make sure the sum of the contrast weights 
are zero.
</p>


<h3>Author(s)</h3>

<p>Keke Lai (University of California&ndash;Merced) and Ken Kelley (University of Notre Dame; <a href="mailto:kkelley@nd.edu">kkelley@nd.edu</a>)</p>


<h3>References</h3>

<p>Kelley, K. (2007). Constructing confidence intervals for standardized effect sizes: Theory, application, and implementation. <em>Journal of Statistical Software, 20</em> (8), 1&ndash;24.
</p>
<p>Maxwell, S. E., &amp; Delaney, H. D. (2004). <em>Designing experiments and analyzing data: A model comparison perspective</em>. Mahwah, NJ: Erlbaum. 
</p>


<h3>See Also</h3>

<p><code>ci.c</code>, <code>ci.sc.ancova</code> </p>


<h3>Examples</h3>

<pre><code class='language-R'># Maxwell &amp; Delaney (2004, pp. 428-468) offer an example that 30 depressive 
# individuals are randomly assigned to three groups, 10 in each, and ANCOVA 
# is performed on the posttest scores using the participants' pretest 
# scores as the covariate. The means of pretest scores of group 1 to 3 are 
# 17, 17.7, and 17.4, respectively, and the adjusted means of groups 1 to 3 
# are 7.5, 12, and 14, respectively. The error variance in ANCOVA is 29, 
# and the sum of squares within groups from ANOVA on the covariate is 
# 313.37. 

# To obtain the confidence interval for adjusted mean of group 1 versus 
# group 2:
ci.c.ancova(adj.means=c(7.5, 12, 14), s.ancova=sqrt(29), c.weights=c(1, -1, 0), 
n=10, cov.means=c(17, 17.7, 17.4), SSwithin.x=313.37)</code></pre>

<hr>
<h2 id='ci.cc'>
Confidence interval for the population correlation coefficient
</h2><span id='topic+ci.cc'></span>

<h3>Description</h3>

<p>This function is used to form a confidence interval for the population correlation coefficient. Note that this appraoch assumes that the variables the sample correlation coefficient are based are assumed to be bivariate normally distributed (e.g., Hays, 1994, Chapter 14). 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ci.cc(r, n, conf.level = 0.95, alpha.lower = NULL, alpha.upper = NULL)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ci.cc_+3A_r">r</code></td>
<td>
<p>observed value of the correlation coefficient (specifically the zero-order Pearson product-moment correlation coefficient)</p>
</td></tr>
<tr><td><code id="ci.cc_+3A_n">n</code></td>
<td>
<p>sample size</p>
</td></tr>
<tr><td><code id="ci.cc_+3A_conf.level">conf.level</code></td>
<td>
<p>desired confidence level, where the error rate is the same on each side</p>
</td></tr>
<tr><td><code id="ci.cc_+3A_alpha.lower">alpha.lower</code></td>
<td>
<p>the Type I error rate for the lower confidence interval limit</p>
</td></tr>
<tr><td><code id="ci.cc_+3A_alpha.upper">alpha.upper</code></td>
<td>
<p>the Type I error rate for the upper confidence interval limit</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Note that this appraoch to confidence intervals does will not generally lead to a symmetric confidence interval. The function first transforms <code class="reqn">r</code> into <code class="reqn">Z^\prime</code> , forms a confidence interval for the population value (i.e., <code class="reqn">\zeta</code>), and then transforms the confidence limits for <code class="reqn">\zeta</code> into the scale of the correlation coefficient. 
</p>


<h3>Value</h3>

<table>
<tr><td><code>Lower.Limit</code></td>
<td>
<p>lower limit of the confidence interval</p>
</td></tr>
<tr><td><code>Estimated.Correlation</code></td>
<td>
<p>observed value of the correlation coefficient</p>
</td></tr>
<tr><td><code>Upper.Limit</code></td>
<td>
<p>upper limit of the confidence interval</p>
</td></tr>
</table>


<h3>Note</h3>

<p>This confidence interval assumes that the two variables the correlation is based are bivariate normal. See Hays (2004, Chapter 14) for details. 
</p>


<h3>Author(s)</h3>

<p> Ken Kelley (University of Notre Dame; <a href="mailto:KKelley@ND.Edu">KKelley@ND.Edu</a>) </p>


<h3>References</h3>

<p>Kelley, K. (2007). Confidence intervals for standardized effect sizes: Theory, application, 
and implementation.<em> Journal of Statistical Software, 20</em>(8), 1&ndash;24.
</p>
<p>Hays, W. L. (1994). <em>Statistics</em> (5th ed). Fort Worth, TX: Harcourt Brace College Publishers)
</p>


<h3>See Also</h3>

<p><code><a href="#topic+transform_Z.r">transform_Z.r</a></code>, <code><a href="#topic+transform_r.Z">transform_r.Z</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example, from Hayes. Suppose n=100 and r=.35. 
ci.cc(r=.35, n=100, conf.level=.95)

# Here is another way to enter the above example. 
ci.cc(r=.35, n=100, conf.level=NULL, alpha.lower=.025, alpha.upper=.025)

# Here are examples of one-sided confidence intervals. 
ci.cc(r=.35, n=100, conf.level=NULL, alpha.lower=0, alpha.upper=.05)
ci.cc(r=.35, n=100, conf.level=NULL, alpha.lower=.05, alpha.upper=0)
</code></pre>

<hr>
<h2 id='ci.cv'>Confidence interval for the coefficient of variation</h2><span id='topic+ci.cv'></span>

<h3>Description</h3>

<p>Function to calculate the confidence interval for the population coefficient of variation using the noncentral <code>t</code>-distribution.</p>


<h3>Usage</h3>

<pre><code class='language-R'>ci.cv(cv=NULL, mean = NULL, sd = NULL, n = NULL, data = NULL, 
conf.level = 0.95, alpha.lower = NULL, alpha.upper = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ci.cv_+3A_cv">cv</code></td>
<td>
<p>coefficient of variation</p>
</td></tr>
<tr><td><code id="ci.cv_+3A_mean">mean</code></td>
<td>
<p>sample mean</p>
</td></tr>
<tr><td><code id="ci.cv_+3A_sd">sd</code></td>
<td>
<p>sample standard deviation (square root of the unbiased estimate of the variance)</p>
</td></tr>
<tr><td><code id="ci.cv_+3A_n">n</code></td>
<td>
<p>sample size</p>
</td></tr>
<tr><td><code id="ci.cv_+3A_data">data</code></td>
<td>
<p>vector of data for which the confidence interval for the coefficient of variation is to be calculated</p>
</td></tr>
<tr><td><code id="ci.cv_+3A_conf.level">conf.level</code></td>
<td>
<p>desired confidence level (1-Type I error rate)</p>
</td></tr>
<tr><td><code id="ci.cv_+3A_alpha.lower">alpha.lower</code></td>
<td>
<p>the proportion of values beyond the lower limit of the confidence interval (cannot be used with <code>conf.level</code>).</p>
</td></tr>
<tr><td><code id="ci.cv_+3A_alpha.upper">alpha.upper</code></td>
<td>
<p>the proportion of values beyond the upper limit of the confidence interval (cannot be used with <code>conf.level</code>).</p>
</td></tr>
<tr><td><code id="ci.cv_+3A_...">...</code></td>
<td>
<p> allows one to potentially include parameter values for inner functions</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Uses the noncentral <em>t</em>-distribution to calculate the confidence interval for the population coefficient of variation.
</p>


<h3>Value</h3>

<table>
<tr><td><code>Lower.Limit.CofV</code></td>
<td>
<p>Lower confidence interval limit</p>
</td></tr>
<tr><td><code>Prob.Less.Lower</code></td>
<td>
<p>Proportion of the distribution beyond <code>Lower.Limit.CofV</code></p>
</td></tr>
<tr><td><code>Upper.Limit.CofV</code></td>
<td>
<p>Upper confidence interval limit</p>
</td></tr>
<tr><td><code>Prob.Greater.Upper</code></td>
<td>
<p>Proportion of the distribution beyond <code>Upper.Limit.CofV</code></p>
</td></tr> 
<tr><td><code>C.of.V</code></td>
<td>
<p>Observed coefficient of variation</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Ken Kelley (University of Notre Dame; <a href="mailto:KKelley@ND.Edu">KKelley@ND.Edu</a>)</p>


<h3>References</h3>

<p>Johnson, B. L., &amp; Welch, B. L. (1940). Applications of the non-central <em>t</em>-distribution. <em>Biometrika</em>, 31, 362&ndash;389.
</p>
<p>Kelley, K. (2007). Sample size planning for the coefficient of variation from the accuracy in parameter estimation approach. <em>Behavior Research Methods, 39</em> (4), 755&ndash;766.
</p>
<p>Kelley, K. (2007). Constructing confidence intervals for standardized effect sizes: Theory, application, and implementation. <em>Journal of Statistical Software, 20</em> (8), 1&ndash;24.
</p>
<p>McKay, A. T. (1932). Distribution of the coefficient of variation and the extended <em>t</em> distribution, <em>Journal of the Royal Statistical Society</em>, <em>95</em>, 695&ndash;698.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cv">cv</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(113)
N &lt;- 15
X &lt;- rnorm(N, 5, 1)
mean.X &lt;- mean(X)
sd.X &lt;- var(X)^.5

ci.cv(mean=mean.X, sd=sd.X, n=N, alpha.lower=.025, alpha.upper=.025,
conf.level=NULL)
ci.cv(data=X, conf.level=.95)
ci.cv(cv=sd.X/mean.X, n=N, conf.level=.95)

</code></pre>

<hr>
<h2 id='ci.omega2'>
Confidence Interval for omega-squared (<code class="reqn">\omega^2</code>) for between-subject fixed-effects ANOVA and ANCOVA designs (and partial omega-squared <code class="reqn">\omega^2_p</code> for between-subject multifactor ANOVA and ANCOVA designs)</h2><span id='topic+ci.omega2'></span>

<h3>Description</h3>

<p>Function to obtain the exact confidence interval using the non-central <code class="reqn">F</code>-distribution for omega-squared or partial omega-squared in between-subject fixed-effects ANOVA and ANCOVA designs.</p>


<h3>Usage</h3>

<pre><code class='language-R'>ci.omega2(F.value = NULL, df.1 = NULL, df.2 = NULL, N = NULL, conf.level = 0.95, 
alpha.lower = NULL, alpha.upper = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ci.omega2_+3A_f.value">F.value</code></td>
<td>

<p>The value of the <code class="reqn">F</code>-statistic for the analysis of (co)variace model (ANOVA) or, in the case of a multifactor ANOVA, the <code class="reqn">F</code>-statistic for the particular factor.)
</p>
</td></tr>
<tr><td><code id="ci.omega2_+3A_df.1">df.1</code></td>
<td>

<p>numerator degrees of freedom
</p>
</td></tr>
<tr><td><code id="ci.omega2_+3A_df.2">df.2</code></td>
<td>

<p>denominator degrees of freedom
</p>
</td></tr>
<tr><td><code id="ci.omega2_+3A_n">N</code></td>
<td>

<p>total sample size (i.e., the number of individual entities in the data)
</p>
</td></tr>
<tr><td><code id="ci.omega2_+3A_conf.level">conf.level</code></td>
<td>
<p> confidence interval coverage (i.e., 1-Type I error rate), default is .95 </p>
</td></tr>
<tr><td><code id="ci.omega2_+3A_alpha.lower">alpha.lower</code></td>
<td>
<p> Type I error for the lower confidence limit </p>
</td></tr>
<tr><td><code id="ci.omega2_+3A_alpha.upper">alpha.upper</code></td>
<td>
<p> Type I error for the upper confidence limit </p>
</td></tr>
<tr><td><code id="ci.omega2_+3A_...">...</code></td>
<td>
<p> allows one to potentially include parameter values for inner functions </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The confidence level must be specified in one of following two ways: using 
confidence interval coverage (<code>conf.level</code>), or lower and upper confidence 
limits (<code>alpha.lower</code> and <code>alpha.upper</code>). The value returned is the confidence 
interval limits for the population <code class="reqn">\omega^2</code> (or partial <code class="reqn">\omega^2</code>). 
</p>
<p>This function uses the confidence interval transformation principle (Steiger, 2004) to transform the confidence limits for the noncentality parameter to the confidence limits for the population's (partial) omega-squared (<code class="reqn">\omega^2</code>). The confidence interval for the noncentral <code class="reqn">F</code>-parameter can be obtained
from the <code>conf.limits.ncf</code> function in MBESS, which is used internally within this function. 
</p>


<h3>Value</h3>

<p>Returns the confidence limits for (partial) omega-sqaured.
</p>
<table>
<tr><td><code>lower_Limit_omega2</code></td>
<td>
<p>lower limit for omega-squared</p>
</td></tr>
<tr><td><code>lower_Limit_omega2</code></td>
<td>
<p>upper limit for omega-squared</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p> Ken Kelley (University of Notre Dame; <a href="mailto:KKelley@ND.Edu">KKelley@ND.Edu</a>) </p>


<h3>References</h3>

<p>Fleishman, A. I. (1980). Confidence intervals for correlation ratios. <em>Educational and Psychological Measurement, 40</em>, 659&ndash;670.
</p>
<p>Kelley, K. (2007). Constructing confidence intervals for standardized effect sizes: Theory, application, and implementation. <em>Journal of Statistical Software, 20</em> (8), 1&ndash;24.
</p>
<p>Steiger, J. H. (2004). Beyond the <em>F</em> Test: Effect size confidence intervals and tests of close fit in the Analysis of Variance and Contrast Analysis. <em>Psychological Methods, 9</em>, 164&ndash;182.
</p>


<h3>See Also</h3>

<p><code>ci.srsnr</code>, <code>ci.snr</code>, <code>conf.limits.ncf</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## To illustrate the calculation of the confidence interval for noncentral 
## F parameter,Bargman (1970) gave an example in which a 5-group ANOVA with 
## 11 subjects in each group is conducted and the observed F value is 11.2213. 
## This exmaple continued to be used in Venables (1975),  Fleishman (1980), 
## and Steiger (2004). If one wants to calculate the exact confidence interval 
## for omega-squared of that example, this function can be used.

ci.omega2(F.value=11.221, df.1=4, df.2=50, N=55)

ci.omega2(F.value=11.221, df.1=4, df.2=50, N=55, conf.level=.90)

  </code></pre>

<hr>
<h2 id='ci.pvaf'>Confidence Interval for the Proportion of Variance Accounted for (in the dependent variable by knowing the levels of the factor) </h2><span id='topic+ci.pvaf'></span>

<h3>Description</h3>

<p>Function to obtain the exact confidence limits for the proportion of variance of the dependent variable accounted for by knowing the levels of the factor (or the grouping factor in a single factor design) group status in a fixed factor analysis of variance.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ci.pvaf(F.value = NULL, df.1 = NULL, df.2 = NULL, N = NULL, 
conf.level = 0.95, alpha.lower = NULL, alpha.upper = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ci.pvaf_+3A_f.value">F.value</code></td>
<td>
<p> observed <em>F</em>-value from fixed effects analysis of variance</p>
</td></tr>
<tr><td><code id="ci.pvaf_+3A_df.1">df.1</code></td>
<td>
<p> numerator degrees of freedom </p>
</td></tr>
<tr><td><code id="ci.pvaf_+3A_df.2">df.2</code></td>
<td>
<p> denominator degrees of freedom </p>
</td></tr>
<tr><td><code id="ci.pvaf_+3A_n">N</code></td>
<td>
<p> sample size </p>
</td></tr>
<tr><td><code id="ci.pvaf_+3A_conf.level">conf.level</code></td>
<td>
<p> confidence interval coverage (i.e., 1-Type I error rate); default is .95 </p>
</td></tr>
<tr><td><code id="ci.pvaf_+3A_alpha.lower">alpha.lower</code></td>
<td>
<p> Type I error for the lower confidence limit </p>
</td></tr>
<tr><td><code id="ci.pvaf_+3A_alpha.upper">alpha.upper</code></td>
<td>
<p> Type I error for the upper confidence limit </p>
</td></tr>
<tr><td><code id="ci.pvaf_+3A_...">...</code></td>
<td>
<p> allows one to potentially include parameter values for inner functions </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The confidence level must be specified in one of following two ways: using confidence interval coverage (<code>conf.level</code>), or lower and upper confidence 
limits (<code>alpha.lower</code> and <code>alpha.upper</code>).
</p>
<p>This function uses the confidence interval transformation principle (Steiger, 2004) to transform the confidence limits for the noncentrality parameter to the confidence limits for the population proportion of variance accounted for by knowing the group status. The confidence interval for the noncentral <em>F</em> parameter can be obtained from the
function <code>conf.limits.ncf</code> in MBESS, which is used within this function.
</p>


<h3>Value</h3>

<p>Returns the confidence interval for the proportion of variance of the dependent variable accounted for by knowing group status in a fixed factor analysis of variance (using a noncentral <em>F</em>-distribution).
</p>
<table>
<tr><td><code>Lower.Limit.Proportion.of.Variance.Accounted.for</code></td>
<td>
<p>The lower confidence limit for the proportion of variance accounted for in the deviation by group status.</p>
</td></tr>
<tr><td><code>Upper.Limit.Proportion.of.Variance.Accounted.for</code></td>
<td>
<p>The upper confidence limit for the proportion of variance accounted for in the deviation by group status.</p>
</td></tr>
</table>


<h3>Note</h3>

 
<p>This function can be used for single or factorial ANOVA designs.
</p>


<h3>Author(s)</h3>

<p> Ken Kelley (University of Notre Dame; <a href="mailto:KKelley@ND.Edu">KKelley@ND.Edu</a>) </p>


<h3>References</h3>

 
<p>Fleishman, A. I. (1980). Confidence intervals for correlation ratios. <em>Educational and Psychological Measurement, 40</em>, 659&ndash;670.
</p>
<p>Kelley, K. (2007). Constructing confidence intervals for standardized effect sizes: Theory, application, and implementation. <em>Journal of Statistical Software, 20</em> (8), 1&ndash;24.
</p>
<p>Steiger, J. H. (2004). Beyond the <em>F</em> Test: Effect size confidence intervals and tests of close fit in the 
Analysis of Variance and Contrast Analysis. <em>Psychological Methods, 9</em>, 164&ndash;182.</p>


<h3>See Also</h3>

<p><code>conf.limits.ncf</code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
## Bargman (1970) gave an example in which a 5-group ANOVA with 11 subjects in each 
## group is conducted and the observed F value is 11.2213. This example was used 
## in Venables (1975),  Fleishman (1980), and Steiger (2004). If one wants to calculate the 
## exact confidence interval for the proportion of variance accounted for in that example, 
## this function can be used.

ci.pvaf(F.value=11.221, df.1=4, df.2=50, N=55)

ci.pvaf(F.value=11.221, df.1=4, df.2=50, N=55, conf.level=.90)

ci.pvaf(F.value=11.221, df.1=4, df.2=50, N=55,  alpha.lower=0, alpha.upper=.05)

## End(Not run)
</code></pre>

<hr>
<h2 id='ci.R'> Confidence interval for the multiple correlation coefficient </h2><span id='topic+ci.R'></span>

<h3>Description</h3>

<p>A function to obtain the confidence interval for the population multiple correlation coefficient when predictors are random (the default) or fixed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ci.R(R = NULL, df.1 = NULL, df.2 = NULL, conf.level = 0.95, 
Random.Predictors = TRUE, Random.Regressors, F.value = NULL, 
N = NULL, K=NULL, alpha.lower = NULL, alpha.upper = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ci.R_+3A_r">R</code></td>
<td>
<p>multiple correlation coefficient </p>
</td></tr>
<tr><td><code id="ci.R_+3A_df.1">df.1</code></td>
<td>
<p> numerator degrees of freedom </p>
</td></tr>
<tr><td><code id="ci.R_+3A_df.2">df.2</code></td>
<td>
<p>denominator degrees of freedom </p>
</td></tr>
<tr><td><code id="ci.R_+3A_conf.level">conf.level</code></td>
<td>
<p>confidence interval coverage (i.e., 1- Type I error rate); default is .95 </p>
</td></tr>
<tr><td><code id="ci.R_+3A_random.predictors">Random.Predictors</code></td>
<td>
<p>whether or not the predictor variables are random or fixed (random is default) </p>
</td></tr>
<tr><td><code id="ci.R_+3A_random.regressors">Random.Regressors</code></td>
<td>
<p>an alias for <code>Random.Predictors</code>; <code>Random.Regressors</code> overrides
<code>Random.Predictors</code> </p>
</td></tr>
<tr><td><code id="ci.R_+3A_f.value">F.value</code></td>
<td>
<p> obtained <em>F</em>-value </p>
</td></tr>
<tr><td><code id="ci.R_+3A_n">N</code></td>
<td>
<p>sample size </p>
</td></tr>
<tr><td><code id="ci.R_+3A_k">K</code></td>
<td>
<p>number of predictors </p>
</td></tr>
<tr><td><code id="ci.R_+3A_alpha.lower">alpha.lower</code></td>
<td>
<p>Type I error for the lower confidence limit </p>
</td></tr>
<tr><td><code id="ci.R_+3A_alpha.upper">alpha.upper</code></td>
<td>
<p>Type I error for the upper confidence limit </p>
</td></tr>
<tr><td><code id="ci.R_+3A_...">...</code></td>
<td>
<p>allows one to potentially include parameter values for inner functions </p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is based on the function <code>ci.R2</code> in MBESS package.
</p>
<p>This function can be used with random predictor variables (<code>Random.Predictors=TRUE</code>) or
when predictor variables are fixed (<code>Random.Predictors=FALSE</code>). In many applications in the behavioral,
educational, and social sciences, predictor variables are random, which is the default for this
function.
</p>
<p>For random predictors, the function implements the procedure of Lee (1971), which was implemented
by Algina and Olejnik (2000; specifically in their <em>ci.smcc.bisec.sas</em> SAS script). When 
<code>Random.Predictors=TRUE</code>, the function implements code that is in part based on the Alginia and
Olejnik (2000) SAS script.
</p>
<p>When <code>Random.Predictors=FALSE</code>, and thus the predictors are planned and thus fixed in hypothetical
replications of the study, the confidence limits are based on a noncentral <em>F</em>-distribution (see
<code>conf.limits.ncf</code>).
</p>


<h3>Value</h3>

<table>
<tr><td><code>Lower.Conf.Limit.R</code></td>
<td>
<p>lower limit of the confidence interval around the population multiple correlation coefficient</p>
</td></tr>
<tr><td><code>Prob.Less.Lower</code></td>
<td>
<p>proportion of the distribution less than <code>Lower.Conf.Limit.R</code></p>
</td></tr>
<tr><td><code>Upper.Conf.Limit.R</code></td>
<td>
<p>upper limit of the confidence interval around the population multiple correlation coefficient</p>
</td></tr>
<tr><td><code>Prob.Greater.Upper</code></td>
<td>
<p>proportion of the distribution greater than <code>Upper.Conf.Limit.R</code></p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p> Ken Kelley (University of Notre Dame; <a href="mailto:KKelley@ND.Edu">KKelley@ND.Edu</a>)</p>


<h3>References</h3>

<p>Algina, J. &amp; Olejnik, S. (2000). Determining sample size for accurate estimation of the squared
multiple correlation coefficient. <em>Multivariate Behavioral Research, 35</em>, 119&ndash;136.
</p>
<p>Lee, Y. S. (1971). Some results on the sampling distribution of the multiple correlation coefficient.
<em>Journal of the Royal Statistical Society, B, 33</em>, 117&ndash;130.
</p>
<p>Smithson, M. (2003). <em>Confidence intervals</em>. New York, NY: Sage Publications.
</p>
<p>Steiger, J. H. (2004). Beyond the <em>F</em> Test: Effect size confidence intervals and tests of close fit in the 
Analysis of Variance and Contrast Analysis. <em>Psychological Methods, 9</em>, 164&ndash;182.
</p>
<p>Steiger, J. H. &amp; Fouladi, R. T. (1992). R2: A computer program for interval estimation, power
calculation, and hypothesis testing for the squared multiple correlation. <em>Behavior research methods,
instruments and computers, 4</em>, 581&ndash;582.
</p>


<h3>See Also</h3>

 <p><code>ci.R2</code>, <code>ss.aipe.R2</code>, <code>conf.limits.nct</code> </p>

<hr>
<h2 id='ci.R2'>Confidence interval for the population squared multiple correlation coefficient</h2><span id='topic+ci.R2'></span>

<h3>Description</h3>

<p>A function to calculate the confidence interval for the population squared multiple correlation coefficient.</p>


<h3>Usage</h3>

<pre><code class='language-R'>ci.R2(R2 = NULL, df.1 = NULL, df.2 = NULL, conf.level = .95, 
Random.Predictors=TRUE, Random.Regressors, F.value = NULL, N = NULL, 
p = NULL, K, alpha.lower = NULL, alpha.upper = NULL, tol = 1e-09)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ci.R2_+3A_r2">R2</code></td>
<td>
<p>squared multiple correlation coefficient</p>
</td></tr>
<tr><td><code id="ci.R2_+3A_df.1">df.1</code></td>
<td>
<p>numerator degrees of freedom</p>
</td></tr>
<tr><td><code id="ci.R2_+3A_df.2">df.2</code></td>
<td>
<p>denominator degrees of freedom</p>
</td></tr>
<tr><td><code id="ci.R2_+3A_conf.level">conf.level</code></td>
<td>
<p>confidence interval coverage; 1-Type I error rate</p>
</td></tr>
<tr><td><code id="ci.R2_+3A_random.predictors">Random.Predictors</code></td>
<td>
<p>whether or not the predictor variables are random or fixed (random is default)</p>
</td></tr>
<tr><td><code id="ci.R2_+3A_random.regressors">Random.Regressors</code></td>
<td>
<p>an alias for <code>Random.Predictors</code>; <code>Random.Regressors</code> overrides 
<code>Random.Predictors</code></p>
</td></tr>
<tr><td><code id="ci.R2_+3A_f.value">F.value</code></td>
<td>
<p>obtained <em>F</em>-value</p>
</td></tr>
<tr><td><code id="ci.R2_+3A_n">N</code></td>
<td>
<p>sample size</p>
</td></tr>
<tr><td><code id="ci.R2_+3A_p">p</code></td>
<td>
<p>number of predictors</p>
</td></tr>
<tr><td><code id="ci.R2_+3A_k">K</code></td>
<td>
<p>alias for <code>p</code>, the number of predictors</p>
</td></tr>
<tr><td><code id="ci.R2_+3A_alpha.lower">alpha.lower</code></td>
<td>
<p>Type I error for the lower confidence limit</p>
</td></tr>
<tr><td><code id="ci.R2_+3A_alpha.upper">alpha.upper</code></td>
<td>
<p>Type I error for the upper confidence limit</p>
</td></tr>
<tr><td><code id="ci.R2_+3A_tol">tol</code></td>
<td>
<p>tolerance for iterative convergence</p>
</td></tr></table>


<h3>Details</h3>

<p>This function can be used with random predictor variables (<code>Random.Predictors=TRUE</code>) or when predictor
variables are fixed (<code>Random.Predictors=FALSE</code>). In many applications of multiple regression, 
predictor variables are random, which is the default in this function. 
</p>
<p>For random predictors, the function implements the procedure of Lee (1971), which was implemented by 
Algina and Olejnik (2000; specifically in their <em>ci.smcc.bisec.sas</em> SAS script). When <code>Random.Predictors=TRUE</code>,
the function implements code that is in part based on the Alginia and Olejnik (2000) SAS script. 
</p>
<p>When <code>Random.Predictors=FALSE</code>, and thus the predictors are planned and thus fixed in 
hypothetical replications of the study, the confidence limits are based on a
noncentral <code class="reqn">F</code>-distribution (see <code>conf.limits.ncf</code>).
</p>


<h3>Value</h3>

<table>
<tr><td><code>Lower.Conf.Limit.R2</code></td>
<td>
<p>upper limit of the confidence interval around the population multiple correlation coefficient</p>
</td></tr>
<tr><td><code>Prob.Less.Lower</code></td>
<td>
<p>proportion of the distribution less than <code>Lower.Conf.Limit.R2</code></p>
</td></tr>
<tr><td><code>Upper.Conf.Limit.R2</code></td>
<td>
<p>upper limit of the confidence interval around the population multiple correlation coefficient</p>
</td></tr>
<tr><td><code>Prob.Greater.Upper</code></td>
<td>
<p>proportion of the distribution greater than <code>Upper.Conf.Limit.R2</code></p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Ken Kelley (University of Notre Dame; <a href="mailto:KKelley@ND.Edu">KKelley@ND.Edu</a>)</p>


<h3>References</h3>

<p>Algina, J. &amp; Olejnik, S. (2000). Determining Sample Size for Accurate Estimation of 
the Squared Multiple Correlation Coefficient. <em>Multivariate Behavioral Research, 35</em>, 
119&ndash;136.
</p>
<p>Kelley, K. (2007). Constructing confidence intervals for standardized effect sizes: Theory, application, and implementation. <em>Journal of Statistical Software, 20</em> (8), 1&ndash;24.
</p>
<p>Lee, Y. S. (1971). Some results on the sampling distribution of the multiple correlation coefficient.
<em>Journal of the Royal Statistical Society, B, 33</em>, 117&ndash;130.
</p>
<p>Smithson, M. (2003). <em>Confidence intervals</em>. New York, NY: Sage Publications. 
</p>
<p>Steiger, J. H. &amp; Fouladi, R. T. (1992) R2: A computer program for interval estimation, power calculation,
and hypothesis testing for the squared multiple correlation. <em>Behavior research methods, instruments and computers, 4</em>, 581&ndash;582.
</p>


<h3>See Also</h3>

<p><code>ss.aipe.R2</code>, <code>conf.limits.ncf</code></p>


<h3>Examples</h3>

<pre><code class='language-R'># For random predictor variables.
# ci.R2(R2=.25, N=100, K=5, conf.level=.95, Random.Predictors=TRUE)

# ci.R2(F.value=6.266667, N=100, K=5, conf.level=.95, Random.Predictors=TRUE)

# For fixed predictor variables.
# ci.R2(R2=.25, N=100, K=5, conf.level=.95, Random.Predictors=TRUE)

# ci.R2(F.value=6.266667, N=100, K=5, conf.level=.95, Random.Predictors=TRUE)

# One sided confidence intervals when predictors are random.
# ci.R2(R2=.25, N=100, K=5, alpha.lower=.05, alpha.upper=0, conf.level=NULL,
# Random.Predictors=TRUE)

# ci.R2(R2=.25, N=100, K=5, alpha.lower=0, alpha.upper=.05, conf.level=NULL,
# Random.Predictors=TRUE)

# One sided confidence intervals when predictors are fixed.
# ci.R2(R2=.25, N=100, K=5, alpha.lower=.05, alpha.upper=0, conf.level=NULL,
# Random.Predictors=FALSE)

# ci.R2(R2=.25, N=100, K=5, alpha.lower=0, alpha.upper=.05, conf.level=NULL,
# Random.Predictors=FALSE)
</code></pre>

<hr>
<h2 id='ci.rc'> Confidence Interval for a Regression Coefficient </h2><span id='topic+ci.rc'></span>

<h3>Description</h3>

<p>A function to calculate a confidence interval for the population regression coefficient of interest
using the standard approach and the noncentral approach when the regression coefficients are
standardized.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ci.rc(b.k, SE.b.k = NULL, s.Y = NULL, s.X = NULL, N, K, R2.Y_X = NULL, 
R2.k_X.without.k = NULL, conf.level = 0.95, R2.Y_X.without.k = NULL, 
t.value = NULL, alpha.lower = NULL, alpha.upper = NULL, 
Noncentral = FALSE, Suppress.Statement = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ci.rc_+3A_b.k">b.k</code></td>
<td>
<p> value of the regression coefficient for the <em>k</em>th predictor variable </p>
</td></tr>
<tr><td><code id="ci.rc_+3A_se.b.k">SE.b.k</code></td>
<td>
<p> standard error for the <em>k</em>th predictor variable </p>
</td></tr>
<tr><td><code id="ci.rc_+3A_s.y">s.Y</code></td>
<td>
<p> standard deviation of <em>Y</em>, the dependent variable </p>
</td></tr>
<tr><td><code id="ci.rc_+3A_s.x">s.X</code></td>
<td>
<p> standard deviation of <em>X</em>, the predictor variable of interest </p>
</td></tr>
<tr><td><code id="ci.rc_+3A_n">N</code></td>
<td>
<p> sample size </p>
</td></tr>
<tr><td><code id="ci.rc_+3A_k">K</code></td>
<td>
<p>the number of predictors </p>
</td></tr>
<tr><td><code id="ci.rc_+3A_r2.y_x">R2.Y_X</code></td>
<td>
<p> the squared multiple correlation coefficient predicting <em>Y</em> from the <em>k</em> predictor variables </p>
</td></tr>
<tr><td><code id="ci.rc_+3A_r2.k_x.without.k">R2.k_X.without.k</code></td>
<td>
<p> the squared multiple correlation coefficient predicting the <em>k</em>th predictor variable
(i.e., the predictor of interest) from the remaining <em>K</em>-1 predictor variables </p>
</td></tr>
<tr><td><code id="ci.rc_+3A_conf.level">conf.level</code></td>
<td>
<p> desired level of confidence for the computed interval (i.e., 1 - the Type I error rate)</p>
</td></tr>
<tr><td><code id="ci.rc_+3A_r2.y_x.without.k">R2.Y_X.without.k</code></td>
<td>
<p> the squared multiple correlation coefficient predicting <em>Y</em> from the <em>K</em>-1 predictor
variable with the <em>k</em>th predictor of interest excluded </p>
</td></tr>
<tr><td><code id="ci.rc_+3A_t.value">t.value</code></td>
<td>
<p> the <em>t</em>-value evaluating the null hypothesis that the population regression coefficient
for the <em>k</em>th predictor equals zero </p>
</td></tr>
<tr><td><code id="ci.rc_+3A_alpha.lower">alpha.lower</code></td>
<td>
<p> the Type I error rate for the lower confidence interval limit </p>
</td></tr>
<tr><td><code id="ci.rc_+3A_alpha.upper">alpha.upper</code></td>
<td>
<p> the Type I error rate for the upper confidence interval limit </p>
</td></tr>
<tr><td><code id="ci.rc_+3A_noncentral">Noncentral</code></td>
<td>
 <p><code>TRUE</code> or <code>FALSE</code> statement specifying whether or not the noncentral approach to
confidence intervals should be used </p>
</td></tr>
<tr><td><code id="ci.rc_+3A_suppress.statement">Suppress.Statement</code></td>
<td>
<p><code>TRUE</code> or <code>FALSE</code> statement specifying whether or not a statement should be printed
that identifies the type of confidence interval formed</p>
</td></tr>
<tr><td><code id="ci.rc_+3A_...">...</code></td>
<td>
<p> optional additional specifications for nested functions </p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function calls upon <code>ci.reg.coef</code> in MBESS, but has a different naming system. See <code>ci.reg.coef</code> for more details.
</p>
<p>For standardized variables, do not specify the standard deviation of the variables and input the
standardized regression coefficient for <code>b.k</code>.
</p>


<h3>Value</h3>

<p>Returns the confidence limits for the standardized regression coefficients of interest from the standard
approach to confidence interval formation or from the noncentral approach to confidence interval
formation using the noncentral <em>t</em>-distribution.
</p>


<h3>Note</h3>

<p> Not all of the values need to be specified, only those that contain all of the necessary information
in order to compute the confidence interval (options are thus given for the values that need to be
specified).
</p>


<h3>Author(s)</h3>

<p> Ken Kelley (University of Notre Dame; <a href="mailto:KKelley@ND.Edu">KKelley@ND.Edu</a>) </p>


<h3>References</h3>

 
<p>Kelley, K. (2007). Confidence intervals for standardized effect sizes: Theory, application, 
and implementation.<em> Journal of Statistical Software, 20</em>(8), 1&ndash;24.
</p>
<p>Kelley, K. &amp; Maxwell, S. E. (2003). Sample size for Multiple Regression: Obtaining regression
coefficients that are accurate, not simply significant.<em> Psychological Methods, 8</em>, 305&ndash;321.
</p>
<p>Kelley, K. &amp; Maxwell, S. E. (2008). Power and accuracy for omnibus and targeted effects:
Issues of sample size planning with applications to Multiple Regression. <em>Handbook of Social Research
Methods</em>, J. Brannon, P. Alasuutari, and L. Bickman (Eds.). New York, NY: Sage Publications.
</p>
<p>Smithson, M. (2003). <em>Confidence intervals</em>. New York, NY: Sage Publications. 
</p>
<p>Steiger, J. H. (2004). Beyond the <em>F</em> Test: Effect size confidence intervals and tests of close fit in the 
Analysis of Variance and Contrast Analysis. <em>Psychological Methods, 9</em>, 164&ndash;182.</p>


<h3>See Also</h3>

 <p><code>ss.aipe.reg.coef</code>, <code>conf.limits.nct</code>, <code>ci.reg.coef</code>, <code>ci.src</code> </p>

<hr>
<h2 id='ci.reg.coef'>Confidence interval for a regression coefficient</h2><span id='topic+ci.reg.coef'></span>

<h3>Description</h3>

<p>A function to calculate a confidence interval around the population 
regression coefficient of interest using the standard approach and the noncentral
approach when the regression coefficients are standardized.</p>


<h3>Usage</h3>

<pre><code class='language-R'>ci.reg.coef(b.j, SE.b.j=NULL, s.Y=NULL, s.X=NULL, N, p, R2.Y_X=NULL,
R2.j_X.without.j=NULL, conf.level=0.95, R2.Y_X.without.j=NULL, 
t.value=NULL, alpha.lower=NULL, alpha.upper=NULL, Noncentral=FALSE, 
Suppress.Statement=FALSE, ...)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ci.reg.coef_+3A_b.j">b.j</code></td>
<td>
<p>value of the regression coefficient for the <em>j</em>th predictor variable</p>
</td></tr>
<tr><td><code id="ci.reg.coef_+3A_se.b.j">SE.b.j</code></td>
<td>
<p>standard error for the <em>j</em>th predictor variable</p>
</td></tr>
<tr><td><code id="ci.reg.coef_+3A_s.y">s.Y</code></td>
<td>
<p>standard deviation of <em>Y</em>, the dependent variable</p>
</td></tr>
<tr><td><code id="ci.reg.coef_+3A_s.x">s.X</code></td>
<td>
<p>standard deviation of <code class="reqn">X_j</code>, the predictor variable of interest</p>
</td></tr>
<tr><td><code id="ci.reg.coef_+3A_n">N</code></td>
<td>
<p>sample size</p>
</td></tr>
<tr><td><code id="ci.reg.coef_+3A_p">p</code></td>
<td>
<p>the number of predictors</p>
</td></tr>
<tr><td><code id="ci.reg.coef_+3A_r2.y_x">R2.Y_X</code></td>
<td>
<p>the squared multiple correlation coefficient predicting <code>Y</code> from the <code>p</code> predictor variables</p>
</td></tr>
<tr><td><code id="ci.reg.coef_+3A_r2.j_x.without.j">R2.j_X.without.j</code></td>
<td>
<p>the squared multiple correlation coefficient predicting the <em><code>j</code></em>th predictor variable (i.e., the predictor of interest) from the remaining <code>p</code>-1 predictor variables</p>
</td></tr>
<tr><td><code id="ci.reg.coef_+3A_conf.level">conf.level</code></td>
<td>
<p>desired level of confidence for the computed interval (i.e., 1 - the Type I error rate)</p>
</td></tr>
<tr><td><code id="ci.reg.coef_+3A_r2.y_x.without.j">R2.Y_X.without.j</code></td>
<td>
<p>the squared multiple correlation coefficient predicting <code>Y</code> from the <em><code>p</code></em>-1 predictor variable with the <code>j</code>th predictor of interest excluded</p>
</td></tr>
<tr><td><code id="ci.reg.coef_+3A_t.value">t.value</code></td>
<td>
<p>the <em>t</em>-value evaluating the null hypothesis that the population regression coefficient for the <code>j</code>th predictor equals zero</p>
</td></tr>
<tr><td><code id="ci.reg.coef_+3A_alpha.lower">alpha.lower</code></td>
<td>
<p>the Type I error rate for the lower confidence interval limit</p>
</td></tr>
<tr><td><code id="ci.reg.coef_+3A_alpha.upper">alpha.upper</code></td>
<td>
<p>the Type I error rate for the upper confidence interval limit</p>
</td></tr>
<tr><td><code id="ci.reg.coef_+3A_noncentral">Noncentral</code></td>
<td>
<p><code>TRUE</code> or <code>FALSE</code>, specifying whether or not the noncentral approach to confidence intervals should be used</p>
</td></tr>
<tr><td><code id="ci.reg.coef_+3A_suppress.statement">Suppress.Statement</code></td>
<td>
<p><code>TRUE</code>/<code>FALSE</code> statement specifying whether or not a statement should be printed that identifies the type of confidence interval formed</p>
</td></tr>
<tr><td><code id="ci.reg.coef_+3A_...">...</code></td>
<td>
<p>optional additional specifications for nested functions</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For standardized variables, do not specify the standard deviation of the variables and input the standardized
regression coefficient for <code>b.j</code>.</p>


<h3>Value</h3>

<p>Returns the confidence limits specified for the regression coefficient of interest from the standard approach to confidence interval formation or from the noncentral approach to confidence interval formation using the noncentral <em>t</em>-distribution.</p>


<h3>Note</h3>

<p>Not all of the values need to be specified, only those that
contain all of the necessary information in order to compute the
confidence interval (options are thus given for the values that need
to be specified).
</p>
<p>The function <code>ci.rc</code> in MBESS also calculates the confidence interval
for the population (unstandardized) regression coefficient. The 
function <code>ci.src</code> also calculates the confidence interval
for the population (standardized) regression coefficient. These two 
functions perform the same tasks as <code>ci.reg.coef</code> does and 
are preferred to it because of simpler arguments.
</p>


<h3>Author(s)</h3>

<p>Ken Kelley (University of Notre Dame; <a href="mailto:KKelley@ND.Edu">KKelley@ND.Edu</a>) </p>


<h3>References</h3>

<p>Kelley, K. &amp; Maxwell, S. E. (2003). Sample size for Multiple Regression: Obtaining regression coefficients that are accurate, not simply significant. 
<em>Psychological Methods, 8</em>, 305&ndash;321.
</p>
<p>Kelley, K. &amp; Maxwell, S. E. (2008). Sample Size Planning with applications to multiple regression: Power and accuracy for omnibus and targeted effects. In P. Alasuuta, J. Brannen, &amp; L. Bickman (Eds.), <em>The Sage handbook of social research methods</em> (pp. 166&ndash;192). Newbury Park, CA: Sage.
</p>
<p>Smithson, M. (2003). <em>Confidence intervals</em>. New York, NY: Sage Publications. 
</p>


<h3>See Also</h3>

<p><code>ss.aipe.reg.coef</code>, <code>conf.limits.nct</code>, <code>ci.rc</code>, <code>ci.src</code>
</p>

<hr>
<h2 id='ci.reliability'>Confidence Interval for a Reliability Coefficient </h2><span id='topic+ci.reliability'></span>

<h3>Description</h3>

<p>A function to calculate the point estimate and confidence interval for a reliability coefficient (alpha, omega, and variations thereof). Please see the many options; the defaults may not be best for your situation. See Kelley and Pornprasertmanit (2016) for recommendation and a discussion of the methods, where they ultimately recommend the bias-corrected and accelerated bootstrap (<code>interval.type="bca"</code> with hierarchical omega (<code>type="hierarchical"</code>) for continuous items.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ci.reliability(data = NULL, S = NULL, N = NULL, aux = NULL, 
type = "omega", interval.type = "default", B = 10000, conf.level = 0.95)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ci.reliability_+3A_data">data</code></td>
<td>
<p>The data set that the reliability coefficient is obtained from. The full data set is required for categorical omega. Also, the full data set is required for bootstrap confidence intervals or asymptotic distribution free confidence interval.</p>
</td></tr>
<tr><td><code id="ci.reliability_+3A_s">S</code></td>
<td>
<p>Symmetric covariance matrix. Correlation matrix can be specified here but not recommended because, in the function, Confirmatory Factor Analysis (CFA) is analyzed based on covariance matrix.</p>
</td></tr>
<tr><td><code id="ci.reliability_+3A_n">N</code></td>
<td>
<p>The total sample size. Sample size is needed only that <code>S</code> is specified.</p>
</td></tr>
<tr><td><code id="ci.reliability_+3A_aux">aux</code></td>
<td>
<p>The names of auxiliary variables. Auxiliary variables will not be used as a composite but they will be used to handle missing observations. Note that full information maximum likelihood is used if auxiliary variables are specified. See <a href="semTools.html#topic+auxiliary">auxiliary</a> for further details.</p>
</td></tr>
<tr><td><code id="ci.reliability_+3A_type">type</code></td>
<td>
<p>The type of reliability coefficient to be calculated: <code>"alpha"</code> or <code>1</code> for coefficient alpha analyzed by the formula proposed by Cronbach (1951), <code>"alpha-cfa"</code> or <code>2</code> for coefficient alpha analyzed by CFA with tau-equivalence (method of estimator depending on confidence interval method but none of them is unweighted least square so technically the result is not equal to the formula from Cronbach), <code>"omega"</code> for coefficient omega, <code>"hierarchical"</code> for hierarchical omega, <code>"categorical"</code> for categorical omega. If  <code>type</code> is specified as <code>NULL</code>, the default is to use hierarchical omega for continuous items and categorical omega for categorical items. The default, however, is simply <code>"omega"</code>.</p>
</td></tr>
<tr><td><code id="ci.reliability_+3A_interval.type">interval.type</code></td>
<td>
<p>There are 13 options for the methods. See <code>details</code> below. Based on our simulation studies (Kelley and Pornprasertmanit, 2016), bias corrected and accelerated bootstrap, <code>"bca"</code>, is recommended for categorical omega. Any bootstrap approaches (e.g., <code>"bca"</code> or <code>"perc"</code>) are recommended for hierarchical omega, coefficient omega, and coefficient alpha.</p>
</td></tr>
<tr><td><code id="ci.reliability_+3A_b">B</code></td>
<td>
<p>the number of bootstrap replications</p>
</td></tr>
<tr><td><code id="ci.reliability_+3A_conf.level">conf.level</code></td>
<td>
<p> the confidence level (i.e., 1-Type I error rate)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>When coefficient alpha is used, the measurement model is assumed to be true-score equivalent (or tau equivalent) model such that factor loadings are equal across items. When the coefficient omega, hierarchical omega, and categorical omega are used, the measurement model is assumed to be congeneric model (i.e., one-factor confirmatory factor analysis model). Coefficient omega assumes that a model fits data perfectly so the variance of the composite scores is calculated from model-implied covariance matrix. However, hierarchical omega allows a model to not fit data perfectly (Kelley and Pornprasertmanit, in press). Categorical omega is a method to calculate coefficient omega for categorical items (Green and Yang, 2009). That is, categorical omega is estimated by the parameter estimates from CFA for categorical items. If coefficient omega or hierarchical omega is used, CFA for continuous items is used, which is not appropriate for categorical items.
</p>
<p>If researchers wish to make the measurement model with all parallel items (equal factor loadings and equal error variances), users can specify it by setting <code>interval.type = "parallel"</code> and <code>type = "alpha"</code> or <code>type = "alpha-cfa"</code>. See McDonald (1999) for the assumptions of each of these models.  
</p>
<p>The list below shows all methods to find the confidence interval of reliability. 
</p>

<ol>
<li> <p><code>"none"</code> or <code>0</code> to not find any confidence interval
</p>
</li>
<li> <p><code>"parallel"</code> or <code>11</code> to assume that the items are parallel and analyze confidence interval based on Wald confidence interval (see van Zyl, Neudecker, &amp; Nel, 2000, Equation 22; also referred as the asymptotic method of Koning &amp; Franses, 2003).
</p>
</li>
<li> <p><code>"feldt"</code> or <code>12</code> is based on that <code class="reqn">\frac{1 - \alpha}{1 - \hat{\alpha}}</code> is distributed as <code class="reqn">F</code> distribution with the degree of freedoms of <code class="reqn">N - 1</code> and <code class="reqn">(N - 1) \times (p - 1)</code> (Feldt, 1965).
</p>
</li>
<li> <p><code>"siotani"</code> or <code>13</code> is the same as the <code>"feldt"</code> method but using the degree of freedoms of <code class="reqn">N</code> and <code class="reqn">N \times (p - 1)</code> (Siotani, Hayakawa, &amp; Fujikoshi, 1985; van Zyl et al., 2000, Equations 7 and 8; also referred as the exact method of Koning &amp; Franses, 2003).
</p>
</li>
<li> <p><code>"fisher"</code> or <code>21</code> for the Fisher's <code class="reqn">z</code> transformation on the correlation coefficient approach, <code class="reqn">z = 0.5 \times \log{\frac{1 + \alpha}{1 - \alpha}}</code>, directly on the coefficient alpha and find confidence interval of transformed scale (Fisher, 1950). The variance of the <code class="reqn">z</code> is <code class="reqn">\frac{1}{N - 3}</code> where <code class="reqn">N</code> is the total sample size.
</p>
</li>
<li> <p><code>"bonett"</code> or <code>22</code> for the Fisher's <code class="reqn">z</code> transformation on the intraclass correlation approach with the variance of <code class="reqn">\frac{2p}{(N - 2)(p - 1)}</code> (Bonett, 2002, Equation 6).
</p>
</li>
<li> <p><code>"hakstian"</code> or <code>23</code> uses the cube root transformation and assumes normal distribution on the cube root transformation (Hakstian &amp; Whalen, 1976). The variance of the transformed reliability is based on the degrees of freedom in the <code>"feldt"</code> method.
</p>
</li>
<li> <p><code>"hakstianbarchard"</code> or <code>24</code> uses a correction of the violation of compound symmetry of covariance matrix by adjusting the degrees of freedom in the <code>"hakstian"</code>. This correction is used for the inference in type 12 sampling (both persons and items are sampled from the population of persons and items) See Hakstian and Barchard (2000) for further details.
</p>
</li>
<li> <p><code>"icc"</code> or <code>25</code> for the Fisher's <code class="reqn">z</code> transformation on the intraclass correlation approach, <code class="reqn">z = \log{1 - \alpha}</code>. The variance of the <code class="reqn">z</code> is <code class="reqn">\frac{2p}{N(p - 1)}</code> where <code class="reqn">p</code> is the number of items (Fisher, 1991, p. 221; van Zyl et al., 2000, p. 277).
</p>
</li>
<li> <p><code>"ml"</code> or <code>31</code> or <code>normal-theory</code> to analyze the confidence interval based on normal-theory approach (or multivariate delta method). See van Zyl, Neudecker, &amp; Nel (2000, Equation 21) for the confidence interval of coefficient alpha (also be referred as Iacobucci &amp; Duhachek's, 2003, method). See Raykov (2002) for details for coefficient omega. If users use <code>type="alpha-cfa"</code>, the <code>sem</code> package will be used to obtain parameter estimates and standard errors used for the formula proposed by Raykov (2002).
</p>
</li>
<li> <p><code>"mll"</code> or <code>32</code> to analyze the confidence interval based on normal-theory approach as above. However, the point estimate and standard error were used to build confidence interval using logistic transformation as the note below.
</p>
</li>
<li> <p><code>"mlr"</code> or <code>33</code> to analyze the confidence interval based on normal-theory approach (or multivariate delta method). However, the estimation method uses  robust standard errors (Satorra and Bentler, 2000). This is the default estimation approach (but see Kelley and Pornprasertmanit (2016) who recommend the BCa bootstrap [which is <code>bca</code>])
</p>
</li>
<li> <p><code>"mlrl"</code> or <code>34</code> to analyze he confidence interval based on normal-theory approach using robust standard error and logistic transformation (see below). 
</p>
</li>
<li> <p><code>"adf"</code> or <code>35</code> for asymptotic distribution-free method (see Maydeu-Olivares, Coffman, &amp; Hartman, 2007 for further details for coefficient omega; we use phantom variable approach, Cheung, 2009, and <code>"WLS"</code> estimator for coefficient omega, Browne, 1984, in the <code>lavaan</code> package, Rosseel, 2012).
</p>
</li>
<li> <p><code>"adfl"</code> or <code>36</code> to use asymptotic distribution-free method to derive standard error and parameter estimate. Then, logistic transformation is used to build confidence interval (see below).
</p>
</li>
<li> <p><code>"ll"</code> or <code>37</code> for profile likelihood-based confidence interval of both reliability coefficients (Cheung, 2009) analyzed by the <code>OpenMx</code> package (Boker et al., 2011)
</p>
</li>
<li> <p><code>"bsi"</code> or <code>41</code> for standard bootstrap confidence interval which finds the standard deviation across the bootstrap estimates, multiply the standard deviation by critical value, and add and subtract from the reliability estimate.
</p>
</li>
<li> <p><code>"bsil"</code> or <code>42</code> to use standard bootstrap confidence interval. However, logistic transformation is used to build confidence interval.
</p>
</li>
<li> <p><code>"perc"</code> or <code>43</code> for percentile bootstrap confidence interval.
</p>
</li>
<li> <p><code>"bca"</code> or <code>44</code> for bias-corrected and accelerated bootstrap confidence interval.
</p>
</li></ol>

<p>The logistic transformation (Browne, 1982) is applicable for <code>"ml"</code>, <code>"mlr"</code>, <code>"adf"</code>, and <code>"bsi"</code> as <code>"mll"</code>, <code>"mlrl"</code>, <code>"adfl"</code>, and <code>"bsil"</code>. The logistic transformation does not assume that the sampling distribution of reliability is symmetric. It acknowledges the fact that reliability ranges from 0 and 1. Logistic transformation is applied to the reliability estimates. Confidence interval is established for the transformed value. The lower and upper bounds of the transformed value is translated back to the reliability estimates. See Browne (1982) or Kelley and Pornprasertmanit (in press) for further details.
</p>
<p>Note that not all confidence interval methods are available for all types of reliability and all types of input. For example, bootstrap confidence intervals are not available for covariance matrix input. Parallel confidence intervals are not available for hierarchical omega. We provided appropriate error messages for all impossible combinations. 
</p>


<h3>Value</h3>

<table>
<tr><td><code>est</code></td>
<td>
<p>The estimated reliability coefficient</p>
</td></tr>
<tr><td><code>se</code></td>
<td>
<p>The standard error of the reliability coefficient. If the bootstrap methods are used, this value represents the standard deviation across bootstrap estimates.</p>
</td></tr>
<tr><td><code>ci.lower</code></td>
<td>
<p>The lower bound of the computed confidence interval</p>
</td></tr>
<tr><td><code>ci.upper</code></td>
<td>
<p>The upper bound of the computed confidence interval</p>
</td></tr>
<tr><td><code>conf.Level</code></td>
<td>
<p>The confidence level (i.e., 1 - Type I error rate)</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>The type of estimated reliability coefficient (alpha or omega)</p>
</td></tr>
<tr><td><code>interval.type</code></td>
<td>
<p>The method used to find confidence interval</p>
</td></tr>
</table>


<h3>Note</h3>

<p>This function is not compatible with code from MBESS Version 3.</p>


<h3>Author(s)</h3>

<p>Sunthud Pornprasertmanit (Texas Tech University; <a href="mailto:sunthud.pornprasertmanit@ttu.edu">sunthud.pornprasertmanit@ttu.edu</a>) and Ken Kelley (University of Notre Dame; <a href="mailto:kkelley@nd.edu">kkelley@nd.edu</a>. The previous version was written by Keke Lai (University of California-Merced), Leann J. Terry (while at Indiana University), and Ken Kelley</p>


<h3>References</h3>

 
<p>Boker, S., M., N., Maes, H., Wilde, M., Spiegel, M., Brick, T., et al. (2011).
OpenMx: An open source extended structural equation modeling framework.
<em>Psychometrika, 76,</em> 306&ndash;317.
</p>
<p>Bonett, D. G. (2002). Sample size requirements for testing and estimating coefficient
alpha. <em>Journal of Educational and Behavioral Statistics, 27,</em> 335&ndash;340.
</p>
<p>Browne, M. W. (1982). Covariance structures. In D. M. Hawkins (Ed.), <em>Topics 
in applied multivariate analysis</em> (pp. 72&ndash;141). Cambridge, UK: Cambridge University Press.
</p>
<p>Browne, M. W. (1984). Asymptotic distribution free methods in the analysis of
covariance structures. <em>British Journal of Mathematical and Statistical
Psychology, 24,</em> 445&ndash;455.
</p>
<p>Cheung, M. W.-L. (2009). Constructing approximate confidence intervals for
parameters with structural constructing approximate confidence intervals for
parameters with structural equation models. <em>Structural Equation Modeling,
16,</em> 267&ndash;294.
</p>
<p>Feldt, L.S. (1965). The approximate sampling distribution of Kuder-Richardson reliability coefficient twenty. <em>Psychometrika,
30</em>, 357&ndash;370.
</p>
<p>Fisher, R. A. (1950). <em>Statistical methods for research workers.</em> Edinburgh, UK:
Oliver &amp; Boyd.
</p>
<p>Fisher, R. A. (1991). Statistical methods for research workers. In J.H. Bennett (Ed.), <em>Statistical methods, experimental
design, and scientific inference.</em> Oxford: Oxford University Press.
</p>
<p>Green, S. B., &amp; Yang, Y. (2009). Reliability of summed item scores using structural equation modeling: 
An alternative to coefficient alpha. <em>Psychometrika, 74,</em> 155&ndash;167. 
</p>
<p>Hakstian, A. R., &amp; Whalen, T. E. (1976). A k-sample significance test for independent alpha
coefficients. <em>Psychometrika, 41,</em> 219&ndash;231.
</p>
<p>Iacobucci, D., &amp; Duhachek, A. (2003). Advancing alpha: measuring reliability with confidence.
<em>Journal of Consumer Psychology, 13,</em> 478&ndash;487.
</p>
<p>Kelley, K. &amp; Pornprasertmanit, P. (2016). Confidence intervals for population reliability coefficients: Evaluation of methods, recommendations, and software for homogeneous composite measures. <em>Psychological Methods, 21,</em> 69&ndash;92.
</p>
<p>Koning, A. J., &amp; Franses, P. H. (2003). <em>Confidence intervals for Cronbach's coefficient
alpha values</em> (ERIM Report Series Ref. No. ERS-2003-041-MKT). Rotterdam, The Netherlands:
Erasmus Research Institute of Management.
</p>
<p>Maydeu-Olivares, A., Coffman, D. L., &amp; Hartmann, W. M. (2007). Asymptotically
distribution-free (ADF) interval estimation of coefficient alpha. <em>Psychological
Methods, 12,</em> 157&ndash;176.
</p>
<p>McDonald, R. P. (1999). <em>Test theory: A unified approach</em>. Mahwah, New Jersey: Lawrence 
Erlbaum Associates, Publishers.
</p>
<p>Raykov, T. (2002). Analytic estimation of standard error and confidence interval
for scale reliability. <em>Multivariate Behavioral Research, 37,</em> 89&ndash;103.
</p>
<p>Rosseel, Y. (2012). lavaan: An R package for structural equation modeling. <em>Journal of Statistical Software, 48,</em> 1&ndash;36.
</p>
<p>Satorra, A. &amp; Bentler, P. M. (2001). A scaled difference chi-square test statistic for moment structure analysis. <em>Psychometrika, 66,</em> 507&ndash;514.
</p>
<p>Siotani, M., Hayakawa, T., &amp; Fujikoshi, Y. (1985). <em>Modem multivariate statistical analysis: A graduate course and
handbook</em>. Columbus, Ohio: American Sciences Press.
</p>
<p>van Zyl, J. M., Neudecker, H., &amp; Nel, D. G. (2000). On the distribution of the maximum likelihood estimator 
of Cronbach's alpha. <em>Psychometrika, 65</em> (3), 271&ndash;280.
</p>
<p>Yuan, K. &amp; Bentler, P. M. (2002). On robustness of the normal-theory based asymptotic distributions of three
reliability coefficient estimates. <em>Psychometrika, 67</em> (2), 251&ndash;259.
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+CFA.1">CFA.1</a></code>; <code><a href="sem.html#topic+sem">sem</a></code>; <code><a href="lavaan.html#topic+lavaan">lavaan</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'># Use this function for the attitude dataset (ignoring the overall rating variable)
# ci.reliability(data=attitude[,-1], type = "omega", interval.type = "mlrl")

# ci.reliability(data=attitude[,-1], type = "alpha", interval.type = "ll")


## Forming a hypothetical population covariance matrix
# Pop.Cov.Mat &lt;- matrix(.3, 9, 9)
# diag(Pop.Cov.Mat) &lt;- 1
# ci.reliability(S=Pop.Cov.Mat, N=50, type="alpha", interval.type = "bonett")
</code></pre>

<hr>
<h2 id='ci.rmsea'>Confidence interval for the population root mean square error of approximation</h2><span id='topic+ci.rmsea'></span>

<h3>Description</h3>

<p>Confidence interval for the population root mean square error of approximation (RMSEA).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ci.rmsea(rmsea, df, N, conf.level = 0.95, alpha.lower = NULL, 
alpha.upper = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ci.rmsea_+3A_rmsea">rmsea</code></td>
<td>
<p>observed root mean square error of approximation</p>
</td></tr>  
<tr><td><code id="ci.rmsea_+3A_df">df</code></td>
<td>
<p>degrees of freedom of the model</p>
</td></tr>
<tr><td><code id="ci.rmsea_+3A_n">N</code></td>
<td>
<p>sample size</p>
</td></tr>
<tr><td><code id="ci.rmsea_+3A_conf.level">conf.level</code></td>
<td>
<p>desired confidence level (e.g., .90, .95, .99)</p>
</td></tr>
<tr><td><code id="ci.rmsea_+3A_alpha.lower">alpha.lower</code></td>
<td>
<p> the Type I error rate for the lower tail </p>
</td></tr>
<tr><td><code id="ci.rmsea_+3A_alpha.upper">alpha.upper</code></td>
<td>
<p> the Type I error rate for the upper tail </p>
</td></tr>
</table>


<h3>Details</h3>

<p>Provides a confidence interval for the population root mean square error of approximation (RMSEA) using the noncentral chi-square distribution (e.g., Steiger &amp; Lind, 1980).
</p>


<h3>Value</h3>

<p>returns the upper and lower limit as well as the observed value of the RMSEA.
</p>


<h3>Author(s)</h3>

<p> Ken Kelley (University of Notre Dame; <a href="mailto:KKelley@ND.Edu">KKelley@ND.Edu</a>) </p>


<h3>References</h3>

 
<p>Steiger, J. H., &amp; Lind, J. C. (1980). <em>Statistically-based tests for the number of common 
factors</em>. Paper presented at the annual Spring meeting of the Psychometric Society, Iowa City, IA.
</p>

<hr>
<h2 id='ci.sc'> Confidence Interval for a Standardized Contrast in a Fixed Effects ANOVA</h2><span id='topic+ci.sc'></span>

<h3>Description</h3>

<p>Function to obtain the confidence interval for a standardized contrast in a fixed effects analysis of variance context.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ci.sc(means = NULL, s.anova = NULL, c.weights = NULL, n = NULL, 
N = NULL, Psi = NULL, ncp = NULL, conf.level = 0.95, 
alpha.lower = NULL, alpha.upper = NULL, df.error = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ci.sc_+3A_means">means</code></td>
<td>
<p> a vector of the group means or the means of the particular
level of the effect (for fixed effect designs) </p>
</td></tr>
<tr><td><code id="ci.sc_+3A_s.anova">s.anova</code></td>
<td>
<p>the standard deviation of the errors from the ANOVA model (i.e., the square root of the mean square error)</p>
</td></tr>
<tr><td><code id="ci.sc_+3A_c.weights">c.weights</code></td>
<td>
<p>the contrast weights (chose weights so that the positive <em>c</em>-weights sum to 1 and the negative <em>c</em>-weights sum to -1; i.e., use fractional values not integers).</p>
</td></tr>
<tr><td><code id="ci.sc_+3A_n">n</code></td>
<td>
<p> sample sizes <em>per group</em> or sample sizes for the level of the particular factor (if length 1 it is 
assumed that the sample size <em>per group</em> or for the level of the particular factor are are equal) </p>
</td></tr>
<tr><td><code id="ci.sc_+3A_n">N</code></td>
<td>
<p> total sample size </p>
</td></tr>
<tr><td><code id="ci.sc_+3A_psi">Psi</code></td>
<td>
<p> the (unstandardized) contrast effect, obtained by multiplying the <em>j</em>th mean 
by the <em>j</em>th contrast weight (this is the unstandardized effect) </p>
</td></tr>
<tr><td><code id="ci.sc_+3A_ncp">ncp</code></td>
<td>
<p> the noncentrality parameter from the <em>t</em>-distribution </p>
</td></tr>
<tr><td><code id="ci.sc_+3A_conf.level">conf.level</code></td>
<td>
<p> desired level of confidence for the computed interval (i.e., 1 - the Type I error rate) </p>
</td></tr>
<tr><td><code id="ci.sc_+3A_alpha.lower">alpha.lower</code></td>
<td>
<p> the Type I error rate for the lower confidence interval limit </p>
</td></tr>
<tr><td><code id="ci.sc_+3A_alpha.upper">alpha.upper</code></td>
<td>
<p> the Type I error rate for the upper confidence interval limit </p>
</td></tr>
<tr><td><code id="ci.sc_+3A_df.error">df.error</code></td>
<td>
<p> the degrees of freedom for the error. In one-way designs, this is simply 
<em>N</em>-length (means) and need not be specified; it must be specified if the design has multiple factors. </p>
</td></tr>
<tr><td><code id="ci.sc_+3A_...">...</code></td>
<td>
<p> optional additional specifications for nested functions </p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>Lower.Conf.Limit.Standardized.Contrast</code></td>
<td>
<p>the lower confidence limit for the standardized contrast</p>
</td></tr>
<tr><td><code>Standardized.contrast</code></td>
<td>
<p>standardized contrast</p>
</td></tr>
<tr><td><code>Upper.Conf.Limit.Standardized.Contrast</code></td>
<td>
<p>the upper confidence limit for the standardized contrast</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Be sure to use the standard deviation and not the error variance for <code>s.anova</code>, not the square of this value (the error variance) which would come from the source table (i.e., do not use the variance of the error but rather use its square root, the standard deviation).
</p>
<p>Be sure to use the error variance and not its square root (i.e., use the variance of the  standard deviation of the errors).
Be sure to use the standard deviations of errors for <code>s.anova</code> and <code>s.ancova</code>, not the square of these values (i.e., do not use the variance of the errors).
</p>
<p>Be sure to use fractional <em>c</em>-weights when doing complex contrasts (not integers) to specify <code>c.weights</code>. For exmaple, in an ANCOVA of four groups, if the user wants to compare the mean of group 1 and 2 with the mean of group 3 and 4, <code>c.weights</code> should be specified as c(0.5, 0.5, -0.5, -0.5) rather than c(1, 1, -1, -1). Make sure the sum of the contrast weights are zero.
</p>


<h3>Author(s)</h3>

<p> Ken Kelley (University of Notre Dame; <a href="mailto:KKelley@ND.Edu">KKelley@ND.Edu</a>) </p>


<h3>References</h3>

 
<p>Kelley, K. (2007). Constructing confidence intervals for standardized effect sizes: Theory, application, and implementation. <em>Journal of Statistical Software, 20</em> (8), 1&ndash;24.
</p>
<p>Lai, K., &amp; Kelley, K. (2007). Sample size planning for standardized ANCOVA and ANOVA 
contrasts: Obtaining narrow confidence intervals. <em>Manuscript submitted for publication</em>.
</p>
<p>Steiger, J. H. (2004). Beyond the <em>F</em> Test: Effect size confidence intervals and tests of close fit in the 
Analysis of Variance and Contrast Analysis. <em>Psychological Methods, 9</em>, 164&ndash;182.  
</p>


<h3>See Also</h3>

 <p><code>conf.limits.nct</code>, <code>ci.src</code>, <code>ci.smd</code>, <code>ci.smd.c</code>, <code>ci.sm</code>, <code>ci.c</code> </p>


<h3>Examples</h3>

<pre><code class='language-R'># Here is a four group example. Suppose that the means of groups 1--4 are 2, 4, 9, 
# and 13, respectively. Further, let the error variance be .64 and thus the standard
# deviation would be .80 (note we use the standard deviation in the function, not the 
# variance). The standardized contrast of interest here is the average of groups 1 and 4
# versus the average of groups 2 and 3. 

ci.sc(means=c(2, 4, 9, 13), s.anova=.80, c.weights=c(.5, -.5, -.5, .5), 
n=c(3, 3, 3, 3), N=12, conf.level=.95)


# Here is an example with two groups. 
ci.sc(means=c(1.6, 0), s.anova=.80, c.weights=c(1, -1), n=c(10, 10), N=20, conf.level=.95)
</code></pre>

<hr>
<h2 id='ci.sc.ancova'> Confidence interval for a standardized contrast in ANCOVA with one covariate</h2><span id='topic+ci.sc.ancova'></span>

<h3>Description</h3>

<p>Calculate the confidence interval for a standardized contrast in ANCOVA with one covariate. The standardizer
(i.e., the divisor) can be either the error standard deviation of the ANOVA model (i.e., the model excluding the covariate)
or of the ANCOVA model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ci.sc.ancova(Psi=NULL, adj.means=NULL, s.anova = NULL, s.ancova, 
standardizer = "s.ancova", c.weights, n, cov.means, SSwithin.x, 
conf.level = 0.95)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ci.sc.ancova_+3A_psi">Psi</code></td>
<td>
<p>unstandardized contrast of adjusted means </p>
</td></tr>
<tr><td><code id="ci.sc.ancova_+3A_adj.means">adj.means</code></td>
<td>
<p>the vector that contains the adjusted mean of each group on the dependent variable</p>
</td></tr>
<tr><td><code id="ci.sc.ancova_+3A_s.anova">s.anova</code></td>
<td>
<p>the standard deviation of the errors from the ANOVA model (i.e., the square root of the mean square error from ANOVA)</p>
</td></tr>
<tr><td><code id="ci.sc.ancova_+3A_s.ancova">s.ancova</code></td>
<td>
<p>the standard deviation of the errors from the ANCOVA model (i.e., the square root of the mean square error from ANCOVA)</p>
</td></tr>
<tr><td><code id="ci.sc.ancova_+3A_standardizer">standardizer</code></td>
<td>
<p>which error standard deviation the user wants to use, the value of which can be
either <code>"s.ancova"</code> or <code>"s.anova"</code></p>
</td></tr>
<tr><td><code id="ci.sc.ancova_+3A_c.weights">c.weights</code></td>
<td>
<p>the contrast weights (chose weights so that the positive <em>c</em>-weights sum to 1 and the negative <em>c</em>-weights sum to -1; i.e., use fractional values not integers).</p>
</td></tr>
<tr><td><code id="ci.sc.ancova_+3A_n">n</code></td>
<td>
<p>either a single number that indicates the sample size per group, or a vector that contains the
sample size of each group</p>
</td></tr>
<tr><td><code id="ci.sc.ancova_+3A_cov.means">cov.means</code></td>
<td>
<p> a vector that contains the group means of the covariate</p>
</td></tr>
<tr><td><code id="ci.sc.ancova_+3A_sswithin.x">SSwithin.x</code></td>
<td>
<p>the sum of squares within groups obtained from the summary table for ANOVA on the covariate</p>
</td></tr>
<tr><td><code id="ci.sc.ancova_+3A_conf.level">conf.level</code></td>
<td>
<p>the desired confidence interval coverage, (i.e., 1 - Type I error rate)</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>standardizer</code></td>
<td>
<p>the divisor used in the standardization</p>
</td></tr>
<tr><td><code>psi.limit.lower</code></td>
<td>
<p>the lower confidence limit of the standardized contrast</p>
</td></tr>
<tr><td><code>psi</code></td>
<td>
<p>the estimated contrast</p>
</td></tr>
<tr><td><code>psi.limit.upper</code></td>
<td>
<p>the upper confidence limit of the standardized contrast</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Be sure to use the standard deviations and not the error variances for <code>s.anova</code> and <code>s.ancova</code>, not the squares of these values which would come from the source tables (i.e., do not use the variance of the errors but rather use its square root, the standard deviation).
</p>
<p>If <code>n</code> receives a single number, that number is considered as the sample size per group. If <code>n</code>
is assigned to a vector, the vector is considered as the sample size of each group.
</p>
<p>Be sure to use fractional <em>c</em>-weights when doing complex contrasts (not integers) to specify <code>c.weights</code>. For example, in an ANCOVA of four groups, if the user wants to compare the mean of group 1 and 2 with the mean of group 3 and 4, <code>c.weights</code> should be specified as c(0.5, 0.5, -0.5, -0.5) rather than c(1, 1, -1, -1). Make sure the sum of the contrast weights are zero.
</p>
<p>The argument to be assigned to <code>standardizer</code> must be either <code>"s.ancova"</code> or <code>"s.anova"</code>. 
</p>


<h3>Author(s)</h3>

<p>Keke Lai (University of California&ndash;Merced) and Ken Kelley <a href="mailto:kkelley@nd.edu">kkelley@nd.edu</a></p>


<h3>References</h3>

 
<p>Kelley, K. (2007). Constructing confidence intervals for standardized effect sizes: Theory, application, 
and implementation. <em>Journal of Statistical Software, 20</em> (8), 1&ndash;24.
</p>
<p>Kelley, K., &amp; Rausch, J. R. (2006). Sample size planning for the standardized mean difference: 
Accuracy in Parameter Estimation via narrow confidence intervals. <em>Psychological Methods, 11</em>, 363&ndash;385.
</p>
<p>Lai, K., &amp; Kelley, K. (2012). Accuracy in parameter estimation for ANCOVA and ANOVA contrasts: Sample size planning via narrow confidence intervals. <em>British Journal of Mathematical and Statistical Psychology, 65</em>, 350&ndash;370.
</p>
<p>Steiger, J. H., &amp; Fouladi, R. T. (1997). Noncentrality interval estimation and the evaluation of
statistical methods. In L. L. Harlow, S. A. Mulaik, &amp; J.H. Steiger (Eds.), <em>What if there were
no significance tests?</em> (pp. 221&ndash;257). Mahwah, NJ: Lawrence Erlbaum. </p>


<h3>See Also</h3>

<p><code>ci.c.ancova</code>, <code>ci.sc</code> </p>


<h3>Examples</h3>

<pre><code class='language-R'># Maxwell &amp; Delaney (2004, pp. 428--468) offer an example that 30 depressive 
# individuals are randomly assigned to three groups, 10 in each, and ANCOVA 
# is performed on the posttest scores using the participants' pretest 
# scores as the covariate. The means of pretest scores of group 1, 2, and 3 are 
# 17, 17.7, and 17.4, respectively, whereas the adjusted means of groups 1, 2, and 3 
# are 7.5, 12, and 14, respectively. The error variance in ANCOVA is 29 and thus 
# 5.385165 is the error standard deviation, with the sum of squares within groups 
# from an ANOVA on the covariate is 752.5. 

# To obtained the confidence interval for the standardized adjusted
# mean difference between group 1 and 2, using the ANCOVA error standard
# deviation:
ci.sc.ancova(adj.means=c(7.5, 12, 14), s.ancova=5.385165, c.weights=c(1,-1,0), 
n=10, cov.means=c(17, 17.7, 17.4), SSwithin.x=752.5)

# Or, with less error in rounding:
ci.sc.ancova(adj.means=c(7.54, 11.98, 13.98), s.ancova=5.393, c.weights=c(-1,0,1), 
n=10, cov.means=c(17, 17.7, 17.4), SSwithin.x=752.5)

# Now, using the standard deviation from ANOVA (and not ANCOVA as above), we have:
ci.sc.ancova(adj.means=c(7.54, 11.98, 13.98), s.anova=6.294, s.ancova=5.393, c.weights=c(-1,0,1),
n=10, cov.means=c(17, 17.7, 17.4), SSwithin.x=752.5, standardizer= "s.anova", conf.level=.95)
</code></pre>

<hr>
<h2 id='ci.sm'> Confidence Interval for the Standardized Mean </h2><span id='topic+ci.sm'></span>

<h3>Description</h3>

<p>Function to obtain the exact confidence interval for the standardized mean.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ci.sm(sm = NULL, Mean = NULL, SD = NULL, ncp = NULL, N = NULL, 
conf.level = 0.95, alpha.lower = NULL, alpha.upper = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ci.sm_+3A_sm">sm</code></td>
<td>
<p> standardized mean</p>
</td></tr>
<tr><td><code id="ci.sm_+3A_mean">Mean</code></td>
<td>
<p> mean </p>
</td></tr>
<tr><td><code id="ci.sm_+3A_sd">SD</code></td>
<td>
<p> standard deviation</p>
</td></tr>
<tr><td><code id="ci.sm_+3A_ncp">ncp</code></td>
<td>
<p> noncentral parameter </p>
</td></tr>
<tr><td><code id="ci.sm_+3A_n">N</code></td>
<td>
<p> sample size </p>
</td></tr>
<tr><td><code id="ci.sm_+3A_conf.level">conf.level</code></td>
<td>
<p> confidence interval coverage (i.e., 1 - Type I error rate); default is .95 </p>
</td></tr>
<tr><td><code id="ci.sm_+3A_alpha.lower">alpha.lower</code></td>
<td>
<p> Type I error for the lower confidence limit </p>
</td></tr>
<tr><td><code id="ci.sm_+3A_alpha.upper">alpha.upper</code></td>
<td>
<p> Type I error for the upper confidence limit </p>
</td></tr>
<tr><td><code id="ci.sm_+3A_...">...</code></td>
<td>
<p> allows one to potentially include parameter values for inner functions </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The user must specify the standardized mean in one and only one of the three ways: a) mean and standard deviation (<code>Mean</code> and <code>SD</code>), b) standardized 
mean (<code>sm</code>), and c) noncentral parameter (<code>ncp</code>). The confidence level must be specified in one of following two ways: using confidence interval 
coverage (<code>conf.level</code>), or lower and upper confidence limits (<code>alpha.lower</code> and <code>alpha.upper</code>).
</p>
<p>This function uses the exact confidence interval method based on noncentral <em>t</em>-distributions. The confidence interval for noncentral <em>t</em>-parameter can be obtained from the <code>conf.limits.nct</code> function in MBESS.
</p>


<h3>Value</h3>

<table>
<tr><td><code>Lower.Conf.Limit.Standardized.Mean</code></td>
<td>
<p>lower confidence limit of the standardized mean</p>
</td></tr>
<tr><td><code>Standardized.Mean</code></td>
<td>
<p>standardized mean</p>
</td></tr>
<tr><td><code>Upper.Conf.Limit.Standardized.Mean</code></td>
<td>
<p>upper confidence limit of the standardized mean</p>
</td></tr>
</table>


<h3>Note</h3>

 
<p>The standardized mean is the mean divided by the standard deviation.
</p>


<h3>Author(s)</h3>

<p> Ken Kelley (University of Notre Dame; <a href="mailto:KKelley@ND.Edu">KKelley@ND.Edu</a>) </p>


<h3>References</h3>

<p>Kelley, K. (2007). Constructing confidence intervals for standardized effect sizes: Theory, application, and implementation. <em>Journal of Statistical Software, 20</em> (8), 1&ndash;24.
</p>
<p>Steiger, J. H., &amp; Fouladi, R. T. (1997). Noncentrality interval estimation and the evaluation of
statistical methods. In L. L. Harlow, S. A. Mulaik, &amp; J.H. Steiger (Eds.), <em>What if there were
no significance tests?</em> (pp. 221&ndash;257). Mahwah, NJ: Lawrence Erlbaum.
</p>


<h3>See Also</h3>

 <p><code>conf.limits.nct</code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>ci.sm(sm=2.037905, N=13, conf.level=.95)
ci.sm(Mean=30, SD=14.721, N=13, conf.level=.95)
ci.sm(ncp=7.347771, N=13, conf.level=.95)
ci.sm(sm=2.037905, N=13, alpha.lower=.05, alpha.upper=0)
ci.sm(Mean=50, SD=10, N=25, conf.level=.95)
</code></pre>

<hr>
<h2 id='ci.smd'>Confidence limits for the standardized mean difference.</h2><span id='topic+ci.smd'></span>

<h3>Description</h3>

<p>Function to calculate the confidence limits for the population standardized 
mean difference using the square root of the pooled variance as the divisor.
This function is thus used to determine the confidence bounds for the population 
quantity of what is generally referred to as Cohen's <em>d</em> (delta being 
that population quantity).</p>


<h3>Usage</h3>

<pre><code class='language-R'>ci.smd(ncp=NULL, smd=NULL, n.1=NULL, n.2=NULL, conf.level=.95, 
alpha.lower=NULL, alpha.upper=NULL, tol=1e-9, ...)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ci.smd_+3A_ncp">ncp</code></td>
<td>
<p> is the estimated noncentrality parameter, this is generally the observed <em>t</em>-statistic from comparing the two groups and assumes homogeneity of variance</p>
</td></tr>
<tr><td><code id="ci.smd_+3A_smd">smd</code></td>
<td>
<p> is the standardized mean difference (using the pooled standard deviation in the denominator)</p>
</td></tr>
<tr><td><code id="ci.smd_+3A_n.1">n.1</code></td>
<td>
<p> is the sample size for Group 1</p>
</td></tr>
<tr><td><code id="ci.smd_+3A_n.2">n.2</code></td>
<td>
<p> is the sample size for Group 2</p>
</td></tr>
<tr><td><code id="ci.smd_+3A_conf.level">conf.level</code></td>
<td>
<p> is the confidence level (1-Type I error rate)</p>
</td></tr>
<tr><td><code id="ci.smd_+3A_alpha.lower">alpha.lower</code></td>
<td>
<p> is the Type I error rate for the lower tail</p>
</td></tr>
<tr><td><code id="ci.smd_+3A_alpha.upper">alpha.upper</code></td>
<td>
<p> is the Type I error rate for the upper tail</p>
</td></tr>
<tr><td><code id="ci.smd_+3A_tol">tol</code></td>
<td>
<p> is the tolerance of the iterative method for determining the critical values</p>
</td></tr>
<tr><td><code id="ci.smd_+3A_...">...</code></td>
<td>
<p> allows one to potentially include parameter values for inner functions</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>Lower.Conf.Limit.smd</code></td>
<td>
<p>The lower bound of the computed confidence interval</p>
</td></tr>
<tr><td><code>smd</code></td>
<td>
<p>The standardized mean difference</p>
</td></tr>
<tr><td><code>Upper.Conf.Limit.smd</code></td>
<td>
<p>The upper bound of the computed confidence interval</p>
</td></tr>
</table>


<h3>Warning</h3>

<p>This function uses <code>conf.limits.nct</code>, which has as one of its arguments <code>tol</code> 
(and can be modified with <code>tol</code> of the present function). 
If the present function fails to converge (i.e., if it runs but does not report a solution), 
it is likely that the <code>tol</code> value is too restrictive and should be increased by a factor of 10, but probably by no more than 100. 
Running the function <code>conf.limits.nct</code> directly will report the actual probability values of the limits found. This should be 
done if any modification to <code>tol</code> is necessary in order to ensure acceptable confidence limits for the noncentral-<em>t</em> parameter have been achieved.
</p>


<h3>Author(s)</h3>

<p>Ken Kelley (University of Notre Dame; <a href="mailto:KKelley@ND.Edu">KKelley@ND.Edu</a>)</p>


<h3>References</h3>

<p>Cohen, J. (1988) Statistical power analysis for the behavioral sciences (2nd ed.). Hillsdale, NJ: Lawrence Erlbaum.
</p>
<p>Cumming, G. &amp; Finch, S. (2001). A primer on the understanding, use, and calculation of confidence intervals that are
based on central and noncentral distributions, <em>Educational and Psychological Measurement, 61</em>, 532&ndash;574.
</p>
<p>Hedges, L. V. (1981). Distribution theory for Glass's Estimator of effect size and related estimators. <em>Journal of Educational Statistics, 2</em>, 107&ndash;128.
</p>
<p>Kelley, K. (2007). Constructing confidence intervals for standardized effect sizes: Theory, application, and implementation. <em>Journal of Statistical Software, 20</em> (8), 1&ndash;24.
</p>
<p>Kelley, K., Maxwell, S. E., &amp; Rausch, J. R. (2003). Obtaining Power or Obtaining Precision: Delineating Methods
of Sample-Size Planning, <em>Evaluation and the Health Professions, 26</em>, 258&ndash;287.
</p>
<p>Steiger, J. H., &amp; Fouladi, R. T. (1997). Noncentrality interval estimation and the evaluation of
statistical methods. In L. L. Harlow, S. A. Mulaik,&amp;J.H. Steiger (Eds.), <em>What if there were
no significance tests?</em> (pp. 221&ndash;257). Mahwah, NJ: Lawrence Erlbaum.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+smd">smd</a></code>, <code><a href="#topic+smd.c">smd.c</a></code>, <code><a href="#topic+ci.smd.c">ci.smd.c</a></code>, <code><a href="#topic+conf.limits.nct">conf.limits.nct</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'># Steiger and Fouladi (1997) example values.
ci.smd(ncp=2.6, n.1=10, n.2=10, conf.level=1-.05)
ci.smd(ncp=2.4, n.1=300, n.2=300, conf.level=1-.05)
</code></pre>

<hr>
<h2 id='ci.smd.c'>Confidence limits for the standardized mean difference using the control
group standard deviation as the divisor.</h2><span id='topic+ci.smd.c'></span>

<h3>Description</h3>

<p>Function to calculate the confidence limits for the standardized mean difference using the control group standard deviation 
as the divisor (Glass's <em>g</em>).</p>


<h3>Usage</h3>

<pre><code class='language-R'>ci.smd.c(ncp = NULL, smd.c = NULL, n.C = NULL, n.E = NULL, 
conf.level = 0.95, alpha.lower = NULL, alpha.upper = NULL, 
tol = 1e-09, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ci.smd.c_+3A_ncp">ncp</code></td>
<td>
<p> is the estimated noncentrality parameter, this is generally the observed <em>t</em>-statistic from comparing the control and experimental group (assuming homogeneity of variance)</p>
</td></tr>
<tr><td><code id="ci.smd.c_+3A_smd.c">smd.c</code></td>
<td>
<p> is the standardized mean difference (using the control group standard deviation in the denominator)</p>
</td></tr>
<tr><td><code id="ci.smd.c_+3A_n.c">n.C</code></td>
<td>
<p> is the sample size for the control group</p>
</td></tr>
<tr><td><code id="ci.smd.c_+3A_n.e">n.E</code></td>
<td>
<p> is the sample size for experimental group</p>
</td></tr>
<tr><td><code id="ci.smd.c_+3A_conf.level">conf.level</code></td>
<td>
<p> is the confidence level (1-Type I error rate)</p>
</td></tr>
<tr><td><code id="ci.smd.c_+3A_alpha.lower">alpha.lower</code></td>
<td>
<p> is the Type I error rate for the lower tail</p>
</td></tr>
<tr><td><code id="ci.smd.c_+3A_alpha.upper">alpha.upper</code></td>
<td>
<p> is the Type I error rate for the upper tail</p>
</td></tr>
<tr><td><code id="ci.smd.c_+3A_tol">tol</code></td>
<td>
<p> is the tolerance of the iterative method for determining the critical values</p>
</td></tr>
<tr><td><code id="ci.smd.c_+3A_...">...</code></td>
<td>
<p> Potentially include parameter for inner functions</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>Lower.Conf.Limit.smd.c</code></td>
<td>
<p>The lower bound of the computed confidence interval</p>
</td></tr>
<tr><td><code>smd.c</code></td>
<td>
<p>The standardized mean difference based on the control group standard deviation</p>
</td></tr>
<tr><td><code>Upper.Conf.Limit.smd.c</code></td>
<td>
<p>The upper bound of the computed confidence interval</p>
</td></tr>
</table>


<h3>Warning</h3>

<p>This function uses <code>conf.limits.nct</code>, which has as one of its arguments <code>tol</code> 
(and can be modified with <code>tol</code> of the present function). 
If the present function fails to converge (i.e., if it runs but does not report a solution), 
it is likely that the <code>tol</code> value is too restrictive and should be increased by a factor of 10, but probably by no more than 100. 
Running the function <code>conf.limits.nct</code> directly will report the actual probability values of the limits found. This should be 
done if any modification to <code>tol</code> is necessary in order to ensure acceptable confidence limits for the noncentral-<em>t</em> 
parameter have been achieved.
</p>


<h3>Author(s)</h3>

<p>Ken Kelley (University of Notre Dame; <a href="mailto:KKelley@ND.Edu">KKelley@ND.Edu</a>)</p>


<h3>References</h3>

<p>Cohen, J. (1988). <em>Statistical power analysis for the behavioral sciences</em> (2nd ed.). Hillsdale, NJ: Lawrence Erlbaum.
</p>
<p>Cumming, G. &amp; Finch, S. (2001). A primer on the understanding, use, and calculation of confidence intervals that are
based on central and noncentral distributions, <em>Educational and Psychological Measurement, 61</em>, 532&ndash;574.
</p>
<p>Glass, G. V. (1976). Primary, secondary, and meta-analysis of research. <em>Educational Researcher, 5</em>, 3&ndash;8.
</p>
<p>Hedges, L. V. (1981). Distribution theory for Glass's Estimator of effect size and related estimators. <em>Journal of Educational Statistics, 2</em>, 107&ndash;128.
</p>
<p>Kelley, K. (2007). Constructing confidence intervals for standardized effect sizes: Theory, application, and implementation. <em>Journal of Statistical Software, 20</em> (8), 1&ndash;24.
</p>
<p>Steiger, J. H., &amp; Fouladi, R. T. (1997). Noncentrality interval estimation and the evaluation of
statistical methods. In L. L. Harlow, S. A. Mulaik, &amp; J. H. Steiger (Eds.), <em>What if there were
no significance tests?</em> (pp. 221&ndash;257). Mahwah, NJ: Lawrence Erlbaum.
</p>


<h3>See Also</h3>

<p><code>smd.c</code>, <code>smd</code>, <code>ci.smd</code>, <code>conf.limits.nct</code></p>


<h3>Examples</h3>

<pre><code class='language-R'>ci.smd.c(smd.c=.5, n.C=100, n.E=100, conf.level=.95)
</code></pre>

<hr>
<h2 id='ci.snr'> Confidence Interval for the Signal-To-Noise Ratio </h2><span id='topic+ci.snr'></span>

<h3>Description</h3>

<p>Function to obtain the exact confidence interval for the signal-to-noise ratio (i.e., the variance of the specific factor over the error variance).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ci.snr(F.value = NULL, df.1 = NULL, df.2 = NULL, N = NULL, conf.level = 0.95,
 alpha.lower = NULL, alpha.upper = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ci.snr_+3A_f.value">F.value</code></td>
<td>
<p> observed <em>F</em>-value from the analysis of variance</p>
</td></tr>
<tr><td><code id="ci.snr_+3A_df.1">df.1</code></td>
<td>
<p> numerator degrees of freedom </p>
</td></tr>
<tr><td><code id="ci.snr_+3A_df.2">df.2</code></td>
<td>
<p> denominator degrees of freedom </p>
</td></tr>
<tr><td><code id="ci.snr_+3A_n">N</code></td>
<td>
<p> sample size </p>
</td></tr>
<tr><td><code id="ci.snr_+3A_conf.level">conf.level</code></td>
<td>
<p> confidence interval coverage (i.e., 1 - Type I error rate), default is .95 </p>
</td></tr>
<tr><td><code id="ci.snr_+3A_alpha.lower">alpha.lower</code></td>
<td>
<p> Type I error for the lower confidence limit </p>
</td></tr>
<tr><td><code id="ci.snr_+3A_alpha.upper">alpha.upper</code></td>
<td>
<p> Type I error for the upper confidence limit </p>
</td></tr>
<tr><td><code id="ci.snr_+3A_...">...</code></td>
<td>
<p> allows one to potentially include parameter values for inner functions </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The confidence level must be specified in one of following two ways: using 
confidence interval coverage (<code>conf.level</code>), or lower and upper confidence 
limits (<code>alpha.lower</code> and <code>alpha.upper</code>).
</p>
<p>This function uses the confidence interval transformation principle (Steiger, 2004) to transform the confidence limits for the noncentality parameter to the confidence limits for the population's signal-to-noise ratio. The confidence interval for noncentral <em>F</em>-parameter can be obtained 
from the <code>conf.limits.ncf</code> function in MBESS, which is used internally within this function.
</p>


<h3>Value</h3>

<p>Returns the confidence limits for the signal-to-noise ratio.
</p>
<table>
<tr><td><code>Lower.Limit.Signal.to.Noise.Ratio</code></td>
<td>
<p>lower limit for signal to noise ratio</p>
</td></tr>
<tr><td><code>Upper.Limit.Signal.to.Noise.Ratio</code></td>
<td>
<p>upper limit for signal to noise ratio</p>
</td></tr>
</table>


<h3>Note</h3>

 
<p>The signal to noise ratio is defined as the variance due to the particular factor over the error variance (i.e., the mean square error).
</p>


<h3>Author(s)</h3>

<p> Ken Kelley (University of Notre Dame; <a href="mailto:KKelley@ND.Edu">KKelley@ND.Edu</a>) </p>


<h3>References</h3>

 
<p>Kelley, K. (2007). Constructing confidence intervals for standardized effect sizes: Theory, application, and implementation. <em>Journal of Statistical Software, 20</em> (8), 1&ndash;24.
</p>
<p>Fleishman, A. I. (1980). Confidence intervals for correlation ratios. <em>Educational and Psychological Measurement, 40</em>, 659&ndash;670.
</p>
<p>Steiger, J. H. (2004). Beyond the <em>F</em> Test: Effect size confidence intervals and tests of close fit in the Analysis of Variance and Contrast Analysis.  <em>Psychological Methods, 9</em>, 164&ndash;182. </p>


<h3>See Also</h3>

 <p><code>ci.srsnr</code>, <code>ci.omega2</code> <code>conf.limits.ncf</code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Bargman (1970) gave an example in which a 5-group ANOVA with 11 subjects in each 
## group is conducted and the observed F value is 11.2213. This example was 
## used in Venables (1975),  Fleishman (1980), and Steiger (2004). If one wants to calculate 
## the exact confidence interval for the signal-to-noise ratio of that example, this
## function can be used.

ci.snr(F.value=11.221, df.1=4, df.2=50, N=55)

ci.snr(F.value=11.221, df.1=4, df.2=50, N=55, conf.level=.90)

ci.snr(F.value=11.221, df.1=4, df.2=50, N=55,  alpha.lower=.02, alpha.upper=.03)
</code></pre>

<hr>
<h2 id='ci.src'> Confidence Interval for a Standardized Regression Coefficient </h2><span id='topic+ci.src'></span>

<h3>Description</h3>

<p>Function to obtain the confidence interval for a standardized regression coefficient.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ci.src(beta.k = NULL, SE.beta.k = NULL, N = NULL, K = NULL, R2.Y_X = NULL, 
R2.k_X.without.k = NULL, conf.level = 0.95, R2.Y_X.without.k = NULL, 
t.value = NULL, b.k = NULL, SE.b.k = NULL, s.Y = NULL, s.X = NULL, 
alpha.lower = NULL, alpha.upper = NULL, Suppress.Statement = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ci.src_+3A_beta.k">beta.k</code></td>
<td>
<p> the standardized regression coefficient </p>
</td></tr>
<tr><td><code id="ci.src_+3A_se.beta.k">SE.beta.k</code></td>
<td>
<p>the standard error of the standarized regression coefficient </p>
</td></tr>
<tr><td><code id="ci.src_+3A_n">N</code></td>
<td>
<p> sample size </p>
</td></tr>
<tr><td><code id="ci.src_+3A_k">K</code></td>
<td>
<p> the number of predictors </p>
</td></tr>
<tr><td><code id="ci.src_+3A_r2.y_x">R2.Y_X</code></td>
<td>
<p> the squared multiple correlation coefficient predicting <em>Y</em> from the <em>k</em> predictor variables </p>
</td></tr>
<tr><td><code id="ci.src_+3A_r2.k_x.without.k">R2.k_X.without.k</code></td>
<td>
<p> the squared multiple correlation coefficient predicting the <em>k</em>th predictor variable
(i.e., the predictor of interest) from the remaining <em>p</em>-1 predictor variables </p>
</td></tr>
<tr><td><code id="ci.src_+3A_conf.level">conf.level</code></td>
<td>
<p> desired level of confidence for the computed interval (i.e., 1 - the Type I error rate)</p>
</td></tr>
<tr><td><code id="ci.src_+3A_r2.y_x.without.k">R2.Y_X.without.k</code></td>
<td>
<p> the squared multiple correlation coefficient predicting <em>Y</em> from the <em>p</em>-1 predictor
variable with the <em>k</em>th predictor of interest excluded </p>
</td></tr>
<tr><td><code id="ci.src_+3A_t.value">t.value</code></td>
<td>
<p> the <em>t</em>-value evaluating the null hypothesis that the population regression coefficient
for the <em>k</em>th predictor equals zero </p>
</td></tr>
<tr><td><code id="ci.src_+3A_b.k">b.k</code></td>
<td>
<p> the unstandardized regression coefficient </p>
</td></tr>
<tr><td><code id="ci.src_+3A_se.b.k">SE.b.k</code></td>
<td>
<p> the standard error of the unstandardized regression coefficient </p>
</td></tr>
<tr><td><code id="ci.src_+3A_s.y">s.Y</code></td>
<td>
<p> standard deviation of <em>Y</em>, the dependent variable </p>
</td></tr>
<tr><td><code id="ci.src_+3A_s.x">s.X</code></td>
<td>
<p> standard deviation of <em>X</em>, the predictor variable of interest </p>
</td></tr>
<tr><td><code id="ci.src_+3A_alpha.lower">alpha.lower</code></td>
<td>
<p>  the Type I error rate for the lower confidence interval limit </p>
</td></tr>
<tr><td><code id="ci.src_+3A_alpha.upper">alpha.upper</code></td>
<td>
<p>  the Type I error rate for the upper confidence interval limit </p>
</td></tr>
<tr><td><code id="ci.src_+3A_suppress.statement">Suppress.Statement</code></td>
<td>
 <p><code>TRUE</code> or <code>FALSE</code> statement specifying whether or not a statement should be printed
that identifies the type of confidence interval formed </p>
</td></tr>
<tr><td><code id="ci.src_+3A_...">...</code></td>
<td>
<p> optional additional specifications for nested functions </p>
</td></tr>
</table>


<h3>Details</h3>

<p>For standardized variables, do not specify the standard deviation of the variables and input the
standardized regression coefficient for <code>b.k</code>.
</p>


<h3>Value</h3>

<p>Returns the confidence limits specified for the regression coefficient of interest from the standard
approach to confidence interval formation or from the noncentral approach to confidence interval
formation using the noncentral <em>t</em>-distribution.
</p>


<h3>Note</h3>

 
<p>This function calls upon <code>ci.reg.coef</code> in MBESS, but has a different naming scheme. See  <code>ci.reg.coef</code> for more details.
</p>
<p>To form a confidence interval for the unstandardized regression coefficient, use <code>ci.rc</code>. This function is used to form a confidence interval for the 
standardized regression coefficient.
</p>
<p>Not all of the values need to be specified, only those that contain all of the necessary information
in order to compute the confidence interval (options are thus given for the values that need to be
specified).
</p>


<h3>Author(s)</h3>

<p> Ken Kelley (University of Notre Dame; <a href="mailto:KKelley@ND.Edu">KKelley@ND.Edu</a>) </p>


<h3>References</h3>

 
<p>Kelley, K. (2007). Constructing confidence intervals for standardized effect sizes: Theory, application, and implementation. <em>Journal of Statistical Software, 20</em> (8), 1&ndash;24.
</p>
<p>Kelley, K., &amp; Maxwel, S. E. (2003). Sample size for Multiple Regression: Obtaining regression
coefficients that are accurate, not simply significant. <em>Psychological Methods, 8</em>, 305&ndash;321.
</p>
<p>Kelley, K., &amp; Maxwell, S. E. (2008). Sample Size Planning with applications to multiple regression: Power and accuracy for omnibus and targeted effects. In P. Alasuuta, J. Brannen, &amp; L. Bickman (Eds.), <em>The Sage handbook of social research methods</em> (pp. 166&ndash;192). Newbury Park, CA: Sage.
</p>
<p>Smithson, M. (2003). <em>Confidence intervals</em>. New York, NY: Sage Publications. 
</p>
<p>Steiger, J. H. (2004). Beyond the <em>F</em> Test: Effect size confidence intervals and tests of close fit in the 
Analysis of Variance and Contrast Analysis. <em>Psychological Methods, 9</em>, 164&ndash;182.
</p>


<h3>See Also</h3>

 <p><code>ss.aipe.reg.coef</code>, <code>conf.limits.nct</code>, <code>ci.reg.coef</code>, <code>ci.rc</code> </p>

<hr>
<h2 id='ci.srsnr'> Confidence Interval for the Square Root of the Signal-To-Noise Ratio </h2><span id='topic+ci.srsnr'></span>

<h3>Description</h3>

<p>Function to calculate the exact confidence interval for the square root of the signal-to-noise ratio.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ci.srsnr(F.value = NULL, df.1 = NULL, df.2 = NULL, N = NULL, 
conf.level = 0.95, alpha.lower = NULL, alpha.upper = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ci.srsnr_+3A_f.value">F.value</code></td>
<td>
<p> observed <em>F</em>-value from the analysis of variance </p>
</td></tr>
<tr><td><code id="ci.srsnr_+3A_df.1">df.1</code></td>
<td>
<p> numerator degrees of freedom </p>
</td></tr>
<tr><td><code id="ci.srsnr_+3A_df.2">df.2</code></td>
<td>
<p> denominator degrees of freedom </p>
</td></tr>
<tr><td><code id="ci.srsnr_+3A_n">N</code></td>
<td>
<p> sample size </p>
</td></tr>
<tr><td><code id="ci.srsnr_+3A_conf.level">conf.level</code></td>
<td>
<p> confidence interval coverage (i.e., 1 - Type I error rate); default is .95 </p>
</td></tr>
<tr><td><code id="ci.srsnr_+3A_alpha.lower">alpha.lower</code></td>
<td>
<p> Type I error for the lower confidence limit </p>
</td></tr>
<tr><td><code id="ci.srsnr_+3A_alpha.upper">alpha.upper</code></td>
<td>
<p> Type I error for the upper confidence limit </p>
</td></tr>
<tr><td><code id="ci.srsnr_+3A_...">...</code></td>
<td>
<p> allows one to potentially include parameter values for inner functions </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The confidence level must be specified in one of following two ways: using 
confidence interval coverage (<code>conf.level</code>), or lower and upper confidence 
limits (<code>alpha.lower</code> and <code>alpha.upper</code>).
</p>
<p>The square root of the signal-to-noise ratio is defined as the standard deviation due to the particular factor over the 
standard deviation of the error (i.e., the square root of the mean square error). This function uses the confidence 
interval transformation principle (Steiger, 2004) to transform the confidence limits for the noncentality 
parameter to the confidence limits for square root of signal-to-noise ratio. The confidence interval 
for noncentral <em>F</em> parameter can be abtained from function <code>conf.limits.ncf</code> in MBESS. 
</p>


<h3>Value</h3>

<p>Returns the square root of the confidence limits for the signal to noise ratio.
</p>
<table>
<tr><td><code>Lower.Limit.of.the.Square.Root.of.the.Signal.to.Noise.Ratio</code></td>
<td>
<p>lower limit of the square root of the signal to noise ratio</p>
</td></tr>
<tr><td><code>Upper.Limit.of.the.Square.Root.of.the.Signal.to.Noise.Ratio</code></td>
<td>
<p>upper limit of the square root of the signal to noise ratio</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p> Ken Kelley (University of Notre Dame; <a href="mailto:KKelley@ND.Edu">KKelley@ND.Edu</a>) </p>


<h3>References</h3>

<p>Fleishman, A. I. (1980). Confidence intervals for correlation ratios. <em>Educational and Psychological Measurement, 40</em>, 659&ndash;670.
</p>
<p>Kelley, K. (2007). Constructing confidence intervals for standardized effect sizes: Theory, application, and implementation. <em>Journal of Statistical Software, 20</em> (8), 1&ndash;24.
</p>
<p>Steiger, J. H. (2004). Beyond the <em>F</em> Test: Effect size confidence intervals and tests of close fit in the Analysis of Variance and Contrast Analysis. <em>Psychological Methods, 9</em>, 164&ndash;182.  </p>


<h3>See Also</h3>

 <p><code>ci.snr</code>, <code>conf.limits.ncf</code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>## To illustrate the calculation of the confidence interval for noncentral 
## F parameter,Bargman (1970) gave an example in which a 5-group ANOVA with 
## 11 subjects in each group is conducted and the observed F value is 11.2213. 
## This exmaple continued to be used in Venables (1975),  Fleishman (1980), 
## and Steiger (2004). If one wants to calculate the exact confidence interval 
## for square root of the signal-to-noise ratio of that example, this 
## function can be used.

ci.srsnr(F.value=11.221, df.1=4, df.2=50, N=55)

ci.srsnr(F.value=11.221, df.1=4, df.2=50, N=55, conf.level=.90)

ci.srsnr(F.value=11.221, df.1=4, df.2=50, N=55,  alpha.lower=.02, alpha.upper=.03)
</code></pre>

<hr>
<h2 id='conf.limits.nc.chisq'>Confidence limits for noncentral chi square parameters</h2><span id='topic+conf.limits.nc.chisq'></span>

<h3>Description</h3>

<p>Function to determine the noncentral parameter that leads to the observed <code>Chi.Square</code>-value, 
so that a confidence interval for the population noncentral chi-squrae value can be formed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>conf.limits.nc.chisq(Chi.Square=NULL, conf.level=.95, df=NULL, 
alpha.lower=NULL, alpha.upper=NULL, tol=1e-9, Jumping.Prop=.10)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="conf.limits.nc.chisq_+3A_chi.square">Chi.Square</code></td>
<td>
<p>the observed chi-square value</p>
</td></tr>
<tr><td><code id="conf.limits.nc.chisq_+3A_conf.level">conf.level</code></td>
<td>
<p>the desired degree of confidence for the interval</p>
</td></tr>
<tr><td><code id="conf.limits.nc.chisq_+3A_df">df</code></td>
<td>
<p>the degrees of freedom</p>
</td></tr>
<tr><td><code id="conf.limits.nc.chisq_+3A_alpha.lower">alpha.lower</code></td>
<td>
<p>Type I error for the lower confidence limit</p>
</td></tr>
<tr><td><code id="conf.limits.nc.chisq_+3A_alpha.upper">alpha.upper</code></td>
<td>
<p>Type I error for the upper confidence limit</p>
</td></tr>
<tr><td><code id="conf.limits.nc.chisq_+3A_tol">tol</code></td>
<td>
<p>tolerance for iterative convergence</p>
</td></tr>
<tr><td><code id="conf.limits.nc.chisq_+3A_jumping.prop">Jumping.Prop</code></td>
<td>
<p>Value used in the iterative scheme to determine the noncentral 
parameters necessary for confidence interval construction using noncentral 
chi square-distributions (<code>0 &lt; Jumping.Prop &lt; 1</code>)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If the function fails (or if a function relying upon this function fails), adjust the <code>Jumping.Prop</code>
(to a smaller value).
</p>


<h3>Value</h3>

<table>
<tr><td><code>Lower.Limit</code></td>
<td>
<p>Value of the distribution with <code>Lower.Limit</code> noncentral value that has at its specified quantile <code>Chi.Square</code></p>
</td></tr>
<tr><td><code>Prob.Less.Lower</code></td>
<td>
<p>Proportion of cases falling below <code>Lower.Limit</code></p>
</td></tr>
<tr><td><code>Upper.Limit</code></td>
<td>
<p>Value of the distribution with <code>Upper.Limit</code> noncentral value that has at its specified quantile <code>Chi.Square</code></p>
</td></tr>
<tr><td><code>Prob.Greater.Upper</code></td>
<td>
<p>Proportion of cases falling above <code>Upper.Limit</code></p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Ken Kelley (University of Notre Dame; <a href="mailto:KKelley@ND.Edu">KKelley@ND.Edu</a>);
Keke Lai (University of California&ndash;Merced)
</p>


<h3>See Also</h3>

<p><code>conf.limits.nct</code>, <code>conf.limits.ncf</code></p>


<h3>Examples</h3>

<pre><code class='language-R'># A typical call to the function.
conf.limits.nc.chisq(Chi.Square=30, conf.level=.95, df=15)

# A one sided (upper) confidence interval.
 conf.limits.nc.chisq(Chi.Square=30, alpha.lower=0, alpha.upper=.05, 
 conf.level=NULL, df=15)
</code></pre>

<hr>
<h2 id='conf.limits.ncf'>Confidence limits for noncentral F parameters</h2><span id='topic+conf.limits.ncf'></span>

<h3>Description</h3>

<p>Function to determine the noncentral parameter that leads to the observed <em>F</em>-value, 
so that a confidence interval around the population <em>F</em>-value can be conducted. Used for forming confidence intervals around noncentral parameters (given the monotonic relationship between the <em>F</em>-value and the noncentral value).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>conf.limits.ncf(F.value = NULL, conf.level = .95, df.1 = NULL, 
df.2 = NULL, alpha.lower = NULL, alpha.upper = NULL, tol = 1e-09,
Jumping.Prop = 0.1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="conf.limits.ncf_+3A_f.value">F.value</code></td>
<td>
<p>the observed <em>F</em>-value</p>
</td></tr>
<tr><td><code id="conf.limits.ncf_+3A_conf.level">conf.level</code></td>
<td>
<p>the desired degree of confidence for the interval</p>
</td></tr>
<tr><td><code id="conf.limits.ncf_+3A_df.1">df.1</code></td>
<td>
<p>the numerator degrees of freedom</p>
</td></tr>
<tr><td><code id="conf.limits.ncf_+3A_df.2">df.2</code></td>
<td>
<p>the denominator degrees of freedom</p>
</td></tr>
<tr><td><code id="conf.limits.ncf_+3A_alpha.lower">alpha.lower</code></td>
<td>
<p>Type I error for the lower confidence limit</p>
</td></tr>
<tr><td><code id="conf.limits.ncf_+3A_alpha.upper">alpha.upper</code></td>
<td>
<p>Type I error for the upper confidence limit</p>
</td></tr>
<tr><td><code id="conf.limits.ncf_+3A_tol">tol</code></td>
<td>
<p>tolerance for iterative convergence</p>
</td></tr>
<tr><td><code id="conf.limits.ncf_+3A_jumping.prop">Jumping.Prop</code></td>
<td>
<p>Value used in the iterative scheme to determine the noncentral 
parameters necessary for confidence interval construction using noncentral 
<em>F</em>-distributions (<code>0 &lt; Jumping.Prop &lt; 1</code>) (users should not need to change this value)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is the relied upon by the <code>ci.R2</code> and <code>ss.aipe.R2</code>. If the function fails 
(or if a function relying upon this function fails), adjust the <code>Jumping.Prop</code>
(to a smaller value).
</p>


<h3>Value</h3>

<table>
<tr><td><code>Lower.Limit</code></td>
<td>
<p>Value of the distribution with <code>Lower.Limit</code> noncentral value that has at its specified quantile <code>F.value</code></p>
</td></tr>
<tr><td><code>Prob.Less.Lower</code></td>
<td>
<p>Proportion of cases falling below <code>Lower.Limit</code></p>
</td></tr>
<tr><td><code>Upper.Limit</code></td>
<td>
<p>Value of the distribution with <code>Upper.Limit</code> noncentral value that has at its specified quantile <code>F.value</code></p>
</td></tr>
<tr><td><code>Prob.Greater.Upper</code></td>
<td>
<p>Proportion of cases falling above <code>Upper.Limit</code></p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Ken Kelley (University of Notre Dame; <a href="mailto:KKelley@ND.Edu">KKelley@ND.Edu</a>); Keke Lai (University of Califonia-Merced)</p>


<h3>See Also</h3>

<p><code>ss.aipe.R2</code>, <code>ci.R2</code>, <code>conf.limits.nct</code></p>


<h3>Examples</h3>

<pre><code class='language-R'>conf.limits.ncf(F.value = 5, conf.level = .95, df.1 = 5, 
df.2 = 100)

# A one sided confidence interval.
conf.limits.ncf(F.value = 5, conf.level = NULL, df.1 = 5, 
df.2 = 100, alpha.lower = .05, alpha.upper = 0, tol = 1e-09,
Jumping.Prop = 0.1)
</code></pre>

<hr>
<h2 id='conf.limits.nct'>Confidence limits for a noncentrality parameter from a t-distribution</h2><span id='topic+conf.limits.nct'></span>

<h3>Description</h3>

<p>Function to determine the noncentrality parameters necessary to form a confidence interval around the population noncentrality parameter and related parameters.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>conf.limits.nct(ncp, df, conf.level = 0.95, alpha.lower = NULL, 
alpha.upper = NULL, t.value, tol = 1e-09, sup.int.warns = TRUE, 
...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="conf.limits.nct_+3A_ncp">ncp</code></td>
<td>
<p>the noncentrality parameter (e.g., observed <em>t</em>-value) of interest.</p>
</td></tr>
<tr><td><code id="conf.limits.nct_+3A_df">df</code></td>
<td>
<p>the degrees of freedom.</p>
</td></tr>
<tr><td><code id="conf.limits.nct_+3A_conf.level">conf.level</code></td>
<td>
<p>the level of confidence for a symmetric confidence interval.</p>
</td></tr>
<tr><td><code id="conf.limits.nct_+3A_alpha.lower">alpha.lower</code></td>
<td>
<p>the proportion of values beyond the lower limit of the confidence interval (cannot be used with <code>conf.level</code>).</p>
</td></tr>
<tr><td><code id="conf.limits.nct_+3A_alpha.upper">alpha.upper</code></td>
<td>
<p>the proportion of values beyond the upper limit of the confidence interval (cannot be used with <code>conf.level</code>).</p>
</td></tr>
<tr><td><code id="conf.limits.nct_+3A_t.value">t.value</code></td>
<td>
<p>alias for <code>ncp</code></p>
</td></tr>
<tr><td><code id="conf.limits.nct_+3A_tol">tol</code></td>
<td>
<p>is the tolerance of the iterative method for determining the critical values.</p>
</td></tr>
<tr><td><code id="conf.limits.nct_+3A_sup.int.warns">sup.int.warns</code></td>
<td>
<p>Suppress internal warnings (from internal functions): <code>TRUE</code> or <code>FALSE</code></p>
</td></tr>
<tr><td><code id="conf.limits.nct_+3A_...">...</code></td>
<td>
<p> allows one to potentially include parameter values for inner functions</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Function for finding the upper and lower confidence limits for a noncentral parameter from a noncentral <em>t</em>-distribution with <code>df</code> degrees of freedom. 
This function is especially helpful when forming confidence intervals around standardized mean differences (i.e., Cohen's <em>d</em>; Glass's <em>g</em>; Hedges' <em>g</em>), standardized regression coefficients, and 
coefficients of variations. The <code>Lower.Limit</code> and the <code>Upper.Limit</code> values correspond to the noncentral parameters of a <em>t</em>-distribution with <code>df</code> degrees of
freedom whose upper and lower tails contain the desired proportion of the respective noncentral <em>t</em>-distribution.
When <code>ncp</code> is zero, the <code>Lower.Limit</code> and <code>Upper.Limit</code> are simply the desired quantiles of the
central <em>t</em>-distribution with <code>df</code> degrees of freedom.
</p>
<p>Note that the confidence interval limit(s) are found twice, using two different methods. The first method uses the <code>optimize</code> function, whereas the second method uses the <code>nlm</code> function. The best of the two methods, if not equal and numerically exact, is taken. This does not concern the user. 
</p>


<h3>Value</h3>

 
<table>
<tr><td><code>Lower.Limit</code></td>
<td>
<p>Value of the distribution with <code>Lower.Limit</code> noncentral value that has at its specified quantile <code>F.value</code></p>
</td></tr>
<tr><td><code>Prob.Less.Lower</code></td>
<td>
<p>Proportion of the distribution beyond (i.e., less than) <code>Lower.Limit</code></p>
</td></tr>
<tr><td><code>Upper.Limit</code></td>
<td>
<p>Value of the distribution with <code>Upper.Limit</code> noncentral value that has at its specified quantile <code>F.value</code></p>
</td></tr>
<tr><td><code>Prob.Greater.Upper</code></td>
<td>
<p>Proportion of the distribution beyond (i.e., larger than) <code>Upper.Limit</code></p>
</td></tr>
</table>


<h3>Warning</h3>

<p>At the present time, the largest <code>ncp</code> that R can accurately handle is 37.62.
</p>


<h3>Author(s)</h3>

<p>Ken Kelley (University of Notre Dame; <a href="mailto:KKelley@ND.Edu">KKelley@ND.Edu</a>)</p>


<h3>References</h3>

<p>Cumming, G. &amp; Finch, S. (2001). A primer on the understanding, use, and calculation of confidence intervals that are
based on central and noncentral distributions, <em>Educational and Psychological Measurement, 61</em>, 532&ndash;574.
</p>
<p>Kelley, K. (2005). The effects of nonnormal distributions on confidence intervals around the standardized mean
difference: Bootstrap and parametric confidence intervals, <em>Educational and Psychological Measurement, 65</em>, 51&ndash;69.
</p>
<p>Kelley, K. (2007). Constructing confidence intervals for standardized effect sizes: Theory, application, and implementation. <em>Journal of Statistical Software, 20</em> (8), 1&ndash;24.
</p>
<p>Steiger, J. &amp; Fouladi, T. (1997). Noncentrality interval estimation and the evaluation of statistical models. In L. Harlow, 
S. Muliak, &amp; J. Steiger (Eds.), <em>What if there were no significance tests?</em>. Mahwah, NJ: Lawrence Erlbaum.
</p>


<h3>See Also</h3>

<p><code>pt</code>, <code>qt</code>, <code>ci.smd</code>, <code>ci.smd.c</code>, <code>ss.aipe</code>, <code>conf.limits.ncf</code>, <code>conf.limits.nc.chisq</code></p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Suppose observed t-value based on 'df'=126 is 2.83. Finding the lower 
# and upper critical values for the population noncentrality parameter 
# with a symmetric confidence interval with 95% confidence is given as:
conf.limits.nct(ncp=2.83, df=126, conf.level=.95)

# Modifying the above example so that a nonsymmetric 95% confidence interval
# can be formed:
conf.limits.nct(ncp=2.83, df=126, alpha.lower=.01, alpha.upper=.04,
conf.level=NULL)

# Modifying the above example so that a single-sided 95% confidence interval
# can be formed:
conf.limits.nct(ncp=2.83, df=126, alpha.lower=0, alpha.upper=.05,
conf.level=NULL)

</code></pre>

<hr>
<h2 id='Cor.Mat.Lomax'> Correlation matrix for Lomax (1983) data set</h2><span id='topic+Cor.Mat.Lomax'></span>

<h3>Description</h3>

<p>Correlation matrix for Lomax (1983) data set
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(Cor.Mat.Lomax)</code></pre>


<h3>Details</h3>

<p>Variables 1 through 14 in the correlation matrix are, respectively: </p>

<table>
<tr>
 <td style="text-align: left;">
Variables </td>
</tr>
<tr>
 <td style="text-align: left;">
(1) DRS-consonant sounds </td>
</tr>
<tr>
 <td style="text-align: left;">
(2) DRS-consonant blends and diagraphs </td>
</tr>
<tr>
 <td style="text-align: left;">
(3) DRS-common syllables or phonograms </td>
</tr>
<tr>
 <td style="text-align: left;">
(4) DRS-blending </td>
</tr>
<tr>
 <td style="text-align: left;">
(5) WRAT-total raw score </td>
</tr>
<tr>
 <td style="text-align: left;">
(6) DRS-total correct both lists </td>
</tr>
<tr>
 <td style="text-align: left;">
(7) DRS-total words read correct oral </td>
</tr>
<tr>
 <td style="text-align: left;">
(8) DRS-wpm first oral passage </td>
</tr>
<tr>
 <td style="text-align: left;">
(9) DRS-wpm first silent passage </td>
</tr>
<tr>
 <td style="text-align: left;">
(10) DRS-mean wpm oral passages read </td>
</tr>
<tr>
 <td style="text-align: left;">
(11) DRS-mean wpm silent passages read </td>
</tr>
<tr>
 <td style="text-align: left;">
(12) DRS-total correct oral comprehension</td>
</tr>
<tr>
 <td style="text-align: left;">
(13) DRS-total correct silent comprehension</td>
</tr>
<tr>
 <td style="text-align: left;">
(14) CTBS-comprehension ESS scores
</td>
</tr>

</table>

<p>DRS refers to Diagnostic Reading Scales, WRAT refers to Wide Range Achievement Test, and CTBS refers to
Comprehensive Tests of basic skills.  
</p>
<p>The model was designed to study the causal relationship between the phonological, word recognition, reading rate, and comprehension components of the reading
process. There are four latent variables in the model: (a) phonological; (b) word recognition; (c) reading rate; 
(d) reading comprehension.
</p>
<p>Phonological is indicated by (a) DRS-consonant sounds; (b) DRS-consonant blends and diagraphs; (c) DRS-common
syllables or phonograms; (d) DRS-blending.
</p>
<p>Word recognition is indicated by (a) WRAT-total raw score; (b) DRS-total correct both lists; (c) DRS-total
words read correct oral
</p>
<p>Reading rate is indicated by (a) DRS-wpm first oral passage; (b) DRS-wpm first silent passage; 
(c) DRS-mean wpm oral passages read; (d) DRS-mean wpm silent passages read.
</p>
<p>Reading comprehension is indicated by (a) DRS-total correct oral comprehension; (b) DRS-total correct 
silent comprehension; (c) CTBS-comprehension ESS scores.
</p>


<h3>Source</h3>

<p>Lomax, R. G. (1983). Applying structural modeling to some component processes of reading comprehension
development. <em>Journal of Experimental Education, 52</em> (1), 33&ndash;40.
</p>


<h3>References</h3>

<p>Lomax, R. G. (1983). Applying structural modeling to some component processes of reading comprehension
development. <em>Journal of Experimental Education, 52</em> (1), 33&ndash;40.
</p>

<hr>
<h2 id='Cor.Mat.MM'> Correlation matrix for Maruyama &amp; McGarvey (1980) data set
</h2><span id='topic+Cor.Mat.MM'></span>

<h3>Description</h3>

<p>Correlation matrix for Maruyama &amp; McGarvey (1980) data set
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(Cor.Mat.MM)</code></pre>


<h3>Details</h3>

<p>Variables 1 through 13 in the correlation matrix are, respectively: 
</p>

<table>
<tr>
 <td style="text-align: left;">
Variables </td>
</tr>
<tr>
 <td style="text-align: left;">
(1) seating popularity </td>
</tr>
<tr>
 <td style="text-align: left;">
(2) playground popularity</td>
</tr>
<tr>
 <td style="text-align: left;">
(3) schoolwork popularity</td>
</tr>
<tr>
 <td style="text-align: left;">
(4) verbal achievement</td>
</tr>
<tr>
 <td style="text-align: left;">
(5) verbal grades </td>
</tr>
<tr>
 <td style="text-align: left;">
(6) Duncan SEI </td>
</tr>
<tr>
 <td style="text-align: left;">
(7) education of head of house</td>
</tr>
<tr>
 <td style="text-align: left;">
(8) No. of rooms over No. of persons </td>
</tr>
<tr>
 <td style="text-align: left;">
(9) Raven Progressive Matrices </td>
</tr>
<tr>
 <td style="text-align: left;">
(10) Peabody PVT </td>
</tr>
<tr>
 <td style="text-align: left;">
(11) father's evaluation </td>
</tr>
<tr>
 <td style="text-align: left;">
(12) mothers evaluation </td>
</tr>
<tr>
 <td style="text-align: left;">
(13) teacher's evaluation
</td>
</tr>

</table>

<p>The model was designed to examine whether acceptance by significant others (i.e., parents, teachers, and peers)
causes improved scholastic achievement. There are five latent variables in the model: (a) SES, socio-economic
status; (b) ABL, academic ability; (c) ACH, achievement; (d) ASA, acceptance by significant adults; (e) APR,
acceptance by peers. 
</p>
<p>SES is indicated by (a) SEI, Duncan Socioeconomic Index of Occupations; (b) EDHH, educational attainment of
the head of the household; (c) R/P, ratio of rooms in the house to persons living in the house.
</p>
<p>ACH is indicated by (a) VACH, standardized verbal test scores; (b) VGR, verbal grades.
</p>
<p>ABL is indicated by (a) PEA, Peabody Picture Vocabulary Test; (b) RAV, Raven Progressive Matrices.
</p>
<p>ASA is indicated by (a) FEV, father's evaluation; (b) MEV, mother's evaluation; (c) TEV, teacher's evaluation.
</p>
<p>APR is indicated by (a) PPOP, playground popularity; (b) SPOP, seating popularity; (c) WPOP, schoolwork popularity.
</p>


<h3>Source</h3>

<p>Maruyama, G., &amp; McGarvey, B. (1980). Evaluating causal models: An application of maximum-likelihood analysis
of structural equations. <em>Psychological Bulletin, 87</em> (3), 502&ndash;512.
</p>


<h3>References</h3>

<p>Maruyama, G., &amp; McGarvey, B. (1980). Evaluating causal models: An application of maximum-likelihood analysis
of structural equations. <em>Psychological Bulletin, 87</em> (3), 502&ndash;512.
</p>

<hr>
<h2 id='cor2cov'> Correlation Matrix to Covariance Matrix Conversion </h2><span id='topic+cor2cov'></span>

<h3>Description</h3>

<p>Function to convert a correlation matrix to a covariance matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cor2cov(cor.mat, sd, discrepancy=1e-5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cor2cov_+3A_cor.mat">cor.mat</code></td>
<td>
<p> the correlation matrix to be converted </p>
</td></tr>
<tr><td><code id="cor2cov_+3A_sd">sd</code></td>
<td>
<p> a vector that contains the standard deviations of the variables in the correlation matrix </p>
</td></tr>
<tr><td><code id="cor2cov_+3A_discrepancy">discrepancy</code></td>
<td>
<p>a neighborhood of 1, such that numbers on the main diagonal of the correlation matrix
will be considered as equal to 1 if they fall in this neighborhood</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The correlation matrix to convert can be either symmetric or triangular. The covariance matrix
returned is always a symmetric matrix.</p>


<h3>Note</h3>

<p> The correlation matrix input should be a square matrix, and the length of <code>sd</code> should be equal to
the number of variables in the correlation matrix (i.e., the number of rows/columns). Sometimes the correlation
matrix input may not have exactly 1's on the main diagonal, due to, eg, rounding; <code>discrepancy</code> specifies
the allowable discrepancy so that the function still considers the input as a correlation matrix and can 
proceed (but the function does not change the numbers on the main diagonal).    
</p>


<h3>Author(s)</h3>

<p> Ken Kelley (University of Notre Dame; <a href="mailto:KKelley@ND.Edu">KKelley@ND.Edu</a>), Keke Lai </p>

<hr>
<h2 id='covmat.from.cfm'> Covariance matrix from confirmatory (single) factor model.</h2><span id='topic+covmat.from.cfm'></span>

<h3>Description</h3>

<p>Function calculates a covariance matrix using the specified <code>Lambda</code> and <code>Psi.Square</code> values from a confirmatory
factor model approach (McDonald, 1999).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>covmat.from.cfm(Lambda, Psi.Square, tol.det = 1e-05)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="covmat.from.cfm_+3A_lambda">Lambda</code></td>
<td>
<p>the vector of population factor loadings</p>
</td></tr>
<tr><td><code id="covmat.from.cfm_+3A_psi.square">Psi.Square</code></td>
<td>
<p>the vector of population error variances </p>
</td></tr>
<tr><td><code id="covmat.from.cfm_+3A_tol.det">tol.det</code></td>
<td>
<p>the specified tolerance for the determinant </p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>Population.Covariance</code></td>
<td>
<p>the population covariance matrix</p>
</td></tr>
<tr><td><code>True.Covariance</code></td>
<td>
<p>the true covariance matrix</p>
</td></tr>
<tr><td><code>True.Covariance</code></td>
<td>
<p>the error covariance matrix</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Ken Kelley (University of Notre Dame; <a href="mailto:KKelley@ND.Edu">KKelley@ND.Edu</a>); 
Leann Terry (Indiana University; <a href="mailto:ljterry@Indiana.Edu">ljterry@Indiana.Edu</a>)
</p>


<h3>References</h3>

<p>McDonald, R. P. (1999). <em>Test theory: A unified approach</em>. Mahwah, NJ: Erlbaum.</p>


<h3>See Also</h3>

<p><code><a href="#topic+CFA.1">CFA.1</a></code>;<code><a href="sem.html#topic+sem">sem</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'># General Congeneric
# covmat.from.cfm(Lambda=c(.8, .9, .6, .8), Psi.Square=c(.6, .2, .1, .3), tol.det=.00001)


# True-score equivalent
# covmat.from.cfm(Lambda=c(.8, .8, .8, .8), Psi.Square=c(.6, .2, .1, .3), tol.det=.00001)


# Parallel 
# covmat.from.cfm(Lambda=c(.8, .8, .8, .8), Psi.Square=c(.2, .2, .2, .2), tol.det=.00001)
</code></pre>

<hr>
<h2 id='cv'>Function to calculate the regular (which is also biased) estimate of the coefficient of variation or the unbiased estimate of the coefficient of variation.</h2><span id='topic+cv'></span>

<h3>Description</h3>

<p>Returns the estimated coefficient of variation or the unbiased estimate of the coefficient of variation.</p>


<h3>Usage</h3>

<pre><code class='language-R'>cv(C.of.V=NULL, mean=NULL, sd=NULL, N=NULL, unbiased=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cv_+3A_c.of.v">C.of.V</code></td>
<td>
<p>Usual estimate of the coefficient of variation (<code>C.of.V=sd/mean</code>)</p>
</td></tr>
<tr><td><code id="cv_+3A_mean">mean</code></td>
<td>
<p>observed mean</p>
</td></tr>
<tr><td><code id="cv_+3A_sd">sd</code></td>
<td>
<p>observed standard deviation (based on <code>N</code>-1 in the denominator of the variance)</p>
</td></tr>
<tr><td><code id="cv_+3A_n">N</code></td>
<td>
<p>sample size</p>
</td></tr>
<tr><td><code id="cv_+3A_unbiased">unbiased</code></td>
<td>
<p>return the unbiased estimate of the coefficient of variation</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A function to calculate the usual estimate of the coefficient of variation or its unbiased estimate.
</p>


<h3>Value</h3>

<p>Returns the estimated coefficient of variation (regular but biased estimate or unbiased estimate.
</p>


<h3>Author(s)</h3>

<p>Ken Kelley (University of Notre Dame; <a href="mailto:KKelley@ND.Edu">KKelley@ND.Edu</a>)</p>


<h3>See Also</h3>

<p><code><a href="#topic+ci.cv">ci.cv</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>cv(mean=100, sd=15)
cv(mean=100, sd=15, N=50, unbiased=TRUE)
cv(C.of.V=.15, N=2, unbiased=TRUE)</code></pre>

<hr>
<h2 id='Expected.R2'>Expected value of the squared multiple correlation coefficient</h2><span id='topic+Expected.R2'></span>

<h3>Description</h3>

<p>Returns the expected value of the squared multiple correlation coefficient given the population squared multiple correlation coefficient, sample size, and the number of predictors</p>


<h3>Usage</h3>

<pre><code class='language-R'>Expected.R2(Population.R2, N, p)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Expected.R2_+3A_population.r2">Population.R2</code></td>
<td>
<p>population squared multiple correlation coefficient</p>
</td></tr>
<tr><td><code id="Expected.R2_+3A_n">N</code></td>
<td>
<p>sample size</p>
</td></tr>
<tr><td><code id="Expected.R2_+3A_p">p</code></td>
<td>
<p>the number of predictor variables</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Uses the hypergeometric function as discussed in section 28 of Stuart, Ord, and Arnold (1999) in order to obtain the <em>correct</em>
value for the squared multiple correlation coefficient. Many times an exact value is given that ignores the hypergeometric function. 
This function yields the correct value. 
</p>


<h3>Value</h3>

<p>Returns the expected value of the squared multiple correlation coefficient.
</p>


<h3>Note</h3>

<p>Uses package <code>gsl</code> and its <code>hyperg_2F1</code> function.
</p>


<h3>Author(s)</h3>

<p>Ken Kelley (University of Notre Dame; <a href="mailto:KKelley@ND.Edu">KKelley@ND.Edu</a>)</p>


<h3>References</h3>

<p>Olkin, I. &amp; Pratt, J. W. (1958). Unbiased estimation of certain correlation coefficients. <em>Annals of Mathematical statistics, 29</em>, 201&ndash;211.
</p>
<p>Stuart, A., Ord, J. K., &amp; Arnold, S. (1999). <em>Kendall's advanced theory of statistics: Classical inference and the linear model</em> (Volume 2A, 2nd Edition).
New York, NY: Oxford University Press. 
</p>


<h3>See Also</h3>

<p><code>ss.aipe.R2</code>, <code>ci.R2</code>, <code>Variance.R2</code></p>


<h3>Examples</h3>

<pre><code class='language-R'># library(gsl)
# Expected.R2(.5, 10, 5)
# Expected.R2(.5, 25, 5)
# Expected.R2(.5, 50, 5)
# Expected.R2(.5, 100, 5)
# Expected.R2(.5, 1000, 5)
# Expected.R2(.5, 10000, 5)
</code></pre>

<hr>
<h2 id='F.and.R2.Noncentral.Conversion'>Conversion functions from noncentral noncentral values to their corresponding
and vice versa, for those related to the F-test and R Square.</h2><span id='topic+Rsquare2F'></span><span id='topic+Rsquare2Lambda'></span><span id='topic+F2Rsquare'></span><span id='topic+Lambda2Rsquare'></span>

<h3>Description</h3>

<p>Given values of test statistics (and the appropriate additional information) the value of the noncentral
values can be obtained. Likewise, given noncentral values (and the appropriate additional information)
the value of the test statistic can be obtained. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Rsquare2F(R2 = NULL, df.1 = NULL, df.2 = NULL, p = NULL, N = NULL)

F2Rsquare(F.value = NULL, df.1 = NULL, df.2 = NULL)

Lambda2Rsquare(Lambda = NULL, N = NULL)

Rsquare2Lambda(R2 = NULL, N = NULL)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="F.and.R2.Noncentral.Conversion_+3A_r2">R2</code></td>
<td>
<p>squared multiple correlation coefficient (population or observed)</p>
</td></tr>
<tr><td><code id="F.and.R2.Noncentral.Conversion_+3A_df.1">df.1</code></td>
<td>
<p>degrees of freedom for the numerator of the <em>F</em>-distribution</p>
</td></tr>
<tr><td><code id="F.and.R2.Noncentral.Conversion_+3A_df.2">df.2</code></td>
<td>
<p>degrees of freedom for the denominator of the <em>F</em>-distribution</p>
</td></tr>
<tr><td><code id="F.and.R2.Noncentral.Conversion_+3A_p">p</code></td>
<td>
<p>number of predictor variables for <code>R2</code></p>
</td></tr>
<tr><td><code id="F.and.R2.Noncentral.Conversion_+3A_n">N</code></td>
<td>
<p>sample size</p>
</td></tr>
<tr><td><code id="F.and.R2.Noncentral.Conversion_+3A_f.value">F.value</code></td>
<td>
<p>The obtained F value from a test of significance for the squared multiple correlation coefficient</p>
</td></tr>
<tr><td><code id="F.and.R2.Noncentral.Conversion_+3A_lambda">Lambda</code></td>
<td>
<p>The noncentral parameter from an <em>F</em>-distribution</p>
</td></tr>
</table>


<h3>Details</h3>

<p>These functions are especially helpful in the search for confidence intervals for noncentral parameters, as they 
convert to and from related quantities.</p>


<h3>Value</h3>

<p>Returns the converted value from the specified function.
</p>


<h3>Author(s)</h3>

<p>Ken Kelley (University of Notre Dame, <a href="mailto:KKelley@ND.Edu">KKelley@ND.Edu</a>)</p>


<h3>See Also</h3>

<p><code>ss.aipe.R2</code>, <code>ci.R2</code>, <code>conf.limits.nct</code>, <code>conf.limits.ncf</code></p>


<h3>Examples</h3>

<pre><code class='language-R'>Rsquare2Lambda(R2=.5, N=100)</code></pre>

<hr>
<h2 id='Gardner.LD'>The Gardner learning data, which was used by L.R. Tucker</h2><span id='topic+Gardner.LD'></span>

<h3>Description</h3>

<p>Repeated measures data on 24 participants, each with 21 trials (each trial based on 20 replications).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(Gardner.LD)</code></pre>


<h3>Format</h3>

<p>A data frame where the rows represent the timepoints for the individuals.
</p>

<dl>
<dt><code>ID</code></dt><dd><p>: a numeric vector</p>
</dd>
<dt><code>Trial</code></dt><dd><p>: a numeric vector</p>
</dd>
<dt><code>Score</code></dt><dd><p>: a numeric vector</p>
</dd>
<dt><code>Group</code></dt><dd><p>: a numeric vector</p>
</dd>
</dl>



<h3>Details</h3>

<p>The 24 participants of this study were presented with 420 presentations of four letters 
where the task was to identify the next letter that was to be presented. Twelve of the participants (Group 1) were
presented the letters S, L, N, and D with probabilities .70, .10, .10, and .10, respectively.
The other 12 participants (Group 2) were presented the letter L with probability .70 and three other
letters, each with a probability of .10. The 420 presentations were (arbitrarily it seems) 
grouped into 21 trials of 20 presentations. The score for each trial was the number of times the individual
correctly guessed the dominant letter. The participants were naive to the probability that the
letters would be presented. Other groups of individuals (although the data is not available) 
were tested under a different probability structure. The data given here is thus known as the 70-10-10-10 group from 
Gardner's paper. L. R. Tucker used this data set to illustrate methods for understanding change.
</p>


<h3>Source</h3>

<p>Tucker, L. R. (1960). Determination of Generalized Learning Curves by Factor Analysis,
Educational Testing Services, Princeton, NJ.
</p>


<h3>References</h3>

<p>Gardner, R. A., (1958). Multiple-choice decision-behavior, <em>American Journal of Psychology</em>, 71,
710&ndash;717.
</p>

<hr>
<h2 id='HS'> Complete Data Set of Holzinger and Swineford's (1939) Study</h2><span id='topic+HS'></span>

<h3>Description</h3>

<p>The <em>complete</em> data set of scores of 301 participants in 26 tests in Holzinger and Swineford's (1939) study.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(HS)</code></pre>


<h3>Format</h3>

<p>A data frame with 301 observations on the following 34 variables.
</p>

<dl>
<dt><code>id</code></dt><dd><p>case number of participants (note there are skips) </p>
</dd>
<dt><code>sex</code></dt><dd><p>sex of participants</p>
</dd>
<dt><code>grade</code></dt><dd><p>grade in school of the participants with levels <code>Female</code> <code>Male</code></p>
</dd>
<dt><code>age</code></dt><dd><p>the age (ignoring months into the year) of the participants</p>
</dd>
<dt><code>month_since_birthday</code></dt><dd><p>the number of months since the last birthday</p>
</dd>
<dt><code>age_months</code></dt><dd><p>age in months</p>
</dd>
<dt><code>age_years</code></dt><dd><p>age in years and months combined (more fine grained measure of years)</p>
</dd>
<dt><code>school</code></dt><dd><p>the school the participant is from with levels <code>Grant-White</code> <code>Pasteur</code></p>
</dd>
<dt><code>t1_visual_perception</code></dt><dd><p>scores on visual perception test, test 1</p>
</dd>
<dt><code>t2_cubes</code></dt><dd><p>scores on cubes test, test 2</p>
</dd>
<dt><code>t3_paper_form_board</code></dt><dd><p>scores on paper form board test, test 3</p>
</dd>
<dt><code>t4_lozenges</code></dt><dd><p>scores on lozenges test, test 4</p>
</dd>
<dt><code>t5_general_information</code></dt><dd><p>scores on general information test, test 5</p>
</dd>
<dt><code>t6_paragraph_comprehension</code></dt><dd><p>scores on paragraph comprehension test, test 6</p>
</dd>
<dt><code>t7_sentence</code></dt><dd><p>scores on sentence completion test, test 7</p>
</dd>
<dt><code>t8_word_classification</code></dt><dd><p>scores on word classification test, test 8</p>
</dd>
<dt><code>t9_word_meaning</code></dt><dd><p>scores on word meaning test, test 9</p>
</dd>
<dt><code>t10_addition</code></dt><dd><p>scores on add test, test 10</p>
</dd>
<dt><code>t11_code</code></dt><dd><p>scores on code test, test 11</p>
</dd>
<dt><code>t12_counting_groups_of_dots</code></dt><dd><p>scores on counting groups of dots test, test 12</p>
</dd>
<dt><code>t13_straight_and_curved_capitals</code></dt><dd><p>scores on straight and curved capitals test, test 13</p>
</dd>
<dt><code>t14_word_recognition</code></dt><dd><p>scores on word recognition test, test 14</p>
</dd>
<dt><code>t15_number_recognition</code></dt><dd><p>scores on number recognition test, test 15</p>
</dd>
<dt><code>t16_figure_recognition</code></dt><dd><p>scores on figure recognition test, test 16</p>
</dd>
<dt><code>t17_object_number</code></dt><dd><p>scores on object-number test, test 17</p>
</dd>
<dt><code>t18_number_figure</code></dt><dd><p>scores on number-figure test, test 18</p>
</dd>
<dt><code>t19_figure_word</code></dt><dd><p>scores on figure-word test, test 19</p>
</dd>
<dt><code>t20_deduction</code></dt><dd><p>scores on deduction test, test 20</p>
</dd>
<dt><code>t21_numerical_puzzles</code></dt><dd><p>scores on numerical puzzles test, test 21</p>
</dd>
<dt><code>t22_problem_reasoning</code></dt><dd><p>scores on problem reasoning test, test 22</p>
</dd>
<dt><code>t23_series_completion</code></dt><dd><p>scores on series completion test, test 23</p>
</dd>
<dt><code>t24_woody_mccall</code></dt><dd><p>scores on Woody-McCall mixed fundamentals, form I test, test 24</p>
</dd>
<dt><code>t25_paper_form_board_r</code></dt><dd><p>scores on additional paper form board test, test 25</p>
</dd>
<dt><code>t26_flags</code></dt><dd><p>scores on flags test, test 26</p>
</dd>
</dl>



<h3>Details</h3>

<p>Holzinger and Swineford (1939) data is widely cited, but generally only the Grant-White School data 
is used. The present dataset contains the complete data of Holzinger and Swineford (1939). 
</p>
<p>A total number of 301 pupils, coming from Paster School and Grant-White School, who participated in Holzinger
and Swineford's (1939) study. This study consists of 26 tests, which are used to measure 
the participants' spatial, verbal, mental speed, memory, and mathematical ability. 
</p>
<p>The spatial tests consist of <code>t1_visual_perception</code>, <code>t2_cubes</code>, <code>t3_paper_form_board</code>, <code>t4_lozenges</code>. Additional spatial tests are <code>t25_paper_form_board_r</code> (revised test 3) and <code>t26_flags</code>. <code>t25_paper_form_board_r</code> can (potentially) be used as a substitute for <code>t3_paper_form_board</code>. <code>t26_flags</code> is thought to be a possible substitute for <code>t4_lozenges</code>.
</p>
<p>The verbal tests consist of <code>t5_general_information</code>, <code>t6_paragraph_comprehension</code>, <code>t7_sentence</code>, <code>t8_word_classification</code>, and <code>t9_word_meaning</code>.
</p>
<p>The speed tests consist of <code>t10_addition</code>, <code>t11_code</code>, <code>t12_counting_groups_of_dots</code>, and <code>t13_straight_and_curved_capitals</code>.
</p>
<p>The memory tests consist of <code>t14_word_recognition</code>, <code>t15_number_recognition</code>, <code>t16_figure_recognition</code>, <code>t17_object_number</code>, <code>t18_number_figure</code>, and <code>t19_figure_word</code>.
</p>
<p>The mathematical-ability tests consist of <code>t20_deduction</code>, <code>t21_numerical_puzzles</code>, <code>t22_problem_reasoning</code>, 
<code>t23_series_completion</code>, and <code>t24_woody_mccall</code>.
</p>


<h3>Source</h3>

<p>Holzinger, K. J. and Swineford, F. A. (1939). A study in factor
analysis: The stability of a bi-factor solution. <em>Supplementary Education
Monographs, 48</em>. University of Chicago.
</p>


<h3>References</h3>

<p>Holzinger, K. J. and Swineford, F. A. (1939). A study in factor
analysis: The stability of a bi-factor solution. <em>Supplementary Education
Monographs, 48</em>. University of Chicago.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(HS)
summary(HS)
</code></pre>

<hr>
<h2 id='intr.plot'>  Regression Surface Containing Interaction </h2><span id='topic+intr.plot'></span>

<h3>Description</h3>

<p>To plot a three dimentional figure of a multiple regression surface containing one two-way interaction.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>intr.plot(b.0, b.x, b.z, b.xz, x.min = NULL, x.max = NULL, z.min = NULL, 
z.max = NULL, n.x = 50, n.z = 50, x = NULL, z = NULL, col = "lightblue", 
hor.angle = -60, vert.angle = 15, xlab = "Value of X", zlab = "Value of Z", 
ylab = "Dependent Variable", expand = 0.5, lines.plot=TRUE, col.line = "red", 
line.wd = 2, gray.scale = FALSE, ticktype="detailed", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="intr.plot_+3A_b.0">b.0</code></td>
<td>
<p> the intercept </p>
</td></tr>
<tr><td><code id="intr.plot_+3A_b.x">b.x</code></td>
<td>
<p> regression coefficient for predictor x </p>
</td></tr>
<tr><td><code id="intr.plot_+3A_b.z">b.z</code></td>
<td>
<p> regression coefficient for predictor z </p>
</td></tr>
<tr><td><code id="intr.plot_+3A_b.xz">b.xz</code></td>
<td>
<p> regression coefficient for the interaction of predictors x and z </p>
</td></tr>
<tr><td><code id="intr.plot_+3A_x.min">x.min</code>, <code id="intr.plot_+3A_x.max">x.max</code>, <code id="intr.plot_+3A_z.min">z.min</code>, <code id="intr.plot_+3A_z.max">z.max</code></td>
<td>
<p>ranges of x and z. The regression surface defined by these limits will be plotted.</p>
</td></tr>
<tr><td><code id="intr.plot_+3A_n.x">n.x</code></td>
<td>
<p> number of elements in predictor vector x; number of points to be plotted on the regression surface; default is 50</p>
</td></tr>
<tr><td><code id="intr.plot_+3A_n.z">n.z</code></td>
<td>
<p> number of elements in predictor vector z; number of points to be plotted on the regression surface; default is 50</p>
</td></tr>
<tr><td><code id="intr.plot_+3A_x">x</code></td>
<td>
<p> a specific predictor vector <code>x</code>, used instead of <code>x.max</code> and <code>x.min</code></p>
</td></tr>
<tr><td><code id="intr.plot_+3A_z">z</code></td>
<td>
<p> a specific predictor vector <code>z</code>, used instead of <code>z.max</code> and <code>z.min</code> </p>
</td></tr>
<tr><td><code id="intr.plot_+3A_col">col</code></td>
<td>
<p> color of the regression surface; default is lightbule</p>
</td></tr>
<tr><td><code id="intr.plot_+3A_hor.angle">hor.angle</code></td>
<td>
<p> rotate the regression surface horizontally; default is -60 degree </p>
</td></tr>
<tr><td><code id="intr.plot_+3A_vert.angle">vert.angle</code></td>
<td>
<p> rotate the regression surface vertically; default is 15 degree </p>
</td></tr>
<tr><td><code id="intr.plot_+3A_xlab">xlab</code></td>
<td>
<p> title for the axis which the predictor <code>x</code> is on  </p>
</td></tr>
<tr><td><code id="intr.plot_+3A_zlab">zlab</code></td>
<td>
<p> title for the axis which the predictor <code>z</code> is on </p>
</td></tr>
<tr><td><code id="intr.plot_+3A_ylab">ylab</code></td>
<td>
<p> title for the axis which the dependent <code>y</code> is on </p>
</td></tr>
<tr><td><code id="intr.plot_+3A_expand">expand</code></td>
<td>
<p> default is 0.5; expansion factor applied to the axis of the dependent variable. Often used with 0 &lt; <code>expand</code> &lt; 1 to shrink the plotting box in the direction of the dependent variable's axis. </p>
</td></tr>
<tr><td><code id="intr.plot_+3A_lines.plot">lines.plot</code></td>
<td>
<p> whether or not to plot on the regression surface regression lines holding z at
values 0, 1, -1, 2, -2 above the mean; default is <code>TRUE</code>. </p>
</td></tr>
<tr><td><code id="intr.plot_+3A_col.line">col.line</code></td>
<td>
<p> the color of regression lines plotted on the regression surface; default is red </p>
</td></tr>
<tr><td><code id="intr.plot_+3A_line.wd">line.wd</code></td>
<td>
<p> the width of regression lines plotted on the regression surface; default is 2 </p>
</td></tr>
<tr><td><code id="intr.plot_+3A_gray.scale">gray.scale</code></td>
<td>
<p> whether or not to plot the figure black and white; default is <code>FALSE</code> </p>
</td></tr>
<tr><td><code id="intr.plot_+3A_ticktype">ticktype</code></td>
<td>
<p> whether the axes should be plotted with (<code>"detailed"</code>) or without (<code>"simple"</code>) tick marks</p>
</td></tr>
<tr><td><code id="intr.plot_+3A_...">...</code></td>
<td>
<p> allows one to potentially include parameter values for inner functions </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The user can input either the limits of <code>x</code> and <code>z</code>, or specific <code>x</code> and <code>z</code> vectors, to draw the regression surface. If the user inputs simply the limits of the predictors, the function would generate predictor vectors for plotting. 
If the user inputs specific predictor vectors, the function would plot the regression surface based on those vectors. 
</p>


<h3>Note</h3>

<p> If the user enters specific vectors instead of the ranges of predictors, please make sure
elements in those vectors are in ascending order. This is required by function <code>persp</code>, which 
is used within this function.  
</p>


<h3>Author(s)</h3>

<p>Keke Lai (University of California &ndash; Merced) and Ken Kelley (University of Notre Dame; <a href="mailto:KKelley@ND.Edu">KKelley@ND.Edu</a>) </p>


<h3>References</h3>

<p>Cohen, J., Cohen, P., West, S. G. and Aiken, L. S. (2003). <em>Applied multiple regression/correlation analysis for the behavioral sciences</em> (3rd ed.). Mahwah, NJ: Erlbaum. </p>


<h3>See Also</h3>

 <p><code>intr.plot.2d</code>, <code>persp</code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>##  A way to replicate the example given by Cohen et al. (2003) (pp. 258--263):
##  The regression equation with interaction is y=.2X+.6Z+.4XZ+2
##  To plot a regression surface and regression lines of Y on X holding Z 
##  at -1, 0, and 1 standard deviation above the mean

x&lt;- c(0,2,4,6,8,10)
z&lt;-c(0,2,4,6,8,10)
intr.plot(b.0=2, b.x=.2, b.z=.6, b.xz=.4, x=x, z=z)

## input limits of the predictors instead of specific x and z predictor vectors
intr.plot(b.0=2, b.x=.2, b.z=.6, b.xz=.4, x.min=5, x.max=10, z.min=0, z.max=20)

intr.plot(b.0=2, b.x=.2, b.z=.6, b.xz=.4, x.min=0, x.max=10, z.min=0, z.max=10, 
col="gray", hor.angle=-65, vert.angle=10)

##  To plot a black-and-white figure
intr.plot(b.0=2, b.x=.2, b.z=.6, b.xz=.4, x.min=0, x.max=10, z.min=0, z.max=10, 
gray.scale=TRUE)

## to adjust the tick marks on the axes
intr.plot(b.0=2, b.x=.2, b.z=.6, b.xz=.4, x.min=0, x.max=10, z.min=0, z.max=10, 
ticktype="detailed", nticks=8)
</code></pre>

<hr>
<h2 id='intr.plot.2d'>Plotting Conditional Regression Lines with Interactions in Two Dimensions </h2><span id='topic+intr.plot.2d'></span>

<h3>Description</h3>

<p>To plot regression lines for one two-way interactions, holding one of the predictors (in this function, z) at 
values -2, -1, 0, 1, and 2 standard deviations above the mean.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
intr.plot.2d(b.0, b.x, b.z, b.xz,x.min=NULL, x.max=NULL, x=NULL, 
n.x=50, mean.z=NULL, sd.z=NULL, z=NULL,xlab="Value of X",  
ylab="Dependent Variable", sd.plot=TRUE, sd2.plot=TRUE, sd_1.plot=TRUE, 
sd_2.plot=TRUE, type.sd=2, type.sd2=3, type.sd_1=4, type.sd_2=5, 
legend.pos="bottomright", legend.on=TRUE, ... )
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="intr.plot.2d_+3A_b.0">b.0</code></td>
<td>
<p> the intercept </p>
</td></tr>
<tr><td><code id="intr.plot.2d_+3A_b.x">b.x</code></td>
<td>
<p> regression coefficient for predictor x </p>
</td></tr>
<tr><td><code id="intr.plot.2d_+3A_b.z">b.z</code></td>
<td>
<p> regression coefficient for predictor z  </p>
</td></tr>
<tr><td><code id="intr.plot.2d_+3A_b.xz">b.xz</code></td>
<td>
<p> regression coefficient for the interaction of predictors x and z </p>
</td></tr>
<tr><td><code id="intr.plot.2d_+3A_x.min">x.min</code>, <code id="intr.plot.2d_+3A_x.max">x.max</code></td>
<td>
<p>the range of x used in the plot</p>
</td></tr>
<tr><td><code id="intr.plot.2d_+3A_x">x</code></td>
<td>
<p> a specific predictor vector x, used instead of <code>x.min</code> and <code>x.max</code> </p>
</td></tr>
<tr><td><code id="intr.plot.2d_+3A_n.x">n.x</code></td>
<td>
<p>number of elements in predictor vector x</p>
</td></tr>
<tr><td><code id="intr.plot.2d_+3A_mean.z">mean.z</code></td>
<td>
<p> mean of predictor z </p>
</td></tr>
<tr><td><code id="intr.plot.2d_+3A_sd.z">sd.z</code></td>
<td>
<p> standard deviation of predictor z </p>
</td></tr>
<tr><td><code id="intr.plot.2d_+3A_z">z</code></td>
<td>
<p>a specific predictor vector z, used instead of <code>z.min</code> and <code>z.max</code> </p>
</td></tr>
<tr><td><code id="intr.plot.2d_+3A_xlab">xlab</code></td>
<td>
<p> title for the axis which the predictor x is on </p>
</td></tr>
<tr><td><code id="intr.plot.2d_+3A_ylab">ylab</code></td>
<td>
<p> title for the axis which the dependent y is on </p>
</td></tr>
<tr><td><code id="intr.plot.2d_+3A_sd.plot">sd.plot</code>, <code id="intr.plot.2d_+3A_sd2.plot">sd2.plot</code>, <code id="intr.plot.2d_+3A_sd_1.plot">sd_1.plot</code>, <code id="intr.plot.2d_+3A_sd_2.plot">sd_2.plot</code></td>
<td>
<p> whether or not to plot 
the regression line holding z at values 1, 2, -1, and -2 standard deviations above the mean, respectively. 
Default values are all <code>TRUE</code>. </p>
</td></tr>
<tr><td><code id="intr.plot.2d_+3A_type.sd">type.sd</code>, <code id="intr.plot.2d_+3A_type.sd2">type.sd2</code>, <code id="intr.plot.2d_+3A_type.sd_1">type.sd_1</code>, <code id="intr.plot.2d_+3A_type.sd_2">type.sd_2</code></td>
<td>
<p> types of lines to be plotted holding z at values 1, 2,
-1, and -2 standard deviations above the mean, respectively. Default are line type 2,3,4, and 5, respectively. </p>
</td></tr>
<tr><td><code id="intr.plot.2d_+3A_legend.pos">legend.pos</code></td>
<td>
<p> position of the legend; possible options are <code>"bottomright"</code>, <code>"bottom"</code>, 
<code>"bottomleft"</code>, <code>"left"</code>, <code>"center"</code>, <code>"right"</code>, <code>"topleft"</code>, 
<code>"top"</code>, and <code>"topright"</code>. </p>
</td></tr>
<tr><td><code id="intr.plot.2d_+3A_legend.on">legend.on</code></td>
<td>
<p>whether or not to show the legend</p>
</td></tr>
<tr><td><code id="intr.plot.2d_+3A_...">...</code></td>
<td>
<p> allows one to potentially include parameter values for inner functions </p>
</td></tr>
</table>


<h3>Details</h3>

<p>To input the predictor x, one can use either the limits of x (<code>x.max</code> and <code>x.min</code>) , or a specific vector x (<code>x</code>). 
To input the predictor z, one can use either the mean and standard deviation of z (<code>mean.z</code> and <code>sd.z</code> ), or a specific vector z (<code>z</code>).   
</p>


<h3>Note</h3>

<p> Sometimes some of the regression lines are outside the default scope of the coordinates 
and thus cannot be seen; in such situations, one needs to, by entering additional arguments, adjust the scope to
let proper sections of regression lines be seen. Refer to examples below for more details.
</p>


<h3>Author(s)</h3>

<p> Keke Lai, Ken Kelley (University of Notre Dame; <a href="mailto:KKelley@ND.Edu">KKelley@ND.Edu</a>)  </p>


<h3>References</h3>

<p>Cohen, J., Cohen, P., West, S. G. and Aiken, L. S. (2003). <em>Applied multiple regression/correlation 
analysis for the behavioral sciences</em> (3rd ed.). Mahwah, NJ: Erlbaum.</p>


<h3>See Also</h3>

 <p><code>intr.plot</code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>## A situation where one regression line is outside the default scope of the coordinates
intr.plot.2d(b.0=16, b.x=2.2, b.z=2.6, b.xz=.4, x.min=0, x.max=20, mean.z=0, sd.z=3)

## Adjust the scope of x and y axes so that proper sections of regression lines can be seen 
intr.plot.2d(b.0=16, b.x=2.2, b.z=2.6, b.xz=.4, x.min=0, x.max=50, mean.z=0, 
sd.z=3, xlim=c(0,50), ylim=c(-20,100) )

## Use specific vector(s) to define the predictor(s) 
intr.plot.2d(b.0=16, b.x=2.2, b.z=2.6, b.xz=.4, x=c(1:10), z=c(0,2,4,6,8,10))

intr.plot.2d(b.0=16, b.x=2.2, b.z=2.6, b.xz=.4, x.min=0, x.max=20, 
z=c(1,3,6,7,9,13,16,20), ylim=c(0,100))

## Change the position of the legend so that it does not block regression lines
intr.plot.2d(b.0=10, b.x=-.3, b.z=1, b.xz=.5, x.min=0, x.max=40, mean.z=-5, sd.z=3, 
ylim=c(-100,100),legend.pos="topright" )

</code></pre>

<hr>
<h2 id='MBESS'>MBESS</h2><span id='topic+MBESS'></span><span id='topic+mbess'></span><span id='topic+MBES'></span><span id='topic+mbes'></span>

<h3>Description</h3>

<p><code>MBESS</code> Implements methods that are useful in designing research studies and analyzing data, with 
particular emphasis on methods that are developed for or used within the behavioral, 
educational, and social sciences (broadly defined). That being said, many of the methods 
implemented within MBESS are applicable to a wide variety of disciplines. MBESS has a 
suite of functions for a variety of related topics, such as effect sizes, confidence intervals 
for effect sizes (including standardized effect sizes and noncentral effect sizes), sample size
planning (from the accuracy in parameter estimation [AIPE], power analytic, equivalence, and 
minimum-risk point estimation perspectives), mediation analysis, various properties of 
distributions, and a variety of utility functions. MBESS (pronounced 'em-bes') was originally 
an acronym for 'Methods for the Behavioral, Educational, and Social Sciences,' but MBESS became
more general and now contains methods applicable and used in a wide variety of fields and is an 
orphan acronym, in the sense that what was an acronym is now literally its name. MBESS has 
greatly benefited from others, see &lt;https://www3.nd.edu/~kkelley/site/MBESS.html&gt; for a detailed 
list of those that have contributed and other details.
</p>


<h3>Details</h3>


<table>
<tr>
 <td style="text-align: left;">
Package: </td><td style="text-align: left;"> MBESS</td>
</tr>
<tr>
 <td style="text-align: left;">
Type: </td><td style="text-align: left;"> Package</td>
</tr>
<tr>
 <td style="text-align: left;">
Version: </td><td style="text-align: left;"> 4.8.1 </td>
</tr>
<tr>
 <td style="text-align: left;">
Date: </td><td style="text-align: left;"> 2021-10-16</td>
</tr>
<tr>
 <td style="text-align: left;">
License: </td><td style="text-align: left;"> GPL(&gt;=2)</td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>

<p>Please read the manual and visit the corresponding web site 
<a href="https://www3.nd.edu/~kkelley/site/MBESS.html">https://www3.nd.edu/~kkelley/site/MBESS.html</a> 
for information on the capabilities of the <code>MBESS</code> package. Feel free 
to contact me if there is a feature you would like to see added if it would 
complement the goals of the MBESS package. Beginning with version 
4.8.0, the package also has a home on GitHub <a href="https://github.com/yelleKneK/MBESS">https://github.com/yelleKneK/MBESS</a>. 
Over the years, multiple people have contributed functions to the package. See individual 
functions for details. 
</p>


<h3>Author(s)</h3>

<p>Ken Kelley &lt;<a href="mailto:KKelley@ND.Edu">KKelley@ND.Edu</a>; https://www3.nd.edu/~kkelley/&gt; 
</p>
<p>Maintainer: Ken Kelley &lt;<a href="mailto:KKelley@ND.Edu">KKelley@ND.Edu</a>; https://www3.nd.edu/~kkelley/&gt;
</p>

<hr>
<h2 id='mediation'> Effect sizes and confidence intervals in a mediation model </h2><span id='topic+mediation'></span>

<h3>Description</h3>

<p>Automate the process of simple mediation analysis (one independent variable and one mediator) and effect size estimation for mediation models, as discussed in Preacher and Kelley (2011). 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mediation(x, mediator, dv, S = NULL, N = NULL, x.location.S = NULL, 
mediator.location.S = NULL, dv.location.S = NULL, mean.x = NULL, 
mean.m = NULL, mean.dv = NULL, conf.level = 0.95, 
bootstrap = FALSE, B = 10000, which.boot="both", save.bs.replicates=FALSE,
complete.set=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mediation_+3A_x">x</code></td>
<td>
<p>vector of the predictor/independent variable</p>
</td></tr>
<tr><td><code id="mediation_+3A_mediator">mediator</code></td>
<td>
<p>vector of the mediator variable</p>
</td></tr>
<tr><td><code id="mediation_+3A_dv">dv</code></td>
<td>
<p>vector of the dependent/outcome variable</p>
</td></tr>
<tr><td><code id="mediation_+3A_s">S</code></td>
<td>
<p>Covariance matrix</p>
</td></tr>
<tr><td><code id="mediation_+3A_n">N</code></td>
<td>
<p>Sample size, necessary when a covariance matrix (<code>S</code>) is used</p>
</td></tr>
<tr><td><code id="mediation_+3A_x.location.s">x.location.S</code></td>
<td>
<p> location of the predictor/independent variable in the covariance matrix (<code>S</code>)</p>
</td></tr>
<tr><td><code id="mediation_+3A_mediator.location.s">mediator.location.S</code></td>
<td>
<p>location of the mediator variable in the covariance matrix (<code>S</code>)</p>
</td></tr>
<tr><td><code id="mediation_+3A_dv.location.s">dv.location.S</code></td>
<td>
<p>location of the dependent/outcome variable in the covariance matrix (<code>S</code>)</p>
</td></tr>
<tr><td><code id="mediation_+3A_mean.x">mean.x</code></td>
<td>
<p>mean of the <code>x</code> (independent/predictor) variable when a covariance matrix (<code>S</code>) is used</p>
</td></tr>
<tr><td><code id="mediation_+3A_mean.m">mean.m</code></td>
<td>
<p>mean of the <code>m</code> (mediator) variable when a covariance matrix (<code>S</code>) is used</p>
</td></tr>
<tr><td><code id="mediation_+3A_mean.dv">mean.dv</code></td>
<td>
<p>mean of the <code>y/dv</code> (dependent/outcome) variable when a covariance matrix (<code>S</code>) is used</p>
</td></tr>
<tr><td><code id="mediation_+3A_conf.level">conf.level</code></td>
<td>
<p>desired level of confidence (e.g., .90, .95, .99, etc.)</p>
</td></tr>
<tr><td><code id="mediation_+3A_bootstrap">bootstrap</code></td>
<td>
<p><code>TRUE</code> or <code>FALSE</code>, based on whether or not a bootstrap procedure is performed to obtain confidence intervals for the various effect sizes</p>
</td></tr>
<tr><td><code id="mediation_+3A_b">B</code></td>
<td>
<p>number of bootstrap replications when <code>bootstrap=TRUE</code> (e.g., 10000)</p>
</td></tr>
<tr><td><code id="mediation_+3A_which.boot">which.boot</code></td>
<td>
<p>which bootstrap method to use. It can be <code>Percentile</code> or <code>BCa</code>, or both</p>
</td></tr>
<tr><td><code id="mediation_+3A_save.bs.replicates">save.bs.replicates</code></td>
<td>
<p>Logical argument indicating whether to save the each bootstrap sample or not</p>
</td></tr>
<tr><td><code id="mediation_+3A_complete.set">complete.set</code></td>
<td>
<p>identifies if the function should report the estimated kappa.squarred (see below)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Based on the work of Preacher and Kelley (2010) and works cited therein, this function implements (simple) mediation analysis in a way that automates much of the results that are generally of interest, where &quot;simple&quot; means one independent variable, one mediator, and one dependent variable. More specifically, three regression outputs are automated as is the calculation of effect sizes that are thought to be useful or potentially useful in the context of mediation. Much work on mediation models exists in the literature, which should be consulted for proper interpretation of the effect sizes, models, and meaning of results. The usefulness of effect size <code class="reqn">\kappa^2</code> was called into question
by Wen and Fan (2015). Further, another paper by Lachowicz, Preacher, and Kelley (submitted) offers a better was of quantifying the effect size and it is developed for more complex models. Users are encouraged to use, instead of or in addition to this function, the <a href="#topic+upsilon">upsilon</a> function.
</p>


<h3>Value</h3>

<table>
<tr><td><code>Y.on.X$Regression.Table</code></td>
<td>
<p>Regression table of <code>Y</code> conditional on <code>X</code></p>
</td></tr>
<tr><td><code>Y.on.X$Model.Fit</code></td>
<td>
<p>Summary of model fit for the regression of <code>Y</code> conditional on <code>X</code></p>
</td></tr>
<tr><td><code>M.on.X$Regression.Table</code></td>
<td>
<p>Regression table of <code>X</code> conditional on <code>M</code></p>
</td></tr>
<tr><td><code>M.on.X$Model.Fit</code></td>
<td>
<p>Summary of model fit for the regression of <code>X</code> conditional on <code>M</code></p>
</td></tr>
<tr><td><code>Y.on.X.and.M$Regression.Table</code></td>
<td>
<p>Regression table of <code>Y</code> conditional on <code>X</code> and <code>M</code></p>
</td></tr>
<tr><td><code>Y.on.X.and.M$Model.Fit</code></td>
<td>
<p>Summary of model fit for the regression of <code>Y</code> conditional on <code>X</code> and <code>M</code></p>
</td></tr>
<tr><td><code>Indirect.Effect</code></td>
<td>
<p>the product of <code class="reqn">\hat{a} \times \hat{b}</code>, where <code class="reqn">\hat{a}</code> and <code class="reqn">\hat{b}</code> are the estimated coefficients of the path from the independent variable to the mediator and the path from the mediator to the dependent variable</p>
</td></tr>
<tr><td><code>Indirect.Effect.Partially.Standardized</code></td>
<td>
<p>It is the indirect effect (see <code>Indirect.Effect</code> above) divided by the estimated standard deviation of <code>Y</code> (MacKinnon, 2008)</p>
</td></tr>
<tr><td><code>Index.of.Mediation</code></td>
<td>
<p>Index of mediation (indirect effect multiplied by the ratio of the standard deviation of X to the standard deviation of Y) (Preacher and Hayes, 2008)</p>
</td></tr>
<tr><td><code>R2_4.5</code></td>
<td>
<p>An index of explained variance see MacKinnon (2008, Eq. 4.5) for details</p>
</td></tr>
<tr><td><code>R2_4.6</code></td>
<td>
<p>An index of explained variance see MacKinnon (2008, Eq. 4.6) for details</p>
</td></tr>
<tr><td><code>R2_4.7</code></td>
<td>
<p>An index of explained variance see MacKinnon (2008, Eq. 4.7) for details</p>
</td></tr>
<tr><td><code>Maximum.Possible.Mediation.Effect</code></td>
<td>
<p>the maximum attainable value of the mediation effect (i.e., the indirect effect), in the direction of the observed indirect effect, that could have been observed, conditional on the sample variances and on the magnitudes of relationships among some of the variables</p>
</td></tr>
<tr><td><code>ab.to.Maximum.Possible.Mediation.Effect_kappa.squared</code></td>
<td>
<p>the proportion of the maximum possible indirect effect; Uses the indirect effect in the numerator with the maximum possible mediation effect in the denominator (Preacher &amp; Kelley, 2010)</p>
</td></tr>
<tr><td><code>Ratio.of.Indirect.to.Total.Effect</code></td>
<td>
<p>ratio of the indirect effect to the total effect (Freedman, 2001); also known as mediation ratio (Ditlevsen, Christensen, Lynch, Damsgaard, &amp; Keiding, 2005); in epidemiological research and as the relative indirect effect (Huang, Sivaganesan, Succop, &amp; Goodman, 2004); often loosely interpreted as the relative indirect effect</p>
</td></tr>
<tr><td><code>Ratio.of.Indirect.to.Direct.Effect</code></td>
<td>
<p>ratio of the indirect effect to the direct effect (Sobel, 1982)</p>
</td></tr>
<tr><td><code>Success.of.Surrogate.Endpoint</code></td>
<td>
<p>Success of a surrogate endpoint (Buyse &amp; Molenberghs, 1998) </p>
</td></tr>
<tr><td><code>SOS</code></td>
<td>
<p>shared over simple effects (SOS) index, which is the ratio of the variance in Y explained by both <code>X</code> and <code>M</code> divided by the variance in <code>Y</code> explained by <code>X</code> (Lindenberger &amp; Potter, 1998)</p>
</td></tr>
<tr><td><code>Residual.Based_Gamma</code></td>
<td>
<p>A residual based index (Preacher &amp; Kelley, 2010)</p>
</td></tr>
<tr><td><code>Residual.Based.Standardized_gamma</code></td>
<td>
<p>A residual based index that is standardized, where the scales of M and Y are removed by using standardized values of M and Y (Preacher &amp; Kelley, 2010)</p>
</td></tr>
<tr><td><code>ES.for.two.groups</code></td>
<td>
<p>When X is 0 and 1 representing a two group structure, 
Hansen and McNeal's (1996) Effect Size Index for Two Groups</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Ken Kelley (University of Notre Dame; KKelley@nd.edu)</p>


<h3>References</h3>

 
<p>Buyse, M., &amp; Molenberghs, G. (1998). Criteria for the validation of surrogate endpoints in randomized experiments. <em>Biometrics, 54</em>, 1014&ndash;1029.
</p>
<p>Ditlevsen, S., Christensen, U., Lynch, J., Damsgaard, M. T., &amp; Keiding, N. (2005). The mediation proportion: A structural equation approach for estimating the proportion of exposure effect on outcome explained by an intermediate variable. <em>Epidemiology, 16</em>, 114&ndash;120.
</p>
<p>Freedman, L. S. (2001). Confidence intervals and statistical power of the 'Validation' ratio for surrogate or intermediate endpoints. <em>Journal of Statistical Planning and Inference, 96</em>, 143&ndash;153.
</p>
<p>Hansen, W. B., &amp; McNeal, R. B. (1996). The law of maximum expected potential effect: Constraints placed on program effectiveness by mediator relationships. <em>Health Education Research, 11</em>, 501&ndash;507.
</p>
<p>Huang, B., Sivaganesan, S., Succop, P., &amp; Goodman, E. (2004). Statistical assessment of mediational effects for logistic mediational models. <em>Statistics in Medicine, 23</em>, 2713&ndash;2728.
</p>
<p>Lachowicz, M. J., Preacher, K. J., &amp; Kelley, K. (submitted). A novel measure of effect size for mediation analysis. Submited for publication. 
</p>
<p>Lindenberger, U., &amp; Potter, U. (1998). The complex nature of unique and shared effects in hierarchical linear regression: Implications for developmental psychology. <em>Psychological Methods, 3</em>, 218&ndash;230.
</p>
<p>MacKinnon, D. P. (2008). <em>Introduction to statistical mediation analysis</em>. Mahwah, NJ: Erlbaum.
</p>
<p>Preacher, K. J., &amp; Hayes, A. F. (2008b). Asymptotic and resampling strategies for assessing and comparing indirect effects in multiple mediator models. <em>Behavior Research Methods, 40</em>, 879&ndash;891.
</p>
<p>Preacher, K. J., &amp; Kelley, K. (2011). Effect size measures for mediation models: Quantitative and graphical strategies for communicating indirect effects. <em>Psychological Methods, 16</em>, 93&ndash;115.
</p>
<p>Sobel, M. E. (1982). Asymptotic confidence intervals for indirect effects in structural equation models. In S. Leinhardt (Ed.), <em>Sociological Methodology 1982</em> (pp. 290&ndash;312). Washington DC: American Sociological Association.
</p>
<p>Wen, Z., &amp; Fan, X. (2015). Monotonicity of effect sizes: Questioning kappa-squared as mediation effect size measure. 
<em>Psychological Methods</em>, <em>20</em>, 193&ndash;203.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mediation.effect.plot">mediation.effect.plot</a></code>, <code><a href="#topic+mediation.effect.bar.plot">mediation.effect.bar.plot</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
############################################
# EXAMPLE 1
# Using the Jessor data discussed in Preacher and Kelley (2011), to illustrate
# the methods based on summary statistics. 
 
mediation(S=rbind(c(2.26831107,  0.6615415, -0.08691755), 
c(0.66154147,  2.2763549, -0.22593820), c(-0.08691755, -0.2259382,  0.09218055)), 
N=432, x.location.S=1, mediator.location.S=2, dv.location.S=3, mean.x=7.157645, 
mean.m=5.892785, mean.dv=1.649316, conf.level=.95)

############################################
# EXAMPLE 2
# Clear the workspace:
rm(list=ls(all=TRUE))

# An (unrealistic) example data (from Hayes) 
Data &lt;- rbind(
  c(-5.00, 25.00, -1.00),
  c(-4.00, 16.00, 2.00),
  c(-3.00, 9.00, 3.00),
  c(-2.00, 4.00, 4.00),
  c(-1.00, 1.00, 5.00),
  c(.00, .00, 6.00),
  c(1.00, 1.00, 7.00),
  c(2.00, 4.00, 8.00),
  c(3.00, 9.00, 9.00),
  c(4.00, 16.00, 10.00),
  c(5.00, 25.00, 13.00),
  c(-5.00, 25.00, -1.00),
  c(-4.00, 16.00, 2.00),
  c(-3.00, 9.00, 3.00),
  c(-2.00, 4.00, 4.00),
  c(-1.00, 1.00, 5.00),
  c(.00, .00, 6.00),
  c(1.00, 1.00, 7.00),
  c(2.00, 4.00, 8.00),
  c(3.00, 9.00, 9.00),
  c(4.00, 16.00, 10.00),
  c(5.00, 25.00, 13.00))


# Raw data example of the Hayes data.
mediation(x=Data[,1], mediator=Data[,2], dv=Data[,3], conf.level=.95)

# Sufficient statistics example of the Hayes data.
mediation(S=var(Data), N=22, x.location.S=1, mediator.location.S=2, dv.location.S=3, 
mean.x=mean(Data[,1]), mean.m=mean(Data[,2]), mean.dv=mean(Data[,3]), conf.level=.95)

# Example had there been two groups. 
gp.size &lt;- length(Data[,1])/2 # adjust if using an odd number of observations.
grouping.variable &lt;- c(rep(0, gp.size), rep(1, gp.size))
mediation(x=grouping.variable, mediator=Data[,2], dv=Data[,3])

############################################
# EXAMPLE 3
# Bootstrap of continuous data. 
set.seed(12414) # Seed used for repeatability (there is nothing special about this seed)
bs.Results &lt;- mediation(x=Data[,1], mediator=Data[,2], dv=Data[,3], 
bootstrap=TRUE, B=5000, save.bs.replicates=TRUE)

ls() # Notice that Bootstrap.Replicates is available in the 
workspace (if save.bs.replicates=TRUE in the above call). 

#Now, given the Bootstrap.Replicates object, one can do whatever they want with them. 

# See the names of the effect sizes (and their ordering)
colnames(Bootstrap.Replicates)

# Define IE as the indirect effect from the Bootstrap.Replicates object. 
IE &lt;- Bootstrap.Replicates$Indirect.Effect

# Summary statistics
mean(IE)
median(IE)
sqrt(var(IE))

# CIs from percentile perspective
quantile(IE, probs=c(.025, .975))

# Two-sided p-value. 
## First, calculate obseved value of the indirect effect and extract it here. 
IE.Observed &lt;- mediation(x=Data[,1], mediator=Data[,2], dv=Data[,3], 
conf.level=.95)$Effect.Sizes[1,]

## Now, find those values of the bootstrap indirect effects that are more extreme (in an absolute 
## sense) than the indirect effect observed. Note that the p-value is 1 here because the observed
## indirect effect is exactly 0. 
mean(abs(IE) &gt;= abs(IE.Observed))

## End(Not run)
</code></pre>

<hr>
<h2 id='mediation.effect.bar.plot'> Bar plots of mediation effects</h2><span id='topic+mediation.effect.bar.plot'></span>

<h3>Description</h3>

<p>Provides an effect bar plot in the context of simple mediation. </p>


<h3>Usage</h3>

<pre><code class='language-R'>mediation.effect.bar.plot(x, mediator, dv, 
main = "Mediation Effect Bar Plot", width = 1, left.text.adj = 0, 
right.text.adj = 0, rounding = 3, file = "", save.pdf = FALSE, 
save.eps = FALSE, save.jpg = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mediation.effect.bar.plot_+3A_x">x</code></td>
<td>
<p>vector of the predictor/independent variable</p>
</td></tr>
<tr><td><code id="mediation.effect.bar.plot_+3A_mediator">mediator</code></td>
<td>
<p>vector of the mediator variable</p>
</td></tr>
<tr><td><code id="mediation.effect.bar.plot_+3A_dv">dv</code></td>
<td>
<p>vector of the dependent/outcome variable</p>
</td></tr>
<tr><td><code id="mediation.effect.bar.plot_+3A_main">main</code></td>
<td>
<p> main title </p>
</td></tr>
<tr><td><code id="mediation.effect.bar.plot_+3A_width">width</code></td>
<td>
<p> width of bar, default 1</p>
</td></tr>
<tr><td><code id="mediation.effect.bar.plot_+3A_left.text.adj">left.text.adj</code></td>
<td>
<p> for fine tuning left side text adjustment </p>
</td></tr>
<tr><td><code id="mediation.effect.bar.plot_+3A_right.text.adj">right.text.adj</code></td>
<td>
<p> for fine tuning right side text adjustment </p>
</td></tr>
<tr><td><code id="mediation.effect.bar.plot_+3A_rounding">rounding</code></td>
<td>
<p> how to round so that the values displayed in the plot do not have too few or too many significant digits </p>
</td></tr>
<tr><td><code id="mediation.effect.bar.plot_+3A_file">file</code></td>
<td>
<p> file name of the plot to be saved (not necessary) </p>
</td></tr>
<tr><td><code id="mediation.effect.bar.plot_+3A_save.pdf">save.pdf</code></td>
<td>
<p><code>TRUE</code> or <code>FALSE</code> if the produced figure should be saved as a PDF file</p>
</td></tr>
<tr><td><code id="mediation.effect.bar.plot_+3A_save.eps">save.eps</code></td>
<td>
<p><code>TRUE</code> or <code>FALSE</code> if the produced figure should be saved as an EPS file</p>
</td></tr>
<tr><td><code id="mediation.effect.bar.plot_+3A_save.jpg">save.jpg</code></td>
<td>
<p><code>TRUE</code> or <code>FALSE</code> if the produced figure should be saved as a JPG file</p>
</td></tr>
<tr><td><code id="mediation.effect.bar.plot_+3A_...">...</code></td>
<td>
<p>optional additional specifications for nested functions </p>
</td></tr>
</table>


<h3>Details</h3>

<p>Provides an effect bar for mediation (Bauer, Preacher, &amp; Gil, 2006) may be used to plot the results of a mediation analysis compactly. Effect bars represent, in a single metric, the relative magnitudes of several values that are important for interpreting indirect effects. Preacher and Kelley (2011) discuss this plotting method also.
</p>


<h3>Value</h3>

<p>Only a figure is returned
</p>


<h3>Author(s)</h3>

<p>Ken Kelley (University of Notre Dame; KKelley@nd.edu)</p>


<h3>References</h3>

<p>Bauer, D. J., Preacher, K. J., &amp; Gil, K. M. (2006). Conceptualizing and testing random indirect effects and moderated mediation in multilevel models: New procedures and recommendations. <em>Psychological Methods, 11</em>, 142&ndash;163.
</p>
<p>Preacher, K. J., &amp; Kelley, K. (2011). Effect size measures for mediation models: Quantitative and graphical strategies for communicating indirect effects. <em>Psychological Methods</em>, <em>16</em>, 93&ndash;115.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mediation">mediation</a></code>, <code><a href="#topic+mediation.effect.bar.plot">mediation.effect.bar.plot</a></code></p>

<hr>
<h2 id='mediation.effect.plot'> Visualizing mediation effects</h2><span id='topic+mediation.effect.plot'></span>

<h3>Description</h3>

<p> Create a mediation effect plot
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mediation.effect.plot(x, mediator, dv, ylab = "Dependent Variable", 
xlab = "Mediator", main = "Mediation Effect Plot", 
pct.from.top.a = 0.05, pct.from.left.c = 0.05, arrow.length.a = 0.05, 
arrow.length.c = 0.05, legend.loc = "topleft", file = "", pch = 20, 
xlim = NULL, ylim = NULL, save.pdf = FALSE, save.eps = FALSE, 
save.jpg = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mediation.effect.plot_+3A_x">x</code></td>
<td>
<p>vector of the predictor/independent variable</p>
</td></tr>
<tr><td><code id="mediation.effect.plot_+3A_mediator">mediator</code></td>
<td>
<p>vector of the mediator variable</p>
</td></tr>
<tr><td><code id="mediation.effect.plot_+3A_dv">dv</code></td>
<td>
<p>vector of the dependent/outcome variable</p>
</td></tr>
<tr><td><code id="mediation.effect.plot_+3A_ylab">ylab</code></td>
<td>
 <p><em>y</em>-axis title label </p>
</td></tr>
<tr><td><code id="mediation.effect.plot_+3A_xlab">xlab</code></td>
<td>
 <p><em>x</em>-axis title label </p>
</td></tr>
<tr><td><code id="mediation.effect.plot_+3A_main">main</code></td>
<td>
<p> main title label </p>
</td></tr>
<tr><td><code id="mediation.effect.plot_+3A_pct.from.top.a">pct.from.top.a</code></td>
<td>
<p>figure fine tuning adjustment</p>
</td></tr>
<tr><td><code id="mediation.effect.plot_+3A_pct.from.left.c">pct.from.left.c</code></td>
<td>
<p>figure fine tuning adjustment</p>
</td></tr>
<tr><td><code id="mediation.effect.plot_+3A_arrow.length.a">arrow.length.a</code></td>
<td>
<p>figure fine tuning adjustment </p>
</td></tr>
<tr><td><code id="mediation.effect.plot_+3A_arrow.length.c">arrow.length.c</code></td>
<td>
<p> figure fine tuning adjustment</p>
</td></tr>
<tr><td><code id="mediation.effect.plot_+3A_legend.loc">legend.loc</code></td>
<td>
<p> specify the location of the legend </p>
</td></tr>
<tr><td><code id="mediation.effect.plot_+3A_file">file</code></td>
<td>
<p> file name of the plot to be saved (not necessary) </p>
</td></tr>
<tr><td><code id="mediation.effect.plot_+3A_pch">pch</code></td>
<td>
<p> plotting character </p>
</td></tr>
<tr><td><code id="mediation.effect.plot_+3A_xlim">xlim</code></td>
<td>
<p> limits for the <em>x</em>-axis </p>
</td></tr>
<tr><td><code id="mediation.effect.plot_+3A_ylim">ylim</code></td>
<td>
<p> limits for the <em>y</em>-axis </p>
</td></tr>
<tr><td><code id="mediation.effect.plot_+3A_save.pdf">save.pdf</code></td>
<td>
<p><code>TRUE</code> or <code>FALSE</code> if the produced figure should be saved as a PDF file</p>
</td></tr>
<tr><td><code id="mediation.effect.plot_+3A_save.eps">save.eps</code></td>
<td>
<p><code>TRUE</code> or <code>FALSE</code> if the produced figure should be saved as an EPS file</p>
</td></tr>
<tr><td><code id="mediation.effect.plot_+3A_save.jpg">save.jpg</code></td>
<td>
<p><code>TRUE</code> or <code>FALSE</code> if the produced figure should be saved as a JPG file</p>
</td></tr>
<tr><td><code id="mediation.effect.plot_+3A_...">...</code></td>
<td>
<p>to incorporate options from interval functions</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Merrill (1994; see also MacKinnon, 2008; MacKinnon et al., 2007; Sy, 2004) presents a method that involves plotting the indirect effect as the vertical distance between two lines. Fritz and MacKinnon (2008) present a detailed exposition of this method too. Preacher and Kelley (2011) discuss this plotting method and implement their own code, which was also independently done as part of Fritz and MacKinnon (2008).
</p>
<p>In this type of plot, the two horizontal lines correspond to the predicted values of Y regressed on X at the mean of X and at one unit above the mean of X. The distance between these two lines is thus <code class="reqn">\hat{c}</code>. The two vertical lines correspond to predicted values of M regressed on X at the same two values of X. The distance between these lines is <code class="reqn">\hat{a}</code>. The lines corresponding to the regression of Y on M (controlling for X) are plotted for the same two values of X. 
</p>


<h3>Value</h3>

<p>A figure is returned.
</p>


<h3>Note</h3>

<p>Requires raw data.</p>


<h3>Author(s)</h3>

<p>Ken Kelley (University of Notre Dame; KKelley@nd.edu)</p>


<h3>References</h3>

<p>Fritz, M. S., &amp; MacKinnon, D. P. (2008). A graphical representation of the mediated effect. <em>Behavior Research Methods, 40</em>, 55&ndash;60.
</p>
<p>MacKinnon, D. P. (2008). <em>Introduction to statistical mediation analysis</em>. Mahwah, NJ: Erlbaum.
</p>
<p>MacKinnon, D. P., Fairchild, A. J., &amp; Fritz, M. S. (2007). Mediation analysis. <em>Annual Review of Psychology, 58</em>, 593&ndash;614.
</p>
<p>Merrill, R. M. (1994). <em>Treatment effect evaluation in non-additive mediation models</em>. Unpublished dissertation, Arizona State University.
</p>
<p>Preacher, K. J., &amp; Kelley, K. (2011). Effect size measures for mediation models: Quantitative and graphical strategies for communicating indirect effects. <em>Psychological Methods</em>, <em>16</em>, 93&ndash;115.
</p>
<p>Sy, O. S. (2004). <em>Multilevel mediation analysis: Estimation and applications</em>. Unpublished dissertation, Kansas State University.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mediation.effect.plot">mediation.effect.plot</a></code>, <code><a href="#topic+mediation.effect.bar.plot">mediation.effect.bar.plot</a></code></p>

<hr>
<h2 id='mr.cv'>
Minimum risk point estimation of the population coefficient of variation
</h2><span id='topic+mr.cv'></span>

<h3>Description</h3>

<p>A function for the sequential estimation of the coefficient of variations with minimum risk. The function implements the ideas of Chattopadhyay and Kelley (in press), which considers study cost and accuracy of the estimated
coefficient of variation simultaneously. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mr.cv(data, A, structural.cost, epsilon, sampling.cost, pilot=FALSE, m0=4, gamma=.49, 
verbose=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mr.cv_+3A_data">data</code></td>
<td>
<p>the data for which to evalaute the function
</p>
</td></tr>
<tr><td><code id="mr.cv_+3A_a">A</code></td>
<td>
<p><code>structural.cost</code>/<code>epsilon</code>^2; this is the structural cost that one is willing to pay in a study to estimate the coefficient of variation divided by the square of the desired difference (between the estimate and the parameter)
</p>
</td></tr>
<tr><td><code id="mr.cv_+3A_structural.cost">structural.cost</code></td>
<td>
<p>this is the the structural cost of what one is willing to pay in a study (see note below). 
</p>
</td></tr>
<tr><td><code id="mr.cv_+3A_epsilon">epsilon</code></td>
<td>

<p>The maximum desired difference between the estimated coefficient of variation and the population value)
</p>
</td></tr>
<tr><td><code id="mr.cv_+3A_sampling.cost">sampling.cost</code></td>
<td>

<p>The sampling cost to collect an additional observation. For example, if each survey costs 10 dollars to distribute and score, <code>sampling.cost</code> would be 10 dollars per additional observation.
</p>
</td></tr>
<tr><td><code id="mr.cv_+3A_pilot">pilot</code></td>
<td>

<p><code>TRUE</code> or <code>FALSE</code> based on whether the users is using the function to plan a pilot sample size (<code>TRUE</code>) or if it is being used to assess if the optimization criterion has been satisfied (<code>FALSE</code>)
</p>
</td></tr>
<tr><td><code id="mr.cv_+3A_m0">m0</code></td>
<td>
<p>the minimum bound on the initial pilot sample size</p>
</td></tr>
<tr><td><code id="mr.cv_+3A_gamma">gamma</code></td>
<td>
<p>A correction factor in which we suggest .49; see the two Chattopadhyay &amp; Kelley articles for more details (ignorable for most users).</p>
</td></tr>
<tr><td><code id="mr.cv_+3A_verbose">verbose</code></td>
<td>
<p>If <code>TRUE</code>, extra information is printed; defaults to <code>FALSE</code>
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The value of <code>epsilon</code> is context specific; the smaller the value the closer the estimated value will tend to be to the population value.
</p>


<h3>Value</h3>

<table>
<tr><td><code>Risk</code></td>
<td>
<p>The value of the risk function </p>
</td></tr>
<tr><td><code>N</code></td>
<td>
<p>The current sample size</p>
</td></tr>
<tr><td><code>cv</code></td>
<td>
<p>The current coefficient of variation</p>
</td></tr>
<tr><td><code>Is.Satisfied?</code></td>
<td>
<p>A TRUE/FALSE statement of whether or not the risk function has been satisfied. If TRUE then sampling can stop as the stopping rule has been satisfied.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>When a study's aim is to estimate a parameter accurately, such as the coefficient of variation, the structural costs and the maximum probable error of the estimate (i.e., <code class="reqn">\epsilon</code>) are combined to form <code class="reqn">A</code>. When we say &ldquo;what the researcher is willing to pay,&quot; we literally mean the structural cost (<code class="reqn">c</code>) the researcher is willing to invest in a study in order to estimate the parameter of interest with the desired degree of accuracy. This value is implicitly included (along with anticipated sampling cost) in grant applications for empirical studies when a certain amount of money is requested to conduct a study. If a researcher is willing to pay more and/or desire a smaller value of <code class="reqn">\epsilon</code>, <code class="reqn">A</code> is larger than it would have been. A larger <code class="reqn">A</code> value will translate into a more expensive study, holding everything else constant. Notice that <code class="reqn">A</code> is a fixed value in any investigation, as the researcher specifies <code class="reqn">A</code> directly or by specifying its two components (structural cost and <code class="reqn">\epsilon</code>) individually. However, what is not fixed but rather evaluated in multiple steps throughout the process is the sampling cost, as it is unknown the necessary sample size in order to accomplish the study's goal of achieving a sufficiently accurate estimate of the coefficient of variation. This is the core of our contributions: minimizing sampling cost, and thereby study cost, by using a sequential procedure that evaluates a stopping rule using the risk function to determine if the optimation criterion has been satisfied (based on the goals of the researcher and current information available). This function implements the ideas of  sampling error and the study costs are considered simultaneously, so that the cost is not higher than necessary for the tolerable sampling error.</p>


<h3>Author(s)</h3>

<p>Ken Kelley (University of Notre Dame; <a href="mailto:kkelley@nd.edu">kkelley@nd.edu</a>) and Bhargab Chattopadhyay (University of Texas - Dallas; <a href="mailto:bhargab@utdallas.edu">bhargab@utdallas.edu</a>)
</p>


<h3>References</h3>

<p>Chattopadhyay, B., &amp; Kelley, K. (in press). Estimation of the Coefficient of Variation with Minimum Risk: A Sequential Method for Minimizing Sampling Error and Study Cost. <em>Multivariate Behavioral Research</em>, <em>X</em>, X&ndash;X.
</p>
<p>Kelley, K. (2007). Sample size planning for the coefficient of variation from the accuracy in parameter estimation approach. <em>Behavior Research Methods, 39</em> <em>4</em>, 755&ndash;766.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ci.cv">ci.cv</a></code>, <code><a href="#topic+cv">cv</a></code>, <code><a href="#topic+mr.smd">mr.smd</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'># Determine pilot sample size:
mr.cv(pilot=TRUE, A=400000, sampling.cost=75, gamma=.49)

# Collect data (the size of which is the pilot sample size)
Data &lt;- c(36, 53, 19, 11, 10, 24, 14, 65, 18, 48, 25, 35, 13, 18, 3, 41, 5, 3)

# Use mr.cv() to assess if the criterion for stopping the sequential study has been satisfied:
mr.cv(data=Data, A=400000, sampling.cost=75, gamma=.49)

# Collect another data (m=1 here) and perform another check:
Data &lt;- c(Data, 44)
mr.cv(data=Data, A=400000, sampling.cost=75, gamma=.49)

# Continue adding obervations, checking each time if m=1, until the minimum risk criteria 
# are satisfied:
Data &lt;- c(Data, 26, 13, 39, 2, 3, 26, 22, 8, 15, 12, 22, 5, 21, 23, 40, 18)
mr.cv(data=Data, A=400000, sampling.cost=75, gamma=.49)
</code></pre>

<hr>
<h2 id='mr.smd'>
Minimum risk point estimation of the population standardized mean difference</h2><span id='topic+mr.smd'></span>

<h3>Description</h3>

<p>A function for the sequential estimation of the standardized mean difference with minimum risk. The function implements the ideas of Chattopadhyay and Kelley (submitted, Psychological Methods), which considers study cost and accuracy of the estimated
standardized mean difference simultaniously. This is important to specify that <code>mr.smd.R</code> was developed under the assumption of normally distributed data with equal sample size and equal cost of sampling per observation for each group.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mr.smd(A, structural.cost, epsilon, d, n, sampling.cost, pilot = FALSE, m0 = 4, 
gamma = 0.49)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mr.smd_+3A_a">A</code></td>
<td>
<p>is the price one is willing to pay in order to have a maximum allowable difference of <code class="reqn">epsilon^2</code> between the estimate of the standardized mean difference and its corresponding parameter.
</p>
</td></tr>
<tr><td><code id="mr.smd_+3A_structural.cost">structural.cost</code></td>
<td>

<p>Other costs not associated the cost of sampling itself. That is, beyond sampling costs, the fnancial resources that are required to design, conduct, analyze the data of a study. 
</p>
</td></tr>
<tr><td><code id="mr.smd_+3A_epsilon">epsilon</code></td>
<td>

<p>The maximum desired difference between the estimated standardized mean difference and the population value)
</p>
</td></tr>
<tr><td><code id="mr.smd_+3A_d">d</code></td>
<td>
<p>the current estimate of the standardized mean difference</p>
</td></tr>
<tr><td><code id="mr.smd_+3A_n">n</code></td>
<td>
<p>current sample size <em>per group</em> (thus total sample size is <code class="reqn">2n</code>); requires equal sample size <em>per group</em>.</p>
</td></tr>
<tr><td><code id="mr.smd_+3A_sampling.cost">sampling.cost</code></td>
<td>

<p>The sampling cost to collect an additional observation. For example, if each survey costs 10 dollars to distribute and score, <code>sampling.cost</code> would be 10 dollars per additional observation.</p>
</td></tr>
<tr><td><code id="mr.smd_+3A_pilot">pilot</code></td>
<td>

<p><code>TRUE</code> or <code>FALSE</code> based on whether the users is using the function to plan a pilot sample size (TRUE) or if it is being used to assess if the optimization criterion has been satisfied (FALSE)
</p>
</td></tr>
<tr><td><code id="mr.smd_+3A_m0">m0</code></td>
<td>
<p>the minimum bound on the initial pilot sample size</p>
</td></tr>
<tr><td><code id="mr.smd_+3A_gamma">gamma</code></td>
<td>
<p>A correction factor in which we suggest .49; see the two Chattopadhyay &amp; Kelley articles for more details (ignorable for most users).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The standardized mean difference is a widely used measure effect size. In this article, we developed a general theory for estimating the population standardized mean difference by minimizing both the mean square error of the estimator and the total sampling cost. This function implements our ideas discussed in Chattopadhyay and Kelley (submitted). See also Kelley and Rausch (2006) for additional information on the standardized mean difference.
</p>


<h3>Value</h3>

<table>
<tr><td><code>Risk</code></td>
<td>
<p><em>Per group</em> sample size (this simply repeats what was supplied to the function)</p>
</td></tr>
<tr><td><code>n1</code></td>
<td>
<p>Sample size for group 1 (echos the input value)</p>
</td></tr>
<tr><td><code>n1</code></td>
<td>
<p>Sample size for group 2 (echos the input value)</p>
</td></tr>
<tr><td><code>d</code></td>
<td>
<p>Observed value of the standardized mean difference (i.e., <em>d</em>; echos the input value)</p>
</td></tr>
<tr><td><code>Is.Satisfied?</code></td>
<td>
<p>A <code>TRUE</code> or <code>FALSE</code> statement of that evaluates a stopping rule using the risk function to determine if the optimation criterion has been satisfied (based on the goals of the researcher and current information available)</p>
</td></tr>
</table>


<h3>Note</h3>

<p>When <code>pilot=TRUE</code> the function returns the size of the pilot sample size, <em>per group</em>, that should be used (thus, the total sample size is twice the pilot sample size).</p>


<h3>Author(s)</h3>

<p>Ken Kelley (University of Notre Dame; <a href="mailto:kkelley@nd.edu">kkelley@nd.edu</a>) and Bhargab Chattopadhyay (University of Texas - Dallas; <a href="mailto:bhargab@utdallas.edu">bhargab@utdallas.edu</a>)
</p>


<h3>References</h3>

<p>Chattopadhyay, B., &amp; Kelley, K. (submitted, minor revision requested). Estimating the standardized mean difference with minimum risk: Maximizing accuracy and minimizing cost with sequential estimation. <em>Psychological Methods</em>, <em>X</em>, X&ndash;X.
</p>
<p>Chattopadhyay, B., &amp; Kelley, K. (in press). Estimation of the Coefficient of Variation with Minimum Risk: A Sequential Method for Minimizing Sampling Error and Study Cost. <em>Multivariate Behavioral Research</em>, <em>X</em>, X&ndash;X.
</p>
<p>Kelley, K., &amp; Rausch, J. R. (2006). Sample size planning for the standardized mean difference: 
Accuracy in Parameter Estimation via narrow confidence intervals. <em>Psychological Methods, 11</em>, 363&ndash;385.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ci.smd">ci.smd</a></code>, <code><a href="#topic+mr.cv">mr.cv</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'># To obtain pilot sample size in a situation in which A=10000. Note that 'A' is 
# 'structural.cost' divided by the square of 'epsilon'.

# From Chattopadhyay and Kelley (submitted, minor revision requested)
mr.smd(pilot=TRUE, A=10000, sampling.cost=2.4, gamma=.49)

High.SLS &lt;- c(11, 7, 22, 13, 6, 9, 11, 16, 12, 17, 14, 8, 16)
Low.SLS  &lt;- c(3, 6, 10, 8, 14, 5, 12, 10, 6, 8, 13, 5, 9)

mr.smd(d=1.021484, n=13, A=10000, sampling.cost=2.40, gamma=.49)

# Or, using the smd() function:
mr.smd(d=smd(Group.1=High.SLS, Group.2=Low.SLS), n=13, A=10000, sampling.cost=2.40, gamma=.49)

# Here, for this situation, the stopping rule is satisfied:
mr.smd(d=1.00, n=75, A=10000, sampling.cost=2.40, gamma=.49)

</code></pre>

<hr>
<h2 id='power.density.equivalence.md'> Density for power of two one-sided tests procedure (TOST) for equivalence </h2><span id='topic+power.density.equivalence.md'></span>

<h3>Description</h3>

<p>A function to calculate density for the power of the two one-sided tests prodedure (TOST). (See package <code>equivalence</code>, function <code>tost</code>.)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>power.density.equivalence.md(power_sigma, alpha = alpha, theta1 = theta1, 
theta2 = theta2, diff = diff, sigma = sigma, n = n, nu = nu)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="power.density.equivalence.md_+3A_power_sigma">power_sigma</code></td>
<td>
<p>x-value for integration</p>
</td></tr>
<tr><td><code id="power.density.equivalence.md_+3A_alpha">alpha</code></td>
<td>
 <p><code class="reqn">\alpha</code> level (Type I error rate) for the 2 <code class="reqn">t</code>-tests (usually <code class="reqn">\alpha=0.05</code>). Confidence interval for full test is at level (<code class="reqn">1-2*\alpha</code>)</p>
</td></tr>
<tr><td><code id="power.density.equivalence.md_+3A_theta1">theta1</code></td>
<td>
<p> lower limit of equivalence interval on appropriate scale (regular or log) </p>
</td></tr>
<tr><td><code id="power.density.equivalence.md_+3A_theta2">theta2</code></td>
<td>
<p> upper limit of equivalence interval on appropriate scale </p>
</td></tr>
<tr><td><code id="power.density.equivalence.md_+3A_diff">diff</code></td>
<td>
<p> true difference (ratio on log scale) in treatment means on appropriate scale </p>
</td></tr>
<tr><td><code id="power.density.equivalence.md_+3A_sigma">sigma</code></td>
<td>
<p> sqrt(error variance) as fraction (i.e., square root of the mean square error from ANOVA, or coefficient of variation) </p>
</td></tr>
<tr><td><code id="power.density.equivalence.md_+3A_n">n</code></td>
<td>
<p> number of participants per treatment (number of total subjects for crossover design) </p>
</td></tr>
<tr><td><code id="power.density.equivalence.md_+3A_nu">nu</code></td>
<td>
<p> degrees of freedom for sigma </p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>power_density</code></td>
<td>
<p>density at diff for power of TOST: the probability that the confidence interval will lie within ['theta1', 'theta2']</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p> Kem Phillips; <a href="mailto:kemphillips@comcast.net">kemphillips@comcast.net</a> </p>


<h3>References</h3>

 
<p>Diletti, E., Hauschke D. &amp; Steinijans, V.W. (1991). Sample size determination of bioequivalence assessment by means of confidence intervals, <em>International Journal of Clinical Pharmacology, Therapy and Toxicology, 29</em>, No. 1, 1&ndash;8.
</p>
<p>Phillips, K.F. (1990). Power of the Two One-Sided Tests Procedure in Bioquivalence, <em>Journal of Pharmacokinetics and Biopharmaceutics, 18</em>, No. 2, 139&ndash;144.
</p>
<p>Schuirmann, D.J. (1987). A comparison of the two one-sided tests procedure and the power approach for assessing the equivalence of average bioavailability, <em>Journal of Pharmacokinetics and Biopharmaceutics, 15</em>. 657&ndash;680.
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+power.equivalence.md.plot">power.equivalence.md.plot</a></code>, <code><a href="#topic+power.density.equivalence.md">power.density.equivalence.md</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# This function is called by power.equivalence.md within 
# the integrate function. It is integrated over 
# appropriate limits to compute the power. Use

power.density.equivalence.md(.1, alpha=.05, theta1=-.2, theta2=.2, diff=.05, 
	sigma= .20, n=24, nu=22)

# The usage for the logarithmic scale is the same, except that 
# theta1, theta2, and diff must be on that scale. That is, use log(.8), etc.

## End(Not run)
</code></pre>

<hr>
<h2 id='power.equivalence.md'> Power of Two One-Sided Tests Procedure (TOST) for Equivalence </h2><span id='topic+power.equivalence.md'></span>

<h3>Description</h3>

<p>A function to calculate the power of the two one-sided tests prodedure (TOST). This is 
the probability that a confidence interval lies within a specified equivalence 
interval. (See also package <code>equivalence</code>, function <code>tost</code>.)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>power.equivalence.md(alpha, logscale, ltheta1, ltheta2, ldiff, sigma, n, nu)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="power.equivalence.md_+3A_alpha">alpha</code></td>
<td>
 <p><code class="reqn">\alpha</code> level (Type I error rate) for the two <code class="reqn">t</code>-tests (usually <code class="reqn">\alpha=0.05</code>). 
Confidence interval for full test is at level 1-2*<code>alpha</code> </p>
</td></tr>
<tr><td><code id="power.equivalence.md_+3A_logscale">logscale</code></td>
<td>
<p>whether to use logarithmic scale (<code>TRUE</code>) or not (<code>FALSE</code>) </p>
</td></tr>
<tr><td><code id="power.equivalence.md_+3A_ltheta1">ltheta1</code></td>
<td>
<p> lower limit of equivalence interval</p>
</td></tr>
<tr><td><code id="power.equivalence.md_+3A_ltheta2">ltheta2</code></td>
<td>
<p> upper limit of equivalence interval </p>
</td></tr>
<tr><td><code id="power.equivalence.md_+3A_ldiff">ldiff</code></td>
<td>
<p> true difference (ratio on log scale) in treatment means </p>
</td></tr>
<tr><td><code id="power.equivalence.md_+3A_sigma">sigma</code></td>
<td>
 <p><code>sqrt</code>(error variance) as fraction (square root of the mean square error from ANOVA, or coefficient of variation) </p>
</td></tr>
<tr><td><code id="power.equivalence.md_+3A_n">n</code></td>
<td>
<p> number of participants per treatment (number of total subjects for crossover design) </p>
</td></tr>
<tr><td><code id="power.equivalence.md_+3A_nu">nu</code></td>
<td>
<p> degrees of freedom for <code>sigma</code> </p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>power</code></td>
<td>
<p>Power of TOST; the probability that the confidence interval will lie within ['theta1', 'theta2'] given <code>sigma</code>, <code>n</code>, and <code>nu</code></p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Kem Phillips; <a href="mailto:kemphillips@comcast.net">kemphillips@comcast.net</a>
</p>


<h3>References</h3>

 
<p>Diletti, E., Hauschke D. &amp; Steinijans, V.W. (1991). Sample size determination of 
bioequivalence assessment by means of confidence intervals, 
<em>International Journal of Clinical Pharmacology, Therapy and Toxicology, 29</em>, No. 1, 1&ndash;8.
</p>
<p>Phillips, K.F. (1990). Power of the Two One-Sided Tests Procedure in Bioquivalence,
<em>Journal of Pharmacokinetics and Biopharmaceutics, 18</em>, No. 2, 139&ndash;144.
</p>
<p>Schuirmann, D.J. (1987). A comparison of the two one-sided tests procedure and the power approach for assessing the equivalence of average bioavailability,
<em>Journal of Pharmacokinetics and Biopharmaceutics, 15</em>. 657&ndash;680.
</p>


<h3>Examples</h3>

<pre><code class='language-R'> # Suppose that two formulations of a drug are to be compared on 
 # the regular scale using a two-period crossover design, with 
 # theta1 = -0.20, theta2 = 0.20, rm{CV} = 0.20, the 
 # difference in the mean bioavailability is 0.05 (5 percent), and we choose 
 # n=24, corresponding to 22 degrees of freedom.  We need to test 
 # bioequivalence at the 5 percent significance level, which corresponds to 
 # having a 90 percent confidence interval lying within (-0.20, 0.20). Then 
 # the power will be 0.8029678.  This corresponds to Phillips (1990), 
 # Table 1, 5th row, 5th column, and Figure 3.  Use
 
power.equivalence.md(.05, FALSE, -.2, .2, .05, .20, 24, 22)


# If the formulations are compared on the logarithmic scale with 
# theta1 = 0.80, theta2 = 1.25, n=18 (16 degrees of freedom), and 
# a ratio of test to reference of 1.05. Then the power will be 0.7922796.
# This corresponds to Diletti, Table 1, power=.80, CV=.20, ratio=1.05, and Figure 1c. Use

power.equivalence.md(.05, TRUE, .8, 1.25, 1.05, .20, 18, 16)
</code></pre>

<hr>
<h2 id='power.equivalence.md.plot'> Plot power of Two One-Sided Tests Procedure (TOST) for Equivalence</h2><span id='topic+power.equivalence.md.plot'></span>

<h3>Description</h3>

<p>A function to plot the power of the two one-sided tests prodedure (TOST) for various alternatives. (See also package <code>equivalence</code>, function <code>tost</code>.)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>power.equivalence.md.plot(alpha, logscale, theta1, theta2, sigma, n, nu, title2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="power.equivalence.md.plot_+3A_alpha">alpha</code></td>
<td>
 <p><em>alpha</em> level for the 2 <em>t</em>-tests (usually <em>alpha</em>=0.05). 
Confidence interval for full test is at level 1- 2*<code>alpha</code> </p>
</td></tr>
<tr><td><code id="power.equivalence.md.plot_+3A_logscale">logscale</code></td>
<td>
<p> whether to use logarithmic scale <code>TRUE</code> or not <code>FALSE</code> </p>
</td></tr>
<tr><td><code id="power.equivalence.md.plot_+3A_theta1">theta1</code></td>
<td>
<p> lower limit of equivalence interval</p>
</td></tr>
<tr><td><code id="power.equivalence.md.plot_+3A_theta2">theta2</code></td>
<td>
<p> upper limit of equivalence interval </p>
</td></tr>
<tr><td><code id="power.equivalence.md.plot_+3A_sigma">sigma</code></td>
<td>
 <p><code>sqrt</code>(error variance) as fraction (root MSE from ANOVA, or coefficient of variation) </p>
</td></tr>
<tr><td><code id="power.equivalence.md.plot_+3A_n">n</code></td>
<td>
<p> number of subjects per treatment (number of total subjects for crossover design) </p>
</td></tr>
<tr><td><code id="power.equivalence.md.plot_+3A_nu">nu</code></td>
<td>
<p> degrees of freedom for <code>sigma</code> </p>
</td></tr>
<tr><td><code id="power.equivalence.md.plot_+3A_title2">title2</code></td>
<td>
<p> Title appearing at bottom of plot </p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>power</code></td>
<td>
<p>Plot of power of TOST (probability that (1-2*<code>alpha</code>) confidence 
interval will lie within (<code>theta1</code>, <code>theta2</code>) given <code>sigma</code>, <code>n</code>, 
and <code>nu</code>.  Also returns matrix of 201 differences between <code>theta1</code> 
and <code>theta2</code> as first column, and power values corresponding to <code>n</code> for other columns.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Kem Phillips; <a href="mailto:kemphillips@comcast.net">kemphillips@comcast.net</a>
</p>


<h3>References</h3>

 
<p>Diletti, E., Hauschke D. &amp; Steinijans, V.W. (1991) Sample size determination of bioequivalence assessment by means of confidence intervals, <em>International Journal of Clinical Pharmacology, Therapy and Toxicology, 29</em>, No. 1, 1-8.
</p>
<p>Phillips, K.F. (1990) Power of the Two One-Sided Tests Procedure in Bioquivalence,
<em>Journal of Pharmacokinetics and Biopharmaceutics, 18</em>, No. 2, 139-144.
</p>
<p>Schuirmann, D.J. (1987) A comparison of the two one-sided tests procedure and the power approach for assessing the equivalence of average bioavailability,
<em>Journal of Pharmacokinetics and Biopharmaceutics, 15</em>. 657-680.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Suppose that two formulations of a drug are to be compared 
# on the regular scale using a two-period crossover design, 
# with theta1 = -0.20, theta2 = 0.20, rm(CV) = 0.20, and 
# we choose 
n&lt;-c(9,12,18,24,30,40,60)

# corresponding to 
nu&lt;-c(7,10,16,22,28,38,58)

# degrees of freedom.  We need to test bioequivalence at the 
# .05 significance level, which corresponds to having a .90 confidence
# interval lying within (-0.20, 0.20). This corresponds to 
# Phillips (1990),  Figure 3.  Use

power.equivalence.md.plot(.05, FALSE, -.2, .2, .20, n, nu, 'Phillips Figure 3')

# If the formulations are compared on the logarithmic scale with 
# theta1 = 0.80, theta2 = 1.25, and 

n&lt;-c(8,12,18,24,30,40,60)

# corresponding  to 
nu&lt;-c(6,10,16,22,28,38,58)

# degrees of freedom. This corresponds to Diletti, Figure 1c. Use

power.equivalence.md.plot(.05, TRUE, .8, 1.25, .20, n, nu, 'Diletti, Figure 1c')

## End(Not run)
</code></pre>

<hr>
<h2 id='prof.salary'>Cohen et. al. (2003)'s professor salary data set</h2><span id='topic+prof.salary'></span>

<h3>Description</h3>

<p>The data set of the salaries and other information of 62 some professors in Cohen et. al. (2003, pp. 81-82).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(prof.salary)</code></pre>


<h3>Format</h3>

<p>A data frame with 62 observations on the following 6 variables.
</p>

<dl>
<dt><code>id</code></dt><dd><p>the identification number</p>
</dd>
<dt><code>time</code></dt><dd><p>the time since getting the Ph.D. degree</p>
</dd>
<dt><code>pub</code></dt><dd><p>the number of publications</p>
</dd>
<dt><code>sex</code></dt><dd><p>the gender, 1 for female and 0 for male</p>
</dd>
<dt><code>citation</code></dt><dd><p>the citation count</p>
</dd>
<dt><code>salary</code></dt><dd><p>the professor's current salary</p>
</dd>
</dl>



<h3>Source</h3>

<p>Cohen, J., Cohen, P., West, S. G., &amp; Aiken, L. S. (2003). <em>Applied multiple regression/correlation analysis for the behavioral sciences</em> (3rd ed.). Mahwah, NJ: Erlbaum.
</p>


<h3>References</h3>

<p>Cohen, J., Cohen, P., West, S. G., &amp; Aiken, L. S. (2003). <em>Applied multiple regression/correlation analysis for the behavioral sciences</em> (3rd ed.). Mahwah, NJ: Erlbaum.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(prof.salary)

</code></pre>

<hr>
<h2 id='s.u'>Unbiased estimate of the population standard deviation</h2><span id='topic+s.u'></span>

<h3>Description</h3>

<p>Transforms the usual (and biased) estimate of the standard deviation into an unbiased estimator.</p>


<h3>Usage</h3>

<pre><code class='language-R'>s.u(s=NULL, N=NULL, X=NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="s.u_+3A_s">s</code></td>
<td>
<p>the usual estimate of the standard deviation (i.e., the square root of the unibased estimate of the variance)</p>
</td></tr>
<tr><td><code id="s.u_+3A_n">N</code></td>
<td>
<p>sample size <code>s</code> is based</p>
</td></tr>
<tr><td><code id="s.u_+3A_x">X</code></td>
<td>
<p>vector of scores in which the unbiased estimate of the standard deviation should be calculated</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Returns the unbiased estimate for the standard deviation.
</p>


<h3>Value</h3>

<p>The unbiased estimate for the standard deviation.
</p>


<h3>Author(s)</h3>

<p>Ken Kelley (University of Notre Dame; <a href="mailto:KKelley@ND.Edu">KKelley@ND.Edu</a>)</p>


<h3>References</h3>

<p>Holtzman, W. H. (1950). The unbiased estimate of the population variance and standard deviation. <em>American 
Journal of Psychology</em>, <em>63</em>, 615&ndash;617.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(113)
X &lt;- rnorm(10, 100, 15)

# Square root of the unbiased estimate of the variance (not unbiased)
var(X)^.5

# One way to implement the function.
s.u(s=var(X)^.5, N=length(X))

# Another way to implement the function.
s.u(X=X)
</code></pre>

<hr>
<h2 id='Sigma.2.SigmaStar'>Construct a covariance matrix with specified error of approximation</h2><span id='topic+Sigma.2.SigmaStar'></span>

<h3>Description</h3>

<p>This function implements Cudeck &amp; Browne's (1992) method to construct a covariance matrix in the structural equation modeling (SEM) context. Given an SEM model and its model parameters, a covariance matrix is obtained so that (a) the population discrepancy due to approximation equals a certain specified value; and (b) the population model parameter vector is the minimizer of the discrepancy function. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Sigma.2.SigmaStar(model, model.par, latent.var, discrep, ML = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Sigma.2.SigmaStar_+3A_model">model</code></td>
<td>
<p> an RAM (reticular action model; e.g., McArdle &amp; McDonald, 1984) specification of a structural equation model, and should be of class <code>mod</code>. The model is specified in the same manner as does the <code><a href="sem.html#topic+sem">sem</a></code> package; see <code><a href="sem.html#topic+sem">sem</a></code> and <code><a href="sem.html#topic+specify.model">specify.model</a></code> for detailed documentations about model specifications in the RAM notation. </p>
</td></tr>
<tr><td><code id="Sigma.2.SigmaStar_+3A_model.par">model.par</code></td>
<td>
<p> a vector containing the model parameters. The names of the elements in <code>theta</code> must be the same as the names of the model parameters specified in <code>model</code>. </p>
</td></tr>
<tr><td><code id="Sigma.2.SigmaStar_+3A_latent.var">latent.var</code></td>
<td>
<p> a vector containing the names of the latent variables </p>
</td></tr>
<tr><td><code id="Sigma.2.SigmaStar_+3A_discrep">discrep</code></td>
<td>
<p> the desired discrepancy function minimum value </p>
</td></tr>
<tr><td><code id="Sigma.2.SigmaStar_+3A_ml">ML</code></td>
<td>
<p> the discrepancy function to be used, if <code>ML=TRUE</code> then the discrepancy function is based on normal theory maximum likelihood</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function constructs a covariance matrix <code class="reqn"> \Sigma^{*} </code> such that <code class="reqn"> \Sigma^{*} = \Sigma( \theta ) + E </code>, where <code class="reqn"> \Sigma(\theta)</code> is the population model-implied covariance matrix, and <code class="reqn">E</code> is a matrix containing the errors due to approximation. The matrix <code class="reqn">E</code> is chosen so that the discrepancy function <code class="reqn">F( \Sigma^{*}, \Sigma (\theta) ) </code> has the specified discrepancy value. 
</p>
<p>This function uses the same notation to specify SEM models as does <code><a href="sem.html#topic+sem">sem</a></code>. Please refer to <code><a href="sem.html#topic+sem">sem</a></code> for more detailed documentation about model specification and the RAM notation. For technical discussion on how to obtain the model implied covariance matrix in the RAM notation given model parameters, see McArdle and McDonald (1984).
</p>


<h3>Value</h3>

  
<table>
<tr><td><code>Sigma.star</code></td>
<td>
<p>the population covariance matrix of manifest variables</p>
</td></tr>
<tr><td><code>Sigma_theta</code></td>
<td>
<p>the population model-implied covariance matrix</p>
</td></tr>
<tr><td><code>E</code></td>
<td>
<p>the matrix containing the population errors of approximation,
i.e., <code>Sigma.star</code> - <code>Sigma_theta</code></p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Keke Lai (University of California-Merced) </p>


<h3>References</h3>

 
<p>Cudeck, R., &amp; Browne, M. W. (1992). Constructing a covariance matrix that yields a specified minimizer and a specified minimum discrepancy function value. <em>Psychometrika, 57</em>, 357&ndash;369. 
</p>
<p>Fox, J. (2006). Structural equation modeling with the sem package in R. <em>Structural Equation Modeling, 13</em>, 465&ndash;486.
</p>
<p>McArdle, J. J., &amp; McDonald, R. P. (1984). Some algebraic properties of the reticular action model. <em>British Journal of Mathematical and Statistical Psychology, 37</em>, 234&ndash;251.
</p>


<h3>See Also</h3>

<p><code><a href="sem.html#topic+sem">sem</a></code>; <code><a href="sem.html#topic+specify.model">specify.model</a></code>; <code><a href="#topic+theta.2.Sigma.theta">theta.2.Sigma.theta</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(sem)

###############
## EXAMPLE 1; a CFA model with three latent variables and nine indicators.
###############

# To specify the model
model.cfa&lt;-specify.model()
xi1 -&gt; x1, lambda1, 0.6
xi1 -&gt; x2, lambda2, 0.7
xi1 -&gt; x3, lambda3, 0.8
xi2 -&gt; x4, lambda4, 0.65
xi2 -&gt; x5, lambda5, 0.75
xi2 -&gt; x6, lambda6, 0.85
xi3 -&gt; x7, lambda7, 0.5
xi3 -&gt; x8, lambda8, 0.7
xi3 -&gt; x9, lambda9, 0.9
xi1 &lt;-&gt; xi1, NA, 1
xi2 &lt;-&gt; xi2, NA, 1
xi3 &lt;-&gt; xi3, NA, 1
xi1 &lt;-&gt; xi2, phi21, 0.5
xi1 &lt;-&gt; xi3, phi31, 0.4
xi2 &lt;-&gt; xi3, phi32, 0.6
x1 &lt;-&gt; x1, delta11, 0.36
x2 &lt;-&gt; x2, delta22, 0.5
x3 &lt;-&gt; x3, delta33, 0.9
x4 &lt;-&gt; x4, delta44, 0.4
x5 &lt;-&gt; x5, delta55, 0.5
x6 &lt;-&gt; x6, delta66, 0.6
x7 &lt;-&gt; x7, delta77, 0.6
x8 &lt;-&gt; x8, delta88, 0.7
x9 &lt;-&gt; x9, delta99, 0.7


# To specify model parameters
theta &lt;- c(0.6, 0.7, 0.8,
0.65, 0.75, 0.85,
0.5, 0.7, 0.9,
0.5, 0.4, 0.6,
0.8, 0.6, 0.5,
0.6, 0.5, 0.4,
0.7, 0.7, 0.6)

names(theta) &lt;- c("lambda1", "lambda2", "lambda3", 
"lambda4","lambda5", "lambda6", 
"lambda7", "lambda8","lambda9",
"phi21", "phi31", "phi32", 
"delta11", "delta22","delta33",
"delta44", "delta55","delta66",
"delta77", "delta88","delta99")

res.matrix &lt;- Sigma.2.SigmaStar(model=model.cfa, model.par=theta, 
latent.var=c("xi1", "xi2", "xi3"), discrep=0.06)

# res.matrix

# To verify the returned covariance matrix; the model chi-square
# should be equal to (N-1) times the specified discrepancy value.
# Also the "point estimates" of model parameters should be 
# equal to the specified model parameters

# res.sem&lt;-sem(model.cfa, res.matrix$Sigma.star, 1001)
# summary(res.sem)

# To construct a covariance matrix so that the model has
# a desired population RMSEA value, one can transform the RMSEA
# value to the discrepancy value

res.matrix &lt;- Sigma.2.SigmaStar(model=model.cfa, model.par=theta, 
latent.var=c("xi1", "xi2", "xi3"), discrep=0.075*0.075*24)

# To verify the population RMSEA value
# res.sem&lt;-sem(model.cfa, res.matrix$Sigma.star, 1000000)
# summary(res.sem)

###############
## EXAMPLE 2; an SEM model with five latent variables
###############

model.5f &lt;- specify.model()
eta1 -&gt; y4, NA, 1
eta1 -&gt; y5, lambda5, NA
eta2 -&gt; y1, NA, 1
eta2 -&gt; y2, lambda2, NA 
eta2 -&gt; y3, lambda3, NA
xi1 -&gt; x1, NA, 1
xi1 -&gt; x2, lambda6, NA 
xi1 -&gt; x3, lambda7, NA
xi2 -&gt; x4, NA, 1
xi2 -&gt; x5, lambda8, NA 
xi3 -&gt; x6, NA, 1
xi3 -&gt; x7, lambda9, NA 
xi3 -&gt; x8, lambda10, NA
xi1 -&gt; eta1, gamma11, NA
xi2 -&gt; eta1, gamma12, NA
xi3 -&gt; eta1, gamma13, NA
xi3 -&gt; eta2, gamma23, NA
eta1 -&gt; eta2, beta21, NA
xi1 &lt;-&gt; xi2, phi21, NA
xi1 &lt;-&gt; xi3, phi31, NA
xi3 &lt;-&gt; xi2, phi32, NA
xi1 &lt;-&gt; xi1, phi11, NA
xi2 &lt;-&gt; xi2, phi22, NA
xi3 &lt;-&gt; xi3, phi33, NA
eta1 &lt;-&gt; eta1, psi11, NA
eta2 &lt;-&gt; eta2, psi22, NA
y1 &lt;-&gt; y1, eplison11, NA
y2 &lt;-&gt; y2, eplison22, NA
y3 &lt;-&gt; y3, eplison33, NA
y4 &lt;-&gt; y4, eplison44, NA
y5 &lt;-&gt; y5, eplison55, NA
x1 &lt;-&gt; x1, delta11, NA
x2 &lt;-&gt; x2, delta22, NA
x3 &lt;-&gt; x3, delta33, NA
x4 &lt;-&gt; x4, delta44, NA
x5 &lt;-&gt; x5, delta55, NA
x6 &lt;-&gt; x6, delta66, NA
x7 &lt;-&gt; x7, delta77, NA
x8 &lt;-&gt; x8, delta88, NA


theta &lt;- c(0.84, 0.8, 0.9, 
1.26, 0.75, 1.43, 1.58, 0.83, 
0.4, 0.98, 0.52, 0.6,0.47, 
0.12, 0.14, 0.07,
0.44, 0.22, 0.25, 
0.3, 0.47, 
0.37, 0.5, 0.4, 0.4, 0.58, 
0.56,0.3, 0.6, 0.77, 0.54, 0.75, 0.37, 0.6)

names(theta) &lt;- c(
"lambda5","lambda2","lambda3",
"lambda6","lambda7","lambda8","lambda9","lambda10" , 
"gamma11",  "gamma12","gamma13" ,  "gamma23" ,  "beta21",
"phi21","phi31", "phi32", 
"phi11","phi22",  "phi33",     
"psi11" ,    "psi22"   ,  
"eplison11","eplison22" ,"eplison33", "eplison44" ,"eplison55", 
  "delta11"  , "delta22" ,  "delta33" ,  "delta44" ,  "delta55" ,  "delta66",  
"delta77" , "delta88")

# To construct a covariance matrix so that the model has 
# a population RMSEA of 0.08

res.matrix &lt;- Sigma.2.SigmaStar(model=model.5f, model.par=theta, 
latent.var=c("xi1", "xi2", "xi3", "eta1","eta2"), discrep=0.08*0.08*57)

# To verify
# res.sem&lt;- sem(model.5f, res.matrix$Sigma.star, 1000000)
# summary(res.sem)

## End(Not run)
</code></pre>

<hr>
<h2 id='signal.to.noise.R2'>Signal to noise using squared multiple correlation coefficient</h2><span id='topic+signal.to.noise.R2'></span>

<h3>Description</h3>

<p>Function that calculates five different signal-to-noise ratios using the squared multiple correlation coefficient.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>signal.to.noise.R2(R.Square, N, p)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="signal.to.noise.R2_+3A_r.square">R.Square</code></td>
<td>
<p>usual estimate of the squared multiple correlation coefficient (with no adjustments)</p>
</td></tr>
<tr><td><code id="signal.to.noise.R2_+3A_n">N</code></td>
<td>
<p>sample size</p>
</td></tr>
<tr><td><code id="signal.to.noise.R2_+3A_p">p</code></td>
<td>
<p>number of predictors</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The method of choice is <code>phi2.UMVUE.NL</code>, but it requires <code>p</code> of 5 or more. In situations where <code>p</code> &lt; 5, it is suggested that <code>phi2.UMVUE.L</code> be used. 
</p>


<h3>Value</h3>

<table>
<tr><td><code>phi2.hat</code></td>
<td>
<p>Basic estimate of the signal-to-noise ratio using the usual estimate of the squared multiple correlation coefficient: <code>phi2.hat</code>=<code>R.Square</code>/(1-<code>R.Square</code>)</p>
</td></tr>
<tr><td><code>phi2.adj.hat</code></td>
<td>
<p>Estimate of the signal-to-noise ratio using the usual adjusted R Square in place of <em>R</em>-Square: <code>phi2.hat</code>=<em>Adj.R2</em>/(1-<em>Adj.R2</em>)</p>
</td></tr>
<tr><td><code>phi2.UMVUE</code></td>
<td>
<p>Muirhead's (1985) unique minimum variance unbiased estimate of the signal-to-noise ratio (Muirhead uses theta-U): see reference or code for formula</p>
</td></tr>
<tr><td><code>phi2.UMVUE.L</code></td>
<td>
<p>Muirhead's (1985) unique minimum variance unbiased linear estimate of the signal-to-noise ratio (Muirhead uses theta-L): see reference or code for formula</p>
</td></tr>
<tr><td><code>phi2.UMVUE.NL</code></td>
<td>
<p>Muirhead's (1985) unique minimum variance unbiased nonlinear estimate of the signal-to-noise ratio (Muirhead uses theta-NL); requires the number of predictors to be greater than five: see reference or code for formula</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Ken Kelley (University of Notre Dame; <a href="mailto:KKelley@ND.Edu">KKelley@ND.Edu</a>)</p>


<h3>References</h3>

<p>Cohen, J. (1988). Statistical power analysis for the behavioral sciences (2nd ed.). Hillsdale, NJ: Lawrence Erlbaum.
</p>
<p>Muirhead, R. J. (1985). Estimating a particular function of the multiple correlation coefficient. <em>Journal of the American Statistical Association,  80</em>, 923&ndash;925.
</p>


<h3>See Also</h3>

<p><code>ci.R2</code>, <code>ss.aipe.R2</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>signal.to.noise.R2(R.Square=.5, N=50, p=2)
signal.to.noise.R2(R.Square=.5, N=50, p=5)
signal.to.noise.R2(R.Square=.5, N=100, p=2)
signal.to.noise.R2(R.Square=.5, N=100, p=5)
</code></pre>

<hr>
<h2 id='smd'>Standardized mean difference</h2><span id='topic+smd'></span>

<h3>Description</h3>

<p>Function to calculate the standardized mean difference (regular or unbiased) using either raw data or summary measures.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>smd(Group.1 = NULL, Group.2 = NULL, Mean.1 = NULL, Mean.2 = NULL, 
s.1 = NULL, s.2 = NULL, s = NULL, n.1 = NULL, n.2 = NULL,
Unbiased=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="smd_+3A_group.1">Group.1</code></td>
<td>
<p>Raw data for group 1.</p>
</td></tr>
<tr><td><code id="smd_+3A_group.2">Group.2</code></td>
<td>
<p>Raw data for group 2.</p>
</td></tr>
<tr><td><code id="smd_+3A_mean.1">Mean.1</code></td>
<td>
<p>The mean of group 1.</p>
</td></tr>
<tr><td><code id="smd_+3A_mean.2">Mean.2</code></td>
<td>
<p>The mean of group 2.</p>
</td></tr>
<tr><td><code id="smd_+3A_s.1">s.1</code></td>
<td>
<p>The standard deviation of group 1 (i.e., the square root of the unbiased estimator of the population variance).</p>
</td></tr>
<tr><td><code id="smd_+3A_s.2">s.2</code></td>
<td>
<p>The standard deviation of group 2 (i.e., the square root of the unbiased estimator of the population variance).</p>
</td></tr>
<tr><td><code id="smd_+3A_s">s</code></td>
<td>
<p>The pooled group standard deviation (i.e., the square root of the unbiased estimator of the population variance).</p>
</td></tr>
<tr><td><code id="smd_+3A_n.1">n.1</code></td>
<td>
<p>The sample size within group 1.</p>
</td></tr>
<tr><td><code id="smd_+3A_n.2">n.2</code></td>
<td>
<p>The sample size within group 2.</p>
</td></tr>
<tr><td><code id="smd_+3A_unbiased">Unbiased</code></td>
<td>
<p>Returns the unbiased estimate of the standardized mean difference.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>When <code>Unbiased=TRUE</code>, the unbiased estimate of the standardized mean difference is returned (Hedges, 1981).
</p>


<h3>Value</h3>

<p>Returns the estimated standardized mean difference.
</p>


<h3>Author(s)</h3>

<p>Ken Kelley (University of Notre Dame; <a href="mailto:KKelley@ND.Edu">KKelley@ND.Edu</a>)</p>


<h3>References</h3>

<p>Cohen, J. (1988). <em>Statistical power analysis for the behavioral sciences</em> (2nd ed.). Hillsdale, NJ: Lawrence Erlbaum.
</p>
<p>Cumming, G. &amp; Finch, S. (2001). A primer on the understanding, use, and calculation of confidence intervals that are
based on central and noncentral distributions, <em>Educational and Psychological Measurement, 61</em>, 532&ndash;574.
</p>
<p>Hedges, L. V. (1981). Distribution theory for Glass's Estimator of effect size and related estimators. <em>Journal of Educational Statistics, 2</em>, 107&ndash;128.
</p>
<p>Kelley, K. (2005) The effects of nonnormal distributions on confidence intervals around the standardized mean
difference: Bootstrap and parametric confidence intervals, <em>Educational and Psychological Measurement, 65</em>, 51&ndash;69.
</p>
<p>Kelley, K. (2007). Constructing confidence intervals for standardized effect sizes: Theory, application, and implementation. <em>Journal of Statistical Software, 20</em> (8), 1&ndash;24.
</p>
<p>Steiger, J. H., &amp; Fouladi, R. T. (1997). Noncentrality interval estimation and the evaluation of
statistical methods. In L. L. Harlow, S. A. Mulaik, &amp; J. H. Steiger (Eds.), <em>What if there were
no significance tests?</em> (pp. 221&ndash;257). Mahwah, NJ: Lawrence Erlbaum.
</p>


<h3>See Also</h3>

<p><code>smd.c</code>, <code>conf.limits.nct</code>, <code>ss.aipe</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Generate sample data.
set.seed(113)
g.1 &lt;- rnorm(n=25, mean=.5, sd=1)
g.2 &lt;- rnorm(n=25, mean=0, sd=1)
smd(Group.1=g.1, Group.2=g.2)

M.x &lt;- .66745
M.y &lt;- .24878
sd &lt;- 1.048
smd(Mean.1=M.x, Mean.2=M.y, s=sd)

M.x &lt;- .66745
M.y &lt;- .24878
n1 &lt;- 25
n2 &lt;- 25
sd.1 &lt;- .95817
sd.2 &lt;- 1.1311
smd(Mean.1=M.x, Mean.2=M.y, s.1=sd.1, s.2=sd.2, n.1=n1, n.2=n2)

smd(Mean.1=M.x, Mean.2=M.y, s.1=sd.1, s.2=sd.2, n.1=n1, n.2=n2, 
Unbiased=TRUE)

</code></pre>

<hr>
<h2 id='smd.c'>Standardized mean difference using the control group as the basis of 
standardization</h2><span id='topic+smd.c'></span>

<h3>Description</h3>

<p>Function to calculate the standardized mean difference (regular or unbiased) using the control group standard deviation 
as the basis of standardization (for either raw data or summary measures).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>smd.c(Group.T = NULL, Group.C = NULL, Mean.T = NULL, Mean.C = NULL, 
s.C = NULL, n.C = NULL, Unbiased=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="smd.c_+3A_group.t">Group.T</code></td>
<td>
<p>Raw data for the treatment group.</p>
</td></tr>
<tr><td><code id="smd.c_+3A_group.c">Group.C</code></td>
<td>
<p>Raw data for the control group.</p>
</td></tr>
<tr><td><code id="smd.c_+3A_mean.t">Mean.T</code></td>
<td>
<p>The mean of the treatment group.</p>
</td></tr>
<tr><td><code id="smd.c_+3A_mean.c">Mean.C</code></td>
<td>
<p>The mean of the control group.</p>
</td></tr>
<tr><td><code id="smd.c_+3A_s.c">s.C</code></td>
<td>
<p>The standard deviation of the control group (i.e., the square root of the unbiased estimator of the population variance).</p>
</td></tr>
<tr><td><code id="smd.c_+3A_n.c">n.C</code></td>
<td>
<p>The sample size of the control group.</p>
</td></tr>
<tr><td><code id="smd.c_+3A_unbiased">Unbiased</code></td>
<td>
<p>Returns the unbiased estimate of the standardized mean difference using the standard deviation of the control group.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>When <code>Unbiased=TRUE</code>, the unbiased estimate of the standardized mean difference (using the control group as the
basis of standardization) is returned (Hedges, 1981). Although
the unbiased estimate of the standardized mean difference is not often reported, at least at the present time, it is
nevertheless made available to those who are interested in calculating this quantity. 
</p>


<h3>Value</h3>

<p>Returns the estimated standardized mean difference using the control group standard deviation as the basis of standardization.
</p>


<h3>Author(s)</h3>

<p>Ken Kelley (University of Notre Dame; <a href="mailto:KKelley@ND.Edu">KKelley@ND.Edu</a>)</p>


<h3>References</h3>

<p>Hedges, L. V. (1981). Distribution theory for Glass's Estimator of effect size and related estimators. <em>Journal of Educational Statistics, 2</em>, 107&ndash;128.
</p>
<p>Glass, G. (1976). Primary, secondary, and meta-analysis of research. <em>Educational Researcher, 5</em>, 3&ndash;8.  
</p>


<h3>See Also</h3>

<p><code>smd</code>, <code>conf.limits.nct</code></p>


<h3>Examples</h3>

<pre><code class='language-R'># Generate sample data.
set.seed(113)
g.T &lt;- rnorm(n=25, mean=.5, sd=1)
g.C &lt;- rnorm(n=25, mean=0, sd=1)
smd.c(Group.T=g.T, Group.C=g.C)

M.T &lt;- .66745
M.C &lt;- .24878
sd.c &lt;- 1.1311
n.c &lt;- 25
smd.c(Mean.T=M.T, Mean.C=M.C, s=sd.c)
smd.c(Mean.T=M.T, Mean.C=M.C, s=sd.c, n.C=n.c, Unbiased=TRUE)
</code></pre>

<hr>
<h2 id='ss.aipe.c'>Sample size planning for an ANOVA contrast from the Accuracy in Parameter Estimation (AIPE) perspective</h2><span id='topic+ss.aipe.c'></span>

<h3>Description</h3>

<p>A function to calculate the appropriate sample size <em>per group</em> for the (unstandardized) ANOVA contrast 
so that the width of the confidence interval is sufficiently narrow. </p>


<h3>Usage</h3>

<pre><code class='language-R'>ss.aipe.c(error.variance = NULL, c.weights, width, conf.level = 0.95, 
assurance = NULL, certainty = NULL, MSwithin = NULL, SD = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ss.aipe.c_+3A_error.variance">error.variance</code></td>
<td>
<p>the common error variance; i.e., the mean square error</p>
</td></tr>
<tr><td><code id="ss.aipe.c_+3A_c.weights">c.weights</code></td>
<td>
<p> the contrast weights </p>
</td></tr>
<tr><td><code id="ss.aipe.c_+3A_width">width</code></td>
<td>
<p> the desired full width of the obtained confidence interval </p>
</td></tr>
<tr><td><code id="ss.aipe.c_+3A_conf.level">conf.level</code></td>
<td>
<p>the desired confidence interval coverage, (i.e., 1 - Type I error rate)</p>
</td></tr>
<tr><td><code id="ss.aipe.c_+3A_assurance">assurance</code></td>
<td>
<p> parameter to ensure that the obtained confidence interval width is narrower than the desired width with a specified degree of certainty (must be NULL or between zero and unity) </p>
</td></tr>
<tr><td><code id="ss.aipe.c_+3A_certainty">certainty</code></td>
<td>
<p>an alias for <code>assurance</code></p>
</td></tr>
<tr><td><code id="ss.aipe.c_+3A_mswithin">MSwithin</code></td>
<td>
<p>an alias for <code>error.variance</code> </p>
</td></tr>
<tr><td><code id="ss.aipe.c_+3A_sd">SD</code></td>
<td>
<p>the standard deviation of the common error in ANOVA model</p>
</td></tr>
<tr><td><code id="ss.aipe.c_+3A_...">...</code></td>
<td>
<p> allows one to potentially include parameter values for inner functions </p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>n</code></td>
<td>
<p>the necessary sample size <em>per group</em></p>
</td></tr>
</table>


<h3>Note</h3>

<p>Be sure to use the error varaince and not its square root (i.e., the standard deviation of the errors).
</p>


<h3>Author(s)</h3>

<p>Ken Kelley (University of Notre Dame; <a href="mailto:KKelley@ND.Edu">KKelley@ND.Edu</a>), Keke Lai </p>


<h3>References</h3>

<p>Kelley, K., Maxwell, S. E., &amp; Rausch, J. R. (2003). Obtaining power or obtaining 
precesion: Delineating methods of sample size planning. <em>Evaluation and the Health Professions, 26</em>, 258&ndash;287.
</p>
<p>Maxwell, S. E., &amp; Delaney, H. D. (2004). <em>Designing experiments and analyzing data: A model 
comparison perspective</em>. Mahwah, NJ: Erlbaum.
</p>


<h3>See Also</h3>

<p><code>ss.aipe.sc</code>, <code>ss.aipe.c.ancova</code>, <code>ci.c</code></p>


<h3>Examples</h3>

<pre><code class='language-R'># Suppose the population error variance of some three-group ANOVA model
# is believed to be 40. The researcher is interested in the difference 
# between the mean of group 1 and the average of means of group 2 and 3. 
# To plan the sample size so that, with 90 percent certainty, the 
# obtained 95 percent full confidence interval width is no wider than 3:

ss.aipe.c(error.variance=40, c.weights=c(1, -0.5, -0.5), width=3, assurance=.90)
</code></pre>

<hr>
<h2 id='ss.aipe.c.ancova'> Sample size planning for a contrast in randomized ANCOVA from the Accuracy in Parameter Estimation (AIPE) perspective</h2><span id='topic+ss.aipe.c.ancova'></span>

<h3>Description</h3>

<p>A function to calculate the appropriate sample size per group for the (unstandardized) contrast, in one-covariate randomized
ANCOVA, so that the width of the confidence interval is sufficiently narrow. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ss.aipe.c.ancova(error.var.ancova = NULL, error.var.anova = NULL, 
rho = NULL, c.weights, width, conf.level = 0.95, 
assurance = NULL, certainty = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ss.aipe.c.ancova_+3A_error.var.ancova">error.var.ancova</code></td>
<td>
<p>the population error variance of the ANCOVA model (i.e., the mean square within of the ANCOVA model)</p>
</td></tr>
<tr><td><code id="ss.aipe.c.ancova_+3A_error.var.anova">error.var.anova</code></td>
<td>
<p>the population error variance of the ANOVA model (i.e., the mean square within of the ANOVA model)</p>
</td></tr>
<tr><td><code id="ss.aipe.c.ancova_+3A_rho">rho</code></td>
<td>
<p>the population correlation coefficient of the response and the covariate</p>
</td></tr>
<tr><td><code id="ss.aipe.c.ancova_+3A_c.weights">c.weights</code></td>
<td>
<p> the contrast weights </p>
</td></tr>
<tr><td><code id="ss.aipe.c.ancova_+3A_width">width</code></td>
<td>
<p> the desired full width of the obtained confidence interval </p>
</td></tr>
<tr><td><code id="ss.aipe.c.ancova_+3A_conf.level">conf.level</code></td>
<td>
<p>the desired confidence interval coverage, (i.e., 1 - Type I error rate)</p>
</td></tr>
<tr><td><code id="ss.aipe.c.ancova_+3A_assurance">assurance</code></td>
<td>
<p> parameter to ensure that the obtained confidence interval width is narrower than the desired width with a specified degree of certainty (must be NULL or between zero and unity) </p>
</td></tr>
<tr><td><code id="ss.aipe.c.ancova_+3A_certainty">certainty</code></td>
<td>
<p>an alias for <code>assurance</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>Either the error variance of the ANCOVA model or of the ANOVA model can be used to plan the appropriate
sample size per group. When using the error variance of the ANOVA model to plan sample size, the correlation coefficient
of the response and the covariate is also needed.</p>


<h3>Value</h3>

<table>
<tr><td><code>n</code></td>
<td>
<p>the necessary sample size <em>per group</em></p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Ken Kelley (University of Notre Dame; <a href="mailto:KKelley@ND.Edu">KKelley@ND.Edu</a>); Keke Lai &lt;Lai.15@ND.Edu&gt; </p>


<h3>References</h3>

 
<p>Kelley, K., Maxwell, S. E., &amp; Rausch, J. R. (2003). Obtaining power or obtaining 
precision: Delineating methods of sample size planning. <em>Evaluation and the Health Professions, 26</em>, 258-287.
</p>
<p>Maxwell, S. E., &amp; Delaney, H. D. (2004). <em>Designing experiments and analyzing data: A model 
comparison perspective</em>. Mahwah, NJ: Erlbaum.
</p>


<h3>See Also</h3>

<p><code>ci.c.ancova</code>, <code>ci.sc.ancova</code>, <code>ss.aipe.c</code> </p>


<h3>Examples</h3>

<pre><code class='language-R'># Suppose the population error variance of some three-group ANOVA model
# is believed to be 40, and the population correlation coefficient 
# of the response and the covariate is 0.22. The researcher is 
# interested in the difference between the mean of group 1 and 
# the average of means of group 2 and 3. To plan the sample size so 
# that, with 90 percent certainty, the obtained 95 percent full 
# confidence interval width is no wider than 3:

ss.aipe.c.ancova(error.var.anova=40, rho=.22, 
c.weights=c(1, -0.5, -0.5), width=3, assurance=.90)
</code></pre>

<hr>
<h2 id='ss.aipe.c.ancova.sensitivity'>Sensitivity analysis for sample size planning for the (unstandardized) contrast in randomized ANCOVA
from the Accuracy in Parameter Estimation (AIPE) Perspective </h2><span id='topic+ss.aipe.c.ancova.sensitivity'></span>

<h3>Description</h3>

<p>Performs a sensitivity analysis when planning sample size from 
the Accuracy in Parameter Estimation (AIPE) Perspective for the (unstandardized) contrast in randomized ANCOVA design.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ss.aipe.c.ancova.sensitivity(true.error.var.ancova = NULL, 
est.error.var.ancova = NULL, true.error.var.anova = NULL, 
est.error.var.anova = NULL, rho, est.rho = NULL, G = 10000, 
mu.y, sigma.y, mu.x, sigma.x, c.weights, width,
conf.level = 0.95, assurance = NULL, certainty=NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ss.aipe.c.ancova.sensitivity_+3A_true.error.var.ancova">true.error.var.ancova</code></td>
<td>
<p>population error variance of the ANCOVA model </p>
</td></tr>
<tr><td><code id="ss.aipe.c.ancova.sensitivity_+3A_est.error.var.ancova">est.error.var.ancova</code></td>
<td>
<p>estimated error variance of the ANCOVA model </p>
</td></tr>
<tr><td><code id="ss.aipe.c.ancova.sensitivity_+3A_true.error.var.anova">true.error.var.anova</code></td>
<td>
<p>population error variance of the ANOVA model (i.e., excluding the covariate) </p>
</td></tr>
<tr><td><code id="ss.aipe.c.ancova.sensitivity_+3A_est.error.var.anova">est.error.var.anova</code></td>
<td>
<p>estimated error variance of the ANOVA model (i.e., excluding the covariate) </p>
</td></tr>
<tr><td><code id="ss.aipe.c.ancova.sensitivity_+3A_rho">rho</code></td>
<td>
<p>population correlation coefficient of the response and the covariate </p>
</td></tr>
<tr><td><code id="ss.aipe.c.ancova.sensitivity_+3A_est.rho">est.rho</code></td>
<td>
<p> estimated correlation coefficient of the response and the covariate </p>
</td></tr>
<tr><td><code id="ss.aipe.c.ancova.sensitivity_+3A_g">G</code></td>
<td>
<p> number of generations (i.e., replications) of the simulation</p>
</td></tr>
<tr><td><code id="ss.aipe.c.ancova.sensitivity_+3A_mu.y">mu.y</code></td>
<td>
<p>vector that contains the response's population mean of each group</p>
</td></tr>
<tr><td><code id="ss.aipe.c.ancova.sensitivity_+3A_sigma.y">sigma.y</code></td>
<td>
<p>the population standard deviation of the response</p>
</td></tr>
<tr><td><code id="ss.aipe.c.ancova.sensitivity_+3A_mu.x">mu.x</code></td>
<td>
<p>the population mean of the covariate</p>
</td></tr>
<tr><td><code id="ss.aipe.c.ancova.sensitivity_+3A_sigma.x">sigma.x</code></td>
<td>
<p>the population standard deviation of the covariate </p>
</td></tr>
<tr><td><code id="ss.aipe.c.ancova.sensitivity_+3A_c.weights">c.weights</code></td>
<td>
<p> the contrast weights </p>
</td></tr>
<tr><td><code id="ss.aipe.c.ancova.sensitivity_+3A_width">width</code></td>
<td>
<p> the desired full width of the obtained confidence interval </p>
</td></tr>
<tr><td><code id="ss.aipe.c.ancova.sensitivity_+3A_conf.level">conf.level</code></td>
<td>
<p>the desired confidence interval coverage, (i.e., 1 - Type I error rate)</p>
</td></tr>
<tr><td><code id="ss.aipe.c.ancova.sensitivity_+3A_assurance">assurance</code></td>
<td>
<p> parameter to ensure that the obtained confidence interval width is narrower than the desired width with a specified degree of certainty (must be NULL or between zero and unity) </p>
</td></tr>
<tr><td><code id="ss.aipe.c.ancova.sensitivity_+3A_certainty">certainty</code></td>
<td>
<p>an alias for <code>assurance</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>The arguments <code>mu.y</code>, <code>mu.x</code>, <code>sigma.y</code>, and <code>sigma.x</code> are used to generate random data in the simulations
for the sensitivity analysis. The value of <code>mu.y</code> should be the same as the square root of <code>true.error.var.anova</code>
</p>
<p>So far this function is based on one-covariate randomized ANCOVA design only. The argument <code>mu.x</code> should be
a single number, because it is assumed that the population mean of the covariate is equal across groups in randomized
ANCOVA. 
</p>


<h3>Value</h3>

<table>
<tr><td><code>Psi.obs</code></td>
<td>
<p>the observed (unstandardized) contrast</p>
</td></tr>
<tr><td><code>se.Psi</code></td>
<td>
<p>the standard error of the observed (unstandardized) contrast</p>
</td></tr>
<tr><td><code>se.Psi.restricted</code></td>
<td>
<p>the standard error of the observed (unstandardized) contrast calculated by ignoring the covariate</p>
</td></tr>
<tr><td><code>se.res.over.se.full</code></td>
<td>
<p>the ratio of contrast's full standard error over the restricted one in each iteration</p>
</td></tr>
<tr><td><code>width.obs</code></td>
<td>
<p>full confidence interval width</p>
</td></tr>
<tr><td><code>Type.I.Error</code></td>
<td>
<p>Type I error happens in each iteration</p>
</td></tr>
<tr><td><code>Type.I.Error.Upper</code></td>
<td>
<p>Type I error happens in the upper end in each iteration</p>
</td></tr>
<tr><td><code>Type.I.Error.Lower</code></td>
<td>
<p>Type I error happens in the lower end in each iteration</p>
</td></tr>
<tr><td><code>Type.I.Error</code></td>
<td>
<p>percentage of Type I error happened in the entire simulation</p>
</td></tr>
<tr><td><code>Type.I.Error.Upper</code></td>
<td>
<p>percentage of Type I error happened in the upper end in the entire simulation</p>
</td></tr>
<tr><td><code>Type.I.Error.Lower</code></td>
<td>
<p>percentage of Type I error happened in the lower end in the entire simulation</p>
</td></tr>
<tr><td><code>width.NARROWER.than.desired</code></td>
<td>
<p>percentage of obtained widths that are narrower than the desired width</p>
</td></tr>
<tr><td><code>Mean.width.obs</code></td>
<td>
<p>mean width of the obtained full confidence intervals</p>
</td></tr>
<tr><td><code>Median.width.obs</code></td>
<td>
<p>median width of the obtained full confidence intervals</p>
</td></tr>
<tr><td><code>Mean.se.res.vs.se.full</code></td>
<td>
<p>the mean of the ratios of contrast's full standard error over the restricted one</p>
</td></tr>
<tr><td><code>Psi.pop</code></td>
<td>
<p>population (unstandardized) contrast</p>
</td></tr>
<tr><td><code>Contrast.Weights</code></td>
<td>
<p>contrast weights</p>
</td></tr>
<tr><td><code>mu.y</code></td>
<td>
<p>the response's population mean of each group</p>
</td></tr>
<tr><td><code>mu.x</code></td>
<td>
<p>the population mean of the covariate</p>
</td></tr>
<tr><td><code>sigma.x</code></td>
<td>
<p>the population standard deviation of the covariate</p>
</td></tr>
<tr><td><code>Sample.Size.per.Group</code></td>
<td>
<p>sample size per group</p>
</td></tr>
<tr><td><code>conf.level</code></td>
<td>
<p>the desired confidence interval coverage, (i.e., 1 - Type I error rate)</p>
</td></tr>
<tr><td><code>assurance</code></td>
<td>
<p>specified <code>assurance</code></p>
</td></tr>
<tr><td><code>rho</code></td>
<td>
<p>population correlation coefficient of the response and the covariate</p>
</td></tr>
<tr><td><code>est.rho</code></td>
<td>
<p>estimated correlation coefficient of the response and the covariate</p>
</td></tr>
<tr><td><code>true.error.var.ANOVA</code></td>
<td>
<p>population error variance of the ANOVA model</p>
</td></tr>
<tr><td><code>est.error.var.ANOVA</code></td>
<td>
<p>estimated error variance of the ANOVA model</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Keke Lai (University of Notre Dame; <a href="mailto:Lai.15@ND.Edu">Lai.15@ND.Edu</a>)</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
ss.aipe.c.ancova.sensitivity(true.error.var.ancova=30, 
est.error.var.ancova=30, rho=.2, mu.y=c(10,12,15,13), mu.x=2, 
G=1000, sigma.x=1.3, sigma.y=2, c.weights=c(1,0,-1,0), width=3)

ss.aipe.c.ancova.sensitivity(true.error.var.anova=36, 
est.error.var.anova=36, rho=.2, est.rho=.2, G=1000, 
mu.y=c(10,12,15,13), mu.x=2, sigma.x=1.3, sigma.y=6, 
c.weights=c(1,0,-1,0), width=3, assurance=NULL)

## End(Not run)
</code></pre>

<hr>
<h2 id='ss.aipe.crd'>
Find target sample sizes for the accuracy in unstandardized conditions means estimation in CRD
</h2><span id='topic+ss.aipe.crd.nclus.fixedwidth'></span><span id='topic+ss.aipe.crd.nindiv.fixedwidth'></span><span id='topic+ss.aipe.crd.nclus.fixedbudget'></span><span id='topic+ss.aipe.crd.nindiv.fixedbudget'></span><span id='topic+ss.aipe.crd.both.fixedbudget'></span><span id='topic+ss.aipe.crd.both.fixedwidth'></span>

<h3>Description</h3>

<p>Find target sample sizes (the number of clusters, cluster size, or both) for the accuracy in unstandardized conditions means estimation in CRD. If users wish to seek for both types of sample sizes simultaneously, an additional constraint is required, such as a desired width or a desired budget.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ss.aipe.crd.nclus.fixedwidth(width, nindiv, prtreat, tauy=NULL, sigma2y=NULL, 
	totalvar=NULL, iccy=NULL, r2between = 0, r2within = 0, numpredictor = 0, 
	assurance=NULL, conf.level = 0.95, cluscost=NULL, indivcost=NULL, diffsize=NULL)
ss.aipe.crd.nindiv.fixedwidth(width, nclus, prtreat, tauy=NULL, sigma2y=NULL, 
	totalvar=NULL, iccy=NULL, r2between = 0, r2within = 0, numpredictor = 0, 
	assurance=NULL, conf.level = 0.95, cluscost=NULL, indivcost=NULL, diffsize=NULL)
ss.aipe.crd.nclus.fixedbudget(budget, nindiv, cluscost = 0, indivcost = 1, 
	prtreat = NULL, tauy=NULL, sigma2y=NULL, totalvar=NULL, iccy=NULL, r2between = 0, 
	r2within = 0, numpredictor = 0, assurance=NULL, conf.level = 0.95, diffsize=NULL)
ss.aipe.crd.nindiv.fixedbudget(budget, nclus, cluscost = 0, indivcost = 1, 
	prtreat = NULL, tauy=NULL, sigma2y=NULL, totalvar=NULL, iccy=NULL, r2between = 0, 
	r2within = 0, numpredictor = 0, assurance=NULL, conf.level = 0.95, diffsize=NULL)
ss.aipe.crd.both.fixedbudget(budget, cluscost=0, indivcost=1, prtreat, tauy=NULL, 
	sigma2y=NULL, totalvar=NULL, iccy=NULL, r2between = 0, r2within = 0, 
	numpredictor = 0, assurance=NULL, conf.level = 0.95, diffsize=NULL)
ss.aipe.crd.both.fixedwidth(width, cluscost=0, indivcost=1, prtreat, tauy=NULL, 
	sigma2y=NULL, totalvar=NULL, iccy=NULL, r2between = 0, r2within = 0, 
	numpredictor = 0, assurance=NULL, conf.level = 0.95, diffsize=NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ss.aipe.crd_+3A_width">width</code></td>
<td>

<p>The desired width of the confidence interval of the unstandardized means difference
</p>
</td></tr>
<tr><td><code id="ss.aipe.crd_+3A_budget">budget</code></td>
<td>

<p>The desired amount of budget
</p>
</td></tr>
<tr><td><code id="ss.aipe.crd_+3A_nclus">nclus</code></td>
<td>

<p>The desired number of clusters
</p>
</td></tr>
<tr><td><code id="ss.aipe.crd_+3A_nindiv">nindiv</code></td>
<td>

<p>The number of individuals in each cluster (cluster size)
</p>
</td></tr>
<tr><td><code id="ss.aipe.crd_+3A_prtreat">prtreat</code></td>
<td>

<p>The proportion of treatment clusters
</p>
</td></tr>
<tr><td><code id="ss.aipe.crd_+3A_cluscost">cluscost</code></td>
<td>

<p>The cost of collecting a new cluster regardless of the number of individuals collected in each cluster
</p>
</td></tr>
<tr><td><code id="ss.aipe.crd_+3A_indivcost">indivcost</code></td>
<td>

<p>The cost of collecting a new individual
</p>
</td></tr>
<tr><td><code id="ss.aipe.crd_+3A_tauy">tauy</code></td>
<td>

<p>The residual variance in the between level before accounting for the covariate
</p>
</td></tr>
<tr><td><code id="ss.aipe.crd_+3A_sigma2y">sigma2y</code></td>
<td>

<p>The residual variance in the within level before accounting for the covariate
</p>
</td></tr>
<tr><td><code id="ss.aipe.crd_+3A_totalvar">totalvar</code></td>
<td>

<p>The total resiudal variance before accounting for the covariate
</p>
</td></tr>
<tr><td><code id="ss.aipe.crd_+3A_iccy">iccy</code></td>
<td>

<p>The intraclass correlation of the dependent variable
</p>
</td></tr>
<tr><td><code id="ss.aipe.crd_+3A_r2within">r2within</code></td>
<td>

<p>The proportion of variance explained in the within level (used when <code>covariate = TRUE</code>)
</p>
</td></tr>
<tr><td><code id="ss.aipe.crd_+3A_r2between">r2between</code></td>
<td>

<p>The proportion of variance explained in the between level (used when <code>covariate = TRUE</code>)
</p>
</td></tr>
<tr><td><code id="ss.aipe.crd_+3A_numpredictor">numpredictor</code></td>
<td>

<p>The number of predictors used in the between level
</p>
</td></tr>
<tr><td><code id="ss.aipe.crd_+3A_assurance">assurance</code></td>
<td>

<p>The degree of assurance, which is the value with which confidence can be placed that describes the likelihood of obtaining a confidence interval less than the value specified (e.g, .80, .90, .95)
</p>
</td></tr>
<tr><td><code id="ss.aipe.crd_+3A_conf.level">conf.level</code></td>
<td>

<p>The desired level of confidence for the confidence interval
</p>
</td></tr>
<tr><td><code id="ss.aipe.crd_+3A_diffsize">diffsize</code></td>
<td>

<p>Difference cluster size specification. The difference in cluster sizes can be specified in two ways. First, users may specify cluster size as integers, which can be negative or positive. The resulting cluster sizes will be based on the estimated cluster size adding by the specified vectors. For example, if the cluster size is 25, the number of clusters is 10, and the specified different cluster size is <code>c(-1, 0, 1)</code>, the cluster sizes will be 24, 25, 26, 24, 25, 26, 24, 25, 26, and 24. Second, users may specify cluster size as positive decimals. The resulting cluster size will be based on the estimated cluster size multiplied by the specified vectors. For example, if the cluster size is 25, the number of clusters is 10, and the specified different cluster size is <code>c(-1, 0, 1)</code>, the cluster sizes will be 24, 25, 26, 24, 25, 26, 24, 25, 26, and 24. If <code>NULL</code>, the cluster size is equal across clusters. 
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Here are the functions' descriptions:
</p>

<ul>
<li> <p><code>ss.aipe.crd.nclus.fixedwidth</code> Find the number of clusters given a specified width of the confidence interval and the cluster size
</p>
</li>
<li> <p><code>ss.aipe.crd.nindiv.fixedwidth</code> Find the cluster size given a specified width of the confidence interval and the number of clusters
</p>
</li>
<li> <p><code>ss.aipe.crd.nclus.fixedbudget</code> Find the number of clusters given a budget and the cluster size
</p>
</li>
<li> <p><code>ss.aipe.crd.nindiv.fixedbudget</code> Find the cluster size given a budget and the number of clusters
</p>
</li>
<li> <p><code>ss.aipe.crd.both.fixedbudget</code> Find the sample size combinations (the number of clusters and that cluster size) providing the narrowest confidence interval given the fixed budget
</p>
</li>
<li> <p><code>ss.aipe.crd.both.fixedwidth</code> Find the sample size combinations (the number of clusters and that cluster size) providing the lowest cost given the specified width of the confidence interval
</p>
</li></ul>



<h3>Value</h3>

<p>The <code>ss.aipe.crd.nclus.fixedwidth</code> and <code>ss.aipe.crd.nclus.fixedbudget</code> functions provide the number of clusters. The <code>ss.aipe.crd.nindiv.fixedwidth</code> and <code>ss.aipe.crd.nindiv.fixedbudget</code> functions provide the cluster size. The <code>ss.aipe.crd.both.fixedbudget</code> and <code>ss.aipe.crd.both.fixedwidth</code> provide the number of clusters and the cluster size, respectively.
</p>


<h3>Author(s)</h3>

<p>Sunthud Pornprasertmanit (<a href="mailto:psunthud@gmail.com">psunthud@gmail.com</a>)
</p>


<h3>References</h3>

<p>Pornprasertmanic, S., &amp; Schneider, W. J. (2014). Accuracy in parameter estimation in cluster randomized designs. <em>Psychological Methods</em>, <em>19</em>, 356&ndash;379.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Examples for each function
ss.aipe.crd.nclus.fixedwidth(width=0.3, nindiv=30, prtreat=0.5, tauy=0.25, sigma2y=0.75)

ss.aipe.crd.nindiv.fixedwidth(width=0.3, nclus=250, prtreat=0.5, tauy=0.25, sigma2y=0.75)

ss.aipe.crd.nclus.fixedbudget(budget=10000, nindiv=20, cluscost=20, indivcost=1)

ss.aipe.crd.nindiv.fixedbudget(budget=10000, nclus=30, cluscost=20, indivcost=1, 
prtreat=0.5, tauy=0.05, sigma2y=0.95, assurance=0.8)

ss.aipe.crd.both.fixedbudget(budget=10000, cluscost=30, indivcost=1, prtreat=0.5, tauy=0.25, 
	sigma2y=0.75)

ss.aipe.crd.both.fixedwidth(width=0.3, cluscost=0, indivcost=1, prtreat=0.5, tauy=0.25, 
	sigma2y=0.75)

# Examples for different cluster size
ss.aipe.crd.nclus.fixedwidth(width=0.3, nindiv=30, prtreat=0.5, tauy=0.25, sigma2y=0.75, 
diffsize = c(-2, 1, 0, 2, -1, 3, -3, 0, 0))

ss.aipe.crd.nclus.fixedwidth(width=0.3, nindiv=30, prtreat=0.5, tauy=0.25, sigma2y=0.75, 
diffsize = c(0.6, 1.2, 0.8, 1.4, 1, 1, 1.1, 0.9))

## End(Not run)
</code></pre>

<hr>
<h2 id='ss.aipe.crd.es'>
Find target sample sizes for the accuracy in standardized conditions means estimation in CRD
</h2><span id='topic+ss.aipe.crd.es.nclus.fixedwidth'></span><span id='topic+ss.aipe.crd.es.nindiv.fixedwidth'></span><span id='topic+ss.aipe.crd.es.nclus.fixedbudget'></span><span id='topic+ss.aipe.crd.es.nindiv.fixedbudget'></span><span id='topic+ss.aipe.crd.es.both.fixedbudget'></span><span id='topic+ss.aipe.crd.es.both.fixedwidth'></span>

<h3>Description</h3>

<p>Find target sample sizes (the number of clusters, cluster size, or both) for the accuracy in standardized conditions means estimation in CRD. If users wish to seek for both types of sample sizes simultaneously, an additional constraint is required, such as a desired width or a desired budget. This function uses the likelihood-based confidence interval (Cheung, 2009) by the <code>OpenMx</code> package (Boker et al., 2011). See further details at Pornprasertmanit and Schneider (2010, submitted).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ss.aipe.crd.es.nclus.fixedwidth(width, nindiv, es, estype = 1, iccy, prtreat, 
	r2between = 0, r2within = 0, numpredictor = 0, assurance=NULL, 
	conf.level = 0.95, nrep = 1000, iccz = NULL, seed = 123321, multicore = FALSE, 
	numProc=NULL, cluscost=NULL, indivcost=NULL, diffsize=NULL)
ss.aipe.crd.es.nindiv.fixedwidth(width, nclus, es, estype = 1, iccy, prtreat, 
	r2between = 0, r2within = 0, numpredictor = 0, assurance=NULL, 
	conf.level = 0.95, nrep = 1000, iccz = NULL, seed = 123321, multicore = FALSE, 
	numProc=NULL, cluscost=NULL, indivcost=NULL, diffsize=NULL) 
ss.aipe.crd.es.nclus.fixedbudget(budget, nindiv, cluscost, indivcost, nrep=NULL, 
	prtreat=NULL, iccy=NULL, es=NULL, estype = 1, numpredictor = 0, 
	iccz=NULL, r2within=NULL, r2between=NULL, assurance=NULL, 
	seed=123321, multicore=FALSE, numProc=NULL, conf.level=0.95, diffsize=NULL)
ss.aipe.crd.es.nindiv.fixedbudget(budget, nclus, cluscost, indivcost, nrep=NULL, 
	prtreat=NULL, iccy=NULL, es=NULL, estype = 1, numpredictor = 0, 
	iccz=NULL, r2within=NULL, r2between=NULL, assurance=NULL, 
	seed=123321, multicore=FALSE, numProc=NULL, conf.level=0.95, diffsize=NULL) 
ss.aipe.crd.es.both.fixedbudget(budget, cluscost=0, indivcost=1, es, estype = 1, 
	iccy, prtreat, r2between = 0, r2within = 0, numpredictor = 0, assurance=NULL, 
	conf.level = 0.95, nrep = 1000, iccz = NULL, seed = 123321, multicore = FALSE, 
	numProc=NULL, diffsize=NULL)
ss.aipe.crd.es.both.fixedwidth(width, cluscost=0, indivcost=1, es, estype = 1, 
	iccy, prtreat, r2between = 0, r2within = 0, numpredictor = 0, assurance=NULL, 
	conf.level = 0.95, nrep = 1000, iccz = NULL, seed = 123321, multicore = FALSE, 
	numProc=NULL, diffsize=NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ss.aipe.crd.es_+3A_width">width</code></td>
<td>

<p>The desired width of the confidence interval of the unstandardized means difference
</p>
</td></tr>
<tr><td><code id="ss.aipe.crd.es_+3A_budget">budget</code></td>
<td>

<p>The desired amount of budget
</p>
</td></tr>
<tr><td><code id="ss.aipe.crd.es_+3A_nclus">nclus</code></td>
<td>

<p>The desired number of clusters
</p>
</td></tr>
<tr><td><code id="ss.aipe.crd.es_+3A_nindiv">nindiv</code></td>
<td>

<p>The number of individuals in each cluster (cluster size)
</p>
</td></tr>
<tr><td><code id="ss.aipe.crd.es_+3A_prtreat">prtreat</code></td>
<td>

<p>The proportion of treatment clusters
</p>
</td></tr>
<tr><td><code id="ss.aipe.crd.es_+3A_cluscost">cluscost</code></td>
<td>

<p>The cost of collecting a new cluster regardless of the number of individuals collected in each cluster
</p>
</td></tr>
<tr><td><code id="ss.aipe.crd.es_+3A_indivcost">indivcost</code></td>
<td>

<p>The cost of collecting a new individual
</p>
</td></tr>
<tr><td><code id="ss.aipe.crd.es_+3A_iccy">iccy</code></td>
<td>

<p>The intraclass correlation of the dependent variable
</p>
</td></tr>
<tr><td><code id="ss.aipe.crd.es_+3A_es">es</code></td>
<td>

<p>The amount of effect size
</p>
</td></tr>
<tr><td><code id="ss.aipe.crd.es_+3A_estype">estype</code></td>
<td>

<p>The type of effect size. There are only three possible options: 0 = the effect size using total standard deviation, 1 = the effect size using the individual-level standard deviation (level 1), 2 = the effect size using the cluster-level standard deviation (level 2)
</p>
</td></tr>
<tr><td><code id="ss.aipe.crd.es_+3A_numpredictor">numpredictor</code></td>
<td>

<p>If 1, a single covariate is included into the model. If 0, the no-covariate model is used. This function cannot handle multiple covariates. Therefore, only the values of 0 and 1 are allowed.
</p>
</td></tr>
<tr><td><code id="ss.aipe.crd.es_+3A_iccz">iccz</code></td>
<td>

<p>The intraclass correlation of the covariate (used when <code>covariate = TRUE</code>). If <code>iccz = 0</code>, the within-level covariate will be only used. If <code>iccz = 1</code>, the between-level covariate will be only used.
</p>
</td></tr>
<tr><td><code id="ss.aipe.crd.es_+3A_r2within">r2within</code></td>
<td>

<p>The proportion of variance explained in the within level (used when <code>covariate = TRUE</code>)
</p>
</td></tr>
<tr><td><code id="ss.aipe.crd.es_+3A_r2between">r2between</code></td>
<td>

<p>The proportion of variance explained in the between level (used when <code>covariate = TRUE</code>)
</p>
</td></tr>
<tr><td><code id="ss.aipe.crd.es_+3A_assurance">assurance</code></td>
<td>

<p>The degree of assurance, which is the value with which confidence can be placed that describes the likelihood of obtaining a confidence interval less than the value specified (e.g, .80, .90, .95)
</p>
</td></tr>
<tr><td><code id="ss.aipe.crd.es_+3A_nrep">nrep</code></td>
<td>

<p>The number of replications used in a priori Monte Carlo simulation
</p>
</td></tr>
<tr><td><code id="ss.aipe.crd.es_+3A_seed">seed</code></td>
<td>

<p>A desired seed number
</p>
</td></tr>
<tr><td><code id="ss.aipe.crd.es_+3A_multicore">multicore</code></td>
<td>

<p>Use multiple processors within a computer. Specify as <code>TRUE</code> to use it. 
</p>
</td></tr>
<tr><td><code id="ss.aipe.crd.es_+3A_numproc">numProc</code></td>
<td>

<p>The number of processors to be used when <code>multicore=TRUE</code>. If it is not specified, the package will use the maximum number of processors in a machine. 
</p>
</td></tr>
<tr><td><code id="ss.aipe.crd.es_+3A_conf.level">conf.level</code></td>
<td>

<p>The desired level of confidence for the confidence interval
</p>
</td></tr>
<tr><td><code id="ss.aipe.crd.es_+3A_diffsize">diffsize</code></td>
<td>

<p>Difference cluster size specification. The difference in cluster sizes can be specified in two ways. First, users may specify cluster size as integers, which can be negative or positive. The resulting cluster sizes will be based on the estimated cluster size adding by the specified vectors. For example, if the cluster size is 25, the number of clusters is 10, and the specified different cluster size is <code>c(-1, 0, 1)</code>, the cluster sizes will be 24, 25, 26, 24, 25, 26, 24, 25, 26, and 24. Second, users may specify cluster size as positive decimals. The resulting cluster size will be based on the estimated cluster size multiplied by the specified vectors. For example, if the cluster size is 25, the number of clusters is 10, and the specified different cluster size is <code>c(-1, 0, 1)</code>, the cluster sizes will be 24, 25, 26, 24, 25, 26, 24, 25, 26, and 24. If <code>NULL</code>, the cluster size is equal across clusters. 
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Here are the functions' descriptions:
</p>

<ul>
<li> <p><code>ss.aipe.crd.es.nclus.fixedwidth</code> Find the number of clusters given a specified width of the confidence interval and the cluster size
</p>
</li>
<li> <p><code>ss.aipe.crd.es.nindiv.fixedwidth</code> Find the cluster size given a specified width of the confidence interval and the number of clusters
</p>
</li>
<li> <p><code>ss.aipe.crd.es.nclus.fixedbudget</code> Find the number of clusters given a budget and the cluster size
</p>
</li>
<li> <p><code>ss.aipe.crd.es.nindiv.fixedbudget</code> Find the cluster size given a budget and the number of clusters
</p>
</li>
<li> <p><code>ss.aipe.crd.es.both.fixedbudget</code> Find the sample size combinations (the number of clusters and that cluster size) providing the narrowest confidence interval given the fixed budget
</p>
</li>
<li> <p><code>ss.aipe.crd.es.both.fixedwidth</code> Find the sample size combinations (the number of clusters and that cluster size) providing the lowest cost given the specified width of the confidence interval
</p>
</li></ul>



<h3>Value</h3>

<p>The <code>ss.aipe.crd.es.nclus.fixedwidth</code> and <code>ss.aipe.crd.es.nclus.fixedbudget</code> functions provide the number of clusters. The <code>ss.aipe.crd.es.nindiv.fixedwidth</code> and <code>ss.aipe.crd.es.nindiv.fixedbudget</code> functions provide the cluster size. The <code>ss.aipe.crd.es.both.fixedbudget</code> and <code>ss.aipe.crd.es.both.fixedwidth</code> provide the number of clusters and the cluster size, respectively.
</p>


<h3>Author(s)</h3>

<p>Sunthud Pornprasertmanit (<a href="mailto:psunthud@gmail.com">psunthud@gmail.com</a>)
</p>


<h3>References</h3>

 
<p>Boker, S., M., N., Maes, H., Wilde, M., Spiegel, M., Brick, T., et al. (2011).
OpenMx: An open source extended structural equation modeling framework.
<em>Psychometrika, 76,</em> 306-317.
</p>
<p>Cheung, M. W.-L. (2009). Constructing approximate confidence intervals for
parameters with structural constructing approximate confidence intervals for
parameters with structural equation models. <em>Structural Equation Modeling,
16,</em> 267-294.
</p>
<p>Pornprasertmanit, S., &amp; Schneider, W. J. (2010). <em>Efficient sample size for power and desired accuracy in Cohen's d estimation in two-group cluster randomized design</em> (Master Thesis). Illinois State University, Normal, IL. 
</p>
<p>Pornprasertmanic, S., &amp; Schneider, W. J. (2014). Accuracy in parameter estimation in cluster randomized designs. <em>Psychological Methods</em>, <em>19</em>, 356&ndash;379.</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Examples for each function
ss.aipe.crd.es.nclus.fixedwidth(width=0.3, nindiv=20, es=0.5, estype=1, iccy=0.25, prtreat=0.5, 
	nrep=20)

ss.aipe.crd.es.nindiv.fixedwidth(width=0.3, 250, es=0.5, estype=1, iccy=0.25, prtreat=0.5, 
	nrep=20)

ss.aipe.crd.es.nclus.fixedbudget(budget=1000, nindiv=20, cluscost=0, indivcost=1, nrep=20, 
	prtreat=0.5, iccy=0.25, es=0.5)

ss.aipe.crd.es.nindiv.fixedbudget(budget=1000, nclus=200, cluscost=0, indivcost=1, nrep=20, 
	prtreat=0.5, iccy=0.25, es=0.5)

ss.aipe.crd.es.both.fixedbudget(budget=1000, cluscost=5, indivcost=1, es=0.5, estype=1, 
	iccy=0.25, prtreat=0.5, nrep=20)

ss.aipe.crd.es.both.fixedwidth(width=0.5, cluscost=5, indivcost=1, es=0.5, estype=1, iccy=0.25, 
	prtreat=0.5, nrep=20)

# Examples for different cluster size
ss.aipe.crd.es.nclus.fixedwidth(width=0.3, nindiv=20, es=0.5, estype=1, iccy=0.25, prtreat=0.5, 
nrep=20, diffsize = c(-2, 1, 0, 2, -1, 3, -3, 0, 0))

ss.aipe.crd.es.nclus.fixedwidth(width=0.3, nindiv=20, es=0.5, estype=1, iccy=0.25, prtreat=0.5, 
nrep=20, diffsize = c(0.6, 1.2, 0.8, 1.4, 1, 1, 1.1, 0.9))

## End(Not run)
</code></pre>

<hr>
<h2 id='ss.aipe.cv'>Sample size planning for the coefficient of variation given the goal of Accuracy in Parameter Estimation approach to sample 
size planning</h2><span id='topic+ss.aipe.cv'></span>

<h3>Description</h3>

<p>Determines the necessary sample size so that the expected confidence interval width
for the coefficient of variation will be sufficiently narrow, optionally with a desired degree of 
certainty that the interval will not be wider than desired. The value of <code>C.of.V</code> should be positive.</p>


<h3>Usage</h3>

<pre><code class='language-R'>ss.aipe.cv(C.of.V = NULL, width = NULL, conf.level = 0.95, 
degree.of.certainty = NULL, assurance=NULL, certainty=NULL, 
mu = NULL, sigma = NULL, alpha.lower = NULL, alpha.upper = NULL, 
Suppress.Statement = TRUE, sup.int.warns = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ss.aipe.cv_+3A_c.of.v">C.of.V</code></td>
<td>
<p>population coefficient of variation on which the sample size procedure is based</p>
</td></tr>
<tr><td><code id="ss.aipe.cv_+3A_width">width</code></td>
<td>
<p>desired (full) width of the confidence interval</p>
</td></tr>
<tr><td><code id="ss.aipe.cv_+3A_conf.level">conf.level</code></td>
<td>
<p>confidence interval coverage; 1-Type I error rate</p>
</td></tr>
<tr><td><code id="ss.aipe.cv_+3A_degree.of.certainty">degree.of.certainty</code></td>
<td>
<p>value with which confidence can be placed that describes the likelihood of obtaining a confidence interval less than the value specified (e.g., .80, .90, .95)</p>
</td></tr>
<tr><td><code id="ss.aipe.cv_+3A_assurance">assurance</code></td>
<td>
<p> an alias for <code>degree.of.certainty</code> </p>
</td></tr>
<tr><td><code id="ss.aipe.cv_+3A_certainty">certainty</code></td>
<td>
<p>an alias for <code>degree.of.certainty</code></p>
</td></tr>
<tr><td><code id="ss.aipe.cv_+3A_mu">mu</code></td>
<td>
<p>population mean (specified with <code>sigma</code> when <code>C.of.V</code> is not specified)</p>
</td></tr>
<tr><td><code id="ss.aipe.cv_+3A_sigma">sigma</code></td>
<td>
<p>population standard deviation (specified with <code>mu</code> when <code>C.of.V</code>) is not specified)</p>
</td></tr>
<tr><td><code id="ss.aipe.cv_+3A_alpha.lower">alpha.lower</code></td>
<td>
<p>Type I error for the lower confidence limit</p>
</td></tr>
<tr><td><code id="ss.aipe.cv_+3A_alpha.upper">alpha.upper</code></td>
<td>
<p>Type I error for the upper confidence limit</p>
</td></tr>
<tr><td><code id="ss.aipe.cv_+3A_suppress.statement">Suppress.Statement</code></td>
<td>
<p>Suppress a message restating the input specifications</p>
</td></tr>
<tr><td><code id="ss.aipe.cv_+3A_sup.int.warns">sup.int.warns</code></td>
<td>
<p>suppress internal function warnings (e.g., warnings associated with <code>qt</code>)</p>
</td></tr>
<tr><td><code id="ss.aipe.cv_+3A_...">...</code></td>
<td>
<p>for modifying parameters of functions this function calls </p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns the necessary sample size given the input specifications.</p>


<h3>Author(s)</h3>

<p>Ken Kelley (University of Notre Dame; <a href="mailto:KKelley@ND.Edu">KKelley@ND.Edu</a>)</p>


<h3>See Also</h3>

<p><code>ss.aipe.cv.sensitivity</code>, <code>cv</code></p>


<h3>Examples</h3>

<pre><code class='language-R'># Suppose one wishes to have a confidence interval with an expected width of .10 
# for a 99% confidence interval when the population coefficient of variation is .25.
ss.aipe.cv(C.of.V=.1, width=.1, conf.level=.99)

# Ensuring that the confidence interval will be sufficiently narrow with a 99% 
# certainty for the situation above.
ss.aipe.cv(C.of.V=.1, width=.1, conf.level=.99, degree.of.certainty=.99)
</code></pre>

<hr>
<h2 id='ss.aipe.cv.sensitivity'>Sensitivity analysis for sample size planning given the Accuracy in Parameter Estimation approach for the coefficient of variation.</h2><span id='topic+ss.aipe.cv.sensitivity'></span>

<h3>Description</h3>

<p>Performs sensitivity analysis for sample size determination for the coefficient of variation
given a population coefficient of variation (or population mean and standard deviation) and goals for the 
sample size procedure. Allows one to determine the effect of being wrong when estimating the 
population coefficient of variation in terms of the width of the obtained (two-sided) confidence intervals. 
The values of <code>True.C.of.V</code> and <code>Estimated.C.of.V</code> should be positive.</p>


<h3>Usage</h3>

<pre><code class='language-R'>ss.aipe.cv.sensitivity(True.C.of.V = NULL, Estimated.C.of.V = NULL,
width = NULL, degree.of.certainty = NULL, assurance=NULL, certainty=NULL, 
mean = 100, Specified.N = NULL, conf.level = 0.95, 
G = 1000, print.iter = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ss.aipe.cv.sensitivity_+3A_true.c.of.v">True.C.of.V</code></td>
<td>
<p>population coefficient of variation</p>
</td></tr>
<tr><td><code id="ss.aipe.cv.sensitivity_+3A_estimated.c.of.v">Estimated.C.of.V</code></td>
<td>
<p>estimated coefficient of variation</p>
</td></tr>
<tr><td><code id="ss.aipe.cv.sensitivity_+3A_width">width</code></td>
<td>
<p>desired confidence interval width</p>
</td></tr>
<tr><td><code id="ss.aipe.cv.sensitivity_+3A_degree.of.certainty">degree.of.certainty</code></td>
<td>
<p>parameter to ensure confidence interval width with a specified degree of certainty (must be NULL or between zero and unity)</p>
</td></tr>
<tr><td><code id="ss.aipe.cv.sensitivity_+3A_assurance">assurance</code></td>
<td>
<p> the alias for <code>degree.of.certainty</code> </p>
</td></tr>
<tr><td><code id="ss.aipe.cv.sensitivity_+3A_certainty">certainty</code></td>
<td>
<p>an alias for <code>degree.of.certainty</code></p>
</td></tr>
<tr><td><code id="ss.aipe.cv.sensitivity_+3A_mean">mean</code></td>
<td>
<p>Some arbitrary value that the simulation uses to generate data (the variance of the data is determined by the mean and the coefficient of variation)</p>
</td></tr>
<tr><td><code id="ss.aipe.cv.sensitivity_+3A_specified.n">Specified.N</code></td>
<td>
<p>selected sample size to use in order to determine distributional properties of at a given value of sample size (not used with <code>Estimated.C.of.V</code>)</p>
</td></tr>
<tr><td><code id="ss.aipe.cv.sensitivity_+3A_conf.level">conf.level</code></td>
<td>
<p>the desired degree of confidence (i.e., 1-Type I error rate).</p>
</td></tr>
<tr><td><code id="ss.aipe.cv.sensitivity_+3A_g">G</code></td>
<td>
<p>number of generations (i.e., replications) of the simulation</p>
</td></tr>
<tr><td><code id="ss.aipe.cv.sensitivity_+3A_print.iter">print.iter</code></td>
<td>
<p>to print the current value of the iterations</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For sensitivity analysis when planning sample size given the desire to obtain narrow confidence intervals
for the population coefficient of variation. Given a population value and an estimated value, one can determine
the effects of incorrectly specifying the population coefficient of variation (<code>True.C.of.V</code>) on the 
obtained widths of the confidence intervals. Also, one can evaluate the percent of the confidence intervals
that are less than the desired width (especially when modifying the <code>degree.of.certainty</code> parameter); see <code>ss.aipe.cv</code>)
</p>
<p>Alternatively, one can specify <code>Specified.N</code> to determine the results at a particular sample size (when doing this <code>Estimated.C.of.V</code> cannot be specified).
</p>


<h3>Value</h3>

<table>
<tr><td><code>Data.from.Simulation</code></td>
<td>
<p>list of the results in matrix form</p>
</td></tr>
<tr><td><code>Specifications</code></td>
<td>
<p>specification of the function</p>
</td></tr>
<tr><td><code>Summary.of.Results</code></td>
<td>
<p>summary measures of some important descriptive statistics</p>
</td></tr>  
</table>


<h3>Note</h3>

<p>Returns three lists, where each list has multiple components.</p>


<h3>Author(s)</h3>

<p>Ken Kelley (University of Notre Dame; <a href="mailto:KKelley@ND.Edu">KKelley@ND.Edu</a>)</p>


<h3>See Also</h3>

<p><code>cv</code>, <code>ss.aipe.cv</code></p>

<hr>
<h2 id='ss.aipe.pcm'>Sample size planning for polynomial change models in longitudinal study
</h2><span id='topic+ss.aipe.pcm'></span>

<h3>Description</h3>

<p>This function plans sample size with respect to the group-by-time interaction in the context of a longitudinal design with two groups. It plans sample size from the accuracy in parameter estimation (AIPE) perspective, where the goal is to obtain a sufficiently narrow confidence interval for the fixed effect polynomial
change coefficient parameter (e.g., linear, quadratic, etc.). The sample size returned can be one such that (a) the expected confidence interval width is sufficiently narrow, or (b) the observed confidence interval will be sufficiently narrow with a specified high degree of assurance (e.g., .99, .95, .90, etc.). This function accompanies Kelley and Rausch (2011).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ss.aipe.pcm(true.variance.trend, error.variance, 
variance.true.minus.estimated.trend = NULL, duration, frequency, 
width, conf.level = 0.95, trend = "linear", assurance = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ss.aipe.pcm_+3A_true.variance.trend">true.variance.trend</code></td>
<td>
<p>The variance of the individuals' true change coefficients (i.e., <code class="reqn">\sigma^2_{\upsilon_m}</code> in Kelley &amp; Rausch, 2011) for the polynomial trend (e.g., linear, quadratic, etc.) of interest.</p>
</td></tr>
<tr><td><code id="ss.aipe.pcm_+3A_error.variance">error.variance</code></td>
<td>
<p>The true error variance (i.e., <code class="reqn">\sigma^2_{\epsilon}</code> in Kelley &amp; Rausch, 2011).</p>
</td></tr>
<tr><td><code id="ss.aipe.pcm_+3A_variance.true.minus.estimated.trend">variance.true.minus.estimated.trend</code></td>
<td>
<p>The variance of the difference between the <code class="reqn">m</code>th true change coefficient minus the <code class="reqn">m</code>th estimated change coefficient (i.e., <code class="reqn">\sigma^2_{\hat{\pi}_{m} - \pi_{m}}</code> from Equation 19 in Kelley &amp; Rausch, 2011).</p>
</td></tr>
<tr><td><code id="ss.aipe.pcm_+3A_duration">duration</code></td>
<td>
<p>The duration of the study.</p>
</td></tr>
<tr><td><code id="ss.aipe.pcm_+3A_frequency">frequency</code></td>
<td>
<p>The number of times measurement occurs within each unit of time. </p>
</td></tr>
<tr><td><code id="ss.aipe.pcm_+3A_width">width</code></td>
<td>
<p>width of the confidence interval</p>
</td></tr>
<tr><td><code id="ss.aipe.pcm_+3A_conf.level">conf.level</code></td>
<td>
<p>The desired level of confidence for the confidence interval that will be computed at the completion of the study. </p>
</td></tr>
<tr><td><code id="ss.aipe.pcm_+3A_trend">trend</code></td>
<td>
<p>The polynomial trend (1st-3rd) of interest specified as &quot;linear&quot;, &quot;quadratic&quot;, or &quot;cubic&quot;.</p>
</td></tr>
<tr><td><code id="ss.aipe.pcm_+3A_assurance">assurance</code></td>
<td>
<p>Value with which confidence can be placed that describes the likelihood of obtaining a confidence interval less than the value specified (e.g, .80, .90, .95)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns the necessary sample size for the combination of the desired goals and values of the population parameters for a specific design. 
</p>


<h3>Note</h3>

<p>Like in all formal sample size planning methods that require the value of one or more population parameter(s), if the population parameters are incorrectly specified, there is no guarantee that the sample size this function returns will be accurate. Of course, the further away from the true values, the further away the true sample size will tend to be.
</p>
<p>The number of timepoints in a study (say <code class="reqn">M</code>) is defined by <code class="reqn">f \times D + 1</code>, where <code class="reqn">f</code> is the frequency and <code class="reqn">D</code> is the duration.</p>


<h3>Author(s)</h3>

<p>Ken Kelley (University of Notre Dame; <a href="mailto:KKelley@ND.Edu">KKelley@ND.Edu</a>)</p>


<h3>References</h3>

<p>Kelley, K., &amp; Rausch, J. R. (2011). Accuracy in parameter estimation for polynomial change models. <em>Psychological Methods</em>.</p>


<h3>Examples</h3>

<pre><code class='language-R'> 
## Not run: 
# An example used in Kelley and Rausch for the expected confidence interval 
# width (returns 278). Thus, a necessary sample size of 278 is required when 
# the duration of the study will be 4 units and the frequency of measurement 
# occasions is 1 year in order for the expected confidence interval 
# width to be 0.025 units.  

ss.aipe.pcm(true.variance.trend=0.003, error.variance=0.0262, duration=4, 
frequency=1, width=0.025, conf.level=.95)

# Now, when incorporating an assurance parameter (returns 316). 
# Thus, a necessary sample size of 316 will ensure that the 95% confidence 
# interval will be sufficiently narrow (i.e., have a width less than .025 units) 
# at least 99% of the time.

ss.aipe.pcm(true.variance.trend=.003, error.variance=.0262, duration=4, 
frequency=1, width=.025, conf.level=.95, assurance=.99)

## End(Not run)
</code></pre>

<hr>
<h2 id='ss.aipe.R2'> Sample Size Planning for Accuracy in Parameter Estimation
for the multiple correlation coefficient. </h2><span id='topic+ss.aipe.R2'></span>

<h3>Description</h3>

<p>Determines necessary sample size for the multiple correlation coefficient so that the 
confidence interval for the population multiple correlation coefficient is 
sufficiently narrow. Optionally, there is a certainty parameter that allows one to be 
a specified percent certain that the observed interval will be no wider than desired.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ss.aipe.R2(Population.R2 = NULL, conf.level = 0.95, width = NULL, 
Random.Predictors = TRUE, Random.Regressors, which.width = "Full", p = NULL, 
K, degree.of.certainty = NULL, assurance=NULL, certainty=NULL, 
verify.ss = FALSE, Tol = 1e-09, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ss.aipe.R2_+3A_population.r2">Population.R2</code></td>
<td>
<p> value of the population multiple correlation coefficient </p>
</td></tr>
<tr><td><code id="ss.aipe.R2_+3A_conf.level">conf.level</code></td>
<td>
<p> confidence interval level (e.g., .95, .99, .90); 1-Type I error rate </p>
</td></tr>
<tr><td><code id="ss.aipe.R2_+3A_width">width</code></td>
<td>
<p>width of the confidence interval (see <code>which.width</code>) </p>
</td></tr>
<tr><td><code id="ss.aipe.R2_+3A_random.predictors">Random.Predictors</code></td>
<td>
<p> whether or not the predictor variables are random (set to <code>TRUE</code>) or are fixed (set to <code>FALSE</code>) </p>
</td></tr>
<tr><td><code id="ss.aipe.R2_+3A_random.regressors">Random.Regressors</code></td>
<td>
<p> an alias for <code>Random.Predictors</code>; <code>Random.Regressors</code> 
overrides <code>Random.Predictors</code> </p>
</td></tr>
<tr><td><code id="ss.aipe.R2_+3A_which.width">which.width</code></td>
<td>
<p> defines the width that <code>width</code> refers to </p>
</td></tr>
<tr><td><code id="ss.aipe.R2_+3A_p">p</code></td>
<td>
<p> the number of predictor variables </p>
</td></tr>
<tr><td><code id="ss.aipe.R2_+3A_k">K</code></td>
<td>
<p> an alias for <code>p</code>; <code>K</code> overrides <code>p</code> </p>
</td></tr>
<tr><td><code id="ss.aipe.R2_+3A_degree.of.certainty">degree.of.certainty</code></td>
<td>
<p>value with which confidence can be placed that describes the likelihood of obtaining a confidence interval less than the value specified (e.e.g, .80, .90, .95)</p>
</td></tr>
<tr><td><code id="ss.aipe.R2_+3A_assurance">assurance</code></td>
<td>
<p> an alias for <code>degree.of.certainty</code> </p>
</td></tr>
<tr><td><code id="ss.aipe.R2_+3A_certainty">certainty</code></td>
<td>
<p>an alias for <code>degree.of.certainty</code></p>
</td></tr>
<tr><td><code id="ss.aipe.R2_+3A_verify.ss">verify.ss</code></td>
<td>
<p>evaluates numerically via an internal Monte Carlo simulation the exact sample size given the specifications</p>
</td></tr>
<tr><td><code id="ss.aipe.R2_+3A_tol">Tol</code></td>
<td>
<p>the tolerance of the iterative function <code>conf.limits.nct</code> for convergence</p>
</td></tr>  
<tr><td><code id="ss.aipe.R2_+3A_...">...</code></td>
<td>
<p>for modifying the parameters of functions this function calls upon</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function determines a necessary sample size so that the expected confidence 
interval width for the squared multiple correlation coefficient is sufficiently narrow (when <code>degree.of.certainty=NULL</code>) so that the obtained confidence 
interval is no larger than the value specified with some desired degree of 
certainty (i.e., a probability that the obtained width is less than the specified 
width). The method depends on whether or not the regressors are regarded as fixed 
or random. This is the case because the distribution theory for the two cases is 
different and thus the confidence interval procedure is conditional on the type of 
regressors. The default methods are approximate but can be made exact with the 
specification of <code>verify.ss=TRUE</code>, which performs an a priori Monte Carlo simulation study. Kelley (2007) and Kelley &amp; Maxwell (2008) detail the methods used in the 
function, with the former focusing on random regressors and the latter on fixed regressors.
</p>
<p>It is recommended that the option <code>verify.ss</code> should always be used! Doing so uses the method implied sample size as an estimate and then evaluates with an internal Monte Carlo simulation (i.e., via &quot;brute-force&quot; methods) the exact sample size given the goals specified. When <code>verify.ss=TRUE</code>, the default number of iterations is 10,000 but this can be changed by specifying G=5000 (or some other value; 10000 is the recommended) When <code>verify.ss=TRUE</code> is specified, an internal function <code>verify.ss.aipe.R2</code> calls upon the <code>ss.aipe.R2.sensitivity</code> function for purposes of the 
internal Monte Carlo simulation study. See the <code>verify.ss.aipe.R2</code> function for arguments that can be passed from <code>ss.aipe.R2</code> to <code>verify.ss.aipe.R2</code>.
</p>


<h3>Value</h3>

<table>
<tr><td><code>Required.Sample.Size</code></td>
<td>
<p>sample size that should be used given the conditions specified.</p>
</td></tr>

</table>


<h3>Note</h3>

<p> This function without <code>verify.SS=FALSE</code> can be slow to converge when
<code>verify.SS=TRUE</code>, the function can take some time to converge (e.g., 15 minutes). 
Most times this will not be the case, but it is possible in some situations.
</p>


<h3>Author(s)</h3>

<p> Ken Kelley (University of Notre Dame; <a href="mailto:KKelley@ND.Edu">KKelley@ND.Edu</a>) </p>


<h3>References</h3>

 
<p>Algina, J. &amp; Olejnik, S. (2000). Determining sample size for accurate estimation of the squared
multiple correlation coefficient. <em>Multivariate Behavioral Research, 35</em>, 119&ndash;136.
</p>
<p>Steiger, J. H. &amp; Fouladi, R. T. (1992). R2: A computer program for interval estimation, power calculation,
and hypothesis testing for the squared multiple correlation. <em>Behavior research methods, instruments and computers, 4</em>, 581&ndash;582.
</p>
<p>Kelley, K. (2007). Sample size planning for the squared multiple correlation coefficient:
Accuracy in parameter estimation via narrow confidence intervals, 
<em>manuscripted submitted for publication</em>.
</p>
<p>Kelley, K. &amp; Maxwell, S. E. (2008). Power and accuracy for omnibus and targeted effects: 
Issues of sample size planning with applications to multiple regression. In P. Alasuuta, J. Brannen, &amp; L. Bickman (Eds.),
<em>Handbook of Social Research Methods</em> (pp. 166&ndash;192). Newbury Park, CA: Sage.
</p>


<h3>See Also</h3>

 <p><code>ci.R2</code>, <code>conf.limits.nct</code>, <code>ss.aipe.R2.sensitivity</code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Returned sample size should be considered approximate; exact sample
# size is obtained by specifying the argument 'verify.ss=TRUE' (see below).
# ss.aipe.R2(Population.R2=.50, conf.level=.95, width=.10, which.width="Full",
# p=5, Random.Predictors=TRUE)
# Uncomment to run in order to get exact sample size.
# ss.aipe.R2(Population.R2=.50, conf.level=.95, width=.10, which.width="Full",
# p=5, Random.Predictors=TRUE, verify.ss=TRUE)


# Same as above, except the predictor variables are considered fixed.
# Returned sample size should be considered approximate; exact sample
# size is obtained by specifying the argument 'verify.ss=TRUE'.
# ss.aipe.R2(Population.R2=.50, conf.level=.95, width=.10, which.width="Full",
# p=5, Random.Predictors=FALSE)
# Uncomment to run in order to get exact sample size.
#ss.aipe.R2(Population.R2=.50, conf.level=.95, width=.10, which.width="Full",
#p=5, Random.Predictors=FALSE, verify.ss=TRUE)


# Returned sample size should be considered approximate; exact sample
# size is obtained by specifying the argument 'verify.ss=TRUE'.
# ss.aipe.R2(Population.R2=.50, conf.level=.95, width=.10, which.width="Full",
# p=5, degree.of.certainty=.85, Random.Predictors=TRUE)
# Uncomment to run in order to get exact sample size.
#ss.aipe.R2(Population.R2=.50, conf.level=.95, width=.10, which.width="Full",
#p=5, degree.of.certainty=.85, Random.Predictors=TRUE, verify.ss=TRUE)


# Same as above, except the predictor variables are considered fixed.
# Returned sample size should be considered approximate; exact sample
# size is obtained by specifying the argument 'verify.ss=TRUE'.
# ss.aipe.R2(Population.R2=.50, conf.level=.95, width=.10, which.width="Full",
# p=5, degree.of.certainty=.85, Random.Predictors=FALSE)
# Uncomment to run in order to get exact sample size.
#ss.aipe.R2(Population.R2=.50, conf.level=.95, width=.10, which.width="Full",
#p=5, degree.of.certainty=.85, Random.Predictors=FALSE, verify.ss=TRUE)

## End(Not run)
</code></pre>

<hr>
<h2 id='ss.aipe.R2.sensitivity'>Sensitivity analysis for sample size planning with the goal of Accuracy in Parameter Estimation (i.e., a narrow observed confidence interval)</h2><span id='topic+ss.aipe.R2.sensitivity'></span>

<h3>Description</h3>

<p>Given <code>Estimated.R2</code> and <code>True.R2</code>, one can perform a sensitivity analysis to determine the effect of a misspecified population 
squared multiple correlation coefficient using the Accuracy in Parameter Estimation (AIPE) approach to sample size planning. The function
evaluates the effect of a misspecified <code>True.R2</code> on the width of obtained confidence intervals. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ss.aipe.R2.sensitivity(True.R2 = NULL, Estimated.R2 = NULL, w = NULL, 
p = NULL, Random.Predictors=TRUE, Selected.N=NULL, 
degree.of.certainty = NULL, assurance=NULL, certainty=NULL, 
conf.level = 0.95, Generate.Random.Predictors=TRUE, rho.yx = 0.3, 
rho.xx = 0.3,  G = 10000, print.iter = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ss.aipe.R2.sensitivity_+3A_true.r2">True.R2</code></td>
<td>
<p>value of the population squared multiple correlation coefficient</p>
</td></tr>
<tr><td><code id="ss.aipe.R2.sensitivity_+3A_estimated.r2">Estimated.R2</code></td>
<td>
<p>value of the estimated (for sample size planning) squared multiple correlation coefficient</p>
</td></tr>
<tr><td><code id="ss.aipe.R2.sensitivity_+3A_w">w</code></td>
<td>
<p>full confidence interval width of interest</p>
</td></tr>
<tr><td><code id="ss.aipe.R2.sensitivity_+3A_p">p</code></td>
<td>
<p>number of predictors</p>
</td></tr>
<tr><td><code id="ss.aipe.R2.sensitivity_+3A_random.predictors">Random.Predictors</code></td>
<td>
<p>whether or not the sample size procedure and the simulation itself should be based on random (set to <code>TRUE</code>) or fixed predictors (set to <code>FALSE</code>)</p>
</td></tr>
<tr><td><code id="ss.aipe.R2.sensitivity_+3A_selected.n">Selected.N</code></td>
<td>
<p>selected sample size to use in order to determine distributional properties at a given value of sample size</p>
</td></tr>
<tr><td><code id="ss.aipe.R2.sensitivity_+3A_degree.of.certainty">degree.of.certainty</code></td>
<td>
<p>parameter to ensure confidence interval width with a specified degree of certainty</p>
</td></tr>
<tr><td><code id="ss.aipe.R2.sensitivity_+3A_assurance">assurance</code></td>
<td>
<p> an alias for <code>degree.of.certainty</code> </p>
</td></tr>
<tr><td><code id="ss.aipe.R2.sensitivity_+3A_certainty">certainty</code></td>
<td>
<p>an alias for <code>degree.of.certainty</code></p>
</td></tr>
<tr><td><code id="ss.aipe.R2.sensitivity_+3A_conf.level">conf.level</code></td>
<td>
<p>confidence interval coverage (symmetric coverage)</p>
</td></tr>
<tr><td><code id="ss.aipe.R2.sensitivity_+3A_generate.random.predictors">Generate.Random.Predictors</code></td>
<td>
<p>specify whether the simulation should be based on random (default) or fixed regressors.</p>
</td></tr>
<tr><td><code id="ss.aipe.R2.sensitivity_+3A_rho.yx">rho.yx</code></td>
<td>
<p>value of the correlation between <em>y</em> (dependent variable) and each of the <em>x</em> variables (independent variables)</p>
</td></tr>
<tr><td><code id="ss.aipe.R2.sensitivity_+3A_rho.xx">rho.xx</code></td>
<td>
<p>value of the correlation among the <em>x</em> variables (independent variables)</p>
</td></tr>
<tr><td><code id="ss.aipe.R2.sensitivity_+3A_g">G</code></td>
<td>
<p>number of generations (i.e., replications) of the simulation</p>
</td></tr>
<tr><td><code id="ss.aipe.R2.sensitivity_+3A_print.iter">print.iter</code></td>
<td>
<p>should the iteration number (between 1 and <code>G</code>) during the run of the function</p>
</td></tr>
<tr><td><code id="ss.aipe.R2.sensitivity_+3A_...">...</code></td>
<td>
<p>for modifying parameters of functions this function calls upon</p>
</td></tr>
</table>


<h3>Details</h3>

<p>When <code>Estimated.R2</code>=<code>True.R2</code>, the results are that of a simulation study when all assumptions
are satisfied. Rather than specifying <code>Estimated.R2</code>, one can specify <code>Selected.N</code> to determine the results of a particular sample size (when doing this <code>Estimated.R2</code> cannot be specified).
</p>
<p>The sample size estimation procedure technically assumes multivariate normal variables (<code>p</code>+1) with fixed predictors (<code>x</code>/indepdent variables), 
yet the function assumes random multivariate normal predictors (having a <code>p</code>+1 multivariate distribution). As Gatsonis and Sampson (1989) note in the context of statistical 
power analysis (recall this function is used in the context of precision), there is little difference in the outcome.
</p>
<p>In the behavioral, educational, and social sciences, predictor variables are almost always random, and thus <code>Random.Predictors</code> should generally be used.
<code>Random.Predictors=TRUE</code> specifies how both the sample size planning procedure and the confidence intervals are calculated based on the random predictors/regressors. The internal 
simulation generates random or fixed predictors/regressors based on whether variables predictor variables are random or fixed.
However, when <code>Random.Predictors=FALSE</code>, only the sample size planning procedure and the confidence intervals are calculated based on
the parameter. The parameter <code>Generate.Random.Predictors</code> (where the default is <code>TRUE</code> so that random predictors/regressors are generated) allows 
random or fixed predictor variables to be generated. Because the sample size planning procedure and 
the internal simulation are both specified, for purposes of sensitivity analysis random/fixed can be crossed to examine the effects of specifying sample size based on one but using it on 
data based on the other. 
</p>


<h3>Value</h3>

<table>
<tr><td><code>Results</code></td>
<td>
<p>a list containing vectors of the empirical results</p>
</td></tr>
<tr><td><code>Specifications</code></td>
<td>
<p>outputs the input specifications and required sample size</p>
</td></tr>
<tr><td><code>Summary</code></td>
<td>
<p>summary values for the results of the sensitivity analysis (simulation study)</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Ken Kelley (University of Notre Dame; <a href="mailto:KKelley@ND.Edu">KKelley@ND.Edu</a>)</p>


<h3>References</h3>

<p>Algina, J. &amp; Olejnik, S. (2000). Determining Sample Size for Accurate Estimation of the Squared
Multiple Correlation Coefficient. <em>Multivariate Behavioral Research, 35</em>, 119&ndash;136.
</p>
<p>Gatsonis, C. &amp; Sampson, A. R. (1989). Multiple Correlation: Exact power and sample size calculations. <em>Psychological Bulletin, 106</em>, 516&ndash;524.
</p>
<p>Steiger, J. H. &amp; Fouladi, R. T. (1992). R2: A computer program for interval estimation, power calculation,
and hypothesis testing for the squared multiple correlation. <em>Behavior research methods, instruments and computers, 4</em>, 581&ndash;582.
</p>
<p>Kelley, K. (2008). Sample size planning for the squared multiple correlation coefficient:
Accuracy in parameter estimation via narrow confidence intervals, <em>Multivariate Behavioral Research, 43</em>, 524&ndash;555.
</p>
<p>Kelley, K. &amp; Maxwell, S. E. (2008). Sample Size Planning with applications to multiple regression: Power and accuracy for omnibus and targeted effects. In P. Alasuuta, J. Brannen, &amp; L. Bickman (Eds.), <em>The Sage handbook of social research methods</em> (pp. 166&ndash;192). Newbury Park, CA: Sage.
</p>


<h3>See Also</h3>

<p><code>ci.R2</code>, <code>conf.limits.nct</code>, <code>ss.aipe.R2</code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Change 'G' to some large number (e.g., G=10,000)
# ss.aipe.R2.sensitivity(True.R2=.5, Estimated.R2=.4, w=.10, p=5, conf.level=0.95,
# G=25)

## End(Not run)
</code></pre>

<hr>
<h2 id='ss.aipe.rc'>Sample size necessary for the accuracy in parameter estimation approach
for an unstandardized regression coefficient of interest </h2><span id='topic+ss.aipe.rc'></span>

<h3>Description</h3>

<p>A function used to plan sample size from the accuracy in parameter estimation perspective for an unstandardized
regression coefficient of interest given the input specification.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ss.aipe.rc(Rho2.Y_X = NULL, Rho2.k_X.without.k = NULL, 
K = NULL, b.k = NULL, width, which.width = "Full", sigma.Y = 1, 
sigma.X.k = 1, RHO.XX = NULL, Rho.YX = NULL, which.predictor = NULL, 
alpha.lower = NULL, alpha.upper = NULL, conf.level = .95, 
degree.of.certainty = NULL, assurance=NULL,  certainty=NULL, 
Suppress.Statement = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ss.aipe.rc_+3A_rho2.y_x">Rho2.Y_X</code></td>
<td>
<p> Population value of the squared multiple correlation coefficient </p>
</td></tr>
<tr><td><code id="ss.aipe.rc_+3A_rho2.k_x.without.k">Rho2.k_X.without.k</code></td>
<td>
<p> Population value of the squared multiple correlation coefficient predicting the
<em>k</em>th predictor variable from the remaining <em>K</em>-1 predictor variables </p>
</td></tr>
<tr><td><code id="ss.aipe.rc_+3A_k">K</code></td>
<td>
<p> the number of predictor variables </p>
</td></tr>
<tr><td><code id="ss.aipe.rc_+3A_b.k">b.k</code></td>
<td>
<p> the regression coefficient for the <em>k</em>th predictor variable (i.e., the predictor of
interest) </p>
</td></tr>
<tr><td><code id="ss.aipe.rc_+3A_width">width</code></td>
<td>
<p> the desired width of the confidence interval </p>
</td></tr>
<tr><td><code id="ss.aipe.rc_+3A_which.width">which.width</code></td>
<td>
<p>which width (<code>"Full"</code>, <code>"Lower"</code>, or <code>"Upper"</code>) the width refers to (at 
present, only <code>"Full"</code> can be specified) </p>
</td></tr>
<tr><td><code id="ss.aipe.rc_+3A_sigma.y">sigma.Y</code></td>
<td>
<p> the population standard deviation of <em>Y</em> (i.e., the dependent variables) </p>
</td></tr>
<tr><td><code id="ss.aipe.rc_+3A_sigma.x.k">sigma.X.k</code></td>
<td>
<p> the population standard deviation of the <em>k</em>th <em>X</em> variable (i.e., the predictor variable
of interest) </p>
</td></tr>
<tr><td><code id="ss.aipe.rc_+3A_rho.xx">RHO.XX</code></td>
<td>
<p> Population correlation matrix for the <em>p</em> predictor variables </p>
</td></tr>
<tr><td><code id="ss.aipe.rc_+3A_rho.yx">Rho.YX</code></td>
<td>
<p> Population <em>K</em> length vector of correlation between the dependent variable (<em>Y</em>)
and the <em>K</em> independent variables </p>
</td></tr>
<tr><td><code id="ss.aipe.rc_+3A_which.predictor">which.predictor</code></td>
<td>
<p> identifies which of the <em>K</em> predictors is of interest </p>
</td></tr>
<tr><td><code id="ss.aipe.rc_+3A_alpha.lower">alpha.lower</code></td>
<td>
<p> Type I error rate for the lower confidence interval limit </p>
</td></tr>
<tr><td><code id="ss.aipe.rc_+3A_alpha.upper">alpha.upper</code></td>
<td>
<p> Type I error rate for the upper confidence interval limit </p>
</td></tr>
<tr><td><code id="ss.aipe.rc_+3A_conf.level">conf.level</code></td>
<td>
<p> desired level of confidence for the computed interval (i.e., 1 - the Type I error
rate) </p>
</td></tr>
<tr><td><code id="ss.aipe.rc_+3A_degree.of.certainty">degree.of.certainty</code></td>
<td>
<p> degree of certainty that the obtained confidence interval will be sufficiently narrow </p>
</td></tr>
<tr><td><code id="ss.aipe.rc_+3A_assurance">assurance</code></td>
<td>
<p> an alias for <code>degree.of.certainty</code> </p>
</td></tr>
<tr><td><code id="ss.aipe.rc_+3A_certainty">certainty</code></td>
<td>
<p>an alias for <code>degree.of.certainty</code></p>
</td></tr>
<tr><td><code id="ss.aipe.rc_+3A_suppress.statement">Suppress.Statement</code></td>
<td>
 <p><code>TRUE</code> or <code>FALSE</code> statement whether or not a sentence describing the situation defined
is printed with the necessary sample size </p>
</td></tr>
</table>


<h3>Details</h3>

<p>Not all of the arguments need to be specified, only those that provide all of the necessary information
so that the sample size can be determined for the conditions specified.
</p>


<h3>Value</h3>

<p>Returns the necessary sample size in order for the goals of accuracy in parameter estimation to be
satisfied for the confidence interval for a particular regression coefficient given the input specifications.
</p>


<h3>Note</h3>

 
<p>This function calls upon <code>ss.aipe.reg.coef</code> in MBESS but has a different naming scheme. See <code>ss.aipe.reg.coef</code> 
for more details. 
</p>


<h3>Author(s)</h3>

<p>Ken Kelley (University of Notre Dame; <a href="mailto:KKelley@ND.Edu">KKelley@ND.Edu</a>) </p>


<h3>References</h3>

 
<p>Kelley, K. &amp; Maxwel, S. E. (2003). Sample size for Multiple Regression: Obtaining regression
coefficients that are accuracy, not simply significant. <em>Psychological Methods, 8</em>, 305&ndash;321.
</p>


<h3>See Also</h3>

 <p><code>ss.aipe.reg.coef.sensitivity</code>, <code>conf.limits.nct</code>, 
</p>
<p><code>ss.aipe.reg.coef</code>, <code>ss.aipe.src</code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Exchangable correlation structure
# Rho.YX &lt;- c(.3, .3, .3, .3, .3)
# RHO.XX &lt;- rbind(c(1, .5, .5, .5, .5), c(.5, 1, .5, .5, .5), c(.5, .5, 1, .5, .5),
# c(.5, .5, .5, 1, .5), c(.5, .5, .5, .5, 1))

# ss.aipe.rc(width=.1, which.width="Full", sigma.Y=1, sigma.X=1, RHO.XX=RHO.XX,
# Rho.YX=Rho.YX, which.predictor=1, conf.level=1-.05)

# ss.aipe.rc(width=.1, which.width="Full", sigma.Y=1, sigma.X=1, RHO.XX=RHO.XX,
# Rho.YX=Rho.YX, which.predictor=1,  conf.level=1-.05, degree.of.certainty=.85)

## End(Not run)
</code></pre>

<hr>
<h2 id='ss.aipe.rc.sensitivity'> Sensitivity analysis for sample size planing from the Accuracy in Parameter
Estimation Perspective for the unstandardized regression coefficient </h2><span id='topic+ss.aipe.rc.sensitivity'></span>

<h3>Description</h3>

<p>Performs a sensitivity analysis when planning sample size from the Accuracy in Parameter Estimation
Perspective for the unstandardized regression coefficient.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ss.aipe.rc.sensitivity(True.Var.Y = NULL, True.Cov.YX = NULL, 
True.Cov.XX = NULL, Estimated.Var.Y = NULL, Estimated.Cov.YX = NULL, 
Estimated.Cov.XX = NULL, Specified.N = NULL, which.predictor = 1, 
w = NULL, Noncentral = FALSE, Standardize = FALSE, conf.level = 0.95, 
degree.of.certainty = NULL, assurance=NULL, certainty=NULL, 
G = 1000, print.iter = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ss.aipe.rc.sensitivity_+3A_true.var.y">True.Var.Y</code></td>
<td>
<p> Population variance of the dependent variable (<em>Y</em>) </p>
</td></tr>
<tr><td><code id="ss.aipe.rc.sensitivity_+3A_true.cov.yx">True.Cov.YX</code></td>
<td>
<p> Population covariances vector between the <em>p</em> predictor variables and the dependent
variable (<em>Y</em>) </p>
</td></tr>
<tr><td><code id="ss.aipe.rc.sensitivity_+3A_true.cov.xx">True.Cov.XX</code></td>
<td>
<p> Population covariance matrix of the <em>p</em> predictor variables </p>
</td></tr>
<tr><td><code id="ss.aipe.rc.sensitivity_+3A_estimated.var.y">Estimated.Var.Y</code></td>
<td>
<p> Estimated variance of the dependent variable (<em>Y</em>) </p>
</td></tr>
<tr><td><code id="ss.aipe.rc.sensitivity_+3A_estimated.cov.yx">Estimated.Cov.YX</code></td>
<td>
<p> Estimated covariances vector between the p predictor variables and the dependent
variable (<em>Y</em>) </p>
</td></tr>
<tr><td><code id="ss.aipe.rc.sensitivity_+3A_estimated.cov.xx">Estimated.Cov.XX</code></td>
<td>
<p> Estimated Population covariance matrix of the <em>p</em> predictor variables </p>
</td></tr>
<tr><td><code id="ss.aipe.rc.sensitivity_+3A_specified.n">Specified.N</code></td>
<td>
<p> Directly specified sample size (instead of using <code>Estimated.Rho.YX</code> and
<code>Estimated.RHO.XX</code>)</p>
</td></tr>
<tr><td><code id="ss.aipe.rc.sensitivity_+3A_which.predictor">which.predictor</code></td>
<td>
<p> identifies which of the <em>p</em> predictors is of interest </p>
</td></tr>
<tr><td><code id="ss.aipe.rc.sensitivity_+3A_w">w</code></td>
<td>
<p> desired confidence interval width for the regression coefficient of interest</p>
</td></tr>
<tr><td><code id="ss.aipe.rc.sensitivity_+3A_noncentral">Noncentral</code></td>
<td>
<p> specify with a <code>TRUE</code> or <code>FALSE</code> statement whether or not the noncentral approach
to sample size planning should be used </p>
</td></tr>
<tr><td><code id="ss.aipe.rc.sensitivity_+3A_standardize">Standardize</code></td>
<td>
<p> specify with a <code>TRUE</code> or <code>FALSE</code> statement whether or not the regression coefficient
will be standardized; default is <code>TRUE</code> </p>
</td></tr>
<tr><td><code id="ss.aipe.rc.sensitivity_+3A_conf.level">conf.level</code></td>
<td>
<p> desired level of confidence for the computed interval (i.e., 1 - the Type I error
rate) </p>
</td></tr>
<tr><td><code id="ss.aipe.rc.sensitivity_+3A_degree.of.certainty">degree.of.certainty</code></td>
<td>
<p> degree of certainty that the obtained confidence interval will be sufficiently narrow (i.e., the probability that the observed interval will be no larger than desired). </p>
</td></tr>
<tr><td><code id="ss.aipe.rc.sensitivity_+3A_assurance">assurance</code></td>
<td>
<p> an alias for <code>degree.of.certainty</code> </p>
</td></tr>
<tr><td><code id="ss.aipe.rc.sensitivity_+3A_certainty">certainty</code></td>
<td>
<p>an alias for <code>degree.of.certainty</code></p>
</td></tr>
<tr><td><code id="ss.aipe.rc.sensitivity_+3A_g">G</code></td>
<td>
<p> the number of generations/replication of the simulation student within the function </p>
</td></tr>
<tr><td><code id="ss.aipe.rc.sensitivity_+3A_print.iter">print.iter</code></td>
<td>
<p> specify with a <code>TRUE/FALSE</code> statement if the iteration number should be printed
as the simulation within the function runs</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Direct specification of <code>True.Rho.YX</code> and <code>True.RHO.XX</code> is necessary, even if one is interested in
a single regression coefficient, so that the covariance/correlation structure can be specified when
when the simulation student within the function runs.
</p>


<h3>Value</h3>

<table>
<tr><td><code>Results</code></td>
<td>
<p>a matrix containing the empirical results from each of the <code>G</code> replication of the
simulation</p>
</td></tr>
<tr><td><code>Specifications</code></td>
<td>
<p>a list of the input specifications and the required sample size</p>
</td></tr>
<tr><td><code>Summary.of.Results</code></td>
<td>
<p>summary values for the results of the sensitivity analysis (simulation study)
given the input specification</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Note that when <code>True.Rho.YX=Estimated.Rho.YX</code> and <code>True.RHO.XX=Estimated.RHO.XX</code>,
the results are not literally from a sensitivity analysis, rather the function performs a standard simulation
study. A simulation study can be helpful in order to determine if the sample size procedure
under or overestimates necessary sample size.
</p>
<p>See <code>ss.aipe.reg.coef.sensitivity</code> in MBESS for more details.
</p>


<h3>Author(s)</h3>

<p> Ken Kelley (University of Notre Dame; <a href="mailto:KKelley@ND.Edu">KKelley@ND.Edu</a>) </p>


<h3>References</h3>

 
<p>Kelley, K. &amp; Maxwell, S. E. (2003). Sample size for Multiple Regression: Obtaining regression
coefficients that are accuracy, not simply significant. <em>Psychological Methods, 8</em>, 305&ndash;321. </p>


<h3>See Also</h3>

<p><code>ss.aipe.reg.coef.sensitivity</code>, <code>ss.aipe.src.sensitivity</code>, 
</p>
<p><code>ss.aipe.reg.coef</code>, <code>ci.reg.coef</code> </p>

<hr>
<h2 id='ss.aipe.reg.coef'>Sample size necessary for the accuracy in parameter estimation approach for a regression coefficient of interest</h2><span id='topic+ss.aipe.reg.coef'></span>

<h3>Description</h3>

<p>A function used to plan sample size from the accuracy in parameter estimation approach for a regression coefficient of interest given the input specification.</p>


<h3>Usage</h3>

<pre><code class='language-R'>ss.aipe.reg.coef(Rho2.Y_X=NULL, Rho2.j_X.without.j=NULL, p=NULL, 
b.j=NULL, width, which.width="Full", sigma.Y=1, sigma.X=1, RHO.XX=NULL, 
Rho.YX=NULL, which.predictor=NULL, Noncentral=FALSE, alpha.lower=NULL,
alpha.upper=NULL, conf.level=.95, degree.of.certainty=NULL, assurance=NULL, 
certainty=NULL, Suppress.Statement=FALSE)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ss.aipe.reg.coef_+3A_rho2.y_x">Rho2.Y_X</code></td>
<td>
<p>Population value of the squared multiple correlation coefficient</p>
</td></tr>
<tr><td><code id="ss.aipe.reg.coef_+3A_rho2.j_x.without.j">Rho2.j_X.without.j</code></td>
<td>
<p>Population value of the squared multiple correlation coefficient predicting the <em>j</em>th predictor variable from the remaining <em>p</em>-1 predictor variables</p>
</td></tr>
<tr><td><code id="ss.aipe.reg.coef_+3A_p">p</code></td>
<td>
<p>the number of predictor variables</p>
</td></tr>
<tr><td><code id="ss.aipe.reg.coef_+3A_b.j">b.j</code></td>
<td>
<p>the regression coefficient for the <em>j</em>th predictor variable (i.e., the predictor of interest)</p>
</td></tr>
<tr><td><code id="ss.aipe.reg.coef_+3A_width">width</code></td>
<td>
<p>the desired width of the confidence interval</p>
</td></tr>
<tr><td><code id="ss.aipe.reg.coef_+3A_which.width">which.width</code></td>
<td>
<p>which width (<code>"Full"</code>, <code>"Lower"</code>, or <code>"Upper"</code>) the width refers 
to (at present, only <code>"Full"</code> can be specified)</p>
</td></tr>
<tr><td><code id="ss.aipe.reg.coef_+3A_sigma.y">sigma.Y</code></td>
<td>
<p>the population standard deviation of <em>Y</em> (i.e., the dependent variables)</p>
</td></tr>
<tr><td><code id="ss.aipe.reg.coef_+3A_sigma.x">sigma.X</code></td>
<td>
<p>the population standard deviation of the <em>j</em>th <em>X</em> variable (i.e., the predictor variable of interest)</p>
</td></tr>
<tr><td><code id="ss.aipe.reg.coef_+3A_rho.xx">RHO.XX</code></td>
<td>
<p>Population correlation matrix for the <code>p</code> predictor variables</p>
</td></tr>
<tr><td><code id="ss.aipe.reg.coef_+3A_rho.yx">Rho.YX</code></td>
<td>
<p>Population <code>p</code> length vector of correlation between the dependent variable (<em>Y</em>) and the <code>p</code> independent variables</p>
</td></tr>
<tr><td><code id="ss.aipe.reg.coef_+3A_which.predictor">which.predictor</code></td>
<td>
<p>identifies which of the <code>p</code> predictors is of interest</p>
</td></tr>
<tr><td><code id="ss.aipe.reg.coef_+3A_noncentral">Noncentral</code></td>
<td>
<p>specify with a <code>TRUE</code> or <code>FALSE</code> statement whether or not the noncentral approach to sample size planning should be used</p>
</td></tr>
<tr><td><code id="ss.aipe.reg.coef_+3A_alpha.lower">alpha.lower</code></td>
<td>
<p>Type I error rate for the lower confidence interval limit</p>
</td></tr>
<tr><td><code id="ss.aipe.reg.coef_+3A_alpha.upper">alpha.upper</code></td>
<td>
<p>Type I error rate for the upper confidence interval limit</p>
</td></tr>
<tr><td><code id="ss.aipe.reg.coef_+3A_conf.level">conf.level</code></td>
<td>
<p>desired level of confidence for the computed interval (i.e., 1 - the Type I error rate)</p>
</td></tr>
<tr><td><code id="ss.aipe.reg.coef_+3A_degree.of.certainty">degree.of.certainty</code></td>
<td>
<p>degree of certainty that the obtained confidence interval will be sufficiently narrow</p>
</td></tr>
<tr><td><code id="ss.aipe.reg.coef_+3A_assurance">assurance</code></td>
<td>
<p> an alias for <code>degree.of.certainty</code> </p>
</td></tr>
<tr><td><code id="ss.aipe.reg.coef_+3A_certainty">certainty</code></td>
<td>
<p>an alias for <code>degree.of.certainty</code></p>
</td></tr>
<tr><td><code id="ss.aipe.reg.coef_+3A_suppress.statement">Suppress.Statement</code></td>
<td>
<p><code>TRUE</code>/<code>FALSE</code> statement whether or not a sentence describing the situation defined is printed with the necessary sample size</p>
</td></tr></table>


<h3>Details</h3>

<p>Not all of the arguments need to be specified, only those that provide all of the necessary information so that the
sample size can be determined for the conditions specified.</p>


<h3>Value</h3>

<p>Returns the necessary sample size in order for the goals of
accuracy in parameter estimation to be satisfied for the confidence
interval for a particular regression coefficient given the input
specifications.</p>


<h3>Author(s)</h3>

<p>Ken Kelley (University of Notre Dame; <a href="mailto:KKelley@ND.Edu">KKelley@ND.Edu</a>)</p>


<h3>References</h3>

<p>Kelley, K. &amp; Maxwel, S. E. (2003). Sample size for Multiple Regression: Obtaining regression coefficients that are accurate, not simply significant. 
<em>Psychological Methods, 8</em>, 305&ndash;321.</p>


<h3>See Also</h3>

<p><code>ss.aipe.reg.coef.sensitivity</code>, <code>conf.limits.nct</code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Exchangable correlation structure
# Rho.YX &lt;- c(.3, .3, .3, .3, .3)
# RHO.XX &lt;- rbind(c(1, .5, .5, .5, .5), c(.5, 1, .5, .5, .5), c(.5, .5, 1, .5, .5), 
# c(.5, .5, .5, 1, .5), c(.5, .5, .5, .5, 1))
# ss.aipe.reg.coef(width=.1, which.width="Full", sigma.Y=1, sigma.X=1, RHO.XX=RHO.XX,
# Rho.YX=Rho.YX, which.predictor=1, Noncentral=FALSE, conf.level=1-.05, 
# degree.of.certainty=NULL, Suppress.Statement=FALSE)

# ss.aipe.reg.coef(width=.1, which.width="Full", sigma.Y=1, sigma.X=1, RHO.XX=RHO.XX,
# Rho.YX=Rho.YX, which.predictor=1, Noncentral=FALSE, conf.level=1-.05, 
# degree.of.certainty=.85, Suppress.Statement=FALSE)

# ss.aipe.reg.coef(width=.1, which.width="Full", sigma.Y=1, sigma.X=1, RHO.XX=RHO.XX,
# Rho.YX=Rho.YX, which.predictor=1, Noncentral=TRUE, conf.level=1-.05,
# degree.of.certainty=NULL, Suppress.Statement=FALSE)

# ss.aipe.reg.coef(width=.1, which.width="Full", sigma.Y=1, sigma.X=1, RHO.XX=RHO.XX, 
# Rho.YX=Rho.YX, which.predictor=1, Noncentral=TRUE, conf.level=1-.05, 
# degree.of.certainty=.85, Suppress.Statement=FALSE)
## End(Not run)
</code></pre>

<hr>
<h2 id='ss.aipe.reg.coef.sensitivity'>Sensitivity analysis for sample size planning from the Accuracy in Parameter Estimation Perspective for the (standardized and unstandardized) regression coefficient</h2><span id='topic+ss.aipe.reg.coef.sensitivity'></span>

<h3>Description</h3>

<p>Performs a sensitivity analysis when planning sample size from the Accuracy in Parameter Estimation Perspective for the standardized or unstandardized regression coefficient.</p>


<h3>Usage</h3>

<pre><code class='language-R'>ss.aipe.reg.coef.sensitivity(True.Var.Y = NULL, True.Cov.YX = NULL,
True.Cov.XX = NULL, Estimated.Var.Y = NULL, Estimated.Cov.YX = NULL,
Estimated.Cov.XX = NULL, Specified.N = NULL, which.predictor = 1, 
w = NULL, Noncentral = FALSE, Standardize = FALSE, conf.level = 0.95, 
degree.of.certainty = NULL, assurance=NULL, certainty=NULL,
 G = 1000, print.iter = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ss.aipe.reg.coef.sensitivity_+3A_true.var.y">True.Var.Y</code></td>
<td>
<p>Population variance of the dependent variable (<em>Y</em>)</p>
</td></tr>
<tr><td><code id="ss.aipe.reg.coef.sensitivity_+3A_true.cov.yx">True.Cov.YX</code></td>
<td>
<p>Population covariances vector between the <code>p</code> predictor variables and the dependent variable (<em>Y</em>)</p>
</td></tr>
<tr><td><code id="ss.aipe.reg.coef.sensitivity_+3A_true.cov.xx">True.Cov.XX</code></td>
<td>
<p>Population covariance matrix of the <code>p</code> predictor variables</p>
</td></tr>
<tr><td><code id="ss.aipe.reg.coef.sensitivity_+3A_estimated.var.y">Estimated.Var.Y</code></td>
<td>
<p>Estimated variance of the dependent variable (<em>Y</em>)</p>
</td></tr>
<tr><td><code id="ss.aipe.reg.coef.sensitivity_+3A_estimated.cov.yx">Estimated.Cov.YX</code></td>
<td>
<p>Estimated covariances vector between the <code>p</code> predictor variables and the dependent variable (<code>Y</code>)</p>
</td></tr>
<tr><td><code id="ss.aipe.reg.coef.sensitivity_+3A_estimated.cov.xx">Estimated.Cov.XX</code></td>
<td>
<p>Estimated Population covariance matrix of the <code>p</code> predictor variables</p>
</td></tr>
<tr><td><code id="ss.aipe.reg.coef.sensitivity_+3A_specified.n">Specified.N</code></td>
<td>
<p>Directly specified sample size (instead of using <code>Estimated.Rho.YX</code> and <code>Estimated.RHO.XX</code>)</p>
</td></tr>
<tr><td><code id="ss.aipe.reg.coef.sensitivity_+3A_which.predictor">which.predictor</code></td>
<td>
<p>identifies which of the <em>p</em> predictors is of interest</p>
</td></tr>
<tr><td><code id="ss.aipe.reg.coef.sensitivity_+3A_w">w</code></td>
<td>
<p>desired confidence interval width for the regression coefficient of interest</p>
</td></tr>
<tr><td><code id="ss.aipe.reg.coef.sensitivity_+3A_noncentral">Noncentral</code></td>
<td>
<p>specify with a <code>TRUE</code> or <code>FALSE</code> statement whether or not the noncentral approach to sample size planning should be used</p>
</td></tr>
<tr><td><code id="ss.aipe.reg.coef.sensitivity_+3A_standardize">Standardize</code></td>
<td>
<p>specify with a <code>TRUE</code> or <code>FALSE</code> statement whether or not the regression coefficient will be standardized</p>
</td></tr>
<tr><td><code id="ss.aipe.reg.coef.sensitivity_+3A_conf.level">conf.level</code></td>
<td>
<p>desired level of confidence for the computed interval (i.e., 1 - the Type I error rate)</p>
</td></tr>
<tr><td><code id="ss.aipe.reg.coef.sensitivity_+3A_degree.of.certainty">degree.of.certainty</code></td>
<td>
<p>degree of certainty that the obtained confidence interval will be sufficiently narrow</p>
</td></tr>
<tr><td><code id="ss.aipe.reg.coef.sensitivity_+3A_assurance">assurance</code></td>
<td>
<p> an alias for <code>degree.of.certainty</code> </p>
</td></tr>
<tr><td><code id="ss.aipe.reg.coef.sensitivity_+3A_certainty">certainty</code></td>
<td>
<p>an alias for <code>degree.of.certainty</code></p>
</td></tr>
<tr><td><code id="ss.aipe.reg.coef.sensitivity_+3A_g">G</code></td>
<td>
<p>the number of generations/replication of the simulation student within the function</p>
</td></tr>
<tr><td><code id="ss.aipe.reg.coef.sensitivity_+3A_print.iter">print.iter</code></td>
<td>
<p>specify with a <code>TRUE</code>/<code>FALSE</code> statement if the iteration number should be printed as the simulation within the function runts</p>
</td></tr>
</table>


<h3>Details</h3>

<p> Direct specification of <code>True.Rho.YX</code> and <code>True.RHO.XX</code> is necessary, even if one is interested in a single regression
coefficient, so that the covariance/correlation structure can be specified when the simulation student within the function runs.</p>


<h3>Value</h3>

<table>
<tr><td><code>Results</code></td>
<td>
<p>a matrix containing the empirical results from each of the <code>G</code> replications of the simulation</p>
</td></tr>
<tr><td><code>Specifications</code></td>
<td>
<p>a list of the input specifications and the required sample size</p>
</td></tr>
<tr><td><code>Summary.of.Results</code></td>
<td>
<p>summary values for the results of the sensitivity analysis (simulation study) given the input specification</p>
</td></tr></table>


<h3>Note</h3>

<p>Note that when <code>True.Rho.YX</code>=<code>Estimated.Rho.YX</code> and <code>True.RHO.XX</code>=<code>Estimated.RHO.XX</code>, the results are not
literally from a sensitivity analysis, rather the function performs a standard simulation study. A simulation study 
can be helpful in order to determine if the sample size procedure under or overestimates necessary sample size.</p>


<h3>Author(s)</h3>

<p>Ken Kelley (University of Notre Dame; <a href="mailto:KKelley@ND.Edu">KKelley@ND.Edu</a>)</p>


<h3>References</h3>

<p>Kelley, K. &amp; Maxwell, S. E. (2003). Sample size for Multiple Regression: Obtaining regression coefficients that are accuracy, not simply significant. <em>Psychological Methods, 8</em>, 305&ndash;321.</p>


<h3>See Also</h3>

<p><code>ss.aipe.reg.coef</code>, <code>ci.reg.coef</code></p>

<hr>
<h2 id='ss.aipe.reliability'> Sample Size Planning for Accuracy in Parameter Estimation for Reliability Coefficients.</h2><span id='topic+ss.aipe.reliability'></span>

<h3>Description</h3>

<p>This function determines a necessary sample size so that the expected confidence interval width for the alpha coefficient or omega coefficient
is sufficiently narrow (when assurance=NULL) or so that the obtained confidence interval is no larger than the value specified with some desired degree of certainty (i.e., a probability that the obtained width is less than the specified width; assurance=.85). This function calculates coefficient alpha based on 
McDonald's (1999) formula for coefficient alpha, also known as Guttman-Cronbach alpha. It also uses coefficient omega from McDonald (1999). When the 'Parallel' or 'True Score' model is used, coefficient alpha is calculated. When the 'Congeneric' model is used, coefficient omega is calculated.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ss.aipe.reliability(model = NULL, type = NULL, width = NULL, S = NULL, 
conf.level = 0.95, assurance = NULL, data = NULL, i = NULL, cor.est = NULL, 
lambda = NULL, psi.square = NULL, initial.iter = 500, 
final.iter = 5000, start.ss = NULL, verbose=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ss.aipe.reliability_+3A_model">model</code></td>
<td>
<p> the type of measurement model (e.g., <code>"parallel items"</code>, <code>"true-score equivalent"</code>, or 
<code>"congeneric model"</code>) for a homogeneous single common factor test </p>
</td></tr>
<tr><td><code id="ss.aipe.reliability_+3A_type">type</code></td>
<td>
<p>the type of method to base the formation of the confidence interval on, either the <code>"Factor Analytic"</code> (McDonald, 1999) or <code>"Normal Theory"</code> (van Zyl, Neudecker, &amp; Nel, 2000) </p>
</td></tr>
<tr><td><code id="ss.aipe.reliability_+3A_width">width</code></td>
<td>
<p> the desired full width of the confidence interval</p>
</td></tr>
<tr><td><code id="ss.aipe.reliability_+3A_s">S</code></td>
<td>
<p> a symmetric covariance matrix</p>
</td></tr>
<tr><td><code id="ss.aipe.reliability_+3A_conf.level">conf.level</code></td>
<td>
<p> the desired confidence interval coverage, (i.e., 1- Type I error rate) </p>
</td></tr>
<tr><td><code id="ss.aipe.reliability_+3A_assurance">assurance</code></td>
<td>
<p> parameter to ensure that the obtained confidence interval width is narrower than the desired width with a specificied degree of certainty</p>
</td></tr>
<tr><td><code id="ss.aipe.reliability_+3A_data">data</code></td>
<td>
<p>the data set that the reliability coefficient is obtained from</p>
</td></tr>
<tr><td><code id="ss.aipe.reliability_+3A_i">i</code></td>
<td>
<p> number of items </p>
</td></tr>
<tr><td><code id="ss.aipe.reliability_+3A_cor.est">cor.est</code></td>
<td>
<p> the estimated inter-item correlation </p>
</td></tr>
<tr><td><code id="ss.aipe.reliability_+3A_lambda">lambda</code></td>
<td>
<p> the vector of population factor loadings</p>
</td></tr>
<tr><td><code id="ss.aipe.reliability_+3A_psi.square">psi.square</code></td>
<td>
<p> the vector of population error variances</p>
</td></tr>
<tr><td><code id="ss.aipe.reliability_+3A_initial.iter">initial.iter</code></td>
<td>
<p> the number of initial iterations or generations/replications of the simulation study within the function</p>
</td></tr>
<tr><td><code id="ss.aipe.reliability_+3A_final.iter">final.iter</code></td>
<td>
<p> the number of final iterations or generations/replications of the simulation study </p>
</td></tr>
<tr><td><code id="ss.aipe.reliability_+3A_start.ss">start.ss</code></td>
<td>
<p> the initial sample size to start the simulation at </p>
</td></tr>
<tr><td><code id="ss.aipe.reliability_+3A_verbose">verbose</code></td>
<td>
<p>shows extra information one the current sample size and current level of assurance; helpful if the function gets stuck in a long iterative process</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Use <code>verbose=TRUE</code> if the function is taking a very long time to provide an answer. 
</p>


<h3>Value</h3>

<table>
<tr><td><code>Required.Sample.Size</code></td>
<td>
<p>the necessary sample size</p>
</td></tr>
<tr><td><code>width</code></td>
<td>
<p>the specified full width of the confidence interval</p>
</td></tr>
<tr><td><code>specified.assurance</code></td>
<td>
<p>the specified degree of certainty</p>
</td></tr>
<tr><td><code>empirical.assurance</code></td>
<td>
<p>the empirical assurance based on the necessary sample size returned</p>
</td></tr>
<tr><td><code>final.iter</code></td>
<td>
<p>the specified number of iterations in the simulation study</p>
</td></tr>
</table>


<h3>Warning </h3>

<p>In some conditions, you may receive a warning, such as &quot;<code>In sem.default(ram = ram, S = S, N = N, param.names = pars, var.names = vars,; Could not compute QR decomposition of Hessian. Optimization probably did not converge.</code>&quot; 
This indicates that the model likely did not converge. In certain conditions this may occur because the model is not being fit well due to small sample size, a low number of iterations, or a poorly behaved covariance matrix.  </p>


<h3>Note</h3>

<p> Not all of the items can be entered into the function to represent the population values. For example, either 'data' can be used, or <code>S</code>, or  <code>i</code>, <code>cor.est</code>, and <code>psi.square</code>, or <code>i</code>, <code>lambda</code>, and <code>psi.square</code>. With a
large number of iterations (<code>final.iter</code>) this function may take considerable time.</p>


<h3>Author(s)</h3>

<p>Leann J. Terry (Indiana University; <a href="mailto:ljterry@Indiana.Edu">ljterry@Indiana.Edu</a>);
Ken Kelley (University of Notre Dame; <a href="mailto:KKelley@ND.Edu">KKelley@ND.Edu</a>)</p>


<h3>References</h3>

<p> McDonald, R. P. (1999). <em>Test theory: A unified approach</em>. Mahwah, New Jersey: Lawrence 
Erlbaum Associates, Publishers.
</p>
<p>van Zyl, J. M., Neudecker, H., &amp; Nel, D. G. (2000). On the distribution of the maximum likelihood estimator 
of Cronbach's alpha. <em>Psychometrika, 65</em> (3), 271&ndash;280. </p>


<h3>See Also</h3>

 <p><code><a href="#topic+CFA.1">CFA.1</a></code>; <code><a href="sem.html#topic+sem">sem</a></code>; <code><a href="#topic+ci.reliability">ci.reliability</a></code>;  </p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
ss.aipe.reliability (model='Parallel', type='Normal Theory', width=.1, i=6, 
                     cor.est=.3, psi.square=.2, conf.level=.95, assurance=NULL, initial.iter=500, 
                     final.iter=5000)

# Same as above but now 'assurance' is used. 
ss.aipe.reliability (model='Parallel', type='Normal Theory', width=.1, i=6, 
cor.est=.3, psi.square=.2, conf.level=.95, assurance=.85, initial.iter=500, 
final.iter=5000)


# Similar to the above but now the "True Score" model is used. Note how the psi.square changes 
# from a scalar to a vector of length i (number of items). 
# Also note, however, that cor.est is a single value (due to the true-score model specified)
ss.aipe.reliability (model='True Score', type='Normal Theory', width=.1, i=5, 
                     cor.est=.3, psi.square=c(.2, .3, .3, .2, .3), conf.level=.95, 
                     assurance=.85, initial.iter=500, final.iter=5000)
                     
ss.aipe.reliability (model='True Score', type='Normal Theory', width=.1, i=5, 
                     cor.est=.3, psi.square=c(.2, .3, .3, .2, .3), conf.level=.95, 
                     assurance=.85, initial.iter=500, final.iter=5000)                 

# Now, a congeneric model is used with the factor analytic appraoch. This is likely the 
# most realistic scenario (and maps onto the ideas of Coefficient Omega). 
ss.aipe.reliability (model='Congeneric', type='Factor Analytic', width=.1, i=5, 
lambda=c(.4, .4, .3, .3, .5), psi.square=c(.2, .4, .3, .3, .2), conf.level=.95, 
assurance=.85, initial.iter=1000, final.iter=5000)

# Now, the presumed population matrix among the items is used. 
Pop.Mat&lt;-rbind(c(1.0000000, 0.3813850, 0.4216370, 0.3651484, 0.4472136), 
c(0.3813850, 1.0000000, 0.4020151, 0.3481553, 0.4264014), c(0.4216370, 
0.4020151, 1.0000000, 0.3849002, 0.4714045), c(0.3651484, 0.3481553, 
0.3849002, 1.0000000, 0.4082483), c(0.4472136, 0.4264014, 0.4714045, 
0.4082483, 1.0000000))

ss.aipe.reliability (model='True Score', type='Normal Theory', width=.15, 
S=Pop.Mat, conf.level=.95, assurance=.85, initial.iter=1000, final.iter=5000) 


## End(Not run)
</code></pre>

<hr>
<h2 id='ss.aipe.rmsea'> Sample size planning for RMSEA in SEM</h2><span id='topic+ss.aipe.rmsea'></span>

<h3>Description</h3>

<p>Sample size planning for the population root mean square error of approximation (RMSEA) from the accuracy in parameter estimation (AIPE) perspective. The sample size is planned so that the expected width of a confidence interval for the population RMSEA is no larger than desired.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ss.aipe.rmsea(RMSEA, df, width, conf.level = 0.95)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ss.aipe.rmsea_+3A_rmsea">RMSEA</code></td>
<td>
<p>the input RMSEA value </p>
</td></tr>
<tr><td><code id="ss.aipe.rmsea_+3A_df">df</code></td>
<td>
<p>degrees of freedom of the model</p>
</td></tr>
<tr><td><code id="ss.aipe.rmsea_+3A_width">width</code></td>
<td>
<p>desired confidence interval width</p>
</td></tr>
<tr><td><code id="ss.aipe.rmsea_+3A_conf.level">conf.level</code></td>
<td>
<p>desired confidence level (e.g., .90, .95, .99, etc.)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns the necessary total sample size in order to achieve the desired 
degree of accuracy (i.e., the sufficiently narrow confidence interval). 
</p>


<h3>Author(s)</h3>

<p>Ken Kelley (University of Notre Dame; <a href="mailto:KKelley@ND.Edu">KKelley@ND.Edu</a>) and Keke Lai</p>


<h3>See Also</h3>

 <p><code><a href="#topic+ci.rmsea">ci.rmsea</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# ss.aipe.rmsea(RMSEA=.035, df=50, width=.05, conf.level=.95)

## End(Not run)
</code></pre>

<hr>
<h2 id='ss.aipe.rmsea.sensitivity'>a priori Monte Carlo simulation for sample size planning for RMSEA in SEM
</h2><span id='topic+ss.aipe.rmsea.sensitivity'></span>

<h3>Description</h3>

<p>Conduct a priori Monte Carlo simulation to empirically study the effects of (mis)specifications of input information on the calculated sample size. The sample size is planned so that the expected width of a confidence interval for the population RMSEA is no larger than desired. Random data are generated from the true covariance matrix but fit to the proposed model, whereas sample size is calculated based on the input covariance matrix and proposed model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ss.aipe.rmsea.sensitivity(width, model, Sigma, N=NULL, 
conf.level=0.95, G=200, save.file="sim.results.txt", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ss.aipe.rmsea.sensitivity_+3A_width">width</code></td>
<td>
<p>desired confidence interval width for the model parameter of interest </p>
</td></tr>
<tr><td><code id="ss.aipe.rmsea.sensitivity_+3A_model">model</code></td>
<td>
<p> the model the researcher proposes, may or may not be the true model. This argument should be an RAM (reticular action model; e.g., McArdle &amp; McDonald, 1984) specification of a structural equation model, and should be of class <code>mod</code>. The model is specified in the same manner as does the <code><a href="sem.html#topic+sem">sem</a></code> package; see <code><a href="sem.html#topic+sem">sem</a></code> and <code><a href="sem.html#topic+specify.model">specify.model</a></code> for detailed documentation about model specifications in the RAM notation.</p>
</td></tr>
<tr><td><code id="ss.aipe.rmsea.sensitivity_+3A_sigma">Sigma</code></td>
<td>
<p>the true population covariance matrix, which will be used to generate random data for the simulation study. The row names and column names of <code>Sigma</code> should be the same as the manifest variables in <code>model</code>.
</p>
</td></tr>
<tr><td><code id="ss.aipe.rmsea.sensitivity_+3A_n">N</code></td>
<td>
<p>if <code>N</code> is specified, random sample of the specified <code>N</code> size will be generated. Otherwise the sample size is calculated with the sample size planning method with the goal that the expected width of a confidence interval for population RMSEA is no larger than desired.
</p>
</td></tr>
<tr><td><code id="ss.aipe.rmsea.sensitivity_+3A_conf.level">conf.level</code></td>
<td>
<p> confidence level (i.e., 1- Type I error rate)</p>
</td></tr>
<tr><td><code id="ss.aipe.rmsea.sensitivity_+3A_g">G</code></td>
<td>
<p>number of replications in the Monte Carlo simulation </p>
</td></tr>
<tr><td><code id="ss.aipe.rmsea.sensitivity_+3A_save.file">save.file</code></td>
<td>
<p>the name of the file that simulation results will be saved to</p>
</td></tr>
<tr><td><code id="ss.aipe.rmsea.sensitivity_+3A_...">...</code></td>
<td>
<p>  allows one to potentially include parameter values for inner functions</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function implements the sample size planning methods proposed in Kelley and Lai (2010). It depends on the 
function <code><a href="sem.html#topic+sem">sem</a></code> in the <code>sem</code> package to fit the proposed model to random data, and uses the same notation to specify SEM 
models as does <code><a href="sem.html#topic+sem">sem</a></code>. Please refer to <code><a href="sem.html#topic+sem">sem</a></code> for more detailed documentation 
about model specifications, the RAM notation, and model fitting techniques. For technical discussion 
on how to obtain the model implied covariance matrix in the RAM notation given model parameters, see McArdle and McDonald (1984)
</p>


<h3>Value</h3>

<table>
<tr><td><code>successful.replication</code></td>
<td>
<p>the number of successful replications</p>
</td></tr>
<tr><td><code>w</code></td>
<td>
<p>the <code>G</code> random confidence interval widths </p>
</td></tr>
<tr><td><code>RMSEA.hat</code></td>
<td>
<p>the <code>G</code> estimated RMSEA values based on the <code>G</code> random samples </p>
</td></tr>
<tr><td><code>sample.size</code></td>
<td>
<p>the sample size calculated </p>
</td></tr>
<tr><td><code>df</code></td>
<td>
<p>degrees of freedom of the proposed model</p>
</td></tr>
<tr><td><code>RMSEA.pop</code></td>
<td>
<p>the input RMSEA value that is used to calculated the necessary sample size</p>
</td></tr>
<tr><td><code>desired.width</code></td>
<td>
<p>desired confidence interval width</p>
</td></tr>
<tr><td><code>mean.width</code></td>
<td>
<p>mean of the random confidence interval widths</p>
</td></tr>
<tr><td><code>median.width</code></td>
<td>
<p>median of the random confidence interval widths</p>
</td></tr>
<tr><td><code>assurance</code></td>
<td>
<p>the proportion of confidence interval widths narrower than desired</p>
</td></tr> 
<tr><td><code>quantile.width</code></td>
<td>
<p>99, 97, 95, 90, 80, 70, and 60 percentiles of the random confidence interval widths</p>
</td></tr>
<tr><td><code>alpha.upper</code></td>
<td>
<p>the upper empirical Type I error rate</p>
</td></tr> 
<tr><td><code>alpha.lower</code></td>
<td>
<p>the lower empirical Type I error rate</p>
</td></tr>
<tr><td><code>alpha</code></td>
<td>
<p>total empirical Type I error rate</p>
</td></tr>  
<tr><td><code>conf.level</code></td>
<td>
<p>confidence level</p>
</td></tr>
<tr><td><code>sim.results.txt</code></td>
<td>
<p>a text file that saves the simulation results; it updates after each replication. 'sim.results.txt' is the default file name</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Sometimes this function jumps out of the loop before it finishes the simulation. The reason is because the 
<code><a href="sem.html#topic+sem">sem</a></code> function that this function calls to fit the model fails to converge when searching for
maximum likelihood estimates of model parameters. Since the results in previous replications are saved, the
user can start this function again, and specify the number of replications (i.e., <code>G</code>) to be the desired
total number of replications minus the number of previous successful replications.
</p>


<h3>Author(s)</h3>

<p>Keke Lai (University of California &ndash; Merced) and Ken Kelley (University of Notre Dame; <a href="mailto:KKelley@ND.Edu">KKelley@ND.Edu</a>)
</p>


<h3>References</h3>

<p>Cudeck, R., &amp; Browne, M. W. (1992). Constructing a covariance matrix that yields a specified minimizer and a specified minimum discrepancy function value. <em>Psychometrika, 57</em>, 357&ndash;369. 
</p>
<p>Fox, J. (2006). Structural equation modeling with the sem package in R. <em>Structural Equation Modeling, 13</em>, 465&ndash;486.
</p>
<p>Kelley, K., &amp; Lai, K. (2010). Accuracy in parameter estimation for the root mean square of approximation: Sample size planning for narrow confidence intervals. <em>Manuscript under review</em>.
</p>
<p>McArdle, J. J., &amp; McDonald, R. P. (1984). Some algebraic properties of the reticular action model. <em>British Journal of Mathematical and Statistical Psychology, 37</em>, 234&ndash;251.
</p>


<h3>See Also</h3>

<p><code><a href="sem.html#topic+sem">sem</a></code>; <code><a href="sem.html#topic+specify.model">specify.model</a></code>; <code><a href="#topic+ss.aipe.rmsea">ss.aipe.rmsea</a></code>; <code><a href="#topic+theta.2.Sigma.theta">theta.2.Sigma.theta</a></code>; <code><a href="#topic+Sigma.2.SigmaStar">Sigma.2.SigmaStar</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
#########################
EXAMPLE 1 
######################### 
# To replicate the simulation in the first panel, second column of 
# Table 2 (i.e., population RMSEA=0.0268, df=23, desired width=0.02) 
# in Lai and Kelley (2010), the following steps can be used.

## STEP 1: Obtain the (correct) population covariance matrix implied by Model 2
# This requires the model and its population model parameter values.
library(MASS)
library(sem)

# Specify Model 2 in the RAM notation
model.2&lt;-specifyModel()
xi1 -&gt; y1, lambda1, 1
xi1 -&gt; y2, NA, 1
xi1 -&gt; y3, lambda2, 1
xi1 -&gt; y4, lambda3, 0.3
eta1 -&gt; y4, lambda4, 1
eta1 -&gt; y5, NA, 1
eta1 -&gt; y6, lambda5, 1
eta1 -&gt; y7, lambda6, 0.3
eta2 -&gt; y6, lambda7, 0.3
eta2 -&gt; y7, lambda8, 1
eta2 -&gt; y8, NA, 1
eta2 -&gt; y9, lambda9, 1
xi1 -&gt; eta1, gamma11, 0.6
eta1 -&gt; eta2, beta21, 0.6 
xi1 &lt;-&gt; xi1, phi11, 0.49
eta1 &lt;-&gt; eta1, psi11, 0.3136
eta2 &lt;-&gt; eta2, psi22, 0.3136
y1 &lt;-&gt; y1, delta1, 0.51
y2 &lt;-&gt; y2, delta2, 0.51
y3 &lt;-&gt; y3, delta3, 0.51
y4 &lt;-&gt; y4, delta4, 0.2895
y5 &lt;-&gt; y5, delta5, 0.51
y6 &lt;-&gt; y6, delta6, 0.2895
y7 &lt;-&gt; y7, delta7, 0.2895
y8 &lt;-&gt; y8, delta8, 0.51
y9 &lt;-&gt; y9, delta9, 0.51


# To inspect the specified model
model.2

# Specify model parameter values
theta &lt;- c(1, 1, 0.3, 1,1, 0.3, 0.3, 1, 1, 0.6, 0.6,
0.49, 0.3136, 0.3136, 0.51, 0.51, 0.51, 0.2895, 0.51, 0.2895, 0.2895, 0.51, 0.51)

names(theta) &lt;- c("lambda1","lambda2","lambda3",
"lambda4","lambda5","lambda6","lambda7","lambda8","lambda9",
"gamma11", "beta21",
"phi11", "psi11", "psi22", 
"delta1","delta2","delta3","delta4","delta5","delta6","delta7",
"delta8","delta9")

res&lt;-theta.2.Sigma.theta(model=model.2, theta=theta, 
latent.vars=c("xi1", "eta1","eta2"))

Sigma.theta &lt;- res$Sigma.theta
# Then 'Sigma.theta' is the (true) population covariance matrix

## STEP 2: Create a misspecified model
# The following model is misspecified in the same way as did Lai and Kelley (2010)
# with the goal to obtain a relatively small population RMSEA

model.2.mis&lt;-specifyModel()
xi1 -&gt; y1, lambda1, 1
xi1 -&gt; y2, NA, 1
xi1 -&gt; y3, lambda2, 1
xi1 -&gt; y4, lambda3, 0.3
eta1 -&gt; y4, lambda4, 1
eta1 -&gt; y5, NA, 1
eta1 -&gt; y6, lambda5, 0.96
eta2 -&gt; y6, lambda7, 0.33
eta2 -&gt; y7, lambda8, 1.33
eta2 -&gt; y8, NA, 1
eta2 -&gt; y9, lambda9, 1
xi1 -&gt; eta1, gamma11, 0.6
eta1 -&gt; eta2, beta21, 0.65 
xi1 &lt;-&gt; xi1, phi11, 0.49
eta1 &lt;-&gt; eta1, psi11, 0.3136
eta2 &lt;-&gt; eta2, psi22, 0.23
y1 &lt;-&gt; y1, delta1, 0.51
y2 &lt;-&gt; y2, delta2, 0.51
y3 &lt;-&gt; y3, delta3, 0.51
y4 &lt;-&gt; y4, delta4, 0.2895
y5 &lt;-&gt; y5, delta5, 0.51
y6 &lt;-&gt; y6, delta6, 0.29
y7 &lt;-&gt; y7, delta7, 0.22
y8 &lt;-&gt; y8, delta8, 0.56
y9 &lt;-&gt; y9, delta9, 0.56


# To verify the population RMSEA of this misspecified model
fit&lt;-sem(ram=model.2.mis, S=Sigma.theta, N=1000000)
summary(fit)$RMSEA

## STEP 3: Conduct the simulation
# The number of replications is set to a very small value just to demonstrate
# and save time. Real simulation studies require a larger number (e.g., 500, 1,000)

ss.aipe.rmsea.sensitivity(width=0.02, model=model.2.mis, Sigma=Sigma.theta, G=10)

## STEP 3+: In cases where this function stops before it finishes the simulation
# Suppose it stops at the 7th replication. The text 
# file "results_ss.aipe.rmsea.sensitivity.txt" saves the results in all 
# previous replications; in this case it contains 6 replications since
# the simulation stopped at the 7th. The user can start this function again and specify
# 'G' to 4 (i.e., 10-6). New results will be appended to previous ones in the same file.

ss.aipe.rmsea.sensitivity(width=0.02, model=model.2.mis, Sigma=Sigma.theta, G=4)

########################################
EXAMPLE 2
########################################
# In addition to create a misspecified model by changing the model
# parameters in the true model as does Example 1, a misspecified
# model can also be created with the Cudeck-Browne (1992) procedure. 
# This procedure is implemented in the 'Sigma.2.SigmaStar( )' function in
# the MBESS package. Please refer to the help file of 'Sigma.2.SigmaStar( )'
# for detailed documentation.

## STEP 1: Specify the model
# This model is the same as the model in the first step of Example 1, but the
# model-implied population covariance matrix is no longer the true population 
# covariance matrix. The true population covariance matrix will be generated
# in Step 2 with the Cudeck-Browne procedure.
library(MASS)
library(sem)

model.2&lt;-specifyModel()
xi1 -&gt; y1, lambda1, 1
xi1 -&gt; y2, NA, 1
xi1 -&gt; y3, lambda2, 1
xi1 -&gt; y4, lambda3, 0.3
eta1 -&gt; y4, lambda4, 1
eta1 -&gt; y5, NA, 1
eta1 -&gt; y6, lambda5, 1
eta1 -&gt; y7, lambda6, 0.3
eta2 -&gt; y6, lambda7, 0.3
eta2 -&gt; y7, lambda8, 1
eta2 -&gt; y8, NA, 1
eta2 -&gt; y9, lambda9, 1
xi1 -&gt; eta1, gamma11, 0.6
eta1 -&gt; eta2, beta21, 0.6 
xi1 &lt;-&gt; xi1, phi11, 0.49
eta1 &lt;-&gt; eta1, psi11, 0.3136
eta2 &lt;-&gt; eta2, psi22, 0.3136
y1 &lt;-&gt; y1, delta1, 0.51
y2 &lt;-&gt; y2, delta2, 0.51
y3 &lt;-&gt; y3, delta3, 0.51
y4 &lt;-&gt; y4, delta4, 0.2895
y5 &lt;-&gt; y5, delta5, 0.51
y6 &lt;-&gt; y6, delta6, 0.2895
y7 &lt;-&gt; y7, delta7, 0.2895
y8 &lt;-&gt; y8, delta8, 0.51
y9 &lt;-&gt; y9, delta9, 0.51



theta &lt;- c(1, 1, 0.3, 1,1, 0.3, 0.3, 1, 1, 0.6, 0.6,
0.49, 0.3136, 0.3136, 0.51, 0.51, 0.51, 0.2895, 0.51, 0.2895, 0.2895, 0.51, 0.51)

names(theta) &lt;- c("lambda1","lambda2","lambda3",
"lambda4","lambda5","lambda6","lambda7","lambda8","lambda9",
"gamma11", "beta21",
"phi11", "psi11", "psi22", 
"delta1","delta2","delta3","delta4","delta5","delta6","delta7",
"delta8","delta9")

## STEP 2: Create the true population covariance matrix, so that (a) the model fits
# to this covariance matrix with specified discrepancy; (b) the population model
# parameters (the object 'theta') is the minimizer in fitting the model to the true 
# population covariance matrix.

# Since the desired RMSEA is 0.0268 and the df is 22, the MLE discrepancy value
# is specified to be 22*0.0268*0.0268, given the definition of RMSEA.

res &lt;- Sigma.2.SigmaStar(model=model.2, model.par=theta, 
latent.var=c("xi1", "eta1", "eta2"), discrep=22*0.0268*0.0268)

Sigma.theta.star &lt;- res$Sigma.star

# To verify that the population RMSEA is 0.0268
res2 &lt;- sem(ram=model.2, S=Sigma.theta.star, N=1000000)
summary(res2)$RMSEA

## STEP 3: Conduct the simulation
# Note although Examples 1 and 2 have the same population RMSEA, the
# model df and true population covariance matrix are different. Example 1
# uses 'model.2.mis' and 'Sigma.theta', whereas Example 2 uses 'model.2'
# and 'Sigma.theta.star'. Since the df is different, it requires a different sample
# size to achieve the same desired confidence interval width. 
ss.aipe.rmsea.sensitivity(width=0.02, model=model.2, Sigma=Sigma.theta.star, G=10)

## End(Not run)
</code></pre>

<hr>
<h2 id='ss.aipe.sc'>Sample size planning for Accuracy in Parameter Estimation (AIPE) of the standardized contrast in ANOVA</h2><span id='topic+ss.aipe.sc'></span>

<h3>Description</h3>

<p>A function to calculate the appropriate sample size per group for the standardized contrast in ANOVA such that the 
width of the confidence interval is sufficiently narrow. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ss.aipe.sc(psi, c.weights, width, conf.level = 0.95, 
assurance = NULL, certainty = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ss.aipe.sc_+3A_psi">psi</code></td>
<td>
<p> population standardized contrast </p>
</td></tr>
<tr><td><code id="ss.aipe.sc_+3A_c.weights">c.weights</code></td>
<td>
<p> the contrast weights </p>
</td></tr>
<tr><td><code id="ss.aipe.sc_+3A_width">width</code></td>
<td>
<p> the desired full width of the obtained confidence interval </p>
</td></tr>
<tr><td><code id="ss.aipe.sc_+3A_conf.level">conf.level</code></td>
<td>
<p>the desired confidence interval coverage, (i.e., 1 - Type I error rate)</p>
</td></tr>
<tr><td><code id="ss.aipe.sc_+3A_assurance">assurance</code></td>
<td>
<p> parameter to ensure that the obtained confidence interval width is narrower than the desired width with a specified degree of certainty (must be NULL or between zero and unity) </p>
</td></tr>
<tr><td><code id="ss.aipe.sc_+3A_certainty">certainty</code></td>
<td>
<p>an alias for <code>assurance</code></p>
</td></tr>
<tr><td><code id="ss.aipe.sc_+3A_...">...</code></td>
<td>
<p> allows one to potentially include parameter values for inner functions </p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>n</code></td>
<td>
<p>necessary sample size <em>per group</em></p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p> Ken Kelley (University of Notre Dame; <a href="mailto:KKelley@ND.Edu">KKelley@ND.Edu</a>); Keke Lai </p>


<h3>References</h3>

<p>Cumming, G. &amp; Finch, S. (2001). A primer on the understanding, use, and calculation of confidence intervals that are
based on central and noncentral distributions, <em>Educational and Psychological Measurement, 61</em>, 532&ndash;574.
</p>
<p>Hedges, L. V. (1981). Distribution theory for Glass's Estimator of effect size and related estimators. <em>Journal of Educational Statistics, 2</em>, 107&ndash;128.
</p>
<p>Kelley, K. (2005). The effects of nonnormal distributions on confidence intervals around the standardized mean
difference: Bootstrap and parametric confidence intervals, <em>Educational and Psychological Measurement, 65</em>, 51&ndash;69.
</p>
<p>Kelley, K. (2007). Constructing confidence intervals for standardized effect sizes: Theory, application, 
and implementation. <em>Journal of Statistical Software, 20</em> (8), 1&ndash;24.
</p>
<p>Kelley, K., &amp; Rausch, J. R. (2006). Sample size planning for the standardized mean difference: 
Accuracy in Parameter Estimation via narrow confidence intervals. <em>Psychological Methods, 11(4)</em>, 363&ndash;385.
</p>
<p>Lai, K., &amp; Kelley, K. (2007). Sample size planning for standardized ANCOVA and ANOVA 
contrasts: Obtaining narrow confidence intervals. <em>Manuscript submitted for publication</em>.
</p>
<p>Steiger, J. H., &amp; Fouladi, R. T. (1997). Noncentrality interval estimation and the evaluation of
statistical methods. In L. L. Harlow, S. A. Mulaik, &amp; J.H. Steiger (Eds.), <em>What if there were
no significance tests?</em> (pp. 221&ndash;257). Mahwah, NJ: Lawrence Erlbaum. </p>


<h3>See Also</h3>

 <p><code>ci.sc</code>, <code>conf.limits.nct</code>, <code>ss.aipe.c</code> </p>


<h3>Examples</h3>

<pre><code class='language-R'># Suppose the population standardized contrast is believed to be .6 
# in some 5-group ANOVA model. The researcher is interested in comparing 
# the average of means of group 1 and 2 with the average of group 3 and 4.

# To calculate the necessary sample size per gorup such that the width 
# of 95 percent confidence interval of the standardized 
# contrast is, with 90 percent assurance, no wider than .4:

# ss.aipe.sc(psi=.6, c.weights=c(.5, .5, -.5, -.5, 0), width=.4, assurance=.90) 
</code></pre>

<hr>
<h2 id='ss.aipe.sc.ancova'>Sample size planning from the AIPE perspective for standardized ANCOVA contrasts </h2><span id='topic+ss.aipe.sc.ancova'></span>

<h3>Description</h3>

<p>Sample size planning from the accuracy in parameter estimation (AIPE) perspective for standardized ANCOVA contrasts.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ss.aipe.sc.ancova(Psi = NULL, sigma.anova = NULL, sigma.ancova = NULL,
psi = NULL, ratio = NULL, rho = NULL, divisor = "s.ancova", 
c.weights, width, conf.level = 0.95, assurance = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ss.aipe.sc.ancova_+3A_psi">Psi</code></td>
<td>
<p> the population unstandardized ANCOVA (adjusted) contrast </p>
</td></tr>
<tr><td><code id="ss.aipe.sc.ancova_+3A_sigma.anova">sigma.anova</code></td>
<td>
<p> the population error standard deviation of the ANOVA model </p>
</td></tr>
<tr><td><code id="ss.aipe.sc.ancova_+3A_sigma.ancova">sigma.ancova</code></td>
<td>
<p> the population error standard deviation of the ANCOVA model  </p>
</td></tr>
<tr><td><code id="ss.aipe.sc.ancova_+3A_psi">psi</code></td>
<td>
<p> the population standardized ANCOVA (adjusted) contrast </p>
</td></tr>
<tr><td><code id="ss.aipe.sc.ancova_+3A_ratio">ratio</code></td>
<td>
<p> the ratio of <code>sigma.ancova</code> over <code>sigma.anova</code> </p>
</td></tr>
<tr><td><code id="ss.aipe.sc.ancova_+3A_rho">rho</code></td>
<td>
<p> the population correlation coefficient between the response and the covariate </p>
</td></tr>
<tr><td><code id="ss.aipe.sc.ancova_+3A_divisor">divisor</code></td>
<td>
<p> which error standard deviation to be used in standardizing the contrast; the value can be
either <code>"s.ancova"</code> or <code>"s.anova"</code> </p>
</td></tr>
<tr><td><code id="ss.aipe.sc.ancova_+3A_c.weights">c.weights</code></td>
<td>
<p> contrast weights </p>
</td></tr>
<tr><td><code id="ss.aipe.sc.ancova_+3A_width">width</code></td>
<td>
<p> the desired full width of the obtained confidence interval</p>
</td></tr>
<tr><td><code id="ss.aipe.sc.ancova_+3A_conf.level">conf.level</code></td>
<td>
<p> the desired confidence interval coverage, (i.e., 1 - Type I error rate) </p>
</td></tr>
<tr><td><code id="ss.aipe.sc.ancova_+3A_assurance">assurance</code></td>
<td>
<p> parameter to ensure that the obtained confidence interval width is narrower 
than the desired width with a specified degree of certainty (must be <code>NULL</code> or between zero and unity)</p>
</td></tr>
<tr><td><code id="ss.aipe.sc.ancova_+3A_...">...</code></td>
<td>
<p> allows one to potentially include parameter values for inner functions </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The sample size planning method this function is based on is developed in the context of simple (i.e., one-response-one-covariate) 
ANCOVA model and randomized design (i.e., same population covariate mean across groups).
</p>
<p>An ANCOVA contrast can be standardized in at least two ways: (a) divided by the error standard deviation of the
ANOVA model, (b) divided by the error standard deviation of the ANCOVA model. This function can be used to analyze
both types of standardized ANCOVA contrasts.
</p>
<p>Not all of the arguments about the effect sizes need to be specified. If <code>divisor="s.ancova"</code> is 
used in the argument, then input either (a) <code>psi</code>, or (b) <code>Psi</code> and <code>s.ancova</code>. 
If <code>divisor="s.anova"</code> is used in the argument, possible specifications 
are (a) <code>Psi</code>, <code>s.ancova</code>, and <code>s.anova</code>; (b) <code>psi</code>, and <code>ratio</code>; 
(c) <code>psi</code>, and <code>rho</code>. 
</p>


<h3>Value</h3>

<p>This function returns the sample size <em>per group</em>.
</p>


<h3>Note</h3>

 
<p>When <code>divisor="s.anova"</code> and the argument <code>assurance</code> is specified, the necessary
sample size <em>per group</em> returned by the function with <code>assurance</code> specified is slightly underestimated. 
The method to obtain exact sample size in the above situation has not been developed yet. A practical solution is
to use the sample size returned as the starting value to conduct a priori Montre Carlo simulations with 
function <code><a href="#topic+ss.aipe.sc.ancova.sensitivity">ss.aipe.sc.ancova.sensitivity</a></code>, as discussed in Lai &amp; Kelley (under review).
</p>


<h3>Author(s)</h3>

<p> Keke Lai (University of California&ndash;Merced) </p>


<h3>References</h3>

 
<p>Kelley, K. (2007). Constructing confidence intervals for standardized effect sizes: Theory, application, 
and implementation. <em>Journal of Statistical Software, 20</em> (8), 1&ndash;24.
</p>
<p>Kelley, K., &amp; Rausch, J. R. (2006). Sample size planning for the standardized mean difference: 
Accuracy in Parameter Estimation via narrow confidence intervals. <em>Psychological Methods, 11</em> (4), 363&ndash;385.
</p>
<p>Lai, K., &amp; Kelley, K. (2012). Accuracy in parameter estimation for ANCOVA and ANOVA contrasts: Sample size planning via narrow confidence intervals. 
<em>British Journal of Mathematical and Statistical Psychology, 65</em>, 350&ndash;370.
</p>
<p>Steiger, J. H., &amp; Fouladi, R. T. (1997). Noncentrality interval estimation and the evaluation of
statistical methods. In L. L. Harlow, S. A. Mulaik, &amp; J.H. Steiger (Eds.), <em>What if there were
no significance tests?</em> (pp. 221&ndash;257). Mahwah, NJ: Lawrence Erlbaum.</p>


<h3>See Also</h3>

 <p><code>ss.aipe.sc</code>, <code>ss.aipe.sc.ancova.sensitivity</code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
ss.aipe.sc.ancova(psi=.8, width=.5, c.weights=c(.5, .5, 0, -1))

ss.aipe.sc.ancova(psi=.8, ratio=.6, width=.5, 
c.weights=c(.5, .5, 0, -1), divisor="s.anova")

ss.aipe.sc.ancova(psi=.5, rho=.4, width=.3, 
c.weights=c(.5, .5, 0, -1), divisor="s.anova")

## End(Not run)

</code></pre>

<hr>
<h2 id='ss.aipe.sc.ancova.sensitivity'>Sensitivity analysis for the sample size planning method for standardized ANCOVA contrast </h2><span id='topic+ss.aipe.sc.ancova.sensitivity'></span>

<h3>Description</h3>

<p>Sensitivity analysis for the sample size planning method with the goal to obtain sufficiently narrow confidence intervals for standardized 
ANCOVA complex contrasts.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ss.aipe.sc.ancova.sensitivity(true.psi = NULL, estimated.psi = NULL, 
c.weights, desired.width = NULL, selected.n = NULL, mu.x = 0, 
sigma.x = 1, rho, divisor = "s.ancova", assurance = NULL, 
conf.level = 0.95, G = 10000, print.iter = TRUE, detail = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ss.aipe.sc.ancova.sensitivity_+3A_true.psi">true.psi</code></td>
<td>
<p> the population standardized ANCOVA contrast </p>
</td></tr>
<tr><td><code id="ss.aipe.sc.ancova.sensitivity_+3A_estimated.psi">estimated.psi</code></td>
<td>
<p> the estimated standardized ANCOVA contrast </p>
</td></tr>
<tr><td><code id="ss.aipe.sc.ancova.sensitivity_+3A_c.weights">c.weights</code></td>
<td>
<p> the contrast weights</p>
</td></tr>
<tr><td><code id="ss.aipe.sc.ancova.sensitivity_+3A_desired.width">desired.width</code></td>
<td>
<p> the desired full width of the obtained confidence interval </p>
</td></tr>
<tr><td><code id="ss.aipe.sc.ancova.sensitivity_+3A_selected.n">selected.n</code></td>
<td>
<p> selected sample size to use in order to determine distributional properties of a given value of sample size</p>
</td></tr>
<tr><td><code id="ss.aipe.sc.ancova.sensitivity_+3A_mu.x">mu.x</code></td>
<td>
<p> the population mean for the covariate </p>
</td></tr>
<tr><td><code id="ss.aipe.sc.ancova.sensitivity_+3A_sigma.x">sigma.x</code></td>
<td>
<p> the population standard deviation of the covariate </p>
</td></tr>
<tr><td><code id="ss.aipe.sc.ancova.sensitivity_+3A_rho">rho</code></td>
<td>
<p> the population correlation coefficient between the response and the covariate </p>
</td></tr>
<tr><td><code id="ss.aipe.sc.ancova.sensitivity_+3A_divisor">divisor</code></td>
<td>
<p> which error standard deviation to be used in standardizing the contrast; the value can be
either <code>"s.ancova"</code> or <code>"s.anova"</code> </p>
</td></tr>
<tr><td><code id="ss.aipe.sc.ancova.sensitivity_+3A_assurance">assurance</code></td>
<td>
<p> parameter to ensure that the obtained confidence interval width is narrower than the 
desired width with a specified degree of certainty (must be <code>NULL</code> or between zero and unity) </p>
</td></tr>
<tr><td><code id="ss.aipe.sc.ancova.sensitivity_+3A_conf.level">conf.level</code></td>
<td>
<p> the desired confidence interval coverage, (i.e., 1 - Type I error rate) </p>
</td></tr>
<tr><td><code id="ss.aipe.sc.ancova.sensitivity_+3A_g">G</code></td>
<td>
<p> number of generations (i.e., replications) of the simulation </p>
</td></tr>
<tr><td><code id="ss.aipe.sc.ancova.sensitivity_+3A_print.iter">print.iter</code></td>
<td>
<p> to print the current value of the iterations </p>
</td></tr>
<tr><td><code id="ss.aipe.sc.ancova.sensitivity_+3A_detail">detail</code></td>
<td>
<p> whether the user needs a detailed (<code>TRUE</code>) or brief (<code>FALSE</code>) report of the simulation results; the 
detail report includes all the raw data in the simulations </p>
</td></tr>
<tr><td><code id="ss.aipe.sc.ancova.sensitivity_+3A_...">...</code></td>
<td>
<p> allows one to potentially include parameter values for inner functions </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The sample size planning method this function is based on is developed in the context of simple (i.e., one-response-one-covariate) 
ANCOVA model and randomized design (i.e., same population covariate mean across groups).
</p>
<p>An ANCOVA contrast can be standardized in at least two ways: (a) divided by the error standard deviation of the
ANOVA model, (b) divided by the error standard deviation of the ANCOVA model. This function can be used to analyze
both types of standardized ANCOVA contrasts.
</p>
<p>The population mean and standard deviation of the covariate does not affect the sample size planning 
procedure; they can be specified as any values that are considered as reasonable by the user.
</p>


<h3>Value</h3>

<table>
<tr><td><code>psi.obs</code></td>
<td>
<p>observed standardized contrast in each iteration</p>
</td></tr>
<tr><td><code>Full.Width</code></td>
<td>
<p>vector of the full confidence interval width</p>
</td></tr>
<tr><td><code>Width.from.psi.obs.Lower</code></td>
<td>
<p>vector of the lower confidence interval width</p>
</td></tr>
<tr><td><code>Width.from.psi.obs.Upper</code></td>
<td>
<p>vector of the upper confidence interval width</p>
</td></tr>
<tr><td><code>Type.I.Error.Upper</code></td>
<td>
<p>iterations where a Type I error occurred on the upper end of the confidence interval</p>
</td></tr>
<tr><td><code>Type.I.Error.Lower</code></td>
<td>
<p>iterations where a Type I error occurred on the lower end of the confidence interval</p>
</td></tr>
<tr><td><code>Type.I.Error</code></td>
<td>
<p>iterations where a Type I error happens</p>
</td></tr>
<tr><td><code>Lower.Limit</code></td>
<td>
<p>the lower limit of the obtained confidence interval</p>
</td></tr>
<tr><td><code>Upper.Limit</code></td>
<td>
<p>the upper limit of the obtained confidence interval</p>
</td></tr>
<tr><td><code>replications</code></td>
<td>
<p>number of replications of the simulation</p>
</td></tr>
<tr><td><code>True.psi</code></td>
<td>
<p>population standardized contrast</p>
</td></tr>
<tr><td><code>Estimated.psi</code></td>
<td>
<p>estimated standardized contrast</p>
</td></tr>
<tr><td><code>Desired.Width</code></td>
<td>
<p>the desired full width of the obtained confidence interval</p>
</td></tr>
<tr><td><code>assurance</code></td>
<td>
<p>the value assigned to the argument <code>assurance</code></p>
</td></tr>
<tr><td><code>Sample.Size.per.Group</code></td>
<td>
<p>sample size <em>per group</em></p>
</td></tr>
<tr><td><code>Number.of.Groups</code></td>
<td>
<p>number of groups</p>
</td></tr>
<tr><td><code>mean.full.width</code></td>
<td>
<p>mean width of the obtained full confidence intervals</p>
</td></tr>
<tr><td><code>median.full.width</code></td>
<td>
<p>median width of the obtained full confidence intervals</p>
</td></tr>
<tr><td><code>sd.full.width</code></td>
<td>
<p>standard deviation of the widths of the obtained full confidence intervals</p>
</td></tr>
<tr><td><code>Pct.Width.obs.NARROWER.than.desired</code></td>
<td>
<p>percentage of the obtained full confidence interval widths that are narrower than the desired width</p>
</td></tr>
<tr><td><code>mean.Width.from.psi.obs.Lower</code></td>
<td>
<p>mean lower width of the obtained confidence intervals</p>
</td></tr>
<tr><td><code>mean.Width.from.psi.obs.Upper</code></td>
<td>
<p>mean upper width of the obtained confidence intervals</p>
</td></tr>
<tr><td><code>Type.I.Error.Upper</code></td>
<td>
<p>Type I error rate from the upper side</p>
</td></tr>
<tr><td><code>Type.I.Error.Lower</code></td>
<td>
<p>Type I error rate from the lower side</p>
</td></tr>
<tr><td><code>Type.I.Error</code></td>
<td>
<p>Type I error rate</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p> Keke Lai </p>


<h3>References</h3>

 
<p>Kelley, K. (2007). Constructing confidence intervals for standardized effect sizes: Theory, application, 
and implementation. <em>Journal of Statistical Software, 20</em> (8), 1&ndash;24.
</p>
<p>Kelley, K., &amp; Rausch, J. R. (2006). Sample size planning for the standardized mean difference: 
Accuracy in Parameter Estimation via narrow confidence intervals. <em>Psychological Methods, 11</em> (4), 363&ndash;385.
</p>
<p>Lai, K., &amp; Kelley, K. (2012). Accuracy in parameter estimation for ANCOVA and ANOVA contrasts: Sample size planning via narrow confidence intervals. 
<em>British Journal of Mathematical and Statistical Psychology, 65</em>, 350&ndash;370.
</p>
<p>Steiger, J. H., &amp; Fouladi, R. T. (1997). Noncentrality interval estimation and the evaluation of
statistical methods. In L. L. Harlow, S. A. Mulaik, &amp; J.H. Steiger (Eds.), <em>What if there were
no significance tests?</em> (pp. 221&ndash;257). Mahwah, NJ: Lawrence Erlbaum. </p>


<h3>See Also</h3>

 <p><code><a href="#topic+ss.aipe.sc.ancova">ss.aipe.sc.ancova</a></code>; <code><a href="#topic+ss.aipe.sc.sensitivity">ss.aipe.sc.sensitivity</a></code> </p>

<hr>
<h2 id='ss.aipe.sc.sensitivity'>Sensitivity analysis for sample size planning for the standardized ANOVA contrast from 
the Accuracy in Parameter Estimation (AIPE) Perspective</h2><span id='topic+ss.aipe.sc.sensitivity'></span>

<h3>Description</h3>

<p>Performs a sensitivity analysis when planning sample size from the Accuracy in Parameter Estimation (AIPE) 
Perspective for the standardized ANOVA contrast.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ss.aipe.sc.sensitivity(true.psi = NULL, estimated.psi = NULL, c.weights, 
desired.width = NULL, selected.n = NULL, assurance = NULL, certainty=NULL, 
conf.level = 0.95, G = 10000, print.iter = TRUE, detail = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ss.aipe.sc.sensitivity_+3A_true.psi">true.psi</code></td>
<td>
<p>population standardized contrast </p>
</td></tr>
<tr><td><code id="ss.aipe.sc.sensitivity_+3A_estimated.psi">estimated.psi</code></td>
<td>
<p> estimated standardized contrast</p>
</td></tr>
<tr><td><code id="ss.aipe.sc.sensitivity_+3A_c.weights">c.weights</code></td>
<td>
<p> the contrast weights </p>
</td></tr>
<tr><td><code id="ss.aipe.sc.sensitivity_+3A_desired.width">desired.width</code></td>
<td>
<p> the desired full width of the obtained confidence interval </p>
</td></tr>
<tr><td><code id="ss.aipe.sc.sensitivity_+3A_selected.n">selected.n</code></td>
<td>
<p> selected sample size to use in order to determine distributional properties of at a given value of sample size </p>
</td></tr>
<tr><td><code id="ss.aipe.sc.sensitivity_+3A_assurance">assurance</code></td>
<td>
<p> parameter to ensure that the obtained confidence interval width is narrower than the desired width with a specified degree of certainty (must be NULL or between zero and unity) </p>
</td></tr>
<tr><td><code id="ss.aipe.sc.sensitivity_+3A_certainty">certainty</code></td>
<td>
<p>an alias for <code>assurance</code></p>
</td></tr>
<tr><td><code id="ss.aipe.sc.sensitivity_+3A_conf.level">conf.level</code></td>
<td>
<p>the desired confidence interval coverage, (i.e., 1 - Type I error rate)</p>
</td></tr>
<tr><td><code id="ss.aipe.sc.sensitivity_+3A_g">G</code></td>
<td>
<p> number of generations (i.e., replications) of the simulation</p>
</td></tr>
<tr><td><code id="ss.aipe.sc.sensitivity_+3A_print.iter">print.iter</code></td>
<td>
<p> to print the current value of the iterations</p>
</td></tr>
<tr><td><code id="ss.aipe.sc.sensitivity_+3A_detail">detail</code></td>
<td>
<p>whether the user needs a detailed (<code>TRUE</code>) or brief (<code>FALSE</code>) report of the simulation results; the 
detailed report includes all the raw data in the simulations</p>
</td></tr>
<tr><td><code id="ss.aipe.sc.sensitivity_+3A_...">...</code></td>
<td>
<p> allows one to potentially include parameter values for inner functions </p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>psi.obs</code></td>
<td>
<p>observed standardized contrast in each iteration</p>
</td></tr>
<tr><td><code>Full.Width</code></td>
<td>
<p>vector of the full confidence interval width</p>
</td></tr>
<tr><td><code>Width.from.psi.obs.Lower</code></td>
<td>
<p>vector of the lower confidence interval width</p>
</td></tr>
<tr><td><code>Width.from.psi.obs.Upper</code></td>
<td>
<p>vector of the upper confidence interval width</p>
</td></tr>
<tr><td><code>Type.I.Error.Upper</code></td>
<td>
<p>iterations where a Type I error occurred on the upper end of the confidence interval</p>
</td></tr>
<tr><td><code>Type.I.Error.Lower</code></td>
<td>
<p>iterations where a Type I error occurred on the lower end of the confidence interval</p>
</td></tr>
<tr><td><code>Type.I.Error</code></td>
<td>
<p>iterations where a Type I error happens</p>
</td></tr>
<tr><td><code>Lower.Limit</code></td>
<td>
<p>the lower limit of the obtained confidence interval</p>
</td></tr>
<tr><td><code>Upper.Limit</code></td>
<td>
<p>the upper limit of the obtained confidence interval</p>
</td></tr>
<tr><td><code>replications</code></td>
<td>
<p>number of replications of the simulation</p>
</td></tr>
<tr><td><code>True.psi</code></td>
<td>
<p>population standardized contrast</p>
</td></tr>
<tr><td><code>Estimated.psi</code></td>
<td>
<p>estimated standardized contrast</p>
</td></tr>
<tr><td><code>Desired.Width</code></td>
<td>
<p>the desired full width of the obtained confidence interval</p>
</td></tr>
<tr><td><code>assurance</code></td>
<td>
<p>the value assigned to the argument <code>assurance</code></p>
</td></tr>
<tr><td><code>Sample.Size.per.Group</code></td>
<td>
<p>sample size per group</p>
</td></tr>
<tr><td><code>Number.of.Groups</code></td>
<td>
<p>number of groups</p>
</td></tr>
<tr><td><code>mean.full.width</code></td>
<td>
<p>mean width of the obtained full conficence intervals</p>
</td></tr>
<tr><td><code>median.full.width</code></td>
<td>
<p>median width of the obtained full confidence intervals</p>
</td></tr>
<tr><td><code>sd.full.width</code></td>
<td>
<p>standard deviation of the widths of the obtained full confidence intervals</p>
</td></tr>
<tr><td><code>Pct.Width.obs.NARROWER.than.desired</code></td>
<td>
<p>percentage of the obtained full confidence interval widths that are narrower than the desired width</p>
</td></tr>
<tr><td><code>mean.Width.from.psi.obs.Lower</code></td>
<td>
<p>mean lower width of the obtained confidence intervals</p>
</td></tr>
<tr><td><code>mean.Width.from.psi.obs.Upper</code></td>
<td>
<p>mean upper width of the obtained confidence intervals</p>
</td></tr>
<tr><td><code>Type.I.Error.Upper</code></td>
<td>
<p>Type I error rate from the upper side</p>
</td></tr>
<tr><td><code>Type.I.Error.Lower</code></td>
<td>
<p>Type I error rate from the lower side</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p> Ken Kelley (University of Notre Dame; <a href="mailto:KKelley@ND.Edu">KKelley@ND.Edu</a>); Keke Lai (University of California &ndash; Merced) </p>


<h3>References</h3>

 
<p>Cumming, G. &amp; Finch, S. (2001). A primer on the understanding, use, and calculation of confidence intervals that are
based on central and noncentral distributions, <em>Educational and Psychological Measurement, 61</em>, 532&ndash;574.
</p>
<p>Hedges, L. V. (1981). Distribution theory for Glass's Estimator of effect size and related estimators. <em>Journal of Educational Statistics, 2</em>, 107&ndash;128.
</p>
<p>Kelley, K. (2007). Constructing confidence intervals for standardized effect sizes: Theory, application, 
and implementation. <em>Journal of Statistical Software, 20</em> (8), 1&ndash;24.
</p>
<p>Kelley, K., &amp; Rausch, J. R. (2006). Sample size planning for the standardized mean difference: 
Accuracy in Parameter Estimation via narrow confidence intervals. P<em>sychological Methods, 11</em> (4), 363&ndash;385.
</p>
<p>Lai, K., &amp; Kelley, K. (2007). Sample size planning for standardized ANCOVA and ANOVA 
contrasts: Obtaining narrow confidence intervals. <em>Manuscript submitted for publication</em>.
</p>
<p>Steiger, J. H., &amp; Fouladi, R. T. (1997). Noncentrality interval estimation and the evaluation of
statistical methods. In L. L. Harlow, S. A. Mulaik, &amp; J.H. Steiger (Eds.), <em>What if there where
no significance tests?</em> (pp. 221&ndash;257). Mahwah, NJ: Lawrence Erlbaum. </p>


<h3>See Also</h3>

<p><code>ss.aipe.sc</code>, <code>ss.aipe.c</code>, <code>conf.limits.nct</code></p>

<hr>
<h2 id='ss.aipe.sem.path'>Sample size planning for SEM targeted effects</h2><span id='topic+ss.aipe.sem.path'></span>

<h3>Description</h3>

<p>Plan sample size for structural equation models so that the confidence intervals for the model parameters of interest are sufficiently narrow
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ss.aipe.sem.path(model, Sigma, desired.width, which.path, 
conf.level = 0.95, assurance = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ss.aipe.sem.path_+3A_model">model</code></td>
<td>
<p> an RAM (reticular action model; e.g., McArdle &amp; McDonald, 1984) specification of a structural equation model, and should be of class <code>mod</code>. The model is specified in the same manner as the <code><a href="sem.html#topic+sem">sem</a></code> package; see <code><a href="sem.html#topic+sem">sem</a></code> and <code><a href="sem.html#topic+specify.model">specify.model</a></code> for detailed documentation about model specifications in the RAM notation. </p>
</td></tr>
<tr><td><code id="ss.aipe.sem.path_+3A_sigma">Sigma</code></td>
<td>
<p> estimated population covariance matrix of the manifest variables</p>
</td></tr>
<tr><td><code id="ss.aipe.sem.path_+3A_desired.width">desired.width</code></td>
<td>
<p> desired confidence interval width for the model parameter of interest </p>
</td></tr>
<tr><td><code id="ss.aipe.sem.path_+3A_which.path">which.path</code></td>
<td>
<p> the name of the model parameter of interest, presented in double quotation marks </p>
</td></tr>
<tr><td><code id="ss.aipe.sem.path_+3A_conf.level">conf.level</code></td>
<td>
<p> confidence level (i.e., 1- Type I error rate) </p>
</td></tr>
<tr><td><code id="ss.aipe.sem.path_+3A_assurance">assurance</code></td>
<td>
<p> the assurance that the confidence interval obtained in a particular study will be no wider than desired (must be <code>NULL</code> or a value between 0.50 and 1) </p>
</td></tr>
<tr><td><code id="ss.aipe.sem.path_+3A_...">...</code></td>
<td>
<p>allows one to potentially include parameter values for inner functions </p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function implements the sample size planning methods proposed in Lai and Kelley (2010). It depends on the 
function <code><a href="sem.html#topic+sem">sem</a></code> in the <code>sem</code> package to calculate the expected information matrix, and uses the same notation to specify SEM 
models as does <code><a href="sem.html#topic+sem">sem</a></code>. Please refer to <code><a href="sem.html#topic+sem">sem</a></code> for more detailed documentations 
about model specification, the RAM notation, and model fitting techniques. For technical discussion 
on how to obtain the model implied covariance matrix in the RAM notation given model parameters, see McArdle and McDonald (1984).</p>


<h3>Value</h3>

<table>
<tr><td><code>parameters</code></td>
<td>
<p>the names of the model parameters </p>
</td></tr>
<tr><td><code>path.index</code></td>
<td>
<p>the index of the model parameter of interest </p>
</td></tr>
<tr><td><code>sample.size</code></td>
<td>
<p>the necessary sample size calculated </p>
</td></tr>
<tr><td><code>obs.vars</code></td>
<td>
<p>the names of the observed variables </p>
</td></tr>
<tr><td><code>var.theta.j</code></td>
<td>
<p>the population variance of the model parameter of interest at the calculated sample size</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p> Keke Lai (University of California&ndash;Merced) </p>


<h3>References</h3>

 
<p>Fox, J. (2006). Structural equation modeling with the sem package in R. <em>Structural Equation Modeling, 13</em>, 465&ndash;486.
</p>
<p>Lai, K., &amp; Kelley, K. (in press). Accuracy in parameter estimation for targeted effects in structural equation modeling: Sample size planning for narrow confidence intervals. <em>Psychological Methods</em>.
</p>
<p>McArdle, J. J., &amp; McDonald, R. P. (1984). Some algebraic properties of the reticular action model. <em>British Journal of Mathematical and Statistical Psychology, 37</em>, 234&ndash;251.  </p>


<h3>See Also</h3>

 <p><code><a href="sem.html#topic+sem">sem</a></code>; <code><a href="sem.html#topic+specify.model">specify.model</a></code>; <code><a href="#topic+theta.2.Sigma.theta">theta.2.Sigma.theta</a></code>; <code><a href="#topic+ss.aipe.sem.path.sensitiv">ss.aipe.sem.path.sensitiv</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Suppose the model of interest is Model 2 in the simulation study 
# in Lai and Kelley (2010), and the goal is to obtain a 95% confidence 
# interval for 'beta21' no wider than 0.3. The necessary sample size 
# can be calculated as follows.

library(sem)

# specify a model object in the RAM notation
model.2&lt;-specifyModel()
xi1 -&gt; y1, lambda1, 1
xi1 -&gt; y2, NA, 1
xi1 -&gt; y3, lambda2, 1
xi1 -&gt; y4, lambda3, 0.3
eta1 -&gt; y4, lambda4, 1
eta1 -&gt; y5, NA, 1
eta1 -&gt; y6, lambda5, 1
eta1 -&gt; y7, lambda6, 0.3
eta2 -&gt; y6, lambda7, 0.3
eta2 -&gt; y7, lambda8, 1
eta2 -&gt; y8, NA, 1
eta2 -&gt; y9, lambda9, 1
xi1 -&gt; eta1, gamma11, 0.6
eta1 -&gt; eta2, beta21, 0.6 
xi1 &lt;-&gt; xi1, phi11, 0.49
eta1 &lt;-&gt; eta1, psi11, 0.3136
eta2 &lt;-&gt; eta2, psi22, 0.3136
y1 &lt;-&gt; y1, delta1, 0.51
y2 &lt;-&gt; y2, delta2, 0.51
y3 &lt;-&gt; y3, delta3, 0.51
y4 &lt;-&gt; y4, delta4, 0.2895
y5 &lt;-&gt; y5, delta5, 0.51
y6 &lt;-&gt; y6, delta6, 0.2895
y7 &lt;-&gt; y7, delta7, 0.2895
y8 &lt;-&gt; y8, delta8, 0.51
y9 &lt;-&gt; y9, delta9, 0.51


# to inspect the specified model
model.2

# one way to specify the population covariance matrix is to first 
# specify path coefficients and then calcualte the model-implied 
# covariance matrix
theta &lt;- c(1, 1, 0.3, 1,1, 0.3, 0.3, 1, 1, 0.6, 0.6,
0.49, 0.3136, 0.3136, 0.51, 0.51, 0.51, 0.2895, 0.51, 0.2895, 0.2895, 0.51, 0.51)

names(theta) &lt;- c("lambda1","lambda2","lambda3",
"lambda4","lambda5","lambda6","lambda7","lambda8","lambda9",
"gamma11", "beta21",
"phi11", "psi11", "psi22", 
"delta1","delta2","delta3","delta4","delta5","delta6","delta7",
"delta8","delta9")

res&lt;-theta.2.Sigma.theta(model=model.2, theta=theta, 
latent.vars=c("xi1", "eta1","eta2"))

Sigma.theta &lt;- res$Sigma.theta
# thus 'Sigma.theta' is the input covariance matrix for sample size 
# planning procedure.

# the necessary sample size can be calculated as follows.
# ss.aipe.sem.path(model=model.2, Sigma=Sigma.theta, 
# desired.width=0.3, which.path="beta21")

## End(Not run)
</code></pre>

<hr>
<h2 id='ss.aipe.sem.path.sensitiv'> a priori Monte Carlo simulation for sample size planning for SEM targeted effects</h2><span id='topic+ss.aipe.sem.path.sensitiv'></span>

<h3>Description</h3>

<p>Conduct a priori Monte Carlo simulation to empirically study the effects of (mis)specifications of input information on the calculated sample size. Random data are generated from the true covariance matrix but fit to the proposed model, whereas sample size is calculated based on the input covariance matrix and proposed model. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ss.aipe.sem.path.sensitiv(model, est.Sigma, true.Sigma = est.Sigma, 
which.path, desired.width, N=NULL, conf.level = 0.95, assurance = NULL, 
G = 100, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ss.aipe.sem.path.sensitiv_+3A_model">model</code></td>
<td>
<p> the model the researcher proposes, may or may not be the true model. This argument should be an RAM (reticular action model; e.g., McArdle &amp; McDonald, 1984) specification of a structural equation model, and should be of class <code>mod</code>. The model is specified in the same manner as does the <code><a href="sem.html#topic+sem">sem</a></code> package; see <code><a href="sem.html#topic+sem">sem</a></code> and <code><a href="sem.html#topic+specify.model">specify.model</a></code> for detailed documentation about model specifications in the RAM notation.</p>
</td></tr>
<tr><td><code id="ss.aipe.sem.path.sensitiv_+3A_est.sigma">est.Sigma</code></td>
<td>
<p> the covariance matrix used to calculate sample size, may or may not be the true covariance matrix. The row names and column names of <code>est.Sigma</code> should be the same as the manifest variables in <code>est.model</code>. </p>
</td></tr>
<tr><td><code id="ss.aipe.sem.path.sensitiv_+3A_true.sigma">true.Sigma</code></td>
<td>
<p> the true population covariance matrix, which will be used to generate random data for the simulation study. The row names and column names of <code>est.Sigma</code> should be the same as the manifest variables in <code>est.model</code>.</p>
</td></tr>
<tr><td><code id="ss.aipe.sem.path.sensitiv_+3A_which.path">which.path</code></td>
<td>
<p> the name of the model parameter of interest, and must be in a double quote </p>
</td></tr>
<tr><td><code id="ss.aipe.sem.path.sensitiv_+3A_desired.width">desired.width</code></td>
<td>
<p>desired confidence interval width for the model parameter of interest </p>
</td></tr>
<tr><td><code id="ss.aipe.sem.path.sensitiv_+3A_n">N</code></td>
<td>
<p>the sample size of random data. If it is <code>NULL</code>, it will be determined by the sample size planning method</p>
</td></tr>
<tr><td><code id="ss.aipe.sem.path.sensitiv_+3A_conf.level">conf.level</code></td>
<td>
<p> confidence level (i.e., 1- Type I error rate) </p>
</td></tr>
<tr><td><code id="ss.aipe.sem.path.sensitiv_+3A_assurance">assurance</code></td>
<td>
<p>the assurance that the confidence interval obtained in a particular study will be no wider than desired (must be <code>NULL</code> or a value between 0.50 and 1)  </p>
</td></tr>
<tr><td><code id="ss.aipe.sem.path.sensitiv_+3A_g">G</code></td>
<td>
<p>number of replications in the Monte Carlo simulation </p>
</td></tr>
<tr><td><code id="ss.aipe.sem.path.sensitiv_+3A_...">...</code></td>
<td>
<p> allows one to potentially include parameter values for inner functions </p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function implements the sample size planning methods proposed in Lai and Kelley (2010). It depends on the 
function <code><a href="sem.html#topic+sem">sem</a></code> in the <code>sem</code> package to calculate the expected information matrix, and uses the same notation to specify SEM 
models as does <code><a href="sem.html#topic+sem">sem</a></code>. Please refer to <code><a href="sem.html#topic+sem">sem</a></code> for more detailed documentation 
about model specifications, the RAM notation, and model fitting techniques. For technical discussion 
on how to obtain the model implied covariance matrix in the RAM notation given model parameters, see McArdle and McDonald (1984).</p>


<h3>Value</h3>

<table>
<tr><td><code>w</code></td>
<td>
<p>the <code>G</code> random confidence interval widths </p>
</td></tr>
<tr><td><code>sample.size</code></td>
<td>
<p>the sample size calculated </p>
</td></tr>
<tr><td><code>path.of.interest</code></td>
<td>
<p>name of the model parameter of interest</p>
</td></tr>
<tr><td><code>desired.width</code></td>
<td>
<p>desired confidence interval width</p>
</td></tr>
<tr><td><code>mean.width</code></td>
<td>
<p>mean of the <code>G</code> random confidence interval widths</p>
</td></tr>
<tr><td><code>median.width</code></td>
<td>
<p>median of the <code>G</code> random confidence interval widths</p>
</td></tr>
<tr><td><code>quantile.width</code></td>
<td>
<p>99, 95, 90, 85, 80, 75, 70, and 60 percentiles of the <code>G</code> random confidence interval widths</p>
</td></tr>
<tr><td><code>width.less.than.desired</code></td>
<td>
<p>the proportion of confidence interval widths narrower than desired</p>
</td></tr>
<tr><td><code>Type.I.err.upper</code></td>
<td>
<p>the upper empirical Type I error rate</p>
</td></tr>
<tr><td><code>Type.I.err.lower</code></td>
<td>
<p>the lower empirical Type I error rate</p>
</td></tr>
<tr><td><code>Type.I.err</code></td>
<td>
<p>total empirical Type I error rate</p>
</td></tr>
<tr><td><code>conf.level</code></td>
<td>
<p>confidence level</p>
</td></tr>
<tr><td><code>rep</code></td>
<td>
<p>successful replications</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Sometimes the simulation stops in the middle of fitting the model to the random data. The reason is that <code><a href="stats.html#topic+nlm">nlm</a></code>, the 
function <code><a href="sem.html#topic+sem">sem</a></code> calls to fit the model, fails to converge. We suggest using the <code><a href="base.html#topic+try">try</a></code> function in simulation so that
the simulation can proceed with unsuccessful iterations.</p>


<h3>Author(s)</h3>

<p> Keke Lai (University of California &ndash; Merced) and Ken Kelley <a href="mailto:kkelley@nd.edu">kkelley@nd.edu</a> </p>


<h3>References</h3>

 
<p>Fox, J. (2006). Structural equation modeling with the sem package in R. <em>Structural Equation Modeling, 13</em>, 465&ndash;486.
</p>
<p>Lai, K., &amp; Kelley, K. (in press). Accuracy in parameter estimation for targeted effects in structural equation modeling: Sample size planning for narrow confidence intervals. <em>Psychological Methods</em>.
</p>
<p>McArdle, J. J., &amp; McDonald, R. P. (1984). Some algebraic properties of the reticular action model. <em>British Journal of Mathematical and Statistical Psychology, 37</em>, 234&ndash;251.  </p>


<h3>See Also</h3>

 <p><code><a href="sem.html#topic+sem">sem</a></code>; <code><a href="sem.html#topic+specify.model">specify.model</a></code>; <code><a href="#topic+theta.2.Sigma.theta">theta.2.Sigma.theta</a></code>; <code><a href="#topic+ss.aipe.sem.path">ss.aipe.sem.path</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Suppose the model of interest is Model 2 of the simulation study in 
# Lai and Kelley (2010), and the goal is to obtain a 95% confidence 
# interval for 'beta21' no wider than 0.3.

library(sem)

# specify a model object in the RAM notation
model.2&lt;-specifyModel()
xi1 -&gt; y1, lambda1, 1
xi1 -&gt; y2, NA, 1
xi1 -&gt; y3, lambda2, 1
xi1 -&gt; y4, lambda3, 0.3
eta1 -&gt; y4, lambda4, 1
eta1 -&gt; y5, NA, 1
eta1 -&gt; y6, lambda5, 1
eta1 -&gt; y7, lambda6, 0.3
eta2 -&gt; y6, lambda7, 0.3
eta2 -&gt; y7, lambda8, 1
eta2 -&gt; y8, NA, 1
eta2 -&gt; y9, lambda9, 1
xi1 -&gt; eta1, gamma11, 0.6
eta1 -&gt; eta2, beta21, 0.6 
xi1 &lt;-&gt; xi1, phi11, 0.49
eta1 &lt;-&gt; eta1, psi11, 0.3136
eta2 &lt;-&gt; eta2, psi22, 0.3136
y1 &lt;-&gt; y1, delta1, 0.51
y2 &lt;-&gt; y2, delta2, 0.51
y3 &lt;-&gt; y3, delta3, 0.51
y4 &lt;-&gt; y4, delta4, 0.2895
y5 &lt;-&gt; y5, delta5, 0.51
y6 &lt;-&gt; y6, delta6, 0.2895
y7 &lt;-&gt; y7, delta7, 0.2895
y8 &lt;-&gt; y8, delta8, 0.51
y9 &lt;-&gt; y9, delta9, 0.51


# to inspect the specified model
model.2

# one way to specify the population covariance matrix is to
# first specify path coefficients and then calcualte the 
# model-implied covariance matrix
theta &lt;- c(1, 1, 0.3, 1,1, 0.3, 0.3, 1, 1, 0.6, 0.6,
0.49, 0.3136, 0.3136, 0.51, 0.51, 0.51, 0.2895, 0.51, 0.2895, 0.2895, 0.51, 0.51)

names(theta) &lt;- c("lambda1","lambda2","lambda3",
"lambda4","lambda5","lambda6","lambda7","lambda8","lambda9",
"gamma11", "beta21",
"phi11", "psi11", "psi22", 
"delta1","delta2","delta3","delta4","delta5","delta6","delta7",
"delta8","delta9")

res&lt;-theta.2.Sigma.theta(model=model.2, theta=theta, 
latent.vars=c("xi1", "eta1","eta2"))

Sigma.theta &lt;- res$Sigma.theta
# thus 'Sigma.theta' is the input covariance matrix for sample size planning procedure.

# the necessary sample size can be calculated as follows.
# ss.aipe.sem.path(model=model.2, Sigma=Sigma.theta, 
# desired.width=0.3, which.path="beta21")

# to verify the sample size calculated
# ss.aipe.sem.path.sensitiv(est.model=model.2, est.Sigma=Sigma.theta, 
# which.path="beta21", desired.width=0.3, G = 300)

# suppose the true covariance matrix ('var(X)' below) is in fact 
# a point close to 'Sigma.theta':

# X&lt;-mvrnorm(n=1000, mu=rep(0,9), Sigma=Sigma.pop)
# var(X)
# ss.aipe.sem.path.sensitiv(est.model=model.2, est.Sigma=Sigma.theta, 
# true.Sigma=var(X), which.path="beta21", desired.width=0.3, G=300)

## End(Not run)
</code></pre>

<hr>
<h2 id='ss.aipe.sm'>Sample size planning for Accuracy in Parameter Estimation (AIPE) of the standardized mean</h2><span id='topic+ss.aipe.sm'></span>

<h3>Description</h3>

<p>A function to calculate the appropriate sample size for the standardized mean such that the 
width of the confidence interval is sufficiently narrow. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ss.aipe.sm(sm, width, conf.level = 0.95, assurance = NULL, certainty=NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ss.aipe.sm_+3A_sm">sm</code></td>
<td>
<p>the population standardized mean </p>
</td></tr>
<tr><td><code id="ss.aipe.sm_+3A_width">width</code></td>
<td>
<p> the desired full width of the obtained confidence interval </p>
</td></tr>
<tr><td><code id="ss.aipe.sm_+3A_conf.level">conf.level</code></td>
<td>
<p>the desired confidence interval coverage, (i.e., 1 - Type I error rate)</p>
</td></tr>
<tr><td><code id="ss.aipe.sm_+3A_assurance">assurance</code></td>
<td>
<p> parameter to ensure that the obtained confidence interval width is 
narrower than the desired width with a specified degree of certainty (must be <code>NULL</code> or between zero and unity) </p>
</td></tr>
<tr><td><code id="ss.aipe.sm_+3A_certainty">certainty</code></td>
<td>
<p>an alias for <code>assurance</code></p>
</td></tr>
<tr><td><code id="ss.aipe.sm_+3A_...">...</code></td>
<td>
<p> allows one to potentially include parameter values for inner functions </p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>n</code></td>
<td>
<p>the necessary sample size in order to achieve the desired degree of accuracy (i.e., the sufficiently narrow confidence interval)</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p> Ken Kelley (University of Notre Dame; <a href="mailto:KKelley@ND.Edu">KKelley@ND.Edu</a>); Keke Lai</p>


<h3>References</h3>

 
<p>Cumming, G. &amp; Finch, S. (2001). A primer on the understanding, use, and calculation of confidence intervals that are
based on central and noncentral distributions, <em>Educational and Psychological Measurement, 61</em>, 532&ndash;574.
</p>
<p>Hedges, L. V. (1981). Distribution theory for Glass's Estimator of effect size and related estimators. <em>Journal of Educational Statistics, 2</em>, 107&ndash;128.
</p>
<p>Kelley, K. (2005). The effects of nonnormal distributions on confidence intervals around the standardized mean
difference: Bootstrap and parametric confidence intervals, <em>Educational and Psychological Measurement, 65</em>, 51&ndash;69.
</p>
<p>Kelley, K. (2007). Constructing confidence intervals for standardized effect sizes: Theory, application, and implementation. <em>Journal of Statistical Software, 20</em> (8), 1&ndash;24.
</p>
<p>Kelley, K., &amp; Rausch, J. R. (2006). Sample size planning for the standardized mean difference: 
Accuracy in Parameter Estimation via narrow confidence intervals. <em>Psychological Methods, 11(4)</em>, 363&ndash;385.
</p>
<p>Steiger, J. H., &amp; Fouladi, R. T. (1997). Noncentrality interval estimation and the evaluation of
statistical methods. In L. L. Harlow, S. A. Mulaik,&amp; J.H. Steiger (Eds.), <em>What if there were
no significance tests?</em> (pp. 221&ndash;257). Mahwah, NJ: Lawrence Erlbaum. </p>


<h3>See Also</h3>

 <p><code>conf.limit.nct</code>, <code>ci.sm</code> </p>


<h3>Examples</h3>

<pre><code class='language-R'># Suppose the population mean is believed to be 20, and the population
# standard deviation is believed to be 2; thus the population standardized
# mean is believed to be 10. To determine the necessary sample size for a 
# study so that the full width of the 95 percent confidence interval 
# obtained in the study will be, with 90% assurance, no wider than 2.5, 
# the function should be specified as follows. 

# ss.aipe.sm(sm=10, width=2.5, conf.level=.95, assurance=.90)
</code></pre>

<hr>
<h2 id='ss.aipe.sm.sensitivity'>Sensitivity analysis for sample size planning for the standardized mean from the Accuracy in Parameter Estimation (AIPE) 
Perspective </h2><span id='topic+ss.aipe.sm.sensitivity'></span>

<h3>Description</h3>

<p>Performs a sensitivity analysis when planning sample size from the Accuracy in Parameter Estimation (AIPE) 
Perspective for the standardized mean.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ss.aipe.sm.sensitivity(true.sm = NULL, estimated.sm = NULL, 
desired.width = NULL, selected.n = NULL, assurance = NULL, 
certainty=NULL, conf.level = 0.95, G = 10000, print.iter = TRUE, 
detail = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ss.aipe.sm.sensitivity_+3A_true.sm">true.sm</code></td>
<td>
<p> population standardized mean </p>
</td></tr>
<tr><td><code id="ss.aipe.sm.sensitivity_+3A_estimated.sm">estimated.sm</code></td>
<td>
<p> estimated standardized mean </p>
</td></tr>
<tr><td><code id="ss.aipe.sm.sensitivity_+3A_desired.width">desired.width</code></td>
<td>
<p> desired full width of the confidence interval for the population standardized mean </p>
</td></tr>
<tr><td><code id="ss.aipe.sm.sensitivity_+3A_selected.n">selected.n</code></td>
<td>
<p> selected sample size to use in order to determine distributional properties of a given value of sample size </p>
</td></tr>
<tr><td><code id="ss.aipe.sm.sensitivity_+3A_assurance">assurance</code></td>
<td>
<p> parameter to ensure that the obtained confidence interval width is narrower 
than the desired width with a specified degree of certainty (must be <code>NULL</code> or between zero and unity) </p>
</td></tr>
<tr><td><code id="ss.aipe.sm.sensitivity_+3A_certainty">certainty</code></td>
<td>
<p>an alias for <code>assurance</code></p>
</td></tr>
<tr><td><code id="ss.aipe.sm.sensitivity_+3A_conf.level">conf.level</code></td>
<td>
<p>the desired confidence interval coverage, (i.e., 1 - Type I error rate)</p>
</td></tr>
<tr><td><code id="ss.aipe.sm.sensitivity_+3A_g">G</code></td>
<td>
<p> number of generations (i.e., replications) of the simulation</p>
</td></tr>
<tr><td><code id="ss.aipe.sm.sensitivity_+3A_print.iter">print.iter</code></td>
<td>
<p> to print the current value of the iterations</p>
</td></tr>
<tr><td><code id="ss.aipe.sm.sensitivity_+3A_detail">detail</code></td>
<td>
<p>whether the user needs a detailed (<code>TRUE</code>) or brief (<code>FALSE</code>) report of the simulation results; the 
detailed report includes all the raw data in the simulations</p>
</td></tr>
<tr><td><code id="ss.aipe.sm.sensitivity_+3A_...">...</code></td>
<td>
<p> allows one to potentially include parameter values for inner functions </p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>sm.obs</code></td>
<td>
<p>vector of the observed standardized mean</p>
</td></tr>
<tr><td><code>Full.Width</code></td>
<td>
<p>vector of the full confidence interval width</p>
</td></tr>
<tr><td><code>Width.from.sm.obs.Lower</code></td>
<td>
<p>vector of the lower confidence interval width</p>
</td></tr>
<tr><td><code>Width.from.sm.obs.Upper</code></td>
<td>
<p>vector of the upper confidence interval width</p>
</td></tr>
<tr><td><code>Type.I.Error.Upper</code></td>
<td>
<p>iterations where a Type I error occurred on the upper end of the confidence interval</p>
</td></tr>
<tr><td><code>Type.I.Error.Lower</code></td>
<td>
<p>iterations where a Type I error occurred on the lower end of the confidence interval</p>
</td></tr>
<tr><td><code>Type.I.Error</code></td>
<td>
<p>iterations where a Type I error happens</p>
</td></tr>
<tr><td><code>Lower.Limit</code></td>
<td>
<p>the lower limit of the obtained confidence interval</p>
</td></tr>
<tr><td><code>Upper.Limit</code></td>
<td>
<p>the upper limit of the obtained confidence interval</p>
</td></tr>
<tr><td><code>replications</code></td>
<td>
<p>number of replications of the simulation</p>
</td></tr>
<tr><td><code>True.sm</code></td>
<td>
<p>the population standardized mean</p>
</td></tr>
<tr><td><code>Estimated.sm</code></td>
<td>
<p>the estimated standardized mean</p>
</td></tr>
<tr><td><code>Desired.Width</code></td>
<td>
<p>the desired full confidence interval width</p>
</td></tr>
<tr><td><code>assurance</code></td>
<td>
<p>parameter to ensure that the obtained confidence interval width is narrower than the desired width with a specified degree of certainty</p>
</td></tr>
<tr><td><code>Sample.Size</code></td>
<td>
<p>the sample size used in the simulation</p>
</td></tr>
<tr><td><code>mean.full.width</code></td>
<td>
<p>mean width of the obtained full confidence intervals</p>
</td></tr>
<tr><td><code>median.full.width</code></td>
<td>
<p>median width of the obtained full confidence intervals</p>
</td></tr>
<tr><td><code>sd.full.width</code></td>
<td>
<p>standard deviation of the widths of the obtained full confidence intervals</p>
</td></tr>
<tr><td><code>Pct.Width.obs.NARROWER.than.desired</code></td>
<td>
<p>percentage of the obtained full confidence interval widths that are narrower than the desired width </p>
</td></tr>
<tr><td><code>mean.Width.from.sm.obs.Lower</code></td>
<td>
<p>mean lower width of the obtained confidence intervals</p>
</td></tr>
<tr><td><code>mean.Width.from.sm.obs.Upper</code></td>
<td>
<p>mean upper width of the obtained confidence intervals</p>
</td></tr>
<tr><td><code>Type.I.Error.Upper</code></td>
<td>
<p>Type I error rate from the upper side</p>
</td></tr>
<tr><td><code>Type.I.Error.Lower</code></td>
<td>
<p>Type I error rate from the lower side</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p> Ken Kelley (University of Notre Dame; <a href="mailto:KKelley@ND.Edu">KKelley@ND.Edu</a>); Keke Lai</p>


<h3>References</h3>

<p>Cumming, G. &amp; Finch, S. (2001). A primer on the understanding, use, and calculation of confidence intervals that are
based on central and noncentral distributions, <em>Educational and Psychological Measurement, 61</em>, 532&ndash;574.
</p>
<p>Hedges, L. V. (1981). Distribution theory for Glass's Estimator of effect size and related estimators. <em>Journal of Educational Statistics, 2</em>, 107&ndash;128.
</p>
<p>Kelley, K. (2005). The effects of nonnormal distributions on confidence intervals around the standardized mean
difference: Bootstrap and parametric confidence intervals, <em>Educational and Psychological Measurement, 65</em>, 51&ndash;69.
</p>
<p>Kelley, K. (2007). Constructing confidence intervals for standardized effect sizes: Theory, application, 
and implementation. <em>Journal of Statistical Software, 20</em> (8), 1&ndash;24.
</p>
<p>Kelley, K., &amp; Rausch, J. R. (2006). Sample size planning for the standardized mean difference: 
Accuracy in Parameter Estimation via narrow confidence intervals. <em>Psychological Methods, 11(4)</em>, 363&ndash;385.
</p>
<p>Steiger, J. H., &amp; Fouladi, R. T. (1997). Noncentrality interval estimation and the evaluation of
statistical methods. In L. L. Harlow, S. A. Mulaik, &amp; J.H. Steiger (Eds.), <em>What if there were
no significance tests?</em> (pp. 221&ndash;257). Mahwah, NJ: Lawrence Erlbaum. </p>


<h3>See Also</h3>

 <p><code>ss.aipe.sm</code></p>


<h3>Examples</h3>

<pre><code class='language-R'># Since 'true.sm' equals 'estimated.sm', this usage
# returns the results of a correctly specified situation.
# Note that 'G' should be large (10 is used to make the 
# example run easily)
# Res.1 &lt;- ss.aipe.sm.sensitivity(true.sm=10, estimated.sm=10, 
# desired.width=.5, assurance=.95, conf.level=.95, G=10,
# print.iter=FALSE)

# Lists contained in Res.1.
# names(Res.1) 

#Objects contained in the 'Results' lists.
# names(Res.1$Results) 

#How many obtained full widths are narrower than the desired one?
# Res.1$Summary$Pct.Width.obs.NARROWER.than.desired

# True standardized mean difference is 10, but specified at 12.
# Change 'G' to some large number (e.g., G=20)
# Res.2 &lt;- ss.aipe.sm.sensitivity(true.sm=10, estimated.sm=12, 
# desired.width=.5, assurance=NULL, conf.level=.95, G=20)

# The effect of the misspecification on mean confidence intervals is:
# Res.2$Summary$mean.full.width

</code></pre>

<hr>
<h2 id='ss.aipe.smd'>Sample size planning for the standardized mean difference from the 
Accuracy in Parameter Estimation (AIPE) perspective
</h2><span id='topic+ss.aipe.smd'></span>

<h3>Description</h3>

<p>A function to calculate the appropriate sample size for the standardized mean difference such that 
the expected value of the confidence interval is sufficiently narrow, optionally with a 
<code>degree.of.certainty</code>.</p>


<h3>Usage</h3>

<pre><code class='language-R'>ss.aipe.smd(delta, conf.level, width, which.width="Full", 
degree.of.certainty=NULL, assurance=NULL, certainty=NULL, ...)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ss.aipe.smd_+3A_delta">delta</code></td>
<td>
<p>the population value of the standardized mean difference</p>
</td></tr>
<tr><td><code id="ss.aipe.smd_+3A_conf.level">conf.level</code></td>
<td>
<p>the desired degree of confidence (i.e., 1-Type I error rate)</p>
</td></tr>
<tr><td><code id="ss.aipe.smd_+3A_width">width</code></td>
<td>
<p>desired width of the specified (i.e., <code>Full</code>, <code>Lower</code>, and <code>Upper</code> widths) region of the confidence interval</p>
</td></tr>
<tr><td><code id="ss.aipe.smd_+3A_which.width">which.width</code></td>
<td>
<p>the width that the <code>width</code> argument refers identifies the width of interest (i.e., <code>Full</code>, <code>Lower</code>, and <code>Upper</code> widths)</p>
</td></tr>
<tr><td><code id="ss.aipe.smd_+3A_degree.of.certainty">degree.of.certainty</code></td>
<td>
<p>parameter to ensure confidence interval width with a specified degree of certainty</p>
</td></tr>
<tr><td><code id="ss.aipe.smd_+3A_assurance">assurance</code></td>
<td>
<p> an alias for <code>degree.of.certainty</code> </p>
</td></tr>
<tr><td><code id="ss.aipe.smd_+3A_certainty">certainty</code></td>
<td>
<p>an alias for <code>degree.of.certainty</code></p>
</td></tr>
<tr><td><code id="ss.aipe.smd_+3A_...">...</code></td>
<td>
<p>for modifying parameters of functions this function calls upon</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns the necessary sample size <em>per group</em> in order to achieve the desired 
degree of accuracy (i.e., the sufficiently narrow confidence interval).
</p>


<h3>Warning</h3>

<p>Finding sample size for lower and uppper confidence limits is approximate, but very close to being exact. The <code>pt()</code> function is limited to accurate values 
when the the noncentral parameter is less than 37.62.</p>


<h3>Note</h3>

<p>The function <code>ss.aipe.smd</code> is the preferred function, and is the one that is recommended for widespread use.
The functions <code>ss.aipe.smd.lower</code>, <code>ss.aipe.smd.upper</code> and 
<code>ss.aipe.smd.full</code> are called from the <code>ss.aipe.smd</code> function.</p>


<h3>Author(s)</h3>

<p>Ken Kelley (University of Notre Dame; <a href="mailto:KKelley@ND.Edu">KKelley@ND.Edu</a>)</p>


<h3>References</h3>

<p>Cohen, J. (1988). Statistical power analysis for the behavioral sciences (2nd ed.). Hillsdale, NJ: Lawrence Erlbaum.
</p>
<p>Cumming, G. &amp; Finch, S. (2001). A primer on the understanding, use, and calculation of confidence intervals that are
based on central and noncentral distributions, <em>Educational and Psychological Measurement, 61</em>, 532&ndash;574.
</p>
<p>Hedges, L. V. (1981). Distribution theory for Glass's Estimator of effect size and related estimators. <em>Journal of Educational Statistics, 2</em>, 107&ndash;128.
</p>
<p>Kelley, K. (2005). The effects of nonnormal distributions on confidence intervals around the standardized mean
difference: Bootstrap and parametric confidence intervals, <em>Educational and Psychological Measurement, 65</em>, 51&ndash;69.
</p>
<p>Kelley, K., Maxwell, S. E., &amp; Rausch, J. R. (2003). Obtaining Power or Obtaining Precision: Delineating Methods
of Sample-Size Planning, <em>Evaluation and the Health Professions, 26</em>, 258&ndash;287.
</p>
<p>Kelley, K., &amp; Rausch, J. R. (2006). Sample size planning for the standardized mean difference: 
Accuracy in Parameter Estimation via narrow confidence intervals. <em>Psychological Methods, 11(4)</em>, 363&ndash;385.
</p>
<p>Steiger, J. H., &amp; Fouladi, R. T. (1997) Noncentrality interval estimation and the evaluation of
statistical methods. In L. L. Harlow, S. A. Mulaik, &amp; J. H. Steiger (Eds.), <em>What if there where
no significance tests?</em> (pp. 221-257). Mahwah, NJ: Lawrence Erlbaum.
</p>


<h3>See Also</h3>

<p><code>smd</code>, <code>smd.c</code>, <code>ci.smd</code>, <code>ci.smd.c</code>, 
<code>conf.limits.nct</code>, <code>power.t.test</code>, <code>ss.aipe.smd.lower</code>, 
<code>ss.aipe.smd.upper</code>, <code>ss.aipe.smd.full</code></p>


<h3>Examples</h3>

<pre><code class='language-R'># ss.aipe.smd(delta=.5, conf.level=.95, width=.30)
# ss.aipe.smd(delta=.5, conf.level=.95, width=.30, degree.of.certainty=.8)
# ss.aipe.smd(delta=.5, conf.level=.95, width=.30, degree.of.certainty=.95)
</code></pre>

<hr>
<h2 id='ss.aipe.smd.sensitivity'>Sensitivity analysis for sample size given the Accuracy in Parameter Estimation approach for the standardized mean difference.</h2><span id='topic+ss.aipe.smd.sensitivity'></span>

<h3>Description</h3>

<p>Performs sensitivity analysis for sample size determination for the standardized mean difference 
given a population and a standardized mean difference. Allows one to determine the effect of being
wrong when estimating the population standardized mean difference in terms of the 
width of the obtained (two-sided) confidence intervals. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ss.aipe.smd.sensitivity(true.delta = NULL, estimated.delta = NULL, 
desired.width = NULL, selected.n=NULL, assurance=NULL, certainty = NULL, 
conf.level = 0.95, G = 10000, print.iter = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ss.aipe.smd.sensitivity_+3A_true.delta">true.delta</code></td>
<td>
<p>population standardized mean difference</p>
</td></tr>
<tr><td><code id="ss.aipe.smd.sensitivity_+3A_estimated.delta">estimated.delta</code></td>
<td>
<p>estimated standardized mean difference; can be <code>true.delta</code> to perform standard simulations</p>
</td></tr>
<tr><td><code id="ss.aipe.smd.sensitivity_+3A_desired.width">desired.width</code></td>
<td>
<p>describe full width for the confidence interval around the population standardized mean difference</p>
</td></tr>
<tr><td><code id="ss.aipe.smd.sensitivity_+3A_selected.n">selected.n</code></td>
<td>
<p>selected sample size to use in order to determine distributional properties of at a given value of sample size</p>
</td></tr>
<tr><td><code id="ss.aipe.smd.sensitivity_+3A_assurance">assurance</code></td>
<td>
<p>parameter to ensure confidence interval width with a specified degree of certainty (must 
be <code>NULL</code> or between zero and unity)</p>
</td></tr>
<tr><td><code id="ss.aipe.smd.sensitivity_+3A_certainty">certainty</code></td>
<td>
<p>an alias for <code>assurance</code></p>
</td></tr>
<tr><td><code id="ss.aipe.smd.sensitivity_+3A_conf.level">conf.level</code></td>
<td>
<p>the desired degree of confidence (i.e., 1-Type I error rate).</p>
</td></tr>
<tr><td><code id="ss.aipe.smd.sensitivity_+3A_g">G</code></td>
<td>
<p>number of generations (i.e., replications) of the simulation</p>
</td></tr>
<tr><td><code id="ss.aipe.smd.sensitivity_+3A_print.iter">print.iter</code></td>
<td>
<p>to print the current value of the iterations</p>
</td></tr>
<tr><td><code id="ss.aipe.smd.sensitivity_+3A_...">...</code></td>
<td>
<p>for modifying parameters of functions this function calls</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For sensitivity analysis when planning sample size given the desire to obtain narrow confidence intervals
for the population standardized mean difference. Given a population value and an estimated value, one can determine
the effects of incorrectly specifying the population standardized mean difference (<code>true.delta</code>) on the 
obtained widths of the confidence intervals. Also, one can evaluate the percent of the confidence intervals
that are less than the desired width (especially when modifying the <code>certainty</code> parameter); see <code>ss.aipe.smd</code>)
</p>
<p>Alternatively, one can specify <code>selected.n</code> to determine the results at a particular sample size (when doing this <code>estimated.delta</code> cannot be specified).
</p>


<h3>Value</h3>

<table>
<tr><td><code>Results</code></td>
<td>
<p>list of the results in <code>G</code>-length vector form</p>
</td></tr>
<tr><td><code>Specifications</code></td>
<td>
<p>specification of the function</p>
</td></tr>
<tr><td><code>Summary</code></td>
<td>
<p>summary measures of some important descriptive statistics</p>
</td></tr>
<tr><td><code>d</code></td>
<td>
<p>contained in <code>Results</code> list: vector of the observed <code>d</code> values</p>
</td></tr>
<tr><td><code>Full.Width</code></td>
<td>
<p>contained in <code>Results</code> list: vector of </p>
</td></tr>
<tr><td><code>Width.from.d.Upper</code></td>
<td>
<p>contained in <code>Results</code> list: vector of the observed upper widths of the confidence interval (upper limit minus observed standardized mean difference)</p>
</td></tr>
<tr><td><code>Width.from.d.Lower</code></td>
<td>
<p>contained in <code>Results</code> list: vector of the observed lower widths of the confidence interval (standardized mean difference minus lower limit)</p>
</td></tr>
<tr><td><code>Type.I.Error.Upper</code></td>
<td>
<p>contained in <code>Results</code> list: iterations where a Type I error occurred on the upper end of the confidence interval</p>
</td></tr>
<tr><td><code>Type.I.Error.Lower</code></td>
<td>
<p>contained in <code>Results</code> list: iterations where a Type I error occurred on the lower end of the confidence interval</p>
</td></tr>
<tr><td><code>Type.I.Error</code></td>
<td>
<p>contained in <code>Results</code> list: iterations where a Type I error occurred</p>
</td></tr>
<tr><td><code>Upper.Limit</code></td>
<td>
<p>contained in <code>Results</code> list: vector of the obtained upper limits from the simulation</p>
</td></tr>
<tr><td><code>Low.Limit</code></td>
<td>
<p>contained in <code>Results</code> list: vector of the obtained lower limits from the simulation</p>
</td></tr>
<tr><td><code>replications</code></td>
<td>
<p>contained in <code>Specifications</code> list: number of generations (i.e., replication) of the simulation</p>
</td></tr>
<tr><td><code>true.delta</code></td>
<td>
<p>contained in <code>Specifications</code> list: population value of the standardized mean difference</p>
</td></tr>
<tr><td><code>estimated.delta</code></td>
<td>
<p>contained in <code>Specifications</code> list: value of the population (mis)specified for purposes of sample size planning</p>
</td></tr>
<tr><td><code>desired.width</code></td>
<td>
<p>contained in <code>Specifications</code> list: desired full width of the confidence interval around the population standardized mean difference</p>
</td></tr>
<tr><td><code>certainty</code></td>
<td>
<p>contained in <code>Specifications</code> list: desired degree of certainty that the obtained confidence interval width is less than the value specified</p>
</td></tr>
<tr><td><code>n.j</code></td>
<td>
<p>contained in <code>Specifications</code> list: sample size per group given the specifications</p>
</td></tr>
<tr><td><code>mean.full.width</code></td>
<td>
<p>contained in <code>Summary</code> list: mean width of the obtained confidence intervals</p>
</td></tr>
<tr><td><code>median.full.width</code></td>
<td>
<p>contained in <code>Summary</code> list: median width of the obtained confidence intervals</p>
</td></tr>
<tr><td><code>sd.full.width</code></td>
<td>
<p>contained in <code>Summary</code> list: standard deviation of the obtained confidence intervals</p>
</td></tr>
<tr><td><code>Pct.Less.Desired</code></td>
<td>
<p>contained in <code>Summary</code> list: Percent of the confidence widths less than the width specified.</p>
</td></tr>
<tr><td><code>mean.Width.from.d.Lower</code></td>
<td>
<p>contained in <code>Summary</code> list:mean width of the lower portion of the confidence interval (from d)</p>
</td></tr>
<tr><td><code>mean.Width.from.d.Upper</code></td>
<td>
<p>contained in <code>Summary</code> list:mean width of the upper portion of the confidence interval (from d)</p>
</td></tr>
<tr><td><code>Type.I.Error.Upper</code></td>
<td>
<p>contained in <code>Summary</code> list: Type I error rate from the upper side</p>
</td></tr>
<tr><td><code>Type.I.Error.Lower</code></td>
<td>
<p>contained in <code>Summary</code> list: Type I error rate from the lower side</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Returns three lists, where each list has multiple components.</p>


<h3>Author(s)</h3>

<p>Ken Kelley (University of Notre Dame; <a href="mailto:KKelley@ND.Edu">KKelley@ND.Edu</a>)</p>


<h3>References</h3>

<p>Cumming, G. &amp; Finch, S. (2001). A primer on the understanding, use, and calculation of confidence intervals that are
based on central and noncentral distributions, <em>Educational and Psychological Measurement, 61</em>, 532&ndash;574.
</p>
<p>Hedges, L. V. (1981). Distribution theory for Glass's Estimator of effect size and related estimators. <em>Journal of Educational Statistics, 2</em>, 107&ndash;128.
</p>
<p>Kelley, K. (2005). The effects of nonnormal distributions on confidence intervals around the standardized mean
difference: Bootstrap and parametric confidence intervals, <em>Educational and Psychological Measurement, 65</em>, 51&ndash;69.
</p>
<p>Steiger, J. H., &amp; Fouladi, R. T. (1997). Noncentrality interval estimation and the evaluation of
statistical methods. In L. L. Harlow, S. A. Mulaik, &amp; J.H. Steiger (Eds.), <em>What if there were
no significance tests?</em> (pp. 221&ndash;257). Mahwah, NJ: Lawrence Erlbaum.
</p>


<h3>See Also</h3>

<p><code>ss.aipe.smd</code></p>


<h3>Examples</h3>

<pre><code class='language-R'># Since 'true.delta' equals 'estimated.delta', this usage 
# returns the results of a correctly specified situation.
# Note that 'G' should be large (50 is used to make the example run easily)
# Res.1 &lt;- ss.aipe.smd.sensitivity(true.delta=.5, estimated.delta=.5, 
# desired.width=.30, certainty=NULL, conf.level=.95, G=50,
# print.iter=FALSE)

# Lists contained in Res.1.
# names(Res.1) 

#Objects contained in the 'Results' lists.
# names(Res.1$Results) 

#Extract d from the Results list of Res.1.
# d &lt;- Res.1$Results$d 

# hist(d)

# Pull out summary measures
# Res.1$Summary

# True standardized mean difference is .4, but specified at .5.
# Change 'G' to some large number (e.g., G=5,000)
# Res.2 &lt;- ss.aipe.smd.sensitivity(true.delta=.4, estimated.delta=.5, 
# desired.width=.30, certainty=NULL, conf.level=.95, G=50, 
# print.iter=FALSE)

# The effect of the misspecification on mean confidence intervals is:
# Res.2$Summary$mean.full.width

# True standardized mean difference is .5, but specified at .4.
# Res.3 &lt;- ss.aipe.smd.sensitivity(true.delta=.5, estimated.delta=.4, 
# desired.width=.30, certainty=NULL, conf.level=.95, G=50, 
# print.iter=FALSE)

# The effect of the misspecification on mean confidence intervals is:
# Res.3$Summary$mean.full.width
</code></pre>

<hr>
<h2 id='ss.aipe.src'> sample size necessary for the accuracy in parameter estimation approach for a standardized regression coefficient of interest </h2><span id='topic+ss.aipe.src'></span>

<h3>Description</h3>

<p>A function used to plan sample size from the accuracy in parameter estimation approach for a standardized
regression coefficient of interest given the input specification.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ss.aipe.src(Rho2.Y_X = NULL, Rho2.k_X.without.k = NULL, K = NULL, 
beta.k = NULL, width, which.width = "Full", sigma.Y = 1, sigma.X.k = 1, 
RHO.XX = NULL, Rho.YX = NULL, which.predictor = NULL, 
alpha.lower = NULL, alpha.upper = NULL, conf.level = .95, 
degree.of.certainty = NULL, assurance=NULL, certainty=NULL, 
Suppress.Statement = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ss.aipe.src_+3A_rho2.y_x">Rho2.Y_X</code></td>
<td>
<p> Population value of the squared multiple correlation coefficient </p>
</td></tr>
<tr><td><code id="ss.aipe.src_+3A_rho2.k_x.without.k">Rho2.k_X.without.k</code></td>
<td>
<p> Population value of the squared multiple correlation coefficient predicting the
<em>k</em>th predictor variable from the remaining <em>p</em>-1 predictor variables </p>
</td></tr>
<tr><td><code id="ss.aipe.src_+3A_k">K</code></td>
<td>
<p> the number of predictor variables </p>
</td></tr>
<tr><td><code id="ss.aipe.src_+3A_beta.k">beta.k</code></td>
<td>
<p> the regression coefficient for the <em>k</em>th predictor variable (i.e., the predictor of
interest) </p>
</td></tr>
<tr><td><code id="ss.aipe.src_+3A_width">width</code></td>
<td>
<p> the desired width of the confidence interval </p>
</td></tr>
<tr><td><code id="ss.aipe.src_+3A_which.width">which.width</code></td>
<td>
<p> which width (<code>"Full"</code>, <code>"Lower"</code>, or <code>"Upper"</code>) the width refers 
to (at present, only <code>"Full"</code> can be specified) </p>
</td></tr>
<tr><td><code id="ss.aipe.src_+3A_sigma.y">sigma.Y</code></td>
<td>
<p> the population standard deviation of <em>Y</em> (i.e., the dependent variables) </p>
</td></tr>
<tr><td><code id="ss.aipe.src_+3A_sigma.x.k">sigma.X.k</code></td>
<td>
<p> the population standard deviation of the <em>k</em>th <em>X</em> variable (i.e., the 
predictor variable of interest) </p>
</td></tr>
<tr><td><code id="ss.aipe.src_+3A_rho.xx">RHO.XX</code></td>
<td>
<p> Population correlation matrix for the <em>p</em> predictor variables </p>
</td></tr>
<tr><td><code id="ss.aipe.src_+3A_rho.yx">Rho.YX</code></td>
<td>
<p> Population <em>p</em> length vector of correlation between the dependent variable (<em>Y</em>)
and the <em>p</em> independent variables </p>
</td></tr>
<tr><td><code id="ss.aipe.src_+3A_which.predictor">which.predictor</code></td>
<td>
<p> identifies which of the <em>p</em> predictors is of interest </p>
</td></tr>
<tr><td><code id="ss.aipe.src_+3A_alpha.lower">alpha.lower</code></td>
<td>
<p> Type I error rate for the lower confidence interval limit </p>
</td></tr>
<tr><td><code id="ss.aipe.src_+3A_alpha.upper">alpha.upper</code></td>
<td>
<p> Type I error rate for the upper confidence interval limit </p>
</td></tr>
<tr><td><code id="ss.aipe.src_+3A_conf.level">conf.level</code></td>
<td>
<p> desired level of confidence for the computed interval (i.e., 1 - the Type I error
rate) </p>
</td></tr>
<tr><td><code id="ss.aipe.src_+3A_degree.of.certainty">degree.of.certainty</code></td>
<td>
<p> degree of certainty that the obtained confidence interval will be sufficiently narrow, which 
yields an approximate sample size to be verified with function <code>ss.aipe.reg.coef.sensitivity</code>
to determine if it is appropriate. </p>
</td></tr>
<tr><td><code id="ss.aipe.src_+3A_assurance">assurance</code></td>
<td>
<p> an alias for <code>degree.of.certainty</code> </p>
</td></tr>
<tr><td><code id="ss.aipe.src_+3A_certainty">certainty</code></td>
<td>
<p>an alias for <code>degree.of.certainty</code></p>
</td></tr>
<tr><td><code id="ss.aipe.src_+3A_suppress.statement">Suppress.Statement</code></td>
<td>
 <p><code>TRUE/FALSE</code> statement whether or not a sentence describing the situation defined
is printed with the necessary sample size </p>
</td></tr>
</table>


<h3>Details</h3>

<p>Not all of the arguments need to be specified, only those that provide all of the necessary information
so that the sample size can be determined for the conditions specified.
</p>


<h3>Value</h3>

<p>Returns the necessary sample size in order for the goals of accuracy in parameter estimation to be
satisfied for the confidence interval for a particular regression coefficient given the input specifications.
</p>


<h3>Warning </h3>

<p>As discussed in Kelley and Maxwell (2008), the sample size planning approach from the AIPE perspective used in this function is only an approximation.</p>


<h3>Note</h3>

<p>This function calls upon <code><a href="#topic+ss.aipe.reg.coef">ss.aipe.reg.coef</a></code> in MBESS but has a different naming 
scheme. See <code><a href="#topic+ss.aipe.reg.coef">ss.aipe.reg.coef</a></code> for more details.</p>


<h3>Author(s)</h3>

<p>Ken Kelley (University of Notre Dame; <a href="mailto:KKelley@ND.Edu">KKelley@ND.Edu</a>)</p>


<h3>References</h3>

 
<p>Kelley, K. &amp; Maxwell, S. E. (2003). Sample size for Multiple Regression: Obtaining regression
coefficients that are accurate, not simply significant. <em>Psychological Methods, 8</em>, 305&ndash;321.
</p>
<p>Kelley, K. &amp; Maxwell, S. E. (2008). Sample Size Planning with applications to multiple regression: Power and accuracy for omnibus and targeted effects. In P. Alasuuta, J. Brannen, &amp; L. Bickman (Eds.), <em>The Sage handbook of social research methods</em> (pp. 166&ndash;192). Newbury Park, CA: Sage.
</p>


<h3>See Also</h3>

 <p><code>ss.aipe.reg.coef.sensitivity</code>, <code>conf.limits.nct</code>, 
<code>ss.aipe.reg.coef</code>, <code>ss.aipe.rc</code> </p>


<h3>Examples</h3>

<pre><code class='language-R'># Exchangable correlation structure
# Rho.YX &lt;- c(.3, .3, .3, .3, .3)
# RHO.XX &lt;- rbind(c(1, .5, .5, .5, .5), c(.5, 1, .5, .5, .5), c(.5, .5, 1, .5, .5),
# c(.5, .5, .5, 1, .5), c(.5, .5, .5, .5, 1))

# ss.aipe.src(width=.1, which.width="Full", sigma.Y=1, sigma.X=1, RHO.XX=RHO.XX,
# Rho.YX=Rho.YX, which.predictor=1, conf.level=1-.05)

# ss.aipe.src(width=.1, which.width="Full", sigma.Y=1, sigma.X=1, RHO.XX=RHO.XX,
# Rho.YX=Rho.YX, which.predictor=1, conf.level=1-.05, degree.of.certainty=.85)
</code></pre>

<hr>
<h2 id='ss.aipe.src.sensitivity'>Sensitivity analysis for sample size planing from the Accuracy in Parameter
Estimation Perspective for the standardized regression coefficient</h2><span id='topic+ss.aipe.src.sensitivity'></span>

<h3>Description</h3>

<p>Performs a sensitivity analysis when planning sample size from the Accuracy in Parameter Estimation
Perspective for the standardized regression coefficient.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ss.aipe.src.sensitivity(True.Var.Y = NULL, True.Cov.YX = NULL, 
True.Cov.XX = NULL, Estimated.Var.Y = NULL, Estimated.Cov.YX = NULL, 
Estimated.Cov.XX = NULL, Specified.N = NULL, which.predictor = 1, 
w = NULL, Noncentral = TRUE, Standardize = TRUE, conf.level = 0.95, 
degree.of.certainty = NULL, assurance=NULL, certainty=NULL,
 G = 1000, print.iter = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ss.aipe.src.sensitivity_+3A_true.var.y">True.Var.Y</code></td>
<td>
<p> Population variance of the dependent variable (<em>Y</em>) </p>
</td></tr>
<tr><td><code id="ss.aipe.src.sensitivity_+3A_true.cov.yx">True.Cov.YX</code></td>
<td>
<p> Population covariances vector between the p predictor variables and the dependent
variable (<em>Y</em>) </p>
</td></tr>
<tr><td><code id="ss.aipe.src.sensitivity_+3A_true.cov.xx">True.Cov.XX</code></td>
<td>
<p> Population covariance matrix of the <em>p</em> predictor variables </p>
</td></tr>
<tr><td><code id="ss.aipe.src.sensitivity_+3A_estimated.var.y">Estimated.Var.Y</code></td>
<td>
<p> Estimated variance of the dependent variable (<em>Y</em>) </p>
</td></tr>
<tr><td><code id="ss.aipe.src.sensitivity_+3A_estimated.cov.yx">Estimated.Cov.YX</code></td>
<td>
<p>Estimated covariances vector between the <em>p</em> predictor variables and the dependent
variable (<em>Y</em>) </p>
</td></tr>
<tr><td><code id="ss.aipe.src.sensitivity_+3A_estimated.cov.xx">Estimated.Cov.XX</code></td>
<td>
<p> Estimated Population covariance matrix of the <em>p</em> predictor variables </p>
</td></tr>
<tr><td><code id="ss.aipe.src.sensitivity_+3A_specified.n">Specified.N</code></td>
<td>
<p>Directly specified sample size (instead of using <code>Estimated.Rho.YX</code> and
<code>Estimated.RHO.XX</code>)</p>
</td></tr>
<tr><td><code id="ss.aipe.src.sensitivity_+3A_which.predictor">which.predictor</code></td>
<td>
<p> identifies which of the <em>p</em> predictors is of interest </p>
</td></tr>
<tr><td><code id="ss.aipe.src.sensitivity_+3A_w">w</code></td>
<td>
<p> desired confidence interval width for the regression coefficient of interest </p>
</td></tr>
<tr><td><code id="ss.aipe.src.sensitivity_+3A_noncentral">Noncentral</code></td>
<td>
<p> specify with a <code>TRUE</code> or <code>FALSE</code> statement whether or not the noncentral approach
to sample size planning should be used</p>
</td></tr>
<tr><td><code id="ss.aipe.src.sensitivity_+3A_standardize">Standardize</code></td>
<td>
<p> specify with a <code>TRUE</code> or <code>FALSE</code> statement whether or not the regression coefficient
will be standardized; default is <code>TRUE</code>  </p>
</td></tr>
<tr><td><code id="ss.aipe.src.sensitivity_+3A_conf.level">conf.level</code></td>
<td>
<p> desired level of confidence for the computed interval (i.e., 1 - the Type I error
rate) </p>
</td></tr>
<tr><td><code id="ss.aipe.src.sensitivity_+3A_degree.of.certainty">degree.of.certainty</code></td>
<td>
<p>degree of certainty that the obtained confidence interval will be sufficiently narrow </p>
</td></tr>
<tr><td><code id="ss.aipe.src.sensitivity_+3A_assurance">assurance</code></td>
<td>
<p> an alias for <code>degree.of.certainty</code> </p>
</td></tr>
<tr><td><code id="ss.aipe.src.sensitivity_+3A_certainty">certainty</code></td>
<td>
<p>an alias for <code>degree.of.certainty</code></p>
</td></tr>
<tr><td><code id="ss.aipe.src.sensitivity_+3A_g">G</code></td>
<td>
<p> the number of generations/replication of the simulation study within the function </p>
</td></tr>
<tr><td><code id="ss.aipe.src.sensitivity_+3A_print.iter">print.iter</code></td>
<td>
<p> specify with a <code>TRUE/FALSE</code> statement if the iteration number should be printed
as the simulation within the function runs </p>
</td></tr>
</table>


<h3>Details</h3>

<p>Direct specification of <code>True.Rho.YX</code> and <code>True.RHO.XX</code> is necessary, even if one is interested in
a single regression coefficient, so that the covariance/correlation structure can be specified when
the simulation study within the function runs.
</p>


<h3>Value</h3>

<table>
<tr><td><code>Results</code></td>
<td>
<p>a matrix containing the empirical results from each of the <code>G</code> replication of the
simulation</p>
</td></tr>
<tr><td><code>Specifications</code></td>
<td>
<p>a list of the input specifications and the required sample size</p>
</td></tr>
<tr><td><code>Summary.of.Results</code></td>
<td>
<p>summary values for the results of the sensitivity analysis (simulation study)
given the input specification</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Note that when <code>True.Rho.YX=Estimated.Rho.YX</code> and <code>True.RHO.XX=Estimated.RHO.XX</code>,
the results are not literally from a sensitivity analysis, rather the function performs a standard simulation
study. A simulation study can be helpful in order to determine if the sample size procedure
under or overestimates necessary sample size.
</p>
<p>See <code>ss.aipe.reg.coef.sensitivity</code> in MBESS for more details.
</p>


<h3>Author(s)</h3>

<p> Ken Kelley (University of Notre Dame; <a href="mailto:KKelley@ND.Edu">KKelley@ND.Edu</a>) </p>


<h3>References</h3>

 
<p>Kelley, K. &amp; Maxwell, S. E. (2003). Sample size for Multiple Regression: Obtaining regression
coefficients that are accurate, not simply significant.<em>Psychological Methods, 8</em>, 305&ndash;321.
</p>


<h3>See Also</h3>

 <p><code>ss.aipe.reg.coef.sensitivity</code>, <code>ss.aipe.rc.sensitivity</code>, 
</p>
<p><code>ss.aipe.reg.coef</code>, <code>ci.reg.coef</code></p>

<hr>
<h2 id='ss.power.pcm'>Sample size planning for power for polynomial change models</h2><span id='topic+ss.power.pcm'></span>

<h3>Description</h3>

<p> Returns power given the sample size, or sample size given the desired power, for polynomial change models  (currently only linear, that is, straight-line, change models)</p>


<h3>Usage</h3>

<pre><code class='language-R'>ss.power.pcm(beta, tau, level.1.variance, frequency, duration, desired.power = NULL, 
N = NULL, alpha.level = 0.05, standardized = TRUE, directional = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ss.power.pcm_+3A_beta">beta</code></td>
<td>
<p> the level two regression coefficient for the group by time (linear) interaction; 
where &quot;X&quot; is coded -.5 and .5 for the two groups. </p>
</td></tr>
<tr><td><code id="ss.power.pcm_+3A_tau">tau</code></td>
<td>
<p> the true variance of the individuals' slopes </p>
</td></tr>
<tr><td><code id="ss.power.pcm_+3A_level.1.variance">level.1.variance</code></td>
<td>
<p> level one variance </p>
</td></tr>
<tr><td><code id="ss.power.pcm_+3A_frequency">frequency</code></td>
<td>
<p> frequency of measurements per unit of time duration of the study in the
particular units (e.g., age, hours, grade level, years, etc.)  </p>
</td></tr>
<tr><td><code id="ss.power.pcm_+3A_duration">duration</code></td>
<td>
<p> time in some number of units (e.g., years) </p>
</td></tr>
<tr><td><code id="ss.power.pcm_+3A_desired.power">desired.power</code></td>
<td>
<p> desired power </p>
</td></tr>
<tr><td><code id="ss.power.pcm_+3A_n">N</code></td>
<td>
<p> total sample size (one-half in each of the two groups) </p>
</td></tr>
<tr><td><code id="ss.power.pcm_+3A_alpha.level">alpha.level</code></td>
<td>
<p> Type I error rate </p>
</td></tr>
<tr><td><code id="ss.power.pcm_+3A_standardized">standardized</code></td>
<td>
<p> the standardized slope is the unstandardized slope divided by the square root of tau, the variance of the unique effects for beta.  </p>
</td></tr>
<tr><td><code id="ss.power.pcm_+3A_directional">directional</code></td>
<td>
<p> should a one (<code>TRUE</code>) or two (<code>FALSE</code>) tailed test be performed.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Ken Kelley (University of Notre Dame; <a href="mailto:KKelley@ND.Edu">KKelley@ND.Edu</a>)</p>


<h3>References</h3>

<p> Raudenbush, S. W., &amp; X-F., Liu. (2001). Effects of study duration, frequency of observation, 
and sample size on power in studies of group differences in polynomial change. <em>Psychological Methods, 6</em>, 387&ndash;401.  </p>


<h3>Examples</h3>

<pre><code class='language-R'># Example from Raudenbush and Liu (2001)
ss.power.pcm(beta=-.4, tau=.003, level.1.variance=.0262, frequency=2, duration=2, 
desired.power=.80, alpha.level=.05, standardized=TRUE, directional=FALSE)
ss.power.pcm(beta=-.4, tau=.003, level.1.variance=.0262, frequency=2, duration=2,
N=238, alpha.level=.05, standardized=TRUE, directional=FALSE)


# The standardized effect size is obtained as beta/sqrt(tau): -.4/sqrt(.003) = -.0219.
# ss.power.pcm(beta=-.0219, tau=.003, level.1.variance=.0262, frequency=2, duration=2, 
# desired.power=.80, alpha.level=.05, standardized=FALSE, directional=FALSE)
ss.power.pcm(beta=-.0219, tau=.003, level.1.variance=.0262, frequency=2, duration=2, 
N=238, alpha.level=.05, standardized=FALSE, directional=FALSE)

</code></pre>

<hr>
<h2 id='ss.power.R2'>Function to plan sample size so that the test of the squared multiple correlation coefficient is sufficiently powerful.</h2><span id='topic+ss.power.R2'></span>

<h3>Description</h3>

<p>Function for determining the necessary sample size for the test of the squared multiple correlation 
coefficient or for determining the statistical power given a specified sample size for 
the squared multiple correlation coefficient in models where the regressors are regarded as fixed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ss.power.R2(Population.R2 = NULL, alpha.level = 0.05, desired.power = 0.85,
p, Specified.N = NULL, Cohen.f2 = NULL, Null.R2 = 0, 
Print.Progress = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ss.power.R2_+3A_population.r2">Population.R2</code></td>
<td>
<p>Population squared multiple correlation coefficient</p>
</td></tr>
<tr><td><code id="ss.power.R2_+3A_alpha.level">alpha.level</code></td>
<td>
<p>Type I error rate</p>
</td></tr>
<tr><td><code id="ss.power.R2_+3A_desired.power">desired.power</code></td>
<td>
<p>desired degree of statistical power</p>
</td></tr>
<tr><td><code id="ss.power.R2_+3A_p">p</code></td>
<td>
<p>the number of predictor variables</p>
</td></tr>
<tr><td><code id="ss.power.R2_+3A_specified.n">Specified.N</code></td>
<td>
<p>the sample size used to calculate power (rather than determine necessary sample size)</p>
</td></tr>
<tr><td><code id="ss.power.R2_+3A_cohen.f2">Cohen.f2</code></td>
<td>
<p>Cohen's (1988) effect size for multiple regression: <code>Population.R2</code>/(1-<code>Population.R2</code>)</p>
</td></tr>
<tr><td><code id="ss.power.R2_+3A_null.r2">Null.R2</code></td>
<td>
<p>value of the null hypothesis that the squared multiple correlation will be evaluated against (this will typically be zero)</p>
</td></tr>
<tr><td><code id="ss.power.R2_+3A_print.progress">Print.Progress</code></td>
<td>
<p>if the progress of the iterative procedure is printed to the screen as the iterations are occuring</p>
</td></tr>
<tr><td><code id="ss.power.R2_+3A_...">...</code></td>
<td>
<p>possible additional parameters for internal functions</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Determine the necessary sample size given a particular <code>Population.R2</code>, <code>alpha.level</code>, <code>p</code>, and <code>desired.power</code>. Alternatively, given <code>Population.R2</code>, <code>alpha.level</code>, <code>p</code>, and <code>Specified.N</code>, the function can be used to determine the statistical power.
</p>


<h3>Value</h3>

<table>
<tr><td><code>Sample.Size</code></td>
<td>
<p>returns either <code>Necessary.Sample.Size</code> or <code>Specified.Sample.Size</code>, depending on if sample size is being determined for a desired degree of statistical power analysis or if statistical power is being determined given a specified sample size, respectively</p>
</td></tr>
<tr><td><code>Actual.Power</code></td>
<td>
<p>Actual power of the situation described</p>
</td></tr>
</table>


<h3>Note</h3>

<p>When determining sample size for a desired degree of power, there will always be a 
slightly larger degree of actual power. This is the case because the algorithm employed 
determines sample size until the actual power is no less than the 
desired power (given sample size is a whole number power will almost certainly 
not be exactly the specified value). This is the same as other statistical power 
procedures that return whole numbers for necessary sample size.
</p>


<h3>Author(s)</h3>

<p>Ken Kelley (University of Notre Dame; <a href="mailto:KKelley@ND.Edu">KKelley@ND.Edu</a>)</p>


<h3>See Also</h3>

<p><code>ss.aipe.R2</code>, <code>ss.power.reg.coef</code>, <code>conf.limits.ncf</code></p>


<h3>Examples</h3>

<pre><code class='language-R'># ss.power.R2(Population.R2=.5, alpha.level=.05, desired.power=.85, p=5)
# ss.power.R2(Cohen.f2=1, alpha.level=.05, desired.power=.85, p=5)
# ss.power.R2(Population.R2=.5, Specified.N=15, alpha.level=.05, 
# desired.power=.85, p=5)
# ss.power.R2(Cohen.f2=1, Specified.N=15, alpha.level=.05, desired.power=.85, p=5)
</code></pre>

<hr>
<h2 id='ss.power.rc'>sample size for a targeted regression coefficient</h2><span id='topic+ss.power.rc'></span>

<h3>Description</h3>

<p>Determine the necessary sample size for a targeted regression coefficient or determine the degree of power given a specified sample size</p>


<h3>Usage</h3>

<pre><code class='language-R'>ss.power.rc(Rho2.Y_X = NULL, Rho2.Y_X.without.k = NULL, K = NULL, 
desired.power = 0.85, alpha.level = 0.05, Directional = FALSE, 
beta.k = NULL, sigma.X = NULL, sigma.Y = NULL, 
Rho2.k_X.without.k = NULL, RHO.XX = NULL, Rho.YX = NULL, 
which.predictor = NULL, Cohen.f2 = NULL, Specified.N = NULL, 
Print.Progress = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ss.power.rc_+3A_rho2.y_x">Rho2.Y_X</code></td>
<td>
<p>population squared multiple correlation coefficient predicting the dependent variable (i.e., <em>Y</em>) from the <em>p</em> predictor variables (i.e., the <em>X</em> variables)</p>
</td></tr>
<tr><td><code id="ss.power.rc_+3A_rho2.y_x.without.k">Rho2.Y_X.without.k</code></td>
<td>
<p>population squared multiple correlation coefficient predicting the dependent variable (i.e., <em>Y</em>) from the <code>K</code>-1 predictor variables, where the one not used is the predictor of interest</p>
</td></tr>
<tr><td><code id="ss.power.rc_+3A_k">K</code></td>
<td>
<p>number of predictor variables</p>
</td></tr>
<tr><td><code id="ss.power.rc_+3A_desired.power">desired.power</code></td>
<td>
<p>desired degree of statistical power for the test of targeted regression coefficient</p>
</td></tr>
<tr><td><code id="ss.power.rc_+3A_alpha.level">alpha.level</code></td>
<td>
<p>Type I error rate</p>
</td></tr>
<tr><td><code id="ss.power.rc_+3A_directional">Directional</code></td>
<td>
<p>whether or not a direction or a nondirectional test is to be used (usually <code>directional=FALSE</code>)</p>
</td></tr>
<tr><td><code id="ss.power.rc_+3A_beta.k">beta.k</code></td>
<td>
<p>population value of the regression coefficient for the predictor of interest</p>
</td></tr>
<tr><td><code id="ss.power.rc_+3A_sigma.x">sigma.X</code></td>
<td>
<p>population standard deviation for the predictor variable of interest</p>
</td></tr>
<tr><td><code id="ss.power.rc_+3A_sigma.y">sigma.Y</code></td>
<td>
<p>population standard deviation for the outcome variable</p>
</td></tr>
<tr><td><code id="ss.power.rc_+3A_rho2.k_x.without.k">Rho2.k_X.without.k</code></td>
<td>
<p>population squared multiple correlation coefficient predicting the predictor variable of interest from the remaining <code>K</code>-1 predictor variables</p>
</td></tr>
<tr><td><code id="ss.power.rc_+3A_rho.xx">RHO.XX</code></td>
<td>
<p>population correlation matrix for the <em>p</em> predictor variables</p>
</td></tr>
<tr><td><code id="ss.power.rc_+3A_rho.yx">Rho.YX</code></td>
<td>
<p>population vector of correlation coefficient between the <code>p</code> predictor variables and the criterion variable</p>
</td></tr>
<tr><td><code id="ss.power.rc_+3A_which.predictor">which.predictor</code></td>
<td>
<p>identifies the predictor of interest when <code>RHO.XX</code> and <code>Rho.YX</code> are specified</p>
</td></tr>
<tr><td><code id="ss.power.rc_+3A_cohen.f2">Cohen.f2</code></td>
<td>
<p>Cohen's (1988) definition for an effect size for a targeted regression coefficient: <code class="reqn">(Rho2.Y_X-Rho2.Y_X.without.j)/(1-Rho2.Y_X)</code></p>
</td></tr>
<tr><td><code id="ss.power.rc_+3A_specified.n">Specified.N</code></td>
<td>
<p>sample size for which power should be evaluated</p>
</td></tr>
<tr><td><code id="ss.power.rc_+3A_print.progress">Print.Progress</code></td>
<td>
<p>if the progress of the iterative procedure is printed to the screen as the iterations are occurring</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Determines the necessary sample size given a desired level of statistical power. Alternatively, determines the statistical power for a given a specified sample size.
There are a number of ways that the specification regarding the size of the regression coefficient can be entered. The most basic, and often the simplest, is to specify <code>Rho2.Y_X</code> and <code>Rho2.Y_X.without.k</code>. See the examples section 
for several options.
</p>


<h3>Value</h3>

<table>
<tr><td><code>Sample.Size</code></td>
<td>
<p>either the necessary sample size or the specified sample size, depending if one is interested in determining the necessary sample size given a desired degree of statistical power or if one is interested in the determining the value of statistical power given a specified sample size, respectively</p>
</td></tr>
<tr><td><code>Actual.Power</code></td>
<td>
<p>Actual power of the situation described</p>
</td></tr>
<tr><td><code>Noncentral.t.Parm</code></td>
<td>
<p>value of the noncentral distribution for the appropriate <em>t</em>-distribution</p>
</td></tr>
<tr><td><code>Effect.Size.NC.t</code></td>
<td>
<p>effect size for the noncentral <em>t</em>-distribution; this is the square root of <code>Cohen.f2</code>, because <code>Cohen.f2</code> is the effect size using an <em>F</em>-distribution</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Ken Kelley (University of Notre Dame; <a href="mailto:KKelley@ND.Edu">KKelley@ND.Edu</a>)</p>


<h3>References</h3>

 
<p>Maxwell, S. E. (2000). Sample size for multiple regression. <em>Psychological Methods, 4</em>, 434&ndash;458.
</p>
<p>Cohen, J. (1988). <em>Statistical power analysis for the behavioral sciences</em> (2nd ed.). Hillsdale, NJ: Erlbaum.
</p>


<h3>See Also</h3>

<p><code>ss.aipe.reg.coef</code>, <code>ss.power.R2</code>, <code>conf.limits.ncf</code></p>


<h3>Examples</h3>

<pre><code class='language-R'>Cor.Mat &lt;- rbind(
c(1.00, 0.53,  0.58, 0.60, 0.46, 0.66),
c(0.53, 1.00,  0.35, 0.07, 0.14, 0.43),
c(0.58, 0.35,  1.00, 0.18, 0.29, 0.50),
c(0.60, 0.07,  0.18, 1.00, 0.30, 0.26),
c(0.46, 0.14,  0.29, 0.30, 1.00, 0.30),
c(0.66, 0.43,  0.50, 0.26, 0.30, 1.00))

RHO.XX &lt;- Cor.Mat[2:6,2:6]
Rho.YX &lt;- Cor.Mat[1,2:6]

# Method 1
# ss.power.rc(Rho2.Y_X=0.7826786, Rho2.Y_X.without.k=0.7363697, K=5,
# alpha.level=.05, Directional=FALSE, desired.power=.80)

# Method 2
# ss.power.rc(alpha.level=.05, RHO.XX=RHO.XX, Rho.YX=Rho.YX, 
# which.predictor=5, Directional=FALSE, desired.power=.80)

# Method 3
# Here, beta.j is the standardized regression coefficient. Had beta.j 
# been the unstandardized regression coefficient, sigma.X and sigma.Y 
# would have been the standard deviation for the 
# X variable of interest and Y, respectively.
# ss.power.rc(Rho2.Y_X=0.7826786, Rho2.k_X.without.k=0.3652136, 
# beta.k=0.2700964, K=5, alpha.level=.05,  sigma.X=1, sigma.Y=1, 
# Directional=FALSE, desired.power=.80)

# Method 4
# ss.power.rc(alpha.level=.05, Cohen.f2=0.2130898, K=5, 
# Directional=FALSE, desired.power=.80)

# Power given a specified N and squared multiple correlation coefficients.
# ss.power.rc(Rho2.Y_X=0.7826786, Rho2.Y_X.without.k=0.7363697, 
# Specified.N=25, K=5, alpha.level=.05, Directional=FALSE)

# Power given a specified N and effect size.
# ss.power.rc(alpha.level=.05, Cohen.f2=0.2130898, K=5, Specified.N=25,
# Directional=FALSE)

# Reproducing Maxwell's (2000, p. 445) Example
Cor.Mat.Maxwell &lt;- rbind(
c(1.00, 0.35,  0.20, 0.20, 0.20, 0.20),
c(0.35, 1.00,  0.40, 0.40, 0.40, 0.40),
c(0.20, 0.40,  1.00, 0.45, 0.45, 0.45),
c(0.20, 0.40,  0.45, 1.00, 0.45, 0.45),
c(0.20, 0.40,  0.45, 0.45, 1.00, 0.45),
c(0.20, 0.40,  0.45, 0.45, 0.45, 1.00))

RHO.XX.Maxwell &lt;- Cor.Mat.Maxwell[2:6,2:6]
Rho.YX.Maxwell &lt;- Cor.Mat.Maxwell[1,2:6]
R2.Maxwell &lt;- Rho.YX.Maxwell

RHO.XX.Maxwell.no.1 &lt;- Cor.Mat.Maxwell[3:6,3:6]
Rho.YX.Maxwell.no.1 &lt;- Cor.Mat.Maxwell[1,3:6]
R2.Maxwell.no.1 &lt;- 
Rho.YX.Maxwell.no.1


# Note that Maxwell arrives at N=113, whereas this procedure arrives at 111.
# This seems to be the case becuase of rounding error in calculations 
# and tables (Cohen, 1988) used. The present procedure is correct and 
# contains no rounding error in the application of the method.
# ss.power.rc(Rho2.Y_X=R2.Maxwell, Rho2.Y_X.without.k=R2.Maxwell.no.1, K=5,
# alpha.level=.05, Directional=FALSE, desired.power=.80)
</code></pre>

<hr>
<h2 id='ss.power.reg.coef'>sample size for a targeted regression coefficient</h2><span id='topic+ss.power.reg.coef'></span>

<h3>Description</h3>

<p>Determine the necessary sample size for a targeted regression coefficient or determine the degree of power given a specified sample size</p>


<h3>Usage</h3>

<pre><code class='language-R'>ss.power.reg.coef(Rho2.Y_X = NULL, Rho2.Y_X.without.j = NULL, p = NULL, 
desired.power = 0.85, alpha.level = 0.05, Directional = FALSE, 
beta.j = NULL, sigma.X = NULL, sigma.Y = NULL, Rho2.j_X.without.j = NULL,
RHO.XX = NULL, Rho.YX = NULL, which.predictor = NULL, Cohen.f2 = NULL, 
Specified.N=NULL, Print.Progress = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ss.power.reg.coef_+3A_rho2.y_x">Rho2.Y_X</code></td>
<td>
<p>population squared multiple correlation coefficient predicting the dependent variable (i.e., <em>Y</em>) from the <code>p</code> predictor variables (i.e., the <em>X</em> variables)</p>
</td></tr>
<tr><td><code id="ss.power.reg.coef_+3A_rho2.y_x.without.j">Rho2.Y_X.without.j</code></td>
<td>
<p>population squared multiple correlation coefficient predicting the dependent variable (i.e., <em>Y</em>) from the <code>p</code>-1 predictor variables, where the one not used is the predictor of interest</p>
</td></tr>
<tr><td><code id="ss.power.reg.coef_+3A_p">p</code></td>
<td>
<p>number of predictor variables</p>
</td></tr>
<tr><td><code id="ss.power.reg.coef_+3A_desired.power">desired.power</code></td>
<td>
<p>desired degree of statistical power for the test of targeted regression coefficient</p>
</td></tr>
<tr><td><code id="ss.power.reg.coef_+3A_alpha.level">alpha.level</code></td>
<td>
<p>Type I error rate</p>
</td></tr>
<tr><td><code id="ss.power.reg.coef_+3A_directional">Directional</code></td>
<td>
<p>whether or not a direction or a nondirectional test is to be used (usually <code>directional=FALSE</code>)</p>
</td></tr>
<tr><td><code id="ss.power.reg.coef_+3A_beta.j">beta.j</code></td>
<td>
<p>population value of the regression coefficient for the predictor of interest</p>
</td></tr>
<tr><td><code id="ss.power.reg.coef_+3A_sigma.x">sigma.X</code></td>
<td>
<p>population standard deviation for the predictor variable of interest</p>
</td></tr>
<tr><td><code id="ss.power.reg.coef_+3A_sigma.y">sigma.Y</code></td>
<td>
<p>population standard deviation for the outcome variable</p>
</td></tr>
<tr><td><code id="ss.power.reg.coef_+3A_rho2.j_x.without.j">Rho2.j_X.without.j</code></td>
<td>
<p>population squared multiple correlation coefficient predicting the predictor variable of interest from the remaining p-1 predictor variables</p>
</td></tr>
<tr><td><code id="ss.power.reg.coef_+3A_rho.xx">RHO.XX</code></td>
<td>
<p>population correlation matrix for the <code>p</code> predictor variables</p>
</td></tr>
<tr><td><code id="ss.power.reg.coef_+3A_rho.yx">Rho.YX</code></td>
<td>
<p>population vector of correlation coefficient between the <code>p</code> predictor variables and the criterion variable</p>
</td></tr>
<tr><td><code id="ss.power.reg.coef_+3A_cohen.f2">Cohen.f2</code></td>
<td>
<p>Cohen's (1988) definition for an effect size for a targeted regression coefficient: <code>(Rho2.Y_X-Rho2.Y_X.without.j)/(1-Rho2.Y_X)</code></p>
</td></tr>
<tr><td><code id="ss.power.reg.coef_+3A_which.predictor">which.predictor</code></td>
<td>
<p>identifies the predictor of interest when <code>RHO.XX</code> and <code>Rho.YX</code> are specified</p>
</td></tr>
<tr><td><code id="ss.power.reg.coef_+3A_specified.n">Specified.N</code></td>
<td>
<p>sample size for which power should be evaluated</p>
</td></tr>
<tr><td><code id="ss.power.reg.coef_+3A_print.progress">Print.Progress</code></td>
<td>
<p>if the progress of the iterative procedure is printed to the screen as the iterations are occurring</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Determines the necessary sample size given a desired level of statistical power. Alternatively, determines the statistical power for a given a specified sample size.
There are a number of ways that the specification regarding the size of the regression coefficient can be entered. The most basic, and often the simplest, is to specify <code>Rho2.Y_X</code> and <code>Rho2.Y_X.without.j</code>. See the examples section 
for several options.
</p>


<h3>Value</h3>

<table>
<tr><td><code>Sample.Size</code></td>
<td>
<p>either the necessary sample size or the specified sample size, depending if one is interested in determining the necessary sample size given a desired degree of statistical power or if one is interested in the determining the value of statistical power given a specified sample size, respectively</p>
</td></tr>
<tr><td><code>Actual.Power</code></td>
<td>
<p>Actual power of the situation described</p>
</td></tr>
<tr><td><code>Noncentral.t.Parm</code></td>
<td>
<p>value of the noncentral distribution for the appropriate <em>t</em>-distribution</p>
</td></tr>
<tr><td><code>Effect.Size.NC.t</code></td>
<td>
<p>effect size for the noncentral <em>t</em>-distribution; this is the square root of <code>Cohen.f2</code>, because <code>Cohen.f2</code> is the effect size using an <em>F</em>-distribution</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Ken Kelley (University of Notre Dame; <a href="mailto:KKelley@ND.Edu">KKelley@ND.Edu</a>)</p>


<h3>References</h3>

<p>Cohen, J. (1988). <em>Statistical power analysis for the behavioral sciences</em> (2nd ed.). Hillsdale, NJ: Erlbaum.
</p>
<p>Kelley, K. &amp; Maxwell, S. E. (2008). Sample Size Planning with applications to multiple regression: Power and accuracy for omnibus and targeted effects. In P. Alasuuta, J. Brannen, &amp; L. Bickman (Eds.), <em>The Sage handbook of social research methods</em> (pp. 166&ndash;192). Newbury Park, CA: Sage.
</p>
<p>Maxwell, S. E. (2000). Sample size for multiple regression. <em>Psychological Methods, 4</em>, 434&ndash;458.
</p>


<h3>See Also</h3>

<p><code>ss.aipe.reg.coef</code>, <code>ss.power.R2</code>, <code>conf.limits.ncf</code></p>


<h3>Examples</h3>

<pre><code class='language-R'>Cor.Mat &lt;- rbind(
c(1.00, 0.53,  0.58, 0.60, 0.46, 0.66),
c(0.53, 1.00,  0.35, 0.07, 0.14, 0.43),
c(0.58, 0.35,  1.00, 0.18, 0.29, 0.50),
c(0.60, 0.07,  0.18, 1.00, 0.30, 0.26),
c(0.46, 0.14,  0.29, 0.30, 1.00, 0.30),
c(0.66, 0.43,  0.50, 0.26, 0.30, 1.00))

RHO.XX &lt;- Cor.Mat[2:6,2:6]
Rho.YX &lt;- Cor.Mat[1,2:6]

# Method 1
# ss.power.reg.coef(Rho2.Y_X=0.7826786, Rho2.Y_X.without.j=0.7363697, p=5,
# alpha.level=.05, Directional=FALSE, desired.power=.80)

# Method 2
# ss.power.reg.coef(alpha.level=.05, RHO.XX=RHO.XX, Rho.YX=Rho.YX, 
# which.predictor=5,
# Directional=FALSE, desired.power=.80)

# Method 3
# Here, beta.j is the standardized regression coefficient. Had beta.j 
# been the unstandardized regression coefficient, sigma.X and sigma.Y 
# would have been the standard deviation for the 
# X variable of interest and Y, respectively.
# ss.power.reg.coef(Rho2.Y_X=0.7826786, Rho2.j_X.without.j=0.3652136, 
# beta.j=0.2700964,
# p=5, alpha.level=.05,  sigma.X=1, sigma.Y=1, Directional=FALSE, 
# desired.power=.80)

# Method 4
# ss.power.reg.coef(alpha.level=.05, Cohen.f2=0.2130898, p=5, 
# Directional=FALSE,
# desired.power=.80)

# Power given a specified N and squared multiple correlation coefficients.
# ss.power.reg.coef(Rho2.Y_X=0.7826786, Rho2.Y_X.without.j=0.7363697, 
# Specified.N=25,
# p=5, alpha.level=.05, Directional=FALSE)

# Power given a specified N and effect size.
# ss.power.reg.coef(alpha.level=.05, Cohen.f2=0.2130898, p=5, Specified.N=25,
# Directional=FALSE)

# Reproducing Maxwell's (2000, p. 445) Example
Cor.Mat.Maxwell &lt;- rbind(
c(1.00, 0.35,  0.20, 0.20, 0.20, 0.20),
c(0.35, 1.00,  0.40, 0.40, 0.40, 0.40),
c(0.20, 0.40,  1.00, 0.45, 0.45, 0.45),
c(0.20, 0.40,  0.45, 1.00, 0.45, 0.45),
c(0.20, 0.40,  0.45, 0.45, 1.00, 0.45),
c(0.20, 0.40,  0.45, 0.45, 0.45, 1.00))

RHO.XX.Maxwell &lt;- Cor.Mat.Maxwell[2:6,2:6]
Rho.YX.Maxwell &lt;- Cor.Mat.Maxwell[1,2:6]
R2.Maxwell &lt;- Rho.YX.Maxwell

RHO.XX.Maxwell.no.1 &lt;- Cor.Mat.Maxwell[3:6,3:6]
Rho.YX.Maxwell.no.1 &lt;- Cor.Mat.Maxwell[1,3:6]
R2.Maxwell.no.1 &lt;- 
Rho.YX.Maxwell.no.1


# Note that Maxwell arrives at N=113, whereas this procedure arrives at 111.
# This seems to be the case becuase of rounding error in calculations 
# in Cohen (1988)'s tables. The present procedure is correct and contains no 
# rounding error
# in the application of the method.
# ss.power.reg.coef(Rho2.Y_X=R2.Maxwell, 
# Rho2.Y_X.without.j=R2.Maxwell.no.1, p=5,
# alpha.level=.05, Directional=FALSE, desired.power=.80)
</code></pre>

<hr>
<h2 id='ss.power.sem'>
Sample size planning for structural equation modeling from the power analysis perspective
</h2><span id='topic+ss.power.sem'></span>

<h3>Description</h3>

<p>Calculate the necessary sample size for an SEM study, so as to have enough power to reject the 
null hypothesis that (a) the model has perfect fit, or (b) the difference in fit between two nested models equal some
specified amount.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ss.power.sem(F.ML = NULL, df = NULL, RMSEA.null = NULL, RMSEA.true = NULL, 
F.full = NULL, F.res = NULL, RMSEA.full = NULL, RMSEA.res = NULL, 
df.full = NULL, df.res = NULL, alpha = 0.05, power = 0.8)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ss.power.sem_+3A_f.ml">F.ML</code></td>
<td>

<p>The true maximum likelihood fit function value in the population for the model of interest. Leave this argument NULL
if you are doing nested model significance tests. 
</p>
</td></tr>
<tr><td><code id="ss.power.sem_+3A_df">df</code></td>
<td>

<p>The degrees of freedom of the model of interest. Leave this argument NULL
if you are doing nested model significance tests. 
</p>
</td></tr>
<tr><td><code id="ss.power.sem_+3A_rmsea.null">RMSEA.null</code></td>
<td>

<p>The model's population RMSEA under the null hypothesis. Leave this argument NULL
if you are doing nested model significance tests. 
</p>
</td></tr>
<tr><td><code id="ss.power.sem_+3A_rmsea.true">RMSEA.true</code></td>
<td>

<p>The model's population RMSEA under the alternative hypothesis. This should be the model's 
true population RMSEA value. Leave this argument NULL
if you are doing nested model significance tests. 
</p>
</td></tr>
<tr><td><code id="ss.power.sem_+3A_f.full">F.full</code></td>
<td>

<p>The maximum likelihood fit function value for the full model.
</p>
</td></tr>
<tr><td><code id="ss.power.sem_+3A_f.res">F.res</code></td>
<td>

<p>The maximum likelihood fit function value for the restricted model.
</p>
</td></tr>
<tr><td><code id="ss.power.sem_+3A_rmsea.full">RMSEA.full</code></td>
<td>

<p>The population RMSEA value for the full model.
</p>
</td></tr>
<tr><td><code id="ss.power.sem_+3A_rmsea.res">RMSEA.res</code></td>
<td>

<p>The population RMSEA value for the restricted model.
</p>
</td></tr>
<tr><td><code id="ss.power.sem_+3A_df.full">df.full</code></td>
<td>

<p>The degrees of freedom for the full model. 
</p>
</td></tr>
<tr><td><code id="ss.power.sem_+3A_df.res">df.res</code></td>
<td>

<p>The degrees of freedom for the restricted model.
</p>
</td></tr>
<tr><td><code id="ss.power.sem_+3A_alpha">alpha</code></td>
<td>

<p>The Type I error rate.
</p>
</td></tr>
<tr><td><code id="ss.power.sem_+3A_power">power</code></td>
<td>

<p>The desired power.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Keke Lai (University of California - Merced)
</p>

<hr>
<h2 id='t.and.smd.conversion'>Conversion functions for noncentral t-distribution</h2><span id='topic+delta2lambda'></span><span id='topic+lambda2delta'></span>

<h3>Description</h3>

<p>Functions useful for converting a standardized mean difference to a noncentrality parameter, and vice versa.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lambda2delta(lambda, n.1, n.2)
delta2lambda(delta, n.1, n.2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="t.and.smd.conversion_+3A_lambda">lambda</code></td>
<td>
<p>noncentral value from a <em>t</em>-distribution</p>
</td></tr>
<tr><td><code id="t.and.smd.conversion_+3A_delta">delta</code></td>
<td>
<p>population value of the standardized mean difference</p>
</td></tr>
<tr><td><code id="t.and.smd.conversion_+3A_n.1">n.1</code></td>
<td>
<p>sample size in group 1</p>
</td></tr>
<tr><td><code id="t.and.smd.conversion_+3A_n.2">n.2</code></td>
<td>
<p>sample size in group 2</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Although <code>lambda</code> is the population noncentral value, an estimate of it is the observed value of a
<em>t</em>-statistic. Likewise, delta can be estimated as the observed standardized mean difference. Thus, the observed 
standardized mean difference can be converted to the observed <em>t</em>-value. These functions are especially helpful in the
context of forming confidence intervals for the population standardized mean difference. 
</p>


<h3>Value</h3>

<p>Either the value of <code>delta</code> given <code>lambda</code> or <code>lambda</code> given <code>delta</code> (and the <em>per group</em> sample sizes).
</p>


<h3>Author(s)</h3>

<p>Ken Kelley (University of Notre Dame; <a href="mailto:KKelley@ND.Edu">KKelley@ND.Edu</a>)</p>


<h3>See Also</h3>

<p><code>smd</code>, <code>ci.smd</code>, <code>ss.aipe.smd</code></p>


<h3>Examples</h3>

<pre><code class='language-R'>lambda2delta(lambda=2, n.1=113, n.2=113)
delta2lambda(delta=.266076, n.1=113, n.2=113)
</code></pre>

<hr>
<h2 id='theta.2.Sigma.theta'>Compute the model-implied covariance matrix of an SEM model </h2><span id='topic+theta.2.Sigma.theta'></span>

<h3>Description</h3>

<p>Obtain the model-implied covariance matrix of manifest variables given a structural equation model and its model parameters
</p>


<h3>Usage</h3>

<pre><code class='language-R'>theta.2.Sigma.theta(model, theta, latent.vars)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="theta.2.Sigma.theta_+3A_model">model</code></td>
<td>
<p> an RAM (reticular action model; e.g., McArdle &amp; McDonald, 1984) specification of a structural equation model, and should be of class <code>mod</code>. The model is specified in the same manner as does the <code><a href="sem.html#topic+sem">sem</a></code> package; see <code><a href="sem.html#topic+sem">sem</a></code> and <code><a href="sem.html#topic+specify.model">specify.model</a></code> for detailed documentations about model specifications in the RAM notation. </p>
</td></tr>
<tr><td><code id="theta.2.Sigma.theta_+3A_theta">theta</code></td>
<td>
<p> a vector containing the model parameters. The names of the elements in <code>theta</code> must be the same as the names of the model parameters specified in <code>model</code>. </p>
</td></tr>
<tr><td><code id="theta.2.Sigma.theta_+3A_latent.vars">latent.vars</code></td>
<td>
<p> a vector containing the names of the latent variables </p>
</td></tr>
</table>


<h3>Details</h3>

<p>Part of the codes in this function are adapted from the function <code><a href="sem.html#topic+sem">sem</a></code> in the <code>sem</code> R package (Fox, 2006). This function uses the same notation to specify SEM models as does <code><a href="sem.html#topic+sem">sem</a></code>. Please refer to <code><a href="sem.html#topic+sem">sem</a></code> and the example below for more detailed documentation about model specification and the RAM notation. For technical discussion on how to obtain the model implied covariance matrix in the RAM notation given model parameters, see McArdle and McDonald (1984).</p>


<h3>Value</h3>

<table>
<tr><td><code>ram</code></td>
<td>
<p>RAM matrix, including any rows generated for covariances among fixed exogenous variables; column 5 includes computed start values.</p>
</td></tr>
<tr><td><code>t</code></td>
<td>
<p>number of model parameters (i.e., the length of <code>theta</code>)</p>
</td></tr>
<tr><td><code>m</code></td>
<td>
<p>total number of variables (i.e., manifest variables plus latent variables)</p>
</td></tr>
<tr><td><code>n</code></td>
<td>
<p>number of observed variables</p>
</td></tr>
<tr><td><code>all.vars</code></td>
<td>
<p>the names of all variables (i.e., manifest plus latent)</p>
</td></tr>
<tr><td><code>obs.vars</code></td>
<td>
<p>the names of observed variables</p>
</td></tr>
<tr><td><code>latent.vars</code></td>
<td>
<p>the names of latent variables</p>
</td></tr>
<tr><td><code>pars</code></td>
<td>
<p>the names of model parameters</p>
</td></tr>
<tr><td><code>P</code></td>
<td>
<p>the <em>P</em> matrix in RAM notation</p>
</td></tr>
<tr><td><code>A</code></td>
<td>
<p>the <em>A</em> matrix in RAM notation</p>
</td></tr>
<tr><td><code>Sigma.theta</code></td>
<td>
<p>the model implied covariance matrix</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Keke Lai (University of California&ndash;Merced) </p>


<h3>References</h3>

 
<p>Fox, J. (2006). Structural equation modeling with the sem package in R. <em>Structural Equation Modeling, 13</em>, 465&ndash;486.
</p>
<p>Lai, K., &amp; Kelley, K. (in press). Accuracy in parameter estimation for targeted effects in structural equation modeling: Sample size planning for narrow confidence intervals. <em>Psychological Methods</em>.
</p>
<p>McArdle, J. J., &amp; McDonald, R. P. (1984). Some algebraic properties of the reticular action model. <em>British Journal of Mathematical and Statistical Psychology, 37</em>, 234&ndash;251. 
</p>


<h3>See Also</h3>

<p><code><a href="sem.html#topic+sem">sem</a></code>; <code><a href="sem.html#topic+specify.model">specify.model</a></code>  </p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# to obtain the model implied covariance matrix of Model 2 in the simulation 
# study in Lai and Kelley (2010), one can use the present function in the 
# following manner.

library(sem)

# specify a model object in the RAM notation
model.2&lt;-specify.model()
xi1 -&gt; y1, lambda1, 1
xi1 -&gt; y2, NA, 1
xi1 -&gt; y3, lambda2, 1
xi1 -&gt; y4, lambda3, 0.3
eta1 -&gt; y4, lambda4, 1
eta1 -&gt; y5, NA, 1
eta1 -&gt; y6, lambda5, 1
eta1 -&gt; y7, lambda6, 0.3
eta2 -&gt; y6, lambda7, 0.3
eta2 -&gt; y7, lambda8, 1
eta2 -&gt; y8, NA, 1
eta2 -&gt; y9, lambda9, 1
xi1 -&gt; eta1, gamma11, 0.6
eta1 -&gt; eta2, beta21, 0.6 
xi1 &lt;-&gt; xi1, phi11, 0.49
eta1 &lt;-&gt; eta1, psi11, 0.3136
eta2 &lt;-&gt; eta2, psi22, 0.3136
y1 &lt;-&gt; y1, delta1, 0.51
y2 &lt;-&gt; y2, delta2, 0.51
y3 &lt;-&gt; y3, delta3, 0.51
y4 &lt;-&gt; y4, delta4, 0.2895
y5 &lt;-&gt; y5, delta5, 0.51
y6 &lt;-&gt; y6, delta6, 0.2895
y7 &lt;-&gt; y7, delta7, 0.2895
y8 &lt;-&gt; y8, delta8, 0.51
y9 &lt;-&gt; y9, delta9, 0.51


# to inspect the specified model
model.2

theta &lt;- c(1, 1, 0.3, 1,1, 0.3, 0.3, 1, 1, 0.6, 0.6,
0.49, 0.3136, 0.3136, 0.51, 0.51, 0.51, 0.2895, 0.51, 0.2895, 0.2895, 0.51, 0.51)

names(theta) &lt;- c("lambda1","lambda2","lambda3",
"lambda4","lambda5","lambda6","lambda7","lambda8","lambda9",
"gamma11", "beta21",
"phi11", "psi11", "psi22", 
"delta1","delta2","delta3","delta4","delta5","delta6","delta7",
"delta8","delta9")

res&lt;-theta.2.Sigma.theta(model=model.2, theta=theta, 
latent.vars=c("xi1", "eta1","eta2"))

Sigma.theta &lt;- res$Sigma.theta

## End(Not run)
</code></pre>

<hr>
<h2 id='transform_r.Z'>Transform a correlation coefficient (r) into the scale of Fisher's <code class="reqn">Z^\prime</code>
</h2><span id='topic+transform_r.Z'></span>

<h3>Description</h3>

<p>This function transform a correlation coefficient into the scale of Fisher's <code class="reqn">Z^\prime</code>.</p>


<h3>Usage</h3>

<pre><code class='language-R'>transform_r.Z(r)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="transform_r.Z_+3A_r">r</code></td>
<td>
<p>correlation coefficient (between two variables)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is typically used in the context of forming a confidence interval for a population correlation coefficient. Note that, in that situation, the two variables are assumed to follow a bivariate normal distribution (e.g., Hays, 1994). 
</p>


<h3>Value</h3>

<p>returns a value on the scale of Fisher's <code class="reqn">Z^\prime</code>, also called Fisher's <code class="reqn">Z</code>, from a given correlation value. 
</p>


<h3>Author(s)</h3>

<p> Ken Kelley (University of Notre Dame; <a href="mailto:KKelley@ND.Edu">KKelley@ND.Edu</a>) </p>


<h3>References</h3>

<p>Kelley, K. (2007). Confidence intervals for standardized effect sizes: Theory, application, 
and implementation.<em> Journal of Statistical Software, 20</em>(8), 1&ndash;24.
</p>
<p>Hays, W. L. (1994). <em>Statistics</em> (5th ed). Fort Worth, TX: Harcourt Brace College Publishers)
</p>


<h3>See Also</h3>

<p><code><a href="#topic+transform_Z.r">transform_Z.r</a></code>, <code><a href="#topic+ci.cc">ci.cc</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># From Hays (1994, pp. 649--650)
transform_r.Z(.35)
</code></pre>

<hr>
<h2 id='transform_Z.r'>
Transform Fischer's <em>Z</em> into the scale of a correlation coefficient 
</h2><span id='topic+transform_Z.r'></span>

<h3>Description</h3>

<p>A function to transform Fischer's <code class="reqn">Z^\prime</code> into the scale of a correlation coefficient. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>transform_Z.r(Z)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="transform_Z.r_+3A_z">Z</code></td>
<td>
<p>Value of Fisher's <code class="reqn">Z^\prime</code> (also called Fisher's <code class="reqn">Z</code>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is typically used in the context of forming a confidence interval for a population correlation coefficient. Note that, in that situation, the two variables are assumed to follow a bivariate normal distribution (e.g., Hays, 1994).
</p>


<h3>Value</h3>

<p>returns a value on the scale of a correlation coefficieint from a value of Fisher's <em>Z</em>. 
</p>


<h3>Author(s)</h3>

<p> Ken Kelley (University of Notre Dame; <a href="mailto:KKelley@ND.Edu">KKelley@ND.Edu</a>) </p>


<h3>References</h3>

<p>Kelley, K. (2007). Confidence intervals for standardized effect sizes: Theory, application, 
and implementation.<em> Journal of Statistical Software, 20</em>(8), 1&ndash;24.
</p>
<p>Hays, W. L. (1994). <em>Statistics</em> (5th ed). Fort Worth, TX: Harcourt Brace College Publishers)
</p>


<h3>See Also</h3>

<p><code><a href="#topic+transform_r.Z">transform_r.Z</a></code>, <code><a href="#topic+ci.cc">ci.cc</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># From Hays (1994, pp. 649--650)
transform_Z.r(0.3654438)
</code></pre>

<hr>
<h2 id='upsilon'>
This function implements the upsilon effect size statistic as described in Lachowicz, Preacher, &amp; Kelley (in press) for mediation.</h2><span id='topic+upsilon'></span>

<h3>Description</h3>

<p>This function implements the upsilon effect size statistic as described in Lachowicz, Preacher, &amp; Kelley (in press) for mediation.</p>


<h3>Usage</h3>

<pre><code class='language-R'>upsilon(x, mediator, dv, conf.level = 0.95, bootstrap = TRUE, 
bootstrap.package = "lavaan", bootstrap.type="ordinary", B = 1000,
boot.data.out=FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="upsilon_+3A_x">x</code></td>
<td>
<p><code>x</code> is the independent variable. </p>
</td></tr>
<tr><td><code id="upsilon_+3A_mediator">mediator</code></td>
<td>
<p><code>mediator</code> is the mediator variable.</p>
</td></tr>
<tr><td><code id="upsilon_+3A_dv">dv</code></td>
<td>
<p><code>dv</code> is the outcome or dependent variable.</p>
</td></tr>
<tr><td><code id="upsilon_+3A_conf.level">conf.level</code></td>
<td>
<p><code>conf.level</code> is the desired confidence coefficient (i.e., the complement of the Type I error rate).</p>
</td></tr>
<tr><td><code id="upsilon_+3A_bootstrap">bootstrap</code></td>
<td>
<p><code>TRUE</code> or <code>FALSE</code> regarding if a bootstrap confidence interval should be constructed</p>
</td></tr>
<tr><td><code id="upsilon_+3A_bootstrap.package">bootstrap.package</code></td>
<td>
<p>The package that will be used for bootstrapping, either <span class="pkg">lavaan</span> or <span class="pkg">boot</span> (default is <span class="pkg">lavaan</span>).</p>
</td></tr>
<tr><td><code id="upsilon_+3A_bootstrap.type">bootstrap.type</code></td>
<td>
<p>The type of bootstrap confidence interval. If <code>bootstrap.package = ``lavaan''</code>, this can be either <code>"ordinary"</code> or<code>"bollen.stine"</code> (default is <code>"ordinary"</code>). If <code>bootstrap.package = ``boot''</code>, <code>"normal"</code>, <code>"basic"</code>, <code>"student"</code>, <code>"perc"</code>, or <code>"bca"</code> CIs (default is <code>"perc"</code>.</p>
</td></tr>
<tr><td><code id="upsilon_+3A_b">B</code></td>
<td>
<p>The number of bootstrap replications (1000 is default)</p>
</td></tr>
<tr><td><code id="upsilon_+3A_boot.data.out">boot.data.out</code></td>
<td>
<p><code>TRUE</code> or <code>FALSE</code> regarding if bootstrap data is returned with function output (only available if <code>bootstrap.boot = TRUE</code>).</p>
</td></tr>
<tr><td><code id="upsilon_+3A_...">...</code></td>
<td>
<p>Allows specifictions for functions that are used within this function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns the value of the effect size upsilon for a simple mediation model. 
</p>


<h3>Note</h3>

<p>Note that this function overcomes some limitations of other effects for mediation models, such as those discussed in Preacher and Kelley (2012) and Wen and Fan (2015) and that was developed and delineated in Lachowicz, Preacher, and Kelley, K (in press). This function can only be used for simple mediation models at this time. Note that <code>upsilon()</code> was included in the <code>mediation()</code> function but it has become it's own function to provide more flexibility. 
</p>


<h3>Author(s)</h3>

<p>Lachowicz
Mark J. Lachowicz (Vanderbilt University; <a href="mailto:Mark.J.Lachowicz@Vanderbilt.edu">Mark.J.Lachowicz@Vanderbilt.edu</a>)
</p>


<h3>References</h3>

<p>Lachowicz, M. J., Preacher, K. J., &amp; Kelley, K. (in press). A novel measure of effect size for mediation analysis. <em>Psychological Methods</em>, <em>X</em>, X&ndash;X.
</p>
<p>Preacher, K. J., &amp; Kelley, K. (2011). Effect size measures for mediation models: quantitative strategies for communicating indirect effects. <em>Psychological Methods</em>, <em>16</em>, 93&ndash;115. 
</p>
<p>Wen, Z., &amp; Fan, X. (2015). Monotonicity of effect sizes: Questioning kappa-squared as mediation effect size measure. 
<em>Psychological Methods</em>, <em>20</em>, 193&ndash;203. 
</p>


<h3>See Also</h3>

<p><a href="#topic+mediation">mediation</a>,<a href="lavaan.html#topic+lavaan">lavaan</a>,<a href="boot.html#topic+boot">boot</a>
</p>

<hr>
<h2 id='var.ete'>
The Variance of the Estimated Treatment Effect at Selected Covariate Values in a Two-group ANCOVA.
</h2><span id='topic+var.ete'></span>

<h3>Description</h3>

<p>Calculate the variance or an estimated variance of the estimated treatment effect at selected covariate values assuming heterogeneity of regression and a random covariate in a two-group ANCOVA. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>var.ete(sigma2, sigmaz2, n1, n2, beta1, beta2, muz = 0, c = 0, type = "sample", 
covariate.value = "sample.mean")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="var.ete_+3A_sigma2">sigma2</code></td>
<td>

<p>Variance of the residual errors if 'type = population' and sample variance of the residual errors if 'type = sample'</p>
</td></tr>
<tr><td><code id="var.ete_+3A_sigmaz2">sigmaz2</code></td>
<td>

<p>Variance of the random covariate if 'type = population' and sample variance of the random covariate if 'type = sample'</p>
</td></tr>
<tr><td><code id="var.ete_+3A_n1">n1</code></td>
<td>

<p>Sample size of group 1</p>
</td></tr>
<tr><td><code id="var.ete_+3A_n2">n2</code></td>
<td>

<p>Sample size of group 2</p>
</td></tr>
<tr><td><code id="var.ete_+3A_beta1">beta1</code></td>
<td>

<p>Slope of the random covariate for group 1 if 'type = population' and estimated slope of the random covariate for group 1 if 'type = sample'</p>
</td></tr>
<tr><td><code id="var.ete_+3A_beta2">beta2</code></td>
<td>

<p>Slope of the random covariate for group 2 if 'type = population' and estimated slope of the random covariate for group 2 if 'type = sample'</p>
</td></tr>
<tr><td><code id="var.ete_+3A_muz">muz</code></td>
<td>

<p>Population mean of the random covariate if 'type = population' and sample mean of the random covariate if 'type = sample'</p>
</td></tr>
<tr><td><code id="var.ete_+3A_c">c</code></td>
<td>

<p>Fixed value where the treatment effect is assessed</p>
</td></tr>
<tr><td><code id="var.ete_+3A_type">type</code></td>
<td>

<p>The type of variance formula: 'population' refers to the variance of the estimated treatment effect using population slopes and variances; 'sample'refers to an unbiased estimate of the variance using sample slopes and variances</p>
</td></tr>
<tr><td><code id="var.ete_+3A_covariate.value">covariate.value</code></td>
<td>

<p>The covariate value is chosen at the sample grand mean if 'covariate.value = sample.mean', at the sample grand mean plus or minus one sample standard deviation if 'covariate.value = SD', and at a fixed value if 'covariate.value = fixed'</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function yields the variance of the estimated treatment effect for the specified input values. 
</p>


<h3>Author(s)</h3>

<p>Li Li (University of New Mexico; <a href="mailto:llis@unm.edu">llis@unm.edu</a>)
</p>


<h3>References</h3>

<p>Maxwell, S. E., Delaney, H. D., &amp; Kelley, K. (2018).  <em>Designing experiments and analyzing data:  A model comparison perspective</em>.  New York:  Routledge.
</p>
<p>Li, L., McLouth, C. J., and Delaney, H. D. (submitted). Analysis of Covariance with Heterogeneity of Regression and a Random Covariate: The Variance of the Estimated Treatment Effect at Selected Covariate Values.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Pygmalion in the Classroom: Teacher Expectation and Pupils' Intellectual Development. 
# This dataset has been used to illustrate heterogeneity of regression 
# by Maxwell, Delaney, and Kelley (2018).
nA &lt;- 64
nB &lt;- 246
muz &lt;- 0
sigma2 &lt;- 175.3251
sigmaz2 &lt;- 348.9099
betaA &lt;- 0.96895
betaB &lt;- 0.77799
var.ete(sigma2=sigma2, sigmaz2=sigmaz2, n1=nA, n2=nB, beta1=betaA, beta2=betaB, 
type="sample", covariate.value = "sample.mean")
var.ete(sigma2=sigma2, sigmaz2=sigmaz2, n1=nA, n2=nB, beta1=betaA, beta2=betaB, 
type="sample", covariate.value = "SD")
var.ete(sigma2=sigma2, sigmaz2=sigmaz2, n1=nA, n2=nB, beta1=betaA, beta2=betaB, 
c = 4.2631, muz=muz, type="sample",covariate.value = "fixed")
</code></pre>

<hr>
<h2 id='Variance.R2'>Variance of squared multiple correlation coefficient</h2><span id='topic+Variance.R2'></span>

<h3>Description</h3>

<p>Function to determine the variance of the squared multiple correlation coefficient given the population squared multiple correlation coefficient,
sample size, and the number of predictors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Variance.R2(Population.R2, N, p)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Variance.R2_+3A_population.r2">Population.R2</code></td>
<td>
<p>population squared multiple correlation coefficient</p>
</td></tr>
<tr><td><code id="Variance.R2_+3A_n">N</code></td>
<td>
<p>sample size</p>
</td></tr>
<tr><td><code id="Variance.R2_+3A_p">p</code></td>
<td>
<p>the number of predictor variables</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Uses the hypergeometric function as discussed in and section 28 of Stuart, Ord, and Arnold (1999) in order to obtain the <em>correct</em>
value for the variance of the squared multiple correlation coefficient.</p>


<h3>Value</h3>

<p>Returns the variance of the of the squared multiple correlation coefficient.
</p>


<h3>Note</h3>

<p>Uses package <code>gsl</code> and its <code>hyperg_2F1</code> function.
</p>


<h3>Author(s)</h3>

<p>Ken Kelley (University of Notre Dame; <a href="mailto:KKelley@ND.Edu">KKelley@ND.Edu</a>)</p>


<h3>References</h3>

<p>Stuart, A., Ord, J. K., &amp; Arnold, S. (1999). <em>Kendall's advanced theory of statistics: Classical inference and the linear model</em> (Volume 2A, 2nd Edition).
New York, NY: Oxford University Press.</p>


<h3>See Also</h3>

<p><code>Expected.R2</code>, <code>ci.R2</code>, <code>ss.aipe.R2</code></p>


<h3>Examples</h3>

<pre><code class='language-R'># library(gsl)
# Variance.R2(.5, 10, 5)
# Variance.R2(.5, 25, 5)
# Variance.R2(.5, 50, 5)
# Variance.R2(.5, 100, 5)
</code></pre>

<hr>
<h2 id='verify.ss.aipe.R2'>Internal MBESS function for verifying the sample size in ss.aipe.R2</h2><span id='topic+verify.ss.aipe.R2'></span>

<h3>Description</h3>

<p>Internal function called upon by <code>ss.aipe.R2</code> when <code>verify.ss=TRUE</code>. This function then calls 
upon <code>ss.aipe.R2.sensitivity</code> for the simulation study.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>verify.ss.aipe.R2(Population.R2 = NULL, conf.level = 0.95, width = NULL, 
Random.Predictors = TRUE, which.width = "Full", p = NULL, n = NULL, 
degree.of.certainty = NULL, g = 500, G = 10000, print.iter=FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="verify.ss.aipe.R2_+3A_population.r2">Population.R2</code></td>
<td>
<p>value of the population multiple correlation coefficient</p>
</td></tr>
<tr><td><code id="verify.ss.aipe.R2_+3A_conf.level">conf.level</code></td>
<td>
<p>confidence interval level (e.g., .95, .99, .90); 1-Type I error rate</p>
</td></tr>
<tr><td><code id="verify.ss.aipe.R2_+3A_width">width</code></td>
<td>
<p>width of the confidence interval (see <code>which.width</code>)</p>
</td></tr>
<tr><td><code id="verify.ss.aipe.R2_+3A_random.predictors">Random.Predictors</code></td>
<td>
<p>whether or not the predictor variables are random (set to <code>TRUE</code>) or are fixed (set to <code>FALSE</code>)</p>
</td></tr>
<tr><td><code id="verify.ss.aipe.R2_+3A_which.width">which.width</code></td>
<td>
<p>defines the width that <code>width</code> refers to</p>
</td></tr>
<tr><td><code id="verify.ss.aipe.R2_+3A_p">p</code></td>
<td>
<p>the number of predictor variables</p>
</td></tr>
<tr><td><code id="verify.ss.aipe.R2_+3A_n">n</code></td>
<td>
<p>starting sample size (i.e., from <code>ss.aipe.R2</code>)</p>
</td></tr>
<tr><td><code id="verify.ss.aipe.R2_+3A_degree.of.certainty">degree.of.certainty</code></td>
<td>
<p>value with which confidence can be placed that describes the likelihood of obtaining a confidence interval less than the value specified (e.g., .80, .90, .95)</p>
</td></tr>
<tr><td><code id="verify.ss.aipe.R2_+3A_g">g</code></td>
<td>
<p>simulations for the preliminary sample size (much smaller than <code>G</code>)</p>
</td></tr>
<tr><td><code id="verify.ss.aipe.R2_+3A_g">G</code></td>
<td>
<p>number of replications for the actual Monte Carlo simulation (should be large)</p>
</td></tr>
<tr><td><code id="verify.ss.aipe.R2_+3A_print.iter">print.iter</code></td>
<td>
<p>specify whether or not the internal iterations should be printed</p>
</td></tr>
<tr><td><code id="verify.ss.aipe.R2_+3A_...">...</code></td>
<td>
<p>additional arguments passed to internal functions</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is internal to MBESS and is called upon when <code>verify.ss=TRUE</code> in
the <code>ss.aipe.R2</code> function. Although users can use <code>verify.ss.aipe.R2</code> directly, it is not 
recommended.
</p>


<h3>Value</h3>

<p>Returns the exact (provided <code>G</code> is large enough) sample size necessary to satisfy the 
conditions specified.
</p>


<h3>Author(s)</h3>

<p>Ken Kelley (University of Notre Dame; <a href="mailto:KKelley@ND.Edu">KKelley@ND.Edu</a>)</p>

<hr>
<h2 id='vit'> Visualize individual trajectories  </h2><span id='topic+vit'></span>

<h3>Description</h3>

<p>A function to help visualize individual trajectories in a longitudinal (i.e., analysis of change) context.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>vit(id = "", occasion = "", score = "", Data = NULL, group = NULL, 
subset.ids = NULL, pct.rand = NULL, number.rand = NULL, 
All.in.One = TRUE, ylab = NULL, xlab = NULL, same.scales = TRUE, 
plot.points = TRUE, save.pdf = FALSE, save.eps = FALSE,
 save.jpg = FALSE, file = "", layout = c(3, 3), col = NULL, 
 pch = 16, cex = 0.7, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="vit_+3A_id">id</code></td>
<td>
<p> string variable of the column name of id </p>
</td></tr>
<tr><td><code id="vit_+3A_occasion">occasion</code></td>
<td>
<p> string variable of the column name of time variable </p>
</td></tr>
<tr><td><code id="vit_+3A_score">score</code></td>
<td>
<p> string variable of the column name where the score (i.e., dependent variable) is located </p>
</td></tr>
<tr><td><code id="vit_+3A_data">Data</code></td>
<td>
<p> data set with named column variables (see above) </p>
</td></tr>
<tr><td><code id="vit_+3A_group">group</code></td>
<td>
<p> if plotting parameters should be conditional on group membership </p>
</td></tr>
<tr><td><code id="vit_+3A_subset.ids">subset.ids</code></td>
<td>
<p> id values for a selected subset of individuals </p>
</td></tr>
<tr><td><code id="vit_+3A_pct.rand">pct.rand</code></td>
<td>
<p> percentage of random trajectories to be plotted </p>
</td></tr>
<tr><td><code id="vit_+3A_number.rand">number.rand</code></td>
<td>
<p> number of random trajectories to be plotted </p>
</td></tr>
<tr><td><code id="vit_+3A_all.in.one">All.in.One</code></td>
<td>
<p> should trajectories be in a single or multiple plots </p>
</td></tr>
<tr><td><code id="vit_+3A_ylab">ylab</code></td>
<td>
<p> label for the ordinate (i.e., y-axis; see par) </p>
</td></tr>
<tr><td><code id="vit_+3A_xlab">xlab</code></td>
<td>
<p> label for the abscissa (i.e., x-axis; see par) </p>
</td></tr>
<tr><td><code id="vit_+3A_same.scales">same.scales</code></td>
<td>
<p> should the y-axes have the same scales </p>
</td></tr>
<tr><td><code id="vit_+3A_plot.points">plot.points</code></td>
<td>
<p> should the points be plotted </p>
</td></tr>
<tr><td><code id="vit_+3A_save.pdf">save.pdf</code></td>
<td>
<p> save a pdf file </p>
</td></tr>
<tr><td><code id="vit_+3A_save.eps">save.eps</code></td>
<td>
<p> save a postscript file </p>
</td></tr>
<tr><td><code id="vit_+3A_save.jpg">save.jpg</code></td>
<td>
<p> save a jpg file </p>
</td></tr>
<tr><td><code id="vit_+3A_file">file</code></td>
<td>
<p> file name and file path for the graph(s) to save, if <code>file=""</code> a file would be saved in the current working directory </p>
</td></tr>
<tr><td><code id="vit_+3A_layout">layout</code></td>
<td>
<p> define the per-page layout when <code>All.in.One=FALSE</code> </p>
</td></tr>
<tr><td><code id="vit_+3A_col">col</code></td>
<td>
<p> color(s) of the line(s) and points </p>
</td></tr>
<tr><td><code id="vit_+3A_pch">pch</code></td>
<td>
<p> plotting character(s); see par </p>
</td></tr>
<tr><td><code id="vit_+3A_cex">cex</code></td>
<td>
<p> size of the points (1 is the R default; see par) </p>
</td></tr>
<tr><td><code id="vit_+3A_...">...</code></td>
<td>
<p> optional plotting specifications </p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function makes visualizing individual trajectories simple. 
Data should be in the &quot;univariate format&quot; (i.e., the same format as lmer and nlme data.)
</p>


<h3>Value</h3>

<p>Returns a plot of individual trajectories with the specifications provided.
</p>


<h3>Author(s)</h3>

<p> Ken Kelley (University of Notre Dame; <a href="mailto:KKelley@ND.Edu">KKelley@ND.Edu</a>) and Po-Ju Wu (Indiana University)</p>


<h3>See Also</h3>

<p> par, nlme, vit.fitted,  </p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(Gardner.LD)

# Although many options are possible, a simple call to
# 'vit' is of the form:
# vit(id="ID", occasion= "Trial", score= "Score", Data=Gardner.LD)

# Now color is conditional on group membership.
# vit(id="ID", occasion= "Trial", score="Score", Data=Gardner.LD, 
# group="Group")

# Now randomly selects 50
# vit(id="ID", occasion= "Trial", score="Score", Data=Gardner.LD, 
# pct.rand=50, group="Group")

# Specified individuals are plotted (by group)
# vit(id="ID", occasion= "Trial", score="Score", Data=Gardner.LD, 
# subset.ids=c(1, 4, 8, 13, 17, 21), group="Group")

# Now colors for groups are changed .
# vit(id="ID", occasion= "Trial", score="Score", Data=Gardner.LD, 
# group="Group",subset.ids=c(1, 4, 8, 13, 17, 21), col=c("Green", "Blue"))

# Now each individual specified is plotted separately.
# vit(id="ID", occasion= "Trial", score="Score", Data=Gardner.LD, 
# group="Group",subset.ids=c(1, 4, 8, 13, 17, 21), col=c("Green", "Blue"),
# All.in.One=FALSE)

## End(Not run)
</code></pre>

<hr>
<h2 id='vit.fitted'>Visualize individual trajectories with fitted curve and quality of fit </h2><span id='topic+vit.fitted'></span>

<h3>Description</h3>

<p>A function to help visualize individual trajectories in a longitudinal (i.e., analysis of change) context with fitted curve
and quality of fit after analyzing the data with lme, lmer, or nlme function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>vit.fitted(fit.Model, layout = c(3, 3), ylab = "", xlab = "", 
pct.rand = NULL, number.rand = NULL, subset.ids = NULL, 
same.scales = TRUE, save.pdf = FALSE, save.eps = FALSE, 
save.jpg = FALSE, file = "", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="vit.fitted_+3A_fit.model">fit.Model</code></td>
<td>
<p> lme, nlme object produced by nlme package or lmer object produced by lme4 package </p>
</td></tr>
<tr><td><code id="vit.fitted_+3A_layout">layout</code></td>
<td>
<p> define the per-page layout when <code>All.in.One=FALSE</code> </p>
</td></tr>
<tr><td><code id="vit.fitted_+3A_ylab">ylab</code></td>
<td>
<p> label for the ordinate (i.e., y-axis; see par) </p>
</td></tr>
<tr><td><code id="vit.fitted_+3A_xlab">xlab</code></td>
<td>
<p> label for the abscissa (i.e., x-axis; see par) </p>
</td></tr>
<tr><td><code id="vit.fitted_+3A_pct.rand">pct.rand</code></td>
<td>
<p> percentage of random trajectories to be plotted </p>
</td></tr>
<tr><td><code id="vit.fitted_+3A_number.rand">number.rand</code></td>
<td>
<p> number of random trajectories to be plotted </p>
</td></tr>
<tr><td><code id="vit.fitted_+3A_subset.ids">subset.ids</code></td>
<td>
<p> id values for a selected subset of individuals to be plotted </p>
</td></tr>
<tr><td><code id="vit.fitted_+3A_same.scales">same.scales</code></td>
<td>
<p> should the y-axes have the same scales </p>
</td></tr>
<tr><td><code id="vit.fitted_+3A_save.pdf">save.pdf</code></td>
<td>
<p> save a pdf file </p>
</td></tr>
<tr><td><code id="vit.fitted_+3A_save.eps">save.eps</code></td>
<td>
<p> save a postscript file </p>
</td></tr>
<tr><td><code id="vit.fitted_+3A_save.jpg">save.jpg</code></td>
<td>
<p> save a jpg file </p>
</td></tr>
<tr><td><code id="vit.fitted_+3A_file">file</code></td>
<td>
<p> file name and file path for the graph(s) to save, if <code>file=""</code> a file would be saved in the current working directory </p>
</td></tr>
<tr><td><code id="vit.fitted_+3A_...">...</code></td>
<td>
<p> optional plotting specifications </p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function uses the fitted model from nlme and lme functions in nlme package, and lmer function in lme4 package. 
It returns a set of plots of individual observed data, the fitted curves and the quality of fit.
</p>


<h3>Author(s)</h3>

<p> Ken Kelley (University of Notre Dame; <a href="mailto:KKelley@ND.Edu">KKelley@ND.Edu</a>) and Po-Ju Wu (Indiana University; <a href="mailto:pojwu@indiana.edu">pojwu@indiana.edu</a>) </p>


<h3>See Also</h3>

<p> par, nlme, lme4, lme, lmer, vit.fitted </p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Note that the following example works fine in R (&lt;2.7.0), but not in 
# the development version of R-2.7.0 (the cause can be either in this 
# function or in the R program)

# data(Gardner.LD)
# library(nlme)
# Full.grouped.Gardner.LD &lt;- groupedData(Score ~ Trial|ID, data=Gardner.LD, order.groups=FALSE)    

# Examination of the plot reveals that the logistic change model does not adequately describe
# the trajectories of individuals 6 and 19 (a negative exponential change model would be 
# more appropriate). Thus we remove these two subjects.
# grouped.Gardner.LD &lt;- Full.grouped.Gardner.LD[!(Full.grouped.Gardner.LD["ID"]==6 | 
#   Full.grouped.Gardner.LD["ID"]==19),]

# G.L.nlsList&lt;- nlsList(SSlogis,grouped.Gardner.LD)
# G.L.nlme &lt;- nlme(G.L.nlsList)
# to visualize individual trajectories:  vit.fitted(G.L.nlme)
# plot 50 percent random trajectories:  vit.fitted(G.L.nlme, pct.rand = 50)

## End(Not run)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
