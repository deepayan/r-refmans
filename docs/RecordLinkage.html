<!DOCTYPE html><html lang="en"><head><title>Help for package RecordLinkage</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {RecordLinkage}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#+25append+25-methods'>
<p>Concatenate comparison patterns or classification results</p></a></li>
<li><a href='#classifySupv'><p>Supervised Classification</p></a></li>
<li><a href='#classifyUnsup'><p>Unsupervised Classification</p></a></li>
<li><a href='#clone'>
<p>Serialization of record linkage object.</p></a></li>
<li><a href='#compare'><p>Compare Records</p></a></li>
<li><a href='#deleteNULLs'><p>Remove NULL Values</p></a></li>
<li><a href='#editMatch'>
<p>Edit Matching Status</p></a></li>
<li><a href='#emClassify'><p>Weight-based Classification of Data Pairs</p></a></li>
<li><a href='#emWeights'><p>Calculate weights</p></a></li>
<li><a href='#epiClassify'>
<p>Classify record pairs with EpiLink weights</p></a></li>
<li><a href='#epiWeights'>
<p>Calculate EpiLink weights</p></a></li>
<li><a href='#ff_vector-class'><p>Class <code>"ff_vector"</code></p></a></li>
<li><a href='#ffdf-class'><p>Class <code>"ffdf"</code></p></a></li>
<li><a href='#genSamples'><p>Generate Training Set</p></a></li>
<li><a href='#getErrorMeasures-methods'><p>Calculate Error Measures</p></a></li>
<li><a href='#getExpectedSize'>
<p>Estimate number of record pairs.</p></a></li>
<li><a href='#getFrequencies-methods'><p>Get attribute frequencies</p></a></li>
<li><a href='#getMinimalTrain'>
<p>Create a minimal training set</p></a></li>
<li><a href='#getPairs'><p>Extract Record Pairs</p></a></li>
<li><a href='#getPairsBackend'>
<p>Backend function for getPairs</p></a></li>
<li><a href='#getParetoThreshold'>
<p>Estimate Threshold from Pareto Distribution</p></a></li>
<li><a href='#getTable-methods'><p>Build contingency table</p></a></li>
<li><a href='#gpdEst'>
<p>Estimate Threshold from Pareto Distribution</p></a></li>
<li><a href='#internals'>
<p>Internal functions and methods</p></a></li>
<li><a href='#isFALSE'><p>Check for FALSE</p></a></li>
<li><a href='#makeBlockingPairs'>
<p>Create record pairs from blocks of ids.</p></a></li>
<li><a href='#mrl'>
<p>Mean Residual Life Plot</p></a></li>
<li><a href='#mygllm'><p>Generalized Log-Linear Fitting</p></a></li>
<li><a href='#optimalThreshold'>
<p>Optimal Threshold for Record Linkage</p></a></li>
<li><a href='#phonetics'><p>Phonetic Code</p></a></li>
<li><a href='#RecLinkClassif-class'><p>Class &quot;RecLinkClassif&quot;</p></a></li>
<li><a href='#RecLinkData-class'><p>Class &quot;RecLinkData&quot;</p></a></li>
<li><a href='#RecLinkData.object'>
<p>Record Linkage Data Object</p></a></li>
<li><a href='#RecLinkResult-class'><p>Class &quot;RecLinkResult&quot;</p></a></li>
<li><a href='#RecLinkResult.object'>
<p>Record Linkage Result Object</p></a></li>
<li><a href='#resample'><p>Safe Sampling</p></a></li>
<li><a href='#RLBigData-class'><p>Class &quot;RLBigData&quot;</p></a></li>
<li><a href='#RLBigDataDedup'>
<p>Constructors for big data objects.</p></a></li>
<li><a href='#RLBigDataDedup-class'><p>Class &quot;RLBigDataDedup&quot;</p></a></li>
<li><a href='#RLBigDataLinkage-class'><p>Class &quot;RLBigDataLinkage&quot;</p></a></li>
<li><a href='#RLdata'><p>Test data for Record Linkage</p></a></li>
<li><a href='#RLResult-class'><p>Class &quot;RLResult&quot;</p></a></li>
<li><a href='#show'>
<p>Show a RLBigData object</p></a></li>
<li><a href='#splitData'><p>Split Data</p></a></li>
<li><a href='#stochastic'>
<p>Stochastic record linkage.</p></a></li>
<li><a href='#strcmp'><p>String Metrics</p></a></li>
<li><a href='#subset'>
<p>Subset operator for record linkage objects</p></a></li>
<li><a href='#summary'><p>Print Summary of Record Linkage Data</p></a></li>
<li><a href='#summary.RLBigData'>
<p>summary methods for <code>"RLBigData"</code> objects.</p></a></li>
<li><a href='#summary.RLResult'>
<p>Summary method for <code>"RLResult"</code> objects.</p></a></li>
<li><a href='#texSummary'>
<p>LaTeX Summary of linkage results</p></a></li>
<li><a href='#trainSupv'><p>Train a Classifier</p></a></li>
<li><a href='#unorderedPairs'><p>Create Unordered Pairs</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Version:</td>
<td>0.4-12.4</td>
</tr>
<tr>
<td>Title:</td>
<td>Record Linkage Functions for Linking and Deduplicating Data Sets</td>
</tr>
<tr>
<td>Description:</td>
<td>Provides functions for linking and deduplicating data sets.
  Methods based on a stochastic approach are implemented as well as 
  classification algorithms from the machine learning domain. For details, 
  see our paper "The RecordLinkage Package: Detecting Errors in Data" 
  Sariyar M / Borg A (2010) &lt;<a href="https://doi.org/10.32614%2FRJ-2010-017">doi:10.32614/RJ-2010-017</a>&gt;. </td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0), DBI, RSQLite(&ge; 1.0.0), ff</td>
</tr>
<tr>
<td>Imports:</td>
<td>e1071, rpart, ada, ipred, stats, evd, methods, data.table (&ge;
1.7.8), nnet, xtable</td>
</tr>
<tr>
<td>Suggests:</td>
<td>RUnit, knitr</td>
</tr>
<tr>
<td>Collate:</td>
<td>register-S3-classes.r RLBigData-classes.r RLResult-class.r
accessor-methods.r evt.r classify.r classifySupv-methods.r
genSamples.r strcmp.r compare.r getPairs.r summary.r
em-methods.r internals.r em.r mygllm.r epilink-methods.r
phonetics.r onAttach.r getPairs-methods.r serialization.r
tools.r stochastic.r</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2022-11-08 13:25:36 UTC; sym3</td>
</tr>
<tr>
<td>Author:</td>
<td>Murat Sariyar [aut, cre],
  Andreas Borg [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Murat Sariyar &lt;murat.sariyar@bfh.ch&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2022-11-08 14:10:15 UTC</td>
</tr>
</table>
<hr>
<h2 id='+25append+25-methods'>
Concatenate comparison patterns or classification results
</h2><span id='topic++25append+25-methods'></span><span id='topic++25append+25'></span><span id='topic++25append+25+2CRecLinkData+2CRecLinkData-method'></span><span id='topic++25append+25+2CRecLinkResult+2CRecLinkResult-method'></span>

<h3>Description</h3>

<p>Combines two object of class  <code>"<a href="#topic+RecLinkData">RecLinkData</a>"</code>
or <code>"<a href="#topic+RecLinkResult">RecLinkResult</a>"</code> by concatenating comparison patterns
and, if available, weights and classification results.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
x %append% y

## S4 method for signature 'RecLinkData,RecLinkData'
x %append% y

## S4 method for signature 'RecLinkResult,RecLinkResult'
x %append% y
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="+2B25append+2B25-methods_+3A_x">x</code>, <code id="+2B25append+2B25-methods_+3A_y">y</code></td>
<td>
<p>The objects to combine.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object with class corresponding to the input objects which represents
the concatenation of <code>x</code> and <code>y</code>. Its
component <code>pairs</code> is <code>rbind(x$pairs, y$pairs)</code>. If both <code>x</code>
and <code>y</code> have weights stored in component <code>Wdata</code>, the result
gets <code>c(x$Wdata, y$Wdata)</code> as component <code>Wdata</code>. For the
<code>"<a href="#topic+RecLinkResult">RecLinkResult</a>"</code> method, the result also includes the
concatenation of the predicted classes in <code>x</code> and <code>y</code> as
component <code>prediction</code>.
</p>


<h3>Note</h3>

<p>The methods perform only a minimum of integrity checks, so the user has to
make sure that the underlying data, the formats of comparison patterns
(e.g. excluded columns) and the type of weights (method and parameters of
weight calculation) match.
</p>


<h3>Author(s)</h3>

<p>Andreas Borg, Murat Sariyar</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(RLdata500)
rpairs1=compare.dedup(RLdata500, blockfld=1, identity = identity.RLdata500)
rpairs2=compare.dedup(RLdata500, blockfld=3, identity = identity.RLdata500)

summary(rpairs1)
summary(rpairs2)
summary(rpairs1 %append% rpairs2)
</code></pre>

<hr>
<h2 id='classifySupv'>Supervised Classification</h2><span id='topic+classifySupv'></span><span id='topic+classifySupv-methods'></span><span id='topic+classifySupv+2CRecLinkClassif+2CRecLinkData-method'></span><span id='topic+classifySupv+2CRecLinkClassif+2CRLBigData-method'></span>

<h3>Description</h3>

<p>Supervised classification of record pairs based on a trained model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
  classifySupv(model, newdata, ...)

  ## S4 method for signature 'RecLinkClassif,RecLinkData'
classifySupv(model, newdata,
    convert.na = TRUE, ...)

  ## S4 method for signature 'RecLinkClassif,RLBigData'
classifySupv(model, newdata,
    convert.na = TRUE, withProgressBar = (sink.number()==0), ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="classifySupv_+3A_model">model</code></td>
<td>
<p>Object of class <code>RecLinkClassif</code>. The
calibrated model. See <code><a href="#topic+trainSupv">trainSupv</a></code>.</p>
</td></tr>
<tr><td><code id="classifySupv_+3A_newdata">newdata</code></td>
<td>
<p>Object of class <code>"<a href="#topic+RecLinkData">RecLinkData</a>"</code>
or <code>"<a href="#topic+RLBigData-class">RLBigData</a>"</code>. The data to classify.</p>
</td></tr>
<tr><td><code id="classifySupv_+3A_convert.na">convert.na</code></td>
<td>
<p>Logical. Whether to convert missing values in the comparison
patterns to 0.</p>
</td></tr>
<tr><td><code id="classifySupv_+3A_withprogressbar">withProgressBar</code></td>
<td>
<p>Whether to display a progress bar</p>
</td></tr>
<tr><td><code id="classifySupv_+3A_...">...</code></td>
<td>
<p>Further arguments for the <code><a href="stats.html#topic+predict">predict</a></code> method.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The record pairs in <code>newdata</code> are classified by calling
the appropriate <code><a href="stats.html#topic+predict">predict</a></code> method for <code>model$model</code>.
</p>
<p>By default, the <code>"<a href="#topic+RLBigDataDedup-class">RLBigDataDedup</a>"</code> method displays a
progress bar unless output is diverted by <code>sink</code>, e.g. when processing
a Sweave file.
</p>


<h3>Value</h3>

<p>For the <code>"<a href="#topic+RecLinkData">RecLinkData</a>"</code> method, a S3 object
of class <code>"<a href="#topic+RecLinkResult">RecLinkResult</a>"</code> that represents a copy
of <code>newdata</code> with element <code>rpairs$prediction</code>, which stores
the classification result, as addendum.
</p>
<p>For the <code>"<a href="#topic+RLBigData-class">RLBigData</a>"</code> method, a S4 object of class
<code>"<a href="#topic+RLResult-class">RLResult</a>"</code>.
</p>


<h3>Author(s)</h3>

<p>Andreas Borg, Murat Sariyar</p>


<h3>See Also</h3>

<p><code><a href="#topic+trainSupv">trainSupv</a></code> for training of classifiers,
<code><a href="#topic+classifyUnsup">classifyUnsup</a></code> for unsupervised classification.</p>


<h3>Examples</h3>

<pre><code class='language-R'># Split data into training and validation set, train and classify with rpart
data(RLdata500)
pairs=compare.dedup(RLdata500, identity=identity.RLdata500,
                    blockfld=list(1,3,5,6,7))
l=splitData(pairs, prop=0.5, keep.mprop=TRUE)                    
model=trainSupv(l$train, method="rpart", minsplit=5)
result=classifySupv(model=model, newdata=l$valid)
summary(result)

</code></pre>

<hr>
<h2 id='classifyUnsup'>Unsupervised Classification</h2><span id='topic+classifyUnsup'></span>

<h3>Description</h3>

<p>Classify record pairs with unsupervised clustering methods.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>classifyUnsup(rpairs, method, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="classifyUnsup_+3A_rpairs">rpairs</code></td>
<td>
<p>Object of type <code><a href="#topic+RecLinkData">RecLinkData</a></code>. The data to
classify.</p>
</td></tr>
<tr><td><code id="classifyUnsup_+3A_method">method</code></td>
<td>
<p>The classification method to use. One of <code>"kmeans"</code>,
<code>"bclust"</code>.</p>
</td></tr>
<tr><td><code id="classifyUnsup_+3A_...">...</code></td>
<td>
<p>Further arguments for the classification method</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A clustering algorithm is applied to find clusters in the comparison patterns. In the
case of two clusters (the default), the cluster further from the origin 
(i.e. representing higher similarity values) is interpreted as the set of links, 
the other as the set of non-links.
</p>
<p>Supported methods are:
</p>

<dl>
<dt>kmeans</dt><dd><p>K-means clustering, see <code><a href="stats.html#topic+kmeans">kmeans</a></code>.</p>
</dd>
<dt>bclust</dt><dd><p>Bagged clustering, see <code><a href="e1071.html#topic+bclust">bclust</a></code>.</p>
</dd>
</dl>



<h3>Value</h3>

<p>An object of class <code>"<a href="#topic+RecLinkResult">RecLinkResult</a>"</code> that represents a copy
of <code>newdata</code> with element <code>rpairs$prediction</code>, which stores
the classification result, as addendum.
</p>


<h3>Author(s)</h3>

<p>Andreas Borg, Murat Sariyar</p>


<h3>See Also</h3>

<p><code><a href="#topic+trainSupv">trainSupv</a></code> and <code><a href="#topic+classifySupv">classifySupv</a></code> for supervised
classification.</p>


<h3>Examples</h3>

<pre><code class='language-R'># Classification with bclust
data(RLdata500)
rpairs=compare.dedup(RLdata500, identity=identity.RLdata500,
                    blockfld=list(1,3,5,6,7))
result=classifyUnsup(rpairs,method="bclust")
summary(result)                    
</code></pre>

<hr>
<h2 id='clone'>
Serialization of record linkage object.
</h2><span id='topic+clone'></span><span id='topic+saveRLObject'></span><span id='topic+loadRLObject'></span><span id='topic+clone-methods'></span><span id='topic+clone+2CRLBigData-method'></span><span id='topic+clone+2CRLResult-method'></span><span id='topic+saveRLObject-methods'></span><span id='topic+saveRLObject+2CRLBigData-method'></span><span id='topic+saveRLObject+2CRLResult-method'></span>

<h3>Description</h3>

<p>Saving, loading and deep copying of record linkage objects
for big data sets.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  clone(object, ...)
  saveRLObject(object, file, ...)
  loadRLObject(file)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="clone_+3A_object">object</code></td>
<td>
<p>Object of class <code>"<a href="#topic+RLBigData-class">RLBigData</a>"</code>. The object to save.</p>
</td></tr>
<tr><td><code id="clone_+3A_file">file</code></td>
<td>
<p>The name of the file to save to or load from.</p>
</td></tr>
<tr><td><code id="clone_+3A_...">...</code></td>
<td>
<p>Optional arguments for possible additions, currently not used.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The classes for big data sets make use of file-backed data structures from
the <span class="pkg">ff</span> package, therefore the <code>load</code> and <code>save</code> mechanism of
R is not sufficient for persistent storage of these objects. Also, assignment
via <code>&lt;-</code> does not duplicate the <span class="pkg">ff</span> data structures.
</p>
<p><code>clone</code> makes a deep copy of an object by duplicating the underlying
files.
</p>
<p><code>saveRLObject</code> saves an object to zip file containing
a dump of the R object as well as the associated <span class="pkg">ff</span> files.
</p>
<p><code>loadRLObject</code> loads an object from a file saved by <code>saveRLObject</code>.
</p>
<p><code>clone</code> and <code>saveRLObject</code> are generic functions with methods for
<code>"<a href="#topic+RLBigData-class">RLBigData</a>"</code> and <code>"<a href="#topic+RLResult-class">RLResult</a>"</code>.
</p>
<p>If <code>loadRLObject</code> is called with <code>inPlace = FALSE</code> (the default),
a working copy of the database is made in a temporary file and the original
file left untouched. Calling with <code>inPlace = TRUE</code> sets the provided file as
working copy and changes made to the database are persistent. This option is
useful when working with large files in order to prevent disk usage
overhead.
</p>
<p><code>saveRLObject</code> and <code>loadRLObject</code> require working zip / unzip programs.
</p>


<h3>Value</h3>

<p><code>clone</code> returns a deep copy of <code>object</code>.
</p>
<p><code>loadRLObject</code> returns the loaded object.
</p>
<p><code>saveRLObject</code> is used for its side effects.
</p>


<h3>Note</h3>

<p>Objects loaded with <code>inPlace = TRUE</code> must be saved again after changes
have been made to the object (e.g. calculation of weights).
</p>


<h3>Author(s)</h3>

<p>Andreas Borg, Murat Sariyar
</p>

<hr>
<h2 id='compare'>Compare Records</h2><span id='topic+compare.dedup'></span><span id='topic+compare.linkage'></span>

<h3>Description</h3>

<p>Builds comparison patterns of record pairs for deduplication or
linkage.</p>


<h3>Usage</h3>

<pre><code class='language-R'>compare.dedup (dataset, blockfld = FALSE, phonetic = FALSE, 
  phonfun = soundex, strcmp = FALSE, strcmpfun = jarowinkler, exclude = FALSE,
  identity = NA, n_match = NA, n_non_match = NA)

compare.linkage (dataset1, dataset2, blockfld = FALSE, 
  phonetic = FALSE, phonfun = soundex, strcmp = FALSE, 
  strcmpfun = jarowinkler, exclude = FALSE, identity1 = NA, identity2 = NA,
  n_match = NA, n_non_match = NA)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="compare_+3A_dataset">dataset</code></td>
<td>
<p>Table of records to be deduplicated. Either a data frame or 
a matrix.</p>
</td></tr> 
<tr><td><code id="compare_+3A_dataset1">dataset1</code>, <code id="compare_+3A_dataset2">dataset2</code></td>
<td>
<p>Two data sets to be linked.</p>
</td></tr>
<tr><td><code id="compare_+3A_blockfld">blockfld</code></td>
<td>
<p>Blocking field definition. A list of integer or character vectors
with column indices or <code>FALSE</code> to disable
blocking. See details and examples.</p>
</td></tr>
<tr><td><code id="compare_+3A_phonetic">phonetic</code></td>
<td>
<p>Determines usage of a phonetic code. If <code>FALSE</code>, no
phonetic code will be used; if <code>TRUE</code>, the phonetic code
will be used for all columns; if a numeric or character vector is given, the
phonetic code will be used for the specified columns.</p>
</td></tr>
<tr><td><code id="compare_+3A_phonfun">phonfun</code></td>
<td>
<p>Function for phonetic code. See details.</p>
</td></tr>
<tr><td><code id="compare_+3A_strcmp">strcmp</code></td>
<td>
<p>Determines usage of a string metric. Used in the same manner
as <code>phonetic</code></p>
</td></tr>
<tr><td><code id="compare_+3A_strcmpfun">strcmpfun</code></td>
<td>
<p>User-defined function for string metric. See details.</p>
</td></tr>
<tr><td><code id="compare_+3A_exclude">exclude</code></td>
<td>
<p>Columns to be excluded. A numeric or character vector specifying the columns which should be excluded from comparison</p>
</td></tr>
<tr><td><code id="compare_+3A_identity">identity</code>, <code id="compare_+3A_identity1">identity1</code>, <code id="compare_+3A_identity2">identity2</code></td>
<td>
<p>Optional numerical vectors for identifying matches and non-matches. In a deduplication process, two records <code>dataset[i,]</code> and <code>dataset[j,]</code> are a true match if and only if           <code>identity[i,]==identity[j,]</code>. In a linkage process, two records <code>dataset1[i,]</code> and <code>dataset2[j,]</code> are a true match if and only if <br /> <code>identity1[i,]==identity2[j,]</code>.</p>
</td></tr>
<tr><td><code id="compare_+3A_n_match">n_match</code>, <code id="compare_+3A_n_non_match">n_non_match</code></td>
<td>
<p>Number of desired matches and non-matches in the result.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>These functions build record pairs and finally comparison patterns
by which these pairs are later classified as links or non-links. They make up
the initial stage in a Record Linkage process after possibly 
normalizing the data. Two general
scenarios are reflected by the two functions: <code>compare.dedup</code> works on a
single data set which is to be deduplicated, <code>compare.linkage</code> is intended
for linking two data sets together.
</p>
<p>Data sets are represented as data frames or matrices (typically of type 
character), each row representing one record, each column representing one
field or attribute (like first name, date of birth...). Row names are not
retained in the record pairs. If an identifier other than row number is
needed, it should be supplied as a designated column and excluded from
comparison (see note on <code>exclude</code> below).
</p>
<p>Each element of <code>blockfld</code> specifies a set of columns in which two
records must agree to be included in the output. Each blocking definition in
the list is applied individually, the sets obtained 
thereby are combined by a union operation.                              
If <code>blockfld</code> is <code>FALSE</code>, no blocking will be performed,
which leads to a large number of record pairs 
(<code class="reqn">\frac{n(n-1)}{2}</code> where <code class="reqn">n</code> is the number of
records).
</p>
<p>As an alternative to blocking, a determined number of <code>n_match</code> matches 
and <code>n_non_match</code> non-matches can be drawn if <code>identity</code> or
<code>identity1</code> and <code>identity2</code> are supplied. This is relevant for generating training sets for the supervised classificators (see <code><a href="#topic+trainSupv">trainSupv</a></code>).
</p>
<p>Fields can be excluded from the linkage process by supplying their column index in the vector <code>exclude</code>, which is especially useful for external identifiers. Excluded fields can still be used for blocking, also with phonetic code.
</p>
<p>Phonetic codes and string similarity measures are supported for enhanced detection of misspellings. Applying a phonetic code leads to a binary values, where 1 denotes equality of the generated phonetic code. A string comparator leads to a similarity value in the range <code class="reqn">[0,1]</code>.
</p>
<p>String comparison is not allowed on a field for which a phonetic code is generated. For phonetic encoding functions included in the package,  see <a href="#topic+phonetics">phonetics</a>. For the included string comparators, see <code><a href="#topic+jarowinkler">jarowinkler</a></code> and <code><a href="#topic+levenshteinSim">levenshteinSim</a></code>.
</p>
<p>Please note that phonetic code and string metrics can slow down the generation of comparison patterns significantly.
</p>
<p>User-defined functions for phonetic code and string comparison can be supplied  via the arguments <code>phonfun</code> and <code>strcmpfun</code>. <code>phonfun</code> is expected to have a single character argument (the string to be transformed) and must return a character value with the encoded string. 
</p>
<p><code>strcmpfun</code> must have as arguments the two strings to be compared and return a similarity value in the range <code class="reqn">[0,1]</code>, with 0 denoting the lowest and 1 denoting the highest degree of similarity. Both functions must be fully vectorized to work on matrices.
</p>


<h3>Value</h3>

<p>An object of class <code>RecLinkPairs</code> with the following components:
</p>
<table role = "presentation">
<tr><td><code>data</code></td>
<td>
<p>Copy of the records, converted to a data frame.</p>
</td></tr>
<tr><td><code>pairs</code></td>
<td>
<p>Generated comparison patterns.</p>
</td></tr>
<tr><td><code>frequencies</code></td>
<td>
<p>For each column included in <code>pairs</code>, the average
frequency of values (reciprocal of number of distinct values).</p>
</td></tr>   
</table>


<h3>Author(s)</h3>

<p>Andreas Borg, Murat Sariyar</p>


<h3>See Also</h3>

<p><code><a href="#topic+RecLinkData">RecLinkData</a></code> for the format of returned objects.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(RLdata500)
data(RLdata10000)

# deduplication without blocking, use string comparator on names
## Not run: rpairs=compare.dedup(RLdata500,strcmp=1:4)
# linkage with blocking on first name and year of birth, use phonetic
# code on first components of first and last name

## Not run: rpairs=compare.linkage(RLdata500,RLdata10000,blockfld=c(1,7),phonetic=c(1,3))
# deduplication with blocking on either last name or complete date of birth,
# use string comparator on all fields, include identity information
## Not run: rpairs=compare.dedup(RLdata500, identity=identity.RLdata500, strcmp=TRUE,
  blockfld=list(1,c(5,6,7)))
## End(Not run)

# Draw 100 matches and 1000 non-matches
## Not run: rpairs=compare.dedup(RLdata10000,identity=identity.RLdata10000,n_match=100,
  n_non_match=10000)
## End(Not run)
</code></pre>

<hr>
<h2 id='deleteNULLs'>Remove NULL Values</h2><span id='topic+deleteNULLs'></span>

<h3>Description</h3>

<p>Removes all <code>NULL</code> elements from a list or vector.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>deleteNULLs(x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="deleteNULLs_+3A_x">x</code></td>
<td>
<p>A vector or list</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A copy of <code>x</code> with <code>NULL</code> values removed.
</p>


<h3>Note</h3>

<p>This function is internally used for simple lists and vectors. The behaviour for nested lists and vectors embedded in lists is not thoroughly tested.
</p>


<h3>References</h3>

<p>Taken from a posting by Jim Holtman on the R-help mailing list,
<a href="https://stat.ethz.ch/pipermail/r-help/2006-August/111896.html">https://stat.ethz.ch/pipermail/r-help/2006-August/111896.html</a></p>

<hr>
<h2 id='editMatch'>
Edit Matching Status
</h2><span id='topic+editMatch'></span><span id='topic+editMatch-methods'></span><span id='topic+editMatch+2CRecLinkData-method'></span><span id='topic+editMatch+2CRLBigData-method'></span>

<h3>Description</h3>

<p>Allows editing the matching status of record pairs.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>editMatch(rpairs)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="editMatch_+3A_rpairs">rpairs</code></td>
<td>

<p>A <code>"<a href="#topic+RecLinkData">RecLinkData</a>"</code> or <code>"<a href="#topic+RLBigData-class">RLBigData</a>"</code> object.
The record pairs to edit.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function pops up an editor (via <code><a href="utils.html#topic+edit">edit</a></code>) where each record
pair in <code>rpairs</code> is printed in two consecutive lines, pairs separated by blank
lines. The matching status is printed and can be edited in the last column
following the first respective record. A match is denoted by 1, a non-match
by 0. <code>NA</code>s are possible to mark pairs with unknown status. Changes in
other fields are ignored.
</p>
<p>Manual editing of the matching status is useful for clerical review in 
general and in particular to label training sets. In conjunction with
<code><a href="#topic+getMinimalTrain">getMinimalTrain</a></code>, good results can be obtained with a manageable
effort of manual review.
</p>


<h3>Value</h3>

<p>A copy of <code>rpairs</code> with edited matching status.
</p>


<h3>Author(s)</h3>

<p>Andreas Borg
</p>


<h3>See Also</h3>

<p><code><a href="#topic+getMinimalTrain">getMinimalTrain</a></code>
</p>

<hr>
<h2 id='emClassify'>Weight-based Classification of Data Pairs</h2><span id='topic+emClassify'></span><span id='topic+emClassify+2CRLBigData-method'></span><span id='topic+emClassify+2CRecLinkData+2CANY+2CANY-method'></span><span id='topic+emClassify+2CRLBigData+2CANY+2CANY-method'></span><span id='topic+emClassify+2CRecLinkData+2Cmissing+2Cmissing-method'></span><span id='topic+emClassify+2CRLBigData+2Cmissing+2Cmissing-method'></span>

<h3>Description</h3>

<p>Classifies data pairs to which weights were assigned by <code><a href="#topic+emWeights">emWeights</a></code>.
Based on user-defined thresholds or predefined error rates.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  emClassify(rpairs, threshold.upper = Inf,
    threshold.lower = threshold.upper, my = Inf, ny = Inf, ...)

  ## S4 method for signature 'RecLinkData,ANY,ANY'
emClassify(rpairs, threshold.upper = Inf,
    threshold.lower = threshold.upper, my = Inf, ny = Inf)

  ## S4 method for signature 'RLBigData,ANY,ANY'
emClassify(rpairs, threshold.upper = Inf,
    threshold.lower = threshold.upper, my = Inf, ny = Inf,
    withProgressBar = (sink.number()==0))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="emClassify_+3A_rpairs">rpairs</code></td>
<td>
<p><code><a href="#topic+RecLinkData">RecLinkData</a></code> object with weight information.</p>
</td></tr>
<tr><td><code id="emClassify_+3A_my">my</code></td>
<td>
<p>A probability. Error bound for false positives.</p>
</td></tr>
<tr><td><code id="emClassify_+3A_ny">ny</code></td>
<td>
<p>A probability. Error bound for false negatives.</p>
</td></tr>
<tr><td><code id="emClassify_+3A_threshold.upper">threshold.upper</code></td>
<td>
<p>A numeric value. Threshold for links.</p>
</td></tr>
<tr><td><code id="emClassify_+3A_threshold.lower">threshold.lower</code></td>
<td>
<p>A numeric value. Threshold for possible links.</p>
</td></tr>
<tr><td><code id="emClassify_+3A_withprogressbar">withProgressBar</code></td>
<td>
<p>Whether to display a progress bar</p>
</td></tr>
<tr><td><code id="emClassify_+3A_...">...</code></td>
<td>
<p>Placeholder for method-specific arguments.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Two general approaches are implemented. The classical procedure
by Fellegi and Sunter (see references) minimizes the number of
possible links with given error levels for false links (<code>my</code>) and
false non-links (<code>ny</code>).
</p>
<p>The second approach requires thresholds for links and possible links to be set
by the user. A pair with weight <code class="reqn">w</code> is classified as a link if 
<code class="reqn">w\geq \textit{threshold.upper}</code>, as a possible link if 
<code class="reqn">\textit{threshold.upper}\geq w\geq \textit{threshold.lower}</code> and as a non-link if <code class="reqn">w&lt;\textit{threshold.lower}</code>.
</p>
<p>If <code>threshold.upper</code> or <code>threshold.lower</code> is given, the 
threshold-based approach is used, otherwise, if one of the error bounds is
given, the Fellegi-Sunter model. If only <code>my</code> is supplied, links are
chosen to meet the error bound and all other pairs are classified as non-links
(the equivalent case holds if only <code>ny</code> is specified). If no further arguments
than <code>rpairs</code> are given, a single threshold of 0 is used.
</p>


<h3>Value</h3>

<p>For the <code>"<a href="#topic+RecLinkData">RecLinkData</a>"</code> method, a S3 object
of class <code>"<a href="#topic+RecLinkResult">RecLinkResult</a>"</code> that represents a copy
of <code>newdata</code> with element <code>rpairs$prediction</code>, which stores
the classification result, as addendum.
</p>
<p>For the <code>"<a href="#topic+RLBigData-class">RLBigData</a>"</code> method, a S4 object of class
<code>"<a href="#topic+RLResult-class">RLResult</a>"</code>.
</p>


<h3>Note</h3>

<p>The quality of classification of the Fellegi-Sunter method 
relies strongly on reasonable estimations of m- and u-probabilities. 
The results should be evaluated  critically.
</p>


<h3>Author(s)</h3>

<p>Andreas Borg, Murat Sariyar</p>


<h3>References</h3>

<p>Ivan P. Fellegi, Alan B. Sunter: A Theory for Record Linkage,
in: Journal of the American Statistical Association Vol. 64, No. 328 
(Dec., 1969), pp. 1183&ndash;1210.</p>


<h3>See Also</h3>

<p><code><a href="#topic+getPairs">getPairs</a></code> to produce output from which thresholds can
be determined conveniently.</p>

<hr>
<h2 id='emWeights'>Calculate weights</h2><span id='topic+emWeights'></span><span id='topic+emWeights-methods'></span><span id='topic+emWeights+2CRecLinkData-method'></span><span id='topic+emWeights+2CRLBigData-method'></span>

<h3>Description</h3>

<p>Calculates weights for Record Linkage based on an EM algorithm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  emWeights(rpairs, cutoff = 0.95, ...)

  ## S4 method for signature 'RecLinkData'
emWeights(rpairs, cutoff = 0.95, ...)

  ## S4 method for signature 'RLBigData'
emWeights(rpairs, cutoff = 0.95,
    verbose = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="emWeights_+3A_rpairs">rpairs</code></td>
<td>
<p>The record pairs for which to
compute weights. See details.</p>
</td></tr>
<tr><td><code id="emWeights_+3A_cutoff">cutoff</code></td>
<td>
<p>Either a numeric value in the range [0,1] or a vector with the same 
length as the number of attributes in the data. Cutoff value for string comparator.</p>
</td></tr>
<tr><td><code id="emWeights_+3A_verbose">verbose</code></td>
<td>
<p>Logical. Whether to print progress messages.</p>
</td></tr>
<tr><td><code id="emWeights_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to <code><a href="#topic+mygllm">mygllm</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Since package version 0.3, this is a generic functions with methods for
S3 objects of class <code><a href="#topic+RecLinkData">RecLinkData</a></code> as well as S4 objects
of classes <code>"<a href="#topic+RLBigDataDedup-class">RLBigDataDedup</a>"</code> and
<code>"<a href="#topic+RLBigDataLinkage-class">RLBigDataLinkage</a>"</code>.
</p>
<p>The weight of a record pair is calculated by <code class="reqn">\log_{2}\frac{M}{U}</code>, where <code class="reqn">M</code> and <code class="reqn">U</code> are estimated m- and u-probabilities
for the present comparison pattern. If a string comparator is used, weights
are first calculated based on a binary table where all comparison 
values greater or equal <code>cutoff</code> are set to one, all other to zero.
The resulting weight is adjusted by adding for every pair
<code class="reqn">\log_{2}\left(\prod_{j:s^{i}_{j}\geq \textit{cutoff }}s^{i}_{j}\right)</code>, where
<code class="reqn">s^{i}_{j}</code> is the value of the string metric for attribute j in 
data pair i.
</p>
<p>The appropriate value of <code>cutoff</code> depends on the choice of string
comparator. The default is adjusted to <code><a href="#topic+jarowinkler">jarowinkler</a></code>,
a lower value (e.g. 0.7) is recommended for <code><a href="#topic+levenshteinSim">levenshteinSim</a></code>.
</p>
<p>Estimation of <code class="reqn">M</code> and <code class="reqn">U</code> is done by an EM algorithm, implemented by
<code><a href="#topic+mygllm">mygllm</a></code>. For every comparison
pattern, the estimated numbers of matches and non-matches are used to compute
the corresponding probabilities. Estimations based on the average 
frequencies of values and given error rates are taken as initial values.
In our experience, this increases stability and performance of the
EM algorithm.
</p>
<p>Some progress messages are printed to the message stream (see
<code><a href="base.html#topic+message">message</a></code> if <code>verbose == TRUE</code>.
This includes progress bars, but these are suppressed if output is diverted by
<code><a href="base.html#topic+sink">sink</a></code> to avoid cluttering the output file.
</p>


<h3>Value</h3>

<p>A copy of <code>rpairs</code> with the weights attached. See the class documentation
(<code><a href="#topic+RecLinkData">RecLinkData</a></code>, <code>"<a href="#topic+RLBigDataDedup-class">RLBigDataDedup</a>"</code> and
<code>"<a href="#topic+RLBigDataLinkage-class">RLBigDataLinkage</a>"</code>) on how weights are stored.
</p>


<h3>Side effects</h3>

<p>The <code>"<a href="#topic+RLBigData-class">RLBigData</a>"</code> method writes to a disk file containing
a <code>ffvector</code> that contains the calculated weights.
belonging to <code>object</code>
</p>


<h3>Author(s)</h3>

<p>Andreas Borg, Murat Sariyar</p>


<h3>References</h3>

<p>William E. Winkler: Using the EM Algorithm for Weight Computation
in the Fellegi-Sunter Model of Record Linkage, in: Proceedings of the Section 
on Survey Research Methods, American Statistical Association 1988, 
pp. 667&ndash;671.</p>


<h3>See Also</h3>

<p><code><a href="#topic+emClassify">emClassify</a></code> for classification of weighted pairs.
<code><a href="#topic+epiWeights">epiWeights</a></code> for a different approach for weight calculation.
</p>

<hr>
<h2 id='epiClassify'>
Classify record pairs with EpiLink weights
</h2><span id='topic+epiClassify'></span><span id='topic+epiClassify-methods'></span><span id='topic+epiClassify+2CRLBigData-method'></span><span id='topic+epiClassify+2CRecLinkData-method'></span>

<h3>Description</h3>

<p>Classifies record pairs as link, non-link or possible link based on
weights computed by <code><a href="#topic+epiWeights">epiWeights</a></code> and the thresholds
passed as arguments.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>epiClassify(rpairs, threshold.upper, threshold.lower = threshold.upper,
  ...)

## S4 method for signature 'RecLinkData'
epiClassify(rpairs, threshold.upper, threshold.lower = threshold.upper)

## S4 method for signature 'RLBigData'
epiClassify(rpairs, threshold.upper, threshold.lower = threshold.upper,
  e = 0.01, f = getFrequencies(rpairs), withProgressBar = (sink.number()==0))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="epiClassify_+3A_rpairs">rpairs</code></td>
<td>

<p><code><a href="#topic+RecLinkData">RecLinkData</a></code> object. Record pairs to be classified.</p>
</td></tr>
<tr><td><code id="epiClassify_+3A_threshold.upper">threshold.upper</code></td>
<td>
<p>A numeric value between 0 and 1. </p>
</td></tr>
<tr><td><code id="epiClassify_+3A_threshold.lower">threshold.lower</code></td>
<td>
<p>A numeric value between 0 and 1 lower than <code>threshold.upper</code></p>
</td></tr>
<tr><td><code id="epiClassify_+3A_e">e</code></td>
<td>
<p>Numeric vector. Estimated error rate(s).</p>
</td></tr>
<tr><td><code id="epiClassify_+3A_f">f</code></td>
<td>
<p>Numeric vector. Average frequency of attribute values.</p>
</td></tr>
<tr><td><code id="epiClassify_+3A_withprogressbar">withProgressBar</code></td>
<td>
<p>Logical. Whether to display a progress bar.</p>
</td></tr>
<tr><td><code id="epiClassify_+3A_...">...</code></td>
<td>
<p>Placeholder for optional arguments</p>
</td></tr>
</table>


<h3>Details</h3>

<p>All record pairs with weights greater or
equal <code>threshold.upper</code> are classified as links. Record pairs with
weights smaller than <code>threshold.upper</code> and greater or equal
<code>threshold.lower</code> are classified as possible links. All remaining
records are classified as non-links.
</p>
<p>For the <code>"RecLinkData"</code> method, weights must have been calculated
for <code>rpairs</code> using <code><a href="#topic+epiWeights">epiWeights</a></code>.
</p>
<p>A progress bar is displayed by the <code>"RLBigData"</code> method only if
weights are calculated on the fly and, by default, unless output is diverted by
<code><a href="base.html#topic+sink">sink</a></code> (e.g. in a Sweave script).
</p>


<h3>Value</h3>

<p>For the <code>"<a href="#topic+RecLinkData">RecLinkData</a>"</code> method, a S3 object
of class <code>"<a href="#topic+RecLinkResult">RecLinkResult</a>"</code> that represents a copy
of <code>newdata</code> with element <code>rpairs$prediction</code>, which stores
the classification result, as addendum.
</p>
<p>For the <code>"<a href="#topic+RLBigData-class">RLBigData</a>"</code> method, a S4 object of class
<code>"<a href="#topic+RLResult-class">RLResult</a>"</code>.
</p>


<h3>Author(s)</h3>

<p>Andreas Borg, Murat Sariyar</p>


<h3>See Also</h3>

<p><code><a href="#topic+epiWeights">epiWeights</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># generate record pairs
data(RLdata500)
p=compare.dedup(RLdata500,strcmp=TRUE ,strcmpfun=levenshteinSim,
  identity=identity.RLdata500, blockfld=list("by", "bm", "bd"))

# calculate weights
p=epiWeights(p)

# classify and show results
summary(epiClassify(p,0.6))
</code></pre>

<hr>
<h2 id='epiWeights'>
Calculate EpiLink weights
</h2><span id='topic+epiWeights'></span><span id='topic+epiWeights-methods'></span><span id='topic+epiWeights+2CRecLinkData-method'></span><span id='topic+epiWeights+2CRLBigData-method'></span>

<h3>Description</h3>

<p>Calculates weights for record pairs based on the EpiLink approach
(see references).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  epiWeights(rpairs, e = 0.01, f, ...)

  ## S4 method for signature 'RecLinkData'
epiWeights(rpairs, e = 0.01, f = rpairs$frequencies)

  ## S4 method for signature 'RLBigData'
epiWeights(rpairs, e = 0.01, f = getFrequencies(rpairs),
    withProgressBar = (sink.number()==0))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="epiWeights_+3A_rpairs">rpairs</code></td>
<td>
<p>The record pairs for which to
compute weights. See details.</p>
</td></tr>
<tr><td><code id="epiWeights_+3A_e">e</code></td>
<td>

<p>Numeric vector. Estimated error rate(s).
</p>
</td></tr>
<tr><td><code id="epiWeights_+3A_f">f</code></td>
<td>

<p>Numeric vector. Average frequency of attribute values.
</p>
</td></tr>
<tr><td><code id="epiWeights_+3A_withprogressbar">withProgressBar</code></td>
<td>
<p>Whether to display a progress bar</p>
</td></tr>
<tr><td><code id="epiWeights_+3A_...">...</code></td>
<td>
<p>Placeholder for method-specific arguments.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function calculates weights for record pairs based on the approach used by Contiero et alia in the EpiLink record linkage software (see references).
</p>
<p>Since package version 0.3, this is a generic function with methods for S3 objects of class <code><a href="#topic+RecLinkData">RecLinkData</a></code>
as well as S4 objects of classes  <code>"<a href="#topic+RLBigDataDedup-class">RLBigDataDedup</a>"</code> and
<code>"<a href="#topic+RLBigDataLinkage-class">RLBigDataLinkage</a>"</code>.
</p>
<p>The weight for a record pair <code class="reqn">(x^{1},x^{2})</code> is computed by the formula 
</p>
<p style="text-align: center;"><code class="reqn">\frac{\sum_{i}w_{i}s(x^{1}_{i},x^{2}_{i})}{\sum_{i}w_{i}}</code>
</p>

<p>where <code class="reqn">s(x^{1}_{i},x^{2}_{i})</code> is the value of a string comparison of
records <code class="reqn">x^{1}</code> and <code class="reqn">x^{2}</code> in the i-th field and <code class="reqn">w_{i}</code> is a weighting factor computed by 
</p>
<p style="text-align: center;"><code class="reqn">w_{i}=\log_{2}(1-e_{i})/f_{i}</code>
</p>
<p>,  where <code class="reqn">f_{i}</code> denotes the average frequency of values and <code class="reqn">e_{i}</code> the estimated error rate for field <code class="reqn">i</code>. 
</p>
<p>String comparison values are taken from the record pairs as they were generated with <code><a href="#topic+compare.dedup">compare.dedup</a></code> or <code><a href="#topic+compare.linkage">compare.linkage</a></code>. The use of binary patterns is possible, but in general yields poor results.
</p>
<p>The average frequency of values is by default taken from the object   <code>rpairs</code>. Both frequency and error rate <code>e</code> can be set to a single value, which will be recycled, or to a vector with distinct error rates for every field. 
</p>
<p>The error rate(s) and frequencie(s) must satisfy 
<code class="reqn">e_{i}\leq{}1-f_{i}</code> for all <code class="reqn">i</code>, otherwise the functions fails. Also, some other rare combinations can result in weights with illegal values (NaN, less than 0 or greater than 1). In this case a  warning is issued.
</p>
<p>By default, the <code>"<a href="#topic+RLBigDataDedup-class">RLBigDataDedup</a>"</code> method displays a progress bar unless output is diverted by <code>sink</code>, e.g. when processing a Sweave file.
</p>


<h3>Value</h3>

<p>A copy of <code>rpairs</code> with the weights attached. See the class documentation
(<code><a href="#topic+RecLinkData">RecLinkData</a></code>, <code>"<a href="#topic+RLBigDataDedup-class">RLBigDataDedup</a>"</code> and
<code>"<a href="#topic+RLBigDataLinkage-class">RLBigDataLinkage</a>"</code>) on how weights are stored.
</p>
<p>For the <code>"RLBigData"</code> method, the returned object is only a shallow
copy in the sense that it links to the same ff data files as database file as
<code>rpairs</code>.
</p>


<h3>Side effects</h3>

<p>The <code>"RLBigData"</code> method creates a <code>"ffvector"</code> object,
for which a disk file is created.
</p>


<h3>Author(s)</h3>

<p>Andreas Borg, Murat Sariyar
</p>


<h3>References</h3>

<p>P. Contiero et al., The EpiLink record linkage software, in: Methods of 
Information in Medicine 2005, 44 (1), 66&ndash;71.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+epiClassify">epiClassify</a></code> for classification based on EpiLink weights.
<code><a href="#topic+emWeights">emWeights</a></code> for a different approach for weight calculation.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># generate record pairs
data(RLdata500)
p=compare.dedup(RLdata500,strcmp=TRUE ,strcmpfun=levenshteinSim,
  identity=identity.RLdata500, blockfld=list("by", "bm", "bd"))

# calculate weights
p=epiWeights(p)

# classify and show results
summary(epiClassify(p,0.6))
</code></pre>

<hr>
<h2 id='ff_vector-class'>Class <code>"ff_vector"</code></h2><span id='topic+ff_vector-class'></span>

<h3>Description</h3>

<p>S4 representation of S3 class <code>"ff_vector"</code>, created by <code><a href="methods.html#topic+setOldClass">setOldClass</a></code>.
See <code><a href="ff.html#topic+ff">ff</a></code> for documentation of the underlying S3 class.
</p>


<h3>Objects from the Class</h3>

<p>A virtual Class: No objects may be created from it.</p>


<h3>Slots</h3>


<dl>
<dt><code>.S3Class</code>:</dt><dd><p>Object of class <code>"character"</code></p>
</dd>
</dl>



<h3>Extends</h3>

<p>Class <code>"<a href="methods.html#topic+oldClass-class">oldClass</a>"</code>, directly.
</p>


<h3>Methods</h3>

<p>No methods defined with class &quot;ff_vector&quot; in the signature.
</p>

<hr>
<h2 id='ffdf-class'>Class <code>"ffdf"</code></h2><span id='topic+ffdf-class'></span>

<h3>Description</h3>

<p>S4 representation of S3 class <code>"ffdf"</code>, created by <code><a href="methods.html#topic+setOldClass">setOldClass</a></code>.
See <code><a href="ff.html#topic+ffdf">ffdf</a></code> for documentation of the underlying S3 class.
</p>


<h3>Objects from the Class</h3>

<p>A virtual Class: No objects may be created from it.</p>


<h3>Slots</h3>


<dl>
<dt><code>.S3Class</code>:</dt><dd><p>Object of class <code>"character"</code></p>
</dd>
</dl>



<h3>Extends</h3>

<p>Class <code>"<a href="methods.html#topic+oldClass-class">oldClass</a>"</code>, directly.
</p>


<h3>Methods</h3>

<p>No methods defined with class &quot;ffdf&quot; in the signature.
</p>

<hr>
<h2 id='genSamples'>Generate Training Set</h2><span id='topic+genSamples'></span>

<h3>Description</h3>

<p>Generates training data by unsupervised classification.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>genSamples(dataset, num.non, des.mprop = 0.1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="genSamples_+3A_dataset">dataset</code></td>
<td>
<p>Object of class <code><a href="#topic+RecLinkData">RecLinkData</a></code>. Data pairs from 
which to sample.</p>
</td></tr>
<tr><td><code id="genSamples_+3A_num.non">num.non</code></td>
<td>
<p>Positive Integer. Number of desired non-links in the training set.</p>
</td></tr>
<tr><td><code id="genSamples_+3A_des.mprop">des.mprop</code></td>
<td>
<p>Real number in the range [0,1]. Ratio of number of links to
number of non-links in the training set.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The application of supervised classifiers (via <code><a href="#topic+classifySupv">classifySupv</a></code>)
requires a training set of record pairs with known matching status.
Where no such data are available, <code>genSamples</code> can be used to generate
training data. The matching status is determined by unsupervised
clustering with <code><a href="e1071.html#topic+bclust">bclust</a></code>. Subsequently, the desired number of 
links and  non-links are sampled.
</p>
<p>If the requested numbers of matches or non-matches is not feasible, a
warning is issued and the maximum possible number is considered.
</p>


<h3>Value</h3>

<p>A list of <code><a href="#topic+RecLinkResult-class">&quot;RecLinkResult&quot;</a></code> objects.
</p>
<table role = "presentation">
<tr><td><code>train</code></td>
<td>
<p>The sampled training data.</p>
</td></tr>
<tr><td><code>valid</code></td>
<td>
<p>All other record pairs</p>
</td></tr>
</table>
<p>Record pairs are split into the respective <code>pairs</code> components.
The <code>prediction</code> components represent the clustering result. If weights are
present in <code>dataset</code>, the corresponding values of <code>Wdata</code> are
stored to <code>train</code> and <code>valid</code>. All other components are copied
from <code>dataset</code>.
</p>


<h3>Note</h3>

<p>Unsupervised clustering may lead to a poor quality of classification, all
subsequent results should be evaluated critically.
</p>


<h3>Author(s)</h3>

<p>Andreas Borg, Murat Sariyar</p>


<h3>See Also</h3>

<p><code><a href="#topic+splitData">splitData</a></code> for splitting data sets without clustering.</p>

<hr>
<h2 id='getErrorMeasures-methods'>Calculate Error Measures</h2><span id='topic+getErrorMeasures'></span><span id='topic+getErrorMeasures-methods'></span><span id='topic+getErrorMeasures+2CRecLinkResult-method'></span><span id='topic+getErrorMeasures+2CRLResult-method'></span><span id='topic+errorMeasures'></span>

<h3>Description</h3>

<p>Computes various error measures for the classification of a data set.
</p>


<h3>Details</h3>

<p>Let <code class="reqn">\mathit{TP}</code> be the number of correctly classified matches 
(true positives), <code class="reqn">\mathit{TN}</code> the number of correctly classified 
non-matches (true negatives), <code class="reqn">\mathit{FP}</code> and <code class="reqn">\mathit{FN}</code> 
the number of misclassified non-matches and matches
(false positives and false negatives). The calculated error measures are:
</p>

<dl>
<dt>alpha error</dt><dd><p><code class="reqn">\frac{\mathit{FN}}{\mathit{TP}+\mathit{FN}}</code></p>
</dd>
<dt>beta error</dt><dd><p><code class="reqn">\frac{\mathit{FP}}{\mathit{TN}+\mathit{FP}}</code></p>
</dd>
<dt>accuracy</dt><dd><p><code class="reqn">\frac{\mathit{TP}+\mathit{TN}}{\mathit{TP}+\mathit{TN}+\mathit{FP}+\mathit{FN}}</code></p>
</dd>
<dt>precision</dt><dd><p><code class="reqn">\frac{\mathit{TP}}{\mathit{TP}+\mathit{FP}}</code></p>
</dd>
<dt>sensitivity</dt><dd><p><code class="reqn">\frac{\mathit{TP}}{\mathit{TP}+\mathit{FN}}</code></p>
</dd>
<dt>specificity</dt><dd><p><code class="reqn">\frac{\mathit{TN}}{\mathit{TN}+\mathit{FP}}</code></p>
</dd>
<dt>ppv</dt><dd><p>Positive predictive value:<code class="reqn">\frac{\mathit{TP}}{\mathit{TP}+\mathit{FP}}</code></p>
</dd>
<dt>npv</dt><dd><p>Negative predictive value:<code class="reqn">\frac{\mathit{TN}}{\mathit{TN}+\mathit{FN}}</code></p>
</dd>
</dl>



<h3>Value</h3>

<p>A list with components <code>alpha</code>, <code>beta</code>, <code>accuracy</code>, 
<code>precision</code>, <code>sensitivity</code>, <code>specificity</code>, <code>ppv</code> and
<code>npv</code>, each a number in the range <code class="reqn">[0,1]</code>.
</p>


<h3>Methods</h3>


<dl>
<dt><code>signature(object = "RecLinkResult")</code></dt><dd>
<p>Method for S3 result objects of class <code>"RecLinkResult"</code> </p>
</dd>
<dt><code>signature(object = "RLResult")</code></dt><dd>
<p>Method for S4 objects of class <code><a href="#topic+RecLinkResult-class">&quot;RLResult&quot;</a></code>, 
from classification of big data objects (see <code>"<a href="#topic+RLBigData-class">RLBigData</a>"</code>,
<code>"<a href="#topic+RLBigDataDedup-class">RLBigDataDedup</a>"</code>, <code>"<a href="#topic+RLBigDataLinkage-class">RLBigDataLinkage</a>"</code>)
</p>
</dd>
</dl>

<p>A wrapper function <code>errorMeasures(result)</code> exists for compatibility with package version
0.2.
</p>


<h3>Note</h3>

<p>Record pairs with unknown true matching status (e.g. due to missing
values in the argument <code>identity</code> to <code><a href="#topic+RLBigDataDedup">RLBigDataDedup</a></code>)
and possible links are not counted, which can distort the values returned
by this function.
</p>


<h3>Author(s)</h3>

<p>Murat Sariyar, Andreas Borg
</p>

<hr>
<h2 id='getExpectedSize'>
Estimate number of record pairs.
</h2><span id='topic+getExpectedSize'></span><span id='topic+getExpectedSize-methods'></span><span id='topic+getExpectedSize+2CRLBigDataDedup-method'></span><span id='topic+getExpectedSize+2CRLBigDataLinkage-method'></span><span id='topic+getExpectedSize+2Cdata.frame-method'></span>

<h3>Description</h3>

<p>Estimates the total number of record pairs generated by a dataset and
specified blocking conditions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  getExpectedSize(object, ...)

  ## S4 method for signature 'RLBigDataDedup'
getExpectedSize(object)

  ## S4 method for signature 'RLBigDataLinkage'
getExpectedSize(object)

  ## S4 method for signature 'data.frame'
getExpectedSize(object, blockfld = list())
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="getExpectedSize_+3A_object">object</code></td>
<td>

<p>Either a record linkage object or a dataset.
</p>
</td></tr>
<tr><td><code id="getExpectedSize_+3A_blockfld">blockfld</code></td>
<td>
<p>A blocking definition, such as in <code><a href="#topic+compare.dedup">compare.dedup</a></code></p>
</td></tr>
<tr><td><code id="getExpectedSize_+3A_...">...</code></td>
<td>

<p>Placeholder for additional arguments.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>"RLBigData*"</code> methods are only left for backward compatibility.
Since version 0.4, all record pairs for such objects are generated and stored
in a disk file. The methods return the true number of record pairs.
</p>
<p>For the <code>"data.frame"</code> method, estimation is based on the assumption
that agreement or disagreement of one attribute is independent of the other attributes.
</p>
<p><code>blockfld</code> is a blocking definition such as for
<code><a href="#topic+RLBigDataDedup">RLBigDataDedup</a></code>.
</p>


<h3>Value</h3>

<p>The expected number of record pairs.
</p>


<h3>Author(s)</h3>

<p>Andreas Borg, Murat Sariyar
</p>

<hr>
<h2 id='getFrequencies-methods'>Get attribute frequencies</h2><span id='topic+getFrequencies'></span><span id='topic+getFrequencies-methods'></span><span id='topic+getFrequencies+2CRLBigData-method'></span>

<h3>Description</h3>

<p>Returns the average frequencies of attribute values for a Record Linkage
object, which is <code>1 / unique(c)</code>, for every data column <code>c</code>.
</p>


<h3>Methods</h3>


<dl>
<dt><code>signature(x = "RLBigData")</code></dt><dd></dd>
</dl>

<hr>
<h2 id='getMinimalTrain'>
Create a minimal training set
</h2><span id='topic+getMinimalTrain'></span><span id='topic+getMinimalTrain-methods'></span><span id='topic+getMinimalTrain+2CRecLinkData-method'></span><span id='topic+getMinimalTrain+2CRLBigData-method'></span>

<h3>Description</h3>

<p>Samples a subset of the provided data (comparison patterns) so that every
comparison pattern in <code>rpairs</code> is represented in the subset
at least once.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getMinimalTrain(rpairs, nEx = 1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="getMinimalTrain_+3A_rpairs">rpairs</code></td>
<td>

<p>A <code>"RecLinkData"</code> or <code>"RLBigData"</code> object. The data set
from which to create a minimal training set.
</p>
</td></tr>
<tr><td><code id="getMinimalTrain_+3A_nex">nEx</code></td>
<td>

<p>The desired number of examples per comparison pattern.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Our internal research has given indication that in the context of Record Linkage 
with supervised classification procedures small training sets are often 
sufficient, provided they cover the whole range of present comparison patterns.
</p>
<p>By default, this function creates a minimal training set that is
a subset of the record pairs to be classified in which every present 
comparison pattern is represented by exactly one training example.
By this approach, the work to classify a training set by
clerical review can be minimized while keeping a good classification 
performance.
</p>
<p>Larger training sets can be obtained by setting <code>nEx</code> to a 
higher number. Up to <code>nEx</code> examples for every comparison pattern
are randomly selected, limited by the total number of record pairs with
that pattern.
</p>


<h3>Value</h3>

<p>An object of the same class as <code>rpairs</code>, representing a minimal
comprehensive training set. The appropriate subset of comparison patterns
(and weights, if present) is taken, all other components are copied.
</p>


<h3>Note</h3>

<p>Application is only advisable for binary comparison patterns (i.e. only 0
and 1 appear as agreement values). For patterns with string comparison
values, the size of the returned set can be too large for a manual review.
A warning is issued if fuzzy agreement values (<code class="reqn">&gt;0</code> and <code class="reqn">&lt;1</code>) are
present in the data.
</p>


<h3>Note</h3>

<p>Due to the small size of the resulting training set, outliers can have a
relatively high impact on further classification results. Stable methods
such as Bagging or Support-Vector-Machines should be used in conjunction
with minimal training sets to minimize this risk.
</p>


<h3>Author(s)</h3>

<p>Andreas Borg, Murat Sariyar
</p>


<h3>See Also</h3>

<p><code><a href="#topic+editMatch">editMatch</a></code> for manually setting the matching status of the
training pairs.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(RLdata500)
p &lt;- compare.dedup(RLdata500,blockfld=list(1,3),identity=identity.RLdata500)
train &lt;- getMinimalTrain(p)
classif &lt;- trainSupv(train,method="bagging")
summary(classifySupv(classif,newdata=p))
</code></pre>

<hr>
<h2 id='getPairs'>Extract Record Pairs</h2><span id='topic+getPairs'></span><span id='topic+getPairs+2CRecLinkData-method'></span><span id='topic+getPairs+2CRecLinkResult-method'></span><span id='topic+getPairs-methods'></span><span id='topic+getPairs+2CRLResult-method'></span><span id='topic+getPairs+2CRLBigData-method'></span><span id='topic+getFalsePos'></span><span id='topic+getFalseNeg'></span><span id='topic+getFalse'></span>

<h3>Description</h3>

<p>Extracts record pairs from data and result objects.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'RecLinkData'
getPairs(object, max.weight = Inf, min.weight = -Inf,
         single.rows = FALSE, show = "all", sort = !is.null(object$Wdata))

## S4 method for signature 'RLBigData'
getPairs(object, max.weight = Inf, min.weight = -Inf,
    filter.match = c("match", "unknown", "nonmatch"),
    withWeight = hasWeights(object), withMatch = TRUE, single.rows = FALSE,
    sort = withWeight)

## S4 method for signature 'RLResult'
getPairs(object, filter.match = c("match", "unknown", "nonmatch"),
    filter.link = c("nonlink", "possible", "link"), max.weight = Inf, 
    min.weight = -Inf, withMatch = TRUE, withClass = TRUE, 
    withWeight = hasWeights(object@data), single.rows = FALSE, sort = withWeight)

getFalsePos(object, single.rows = FALSE)
getFalseNeg(object, single.rows = FALSE)
getFalse(object, single.rows = FALSE)

</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="getPairs_+3A_object">object</code></td>
<td>
<p>The data or result object from which to extract record pairs.</p>
</td></tr>
<tr><td><code id="getPairs_+3A_max.weight">max.weight</code>, <code id="getPairs_+3A_min.weight">min.weight</code></td>
<td>
<p>Real numbers. Upper and lower weight threshold.</p>
</td></tr>
<tr><td><code id="getPairs_+3A_filter.match">filter.match</code></td>
<td>
<p>Character vector, a nonempty subset of <code>c("match", "nonmatch", "unkown")</code>
denoting which pairs to allow in the output.</p>
</td></tr>
<tr><td><code id="getPairs_+3A_filter.link">filter.link</code></td>
<td>
<p>Character vector, a nonempty subset of <code>c("link", "nonlink", "unkown")</code>
denoting which pairs to allow in the output.</p>
</td></tr>
<tr><td><code id="getPairs_+3A_withweight">withWeight</code></td>
<td>
<p>Logical. Whether to include linkage weights in the output.</p>
</td></tr>
<tr><td><code id="getPairs_+3A_withmatch">withMatch</code></td>
<td>
<p>Logical. Whether to include matching status in the output.</p>
</td></tr>
<tr><td><code id="getPairs_+3A_withclass">withClass</code></td>
<td>
<p>Logical. Whether to include classification result in the output.</p>
</td></tr>
<tr><td><code id="getPairs_+3A_single.rows">single.rows</code></td>
<td>
<p>Logical. Whether to print record pairs in one row instead
of two consecutive rows.</p>
</td></tr>
<tr><td><code id="getPairs_+3A_show">show</code></td>
<td>
<p>Character. Selects which records to show, one of <code>"links"</code>,
<code>"nonlinks"</code>, <code>"possible"</code>, <code>"all"</code>.</p>
</td></tr>
<tr><td><code id="getPairs_+3A_sort">sort</code></td>
<td>
<p>Logical. Whether to sort descending by weight.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>These methods extract record pairs from <code>"<a href="#topic+RecLinkData">RecLinkData</a>"</code>,
or <code>"<a href="#topic+RecLinkResult">RecLinkResult</a>"</code>, <code>"<a href="#topic+RLBigData-class">RLBigData</a>"</code> and
<code>"<a href="#topic+RLResult-class">RLResult</a>"</code> objects. Possible applications are retrieving
a linkage result for further processing, conducting a manual review in order
to determine classification thresholds or inspecting misclassified pairs.
</p>
<p>The various arguments can be grouped by the following purposes:
</p>

<ol>
<li><p>Controlling which record pairs are included in the output:
<code>min.weight</code> and <code>max.weight</code>, <code>filter.match</code>,
<code>filter.link</code>, <code>show</code>.
</p>
</li>
<li><p>Controlling which information is shown: <code>withWeight</code>, <code>withMatch</code>,
<code>withClass</code>
</p>
</li>
<li><p>Controlling the overall structure of the result: <code>sort</code>,
<code>single.rows</code>.
</p>
</li></ol>

<p>The weight limits are inclusive, i.e. a record pair with weight <code>w</code>
is included only if <br /> <code>w &gt;= min.weight &amp;&amp; w &lt;= max.weight</code>.
</p>
<p>If <code>single.rows</code> is not <code>TRUE</code>, pairs are output on two consecutive
lines in a more readable format. All data are converted to character, which
can lead to a loss of precision for numeric values.
Therefore, this format should be used  for printing only.
</p>
<p><code>getFalsePos</code>, <code>getFalseNeg</code> and <code>getFalse</code> are shortcuts
(currently for objects of class <code>"<a href="#topic+RLResult-class">RLResult</a>"</code> only)
to retrieve false positives (links that are non-matches in fact),
false negatives (non-links that are matches in fact) or all falsely classified
pairs, respectively.
</p>


<h3>Value</h3>

<p>A data frame. If <code>single.rows</code> is <code>TRUE</code>, each row holds (in this
order) id and data fields of the
first record, id and data fields of the second record and possibly matching
status, classification result and/or weight.
</p>
<p>If <code>single.rows</code> is not <code>TRUE</code>, the result holds for each resulting
record pair consecutive rows of the following format:
</p>

<ol>
<li><p>ID and data fields of the first record followed by as many empty
fields to match the length of the following line.
</p>
</li>
<li><p>ID and data fields of the second record, possibly followed by
matching status, classification result and/or weight.
</p>
</li>
<li><p>A blank line to separate record pairs.
</p>
</li></ol>



<h3>Note</h3>

<p>When non-matches are included in the output and blocking is permissive,
the result object can be very large, possibly leading to memory problems.
</p>


<h3>Author(s)</h3>

<p>Andreas Borg, Murat Sariyar</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(RLdata500)

# create record pairs and calculate epilink weights
rpairs &lt;- RLBigDataDedup(RLdata500, identity = identity.RLdata500,
  blockfld=list(1,3,5,6,7))
rpairs &lt;- epiWeights(rpairs)

# show all record pairs with weights between 0.5 and 0.6
getPairs(rpairs, min.weight=0.5, max.weight=0.6)

# show only matches with weight &lt;= 0.5
getPairs(rpairs, max.weight=0.5, filter.match="match")

# classify with one threshold
result &lt;- epiClassify(rpairs, 0.5)

# show all links, do not show classification in the output
getPairs(result, filter.link="link", withClass = FALSE)

# see wrongly classified pairs
getFalsePos(result)
getFalseNeg(result)
</code></pre>

<hr>
<h2 id='getPairsBackend'>
Backend function for getPairs
</h2><span id='topic+getPairsBackend'></span>

<h3>Description</h3>

<p>Backend function for <code><a href="#topic+getPairs">getPairs</a></code> methods. Not to be called directly.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getPairsBackend(object, filter.match, filter.link = c("nonlink", "possible", "link"), 
  max.weight = Inf, min.weight = -Inf, withMatch = TRUE, withClass = FALSE, 
  withWeight = FALSE, sort = FALSE, single.rows = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="getPairsBackend_+3A_object">object</code></td>
<td>
<p>The object from which to extract pairs.</p>
</td></tr>
<tr><td><code id="getPairsBackend_+3A_filter.match">filter.match</code></td>
<td>
<p>Character vector, specifies matching status for pairs to appear in the output.</p>
</td></tr>
<tr><td><code id="getPairsBackend_+3A_filter.link">filter.link</code></td>
<td>
<p>Character vector, specifies linkage result for pairs to appear in the output.</p>
</td></tr>
<tr><td><code id="getPairsBackend_+3A_max.weight">max.weight</code></td>
<td>
<p>Maximum weight of pairs to include in the output.</p>
</td></tr>
<tr><td><code id="getPairsBackend_+3A_min.weight">min.weight</code></td>
<td>
<p>Minimum weight of pairs to include in the output.</p>
</td></tr>
<tr><td><code id="getPairsBackend_+3A_withmatch">withMatch</code></td>
<td>
<p>Logical. Whether to include matching status in the output.</p>
</td></tr>
<tr><td><code id="getPairsBackend_+3A_withclass">withClass</code></td>
<td>
<p>Logical. Whether to include linkage result in the output.</p>
</td></tr>
<tr><td><code id="getPairsBackend_+3A_withweight">withWeight</code></td>
<td>
<p>Logical. Whether to include weights in the output.</p>
</td></tr>
<tr><td><code id="getPairsBackend_+3A_sort">sort</code></td>
<td>
<p>Logical. Whether to sort descending by weights.</p>
</td></tr>
<tr><td><code id="getPairsBackend_+3A_single.rows">single.rows</code></td>
<td>
<p>Logical. Whether to print record pairs in one row instead
of two consecutive rows.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See <code><a href="#topic+getPairs">getPairs</a></code>
</p>


<h3>Value</h3>

<p>See <code><a href="#topic+getPairs">getPairs</a></code>
</p>


<h3>Author(s)</h3>

<p>Andreas Borg, Murat Sariyar
</p>

<hr>
<h2 id='getParetoThreshold'>
Estimate Threshold from Pareto Distribution
</h2><span id='topic+getParetoThreshold'></span><span id='topic+getParetoThreshold-methods'></span><span id='topic+getParetoThreshold+2CRecLinkData-method'></span><span id='topic+getParetoThreshold+2CRLBigData-method'></span>

<h3>Description</h3>

<p>Calculates a classification threshold based on a generalized Pareto distribution (GPD) fitted to the weights distribution of the given data pairs.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getParetoThreshold(rpairs, quantil = 0.95, interval = NA)
## S4 method for signature 'RecLinkData'
getParetoThreshold(rpairs, quantil = 0.95, interval = NA)
## S4 method for signature 'RLBigData'
getParetoThreshold(rpairs, quantil = 0.95, interval = NA)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="getParetoThreshold_+3A_rpairs">rpairs</code></td>
<td>

<p>A <code>"<a href="#topic+RecLinkData">RecLinkData</a>"</code> or <code>"<a href="#topic+RLBigData-class">RLBigData</a>"</code> object with weights.The data for which to compute a threshold.
</p>
</td></tr>
<tr><td><code id="getParetoThreshold_+3A_quantil">quantil</code></td>
<td>

<p>A real number between 0 and 1. The quantile which to compute.
</p>
</td></tr>
<tr><td><code id="getParetoThreshold_+3A_interval">interval</code></td>
<td>

<p>A numeric vector denoting the interval on which to fit
a GPD.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This threshold calculation is based on the assumption that the distribution   of weights exhibit a &lsquo;fat tail&rsquo; which can be fitted by a generalized Pareto distribution (GPD). The limits of the interval which is subject to the fitting are usually determined by reviewing a mean residual life plot of the data. If the limits are not externally supplied, a MRL plot is displayed  from which the endpoints can be selected by mouse input. If only one endpoint is selected or supplied, the greater endpoint is set to the maximum weight. A suitable interval is characterized by a relatively long, approximately linear segment of the plot. 
</p>


<h3>Value</h3>

<p>A classification threshold.
</p>


<h3>Note</h3>

<p>The quality of matching varies, poor results can occur in some cases. Evaluate carefully before applying to a real case.
</p>


<h3>Author(s)</h3>

<p>Andreas Borg, Murat Sariyar
</p>


<h3>References</h3>

<p>Sariyar M., Borg A. and Pommerening M.: Controlling false match rates in record linkage using extreme value theory. Journal of Biomedical Informatics, <a href="https://doi.org/10.1016/j.jbi.2011.02.008">doi:10.1016/j.jbi.2011.02.008</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+emWeights">emWeights</a></code> and <code><a href="#topic+epiWeights">epiWeights</a></code> for calculating weights,
<code><a href="#topic+emClassify">emClassify</a></code> and <code><a href="#topic+epiClassify">epiClassify</a></code> for classifying with
the returned threshold.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  data(RLdata500)
  rpairs=compare.dedup(RLdata500, identity=identity.RLdata500, strcmp=TRUE,
    blockfld=list(1,3,5:7))
  rpairs=epiWeights(rpairs)
  # leave out argument interval to choose from plot
  ## Not run: threshold=getParetoThreshold(rpairs,interval=c(0.68, 0.79))
  ## Not run: summary(epiClassify(rpairs,threshold))
</code></pre>

<hr>
<h2 id='getTable-methods'>Build contingency table</h2><span id='topic+getTable'></span><span id='topic+getTable-methods'></span><span id='topic+getTable+2CRecLinkResult-method'></span><span id='topic+getTable+2CRLResult-method'></span>

<h3>Description</h3>

<p>Builds a contingency table for a linkage result with counts for
each combination of real matching status and predicted result.
</p>


<h3>Methods</h3>


<dl>
<dt><code>signature(object = "RecLinkResult")</code></dt><dd>
<p>Method for S3 result sets.
</p>
</dd>
<dt><code>signature(object = "RLResult")</code></dt><dd>
<p>Method for S4 result sets (big data sets).
</p>
</dd>
</dl>

<hr>
<h2 id='gpdEst'>
Estimate Threshold from Pareto Distribution
</h2><span id='topic+gpdEst'></span>

<h3>Description</h3>

<p>Fits a Pareto distribution to the distribution of weights
and calculates a quantile on the fitted model as classification threshold.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gpdEst(Wdata, thresh = -Inf, quantil = 0.95)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gpdEst_+3A_wdata">Wdata</code></td>
<td>

<p>A numeric vector representing weights of record pairs.
</p>
</td></tr>
<tr><td><code id="gpdEst_+3A_thresh">thresh</code></td>
<td>

<p>Threshold for exceedances.
</p>
</td></tr>
<tr><td><code id="gpdEst_+3A_quantil">quantil</code></td>
<td>

<p>A real number between 0 and 1. The desired quantile.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The weights that exceed <code>thresh</code> are fitted to a 
generalized Pareto distribution (GPD). The estimated parameters <code>shape</code>
and <code>scale</code> are used to calculate a classification threshold by the
formula
</p>
<p style="text-align: center;"><code class="reqn">\mathit{thresh}+\frac{\mathit{scale}}{\mathit{shape}}
    ((\frac{n}{k}(1-\mathit{quantil}))^{-\mathit{shape}} -1)</code>
</p>
  
<p>where <code class="reqn">n</code> is the total number of weights and <code class="reqn">k</code> the number of
exceedances.
</p>


<h3>Value</h3>

<p>A real number representing the resulting classification threshold. It is
assured that the threshold lies in a reasonable range.
</p>


<h3>Author(s)</h3>

<p>Murat Sariyar
</p>


<h3>See Also</h3>

<p><code><a href="#topic+getParetoThreshold">getParetoThreshold</a></code> for user-level function
</p>

<hr>
<h2 id='internals'>
Internal functions and methods
</h2><span id='topic+begin'></span><span id='topic+begin-methods'></span><span id='topic+begin+2CRLBigData-method'></span><span id='topic+nextPairs'></span><span id='topic+nextPairs-methods'></span><span id='topic+nextPairs+2CRLBigData-method'></span><span id='topic+clear'></span><span id='topic+clear-methods'></span><span id='topic+clear+2CRLBigData-method'></span><span id='topic+blockfldfun'></span><span id='topic+getSQLStatement'></span><span id='topic+getSQLStatement-methods'></span><span id='topic+getSQLStatement+2CRLBigData-method'></span><span id='topic+init_sqlite_extensions'></span><span id='topic+.allows_extensions'></span><span id='topic+.lib_path'></span><span id='topic+getPatternCounts'></span><span id='topic+getPatternCounts-methods'></span><span id='topic+getPatternCounts+2CRLBigData-method'></span><span id='topic+getMatchCount'></span><span id='topic+getMatchCount-methods'></span><span id='topic+getMatchCount+2CRLBigData-method'></span><span id='topic+getNonMatchCount'></span><span id='topic+getNonMatchCount-methods'></span><span id='topic+getNonMatchCount+2CRLBigData-method'></span><span id='topic+getNACount'></span><span id='topic+getNACount-methods'></span><span id='topic+getNACount+2CRLBigData-method'></span><span id='topic+getColumnNames'></span><span id='topic+getColumnNames-methods'></span><span id='topic+getColumnNames+2CRLBigDataDedup-method'></span><span id='topic+getColumnNames+2CRLBigDataLinkage-method'></span><span id='topic+getThresholds'></span><span id='topic+countpattern'></span><span id='topic+hasWeights'></span><span id='topic+hasWeights-methods'></span><span id='topic+hasWeights+2CRecLinkData-method'></span><span id='topic+hasWeights+2CRLBigData-method'></span>

<h3>Description</h3>

<p>These functions and methods are used internally and should usually not
be called from outside the package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  begin(x, ...)
  nextPairs(x, n = 10000, ...)
  clear(x, ...)
  blockfldfun(blockfld, phoneticFld, phoneticFun, coln)
  getSQLStatement(data1, data2 = data1, con, type, blockFld, excludeFld,
    strcmpFld, strcmpFun, phoneticFld, phoneticFun)
  init_sqlite_extensions(db)
  .allows_extensions(db)
  .lib_path()
  getPatternCounts(x, n=10000, cutoff=1, withProgressBar = (sink.number()==0))
  getMatchCount(object)
  getNonMatchCount(object)
  getNACount(object)
  getColumnNames(object, withExcluded = FALSE)
  getThresholds(W, M, U, my, ny)
  countpattern(x, matching = FALSE)
  hasWeights(object)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="internals_+3A_x">x</code>, <code id="internals_+3A_object">object</code></td>
<td>
<p>Depends on the function, usually a <code>"<a href="#topic+RecLinkData-class">RecLinkData</a>"</code>,
<code>"<a href="#topic+RLBigData-class">RLBigData</a>"</code> or <code>"<a href="#topic+RLResult-class">RLResult</a>"</code>.
A matrix of binary observations for <code>countpattern</code>.</p>
</td></tr>
<tr><td><code id="internals_+3A_n">n</code></td>
<td>
<p>Maximum number of comparison patterns to fetch.</p>
</td></tr>
<tr><td><code id="internals_+3A_blockfld">blockfld</code></td>
<td>
<p>Blocking definition as in
<code><a href="#topic+RLBigDataDedup">RLBigData*</a></code>.</p>
</td></tr>
<tr><td><code id="internals_+3A_phoneticfld">phoneticFld</code></td>
<td>
<p>Indices of attributes for which phonetic code should be used.</p>
</td></tr>
<tr><td><code id="internals_+3A_phoneticfun">phoneticFun</code></td>
<td>
<p>Name of phonetic function as in
<code><a href="#topic+RLBigDataDedup">RLBigData*</a></code>.</p>
</td></tr>
<tr><td><code id="internals_+3A_data1">data1</code>, <code id="internals_+3A_data2">data2</code></td>
<td>
<p>Data frame with records.</p>
</td></tr>
<tr><td><code id="internals_+3A_type">type</code></td>
<td>
<p>&quot;linkage&quot; or &quot;deduplication&quot;, the type of linkage.</p>
</td></tr>
<tr><td><code id="internals_+3A_excludefld">excludeFld</code></td>
<td>
<p>Indices or names of fields to exclude from comparison.</p>
</td></tr>
<tr><td><code id="internals_+3A_strcmpfld">strcmpFld</code></td>
<td>
<p>Indices of attributes for which string comparison should be used.</p>
</td></tr>
<tr><td><code id="internals_+3A_strcmpfun">strcmpFun</code></td>
<td>
<p>Name of string comparison function as in
<code><a href="#topic+RLBigDataDedup">RLBigData*</a></code>.</p>
</td></tr>
<tr><td><code id="internals_+3A_con">con</code></td>
<td>
<p>A SQLite database connection.</p>
</td></tr>
<tr><td><code id="internals_+3A_coln">coln</code></td>
<td>
<p>Column names of records.</p>
</td></tr>
<tr><td><code id="internals_+3A_db">db</code></td>
<td>
<p>Database connection.</p>
</td></tr>
<tr><td><code id="internals_+3A_cutoff">cutoff</code></td>
<td>
<p>Threshold from which string comparison values are rounded to 1.</p>
</td></tr>
<tr><td><code id="internals_+3A_withprogressbar">withProgressBar</code></td>
<td>
<p>Whether to display a progress bar.</p>
</td></tr>
<tr><td><code id="internals_+3A_withexcluded">withExcluded</code></td>
<td>
<p>Logical. Whether to output names of excluded columns</p>
</td></tr>
<tr><td><code id="internals_+3A_w">W</code>, <code id="internals_+3A_m">M</code>, <code id="internals_+3A_u">U</code></td>
<td>
<p>Linkage weights, m- and u-probabilities. See <code><a href="#topic+emWeights">emWeights</a></code>
for details.</p>
</td></tr>
<tr><td><code id="internals_+3A_my">my</code>, <code id="internals_+3A_ny">ny</code></td>
<td>
<p>Error bounds. See <code><a href="#topic+emClassify">emClassify</a></code> for details.</p>
</td></tr>
<tr><td><code id="internals_+3A_...">...</code></td>
<td>
<p>Optional arguments.</p>
</td></tr>
<tr><td><code id="internals_+3A_matching">matching</code></td>
<td>
<p>If TRUE an additional vector is returned which stores which
row belongs to which pattern.</p>
</td></tr>
</table>


<h3>Details</h3>


<dl>
<dt><code>begin</code></dt><dd><p>Sends a query to the database of an <code>"RLBigData"</code>
object which creates comparison patterns.</p>
</dd>
<dt><code>nextPairs</code></dt><dd><p>Retrieves the next <code>n</code> comparison patterns.</p>
</dd>
<dt><code>clear</code></dt><dd><p>Closes the result set opened by <code>begin</code>.</p>
</dd>
<dt><code>blockfldfun</code></dt><dd><p>Constructs the part of SQL statement which
implements blocking.</p>
</dd>
<dt><code>blockfldfun</code></dt><dd><p>Constructs the part of SQL statement which
implements blocking.</p>
</dd>
<dt><code>getSQLStatement</code></dt><dd><p>Constructs SQL statement for retrieving
comparison patterns.</p>
</dd>
<dt><code>init_sqlite_extensions</code></dt><dd><p>Load string comparison and phonetic
functions into database.</p>
</dd>
<dt><code>.allows_extensions</code></dt><dd><p>Tests whether SQLite engine supports
extension functions.</p>
</dd>
<dt><code>.lib_path</code></dt><dd><p>Gets path of shared library of package.</p>
</dd>
<dt><code>getPatternCounts</code></dt><dd><p>Counts binary patterns, implemented through
<code><a href="#topic+countpattern">countpattern</a></code>.</p>
</dd>
<dt><code>getMatchCount</code></dt><dd><p>Gets number of matches from a
<code>"<a href="#topic+RLBigData-class">RLBigData</a>"</code> object.</p>
</dd>
<dt><code>getNACount</code></dt><dd><p>Gets number of pairs with unknown matching status
from a <code>"<a href="#topic+RLBigData-class">RLBigData</a>"</code> object.</p>
</dd>
<dt><code>getDbFile</code></dt><dd><p>Returns path of database file for a data or result
object.</p>
</dd>
<dt><code>getColumnNames</code></dt><dd><p>Returns column names of a
<code>"<a href="#topic+RLBigData-class">RLBigData</a>"</code> object as a character vector.</p>
</dd>
<dt><code>getThresholds</code></dt><dd><p>Calculates upper and lower classification
based on error bounds.</p>
</dd>
<dt><code>countpattern</code></dt><dd><p>Modified version of <code><a href="e1071.html#topic+countpattern">countpattern</a></code>
in package e1071.</p>
</dd>
<dt><code>hasWeights</code></dt><dd><p>Determines whether a data object has weights.</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Andreas Borg, Murat Sariyar
</p>

<hr>
<h2 id='isFALSE'>Check for FALSE</h2><span id='topic+isFALSE'></span>

<h3>Description</h3>

<p>Shortcut for <code>identical(x,FALSE)</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>isFALSE(x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="isFALSE_+3A_x">x</code></td>
<td>
<p>Any object</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns <code>TRUE</code> if <code>x</code> is identical to <code>FALSE</code>, <code>FALSE</code>
otherwise.
</p>


<h3>Author(s)</h3>

<p>Andreas Borg</p>

<hr>
<h2 id='makeBlockingPairs'>
Create record pairs from blocks of ids.
</h2><span id='topic+makeBlockingPairs'></span>

<h3>Description</h3>

<p>Create record pairs from blocks of ids. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>makeBlockingPairs(id_vec)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="makeBlockingPairs_+3A_id_vec">id_vec</code></td>
<td>

<p>A list of integer vectors.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Each element in <code>id_vec</code> holds the ids of a set of records which agree
for a particular blocking variable (see <code><a href="#topic+compare.dedup">compare.dedup</a></code> for the
blocking mechanism). For each block, all unordered pairs of the ids are 
created and concatenated in the output.
</p>


<h3>Value</h3>

<p>A matrix with two columns, each row holding the ids of one record pair.
</p>


<h3>Note</h3>

<p>Internal function used by <code><a href="#topic+compare.dedup">compare.dedup</a></code>.
</p>


<h3>Author(s)</h3>

<p>Andreas Borg
</p>

<hr>
<h2 id='mrl'>
Mean Residual Life Plot
</h2><span id='topic+mrl'></span><span id='topic+plotMRL'></span>

<h3>Description</h3>

<p>Create mean residual life statistics for classification based on extreme
value theory.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mrl(data, umin = min(data), umax = max(data) - 0.1, 
  nint = round(max(data) - min(data)) * 20)

plotMRL(rpairs, l = .computeMRL(sort(as.ram((rpairs$Wdata)))))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mrl_+3A_data">data</code></td>
<td>

<p>A numerical vector, representing weights in the context of Record Linkage.
</p>
</td></tr>
<tr><td><code id="mrl_+3A_umin">umin</code>, <code id="mrl_+3A_umax">umax</code></td>
<td>

<p>The minimum and maximum thresholds at which the mean residual life function is calculated.
</p>
</td></tr>
<tr><td><code id="mrl_+3A_nint">nint</code></td>
<td>

<p>The number of points at which the mean residual life function is calculated.
</p>
</td></tr>
<tr><td><code id="mrl_+3A_rpairs">rpairs</code></td>
<td>

<p>A <code><a href="#topic+RecLinkData">RecLinkData</a></code> object with assigned weights.
</p>
</td></tr>
<tr><td><code id="mrl_+3A_l">l</code></td>
<td>

<p>A list with components <code>x</code> and <code>y</code> representing MRL statistics
as returned by <code>mrl</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>While <code>mrl</code> only returns MRL statistics as a list, <code>plotMRL</code>
produces a plot thereof. These functions are used internally for threshold
estimation based on Extreme Value Theory, see 
<code><a href="#topic+getParetoThreshold">getParetoThreshold</a></code>.
</p>
<p><code>mrl</code> is a simplified version of <code>mrl.plot</code> in package <code>ismev</code>.
</p>


<h3>Value</h3>

<p><code>mrl</code> returns a list with 
</p>
<table role = "presentation">
<tr><td><code>x</code></td>
<td>
<p>x-coordinates of MRL statistics</p>
</td></tr>
<tr><td><code>y</code></td>
<td>
<p>y-coordinates of MRL statistics</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+getParetoThreshold">getParetoThreshold</a></code>
</p>

<hr>
<h2 id='mygllm'>Generalized Log-Linear Fitting</h2><span id='topic+mygllm'></span>

<h3>Description</h3>

<p>Fits a log-linear model for collapsed contingency tables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mygllm(y, s, X, maxit = 1000, tol = 1e-05, E = rep(1, length(s)))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mygllm_+3A_y">y</code></td>
<td>
<p>Vector of observed cell frequencies.</p>
</td></tr>
<tr><td><code id="mygllm_+3A_s">s</code></td>
<td>
<p>Scatter matrix. s[i] is the cell in the observed array that
corresponds to cell i in the full array.</p>
</td></tr>
<tr><td><code id="mygllm_+3A_x">X</code></td>
<td>
<p>Design matrix.</p>
</td></tr>
<tr><td><code id="mygllm_+3A_maxit">maxit</code></td>
<td>
<p>Maximum number of iterations.</p>
</td></tr>
<tr><td><code id="mygllm_+3A_tol">tol</code></td>
<td>
<p>Convergence parameter.</p>
</td></tr>
<tr><td><code id="mygllm_+3A_e">E</code></td>
<td>
<p>Full contingency table. Should be initialized with either ones or
a priori estimates.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is an implementation and extension of the algorithm published by
Haber (1984). It also incorporates ideas of David Duffy (see references).
</p>
<p>A priori estimates of the full contingency table can be given as
start values by argument <code>E</code>. This can reduce
execution time significantly.        
</p>


<h3>Value</h3>

<p>Estimated full contingency table.</p>


<h3>Author(s)</h3>

<p>Andreas Borg, Murat Sariyar</p>


<h3>References</h3>

<p>Michael Haber, Algorithm AS 207: Fitting a General Log-Linear
Model, in: Applied Statistics 33 (1984) No. 3, 358&ndash;362.
</p>
<p>David Duffy: gllm: Generalised log-linear model. R package
version 0.31. <a href="https://cran.r-project.org/package=gllm">https://cran.r-project.org/package=gllm</a></p>


<h3>See Also</h3>

<p><code><a href="#topic+emWeights">emWeights</a></code>, which makes use of log-linear fitting for
weight calculation.</p>

<hr>
<h2 id='optimalThreshold'>
Optimal Threshold for Record Linkage
</h2><span id='topic+optimalThreshold'></span><span id='topic+optimalThreshold-methods'></span><span id='topic+optimalThreshold+2CRecLinkData-method'></span><span id='topic+optimalThreshold+2CRLBigData-method'></span>

<h3>Description</h3>

<p>Calculates the optimal threshold for weight-based Record Linkage.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>optimalThreshold(rpairs, my = NaN, ny = NaN)
## S4 method for signature 'RecLinkData'
optimalThreshold(rpairs, my = NaN, ny = NaN)
## S4 method for signature 'RLBigData'
optimalThreshold(rpairs, my = NaN, ny = NaN)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="optimalThreshold_+3A_rpairs">rpairs</code></td>
<td>

<p>Record pairs for which to calculate a threshold.
</p>
</td></tr>
<tr><td><code id="optimalThreshold_+3A_my">my</code></td>
<td>

<p>A real value in the range [0,1]. Error bound for false positives.
</p>
</td></tr>
<tr><td><code id="optimalThreshold_+3A_ny">ny</code></td>
<td>

<p>A real value in the range [0,1]. Error bound for false negatives.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Weights must have been calculated for <code>rpairs</code>, for example by
<code><a href="#topic+emWeights">emWeights</a></code> or <code><a href="#topic+epiWeights">epiWeights</a></code>.
The true match result must be known for <code>rpairs</code>, mostly this is provided
through the <code>identity</code> argument of <code><a href="#topic+compare.dedup">compare.*</a></code>
</p>
<p>For the following, it is assumed that all records with weights greater than or
equal to the threshold are classified as links, the remaining as non-links.
If no further arguments are given, a threshold which minimizes the
absolute number of misclassified record pairs is returned. If <code>my</code> is 
supplied (<code>ny</code> is ignored in this case), a threshold is picked which
maximizes the number of correctly classified links while keeping the ratio 
of false links to the total number of links below or equal <code>my</code>.
If <code>ny</code> is supplied, the number of correct non-links is maximized under the
condition that the ratio of falsely classified non-links to the total number of
non-links does not exceed <code>ny</code>.
</p>
<p>Two separate runs of <code>optimalThreshold</code> with values for <code>my</code> and
<code>ny</code> respectively allow for obtaining a lower and an upper threshold
for a three-way classification approach (yielding links, non-links and
possible links).
</p>


<h3>Value</h3>

<p>A numeric value, the calculated threshold.
</p>


<h3>Author(s)</h3>

<p>Andreas Borg, Murat Sariyar
</p>


<h3>See Also</h3>

<p><code><a href="#topic+emWeights">emWeights</a></code>
<code><a href="#topic+emClassify">emClassify</a></code>
<code><a href="#topic+epiWeights">epiWeights</a></code>
<code><a href="#topic+epiClassify">epiClassify</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># create record pairs
data(RLdata500)
p=compare.dedup(RLdata500,identity=identity.RLdata500, strcmp=TRUE,
  strcmpfun=levenshteinSim)

# calculate weights
p=epiWeights(p)

# split record pairs in two sets
l=splitData(dataset=p, prop=0.5, keep.mprop=TRUE)

# get threshold from training set
threshold=optimalThreshold(l$train)

# classify remaining data
summary(epiClassify(l$valid,threshold))
</code></pre>

<hr>
<h2 id='phonetics'>Phonetic Code</h2><span id='topic+phonetics'></span><span id='topic+soundex'></span>

<h3>Description</h3>

<p>Interface to phonetic coding functions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>soundex(str)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="phonetics_+3A_str">str</code></td>
<td>
<p>A character vector or matrix.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>soundex</code> is a widespread algorithm for English names. This implementation
can only handle common characters. It strips off non-alphabetical characters.
</p>
<p>The C code for <code>soundex</code> was taken from PostgreSQL 8.3.6.  
</p>


<h3>Value</h3>

<p>A character vector or matrix with the same size and dimensions as <code>str</code>,
containing its phonetic encoding.
</p>


<h3>Author(s)</h3>

<p>Andreas Borg (R interface only)</p>


<h3>References</h3>

<p>see also <a href="https://www.codedrome.com/the-soundex-algorithm-in-c/">https://www.codedrome.com/the-soundex-algorithm-in-c/</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+jarowinkler">jarowinkler</a></code> and <code><a href="#topic+levenshteinSim">levenshteinSim</a></code>
for string comparison.</p>

<hr>
<h2 id='RecLinkClassif-class'>Class &quot;RecLinkClassif&quot;</h2><span id='topic+RecLinkClassif-class'></span><span id='topic+RecLinkClassif'></span>

<h3>Description</h3>

<p>S4 wrapper for S3 class with the same name, which has the same structure
as a <code><a href="#topic+RecLinkData">RecLinkData</a></code> object plus the following components:
</p>

<dl>
<dt><code>prediction</code></dt><dd><p>Linkage result. Coded as a factor with levels
<code>"N"</code> for non-links, <code>"P"</code> for possible links and <code>"L"</code>
for links.</p>
</dd>
<dt><code>attrNames</code></dt><dd><p>Column names of the set of comparison patterns.</p>
</dd>
</dl>



<h3>Objects from the Class</h3>

<p>Objects of the S3 class are created by classification
functions, such as <code><a href="#topic+classifySupv">classifySupv</a></code> or <code><a href="#topic+emClassify">emClassify</a></code></p>


<h3>Slots</h3>


<dl>
<dt><code>.S3Class</code>:</dt><dd><p>Object of class <code>"character"</code>.</p>
</dd>
</dl>



<h3>Extends</h3>

<p>Class <code>"<a href="methods.html#topic+oldClass-class">oldClass</a>"</code>, directly.
</p>


<h3>Methods</h3>


<dl>
<dt>classifySupv</dt><dd><p><code>signature(model = "RecLinkClassif", newdata = "RecLinkData")</code></p>
</dd>
<dt>classifySupv</dt><dd><p><code>signature(model = "RecLinkClassif", newdata = "RLBigData")</code></p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Andreas Borg, Murat Sariyar
</p>


<h3>Examples</h3>

<pre><code class='language-R'>showClass("RecLinkClassif")
</code></pre>

<hr>
<h2 id='RecLinkData-class'>Class &quot;RecLinkData&quot;</h2><span id='topic+RecLinkData-class'></span>

<h3>Description</h3>

<p>S4 wrapper for S3 class <code>"<a href="#topic+RecLinkData">RecLinkData</a>"</code>.
</p>


<h3>Objects from the Class</h3>

<p>Objects of the S3 class are created by
the comparison functions <code><a href="#topic+compare.dedup">compare.*</a></code>.
The S4 class is virtual and exists solely for internal usage in method signatures.
</p>


<h3>Slots</h3>


<dl>
<dt><code>.S3Class</code>:</dt><dd><p>Internal slot.</p>
</dd>
</dl>

<p>See <code>"<a href="#topic+RecLinkData">RecLinkData</a>"</code> for the structure of the S3 class.
</p>


<h3>Extends</h3>

<p>Class <code>"<a href="methods.html#topic+oldClass-class">oldClass</a>"</code>, directly.
</p>


<h3>Methods</h3>

<p>Use <code>getMethods(classes = "RecLinkData")</code> to list the methods defined for
this class.
</p>


<h3>Author(s)</h3>

<p>Andreas Borg, Murat Sariyar
</p>


<h3>See Also</h3>

<p><code>"<a href="#topic+RecLinkData">RecLinkData</a>"</code> for the structure of the S3 class.
<code><a href="#topic+compare.dedup">compare.dedup</a></code>, which creates objects of this class.
<code>"<a href="#topic+RLBigData-class">RLBigData</a>"</code>, an alternative data structure
suitable for big data sets.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>showClass("RecLinkData")
</code></pre>

<hr>
<h2 id='RecLinkData.object'>
Record Linkage Data Object 
</h2><span id='topic+RecLinkData.object'></span><span id='topic+RecLinkData'></span>

<h3>Description</h3>

<p>S3 class representing information about record pairs for Record
Linkage, as returned by functions <code><a href="#topic+compare.dedup">compare.dedup</a></code> and
<code><a href="#topic+compare.linkage">compare.linkage</a></code>.
</p>


<h3>Value</h3>

<p>A list with at least the following elements:
</p>

<dl>
<dt><code>data</code> (for <code>type = "deduplication"</code>):</dt><dd><p>Object of class
<code>"data.frame"</code>. Data frame of original records.</p>
</dd>
<dt><code>data1</code>, <code>data2</code> (for <code>type = "linkage"</code>):</dt><dd><p>Objects of class
<code>"data.frame"</code>. Data frames of original records.</p>
</dd>
<dt><code>pairs</code>:</dt><dd><p>Object of class <code>"data.frame"</code>
Data frame of data pairs. Each row represents the comparison pattern of two records,
identified by columns <code>id1</code> and <code>id2</code>. The other columns contain for each
considered attribute a real number in the range [0..1] representing the degree of
similarity. These columns are named according to the respective columns in
<code>data</code>. The last column contains the matching status of the pair,
coded as 1 for a match or 0 for a non-match.
</p>
</dd>
<dt><code>frequencies</code>:</dt><dd><p>Object of class <code>"numeric"</code>
Numeric vector with average frequency of values for each column
included in <code>pairs</code> (reciprocal of number of distinct values).
</p>
</dd>
<dt><code>type</code>:</dt><dd><p>Object of class <code>"character"</code>
Identifies whether a linkage
(<code>"linkage"</code>) or a deduplication (<code>"deduplication"</code>) project is
represented.</p>
</dd>
<dt><code>.S3class</code>:</dt><dd><p>Internal slot.</p>
</dd>
</dl>

<p>The following elements are optional:
</p>

<dl>
<dt><code>M</code>:</dt><dd><p>Object of class <code>"numeric"</code>
Vector of m-probabilities as calculated by <code><a href="#topic+emWeights">emWeights</a></code>.
</p>
</dd>
<dt><code>U</code>:</dt><dd><p>Object of class <code>"numeric"</code>
Vector of u-probabilities as calculated by <code><a href="#topic+emWeights">emWeights</a></code>.
</p>
</dd>
<dt><code>W</code>:</dt><dd><p>Object of class <code>"numeric"</code>
Vector of log-likelihood weights as calculated by <code><a href="#topic+emWeights">emWeights</a></code>,
corresponding to binary comparison patterns as created by
<code><a href="e1071.html#topic+bincombinations">bincombinations</a></code>.
</p>
</dd>
<dt><code>Wdata</code>:</dt><dd><p>Object of class <code>"numeric"</code>
Vector of log-likelihood weights as calculated by <code><a href="#topic+emWeights">emWeights</a></code>,
corresponding to the rows of <code>pairs</code>.
</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Andreas Borg, Murat Sariyar</p>


<h3>See Also</h3>

<p><code>"<a href="#topic+RecLinkData-class">RecLinkData</a>"</code> for the S4 representation.
<code><a href="#topic+compare.dedup">compare.dedup</a></code>, which creates objects of this class.
<code>"<a href="#topic+RLBigData-class">RLBigData</a>"</code>, an alternative data structure suitable for
big data sets.
</p>

<hr>
<h2 id='RecLinkResult-class'>Class &quot;RecLinkResult&quot;</h2><span id='topic+RecLinkResult-class'></span>

<h3>Description</h3>

<p>S4 wrapper for S3 class <code>"<a href="#topic+RecLinkResult">RecLinkResult</a>"</code>.
</p>


<h3>Objects from the Class</h3>

<p>Object of the S3 class are created by
classification functions, such as <code><a href="#topic+classifySupv">classifySupv</a></code> and 
<code><a href="#topic+emClassify">emClassify</a></code>. The S4 class is virtual and exists solely 
for internal usage in method signatures.
</p>


<h3>Slots</h3>


<dl>
<dt><code>.S3Class</code>:</dt><dd><p>Internal slot.</p>
</dd>
</dl>

<p>See <code>"<a href="#topic+RecLinkResult">RecLinkResult</a>"</code> for the structure of the S3 class.
</p>


<h3>Extends</h3>

<p>Class <code>"<a href="#topic+RecLinkData-class">RecLinkData</a>"</code>, directly.
Class <code>"<a href="methods.html#topic+oldClass-class">oldClass</a>"</code>, by class &quot;RecLinkData&quot;, distance 2.
</p>


<h3>Methods</h3>


<dl>
<dt>%append%</dt><dd><p><code>signature(x = "RecLinkResult", y = "RecLinkResult")</code></p>
</dd>
<dt>getErrorMeasures</dt><dd><p><code>signature(object="RecLinkResult")</code></p>
</dd>
<dt>getTable</dt><dd><p><code>signature(object="RecLinkResult")</code></p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Andreas Borg, Murat Sariyar
</p>


<h3>See Also</h3>

<p><code>"<a href="#topic+RecLinkResult">RecLinkResult</a>"</code> for the structure of the S3 class.
<code>"<a href="#topic+RLResult-class">RLResult</a>"</code>, the equivalent data structure for
big data sets.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>showClass("RecLinkResult")
</code></pre>

<hr>
<h2 id='RecLinkResult.object'>
Record Linkage Result Object 
</h2><span id='topic+RecLinkResult'></span>

<h3>Description</h3>

<p>An object representing information about the classification result of a
Record Linkage procedure. 
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>data</code>, <code>pairs</code>, <code>frequencies</code></td>
<td>

<p>Inherited from <code><a href="#topic+RecLinkData">RecLinkData</a></code>.
</p>
</td></tr>
<tr><td><code>prediction</code></td>
<td>
<p>Factor object indicating the classification of each record
pair in <code>valid</code>. Levels are:
</p>

<dl>
<dt><code>"L"</code></dt><dd><p>for links,</p>
</dd>
<dt><code>"P"</code></dt><dd><p>for possible links</p>
</dd>
<dt><code>"N"</code></dt><dd><p>for non-links</p>
</dd>
</dl>

</td></tr>
</table>


<h3>Author(s)</h3>

<p>Andreas Borg</p>


<h3>See Also</h3>

<p><code><a href="#topic+emClassify">emClassify</a></code>.
<code><a href="#topic+RecLinkData">RecLinkData</a></code>.
</p>

<hr>
<h2 id='resample'>Safe Sampling</h2><span id='topic+resample'></span>

<h3>Description</h3>

                                                          
<p>Performs sampling without replacement while avoiding undesired behaviour if
<code>x</code> has length 1.
See documentation of <code><a href="base.html#topic+sample">sample</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>resample(x, size, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="resample_+3A_x">x</code></td>
<td>
<p>A vector from which to sample.</p>
</td></tr>
<tr><td><code id="resample_+3A_size">size</code></td>
<td>
<p>A non-negative number giving the size of the sample.</p>
</td></tr>
<tr><td><code id="resample_+3A_...">...</code></td>
<td>
<p>Further arguments to <code><a href="base.html#topic+sample">sample</a></code>.</p>
</td></tr>
</table>

<hr>
<h2 id='RLBigData-class'>Class &quot;RLBigData&quot;</h2><span id='topic+RLBigData-class'></span>

<h3>Description</h3>

<p>Abstract class for big data sets.
</p>


<h3>Objects from the Class</h3>

<p>A virtual Class: No objects may be created from it.</p>


<h3>Slots in &quot;RLBigData&quot;</h3>


<dl>
<dt><code>frequencies</code>:</dt><dd><p>Object of class <code>"numeric"</code>.
Average frequency of values for each column of the underlying data
(1 / of number of distinct values)
</p>
</dd>
<dt><code>blockFld</code>:</dt><dd><p>Object of class <code>"list"</code>. Blocking definition.
See documentation for <a href="#topic+RLBigDataDedup">constructor functions</a> for details.
</p>
</dd>
<dt><code>excludeFld</code>:</dt><dd><p>Object of class <code>"numeric"</code>.
Indices of attributes which are not considered for comparison.
</p>
</dd>
<dt><code>strcmpFld</code>:</dt><dd><p>Object of class <code>"numeric"</code>.
Indices of attributes on which a string comparator is executed.
</p>
</dd>
<dt><code>strcmpFun</code>:</dt><dd><p>Object of class <code>"character"</code>.
String representing the string comparison function.
</p>
</dd>
<dt><code>phoneticFld</code>:</dt><dd><p>Object of class <code>"numeric"</code>.
Indices of attributes on which a phonetic code is generated.      
</p>
</dd>
<dt><code>phoneticFun</code>:</dt><dd><p>Object of class <code>"character"</code>.
String representing the phonetic coding function.
</p>
</dd>
<dt><code>drv</code>:</dt><dd><p>Object of class <code>"DBIDriver"</code>.
Database driver.
</p>
</dd>
<dt><code>con</code>:</dt><dd><p>Object of class <code>"DBIConnection"</code>.
Database connection.
</p>
</dd>
</dl>



<h3>Methods</h3>


<dl>
<dt>begin</dt><dd><p><code>signature(x = "RLBigData")</code></p>
</dd>
<dt>classifySupv</dt><dd><p><code>signature(model = "RecLinkClassif", newdata = "RLBigData")</code></p>
</dd>
<dt>clear</dt><dd><p><code>signature(x = "RLBigData")</code></p>
</dd>
<dt>clone</dt><dd><p><code>signature(object = "RLBigData")</code></p>
</dd>
<dt>emClassify</dt><dd><p><code>signature(rpairs = "RLBigData")</code></p>
</dd>
<dt>emWeights</dt><dd><p><code>signature(rpairs = "RLBigData")</code></p>
</dd>
<dt>epiClassify</dt><dd><p><code>signature(rpairs = "RLBigData")</code></p>
</dd>
<dt>epiWeights</dt><dd><p><code>signature(rpairs = "RLBigData")</code></p>
</dd>
<dt>getDbFile</dt><dd><p><code>signature(object = "RLBigData")</code></p>
</dd>
<dt>getFrequencies</dt><dd><p><code>signature(x = "RLBigData")</code></p>
</dd>
<dt>getMatchCount</dt><dd><p><code>signature(object = "RLBigData")</code></p>
</dd>
<dt>getNACount</dt><dd><p><code>signature(object = "RLBigData")</code></p>
</dd>
<dt>getPairs</dt><dd><p><code>signature(object = "RLBigData")</code></p>
</dd>
<dt>getPatternCounts</dt><dd><p><code>signature(x = "RLBigData")</code></p>
</dd>
<dt>getSQLStatement</dt><dd><p><code>signature(object = "RLBigData")</code></p>
</dd>
<dt>nextPairs</dt><dd><p><code>signature(x = "RLBigData")</code></p>
</dd>
<dt>saveRLObject</dt><dd><p><code>signature(object = "RLBigData")</code></p>
</dd>
<dt>show</dt><dd><p><code>signature(object = "RLBigData")</code></p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Andreas Borg
</p>


<h3>See Also</h3>

<p>Non-abstract subclasses <code>"<a href="#topic+RLBigDataDedup-class">RLBigDataDedup</a>"</code> and
<code>"<a href="#topic+RLBigDataLinkage-class">RLBigDataLinkage</a>"</code> with constructors
<code><a href="#topic+RLBigDataDedup">RLBigDataDedup</a></code> and <code><a href="#topic+RLBigDataLinkage">RLBigDataLinkage</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>showClass("RLBigData")
</code></pre>

<hr>
<h2 id='RLBigDataDedup'>
Constructors for big data objects.
</h2><span id='topic+RLBigDataDedup'></span><span id='topic+RLBigDataLinkage'></span>

<h3>Description</h3>

<p>These are constructors which initialize a record linkage setup for
big datasets, either deduplication of one (<code>RLBigDataDedup</code>)
or linkage of two datasets (<code>RLBigDataLinkage</code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RLBigDataDedup(dataset, identity = NA, blockfld = list(), exclude = numeric(0), 
  strcmp = numeric(0), strcmpfun = "jarowinkler", phonetic = numeric(0), 
  phonfun = "soundex")

RLBigDataLinkage(dataset1, dataset2, identity1 = NA, identity2 = NA, 
  blockfld = list(), exclude = numeric(0), strcmp = numeric(0), 
  strcmpfun = "jarowinkler", phonetic = numeric(0), phonfun = "soundex")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="RLBigDataDedup_+3A_dataset">dataset</code>, <code id="RLBigDataDedup_+3A_dataset1">dataset1</code>, <code id="RLBigDataDedup_+3A_dataset2">dataset2</code></td>
<td>
<p>Table of records to be deduplicated or linked.
Either a data frame or a matrix.</p>
</td></tr>
<tr><td><code id="RLBigDataDedup_+3A_identity">identity</code>, <code id="RLBigDataDedup_+3A_identity1">identity1</code>, <code id="RLBigDataDedup_+3A_identity2">identity2</code></td>
<td>
<p>Optional vectors (are converted to
factors) for identifying true matches and
non-matches. In a deduplication process, two records <code>dataset[i,]</code>
and <code>dataset[j,]</code> are a true match if and only if 
<code>identity[i,]==identity[j,]</code>. In a linkage process, two 
records <code>dataset1[i,]</code> and <code>dataset2[j,]</code> are a true 
match if and only if <code>identity1[i,]==identity2[j,]</code>.</p>
</td></tr>
<tr><td><code id="RLBigDataDedup_+3A_blockfld">blockfld</code></td>
<td>
<p>Blocking field definition. A numeric or character vector or a list of several such vectors, corresponding to column numbers or names. See details and examples.</p>
</td></tr>
<tr><td><code id="RLBigDataDedup_+3A_exclude">exclude</code></td>
<td>
<p>Columns to be excluded. A numeric or character vector corresponding to columns of dataset or dataset1 and dataset2 which should be excluded from comparison</p>
</td></tr>
<tr><td><code id="RLBigDataDedup_+3A_strcmp">strcmp</code></td>
<td>
<p>Determines usage of string comparison. If <code>FALSE</code>, no string comparison will be used; if <code>TRUE</code>, string comparison will be used for all columns; if a numeric or character vector is given, the string comparison will be used for the specified columns.</p>
</td></tr>
<tr><td><code id="RLBigDataDedup_+3A_strcmpfun">strcmpfun</code></td>
<td>
<p>Character string representing the string comparison function. Possible values are <code>"jarowinkler"</code> and <code>"levenshtein"</code>.
</p>
</td></tr>
<tr><td><code id="RLBigDataDedup_+3A_phonetic">phonetic</code></td>
<td>
<p>Determines usage of phonetic code. Used in the same manner as <code>strcmp</code></p>
</td></tr></table>
<p>.
</p>
<table role = "presentation">
<tr><td><code id="RLBigDataDedup_+3A_phonfun">phonfun</code></td>
<td>
<p>Character string representing the phonetic function. Currently, only <code>"soundex"</code> is supported (see <code><a href="#topic+soundex">soundex</a></code>).
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>These functions act as constructors for the S4 classes
<code>"<a href="#topic+RLBigDataDedup-class">RLBigDataDedup</a>"</code> and <code>"<a href="#topic+RLBigDataLinkage-class">RLBigDataLinkage</a>"</code>.
They make up the initial stage in a Record Linkage process using
large data sets (&gt;= 1.000.000 record pairs) after possibly
normalizing the data. Two general
scenarios are reflected by the two functions: <code>RLBigDataDedup</code> works on a
single data set which is to be deduplicated, <code>RLBigDataLinkage</code> is intended
for linking two data sets together. Their usage follows the functions
<code><a href="#topic+compare.dedup">compare.dedup</a></code> and <code><a href="#topic+compare.linkage">compare.linkage</a></code>, which are recommended
for smaller amounts of data, e.g. training sets.
</p>
<p>Datasets are represented as data frames or matrices (typically of type
character), each row representing one record, each column representing one
attribute (like first name, date of birth,...). Row names are not
retained in the record pairs. If an identifier other than row number is
needed, it should be supplied as a designated column and excluded from
comparison (see note on <code>exclude</code> below).
</p>
<p>In case of <code>RLBigDataLinkage</code>, the two datasets must have the same number
of columns and it is assumed that their column classes and semantics match.
If present, the column names of <code>dataset1</code> are assigned to <code>dataset2</code>
in order to enforce a matching format. Therefore, column names used in
<code>blockfld</code> or other arguments refer to <code>dataset1</code>.
</p>
<p>Each element of <code>blockfld</code> specifies a set of columns in which two
records must agree to be included in the output. Each blocking definition in
the list is applied individually, the sets obtained
thereby are combined by a union operation.
If <code>blockfld</code> is <code>FALSE</code>, no blocking will be performed,
which leads to a large number of record pairs
(<code class="reqn">\frac{n(n-1)}{2}</code> where <code class="reqn">n</code> is the number of
records).
</p>
<p>Fields can be excluded from the linkage process by supplying their column
index in the vector <code>exclude</code>, which is especially useful for
external identifiers. Excluded fields can still be used for
blocking, also with phonetic code.
</p>
<p>Phonetic codes and string similarity measures are supported for enhanced
detection of misspellings. Applying a phonetic code leads to binary
similarity values, where 1 denotes equality of the generated phonetic code.
A string comparator leads to a similarity value in the range <code class="reqn">[0,1]</code>.
Using string comparison on a field for which a phonetic code
is generated is possible, but issues a warning.
</p>
<p>In contrast to the <code>compare.*</code> functions, phonetic coding and string
comparison is not carried out in R, but by database functions. Supported
functions are <code>"soundex"</code> for phonetic coding and <code>"jarowinkler"</code> and
<code>"levenshtein"</code> for string comparison. See the documentation for their
R equivalents (<a href="#topic+phonetics">phonetic functions</a>,
<a href="#topic+strcmp">string comparison</a>) for further information.
</p>


<h3>Value</h3>

<p>An object of class <code>"<a href="#topic+RLBigDataDedup-class">RLBigDataDedup</a>"</code> or
<code>"<a href="#topic+RLBigDataLinkage-class">RLBigDataLinkage</a>"</code>, depending on the called function.
</p>


<h3>Side effects</h3>

<p>The RSQLite database driver is initialized via <code>dbDriver("SQLite")</code>
and a connection established and stored in the returned object. Extension
functions for phonetic code and string comparison are loaded into the database.
The records in <code>dataset</code> or <code>dataset1</code> and <code>dataset2</code> are stored in tables
<code>"data"</code> or <code>"data1"</code> and <code>"data2"</code>, respectively, and 
indices are created on all columns involved in blocking.
</p>


<h3>Author(s)</h3>

<p>Andreas Borg, Murat Sariyar
</p>


<h3>See Also</h3>

<p><code>"<a href="#topic+RLBigDataDedup-class">RLBigDataDedup</a>"</code>, <code>"<a href="#topic+RLBigDataLinkage-class">RLBigDataLinkage</a>"</code>,
<code><a href="#topic+compare.dedup">compare.dedup</a></code>, <code><a href="#topic+compare.linkage">compare.linkage</a></code>,
the vignette &quot;Classes for record linkage of big data sets&quot;.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(RLdata500)
data(RLdata10000)
# deduplication without blocking, use string comparator on names
rpairs &lt;- RLBigDataDedup(RLdata500, strcmp = 1:4)
# linkage with blocking on first name and year of birth, use phonetic
# code on first components of first and last name
rpairs &lt;- RLBigDataLinkage(RLdata500, RLdata10000, blockfld = c(1, 7),
  phonetic = c(1, 3))
# deduplication with blocking on either last name or complete date of birth,
# use string comparator on all fields, include identity information
rpairs &lt;- RLBigDataDedup(RLdata500, identity = identity.RLdata500, strcmp=TRUE,
  blockfld = list(1, c(5, 6, 7)))

</code></pre>

<hr>
<h2 id='RLBigDataDedup-class'>Class &quot;RLBigDataDedup&quot;</h2><span id='topic+RLBigDataDedup-class'></span>

<h3>Description</h3>

<p>Represents a record linkage setup where a single dataset is to
be deduplicated.
</p>


<h3>Objects from the Class</h3>

<p>Objects should be created using the constructor function
<code><a href="#topic+RLBigDataDedup">RLBigDataDedup</a></code>, which does some essential error checking,
conversion and initialization.
</p>


<h3>Slots</h3>

<p>See also <code>"<a href="#topic+RLBigData-class">RLBigData</a>"</code> for inherited slots.
</p>

<dl>
<dt><code>data</code>:</dt><dd><p>Object of class <code>"data.frame"</code> Data set. </p>
</dd>
<dt><code>identity</code>:</dt><dd><p>Object of class <code>"factor"</code> True ID of records in <code>data</code> </p>
</dd>
</dl>



<h3>Extends</h3>

<p>Class <code>"<a href="#topic+RLBigData-class">RLBigData</a>"</code>, directly.
</p>


<h3>Methods</h3>


<dl>
<dt>getColumnNames</dt><dd><p><code>signature(object = "RLBigDataDedup")</code></p>
</dd>
<dt>getExpectedSize</dt><dd><p><code>signature(object = "RLBigDataDedup")</code></p>
</dd>
</dl>

<p>See also <a href="#topic+RLBigData-class">RLBigData-class</a> for inherited methods.
</p>


<h3>Author(s)</h3>

<p>Andreas Borg
</p>


<h3>See Also</h3>

<p><code><a href="#topic+RLBigDataDedup">RLBigDataDedup</a></code>, <a href="#topic+RLBigData-class">RLBigData-class</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>showClass("RLBigDataDedup")
</code></pre>

<hr>
<h2 id='RLBigDataLinkage-class'>Class &quot;RLBigDataLinkage&quot;</h2><span id='topic+RLBigDataLinkage-class'></span>

<h3>Description</h3>

<p>Represents a record linkage setup with two datasets which are to 
be linked together.
</p>


<h3>Objects from the Class</h3>

<p>Objects should be created using the constructor function 
<code><a href="#topic+RLBigDataLinkage">RLBigDataLinkage</a></code>, which does some essential error checking, 
conversion and initialization.
</p>


<h3>Slots</h3>

<p>See also <code>"<a href="#topic+RLBigData-class">RLBigData</a>"</code> for inherited slots.
</p>

<dl>
<dt><code>data1</code>:</dt><dd><p>Object of class <code>"data.frame"</code> First data set. </p>
</dd>
<dt><code>data2</code>:</dt><dd><p>Object of class <code>"data.frame"</code> Second data set. </p>
</dd>
<dt><code>identity1</code>:</dt><dd><p>Object of class <code>"factor"</code> True ID of records in <code>data1</code> </p>
</dd>
<dt><code>identity2</code>:</dt><dd><p>Object of class <code>"factor"</code> True ID of records in <code>data2</code>  </p>
</dd>
</dl>



<h3>Extends</h3>

<p>Class <code>"<a href="#topic+RLBigData-class">RLBigData</a>"</code>, directly.
</p>


<h3>Methods</h3>


<dl>
<dt>getColumnNames</dt><dd><p><code>signature(object = "RLBigDataLinkage")</code></p>
</dd>
<dt>getExpectedSize</dt><dd><p><code>signature(object = "RLBigDataLinkage")</code></p>
</dd>
</dl>

<p>See also <a href="#topic+RLBigData-class">RLBigData-class</a> for inherited methods.
</p>


<h3>Author(s)</h3>

<p>Andreas Borg
</p>


<h3>See Also</h3>

<p><code>"<a href="#topic+RLBigData-class">RLBigData</a>"</code>, <code><a href="#topic+RLBigDataLinkage">RLBigDataLinkage</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>showClass("RLBigDataLinkage")
</code></pre>

<hr>
<h2 id='RLdata'>Test data for Record Linkage</h2><span id='topic+RLdata500'></span><span id='topic+RLdata10000'></span><span id='topic+identity.RLdata500'></span><span id='topic+identity.RLdata10000'></span>

<h3>Description</h3>

<p>The <code>RLdata</code> tables contain artificial personal data for the 
evaluation of Record Linkage procedures. Some records have been duplicated
with randomly generated errors. <code>RLdata500</code> contains fifty duplicates,
<code>RLdata10000</code> thousand duplicates.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RLdata500 
RLdata10000
identity.RLdata500 
identity.RLdata10000
</code></pre>


<h3>Format</h3>

<p><code>RLdata500</code> and <code>RLdata10000</code> are character matrices with 
500 and 10000 records. Each row represents one record, with the following
columns:
</p>

<dl>
<dt>fname_c1</dt><dd><p>First name, first component</p>
</dd>
<dt>fname_c2</dt><dd><p>First name, second component</p>
</dd>
<dt>lname_c1</dt><dd><p>Last name, first component</p>
</dd>
<dt>lname_c2</dt><dd><p>Last name, second component</p>
</dd>
<dt>by</dt><dd><p>Year of birth</p>
</dd>
<dt>bm</dt><dd><p>Month of birth</p>
</dd>
<dt>bd</dt><dd><p>Day of birth</p>
</dd>
</dl>

<p><code>identity.RLdata500</code> and <code>identity.RLdata10000</code> are integer vectors
representing the true record
ids of the two data sets. Two records are duplicates, if and only if their
corresponding values in the identity vector agree.
</p>


<h3>Author(s)</h3>

<p>Andreas Borg, Murat Sariyar</p>


<h3>Source</h3>

<p>Generated with the data generation component of Febrl (Freely 
Extensible Biomedical Record Linkage), version 0.3 (<a href="https://sourceforge.net/projects/febrl/">https://sourceforge.net/projects/febrl/</a>).
The following data sources were used (all relate to Germany):
</p>
<p><a href="https://blog.beliebte-vornamen.de/2009/02/prozentuale-anteile-2008/">https://blog.beliebte-vornamen.de/2009/02/prozentuale-anteile-2008/</a>, a
list of the frequencies of the 20 most popular female names in 2008.
</p>
<p><a href="https://www.beliebte-vornamen.de/760-alle_jahre.htm">https://www.beliebte-vornamen.de/760-alle_jahre.htm</a>, a list of the
100 most popular first names since 1890. The frequencies found in
the source above were extrapolated to fit this list.
</p>
<p><a href="http://www.ahnenforschung-in-stormarn.de/geneal/nachnamen_100.htm">http://www.ahnenforschung-in-stormarn.de/geneal/nachnamen_100.htm</a>, a list of the
100 most frequent family names with frequencies.
</p>
<p>Age distribution as of Dec 31st, 2008, statistics of Statistisches Bundesamt Deutschland, taken from the GENESIS database (<a href="https://www-genesis.destatis.de/genesis/online/logon">https://www-genesis.destatis.de/genesis/online/logon</a>).  
</p>
<p>Web links as of August 2020.
</p>

<hr>
<h2 id='RLResult-class'>Class &quot;RLResult&quot;</h2><span id='topic+RLResult-class'></span>

<h3>Description</h3>

<p>A class that represents the result of a record linkage procedure with
big data sets.
</p>


<h3>Objects from the Class</h3>

<p>Objects from this class are created by the classification functions in
this package, e.g. <code><a href="#topic+classifySupv">classifySupv</a></code>. Directly creating instances
by calling <code>new</code> is neither necessary nor recommended.
</p>


<h3>Slots</h3>


<dl>
<dt><code>data</code>:</dt><dd><p>Object of class <code>"RLBigData"</code>. The data set
which was classified.</p>
</dd>
<dt><code>prediction</code>:</dt><dd><p>Object of class <code>"ff"</code>. A vector
with classification result for every record pair, coded by levels
<code>"N"</code> for a non-link, <code>"P"</code> for a possible link and <code>"L"</code>
for a link.</p>
</dd>
</dl>



<h3>Methods</h3>


<dl>
<dt>clone</dt><dd><p><code>signature(object = "RLResult")</code></p>
</dd>
<dt>getDbFile</dt><dd><p><code>signature(object = "RLResult")</code></p>
</dd>
<dt>getErrorMeasures</dt><dd><p><code>signature(object = "RLResult")</code></p>
</dd>
<dt>getPairs</dt><dd><p><code>signature(object = "RLResult")</code></p>
</dd>
<dt>getTable</dt><dd><p><code>signature(object = "RLResult")</code></p>
</dd>
<dt>saveRLObject</dt><dd><p><code>signature(object = "RLResult")</code></p>
</dd>
</dl>



<h3>Note</h3>

<p>The slot <code>data</code> uses a database to store data and create
comparison patterns, thus assignment of a <code>"RLResult"</code> object to a
different variable can lead to undesired results. Use <code>clone</code> to make
a distinct copy. Similarly, the standard save mechanism does not work;
<code>saveRLObject</code> and <code>loadRLObject</code> are provided to make objects
persistent over different R sessions.
</p>


<h3>Author(s)</h3>

<p>Andreas Borg, Murat Sariyar
</p>


<h3>See Also</h3>

<p><code><a href="#topic+classifySupv">classifySupv</a></code>, <code><a href="#topic+emClassify">emClassify</a></code> and
<code><a href="#topic+epiClassify">epiClassify</a></code> create objects of this type.
</p>

<hr>
<h2 id='show'>
Show a RLBigData object
</h2><span id='topic+show'></span><span id='topic+show+2CRLBigData-method'></span>

<h3>Description</h3>

<p>Shows summarized information on a <code>"<a href="#topic+RLBigData-class">RLBigData</a>"</code> object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  ## S4 method for signature 'RLBigData'
show(object)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="show_+3A_object">object</code></td>
<td>
<p>The object for which to show a summary.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The printed information consists of the type of linkage procedure
(deduplication or linkage) and the number of records and the approximate
number of record pairs as calculated by <code><a href="#topic+getExpectedSize">getExpectedSize</a></code>.
More information is obtained by the
<code><a href="#topic+summary.RLBigDataDedup">summary</a></code> methods for these classes.
</p>


<h3>Value</h3>

<p><code>show</code> returns an invisible <code>NULL</code> and is used for its side effect.
</p>


<h3>Author(s)</h3>

<p>Andreas Borg, Murat Sariyar
</p>


<h3>See Also</h3>

<p><code><a href="methods.html#topic+show">show</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  data(RLdata500)
  rpairs &lt;- RLBigDataDedup(RLdata500)
  rpairs
</code></pre>

<hr>
<h2 id='splitData'>Split Data</h2><span id='topic+splitData'></span>

<h3>Description</h3>

<p>Splits a data set into two sets with desired proportions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>splitData(dataset, prop, keep.mprop = FALSE, num.non = 0, des.mprop = 0, 
use.pred = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="splitData_+3A_dataset">dataset</code></td>
<td>
<p>Object of class <code><a href="#topic+RecLinkData">RecLinkData</a></code>. Data pairs to split.</p>
</td></tr>
<tr><td><code id="splitData_+3A_prop">prop</code></td>
<td>
<p>Real number between 0 and 1. Proportion of data pairs to form the training set.</p>
</td></tr>
<tr><td><code id="splitData_+3A_keep.mprop">keep.mprop</code></td>
<td>
<p>Logical. Whether the ratio of matches should be retained.</p>
</td></tr>
<tr><td><code id="splitData_+3A_num.non">num.non</code></td>
<td>
<p>Positive Integer. Desired number on non-matches in the training set.</p>
</td></tr>
<tr><td><code id="splitData_+3A_des.mprop">des.mprop</code></td>
<td>
<p>Real number between 0 and 1. Desired proportion of matches to
non-matches in the training set.</p>
</td></tr>
<tr><td><code id="splitData_+3A_use.pred">use.pred</code></td>
<td>
<p>Logical. Whether to apply match ratio to previous classification 
results instead of true matching status.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of <code><a href="#topic+RecLinkData">RecLinkData</a></code> objects.
</p>
<table role = "presentation">
<tr><td><code>train</code></td>
<td>
<p>The sampled training data.</p>
</td></tr>
<tr><td><code>valid</code></td>
<td>
<p>All other record pairs</p>
</td></tr>
</table>
<p>The sampled data are stored in the <code>pairs</code> attributes of <code>train</code> 
and <code>valid</code>. If present, the attributes <code>prediction</code> and <code>Wdata</code> 
are split and the corresponding values saved. All other attributes are
copied to both data sets.
</p>
<p>If the number of desired matches or non-matches is higher than the number
actually present in the data, the maximum possible number is chosen and a
warning issued.
</p>


<h3>Author(s)</h3>

<p>Andreas Borg, Murat Sariyar</p>


<h3>See Also</h3>

<p><code><a href="#topic+genSamples">genSamples</a></code> for generating training data based on 
unsupervised classification.</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(RLdata500)
pairs=compare.dedup(RLdata500, identity=identity.RLdata500, 
  blockfld=list(1,3,5,6,7))

# split into halves, do not enforce match ratio
l=splitData(pairs, prop=0.5)
summary(l$train)
summary(l$valid)

# split into 1/3 and 2/3, retain match ration
l=splitData(pairs, prop=1/3, keep.mprop=TRUE)
summary(l$train)
summary(l$valid)

# generate a training set with 100 non-matches and 10 matches
l=splitData(pairs, num.non=100, des.mprop=0.1, keep.mprop=TRUE)
summary(l$train)
summary(l$valid)

</code></pre>

<hr>
<h2 id='stochastic'>
Stochastic record linkage.
</h2><span id='topic+fsClassify'></span><span id='topic+fsClassify-methods'></span><span id='topic+fsClassify+2CRLBigData-method'></span><span id='topic+fsClassify+2CRecLinkData-method'></span><span id='topic+fsWeights'></span><span id='topic+fsWeights-methods'></span><span id='topic+fsWeights+2CRLBigData-method'></span><span id='topic+fsWeights+2CRecLinkData-method'></span>

<h3>Description</h3>

<p>Methods for stochastic record linkage following the framework
of Fellegi and Sunter.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>

## S4 method for signature 'RecLinkData'
fsWeights(rpairs, m = 0.95, u = rpairs$frequencies, cutoff = 1)
## S4 method for signature 'RLBigData'
fsWeights(rpairs, m=0.95, u=getFrequencies(rpairs),
    cutoff=1, withProgressBar = (sink.number()==0))
## S4 method for signature 'RecLinkData'
fsClassify(rpairs, ...)
## S4 method for signature 'RLBigData'
fsClassify(rpairs, threshold.upper, threshold.lower=threshold.upper, 
  m=0.95, u=getFrequencies(rpairs), withProgressBar = (sink.number()==0), cutoff=1)

</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="stochastic_+3A_rpairs">rpairs</code></td>
<td>
<p>The record pairs to be classified.</p>
</td></tr>
<tr><td><code id="stochastic_+3A_threshold.upper">threshold.upper</code></td>
<td>
<p>A numeric value between 0 and 1.</p>
</td></tr>
<tr><td><code id="stochastic_+3A_threshold.lower">threshold.lower</code></td>
<td>
<p>A numeric value between 0 and 1 lower than <code>threshold.upper</code>.</p>
</td></tr>
<tr><td><code id="stochastic_+3A_m">m</code>, <code id="stochastic_+3A_u">u</code></td>
<td>
<p>Numeric vectors. m- and u-probabilities of matching variables, see Details.</p>
</td></tr>
<tr><td><code id="stochastic_+3A_withprogressbar">withProgressBar</code></td>
<td>
<p>Logical. Whether to display a progress bar.</p>
</td></tr>
<tr><td><code id="stochastic_+3A_cutoff">cutoff</code></td>
<td>
<p>Numeric value. Threshold for converting string comparison values
to binary values.</p>
</td></tr>
<tr><td><code id="stochastic_+3A_...">...</code></td>
<td>
<p>Arguments passed to emClassify.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>These methods perform stochastic record linkage following the framework of
Fellegi and Sunter (see reference).
</p>
<p><code>fsWeights</code> calculates matching weights on an object based on the
specified m- and u-probabilities. Each of <code>m</code> and <code>u</code> can be a
numeric vector or a single number in the range <code class="reqn">[0, 1]</code>.
</p>
<p><code>fsClassify</code> performs classification based on the calculated weights.
All record pairs with weights greater or
equal <code>threshold.upper</code> are classified as links. Record pairs with
weights smaller than <code>threshold.upper</code> and greater or equal
<code>threshold.lower</code> are classified as possible links. All remaining
records are classified as non-links.
</p>
<p>The <code>"RecLinkData"</code> method is a shortcut for <code><a href="#topic+emClassify">emClassify</a></code>.
</p>
<p>The <code>"RLBigData"</code> method checks if weights are present in the underlying database. If this is the case, classification
is based on the existing weights. If not, weights are calculated on the fly during classification, but not stored. The latter behaviour might be preferable when a very large dataset is to be classified and disk space is limited.
A progress bar is displayed only if weights are calculated on the fly and, by default, unless output is diverted by
<code><a href="base.html#topic+sink">sink</a></code> (e.g. in a Sweave script).
</p>
<p>For a general introduction to weight based record linkage, see the vignette &quot;Weight-based deduplication&quot;.
</p>


<h3>Value</h3>

<p><code>fsWeights</code> returns a copy of the object with the calculated weights
added. Note that <code>"<a href="#topic+RLBigData-class">RLBigData</a>"</code> objects have some
reference-style semantics, see <a href="#topic+clone">clone</a> for more information.
</p>
<p>For the <code>"<a href="#topic+RecLinkData">RecLinkData</a>"</code> method, <code>fsClassify</code> returns a S3 object
of class <code>"<a href="#topic+RecLinkResult">RecLinkResult</a>"</code> that represents a copy
of <code>newdata</code> with element <code>rpairs$prediction</code>, which stores
the classification result, as addendum.
</p>
<p>For the <code>"<a href="#topic+RLBigData-class">RLBigData</a>"</code> method, <code>fsClassify</code> returns
a S4 object of class <code>"<a href="#topic+RLResult-class">RLResult</a>"</code>.
</p>


<h3>Author(s)</h3>

<p>Andreas Borg, Murat Sariyar</p>


<h3>References</h3>

<p>Ivan P. Fellegi, Alan B. Sunter: A Theory for Record Linkage,
in: Journal of the American Statistical Association Vol. 64, No. 328
(Dec., 1969), pp. 1183&ndash;1210.</p>


<h3>See Also</h3>

<p><code><a href="#topic+epiWeights">epiWeights</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># generate record pairs
data(RLdata500)
rpairs &lt;- compare.dedup(RLdata500, blockfld=list(1,3,5,6,7), identity=identity.RLdata500)

# calculate weights
rpairs &lt;- fsWeights(rpairs)

# classify and show results
summary(fsClassify(rpairs,0))
</code></pre>

<hr>
<h2 id='strcmp'>String Metrics</h2><span id='topic+strcmp'></span><span id='topic+jarowinkler'></span><span id='topic+jaro'></span><span id='topic+winkler'></span><span id='topic+levenshtein'></span><span id='topic+levenshteinDist'></span><span id='topic+levenshteinSim'></span>

<h3>Description</h3>

<p>Functions for computation of the similarity between two strings.</p>


<h3>Usage</h3>

<pre><code class='language-R'>jarowinkler(str1, str2, W_1=1/3, W_2=1/3, W_3=1/3, r=0.5)
levenshteinSim(str1, str2)
levenshteinDist(str1, str2)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="strcmp_+3A_str1">str1</code>, <code id="strcmp_+3A_str2">str2</code></td>
<td>
<p>Two character vectors to compare.</p>
</td></tr>
<tr><td><code id="strcmp_+3A_w_1">W_1</code>, <code id="strcmp_+3A_w_2">W_2</code>, <code id="strcmp_+3A_w_3">W_3</code></td>
<td>
<p>Adjustable weights.</p>
</td></tr>
<tr><td><code id="strcmp_+3A_r">r</code></td>
<td>
<p>Maximum transposition radius. A fraction of the length of the
shorter string.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>String metrics compute a similarity value in the range <code class="reqn">[0,1]</code> for two strings, with 1 denoting the highest (usually equality) and 0 denoting the lowest degree of similarity. In the context of Record Linkage, string similarities can improve the discernibility between matches and non-matches.
</p>
<p><code>jarowinkler</code> is an implementation of the algorithm by Jaro and Winkler (see references). For the meaning of <code>W_1</code>, <code>W_2</code>, <code>W_3</code> and <code>r</code> see the referenced article. For most applications, the default values are reasonable.
</p>
<p><code>levenshteinDist</code> returns the Levenshtein distance, which cannot be directly used as a valid string comparator.
</p>
<p><code>levenshteinSim</code> is a similarity function based on the Levenshtein distance, calculated by
<code class="reqn">1-\frac{\mathrm{d}(\mathit{str}_{1},\mathit{str}_{2})}{\max(A,B))}</code>, where <code class="reqn">\mathrm{d}</code> is the Levenshtein distance
function and <code class="reqn">A</code> and <code class="reqn">B</code> are the lengths of the strings.
</p>
<p>Arguments <code>str1</code> and <code>str2</code> are expected to be of type 
<code>"character"</code>.
Non-alphabetical characters can be processed. Valid format combinations for
the arguments are:
</p>

<ul>
<li><p> Two arrays with the same dimensions.
</p>
</li>
<li><p> Two vectors. The shorter one is recycled as necessary.
</p>
</li></ul>



<h3>Value</h3>

<p>A numeric vector with similarity values in the interval
<code class="reqn">[0,1]</code>. For <code>levenshteinDist</code>, the edit distance as an
integer vector.
</p>


<h3>Note</h3>

<p>String comparison is case-sensitive, which means that for example <code>"R"</code> and <code>"r"</code> have a similarity of 0. If this behaviour is undesired, strings should be normalized before processing.</p>


<h3>Author(s)</h3>

<p>Andreas Borg, Murat Sariyar</p>


<h3>References</h3>

<p>Winkler, W.E.: String Comparator Metrics and Enhanced Decision
Rules in the Fellegi-Sunter Model of Record Linkage. In: Proceedings
of the Section on Survey Research Methods, American Statistical Association
(1990), S. 354&ndash;369.</p>


<h3>Examples</h3>

<pre><code class='language-R'># compare two strings:
jarowinkler("Andreas","Anreas")
# compare one string with several others:
levenshteinSim("Andreas",c("Anreas","Andeas"))
# compare two vectors of strings:
jarowinkler(c("Andreas","Borg"),c("Andreas","Bork"))
</code></pre>

<hr>
<h2 id='subset'>
Subset operator for record linkage objects
</h2><span id='topic++5B.RecLinkData'></span><span id='topic++5B.RecLinkResult'></span><span id='topic++5B.RLBigData'></span><span id='topic++5B.RLResult'></span>

<h3>Description</h3>

<p>Extracts a subset of a <code>"<a href="#topic+RecLinkData">RecLinkData</a>"</code> or
<code>"<a href="#topic+RecLinkResult">RecLinkResult</a>"</code> object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  ## S3 method for class 'RecLinkData'
x[i]
  ## S3 method for class 'RecLinkResult'
x[i]
  ## S3 method for class 'RLBigData'
x[i]
  ## S3 method for class 'RLResult'
x[i]
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="subset_+3A_x">x</code></td>
<td>

<p>The object which to index.
</p>
</td></tr>
<tr><td><code id="subset_+3A_i">i</code></td>
<td>

<p>Indices of pairs to include in the subset.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A copy of <code>x</code> with only the pairs with indices specified by <code>x</code>.
</p>


<h3>Author(s)</h3>

<p>Andreas Borg, Murat Sariyar
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Samples a subset of pairs

data(RLdata500)
rpairs &lt;- compare.dedup(RLdata500, identity = identity.RLdata500,
  blockfld = list(1,3,5,6,7))
nPairs &lt;- nrow(rpairs$pairs)
s &lt;- sample(nPairs, nPairs / 2)
samp &lt;- rpairs[s]
</code></pre>

<hr>
<h2 id='summary'>Print Summary of Record Linkage Data</h2><span id='topic+summary.RecLinkData'></span><span id='topic+summary.RecLinkResult'></span>

<h3>Description</h3>

<p>Prints information on <code><a href="#topic+RecLinkData">RecLinkData</a></code> and
<code>"<a href="#topic+RecLinkResult-class">RecLinkResult</a>"</code> objects.</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'RecLinkData'
summary(object,...)

## S3 method for class 'RecLinkResult'
summary(object,...)

</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="summary_+3A_object">object</code></td>
<td>
<p>The object for which to print a summary.</p>
</td></tr> 
<tr><td><code id="summary_+3A_...">...</code></td>
<td>
<p>Additional arguments from the generic, silently ignored.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The printed information for <code><a href="#topic+RecLinkData">RecLinkData</a></code> objects
includes:
</p>

<ul>
<li><p> The number of records.
</p>
</li>
<li><p> The number of record pairs.
</p>
</li>
<li><p> The number of true matches, true non-matches and pairs with unknown
status.
</p>
</li>
<li><p> If weights have been calculated for this object, a textual histogram
of the weight distribution.            
</p>
</li></ul>

<p>Information on <code>"<a href="#topic+RecLinkResult-class">RecLinkResult</a>"</code> objects includes all of the
above and the following:
</p>

<ul>
<li><p> The number of detected links, non-links and possible links.
</p>
</li>
<li><p> The following error measures, if the true matching status of all record pairs is
known: Alpha error (ratio of false links
to matches), beta error (ratio of false non-links to
non-matches) and accuracy (ratio of correctly classified
pairs to the total number of pairs).
</p>
</li>
<li><p> A cross-classified table counting true matching status against
classification. The true matching status is represented as logical
values, possibly including <code>NA</code> for unknown status.
Classification results are represented by:
</p>

<dl>
<dt><code>"L"</code></dt><dd><p>for links,</p>
</dd>
<dt><code>"P"</code></dt><dd><p>for possible links</p>
</dd>
<dt><code>"N"</code></dt><dd><p>for non-links</p>
</dd>
</dl>

</li></ul>



<h3>Value</h3>

<p>Returns an invisible <code>NULL</code> and is used for its side effect.</p>


<h3>Author(s)</h3>

<p>Andreas Borg</p>


<h3>See Also</h3>

<p><code><a href="#topic+RecLinkData">RecLinkData</a></code>,<code>"<a href="#topic+RecLinkResult-class">RecLinkResult</a>"</code></p>

<hr>
<h2 id='summary.RLBigData'>
summary methods for <code>"RLBigData"</code> objects.
</h2><span id='topic+summary.RLBigData'></span><span id='topic+summary.RLBigDataDedup'></span><span id='topic+summary.RLBigDataLinkage'></span><span id='topic+print.summaryRLBigDataDedup'></span><span id='topic+print.summaryRLBigDataLinkage'></span>

<h3>Description</h3>

<p>Shows summarized information on a <code>"<a href="#topic+RLBigDataDedup-class">RLBigDataDedup</a>"</code>
or <code>"<a href="#topic+RLBigDataDedup-class">RLBigDataDedup</a>"</code> object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  ## S3 method for class 'RLBigDataDedup'
summary(object, ...)
  ## S3 method for class 'RLBigDataLinkage'
summary(object, ...)
  ## S3 method for class 'summaryRLBigDataDedup'
print(x, ...)
  ## S3 method for class 'summaryRLBigDataLinkage'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="summary.RLBigData_+3A_object">object</code></td>
<td>
<p>The object for which to show a summary.</p>
</td></tr>
<tr><td><code id="summary.RLBigData_+3A_x">x</code></td>
<td>
<p>Return value of the summary function.</p>
</td></tr>
<tr><td><code id="summary.RLBigData_+3A_...">...</code></td>
<td>
<p>Additional arguments from the generic function are ignored.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>summary</code> methods return a list of the format shown below. The print
method displays this information on the console in a user-friendly format.
</p>
<p>Blocking fields are displayed in a style like &lsquo;<span class="samp">&#8288;[attr1], [attr2, attr3]&#8288;</span>&rsquo;,
where &lsquo;<span class="samp">&#8288;attr1&#8288;</span>&rsquo; etc. are column names and attributes within brackets
represent one blocking iteration. See <code><a href="#topic+compare.dedup">compare.dedup</a></code> or
<code><a href="#topic+RLBigDataDedup">RLBigDataDedup</a></code> for an explanation of blocking criteria.
</p>


<h3>Value</h3>

<p>For <code>summary</code>, a list with components
</p>
<table role = "presentation">
<tr><td><code>nData</code></td>
<td>
<p>Only for the <code>"<a href="#topic+RLBigDataDedup-class">RLBigDataDedup</a>"</code> method:
Number of records in the dataset.</p>
</td></tr>
<tr><td><code>nData1</code></td>
<td>
<p>Only for the <code>"<a href="#topic+RLBigDataLinkage-class">RLBigDataLinkage</a>"</code> method:
Number of records in dataset 1.</p>
</td></tr>
<tr><td><code>nData2</code></td>
<td>
<p>Only for the <code>"<a href="#topic+RLBigDataLinkage-class">RLBigDataLinkage</a>"</code> method:
Number of records in dataset 2.</p>
</td></tr>
<tr><td><code>attributes</code></td>
<td>
<p>Column names of dataset(s).</p>
</td></tr>
<tr><td><code>blockFld</code></td>
<td>
<p>Blocking definition as a list of character vectors,
representing column names.</p>
</td></tr>
<tr><td><code>nPairs</code></td>
<td>
<p>Number of record pairs</p>
</td></tr>
<tr><td><code>nMatches</code></td>
<td>
<p>Number of matches in the set of record pairs.</p>
</td></tr>
<tr><td><code>nNonMatches</code></td>
<td>
<p>Number of non-matches in the set of record pairs.</p>
</td></tr>
<tr><td><code>nUnkonwn</code></td>
<td>
<p>Number of record pairs with unknown matching status.</p>
</td></tr>
<tr><td><code>weightHist</code></td>
<td>
<p>Only if weights have been calculated for <code>object</code>:
a summary of the weights in histogram style.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Andreas Borg, Murat Sariyar
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+summary">summary</a></code>
<code>"<a href="#topic+RLBigData-class">RLBigData</a>"</code>
<code>RLBigDataDedup</code>, <code>RLBigDataLinkage</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  data(RLdata500)
  rpairs &lt;- RLBigDataDedup(RLdata500, identity = identity.RLdata500,
     blockfld=list(1,3,5:7))
  rpairs &lt;- epiWeights(rpairs)
  summary(rpairs)
</code></pre>

<hr>
<h2 id='summary.RLResult'>
Summary method for <code>"RLResult"</code> objects.
</h2><span id='topic+summary.RLResult'></span><span id='topic+summary+2CRLResult-method'></span><span id='topic+print.summaryRLResult'></span>

<h3>Description</h3>

<p>Get summarized information on a <code>"<a href="#topic+RLResult-class">RLResult</a>"</code>
object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  ## S4 method for signature 'RLResult'
summary(object)
  ## S3 method for class 'summaryRLResult'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="summary.RLResult_+3A_object">object</code></td>
<td>
<p>The object for which to show a summary.</p>
</td></tr>
<tr><td><code id="summary.RLResult_+3A_x">x</code></td>
<td>
<p>Return value of the summary function.</p>
</td></tr>
<tr><td><code id="summary.RLResult_+3A_...">...</code></td>
<td>
<p>Additional arguments from the generic function are ignored.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>summary</code> methods return a list of the format shown below. The print
method displays this information on the console in a user-friendly format.
</p>


<h3>Value</h3>

<p>For <code>summary</code>, a list with components
</p>
<table role = "presentation">
<tr><td><code>nPairs</code></td>
<td>
<p>Number of record pairs.</p>
</td></tr>
<tr><td><code>nLinks</code></td>
<td>
<p>Number of detected links.</p>
</td></tr>
<tr><td><code>nPossibleLinks</code></td>
<td>
<p>Number of detected possible links.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Andreas Borg, Murat Sariyar
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+summary">summary</a></code>
<code>"<a href="#topic+RLResult-class">RLResult</a>"</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  data(RLdata500)
  rpairs &lt;- RLBigDataDedup(RLdata500, blockfld=list(1,3,5:7),
    identity = identity.RLdata500)
  rpairs &lt;- epiWeights(rpairs)
  result &lt;- epiClassify(rpairs, 0.7)
  summary(result)
</code></pre>

<hr>
<h2 id='texSummary'>
LaTeX Summary of linkage results
</h2><span id='topic+texSummary'></span>

<h3>Description</h3>

<p>LaTeX Summary of linkage results
</p>


<h3>Usage</h3>

<pre><code class='language-R'>texSummary(object)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="texSummary_+3A_object">object</code></td>
<td>
<p>A RecLinkResultObject</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For internal usage.
</p>


<h3>Value</h3>

<p>Used for its side effect.
</p>


<h3>Author(s)</h3>

<p>Andreas Borg
</p>

<hr>
<h2 id='trainSupv'>Train a Classifier</h2><span id='topic+trainSupv'></span>

<h3>Description</h3>

<p>Trains a classifier for supervised classification of record pairs.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>trainSupv(rpairs, method, use.pred = FALSE, omit.possible = TRUE, 
  convert.na = TRUE, include.data = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="trainSupv_+3A_rpairs">rpairs</code></td>
<td>
<p>Object of class <code><a href="#topic+RecLinkData">RecLinkData</a></code>. Training data.</p>
</td></tr>
<tr><td><code id="trainSupv_+3A_method">method</code></td>
<td>
<p>A character vector. The classification method to use.</p>
</td></tr>
<tr><td><code id="trainSupv_+3A_use.pred">use.pred</code></td>
<td>
<p>Logical. Whether to use results of an unsupervised classification 
instead of true matching status.</p>
</td></tr>
<tr><td><code id="trainSupv_+3A_omit.possible">omit.possible</code></td>
<td>
<p>Logical. Whether to remove pairs labeled as possible
links or with unknown status.</p>
</td></tr>
<tr><td><code id="trainSupv_+3A_convert.na">convert.na</code></td>
<td>
<p>Logical. Whether to convert <code>NA</code>s to 0 in the
comparison patterns.</p>
</td></tr>
<tr><td><code id="trainSupv_+3A_include.data">include.data</code></td>
<td>
<p>Logical. Whether to include training data in the result object.</p>
</td></tr>
<tr><td><code id="trainSupv_+3A_...">...</code></td>
<td>
<p>Further arguments to the training method.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The given dataset is used as training data for a supervised classification.
Either the true matching status has to be known for a sufficient number of
data pairs or the data must have been classified previously, e.g. by using
<code><a href="#topic+emClassify">emClassify</a></code> or <code><a href="#topic+classifyUnsup">classifyUnsup</a></code>. In the latter case,
argument <code>use.pred</code> has to be set to <code>TRUE</code>.
</p>
<p>A classifying method has to be provided as a character string (factors are
converted to character) through argument <code>method</code>.
The supported classifiers are:
</p>

<dl>
<dt><code>"svm"</code></dt><dd><p>Support vector machine, see <code><a href="e1071.html#topic+svm">svm</a></code>.</p>
</dd>
<dt><code>"rpart"</code></dt><dd><p>Recursive partitioning tree, see <code><a href="rpart.html#topic+rpart">rpart</a></code>.</p>
</dd>
<dt><code>"ada"</code></dt><dd><p>Stochastic boosting model, see <code><a href="ada.html#topic+ada">ada</a></code>.</p>
</dd>
<dt><code>"bagging"</code></dt><dd><p>Bagging with classification trees, see <code><a href="ipred.html#topic+bagging">bagging</a></code>.</p>
</dd>
<dt><code>"nnet"</code></dt><dd><p>Single-hidden-layer neural network, see <code><a href="nnet.html#topic+nnet">nnet</a></code>.</p>
</dd>
<dt><code>"bumping"</code></dt><dd><p>A bootstrap based method using classification trees, see details.</p>
</dd>
</dl>

<p>Arguments in <code>...</code> are passed to the corresponding function.
</p>
<p>Most classifiers cannot handle <code>NA</code>s in the data, so by default these
are converted to 0 before training.
</p>
<p>By <code>omit.possible = TRUE</code>, possible links or pairs with unknown status
are excluded from the training set. Setting this argument to <code>FALSE</code>
allows three-class-classification (links, non-links and possible links), but
the results tend to be poor.
</p>
<p>Leaving <code>include.data=FALSE</code> saves memory, setting it to <code>TRUE</code> can be useful for saving the classificator while keeping track of the underlying training data.
</p>
<p><abbr><span class="acronym">Bumping</span></abbr>, (acronym for &ldquo;Bootstrap umbrella of model
parameters&rdquo;), is an ensemble method described by <cite>Tibshirani and Knight,
1999</cite>. Such as in bagging, multiple classifiers are trained on bootstrap
samples of the training set. The key difference is that not the aggregated
decision of all classifiers (e.g. by majority vote) is used to classify new
data, but only the single model that performs best on the whole training set.
In combination with classification trees as underlying classifiers this
approach allows good interpretability of the trained model while being more
stable against outliers than traditionally induced decision trees. The number
of bootstrap samples to use can be controlled by supplying the argument
<code>n.bootstrap</code>, which defaults to 25.
</p>


<h3>Value</h3>

<p>An object of class <code>RecLinkClassif</code> with the following components:
</p>
<table role = "presentation">
<tr><td><code>train</code></td>
<td>
<p>If <code>include.data</code> is <code>TRUE</code>, a copy of <code>rpairs</code>,
otherwise an empty data frame with the same column names.</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>The model returned by the underlying training function.</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>A copy of the argument <code>method</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Andreas Borg, Murat Sariyar</p>


<h3>References</h3>

<p>Tibshirani R, Knight K: Model search by bootstrap &ldquo;bumping&rdquo;.
Journal of Computational and Graphical Statistics 8(1999):671&ndash;686.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+classifySupv">classifySupv</a></code> for classifying with the trained model, 
<code><a href="#topic+classifyUnsup">classifyUnsup</a></code> for unsupervised classification</p>


<h3>Examples</h3>

<pre><code class='language-R'># Train a rpart decision tree with additional parameter minsplit
data(RLdata500)
pairs=compare.dedup(RLdata500, identity=identity.RLdata500,
                    blockfld=list(1,3,5,6,7))
model=trainSupv(pairs, method="rpart", minsplit=5)
summary(model)
</code></pre>

<hr>
<h2 id='unorderedPairs'>Create Unordered Pairs</h2><span id='topic+unorderedPairs'></span>

<h3>Description</h3>

<p>Creates all unordered pairs of some objects or of the first
<code>x</code> natural numbers.  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>unorderedPairs(x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="unorderedPairs_+3A_x">x</code></td>
<td>
<p>Either an arbitrary vector of literals or a natural number</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If <code>x</code> has length one, all unordered pairs of the first <code>x</code>
natural numbers are created. If <code>x</code> has more than one element,
all unordered pairs of the elements of <code>x</code> are created.
</p>


<h3>Value</h3>

<p>A matrix with two rows, each column holding one pair.
</p>


<h3>Author(s)</h3>

<p>Andreas Borg</p>


<h3>Examples</h3>

<pre><code class='language-R'>  # create unordered pairs of {1,2,3}: {1,2},{1,3} and {2,3}
  unorderedPairs(3)
  # create unordered pairs of {"a","b","c"}: {"a","b"}, {"a","c"},{"b","c"}
  unorderedPairs(c("a","b","c"))
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
