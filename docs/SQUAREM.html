<!DOCTYPE html><html><head><title>Help for package SQUAREM</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {SQUAREM}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#fpiter'><p>Fixed-Point Iteration Scheme</p></a></li>
<li><a href='#internal'><p>Internal functions for SQUAREM</p></a></li>
<li><a href='#squarem'><p>Squared Extrapolation Methods for Accelerating Slowly-Convergent</p>
Fixed-Point Iterations</a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Version:</td>
<td>2021.1</td>
</tr>
<tr>
<td>Date:</td>
<td>2021-01-12</td>
</tr>
<tr>
<td>Title:</td>
<td>Squared Extrapolation Methods for Accelerating EM-Like Monotone
Algorithms</td>
</tr>
<tr>
<td>Description:</td>
<td>Algorithms for accelerating the convergence of slow,
        monotone sequences from smooth, contraction mapping such as the
        EM algorithm. It can be used to accelerate any smooth, linearly
        convergent acceleration scheme.  A tutorial style introduction
        to this package is available in a vignette on the CRAN download
        page or, when the package is loaded in an R session, with
        vignette("SQUAREM"). Refer to the J Stat Software article: &lt;<a href="https://doi.org/10.18637%2Fjss.v092.i07">doi:10.18637/jss.v092.i07</a>&gt;. </td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.0)</td>
</tr>
<tr>
<td>Suggests:</td>
<td>setRNG</td>
</tr>
<tr>
<td>LazyLoad:</td>
<td>yes</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>Author:</td>
<td>Ravi Varadhan</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Ravi Varadhan &lt;ravi.varadhan@jhu.edu&gt;</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://coah.jhu.edu/people/Faculty_personal_Pages/Varadhan.html">https://coah.jhu.edu/people/Faculty_personal_Pages/Varadhan.html</a></td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2021-01-12 23:59:02 UTC; rvaradhan</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2021-01-13 06:40:10 UTC</td>
</tr>
</table>
<hr>
<h2 id='fpiter'>Fixed-Point Iteration Scheme</h2><span id='topic+fpiter'></span>

<h3>Description</h3>

<p>A function to implement the fixed-point iteration algorithm.  This includes monotone, contraction mappings including EM and MM algorithms</p>


<h3>Usage</h3>

<pre><code class='language-R'>  fpiter(par, fixptfn, objfn=NULL, control=list( ), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fpiter_+3A_par">par</code></td>
<td>
<p>A vector of parameters denoting the initial guess for the
fixed-point iteration.</p>
</td></tr>
<tr><td><code id="fpiter_+3A_fixptfn">fixptfn</code></td>
<td>
<p>A vector function, <code class="reqn">F</code> that denotes the fixed-point 
mapping. This function is the most essential input in the package.  It 
should accept a parameter vector as input and should return a parameter
vector of same length. This function defines the fixed-point iteration: 
<code class="reqn">x_{k+1} = F(x_k)</code>.  
In the case of EM algorithm, <code class="reqn">F</code> defines a single E and M step.</p>
</td></tr> 
<tr><td><code id="fpiter_+3A_objfn">objfn</code></td>
<td>
<p>This is a scalar function, $L$, that denotes a &rdquo;merit&rdquo; 
function which attains its local minimum at the fixed-point of $F$.  
This function should accept a parameter vector as input and should 
return a scalar value. In the EM algorithm, the merit function <code class="reqn">L</code>
is the log-likelihood. In some problems, a natural merit function may 
not exist, in which case the algorithm works with only <code>fixptfn</code>.
The merit function function <code>objfn</code> does not have to be specified,
even when a natural merit function is available, especially when its 
computation is expensive.</p>
</td></tr> 
<tr><td><code id="fpiter_+3A_control">control</code></td>
<td>
<p> A list of control parameters to pass on to the algorithm.  Full names of control list elements must be specified, otherwise, user-specifications are ignored.  See *Details* below.</p>
</td></tr>
<tr><td><code id="fpiter_+3A_...">...</code></td>
<td>
<p>Arguments passed to <code>fixptfn</code> and <code>objfn</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>control</code> is list of control parameters for the algorithm.  
</p>

<p><code>control = list(tol = 1.e-07, maxiter = 1500, trace = FALSE, intermed=FALSE)</code>
</p>
<p><code>tol</code> - a small, positive scalar that determines when iterations 
should be terminated.  Iteration is terminated when 
<code class="reqn">||x_k - F(x_k)|| \leq tol</code>.  
Default is <code>1.e-07</code>.
</p>
<p><code>maxiter</code> - an integer denoting the maximum limit on the number of 
evaluations of  <code>fixptfn</code>, <code class="reqn">F</code>.  Default is <code>1500</code>.
</p>
<p><code>trace</code> - a logical variable denoting whether some of the intermediate 
results of iterations should be displayed to the user.  
Default is <code>FALSE</code>. 
</p>
<p><code>intermed</code> - a logical variable denoting whether the intermediate 
results of iterations should be returned. If set to <code>TRUE</code>, the function 
will return a matrix where each row corresponds to parameters at each iteration, 
along with the corresponding fixed-point residual value. Default is <code>FALSE</code>.
</p>


<h3>Value</h3>

<p>A list with the following components:
</p>
<table>
<tr><td><code>par</code></td>
<td>
<p>Parameter,<code class="reqn">x*</code> that are the fixed-point of <code class="reqn">F</code> such 
that <code class="reqn">x* = F(x*)</code>, if convergence is successful.</p>
</td></tr>
<tr><td><code>value.objfn</code></td>
<td>
<p>The value of the objective function <code class="reqn">L</code> at termination.</p>
</td></tr>
<tr><td><code>fpevals</code></td>
<td>
<p>Number of times the fixed-point function <code>fixptfn</code> was evaluated.</p>
</td></tr>
<tr><td><code>objfevals</code></td>
<td>
<p>Number of times the objective function <code>objfn</code> was evaluated.</p>
</td></tr>
<tr><td><code>convergence</code></td>
<td>
<p>An integer code indicating type of convergence.  
<code>0</code> indicates successful convergence, 
whereas <code>1</code> denotes failure to converge.</p>
</td></tr>
</table>


<h3>References</h3>

 
<p>R Varadhan and C Roland (2008), Simple and globally convergent numerical 
schemes for accelerating the convergence of any EM algorithm, 
<em>Scandinavian Journal of Statistics</em>, 35:335-353.
</p>
<p>C Roland, R Varadhan, and CE Frangakis (2007), Squared polynomial extrapolation 
methods with cycling: an application to the positron emission tomography 
problem, <em>Numerical Algorithms</em>, 44:159-172.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+squarem">squarem</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
##############################################################################
# Example 1:  EM algorithm for Poisson mixture estimation 
poissmix.em &lt;- function(p,y) {
# The fixed point mapping giving a single E and M step of the EM algorithm
# 
pnew &lt;- rep(NA,3)
i &lt;- 0:(length(y)-1)
zi &lt;- p[1]*exp(-p[2])*p[2]^i / (p[1]*exp(-p[2])*p[2]^i + (1 - p[1])*exp(-p[3])*p[3]^i)
pnew[1] &lt;- sum(y*zi)/sum(y)
pnew[2] &lt;- sum(y*i*zi)/sum(y*zi)
pnew[3] &lt;- sum(y*i*(1-zi))/sum(y*(1-zi))
p &lt;- pnew
return(pnew)
}

poissmix.loglik &lt;- function(p,y) {
# Objective function whose local minimum is a fixed point \
# negative log-likelihood of binary poisson mixture
i &lt;- 0:(length(y)-1)
loglik &lt;- y*log(p[1]*exp(-p[2])*p[2]^i/exp(lgamma(i+1)) + 
		(1 - p[1])*exp(-p[3])*p[3]^i/exp(lgamma(i+1)))
return ( -sum(loglik) )
}

# Real data from Hasselblad (JASA 1969)
poissmix.dat &lt;- data.frame(death=0:9, freq=c(162,267,271,185,111,61,27,8,3,1))
y &lt;- poissmix.dat$freq
tol &lt;- 1.e-08

# Use a preset seed so the example is reproducible. 
require("setRNG")
old.seed &lt;- setRNG(list(kind="Mersenne-Twister", normal.kind="Inversion",
    seed=54321))

p0 &lt;- c(runif(1),runif(2,0,4))  # random starting value

# Basic EM algorithm
pf1 &lt;- fpiter(p=p0, y=y, fixptfn=poissmix.em, objfn=poissmix.loglik, control=list(tol=tol))


##############################################################################
# Example 2:  Accelerating the convergence of power method iteration for 
# finding the dominant eigenvector of a matrix 

power.method &lt;- function(x, A) {

# Defines one iteration of the power method
# x = starting guess for dominant eigenvector
# A = a square matrix

ax &lt;- as.numeric(A %*% x)
f &lt;- ax / sqrt(as.numeric(crossprod(ax)))
f
}

# Finding the dominant eigenvector of the Bodewig matrix
# This is a famous matrix for which power method has trouble converging
# See, for example, Sidi, Ford, and Smith (SIAM Review, 1988) 
#
# Note: there are two eigenvalues that are equally dominant, 
#  but have opposite signs.
# Sometimes the power method finds the eigenvector corresponding to the 
# large positive eigenvalue, but other times it finds the eigenvector
# corresponding to the large negative eigenvalue
b &lt;- c(2, 1, 3, 4, 1,  -3,   1,   5,  3,   1,   6,  -2,  4,   5,  -2,  -1)
bodewig.mat &lt;- matrix(b,4,4)
eigen(bodewig.mat)

p0 &lt;- rnorm(4)

# Standard power method iteration
ans1 &lt;- fpiter(p0, fixptfn=power.method, A=bodewig.mat)
# re-scaling the eigenvector so that it has unit length
ans1$par &lt;- ans1$par / sqrt(sum(ans1$par^2))  
ans1

</code></pre>

<hr>
<h2 id='internal'>Internal functions for SQUAREM</h2><span id='topic+squarem1'></span><span id='topic+squarem2'></span><span id='topic+cyclem1'></span><span id='topic+cyclem2'></span>

<h3>Description</h3>

<p>SQUAREM functions not to be called by users.</p>


<h3>Usage</h3>

<pre><code class='language-R'>  squarem1(par, fixptfn, objfn, ... , control=list()) 
  squarem2(par, fixptfn, ... , control=list() )
  cyclem1(par, fixptfn, objfn, control=list(), ...)
  cyclem2(par, fixptfn, control=list(), ...)
  </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="internal_+3A_par">par</code></td>
<td>
<p>See <code><a href="#topic+squarem">squarem</a></code>.</p>
</td></tr>
<tr><td><code id="internal_+3A_fixptfn">fixptfn</code></td>
<td>
<p>See <code><a href="#topic+squarem">squarem</a></code>.</p>
</td></tr> 
<tr><td><code id="internal_+3A_objfn">objfn</code></td>
<td>
<p>See <code><a href="#topic+squarem">squarem</a></code>.</p>
</td></tr> 
<tr><td><code id="internal_+3A_control">control</code></td>
<td>
<p>See <code><a href="#topic+squarem">squarem</a></code>.</p>
</td></tr>
<tr><td><code id="internal_+3A_...">...</code></td>
<td>
<p>See <code><a href="#topic+squarem">squarem</a></code>.</p>
</td></tr>
</table>

<hr>
<h2 id='squarem'>Squared Extrapolation Methods for Accelerating Slowly-Convergent 
Fixed-Point Iterations</h2><span id='topic+squarem'></span>

<h3>Description</h3>

<p>Globally-convergent, partially monotone, acceleration schemes for 
accelerating the convergence of *any* smooth, monotone, slowly-converging
contraction mapping. It can be used to accelerate the convergence of a wide 
variety of iterations including the expectation-maximization (EM) algorithms 
and its variants, majorization-minimization (MM) algorithm, power method for 
dominant eigenvalue-eigenvector, Google's page-rank algorithm, and 
multi-dimensional scaling.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  squarem(par, fixptfn, objfn, ... , control=list())
  </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="squarem_+3A_par">par</code></td>
<td>
<p>A vector of parameters denoting the initial guess for the 
fixed-point.</p>
</td></tr>
<tr><td><code id="squarem_+3A_fixptfn">fixptfn</code></td>
<td>
<p>A vector function, $F$ that denotes the fixed-point 
mapping.  This function is the most essential input in the package.  
It should accept a parameter vector as input and should return a 
parameter vector of same length. This function defines the fixed-point 
iteration: <code class="reqn">x_{k+1} = F(x_k)</code>.  
In the case of EM algorithm, <code class="reqn">F</code> defines a single E and M step.</p>
</td></tr> 
<tr><td><code id="squarem_+3A_objfn">objfn</code></td>
<td>
<p>This is a scalar function, <code class="reqn">L</code>, that denotes 
a &rdquo;merit&rdquo; function which attains its local maximum or minimum at the fixed          -point of <code class="reqn">F</code>. Also see the control parameter <code>minimize</code> which              determines whether the objective function is minimized or maximized. The               objective function should accept a parameter vector as input and should return a       scalar value.  In the EM algorithm, the merit function <code class="reqn">L</code> is the either        log-likelihood or its negative. In someproblems, a natural merit function may not       exist, in which case the algorithm works with only <code>fixptfn</code>. The merit           function function <code>objfn</code> does not have to be specified, even when a natural       merit function is available, especially when its computation is expensive.</p>
</td></tr> 
<tr><td><code id="squarem_+3A_control">control</code></td>
<td>
<p>A list of control parameters specifing any changes to 
default values of algorithm control parameters.  Full names of control list            elements must be specified, otherwise, user-specifications are ignored.  
See *Details*.</p>
</td></tr>
<tr><td><code id="squarem_+3A_...">...</code></td>
<td>
<p>Arguments passed to <code>fixptfn</code> and  <code>objfn</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function <code>squarem</code> is a general-purpose algorithm for accelerating 
the convergence of <em>any</em> slowly-convergent (smooth) fixed-point iteration.  Full names of 
</p>
<p>Default values of <code>control</code> are:
<code>K=1</code>,
<code>method=3</code>, 
<code>minimize=TRUE</code>,
<code>square=TRUE</code>, 
<code>step.min0=1</code>, 
<code>step.max0=1</code>, 
<code>mstep=4</code>, 
<code>objfn.inc=1</code>, 
<code>kr=1</code>, 
<code>tol=1e-07</code>, 
<code>maxiter=1500</code>, 
<code>trace=FALSE</code>,
<code>intermed=FALSE</code>.
</p>

<dl>
<dt><code>K</code></dt><dd><p>An integer denoting the order of the SQUAREM scheme.
Default is 1, which is a first-order scheme developed in Varadhan and 
Roland (2008). Our experience is that first-order schemes are adequate 
for most problems. <code>K=2,3</code> may provide greater speed in some 
problems, although they are less reliable than the first-order schemes.</p>
</dd>
<dt><code>method</code></dt><dd><p>Either an integer or a character variable that denotes the 
particular SQUAREM scheme to be used.  When <code>K=1</code>, method should be 
an integer, either 1, 2, or 3.  These correspond to the 3 schemes 
discussed in Varadhan and Roland (2008).  Default is <code>method=3</code>.  
When K &gt; 1, method should be a character string, either <code>''RRE''</code> 
or <code>''MPE''</code>.  These correspond to the reduced-rank extrapolation 
or squared minimal=polynomial extrapolation (See Roland, Varadhan, and 
Frangakis (2007)).  Default is &rdquo;RRE&rdquo;.</p>
</dd>
<dt><code>minimize</code></dt><dd><p>A logical variable.  By default it is set to <code>TRUE</code> for minimization of the objective function. If the objective function is to be maximized, which is commonly the case for likelihood estimation, it should be changed to <code>FALSE</code>.</p>
</dd>
<dt><code>square</code></dt><dd><p>A logical variable indicating whether or not a squared 
extrapolation scheme should be used.  Our experience is that the 
squared extrapolation schemes are faster and more stable than the 
unsquared schemes. Hence, we have set the default as TRUE.</p>
</dd>  
<dt><code>step.min0</code></dt><dd><p>A scalar denoting the minimum steplength taken by a
SQUAREM algorithm.  Default is 1.  For contractive fixed-point 
iterations (e.g. EM and MM), this defualt works well.  In problems 
where an eigenvalue of the Jacobian of $F$ is outside of the 
interval <code class="reqn">(0,1)</code>, <code>step.min0</code> should be less than 1 
or even negative in some cases.</p>
</dd>
<dt><code>step.max0</code></dt><dd><p>A positive-valued scalar denoting the initial value 
of the maximum steplength taken by a SQUAREM algorithm.  
Default is 1.  When the steplength computed by SQUAREM exceeds  
<code>step.max0</code>, the steplength is set equal to step.max0, but 
then step.max0 is increased by a factor of mstep.</p>
</dd>
<dt><code>mstep</code></dt><dd><p>A scalar greater than 1.  When the steplength computed 
by SQUAREM exceeds  <code>step.max0</code>, the steplength is set equal 
to  <code>step.max0</code>, but  <code>step.max0</code> is increased by a factor 
of  <code>mstep</code>. Default is 4.</p>
</dd>
<dt><code>objfn.inc</code></dt><dd><p>A non-negative scalar that dictates the degree of 
non-montonicity.  Default is 1.  Set  <code>objfn.inc = 0</code> to 
obtain monotone convergence. Setting  <code>objfn.inc = Inf</code> gives a 
non-monotone scheme.  In-between values result in partially-monotone 
convergence.</p>
</dd>
<dt><code>kr</code></dt><dd><p>A non-negative scalar that dictates the degree of 
non-montonicity.  Default is 1.  Set  <code>kr = 0</code> to obtain 
monotone convergence. Setting  <code>kr = Inf</code> gives a non-monotone 
scheme.  In-between values result in partially-monotone convergence.  This parameter is only used when  <code>objfn</code> is not specified by user.</p>
</dd>
<dt><code>tol</code></dt><dd><p>A small, positive scalar that determines when iterations 
should be terminated.  Iteration is terminated when 
<code class="reqn">||x_k - F(x_k)|| \leq tol</code>.  
Default is <code>1.e-07</code>.</p>
</dd>
<dt><code>maxiter</code></dt><dd><p>An integer denoting the maximum limit on the number 
of evaluations of  <code>fixptfn</code>, <code class="reqn">F</code>.  Default is 1500.</p>
</dd>
<dt><code>trace</code></dt><dd><p>A logical variable denoting whether some of the intermediate 
results of iterations should be displayed to the user.  
Default is <code>FALSE</code>.</p>
</dd>
<dt><code>intermed</code></dt><dd><p>A logical variable denoting whether the intermediate 
results of iterat ions should be returned. If set to <code>TRUE</code>, the function 
will return a matrix where each row corresponds to parameters at each iteration, 
along with the corresponding log-likelihood value.  When the codeobjfn is not specified it will return the fixed-point residual instead of the objective function values. 
Default is <code>FALSE</code>.</p>
</dd>
</dl>



<h3>Value</h3>

<p>A list with the following components:
</p>
<table>
<tr><td><code>par</code></td>
<td>
<p>Parameter, <code class="reqn">x*</code> that are the fixed-point of <code class="reqn">F</code> 
such that <code class="reqn">x* = F(x*)</code>, if convergence is successful.</p>
</td></tr>
<tr><td><code>value.objfn</code></td>
<td>
<p>The value of the objective function $L$ at termination.</p>
</td></tr>
<tr><td><code>fpevals</code></td>
<td>
<p>Number of times the fixed-point function <code>fixptfn</code> was evaluated.</p>
</td></tr>
<tr><td><code>objfevals</code></td>
<td>
<p>Number of times the objective function <code>objfn</code> was evaluated.</p>
</td></tr>
<tr><td><code>convergence</code></td>
<td>
<p>An integer code indicating type of convergence.  <code>0</code> 
indicates successful convergence, whereas <code>1</code> denotes failure to 
converge.</p>
</td></tr>
<tr><td><code>p.intermed</code></td>
<td>
<p>A matrix where each row corresponds to parameters at each iteration, 
along with the corresponding log-likelihood value. This object is returned only when 
the control parameter <code>intermed</code> is set to <code>TRUE</code>.  It is not returned when 
<code>objfn</code> is not specified.</p>
</td></tr>
</table>


<h3>References</h3>

 
<p>R Varadhan and C Roland (2008), Simple and globally convergent numerical 
schemes for accelerating the convergence of any EM algorithm, 
<em>Scandinavian Journal of Statistics</em>, 35:335-353.
</p>
<p>C Roland, R Varadhan, and CE Frangakis (2007), Squared polynomial 
extrapolation methods with cycling: an application to the positron emission 
tomography problem, <em>Numerical Algorithms</em>, 44:159-172.
</p>
<p>Y Du and R Varadhan (2020), SQUAREM: An R package for off-the-shelf acceleration 
of EM, MM, and other EM-like monotone algorithms, <em>Journal of Statistical Software</em>,
92(7): 1-41.  &lt;doi:10.18637/jss.v092.i07&gt;
</p>


<h3>See Also</h3>

<p><code><a href="#topic+fpiter">fpiter</a></code> 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>###########################################################################
# Also see the vignette by typing:
#  vignette("SQUAREM", all=FALSE)
#
# Example 1:  EM algorithm for Poisson mixture estimation 

poissmix.em &lt;- function(p,y) {
# The fixed point mapping giving a single E and M step of the EM algorithm
# 
pnew &lt;- rep(NA,3)
i &lt;- 0:(length(y)-1)
zi &lt;- p[1]*exp(-p[2])*p[2]^i / (p[1]*exp(-p[2])*p[2]^i + (1 - p[1])*exp(-p[3])*p[3]^i)
pnew[1] &lt;- sum(y*zi)/sum(y)
pnew[2] &lt;- sum(y*i*zi)/sum(y*zi)
pnew[3] &lt;- sum(y*i*(1-zi))/sum(y*(1-zi))
p &lt;- pnew
return(pnew)
}

poissmix.loglik &lt;- function(p,y) {
# Objective function whose local minimum is a fixed point 
# negative log-likelihood of binary poisson mixture
i &lt;- 0:(length(y)-1)
loglik &lt;- y*log(p[1]*exp(-p[2])*p[2]^i/exp(lgamma(i+1)) + 
		(1 - p[1])*exp(-p[3])*p[3]^i/exp(lgamma(i+1)))
return ( -sum(loglik) )
}

# Real data from Hasselblad (JASA 1969)
poissmix.dat &lt;- data.frame(death=0:9, freq=c(162,267,271,185,111,61,27,8,3,1))
y &lt;- poissmix.dat$freq
tol &lt;- 1.e-08

# Use a preset seed so the example is reproducable. 
require("setRNG")
old.seed &lt;- setRNG(list(kind="Mersenne-Twister", normal.kind="Inversion",
    seed=54321))

p0 &lt;- c(runif(1),runif(2,0,4))  # random starting value

# Basic EM algorithm
pf1 &lt;- fpiter(p=p0, y=y, fixptfn=poissmix.em, objfn=poissmix.loglik, control=list(tol=tol))

# First-order SQUAREM algorithm with SqS3 method
pf2 &lt;- squarem(par=p0, y=y, fixptfn=poissmix.em, objfn=poissmix.loglik, 
               control=list(tol=tol))

# First-order SQUAREM algorithm with SqS2 method
pf3 &lt;- squarem(par=p0, y=y, fixptfn=poissmix.em, objfn=poissmix.loglik, 
               control=list(method=2, tol=tol))

# First-order SQUAREM algorithm with SqS3 method; non-monotone 
# Note: the objective function is not evaluated when objfn.inc = Inf 
pf4 &lt;- squarem(par=p0,y=y, fixptfn=poissmix.em,
               control=list(tol=tol, objfn.inc=Inf))

# First-order SQUAREM algorithm with SqS3 method; 
#  objective function is not specified
pf5 &lt;- squarem(par=p0,y=y, fixptfn=poissmix.em, control=list(tol=tol, kr=0.1))

# Second-order (K=2) SQUAREM algorithm with SqRRE 
pf6 &lt;- squarem(par=p0, y=y, fixptfn=poissmix.em, objfn=poissmix.loglik, 
               control=list (K=2, tol=tol))

# Second-order SQUAREM algorithm with SqRRE; objective function is not specified
pf7 &lt;- squarem(par=p0, y=y, fixptfn=poissmix.em, control=list(K=2, tol=tol))

# Comparison of converged parameter estimates
par.mat &lt;- rbind(pf1$par, pf2$par, pf3$par, pf4$par, pf5$par, pf6$par, pf7$par)
par.mat

# Compare objective function values 
# (note: `NA's indicate that \code{objfn} was not specified)
c(pf1$value, pf2$value, pf3$value, pf4$value, 
  pf5$value, pf6$value, pf7$value)

# Compare number of fixed-point evaluations
c(pf1$fpeval, pf2$fpeval, pf3$fpeval, pf4$fpeval, 
  pf5$fpeval, pf6$fpeval, pf7$fpeval)

# Compare mumber of objective function evaluations 
# (note: `0' indicate that \code{objfn} was not specified)
c(pf1$objfeval, pf2$objfeval, pf3$objfeval, pf4$objfeval, 
  pf5$objfeval, pf6$objfeval, pf7$objfeval)

###############################################################
# Example 2: Same as above (i.e. Poisson mixture)
# but now showing how to "maximize" the log-likelihood

poissmix.loglik.max &lt;- function(p,y) {
# Objective function which is to be *maximized* 
# Log-likelihood of binary poisson mixture
i &lt;- 0:(length(y)-1)
loglik &lt;- y*log(p[1]*exp(-p[2])*p[2]^i/exp(lgamma(i+1)) + 
		(1 - p[1])*exp(-p[3])*p[3]^i/exp(lgamma(i+1)))
return ( sum(loglik) )
}

# Maximizing the log-likelihood
# Note:  the control parameter `minimize' is set to FALSE
#
pf.max &lt;- squarem(par=p0, y=y, fixptfn=poissmix.em, objfn=poissmix.loglik.max, 
               control=list(tol=tol, minimize=FALSE))
pf.max

##############################################################################
# Example 3:  Accelerating the convergence of power method iteration 
#  for finding the dominant eigenvector of a matrix 

power.method &lt;- function(x, A) {
# Defines one iteration of the power method
# x = starting guess for dominant eigenvector
# A = a square matrix
ax &lt;- as.numeric(A %*% x)
f &lt;- ax / sqrt(as.numeric(crossprod(ax)))
f
}

# Finding the dominant eigenvector of the Bodewig matrix
b &lt;- c(2, 1, 3, 4, 1,  -3,   1,   5,  3,   1,   6,  -2,  4,   5,  -2,  -1)
bodewig.mat &lt;- matrix(b,4,4)
eigen(bodewig.mat)

p0 &lt;- rnorm(4)

# Standard power method iteration
ans1 &lt;- fpiter(p0, fixptfn=power.method, A=bodewig.mat)
# re-scaling the eigenvector so that it has unit length
ans1$par &lt;- ans1$par / sqrt(sum(ans1$par^2))  
ans1

# First-order SQUAREM with default settings 
ans2 &lt;- squarem(p0, fixptfn=power.method, A=bodewig.mat, control=list(K=1))
ans2$par &lt;- ans2$par / sqrt(sum(ans2$par^2))
ans2

# First-order SQUAREM with a smaller step.min0
# Convergence is dramatically faster now!
ans3 &lt;- squarem(p0, fixptfn=power.method, A=bodewig.mat, control=list(step.min0 = 0.5))
ans3$par &lt;- ans3$par / sqrt(sum(ans3$par^2))
ans3

# Second-order SQUAREM
ans4 &lt;- squarem(p0, fixptfn=power.method, A=bodewig.mat, control=list(K=2, method="rre"))
ans4$par &lt;- ans4$par / sqrt(sum(ans4$par^2))
ans4
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
