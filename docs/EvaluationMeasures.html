<!DOCTYPE html><html lang="en"><head><title>Help for package EvaluationMeasures</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {EvaluationMeasures}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#EvaluationMeasures.Accuracy'><p>EvaluationMeasures.Accuracy</p></a></li>
<li><a href='#EvaluationMeasures.DOR'><p>EvaluationMeasures.DOR</p></a></li>
<li><a href='#EvaluationMeasures.F1Score'><p>EvaluationMeasures.F1Score</p></a></li>
<li><a href='#EvaluationMeasures.FallOut'><p>EvaluationMeasures.FallOut</p></a></li>
<li><a href='#EvaluationMeasures.FBMeasure'><p>EvaluationMeasures.FBMeasure</p></a></li>
<li><a href='#EvaluationMeasures.FDR'><p>EvaluationMeasures.FDR</p></a></li>
<li><a href='#EvaluationMeasures.FMeasure'><p>EvaluationMeasures.FMeasure</p></a></li>
<li><a href='#EvaluationMeasures.FNR'><p>EvaluationMeasures.FNR</p></a></li>
<li><a href='#EvaluationMeasures.FOR'><p>EvaluationMeasures.FOR</p></a></li>
<li><a href='#EvaluationMeasures.FPR'><p>EvaluationMeasures.FPR</p></a></li>
<li><a href='#EvaluationMeasures.MCC'><p>EvaluationMeasures.MCC</p></a></li>
<li><a href='#EvaluationMeasures.MissRate'><p>EvaluationMeasures.MissRate</p></a></li>
<li><a href='#EvaluationMeasures.NLR'><p>EvaluationMeasures.NLR</p></a></li>
<li><a href='#EvaluationMeasures.NPV'><p>EvaluationMeasures.NPV</p></a></li>
<li><a href='#EvaluationMeasures.PLR'><p>EvaluationMeasures.PLR</p></a></li>
<li><a href='#EvaluationMeasures.PPV'><p>EvaluationMeasures.PPV</p></a></li>
<li><a href='#EvaluationMeasures.Precision'><p>EvaluationMeasures.Precision</p></a></li>
<li><a href='#EvaluationMeasures.Recall'><p>EvaluationMeasures.Recall</p></a></li>
<li><a href='#EvaluationMeasures.Sensitivity'><p>EvaluationMeasures.Sensitivity</p></a></li>
<li><a href='#EvaluationMeasures.Specificity'><p>EvaluationMeasures.Specificity</p></a></li>
<li><a href='#EvaluationMeasures.table'><p>EvaluationMeasures.table</p></a></li>
<li><a href='#EvaluationMeasures.TNR'><p>EvaluationMeasures.TNR</p></a></li>
<li><a href='#EvaluationMeasures.TPR'><p>EvaluationMeasures.TPR</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Collection of Model Evaluation Measure Functions</td>
</tr>
<tr>
<td>Version:</td>
<td>1.1.0</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Babak Khorsand &lt;khorsand@yahoo.com&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Provides Some of the most important evaluation measures for evaluating a model. Just by giving the real and predicted class, measures such as accuracy, sensitivity, specificity, ppv, npv, fmeasure, mcc and ... will be returned.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL]</td>
</tr>
<tr>
<td>LazyData:</td>
<td>TRUE</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>5.0.1</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2016-07-27 09:48:27 UTC; Challenger1980</td>
</tr>
<tr>
<td>Author:</td>
<td>Babak Khorsand [aut, cre],
  Javad Zahiri [ths],
  Abdorreza Savadi [ths]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2016-07-27 12:03:25</td>
</tr>
</table>
<hr>
<h2 id='EvaluationMeasures.Accuracy'>EvaluationMeasures.Accuracy</h2><span id='topic+EvaluationMeasures.Accuracy'></span>

<h3>Description</h3>

<p>Accuracy of prediction
</p>


<h3>Usage</h3>

<pre><code class='language-R'>EvaluationMeasures.Accuracy(Real = NULL, Predicted = NULL, Positive = 1,
  TP = NULL, TN = NULL, FP = NULL, FN = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="EvaluationMeasures.Accuracy_+3A_real">Real</code></td>
<td>
<p>Real binary values of the class</p>
</td></tr>
<tr><td><code id="EvaluationMeasures.Accuracy_+3A_predicted">Predicted</code></td>
<td>
<p>Predicted binary values of the class</p>
</td></tr>
<tr><td><code id="EvaluationMeasures.Accuracy_+3A_positive">Positive</code></td>
<td>
<p>Consider 1 label as Positive Class unless changing this parameter to 0</p>
</td></tr>
<tr><td><code id="EvaluationMeasures.Accuracy_+3A_tp">TP</code></td>
<td>
<p>Number of True Positives. Number of 1 in real which is 1 in predicted.</p>
</td></tr>
<tr><td><code id="EvaluationMeasures.Accuracy_+3A_tn">TN</code></td>
<td>
<p>Number of True Negatives. Number of 0 in real which is 0 in predicted.</p>
</td></tr>
<tr><td><code id="EvaluationMeasures.Accuracy_+3A_fp">FP</code></td>
<td>
<p>Number of False Positives. Number of 0 in real which is 1 in predicted.</p>
</td></tr>
<tr><td><code id="EvaluationMeasures.Accuracy_+3A_fn">FN</code></td>
<td>
<p>Number of False Negatives. Number of 1 in real which is 0 in predicted.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Accuracy is What fraction of our prediction is true.
</p>
<p>By getting the predicted and real values or number of TP,TN,FP,FN return the accuaracy of model
</p>


<h3>Value</h3>

<p>Accuracy
</p>


<h3>Author(s)</h3>

<p>Babak Khorsand
</p>


<h3>Examples</h3>

<pre><code class='language-R'>EvaluationMeasures.Accuracy(c(1,0,1,0,1,0,1,0),c(1,1,1,1,1,1,0,0))
</code></pre>

<hr>
<h2 id='EvaluationMeasures.DOR'>EvaluationMeasures.DOR</h2><span id='topic+EvaluationMeasures.DOR'></span>

<h3>Description</h3>

<p>DOR of prediction
</p>


<h3>Usage</h3>

<pre><code class='language-R'>EvaluationMeasures.DOR(Real = NULL, Predicted = NULL, Positive = 1,
  TP = NULL, TN = NULL, FP = NULL, FN = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="EvaluationMeasures.DOR_+3A_real">Real</code></td>
<td>
<p>Real binary values of the class</p>
</td></tr>
<tr><td><code id="EvaluationMeasures.DOR_+3A_predicted">Predicted</code></td>
<td>
<p>Predicted binary values of the class</p>
</td></tr>
<tr><td><code id="EvaluationMeasures.DOR_+3A_positive">Positive</code></td>
<td>
<p>Consider 1 label as Positive Class unless changing this parameter to 0</p>
</td></tr>
<tr><td><code id="EvaluationMeasures.DOR_+3A_tp">TP</code></td>
<td>
<p>Number of True Positives. Number of 1 in real which is 1 in predicted.</p>
</td></tr>
<tr><td><code id="EvaluationMeasures.DOR_+3A_tn">TN</code></td>
<td>
<p>Number of True Negatives. Number of 0 in real which is 0 in predicted.</p>
</td></tr>
<tr><td><code id="EvaluationMeasures.DOR_+3A_fp">FP</code></td>
<td>
<p>Number of False Positives. Number of 0 in real which is 1 in predicted.</p>
</td></tr>
<tr><td><code id="EvaluationMeasures.DOR_+3A_fn">FN</code></td>
<td>
<p>Number of False Negatives. Number of 1 in real which is 0 in predicted.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Diaognastic odds Ratio is the ratio of Positive Likelihood Ratio by Negative Likelihood Ratio
</p>
<p>By getting the predicted and real values or number of TP,TN,FP,FN return the Diaognastic odds Ratio of model
</p>


<h3>Value</h3>

<p>DOR
</p>


<h3>Author(s)</h3>

<p>Babak Khorsand
</p>


<h3>Examples</h3>

<pre><code class='language-R'>EvaluationMeasures.DOR(c(1,0,1,0,1,0,1,0),c(1,1,1,1,1,1,0,0))
</code></pre>

<hr>
<h2 id='EvaluationMeasures.F1Score'>EvaluationMeasures.F1Score</h2><span id='topic+EvaluationMeasures.F1Score'></span>

<h3>Description</h3>

<p>F1Score of prediction
</p>


<h3>Usage</h3>

<pre><code class='language-R'>EvaluationMeasures.F1Score(Real = NULL, Predicted = NULL, Positive = 1,
  TP = NULL, TN = NULL, FP = NULL, FN = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="EvaluationMeasures.F1Score_+3A_real">Real</code></td>
<td>
<p>Real binary values of the class</p>
</td></tr>
<tr><td><code id="EvaluationMeasures.F1Score_+3A_predicted">Predicted</code></td>
<td>
<p>Predicted binary values of the class</p>
</td></tr>
<tr><td><code id="EvaluationMeasures.F1Score_+3A_positive">Positive</code></td>
<td>
<p>Consider 1 label as Positive Class unless changing this parameter to 0</p>
</td></tr>
<tr><td><code id="EvaluationMeasures.F1Score_+3A_tp">TP</code></td>
<td>
<p>Number of True Positives. Number of 1 in real which is 1 in predicted.</p>
</td></tr>
<tr><td><code id="EvaluationMeasures.F1Score_+3A_tn">TN</code></td>
<td>
<p>Number of True Negatives. Number of 0 in real which is 0 in predicted.</p>
</td></tr>
<tr><td><code id="EvaluationMeasures.F1Score_+3A_fp">FP</code></td>
<td>
<p>Number of False Positives. Number of 0 in real which is 1 in predicted.</p>
</td></tr>
<tr><td><code id="EvaluationMeasures.F1Score_+3A_fn">FN</code></td>
<td>
<p>Number of False Negatives. Number of 1 in real which is 0 in predicted.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>F1Score is Harmonic mean of precision and recall.
</p>
<p>By getting the predicted and real values or number of TP,TN,FP,FN return the F1Score or F1Measure of model
</p>


<h3>Value</h3>

<p>F1Score
</p>


<h3>Author(s)</h3>

<p>Babak Khorsand
</p>


<h3>Examples</h3>

<pre><code class='language-R'>EvaluationMeasures.F1Score(c(1,0,1,0,1,0,1,0),c(1,1,1,1,1,1,0,0))
</code></pre>

<hr>
<h2 id='EvaluationMeasures.FallOut'>EvaluationMeasures.FallOut</h2><span id='topic+EvaluationMeasures.FallOut'></span>

<h3>Description</h3>

<p>FallOut of prediction
</p>


<h3>Usage</h3>

<pre><code class='language-R'>EvaluationMeasures.FallOut(Real = NULL, Predicted = NULL, Positive = 1,
  TP = NULL, TN = NULL, FP = NULL, FN = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="EvaluationMeasures.FallOut_+3A_real">Real</code></td>
<td>
<p>Real binary values of the class</p>
</td></tr>
<tr><td><code id="EvaluationMeasures.FallOut_+3A_predicted">Predicted</code></td>
<td>
<p>Predicted binary values of the class</p>
</td></tr>
<tr><td><code id="EvaluationMeasures.FallOut_+3A_positive">Positive</code></td>
<td>
<p>Consider 1 label as Positive Class unless changing this parameter to 0</p>
</td></tr>
<tr><td><code id="EvaluationMeasures.FallOut_+3A_tp">TP</code></td>
<td>
<p>Number of True Positives. Number of 1 in real which is 1 in predicted.</p>
</td></tr>
<tr><td><code id="EvaluationMeasures.FallOut_+3A_tn">TN</code></td>
<td>
<p>Number of True Negatives. Number of 0 in real which is 0 in predicted.</p>
</td></tr>
<tr><td><code id="EvaluationMeasures.FallOut_+3A_fp">FP</code></td>
<td>
<p>Number of False Positives. Number of 0 in real which is 1 in predicted.</p>
</td></tr>
<tr><td><code id="EvaluationMeasures.FallOut_+3A_fn">FN</code></td>
<td>
<p>Number of False Negatives. Number of 1 in real which is 0 in predicted.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Fall out is Poportional of negatives that predict as positive.
</p>
<p>By getting the predicted and real values or number of TP,TN,FP,FN return the Fall out or False Positive Rate of model
</p>


<h3>Value</h3>

<p>FallOut
</p>


<h3>Author(s)</h3>

<p>Babak Khorsand
</p>


<h3>Examples</h3>

<pre><code class='language-R'>EvaluationMeasures.FallOut(c(1,0,1,0,1,0,1,0),c(1,1,1,1,1,1,0,0))
</code></pre>

<hr>
<h2 id='EvaluationMeasures.FBMeasure'>EvaluationMeasures.FBMeasure</h2><span id='topic+EvaluationMeasures.FBMeasure'></span>

<h3>Description</h3>

<p>FBMeasure of prediction
</p>


<h3>Usage</h3>

<pre><code class='language-R'>EvaluationMeasures.FBMeasure(Real = NULL, Predicted = NULL, Positive = 1,
  TP = NULL, TN = NULL, FP = NULL, FN = NULL, B = 1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="EvaluationMeasures.FBMeasure_+3A_real">Real</code></td>
<td>
<p>Real binary values of the class</p>
</td></tr>
<tr><td><code id="EvaluationMeasures.FBMeasure_+3A_predicted">Predicted</code></td>
<td>
<p>Predicted binary values of the class</p>
</td></tr>
<tr><td><code id="EvaluationMeasures.FBMeasure_+3A_positive">Positive</code></td>
<td>
<p>Consider 1 label as Positive Class unless changing this parameter to 0</p>
</td></tr>
<tr><td><code id="EvaluationMeasures.FBMeasure_+3A_tp">TP</code></td>
<td>
<p>Number of True Positives. Number of 1 in real which is 1 in predicted.</p>
</td></tr>
<tr><td><code id="EvaluationMeasures.FBMeasure_+3A_tn">TN</code></td>
<td>
<p>Number of True Negatives. Number of 0 in real which is 0 in predicted.</p>
</td></tr>
<tr><td><code id="EvaluationMeasures.FBMeasure_+3A_fp">FP</code></td>
<td>
<p>Number of False Positives. Number of 0 in real which is 1 in predicted.</p>
</td></tr>
<tr><td><code id="EvaluationMeasures.FBMeasure_+3A_fn">FN</code></td>
<td>
<p>Number of False Negatives. Number of 1 in real which is 0 in predicted.</p>
</td></tr>
<tr><td><code id="EvaluationMeasures.FBMeasure_+3A_b">B</code></td>
<td>
<p>Weight of FMeasure</p>
</td></tr>
</table>


<h3>Details</h3>

<p>FBMeasure is weighted FMeasure.
</p>
<p>By getting the predicted and real values or number of TP,TN,FP,FN return the FBMeasure of model
</p>


<h3>Value</h3>

<p>FBMeasure
</p>


<h3>Author(s)</h3>

<p>Babak Khorsand
</p>


<h3>Examples</h3>

<pre><code class='language-R'>EvaluationMeasures.FBMeasure(c(1,0,1,0,1,0,1,0),c(1,1,1,1,1,1,0,0),B=3)
</code></pre>

<hr>
<h2 id='EvaluationMeasures.FDR'>EvaluationMeasures.FDR</h2><span id='topic+EvaluationMeasures.FDR'></span>

<h3>Description</h3>

<p>FDR of prediction
</p>


<h3>Usage</h3>

<pre><code class='language-R'>EvaluationMeasures.FDR(Real = NULL, Predicted = NULL, Positive = 1,
  TP = NULL, TN = NULL, FP = NULL, FN = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="EvaluationMeasures.FDR_+3A_real">Real</code></td>
<td>
<p>Real binary values of the class</p>
</td></tr>
<tr><td><code id="EvaluationMeasures.FDR_+3A_predicted">Predicted</code></td>
<td>
<p>Predicted binary values of the class</p>
</td></tr>
<tr><td><code id="EvaluationMeasures.FDR_+3A_positive">Positive</code></td>
<td>
<p>Consider 1 label as Positive Class unless changing this parameter to 0</p>
</td></tr>
<tr><td><code id="EvaluationMeasures.FDR_+3A_tp">TP</code></td>
<td>
<p>Number of True Positives. Number of 1 in real which is 1 in predicted.</p>
</td></tr>
<tr><td><code id="EvaluationMeasures.FDR_+3A_tn">TN</code></td>
<td>
<p>Number of True Negatives. Number of 0 in real which is 0 in predicted.</p>
</td></tr>
<tr><td><code id="EvaluationMeasures.FDR_+3A_fp">FP</code></td>
<td>
<p>Number of False Positives. Number of 0 in real which is 1 in predicted.</p>
</td></tr>
<tr><td><code id="EvaluationMeasures.FDR_+3A_fn">FN</code></td>
<td>
<p>Number of False Negatives. Number of 1 in real which is 0 in predicted.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>False Discovery Rate is What fraction of positive predicted are real negative.
</p>
<p>By getting the predicted and real values or number of TP,TN,FP,FN return the False Discovery Rate of model
</p>


<h3>Value</h3>

<p>FDR
</p>


<h3>Author(s)</h3>

<p>Babak Khorsand
</p>


<h3>Examples</h3>

<pre><code class='language-R'>EvaluationMeasures.FDR(c(1,0,1,0,1,0,1,0),c(1,1,1,1,1,1,0,0))
</code></pre>

<hr>
<h2 id='EvaluationMeasures.FMeasure'>EvaluationMeasures.FMeasure</h2><span id='topic+EvaluationMeasures.FMeasure'></span>

<h3>Description</h3>

<p>FMeasure of prediction
</p>


<h3>Usage</h3>

<pre><code class='language-R'>EvaluationMeasures.FMeasure(Real = NULL, Predicted = NULL, Positive = 1,
  TP = NULL, TN = NULL, FP = NULL, FN = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="EvaluationMeasures.FMeasure_+3A_real">Real</code></td>
<td>
<p>Real binary values of the class</p>
</td></tr>
<tr><td><code id="EvaluationMeasures.FMeasure_+3A_predicted">Predicted</code></td>
<td>
<p>Predicted binary values of the class</p>
</td></tr>
<tr><td><code id="EvaluationMeasures.FMeasure_+3A_positive">Positive</code></td>
<td>
<p>Consider 1 label as Positive Class unless changing this parameter to 0</p>
</td></tr>
<tr><td><code id="EvaluationMeasures.FMeasure_+3A_tp">TP</code></td>
<td>
<p>Number of True Positives. Number of 1 in real which is 1 in predicted.</p>
</td></tr>
<tr><td><code id="EvaluationMeasures.FMeasure_+3A_tn">TN</code></td>
<td>
<p>Number of True Negatives. Number of 0 in real which is 0 in predicted.</p>
</td></tr>
<tr><td><code id="EvaluationMeasures.FMeasure_+3A_fp">FP</code></td>
<td>
<p>Number of False Positives. Number of 0 in real which is 1 in predicted.</p>
</td></tr>
<tr><td><code id="EvaluationMeasures.FMeasure_+3A_fn">FN</code></td>
<td>
<p>Number of False Negatives. Number of 1 in real which is 0 in predicted.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>FMeasure is Harmonic mean of precision and recall.
</p>
<p>By getting the predicted and real values or number of TP,TN,FP,FN return the FMeasure or F1Score of model
</p>


<h3>Value</h3>

<p>FMeasure
</p>


<h3>Author(s)</h3>

<p>Babak Khorsand
</p>


<h3>Examples</h3>

<pre><code class='language-R'>EvaluationMeasures.FMeasure(c(1,0,1,0,1,0,1,0),c(1,1,1,1,1,1,0,0))
</code></pre>

<hr>
<h2 id='EvaluationMeasures.FNR'>EvaluationMeasures.FNR</h2><span id='topic+EvaluationMeasures.FNR'></span>

<h3>Description</h3>

<p>FNR of prediction
</p>


<h3>Usage</h3>

<pre><code class='language-R'>EvaluationMeasures.FNR(Real = NULL, Predicted = NULL, Positive = 1,
  TP = NULL, TN = NULL, FP = NULL, FN = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="EvaluationMeasures.FNR_+3A_real">Real</code></td>
<td>
<p>Real binary values of the class</p>
</td></tr>
<tr><td><code id="EvaluationMeasures.FNR_+3A_predicted">Predicted</code></td>
<td>
<p>Predicted binary values of the class</p>
</td></tr>
<tr><td><code id="EvaluationMeasures.FNR_+3A_positive">Positive</code></td>
<td>
<p>Consider 1 label as Positive Class unless changing this parameter to 0</p>
</td></tr>
<tr><td><code id="EvaluationMeasures.FNR_+3A_tp">TP</code></td>
<td>
<p>Number of True Positives. Number of 1 in real which is 1 in predicted.</p>
</td></tr>
<tr><td><code id="EvaluationMeasures.FNR_+3A_tn">TN</code></td>
<td>
<p>Number of True Negatives. Number of 0 in real which is 0 in predicted.</p>
</td></tr>
<tr><td><code id="EvaluationMeasures.FNR_+3A_fp">FP</code></td>
<td>
<p>Number of False Positives. Number of 0 in real which is 1 in predicted.</p>
</td></tr>
<tr><td><code id="EvaluationMeasures.FNR_+3A_fn">FN</code></td>
<td>
<p>Number of False Negatives. Number of 1 in real which is 0 in predicted.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>False Negative Rate is Proportional of positives that predict as negative .
</p>
<p>By getting the predicted and real values or number of TP,TN,FP,FN return the Miss Rate or False Negative Rate of model
</p>


<h3>Value</h3>

<p>FNR
</p>


<h3>Author(s)</h3>

<p>Babak Khorsand
</p>


<h3>Examples</h3>

<pre><code class='language-R'>EvaluationMeasures.FNR(c(1,0,1,0,1,0,1,0),c(1,1,1,1,1,1,0,0))
</code></pre>

<hr>
<h2 id='EvaluationMeasures.FOR'>EvaluationMeasures.FOR</h2><span id='topic+EvaluationMeasures.FOR'></span>

<h3>Description</h3>

<p>FOR of prediction
</p>


<h3>Usage</h3>

<pre><code class='language-R'>EvaluationMeasures.FOR(Real = NULL, Predicted = NULL, Positive = 1,
  TP = NULL, TN = NULL, FP = NULL, FN = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="EvaluationMeasures.FOR_+3A_real">Real</code></td>
<td>
<p>Real binary values of the class</p>
</td></tr>
<tr><td><code id="EvaluationMeasures.FOR_+3A_predicted">Predicted</code></td>
<td>
<p>Predicted binary values of the class</p>
</td></tr>
<tr><td><code id="EvaluationMeasures.FOR_+3A_positive">Positive</code></td>
<td>
<p>Consider 1 label as Positive Class unless changing this parameter to 0</p>
</td></tr>
<tr><td><code id="EvaluationMeasures.FOR_+3A_tp">TP</code></td>
<td>
<p>Number of True Positives. Number of 1 in real which is 1 in predicted.</p>
</td></tr>
<tr><td><code id="EvaluationMeasures.FOR_+3A_tn">TN</code></td>
<td>
<p>Number of True Negatives. Number of 0 in real which is 0 in predicted.</p>
</td></tr>
<tr><td><code id="EvaluationMeasures.FOR_+3A_fp">FP</code></td>
<td>
<p>Number of False Positives. Number of 0 in real which is 1 in predicted.</p>
</td></tr>
<tr><td><code id="EvaluationMeasures.FOR_+3A_fn">FN</code></td>
<td>
<p>Number of False Negatives. Number of 1 in real which is 0 in predicted.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>False Ommision Rate is What fraction of negative predicted are real positive.
</p>
<p>By getting the predicted and real values or number of TP,TN,FP,FN return the False Omission Rate of model
</p>


<h3>Value</h3>

<p>FOR
</p>


<h3>Author(s)</h3>

<p>Babak Khorsand
</p>


<h3>Examples</h3>

<pre><code class='language-R'>EvaluationMeasures.FOR(c(1,0,1,0,1,0,1,0),c(1,1,1,1,1,1,0,0))
</code></pre>

<hr>
<h2 id='EvaluationMeasures.FPR'>EvaluationMeasures.FPR</h2><span id='topic+EvaluationMeasures.FPR'></span>

<h3>Description</h3>

<p>FPR of prediction
</p>


<h3>Usage</h3>

<pre><code class='language-R'>EvaluationMeasures.FPR(Real = NULL, Predicted = NULL, Positive = 1,
  TP = NULL, TN = NULL, FP = NULL, FN = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="EvaluationMeasures.FPR_+3A_real">Real</code></td>
<td>
<p>Real binary values of the class</p>
</td></tr>
<tr><td><code id="EvaluationMeasures.FPR_+3A_predicted">Predicted</code></td>
<td>
<p>Predicted binary values of the class</p>
</td></tr>
<tr><td><code id="EvaluationMeasures.FPR_+3A_positive">Positive</code></td>
<td>
<p>Consider 1 label as Positive Class unless changing this parameter to 0</p>
</td></tr>
<tr><td><code id="EvaluationMeasures.FPR_+3A_tp">TP</code></td>
<td>
<p>Number of True Positives. Number of 1 in real which is 1 in predicted.</p>
</td></tr>
<tr><td><code id="EvaluationMeasures.FPR_+3A_tn">TN</code></td>
<td>
<p>Number of True Negatives. Number of 0 in real which is 0 in predicted.</p>
</td></tr>
<tr><td><code id="EvaluationMeasures.FPR_+3A_fp">FP</code></td>
<td>
<p>Number of False Positives. Number of 0 in real which is 1 in predicted.</p>
</td></tr>
<tr><td><code id="EvaluationMeasures.FPR_+3A_fn">FN</code></td>
<td>
<p>Number of False Negatives. Number of 1 in real which is 0 in predicted.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>False Positive Rate is Poportional of negatives that predict as positive.
</p>
<p>By getting the predicted and real values or number of TP,TN,FP,FN return the Fall out or False Positive Rate of model
</p>


<h3>Value</h3>

<p>FPR
</p>


<h3>Author(s)</h3>

<p>Babak Khorsand
</p>


<h3>Examples</h3>

<pre><code class='language-R'>EvaluationMeasures.FPR(c(1,0,1,0,1,0,1,0),c(1,1,1,1,1,1,0,0))
</code></pre>

<hr>
<h2 id='EvaluationMeasures.MCC'>EvaluationMeasures.MCC</h2><span id='topic+EvaluationMeasures.MCC'></span>

<h3>Description</h3>

<p>MCC of prediction
</p>


<h3>Usage</h3>

<pre><code class='language-R'>EvaluationMeasures.MCC(Real = NULL, Predicted = NULL, Positive = 1,
  TP = NULL, TN = NULL, FP = NULL, FN = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="EvaluationMeasures.MCC_+3A_real">Real</code></td>
<td>
<p>Real binary values of the class</p>
</td></tr>
<tr><td><code id="EvaluationMeasures.MCC_+3A_predicted">Predicted</code></td>
<td>
<p>Predicted binary values of the class</p>
</td></tr>
<tr><td><code id="EvaluationMeasures.MCC_+3A_positive">Positive</code></td>
<td>
<p>Consider 1 label as Positive Class unless changing this parameter to 0</p>
</td></tr>
<tr><td><code id="EvaluationMeasures.MCC_+3A_tp">TP</code></td>
<td>
<p>Number of True Positives. Number of 1 in real which is 1 in predicted.</p>
</td></tr>
<tr><td><code id="EvaluationMeasures.MCC_+3A_tn">TN</code></td>
<td>
<p>Number of True Negatives. Number of 0 in real which is 0 in predicted.</p>
</td></tr>
<tr><td><code id="EvaluationMeasures.MCC_+3A_fp">FP</code></td>
<td>
<p>Number of False Positives. Number of 0 in real which is 1 in predicted.</p>
</td></tr>
<tr><td><code id="EvaluationMeasures.MCC_+3A_fn">FN</code></td>
<td>
<p>Number of False Negatives. Number of 1 in real which is 0 in predicted.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Matthews Correlation Coefficient is correlation coefficient between real and predicted.
</p>
<p>Positive One means perfect prediction,Zero means random prediction, Negative one means total disagreement.
</p>
<p>By getting the predicted and real values or number of TP,TN,FP,FN return the Matthews Correlation Coefficient of model
</p>


<h3>Value</h3>

<p>MCC
</p>


<h3>Author(s)</h3>

<p>Babak Khorsand
</p>


<h3>Examples</h3>

<pre><code class='language-R'>EvaluationMeasures.MCC(c(1,0,1,0,1,0,1,0),c(1,1,1,1,1,1,0,0))
</code></pre>

<hr>
<h2 id='EvaluationMeasures.MissRate'>EvaluationMeasures.MissRate</h2><span id='topic+EvaluationMeasures.MissRate'></span>

<h3>Description</h3>

<p>MissRate of prediction
</p>


<h3>Usage</h3>

<pre><code class='language-R'>EvaluationMeasures.MissRate(Real = NULL, Predicted = NULL, Positive = 1,
  TP = NULL, TN = NULL, FP = NULL, FN = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="EvaluationMeasures.MissRate_+3A_real">Real</code></td>
<td>
<p>Real binary values of the class</p>
</td></tr>
<tr><td><code id="EvaluationMeasures.MissRate_+3A_predicted">Predicted</code></td>
<td>
<p>Predicted binary values of the class</p>
</td></tr>
<tr><td><code id="EvaluationMeasures.MissRate_+3A_positive">Positive</code></td>
<td>
<p>Consider 1 label as Positive Class unless changing this parameter to 0</p>
</td></tr>
<tr><td><code id="EvaluationMeasures.MissRate_+3A_tp">TP</code></td>
<td>
<p>Number of True Positives. Number of 1 in real which is 1 in predicted.</p>
</td></tr>
<tr><td><code id="EvaluationMeasures.MissRate_+3A_tn">TN</code></td>
<td>
<p>Number of True Negatives. Number of 0 in real which is 0 in predicted.</p>
</td></tr>
<tr><td><code id="EvaluationMeasures.MissRate_+3A_fp">FP</code></td>
<td>
<p>Number of False Positives. Number of 0 in real which is 1 in predicted.</p>
</td></tr>
<tr><td><code id="EvaluationMeasures.MissRate_+3A_fn">FN</code></td>
<td>
<p>Number of False Negatives. Number of 1 in real which is 0 in predicted.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Miss Rate is Proportional of positives that predict as negative .
</p>
<p>By getting the predicted and real values or number of TP,TN,FP,FN return the Miss Rate or False Negative Rate of model
</p>


<h3>Value</h3>

<p>MissRate
</p>


<h3>Author(s)</h3>

<p>Babak Khorsand
</p>


<h3>Examples</h3>

<pre><code class='language-R'>EvaluationMeasures.MissRate(c(1,0,1,0,1,0,1,0),c(1,1,1,1,1,1,0,0))
</code></pre>

<hr>
<h2 id='EvaluationMeasures.NLR'>EvaluationMeasures.NLR</h2><span id='topic+EvaluationMeasures.NLR'></span>

<h3>Description</h3>

<p>NLR of prediction
</p>


<h3>Usage</h3>

<pre><code class='language-R'>EvaluationMeasures.NLR(Real = NULL, Predicted = NULL, Positive = 1,
  TP = NULL, TN = NULL, FP = NULL, FN = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="EvaluationMeasures.NLR_+3A_real">Real</code></td>
<td>
<p>Real binary values of the class</p>
</td></tr>
<tr><td><code id="EvaluationMeasures.NLR_+3A_predicted">Predicted</code></td>
<td>
<p>Predicted binary values of the class</p>
</td></tr>
<tr><td><code id="EvaluationMeasures.NLR_+3A_positive">Positive</code></td>
<td>
<p>Consider 1 label as Positive Class unless changing this parameter to 0</p>
</td></tr>
<tr><td><code id="EvaluationMeasures.NLR_+3A_tp">TP</code></td>
<td>
<p>Number of True Positives. Number of 1 in real which is 1 in predicted.</p>
</td></tr>
<tr><td><code id="EvaluationMeasures.NLR_+3A_tn">TN</code></td>
<td>
<p>Number of True Negatives. Number of 0 in real which is 0 in predicted.</p>
</td></tr>
<tr><td><code id="EvaluationMeasures.NLR_+3A_fp">FP</code></td>
<td>
<p>Number of False Positives. Number of 0 in real which is 1 in predicted.</p>
</td></tr>
<tr><td><code id="EvaluationMeasures.NLR_+3A_fn">FN</code></td>
<td>
<p>Number of False Negatives. Number of 1 in real which is 0 in predicted.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Negative Likelihood Ratio is (1-Sensitivity) / Specificity = PR(T-|D+)/PR(T-|D-)
</p>
<p>By getting the predicted and real values or number of TP,TN,FP,FN return the Negative Likelihood Ratio of model
</p>


<h3>Value</h3>

<p>NLR
</p>


<h3>Author(s)</h3>

<p>Babak Khorsand
</p>


<h3>Examples</h3>

<pre><code class='language-R'>EvaluationMeasures.NLR(c(1,0,1,0,1,0,1,0),c(1,1,1,1,1,1,0,0))
</code></pre>

<hr>
<h2 id='EvaluationMeasures.NPV'>EvaluationMeasures.NPV</h2><span id='topic+EvaluationMeasures.NPV'></span>

<h3>Description</h3>

<p>NPV of prediction
</p>


<h3>Usage</h3>

<pre><code class='language-R'>EvaluationMeasures.NPV(Real = NULL, Predicted = NULL, Positive = 1,
  TP = NULL, TN = NULL, FP = NULL, FN = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="EvaluationMeasures.NPV_+3A_real">Real</code></td>
<td>
<p>Real binary values of the class</p>
</td></tr>
<tr><td><code id="EvaluationMeasures.NPV_+3A_predicted">Predicted</code></td>
<td>
<p>Predicted binary values of the class</p>
</td></tr>
<tr><td><code id="EvaluationMeasures.NPV_+3A_positive">Positive</code></td>
<td>
<p>Consider 1 label as Positive Class unless changing this parameter to 0</p>
</td></tr>
<tr><td><code id="EvaluationMeasures.NPV_+3A_tp">TP</code></td>
<td>
<p>Number of True Positives. Number of 1 in real which is 1 in predicted.</p>
</td></tr>
<tr><td><code id="EvaluationMeasures.NPV_+3A_tn">TN</code></td>
<td>
<p>Number of True Negatives. Number of 0 in real which is 0 in predicted.</p>
</td></tr>
<tr><td><code id="EvaluationMeasures.NPV_+3A_fp">FP</code></td>
<td>
<p>Number of False Positives. Number of 0 in real which is 1 in predicted.</p>
</td></tr>
<tr><td><code id="EvaluationMeasures.NPV_+3A_fn">FN</code></td>
<td>
<p>Number of False Negatives. Number of 1 in real which is 0 in predicted.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Negative Predicted Value is What fraction of negative predicted are real negative.
</p>
<p>By getting the predicted and real values or number of TP,TN,FP,FN return the Negative Predicted Value of model
</p>


<h3>Value</h3>

<p>NPV
</p>


<h3>Author(s)</h3>

<p>Babak Khorsand
</p>


<h3>Examples</h3>

<pre><code class='language-R'>EvaluationMeasures.NPV(c(1,0,1,0,1,0,1,0),c(1,1,1,1,1,1,0,0))
</code></pre>

<hr>
<h2 id='EvaluationMeasures.PLR'>EvaluationMeasures.PLR</h2><span id='topic+EvaluationMeasures.PLR'></span>

<h3>Description</h3>

<p>PLR of prediction
</p>


<h3>Usage</h3>

<pre><code class='language-R'>EvaluationMeasures.PLR(Real = NULL, Predicted = NULL, Positive = 1,
  TP = NULL, TN = NULL, FP = NULL, FN = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="EvaluationMeasures.PLR_+3A_real">Real</code></td>
<td>
<p>Real binary values of the class</p>
</td></tr>
<tr><td><code id="EvaluationMeasures.PLR_+3A_predicted">Predicted</code></td>
<td>
<p>Predicted binary values of the class</p>
</td></tr>
<tr><td><code id="EvaluationMeasures.PLR_+3A_positive">Positive</code></td>
<td>
<p>Consider 1 label as Positive Class unless changing this parameter to 0</p>
</td></tr>
<tr><td><code id="EvaluationMeasures.PLR_+3A_tp">TP</code></td>
<td>
<p>Number of True Positives. Number of 1 in real which is 1 in predicted.</p>
</td></tr>
<tr><td><code id="EvaluationMeasures.PLR_+3A_tn">TN</code></td>
<td>
<p>Number of True Negatives. Number of 0 in real which is 0 in predicted.</p>
</td></tr>
<tr><td><code id="EvaluationMeasures.PLR_+3A_fp">FP</code></td>
<td>
<p>Number of False Positives. Number of 0 in real which is 1 in predicted.</p>
</td></tr>
<tr><td><code id="EvaluationMeasures.PLR_+3A_fn">FN</code></td>
<td>
<p>Number of False Negatives. Number of 1 in real which is 0 in predicted.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Positive Likelihood Ratio is Sensitivity / (1-Specificity) = PR(T+|D+)/PR(T+|D-)
</p>
<p>By getting the predicted and real values or number of TP,TN,FP,FN return the Positive Likelihood Ratio of model
</p>


<h3>Value</h3>

<p>PLR
</p>


<h3>Author(s)</h3>

<p>Babak Khorsand
</p>


<h3>Examples</h3>

<pre><code class='language-R'>EvaluationMeasures.PLR(c(1,0,1,0,1,0,1,0),c(1,1,1,1,1,1,0,0))
</code></pre>

<hr>
<h2 id='EvaluationMeasures.PPV'>EvaluationMeasures.PPV</h2><span id='topic+EvaluationMeasures.PPV'></span>

<h3>Description</h3>

<p>PPV of prediction
</p>


<h3>Usage</h3>

<pre><code class='language-R'>EvaluationMeasures.PPV(Real = NULL, Predicted = NULL, Positive = 1,
  TP = NULL, TN = NULL, FP = NULL, FN = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="EvaluationMeasures.PPV_+3A_real">Real</code></td>
<td>
<p>Real binary values of the class</p>
</td></tr>
<tr><td><code id="EvaluationMeasures.PPV_+3A_predicted">Predicted</code></td>
<td>
<p>Predicted binary values of the class</p>
</td></tr>
<tr><td><code id="EvaluationMeasures.PPV_+3A_positive">Positive</code></td>
<td>
<p>Consider 1 label as Positive Class unless changing this parameter to 0</p>
</td></tr>
<tr><td><code id="EvaluationMeasures.PPV_+3A_tp">TP</code></td>
<td>
<p>Number of True Positives. Number of 1 in real which is 1 in predicted.</p>
</td></tr>
<tr><td><code id="EvaluationMeasures.PPV_+3A_tn">TN</code></td>
<td>
<p>Number of True Negatives. Number of 0 in real which is 0 in predicted.</p>
</td></tr>
<tr><td><code id="EvaluationMeasures.PPV_+3A_fp">FP</code></td>
<td>
<p>Number of False Positives. Number of 0 in real which is 1 in predicted.</p>
</td></tr>
<tr><td><code id="EvaluationMeasures.PPV_+3A_fn">FN</code></td>
<td>
<p>Number of False Negatives. Number of 1 in real which is 0 in predicted.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Positive Predictive Value is What fraction of positive predicted are real positive.
</p>
<p>By getting the predicted and real values or number of TP,TN,FP,FN return the Precision or Positive Predicted Value of model
</p>


<h3>Value</h3>

<p>PPV
</p>


<h3>Author(s)</h3>

<p>Babak Khorsand
</p>


<h3>Examples</h3>

<pre><code class='language-R'>EvaluationMeasures.PPV(c(1,0,1,0,1,0,1,0),c(1,1,1,1,1,1,0,0))
</code></pre>

<hr>
<h2 id='EvaluationMeasures.Precision'>EvaluationMeasures.Precision</h2><span id='topic+EvaluationMeasures.Precision'></span>

<h3>Description</h3>

<p>Precision of prediction
</p>


<h3>Usage</h3>

<pre><code class='language-R'>EvaluationMeasures.Precision(Real = NULL, Predicted = NULL, Positive = 1,
  TP = NULL, TN = NULL, FP = NULL, FN = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="EvaluationMeasures.Precision_+3A_real">Real</code></td>
<td>
<p>Real binary values of the class</p>
</td></tr>
<tr><td><code id="EvaluationMeasures.Precision_+3A_predicted">Predicted</code></td>
<td>
<p>Predicted binary values of the class</p>
</td></tr>
<tr><td><code id="EvaluationMeasures.Precision_+3A_positive">Positive</code></td>
<td>
<p>Consider 1 label as Positive Class unless changing this parameter to 0</p>
</td></tr>
<tr><td><code id="EvaluationMeasures.Precision_+3A_tp">TP</code></td>
<td>
<p>Number of True Positives. Number of 1 in real which is 1 in predicted.</p>
</td></tr>
<tr><td><code id="EvaluationMeasures.Precision_+3A_tn">TN</code></td>
<td>
<p>Number of True Negatives. Number of 0 in real which is 0 in predicted.</p>
</td></tr>
<tr><td><code id="EvaluationMeasures.Precision_+3A_fp">FP</code></td>
<td>
<p>Number of False Positives. Number of 0 in real which is 1 in predicted.</p>
</td></tr>
<tr><td><code id="EvaluationMeasures.Precision_+3A_fn">FN</code></td>
<td>
<p>Number of False Negatives. Number of 1 in real which is 0 in predicted.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Precision is What fraction of positive predicted are real positive.
</p>
<p>By getting the predicted and real values or number of TP,TN,FP,FN return the Precision or Positive Predicted Value of model
</p>


<h3>Value</h3>

<p>Precision
</p>


<h3>Author(s)</h3>

<p>Babak Khorsand
</p>


<h3>Examples</h3>

<pre><code class='language-R'>EvaluationMeasures.Precision(c(1,0,1,0,1,0,1,0),c(1,1,1,1,1,1,0,0))
</code></pre>

<hr>
<h2 id='EvaluationMeasures.Recall'>EvaluationMeasures.Recall</h2><span id='topic+EvaluationMeasures.Recall'></span>

<h3>Description</h3>

<p>Recall of prediction
</p>


<h3>Usage</h3>

<pre><code class='language-R'>EvaluationMeasures.Recall(Real = NULL, Predicted = NULL, Positive = 1,
  TP = NULL, TN = NULL, FP = NULL, FN = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="EvaluationMeasures.Recall_+3A_real">Real</code></td>
<td>
<p>Real binary values of the class</p>
</td></tr>
<tr><td><code id="EvaluationMeasures.Recall_+3A_predicted">Predicted</code></td>
<td>
<p>Predicted binary values of the class</p>
</td></tr>
<tr><td><code id="EvaluationMeasures.Recall_+3A_positive">Positive</code></td>
<td>
<p>Consider 1 label as Positive Class unless changing this parameter to 0</p>
</td></tr>
<tr><td><code id="EvaluationMeasures.Recall_+3A_tp">TP</code></td>
<td>
<p>Number of True Positives. Number of 1 in real which is 1 in predicted.</p>
</td></tr>
<tr><td><code id="EvaluationMeasures.Recall_+3A_tn">TN</code></td>
<td>
<p>Number of True Negatives. Number of 0 in real which is 0 in predicted.</p>
</td></tr>
<tr><td><code id="EvaluationMeasures.Recall_+3A_fp">FP</code></td>
<td>
<p>Number of False Positives. Number of 0 in real which is 1 in predicted.</p>
</td></tr>
<tr><td><code id="EvaluationMeasures.Recall_+3A_fn">FN</code></td>
<td>
<p>Number of False Negatives. Number of 1 in real which is 0 in predicted.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Recall is Proportional of positives that are correctly identified
</p>
<p>By getting the predicted and real values or number of TP,TN,FP,FN return the True Positive Rate or Sensitivity or Recall of model
</p>


<h3>Value</h3>

<p>Recall
</p>


<h3>Author(s)</h3>

<p>Babak Khorsand
</p>


<h3>Examples</h3>

<pre><code class='language-R'>EvaluationMeasures.Recall(c(1,0,1,0,1,0,1,0),c(1,1,1,1,1,1,0,0))
</code></pre>

<hr>
<h2 id='EvaluationMeasures.Sensitivity'>EvaluationMeasures.Sensitivity</h2><span id='topic+EvaluationMeasures.Sensitivity'></span>

<h3>Description</h3>

<p>Sensitivity of prediction
</p>


<h3>Usage</h3>

<pre><code class='language-R'>EvaluationMeasures.Sensitivity(Real = NULL, Predicted = NULL,
  Positive = 1, TP = NULL, TN = NULL, FP = NULL, FN = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="EvaluationMeasures.Sensitivity_+3A_real">Real</code></td>
<td>
<p>Real binary values of the class</p>
</td></tr>
<tr><td><code id="EvaluationMeasures.Sensitivity_+3A_predicted">Predicted</code></td>
<td>
<p>Predicted binary values of the class</p>
</td></tr>
<tr><td><code id="EvaluationMeasures.Sensitivity_+3A_positive">Positive</code></td>
<td>
<p>Consider 1 label as Positive Class unless changing this parameter to 0</p>
</td></tr>
<tr><td><code id="EvaluationMeasures.Sensitivity_+3A_tp">TP</code></td>
<td>
<p>Number of True Positives. Number of 1 in real which is 1 in predicted.</p>
</td></tr>
<tr><td><code id="EvaluationMeasures.Sensitivity_+3A_tn">TN</code></td>
<td>
<p>Number of True Negatives. Number of 0 in real which is 0 in predicted.</p>
</td></tr>
<tr><td><code id="EvaluationMeasures.Sensitivity_+3A_fp">FP</code></td>
<td>
<p>Number of False Positives. Number of 0 in real which is 1 in predicted.</p>
</td></tr>
<tr><td><code id="EvaluationMeasures.Sensitivity_+3A_fn">FN</code></td>
<td>
<p>Number of False Negatives. Number of 1 in real which is 0 in predicted.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Sensitivity is Proportional of positives that are correctly identified
</p>
<p>By getting the predicted and real values or number of TP,TN,FP,FN return the Sensitivity or Recall or True Positive Rate of model
</p>


<h3>Value</h3>

<p>Sensitivity
</p>


<h3>Author(s)</h3>

<p>Babak Khorsand
</p>


<h3>Examples</h3>

<pre><code class='language-R'>EvaluationMeasures.Sensitivity(c(1,0,1,0,1,0,1,0),c(1,1,1,1,1,1,0,0))
</code></pre>

<hr>
<h2 id='EvaluationMeasures.Specificity'>EvaluationMeasures.Specificity</h2><span id='topic+EvaluationMeasures.Specificity'></span>

<h3>Description</h3>

<p>Specificity of prediction
</p>


<h3>Usage</h3>

<pre><code class='language-R'>EvaluationMeasures.Specificity(Real = NULL, Predicted = NULL,
  Positive = 1, TP = NULL, TN = NULL, FP = NULL, FN = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="EvaluationMeasures.Specificity_+3A_real">Real</code></td>
<td>
<p>Real binary values of the class</p>
</td></tr>
<tr><td><code id="EvaluationMeasures.Specificity_+3A_predicted">Predicted</code></td>
<td>
<p>Predicted binary values of the class</p>
</td></tr>
<tr><td><code id="EvaluationMeasures.Specificity_+3A_positive">Positive</code></td>
<td>
<p>Consider 1 label as Positive Class unless changing this parameter to 0</p>
</td></tr>
<tr><td><code id="EvaluationMeasures.Specificity_+3A_tp">TP</code></td>
<td>
<p>Number of True Positives. Number of 1 in real which is 1 in predicted.</p>
</td></tr>
<tr><td><code id="EvaluationMeasures.Specificity_+3A_tn">TN</code></td>
<td>
<p>Number of True Negatives. Number of 0 in real which is 0 in predicted.</p>
</td></tr>
<tr><td><code id="EvaluationMeasures.Specificity_+3A_fp">FP</code></td>
<td>
<p>Number of False Positives. Number of 0 in real which is 1 in predicted.</p>
</td></tr>
<tr><td><code id="EvaluationMeasures.Specificity_+3A_fn">FN</code></td>
<td>
<p>Number of False Negatives. Number of 1 in real which is 0 in predicted.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Specificity is Proportional of negatives that are correctly identified
</p>
<p>By getting the predicted and real values or number of TP,TN,FP,FN return the Specificity or True Negative Rate of model
</p>


<h3>Value</h3>

<p>Specificity
</p>


<h3>Author(s)</h3>

<p>Babak Khorsand
</p>


<h3>Examples</h3>

<pre><code class='language-R'>EvaluationMeasures.Specificity(c(1,0,1,0,1,0,1,0),c(1,1,1,1,1,1,0,0))
</code></pre>

<hr>
<h2 id='EvaluationMeasures.table'>EvaluationMeasures.table</h2><span id='topic+EvaluationMeasures.table'></span>

<h3>Description</h3>

<p>Specify the number of TP,TN,FP,FN
</p>


<h3>Usage</h3>

<pre><code class='language-R'>EvaluationMeasures.table(Real, Predicted, Positive = 1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="EvaluationMeasures.table_+3A_real">Real</code></td>
<td>
<p>Real binary values of the class</p>
</td></tr>
<tr><td><code id="EvaluationMeasures.table_+3A_predicted">Predicted</code></td>
<td>
<p>Predicted binary values of the class</p>
</td></tr>
<tr><td><code id="EvaluationMeasures.table_+3A_positive">Positive</code></td>
<td>
<p>Consider 1 label as Positive Class unless changing this parameter to 0</p>
</td></tr>
</table>


<h3>Details</h3>

<p>By getting the predicted values and real values calulate the number of True positive samples, False Negative, False Positive and True Negative
</p>


<h3>Value</h3>

<p>TP,TN,FP,FN
</p>


<h3>Author(s)</h3>

<p>Babak Khorsand
</p>


<h3>Examples</h3>

<pre><code class='language-R'>EvaluationMeasures.table(c(1,0,1,0,1,0,1,0),c(1,1,1,1,1,0,0,0))
</code></pre>

<hr>
<h2 id='EvaluationMeasures.TNR'>EvaluationMeasures.TNR</h2><span id='topic+EvaluationMeasures.TNR'></span>

<h3>Description</h3>

<p>TNR of prediction
</p>


<h3>Usage</h3>

<pre><code class='language-R'>EvaluationMeasures.TNR(Real = NULL, Predicted = NULL, Positive = 1,
  TP = NULL, TN = NULL, FP = NULL, FN = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="EvaluationMeasures.TNR_+3A_real">Real</code></td>
<td>
<p>Real binary values of the class</p>
</td></tr>
<tr><td><code id="EvaluationMeasures.TNR_+3A_predicted">Predicted</code></td>
<td>
<p>Predicted binary values of the class</p>
</td></tr>
<tr><td><code id="EvaluationMeasures.TNR_+3A_positive">Positive</code></td>
<td>
<p>Consider 1 label as Positive Class unless changing this parameter to 0</p>
</td></tr>
<tr><td><code id="EvaluationMeasures.TNR_+3A_tp">TP</code></td>
<td>
<p>Number of True Positives. Number of 1 in real which is 1 in predicted.</p>
</td></tr>
<tr><td><code id="EvaluationMeasures.TNR_+3A_tn">TN</code></td>
<td>
<p>Number of True Negatives. Number of 0 in real which is 0 in predicted.</p>
</td></tr>
<tr><td><code id="EvaluationMeasures.TNR_+3A_fp">FP</code></td>
<td>
<p>Number of False Positives. Number of 0 in real which is 1 in predicted.</p>
</td></tr>
<tr><td><code id="EvaluationMeasures.TNR_+3A_fn">FN</code></td>
<td>
<p>Number of False Negatives. Number of 1 in real which is 0 in predicted.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>True Negative Rate is Proportional of negatives that are correctly identified
</p>
<p>By getting the predicted and real values or number of TP,TN,FP,FN return the Specificity or True Negative Rate of model
</p>


<h3>Value</h3>

<p>TNR
</p>


<h3>Author(s)</h3>

<p>Babak Khorsand
</p>


<h3>Examples</h3>

<pre><code class='language-R'>EvaluationMeasures.TNR(c(1,0,1,0,1,0,1,0),c(1,1,1,1,1,1,0,0))
</code></pre>

<hr>
<h2 id='EvaluationMeasures.TPR'>EvaluationMeasures.TPR</h2><span id='topic+EvaluationMeasures.TPR'></span>

<h3>Description</h3>

<p>TPR of prediction
</p>


<h3>Usage</h3>

<pre><code class='language-R'>EvaluationMeasures.TPR(Real = NULL, Predicted = NULL, Positive = 1,
  TP = NULL, TN = NULL, FP = NULL, FN = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="EvaluationMeasures.TPR_+3A_real">Real</code></td>
<td>
<p>Real binary values of the class</p>
</td></tr>
<tr><td><code id="EvaluationMeasures.TPR_+3A_predicted">Predicted</code></td>
<td>
<p>Predicted binary values of the class</p>
</td></tr>
<tr><td><code id="EvaluationMeasures.TPR_+3A_positive">Positive</code></td>
<td>
<p>Consider 1 label as Positive Class unless changing this parameter to 0</p>
</td></tr>
<tr><td><code id="EvaluationMeasures.TPR_+3A_tp">TP</code></td>
<td>
<p>Number of True Positives. Number of 1 in real which is 1 in predicted.</p>
</td></tr>
<tr><td><code id="EvaluationMeasures.TPR_+3A_tn">TN</code></td>
<td>
<p>Number of True Negatives. Number of 0 in real which is 0 in predicted.</p>
</td></tr>
<tr><td><code id="EvaluationMeasures.TPR_+3A_fp">FP</code></td>
<td>
<p>Number of False Positives. Number of 0 in real which is 1 in predicted.</p>
</td></tr>
<tr><td><code id="EvaluationMeasures.TPR_+3A_fn">FN</code></td>
<td>
<p>Number of False Negatives. Number of 1 in real which is 0 in predicted.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>True Positive Rate is Proportional of positives that are correctly identified
</p>
<p>By getting the predicted and real values or number of TP,TN,FP,FN return the True Positive Rate or Sensitivity or Recall of model
</p>


<h3>Value</h3>

<p>TPR
</p>


<h3>Author(s)</h3>

<p>Babak Khorsand
</p>


<h3>Examples</h3>

<pre><code class='language-R'>EvaluationMeasures.TPR(c(1,0,1,0,1,0,1,0),c(1,1,1,1,1,1,0,0))
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
