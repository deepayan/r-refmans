<!DOCTYPE html><html><head><title>Help for package emmeans</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {emmeans}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#emmeans-package'><p>Estimated marginal means (aka Least-squares means)</p></a></li>
<li><a href='#as.list.emmGrid'><p>Convert to and from <code>emmGrid</code> objects</p></a></li>
<li><a href='#as.mcmc.emmGrid'><p>Support for MCMC-based estimation</p></a></li>
<li><a href='#auto.noise'><p>Auto Pollution Filter Noise</p></a></li>
<li><a href='#cld.emmGrid'><p>Compact letter displays</p></a></li>
<li><a href='#comb_facs'><p>Manipulate factors in a reference grid</p></a></li>
<li><a href='#contrast'><p>Contrasts and linear functions of EMMs</p></a></li>
<li><a href='#contrast-methods'><p>Contrast families</p></a></li>
<li><a href='#eff_size'><p>Calculate effect sizes and confidence bounds thereof</p></a></li>
<li><a href='#emm'><p>Support for <code>multcomp::glht</code></p></a></li>
<li><a href='#emm_example'><p>Run or list additional examples</p></a></li>
<li><a href='#emm_list'><p>The <code>emm_list</code> class</p></a></li>
<li><a href='#emm_options'><p>Set or change emmeans options</p></a></li>
<li><a href='#emmeans'><p>Estimated marginal means (Least-squares means)</p></a></li>
<li><a href='#emmGrid-class'><p>The <code>emmGrid</code> class</p></a></li>
<li><a href='#emmip'><p>Interaction-style plots for estimated marginal means</p></a></li>
<li><a href='#emmobj'><p>Construct an <code>emmGrid</code> object from scratch</p></a></li>
<li><a href='#emtrends'><p>Estimated marginal means of linear trends</p></a></li>
<li><a href='#extending-emmeans'><p>Support functions for model extensions</p></a></li>
<li><a href='#feedlot'><p>Feedlot data</p></a></li>
<li><a href='#fiber'><p>Fiber data</p></a></li>
<li><a href='#hpd.summary'><p>Summarize an emmGrid from a Bayesian model</p></a></li>
<li><a href='#joint_tests'><p>Compute joint tests of the terms in a model</p></a></li>
<li><a href='#lsmeans'><p>Wrappers for alternative naming of EMMs</p></a></li>
<li><a href='#make.tran'><p>Response-transformation extensions</p></a></li>
<li><a href='#MOats'><p>Oats data in multivariate form</p></a></li>
<li><a href='#models'><p>Models supported in <span class="pkg">emmeans</span></p></a></li>
<li><a href='#mvcontrast'><p>Multivariate contrasts</p></a></li>
<li><a href='#neuralgia'><p>Neuralgia data</p></a></li>
<li><a href='#nutrition'><p>Nutrition data</p></a></li>
<li><a href='#oranges'><p>Sales of oranges</p></a></li>
<li><a href='#pigs'><p>Effects of dietary protein on free plasma leucine concentration in pigs</p></a></li>
<li><a href='#plot.emmGrid'><p>Plot an <code>emmGrid</code> or <code>summary_emm</code> object</p></a></li>
<li><a href='#pwpm'><p>Pairwise P-value matrix (plus other statistics)</p></a></li>
<li><a href='#pwpp'><p>Pairwise P-value plot</p></a></li>
<li><a href='#qdrg'><p>Quick and dirty reference grid</p></a></li>
<li><a href='#rbind.emmGrid'><p>Combine or subset <code>emmGrid</code> objects</p></a></li>
<li><a href='#ref_grid'><p>Create a reference grid from a fitted model</p></a></li>
<li><a href='#regrid'><p>Reconstruct a reference grid with a new transformation or simulations</p></a></li>
<li><a href='#str.emmGrid'><p>Miscellaneous methods for <code>emmGrid</code> objects</p></a></li>
<li><a href='#summary.emmGrid'><p>Summaries, predictions, intervals, and tests for <code>emmGrid</code> objects</p></a></li>
<li><a href='#ubds'><p>Unbalanced dataset</p></a></li>
<li><a href='#untidy'><p>Dare to be un-&quot;tidy&quot;!</p></a></li>
<li><a href='#update.emmGrid'><p>Update an <code>emmGrid</code> object</p></a></li>
<li><a href='#xtable.emmGrid'><p>Using <code>xtable</code> for EMMs</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Estimated Marginal Means, aka Least-Squares Means</td>
</tr>
<tr>
<td>Version:</td>
<td>1.10.3</td>
</tr>
<tr>
<td>Date:</td>
<td>2024-07-01</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 4.1.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>estimability (&ge; 1.4.1), graphics, methods, numDeriv, stats,
utils, mvtnorm</td>
</tr>
<tr>
<td>Suggests:</td>
<td>bayesplot, bayestestR, biglm, brms, car, coda (&ge; 0.17),
ggplot2, lattice, logspline, mediation, mgcv, multcomp,
multcompView, nlme, ordinal (&ge; 2014.11-12), pbkrtest (&ge;
0.4-1), lme4, lmerTest (&ge; 2.0.32), MASS, MuMIn, rsm, knitr,
rmarkdown, sandwich, scales, splines, testthat, tibble, xtable
(&ge; 1.8-2)</td>
</tr>
<tr>
<td>Enhances:</td>
<td>CARBayes, coxme, gee, geepack, MCMCglmm, MCMCpack, mice,
nnet, pscl, rstanarm, sommer, survival</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://rvlenth.github.io/emmeans/">https://rvlenth.github.io/emmeans/</a>,<a href="https://rvlenth.github.io/emmeans/">https://rvlenth.github.io/emmeans/</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/rvlenth/emmeans/issues">https://github.com/rvlenth/emmeans/issues</a></td>
</tr>
<tr>
<td>LazyData:</td>
<td>yes</td>
</tr>
<tr>
<td>ByteCompile:</td>
<td>yes</td>
</tr>
<tr>
<td>Description:</td>
<td>Obtain estimated marginal means (EMMs) for many linear, generalized 
  linear, and mixed models. Compute contrasts or linear functions of EMMs,
  trends, and comparisons of slopes. Plots and other displays.
  Least-squares means are discussed, and the term "estimated marginal means"
  is suggested, in Searle, Speed, and Milliken (1980) Population marginal means 
  in the linear model: An alternative to least squares means, The American 
  Statistician 34(4), 216-221 &lt;<a href="https://doi.org/10.1080%2F00031305.1980.10483031">doi:10.1080/00031305.1980.10483031</a>&gt;.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.1</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-07-01 16:20:28 UTC; rlenth</td>
</tr>
<tr>
<td>Author:</td>
<td>Russell V. Lenth [aut, cre, cph],
  Ben Bolker [ctb],
  Paul Buerkner [ctb],
  Iago Giné-Vázquez [ctb],
  Maxime Herve [ctb],
  Maarten Jung [ctb],
  Jonathon Love [ctb],
  Fernando Miguez [ctb],
  Julia Piaskowski [ctb],
  Hannes Riebl [ctb],
  Henrik Singmann [ctb]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Russell V. Lenth &lt;russell-lenth@uiowa.edu&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-07-01 17:50:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='emmeans-package'>Estimated marginal means (aka Least-squares means)</h2><span id='topic+emmeans-package'></span>

<h3>Description</h3>

<p>This package provides methods for obtaining estimated marginal means (EMMs, also 
known as least-squares means) for factor combinations in a variety of models.
Supported models include [generalized linear] models, models for counts,
multivariate, multinomial and ordinal responses, survival models, GEEs, and
Bayesian models. For the latter, posterior samples of EMMs are provided.
The package can compute contrasts or linear
combinations of these marginal means with various multiplicity adjustments.
One can also estimate and contrast slopes of trend lines.
Some graphical displays of these results are provided.
</p>


<h3>Overview</h3>


<dl>
<dt>Vignettes</dt><dd><p>A number of vignettes are provided to help the user get
acquainted with the <span class="pkg">emmeans</span> package and see some examples.</p>
</dd>
<dt>Concept</dt><dd><p>Estimated marginal means (see Searle <em>et al.</em> 1980 are
popular for summarizing linear models that include factors. For balanced
experimental designs, they are just the marginal means. For unbalanced data,
they in essence estimate the marginal means you <em>would</em> have observed
that the data arisen from a balanced experiment. Earlier developments
regarding these techniques were developed in a least-squares context and are
sometimes referred to as &ldquo;least-squares means&rdquo;. Since its early
development, the concept has expanded far beyond least-squares settings.</p>
</dd>
<dt>Reference grids</dt><dd><p> The implementation in <span class="pkg">emmeans</span> relies on our own
concept of a <em>reference grid</em>, which is an array of factor and predictor
levels. Predictions are made on this grid, and estimated marginal means (or
EMMs) are defined as averages of these predictions over zero or more
dimensions of the grid. The function <code><a href="#topic+ref_grid">ref_grid</a></code> explicitly
creates a reference grid that can subsequently be used to obtain
least-squares means. The object returned by <code>ref_grid</code> is of class
<code>"emmGrid"</code>, the same class as is used for estimated marginal means (see
below).
</p>
<p>Our reference-grid framework expands slightly upon Searle <em>et al.</em>'s
definitions of EMMs, in that it is possible to include multiple levels of
covariates in the grid. </p>
</dd>
<dt>Models supported</dt><dd><p>As is mentioned in the package description, many
types of models are supported by the package. 
See <a href="../doc/models.html">vignette(&quot;models&quot;, &quot;emmeans&quot;)</a> for full details. 
Some models may require other packages be
installed in order to  access all of the available features.
For models not explicitly supported, it may still be possible to do basic
post hoc analyses of them via the <code><a href="#topic+qdrg">qdrg</a></code> function.</p>
</dd>
<dt>Estimated marginal means</dt><dd>
<p>The <code><a href="#topic+emmeans">emmeans</a></code> function computes EMMs given a fitted model (or a
previously constructed <code>emmGrid</code> object), using a specification indicating
what factors to include. The <code><a href="#topic+emtrends">emtrends</a></code> function creates the same
sort of results for estimating and comparing slopes of fitted lines. Both
return an <code>emmGrid</code> object.</p>
</dd>
<dt>Summaries and analysis</dt><dd>
<p>The <code><a href="#topic+summary.emmGrid">summary.emmGrid</a></code>  method may be used to display an <code>emmGrid</code>
object. Special-purpose summaries are available via <code><a href="#topic+confint.emmGrid">confint.emmGrid</a></code> and
<code><a href="#topic+test.emmGrid">test.emmGrid</a></code>, the latter of which can also do a joint test of several
estimates. The user may specify by variables, multiplicity-adjustment
methods, confidence levels, etc., and if a transformation or link function is
involved, may reverse-transform the results to the response scale.</p>
</dd>
<dt>Contrasts and comparisons</dt><dd>
<p>The <code><a href="#topic+contrast">contrast</a></code> method for <code>emmGrid</code> objects is used to obtain
contrasts among the estimates; several standard contrast families are
available such as deviations from the mean, polynomial contrasts, and
comparisons with one or more controls. Another <code>emmGrid</code> object is returned,
which can be summarized or further analyzed. For convenience, a <code>pairs.emmGrid</code>
method is provided for the case of pairwise comparisons. 
</p>
</dd>
<dt>Graphs</dt><dd><p>The <code><a href="#topic+plot.emmGrid">plot.emmGrid</a></code> method will display
side-by-side confidence intervals for the estimates, and/or
&ldquo;comparison arrows&rdquo; whereby the *P* values of pairwise differences
can be observed by how much the arrows overlap. The <code><a href="#topic+emmip">emmip</a></code> function
displays estimates like an interaction plot, multi-paneled if there are by
variables. These graphics capabilities require the <span class="pkg">lattice</span> package be
installed.</p>
</dd>
<dt>MCMC support</dt><dd><p>When a model is fitted using MCMC methods, the posterior
chains(s) of parameter estimates are retained and converted into posterior
samples of EMMs or contrasts thereof. These may then be summarized or plotted
like any other MCMC results, using tools in, say <span class="pkg">coda</span> or
<span class="pkg">bayesplot</span>.</p>
</dd>
<dt><span class="pkg">multcomp</span> interface</dt><dd><p>The <code><a href="#topic+as.glht">as.glht</a></code> function and
<code>glht</code> method for <code>emmGrid</code>s provide an interface to the
<code>glht</code> function in the <span class="pkg">multcomp</span> package, thus
providing for more exacting simultaneous estimation or testing. The package
also provides an <code><a href="#topic+emm">emm</a></code> function that works as an alternative to
<code>mcp</code> in a call to <code>glht</code>.
</p>
</dd>
</dl>
 

<hr>
<h2 id='as.list.emmGrid'>Convert to and from <code>emmGrid</code> objects</h2><span id='topic+as.list.emmGrid'></span><span id='topic+as.emm_list'></span><span id='topic+as.emmGrid'></span>

<h3>Description</h3>

<p>These are useful utility functions for creating a compact version of an
<code>emmGrid</code> object that may be saved and later reconstructed, or for
converting old <code>ref.grid</code> or <code>lsmobj</code> objects into <code>emmGrid</code>
objects.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'emmGrid'
as.list(x, model.info.slot = FALSE, ...)

as.emm_list(object, ...)

as.emmGrid(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="as.list.emmGrid_+3A_x">x</code></td>
<td>
<p>An <code>emmGrid</code> object</p>
</td></tr>
<tr><td><code id="as.list.emmGrid_+3A_model.info.slot">model.info.slot</code></td>
<td>
<p>Logical value: Include the <code>model.info</code> slot?
Set this to <code>TRUE</code> if you want to preserve the original call and 
information needed by the <code>submodel</code> option.
If <code>FALSE</code>, only the nesting information (if any) is saved</p>
</td></tr>
<tr><td><code id="as.list.emmGrid_+3A_...">...</code></td>
<td>
<p>In <code>as.emmGrid</code>, additional arguments passed to 
<code><a href="#topic+update.emmGrid">update.emmGrid</a></code> before returning the object. This
argument is ignored in <code>as.list.emmGrid</code></p>
</td></tr>
<tr><td><code id="as.list.emmGrid_+3A_object">object</code></td>
<td>
<p>Object to be converted to class <code>emmGrid</code>. It may
be a <code>list</code> returned by <code>as.list.emmGrid</code>, or a <code>ref.grid</code>
or <code>lsmobj</code> object created by <span class="pkg">emmeans</span>'s predecessor, the 
<span class="pkg">lsmeans</span> package. An error is thrown if <code>object</code> cannot
be converted.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>An <code>emmGrid</code> object is an S4 object, and as such cannot be saved in a
text format or saved without a lot of overhead. By using <code>as.list</code>,
the essential parts of the object are converted to a list format that can be
easily and compactly saved for use, say, in another session or by another user.
Providing this list as the arguments for <code><a href="#topic+emmobj">emmobj</a></code> allows the user 
to restore a working <code>emmGrid</code> object.
</p>


<h3>Value</h3>

<p><code>as.list.emmGrid</code> returns an object of class <code>list</code>.
</p>
<p><code>as.emm_list</code> returns an object of class <code>emm_list</code>.
</p>
<p><code>as.emmGrid</code> returns an object of class <code>emmGrid</code>. 
However, in fact, both <code>as.emmGrid</code> and <code>as.emm_list</code> check for an
attribute in <code>object</code> to decide whether to return an <code>emmGrid</code> 
or <code>emm_list)</code> object.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+emmobj">emmobj</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>pigs.lm &lt;- lm(log(conc) ~ source + factor(percent), data = pigs)
pigs.sav &lt;- as.list(ref_grid(pigs.lm))

pigs.anew &lt;- as.emmGrid(pigs.sav)
emmeans(pigs.anew, "source")
</code></pre>

<hr>
<h2 id='as.mcmc.emmGrid'>Support for MCMC-based estimation</h2><span id='topic+as.mcmc.emmGrid'></span><span id='topic+mcmc-support'></span><span id='topic+as.mcmc.emm_list'></span><span id='topic+as.mcmc.list.emmGrid'></span><span id='topic+as.mcmc.list.emm_list'></span>

<h3>Description</h3>

<p>When a model is fitted using Markov chain Monte Carlo (MCMC) methods, 
its reference grid contains a <code>post.beta</code> slot. These functions 
transform those posterior samples to posterior samples of EMMs or
related contrasts. They can then be summarized or plotted using,
e.g., functions in the <span class="pkg">coda</span> package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'emmGrid'
as.mcmc(x, names = TRUE, sep.chains = TRUE, likelihood,
  NE.include = FALSE, ...)

## S3 method for class 'emm_list'
as.mcmc(x, which = 1, ...)

## S3 method for class 'emmGrid'
as.mcmc.list(x, names = TRUE, ...)

## S3 method for class 'emm_list'
as.mcmc.list(x, which = 1, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="as.mcmc.emmGrid_+3A_x">x</code></td>
<td>
<p>An object of class <code>emmGrid</code></p>
</td></tr>
<tr><td><code id="as.mcmc.emmGrid_+3A_names">names</code></td>
<td>
<p>Logical scalar or vector specifying whether variable names are
appended to levels in the column labels for the <code>as.mcmc</code> or
<code>as.mcmc.list</code> result &ndash; e.g., column names of <code>treat A</code> and
<code>treat B</code> versus  just <code>A</code> and <code>B</code>. When there is more than
one variable involved, the elements of <code>names</code> are used cyclically.</p>
</td></tr>
<tr><td><code id="as.mcmc.emmGrid_+3A_sep.chains">sep.chains</code></td>
<td>
<p>Logical value. If <code>TRUE</code>, and there is more than one
MCMC chain available, an <code><a href="coda.html#topic+mcmc.list">mcmc.list</a></code> object is returned
by <code>as.mcmc</code>, with separate EMMs posteriors in each chain.</p>
</td></tr>
<tr><td><code id="as.mcmc.emmGrid_+3A_likelihood">likelihood</code></td>
<td>
<p>Character value or function. If given, simulations are made from 
the corresponding posterior predictive distribution. If not given, we obtain
the posterior distribution of the parameters in <code>object</code>. See Prediction
section below.</p>
</td></tr>
<tr><td><code id="as.mcmc.emmGrid_+3A_ne.include">NE.include</code></td>
<td>
<p>Logical value. If <code>TRUE</code>, non-estimable columns are
kept but returned as columns of <code>NA</code> values (this may create errors or
warnings in subsequent analyses using, say, <span class="pkg">coda</span>). If <code>FALSE</code>,
non-estimable columns are dropped, and a warning is issued. (If all are
non-estimable, an error is thrown.)</p>
</td></tr>
<tr><td><code id="as.mcmc.emmGrid_+3A_...">...</code></td>
<td>
<p>arguments passed to other methods</p>
</td></tr>
<tr><td><code id="as.mcmc.emmGrid_+3A_which">which</code></td>
<td>
<p>item in the <code>emm_list</code> to use</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code><a href="coda.html#topic+mcmc">mcmc</a></code> or <code><a href="coda.html#topic+mcmc.list">mcmc.list</a></code>.
</p>


<h3>Details</h3>

<p>When the object's <code>post.beta</code> slot is non-trivial, <code>as.mcmc</code> will
return an <code><a href="coda.html#topic+mcmc">mcmc</a></code> or <code><a href="coda.html#topic+mcmc.list">mcmc.list</a></code> object
that can be summarized or plotted using methods in the <span class="pkg">coda</span> package.
In these functions, <code>post.beta</code> is transformed by post-multiplying it by
<code>t(linfct)</code>, creating a sample from the posterior distribution of LS
means. In <code>as.mcmc</code>, if <code>sep.chains</code> is <code>TRUE</code> and there is in
fact more than one chain, an <code>mcmc.list</code> is returned with each chain's
results. The <code>as.mcmc.list</code> method is guaranteed to return an
<code>mcmc.list</code>, even if it comprises just one chain.
</p>


<h3>Prediction</h3>

<p>When <code>likelihood</code> is specified, it is used to simulate values from the
posterior predictive distribution corresponding to the given likelihood and
the posterior distribution of parameter values. Denote the likelihood 
function as <code class="reqn">f(y|\theta,\phi)</code>, where <code class="reqn">y</code> is a response, <code class="reqn">\theta</code>
is the parameter estimated in <code>object</code>, and <code class="reqn">\phi</code> comprises zero or
more additional parameters to be specified. If <code>likelihood</code> is a 
function, that function should take as its first argument a vector of 
<code class="reqn">\theta</code> values (each corresponding to one row of <code>object@grid</code>).
Any <code class="reqn">\phi</code> values should be specified as additional named function
arguments, and passed to <code>likelihood</code> via <code>...</code>. This function should 
simulate values of <code class="reqn">y</code>.
</p>
<p>A few standard likelihoods are available by specifying <code>likelihood</code> as
a character value. They are:
</p>

<dl>
<dt><code>"normal"</code></dt><dd><p>The normal distribution with mean <code class="reqn">\theta</code> and
standard deviation specified by additional argument <code>sigma</code></p>
</dd>
<dt><code>"binomial"</code></dt><dd><p>The binomial distribution with success probability 
<code class="reqn">theta</code>, and number of trials specified by <code>trials</code></p>
</dd>
<dt><code>"poisson"</code></dt><dd><p>The Poisson distribution with mean <code class="reqn">theta</code> 
(no additional parameters)</p>
</dd>
<dt><code>"gamma"</code></dt><dd><p>The gamma distribution with scale parameter <code class="reqn">\theta</code>
and shape parameter specified by <code>shape</code></p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>if(requireNamespace("coda")) 
    emm_example("as.mcmc-coda")
    # Use emm_example("as.mcmc-coda", list = TRUE) # to see just the code
    
</code></pre>

<hr>
<h2 id='auto.noise'>Auto Pollution Filter Noise</h2><span id='topic+auto.noise'></span>

<h3>Description</h3>

<p>Three-factor experiment comparing pollution-filter noise for two filters,
three sizes of cars, and two sides of the car.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>auto.noise
</code></pre>


<h3>Format</h3>

<p>A data frame with 36 observations on the following 4 variables.
</p>

<dl>
<dt><code>noise</code></dt><dd><p>Noise level in decibels (but see note) - a numeric vector.</p>
</dd>
<dt><code>size</code></dt><dd><p>The size of the vehicle - an ordered factor with
levels <code>S</code>, <code>M</code>, <code>L</code>.</p>
</dd>
<dt><code>type</code></dt><dd><p>Type of anti-pollution filter - a factor with levels
<code>Std</code> and <code>Octel</code></p>
</dd>
<dt><code>side</code></dt><dd><p>The side of the car where measurement was taken &ndash; a
factor with levels <code>L</code> and <code>R</code>.</p>
</dd>
</dl>



<h3>Details</h3>

<p>The data are from a statement by Texaco, Inc., to the Air and Water Pollution
Subcommittee of the Senate Public Works Committee on June 26, 1973.    
Mr. John McKinley, President of Texaco, cited an automobile filter developed
by Associated Octel Company as effective in reducing pollution. However, 
questions had been raised about the effects of filters on vehicle performance, 
fuel consumption, exhaust gas back pressure, and silencing. On the last 
question, he referred to the data included here as evidence that the silencing
properties of the Octel filter were at least equal to those of standard silencers.
</p>


<h3>Note</h3>

<p>While the data source claims that <code>noise</code> is measured in decibels,
the values are implausible. I believe that these measurements are actually
in tenths of dB (centibels?). Looking at the values in the dataset, note 
that every measurement ends in 0 or 5, and it is reasonable to believe that
measurements are accurate to the nearest half of a decibel.

</p>


<h3>Source</h3>

<p>The dataset was obtained from the Data and Story Library (DASL)
at Carnegie-Mellon University. Apparently it has since been removed. The
original dataset was altered by assigning meaningful names to the factors
and sorting the observations in random order as if this were the run order
of the experiment.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># (Based on belief that noise/10 is in decibel units)
noise.lm &lt;- lm(noise/10 ~ size * type * side, data = auto.noise)

# Interaction plot of predictions
emmip(noise.lm, type ~ size | side)

# Confidence intervals
plot(emmeans(noise.lm, ~ size | side*type))

</code></pre>

<hr>
<h2 id='cld.emmGrid'>Compact letter displays</h2><span id='topic+cld.emmGrid'></span><span id='topic+cld.emm_list'></span>

<h3>Description</h3>

<p>A method for <code>multcomp::cld()</code> is provided for users desiring to produce 
compact-letter displays (CLDs). 
This method uses the Piepho (2004) algorithm (as implemented in the
<span class="pkg">multcompView</span> package) to generate a compact letter display of all
pairwise comparisons of estimated marginal means. The function obtains (possibly
adjusted) P values for all pairwise comparisons of means, using the
<code><a href="#topic+contrast">contrast</a></code> function with <code>method = "pairwise"</code>. When a P
value exceeds <code>alpha</code>, then the two means have at least one letter in
common.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'emmGrid'
cld(object, details = FALSE, sort = TRUE, by,
  alpha = 0.05, Letters = c("1234567890", LETTERS, letters),
  reversed = decreasing, decreasing = FALSE, signif.sets = FALSE,
  delta = 0, ...)

## S3 method for class 'emm_list'
cld(object, ..., which = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cld.emmGrid_+3A_object">object</code></td>
<td>
<p>An object of class <code>emmGrid</code></p>
</td></tr>
<tr><td><code id="cld.emmGrid_+3A_details">details</code></td>
<td>
<p>Logical value determining whether detailed information on tests of
pairwise comparisons is displayed</p>
</td></tr>
<tr><td><code id="cld.emmGrid_+3A_sort">sort</code></td>
<td>
<p>Logical value determining whether the EMMs are sorted before the comparisons
are produced. When <code>TRUE</code>, the results are displayed according to
<code>reversed</code>.</p>
</td></tr>
<tr><td><code id="cld.emmGrid_+3A_by">by</code></td>
<td>
<p>Character value giving the name or names of variables by which separate
families of comparisons are tested. If NULL, all means are compared.
If missing, the object's <code>by.vars</code> setting, if any, is used.</p>
</td></tr>
<tr><td><code id="cld.emmGrid_+3A_alpha">alpha</code></td>
<td>
<p>Numeric value giving the significance level for the comparisons</p>
</td></tr>
<tr><td><code id="cld.emmGrid_+3A_letters">Letters</code></td>
<td>
<p>Character vector of letters to use in the display. Any strings of
length greater than 1 are expanded into individual characters</p>
</td></tr>
<tr><td><code id="cld.emmGrid_+3A_reversed">reversed</code>, <code id="cld.emmGrid_+3A_decreasing">decreasing</code></td>
<td>
<p>Logical value (passed to <code>multcompView::multcompLetters</code>.)
If <code>TRUE</code>, the order of use of the letters is reversed.
Either <code>reversed</code> or <code>decreasing</code> may be specified, thus providing
compatibility with both <code>multcompView::multcompLetters(..., reversed, ...)</code> and
<code>multcomp::cld(..., decreasing, ...)</code>.
In addition, if both <code>sort</code> and <code>reversed</code> are TRUE, the sort
order of results is reversed.</p>
</td></tr>
<tr><td><code id="cld.emmGrid_+3A_signif.sets">signif.sets</code></td>
<td>
<p>Logical value. If <code>FALSE</code> (and <code>delta = 0</code>), a 
&lsquo;traditional&rsquo;
compact-letter display is constructed with groupings representing sets of
estimates that are not statistically different. If <code>TRUE</code>, the criteria
are reversed so that two estimates sharing the same symbol test as significantly
different. See also <code>delta</code>.</p>
</td></tr>
<tr><td><code id="cld.emmGrid_+3A_delta">delta</code></td>
<td>
<p>Numeric value passed to <code><a href="#topic+test.emmGrid">test.emmGrid</a></code>. If this
is positive, it is used as an equivalence threshold in the TOST procedure for
two-sided equivalence testing. In the resulting compact letter display,
two estimates share the same grouping letter only if they are found to be
statistically equivalent &ndash; that is, groupings reflect actual <em>findings</em>
of equivalence rather than failure to find a significant difference.
When <code>delta</code> is nonzero, <code>signif.sets</code> is ignored.</p>
</td></tr>
<tr><td><code id="cld.emmGrid_+3A_...">...</code></td>
<td>
<p>Arguments passed to <code><a href="#topic+contrast">contrast</a></code> (for example,
an <code>adjust</code> method)</p>
</td></tr>
<tr><td><code id="cld.emmGrid_+3A_which">which</code></td>
<td>
<p>Which element of the <code>emm_list</code> object to process
(If length exceeds one, only the first one is used)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code><a href="#topic+summary.emmGrid">summary_emm</a></code> object showing the estimated marginal means
plus an additional column labeled <code>.group</code> (when <code>signif.sets = FALSE</code>), 
<code>.signif.set</code> (when <code>signif.sets = TRUE</code>), or <code>.equiv.set</code> 
(when <code>delta &gt; 0</code>).
</p>


<h3>Note</h3>

<p>We warn that the default display encourages a poor
practice in interpreting significance tests. Such CLDs are misleading because they
visually group means with comparisons <em>P</em> &gt; <code>alpha</code> as though they 
are equal, when in fact we have only failed to prove that they differ.
A better alternative if one wants to show groupings is to specify an equivalence
threshold <code>delta</code>; then groupings will be based on actual findings of
equivalence. Another way to display actual findings is to set
<code>signif.sets = TRUE</code>, so that estimates in the same group are those 
found to be statistically <em>different</em>. Obviously, these different options
require different interpretations of the results; the annotations and the label
given the final column help guide how to assess the results.
</p>
<p>As further alternatives, consider <code><a href="#topic+pwpp">pwpp</a></code> (graphical display of <em>P</em> 
values) or <code><a href="#topic+pwpm">pwpm</a></code> (matrix display).
</p>


<h3>References</h3>

<p>Piepho, Hans-Peter (2004) An algorithm for a letter-based 
representation of all pairwise comparisons, 
Journal of Computational and Graphical Statistics, 
13(2), 456-466.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if(requireNamespace("multcomp"))
    emm_example("cld-multcomp")
    # Use emm_example("cld-multcomp", list = TRUE) # to just list the code

</code></pre>

<hr>
<h2 id='comb_facs'>Manipulate factors in a reference grid</h2><span id='topic+comb_facs'></span><span id='topic+split_fac'></span><span id='topic+add_grouping'></span><span id='topic+permute_levels'></span>

<h3>Description</h3>

<p>These functions manipulate the levels of factors comprising a reference
grid by combining factor levels, splitting a factor's levels into 
combinations of newly-defined factors, creating a grouping factor in which 
factor(s) levels are nested, or permuting the order of levels of a factor
</p>


<h3>Usage</h3>

<pre><code class='language-R'>comb_facs(object, facs, newname = paste(facs, collapse = "."),
  drop = FALSE, ...)

split_fac(object, fac, newfacs, ...)

add_grouping(object, newname, refname, newlevs, ...)

permute_levels(object, fac, pos)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="comb_facs_+3A_object">object</code></td>
<td>
<p>An object of class <code>emmGrid</code></p>
</td></tr>
<tr><td><code id="comb_facs_+3A_facs">facs</code></td>
<td>
<p>Character vector. The names of the factors to combine</p>
</td></tr>
<tr><td><code id="comb_facs_+3A_newname">newname</code></td>
<td>
<p>Character name of grouping factor to add (different from any
existing factor in the grid)</p>
</td></tr>
<tr><td><code id="comb_facs_+3A_drop">drop</code></td>
<td>
<p>Logical value. If <code>TRUE</code>, any levels of the new factor that 
are dropped if all occurrences in the newly reconstructed object have 
weight zero. If <code>FALSE</code>, all levels are retained. 
(This argument is ignored if there is no <code>.wgt.</code> column
in <code>object@grid</code>.)</p>
</td></tr>
<tr><td><code id="comb_facs_+3A_...">...</code></td>
<td>
<p>arguments passed to other methods</p>
</td></tr>
<tr><td><code id="comb_facs_+3A_fac">fac</code></td>
<td>
<p>The name of a factor that is part of the grid in <code>object</code></p>
</td></tr>
<tr><td><code id="comb_facs_+3A_newfacs">newfacs</code></td>
<td>
<p>A named list with the names of new factors
and their levels. The names must not already exist in the object,
and the product of the lengths of the levels must equal the number
of levels of <code>fac</code>.</p>
</td></tr>
<tr><td><code id="comb_facs_+3A_refname">refname</code></td>
<td>
<p>Character name(s) of the reference factor(s)</p>
</td></tr>
<tr><td><code id="comb_facs_+3A_newlevs">newlevs</code></td>
<td>
<p>Character vector or factor of the same length as that of the (combined) levels for 
<code>refname</code>. The grouping factor <code>newname</code> will have the unique
values of <code>newlevs</code> as its levels. The order of levels in <code>newlevs</code>
is the same as the order of the level combinations produced by 
<code><a href="base.html#topic+expand.grid">expand.grid</a></code> applied to the levels of <code>refname</code> &ndash; that is, the
first factor's levels change the fastest and the last one's vary the slowest.</p>
</td></tr>
<tr><td><code id="comb_facs_+3A_pos">pos</code></td>
<td>
<p>Integer vector consisting of some permutation of the sequence
<code>1:k</code>, where <code>k</code> is the number of levels of <code>fac</code>.
This determines which position each level of <code>fac</code> will occupy
after the levels are permuted; thus, if the
levels of <code>fac</code> are <code>A,B,C,D</code>, and <code>pos = c(3,1,2,4)</code>, 
then the permuted levels will be <code>B,C,A,D</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A modified object of class <code>emmGrid</code>
</p>


<h3>The <code>comb_facs</code> function</h3>

<p><code>comb_facs</code> combines the levels of factors into a single factor
in the reference grid (similar to <code><a href="base.html#topic+interaction">interaction</a></code>). This new factor
replaces the factors that comprise it.
</p>
<p><em>Additional note:</em>
The choice of whether to drop levels or not can make a profound difference.
If the goal is to combine factors for use in <code>joint_tests</code>, we advise <em>against</em> 
<code>drop = TRUE</code> because that might change the weights used in deriving marginal means.
If combining factors in a nested structure, dropping unused cases can considerably reduce 
the storage required.
</p>


<h3>The <code>split_fac</code> function</h3>

<p>The levels in <code>newfacs</code> are expanded via <code><a href="base.html#topic+expand.grid">expand.grid</a></code> into
combinations of levels, and the factor <code>fac</code> is replaced by those 
factor combinations. Unlike <code>add_grouping</code>, this creates a crossed, 
rather than a nested structure. Note that the order of factor combinations
is systematic with the levels of first factor in <code>newfacs</code> varying 
the fastest; and those factor combinations are assigned respectively
to the levels of <code>fac</code> as displayed in <code>str(object)</code>.
</p>


<h3>The <code>add_grouping</code> function</h3>

<p>This function adds a grouping factor to an existing reference grid or other 
<code>emmGrid</code> object, such that the levels of one or more existing factors (call them the
reference factors) are mapped to a smaller number of levels of the new
grouping factor. The reference factors are then nested in a 
new grouping factor named <code>newname</code>, and a new nesting structure
<code>refname %in% newname</code>.
This facilitates obtaining marginal means of the grouping factor, and 
contrasts thereof.
</p>
<p><em>Additional notes:</em> By default, the levels of <code>newname</code> will be ordered
alphabetically. To dictate a different ordering of levels, supply 
<code>newlevs</code> as a <code>factor</code> having its levels in the desired order.
</p>
<p>When <code>refname</code> specifies more than one factor, this can
fundamentally (and permanently) change what is meant by the levels of those
individual factors. For instance, in the <code>gwrg</code> example below, there
are two levels of <code>wool</code> nested in each <code>prod</code>; and that implies
that we now regard these as four different kinds of wool. Similarly, there
are five different tensions (L, M, H in prod 1, and L, M in prod 2).
</p>


<h3>The <code>permute_levels</code> function</h3>

<p>This function permutes the levels of <code>fac</code>. The returned object
has the same factors, same <code>by</code> variables, but with the levels
of <code>fac</code> permuted. 
The order of the columns in <code>object@grid</code> may be altered.
</p>
<p>NOTE: <code>fac</code> must not be nested in another factor. <code>permute_levels</code> 
throws an error when <code>fac</code> is nested.
</p>
<p>NOTE: Permuting the levels of a numeric predictor is tricky. For example,
if you want to display the new ordering of levels in <code>emmip()</code>,
you must add the arguments <code>style = "factor"</code> and <code>nesting.order = TRUE</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>mtcars.lm &lt;- lm(mpg ~ factor(vs)+factor(cyl)*factor(gear), data = mtcars)
(v.c.g &lt;- ref_grid(mtcars.lm))
(v.cg &lt;- comb_facs(v.c.g, c("cyl", "gear")))
  
# One use is obtaining a single test for the joint contributions of two factors:
joint_tests(v.c.g)

joint_tests(v.cg)

# undo the 'comb_facs' operation:
split_fac(v.cg, "cyl.gear", list(cyl = c(4, 6, 8), gear = 3:5))

IS.glm &lt;- glm(count ~ spray, data = InsectSprays, family = poisson)
IS.emm &lt;- emmeans(IS.glm, "spray")
IS.new &lt;- split_fac(IS.emm, "spray", list(A = 1:2, B = c("low", "med", "hi")))
str(IS.new)

fiber.lm &lt;- lm(strength ~ diameter + machine, data = fiber)
( frg &lt;- ref_grid(fiber.lm) )

# Suppose the machines are two different brands
brands &lt;- factor(c("FiberPro", "FiberPro", "Acme"), levels = c("FiberPro", "Acme"))
( gfrg &lt;- add_grouping(frg, "brand", "machine", brands) )

emmeans(gfrg, "machine")

emmeans(gfrg, "brand")

### More than one reference factor
warp.lm &lt;- lm(breaks ~ wool * tension, data = warpbreaks)
gwrg &lt;- add_grouping(ref_grid(warp.lm), 
    "prod",  c("tension", "wool"),  c(2, 1, 1,  1, 2, 1))
        # level combinations:         LA MA HA  LB MB HB

emmeans(gwrg, ~ wool * tension)   # some NAs due to impossible combinations

emmeans(gwrg, "prod")

str(v.c.g)
str(permute_levels(v.c.g, "cyl", c(2,3,1)))

</code></pre>

<hr>
<h2 id='contrast'>Contrasts and linear functions of EMMs</h2><span id='topic+contrast'></span><span id='topic+contrast.emmGrid'></span><span id='topic+pairs.emmGrid'></span><span id='topic+coef.emmGrid'></span><span id='topic+weights.emmGrid'></span>

<h3>Description</h3>

<p>These methods provide for follow-up analyses of <code>emmGrid</code> objects:
Contrasts, pairwise comparisons, tests, and confidence intervals. They may
also be used to compute arbitrary linear functions of predictions or EMMs.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>contrast(object, ...)

## S3 method for class 'emmGrid'
contrast(object, method = "eff", interaction = FALSE, by,
  offset = NULL, scale = NULL, name = "contrast",
  options = get_emm_option("contrast"), type, adjust, simple,
  combine = FALSE, ratios = TRUE, parens, enhance.levels = TRUE, wts,
  ...)

## S3 method for class 'emmGrid'
pairs(x, reverse = FALSE, ...)

## S3 method for class 'emmGrid'
coef(object, ...)

## S3 method for class 'emmGrid'
weights(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="contrast_+3A_object">object</code></td>
<td>
<p>An object of class <code>emmGrid</code></p>
</td></tr>
<tr><td><code id="contrast_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to other methods</p>
</td></tr>
<tr><td><code id="contrast_+3A_method">method</code></td>
<td>
<p>Character value giving the root name of a contrast method (e.g.
<code>"pairwise"</code> &ndash; see <a href="#topic+emmc-functions">emmc-functions</a>). Alternatively, a function
of the same form, or a named <code>list</code> of coefficients (for a contrast or
linear function) that must each conform to the number of results in each
<code>by</code> group. In a multi-factor situation, the factor levels are
combined and treated like a single factor.</p>
</td></tr>
<tr><td><code id="contrast_+3A_interaction">interaction</code></td>
<td>
<p>Character vector, logical value, or list. If this is specified,
<code>method</code> is ignored. See the &ldquo;Interaction contrasts&rdquo; section
below for details.</p>
</td></tr>
<tr><td><code id="contrast_+3A_by">by</code></td>
<td>
<p>Character names of variable(s) to be used for &ldquo;by&rdquo; groups. The
contrasts or joint tests will be evaluated separately for each combination
of these variables. If <code>object</code> was created with by groups, those are
used unless overridden. Use <code>by = NULL</code> to use no by groups at all.</p>
</td></tr>
<tr><td><code id="contrast_+3A_offset">offset</code>, <code id="contrast_+3A_scale">scale</code></td>
<td>
<p>Numeric vectors of the same length as each <code>by</code> group.
The <code>scale</code> values, if supplied, multiply their respective linear estimates, and
any <code>offset</code> values are added. Scalar values are also allowed. 
(These arguments are ignored when <code>interaction</code> is specified.)</p>
</td></tr>
<tr><td><code id="contrast_+3A_name">name</code></td>
<td>
<p>Character name to use to override the default label for contrasts
used in table headings or subsequent contrasts of the returned object.</p>
</td></tr>
<tr><td><code id="contrast_+3A_options">options</code></td>
<td>
<p>If non-<code>NULL</code>, a named <code>list</code> of arguments to pass
to <code><a href="#topic+update.emmGrid">update.emmGrid</a></code>, just after the object is constructed.</p>
</td></tr>
<tr><td><code id="contrast_+3A_type">type</code></td>
<td>
<p>Character: prediction type (e.g., <code>"response"</code>) &ndash; added to
<code>options</code></p>
</td></tr>
<tr><td><code id="contrast_+3A_adjust">adjust</code></td>
<td>
<p>Character: adjustment method (e.g., <code>"bonferroni"</code>) &ndash;
added to <code>options</code></p>
</td></tr>
<tr><td><code id="contrast_+3A_simple">simple</code></td>
<td>
<p>Character vector or list: Specify the factor(s) <em>not</em> in
<code>by</code>, or a list thereof. See the section below on simple contrasts.</p>
</td></tr>
<tr><td><code id="contrast_+3A_combine">combine</code></td>
<td>
<p>Logical value that determines what is returned when
<code>simple</code> is a list. See the section on simple contrasts.</p>
</td></tr>
<tr><td><code id="contrast_+3A_ratios">ratios</code></td>
<td>
<p>Logical value determining how log and logit transforms are
handled. These transformations are exceptional cases in that there is a
valid way to back-transform contrasts: differences of logs are logs of
ratios, and differences of logits are odds ratios. If <code>ratios = TRUE</code>
and summarized with <code>type = "response"</code>, <code>contrast</code> results are
back-transformed to ratios whenever we have true contrasts (coefficients
sum to zero). For other transformations, there is no natural way to
back-transform contrasts, so even when summarized with <code>type = "response"</code>,
contrasts are computed and displayed on the linear-predictor scale. Similarly, 
if <code>ratios = FALSE</code>, log and logit transforms are treated in the same way as
any other transformation.</p>
</td></tr>
<tr><td><code id="contrast_+3A_parens">parens</code></td>
<td>
<p>character or <code>NULL</code>. If a character value, the labels for levels
being contrasted are parenthesized if they match the regular expression in 
<code>parens[1]</code> (via <code><a href="base.html#topic+grep">grep</a></code>). The default is <code>emm_option("parens")</code>.
Optionally, <code>parens</code> may contain second and third elements specifying
what to use for left and right parentheses (default <code>"("</code> and <code>")"</code>).
Specify <code>parens = NULL</code> or <code>parens = "a^"</code> (which won't match anything)
to disable all parenthesization.</p>
</td></tr>
<tr><td><code id="contrast_+3A_enhance.levels">enhance.levels</code></td>
<td>
<p>character or logical. 
If character, the levels of the named factors that are contrasted are enhanced 
by appending the name of the factor; e.g., if a factor named <code>"trt"</code> has
levels <code>A</code> and <code>B</code>, a <code>trt</code> comparison is labeled <code>trtA - trtB</code>.
If <code>enhance.levels</code> is logical, then if <code>TRUE</code> (the default), 
only factors with numeric levels are enhanced; and of
course if <code>FALSE</code>, no levels are enhanced.
The levels of <code>by</code> variables are not enhanced, and any 
names of factors that don't exist are silently ignored. 
To enhance the labels beyond what is done here, change them
directly via <code><a href="#topic+update.emmGrid">levels&lt;-</a></code>.</p>
</td></tr>
<tr><td><code id="contrast_+3A_wts">wts</code></td>
<td>
<p>The <code>wts</code> argument for some contrast methods. You should omit
this argument unless you want unequal <code>wts</code>. Otherwise we recommend
specifying <code>wts = NA</code> which instructs that <code>wts</code> be obtained from
<code>object</code>, <em>separately</em> for each <code>by</code> group. If numerical
<code>wts</code> are specified, they must
conform to the number of levels in each <code>by</code> group, and those same weights
are used in each group.</p>
</td></tr>
<tr><td><code id="contrast_+3A_x">x</code></td>
<td>
<p>An <code>emmGrid</code> object</p>
</td></tr>
<tr><td><code id="contrast_+3A_reverse">reverse</code></td>
<td>
<p>Logical value - determines whether to use <code>"pairwise"</code> (if <code>TRUE</code>) or <code>"revpairwise"</code> (if <code>FALSE</code>).</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>contrast</code> and <code>pairs</code> return an object of class
<code>emmGrid</code>. Its grid will correspond to the levels of the contrasts and
any <code>by</code> variables. The exception is that an <code><a href="#topic+emm_list">emm_list</a></code>
object is returned if <code>simple</code> is a list and <code>combine</code> is
<code>FALSE</code>.
</p>
<p><code>coef</code> returns a <code>data.frame</code> containing the &quot;parent&quot; object's grid, 
along with columns named <code>c.1, c.2, ...</code> containing the contrast coefficients
used to produce the linear functions embodied in the object. <code>coef()</code> only
returns coefficients if <code>object</code> is the result of a call to <code>contrast()</code>,
and the parent object is the object that was handed to <code>contrast</code>. This
is most useful for understanding interaction contrasts.
</p>
<p><code>weights</code> returns the weights stored for each row of <code>object</code>,
or a vector of 1s if no weights are saved.
</p>


<h3>Pairs method</h3>

<p>The call <code>pairs(object)</code> is equivalent to
<code>contrast(object, method = "pairwise")</code>; and <code>pairs(object,
  reverse = TRUE)</code> is the same as <code>contrast(object, method =
  "revpairwise")</code>.
</p>


<h3>Interaction contrasts</h3>

<p>When <code>interaction</code> is specified,
interaction contrasts are computed. Specifically contrasts are generated
for each factor separately, one at a time; and these contrasts are applied
to the object (the first time around) or to the previous result
(subsequently). (Any factors specified in <code>by</code> are skipped.) The final
result comprises contrasts of contrasts, or, equivalently, products of
contrasts for the factors involved. Any named elements of <code>interaction</code>
are assigned to contrast methods; others are assigned in order of
appearance in <code>object@levels</code>. The contrast factors in the resulting 
<code>emmGrid</code> object are ordered the same as in <code>interaction</code>.
</p>
<p><code>interaction</code> may be a character vector or list of valid contrast
methods (as documented for the <code>method</code> argument). If the vector or
list is shorter than the number needed, it is recycled. Alternatively, if
the user specifies <code>contrast = TRUE</code>, the contrast specified in
<code>method</code> is used for all factors involved.
</p>


<h3>Simple contrasts</h3>

<p><code>simple</code> is essentially the complement of <code>by</code>: When
<code>simple</code> is a character vector, <code>by</code> is set to all the factors in
the grid <em>except</em> those in <code>simple</code>. If <code>simple</code> is a list,
each element is used in turn as <code>simple</code>, and assembled in an
<code>"emm_list"</code>. To generate <em>all</em> simple main effects, use
<code>simple = "each"</code> (this works unless there actually is a factor named
<code>"each"</code>). Note that a non-missing <code>simple</code> will cause <code>by</code>
to be ignored.
</p>
<p>Ordinarily, when <code>simple</code> is a list or <code>"each"</code>, the return value
is an <code><a href="#topic+emm_list">emm_list</a></code> object with each entry in correspondence with
the entries of <code>simple</code>. However, with <code>combine = TRUE</code>, the
elements are all combined into one family of contrasts in a single
<code><a href="#topic+emmGrid-class">emmGrid</a></code> object using
<code><a href="#topic+rbind.emmGrid">rbind.emmGrid</a></code>.. In that case, the <code>adjust</code> argument sets
the adjustment method for the combined set of contrasts.
</p>


<h3>Note</h3>

<p>When <code>object</code> has a nesting structure (this can be seen via
<code>str(object)</code>), then any grouping factors involved are forced into
service as <code>by</code> variables, and the contrasts are thus computed
separately in each nest. This in turn may lead to an irregular grid in the
returned <code>emmGrid</code> object, which may not be valid for subsequent
<code>emmeans</code> calls.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>warp.lm &lt;- lm(breaks ~ wool*tension, data = warpbreaks)
(warp.emm &lt;- emmeans(warp.lm, ~ tension | wool))

contrast(warp.emm, "poly")    # inherits 'by = "wool"' from warp.emm

### Custom contrast coefs (we already have wool as 'by' thus 3 means to contrast)
contrast(warp.emm, list(mid.vs.ends = c(-1,2,-1)/2, lo.vs.hi = c(1,0,-1)))

pairs(warp.emm)

# Effects (dev from mean) of the 6 factor combs, with enhanced levels:
contrast(warp.emm, "eff", by = NULL, 
    enhance.levels = c("wool", "tension"))  
    
pairs(warp.emm, simple = "wool") # same as pairs(warp.emm, by = "tension")

# Do all "simple" comparisons, combined into one family
pairs(warp.emm, simple = "each", combine = TRUE)

## Not run: 

## Note that the following are NOT the same:
contrast(warp.emm, simple = c("wool", "tension"))
contrast(warp.emm, simple = list("wool", "tension"))
## The first generates contrasts for combinations of wool and tension
##   (same as by = NULL)
## The second generates contrasts for wool by tension, and for 
##   tension by wool, respectively.

## End(Not run)

# An interaction contrast for tension:wool
tw.emm &lt;- contrast(warp.emm, interaction = c(tension = "poly", wool = "consec"), 
                   by = NULL)
tw.emm          # see the estimates
coef(tw.emm)    # see the contrast coefficients

# Use of scale and offset
#   an unusual use of the famous stack-loss data...
mod &lt;- lm(Water.Temp ~ poly(stack.loss, degree = 2), data = stackloss)
(emm &lt;- emmeans(mod, "stack.loss", at = list(stack.loss = 10 * (1:4))))
# Convert results from Celsius to Fahrenheit:
confint(contrast(emm, "identity", scale = 9/5, offset = 32))

</code></pre>

<hr>
<h2 id='contrast-methods'>Contrast families</h2><span id='topic+contrast-methods'></span><span id='topic+pairwise.emmc'></span><span id='topic+emmc-functions'></span><span id='topic+revpairwise.emmc'></span><span id='topic+tukey.emmc'></span><span id='topic+poly.emmc'></span><span id='topic+trt.vs.ctrl.emmc'></span><span id='topic+trt.vs.ctrl1.emmc'></span><span id='topic+trt.vs.ctrlk.emmc'></span><span id='topic+dunnett.emmc'></span><span id='topic+eff.emmc'></span><span id='topic+del.eff.emmc'></span><span id='topic+consec.emmc'></span><span id='topic+mean_chg.emmc'></span><span id='topic+wtcon.emmc'></span><span id='topic+identity.emmc'></span>

<h3>Description</h3>

<p>Functions with an extension of <code>.emmc</code> provide for named contrast
families. One of the standard ones documented here may be used, or the user
may write such a function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pairwise.emmc(levs, exclude = integer(0), include, ...)

revpairwise.emmc(levs, exclude = integer(0), include, ...)

tukey.emmc(levs, reverse = FALSE, ...)

poly.emmc(levs, max.degree = min(6, k - 1), ...)

trt.vs.ctrl.emmc(levs, ref = 1, reverse = FALSE, exclude = integer(0),
  include, ...)

trt.vs.ctrl1.emmc(levs, ref = 1, ...)

trt.vs.ctrlk.emmc(levs, ref = length(levs), ...)

dunnett.emmc(levs, ref = 1, ...)

eff.emmc(levs, exclude = integer(0), include, wts = rep(1, length(levs)),
  ...)

del.eff.emmc(levs, exclude = integer(0), include, wts = rep(1,
  length(levs)), ...)

consec.emmc(levs, reverse = FALSE, exclude = integer(0), include, ...)

mean_chg.emmc(levs, reverse = FALSE, exclude = integer(0), include, ...)

wtcon.emmc(levs, wts, cmtype = "GrandMean", ...)

identity.emmc(levs, exclude = integer(0), include, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="contrast-methods_+3A_levs">levs</code></td>
<td>
<p>Vector of factor levels</p>
</td></tr>
<tr><td><code id="contrast-methods_+3A_exclude">exclude</code></td>
<td>
<p>integer vector of indices, or character vector of levels to
exclude from consideration. These levels will receive weight 0 in all
contrasts. Character levels must exactly match elements of <code>levs</code>.</p>
</td></tr>
<tr><td><code id="contrast-methods_+3A_include">include</code></td>
<td>
<p>integer or character vector of levels to include (the
complement of <code>exclude</code>). An error will result if the user specifies
both <code>exclude</code> and <code>include</code>.</p>
</td></tr>
<tr><td><code id="contrast-methods_+3A_...">...</code></td>
<td>
<p>Additional arguments, passed to related methods as appropriate</p>
</td></tr>
<tr><td><code id="contrast-methods_+3A_reverse">reverse</code></td>
<td>
<p>Logical value to determine the direction of comparisons</p>
</td></tr>
<tr><td><code id="contrast-methods_+3A_max.degree">max.degree</code></td>
<td>
<p>Integer specifying the maximum degree of polynomial contrasts</p>
</td></tr>
<tr><td><code id="contrast-methods_+3A_ref">ref</code></td>
<td>
<p>Integer(s) or character(s) specifying which level(s) to use 
as the reference. Character values must exactly match elements of <code>levs</code>
(including any enhancements &ndash; see examples)</p>
</td></tr>
<tr><td><code id="contrast-methods_+3A_wts">wts</code></td>
<td>
<p>Optional weights to use with <code>eff.emmc</code> and <code>del.eff.emmc</code> contrasts.
These default to equal weights.
If <code>exclude</code> or <code>include</code> are specified, <code>wts</code> may be
either the same length as <code>levs</code> or the length of the included levels.
In the former case, weights for any excluded levels are set to zero.
<code>wts</code> has no impact on the results unless there are at least
three levels included in the contrast.</p>
</td></tr>
<tr><td><code id="contrast-methods_+3A_cmtype">cmtype</code></td>
<td>
<p>the <code>type</code> argument passed to <code><a href="multcomp.html#topic+contrMat">contrMat</a></code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>Each standard contrast family has a default multiple-testing adjustment as
noted below. These adjustments are often only approximate; for a more
exacting adjustment, use the interfaces provided to <code>glht</code> in the
<span class="pkg">multcomp</span> package.
</p>
<p><code>pairwise.emmc</code>, <code>revpairwise.emmc</code>, and <code>tukey.emmc</code> generate
contrasts for all pairwise comparisons among estimated marginal means at the
levels in levs. The distinction is in which direction they are subtracted.
For factor levels A, B, C, D, <code>pairwise.emmc</code> generates the comparisons
A-B, A-C, A-D, B-C, B-D, and C-D, whereas <code>revpairwise.emmc</code> generates
B-A, C-A, C-B, D-A, D-B, and D-C. <code>tukey.emmc</code> invokes
<code>pairwise.emmc</code> or <code>revpairwise.emmc</code> depending on <code>reverse</code>.
The default multiplicity adjustment method is <code>"tukey"</code>, which is only
approximate when the standard errors differ.
</p>
<p><code>poly.emmc</code> generates orthogonal polynomial contrasts, assuming
equally-spaced factor levels. These are derived from the
<code><a href="stats.html#topic+poly">poly</a></code> function, but an <em>ad hoc</em> algorithm is used to
scale them to integer coefficients that are (usually) the same as in
published tables of orthogonal polynomial contrasts. The default multiplicity
adjustment method is <code>"none"</code>.
</p>
<p><code>trt.vs.ctrl.emmc</code> and its relatives generate contrasts for comparing
one level (or the average over specified levels) with each of the other
levels. The argument <code>ref</code> should be the index(es) (not the labels) of
the reference level(s). <code>trt.vs.ctrl1.emmc</code> is the same as
<code>trt.vs.ctrl.emmc</code> with a reference value of 1, and
<code>trt.vs.ctrlk.emmc</code> is the same as <code>trt.vs.ctrl</code> with a reference
value of <code>length(levs)</code>. <code>dunnett.emmc</code> is the same as
<code>trt.vs.ctrl</code>. The default multiplicity adjustment method is
<code>"dunnettx"</code>, a close approximation to the Dunnett adjustment.
<em>Note</em> in all of these functions, it is illegal to have any overlap
between the <code>ref</code> levels and the <code>exclude</code> levels. If any is found,
an error is thrown.
</p>
<p><code>consec.emmc</code> and <code>mean_chg.emmc</code> are useful for contrasting
treatments that occur in sequence. For a factor with levels A, B, C, D, E,
<code>consec.emmc</code> generates the comparisons B-A, C-B, and D-C, while
<code>mean_chg.emmc</code> generates the contrasts (B+C+D)/3 - A, (C+D)/2 -
(A+B)/2, and D - (A+B+C)/3. With <code>reverse = TRUE</code>, these differences go
in the opposite direction.
</p>
<p><code>eff.emmc</code> and <code>del.eff.emmc</code> generate contrasts that compare each
level with the average over all levels (in <code>eff.emmc</code>) or over all other
levels (in <code>del.eff.emmc</code>). These differ only in how they are scaled.
For a set of k EMMs, <code>del.eff.emmc</code> gives weight 1 to one EMM and weight
-1/(k-1) to the others, while <code>eff.emmc</code> gives weights (k-1)/k and -1/k
respectively, as in subtracting the overall EMM from each EMM. The default
multiplicity adjustment method is <code>"fdr"</code>. This is a Bonferroni-based
method and is slightly conservative; see <code><a href="stats.html#topic+p.adjust">p.adjust</a></code>.
</p>
<p><code>wtcon.emmc</code> generates weighted contrasts based on the function 
<code><a href="multcomp.html#topic+contrMat">contrMat</a></code> function in the <span class="pkg">multcomp</span> package,
using the provided <code>type</code> as documented there. If the user provides 
<code>wts</code>, they have to conform to the length of <code>levs</code>; however,
if <code>wts</code> is not specified, <code>contrast</code> will fill-in what is
required, and usually this is safer (especially when <code>by != NULL</code>
which usually means that the weights are different in each <code>by</code> group).
</p>
<p><code>identity.emmc</code> simply returns the identity matrix (as a data frame),
minus any columns specified in <code>exclude</code>. It is potentially useful in
cases where a contrast function must be specified, but none is desired.
</p>


<h3>Value</h3>

<p>A data.frame, each column containing contrast coefficients for levs.
The &quot;desc&quot; attribute is used to label the results in emmeans, and the
&quot;adjust&quot; attribute gives the default adjustment method for multiplicity.
</p>


<h3>Note</h3>

<p>Caution is needed in cases where the user alters the ordering of
results (e.g., using the the <code>"[...]"</code> operator), because the
contrasts generated depend on the order of the levels provided. For
example, suppose <code>trt.vs.ctrl1</code> contrasts are applied to two <code>by</code>
groups with levels ordered (Ctrl, T1, T2) and (T1, T2, Ctrl) respectively,
then the contrasts generated will be for (T1 - Ctrl, T2 - Ctrl) in the
first group and (T2 - T1, Ctrl - T1) in the second group, because the first
level in each group is used as the reference level.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>warp.lm &lt;- lm(breaks ~ wool*tension, data = warpbreaks)
warp.emm &lt;- emmeans(warp.lm, ~ tension | wool)
contrast(warp.emm, "poly")
contrast(warp.emm, "trt.vs.ctrl", ref = "M")
## Not run: 
## Same when enhanced labeling is used:
contrast(warp.emm, "trt.vs.ctrl", 
         enhance.levels = "tension", ref = "tensionM")
## End(Not run)

# Comparisons with grand mean
contrast(warp.emm, "eff")
# Comparisons with a weighted grand mean
contrast(warp.emm, "eff", wts = c(2, 5, 3))

# Compare only low and high tensions
# Note pairs(emm, ...) calls contrast(emm, "pairwise", ...)
pairs(warp.emm, exclude = 2)
# (same results using exclude = "M" or include = c("L","H") or include = c(1,3))

### Setting up a custom contrast function
helmert.emmc &lt;- function(levs, ...) {
    M &lt;- as.data.frame(contr.helmert(levs))
    names(M) &lt;- paste(levs[-1],"vs earlier")
    attr(M, "desc") &lt;- "Helmert contrasts"
    M
}
contrast(warp.emm, "helmert")
## Not run: 
# See what is used for polynomial contrasts with 6 levels
emmeans:::poly.emmc(1:6)

## End(Not run)
</code></pre>

<hr>
<h2 id='eff_size'>Calculate effect sizes and confidence bounds thereof</h2><span id='topic+eff_size'></span>

<h3>Description</h3>

<p>Standardized effect sizes are typically calculated using pairwise differences of estimates,
divided by the SD of the population providing the context for those effects.
This function calculates effect sizes from an <code>emmGrid</code> object,
and confidence intervals for them, accounting for uncertainty in both the estimated
effects and the population SD.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>eff_size(object, sigma, edf, method = "pairwise", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="eff_size_+3A_object">object</code></td>
<td>
<p>an <code><a href="#topic+emmGrid-class">emmGrid</a></code> object, 
typically one defining the EMMs to 
be contrasted. If instead, <code>class(object) == "emm_list"</code>,
such as is produced by <code>emmeans(model, pairwise ~ treatment)</code>,
a message is displayed; the contrasts already therein are used; and 
<code>method</code> is replaced by <code>"identity"</code>.</p>
</td></tr>
<tr><td><code id="eff_size_+3A_sigma">sigma</code></td>
<td>
<p>numeric scalar, value of the population SD.</p>
</td></tr>
<tr><td><code id="eff_size_+3A_edf">edf</code></td>
<td>
<p>numeric scalar that specifies the equivalent degrees of freedom
for the <code>sigma</code>. This is a way of specifying the uncertainty in <code>sigma</code>,
in that we regard our estimate of <code>sigma^2</code> as being proportional to
a chi-square random variable with <code>edf</code> degrees of freedom. (<code>edf</code> should
not be confused with the <code>df</code> argument that may be passed via <code>...</code>
to specify the degrees of freedom to use in <code class="reqn">t</code> statistics and confidence intervals.)</p>
</td></tr>
<tr><td><code id="eff_size_+3A_method">method</code></td>
<td>
<p>the contrast method to use to define the effects.
This is passed to <code><a href="#topic+contrast">contrast</a></code> after the elements of <code>object</code>
are scaled.</p>
</td></tr>
<tr><td><code id="eff_size_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to <code>contrast</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>Any <code>by</code> variables specified in <code>object</code> will remain in force in the returned
effects, unless overridden in the optional arguments.
</p>
<p>For models having a single random effect, such as those fitted using
<code><a href="stats.html#topic+lm">lm</a></code>; in that case, the <code>stats::sigma</code> and
<code>stats::df.residual</code> functions may be useful for specifying <code>sigma</code>
and <code>edf</code>. For models with more than one random effect, <code>sigma</code> may
be based on some combination of the random-effect variances. 
</p>
<p>Specifying <code>edf</code> can be rather unintuitive but is also relatively
uncritical; but the smaller the value, the wider the confidence intervals for
effect size. The value of <code>sqrt(2/edf)</code> can be interpreted as the
relative accuracy of <code>sigma</code>; for example, with <code>edf = 50</code>,
<code class="reqn">\sqrt(2/50) = 0.2</code>, meaning that <code>sigma</code> is accurate to plus or
minus 20 percent. Note in an example below, we tried two different <code>edf</code>
values as kind of a bracketing/sensitivity-analysis strategy. A value of
<code>Inf</code> is allowable, in which case you are assuming that <code>sigma</code> is
known exactly. Obviously, this narrows the confidence intervals for the
effect sizes &ndash; unrealistically if in fact <code>sigma</code> is unknown.
</p>


<h3>Value</h3>

<p>an <code><a href="#topic+emmGrid-class">emmGrid</a></code> object containing the effect sizes
</p>


<h3>Computation</h3>

<p>This function uses calls to <code><a href="#topic+regrid">regrid</a></code> to put the estimated
marginal means (EMMs) on the log scale. Then an extra element is added to
this grid for the log of <code>sigma</code> and its standard error (where we assume
that <code>sigma</code> is uncorrelated with the log EMMs). Then a call to
<code><a href="#topic+contrast">contrast</a></code> subtracts <code>log{sigma}</code> from each of the log EMMs,
yielding values of <code>log(EMM/sigma)</code>.
Finally, the results are re-gridded back to the original scale and the
desired contrasts are computed using <code>method</code>. In the log-scaling
part, we actually rescale the absolute values and keep track of the signs.
</p>


<h3>Note</h3>

<p>The effects are always computed on the scale of the <em>linear-predictor</em>;
any response transformation or link function is completely ignored. If you
wish to base the effect sizes on the response scale, it is <em>not</em> enough
to replace <code>object</code> with <code>regrid(object)</code>, because this
back-transformation changes the SD required to compute effect sizes.
</p>
<p><strong>Paired data:</strong> Be careful with paired-data situations, where Cohen's d is typically referenced to
the SD of the <em>paired differences</em> rather than the <em>residual</em> SD.
You may need to enlarge <code>sigma</code> by a factor of <code>sqrt(2)</code> to obtain
comparable results with other software.
</p>
<p><strong>Disclaimer:</strong> There is substantial disagreement among practitioners on
what is the appropriate <code>sigma</code> to use in computing effect sizes; or,
indeed, whether <em>any</em> effect-size measure is appropriate for some
situations. The user is completely responsible for specifying 
appropriate parameters (or for failing to do so).
</p>
<p>The examples here illustrate a sobering message that effect sizes are often not nearly as accurate as you may think.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>fiber.lm &lt;- lm(strength ~ diameter + machine, data = fiber)

emm &lt;- emmeans(fiber.lm, "machine")
eff_size(emm, sigma = sigma(fiber.lm), edf = df.residual(fiber.lm))

# or equivalently:
eff_size(pairs(emm), sigma(fiber.lm), df.residual(fiber.lm), method = "identity")


### Mixed model example:
if (require(nlme)) withAutoprint({
  Oats.lme &lt;- lme(yield ~ Variety + factor(nitro), 
                  random = ~ 1 | Block / Variety,
                  data = Oats)
  # Combine variance estimates
  VarCorr(Oats.lme)
  (totSD &lt;- sqrt(214.4724 + 109.6931 + 162.5590))
  # I figure edf is somewhere between 5 (Blocks df) and 51 (Resid df)
  emmV &lt;- emmeans(Oats.lme, ~ Variety)
  eff_size(emmV, sigma = totSD, edf = 5)
  eff_size(emmV, sigma = totSD, edf = 51)
}, spaced = TRUE)

# Multivariate model for the same data:
 MOats.lm &lt;- lm(yield ~ Variety, data = MOats)
 eff_size(emmeans(MOats.lm, "Variety"), 
          sigma = sqrt(mean(sigma(MOats.lm)^2)),   # RMS of sigma()
          edf = df.residual(MOats.lm))
</code></pre>

<hr>
<h2 id='emm'>Support for <code>multcomp::glht</code></h2><span id='topic+emm'></span><span id='topic+glht-support'></span><span id='topic+glht.emmGrid'></span><span id='topic+glht.emmlf'></span><span id='topic+modelparm.emmwrap'></span><span id='topic+as.glht'></span><span id='topic+as.glht.emmGrid'></span>

<h3>Description</h3>

<p>These functions and methods provide an interface between <span class="pkg">emmeans</span> and
the <code>multcomp::glht</code> function for simultaneous inference provided
by the <span class="pkg">multcomp</span> package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>emm(...)

as.glht(object, ...)

## S3 method for class 'emmGrid'
as.glht(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="emm_+3A_...">...</code></td>
<td>
<p>In <code>emm</code>, the <code>specs</code>, <code>by</code>, and <code>contr</code>
arguments you would normally supply to <code><a href="#topic+emmeans">emmeans</a></code>. Only
<code>specs</code> is required. Otherwise, arguments are passed to other
methods. You may also include a <code>which</code> argument; see Details.</p>
</td></tr>
<tr><td><code id="emm_+3A_object">object</code></td>
<td>
<p>An object of class <code>emmGrid</code> or <code>emm_list</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>emm</code> returns an object of an intermediate class for which
there is a <code>multcomp::glht</code> method.
</p>
<p><code>as.glht</code> returns an object of class <code>glht</code> or <code>glht_list</code>
according to whether <code>object</code> is of class <code>emmGrid</code> or <code>emm_list</code>. 
See Details below for more on <code>glht_list</code>s.
</p>


<h3>Details for <code>emm</code></h3>

<p><code>emm</code> is meant to be called only <em>from</em> <code>"glht"</code> as its second
(<code>linfct</code>) argument. It works similarly to <code>multcomp::mcp</code>,
except with <code>specs</code> (and optionally <code>by</code> and <code>contr</code>
arguments) provided as in a call to <code><a href="#topic+emmeans">emmeans</a></code>.
</p>
<p>If the specifications in <code>...</code> would result in a list (i.e., an
<code>emm_list</code> object), then by default, only the last element of that list
is passed to <code>glht</code>. However, if <code>...</code> contains a <code>which</code>
argument consisting of integer values, the list elements with those indexes
are selected and combined and passed on to <code>glht</code>. No checking is done
on whether the indexes are valid, and the keyword <code>which</code> must be spelled-out.
</p>


<h3>Details for <code>as.glht</code></h3>

<p>When no <code>by</code> variable is in force, we obtain a <code>glht</code> object; otherwise
it is a <code>glht_list</code>. The latter is defined in <span class="pkg">emmeans</span>, not <span class="pkg">multcomp</span>,
and is simply a <code>list</code> of <code>glht</code> objects. 
Appropriate convenience methods <code>coef</code>,
<code>confint</code>, <code>plot</code>, <code>summary</code>, and <code>vcov</code> are provided,
which simply apply the corresponding <code>glht</code> methods to each member.
</p>


<h3>Note</h3>

<p>The multivariate-<code class="reqn">t</code> routines used by <code>glht</code> require that all
estimates in the family have the same integer degrees of freedom. In cases
where that is not true, a message is displayed that shows what df is used.
The user may override this via the <code>df</code> argument.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if(require(multcomp, quietly = TRUE)) 
    emm_example("glht-multcomp") 
    # Use emm_example("glht-multcomp", list = TRUE) # to see just the code
    
</code></pre>

<hr>
<h2 id='emm_example'>Run or list additional examples</h2><span id='topic+emm_example'></span>

<h3>Description</h3>

<p>This function exists so as to provide cleaner-looking examples in
help files when it must be run conditionally on another package.
Typically we want to run the code (<code>run = TRUE</code> is the default),
or otherwise just list it on the console (<code>list = TRUE</code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>emm_example(name, run = !list, list = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="emm_example_+3A_name">name</code></td>
<td>
<p>Character name of file to run. We look for a file with this name
(with <code>".R"</code> appended) in the system files provided with <span class="pkg">emmeans</span>.</p>
</td></tr>
<tr><td><code id="emm_example_+3A_run">run</code></td>
<td>
<p>Logical choosing whether or not to run the example code</p>
</td></tr>
<tr><td><code id="emm_example_+3A_list">list</code></td>
<td>
<p>Logical choosing whether or not to list the example code</p>
</td></tr>
<tr><td><code id="emm_example_+3A_...">...</code></td>
<td>
<p>Used only by the developer</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'># List an example
emm_example("qdrg-biglm", list = TRUE)

# Run an example
if (require(biglm))
    emm_example("qdrg-biglm")

</code></pre>

<hr>
<h2 id='emm_list'>The <code>emm_list</code> class</h2><span id='topic+emm_list'></span><span id='topic+contrast.emm_list'></span><span id='topic+pairs.emm_list'></span><span id='topic+test.emm_list'></span><span id='topic+confint.emm_list'></span><span id='topic+plot.emm_list'></span><span id='topic+coef.emm_list'></span><span id='topic+str.emm_list'></span><span id='topic+summary.emm_list'></span><span id='topic+print.emm_list'></span><span id='topic+as.data.frame.emm_list'></span><span id='topic+as.data.frame.summary_eml'></span>

<h3>Description</h3>

<p>An <code>emm_list</code> object is simply a list of
<code><a href="#topic+emmGrid-class">emmGrid</a></code> objects. Such a list is returned,
for example, by <code><a href="#topic+emmeans">emmeans</a></code> with a two-sided formula or a list as its
<code>specs</code> argument. Several methods for this class are provided, as detailed below.
Typically, these methods just quietly do the same thing as their <code>emmGrid</code>
methods, using the first element of the list. You can specify <code>which</code>
to select a different element, or just run the corresponding <code>emmGrid</code>
method on <code>object[[k]]</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'emm_list'
contrast(object, ..., which = 1)

## S3 method for class 'emm_list'
pairs(x, ..., which = 1)

## S3 method for class 'emm_list'
test(object, ..., which = seq_along(object))

## S3 method for class 'emm_list'
confint(object, ..., which = seq_along(object))

## S3 method for class 'emm_list'
plot(x, ..., which = 1)

## S3 method for class 'emm_list'
coef(object, ..., which = 2)

## S3 method for class 'emm_list'
str(object, ...)

## S3 method for class 'emm_list'
summary(object, ..., which = seq_along(object))

## S3 method for class 'emm_list'
print(x, ...)

## S3 method for class 'emm_list'
as.data.frame(x, ...)

## S3 method for class 'summary_eml'
as.data.frame(x, row.names = NULL, optional = FALSE,
  which, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="emm_list_+3A_object">object</code>, <code id="emm_list_+3A_x">x</code></td>
<td>
<p>an object of class <code>emm_list</code></p>
</td></tr>
<tr><td><code id="emm_list_+3A_...">...</code></td>
<td>
<p>additional arguments passed to corresponding <code>emmGrid</code> method</p>
</td></tr>
<tr><td><code id="emm_list_+3A_which">which</code></td>
<td>
<p>integer vector specifying which elements to select.</p>
</td></tr>
<tr><td><code id="emm_list_+3A_row.names">row.names</code>, <code id="emm_list_+3A_optional">optional</code></td>
<td>
<p>Required arguments of <code>as.data.frame</code>, ignored</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a <code>list</code> of objects returned by the corresponding <code>emmGrid</code>
method (thus, often, another <code>emm_list</code> object). However, if
<code>which</code> has length 1, the one result is not wrapped in a list.
</p>
<p><code>summary.emm_list</code> returns an object
of class <code>summary_eml</code>, which is a list of <code>summary_emm</code>
objects.
</p>
<p>The <code>as.data.frame</code> methods return a single data frame via
<code>as.data.frame(rbind(x))</code>.
See also <code><a href="#topic+rbind.emm_list">rbind.emm_list</a></code> and <code><a href="#topic+as.data.frame.emmGrid">as.data.frame.emmGrid</a></code>
</p>


<h3>Note</h3>

<p>The <code>plot</code> method uses only the first element of <code>which</code>; the others are ignored.
</p>
<p>No <code>export</code> option is provided for printing an <code>emm_list</code>
(see <code><a href="#topic+print.emmGrid">print.emmGrid</a></code>). If you wish to export these objects, you 
must do so separately for each element in the list.
</p>

<hr>
<h2 id='emm_options'>Set or change emmeans options</h2><span id='topic+emm_options'></span><span id='topic+get_emm_option'></span><span id='topic+emm_defaults'></span>

<h3>Description</h3>

<p>Use <code>emm_options</code> to set or change various options that are used in
the <span class="pkg">emmeans</span> package. These options are set separately for different contexts in
which <code>emmGrid</code> objects are created, in a named list of option lists.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>emm_options(..., disable)

get_emm_option(x, default = emm_defaults[[x]])

emm_defaults
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="emm_options_+3A_...">...</code></td>
<td>
<p>Option names and values (see Details)</p>
</td></tr>
<tr><td><code id="emm_options_+3A_disable">disable</code></td>
<td>
<p>If non-missing, this will reset all options to their defaults 
if <code>disable</code> tests <code>TRUE</code> (but first save them for possible later 
restoration). Otherwise, all previously saved options
are restored. This is important for bug reporting; please see the section below
on reproducible bugs. When <code>disable</code> is specified, the other arguments are ignored.</p>
</td></tr>
<tr><td><code id="emm_options_+3A_x">x</code></td>
<td>
<p>Character value - the name of an option to be queried</p>
</td></tr>
<tr><td><code id="emm_options_+3A_default">default</code></td>
<td>
<p>Value to return if <code>x</code> is not found</p>
</td></tr>
</table>


<h3>Format</h3>

<p>An object of class <code>list</code> of length 21.
</p>


<h3>Details</h3>

<p><span class="pkg">emmeans</span>'s options are stored as a list in the system option <code>"emmeans"</code>. 
Thus, <code>emm_options(foo = bar)</code> is the same as 
<code>options(emmeans = list(..., foo = bar))</code> where <code>...</code> represents any
previously existing options. The list <code>emm_defaults</code> contains the default
values in case the corresponding element of system option <code>emmeans</code> is <code>NULL</code>.
</p>
<p>Currently, the following main list entries are supported:
</p>

<dl>
<dt><code>ref_grid</code></dt><dd><p>A named <code>list</code> of defaults for objects created by
<code><a href="#topic+ref_grid">ref_grid</a></code>. This could affect other objects as well. For example,
if <code>emmeans</code> is called with a fitted model object, it calls
<code>ref_grid</code> and this option will affect the resulting <code>emmGrid</code>
object.</p>
</dd>
<dt><code>emmeans</code></dt><dd><p>A named <code>list</code> of defaults for objects created by
<code><a href="#topic+emmeans">emmeans</a></code> or <code><a href="#topic+emtrends">emtrends</a></code>.</p>
</dd>
<dt><code>contrast</code></dt><dd><p>A named <code>list</code> of defaults for objects created by
<code><a href="#topic+contrast.emmGrid">contrast.emmGrid</a></code> or <code><a href="#topic+pairs.emmGrid">pairs.emmGrid</a></code>.</p>
</dd>
<dt><code>summary</code></dt><dd><p>A named <code>list</code> of defaults used by the methods
<code><a href="#topic+summary.emmGrid">summary.emmGrid</a></code>, <code><a href="#topic+predict.emmGrid">predict.emmGrid</a></code>, <code><a href="#topic+test.emmGrid">test.emmGrid</a></code>,
<code><a href="#topic+confint.emmGrid">confint.emmGrid</a></code>, and <code><a href="#topic+emmip">emmip</a></code>. The only option that can
affect the latter four is <code>"predict.method"</code>.</p>
</dd>
<dt><code>sep</code></dt><dd><p>A character value to use as a separator in labeling factor combinations.
Such labels are potentially used in several places such as <code><a href="#topic+contrast">contrast</a></code> and 
<code><a href="#topic+plot.emmGrid">plot.emmGrid</a></code> when combinations of factors are compared or plotted.
The default is <code>" "</code>.</p>
</dd>
<dt><code>parens</code></dt><dd><p>Character vector that determines which labels are parenthesized
when they are contrasted. The first element is a regular expression, and the second and
third elements are used as left and right parentheses. 
See details for the <code>parens</code> argument in <code><a href="#topic+contrast">contrast</a></code>. The default
will parenthesize labels containing the four arithmetic operators, 
using round parentheses.</p>
</dd>
<dt><code>cov.keep</code></dt><dd><p>The default value of <code>cov.keep</code> in <code><a href="#topic+ref_grid">ref_grid</a></code>.
Defaults to <code>"2"</code>, i.e., two-level covariates are treated like factors.</p>
</dd>
<dt><code>graphics.engine</code></dt><dd><p>A character value matching 
<code>c("ggplot", "lattice")</code>, setting the default engine to use in
<code><a href="#topic+emmip">emmip</a></code> and <code><a href="#topic+plot.emmGrid">plot.emmGrid</a></code>.  Defaults to <code>"ggplot"</code>.</p>
</dd>
<dt><code>msg.interaction</code></dt><dd><p>A logical value controlling whether or not
a message is displayed when <code>emmeans</code> averages over a factor involved
in an interaction. It is probably not appropriate to do this, unless
the interaction is weak. Defaults to <code>TRUE</code>.</p>
</dd>
<dt><code>msg.nesting</code></dt><dd><p>A logical value controlling whether or not to
display a message when a nesting structure is auto-detected. The existence
of such a structure affects computations of EMMs. Sometimes, a nesting
structure is falsely detected &ndash; namely when a user has omitted some
main effects but included them in interactions. This does not change the
model fit, but it produces a different parameterization that is picked
up when the reference grid is constructed. Defaults to <code>TRUE</code>.</p>
</dd>
<dt><code>rg.limit</code></dt><dd><p>An integer value setting a limit on the number of rows
in a newly constructed reference grid. This is checked based on the number of
levels of the factors involved; but it excludes the levels of any multivariate
responses because those are not yet known. The reference grid consists of all
possible combinations of the predictors, and this can become huge if there are
several factors. An error is thrown if this limit is exceeded. One can use the 
<code>nuisance</code> argument of <code><a href="#topic+ref_grid">ref_grid</a></code> to collapse on nuisance
factors, thus making the grid smaller. Defaults to 10,000.</p>
</dd>
<dt><code>simplify.names</code></dt><dd><p>A logical value controlling whether to
simplify (when possible) names in the model formula that refer to datasets &ndash;
for example, should we simplify a predictor name like &ldquo;<code>data$trt</code>&rdquo;
to just &ldquo;<code>trt</code>&rdquo;? Defaults to <code>TRUE</code>.</p>
</dd>
<dt><code>opt.digits</code></dt><dd><p>A logical value controlling the precision with which
summaries are printed. If <code>TRUE</code> (default), the number of digits
displayed is just enough to reasonably distinguish estimates from the ends
of their confidence intervals; but always at least 3 digits. If
<code>FALSE</code>, the system value <code>getOption("digits")</code> is used.</p>
</dd>
<dt><code>back.bias.adj</code></dt><dd><p>A logical value controlling whether we 
try to adjust bias when back-transforming. If <code>FALSE</code>, we use naive
back transformation. If <code>TRUE</code> <em>and <code>sigma</code> is available and valid</em>, a
second-order adjustment is applied to estimate the mean on the response
scale. A warning is issued if no valid <code>sigma</code> is available</p>
</dd>
<dt><code>enable.submodel</code></dt><dd><p>A logical value. If <code>TRUE</code>, enables support 
for selected model classes to implement the <code>submodel</code> option. If
<code>FALSE</code>, this support is disabled. Setting this option to <code>FALSE</code>
could save excess memory consumption.</p>
</dd>
</dl>

<p>Some other options have more specific purposes:
</p>

<dl>
<dt><code>estble.tol</code></dt><dd><p>Tolerance for determining estimability in
rank-deficient cases. If absent, the value in <code>emm_defaults$estble.tol)</code>
is used.</p>
</dd>
<dt><code>save.ref_grid</code></dt><dd><p>Logical value of <code>TRUE</code> if you wish the 
latest reference grid created to be saved in <code>.Last.ref_grid</code>.
The default is <code>FALSE</code>.</p>
</dd>
<dt>Options for <code>lme4::lmerMod</code> models</dt><dd><p>Options <code>lmer.df</code>,
<code>disable.pbkrtest</code>, <code>pbkrtest.limit</code>, <code>disable.lmerTest</code>,
and <code>lmerTest.limit</code>
options affect how degrees of freedom are computed for <code>lmerMod</code> objects
produced by the <span class="pkg">lme4</span> package). See that section of the &quot;models&quot; vignette
for details.</p>
</dd>
</dl>
 


<h3>Value</h3>

<p><code>emm_options</code> returns the current options (same as the result 
of &lsquo;<span class="samp">&#8288;getOption("emmeans")&#8288;</span>&rsquo;) &ndash; invisibly, unless called with no arguments.
</p>
<p><code>get_emm_option</code> returns the currently stored option for <code>x</code>, 
or its default value if not found.
</p>


<h3>Reproducible bugs</h3>

<p>Most options set display attributes and such that are not likely to be associated
with bugs in the code. However, some other options (e.g., <code>cov.keep</code>)
are essentially configuration settings that may affect how/whether the code
runs, and the settings for these options may cause subtle effects that may be
hard to reproduce. Therefore, when sending a bug report, please create a reproducible
example and make sure the bug occurs with all options set at their defaults.
This is done by preceding it with  <code>emm_options(disable = TRUE)</code>. 
</p>
<p>By the way, <code>disable</code> works like a stack (LIFO buffer), in that <code>disable = TRUE</code>
is equivalent to <code>emm_options(saved.opts = emm_options())</code> and 
<code>emm_options(disable = FALSE)</code> is equivalent to 
<code>options(emmeans = get_emm_option("saved.opts"))</code>. To completely erase
all options, use <code>options(emmeans = NULL)</code>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+update.emmGrid">update.emmGrid</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
emm_options(ref_grid = list(level = .90),
            contrast = list(infer = c(TRUE,FALSE)),
            estble.tol = 1e-6)
# Sets default confidence level to .90 for objects created by ref.grid
# AS WELL AS emmeans called with a model object (since it creates a 
# reference grid). In addition, when we call 'contrast', 'pairs', etc.,
# confidence intervals rather than tests are displayed by default.

## End(Not run)

## Not run: 
emm_options(disable.pbkrtest = TRUE)
# This forces use of asymptotic methods for lmerMod objects.
# Set to FALSE or NULL to re-enable using pbkrtest.

## End(Not run)

# See tolerance being used for determining estimability
get_emm_option("estble.tol")

## Not run: 
# Set all options to their defaults
emm_options(disable = TRUE)
# ... and perhaps follow with code for a minimal reproducible bug,
#     which may include emm_options() clls if they are pertinent ...

# restore options that had existed previously
emm_options(disable = FALSE)

## End(Not run)

</code></pre>

<hr>
<h2 id='emmeans'>Estimated marginal means (Least-squares means)</h2><span id='topic+emmeans'></span>

<h3>Description</h3>

<p>Compute estimated marginal means (EMMs) for specified factors
or factor combinations in a linear model; and optionally, comparisons or
contrasts among them. EMMs are also known as least-squares means.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>emmeans(object, specs, by = NULL, fac.reduce = function(coefs) apply(coefs,
  2, mean), contr, options = get_emm_option("emmeans"), weights, offset, ...,
  tran)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="emmeans_+3A_object">object</code></td>
<td>
<p>An object of class <code>emmGrid</code>; or a fitted model object
that is supported, such as the result of a call to <code>lm</code> or
<code>lmer</code>. Many fitted-model objects are supported; see
<a href="../doc/models.html"><code>vignette("models", "emmeans")</code></a> for details.</p>
</td></tr>
<tr><td><code id="emmeans_+3A_specs">specs</code></td>
<td>
<p>A <code>character</code> vector specifying the names of the predictors
over which EMMs are desired. <code>specs</code> may also be a <code>formula</code>
or a <code>list</code> (optionally named) of valid <code>spec</code>s. Use of formulas
is described in the Overview section below. 
<b>Note:</b> We recommend <em>against</em> using two-sided formulas; see the
note below for <code>contr</code>.</p>
</td></tr>
<tr><td><code id="emmeans_+3A_by">by</code></td>
<td>
<p>A character vector specifying the names of predictors to condition on.</p>
</td></tr>
<tr><td><code id="emmeans_+3A_fac.reduce">fac.reduce</code></td>
<td>
<p>A function that combines the rows of a matrix into a single
vector. This implements the &ldquo;marginal averaging&rdquo; aspect of EMMs. 
The default is the mean of the rows. Typically if it is overridden,
it would be some kind of weighted mean of the rows. If <code>fac.reduce</code> is
nonlinear, bizarre results are likely, and EMMs will not be
interpretable. NOTE: If the <code>weights</code> argument is non-missing,
<code>fac.reduce</code> is ignored.</p>
</td></tr>
<tr><td><code id="emmeans_+3A_contr">contr</code></td>
<td>
<p>A character value or <code>list</code> specifying contrasts to be
added. See <code><a href="#topic+contrast">contrast</a></code>. <b>Note:</b> <code>contr</code> is ignored when
<code>specs</code> is a formula. <b>Note 2:</b>: We recommend <em>against</em> using this
argument; obtaining means and obtaining contrasts are two different things,
and it is best to do them in separate steps, using the <code><a href="#topic+contrast">contrast</a></code>
function for the contrasts.</p>
</td></tr>
<tr><td><code id="emmeans_+3A_options">options</code></td>
<td>
<p>If non-<code>NULL</code>, a named <code>list</code> of arguments to pass
to <code><a href="#topic+update.emmGrid">update.emmGrid</a></code>, just after the object is constructed.
(Options may also be included in <code>...</code>; see the &lsquo;options&rsquo;
section below.)</p>
</td></tr>
<tr><td><code id="emmeans_+3A_weights">weights</code></td>
<td>
<p>Character value, numeric vector, or numeric matrix specifying
weights to use in averaging predictions. See &ldquo;Weights&rdquo; section below.
Also, if <code>object</code> is not already a reference grid, <code>weights</code>
(if it is character) is passed to <code>ref_grid</code> as <code>wt.nuis</code> in case 
nuisance factors are specified. We can override this by specifying 
<code>wt.nuis</code> explicitly.
This more-or-less makes the weighting of nuisance factors consistent with
that of primary factors.</p>
</td></tr>
<tr><td><code id="emmeans_+3A_offset">offset</code></td>
<td>
<p>Numeric vector or scalar. If specified, this adds an offset to
the predictions, or overrides any offset in the model or its
reference grid. If a vector of length differing from the number of rows in 
the result, it is subsetted or cyclically recycled.</p>
</td></tr>
<tr><td><code id="emmeans_+3A_...">...</code></td>
<td>
<p>When <code>object</code> is not already a <code>"emmGrid"</code>
object, these arguments are passed to <code><a href="#topic+ref_grid">ref_grid</a></code>. Common
examples are <code>at</code>, <code>cov.reduce</code>, <code>data</code>, <code>type</code>, 
<code>regrid</code>, <code>df</code>, <code>nesting</code>, and <code>vcov.</code>.
Model-type-specific options (see
<a href="../doc/models.html"><code>vignette("models", "emmeans")</code></a>), commonly
<code>mode</code>, may be used here as well. In addition, if the model formula
contains references to variables that are not predictors, you must provide
a <code>params</code> argument with a list of their names.
These arguments may also be used in lieu of <code>options</code>. See the 
&lsquo;Options&rsquo; section below.</p>
</td></tr>
<tr><td><code id="emmeans_+3A_tran">tran</code></td>
<td>
<p>Placeholder to prevent it from being included in <code>...</code>.
If non-missing, it is added to 'options'. See the &lsquo;Options&rsquo;
section.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Users should also consult the documentation for <code><a href="#topic+ref_grid">ref_grid</a></code>, 
because many important options for EMMs are implemented there, via the 
<code>...</code> argument.
</p>


<h3>Value</h3>

<p>When <code>specs</code> is a <code>character</code> vector or one-sided formula,
an object of class <code>"emmGrid"</code>. A number of methods
are provided for further analysis, including
<code><a href="#topic+summary.emmGrid">summary.emmGrid</a></code>, <code><a href="#topic+confint.emmGrid">confint.emmGrid</a></code>,
<code><a href="#topic+test.emmGrid">test.emmGrid</a></code>, <code><a href="#topic+contrast.emmGrid">contrast.emmGrid</a></code>,
and <code><a href="#topic+pairs.emmGrid">pairs.emmGrid</a></code>.
When <code>specs</code> is a <code>list</code> or a <code>formula</code> having a left-hand
side, the return value is an <code><a href="#topic+emm_list">emm_list</a></code> object, which is simply a
<code>list</code> of <code>emmGrid</code> objects.
</p>


<h3>Overview</h3>

<p>Estimated marginal means or EMMs (sometimes called least-squares means) are
predictions from a linear model over a <em>reference grid</em>; or marginal
averages thereof. The <code><a href="#topic+ref_grid">ref_grid</a></code> function identifies/creates the
reference grid upon which <code>emmeans</code> is based.
</p>
<p>For those who prefer the terms &ldquo;least-squares means&rdquo; or
&ldquo;predicted marginal means&rdquo;, functions <code>lsmeans</code> and
<code>pmmeans</code> are provided as wrappers. See <code><a href="#topic+wrappers">wrappers</a></code>.
</p>
<p>If <code>specs</code> is a <code>formula</code>, it should be of the form <code>~ specs</code>,
<code>~ specs | by</code>, <code>contr ~ specs</code>, or <code>contr ~ specs | by</code>. The
formula is parsed and the variables therein are used as the arguments
<code>specs</code>, <code>by</code>, and <code>contr</code> as indicated. The left-hand side is
optional (and we don't recommend it), but if specified it should be the 
name of a contrast family (e.g., <code>pairwise</code>). Operators like
<code>*</code> or <code>:</code> are needed in the formula to delineate names, but
otherwise are ignored.
</p>
<p>In the special case where the mean (or weighted mean) of all the predictions
is desired, specify <code>specs</code> as <code>~ 1</code> or <code>"1"</code>.
</p>
<p>A number of standard contrast families are provided. They can be identified 
as functions having names ending in <code>.emmc</code> &ndash; see the documentation
for <code><a href="#topic+emmc-functions">emmc-functions</a></code> for details &ndash; including how to write your
own <code>.emmc</code> function for custom contrasts.
</p>


<h3>Weights</h3>

<p>If <code>weights</code> is a vector, its length must equal
the number of predictions to be averaged to obtain each EMM.
If a matrix, each row of the matrix is used in turn, wrapping back to the
first row as needed.  When in doubt about what is being averaged (or how
many), first call <code>emmeans</code> with <code>weights = "show.levels"</code>.
</p>
<p>If <code>weights</code> is a string, it should partially match one of the following:
</p>

<dl>
<dt><code>"equal"</code></dt><dd><p>Use an equally weighted average.</p>
</dd>
<dt><code>"proportional"</code></dt><dd><p>Weight in proportion to the frequencies (in the
original data) of the factor combinations that are averaged over.</p>
</dd>
<dt><code>"outer"</code></dt><dd><p>Weight in proportion to each individual factor's
marginal frequencies. Thus, the weights for a combination of factors are the
outer product of the one-factor margins</p>
</dd>
<dt><code>"cells"</code></dt><dd><p>Weight according to the frequencies of the cells being
averaged.</p>
</dd>
<dt><code>"flat"</code></dt><dd><p>Give equal weight to all cells with data, and ignore
empty cells.</p>
</dd>
<dt><code>"show.levels"</code></dt><dd><p>This is a convenience feature for understanding
what is being averaged over. Instead of a table of EMMs, this causes the
function to return a table showing the levels that are averaged over, in the
order that they appear.</p>
</dd>
</dl>

<p>Outer weights are like the 'expected' counts in a chi-square test of
independence, and will yield the same results as those obtained by
proportional averaging with one factor at a time. All except <code>"cells"</code>
uses the same set of weights for each mean. In a model where the predicted
values are the cell means, cell weights will yield the raw averages of the
data for the factors involved. Using <code>"flat"</code> is similar to
<code>"cells"</code>, except nonempty cells are weighted equally and empty cells
are ignored.
</p>


<h3>Offsets</h3>

<p>Unlike in <code>ref_grid</code>, an offset need not be scalar. If not enough values
are supplied, they are cyclically recycled. For a vector of offsets, it is 
important to understand that the ordering of results goes with the first 
name in <code>specs</code> varying fastest. If there are any <code>by</code> factors,
those vary slower than all the primary ones, but the first <code>by</code> variable
varies the fastest within that hierarchy. See the examples.
</p>


<h3>Options and <code>...</code></h3>

<p>Arguments that could go in <code>options</code> may instead be included in <code>...</code>,
typically, arguments such as <code>type</code>, <code>infer</code>, etc. that in essence
are passed to <code><a href="#topic+summary.emmGrid">summary.emmGrid</a></code>. Arguments in both places are 
overridden by the ones in <code>...</code>.
</p>
<p>There is a danger that <code>...</code> arguments could partially match those used
by both <code>ref_grid</code> and <code>update.emmGrid</code>, creating a conflict.
If these occur, usually they can be resolved by providing complete (or at least 
longer) argument names; or by isolating non-<code>ref_grid</code> arguments in
<code>options</code>; or by calling <code>ref_grid</code> separately and passing the
result as <code>object</code>. See a not-run example below.
</p>
<p>Also, when <code>specs</code> is a two-sided formula, or <code>contr</code> is specified,
there is potential confusion concerning which <code>...</code> arguments
apply to the means, and which to the contrasts. When such confusion is possible,
we suggest doing things separately 
(a call to <code>emmeans</code> with no contrasts, followed by a call to 
<code><a href="#topic+contrast">contrast</a></code>). We treat
<code>adjust</code> as a special case: it is applied to the <code>emmeans</code> results 
<em>only</em> if there are
no contrasts specified, otherwise it is passed only to <code>contrast</code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ref_grid">ref_grid</a></code>, <code><a href="#topic+contrast">contrast</a></code>, 
<a href="../doc/models.html">vignette(&quot;models&quot;, &quot;emmeans&quot;)</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>warp.lm &lt;- lm(breaks ~ wool * tension, data = warpbreaks)
emmeans (warp.lm,  ~ wool | tension)
# or equivalently emmeans(warp.lm, "wool", by = "tension")

# 'adjust' argument ignored in emmeans, passed to contrast part...
emmeans (warp.lm, poly ~ tension | wool, adjust = "sidak")

# 'adjust' argument NOT ignored ...
emmeans (warp.lm, ~ tension | wool, adjust = "sidak")


## Not run: 
  ### Offsets: Consider a silly example:
  emmeans(warp.lm, ~ tension | wool, offset = c(17, 23, 47)) @ grid
  # note that offsets are recycled so that each level of tension receives
  # the same offset for each wool.
  # But using the same offsets with ~ wool | tension will probably not
  # be what you want because the ordering of combinations is different.

## End(Not run)
</code></pre>

<hr>
<h2 id='emmGrid-class'>The <code>emmGrid</code> class</h2><span id='topic+emmGrid-class'></span>

<h3>Description</h3>

<p>The <code>emmGrid</code> class encapsulates linear functions of regression
parameters, defined over a grid of predictors. This includes reference
grids and grids of marginal means thereof (aka estimated marginal means).
Objects of class 'emmGrid' may be used independently of the underlying model
object. Instances are created primarily by <code><a href="#topic+ref_grid">ref_grid</a></code> and
<code><a href="#topic+emmeans">emmeans</a></code>, and several related functions.
</p>


<h3>Slots</h3>


<dl>
<dt><code>model.info</code></dt><dd><p>list. Contains the elements <code>call</code> (the call that
produced the model), <code>terms</code> (its <code>terms</code> object), and
<code>xlev</code> (factor-level information)</p>
</dd>
<dt><code>roles</code></dt><dd><p>list. Contains at least the elements <code>predictors</code>, 
<code>responses</code>, and <code>multresp</code>. Each is a character vector of names 
of these variables.</p>
</dd>
<dt><code>grid</code></dt><dd><p>data.frame. Contains the combinations of the variables that define
the reference grid. In addition, there is an auxiliary column named
<code>".wgt."</code> holding the observed frequencies or weights for each factor
combination (excluding covariates). If the model has one or more
<code><a href="stats.html#topic+offset">offset</a>()</code> calls, there is an another auxiliary column named
<code>".offset."</code>. Auxiliary columns are not considered part of the
reference grid. (However, any variables included in <code>offset</code> calls
<em>are</em> in the reference grid.)</p>
</dd>
<dt><code>levels</code></dt><dd><p>list. Each entry is a character vector with the distinct levels
of each variable in the reference grid. Note that <code>grid</code> is obtained
by applying the function <code><a href="base.html#topic+expand.grid">expand.grid</a></code> to this list</p>
</dd>
<dt><code>matlevs</code></dt><dd><p>list. Like <code>levels</code> but has the levels of any matrices in
the original dataset. Matrix columns are always concatenated and treated as
a single variable for purposes of the reference grid</p>
</dd>
<dt><code>linfct</code></dt><dd><p>matrix. Each row consists of the linear function of the
regression coefficients for predicting its corresponding element of the
reference grid. The rows of this matrix go in one-to-one correspondence
with the rows of <code>grid</code>, and the columns with elements of <code>bhat</code>.</p>
</dd>
<dt><code>bhat</code></dt><dd><p>numeric. The regression coefficients. If there is a multivariate
response, the matrix of coefficients is flattened to a single vector, and
<code>linfct</code> and <code>V</code> redefined appropriately. Important: <code>bhat</code>
must <em>include</em> any <code>NA</code> values produced as a result of 
collinearity in the predictors. These are taken care of later in the 
estimability check.</p>
</dd>
<dt><code>nbasis</code></dt><dd><p>matrix. The basis for the non-estimable functions of the
regression coefficients. Every EMM will correspond to a linear combination
of rows of <code>linfct</code>, and that result must be orthogonal to all the
columns of <code>nbasis</code> in order to be estimable. If everything is
estimable, <code>nbasis</code> should be a 1 x 1 matrix of <code>NA</code>.</p>
</dd>
<dt><code>V</code></dt><dd><p>matrix. The symmetric variance-covariance matrix of <code>bhat</code></p>
</dd>
<dt><code>dffun</code></dt><dd><p>function having two arguments. <code>dffun(k, dfargs)</code> should
return the degrees of freedom for the linear function <code>sum(k*bhat)</code>,
or <code>NA</code> if unavailable</p>
</dd>
<dt><code>dfargs</code></dt><dd><p>list. Used to hold any additional information needed by
<code>dffun</code>.</p>
</dd>
<dt><code>misc</code></dt><dd><p>list. Additional information used by methods. These include at
least the following: <code>estName</code> (the label for the estimates of linear
functions), and the default values of <code>infer</code>, <code>level</code>, and
<code>adjust</code> to be used in the <code><a href="#topic+summary.emmGrid">summary.emmGrid</a></code> method. Elements in
this slot may be modified if desired using the <code><a href="#topic+update.emmGrid">update.emmGrid</a></code>
method.</p>
</dd>
<dt><code>post.beta</code></dt><dd><p>matrix. A sample from the posterior distribution of the
regression coefficients, if MCMC methods were used; or a 1 x 1 matrix of
<code>NA</code> otherwise. When it is non-trivial, the <code><a href="#topic+as.mcmc.emmGrid">as.mcmc.emmGrid</a></code>
method returns <code>post.beta %*% t(linfct)</code>, which is a sample from the
posterior distribution of the EMMs.</p>
</dd>
</dl>


<h3>Methods</h3>

<p>All methods for these objects are S3 methods except for <code>show</code>. 
They include <code><a href="#topic++5B.emmGrid">[.emmGrid</a></code>, <code><a href="#topic+as.glht.emmGrid">as.glht.emmGrid</a></code>,
<code><a href="#topic+as.mcmc.emmGrid">as.mcmc.emmGrid</a></code>, <code><a href="#topic+as.mcmc.list.emmGrid">as.mcmc.list.emmGrid</a></code> (see <span class="pkg">coda</span>),
<code><a href="#topic+cld.emmGrid">cld.emmGrid</a></code> (see <span class="pkg">multcomp</span>),
<code><a href="#topic+coef.emmGrid">coef.emmGrid</a></code>, <code><a href="#topic+confint.emmGrid">confint.emmGrid</a></code>, 
<code><a href="#topic+contrast.emmGrid">contrast.emmGrid</a></code>, <code><a href="#topic+pairs.emmGrid">pairs.emmGrid</a></code>,
<code><a href="#topic+plot.emmGrid">plot.emmGrid</a></code>, <code><a href="#topic+predict.emmGrid">predict.emmGrid</a></code>, <code><a href="#topic+print.emmGrid">print.emmGrid</a></code>,
<code><a href="#topic+rbind.emmGrid">rbind.emmGrid</a></code>, <code>show.emmGrid</code>, <code><a href="#topic+str.emmGrid">str.emmGrid</a></code>, 
<code><a href="#topic+summary.emmGrid">summary.emmGrid</a></code>, <code><a href="#topic+test.emmGrid">test.emmGrid</a></code>, 
<code><a href="#topic+update.emmGrid">update.emmGrid</a></code>, <code><a href="#topic+vcov.emmGrid">vcov.emmGrid</a></code>, and 
<code><a href="#topic+xtable.emmGrid">xtable.emmGrid</a></code>
</p>

<hr>
<h2 id='emmip'>Interaction-style plots for estimated marginal means</h2><span id='topic+emmip'></span><span id='topic+emmip.default'></span><span id='topic+emmip_ggplot'></span><span id='topic+emmip_lattice'></span>

<h3>Description</h3>

<p>Creates an interaction plot of EMMs based on a fitted model and a simple
formula specification.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>emmip(object, formula, ...)

## Default S3 method:
emmip(object, formula, type, CIs = FALSE, PIs = FALSE,
  style, engine = get_emm_option("graphics.engine"), plotit = TRUE,
  nesting.order = FALSE, ...)

emmip_ggplot(emms, style = "factor", dodge = 0.1, xlab = labs$xlab,
  ylab = labs$ylab, tlab = labs$tlab, facetlab = "label_context", scale,
  dotarg = list(shape = "circle"), linearg = list(linetype = "solid"),
  CIarg = list(lwd = 2, alpha = 0.5), PIarg = list(lwd = 1.25, alpha =
  0.33), col, ...)

emmip_lattice(emms, style = "factor", xlab = labs$xlab, ylab = labs$ylab,
  tlab = labs$tlab, pch = c(1, 2, 6, 7, 9, 10, 15:20), lty = 1,
  col = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="emmip_+3A_object">object</code></td>
<td>
<p>An object of class <code>emmGrid</code>, or a fitted model of a class
supported by the <span class="pkg">emmeans</span> package</p>
</td></tr>
<tr><td><code id="emmip_+3A_formula">formula</code></td>
<td>
<p>Formula of the form 
<code>trace.factors ~ x.factors | by.factors</code>. The EMMs are
plotted against <code>x.factor</code> for each level of <code>trace.factors</code>.
<code>by.factors</code> is optional, but if present, it determines separate
panels. Each element of this formula may be a single factor in the model,
or a combination of factors using the <code>*</code> operator.</p>
</td></tr>
<tr><td><code id="emmip_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to <code><a href="#topic+emmeans">emmeans</a></code> (when
<code>object</code> is not already an <code>emmGrid</code> object),
<code>predict.emmGrid</code>, 
<code>emmip_ggplot</code>, or <code>emmip_lattice</code>.</p>
</td></tr>
<tr><td><code id="emmip_+3A_type">type</code></td>
<td>
<p>As in <code><a href="#topic+predict.emmGrid">predict.emmGrid</a></code>, this determines
whether we want to inverse-transform the predictions
(<code>type = "response"</code>) or not (any other choice). The default is
<code>"link"</code>, unless the <code>"predict.type"</code> option is in force; see
<code><a href="#topic+emm_options">emm_options</a></code>.
In addition, the user may specify <code>type = "scale"</code> to create a
transformed scale for the vertical axis based on <code>object</code>'s response 
transformation or link function.</p>
</td></tr>
<tr><td><code id="emmip_+3A_cis">CIs</code></td>
<td>
<p>Logical value. If <code>TRUE</code>, confidence intervals (or HPD intervals
for Bayesian models) are added to the plot 
(works only with <code>engine = "ggplot"</code>).</p>
</td></tr>
<tr><td><code id="emmip_+3A_pis">PIs</code></td>
<td>
<p>Logical value. If <code>TRUE</code>, prediction intervals are added to the plot 
(works only with <code>engine = "ggplot"</code>). This is allowed only if the
underlying model family is <code>"gaussian"</code>.
If both <code>CIs</code> and
<code>PIs</code> are <code>TRUE</code>, the prediction intervals will be somewhat
longer, lighter, and thinner than the confidence intervals. Additional
parameters to <code><a href="#topic+predict.emmGrid">predict.emmGrid</a></code> (e.g., <code>sigma</code>) may be passed via
<code>...</code>. For Bayesian models, PIs require <code>frequentist = TRUE</code> and 
a value for <code>sigma</code>.</p>
</td></tr>
<tr><td><code id="emmip_+3A_style">style</code></td>
<td>
<p>Optional character value. This has an effect only when the
horizontal variable is a single numeric variable. If <code>style</code> is
unspecified or <code>"numeric"</code>, the horizontal scale will be numeric and
curves are plotted using lines (and no symbols). With <code>style =
"factor"</code>, the horizontal variable is treated as the levels of a factor
(equally spaced along the horizontal scale), and curves are plotted using
lines and symbols. When the horizontal variable is character or factor, or
a combination of more than one predictor, <code>"factor"</code> style is always used.</p>
</td></tr>
<tr><td><code id="emmip_+3A_engine">engine</code></td>
<td>
<p>Character value matching <code>"ggplot"</code> (default), 
<code>"lattice"</code>, or <code>"none"</code>. The graphics engine to be used to produce the plot.
These require, respectively, the <span class="pkg">ggplot2</span> or <span class="pkg">lattice</span> package to
be installed. Specifying <code>"none"</code> is equivalent to setting <code>plotit = FALSE</code>.</p>
</td></tr>
<tr><td><code id="emmip_+3A_plotit">plotit</code></td>
<td>
<p>Logical value. If <code>TRUE</code>, a graphical object is returned;
if <code>FALSE</code>, a data.frame is returned containing all the values
used to construct the plot.</p>
</td></tr>
<tr><td><code id="emmip_+3A_nesting.order">nesting.order</code></td>
<td>
<p>Logical value. If <code>TRUE</code>, factors that are nested
are presented in order according to their nesting factors, even if those nesting
factors are not present in <code>formula</code>. If <code>FALSE</code>, only the
variables in <code>formula</code> are used to order the variables.</p>
</td></tr>
<tr><td><code id="emmip_+3A_emms">emms</code></td>
<td>
<p>A <code>data.frame</code> created by calling <code>emmip</code> with
<code>plotit = FALSE</code>. Certain variables and attributes are expected
to exist in this data frame; see the section detailing the rendering functions.</p>
</td></tr>
<tr><td><code id="emmip_+3A_dodge">dodge</code></td>
<td>
<p>Numerical amount passed to <code>ggplot2::position_dodge</code> 
by which points and intervals are offset so they do not collide.</p>
</td></tr>
<tr><td><code id="emmip_+3A_xlab">xlab</code>, <code id="emmip_+3A_ylab">ylab</code>, <code id="emmip_+3A_tlab">tlab</code></td>
<td>
<p>Character labels for the horizontal axis, vertical
axis, and traces (the different curves), respectively. The <code>emmip</code>
function generates these automatically and provides therm via the <code>labs</code> 
attribute, but the user may override these if desired.</p>
</td></tr>
<tr><td><code id="emmip_+3A_facetlab">facetlab</code></td>
<td>
<p>Labeller for facets (when by variables are in play).
Use <code>"label_value"</code> to show just the factor levels, or <code>"label_both"</code>
to show both the factor names and factor levels. The default of
<code>"label_context"</code> decides which based on how many <code>by</code> factors there are.
See the documentation for <code>ggplot2::label_context</code>.</p>
</td></tr>
<tr><td><code id="emmip_+3A_scale">scale</code></td>
<td>
<p>If not missing, an object of class <code>scales::trans</code> specifying
a (usually) nonlinear scaling for the vertical axis. For example, 
<code>scales = scales::log_trans()</code> specifies a logarithmic scale. For
fine-tuning purposes, additional
arguments to <code>ggplot2::scale_y_continuous</code> may be included in <code>...</code> .</p>
</td></tr>
<tr><td><code id="emmip_+3A_dotarg">dotarg</code></td>
<td>
<p><code>list</code>
of arguments passed to <code>geom_point</code> to customize appearance of points</p>
</td></tr>
<tr><td><code id="emmip_+3A_linearg">linearg</code></td>
<td>
<p><code>list</code>
of arguments passed to <code>geom_line</code> to customize appearance of lines</p>
</td></tr>
<tr><td><code id="emmip_+3A_ciarg">CIarg</code>, <code id="emmip_+3A_piarg">PIarg</code></td>
<td>
<p><code>list</code>s
of arguments passed to <code>geom_linerange</code> to customize appearance of intervals.
(Note: the <code>linetype</code> aesthetic defaults to <code>"solid"</code> under the hood)</p>
</td></tr>
<tr><td><code id="emmip_+3A_col">col</code></td>
<td>
<p>With <code>emmip_ggplot</code>, this adds <code>color = col</code> (not
<code>colour</code>) to all of the <code>*arg</code> lists. This is intended for setting a
common color for everything, such as a black-and-white plot. 
With <code>emmip_lattice</code>, <code>col</code> specifies the colors to use
for each group, recycled as needed. If not specified, the default trellis
colors are used.</p>
</td></tr>
<tr><td><code id="emmip_+3A_pch">pch</code></td>
<td>
<p>(Lattice only) The plotting characters to use for each group (i.e., levels of
<code>trace.factors</code>). They are recycled as needed.</p>
</td></tr>
<tr><td><code id="emmip_+3A_lty">lty</code></td>
<td>
<p>(Lattice only) The line types to use for each group. Recycled as needed.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>If <code>plotit = FALSE</code>, a <code>data.frame</code> (actually, a
<code>summary_emm</code> object) with the table of EMMs that would be plotted.
The variables plotted are named <code>xvar</code> and <code>yvar</code>, and the trace
factor is named <code>tvar</code>. This data frame has an added <code>"labs"</code>
attribute containing the labels <code>xlab</code>, <code>ylab</code>, and <code>tlab</code>
for these respective variables. The confidence limits are also
included, renamed <code>LCL</code> and <code>UCL</code>.
</p>
<p>If <code>plotit = TRUE</code>, the function
returns an object of class <code>"ggplot"</code> or a <code>"trellis"</code>, depending
on <code>engine</code>.
</p>


<h3>Details</h3>

<p>If <code>object</code> is a fitted model, <code><a href="#topic+emmeans">emmeans</a></code> is called with an
appropriate specification to obtain estimated marginal means for each
combination of the factors present in <code>formula</code> (in addition, any 
arguments in <code>...</code> that match <code>at</code>, <code>trend</code>, 
<code>cov.reduce</code>, or <code>fac.reduce</code> are passed to <code>emmeans</code>). 
Otherwise, if <code>object</code> is an <code>emmGrid</code> object, its first element is 
used, and it must contain one estimate for each combination of the factors
present in <code>formula</code>.
</p>


<h3>Rendering functions</h3>

<p>The functions <code>emmip_ggplot</code> and <code>emmip_lattice</code>
are called when <code>plotit == TRUE</code> to render the plots; 
but they may also be called later on an object saved via <code>plotit = FALSE</code>
(or <code>engine = "none"</code>). The functions require that <code>emms</code> contains variables
<code>xvar</code>, <code>yvar</code>, and <code>tvar</code>, and attributes <code>"labs"</code> and <code>"vars"</code>.
Confidence intervals are plotted if variables <code>LCL</code> and <code>UCL</code> exist;
and prediction intervals are plotted if <code>LPL</code> and <code>UPL</code> exist.
Finally, it must contain the variables named in <code>attr(emms, "vars")</code>.
</p>
<p>In <code>emmip_ggplot</code>, colors, linetypes, and shapes are all assigned to
groups (according to <code>tvar</code>) unless overridden. So, for example, one may 
have different symbols for each group by simply specifying <code>dotarg = list()</code>.
</p>


<h3>Note</h3>

<p>Conceptually, this function is equivalent to 
<code><a href="stats.html#topic+interaction.plot">interaction.plot</a></code> where the summarization function is thought 
to return the EMMs.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+emmeans">emmeans</a></code>, <code><a href="stats.html#topic+interaction.plot">interaction.plot</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#--- Three-factor example
noise.lm = lm(noise ~ size * type * side, data = auto.noise)

# Separate interaction plots of size by type, for each side
emmip(noise.lm, type ~ size | side)

# One interaction plot, using combinations of size and side as the x factor
# ... with added confidence intervals and some formatting changes
emmip(noise.lm, type ~ side * size, CIs = TRUE,
    CIarg = list(lwd = 1, alpha = 1, color = "cyan"),
    dotarg = list(color = "black"))

# Create a black-and-white version of above with different linetypes
# (Let the linetypes and symbols default to the palette)
emmip(noise.lm, type ~ side * size, CIs = TRUE, col = "black",
      linearg = list(), dotarg = list(size = 2), CIarg = list(alpha = 1)) +
    ggplot2::theme_bw()

# One interaction plot using combinations of type and side as the trace factor
emmip(noise.lm, type * side ~ size)

# Individual traces in panels
emmip(noise.lm, ~ size | type * side)

# Example for the 'style' argument
fib.lm = lm(strength ~ machine * sqrt(diameter), data = fiber)
fib.rg = ref_grid(fib.lm, at = list(diameter = c(3.5, 4, 4.5, 5, 5.5, 6)^2))
emmip(fib.rg, machine ~ diameter)   # curves (because diameter is numeric)
emmip(fib.rg, machine ~ diameter, style = "factor")  # points and lines

# For an example using extra ggplot2 code, see 'vignette("messy-data")',
# in the section on nested models.

### Options with transformations or link functions
neuralgia.glm &lt;- glm(Pain ~ Treatment * Sex + Age, family = binomial(), 
                     data = neuralgia) 

# On link scale:
emmip(neuralgia.glm, Treatment ~ Sex)

# On response scale:
emmip(neuralgia.glm, Treatment ~ Sex, type = "response")

# With transformed axis scale and custom scale divisions
emmip(neuralgia.glm, Treatment ~ Sex, type = "scale",
    breaks = seq(0.10, 0.90, by = 0.10))
</code></pre>

<hr>
<h2 id='emmobj'>Construct an <code>emmGrid</code> object from scratch</h2><span id='topic+emmobj'></span>

<h3>Description</h3>

<p>This allows the user to incorporate results obtained by some analysis
into an <code>emmGrid</code> object, enabling the use of <code>emmGrid</code> methods
to perform related follow-up analyses.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>emmobj(bhat, V, levels, linfct = diag(length(bhat)), df = NA, dffun,
  dfargs = list(), post.beta = matrix(NA), nesting = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="emmobj_+3A_bhat">bhat</code></td>
<td>
<p>Numeric. Vector of regression coefficients</p>
</td></tr>
<tr><td><code id="emmobj_+3A_v">V</code></td>
<td>
<p>Square matrix. Covariance matrix of <code>bhat</code></p>
</td></tr>
<tr><td><code id="emmobj_+3A_levels">levels</code></td>
<td>
<p>Named list or vector. Levels of factor(s) that define the
estimates defined by <code>linfct</code>. If not a list, we assume one factor
named <code>"level"</code></p>
</td></tr>
<tr><td><code id="emmobj_+3A_linfct">linfct</code></td>
<td>
<p>Matrix. Linear functions of <code>bhat</code> for each combination 
of <code>levels</code>.</p>
</td></tr>
<tr><td><code id="emmobj_+3A_df">df</code></td>
<td>
<p>Numeric value or function with arguments <code>(x, dfargs)</code>. If a
number, that is used for the degrees of freedom. If a function, it should
return the degrees of freedom for <code>sum(x*bhat)</code>, with any additional
parameters in <code>dfargs</code>.</p>
</td></tr>
<tr><td><code id="emmobj_+3A_dffun">dffun</code></td>
<td>
<p>Overrides <code>df</code> if specified. This is a convenience
to match the slot names of the returned object.</p>
</td></tr>
<tr><td><code id="emmobj_+3A_dfargs">dfargs</code></td>
<td>
<p>List containing arguments for <code>df</code>.
This is ignored if df is numeric.</p>
</td></tr>
<tr><td><code id="emmobj_+3A_post.beta">post.beta</code></td>
<td>
<p>Matrix whose columns comprise a sample from the posterior
distribution of the regression coefficients (so that typically, the column
averages will be <code>bhat</code>). A 1 x 1 matrix of <code>NA</code> indicates that
such a sample is unavailable.</p>
</td></tr>
<tr><td><code id="emmobj_+3A_nesting">nesting</code></td>
<td>
<p>Nesting specification as in <code><a href="#topic+ref_grid">ref_grid</a></code>. This is
ignored if <code>model.info</code> is supplied.</p>
</td></tr>
<tr><td><code id="emmobj_+3A_...">...</code></td>
<td>
<p>Arguments passed to <code><a href="#topic+update.emmGrid">update.emmGrid</a></code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>The arguments must be conformable. This includes that the length of
<code>bhat</code>, the number of columns of <code>linfct</code>, and the number of
columns of <code>post.beta</code> must all be equal. And that the product of
lengths in <code>levels</code> must be equal to the number of rows of
<code>linfct</code>. The <code>grid</code> slot of the returned object is generated 
by <code><a href="base.html#topic+expand.grid">expand.grid</a></code> using <code>levels</code> as its arguments. So the
rows of <code>linfct</code> should be in corresponding order.
</p>
<p>The functions <code>qdrg</code> and <code><a href="#topic+emmobj">emmobj</a></code> are close cousins, in that
they both produce <code>emmGrid</code> objects. When starting with summary
statistics for an existing grid, <code>emmobj</code> is more useful, while
<code>qdrg</code> is more useful when starting from an unsupported fitted model.
</p>


<h3>Value</h3>

<p>An <code>emmGrid</code> object
</p>


<h3>See Also</h3>

<p><code><a href="#topic+qdrg">qdrg</a></code>, an alternative that is useful when starting 
with a fitted model not supported in <span class="pkg">emmeans</span>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Given summary statistics for 4 cells in a 2 x 2 layout, obtain 
# marginal means and comparisons thereof. Assume heteroscedasticity
# and use the Satterthwaite method
levels &lt;- list(trt = c("A", "B"), dose = c("high", "low"))
ybar &lt;- c(57.6, 43.2, 88.9, 69.8)
s &lt;-    c(12.1, 19.5, 22.8, 43.2)
n &lt;-    c(44,   11,   37,   24)
se2 = s^2 / n
Satt.df &lt;- function(x, dfargs)
    sum(x * dfargs$v)^2 / sum((x * dfargs$v)^2 / (dfargs$n - 1))
    
expt.rg &lt;- emmobj(bhat = ybar, V = diag(se2),
    levels = levels, linfct = diag(c(1, 1, 1, 1)),
    df = Satt.df, dfargs = list(v = se2, n = n), estName = "mean")
plot(expt.rg)

( trt.emm &lt;- emmeans(expt.rg, "trt") )
( dose.emm &lt;- emmeans(expt.rg, "dose") )

rbind(pairs(trt.emm), pairs(dose.emm), adjust = "mvt")
</code></pre>

<hr>
<h2 id='emtrends'>Estimated marginal means of linear trends</h2><span id='topic+emtrends'></span>

<h3>Description</h3>

<p>The <code>emtrends</code> function is useful when a fitted model involves a
numerical predictor <code class="reqn">x</code>  interacting with another predictor <code>a</code>
(typically a factor). Such models specify that <code class="reqn">x</code> has a different trend
depending on <code class="reqn">a</code>; thus, it may be of interest to estimate and compare
those trends. Analogous to the <code><a href="#topic+emmeans">emmeans</a></code> setting, we construct a
reference grid of these predicted trends, and then possibly average them over
some of the predictors in the grid.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>emtrends(object, specs, var, delta.var = 0.001 * rng, max.degree = 1, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="emtrends_+3A_object">object</code></td>
<td>
<p>A supported model object (<em>not</em> a reference grid)</p>
</td></tr>
<tr><td><code id="emtrends_+3A_specs">specs</code></td>
<td>
<p>Specifications for what marginal trends are desired &ndash; as in
<code><a href="#topic+emmeans">emmeans</a></code>. If <code>specs</code> is missing or <code>NULL</code>,
<code>emmeans</code> is not run and the reference grid for specified trends
is returned.</p>
</td></tr>
<tr><td><code id="emtrends_+3A_var">var</code></td>
<td>
<p>Character value giving the name of a variable with respect to 
which a difference quotient of the linear predictors is computed. In order
for this to be useful, <code>var</code> should be a numeric predictor that
interacts with at least one factor in <code>specs</code>. Then instead of
computing EMMs, we compute and compare the slopes of the <code>var</code> trend
over levels of the specified other predictor(s). As in EMMs, marginal
averages are computed for the predictors in <code>specs</code> and <code>by</code>.
See also the &ldquo;Generalizations&rdquo; section below.</p>
</td></tr>
<tr><td><code id="emtrends_+3A_delta.var">delta.var</code></td>
<td>
<p>The value of <em>h</em> to use in forming the difference
quotient <code class="reqn">(f(x+h) - f(x))/h</code>. Changing it (especially changing its
sign) may be necessary to avoid numerical problems such as logs of negative
numbers. The default value is 1/1000 of the range of <code>var</code> over the
dataset.</p>
</td></tr>
<tr><td><code id="emtrends_+3A_max.degree">max.degree</code></td>
<td>
<p>Integer value. The maximum degree of trends to compute (this
is capped at 5). If greater than 1, an additional factor <code>degree</code> is
added to the grid, with corresponding numerical derivatives of orders
<code>1, 2, ..., max.degree</code> as the estimates.</p>
</td></tr>
<tr><td><code id="emtrends_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to <code><a href="#topic+ref_grid">ref_grid</a></code> or 
<code><a href="#topic+emmeans">emmeans</a></code> as appropriate. See Details.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function works by constructing reference grids for <code>object</code> with 
various values of <code>var</code>, and then calculating difference quotients of predictions
from those reference grids. Finally, <code><a href="#topic+emmeans">emmeans</a></code> is called with
the given <code>specs</code>, thus computing marginal averages as needed of
the difference quotients. Any <code>...</code> arguments are passed to the
<code>ref_grid</code> and <code><a href="#topic+emmeans">emmeans</a></code>; examples of such optional
arguments include optional arguments (often <code>mode</code>) that apply to
specific models; <code>ref_grid</code> options such as <code>data</code>, <code>at</code>,
<code>cov.reduce</code>, <code>mult.names</code>, <code>nesting</code>, or <code>transform</code>;
and <code>emmeans</code> options such as <code>weights</code> (but please avoid
<code>trend</code> or <code>offset</code>.
</p>


<h3>Value</h3>

<p>An <code>emmGrid</code> or <code>emm_list</code> object, according to <code>specs</code>.
See <code><a href="#topic+emmeans">emmeans</a></code> for more details on when a list is returned.
</p>


<h3>Generalizations</h3>

<p>Instead of a single predictor, the user may specify some monotone function of
one variable, e.g., <code>var = "log(dose)"</code>. If so, the chain rule is
applied. Note that, in this example, if <code>object</code> contains
<code>log(dose)</code> as a predictor, we will be comparing the slopes estimated by
that model, whereas specifying <code>var = "dose"</code> would perform a
transformation of those slopes, making the predicted trends vary depending on
<code>dose</code>.
</p>


<h3>Note</h3>

<p>In earlier versions of <code>emtrends</code>, the first argument was named
<code>model</code> rather than <code>object</code>. (The name was changed because of
potential mis-matching with a <code>mode</code> argument, which is an option for
several types of models.) For backward compatibility, <code>model</code> still works
<em>provided all arguments are named</em>.
</p>
<p>It is important to understand that trends computed by <code>emtrends</code> are
<em>not</em> equivalent to polynomial contrasts in a parallel model where
<code>var</code> is regarded as a factor. That is because the model <code>object</code>
here is assumed to fit a smooth function of <code>var</code>, and the estimated
trends reflect <em>local</em> behavior at particular value(s) of <code>var</code>;
whereas when <code>var</code> is modeled as a factor and polynomial contrasts are
computed, those contrasts represent the <em>global</em> pattern of changes over
<em>all</em> levels of <code>var</code>. 
</p>
<p>See the <code>pigs.poly</code> and <code>pigs.fact</code> examples below for an
illustration. The linear and quadratic trends depend on the value of 
<code>percent</code>, but the cubic trend is constant (because that is true of
a cubic polynomial, which is the underlying model). The cubic contrast
in the factorial model has the same P value as for the cubic trend,
again because the cubic trend is the same everywhere.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+emmeans">emmeans</a></code>, <code><a href="#topic+ref_grid">ref_grid</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>fiber.lm &lt;- lm(strength ~ diameter*machine, data=fiber)
# Obtain slopes for each machine ...
( fiber.emt &lt;- emtrends(fiber.lm, "machine", var = "diameter") )
# ... and pairwise comparisons thereof
pairs(fiber.emt)

# Suppose we want trends relative to sqrt(diameter)...
emtrends(fiber.lm, ~ machine | diameter, var = "sqrt(diameter)", 
         at = list(diameter = c(20, 30)))

# Obtaining a reference grid
mtcars.lm &lt;- lm(mpg ~ poly(disp, degree = 2) * (factor(cyl) + factor(am)), data = mtcars)

# Center trends at mean disp for each no. of cylinders
mtcTrends.rg &lt;- emtrends(mtcars.lm, var = "disp", 
                          cov.reduce = disp ~ factor(cyl))
summary(mtcTrends.rg)  # estimated trends at grid nodes
emmeans(mtcTrends.rg, "am", weights = "prop")


### Higher-degree trends ...

pigs.poly &lt;- lm(conc ~ poly(percent, degree = 3), data = pigs)
emt &lt;- emtrends(pigs.poly, ~ degree | percent, "percent", max.degree = 3,
                at = list(percent = c(9, 13.5, 18)))
       # note: 'degree' is an extra factor created by 'emtrends'
       
summary(emt, infer = c(TRUE, TRUE))

# Compare above results with poly contrasts when 'percent' is modeled as a factor ...
pigs.fact &lt;- lm(conc ~ factor(percent), data = pigs)
emm &lt;- emmeans(pigs.fact, "percent")

contrast(emm, "poly")
# Some P values are comparable, some aren't! See Note in documentation
</code></pre>

<hr>
<h2 id='extending-emmeans'>Support functions for model extensions</h2><span id='topic+extending-emmeans'></span><span id='topic+recover_data'></span><span id='topic+recover_data.call'></span><span id='topic+emm_basis'></span><span id='topic+.recover_data'></span><span id='topic+.emm_basis'></span><span id='topic+.emm_register'></span><span id='topic+.std.link.labels'></span><span id='topic+.combine.terms'></span><span id='topic+.aovlist.dffun'></span><span id='topic+.cmpMM'></span><span id='topic+.get.excl'></span><span id='topic+.get.offset'></span><span id='topic+.my.vcov'></span><span id='topic+.all.vars'></span><span id='topic+.diag'></span><span id='topic+.num.key'></span><span id='topic+.emm_vignette'></span><span id='topic+.hurdle.support'></span><span id='topic+.zi.support'></span>

<h3>Description</h3>

<p>This documents some functions and methods that may be useful to package 
developers wishing to add support for <span class="pkg">emmeans</span> for their model objects.A user
or package developer may add <span class="pkg">emmeans</span> support for a model
class by writing <code>recover_data</code> and <code>emm_basis</code> methods
for that class. (Users in need for a quick way to obtain results for a model
that is not supported may be better served by the <code><a href="#topic+qdrg">qdrg</a></code> function.)
There are several other exported functions that may be useful. See the
&quot;xtending&quot; vignette for more details.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>recover_data(object, ...)

## S3 method for class 'call'
recover_data(object, trms, na.action, data = NULL,
  params = "pi", frame, pwts, addl.vars, ...)

emm_basis(object, trms, xlev, grid, ...)

.recover_data(object, ...)

.emm_basis(object, trms, xlev, grid, ...)

.emm_register(classes, pkgname)

.std.link.labels(fam, misc)

.combine.terms(...)

.aovlist.dffun(k, dfargs)

.cmpMM(X, weights = rep(1, nrow(X)), assign = attr(X$qr, "assign"))

.get.excl(levs, exc, inc)

.get.offset(terms, grid)

.my.vcov(object, vcov. = .statsvcov, ...)

.all.vars(expr, retain = c("\\$", "\\[\\[", "\\]\\]", "'", "\""),
  ...)

.diag(x, nrow, ncol)

.num.key(levs, key)

.emm_vignette(css = system.file("css", "clean-simple.css", package =
  "emmeans"), highlight = NULL, ...)

.hurdle.support(cmu, cshape, cp0, cmean, zmu, zshape, zp0)

.zi.support(zmu, zshape, zp0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="extending-emmeans_+3A_object">object</code></td>
<td>
<p>An object of the same class as is supported by a new method.</p>
</td></tr>
<tr><td><code id="extending-emmeans_+3A_...">...</code></td>
<td>
<p>Additional parameters that may be supported by the method.</p>
</td></tr>
<tr><td><code id="extending-emmeans_+3A_trms">trms</code></td>
<td>
<p>The <code><a href="stats.html#topic+terms">terms</a></code> component of <code>object</code> (typically with
the response deleted, e.g. via <code><a href="stats.html#topic+delete.response">delete.response</a></code>)</p>
</td></tr>
<tr><td><code id="extending-emmeans_+3A_na.action">na.action</code></td>
<td>
<p>Integer vector of indices of observations to ignore; or
<code>NULL</code> if none</p>
</td></tr>
<tr><td><code id="extending-emmeans_+3A_data">data</code></td>
<td>
<p>Data frame. Usually, this is <code>NULL</code>. However, if non-null,
this is used in place of the reconstructed dataset. It must have all of the
predictors used in the model, and any factor levels must match those used
in fitting the model.</p>
</td></tr>
<tr><td><code id="extending-emmeans_+3A_params">params</code></td>
<td>
<p>Character vector giving the names of any variables in the model
formula that are <em>not</em> predictors. For example, a spline model may involve
a local variable <code>knots</code> that is not a predictor, but its value is
needed to fit the model. Names of parameters not actually used are harmless,
and the default value <code>"pi"</code> (the only numeric constant in base R)
is provided in case the model involves it. An example involving splines
may be found at <a href="https://github.com/rvlenth/emmeans/issues/180">https://github.com/rvlenth/emmeans/issues/180</a>.</p>
</td></tr>
<tr><td><code id="extending-emmeans_+3A_frame">frame</code></td>
<td>
<p>Optional <code>data.frame</code>. Many model objects contain the 
model frame used when fitting the model. In cases where there are no 
predictor transformations, this model frame has all the original predictor
values and so is usable for recovering the data. Thus, if <code>frame</code> is
non-missing and <code>data</code> is <code>NULL</code>, a check is made on <code>trms</code>
and if there are no function calls, we use <code>data = frame</code>. This
can be helpful because it provides a modicum of security against the
possibility that the original data used when fitting the model has been
altered or removed.</p>
</td></tr>
<tr><td><code id="extending-emmeans_+3A_pwts">pwts</code></td>
<td>
<p>Optional vector of prior weights. Typically, this may be obtained
from the fitted <code>model</code> via <code>weights(model)</code>. If this is provided,
it is used to set weights as long as it is non-<code>NULL</code> and the same length 
as the number of rows of the data.</p>
</td></tr>
<tr><td><code id="extending-emmeans_+3A_addl.vars">addl.vars</code></td>
<td>
<p>Character value or vector specifying additional predictors
to include in the reference grid. These must be names of variables that
exist, or you will get an error. 
This may be useful if you need to do
additional computations later on that depend on these variables; e.g., 
bias adjustments for random slopes of variables not among the fixed predictors.</p>
</td></tr>
<tr><td><code id="extending-emmeans_+3A_xlev">xlev</code></td>
<td>
<p>Named list of factor levels (<em>excluding</em> ones coerced to 
factors in the model formula)</p>
</td></tr>
<tr><td><code id="extending-emmeans_+3A_grid">grid</code></td>
<td>
<p>A <code>data.frame</code> (provided by <code>ref_grid</code>) containing 
the predictor settings needed in the reference grid</p>
</td></tr>
<tr><td><code id="extending-emmeans_+3A_classes">classes</code></td>
<td>
<p>Character names of one or more classes to be registered.
The package must contain the functions <code>recover_data.foo</code> and
<code>emm_basis.foo</code> for each class <code>foo</code> listed in <code>classes</code>.</p>
</td></tr>
<tr><td><code id="extending-emmeans_+3A_pkgname">pkgname</code></td>
<td>
<p>Character name of package providing the methods (usually
should be the second argument of <code>.onLoad</code>)</p>
</td></tr>
<tr><td><code id="extending-emmeans_+3A_fam">fam</code></td>
<td>
<p>Result of call to <code>family(object)</code></p>
</td></tr>
<tr><td><code id="extending-emmeans_+3A_misc">misc</code></td>
<td>
<p>A <code>list</code> intended for the <code>@misc</code> slot of an <code>emmGrid</code> object</p>
</td></tr>
<tr><td><code id="extending-emmeans_+3A_k">k</code>, <code id="extending-emmeans_+3A_dfargs">dfargs</code></td>
<td>
<p>Arguments to <code>.aovlist.dffun</code>, which is made available as a 
convenience to developers providing support similar to that provided for 
<code>aovlist</code> objects</p>
</td></tr>
<tr><td><code id="extending-emmeans_+3A_x">X</code>, <code id="extending-emmeans_+3A_weights">weights</code>, <code id="extending-emmeans_+3A_assign">assign</code></td>
<td>
<p>Arguments for <code>.cmpMM</code>, which compacts a model
matrix <code>X</code> into a much smaller matrix that has the same row space.
Specifically, it returns the R portion of its QR decomposition. If <code>X</code>
is already of class <code>qr</code>, it is used directly. <code>weights</code> should be
the weights used in the model fit, and <code>assign</code> is used for unravelling
any pivoting done by <code><a href="base.html#topic+qr">qr</a></code>.</p>
</td></tr>
<tr><td><code id="extending-emmeans_+3A_levs">levs</code>, <code id="extending-emmeans_+3A_key">key</code></td>
<td>
<p>The <code>.num.key</code> function returns the numeric indices of
the levels in <code>levs</code> to the set of all levels in <code>key</code></p>
</td></tr>
<tr><td><code id="extending-emmeans_+3A_exc">exc</code>, <code id="extending-emmeans_+3A_inc">inc</code></td>
<td>
<p>Arguments for <code>.get.excl</code> which is useful
in writing <code>.emmc</code> functions for generating contrast coefficients,
and supports arguments <code>exclude</code> or <code>include</code> for excluding
or specifying which levels to use.</p>
</td></tr>
<tr><td><code id="extending-emmeans_+3A_terms">terms</code></td>
<td>
<p>A <code>terms</code> component</p>
</td></tr>
<tr><td><code id="extending-emmeans_+3A_vcov.">vcov.</code></td>
<td>
<p>Function or matrix that returns a suitable covariance matrix.
The default is <code>.statsvcov</code> which is <code>stats::vcov</code>. The <code>.my.vcov</code> 
function should be called in place of <code><a href="stats.html#topic+vcov">vcov</a></code>, and it supports the user 
being able to specify a different matrix or function via the
optional <code>vcov.</code> argument.</p>
</td></tr>
<tr><td><code id="extending-emmeans_+3A_expr">expr</code>, <code id="extending-emmeans_+3A_retain">retain</code></td>
<td>
<p>Arguments for <code>.all.vars</code>, which is an alternative to <code><a href="base.html#topic+all.vars">all.vars</a></code>
that has special provisions for retaining the special characters in <code>retain</code>,
thus allowing model specifications like <code>y ~ data$trt * df[["dose"]]</code></p>
</td></tr>
<tr><td><code id="extending-emmeans_+3A_x">x</code>, <code id="extending-emmeans_+3A_nrow">nrow</code>, <code id="extending-emmeans_+3A_ncol">ncol</code></td>
<td>
<p>Arguments for <code>.diag</code>, which is an alternative to 
<code><a href="base.html#topic+diag">diag</a></code> that lacks its idiosyncrasy of returning an
identity matrix when <code>x</code> is of length 1.</p>
</td></tr>
<tr><td><code id="extending-emmeans_+3A_css">css</code>, <code id="extending-emmeans_+3A_package">package</code>, <code id="extending-emmeans_+3A_highlight">highlight</code></td>
<td>
<p>Arguments for <code>.emm_vignette</code>, which is
a clean and simple alternative to such as <code>html_document</code> for use
as the output style of a Markdown file. All the vignettes in the
<span class="pkg">emmeans</span> package use this output style.</p>
</td></tr>
<tr><td><code id="extending-emmeans_+3A_cmu">cmu</code>, <code id="extending-emmeans_+3A_zmu">zmu</code></td>
<td>
<p>In <code>.hurdle.support</code> and <code>.zi.support</code>, 
these specify a vector of back-transformed 
estimates for the count and zero model, respectively</p>
</td></tr>
<tr><td><code id="extending-emmeans_+3A_cshape">cshape</code>, <code id="extending-emmeans_+3A_zshape">zshape</code></td>
<td>
<p>Shape parameter for the count and zero model, respectively</p>
</td></tr>
<tr><td><code id="extending-emmeans_+3A_cp0">cp0</code>, <code id="extending-emmeans_+3A_zp0">zp0</code></td>
<td>
<p>Function of <code>(mu, shape)</code> for computing Prob(Y = 0)
for the count and zero model, respectively</p>
</td></tr>
<tr><td><code id="extending-emmeans_+3A_cmean">cmean</code></td>
<td>
<p>Function of <code>(mu, shape)</code> for computing the mean of the
count model. Typically, this just returns <code>mu</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>The <code>recover_data</code> method must return a <code><a href="base.html#topic+data.frame">data.frame</a></code>
containing all the variables that appear as predictors in the model,
and attributes <code>"call"</code>, <code>"terms"</code>, <code>"predictors"</code>,
and <code>"responses"</code>. (<code>recover_data.call</code> will 
provide these attributes.)
</p>
<p>The <code>emm_basis</code> method should return a <code>list</code> with the
following elements:
</p>

<dl>
<dt>X</dt><dd><p>The matrix of linear functions over <code>grid</code>, having the same
number of rows as <code>grid</code> and the number of columns equal to the length
of <code>bhat</code>.</p>
</dd>
<dt>bhat</dt><dd><p>The vector of regression coefficients for fixed effects. This
should <em>include</em> any <code>NA</code>s that result from rank deficiencies.</p>
</dd>
<dt>nbasis</dt><dd><p>A matrix whose columns form a basis for non-estimable functions
of beta, or a 1x1 matrix of <code>NA</code> if there is no rank deficiency.</p>
</dd>
<dt>V</dt><dd><p>The estimated covariance matrix of <code>bhat</code>.</p>
</dd>
<dt>dffun</dt><dd><p>A function of <code>(k, dfargs)</code> that returns the degrees of
freedom associated with <code>sum(k * bhat)</code>.</p>
</dd>
<dt>dfargs</dt><dd><p>A <code>list</code> containing additional arguments needed for
<code>dffun</code></p>
</dd></dl>
<p>.
 
</p>
<p><code>.recover_data</code> and <code>.emm_basis</code> are hidden exported versions of 
<code>recover_data</code> and <code>emm_basis</code>, respectively. They run in <span class="pkg">emmeans</span>'s
namespace, thus providing access to all existing methods.
</p>
<p><code>.std.link.llabels</code> returns a modified version of <code>misc</code>
with the appropriate information included corresponding to the information in <code>fam</code>
</p>
<p><code>combine.terms</code> returns a <code>terms</code> object resulting
from combining all the terms or formulas in <code>...</code>.
</p>
<p><code>.get.offset</code> returns the values, based on <code>grid</code>, of 
any <code>offset</code> component in <code>terms</code>
</p>
<p><code>.hurdle.support</code> returns a matrix with 3 rows containing the
estimated mean responses and the differentials wrt <code>cmu</code> and <code>zmu</code>,
resp.
</p>
<p><code>.zi.support</code> returns a matrix with 2 rows containing the
estimated probabilities of 0 and the differentials wrt <code>mu</code>.
See the section on hurdle and zero-inflated models.
</p>


<h3>Details</h3>

<p>To create a reference grid, the <code>ref_grid</code> function needs to reconstruct
the data used in fitting the model, and then obtain a matrix of linear
functions of the regression coefficients for a given grid of predictor
values. These tasks are performed by calls to <code>recover_data</code> and
<code>emm_basis</code> respectively. A vignette giving details and examples
is available via <a href="../doc/xtending.html">vignette(&quot;xtending&quot;, &quot;emmeans&quot;)</a>
</p>
<p>To extend <span class="pkg">emmeans</span>'s support to additional model types, one need only
write S3 methods for these two functions. The existing methods serve as
helpful guidance for writing new ones.  Most of the work for
<code>recover_data</code> can be done by its method for class <code>"call"</code>,
providing the <code>terms</code> component and <code>na.action</code> data as additional
arguments. Writing an <code>emm_basis</code> method is more involved, but the
existing methods (e.g., <code>emmeans:::emm_basis.lm</code>) can serve as models.
Certain <code>recover_data</code> and <code>emm_basis</code> methods are exported from
<span class="pkg">emmeans</span>. (To find out, do <code>methods("recover_data")</code>.) If your
object is based on another model-fitting object, it
may be that all that is needed is to call one of these exported methods and
perhaps make modifications to the results. Contact the developer if you need
others of these exported.
</p>
<p>If the model has a multivariate response, <code>bhat</code> needs to be
&ldquo;flattened&rdquo; into a single vector, and <code>X</code> and <code>V</code> must be
constructed consistently.
</p>
<p>In models where a non-full-rank result is possible (often, you can tell by
seeing if there is a <code>singular.ok</code> argument in the model-fitting
function), <code><a href="#topic+summary.emmGrid">summary.emmGrid</a></code> and its relatives check the
estimability of each
prediction, using the <code><a href="estimability.html#topic+nonest.basis">nonest.basis</a></code> function in
the <span class="pkg">estimability</span> package.
</p>
<p>The models already supported are detailed in <a href="../doc/models.html">the
&quot;models&quot; vignette</a>. Some packages may provide additional <span class="pkg">emmeans</span>
support for its object classes.
</p>


<h3>Communication between methods</h3>

<p>If the <code>recover_data</code> method generates information needed by <code>emm_basis</code>,
that information may be incorporated by creating a <code>"misc"</code> attribute in the
returned recovered data. That information is then passed as the <code>misc</code> 
argument when <code>ref_grid</code> calls <code>emm_basis</code>.
</p>


<h3>Optional hooks</h3>

<p>Some models may need something other than standard linear estimates and
standard errors. If so, custom functions may be pointed to via the items
<code>misc$estHook</code>, <code>misc$vcovHook</code> and <code>misc$postGridHook</code>. If
just the name of the hook function is provided as a character string, then it
is retrieved using <code><a href="base.html#topic+get">get</a></code>.
</p>
<p>The <code>estHook</code> function should have arguments &lsquo;<span class="samp">&#8288;(object, do.se, tol,
...)&#8288;</span>&rsquo; where <code>object</code> is the <code>emmGrid</code> object,
<code>do.se</code> is a logical flag for whether to return the standard error, and
<code>tol</code> is the tolerance for assessing estimability. It should return a
matrix with 3 columns: the estimates, standard errors (<code>NA</code> when
<code>do.se==FALSE</code>), and degrees of freedom (<code>NA</code> for asymptotic). The
number of rows should be the same as &lsquo;<span class="samp">&#8288;object@linfct&#8288;</span>&rsquo;. The
<code>vcovHook</code> function should have arguments &lsquo;<span class="samp">&#8288;(object, tol, ...)&#8288;</span>&rsquo; as
described. It should return the covariance matrix for the estimates. Finally,
<code>postGridHook</code>, if present, is called at the very end of
<code>ref_grid</code>; it takes one argument, the constructed <code>object</code>, and
should return a suitably modified <code>emmGrid</code> object.
</p>


<h3>Registering S3 methods for a model class</h3>

<p>The <code>.emm_register</code> function is provided as a convenience to conditionally 
register your
S3 methods for a model class, <code>recover_data.foo</code> and <code>emm_basis.foo</code>,
where <code>foo</code> is the class name. Your package should implement an
<code>.onLoad</code> function and call <code>.emm_register</code> if <span class="pkg">emmeans</span> is
installed. See the example.
</p>


<h3>Support for Hurdle and Zero-inflated models</h3>

<p>The functions <code>.hurdle.support</code> and <code>.zi.support</code> help facilitate
calculations needed to estimate the mean response (count model and zero model
combined) of these models. <code>.hurdle.support</code> returns a matrix of three rows.
The first is the estimated mean for a hurdle model, and the 2nd and 3rd rows are
differentials for the count and zero models, which needed for delta-method
calculations. To use these, regard the <code>@linfct</code> slot as comprising
two sets of columns, for the count and zero models respectively. To do
the delta method calculations, multiply the rows of the count part by its 
differentials times <code>link$mu.eta</code> evcaluated at that part of the linear predictor.
Do the same for the zero part, using its differentials and <code>mu.eta</code>.
If the resulting matrix is <b>A</b>, then the covariance of the mean response
is <b>AVA'</b> where <b>V</b>is the <code>@V</code> slot of the object.
</p>
<p>The function <code>zi.support</code> works the same way, only it is much simpler,
and is used to estimate the probability of 0 and its differential for either 
part of a zero-inflated model or hurdle model.
</p>
<p>See the code for <code>emm_basis.zeroinfl</code> and <code>emm_basis.hurdle</code>
for how these are used with models fitted by the <span class="pkg">pscl</span> package.
</p>


<h3>Note</h3>

<p>Without an explicit <code>data</code> argument, <code>recover_data</code> returns
the <em>current version</em> of the dataset. If the dataset has changed
since the model was fitted, then this will not be the data used to fit
the model. It is especially important to know this in simulation studies
where the data are randomly generated or permuted, and in cases where
several datasets are processed in one step (e.g., using <code>dplyr</code>).
In those cases, users should be careful to provide the actual data
used to fit the model in the <code>data</code> argument.
</p>


<h3>See Also</h3>

<p><a href="../doc/xtending.html">Vignette on extending emmeans</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
#--- If your package provides recover_data and emm_grid methods for class 'mymod',
#--- put something like this in your package code -- say in zzz.R:
  .onLoad &lt;- function(libname, pkgname) {
    if (requireNamespace("emmeans", quietly = TRUE))
      emmeans::.emm_register("mymod", pkgname)
  }

## End(Not run)
</code></pre>

<hr>
<h2 id='feedlot'>Feedlot data</h2><span id='topic+feedlot'></span>

<h3>Description</h3>

<p>This is an unbalanced analysis-of-covariance example, where one covariate is
affected by a factor. Feeder calves from various herds enter a feedlot, where
they are fed one of three diets. The weight of the animal at entry is the
covariate, and the weight at slaughter is the response.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>feedlot
</code></pre>


<h3>Format</h3>

<p>A data frame with 67 observations and 4 variables:
</p>

<dl>
<dt><code>herd</code></dt><dd><p>a factor with levels <code>9</code> <code>16</code> <code>3</code>
<code>32</code> <code>24</code> <code>31</code> <code>19</code> <code>36</code> <code>34</code> <code>35</code>
<code>33</code>, designating the herd that a feeder calf came from.</p>
</dd>
<dt><code>diet</code></dt><dd><p>a factor with levels <code>Low</code> <code>Medium</code>
<code>High</code>: the energy level of the diet given the animal.</p>
</dd>
<dt><code>swt</code></dt><dd><p>a numeric vector: the weight of the animal at slaughter.</p>
</dd>
<dt><code>ewt</code></dt><dd><p>a numeric vector: the weight of the animal at entry to the feedlot.</p>
</dd>
</dl>



<h3>Details</h3>

<p>The data arise from a Western Regional Research Project conducted at New
Mexico State University. Calves born in 1975 in commercial herds entered a
feedlot as yearlings. Both diets and herds are of interest as factors. The
covariate, <code>ewt</code>, is thought to be dependent on <code>herd</code> due to
different genetic backgrounds, breeding history, etc. The levels of
<code>herd</code> ordered to similarity of genetic background.
</p>
<p>Note: There are some empty cells in the cross-classification of 
<code>herd</code> and <code>diet</code>.
</p>


<h3>Source</h3>

<p>Urquhart NS (1982) Adjustment in covariates when one factor affects
the covariate. <em>Biometrics</em> 38, 651-660.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>feedlot.lm &lt;- lm(swt ~ ewt + herd*diet, data = feedlot)

# Obtain EMMs with a separate reference value of ewt for each 
# herd. This reproduces the last part of Table 2 in the reference
emmeans(feedlot.lm,  ~ diet | herd,  cov.reduce = ewt ~ herd)

</code></pre>

<hr>
<h2 id='fiber'>Fiber data</h2><span id='topic+fiber'></span>

<h3>Description</h3>

<p>Fiber data from Montgomery Design (8th ed.), p.656 (Table 15.10). Useful as a
simple analysis-of-covariance example.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fiber
</code></pre>


<h3>Format</h3>

<p>A data frame with 15 observations and 3 variables:
</p>

<dl>
<dt><code>machine</code></dt><dd><p>a factor with levels <code>A</code> <code>B</code> <code>C</code>. 
This is the primary factor of interest.</p>
</dd>
<dt><code>strength</code></dt><dd><p>a numeric vector. The response variable.</p>
</dd>
<dt><code>diameter</code></dt><dd><p>a numeric vector. A covariate.</p>
</dd>
</dl>



<h3>Details</h3>

<p>The goal of the experiment is to compare the mean breaking strength of fibers
produced by the three machines. When testing this, the technician also
measured the diameter of each fiber, and this measurement may be used as a
concomitant variable to improve precision of the estimates.
</p>


<h3>Source</h3>

<p>Montgomery, D. C. (2013) <em>Design and Analysis of Experiments</em>
(8th ed.). John Wiley and Sons, ISBN 978-1-118-14692-7.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>fiber.lm &lt;- lm(strength ~ diameter + machine, data=fiber)
ref_grid(fiber.lm)

# Covariate-adjusted means and comparisons
emmeans(fiber.lm, pairwise ~ machine)

</code></pre>

<hr>
<h2 id='hpd.summary'>Summarize an emmGrid from a Bayesian model</h2><span id='topic+hpd.summary'></span>

<h3>Description</h3>

<p>This function computes point estimates and HPD intervals for each
factor combination in <code>object@emmGrid</code>. While this function
may be called independently, it is called automatically by the S3 method
<code><a href="#topic+summary.emmGrid">summary.emmGrid</a></code> when the object is based on a Bayesian model.
(Note: the <code>level</code> argument, or its default, is passed as <code>prob</code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hpd.summary(object, prob, by, type, point.est = median, delta,
  bias.adjust = get_emm_option("back.bias.adj"), sigma, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="hpd.summary_+3A_object">object</code></td>
<td>
<p>an <code>emmGrid</code> object having a non-missing <code>post.beta</code> slot</p>
</td></tr>
<tr><td><code id="hpd.summary_+3A_prob">prob</code></td>
<td>
<p>numeric probability content for HPD intervals (note: when not specified,
the current <code>level</code> option is used; see <code><a href="#topic+emm_options">emm_options</a></code>)</p>
</td></tr>
<tr><td><code id="hpd.summary_+3A_by">by</code></td>
<td>
<p>factors to use as <code>by</code> variables</p>
</td></tr>
<tr><td><code id="hpd.summary_+3A_type">type</code></td>
<td>
<p>prediction type as in <code><a href="#topic+summary.emmGrid">summary.emmGrid</a></code></p>
</td></tr>
<tr><td><code id="hpd.summary_+3A_point.est">point.est</code></td>
<td>
<p>function to use to compute the point estimates from the 
posterior sample for each grid point</p>
</td></tr>
<tr><td><code id="hpd.summary_+3A_delta">delta</code></td>
<td>
<p>Numeric equivalence threshold (on the linear predictor scale 
regardless of <code>type</code>).
See the section below on equivalence testing.</p>
</td></tr>
<tr><td><code id="hpd.summary_+3A_bias.adjust">bias.adjust</code></td>
<td>
<p>Logical value for whether to adjust for bias in
back-transforming (<code>type = "response"</code>). This requires a value of 
<code>sigma</code> to exist in the object or be specified.</p>
</td></tr>
<tr><td><code id="hpd.summary_+3A_sigma">sigma</code></td>
<td>
<p>Error SD assumed for bias correction (when 
<code>type = "response"</code>. If not specified,
<code>object@misc$sigma</code> is used, and a warning if it is not found or invalid.
<em>Note:</em> <code>sigma</code> may be a vector, as long as it conforms to the 
number of observations in the posterior sample.</p>
</td></tr>
<tr><td><code id="hpd.summary_+3A_...">...</code></td>
<td>
<p>required but not used</p>
</td></tr>
</table>


<h3>Value</h3>

<p>an object of class <code>summary_emm</code>
</p>


<h3>Equivalence testing note</h3>

<p>If <code>delta</code> is positive, two columns labeled <code>p.equiv</code> and
<code>odds.eq</code> are appended to the summary. <code>p.equiv</code> is the fraction
of posterior estimates having absolute values less than <code>delta</code>. The
<code>odds.eq</code> column is just <code>p.equiv</code> converted to an odds ratio; so
it is the posterior odds of equivalence.
</p>
<p>A high value of <code>p.equiv</code> is evidence
in favor of equivalence. It can be used to obtain something equivalent
(in spirit) to the frequentist Schuirmann (TOST) procedure, whereby we would
conclude equivalence at significance level <code class="reqn">\alpha</code> if the <code class="reqn">(1 - 2\alpha)</code>
confidence interval falls entirely in the interval <code class="reqn">[-\delta, \delta]</code>.
Similarly in the Bayesian context, an equally strong argument for
equivalence is obtained if <code>p.equiv</code> exceeds <code class="reqn">1 - 2\alpha</code>.
</p>
<p>A closely related quantity is the ROPE (region of practical equivalence),
obtainable via <code>bayestestR::rope(object, range = c(-delta, delta))</code>.
Its value is approximately <code>100 * p.equiv / 0.95</code> if the default
<code>ci = 0.95</code> is used. See also <span class="pkg">bayestestR</span>'s 
<a href="https://github.com/easystats/bayestestR/issues/567">issue #567</a>.
</p>
<p>Finally, a Bayes factor for equivalence is obtainable by dividing 
<code>odds.eq</code> by the prior odds of equivalence, assessed or elicited separately.
</p>


<h3>See Also</h3>

<p>summary.emmGrid
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if(require("coda")) 
    emm_example("hpd.summary-coda")
    # Use emm_example("hpd.summary-coda", list = TRUE) # to see just the code

</code></pre>

<hr>
<h2 id='joint_tests'>Compute joint tests of the terms in a model</h2><span id='topic+joint_tests'></span><span id='topic+make.meanint'></span><span id='topic+meanint'></span><span id='topic+make.symmint'></span><span id='topic+symmint'></span>

<h3>Description</h3>

<p>This function produces an analysis-of-variance-like table based on linear
functions of predictors in a model or <code>emmGrid</code> object. Specifically,
the function constructs, for each combination of factors (or covariates
reduced to two or more levels), a set of (interaction) contrasts via
<code><a href="#topic+contrast">contrast</a></code>, and then tests them using <code><a href="#topic+test">test</a></code> with
<code>joint = TRUE</code>. Optionally, one or more of the predictors may be used as
<code>by</code> variable(s), so that separate tables of tests are produced for
each combination of them.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>joint_tests(object, by = NULL, show0df = FALSE, showconf = TRUE,
  cov.reduce = make.meanint(1), ...)

make.meanint(delta)

meanint(x)

make.symmint(ctr, delta)

symmint(ctr)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="joint_tests_+3A_object">object</code></td>
<td>
<p>a fitted model, <code>emmGrid</code>, or <code>emm_list</code>. If the
latter, its first element is used.</p>
</td></tr>
<tr><td><code id="joint_tests_+3A_by">by</code></td>
<td>
<p>character names of <code>by</code> variables. Separate sets of tests are
run for each combination of these.</p>
</td></tr>
<tr><td><code id="joint_tests_+3A_show0df">show0df</code></td>
<td>
<p>logical value; if <code>TRUE</code>, results with zero numerator
degrees of freedom are displayed, if <code>FALSE</code> they are skipped</p>
</td></tr>
<tr><td><code id="joint_tests_+3A_showconf">showconf</code></td>
<td>
<p>logical value.
When we have models with estimability issues (e.g., missing cells), then with
<code>showconf = TRUE</code>, we test any remaining effects that are not purely
due to contrasts of a single term. If found, they are labeled
<code>(confounded)</code>. See
<code>vignette("xplanations")</code> for more information.</p>
</td></tr>
<tr><td><code id="joint_tests_+3A_cov.reduce">cov.reduce</code></td>
<td>
<p>a function.
If <code>object</code> is a fitted model, it is
replaced by <code>ref_grid(object, cov.reduce = cov.reduce, ...)</code>.
For this purpose, the functions <code>meanint</code> and <code>symmint</code> are
available for returning an interval around the mean or around zero,
respectively. Se the section below on covariates.</p>
</td></tr>
<tr><td><code id="joint_tests_+3A_...">...</code></td>
<td>
<p>additional arguments passed to <code>ref_grid</code> and <code>emmeans</code></p>
</td></tr>
<tr><td><code id="joint_tests_+3A_delta">delta</code>, <code id="joint_tests_+3A_ctr">ctr</code></td>
<td>
<p>arguments for <code>make.meanint</code> and <code>make.symmint</code></p>
</td></tr>
<tr><td><code id="joint_tests_+3A_x">x</code></td>
<td>
<p>argument for <code>meanint</code> and <code>symmint</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>In models with only factors, no covariates, these tests correspond to
&ldquo;type III&rdquo; tests a la <span class="pkg">SAS</span>, as long as equal-weighted averaging
is used and there are no estimability issues. When covariates are present and
they interact with factors, the results depend on how the covariate is
handled in constructing the reference grid. See the section on covariates
below. The point that one must always remember is that <code>joint_tests</code>
always tests contrasts among EMMs, in the context of the reference grid,
whereas type III tests are tests of model coefficients &ndash; which may or may
not have anything to do with EMMs or contrasts.
</p>


<h3>Value</h3>

<p>a <code>summary_emm</code> object (same as is produced by 
<code><a href="#topic+summary.emmGrid">summary.emmGrid</a></code>). All effects for which there are no
estimable contrasts are omitted from the results. 
There may be an additional row named <code>(confounded)</code> which accounts
for additional degrees of freedom for effects not accounted for in the 
preceding rows.
</p>
<p>The returned object also includes an <code>"est.fcns"</code> attribute, which is a
named list containing the linear functions associated with each joint test. 
No estimable functions are included for confounded effects.
</p>
<p><code>make.meanint</code> returns the function 
<code>function(x) mean(x) + delta * c(-1, 1)</code>,
and <code>make.symmint(ctr, delta)</code> returns the function
<code>function(x) ctr + delta * c(-1, 1)</code>
(which does not depend on <code>x</code>).
The cases with <code>delta = 1</code>, <code>meanint = make.meanint(1)</code> 
and <code>symmint(ctr) = make.symmint(ctr, 1)</code>
are retained for back-compatibility reasons.
These functions are available primarily for use with <code>cov.reduce</code>.
</p>


<h3>Dealing with covariates</h3>

<p>A covariate (or any other predictor) must have <em>more than one value in 
the reference grid</em> in order to test its effect and be included in the results.
Therefore, when <code>object</code> is a model, we default to <code>cov.reduce = meanint</code>
which sets each covariate at a symmetric interval about its mean. But
when <code>object</code> is an existing reference grid, it often has only one value 
for covariates, in which case they are excluded from the joint tests.
</p>
<p>Covariates present further complications in that their values in the
reference grid can affect the joint tests of <em>other</em> effects. When
covariates are centered around their means (the default), then the tests we
obtain can be described as joint tests of covariate-adjusted means; and that
is our intended use here. However, some software such as <span class="pkg">SAS</span> and
<code>car::Anova</code> adopt the convention of centering covariates around zero;
and for that purpose, one can use <code>cov.reduce = symmint(0)</code> when calling
with a model object (or in constructing a reference grid). However, adjusted
means with covariates set at or around zero do not make much sense in the
context of interpreting estimated marginal means, unless the covariate means
really are zero.
</p>
<p>See the examples below with the <code>toy</code> dataset.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+test">test</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>pigs.lm &lt;- lm(log(conc) ~ source * factor(percent), data = pigs)

(jt &lt;- joint_tests(pigs.lm))             ## will be same as type III ANOVA

### Estimable functions associated with "percent"
attr(jt, "est.fcns") $ "percent"

joint_tests(pigs.lm, weights = "outer")  ## differently weighted

joint_tests(pigs.lm, by = "source")      ## separate joint tests of 'percent'

### Comparisons with type III tests in SAS
toy = data.frame(
    treat = rep(c("A", "B"), c(4, 6)),
    female = c(1, 0, 0, 1,   0, 0, 0, 1, 1, 0 ),
    resp = c(17, 12, 14, 19, 28, 26, 26, 34, 33, 27))
toy.fac = lm(resp ~ treat * factor(female), data = toy)
toy.cov = lm(resp ~ treat * female, data = toy)
# (These two models have identical fitted values and residuals)

# -- SAS output we'd get with toy.fac --
## Source          DF    Type III SS    Mean Square   F Value   Pr &gt; F
## treat            1    488.8928571    488.8928571    404.60   &lt;.0001
## female           1     78.8928571     78.8928571     65.29   0.0002
## treat*female     1      1.7500000      1.7500000      1.45   0.2741
# 
# -- SAS output we'd get with toy.cov --
## Source          DF    Type III SS    Mean Square   F Value   Pr &gt; F
## treat            1    252.0833333    252.0833333    208.62   &lt;.0001
## female           1     78.8928571     78.8928571     65.29   0.0002
## female*treat     1      1.7500000      1.7500000      1.45   0.2741

joint_tests(toy.fac)
joint_tests(toy.cov)   # female is regarded as a 2-level factor by default

## Treat 'female' as a numeric covariate (via cov.keep = 0)
## ... then tests depend on where we center things

# Center around the mean
joint_tests(toy.cov, cov.keep = 0, cov.reduce = make.meanint(delta = 1))
# Center around zero (like SAS's results for toy.cov)
joint_tests(toy.cov, cov.keep = 0, cov.reduce = make.symmint(ctr = 0, delta = 1))
# Center around 0.5 (like SAS's results for toy.fac)
joint_tests(toy.cov, cov.keep = 0, cov.reduce = range)

### Example with empty cells and confounded effects
low3 &lt;- unlist(attr(ubds, "cells")[1:3]) 
ubds.lm &lt;- lm(y ~ A*B*C, data = ubds, subset = -low3)

# Show overall joint tests by C:
ref_grid(ubds.lm, by = "C") |&gt; contrast("consec") |&gt; test(joint = TRUE)

# Break each of the above into smaller components:
joint_tests(ubds.lm, by = "C")

</code></pre>

<hr>
<h2 id='lsmeans'>Wrappers for alternative naming of EMMs</h2><span id='topic+lsmeans'></span><span id='topic+wrappers'></span><span id='topic+lstrends'></span><span id='topic+lsmip'></span><span id='topic+lsm'></span><span id='topic+lsmobj'></span><span id='topic+lsm.options'></span><span id='topic+get.lsm.option'></span>

<h3>Description</h3>

<p>These are wrappers for <code><a href="#topic+emmeans">emmeans</a></code> and related functions to provide
backward compatibility, or for users who may prefer to
use other terminology than &ldquo;estimated marginal means&rdquo; &ndash; namely 
&ldquo;least-squares means&rdquo;. These functions also provide the functionality
formerly provided by the <span class="pkg">lsmeans</span> package, which is now just a front-end
for <span class="pkg">emmeans</span>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lsmeans(...)

lstrends(...)

lsmip(...)

lsm(...)

lsmobj(...)

lsm.options(...)

get.lsm.option(x, default = emm_defaults[[x]])
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lsmeans_+3A_...">...</code></td>
<td>
<p>Arguments passed to the corresponding <code>em</code><em>xxxx</em> function</p>
</td></tr>
<tr><td><code id="lsmeans_+3A_x">x</code></td>
<td>
<p>Character name of desired option</p>
</td></tr>
<tr><td><code id="lsmeans_+3A_default">default</code></td>
<td>
<p>default value to return if <code>x</code> not found</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For each function with <code>ls</code><em>xxxx</em> in its name,
the same function named <code>em</code><em>xxxx</em> is called. Any estimator names or 
list items beginning with &ldquo;em&rdquo; are replaced with &ldquo;ls&rdquo; 
before the results are returned
</p>


<h3>Value</h3>

<p>The result of the call to <code>em</code><em>xxxx</em>, suitably modified.
</p>
<p><code>get.lsm.option</code> and <code>lsm.options</code> remap options from
and to corresponding options in the <span class="pkg">emmeans</span> options system.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+emmeans">emmeans</a></code>, <code><a href="#topic+emtrends">emtrends</a></code>, <code><a href="#topic+emmip">emmip</a></code>,
<code><a href="#topic+emm">emm</a></code>, <code><a href="#topic+emmobj">emmobj</a></code>, <code><a href="#topic+emm_options">emm_options</a></code>,
<code><a href="#topic+get_emm_option">get_emm_option</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>pigs.lm &lt;- lm(log(conc) ~ source + factor(percent), data = pigs)
lsmeans(pigs.lm, "source")
</code></pre>

<hr>
<h2 id='make.tran'>Response-transformation extensions</h2><span id='topic+make.tran'></span><span id='topic+inverse'></span>

<h3>Description</h3>

<p>The <code>make.tran</code> function creates the needed information to perform
transformations of the response
variable, including inverting the transformation and estimating variances of
back-transformed predictions via the delta method. <code>make.tran</code> is
similar to <code><a href="stats.html#topic+make.link">make.link</a></code>, but it covers additional transformations.
The result can be used as an environment in which the model is fitted, or as
the <code>tran</code> argument in <code><a href="#topic+update.emmGrid">update.emmGrid</a></code> (when the given
transformation was already applied in an existing model).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>make.tran(type = c("genlog", "power", "boxcox", "sympower", "asin.sqrt",
  "atanh", "bcnPower", "scale"), alpha = 1, beta = 0, param, y, inner, ...)

inverse(y)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="make.tran_+3A_type">type</code></td>
<td>
<p>The name of a standard transformation supported by <code>stat::make.link</code>,
or of a special transformation described under Details.</p>
</td></tr>
<tr><td><code id="make.tran_+3A_alpha">alpha</code>, <code id="make.tran_+3A_beta">beta</code></td>
<td>
<p>Numeric parameters needed for special transformations.</p>
</td></tr>
<tr><td><code id="make.tran_+3A_param">param</code></td>
<td>
<p>If non-missing, this specifies either
<code>alpha</code> or <code>c(alpha, beta)</code> (provided for backward compatibility).
Also, for the same reason, if <code>alpha</code> is of length more than 1,
it is taken as <code>param</code>.</p>
</td></tr>
<tr><td><code id="make.tran_+3A_y">y</code></td>
<td>
<p>A numeric response variable used (<em>and required</em>) with <code>type = "scale"</code>, 
where <code>scale(y)</code> determines <code>alpha</code> and <code>beta</code>.</p>
</td></tr>
<tr><td><code id="make.tran_+3A_inner">inner</code></td>
<td>
<p>another transformation. See the section on compound transformations</p>
</td></tr>
<tr><td><code id="make.tran_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to other functions/methods</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code>list</code> having at least the same elements as those returned by
<code><a href="stats.html#topic+make.link">make.link</a></code>. The <code>linkfun</code> component is the transformation
itself. Each of the functions is associated with an environment where any 
parameter values are defined.
</p>
<p><code>inverse</code> returns the reciprocal of its argument. It allows
the <code>"inverse"</code> link to be auto-detected as a response transformation.
</p>


<h3>Details</h3>

<p>The <code>make.tran</code> function returns a
suitable list of functions for several popular transformations. Besides being
usable with <code>update</code>, the user may use this list as an enclosing
environment in fitting the model itself, in which case the transformation is
auto-detected when the special name <code>linkfun</code> (the transformation
itself) is used as the response transformation in the call. See the examples
below.
</p>
<p>The primary purpose of <code>make.tran</code> is to support transformations that
require additional parameters, specified as <code>alpha</code> and <code>beta</code>;
these are the onse shown in the argument-matching list. However, standard
transformations supported by <code>stats::make.link</code> are also supported.
In the following discussion of ones requiring parameters, 
we use <code class="reqn">\alpha</code> and <code class="reqn">\beta</code> to
denote <code>alpha</code> and <code>beta</code>, and <code class="reqn">y</code> to denote the response variable.
The <code>type</code> argument specifies the following transformations:
</p>

<dl>
<dt><code>"genlog"</code></dt><dd><p>Generalized logarithmic transformation: <code class="reqn">\log_\beta(y +
  \alpha)</code>, where <code class="reqn">y &gt; -\alpha</code>.
When <code class="reqn">\beta = 0</code> (the default), we use <code class="reqn">\log_e(y + \alpha)</code></p>
</dd>
<dt><code>"power"</code></dt><dd><p>Power transformation: <code class="reqn">(y-\beta)^\alpha</code>, where <code class="reqn">y &gt; \beta</code>.
When <code class="reqn">\alpha = 0</code>, <code class="reqn">\log(y-\beta)</code> is used instead.</p>
</dd>
<dt><code>"boxcox"</code></dt><dd><p>The Box-Cox transformation (unscaled by the geometric
mean): <code class="reqn">((y - \beta)^\alpha - 1) / \alpha</code>, where <code class="reqn">y &gt; \beta</code>. 
When <code class="reqn">\alpha = 0</code>, <code class="reqn">\log(y - \beta)</code>
is used.</p>
</dd>
<dt><code>"sympower"</code></dt><dd><p>A symmetrized power transformation on the whole real
line:
<code class="reqn">|y - \beta|^\alpha\cdot sign(y - \beta)</code>. There are no restrictions on <code class="reqn">y</code>, but we
require <code class="reqn">\alpha &gt; 0</code> in order for the transformation to be monotone and
continuous.</p>
</dd>
<dt><code>"asin.sqrt"</code></dt><dd><p>Arcsin-square-root transformation:
<code class="reqn">\sin^{-1}(y/\alpha)^{1/2}</code>. Typically, <code>alpha</code> will be either 1 (default) or 100.</p>
</dd>
<dt><code>"atanh"</code></dt><dd><p>Arctanh transformation:
<code class="reqn">\tanh^{-1}(y/\alpha)</code>. Typically, <code>alpha</code> will be either 1 (default) or 100.</p>
</dd>
<dt><code>"bcnPower"</code></dt><dd><p>Box-Cox with negatives allowed, as described for the 
<code>bcnPower</code> function in the <span class="pkg">car</span> package. It is defined as the Box-Cox
transformation <code class="reqn">(z^\alpha - 1) / \alpha</code> of the variable <code class="reqn">z = y + (y^2+\beta^2)^{1/2}</code>. 
Note that this requires both parameters and that <code>beta &gt; 0</code>.</p>
</dd>
<dt><code>"scale"</code></dt><dd><p>This one is a little different than the others, in that
<code>alpha</code> and <code>beta</code> are ignored; instead, they are determined by calling 
<code>scale(y, ...)</code>. The user should give as <code>y</code> the response variable in the
model to be fitted to its scaled version.</p>
</dd>
</dl>

<p>Note that with the <code>"power"</code>, <code>"boxcox"</code>, or <code>"sympower"</code> transformations, 
the argument <code>beta</code> specifies a location shift. 
In the <code>"genpower"</code> transformation, <code>beta</code> specifies
the base of the logarithm &ndash; however, quirkily, the default of <code>beta = 0</code>
is taken to be the natural logarithm. For example,
<code>make.tran(0.5, 10)</code> sets up the <code class="reqn">\log_{10}(y + \frac12)</code>
transformation. In the <code>"bcnPower"</code> transformation, <code>beta</code>
must be specified as a positive value.
</p>
<p>For purposes of back-transformation, the &lsquo;<span class="samp">&#8288;sqrt(y) + sqrt(y+1)&#8288;</span>&rsquo;
transformation is treated exactly the same way as &lsquo;<span class="samp">&#8288;2*sqrt(y)&#8288;</span>&rsquo;, because
both are regarded as estimates of <code class="reqn">2\sqrt\mu</code>.
</p>


<h3>Cases where <code>make.tran</code> may not be needed</h3>

<p>For standard transformations with no parameters, we usually don't need to use
<code>make.tran</code>; just the name of the transformation is all that is needed.
The functions <code><a href="#topic+emmeans">emmeans</a></code>, <code><a href="#topic+ref_grid">ref_grid</a></code>, and related ones
automatically detect response transformations that are recognized by
examining the model formula. These are <code>log</code>, <code>log2</code>, <code>log10</code>,
<code>log1p</code>,
<code>sqrt</code>, <code>logit</code>, <code>probit</code>, <code>cauchit</code>, <code>cloglog</code>; as
well as (for a response variable <code>y</code>) <code>asin(sqrt(y))</code>,
<code>asinh(sqrt(y))</code>, <code>atanh(y)</code>, and <code>sqrt(y) + sqrt(y+1)</code>. 
In addition, any
constant multiple of these (e.g., <code>2*sqrt(y)</code>) is auto-detected and
appropriately scaled (see also the <code>tran.mult</code> argument in
<code><a href="#topic+update.emmGrid">update.emmGrid</a></code>).
</p>
<p>A few additional transformations may be specified as character strings and
are auto-detected: <code>"identity"</code>, <code>"1/mu^2"</code>,
<code>"inverse"</code>, <code>"reciprocal"</code>, <code>"log10"</code>, <code>"log2"</code>,
<code>"asin.sqrt"</code>, <code>"asinh.sqrt"</code>, and <code>"atanh"</code>.
</p>


<h3>Compound transformations</h3>

<p>A transformation that is a function of another function can be created by
specifying <code>inner</code> for the other function. For example, the
transformation <code class="reqn">1/\sqrt{y}</code> can be created either by
<code>make.tran("inverse", inner = "sqrt")</code> or by <code>make.tran("power",
-0.5)</code>. In principle, transformations can be compounded to any depth.
Also, if <code>type</code> is <code>"scale"</code>, <code>y</code> is replaced by 
<code>inner$linkfun(y)</code>, because that will be the variable that is scaled.
</p>


<h3>Note</h3>

<p>The <code>genlog</code> transformation is technically unneeded, because
a response transformation of the form <code>log(y + c)</code> is now auto-detected 
by <code><a href="#topic+ref_grid">ref_grid</a></code>.
</p>
<p>We modify certain <code><a href="stats.html#topic+make.link">make.link</a></code> results in transformations
where there is a restriction on valid prediction values, so that reasonable
inverse predictions are obtained, no matter what. For example, if a
<code>sqrt</code> transformation was used but a predicted value is negative, the
inverse transformation is zero rather than the square of the prediction. A
side effect of this is that it is possible for one or both confidence
limits, or even a standard error, to be zero.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Fit a model using an oddball transformation:
bctran &lt;- make.tran("boxcox", 0.368)
warp.bc &lt;- with(bctran, 
    lm(linkfun(breaks) ~ wool * tension, data = warpbreaks))
# Obtain back-transformed LS means:    
emmeans(warp.bc, ~ tension | wool, type = "response")

### Using a scaled response...
# Case where it is auto-detected:
mod &lt;- lm(scale(yield[, 1]) ~ Variety, data = MOats)
emmeans(mod, "Variety", type = "response")

# Case where scaling is not auto-detected -- and what to do about it:
copt &lt;- options(contrasts = c("contr.sum", "contr.poly"))
mod.aov &lt;- aov(scale(yield[, 1]) ~ Variety + Error(Block), data = MOats)
emm.aov &lt;- suppressWarnings(emmeans(mod.aov, "Variety", type = "response"))

# Scaling was not retrieved, but we can do:
emm.aov &lt;- update(emm.aov, tran = make.tran("scale", y = MOats$yield[, 1]))
emmeans(emm.aov, "Variety", type = "response")

### Compound transformations
# The following amount to the same thing:
t1 &lt;- make.tran("inverse", inner = "sqrt")
t2 &lt;- make.tran("power", -0.5)

options(copt)


## Not run: 
### An existing model 'mod' was fitted with a y^(2/3) transformation...
  ptran = make.tran("power", 2/3)
  emmeans(mod, "treatment", tran = ptran)

## End(Not run)

pigs.lm &lt;- lm(inverse(conc) ~ source + factor(percent), data = pigs)
emmeans(pigs.lm, "source", type = "response")
</code></pre>

<hr>
<h2 id='MOats'>Oats data in multivariate form</h2><span id='topic+MOats'></span>

<h3>Description</h3>

<p>This is the <code>Oats</code> dataset provided in the <span class="pkg">nlme</span> package, but it is
rearranged as one multivariate observation per plot.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MOats
</code></pre>


<h3>Format</h3>

<p>A data frame with 18 observations and 3 variables
</p>

<dl>
<dt><code>Variety</code></dt><dd><p>a factor with levels <code>Golden Rain</code>,
<code>Marvellous</code>, <code>Victory</code></p>
</dd>
<dt><code>Block</code></dt><dd><p>an ordered factor with levels <code>VI</code> &lt; <code>V</code> &lt;
<code>III</code> &lt; <code>IV</code> &lt; <code>II</code> &lt; <code>I</code></p>
</dd>
<dt><code>yield</code></dt><dd><p>a matrix with 4 columns, giving the yields with
nitrogen concentrations of 0, .2, .4, and .6.</p>
</dd>
</dl>



<h3>Details</h3>

<p>These data arise from a split-plot experiment reported by Yates (1935) and
used as an example in Pinheiro and Bates (2000) and other texts. Six blocks
were divided into three whole plots, randomly assigned to the three varieties
of oats. The whole plots were each divided into 4 split plots and randomized
to the four concentrations of nitrogen.
</p>


<h3>Source</h3>

<p>The dataset <code><a href="nlme.html#topic+Oats">Oats</a></code> in the <span class="pkg">nlme</span> package.
</p>


<h3>References</h3>

<p>Pinheiro, J. C. and Bates D. M. (2000) <em>Mixed-Effects Models in S and
S-PLUS</em>, Springer, New York. (Appendix A.15)
</p>
<p>Yates, F. (1935) Complex experiments, <em>Journal of the Royal Statistical
Society</em> Suppl. 2, 181-247
</p>


<h3>Examples</h3>

<pre><code class='language-R'>MOats.lm &lt;- lm (yield ~ Block + Variety, data = MOats)
MOats.rg &lt;- ref_grid (MOats.lm, mult.name = "nitro")
emmeans(MOats.rg, ~ nitro | Variety)
</code></pre>

<hr>
<h2 id='models'>Models supported in <span class="pkg">emmeans</span></h2><span id='topic+models'></span>

<h3>Description</h3>

<p>Documentation for models has been moved to a vignette. To access it,
use <a href="../doc/models.html"><code>vignette("models", "emmeans")</code></a>.
</p>

<hr>
<h2 id='mvcontrast'>Multivariate contrasts</h2><span id='topic+mvcontrast'></span>

<h3>Description</h3>

<p>This function displays tests of multivariate comparisons or contrasts.
The contrasts are constructed at each level of the variable in <code>mult.name</code>,
and then we do a multivariate test that the vector of estimates is equal to
<code>null</code> (zero by default). The <em>F</em> statistic and degrees
of freedom are determined via the Hotelling distribution. that is, if there are
<code class="reqn">m</code> error degrees of freedom and multivariate dimensionality <code class="reqn">d</code>, then
the resulting <code class="reqn">F</code> statistic has degrees of freedom <code class="reqn">(d, m - d + 1)</code>
as shown in Hotelling (1931).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mvcontrast(object, method = "eff", mult.name = object@roles$multresp,
  null = 0, by = object@misc$by.vars, adjust = c("sidak",
  p.adjust.methods), show.ests = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mvcontrast_+3A_object">object</code></td>
<td>
<p>An object of class <code>emmGrid</code></p>
</td></tr>
<tr><td><code id="mvcontrast_+3A_method">method</code></td>
<td>
<p>A contrast method, per <code><a href="#topic+contrast.emmGrid">contrast.emmGrid</a></code></p>
</td></tr>
<tr><td><code id="mvcontrast_+3A_mult.name">mult.name</code></td>
<td>
<p>Character vector of nNames of the factors whose levels
define the multivariate means to contrast. If the model itself has a
multivariate response, that is what is used. Otherwise, <code>mult.name</code>
<em>must</em> be specified.</p>
</td></tr>
<tr><td><code id="mvcontrast_+3A_null">null</code></td>
<td>
<p>Scalar or conformable vector of null-hypothesis values to test against</p>
</td></tr>
<tr><td><code id="mvcontrast_+3A_by">by</code></td>
<td>
<p>Any <code>by</code> variable(s). These should not include the primary
variables to be contrasted. For convenience, the <code>by</code> variable is
nulled-out if it would result in no primary factors being contrasted.</p>
</td></tr>
<tr><td><code id="mvcontrast_+3A_adjust">adjust</code></td>
<td>
<p>Character value of a multiplicity adjustment method
(<code>"none"</code> for no adjustment). The available adjustment methods are
more limited that in <code>contrast</code>, and any default adjustment returned
via <code>method</code> is ignored.</p>
</td></tr>
<tr><td><code id="mvcontrast_+3A_show.ests">show.ests</code></td>
<td>
<p>Logical flag determining whether the multivariate means 
are displayed</p>
</td></tr>
<tr><td><code id="mvcontrast_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to <code>contrast</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code>summary_emm</code> containing the multivariate
test results; or a list of the estimates and the tests if <code>show.ests</code>
is <code>TRUE</code>. The test results include the Hotelling <code class="reqn">T^2</code> statistic,
<code class="reqn">F</code> ratios, degrees of freedom, and <code class="reqn">P</code> values.
</p>


<h3>Note</h3>

<p>If some interactions among the primary and <code>mult.name</code> factors are
absent, the covariance of the multivariate means is singular; this situation
is accommodated, but the result has reduced degrees of freedom and a message
is displayed. If there are other abnormal conditions such as non-estimable
results, estimates are shown as <code>NA</code>.
</p>
<p>While designed primarily for testing contrasts, multivariate tests of the
mean vector itself can be implemented via <code>method = "identity")</code> (see
the examples).
</p>


<h3>References</h3>

<p>Hotelling, Harold (1931) &quot;The generalization of Student's ratio&quot;, 
<em>Annals of Mathematical Statistics</em> 2(3), 360–378. doi:10.1214/aoms/1177732979
</p>


<h3>Examples</h3>

<pre><code class='language-R'>MOats.lm &lt;- lm(yield ~ Variety + Block, data = MOats)
MOats.emm &lt;- emmeans(MOats.lm, ~ Variety | rep.meas)
mvcontrast(MOats.emm, "consec", show.ests = TRUE)  # mult.name defaults to rep.meas

# Test each mean against a specified null vector
mvcontrast(MOats.emm, "identity", name = "Variety", 
           null = c(80, 100, 120, 140), adjust = "none")
# (Note 'name' is passed to contrast() and overrides default name "contrast")

# 'mult.name' need not refer to a multivariate response
mvcontrast(MOats.emm, "trt.vs.ctrl1", mult.name = "Variety")

</code></pre>

<hr>
<h2 id='neuralgia'>Neuralgia data</h2><span id='topic+neuralgia'></span>

<h3>Description</h3>

<p>These data arise from a study of analgesic effects of treatments of elderly
patients who have neuralgia. Two treatments and a placebo are compared. The 
response variable is whether the patient reported pain or not. Researchers
recorded the age and gender of 60 patients along with the duration of
complaint before the treatment began.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>neuralgia
</code></pre>


<h3>Format</h3>

<p>A data frame with 60 observations and 5 variables:
</p>

<dl>
<dt><code>Treatment</code></dt><dd><p>Factor with 3 levels <code>A</code>, <code>B</code>, and <code>P</code>.
The latter is placebo</p>
</dd>
<dt><code>Sex</code></dt><dd><p>Factor with two levels <code>F</code> and <code>M</code></p>
</dd>
<dt><code>Age</code></dt><dd><p>Numeric covariate &ndash; patient's age in years</p>
</dd>
<dt><code>Duration</code></dt><dd><p>Numeric covariate &ndash; duration of the condition before
beginning treatment</p>
</dd>
<dt><code>Pain</code></dt><dd><p>Binary response factor with levels <code>No</code> and <code>Yes</code></p>
</dd>
</dl>



<h3>Source</h3>

<p>Cai, Weijie (2014) <em>Making Comparisons Fair: How LS-Means Unify 
the Analysis of Linear Models</em>, SAS Institute, Inc. Technical paper 142-2014,
page 12, 
<a href="http://support.sas.com/resources/papers/proceedings14/SAS060-2014.pdf">http://support.sas.com/resources/papers/proceedings14/SAS060-2014.pdf</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Model and analysis shown in the SAS report:
neuralgia.glm &lt;- glm(Pain ~ Treatment * Sex + Age, family = binomial(),
   data = neuralgia) 
pairs(emmeans(neuralgia.glm, ~ Treatment, at = list(Sex = "F")), 
    reverse = TRUE, type = "response", adjust = "bonferroni")

</code></pre>

<hr>
<h2 id='nutrition'>Nutrition data</h2><span id='topic+nutrition'></span>

<h3>Description</h3>

<p>This observational dataset involves three factors, but where several factor 
combinations are missing. It is used as a case study in Milliken and Johnson,
Chapter 17, p.202. (You may also find it in the second edition, p.278.)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nutrition
</code></pre>


<h3>Format</h3>

<p>A data frame with 107 observations and 4 variables:
</p>

<dl>
<dt><code>age</code></dt><dd><p>a factor with levels <code>1</code>, <code>2</code>, <code>3</code>,
<code>4</code>. Mother's age group.</p>
</dd>
<dt><code>group</code></dt><dd><p>a factor with levels <code>FoodStamps</code>, <code>NoAid</code>.
Whether or not the family receives food stamp assistance.</p>
</dd>
<dt><code>race</code></dt><dd><p>a factor with levels <code>Black</code>, <code>Hispanic</code>,
<code>White</code>. Mother's race.</p>
</dd>
<dt><code>gain</code></dt><dd><p>a numeric vector (the response variable). Gain score
(posttest minus pretest) on knowledge of nutrition.</p>
</dd>
</dl>



<h3>Details</h3>

<p>A survey was conducted by home economists &ldquo;to study how much
lower-socioeconomic-level mothers knew about nutrition and to judge the
effect of a training program designed to increase their knowledge of
nutrition.&rdquo; This is a messy dataset with several empty cells.
</p>


<h3>Source</h3>

<p>Milliken, G. A. and Johnson, D. E. (1984)
<em>Analysis of Messy Data &ndash; Volume I: Designed Experiments</em>. 
Van Nostrand, ISBN 0-534-02713-7.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>nutr.aov &lt;- aov(gain ~ (group + age + race)^2, data = nutrition)

# Summarize predictions for age group 3
nutr.emm &lt;- emmeans(nutr.aov, ~ race * group, at = list(age="3"))
                   
emmip(nutr.emm, race ~ group)

# Hispanics seem exceptional; but this doesn't test out due to very sparse data
pairs(nutr.emm, by = "group")
pairs(nutr.emm, by = "race")
</code></pre>

<hr>
<h2 id='oranges'>Sales of oranges</h2><span id='topic+oranges'></span>

<h3>Description</h3>

<p>This example dataset on sales of oranges has two factors, two covariates, and
two responses. There is one observation per factor combination.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>oranges
</code></pre>


<h3>Format</h3>

<p>A data frame with 36 observations and 6 variables:
</p>

<dl>
<dt><code>store</code></dt><dd><p>a factor with levels <code>1</code> <code>2</code> <code>3</code>
<code>4</code> <code>5</code> <code>6</code>. The store that was observed.</p>
</dd>
<dt><code>day</code></dt><dd><p>a factor with levels <code>1</code> <code>2</code> <code>3</code>
<code>4</code> <code>5</code> <code>6</code>. The day the observation was taken (same for
each store).</p>
</dd>
<dt><code>price1</code></dt><dd><p>a numeric vector. Price of variety 1.</p>
</dd>
<dt><code>price2</code></dt><dd><p>a numeric vector. Price of variety 2.</p>
</dd>
<dt><code>sales1</code></dt><dd><p>a numeric vector. Sales (per customer) of variety 1.</p>
</dd>
<dt><code>sales2</code></dt><dd><p>a numeric vector. Sales (per customer) of variety 2.</p>
</dd>
</dl>



<h3>Source</h3>

<p>This is (or once was) available as a SAS sample dataset.
</p>


<h3>References</h3>

<p>Littell, R., Stroup W., Freund, R. (2002) <em>SAS For Linear Models</em> (4th
edition). SAS Institute. ISBN 1-59047-023-0.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example on p.244 of Littell et al.
oranges.lm &lt;- lm(sales1 ~ price1*day, data = oranges)
emmeans(oranges.lm, "day")

# Example on p.246 of Littell et al.
emmeans(oranges.lm, "day", at = list(price1 = 0))

# A more sensible model to consider, IMHO (see vignette("interactions"))
org.mlm &lt;- lm(cbind(sales1, sales2) ~ price1 * price2 + day + store, 
              data = oranges)
</code></pre>

<hr>
<h2 id='pigs'>Effects of dietary protein on free plasma leucine concentration in pigs</h2><span id='topic+pigs'></span>

<h3>Description</h3>

<p>A two-factor experiment with some observations lost
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pigs
</code></pre>


<h3>Format</h3>

<p>A data frame with 29 observations and 3 variables:
</p>

<dl>
<dt>source</dt><dd><p>Source of protein in the diet (factor with 3 levels: 
fish meal, soybean meal, dried skim milk)</p>
</dd>
<dt>percent</dt><dd><p>Protein percentage in the diet (numeric with 4 values:
9, 12, 15, and 18)</p>
</dd>
<dt>conc</dt><dd><p>Concentration of free plasma leucine, in mcg/ml</p>
</dd>
</dl>



<h3>Source</h3>

<p>Windels HF (1964) PhD thesis, Univ. of Minnesota. (Reported as
Problem 10.8 in Oehlert G (2000) <em>A First Course in Design and
Analysis of Experiments</em>, licensed under Creative Commons,
<a href="http://users.stat.umn.edu/~gary/Book.html">http://users.stat.umn.edu/~gary/Book.html</a>.) Observations 7, 22, 23,
31, 33, and 35 have been omitted, creating a more notable imbalance.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  pigs.lm &lt;- lm(inverse(conc) ~ source + factor(percent), data = pigs)
  emmeans(pigs.lm, "source")
</code></pre>

<hr>
<h2 id='plot.emmGrid'>Plot an <code>emmGrid</code> or <code>summary_emm</code> object</h2><span id='topic+plot.emmGrid'></span><span id='topic+plot.summary_emm'></span>

<h3>Description</h3>

<p>Methods are provided to plot EMMs as side-by-side CIs, and optionally to display 
&ldquo;comparison arrows&rdquo; for displaying pairwise comparisons.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'emmGrid'
plot(x, y, type, CIs = TRUE, PIs = FALSE,
  comparisons = FALSE, colors = c("black", "blue", "blue", "red"),
  alpha = 0.05, adjust = "tukey", int.adjust = "none", intervals, ...)

## S3 method for class 'summary_emm'
plot(x, y, horizontal = TRUE, CIs = TRUE, xlab, ylab,
  layout, scale = NULL, colors = c("black", "blue", "blue", "red"),
  intervals, plotit = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.emmGrid_+3A_x">x</code></td>
<td>
<p>Object of class <code>emmGrid</code> or <code>summary_emm</code></p>
</td></tr>
<tr><td><code id="plot.emmGrid_+3A_y">y</code></td>
<td>
<p>(Required but ignored)</p>
</td></tr>
<tr><td><code id="plot.emmGrid_+3A_type">type</code></td>
<td>
<p>Character value specifying the type of prediction desired
(matching <code>"linear.predictor"</code>, <code>"link"</code>, or <code>"response"</code>).
See details under <code><a href="#topic+summary.emmGrid">summary.emmGrid</a></code>.
In addition, the user may specify <code>type = "scale"</code>, in which case
a transformed scale (e.g., a log scale) is displayed based on the transformation
or link function used. Additional customization of this scale is available through
including arguments to <code>ggplot2::scale_x_continuous</code> in <code>...</code> .</p>
</td></tr>
<tr><td><code id="plot.emmGrid_+3A_cis">CIs</code></td>
<td>
<p>Logical value. If <code>TRUE</code>, confidence intervals are
plotted for each estimate.</p>
</td></tr>
<tr><td><code id="plot.emmGrid_+3A_pis">PIs</code></td>
<td>
<p>Logical value. If <code>TRUE</code>, prediction intervals are
plotted for each estimate. If <code>object</code> is a Bayesian model,
this requires the <code>...</code> arguments to include
<code>frequentist = TRUE</code> and <code>sigma =</code> (some value).
Note that the <code>PIs</code> option is <em>not</em> available with
<code>summary_emm</code> objects &ndash; only for <code>emmGrid</code> objects.
Also, prediction intervals are not available
with <code>engine = "lattice"</code>.</p>
</td></tr>
<tr><td><code id="plot.emmGrid_+3A_comparisons">comparisons</code></td>
<td>
<p>Logical value. If <code>TRUE</code>, &ldquo;comparison arrows&rdquo;
are added to the plot, in such a way that the degree to which arrows
overlap reflects as much as possible the significance of the comparison of
the two estimates. (A warning is issued if this can't be done.)
Note that comparison arrows are not available with 'summary_emm' objects.</p>
</td></tr>
<tr><td><code id="plot.emmGrid_+3A_colors">colors</code></td>
<td>
<p>Character vector of color names to use for estimates, CIs, PIs, 
and comparison arrows, respectively. CIs and PIs are rendered with some
transparency, and colors are recycled if the length is less than four;
so all plot elements are visible even if a single color is specified.</p>
</td></tr>
<tr><td><code id="plot.emmGrid_+3A_alpha">alpha</code></td>
<td>
<p>The significance level to use in constructing comparison arrows</p>
</td></tr>
<tr><td><code id="plot.emmGrid_+3A_adjust">adjust</code></td>
<td>
<p>Character value: Multiplicity adjustment method for comparison arrows <em>only</em>.</p>
</td></tr>
<tr><td><code id="plot.emmGrid_+3A_int.adjust">int.adjust</code></td>
<td>
<p>Character value: Multiplicity adjustment method for the plotted confidence intervals <em>only</em>.</p>
</td></tr>
<tr><td><code id="plot.emmGrid_+3A_intervals">intervals</code></td>
<td>
<p>If specified, it is used to set <code>CIs</code>. This is the previous
argument name for <code>CIs</code> and is provided for backward compatibility.</p>
</td></tr>
<tr><td><code id="plot.emmGrid_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to <code><a href="#topic+update.emmGrid">update.emmGrid</a></code>, 
<code><a href="#topic+summary.emmGrid">summary.emmGrid</a></code>,
<code><a href="#topic+predict.emmGrid">predict.emmGrid</a></code>, or
<code><a href="lattice.html#topic+xyplot">dotplot</a></code></p>
</td></tr>
<tr><td><code id="plot.emmGrid_+3A_horizontal">horizontal</code></td>
<td>
<p>Logical value specifying whether the intervals should be
plotted horizontally or vertically</p>
</td></tr>
<tr><td><code id="plot.emmGrid_+3A_xlab">xlab</code></td>
<td>
<p>Character label for horizontal axis</p>
</td></tr>
<tr><td><code id="plot.emmGrid_+3A_ylab">ylab</code></td>
<td>
<p>Character label for vertical axis</p>
</td></tr>
<tr><td><code id="plot.emmGrid_+3A_layout">layout</code></td>
<td>
<p>Numeric value passed to <code><a href="lattice.html#topic+xyplot">dotplot</a></code>
when <code>engine == "lattice"</code>.</p>
</td></tr>
<tr><td><code id="plot.emmGrid_+3A_scale">scale</code></td>
<td>
<p>Object of class <code>trans</code> (in the <span class="pkg">scales</span> package) to
specify a nonlinear scale. This is used in lieu of <code>type = "scale"</code> when
plotting a <code>summary_emm</code> object created with <code>type = "response"</code>.
This is ignored with other types of summaries.</p>
</td></tr>
<tr><td><code id="plot.emmGrid_+3A_plotit">plotit</code></td>
<td>
<p>Logical value. If <code>TRUE</code>, a graphical object is returned;
if <code>FALSE</code>, a data.frame is returned containing all the values
used to construct the plot.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>If <code>plotit = TRUE</code>, a graphical object is returned.
</p>
<p>If <code>plotit = FALSE</code>, a <code>data.frame</code> with the table of
EMMs that would be plotted. In the latter case, the estimate being plotted
is named <code>the.emmean</code>, and any factors involved have the same names as
in the object. Confidence limits are named <code>lower.CL</code> and
<code>upper.CL</code>, prediction limits are named <code>lpl</code> and <code>upl</code>, and
comparison-arrow limits are named <code>lcmpl</code> and <code>ucmpl</code>.
There is also a variable named <code>pri.fac</code> which contains the factor 
combinations that are <em>not</em> among the <code>by</code> variables.
</p>


<h3>Details</h3>

<p>If any <code>by</code> variables are in force, the plot is divided into separate
panels. For
<code>"summary_emm"</code> objects, the <code>...</code> arguments in <code>plot</code>
are passed <em>only</em> to <code>dotplot</code>, whereas for <code>"emmGrid"</code>
objects, the object is updated using <code>...</code> before summarizing and
plotting.
</p>
<p>In plots with <code>comparisons = TRUE</code>, the resulting arrows are only
approximate, and in some cases may fail to accurately reflect the pairwise
comparisons of the estimates &ndash; especially when estimates having large and
small standard errors are intermingled in just the wrong way. Note that the
maximum and minimum estimates have arrows only in one direction, since there
is no need to compare them with anything higher or lower, respectively. See
the <a href="../doc/xplanations.html#arrows"><code>vignette("xplanations",
"emmeans")</code></a> for details on how these are derived.
</p>
<p>If <code>adjust</code> or <code>int.adjust</code> are not supplied, they default to the 
internal <code>adjust</code> setting saved in <code>pairs(x)</code> and <code>x</code> 
respectively (see <code><a href="#topic+update.emmGrid">update.emmGrid</a></code>).
</p>


<h3>Note</h3>

<p>In order to play nice with the plotting functions,
any variable names that are not syntactically correct (e.g., contain spaces)
are altered using <code><a href="base.html#topic+make.names">make.names</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>warp.lm &lt;- lm(breaks ~ wool * tension, data = warpbreaks)
warp.emm &lt;- emmeans(warp.lm, ~ tension | wool)
plot(warp.emm)
plot(warp.emm, by = NULL, comparisons = TRUE, adjust = "mvt", 
     horizontal = FALSE, colors = "darkgreen")

### Using a transformed scale
pigs.lm &lt;- lm(log(conc + 2) ~ source * factor(percent), data = pigs)
pigs.emm &lt;- emmeans(pigs.lm, ~ percent | source)
plot(pigs.emm, type = "scale", breaks = seq(20, 100, by = 10))

# Based on a summary. 
# To get a transformed axis, must specify 'scale'; but it does not necessarily
# have to be the same as the actual response transformation
pigs.ci &lt;- confint(pigs.emm, type = "response")
plot(pigs.ci, scale = scales::log10_trans())
</code></pre>

<hr>
<h2 id='pwpm'>Pairwise P-value matrix (plus other statistics)</h2><span id='topic+pwpm'></span>

<h3>Description</h3>

<p>This function presents results from <code>emmeans</code> and pairwise comparisons
thereof in a compact way. It displays a matrix (or matrices) of estimates,
pairwise differences, and P values. The user may opt to exclude any of these
via arguments <code>means</code>, <code>diffs</code>, and <code>pvals</code>, respectively.
To control the direction of the pairwise differences, use <code>reverse</code>;
and to control what appears in the upper and lower triangle(s), use <code>flip</code>.
Optional arguments are passed to <code>contrast.emmGrid</code> and/or 
<code>summary.emmGrid</code>, making it possible to control what estimates 
and tests are displayed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pwpm(emm, by, reverse = FALSE, pvals = TRUE, means = TRUE,
  diffs = TRUE, flip = FALSE, digits, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pwpm_+3A_emm">emm</code></td>
<td>
<p>An <code>emmGrid</code> object</p>
</td></tr>
<tr><td><code id="pwpm_+3A_by">by</code></td>
<td>
<p>Character vector of variable(s) in the grid to condition on. These
will create different matrices, one for each level or level-combination.
If missing, <code>by</code> is set to <code>emm@misc$by.vars</code>.
Grid factors not in <code>by</code> are the <em>primary</em> factors:
whose levels or level combinations are compared pairwise.</p>
</td></tr>
<tr><td><code id="pwpm_+3A_reverse">reverse</code></td>
<td>
<p>Logical value passed to <code><a href="#topic+pairs.emmGrid">pairs.emmGrid</a></code>.
Thus, <code>FALSE</code> specifies <code>"pairwise"</code> comparisons 
(earlier vs. later), and <code>TRUE</code> specifies <code>"revpairwise"</code>
comparisons (later vs. earlier).</p>
</td></tr>
<tr><td><code id="pwpm_+3A_pvals">pvals</code></td>
<td>
<p>Logical value. If <code>TRUE</code>, the pairwise differences 
of the EMMs are included in each matrix according to <code>flip</code>.</p>
</td></tr>
<tr><td><code id="pwpm_+3A_means">means</code></td>
<td>
<p>Logical value. If <code>TRUE</code>, the estimated marginal means
(EMMs) from <code>emm</code> are included in the matrix diagonal(s).</p>
</td></tr>
<tr><td><code id="pwpm_+3A_diffs">diffs</code></td>
<td>
<p>Logical value. If <code>TRUE</code>, the pairwise differences 
of the EMMs are included in each matrix according to <code>flip</code>.</p>
</td></tr>
<tr><td><code id="pwpm_+3A_flip">flip</code></td>
<td>
<p>Logical value that determines where P values and differences 
are placed. <code>FALSE</code> places the P values in the upper triangle
and differences in the lower, and <code>TRUE</code> does just the opposite.</p>
</td></tr>
<tr><td><code id="pwpm_+3A_digits">digits</code></td>
<td>
<p>Integer. Number of digits to display. If missing,
an optimal number of digits is determined.</p>
</td></tr>
<tr><td><code id="pwpm_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to <code><a href="#topic+contrast.emmGrid">contrast.emmGrid</a></code> and 
<code><a href="#topic+summary.emmGrid">summary.emmGrid</a></code>. You should <em>not</em> include <code>method</code>
here, because pairwise comparisons are always used.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix or 'list' of matrices, one for each 'by' level.
</p>


<h3>Note</h3>

<p>If <code>emm</code> is the result of a Bayesian analysis, <code>pwpm</code> is
based on a frequentist analysis
</p>


<h3>See Also</h3>

<p>A graphical display of essentially the same results is available
from <code><a href="#topic+pwpp">pwpp</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>warp.lm &lt;- lm(breaks ~ wool * tension, data = warpbreaks)
warp.emm &lt;- emmeans(warp.lm, ~ tension | wool)

pwpm(warp.emm)

# use dot options to specify noninferiority tests
pwpm(warp.emm, by = NULL, side = "&gt;", delta = 5, adjust = "none")
</code></pre>

<hr>
<h2 id='pwpp'>Pairwise P-value plot</h2><span id='topic+pwpp'></span>

<h3>Description</h3>

<p>Constructs a plot of P values associated with pairwise comparisons of 
estimated marginal means.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pwpp(emm, method = "pairwise", by, sort = TRUE, values = TRUE,
  rows = ".", xlab, ylab, xsub = "", plim = numeric(0), add.space = 0,
  aes, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pwpp_+3A_emm">emm</code></td>
<td>
<p>An <code>emmGrid</code> object</p>
</td></tr>
<tr><td><code id="pwpp_+3A_method">method</code></td>
<td>
<p>Character or list. Passed to <code><a href="#topic+contrast">contrast</a></code>, and defines 
the contrasts to be displayed. Any contrast method may be used,
provided that each contrast includes one coefficient of <code>1</code>,
one coefficient of <code>-1</code>, and the rest <code>0</code>. That is, calling
<code>contrast(object, method)</code> produces a set of comparisons, each with
one estimate minus another estimate.</p>
</td></tr>
<tr><td><code id="pwpp_+3A_by">by</code></td>
<td>
<p>Character vector of variable(s) in the grid to condition on. These will
create different panels, one for each level or level-combination.
Grid factors not in <code>by</code> are the <em>primary</em> factors: 
whose levels or level combinations are compared pairwise.</p>
</td></tr>
<tr><td><code id="pwpp_+3A_sort">sort</code></td>
<td>
<p>Logical value. If <code>TRUE</code>, levels of the factor combinations are
ordered by their marginal means. If <code>FALSE</code>, they appear in
order based on the existing ordering of the factor levels involved.
Note that the levels are ordered the same way in all panels, and in
many cases this implies that the means in any particular panel
will <em>not</em> be ordered even when <code>sort = TRUE</code>.</p>
</td></tr>
<tr><td><code id="pwpp_+3A_values">values</code></td>
<td>
<p>Logical value. If <code>TRUE</code>, the values of the EMMs are included
in the plot. When there are several side-by-side panels due
to <code>by</code> variable(s), the labels showing values start
stealing a lot of space from the plotting area; in those cases,
it may be desirable to specify <code>FALSE</code> or use <code>rows</code>
so that some panels are vertically stacked.</p>
</td></tr>
<tr><td><code id="pwpp_+3A_rows">rows</code></td>
<td>
<p>Character vector of which <code>by</code> variable(s) are used to define
rows of the panel layout. Those variables in <code>by</code> not included in 
<code>rows</code> define columns in the array of panels.
A <code>"."</code> indicates that only one row
is used, so all panels are stacked side-by-side.</p>
</td></tr>
<tr><td><code id="pwpp_+3A_xlab">xlab</code></td>
<td>
<p>Character label to use in place of the default for the P-value axis.</p>
</td></tr>
<tr><td><code id="pwpp_+3A_ylab">ylab</code></td>
<td>
<p>Character label to use in place of the default for the primary-factor axis.</p>
</td></tr>
<tr><td><code id="pwpp_+3A_xsub">xsub</code></td>
<td>
<p>Character label used as caption at the lower right of the plot.</p>
</td></tr>
<tr><td><code id="pwpp_+3A_plim">plim</code></td>
<td>
<p>numeric vector of value(s) between 0 and 1. These are included
among the observed p values so that the range of tick marks includes at
least the range of <code>plim</code>. Choosing <code>plim = c(0,1)</code> will ensure
the widest possible range.</p>
</td></tr>
<tr><td><code id="pwpp_+3A_add.space">add.space</code></td>
<td>
<p>Numeric value to adjust amount of space used for value labels. Positioning
of value labels is tricky, and depends on how many panels and the
physical size of the plotting region. This parameter allows the user to
adjust the position. Changing it by one unit should shift the position by
about one character width (right if positive, left if negative).
Note that this interacts with <code>aes$label</code> below.</p>
</td></tr>
<tr><td><code id="pwpp_+3A_aes">aes</code></td>
<td>
<p>optional named list of lists. Entries considered are <code>point</code>, 
<code>segment</code>, and <code>label</code>, and contents are passed to the respective
<code>ggplot2::geom_xxx()</code> functions. These affect rendering of points, 
line segments joining them, and value labels. 
Defaults are <code>point = list(size = 2)</code>,
<code>segment = list()</code>, and <code>label = list(size = 2.5)</code>.</p>
</td></tr>
<tr><td><code id="pwpp_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to <code>contrast</code> and <code><a href="#topic+summary.emmGrid">summary.emmGrid</a></code>, 
as well as to <code>geom_segment</code> and <code>geom_label</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>Factor levels (or combinations thereof) are plotted on the vertical scale, and P values
are plotted on the horizontal scale. Each P value is plotted twice &ndash; at
vertical positions corresponding to the levels being compared &ndash; and connected by
a line segment. Thus, it is easy to visualize which P values are small and large,
and which levels are compared. In addition, factor levels are color-coded, and the points
and half-line segments appear in the color of the other level.
The P-value scale is nonlinear, so as to stretch-out smaller P values and
compress larger ones.
P values smaller than 0.0004 are altered and plotted in a way that makes 
them more distinguishable from one another.
</p>
<p>If <code>xlab</code>, <code>ylab</code>, and <code>xsub</code> are not provided, reasonable labels
are created. <code>xsub</code> is used to note special features; e.g., equivalence
thresholds or one-sided tests.
</p>


<h3>Note</h3>

<p>If <code>emm</code> is the result of a Bayesian analysis, the plot is based on
summaries with <code>frequentist = TRUE</code>.
</p>
<p>The <span class="pkg">ggplot2</span> and <span class="pkg">scales</span> packages must be installed in order 
for <code>pwpp</code> to work.
</p>
<p>Additional plot aesthetics are available by adding them to the returned object;
see the examples
</p>


<h3>See Also</h3>

<p>A numerical display of essentially the same results is available
from <code><a href="#topic+pwpm">pwpm</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>pigs.lm &lt;- lm(log(conc) ~ source * factor(percent), data = pigs)
emm = emmeans(pigs.lm, ~ percent | source)
pwpp(emm)
pwpp(emm, method = "trt.vs.ctrl1", type = "response", side = "&gt;")

# custom aesthetics:
my.aes &lt;- list(point = list(shape = "square"), 
               segment = list(linetype = "dashed", color = "red"),
               label = list(family = "serif", fontface = "italic"))
my.pal &lt;- c("darkgreen", "blue", "magenta", "orange")
pwpp(emm, aes = my.aes) + ggplot2::scale_color_manual(values = my.pal)

</code></pre>

<hr>
<h2 id='qdrg'>Quick and dirty reference grid</h2><span id='topic+qdrg'></span>

<h3>Description</h3>

<p>This function may make it possible to compute a reference grid for a model 
object that is otherwise not supported.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>qdrg(formula, data, coef, vcov, df, mcmc, object, subset, weights, contrasts,
  link, qr, ordinal, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="qdrg_+3A_formula">formula</code></td>
<td>
<p>Formula for the fixed effects</p>
</td></tr>
<tr><td><code id="qdrg_+3A_data">data</code></td>
<td>
<p>Dataset containing the variables in the model</p>
</td></tr>
<tr><td><code id="qdrg_+3A_coef">coef</code></td>
<td>
<p>Fixed-effect regression coefficients (must conform to formula)</p>
</td></tr>
<tr><td><code id="qdrg_+3A_vcov">vcov</code></td>
<td>
<p>Variance-covariance matrix of the fixed effects</p>
</td></tr>
<tr><td><code id="qdrg_+3A_df">df</code></td>
<td>
<p>Error degrees of freedom</p>
</td></tr>
<tr><td><code id="qdrg_+3A_mcmc">mcmc</code></td>
<td>
<p>Posterior sample of fixed-effect coefficients</p>
</td></tr>
<tr><td><code id="qdrg_+3A_object">object</code></td>
<td>
<p>Optional model object. <em>This rarely works!</em>; 
but if provided, we try to set 
other arguments based on an expectation that 'object' has a similar
structure to 'lm' objects. See Details.</p>
</td></tr>
<tr><td><code id="qdrg_+3A_subset">subset</code></td>
<td>
<p>Subset of <code>data</code> used in fitting the model</p>
</td></tr>
<tr><td><code id="qdrg_+3A_weights">weights</code></td>
<td>
<p>Weights used in fitting the model</p>
</td></tr>
<tr><td><code id="qdrg_+3A_contrasts">contrasts</code></td>
<td>
<p>List of contrasts specified in fitting the model</p>
</td></tr>
<tr><td><code id="qdrg_+3A_link">link</code></td>
<td>
<p>Link function (character or list) used, if a generalized linear model.
(Note: response transformations are auto-detected from <code>formula</code>)</p>
</td></tr>
<tr><td><code id="qdrg_+3A_qr">qr</code></td>
<td>
<p>QR decomposition of the model matrix; used only if there are <code>NA</code>s
in <code>coef</code>.</p>
</td></tr>
<tr><td><code id="qdrg_+3A_ordinal">ordinal</code></td>
<td>
<p><code>list</code> with elements <code>dim</code> and <code>mode</code>.
<code>ordinal$dim</code> (integer) is the number of levels in an ordinal response. If 
<code>ordinal</code> is provided, the intercept terms are modified appropriate to predicting 
an ordinal response, as described in <code>vignette("models")</code>, Section O,
using <code>ordinal$mode</code> as the <code>mode</code> argument (if not
provided, <code>"latent"</code> is assumed).
(All modes are supported except 'scale')
For this to work, we expect
the first <code>ordinal$dim - 1</code> elements of <code>coef</code> to be the
estimated threshold parameters, followed by the coefficients for the
linear predictor.</p>
</td></tr>
<tr><td><code id="qdrg_+3A_...">...</code></td>
<td>
<p>Optional arguments passed to <code><a href="#topic+ref_grid">ref_grid</a></code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>Usually, you need to provide either <code>object</code>; or
<code>formula</code>, <code>coef</code>, <code>vcov</code>, <code>data</code>, and perhaps other
parameters. It is usually fairly straightforward to figure out how to get
these from the model <code>object</code>; see the documentation for the model class that
was fitted. Sometimes one or more of these quantities contains extra parameters,
and if so, you may need to subset them to make everything conformable. For a given <code>formula</code> and <code>data</code>,
you can find out what is needed via <code>colnames(model.matrix(formula, data))</code>.
(However, for an ordinal model, we expect the first <code>ordinal.dim - 1</code> coefficients
to replace <code>(Intercept)</code>. And for a multivariate model, we expect <code>coef</code> 
to be a matrix with these row names, and <code>vcov</code> to have as many rows and columns as
the total number of elements of <code>coef</code>.)
</p>
<p>If your model object follows fairly closely the conventions of an <code><a href="stats.html#topic+lm">lm</a></code>
or <code><a href="stats.html#topic+glm">glm</a></code>object, you may be able to get by providing the model as <code>object</code>,
and perhaps some other parameters to override the defaults.
When <code>object</code> is specified, it is used as detailed below to try to obtain the 
other arguments. The user should ensure that the defaults
shown below do indeed work. 
The default values for the arguments are as follows:
</p>

<ul>
<li><p><code>formula</code>: <code>formula(object)</code>
</p>
</li>
<li><p><code>data</code>: <code>recover_data.lm(object)</code> is tried, and if an error is thrown,
we also check <code>object$data</code>.
</p>
</li>
<li><p><code>coef</code>: <code>coef(object)</code>
</p>
</li>
<li><p><code>vcov</code>: <code>vcov(object)</code>
</p>
</li>
<li><p><code>df</code>: Set to <code>Inf</code> if not available in <code>df.residual(object)</code>
</p>
</li>
<li><p><code>mcmc</code>: <code>object$sample</code>
</p>
</li>
<li><p><code>subset</code>: <code>NULL</code> (so that all observations in <code>data</code> are used)
</p>
</li>
<li><p><code>contrasts</code>: <code>object$contrasts</code>
</p>
</li></ul>

<p>The functions <code><a href="#topic+qdrg">qdrg</a></code> and <code>emmobj</code> are close cousins, in that
they both produce <code>emmGrid</code> objects. When starting with summary
statistics for an existing grid, <code>emmobj</code> is more useful, while
<code>qdrg</code> is more useful when starting from a fitted model.
</p>


<h3>Value</h3>

<p>An <code>emmGrid</code> object constructed from the arguments
</p>


<h3>Rank deficiencies</h3>

<p>Different model-fitting packages take different approaches when the model
matrix is singular, but <code>qdrg</code> tries to reconcile them by comparing the
linear functions created by <code>formula</code> to <code>coefs</code> and <code>vcov</code>.
We may then use the <span class="pkg">estimability</span> package to determine what quantities
are estimable. For reconciling to work properly, <code>coef</code> should be named
and <code>vcov</code> should have dimnames. To disable this name-matching
action, remove the names from <code>coef</code>, e.g., by calling <code>unname()</code>.
No reconciliation is attempted in multivariate-response cases. For more
details on estimability, see the documentation in the <span class="pkg">estimability</span>
package.
</p>


<h3>Note</h3>

<p>For backwards compatibility, an argument <code>ordinal.dim</code> is invisibly 
supported as part of <code>...</code>, and if present, sets 
<code>ordinal = list(dim = ordinal.dim, mode = "latent")</code>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+emmobj">emmobj</a></code> for an alternative way to construct an <code>emmGrid</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># In these examples, use emm_example(..., list = TRUE) # to see just the code

if (require(biglm, quietly = TRUE)) 
    emm_example("qdrg-biglm")
    
if(require(coda, quietly = TRUE) &amp;&amp; require(lme4, quietly = TRUE)) 
    emm_example("qdrg-coda")
    
if(require(ordinal, quietly = TRUE)) 
    emm_example("qdrg-ordinal")

</code></pre>

<hr>
<h2 id='rbind.emmGrid'>Combine or subset <code>emmGrid</code> objects</h2><span id='topic+rbind.emmGrid'></span><span id='topic++2B.emmGrid'></span><span id='topic++5B.emmGrid'></span><span id='topic+head.emmGrid'></span><span id='topic+tail.emmGrid'></span><span id='topic+subset.emmGrid'></span><span id='topic+rbind.emm_list'></span><span id='topic+rbind.summary_emm'></span><span id='topic+force_regular'></span>

<h3>Description</h3>

<p>These functions provide methods for <code><a href="base.html#topic+cbind">rbind</a></code> and
<code><a href="base.html#topic+Extract">[</a></code> that may be used to combine <code>emmGrid</code> objects
together, or to extract a subset of cases. The primary reason for 
doing this would be to obtain multiplicity-adjusted results for smaller
or larger families of tests or confidence intervals.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'emmGrid'
rbind(..., deparse.level = 1, adjust = "bonferroni")

## S3 method for class 'emmGrid'
e1 + e2

## S3 method for class 'emmGrid'
x[i, adjust, drop.levels = TRUE, ...]

## S3 method for class 'emmGrid'
head(x, n = 6, ...)

## S3 method for class 'emmGrid'
tail(x, n = 6, ...)

## S3 method for class 'emmGrid'
subset(x, subset, ...)

## S3 method for class 'emm_list'
rbind(..., which, adjust = "bonferroni")

## S3 method for class 'summary_emm'
rbind(..., which)

force_regular(object)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rbind.emmGrid_+3A_...">...</code></td>
<td>
<p>In <code>rbind</code>, object(s) of class <code>emmGrid</code> or <code>summary_emm</code>.
In others, additional arguments passed to other methods</p>
</td></tr>
<tr><td><code id="rbind.emmGrid_+3A_deparse.level">deparse.level</code></td>
<td>
<p>(required but not used)</p>
</td></tr>
<tr><td><code id="rbind.emmGrid_+3A_adjust">adjust</code></td>
<td>
<p>Character value passed to <code><a href="#topic+update.emmGrid">update.emmGrid</a></code></p>
</td></tr>
<tr><td><code id="rbind.emmGrid_+3A_e1">e1</code>, <code id="rbind.emmGrid_+3A_e2">e2</code>, <code id="rbind.emmGrid_+3A_x">x</code>, <code id="rbind.emmGrid_+3A_object">object</code></td>
<td>
<p>Objects of class <code>emmGrid</code></p>
</td></tr>
<tr><td><code id="rbind.emmGrid_+3A_i">i</code></td>
<td>
<p>Integer vector of indexes</p>
</td></tr>
<tr><td><code id="rbind.emmGrid_+3A_drop.levels">drop.levels</code></td>
<td>
<p>Logical value. If <code>TRUE</code>, the <code>"levels"</code> slot in
the returned object is updated to hold only the predictor levels that actually occur</p>
</td></tr>
<tr><td><code id="rbind.emmGrid_+3A_n">n</code></td>
<td>
<p>integer number of entries to include (or exclude if negative)</p>
</td></tr>
<tr><td><code id="rbind.emmGrid_+3A_subset">subset</code></td>
<td>
<p>logical expression indicating which rows of the grid to keep</p>
</td></tr>
<tr><td><code id="rbind.emmGrid_+3A_which">which</code></td>
<td>
<p>Integer vector of subset of elements to use; if missing, all are combined</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A revised object of class <code>emmGrid</code>
</p>
<p>The result of <code>e1 + e2</code> is the same as <code>rbind(e1, e2)</code>
</p>
<p>The <code>rbind</code> method for <code>emm_list</code> objects simply combines 
the <code>emmGrid</code> objects comprising the first element of <code>...</code>.
Note that the returned object is not yet summarized, so any <code>adjust</code>
parameters apply to the combined <code>emmGrid</code>.
</p>
<p>The <code>rbind</code> method for <code>summary_emm</code> objects (or a list thereof)
returns a single <code>summary_emm</code> object. This combined object
<em>preserves</em> any adjusted P values or confidence limits in the
original summaries, since those quantities have already been computed.
</p>
<p><code>force_regular</code> adds extra (invisible) rows to an <code>emmGrid</code> object
to make it a regular grid (all combinations of factors). This regular structure is 
needed by <code>emmeans</code>. An object can become irregular by, for example,
subsetting rows, or by obtaining contrasts of a nested structure.
</p>


<h3>Note</h3>

<p><code>rbind</code> throws an error if there are incompatibilities in
the objects' coefficients, covariance structures, etc. But they 
are allowed to have different factors; a missing level <code>'.'</code>
is added to factors as needed.
</p>
<p>These functions generally reset <code>by.vars</code> to <code>NULL</code>;
so if you want to keep any &ldquo;by&rdquo; variables, you should follow-up
with <code><a href="#topic+update.emmGrid">update.emmGrid</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>warp.lm &lt;- lm(breaks ~ wool * tension, data = warpbreaks)
warp.rg &lt;- ref_grid(warp.lm)

# Do all pairwise comparisons within rows or within columns, 
# all considered as one faily of tests:
w.t &lt;- pairs(emmeans(warp.rg, ~ wool | tension))
t.w &lt;- pairs(emmeans(warp.rg, ~ tension | wool))
rbind(w.t, t.w, adjust = "mvt")
update(w.t + t.w, adjust = "fdr")  ## same as above except for adjustment

# Show only 3 of the 6 cases
summary(warp.rg[c(2, 4, 5)])

# After-the-fact 'at' specification
subset(warp.rg, wool == "A")  ## or warp.rg |&gt; subset(wool == "A")


### Working with 'emm_list' objects
mod &lt;- lm(conc ~ source + factor(percent), data = pigs)
all &lt;- emmeans(mod, list(src = pairwise ~ source, pct = consec ~ percent))
rbind(all, which = c(2, 4), adjust = "mvt")

### Irregular object
tmp &lt;- warp.rg[-1]
## emmeans(tmp, "tension")   # will fail because tmp is irregular
emmeans(force_regular(tmp), "tension")   # will show some results
</code></pre>

<hr>
<h2 id='ref_grid'>Create a reference grid from a fitted model</h2><span id='topic+ref_grid'></span>

<h3>Description</h3>

<p>Using a fitted model object, determine a reference grid for which estimated
marginal means are defined. The resulting <code>ref_grid</code> object encapsulates
all the information needed to calculate EMMs and make inferences on them.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ref_grid(object, at, cov.reduce = mean,
  cov.keep = get_emm_option("cov.keep"), mult.names, mult.levs,
  options = get_emm_option("ref_grid"), data, df, type, regrid, nesting,
  offset, sigma, counterfactuals, wt.counter, avg.counter = TRUE,
  nuisance = character(0), non.nuisance, wt.nuis = "equal",
  rg.limit = get_emm_option("rg.limit"), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ref_grid_+3A_object">object</code></td>
<td>
<p>An object produced by a supported model-fitting function, such
as <code>lm</code>. Many models are supported. See
<a href="../doc/models.html"><code>vignette("models", "emmeans")</code></a>.</p>
</td></tr>
<tr><td><code id="ref_grid_+3A_at">at</code></td>
<td>
<p>Optional named list of levels for the corresponding variables</p>
</td></tr>
<tr><td><code id="ref_grid_+3A_cov.reduce">cov.reduce</code></td>
<td>
<p>A function, logical value, or formula; or a named list of
these. Each covariate <em>not</em> specified in <code>cov.keep</code> or <code>at</code>
is reduced according to these specifications. See the section below on
&ldquo;Using <code>cov.reduce</code> and <code>cov.keep</code>&rdquo;.</p>
</td></tr>
<tr><td><code id="ref_grid_+3A_cov.keep">cov.keep</code></td>
<td>
<p>Character vector: names of covariates that are <em>not</em>
to be reduced; these are treated as factors and used in weighting calculations.
<code>cov.keep</code> may also include integer value(s), and if so, the maximum
of these is used to set a threshold such that any covariate having no more
than that many unique values is automatically included in <code>cov.keep</code>.</p>
</td></tr>
<tr><td><code id="ref_grid_+3A_mult.names">mult.names</code></td>
<td>
<p>Character value: the name(s) to give to the
pseudo-factor(s) whose levels delineate the elements of a multivariate
response. If this is provided, it overrides the default name(s) used for
<code>class(object)</code> when it has a multivariate response (e.g., the default
is <code>"rep.meas"</code> for <code>"mlm"</code> objects).</p>
</td></tr>
<tr><td><code id="ref_grid_+3A_mult.levs">mult.levs</code></td>
<td>
<p>A named list of levels for the dimensions of a multivariate
response. If there is more than one element, the combinations of levels are
used, in <code><a href="base.html#topic+expand.grid">expand.grid</a></code> order. The (total) number of levels must
match the number of dimensions. If <code>mult.name</code> is specified, this
argument is ignored.</p>
</td></tr>
<tr><td><code id="ref_grid_+3A_options">options</code></td>
<td>
<p>If non-<code>NULL</code>, a named <code>list</code> of arguments to pass
to <code><a href="#topic+update.emmGrid">update.emmGrid</a></code>, just after the object is constructed.</p>
</td></tr>
<tr><td><code id="ref_grid_+3A_data">data</code></td>
<td>
<p>A <code>data.frame</code> to use to obtain information about the
predictors (e.g. factor levels). If missing, then
<code><a href="#topic+recover_data">recover_data</a></code> is used to attempt to reconstruct the data. See
the note with <code><a href="#topic+recover_data">recover_data</a></code> for an important precaution.</p>
</td></tr>
<tr><td><code id="ref_grid_+3A_df">df</code></td>
<td>
<p>Numeric value. This is equivalent to specifying <code>options(df =
df)</code>. See <code><a href="#topic+update.emmGrid">update.emmGrid</a></code>.</p>
</td></tr>
<tr><td><code id="ref_grid_+3A_type">type</code></td>
<td>
<p>Character value. If provided, this is saved as the
<code>"predict.type"</code> setting. See <code><a href="#topic+update.emmGrid">update.emmGrid</a></code> and the
section below on prediction types and transformations.</p>
</td></tr>
<tr><td><code id="ref_grid_+3A_regrid">regrid</code></td>
<td>
<p>Character, logical, or list. If non-missing, the reference
grid is reconstructed via <code><a href="#topic+regrid">regrid</a></code> with the argument
<code>transform = regrid</code>. See the section below on prediction types and
transformations. <em>Note:</em> This argument was named <code>transform</code> in
version 1.7.2 and earlier. For compatibility with old code, <code>transform</code>
is still accepted if found among <code>...</code>, 
as long as it doesn't match <code>tran</code>.</p>
</td></tr>
<tr><td><code id="ref_grid_+3A_nesting">nesting</code></td>
<td>
<p>If the model has nested fixed effects, this may be specified
here via a character vector or named <code>list</code> specifying the nesting
structure. Specifying <code>nesting</code> overrides any nesting structure that
is automatically detected. See the section below on Recovering or Overriding 
Model Information.</p>
</td></tr>
<tr><td><code id="ref_grid_+3A_offset">offset</code></td>
<td>
<p>Numeric scalar value (if a vector, only the first element is
used). This may be used to add an offset, or override offsets based on the
model. A common usage would be to specify <code>offset = 0</code> for a Poisson
regression model, so that predictions from the reference grid become rates
relative to the offset that had been specified in the model.</p>
</td></tr>
<tr><td><code id="ref_grid_+3A_sigma">sigma</code></td>
<td>
<p>Numeric value to use for subsequent predictions or
back-transformation bias adjustments. If not specified, we use
<code>sigma(object)</code>, if available, and <code>NULL</code> otherwise.
Note: This applies only when the family is <code>"gaussian"</code>; for other families,
<code>sigma</code> is set to <code>NA</code> and cannot be overridden.</p>
</td></tr>
<tr><td><code id="ref_grid_+3A_counterfactuals">counterfactuals</code>, <code id="ref_grid_+3A_wt.counter">wt.counter</code>, <code id="ref_grid_+3A_avg.counter">avg.counter</code></td>
<td>
<p><code>counterfactuals</code> specifies character
names of counterfactual factors. If this is non-missing, a reference grid
is created consisting of combinations of counterfactual levels and a constructed
factor <code>.obs.no.</code> having a level for each observation in the dataset.
By default, this grid is re-gridded with the response transformation
and averaged over <code>.obs.no.</code> (by default, with equal weights, but
a vector of weights may be specified in <code>wt.counter</code>; it must be
of length equal to the number of observations in the dataset).
If <code>avg.counter</code> is set to <code>FALSE</code>, this averaging is disabled.
See the section below on counterfactuals.</p>
</td></tr>
<tr><td><code id="ref_grid_+3A_nuisance">nuisance</code>, <code id="ref_grid_+3A_non.nuisance">non.nuisance</code>, <code id="ref_grid_+3A_wt.nuis">wt.nuis</code></td>
<td>
<p>If <code>nuisance</code> is a vector of predictor names,
those predictors are omitted from the reference grid. Instead, the result 
will be as if we had averaged over the levels of those factors, with either 
equal or proportional weights as specified in <code>wt.nuis</code> (see the 
<code>weights</code> argument in <code><a href="#topic+emmeans">emmeans</a></code>). The factors in 
<code>nuisance</code> must not interact with other factors, not even other
nuisance factors. Specifying nuisance factors can save considerable
storage and computation time, and help avoid exceeding the maximum
reference-grid size (<code>get_emm_option("rg.limit")</code>).</p>
</td></tr>
<tr><td><code id="ref_grid_+3A_rg.limit">rg.limit</code></td>
<td>
<p>Integer limit on the number of reference-grid rows to allow
(checked before any multivariate responses are included).</p>
</td></tr>
<tr><td><code id="ref_grid_+3A_...">...</code></td>
<td>
<p>Optional arguments passed to <code><a href="#topic+summary.emmGrid">summary.emmGrid</a></code>,
<code><a href="#topic+emm_basis">emm_basis</a></code>, and
<code><a href="#topic+recover_data">recover_data</a></code>, such as <code>params</code>, <code>vcov.</code> (see
<b>Covariance matrix</b> below), or options such as <code>mode</code> for
specific model types (see <a href="../doc/models.html">vignette(&quot;models&quot;,
&quot;emmeans&quot;)</a>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>To users, the <code>ref_grid</code> function itself is important because most of
its arguments are in effect arguments of <code><a href="#topic+emmeans">emmeans</a></code> and related
functions, in that those functions pass their <code>...</code> arguments to
<code>ref_grid</code>.
</p>
<p>The reference grid consists of combinations of independent variables over
which predictions are made. Estimated marginal means are defined as these
predictions, or marginal averages thereof. The grid is determined by first
reconstructing the data used in fitting the model (see
<code><a href="#topic+recover_data">recover_data</a></code>), or by using the <code>data.frame</code> provided in
<code>data</code>. The default reference grid is determined by the observed levels
of any factors, the ordered unique values of character-valued predictors, and
the results of <code>cov.reduce</code> for numeric predictors. These may be
overridden using <code>at</code>. See also the section below on
recovering/overriding model information.
</p>


<h3>Value</h3>

<p>An object of the S4 class <code>"emmGrid"</code> (see
<code><a href="#topic+emmGrid-class">emmGrid-class</a></code>). These objects encapsulate everything needed
to do calculations and inferences for estimated marginal means, and contain
nothing that depends on the model-fitting procedure.
</p>


<h3>Using <code>cov.reduce</code> and <code>cov.keep</code></h3>

<p>The <code>cov.keep</code> argument was not available in <span class="pkg">emmeans</span> versions
1.4.1 and earlier. Any covariates named in this list are treated as if they
are factors: all the unique levels are kept in the reference grid. The user
may also specify an integer value, in which case any covariate having no more
than that number of unique values is implicitly included in <code>cov.keep</code>.
The default for <code>cov.keep</code> is set and retrieved via the 
<code><a href="#topic+emm_options">emm_options</a></code> framework, and the system default is <code>"2"</code>,
meaning that covariates having only two unique values are automatically
treated as two-level factors. See also the Note below on backward compatibility.
</p>
<p>There is a subtle distinction between including a covariate in <code>cov.keep</code>
and specifying its values manually in <code>at</code>: Covariates included in 
<code>cov.keep</code> are treated as factors for purposes of weighting, while
specifying levels in <code>at</code> will not include the covariate in weighting.
See the <code>mtcars.lm</code> example below for an illustration.
</p>
<p><code>cov.reduce</code> may be a function,
logical value, formula, or a named list of these.
If a single function, it is applied to each covariate.
If logical and <code>TRUE</code>, <code>mean</code> is used. If logical and
<code>FALSE</code>, it is equivalent to including all covariates in
<code>cov.keep</code>. Use of &lsquo;<span class="samp">&#8288;cov.reduce = FALSE&#8288;</span>&rsquo; is inadvisable because it
can result in a huge reference grid; it is far better to use
<code>cov.keep</code>.
</p>
<p>If a formula (which must be two-sided), then a model is fitted to that
formula using <code><a href="stats.html#topic+lm">lm</a></code>; then in the reference grid, its response
variable is set to the results of <code><a href="stats.html#topic+predict">predict</a></code> for that model,
with the reference grid as <code>newdata</code>. (This is done <em>after</em> the
reference grid is determined.) A formula is appropriate here when you think
experimental conditions affect the covariate as well as the response.
</p>
<p>To allow for situations where a simple <code>lm()</code> call as described above won't
be adequate, a formula of the form <code>ext ~ fcnname</code> is also supported,
where the left-hand side may be <code>ext</code>, <code>extern</code>, or
<code>external</code> (and must <em>not</em> be a predictor name) and the
right-hand side is the name of an existing function. The function is called
with one argument, a data frame with columns for each variable in the
reference grid. The function is expected to use that frame as new data to
be used to obtain predictions for one or more models; and it should return
a named list or data frame with replacement values for one or more of the
covariates.
</p>
<p>If <code>cov.reduce</code> is a named list, then the above criteria are used to
determine what to do with covariates named in the list. (However, formula
elements do not need to be named, as those names are determined from the
formulas' left-hand sides.) Any unresolved covariates are reduced using
<code>"mean"</code>.
</p>
<p>Any <code>cov.reduce</code> of <code>cov.keep</code> specification for a covariate 
also named in <code>at</code> is ignored.
</p>


<h3>Interdependent covariates</h3>

<p>Care must be taken when covariate values
depend on one another. For example, when a polynomial model was fitted
using predictors <code>x</code>, <code>x2</code> (equal to <code>x^2</code>), and <code>x3</code>
(equal to <code>x^3</code>), the reference grid will by default set <code>x2</code> and
<code>x3</code> to their means, which is inconsistent. The user should instead
use the <code>at</code> argument to set these to the square and cube of
<code>mean(x)</code>. Better yet, fit the model using a formula involving
<code>poly(x, 3)</code> or <code>I(x^2)</code> and <code>I(x^3)</code>; then there is only
<code>x</code> appearing as a covariate; it will be set to its mean, and the
model matrix will have the correct corresponding quadratic and cubic terms.
</p>


<h3>Matrix covariates</h3>

<p>Support for covariates that appear in the dataset
as matrices is very limited. If the matrix has but one column, it is
treated like an ordinary covariate. Otherwise, with more than one column,
each column is reduced to a single reference value &ndash; the result of
applying <code>cov.reduce</code> to each column (averaged together if that
produces more than one value); you may not specify values in <code>at</code>; and
they are not treated as variables in the reference grid, except for
purposes of obtaining predictions.
</p>


<h3>Recovering or overriding model information</h3>

<p>Ability to support a
particular class of <code>object</code> depends on the existence of
<code>recover_data</code> and <code>emm_basis</code> methods &ndash; see
<a href="#topic+extending-emmeans">extending-emmeans</a> for details. The call
<code>methods("recover_data")</code> will help identify these.
</p>
<p><b>Data.</b> In certain models, (e.g., results of
<code><a href="lme4.html#topic+glmer.nb">glmer.nb</a></code>), it is not possible to identify the original
dataset. In such cases, we can work around this by setting <code>data</code>
equal to the dataset used in fitting the model, or a suitable subset. Only
the complete cases in <code>data</code> are used, so it may be necessary to
exclude some unused variables. Using <code>data</code> can also help save
computing, especially when the dataset is large. In any case, <code>data</code>
must represent all factor levels used in fitting the model. It
<em>cannot</em> be used as an alternative to <code>at</code>. (Note: If there is a
pattern of <code>NAs</code> that caused one or more factor levels to be excluded
when fitting the model, then <code>data</code> should also exclude those levels.)
</p>
<p><b>Covariance matrix.</b> By default, the variance-covariance matrix for
the fixed effects is obtained from <code>object</code>, usually via its
<code><a href="stats.html#topic+vcov">vcov</a></code> method. However, the user may override this via a
<code>vcov.</code> argument, specifying a matrix or a function. If a matrix, it
must be square and of the same dimension and parameter order of the fixed
effects. If a function, must return a suitable matrix when it is called
with arguments <code>(object, ...)</code>. Be careful with possible 
unintended conflicts with arguments in <code>...</code>; for example, 
<code>sandwich::vcovHAC()</code> has optional arguments <code>adjust</code> and <code>weights</code>
that may be intended for <code>emmeans()</code> but will also be passed to <code>vcov.()</code>.
</p>
<p><b>Nested factors.</b> Having a nesting structure affects marginal
averaging in <code>emmeans</code> in that it is done separately for each level
(or combination thereof) of the grouping factors. <code>ref_grid</code> tries to
discern which factors are nested in other factors, but it is not always
obvious, and if it misses some, the user must specify this structure via
<code>nesting</code>; or later using <code><a href="#topic+update.emmGrid">update.emmGrid</a></code>. The
<code>nesting</code> argument may be a character vector, a named <code>list</code>, 
or <code>NULL</code>.
If a <code>list</code>, each name should be the name of a single factor in the
grid, and its entry a character vector of the name(s) of its grouping
factor(s). <code>nested</code> may also be a character value of the form
<code>"factor1 %in% (factor2*factor3)"</code> (the parentheses are optional).
If there is more than one such specification, they may be appended
separated by commas, or as separate elements of a character vector. For
example, these specifications are equivalent: <code>nesting = list(state =
  "country", city = c("state", "country")</code>, <code>nesting = "state %in%
  country, city %in% (state*country)"</code>, and <code>nesting = c("state %in%
  country", "city %in% state*country")</code>.
</p>


<h3>Predictors with subscripts and data-set references</h3>

<p>When the fitted
model contains subscripts or explicit references to data sets, the
reference grid may optionally be post-processed to simplify the variable
names, depending on the <code>simplify.names</code> option (see
<code><a href="#topic+emm_options">emm_options</a></code>), which by default is <code>TRUE</code>. For example,
if the model formula is <code>data1$resp ~ data1$trt + data2[[3]] +
  data2[["cov"]]</code>, the simplified predictor names (for use, e.g., in the
<code>specs</code> for <code><a href="#topic+emmeans">emmeans</a></code>) will be <code>trt</code>,
<code>data2[[3]]</code>, and <code>cov</code>. Numerical subscripts are not simplified;
nor are variables having simplified names that coincide, such as if
<code>data2$trt</code> were also in the model.
</p>
<p>Please note that this simplification is performed <em>after</em> the
reference grid is constructed. Thus, non-simplified names must be used in
the <code>at</code> argument (e.g., <code>at = list(`data2["cov"]` = 2:4)</code>.
</p>
<p>If you don't want names simplified, use <code>emm_options(simplify.names =
  FALSE)</code>.
</p>


<h3>Prediction types and transformations</h3>

<p>Transformations can exist because of a link function in a generalized linear model, 
or as a response transformation, or even both. In many cases, they are auto-detected,
for example a model formula of the form <code>sqrt(y) ~ ...</code>. Even transformations
containing multiplicative or additive constants, such as <code>2*sqrt(y + pi) ~ ...</code>,
are auto-detected. A response transformation of <code>y + 1 ~ ...</code> is <em>not</em>
auto-detected, but <code>I(y + 1) ~ ...</code> is interpreted as <code>identity(y + 1) ~ ...</code>.
A warning is issued if it gets too complicated.
Complex transformations like the Box-Cox transformation are not auto-detected; but see 
the help page for <code><a href="#topic+make.tran">make.tran</a></code> for information on some advanced methods.
</p>
<p>There is a subtle difference
between specifying &lsquo;<span class="samp">&#8288;type = "response"&#8288;</span>&rsquo; and &lsquo;<span class="samp">&#8288;regrid =
  "response"&#8288;</span>&rsquo;. While the summary statistics for the grid itself are the same,
subsequent use in <code><a href="#topic+emmeans">emmeans</a></code> will yield different results if
there is a response transformation or link function. With &lsquo;<span class="samp">&#8288;type =
  "response"&#8288;</span>&rsquo;, EMMs are computed by averaging together predictions on the
<em>linear-predictor</em> scale and then back-transforming to the response
scale; while with &lsquo;<span class="samp">&#8288;regrid = "response"&#8288;</span>&rsquo;, the predictions are
already on the response scale so that the EMMs will be the arithmetic means
of those response-scale predictions. To add further to the possibilities,
<em>geometric</em> means of the response-scale predictions are obtainable via
&lsquo;<span class="samp">&#8288;regrid = "log", type = "response"&#8288;</span>&rsquo;. See also the help page for 
<code><a href="#topic+regrid">regrid</a></code>.
</p>
<p><em>Order-of-processing issues:</em> 
The <code>regrid</code> argument, if present, is acted on immediately after the reference 
grid is constructed, while some of the <code>...</code> arguments may be used to
update the object at the very end. Thus, code like
<code>ref_grid(mod, tran = "sqrt", regrid = "response")</code> will not work correctly
if the intention was to specify the response transformation, because the re-grid 
is done <em>before</em> it processes <code>tran = "sqrt"</code>. To get the intended
result, do
<code>regrid(ref_grid(mod, tran = "sqrt"), transform = "response")</code>.
</p>


<h3>Counterfactuals</h3>

<p>If <code>counterfactuals</code> is specified, the rows of the entire dataset
become a factor in the reference grid, and the other reference levels are
confined to those named in <code>counterfactuals</code>. In this type of analysis
(called G-computation), we substitute each combination of counterfactual
levels into the entire dataset. Thus, predictions from this grid are those
of each observation under each of the counterfactual levels. For this to
make sense, we require an assumption of exchangeability of these levels.
</p>
<p>By default, this grid is converted to the response scale (unless otherwise
specified in <code>regrid</code>) and averaged over the observations in the dataset.
Averaging can be disabled by setting <code>avg.counter = FALSE</code>, but
be warned that the resulting reference grid is potentially huge &ndash; the
number of observations in the dataset times the number of counterfactual 
combinations, times the number of multivariate levels.
</p>
<p>The counterfactuals code is still fairly rudimentary and we can't guarantee
it will always work, such as in cases of nested models. Sometimes, an error
can be averted by specifying <code>avg.counter = FALSE</code>.
</p>


<h3>Optional side effect</h3>

<p>If the <code>save.ref_grid</code> option is set to
<code>TRUE</code> (see <code><a href="#topic+emm_options">emm_options</a></code>),
The most recent result of <code>ref_grid</code>, whether
called directly or indirectly via <code><a href="#topic+emmeans">emmeans</a></code>,
<code><a href="#topic+emtrends">emtrends</a></code>, or some other function that calls one of these, is
saved in the user's environment as <code>.Last.ref_grid</code>. This facilitates
checking what reference grid was used, or reusing the same reference grid
for further calculations. This automatic saving is disabled by default, but
may be enabled via &lsquo;<span class="samp">&#8288;emm_options(save.ref_grid = TRUE)&#8288;</span>&rsquo;.
</p>


<h3>Note</h3>

<p>The system default for <code>cov.keep</code> causes models
containing indicator variables to be handled differently than in
<span class="pkg">emmeans</span> version 1.4.1 or earlier. To replicate older
analyses, change the default via 
&lsquo;<span class="samp">&#8288;emm_options(cov.keep = character(0))&#8288;</span>&rsquo;.
</p>
<p>Some earlier versions of <span class="pkg">emmeans</span> offer a <code>covnest</code> argument.
This is now obsolete; if <code>covnest</code> is specified, it is harmlessly
ignored. Cases where it was needed are now handled appropriately via the
code associated with <code>cov.keep</code>.
</p>


<h3>See Also</h3>

<p>Reference grids are of class <code><a href="#topic+emmGrid-class">emmGrid</a></code>,
and several methods exist for them &ndash; for example
<code><a href="#topic+summary.emmGrid">summary.emmGrid</a></code>. Reference grids are fundamental to
<code><a href="#topic+emmeans">emmeans</a></code>. Supported models are detailed in
<a href="../doc/models.html"><code>vignette("models", "emmeans")</code></a>.
See <code><a href="#topic+update.emmGrid">update.emmGrid</a></code> for details of arguments that can be in 
<code>options</code> (or in <code>...</code>).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>fiber.lm &lt;- lm(strength ~ machine*diameter, data = fiber)
ref_grid(fiber.lm)

ref_grid(fiber.lm, at = list(diameter = c(15, 25)))

## Not run: 
# We could substitute the sandwich estimator vcovHAC(fiber.lm)
# as follows:
summary(ref_grid(fiber.lm, vcov. = sandwich::vcovHAC))

## End(Not run)

# If we thought that the machines affect the diameters
# (admittedly not plausible in this example), then we should use:
ref_grid(fiber.lm, cov.reduce = diameter ~ machine)

### Model with indicator variables as predictors:
mtcars.lm &lt;- lm(mpg ~ disp + wt + vs * am, data = mtcars)
(rg.default &lt;- ref_grid(mtcars.lm))
(rg.nokeep &lt;- ref_grid(mtcars.lm, cov.keep = character(0)))
(rg.at &lt;- ref_grid(mtcars.lm, at = list(vs = 0:1, am = 0:1)))

# Two of these have the same grid but different weights:
rg.default@grid
rg.at@grid

### Using cov.reduce formulas...
# Above suggests we can vary disp indep. of other factors - unrealistic
rg.alt &lt;- ref_grid(mtcars.lm, at = list(wt = c(2.5, 3, 3.5)),
    cov.reduce = disp ~ vs * wt)
rg.alt@grid

# Alternative to above where we model sqrt(disp)
disp.mod &lt;- lm(sqrt(disp) ~ vs * wt, data = mtcars)
disp.fun &lt;- function(dat)
    list(disp = predict(disp.mod, newdata = dat)^2)
rg.alt2 &lt;- ref_grid(mtcars.lm, at = list(wt = c(2.5, 3, 3.5)),
    cov.reduce = external ~ disp.fun)
rg.alt2@grid


# Multivariate example
MOats.lm = lm(yield ~ Block + Variety, data = MOats)
ref_grid(MOats.lm, mult.names = "nitro")
# Silly illustration of how to use 'mult.levs' to make comb's of two factors
ref_grid(MOats.lm, mult.levs = list(T=LETTERS[1:2], U=letters[1:2]))

# Comparing estimates with and without counterfactuals
neuralgia.glm &lt;- glm(Pain ~ Treatment + Sex + Age + Duration, 
                     family = binomial(), data = neuralgia)
emmeans(neuralgia.glm, "Treatment", type = "response")

emmeans(neuralgia.glm, "Treatment", counterfactuals = "Treatment")


# Using 'params'
require("splines")
my.knots = c(2.5, 3, 3.5)
mod = lm(Sepal.Length ~ Species * ns(Sepal.Width, knots = my.knots), data = iris)
## my.knots is not a predictor, so need to name it in 'params'
ref_grid(mod, params = "my.knots") 

</code></pre>

<hr>
<h2 id='regrid'>Reconstruct a reference grid with a new transformation or simulations</h2><span id='topic+regrid'></span>

<h3>Description</h3>

<p>The typical use of this function is to cause EMMs to be computed on
a different scale, e.g., the back-transformed scale rather than the 
linear-predictor scale. In other words, if you want back-transformed 
results, do you want to average and then back-transform, or 
back-transform and then average?
</p>


<h3>Usage</h3>

<pre><code class='language-R'>regrid(object, transform = c("response", "mu", "unlink", "none", "pass",
  links), inv.link.lbl = "response", predict.type,
  bias.adjust = get_emm_option("back.bias.adj"), sigma, N.sim,
  sim = mvtnorm::rmvnorm, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="regrid_+3A_object">object</code></td>
<td>
<p>An object of class <code>emmGrid</code></p>
</td></tr>
<tr><td><code id="regrid_+3A_transform">transform</code></td>
<td>
<p>Character, list, or logical value. If <code>"response"</code>,
<code>"mu"</code>, or <code>TRUE</code>, the inverse transformation is applied to the
estimates in the grid (but if there is both a link function and a response
transformation, <code>"mu"</code> back-transforms only the link part); if
<code>"none"</code> or <code>FALSE</code>, <code>object</code> is re-gridded so that its
<code>bhat</code> slot contains <code>predict(object)</code> and its <code>linfct</code> slot
is the identity. Any internal transformation information is preserved. If
<code>transform = "pass"</code>, the object is not re-gridded in any way (this
may be useful in conjunction with <code>N.sim</code>).
</p>
<p>If <code>transform</code> is a character value in <code>links</code> (which is the set
of valid arguments for the <code><a href="stats.html#topic+make.link">make.link</a></code> function, excepting
<code>"identity"</code>), or if <code>transform</code> is a list of the same form as
returned by <code>make.links</code> or <code><a href="#topic+make.tran">make.tran</a></code>, the results are
formulated as if the response had been transformed with that link function.</p>
</td></tr>
<tr><td><code id="regrid_+3A_inv.link.lbl">inv.link.lbl</code></td>
<td>
<p>Character value. This applies only when <code>transform</code> 
is in <code>links</code>, and is used to label the predictions if subsequently summarized
with <code>type = "response"</code>.</p>
</td></tr>
<tr><td><code id="regrid_+3A_predict.type">predict.type</code></td>
<td>
<p>Character value. If provided, the returned object is
updated with the given type to use by default by <code>summary.emmGrid</code>
(see <code><a href="#topic+update.emmGrid">update.emmGrid</a></code>).  This may be useful if, for example,
when one specifies <code>transform = "log"</code> but desires summaries to be
produced by default on the response scale.</p>
</td></tr>
<tr><td><code id="regrid_+3A_bias.adjust">bias.adjust</code></td>
<td>
<p>Logical value for whether to adjust for bias in
back-transforming (<code>transform = "response"</code>). This requires a valid value of 
<code>sigma</code> to exist in the object or be specified.</p>
</td></tr>
<tr><td><code id="regrid_+3A_sigma">sigma</code></td>
<td>
<p>Error SD assumed for bias correction (when 
<code>transform = "response"</code> and a transformation
is in effect). If not specified,
<code>object@misc$sigma</code> is used, and a warning is issued if it is not found.</p>
</td></tr>
<tr><td><code id="regrid_+3A_n.sim">N.sim</code></td>
<td>
<p>Integer value. If specified and <code>object</code> is based on a 
frequentist model (i.e., does not have a posterior sample), then a fake 
posterior sample is generated using the function <code>sim</code>.</p>
</td></tr>
<tr><td><code id="regrid_+3A_sim">sim</code></td>
<td>
<p>A function of three arguments (no names are assumed).
If <code>N.sim</code> is supplied with a frequentist model, this function is called
with respective arguments <code>N.sim</code>, <code>object@bhat</code>, and <code>object@V</code>.
The default is the multivariate normal distribution.</p>
</td></tr>
<tr><td><code id="regrid_+3A_...">...</code></td>
<td>
<p>Ignored.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>regrid</code> function reparameterizes an existing <code>ref.grid</code> so
that its <code>linfct</code> slot is the identity matrix and its <code>bhat</code> slot
consists of the estimates at the grid points. If <code>transform</code> is
<code>TRUE</code>, the inverse transform is applied to the estimates. Outwardly,
when <code>transform = "response"</code>, the result of <code><a href="#topic+summary.emmGrid">summary.emmGrid</a></code>
after applying <code>regrid</code> is identical to the summary of the original
object using &lsquo;<span class="samp">&#8288;type="response"&#8288;</span>&rsquo;. But subsequent EMMs or
contrasts will be conducted on the new scale &ndash; which is
the reason this function exists. 
</p>
<p>This function may also be used to simulate a sample of regression
coefficients for a frequentist model for subsequent use as though it were a
Bayesian model. To do so, specify a value for <code>N.sim</code> and a sample is
simulated using the function <code>sim</code>. The grid may be further processed in
accordance with the other arguments; or if <code>transform = "pass"</code>, it is
simply returned with the only change being the addition of the simulated
sample.
</p>


<h3>Value</h3>

<p>An <code>emmGrid</code> object with the requested changes
</p>


<h3>Degrees of freedom</h3>

<p>In cases where the
degrees of freedom depended on the linear function being estimated (e.g.,
Satterthwaite method), the d.f.
from the reference grid are saved, and a kind of &ldquo;containment&rdquo; method
is substituted in the returned object, whereby the calculated d.f. for a new
linear function will be the minimum d.f. among those having nonzero
coefficients. This is kind of an <em>ad hoc</em> method, and it can
over-estimate the degrees of freedom in some cases. An annotation is
displayed below any subsequent summary results stating that the 
degrees-of-freedom method is inherited from the previous method at
the time of re-gridding.
</p>


<h3>Note</h3>

<p>Another way to use <code>regrid</code> is to supply a <code>regrid</code> 
argument to <code><a href="#topic+ref_grid">ref_grid</a></code> (either directly of indirectly via
<code><a href="#topic+emmeans">emmeans</a></code>), in which case its value is passed to <code>regrid</code> as
<code>transform</code>. This is often a simpler approach if the reference
grid has not already been constructed.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>pigs.lm &lt;- lm(log(conc) ~ source + factor(percent), data = pigs)
rg &lt;- ref_grid(pigs.lm)

# This will yield EMMs as GEOMETRIC means of concentrations:
(emm1 &lt;- emmeans(rg, "source", type = "response"))
pairs(emm1) ## We obtain RATIOS

# This will yield EMMs as ARITHMETIC means of concentrations:
(emm2 &lt;- emmeans(regrid(rg, transform = "response"), "source"))
pairs(emm2)  ## We obtain DIFFERENCES
# Same result, useful if we hadn't already created 'rg'
# emm2 &lt;- emmeans(pigs.lm, "source", regrid = "response")

# Simulate a sample of regression coefficients
set.seed(2.71828)
rgb &lt;- regrid(rg, N.sim = 200, transform = "pass")
emmeans(rgb, "source", type = "response")  ## similar to emm1
</code></pre>

<hr>
<h2 id='str.emmGrid'>Miscellaneous methods for <code>emmGrid</code> objects</h2><span id='topic+str.emmGrid'></span><span id='topic+print.emmGrid'></span><span id='topic+vcov.emmGrid'></span>

<h3>Description</h3>

<p>Miscellaneous methods for <code>emmGrid</code> objects
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'emmGrid'
str(object, ...)

## S3 method for class 'emmGrid'
print(x, ..., export = FALSE)

## S3 method for class 'emmGrid'
vcov(object, ..., sep = get_emm_option("sep"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="str.emmGrid_+3A_object">object</code></td>
<td>
<p>An <code>emmGrid</code> object</p>
</td></tr>
<tr><td><code id="str.emmGrid_+3A_...">...</code></td>
<td>
<p>(required but not used)</p>
</td></tr>
<tr><td><code id="str.emmGrid_+3A_x">x</code></td>
<td>
<p>An <code>emmGrid</code> object</p>
</td></tr>
<tr><td><code id="str.emmGrid_+3A_export">export</code></td>
<td>
<p>Logical value. If <code>FALSE</code>, the object is printed. 
If <code>TRUE</code>, a list is invisibly returned, which contains character
elements named <code>summary</code> and <code>annotations</code> that may be saved 
or displayed as the user sees fit. <code>summary</code> is a character matrix 
(or list of such matrices, if a <code>by</code> variable is in effect).
<code>annotations</code> is a character vector of the annotations that would 
have been printed below the summary or summaries.</p>
</td></tr>
<tr><td><code id="str.emmGrid_+3A_sep">sep</code></td>
<td>
<p>separator for pasting levels in creating row and column
names for <code>vcov()</code> results</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The <code>vcov</code> method returns a symmetric matrix of variances and
covariances for <code>predict.emmGrid(object, type = "lp")</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>warp.lm &lt;- lm(breaks ~ wool * tension, data = warpbreaks)
warp.emm &lt;- emmeans(warp.lm, ~ tension | wool)
vcov(warp.emm) |&gt; zapsmall()

vcov(pairs(warp.emm), sep = "|") |&gt; zapsmall()
</code></pre>

<hr>
<h2 id='summary.emmGrid'>Summaries, predictions, intervals, and tests for <code>emmGrid</code> objects</h2><span id='topic+summary.emmGrid'></span><span id='topic+confint.emmGrid'></span><span id='topic+test'></span><span id='topic+test.emmGrid'></span><span id='topic+predict.emmGrid'></span><span id='topic+as.data.frame.emmGrid'></span><span id='topic++5B.summary_emm'></span>

<h3>Description</h3>

<p>These are the primary methods for obtaining numerical or tabular results from
an <code>emmGrid</code> object. <code>summary.emmGrid</code> is the general function for
summarizing <code>emmGrid</code> objects. It also serves as the print method for
these objects; so for convenience, <code>summary()</code> arguments may be included
in calls to functions such as <code><a href="#topic+emmeans">emmeans</a></code> and
<code><a href="#topic+contrast">contrast</a></code> that construct <code>emmGrid</code> objects. Note that by
default, summaries for Bayesian models are diverted to
<code><a href="#topic+hpd.summary">hpd.summary</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'emmGrid'
summary(object, infer, level, adjust, by,
  cross.adjust = "none", type, df, calc, null, delta, side, frequentist,
  bias.adjust = get_emm_option("back.bias.adj"), sigma, ...)

## S3 method for class 'emmGrid'
confint(object, parm, level = 0.95, ...)

test(object, null, ...)

## S3 method for class 'emmGrid'
test(object, null = 0, joint = FALSE, verbose = FALSE,
  rows, by, status = FALSE, ...)

## S3 method for class 'emmGrid'
predict(object, type, interval = c("none", "confidence",
  "prediction"), level = 0.95,
  bias.adjust = get_emm_option("back.bias.adj"), sigma, ...)

## S3 method for class 'emmGrid'
as.data.frame(x, row.names = NULL, optional,
  check.names = TRUE, destroy.annotations = FALSE, ...)

## S3 method for class 'summary_emm'
x[..., as.df = FALSE]
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.emmGrid_+3A_object">object</code></td>
<td>
<p>An object of class <code>"emmGrid"</code> (see <a href="#topic+emmGrid-class">emmGrid-class</a>)</p>
</td></tr>
<tr><td><code id="summary.emmGrid_+3A_infer">infer</code></td>
<td>
<p>A vector of one or two logical values. The first determines
whether confidence intervals are displayed, and the second determines
whether <em>t</em> tests and <em>P</em> values are displayed. If only one value
is provided, it is used for both.</p>
</td></tr>
<tr><td><code id="summary.emmGrid_+3A_level">level</code></td>
<td>
<p>Numerical value between 0 and 1. Confidence level for confidence
intervals, if <code>infer[1]</code> is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="summary.emmGrid_+3A_adjust">adjust</code></td>
<td>
<p>Character value naming the method used to adjust <code class="reqn">p</code> values
or confidence limits; or to adjust comparison arrows in <code>plot</code>. See
the P-value adjustments section below.</p>
</td></tr>
<tr><td><code id="summary.emmGrid_+3A_by">by</code></td>
<td>
<p>Character name(s) of variables to use for grouping into separate 
tables. This affects the family of tests considered in adjusted <em>P</em>
values.</p>
</td></tr>
<tr><td><code id="summary.emmGrid_+3A_cross.adjust">cross.adjust</code></td>
<td>
<p>Character: <code class="reqn">p</code>-value adjustment method to 
additionally apply <em>across</em> 
the <code>by</code> groups. See the section on P-value adjustments for details.</p>
</td></tr>
<tr><td><code id="summary.emmGrid_+3A_type">type</code></td>
<td>
<p>Character: type of prediction desired. This only has an effect if
there is a known transformation or link function. <code>"response"</code> 
specifies that the inverse transformation be applied. <code>"mu"</code> (or 
equivalently, <code>"unlink"</code>) is usually the same as <code>"response"</code>,
but in the case where the model has both a link function and a response 
transformation, only the link part is back-transformed. Other valid values 
are <code>"link"</code>, <code>"lp"</code>, and <code>"linear.predictor"</code>; these are
equivalent, and request that results be shown for the linear predictor,
with no back-transformation. The default is <code>"link"</code>, unless the 
<code>"predict.type"</code> option is in force; see <code><a href="#topic+emm_options">emm_options</a></code>,
and also the section below on transformations and links.</p>
</td></tr>
<tr><td><code id="summary.emmGrid_+3A_df">df</code></td>
<td>
<p>Numeric. If non-missing, a constant number of degrees of freedom to
use in constructing confidence intervals and <em>P</em> values (<code>NA</code>
specifies asymptotic results).</p>
</td></tr>
<tr><td><code id="summary.emmGrid_+3A_calc">calc</code></td>
<td>
<p>Named list of character value(s) or formula(s).
The expressions in <code>char</code> are evaluated and appended to the
summary, just after the <code>df</code> column. The expression may include
any names up through <code>df</code> in the summary, any additional names in 
<code>object@grid</code> (such as <code>.wgt.</code> or <code>.offset.</code>), or any
earlier elements of <code>calc</code>.</p>
</td></tr>
<tr><td><code id="summary.emmGrid_+3A_null">null</code></td>
<td>
<p>Numeric. Null hypothesis value(s), on the linear-predictor scale,
against which estimates are tested. May be a single value used for all, or
a numeric vector of length equal to the number of tests in each family
(i.e., <code>by</code> group in the displayed table).</p>
</td></tr>
<tr><td><code id="summary.emmGrid_+3A_delta">delta</code></td>
<td>
<p>Numeric value (on the linear-predictor scale). If zero, ordinary
tests of significance are performed. If positive, this specifies a
threshold for testing equivalence (using the TOST or two-one-sided-test
method), non-inferiority, or non-superiority, depending on <code>side</code>. See
Details for how the test statistics are defined.</p>
</td></tr>
<tr><td><code id="summary.emmGrid_+3A_side">side</code></td>
<td>
<p>Numeric or character value specifying whether the test is
left-tailed (<code>-1</code>, <code>"-"</code>, <code>"&lt;"</code>, <code>"left"</code>, or
<code>"nonsuperiority"</code>); right-tailed (<code>1</code>, <code>"+"</code>, <code>"&gt;"</code>,
<code>"right"</code>, or <code>"noninferiority"</code>); or two-sided (<code>0</code>,
<code>2</code>, <code>"!="</code>, <code>"two-sided"</code>, <code>"both"</code>,
<code>"equivalence"</code>, or <code>"="</code>). See the special section below for
more details.</p>
</td></tr>
<tr><td><code id="summary.emmGrid_+3A_frequentist">frequentist</code></td>
<td>
<p>Ignored except if a Bayesian model was fitted. If missing
or <code>FALSE</code>, the object is passed to <code><a href="#topic+hpd.summary">hpd.summary</a></code>. Otherwise, 
a logical value of <code>TRUE</code> will have it return a frequentist summary.</p>
</td></tr>
<tr><td><code id="summary.emmGrid_+3A_bias.adjust">bias.adjust</code></td>
<td>
<p>Logical value for whether to adjust for bias in
back-transforming (<code>type = "response"</code>). This requires a valid value of 
<code>sigma</code> to exist in the object or be specified.</p>
</td></tr>
<tr><td><code id="summary.emmGrid_+3A_sigma">sigma</code></td>
<td>
<p>Error SD assumed for bias correction (when 
<code>type = "response"</code> and a transformation
is in effect), or for constructing prediction intervals. If not specified,
<code>object@misc$sigma</code> is used, and a warning is issued if it is not found
or not valid.
<em>Note:</em> <code>sigma</code> may be a vector, but be careful that it correctly
corresponds (perhaps after recycling) to the order of the reference grid.</p>
</td></tr>
<tr><td><code id="summary.emmGrid_+3A_...">...</code></td>
<td>
<p>Optional arguments such as <code>scheffe.rank</code> 
(see &ldquo;P-value adjustments&rdquo;). 
In <code>confint.emmGrid</code>, 
<code>predict.emmGrid</code>, and 
<code>test.emmGrid</code>, these arguments are passed to
<code>summary.emmGrid</code>.</p>
</td></tr>
<tr><td><code id="summary.emmGrid_+3A_parm">parm</code></td>
<td>
<p>(Required argument for <code>confint</code> methods, but not used)</p>
</td></tr>
<tr><td><code id="summary.emmGrid_+3A_joint">joint</code></td>
<td>
<p>Logical value. If <code>FALSE</code>, the arguments are passed to 
<code><a href="#topic+summary.emmGrid">summary.emmGrid</a></code> with <code>infer=c(FALSE, TRUE)</code>. If <code>joint = 
TRUE</code>, a joint test of the hypothesis L beta = null is performed, where L 
is <code>object@linfct</code> and beta is the vector of fixed effects estimated 
by <code>object@betahat</code>. This will be either an <em>F</em> test or a 
chi-square (Wald) test depending on whether degrees of freedom are 
available. See also <code><a href="#topic+joint_tests">joint_tests</a></code>.</p>
</td></tr>
<tr><td><code id="summary.emmGrid_+3A_verbose">verbose</code></td>
<td>
<p>Logical value. If <code>TRUE</code> and <code>joint = TRUE</code>, a table
of the effects being tested is printed.</p>
</td></tr>
<tr><td><code id="summary.emmGrid_+3A_rows">rows</code></td>
<td>
<p>Integer values. The rows of L to be tested in the joint test. If
missing, all rows of L are used. If not missing, <code>by</code> variables are
ignored.</p>
</td></tr>
<tr><td><code id="summary.emmGrid_+3A_status">status</code></td>
<td>
<p>logical. If <code>TRUE</code>, a <code>note</code> column showing status
flags (for rank deficiencies and estimability issues) is displayed even 
when empty. If <code>FALSE</code>, the column is included only if there are 
such issues.</p>
</td></tr>
<tr><td><code id="summary.emmGrid_+3A_interval">interval</code></td>
<td>
<p>Type of interval desired (partial matching is allowed): 
<code>"none"</code> for no intervals,
otherwise confidence or prediction intervals with given arguments, 
via <code><a href="#topic+confint.emmGrid">confint.emmGrid</a></code>. 
Note: prediction intervals are not available
unless the model family is <code>"gaussian"</code>.</p>
</td></tr>
<tr><td><code id="summary.emmGrid_+3A_x">x</code></td>
<td>
<p>object of the given class</p>
</td></tr>
<tr><td><code id="summary.emmGrid_+3A_row.names">row.names</code></td>
<td>
<p>passed to <code><a href="base.html#topic+as.data.frame">as.data.frame</a></code></p>
</td></tr>
<tr><td><code id="summary.emmGrid_+3A_optional">optional</code></td>
<td>
<p>required argument, but ignored in <code>as.data.frame.emmGrid</code></p>
</td></tr>
<tr><td><code id="summary.emmGrid_+3A_check.names">check.names</code></td>
<td>
<p>passed to <code><a href="base.html#topic+data.frame">data.frame</a></code></p>
</td></tr>
<tr><td><code id="summary.emmGrid_+3A_destroy.annotations">destroy.annotations</code></td>
<td>
<p>Logical value. If <code>FALSE</code>, an object of class
<code>summary_emm</code> is returned (which inherits from <code>data.frame</code>),
but if displayed, details like confidence levels, P-value adjustments, 
transformations, etc. are also shown. But unlike the result
of <code>summary</code>, the number of digits displayed
is obtained from <code>getOption("digits")</code> rather than using the
optimal digits algorithm we usually use. Thus, it is formatted more like a 
regular data frame, but with any annotations and groupings still intact.
If <code>TRUE</code> (not recommended), a &ldquo;plain vanilla&rdquo; data frame is 
returned, based on <code>row.names</code> and <code>check.names</code>.</p>
</td></tr>
<tr><td><code id="summary.emmGrid_+3A_as.df">as.df</code></td>
<td>
<p>Logical value. With <code>x[..., as.df = TRUE]</code>, the result is
object is coerced to a <code><a href="base.html#topic+data.frame">data.frame</a></code> before the subscripting 
is applied. With <code>as.df = FALSE</code>, the result is
returned as a <code>summary_emm</code> object when possible.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>confint.emmGrid</code> is equivalent to <code>summary.emmGrid with 
infer = c(TRUE, FALSE)</code>. The function <code>test.emmGrid</code>, when called with 
<code>joint = FALSE</code>, is equivalent to <code>summary.emmGrid</code> with <code>infer = c(FALSE, TRUE)</code>. 
</p>
<p>With <code>joint = TRUE</code>, <code>test.emmGrid</code> calculates the Wald test of the
hypothesis <code>linfct %*% bhat = null</code>, where <code>linfct</code> and
<code>bhat</code> refer to slots in <code>object</code> (possibly subsetted according to
<code>by</code> or <code>rows</code>). An error is thrown if any row of <code>linfct</code> is
non-estimable. It is permissible for the rows of <code>linfct</code> to be linearly
dependent, as long as <code>null == 0</code>, in which case a reduced set of 
contrasts is tested. Linear dependence and nonzero <code>null</code> cause an 
error. The returned object has an additional <code>"est.fcns"</code> attribute, which
is a list of the linear functions associated with the joint test.
</p>


<h3>Value</h3>

<p><code>summary.emmGrid</code>, <code>confint.emmGrid</code>, and
<code>test.emmGrid</code> return an object of class <code>"summary_emm"</code>, which
is an extension of <code><a href="base.html#topic+data.frame">data.frame</a></code> but with a special <code>print</code>
method that displays it with custom formatting. For models fitted using
MCMC methods, the call is diverted to <code><a href="#topic+hpd.summary">hpd.summary</a></code> (with 
<code>prob</code> set to <code>level</code>, if specified); one may
alternatively use general MCMC summarization tools with the 
results of <code>as.mcmc</code>.
</p>
<p><code>predict</code> returns a vector of predictions for each row of <code>object@grid</code>.
</p>
<p>The <code>as.data.frame</code> method returns an object that inherits 
from <code>"data.frame"</code>.
</p>


<h3>Defaults</h3>

<p>The <code>misc</code> slot in <code>object</code> may contain default values for
<code>by</code>, <code>calc</code>, <code>infer</code>, <code>level</code>, <code>adjust</code>, 
<code>type</code>, <code>null</code>, <code>side</code>, and <code>delta</code>. 
These defaults vary depending
on the code that created the object. The <code><a href="stats.html#topic+update">update</a></code> method may be
used to change these defaults. In addition, any options set using 
&lsquo;<span class="samp">&#8288;emm_options(summary = ...)&#8288;</span>&rsquo; will trump those stored in the object's 
<code>misc</code> slot.
</p>


<h3>Transformations and links</h3>

<p>With <code>type = "response"</code>, the transformation assumed can be found in
&lsquo;<span class="samp">&#8288;object@misc$tran&#8288;</span>&rsquo;, and its label, for the summary is in
&lsquo;<span class="samp">&#8288;object@misc$inv.lbl&#8288;</span>&rsquo;. Any <code class="reqn">t</code> or <code class="reqn">z</code> tests are still performed
on the scale of the linear predictor, not the inverse-transformed one.
Similarly, confidence intervals are computed on the linear-predictor scale,
then inverse-transformed.
</p>


<h3>Bias adjustment when back-transforming</h3>

<p>When <code>bias.adjust</code> is <code>TRUE</code>, then back-transformed estimates
are adjusted by adding 
<code class="reqn">0.5 h''(u)\sigma^2</code>, where <code class="reqn">h</code> is the inverse transformation and
<code class="reqn">u</code> is the linear predictor. This is based on a second-order Taylor
expansion. There are better or exact adjustments for certain specific
cases, and these may be incorporated in future updates.
</p>
<p>Note: In certain models, e.g., those with non-gaussian families,
<code>sigma</code> is initialized as <code>NA</code>, and so by default, bias adjustment
is skipped and a warning is issued. You may override this by specifying a
value for <code>sigma</code>. However, <em>with ordinary generalized linear models,
bias adjustment is inappropriate</em> and you should not try to do it. With GEEs and GLMMs,
you probably should <em>not</em> use <code>sigma(model)</code>, and instead you should create an
appropriate value using the estimated random effects, e.g., from <code>VarCorr(model)</code>.
An example is provided in the &ldquo;transformations&rdquo; vignette.
</p>


<h3>P-value adjustments</h3>

<p>The <code>adjust</code> argument specifies a multiplicity adjustment for tests or
confidence intervals. This adjustment always is applied <em>separately</em>
to each table or sub-table that you see in the printed output (see
<code><a href="#topic+rbind.emmGrid">rbind.emmGrid</a></code> for how to combine tables). If there are non-estimable
cases in a <code>by</code> group, those cases are <em>excluded</em> before determining
the adjustment; that means there could be different adjustments in different groups.
</p>
<p>The valid values of <code>adjust</code> are as follows:
</p>

<dl>
<dt><code>"tukey"</code></dt><dd><p>Uses the Studentized range distribution with the number
of means in the family. (Available for two-sided cases only.)</p>
</dd>
<dt><code>"scheffe"</code></dt><dd><p>Computes <code class="reqn">p</code> values from the <code class="reqn">F</code>
distribution, according to the Scheffe critical value of
<code class="reqn">\sqrt{rF(\alpha; r, d)}</code>, where <code class="reqn">d</code> is
the error degrees of freedom and <code class="reqn">r</code> is the rank of the set of linear
functions under consideration. By default, the value of <code>r</code> is
computed from <code>object@linfct</code> for each by group; however, if the
user specifies an argument matching <code>scheffe.rank</code>, its value will
be used instead. Ordinarily, if there are <code class="reqn">k</code> means involved, then
<code class="reqn">r = k - 1</code> for a full set of contrasts involving all <code class="reqn">k</code> means, and
<code class="reqn">r = k</code> for the means themselves. (The Scheffe adjustment is available
for two-sided cases only.)</p>
</dd>
<dt><code>"sidak"</code></dt><dd><p>Makes adjustments as if the estimates were independent
(a conservative adjustment in many cases).</p>
</dd>
<dt><code>"bonferroni"</code></dt><dd><p>Multiplies <code class="reqn">p</code> values, or divides significance
levels by the number of estimates. This is a conservative adjustment.</p>
</dd>
<dt><code>"dunnettx"</code></dt><dd><p>Uses our own<em>ad hoc</em> approximation to the 
Dunnett distribution for a family of estimates having pairwise
correlations of <code class="reqn">0.5</code> (as is true when comparing treatments with a
control with equal sample sizes). The accuracy of the approximation
improves with the number of simultaneous estimates, and is much faster
than <code>"mvt"</code>. (Available for two-sided cases only.)</p>
</dd>
<dt><code>"mvt"</code></dt><dd><p>Uses the multivariate <code class="reqn">t</code> distribution to assess the
probability or critical value for the maximum of <code class="reqn">k</code> estimates. This
method produces the same <code class="reqn">p</code> values and intervals as the default
<code>summary</code> or <code>confint</code> methods to the results of
<code><a href="#topic+as.glht">as.glht</a></code>. In the context of pairwise comparisons or comparisons
with a control, this produces &ldquo;exact&rdquo; Tukey or Dunnett adjustments,
respectively. However, the algorithm (from the <span class="pkg">mvtnorm</span> package) uses a
Monte Carlo method, so results are not exactly repeatable unless the same
random-number seed is used (see <code><a href="base.html#topic+Random">set.seed</a></code>). As the family
size increases, the required computation time will become noticeable or even
intolerable, making the <code>"tukey"</code>, <code>"dunnettx"</code>, or others more
attractive.</p>
</dd>
<dt><code>"none"</code></dt><dd><p>Makes no adjustments to the <code class="reqn">p</code> values.</p>
</dd>
</dl>
 
<p>For tests, not confidence intervals, the Bonferroni-inequality-based adjustment
methods in <code><a href="stats.html#topic+p.adjust">p.adjust</a></code> are also available (currently, these
include <code>"holm"</code>, <code>"hochberg"</code>, <code>"hommel"</code>,
<code>"bonferroni"</code>, <code>"BH"</code>, <code>"BY"</code>, <code>"fdr"</code>, and
<code>"none"</code>). If a <code>p.adjust.methods</code> method other than
<code>"bonferroni"</code> or <code>"none"</code> is specified for confidence limits, the
straight Bonferroni adjustment is used instead. Also, if an adjustment method
is not appropriate (e.g., using <code>"tukey"</code> with one-sided tests, or with
results that are not pairwise comparisons), a more appropriate method
(usually <code>"sidak"</code>) is substituted.
</p>
<p>In some cases, confidence and <code class="reqn">p</code>-value adjustments are only approximate
&ndash; especially when the degrees of freedom or standard errors vary greatly
within the family of tests. The <code>"mvt"</code> method is always the correct
one-step adjustment, but it can be very slow. One may use
<code><a href="#topic+as.glht">as.glht</a></code> with methods in the <span class="pkg">multcomp</span> package to obtain
non-conservative multi-step adjustments to tests.
</p>
<p><em>Warning:</em> Non-estimable cases are <em>included</em> in the family to which adjustments
are applied. You may wish to subset the object using the <code>[]</code> operator
to work around this problem.
</p>
<p>The <code>cross.adjust</code> argument is a way of specifying a multiplicity
adjustment across the <code>by</code> groups (otherwise by default, each group is
treated as a separate family in regards to multiplicity adjustments). It
applies only to <code class="reqn">p</code> values. Valid options are one of the
<code>p.adjust.methods</code> or <code>"sidak"</code>. This argument is ignored unless
it is other than <code>"none"</code>, there is more than one <code>by</code> group, and
they are all the same size. Under those conditions, we first use
<code>adjust</code> to determine the within-group adjusted <code class="reqn">p</code> values.
Imagine each group's adjusted <code class="reqn">p</code> values arranged in side-by-side
columns, thus forming a matrix with the number of columns equal to the
number of <code>by</code> groups. Then we use the <code>cross.adjust</code> method to
further adjust the adjusted <code class="reqn">p</code> values in each row of this matrix. Note
that an <em>overall</em> Bonferroni (or Sidak) adjustment is obtainable by
specifying <em>both</em> <code>adjust</code> and <code>cross.adjust</code> as
<code>"bonferroni"</code> (or <code>"sidak"</code>). However, less conservative (but
yet conservative) overall adjustments are available when it is possible to
use an &ldquo;exact&rdquo; within-group method (e.g., <code>adjust = "tukey"</code>
for pairwise comparisons) and <code>cross.adjust</code> as a conservative
adjustment. [<code>cross.adjust</code> methods other than <code>"none"</code>, 
<code>"bonferroni"</code>, or <code>"sidak"</code> do not seem advisable, but other 
<code>p.adjust</code> methods are available if you can make sense of them.]
</p>


<h3>Tests of significance, nonsuperiority, noninferiority, or equivalence</h3>

<p>When <code>delta = 0</code>, test statistics are the usual tests of significance.
They are of the form 
&lsquo;<span class="samp">&#8288;(estimate - null)/SE&#8288;</span>&rsquo;. Notationally: 
</p>

<dl>
<dt>Significance</dt><dd><p><code class="reqn">H_0: \theta = \theta_0</code>  versus <br />
<code class="reqn">H_1: \theta &lt; \theta_0</code> (left-sided), or<br />
<code class="reqn">H_1 \theta &gt; \theta_0</code> (right-sided), or<br />
<code class="reqn">H_1: \theta \ne \theta_0</code> (two-sided)<br />
The test statistic is<br />
<code class="reqn">t = (Q - \theta_0)/SE</code><br /> 
where <code class="reqn">Q</code> is our estimate of <code class="reqn">\theta</code>;
then left, right, or two-sided <code class="reqn">p</code> values are produced, 
depending on <code>side</code>.</p>
</dd>
</dl>

<p>When <code>delta</code> is positive, the test statistic depends on <code>side</code> as
follows.
</p>

<dl>
<dt>Left-sided (nonsuperiority)</dt><dd><p><code class="reqn">H_0: \theta \ge \theta_0 + \delta</code>
versus <code class="reqn">H_1: \theta &lt; \theta_0 + \delta</code><br /> 
<code class="reqn">t = (Q - \theta_0 - \delta)/SE</code><br /> 
The <code class="reqn">p</code> value is the lower-tail probability.</p>
</dd>
<dt>Right-sided (noninferiority)</dt><dd><p><code class="reqn">H_0: \theta \le \theta_0 - \delta</code>
versus <code class="reqn">H_1: \theta &gt; \theta_0 - \delta</code><br /> 
<code class="reqn">t = (Q - \theta_0 + \delta)/SE</code><br />
The <code class="reqn">p</code> value is the upper-tail probability.</p>
</dd>
<dt>Two-sided (equivalence)</dt><dd><p><code class="reqn">H_0: |\theta - \theta_0| \ge \delta</code>
versus <code class="reqn">H_1: |\theta - \theta_0| &lt; \delta</code><br />
<code class="reqn">t = (|Q - \theta_0| - \delta)/SE</code><br />
The <code class="reqn">p</code> value is the <em>lower</em>-tail probability.<br />
Note that <code class="reqn">t</code> is the maximum of <code class="reqn">t_{nonsup}</code> and <code class="reqn">-t_{noninf}</code>. 
This is equivalent to choosing the less 
significant result in the two-one-sided-test (TOST) procedure.</p>
</dd>
</dl>
 


<h3>Non-estimable cases</h3>

<p>When the model is rank-deficient, each row <code>x</code> of <code>object</code>'s
<code>linfct</code> slot is checked for estimability. If <code>sum(x*bhat)</code>
is found to be non-estimable, then the string <code>NonEst</code> is displayed for the
estimate, and associated statistics are set to <code>NA</code>. 
The estimability check is performed
using the orthonormal basis <code>N</code> in the <code>nbasis</code> slot for the null
space of the rows of the model matrix. Estimability fails when
<code class="reqn">||Nx||^2 / ||x||^2</code> exceeds <code>tol</code>, which by default is
<code>1e-8</code>. You may change it via <code><a href="#topic+emm_options">emm_options</a></code> by setting
<code>estble.tol</code> to the desired value.
</p>
<p>See the warning above that non-estimable cases are still included when
determining the family size for <em>P</em>-value adjustments.
</p>


<h3>Warning about potential misuse of P values</h3>

<p>Some in the statistical and scientific community argue that
the term &ldquo;statistical significance&rdquo; should be completely abandoned, and
that criteria such as &ldquo;p &lt; 0.05&rdquo; never be used to assess the
importance of an effect. These practices can be too misleading and are prone to abuse.
See <a href="../doc/basics.html#pvalues">the &ldquo;basics&rdquo; vignette</a> for more
discussion.
</p>


<h3>Note</h3>

<p>In doing testing and a transformation and/or link is in force, any
<code>null</code> and/or <code>delta</code> values specified must always be on the
scale of the linear predictor, regardless of the setting for 'type'. If
<code>type = "response"</code>, the null value displayed in the summary table 
will be back-transformed from the value supplied by the user. But the
displayed <code>delta</code> will not be changed, because there (often) is
not a natural way to back-transform it.
</p>
<p>When we have <code>type = "response"</code>, and <code>bias.adj = TRUE</code>,
the <code>null</code> value displayed in the output is both back-transformed
and bias-adjusted, leading to a rather non-intuitive-looking null value.
However, since the tests themselves are performed on the link scale,
this is the response value at which a *P* value of 1 would be obtained.
</p>
<p>The default <code>show</code> method for <code>emmGrid</code> objects (with the
exception of newly created reference grids) is <code>print(summary())</code>.
Thus, with ordinary usage of <code><a href="#topic+emmeans">emmeans</a></code> and such, it is
unnecessary to call <code>summary</code> unless there is a need to
specify other than its default options.
</p>
<p>If a data frame is needed, <code>summary</code>, <code>confint</code>,
and <code>test</code> serve this need. <code>as.data.frame</code> routes to
<code>summary</code> by default; calling it with <code>destroy.annotations = TRUE</code>
is not recommended for exactly that reason.
If you want to see more digits in the output, use
<code>print(summary(object), digits = ...)</code>; and if you <em>always</em> want
to see more digits, use <code>emm_options(opt.digits = FALSE)</code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+hpd.summary">hpd.summary</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>warp.lm &lt;- lm(breaks ~ wool * tension, data = warpbreaks)
warp.emm &lt;- emmeans(warp.lm, ~ tension | wool)
warp.emm    # implicitly runs 'summary'

confint(warp.emm, by = NULL, level = .90)

# --------------------------------------------------------------
pigs.lm &lt;- lm(log(conc) ~ source + factor(percent), data = pigs)
pigs.emm &lt;- emmeans(pigs.lm, "percent", type = "response")
summary(pigs.emm)    # (inherits type = "response")
summary(pigs.emm, calc = c(n = ".wgt."))  # Show sample size

# For which percents is EMM non-inferior to 35, based on a 10% threshold?
# Note the test is done on the log scale even though we have type = "response"
test(pigs.emm, null = log(35), delta = log(1.10), side = "&gt;")

con &lt;- contrast(pigs.emm, "consec")
test(con)

test(con, joint = TRUE)

# default Scheffe adjustment - rank = 3
summary(con, infer = c(TRUE, TRUE), adjust = "scheffe")

# Consider as some of many possible contrasts among the six cell means
summary(con, infer = c(TRUE, TRUE), adjust = "scheffe", scheffe.rank = 5)

# Show estimates to more digits
print(test(con), digits = 7)

# --------------------------------------------------------------
# Cross-adjusting P values
prs &lt;- pairs(warp.emm)   # pairwise comparisons of tension, by wool
test(prs, adjust = "tukey", cross.adjust = "bonferroni")

# Same comparisons taken as one big family (more conservative)
test(prs, adjust = "bonferroni", by = NULL)

</code></pre>

<hr>
<h2 id='ubds'>Unbalanced dataset</h2><span id='topic+ubds'></span>

<h3>Description</h3>

<p>This is a simulated unbalanced dataset with three factors
and two numeric variables. There are true relationships among these variables.
This dataset can be useful in testing or illustrating messy-data situations.
There are no missing data, and there is at least one observation for every 
factor combination; however, the <code>"cells"</code> attribute makes it simple
to construct subsets that have empty cells.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ubds
</code></pre>


<h3>Format</h3>

<p>A data frame with 100 observations, 5 variables,
and a special <code>"cells"</code> attribute:
</p>

<dl>
<dt>A</dt><dd><p>Factor with levels 1, 2, and 3</p>
</dd>
<dt>B</dt><dd><p>Factor with levels 1, 2, and 3</p>
</dd>
<dt>C</dt><dd><p>Factor with levels 1, 2, and 3</p>
</dd>
<dt>x</dt><dd><p>A numeric variable</p>
</dd>
<dt>y</dt><dd><p>A numeric variable</p>
</dd>
</dl>

<p>In addition, <code>attr(ubds, "cells")</code> consists of a named list of length 27 with the row numbers for
each combination of <code>A, B, C</code>. For example, 
<code>attr(ubds, "cells")[["213"]]</code> has the row numbers corresponding
to levels <code>A == 2, B == 1, C == 3</code>. The entries are ordered by
length, so the first entry is the cell with the lowest frequency.
</p>


<h3>Examples</h3>

<pre><code class='language-R'> # Omit the three lowest-frequency cells
 low3 &lt;- unlist(attr(ubds, "cells")[1:3]) 
 messy.lm &lt;- lm(y ~ (x + A + B + C)^3, data = ubds, subset = -low3)
  
</code></pre>

<hr>
<h2 id='untidy'>Dare to be un-&quot;tidy&quot;!</h2><span id='topic+untidy'></span>

<h3>Description</h3>

<p>Users who use <span class="pkg">emmeans</span> functions as part of a pipeline &ndash; or post-process 
those results in some other way &ndash; are likely missing some important information.
</p>


<h3>Details</h3>

<p>Your best bet is to display the actual results without any post-processing.
That's because <code>emmeans</code> and its relatives have their own <code>summary</code> 
and <code>print</code> methods that display annotations that may be helpful in
explaining what you have. If you just pipe the results into the next step,
those annotations are stripped away and you never see them. Statistical
analysis is not just a workflow; it is a discipline that involves care in
interpreting intermediate results, and thinking before moving on.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>neur.glm &lt;- glm(Pain ~ Treatment + Sex + Age, family = binomial(),
            data = neuralgia)
            
### The actual results with annotations (e.g. ests are on logit scale):
emmeans(neur.glm, "Treatment")

### Post-processed results lose the annotations
if(requireNamespace("tibble")) {
    emmeans(neur.glm, "Treatment") |&gt; tibble::as_tibble()
}

</code></pre>

<hr>
<h2 id='update.emmGrid'>Update an <code>emmGrid</code> object</h2><span id='topic+update.emmGrid'></span><span id='topic+levels+3C-.emmGrid'></span><span id='topic+update.summary_emm'></span>

<h3>Description</h3>

<p>Objects of class <code>emmGrid</code> contain several settings that affect such things as
what arguments to pass to <code><a href="#topic+summary.emmGrid">summary.emmGrid</a></code>. 
The <code>update</code> method allows safer management of these settings than
by direct modification of its slots.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'emmGrid'
update(object, ..., silent = FALSE)

## S3 replacement method for class 'emmGrid'
levels(x) &lt;- value

## S3 method for class 'summary_emm'
update(object, by.vars, mesg, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="update.emmGrid_+3A_object">object</code></td>
<td>
<p>An <code>emmGrid</code> object</p>
</td></tr>
<tr><td><code id="update.emmGrid_+3A_...">...</code></td>
<td>
<p>Options to be set. These must match a list of known options (see
Details)</p>
</td></tr>
<tr><td><code id="update.emmGrid_+3A_silent">silent</code></td>
<td>
<p>Logical value. If <code>FALSE</code> (the default), a message is
displayed if any options are not matched. If <code>TRUE</code>, no messages are
shown.</p>
</td></tr>
<tr><td><code id="update.emmGrid_+3A_x">x</code></td>
<td>
<p>an <code>emmGrid</code> object</p>
</td></tr>
<tr><td><code id="update.emmGrid_+3A_value">value</code></td>
<td>
<p><code>list</code> or replacement levels. See the documentation for
<code>update.emmGrid</code> with the <code>levels</code> argument, 
as well as the section below on &ldquo;Replaciong levels&rdquo;</p>
</td></tr>
<tr><td><code id="update.emmGrid_+3A_by.vars">by.vars</code>, <code id="update.emmGrid_+3A_mesg">mesg</code></td>
<td>
<p>Attributes that can be altered in <code>update.summary_emm</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>an updated <code>emmGrid</code> object.
</p>
<p><code>levels&lt;-</code> replaces the levels of the object in-place.
See the section on replacing levels for details.
</p>


<h3>Details</h3>

<p>The names in <code>...</code> are partially matched against those that are valid, and if a match is found, it adds or replaces the current setting. The valid names are
</p>

<dl>
<dt><code>tran</code>, <code>tran2</code></dt><dd><p>(<code>list</code> or <code>character</code>) specifies
the transformation which, when inverted, determines the results displayed by
<code><a href="#topic+summary.emmGrid">summary.emmGrid</a></code>, <code><a href="#topic+predict.emmGrid">predict.emmGrid</a></code>, or <code><a href="#topic+emmip">emmip</a></code> when
<code>type="response"</code>. The value may be the name of a standard
transformation from <code><a href="stats.html#topic+make.link">make.link</a></code> or additional ones supported by
name, such as <code>"log2"</code>; or, for a custom transformation, a <code>list</code>
containing at least the functions <code>linkinv</code> (the inverse of the
transformation) and <code>mu.eta</code> (the derivative thereof). The
<code><a href="#topic+make.tran">make.tran</a></code> function returns such lists for a number of popular
transformations. See the help page of <code><a href="#topic+make.tran">make.tran</a></code> for details as
well as information on the additional named transformations that are
supported. <code>tran2</code> is just like <code>tran</code> except it is a second
transformation (i.e., a response transformation in a generalized linear
model).</p>
</dd>
<dt><code>tran.mult</code></dt><dd><p>Multiple for <code>tran</code>. For example, for the
response transformation &lsquo;<span class="samp">&#8288;2*sqrt(y)&#8288;</span>&rsquo; (or &lsquo;<span class="samp">&#8288;sqrt(y) + sqrt(y + 1)&#8288;</span>&rsquo;,
for that matter), we should have <code>tran = "sqrt"</code> and <code>tran.mult =
2</code>. If absent, a multiple of 1 is assumed.</p>
</dd>
<dt><code>tran.offset</code></dt><dd><p>Additive constant before a transformation is applied.
For example, a response transformation of <code>log(y + pi)</code> has
<code>tran.offset  = pi</code>. If no value is present, an offset of 0 is assumed.</p>
</dd>
<dt><code>estName</code></dt><dd><p>(<code>character</code>) is the column label used for
displaying predictions or EMMs.</p>
</dd>
<dt><code>inv.lbl</code></dt><dd><p>(<code>character)</code>) is the column label to use for
predictions or EMMs when <code>type="response"</code>.</p>
</dd>
<dt><code>by.vars</code></dt><dd><p>(<code>character)</code> vector or <code>NULL</code>) the variables
used for grouping in the summary, and also for defining subfamilies in a call
to <code><a href="#topic+contrast">contrast</a></code>.</p>
</dd>
<dt><code>pri.vars</code></dt><dd><p>(<code>character</code> vector) are the names of the grid
variables that are not in <code>by.vars</code>. Thus, the combinations of their
levels are used as columns in each table produced by <code><a href="#topic+summary.emmGrid">summary.emmGrid</a></code>.</p>
</dd>
<dt><code>alpha</code></dt><dd><p>(numeric) is the default significance level for tests, in
<code><a href="#topic+summary.emmGrid">summary.emmGrid</a></code> as well as <code><a href="#topic+plot.emmGrid">plot.emmGrid</a></code>
when &lsquo;<span class="samp">&#8288;CIs = TRUE&#8288;</span>&rsquo;. Be cautious that methods that depend on
specifying <code>alpha</code> are prone to abuse. See the
discussion in <a href="../doc/basics.html#pvalues"><code>vignette("basics", "emmeans")</code></a>.</p>
</dd>
<dt><code>adjust</code></dt><dd><p>(<code>character)</code>) is the default for the <code>adjust</code>
argument in <code><a href="#topic+summary.emmGrid">summary.emmGrid</a></code>.</p>
</dd>
<dt><code>cross.adjust</code></dt><dd><p>(<code>character)</code>) is the default for the <code>cross.adjust</code>
argument in <code><a href="#topic+summary.emmGrid">summary.emmGrid</a></code> (used for adjusting between groups).</p>
</dd>
<dt><code>famSize</code></dt><dd><p>(integer) is the number of means involved in a family of
inferences; used in Tukey adjustment</p>
</dd>
<dt><code>infer</code></dt><dd><p>(<code>logical</code> vector of length 2) is the default value
of <code>infer</code> in <code><a href="#topic+summary.emmGrid">summary.emmGrid</a></code>.</p>
</dd>
<dt><code>level</code></dt><dd><p>(numeric) is the default confidence level, <code>level</code>,
in <code><a href="#topic+summary.emmGrid">summary.emmGrid</a></code>. <em>Note:</em> You must specify all five letters 
of &lsquo;level&rsquo; to distinguish it from the slot name &lsquo;levels&rsquo;.</p>
</dd>
<dt><code>df</code></dt><dd><p>(numeric) overrides the default degrees of freedom with a
specified single value.</p>
</dd>
<dt><code>calc</code></dt><dd><p>(list) additional calculated columns. See <code><a href="#topic+summary.emmGrid">summary.emmGrid</a></code>.</p>
</dd>
<dt><code>null</code></dt><dd><p>(numeric) null hypothesis for <code>summary</code> or
<code>test</code> (taken to be zero if missing).</p>
</dd>
<dt><code>side</code></dt><dd><p>(numeric or character) <code>side</code> specification for for
<code>summary</code> or <code>test</code> (taken to be zero if missing).</p>
</dd>
<dt><code>sigma</code></dt><dd><p>(numeric) Error SD to use in predictions and for bias-adjusted
back-transformations</p>
</dd>
<dt><code>delta</code></dt><dd><p>(numeric) <code>delta</code> specification for <code>summary</code>
or <code>test</code> (taken to be zero if missing).</p>
</dd>
<dt><code>predict.type</code> or <code>type</code></dt><dd><p>(character) sets the default method
of displaying predictions in <code><a href="#topic+summary.emmGrid">summary.emmGrid</a></code>,
<code><a href="#topic+predict.emmGrid">predict.emmGrid</a></code>, and <code><a href="#topic+emmip">emmip</a></code>. Valid values are
<code>"link"</code> (with synonyms <code>"lp"</code> and <code>"linear"</code>), or
<code>"response"</code>.</p>
</dd>
<dt><code>bias.adjust</code>, <code>frequentist</code></dt><dd><p>(logical) These
are used by <code>summary</code> if the value of these arguments are not specified.</p>
</dd>
<dt><code>estType</code></dt><dd><p>(<code>character</code>) is used internally to determine 
what <code>adjust</code> methods are appropriate. It should match one of 
&lsquo;<span class="samp">&#8288;c("prediction", "contrast", "pairs")&#8288;</span>&rsquo;. As an example of why this is needed,
the Tukey adjustment should only be used for pairwise comparisons 
(<code>estType = "pairs"</code>); if <code>estType</code> is some other string, Tukey
adjustments are not allowed.</p>
</dd>
<dt><code>avgd.over</code></dt><dd><p>(<code>character)</code> vector) are the names of the 
variables whose levels are averaged over in obtaining marginal averages of 
predictions, i.e., estimated marginal means. Changing this might produce a 
misleading printout, but setting it to <code>character(0)</code> will suppress the 
&ldquo;averaged over&rdquo; message in the summary.</p>
</dd>
<dt><code>initMesg</code></dt><dd><p>(<code>character</code>) is a string that is added to the
beginning of any annotations that appear below the <code><a href="#topic+summary.emmGrid">summary.emmGrid</a></code>
display.</p>
</dd>
<dt><code>methDesc</code></dt><dd><p>(<code>character</code>) is a string that may be used for
creating names for a list of <code>emmGrid</code> objects. </p>
</dd>
<dt><code>nesting</code></dt><dd><p>(Character or named <code>list</code>) specifies the nesting
structure. See &ldquo;Recovering or overriding model information&rdquo; in the
documentation for <code><a href="#topic+ref_grid">ref_grid</a></code>. The current nesting structure is
displayed by <code><a href="#topic+str.emmGrid">str.emmGrid</a></code>.</p>
</dd>
<dt><code>levels</code></dt><dd><p>named <code>list</code> of new levels for the elements of the
current <code>emmGrid</code>. The list name(s) are used as new variable names, and
if needed, the list is expanded using <code>expand.grid</code>. These results replace
current variable names and levels. This specification changes the <code>levels</code>,
<code>grid</code>, <code>roles</code>, and <code>misc</code> slots in the updated <code>emmGrid</code>,
and resets <code>pri.vars</code>, <code>by.vars</code>, <code>adjust</code>, <code>famSize</code>,
and <code>avgd.over</code>. In addition, if there is nesting of factors, that may be 
altered; a warning is issued if it involves something other than mere name changes.
<em>Note:</em> All six letters of <code>levels</code> is needed in order to distinguish
it from <code>level</code>.</p>
</dd>
<dt><code>submodel</code></dt><dd><p><code>formula</code> or <code>character</code> value specifying a 
submodel (requires this feature being supported by underlying methods 
for the model class). When specified, the <code>linfct</code> slot is replaced by 
its aliases for the specified sub-model. Any factors in the sub-model that 
do not appear in the model matrix are ignored, as are any interactions that 
are not in the main model, and any factors associate with multivariate responses. 
The estimates displayed are then computed as if 
the sub-model had been fitted. (However, the standard errors will be based on the
error variance(s) of the full model.) 
<em>Note:</em> The formula should refer only to predictor names, <em>excluding</em> any
function calls (such as <code>factor</code> or <code>poly</code>) that appear in the 
original model formula. See the example.
</p>
<p>The character values allowed should partially 
match <code>"minimal"</code> or <code>"type2"</code>. With <code>"minimal"</code>, the sub-model
is taken to be the one only involving the surviving factors in <code>object</code>
(the ones averaged over being omitted). Specifying <code>"type2"</code> is the same as
<code>"minimal"</code> except only the highest-order term in the submodel is retained,
and all effects not containing it are orthogonalized-out. Thus, in a purely linear
situation such as an <code>lm</code> model, the joint test
of the modified object is in essence a type-2 test as in <code>car::Anova</code>.
</p>
<p>For some objects such as generalized linear models, specifying <code>submodel</code>
will typically not produce the same estimates or type-2 tests as would be
obtained by actually fitting a separate model with those specifications.
The reason is that those models are fitted by iterative-reweighting methods,
whereas the <code>submodel</code> calculations preserve the final weights used in
fitting the full model.</p>
</dd>
<dt>(any other slot name)</dt><dd><p>If the name matches an element of
<code>slotNames(object)</code> other than <code>levels</code>, that slot is replaced by 
the supplied value, if it is of the required class (otherwise an error occurs). 
</p>
<p>The user must be very careful in
replacing slots because they are interrelated; for example, the lengths
and dimensions of <code>grid</code>, <code>linfct</code>, <code>bhat</code>, and <code>V</code> must
conform.</p>
</dd>
</dl>
 


<h3>Replacing levels</h3>

<p>The <code>levels&lt;-</code> method uses <code>update.emmGrid</code> to replace the
levels of one or more factors. This method allows selectively replacing
the levels of just one factor (via subsetting operators), whereas 
<code>update(x, levels = list(...))</code> requires a list of <em>all</em> factors
and their levels. If any factors are to be renamed, we must replace all
levels and include the new names in the replacements. See the examples.
</p>


<h3>Method for <code>summary_emm</code> objects</h3>

<p>This method exists so that we can change the way a summary is displayed,
by changing the by variables or the annotations.
</p>


<h3>Note</h3>

<p>When it makes sense, an option set by <code>update</code> will persist into 
future results based on that object. But some options are disabled as well.
For example, a <code>calc</code> option will be nulled-out if <code>contrast</code>
is called, because it probably will not make sense to do the same 
calculations on the contrast results, and in fact the variable(s) needed
may not even still exist.
<code>factor(percent)</code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+emm_options">emm_options</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Using an already-transformed response:
pigs.lm &lt;- lm(log(conc) ~ source * factor(percent), data = pigs)

# Reference grid that knows about the transformation
# and asks to include the sample size in any summaries:
pigs.rg &lt;- update(ref_grid(pigs.lm), tran = "log", 
                    predict.type = "response",
                    calc = c(n = ~.wgt.))
emmeans(pigs.rg, "source")

# Obtain estimates for the additive model
# [Note that the submodel refers to 'percent', not 'factor(percent)']
emmeans(pigs.rg, "source", submodel = ~ source + percent)

# Type II ANOVA
joint_tests(pigs.rg, submodel = "type2")

## Changing levels of one factor
newrg &lt;- pigs.rg
levels(newrg)$source &lt;- 1:3
newrg

## Unraveling a previously standardized covariate
zd = scale(fiber$diameter)
fibz.lm &lt;- lm(strength ~ machine * zd, data = fiber)
(fibz.rg &lt;- ref_grid(fibz.lm, at = list(zd = -2:2)))   ### 2*SD range
lev &lt;- levels(fibz.rg)
levels(fibz.rg) &lt;- list (
    machine = lev$machine,
    diameter = with(attributes(zd), 
                    `scaled:center` + `scaled:scale` * lev$zd) )
fibz.rg

### Compactify results with a by variable
update(joint_tests(pigs.rg, by = "source"), by = NULL)
</code></pre>

<hr>
<h2 id='xtable.emmGrid'>Using <code>xtable</code> for EMMs</h2><span id='topic+xtable.emmGrid'></span><span id='topic+xtable.summary_emm'></span><span id='topic+print.xtable_emm'></span>

<h3>Description</h3>

<p>These methods provide support for the <span class="pkg">xtable</span> package, enabling 
polished presentations of tabular output from <code><a href="#topic+emmeans">emmeans</a></code>
and other functions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'emmGrid'
xtable(x, caption = NULL, label = NULL, align = NULL,
  digits = 4, display = NULL, auto = FALSE, ...)

## S3 method for class 'summary_emm'
xtable(x, caption = NULL, label = NULL,
  align = NULL, digits = 4, display = NULL, auto = FALSE, ...)

## S3 method for class 'xtable_emm'
print(x, type = getOption("xtable.type", "latex"),
  include.rownames = FALSE, sanitize.message.function = footnotesize, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="xtable.emmGrid_+3A_x">x</code></td>
<td>
<p>Object of class <code>emmGrid</code></p>
</td></tr>
<tr><td><code id="xtable.emmGrid_+3A_caption">caption</code></td>
<td>
<p>Passed to <code><a href="xtable.html#topic+xtableList">xtableList</a></code></p>
</td></tr>
<tr><td><code id="xtable.emmGrid_+3A_label">label</code></td>
<td>
<p>Passed to <code>xtableList</code></p>
</td></tr>
<tr><td><code id="xtable.emmGrid_+3A_align">align</code></td>
<td>
<p>Passed to <code>xtableList</code></p>
</td></tr>
<tr><td><code id="xtable.emmGrid_+3A_digits">digits</code></td>
<td>
<p>Passed to <code>xtableList</code></p>
</td></tr>
<tr><td><code id="xtable.emmGrid_+3A_display">display</code></td>
<td>
<p>Passed to <code>xtableList</code></p>
</td></tr>
<tr><td><code id="xtable.emmGrid_+3A_auto">auto</code></td>
<td>
<p>Passed to <code>xtableList</code></p>
</td></tr>
<tr><td><code id="xtable.emmGrid_+3A_...">...</code></td>
<td>
<p>Arguments passed to <code><a href="#topic+summary.emmGrid">summary.emmGrid</a></code></p>
</td></tr>
<tr><td><code id="xtable.emmGrid_+3A_type">type</code></td>
<td>
<p>Passed to <code><a href="xtable.html#topic+print.xtable">print.xtable</a></code></p>
</td></tr>
<tr><td><code id="xtable.emmGrid_+3A_include.rownames">include.rownames</code></td>
<td>
<p>Passed to <code>print.xtable</code></p>
</td></tr>
<tr><td><code id="xtable.emmGrid_+3A_sanitize.message.function">sanitize.message.function</code></td>
<td>
<p>Passed to <code>print.xtable</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>The methods actually use <code><a href="xtable.html#topic+xtableList">xtableList</a></code>,
because of its ability to display messages such as those for P-value
adjustments. These methods return an object of class <code>"xtable_emm"</code> &ndash;
an extension of <code>"xtableList"</code>. Unlike other <code>xtable</code> methods, the
number of digits defaults to 4; and degrees of freedom and <em>t</em> ratios
are always formatted independently of <code>digits</code>. The <code>print</code> method
uses <code><a href="xtable.html#topic+xtableList">print.xtableList</a></code>, and any <code>...</code> arguments are
passed there.
</p>


<h3>Value</h3>

<p>The <code>xtable</code> methods return an <code>xtable_emm</code>
object, for which its print method is <code>print.xtable_emm</code> .
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if(requireNamespace("xtable"))
    emm_example("xtable")
    # Use emm_example("xtable", list = TRUE) # to just list the code
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
