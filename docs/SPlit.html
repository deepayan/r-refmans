<!DOCTYPE html><html><head><title>Help for package SPlit</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {SPlit}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#SPlit'><p>Split a dataset for training and testing</p></a></li>
<li><a href='#SPlit-package'><p>SPlit</p></a></li>
<li><a href='#splitratio'><p>Optimal splitting ratio</p></a></li>
<li><a href='#subsample'><p>Nearest neighbor subsampling</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Split a Dataset for Training and Testing</td>
</tr>
<tr>
<td>Version:</td>
<td>1.2</td>
</tr>
<tr>
<td>Date:</td>
<td>2022-03-22</td>
</tr>
<tr>
<td>Description:</td>
<td>Procedure to optimally split a dataset for training and testing. 
    'SPlit' is based on the method of support points, which is independent of modeling methods.
    Please see Joseph and Vakayil (2021) &lt;<a href="https://doi.org/10.1080%2F00401706.2021.1921037">doi:10.1080/00401706.2021.1921037</a>&gt; for details.
    This work is supported by U.S. National Science Foundation grant DMREF-1921873.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>Imports:</td>
<td>Rcpp (&ge; 1.0.4)</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp, RcppArmadillo</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.2</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2022-03-22 05:20:04 UTC; akhil</td>
</tr>
<tr>
<td>Author:</td>
<td>Akhil Vakayil [aut, cre],
  Roshan Joseph [aut, ths],
  Simon Mak [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Akhil Vakayil &lt;akhilv@gatech.edu&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2022-03-22 08:00:08 UTC</td>
</tr>
</table>
<hr>
<h2 id='SPlit'>Split a dataset for training and testing</h2><span id='topic+SPlit'></span>

<h3>Description</h3>

<p><code>SPlit()</code> implements the optimal data splitting procedure described in Joseph and Vakayil (2021). <code>SPlit</code> can be applied to both regression and classification problems, and is model-independent. As a preprocessing step, the nominal categorical columns in the dataset must be declared as factors, and the ordinal categorical columns must be converted to numeric using scoring.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SPlit(
  data,
  splitRatio = 0.2,
  kappa = NULL,
  maxIterations = 500,
  tolerance = 1e-10,
  nThreads
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SPlit_+3A_data">data</code></td>
<td>
<p>The dataset including both the predictors and response(s); should not contain missing values, and only numeric and/or factor column(s) are allowed.</p>
</td></tr>
<tr><td><code id="SPlit_+3A_splitratio">splitRatio</code></td>
<td>
<p>The ratio in which the dataset is to be split; should be in (0, 1) e.g. for an 80-20 split, the <code>splitRatio</code> is either 0.8 or 0.2.</p>
</td></tr>
<tr><td><code id="SPlit_+3A_kappa">kappa</code></td>
<td>
<p>If provided, stochastic majorization-minimization is used for computing support points using a random sample from the dataset of size = <code>ceiling(kappa * splitRatio * nrow(data))</code>, in every iteration.</p>
</td></tr>
<tr><td><code id="SPlit_+3A_maxiterations">maxIterations</code></td>
<td>
<p>The maximum number of iterations before the tolerance level is reached during support points optimization.</p>
</td></tr>
<tr><td><code id="SPlit_+3A_tolerance">tolerance</code></td>
<td>
<p>The tolerance level for support points optimization; measured in terms of the maximum point-wise difference in distance between successive solutions.</p>
</td></tr>
<tr><td><code id="SPlit_+3A_nthreads">nThreads</code></td>
<td>
<p>Number of threads to be used for parallel computation; if not supplied, <code>nThreads</code> defaults to maximum available threads.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Support points are defined only for continuous variables. The categorical variables are handled as follows. <code>SPlit()</code> will automatically convert a nominal categorical variable with <code class="reqn">m</code> levels to <code class="reqn">m-1</code> continuous variables using Helmert coding. Ordinal categorical variables should be converted to numerical columns using a scoring method before using <code>SPlit()</code>. 
For example, if the three levels of an ordinal variable are poor, good, and excellent, then the user may choose 1, 2, and 5 to represent the three levels. These values depend on the problem and data collection method, and therefore, <code>SPlit()</code> will not do it automatically. The columns of the resulting numeric dataset are then standardized to have mean zero and variance one. 
<code>SPlit()</code> then computes the support points and calls the provided <code>subsample()</code> function to perform a nearest neighbor subsampling. The indices of this subsample are returned.
</p>
<p><code>SPlit</code> can be time consuming for large datasets. The computational time can be reduced by using the stochastic majorization-minimization technique with a trade-off in the quality of the split. For example, setting <code>kappa = 2</code> will use a random sample, twice the size of the smaller subset in the split, instead of using the whole dataset in every iteration of the support points optimization. Another option for large datasets is to use data twinning (Vakayil and Joseph, 2022) implemented in the <code>R</code> package <a href="https://CRAN.R-project.org/package=twinning"><code>twinning</code></a>. <code>Twinning</code> is extremely fast, but for small datasets, the results may not be as good as <code>SPlit</code>.
</p>


<h3>Value</h3>

<p>Indices of the smaller subset in the split.
</p>


<h3>References</h3>

<p>Joseph, V. R., &amp; Vakayil, A. (2021). SPlit: An Optimal Method for Data Splitting. Technometrics, 1-11. doi:10.1080/00401706.2021.1921037.
</p>
<p>Vakayil, A., &amp; Joseph, V. R. (2022). Data Twinning. Statistical Analysis and Data Mining: The ASA Data Science Journal. https://doi.org/10.1002/sam.11574.
</p>
<p>Mak, S., &amp; Joseph, V. R. (2018). Support points. The Annals of Statistics, 46(6A), 2562-2592.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## 1. An 80-20 split of a numeric dataset
X = rnorm(n = 100, mean = 0, sd = 1)
Y = rnorm(n = 100, mean = X^2, sd = 1)
data = cbind(X, Y)
SPlitIndices = SPlit(data, tolerance = 1e-6, nThreads = 2) 
dataTest = data[SPlitIndices, ]
dataTrain = data[-SPlitIndices, ]
plot(data, main = "SPlit testing set")
points(dataTest, col = 'green', cex = 2)

## 2. An 80-20 split of the iris dataset
SPlitIndices = SPlit(iris, nThreads = 2)
irisTest = iris[SPlitIndices, ]
irisTrain = iris[-SPlitIndices, ]

</code></pre>

<hr>
<h2 id='SPlit-package'>SPlit</h2><span id='topic+SPlit-package'></span>

<h3>Description</h3>

<p>Split a dataset for training and testing
</p>


<h3>Details</h3>

<p>The package <code>SPlit</code> provides the function <code>SPlit()</code> to optimally split a dataset for training and testing using the method of support points (Mak and Joseph, 2018). Support points is a model-independent method for finding optimal representative points of a distribution. <code>SPlit()</code> attempts to obtain a split in which the distribution of both the training and testing sets resemble the distribution of the dataset. The benefits of <code>SPlit</code> over existing data splitting procedures are detailed in Joseph and Vakayil (2021).
</p>


<h3>Author(s)</h3>

<p>Akhil Vakayil, V. Roshan Joseph, Simon Mak
</p>
<p>Maintainer: Akhil Vakayil &lt;akhilv@gatech.edu&gt;
</p>


<h3>References</h3>

<p>Joseph, V. R., &amp; Vakayil, A. (2021). SPlit: An Optimal Method for Data Splitting. Technometrics, 1-11. doi:10.1080/00401706.2021.1921037.
</p>
<p>Mak, S., &amp; Joseph, V. R. (2018). Support points. The Annals of Statistics, 46(6A), 2562-2592.
</p>

<hr>
<h2 id='splitratio'>Optimal splitting ratio</h2><span id='topic+splitratio'></span>

<h3>Description</h3>

<p><code>splitratio()</code> finds the optimal splitting ratio by assuming a polynomial regression model with interactions can approximate the true model. The number of parameters in the model is estimated from the full data using stepwise regression. A simpler solution is to choose the number of parameters to be square root of the number of unique rows in the input matrix of the dataset. Please see Joseph (2022) for details.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>splitratio(x, y, method = "simple", degree = 2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="splitratio_+3A_x">x</code></td>
<td>
<p>Input matrix</p>
</td></tr>
<tr><td><code id="splitratio_+3A_y">y</code></td>
<td>
<p>Response (output variable)</p>
</td></tr>
<tr><td><code id="splitratio_+3A_method">method</code></td>
<td>
<p>This could be “simple” or “regression”. The default method “simple” uses the square root of the number of unique rows in <code>x</code> as the number of parameters, whereas “regression” estimates the number of parameters using stepwise regression. The “regression” method works only with continuous output variable.</p>
</td></tr>
<tr><td><code id="splitratio_+3A_degree">degree</code></td>
<td>
<p>This specifies the degree of the polynomial to be fitted, which is needed only if <code>method</code>=“regression” is used. Default is 2.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Splitting ratio, which is the fraction of the dataset to be used for testing.
</p>


<h3>References</h3>

<p>Joseph, V. R. (2022). Optimal Ratio for Data Splitting. Statistical Analysis &amp; Data Mining: The ASA Data Science Journal, to appear.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>X = rnorm(n=100, mean=0, sd=1) 
Y = rnorm(n=100, mean=X^2, sd=1)
splitratio(x=X, y=Y)
splitratio(x=X, y=Y, method="regression")

</code></pre>

<hr>
<h2 id='subsample'>Nearest neighbor subsampling</h2><span id='topic+subsample'></span>

<h3>Description</h3>

<p><code>subsample()</code> finds the nearest data points in a dataset to a given set of points as described in Joseph and Vakayil (2021). It uses an efficient kd-tree based algorithm that allows for lazy deletion of a data point from the kd-tree, thereby avoiding the need to rebuild the tree after each query. Please see Blanco and Rai (2014) for details.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>	subsample(data, points)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="subsample_+3A_data">data</code></td>
<td>
<p>The dataset; should be numeric.</p>
</td></tr>
<tr><td><code id="subsample_+3A_points">points</code></td>
<td>
<p>The set of query points of the same dimension as the dataset.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Indices of the nearest neighbors in the dataset.
</p>


<h3>References</h3>

<p>Blanco, J. L. &amp; Rai, P. K. (2014). nanoflann: a C++ header-only fork of FLANN, a library for nearest neighbor (NN) with kd-trees. https://github.com/jlblancoc/nanoflann.
</p>
<p>Joseph, V. R., &amp; Vakayil, A. (2021). SPlit: An Optimal Method for Data Splitting. Technometrics, 1-11. doi:10.1080/00401706.2021.1921037.
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
