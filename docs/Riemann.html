<!DOCTYPE html><html><head><title>Help for package Riemann</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {Riemann}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#acg'><p>Angular Central Gaussian Distribution</p></a></li>
<li><a href='#cities'><p>Data : Populated Cities in the U.S.</p></a></li>
<li><a href='#density'><p>S3 method for mixture model : evaluate density</p></a></li>
<li><a href='#ERP'><p>Data : EEG Covariances for Event-Related Potentials</p></a></li>
<li><a href='#gorilla'><p>Data : Gorilla Skull</p></a></li>
<li><a href='#grassmann.optmacg'><p>Estimation of Distribution Algorithm with MACG Distribution</p></a></li>
<li><a href='#grassmann.runif'><p>Generate Uniform Samples on Grassmann Manifold</p></a></li>
<li><a href='#grassmann.utest'><p>Test of Uniformity on Grassmann Manifold</p></a></li>
<li><a href='#hands'><p>Data : Left Hands</p></a></li>
<li><a href='#label'><p>S3 method for mixture model : predict labels</p></a></li>
<li><a href='#loglkd'><p>S3 method for mixture model : log-likelihood</p></a></li>
<li><a href='#macg'><p>Matrix Angular Central Gaussian Distribution</p></a></li>
<li><a href='#moSL'><p>Finite Mixture of Spherical Laplace Distributions</p></a></li>
<li><a href='#moSN'><p>Finite Mixture of Spherical Normal Distributions</p></a></li>
<li><a href='#orbital'><p>Data : Normal Vectors to the Orbital Planes of the 9 Planets</p></a></li>
<li><a href='#passiflora'><p>Data : Passiflora Leaves</p></a></li>
<li><a href='#predict.m2skreg'><p>Prediction for Manifold-to-Scalar Kernel Regression</p></a></li>
<li><a href='#riem.clrq'><p>Competitive Learning Riemannian Quantization</p></a></li>
<li><a href='#riem.coreset18B'><p>Build Lightweight Coreset</p></a></li>
<li><a href='#riem.distlp'><p>Distance between Two Curves on Manifolds</p></a></li>
<li><a href='#riem.dtw'><p>Dynamic Time Warping Distance</p></a></li>
<li><a href='#riem.fanova'><p>Fréchet Analysis of Variance</p></a></li>
<li><a href='#riem.hclust'><p>Hierarchical Agglomerative Clustering</p></a></li>
<li><a href='#riem.interp'><p>Geodesic Interpolation</p></a></li>
<li><a href='#riem.interps'><p>Geodesic Interpolation of Multiple Points</p></a></li>
<li><a href='#riem.isomap'><p>Isometric Feature Mapping</p></a></li>
<li><a href='#riem.kmeans'><p>K-Means Clustering</p></a></li>
<li><a href='#riem.kmeans18B'><p>K-Means Clustering with Lightweight Coreset</p></a></li>
<li><a href='#riem.kmeanspp'><p>K-Means++ Clustering</p></a></li>
<li><a href='#riem.kmedoids'><p>K-Medoids Clustering</p></a></li>
<li><a href='#riem.knn'><p>Find K-Nearest Neighbors</p></a></li>
<li><a href='#riem.kpca'><p>Kernel Principal Component Analysis</p></a></li>
<li><a href='#riem.m2skreg'><p>Manifold-to-Scalar Kernel Regression</p></a></li>
<li><a href='#riem.m2skregCV'><p>Manifold-to-Scalar Kernel Regression with K-Fold Cross Validation</p></a></li>
<li><a href='#riem.mds'><p>Multidimensional Scaling</p></a></li>
<li><a href='#riem.mean'><p>Fréchet Mean and Variation</p></a></li>
<li><a href='#riem.median'><p>Fréchet Median and Variation</p></a></li>
<li><a href='#riem.nmshift'><p>Nonlinear Mean Shift</p></a></li>
<li><a href='#riem.pdist'><p>Compute Pairwise Distances for Data</p></a></li>
<li><a href='#riem.pdist2'><p>Compute Pairwise Distances for Two Sets of Data</p></a></li>
<li><a href='#riem.pga'><p>Principal Geodesic Analysis</p></a></li>
<li><a href='#riem.phate'><p>PHATE</p></a></li>
<li><a href='#riem.rmml'><p>Riemannian Manifold Metric Learning</p></a></li>
<li><a href='#riem.sammon'><p>Sammon Mapping</p></a></li>
<li><a href='#riem.sc05Z'><p>Spectral Clustering by Zelnik-Manor and Perona (2005)</p></a></li>
<li><a href='#riem.scNJW'><p>Spectral Clustering by Ng, Jordan, and Weiss (2002)</p></a></li>
<li><a href='#riem.scSM'><p>Spectral Clustering by Shi and Malik (2000)</p></a></li>
<li><a href='#riem.scUL'><p>Spectral Clustering with Unnormalized Laplacian</p></a></li>
<li><a href='#riem.seb'><p>Find the Smallest Enclosing Ball</p></a></li>
<li><a href='#riem.test2bg14'><p>Two-Sample Test modified from Biswas and Ghosh (2014)</p></a></li>
<li><a href='#riem.test2wass'><p>Two-Sample Test with Wasserstein Metric</p></a></li>
<li><a href='#riem.tsne'><p>t-distributed Stochastic Neighbor Embedding</p></a></li>
<li><a href='#riem.wasserstein'><p>Wasserstein Distance between Empirical Measures</p></a></li>
<li><a href='#rmvnorm'><p>Generate Random Samples from Multivariate Normal Distribution</p></a></li>
<li><a href='#spd.geometry'><p>Supported Geometries on SPD Manifold</p></a></li>
<li><a href='#spd.pdist'><p>Pairwise Distance on SPD Manifold</p></a></li>
<li><a href='#spd.wassbary'><p>Wasserstein Barycenter of SPD Matrices</p></a></li>
<li><a href='#sphere.convert'><p>Convert between Cartesian Coordinates and Geographic Coordinates</p></a></li>
<li><a href='#sphere.runif'><p>Generate Uniform Samples on Sphere</p></a></li>
<li><a href='#sphere.utest'><p>Test of Uniformity on Sphere</p></a></li>
<li><a href='#splaplace'><p>Spherical Laplace Distribution</p></a></li>
<li><a href='#spnorm'><p>Spherical Normal Distribution</p></a></li>
<li><a href='#stiefel.optSA'><p>Simulated Annealing on Stiefel Manifold</p></a></li>
<li><a href='#stiefel.runif'><p>Generate Uniform Samples on Stiefel Manifold</p></a></li>
<li><a href='#stiefel.utest'><p>Test of Uniformity on Stiefel Manifold</p></a></li>
<li><a href='#wrap.correlation'><p>Prepare Data on Correlation Manifold</p></a></li>
<li><a href='#wrap.euclidean'><p>Prepare Data on Euclidean Space</p></a></li>
<li><a href='#wrap.grassmann'><p>Prepare Data on Grassmann Manifold</p></a></li>
<li><a href='#wrap.landmark'><p>Wrap Landmark Data on Shape Space</p></a></li>
<li><a href='#wrap.multinomial'><p>Prepare Data on Multinomial Manifold</p></a></li>
<li><a href='#wrap.rotation'><p>Prepare Data on Rotation Group</p></a></li>
<li><a href='#wrap.spd'><p>Prepare Data on Symmetric Positive-Definite (SPD) Manifold</p></a></li>
<li><a href='#wrap.spdk'><p>Prepare Data on SPD Manifold of Fixed-Rank</p></a></li>
<li><a href='#wrap.sphere'><p>Prepare Data on Sphere</p></a></li>
<li><a href='#wrap.stiefel'><p>Prepare Data on (Compact) Stiefel Manifold</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Learning with Data on Riemannian Manifolds</td>
</tr>
<tr>
<td>Version:</td>
<td>0.1.4</td>
</tr>
<tr>
<td>Description:</td>
<td>We provide a variety of algorithms for manifold-valued data, including Fréchet summaries, hypothesis testing, clustering, visualization, and other learning tasks. See Bhattacharya and Bhattacharya (2012) &lt;<a href="https://doi.org/10.1017%2FCBO9781139094764">doi:10.1017/CBO9781139094764</a>&gt; for general exposition to statistics on manifolds.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>Imports:</td>
<td>CVXR, Rcpp (&ge; 1.0.5), Rdpack, RiemBase, Rdimtools, T4cluster,
DEoptim, lpSolve, Matrix, maotai (&ge; 0.2.2), stats, utils</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://kisungyou.com/Riemann/">https://kisungyou.com/Riemann/</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/kisungyou/Riemann/issues">https://github.com/kisungyou/Riemann/issues</a></td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp, RcppArmadillo</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.2</td>
</tr>
<tr>
<td>RdMacros:</td>
<td>Rdpack</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 2.10)</td>
</tr>
<tr>
<td>Suggests:</td>
<td>R.rsp, knitr, rmarkdown</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>R.rsp, knitr</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2022-02-28 19:30:40 UTC; kisung</td>
</tr>
<tr>
<td>Author:</td>
<td>Kisung You <a href="https://orcid.org/0000-0002-8584-459X"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut,
    cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Kisung You &lt;kisungyou@outlook.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2022-02-28 20:30:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='acg'>Angular Central Gaussian Distribution</h2><span id='topic+acg'></span><span id='topic+dacg'></span><span id='topic+racg'></span><span id='topic+mle.acg'></span>

<h3>Description</h3>

<p>For a hypersphere <code class="reqn">\mathcal{S}^{p-1}</code> in <code class="reqn">\mathbf{R}^p</code>, Angular 
Central Gaussian (ACG) distribution <code class="reqn">ACG_p (A)</code> is defined via a density
</p>
<p style="text-align: center;"><code class="reqn">f(x\vert A) = |A|^{-1/2} (x^\top A^{-1} x)^{-p/2}</code>
</p>
 
<p>with respect to the uniform measure on <code class="reqn">\mathcal{S}^{p-1}</code> and <code class="reqn">A</code> is 
a symmetric positive-definite matrix. Since <code class="reqn">f(x\vert A) = f(-x\vert A)</code>, 
it can also be used as an axial distribution on real projective space, which is
unit sphere modulo <code class="reqn">\lbrace{+1,-1\rbrace}</code>. One constraint we follow is that 
<code class="reqn">f(x\vert A) = f(x\vert cA)</code> for <code class="reqn">c &gt; 0</code> in that we use a normalized 
version for numerical stability by restricting <code class="reqn">tr(A)=p</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dacg(datalist, A)

racg(n, A)

mle.acg(datalist, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="acg_+3A_datalist">datalist</code></td>
<td>
<p>a list of length-<code class="reqn">p</code> unit-norm vectors.</p>
</td></tr>
<tr><td><code id="acg_+3A_a">A</code></td>
<td>
<p>a <code class="reqn">(p\times p)</code> symmetric positive-definite matrix.</p>
</td></tr>
<tr><td><code id="acg_+3A_n">n</code></td>
<td>
<p>the number of samples to be generated.</p>
</td></tr>
<tr><td><code id="acg_+3A_...">...</code></td>
<td>
<p>extra parameters for computations, including</p>

<dl>
<dt>maxiter</dt><dd><p>maximum number of iterations to be run (default:50).</p>
</dd>
<dt>eps</dt><dd><p>tolerance level for stopping criterion (default: 1e-5).</p>
</dd>
</dl>
</td></tr>
</table>


<h3>Value</h3>

<p><code>dacg</code> gives a vector of evaluated densities given samples. <code>racg</code> generates 
unit-norm vectors in <code class="reqn">\mathbf{R}^p</code> wrapped in a list. <code>mle.acg</code> estimates 
the SPD matrix <code class="reqn">A</code>.
</p>


<h3>References</h3>

<p>Tyler DE (1987).
&ldquo;Statistical analysis for the angular central Gaussian distribution on the sphere.&rdquo;
<em>Biometrika</em>, <b>74</b>(3), 579&ndash;589.
ISSN 0006-3444, 1464-3510.
</p>
<p>Mardia KV, Jupp PE (eds.) (1999).
<em>Directional Statistics</em>,  Wiley Series in Probability and Statistics.
John Wiley \&amp; Sons, Inc., Hoboken, NJ, USA.
ISBN 978-0-470-31697-9 978-0-471-95333-3.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># -------------------------------------------------------------------
#          Example with Angular Central Gaussian Distribution
#
# Given a fixed A, generate samples and estimate A via ML.
# -------------------------------------------------------------------
## GENERATE AND MLE in R^5
#  Generate data
Atrue = diag(5)          # true SPD matrix
sam1  = racg(50,  Atrue) # random samples
sam2  = racg(100, Atrue)

#  MLE
Amle1 = mle.acg(sam1)
Amle2 = mle.acg(sam2)

#  Visualize
opar &lt;- par(no.readonly=TRUE)
par(mfrow=c(1,3), pty="s")
image(Atrue[,5:1], axes=FALSE, main="true SPD")
image(Amle1[,5:1], axes=FALSE, main="MLE with n=50")
image(Amle2[,5:1], axes=FALSE, main="MLE with n=100")
par(opar)

</code></pre>

<hr>
<h2 id='cities'>Data : Populated Cities in the U.S.</h2><span id='topic+cities'></span>

<h3>Description</h3>

<p>As of January 2006, there are 60 cities in the contiguous U.S. with population size 
larger than <code class="reqn">300000</code>. We extracted information of the cities from the data 
delivered by <span class="pkg">maps</span> package. Variables <code>coord</code> and <code>cartesian</code> are 
two identical representations of locations, which can be mutually converted by 
<code><a href="#topic+sphere.convert">sphere.convert</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(cities)
</code></pre>


<h3>Format</h3>

<p>a named list containing</p>

<dl>
<dt>names</dt><dd><p>a length-<code class="reqn">60</code> vector of city names.</p>
</dd>
<dt>coord</dt><dd><p>a <code class="reqn">(60\times 2)</code> matrix of latitude and longitude.</p>
</dd>
<dt>cartesian</dt><dd><p>a <code class="reqn">(60\times 3)</code> matrix of cartesian coordinates on the unit sphere.</p>
</dd>
<dt>population</dt><dd><p>a length-<code class="reqn">60</code> vector of cities' populations.</p>
</dd>
</dl>



<h3>See Also</h3>

<p><code><a href="#topic+wrap.sphere">wrap.sphere</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## LOAD THE DATA AND WRAP AS RIEMOBJ
data(cities)
myriem = wrap.sphere(cities$cartesian)

## COMPUTE INTRINSIC/EXTRINSIC MEANS
intmean = as.vector(riem.mean(myriem, geometry="intrinsic")$mean)
extmean = as.vector(riem.mean(myriem, geometry="extrinsic")$mean)

## CONVERT TO GEOGRAPHIC COORDINATES (Lat/Lon)
geo.int = sphere.xyz2geo(intmean)
geo.ext = sphere.xyz2geo(extmean)


</code></pre>

<hr>
<h2 id='density'>S3 method for mixture model : evaluate density</h2><span id='topic+density'></span>

<h3>Description</h3>

<p>Compute density for a fitted mixture model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>density(object, newdata)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="density_+3A_object">object</code></td>
<td>
<p>a fitted mixture model of <code>riemmix</code> class.</p>
</td></tr>
<tr><td><code id="density_+3A_newdata">newdata</code></td>
<td>
<p>data of <code class="reqn">n</code> objects (vectors, matrices) that can be wrapped by one of <code>wrap.*</code> functions in the <span class="pkg">Riemann</span> package.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a length-<code class="reqn">n</code> vector of class labels.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# ---------------------------------------------------- #
#            FIT A MODEL &amp; APPLY THE METHOD
# ---------------------------------------------------- #
# Load the 'city' data and wrap as 'riemobj'
data(cities)
locations = cities$cartesian
embed2    = array(0,c(60,2)) 
for (i in 1:60){
   embed2[i,] = sphere.xyz2geo(locations[i,])
}

# Fit a model
k3 = moSN(locations, k=3)

# Evaluate 
newdensity = density(k3, locations)


</code></pre>

<hr>
<h2 id='ERP'>Data : EEG Covariances for Event-Related Potentials</h2><span id='topic+ERP'></span>

<h3>Description</h3>

<p>This dataset delivers 216 covariance matrices from EEG ERPs with 4 different 
known classes by types of sources. Among 60 channels, only 32 channels are 
taken and sample covariance matrix is computed for each participant. The 
data is taken from a Python library <a href="https://mne.tools/stable/generated/mne.datasets.sample.data_path.html#mne.datasets.sample.data_path">mne</a>'s 
sample data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(ERP)
</code></pre>


<h3>Format</h3>

<p>a named list containing</p>

<dl>
<dt>covariance</dt><dd><p>an <code class="reqn">(32\times 32\times 216)</code> array of covariance matrices.</p>
</dd>
<dt>label</dt><dd><p>a length-<code class="reqn">216</code> factor of 4 different classes.</p>
</dd>
</dl>



<h3>See Also</h3>

<p><code><a href="#topic+wrap.spd">wrap.spd</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## LOAD THE DATA AND WRAP AS RIEMOBJ
data(ERP)
myriem = wrap.spd(ERP$covariance)


</code></pre>

<hr>
<h2 id='gorilla'>Data : Gorilla Skull</h2><span id='topic+gorilla'></span>

<h3>Description</h3>

<p>This is 29 male and 30 female gorillas' skull landmark data where each 
individual is represented as 8-ad/landmarks in 2 dimensions. This is a 
re-arranged version of the data from <span class="pkg">shapes</span> package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(gorilla)
</code></pre>


<h3>Format</h3>

<p>a named list containing</p>

<dl>
<dt>male</dt><dd><p>a 3d array of size <code class="reqn">(8\times 2\times 29)</code></p>
</dd>
<dt>female</dt><dd><p>a 3d array of size <code class="reqn">(8\times 2\times 30)</code></p>
</dd>
</dl>



<h3>References</h3>

<p>Dryden IL, Mardia KV (2016).
<em>Statistical shape analysis with applications in R</em>,  Wiley series in probability and statistics, Second edition edition.
John Wiley \&amp; Sons, Chichester, UK ; Hoboken, NJ.
ISBN 978-1-119-07251-5 978-1-119-07250-8.
</p>
<p>Reno PL, Meindl RS, McCollum MA, Lovejoy CO (2003). &quot;Sexual dimorphism in Australopithecus afarensis was similar to that of modern humans.&quot; <em>Proceedings of the National Academy of Sciences</em>, 100(16):9404–9409.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+wrap.landmark">wrap.landmark</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(gorilla)                               # load the data
riem.female = wrap.landmark(gorilla$female) # wrap as RIEMOBJ
opar &lt;- par(no.readonly=TRUE)
for (i in 1:30){
  if (i &lt; 2){
    plot(riem.female$data[[i]], cex=0.5, 
         xlim=c(-1,1)/2, ylim=c(-2,2)/5,
         main="30 female gorilla skull preshapes",
         xlab="dimension 1", ylab="dimension 2")
    lines(riem.female$data[[i]])
  } else {
    points(riem.female$data[[i]], cex=0.5)
    lines(riem.female$data[[i]])
  }
}
par(opar)

</code></pre>

<hr>
<h2 id='grassmann.optmacg'>Estimation of Distribution Algorithm with MACG Distribution</h2><span id='topic+grassmann.optmacg'></span>

<h3>Description</h3>

<p>For a function <code class="reqn">f : Gr(k,p) \rightarrow \mathbf{R}</code>, find the minimizer 
and the attained minimum value with estimation of distribution algorithm 
using MACG distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>grassmann.optmacg(func, p, k, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="grassmann.optmacg_+3A_func">func</code></td>
<td>
<p>a function to be <em>minimized</em>.</p>
</td></tr>
<tr><td><code id="grassmann.optmacg_+3A_p">p</code></td>
<td>
<p>dimension parameter as in <code class="reqn">Gr(k,p)</code>.</p>
</td></tr>
<tr><td><code id="grassmann.optmacg_+3A_k">k</code></td>
<td>
<p>dimension parameter as in <code class="reqn">Gr(k,p)</code>.</p>
</td></tr>
<tr><td><code id="grassmann.optmacg_+3A_...">...</code></td>
<td>
<p>extra parameters including</p>

<dl>
<dt>n.start</dt><dd><p>number of runs; algorithm is executed <code>n.start</code> times (default: 10).</p>
</dd>
<dt>maxiter</dt><dd><p>maximum number of iterations for each run (default: 100).</p>
</dd>
<dt>popsize</dt><dd><p>the number of samples generated at each step for stochastic search (default: 100).</p>
</dd>
<dt>ratio</dt><dd><p>ratio in <code class="reqn">(0,1)</code> where top <code>ratio*popsize</code> samples are chosen for parameter update (default: 0.25).</p>
</dd>
<dt>print.progress</dt><dd><p>a logical; if <code>TRUE</code>, it prints each iteration (default: <code>FALSE</code>).</p>
</dd>
</dl>
</td></tr>
</table>


<h3>Value</h3>

<p>a named list containing: </p>

<dl>
<dt>cost</dt><dd><p>minimized function value.</p>
</dd>
<dt>solution</dt><dd><p>a <code class="reqn">(p\times k)</code> matrix that attains the <code>cost</code>.</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>#-------------------------------------------------------------------
#               Optimization for Eigen-Decomposition
#
# Given (5x5) covariance matrix S, eigendecomposition is can be 
# considered as an optimization on Grassmann manifold. Here, 
# we are trying to find top 3 eigenvalues and compare.
#-------------------------------------------------------------------

## PREPARE
A = cov(matrix(rnorm(100*5), ncol=5)) # define covariance
myfunc &lt;- function(p){                # cost function to minimize
  return(sum(-diag(t(p)%*%A%*%p)))
} 

## SOLVE THE OPTIMIZATION PROBLEM
Aout = grassmann.optmacg(myfunc, p=5, k=3, popsize=100, n.start=30)

## COMPUTE EIGENVALUES
#  1. USE SOLUTIONS TO THE ABOVE OPTIMIZATION 
abase   = Aout$solution
eig3sol = sort(diag(t(abase)%*%A%*%abase), decreasing=TRUE)

#  2. USE BASIC 'EIGEN' FUNCTION
eig3dec = sort(eigen(A)$values, decreasing=TRUE)[1:3]

## VISUALIZE
opar &lt;- par(no.readonly=TRUE)
yran = c(min(min(eig3sol),min(eig3dec))*0.95,
         max(max(eig3sol),max(eig3dec))*1.05)
plot(1:3, eig3sol, type="b", col="red",  pch=19, ylim=yran,
     xlab="index", ylab="eigenvalue", main="compare top 3 eigenvalues")
lines(1:3, eig3dec, type="b", col="blue", pch=19)
legend(1.55, max(yran), legend=c("optimization","decomposition"), col=c("red","blue"),
       lty=rep(1,2), pch=19)
par(opar)


</code></pre>

<hr>
<h2 id='grassmann.runif'>Generate Uniform Samples on Grassmann Manifold</h2><span id='topic+grassmann.runif'></span>

<h3>Description</h3>

<p>It generates <code class="reqn">n</code> random samples from Grassmann manifold <code class="reqn">Gr(k,p)</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>grassmann.runif(n, k, p, type = c("list", "array", "riemdata"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="grassmann.runif_+3A_n">n</code></td>
<td>
<p>number of samples to be generated.</p>
</td></tr>
<tr><td><code id="grassmann.runif_+3A_k">k</code></td>
<td>
<p>dimension of the subspace.</p>
</td></tr>
<tr><td><code id="grassmann.runif_+3A_p">p</code></td>
<td>
<p>original dimension (of the ambient space).</p>
</td></tr>
<tr><td><code id="grassmann.runif_+3A_type">type</code></td>
<td>
<p>return type; </p>

<dl>
<dt><code>"list"</code></dt><dd><p>a length-<code class="reqn">n</code> list of <code class="reqn">(p\times k)</code> basis of <code class="reqn">k</code>-subspaces.</p>
</dd>
<dt><code>"array"</code></dt><dd><p>a <code class="reqn">(p\times k\times n)</code> 3D array whose slices are <code class="reqn">k</code>-subspace basis.</p>
</dd>
<dt><code>"riemdata"</code></dt><dd><p>a S3 object. See <code><a href="#topic+wrap.grassmann">wrap.grassmann</a></code> for more details.</p>
</dd>
</dl>
</td></tr>
</table>


<h3>Value</h3>

<p>an object from one of the above by <code>type</code> option.
</p>


<h3>References</h3>

<p>Chikuse Y (2003).
<em>Statistics on Special Manifolds</em>, volume 174 of <em>Lecture Notes in Statistics</em>.
Springer New York, New York, NY.
ISBN 978-0-387-00160-9 978-0-387-21540-2.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+stiefel.runif">stiefel.runif</a></code>, <code><a href="#topic+wrap.grassmann">wrap.grassmann</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#-------------------------------------------------------------------
#                 Draw Samples on Grassmann Manifold 
#-------------------------------------------------------------------
#  Multiple Return Types with 3 Observations of 5-dim subspaces in R^10
dat.list = grassmann.runif(n=3, k=5, p=10, type="list")
dat.arr3 = grassmann.runif(n=3, k=5, p=10, type="array")
dat.riem = grassmann.runif(n=3, k=5, p=10, type="riemdata")

</code></pre>

<hr>
<h2 id='grassmann.utest'>Test of Uniformity on Grassmann Manifold</h2><span id='topic+grassmann.utest'></span>

<h3>Description</h3>

<p>Given the data on Grassmann manifold <code class="reqn">Gr(k,p)</code>, it tests whether the 
data is distributed uniformly.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>grassmann.utest(grobj, method = c("Bing", "BingM"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="grassmann.utest_+3A_grobj">grobj</code></td>
<td>
<p>a S3 <code>"riemdata"</code> class of Grassmann-valued data.</p>
</td></tr>
<tr><td><code id="grassmann.utest_+3A_method">method</code></td>
<td>
<p>(case-insensitive) name of the test method containing </p>

<dl>
<dt><code>"Bing"</code></dt><dd><p>Bingham statistic.</p>
</dd>
<dt><code>"BingM"</code></dt><dd><p>modified Bingham statistic with better order of error.</p>
</dd>
</dl>
</td></tr>
</table>


<h3>Value</h3>

<p>a (list) object of <code>S3</code> class <code>htest</code> containing: </p>

<dl>
<dt>statistic</dt><dd><p>a test statistic.</p>
</dd>
<dt>p.value</dt><dd><p><code class="reqn">p</code>-value under <code class="reqn">H_0</code>.</p>
</dd>
<dt>alternative</dt><dd><p>alternative hypothesis.</p>
</dd>
<dt>method</dt><dd><p>name of the test.</p>
</dd>
<dt>data.name</dt><dd><p>name(s) of provided sample data.</p>
</dd>
</dl>



<h3>References</h3>

<p>Chikuse Y (2003).
<em>Statistics on Special Manifolds</em>, volume 174 of <em>Lecture Notes in Statistics</em>.
Springer New York, New York, NY.
ISBN 978-0-387-00160-9 978-0-387-21540-2.
</p>
<p>Mardia KV, Jupp PE (eds.) (1999).
<em>Directional Statistics</em>,  Wiley Series in Probability and Statistics.
John Wiley \&amp; Sons, Inc., Hoboken, NJ, USA.
ISBN 978-0-470-31697-9 978-0-471-95333-3.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+wrap.grassmann">wrap.grassmann</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#-------------------------------------------------------------------
#   Compare Bingham's original and modified versions of the test
# 
# Test 1. sample uniformly from Gr(2,4)
# Test 2. use perturbed principal components from 'iris' data in R^4
#         which is concentrated around a point to reject H0.
#-------------------------------------------------------------------
## Data Generation
#  1. uniform data
myobj1 = grassmann.runif(n=100, k=2, p=4)

#  2. perturbed principal components
data(iris)
irdat = list()
for (n in 1:100){
   tmpdata    = iris[1:50,1:4] + matrix(rnorm(50*4,sd=0.5),ncol=4)
   irdat[[n]] = eigen(cov(tmpdata))$vectors[,1:2]
}
myobj2 = wrap.grassmann(irdat)

## Test 1 : uniform data
grassmann.utest(myobj1, method="Bing")
grassmann.utest(myobj1, method="BingM")

## Tests : iris data
grassmann.utest(myobj2, method="bINg")   # method names are 
grassmann.utest(myobj2, method="BiNgM")  # CASE - INSENSITIVE !

</code></pre>

<hr>
<h2 id='hands'>Data : Left Hands</h2><span id='topic+hands'></span>

<h3>Description</h3>

<p>This dataset contains 10 shapes of 4 subjects's left hands where each shape is represented 
by 56 landmark points. For each person, first six shapes are equally spaced sequence 
from maximally to minimally spread fingures. The rest are arbitrarily chosen 
with two constraints; (1) the palm should face the support and (2) the contour 
should contain no crossins.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(hands)
</code></pre>


<h3>Format</h3>

<p>a named list containing</p>

<dl>
<dt>data</dt><dd><p>an <code class="reqn">(56\times 2\times 40)</code> array of landmarks for 40 subjects.</p>
</dd>
<dt>person</dt><dd><p>a length-<code class="reqn">40</code> vector of subject indices.</p>
</dd>
</dl>



<h3>References</h3>

<p>Stegmann M, Gomez D (2002) &quot;A Brief Introduction to Statistical Shape Analysis.&quot; <em>Informatics and Mathematical Modelling, Technical University of Denmark, DTU.</em>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+wrap.landmark">wrap.landmark</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## LOAD THE DATA 
data(hands)

## VISUALIZE 6 HANDS OF PERSON 1
opar &lt;- par(no.readonly=TRUE)
par(mfrow=c(2,3))
for (i in 1:6){
  xx = hands$data[,1,i]
  yy = hands$data[,2,i]
  plot(xx,yy,"b", cex=0.9)
}
par(opar)


</code></pre>

<hr>
<h2 id='label'>S3 method for mixture model : predict labels</h2><span id='topic+label'></span>

<h3>Description</h3>

<p>Given a fitted mixture model of <code class="reqn">K</code> components, predict labels of 
observations accordingly.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>label(object, newdata)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="label_+3A_object">object</code></td>
<td>
<p>a fitted mixture model of <code>riemmix</code> class.</p>
</td></tr>
<tr><td><code id="label_+3A_newdata">newdata</code></td>
<td>
<p>data of <code class="reqn">n</code> objects (vectors, matrices) that can be wrapped by one of <code>wrap.*</code> functions in the <span class="pkg">Riemann</span> package.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a length-<code class="reqn">n</code> vector of class labels.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# ---------------------------------------------------- #
#            FIT A MODEL &amp; APPLY THE METHOD
# ---------------------------------------------------- #
# Load the 'city' data and wrap as 'riemobj'
data(cities)
locations = cities$cartesian
embed2    = array(0,c(60,2)) 
for (i in 1:60){
   embed2[i,] = sphere.xyz2geo(locations[i,])
}

# Fit a model
k3 = moSN(locations, k=3)

# Evaluate
newlabel = label(k3, locations)


</code></pre>

<hr>
<h2 id='loglkd'>S3 method for mixture model : log-likelihood</h2><span id='topic+loglkd'></span>

<h3>Description</h3>

<p>Given a fitted mixture model <code class="reqn">f(x)</code> and observations <code class="reqn">x_1, \ldots, x_n \in \mathcal{M}</code>, compute the log-likelihood
</p>
<p style="text-align: center;"><code class="reqn">L = \log \prod_{i=1}^n f(x_i) = \sum_{i=1}^n \log f(x_i)</code>
</p>
<p>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>loglkd(object, newdata)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="loglkd_+3A_object">object</code></td>
<td>
<p>a fitted mixture model of <code>riemmix</code> class.</p>
</td></tr>
<tr><td><code id="loglkd_+3A_newdata">newdata</code></td>
<td>
<p>data of <code class="reqn">n</code> objects (vectors, matrices) that can be wrapped by one of <code>wrap.*</code> functions in the <span class="pkg">Riemann</span> package.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>the log-likelihood.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# ---------------------------------------------------- #
#            FIT A MODEL &amp; APPLY THE METHOD
# ---------------------------------------------------- #
# Load the 'city' data and wrap as 'riemobj'
data(cities)
locations = cities$cartesian
embed2    = array(0,c(60,2)) 
for (i in 1:60){
   embed2[i,] = sphere.xyz2geo(locations[i,])
}

# Fit a model
k3 = moSN(locations, k=3)

# Evaluate
newloglkd = round(loglkd(k3, locations), 3)
print(paste0("Log-likelihood for K=3 model fit : ", newloglkd))


</code></pre>

<hr>
<h2 id='macg'>Matrix Angular Central Gaussian Distribution</h2><span id='topic+macg'></span><span id='topic+dmacg'></span><span id='topic+rmacg'></span><span id='topic+mle.macg'></span>

<h3>Description</h3>

<p>For Stiefel and Grassmann manifolds <code class="reqn">St(r,p)</code> and <code class="reqn">Gr(r,p)</code>, the matrix 
variant of ACG distribution is known as Matrix Angular Central Gaussian (MACG) 
distribution <code class="reqn">MACG_{p,r}(\Sigma)</code> with density
</p>
<p style="text-align: center;"><code class="reqn">f(X\vert \Sigma) = |\Sigma|^{-r/2} |X^\top \Sigma^{-1} X|^{-p/2}</code>
</p>

<p>where <code class="reqn">\Sigma</code> is a <code class="reqn">(p\times p)</code> symmetric positive-definite matrix. 
Similar to vector-variate ACG case, we follow a convention that <code class="reqn">tr(\Sigma)=p</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dmacg(datalist, Sigma)

rmacg(n, r, Sigma)

mle.macg(datalist, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="macg_+3A_datalist">datalist</code></td>
<td>
<p>a list of <code class="reqn">(p\times r)</code> orthonormal matrices.</p>
</td></tr>
<tr><td><code id="macg_+3A_sigma">Sigma</code></td>
<td>
<p>a <code class="reqn">(p\times p)</code> symmetric positive-definite matrix.</p>
</td></tr>
<tr><td><code id="macg_+3A_n">n</code></td>
<td>
<p>the number of samples to be generated.</p>
</td></tr>
<tr><td><code id="macg_+3A_r">r</code></td>
<td>
<p>the number of basis.</p>
</td></tr>
<tr><td><code id="macg_+3A_...">...</code></td>
<td>
<p>extra parameters for computations, including</p>

<dl>
<dt>maxiter</dt><dd><p>maximum number of iterations to be run (default:50).</p>
</dd>
<dt>eps</dt><dd><p>tolerance level for stopping criterion (default: 1e-5).</p>
</dd>
</dl>
</td></tr>
</table>


<h3>Value</h3>

<p><code>dmacg</code> gives a vector of evaluated densities given samples. <code>rmacg</code> generates  
<code class="reqn">(p\times r)</code> orthonormal matrices wrapped in a list. <code>mle.macg</code> estimates 
the SPD matrix <code class="reqn">\Sigma</code>.
</p>


<h3>References</h3>

<p>Chikuse Y (1990).
&ldquo;The matrix angular central Gaussian distribution.&rdquo;
<em>Journal of Multivariate Analysis</em>, <b>33</b>(2), 265&ndash;274.
ISSN 0047259X.
</p>
<p>Mardia KV, Jupp PE (eds.) (1999).
<em>Directional Statistics</em>,  Wiley Series in Probability and Statistics.
John Wiley \&amp; Sons, Inc., Hoboken, NJ, USA.
ISBN 978-0-470-31697-9 978-0-471-95333-3.
</p>
<p>Kent JT, Ganeiber AM, Mardia KV (2013). &quot;A new method to simulate the Bingham and related distributions in directional data analysis with applications.&quot; <em>arXiv:1310.8110</em>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+acg">acg</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># -------------------------------------------------------------------
#          Example with Matrix Angular Central Gaussian Distribution
#
# Given a fixed Sigma, generate samples and estimate Sigma via ML.
# -------------------------------------------------------------------
## GENERATE AND MLE in St(2,5)/Gr(2,5)
#  Generate data
Strue = diag(5)                  # true SPD matrix
sam1  = rmacg(n=50,  r=2, Strue) # random samples
sam2  = rmacg(n=100, r=2, Strue) # random samples

#  MLE
Smle1 = mle.macg(sam1)
Smle2 = mle.macg(sam2)

#  Visualize
opar &lt;- par(no.readonly=TRUE)
par(mfrow=c(1,3), pty="s")
image(Strue[,5:1], axes=FALSE, main="true SPD")
image(Smle1[,5:1], axes=FALSE, main="MLE with n=50")
image(Smle2[,5:1], axes=FALSE, main="MLE with n=100")
par(opar)

</code></pre>

<hr>
<h2 id='moSL'>Finite Mixture of Spherical Laplace Distributions</h2><span id='topic+moSL'></span><span id='topic+loglkd.moSL'></span><span id='topic+label.moSL'></span><span id='topic+density.moSL'></span>

<h3>Description</h3>

<p>For <code class="reqn">n</code> observations on a <code class="reqn">(p-1)</code> sphere in <code class="reqn">\mathbf{R}^p</code>, 
a finite mixture model is fitted whose components are spherical Laplace distributions via the following model
</p>
<p style="text-align: center;"><code class="reqn">f(x; \left\lbrace w_k, \mu_k, \sigma_k \right\rbrace_{k=1}^K) = \sum_{k=1}^K w_k SL(x; \mu_k, \sigma_k)</code>
</p>

<p>with parameters <code class="reqn">w_k</code>'s for component weights, <code class="reqn">\mu_k</code>'s for component locations, and <code class="reqn">\sigma_k</code>'s for component scales.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>moSL(
  data,
  k = 2,
  same.sigma = FALSE,
  variants = c("soft", "hard", "stochastic"),
  ...
)

## S3 method for class 'moSL'
loglkd(object, newdata)

## S3 method for class 'moSL'
label(object, newdata)

## S3 method for class 'moSL'
density(object, newdata)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="moSL_+3A_data">data</code></td>
<td>
<p>data vectors in form of either an <code class="reqn">(n\times p)</code> matrix or a length-<code class="reqn">n</code> list.  See <code><a href="#topic+wrap.sphere">wrap.sphere</a></code> for descriptions on supported input types.</p>
</td></tr>
<tr><td><code id="moSL_+3A_k">k</code></td>
<td>
<p>the number of clusters (default: 2).</p>
</td></tr>
<tr><td><code id="moSL_+3A_same.sigma">same.sigma</code></td>
<td>
<p>a logical; <code>TRUE</code> to use same scale parameter across all components, or <code>FALSE</code> otherwise.</p>
</td></tr>
<tr><td><code id="moSL_+3A_variants">variants</code></td>
<td>
<p>type of the class assignment methods, one of <code>"soft"</code>,<code>"hard"</code>, and <code>"stochastic"</code>.</p>
</td></tr>
<tr><td><code id="moSL_+3A_...">...</code></td>
<td>
<p>extra parameters including </p>

<dl>
<dt>maxiter</dt><dd><p>the maximum number of iterations (default: 50).</p>
</dd>
<dt>eps</dt><dd><p>stopping criterion for the EM algorithm (default: 1e-6).</p>
</dd>
<dt>printer</dt><dd><p>a logical; <code>TRUE</code> to show history of the algorithm, <code>FALSE</code> otherwise.</p>
</dd>
</dl>
</td></tr>
<tr><td><code id="moSL_+3A_object">object</code></td>
<td>
<p>a fitted <code>moSL</code> model from the <code><a href="#topic+moSL">moSL</a></code> function.</p>
</td></tr>
<tr><td><code id="moSL_+3A_newdata">newdata</code></td>
<td>
<p>data vectors in form of either an <code class="reqn">(m\times p)</code> matrix or a length-<code class="reqn">m</code> list.  See <code><a href="#topic+wrap.sphere">wrap.sphere</a></code> for descriptions on supported input types.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a named list of S3 class <code>riemmix</code> containing
</p>

<dl>
<dt>cluster</dt><dd><p>a length-<code class="reqn">n</code> vector of class labels (from <code class="reqn">1:k</code>).</p>
</dd>
<dt>loglkd</dt><dd><p>log likelihood of the fitted model.</p>
</dd>
<dt>criteria</dt><dd><p>a vector of information criteria.</p>
</dd>
<dt>parameters</dt><dd><p>a list containing <code>proportion</code>, <code>location</code>, and <code>scale</code>. See the section for more details.</p>
</dd>
<dt>membership</dt><dd><p>an <code class="reqn">(n\times k)</code> row-stochastic matrix of membership.</p>
</dd>
</dl>



<h3>Parameters of the fitted model</h3>

<p>A fitted model is characterized by three parameters. For <code class="reqn">k</code>-mixture model on a <code class="reqn">(p-1)</code> 
sphere in <code class="reqn">\mathbf{R}^p</code>, (1) <code>proportion</code> is a length-<code class="reqn">k</code> vector of component weight 
that sums to 1, (2) <code>location</code> is an <code class="reqn">(k\times p)</code> matrix whose rows are per-cluster locations, and 
(3) <code>concentration</code> is a length-<code class="reqn">k</code> vector of scale parameters for each component.
</p>


<h3>Note on S3 methods</h3>

<p>There are three S3 methods; <code>loglkd</code>, <code>label</code>, and <code>density</code>. Given a random sample of 
size <code class="reqn">m</code> as <code>newdata</code>, (1) <code>loglkd</code> returns a scalar value of the computed log-likelihood, 
(2) <code>label</code> returns a length-<code class="reqn">m</code> vector of cluster assignments, and (3) <code>density</code> 
evaluates densities of every observation according ot the model fit.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# ---------------------------------------------------- #
#                 FITTING THE MODEL
# ---------------------------------------------------- #
# Load the 'city' data and wrap as 'riemobj'
data(cities)
locations = cities$cartesian
embed2    = array(0,c(60,2)) 
for (i in 1:60){
   embed2[i,] = sphere.xyz2geo(locations[i,])
}

# Fit the model with different numbers of clusters
k2 = moSL(locations, k=2)
k3 = moSL(locations, k=3)
k4 = moSL(locations, k=4)

# Visualize
opar &lt;- par(no.readonly=TRUE)
par(mfrow=c(1,3))
plot(embed2, col=k2$cluster, pch=19, main="K=2")
plot(embed2, col=k3$cluster, pch=19, main="K=3")
plot(embed2, col=k4$cluster, pch=19, main="K=4")
par(opar)

# ---------------------------------------------------- #
#                   USE S3 METHODS
# ---------------------------------------------------- #
# Use the same 'locations' data as new data 
# (1) log-likelihood
newloglkd = round(loglkd(k3, locations), 5)
fitloglkd = round(k3$loglkd, 5)
print(paste0("Log-likelihood for K=3 fitted    : ", fitloglkd))
print(paste0("Log-likelihood for K=3 predicted : ", newloglkd))

# (2) label
newlabel = label(k3, locations)

# (3) density
newdensity = density(k3, locations)


</code></pre>

<hr>
<h2 id='moSN'>Finite Mixture of Spherical Normal Distributions</h2><span id='topic+moSN'></span><span id='topic+loglkd.moSN'></span><span id='topic+label.moSN'></span><span id='topic+density.moSN'></span>

<h3>Description</h3>

<p>For <code class="reqn">n</code> observations on a <code class="reqn">(p-1)</code> sphere in <code class="reqn">\mathbf{R}^p</code>, 
a finite mixture model is fitted whose components are spherical normal distributions via the following model
</p>
<p style="text-align: center;"><code class="reqn">f(x; \left\lbrace w_k, \mu_k, \lambda_k \right\rbrace_{k=1}^K) = \sum_{k=1}^K w_k SN(x; \mu_k, \lambda_k)</code>
</p>

<p>with parameters <code class="reqn">w_k</code>'s for component weights, <code class="reqn">\mu_k</code>'s for component locations, and <code class="reqn">\lambda_k</code>'s for component concentrations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>moSN(
  data,
  k = 2,
  same.lambda = FALSE,
  variants = c("soft", "hard", "stochastic"),
  ...
)

## S3 method for class 'moSN'
loglkd(object, newdata)

## S3 method for class 'moSN'
label(object, newdata)

## S3 method for class 'moSN'
density(object, newdata)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="moSN_+3A_data">data</code></td>
<td>
<p>data vectors in form of either an <code class="reqn">(n\times p)</code> matrix or a length-<code class="reqn">n</code> list.  See <code><a href="#topic+wrap.sphere">wrap.sphere</a></code> for descriptions on supported input types.</p>
</td></tr>
<tr><td><code id="moSN_+3A_k">k</code></td>
<td>
<p>the number of clusters (default: 2).</p>
</td></tr>
<tr><td><code id="moSN_+3A_same.lambda">same.lambda</code></td>
<td>
<p>a logical; <code>TRUE</code> to use same concentration parameter across all components, or <code>FALSE</code> otherwise.</p>
</td></tr>
<tr><td><code id="moSN_+3A_variants">variants</code></td>
<td>
<p>type of the class assignment methods, one of <code>"soft"</code>,<code>"hard"</code>, and <code>"stochastic"</code>.</p>
</td></tr>
<tr><td><code id="moSN_+3A_...">...</code></td>
<td>
<p>extra parameters including </p>

<dl>
<dt>maxiter</dt><dd><p>the maximum number of iterations (default: 50).</p>
</dd>
<dt>eps</dt><dd><p>stopping criterion for the EM algorithm (default: 1e-6).</p>
</dd>
<dt>printer</dt><dd><p>a logical; <code>TRUE</code> to show history of the algorithm, <code>FALSE</code> otherwise.</p>
</dd>
</dl>
</td></tr>
<tr><td><code id="moSN_+3A_object">object</code></td>
<td>
<p>a fitted <code>moSN</code> model from the <code><a href="#topic+moSN">moSN</a></code> function.</p>
</td></tr>
<tr><td><code id="moSN_+3A_newdata">newdata</code></td>
<td>
<p>data vectors in form of either an <code class="reqn">(m\times p)</code> matrix or a length-<code class="reqn">m</code> list.  See <code><a href="#topic+wrap.sphere">wrap.sphere</a></code> for descriptions on supported input types.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a named list of S3 class <code>riemmix</code> containing
</p>

<dl>
<dt>cluster</dt><dd><p>a length-<code class="reqn">n</code> vector of class labels (from <code class="reqn">1:k</code>).</p>
</dd>
<dt>loglkd</dt><dd><p>log likelihood of the fitted model.</p>
</dd>
<dt>criteria</dt><dd><p>a vector of information criteria.</p>
</dd>
<dt>parameters</dt><dd><p>a list containing <code>proportion</code>, <code>center</code>, and <code>concentration</code>. See the section for more details.</p>
</dd>
<dt>membership</dt><dd><p>an <code class="reqn">(n\times k)</code> row-stochastic matrix of membership.</p>
</dd>
</dl>



<h3>Parameters of the fitted model</h3>

<p>A fitted model is characterized by three parameters. For <code class="reqn">k</code>-mixture model on a <code class="reqn">(p-1)</code> 
sphere in <code class="reqn">\mathbf{R}^p</code>, (1) <code>proportion</code> is a length-<code class="reqn">k</code> vector of component weight 
that sums to 1, (2) <code>center</code> is an <code class="reqn">(k\times p)</code> matrix whose rows are cluster centers, and 
(3) <code>concentration</code> is a length-<code class="reqn">k</code> vector of concentration parameters for each component.
</p>


<h3>Note on S3 methods</h3>

<p>There are three S3 methods; <code>loglkd</code>, <code>label</code>, and <code>density</code>. Given a random sample of 
size <code class="reqn">m</code> as <code>newdata</code>, (1) <code>loglkd</code> returns a scalar value of the computed log-likelihood, 
(2) <code>label</code> returns a length-<code class="reqn">m</code> vector of cluster assignments, and (3) <code>density</code> 
evaluates densities of every observation according ot the model fit.
</p>


<h3>References</h3>

<p>You K, Suh C (2022).
&ldquo;Parameter Estimation and Model-Based Clustering with Spherical Normal Distribution on the Unit Hypersphere.&rdquo;
<em>Computational Statistics \&amp; Data Analysis</em>, 107457.
ISSN 01679473.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# ---------------------------------------------------- #
#                 FITTING THE MODEL
# ---------------------------------------------------- #
# Load the 'city' data and wrap as 'riemobj'
data(cities)
locations = cities$cartesian
embed2    = array(0,c(60,2)) 
for (i in 1:60){
   embed2[i,] = sphere.xyz2geo(locations[i,])
}

# Fit the model with different numbers of clusters
k2 = moSN(locations, k=2)
k3 = moSN(locations, k=3)
k4 = moSN(locations, k=4)

# Visualize
opar &lt;- par(no.readonly=TRUE)
par(mfrow=c(1,3))
plot(embed2, col=k2$cluster, pch=19, main="K=2")
plot(embed2, col=k3$cluster, pch=19, main="K=3")
plot(embed2, col=k4$cluster, pch=19, main="K=4")
par(opar)

# ---------------------------------------------------- #
#                   USE S3 METHODS
# ---------------------------------------------------- #
# Use the same 'locations' data as new data 
# (1) log-likelihood
newloglkd = round(loglkd(k3, locations), 3)
print(paste0("Log-likelihood for K=3 model fit : ", newloglkd))

# (2) label
newlabel = label(k3, locations)

# (3) density
newdensity = density(k3, locations)


</code></pre>

<hr>
<h2 id='orbital'>Data : Normal Vectors to the Orbital Planes of the 9 Planets</h2><span id='topic+orbital'></span>

<h3>Description</h3>

<p>The 9 planets in our solar system are evolving the sun via their own orbits. 
This data provides normal vector of the orbital planes. Normal vectors are 
unit-norm vectors, so that they are thought to reside on 2-dimensional sphere.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(orbital)
</code></pre>


<h3>Format</h3>

<p>an <code class="reqn">(9\times 3)</code> matrix where each row is a normal vector for a planet.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+wrap.sphere">wrap.sphere</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## LOAD THE DATA AND WRAP AS RIEMOBJ
data(orbital)
myorb = wrap.sphere(orbital)

## VISUALIZE
mds2d = riem.mds(myorb)$embed
opar &lt;- par(no.readonly=TRUE)
plot(mds2d, main="9 Planets", pch=19, xlab="x", ylab="y")
par(opar)

</code></pre>

<hr>
<h2 id='passiflora'>Data : Passiflora Leaves</h2><span id='topic+passiflora'></span>

<h3>Description</h3>

<p>Passiflora is a genus of about 550 species of flowering plants. This dataset contains 
15 landmarks in 2 dimension of 3319 leaves of 40 species. Papers listed in the 
reference section analyzed the data and found 7 clusters.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(passiflora)
</code></pre>


<h3>Format</h3>

<p>a named list containing</p>

<dl>
<dt>data</dt><dd><p>a 3d array of size <code class="reqn">(15\times 2\times 3319)</code>.</p>
</dd>
<dt>species</dt><dd><p>a length-<code class="reqn">3319</code> vector of 40 species factors.</p>
</dd>
<dt>class</dt><dd><p>a length-<code class="reqn">3319</code> vector of 7 cluster factors.</p>
</dd>
</dl>



<h3>References</h3>

<p>Chitwood DH, Otoni WC (2017).
&ldquo;Divergent leaf shapes among Passiflora species arise from a shared juvenile morphology.&rdquo;
<em>Plant Direct</em>, <b>1</b>(5), e00028.
ISSN 24754455.
</p>
<p>Chitwood DH, Otoni WC (2017).
&ldquo;Morphometric analysis of Passiflora leaves: the relationship between landmarks of the vasculature and elliptical Fourier descriptors of the blade.&rdquo;
<em>GigaScience</em>, <b>6</b>(1).
ISSN 2047-217X.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+wrap.landmark">wrap.landmark</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(passiflora)                         # load the data
riemobj = wrap.landmark(passiflora$data) # wrap as RIEMOBJ
pga2d   = riem.pga(riemobj)$embed        # embedding via PGA

opar &lt;- par(no.readonly=TRUE)            # visualize
plot(pga2d, col=passiflora$class, pch=19, cex=0.7,
     main="PGA Embedding of Passiflora Leaves",
     xlab="dimension 1", ylab="dimension 2")
par(opar)

</code></pre>

<hr>
<h2 id='predict.m2skreg'>Prediction for Manifold-to-Scalar Kernel Regression</h2><span id='topic+predict.m2skreg'></span>

<h3>Description</h3>

<p>Given new observations <code class="reqn">X_1, X_2, \ldots, X_M \in \mathcal{M}</code>, plug in 
the data with respect to the fitted model for prediction.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'm2skreg'
predict(object, newdata, geometry = c("intrinsic", "extrinsic"), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.m2skreg_+3A_object">object</code></td>
<td>
<p>an object of <code>m2skreg</code> class. See <code><a href="#topic+riem.m2skreg">riem.m2skreg</a></code> for more details.</p>
</td></tr>
<tr><td><code id="predict.m2skreg_+3A_newdata">newdata</code></td>
<td>
<p>a S3 <code>"riemdata"</code> class for manifold-valued data corresponding to <code class="reqn">X_1,\ldots,X_M</code>.</p>
</td></tr>
<tr><td><code id="predict.m2skreg_+3A_geometry">geometry</code></td>
<td>
<p>(case-insensitive) name of geometry; either geodesic (<code>"intrinsic"</code>) or embedded (<code>"extrinsic"</code>) geometry.</p>
</td></tr>
<tr><td><code id="predict.m2skreg_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a length-<code class="reqn">M</code> vector of predictted values.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+riem.m2skreg">riem.m2skreg</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
#-------------------------------------------------------------------
#                    Example on Sphere S^2
#
#  X : equi-spaced points from (0,0,1) to (0,1,0)
#  y : sin(x) with perturbation
#
#  Our goal is to check whether the predict function works well
#  by comparing the originally predicted values vs. those of the same data.
#-------------------------------------------------------------------
# GENERATE DATA
npts = 100
nlev = 0.25
thetas = seq(from=0, to=pi/2, length.out=npts)
Xstack = cbind(rep(0,npts), sin(thetas), cos(thetas))

Xriem  = wrap.sphere(Xstack)
ytrue  = sin(seq(from=0, to=2*pi, length.out=npts))
ynoise = ytrue + rnorm(npts, sd=nlev)

# FIT &amp; PREDICT
obj_fit   = riem.m2skreg(Xriem, ynoise, bandwidth=0.01)
yval_fits = obj_fit$ypred
yval_pred = predict(obj_fit, Xriem)

# VISUALIZE
xgrd &lt;- 1:npts
opar &lt;- par(no.readonly=TRUE)
par(mfrow=c(1,2))
plot(xgrd, yval_fits, pch=19, cex=0.5, "b", xlab="", ylim=c(-2,2), main="original fit")
lines(xgrd, ytrue, col="red", lwd=1.5)
plot(xgrd, yval_pred, pch=19, cex=0.5, "b", xlab="", ylim=c(-2,2), main="from 'predict'")
lines(xgrd, ytrue, col="red", lwd=1.5)
par(opar)


</code></pre>

<hr>
<h2 id='riem.clrq'>Competitive Learning Riemannian Quantization</h2><span id='topic+riem.clrq'></span>

<h3>Description</h3>

<p>Given <code class="reqn">N</code> observations  <code class="reqn">X_1, X_2, \ldots, X_N \in \mathcal{M}</code>, 
perform clustering via Competitive Learning Riemannian Quantization (CLRQ). 
Originally, the algorithm is designed for finding voronoi cells that are 
used in domain quantization. Given the discrete measure of data, centers of the cells 
play a role of cluster centers and data are labeled accordingly based on the distance 
to voronoi centers. For an iterative update of centers, gradient descent algorithm 
adapted for the Riemannian manifold setting is used with the gain factor sequence
</p>
<p style="text-align: center;"><code class="reqn">\gamma_t = \frac{a}{1 + b \sqrt{t}}</code>
</p>

<p>where two parameters <code class="reqn">a,b</code> are represented by <code>par.a</code> and <code>par.b</code>. For 
initialization, we provide k-means++ and random seeding options as in k-means.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>riem.clrq(riemobj, k = 2, init = c("plus", "random"), gain.a = 1, gain.b = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="riem.clrq_+3A_riemobj">riemobj</code></td>
<td>
<p>a S3 <code>"riemdata"</code> class for <code class="reqn">N</code> manifold-valued data.</p>
</td></tr>
<tr><td><code id="riem.clrq_+3A_k">k</code></td>
<td>
<p>the number of clusters.</p>
</td></tr>
<tr><td><code id="riem.clrq_+3A_init">init</code></td>
<td>
<p>(case-insensitive) name of an initialization scheme. (default: <code>"plus"</code>.)</p>
</td></tr>
<tr><td><code id="riem.clrq_+3A_gain.a">gain.a</code></td>
<td>
<p>parameter <code class="reqn">a</code> for gain factor sequence.</p>
</td></tr>
<tr><td><code id="riem.clrq_+3A_gain.b">gain.b</code></td>
<td>
<p>parameter <code class="reqn">b</code> for gain factor sequence.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a named list containing</p>

<dl>
<dt>centers</dt><dd><p>a 3d array where each slice along 3rd dimension is a matrix representation of class centers.</p>
</dd>
<dt>cluster</dt><dd><p>a length-<code class="reqn">N</code> vector of class labels (from <code class="reqn">1:k</code>).</p>
</dd>
</dl>



<h3>References</h3>

<p>Le Brigant A, Puechmorel S (2019).
&ldquo;Quantization and clustering on Riemannian manifolds with an application to air traffic analysis.&rdquo;
<em>Journal of Multivariate Analysis</em>, <b>173</b>, 685&ndash;703.
ISSN 0047259X.
</p>
<p>Bonnabel S (2013).
&ldquo;Stochastic Gradient Descent on Riemannian Manifolds.&rdquo;
<em>IEEE Transactions on Automatic Control</em>, <b>58</b>(9), 2217&ndash;2229.
ISSN 0018-9286, 1558-2523.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+riem.kmeans">riem.kmeans</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#-------------------------------------------------------------------
#          Example on Sphere : a dataset with three types
#
# class 1 : 10 perturbed data points near (1,0,0) on S^2 in R^3
# class 2 : 10 perturbed data points near (0,1,0) on S^2 in R^3
# class 3 : 10 perturbed data points near (0,0,1) on S^2 in R^3
#-------------------------------------------------------------------
## GENERATE DATA
mydata = list()
for (i in 1:10){
  tgt = c(1, stats::rnorm(2, sd=0.1))
  mydata[[i]] = tgt/sqrt(sum(tgt^2))
}
for (i in 11:20){
  tgt = c(rnorm(1,sd=0.1),1,rnorm(1,sd=0.1))
  mydata[[i]] = tgt/sqrt(sum(tgt^2))
}
for (i in 21:30){
  tgt = c(stats::rnorm(2, sd=0.1), 1)
  mydata[[i]] = tgt/sqrt(sum(tgt^2))
}
myriem = wrap.sphere(mydata)
mylabs = rep(c(1,2,3), each=10)

## CLRQ WITH K=2,3,4
clust2 = riem.clrq(myriem, k=2)
clust3 = riem.clrq(myriem, k=3)
clust4 = riem.clrq(myriem, k=4)

## MDS FOR VISUALIZATION
mds2d = riem.mds(myriem, ndim=2)$embed

## VISUALIZE
opar &lt;- par(no.readonly=TRUE)
par(mfrow=c(2,2), pty="s")
plot(mds2d, pch=19, main="true label", col=mylabs)
plot(mds2d, pch=19, main="K=2", col=clust2$cluster)
plot(mds2d, pch=19, main="K=3", col=clust3$cluster)
plot(mds2d, pch=19, main="K=4", col=clust4$cluster)
par(opar)

</code></pre>

<hr>
<h2 id='riem.coreset18B'>Build Lightweight Coreset</h2><span id='topic+riem.coreset18B'></span>

<h3>Description</h3>

<p>Given manifold-valued data <code class="reqn">X_1,X_2,\ldots,X_N \in \mathcal{M}</code>, this algorithm 
finds the coreset of size <code class="reqn">M</code> that can be considered as a compressed representation 
according to the lightweight coreset construction scheme proposed by the reference below.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>riem.coreset18B(
  riemobj,
  M = length(riemobj$data)/2,
  geometry = c("intrinsic", "extrinsic"),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="riem.coreset18B_+3A_riemobj">riemobj</code></td>
<td>
<p>a S3 <code>"riemdata"</code> class for <code class="reqn">N</code> manifold-valued data.</p>
</td></tr>
<tr><td><code id="riem.coreset18B_+3A_m">M</code></td>
<td>
<p>the size of coreset (default: <code class="reqn">N/2</code>).</p>
</td></tr>
<tr><td><code id="riem.coreset18B_+3A_geometry">geometry</code></td>
<td>
<p>(case-insensitive) name of geometry; either geodesic (<code>"intrinsic"</code>) or embedded (<code>"extrinsic"</code>) geometry.</p>
</td></tr>
<tr><td><code id="riem.coreset18B_+3A_...">...</code></td>
<td>
<p>extra parameters including</p>

<dl>
<dt>maxiter</dt><dd><p>maximum number of iterations to be run (default:50).</p>
</dd>
<dt>eps</dt><dd><p>tolerance level for stopping criterion (default: 1e-5).</p>
</dd>
</dl>
</td></tr>
</table>


<h3>Value</h3>

<p>a named list containing</p>

<dl>
<dt>coreid</dt><dd><p>a length-<code class="reqn">M</code> index vector of the coreset.</p>
</dd>
<dt>weight</dt><dd><p>a length-<code class="reqn">M</code> vector of weights for each element.</p>
</dd>
</dl>



<h3>References</h3>

<p>Bachem O, Lucic M, Krause A (2018).
&ldquo;Scalable k -Means Clustering via Lightweight Coresets.&rdquo;
In <em>Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery \&amp; Data Mining</em>, 1119&ndash;1127.
ISBN 978-1-4503-5552-0.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#-------------------------------------------------------------------
#          Example on Sphere : a dataset with three types
#
# * 10 perturbed data points near (1,0,0) on S^2 in R^3
# * 10 perturbed data points near (0,1,0) on S^2 in R^3
# * 10 perturbed data points near (0,0,1) on S^2 in R^3
#-------------------------------------------------------------------
## GENERATE DATA
mydata = list()
for (i in 1:10){
  tgt = c(1, stats::rnorm(2, sd=0.1))
  mydata[[i]] = tgt/sqrt(sum(tgt^2))
}
for (i in 11:20){
  tgt = c(rnorm(1,sd=0.1),1,rnorm(1,sd=0.1))
  mydata[[i]] = tgt/sqrt(sum(tgt^2))
}
for (i in 21:30){
  tgt = c(stats::rnorm(2, sd=0.1), 1)
  mydata[[i]] = tgt/sqrt(sum(tgt^2))
}
myriem = wrap.sphere(mydata)

## MDS FOR VISUALIZATION
embed2 = riem.mds(myriem, ndim=2)$embed

## FIND CORESET OF SIZES 3, 6, 9
core1 = riem.coreset18B(myriem, M=3)
core2 = riem.coreset18B(myriem, M=6)
core3 = riem.coreset18B(myriem, M=9)

col1 = rep(1,30); col1[core1$coreid] = 2
col2 = rep(1,30); col2[core2$coreid] = 2
col3 = rep(1,30); col3[core3$coreid] = 2

## VISUALIZE
opar &lt;- par(no.readonly=TRUE)
par(mfrow=c(1,3), pty="s")
plot(embed2, pch=19, col=col1, main="coreset size=3")
plot(embed2, pch=19, col=col2, main="coreset size=6")
plot(embed2, pch=19, col=col3, main="coreset size=9")
par(opar)

</code></pre>

<hr>
<h2 id='riem.distlp'>Distance between Two Curves on Manifolds</h2><span id='topic+riem.distlp'></span>

<h3>Description</h3>

<p>Given two curves <code class="reqn">\gamma_1, \gamma_2 : I \rightarrow \mathcal{M}</code>, we are 
interested in measuring the discrepancy of two curves. Usually, data are given 
as discrete observations so we are offering several methods to perform the task. See 
the section below for detailed description.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>riem.distlp(
  riemobj1,
  riemobj2,
  vect = NULL,
  geometry = c("intrinsic", "extrinsic"),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="riem.distlp_+3A_riemobj1">riemobj1</code></td>
<td>
<p>a S3 <code>"riemdata"</code> class for <code class="reqn">N</code> manifold-valued data along the curve.</p>
</td></tr>
<tr><td><code id="riem.distlp_+3A_riemobj2">riemobj2</code></td>
<td>
<p>a S3 <code>"riemdata"</code> class for <code class="reqn">N</code> manifold-valued data along the curve.</p>
</td></tr>
<tr><td><code id="riem.distlp_+3A_vect">vect</code></td>
<td>
<p>a vector of domain values. If given <code>Null</code> (default), sequence <code>1:N</code> is set.</p>
</td></tr>
<tr><td><code id="riem.distlp_+3A_geometry">geometry</code></td>
<td>
<p>(case-insensitive) name of geometry; either geodesic (<code>"intrinsic"</code>) or embedded (<code>"extrinsic"</code>) geometry.</p>
</td></tr>
<tr><td><code id="riem.distlp_+3A_...">...</code></td>
<td>
<p>extra parameters including</p>

<dl>
<dt>p</dt><dd><p>an exponent (default: 2).</p>
</dd>
</dl>
</td></tr>
</table>


<h3>Value</h3>

<p>the distance value.
</p>


<h3>Default Method </h3>

<p>Trapezoidal Approximation
Assume <code class="reqn">\gamma_1 (t_i) = X_i</code> and <code class="reqn">\gamma_2 (t_i) = Y_i</code> for 
<code class="reqn">i=1,2,\ldots,N</code>. In the Euclidean space, <code class="reqn">L_p</code> distance between two 
scalar-valued functions is defined as 
</p>
<p style="text-align: center;"><code class="reqn">L_p^p (\gamma_1 (x), \gamma_2 (x) = \int_{\mathcal{X}} |\gamma_1 (x) - \gamma_2 (x)|^p dx </code>
</p>
<p>. 
We extend this approach to manifold-valued curves
</p>
<p style="text-align: center;"><code class="reqn">L_p^p (\gamma_1 (t), \gamma_2 (t)) = \int_{t\in I} d^p (\gamma_1 (t), \gamma_2 (t)) dt</code>
</p>

<p>where <code class="reqn">d(\cdot,\cdot)</code> is an intrinsic/extrinsic distance on manifolds. With the given 
representations, the above integral is approximated using trapezoidal rule.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#-------------------------------------------------------------------
#                          Curves on Sphere
#
#  curve1 : y = 0.5*cos(x) on the tangent space at (0,0,1)
#  curve2 : y = 0.5*cos(x) on the tangent space at (0,0,1)
#  curve3 : y = 0.5*sin(x) on the tangent space at (0,0,1)
#
# * distance between curve1 &amp; curve2 should be close to 0.
# * distance between curve1 &amp; curve3 should be large.
#-------------------------------------------------------------------
## GENERATION
vecx  = seq(from=-0.9, to=0.9, length.out=50)
vecy1 = 0.5*cos(vecx) + rnorm(50, sd=0.05)
vecy2 = 0.5*cos(vecx) + rnorm(50, sd=0.05)
vecy3 = 0.5*sin(vecx) + rnorm(50, sd=0.05)

## WRAP AS RIEMOBJ
mat1 = cbind(vecx, vecy1, 1); mat1 = mat1/sqrt(rowSums(mat1^2))
mat2 = cbind(vecx, vecy2, 1); mat2 = mat2/sqrt(rowSums(mat2^2))
mat3 = cbind(vecx, vecy3, 1); mat3 = mat3/sqrt(rowSums(mat3^2))

rcurve1 = wrap.sphere(mat1)
rcurve2 = wrap.sphere(mat2)
rcurve3 = wrap.sphere(mat3)

## COMPUTE DISTANCES
riem.distlp(rcurve1, rcurve2, vect=vecx)
riem.distlp(rcurve1, rcurve3, vect=vecx)

</code></pre>

<hr>
<h2 id='riem.dtw'>Dynamic Time Warping Distance</h2><span id='topic+riem.dtw'></span>

<h3>Description</h3>

<p>Given two time series - a query <code class="reqn">X = (X_1,X_2,\ldots,X_N)</code> and a reference <code class="reqn">Y = (Y_1,Y_2,\ldots,Y_M)</code>, 
<code>riem.dtw</code> computes the most basic version of Dynamic Time Warping (DTW) distance between two series using a symmetric step pattern, meaning 
no window constraints and others at all. Although the scope of DTW in Euclidean space-valued objects is rich, it is scarce for manifold-valued curves. 
If you are interested in the topic, we refer to <span class="pkg">dtw</span> package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>riem.dtw(riemobj1, riemobj2, geometry = c("intrinsic", "extrinsic"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="riem.dtw_+3A_riemobj1">riemobj1</code></td>
<td>
<p>a S3 <code>"riemdata"</code> class for <code class="reqn">M</code> manifold-valued data along the curve.</p>
</td></tr>
<tr><td><code id="riem.dtw_+3A_riemobj2">riemobj2</code></td>
<td>
<p>a S3 <code>"riemdata"</code> class for <code class="reqn">N</code> manifold-valued data along the curve.</p>
</td></tr>
<tr><td><code id="riem.dtw_+3A_geometry">geometry</code></td>
<td>
<p>(case-insensitive) name of geometry; either geodesic (<code>"intrinsic"</code>) or embedded (<code>"extrinsic"</code>) geometry.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>the distance value.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
#-------------------------------------------------------------------
#                          Curves on Sphere
#
#  curve1 : y = 0.5*cos(x) on the tangent space at (0,0,1)
#  curve2 : y = 0.5*sin(x) on the tangent space at (0,0,1)
# 
#  we will generate two sets for curves of different sizes.
#-------------------------------------------------------------------
## GENERATION
clist = list()
for (i in 1:10){ # curve type 1
  vecx = seq(from=-0.9, to=0.9, length.out=sample(10:50, 1))
  vecy = 0.5*cos(vecx) + rnorm(length(vecx), sd=0.1)
  mats = cbind(vecx, vecy, 1)
  clist[[i]] = wrap.sphere(mats/sqrt(rowSums(mats^2)))
}
for (i in 1:10){ # curve type 2
  vecx = seq(from=-0.9, to=0.9, length.out=sample(10:50, 1))
  vecy = 0.5*sin(vecx) + rnorm(length(vecx), sd=0.1)
  mats = cbind(vecx, vecy, 1)
  clist[[i+10]] = wrap.sphere(mats/sqrt(rowSums(mats^2)))
}

## COMPUTE DISTANCES
outint = array(0,c(20,20))
outext = array(0,c(20,20))
for (i in 1:19){
  for (j in 2:20){
    outint[i,j] &lt;- outint[j,i] &lt;- riem.dtw(clist[[i]], clist[[j]], 
                                           geometry="intrinsic")
    outext[i,j] &lt;- outext[j,i] &lt;- riem.dtw(clist[[i]], clist[[j]],
                                           geometry="extrinsic")
  }
}

## VISUALIZE
opar &lt;- par(no.readonly=TRUE)
par(mfrow=c(1,2), pty="s")
image(outint[,20:1], axes=FALSE, main="intrinsic DTW Distance")
image(outext[,20:1], axes=FALSE, main="extrinsic DTW Distance")
par(opar)


</code></pre>

<hr>
<h2 id='riem.fanova'>Fréchet Analysis of Variance</h2><span id='topic+riem.fanova'></span><span id='topic+riem.fanovaP'></span>

<h3>Description</h3>

<p>Given sets of manifold-valued data <code class="reqn">X^{(1)}_{1:{n_1}}, X^{(2)}_{1:{n_2}}, \ldots, X^{(m)}_{1:{n_m}}</code>, 
performs analysis of variance to test equality of distributions. This means, small <code class="reqn">p</code>-value implies that 
at least one of the equalities does not hold.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>riem.fanova(..., maxiter = 50, eps = 1e-05)

riem.fanovaP(..., maxiter = 50, eps = 1e-05, nperm = 99)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="riem.fanova_+3A_...">...</code></td>
<td>
<p>S3 objects of <code>riemdata</code> class for manifold-valued data.</p>
</td></tr>
<tr><td><code id="riem.fanova_+3A_maxiter">maxiter</code></td>
<td>
<p>maximum number of iterations to be run.</p>
</td></tr>
<tr><td><code id="riem.fanova_+3A_eps">eps</code></td>
<td>
<p>tolerance level for stopping criterion.</p>
</td></tr>
<tr><td><code id="riem.fanova_+3A_nperm">nperm</code></td>
<td>
<p>the number of permutations for resampling-based test.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a (list) object of <code>S3</code> class <code>htest</code> containing: </p>

<dl>
<dt>statistic</dt><dd><p>a test statistic.</p>
</dd>
<dt>p.value</dt><dd><p><code class="reqn">p</code>-value under <code class="reqn">H_0</code>.</p>
</dd>
<dt>alternative</dt><dd><p>alternative hypothesis.</p>
</dd>
<dt>method</dt><dd><p>name of the test.</p>
</dd>
<dt>data.name</dt><dd><p>name(s) of provided sample data.</p>
</dd>
</dl>



<h3>References</h3>

<p>Dubey P, Müller H (2019).
&ldquo;Fréchet analysis of variance for random objects.&rdquo;
<em>Biometrika</em>, <b>106</b>(4), 803&ndash;821.
ISSN 0006-3444, 1464-3510.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#-------------------------------------------------------------------
#            Example on Sphere : Uniform Samples
#
#  Each of 4 classes consists of 20 uniform samples from uniform 
#  density on 2-dimensional sphere S^2 in R^3.
#-------------------------------------------------------------------
## PREPARE DATA OF 4 CLASSES
ndata  = 200
class1 = list()
class2 = list()
class3 = list()
class4 = list()
for (i in 1:ndata){
  tmpxy = matrix(rnorm(4*2, sd=0.1), ncol=2)
  tmpz  = rep(1,4)
  tmp3d = cbind(tmpxy, tmpz)
  tmp  = tmp3d/sqrt(rowSums(tmp3d^2))
  
  class1[[i]] = tmp[1,]
  class2[[i]] = tmp[2,]
  class3[[i]] = tmp[3,]
  class4[[i]] = tmp[4,]
}
obj1 = wrap.sphere(class1)
obj2 = wrap.sphere(class2)
obj3 = wrap.sphere(class3)
obj4 = wrap.sphere(class4)

## RUN THE ASYMPTOTIC TEST
riem.fanova(obj1, obj2, obj3, obj4)


## RUN THE PERMUTATION TEST WITH MANY PERMUTATIONS
riem.fanovaP(obj1, obj2, obj3, obj4, nperm=999)


</code></pre>

<hr>
<h2 id='riem.hclust'>Hierarchical Agglomerative Clustering</h2><span id='topic+riem.hclust'></span>

<h3>Description</h3>

<p>Given <code class="reqn">N</code> observations <code class="reqn">X_1, X_2, \ldots, X_M \in \mathcal{M}</code>, 
perform hierarchical agglomerative clustering with 
<span class="pkg">fastcluster</span> package's implementation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>riem.hclust(
  riemobj,
  geometry = c("intrinsic", "extrinsic"),
  method = c("single", "complete", "average", "mcquitty", "ward.D", "ward.D2",
    "centroid", "median"),
  members = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="riem.hclust_+3A_riemobj">riemobj</code></td>
<td>
<p>a S3 <code>"riemdata"</code> class for <code class="reqn">N</code> manifold-valued data.</p>
</td></tr>
<tr><td><code id="riem.hclust_+3A_geometry">geometry</code></td>
<td>
<p>(case-insensitive) name of geometry; either geodesic (<code>"intrinsic"</code>) or embedded (<code>"extrinsic"</code>) geometry.</p>
</td></tr>
<tr><td><code id="riem.hclust_+3A_method">method</code></td>
<td>
<p>agglomeration method to be used. This must be one of <code>"single"</code>, <code>"complete"</code>, <code>"average"</code>, <code>"mcquitty"</code>, <code>"ward.D"</code>, <code>"ward.D2"</code>, <code>"centroid"</code> or <code>"median"</code>.</p>
</td></tr>
<tr><td><code id="riem.hclust_+3A_members">members</code></td>
<td>
<p><code>NULL</code> or a vector whose length equals the number of observations. See <code><a href="stats.html#topic+hclust">hclust</a></code> for details.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>an object of class <code>hclust</code>. See <code><a href="stats.html#topic+hclust">hclust</a></code> for details.
</p>


<h3>References</h3>

<p>Müllner D (2013).
&ldquo;fastcluster : Fast Hierarchical, Agglomerative Clustering Routines for R and Python.&rdquo;
<em>Journal of Statistical Software</em>, <b>53</b>(9).
ISSN 1548-7660.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#-------------------------------------------------------------------
#          Example on Sphere : a dataset with three types
#
# class 1 : 10 perturbed data points near (1,0,0) on S^2 in R^3
# class 2 : 10 perturbed data points near (0,1,0) on S^2 in R^3
# class 3 : 10 perturbed data points near (0,0,1) on S^2 in R^3
#-------------------------------------------------------------------
## GENERATE DATA
mydata = list()
for (i in 1:10){
  tgt = c(1, stats::rnorm(2, sd=0.1))
  mydata[[i]] = tgt/sqrt(sum(tgt^2))
}
for (i in 11:20){
  tgt = c(rnorm(1,sd=0.1),1,rnorm(1,sd=0.1))
  mydata[[i]] = tgt/sqrt(sum(tgt^2))
}
for (i in 21:30){
  tgt = c(stats::rnorm(2, sd=0.1), 1)
  mydata[[i]] = tgt/sqrt(sum(tgt^2))
}
myriem = wrap.sphere(mydata)

## COMPUTE SINGLE AND COMPLETE LINKAGE
hc.sing &lt;- riem.hclust(myriem, method="single")
hc.comp &lt;- riem.hclust(myriem, method="complete")

## VISUALIZE
opar &lt;- par(no.readonly=TRUE)
par(mfrow=c(1,2))
plot(hc.sing, main="single linkage")
plot(hc.comp, main="complete linkage")
par(opar)

</code></pre>

<hr>
<h2 id='riem.interp'>Geodesic Interpolation</h2><span id='topic+riem.interp'></span>

<h3>Description</h3>

<p>Given 2 observations <code class="reqn">X_1, X_2 \in \mathcal{M}</code>, find the interpolated 
point of a geodesic <code class="reqn">\gamma(t)</code> for <code class="reqn">t \in (0,1)</code> which 
assumes two endpoints <code class="reqn">\gamma(0)=X_1</code> and <code class="reqn">\gamma(1)=X_2</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>riem.interp(riemobj, t = 0.5, geometry = c("intrinsic", "extrinsic"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="riem.interp_+3A_riemobj">riemobj</code></td>
<td>
<p>a S3 <code>"riemdata"</code> class for <code class="reqn">2</code> manifold-valued data where the first object is the starting point.</p>
</td></tr>
<tr><td><code id="riem.interp_+3A_t">t</code></td>
<td>
<p>a scalar in <code class="reqn">(0,1)</code> for which the interpolation is taken.</p>
</td></tr>
<tr><td><code id="riem.interp_+3A_geometry">geometry</code></td>
<td>
<p>(case-insensitive) name of geometry; either geodesic (<code>"intrinsic"</code>) or embedded (<code>"extrinsic"</code>) geometry.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>an interpolated object in matrix representation on <code class="reqn">\mathcal{M}</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#-------------------------------------------------------------------
#       Geodesic Interpolation between (1,0) and (0,1) in S^1
#-------------------------------------------------------------------
## PREPARE DATA
sp.start = c(1,0)
sp.end   = c(0,1)
sp.data  = wrap.sphere(rbind(sp.start, sp.end))

## FIND THE INTERPOLATED POINT AT "t=0.25"
mid.int = as.vector(riem.interp(sp.data, t=0.25, geometry="intrinsic"))
mid.ext = as.vector(riem.interp(sp.data, t=0.25, geometry="extrinsic"))

## VISUALIZE
#  Prepare Lines and Points
thetas  = seq(from=0, to=pi/2, length.out=100)
quarter = cbind(cos(thetas), sin(thetas))
pic.pts = rbind(sp.start, mid.int, mid.ext, sp.end)
pic.col = c("black","red","green","black")

# Draw
opar &lt;- par(no.readonly=TRUE)
par(pty="s")
plot(quarter, main="two interpolated points at t=0.25",
     xlab="x", ylab="y", type="l")
points(pic.pts, col=pic.col, pch=19)
text(mid.int[1]-0.1, mid.int[2], "intrinsic", col="red")
text(mid.ext[1]-0.1, mid.ext[2], "extrinsic", col="green")
par(opar)

</code></pre>

<hr>
<h2 id='riem.interps'>Geodesic Interpolation of Multiple Points</h2><span id='topic+riem.interps'></span>

<h3>Description</h3>

<p>Given 2 observations <code class="reqn">X_1, X_2 \in \mathcal{M}</code>, find 
the interpolated points of a geodesic <code class="reqn">\gamma(t)</code> for <code class="reqn">t \in (0,1)</code> which 
assumes two endpoints <code class="reqn">\gamma(0)=X_1</code> and <code class="reqn">\gamma(1)=X_2</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>riem.interps(
  riemobj,
  vect = c(0.25, 0.5, 0.75),
  geometry = c("intrinsic", "extrinsic")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="riem.interps_+3A_riemobj">riemobj</code></td>
<td>
<p>a S3 <code>"riemdata"</code> class for <code class="reqn">2</code> manifold-valued data where the first object is the starting point.</p>
</td></tr>
<tr><td><code id="riem.interps_+3A_vect">vect</code></td>
<td>
<p>a length-<code class="reqn">T</code> vector in <code class="reqn">(0,1)</code> for which the interpolations are taken.</p>
</td></tr>
<tr><td><code id="riem.interps_+3A_geometry">geometry</code></td>
<td>
<p>(case-insensitive) name of geometry; either geodesic (<code>"intrinsic"</code>) or embedded (<code>"extrinsic"</code>) geometry.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a 3d array where <code class="reqn">T</code> slices along 3rd dimension are interpolated objects in matrix representation.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#-------------------------------------------------------------------
#       Geodesic Interpolation between (1,0) and (0,1) in S^1
#-------------------------------------------------------------------
## PREPARE DATA
sp.start = c(1,0)
sp.end   = c(0,1)
sp.data  = wrap.sphere(rbind(sp.start, sp.end))

## FIND THE INTERPOLATED POINT AT FOR t=0.1, 0.2, ..., 0.9.
myvect  = seq(from=0.1, to=0.9, by=0.1)
geo.int = riem.interps(sp.data, vect=myvect, geometry="intrinsic")
geo.ext = riem.interps(sp.data, vect=myvect, geometry="extrinsic")

geo.int = matrix(geo.int, byrow=TRUE, ncol=2) # re-arrange for plotting
geo.ext = matrix(geo.ext, byrow=TRUE, ncol=2)

## VISUALIZE
#  Prepare Lines and Points
thetas  = seq(from=0, to=pi/2, length.out=100)
quarter = cbind(cos(thetas), sin(thetas))

pts.int = rbind(sp.start, geo.int, sp.end)
pts.ext = rbind(sp.start, geo.ext, sp.end)
col.int = c("black", rep("red",9),  "black")
col.ext = c("black", rep("blue",9), "black")

# Draw
opar &lt;- par(no.readonly=TRUE)
par(mfrow=c(1,2), pty="s")
plot(quarter, main="intrinsic interpolation", # intrinsic geodesic
     xlab="x", ylab="y", type="l")
points(pts.int, col=col.int, pch=19)
for (i in 1:9){
  text(geo.int[i,1]*0.9, geo.int[i,2]*0.9, 
       paste0(round(i/10,2)), col="red")
}
plot(quarter, main="extrinsic interpolation", # intrinsic geodesic
     xlab="x", ylab="y", type="l")
points(pts.ext, col=col.ext, pch=19)
for (i in 1:9){
  text(geo.ext[i,1]*0.9, geo.ext[i,2]*0.9, 
       paste0(round(i/10,2)), col="blue")
}
par(opar)

</code></pre>

<hr>
<h2 id='riem.isomap'>Isometric Feature Mapping</h2><span id='topic+riem.isomap'></span>

<h3>Description</h3>

<p>ISOMAP - isometric feature mapping - is a dimensionality reduction method 
to apply classical multidimensional scaling to the geodesic distance 
that is computed on a weighted nearest neighborhood graph. Nearest neighbor 
is defined by <code class="reqn">k</code>-NN where two observations are said to be connected when 
they are mutually included in each other's nearest neighbor. Note that 
it is possible for geodesic distances to be <code>Inf</code> when nearest neighbor 
graph construction incurs separate connected components. When an extra 
parameter <code>padding=TRUE</code>, infinite distances are replaced by 2 times 
the maximal finite geodesic distance.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>riem.isomap(
  riemobj,
  ndim = 2,
  nnbd = 5,
  geometry = c("intrinsic", "extrinsic"),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="riem.isomap_+3A_riemobj">riemobj</code></td>
<td>
<p>a S3 <code>"riemdata"</code> class for <code class="reqn">N</code> manifold-valued data.</p>
</td></tr>
<tr><td><code id="riem.isomap_+3A_ndim">ndim</code></td>
<td>
<p>an integer-valued target dimension (default: 2).</p>
</td></tr>
<tr><td><code id="riem.isomap_+3A_nnbd">nnbd</code></td>
<td>
<p>the size of nearest neighborhood (default: 5).</p>
</td></tr>
<tr><td><code id="riem.isomap_+3A_geometry">geometry</code></td>
<td>
<p>(case-insensitive) name of geometry; either geodesic (<code>"intrinsic"</code>) or embedded (<code>"extrinsic"</code>) geometry.</p>
</td></tr>
<tr><td><code id="riem.isomap_+3A_...">...</code></td>
<td>
<p>extra parameters including</p>

<dl>
<dt>padding</dt><dd><p>a logical; if <code>TRUE</code>, <code>Inf</code>-valued geodesic distances are replaced by 2 times the maximal geodesic distance in the data.</p>
</dd>
</dl>
</td></tr>
</table>


<h3>Value</h3>

<p>a named list containing </p>

<dl>
<dt>embed</dt><dd><p>an <code class="reqn">(N\times ndim)</code> matrix whose rows are embedded observations.</p>
</dd>
</dl>



<h3>References</h3>

<p>Silva VD, Tenenbaum JB (2003).
&ldquo;Global Versus Local Methods in Nonlinear Dimensionality Reduction.&rdquo;
In Becker S, Thrun S, Obermayer K (eds.), <em>Advances in Neural Information Processing Systems 15</em>, 721&ndash;728.
MIT Press.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#-------------------------------------------------------------------
#          Example on Sphere : a dataset with three types
#
# 10 perturbed data points near (1,0,0) on S^2 in R^3
# 10 perturbed data points near (0,1,0) on S^2 in R^3
# 10 perturbed data points near (0,0,1) on S^2 in R^3
#-------------------------------------------------------------------
## GENERATE DATA
mydata = list()
for (i in 1:10){
  tgt = c(1, stats::rnorm(2, sd=0.1))
  mydata[[i]] = tgt/sqrt(sum(tgt^2))
}
for (i in 11:20){
  tgt = c(rnorm(1,sd=0.1),1,rnorm(1,sd=0.1))
  mydata[[i]] = tgt/sqrt(sum(tgt^2))
}
for (i in 21:30){
  tgt = c(stats::rnorm(2, sd=0.1), 1)
  mydata[[i]] = tgt/sqrt(sum(tgt^2))
}
myriem = wrap.sphere(mydata)
mylabs = rep(c(1,2,3), each=10)

## MDS AND ISOMAP WITH DIFFERENT NEIGHBORHOOD SIZE
mdss = riem.mds(myriem)$embed
iso1 = riem.isomap(myriem, nnbd=5)$embed
iso2 = riem.isomap(myriem, nnbd=10)$embed

## VISUALIZE
opar = par(no.readonly=TRUE)
par(mfrow=c(1,3), pty="s")
plot(mdss, col=mylabs, pch=19, main="MDS")
plot(iso1, col=mylabs, pch=19, main="ISOMAP:nnbd=5")
plot(iso2, col=mylabs, pch=19, main="ISOMAP:nnbd=10")
par(opar)

</code></pre>

<hr>
<h2 id='riem.kmeans'>K-Means Clustering</h2><span id='topic+riem.kmeans'></span>

<h3>Description</h3>

<p>Given <code class="reqn">N</code> observations  <code class="reqn">X_1, X_2, \ldots, X_N \in \mathcal{M}</code>, 
perform k-means clustering by minimizing within-cluster sum of squares (WCSS). 
Since the problem is NP-hard and sensitive to the initialization, we provide an 
option with multiple starts and return the best result with respect to WCSS.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>riem.kmeans(riemobj, k = 2, geometry = c("intrinsic", "extrinsic"), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="riem.kmeans_+3A_riemobj">riemobj</code></td>
<td>
<p>a S3 <code>"riemdata"</code> class for <code class="reqn">N</code> manifold-valued data.</p>
</td></tr>
<tr><td><code id="riem.kmeans_+3A_k">k</code></td>
<td>
<p>the number of clusters.</p>
</td></tr>
<tr><td><code id="riem.kmeans_+3A_geometry">geometry</code></td>
<td>
<p>(case-insensitive) name of geometry; either geodesic (<code>"intrinsic"</code>) or embedded (<code>"extrinsic"</code>) geometry.</p>
</td></tr>
<tr><td><code id="riem.kmeans_+3A_...">...</code></td>
<td>
<p>extra parameters including</p>

<dl>
<dt>algorithm</dt><dd><p>(case-insensitive) name of an algorithm; <code>"MacQueen"</code> (default), or <code>"Lloyd"</code>.</p>
</dd>
<dt>init</dt><dd><p>(case-insensitive) name of an initialization scheme; <code>"plus"</code> for k-means++ (default), or <code>"random"</code>.</p>
</dd>
<dt>maxiter</dt><dd><p>maximum number of iterations to be run (default:50).</p>
</dd>
<dt>nstart</dt><dd><p>the number of random starts (default: 5).</p>
</dd>
</dl>
</td></tr>
</table>


<h3>Value</h3>

<p>a named list containing</p>

<dl>
<dt>cluster</dt><dd><p>a length-<code class="reqn">N</code> vector of class labels (from <code class="reqn">1:k</code>).</p>
</dd>
<dt>means</dt><dd><p>a 3d array where each slice along 3rd dimension is a matrix representation of class mean.</p>
</dd>
<dt>score</dt><dd><p>within-cluster sum of squares (WCSS).</p>
</dd>
</dl>



<h3>References</h3>

<p>Lloyd S (1982).
&ldquo;Least squares quantization in PCM.&rdquo;
<em>IEEE Transactions on Information Theory</em>, <b>28</b>(2), 129&ndash;137.
ISSN 0018-9448.
</p>
<p>MacQueen J (1967).
&ldquo;Some methods for classification and analysis of multivariate observations.&rdquo;
In <em>Proceedings of the fifth berkeley symposium on mathematical statistics and probability, volume 1: Statistics</em>, 281&ndash;297.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+riem.kmeanspp">riem.kmeanspp</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#-------------------------------------------------------------------
#          Example on Sphere : a dataset with three types
#
# class 1 : 10 perturbed data points near (1,0,0) on S^2 in R^3
# class 2 : 10 perturbed data points near (0,1,0) on S^2 in R^3
# class 3 : 10 perturbed data points near (0,0,1) on S^2 in R^3
#-------------------------------------------------------------------
## GENERATE DATA
mydata = list()
for (i in 1:10){
  tgt = c(1, stats::rnorm(2, sd=0.1))
  mydata[[i]] = tgt/sqrt(sum(tgt^2))
}
for (i in 11:20){
  tgt = c(rnorm(1,sd=0.1),1,rnorm(1,sd=0.1))
  mydata[[i]] = tgt/sqrt(sum(tgt^2))
}
for (i in 21:30){
  tgt = c(stats::rnorm(2, sd=0.1), 1)
  mydata[[i]] = tgt/sqrt(sum(tgt^2))
}
myriem = wrap.sphere(mydata)
mylabs = rep(c(1,2,3), each=10)

## K-MEANS WITH K=2,3,4
clust2 = riem.kmeans(myriem, k=2)
clust3 = riem.kmeans(myriem, k=3)
clust4 = riem.kmeans(myriem, k=4)

## MDS FOR VISUALIZATION
mds2d = riem.mds(myriem, ndim=2)$embed

## VISUALIZE
opar &lt;- par(no.readonly=TRUE)
par(mfrow=c(2,2), pty="s")
plot(mds2d, pch=19, main="true label", col=mylabs)
plot(mds2d, pch=19, main="K=2", col=clust2$cluster)
plot(mds2d, pch=19, main="K=3", col=clust3$cluster)
plot(mds2d, pch=19, main="K=4", col=clust4$cluster)
par(opar)

</code></pre>

<hr>
<h2 id='riem.kmeans18B'>K-Means Clustering with Lightweight Coreset</h2><span id='topic+riem.kmeans18B'></span>

<h3>Description</h3>

<p>The modified version of lightweight coreset for scalable <code class="reqn">k</code>-means computation 
is applied for manifold-valued data <code class="reqn">X_1,X_2,\ldots,X_N \in \mathcal{M}</code>. 
The smaller the set is, the faster the execution becomes with potentially larger quantization errors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>riem.kmeans18B(
  riemobj,
  k = 2,
  M = length(riemobj$data)/2,
  geometry = c("intrinsic", "extrinsic"),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="riem.kmeans18B_+3A_riemobj">riemobj</code></td>
<td>
<p>a S3 <code>"riemdata"</code> class for <code class="reqn">N</code> manifold-valued data.</p>
</td></tr>
<tr><td><code id="riem.kmeans18B_+3A_k">k</code></td>
<td>
<p>the number of clusters.</p>
</td></tr>
<tr><td><code id="riem.kmeans18B_+3A_m">M</code></td>
<td>
<p>the size of coreset (default: <code class="reqn">N/2</code>).</p>
</td></tr>
<tr><td><code id="riem.kmeans18B_+3A_geometry">geometry</code></td>
<td>
<p>(case-insensitive) name of geometry; either geodesic (<code>"intrinsic"</code>) or embedded (<code>"extrinsic"</code>) geometry.</p>
</td></tr>
<tr><td><code id="riem.kmeans18B_+3A_...">...</code></td>
<td>
<p>extra parameters including</p>

<dl>
<dt>maxiter</dt><dd><p>maximum number of iterations to be run (default:50).</p>
</dd>
<dt>nstart</dt><dd><p>the number of random starts (default: 5).</p>
</dd>
</dl>
</td></tr>
</table>


<h3>Value</h3>

<p>a named list containing</p>

<dl>
<dt>cluster</dt><dd><p>a length-<code class="reqn">N</code> vector of class labels (from <code class="reqn">1:k</code>).</p>
</dd>
<dt>means</dt><dd><p>a 3d array where each slice along 3rd dimension is a matrix representation of class mean.</p>
</dd>
<dt>score</dt><dd><p>within-cluster sum of squares (WCSS).</p>
</dd>
</dl>



<h3>References</h3>

<p>Bachem O, Lucic M, Krause A (2018).
&ldquo;Scalable k -Means Clustering via Lightweight Coresets.&rdquo;
In <em>Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery \&amp; Data Mining</em>, 1119&ndash;1127.
ISBN 978-1-4503-5552-0.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+riem.coreset18B">riem.coreset18B</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#-------------------------------------------------------------------
#          Example on Sphere : a dataset with three types
#
# class 1 : 10 perturbed data points near (1,0,0) on S^2 in R^3
# class 2 : 10 perturbed data points near (0,1,0) on S^2 in R^3
# class 3 : 10 perturbed data points near (0,0,1) on S^2 in R^3
#-------------------------------------------------------------------
## GENERATE DATA
mydata = list()
for (i in 1:10){
  tgt = c(1, stats::rnorm(2, sd=0.1))
  mydata[[i]] = tgt/sqrt(sum(tgt^2))
}
for (i in 11:20){
  tgt = c(rnorm(1,sd=0.1),1,rnorm(1,sd=0.1))
  mydata[[i]] = tgt/sqrt(sum(tgt^2))
}
for (i in 21:30){
  tgt = c(stats::rnorm(2, sd=0.1), 1)
  mydata[[i]] = tgt/sqrt(sum(tgt^2))
}
myriem = wrap.sphere(mydata)
mylabs = rep(c(1,2,3), each=10)

## TRY DIFFERENT SIZES OF CORESET WITH K=4 FIXED
core1 = riem.kmeans18B(myriem, k=3, M=5)
core2 = riem.kmeans18B(myriem, k=3, M=10)
core3 = riem.kmeans18B(myriem, k=3, M=15)

## MDS FOR VISUALIZATION
mds2d = riem.mds(myriem, ndim=2)$embed

## VISUALIZE
opar &lt;- par(no.readonly=TRUE)
par(mfrow=c(2,2), pty="s")
plot(mds2d, pch=19, main="true label", col=mylabs)
plot(mds2d, pch=19, main="kmeans18B: M=5",  col=core1$cluster)
plot(mds2d, pch=19, main="kmeans18B: M=10", col=core2$cluster)
plot(mds2d, pch=19, main="kmeans18B: M=15", col=core3$cluster)
par(opar)

</code></pre>

<hr>
<h2 id='riem.kmeanspp'>K-Means++ Clustering</h2><span id='topic+riem.kmeanspp'></span>

<h3>Description</h3>

<p>Given <code class="reqn">N</code> observations  <code class="reqn">X_1, X_2, \ldots, X_N \in \mathcal{M}</code>, 
perform k-means++ clustering algorithm using pairwise distances. The algorithm 
was originally designed as an efficient initialization method for k-means 
algorithm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>riem.kmeanspp(riemobj, k = 2, geometry = c("intrinsic", "extrinsic"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="riem.kmeanspp_+3A_riemobj">riemobj</code></td>
<td>
<p>a S3 <code>"riemdata"</code> class for <code class="reqn">N</code> manifold-valued data.</p>
</td></tr>
<tr><td><code id="riem.kmeanspp_+3A_k">k</code></td>
<td>
<p>the number of clusters.</p>
</td></tr>
<tr><td><code id="riem.kmeanspp_+3A_geometry">geometry</code></td>
<td>
<p>(case-insensitive) name of geometry; either geodesic (<code>"intrinsic"</code>) or embedded (<code>"extrinsic"</code>) geometry.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a named list containing</p>

<dl>
<dt>centers</dt><dd><p>a length-<code class="reqn">k</code> vector of sampled centers' indices.</p>
</dd>
<dt>cluster</dt><dd><p>a length-<code class="reqn">N</code> vector of class labels (from <code class="reqn">1:k</code>).</p>
</dd>
</dl>



<h3>References</h3>

<p>Arthur D, Vassilvitskii S (2007).
&ldquo;K-Means++: The advantages of careful seeding.&rdquo;
In <em>Proceedings of the eighteenth annual ACM-SIAM symposium on discrete algorithms</em>,  SODA '07, 1027&ndash;1035.
ISBN 978-0-89871-624-5, Number of pages: 9 Place: New Orleans, Louisiana.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#-------------------------------------------------------------------
#          Example on Sphere : a dataset with three types
#
# class 1 : 10 perturbed data points near (1,0,0) on S^2 in R^3
# class 2 : 10 perturbed data points near (0,1,0) on S^2 in R^3
# class 3 : 10 perturbed data points near (0,0,1) on S^2 in R^3
#-------------------------------------------------------------------
## GENERATE DATA
mydata = list()
for (i in 1:10){
  tgt = c(1, stats::rnorm(2, sd=0.1))
  mydata[[i]] = tgt/sqrt(sum(tgt^2))
}
for (i in 11:20){
  tgt = c(rnorm(1,sd=0.1),1,rnorm(1,sd=0.1))
  mydata[[i]] = tgt/sqrt(sum(tgt^2))
}
for (i in 21:30){
  tgt = c(stats::rnorm(2, sd=0.1), 1)
  mydata[[i]] = tgt/sqrt(sum(tgt^2))
}
myriem = wrap.sphere(mydata)
mylabs = rep(c(1,2,3), each=10)

## K-MEANS++ WITH K=2,3,4
clust2 = riem.kmeanspp(myriem, k=2)
clust3 = riem.kmeanspp(myriem, k=3)
clust4 = riem.kmeanspp(myriem, k=4)

## MDS FOR VISUALIZATION
mds2d = riem.mds(myriem, ndim=2)$embed

## VISUALIZE
opar &lt;- par(no.readonly=TRUE)
par(mfrow=c(2,2), pty="s")
plot(mds2d, pch=19, main="true label", col=mylabs)
plot(mds2d, pch=19, main="K=2", col=clust2$cluster)
plot(mds2d, pch=19, main="K=3", col=clust3$cluster)
plot(mds2d, pch=19, main="K=4", col=clust4$cluster)
par(opar)

</code></pre>

<hr>
<h2 id='riem.kmedoids'>K-Medoids Clustering</h2><span id='topic+riem.kmedoids'></span>

<h3>Description</h3>

<p>Given <code class="reqn">N</code> observations  <code class="reqn">X_1, X_2, \ldots, X_N \in \mathcal{M}</code>, 
perform k-medoids clustering using pairwise distances.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>riem.kmedoids(riemobj, k = 2, geometry = c("intrinsic", "extrinsic"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="riem.kmedoids_+3A_riemobj">riemobj</code></td>
<td>
<p>a S3 <code>"riemdata"</code> class for <code class="reqn">N</code> manifold-valued data.</p>
</td></tr>
<tr><td><code id="riem.kmedoids_+3A_k">k</code></td>
<td>
<p>the number of clusters.</p>
</td></tr>
<tr><td><code id="riem.kmedoids_+3A_geometry">geometry</code></td>
<td>
<p>(case-insensitive) name of geometry; either geodesic (<code>"intrinsic"</code>) or embedded (<code>"extrinsic"</code>) geometry.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a named list containing</p>

<dl>
<dt>medoids</dt><dd><p>a length-<code class="reqn">k</code> vector of medoids' indices.</p>
</dd>
<dt>cluster</dt><dd><p>a length-<code class="reqn">N</code> vector of class labels (from <code class="reqn">1:k</code>).</p>
</dd>
</dl>



<h3>See Also</h3>

<p><code><a href="cluster.html#topic+pam">pam</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#-------------------------------------------------------------------
#          Example on Sphere : a dataset with three types
#
# class 1 : 10 perturbed data points near (1,0,0) on S^2 in R^3
# class 2 : 10 perturbed data points near (0,1,0) on S^2 in R^3
# class 3 : 10 perturbed data points near (0,0,1) on S^2 in R^3
#-------------------------------------------------------------------
## GENERATE DATA
mydata = list()
for (i in 1:10){
  tgt = c(1, stats::rnorm(2, sd=0.1))
  mydata[[i]] = tgt/sqrt(sum(tgt^2))
}
for (i in 11:20){
  tgt = c(rnorm(1,sd=0.1),1,rnorm(1,sd=0.1))
  mydata[[i]] = tgt/sqrt(sum(tgt^2))
}
for (i in 21:30){
  tgt = c(stats::rnorm(2, sd=0.1), 1)
  mydata[[i]] = tgt/sqrt(sum(tgt^2))
}
myriem = wrap.sphere(mydata)
mylabs = rep(c(1,2,3), each=10)

## K-MEDOIDS WITH K=2,3,4
clust2 = riem.kmedoids(myriem, k=2)
clust3 = riem.kmedoids(myriem, k=3)
clust4 = riem.kmedoids(myriem, k=4)

## MDS FOR VISUALIZATION
mds2d = riem.mds(myriem, ndim=2)$embed

## VISUALIZE
opar &lt;- par(no.readonly=TRUE)
par(mfrow=c(2,2), pty="s")
plot(mds2d, pch=19, main="true label", col=mylabs)
plot(mds2d, pch=19, main="K=2", col=clust2$cluster)
plot(mds2d, pch=19, main="K=3", col=clust3$cluster)
plot(mds2d, pch=19, main="K=4", col=clust4$cluster)
par(opar)
 
</code></pre>

<hr>
<h2 id='riem.knn'>Find K-Nearest Neighbors</h2><span id='topic+riem.knn'></span>

<h3>Description</h3>

<p>Given <code class="reqn">N</code> observations  <code class="reqn">X_1, X_2, \ldots, X_N \in \mathcal{M}</code>, 
<code>riem.knn</code> constructs <code class="reqn">k</code>-nearest neighbors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>riem.knn(riemobj, k = 2, geometry = c("intrinsic", "extrinsic"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="riem.knn_+3A_riemobj">riemobj</code></td>
<td>
<p>a S3 <code>"riemdata"</code> class for <code class="reqn">N</code> manifold-valued data.</p>
</td></tr>
<tr><td><code id="riem.knn_+3A_k">k</code></td>
<td>
<p>the number of neighbors to find.</p>
</td></tr>
<tr><td><code id="riem.knn_+3A_geometry">geometry</code></td>
<td>
<p>(case-insensitive) name of geometry; either geodesic (<code>"intrinsic"</code>) or embedded (<code>"extrinsic"</code>) geometry.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a named list containing</p>

<dl>
<dt>nn.idx</dt><dd><p>an <code class="reqn">(N \times k)</code> neighborhood index matrix.</p>
</dd>
<dt>nn.dists</dt><dd><p>an <code class="reqn">(N\times k)</code> distances from a point to its neighbors.</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>#-------------------------------------------------------------------
#          Example on Sphere : a dataset with three types
#
# * 10 perturbed data points near (1,0,0) on S^2 in R^3
# * 10 perturbed data points near (0,1,0) on S^2 in R^3
# * 10 perturbed data points near (0,0,1) on S^2 in R^3
#-------------------------------------------------------------------
## GENERATE DATA
mydata = list()
for (i in 1:10){
  tgt = c(1, stats::rnorm(2, sd=0.1))
  mydata[[i]] = tgt/sqrt(sum(tgt^2))
}
for (i in 11:20){
  tgt = c(rnorm(1,sd=0.1),1,rnorm(1,sd=0.1))
  mydata[[i]] = tgt/sqrt(sum(tgt^2))
}
for (i in 21:30){
  tgt = c(stats::rnorm(2, sd=0.1), 1)
  mydata[[i]] = tgt/sqrt(sum(tgt^2))
}
myriem = wrap.sphere(mydata)
mylabs = rep(c(2,3,4), each=10)

## K-NN CONSTRUCTION WITH K=5 &amp; K=10
knn1 = riem.knn(myriem, k=5)
knn2 = riem.knn(myriem, k=10)

## MDS FOR VISUALIZATION
embed2 = riem.mds(myriem, ndim=2)$embed

## VISUALIZE
opar &lt;- par(no.readonly=TRUE)
par(mfrow=c(1,2), pty="s")
plot(embed2, pch=19, main="knn with k=4", col=mylabs)
for (i in 1:30){
  for (j in 1:5){
    lines(embed2[c(i,knn1$nn.idx[i,j]),])
  }
}
plot(embed2, pch=19, main="knn with k=8", col=mylabs)
for (i in 1:30){
  for (j in 1:10){
    lines(embed2[c(i,knn2$nn.idx[i,j]),])
  }
}
par(opar)

</code></pre>

<hr>
<h2 id='riem.kpca'>Kernel Principal Component Analysis</h2><span id='topic+riem.kpca'></span>

<h3>Description</h3>

<p>Although the method of Kernel Principal Component Analysis (KPCA) was originally 
developed to visualize non-linearly distributed data in Euclidean space, 
we graft this to the case for manifolds where extrinsic geometry is explicitly available.
The algorithm uses Gaussian kernel with 
</p>
<p style="text-align: center;"><code class="reqn">K(X_i, X_j) = \exp\left( - \frac{d^2 (X_i, X_j)}{2 \sigma^2} \right )</code>
</p>

<p>where <code class="reqn">\sigma</code> is a bandwidth parameter and <code class="reqn">d(\cdot, \cdot)</code> is 
an extrinsic distance defined on a specific manifold.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>riem.kpca(riemobj, ndim = 2, sigma = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="riem.kpca_+3A_riemobj">riemobj</code></td>
<td>
<p>a S3 <code>"riemdata"</code> class for <code class="reqn">N</code> manifold-valued data.</p>
</td></tr>
<tr><td><code id="riem.kpca_+3A_ndim">ndim</code></td>
<td>
<p>an integer-valued target dimension (default: 2).</p>
</td></tr>
<tr><td><code id="riem.kpca_+3A_sigma">sigma</code></td>
<td>
<p>the bandwidth parameter (default: 1).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a named list containing </p>

<dl>
<dt>embed</dt><dd><p>an <code class="reqn">(N\times ndim)</code> matrix whose rows are embedded observations.</p>
</dd>
<dt>vars</dt><dd><p>a length-<code class="reqn">N</code> vector of eigenvalues from kernelized covariance matrix.</p>
</dd>
</dl>



<h3>References</h3>

<p>Schölkopf B, Smola A, Müller K (1997).
&ldquo;Kernel principal component analysis.&rdquo;
In Goos G, Hartmanis J, van Leeuwen J, Gerstner W, Germond A, Hasler M, Nicoud J (eds.), <em>Artificial Neural Networks — ICANN'97</em>, volume 1327, 583&ndash;588.
Springer Berlin Heidelberg, Berlin, Heidelberg.
ISBN 978-3-540-63631-1 978-3-540-69620-9.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#-------------------------------------------------------------------
#          Example for Gorilla Skull Data : 'gorilla'
#-------------------------------------------------------------------
## PREPARE THE DATA
#  Aggregate two classes into one set
data(gorilla)

mygorilla = array(0,c(8,2,59))
for (i in 1:29){
  mygorilla[,,i] = gorilla$male[,,i]
}
for (i in 30:59){
  mygorilla[,,i] = gorilla$female[,,i-29]
}

gor.riem = wrap.landmark(mygorilla)
gor.labs = c(rep("red",29), rep("blue",30))

## APPLY KPCA WITH DIFFERENT KERNEL BANDWIDTHS
kpca1 = riem.kpca(gor.riem, sigma=0.01)
kpca2 = riem.kpca(gor.riem, sigma=1)
kpca3 = riem.kpca(gor.riem, sigma=100)
## VISUALIZE
opar &lt;- par(no.readonly=TRUE)
par(mfrow=c(1,3), pty="s")
plot(kpca1$embed, pch=19, col=gor.labs, main="sigma=1/100")
plot(kpca2$embed, pch=19, col=gor.labs, main="sigma=1")
plot(kpca3$embed, pch=19, col=gor.labs, main="sigma=100")
par(opar)

</code></pre>

<hr>
<h2 id='riem.m2skreg'>Manifold-to-Scalar Kernel Regression</h2><span id='topic+riem.m2skreg'></span>

<h3>Description</h3>

<p>Given <code class="reqn">N</code> observations <code class="reqn">X_1, X_2, \ldots, X_N \in \mathcal{M}</code> and 
scalars <code class="reqn">y_1, y_2, \ldots, y_N \in \mathbf{R}</code>, perform the Nadaraya-Watson kernel 
regression by 
</p>
<p style="text-align: center;"><code class="reqn">\hat{m}_h (X) = \frac{\sum_{i=1}^n K \left( \frac{d(X,X_i)}{h}  \right) y_i}{\sum_{i=1}^n K \left( \frac{d(X,X_i)}{h}  \right)}</code>
</p>

<p>where the Gaussian kernel is defined as
</p>
<p style="text-align: center;"><code class="reqn">K(x) := \frac{1}{\sqrt{2\pi}} \exp \left( - \frac{x^2}{2}\right)</code>
</p>
 
<p>with the bandwidth parameter <code class="reqn">h &gt; 0</code> that controls the degree of smoothness.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>riem.m2skreg(
  riemobj,
  y,
  bandwidth = 0.5,
  geometry = c("intrinsic", "extrinsic")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="riem.m2skreg_+3A_riemobj">riemobj</code></td>
<td>
<p>a S3 <code>"riemdata"</code> class for <code class="reqn">N</code> manifold-valued data corresponding to <code class="reqn">X_1,\ldots,X_N</code>.</p>
</td></tr>
<tr><td><code id="riem.m2skreg_+3A_y">y</code></td>
<td>
<p>a length-<code class="reqn">N</code> vector of dependent variable values.</p>
</td></tr>
<tr><td><code id="riem.m2skreg_+3A_bandwidth">bandwidth</code></td>
<td>
<p>a nonnegative number that controls smoothness.</p>
</td></tr>
<tr><td><code id="riem.m2skreg_+3A_geometry">geometry</code></td>
<td>
<p>(case-insensitive) name of geometry; either geodesic (<code>"intrinsic"</code>) or embedded (<code>"extrinsic"</code>) geometry.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a named list of S3 class <code>m2skreg</code> containing
</p>

<dl>
<dt>ypred</dt><dd><p>a length-<code class="reqn">N</code> vector of smoothed responses.</p>
</dd>
<dt>bandwidth</dt><dd><p>the bandwidth value that was originally provided, which is saved for future use.</p>
</dd>
<dt>inputs</dt><dd><p>a list containing both <code>riemobj</code> and <code>y</code> for future use.</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>
#-------------------------------------------------------------------
#                    Example on Sphere S^2
#
#  X : equi-spaced points from (0,0,1) to (0,1,0)
#  y : sin(x) with perturbation
#-------------------------------------------------------------------
# GENERATE DATA
npts = 100
nlev = 0.25
thetas = seq(from=0, to=pi/2, length.out=npts)
Xstack = cbind(rep(0,npts), sin(thetas), cos(thetas))

Xriem  = wrap.sphere(Xstack)
ytrue  = sin(seq(from=0, to=2*pi, length.out=npts))
ynoise = ytrue + rnorm(npts, sd=nlev)

# FIT WITH DIFFERENT BANDWIDTHS
fit1 = riem.m2skreg(Xriem, ynoise, bandwidth=0.001)
fit2 = riem.m2skreg(Xriem, ynoise, bandwidth=0.01)
fit3 = riem.m2skreg(Xriem, ynoise, bandwidth=0.1)

# VISUALIZE
xgrd &lt;- 1:npts
opar &lt;- par(no.readonly=TRUE)
par(mfrow=c(1,3))
plot(xgrd, fit1$ypred, pch=19, cex=0.5, "b", xlab="", ylim=c(-2,2), main="h=1e-3")
lines(xgrd, ytrue, col="red", lwd=1.5)
plot(xgrd, fit2$ypred, pch=19, cex=0.5, "b", xlab="", ylim=c(-2,2), main="h=1e-2")
lines(xgrd, ytrue, col="red", lwd=1.5)
plot(xgrd, fit3$ypred, pch=19, cex=0.5, "b", xlab="", ylim=c(-2,2), main="h=1e-1")
lines(xgrd, ytrue, col="red", lwd=1.5)
par(opar)


</code></pre>

<hr>
<h2 id='riem.m2skregCV'>Manifold-to-Scalar Kernel Regression with K-Fold Cross Validation</h2><span id='topic+riem.m2skregCV'></span>

<h3>Description</h3>

<p>Manifold-to-Scalar Kernel Regression with K-Fold Cross Validation
</p>


<h3>Usage</h3>

<pre><code class='language-R'>riem.m2skregCV(
  riemobj,
  y,
  bandwidths = seq(from = 0.01, to = 1, length.out = 10),
  geometry = c("intrinsic", "extrinsic"),
  kfold = 5
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="riem.m2skregCV_+3A_riemobj">riemobj</code></td>
<td>
<p>a S3 <code>"riemdata"</code> class for <code class="reqn">N</code> manifold-valued data corresponding to <code class="reqn">X_1,\ldots,X_N</code>.</p>
</td></tr>
<tr><td><code id="riem.m2skregCV_+3A_y">y</code></td>
<td>
<p>a length-<code class="reqn">N</code> vector of dependent variable values.</p>
</td></tr>
<tr><td><code id="riem.m2skregCV_+3A_bandwidths">bandwidths</code></td>
<td>
<p>a vector of nonnegative numbers that control smoothness.</p>
</td></tr>
<tr><td><code id="riem.m2skregCV_+3A_geometry">geometry</code></td>
<td>
<p>(case-insensitive) name of geometry; either geodesic (<code>"intrinsic"</code>) or embedded (<code>"extrinsic"</code>) geometry.</p>
</td></tr>
<tr><td><code id="riem.m2skregCV_+3A_kfold">kfold</code></td>
<td>
<p>the number of folds for cross validation.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a named list of S3 class <code>m2skreg</code> containing
</p>

<dl>
<dt>ypred</dt><dd><p>a length-<code class="reqn">N</code> vector of optimal smoothed responses.</p>
</dd>
<dt>bandwidth</dt><dd><p>the optimal bandwidth value.</p>
</dd>
<dt>inputs</dt><dd><p>a list containing both <code>riemobj</code> and <code>y</code> for future use.</p>
</dd>
<dt>errors</dt><dd><p>a matrix whose columns are <code>bandwidths</code> values and corresponding errors measure in SSE.</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>
#-------------------------------------------------------------------
#                    Example on Sphere S^2
#
#  X : equi-spaced points from (0,0,1) to (0,1,0)
#  y : sin(x) with perturbation
#-------------------------------------------------------------------
# GENERATE DATA
set.seed(496) 
npts = 100
nlev = 0.25
thetas = seq(from=0, to=pi/2, length.out=npts)
Xstack = cbind(rep(0,npts), sin(thetas), cos(thetas))

Xriem  = wrap.sphere(Xstack)
ytrue  = sin(seq(from=0, to=2*pi, length.out=npts))
ynoise = ytrue + rnorm(npts, sd=nlev)

# FIT WITH 5-FOLD CV
cv_band = (10^seq(from=-4, to=-1, length.out=200))
cv_fit  = riem.m2skregCV(Xriem, ynoise, bandwidths=cv_band)
cv_err  = cv_fit$errors

# VISUALIZE
opar &lt;- par(no.readonly=TRUE)
par(mfrow=c(1,2))
plot(1:npts, cv_fit$ypred, pch=19, cex=0.5, "b", xlab="", main="optimal prediction")
lines(1:npts, ytrue, col="red", lwd=1.5)
plot(cv_err[,1], cv_err[,2], "b", pch=19, cex=0.5, main="5-fold CV errors",
     xlab="bandwidth", ylab="SSE")
abline(v=cv_fit$bandwidth, col="blue", lwd=1.5)
par(opar)


</code></pre>

<hr>
<h2 id='riem.mds'>Multidimensional Scaling</h2><span id='topic+riem.mds'></span>

<h3>Description</h3>

<p>Given <code class="reqn">N</code> observations <code class="reqn">X_1, X_2, \ldots, X_N \in \mathcal{M}</code>, 
apply multidimensional scaling to get low-dimensional embedding 
in Euclidean space. Usually, <code>ndim=2,3</code> are chosen for visualization.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>riem.mds(riemobj, ndim = 2, geometry = c("intrinsic", "extrinsic"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="riem.mds_+3A_riemobj">riemobj</code></td>
<td>
<p>a S3 <code>"riemdata"</code> class for <code class="reqn">N</code> manifold-valued data.</p>
</td></tr>
<tr><td><code id="riem.mds_+3A_ndim">ndim</code></td>
<td>
<p>an integer-valued target dimension (default: 2).</p>
</td></tr>
<tr><td><code id="riem.mds_+3A_geometry">geometry</code></td>
<td>
<p>(case-insensitive) name of geometry; either geodesic (<code>"intrinsic"</code>) or embedded (<code>"extrinsic"</code>) geometry.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a named list containing </p>

<dl>
<dt>embed</dt><dd><p>an <code class="reqn">(N\times ndim)</code> matrix whose rows are embedded observations.</p>
</dd>
<dt>stress</dt><dd><p>discrepancy between embedded and original distances as a measure of error.</p>
</dd>
</dl>



<h3>References</h3>

<p>Torgerson WS (1952).
&ldquo;Multidimensional scaling: I. Theory and method.&rdquo;
<em>Psychometrika</em>, <b>17</b>(4), 401&ndash;419.
ISSN 0033-3123, 1860-0980.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#-------------------------------------------------------------------
#          Example on Sphere : a dataset with three types
#
# 10 perturbed data points near (1,0,0) on S^2 in R^3
# 10 perturbed data points near (0,1,0) on S^2 in R^3
# 10 perturbed data points near (0,0,1) on S^2 in R^3
#-------------------------------------------------------------------
## GENERATE DATA
mydata = list()
for (i in 1:10){
  tgt = c(1, stats::rnorm(2, sd=0.1))
  mydata[[i]] = tgt/sqrt(sum(tgt^2))
}
for (i in 11:20){
  tgt = c(rnorm(1,sd=0.1),1,rnorm(1,sd=0.1))
  mydata[[i]] = tgt/sqrt(sum(tgt^2))
}
for (i in 21:30){
  tgt = c(stats::rnorm(2, sd=0.1), 1)
  mydata[[i]] = tgt/sqrt(sum(tgt^2))
}
myriem = wrap.sphere(mydata)
mylabs = rep(c(1,2,3), each=10)

## MDS EMBEDDING WITH TWO GEOMETRIES
embed2int = riem.mds(myriem, geometry="intrinsic")$embed
embed2ext = riem.mds(myriem, geometry="extrinsic")$embed

## VISUALIZE
opar = par(no.readonly=TRUE)
par(mfrow=c(1,2), pty="s")
plot(embed2int, main="intrinsic MDS", ylim=c(-2,2), col=mylabs, pch=19)
plot(embed2ext, main="extrinsic MDS", ylim=c(-2,2), col=mylabs, pch=19)
par(opar)

</code></pre>

<hr>
<h2 id='riem.mean'>Fréchet Mean and Variation</h2><span id='topic+riem.mean'></span>

<h3>Description</h3>

<p>Given <code class="reqn">N</code> observations <code class="reqn">X_1, X_2, \ldots, X_N \in \mathcal{M}</code>, 
compute Fréchet mean and variation with respect to the geometry by minimizing
</p>
<p style="text-align: center;"><code class="reqn">\textrm{min}_x \sum_{n=1}^N w_n \rho^2 (x, x_n),\quad x\in\mathcal{M}</code>
</p>
<p> where
<code class="reqn">\rho (x, y)</code> is a distance for two points <code class="reqn">x,y\in\mathcal{M}</code>. 
If non-uniform weights are given, normalized version of the mean is computed 
and if <code>weight=NULL</code>, it automatically sets equal weights (<code class="reqn">w_i = 1/n</code>) for all observations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>riem.mean(riemobj, weight = NULL, geometry = c("intrinsic", "extrinsic"), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="riem.mean_+3A_riemobj">riemobj</code></td>
<td>
<p>a S3 <code>"riemdata"</code> class for <code class="reqn">N</code> manifold-valued data.</p>
</td></tr>
<tr><td><code id="riem.mean_+3A_weight">weight</code></td>
<td>
<p>weight of observations; if <code>NULL</code> it assumes equal weights, or a nonnegative length-<code class="reqn">N</code> vector that sums to 1 should be given.</p>
</td></tr>
<tr><td><code id="riem.mean_+3A_geometry">geometry</code></td>
<td>
<p>(case-insensitive) name of geometry; either geodesic (<code>"intrinsic"</code>) or embedded (<code>"extrinsic"</code>) geometry.</p>
</td></tr>
<tr><td><code id="riem.mean_+3A_...">...</code></td>
<td>
<p>extra parameters including</p>

<dl>
<dt>maxiter</dt><dd><p>maximum number of iterations to be run (default:50).</p>
</dd>
<dt>eps</dt><dd><p>tolerance level for stopping criterion (default: 1e-5).</p>
</dd>
</dl>
</td></tr>
</table>


<h3>Value</h3>

<p>a named list containing</p>

<dl>
<dt>mean</dt><dd><p>a mean matrix on <code class="reqn">\mathcal{M}</code>.</p>
</dd>
<dt>variation</dt><dd><p>sum of (weighted) squared distances.</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>#-------------------------------------------------------------------
#        Example on Sphere : points near (0,1) on S^1 in R^2
#-------------------------------------------------------------------
## GENERATE DATA
ndata = 50
mydat = array(0,c(ndata,2))
for (i in 1:ndata){
  tgt = c(stats::rnorm(1, sd=2), 1)
  mydat[i,] = tgt/sqrt(sum(tgt^2))
}
myriem = wrap.sphere(mydat)

## COMPUTE TWO MEANS
mean.int = as.vector(riem.mean(myriem, geometry="intrinsic")$mean)
mean.ext = as.vector(riem.mean(myriem, geometry="extrinsic")$mean)

## VISUALIZE
opar &lt;- par(no.readonly=TRUE)
plot(mydat[,1], mydat[,2], pch=19, xlim=c(-1.1,1.1), ylim=c(0,1.1),
     main="BLUE-extrinsic vs RED-intrinsic")
arrows(x0=0,y0=0,x1=mean.int[1],y1=mean.int[2],col="red")
arrows(x0=0,y0=0,x1=mean.ext[1],y1=mean.ext[2],col="blue")
par(opar)

</code></pre>

<hr>
<h2 id='riem.median'>Fréchet Median and Variation</h2><span id='topic+riem.median'></span>

<h3>Description</h3>

<p>Given <code class="reqn">N</code> observations <code class="reqn">X_1, X_2, \ldots, X_N \in \mathcal{M}</code>, 
compute Fréchet median and variation with respect to the geometry by minimizing
</p>
<p style="text-align: center;"><code class="reqn">\textrm{min}_x \sum_{n=1}^N w_n \rho (x, x_n),\quad x\in\mathcal{M}</code>
</p>
<p> where
<code class="reqn">\rho (x, y)</code> is a distance for two points <code class="reqn">x,y\in\mathcal{M}</code>. 
If non-uniform weights are given, normalized version of the mean is computed 
and if <code>weight=NULL</code>, it automatically sets equal weights for all observations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>riem.median(
  riemobj,
  weight = NULL,
  geometry = c("intrinsic", "extrinsic"),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="riem.median_+3A_riemobj">riemobj</code></td>
<td>
<p>a S3 <code>"riemdata"</code> class for <code class="reqn">N</code> manifold-valued data.</p>
</td></tr>
<tr><td><code id="riem.median_+3A_weight">weight</code></td>
<td>
<p>weight of observations; if <code>NULL</code> it assumes equal weights, or a nonnegative length-<code class="reqn">N</code> vector that sums to 1 should be given.</p>
</td></tr>
<tr><td><code id="riem.median_+3A_geometry">geometry</code></td>
<td>
<p>(case-insensitive) name of geometry; either geodesic (<code>"intrinsic"</code>) or embedded (<code>"extrinsic"</code>) geometry.</p>
</td></tr>
<tr><td><code id="riem.median_+3A_...">...</code></td>
<td>
<p>extra parameters including</p>

<dl>
<dt>maxiter</dt><dd><p>maximum number of iterations to be run (default:50).</p>
</dd>
<dt>eps</dt><dd><p>tolerance level for stopping criterion (default: 1e-5).</p>
</dd>
</dl>
</td></tr>
</table>


<h3>Value</h3>

<p>a named list containing</p>

<dl>
<dt>median</dt><dd><p>a median matrix on <code class="reqn">\mathcal{M}</code>.</p>
</dd>
<dt>variation</dt><dd><p>sum of (weighted) distances.</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>#-------------------------------------------------------------------
#        Example on Sphere : points near (0,1) on S^1 in R^2
#-------------------------------------------------------------------
## GENERATE DATA
ndata = 50
mydat = array(0,c(ndata,2))
for (i in 1:ndata){
  tgt = c(stats::rnorm(1, sd=2), 1)
  mydat[i,] = tgt/sqrt(sum(tgt^2))
}
myriem = wrap.sphere(mydat)

## COMPUTE TWO MEANS
med.int = as.vector(riem.median(myriem, geometry="intrinsic")$median)
med.ext = as.vector(riem.median(myriem, geometry="extrinsic")$median)

## VISUALIZE
opar &lt;- par(no.readonly=TRUE)
plot(mydat[,1], mydat[,2], pch=19, xlim=c(-1.1,1.1), ylim=c(0,1.1),
     main="BLUE-extrinsic vs RED-intrinsic")
arrows(x0=0,y0=0,x1=med.int[1],y1=med.int[2],col="red")
arrows(x0=0,y0=0,x1=med.ext[1],y1=med.ext[2],col="blue")
par(opar)

</code></pre>

<hr>
<h2 id='riem.nmshift'>Nonlinear Mean Shift</h2><span id='topic+riem.nmshift'></span>

<h3>Description</h3>

<p>Given <code class="reqn">N</code> observations  <code class="reqn">X_1, X_2, \ldots, X_N \in \mathcal{M}</code>, 
perform clustering of the data based on the nonlinear mean shift algorithm. 
Gaussian kernel is used with the bandwidth <code class="reqn">h</code> as of 
</p>
<p style="text-align: center;"><code class="reqn">G(x_i, x_j) \propto \exp \left( - \frac{\rho^2 (x_i,x_j)}{h^2} \right)</code>
</p>

<p>where <code class="reqn">\rho(x,y)</code> is geodesic distance between two points <code class="reqn">x,y\in\mathcal{M}</code>. 
Numerically, some of the limiting points that collapse into the same cluster are 
not exact. For such purpose, we require <code>maxk</code> parameter to search the 
optimal number of clusters based on <code class="reqn">k</code>-medoids clustering algorithm 
in conjunction with silhouette criterion.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>riem.nmshift(riemobj, h = 1, maxk = 5, maxiter = 50, eps = 1e-05)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="riem.nmshift_+3A_riemobj">riemobj</code></td>
<td>
<p>a S3 <code>"riemdata"</code> class for <code class="reqn">N</code> manifold-valued data.</p>
</td></tr>
<tr><td><code id="riem.nmshift_+3A_h">h</code></td>
<td>
<p>bandwidth parameter. The larger the <code class="reqn">h</code> is, the more blurring is applied.</p>
</td></tr>
<tr><td><code id="riem.nmshift_+3A_maxk">maxk</code></td>
<td>
<p>maximum number of clusters to determine the optimal number of clusters.</p>
</td></tr>
<tr><td><code id="riem.nmshift_+3A_maxiter">maxiter</code></td>
<td>
<p>maximum number of iterations to be run.</p>
</td></tr>
<tr><td><code id="riem.nmshift_+3A_eps">eps</code></td>
<td>
<p>tolerance level for stopping criterion.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a named list containing</p>

<dl>
<dt>distance</dt><dd><p>an <code class="reqn">(N\times N)</code> distance between modes corresponding to each data point.</p>
</dd>
<dt>cluster</dt><dd><p>a length-<code class="reqn">N</code> vector of class labels.</p>
</dd>
</dl>



<h3>References</h3>

<p>Subbarao R, Meer P (2009).
&ldquo;Nonlinear Mean Shift over Riemannian Manifolds.&rdquo;
<em>International Journal of Computer Vision</em>, <b>84</b>(1), 1&ndash;20.
ISSN 0920-5691, 1573-1405.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#-------------------------------------------------------------------
#          Example on Sphere : a dataset with three types
#
# class 1 : 10 perturbed data points near (1,0,0) on S^2 in R^3
# class 2 : 10 perturbed data points near (0,1,0) on S^2 in R^3
# class 3 : 10 perturbed data points near (0,0,1) on S^2 in R^3
#-------------------------------------------------------------------
## GENERATE DATA
set.seed(496)
ndata  = 10
mydata = list()
for (i in 1:ndata){
  tgt = c(1, stats::rnorm(2, sd=0.1))
  mydata[[i]] = tgt/sqrt(sum(tgt^2))
}
for (i in (ndata+1):(2*ndata)){
  tgt = c(rnorm(1,sd=0.1),1,rnorm(1,sd=0.1))
  mydata[[i]] = tgt/sqrt(sum(tgt^2))
}
for (i in ((2*ndata)+1):(3*ndata)){
  tgt = c(stats::rnorm(2, sd=0.1), 1)
  mydata[[i]] = tgt/sqrt(sum(tgt^2))
}
myriem = wrap.sphere(mydata)
mylabs = rep(c(1,2,3), each=ndata)

## RUN NONLINEAR MEANSHIFT FOR DIFFERENT 'h' VALUES
run1 = riem.nmshift(myriem, maxk=10, h=0.1)
run2 = riem.nmshift(myriem, maxk=10, h=1)
run3 = riem.nmshift(myriem, maxk=10, h=10)

## MDS FOR VISUALIZATION
mds2d = riem.mds(myriem, ndim=2)$embed

## VISUALIZE
opar &lt;- par(no.readonly=TRUE)
par(mfrow=c(2,3), pty="s")
plot(mds2d, pch=19, main="label : h=0.1", col=run1$cluster)
plot(mds2d, pch=19, main="label : h=1",   col=run2$cluster)
plot(mds2d, pch=19, main="label : h=10",  col=run3$cluster)
image(run1$distance[,30:1], axes=FALSE, main="distance : h=0.1")
image(run2$distance[,30:1], axes=FALSE, main="distance : h=1")
image(run3$distance[,30:1], axes=FALSE, main="distance : h=10")
par(opar)

</code></pre>

<hr>
<h2 id='riem.pdist'>Compute Pairwise Distances for Data</h2><span id='topic+riem.pdist'></span>

<h3>Description</h3>

<p>Given <code class="reqn">N</code> observations <code class="reqn">X_1, X_2, \ldots, X_N \in \mathcal{M}</code>, compute 
pairwise distances.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>riem.pdist(riemobj, geometry = c("intrinsic", "extrinsic"), as.dist = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="riem.pdist_+3A_riemobj">riemobj</code></td>
<td>
<p>a S3 <code>"riemdata"</code> class for <code class="reqn">N</code> manifold-valued data.</p>
</td></tr>
<tr><td><code id="riem.pdist_+3A_geometry">geometry</code></td>
<td>
<p>(case-insensitive) name of geometry; either geodesic (<code>"intrinsic"</code>) or embedded (<code>"extrinsic"</code>) in geometry</p>
</td></tr>
<tr><td><code id="riem.pdist_+3A_as.dist">as.dist</code></td>
<td>
<p>logical; if <code>TRUE</code>, it returns <code>dist</code> object, else it returns a symmetric matrix.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a S3 <code>dist</code> object or <code class="reqn">(N\times N)</code> symmetric matrix of pairwise distances according to <code>as.dist</code> parameter.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#-------------------------------------------------------------------
#          Example on Sphere : a dataset with two types
#
#  group1 : perturbed data points near (0,0,1) on S^2 in R^3
#  group2 : perturbed data points near (1,0,0) on S^2 in R^3
#-------------------------------------------------------------------
## GENERATE DATA
mydata = list()
sdval  = 0.1
for (i in 1:10){
  tgt = c(stats::rnorm(2, sd=sdval), 1)
  mydata[[i]] = tgt/sqrt(sum(tgt^2))
}
for (i in 11:20){
  tgt = c(1, stats::rnorm(2, sd=sdval))
  mydata[[i]] = tgt/sqrt(sum(tgt^2))
}
myriem = wrap.sphere(mydata)

## COMPARE TWO DISTANCES
dint = riem.pdist(myriem, geometry="intrinsic", as.dist=FALSE)
dext = riem.pdist(myriem, geometry="extrinsic", as.dist=FALSE)

## VISUALIZE
opar = par(no.readonly=TRUE)
par(mfrow=c(1,2), pty="s")
image(dint[,nrow(dint):1], main="intrinsic", axes=FALSE)
image(dext[,nrow(dext):1], main="extrinsic", axes=FALSE)
par(opar)

</code></pre>

<hr>
<h2 id='riem.pdist2'>Compute Pairwise Distances for Two Sets of Data</h2><span id='topic+riem.pdist2'></span>

<h3>Description</h3>

<p>Given <code class="reqn">M</code> observations <code class="reqn">X_1, X_2, \ldots, X_M \in \mathcal{M}</code> and 
<code class="reqn">N</code> observations <code class="reqn">Y_1, Y_2, \ldots, Y_N \in \mathcal{M}</code>, 
compute pairwise distances between two sets' elements.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>riem.pdist2(riemobj1, riemobj2, geometry = c("intrinsic", "extrinsic"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="riem.pdist2_+3A_riemobj1">riemobj1</code></td>
<td>
<p>a S3 <code>"riemdata"</code> class for <code class="reqn">M</code> manifold-valued data.</p>
</td></tr>
<tr><td><code id="riem.pdist2_+3A_riemobj2">riemobj2</code></td>
<td>
<p>a S3 <code>"riemdata"</code> class for <code class="reqn">N</code> manifold-valued data.</p>
</td></tr>
<tr><td><code id="riem.pdist2_+3A_geometry">geometry</code></td>
<td>
<p>(case-insensitive) name of geometry; either geodesic (<code>"intrinsic"</code>) or embedded (<code>"extrinsic"</code>) geometry.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>an <code class="reqn">(M\times N)</code> matrix of distances.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
#-------------------------------------------------------------------
#          Example on Sphere : a dataset with two types
#
#  group1 : 10 perturbed data points near (0,0,1) on S^2 in R^3
#  group2 : 10 perturbed data points near (1,0,0) on S^2 in R^3
#           10 perturbed data points near (0,1,0) on S^2 in R^3
#           10 perturbed data points near (0,0,1) on S^2 in R^3
#-------------------------------------------------------------------
## GENERATE DATA
mydata1 = list()
mydata2 = list()
for (i in 1:10){
  tgt = c(stats::rnorm(2, sd=0.1), 1)
  mydata1[[i]] = tgt/sqrt(sum(tgt^2))
}
for (i in 1:10){
  tgt = c(1, stats::rnorm(2, sd=0.1))
  mydata2[[i]] = tgt/sqrt(sum(tgt^2))
}
for (i in 11:20){
  tgt = c(rnorm(1,sd=0.1),1,rnorm(1,sd=0.1))
  mydata2[[i]] = tgt/sqrt(sum(tgt^2))
}
for (i in 21:30){
  tgt = c(stats::rnorm(2, sd=0.1), 1)
  mydata2[[i]] = tgt/sqrt(sum(tgt^2))
}
myriem1 = wrap.sphere(mydata1)
myriem2 = wrap.sphere(mydata2)

## COMPARE TWO DISTANCES
dint = riem.pdist2(myriem1, myriem2, geometry="intrinsic")
dext = riem.pdist2(myriem1, myriem2, geometry="extrinsic")

## VISUALIZE
opar = par(no.readonly=TRUE)
par(mfrow=c(1,2))
image(dint[nrow(dint):1,], main="intrinsic", axes=FALSE)
image(dext[nrow(dext):1,], main="extrinsic", axes=FALSE)
par(opar)


</code></pre>

<hr>
<h2 id='riem.pga'>Principal Geodesic Analysis</h2><span id='topic+riem.pga'></span>

<h3>Description</h3>

<p>Given <code class="reqn">N</code> observations <code class="reqn">X_1, X_2, \ldots, X_N \in \mathcal{M}</code>, 
Principal Geodesic Analysis (PGA) finds a low-dimensional embedding by decomposing 
2nd-order information in tangent space at an intrinsic mean of the data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>riem.pga(riemobj, ndim = 2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="riem.pga_+3A_riemobj">riemobj</code></td>
<td>
<p>a S3 <code>"riemdata"</code> class for <code class="reqn">N</code> manifold-valued data.</p>
</td></tr>
<tr><td><code id="riem.pga_+3A_ndim">ndim</code></td>
<td>
<p>an integer-valued target dimension.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a named list containing </p>

<dl>
<dt>center</dt><dd><p>an intrinsic mean in a matrix representation form.</p>
</dd>
<dt>embed</dt><dd><p>an <code class="reqn">(N\times ndim)</code> matrix whose rows are embedded observations.</p>
</dd>
</dl>



<h3>References</h3>

<p>Fletcher PT, Lu C, Pizer SM, Joshi S (2004).
&ldquo;Principal Geodesic Analysis for the Study of Nonlinear Statistics of Shape.&rdquo;
<em>IEEE Transactions on Medical Imaging</em>, <b>23</b>(8), 995&ndash;1005.
ISSN 0278-0062.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#-------------------------------------------------------------------
#          Example on Sphere : a dataset with three types
#
# 10 perturbed data points near (1,0,0) on S^2 in R^3
# 10 perturbed data points near (0,1,0) on S^2 in R^3
# 10 perturbed data points near (0,0,1) on S^2 in R^3
#-------------------------------------------------------------------
## GENERATE DATA
mydata = list()
for (i in 1:10){
  tgt = c(1, stats::rnorm(2, sd=0.1))
  mydata[[i]] = tgt/sqrt(sum(tgt^2))
}
for (i in 11:20){
  tgt = c(rnorm(1,sd=0.1),1,rnorm(1,sd=0.1))
  mydata[[i]] = tgt/sqrt(sum(tgt^2))
}
for (i in 21:30){
  tgt = c(stats::rnorm(2, sd=0.1), 1)
  mydata[[i]] = tgt/sqrt(sum(tgt^2))
}
myriem = wrap.sphere(mydata)
mylabs = rep(c(1,2,3), each=10)

## EMBEDDING WITH MDS AND PGA
embed2mds = riem.mds(myriem, ndim=2, geometry="intrinsic")$embed
embed2pga = riem.pga(myriem, ndim=2)$embed

## VISUALIZE
opar = par(no.readonly=TRUE)
par(mfrow=c(1,2), pty="s")
plot(embed2mds, main="Multidimensional Scaling",    col=mylabs, pch=19)
plot(embed2pga, main="Principal Geodesic Analysis", col=mylabs, pch=19)
par(opar)

</code></pre>

<hr>
<h2 id='riem.phate'>PHATE</h2><span id='topic+riem.phate'></span>

<h3>Description</h3>

<p>PHATE is a nonlinear manifold learning method that is specifically targeted at 
improving diffusion maps by incorporating data-adaptive kernel construction, 
detection of optimal time scale, and information-theoretic metric measures.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>riem.phate(riemobj, ndim = 2, geometry = c("intrinsic", "extrinsic"), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="riem.phate_+3A_riemobj">riemobj</code></td>
<td>
<p>a S3 <code>"riemdata"</code> class for <code class="reqn">N</code> manifold-valued data.</p>
</td></tr>
<tr><td><code id="riem.phate_+3A_ndim">ndim</code></td>
<td>
<p>an integer-valued target dimension (default: 2).</p>
</td></tr>
<tr><td><code id="riem.phate_+3A_geometry">geometry</code></td>
<td>
<p>(case-insensitive) name of geometry; either geodesic (<code>"intrinsic"</code>) or embedded (<code>"extrinsic"</code>) geometry.</p>
</td></tr>
<tr><td><code id="riem.phate_+3A_...">...</code></td>
<td>
<p>extra parameters for <code>PHATE</code> including </p>

<dl>
<dt>nbdk</dt><dd><p>size of nearest neighborhood (default: 5).</p>
</dd>
<dt>alpha</dt><dd><p>decay parameter for Gaussian kernel exponent (default: 2).</p>
</dd>
<dt>potential</dt><dd><p>type of potential distance transformation; <code>"log"</code> or <code>"sqrt"</code> (default: <code>"log"</code>).</p>
</dd>
</dl>
</td></tr>
</table>


<h3>Value</h3>

<p>a named list containing </p>

<dl>
<dt>embed</dt><dd><p>an <code class="reqn">(N\times ndim)</code> matrix whose rows are embedded observations.</p>
</dd>
</dl>



<h3>References</h3>

<p>Moon KR, van Dijk D, Wang Z, Gigante S, Burkhardt DB, Chen WS, Yim K, van den Elzen A, Hirn MJ, Coifman RR, Ivanova NB, Wolf G, Krishnaswamy S (2019).
&ldquo;Visualizing Structure and Transitions in High-Dimensional Biological Data.&rdquo;
<em>Nature Biotechnology</em>, <b>37</b>(12), 1482&ndash;1492.
ISSN 1087-0156, 1546-1696.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
#-------------------------------------------------------------------
#          Example on Sphere : a dataset with three types
#
# 10 perturbed data points near (1,0,0) on S^2 in R^3
# 10 perturbed data points near (0,1,0) on S^2 in R^3
# 10 perturbed data points near (0,0,1) on S^2 in R^3
#-------------------------------------------------------------------
## GENERATE DATA
mydata = list()
for (i in 1:10){
  tgt = c(1, stats::rnorm(2, sd=0.1))
  mydata[[i]] = tgt/sqrt(sum(tgt^2))
}
for (i in 11:20){
  tgt = c(rnorm(1,sd=0.1),1,rnorm(1,sd=0.1))
  mydata[[i]] = tgt/sqrt(sum(tgt^2))
}
for (i in 21:30){
  tgt = c(stats::rnorm(2, sd=0.1), 1)
  mydata[[i]] = tgt/sqrt(sum(tgt^2))
}
myriem = wrap.sphere(mydata)
mylabs = rep(c(1,2,3), each=10)

## PHATE EMBEDDING WITH LOG &amp; SQRT POTENTIAL 
phate_log  = riem.phate(myriem, potential="log")$embed
phate_sqrt = riem.phate(myriem, potential="sqrt")$embed
embed_mds  = riem.mds(myriem)$embed

## VISUALIZE
opar = par(no.readonly=TRUE)
par(mfrow=c(1,3), pty="s")
plot(embed_mds,  col=mylabs, pch=19, main="MDS" )
plot(phate_log,  col=mylabs, pch=19, main="PHATE+Log")
plot(phate_sqrt, col=mylabs, pch=19, main="PHATE+Sqrt")
par(opar)


</code></pre>

<hr>
<h2 id='riem.rmml'>Riemannian Manifold Metric Learning</h2><span id='topic+riem.rmml'></span>

<h3>Description</h3>

<p>Given <code class="reqn">N</code> observations <code class="reqn">X_1, X_2, \ldots, X_N \in \mathcal{M}</code> and 
corresponding label information, <code>riem.rmml</code> computes pairwise distance of data under Riemannian Manifold Metric Learning 
(RMML) framework based on equivariant embedding. When the number of data points 
is not sufficient, an inverse of scatter matrix does not exist analytically so 
the small regularization parameter <code class="reqn">\lambda</code> is recommended with default value of <code class="reqn">\lambda=0.1</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>riem.rmml(riemobj, label, lambda = 0.1, as.dist = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="riem.rmml_+3A_riemobj">riemobj</code></td>
<td>
<p>a S3 <code>"riemdata"</code> class for <code class="reqn">N</code> manifold-valued data.</p>
</td></tr>
<tr><td><code id="riem.rmml_+3A_label">label</code></td>
<td>
<p>a length-<code class="reqn">N</code> vector of class labels. <code>NA</code> values are omitted.</p>
</td></tr>
<tr><td><code id="riem.rmml_+3A_lambda">lambda</code></td>
<td>
<p>regularization parameter. If <code class="reqn">\lambda \leq 0</code>, no regularization is applied.</p>
</td></tr>
<tr><td><code id="riem.rmml_+3A_as.dist">as.dist</code></td>
<td>
<p>logical; if <code>TRUE</code>, it returns <code>dist</code> object, else it returns a symmetric matrix.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a S3 <code>dist</code> object or <code class="reqn">(N\times N)</code> symmetric matrix of pairwise distances according to <code>as.dist</code> parameter.
</p>


<h3>References</h3>

<p>Zhu P, Cheng H, Hu Q, Wang Q, Zhang C (2018).
&ldquo;Towards Generalized and Efficient Metric Learning on Riemannian Manifold.&rdquo;
In <em>Proceedings of the Twenty-Seventh International Joint Conference on Artificial Intelligence</em>, 3235&ndash;3241.
ISBN 978-0-9992411-2-7.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#-------------------------------------------------------------------
#            Distance between Two Classes of SPD Matrices
#
#  Class 1 : Empirical Covariance from Standard Normal Distribution
#  Class 2 : Empirical Covariance from Perturbed 'iris' dataset
#-------------------------------------------------------------------
## DATA GENERATION
data(iris)
ndata  = 10
mydata = list()
for (i in 1:ndata){
  mydata[[i]] = stats::cov(matrix(rnorm(100*4),ncol=4))
}
for (i in (ndata+1):(2*ndata)){
  tmpdata = as.matrix(iris[,1:4]) + matrix(rnorm(150*4,sd=0.5),ncol=4)
  mydata[[i]] = stats::cov(tmpdata)
}
myriem = wrap.spd(mydata)
mylabs = rep(c(1,2), each=ndata)

## COMPUTE GEODESIC AND RMML PAIRWISE DISTANCE
pdgeo = riem.pdist(myriem)
pdmdl = riem.rmml(myriem, label=mylabs)

## VISUALIZE
opar = par(no.readonly=TRUE)
par(mfrow=c(1,2), pty="s")
image(pdgeo[,(2*ndata):1], main="geodesic distance", axes=FALSE)
image(pdmdl[,(2*ndata):1], main="RMML distance", axes=FALSE)
par(opar)

</code></pre>

<hr>
<h2 id='riem.sammon'>Sammon Mapping</h2><span id='topic+riem.sammon'></span>

<h3>Description</h3>

<p>Given <code class="reqn">N</code> observations <code class="reqn">X_1, X_2, \ldots, X_N \in \mathcal{M}</code>, 
apply Sammon mapping, a non-linear dimensionality reduction method. Since 
the method depends only on the pairwise distances of the data, it can be 
adapted to the manifold-valued data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>riem.sammon(riemobj, ndim = 2, geometry = c("intrinsic", "extrinsic"), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="riem.sammon_+3A_riemobj">riemobj</code></td>
<td>
<p>a S3 <code>"riemdata"</code> class for <code class="reqn">N</code> manifold-valued data.</p>
</td></tr>
<tr><td><code id="riem.sammon_+3A_ndim">ndim</code></td>
<td>
<p>an integer-valued target dimension (default: 2).</p>
</td></tr>
<tr><td><code id="riem.sammon_+3A_geometry">geometry</code></td>
<td>
<p>(case-insensitive) name of geometry; either geodesic (<code>"intrinsic"</code>) or embedded (<code>"extrinsic"</code>) geometry.</p>
</td></tr>
<tr><td><code id="riem.sammon_+3A_...">...</code></td>
<td>
<p>extra parameters including</p>

<dl>
<dt>maxiter</dt><dd><p>maximum number of iterations to be run (default:50).</p>
</dd>
<dt>eps</dt><dd><p>tolerance level for stopping criterion (default: 1e-5).</p>
</dd>
</dl>
</td></tr>
</table>


<h3>Value</h3>

<p>a named list containing </p>

<dl>
<dt>embed</dt><dd><p>an <code class="reqn">(N\times ndim)</code> matrix whose rows are embedded observations.</p>
</dd>
<dt>stress</dt><dd><p>discrepancy between embedded and original distances as a measure of error.</p>
</dd>
</dl>



<h3>References</h3>

<p>Sammon JW (1969).
&ldquo;A Nonlinear Mapping for Data Structure Analysis.&rdquo;
<em>IEEE Transactions on Computers</em>, <b>C-18</b>(5), 401&ndash;409.
ISSN 0018-9340.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#-------------------------------------------------------------------
#          Example on Sphere : a dataset with three types
#
# 10 perturbed data points near (1,0,0) on S^2 in R^3
# 10 perturbed data points near (0,1,0) on S^2 in R^3
# 10 perturbed data points near (0,0,1) on S^2 in R^3
#-------------------------------------------------------------------
## GENERATE DATA
mydata = list()
for (i in 1:10){
  tgt = c(1, stats::rnorm(2, sd=0.1))
  mydata[[i]] = tgt/sqrt(sum(tgt^2))
}
for (i in 11:20){
  tgt = c(rnorm(1,sd=0.1),1,rnorm(1,sd=0.1))
  mydata[[i]] = tgt/sqrt(sum(tgt^2))
}
for (i in 21:30){
  tgt = c(stats::rnorm(2, sd=0.1), 1)
  mydata[[i]] = tgt/sqrt(sum(tgt^2))
}
myriem = wrap.sphere(mydata)
mylabs = rep(c(1,2,3), each=10)

## COMPARE SAMMON WITH MDS
embed2mds = riem.mds(myriem, ndim=2)$embed
embed2sam = riem.sammon(myriem, ndim=2)$embed

## VISUALIZE
opar = par(no.readonly=TRUE)
par(mfrow=c(1,2), pty="s")
plot(embed2mds, col=mylabs, pch=19, main="MDS")
plot(embed2sam, col=mylabs, pch=19, main="Sammon mapping")
par(opar)

</code></pre>

<hr>
<h2 id='riem.sc05Z'>Spectral Clustering by Zelnik-Manor and Perona (2005)</h2><span id='topic+riem.sc05Z'></span>

<h3>Description</h3>

<p>Zelnik-Manor and Perona proposed a method to define a set of data-driven 
bandwidth parameters where <code class="reqn">\sigma_i</code> is the distance from a point <code class="reqn">x_i</code> to its <code>nnbd</code>-th 
nearest neighbor. Then the affinity matrix is defined as
</p>
<p style="text-align: center;"><code class="reqn">A_{ij} = \exp(-d(x_i, d_j)^2 / \sigma_i \sigma_j)</code>
</p>
<p> and the standard 
spectral clustering of Ng, Jordan, and Weiss (<code><a href="#topic+riem.scNJW">riem.scNJW</a></code>) is applied.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>riem.sc05Z(riemobj, k = 2, nnbd = 7, geometry = c("intrinsic", "extrinsic"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="riem.sc05Z_+3A_riemobj">riemobj</code></td>
<td>
<p>a S3 <code>"riemdata"</code> class for <code class="reqn">N</code> manifold-valued data.</p>
</td></tr>
<tr><td><code id="riem.sc05Z_+3A_k">k</code></td>
<td>
<p>the number of clusters (default: 2).</p>
</td></tr>
<tr><td><code id="riem.sc05Z_+3A_nnbd">nnbd</code></td>
<td>
<p>neighborhood size to define data-driven bandwidth parameter (default: 7).</p>
</td></tr>
<tr><td><code id="riem.sc05Z_+3A_geometry">geometry</code></td>
<td>
<p>(case-insensitive) name of geometry; either geodesic (<code>"intrinsic"</code>) or embedded (<code>"extrinsic"</code>) geometry.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a named list containing 
</p>

<dl>
<dt>cluster</dt><dd><p>a length-<code class="reqn">N</code> vector of class labels (from <code class="reqn">1:k</code>).</p>
</dd> 
<dt>eigval</dt><dd><p>eigenvalues of the graph laplacian's spectral decomposition.</p>
</dd>
<dt>embeds</dt><dd><p>an <code class="reqn">(N\times k)</code> low-dimensional embedding.</p>
</dd>
</dl>



<h3>References</h3>

<p>Zelnik-manor L, Perona P (2005). &quot;Self-Tuning Spectral Clustering.&quot; In Saul LK, Weiss Y, Bottou L (eds.), <em>Advances in Neural Information Processing Systems 17</em>, 1601–1608. MIT Press.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#-------------------------------------------------------------------
#          Example on Sphere : a dataset with three types
#
# class 1 : 10 perturbed data points near (1,0,0) on S^2 in R^3
# class 2 : 10 perturbed data points near (0,1,0) on S^2 in R^3
# class 3 : 10 perturbed data points near (0,0,1) on S^2 in R^3
#-------------------------------------------------------------------
## GENERATE DATA
mydata = list()
for (i in 1:10){
  tgt = c(1, stats::rnorm(2, sd=0.1))
  mydata[[i]] = tgt/sqrt(sum(tgt^2))
}
for (i in 11:20){
  tgt = c(rnorm(1,sd=0.1),1,rnorm(1,sd=0.1))
  mydata[[i]] = tgt/sqrt(sum(tgt^2))
}
for (i in 21:30){
  tgt = c(stats::rnorm(2, sd=0.1), 1)
  mydata[[i]] = tgt/sqrt(sum(tgt^2))
}
myriem = wrap.sphere(mydata)
lab    = rep(c(1,2,3), each=10)

## CLUSTERING WITH DIFFERENT K VALUES
cl2 = riem.sc05Z(myriem, k=2)$cluster
cl3 = riem.sc05Z(myriem, k=3)$cluster
cl4 = riem.sc05Z(myriem, k=4)$cluster

## MDS FOR VISUALIZATION
mds2d = riem.mds(myriem, ndim=2)$embed

## VISUALIZE
opar &lt;- par(no.readonly=TRUE)
par(mfrow=c(1,4), pty="s")
plot(mds2d, col=lab, pch=19, main="true label")
plot(mds2d, col=cl2, pch=19, main="riem.sc05Z: k=2")
plot(mds2d, col=cl3, pch=19, main="riem.sc05Z: k=3")
plot(mds2d, col=cl4, pch=19, main="riem.sc05Z: k=4")
par(opar)

</code></pre>

<hr>
<h2 id='riem.scNJW'>Spectral Clustering by Ng, Jordan, and Weiss (2002)</h2><span id='topic+riem.scNJW'></span>

<h3>Description</h3>

<p>The version of Ng, Jordan, and Weiss first constructs the affinity matrix
</p>
<p style="text-align: center;"><code class="reqn">A_{ij} = \exp(-d(x_i, d_j)^2 / \sigma^2)</code>
</p>

<p>where <code class="reqn">\sigma</code> is a common bandwidth parameter and performs k-means clustering on 
the row-space of eigenvectors for the symmetric graph laplacian matrix
</p>
<p style="text-align: center;"><code class="reqn">L=D^{-1/2}(D-A)D^{-1/2}</code>
</p>
<p>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>riem.scNJW(riemobj, k = 2, sigma = 1, geometry = c("intrinsic", "extrinsic"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="riem.scNJW_+3A_riemobj">riemobj</code></td>
<td>
<p>a S3 <code>"riemdata"</code> class for <code class="reqn">N</code> manifold-valued data.</p>
</td></tr>
<tr><td><code id="riem.scNJW_+3A_k">k</code></td>
<td>
<p>the number of clusters (default: 2).</p>
</td></tr>
<tr><td><code id="riem.scNJW_+3A_sigma">sigma</code></td>
<td>
<p>bandwidth parameter (default: 1).</p>
</td></tr>
<tr><td><code id="riem.scNJW_+3A_geometry">geometry</code></td>
<td>
<p>(case-insensitive) name of geometry; either geodesic (<code>"intrinsic"</code>) or embedded (<code>"extrinsic"</code>) geometry.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a named list containing 
</p>

<dl>
<dt>cluster</dt><dd><p>a length-<code class="reqn">N</code> vector of class labels (from <code class="reqn">1:k</code>).</p>
</dd> 
<dt>eigval</dt><dd><p>eigenvalues of the graph laplacian's spectral decomposition.</p>
</dd>
<dt>embeds</dt><dd><p>an <code class="reqn">(N\times k)</code> low-dimensional embedding.</p>
</dd>
</dl>



<h3>References</h3>

<p>Ng AY, Jordan MI, Weiss Y (2002). &quot;On Spectral Clustering: Analysis and an Algorithm.&quot; In Dietterich TG, Becker S, Ghahramani Z (eds.), <em>Advances in Neural Information Processing Systems 14</em>, 849–856. MIT Press.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#-------------------------------------------------------------------
#          Example on Sphere : a dataset with three types
#
# class 1 : 10 perturbed data points near (1,0,0) on S^2 in R^3
# class 2 : 10 perturbed data points near (0,1,0) on S^2 in R^3
# class 3 : 10 perturbed data points near (0,0,1) on S^2 in R^3
#-------------------------------------------------------------------
## GENERATE DATA
mydata = list()
for (i in 1:10){
  tgt = c(1, stats::rnorm(2, sd=0.1))
  mydata[[i]] = tgt/sqrt(sum(tgt^2))
}
for (i in 11:20){
  tgt = c(rnorm(1,sd=0.1),1,rnorm(1,sd=0.1))
  mydata[[i]] = tgt/sqrt(sum(tgt^2))
}
for (i in 21:30){
  tgt = c(stats::rnorm(2, sd=0.1), 1)
  mydata[[i]] = tgt/sqrt(sum(tgt^2))
}
myriem = wrap.sphere(mydata)
lab    = rep(c(1,2,3), each=10)

## CLUSTERING WITH DIFFERENT K VALUES
cl2 = riem.scNJW(myriem, k=2)$cluster
cl3 = riem.scNJW(myriem, k=3)$cluster
cl4 = riem.scNJW(myriem, k=4)$cluster

## MDS FOR VISUALIZATION
mds2d = riem.mds(myriem, ndim=2)$embed

## VISUALIZE
opar &lt;- par(no.readonly=TRUE)
par(mfrow=c(1,4), pty="s")
plot(mds2d, col=lab, pch=19, main="true label")
plot(mds2d, col=cl2, pch=19, main="riem.scNJW: k=2")
plot(mds2d, col=cl3, pch=19, main="riem.scNJW: k=3")
plot(mds2d, col=cl4, pch=19, main="riem.scNJW: k=4")
par(opar)

</code></pre>

<hr>
<h2 id='riem.scSM'>Spectral Clustering by Shi and Malik (2000)</h2><span id='topic+riem.scSM'></span>

<h3>Description</h3>

<p>The version of Shi and Malik first constructs the affinity matrix
</p>
<p style="text-align: center;"><code class="reqn">A_{ij} = \exp(-d(x_i, d_j)^2 / \sigma^2)</code>
</p>

<p>where <code class="reqn">\sigma</code> is a common bandwidth parameter and performs k-means clustering on 
the row-space of eigenvectors for the random-walk graph laplacian matrix
</p>
<p style="text-align: center;"><code class="reqn">L=D^{-1}(D-A)</code>
</p>
<p>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>riem.scSM(riemobj, k = 2, sigma = 1, geometry = c("intrinsic", "extrinsic"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="riem.scSM_+3A_riemobj">riemobj</code></td>
<td>
<p>a S3 <code>"riemdata"</code> class for <code class="reqn">N</code> manifold-valued data.</p>
</td></tr>
<tr><td><code id="riem.scSM_+3A_k">k</code></td>
<td>
<p>the number of clusters (default: 2).</p>
</td></tr>
<tr><td><code id="riem.scSM_+3A_sigma">sigma</code></td>
<td>
<p>bandwidth parameter (default: 1).</p>
</td></tr>
<tr><td><code id="riem.scSM_+3A_geometry">geometry</code></td>
<td>
<p>(case-insensitive) name of geometry; either geodesic (<code>"intrinsic"</code>) or embedded (<code>"extrinsic"</code>) geometry.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a named list containing 
</p>

<dl>
<dt>cluster</dt><dd><p>a length-<code class="reqn">N</code> vector of class labels (from <code class="reqn">1:k</code>).</p>
</dd> 
<dt>eigval</dt><dd><p>eigenvalues of the graph laplacian's spectral decomposition.</p>
</dd>
<dt>embeds</dt><dd><p>an <code class="reqn">(N\times k)</code> low-dimensional embedding.</p>
</dd>
</dl>



<h3>References</h3>

<p>Shi J, Malik J (2000). “Normalized Cuts and Image Segmentation.&quot; <em>IEEE Transactions on Pattern Analysis and Machine Intelligence</em>, 22(8):888–905.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#-------------------------------------------------------------------
#          Example on Sphere : a dataset with three types
#
# class 1 : 10 perturbed data points near (1,0,0) on S^2 in R^3
# class 2 : 10 perturbed data points near (0,1,0) on S^2 in R^3
# class 3 : 10 perturbed data points near (0,0,1) on S^2 in R^3
#-------------------------------------------------------------------
## GENERATE DATA
mydata = list()
for (i in 1:10){
  tgt = c(1, stats::rnorm(2, sd=0.1))
  mydata[[i]] = tgt/sqrt(sum(tgt^2))
}
for (i in 11:20){
  tgt = c(rnorm(1,sd=0.1),1,rnorm(1,sd=0.1))
  mydata[[i]] = tgt/sqrt(sum(tgt^2))
}
for (i in 21:30){
  tgt = c(stats::rnorm(2, sd=0.1), 1)
  mydata[[i]] = tgt/sqrt(sum(tgt^2))
}
myriem = wrap.sphere(mydata)
lab    = rep(c(1,2,3), each=10)

## CLUSTERING WITH DIFFERENT K VALUES
cl2 = riem.scSM(myriem, k=2)$cluster
cl3 = riem.scSM(myriem, k=3)$cluster
cl4 = riem.scSM(myriem, k=4)$cluster

## MDS FOR VISUALIZATION
mds2d = riem.mds(myriem, ndim=2)$embed

## VISUALIZE
opar &lt;- par(no.readonly=TRUE)
par(mfrow=c(1,4), pty="s")
plot(mds2d, col=lab, pch=19, main="true label")
plot(mds2d, col=cl2, pch=19, main="riem.scSM: k=2")
plot(mds2d, col=cl3, pch=19, main="riem.scSM: k=3")
plot(mds2d, col=cl4, pch=19, main="riem.scSM: k=4")
par(opar)

</code></pre>

<hr>
<h2 id='riem.scUL'>Spectral Clustering with Unnormalized Laplacian</h2><span id='topic+riem.scUL'></span>

<h3>Description</h3>

<p>The version of Shi and Malik first constructs the affinity matrix
</p>
<p style="text-align: center;"><code class="reqn">A_{ij} = \exp(-d(x_i, d_j)^2 / \sigma^2)</code>
</p>

<p>where <code class="reqn">\sigma</code> is a common bandwidth parameter and performs k-means clustering on 
the row-space of eigenvectors for the unnormalized graph laplacian matrix
</p>
<p style="text-align: center;"><code class="reqn">L=D-A</code>
</p>
<p>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>riem.scUL(riemobj, k = 2, sigma = 1, geometry = c("intrinsic", "extrinsic"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="riem.scUL_+3A_riemobj">riemobj</code></td>
<td>
<p>a S3 <code>"riemdata"</code> class for <code class="reqn">N</code> manifold-valued data.</p>
</td></tr>
<tr><td><code id="riem.scUL_+3A_k">k</code></td>
<td>
<p>the number of clusters (default: 2).</p>
</td></tr>
<tr><td><code id="riem.scUL_+3A_sigma">sigma</code></td>
<td>
<p>bandwidth parameter (default: 1).</p>
</td></tr>
<tr><td><code id="riem.scUL_+3A_geometry">geometry</code></td>
<td>
<p>(case-insensitive) name of geometry; either geodesic (<code>"intrinsic"</code>) or embedded (<code>"extrinsic"</code>) geometry.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a named list containing 
</p>

<dl>
<dt>cluster</dt><dd><p>a length-<code class="reqn">N</code> vector of class labels (from <code class="reqn">1:k</code>).</p>
</dd> 
<dt>eigval</dt><dd><p>eigenvalues of the graph laplacian's spectral decomposition.</p>
</dd>
<dt>embeds</dt><dd><p>an <code class="reqn">(N\times k)</code> low-dimensional embedding.</p>
</dd>
</dl>



<h3>References</h3>

<p>von Luxburg U (2007). “A Tutorial on Spectral Clustering.” <em>Statistics and Computing</em>, 17(4):395–416.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#-------------------------------------------------------------------
#          Example on Sphere : a dataset with three types
#
# class 1 : 10 perturbed data points near (1,0,0) on S^2 in R^3
# class 2 : 10 perturbed data points near (0,1,0) on S^2 in R^3
# class 3 : 10 perturbed data points near (0,0,1) on S^2 in R^3
#-------------------------------------------------------------------
## GENERATE DATA
mydata = list()
for (i in 1:10){
  tgt = c(1, stats::rnorm(2, sd=0.1))
  mydata[[i]] = tgt/sqrt(sum(tgt^2))
}
for (i in 11:20){
  tgt = c(rnorm(1,sd=0.1),1,rnorm(1,sd=0.1))
  mydata[[i]] = tgt/sqrt(sum(tgt^2))
}
for (i in 21:30){
  tgt = c(stats::rnorm(2, sd=0.1), 1)
  mydata[[i]] = tgt/sqrt(sum(tgt^2))
}
myriem = wrap.sphere(mydata)
lab    = rep(c(1,2,3), each=10)

## CLUSTERING WITH DIFFERENT K VALUES
cl2 = riem.scUL(myriem, k=2)$cluster
cl3 = riem.scUL(myriem, k=3)$cluster
cl4 = riem.scUL(myriem, k=4)$cluster

## MDS FOR VISUALIZATION
mds2d = riem.mds(myriem, ndim=2)$embed

## VISUALIZE
opar &lt;- par(no.readonly=TRUE)
par(mfrow=c(1,4), pty="s")
plot(mds2d, col=lab, pch=19, main="true label")
plot(mds2d, col=cl2, pch=19, main="riem.scUL: k=2")
plot(mds2d, col=cl3, pch=19, main="riem.scUL: k=3")
plot(mds2d, col=cl4, pch=19, main="riem.scUL: k=4")
par(opar)

</code></pre>

<hr>
<h2 id='riem.seb'>Find the Smallest Enclosing Ball</h2><span id='topic+riem.seb'></span>

<h3>Description</h3>

<p>Given <code class="reqn">N</code> observations <code class="reqn">X_1, X_2, \ldots, X_N \in \mathcal{M}</code>, find the smallest enclosing ball.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>riem.seb(riemobj, method = c("aa2013"), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="riem.seb_+3A_riemobj">riemobj</code></td>
<td>
<p>a S3 <code>"riemdata"</code> class for <code class="reqn">N</code> manifold-valued data.</p>
</td></tr>
<tr><td><code id="riem.seb_+3A_method">method</code></td>
<td>
<p>(case-insensitive) name of the algorithm to be used as follows;</p>

<dl>
<dt><code>"aa2013"</code></dt><dd><p>Arnaudon and Nielsen (2013).</p>
</dd>
</dl>
</td></tr>
<tr><td><code id="riem.seb_+3A_...">...</code></td>
<td>
<p>extra parameters including</p>

<dl>
<dt>maxiter</dt><dd><p>maximum number of iterations to be run (default:50).</p>
</dd>
<dt>eps</dt><dd><p>tolerance level for stopping criterion (default: 1e-5).</p>
</dd>
</dl>
</td></tr>
</table>


<h3>Value</h3>

<p>a named list containing </p>

<dl>
<dt>center</dt><dd><p>a matrix on <code class="reqn">\mathcal{M}</code> that minimizes the radius.</p>
</dd>
<dt>radius</dt><dd><p>the minimal radius with respect to the <code>center</code>.</p>
</dd>
</dl>



<h3>References</h3>

<p>Bâdoiu M, Clarkson KL (2003).
&ldquo;Smaller core-sets for balls.&rdquo;
In <em>Proceedings of the fourteenth annual ACM-SIAM symposium on discrete algorithms</em>,  SODA '03, 801&ndash;802.
ISBN 0-89871-538-5.
</p>
<p>Arnaudon M, Nielsen F (2013).
&ldquo;On approximating the Riemannian 1-center.&rdquo;
<em>Computational Geometry</em>, <b>46</b>(1), 93&ndash;104.
ISSN 09257721.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#-------------------------------------------------------------------
#       Euclidean Example : samples from Standard Normal in R^2
#-------------------------------------------------------------------
## GENERATE 25 OBSERVATIONS FROM N(0,I)
ndata  = 25
mymats = array(0,c(ndata, 2))
mydata = list()
for (i in 1:ndata){
  mydata[[i]] = stats::rnorm(2)
  mymats[i,]  = mydata[[i]]
}
myriem = wrap.euclidean(mydata)

## COMPUTE
sebobj = riem.seb(myriem)
center = as.vector(sebobj$center) 
radius = sebobj$radius

## VISUALIZE
#  1. prepare the circle for drawing
theta  = seq(from=0, to=2*pi, length.out=100)
coords = radius*cbind(cos(theta), sin(theta))
coords = coords + matrix(rep(center, each=100), ncol=2)

#  2. draw
opar &lt;- par(no.readonly=TRUE)
par(pty="s")
plot(coords, type="l", lwd=2, col="red",
     main="Euclidean SEB", xlab="x", ylab="y")
points(mymats, pch=19)                           # data
points(center[1], center[2], pch=19, col="blue") # center 
par(opar)

</code></pre>

<hr>
<h2 id='riem.test2bg14'>Two-Sample Test modified from Biswas and Ghosh (2014)</h2><span id='topic+riem.test2bg14'></span>

<h3>Description</h3>

<p>Given <code class="reqn">M</code> observations <code class="reqn">X_1, X_2, \ldots, X_M \in \mathcal{M}</code> and 
<code class="reqn">N</code> observations <code class="reqn">Y_1, Y_2, \ldots, Y_N \in \mathcal{M}</code>, perform the permutation test of equal distribution
</p>
<p style="text-align: center;"><code class="reqn">H_0~:~\mathcal{P}_X = \mathcal{P}_Y</code>
</p>

<p>by the method from Biswas and Ghosh (2014). The method, originally proposed 
for Euclidean-valued data, is adapted to the general Riemannian manifold 
with intrinsic/extrinsic distance.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>riem.test2bg14(riemobj1, riemobj2, geometry = c("intrinsic", "extrinsic"), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="riem.test2bg14_+3A_riemobj1">riemobj1</code></td>
<td>
<p>a S3 <code>"riemdata"</code> class for <code class="reqn">M</code> manifold-valued data.</p>
</td></tr>
<tr><td><code id="riem.test2bg14_+3A_riemobj2">riemobj2</code></td>
<td>
<p>a S3 <code>"riemdata"</code> class for <code class="reqn">N</code> manifold-valued data.</p>
</td></tr>
<tr><td><code id="riem.test2bg14_+3A_geometry">geometry</code></td>
<td>
<p>(case-insensitive) name of geometry; either geodesic (<code>"intrinsic"</code>) or embedded (<code>"extrinsic"</code>) geometry.</p>
</td></tr>
<tr><td><code id="riem.test2bg14_+3A_...">...</code></td>
<td>
<p>extra parameters including</p>

<dl>
<dt>nperm</dt><dd><p>the number of permutations (default: 999).</p>
</dd>
</dl>
</td></tr>
</table>


<h3>Value</h3>

<p>a (list) object of <code>S3</code> class <code>htest</code> containing: </p>

<dl>
<dt>statistic</dt><dd><p>a test statistic.</p>
</dd>
<dt>p.value</dt><dd><p><code class="reqn">p</code>-value under <code class="reqn">H_0</code>.</p>
</dd>
<dt>alternative</dt><dd><p>alternative hypothesis.</p>
</dd>
<dt>method</dt><dd><p>name of the test.</p>
</dd>
<dt>data.name</dt><dd><p>name(s) of provided sample data.</p>
</dd>
</dl>



<h3>References</h3>

<p>Biswas M, Ghosh AK (2014).
&ldquo;A nonparametric two-sample test applicable to high dimensional data.&rdquo;
<em>Journal of Multivariate Analysis</em>, <b>123</b>, 160&ndash;171.
ISSN 0047259X.
</p>
<p>You K, Park H (2020).
&ldquo;Re-visiting Riemannian geometry of symmetric positive definite matrices for the analysis of functional connectivity.&rdquo;
<em>NeuroImage</em>, 117464.
ISSN 10538119.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#-------------------------------------------------------------------
#          Example on Sphere : a dataset with two types
#
# class 1 : 20 perturbed data points near (1,0,0) on S^2 in R^3
# class 2 : 30 perturbed data points near (0,1,0) on S^2 in R^3
#-------------------------------------------------------------------
## GENERATE DATA
mydata1 = list()
mydata2 = list()
for (i in 1:20){
  tgt = c(1, stats::rnorm(2, sd=0.1))
  mydata1[[i]] = tgt/sqrt(sum(tgt^2))
}
for (i in 1:20){
  tgt = c(rnorm(1,sd=0.1),1,rnorm(1,sd=0.1))
  mydata2[[i]] = tgt/sqrt(sum(tgt^2))
}
myriem1 = wrap.sphere(mydata1)
myriem2 = wrap.sphere(mydata2)

## PERFORM PERMUTATION TEST
#  it is expected to return a very small number.

riem.test2bg14(myriem1, myriem2, nperm=999)


## Not run: 
## CHECK WITH EMPIRICAL TYPE-1 ERROR
set.seed(777)
ntest = 1000
pvals = rep(0,ntest)

for (i in 1:ntest){
  X = cbind(matrix(rnorm(30*2, sd=0.1),ncol=2), rep(1,30))
  Y = cbind(matrix(rnorm(30*2, sd=0.1),ncol=2), rep(1,30))
  Xnorm = X/sqrt(rowSums(X^2))
  Ynorm = Y/sqrt(rowSums(Y^2))
  
  Xriem = wrap.sphere(Xnorm)
  Yriem = wrap.sphere(Ynorm)
  pvals[i] = riem.test2bg14(Xriem, Yriem, nperm=999)$p.value
}

emperr = round(sum((pvals &lt;= 0.05))/ntest, 5)
print(paste0("* EMPIRICAL TYPE-1 ERROR=", emperr))

## End(Not run)

</code></pre>

<hr>
<h2 id='riem.test2wass'>Two-Sample Test with Wasserstein Metric</h2><span id='topic+riem.test2wass'></span>

<h3>Description</h3>

<p>Given <code class="reqn">M</code> observations <code class="reqn">X_1, X_2, \ldots, X_M \in \mathcal{M}</code> and 
<code class="reqn">N</code> observations <code class="reqn">Y_1, Y_2, \ldots, Y_N \in \mathcal{M}</code>, permutation 
test based on the Wasserstein metric (see <code><a href="#topic+riem.wasserstein">riem.wasserstein</a></code> for 
more details) is applied to test whether two distributions are same or not, i.e.,
</p>
<p style="text-align: center;"><code class="reqn">H_0~:~\mathcal{P}_X = \mathcal{P}_Y</code>
</p>

<p>with Wasserstein metric <code class="reqn">\mathcal{W}_p</code> being the measure of discrepancy 
between two samples.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>riem.test2wass(
  riemobj1,
  riemobj2,
  p = 2,
  geometry = c("intrinsic", "extrinsic"),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="riem.test2wass_+3A_riemobj1">riemobj1</code></td>
<td>
<p>a S3 <code>"riemdata"</code> class for <code class="reqn">M</code> manifold-valued data.</p>
</td></tr>
<tr><td><code id="riem.test2wass_+3A_riemobj2">riemobj2</code></td>
<td>
<p>a S3 <code>"riemdata"</code> class for <code class="reqn">N</code> manifold-valued data.</p>
</td></tr>
<tr><td><code id="riem.test2wass_+3A_p">p</code></td>
<td>
<p>an exponent for Wasserstein distance <code class="reqn">\mathcal{W}_p</code> (default: 2).</p>
</td></tr>
<tr><td><code id="riem.test2wass_+3A_geometry">geometry</code></td>
<td>
<p>(case-insensitive) name of geometry; either geodesic (<code>"intrinsic"</code>) or embedded (<code>"extrinsic"</code>) geometry.</p>
</td></tr>
<tr><td><code id="riem.test2wass_+3A_...">...</code></td>
<td>
<p>extra parameters including</p>

<dl>
<dt>nperm</dt><dd><p>the number of permutations (default: 999).</p>
</dd>
<dt>use.smooth</dt><dd><p>a logical; <code>TRUE</code> to use a smoothed Wasserstein distance, <code>FALSE</code> otherwise.</p>
</dd>
</dl>
</td></tr>
</table>


<h3>Value</h3>

<p>a (list) object of <code>S3</code> class <code>htest</code> containing: </p>

<dl>
<dt>statistic</dt><dd><p>a test statistic.</p>
</dd>
<dt>p.value</dt><dd><p><code class="reqn">p</code>-value under <code class="reqn">H_0</code>.</p>
</dd>
<dt>alternative</dt><dd><p>alternative hypothesis.</p>
</dd>
<dt>method</dt><dd><p>name of the test.</p>
</dd>
<dt>data.name</dt><dd><p>name(s) of provided sample data.</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>#-------------------------------------------------------------------
#          Example on Sphere : a dataset with two types
#
# class 1 : 20 perturbed data points near (1,0,0) on S^2 in R^3
# class 2 : 30 perturbed data points near (0,1,0) on S^2 in R^3
#-------------------------------------------------------------------
## GENERATE DATA
mydata1 = list()
mydata2 = list()
for (i in 1:20){
  tgt = c(1, stats::rnorm(2, sd=0.1))
  mydata1[[i]] = tgt/sqrt(sum(tgt^2))
}
for (i in 1:20){
  tgt = c(rnorm(1,sd=0.1),1,rnorm(1,sd=0.1))
  mydata2[[i]] = tgt/sqrt(sum(tgt^2))
}
myriem1 = wrap.sphere(mydata1)
myriem2 = wrap.sphere(mydata2)

## PERFORM PERMUTATION TEST
#  it is expected to return a very small number, but 
#  small number of 'nperm' may not give a reasonable p-value.

riem.test2wass(myriem1, myriem2, nperm=99, use.smooth=FALSE)


## Not run: 
## CHECK WITH EMPIRICAL TYPE-1 ERROR
set.seed(777)
ntest = 1000
pvals = rep(0,ntest)

for (i in 1:ntest){
  X = cbind(matrix(rnorm(30*2, sd=0.1),ncol=2), rep(1,30))
  Y = cbind(matrix(rnorm(30*2, sd=0.1),ncol=2), rep(1,30))
  Xnorm = X/sqrt(rowSums(X^2))
  Ynorm = Y/sqrt(rowSums(Y^2))
  
  Xriem = wrap.sphere(Xnorm)
  Yriem = wrap.sphere(Ynorm)
  pvals[i] = riem.test2wass(Xriem, Yriem, nperm=999)$p.value
  print(paste0("iteration ",i,"/",ntest," complete.."))
}

emperr = round(sum((pvals &lt;= 0.05))/ntest, 5)
print(paste0("* EMPIRICAL TYPE-1 ERROR=", emperr))

## End(Not run)

</code></pre>

<hr>
<h2 id='riem.tsne'>t-distributed Stochastic Neighbor Embedding</h2><span id='topic+riem.tsne'></span>

<h3>Description</h3>

<p>Given <code class="reqn">N</code> observations <code class="reqn">X_1, X_2, \ldots, X_N \in \mathcal{M}</code>, 
t-SNE mimicks the pattern of probability distributions over pairs of manifold-valued 
objects on low-dimensional target embedding space by minimizing Kullback-Leibler divergence.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>riem.tsne(riemobj, ndim = 2, geometry = c("intrinsic", "extrinsic"), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="riem.tsne_+3A_riemobj">riemobj</code></td>
<td>
<p>a S3 <code>"riemdata"</code> class for <code class="reqn">N</code> manifold-valued data.</p>
</td></tr>
<tr><td><code id="riem.tsne_+3A_ndim">ndim</code></td>
<td>
<p>an integer-valued target dimension.</p>
</td></tr>
<tr><td><code id="riem.tsne_+3A_geometry">geometry</code></td>
<td>
<p>(case-insensitive) name of geometry; either geodesic (<code>"intrinsic"</code>) or embedded (<code>"extrinsic"</code>) geometry.</p>
</td></tr>
<tr><td><code id="riem.tsne_+3A_...">...</code></td>
<td>
<p>extra parameters for <code>Rtsne</code> algorithm from <span class="pkg">Rtsne</span> package, such as perplexity, momentum, and others.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a named list containing </p>

<dl>
<dt>embed</dt><dd><p>an <code class="reqn">(N\times ndim)</code> matrix whose rows are embedded observations.</p>
</dd>
<dt>stress</dt><dd><p>discrepancy between embedded and original distances as a measure of error.</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>#-------------------------------------------------------------------
#          Example on Sphere : a dataset with three types
#
# 10 perturbed data points near (1,0,0) on S^2 in R^3
# 10 perturbed data points near (0,1,0) on S^2 in R^3
# 10 perturbed data points near (0,0,1) on S^2 in R^3
#-------------------------------------------------------------------
## GENERATE DATA
mydata = list()
for (i in 1:20){
  tgt = c(1, stats::rnorm(2, sd=0.1))
  mydata[[i]] = tgt/sqrt(sum(tgt^2))
}
for (i in 21:40){
  tgt = c(rnorm(1,sd=0.1),1,rnorm(1,sd=0.1))
  mydata[[i]] = tgt/sqrt(sum(tgt^2))
}
for (i in 41:60){
  tgt = c(stats::rnorm(2, sd=0.1), 1)
  mydata[[i]] = tgt/sqrt(sum(tgt^2))
}
myriem = wrap.sphere(mydata)
mylabs = rep(c(1,2,3), each=20)

## RUN THE ALGORITHM IN TWO GEOMETRIES
mypx = 5
embed2int = riem.tsne(myriem, ndim=2, geometry="intrinsic", perplexity=mypx)
embed2ext = riem.tsne(myriem, ndim=2, geometry="extrinsic", perplexity=mypx)

## VISUALIZE
opar = par(no.readonly=TRUE)
par(mfrow=c(1,2), pty="s")
plot(embed2int$embed, main="intrinsic t-SNE", col=mylabs, pch=19)
plot(embed2ext$embed, main="extrinsic t-SNE", col=mylabs, pch=19)
par(opar)

</code></pre>

<hr>
<h2 id='riem.wasserstein'>Wasserstein Distance between Empirical Measures</h2><span id='topic+riem.wasserstein'></span>

<h3>Description</h3>

<p>Given two empirical measures <code class="reqn">\mu, \nu</code> consisting of <code class="reqn">M</code> and <code class="reqn">N</code> observations, <code class="reqn">p</code>-Wasserstein distance for <code class="reqn">p\geq 1</code> between two empirical measures 
is defined as 
</p>
<p style="text-align: center;"><code class="reqn">\mathcal{W}_p (\mu, \nu) = \left( \inf_{\gamma \in \Gamma(\mu, \nu)} \int_{\mathcal{M}\times \mathcal{M}} d(x,y)^p d \gamma(x,y) \right)^{1/p}</code>
</p>

<p>where <code class="reqn">\Gamma(\mu, \nu)</code> denotes the collection of all measures/couplings on <code class="reqn">\mathcal{M}\times \mathcal{M}</code> 
whose marginals are <code class="reqn">\mu</code> and <code class="reqn">\nu</code> on the first and second factors, respectively.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>riem.wasserstein(
  riemobj1,
  riemobj2,
  p = 2,
  geometry = c("intrinsic", "extrinsic"),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="riem.wasserstein_+3A_riemobj1">riemobj1</code></td>
<td>
<p>a S3 <code>"riemdata"</code> class for <code class="reqn">M</code> manifold-valued data, which are atoms of <code class="reqn">\mu</code>.</p>
</td></tr>
<tr><td><code id="riem.wasserstein_+3A_riemobj2">riemobj2</code></td>
<td>
<p>a S3 <code>"riemdata"</code> class for <code class="reqn">N</code> manifold-valued data, which are atoms of <code class="reqn">\nu</code>.</p>
</td></tr>
<tr><td><code id="riem.wasserstein_+3A_p">p</code></td>
<td>
<p>an exponent for Wasserstein distance <code class="reqn">\mathcal{W}_p</code> (default: 2).</p>
</td></tr>
<tr><td><code id="riem.wasserstein_+3A_geometry">geometry</code></td>
<td>
<p>(case-insensitive) name of geometry; either geodesic (<code>"intrinsic"</code>) or embedded (<code>"extrinsic"</code>) geometry.</p>
</td></tr>
<tr><td><code id="riem.wasserstein_+3A_...">...</code></td>
<td>
<p>extra parameters including</p>

<dl>
<dt>weight1</dt><dd><p>a length-<code class="reqn">M</code> weight vector for <code class="reqn">\mu</code>; if <code>NULL</code> (default), uniform weight is set.</p>
</dd>
<dt>weight2</dt><dd><p>a length-<code class="reqn">N</code> weight vector for <code class="reqn">\nu</code>; if <code>NULL</code> (default), uniform weight is set.</p>
</dd>
</dl>
</td></tr>
</table>


<h3>Value</h3>

<p>a named list containing </p>

<dl>
<dt>distance</dt><dd><p><code class="reqn">\mathcal{W_p}</code> distance between two empirical measures.</p>
</dd>
<dt>plan</dt><dd><p>an <code class="reqn">(M\times N)</code> matrix whose rowSums and columnSums are <code>weight1</code> and <code>weight2</code> respectively.</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>#-------------------------------------------------------------------
#          Example on Sphere : a dataset with two types
#
# class 1 : 20 perturbed data points near (1,0,0) on S^2 in R^3
# class 2 : 30 perturbed data points near (0,1,0) on S^2 in R^3
#-------------------------------------------------------------------
## GENERATE DATA
mydata1 = list()
mydata2 = list()
for (i in 1:20){
  tgt = c(1, stats::rnorm(2, sd=0.1))
  mydata1[[i]] = tgt/sqrt(sum(tgt^2))
}
for (i in 1:30){
  tgt = c(rnorm(1,sd=0.1),1,rnorm(1,sd=0.1))
  mydata2[[i]] = tgt/sqrt(sum(tgt^2))
}
myriem1 = wrap.sphere(mydata1)
myriem2 = wrap.sphere(mydata2)

## COMPUTE p-WASSERSTEIN DISTANCES
dist1 = riem.wasserstein(myriem1, myriem2, p=1)
dist2 = riem.wasserstein(myriem1, myriem2, p=2)
dist5 = riem.wasserstein(myriem1, myriem2, p=5)

pm1 = paste0("p=1: dist=",round(dist1$distance,3))
pm2 = paste0("p=2: dist=",round(dist2$distance,3))
pm5 = paste0("p=5: dist=",round(dist5$distance,3))

## VISUALIZE TRANSPORT PLAN AND DISTANCE
opar &lt;- par(no.readonly=TRUE)
par(mfrow=c(1,3))
image(dist1$plan, axes=FALSE, main=pm1)
image(dist2$plan, axes=FALSE, main=pm2)
image(dist5$plan, axes=FALSE, main=pm5)
par(opar)

</code></pre>

<hr>
<h2 id='rmvnorm'>Generate Random Samples from Multivariate Normal Distribution</h2><span id='topic+rmvnorm'></span>

<h3>Description</h3>

<p>In <code class="reqn">\mathbf{R}^p</code>, random samples are drawn
</p>
<p style="text-align: center;"><code class="reqn">X_1,X_2,\ldots,X_n~ \sim ~ \mathcal{N}(\mu, \Sigma)</code>
</p>

<p>where <code class="reqn">\mu \in \mathbf{R}^p</code> is a mean vector and <code class="reqn">\Sigma \in \textrm{SPD}(p)</code> 
is a positive definite covariance matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rmvnorm(n = 1, mu, sigma)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rmvnorm_+3A_n">n</code></td>
<td>
<p>the number of samples to be generated.</p>
</td></tr>
<tr><td><code id="rmvnorm_+3A_mu">mu</code></td>
<td>
<p>mean vector.</p>
</td></tr>
<tr><td><code id="rmvnorm_+3A_sigma">sigma</code></td>
<td>
<p>covariance matrix.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>either (1) a length-<code class="reqn">p</code> vector (<code class="reqn">n=1</code>) or (2) an <code class="reqn">(n\times p)</code> matrix where rows are random samples.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#-------------------------------------------------------------------
#   Generate Random Data and Compare with Empirical Covariances
#
# In R^5 with zero mean and diagonal covariance, 
# generate 100 and 200 observations and compute MLE covariance.
#-------------------------------------------------------------------
## GENERATE DATA
mymu  = rep(0,5)
mysig = diag(5)

## MLE FOR COVARIANCE
smat1 = stats::cov(rmvnorm(n=100, mymu, mysig))
smat2 = stats::cov(rmvnorm(n=200, mymu, mysig))

## VISUALIZE
opar &lt;- par(no.readonly=TRUE)
par(mfrow=c(1,3), pty="s")
image(mysig[,5:1], axes=FALSE, main="true covariance")
image(smat1[,5:1], axes=FALSE, main="empirical cov with n=100")
image(smat2[,5:1], axes=FALSE, main="empirical cov with n=200")
par(opar)

</code></pre>

<hr>
<h2 id='spd.geometry'>Supported Geometries on SPD Manifold</h2><span id='topic+spd.geometry'></span>

<h3>Description</h3>

<p>SPD manifold is a well-studied space in that there have been many geometries 
proposed on the space. For special functions on under SPD category, this 
function finds whether there exists a matching name that is currently 
supported in <span class="pkg">Riemann</span>. If there is none, it will return an error message.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>spd.geometry(geometry)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="spd.geometry_+3A_geometry">geometry</code></td>
<td>
<p>name of supported geometries, including
</p>

<dl>
<dt>AIRM</dt><dd><p>Affine-Invariant Riemannian Metric.</p>
</dd>
<dt>LERM</dt><dd><p>Log-Euclidean Riemannian Metric.</p>
</dd>
<dt>Jeffrey</dt><dd><p>Jeffrey's divergence.</p>
</dd>
<dt>Stein</dt><dd><p>Stein's metric.</p>
</dd>
<dt>Wasserstein</dt><dd><p>2-Wasserstein geometry.</p>
</dd>
</dl>
</td></tr>
</table>


<h3>Value</h3>

<p>a matching name in lower-case.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># it just returns a small-letter string.
mygeom = spd.geometry("stein")

</code></pre>

<hr>
<h2 id='spd.pdist'>Pairwise Distance on SPD Manifold</h2><span id='topic+spd.pdist'></span>

<h3>Description</h3>

<p>Given <code class="reqn">N</code> observations <code class="reqn">X_1, X_2, \ldots, X_N</code> in SPD manifold, compute 
pairwise distances among observations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>spd.pdist(spdobj, geometry, as.dist = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="spd.pdist_+3A_spdobj">spdobj</code></td>
<td>
<p>a S3 <code>"riemdata"</code> class of SPD-valued data.</p>
</td></tr>
<tr><td><code id="spd.pdist_+3A_geometry">geometry</code></td>
<td>
<p>name of the geometry to be used. See <code><a href="#topic+spd.geometry">spd.geometry</a></code> for supported geometries.</p>
</td></tr>
<tr><td><code id="spd.pdist_+3A_as.dist">as.dist</code></td>
<td>
<p>logical; if <code>TRUE</code>, it returns a <code>dist</code> object. Else, it returns a symmetric matrix.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a S3 <code>dist</code> object or <code class="reqn">(N\times N)</code> symmetric matrix of pairwise distances according to <code>as.dist</code> parameter.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
#-------------------------------------------------------------------
#                   Two Types of Covariances
#
#  group1 : perturbed from data by N(0,1) in R^3
#  group2 : perturbed from data by [sin(x); cos(x); sin(x)*cos(x)]
#-------------------------------------------------------------------
## GENERATE DATA
spd_mats = array(0,c(3,3,20))
for (i in 1:10){
  spd_mats[,,i] = stats::cov(matrix(rnorm(50*3), ncol=3))
}
for (j in 11:20){
  randvec = stats::rnorm(50, sd=3)
  randmat = cbind(sin(randvec), cos(randvec), sin(randvec)*cos(randvec))
  spd_mats[,,j] = stats::cov(randmat + matrix(rnorm(50*3, sd=0.1), ncol=3))
}

## WRAP IT AS SPD OBJECT
spd_obj = wrap.spd(spd_mats)

## COMPUTE PAIRWISE DISTANCES
#  Geometries are case-insensitive.
pdA = spd.pdist(spd_obj, "airM")
pdL = spd.pdist(spd_obj, "lErm")
pdJ = spd.pdist(spd_obj, "Jeffrey")
pdS = spd.pdist(spd_obj, "stEin")
pdW = spd.pdist(spd_obj, "wasserstein")

## VISUALIZE
opar &lt;- par(no.readonly=TRUE)
par(mfrow=c(2,3), pty="s")
image(pdA, axes=FALSE, main="AIRM")
image(pdL, axes=FALSE, main="LERM")
image(pdJ, axes=FALSE, main="Jeffrey")
image(pdS, axes=FALSE, main="Stein")
image(pdW, axes=FALSE, main="Wasserstein")
par(opar)


</code></pre>

<hr>
<h2 id='spd.wassbary'>Wasserstein Barycenter of SPD Matrices</h2><span id='topic+spd.wassbary'></span>

<h3>Description</h3>

<p>Given <code class="reqn">N</code> observations <code class="reqn">X_1, X_2, \ldots, X_N</code> in SPD manifold, compute 
the <code class="reqn">L_2</code>-Wasserstein barycenter that minimizes
</p>
<p style="text-align: center;"><code class="reqn">\sum_{n=1}^N \lambda_i \mathcal{W}_2 (N(X), N(X_i))^2</code>
</p>

<p>where <code class="reqn">N(X)</code> denotes the zero-mean Gaussian measure with covariance <code class="reqn">X</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>spd.wassbary(spdobj, weight = NULL, method = c("RU02", "AE16"), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="spd.wassbary_+3A_spdobj">spdobj</code></td>
<td>
<p>a S3 <code>"riemdata"</code> class of SPD-valued data of <code class="reqn">(p\times p)</code> matrices.</p>
</td></tr>
<tr><td><code id="spd.wassbary_+3A_weight">weight</code></td>
<td>
<p>weight of observations; if <code>NULL</code> it assumes equal weights, or a nonnegative length-<code class="reqn">N</code> vector that sums to 1 should be given.</p>
</td></tr>
<tr><td><code id="spd.wassbary_+3A_method">method</code></td>
<td>
<p>name of the algortihm to be used; one of the <code>"RU02"</code>, <code>"AE16"</code>.</p>
</td></tr>
<tr><td><code id="spd.wassbary_+3A_...">...</code></td>
<td>
<p>extra parameters including</p>

<dl>
<dt>maxiter</dt><dd><p>maximum number of iterations to be run (default:20).</p>
</dd>
<dt>abstol</dt><dd><p>tolerance level for stopping criterion (default: 1e-8).</p>
</dd>
</dl>
</td></tr>
</table>


<h3>Value</h3>

<p>a <code class="reqn">(p\times p)</code> Wasserstein barycenter matrix.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
#-------------------------------------------------------------------
#        Covariances from standard multivariate Gaussians.
#-------------------------------------------------------------------
## GENERATE DATA
ndata = 20
pdim  = 10
mydat = array(0,c(pdim,pdim,ndata))
for (i in 1:ndata){
  mydat[,,i] = stats::cov(matrix(rnorm(100*pdim), ncol=pdim))
}
myriem = wrap.spd(mydat)

## COMPUTE BY DIFFERENT ALGORITHMS
baryRU &lt;- spd.wassbary(myriem, method="RU02")
baryAE &lt;- spd.wassbary(myriem, method="AE16")

## VISUALIZE
opar &lt;- par(no.readonly=TRUE)
par(mfrow=c(1,3), pty="s")
image(diag(pdim), axes=FALSE, main="True Covariance")
image(baryRU, axes=FALSE, main="by RU02")
image(baryAE, axes=FALSE, main="by AE16")
par(opar)



</code></pre>

<hr>
<h2 id='sphere.convert'>Convert between Cartesian Coordinates and Geographic Coordinates</h2><span id='topic+sphere.convert'></span><span id='topic+sphere.geo2xyz'></span><span id='topic+sphere.xyz2geo'></span>

<h3>Description</h3>

<p>In geospatial data analysis, it is common to consider locations on the Earth as 
data. These locations, usually provided by latitude and longitude, are not directly 
applicable for spherical data analysis. We provide two functions - <code>sphere.geo2xyz</code> and <code>sphere.xyz2geo</code> - 
that convert geographic coordinates in longitude/latitude into a unit-norm vector on <code class="reqn">\mathcal{S}^2</code>, and vice versa. 
As a convention, latitude and longitude are represented as <em>decimal degrees</em>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sphere.geo2xyz(lat, lon)

sphere.xyz2geo(xyz)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sphere.convert_+3A_lat">lat</code></td>
<td>
<p>latitude (in decimal degrees).</p>
</td></tr>
<tr><td><code id="sphere.convert_+3A_lon">lon</code></td>
<td>
<p>longitude (in decimal degrees).</p>
</td></tr>
<tr><td><code id="sphere.convert_+3A_xyz">xyz</code></td>
<td>
<p>a unit-norm vector in <code class="reqn">\mathcal{S}^{2}</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>transformed data.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## EXAMPLE DATA WITH POPULATED US CITIES
data(cities)

## SELECT ALBUQUERQUE
geo = cities$coord[1,]
xyz = cities$cartesian[1,]

## CHECK TWO INPUT TYPES AND THEIR CONVERSIONS
sphere.geo2xyz(geo[1], geo[2])
sphere.xyz2geo(xyz)

</code></pre>

<hr>
<h2 id='sphere.runif'>Generate Uniform Samples on Sphere</h2><span id='topic+sphere.runif'></span>

<h3>Description</h3>

<p>It generates <code class="reqn">n</code> random samples from <code class="reqn">\mathcal{S}^{p-1}</code>. For convenient 
usage of users, we provide a number of options in terms of the return type.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sphere.runif(n, p, type = c("list", "matrix", "riemdata"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sphere.runif_+3A_n">n</code></td>
<td>
<p>number of samples to be generated.</p>
</td></tr>
<tr><td><code id="sphere.runif_+3A_p">p</code></td>
<td>
<p>original dimension (of the ambient space).</p>
</td></tr>
<tr><td><code id="sphere.runif_+3A_type">type</code></td>
<td>
<p>return type; </p>

<dl>
<dt><code>"list"</code></dt><dd><p>a length-<code class="reqn">n</code> list of length-<code class="reqn">p</code> vectors.</p>
</dd>
<dt><code>"matrix"</code></dt><dd><p>a <code class="reqn">(n\times p)</code> where rows are unit vectors.</p>
</dd>
<dt><code>"riemdata"</code></dt><dd><p>a S3 object. See <code><a href="#topic+wrap.sphere">wrap.sphere</a></code> for more details (<em>Default</em>).</p>
</dd>
</dl>
</td></tr>
</table>


<h3>Value</h3>

<p>an object from one of the above by <code>type</code> option.
</p>


<h3>References</h3>

<p>Chikuse Y (2003).
<em>Statistics on Special Manifolds</em>, volume 174 of <em>Lecture Notes in Statistics</em>.
Springer New York, New York, NY.
ISBN 978-0-387-00160-9 978-0-387-21540-2.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+wrap.sphere">wrap.sphere</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#-------------------------------------------------------------------
#                       Draw Samples on Sphere
#
# Multiple return types on S^4 in R^5
#-------------------------------------------------------------------
dat.list = sphere.runif(n=10, p=5, type="list")
dat.matx = sphere.runif(n=10, p=5, type="matrix")
dat.riem = sphere.runif(n=10, p=5, type="riemdata")

</code></pre>

<hr>
<h2 id='sphere.utest'>Test of Uniformity on Sphere</h2><span id='topic+sphere.utest'></span>

<h3>Description</h3>

<p>Given <code class="reqn">N</code> observations <code class="reqn">\lbrace X_1, X_2, \ldots, X_M \brace</code> on 
<code class="reqn">\mathcal{S}^{p-1}</code>, it tests whether the data is distributed uniformly 
on the sphere.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sphere.utest(spobj, method = c("Rayleigh", "RayleighM"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sphere.utest_+3A_spobj">spobj</code></td>
<td>
<p>a S3 <code>"riemdata"</code> class for <code class="reqn">N</code> Sphere-valued data.</p>
</td></tr>
<tr><td><code id="sphere.utest_+3A_method">method</code></td>
<td>
<p>(case-insensitive) name of the test method containing </p>

<dl>
<dt><code>"Rayleigh"</code></dt><dd><p>original Rayleigh statistic.</p>
</dd>
<dt><code>"RayleighM"</code></dt><dd><p>modified Rayleigh statistic with better order of error.</p>
</dd>
</dl>
</td></tr>
</table>


<h3>Value</h3>

<p>a (list) object of <code>S3</code> class <code>htest</code> containing: </p>

<dl>
<dt>statistic</dt><dd><p>a test statistic.</p>
</dd>
<dt>p.value</dt><dd><p><code class="reqn">p</code>-value under <code class="reqn">H_0</code>.</p>
</dd>
<dt>alternative</dt><dd><p>alternative hypothesis.</p>
</dd>
<dt>method</dt><dd><p>name of the test.</p>
</dd>
<dt>data.name</dt><dd><p>name(s) of provided sample data.</p>
</dd>
</dl>



<h3>References</h3>

<p>Chikuse Y (2003).
<em>Statistics on Special Manifolds</em>, volume 174 of <em>Lecture Notes in Statistics</em>.
Springer New York, New York, NY.
ISBN 978-0-387-00160-9 978-0-387-21540-2.
</p>
<p>Mardia KV, Jupp PE (eds.) (1999).
<em>Directional Statistics</em>,  Wiley Series in Probability and Statistics.
John Wiley \&amp; Sons, Inc., Hoboken, NJ, USA.
ISBN 978-0-470-31697-9 978-0-471-95333-3.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+wrap.sphere">wrap.sphere</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#-------------------------------------------------------------------
#   Compare Rayleigh's original and modified versions of the test
#-------------------------------------------------------------------
#  Data Generation
myobj = sphere.runif(n=100, p=5, type="riemdata")

#  Compare 2 versions : Original vs Modified Rayleigh
sphere.utest(myobj, method="rayleigh")
sphere.utest(myobj, method="rayleighm")


</code></pre>

<hr>
<h2 id='splaplace'>Spherical Laplace Distribution</h2><span id='topic+splaplace'></span><span id='topic+dsplaplace'></span><span id='topic+rsplaplace'></span><span id='topic+mle.splaplace'></span>

<h3>Description</h3>

<p>This is a collection of tools for learning with spherical Laplace (SL) distribution 
on a <code class="reqn">(p-1)</code>-dimensional sphere in <code class="reqn">\mathbf{R}^p</code> including sampling, density evaluation, and 
maximum likelihood estimation of the parameters. The SL distribution is characterized by the following 
density function,
</p>
<p style="text-align: center;"><code class="reqn">f_{SL}(x; \mu, \sigma) = \frac{1}{C(\sigma)} \exp \left( -\frac{d(x,\mu)}{\sigma}  \right)</code>
</p>

<p>for location and scale parameters <code class="reqn">\mu</code> and <code class="reqn">\sigma</code> respectively.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dsplaplace(data, mu, sigma, log = FALSE)

rsplaplace(n, mu, sigma)

mle.splaplace(data, method = c("DE", "Optimize", "Newton"), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="splaplace_+3A_data">data</code></td>
<td>
<p>data vectors in form of either an <code class="reqn">(n\times p)</code> matrix or a length-<code class="reqn">n</code> list.  See <code><a href="#topic+wrap.sphere">wrap.sphere</a></code> for descriptions on supported input types.</p>
</td></tr>
<tr><td><code id="splaplace_+3A_mu">mu</code></td>
<td>
<p>a length-<code class="reqn">p</code> unit-norm vector of location.</p>
</td></tr>
<tr><td><code id="splaplace_+3A_sigma">sigma</code></td>
<td>
<p>a scale parameter that is positive.</p>
</td></tr>
<tr><td><code id="splaplace_+3A_log">log</code></td>
<td>
<p>a logical; <code>TRUE</code> to return log-density, <code>FALSE</code> for densities without logarithm applied.</p>
</td></tr>
<tr><td><code id="splaplace_+3A_n">n</code></td>
<td>
<p>the number of samples to be generated.</p>
</td></tr>
<tr><td><code id="splaplace_+3A_method">method</code></td>
<td>
<p>an algorithm name for concentration parameter estimation. It should be one of <code>"Newton"</code>, <code>"Optimize"</code>, and <code>"DE"</code> (case-sensitive).</p>
</td></tr>
<tr><td><code id="splaplace_+3A_...">...</code></td>
<td>
<p>extra parameters for computations, including</p>

<dl>
<dt>maxiter</dt><dd><p>maximum number of iterations to be run (default:50).</p>
</dd>
<dt>eps</dt><dd><p>tolerance level for stopping criterion (default: 1e-6).</p>
</dd>
<dt>use.exact</dt><dd><p>a logical to use exact (<code>TRUE</code>) or approximate (<code>FALSE</code>) updating rules (default: <code>FALSE</code>).</p>
</dd>
</dl>
</td></tr>
</table>


<h3>Value</h3>

<p><code>dsplaplace</code> gives a vector of evaluated densities given samples. <code>rsplaplace</code> generates 
unit-norm vectors in <code class="reqn">\mathbf{R}^p</code> wrapped in a list. <code>mle.splaplace</code> computes MLEs and returns a list 
containing estimates of location (<code>mu</code>) and scale (<code>sigma</code>) parameters.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# -------------------------------------------------------------------
#          Example with Spherical Laplace Distribution
#
# Given a fixed set of parameters, generate samples and acquire MLEs.
# Especially, we will see the evolution of estimation accuracy.
# -------------------------------------------------------------------
## DEFAULT PARAMETERS
true.mu  = c(1,0,0,0,0)
true.sig = 1

## GENERATE A RANDOM SAMPLE OF SIZE N=1000
big.data = rsplaplace(1000, true.mu, true.sig)

## ITERATE FROM 50 TO 1000 by 10
idseq = seq(from=50, to=1000, by=10)
nseq  = length(idseq)

hist.mu  = rep(0, nseq)
hist.sig = rep(0, nseq)

for (i in 1:nseq){
  small.data = big.data[1:idseq[i]]             # data subsetting
  small.MLE  = mle.splaplace(small.data)        # compute MLE
  
  hist.mu[i]  = acos(sum(small.MLE$mu*true.mu)) # difference in mu
  hist.sig[i] = small.MLE$sigma
}

## VISUALIZE
opar &lt;- par(no.readonly=TRUE)
par(mfrow=c(1,2))
plot(idseq, hist.mu,  "b", pch=19, cex=0.5, 
     main="difference in location", xlab="sample size")
plot(idseq, hist.sig, "b", pch=19, cex=0.5, 
     main="scale parameter", xlab="sample size")
abline(h=true.sig, lwd=2, col="red")
par(opar)


</code></pre>

<hr>
<h2 id='spnorm'>Spherical Normal Distribution</h2><span id='topic+spnorm'></span><span id='topic+dspnorm'></span><span id='topic+rspnorm'></span><span id='topic+mle.spnorm'></span>

<h3>Description</h3>

<p>We provide tools for an isotropic spherical normal (SN) distributions on 
a <code class="reqn">(p-1)</code>-sphere in <code class="reqn">\mathbf{R}^p</code> for sampling, density evaluation, and maximum likelihood estimation 
of the parameters where the density is defined as
</p>
<p style="text-align: center;"><code class="reqn">f_{SN}(x; \mu, \lambda) = \frac{1}{Z(\lambda)} \exp \left( -\frac{\lambda}{2} d^2(x,\mu) \right)</code>
</p>

<p>for location and concentration parameters <code class="reqn">\mu</code> and <code class="reqn">\lambda</code> respectively and the normalizing constant <code class="reqn">Z(\lambda)</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dspnorm(data, mu, lambda, log = FALSE)

rspnorm(n, mu, lambda)

mle.spnorm(data, method = c("Newton", "Halley", "Optimize", "DE"), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="spnorm_+3A_data">data</code></td>
<td>
<p>data vectors in form of either an <code class="reqn">(n\times p)</code> matrix or a length-<code class="reqn">n</code> list.  See <code><a href="#topic+wrap.sphere">wrap.sphere</a></code> for descriptions on supported input types.</p>
</td></tr>
<tr><td><code id="spnorm_+3A_mu">mu</code></td>
<td>
<p>a length-<code class="reqn">p</code> unit-norm vector of location.</p>
</td></tr>
<tr><td><code id="spnorm_+3A_lambda">lambda</code></td>
<td>
<p>a concentration parameter that is positive.</p>
</td></tr>
<tr><td><code id="spnorm_+3A_log">log</code></td>
<td>
<p>a logical; <code>TRUE</code> to return log-density, <code>FALSE</code> for densities without logarithm applied.</p>
</td></tr>
<tr><td><code id="spnorm_+3A_n">n</code></td>
<td>
<p>the number of samples to be generated.</p>
</td></tr>
<tr><td><code id="spnorm_+3A_method">method</code></td>
<td>
<p>an algorithm name for concentration parameter estimation. It should be one of <code>"Newton"</code>,<code>"Halley"</code>,<code>"Optimize"</code>, and <code>"DE"</code> (case sensitive).</p>
</td></tr>
<tr><td><code id="spnorm_+3A_...">...</code></td>
<td>
<p>extra parameters for computations, including</p>

<dl>
<dt>maxiter</dt><dd><p>maximum number of iterations to be run (default:50).</p>
</dd>
<dt>eps</dt><dd><p>tolerance level for stopping criterion (default: 1e-5).</p>
</dd>
</dl>
</td></tr>
</table>


<h3>Value</h3>

<p><code>dspnorm</code> gives a vector of evaluated densities given samples. <code>rspnorm</code> generates 
unit-norm vectors in <code class="reqn">\mathbf{R}^p</code> wrapped in a list. <code>mle.spnorm</code> computes MLEs and returns a list 
containing estimates of location (<code>mu</code>) and concentration (<code>lambda</code>) parameters.
</p>


<h3>References</h3>

<p>Hauberg S (2018).
&ldquo;Directional Statistics with the Spherical Normal Distribution.&rdquo;
In <em>2018 21st International Conference on Information Fusion (FUSION)</em>, 704&ndash;711.
ISBN 978-0-9964527-6-2.
</p>
<p>You K, Suh C (2022).
&ldquo;Parameter Estimation and Model-Based Clustering with Spherical Normal Distribution on the Unit Hypersphere.&rdquo;
<em>Computational Statistics \&amp; Data Analysis</em>, 107457.
ISSN 01679473.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# -------------------------------------------------------------------
#          Example with Spherical Normal Distribution
#
# Given a fixed set of parameters, generate samples and acquire MLEs.
# Especially, we will see the evolution of estimation accuracy.
# -------------------------------------------------------------------
## DEFAULT PARAMETERS
true.mu  = c(1,0,0,0,0)
true.lbd = 5

## GENERATE DATA N=1000
big.data = rspnorm(1000, true.mu, true.lbd)

## ITERATE FROM 50 TO 1000 by 10
idseq = seq(from=50, to=1000, by=10)
nseq  = length(idseq)

hist.mu  = rep(0, nseq)
hist.lbd = rep(0, nseq)

for (i in 1:nseq){
  small.data = big.data[1:idseq[i]]          # data subsetting
  small.MLE  = mle.spnorm(small.data) # compute MLE
  
  hist.mu[i]  = acos(sum(small.MLE$mu*true.mu)) # difference in mu
  hist.lbd[i] = small.MLE$lambda
}

## VISUALIZE
opar &lt;- par(no.readonly=TRUE)
par(mfrow=c(1,2))
plot(idseq, hist.mu,  "b", pch=19, cex=0.5, main="difference in location")
plot(idseq, hist.lbd, "b", pch=19, cex=0.5, main="concentration param")
abline(h=true.lbd, lwd=2, col="red")
par(opar)


</code></pre>

<hr>
<h2 id='stiefel.optSA'>Simulated Annealing on Stiefel Manifold</h2><span id='topic+stiefel.optSA'></span>

<h3>Description</h3>

<p>Simulated Annealing is a black-box, derivative-free optimization algorithm 
that iterates via stochastic search in the neighborhood of current position. 
<code>stiefel.optSA</code> solves the following problem
</p>
<p style="text-align: center;"><code class="reqn">\min_X f(X),\quad X \in St(p,k)</code>
</p>

<p>without any other auxiliary information such as gradient or hessian involved.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>stiefel.optSA(func, p, k, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="stiefel.optSA_+3A_func">func</code></td>
<td>
<p>a function to be <em>minimized</em>.</p>
</td></tr>
<tr><td><code id="stiefel.optSA_+3A_p">p</code></td>
<td>
<p>dimension parameter as in <code class="reqn">St(k,p)</code>.</p>
</td></tr>
<tr><td><code id="stiefel.optSA_+3A_k">k</code></td>
<td>
<p>dimension parameter as in <code class="reqn">St(k,p)</code>.</p>
</td></tr>
<tr><td><code id="stiefel.optSA_+3A_...">...</code></td>
<td>
<p>extra parameters for SA algorithm including</p>

<dl>
<dt>n.start</dt><dd><p>number of runs; algorithm is executed <code>n.start</code> times (default: 5).</p>
</dd>
<dt>stepsize</dt><dd><p>size of random walk on each component (default: 0.1).</p>
</dd>
<dt>maxiter</dt><dd><p>maximum number of iterations for each run (default: 100).</p>
</dd>
<dt>cooling</dt><dd><p>triplet for cooling schedule. See the section for the usage.</p>
</dd>
<dt>init.val</dt><dd><p>if <code>NULL</code>, starts from a random point. Otherwise, a Stiefel matrix of size <code class="reqn">(p,k)</code> should be provided for fixed starting point.</p>
</dd>
<dt>print.progress</dt><dd><p>a logical; if <code>TRUE</code>, it prints each iteration.</p>
</dd>
</dl>
</td></tr>
</table>


<h3>Value</h3>

<p>a named list containing: </p>

<dl>
<dt>cost</dt><dd><p>minimized function value.</p>
</dd>
<dt>solution</dt><dd><p>a <code class="reqn">(p\times k)</code> matrix that attains the <code>cost</code>.</p>
</dd>
<dt>accfreq</dt><dd><p>frequency of acceptance moves.</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>#-------------------------------------------------------------------
#               Optimization for Eigen-Decomposition
#
# Given (5x5) covariance matrix S, eigendecomposition is indeed 
# an optimization problem cast on the stiefel manifold. Here, 
# we are trying to find top 3 eigenvalues and compare.
#-------------------------------------------------------------------
## PREPARE
set.seed(121)                         # set seed
A = cov(matrix(rnorm(100*5), ncol=5)) # define covariance
myfunc &lt;- function(p){                # cost function to minimize
  return(sum(-diag(t(p)%*%A%*%p)))
} 

## SOLVE THE OPTIMIZATION PROBLEM
Aout = stiefel.optSA(myfunc, p=5, k=3, n.start=40, maxiter=200)

## COMPUTE EIGENVALUES
#  1. USE SOLUTIONS TO THE ABOVE OPTIMIZATION 
abase   = Aout$solution
eig3sol = sort(diag(t(abase)%*%A%*%abase), decreasing=TRUE)

#  2. USE BASIC 'EIGEN' FUNCTION
eig3dec = sort(eigen(A)$values, decreasing=TRUE)[1:3]

## VISUALIZE
opar &lt;- par(no.readonly=TRUE)
yran = c(min(min(eig3sol),min(eig3dec))*0.95,
         max(max(eig3sol),max(eig3dec))*1.05)
plot(1:3, eig3sol, type="b", col="red",  pch=19, ylim=yran,
     xlab="index", ylab="eigenvalue", main="compare top 3 eigenvalues")
lines(1:3, eig3dec, type="b", col="blue", pch=19)
legend(1, 1, legend=c("optimization","decomposition"), col=c("red","blue"),
       lty=rep(1,2), pch=19)
par(opar)

</code></pre>

<hr>
<h2 id='stiefel.runif'>Generate Uniform Samples on Stiefel Manifold</h2><span id='topic+stiefel.runif'></span>

<h3>Description</h3>

<p>It generates <code class="reqn">n</code> random samples from Stiefel manifold <code class="reqn">St(k,p)</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>stiefel.runif(n, k, p, type = c("list", "array", "riemdata"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="stiefel.runif_+3A_n">n</code></td>
<td>
<p>number of samples to be generated.</p>
</td></tr>
<tr><td><code id="stiefel.runif_+3A_k">k</code></td>
<td>
<p>dimension of the frame.</p>
</td></tr>
<tr><td><code id="stiefel.runif_+3A_p">p</code></td>
<td>
<p>original dimension (of the ambient space).</p>
</td></tr>
<tr><td><code id="stiefel.runif_+3A_type">type</code></td>
<td>
<p>return type; </p>

<dl>
<dt><code>"list"</code></dt><dd><p>a length-<code class="reqn">n</code> list of <code class="reqn">(p\times k)</code> basis of <code class="reqn">k</code>-frames.</p>
</dd>
<dt><code>"array"</code></dt><dd><p>a <code class="reqn">(p\times k\times n)</code> 3D array whose slices are <code class="reqn">k</code>-frame basis.</p>
</dd>
<dt><code>"riemdata"</code></dt><dd><p>a S3 object. See <code><a href="#topic+wrap.stiefel">wrap.stiefel</a></code> for more details.</p>
</dd>
</dl>
</td></tr>
</table>


<h3>Value</h3>

<p>an object from one of the above by <code>type</code> option.
</p>


<h3>References</h3>

<p>Chikuse Y (2003).
<em>Statistics on Special Manifolds</em>, volume 174 of <em>Lecture Notes in Statistics</em>.
Springer New York, New York, NY.
ISBN 978-0-387-00160-9 978-0-387-21540-2.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+wrap.stiefel">wrap.stiefel</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#-------------------------------------------------------------------
#                 Draw Samples on Stiefel Manifold 
#
# Try Different Return Types with 3 Observations of 5-frames in R^10
#-------------------------------------------------------------------
#  GENERATION
dat.list = stiefel.runif(n=3, k=5, p=10, type="list")
dat.arr3 = stiefel.runif(n=3, k=5, p=10, type="array")
dat.riem = stiefel.runif(n=3, k=5, p=10, type="riemdata")

</code></pre>

<hr>
<h2 id='stiefel.utest'>Test of Uniformity on Stiefel Manifold</h2><span id='topic+stiefel.utest'></span>

<h3>Description</h3>

<p>Given the data on Stiefel manifold <code class="reqn">St(k,p)</code>, it tests whether the 
data is distributed uniformly.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>stiefel.utest(stobj, method = c("Rayleigh", "RayleighM"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="stiefel.utest_+3A_stobj">stobj</code></td>
<td>
<p>a S3 <code>"riemdata"</code> class for <code class="reqn">N</code> Stiefel-valued data.</p>
</td></tr>
<tr><td><code id="stiefel.utest_+3A_method">method</code></td>
<td>
<p>(case-insensitive) name of the test method containing </p>

<dl>
<dt><code>"Rayleigh"</code></dt><dd><p>original Rayleigh statistic.</p>
</dd>
<dt><code>"RayleighM"</code></dt><dd><p>modified Rayleigh statistic with better order of error.</p>
</dd>
</dl>
</td></tr>
</table>


<h3>Value</h3>

<p>a (list) object of <code>S3</code> class <code>htest</code> containing: </p>

<dl>
<dt>statistic</dt><dd><p>a test statistic.</p>
</dd>
<dt>p.value</dt><dd><p><code class="reqn">p</code>-value under <code class="reqn">H_0</code>.</p>
</dd>
<dt>alternative</dt><dd><p>alternative hypothesis.</p>
</dd>
<dt>method</dt><dd><p>name of the test.</p>
</dd>
<dt>data.name</dt><dd><p>name(s) of provided sample data.</p>
</dd>
</dl>



<h3>References</h3>

<p>Chikuse Y (2003).
<em>Statistics on Special Manifolds</em>, volume 174 of <em>Lecture Notes in Statistics</em>.
Springer New York, New York, NY.
ISBN 978-0-387-00160-9 978-0-387-21540-2.
</p>
<p>Mardia KV, Jupp PE (eds.) (1999).
<em>Directional Statistics</em>,  Wiley Series in Probability and Statistics.
John Wiley \&amp; Sons, Inc., Hoboken, NJ, USA.
ISBN 978-0-470-31697-9 978-0-471-95333-3.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+wrap.stiefel">wrap.stiefel</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#-------------------------------------------------------------------
#   Compare Rayleigh's original and modified versions of the test
# 
# Test 1. sample uniformly from St(2,4)
# Test 2. use perturbed principal components from 'iris' data in R^4
#         which is concentrated around a point to reject H0.
#-------------------------------------------------------------------
## DATA GENERATION
#  1. uniform data
myobj1 = stiefel.runif(n=100, k=2, p=4)

#  2. perturbed principal components
data(iris)
irdat = list()
for (n in 1:100){
   tmpdata    = iris[1:50,1:4] + matrix(rnorm(50*4,sd=0.5),ncol=4)
   irdat[[n]] = eigen(cov(tmpdata))$vectors[,1:2]
}
myobj2 = wrap.stiefel(irdat)

## TEST
#  1. uniform data
stiefel.utest(myobj1, method="Rayleigh")
stiefel.utest(myobj1, method="RayleighM")

#  2. concentrated data
stiefel.utest(myobj2, method="rayleIgh")   # method names are 
stiefel.utest(myobj2, method="raYleiGhM")  # CASE - INSENSITIVE !

</code></pre>

<hr>
<h2 id='wrap.correlation'>Prepare Data on Correlation Manifold</h2><span id='topic+wrap.correlation'></span>

<h3>Description</h3>

<p>The collection of correlation matrices is considered as a subset (and quotient) of 
the well-known SPD manifold. In our package, it is defined as
</p>
<p style="text-align: center;"><code class="reqn">\mathcal{C}_{++}^p = \lbrace X \in \mathbf{R}^{p\times p} ~\vert~ X^\top = X,~ \textrm{rank}(X)=p,~ \textrm{diag}(X) = 1 \rbrace</code>
</p>

<p>where the rank condition means it is strictly positive definite. Please note that 
the geometry involving semi-definite correlation matrices is not the objective here.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>wrap.correlation(input)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="wrap.correlation_+3A_input">input</code></td>
<td>
<p>correlation data matrices to be wrapped as <code>riemdata</code> class. Following inputs are considered,
</p>

<dl>
<dt>array</dt><dd><p>an <code class="reqn">(p\times p\times n)</code> array where each slice along 3rd dimension is a correlation matrix.</p>
</dd>
<dt>list</dt><dd><p>a length-<code class="reqn">n</code> list whose elements are <code class="reqn">(p\times p)</code> correlation matrices.</p>
</dd>
</dl>
</td></tr>
</table>


<h3>Value</h3>

<p>a named <code>riemdata</code> S3 object containing
</p>

<dl>
<dt>data</dt><dd><p>a list of <code class="reqn">(p\times p)</code> correlation matrices.</p>
</dd>
<dt>size</dt><dd><p>size of each correlation matrix.</p>
</dd>
<dt>name</dt><dd><p>name of the manifold of interests, <em>&quot;correlation&quot;</em></p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>#-------------------------------------------------------------------
#                 Checker for Two Types of Inputs
#
#  5 observations; empirical correlation of normal observations.
#-------------------------------------------------------------------
#  Data Generation
d1 = array(0,c(3,3,5))
d2 = list()
for (i in 1:5){
  dat = matrix(rnorm(10*3),ncol=3)
  d1[,,i] = stats::cor(dat)
  d2[[i]] = d1[,,i]
}

#  Run
test1 = wrap.correlation(d1)
test2 = wrap.correlation(d2)

</code></pre>

<hr>
<h2 id='wrap.euclidean'>Prepare Data on Euclidean Space</h2><span id='topic+wrap.euclidean'></span>

<h3>Description</h3>

<p>Euclidean space <code class="reqn">\mathbf{R}^p</code> is the most common space for data analysis, 
which can be considered as a Riemannian manifold with flat metric. Since
the space of matrices is isomorphic to Euclidean space after vectorization, 
we consider the inputs as <code class="reqn">p</code>-dimensional vectors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>wrap.euclidean(input)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="wrap.euclidean_+3A_input">input</code></td>
<td>
<p>data vectors to be wrapped as <code>riemdata</code> class. Following inputs are considered,
</p>

<dl>
<dt>matrix</dt><dd><p>an <code class="reqn">(n \times p)</code> matrix of row observations.</p>
</dd>
<dt>list</dt><dd><p>a length-<code class="reqn">n</code> list whose elements are length-<code class="reqn">p</code> vectors.</p>
</dd>
</dl>
</td></tr>
</table>


<h3>Value</h3>

<p>a named <code>riemdata</code> S3 object containing
</p>

<dl>
<dt>data</dt><dd><p>a list of <code class="reqn">(p\times 1)</code> matrices in <code class="reqn">\mathbf{R}^p</code>.</p>
</dd>
<dt>size</dt><dd><p>dimension of the ambient space.</p>
</dd>
<dt>name</dt><dd><p>name of the manifold of interests, <em>&quot;euclidean&quot;</em></p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>#-------------------------------------------------------------------
#                 Checker for Two Types of Inputs
#
#  Generate 5 observations in R^3 in Matrix and List.
#-------------------------------------------------------------------
## DATA GENERATION
d1 = array(0,c(5,3))
d2 = list()
for (i in 1:5){
  single  = stats::rnorm(3)
  d1[i,]  = single
  d2[[i]] = single
}

## RUN
test1 = wrap.euclidean(d1)
test2 = wrap.euclidean(d2)

</code></pre>

<hr>
<h2 id='wrap.grassmann'>Prepare Data on Grassmann Manifold</h2><span id='topic+wrap.grassmann'></span>

<h3>Description</h3>

<p>Grassmann manifold <code class="reqn">Gr(k,p)</code> is the set of <code class="reqn">k</code>-planes, or <code class="reqn">k</code>-dimensional subspaces in <code class="reqn">R^p</code>, 
which means that for a given matrix <code class="reqn">Y \in \mathbf{R}{p\times k}</code>, the column space <code class="reqn">SPAN(Y)</code> is an element 
in Grassmann manifold. We use a convention that each element in <code class="reqn">Gr(k,p)</code> is represented as an orthonormal basis (ONB) <code class="reqn">X \in \mathbf{R}^{p\times k}</code> where
</p>
<p style="text-align: center;"><code class="reqn">X^\top X = I_k.</code>
</p>
<p> If not provided in such a form, this wrapper takes a QR decomposition of the given data 
to recover a corresponding ONB.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>wrap.grassmann(input)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="wrap.grassmann_+3A_input">input</code></td>
<td>
<p>data matrices to be wrapped as <code>riemdata</code> class. Following inputs are considered,
</p>

<dl>
<dt>array</dt><dd><p>an <code class="reqn">(p\times k\times n)</code> array where each slice along 3rd dimension is a <code class="reqn">k</code>-subspace basis in dimension <code class="reqn">p</code>.</p>
</dd>
<dt>list</dt><dd><p>a length-<code class="reqn">n</code> list whose elements are <code class="reqn">(p\times k)</code> basis for <code class="reqn">k</code>-subspace.</p>
</dd>
</dl>
</td></tr>
</table>


<h3>Value</h3>

<p>a named <code>riemdata</code> S3 object containing
</p>

<dl>
<dt>data</dt><dd><p>a list of k-subspace basis matrices.</p>
</dd>
<dt>size</dt><dd><p>size of each k-subspace basis matrix.</p>
</dd>
<dt>name</dt><dd><p>name of the manifold of interests, <em>&quot;grassmann&quot;</em></p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>#-------------------------------------------------------------------
#                 Checker for Two Types of Inputs
#
#  Generate 5 observations in Gr(2,4)
#-------------------------------------------------------------------
#  Generation
d1 = array(0,c(4,2,5))
d2 = list()
for (i in 1:5){
  d1[,,i] = matrix(rnorm(4*2), ncol=2)
  d2[[i]] = d1[,,i]
}

#  Run
test1 = wrap.grassmann(d1)
test2 = wrap.grassmann(d2)

</code></pre>

<hr>
<h2 id='wrap.landmark'>Wrap Landmark Data on Shape Space</h2><span id='topic+wrap.landmark'></span>

<h3>Description</h3>

<p>One of the frameworks used in shape space is to represent the data as landmarks. 
Each shape is a point set of <code class="reqn">k</code> points in <code class="reqn">\mathbf{R}^p</code> where each 
point is a labeled object. We consider general landmarks in <code class="reqn">p=2,3,\ldots</code>. 
Note that when <code class="reqn">p &gt; 2</code>, it is stratified space but we assume singularities do not exist or 
are omitted. The wrapper takes translation and scaling out from the data to make it 
<em>preshape</em> (centered, unit-norm). Also, for convenience, orthogonal 
Procrustes analysis is applied with the first observation being the reference so 
that all the other data are rotated to match the shape of the first.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>wrap.landmark(input)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="wrap.landmark_+3A_input">input</code></td>
<td>
<p>data matrices to be wrapped as <code>riemdata</code> class. Following inputs are considered,
</p>

<dl>
<dt>array</dt><dd><p>a <code class="reqn">(k\times p\times n)</code> array where each slice along 3rd dimension is a <code class="reqn">k</code>-ad in <code class="reqn">\mathbf{R}^p</code>.</p>
</dd>
<dt>list</dt><dd><p>a length-<code class="reqn">n</code> list whose elements are <code class="reqn">k</code>-ads.</p>
</dd>
</dl>
</td></tr>
</table>


<h3>Value</h3>

<p>a named <code>riemdata</code> S3 object containing
</p>

<dl>
<dt>data</dt><dd><p>a list of preshapes in <code class="reqn">\mathbf{R}^p</code>.</p>
</dd>
<dt>size</dt><dd><p>size of each preshape.</p>
</dd>
<dt>name</dt><dd><p>name of the manifold of interests, <em>&quot;landmark&quot;</em></p>
</dd>
</dl>



<h3>References</h3>

<p>Dryden IL, Mardia KV (2016).
<em>Statistical shape analysis with applications in R</em>,  Wiley series in probability and statistics, Second edition edition.
John Wiley \&amp; Sons, Chichester, UK ; Hoboken, NJ.
ISBN 978-1-119-07251-5 978-1-119-07250-8.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## USE 'GORILLA' DATA
data(gorilla)
riemobj = wrap.landmark(gorilla$male)

</code></pre>

<hr>
<h2 id='wrap.multinomial'>Prepare Data on Multinomial Manifold</h2><span id='topic+wrap.multinomial'></span>

<h3>Description</h3>

<p>Multinomial manifold is referred to the data that is nonnegative and sums to 1. 
Also known as probability simplex or positive orthant, we denote <code class="reqn">(p-1)</code> simplex 
in <code class="reqn">\mathbf{R}^p</code> by 
</p>
<p style="text-align: center;"><code class="reqn">\Delta^{p-1} = \lbrace
x \in \mathbf{R}^p~\vert~ \sum_{i=1}^p x_i = 1, x_i &gt; 0
\rbrace</code>
</p>

<p>in that data are positive <code class="reqn">L_1</code> unit-norm vectors. 
In <code>wrap.multinomial</code>, normalization is applied when each data point is not on the simplex, 
but if vectors contain values not in <code class="reqn">(0,1)</code>, it returns errors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>wrap.multinomial(input)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="wrap.multinomial_+3A_input">input</code></td>
<td>
<p>data vectors to be wrapped as <code>riemdata</code> class. Following inputs are considered,
</p>

<dl>
<dt>matrix</dt><dd><p>an <code class="reqn">(n \times p)</code> matrix of row observations.</p>
</dd>
<dt>list</dt><dd><p>a length-<code class="reqn">n</code> list whose elements are length-<code class="reqn">p</code> vectors.</p>
</dd>
</dl>
</td></tr>
</table>


<h3>Value</h3>

<p>a named <code>riemdata</code> S3 object containing
</p>

<dl>
<dt>data</dt><dd><p>a list of <code class="reqn">(p\times 1)</code> matrices in <code class="reqn">\Delta^{p-1}</code>.</p>
</dd>
<dt>size</dt><dd><p>dimension of the ambient space.</p>
</dd>
<dt>name</dt><dd><p>name of the manifold of interests, <em>&quot;multinomial&quot;</em></p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>#-------------------------------------------------------------------
#                 Checker for Two Types of Inputs
#-------------------------------------------------------------------
## DATA GENERATION
d1 = array(0,c(5,3))
d2 = list()
for (i in 1:5){
  single  = abs(stats::rnorm(3))
  d1[i,]  = single
  d2[[i]] = single
}

## RUN
test1 = wrap.multinomial(d1)
test2 = wrap.multinomial(d2)

</code></pre>

<hr>
<h2 id='wrap.rotation'>Prepare Data on Rotation Group</h2><span id='topic+wrap.rotation'></span>

<h3>Description</h3>

<p>Rotation group, also known as special orthogonal group, is a Riemannian 
manifold
</p>
<p style="text-align: center;"><code class="reqn">SO(p) = \lbrace Q \in \mathbf{R}^{p\times p}~\vert~ Q^\top Q = I, \textrm{det}(Q)=1 \rbrace </code>
</p>

<p>where the name originates from an observation that when <code class="reqn">p=2,3</code> these matrices are rotation of 
shapes/configurations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>wrap.rotation(input)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="wrap.rotation_+3A_input">input</code></td>
<td>
<p>data matrices to be wrapped as <code>riemdata</code> class. Following inputs are considered,
</p>

<dl>
<dt>array</dt><dd><p>a <code class="reqn">(p\times p\times n)</code> array where each slice along 3rd dimension is a rotation matrix.</p>
</dd>
<dt>list</dt><dd><p>a length-<code class="reqn">n</code> list whose elements are <code class="reqn">(p\times p)</code> rotation matrices.</p>
</dd>
</dl>
</td></tr>
</table>


<h3>Value</h3>

<p>a named <code>riemdata</code> S3 object containing
</p>

<dl>
<dt>data</dt><dd><p>a list of <code class="reqn">(p\times p)</code> rotation matrices.</p>
</dd>
<dt>size</dt><dd><p>size of each rotation matrix.</p>
</dd>
<dt>name</dt><dd><p>name of the manifold of interests, <em>&quot;rotation&quot;</em></p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>#-------------------------------------------------------------------
#                 Checker for Two Types of Inputs
#-------------------------------------------------------------------
## DATA GENERATION
d1 = array(0,c(3,3,5))
d2 = list()
for (i in 1:5){
  single  = qr.Q(qr(matrix(rnorm(9),nrow=3)))
  d1[,,i] = single
  d2[[i]] = single
}

## RUN
test1 = wrap.rotation(d1)
test2 = wrap.rotation(d2)

</code></pre>

<hr>
<h2 id='wrap.spd'>Prepare Data on Symmetric Positive-Definite (SPD) Manifold</h2><span id='topic+wrap.spd'></span>

<h3>Description</h3>

<p>The collection of symmetric positive-definite matrices is a well-known example 
of matrix manifold. It is defined as
</p>
<p style="text-align: center;"><code class="reqn">\mathcal{S}_{++}^p = \lbrace X \in \mathbf{R}^{p\times p} ~\vert~ X^\top = X,~ \textrm{rank}(X)=p \rbrace</code>
</p>

<p>where the rank condition means it is strictly positive definite. Please note that 
the geometry involving semi-definite matrices is considered in <code>wrap.spdk</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>wrap.spd(input)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="wrap.spd_+3A_input">input</code></td>
<td>
<p>SPD data matrices to be wrapped as <code>riemdata</code> class. Following inputs are considered,
</p>

<dl>
<dt>array</dt><dd><p>an <code class="reqn">(p\times p\times n)</code> array where each slice along 3rd dimension is a SPD matrix.</p>
</dd>
<dt>list</dt><dd><p>a length-<code class="reqn">n</code> list whose elements are <code class="reqn">(p\times p)</code> SPD matrices.</p>
</dd>
</dl>
</td></tr>
</table>


<h3>Value</h3>

<p>a named <code>riemdata</code> S3 object containing
</p>

<dl>
<dt>data</dt><dd><p>a list of <code class="reqn">(p\times p)</code> SPD matrices.</p>
</dd>
<dt>size</dt><dd><p>size of each SPD matrix.</p>
</dd>
<dt>name</dt><dd><p>name of the manifold of interests, <em>&quot;spd&quot;</em></p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>#-------------------------------------------------------------------
#                 Checker for Two Types of Inputs
#
#  Generate 5 observations; empirical covariance of normal observations.
#-------------------------------------------------------------------
#  Data Generation
d1 = array(0,c(3,3,5))
d2 = list()
for (i in 1:5){
  dat = matrix(rnorm(10*3),ncol=3)
  d1[,,i] = stats::cov(dat)
  d2[[i]] = d1[,,i]
}

#  Run
test1 = wrap.spd(d1)
test2 = wrap.spd(d2)

</code></pre>

<hr>
<h2 id='wrap.spdk'>Prepare Data on SPD Manifold of Fixed-Rank</h2><span id='topic+wrap.spdk'></span>

<h3>Description</h3>

<p>When <code class="reqn">(p\times p)</code> SPD matrices are of fixed-rank <code class="reqn">k &lt; p</code>, they form 
a geometric structure represented by <code class="reqn">(p\times k)</code> matrices,
</p>
<p style="text-align: center;"><code class="reqn">SPD(k,p) = \lbrace X \in \mathbf{R}^{(p\times p)}~\vert~ Y Y^\top = X, \textrm{rank}(X) = k \rbrace</code>
</p>

<p>It's key difference from <code class="reqn">\mathcal{S}_{++}^p</code> is that all matrices should be 
of fixed rank <code class="reqn">k</code> where <code class="reqn">k</code> is usually smaller than <code class="reqn">p</code>. Inputs are 
given as <code class="reqn">(p\times p)</code> matrices with specified <code class="reqn">k</code> and <code>wrap.spdk</code> 
automatically decomposes input square matrices into rank-<code class="reqn">k</code> representation matrices.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>wrap.spdk(input, k)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="wrap.spdk_+3A_input">input</code></td>
<td>
<p>data matrices to be wrapped as <code>riemdata</code> class. Following inputs are considered,
</p>

<dl>
<dt>array</dt><dd><p>a <code class="reqn">(p\times p\times n)</code> array where each slice along 3rd dimension is a rank-<code class="reqn">k</code> matrix.</p>
</dd>
<dt>list</dt><dd><p>a length-<code class="reqn">n</code> list whose elements are <code class="reqn">(p\times p)</code> matrices of rank-<code class="reqn">k</code>.</p>
</dd>
</dl>
</td></tr>
<tr><td><code id="wrap.spdk_+3A_k">k</code></td>
<td>
<p>rank of the SPD matrices.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a named <code>riemdata</code> S3 object containing
</p>

<dl>
<dt>data</dt><dd><p>a list of <code class="reqn">(p\times k)</code> representation of the corresponding rank-<code class="reqn">k</code> SPSD matrices.</p>
</dd>
<dt>size</dt><dd><p>size of each representation matrix.</p>
</dd>
<dt>name</dt><dd><p>name of the manifold of interests, <em>&quot;spdk&quot;</em></p>
</dd>
</dl>



<h3>References</h3>

<p>Journée M, Bach F, Absil P, Sepulchre R (2010).
&ldquo;Low-rank optimization on the cone of positive semidefinite matrices.&rdquo;
<em>SIAM Journal on Optimization</em>, <b>20</b>(5), 2327&ndash;2351.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#-------------------------------------------------------------------
#                 Checker for Two Types of Inputs
#-------------------------------------------------------------------
#  Data Generation
d1 = array(0,c(10,10,3))
d2 = list()
for (i in 1:3){
  dat = matrix(rnorm(10*10),ncol=10)
  d1[,,i] = stats::cov(dat)
  d2[[i]] = d1[,,i]
}

#  Run
test1 = wrap.spdk(d1, k=2)
test2 = wrap.spdk(d2, k=2)


</code></pre>

<hr>
<h2 id='wrap.sphere'>Prepare Data on Sphere</h2><span id='topic+wrap.sphere'></span>

<h3>Description</h3>

<p>The unit hypersphere (sphere, for short) is one of the most fundamental curved 
space in studying geometry. Precisely, we denote <code class="reqn">(p-1)</code> sphere in <code class="reqn">\mathbf{R}^p</code> by
</p>
<p style="text-align: center;"><code class="reqn">\mathcal{S}^{p-1} = \lbrace x \in \mathbf{R}^p ~ \vert ~ x^\top x = \|x\|^2 = 1 \rbrace</code>
</p>

<p>where vectors are of unit norm. In <code>wrap.sphere</code>, normalization is applied when 
each data point is not on the unit sphere.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>wrap.sphere(input)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="wrap.sphere_+3A_input">input</code></td>
<td>
<p>data vectors to be wrapped as <code>riemdata</code> class. Following inputs are considered,
</p>

<dl>
<dt>matrix</dt><dd><p>an <code class="reqn">(n \times p)</code> matrix of row observations of unit norm.</p>
</dd>
<dt>list</dt><dd><p>a length-<code class="reqn">n</code> list whose elements are length-<code class="reqn">p</code> vectors of unit norm.</p>
</dd>
</dl>
</td></tr>
</table>


<h3>Value</h3>

<p>a named <code>riemdata</code> S3 object containing
</p>

<dl>
<dt>data</dt><dd><p>a list of <code class="reqn">(p\times 1)</code> matrices in <code class="reqn">\mathcal{S}^{p-1}</code>.</p>
</dd>
<dt>size</dt><dd><p>dimension of the ambient space.</p>
</dd>
<dt>name</dt><dd><p>name of the manifold of interests, <em>&quot;sphere&quot;</em></p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>#-------------------------------------------------------------------
#                 Checker for Two Types of Inputs
#
#  Generate 5 observations in S^2 embedded in R^3.
#-------------------------------------------------------------------
## DATA GENERATION
d1 = array(0,c(5,3))
d2 = list()
for (i in 1:5){
  single  = stats::rnorm(3)
  d1[i,]  = single
  d2[[i]] = single
}

## RUN
test1 = wrap.sphere(d1)
test2 = wrap.sphere(d2)

</code></pre>

<hr>
<h2 id='wrap.stiefel'>Prepare Data on (Compact) Stiefel Manifold</h2><span id='topic+wrap.stiefel'></span>

<h3>Description</h3>

<p>Stiefel manifold <code class="reqn">St(k,p)</code> is the set of <code class="reqn">k</code>-frames in <code class="reqn">\mathbf{R}^p</code>, 
which is indeed a Riemannian manifold. For usage in <span class="pkg">Riemann</span> package, 
each data point is represented as a matrix by the convention
</p>
<p style="text-align: center;"><code class="reqn">St(k,p) = \lbrace X \in \mathbf{R}^{p\times k} ~\vert~ X^\top X = I_k \rbrace</code>
</p>

<p>which means that columns are orthonormal. When the provided matrix is not 
an orthonormal basis as above, <code>wrap.stiefel</code> applies orthogonalization 
to extract valid basis information.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>wrap.stiefel(input)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="wrap.stiefel_+3A_input">input</code></td>
<td>
<p>data matrices to be wrapped as <code>riemdata</code> class. Following inputs are considered,
</p>

<dl>
<dt>array</dt><dd><p>a <code class="reqn">(p\times k\times n)</code> array where each slice along 3rd dimension is a <code class="reqn">k</code>-frame.</p>
</dd>
<dt>list</dt><dd><p>a length-<code class="reqn">n</code> list whose elements are <code class="reqn">(p\times k)</code> <code class="reqn">k</code>-frames.</p>
</dd>
</dl>
</td></tr>
</table>


<h3>Value</h3>

<p>a named <code>riemdata</code> S3 object containing
</p>

<dl>
<dt>data</dt><dd><p>a list of <code class="reqn">k</code>-frame orthonormal matrices.</p>
</dd>
<dt>size</dt><dd><p>size of each <code class="reqn">k</code>-frame basis matrix.</p>
</dd>
<dt>name</dt><dd><p>name of the manifold of interests, <em>&quot;stiefel&quot;</em></p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>#-------------------------------------------------------------------
#                 Checker for Two Types of Inputs
#
#  Generate 5 observations in St(2,4)
#-------------------------------------------------------------------
#  Data Generation by QR Decomposition
d1 = array(0,c(4,2,5))
d2 = list()
for (i in 1:5){
  d1[,,i] = qr.Q(qr(matrix(rnorm(4*2),ncol=2)))
  d2[[i]] = d1[,,i]
}

#  Run
test1 = wrap.stiefel(d1)
test2 = wrap.stiefel(d2)

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
