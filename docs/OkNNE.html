<!DOCTYPE html><html><head><title>Help for package OkNNE</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {OkNNE}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#OKNNE'>
<p>Optimal k-Nearest Neighbours Ensemble</p></a></li>
<li><a href='#OkNNE-package'>
<p>A k-Nearest Neighbours Ensemble via Optimal Model Selection for Regression</p></a></li>
<li><a href='#SMSA'>
<p>Standard Metropolitan Statistical Areas</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>A k-Nearest Neighbours Ensemble via Optimal Model Selection for
Regression</td>
</tr>
<tr>
<td>Version:</td>
<td>1.0.1</td>
</tr>
<tr>
<td>Description:</td>
<td>Optimal k Nearest Neighbours Ensemble is an ensemble of base k nearest neighbour models each constructed on a bootstrap sample with a random subset of features. k closest observations are identified for a test point "x" (say), in each base k nearest neighbour model to fit a stepwise regression to predict the output value of "x". The final predicted value of "x" is the mean of estimates given by all the models. The implemented model takes training and test datasets and trains the model on training data to predict the test data. Ali, A., Hamraz, M., Kumam, P., Khan, D.M., Khalil, U., Sulaiman, M. and Khan, Z. (2020) &lt;<a href="https://doi.org/10.1109%2FACCESS.2020.3010099">doi:10.1109/ACCESS.2020.3010099</a>&gt;.</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0)</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL (&ge; 3)</a></td>
</tr>
<tr>
<td>Imports:</td>
<td>FNN,stats</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2022-12-19 14:48:41 UTC; aaliu</td>
</tr>
<tr>
<td>Author:</td>
<td>Amjad Ali [aut, cre, cph],
  Zardad Khan [aut, ths],
  Muhammad Hamraz [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Amjad Ali &lt;aalistat1@gmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2022-12-19 15:00:09 UTC</td>
</tr>
</table>
<hr>
<h2 id='OKNNE'>
Optimal k-Nearest Neighbours Ensemble
</h2><span id='topic+OKNNE'></span>

<h3>Description</h3>

<p>Optimal k-Nearest Neighbours Ensemble &quot;OkNNE&quot; is an ensemble of base k-NN models each constructed on a bootstrap sample with a random subset of features. k closest observations are identified for a test point &quot;x&quot; (say), in each base k-NN model to fit a stepwise regression to predict the output value of &quot;x&quot;. The final predicted value of &quot;x&quot; is the mean of estimates given by all the models. OkNNE takes training and test datasets and trains the model on training data to predict the test data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>OKNNE(xtrain, ytrain, xtest = NULL, ytest = NULL, k = 10, B = 100,
direction = "forward", q = trunc(sqrt(ncol(xtrain))), algorithm =
c("kd_tree", "cover_tree", "CR", "brute"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="OKNNE_+3A_xtrain">xtrain</code></td>
<td>

<p>The features space of the training dataset.
</p>
</td></tr>
<tr><td><code id="OKNNE_+3A_ytrain">ytrain</code></td>
<td>

<p>The response variable of training dataset.
</p>
</td></tr>
<tr><td><code id="OKNNE_+3A_xtest">xtest</code></td>
<td>

<p>The test dataset to be predicted.
</p>
</td></tr>
<tr><td><code id="OKNNE_+3A_ytest">ytest</code></td>
<td>

<p>The response variable of test dataset.
</p>
</td></tr>
<tr><td><code id="OKNNE_+3A_k">k</code></td>
<td>

<p>The maximum number of nearest neighbors to search. The default value is set to 10.
</p>
</td></tr>
<tr><td><code id="OKNNE_+3A_b">B</code></td>
<td>

<p>The number of bootstrap samples.
</p>
</td></tr>
<tr><td><code id="OKNNE_+3A_direction">direction</code></td>
<td>

<p>Method used to fit stepwise models. By default <code>forward</code> procedure is used.
</p>
</td></tr>
<tr><td><code id="OKNNE_+3A_q">q</code></td>
<td>

<p>The number of features to be selected for each base k-NN model.
</p>
</td></tr>
<tr><td><code id="OKNNE_+3A_algorithm">algorithm</code></td>
<td>

<p>Method used for searching nearest neighbors.
</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>PREDICTIONS</code></td>
<td>
<p>Predicted values for test data response variable</p>
</td></tr>
<tr><td><code>RMSE</code></td>
<td>
<p>Root mean square error estimate based on test data</p>
</td></tr>
<tr><td><code>R.SQUARE</code></td>
<td>
<p>Coefficient of determination estimate based on test data</p>
</td></tr>
<tr><td><code>CORRELATION</code></td>
<td>
<p>Correlation estimate based on test data</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Amjad Ali, Muhammad Hamraz, Zardad Khan
</p>
<p>Maintainer: Amjad Ali &lt;aalistat1@gmail.com&gt;
</p>


<h3>References</h3>

<p>A. Ali et al., &quot;A k-Nearest Nieghbours Based Ensemble Via Optimal Model Selection For Regression,&quot; in IEEE Access, doi: 10.1109/ACCESS.2020.3010099.
</p>
<p>Li, S. (2009). Random KNN modeling and variable selection for high dimensional data.
</p>
<p>Shengqiao Li, E James Harner and Donald A Adjeroh. (2011). Random KNN feature selection - a fast and stable alternative to Random Forests. BMC Bioinformatics , 12:450.
</p>
<p>Alina Beygelzimer, Sham Kakadet, John Langford, Sunil Arya, David Mount and Shengqiao Li (2019). FNN: Fast Nearest Neighbor Search Algorithms and Applications. R package version 1.1.3.
</p>
<p>Venables, W. N. and Ripley, B. D. (2002). Modern Applied Statistics with S. New York: Springer (4th ed).
</p>


<h3>Examples</h3>

<pre><code class='language-R'> data(SMSA)

 anyNA(SMSA)
 #[1] FALSE

 dim(SMSA)
 #[1] 59 15

 n=nrow(SMSA)

 X &lt;- SMSA[names(SMSA)!="NOx"]
 Y &lt;- SMSA[names(SMSA)=="NOx"]

 set.seed(25)
 train.obs &lt;- sample(1:n, 0.7*n, replace = FALSE)
 test.obs &lt;- (1:n)[-train.obs]
 xtrain &lt;- X[train.obs,]; ytrain &lt;- Y[train.obs,];
 xtest &lt;- X[test.obs,]; ytest &lt;- Y[test.obs,]

 OkNNE.MODEL = OKNNE(xtrain = xtrain, ytrain = ytrain, xtest = xtest, ytest
 = ytest, k = 10, B = 5, q = trunc(sqrt(ncol(xtrain))), direction = "both",
 algorithm=c("kd_tree", "cover_tree", "CR", "brute"))

 OkNNE.MODEL

</code></pre>

<hr>
<h2 id='OkNNE-package'>
A k-Nearest Neighbours Ensemble via Optimal Model Selection for Regression
</h2><span id='topic+OkNNE-package'></span><span id='topic+OkNNE'></span>

<h3>Description</h3>

<p>Optimal k-Nearest Neighbours Ensemble &quot;OkNNE&quot; is an ensemble of base k-NN models each constructed on a bootstrap sample with a random subset of features. k closest observations are identified for a test point &quot;x&quot; (say), in each base k-NN model to fit a stepwise regression to predict the output value of &quot;x&quot;. The final predicted value of &quot;x&quot; is the mean of estimates given by all the models. OkNNE takes training and test datasets and trains the model on training data to predict the test data.
</p>


<h3>Details</h3>


<table>
<tr>
 <td style="text-align: left;">
Package: </td><td style="text-align: left;"> OkNNE</td>
</tr>
<tr>
 <td style="text-align: left;">
Type: </td><td style="text-align: left;"> Package</td>
</tr>
<tr>
 <td style="text-align: left;">
Version: </td><td style="text-align: left;"> 1.0.0</td>
</tr>
<tr>
 <td style="text-align: left;">
Date: </td><td style="text-align: left;"> 2020-07-22</td>
</tr>
<tr>
 <td style="text-align: left;">
License: </td><td style="text-align: left;"> GPL-3</td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>



<h3>Author(s)</h3>

<p>Amjad Ali, Muhammad Hamraz, Zardad Khan
</p>
<p>Maintainer: Amjad Ali &lt;aalistat1@gmail.com&gt;
</p>


<h3>References</h3>

<p>A. Ali et al., &quot;A k-Nearest Nieghbours Based Ensemble Via Optimal Model Selection For Regression,&quot; in IEEE Access, doi: 10.1109/ACCESS.2020.3010099.
</p>
<p>Li, S. (2009). Random KNN modeling and variable selection for high dimensional data.
</p>
<p>Shengqiao Li, E James Harner and Donald A Adjeroh. (2011). Random KNN feature selection- a fast and stable alternative to Random Forests. BMC Bioinformatics , 12:450.
</p>
<p>Alina Beygelzimer, Sham Kakadet, John Langford, Sunil Arya, David Mount and Shengqiao Li (2019). FNN: Fast Nearest Neighbor Search Algorithms and Applications. R package version 1.1.3.
</p>
<p>Venables, W. N. and Ripley, B. D. (2002). Modern Applied Statistics with S. New York: Springer (4th ed).
</p>

<hr>
<h2 id='SMSA'>
Standard Metropolitan Statistical Areas
</h2><span id='topic+SMSA'></span>

<h3>Description</h3>

<p>The properties of Standard Metropolitan Statistical Areas (a standard Census Bureau designation of the region around a city) in the United States, collected from a variety of sources. The data include information on the social and economic conditions in these areas, on their climate, and some indices of air pollution potentials. The dataset has 59 observations on 15 variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("SMSA")</code></pre>


<h3>Format</h3>

<p>A data frame with 59 observations on the following 15 variables.
</p>

<dl>
<dt><code>JanTemp</code></dt><dd><p>Mean January temperature (in degrees Farenheit)</p>
</dd>
<dt><code>JulyTemp</code></dt><dd><p>Mean July temperature (in degrees Farenheit)</p>
</dd>
<dt><code>RelHum</code></dt><dd><p>Relative Humidity</p>
</dd>
<dt><code>Rain</code></dt><dd><p>Annual rainfall (in inches)</p>
</dd>
<dt><code>Mortality</code></dt><dd><p>Age adjusted mortality</p>
</dd>
<dt><code>Education</code></dt><dd><p>Median education</p>
</dd>
<dt><code>PopDensity</code></dt><dd><p>Population density</p>
</dd>
<dt><code>PerNonWhite</code></dt><dd><p>Percentage of non whites</p>
</dd>
<dt><code>PerWC</code></dt><dd><p>Percentage of white collour workers</p>
</dd>
<dt><code>pop</code></dt><dd><p>Population</p>
</dd>
<dt><code>popPerhouse</code></dt><dd><p>Population per household</p>
</dd>
<dt><code>income</code></dt><dd><p>Median income</p>
</dd>
<dt><code>HCPot</code></dt><dd><p>HC pollution potential</p>
</dd>
<dt><code>S02Pot</code></dt><dd><p>Sulfur Dioxide pollution potential</p>
</dd>
<dt><code>NOx</code></dt><dd><p>Nitrous Oxide (target variable)</p>
</dd>
</dl>



<h3>Source</h3>

<p>https://www.openml.org/d/1091
</p>


<h3>References</h3>

<p>U.S. Department of Labour Statistics Authorization: free use
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(SMSA)
## maybe str(SMSA) ; plot(SMSA) ...
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
