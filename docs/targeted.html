<!DOCTYPE html><html><head><title>Help for package targeted</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {targeted}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#aipw'><p>AIPW estimator</p></a></li>
<li><a href='#alean'><p>Assumption Lean inference for generalized linear model parameters</p></a></li>
<li><a href='#ate'><p>AIPW (doubly-robust) estimator for Average Treatement Effect</p></a></li>
<li><a href='#calibration'><p>Calibration (training)</p></a></li>
<li><a href='#calibration-class'><p>calibration class object</p></a></li>
<li><a href='#cate'><p>Conditional Average Treatment Effect estimation</p></a></li>
<li><a href='#cate_link'><p>Conditional Relative Risk estimation</p></a></li>
<li><a href='#cross_validated-class'><p>cross_validated class object</p></a></li>
<li><a href='#crr'><p>Conditional Relative Risk estimation</p></a></li>
<li><a href='#cv'><p>Cross-validation</p></a></li>
<li><a href='#design'><p>Extract design matrix</p></a></li>
<li><a href='#expand.list'><p>Create a list from all combination of input variables</p></a></li>
<li><a href='#ML'><p>ML model</p></a></li>
<li><a href='#ml_model'><p>R6 class for prediction models</p></a></li>
<li><a href='#NB'><p>Naive Bayes</p></a></li>
<li><a href='#NB-class'><p>NB class object</p></a></li>
<li><a href='#nondom'><p>Find non-dominated points of a set</p></a></li>
<li><a href='#pava'><p>Pooled Adjacent Violators Algorithm</p></a></li>
<li><a href='#predict.density'><p>Prediction for kernel density estimates</p></a></li>
<li><a href='#predict.NB'><p>Predictions for Naive Bayes Classifier</p></a></li>
<li><a href='#RATE'><p>Responder Average Treatment Effect</p></a></li>
<li><a href='#RATE.surv'><p>Responder Average Treatment Effect</p></a></li>
<li><a href='#riskreg'><p>Risk regression</p></a></li>
<li><a href='#riskreg_cens'><p>Binary regression models with right censored outcomes</p></a></li>
<li><a href='#scoring'><p>Predictive model scoring</p></a></li>
<li><a href='#SL'><p>SuperLearner wrapper for ml_model</p></a></li>
<li><a href='#softmax'><p>Softmax transformation</p></a></li>
<li><a href='#solve_ode'><p>Solve ODE</p></a></li>
<li><a href='#specify_ode'><p>Specify Ordinary Differential Equation (ODE)</p></a></li>
<li><a href='#targeted-class'><p>targeted class object</p></a></li>
<li><a href='#targeted-package'><p>targeted: Targeted Inference</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Targeted Inference</td>
</tr>
<tr>
<td>Version:</td>
<td>0.5</td>
</tr>
<tr>
<td>Date:</td>
<td>2024-02-22</td>
</tr>
<tr>
<td>Author:</td>
<td>Klaus K. Holst [aut, cre],
  Andreas Nordland [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Klaus K. Holst &lt;klaus@holst.it&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Various methods for targeted and semiparametric inference including
	     augmented inverse probability weighted (AIPW) estimators for missing data and
	     causal inference (Bang and Robins (2005) &lt;<a href="https://doi.org/10.1111%2Fj.1541-0420.2005.00377.x">doi:10.1111/j.1541-0420.2005.00377.x</a>&gt;),
         variable importance and conditional average treatment effects (CATE)
         (van der Laan (2006) &lt;<a href="https://doi.org/10.2202%2F1557-4679.1008">doi:10.2202/1557-4679.1008</a>&gt;),
	     estimators for risk differences and relative risks (Richardson et al. (2017)
	     &lt;<a href="https://doi.org/10.1080%2F01621459.2016.1192546">doi:10.1080/01621459.2016.1192546</a>&gt;), assumption lean inference for generalized
         linear model parameters (Vansteelandt et al. (2022) &lt;<a href="https://doi.org/10.1111%2Frssb.12504">doi:10.1111/rssb.12504</a>&gt;).</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 4.0), lava (&ge; 1.7.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>data.table, digest, futile.logger, future.apply, optimx,
progressr, methods, mets, R6, Rcpp (&ge; 1.0.0), survival</td>
</tr>
<tr>
<td>Suggests:</td>
<td>grf, mgcv, testthat (&ge; 0.11), rmarkdown, scatterplot3d,
SuperLearner (&ge; 2.0-28), knitr, xgboost, viridisLite</td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/kkholst/targeted/issues">https://github.com/kkholst/targeted/issues</a></td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.apache.org/licenses/LICENSE-2.0">Apache License (== 2.0)</a></td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp, RcppArmadillo</td>
</tr>
<tr>
<td>LazyLoad:</td>
<td>yes</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>ByteCompile:</td>
<td>yes</td>
</tr>
<tr>
<td>RcppModules:</td>
<td>riskregmodel</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.1</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-02-22 09:09:23 UTC; kkzh</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-02-22 10:00:21 UTC</td>
</tr>
</table>
<hr>
<h2 id='aipw'>AIPW estimator</h2><span id='topic+aipw'></span>

<h3>Description</h3>

<p>AIPW for the mean (and linear projections of the EIF) with missing
observations
</p>


<h3>Usage</h3>

<pre><code class='language-R'>aipw(response_model, data, formula = ~1, missing_model, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="aipw_+3A_response_model">response_model</code></td>
<td>
<p>Model for the response given covariates (ml_model or
formula)</p>
</td></tr>
<tr><td><code id="aipw_+3A_data">data</code></td>
<td>
<p>data.frame</p>
</td></tr>
<tr><td><code id="aipw_+3A_formula">formula</code></td>
<td>
<p>design specifying the OLS estimator with outcome given by the
EIF</p>
</td></tr>
<tr><td><code id="aipw_+3A_missing_model">missing_model</code></td>
<td>
<p>Optional missing_model (ml_model or formula). By
default will use the same design as the response_model.</p>
</td></tr>
<tr><td><code id="aipw_+3A_...">...</code></td>
<td>
<p>arguments to cate</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>m &lt;- lvm(y ~ x+z, r ~ x)
distribution(m,~ r) &lt;- binomial.lvm()
transform(m, y0~r+y) &lt;- function(x) { x[x[,1]==0,2] &lt;- NA; x[,2] }
d &lt;- sim(m,1e3,seed=1)

aipw(y0 ~ x, data=d)
</code></pre>

<hr>
<h2 id='alean'>Assumption Lean inference for generalized linear model parameters</h2><span id='topic+alean'></span>

<h3>Description</h3>

<p>Assumption lean inference via cross-fitting (Double ML). See
&lt;doi:10.1111/rssb.12504
</p>


<h3>Usage</h3>

<pre><code class='language-R'>alean(
  response_model,
  exposure_model,
  data,
  link = "identity",
  g_model,
  nfolds = 1,
  silent = FALSE,
  mc.cores,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="alean_+3A_response_model">response_model</code></td>
<td>
<p>formula or ml_model object (formula =&gt; glm)</p>
</td></tr>
<tr><td><code id="alean_+3A_exposure_model">exposure_model</code></td>
<td>
<p>model for the exposure</p>
</td></tr>
<tr><td><code id="alean_+3A_data">data</code></td>
<td>
<p>data.frame</p>
</td></tr>
<tr><td><code id="alean_+3A_link">link</code></td>
<td>
<p>Link function (g)</p>
</td></tr>
<tr><td><code id="alean_+3A_g_model">g_model</code></td>
<td>
<p>Model for <code class="reqn">E[g(Y|A,W)|W]</code></p>
</td></tr>
<tr><td><code id="alean_+3A_nfolds">nfolds</code></td>
<td>
<p>Number of folds</p>
</td></tr>
<tr><td><code id="alean_+3A_silent">silent</code></td>
<td>
<p>supress all messages and progressbars</p>
</td></tr>
<tr><td><code id="alean_+3A_mc.cores">mc.cores</code></td>
<td>
<p>mc.cores Optional number of cores. parallel::mcmapply used instead of future</p>
</td></tr>
<tr><td><code id="alean_+3A_...">...</code></td>
<td>
<p>additional arguments to future.apply::future_mapply</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Let <code class="reqn">Y</code> be the response variable, <code class="reqn">A</code> the exposure and <code class="reqn">W</code>
covariates. The target parameter is: </p>
<p style="text-align: center;"><code class="reqn">\Psi(P) = \frac{E(Cov[A,
g\{E(Y|A,W)\}\mid W])} {E\{Var(A\mid W)\}} </code>
</p>

<p>The <code>response_model</code> is the model for <code class="reqn">E(Y|A,W)</code>, and
<code>exposure_model</code> is the model for <code class="reqn">E(A|W)</code>.
<code>link</code> specifies <code class="reqn">g</code>.
</p>


<h3>Value</h3>

<p>alean.targeted object
</p>


<h3>Author(s)</h3>

<p>Klaus KÃ¤hler Holst
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
sim1 &lt;- function(n, family=gaussian(), ...) {
   m &lt;- lvm() |&gt;
     distribution(~ y, binomial.lvm()) |&gt;
     regression('a', value=function(l) l) |&gt;
     regression('y', value=function(a,l) a + l)
     if (family$family=="binomial")
        distribution(m, ~a) &lt;- binomial.lvm()
   sim(m, n)
}

library(splines)
f &lt;- binomial()
d &lt;- sim1(1e4, family=f)
e &lt;- alean(response_model=ML(y ~ a + bs(l, df=3), family=binomial),
           exposure_model=ML(a ~ bs(l, df=3), family=f),
           data=d,
           link = "logit", mc.cores=1, nfolds=1)
e

e &lt;- alean(response_model=ML(y ~ a + l, family=binomial),
           exposure_model=ML(a ~ l),
           data=d,
           link = "logit", mc.cores=1, nfolds=1)
e
</code></pre>

<hr>
<h2 id='ate'>AIPW (doubly-robust) estimator for Average Treatement Effect</h2><span id='topic+ate'></span>

<h3>Description</h3>

<p>Augmented Inverse Probability Weighting estimator for the Average (Causal)
Treatment Effect. All nuisance models are here parametric (glm). For a more
general approach see the <code>cate</code> implementation. In this implementation
the standard errors are correct even when the nuisance models are
misspecified (the influence curve is calculated including the term coming
from the parametric nuisance models). The estimate is consistent if either
the propensity model or the outcome model / Q-model is correctly specified.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ate(
  formula,
  data = parent.frame(),
  weights,
  offset,
  family = stats::gaussian(identity),
  nuisance = NULL,
  propensity = nuisance,
  all,
  labels = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ate_+3A_formula">formula</code></td>
<td>
<p>Formula (see details below)</p>
</td></tr>
<tr><td><code id="ate_+3A_data">data</code></td>
<td>
<p>data.frame</p>
</td></tr>
<tr><td><code id="ate_+3A_weights">weights</code></td>
<td>
<p>optional frequency weights</p>
</td></tr>
<tr><td><code id="ate_+3A_offset">offset</code></td>
<td>
<p>optional offset (character or vector). can also be specified in the formula.</p>
</td></tr>
<tr><td><code id="ate_+3A_family">family</code></td>
<td>
<p>Exponential family argument for outcome model</p>
</td></tr>
<tr><td><code id="ate_+3A_nuisance">nuisance</code></td>
<td>
<p>outcome regression formula (Q-model)</p>
</td></tr>
<tr><td><code id="ate_+3A_propensity">propensity</code></td>
<td>
<p>propensity model formula</p>
</td></tr>
<tr><td><code id="ate_+3A_all">all</code></td>
<td>
<p>If TRUE all standard errors are calculated (default TRUE when exposure
only has two levels)</p>
</td></tr>
<tr><td><code id="ate_+3A_labels">labels</code></td>
<td>
<p>Optional treatment labels</p>
</td></tr>
<tr><td><code id="ate_+3A_...">...</code></td>
<td>
<p>Additional arguments to lower level functions</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The formula may either be specified as:
response ~ treatment | nuisance-formula | propensity-formula
</p>
<p>For example: <code>ate(y~a | x+z+a | x*z, data=...)</code>
</p>
<p>Alternatively, as a list: <code>ate(list(y~a, ~x+z, ~x*z), data=...)</code>
</p>
<p>Or using the nuisance (and propensity argument): <code>ate(y~a, nuisance=~x+z, ...)</code>
</p>


<h3>Value</h3>

<p>An object of class '<code>ate.targeted</code>' is returned. See <code><a href="#topic+targeted-class">targeted-class</a></code>
for more details about this class and its generic functions.
</p>


<h3>Author(s)</h3>

<p>Klaus K. Holst
</p>


<h3>See Also</h3>

<p>cate
</p>


<h3>Examples</h3>

<pre><code class='language-R'>m &lt;- lvm(y ~ a+x, a~x)
distribution(m, ~y) &lt;- binomial.lvm()
m &lt;- ordinal(m, K=4, ~a)
transform(m, ~a) &lt;- factor
d &lt;- sim(m, 1e3, seed=1)
(a &lt;- ate(y~a|a*x|x, data=d))
## ate(y~a, nuisance=~a*x, propensity=~x, ...)

# Comparison with randomized experiment
m0 &lt;- cancel(m, a~x)
lm(y~a-1, sim(m0,2e4))

# Choosing a different contrast for the association measures
summary(a, contrast=c(2,4))
</code></pre>

<hr>
<h2 id='calibration'>Calibration (training)</h2><span id='topic+calibration'></span><span id='topic+calibrate'></span>

<h3>Description</h3>

<p>Calibration for multiclassication methods
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calibration(
  pr,
  cl,
  weights = NULL,
  threshold = 10,
  method = "bin",
  breaks = nclass.Sturges,
  df = 3,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="calibration_+3A_pr">pr</code></td>
<td>
<p>matrix with probabilities for each class</p>
</td></tr>
<tr><td><code id="calibration_+3A_cl">cl</code></td>
<td>
<p>class variable</p>
</td></tr>
<tr><td><code id="calibration_+3A_weights">weights</code></td>
<td>
<p>counts</p>
</td></tr>
<tr><td><code id="calibration_+3A_threshold">threshold</code></td>
<td>
<p>do not calibrate if less then 'threshold' events</p>
</td></tr>
<tr><td><code id="calibration_+3A_method">method</code></td>
<td>
<p>either 'isotonic' (pava), 'logistic', 'mspline' (monotone spline), 'bin' (local constant)</p>
</td></tr>
<tr><td><code id="calibration_+3A_breaks">breaks</code></td>
<td>
<p>optional number of bins (only for method 'bin')</p>
</td></tr>
<tr><td><code id="calibration_+3A_df">df</code></td>
<td>
<p>degrees of freedom (only for spline methods)</p>
</td></tr>
<tr><td><code id="calibration_+3A_...">...</code></td>
<td>
<p>additional arguments to lower level functions</p>
</td></tr>
</table>


<h3>Details</h3>

<p>...
</p>


<h3>Value</h3>

<p>An object of class '<code>calibration</code>' is returned. See <code><a href="#topic+calibration-class">calibration-class</a></code>
for more details about this class and its generic functions.
</p>


<h3>Author(s)</h3>

<p>Klaus K. Holst
</p>


<h3>Examples</h3>

<pre><code class='language-R'>sim1 &lt;- function(n, beta=c(-3, rep(.5,10)), rho=.5) {
 p &lt;- length(beta)-1
 xx &lt;- lava::rmvn0(n,sigma=diag(nrow=p)*(1-rho)+rho)
 y &lt;- rbinom(n, 1, lava::expit(cbind(1,xx)%*%beta))
 d &lt;- data.frame(y=y, xx)
 names(d) &lt;- c("y",paste0("x",1:p))
 return(d)
}

set.seed(1)
beta &lt;- c(-2,rep(1,10))
d &lt;- sim1(1e4, beta=beta)
a1 &lt;- NB(y ~ ., data=d)
a2 &lt;- glm(y ~ ., data=d, family=binomial)
## a3 &lt;- randomForest(factor(y) ~ ., data=d, family=binomial)

d0 &lt;- sim1(1e4, beta=beta)
p1 &lt;- predict(a1, newdata=d0)
p2 &lt;- predict(a2, newdata=d0, type="response")
## p3 &lt;- predict(a3, newdata=d0, type="prob")

c2 &lt;- calibration(p2, d0$y, method="isotonic")
c1 &lt;- calibration(p1, d0$y, breaks=100)
if (interactive()) {
  plot(c1)
  plot(c2,col="red",add=TRUE)
  abline(a=0,b=1)##'
  with(c1$xy[[1]], points(pred,freq,type="b", col="red"))
}

set.seed(1)
beta &lt;- c(-2,rep(1,10))
dd &lt;- lava::csplit(sim1(1e4, beta=beta), k=3)
mod &lt;- NB(y ~ ., data=dd[[1]])
p1 &lt;- predict(mod, newdata=dd[[2]])
cal &lt;- calibration(p1, dd[[2]]$y)
p2 &lt;- predict(mod, newdata=dd[[3]])
pp &lt;- predict(c1, p2)
cc &lt;- calibration(pp, dd[[3]]$y)
if (interactive()) {##'
  plot(cal)
  plot(cc, add=TRUE, col="blue")
}
</code></pre>

<hr>
<h2 id='calibration-class'>calibration class object</h2><span id='topic+calibration-class'></span>

<h3>Description</h3>

<p>The functions <code><a href="#topic+calibration">calibration</a></code> returns an object of the class <code>calibration</code>.
</p>
<p>An object of class '<code>calibration</code>' is a list with at least the following components:
</p>

<dl>
<dt>stepfun</dt><dd><p>estimated step-functions (see <code>stepfun</code>) for each class</p>
</dd>
<dt>classes</dt><dd><p>the unique classes</p>
</dd>
<dt>model</dt><dd><p>model/method type (string)</p>
</dd>
<dt>xy</dt><dd><p>list of data.frame's with predictions (pr) and estimated probabilities of success (only for 'bin' method)</p>
</dd>
</dl>



<h3>Value</h3>

<p>objects of the S3 class '<code>calibration</code>'
</p>


<h3>S3 generics</h3>

<p>The following S3 generic functions are available for an object of class <code>targeted</code>:
</p>

<dl>
<dt><code>predict</code></dt><dd><p>Apply calibration to new data.</p>
</dd>
<dt><code>plot</code></dt><dd><p>Plot the calibration curves (reliability plot).</p>
</dd>
<dt><code>print</code></dt><dd><p>Basic print method.</p>
</dd>
</dl>



<h3>See Also</h3>

<p><code><a href="#topic+calibration">calibration</a></code>, <code><a href="#topic+calibrate">calibrate</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## See example(calibration) for examples
</code></pre>

<hr>
<h2 id='cate'>Conditional Average Treatment Effect estimation</h2><span id='topic+cate'></span>

<h3>Description</h3>

<p>Conditional Average Treatment Effect estimation via Double Machine Learning
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cate(
  treatment,
  response_model,
  propensity_model,
  contrast = c(1, 0),
  data,
  nfolds = 5,
  type = "dml2",
  silent = FALSE,
  stratify = FALSE,
  mc.cores,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cate_+3A_treatment">treatment</code></td>
<td>
<p>formula specifying treatment and variables to condition on</p>
</td></tr>
<tr><td><code id="cate_+3A_response_model">response_model</code></td>
<td>
<p>formula or ml_model object (formula =&gt; glm)</p>
</td></tr>
<tr><td><code id="cate_+3A_propensity_model">propensity_model</code></td>
<td>
<p>formula or ml_model object (formula =&gt; glm)</p>
</td></tr>
<tr><td><code id="cate_+3A_contrast">contrast</code></td>
<td>
<p>treatment contrast (default 1 vs 0)</p>
</td></tr>
<tr><td><code id="cate_+3A_data">data</code></td>
<td>
<p>data.frame</p>
</td></tr>
<tr><td><code id="cate_+3A_nfolds">nfolds</code></td>
<td>
<p>Number of folds</p>
</td></tr>
<tr><td><code id="cate_+3A_type">type</code></td>
<td>
<p>'dml1' or 'dml2'</p>
</td></tr>
<tr><td><code id="cate_+3A_silent">silent</code></td>
<td>
<p>supress all messages and progressbars</p>
</td></tr>
<tr><td><code id="cate_+3A_stratify">stratify</code></td>
<td>
<p>If TRUE the response_model will be stratified by treatment</p>
</td></tr>
<tr><td><code id="cate_+3A_mc.cores">mc.cores</code></td>
<td>
<p>mc.cores Optional number of cores. parallel::mcmapply used
instead of future</p>
</td></tr>
<tr><td><code id="cate_+3A_...">...</code></td>
<td>
<p>additional arguments to future.apply::future_mapply</p>
</td></tr>
</table>


<h3>Value</h3>

<p>cate.targeted object
</p>


<h3>Author(s)</h3>

<p>Klaus KÃ¤hler Holst
</p>


<h3>Examples</h3>

<pre><code class='language-R'>sim1 &lt;- function(n=1e4,
                 seed=NULL,
                 return_model=FALSE, ...) {
suppressPackageStartupMessages(require("lava"))
if (!is.null(seed)) set.seed(seed)
m &lt;- lava::lvm()
regression(m, ~a) &lt;- function(z1,z2,z3,z4,z5)
         cos(z1)+sin(z1*z2)+z3+z4+z5^2
regression(m, ~u) &lt;- function(a,z1,z2,z3,z4,z5)
        (z1+z2+z3)*a + z1+z2+z3 + a
distribution(m, ~a) &lt;- binomial.lvm()
if (return_model) return(m)
lava::sim(m, n, p=par)
}

d &lt;- sim1(200)
e &lt;- cate(a ~ z1+z2+z3, response=u~., data=d)
e
</code></pre>

<hr>
<h2 id='cate_link'>Conditional Relative Risk estimation</h2><span id='topic+cate_link'></span>

<h3>Description</h3>

<p>Conditional average treatment effect estimation via Double Machine Learning
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cate_link(
  treatment,
  link = "identity",
  response_model,
  propensity_model,
  importance_model,
  contrast = c(1, 0),
  data,
  nfolds = 5,
  type = "dml1",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cate_link_+3A_treatment">treatment</code></td>
<td>
<p>formula specifying treatment and variables to condition on</p>
</td></tr>
<tr><td><code id="cate_link_+3A_link">link</code></td>
<td>
<p>Link function</p>
</td></tr>
<tr><td><code id="cate_link_+3A_response_model">response_model</code></td>
<td>
<p>SL object</p>
</td></tr>
<tr><td><code id="cate_link_+3A_propensity_model">propensity_model</code></td>
<td>
<p>SL object</p>
</td></tr>
<tr><td><code id="cate_link_+3A_importance_model">importance_model</code></td>
<td>
<p>SL object</p>
</td></tr>
<tr><td><code id="cate_link_+3A_contrast">contrast</code></td>
<td>
<p>treatment contrast (default 1 vs 0)</p>
</td></tr>
<tr><td><code id="cate_link_+3A_data">data</code></td>
<td>
<p>data.frame</p>
</td></tr>
<tr><td><code id="cate_link_+3A_nfolds">nfolds</code></td>
<td>
<p>Number of folds</p>
</td></tr>
<tr><td><code id="cate_link_+3A_type">type</code></td>
<td>
<p>'dml1' or 'dml2'</p>
</td></tr>
<tr><td><code id="cate_link_+3A_...">...</code></td>
<td>
<p>additional arguments to SuperLearner</p>
</td></tr>
</table>


<h3>Value</h3>

<p>cate.targeted object
</p>


<h3>Author(s)</h3>

<p>Klaus KÃ¤hler Holst &amp; Andreas Nordland
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example 1:
sim1 &lt;- function(n=1e4,
                 seed=NULL,
                 return_model=FALSE, ...){
suppressPackageStartupMessages(require("lava"))
if (!is.null(seed)) set.seed(seed)
m &lt;- lava::lvm()
distribution(m, ~x) &lt;- gaussian.lvm()
distribution(m, ~v) &lt;- gaussian.lvm(mean = 10)
distribution(m, ~a) &lt;- binomial.lvm("logit")
regression(m, "a") &lt;- function(v, x){.1*v + x}
distribution(m, "y") &lt;- gaussian.lvm()
regression(m, "y") &lt;- function(a, v, x){v+x+a*x+a*v*v}
if (return_model) return(m)
lava::sim(m, n = n)
}

if (require("SuperLearner",quietly=TRUE)) {
  d &lt;- sim1(n = 1e3, seed = 1)
  e &lt;- cate_link(data=d,
           type = "dml2",
           treatment = a ~ v,
           response_model = y~ a*(x + v + I(v^2)),
           importance_model = SL(D_ ~ v + I(v^2)),
           nfolds = 10)
  summary(e) # the true parameters are c(1,1)
}
</code></pre>

<hr>
<h2 id='cross_validated-class'>cross_validated class object</h2><span id='topic+cross_validated-class'></span><span id='topic+cross_validated'></span>

<h3>Description</h3>

<p>The functions <code><a href="#topic+cv">cv</a></code> returns an object of the type
<code>cross_validated</code>.
</p>
<p>An object of class '<code>cross_validated</code>' is a list with at least the
following components:
</p>

<dl>
<dt>cv</dt><dd><p>An array with the model score(s) evaluated for each fold,
repetition, and model estimates
(see <code><a href="lava.html#topic+estimate.default">estimate.default</a></code>)</p>
</dd>
<dt>names</dt><dd><p>Names (character vector) of the models</p>
</dd>
<dt>rep</dt><dd><p>number of repetitions of the CV</p>
</dd>
<dt>folds</dt><dd><p>Number of folds of the CV</p>
</dd>
</dl>



<h3>Value</h3>

<p>objects of the S3 class '<code>cross_validated</code>'
</p>


<h3>S3 generics</h3>

<p>The following S3 generic functions are available for an object of
class <code>cross_validated</code>:
</p>

<dl>
<dt><code>coef</code></dt><dd><p>Extract average model scores from the
cross-validation procedure.</p>
</dd>
<dt><code>print</code></dt><dd><p>Basic print method.</p>
</dd>
<dt><code>summary</code></dt><dd><p>Summary of the cross-validation procedure.</p>
</dd></dl>
<p>'

</p>


<h3>See Also</h3>

<p><code><a href="#topic+cv">cv</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## See example(cv) for examples
</code></pre>

<hr>
<h2 id='crr'>Conditional Relative Risk estimation</h2><span id='topic+crr'></span>

<h3>Description</h3>

<p>Conditional Relative Risk estimation via Double Machine Learning
</p>


<h3>Usage</h3>

<pre><code class='language-R'>crr(
  treatment,
  response_model,
  propensity_model,
  importance_model,
  contrast = c(1, 0),
  data,
  nfolds = 5,
  type = "dml1",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="crr_+3A_treatment">treatment</code></td>
<td>
<p>formula specifying treatment and variables to condition on</p>
</td></tr>
<tr><td><code id="crr_+3A_response_model">response_model</code></td>
<td>
<p>SL object</p>
</td></tr>
<tr><td><code id="crr_+3A_propensity_model">propensity_model</code></td>
<td>
<p>SL object</p>
</td></tr>
<tr><td><code id="crr_+3A_importance_model">importance_model</code></td>
<td>
<p>SL object</p>
</td></tr>
<tr><td><code id="crr_+3A_contrast">contrast</code></td>
<td>
<p>treatment contrast (default 1 vs 0)</p>
</td></tr>
<tr><td><code id="crr_+3A_data">data</code></td>
<td>
<p>data.frame</p>
</td></tr>
<tr><td><code id="crr_+3A_nfolds">nfolds</code></td>
<td>
<p>Number of folds</p>
</td></tr>
<tr><td><code id="crr_+3A_type">type</code></td>
<td>
<p>'dml1' or 'dml2'</p>
</td></tr>
<tr><td><code id="crr_+3A_...">...</code></td>
<td>
<p>additional arguments to SuperLearner</p>
</td></tr>
</table>


<h3>Value</h3>

<p>cate.targeted object
</p>


<h3>Author(s)</h3>

<p>Klaus KÃ¤hler Holst &amp; Andreas Nordland
</p>


<h3>Examples</h3>

<pre><code class='language-R'>sim1 &lt;- function(n=1e4,
                 seed=NULL,
                 return_model=FALSE, ...){
suppressPackageStartupMessages(require("lava"))
if (!is.null(seed)) set.seed(seed)
m &lt;- lava::lvm()
distribution(m, ~x) &lt;- gaussian.lvm()
distribution(m, ~v) &lt;- gaussian.lvm(mean = 10)
distribution(m, ~a) &lt;- binomial.lvm("logit")
regression(m, "a") &lt;- function(v, x){.1*v + x}
distribution(m, "y") &lt;- gaussian.lvm()
regression(m, "y") &lt;- function(a, v, x){v+x+a*x+a*v*v}
if (return_model) return(m)
lava::sim(m, n = n)
}

d &lt;- sim1(n = 2e3, seed = 1)
if (require("SuperLearner",quietly=TRUE)) {
  e &lt;- crr(data=d,
           type = "dml2",
           treatment = a ~ v,
           response_model = ML(y~ a*(x + v + I(v^2))),
           importance_model = ML(D_ ~ v + I(v^2)),
           propensity_model = ML(a ~ x + v + I(v^2), family=binomial),
           nfolds = 2)
  summary(e) # the true parameters are c(1,1)
}

</code></pre>

<hr>
<h2 id='cv'>Cross-validation</h2><span id='topic+cv'></span>

<h3>Description</h3>

<p>Generic cross-validation function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cv(
  models,
  data,
  response = NULL,
  nfolds = 5,
  rep = 1,
  weights = NULL,
  modelscore,
  seed = NULL,
  shared = NULL,
  args.pred = NULL,
  args.future = list(),
  mc.cores,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cv_+3A_models">models</code></td>
<td>
<p>List of fitting functions</p>
</td></tr>
<tr><td><code id="cv_+3A_data">data</code></td>
<td>
<p>data.frame or matrix</p>
</td></tr>
<tr><td><code id="cv_+3A_response">response</code></td>
<td>
<p>Response variable (vector or name of column in <code>data</code>).</p>
</td></tr>
<tr><td><code id="cv_+3A_nfolds">nfolds</code></td>
<td>
<p>Number of folds (default 5. K=0 splits in 1:n/2, n/2:n with
last part used for testing)</p>
</td></tr>
<tr><td><code id="cv_+3A_rep">rep</code></td>
<td>
<p>Number of repetitions (default 1)</p>
</td></tr>
<tr><td><code id="cv_+3A_weights">weights</code></td>
<td>
<p>Optional frequency weights</p>
</td></tr>
<tr><td><code id="cv_+3A_modelscore">modelscore</code></td>
<td>
<p>Model scoring metric (default: MSE / Brier score). Must be
a function with arguments: response, prediction, weights, ...</p>
</td></tr>
<tr><td><code id="cv_+3A_seed">seed</code></td>
<td>
<p>Random seed (argument parsed to future_Apply::future_lapply)</p>
</td></tr>
<tr><td><code id="cv_+3A_shared">shared</code></td>
<td>
<p>Function applied to each fold with results send to each model</p>
</td></tr>
<tr><td><code id="cv_+3A_args.pred">args.pred</code></td>
<td>
<p>Optional arguments to prediction function (see details
below)</p>
</td></tr>
<tr><td><code id="cv_+3A_args.future">args.future</code></td>
<td>
<p>Arguments to future.apply::future_mapply</p>
</td></tr>
<tr><td><code id="cv_+3A_mc.cores">mc.cores</code></td>
<td>
<p>Optional number of cores. parallel::mcmapply used instead of
future</p>
</td></tr>
<tr><td><code id="cv_+3A_...">...</code></td>
<td>
<p>Additional arguments parsed to models in models</p>
</td></tr>
</table>


<h3>Details</h3>

<p>models should be list of objects of class ml_model. Alternatively,
each element of models should be a list with a fitting function and a
prediction function.
</p>
<p>The <code>response</code> argument can optionally be a named list where the name is
then used as the name of the response argument in models. Similarly, if data
is a named list with a single data.frame/matrix then this name will be used
as the name of the data/design matrix argument in models.
</p>


<h3>Value</h3>

<p>An object of class '<code>cross_validated</code>' is returned. See
<code><a href="#topic+cross_validated-class">cross_validated-class</a></code> for more details about this class and
its generic functions.
</p>


<h3>Author(s)</h3>

<p>Klaus K. Holst
</p>


<h3>Examples</h3>

<pre><code class='language-R'>f0 &lt;- function(data,...) lm(...,data=data)
f1 &lt;- function(data,...) lm(Sepal.Length~Species,data=data)
f2 &lt;- function(data,...) lm(Sepal.Length~Species+Petal.Length,data=data)
x &lt;- cv(list(m0=f0,m1=f1,m2=f2),rep=10, data=iris, formula=Sepal.Length~.)
x
</code></pre>

<hr>
<h2 id='design'>Extract design matrix</h2><span id='topic+design'></span>

<h3>Description</h3>

<p>Extract design matrix from data.frame and formula
</p>


<h3>Usage</h3>

<pre><code class='language-R'>design(formula, data, intercept = FALSE, rm_envir = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="design_+3A_formula">formula</code></td>
<td>
<p>formula</p>
</td></tr>
<tr><td><code id="design_+3A_data">data</code></td>
<td>
<p>data.frame</p>
</td></tr>
<tr><td><code id="design_+3A_intercept">intercept</code></td>
<td>
<p>If FALSE (default) an intercept is not included</p>
</td></tr>
<tr><td><code id="design_+3A_rm_envir">rm_envir</code></td>
<td>
<p>Remove environment</p>
</td></tr>
<tr><td><code id="design_+3A_...">...</code></td>
<td>
<p>additional arguments (e.g, specials such weights, offsets,
subset)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class 'design'
</p>


<h3>Author(s)</h3>

<p>Klaus KÃ¤hler Holst
</p>

<hr>
<h2 id='expand.list'>Create a list from all combination of input variables</h2><span id='topic+expand.list'></span>

<h3>Description</h3>

<p>Similar to <code>expand.grid</code> function, this function creates all combinations
of the input arguments but returns the result as a list.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>expand.list(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="expand.list_+3A_...">...</code></td>
<td>
<p>input variables</p>
</td></tr>
</table>


<h3>Value</h3>

<p>list
</p>


<h3>Author(s)</h3>

<p>Klaus KÃ¤hler Holst
</p>


<h3>Examples</h3>

<pre><code class='language-R'>expand.list(x=2:4, z=c("a","b"))
</code></pre>

<hr>
<h2 id='ML'>ML model</h2><span id='topic+ML'></span>

<h3>Description</h3>

<p>Wrapper for ml_model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ML(formula, model = "glm", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ML_+3A_formula">formula</code></td>
<td>
<p>formula</p>
</td></tr>
<tr><td><code id="ML_+3A_model">model</code></td>
<td>
<p>model (sl, rf, pf, glm, ...)</p>
</td></tr>
<tr><td><code id="ML_+3A_...">...</code></td>
<td>
<p>additional arguments to model object</p>
</td></tr>
</table>


<h3>Details</h3>

<p>model 'sl' (SuperLearner::SuperLearner)
args: SL.library, cvControl, f&lt;aamily, method
example:
</p>
<p>model 'grf' (grf::regression_forest)
args: num.trees, mtry, sample.weights, sample.fraction, min.node.size, ...
example:
</p>
<p>model 'grf.binary' (grf::probability_forest)
args: num.trees, mtry, sample.weights, ...
example:
</p>
<p>model 'glm'
args: family, weights, offset, ...
</p>

<hr>
<h2 id='ml_model'>R6 class for prediction models</h2><span id='topic+ml_model'></span>

<h3>Description</h3>

<p>Provides standardized estimation and prediction methods
</p>


<h3>Public fields</h3>

<div class="r6-fields">

<dl>
<dt><code>info</code></dt><dd><p>Optional information/name of the model</p>
</dd>
<dt><code>formals</code></dt><dd><p>List with formal arguments of estimation and
prediction functions</p>
</dd>
<dt><code>formula</code></dt><dd><p>Formula specifying response and design matrix</p>
</dd>
<dt><code>args</code></dt><dd><p>additional arguments specified during initialization</p>
</dd>
</dl>

</div>


<h3>Active bindings</h3>

<div class="r6-active-bindings">

<dl>
<dt><code>fit</code></dt><dd><p>Active binding returning estimated model object</p>
</dd>
</dl>

</div>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-ml_model-new"><code>ml_model$new()</code></a>
</p>
</li>
<li> <p><a href="#method-ml_model-estimate"><code>ml_model$estimate()</code></a>
</p>
</li>
<li> <p><a href="#method-ml_model-predict"><code>ml_model$predict()</code></a>
</p>
</li>
<li> <p><a href="#method-ml_model-update"><code>ml_model$update()</code></a>
</p>
</li>
<li> <p><a href="#method-ml_model-print"><code>ml_model$print()</code></a>
</p>
</li>
<li> <p><a href="#method-ml_model-response"><code>ml_model$response()</code></a>
</p>
</li>
<li> <p><a href="#method-ml_model-design"><code>ml_model$design()</code></a>
</p>
</li>
<li> <p><a href="#method-ml_model-opt"><code>ml_model$opt()</code></a>
</p>
</li>
<li> <p><a href="#method-ml_model-clone"><code>ml_model$clone()</code></a>
</p>
</li></ul>


<hr>
<a id="method-ml_model-new"></a>



<h4>Method <code>new()</code></h4>

<p>Create a new prediction model object
</p>


<h5>Usage</h5>

<div class="r"><pre>ml_model$new(
  formula = NULL,
  estimate,
  predict = stats::predict,
  predict.args = NULL,
  info = NULL,
  specials,
  response.arg = "y",
  x.arg = "x",
  ...
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>formula</code></dt><dd><p>formula specifying outcome and design matrix</p>
</dd>
<dt><code>estimate</code></dt><dd><p>function for fitting the model (must be a function
response, 'y', and design matrix, 'x'. Alternatively, a function
with a single 'formula' argument)</p>
</dd>
<dt><code>predict</code></dt><dd><p>prediction function (must be a function of model
object, 'object', and new design matrix, 'newdata')</p>
</dd>
<dt><code>predict.args</code></dt><dd><p>optional arguments to prediction function</p>
</dd>
<dt><code>info</code></dt><dd><p>optional description of the model</p>
</dd>
<dt><code>specials</code></dt><dd><p>optional additional terms (weights, offset,
id, subset, ...) passed to 'estimate'</p>
</dd>
<dt><code>response.arg</code></dt><dd><p>name of response argument</p>
</dd>
<dt><code>x.arg</code></dt><dd><p>name of design matrix argument</p>
</dd>
<dt><code>...</code></dt><dd><p>optional arguments to fitting function</p>
</dd>
</dl>

</div>


<hr>
<a id="method-ml_model-estimate"></a>



<h4>Method <code>estimate()</code></h4>

<p>Estimation method
</p>


<h5>Usage</h5>

<div class="r"><pre>ml_model$estimate(data, ..., store = TRUE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>data</code></dt><dd><p>data.frame</p>
</dd>
<dt><code>...</code></dt><dd><p>Additional arguments to estimation method</p>
</dd>
<dt><code>store</code></dt><dd><p>Logical determining if estimated model should be
stored inside the class.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-ml_model-predict"></a>



<h4>Method <code>predict()</code></h4>

<p>Prediction method
</p>


<h5>Usage</h5>

<div class="r"><pre>ml_model$predict(newdata, ..., object = NULL)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>newdata</code></dt><dd><p>data.frame</p>
</dd>
<dt><code>...</code></dt><dd><p>Additional arguments to prediction method</p>
</dd>
<dt><code>object</code></dt><dd><p>Optional model fit object</p>
</dd>
</dl>

</div>


<hr>
<a id="method-ml_model-update"></a>



<h4>Method <code>update()</code></h4>

<p>Update formula
</p>


<h5>Usage</h5>

<div class="r"><pre>ml_model$update(formula, ...)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>formula</code></dt><dd><p>formula or character which defines the new response</p>
</dd>
<dt><code>...</code></dt><dd><p>Additional arguments to lower level functions</p>
</dd>
</dl>

</div>


<hr>
<a id="method-ml_model-print"></a>



<h4>Method <code>print()</code></h4>

<p>Print method
</p>


<h5>Usage</h5>

<div class="r"><pre>ml_model$print(...)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>...</code></dt><dd><p>Additional arguments to lower level functions</p>
</dd>
</dl>

</div>


<hr>
<a id="method-ml_model-response"></a>



<h4>Method <code>response()</code></h4>

<p>Extract response from data
</p>


<h5>Usage</h5>

<div class="r"><pre>ml_model$response(data, ...)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>data</code></dt><dd><p>data.frame</p>
</dd>
<dt><code>...</code></dt><dd><p>additional arguments to 'design'</p>
</dd>
</dl>

</div>


<hr>
<a id="method-ml_model-design"></a>



<h4>Method <code>design()</code></h4>

<p>Extract design matrix (features) from data
</p>


<h5>Usage</h5>

<div class="r"><pre>ml_model$design(data, ...)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>data</code></dt><dd><p>data.frame</p>
</dd>
<dt><code>...</code></dt><dd><p>additional arguments to 'design'</p>
</dd>
</dl>

</div>


<hr>
<a id="method-ml_model-opt"></a>



<h4>Method <code>opt()</code></h4>

<p>Get options
</p>


<h5>Usage</h5>

<div class="r"><pre>ml_model$opt(arg, ...)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>arg</code></dt><dd><p>name of option to get value of</p>
</dd>
<dt><code>...</code></dt><dd><p>additional arguments to lower level functions</p>
</dd>
</dl>

</div>


<hr>
<a id="method-ml_model-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>ml_model$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>




<h3>Author(s)</h3>

<p>Klaus KÃ¤hler Holst
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(iris)
rf &lt;- function(formula, ...)
ml_model$new(formula, info="grf::probability_forest",
  estimate=function(x,y, ...) grf::probability_forest(X=x, Y=y, ...),
  predict=function(object, newdata)
             predict(object, newdata)$predictions, ...)

args &lt;- expand.list(num.trees=c(100,200), mtry=1:3,
          formula=c(Species ~ ., Species ~ Sepal.Length + Sepal.Width))
models &lt;- lapply(args, function(par) do.call(rf, par))

x &lt;- models[[1]]$clone()
x$estimate(iris)
predict(x, newdata=head(iris))

 # Reduce Ex. timing
a &lt;- targeted::cv(models, data=iris)
cbind(coef(a), attr(args, "table"))


ff &lt;- ml_model$new(estimate=function(y,x) lm.fit(x=x, y=y),
        predict=function(object, newdata) newdata%*%object$coefficients)
## tmp &lt;- ff$estimate(y, x=x)
## ff$predict(x)
</code></pre>

<hr>
<h2 id='NB'>Naive Bayes</h2><span id='topic+NB'></span><span id='topic+NB2'></span>

<h3>Description</h3>

<p>Naive Bayes Classifier
</p>


<h3>Usage</h3>

<pre><code class='language-R'>NB(
  formula,
  data,
  weights = NULL,
  kernel = FALSE,
  laplace.smooth = 0,
  prior = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="NB_+3A_formula">formula</code></td>
<td>
<p>Formula with syntax: response ~ predictors | weights</p>
</td></tr>
<tr><td><code id="NB_+3A_data">data</code></td>
<td>
<p>data.frame</p>
</td></tr>
<tr><td><code id="NB_+3A_weights">weights</code></td>
<td>
<p>optional frequency weights</p>
</td></tr>
<tr><td><code id="NB_+3A_kernel">kernel</code></td>
<td>
<p>If TRUE a kernel estimator is used for numeric predictors (otherwise a gaussian model is used)</p>
</td></tr>
<tr><td><code id="NB_+3A_laplace.smooth">laplace.smooth</code></td>
<td>
<p>Laplace smoothing</p>
</td></tr>
<tr><td><code id="NB_+3A_prior">prior</code></td>
<td>
<p>optional prior probabilities (default estimated from data)</p>
</td></tr>
<tr><td><code id="NB_+3A_...">...</code></td>
<td>
<p>additional arguments to lower level functions</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class '<code>NB</code>' is returned. See
<code><a href="#topic+NB-class">NB-class</a></code> for more details about this class and
its generic functions.
</p>


<h3>Author(s)</h3>

<p>Klaus K. Holst
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(iris)
m2 &lt;- NB(Species ~ Sepal.Width + Petal.Length, data=iris)
pr2 &lt;- predict(m2, newdata=iris)
</code></pre>

<hr>
<h2 id='NB-class'>NB class object</h2><span id='topic+NB-class'></span>

<h3>Description</h3>

<p>The functions <code><a href="#topic+NB">NB</a></code> returns an object of the type
<code>NB</code>.
</p>
<p>An object of class '<code>NB</code>' is a list with at least the following components:
</p>

<dl>
<dt>prior</dt><dd><p>Matrix with prior probabilities, i.e. marginal class probabilities Pr(class)</p>
</dd>
<dt>pcond</dt><dd><p>list of matrices with conditional probabilities of the features given
the classes (one list element per class), Pr(x|class)</p>
</dd>
<dt>classes</dt><dd><p>Names (character vector) of the classes</p>
</dd>
<dt>xvar</dt><dd><p>number of repetitions of the CV</p>
</dd>
<dt>xmodel</dt><dd><p>Number of folds of the CV</p>
</dd>
<dt>model</dt><dd><p>Number of folds of the CV</p>
</dd>
</dl>



<h3>Value</h3>

<p>objects of the S3 class '<code>NB</code>'
</p>


<h3>S3 generics</h3>

<p>The following S3 generic functions are available for an object of class <code>NB</code>:
</p>

<dl>
<dt><code>predict</code></dt><dd><p>Predict class probabilities for new features data.</p>
</dd>
<dt><code>print</code></dt><dd><p>Basic print method.</p>
</dd>
</dl>



<h3>See Also</h3>

<p><code><a href="#topic+NB">NB</a></code>, <code><a href="#topic+NB2">NB2</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## See example(NB) for examples
</code></pre>

<hr>
<h2 id='nondom'>Find non-dominated points of a set</h2><span id='topic+nondom'></span>

<h3>Description</h3>

<p>Find the non-dominated point of a set (minima of a point set).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nondom(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="nondom_+3A_x">x</code></td>
<td>
<p>matrix</p>
</td></tr>
<tr><td><code id="nondom_+3A_...">...</code></td>
<td>
<p>additional arguments to lower level functions</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A point x dominates y if it is never worse and at least in one case strictly better.
Formally, let f_i denote the ith coordinate of the condition (objective) function,
then for all i: f_i(x)&lt;=f_i(y) and there exists j: f_j(x)&lt;f_j(y).
</p>
<p>Based on the algorithm of Kung et al. 1975.
</p>


<h3>Value</h3>

<p>matrix
</p>


<h3>Author(s)</h3>

<p>Klaus KÃ¤hler Holst
</p>


<h3>Examples</h3>

<pre><code class='language-R'>rbind(
  c(1.0, 0.5),
  c(0.0, 1.0),
  c(1.0, 0.0),
  c(0.5, 1.0),
  c(1.0, 1.0),
  c(0.8, 0.8)) |&gt; nondom()
</code></pre>

<hr>
<h2 id='pava'>Pooled Adjacent Violators Algorithm</h2><span id='topic+pava'></span><span id='topic+isoreg'></span><span id='topic+isoregw'></span>

<h3>Description</h3>

<p>Pooled Adjacent Violators Algorithm
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pava(y, x = numeric(0), weights = numeric(0))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pava_+3A_y">y</code></td>
<td>
<p>response variable</p>
</td></tr>
<tr><td><code id="pava_+3A_x">x</code></td>
<td>
<p>(optional) predictor vector (otherwise y is assumed
to be a priori sorted according to relevant predictor)</p>
</td></tr>
<tr><td><code id="pava_+3A_weights">weights</code></td>
<td>
<p>weights (optional) weights</p>
</td></tr>
</table>


<h3>Value</h3>

<p>List with index (idx) of jump points and values (value)
at each jump point.
</p>


<h3>Author(s)</h3>

<p>Klaus K. Holst
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- runif(5e3, -5, 5)
pr &lt;- lava::expit(-1 + x)
y &lt;- rbinom(length(pr), 1, pr)
pv &lt;- pava(y, x)
plot(pr ~ x, cex=0.3)
with(pv, lines(sort(x)[index], value, col="red", type="s"))
</code></pre>

<hr>
<h2 id='predict.density'>Prediction for kernel density estimates</h2><span id='topic+predict.density'></span>

<h3>Description</h3>

<p>Kernel density estimator predictions
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'density'
predict(object, xnew, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.density_+3A_object">object</code></td>
<td>
<p>density object</p>
</td></tr>
<tr><td><code id="predict.density_+3A_xnew">xnew</code></td>
<td>
<p>New data on which to make predictions for</p>
</td></tr>
<tr><td><code id="predict.density_+3A_...">...</code></td>
<td>
<p>additional arguments to lower level functions</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Klaus K. Holst
</p>

<hr>
<h2 id='predict.NB'>Predictions for Naive Bayes Classifier</h2><span id='topic+predict.NB'></span>

<h3>Description</h3>

<p>Naive Bayes Classifier predictions
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'NB'
predict(object, newdata, expectation = NULL, threshold = c(0.001, 0.001), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.NB_+3A_object">object</code></td>
<td>
<p>density object</p>
</td></tr>
<tr><td><code id="predict.NB_+3A_newdata">newdata</code></td>
<td>
<p>new data on which to make predictions</p>
</td></tr>
<tr><td><code id="predict.NB_+3A_expectation">expectation</code></td>
<td>
<p>Variable to calculate conditional expectation wrt
probabilities from NB classifier</p>
</td></tr>
<tr><td><code id="predict.NB_+3A_threshold">threshold</code></td>
<td>
<p>Threshold parameters. First element defines the threshold
on the probabilities and the second element the value to set those
truncated probabilities to.</p>
</td></tr>
<tr><td><code id="predict.NB_+3A_...">...</code></td>
<td>
<p>Additional arguments to lower level functions</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Klaus K. Holst
</p>

<hr>
<h2 id='RATE'>Responder Average Treatment Effect</h2><span id='topic+RATE'></span>

<h3>Description</h3>

<p>Estimation of the Average Treatment Effect among Responders
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RATE(
  response,
  post.treatment,
  treatment,
  data,
  family = gaussian(),
  M = 5,
  pr.treatment,
  treatment.level,
  SL.args.response = list(family = gaussian(), SL.library = c("SL.mean", "SL.glm")),
  SL.args.post.treatment = list(family = binomial(), SL.library = c("SL.mean", "SL.glm")),
  preprocess = NULL,
  efficient = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="RATE_+3A_response">response</code></td>
<td>
<p>Response formula (e.g, Y~D*A)</p>
</td></tr>
<tr><td><code id="RATE_+3A_post.treatment">post.treatment</code></td>
<td>
<p>Post treatment marker formula (e.g., D~W)</p>
</td></tr>
<tr><td><code id="RATE_+3A_treatment">treatment</code></td>
<td>
<p>Treatment formula (e.g, A~1)</p>
</td></tr>
<tr><td><code id="RATE_+3A_data">data</code></td>
<td>
<p>data.frame</p>
</td></tr>
<tr><td><code id="RATE_+3A_family">family</code></td>
<td>
<p>Exponential family for response (default gaussian)</p>
</td></tr>
<tr><td><code id="RATE_+3A_m">M</code></td>
<td>
<p>Number of folds in cross-fitting (M=1 is no cross-fitting)</p>
</td></tr>
<tr><td><code id="RATE_+3A_pr.treatment">pr.treatment</code></td>
<td>
<p>(optional) Randomization probability of treatment.</p>
</td></tr>
<tr><td><code id="RATE_+3A_treatment.level">treatment.level</code></td>
<td>
<p>Treatment level in binary treatment (default 1)</p>
</td></tr>
<tr><td><code id="RATE_+3A_sl.args.response">SL.args.response</code></td>
<td>
<p>Arguments to SuperLearner for the response model</p>
</td></tr>
<tr><td><code id="RATE_+3A_sl.args.post.treatment">SL.args.post.treatment</code></td>
<td>
<p>Arguments to SuperLearner for the post treatment indicator</p>
</td></tr>
<tr><td><code id="RATE_+3A_preprocess">preprocess</code></td>
<td>
<p>(optional) Data preprocessing function</p>
</td></tr>
<tr><td><code id="RATE_+3A_efficient">efficient</code></td>
<td>
<p>If TRUE, the estimate will be efficient. If FALSE, the estimate will be a simple plug-in estimate.</p>
</td></tr>
<tr><td><code id="RATE_+3A_...">...</code></td>
<td>
<p>Additional arguments to lower level functions</p>
</td></tr>
</table>


<h3>Value</h3>

<p>estimate object
</p>


<h3>Author(s)</h3>

<p>Andreas Nordland, Klaus K. Holst
</p>

<hr>
<h2 id='RATE.surv'>Responder Average Treatment Effect</h2><span id='topic+RATE.surv'></span>

<h3>Description</h3>

<p>Estimation of the Average Treatment Effect among Responders for Survival Outcomes
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RATE.surv(
  response,
  post.treatment,
  treatment,
  censoring,
  tau,
  data,
  M = 5,
  pr.treatment,
  call.response,
  args.response = list(),
  SL.args.post.treatment = list(family = binomial(), SL.library = c("SL.mean", "SL.glm")),
  call.censoring,
  args.censoring = list(),
  preprocess = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="RATE.surv_+3A_response">response</code></td>
<td>
<p>Response formula (e.g., Surv(time, event) ~ D + W).</p>
</td></tr>
<tr><td><code id="RATE.surv_+3A_post.treatment">post.treatment</code></td>
<td>
<p>Post treatment marker formula (e.g., D ~ W).</p>
</td></tr>
<tr><td><code id="RATE.surv_+3A_treatment">treatment</code></td>
<td>
<p>Treatment formula (e.g., A ~ 1).</p>
</td></tr>
<tr><td><code id="RATE.surv_+3A_censoring">censoring</code></td>
<td>
<p>Censoring formula (e.g., Surv(time, event == 0) ~ D + A + W)).</p>
</td></tr>
<tr><td><code id="RATE.surv_+3A_tau">tau</code></td>
<td>
<p>Time-point of interest, see Details.</p>
</td></tr>
<tr><td><code id="RATE.surv_+3A_data">data</code></td>
<td>
<p>data.frame.</p>
</td></tr>
<tr><td><code id="RATE.surv_+3A_m">M</code></td>
<td>
<p>Number of folds in cross-fitting (M=1 is no cross-fitting).</p>
</td></tr>
<tr><td><code id="RATE.surv_+3A_pr.treatment">pr.treatment</code></td>
<td>
<p>(optional) Randomization probability of treatment.</p>
</td></tr>
<tr><td><code id="RATE.surv_+3A_call.response">call.response</code></td>
<td>
<p>Model call for the response model (e.g. &quot;mets::phreg&quot;).</p>
</td></tr>
<tr><td><code id="RATE.surv_+3A_args.response">args.response</code></td>
<td>
<p>Additional arguments to the response model.</p>
</td></tr>
<tr><td><code id="RATE.surv_+3A_sl.args.post.treatment">SL.args.post.treatment</code></td>
<td>
<p>Additional arguments to SuperLearner for the post treatment indicator model.</p>
</td></tr>
<tr><td><code id="RATE.surv_+3A_call.censoring">call.censoring</code></td>
<td>
<p>Similar to call.response.</p>
</td></tr>
<tr><td><code id="RATE.surv_+3A_args.censoring">args.censoring</code></td>
<td>
<p>Similar to args.response.</p>
</td></tr>
<tr><td><code id="RATE.surv_+3A_preprocess">preprocess</code></td>
<td>
<p>(optional) Data pre-processing function.</p>
</td></tr>
<tr><td><code id="RATE.surv_+3A_...">...</code></td>
<td>
<p>Additional arguments to lower level data pre-processing functions.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Estimation of
</p>
<p style="text-align: center;"><code class="reqn">
\frac{P(T \leq \tau|A=1) - P(T \leq \tau|A=1)}{E[D|A=1]}
</code>
</p>

<p>under right censoring based on plug-in estimates of <code class="reqn">P(T \leq \tau|A=a)</code> and <code class="reqn">E[D|A=1]</code>.
</p>
<p>An efficient one-step estimator of <code class="reqn">P(T \leq \tau|A=a)</code> is constructed using
the efficient influence function
</p>
<p style="text-align: center;"><code class="reqn">
\frac{I\{A=a\}}{P(A = a)} \Big(\frac{\Delta}{S^c_{0}(\tilde T|X)} I\{\tilde T \leq \tau\} + \int_0^\tau \frac{S_0(u|X)-S_0(\tau|X)}{S_0(u|X)S^c_0(u|X)} d M^c_0(u|X))\Big)\\
+ \Big(1 - \frac{I\{A=a\}}{P(A = a)}\Big)F_0(\tau|A=a, W) - P(T \leq \tau|A=a).
</code>
</p>

<p>An efficient one-step estimator of <code class="reqn">E[D|A=1]</code> is constructed using the efficient influence function
</p>
<p style="text-align: center;"><code class="reqn">
\frac{A}{P(A = 1)}\left(D-E[D|A=1, W]\right) + E[D|A=1, W] -E[D|A=1].
</code>
</p>



<h3>Value</h3>

<p>estimate object
</p>


<h3>Author(s)</h3>

<p>Andreas Nordland, Klaus K. Holst
</p>

<hr>
<h2 id='riskreg'>Risk regression</h2><span id='topic+riskreg'></span><span id='topic+riskreg_fit'></span><span id='topic+riskreg_mle'></span>

<h3>Description</h3>

<p>Risk regression with binary exposure and nuisance model for the odds-product.
</p>
<p>Let <code class="reqn">A</code> be the binary exposure, <code class="reqn">V</code> the set of covariates, and
<code class="reqn">Y</code> the binary response variable, and define
<code class="reqn">p_a(v) = P(Y=1 \mid A=a, V=v), a\in\{0,1\}</code>.
</p>
<p>The <b>target parameter</b> is either the <em>relative risk</em>
</p>
<p style="text-align: center;"><code class="reqn">\mathrm{RR}(v) = \frac{p_1(v)}{p_0(v)}</code>
</p>

<p>or the <em>risk difference</em>
</p>
<p style="text-align: center;"><code class="reqn">\mathrm{RD}(v) = p_1(v)-p_0(v)</code>
</p>

<p>We assume a target parameter model given by either
</p>
<p style="text-align: center;"><code class="reqn">\log\{RR(v)\} = \alpha^t v</code>
</p>

<p>or
</p>
<p style="text-align: center;"><code class="reqn">\mathrm{arctanh}\{RD(v)\} = \alpha^t v</code>
</p>

<p>and similarly a working linear <b>nuisance model</b> for the <em>odds-product</em>
</p>
<p style="text-align: center;"><code class="reqn">\phi(v) = \log\left(\frac{p_{0}(v)p_{1}(v)}{(1-p_{0}(v))(1-p_{1}(v))}\right)
= \beta^t v</code>
</p>
<p>.
</p>
<p>A <b>propensity model</b> for <code class="reqn">E(A=1|V)</code> is also fitted using a logistic regression working model
</p>
<p style="text-align: center;"><code class="reqn">\mathrm{logit}\{E(A=1\mid V=v)\} = \gamma^t v.</code>
</p>

<p>If both the odds-product model and the propensity model are correct the estimator is efficient.
Further, the estimator is consistent in the union model, i.e., the estimator is
double-robust in the sense that only one of the two models needs to be correctly specified
to get a consistent estimate.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>riskreg(
  formula,
  nuisance = ~1,
  propensity = ~1,
  target = ~1,
  data,
  weights,
  type = "rr",
  optimal = TRUE,
  std.err = TRUE,
  start = NULL,
  mle = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="riskreg_+3A_formula">formula</code></td>
<td>
<p>formula (see details below)</p>
</td></tr>
<tr><td><code id="riskreg_+3A_nuisance">nuisance</code></td>
<td>
<p>nuisance model (formula)</p>
</td></tr>
<tr><td><code id="riskreg_+3A_propensity">propensity</code></td>
<td>
<p>propensity model (formula)</p>
</td></tr>
<tr><td><code id="riskreg_+3A_target">target</code></td>
<td>
<p>(optional) target model (formula)</p>
</td></tr>
<tr><td><code id="riskreg_+3A_data">data</code></td>
<td>
<p>data.frame</p>
</td></tr>
<tr><td><code id="riskreg_+3A_weights">weights</code></td>
<td>
<p>optional weights</p>
</td></tr>
<tr><td><code id="riskreg_+3A_type">type</code></td>
<td>
<p>type of association measure (rd og rr)</p>
</td></tr>
<tr><td><code id="riskreg_+3A_optimal">optimal</code></td>
<td>
<p>If TRUE optimal weights are calculated</p>
</td></tr>
<tr><td><code id="riskreg_+3A_std.err">std.err</code></td>
<td>
<p>If TRUE standard errors are calculated</p>
</td></tr>
<tr><td><code id="riskreg_+3A_start">start</code></td>
<td>
<p>optional starting values</p>
</td></tr>
<tr><td><code id="riskreg_+3A_mle">mle</code></td>
<td>
<p>Semi-parametric (double-robust) estimate or MLE (TRUE gives MLE)</p>
</td></tr>
<tr><td><code id="riskreg_+3A_...">...</code></td>
<td>
<p>additional arguments to unconstrained optimization routine (nlminb)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The 'formula' argument should be given as
<code>response ~ exposure | target-formula | nuisance-formula</code>
or
<code>response ~ exposure | target | nuisance | propensity</code>
</p>
<p>E.g., <code>riskreg(y ~ a | 1 | x+z | x+z, data=...)</code>
</p>
<p>Alternatively, the model can specifed using the target, nuisance and propensity arguments:
<code>riskreg(y ~ a, target=~1, nuisance=~x+z, ...)</code>
</p>
<p>The <code>riskreg_fit</code> function can be used with matrix inputs rather than formulas.
</p>


<h3>Value</h3>

<p>An object of class '<code>riskreg.targeted</code>' is returned. See <code><a href="#topic+targeted-class">targeted-class</a></code>
for more details about this class and its generic functions.
</p>


<h3>Author(s)</h3>

<p>Klaus K. Holst
</p>


<h3>References</h3>

<p>Richardson, T. S., Robins, J. M., &amp; Wang, L. (2017). On modeling and
estimation for the relative risk and risk difference. Journal of the
American Statistical Association, 112(519),
1121â1130. http://dx.doi.org/10.1080/01621459.2016.1192546
</p>


<h3>Examples</h3>

<pre><code class='language-R'>m &lt;- lvm(a[-2] ~ x,
         z ~ 1,
         lp.target[1] ~ 1,
         lp.nuisance[-1] ~ 2*x)
distribution(m,~a) &lt;- binomial.lvm("logit")
m &lt;- binomial.rr(m, "y","a","lp.target","lp.nuisance")
d &lt;- sim(m,5e2,seed=1)

I &lt;- model.matrix(~1, d)
X &lt;- model.matrix(~1+x, d)
with(d, riskreg_mle(y, a, I, X, type="rr"))

with(d, riskreg_fit(y, a, nuisance=X, propensity=I, type="rr"))
riskreg(y ~ a | 1, nuisance=~x ,  data=d, type="rr")

## Model with same design matrix for nuisance and propensity model:
with(d, riskreg_fit(y, a, nuisance=X, type="rr"))

## a &lt;- riskreg(y ~ a, target=~z, nuisance=~x,  propensity=~x, data=d, type="rr")
a &lt;- riskreg(y ~ a | z, nuisance=~x,  propensity=~x, data=d, type="rr")
a
predict(a, d[1:5,])

riskreg(y ~ a, nuisance=~x,  data=d, type="rr", mle=TRUE)

</code></pre>

<hr>
<h2 id='riskreg_cens'>Binary regression models with right censored outcomes</h2><span id='topic+riskreg_cens'></span>

<h3>Description</h3>

<p>Binary regression models with right censored outcomes
</p>


<h3>Usage</h3>

<pre><code class='language-R'>riskreg_cens(
  response,
  censoring,
  treatment = NULL,
  prediction = NULL,
  data,
  newdata,
  tau,
  type = "risk",
  M = 1,
  call.response = "phreg",
  args.response = list(),
  call.censoring = "phreg",
  args.censoring = list(),
  preprocess = NULL,
  efficient = TRUE,
  control = list(),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="riskreg_cens_+3A_response">response</code></td>
<td>
<p>Response formula (e.g., Surv(time, event) ~ D + W).</p>
</td></tr>
<tr><td><code id="riskreg_cens_+3A_censoring">censoring</code></td>
<td>
<p>Censoring formula (e.g., Surv(time, event == 0) ~ D + A +
W)).</p>
</td></tr>
<tr><td><code id="riskreg_cens_+3A_treatment">treatment</code></td>
<td>
<p>Optional treatment model (ml_model)</p>
</td></tr>
<tr><td><code id="riskreg_cens_+3A_prediction">prediction</code></td>
<td>
<p>Optional prediction model (ml_model)</p>
</td></tr>
<tr><td><code id="riskreg_cens_+3A_data">data</code></td>
<td>
<p>data.frame.</p>
</td></tr>
<tr><td><code id="riskreg_cens_+3A_newdata">newdata</code></td>
<td>
<p>Optional data.frame. In this case the uncentered influence
function evalued in 'newdata' is returned with nuisance parameters
obtained from 'data'.</p>
</td></tr>
<tr><td><code id="riskreg_cens_+3A_tau">tau</code></td>
<td>
<p>Time-point of interest, see Details.</p>
</td></tr>
<tr><td><code id="riskreg_cens_+3A_type">type</code></td>
<td>
<p>&quot;risk&quot;, &quot;treatment&quot;, &quot;rmst&quot;, &quot;brier&quot;</p>
</td></tr>
<tr><td><code id="riskreg_cens_+3A_m">M</code></td>
<td>
<p>Number of folds in cross-fitting (M=1 is no cross-fitting).</p>
</td></tr>
<tr><td><code id="riskreg_cens_+3A_call.response">call.response</code></td>
<td>
<p>Model call for the response model (e.g. &quot;mets::phreg&quot;).</p>
</td></tr>
<tr><td><code id="riskreg_cens_+3A_args.response">args.response</code></td>
<td>
<p>Additional arguments to the response model.</p>
</td></tr>
<tr><td><code id="riskreg_cens_+3A_call.censoring">call.censoring</code></td>
<td>
<p>Similar to call.response.</p>
</td></tr>
<tr><td><code id="riskreg_cens_+3A_args.censoring">args.censoring</code></td>
<td>
<p>Similar to args.response.</p>
</td></tr>
<tr><td><code id="riskreg_cens_+3A_preprocess">preprocess</code></td>
<td>
<p>(optional) Data pre-processing function.</p>
</td></tr>
<tr><td><code id="riskreg_cens_+3A_efficient">efficient</code></td>
<td>
<p>If FALSE an IPCW estimator is returned</p>
</td></tr>
<tr><td><code id="riskreg_cens_+3A_control">control</code></td>
<td>
<p>See details</p>
</td></tr>
<tr><td><code id="riskreg_cens_+3A_...">...</code></td>
<td>
<p>Additional arguments to lower level data pre-processing
functions.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The one-step estimator depends on the calculation of an integral
wrt. the martingale process corresponding to the counting process N(t) =
I(C&gt;min(T,tau)). This can be decomposed into an integral wrt the counting
process, <code class="reqn">dN_c(t)</code> and the compensator <code class="reqn">d\Lambda_c(t)</code> where the
latter term can be computational intensive to calculate. Rather than
calculating this integral in all observed time points, we can make a
coarser evaluation which can be controlled by setting <code>control=(sample=N)</code>.
With <code>N=0</code> the (computational intensive) standard evaluation is used.##'
</p>


<h3>Value</h3>

<p>estimate object
</p>


<h3>Author(s)</h3>

<p>Klaus K. Holst, Andreas Nordland
</p>

<hr>
<h2 id='scoring'>Predictive model scoring</h2><span id='topic+scoring'></span>

<h3>Description</h3>

<p>Predictive model scoring
</p>


<h3>Usage</h3>

<pre><code class='language-R'>scoring(
  response,
  ...,
  type = "quantitative",
  levels = NULL,
  metrics = NULL,
  weights = NULL,
  names = NULL,
  messages = 1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="scoring_+3A_response">response</code></td>
<td>
<p>Observed response</p>
</td></tr>
<tr><td><code id="scoring_+3A_...">...</code></td>
<td>
<p>model predictions (continuous predictions or class probabilities
(matrices))</p>
</td></tr>
<tr><td><code id="scoring_+3A_type">type</code></td>
<td>
<p>continuous or categorical response (the latter is automatically
chosen if response is a factor, otherwise a continuous response is
assumed)</p>
</td></tr>
<tr><td><code id="scoring_+3A_levels">levels</code></td>
<td>
<p>(optional) unique levels in response variable</p>
</td></tr>
<tr><td><code id="scoring_+3A_metrics">metrics</code></td>
<td>
<p>which metrics to report</p>
</td></tr>
<tr><td><code id="scoring_+3A_weights">weights</code></td>
<td>
<p>optional frequency weights</p>
</td></tr>
<tr><td><code id="scoring_+3A_names">names</code></td>
<td>
<p>optional names of models coments (given as ..., alternatively
these can be named arguments)</p>
</td></tr>
<tr><td><code id="scoring_+3A_messages">messages</code></td>
<td>
<p>controls amount of messages/warnings (0: none)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Numeric matrix of dimension m x p, where m is the number of
different models and p is the number of model metrics
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(iris)
set.seed(1)
dat &lt;- csplit(iris,2)
g1 &lt;- NB(Species ~ Sepal.Width + Petal.Length, data=dat[[1]])
g2 &lt;- NB(Species ~ Sepal.Width, data=dat[[1]])
pr1 &lt;- predict(g1, newdata=dat[[2]], wide=TRUE)
pr2 &lt;- predict(g2, newdata=dat[[2]], wide=TRUE)
table(colnames(pr1)[apply(pr1,1,which.max)], dat[[2]]$Species)
table(colnames(pr2)[apply(pr2,1,which.max)], dat[[2]]$Species)
scoring(dat[[2]]$Species, pr1=pr1, pr2=pr2)
## quantitative response:
scoring(response=1:10, prediction=rnorm(1:10))
</code></pre>

<hr>
<h2 id='SL'>SuperLearner wrapper for ml_model</h2><span id='topic+SL'></span>

<h3>Description</h3>

<p>SuperLearner wrapper for ml_model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SL(
  formula = ~.,
  ...,
  SL.library = c("SL.mean", "SL.glm"),
  binomial = FALSE,
  data = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SL_+3A_formula">formula</code></td>
<td>
<p>Model design</p>
</td></tr>
<tr><td><code id="SL_+3A_...">...</code></td>
<td>
<p>Additional arguments for SuperLearner::SuperLearner</p>
</td></tr>
<tr><td><code id="SL_+3A_sl.library">SL.library</code></td>
<td>
<p>character vector of prediction algorithms</p>
</td></tr>
<tr><td><code id="SL_+3A_binomial">binomial</code></td>
<td>
<p>boolean specifying binomial or gaussian family (default FALSE)</p>
</td></tr>
<tr><td><code id="SL_+3A_data">data</code></td>
<td>
<p>Optional data.frame</p>
</td></tr>
</table>


<h3>Value</h3>

<p>ml_model object
</p>


<h3>Author(s)</h3>

<p>Klaus KÃ¤hler Holst
</p>

<hr>
<h2 id='softmax'>Softmax transformation</h2><span id='topic+softmax'></span>

<h3>Description</h3>

<p>Softmax transformation
</p>


<h3>Usage</h3>

<pre><code class='language-R'>softmax(x, log = FALSE, ref = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="softmax_+3A_x">x</code></td>
<td>
<p>Input matrix (e.g., linear predictors of multinomial logistic model)</p>
</td></tr>
<tr><td><code id="softmax_+3A_log">log</code></td>
<td>
<p>Return on log-scale (default FALSE)</p>
</td></tr>
<tr><td><code id="softmax_+3A_ref">ref</code></td>
<td>
<p>Add reference level (add 0 column to x)</p>
</td></tr>
<tr><td><code id="softmax_+3A_...">...</code></td>
<td>
<p>Additional arguments to lower level functions</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Numeric matrix of dimension n x p, where <code>n= nrow(x)</code> and
<code>p = ncol(x) + (ref==TRUE)</code>
</p>

<hr>
<h2 id='solve_ode'>Solve ODE</h2><span id='topic+solve_ode'></span>

<h3>Description</h3>

<p>Solve ODE with Runge-Kutta method (RK4)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>solve_ode(ode_ptr, input, init, par = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="solve_ode_+3A_ode_ptr">ode_ptr</code></td>
<td>
<p>pointer (externalptr) to C++ function or an R function</p>
</td></tr>
<tr><td><code id="solve_ode_+3A_input">input</code></td>
<td>
<p>Input matrix. 1st column specifies the time points</p>
</td></tr>
<tr><td><code id="solve_ode_+3A_init">init</code></td>
<td>
<p>Initial conditions</p>
</td></tr>
<tr><td><code id="solve_ode_+3A_par">par</code></td>
<td>
<p>Parameters defining the ODE (parsed to ode_ptr)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The external point should be created with the function <code>targeted::specify_ode</code>.
</p>


<h3>Value</h3>

<p>Matrix with solution
</p>


<h3>Author(s)</h3>

<p>Klaus KÃ¤hler Holst
</p>


<h3>See Also</h3>

<p>specify_ode
</p>


<h3>Examples</h3>

<pre><code class='language-R'>example(specify_ode)
</code></pre>

<hr>
<h2 id='specify_ode'>Specify Ordinary Differential Equation (ODE)</h2><span id='topic+specify_ode'></span>

<h3>Description</h3>

<p>Define compiled code for ordinary differential equation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>specify_ode(code, fname = NULL, pname = c("dy", "x", "y", "p"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="specify_ode_+3A_code">code</code></td>
<td>
<p>string with the body of the function definition (see details)</p>
</td></tr>
<tr><td><code id="specify_ode_+3A_fname">fname</code></td>
<td>
<p>Optional name of the exported C++ function</p>
</td></tr>
<tr><td><code id="specify_ode_+3A_pname">pname</code></td>
<td>
<p>Vector of variable names (results, inputs, states, parameters)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The model (<code>code</code>) should be specified as the body of of C++ function.
The following variables are defined bye default (see the argument <code>pname</code>)
</p>

<dl>
<dt>dy</dt><dd><p>Vector with derivatives, i.e. the rhs of the ODE (the result).</p>
</dd>
<dt>x</dt><dd><p>Vector with the first element being the time, and the following
elements additional exogenous input variables,</p>
</dd>
<dt>y</dt><dd><p>Vector with the dependent variable</p>
</dd>
<dt>p</dt><dd><p>Parameter vector</p>
</dd>
</dl>

<p><code class="reqn">y'(t) = f_{p}(x(t), y(t))</code>
All variables are treated as Armadillo (http://arma.sourceforge.net/) vectors/matrices.
</p>
<p>As an example consider the <em>Lorenz Equations</em>
<code class="reqn">\frac{dx_{t}}{dt} = \sigma(y_{t}-x_{t})</code>
<code class="reqn">\frac{dy_{t}}{dt} = x_{t}(\rho-z_{t})-y_{t}</code>
<code class="reqn">\frac{dz_{t}}{dt} = x_{t}y_{t}-\beta z_{t}</code>
</p>
<p>We can specify this model as
<code>ode &lt;- 'dy(0) = p(0)*(y(1)-y(0));
      dy(1) = y(0)*(p(1)-y(2));
      dy(2) = y(0)*y(1)-p(2)*y(2);'</code>
<code>dy &lt;- specify_ode(ode)</code>
</p>
<p>As an example of model with exogenous inputs consider the following ODE:
<code class="reqn">y'(t) = \beta_{0} + \beta_{1}y(t) + \beta_{2}y(t)x(t) + \beta_{3}x(t)\cdot t</code>
This could be specified as
<code>mod &lt;- 'double t = x(0);
              dy = p(0) + p(1)*y + p(2)*x(1)*y + p(3)*x(1)*t;'</code>
<code>dy &lt;- specify_ode(mod)</code>##'
</p>


<h3>Value</h3>

<p>pointer (externalptr) to C++ function
</p>


<h3>Author(s)</h3>

<p>Klaus KÃ¤hler Holst
</p>


<h3>See Also</h3>

<p>solve_ode
</p>

<hr>
<h2 id='targeted-class'>targeted class object</h2><span id='topic+targeted-class'></span><span id='topic+riskreg.targeted'></span><span id='topic+ate.targeted'></span>

<h3>Description</h3>

<p>The functions <code><a href="#topic+riskreg">riskreg</a></code> and <code><a href="#topic+ate">ate</a></code> returns an object of the type <code>targeted</code>.
</p>
<p>An object of class '<code>targeted</code>' is a list with at least the following components:
</p>

<dl>
<dt>estimate</dt><dd><p>An <code>estimate</code> object with the target parameter
estimates (see <code><a href="lava.html#topic+estimate.default">estimate.default</a></code>)</p>
</dd>
<dt>opt</dt><dd><p>Object returned from the applied optimization routine</p>
</dd>
<dt>npar</dt><dd><p>number of parameters of the model (target and nuisance)</p>
</dd>
<dt>type</dt><dd><p>String describing the model</p>
</dd>
</dl>



<h3>Value</h3>

<p>objects of the S3 class '<code>targeted</code>'
</p>


<h3>S3 generics</h3>

<p>The following S3 generic functions are available for an object of class <code>targeted</code>:
</p>

<dl>
<dt><code>coef</code></dt><dd><p>Extract target coefficients of the estimated model.</p>
</dd>
<dt><code>vcov</code></dt><dd><p>Extract the variance-covariance matrix of the target parameters.</p>
</dd>
<dt><code>IC</code></dt><dd><p>Extract the estimated influence function.</p>
</dd>
<dt><code>print</code></dt><dd><p>Print estimates of the target parameters.</p>
</dd>
<dt><code>summary</code></dt><dd><p>Extract information on both target parameters and estimated nuisance model.</p>
</dd></dl>
<p>'

</p>


<h3>See Also</h3>

<p><code><a href="#topic+riskreg">riskreg</a></code>, <code><a href="#topic+ate">ate</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## See example(riskreg) for examples
</code></pre>

<hr>
<h2 id='targeted-package'>targeted: Targeted Inference</h2><span id='topic+targeted-package'></span><span id='topic+targeted'></span>

<h3>Description</h3>

<p>Various methods for targeted and semiparametric inference including augmented inverse probability weighted (AIPW) estimators for missing data and causal inference (Bang and Robins (2005) <a href="https://doi.org/10.1111/j.1541-0420.2005.00377.x">doi:10.1111/j.1541-0420.2005.00377.x</a>), variable importance and conditional average treatment effects (CATE) (van der Laan (2006) <a href="https://doi.org/10.2202/1557-4679.1008">doi:10.2202/1557-4679.1008</a>), estimators for risk differences and relative risks (Richardson et al. (2017) <a href="https://doi.org/10.1080/01621459.2016.1192546">doi:10.1080/01621459.2016.1192546</a>), assumption lean inference for generalized linear model parameters (Vansteelandt et al. (2022) <a href="https://doi.org/10.1111/rssb.12504">doi:10.1111/rssb.12504</a>).
</p>
<p>Methods for targeted and semiparametric inference.
</p>


<h3>Author(s)</h3>

<p><strong>Maintainer</strong>: Klaus K. Holst <a href="mailto:klaus@holst.it">klaus@holst.it</a>
</p>
<p>Authors:
</p>

<ul>
<li><p> Andreas Nordland <a href="mailto:andreasnordland@gmail.com">andreasnordland@gmail.com</a>
</p>
</li></ul>

<p>Klaus K. Holst (Maintainer) <a href="mailto:klaus@holst.it">klaus@holst.it</a>
</p>


<h3>See Also</h3>

<p>Useful links:
</p>

<ul>
<li><p> Report bugs at <a href="https://github.com/kkholst/targeted/issues">https://github.com/kkholst/targeted/issues</a>
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
example(riskreg)
example(cate)
example(ate)
example(calibration)

## End(Not run)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
