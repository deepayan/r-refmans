<!DOCTYPE html><html lang="en"><head><title>Help for package KSPM</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {KSPM}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#case.names.kspm'><p>Case names of fitted models</p></a></li>
<li><a href='#coef.kspm'><p>Extract Model Coefficients</p></a></li>
<li><a href='#confint.kspm'><p>Confidence interavls for linear part of model parameters</p></a></li>
<li><a href='#cooks.distance.kspm'><p>Cook's distance for a Kernel Semi Parametric Model Fit</p></a></li>
<li><a href='#csm'><p>Conventional and Social media features of 187 movies.</p></a></li>
<li><a href='#derivatives'><p>Computing kernel function derivatives</p></a></li>
<li><a href='#deviance.kspm'><p>Model deviance</p></a></li>
<li><a href='#energy'><p>Energy consumption measuring hourly during 22 days</p></a></li>
<li><a href='#extractAIC.kspm'><p>Extract AIC from a Kernel Semi Parametric Model</p></a></li>
<li><a href='#fitted.kspm'><p>Extract Model Fitted values</p></a></li>
<li><a href='#flexible.summary'><p>Summarizing Kernel Semi parametric Model Fits with flexible parameters for Davies' approximation method</p></a></li>
<li><a href='#get.parameters'><p>compute Kernel Semi Parametric model parameters</p></a></li>
<li><a href='#hypercoef'><p>Extract Model Hyper-parameter</p></a></li>
<li><a href='#info.kspm'><p>Giving information about Kernel Semi parametric Model Fits</p></a></li>
<li><a href='#Kernel'><p>Create a Kernel Object</p></a></li>
<li><a href='#kernel.function'><p>Kernel Functions</p></a></li>
<li><a href='#kernel.list'><p>List of kernel parts included in the kernel semi parametric model</p></a></li>
<li><a href='#kernel.matrix'><p>Kernel matrix</p></a></li>
<li><a href='#kernel.method'><p>some internal methods in computation of kernel semi parametric model</p></a></li>
<li><a href='#kspm'><p>Fitting Kernel Semi Parametric model</p></a></li>
<li><a href='#kspmControl'><p>Control various aspects of the optimisation problem</p></a></li>
<li><a href='#logLik.kspm'><p>Log Likelihood of a kspm Object</p></a></li>
<li><a href='#lossFunction.looe'><p>Computation of the leave one out error (LOOE) in kernel semi parametric model</p></a></li>
<li><a href='#nobs.kspm'><p>Extract the number of observations from a Kernel Semi parametric Model Fit</p></a></li>
<li><a href='#plot.derivatives'><p>Plot derivatives of a kspm object</p></a></li>
<li><a href='#plot.kspm'><p>Plot Diagnostics for a kspm Object</p></a></li>
<li><a href='#predict.kspm'><p>Predicting Kernel Semi parametric Model Fits</p></a></li>
<li><a href='#print.kspm'><p>Print results from a Kernel Semi parametric Model Fit</p></a></li>
<li><a href='#residuals.kspm'><p>Extract residuals from a Kernel Semi Parametric Model</p></a></li>
<li><a href='#rstandard.kspm'><p>Standardized residuals for Kernel Semi parametric Model Fits</p></a></li>
<li><a href='#search.parameters'><p>Optimisation to cumpute hyperparameter in Kernel Semi Parametric model</p></a></li>
<li><a href='#sigma.kspm'><p>Extract residuals standard deviation</p></a></li>
<li><a href='#stepKSPM'><p>Choose a model by AIC or BIC in a Stepwise Algorithm</p></a></li>
<li><a href='#summary.kspm'><p>Summarizing Kernel Semi parametric Model Fits</p></a></li>
<li><a href='#test.function'><p>Score Tests for kernel part in kernel semi parametric model</p></a></li>
<li><a href='#variable.names.kspm'><p>Variable names of fitted models</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Title:</td>
<td>Kernel Semi-Parametric Models</td>
</tr>
<tr>
<td>Version:</td>
<td>0.2.1</td>
</tr>
<tr>
<td>Description:</td>
<td>To fit the kernel semi-parametric model and its extensions. It allows multiple kernels and unlimited interactions in the same model. Coefficients are estimated by maximizing a penalized log-likelihood; penalization terms and hyperparameters are estimated by minimizing leave-one-out error. It includes predictions with confidence/prediction intervals, statistical tests for the significance of each kernel, a procedure for variable selection and graphical tools for diagnostics and interpretation of covariate effects. Currently it is implemented for continuous dependent variables. The package is based on the paper of Liu et al. (2007), &lt;<a href="https://doi.org/10.1111%2Fj.1541-0420.2007.00799.x">doi:10.1111/j.1541-0420.2007.00799.x</a>&gt;.</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0)</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>6.1.1</td>
</tr>
<tr>
<td>Imports:</td>
<td>expm, CompQuadForm, DEoptim</td>
</tr>
<tr>
<td>Suggests:</td>
<td>testthat, knitr, rmarkdown</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2020-08-08 07:49:11 UTC; caths</td>
</tr>
<tr>
<td>Author:</td>
<td>Catherine Schramm [aut, cre],
  Aurelie Labbe [ctb],
  Celia M. T. Greenwood [ctb]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Catherine Schramm &lt;cath.schramm@gmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2020-08-10 13:32:11 UTC</td>
</tr>
</table>
<hr>
<h2 id='case.names.kspm'>Case names of fitted models</h2><span id='topic+case.names.kspm'></span>

<h3>Description</h3>

<p>Simple utility returning names of cases involved in a kernel semi parametric model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'kspm'
case.names(object, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="case.names.kspm_+3A_object">object</code></td>
<td>
<p>an object of class &quot;kspm&quot;, usually, a result of a call to <code>kspm</code>.</p>
</td></tr>
<tr><td><code id="case.names.kspm_+3A_...">...</code></td>
<td>
<p>additional optional argument (currently unused).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a character vector.
</p>


<h3>Author(s)</h3>

<p>Catherine Schramm, Aurelie Labbe, Celia Greenwood
</p>


<h3>See Also</h3>

<p><a href="#topic+kspm">kspm</a> for fitting model, <a href="#topic+nobs.kspm">nobs.kspm</a>, <a href="#topic+variable.names.kspm">variable.names.kspm</a>.
</p>

<hr>
<h2 id='coef.kspm'>Extract Model Coefficients</h2><span id='topic+coef.kspm'></span>

<h3>Description</h3>

<p>Returns linear and kernel coefficients for a model of class &quot;kspm&quot;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'kspm'
coef(object, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="coef.kspm_+3A_object">object</code></td>
<td>
<p>an object of class &quot;kspm&quot;, usually, a result of a call to <code>kspm</code>.</p>
</td></tr>
<tr><td><code id="coef.kspm_+3A_...">...</code></td>
<td>
<p>additional optional argument (currently unused).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Two matrices of coefficients.
</p>
<table role = "presentation">
<tr><td><code>linear</code></td>
<td>
<p>A vector of coefficients for linear part. One row is one variable.</p>
</td></tr>
<tr><td><code>kernel</code></td>
<td>
<p>A matrix of coefficients for linear part. One row is one subject, one column is one kernel part.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Catherine Schramm, Aurelie Labbe, Celia Greenwood
</p>


<h3>References</h3>

<p>Liu, D., Lin, X., and Ghosh, D. (2007). Semiparametric regression of multidimensional genetic pathway data: least squares kernel machines and linear mixed models. Biometrics, 63(4), 1079:1088.
</p>


<h3>See Also</h3>

<p><a href="#topic+kspm">kspm</a> for fitting model.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- 1:15
z1 &lt;- runif(15, 1, 6)
z2 &lt;- rnorm(15, 1, 2)
y &lt;- 3*x + (z1 + z2)^2 + rnorm(15, 0, 2)
fit &lt;- kspm(y, linear = ~ x, kernel = ~ Kernel(~ z1 + z2,
kernel.function = "polynomial", d= 2, rho = 1, gamma = 0))
coef(fit)

</code></pre>

<hr>
<h2 id='confint.kspm'>Confidence interavls for linear part of model parameters</h2><span id='topic+confint.kspm'></span>

<h3>Description</h3>

<p>Computes confidence intervals for one or more parameters in the linear part of a fitted model of class &quot;kspm&quot;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'kspm'
confint(object, parm = NULL, level = 0.95, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="confint.kspm_+3A_object">object</code></td>
<td>
<p>an object of class &quot;kspm&quot;, usually, a result of a call to <code>kspm</code>.</p>
</td></tr>
<tr><td><code id="confint.kspm_+3A_parm">parm</code></td>
<td>
<p>a vector of names specifying which parameters are to be given confidence intervals. If missing, all parameters are considered.</p>
</td></tr>
<tr><td><code id="confint.kspm_+3A_level">level</code></td>
<td>
<p>the confidence level required. By default 0.95.</p>
</td></tr>
<tr><td><code id="confint.kspm_+3A_...">...</code></td>
<td>
<p>additional optional argument (currently unused).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For objects of class &quot;kspm&quot;, the confidence interval is based on student distribution and effective degree of freedom of the model.
</p>


<h3>Value</h3>

<p>A matrix with column giving lower and upper confidence limits for each parameter. These are labelled as <code class="reqn">\frac{1-level}{2}</code> and <code class="reqn">1 - \frac{1-level}{2}</code> in percentage.
</p>


<h3>Author(s)</h3>

<p>Catherine Schramm, Aurelie Labbe, Celia Greenwood
</p>


<h3>See Also</h3>

<p><a href="#topic+kspm">kspm</a> for fitting model, <a href="#topic+summary.kspm">summary.kspm</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- 1:15
z1 &lt;- runif(15, 1, 6)
z2 &lt;- rnorm(15, 1, 2)
y &lt;- 3*x + (z1 + z2)^2 + rnorm(15, 0, 2)
fit &lt;- kspm(y, linear = ~ x, kernel = ~ Kernel(~ z1 + z2,
kernel.function = "polynomial", d= 2, rho = 1, gamma = 0))
confint(fit)

</code></pre>

<hr>
<h2 id='cooks.distance.kspm'>Cook's distance for a Kernel Semi Parametric Model Fit</h2><span id='topic+cooks.distance.kspm'></span>

<h3>Description</h3>

<p>Computes the Cook's distance method for an object of class &quot;kspm&quot;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'kspm'
cooks.distance(model, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cooks.distance.kspm_+3A_model">model</code></td>
<td>
<p>an model of class &quot;kspm&quot;, usually, a result of a call to <code>kspm</code>.</p>
</td></tr>
<tr><td><code id="cooks.distance.kspm_+3A_...">...</code></td>
<td>
<p>furter arguments passed to or from other methods (currently unused).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Cook's distance values (<code class="reqn">C_i</code>) are computed as follows: <code class="reqn">C_i = \frac{e_i^2 h_{ii}}{\hat{\sigma}^2 tr(H) (1-h_{ii})^2}</code> where e_i is the residual of subject i, h_ii is the i th diagonal element of Hat matrix H corresponding to the leverage associated with subject i and tr(H) is the trace of the Hat matrix H.
</p>


<h3>Value</h3>

<p>A vector containing Cook's distance values.
</p>


<h3>Author(s)</h3>

<p>Catherine Schramm, Aurelie Labbe, Celia Greenwood
</p>


<h3>See Also</h3>

<p><a href="#topic+kspm">kspm</a> for fitting model, <a href="#topic+residuals.kspm">residuals.kspm</a>, <a href="#topic+rstandard.kspm">rstandard.kspm</a>, <a href="#topic+plot.kspm">plot.kspm</a>.
</p>

<hr>
<h2 id='csm'>Conventional and Social media features of 187 movies.</h2><span id='topic+csm'></span>

<h3>Description</h3>

<p>A dataset containing the ratings and other attributes of 187 movies.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>csm
</code></pre>


<h3>Format</h3>

<p>A data frame with 187 rows and 13 variables:
</p>

<dl>
<dt>Year</dt><dd><p>year at which movies were projected on the screens</p>
</dd>
<dt>Ratings</dt><dd><p>ratings</p>
</dd>
<dt>Genre</dt><dd><p>genre of the movie</p>
</dd>
<dt>Gross</dt><dd><p>gross income in USD</p>
</dd>
<dt>Budget</dt><dd><p>budget in USD</p>
</dd>
<dt>Screens</dt><dd><p>number of screens in USA</p>
</dd>
<dt>Sequel</dt><dd><p>sequel</p>
</dd>
<dt>Sentiment</dt><dd><p>sentiment score</p>
</dd>
<dt>Views</dt><dd><p>number of views of movie trailer on Youtube</p>
</dd>
<dt>Likes</dt><dd><p>number of likes of movie trailer on Youtube</p>
</dd>
<dt>Dislikes</dt><dd><p>number of dislikes of movie trailer on Youtube</p>
</dd>
<dt>Comments</dt><dd><p>number of comments of movie trailer on Youtube</p>
</dd>
<dt>Aggregate.Followers</dt><dd><p>aggregate actor followers on Twitter</p>
</dd>
</dl>


<h3>Source</h3>

<p><a href="https://archive.ics.uci.edu/ml/index.php">https://archive.ics.uci.edu/ml/index.php</a>
</p>


<h3>References</h3>

<p>AHMED, Mehreen, JAHANGIR, Maham, AFZAL, Hammad, et al. Using Crowd-source based features from social media and Conventional features to predict the movies popularity. In : Smart City/SocialCom/SustainCom (SmartCity), 2015 IEEE International Conference on. IEEE, 2015. p. 273-278.
</p>

<hr>
<h2 id='derivatives'>Computing kernel function derivatives</h2><span id='topic+derivatives'></span>

<h3>Description</h3>

<p><code>derivatives</code> is a function for &quot;kspm&quot; object computing pointwise partial derivatives of <code class="reqn">h(Z)</code> accroding to each <code class="reqn">Z</code> variable.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>derivatives(object)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="derivatives_+3A_object">object</code></td>
<td>
<p>an object of class &quot;kspm&quot;, usually, a result of a call to <code>kspm</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>derivatives are not computed for interactions. If a variable is included in several kernels, the user may obtain the corresponding pointwise derivatives by summing the pointwise derivatives associated with each kernel.
</p>


<h3>Value</h3>

<p>an object of class 'derivatives'
</p>
<table role = "presentation">
<tr><td><code>derivmat</code></td>
<td>
<p>a list of <code class="reqn">n \times d</code> matrix (one for each kernel) where <code class="reqn">n</code> is the number of subjects and <code class="reqn">d</code> the number of variables included in the kernel</p>
</td></tr>
<tr><td><code>rawmat</code></td>
<td>
<p>a <code class="reqn">n \times q</code> matrix with all variables included in the kernel part of the model <code class="reqn">q</code> the number of variables included in the whole kernel part</p>
</td></tr>
<tr><td><code>scalemat</code></td>
<td>
<p>scaled version of rawmat</p>
</td></tr>
<tr><td><code>modelmat</code></td>
<td>
<p>matrix of correspondance between variable and kernels</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Catherine Schramm, Aurelie Labbe, Celia Greenwood
</p>


<h3>References</h3>

<p>Kim, Choongrak, Byeong U. Park, and Woochul Kim. &quot;Influence diagnostics in semiparametric regression models.&quot; Statistics and probability letters 60.1 (2002): 49:58.
</p>


<h3>See Also</h3>

<p><a href="#topic+plot.derivatives">plot.derivatives</a>
</p>

<hr>
<h2 id='deviance.kspm'>Model deviance</h2><span id='topic+deviance.kspm'></span>

<h3>Description</h3>

<p>Returns the deviance of a fitted model object of class &quot;kspm&quot;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'kspm'
deviance(object, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="deviance.kspm_+3A_object">object</code></td>
<td>
<p>an object of class &quot;kspm&quot;, usually, a result of a call to <code>kspm</code>, for which the deviance is desired.</p>
</td></tr>
<tr><td><code id="deviance.kspm_+3A_...">...</code></td>
<td>
<p>additional optional argument (currently unused).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function extracts deviance of a model fitted using <code>kspm</code> function. The returned deviance is the residual sum of square (RSS).
</p>


<h3>Value</h3>

<p>The value of the deviance extracted from the object <code>object</code>.
</p>


<h3>Author(s)</h3>

<p>Catherine Schramm, Aurelie Labbe, Celia Greenwood
</p>


<h3>See Also</h3>

<p><a href="#topic+kspm">kspm</a>, <a href="#topic+extractAIC.kspm">extractAIC.kspm</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- 1:15
y &lt;- 3*x + rnorm(15, 0, 2)
fit &lt;- kspm(y, kernel = ~ Kernel(x, kernel.function = "linear"))
deviance(fit)

</code></pre>

<hr>
<h2 id='energy'>Energy consumption measuring hourly during 22 days</h2><span id='topic+energy'></span>

<h3>Description</h3>

<p>A dataset containing the energy consumption and other attributes during 22 days.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>energy
</code></pre>


<h3>Format</h3>

<p>A data frame with 504 rows and 7 variables:
</p>

<dl>
<dt>power</dt><dd><p>energy consumption</p>
</dd>
<dt>date</dt><dd><p>date</p>
</dd>
<dt>Temperature</dt><dd><p>temperature</p>
</dd>
<dt>P</dt><dd><p>pression</p>
</dd>
<dt>HR</dt><dd><p>humidity rate</p>
</dd>
<dt>hour</dt><dd><p>hour (categorical)</p>
</dd>
<dt>hour.num</dt><dd><p>hour (numerical)</p>
</dd>
</dl>


<h3>Source</h3>

<p><a href="https://iles-ponant-edf-sei.opendatasoft.com">https://iles-ponant-edf-sei.opendatasoft.com</a>, <a href="https://www.infoclimat.fr">https://www.infoclimat.fr</a>
</p>

<hr>
<h2 id='extractAIC.kspm'>Extract AIC from a Kernel Semi Parametric Model</h2><span id='topic+extractAIC.kspm'></span>

<h3>Description</h3>

<p>Computes the Akaike Information Criterion (AIC) for a kspm fit.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'kspm'
extractAIC(fit, scale = NULL, k = 2,
  correction = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="extractAIC.kspm_+3A_fit">fit</code></td>
<td>
<p>fitted model, usually the result of <a href="#topic+kspm">kspm</a>.</p>
</td></tr>
<tr><td><code id="extractAIC.kspm_+3A_scale">scale</code></td>
<td>
<p>option not available for kspm fit.</p>
</td></tr>
<tr><td><code id="extractAIC.kspm_+3A_k">k</code></td>
<td>
<p>numeric specifying the 'weight' of the effective degrees of freedom (edf) part in the AIC formula. See details.</p>
</td></tr>
<tr><td><code id="extractAIC.kspm_+3A_correction">correction</code></td>
<td>
<p>boolean indicating if the corrected AIC should be computed instead of standard AIC, may be <code>TRUE</code> only for <code>k=2</code>. See details.</p>
</td></tr>
<tr><td><code id="extractAIC.kspm_+3A_...">...</code></td>
<td>
<p>additional optional argument (currently unused).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The criterion used is <code class="reqn">AIC = n log(RSS) + k (n-edf)</code> where <code class="reqn">RSS</code> is the residual sum of squares and <code class="reqn">edf</code> is the effective degree of freedom of the model. <code>k = 2</code> corresponds to the traditional AIC, using <code>k = log(n)</code> provides Bayesian Information Criterion (BIC) instead. For <code>k=2</code>, the corrected Akaike's Information Criterion (AICc) is obtained by <code class="reqn">AICc = AIC + \frac{2 (n-edf) (n-edf+1)}{(edf-1)}</code>.
</p>


<h3>Value</h3>

<p><code>extractAIC.kspm</code> returns a numeric value corresponding to AIC. Of note, the AIC obtained here differs from a constant to the AIC obtained with <code>extractAIC</code> applied to a <a href="stats.html#topic+lm">lm</a> object. If one wants to compare a <code>kspm</code> model with a <code>lm</code> model, it is preferrable to compute again the <code>lm</code> model using <a href="#topic+kspm">kspm</a> function by specifying <code>kernel = NULL</code> and apply <code>extractAIC</code> method on this model.
</p>


<h3>Author(s)</h3>

<p>Catherine Schramm, Aurelie Labbe, Celia Greenwood
</p>


<h3>References</h3>

<p>Liu, D., Lin, X., and Ghosh, D. (2007). Semiparametric regression of multidimensional genetic pathway data: least squares kernel machines and linear mixed models. Biometrics, 63(4), 1079:1088.
</p>


<h3>See Also</h3>

<p><a href="#topic+stepKSPM">stepKSPM</a> for variable selection procedure based on AIC.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- 1:15
y &lt;- 3*x + rnorm(15, 0, 2)
fit &lt;- kspm(y, kernel = ~ Kernel(x, kernel.function = "linear"))
extractAIC(fit)

</code></pre>

<hr>
<h2 id='fitted.kspm'>Extract Model Fitted values</h2><span id='topic+fitted.kspm'></span>

<h3>Description</h3>

<p>Returns fitted values for a model of class &quot;kspm&quot;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'kspm'
fitted(object, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fitted.kspm_+3A_object">object</code></td>
<td>
<p>an object of class &quot;kspm&quot;, usually, a result of a call to <code>kspm</code>.</p>
</td></tr>
<tr><td><code id="fitted.kspm_+3A_...">...</code></td>
<td>
<p>additional optional argument (currently unused).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The vector of fitted values.
</p>


<h3>Author(s)</h3>

<p>Catherine Schramm, Aurelie Labbe, Celia Greenwood
</p>


<h3>References</h3>

<p>Liu, D., Lin, X., and Ghosh, D. (2007). Semiparametric regression of multidimensional genetic pathway data: least squares kernel machines and linear mixed models. Biometrics, 63(4), 1079:1088.
</p>


<h3>See Also</h3>

<p><a href="#topic+kspm">kspm</a> for fitting model, <a href="#topic+residuals.kspm">residuals.kspm</a>, <a href="#topic+coef.kspm">coef.kspm</a>, <a href="#topic+nobs.kspm">nobs.kspm</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- 1:15
z &lt;- runif(15, 1, 6)
y &lt;- 3*x + z^2 + rnorm(15, 0, 2)
fit &lt;- kspm(y, linear = ~ x, kernel = ~ Kernel(z,
kernel.function = "polynomial", d = 2, rho = 1, gamma = 0))
fitted(fit)

</code></pre>

<hr>
<h2 id='flexible.summary'>Summarizing Kernel Semi parametric Model Fits with flexible parameters for Davies' approximation method</h2><span id='topic+flexible.summary'></span>

<h3>Description</h3>

<p>for flexibility in summary method for an object of class &quot;summary.kspm&quot;
</p>


<h3>Usage</h3>

<pre><code class='language-R'>flexible.summary(object, method = "davies", acc = 1e-06, lim = 10000)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="flexible.summary_+3A_object">object</code></td>
<td>
<p>an object of class &quot;summary.kspm&quot;, usually, a result of a call to <code>summary.kspm</code>.</p>
</td></tr>
<tr><td><code id="flexible.summary_+3A_method">method</code></td>
<td>
<p>method to approximate the chi square distribution in p-value computation, default is 'davies', another possibility is 'imhof'.</p>
</td></tr>
<tr><td><code id="flexible.summary_+3A_acc">acc</code>, <code id="flexible.summary_+3A_lim">lim</code></td>
<td>
<p>see davies and imhof functions in CompQuadForm package.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>the description of the model, including coefficients for the linear part and if asked for, test(s) of variance components associated with kernel part.
</p>


<h3>Value</h3>

<p>Computes and returns the followimg summary statistics of the fitted kernel semi parametric model given in object
</p>
<table role = "presentation">
<tr><td><code>residuals</code></td>
<td>
<p>residuals</p>
</td></tr>
<tr><td><code>coefficients</code></td>
<td>
<p>a <code class="reqn">p \times 4</code> matrix with columns for the estimated coefficient, its standard error, t statistic and corresponding (two sided) p value for the linear part of the model.</p>
</td></tr>
<tr><td><code>sigma</code></td>
<td>
<p>the square root of the estimated variance of the random error <code class="reqn">\sigma^2 = \frac{RSS}{edf} </code> where <code class="reqn">RSS</code> is the residual sum of squares and <code class="reqn">edf</code> is the effective degree of freedom.</p>
</td></tr>
<tr><td><code>edf</code></td>
<td>
<p>effective degrees of freedom</p>
</td></tr>
<tr><td><code>r.squared</code></td>
<td>
<p><code class="reqn">R^2</code>, the fraction of variance explained by the model, <code class="reqn">1 - \frac{\sum e_i^2}{\sum(y_i - y^{\ast})^2}</code> where <code class="reqn">y^{\ast}</code> is the mean of <code class="reqn">y_i</code> if there is an intercept and zero otherwise.</p>
</td></tr>
<tr><td><code>adj.r.squared</code></td>
<td>
<p>the above <code class="reqn">R^2</code> statistics, adjusted, penalizing for higher <code class="reqn">p</code>.</p>
</td></tr>
<tr><td><code>score.test</code></td>
<td>
<p>a <code class="reqn">q \times 3</code> matrix with colums for the estimated lambda, tau and p value for the q kernels for which a test should be performed.</p>
</td></tr>
<tr><td><code>global.p.value</code></td>
<td>
<p>p value from the score test for the global model.</p>
</td></tr>
<tr><td><code>sample.size</code></td>
<td>
<p>sample size (all: global sample size, inc: complete data sample size).</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Catherine Schramm, Aurelie Labbe, Celia Greenwood
</p>


<h3>References</h3>

<p>Liu, D., Lin, X., and Ghosh, D. (2007). Semiparametric regression of multidimensional genetic pathway data: least squares kernel machines and linear mixed models. Biometrics, 63(4), 1079:1088.
</p>
<p>Schweiger, Regev, et al. &quot;RL SKAT: an exact and efficient score test for heritability and set tests.&quot; Genetics (2017): genetics 300395.
</p>
<p>Li, Shaoyu, and Yuehua Cui. &quot;Gene centric gene gene interaction: A model based kernel machine method.&quot; The Annals of Applied Statistics 6.3 (2012): 1134:1161.
</p>


<h3>See Also</h3>

<p><a href="#topic+kspm">kspm</a> for fitting model, <a href="#topic+predict.kspm">predict.kspm</a> for predictions, <a href="#topic+plot.kspm">plot.kspm</a> for diagnostics
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- 1:15
z1 &lt;- runif(15, 1, 6)
z2 &lt;- rnorm(15, 1, 2)
y &lt;- 3*x + (z1 + z2)^2 + rnorm(15, 0, 2)
fit &lt;- kspm(y, linear = ~ x, kernel = ~ Kernel(~ z1 + z2,
kernel.function = "polynomial", d= 2, rho = 1, gamma = 0))
summary.fit &lt;- summary(fit)
flexible.summary(summary.fit, acc = 0.000001, lim = 1000)

</code></pre>

<hr>
<h2 id='get.parameters'>compute Kernel Semi Parametric model parameters</h2><span id='topic+get.parameters'></span>

<h3>Description</h3>

<p>internal function to compute model parameters
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get.parameters(X = NULL, Y = NULL, kernelList = NULL,
  free.parameters = NULL, n = NULL, not.missing = NULL,
  compute.kernel = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="get.parameters_+3A_x">X</code></td>
<td>
<p>X matrix</p>
</td></tr>
<tr><td><code id="get.parameters_+3A_y">Y</code></td>
<td>
<p>response matrix</p>
</td></tr>
<tr><td><code id="get.parameters_+3A_kernellist">kernelList</code></td>
<td>
<p>list of kernels</p>
</td></tr>
<tr><td><code id="get.parameters_+3A_free.parameters">free.parameters</code></td>
<td>
<p>free parameters</p>
</td></tr>
<tr><td><code id="get.parameters_+3A_n">n</code></td>
<td>
<p>number of samples</p>
</td></tr>
<tr><td><code id="get.parameters_+3A_not.missing">not.missing</code></td>
<td>
<p>number of non missing samples</p>
</td></tr>
<tr><td><code id="get.parameters_+3A_compute.kernel">compute.kernel</code></td>
<td>
<p>boolean indicating if kernel should be computed</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Catherine Schramm, Aurelie Labbe, Celia Greenwood
</p>

<hr>
<h2 id='hypercoef'>Extract Model Hyper-parameter</h2><span id='topic+hypercoef'></span>

<h3>Description</h3>

<p>Returns hyper-parameters for a model of class &quot;kspm&quot;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hypercoef(object, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="hypercoef_+3A_object">object</code></td>
<td>
<p>an object of class &quot;kspm&quot;, usually, a result of a call to <code>kspm</code>.</p>
</td></tr>
<tr><td><code id="hypercoef_+3A_...">...</code></td>
<td>
<p>additional optional argument (currently unused).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of parameter.
</p>
<table role = "presentation">
<tr><td><code>lambda</code></td>
<td>
<p>A vector of penalisation arameters.</p>
</td></tr>
<tr><td><code>kernel</code></td>
<td>
<p>A vector of tunning parameters.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Catherine Schramm, Aurelie Labbe, Celia Greenwood
</p>


<h3>References</h3>

<p>Liu, D., Lin, X., and Ghosh, D. (2007). Semiparametric regression of multidimensional genetic pathway data: least squares kernel machines and linear mixed models. Biometrics, 63(4), 1079:1088.
</p>


<h3>See Also</h3>

<p><a href="#topic+kspm">kspm</a> for fitting model.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- 1:15
z1 &lt;- runif(15, 1, 6)
z2 &lt;- rnorm(15, 1, 2)
y &lt;- 3*x + (z1 + z2)^2 + rnorm(15, 0, 2)
fit &lt;- kspm(y, linear = ~ x, kernel = ~ Kernel(~ z1 + z2,
kernel.function = "polynomial", d= 2, rho = 1, gamma = 0))
hypercoef(fit)


</code></pre>

<hr>
<h2 id='info.kspm'>Giving information about Kernel Semi parametric Model Fits</h2><span id='topic+info.kspm'></span>

<h3>Description</h3>

<p>gives information about Kernel Semi parametric Model Fits
</p>


<h3>Usage</h3>

<pre><code class='language-R'>info.kspm(object, print = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="info.kspm_+3A_object">object</code></td>
<td>
<p>an object of class &quot;kspm&quot;, usually, a result of a call to <code>kspm</code>.</p>
</td></tr>
<tr><td><code id="info.kspm_+3A_print">print</code></td>
<td>
<p>logical, if <code>TRUE</code>, table of information are printed.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>info.kspm</code> returns a table of information whose each row corresponds to a kernel included in the model and columns are:
</p>
<table role = "presentation">
<tr><td><code>type</code></td>
<td>
<p>type of object used to define the kernel</p>
</td></tr>
<tr><td><code>dim</code></td>
<td>
<p>dimension of data used in the model</p>
</td></tr>
<tr><td><code>type.predict</code></td>
<td>
<p>type of object the user should provide in <a href="#topic+predict.kspm">predict.kspm</a> function</p>
</td></tr>
<tr><td><code>dim.predict</code></td>
<td>
<p>dimension of object the user should provide in <a href="#topic+predict.kspm">predict.kspm</a> function</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Catherine Schramm, Aurelie Labbe, Celia Greenwood
</p>


<h3>See Also</h3>

<p><a href="#topic+kspm">kspm</a>, <a href="#topic+predict.kspm">predict.kspm</a>
</p>

<hr>
<h2 id='Kernel'>Create a Kernel Object</h2><span id='topic+Kernel'></span>

<h3>Description</h3>

<p>Create a kernel object, to use as variable in a model formula.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Kernel(x, kernel.function, scale = TRUE, rho = NULL, gamma = NULL,
  d = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Kernel_+3A_x">x</code></td>
<td>
<p>a formula, a vector or a matrix of variables grouped in the same kernel. It could also be a symetric matrix representing the Gram matrix, associated to a kernel function, already computed by the user.</p>
</td></tr>
<tr><td><code id="Kernel_+3A_kernel.function">kernel.function</code></td>
<td>
<p>type of kernel. Possible values are <code>"gaussian"</code>,  <code>"linear"</code>, <code>"polynomial"</code>, <code>"sigmoid"</code>, <code>"inverse.quadratic"</code> or <code>"equality"</code>. See details below. If <code>x</code> is a Gram matrix, associated to a kernel function, already computed by the user, <code>kernel.function</code> should be equal to <code>"gram.matrix"</code>.</p>
</td></tr>
<tr><td><code id="Kernel_+3A_scale">scale</code></td>
<td>
<p>boolean indicating if variables should be scaled before computing the kernel.</p>
</td></tr>
<tr><td><code id="Kernel_+3A_rho">rho</code>, <code id="Kernel_+3A_gamma">gamma</code>, <code id="Kernel_+3A_d">d</code></td>
<td>
<p>kernel function hyperparameters. See details below.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>To use inside kspm() function. Given two <code class="reqn">p-</code>dimensional vectors <code class="reqn">x</code> and <code class="reqn">y</code>,
</p>

<ul>
<li><p> the Gaussian kernel is defined as <code class="reqn">k(x,y) = exp\left(-\frac{\parallel x-y \parallel^2}{\rho}\right)</code> where <code class="reqn">\parallel x-y \parallel</code> is the Euclidean distance between <code class="reqn">x</code> and <code class="reqn">y</code> and <code class="reqn">\rho &gt; 0</code> is the bandwidth of the kernel,
</p>
</li>
<li><p> the linear kernel is defined as <code class="reqn">k(x,y) = x^Ty</code>,
</p>
</li>
<li><p> the polynomial kernel is defined as <code class="reqn">k(x,y) = (\rho x^Ty + \gamma)^d</code> with <code class="reqn">\rho &gt; 0</code>, <code class="reqn">d</code> is the polynomial order. Of note, a linear kernel is a polynomial kernel with <code class="reqn">\rho = d = 1</code> and <code class="reqn">\gamma = 0</code>,
</p>
</li>
<li><p> the sigmoid kernel is defined as <code class="reqn">k(x,y) = tanh(\rho x^Ty + \gamma)</code> which is similar to the sigmoid function in logistic regression,
</p>
</li>
<li><p> the inverse quadratic function defined as <code class="reqn">k(x,y) = \frac{1}{\sqrt{\parallel x-y \parallel^2 + \gamma}}</code> with <code class="reqn">\gamma &gt; 0</code>,
</p>
</li>
<li><p> the equality kernel defined as <code class="reqn">k(x,y) = \left\lbrace \begin{array}{ll} 1 &amp; if  x = y \\ 0 &amp; otherwise \end{array}\right.</code>.
</p>
</li></ul>

<p>Of note, Gaussian, inverse quadratic and equality kernels are measures of similarity resulting to a matrix containing 1 along the diagonal.
</p>


<h3>Value</h3>

<p>A Kernel object including all parameters needed in computation of the model
</p>


<h3>Author(s)</h3>

<p>Catherine Schramm, Aurelie Labbe, Celia Greenwood
</p>


<h3>References</h3>

<p>Liu, D., Lin, X., and Ghosh, D. (2007). Semiparametric regression of multidimensional genetic pathway data: least squares kernel machines and linear mixed models. Biometrics, 63(4), 1079:1088.
</p>

<hr>
<h2 id='kernel.function'>Kernel Functions</h2><span id='topic+kernel.function'></span><span id='topic+kernel.gaussian'></span><span id='topic+kernel.linear'></span><span id='topic+kernel.polynomial'></span><span id='topic+kernel.sigmoid'></span><span id='topic+kernel.inverse.quadratic'></span><span id='topic+kernel.equality'></span>

<h3>Description</h3>

<p>These functions transform a <code class="reqn">n \times p</code> matrix into a <code class="reqn">n \times n</code> kernel matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>kernel.gaussian(x, rho = ncol(x))

kernel.linear(x)

kernel.polynomial(x, rho = 1, gamma = 0, d = 1)

kernel.sigmoid(x, rho = 1, gamma = 1)

kernel.inverse.quadratic(x, gamma = 1)

kernel.equality(x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="kernel.function_+3A_x">x</code></td>
<td>
<p>a <code class="reqn">n \times p</code> matrix</p>
</td></tr>
<tr><td><code id="kernel.function_+3A_gamma">gamma</code>, <code id="kernel.function_+3A_rho">rho</code>, <code id="kernel.function_+3A_d">d</code></td>
<td>
<p>kernel hyperparameters (see details)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Given two <code class="reqn">p-</code>dimensional vectors <code class="reqn">x</code> and <code class="reqn">y</code>,
</p>

<ul>
<li><p> the Gaussian kernel is defined as <code class="reqn">k(x,y) = exp\left(-\frac{\parallel x-y \parallel^2}{\rho}\right)</code> where <code class="reqn">\parallel x-y \parallel</code> is the Euclidean distance between <code class="reqn">x</code> and <code class="reqn">y</code> and <code class="reqn">\rho &gt; 0</code> is the bandwidth of the kernel,
</p>
</li>
<li><p> the linear kernel is defined as <code class="reqn">k(x,y) = x^Ty</code>,
</p>
</li>
<li><p> the polynomial kernel is defined as <code class="reqn">k(x,y) = (\rho x^Ty + \gamma)^d</code> with <code class="reqn">\rho &gt; 0</code>, <code class="reqn">d</code> is the polynomial order. Of note, a linear kernel is a polynomial kernel with <code class="reqn">\rho = d = 1</code> and <code class="reqn">\gamma = 0</code>,
</p>
</li>
<li><p> the sigmoid kernel is defined as <code class="reqn">k(x,y) = tanh(\rho x^Ty + \gamma)</code> which is similar to the sigmoid function in logistic regression,
</p>
</li>
<li><p> the inverse quadratic function defined as <code class="reqn">k(x,y) = \frac{1}{\sqrt{\parallel x-y \parallel^2 + \gamma}}</code> with <code class="reqn">\gamma &gt; 0</code>,
</p>
</li>
<li><p> the equality kernel defined as <code class="reqn">k(x,y) = \left\lbrace \begin{array}{ll} 1 &amp; if  x = y \\ 0 &amp; otherwise \end{array}\right.</code>.
</p>
</li></ul>

<p>Of note, Gaussian, inverse quadratic and equality kernels are measures of similarity resulting to a matrix containing 1 along the diagonal.
</p>


<h3>Value</h3>

<p>A <code class="reqn">n \times n</code> matrix.
</p>


<h3>Author(s)</h3>

<p>Catherine Schramm, Aurelie Labbe, Celia Greenwood
</p>


<h3>References</h3>

<p>Liu, D., Lin, X., and Ghosh, D. (2007). Semiparametric regression of multidimensional genetic pathway data: least squares kernel machines and linear mixed models. Biometrics, 63(4), 1079:1088.
</p>

<hr>
<h2 id='kernel.list'>List of kernel parts included in the kernel semi parametric model</h2><span id='topic+kernel.list'></span>

<h3>Description</h3>

<p>internal method for listing all kernel parts included in the model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>kernel.list(formula, data, names)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="kernel.list_+3A_formula">formula</code></td>
<td>
<p>kernel part formula provided in the <code>kspm</code> function.</p>
</td></tr>
<tr><td><code id="kernel.list_+3A_data">data</code></td>
<td>
<p>data provided in the <code>kspm</code> function.</p>
</td></tr>
<tr><td><code id="kernel.list_+3A_names">names</code></td>
<td>
<p>row names of samples as they are evaluated in <code>kspm</code> function.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Catherine Schramm, Aurelie Labbe, Celia Greenwood
</p>

<hr>
<h2 id='kernel.matrix'>Kernel matrix</h2><span id='topic+kernel.matrix'></span>

<h3>Description</h3>

<p>These functions transform a <code class="reqn">n \times p</code> matrix into a <code class="reqn">n \times n</code> kernel matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>kernel.matrix(Z, whichkernel, rho = NULL, gamma = NULL, d = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="kernel.matrix_+3A_z">Z</code></td>
<td>
<p>a <code class="reqn">n \times p</code> matrix</p>
</td></tr>
<tr><td><code id="kernel.matrix_+3A_whichkernel">whichkernel</code></td>
<td>
<p>kernel function</p>
</td></tr>
<tr><td><code id="kernel.matrix_+3A_gamma">gamma</code>, <code id="kernel.matrix_+3A_rho">rho</code>, <code id="kernel.matrix_+3A_d">d</code></td>
<td>
<p>kernel hyperparameters (see details)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Given a <code class="reqn">n \times p</code> matrix, this function returns a <code class="reqn">n \times n</code> matrix where each cell represents the similarity between two samples defined by two <code class="reqn">p-</code>dimensional vectors <code class="reqn">x</code> and <code class="reqn">y</code>,
</p>

<ul>
<li><p> the Gaussian kernel is defined as <code class="reqn">k(x,y) = exp\left(-\frac{\parallel x-y \parallel^2}{\rho}\right)</code> where <code class="reqn">\parallel x-y \parallel</code> is the Euclidean distance between <code class="reqn">x</code> and <code class="reqn">y</code> and <code class="reqn">\rho &gt; 0</code> is the bandwidth of the kernel,
</p>
</li>
<li><p> the linear kernel is defined as <code class="reqn">k(x,y) = x^Ty</code>,
</p>
</li>
<li><p> the polynomial kernel is defined as <code class="reqn">k(x,y) = (\rho x^Ty + \gamma)^d</code> with <code class="reqn">\rho &gt; 0</code>, <code class="reqn">d</code> is the polynomial order. Of note, a linear kernel is a polynomial kernel with <code class="reqn">\rho = d = 1</code> and <code class="reqn">\gamma = 0</code>,
</p>
</li>
<li><p> the sigmoid kernel is defined as <code class="reqn">k(x,y) = tanh(\rho x^Ty + \gamma)</code> which is similar to the sigmoid function in logistic regression,
</p>
</li>
<li><p> the inverse quadratic function defined as <code class="reqn">k(x,y) = \frac{1}{\sqrt{\parallel x-y \parallel^2 + \gamma}}</code> with <code class="reqn">\gamma &gt; 0</code>,
</p>
</li>
<li><p> the equality kernel defined as <code class="reqn">k(x,y) = \left\lbrace \begin{array}{ll} 1 &amp; if  x = y \\ 0 &amp; otherwise \end{array}\right.</code>.
</p>
</li></ul>



<h3>Value</h3>

<p>A <code class="reqn">n \times n</code> matrix.
</p>


<h3>Author(s)</h3>

<p>Catherine Schramm, Aurelie Labbe, Celia Greenwood
</p>


<h3>See Also</h3>

<p><a href="#topic+kernel.gaussian">kernel.gaussian</a>, <a href="#topic+kernel.linear">kernel.linear</a>, <a href="#topic+kernel.polynomial">kernel.polynomial</a>, <a href="#topic+kernel.equality">kernel.equality</a>, <a href="#topic+kernel.sigmoid">kernel.sigmoid</a>, <a href="#topic+kernel.inverse.quadratic">kernel.inverse.quadratic</a>.
</p>

<hr>
<h2 id='kernel.method'>some internal methods in computation of kernel semi parametric model</h2><span id='topic+kernel.method'></span><span id='topic+comb'></span><span id='topic+check.integer'></span><span id='topic+asOneSidedFormula'></span><span id='topic+splitFormula'></span><span id='topic+computes.Kernel'></span><span id='topic+computes.Kernel.interaction'></span><span id='topic+computes.KernelALL'></span><span id='topic+renames.Kernel'></span><span id='topic+objects.Kernel'></span>

<h3>Description</h3>

<p>internal methods
</p>


<h3>Usage</h3>

<pre><code class='language-R'>comb(x, ...)

check.integer(N)

asOneSidedFormula(object)

splitFormula(form, sep = "/")

computes.Kernel(x, ind, nameKernel, not.missing = NULL)

computes.Kernel.interaction(x, ind, nameKernel, not.missing = NULL)

computes.KernelALL(kernelList, not.missing = NULL)

renames.Kernel(object, names)

objects.Kernel(formula)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="kernel.method_+3A_x">x</code></td>
<td>
<p>list of objects</p>
</td></tr>
<tr><td><code id="kernel.method_+3A_...">...</code></td>
<td>
<p>other arguments</p>
</td></tr>
<tr><td><code id="kernel.method_+3A_n">N</code></td>
<td>
<p>numeric value</p>
</td></tr>
<tr><td><code id="kernel.method_+3A_object">object</code></td>
<td>
<p>formula provided in the kernel part of <code>kspm</code> function</p>
</td></tr>
<tr><td><code id="kernel.method_+3A_form">form</code></td>
<td>
<p>formula</p>
</td></tr>
<tr><td><code id="kernel.method_+3A_sep">sep</code></td>
<td>
<p>separator</p>
</td></tr>
<tr><td><code id="kernel.method_+3A_ind">ind</code></td>
<td>
<p>index value</p>
</td></tr>
<tr><td><code id="kernel.method_+3A_namekernel">nameKernel</code></td>
<td>
<p>name of kernel</p>
</td></tr>
<tr><td><code id="kernel.method_+3A_not.missing">not.missing</code></td>
<td>
<p>non missing values</p>
</td></tr>
<tr><td><code id="kernel.method_+3A_kernellist">kernelList</code></td>
<td>
<p>list of kernels</p>
</td></tr>
<tr><td><code id="kernel.method_+3A_names">names</code></td>
<td>
<p>name of kernel</p>
</td></tr>
<tr><td><code id="kernel.method_+3A_formula">formula</code></td>
<td>
<p>formula</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Catherine Schramm, Aurelie Labbe, Celia Greenwood
</p>

<hr>
<h2 id='kspm'>Fitting Kernel Semi Parametric model</h2><span id='topic+kspm'></span>

<h3>Description</h3>

<p>kspm is used to fit kernel semi parametric models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>kspm(response, linear = NULL, kernel = NULL, data = NULL,
  level = 1, control = kspmControl())
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="kspm_+3A_response">response</code></td>
<td>
<p>a character with the name of the response variable or a vector containing the outcome or a matrix with outcome in the first column.</p>
</td></tr>
<tr><td><code id="kspm_+3A_linear">linear</code></td>
<td>
<p>an optional object of class &quot;formula&quot;: a symbolic description of the linear part of the model to be fitted or a vector or a matrix containing covariates included in the linear part of the model. Default is intercept only. The details of model specification are given under ‘Details’.</p>
</td></tr>
<tr><td><code id="kspm_+3A_kernel">kernel</code></td>
<td>
<p>an object of class &quot;formula&quot;: a symbolic description of the kernel part of the model to be fitted. If missing a linear model is fitted using lm function. The details of model specification are given under ‘Details’.</p>
</td></tr>
<tr><td><code id="kspm_+3A_data">data</code></td>
<td>
<p>an optional data frame containing the variables in the model. If NULL (default), data are taken from the workspace.</p>
</td></tr>
<tr><td><code id="kspm_+3A_level">level</code></td>
<td>
<p>printed information about the model (0: no information, 1: information about kernels included in the model (default))</p>
</td></tr>
<tr><td><code id="kspm_+3A_control">control</code></td>
<td>
<p>see <a href="#topic+kspmControl">kspmControl</a>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The kernel semi parametric model refers to the following equation <code class="reqn">Y_i = X_i\beta + h(Z_i) + e_i</code> with <code class="reqn">i=1..n</code> where <code class="reqn">n</code> is the sample size, <code class="reqn">Y</code> is the univariate response, <code class="reqn">X\beta</code> is the linear part, <code class="reqn">h(Z)</code> is the kernel part and <code class="reqn">e</code> are the residuals. The linear part is defined using the <code>linear</code> argument by specifying the covariates <code class="reqn">X</code>. It could be either a formula, a vector of length <code class="reqn">n</code> if only one variable is included in the linear part or a <code class="reqn">n \times p</code> design matrix containing the values of the <code class="reqn">p</code> covariates included in the linear part (columns), for each individuals (rows). By default, an intercept is included. To remove the intercept term, use formula specification and add the term <code>-1</code>, as usual. Kernel part is defined using the <code>kernel</code> argument. It should be a formula of <code>Kernel</code> object(s). For a multiple kernel semi parametric model, <code>Kernel</code> objects are separated by the usual signs <code>"+"</code>, <code>"*"</code> and <code>":"</code> to specify addition and interaction between kernels. Specification formats of each <code>Kernel</code>  object may be different. See <a href="#topic+Kernel">Kernel</a> for more information about their specification.
</p>


<h3>Value</h3>

<p><code>kspm</code> returns an object of class kspm.
</p>
<p>An object of class kspm is a list containing the following components:
</p>
<table role = "presentation">
<tr><td><code>linear.coefficients</code></td>
<td>
<p>matrix of coefficients associated with linear part, the number of coefficients is the number of terms included in linear part</p>
</td></tr>
<tr><td><code>kernel.coefficients</code></td>
<td>
<p>matrix of coefficients associated with kernel part, the number of rows is the sample size included in the analysis and the number of columns is the number of kernels included in the model</p>
</td></tr>
<tr><td><code>lambda</code></td>
<td>
<p>penalization parameter(s)</p>
</td></tr>
<tr><td><code>fitted.values</code></td>
<td>
<p>the fitted mean values</p>
</td></tr>
<tr><td><code>residuals</code></td>
<td>
<p>the residuals, that is response minus the fitted values</p>
</td></tr>
<tr><td><code>sigma</code></td>
<td>
<p>standard deviation of residuals</p>
</td></tr>
<tr><td><code>Y</code></td>
<td>
<p>vector of responses</p>
</td></tr>
<tr><td><code>X</code></td>
<td>
<p>design matrix for linear part</p>
</td></tr>
<tr><td><code>K</code></td>
<td>
<p>kernel matrices computed by the model</p>
</td></tr>
<tr><td><code>n.total</code></td>
<td>
<p>total sample size</p>
</td></tr>
<tr><td><code>n</code></td>
<td>
<p>sample size of the model (model is performed on complete data only)</p>
</td></tr>
<tr><td><code>edf</code></td>
<td>
<p>effective degree of freedom</p>
</td></tr>
<tr><td><code>linear.formula</code></td>
<td>
<p>formula corresponding to the linear part of the model</p>
</td></tr>
<tr><td><code>kernel.info</code></td>
<td>
<p>information about kernels included in the model such as matrices of covariates (<code>Z</code>),  kernel function (<code>type</code>), values of hyperparameters (<code>rho</code>, <code>gamma</code>, <code>d</code>). A boolean indicates if covariates were scaled (<code>kernel.scale</code>) and if <code>TRUE</code>, <code>kernel.mean</code>, <code>kernel.sd</code> and <code>Z.scale</code> give information about scaling. <code>kernel.formula</code> indicates the formula of the kernel and <code>free.parameters</code> indicates the hyperparameters that were estimated by the model.</p>
</td></tr>
<tr><td><code>Hat</code></td>
<td>
<p>The hat matrix <code class="reqn">H</code> such that <code class="reqn">\hat{Y} = HY</code></p>
</td></tr>
<tr><td><code>L</code></td>
<td>
<p>A matrix corresponding to <code class="reqn">I - \sum\limits_{\ell = 1}^L K_{\ell} G_{\ell}^{-1} M_{\ell}</code> according to our notations</p>
</td></tr>
<tr><td><code>XLX_inv</code></td>
<td>
<p>A matrix corresponding to <code class="reqn">(XLX)^{-1}</code></p>
</td></tr>
<tr><td><code>GinvM</code></td>
<td>
<p>A list of matrix, each corresponding to a kernel and equaling <code class="reqn">G_{\ell}^{-1}M_{\ell}</code> according to our notations</p>
</td></tr>
<tr><td><code>control</code></td>
<td>
<p>List of control parameters</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Catherine Schramm, Aurelie Labbe, Celia Greenwood
</p>


<h3>References</h3>

<p>Liu, D., Lin, X., and Ghosh, D. (2007). Semiparametric regression of multidimensional genetic pathway data: least squares kernel machines and linear mixed models. Biometrics, 63(4), 1079:1088.
</p>
<p>Kim, Choongrak, Byeong U. Park, and Woochul Kim. &quot;Influence diagnostics in semiparametric regression models.&quot; Statistics and probability letters 60.1 (2002): 49:58.
</p>
<p>Oualkacha, Karim, et al. &quot;Adjusted sequence kernel association test for rare variants controlling for cryptic and family relatedness.&quot; Genetic epidemiology 37.4 (2013): 366:376.
</p>


<h3>See Also</h3>

<p><a href="#topic+summary.kspm">summary.kspm</a> for summary, <a href="#topic+predict.kspm">predict.kspm</a> for predictions, <a href="#topic+plot.kspm">plot.kspm</a> for diagnostics
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- 1:15
z1 &lt;- runif(15, 1, 6)
z2 &lt;- rnorm(15, 1, 2)
y &lt;- 3*x + (z1 + z2)^2 + rnorm(15, 0, 2)
fit &lt;- kspm(y, linear = ~ x, kernel = ~ Kernel(~ z1 + z2,
kernel.function = "polynomial", d= 2, rho = 1, gamma = 0))
summary(fit)

</code></pre>

<hr>
<h2 id='kspmControl'>Control various aspects of the optimisation problem</h2><span id='topic+kspmControl'></span>

<h3>Description</h3>

<p>Allow the user to set some characteristics of the optimisation algorithm
</p>


<h3>Usage</h3>

<pre><code class='language-R'>kspmControl(interval.upper = NA, interval.lower = NA, trace = FALSE,
  optimize.tol = .Machine$double.eps^0.25, NP = NA, itermax = 500,
  CR = 0.5, F = 0.8, initialpop = NULL, storepopfrom = itermax + 1,
  storepopfreq = 1, p = 0.2, c = 0,
  reltol = sqrt(.Machine$double.eps), steptol = itermax,
  parallel = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="kspmControl_+3A_interval.upper">interval.upper</code></td>
<td>
<p>integer or vetor of initial maximum value(s) allowed for parameter(s)</p>
</td></tr>
<tr><td><code id="kspmControl_+3A_interval.lower">interval.lower</code></td>
<td>
<p>integer or vetor of initial maximum value(s) allowed for parameter(s)</p>
</td></tr>
<tr><td><code id="kspmControl_+3A_trace">trace</code></td>
<td>
<p>boolean. If TRUE parameters value at each iteration are displayed.</p>
</td></tr>
<tr><td><code id="kspmControl_+3A_optimize.tol">optimize.tol</code></td>
<td>
<p>if <a href="stats.html#topic+optimize">optimize</a> function is used. See <a href="stats.html#topic+optimize">optimize</a></p>
</td></tr>
<tr><td><code id="kspmControl_+3A_np">NP</code></td>
<td>
<p>if <a href="DEoptim.html#topic+DEoptim">DEoptim</a> function is used. See <a href="DEoptim.html#topic+DEoptim.control">DEoptim.control</a></p>
</td></tr>
<tr><td><code id="kspmControl_+3A_itermax">itermax</code></td>
<td>
<p>if <a href="DEoptim.html#topic+DEoptim">DEoptim</a> function is used. See <a href="DEoptim.html#topic+DEoptim.control">DEoptim.control</a></p>
</td></tr>
<tr><td><code id="kspmControl_+3A_cr">CR</code></td>
<td>
<p>if <a href="DEoptim.html#topic+DEoptim">DEoptim</a> function is used. See <a href="DEoptim.html#topic+DEoptim.control">DEoptim.control</a></p>
</td></tr>
<tr><td><code id="kspmControl_+3A_f">F</code></td>
<td>
<p>if <a href="DEoptim.html#topic+DEoptim">DEoptim</a> function is used. See <a href="DEoptim.html#topic+DEoptim.control">DEoptim.control</a></p>
</td></tr>
<tr><td><code id="kspmControl_+3A_initialpop">initialpop</code></td>
<td>
<p>if <a href="DEoptim.html#topic+DEoptim">DEoptim</a> function is used. See <a href="DEoptim.html#topic+DEoptim.control">DEoptim.control</a></p>
</td></tr>
<tr><td><code id="kspmControl_+3A_storepopfrom">storepopfrom</code></td>
<td>
<p>if <a href="DEoptim.html#topic+DEoptim">DEoptim</a> function is used. See <a href="DEoptim.html#topic+DEoptim.control">DEoptim.control</a></p>
</td></tr>
<tr><td><code id="kspmControl_+3A_storepopfreq">storepopfreq</code></td>
<td>
<p>if <a href="DEoptim.html#topic+DEoptim">DEoptim</a> function is used. See <a href="DEoptim.html#topic+DEoptim.control">DEoptim.control</a></p>
</td></tr>
<tr><td><code id="kspmControl_+3A_p">p</code></td>
<td>
<p>if <a href="DEoptim.html#topic+DEoptim">DEoptim</a> function is used. See <a href="DEoptim.html#topic+DEoptim.control">DEoptim.control</a></p>
</td></tr>
<tr><td><code id="kspmControl_+3A_c">c</code></td>
<td>
<p>if <a href="DEoptim.html#topic+DEoptim">DEoptim</a> function is used. See <a href="DEoptim.html#topic+DEoptim.control">DEoptim.control</a></p>
</td></tr>
<tr><td><code id="kspmControl_+3A_reltol">reltol</code></td>
<td>
<p>if <a href="DEoptim.html#topic+DEoptim">DEoptim</a> function is used. See <a href="DEoptim.html#topic+DEoptim.control">DEoptim.control</a></p>
</td></tr>
<tr><td><code id="kspmControl_+3A_steptol">steptol</code></td>
<td>
<p>if <a href="DEoptim.html#topic+DEoptim">DEoptim</a> function is used. See <a href="DEoptim.html#topic+DEoptim.control">DEoptim.control</a></p>
</td></tr>
<tr><td><code id="kspmControl_+3A_parallel">parallel</code></td>
<td>
<p>if <a href="DEoptim.html#topic+DEoptim">DEoptim</a> function is used. See <a href="DEoptim.html#topic+DEoptim.control">DEoptim.control</a></p>
</td></tr>
</table>


<h3>Details</h3>

<p>When only one hyperparameter should be estimated, the optimisation problem calls the <a href="stats.html#topic+optimize">optimize</a> function from <code>stats</code> basic package. Otherwise, it calls the <a href="DEoptim.html#topic+DEoptim">DEoptim</a> function from the package <code>DEoptim</code>. In both case, the parameters are choosen among the initial interval defined by <code>interval.lower</code> and <code>interval.upper</code>.
</p>


<h3>Value</h3>

<p><code>search.parameters</code> is an iterative algorithm estimating model parameters and returns the following components:
</p>
<table role = "presentation">
<tr><td><code>lambda</code></td>
<td>
<p>tuning parameters for penalization.</p>
</td></tr>
<tr><td><code>beta</code></td>
<td>
<p>vector of coefficients associated with linear part of the model, the size being the number of variable in linear part (including an intercept term).</p>
</td></tr>
<tr><td><code>alpha</code></td>
<td>
<p>vector of coefficients associated with kernel part of the model, the size being the sample size.</p>
</td></tr>
<tr><td><code>Ginv</code></td>
<td>
<p>a matrix used in several calculations. <code class="reqn">Ginv = (\lambda I + K)^{-1}</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Catherine Schramm, Aurelie Labbe, Celia Greenwood
</p>


<h3>See Also</h3>

<p>link get.parameters for computation of parameters at each iteration
</p>

<hr>
<h2 id='logLik.kspm'>Log Likelihood of a kspm Object</h2><span id='topic+logLik.kspm'></span>

<h3>Description</h3>

<p>Returns the Log Likelihood value of the kernel semi parametric model represented by <code>obect</code> evaluated at the estimated coefficients.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'kspm'
logLik(object, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="logLik.kspm_+3A_object">object</code></td>
<td>
<p>an object of class &quot;kspm&quot;, usually, a result of a call to <a href="#topic+kspm">kspm</a>.</p>
</td></tr>
<tr><td><code id="logLik.kspm_+3A_...">...</code></td>
<td>
<p>additional optional argument (currently unused).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function returns the Log Likelihood computed as follow:  <code class="reqn">logLik = -\frac{1}{2} RSS</code> where <code class="reqn">RSS</code> is the residual sum of squares.
</p>


<h3>Value</h3>

<p>logLik of kspm fit
</p>


<h3>Author(s)</h3>

<p>Catherine Schramm, Aurelie Labbe, Celia Greenwood
</p>


<h3>References</h3>

<p>Liu, D., Lin, X., and Ghosh, D. (2007). Semiparametric regression of multidimensional genetic pathway data: least squares kernel machines and linear mixed models. Biometrics, 63(4), 1079:1088.
</p>


<h3>See Also</h3>

<p><a href="#topic+kspm">kspm</a>, <a href="#topic+extractAIC.kspm">extractAIC.kspm</a>, <a href="#topic+deviance.kspm">deviance.kspm</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- 1:15
y &lt;- 3*x + rnorm(15, 0, 2)
fit &lt;- kspm(y, kernel = ~ Kernel(x, kernel.function = "linear"))
logLik(fit)

</code></pre>

<hr>
<h2 id='lossFunction.looe'>Computation of the leave one out error (LOOE) in kernel semi parametric model</h2><span id='topic+lossFunction.looe'></span>

<h3>Description</h3>

<p>internal function to optimize model for estimating hyperparameters based on LOOE
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lossFunction.looe(param. = NULL, Y. = NULL, X. = NULL,
  kernelList. = NULL, n. = NULL, not.missing. = NULL,
  compute.kernel. = NULL, print.lambda. = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="lossFunction.looe_+3A_param.">param.</code></td>
<td>
<p>initial parameter values.</p>
</td></tr>
<tr><td><code id="lossFunction.looe_+3A_y.">Y.</code></td>
<td>
<p>response matrix.</p>
</td></tr>
<tr><td><code id="lossFunction.looe_+3A_x.">X.</code></td>
<td>
<p>X matrix (linear part).</p>
</td></tr>
<tr><td><code id="lossFunction.looe_+3A_kernellist.">kernelList.</code></td>
<td>
<p>list of kernels (kernel part).</p>
</td></tr>
<tr><td><code id="lossFunction.looe_+3A_n.">n.</code></td>
<td>
<p>nb of samples.</p>
</td></tr>
<tr><td><code id="lossFunction.looe_+3A_not.missing.">not.missing.</code></td>
<td>
<p>nb of non missing samples.</p>
</td></tr>
<tr><td><code id="lossFunction.looe_+3A_compute.kernel.">compute.kernel.</code></td>
<td>
<p>boolean. If TRUE, the kernel matrix is computed at each iteration. Should be TRUE when hyperparameters of kernel functions should be estimated by the model.</p>
</td></tr>
<tr><td><code id="lossFunction.looe_+3A_print.lambda.">print.lambda.</code></td>
<td>
<p>boolean. If TRUE, values of tunning parameters (lambda) are printed at each iteration.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Catherine Schramm, Aurelie Labbe, Celia Greenwood
</p>

<hr>
<h2 id='nobs.kspm'>Extract the number of observations from a Kernel Semi parametric Model Fit</h2><span id='topic+nobs.kspm'></span>

<h3>Description</h3>

<p>Extract the number of observations use to estimate the model coefficients. This is principally intented to be used in computing BIC (see <a href="#topic+extractAIC.kspm">extractAIC.kspm</a>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'kspm'
nobs(object, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="nobs.kspm_+3A_object">object</code></td>
<td>
<p>an object of class &quot;kspm&quot;, usually, a result of a call to <code>kspm</code>.</p>
</td></tr>
<tr><td><code id="nobs.kspm_+3A_...">...</code></td>
<td>
<p>additional optional argument (currently unused).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A single number (integer).
</p>


<h3>Author(s)</h3>

<p>Catherine Schramm, Aurelie Labbe, Celia Greenwood
</p>


<h3>See Also</h3>

<p><a href="#topic+kspm">kspm</a> for fitting model, <a href="#topic+extractAIC.kspm">extractAIC.kspm</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- 1:15
y &lt;- 3*x + rnorm(15, 0, 2)
fit &lt;- kspm(y, kernel = ~ Kernel(x, kernel.function = "linear"))
nobs(fit)

</code></pre>

<hr>
<h2 id='plot.derivatives'>Plot derivatives of a kspm object</h2><span id='topic+plot.derivatives'></span>

<h3>Description</h3>

<p>Plot of derivatives for kernel part of a kspm model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'derivatives'
plot(x, subset = NULL, xlab = NULL,
  ylab = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot.derivatives_+3A_x">x</code></td>
<td>
<p>an object of class &quot;derivatives&quot;, usually, a result of a call to <code>derivatives</code>.</p>
</td></tr>
<tr><td><code id="plot.derivatives_+3A_subset">subset</code></td>
<td>
<p>if a subset of the plots is required, specify the names of the variable for which plot of derivatives is required.</p>
</td></tr>
<tr><td><code id="plot.derivatives_+3A_xlab">xlab</code></td>
<td>
<p>x label</p>
</td></tr>
<tr><td><code id="plot.derivatives_+3A_ylab">ylab</code></td>
<td>
<p>y label</p>
</td></tr>
<tr><td><code id="plot.derivatives_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>X axis represents the raw data used as input in kernel part of the model. Y axis represents the pointwise derivative values i.e. the derivatives of fitted value according to the variable of interest.
</p>


<h3>Author(s)</h3>

<p>Catherine Schramm, Aurelie Labbe, Celia Greenwood
</p>


<h3>References</h3>

<p>Kim, Choongrak, Byeong U. Park, and Woochul Kim. &quot;Influence diagnostics in semiparametric regression models.&quot; Statistics and probability letters 60.1 (2002): 49:58.
</p>


<h3>See Also</h3>

<p><a href="#topic+derivatives">derivatives</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- 1:15
z1 &lt;- runif(15, 1, 6)
z2 &lt;- rnorm(15, 1, 2)
y &lt;- 3*x + (z1 + z2)^2 + rnorm(15, 0, 2)
fit &lt;- kspm(y, linear = ~ x, kernel = ~ Kernel(~ z1 + z2,
kernel.function = "polynomial", d= 2, rho = 1, gamma = 0))
plot(derivatives(fit))

</code></pre>

<hr>
<h2 id='plot.kspm'>Plot Diagnostics for a kspm Object</h2><span id='topic+plot.kspm'></span>

<h3>Description</h3>

<p>Five plots (selectable by <code>which</code>) are currently available: a plot of residuals against fitted values, a scale Location plot of <code class="reqn">\sqrt{\mid residuals \mid}</code> against fitted values, a Normal Q Q plot for residuals, a plot of Cook's distances versus row labels and a plot of residuals against leverages. By default, the first three and 5 are provided.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'kspm'
plot(x, which = c(1:3, 5), cook.levels = c(0.5, 1),
  id.n = 3, labels.id = names(x$residuals), cex.id = 0.75,
  col.id = "blue", ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot.kspm_+3A_x">x</code></td>
<td>
<p>an object of class &quot;kspm&quot;, usually, a result of a call to <code>kspm</code>.</p>
</td></tr>
<tr><td><code id="plot.kspm_+3A_which">which</code></td>
<td>
<p>if a subset of the plots is required, specify a subset of the numbers 1:5.</p>
</td></tr>
<tr><td><code id="plot.kspm_+3A_cook.levels">cook.levels</code></td>
<td>
<p>levels of Cook's distance at which to draw contours.</p>
</td></tr>
<tr><td><code id="plot.kspm_+3A_id.n">id.n</code></td>
<td>
<p>number of points to be labelled in each plot, starting with the most extreme.</p>
</td></tr>
<tr><td><code id="plot.kspm_+3A_labels.id">labels.id</code></td>
<td>
<p>vector of labels, from which the labels for extreme points will be chosen. NULL uses names associated to response specified in <code>kspm</code>.</p>
</td></tr>
<tr><td><code id="plot.kspm_+3A_cex.id">cex.id</code></td>
<td>
<p>size of point labels.</p>
</td></tr>
<tr><td><code id="plot.kspm_+3A_col.id">col.id</code></td>
<td>
<p>color of point labels.</p>
</td></tr>
<tr><td><code id="plot.kspm_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Catherine Schramm, Aurelie Labbe, Celia Greenwood
</p>


<h3>References</h3>

<p>Kim, Choongrak, Byeong U. Park, and Woochul Kim. &quot;Influence diagnostics in semiparametric regression models.&quot; Statistics and probability letters 60.1 (2002): 49:58.
</p>


<h3>See Also</h3>

<p><a href="#topic+kspm">kspm</a> for fitting the model, <a href="#topic+summary.kspm">summary.kspm</a> for summary
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- 1:15
z1 &lt;- runif(15, 1, 6)
z2 &lt;- rnorm(15, 1, 2)
y &lt;- 3*x + (z1 + z2)^2 + rnorm(15, 0, 2)
fit &lt;- kspm(y, linear = ~ x, kernel = ~ Kernel(~ z1 + z2,
kernel.function = "polynomial", d= 2, rho = 1, gamma = 0))
plot(fit)

</code></pre>

<hr>
<h2 id='predict.kspm'>Predicting Kernel Semi parametric Model Fits</h2><span id='topic+predict.kspm'></span>

<h3>Description</h3>

<p>predict method for class &quot;kspm&quot;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'kspm'
predict(object, newdata.linear = NULL,
  newdata.kernel = NULL, interval = "none", level = 0.95, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict.kspm_+3A_object">object</code></td>
<td>
<p>an object of class &quot;kspm&quot;, usually, a result of a call to <code>kspm</code>.</p>
</td></tr>
<tr><td><code id="predict.kspm_+3A_newdata.linear">newdata.linear</code></td>
<td>
<p>should be a data frame or design matrix of variables used in the linear part</p>
</td></tr>
<tr><td><code id="predict.kspm_+3A_newdata.kernel">newdata.kernel</code></td>
<td>
<p>a list containing data frame or design matrix of variables used in each kernel part depending on the specification format of each kernel. When a kernel has been specified using <code>kernel.function = "gram.matrix"</code> in <code>Kernel</code> function, the user should also provide the Gram matrix associated to the new data points in <code>newdata.kernel</code>. The function <a href="#topic+info.kspm">info.kspm</a> may help to correctly specify it.</p>
</td></tr>
<tr><td><code id="predict.kspm_+3A_interval">interval</code></td>
<td>
<p>type of interval calculation. If <code>"none"</code> (default), no interval is computed, if <code>"confidence"</code>, the confidence interval is computed, if <code>"prediction"</code>, the prediction interval is computed.</p>
</td></tr>
<tr><td><code id="predict.kspm_+3A_level">level</code></td>
<td>
<p>confidence level. Default is <code>level = 0.95</code> meaning 95% confidence/prediction interval.</p>
</td></tr>
<tr><td><code id="predict.kspm_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>predict.kspm</code> produces predicted values. If a new dataset is not specified, it will return the fitted values from the original data (complete data used in the model specification). If <code>predict.kspm</code> is applied to a new dataset, all variables used in the original model should be provided in  <code>newdata.linear</code> and <code>newdata.kernel</code> arguments but only complete data may be provided. Setting <code>interval</code> specifies computation of confidence or prediction intervals at the specified <code>level</code>.
</p>


<h3>Value</h3>

<p><code>predict.kspm</code> returns a vector of predictions or a matrix containing the following components if <code>interval</code> is set:
</p>
<table role = "presentation">
<tr><td><code>fit</code></td>
<td>
<p>predictions.</p>
</td></tr>
<tr><td><code>lwr</code></td>
<td>
<p>lower bound of confidence/prediction intervals.</p>
</td></tr>
<tr><td><code>upr</code></td>
<td>
<p>upper bound of confidence/prediction intervals.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Catherine Schramm, Aurelie Labbe, Celia Greenwood
</p>


<h3>See Also</h3>

<p><a href="#topic+kspm">kspm</a>, <a href="#topic+summary.kspm">summary.kspm</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- 1:15
z1 &lt;- runif(15, 1, 6)
z2 &lt;- rnorm(15, 1, 2)
y &lt;- 3*x + (z1 + z2)^2 + rnorm(15, 0, 2)
fit &lt;- kspm(y, linear = ~ x, kernel = ~ Kernel(~ z1 + z2,
kernel.function = "polynomial", d= 2, rho = 1, gamma = 0))
predict(fit, interval = "confidence")

</code></pre>

<hr>
<h2 id='print.kspm'>Print results from a Kernel Semi parametric Model Fit</h2><span id='topic+print.kspm'></span><span id='topic+print.summary.kspm'></span>

<h3>Description</h3>

<p>print method for class &quot;kspm&quot;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'kspm'
print(x, ...)

## S3 method for class 'summary.kspm'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="print.kspm_+3A_x">x</code></td>
<td>
<p>an object used to select a method. Usually, a result of a call to <code>kspm</code> or a result from <code>summary.kspm</code>.</p>
</td></tr>
<tr><td><code id="print.kspm_+3A_...">...</code></td>
<td>
<p>additional optional argument (currently unused).</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Catherine Schramm, Aurelie Labbe, Celia Greenwood
</p>


<h3>See Also</h3>

<p><a href="#topic+kspm">kspm</a> for fitting model, <a href="#topic+summary.kspm">summary.kspm</a>
</p>

<hr>
<h2 id='residuals.kspm'>Extract residuals from a Kernel Semi Parametric Model</h2><span id='topic+residuals.kspm'></span>

<h3>Description</h3>

<p>Returns the vector of residuals for a model fit of class &quot;kspm&quot;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'kspm'
residuals(object, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="residuals.kspm_+3A_object">object</code></td>
<td>
<p>an object of class &quot;kspm&quot;, usually, a result of a call to <code>kspm</code>.</p>
</td></tr>
<tr><td><code id="residuals.kspm_+3A_...">...</code></td>
<td>
<p>additional optional argument (currently unused).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of residuals. The vector length is the number of observations used in model coefficients estimation (see <a href="#topic+nobs.kspm">nobs.kspm</a>).
</p>


<h3>Author(s)</h3>

<p>Catherine Schramm, Aurelie Labbe, Celia Greenwood
</p>


<h3>See Also</h3>

<p><a href="#topic+kspm">kspm</a> for fitting model, <a href="#topic+nobs.kspm">nobs.kspm</a>, <a href="#topic+rstandard.kspm">rstandard.kspm</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- 1:15
y &lt;- 3*x + rnorm(15, 0, 2)
fit &lt;- kspm(y, kernel = ~ Kernel(x, kernel.function = "linear"))
residuals(fit)

</code></pre>

<hr>
<h2 id='rstandard.kspm'>Standardized residuals for Kernel Semi parametric Model Fits</h2><span id='topic+rstandard.kspm'></span>

<h3>Description</h3>

<p>computes standardized residuals for an object of class &quot;kspm&quot;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'kspm'
rstandard(model, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rstandard.kspm_+3A_model">model</code></td>
<td>
<p>an model of class &quot;kspm&quot;, usually, a result of a call to <code>kspm</code>.</p>
</td></tr>
<tr><td><code id="rstandard.kspm_+3A_...">...</code></td>
<td>
<p>furter arguments passed to or from other methods (currently unused).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Standardized residuals <code class="reqn">t_i</code> are obtained by <code class="reqn">t_i = \frac{e_i}{\hat{\sigma} \sqrt{1 - h_{ii}}}</code> where <code class="reqn">e_i</code> is the residual, <code class="reqn">\hat{\sigma}</code> is the estimated standard deviation of the errors and <code class="reqn">h_{ii}</code> is the leverage of subject i, i.e. the i th diagonal element of the Hat matrix.
</p>


<h3>Value</h3>

<p>a vector containing the standardized residuals.
</p>


<h3>Author(s)</h3>

<p>Catherine Schramm, Aurelie Labbe, Celia Greenwood
</p>


<h3>See Also</h3>

<p><a href="#topic+kspm">kspm</a> for fitting model, <a href="#topic+residuals.kspm">residuals.kspm</a>, <a href="#topic+cooks.distance.kspm">cooks.distance.kspm</a>, <a href="#topic+plot.kspm">plot.kspm</a>.
</p>

<hr>
<h2 id='search.parameters'>Optimisation to cumpute hyperparameter in Kernel Semi Parametric model</h2><span id='topic+search.parameters'></span>

<h3>Description</h3>

<p>internal function to optimize model for estimating hyperparameters
</p>


<h3>Usage</h3>

<pre><code class='language-R'>search.parameters(Y = NULL, X = NULL, kernelList = NULL, n = NULL,
  not.missing = NULL, compute.kernel = NULL, controlKspm = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="search.parameters_+3A_y">Y</code></td>
<td>
<p>response matrix</p>
</td></tr>
<tr><td><code id="search.parameters_+3A_x">X</code></td>
<td>
<p>X matrix</p>
</td></tr>
<tr><td><code id="search.parameters_+3A_kernellist">kernelList</code></td>
<td>
<p>of kernels</p>
</td></tr>
<tr><td><code id="search.parameters_+3A_n">n</code></td>
<td>
<p>nb of samples</p>
</td></tr>
<tr><td><code id="search.parameters_+3A_not.missing">not.missing</code></td>
<td>
<p>nb of non missing samples</p>
</td></tr>
<tr><td><code id="search.parameters_+3A_compute.kernel">compute.kernel</code></td>
<td>
<p>boolean kernel computation</p>
</td></tr>
<tr><td><code id="search.parameters_+3A_controlkspm">controlKspm</code></td>
<td>
<p>control parameters</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Catherine Schramm, Aurelie Labbe, Celia Greenwood
</p>

<hr>
<h2 id='sigma.kspm'>Extract residuals standard deviation</h2><span id='topic+sigma.kspm'></span>

<h3>Description</h3>

<p>Returns the residuals standard deviation (sigma) for object of class &quot;kspm&quot;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'kspm'
sigma(object, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="sigma.kspm_+3A_object">object</code></td>
<td>
<p>an object of class &quot;kspm&quot;, usually, a result of a call to <code>kspm</code>.</p>
</td></tr>
<tr><td><code id="sigma.kspm_+3A_...">...</code></td>
<td>
<p>additional optional argument (currently unused).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The value returned by the method is <code class="reqn">\sqrt{\frac{RSS}{edf}}</code> where <code class="reqn">RSS</code> is the residual sum of squares and <code class="reqn">edf</code> is the effective degree of freedom.
</p>


<h3>Value</h3>

<p>typically a number, the estimated standard deviation of the errors (&quot;residual standard deviation&quot;)
</p>


<h3>Author(s)</h3>

<p>Catherine Schramm, Aurelie Labbe, Celia Greenwood
</p>


<h3>See Also</h3>

<p><a href="#topic+kspm">kspm</a> for fitting model, <a href="#topic+summary.kspm">summary.kspm</a>, <a href="#topic+residuals.kspm">residuals.kspm</a>, <a href="#topic+nobs.kspm">nobs.kspm</a>, <a href="#topic+deviance.kspm">deviance.kspm</a>.
</p>

<hr>
<h2 id='stepKSPM'>Choose a model by AIC or BIC in a Stepwise Algorithm</h2><span id='topic+stepKSPM'></span>

<h3>Description</h3>

<p>Performs stepwise model selection for Kernel Semi Parametric Model by AIC or BIC.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>stepKSPM(object, data = NULL, linear.lower = NULL,
  linear.upper = NULL, kernel.lower = NULL, kernel.upper = NULL,
  direction = "both", k = 2, kernel.param = "fixed", trace = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="stepKSPM_+3A_object">object</code></td>
<td>
<p>an object of class &quot;kspm&quot; with only one kernel.</p>
</td></tr>
<tr><td><code id="stepKSPM_+3A_data">data</code></td>
<td>
<p>data.</p>
</td></tr>
<tr><td><code id="stepKSPM_+3A_linear.lower">linear.lower</code></td>
<td>
<p>one side formula corresponding to the smallest set of variables that should be included in the linear part of the model.</p>
</td></tr>
<tr><td><code id="stepKSPM_+3A_linear.upper">linear.upper</code></td>
<td>
<p>one side formula corresponding to the largest set of variables that may be included in the linear part of the model.</p>
</td></tr>
<tr><td><code id="stepKSPM_+3A_kernel.lower">kernel.lower</code></td>
<td>
<p>one side formula corresponding to the smallest set of variables that should be included in the kernel part of the model.</p>
</td></tr>
<tr><td><code id="stepKSPM_+3A_kernel.upper">kernel.upper</code></td>
<td>
<p>one side formula corresponding to the  largest set of variables that may be included in the kernel part of the model.</p>
</td></tr>
<tr><td><code id="stepKSPM_+3A_direction">direction</code></td>
<td>
<p>the mode of stepwise search, can be one of &quot;both&quot; (default), &quot;backward&quot;, or &quot;forward&quot;.</p>
</td></tr>
<tr><td><code id="stepKSPM_+3A_k">k</code></td>
<td>
<p>type of information criteria used for the variable selection. If <code>k=2</code> AIC is used (default), if <code>k=log(n)</code>, BIC is used instead.</p>
</td></tr>
<tr><td><code id="stepKSPM_+3A_kernel.param">kernel.param</code></td>
<td>
<p>define if hyperparameters should be fixed (<code>"fixed"</code>) or reestimated at each iteration (<code>"change"</code>). Tu use the last option, hyperparameter of model provided in <code>object</code> should have been estimated by the model.</p>
</td></tr>
<tr><td><code id="stepKSPM_+3A_trace">trace</code></td>
<td>
<p>integer. If positive, information is printed during the running of step.kspm. Larger values may give more information on the fitting process.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This procedure may be done on <code>kspm</code> object defined with only one kernel part and for which a data frame including all variables was provided. Selection may be done on linear part only, on kernel part only or on both at the same time. To perform selection on linear (resp. kernel) part only, <code>kernel.lower</code> and <code>kernel.upper</code> (resp. <code>linear.lower</code> and <code>linear.upper</code>) should contain all the variables that should stay in the model for kernel (resp. linear) part.
</p>


<h3>Value</h3>

<p><code>stepKSPM</code> returns the selected model.
</p>


<h3>Author(s)</h3>

<p>Catherine Schramm, Aurelie Labbe, Celia Greenwood
</p>


<h3>See Also</h3>

<p><a href="#topic+extractAIC.kspm">extractAIC.kspm</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- 1:15
z1 &lt;- runif(15, 1, 6)
z2 &lt;- rnorm(15, 1, 4)
z3 &lt;- rnorm(15, 6, 2)
z4 &lt;- runif(15, -10, 2)
y &lt;- 3*x + (z1 + z2)^2 + rnorm(15, 0, 2)
dfrm &lt;- data.frame(x = x, z1 = z1, z2 = z2, z3 = z3, z4 = z4, y = y)
fit &lt;- kspm(y, linear = ~ x, kernel = ~ Kernel(~ z1 + z2 + z3 + z4,
kernel.function = "polynomial", d= 2, rho = 1, gamma = 0), data = dfrm)
stepKSPM(fit, k = 2, data = dfrm)

</code></pre>

<hr>
<h2 id='summary.kspm'>Summarizing Kernel Semi parametric Model Fits</h2><span id='topic+summary.kspm'></span>

<h3>Description</h3>

<p>summary method for an object of class &quot;kspm&quot;
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'kspm'
summary(object, kernel.test = "all",
  global.test = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="summary.kspm_+3A_object">object</code></td>
<td>
<p>an object of class &quot;kspm&quot;, usually, a result of a call to <code>kspm</code>.</p>
</td></tr>
<tr><td><code id="summary.kspm_+3A_kernel.test">kernel.test</code></td>
<td>
<p>vector of characters indicating for which kernel a test should be performed. Default is <code>"all"</code>. If <code>"none"</code>, no test will be performed.</p>
</td></tr>
<tr><td><code id="summary.kspm_+3A_global.test">global.test</code></td>
<td>
<p>logical, if <code>TRUE</code>, a global test for kernel part is computed.</p>
</td></tr>
<tr><td><code id="summary.kspm_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>the description of the model, including coefficients for the linear part and if asked for, test(s) of variance components associated with kernel part.
</p>


<h3>Value</h3>

<p>Computes and returns the followimg summary statistics of the fitted kernel semi parametric model given in object
</p>
<table role = "presentation">
<tr><td><code>residuals</code></td>
<td>
<p>residuals</p>
</td></tr>
<tr><td><code>coefficients</code></td>
<td>
<p>a <code class="reqn">p \times 4</code> matrix with columns for the estimated coefficient, its standard error, t statistic and corresponding (two sided) p value for the linear part of the model.</p>
</td></tr>
<tr><td><code>sigma</code></td>
<td>
<p>the square root of the estimated variance of the random error <code class="reqn">\sigma^2 = \frac{RSS}{edf} </code> where <code class="reqn">RSS</code> is the residual sum of squares and <code class="reqn">edf</code> is the effective degree of freedom.</p>
</td></tr>
<tr><td><code>edf</code></td>
<td>
<p>effective degrees of freedom</p>
</td></tr>
<tr><td><code>r.squared</code></td>
<td>
<p><code class="reqn">R^2</code>, the fraction of variance explained by the model, <code class="reqn">1 - \frac{\sum e_i^2}{\sum(y_i - y^{\ast})^2}</code> where <code class="reqn">y^{\ast}</code> is the mean of <code class="reqn">y_i</code> if there is an intercept and zero otherwise.</p>
</td></tr>
<tr><td><code>adj.r.squared</code></td>
<td>
<p>the above <code class="reqn">R^2</code> statistics, adjusted, penalizing for higher <code class="reqn">p</code>.</p>
</td></tr>
<tr><td><code>score.test</code></td>
<td>
<p>a <code class="reqn">q \times 3</code> matrix with colums for the estimated lambda, tau and p value for the q kernels for which a test should be performed.</p>
</td></tr>
<tr><td><code>global.p.value</code></td>
<td>
<p>p value from the score test for the global model.</p>
</td></tr>
<tr><td><code>sample.size</code></td>
<td>
<p>sample size (all: global sample size, inc: complete data sample size).</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Catherine Schramm, Aurelie Labbe, Celia Greenwood
</p>


<h3>References</h3>

<p>Liu, D., Lin, X., and Ghosh, D. (2007). Semiparametric regression of multidimensional genetic pathway data: least squares kernel machines and linear mixed models. Biometrics, 63(4), 1079:1088.
</p>
<p>Schweiger, Regev, et al. &quot;RL SKAT: an exact and efficient score test for heritability and set tests.&quot; Genetics (2017): genetics 300395.
</p>
<p>Li, Shaoyu, and Yuehua Cui. &quot;Gene centric gene gene interaction: A model based kernel machine method.&quot; The Annals of Applied Statistics 6.3 (2012): 1134:1161.
</p>


<h3>See Also</h3>

<p><a href="#topic+kspm">kspm</a> for fitting model, <a href="#topic+predict.kspm">predict.kspm</a> for predictions, <a href="#topic+plot.kspm">plot.kspm</a> for diagnostics
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- 1:15
z1 &lt;- runif(15, 1, 6)
z2 &lt;- rnorm(15, 1, 2)
y &lt;- 3*x + (z1 + z2)^2 + rnorm(15, 0, 2)
fit &lt;- kspm(y, linear = ~ x, kernel = ~ Kernel(~ z1 + z2,
kernel.function = "polynomial", d= 2, rho = 1, gamma = 0))
summary(fit)

</code></pre>

<hr>
<h2 id='test.function'>Score Tests for kernel part in kernel semi parametric model</h2><span id='topic+test.function'></span><span id='topic+test.1.kernel'></span><span id='topic+test.global.kernel'></span><span id='topic+test.k.kernel'></span>

<h3>Description</h3>

<p>Perform score tests for kernel part in kernel semi parametric model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>test.1.kernel(object)

test.global.kernel(object)

test.k.kernel(object, kernel.name)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="test.function_+3A_object">object</code></td>
<td>
<p>an object of class &quot;kspm&quot;</p>
</td></tr>
<tr><td><code id="test.function_+3A_kernel.name">kernel.name</code></td>
<td>
<p>vector of character listing names of kernels for which test should be performed</p>
</td></tr>
</table>


<h3>Value</h3>

<p>p values
</p>


<h3>Author(s)</h3>

<p>Catherine Schramm, Aurelie Labbe, Celia Greenwood
</p>


<h3>References</h3>

<p>Schweiger, Regev, et al. &quot;RL SKAT: an exact and efficient score test for heritability and set tests.&quot; Genetics (2017): genetics 300395.
</p>
<p>Li, Shaoyu, and Yuehua Cui. &quot;Gene centric gene gene interaction: A model based kernel machine method.&quot; The Annals of Applied Statistics 6.3 (2012): 1134:1161.
</p>
<p>Oualkacha, Karim, et al. &quot;Adjusted sequence kernel association test for rare variants controlling for cryptic and family relatedness.&quot; Genetic epidemiology 37.4 (2013): 366:376.
</p>
<p>Ge, Tian, et al. &quot;A kernel machine method for detecting effects of interaction between multidimensional variable sets: An imaging genetics application.&quot; Neuroimage 109 (2015): 505:514.
</p>

<hr>
<h2 id='variable.names.kspm'>Variable names of fitted models</h2><span id='topic+variable.names.kspm'></span>

<h3>Description</h3>

<p>Simple utility returning names of variables involved in a kernel semi parametric model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'kspm'
variable.names(object, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="variable.names.kspm_+3A_object">object</code></td>
<td>
<p>an object of class &quot;kspm&quot;, usually, a result of a call to <code>kspm</code>.</p>
</td></tr>
<tr><td><code id="variable.names.kspm_+3A_...">...</code></td>
<td>
<p>additional optional argument (currently unused).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list of character vectors. The first element correspond to the names of variables included in the linear part of the model. Then, a vector containing names of variables including in kernel part is provided for each kernel.
</p>


<h3>Author(s)</h3>

<p>Catherine Schramm, Aurelie Labbe, Celia Greenwood
</p>


<h3>See Also</h3>

<p><a href="#topic+kspm">kspm</a>, <a href="#topic+summary.kspm">summary.kspm</a>, <a href="#topic+case.names.kspm">case.names.kspm</a>.
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
