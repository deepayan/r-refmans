<!DOCTYPE html><html><head><title>Help for package googleCloudVisionR</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {googleCloudVisionR}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#call_vision_api'><p>helper function to send POST request to the Google Vision API</p></a></li>
<li><a href='#create_request_body'><p>helper function to create json for response request</p></a></li>
<li><a href='#create_single_image_request'><p>helper function to create a list of details of one image annotation request</p></a></li>
<li><a href='#encode_image'><p>helper function to base64 encode the image file</p></a></li>
<li><a href='#extract_annotations'><p>helper function code to extract the annotations</p></a></li>
<li><a href='#extract_error'><p>helper function code to extract error from API response into a data.table</p></a></li>
<li><a href='#extract_response'><p>helper function code to extract the response data.frame</p></a></li>
<li><a href='#extractor'><p>helper function code to provide an extractor function for different feature types</p></a></li>
<li><a href='#face_detection_extractor'><p>helper function code to extract API response into a data.table for given feature type</p></a></li>
<li><a href='#gcv_get_available_feature_types'><p>helper function code to record available feature types</p></a></li>
<li><a href='#gcv_get_image_annotations'><p>Get parsed image annotations from the Google Cloud Vision API</p></a></li>
<li><a href='#gcv_get_raw_response'><p>Get raw API response from the Google Cloud Vision API</p></a></li>
<li><a href='#gcv_get_response'><p>helper function to call the API for one batch of images</p></a></li>
<li><a href='#get_bounding_boxes'><p>helper function code to extract Bounding Box x,y coordinates for an API response element</p></a></li>
<li><a href='#get_invalid_image_paths'><p>helper function to validate input image paths</p></a></li>
<li><a href='#googleCloudVisionR-package'><p>googleCloudVisionR: Access to the 'Google Cloud Vision' API for Image Recognition, OCR and</p>
Labeling</a></li>
<li><a href='#label_detection_extractor'><p>helper function code to extract API response into a data.table for given feature type</p></a></li>
<li><a href='#landmark_detection_extractor'><p>helper function code to extract API response into a data.table for given feature type</p></a></li>
<li><a href='#logo_detection_extractor'><p>helper function code to extract API response into a data.table for given feature type</p></a></li>
<li><a href='#ocr_extractor'><p>helper function code to extract API response into a data.table for given feature type</p></a></li>
<li><a href='#split_to_chunks'><p>helper function to split a vector to approximately equally sized chunks</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Title:</td>
<td>Access to the 'Google Cloud Vision' API for Image Recognition,
OCR and Labeling</td>
</tr>
<tr>
<td>Description:</td>
<td>Interact with the 'Google Cloud Vision' <a href="https://cloud.google.com/vision/">https://cloud.google.com/vision/</a>
  API in R. Part of the 'cloudyr' <a href="https://cloudyr.github.io/">https://cloudyr.github.io/</a> project.</td>
</tr>
<tr>
<td>Version:</td>
<td>0.2.0</td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/cloudyr/googleCloudVisionR/issues">https://github.com/cloudyr/googleCloudVisionR/issues</a></td>
</tr>
<tr>
<td>Imports:</td>
<td>googleAuthR, jsonlite, purrr, data.table, glue</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>6.1.1</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, rmarkdown, testthat, mockery, covr</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2020-02-07 13:44:04 UTC; jpal</td>
</tr>
<tr>
<td>Author:</td>
<td>Jeno Pal [cre],
  Tamas Koncz [aut],
  Balazs Varkoly [aut],
  Peter Lukacs [aut],
  Eszter Kocsis [aut],
  Florian Teschner [ctb]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Jeno Pal &lt;paljenczy@gmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2020-02-07 14:00:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='call_vision_api'>helper function to send POST request to the Google Vision API</h2><span id='topic+call_vision_api'></span>

<h3>Description</h3>

<p>sends the request defined in 'body' to the API
</p>


<h3>Usage</h3>

<pre><code class='language-R'>call_vision_api(body, apiEndpoint = "images:annotate",
  httpRequestType = "POST")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="call_vision_api_+3A_body">body</code></td>
<td>
<p>output of create_request_body()</p>
</td></tr>
<tr><td><code id="call_vision_api_+3A_apiendpoint">apiEndpoint</code></td>
<td>
<p>character, api endpoint</p>
</td></tr>
<tr><td><code id="call_vision_api_+3A_httprequesttype">httpRequestType</code></td>
<td>
<p>character, type of the http request</p>
</td></tr>
</table>


<h3>Value</h3>

<p>API response in raw format
</p>

<hr>
<h2 id='create_request_body'>helper function to create json for response request</h2><span id='topic+create_request_body'></span>

<h3>Description</h3>

<p>creates a json output from the inputs
</p>


<h3>Usage</h3>

<pre><code class='language-R'>create_request_body(imagePaths, feature, maxNumResults)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="create_request_body_+3A_imagepaths">imagePaths</code></td>
<td>
<p>character, file paths, URLs or Cloud Storage URIs of the images,
can be a combination of all three</p>
</td></tr>
<tr><td><code id="create_request_body_+3A_feature">feature</code></td>
<td>
<p>character, one out of: &quot;LABEL_DETECTION&quot;, &quot;FACE_DETECTION&quot;,
&quot;TEXT_DETECTION&quot;, &quot;DOCUMENT_TEXT_DETECTION&quot;, &quot;LOGO_DETECTION&quot;, &quot;LANDMARK_DETECTION&quot;</p>
</td></tr>
<tr><td><code id="create_request_body_+3A_maxnumresults">maxNumResults</code></td>
<td>
<p>integer, the maximum number of results (per image) to be returned.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>request body (payload), encoded as json
</p>

<hr>
<h2 id='create_single_image_request'>helper function to create a list of details of one image annotation request</h2><span id='topic+create_single_image_request'></span>

<h3>Description</h3>

<p>creates a list output from the inputs
</p>


<h3>Usage</h3>

<pre><code class='language-R'>create_single_image_request(imagePath, feature, maxNumResults)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="create_single_image_request_+3A_imagepath">imagePath</code></td>
<td>
<p>character, file path, URL or Cloud Storage URI of the image</p>
</td></tr>
<tr><td><code id="create_single_image_request_+3A_feature">feature</code></td>
<td>
<p>character, one out of: &quot;LABEL_DETECTION&quot;, &quot;FACE_DETECTION&quot;,
&quot;TEXT_DETECTION&quot;, &quot;DOCUMENT_TEXT_DETECTION&quot;, &quot;LOGO_DETECTION&quot;, &quot;LANDMARK_DETECTION&quot;</p>
</td></tr>
<tr><td><code id="create_single_image_request_+3A_maxnumresults">maxNumResults</code></td>
<td>
<p>integer, the maximum number of results (per image) to be returned.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>list of request details for one image
</p>

<hr>
<h2 id='encode_image'>helper function to base64 encode the image file</h2><span id='topic+encode_image'></span>

<h3>Description</h3>

<p>base64 encodes an image file
</p>


<h3>Usage</h3>

<pre><code class='language-R'>encode_image(imagePath)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="encode_image_+3A_imagepath">imagePath</code></td>
<td>
<p>character, path to the image</p>
</td></tr>
</table>


<h3>Value</h3>

<p>get the image back as encoded file
</p>

<hr>
<h2 id='extract_annotations'>helper function code to extract the annotations</h2><span id='topic+extract_annotations'></span>

<h3>Description</h3>

<p>a utility to extract features from the API response
</p>


<h3>Usage</h3>

<pre><code class='language-R'>extract_annotations(responses, imagePaths, featureType)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="extract_annotations_+3A_responses">responses</code></td>
<td>
<p>an API response object</p>
</td></tr>
<tr><td><code id="extract_annotations_+3A_imagepaths">imagePaths</code></td>
<td>
<p>character, file paths, URLs or Cloud Storage URIs of the images,
can be a combination of all three</p>
</td></tr>
<tr><td><code id="extract_annotations_+3A_featuretype">featureType</code></td>
<td>
<p>the type of annotation as called in the response object</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a data.table
</p>

<hr>
<h2 id='extract_error'>helper function code to extract error from API response into a data.table</h2><span id='topic+extract_error'></span>

<h3>Description</h3>

<p>helper function code to extract error from API response into a data.table
</p>


<h3>Usage</h3>

<pre><code class='language-R'>extract_error(responses, imagePaths)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="extract_error_+3A_responses">responses</code></td>
<td>
<p>an API response object</p>
</td></tr>
<tr><td><code id="extract_error_+3A_imagepaths">imagePaths</code></td>
<td>
<p>character, file paths, URLs or Cloud Storage URIs of the images,
can be a combination of all three</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a data.table
</p>

<hr>
<h2 id='extract_response'>helper function code to extract the response data.frame</h2><span id='topic+extract_response'></span>

<h3>Description</h3>

<p>a utility to extract features from the API response
</p>


<h3>Usage</h3>

<pre><code class='language-R'>extract_response(responses, imagePaths, feature)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="extract_response_+3A_responses">responses</code></td>
<td>
<p>an API response object</p>
</td></tr>
<tr><td><code id="extract_response_+3A_imagepaths">imagePaths</code></td>
<td>
<p>character, file paths, URLs or Cloud Storage URIs of the images,
can be a combination of all three</p>
</td></tr>
<tr><td><code id="extract_response_+3A_feature">feature</code></td>
<td>
<p>character, one out of: &quot;LABEL_DETECTION&quot;, &quot;FACE_DETECTION&quot;,
&quot;TEXT_DETECTION&quot;, &quot;DOCUMENT_TEXT_DETECTION&quot;, &quot;LOGO_DETECTION&quot;, &quot;LANDMARK_DETECTION&quot;</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a data.table
</p>

<hr>
<h2 id='extractor'>helper function code to provide an extractor function for different feature types</h2><span id='topic+extractor'></span>

<h3>Description</h3>

<p>a utility to provide functions to extract features from the API response
</p>


<h3>Usage</h3>

<pre><code class='language-R'>extractor(featureType)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="extractor_+3A_featuretype">featureType</code></td>
<td>
<p>the type of annotation as called in the response object</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a function
</p>

<hr>
<h2 id='face_detection_extractor'>helper function code to extract API response into a data.table for given feature type</h2><span id='topic+face_detection_extractor'></span>

<h3>Description</h3>

<p>helper function code to extract API response into a data.table for given feature type
</p>


<h3>Usage</h3>

<pre><code class='language-R'>face_detection_extractor(response)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="face_detection_extractor_+3A_response">response</code></td>
<td>
<p>an element of the API response object</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a data.table
</p>

<hr>
<h2 id='gcv_get_available_feature_types'>helper function code to record available feature types</h2><span id='topic+gcv_get_available_feature_types'></span>

<h3>Description</h3>

<p>helper function code to record available feature types
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gcv_get_available_feature_types()
</code></pre>


<h3>Value</h3>

<p>a list of available features names and their types (as returned by the API)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>gcv_get_available_feature_types()

</code></pre>

<hr>
<h2 id='gcv_get_image_annotations'>Get parsed image annotations from the Google Cloud Vision API</h2><span id='topic+gcv_get_image_annotations'></span>

<h3>Description</h3>

<p>Given a list of images, a feature type and the maximum number of responses,
this functions calls the Google Cloud Vision API, and returns the image annotations in a data.table format.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gcv_get_image_annotations(imagePaths, feature = "LABEL_DETECTION",
  maxNumResults = NULL, batchSize = 64L, savePath = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gcv_get_image_annotations_+3A_imagepaths">imagePaths</code></td>
<td>
<p>character, file paths, URLs or Cloud Storage URIs of the images,
can be a combination of all three</p>
</td></tr>
<tr><td><code id="gcv_get_image_annotations_+3A_feature">feature</code></td>
<td>
<p>character, one out of: &quot;LABEL_DETECTION&quot;, &quot;FACE_DETECTION&quot;,
&quot;TEXT_DETECTION&quot;, &quot;DOCUMENT_TEXT_DETECTION&quot;, &quot;LOGO_DETECTION&quot;, &quot;LANDMARK_DETECTION&quot;</p>
</td></tr>
<tr><td><code id="gcv_get_image_annotations_+3A_maxnumresults">maxNumResults</code></td>
<td>
<p>integer, the maximum number of results (per image) to be returned.</p>
</td></tr>
<tr><td><code id="gcv_get_image_annotations_+3A_batchsize">batchSize</code></td>
<td>
<p>integer, the chunk size for batch processing</p>
</td></tr>
<tr><td><code id="gcv_get_image_annotations_+3A_savepath">savePath</code></td>
<td>
<p>character, if specified, results will be saved to this path (as .csv)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a data frame with image annotation results
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
    # Label Detection (default), with maximum 7 results returned per image
    imagePath &lt;- system.file(
      "extdata", "golden_retriever_puppies.jpg", package = "googleCloudVisionR"
    )
    gcv_get_image_annotations(imagePaths = imagePath, maxNumResults = 7)

    # Face detection
    imagePath &lt;- system.file(
      "extdata", "arnold_wife.jpg", package = "googleCloudVisionR"
    )
    gcv_get_image_annotations(imagePaths = imagePath, feature = "FACE_DETECTION")

    # Google Cloud Storage URI as input
    gcv_get_image_annotations("gs://vision-api-handwriting-ocr-bucket/handwriting_image.png")

## End(Not run)

</code></pre>

<hr>
<h2 id='gcv_get_raw_response'>Get raw API response from the Google Cloud Vision API</h2><span id='topic+gcv_get_raw_response'></span>

<h3>Description</h3>

<p>Given a list of images, a feature type and the maximum number of responses,
this functions calls the Google Cloud Vision API, and returns the raw response from the API.
For a friendlier response, refer to the 'gcv_get_image_annotations' function, which returns
results in a data.table format (however, the information returned is limited compared to the
raw response).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gcv_get_raw_response(imagePaths, feature = "LABEL_DETECTION",
  maxNumResults = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gcv_get_raw_response_+3A_imagepaths">imagePaths</code></td>
<td>
<p>character, file paths, URLs or Cloud Storage URIs of the images,
can be a combination of all three</p>
</td></tr>
<tr><td><code id="gcv_get_raw_response_+3A_feature">feature</code></td>
<td>
<p>character, one out of: &quot;LABEL_DETECTION&quot;, &quot;FACE_DETECTION&quot;,
&quot;TEXT_DETECTION&quot;, &quot;DOCUMENT_TEXT_DETECTION&quot;, &quot;LOGO_DETECTION&quot;, &quot;LANDMARK_DETECTION&quot;</p>
</td></tr>
<tr><td><code id="gcv_get_raw_response_+3A_maxnumresults">maxNumResults</code></td>
<td>
<p>integer, the maximum number of results (per image) to be returned.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a response object returned by the API. To get the image annotations, take the
&quot;content&quot; element from the object
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
    imagePath &lt;- system.file(
      "extdata", "golden_retriever_puppies.jpg", package = "googleCloudVisionR"
    )
    raw_response &lt;- gcv_get_raw_response(imagePaths = imagePath, maxNumResults = 7)

    str(raw_response)
    raw_response[["content"]]

## End(Not run)

</code></pre>

<hr>
<h2 id='gcv_get_response'>helper function to call the API for one batch of images</h2><span id='topic+gcv_get_response'></span>

<h3>Description</h3>

<p>helper function to call the API for one batch of images
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gcv_get_response(imagePaths, feature, maxNumResults)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gcv_get_response_+3A_imagepaths">imagePaths</code></td>
<td>
<p>character, file paths, URLs or Cloud Storage URIs of the images,
can be a combination of all three</p>
</td></tr>
<tr><td><code id="gcv_get_response_+3A_feature">feature</code></td>
<td>
<p>character, one out of: &quot;LABEL_DETECTION&quot;, &quot;FACE_DETECTION&quot;,
&quot;TEXT_DETECTION&quot;, &quot;DOCUMENT_TEXT_DETECTION&quot;, &quot;LOGO_DETECTION&quot;, &quot;LANDMARK_DETECTION&quot;</p>
</td></tr>
<tr><td><code id="gcv_get_response_+3A_maxnumresults">maxNumResults</code></td>
<td>
<p>integer, the maximum number of results (per image) to be returned.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a data frame with image annotation results
</p>

<hr>
<h2 id='get_bounding_boxes'>helper function code to extract Bounding Box x,y coordinates for an API response element</h2><span id='topic+get_bounding_boxes'></span>

<h3>Description</h3>

<p>helper function code to extract Bounding Box x,y coordinates for an API response element
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_bounding_boxes(response)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_bounding_boxes_+3A_response">response</code></td>
<td>
<p>an element of the API response object</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a data.table
</p>

<hr>
<h2 id='get_invalid_image_paths'>helper function to validate input image paths</h2><span id='topic+get_invalid_image_paths'></span>

<h3>Description</h3>

<p>helper function to validate input image paths
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_invalid_image_paths(vec)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_invalid_image_paths_+3A_vec">vec</code></td>
<td>
<p>a vector of paths</p>
</td></tr>
</table>


<h3>Value</h3>

<p>vector of invalid paths from @vec
</p>

<hr>
<h2 id='googleCloudVisionR-package'>googleCloudVisionR: Access to the 'Google Cloud Vision' API for Image Recognition, OCR and
Labeling</h2><span id='topic+googleCloudVisionR'></span><span id='topic+googleCloudVisionR-package'></span>

<h3>Description</h3>

<p>Interact with the 'Google Cloud Vision' &lt;https://cloud.google.com/vision/&gt;
API in R. Part of the 'cloudyr' &lt;https://cloudyr.github.io/&gt; project.
</p>


<h3>Author(s)</h3>

<p><strong>Maintainer</strong>: Jeno Pal <a href="mailto:paljenczy@gmail.com">paljenczy@gmail.com</a>
</p>
<p>Authors:
</p>

<ul>
<li><p> Tamas Koncz <a href="mailto:t.koncz@gmail.com">t.koncz@gmail.com</a>
</p>
</li>
<li><p> Balazs Varkoly <a href="mailto:varkoly.balazs@gmail.com">varkoly.balazs@gmail.com</a>
</p>
</li>
<li><p> Peter Lukacs <a href="mailto:lukacs.peter.andras@gmail.com">lukacs.peter.andras@gmail.com</a>
</p>
</li>
<li><p> Eszter Kocsis <a href="mailto:p.kocsis.eszter@gmail.com">p.kocsis.eszter@gmail.com</a>
</p>
</li></ul>

<p>Other contributors:
</p>

<ul>
<li><p> Florian Teschner [contributor]
</p>
</li></ul>



<h3>See Also</h3>

<p>Useful links:
</p>

<ul>
<li><p> Report bugs at <a href="https://github.com/cloudyr/googleCloudVisionR/issues">https://github.com/cloudyr/googleCloudVisionR/issues</a>
</p>
</li></ul>


<hr>
<h2 id='label_detection_extractor'>helper function code to extract API response into a data.table for given feature type</h2><span id='topic+label_detection_extractor'></span>

<h3>Description</h3>

<p>helper function code to extract API response into a data.table for given feature type
</p>


<h3>Usage</h3>

<pre><code class='language-R'>label_detection_extractor(response)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="label_detection_extractor_+3A_response">response</code></td>
<td>
<p>an element of the API response object</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a data.table
</p>

<hr>
<h2 id='landmark_detection_extractor'>helper function code to extract API response into a data.table for given feature type</h2><span id='topic+landmark_detection_extractor'></span>

<h3>Description</h3>

<p>helper function code to extract API response into a data.table for given feature type
</p>


<h3>Usage</h3>

<pre><code class='language-R'>landmark_detection_extractor(response)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="landmark_detection_extractor_+3A_response">response</code></td>
<td>
<p>an element of the API response object</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a data.table
</p>

<hr>
<h2 id='logo_detection_extractor'>helper function code to extract API response into a data.table for given feature type</h2><span id='topic+logo_detection_extractor'></span>

<h3>Description</h3>

<p>helper function code to extract API response into a data.table for given feature type
</p>


<h3>Usage</h3>

<pre><code class='language-R'>logo_detection_extractor(response)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="logo_detection_extractor_+3A_response">response</code></td>
<td>
<p>an element of the API response object</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a data.table
</p>

<hr>
<h2 id='ocr_extractor'>helper function code to extract API response into a data.table for given feature type</h2><span id='topic+ocr_extractor'></span>

<h3>Description</h3>

<p>helper function code to extract API response into a data.table for given feature type
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ocr_extractor(response)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ocr_extractor_+3A_response">response</code></td>
<td>
<p>an element of the API response object</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a data.table
</p>

<hr>
<h2 id='split_to_chunks'>helper function to split a vector to approximately equally sized chunks</h2><span id='topic+split_to_chunks'></span>

<h3>Description</h3>

<p>helper function to split a vector to approximately equally sized chunks
</p>


<h3>Usage</h3>

<pre><code class='language-R'>split_to_chunks(vec, chunkSize)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="split_to_chunks_+3A_vec">vec</code></td>
<td>
<p>a vector</p>
</td></tr>
<tr><td><code id="split_to_chunks_+3A_chunksize">chunkSize</code></td>
<td>
<p>integer, how long should the chunks be?</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list of chunks
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
