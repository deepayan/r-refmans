<!DOCTYPE html><html><head><title>Help for package msda</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {msda}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#cv.msda'>
<p>Cross-validation for msda</p></a></li>
<li><a href='#GDS1615'><p>GDS1615 data introduced in Burczynski et al. (2012).</p></a></li>
<li><a href='#msda'>
<p>Fits a regularization path for Multi-Class Sparse Discriminant Analysis</p></a></li>
<li><a href='#plot.msda'><p>Plot coefficients from a &quot;msda&quot; object</p></a></li>
<li><a href='#predict.msda'>
<p>make predictions from a &quot;msda&quot; object.</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Title:</td>
<td>Multi-Class Sparse Discriminant Analysis</td>
</tr>
<tr>
<td>Version:</td>
<td>1.0.3</td>
</tr>
<tr>
<td>Date:</td>
<td>2022-09-12</td>
</tr>
<tr>
<td>Author:</td>
<td>Qing Mai &lt;mai@stat.fsu.edu&gt;, Yi Yang &lt;yi.yang6@mcgill.ca&gt;,  Hui Zou &lt;hzou@stat.umn.edu&gt;</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Yi Yang &lt;yi.yang6@mcgill.ca&gt;</td>
</tr>
<tr>
<td>Depends:</td>
<td>Matrix, MASS</td>
</tr>
<tr>
<td>Imports:</td>
<td>methods</td>
</tr>
<tr>
<td>Description:</td>
<td>Efficient procedures for computing a new Multi-Class Sparse Discriminant Analysis method that estimates all discriminant directions simultaneously. It is an implementation of the work proposed by Mai, Q., Yang, Y., and Zou, H. (2019) &lt;<a href="https://doi.org/10.5705%2Fss.202016.0117">doi:10.5705/ss.202016.0117</a>&gt;. </td>
</tr>
<tr>
<td>LazyData:</td>
<td>yes</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a></td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/emeryyi/msda">https://github.com/emeryyi/msda</a></td>
</tr>
<tr>
<td>Packaged:</td>
<td>2022-09-12 04:50:15 UTC; jiaozi</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2022-09-12 08:00:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='cv.msda'>
Cross-validation for msda
</h2><span id='topic+cv.msda'></span>

<h3>Description</h3>

<p>Does k-fold cross-validation for msda, returns a value for <code>lambda</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cv.msda(x, y, nfolds = 5, lambda = NULL, lambda.opt = "min", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cv.msda_+3A_x">x</code></td>
<td>

<p>matrix of predictors, of dimension <code class="reqn">N \times p</code>; each row is an observation vector.</p>
</td></tr>
<tr><td><code id="cv.msda_+3A_y">y</code></td>
<td>

<p>response variable. This argument should be a factor for classification.</p>
</td></tr>
<tr><td><code id="cv.msda_+3A_nfolds">nfolds</code></td>
<td>

<p>number of folds - default is 5. Although <code>nfolds</code>
can be as large as the sample size (leave-one-out CV), it is not
recommended for large datasets. Smallest value allowable is <code>nfolds=3</code>.</p>
</td></tr>
<tr><td><code id="cv.msda_+3A_lambda">lambda</code></td>
<td>
<p>optional user-supplied lambda sequence; default is
<code>NULL</code>, and <code><a href="#topic+msda">msda</a></code> chooses its own sequence.</p>
</td></tr>
<tr><td><code id="cv.msda_+3A_lambda.opt">lambda.opt</code></td>
<td>
<p>If choose <code>"min"</code>, 
the smallest <code>lambda</code> that gives minimum
cross validation error <code>cvm</code> will be returned. If choose <code>"max"</code>, 
the largest <code>lambda</code> that gives minimum
cross validation error <code>cvm</code> will be returned.
</p>
</td></tr>
<tr><td><code id="cv.msda_+3A_...">...</code></td>
<td>

<p>other arguments that can be passed to msda.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function runs <code><a href="#topic+msda">msda</a></code> <code>nfolds</code>+1 times; the
first to get the <code>lambda</code> sequence, and then the remainder to
compute the fit with each of the folds omitted. The average error and standard deviation over the folds are computed.</p>


<h3>Value</h3>

<p>an object of class <code><a href="#topic+cv.msda">cv.msda</a></code> is returned, which is a
list with the ingredients of the cross-validation fit.
</p>
<table>
<tr><td><code>lambda</code></td>
<td>
<p>the values of <code>lambda</code> used in the fits.</p>
</td></tr>
<tr><td><code>cvm</code></td>
<td>
<p>the mean cross-validated error - a vector of length
<code>length(lambda)</code>.</p>
</td></tr>
<tr><td><code>cvsd</code></td>
<td>
<p>estimate of standard error of <code>cvm</code>.</p>
</td></tr>
<tr><td><code>lambda.min</code></td>
<td>
<p>the optimal value of <code>lambda</code> that gives minimum
cross validation error <code>cvm</code>.</p>
</td></tr>
<tr><td><code>lambda.1se</code></td>
<td>
<p>the largest value of <code>lambda</code> such that error is
within 1 standard error of the minimum.</p>
</td></tr>
<tr><td><code>msda.fit</code></td>
<td>
<p>a fitted <code><a href="#topic+msda">msda</a></code> object for the full data.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Qing Mai &lt;mai@stat.fsu.edu&gt;, Yi Yang &lt;yi.yang6@mcgill.ca&gt;,  Hui Zou &lt;hzou@stat.umn.edu&gt;<br />
Maintainer: Yi Yang  &lt;yi.yang6@mcgill.ca&gt;</p>


<h3>References</h3>

<p>Mai, Q.*, Yang, Y.*, and Zou, H. (2014), &quot;Multiclass Sparse Discriminant Analysis.&quot; Submitted to <em>Journal of the American Statistical Association</em>. (* co-first author)
</p>
<p>URL: <a href="https://github.com/emeryyi/msda">https://github.com/emeryyi/msda</a><br />
</p>


<h3>See Also</h3>

<p><code><a href="#topic+msda">msda</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>data(GDS1615)
x&lt;-GDS1615$x
y&lt;-GDS1615$y
obj.cv&lt;-cv.msda(x=x,y=y,nfolds=5,lambda.opt="max")
lambda.min&lt;-obj.cv$lambda.min
id.min&lt;-which(obj.cv$lambda==lambda.min)
pred&lt;-predict(obj.cv$msda.fit,x)[,id.min]
</code></pre>

<hr>
<h2 id='GDS1615'>GDS1615 data introduced in Burczynski et al. (2012).</h2><span id='topic+GDS1615'></span><span id='topic+x'></span><span id='topic+y'></span>

<h3>Description</h3>

<p>The  dataset is a subset of the dataset available on Gene Expression Omnibus with the accession number GDS1615. The original dataset contains 22283 gene expression levels and the disease states of the observed subjects. In Mai, Yang and Zou, the dimension of the original dataset was first reduced to 127 by F-test screening.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(GDS1615)</code></pre>


<h3>Value</h3>

<p>This data frame contains the following:
</p>
<table>
<tr><td><code>x</code></td>
<td>
<p>gene expression levels.</p>
</td></tr>
<tr><td><code>y</code></td>
<td>
<p>Disease state that is coded as 1,2,3. 1: normal; 2: ulcerative colitis; 3: Crohn's disease.</p>
</td></tr>
</table>


<h3>References</h3>

<p>M. E. Burczynski, R. L Peterson, N. C. Twine, K. A. Zuberek, B. J. Brodeur, L. Casciotti, V. Maganti, P. S. Reddy, A. Strahs, F. Immermann, W. Spinelli, U. Schwertschlag, A. M. Slager, M. M. Cotreau, and A. J. Dorner.  (2012), &quot;Molecular classification of crohn's disease and ulcerative colitis patients using transcriptional profiles in peripheral blood mononuclear cells&quot;. <em>Journal of Molecular Diagnostics</em>, 8:51&ndash;61.
</p>
<p>Mai, Q.*, Yang, Y.*, and Zou, H. (2014), &quot;Multiclass Sparse Discriminant Analysis.&quot; Submitted to <em>Journal of the American Statistical Association</em>. (* co-first author)
</p>
<p>URL: <a href="https://github.com/emeryyi/msda">https://github.com/emeryyi/msda</a><br />
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(GDS1615)
</code></pre>

<hr>
<h2 id='msda'>
Fits a regularization path for Multi-Class Sparse Discriminant Analysis</h2><span id='topic+msda'></span>

<h3>Description</h3>

<p>Fits a regularization path for Multi-Class Sparse Discriminant Analysis at a sequence of regularization parameters lambda.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>msda(x, y, nlambda = 100, 
lambda.factor = ifelse((nobs - nclass) &lt;= nvars, 0.2, 0.001), 
lambda = NULL, dfmax = nobs, pmax = min(dfmax * 2 + 20, nvars), 
pf = rep(1, nvars), eps = 1e-04, maxit = 1e+06, sml = 1e-06, 
verbose = FALSE, perturb = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="msda_+3A_x">x</code></td>
<td>
<p>matrix of predictors, of dimension <code class="reqn">N \times p</code>; each row is an observation vector.</p>
</td></tr>
<tr><td><code id="msda_+3A_y">y</code></td>
<td>
<p>response variable. This argument should be a factor for classification.
</p>
</td></tr>
<tr><td><code id="msda_+3A_nlambda">nlambda</code></td>
<td>
<p>the number of <code>lambda</code> values - default is 100.</p>
</td></tr>
<tr><td><code id="msda_+3A_lambda.factor">lambda.factor</code></td>
<td>

<p>The factor for getting the minimal lambda in <code>lambda</code> sequence, where <code>min(lambda)</code> = <code>lambda.factor</code> * <code>max(lambda)</code>.  <code>max(lambda)</code> is the smallest value of <code>lambda</code> for which all coefficients are zero. The default depends on the relationship between <code class="reqn">N</code> (the number of rows in the matrix of predictors) and <code class="reqn">p</code> (the number of predictors). If <code class="reqn">N &gt; p</code>, the default is <code>0.0001</code>,
close to zero.  If <code class="reqn">N&lt;p</code>, the default is <code>0.2</code>.
A very small value of <code>lambda.factor</code> will lead to a saturated fit. It takes no effect if there is user-defined <code>lambda</code> sequence.</p>
</td></tr>
<tr><td><code id="msda_+3A_lambda">lambda</code></td>
<td>

<p>a user supplied <code>lambda</code> sequence. Typically, by leaving this option unspecified users can have 
the program compute its own <code>lambda</code> sequence based on
<code>nlambda</code> and <code>lambda.factor</code>. Supplying a value of
<code>lambda</code> overrides this. It is better to supply
a decreasing sequence of <code>lambda</code> values than a single (small) value, if not, the program will sort user-defined <code>lambda</code> sequence in decreasing order automatically.</p>
</td></tr>
<tr><td><code id="msda_+3A_dfmax">dfmax</code></td>
<td>

<p>limit the maximum number of variables in the
model. Useful for very large <code class="reqn">p</code>, if a partial path is desired. Default is <code class="reqn">n</code>.</p>
</td></tr>
<tr><td><code id="msda_+3A_pmax">pmax</code></td>
<td>

<p>limit the maximum number of variables ever to be nonzero. For example once <code class="reqn">\beta</code> enters the model, no matter how many times it exits or re-enters model through the path, it will be counted only once. Default is <code>min(dfmax*1.2,p)</code>.</p>
</td></tr>
<tr><td><code id="msda_+3A_pf">pf</code></td>
<td>

<p>L1 penalty factor of length <code class="reqn">p</code>. Separate L1 penalty weights can be applied to each coefficient of <code class="reqn">\theta</code> to allow
differential L1 shrinkage. Can be 0 for some variables, which implies
no L1 shrinkage, and results in that variable always being included in the
model. Default is 1 for all variables (and implicitly infinity for
variables listed in <code>exclude</code>).</p>
</td></tr>
<tr><td><code id="msda_+3A_eps">eps</code></td>
<td>

<p>convergence threshold for coordinate descent. Each inner
coordinate descent loop continues until the relative change in any
coefficient. Defaults value is <code>1e-8</code>.</p>
</td></tr>
<tr><td><code id="msda_+3A_maxit">maxit</code></td>
<td>

<p>maximum number of outer-loop iterations allowed at fixed lambda value. Default is 1e6. If models do not converge, consider increasing <code>maxit</code>.</p>
</td></tr>
<tr><td><code id="msda_+3A_sml">sml</code></td>
<td>


</td></tr>
<tr><td><code id="msda_+3A_verbose">verbose</code></td>
<td>

<p>whether to print out computation progress. The default is <code>FALSE</code>. </p>
</td></tr>
<tr><td><code id="msda_+3A_perturb">perturb</code></td>
<td>
<p>a scalar number. If it is specified, the number will be added to each diagonal element of the sigma matrix as perturbation. The default is <code>NULL</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Note that for computing speed reason, if models are not converging or running slow, consider increasing <code>eps</code> and <code>sml</code>, or decreasing
<code>nlambda</code>, or increasing <code>lambda.factor</code> before increasing
<code>maxit</code>. Users can also reduce <code>dfmax</code> to limit the maximum number of variables in the model.
</p>


<h3>Value</h3>

<p>An object with S3 class <code><a href="#topic+msda">msda</a></code>.
</p>
<table>
<tr><td><code>theta</code></td>
<td>
<p>a list of length(lambda) for fitted coefficients theta, each one corresponding to one lambda value, each stored as a sparse matrix (<code>dgCMatrix</code> class, the standard class for sparse numeric matrices in the <code>Matrix</code> package.). To convert it into normal type matrix use <code>as.matrix()</code>.</p>
</td></tr>
<tr><td><code>df</code></td>
<td>
<p>the number of nonzero coefficients for each value of
<code>lambda</code>.</p>
</td></tr>
<tr><td><code>obj</code></td>
<td>
<p>the fitted value of the objective function for each value of
<code>lambda</code>.</p>
</td></tr>
<tr><td><code>dim</code></td>
<td>
<p>dimension of each coefficient matrix at each lambda.</p>
</td></tr>
<tr><td><code>lambda</code></td>
<td>
<p>the actual sequence of <code>lambda</code> values used.</p>
</td></tr>
<tr><td><code>x</code></td>
<td>
<p>matrix of predictors.</p>
</td></tr>
<tr><td><code>y</code></td>
<td>
<p>response variable.</p>
</td></tr>
<tr><td><code>npasses</code></td>
<td>
<p>total number of iterations (the most inner loop) summed over all lambda values</p>
</td></tr>
<tr><td><code>jerr</code></td>
<td>
<p>error flag, for warnings and errors, 0 if no error.</p>
</td></tr>
<tr><td><code>sigma</code></td>
<td>
<p>estimated sigma matrix.</p>
</td></tr>
<tr><td><code>delta</code></td>
<td>
<p>estimated delta matrix. delta[k] = mu[k]-mu[1].</p>
</td></tr>
<tr><td><code>mu</code></td>
<td>
<p>estimated mu vector.</p>
</td></tr>
<tr><td><code>prior</code></td>
<td>
<p>prior probability that y belong to class k, estimated by mean(y that belong to k).</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the call that produced this object</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Qing Mai &lt;mai@stat.fsu.edu&gt;, Yi Yang &lt;yi.yang6@mcgill.ca&gt;,  Hui Zou &lt;hzou@stat.umn.edu&gt;<br />
Maintainer: Yi Yang  &lt;yi.yang6@mcgill.ca&gt;</p>


<h3>References</h3>

<p>Mai, Q.*, Yang, Y.*, and Zou, H. (2014), &quot;Multiclass Sparse Discriminant Analysis.&quot; Submitted to <em>Journal of the American Statistical Association</em>. (* co-first author)
</p>
<p>URL: <a href="https://github.com/emeryyi/msda">https://github.com/emeryyi/msda</a><br />
</p>


<h3>See Also</h3>

<p><code>cv.msda</code>, <code>predict.msda</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(GDS1615)
x&lt;-GDS1615$x
y&lt;-GDS1615$y
obj &lt;- msda(x = x, y = y)
</code></pre>

<hr>
<h2 id='plot.msda'>Plot coefficients from a &quot;msda&quot; object</h2><span id='topic+plot.msda'></span>

<h3>Description</h3>

<p>Produces a coefficient profile plot of the coefficient paths for a
fitted <code><a href="#topic+msda">msda</a></code> object. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'msda'
plot(x, xvar = c("norm", "lambda"), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.msda_+3A_x">x</code></td>
<td>
<p>fitted <code><a href="#topic+msda">msda</a></code> model</p>
</td></tr>
<tr><td><code id="plot.msda_+3A_xvar">xvar</code></td>
<td>
<p>the variable on the X-axis. The option <code>"norm"</code> plots the coefficients against the
L1-norm of the coefficients, and the option <code>"lambda"</code> plots the coefficient against the log-lambda
sequence.</p>
</td></tr>
<tr><td><code id="plot.msda_+3A_...">...</code></td>
<td>
<p>other graphical parameters to plot</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A coefficient profile plot is produced.
</p>


<h3>Author(s)</h3>

<p>Qing Mai &lt;mai@stat.fsu.edu&gt;, Yi Yang &lt;yi.yang6@mcgill.ca&gt;,  Hui Zou &lt;hzou@stat.umn.edu&gt;<br />
Maintainer: Yi Yang  &lt;yi.yang6@mcgill.ca&gt;</p>


<h3>References</h3>

<p>Mai, Q.*, Yang, Y.*, and Zou, H. (2014), &quot;Multiclass Sparse Discriminant Analysis.&quot; Submitted to <em>Journal of the American Statistical Association</em>. (* co-first author)
</p>
<p>URL: <a href="https://github.com/emeryyi/msda">https://github.com/emeryyi/msda</a><br />
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(GDS1615)
x&lt;-GDS1615$x
y&lt;-GDS1615$y
obj &lt;- msda(x = x, y = y)
plot(obj)
</code></pre>

<hr>
<h2 id='predict.msda'>
make predictions from a &quot;msda&quot; object.
</h2><span id='topic+predict.msda'></span>

<h3>Description</h3>

<p>This functions predicts class labels from a fitted <code><a href="#topic+msda">msda</a></code> object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'msda'
predict(object, newx, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.msda_+3A_object">object</code></td>
<td>
<p>fitted <code><a href="#topic+msda">msda</a></code> model object.</p>
</td></tr>
<tr><td><code id="predict.msda_+3A_newx">newx</code></td>
<td>
<p>matrix of new values for <code>x</code> at which predictions are
to be made. NOTE: <code>newx</code> must be a matrix, <code>predict</code> function does not accept a vector or other formats of <code>newx</code>.</p>
</td></tr>
<tr><td><code id="predict.msda_+3A_...">...</code></td>
<td>
<p>Not used. Other arguments to predict. </p>
</td></tr>
</table>


<h3>Value</h3>

<p>predicted class label(s) at the entire sequence of the penalty parameter <code>lambda</code> used to create the model.
</p>


<h3>Author(s)</h3>

<p>Qing Mai &lt;mai@stat.fsu.edu&gt;, Yi Yang &lt;yi.yang6@mcgill.ca&gt;,  Hui Zou &lt;hzou@stat.umn.edu&gt;<br />
Maintainer: Yi Yang  &lt;yi.yang6@mcgill.ca&gt;</p>


<h3>References</h3>

<p>Mai, Q.*, Yang, Y.*, and Zou, H. (2014), &quot;Multiclass Sparse Discriminant Analysis.&quot; Submitted to <em>Journal of the American Statistical Association</em>. (* co-first author)
</p>
<p>URL: <a href="https://github.com/emeryyi/msda">https://github.com/emeryyi/msda</a><br />
</p>


<h3>See Also</h3>

<p><code><a href="#topic+msda">msda</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>data(GDS1615)
x&lt;-GDS1615$x
y&lt;-GDS1615$y
obj &lt;- msda(x = x, y = y)
pred&lt;-predict(obj,x)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
