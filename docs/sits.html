<!DOCTYPE html><html><head><title>Help for package sits</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {sits}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#sits-package'><p>sits</p></a></li>
<li><a href='#.check_date_parameter'><p>Check is date is valid</p></a></li>
<li><a href='#'sits_labels&lt;-''><p>Change the labels of a set of time series</p></a></li>
<li><a href='#cerrado_2classes'><p>Samples of classes Cerrado and Pasture</p></a></li>
<li><a href='#plot'><p>Plot time series</p></a></li>
<li><a href='#plot.class_cube'><p>Plot classified images</p></a></li>
<li><a href='#plot.class_vector_cube'><p>Plot Segments</p></a></li>
<li><a href='#plot.geo_distances'><p>Make a kernel density plot of samples distances.</p></a></li>
<li><a href='#plot.patterns'><p>Plot patterns that describe classes</p></a></li>
<li><a href='#plot.predicted'><p>Plot time series predictions</p></a></li>
<li><a href='#plot.probs_cube'><p>Plot probability cubes</p></a></li>
<li><a href='#plot.probs_vector_cube'><p>Plot probability vector cubes</p></a></li>
<li><a href='#plot.raster_cube'><p>Plot RGB data cubes</p></a></li>
<li><a href='#plot.rfor_model'><p>Plot Random Forest  model</p></a></li>
<li><a href='#plot.sits_accuracy'><p>Plot confusion matrix</p></a></li>
<li><a href='#plot.sits_cluster'><p>Plot a dendrogram cluster</p></a></li>
<li><a href='#plot.som_evaluate_cluster'><p>Plot confusion between clusters</p></a></li>
<li><a href='#plot.som_map'><p>Plot a SOM map</p></a></li>
<li><a href='#plot.torch_model'><p>Plot Torch (deep learning) model</p></a></li>
<li><a href='#plot.uncertainty_cube'><p>Plot uncertainty cubes</p></a></li>
<li><a href='#plot.variance_cube'><p>Plot variance cubes</p></a></li>
<li><a href='#plot.vector_cube'><p>Plot RGB vector data cubes</p></a></li>
<li><a href='#plot.xgb_model'><p>Plot XGB model</p></a></li>
<li><a href='#point_mt_6bands'><p>A time series sample with data from 2000 to 2016</p></a></li>
<li><a href='#print.sits_accuracy'><p>Print the values of a confusion matrix</p></a></li>
<li><a href='#print.sits_area_accuracy'><p>Print the area-weighted accuracy</p></a></li>
<li><a href='#samples_l8_rondonia_2bands'><p>Samples of Amazon tropical forest biome for deforestation analysis</p></a></li>
<li><a href='#samples_modis_ndvi'><p>Samples of nine classes for the state of Mato Grosso</p></a></li>
<li><a href='#sits_accuracy'><p>Assess classification accuracy (area-weighted method)</p></a></li>
<li><a href='#sits_accuracy_summary'><p>Print accuracy summary</p></a></li>
<li><a href='#sits_apply'><p>Apply a function on a set of time series</p></a></li>
<li><a href='#sits_as_sf'><p>Return a sits_tibble or raster_cube as an sf object.</p></a></li>
<li><a href='#sits_bands'><p>Get the names of the bands</p></a></li>
<li><a href='#sits_bbox'><p>Get the bounding box of the data</p></a></li>
<li><a href='#sits_classify'><p>Classify time series or data cubes</p></a></li>
<li><a href='#sits_cluster_clean'><p>Removes labels that are minority in each cluster.</p></a></li>
<li><a href='#sits_cluster_dendro'><p>Find clusters in time series samples</p></a></li>
<li><a href='#sits_cluster_frequency'><p>Show label frequency in each cluster produced by dendrogram analysis</p></a></li>
<li><a href='#sits_colors'><p>Function to retrieve sits color table</p></a></li>
<li><a href='#sits_colors_qgis'><p>Function to save color table as QML style for data cube</p></a></li>
<li><a href='#sits_colors_reset'><p>Function to reset sits color table</p></a></li>
<li><a href='#sits_colors_set'><p>Function to set sits color table</p></a></li>
<li><a href='#sits_colors_show'><p>Function to show colors in SITS</p></a></li>
<li><a href='#sits_combine_predictions'><p>Estimate ensemble prediction based on list of probs cubes</p></a></li>
<li><a href='#sits_confidence_sampling'><p>Suggest high confidence samples to increase the training set.</p></a></li>
<li><a href='#sits_config'><p>Configure parameters for sits package</p></a></li>
<li><a href='#sits_config_show'><p>Show current sits configuration</p></a></li>
<li><a href='#sits_cube'><p>Create data cubes from image collections</p></a></li>
<li><a href='#sits_cube_copy'><p>Copy the images of a cube to a local directory</p></a></li>
<li><a href='#sits_factory_function'><p>Create a closure for calling functions with and without data</p></a></li>
<li><a href='#sits_filter'><p>Filter time series with smoothing filter</p></a></li>
<li><a href='#sits_formula_linear'><p>Define a linear formula for classification models</p></a></li>
<li><a href='#sits_formula_logref'><p>Define a loglinear formula for classification models</p></a></li>
<li><a href='#sits_geo_dist'><p>Compute the minimum distances among samples and prediction points.</p></a></li>
<li><a href='#sits_get_data'><p>Get time series from data cubes and cloud services</p></a></li>
<li><a href='#sits_kfold_validate'><p>Cross-validate time series samples</p></a></li>
<li><a href='#sits_label_classification'><p>Build a labelled image from a probability cube</p></a></li>
<li><a href='#sits_labels'><p>Get labels associated to a data set</p></a></li>
<li><a href='#sits_labels_summary'><p>Inform label distribution of a set of time series</p></a></li>
<li><a href='#sits_lighttae'><p>Train a model using Lightweight Temporal Self-Attention Encoder</p></a></li>
<li><a href='#sits_list_collections'><p>List the cloud collections supported by sits</p></a></li>
<li><a href='#sits_merge'><p>Merge two data sets (time series or cubes)</p></a></li>
<li><a href='#sits_mixture_model'><p>Multiple endmember spectral mixture analysis</p></a></li>
<li><a href='#sits_mlp'><p>Train multi-layer perceptron models using torch</p></a></li>
<li><a href='#sits_model_export'><p>Export classification models</p></a></li>
<li><a href='#sits_mosaic'><p>Mosaic classified cubes</p></a></li>
<li><a href='#sits_patterns'><p>Find temporal patterns associated to a set of time series</p></a></li>
<li><a href='#sits_pred_features'><p>Obtain numerical values of predictors for time series samples</p></a></li>
<li><a href='#sits_pred_normalize'><p>Normalize predictor values</p></a></li>
<li><a href='#sits_pred_reference'><p>Obtain categorical id and predictor labels for time series samples</p></a></li>
<li><a href='#sits_pred_sample'><p>Obtain a fraction of the predictors data frame</p></a></li>
<li><a href='#sits_predictors'><p>Obtain predictors for time series samples</p></a></li>
<li><a href='#sits_reclassify'><p>Reclassify a classified cube</p></a></li>
<li><a href='#sits_reduce_imbalance'><p>Reduce imbalance in a set of samples</p></a></li>
<li><a href='#sits_regularize'><p>Build a regular data cube from an irregular one</p></a></li>
<li><a href='#sits_resnet'><p>Train ResNet classification models</p></a></li>
<li><a href='#sits_rfor'><p>Train random forest models</p></a></li>
<li><a href='#sits_run_examples'><p>Informs if sits examples should run</p></a></li>
<li><a href='#sits_run_tests'><p>Informs if sits tests should run</p></a></li>
<li><a href='#sits_sample'><p>Sample a percentage of a time series</p></a></li>
<li><a href='#sits_segment'><p>Segment an image</p></a></li>
<li><a href='#sits_select'><p>Filter bands on a data set (tibble or cube)</p></a></li>
<li><a href='#sits_sgolay'><p>Filter time series with Savitzky-Golay filter</p></a></li>
<li><a href='#sits_show_prediction'><p>Shows the predicted labels for a classified tibble</p></a></li>
<li><a href='#sits_slic'><p>Segment an image using SLIC</p></a></li>
<li><a href='#sits_smooth'><p>Smooth probability cubes with spatial predictors</p></a></li>
<li><a href='#sits_som'><p>Use SOM for quality analysis of time series samples</p></a></li>
<li><a href='#sits_som_clean_samples'><p>Cleans the samples based on SOM map information</p></a></li>
<li><a href='#sits_som_evaluate_cluster'><p>Evaluate cluster</p></a></li>
<li><a href='#sits_stats'><p>Obtain statistics for all sample bands</p></a></li>
<li><a href='#sits_svm'><p>Train support vector machine models</p></a></li>
<li><a href='#sits_tae'><p>Train a model using  Temporal Self-Attention Encoder</p></a></li>
<li><a href='#sits_tempcnn'><p>Train temporal convolutional neural network models</p></a></li>
<li><a href='#sits_timeline'><p>Get timeline of a cube or a set of time series</p></a></li>
<li><a href='#sits_to_csv'><p>Export a sits tibble metadata to the CSV format</p></a></li>
<li><a href='#sits_to_xlsx'><p>Save accuracy assessments as Excel files</p></a></li>
<li><a href='#sits_train'><p>Train classification models</p></a></li>
<li><a href='#sits_tuning'><p>Tuning machine learning models hyper-parameters</p></a></li>
<li><a href='#sits_tuning_hparams'><p>Tuning machine learning models hyper-parameters</p></a></li>
<li><a href='#sits_uncertainty'><p>Estimate classification uncertainty based on probs cube</p></a></li>
<li><a href='#sits_uncertainty_sampling'><p>Suggest samples for enhancing classification accuracy</p></a></li>
<li><a href='#sits_validate'><p>Validate time series samples</p></a></li>
<li><a href='#sits_variance'><p>Calculate the variance of a probability cube</p></a></li>
<li><a href='#sits_view'><p>View data cubes and samples in leaflet</p></a></li>
<li><a href='#sits_whittaker'><p>Filter time series with whittaker filter</p></a></li>
<li><a href='#sits_xgboost'><p>Train extreme gradient boosting models</p></a></li>
<li><a href='#summary.class_cube'><p>Summarize data cubes</p></a></li>
<li><a href='#summary.raster_cube'><p>Summarize data cubes</p></a></li>
<li><a href='#summary.sits'><p>Summarize sits</p></a></li>
<li><a href='#summary.sits_accuracy'><p>Summarize accuracy matrix for training data</p></a></li>
<li><a href='#summary.sits_area_accuracy'><p>Summarize accuracy matrix for area data</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Version:</td>
<td>1.4.2-1</td>
</tr>
<tr>
<td>Title:</td>
<td>Satellite Image Time Series Analysis for Earth Observation Data
Cubes</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Gilberto Camara &lt;gilberto.camara.inpe@gmail.com&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>An end-to-end toolkit for land use and land cover classification
    using big Earth observation data, based on machine learning methods 
    applied to satellite image data cubes, as described in Simoes et al (2021) &lt;<a href="https://doi.org/10.3390%2Frs13132428">doi:10.3390/rs13132428</a>&gt;.
    Builds regular data cubes from collections in AWS, Microsoft Planetary Computer, 
    Brazil Data Cube, and Digital Earth Africa using the Spatio-temporal Asset Catalog (STAC) 
    protocol (<a href="https://stacspec.org/">https://stacspec.org/</a> and the 'gdalcubes' R package 
    developed by Appel and Pebesma (2019) &lt;<a href="https://doi.org/10.3390%2Fdata4030092">doi:10.3390/data4030092</a>&gt;.
    Supports visualization methods for images and time series and 
    smoothing filters for dealing with noisy time series.
    Includes functions for quality assessment of training samples using self-organized maps 
    as presented by Santos et al (2021) &lt;<a href="https://doi.org/10.1016%2Fj.isprsjprs.2021.04.014">doi:10.1016/j.isprsjprs.2021.04.014</a>&gt;. 
    Provides machine learning methods including support vector machines, 
    random forests, extreme gradient boosting, multi-layer perceptrons,
    temporal convolutional neural networks proposed by Pelletier et al (2019) &lt;<a href="https://doi.org/10.3390%2Frs11050523">doi:10.3390/rs11050523</a>&gt;, 
    residual networks by Fawaz et al (2019) &lt;<a href="https://doi.org/10.1007%2Fs10618-019-00619-1">doi:10.1007/s10618-019-00619-1</a>&gt;, and temporal attention encoders
    by Garnot and Landrieu (2020) &lt;<a href="https://doi.org/10.48550/arXiv.2007.00586">doi:10.48550/arXiv.2007.00586</a>&gt;.
    Performs efficient classification of big Earth observation data cubes and includes 
    functions for post-classification smoothing based on Bayesian inference, and 
    methods for uncertainty assessment. Enables best
    practices for estimating area and assessing accuracy of land change as 
    recommended by Olofsson et al (2014) &lt;<a href="https://doi.org/10.1016%2Fj.rse.2014.02.015">doi:10.1016/j.rse.2014.02.015</a>&gt;.
    Minimum recommended requirements: 16 GB RAM and 4 CPU dual-core.</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Language:</td>
<td>en-US</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 4.0.0)</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/e-sensing/sits/">https://github.com/e-sensing/sits/</a>,
<a href="https://e-sensing.github.io/sitsbook/">https://e-sensing.github.io/sitsbook/</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/e-sensing/sits/issues">https://github.com/e-sensing/sits/issues</a></td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a></td>
</tr>
<tr>
<td>ByteCompile:</td>
<td>true</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>Imports:</td>
<td>yaml, dplyr (&ge; 1.0.0), gdalUtilities, grDevices, graphics,
lubridate, parallel (&ge; 4.0.5), purrr (&ge; 1.0.2), Rcpp, rstac
(&ge; 0.9.2-5), sf (&ge; 1.0-12), showtext, sysfonts, slider (&ge;
0.2.0), stats, terra (&ge; 1.5-17), tibble (&ge; 3.1), tidyr (&ge;
1.2.0), torch (&ge; 0.11.0), utils</td>
</tr>
<tr>
<td>Suggests:</td>
<td>caret, cli, dendextend, dtwclust, DiagrammeR, digest, e1071,
exactextractr, FNN, future, gdalcubes (&ge; 0.6.0), geojsonsf,
ggplot2, httr, jsonlite, kohonen (&ge; 3.0.11), leafem (&ge;
0.2.0), leaflet (&ge; 2.2.0), luz (&ge; 0.4.0), methods, mgcv,
nnet, openxlsx, randomForest, randomForestExplainer,
RcppArmadillo (&ge; 0.12), scales, stars (&ge; 0.6), stringr,
supercells, testthat (&ge; 3.1.3), tmap (&ge; 3.3), torchopt (&ge;
0.1.2), xgboost, covr</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>Config/testthat/parallel:</td>
<td>false</td>
</tr>
<tr>
<td>Config/testthat/start-first:</td>
<td>cube, raster, regularize, data, ml</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp, RcppArmadillo</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>Collate:</td>
<td>'api_accessors.R' 'api_accuracy.R' 'api_apply.R' 'api_band.R'
'api_bbox.R' 'api_block.R' 'api_check.R' 'api_chunks.R'
'api_classify.R' 'api_clean.R' 'api_cluster.R' 'api_colors.R'
'api_combine_predictions.R' 'api_comp.R' 'api_conf.R'
'api_csv.R' 'api_cube.R' 'api_data.R' 'api_debug.R'
'api_download.R' 'api_factory.R' 'api_file_info.R' 'api_file.R'
'api_gdal.R' 'api_gdalcubes.R' 'api_imputation.R' 'api_jobs.R'
'api_label_class.R' 'api_mixture_model.R' 'api_ml_model.R'
'api_mosaic.R' 'api_parallel.R' 'api_period.R'
'api_plot_time_series.R' 'api_plot_raster.R'
'api_plot_vector.R' 'api_point.R' 'api_predictors.R'
'api_raster.R' 'api_raster_sub_image.R' 'api_raster_terra.R'
'api_reclassify.R' 'api_regularize.R' 'api_roi.R'
'api_s2tile.R' 'api_samples.R' 'api_segments.R' 'api_sf.R'
'api_shp.R' 'api_signal.R' 'api_smooth.R' 'api_smote.R'
'api_som.R' 'api_source.R' 'api_source_aws.R'
'api_source_bdc.R' 'api_source_deafrica.R' 'api_source_hls.R'
'api_source_local.R' 'api_source_mpc.R' 'api_source_sdc.R'
'api_source_stac.R' 'api_source_usgs.R'
'api_space_time_operations.R' 'api_stac.R' 'api_stats.R'
'api_summary.R' 'api_tibble.R' 'api_tile.R' 'api_timeline.R'
'api_torch.R' 'api_torch_psetae.R' 'api_ts.R' 'api_tuning.R'
'api_uncertainty.R' 'api_utils.R' 'api_values.R'
'api_variance.R' 'api_vector.R' 'api_vector_info.R'
'api_view.R' 'RcppExports.R' 'data.R' 'sits-package.R'
'sits_apply.R' 'sits_accuracy.R' 'sits_active_learning.R'
'sits_bands.R' 'sits_bbox.R' 'sits_classify.R' 'sits_colors.R'
'sits_combine_predictions.R' 'sits_config.R' 'sits_csv.R'
'sits_cube.R' 'sits_cube_copy.R' 'sits_cluster.R'
'sits_factory.R' 'sits_filters.R' 'sits_geo_dist.R'
'sits_get_data.R' 'sits_labels.R' 'sits_label_classification.R'
'sits_lighttae.R' 'sits_machine_learning.R' 'sits_merge.R'
'sits_mixture_model.R' 'sits_mlp.R' 'sits_mosaic.R'
'sits_model_export.R' 'sits_patterns.R' 'sits_plot.R'
'sits_predictors.R' 'sits_reclassify.R' 'sits_regularize.R'
'sits_resnet.R' 'sits_sample_functions.R' 'sits_segmentation.R'
'sits_select.R' 'sits_sf.R' 'sits_smooth.R' 'sits_som.R'
'sits_summary.R' 'sits_tae.R' 'sits_tempcnn.R'
'sits_timeline.R' 'sits_train.R' 'sits_tuning.R' 'sits_utils.R'
'sits_uncertainty.R' 'sits_validate.R' 'sits_view.R'
'sits_variance.R' 'sits_xlsx.R' 'zzz.R'</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-11-01 19:33:18 UTC; gilbertocamara</td>
</tr>
<tr>
<td>Author:</td>
<td>Rolf Simoes [aut],
  Gilberto Camara [aut, cre],
  Felipe Souza [aut],
  Lorena Santos [aut],
  Pedro Andrade [aut],
  Karine Ferreira [aut],
  Alber Sanchez [aut],
  Gilberto Queiroz [aut]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-11-02 15:10:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='sits-package'>sits</h2><span id='topic+sits-package'></span><span id='topic+_PACKAGE'></span><span id='topic+sits'></span>

<h3>Description</h3>

<p>Satellite Image Time Series Analysis
for Earth Observation Data Cubes
</p>


<h3>Purpose</h3>

<p>The SITS package provides a set of tools for analysis,
visualization and classification of satellite image time series.
It includes methods for filtering, clustering, classification,
and post-processing.
</p>


<h3>Author(s)</h3>

<p><strong>Maintainer</strong>: Gilberto Camara <a href="mailto:gilberto.camara.inpe@gmail.com">gilberto.camara.inpe@gmail.com</a>
</p>
<p>Authors:
</p>

<ul>
<li><p> Rolf Simoes <a href="mailto:rolf.simoes@inpe.br">rolf.simoes@inpe.br</a>
</p>
</li>
<li><p> Felipe Souza <a href="mailto:felipe.carvalho@inpe.br">felipe.carvalho@inpe.br</a>
</p>
</li>
<li><p> Lorena Santos <a href="mailto:lorena.santos@inpe.br">lorena.santos@inpe.br</a>
</p>
</li>
<li><p> Pedro Andrade <a href="mailto:pedro.andrade@inpe.br">pedro.andrade@inpe.br</a>
</p>
</li>
<li><p> Karine Ferreira <a href="mailto:karine.ferreira@inpe.br">karine.ferreira@inpe.br</a>
</p>
</li>
<li><p> Alber Sanchez <a href="mailto:alber.ipia@inpe.br">alber.ipia@inpe.br</a>
</p>
</li>
<li><p> Gilberto Queiroz <a href="mailto:gilberto.queiroz@inpe.br">gilberto.queiroz@inpe.br</a>
</p>
</li></ul>



<h3>See Also</h3>

<p>Useful links:
</p>

<ul>
<li> <p><a href="https://github.com/e-sensing/sits/">https://github.com/e-sensing/sits/</a>
</p>
</li>
<li> <p><a href="https://e-sensing.github.io/sitsbook/">https://e-sensing.github.io/sitsbook/</a>
</p>
</li>
<li><p> Report bugs at <a href="https://github.com/e-sensing/sits/issues">https://github.com/e-sensing/sits/issues</a>
</p>
</li></ul>


<hr>
<h2 id='.check_date_parameter'>Check is date is valid</h2><span id='topic+.check_date_parameter'></span>

<h3>Description</h3>

<p>Check is date is valid
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.check_date_parameter(
  param,
  len_min = 1,
  len_max = 1,
  allow_null = FALSE,
  msg = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id=".check_date_parameter_+3A_param">param</code></td>
<td>
<p>parameter to be checked</p>
</td></tr>
<tr><td><code id=".check_date_parameter_+3A_len_min">len_min</code></td>
<td>
<p>minimum length of vector</p>
</td></tr>
<tr><td><code id=".check_date_parameter_+3A_len_max">len_max</code></td>
<td>
<p>maximum length of vector</p>
</td></tr>
<tr><td><code id=".check_date_parameter_+3A_allow_null">allow_null</code></td>
<td>
<p>allow NULL?</p>
</td></tr>
<tr><td><code id=".check_date_parameter_+3A_msg">msg</code></td>
<td>
<p>Error message</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Called for side effects.
</p>

<hr>
<h2 id='+27sits_labels+26lt+3B-+27'>Change the labels of a set of time series</h2><span id='topic++60sits_labels+3C-+60'></span><span id='topic+sits_labels+3C-'></span><span id='topic+sits_labels+3C-.sits'></span><span id='topic+sits_labels+3C-.probs_cube'></span><span id='topic+sits_labels+3C-.class_cube'></span><span id='topic+sits_labels+3C-.default'></span>

<h3>Description</h3>

<p>Given a sits tibble with a set of labels, renames the labels
to the specified in value.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sits_labels(data) &lt;- value

## S3 replacement method for class 'sits'
sits_labels(data) &lt;- value

## S3 replacement method for class 'probs_cube'
sits_labels(data) &lt;- value

## S3 replacement method for class 'class_cube'
sits_labels(data) &lt;- value

## Default S3 replacement method:
sits_labels(data) &lt;- value
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="+2B27sits_labels+2B26lt+2B3B-+2B27_+3A_data">data</code></td>
<td>
<p>Data cube or time series.</p>
</td></tr>
<tr><td><code id="+2B27sits_labels+2B26lt+2B3B-+2B27_+3A_value">value</code></td>
<td>
<p>A character vector used to convert labels. Labels will
be renamed to the respective value positioned at the
labels order returned by <code><a href="#topic+sits_labels">sits_labels</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A sits tibble or data cube with modified labels.
</p>
<p>A probs or class_cube cube with modified labels.
</p>


<h3>Author(s)</h3>

<p>Rolf Simoes, <a href="mailto:rolf.simoes@inpe.br">rolf.simoes@inpe.br</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># show original samples ("Cerrado" and "Pasture")
sits_labels(cerrado_2classes)
# rename label samples to "Savanna" and "Grasslands"
sits_labels(cerrado_2classes) &lt;- c("Savanna", "Grasslands")
# see the change
sits_labels(cerrado_2classes)
</code></pre>

<hr>
<h2 id='cerrado_2classes'>Samples of classes Cerrado and Pasture</h2><span id='topic+cerrado_2classes'></span>

<h3>Description</h3>

<p>A dataset containing a tibble with time series samples
for the Cerrado and Pasture areas of the Mato Grosso state.
The time series come from MOD13Q1 collection 5 images.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(cerrado_2classes)
</code></pre>


<h3>Format</h3>

<p>A tibble with 736 rows and 7 variables:
longitude: East-west coordinate of the time series sample (WGS 84),
latitude (North-south coordinate of the time series sample in WGS 84),
start_date (initial date of the time series),
end_date (final date of the time series),
label (the class label associated to the sample),
cube (the name of the cube associated with the data),
time_series (list containing a tibble with the values of the time series).
</p>

<hr>
<h2 id='plot'>Plot time series</h2><span id='topic+plot'></span><span id='topic+plot.sits'></span>

<h3>Description</h3>

<p>This is a generic function. Parameters depend on the specific
type of input.  See each function description for the
required parameters.
</p>

<ul>
<li><p> sits tibble: see <code><a href="#topic+plot.sits">plot.sits</a></code>
</p>
</li>
<li><p> patterns: see <code><a href="#topic+plot.patterns">plot.patterns</a></code>
</p>
</li>
<li><p> SOM map: see <code><a href="#topic+plot.som_map">plot.som_map</a></code>
</p>
</li>
<li><p> SOM evaluate cluster: see <code><a href="#topic+plot.som_evaluate_cluster">plot.som_evaluate_cluster</a></code>
</p>
</li>
<li><p> classified time series: see <code><a href="#topic+plot.predicted">plot.predicted</a></code>
</p>
</li>
<li><p> raster cube: see <code><a href="#topic+plot.raster_cube">plot.raster_cube</a></code>
</p>
</li>
<li><p> vector cube: see <code><a href="#topic+plot.vector_cube">plot.vector_cube</a></code>
</p>
</li>
<li><p> random forest model: see <code><a href="#topic+plot.rfor_model">plot.rfor_model</a></code>
</p>
</li>
<li><p> xgboost model: see <code><a href="#topic+plot.xgb_model">plot.xgb_model</a></code>
</p>
</li>
<li><p> torch ML model: see <code><a href="#topic+plot.torch_model">plot.torch_model</a></code>
</p>
</li>
<li><p> classification probabilities: see <code><a href="#topic+plot.probs_cube">plot.probs_cube</a></code>
</p>
</li>
<li><p> model uncertainty: see <code><a href="#topic+plot.uncertainty_cube">plot.uncertainty_cube</a></code>
</p>
</li>
<li><p> classified cube: see <code><a href="#topic+plot.class_cube">plot.class_cube</a></code>
</p>
</li>
<li><p> classified vector cube: see <code><a href="#topic+plot.class_vector_cube">plot.class_vector_cube</a></code>
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'sits'
plot(x, y, ..., together = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot_+3A_x">x</code></td>
<td>
<p>Object of class &quot;sits&quot;.</p>
</td></tr>
<tr><td><code id="plot_+3A_y">y</code></td>
<td>
<p>Ignored.</p>
</td></tr>
<tr><td><code id="plot_+3A_...">...</code></td>
<td>
<p>Further specifications for <a href="#topic+plot">plot</a>.</p>
</td></tr>
<tr><td><code id="plot_+3A_together">together</code></td>
<td>
<p>A logical value indicating whether
the samples should be plotted together.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A series of plot objects produced by ggplot2 showing all
time series associated to each combination of band and label,
and including the median, and first and third quartile ranges.
</p>


<h3>Author(s)</h3>

<p>Gilberto Camara, <a href="mailto:gilberto.camara@inpe.br">gilberto.camara@inpe.br</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (sits_run_examples()) {
    # plot sets of time series
    plot(cerrado_2classes)
}

</code></pre>

<hr>
<h2 id='plot.class_cube'>Plot classified images</h2><span id='topic+plot.class_cube'></span>

<h3>Description</h3>

<p>plots a classified raster using ggplot.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'class_cube'
plot(
  x,
  y,
  ...,
  tile = x$tile[[1]],
  title = "Classified Image",
  legend = NULL,
  palette = "Spectral",
  tmap_options = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.class_cube_+3A_x">x</code></td>
<td>
<p>Object of class &quot;class_cube&quot;.</p>
</td></tr>
<tr><td><code id="plot.class_cube_+3A_y">y</code></td>
<td>
<p>Ignored.</p>
</td></tr>
<tr><td><code id="plot.class_cube_+3A_...">...</code></td>
<td>
<p>Further specifications for <a href="#topic+plot">plot</a>.</p>
</td></tr>
<tr><td><code id="plot.class_cube_+3A_tile">tile</code></td>
<td>
<p>Tile to be plotted.</p>
</td></tr>
<tr><td><code id="plot.class_cube_+3A_title">title</code></td>
<td>
<p>Title of the plot.</p>
</td></tr>
<tr><td><code id="plot.class_cube_+3A_legend">legend</code></td>
<td>
<p>Named vector that associates labels to colors.</p>
</td></tr>
<tr><td><code id="plot.class_cube_+3A_palette">palette</code></td>
<td>
<p>Alternative RColorBrewer palette</p>
</td></tr>
<tr><td><code id="plot.class_cube_+3A_tmap_options">tmap_options</code></td>
<td>
<p>List with optional tmap parameters
max_cells (default: 1e+06)
graticules_labels_size (default: 0.7)
scale (default = 0.8)
legend_title_size (default: 0.7)
legend_text_size (default: 0.7)
legend_bg_color (default: &quot;white&quot;)
legend_bg_alpha (default: 0.5)
legend_width (default: 0.5)
legend_height (default: 0.7)
legend_position (default: c(&quot;left&quot;, &quot;bottom&quot;))</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A  color map, where each pixel has the color
associated to a label, as defined by the legend
parameter.
</p>


<h3>Author(s)</h3>

<p>Gilberto Camara, <a href="mailto:gilberto.camara@inpe.br">gilberto.camara@inpe.br</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (sits_run_examples()) {
    # create a random forest model
    rfor_model &lt;- sits_train(samples_modis_ndvi, sits_rfor())
    # create a data cube from local files
    data_dir &lt;- system.file("extdata/raster/mod13q1", package = "sits")
    cube &lt;- sits_cube(
        source = "BDC",
        collection = "MOD13Q1-6",
        data_dir = data_dir
    )
    # classify a data cube
    probs_cube &lt;- sits_classify(
        data = cube, ml_model = rfor_model, output_dir = tempdir()
    )
    # label cube with the most likely class
    label_cube &lt;- sits_label_classification(
        probs_cube,
        output_dir = tempdir()
    )
    # plot the resulting classified image
    plot(label_cube)
}
</code></pre>

<hr>
<h2 id='plot.class_vector_cube'>Plot Segments</h2><span id='topic+plot.class_vector_cube'></span>

<h3>Description</h3>

<p>Plot vector classified cube
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'class_vector_cube'
plot(
  x,
  ...,
  tile = x$tile[[1]],
  legend = NULL,
  seg_color = "black",
  line_width = 0.5,
  palette = "Spectral",
  tmap_options = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.class_vector_cube_+3A_x">x</code></td>
<td>
<p>Object of class &quot;segments&quot;.</p>
</td></tr>
<tr><td><code id="plot.class_vector_cube_+3A_...">...</code></td>
<td>
<p>Further specifications for <a href="#topic+plot">plot</a>.</p>
</td></tr>
<tr><td><code id="plot.class_vector_cube_+3A_tile">tile</code></td>
<td>
<p>Tile to be plotted.</p>
</td></tr>
<tr><td><code id="plot.class_vector_cube_+3A_legend">legend</code></td>
<td>
<p>Named vector that associates labels to colors.</p>
</td></tr>
<tr><td><code id="plot.class_vector_cube_+3A_seg_color">seg_color</code></td>
<td>
<p>Segment color.</p>
</td></tr>
<tr><td><code id="plot.class_vector_cube_+3A_line_width">line_width</code></td>
<td>
<p>Segment line width.</p>
</td></tr>
<tr><td><code id="plot.class_vector_cube_+3A_palette">palette</code></td>
<td>
<p>Alternative RColorBrewer palette</p>
</td></tr>
<tr><td><code id="plot.class_vector_cube_+3A_tmap_options">tmap_options</code></td>
<td>
<p>List with optional tmap parameters
tmap_max_cells (default: 1e+06)
tmap_graticules_labels_size (default: 0.7)
tmap_legend_title_size (default: 1.5)
tmap_legend_text_size (default: 1.2)
tmap_legend_bg_color (default: &quot;white&quot;)
tmap_legend_bg_alpha (default: 0.5)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A plot object with an RGB image
or a B/W image on a color
scale using the pallete
</p>


<h3>Note</h3>

<p>To see which color palettes are supported, please run
</p>


<h3>Author(s)</h3>

<p>Gilberto Camara, <a href="mailto:gilberto.camara@inpe.br">gilberto.camara@inpe.br</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (sits_run_examples()) {
    data_dir &lt;- system.file("extdata/raster/mod13q1", package = "sits")
    cube &lt;- sits_cube(
        source = "BDC",
        collection = "MOD13Q1-6",
        data_dir = data_dir
    )
    # segment the image
    segments &lt;- sits_segment(
        cube = cube,
        output_dir = tempdir()
    )
    # create a classification model
    rfor_model &lt;- sits_train(samples_modis_ndvi, sits_rfor())
    # classify the segments
    probs_segs &lt;- sits_classify(
        data = segments,
        ml_model = rfor_model,
        output_dir = tempdir()
    )
    #
    # Create a classified vector cube
    class_segs &lt;- sits_label_classification(
        cube = probs_segs,
        output_dir = tempdir(),
        multicores = 2,
        memsize = 4
    )
    # plot the segments
    plot(class_segs)
}
</code></pre>

<hr>
<h2 id='plot.geo_distances'>Make a kernel density plot of samples distances.</h2><span id='topic+plot.geo_distances'></span>

<h3>Description</h3>

<p>Make a kernel density plot of samples distances.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'geo_distances'
plot(x, y, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.geo_distances_+3A_x">x</code></td>
<td>
<p>Object of class &quot;geo_distances&quot;.</p>
</td></tr>
<tr><td><code id="plot.geo_distances_+3A_y">y</code></td>
<td>
<p>Ignored.</p>
</td></tr>
<tr><td><code id="plot.geo_distances_+3A_...">...</code></td>
<td>
<p>Further specifications for <a href="#topic+plot">plot</a>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A plot showing the sample-to-sample distances
and sample-to-prediction distances.
</p>


<h3>Note</h3>

<p>Please refer to the sits documentation available in
&lt;https://e-sensing.github.io/sitsbook/&gt; for detailed examples.
</p>


<h3>Author(s)</h3>

<p>Felipe Souza, <a href="mailto:lipecaso@gmail.com">lipecaso@gmail.com</a>
</p>
<p>Rolf Simoes, <a href="mailto:rolf.simoes@inpe.br">rolf.simoes@inpe.br</a>
</p>
<p>Alber Sanchez, <a href="mailto:alber.ipia@inpe.br">alber.ipia@inpe.br</a>
</p>


<h3>References</h3>

<p>Hanna Meyer and Edzer Pebesma,
&quot;Machine learning-based global maps of ecological variables and the
challenge of assessing them&quot; Nature Communications, 13,2022.
DOI: 10.1038/s41467-022-29838-9.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (sits_run_examples()) {
    # read a shapefile for the state of Mato Grosso, Brazil
    mt_shp &lt;- system.file("extdata/shapefiles/mato_grosso/mt.shp",
        package = "sits"
    )
    # convert to an sf object
    mt_sf &lt;- sf::read_sf(mt_shp)
    # calculate sample-to-sample and sample-to-prediction distances
    distances &lt;- sits_geo_dist(samples_modis_ndvi, mt_sf)
    # plot sample-to-sample and sample-to-prediction distances
    plot(distances)
}
</code></pre>

<hr>
<h2 id='plot.patterns'>Plot patterns that describe classes</h2><span id='topic+plot.patterns'></span>

<h3>Description</h3>

<p>Plots the patterns to be used for classification
</p>
<p>Given a sits tibble with a set of patterns, plot them.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'patterns'
plot(x, y, ..., bands = NULL, year_grid = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.patterns_+3A_x">x</code></td>
<td>
<p>Object of class &quot;patterns&quot;.</p>
</td></tr>
<tr><td><code id="plot.patterns_+3A_y">y</code></td>
<td>
<p>Ignored.</p>
</td></tr>
<tr><td><code id="plot.patterns_+3A_...">...</code></td>
<td>
<p>Further specifications for <a href="#topic+plot">plot</a>.</p>
</td></tr>
<tr><td><code id="plot.patterns_+3A_bands">bands</code></td>
<td>
<p>Bands to be viewed (optional).</p>
</td></tr>
<tr><td><code id="plot.patterns_+3A_year_grid">year_grid</code></td>
<td>
<p>Plot a grid of panels using labels as columns and
years as rows. Default is FALSE.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A plot object produced by ggplot2
with one average pattern per label.
</p>


<h3>Note</h3>

<p>This code is reused from the dtwSat package by Victor Maus.
</p>


<h3>Author(s)</h3>

<p>Gilberto Camara, <a href="mailto:gilberto.camara@inpe.br">gilberto.camara@inpe.br</a>
</p>
<p>Victor Maus, <a href="mailto:vwmaus1@gmail.com">vwmaus1@gmail.com</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (sits_run_examples()) {
    # plot patterns
    plot(sits_patterns(cerrado_2classes))
}
</code></pre>

<hr>
<h2 id='plot.predicted'>Plot time series predictions</h2><span id='topic+plot.predicted'></span>

<h3>Description</h3>

<p>Given a sits tibble with a set of predictions, plot them
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'predicted'
plot(x, y, ..., bands = "NDVI", palette = "Harmonic")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.predicted_+3A_x">x</code></td>
<td>
<p>Object of class &quot;predicted&quot;.</p>
</td></tr>
<tr><td><code id="plot.predicted_+3A_y">y</code></td>
<td>
<p>Ignored.</p>
</td></tr>
<tr><td><code id="plot.predicted_+3A_...">...</code></td>
<td>
<p>Further specifications for <a href="#topic+plot">plot</a>.</p>
</td></tr>
<tr><td><code id="plot.predicted_+3A_bands">bands</code></td>
<td>
<p>Bands for visualization.</p>
</td></tr>
<tr><td><code id="plot.predicted_+3A_palette">palette</code></td>
<td>
<p>HCL palette used for visualization
in case classes are not in the default sits palette.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A plot object produced by ggplot2
showing the time series and its label.
</p>


<h3>Note</h3>

<p>This code is reused from the dtwSat package by Victor Maus.
</p>


<h3>Author(s)</h3>

<p>Victor Maus, <a href="mailto:vwmaus1@gmail.com">vwmaus1@gmail.com</a>
</p>
<p>Gilberto Camara, <a href="mailto:gilberto.camara@inpe.br">gilberto.camara@inpe.br</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (sits_run_examples()) {
    # Retrieve the samples for Mato Grosso
    # train an svm model
    ml_model &lt;- sits_train(samples_modis_ndvi, ml_method = sits_svm)
    # classify the point
    point_ndvi &lt;- sits_select(point_mt_6bands, bands = "NDVI")
    point_class &lt;- sits_classify(
        data = point_ndvi, ml_model = ml_model
    )
    plot(point_class)
}
</code></pre>

<hr>
<h2 id='plot.probs_cube'>Plot probability cubes</h2><span id='topic+plot.probs_cube'></span>

<h3>Description</h3>

<p>plots a probability cube using stars
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'probs_cube'
plot(
  x,
  ...,
  tile = x$tile[[1]],
  labels = NULL,
  palette = "YlGnBu",
  rev = FALSE,
  tmap_options = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.probs_cube_+3A_x">x</code></td>
<td>
<p>Object of class &quot;probs_cube&quot;.</p>
</td></tr>
<tr><td><code id="plot.probs_cube_+3A_...">...</code></td>
<td>
<p>Further specifications for <a href="#topic+plot">plot</a>.</p>
</td></tr>
<tr><td><code id="plot.probs_cube_+3A_tile">tile</code></td>
<td>
<p>Tile to be plotted.</p>
</td></tr>
<tr><td><code id="plot.probs_cube_+3A_labels">labels</code></td>
<td>
<p>Labels to plot (optional).</p>
</td></tr>
<tr><td><code id="plot.probs_cube_+3A_palette">palette</code></td>
<td>
<p>RColorBrewer palette</p>
</td></tr>
<tr><td><code id="plot.probs_cube_+3A_rev">rev</code></td>
<td>
<p>Reverse order of colors in palette?</p>
</td></tr>
<tr><td><code id="plot.probs_cube_+3A_tmap_options">tmap_options</code></td>
<td>
<p>List with optional tmap parameters
tmap_max_cells (default: 1e+06)
tmap_graticules_labels_size (default: 0.7)
tmap_legend_title_size (default: 1.5)
tmap_legend_text_size (default: 1.2)
tmap_legend_bg_color (default: &quot;white&quot;)
tmap_legend_bg_alpha (default: 0.5)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A plot containing probabilities associated
to each class for each pixel.
</p>


<h3>Author(s)</h3>

<p>Gilberto Camara, <a href="mailto:gilberto.camara@inpe.br">gilberto.camara@inpe.br</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (sits_run_examples()) {
    # create a random forest model
    rfor_model &lt;- sits_train(samples_modis_ndvi, sits_rfor())
    # create a data cube from local files
    data_dir &lt;- system.file("extdata/raster/mod13q1", package = "sits")
    cube &lt;- sits_cube(
        source = "BDC",
        collection = "MOD13Q1-6",
        data_dir = data_dir
    )
    # classify a data cube
    probs_cube &lt;- sits_classify(
        data = cube, ml_model = rfor_model, output_dir = tempdir()
    )
    # plot the resulting probability cube
    plot(probs_cube)
}

</code></pre>

<hr>
<h2 id='plot.probs_vector_cube'>Plot probability vector cubes</h2><span id='topic+plot.probs_vector_cube'></span>

<h3>Description</h3>

<p>plots a probability cube using stars
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'probs_vector_cube'
plot(
  x,
  ...,
  tile = x$tile[[1]],
  labels = NULL,
  palette = "YlGnBu",
  rev = FALSE,
  tmap_options = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.probs_vector_cube_+3A_x">x</code></td>
<td>
<p>Object of class &quot;probs_vector_cube&quot;.</p>
</td></tr>
<tr><td><code id="plot.probs_vector_cube_+3A_...">...</code></td>
<td>
<p>Further specifications for <a href="#topic+plot">plot</a>.</p>
</td></tr>
<tr><td><code id="plot.probs_vector_cube_+3A_tile">tile</code></td>
<td>
<p>Tile to be plotted.</p>
</td></tr>
<tr><td><code id="plot.probs_vector_cube_+3A_labels">labels</code></td>
<td>
<p>Labels to plot (optional).</p>
</td></tr>
<tr><td><code id="plot.probs_vector_cube_+3A_palette">palette</code></td>
<td>
<p>RColorBrewer palette</p>
</td></tr>
<tr><td><code id="plot.probs_vector_cube_+3A_rev">rev</code></td>
<td>
<p>Reverse order of colors in palette?</p>
</td></tr>
<tr><td><code id="plot.probs_vector_cube_+3A_tmap_options">tmap_options</code></td>
<td>
<p>List with optional tmap parameters
tmap_max_cells (default: 1e+06)
tmap_graticules_labels_size (default: 0.7)
tmap_legend_title_size (default: 1.5)
tmap_legend_text_size (default: 1.2)
tmap_legend_bg_color (default: &quot;white&quot;)
tmap_legend_bg_alpha (default: 0.5)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A plot containing probabilities associated
to each class for each pixel.
</p>


<h3>Author(s)</h3>

<p>Gilberto Camara, <a href="mailto:gilberto.camara@inpe.br">gilberto.camara@inpe.br</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (sits_run_examples()) {
    # create a random forest model
    rfor_model &lt;- sits_train(samples_modis_ndvi, sits_rfor())
    # create a data cube from local files
    data_dir &lt;- system.file("extdata/raster/mod13q1", package = "sits")
    cube &lt;- sits_cube(
        source = "BDC",
        collection = "MOD13Q1-6",
        data_dir = data_dir
    )
    # segment the image
    segments &lt;- sits_segment(
        cube = cube,
        seg_fn = sits_slic(step = 5,
                           compactness = 1,
                           dist_fun = "euclidean",
                           avg_fun = "median",
                           iter = 20,
                           minarea = 10,
                           verbose = FALSE),
        output_dir = tempdir()
    )
    # classify a data cube
    probs_vector_cube &lt;- sits_classify(
        data = segments,
        ml_model = rfor_model,
        output_dir = tempdir()
    )
    # plot the resulting probability cube
    plot(probs_vector_cube)
}

</code></pre>

<hr>
<h2 id='plot.raster_cube'>Plot RGB data cubes</h2><span id='topic+plot.raster_cube'></span>

<h3>Description</h3>

<p>Plot RGB raster cube
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'raster_cube'
plot(
  x,
  ...,
  band = NULL,
  red = NULL,
  green = NULL,
  blue = NULL,
  tile = x$tile[[1]],
  date = NULL,
  palette = "RdYlGn",
  rev = FALSE,
  tmap_options = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.raster_cube_+3A_x">x</code></td>
<td>
<p>Object of class &quot;raster_cube&quot;.</p>
</td></tr>
<tr><td><code id="plot.raster_cube_+3A_...">...</code></td>
<td>
<p>Further specifications for <a href="#topic+plot">plot</a>.</p>
</td></tr>
<tr><td><code id="plot.raster_cube_+3A_band">band</code></td>
<td>
<p>Band for plotting grey images.</p>
</td></tr>
<tr><td><code id="plot.raster_cube_+3A_red">red</code></td>
<td>
<p>Band for red color.</p>
</td></tr>
<tr><td><code id="plot.raster_cube_+3A_green">green</code></td>
<td>
<p>Band for green color.</p>
</td></tr>
<tr><td><code id="plot.raster_cube_+3A_blue">blue</code></td>
<td>
<p>Band for blue color.</p>
</td></tr>
<tr><td><code id="plot.raster_cube_+3A_tile">tile</code></td>
<td>
<p>Tile to be plotted.</p>
</td></tr>
<tr><td><code id="plot.raster_cube_+3A_date">date</code></td>
<td>
<p>Date to be plotted.</p>
</td></tr>
<tr><td><code id="plot.raster_cube_+3A_palette">palette</code></td>
<td>
<p>An RColorBrewer palette</p>
</td></tr>
<tr><td><code id="plot.raster_cube_+3A_rev">rev</code></td>
<td>
<p>Reverse the color order in the palette?</p>
</td></tr>
<tr><td><code id="plot.raster_cube_+3A_tmap_options">tmap_options</code></td>
<td>
<p>List with optional tmap parameters
max_cells (default: 1e+06)
scale (default: 0.5)
graticules_labels_size (default: 0.7)
legend_title_size (default: 1.0)
legend_text_size (default: 1.0)
legend_bg_color (default: &quot;white&quot;)
legend_bg_alpha (default: 0.5)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A plot object with an RGB image
or a B/W image on a color
scale using the pallete
</p>


<h3>Note</h3>

<p>To see which colors are supported, please run <code>sits_colors()</code>
Use <code>scale</code> parameter for general output control.
If required, then set the other params individually
</p>


<h3>Author(s)</h3>

<p>Gilberto Camara, <a href="mailto:gilberto.camara@inpe.br">gilberto.camara@inpe.br</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (sits_run_examples()) {
    # create a data cube from local files
    data_dir &lt;- system.file("extdata/raster/mod13q1", package = "sits")
    cube &lt;- sits_cube(
        source = "BDC",
        collection = "MOD13Q1-6",
        data_dir = data_dir
    )
    # plot NDVI band of the second date date of the data cube
    plot(cube, band = "NDVI", date = sits_timeline(cube)[1])
}
</code></pre>

<hr>
<h2 id='plot.rfor_model'>Plot Random Forest  model</h2><span id='topic+plot.rfor_model'></span>

<h3>Description</h3>

<p>Plots the important variables in a random forest model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'rfor_model'
plot(x, y, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.rfor_model_+3A_x">x</code></td>
<td>
<p>Object of class &quot;rf_model&quot;.</p>
</td></tr>
<tr><td><code id="plot.rfor_model_+3A_y">y</code></td>
<td>
<p>Ignored.</p>
</td></tr>
<tr><td><code id="plot.rfor_model_+3A_...">...</code></td>
<td>
<p>Further specifications for <a href="#topic+plot">plot</a>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A random forest object.
</p>


<h3>Note</h3>

<p>Please refer to the sits documentation available in
&lt;https://e-sensing.github.io/sitsbook/&gt; for detailed examples.
</p>


<h3>Author(s)</h3>

<p>Gilberto Camara, <a href="mailto:gilberto.camara@inpe.br">gilberto.camara@inpe.br</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (sits_run_examples()) {
    # Retrieve the samples for Mato Grosso
    # train a random forest model
    rf_model &lt;- sits_train(samples_modis_ndvi, ml_method = sits_rfor())
    # plot the model
    plot(rf_model)
}
</code></pre>

<hr>
<h2 id='plot.sits_accuracy'>Plot confusion matrix</h2><span id='topic+plot.sits_accuracy'></span>

<h3>Description</h3>

<p>Plot a bar graph with informations about the confusion matrix
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'sits_accuracy'
plot(x, y, ..., title = "Confusion matrix")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.sits_accuracy_+3A_x">x</code></td>
<td>
<p>Object of class &quot;plot.sits_accuracy&quot;.</p>
</td></tr>
<tr><td><code id="plot.sits_accuracy_+3A_y">y</code></td>
<td>
<p>Ignored.</p>
</td></tr>
<tr><td><code id="plot.sits_accuracy_+3A_...">...</code></td>
<td>
<p>Further specifications for <a href="#topic+plot">plot</a>.</p>
</td></tr>
<tr><td><code id="plot.sits_accuracy_+3A_title">title</code></td>
<td>
<p>Title of plot.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A plot object produced by the ggplot2 package
containing color bars showing the confusion
between classes.
</p>


<h3>Note</h3>

<p>Please refer to the sits documentation available in
&lt;https://e-sensing.github.io/sitsbook/&gt; for detailed examples.
</p>


<h3>Author(s)</h3>

<p>Gilberto Camara <a href="mailto:gilberto.camara@inpe.br">gilberto.camara@inpe.br</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (sits_run_examples()) {
    # show accuracy for a set of samples
    train_data &lt;- sits_sample(samples_modis_ndvi, frac = 0.5)
    test_data  &lt;- sits_sample(samples_modis_ndvi, frac = 0.5)
    # compute a random forest model
    rfor_model &lt;- sits_train(train_data, sits_rfor())
    # classify training points
    points_class &lt;- sits_classify(
        data = test_data, ml_model = rfor_model
    )
    # calculate accuracy
    acc &lt;- sits_accuracy(points_class)
    # plot accuracy
    plot(acc)
}
</code></pre>

<hr>
<h2 id='plot.sits_cluster'>Plot a dendrogram cluster</h2><span id='topic+plot.sits_cluster'></span>

<h3>Description</h3>

<p>Plot a dendrogram
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'sits_cluster'
plot(x, ..., cluster, cutree_height, palette)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.sits_cluster_+3A_x">x</code></td>
<td>
<p>sits tibble with cluster indexes.</p>
</td></tr>
<tr><td><code id="plot.sits_cluster_+3A_...">...</code></td>
<td>
<p>Further specifications for <a href="#topic+plot">plot</a>.</p>
</td></tr>
<tr><td><code id="plot.sits_cluster_+3A_cluster">cluster</code></td>
<td>
<p>cluster object produced by 'sits_cluster' function.</p>
</td></tr>
<tr><td><code id="plot.sits_cluster_+3A_cutree_height">cutree_height</code></td>
<td>
<p>dashed horizontal line to be drawn
indicating the height of dendrogram cutting.</p>
</td></tr>
<tr><td><code id="plot.sits_cluster_+3A_palette">palette</code></td>
<td>
<p>HCL color palette.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The dendrogram object.
</p>


<h3>Author(s)</h3>

<p>Rolf Simoes, <a href="mailto:rolf.simoes@inpe.br">rolf.simoes@inpe.br</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (sits_run_examples()) {
     samples &lt;- sits_cluster_dendro(cerrado_2classes,
                bands = c("NDVI", "EVI"))
}

</code></pre>

<hr>
<h2 id='plot.som_evaluate_cluster'>Plot confusion between clusters</h2><span id='topic+plot.som_evaluate_cluster'></span>

<h3>Description</h3>

<p>Plot a bar graph with informations about each cluster.
The percentage of mixture between the clusters.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'som_evaluate_cluster'
plot(x, y, ..., name_cluster = NULL, title = "Confusion by cluster")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.som_evaluate_cluster_+3A_x">x</code></td>
<td>
<p>Object of class &quot;plot.som_evaluate_cluster&quot;.</p>
</td></tr>
<tr><td><code id="plot.som_evaluate_cluster_+3A_y">y</code></td>
<td>
<p>Ignored.</p>
</td></tr>
<tr><td><code id="plot.som_evaluate_cluster_+3A_...">...</code></td>
<td>
<p>Further specifications for <a href="#topic+plot">plot</a>.</p>
</td></tr>
<tr><td><code id="plot.som_evaluate_cluster_+3A_name_cluster">name_cluster</code></td>
<td>
<p>Choose the cluster to plot.</p>
</td></tr>
<tr><td><code id="plot.som_evaluate_cluster_+3A_title">title</code></td>
<td>
<p>Title of plot.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A plot object produced by the ggplot2 package
containing color bars showing the confusion
between classes.
</p>


<h3>Note</h3>

<p>Please refer to the sits documentation available in
&lt;https://e-sensing.github.io/sitsbook/&gt; for detailed examples.
</p>


<h3>Author(s)</h3>

<p>Lorena Santos <a href="mailto:lorena.santos@inpe.br">lorena.santos@inpe.br</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (sits_run_examples()) {
    # create a SOM map
    som_map &lt;- sits_som_map(samples_modis_ndvi)
    # evaluate the SOM cluster
    som_clusters &lt;- sits_som_evaluate_cluster(som_map)
    # plot the SOM cluster evaluation
    plot(som_clusters)
}
</code></pre>

<hr>
<h2 id='plot.som_map'>Plot a SOM map</h2><span id='topic+plot.som_map'></span>

<h3>Description</h3>

<p>plots a SOM map generated by &quot;sits_som_map&quot;.
The plot function produces different plots based on the input data.
If type is &quot;codes&quot;, plots the vector weight for in each neuron.
If type is &quot;mapping&quot;, shows where samples are mapped.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'som_map'
plot(x, y, ..., type = "codes", band = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.som_map_+3A_x">x</code></td>
<td>
<p>Object of class &quot;som_map&quot;.</p>
</td></tr>
<tr><td><code id="plot.som_map_+3A_y">y</code></td>
<td>
<p>Ignored.</p>
</td></tr>
<tr><td><code id="plot.som_map_+3A_...">...</code></td>
<td>
<p>Further specifications for <a href="#topic+plot">plot</a>.</p>
</td></tr>
<tr><td><code id="plot.som_map_+3A_type">type</code></td>
<td>
<p>Type of plot: &quot;codes&quot; for neuron weight (time series) and
&quot;mapping&quot; for the number of samples allocated in a neuron.</p>
</td></tr>
<tr><td><code id="plot.som_map_+3A_band">band</code></td>
<td>
<p>What band will be plotted.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Called for side effects.
</p>


<h3>Note</h3>

<p>Please refer to the sits documentation available in
&lt;https://e-sensing.github.io/sitsbook/&gt; for detailed examples.
</p>


<h3>Author(s)</h3>

<p>Gilberto Camara, <a href="mailto:gilberto.camara@inpe.br">gilberto.camara@inpe.br</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (sits_run_examples()) {
    # create a SOM map
    som_map &lt;- sits_som_map(samples_modis_ndvi)
    # plot the SOM map
    plot(som_map)
}
</code></pre>

<hr>
<h2 id='plot.torch_model'>Plot Torch (deep learning) model</h2><span id='topic+plot.torch_model'></span>

<h3>Description</h3>

<p>Plots a deep learning model developed using torch.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'torch_model'
plot(x, y, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.torch_model_+3A_x">x</code></td>
<td>
<p>Object of class &quot;torch_model&quot;.</p>
</td></tr>
<tr><td><code id="plot.torch_model_+3A_y">y</code></td>
<td>
<p>Ignored.</p>
</td></tr>
<tr><td><code id="plot.torch_model_+3A_...">...</code></td>
<td>
<p>Further specifications for <a href="#topic+plot">plot</a>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A plot object produced by the ggplot2 package
showing the evolution of the loss and
accuracy of the model.
</p>


<h3>Note</h3>

<p>This code has been lifted from the &quot;keras&quot; package.
</p>
<p>Please refer to the sits documentation available in
&lt;https://e-sensing.github.io/sitsbook/&gt; for detailed examples.
</p>


<h3>Author(s)</h3>

<p>Felipe Souza, <a href="mailto:lipecaso@gmail.com">lipecaso@gmail.com</a>
</p>
<p>Rolf Simoes, <a href="mailto:rolf.simoes@inpe.br">rolf.simoes@inpe.br</a>
</p>
<p>Alber Sanchez, <a href="mailto:alber.ipia@inpe.br">alber.ipia@inpe.br</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (sits_run_examples()) {
    # Retrieve the samples for Mato Grosso
    # train a tempCNN model
    ml_model &lt;- sits_train(samples_modis_ndvi, ml_method = sits_tempcnn)
    # plot the model
    plot(ml_model)
}
</code></pre>

<hr>
<h2 id='plot.uncertainty_cube'>Plot uncertainty cubes</h2><span id='topic+plot.uncertainty_cube'></span>

<h3>Description</h3>

<p>plots a probability cube using stars
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'uncertainty_cube'
plot(
  x,
  ...,
  tile = x$tile[[1]],
  palette = "RdYlGn",
  rev = TRUE,
  tmap_options = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.uncertainty_cube_+3A_x">x</code></td>
<td>
<p>Object of class &quot;probs_image&quot;.</p>
</td></tr>
<tr><td><code id="plot.uncertainty_cube_+3A_...">...</code></td>
<td>
<p>Further specifications for <a href="#topic+plot">plot</a>.</p>
</td></tr>
<tr><td><code id="plot.uncertainty_cube_+3A_tile">tile</code></td>
<td>
<p>Tiles to be plotted.</p>
</td></tr>
<tr><td><code id="plot.uncertainty_cube_+3A_palette">palette</code></td>
<td>
<p>An RColorBrewer palette</p>
</td></tr>
<tr><td><code id="plot.uncertainty_cube_+3A_rev">rev</code></td>
<td>
<p>Reverse the color order in the palette?</p>
</td></tr>
<tr><td><code id="plot.uncertainty_cube_+3A_tmap_options">tmap_options</code></td>
<td>
<p>List with optional tmap parameters
tmap_max_cells (default: 1e+06)
tmap_graticules_labels_size (default: 0.7)
tmap_legend_title_size (default: 1.5)
tmap_legend_text_size (default: 1.2)
tmap_legend_bg_color (default: &quot;white&quot;)
tmap_legend_bg_alpha (default: 0.5)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A plot object produced by the stars package
with a map showing the uncertainty associated
to each classified pixel.
</p>


<h3>Author(s)</h3>

<p>Gilberto Camara, <a href="mailto:gilberto.camara@inpe.br">gilberto.camara@inpe.br</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (sits_run_examples()) {
    # create a random forest model
    rfor_model &lt;- sits_train(samples_modis_ndvi, sits_rfor())
    # create a data cube from local files
    data_dir &lt;- system.file("extdata/raster/mod13q1", package = "sits")
    cube &lt;- sits_cube(
        source = "BDC",
        collection = "MOD13Q1-6",
        data_dir = data_dir
    )
    # classify a data cube
    probs_cube &lt;- sits_classify(
        data = cube, ml_model = rfor_model, output_dir = tempdir()
    )
    # calculate uncertainty
    uncert_cube &lt;- sits_uncertainty(probs_cube, output_dir = tempdir())
    # plot the resulting uncertainty cube
    plot(uncert_cube)
}
</code></pre>

<hr>
<h2 id='plot.variance_cube'>Plot variance cubes</h2><span id='topic+plot.variance_cube'></span>

<h3>Description</h3>

<p>plots a probability cube using stars
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'variance_cube'
plot(
  x,
  ...,
  tile = x$tile[[1]],
  labels = NULL,
  palette = "YlGnBu",
  rev = FALSE,
  type = "map",
  tmap_options = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.variance_cube_+3A_x">x</code></td>
<td>
<p>Object of class &quot;variance_cube&quot;.</p>
</td></tr>
<tr><td><code id="plot.variance_cube_+3A_...">...</code></td>
<td>
<p>Further specifications for <a href="#topic+plot">plot</a>.</p>
</td></tr>
<tr><td><code id="plot.variance_cube_+3A_tile">tile</code></td>
<td>
<p>Tile to be plotted.</p>
</td></tr>
<tr><td><code id="plot.variance_cube_+3A_labels">labels</code></td>
<td>
<p>Labels to plot (optional).</p>
</td></tr>
<tr><td><code id="plot.variance_cube_+3A_palette">palette</code></td>
<td>
<p>RColorBrewer palette</p>
</td></tr>
<tr><td><code id="plot.variance_cube_+3A_rev">rev</code></td>
<td>
<p>Reverse order of colors in palette?</p>
</td></tr>
<tr><td><code id="plot.variance_cube_+3A_type">type</code></td>
<td>
<p>Type of plot (&quot;map&quot; or &quot;hist&quot;)</p>
</td></tr>
<tr><td><code id="plot.variance_cube_+3A_tmap_options">tmap_options</code></td>
<td>
<p>List with optional tmap parameters
tmap_max_cells (default: 1e+06)
tmap_graticules_labels_size (default: 0.7)
tmap_legend_title_size (default: 1.5)
tmap_legend_text_size (default: 1.2)
tmap_legend_bg_color (default: &quot;white&quot;)
tmap_legend_bg_alpha (default: 0.5)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A plot containing probabilities associated
to each class for each pixel.
</p>


<h3>Author(s)</h3>

<p>Gilberto Camara, <a href="mailto:gilberto.camara@inpe.br">gilberto.camara@inpe.br</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (sits_run_examples()) {
    # create a random forest model
    rfor_model &lt;- sits_train(samples_modis_ndvi, sits_rfor())
    # create a data cube from local files
    data_dir &lt;- system.file("extdata/raster/mod13q1", package = "sits")
    cube &lt;- sits_cube(
        source = "BDC",
        collection = "MOD13Q1-6",
        data_dir = data_dir
    )
    # classify a data cube
    probs_cube &lt;- sits_classify(
        data = cube, ml_model = rfor_model, output_dir = tempdir()
    )
    # obtain a variance cube
    var_cube &lt;- sits_variance(probs_cube, output_dir = tempdir())
    # plot the variance cube
    plot(var_cube)
}

</code></pre>

<hr>
<h2 id='plot.vector_cube'>Plot RGB vector data cubes</h2><span id='topic+plot.vector_cube'></span>

<h3>Description</h3>

<p>Plot RGB raster cube
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'vector_cube'
plot(
  x,
  ...,
  band = sits_bands(x)[1],
  red = NULL,
  green = NULL,
  blue = NULL,
  tile = x$tile[[1]],
  date = NULL,
  seg_color = "black",
  line_width = 1,
  palette = "RdYlGn",
  rev = FALSE,
  tmap_options = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.vector_cube_+3A_x">x</code></td>
<td>
<p>Object of class &quot;raster_cube&quot;.</p>
</td></tr>
<tr><td><code id="plot.vector_cube_+3A_...">...</code></td>
<td>
<p>Further specifications for <a href="#topic+plot">plot</a>.</p>
</td></tr>
<tr><td><code id="plot.vector_cube_+3A_band">band</code></td>
<td>
<p>Band for plotting grey images.</p>
</td></tr>
<tr><td><code id="plot.vector_cube_+3A_red">red</code></td>
<td>
<p>Band for red color.</p>
</td></tr>
<tr><td><code id="plot.vector_cube_+3A_green">green</code></td>
<td>
<p>Band for green color.</p>
</td></tr>
<tr><td><code id="plot.vector_cube_+3A_blue">blue</code></td>
<td>
<p>Band for blue color.</p>
</td></tr>
<tr><td><code id="plot.vector_cube_+3A_tile">tile</code></td>
<td>
<p>Tile to be plotted.</p>
</td></tr>
<tr><td><code id="plot.vector_cube_+3A_date">date</code></td>
<td>
<p>Date to be plotted.</p>
</td></tr>
<tr><td><code id="plot.vector_cube_+3A_seg_color">seg_color</code></td>
<td>
<p>Color to show the segment boundaries</p>
</td></tr>
<tr><td><code id="plot.vector_cube_+3A_line_width">line_width</code></td>
<td>
<p>Line width to plot the segments boundary (in pixels)</p>
</td></tr>
<tr><td><code id="plot.vector_cube_+3A_palette">palette</code></td>
<td>
<p>An RColorBrewer palette</p>
</td></tr>
<tr><td><code id="plot.vector_cube_+3A_rev">rev</code></td>
<td>
<p>Reverse the color order in the palette?</p>
</td></tr>
<tr><td><code id="plot.vector_cube_+3A_tmap_options">tmap_options</code></td>
<td>
<p>List with optional tmap parameters
tmap_max_cells (default: 1e+06)
tmap_graticules_labels_size (default: 0.7)
tmap_legend_title_size (default: 1.5)
tmap_legend_text_size (default: 1.2)
tmap_legend_bg_color (default: &quot;white&quot;)
tmap_legend_bg_alpha (default: 0.5)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A plot object with an RGB image
or a B/W image on a color
scale using the pallete
</p>


<h3>Note</h3>

<p>To see which color palettes are supported, please run
</p>


<h3>Author(s)</h3>

<p>Gilberto Camara, <a href="mailto:gilberto.camara@inpe.br">gilberto.camara@inpe.br</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (sits_run_examples()) {
    # create a data cube from local files
    data_dir &lt;- system.file("extdata/raster/mod13q1", package = "sits")
    cube &lt;- sits_cube(
        source = "BDC",
        collection = "MOD13Q1-6",
        data_dir = data_dir
    )
    # Segment the cube
    segments &lt;- sits_segment(
        cube = cube,
        output_dir = tempdir(),
        multicores = 2,
        memsize = 4
    )
    # plot NDVI band of the second date date of the data cube
    plot(segments, band = "NDVI", date = sits_timeline(cube)[1])
}
</code></pre>

<hr>
<h2 id='plot.xgb_model'>Plot XGB model</h2><span id='topic+plot.xgb_model'></span>

<h3>Description</h3>

<p>Plots the important variables in an extreme gradient boosting.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'xgb_model'
plot(x, ..., n_trees = 3)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.xgb_model_+3A_x">x</code></td>
<td>
<p>Object of class &quot;xgb_model&quot;.</p>
</td></tr>
<tr><td><code id="plot.xgb_model_+3A_...">...</code></td>
<td>
<p>Further specifications for <a href="#topic+plot">plot</a>.</p>
</td></tr>
<tr><td><code id="plot.xgb_model_+3A_n_trees">n_trees</code></td>
<td>
<p>Number of trees to be plotted</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A plot object.
</p>


<h3>Note</h3>

<p>Please refer to the sits documentation available in
&lt;https://e-sensing.github.io/sitsbook/&gt; for detailed examples.
</p>


<h3>Author(s)</h3>

<p>Gilberto Camara, <a href="mailto:gilberto.camara@inpe.br">gilberto.camara@inpe.br</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (sits_run_examples()) {
    # Retrieve the samples for Mato Grosso
    # train an extreme gradient boosting
    xgb_model &lt;- sits_train(samples_modis_ndvi,
        ml_method = sits_xgboost()
    )
}
</code></pre>

<hr>
<h2 id='point_mt_6bands'>A time series sample with data from 2000 to 2016</h2><span id='topic+point_mt_6bands'></span>

<h3>Description</h3>

<p>A dataset containing a tibble with one time series samples
in the Mato Grosso state of Brazil.
The time series comes from MOD13Q1 collection 6 images.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(point_mt_6bands)
</code></pre>


<h3>Format</h3>

<p>A tibble with 1 rows and 7 variables:
longitude: East-west coordinate of the time series sample (WGS 84),
latitude (North-south coordinate of the time series sample in WGS 84),
start_date (initial date of the time series),
end_date (final date of the time series),
label (the class label associated to the sample),
cube (the name of the cube associated with the data),
time_series (list containing a tibble with the values of the time series).
</p>

<hr>
<h2 id='print.sits_accuracy'>Print the values of a confusion matrix</h2><span id='topic+print.sits_accuracy'></span>

<h3>Description</h3>

<p>Adaptation of the caret::print.confusionMatrix method
for the more common usage in Earth Observation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'sits_accuracy'
print(x, ..., digits = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.sits_accuracy_+3A_x">x</code></td>
<td>
<p>Object of class <code>confusionMatrix</code>.</p>
</td></tr>
<tr><td><code id="print.sits_accuracy_+3A_...">...</code></td>
<td>
<p>Other parameters passed to the &quot;print&quot; function.</p>
</td></tr>
<tr><td><code id="print.sits_accuracy_+3A_digits">digits</code></td>
<td>
<p>Number of significant digits when printed.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Called for side effects.
</p>


<h3>Author(s)</h3>

<p>Gilberto Camara, <a href="mailto:gilberto.camara@inpe.br">gilberto.camara@inpe.br</a>
</p>

<hr>
<h2 id='print.sits_area_accuracy'>Print the area-weighted accuracy</h2><span id='topic+print.sits_area_accuracy'></span>

<h3>Description</h3>

<p>Adaptation of the caret::print.confusionMatrix method
for the more common usage in Earth Observation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'sits_area_accuracy'
print(x, ..., digits = 2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.sits_area_accuracy_+3A_x">x</code></td>
<td>
<p>An object of class <code>sits_area_accuracy</code>.</p>
</td></tr>
<tr><td><code id="print.sits_area_accuracy_+3A_...">...</code></td>
<td>
<p>Other parameters passed to the &quot;print&quot; function</p>
</td></tr>
<tr><td><code id="print.sits_area_accuracy_+3A_digits">digits</code></td>
<td>
<p>Significant digits</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Called for side effects.
</p>


<h3>Author(s)</h3>

<p>Gilberto Camara, <a href="mailto:gilberto.camara@inpe.br">gilberto.camara@inpe.br</a>
</p>

<hr>
<h2 id='samples_l8_rondonia_2bands'>Samples of Amazon tropical forest biome for deforestation analysis</h2><span id='topic+samples_l8_rondonia_2bands'></span>

<h3>Description</h3>

<p>A sits tibble with time series samples from Brazilian Amazonia rain forest.
</p>
<p>The labels are: &quot;Deforestation&quot;, &quot;Forest&quot;, &quot;NatNonForest&quot; and &quot;Pasture&quot;.
</p>
<p>The time series were extracted from the Landsat-8 BDC data cube
(collection = &quot;LC8_30_16D_STK-1&quot;, tiles = &quot;038047&quot;).
These time series comprehends a period of 12 months
(25 observations) from &quot;2018-07-12&quot; to &quot;2019-07-28&quot;.
The extracted bands are NDVI and EVI.
Cloudy values were removed and interpolated.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("samples_l8_rondonia_2bands")
</code></pre>


<h3>Format</h3>

<p>A <code>sits</code> tibble with 160 samples.
</p>

<hr>
<h2 id='samples_modis_ndvi'>Samples of nine classes for the state of Mato Grosso</h2><span id='topic+samples_modis_ndvi'></span>

<h3>Description</h3>

<p>A dataset containing a tibble with time series samples
for the Mato Grosso state in Brasil.
The time series come from MOD13Q1 collection 6 images.
The data set has the following classes:
Cerrado(379 samples), Forest (131 samples),
Pasture (344 samples), and Soy_Corn (364 samples).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(samples_modis_ndvi)
</code></pre>


<h3>Format</h3>

<p>A tibble with 1308 rows and 7 variables:
longitude: East-west coordinate of the time series sample (WGS 84),
latitude (North-south coordinate of the time series sample in WGS 84),
start_date (initial date of the time series),
end_date (final date of the time series),
label (the class label associated to the sample),
cube (the name of the cube associated with the data),
time_series (list containing a tibble with the values of the time series).
</p>

<hr>
<h2 id='sits_accuracy'>Assess classification accuracy (area-weighted method)</h2><span id='topic+sits_accuracy'></span><span id='topic+sits_accuracy.sits'></span><span id='topic+sits_accuracy.class_cube'></span><span id='topic+sits_accuracy.raster_cube'></span><span id='topic+sits_accuracy.derived_cube'></span><span id='topic+sits_accuracy.tbl_df'></span><span id='topic+sits_accuracy.default'></span>

<h3>Description</h3>

<p>This function calculates the accuracy of the classification
result. For a set of time series, it creates a confusion matrix and then
calculates the resulting statistics using package <code>caret</code>. The time
series needs to be classified using <code><a href="#topic+sits_classify">sits_classify</a></code>.
</p>
<p>Classified images are generated using <code><a href="#topic+sits_classify">sits_classify</a></code>
followed by <code><a href="#topic+sits_label_classification">sits_label_classification</a></code>.
For a classified image, the function uses an area-weighted technique
proposed by Olofsson et al. according to [1-3] to produce more reliable
accuracy estimates at 95
</p>
<p>In both cases, it provides an accuracy assessment of the classified,
including Overall Accuracy, Kappa, User's Accuracy, Producer's Accuracy
and error matrix (confusion matrix)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sits_accuracy(data, ...)

## S3 method for class 'sits'
sits_accuracy(data, ...)

## S3 method for class 'class_cube'
sits_accuracy(data, ..., validation)

## S3 method for class 'raster_cube'
sits_accuracy(data, ...)

## S3 method for class 'derived_cube'
sits_accuracy(data, ...)

## S3 method for class 'tbl_df'
sits_accuracy(data, ...)

## Default S3 method:
sits_accuracy(data, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sits_accuracy_+3A_data">data</code></td>
<td>
<p>Either a data cube with classified images or
a set of time series</p>
</td></tr>
<tr><td><code id="sits_accuracy_+3A_...">...</code></td>
<td>
<p>Specific parameters</p>
</td></tr>
<tr><td><code id="sits_accuracy_+3A_validation">validation</code></td>
<td>
<p>Samples for validation (see below)
Only required when data is a class cube.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of lists: The error_matrix, the class_areas, the unbiased
estimated areas, the standard error areas, confidence interval 95
and the accuracy (user, producer, and overall), or NULL if the data is empty.
A confusion matrix assessment produced by the caret package.
</p>


<h3>Note</h3>

<p>The validation data needs to contain the following columns: &quot;latitude&quot;,
&quot;longitude&quot;, &quot;start_date&quot;, &quot;end_date&quot;, and &quot;label&quot;. It can be either a
path to a CSV file, a sits tibble or a data frame.
</p>


<h3>Author(s)</h3>

<p>Rolf Simoes, <a href="mailto:rolf.simoes@inpe.br">rolf.simoes@inpe.br</a>
</p>
<p>Alber Sanchez, <a href="mailto:alber.ipia@inpe.br">alber.ipia@inpe.br</a>
</p>


<h3>References</h3>

<p>[1] Olofsson, P., Foody, G.M., Stehman, S.V., Woodcock, C.E. (2013).
Making better use of accuracy data in land change studies: Estimating
accuracy and area and quantifying uncertainty using stratified estimation.
Remote Sensing of Environment, 129, pp.122-131.
</p>
<p>[2] Olofsson, P., Foody G.M., Herold M., Stehman, S.V.,
Woodcock, C.E., Wulder, M.A. (2014)
Good practices for estimating area and assessing accuracy of land change.
Remote Sensing of Environment, 148, pp. 42-57.
</p>
<p>[3] FAO, Map Accuracy Assessment and Area Estimation: A Practical Guide.
National forest monitoring assessment working paper No.46/E, 2016.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (sits_run_examples()) {
    # show accuracy for a set of samples
    train_data &lt;- sits_sample(samples_modis_ndvi, frac = 0.5)
    test_data  &lt;- sits_sample(samples_modis_ndvi, frac = 0.5)
    rfor_model &lt;- sits_train(train_data, sits_rfor())
    points_class &lt;- sits_classify(
        data = test_data, ml_model = rfor_model
    )
    acc &lt;- sits_accuracy(points_class)

    # show accuracy for a data cube classification
    # create a random forest model
    rfor_model &lt;- sits_train(samples_modis_ndvi, sits_rfor())
    # create a data cube from local files
    data_dir &lt;- system.file("extdata/raster/mod13q1", package = "sits")
    cube &lt;- sits_cube(
        source = "BDC",
        collection = "MOD13Q1-6",
        data_dir = data_dir
    )
    # classify a data cube
    probs_cube &lt;- sits_classify(
        data = cube, ml_model = rfor_model, output_dir = tempdir()
    )
    # label the probability cube
    label_cube &lt;- sits_label_classification(
        probs_cube,
        output_dir = tempdir()
    )
    # obtain the ground truth for accuracy assessment
    ground_truth &lt;- system.file("extdata/samples/samples_sinop_crop.csv",
        package = "sits"
    )
    # make accuracy assessment
    as &lt;- sits_accuracy(label_cube, validation = ground_truth)
}
</code></pre>

<hr>
<h2 id='sits_accuracy_summary'>Print accuracy summary</h2><span id='topic+sits_accuracy_summary'></span>

<h3>Description</h3>

<p>Adaptation of the caret::print.confusionMatrix method
for the more common usage in Earth Observation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sits_accuracy_summary(x, digits = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sits_accuracy_summary_+3A_x">x</code></td>
<td>
<p>Object of class <code>sits_accuracy</code>.</p>
</td></tr>
<tr><td><code id="sits_accuracy_summary_+3A_digits">digits</code></td>
<td>
<p>Number of significant digits when printed.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Called for side effects.
</p>


<h3>Author(s)</h3>

<p>Gilberto Camara, <a href="mailto:gilberto.camara@inpe.br">gilberto.camara@inpe.br</a>
</p>

<hr>
<h2 id='sits_apply'>Apply a function on a set of time series</h2><span id='topic+sits_apply'></span><span id='topic+sits_apply.sits'></span><span id='topic+sits_apply.raster_cube'></span><span id='topic+sits_apply.derived_cube'></span><span id='topic+sits_apply.tbl_df'></span><span id='topic+sits_apply.default'></span>

<h3>Description</h3>

<p>Apply a named expression to a sits cube or a sits tibble
to be evaluated and generate new bands (indices). In the case of sits
cubes, it materializes a new band in <code>output_dir</code> using
<code>gdalcubes</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sits_apply(data, ...)

## S3 method for class 'sits'
sits_apply(data, ...)

## S3 method for class 'raster_cube'
sits_apply(
  data,
  ...,
  window_size = 3L,
  memsize = 4L,
  multicores = 2L,
  output_dir,
  progress = FALSE
)

## S3 method for class 'derived_cube'
sits_apply(data, ...)

## S3 method for class 'tbl_df'
sits_apply(data, ...)

## Default S3 method:
sits_apply(data, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sits_apply_+3A_data">data</code></td>
<td>
<p>Valid sits tibble or cube</p>
</td></tr>
<tr><td><code id="sits_apply_+3A_...">...</code></td>
<td>
<p>Named expressions to be evaluated (see details).</p>
</td></tr>
<tr><td><code id="sits_apply_+3A_window_size">window_size</code></td>
<td>
<p>An odd number representing the size of the
sliding window of sits kernel functions
used in expressions (for a list of supported
kernel functions, please see details).</p>
</td></tr>
<tr><td><code id="sits_apply_+3A_memsize">memsize</code></td>
<td>
<p>Memory available for classification (in GB).</p>
</td></tr>
<tr><td><code id="sits_apply_+3A_multicores">multicores</code></td>
<td>
<p>Number of cores to be used for classification.</p>
</td></tr>
<tr><td><code id="sits_apply_+3A_output_dir">output_dir</code></td>
<td>
<p>Directory where files will be saved.</p>
</td></tr>
<tr><td><code id="sits_apply_+3A_progress">progress</code></td>
<td>
<p>Show progress bar?</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>sits_apply()</code> allow any valid R expression to compute new bands.
Use R syntax to pass an expression to this function.
Besides arithmetic operators, you can use virtually any R function
that can be applied to elements of a matrix (functions that are
unaware of matrix sizes, e.g. <code>sqrt()</code>, <code>sin()</code>,
<code>log()</code>).
</p>
<p>Also, <code>sits_apply()</code> accepts a predefined set of kernel functions
(see below) that can be applied to pixels considering its
neighborhood. <code>sits_apply()</code> considers a neighborhood of a
pixel as a set of pixels equidistant to it (including itself)
according the Chebyshev distance. This neighborhood form a
square window (also known as kernel) around the central pixel
(Moore neighborhood). Users can set the <code>window_size</code>
parameter to adjust the size of the kernel window.
The image is conceptually mirrored at the edges so that neighborhood
including a pixel outside the image is equivalent to take the
'mirrored' pixel inside the edge.
</p>
<p><code>sits_apply()</code> applies a function to the kernel and its result
is assigned to a corresponding central pixel on a new matrix.
The kernel slides throughout the input image and this process
generates an entire new matrix, which is returned as a new band
to the cube. The kernel functions ignores any <code>NA</code> values
inside the kernel window. Central pixel is <code>NA</code> just only
all pixels in the window are <code>NA</code>.
</p>


<h3>Value</h3>

<p>A sits tibble or a sits cube with new bands, produced
according to the requested expression.
</p>


<h3>Summarizing kernel functions</h3>


<ul>
<li><p><code>w_median()</code>: returns the median of the neighborhood's values.
</p>
</li>
<li><p><code>w_sum()</code>: returns the sum of the neighborhood's values.
</p>
</li>
<li><p><code>w_mean()</code>: returns the mean of the neighborhood's values.
</p>
</li>
<li><p><code>w_sd()</code>: returns the standard deviation of the neighborhood's
values.
</p>
</li>
<li><p><code>w_min()</code>: returns the minimum of the neighborhood's values.
</p>
</li>
<li><p><code>w_max()</code>: returns the maximum of the neighborhood's values.
</p>
</li>
<li><p><code>w_var()</code>: returns the variance of the neighborhood's values.
</p>
</li>
<li><p><code>w_modal()</code>: returns the modal of the neighborhood's values.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Rolf Simoes, <a href="mailto:rolf.simoes@inpe.br">rolf.simoes@inpe.br</a>
</p>
<p>Felipe Carvalho, <a href="mailto:felipe.carvalho@inpe.br">felipe.carvalho@inpe.br</a>
</p>
<p>Gilberto Camara, <a href="mailto:gilberto.camara@inpe.br">gilberto.camara@inpe.br</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (sits_run_examples()) {
    # Get a time series
    # Apply a normalization function

    point2 &lt;-
        sits_select(point_mt_6bands, "NDVI") |&gt;
        sits_apply(NDVI_norm = (NDVI - min(NDVI)) / (max(NDVI) - min(NDVI)))

    # Example of generation texture band with variance
    # Create a data cube from local files
    data_dir &lt;- system.file("extdata/raster/mod13q1", package = "sits")
    cube &lt;- sits_cube(
        source = "BDC",
        collection = "MOD13Q1-6",
        data_dir = data_dir
    )

    # Generate a texture images with variance in NDVI images
    cube_texture &lt;- sits_apply(
        data = cube,
        NDVITEXTURE = w_median(NDVI),
        window_size = 5,
        output_dir = tempdir()
    )
}
</code></pre>

<hr>
<h2 id='sits_as_sf'>Return a sits_tibble or raster_cube as an sf object.</h2><span id='topic+sits_as_sf'></span><span id='topic+sits_as_sf.sits'></span><span id='topic+sits_as_sf.raster_cube'></span>

<h3>Description</h3>

<p>Return a sits_tibble or raster_cube as an sf object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sits_as_sf(data, ..., as_crs = NULL)

## S3 method for class 'sits'
sits_as_sf(data, ..., crs = "EPSG:4326", as_crs = NULL)

## S3 method for class 'raster_cube'
sits_as_sf(data, ..., as_crs = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sits_as_sf_+3A_data">data</code></td>
<td>
<p>A sits tibble or sits cube.</p>
</td></tr>
<tr><td><code id="sits_as_sf_+3A_...">...</code></td>
<td>
<p>Additional parameters.</p>
</td></tr>
<tr><td><code id="sits_as_sf_+3A_as_crs">as_crs</code></td>
<td>
<p>Output coordinate reference system.</p>
</td></tr>
<tr><td><code id="sits_as_sf_+3A_crs">crs</code></td>
<td>
<p>Input coordinate reference system.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An sf object of point or polygon geometry.
</p>


<h3>Author(s)</h3>

<p>Felipe Carvalho, <a href="mailto:felipe.carvalho@inpe.br">felipe.carvalho@inpe.br</a>
</p>
<p>Alber Sanchez, <a href="mailto:alber.ipia@inpe.br">alber.ipia@inpe.br</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (sits_run_examples()) {
    # convert sits tibble to an sf object (point)
    sf_object &lt;- sits_as_sf(cerrado_2classes)

    # convert sits cube to an sf object (polygon)
    data_dir &lt;- system.file("extdata/raster/mod13q1", package = "sits")
    cube &lt;- sits_cube(
        source = "BDC",
        collection = "MOD13Q1-6",
        data_dir = data_dir
    )
    sf_object &lt;- sits_as_sf(cube)
}
</code></pre>

<hr>
<h2 id='sits_bands'>Get the names of the bands</h2><span id='topic+sits_bands'></span><span id='topic+sits_bands.sits'></span><span id='topic+sits_bands.raster_cube'></span><span id='topic+sits_bands.patterns'></span><span id='topic+sits_bands.sits_model'></span><span id='topic+sits_bands.tbl_df'></span><span id='topic+sits_bands.default'></span><span id='topic+sits_bands+3C-'></span><span id='topic+sits_bands+3C-.sits'></span><span id='topic+sits_bands+3C-.raster_cube'></span><span id='topic+sits_bands+3C-.default'></span>

<h3>Description</h3>

<p>Finds the names of the bands of a set of time series or of a data cube
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sits_bands(x)

## S3 method for class 'sits'
sits_bands(x)

## S3 method for class 'raster_cube'
sits_bands(x)

## S3 method for class 'patterns'
sits_bands(x)

## S3 method for class 'sits_model'
sits_bands(x)

## S3 method for class 'tbl_df'
sits_bands(x)

## Default S3 method:
sits_bands(x)

sits_bands(x) &lt;- value

## S3 replacement method for class 'sits'
sits_bands(x) &lt;- value

## S3 replacement method for class 'raster_cube'
sits_bands(x) &lt;- value

## Default S3 replacement method:
sits_bands(x) &lt;- value
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sits_bands_+3A_x">x</code></td>
<td>
<p>Valid sits tibble (time series or a cube)</p>
</td></tr>
<tr><td><code id="sits_bands_+3A_value">value</code></td>
<td>
<p>New value for the bands</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector with the names of the bands.
</p>


<h3>Author(s)</h3>

<p>Gilberto Camara, <a href="mailto:gilberto.camara@inpe.br">gilberto.camara@inpe.br</a>
</p>
<p>Rolf Simoes, <a href="mailto:rolf.simoes@inpe.br">rolf.simoes@inpe.br</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (sits_run_examples()) {
    # Create a data cube from local files
    data_dir &lt;- system.file("extdata/raster/mod13q1", package = "sits")
    cube &lt;- sits_cube(
        source = "BDC",
        collection = "MOD13Q1-6",
        data_dir = data_dir
    )
    # Get the bands from a daya cube
    bands &lt;- sits_bands(cube)
    # Get the bands from a sits tibble
    bands &lt;- sits_bands(samples_modis_ndvi)
    # Get the bands from patterns
    bands &lt;- sits_bands(sits_patterns(samples_modis_ndvi))
    # Get the bands from ML model
    rf_model &lt;- sits_train(samples_modis_ndvi, sits_rfor())
    bands &lt;- sits_bands(rf_model)
    # Set the bands for a SITS time series
    sits_bands(samples_modis_ndvi) &lt;- "NDVI2"
    # Set the bands for a SITS cube
    sits_bands(cube) &lt;- "NDVI2"
}
</code></pre>

<hr>
<h2 id='sits_bbox'>Get the bounding box of the data</h2><span id='topic+sits_bbox'></span><span id='topic+sits_bbox.sits'></span><span id='topic+sits_bbox.raster_cube'></span><span id='topic+sits_bbox.tbl_df'></span><span id='topic+sits_bbox.default'></span>

<h3>Description</h3>

<p>Obtain a vector of limits (either on lat/long for time series
or in projection coordinates in the case of cubes)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sits_bbox(data, crs = "EPSG:4326", as_crs = NULL)

## S3 method for class 'sits'
sits_bbox(data, crs = "EPSG:4326", as_crs = NULL)

## S3 method for class 'raster_cube'
sits_bbox(data, crs = "EPSG:4326", as_crs = NULL)

## S3 method for class 'tbl_df'
sits_bbox(data, crs = "EPSG:4326", as_crs = NULL)

## Default S3 method:
sits_bbox(data, crs = "EPSG:4326", as_crs = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sits_bbox_+3A_data">data</code></td>
<td>
<p>samples (class &quot;sits&quot;) or <code>cube</code>.</p>
</td></tr>
<tr><td><code id="sits_bbox_+3A_crs">crs</code></td>
<td>
<p>CRS of the samples points (single char)</p>
</td></tr>
<tr><td><code id="sits_bbox_+3A_as_crs">as_crs</code></td>
<td>
<p>CRS to project the resulting <code>bbox</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code>bbox</code>.
</p>


<h3>Author(s)</h3>

<p>Gilberto Camara, <a href="mailto:gilberto.camara@inpe.br">gilberto.camara@inpe.br</a>
</p>
<p>Rolf Simoes, <a href="mailto:rolf.simoes@inpe.br">rolf.simoes@inpe.br</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (sits_run_examples()) {
    # get the bbox of a set of samples
    sits_bbox(samples_modis_ndvi)
    # get the bbox of a cube in WGS84
    data_dir &lt;- system.file("extdata/raster/mod13q1", package = "sits")
    cube &lt;- sits_cube(
        source = "BDC",
        collection = "MOD13Q1-6",
        data_dir = data_dir
    )
    sits_bbox(cube, as_crs = "EPSG:4326")
}
</code></pre>

<hr>
<h2 id='sits_classify'>Classify time series or data cubes</h2><span id='topic+sits_classify'></span><span id='topic+sits_classify.sits'></span><span id='topic+sits_classify.raster_cube'></span><span id='topic+sits_classify.derived_cube'></span><span id='topic+sits_classify.tbl_df'></span><span id='topic+sits_classify.segs_cube'></span><span id='topic+sits_classify.default'></span>

<h3>Description</h3>

<p>This function classifies a set of time series or data cube given
a trained model prediction model created by <code><a href="#topic+sits_train">sits_train</a></code>.
</p>
<p>SITS supports the following models:
(a) support vector machines:  <code><a href="#topic+sits_svm">sits_svm</a></code>;
(b) random forests:  <code><a href="#topic+sits_rfor">sits_rfor</a></code>;
(c) extreme gradient boosting: <code><a href="#topic+sits_xgboost">sits_xgboost</a></code>;
(d) multi-layer perceptrons: <code><a href="#topic+sits_mlp">sits_mlp</a></code>;
(e) 1D CNN: <code><a href="#topic+sits_tempcnn">sits_tempcnn</a></code>;
(f) deep residual networks: <code><a href="#topic+sits_resnet">sits_resnet</a></code>;
(g) self-attention encoders: <code><a href="#topic+sits_lighttae">sits_lighttae</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sits_classify(
  data,
  ml_model,
  ...,
  filter_fn = NULL,
  multicores = 2L,
  progress = TRUE
)

## S3 method for class 'sits'
sits_classify(
  data,
  ml_model,
  ...,
  filter_fn = NULL,
  multicores = 2L,
  gpu_memory = 16,
  progress = TRUE
)

## S3 method for class 'raster_cube'
sits_classify(
  data,
  ml_model,
  ...,
  roi = NULL,
  filter_fn = NULL,
  start_date = NULL,
  end_date = NULL,
  memsize = 8L,
  multicores = 2L,
  gpu_memory = 16,
  output_dir,
  version = "v1",
  verbose = FALSE,
  progress = TRUE
)

## S3 method for class 'derived_cube'
sits_classify(data, ml_model, ...)

## S3 method for class 'tbl_df'
sits_classify(data, ml_model, ...)

## S3 method for class 'segs_cube'
sits_classify(
  data,
  ml_model,
  ...,
  filter_fn = NULL,
  start_date = NULL,
  end_date = NULL,
  memsize = 8L,
  multicores = 2L,
  gpu_memory = 16,
  output_dir,
  version = "v1",
  n_sam_pol = 40,
  verbose = FALSE,
  progress = TRUE
)

## Default S3 method:
sits_classify(data, ml_model, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sits_classify_+3A_data">data</code></td>
<td>
<p>Data cube (tibble of class &quot;raster_cube&quot;)</p>
</td></tr>
<tr><td><code id="sits_classify_+3A_ml_model">ml_model</code></td>
<td>
<p>R model trained by <code><a href="#topic+sits_train">sits_train</a></code>
(closure of class &quot;sits_model&quot;)</p>
</td></tr>
<tr><td><code id="sits_classify_+3A_...">...</code></td>
<td>
<p>Other parameters for specific functions.</p>
</td></tr>
<tr><td><code id="sits_classify_+3A_filter_fn">filter_fn</code></td>
<td>
<p>Smoothing filter to be applied - optional
(clousure containing object of class &quot;function&quot;).</p>
</td></tr>
<tr><td><code id="sits_classify_+3A_multicores">multicores</code></td>
<td>
<p>Number of cores to be used for classification
(integer, min = 1, max = 2048).</p>
</td></tr>
<tr><td><code id="sits_classify_+3A_progress">progress</code></td>
<td>
<p>Logical: Show progress bar?</p>
</td></tr>
<tr><td><code id="sits_classify_+3A_gpu_memory">gpu_memory</code></td>
<td>
<p>Memory available in GPU in GB (default = 16)</p>
</td></tr>
<tr><td><code id="sits_classify_+3A_roi">roi</code></td>
<td>
<p>Region of interest (either an sf object, shapefile,
or a numeric vector with named XY values
(&quot;xmin&quot;, &quot;xmax&quot;, &quot;ymin&quot;, &quot;ymax&quot;) or
named lat/long values
(&quot;lon_min&quot;, &quot;lat_min&quot;, &quot;lon_max&quot;, &quot;lat_max&quot;).</p>
</td></tr>
<tr><td><code id="sits_classify_+3A_start_date">start_date</code></td>
<td>
<p>Start date for the classification
(Date in YYYY-MM-DD format).</p>
</td></tr>
<tr><td><code id="sits_classify_+3A_end_date">end_date</code></td>
<td>
<p>End date for the classification
(Date im YYYY-MM-DD format).</p>
</td></tr>
<tr><td><code id="sits_classify_+3A_memsize">memsize</code></td>
<td>
<p>Memory available for classification in GB
(integer, min = 1, max = 16384).</p>
</td></tr>
<tr><td><code id="sits_classify_+3A_output_dir">output_dir</code></td>
<td>
<p>Valid directory for output file.
(character vector of length 1).</p>
</td></tr>
<tr><td><code id="sits_classify_+3A_version">version</code></td>
<td>
<p>Version of the output
(character vector of length 1).</p>
</td></tr>
<tr><td><code id="sits_classify_+3A_verbose">verbose</code></td>
<td>
<p>Logical: print information about processing time?</p>
</td></tr>
<tr><td><code id="sits_classify_+3A_n_sam_pol">n_sam_pol</code></td>
<td>
<p>Number of time series per segment to be classified
(integer, min = 10, max = 50).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Time series with predicted labels for
each point (tibble of class &quot;sits&quot;)
or a data cube with probabilities for each class
(tibble of class &quot;probs_cube&quot;).
</p>


<h3>Note</h3>

<p>The <code>roi</code> parameter defines a region of interest. It can be
an sf_object, a shapefile, or a bounding box vector with
named XY values (<code>xmin</code>, <code>xmax</code>, <code>ymin</code>, <code>ymax</code>) or
named lat/long values (<code>lon_min</code>, <code>lon_max</code>,
<code>lat_min</code>, <code>lat_max</code>)
</p>
<p>Parameter <code>filter_fn</code> parameter specifies a smoothing filter
to be applied to each time series for reducing noise. Currently, options
are Savitzky-Golay (see <code><a href="#topic+sits_sgolay">sits_sgolay</a></code>) and Whittaker
(see <code><a href="#topic+sits_whittaker">sits_whittaker</a></code>) filters.
</p>
<p>Parameter <code>memsize</code> controls the amount of memory available
for classification, while <code>multicores</code>  defines the number of cores
used for processing. We recommend using as much memory as possible.
</p>
<p>When using a GPU for deep learning, <code>gpu_memory</code> indicates the
memory of available in the graphics card.
</p>
<p>For classifying vector data cubes created by
<code><a href="#topic+sits_segment">sits_segment</a></code>,
<code>n_sam_pol</code> controls is the number of time series to be
classified per segment.
</p>
<p>Please refer to the sits documentation available in
&lt;https://e-sensing.github.io/sitsbook/&gt; for detailed examples.
</p>


<h3>Author(s)</h3>

<p>Rolf Simoes, <a href="mailto:rolf.simoes@inpe.br">rolf.simoes@inpe.br</a>
</p>
<p>Gilberto Camara, <a href="mailto:gilberto.camara@inpe.br">gilberto.camara@inpe.br</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (sits_run_examples()) {
    # Example of classification of a time series
    # Retrieve the samples for Mato Grosso
    # train a random forest model
    rf_model &lt;- sits_train(samples_modis_ndvi, ml_method = sits_rfor)

    # classify the point
    point_ndvi &lt;- sits_select(point_mt_6bands, bands = c("NDVI"))
    point_class &lt;- sits_classify(
        data = point_ndvi, ml_model = rf_model
    )
    plot(point_class)

    # Example of classification of a data cube
    # create a data cube from local files
    data_dir &lt;- system.file("extdata/raster/mod13q1", package = "sits")
    cube &lt;- sits_cube(
        source = "BDC",
        collection = "MOD13Q1-6",
        data_dir = data_dir
    )
    # classify a data cube
    probs_cube &lt;- sits_classify(
        data = cube,
        ml_model = rf_model,
        output_dir = tempdir(),
        version = "ex_classify"
    )
    # label the probability cube
    label_cube &lt;- sits_label_classification(
        probs_cube,
        output_dir = tempdir(),
        version = "ex_classify"
    )
    # plot the classified image
    plot(label_cube)
    # segmentation
    # segment the image
    segments &lt;- sits_segment(
        cube = cube,
        seg_fn = sits_slic(step = 5,
                       compactness = 1,
                       dist_fun = "euclidean",
                       avg_fun = "median",
                       iter = 50,
                       minarea = 10,
                       verbose = FALSE
                       ),
        output_dir = tempdir()
    )
    # Create a classified vector cube
    probs_segs &lt;- sits_classify(
        data = segments,
        ml_model = rf_model,
        output_dir = tempdir(),
        n_sam_pol = 20,
        multicores = 4,
        version = "segs_classify"
    )
    # Create a labelled vector cube
    class_segs &lt;- sits_label_classification(
        cube = probs_segs,
        output_dir = tempdir(),
        multicores = 2,
        memsize = 4,
        version = "segs_classify"
    )
    # plot class_segs
    plot(class_segs)
}

</code></pre>

<hr>
<h2 id='sits_cluster_clean'>Removes labels that are minority in each cluster.</h2><span id='topic+sits_cluster_clean'></span>

<h3>Description</h3>

<p>Takes a tibble with time series
that has an additional 'cluster' produced by
<code>link[sits]{sits_cluster_dendro()}</code>
and removes labels that are minority in each cluster.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sits_cluster_clean(samples)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sits_cluster_clean_+3A_samples">samples</code></td>
<td>
<p>Tibble with set of time series with additional
cluster information produced
by <code>link[sits]{sits_cluster_dendro()}</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>Tibble with time series (class &quot;sits&quot;)
</p>


<h3>Author(s)</h3>

<p>Rolf Simoes, <a href="mailto:rolf.simoes@inpe.br">rolf.simoes@inpe.br</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (sits_run_examples()) {
    clusters &lt;- sits_cluster_dendro(cerrado_2classes)
    freq1 &lt;- sits_cluster_frequency(clusters)
    freq1
    clean_clusters &lt;- sits_cluster_clean(clusters)
    freq2 &lt;- sits_cluster_frequency(clean_clusters)
    freq2
}
</code></pre>

<hr>
<h2 id='sits_cluster_dendro'>Find clusters in time series samples</h2><span id='topic+sits_cluster_dendro'></span><span id='topic+sits_cluster_dendro.sits'></span><span id='topic+sits_cluster_dendro.tbl_df'></span><span id='topic+sits_cluster_dendro.default'></span>

<h3>Description</h3>

<p>These functions support hierarchical agglomerative clustering in
sits. They provide support from creating a dendrogram and using it for
cleaning samples.
</p>
<p><code>link[sits]{sits_cluster_dendro()}</code> takes a tibble with time series and
produces a sits tibble with an added &quot;cluster&quot; column. The function first
calculates a dendrogram and obtains a validity index for best clustering
using the adjusted Rand Index. After cutting the dendrogram using the chosen
validity index, it assigns a cluster to each sample.
</p>
<p><code>link[sits]{sits_cluster_frequency()}</code> computes the contingency
table between labels
and clusters and produces a matrix.
Its input is a tibble produced by <code>link[sits]{sits_cluster_dendro()}</code>.
</p>
<p><code>link[sits]{sits_cluster_clean()}</code> takes a tibble with time series
that has an additional 'cluster' produced by
<code>link[sits]{sits_cluster_dendro()}</code>
and removes labels that are minority in each cluster.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sits_cluster_dendro(
  samples,
  bands = NULL,
  dist_method = "dtw_basic",
  linkage = "ward.D2",
  k = NULL,
  palette = "RdYlGn"
)

## S3 method for class 'sits'
sits_cluster_dendro(
  samples,
  bands = NULL,
  dist_method = "dtw_basic",
  linkage = "ward.D2",
  k = NULL,
  palette = "RdYlGn",
  ...
)

## S3 method for class 'tbl_df'
sits_cluster_dendro(samples, ...)

## Default S3 method:
sits_cluster_dendro(samples, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sits_cluster_dendro_+3A_samples">samples</code></td>
<td>
<p>Tibble with input set of time series (class &quot;sits&quot;).</p>
</td></tr>
<tr><td><code id="sits_cluster_dendro_+3A_bands">bands</code></td>
<td>
<p>Bands to be used in the clustering
(character vector)</p>
</td></tr>
<tr><td><code id="sits_cluster_dendro_+3A_dist_method">dist_method</code></td>
<td>
<p>One of the supported distances (single char vector)
&quot;dtw&quot;: DTW with a Sakoe-Chiba constraint.
&quot;dtw2&quot;: DTW with L2 norm and Sakoe-Chiba constraint.
&quot;dtw_basic&quot;: A faster DTW with less functionality.
&quot;lbk&quot;: Keogh's lower bound for DTW.
&quot;lbi&quot;: Lemire's lower bound for DTW.</p>
</td></tr>
<tr><td><code id="sits_cluster_dendro_+3A_linkage">linkage</code></td>
<td>
<p>Agglomeration method to be used (single char vector)
One of &quot;ward.D&quot;, &quot;ward.D2&quot;, &quot;single&quot;, &quot;complete&quot;,
&quot;average&quot;, &quot;mcquitty&quot;, &quot;median&quot; or &quot;centroid&quot;.</p>
</td></tr>
<tr><td><code id="sits_cluster_dendro_+3A_k">k</code></td>
<td>
<p>Desired number of clusters (overrides default value)</p>
</td></tr>
<tr><td><code id="sits_cluster_dendro_+3A_palette">palette</code></td>
<td>
<p>Color palette as per 'grDevices::hcl.pals()' function.</p>
</td></tr>
<tr><td><code id="sits_cluster_dendro_+3A_...">...</code></td>
<td>
<p>Additional parameters to be passed
to dtwclust::tsclust() function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Tibble with &quot;cluster&quot; column (class &quot;sits_cluster&quot;).
</p>


<h3>Note</h3>

<p>Please refer to the sits documentation available in
&lt;https://e-sensing.github.io/sitsbook/&gt; for detailed examples.
</p>


<h3>Author(s)</h3>

<p>Rolf Simoes, <a href="mailto:rolf.simoes@inpe.br">rolf.simoes@inpe.br</a>
</p>


<h3>References</h3>

<p>&quot;dtwclust&quot; package (https://CRAN.R-project.org/package=dtwclust)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (sits_run_examples()) {
    # default
    clusters &lt;- sits_cluster_dendro(cerrado_2classes)
    # with parameters
    clusters &lt;- sits_cluster_dendro(cerrado_2classes,
                bands = "NDVI", k = 5)
}

</code></pre>

<hr>
<h2 id='sits_cluster_frequency'>Show label frequency in each cluster produced by dendrogram analysis</h2><span id='topic+sits_cluster_frequency'></span>

<h3>Description</h3>

<p>Show label frequency in each cluster produced by dendrogram analysis
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sits_cluster_frequency(samples)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sits_cluster_frequency_+3A_samples">samples</code></td>
<td>
<p>Tibble with input set of time series with additional
cluster information produced
by <code>link[sits]{sits_cluster_dendro}</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix containing frequencies
of labels in clusters.
</p>


<h3>Author(s)</h3>

<p>Rolf Simoes, <a href="mailto:rolf.simoes@inpe.br">rolf.simoes@inpe.br</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (sits_run_examples()) {
    clusters &lt;- sits_cluster_dendro(cerrado_2classes)
    freq &lt;- sits_cluster_frequency(clusters)
    freq
}
</code></pre>

<hr>
<h2 id='sits_colors'>Function to retrieve sits color table</h2><span id='topic+sits_colors'></span>

<h3>Description</h3>

<p>Returns a color table
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sits_colors(legend = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sits_colors_+3A_legend">legend</code></td>
<td>
<p>One of the accepted legends in sits</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tibble with color names and values
</p>


<h3>Author(s)</h3>

<p>Gilberto Camara, <a href="mailto:gilberto.camara@inpe.br">gilberto.camara@inpe.br</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (sits_run_examples()) {
    # return the names of all colors supported by SITS
    sits_colors()
}
</code></pre>

<hr>
<h2 id='sits_colors_qgis'>Function to save color table as QML style for data cube</h2><span id='topic+sits_colors_qgis'></span>

<h3>Description</h3>

<p>Saves a color table associated to a classified
data cube as a QGIS style file
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sits_colors_qgis(cube, file)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sits_colors_qgis_+3A_cube">cube</code></td>
<td>
<p>a classified data cube</p>
</td></tr>
<tr><td><code id="sits_colors_qgis_+3A_file">file</code></td>
<td>
<p>a QGIS style file to be written to</p>
</td></tr>
</table>


<h3>Value</h3>

<p>No return, called for side effects
</p>


<h3>Author(s)</h3>

<p>Gilberto Camara, <a href="mailto:gilberto.camara@inpe.br">gilberto.camara@inpe.br</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (sits_run_examples()) {
    # reset the default colors supported by SITS
    sits_colors_reset()
}
</code></pre>

<hr>
<h2 id='sits_colors_reset'>Function to reset sits color table</h2><span id='topic+sits_colors_reset'></span>

<h3>Description</h3>

<p>Resets the color table
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sits_colors_reset()
</code></pre>


<h3>Value</h3>

<p>No return, called for side effects
</p>


<h3>Author(s)</h3>

<p>Gilberto Camara, <a href="mailto:gilberto.camara@inpe.br">gilberto.camara@inpe.br</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (sits_run_examples()) {
    # reset the default colors supported by SITS
    sits_colors_reset()
}
</code></pre>

<hr>
<h2 id='sits_colors_set'>Function to set sits color table</h2><span id='topic+sits_colors_set'></span>

<h3>Description</h3>

<p>Sets a color table
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sits_colors_set(color_tb)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sits_colors_set_+3A_color_tb">color_tb</code></td>
<td>
<p>New color table</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A modified sits color table
</p>


<h3>Author(s)</h3>

<p>Gilberto Camara, <a href="mailto:gilberto.camara@inpe.br">gilberto.camara@inpe.br</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (sits_run_examples()) {
    # Define a color table based on the Anderson Land Classification System
    us_nlcd &lt;- tibble::tibble(name = character(), color = character())
    us_nlcd &lt;- us_nlcd |&gt;
        tibble::add_row(name = "Urban Built Up", color = "#85929E") |&gt;
        tibble::add_row(name = "Agricultural Land", color = "#F0B27A") |&gt;
        tibble::add_row(name = "Rangeland", color = "#F1C40F") |&gt;
        tibble::add_row(name = "Forest Land", color = "#27AE60") |&gt;
        tibble::add_row(name = "Water", color = "#2980B9") |&gt;
        tibble::add_row(name = "Wetland", color = "#D4E6F1") |&gt;
        tibble::add_row(name = "Barren Land", color = "#FDEBD0") |&gt;
        tibble::add_row(name = "Tundra", color = "#EBDEF0") |&gt;
        tibble::add_row(name = "Snow and Ice", color = "#F7F9F9")

    # Load the color table into `sits`
    sits_colors_set(us_nlcd)

    # Show the new color table used by sits
    sits_colors_show()
}
</code></pre>

<hr>
<h2 id='sits_colors_show'>Function to show colors in SITS</h2><span id='topic+sits_colors_show'></span>

<h3>Description</h3>

<p>Shows the default SITS colors
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sits_colors_show(legend = NULL, font_family = "plex_sans")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sits_colors_show_+3A_legend">legend</code></td>
<td>
<p>One of the accepted legends in sits</p>
</td></tr>
<tr><td><code id="sits_colors_show_+3A_font_family">font_family</code></td>
<td>
<p>A font family loaded in SITS</p>
</td></tr>
</table>


<h3>Value</h3>

<p>no return, called for side effects
</p>


<h3>Author(s)</h3>

<p>Gilberto Camara, <a href="mailto:gilberto.camara@inpe.br">gilberto.camara@inpe.br</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (sits_run_examples()) {
    # show the colors supported by SITS
    sits_colors_show()
}
</code></pre>

<hr>
<h2 id='sits_combine_predictions'>Estimate ensemble prediction based on list of probs cubes</h2><span id='topic+sits_combine_predictions'></span><span id='topic+sits_combine_predictions.average'></span><span id='topic+sits_combine_predictions.uncertainty'></span><span id='topic+sits_combine_predictions.default'></span>

<h3>Description</h3>

<p>Calculate an ensemble predictor based a list of probability
cubes. The function combines the output of two or more classifier
to derive a value which is based on weights assigned to each model.
The supported types of ensemble predictors are 'average' and
'uncertainty'.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sits_combine_predictions(
  cubes,
  type = "average",
  ...,
  memsize = 8L,
  multicores = 2L,
  output_dir,
  version = "v1"
)

## S3 method for class 'average'
sits_combine_predictions(
  cubes,
  type = "average",
  ...,
  weights = NULL,
  memsize = 8L,
  multicores = 2L,
  output_dir,
  version = "v1"
)

## S3 method for class 'uncertainty'
sits_combine_predictions(
  cubes,
  type = "uncertainty",
  ...,
  uncert_cubes,
  memsize = 8L,
  multicores = 2L,
  output_dir,
  version = "v1"
)

## Default S3 method:
sits_combine_predictions(cubes, type, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sits_combine_predictions_+3A_cubes">cubes</code></td>
<td>
<p>List of probability data cubes (class &quot;probs_cube&quot;)</p>
</td></tr>
<tr><td><code id="sits_combine_predictions_+3A_type">type</code></td>
<td>
<p>Method to measure uncertainty. One of &quot;average&quot; or
&quot;uncertainty&quot;</p>
</td></tr>
<tr><td><code id="sits_combine_predictions_+3A_...">...</code></td>
<td>
<p>Parameters for specific functions.</p>
</td></tr>
<tr><td><code id="sits_combine_predictions_+3A_memsize">memsize</code></td>
<td>
<p>Memory available for classification in GB
(integer, min = 1, max = 16384).</p>
</td></tr>
<tr><td><code id="sits_combine_predictions_+3A_multicores">multicores</code></td>
<td>
<p>Number of cores to be used for classification
(integer, min = 1, max = 2048).</p>
</td></tr>
<tr><td><code id="sits_combine_predictions_+3A_output_dir">output_dir</code></td>
<td>
<p>Valid directory for output file.
(character vector of length 1).</p>
</td></tr>
<tr><td><code id="sits_combine_predictions_+3A_version">version</code></td>
<td>
<p>Version of the output
(character vector of length 1).</p>
</td></tr>
<tr><td><code id="sits_combine_predictions_+3A_weights">weights</code></td>
<td>
<p>Weights for averaging (numeric vector).</p>
</td></tr>
<tr><td><code id="sits_combine_predictions_+3A_uncert_cubes">uncert_cubes</code></td>
<td>
<p>Uncertainty cubes to be used as local weights when
type = &quot;uncertainty&quot; is selected
(list of tibbles with class &quot;uncertainty_cube&quot;)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A combined probability cube (tibble of class &quot;probs_cube&quot;).
</p>


<h3>Author(s)</h3>

<p>Gilberto Camara, <a href="mailto:gilberto.camara@inpe.br">gilberto.camara@inpe.br</a>
</p>
<p>Rolf Simoes, <a href="mailto:rolf.simoes@inpe.br">rolf.simoes@inpe.br</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (sits_run_examples()) {
    # create a data cube from local files
    data_dir &lt;- system.file("extdata/raster/mod13q1", package = "sits")
    cube &lt;- sits_cube(
        source = "BDC",
        collection = "MOD13Q1-6",
        data_dir = data_dir
    )
    # create a random forest model
    rfor_model &lt;- sits_train(samples_modis_ndvi, sits_rfor())
    # classify a data cube using rfor model
    probs_rfor_cube &lt;- sits_classify(
        data = cube, ml_model = rfor_model, output_dir = tempdir(),
        version = "rfor"
    )
    # create an XGBoost model
    svm_model &lt;- sits_train(samples_modis_ndvi, sits_svm())
    # classify a data cube using SVM model
    probs_svm_cube &lt;- sits_classify(
        data = cube, ml_model = svm_model, output_dir = tempdir(),
        version = "svm"
    )
    # create a list of predictions to be combined
    pred_cubes &lt;- list(probs_rfor_cube, probs_svm_cube)
    # combine predictions
    comb_probs_cube &lt;- sits_combine_predictions(
        pred_cubes,
        output_dir = tempdir()
    )
    # plot the resulting combined prediction cube
    plot(comb_probs_cube)
}
</code></pre>

<hr>
<h2 id='sits_confidence_sampling'>Suggest high confidence samples to increase the training set.</h2><span id='topic+sits_confidence_sampling'></span>

<h3>Description</h3>

<p>Suggest points for increasing the training set. These points are labelled
with high confidence so they can be added to the training set.
They need to have a satisfactory margin of confidence to be selected.
The input is a probability cube. For each label, the algorithm finds out
location where the machine learning model has high confidence in choosing
this label compared to all others. The algorithm also considers a
minimum distance between new labels, to minimize spatial autocorrelation
effects.
This function is best used in the following context:
1. Select an initial set of samples.
2. Train a machine learning model.
3. Build a data cube and classify it using the model.
4. Run a Bayesian smoothing in the resulting probability cube.
5. Perform confidence sampling.
</p>
<p>The Bayesian smoothing procedure will reduce the classification outliers
and thus increase the likelihood that the resulting pixels with provide
good quality samples for each class.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sits_confidence_sampling(
  probs_cube,
  n = 20L,
  min_margin = 0.9,
  sampling_window = 10L
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sits_confidence_sampling_+3A_probs_cube">probs_cube</code></td>
<td>
<p>A smoothed probability cube.
See <code><a href="#topic+sits_classify">sits_classify</a></code> and
<code><a href="#topic+sits_smooth">sits_smooth</a></code>.</p>
</td></tr>
<tr><td><code id="sits_confidence_sampling_+3A_n">n</code></td>
<td>
<p>Number of suggested points per class.</p>
</td></tr>
<tr><td><code id="sits_confidence_sampling_+3A_min_margin">min_margin</code></td>
<td>
<p>Minimum margin of confidence to select a sample</p>
</td></tr>
<tr><td><code id="sits_confidence_sampling_+3A_sampling_window">sampling_window</code></td>
<td>
<p>Window size for collecting points (in pixels).
The minimum window size is 10.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tibble with longitude and latitude in WGS84 with locations
which have high uncertainty and meet the minimum distance
criteria.
</p>


<h3>Author(s)</h3>

<p>Alber Sanchez, <a href="mailto:alber.ipia@inpe.br">alber.ipia@inpe.br</a>
</p>
<p>Rolf Simoes, <a href="mailto:rolf.simoes@inpe.br">rolf.simoes@inpe.br</a>
</p>
<p>Felipe Carvalho, <a href="mailto:felipe.carvalho@inpe.br">felipe.carvalho@inpe.br</a>
</p>
<p>Gilberto Camara, <a href="mailto:gilberto.camara@inpe.br">gilberto.camara@inpe.br</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (sits_run_examples()) {
    # create a data cube
    data_dir &lt;- system.file("extdata/raster/mod13q1", package = "sits")
    cube &lt;- sits_cube(
        source = "BDC",
        collection = "MOD13Q1-6",
        data_dir = data_dir
    )
    # build a random forest model
    rfor_model &lt;- sits_train(samples_modis_ndvi, ml_method = sits_rfor())
    # classify the cube
    probs_cube &lt;- sits_classify(
        data = cube, ml_model = rfor_model, output_dir = tempdir()
    )
    # obtain a new set of samples for active learning
    # the samples are located in uncertain places
    new_samples &lt;- sits_confidence_sampling(probs_cube)
}
</code></pre>

<hr>
<h2 id='sits_config'>Configure parameters for sits package</h2><span id='topic+sits_config'></span>

<h3>Description</h3>

<p>These functions load and show sits configurations.
</p>
<p>The 'sits' package uses a configuration file
that contains information on parameters required by different functions.
This includes information about the image collections handled by 'sits'.
</p>
<p><code>sits_config()</code> loads the default configuration file and
the user provided configuration file. The final configuration is
obtained by overriding the options by the values provided by the user.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sits_config(config_user_file = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sits_config_+3A_config_user_file">config_user_file</code></td>
<td>
<p>YAML user configuration file
(character vector of a file with &quot;yml&quot; extension)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Users can provide additional configuration files, by specifying the
location of their file in the environmental variable
<code>SITS_CONFIG_USER_FILE</code> or as parameter to this function.
</p>
<p>To see the key entries and contents of the current configuration values,
use <code>link[sits]{sits_config_show()}</code>.
</p>


<h3>Value</h3>

<p>Called for side effects
</p>


<h3>Author(s)</h3>

<p>Rolf Simoes, <a href="mailto:rolf.simoes@inpe.br">rolf.simoes@inpe.br</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>yaml_user_file &lt;- system.file("extdata/config_user_example.yml",
                  package = "sits")
sits_config(config_user_file = yaml_user_file)
</code></pre>

<hr>
<h2 id='sits_config_show'>Show current sits configuration</h2><span id='topic+sits_config_show'></span>

<h3>Description</h3>

<p>Prints the current sits configuration options.
To show specific configuration options for
a source, a collection, or a palette, users can inform the corresponding
keys to <code>source</code> and <code>collection</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sits_config_show(source = NULL, collection = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sits_config_show_+3A_source">source</code></td>
<td>
<p>Data source (character vector).</p>
</td></tr>
<tr><td><code id="sits_config_show_+3A_collection">collection</code></td>
<td>
<p>Collection (character vector).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>No return value, called for side effects.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>sits_config_show(source = "BDC")
sits_config_show(source = "BDC", collection = "CBERS-WFI-16D")
</code></pre>

<hr>
<h2 id='sits_cube'>Create data cubes from image collections</h2><span id='topic+sits_cube'></span><span id='topic+sits_cube.stac_cube'></span><span id='topic+sits_cube.local_cube'></span>

<h3>Description</h3>

<p>Creates a data cube based on spatial and temporal restrictions
in collections available in cloud services or local repositories.
The following cloud providers are supported, based on the STAC protocol:
Amazon Web Services (AWS), Brazil Data Cube (BDC),
Digital Earth Africa (DEAFRICA), Microsoft Planetary Computer (MPC),
Nasa Harmonized Landsat/Sentinel (HLS), USGS Landsat (USGS), and
Swiss Data Cube (SDC). Data cubes can also be created using local files.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sits_cube(source, collection, ...)

## S3 method for class 'stac_cube'
sits_cube(
  source,
  collection,
  ...,
  bands = NULL,
  tiles = NULL,
  roi = NULL,
  start_date = NULL,
  end_date = NULL,
  platform = NULL,
  progress = TRUE
)

## S3 method for class 'local_cube'
sits_cube(
  source,
  collection,
  ...,
  data_dir,
  vector_dir = NULL,
  tiles = NULL,
  bands = NULL,
  vector_band = NULL,
  start_date = NULL,
  end_date = NULL,
  labels = NULL,
  parse_info = NULL,
  version = "v1",
  delim = "_",
  multicores = 2L,
  progress = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sits_cube_+3A_source">source</code></td>
<td>
<p>Data source (one of <code>"AWS"</code>, <code>"BDC"</code>,
<code>"DEAFRICA"</code>, <code>"MPC"</code>, <code>"SDC"</code>,
<code>"USGS"</code> - character vector of length 1).</p>
</td></tr>
<tr><td><code id="sits_cube_+3A_collection">collection</code></td>
<td>
<p>Image collection in data source
(character vector of length 1).
To find out the supported collections,
use <code><a href="#topic+sits_list_collections">sits_list_collections</a>()</code>).</p>
</td></tr>
<tr><td><code id="sits_cube_+3A_...">...</code></td>
<td>
<p>Other parameters to be passed for specific types.</p>
</td></tr>
<tr><td><code id="sits_cube_+3A_bands">bands</code></td>
<td>
<p>Spectral bands and indices to be included
in the cube (optional - character vector).
Use <code><a href="#topic+sits_list_collections">sits_list_collections</a>()</code> to find out
the bands available for each collection.</p>
</td></tr>
<tr><td><code id="sits_cube_+3A_tiles">tiles</code></td>
<td>
<p>Tiles from the collection to be included in
the cube (see details below)
(character vector of length 1).</p>
</td></tr>
<tr><td><code id="sits_cube_+3A_roi">roi</code></td>
<td>
<p>Region of interest (either an sf object, shapefile,
or a numeric vector with named XY values
(&quot;xmin&quot;, &quot;xmax&quot;, &quot;ymin&quot;, &quot;ymax&quot;) or
named lat/long values
(&quot;lon_min&quot;, &quot;lat_min&quot;, &quot;lon_max&quot;, &quot;lat_max&quot;).</p>
</td></tr>
<tr><td><code id="sits_cube_+3A_start_date">start_date</code>, <code id="sits_cube_+3A_end_date">end_date</code></td>
<td>
<p>Initial and final dates to include
images from the collection in the cube (optional).
(Date in YYYY-MM-DD format).</p>
</td></tr>
<tr><td><code id="sits_cube_+3A_platform">platform</code></td>
<td>
<p>Optional parameter specifying the platform in case
of collections that include more than one satellite
(character vector of length 1).</p>
</td></tr>
<tr><td><code id="sits_cube_+3A_progress">progress</code></td>
<td>
<p>Logical: show a progress bar?</p>
</td></tr>
<tr><td><code id="sits_cube_+3A_data_dir">data_dir</code></td>
<td>
<p>Local directory where images are stored
(for local cubes - character vector of length 1).</p>
</td></tr>
<tr><td><code id="sits_cube_+3A_vector_dir">vector_dir</code></td>
<td>
<p>Local director where vector files are stored
(for local vector cubes - character vector of length 1).</p>
</td></tr>
<tr><td><code id="sits_cube_+3A_vector_band">vector_band</code></td>
<td>
<p>Band for vector cube (&quot;segments&quot;, &quot;probs&quot;, &quot;class&quot;)</p>
</td></tr>
<tr><td><code id="sits_cube_+3A_labels">labels</code></td>
<td>
<p>Labels associated to the classes
(Named character vector for cubes of
classes &quot;probs_cube&quot; or &quot;class_cube&quot;).</p>
</td></tr>
<tr><td><code id="sits_cube_+3A_parse_info">parse_info</code></td>
<td>
<p>Parsing information for local files
(for local cubes - character vector).</p>
</td></tr>
<tr><td><code id="sits_cube_+3A_version">version</code></td>
<td>
<p>Version of the classified and/or labelled files.
(for local cubes - character vector of length 1).</p>
</td></tr>
<tr><td><code id="sits_cube_+3A_delim">delim</code></td>
<td>
<p>Delimiter for parsing local files
(single character)</p>
</td></tr>
<tr><td><code id="sits_cube_+3A_multicores">multicores</code></td>
<td>
<p>Number of workers for parallel processing
(integer, min = 1, max = 2048).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code>tibble</code> describing the contents of a data cube.
</p>


<h3>Note</h3>


<p>To create cubes from cloud providers, users need to inform:
</p>

<ol>
<li> <p><code>source</code>: One of &quot;AWS&quot;, &quot;BDC&quot;, &quot;DEAFRICA&quot;, &quot;HLS&quot;, &quot;MPC&quot;,
&quot;SDC&quot; or &quot;USGS&quot;;
</p>
</li>
<li> <p><code>collection</code>: Collection available in the cloud provider.
Use <code>sits_list_collections()</code> to see which
collections are supported;
</p>
</li>
<li> <p><code>tiles</code>: A set of tiles defined according to the collection
tiling grid;
</p>
</li>
<li> <p><code>roi</code>: Region of interest. Either
a named <code>vector</code> (<code>"lon_min"</code>, <code>"lat_min"</code>,
<code>"lon_max"</code>, <code>"lat_max"</code>) in WGS84, a <code>sfc</code>
or <code>sf</code> object from sf package in WGS84 projection.
</p>
</li></ol>

<p>Either <code>tiles</code> or  <code>roi</code> must be informed.
The parameters <code>bands</code>, <code>start_date</code>, and
<code>end_date</code> are optional for cubes created from cloud providers.
</p>
<p>GeoJSON geometries (RFC 7946) and shapefiles should be converted to
<code>sf</code> objects before being used to define a region of interest.
This parameter does not crop a region; it only selects images that
intersect the <code>roi</code>.
</p>
<p>To create a cube from local files, users need to inform:
</p>

<ol>
<li> <p><code>source</code>: Provider from where the data has been downloaded
(e.g, &quot;BDC&quot;);
</p>
</li>
<li> <p><code>collection</code>: Collection where the data has been extracted from.
(e.g., &quot;SENTINEL-2-L2A&quot; for the Sentinel-2 MPC collection level 2A);
</p>
</li>
<li> <p><code>data_dir</code>: Local directory where images are stored.
</p>
</li>
<li> <p><code>parse_info</code>: Parsing information for files.
Default is <code>c("X1", "X2", "tile", "band", "date")</code>.
</p>
</li>
<li> <p><code>delim</code>: Delimiter character for parsing files.
Default is <code>"_"</code>.
</p>
</li></ol>

<p>To create a cube from local files, all images should have
the same spatial resolution and projection and each file should contain
a single image band for a single date.
Files can belong to different tiles of a spatial reference system and
file names need to include tile, date, and band information.
For example: <code>"CBERS-4_WFI_022024_B13_2018-02-02.tif"</code>
and <code>"SENTINEL-2_MSI_20LKP_B02_2018-07-18.jp2"</code> are accepted names.
The user has to provide parsing information to allow <code>sits</code>
to extract values of tile, band, and date. In the examples above,
the parsing info is c(&quot;X1&quot;, &quot;X2&quot;, &quot;tile&quot;, &quot;band&quot;, &quot;date&quot;)
and the delimiter is &quot;_&quot;, which are the default values.
</p>
<p>It is also possible to create result cubes for these are local files
produced by classification or post-classification algorithms. In
this case, more parameters that are required (see below). The
parameter <code>parse_info</code> is specified differently, as follows:
</p>

<ol>
<li> <p><code>band</code>: Band name associated to the type of result. Use
<code>"probs"</code>, for probability cubes produced by <code>sits_classify()</code>;
<code>"bayes"</code>, for smoothed cubes produced by <code>sits_smooth()</code>;
<code>"segments"</code>, for vector cubes produced by <code>sits_segment()</code>;
<code>"entropy"</code> when using <code>sits_uncertainty()</code>, and <code>"class"</code>
for cubes produced by <code>sits_label_classification()</code>;
</p>
</li>
<li> <p><code>labels</code>: Labels associated to the classification results;
</p>
</li>
<li> <p><code>parse_info</code>: File name parsing information
to deduce the values of &quot;tile&quot;, &quot;start_date&quot;, &quot;end_date&quot; from
the file name. Default is c(&quot;X1&quot;, &quot;X2&quot;, &quot;tile&quot;, &quot;start_date&quot;,
&quot;end_date&quot;, &quot;band&quot;). Unlike non-classified image files,
cubes with results have both
&quot;start_date&quot; and &quot;end_date&quot;.
</p>
</li></ol>

<p>In MPC, sits can access are two open data collections:
<code>"SENTINEL-2-L2A"</code> for Sentinel-2/2A images, and
<code>"LANDSAT-C2-L2"</code> for the Landsat-4/5/7/8/9 collection.
(requester-pays) and <code>"SENTINEL-S2-L2A-COGS"</code> (open data).
</p>
<p>Sentinel-2/2A level 2A files in MPC are organized by sensor
resolution. The bands in 10m resolution are <code>"B02"</code>, <code>"B03"</code>,
<code>"B04"</code>, and <code>"B08"</code>. The  20m bands are <code>"B05"</code>,
<code>"B06"</code>, <code>"B07"</code>, <code>"B8A"</code>, <code>"B11"</code>, and <code>"B12"</code>.
Bands <code>"B01"</code> and <code>"B09"</code> are available at 60m resolution.
The <code>"CLOUD"</code> band is also available.
</p>
<p>All Landsat-4/5/7/8/9 images in MPC have bands with 30 meter
resolution. To account for differences between the different sensors,
Landsat bands in this collection have been renamed <code>"BLUE"</code>,
<code>"GREEN"</code>, <code>"RED"</code>, <code>"NIR08"</code>, <code>"SWIR16"</code>
and <code>"SWIR22"</code>. The <code>"CLOUD"</code> band is also available.
</p>
<p>In AWS, there are two types of collections: open data and
requester-pays. Currently, <code>sits</code> supports collection
<code>"SENTINEL-2-L2A"</code> (open data) and LANDSAT-C2-L2 (requester-pays).
There is no need to provide AWS credentials to access open data
collections. For requester-pays data, users need to provide their
access codes as environment variables, as follows:
<code>
Sys.setenv(
    AWS_ACCESS_KEY_ID     = &lt;your_access_key&gt;,
    AWS_SECRET_ACCESS_KEY = &lt;your_secret_access_key&gt;
)</code>
</p>
<p>Sentinel-2/2A level 2A files in AWS are organized by sensor
resolution. The AWS bands in 10m resolution are <code>"B02"</code>, <code>"B03"</code>,
<code>"B04"</code>, and <code>"B08"</code>. The  20m bands are <code>"B05"</code>,
<code>"B06"</code>, <code>"B07"</code>, <code>"B8A"</code>, <code>"B11"</code>, and <code>"B12"</code>.
Bands <code>"B01"</code> and <code>"B09"</code> are available at 60m resolution.
</p>
<p>For DEAFRICA, sits currently works with collections <code>"S2_L2A"</code>
for Sentinel-2 level 2A and <code>"LS8_SR"</code> for Landsat-8 ARD collection.
(open data). These collections are located in Africa
(Capetown) for faster access to African users. No payment for access
is required.
</p>
<p>For USGS, sits currently works with collection
<code>"LANDSAT-C2L2-SR"</code>, which corresponds to Landsat
Collection 2 Level-2 surface reflectance data, covering
Landsat-8 dataset. This collection is requester-pays and
requires payment for accessing.
</p>
<p>All BDC collections are regularized.
BDC users need to provide their credentials using environment
variables. To create your credentials, please see
&lt;brazil-data-cube.github.io/applications/dc_explorer/token-module.html&gt;.
Accessing data in the BDC is free.
After obtaining the BDC access key, please include it as
an environment variable, as follows:
<code>
Sys.setenv(
    BDC_ACCESS_KEY = &lt;your_bdc_access_key&gt;
)</code>

</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (sits_run_examples()) {
    # --- Access to the Brazil Data Cube
    # create a raster cube file based on the information in the BDC
    cbers_tile &lt;- sits_cube(
        source = "BDC",
        collection = "CBERS-WFI-16D",
        bands = c("NDVI", "EVI"),
        tiles = "007004",
        start_date = "2018-09-01",
        end_date = "2019-08-28"
    )
    # --- Access to Digital Earth Africa
    # create a raster cube file based on the information about the files
    # DEAFRICA does not support definition of tiles
    cube_dea &lt;- sits_cube(
        source = "DEAFRICA",
        collection = "S2_L2A",
        bands = c("B04", "B08"),
        roi = c(
            "lat_min" = 17.379,
            "lon_min" = 1.1573,
            "lat_max" = 17.410,
            "lon_max" = 1.1910
        ),
        start_date = "2019-01-01",
        end_date = "2019-10-28"
    )
    # --- Access to AWS open data Sentinel 2/2A level 2 collection
    s2_cube &lt;- sits_cube(
        source = "AWS",
        collection = "SENTINEL-S2-L2A-COGS",
        tiles = c("20LKP", "20LLP"),
        bands = c("B04", "B08", "B11"),
        start_date = "2018-07-18",
        end_date = "2019-07-23"
    )

    # -- Creating Sentinel cube from MPC
    s2_cube &lt;- sits_cube(
        source = "MPC",
        collection = "SENTINEL-2-L2A",
        tiles = "20LKP",
        bands = c("B05", "CLOUD"),
        start_date = "2018-07-18",
        end_date = "2018-08-23"
    )

    # -- Creating Landsat cube from MPC
    roi &lt;- c("lon_min" = -50.410, "lon_max" = -50.379,
             "lat_min" = -10.1910 , "lat_max" = -10.1573)
    mpc_cube &lt;- sits_cube(
        source = "MPC",
        collection = "LANDSAT-C2-L2",
        bands = c("BLUE", "RED", "CLOUD"),
        roi = roi,
        start_date = "2005-01-01",
        end_date = "2006-10-28"
    )

    ## Sentinel-1 SAR from MPC
    roi_sar &lt;- c("lon_min" = -50.410, "lon_max" = -50.379,
    "lat_min" = -10.1910, "lat_max" = -10.1573)

    s1_cube_open &lt;- sits_cube(
       source = "MPC",
       collection = "SENTINEL-1-GRD",
       bands = c("VV", "VH"),
       roi = roi_sar,
       start_date = "2020-06-01",
       end_date = "2020-09-28"
       )

    # --- Create a cube based on a local MODIS data
    data_dir &lt;- system.file("extdata/raster/mod13q1", package = "sits")
    modis_cube &lt;- sits_cube(
        source = "BDC",
        collection = "MOD13Q1-6",
        data_dir = data_dir
    )
}
</code></pre>

<hr>
<h2 id='sits_cube_copy'>Copy the images of a cube to a local directory</h2><span id='topic+sits_cube_copy'></span>

<h3>Description</h3>

<p>This function downloads the images of a cube in parallel.
A region of interest (<code>roi</code>) can be provided to crop
the images and a resolution (<code>res</code>) to resample the
bands.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sits_cube_copy(
  cube,
  roi = NULL,
  res = NULL,
  multicores = 2L,
  output_dir,
  progress = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sits_cube_copy_+3A_cube">cube</code></td>
<td>
<p>A data cube (class &quot;raster_cube&quot;)</p>
</td></tr>
<tr><td><code id="sits_cube_copy_+3A_roi">roi</code></td>
<td>
<p>Region of interest.
Either an sf_object, a shapefile,
or a bounding box vector with
named XY values (&quot;xmin&quot;, &quot;xmax&quot;, &quot;ymin&quot;, &quot;ymax&quot;) or
named lat/long values
(&quot;lon_min&quot;, &quot;lat_min&quot;, &quot;lon_max&quot;, &quot;lat_max&quot;).</p>
</td></tr>
<tr><td><code id="sits_cube_copy_+3A_res">res</code></td>
<td>
<p>An integer value corresponds to the output
spatial resolution of the images. Default is NULL.</p>
</td></tr>
<tr><td><code id="sits_cube_copy_+3A_multicores">multicores</code></td>
<td>
<p>Number of cores for parallel downloading
(integer, min = 1, max = 2048).</p>
</td></tr>
<tr><td><code id="sits_cube_copy_+3A_output_dir">output_dir</code></td>
<td>
<p>Output directory where images will be saved.
(character vector of length 1).</p>
</td></tr>
<tr><td><code id="sits_cube_copy_+3A_progress">progress</code></td>
<td>
<p>Logical: show progress bar?</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Copy of input data cube (class &quot;raster cube&quot;).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (sits_run_examples()) {
    # Creating a sits cube from BDC
    bdc_cube &lt;- sits_cube(
        source = "BDC",
        collection = "CBERS-WFI-16D",
        tiles = c("007004", "007005"),
        bands = c("B15", "CLOUD"),
        start_date = "2018-01-01",
        end_date = "2018-01-12"
    )
    # Downloading images to a temporary directory
    cube_local &lt;- sits_cube_copy(
        cube = bdc_cube,
        output_dir = tempdir(),
        roi = c(
            lon_min = -46.5,
            lat_min = -45.5,
            lon_max = -15.5,
            lat_max = -14.6
        ),
        multicores = 2L,
        res = 250,
    )
}

</code></pre>

<hr>
<h2 id='sits_factory_function'>Create a closure for calling functions with and without data</h2><span id='topic+sits_factory_function'></span>

<h3>Description</h3>

<p>This function implements the factory method pattern.
Its creates a generic interface to closures in R so that the functions
in the sits package can be called in two different ways:
1. Called directly, passing input data and parameters.
2. Called as second-order values (parameters of another function).
In the second case, the call will pass no data values
and only pass the parameters for execution
</p>
<p>The factory pattern is used in many situations in the sits package,
to allow different alternatives
for filtering, pattern creation, training, and cross-validation
</p>
<p>Please see the chapter &quot;Technical Annex&quot; in the sits book for details.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sits_factory_function(data, fun)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sits_factory_function_+3A_data">data</code></td>
<td>
<p>Input data.</p>
</td></tr>
<tr><td><code id="sits_factory_function_+3A_fun">fun</code></td>
<td>
<p>Function that performs calculation on the input data.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A closure that encapsulates the function applied to data.
</p>


<h3>Author(s)</h3>

<p>Rolf Simoes, <a href="mailto:rolf.simoes@inpe.br">rolf.simoes@inpe.br</a>
</p>
<p>Gilberto Camara, <a href="mailto:gilberto.camara@inpe.br">gilberto.camara@inpe.br</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># example code
if (sits_run_examples()) {
    # Include a new machine learning function (multiple linear regression)
    # function that returns mlr model based on a sits sample tibble

    sits_mlr &lt;- function(samples = NULL, formula = sits_formula_linear(),
                         n_weights = 20000, maxit = 2000) {
        train_fun &lt;- function(samples) {
            # Data normalization
            ml_stats &lt;- sits_stats(samples)
            train_samples &lt;- sits_predictors(samples)
            train_samples &lt;- sits_pred_normalize(
                pred = train_samples,
                stats = ml_stats
            )
            formula &lt;- formula(train_samples[, -1])
            # call method and return the trained model
            result_mlr &lt;- nnet::multinom(
                formula = formula,
                data = train_samples,
                maxit = maxit,
                MaxNWts = n_weights,
                trace = FALSE,
                na.action = stats::na.fail
            )

            # construct model predict closure function and returns
            predict_fun &lt;- function(values) {
                # retrieve the prediction (values and probs)
                prediction &lt;- tibble::as_tibble(
                    stats::predict(result_mlr,
                        newdata = values,
                        type = "probs"
                    )
                )
                return(prediction)
            }
            class(predict_fun) &lt;- c("sits_model", class(predict_fun))
            return(predict_fun)
        }
        result &lt;- sits_factory_function(samples, train_fun)
        return(result)
    }
    # create an mlr model using a set of samples
    mlr_model &lt;- sits_train(samples_modis_ndvi, sits_mlr)
    # classify a point
    point_ndvi &lt;- sits_select(point_mt_6bands, bands = "NDVI")
    point_class &lt;- sits_classify(point_ndvi, mlr_model, multicores = 1)
    plot(point_class)
}
</code></pre>

<hr>
<h2 id='sits_filter'>Filter time series with smoothing filter</h2><span id='topic+sits_filter'></span>

<h3>Description</h3>

<p>Applies a filter to all bands, using a filter function
such as sits_whittaker() or sits_sgolay().
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sits_filter(data, filter = sits_whittaker())
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sits_filter_+3A_data">data</code></td>
<td>
<p>Time series (tibble of class &quot;sits&quot;) or matrix.</p>
</td></tr>
<tr><td><code id="sits_filter_+3A_filter">filter</code></td>
<td>
<p>Filter function to be applied.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Filtered time series
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (sits_run_examples()) {
    # Retrieve a time series with values of NDVI
    point_ndvi &lt;- sits_select(point_mt_6bands, bands = "NDVI")
    # Filter the point using the Whittaker smoother
    point_whit &lt;- sits_filter(point_ndvi, sits_whittaker(lambda = 3.0))
    # Merge time series
    point_ndvi &lt;- sits_merge(point_ndvi, point_whit,
                             suffix = c("", ".WHIT"))
    # Plot the two points to see the smoothing effect
    plot(point_ndvi)
}
</code></pre>

<hr>
<h2 id='sits_formula_linear'>Define a linear formula for classification models</h2><span id='topic+sits_formula_linear'></span>

<h3>Description</h3>

<p>Provides a symbolic description of a fitting model.
Tells the model to do a linear transformation of the input values.
The 'predictors_index' parameter informs the positions of fields
corresponding to formula independent variables.
If no value is given,  that all fields will be used as predictors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sits_formula_linear(predictors_index = -2:0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sits_formula_linear_+3A_predictors_index">predictors_index</code></td>
<td>
<p>Index of the valid columns
whose names are used to compose formula (default: -2:0).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A function that computes a valid formula using a linear function.
</p>


<h3>Author(s)</h3>

<p>Gilberto Camara, <a href="mailto:gilberto.camara@inpe.br">gilberto.camara@inpe.br</a>
</p>
<p>Alexandre Ywata de Carvalho, <a href="mailto:alexandre.ywata@ipea.gov.br">alexandre.ywata@ipea.gov.br</a>
</p>
<p>Rolf Simoes, <a href="mailto:rolf.simoes@inpe.br">rolf.simoes@inpe.br</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (sits_run_examples()) {
    # Example of training a model for time series classification
    # Retrieve the samples for Mato Grosso
    # train an SVM model
    ml_model &lt;- sits_train(samples_modis_ndvi,
        ml_method = sits_svm(formula = sits_formula_logref())
    )
    # classify the point
    point_ndvi &lt;- sits_select(point_mt_6bands, bands = "NDVI")
    # classify the point
    point_class &lt;- sits_classify(
        data = point_ndvi, ml_model = ml_model
    )
    plot(point_class)
}
</code></pre>

<hr>
<h2 id='sits_formula_logref'>Define a loglinear formula for classification models</h2><span id='topic+sits_formula_logref'></span>

<h3>Description</h3>

<p>A function to be used as a symbolic description
of some fitting models such as svm and random forest.
This function tells the models to do a log transformation of the inputs.
The 'predictors_index' parameter informs
the positions of 'tb' fields corresponding to formula independent variables.
If no value is given, the default is NULL,
a value indicating that all fields will be used as predictors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sits_formula_logref(predictors_index = -2:0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sits_formula_logref_+3A_predictors_index">predictors_index</code></td>
<td>
<p>Index of the valid columns
to compose formula (default: -2:0).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A function that computes a valid formula using a log function.
</p>


<h3>Author(s)</h3>

<p>Alexandre Ywata de Carvalho, <a href="mailto:alexandre.ywata@ipea.gov.br">alexandre.ywata@ipea.gov.br</a>
</p>
<p>Rolf Simoes, <a href="mailto:rolf.simoes@inpe.br">rolf.simoes@inpe.br</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (sits_run_examples()) {
    # Example of training a model for time series classification
    # Retrieve the samples for Mato Grosso
    # train an SVM model
    ml_model &lt;- sits_train(samples_modis_ndvi,
        ml_method = sits_svm(formula = sits_formula_logref())
    )
    # classify the point
    point_ndvi &lt;- sits_select(point_mt_6bands, bands = "NDVI")
    # classify the point
    point_class &lt;- sits_classify(
        data = point_ndvi, ml_model = ml_model
    )
    plot(point_class)
}
</code></pre>

<hr>
<h2 id='sits_geo_dist'>Compute the minimum distances among samples and prediction points.</h2><span id='topic+sits_geo_dist'></span>

<h3>Description</h3>

<p>Compute the minimum distances among samples and samples to prediction
points, following the approach proposed by Meyer and Pebesma(2022).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sits_geo_dist(samples, roi, n = 1000L, crs = "EPSG:4326")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sits_geo_dist_+3A_samples">samples</code></td>
<td>
<p>Time series (tibble of class &quot;sits&quot;).</p>
</td></tr>
<tr><td><code id="sits_geo_dist_+3A_roi">roi</code></td>
<td>
<p>A region of interest (ROI), either a file containing a
shapefile or an &quot;sf&quot; object</p>
</td></tr>
<tr><td><code id="sits_geo_dist_+3A_n">n</code></td>
<td>
<p>Maximum number of samples to consider
(integer)</p>
</td></tr>
<tr><td><code id="sits_geo_dist_+3A_crs">crs</code></td>
<td>
<p>CRS of the <code>samples</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tibble with sample-to-sample and sample-to-prediction distances
(object of class &quot;distances&quot;).
</p>


<h3>Author(s)</h3>

<p>Alber Sanchez, <a href="mailto:alber.ipia@inpe.br">alber.ipia@inpe.br</a>
</p>
<p>Rolf Simoes, <a href="mailto:rolf.simoes@inpe.br">rolf.simoes@inpe.br</a>
</p>
<p>Felipe Carvalho, <a href="mailto:felipe.carvalho@inpe.br">felipe.carvalho@inpe.br</a>
</p>
<p>Gilberto Camara, <a href="mailto:gilberto.camara@inpe.br">gilberto.camara@inpe.br</a>
</p>


<h3>References</h3>

<p>Meyer, H., Pebesma, E. &quot;Machine learning-based global maps of
ecological variables and the challenge of assessing them&quot;,
Nature Communications 13, 2208 (2022).
https://doi.org/10.1038/s41467-022-29838-9
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (sits_run_examples()) {
    # read a shapefile for the state of Mato Grosso, Brazil
    mt_shp &lt;- system.file("extdata/shapefiles/mato_grosso/mt.shp",
        package = "sits"
    )
    # convert to an sf object
    mt_sf &lt;- sf::read_sf(mt_shp)
    # calculate sample-to-sample and sample-to-prediction distances
    distances &lt;- sits_geo_dist(
        samples = samples_modis_ndvi,
        roi = mt_sf
    )
    # plot sample-to-sample and sample-to-prediction distances
    plot(distances)
}
</code></pre>

<hr>
<h2 id='sits_get_data'>Get time series from data cubes and cloud services</h2><span id='topic+sits_get_data'></span><span id='topic+sits_get_data.default'></span><span id='topic+sits_get_data.csv'></span><span id='topic+sits_get_data.shp'></span><span id='topic+sits_get_data.sf'></span><span id='topic+sits_get_data.sits'></span><span id='topic+sits_get_data.data.frame'></span>

<h3>Description</h3>

<p>Retrieve a set of time series from a data cube or from
a time series service. Data cubes and puts it in a &quot;sits tibble&quot;.
Sits tibbles are the main structures of sits package.
They contain both the satellite image time series and their metadata.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sits_get_data(
  cube,
  samples,
  ...,
  start_date = NULL,
  end_date = NULL,
  label = "NoClass",
  bands = sits_bands(cube),
  crs = 4326L,
  label_attr = NULL,
  n_sam_pol = 30L,
  pol_avg = FALSE,
  pol_id = NULL,
  multicores = 2L,
  progress = TRUE
)

## Default S3 method:
sits_get_data(cube, samples, ...)

## S3 method for class 'csv'
sits_get_data(
  cube,
  samples,
  ...,
  bands = sits_bands(cube),
  crs = 4326L,
  multicores = 2,
  progress = FALSE
)

## S3 method for class 'shp'
sits_get_data(
  cube,
  samples,
  ...,
  label = "NoClass",
  start_date = NULL,
  end_date = NULL,
  bands = sits_bands(cube),
  label_attr = NULL,
  n_sam_pol = 30,
  pol_avg = FALSE,
  pol_id = NULL,
  multicores = 2,
  progress = FALSE
)

## S3 method for class 'sf'
sits_get_data(
  cube,
  samples,
  ...,
  start_date = NULL,
  end_date = NULL,
  bands = sits_bands(cube),
  label = "NoClass",
  label_attr = NULL,
  n_sam_pol = 30,
  pol_avg = FALSE,
  pol_id = NULL,
  multicores = 2,
  progress = FALSE
)

## S3 method for class 'sits'
sits_get_data(
  cube,
  samples,
  ...,
  bands = sits_bands(cube),
  multicores = 2,
  progress = FALSE
)

## S3 method for class 'data.frame'
sits_get_data(
  cube,
  samples,
  ...,
  start_date = NULL,
  end_date = NULL,
  bands = sits_bands(cube),
  label = "NoClass",
  crs = 4326,
  multicores = 2,
  progress = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sits_get_data_+3A_cube">cube</code></td>
<td>
<p>Data cube from where data is to be retrieved.
(tibble of class &quot;raster_cube&quot;).</p>
</td></tr>
<tr><td><code id="sits_get_data_+3A_samples">samples</code></td>
<td>
<p>Location of the samples to be retrieved.
Either a tibble of class &quot;sits&quot;, an &quot;sf&quot; object,
the name of a shapefile or csv file, or
a data.frame with columns &quot;longitude&quot; and &quot;latitude&quot;.</p>
</td></tr>
<tr><td><code id="sits_get_data_+3A_...">...</code></td>
<td>
<p>Specific parameters for specific cases.</p>
</td></tr>
<tr><td><code id="sits_get_data_+3A_start_date">start_date</code></td>
<td>
<p>Start of the interval for the time series - optional
(Date in &quot;YYYY-MM-DD&quot; format).</p>
</td></tr>
<tr><td><code id="sits_get_data_+3A_end_date">end_date</code></td>
<td>
<p>End of the interval for the time series - optional
(Date in &quot;YYYY-MM-DD&quot; format).</p>
</td></tr>
<tr><td><code id="sits_get_data_+3A_label">label</code></td>
<td>
<p>Label to be assigned to the time series (optional)
(character vector of length 1).</p>
</td></tr>
<tr><td><code id="sits_get_data_+3A_bands">bands</code></td>
<td>
<p>Bands to be retrieved - optional
(character vector).</p>
</td></tr>
<tr><td><code id="sits_get_data_+3A_crs">crs</code></td>
<td>
<p>Default crs for the samples
(character vector of length 1).</p>
</td></tr>
<tr><td><code id="sits_get_data_+3A_label_attr">label_attr</code></td>
<td>
<p>Attribute in the shapefile or sf object to be used
as a polygon label.
(character vector of length 1).</p>
</td></tr>
<tr><td><code id="sits_get_data_+3A_n_sam_pol">n_sam_pol</code></td>
<td>
<p>Number of samples per polygon to be read
for POLYGON or MULTIPOLYGON shapefiles or sf objects
(single integer).</p>
</td></tr>
<tr><td><code id="sits_get_data_+3A_pol_avg">pol_avg</code></td>
<td>
<p>Logical: summarize samples for each polygon?</p>
</td></tr>
<tr><td><code id="sits_get_data_+3A_pol_id">pol_id</code></td>
<td>
<p>ID attribute for polygons
(character vector of length 1)</p>
</td></tr>
<tr><td><code id="sits_get_data_+3A_multicores">multicores</code></td>
<td>
<p>Number of threads to process the time series
(integer, with min = 1 and max = 2048).</p>
</td></tr>
<tr><td><code id="sits_get_data_+3A_progress">progress</code></td>
<td>
<p>Logical: show progress bar?</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tibble of class &quot;sits&quot; with set of time series
&lt;longitude, latitude, start_date, end_date, label, cube, time_series&gt;.
</p>


<h3>Note</h3>

<p>There are four ways of specifying data to be retrieved using the
<code>samples</code> parameter:
(a) CSV file: a CSV file with columns
<code>longitude</code>, <code>latitude</code>,
<code>start_date</code>, <code>end_date</code> and <code>label</code> for each sample;
(b) SHP file: a shapefile in POINT or POLYGON geometry
containing the location of the samples and an attribute to be
used as label. Also, provide start and end date for the time series;
(c) sits object: A sits tibble;
(d) sf object: An <code>link[sf]{sf}</code> object with POINT or POLYGON geometry;
(e) data.frame: A data.frame with with mandatory columns
<code>longitude</code> and <code>latitude</code>.
</p>


<h3>Author(s)</h3>

<p>Gilberto Camara
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (sits_run_examples()) {
    # reading a lat/long from a local cube
    # create a cube from local files
    data_dir &lt;- system.file("extdata/raster/mod13q1", package = "sits")
    raster_cube &lt;- sits_cube(
        source = "BDC",
        collection = "MOD13Q1-6",
        data_dir = data_dir
    )
    samples &lt;- tibble::tibble(longitude = -55.66738, latitude = -11.76990)
    point_ndvi &lt;- sits_get_data(raster_cube, samples)
    #
    # reading samples from a cube based on a  CSV file
    csv_file &lt;- system.file("extdata/samples/samples_sinop_crop.csv",
        package = "sits"
    )
    points &lt;- sits_get_data(cube = raster_cube, samples = csv_file)

    # reading a shapefile from BDC (Brazil Data Cube)
    bdc_cube &lt;- sits_cube(
            source = "BDC",
            collection = "CBERS-WFI-16D",
            bands = c("NDVI", "EVI"),
            tiles = c("007004", "007005"),
            start_date = "2018-09-01",
            end_date = "2018-10-28"
    )
    # define a shapefile to be read from the cube
    shp_file &lt;- system.file("extdata/shapefiles/bdc-test/samples.shp",
            package = "sits"
    )
    # get samples from the BDC based on the shapefile
    time_series_bdc &lt;- sits_get_data(
        cube = bdc_cube,
        samples = shp_file
    )
}

</code></pre>

<hr>
<h2 id='sits_kfold_validate'>Cross-validate time series samples</h2><span id='topic+sits_kfold_validate'></span>

<h3>Description</h3>

<p>Splits the set of time series into training and validation and
perform k-fold cross-validation.
Cross-validation is a technique for assessing how the results
of a statistical analysis will generalize to an independent data set.
It is mainly used in settings where the goal is prediction,
and one wants to estimate how accurately a predictive model will perform.
One round of cross-validation involves partitioning a sample of data
into complementary subsets, performing the analysis on one subset
(called the training set), and validating the analysis on the other subset
(called the validation set or testing set).
</p>
<p>The k-fold cross validation method involves splitting the dataset
into k-subsets. For each subset is held out while the model is trained
on all other subsets. This process is completed until accuracy
is determine for each instance in the dataset, and an overall
accuracy estimate is provided.
</p>
<p>This function returns the confusion matrix, and Kappa values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sits_kfold_validate(
  samples,
  folds = 5,
  ml_method = sits_rfor(),
  multicores = 2
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sits_kfold_validate_+3A_samples">samples</code></td>
<td>
<p>Time series.</p>
</td></tr>
<tr><td><code id="sits_kfold_validate_+3A_folds">folds</code></td>
<td>
<p>Number of partitions to create.</p>
</td></tr>
<tr><td><code id="sits_kfold_validate_+3A_ml_method">ml_method</code></td>
<td>
<p>Machine learning method.</p>
</td></tr>
<tr><td><code id="sits_kfold_validate_+3A_multicores">multicores</code></td>
<td>
<p>Number of cores to process in parallel.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code>caret::confusionMatrix</code> object to be used for
validation assessment.
</p>


<h3>Note</h3>

<p>Please refer to the sits documentation available in
&lt;https://e-sensing.github.io/sitsbook/&gt; for detailed examples.
</p>


<h3>Author(s)</h3>

<p>Rolf Simoes, <a href="mailto:rolf.simoes@inpe.br">rolf.simoes@inpe.br</a>
</p>
<p>Gilberto Camara, <a href="mailto:gilberto.camara@inpe.br">gilberto.camara@inpe.br</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (sits_run_examples()) {
    # A dataset containing a tibble with time series samples
    # for the Mato Grosso state in Brasil
    # create a list to store the results
    results &lt;- list()
    # accuracy assessment lightTAE
    acc_rfor &lt;- sits_kfold_validate(
        samples_modis_ndvi,
        folds = 5,
        ml_method = sits_rfor()
    )
    # use a name
    acc_rfor$name &lt;- "Rfor"
    # put the result in a list
    results[[length(results) + 1]] &lt;- acc_rfor
    # save to xlsx file
    sits_to_xlsx(
        results,
        file = tempfile("accuracy_mato_grosso_dl_", fileext = ".xlsx")
    )
}

</code></pre>

<hr>
<h2 id='sits_label_classification'>Build a labelled image from a probability cube</h2><span id='topic+sits_label_classification'></span><span id='topic+sits_label_classification.probs_cube'></span><span id='topic+sits_label_classification.probs_vector_cube'></span><span id='topic+sits_label_classification.raster_cube'></span><span id='topic+sits_label_classification.derived_cube'></span><span id='topic+sits_label_classification.tbl_df'></span><span id='topic+sits_label_classification.default'></span>

<h3>Description</h3>

<p>Takes a set of classified raster layers with probabilities,
and label them based on the maximum probability for each pixel.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sits_label_classification(
  cube,
  clean = TRUE,
  window_size = 3L,
  memsize = 4,
  multicores = 2,
  output_dir,
  version = "v1",
  progress = TRUE
)

## S3 method for class 'probs_cube'
sits_label_classification(
  cube,
  ...,
  clean = TRUE,
  window_size = 3L,
  memsize = 4L,
  multicores = 2L,
  output_dir,
  version = "v1",
  progress = TRUE
)

## S3 method for class 'probs_vector_cube'
sits_label_classification(
  cube,
  ...,
  output_dir,
  version = "v1",
  progress = TRUE
)

## S3 method for class 'raster_cube'
sits_label_classification(cube, ...)

## S3 method for class 'derived_cube'
sits_label_classification(cube, ...)

## S3 method for class 'tbl_df'
sits_label_classification(cube, ...)

## Default S3 method:
sits_label_classification(cube, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sits_label_classification_+3A_cube">cube</code></td>
<td>
<p>Classified image data cube.</p>
</td></tr>
<tr><td><code id="sits_label_classification_+3A_clean">clean</code></td>
<td>
<p>A logical value to apply a modal function to clean up
possible noisy pixels keeping the most frequently
values within the neighborhood. Default is TRUE.</p>
</td></tr>
<tr><td><code id="sits_label_classification_+3A_window_size">window_size</code></td>
<td>
<p>An odd integer representing the size of the
sliding window of the modal function (min = 1, max = 15).</p>
</td></tr>
<tr><td><code id="sits_label_classification_+3A_memsize">memsize</code></td>
<td>
<p>maximum overall memory (in GB) to label the
classification.</p>
</td></tr>
<tr><td><code id="sits_label_classification_+3A_multicores">multicores</code></td>
<td>
<p>Number of workers to label the classification in
parallel.</p>
</td></tr>
<tr><td><code id="sits_label_classification_+3A_output_dir">output_dir</code></td>
<td>
<p>Output directory for classified files.</p>
</td></tr>
<tr><td><code id="sits_label_classification_+3A_version">version</code></td>
<td>
<p>Version of resulting image
(in the case of multiple runs).</p>
</td></tr>
<tr><td><code id="sits_label_classification_+3A_progress">progress</code></td>
<td>
<p>Show progress bar?</p>
</td></tr>
<tr><td><code id="sits_label_classification_+3A_...">...</code></td>
<td>
<p>Other parameters for specific functions.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data cube with an image with the classified map.
</p>


<h3>Note</h3>

<p>Please refer to the sits documentation available in
&lt;https://e-sensing.github.io/sitsbook/&gt; for detailed examples.
</p>


<h3>Author(s)</h3>

<p>Rolf Simoes, <a href="mailto:rolf.simoes@inpe.br">rolf.simoes@inpe.br</a>
</p>
<p>Felipe Souza, <a href="mailto:felipe.souza@inpe.br">felipe.souza@inpe.br</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (sits_run_examples()) {
    # create a random forest model
    rfor_model &lt;- sits_train(samples_modis_ndvi, sits_rfor())
    # create a data cube from local files
    data_dir &lt;- system.file("extdata/raster/mod13q1", package = "sits")
    cube &lt;- sits_cube(
        source = "BDC",
        collection = "MOD13Q1-6",
        data_dir = data_dir
    )
    # classify a data cube
    probs_cube &lt;- sits_classify(
        data = cube, ml_model = rfor_model, output_dir = tempdir()
    )
    # plot the probability cube
    plot(probs_cube)
    # smooth the probability cube using Bayesian statistics
    bayes_cube &lt;- sits_smooth(probs_cube, output_dir = tempdir())
    # plot the smoothed cube
    plot(bayes_cube)
    # label the probability cube
    label_cube &lt;- sits_label_classification(
        bayes_cube,
        output_dir = tempdir()
    )
    # plot the labelled cube
    plot(label_cube)
}
</code></pre>

<hr>
<h2 id='sits_labels'>Get labels associated to a data set</h2><span id='topic+sits_labels'></span><span id='topic+sits_labels.sits'></span><span id='topic+sits_labels.derived_cube'></span><span id='topic+sits_labels.derived_vector_cube'></span><span id='topic+sits_labels.raster_cube'></span><span id='topic+sits_labels.patterns'></span><span id='topic+sits_labels.sits_model'></span><span id='topic+sits_labels.tbl_df'></span><span id='topic+sits_labels.default'></span><span id='topic+sits_labels+3C-.tbl_df'></span>

<h3>Description</h3>

<p>Finds labels in a sits tibble or data cube
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sits_labels(data)

## S3 method for class 'sits'
sits_labels(data)

## S3 method for class 'derived_cube'
sits_labels(data)

## S3 method for class 'derived_vector_cube'
sits_labels(data)

## S3 method for class 'raster_cube'
sits_labels(data)

## S3 method for class 'patterns'
sits_labels(data)

## S3 method for class 'sits_model'
sits_labels(data)

## S3 method for class 'tbl_df'
sits_labels(data)

## Default S3 method:
sits_labels(data)

## S3 replacement method for class 'tbl_df'
sits_labels(data) &lt;- value
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sits_labels_+3A_data">data</code></td>
<td>
<p>Time series (tibble of class &quot;sits&quot;),
patterns (tibble of class &quot;patterns&quot;),
data cube (tibble of class &quot;raster_cube&quot;), or
model (closure of class &quot;sits_model&quot;).</p>
</td></tr>
<tr><td><code id="sits_labels_+3A_value">value</code></td>
<td>
<p>A character vector used to convert labels. Labels will
be renamed to the respective value positioned at the
labels order returned by <code><a href="#topic+sits_labels">sits_labels</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The labels of the input data (character vector).
</p>


<h3>Author(s)</h3>

<p>Rolf Simoes, <a href="mailto:rolf.simoes@inpe.br">rolf.simoes@inpe.br</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (sits_run_examples()) {
    # get the labels for a time series set
    labels_ts &lt;- sits_labels(samples_modis_ndvi)
    # get labels for a set of patterns
    labels_pat &lt;- sits_labels(sits_patterns(samples_modis_ndvi))
    # create a random forest model
    rfor_model &lt;- sits_train(samples_modis_ndvi, sits_rfor())
    # get lables for the model
    labels_mod &lt;- sits_labels(rfor_model)
    # create a data cube from local files
    data_dir &lt;- system.file("extdata/raster/mod13q1", package = "sits")
    cube &lt;- sits_cube(
        source = "BDC",
        collection = "MOD13Q1-6",
        data_dir = data_dir
    )
    # classify a data cube
    probs_cube &lt;- sits_classify(
        data = cube, ml_model = rfor_model, output_dir = tempdir()
    )
    # get the labels for a probs cube
    labels_probs &lt;- sits_labels(probs_cube)
}
</code></pre>

<hr>
<h2 id='sits_labels_summary'>Inform label distribution of a set of time series</h2><span id='topic+sits_labels_summary'></span><span id='topic+sits_labels_summary.sits'></span>

<h3>Description</h3>

<p>Describes labels in a sits tibble
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sits_labels_summary(data)

## S3 method for class 'sits'
sits_labels_summary(data)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sits_labels_summary_+3A_data">data</code></td>
<td>
<p>Data.frame - Valid sits tibble</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tibble with the frequency of each label.
</p>


<h3>Author(s)</h3>

<p>Rolf Simoes, <a href="mailto:rolf.simoes@inpe.br">rolf.simoes@inpe.br</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># read a tibble with 400 samples of Cerrado and 346 samples of Pasture
data(cerrado_2classes)
# print the labels
sits_labels_summary(cerrado_2classes)
</code></pre>

<hr>
<h2 id='sits_lighttae'>Train a model using Lightweight Temporal Self-Attention Encoder</h2><span id='topic+sits_lighttae'></span>

<h3>Description</h3>

<p>Implementation of Light Temporal Attention Encoder (L-TAE)
for satellite image time series
</p>
<p>This function is based on the paper by Vivien Garnot referenced below
and code available on github at
https://github.com/VSainteuf/lightweight-temporal-attention-pytorch
If you use this method, please cite the original TAE and the LTAE paper.
</p>
<p>We also used the code made available by Maja Schneider in her work with
Marco Körner referenced below and available at
https://github.com/maja601/RC2020-psetae.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sits_lighttae(
  samples = NULL,
  samples_validation = NULL,
  epochs = 150L,
  batch_size = 128L,
  validation_split = 0.2,
  optimizer = torch::optim_adamw,
  opt_hparams = list(lr = 0.005, eps = 1e-08, weight_decay = 1e-06),
  lr_decay_epochs = 50L,
  lr_decay_rate = 1,
  patience = 20L,
  min_delta = 0.01,
  verbose = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sits_lighttae_+3A_samples">samples</code></td>
<td>
<p>Time series with the training samples
(tibble of class &quot;sits&quot;).</p>
</td></tr>
<tr><td><code id="sits_lighttae_+3A_samples_validation">samples_validation</code></td>
<td>
<p>Time series with the validation samples
(tibble of class &quot;sits&quot;).
If <code>samples_validation</code> parameter is provided,
<code>validation_split</code> is ignored.</p>
</td></tr>
<tr><td><code id="sits_lighttae_+3A_epochs">epochs</code></td>
<td>
<p>Number of iterations to train the model
(integer, min = 1, max = 20000).</p>
</td></tr>
<tr><td><code id="sits_lighttae_+3A_batch_size">batch_size</code></td>
<td>
<p>Number of samples per gradient update
(integer, min = 16L, max = 2048L)</p>
</td></tr>
<tr><td><code id="sits_lighttae_+3A_validation_split">validation_split</code></td>
<td>
<p>Fraction of training data
to be used as validation data.</p>
</td></tr>
<tr><td><code id="sits_lighttae_+3A_optimizer">optimizer</code></td>
<td>
<p>Optimizer function to be used.</p>
</td></tr>
<tr><td><code id="sits_lighttae_+3A_opt_hparams">opt_hparams</code></td>
<td>
<p>Hyperparameters for optimizer:
<code>lr</code> : Learning rate of the optimizer
<code>eps</code>: Term added to the denominator
to improve numerical stability.
<code>weight_decay</code>:       L2 regularization rate.</p>
</td></tr>
<tr><td><code id="sits_lighttae_+3A_lr_decay_epochs">lr_decay_epochs</code></td>
<td>
<p>Number of epochs to reduce learning rate.</p>
</td></tr>
<tr><td><code id="sits_lighttae_+3A_lr_decay_rate">lr_decay_rate</code></td>
<td>
<p>Decay factor for reducing learning rate.</p>
</td></tr>
<tr><td><code id="sits_lighttae_+3A_patience">patience</code></td>
<td>
<p>Number of epochs without improvements until
training stops.</p>
</td></tr>
<tr><td><code id="sits_lighttae_+3A_min_delta">min_delta</code></td>
<td>
<p>Minimum improvement in loss function
to reset the patience counter.</p>
</td></tr>
<tr><td><code id="sits_lighttae_+3A_verbose">verbose</code></td>
<td>
<p>Verbosity mode (TRUE/FALSE). Default is FALSE.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A fitted model to be used for classification of data cubes.
</p>


<h3>Author(s)</h3>

<p>Gilberto Camara, <a href="mailto:gilberto.camara@inpe.br">gilberto.camara@inpe.br</a>
</p>
<p>Rolf Simoes, <a href="mailto:rolf.simoes@inpe.br">rolf.simoes@inpe.br</a>
</p>
<p>Charlotte Pelletier, <a href="mailto:charlotte.pelletier@univ-ubs.fr">charlotte.pelletier@univ-ubs.fr</a>
</p>


<h3>References</h3>

<p>Vivien Garnot, Loic Landrieu, Sebastien Giordano, and Nesrine Chehata,
&quot;Satellite Image Time Series Classification with Pixel-Set Encoders
and Temporal Self-Attention&quot;,
2020 Conference on Computer Vision and Pattern Recognition.
pages 12322-12331.
DOI: 10.1109/CVPR42600.2020.01234
</p>
<p>Vivien Garnot, Loic Landrieu,
&quot;Lightweight Temporal Self-Attention  for Classifying
Satellite Images Time Series&quot;,
arXiv preprint arXiv:2007.00586, 2020.
</p>
<p>Schneider, Maja; Körner, Marco,
&quot;[Re] Satellite Image Time Series Classification
with Pixel-Set Encoders and Temporal Self-Attention.&quot;
ReScience C 7 (2), 2021.
DOI: 10.5281/zenodo.4835356
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (sits_run_examples()) {
    # create a lightTAE model
    torch_model &lt;- sits_train(samples_modis_ndvi, sits_lighttae())
    # plot the model
    plot(torch_model)
    # create a data cube from local files
    data_dir &lt;- system.file("extdata/raster/mod13q1", package = "sits")
    cube &lt;- sits_cube(
        source = "BDC",
        collection = "MOD13Q1-6",
        data_dir = data_dir
    )
    # classify a data cube
    probs_cube &lt;- sits_classify(
        data = cube, ml_model = torch_model, output_dir = tempdir()
    )
    # plot the probability cube
    plot(probs_cube)
    # smooth the probability cube using Bayesian statistics
    bayes_cube &lt;- sits_smooth(probs_cube, output_dir = tempdir())
    # plot the smoothed cube
    plot(bayes_cube)
    # label the probability cube
    label_cube &lt;- sits_label_classification(
        bayes_cube,
        output_dir = tempdir()
    )
    # plot the labelled cube
    plot(label_cube)
}
</code></pre>

<hr>
<h2 id='sits_list_collections'>List the cloud collections supported by sits</h2><span id='topic+sits_list_collections'></span>

<h3>Description</h3>

<p>Prints the collections available
in each cloud service supported by sits.
Users can select to get information
only for a single service by using the <code>source</code> parameter.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sits_list_collections(source = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sits_list_collections_+3A_source">source</code></td>
<td>
<p>Data source to be shown in detail.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Prints collections available in
each cloud service supported by sits.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (sits_run_examples()) {
    # show the names of the colors supported by SITS
    sits_list_collections()
}
</code></pre>

<hr>
<h2 id='sits_merge'>Merge two data sets (time series or cubes)</h2><span id='topic+sits_merge'></span><span id='topic+sits_merge.sits'></span><span id='topic+sits_merge.raster_cube'></span><span id='topic+sits_merge.default'></span>

<h3>Description</h3>

<p>To merge two series, we consider that they contain different
attributes but refer to the same data cube, and spatiotemporal location.
This function is useful to merge different bands of the same locations.
For example, one may want to put the raw and smoothed bands
for the same set of locations in the same tibble.
</p>
<p>To merge data cubes, they should share the same sensor, resolution,
bounding box, timeline, and have different bands.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sits_merge(data1, data2, ...)

## S3 method for class 'sits'
sits_merge(data1, data2, ..., suffix = c(".1", ".2"))

## S3 method for class 'raster_cube'
sits_merge(data1, data2, ...)

## Default S3 method:
sits_merge(data1, data2, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sits_merge_+3A_data1">data1</code></td>
<td>
<p>Time series (tibble of class &quot;sits&quot;)
or data cube (tibble of class &quot;raster_cube&quot;) .</p>
</td></tr>
<tr><td><code id="sits_merge_+3A_data2">data2</code></td>
<td>
<p>Time series (tibble of class &quot;sits&quot;)
or data cube (tibble of class &quot;raster_cube&quot;) .</p>
</td></tr>
<tr><td><code id="sits_merge_+3A_...">...</code></td>
<td>
<p>Additional parameters</p>
</td></tr>
<tr><td><code id="sits_merge_+3A_suffix">suffix</code></td>
<td>
<p>If there are duplicate bands in data1 and data2
these suffixes will be added
(character vector).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>merged data sets (tibble of class &quot;sits&quot; or
tibble of class &quot;raster_cube&quot;)
</p>


<h3>Author(s)</h3>

<p>Gilberto Camara, <a href="mailto:gilberto.camara@inpe.br">gilberto.camara@inpe.br</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (sits_run_examples()) {
    # Retrieve a time series with values of NDVI
    point_ndvi &lt;- sits_select(point_mt_6bands, bands = "NDVI")

    # Filter the point using the Whittaker smoother
    point_whit &lt;- sits_filter(point_ndvi, sits_whittaker(lambda = 3.0))
    # Merge time series
    point_ndvi &lt;- sits_merge(point_ndvi, point_whit, suffix = c("", ".WHIT"))

    # Plot the two points to see the smoothing effect
    plot(point_ndvi)
}
</code></pre>

<hr>
<h2 id='sits_mixture_model'>Multiple endmember spectral mixture analysis</h2><span id='topic+sits_mixture_model'></span><span id='topic+sits_mixture_model.sits'></span><span id='topic+sits_mixture_model.raster_cube'></span><span id='topic+sits_mixture_model.derived_cube'></span><span id='topic+sits_mixture_model.tbl_df'></span><span id='topic+sits_mixture_model.default'></span>

<h3>Description</h3>

<p>Create a multiple endmember spectral mixture analyses fractions
images. We use the non-negative least squares (NNLS) solver to calculate the
fractions of each endmember. The NNLS was implemented by Jakob
Schwalb-Willmann in RStoolbox package (licensed as GPL&gt;=3).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sits_mixture_model(
  data,
  endmembers,
  ...,
  rmse_band = TRUE,
  multicores = 2,
  progress = TRUE
)

## S3 method for class 'sits'
sits_mixture_model(
  data,
  endmembers,
  ...,
  rmse_band = TRUE,
  multicores = 2,
  progress = TRUE
)

## S3 method for class 'raster_cube'
sits_mixture_model(
  data,
  endmembers,
  ...,
  rmse_band = TRUE,
  memsize = 4,
  multicores = 2,
  output_dir,
  progress = TRUE
)

## S3 method for class 'derived_cube'
sits_mixture_model(data, endmembers, ...)

## S3 method for class 'tbl_df'
sits_mixture_model(data, endmembers, ...)

## Default S3 method:
sits_mixture_model(data, endmembers, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sits_mixture_model_+3A_data">data</code></td>
<td>
<p>A sits data cube or a sits tibble.</p>
</td></tr>
<tr><td><code id="sits_mixture_model_+3A_endmembers">endmembers</code></td>
<td>
<p>Reference spectral endmembers.
(see details below).</p>
</td></tr>
<tr><td><code id="sits_mixture_model_+3A_...">...</code></td>
<td>
<p>Parameters for specific functions.</p>
</td></tr>
<tr><td><code id="sits_mixture_model_+3A_rmse_band">rmse_band</code></td>
<td>
<p>A boolean indicating whether the error associated
with the linear model should be generated.
If true, a new band with errors for each pixel
is generated using the root mean square
measure (RMSE). Default is TRUE.</p>
</td></tr>
<tr><td><code id="sits_mixture_model_+3A_multicores">multicores</code></td>
<td>
<p>Number of cores to be used for generate the
mixture model.</p>
</td></tr>
<tr><td><code id="sits_mixture_model_+3A_progress">progress</code></td>
<td>
<p>Show progress bar? Default is TRUE.</p>
</td></tr>
<tr><td><code id="sits_mixture_model_+3A_memsize">memsize</code></td>
<td>
<p>Memory available for the mixture model (in GB).</p>
</td></tr>
<tr><td><code id="sits_mixture_model_+3A_output_dir">output_dir</code></td>
<td>
<p>Directory for output images.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>endmembers</code> parameter should be a tibble, csv or
a shapefile. <code>endmembers</code> parameter must have the following columns:
<code>type</code>, which defines the endmembers that will be
created and the columns corresponding to the bands that will be used in the
mixture model. The band values must follow the product scale.
For example, in the case of sentinel-2 images the bands should be in the
range 0 to 1. See the <code>example</code> in this documentation for more details.
</p>


<h3>Value</h3>

<p>In case of a cube, a sits cube with the fractions of each endmember
will be returned. The sum of all fractions is restricted
to 1 (scaled from 0 to 10000), corresponding to the abundance of
the endmembers in the pixels.
In case of a tibble sits, the time series will be returned with the
values corresponding to each fraction.
</p>


<h3>Author(s)</h3>

<p>Felipe Carvalho, <a href="mailto:felipe.carvalho@inpe.br">felipe.carvalho@inpe.br</a>
</p>
<p>Felipe Carlos,   <a href="mailto:efelipecarlos@gmail.com">efelipecarlos@gmail.com</a>
</p>
<p>Rolf Simoes,     <a href="mailto:rolf.simoes@inpe.br">rolf.simoes@inpe.br</a>
</p>
<p>Gilberto Camara, <a href="mailto:gilberto.camara@inpe.br">gilberto.camara@inpe.br</a>
</p>
<p>Alber Sanchez,   <a href="mailto:alber.ipia@inpe.br">alber.ipia@inpe.br</a>
</p>


<h3>References</h3>

<p><code>RStoolbox</code> package (https://github.com/bleutner/RStoolbox/)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (sits_run_examples()) {
    # Create a sentinel-2 cube
    s2_cube &lt;- sits_cube(
        source = "AWS",
        collection = "SENTINEL-2-L2A",
        tiles = "20LKP",
        bands = c("B02", "B03", "B04", "B8A", "B11", "B12", "CLOUD"),
        start_date = "2019-06-13",
        end_date = "2019-06-30"
    )
    # create a directory to store the regularized file
    reg_dir &lt;- paste0(tempdir(), "/mix_model")
    dir.create(reg_dir)
    # Cube regularization for 16 days and 160 meters
    reg_cube &lt;- sits_regularize(
        cube = s2_cube,
        period = "P16D",
        res = 160,
        roi = c(
            lon_min = -65.54870165,
            lat_min = -10.63479162,
            lon_max = -65.07629670,
            lat_max = -10.36046639
        ),
        multicores = 2,
        output_dir = reg_dir
    )

    # Create the endmembers tibble
    em &lt;- tibble::tribble(
        ~class, ~B02, ~B03, ~B04, ~B8A, ~B11, ~B12,
        "forest", 0.02, 0.0352, 0.0189, 0.28, 0.134, 0.0546,
        "land", 0.04, 0.065, 0.07, 0.36, 0.35, 0.18,
        "water", 0.07, 0.11, 0.14, 0.085, 0.004, 0.0026
    )

    # Generate the mixture model
    mm &lt;- sits_mixture_model(
        data = reg_cube,
        endmembers = em,
        memsize = 4,
        multicores = 2,
        output_dir = tempdir()
    )
}

</code></pre>

<hr>
<h2 id='sits_mlp'>Train multi-layer perceptron models using torch</h2><span id='topic+sits_mlp'></span>

<h3>Description</h3>

<p>Use a multi-layer perceptron algorithm to classify data.
This function uses the R &quot;torch&quot; and &quot;luz&quot; packages.
Please refer to the documentation of those package for more details.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sits_mlp(
  samples = NULL,
  samples_validation = NULL,
  layers = c(512, 512, 512),
  dropout_rates = c(0.2, 0.3, 0.4),
  optimizer = torchopt::optim_adamw,
  opt_hparams = list(lr = 0.001, eps = 1e-08, weight_decay = 1e-06),
  epochs = 100,
  batch_size = 64,
  validation_split = 0.2,
  patience = 20,
  min_delta = 0.01,
  verbose = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sits_mlp_+3A_samples">samples</code></td>
<td>
<p>Time series with the training samples.</p>
</td></tr>
<tr><td><code id="sits_mlp_+3A_samples_validation">samples_validation</code></td>
<td>
<p>Time series with the validation samples. if the
<code>samples_validation</code> parameter is provided,
the <code>validation_split</code> parameter is ignored.</p>
</td></tr>
<tr><td><code id="sits_mlp_+3A_layers">layers</code></td>
<td>
<p>Vector with number of hidden nodes in each layer.</p>
</td></tr>
<tr><td><code id="sits_mlp_+3A_dropout_rates">dropout_rates</code></td>
<td>
<p>Vector with the dropout rates (0,1)
for each layer.</p>
</td></tr>
<tr><td><code id="sits_mlp_+3A_optimizer">optimizer</code></td>
<td>
<p>Optimizer function to be used.</p>
</td></tr>
<tr><td><code id="sits_mlp_+3A_opt_hparams">opt_hparams</code></td>
<td>
<p>Hyperparameters for optimizer:
lr : Learning rate of the optimizer
eps: Term added to the denominator
to improve numerical stability..
weight_decay:       L2 regularization</p>
</td></tr>
<tr><td><code id="sits_mlp_+3A_epochs">epochs</code></td>
<td>
<p>Number of iterations to train the model.</p>
</td></tr>
<tr><td><code id="sits_mlp_+3A_batch_size">batch_size</code></td>
<td>
<p>Number of samples per gradient update.</p>
</td></tr>
<tr><td><code id="sits_mlp_+3A_validation_split">validation_split</code></td>
<td>
<p>Number between 0 and 1.
Fraction of the training data for validation.
The model will set apart this fraction
and will evaluate the loss and any model metrics
on this data at the end of each epoch.</p>
</td></tr>
<tr><td><code id="sits_mlp_+3A_patience">patience</code></td>
<td>
<p>Number of epochs without improvements until
training stops.</p>
</td></tr>
<tr><td><code id="sits_mlp_+3A_min_delta">min_delta</code></td>
<td>
<p>Minimum improvement in loss function
to reset the patience counter.</p>
</td></tr>
<tr><td><code id="sits_mlp_+3A_verbose">verbose</code></td>
<td>
<p>Verbosity mode (TRUE/FALSE). Default is FALSE.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A torch mlp model to be used for classification.
</p>


<h3>Note</h3>

<p>The default parameters for the MLP have been chosen based on the work by
Wang et al. 2017 that takes multilayer perceptrons as the baseline
for time series classifications:
(a) Three layers with 512 neurons each, specified by the parameter 'layers';
(b) dropout rates of 10
(c) the &quot;optimizer_adam&quot; as optimizer (default value);
(d) a number of training steps ('epochs') of 100;
(e) a 'batch_size' of 64, which indicates how many time series
are used for input at a given steps;
(f) a validation percentage of 20
will be randomly set side for validation.
(g) The &quot;relu&quot; activation function.
</p>


<h3>Author(s)</h3>

<p>Gilberto Camara, <a href="mailto:gilberto.camara@inpe.br">gilberto.camara@inpe.br</a>
</p>


<h3>References</h3>

<p>Zhiguang Wang, Weizhong Yan, and Tim Oates,
&quot;Time series classification from scratch with deep neural networks:
A strong baseline&quot;,
2017 international joint conference on neural networks (IJCNN).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (sits_run_examples()) {
    # create an MLP model
    torch_model &lt;- sits_train(samples_modis_ndvi, sits_mlp())
    # plot the model
    plot(torch_model)
    # create a data cube from local files
    data_dir &lt;- system.file("extdata/raster/mod13q1", package = "sits")
    cube &lt;- sits_cube(
        source = "BDC",
        collection = "MOD13Q1-6",
        data_dir = data_dir
    )
    # classify a data cube
    probs_cube &lt;- sits_classify(
        data = cube, ml_model = torch_model, output_dir = tempdir()
    )
    # plot the probability cube
    plot(probs_cube)
    # smooth the probability cube using Bayesian statistics
    bayes_cube &lt;- sits_smooth(probs_cube, output_dir = tempdir())
    # plot the smoothed cube
    plot(bayes_cube)
    # label the probability cube
    label_cube &lt;- sits_label_classification(
        bayes_cube,
        output_dir = tempdir()
    )
    # plot the labelled cube
    plot(label_cube)
}
</code></pre>

<hr>
<h2 id='sits_model_export'>Export classification models</h2><span id='topic+sits_model_export'></span><span id='topic+sits_model_export.sits_model'></span>

<h3>Description</h3>

<p>Given a trained machine learning or deep learning model,
exports the model as an object for further exploration outside the
<code>sits</code> package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sits_model_export(ml_model)

## S3 method for class 'sits_model'
sits_model_export(ml_model)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sits_model_export_+3A_ml_model">ml_model</code></td>
<td>
<p>A trained machine learning model</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An R object containing the model in the original format of
machine learning or deep learning package.
</p>


<h3>Author(s)</h3>

<p>Rolf Simoes, <a href="mailto:rolf.simoes@inpe.br">rolf.simoes@inpe.br</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (sits_run_examples()) {
    # create a classification model
    rfor_model &lt;- sits_train(samples_modis_ndvi, sits_rfor())
    # export the model
    rfor_object &lt;- sits_model_export(rfor_model)
}

</code></pre>

<hr>
<h2 id='sits_mosaic'>Mosaic classified cubes</h2><span id='topic+sits_mosaic'></span>

<h3>Description</h3>

<p>Creates a mosaic of all tiles of a sits cube.
Mosaics can be created from EO cubes and derived cubes.
In sits EO cubes, the mosaic will be generated for each band and date.
It is recommended to filter the image with the less cloud cover to create
a mosaic for the EO cubes.
It is possible to provide a <code>roi</code> to crop the mosaic.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sits_mosaic(
  cube,
  crs = "EPSG:3857",
  roi = NULL,
  multicores = 2,
  output_dir,
  version = "v1",
  progress = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sits_mosaic_+3A_cube">cube</code></td>
<td>
<p>A sits data cube.</p>
</td></tr>
<tr><td><code id="sits_mosaic_+3A_crs">crs</code></td>
<td>
<p>A target coordinate reference system of raster mosaic.
The provided crs could be a string
(e.g, &quot;EPSG:4326&quot; or a proj4string), or
an EPSG code number (e.g. 4326).
Default is &quot;EPSG:3857&quot; - WGS 84 / Pseudo-Mercator.</p>
</td></tr>
<tr><td><code id="sits_mosaic_+3A_roi">roi</code></td>
<td>
<p>Region of interest (see below).</p>
</td></tr>
<tr><td><code id="sits_mosaic_+3A_multicores">multicores</code></td>
<td>
<p>Number of cores that will be used to
crop the images in parallel.</p>
</td></tr>
<tr><td><code id="sits_mosaic_+3A_output_dir">output_dir</code></td>
<td>
<p>Directory for output images.</p>
</td></tr>
<tr><td><code id="sits_mosaic_+3A_version">version</code></td>
<td>
<p>Version of resulting image
(in the case of multiple tests)</p>
</td></tr>
<tr><td><code id="sits_mosaic_+3A_progress">progress</code></td>
<td>
<p>Show progress bar? Default is TRUE.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a sits cube with only one tile.
</p>


<h3>Note</h3>

<p>The &quot;roi&quot; parameter defines a region of interest. It can be
an sf_object, a shapefile, or a bounding box vector with
named XY values (<code>xmin</code>, <code>xmax</code>, <code>ymin</code>, <code>ymax</code>) or
named lat/long values (<code>lon_min</code>, <code>lon_max</code>,
<code>lat_min</code>, <code>lat_max</code>).
</p>
<p>The user should specify the crs of the mosaic since in many cases the
input images will be in different coordinate systems. For example,
when mosaicking Sentinel-2 images the inputs will be in general in
different UTM grid zones.
</p>


<h3>Author(s)</h3>

<p>Felipe Carvalho, <a href="mailto:felipe.carvalho@inpe.br">felipe.carvalho@inpe.br</a>
</p>
<p>Rolf Simoes,     <a href="mailto:rolf.simoes@inpe.br">rolf.simoes@inpe.br</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (sits_run_examples()) {
    # create a random forest model
    rfor_model &lt;- sits_train(samples_modis_ndvi, sits_rfor())
    # create a data cube from local files
    data_dir &lt;- system.file("extdata/raster/mod13q1", package = "sits")
    cube &lt;- sits_cube(
        source = "BDC",
        collection = "MOD13Q1-6",
        data_dir = data_dir
    )
    # classify a data cube
    probs_cube &lt;- sits_classify(
        data = cube, ml_model = rfor_model, output_dir = tempdir()
    )
    # smooth the probability cube using Bayesian statistics
    bayes_cube &lt;- sits_smooth(probs_cube, output_dir = tempdir())
    # label the probability cube
    label_cube &lt;- sits_label_classification(
        bayes_cube,
        output_dir = tempdir()
    )
    # create roi
    roi &lt;- sf::st_sfc(
        sf::st_polygon(
            list(rbind(
                c(-55.64768, -11.68649),
                c(-55.69654, -11.66455),
                c(-55.62973, -11.61519),
                c(-55.64768, -11.68649)
            ))
        ),
        crs = "EPSG:4326"
    )
    # crop and mosaic classified image
    mosaic_cube &lt;- sits_mosaic(
        cube = label_cube,
        roi = roi,
        crs = "EPSG:4326",
        output_dir = tempdir()
    )
}

</code></pre>

<hr>
<h2 id='sits_patterns'>Find temporal patterns associated to a set of time series</h2><span id='topic+sits_patterns'></span>

<h3>Description</h3>

<p>This function takes a set of time series samples as input
estimates a set of patterns. The patterns are calculated using a GAM model.
The idea is to use a formula of type y ~ s(x), where x is a temporal
reference and y if the value of the signal. For each time, there will
be as many predictions as there are sample values.
The GAM model predicts a suitable
approximation that fits the assumptions of the statistical model,
based on a smooth function.
</p>
<p>This method is based on the &quot;createPatterns&quot; method of the dtwSat package,
which is also described in the reference paper.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sits_patterns(data = NULL, freq = 8, formula = y ~ s(x), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sits_patterns_+3A_data">data</code></td>
<td>
<p>Time series.</p>
</td></tr>
<tr><td><code id="sits_patterns_+3A_freq">freq</code></td>
<td>
<p>Interval in days for estimates.</p>
</td></tr>
<tr><td><code id="sits_patterns_+3A_formula">formula</code></td>
<td>
<p>Formula to be applied in the estimate.</p>
</td></tr>
<tr><td><code id="sits_patterns_+3A_...">...</code></td>
<td>
<p>Any additional parameters.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Time series with patterns.
</p>


<h3>Author(s)</h3>

<p>Victor Maus, <a href="mailto:vwmaus1@gmail.com">vwmaus1@gmail.com</a>
</p>
<p>Gilberto Camara, <a href="mailto:gilberto.camara@inpe.br">gilberto.camara@inpe.br</a>
</p>
<p>Rolf Simoes, <a href="mailto:rolf.simoes@inpe.br">rolf.simoes@inpe.br</a>
</p>


<h3>References</h3>

<p>Maus V, Camara G, Cartaxo R, Sanchez A, Ramos F, Queiroz GR.
A Time-Weighted Dynamic Time Warping Method for Land-Use
and Land-Cover Mapping. IEEE Journal of Selected Topics in Applied
Earth Observations and Remote Sensing, 9(8):3729-3739,
August 2016. ISSN 1939-1404. doi:10.1109/JSTARS.2016.2517118.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (sits_run_examples()) {
    patterns &lt;- sits_patterns(cerrado_2classes)
    plot(patterns)
}

</code></pre>

<hr>
<h2 id='sits_pred_features'>Obtain numerical values of predictors for time series samples</h2><span id='topic+sits_pred_features'></span>

<h3>Description</h3>

<p>Predictors are X-Y values required for machine learning
algorithms, organized as a data table where each row corresponds
to a training sample. The first two columns of the predictors table
are categorical (&quot;label_id&quot; and &quot;label&quot;). The other columns are
the values of each band and time, organized first by band and then by time.
This function returns the numeric values associated to each sample.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sits_pred_features(pred)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sits_pred_features_+3A_pred">pred</code></td>
<td>
<p>X-Y predictors: a data.frame with one row per sample.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The Y predictors for the sample: data.frame with one row per sample.
</p>


<h3>Note</h3>

<p>Please refer to the sits documentation available in
&lt;https://e-sensing.github.io/sitsbook/&gt; for detailed examples.
</p>


<h3>Author(s)</h3>

<p>Gilberto Camara, <a href="mailto:gilberto.camara@inpe.br">gilberto.camara@inpe.br</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (sits_run_examples()) {
    pred &lt;- sits_predictors(samples_modis_ndvi)
    features &lt;- sits_pred_features(pred)
}
</code></pre>

<hr>
<h2 id='sits_pred_normalize'>Normalize predictor values</h2><span id='topic+sits_pred_normalize'></span>

<h3>Description</h3>

<p>Most machine learning algorithms require data to be
normalized. This applies to the &quot;SVM&quot; method and to all deep learning ones.
To normalize the predictors, it is required that the statistics per band
for each sample have been obtained by the &quot;sits_stats&quot; function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sits_pred_normalize(pred, stats)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sits_pred_normalize_+3A_pred">pred</code></td>
<td>
<p>X-Y predictors: a data.frame with one row per sample.</p>
</td></tr>
<tr><td><code id="sits_pred_normalize_+3A_stats">stats</code></td>
<td>
<p>Values of time series for Q02 and Q98 of the data
(list of numeric values with two elements)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data.frame with normalized predictor values
</p>


<h3>Note</h3>

<p>Please refer to the sits documentation available in
&lt;https://e-sensing.github.io/sitsbook/&gt; for detailed examples.
</p>


<h3>Author(s)</h3>

<p>Gilberto Camara, <a href="mailto:gilberto.camara@inpe.br">gilberto.camara@inpe.br</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (sits_run_examples()) {
    stats &lt;- sits_stats(samples_modis_ndvi)
    pred &lt;- sits_predictors(samples_modis_ndvi)
    pred_norm &lt;- sits_pred_normalize(pred, stats)
}
</code></pre>

<hr>
<h2 id='sits_pred_reference'>Obtain categorical id and predictor labels for time series samples</h2><span id='topic+sits_pred_reference'></span><span id='topic+sits_pred_references'></span>

<h3>Description</h3>

<p>Predictors are X-Y values required for machine learning
algorithms, organized as a data table where each row corresponds
to a training sample. The first two columns of the predictors table
are categorical (&quot;label_id&quot; and &quot;label&quot;). The other columns are
the values of each band and time, organized first by band and then by time.
This function returns the numeric values associated to each sample.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sits_pred_references(pred)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sits_pred_reference_+3A_pred">pred</code></td>
<td>
<p>X-Y predictors: a data.frame with one row per sample.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A character vector with labels associated to training samples.
</p>


<h3>Author(s)</h3>

<p>Gilberto Camara, <a href="mailto:gilberto.camara@inpe.br">gilberto.camara@inpe.br</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (sits_run_examples()) {
    pred &lt;- sits_predictors(samples_modis_ndvi)
    ref &lt;- sits_pred_references(pred)
}
</code></pre>

<hr>
<h2 id='sits_pred_sample'>Obtain a fraction of the predictors data frame</h2><span id='topic+sits_pred_sample'></span>

<h3>Description</h3>

<p>Many machine learning algorithms (especially deep learning)
use part of the original samples as test data to adjust its hyperparameters
and to find an optimal point of convergence using gradient descent.
This function extracts a fraction of the predictors to serve as test values
for the deep learning algorithm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sits_pred_sample(pred, frac)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sits_pred_sample_+3A_pred">pred</code></td>
<td>
<p>X-Y predictors: a data.frame with one row per sample.</p>
</td></tr>
<tr><td><code id="sits_pred_sample_+3A_frac">frac</code></td>
<td>
<p>Fraction of the X-Y predictors to be extracted</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data.frame with the chosen fraction of the X-Y predictors.
</p>


<h3>Note</h3>

<p>Please refer to the sits documentation available in
&lt;https://e-sensing.github.io/sitsbook/&gt; for detailed examples.
</p>


<h3>Author(s)</h3>

<p>Gilberto Camara, <a href="mailto:gilberto.camara@inpe.br">gilberto.camara@inpe.br</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (sits_run_examples()) {
    pred &lt;- sits_predictors(samples_modis_ndvi)
    pred_frac &lt;- sits_pred_sample(pred, frac = 0.5)
}
</code></pre>

<hr>
<h2 id='sits_predictors'>Obtain predictors for time series samples</h2><span id='topic+sits_predictors'></span>

<h3>Description</h3>

<p>Predictors are X-Y values required for machine learning
algorithms, organized as a data table where each row corresponds
to a training sample. The first two columns of the predictors table
are categorical (<code>label_id</code> and <code>label</code>). The other columns are
the values of each band and time, organized first by band and then by time.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sits_predictors(samples)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sits_predictors_+3A_samples">samples</code></td>
<td>
<p>Time series in sits format (tibble of class &quot;sits&quot;)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The predictors for the sample: a data.frame with one row per sample.
</p>


<h3>Author(s)</h3>

<p>Gilberto Camara, <a href="mailto:gilberto.camara@inpe.br">gilberto.camara@inpe.br</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (sits_run_examples()) {
    pred &lt;- sits_predictors(samples_modis_ndvi)
}

</code></pre>

<hr>
<h2 id='sits_reclassify'>Reclassify a classified cube</h2><span id='topic+sits_reclassify'></span><span id='topic+sits_reclassify.class_cube'></span><span id='topic+sits_reclassify.tbl_df'></span><span id='topic+sits_reclassify.default'></span>

<h3>Description</h3>

<p>Apply a set of named expressions to reclassify a classified image.
The expressions should use character values to refer to labels in
logical expressions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sits_reclassify(
  cube,
  mask,
  rules,
  memsize = 4L,
  multicores = 2L,
  output_dir,
  version = "v1"
)

## S3 method for class 'class_cube'
sits_reclassify(
  cube,
  mask,
  rules,
  memsize = 4L,
  multicores = 2L,
  output_dir,
  version = "v1"
)

## S3 method for class 'tbl_df'
sits_reclassify(
  cube,
  mask,
  rules,
  memsize,
  multicores,
  output_dir,
  version = "v1"
)

## Default S3 method:
sits_reclassify(
  cube,
  mask,
  rules,
  memsize,
  multicores,
  output_dir,
  version = "v1"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sits_reclassify_+3A_cube">cube</code></td>
<td>
<p>Image cube to be reclassified (class = &quot;class_cube&quot;)</p>
</td></tr>
<tr><td><code id="sits_reclassify_+3A_mask">mask</code></td>
<td>
<p>Image cube with additional information
to be used in expressions (class = &quot;class_cube&quot;).</p>
</td></tr>
<tr><td><code id="sits_reclassify_+3A_rules">rules</code></td>
<td>
<p>Expressions to be evaluated (named list).</p>
</td></tr>
<tr><td><code id="sits_reclassify_+3A_memsize">memsize</code></td>
<td>
<p>Memory available for classification in GB
(integer, min = 1, max = 16384).</p>
</td></tr>
<tr><td><code id="sits_reclassify_+3A_multicores">multicores</code></td>
<td>
<p>Number of cores to be used for classification
(integer, min = 1, max = 2048).</p>
</td></tr>
<tr><td><code id="sits_reclassify_+3A_output_dir">output_dir</code></td>
<td>
<p>Directory where files will be saved
(character vector of length 1 with valid location).</p>
</td></tr>
<tr><td><code id="sits_reclassify_+3A_version">version</code></td>
<td>
<p>Version of resulting image (character).</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>sits_reclassify()</code> allow any valid R expression to compute
reclassification. User should refer to <code>cube</code> and <code>mask</code>
to construct logical expressions.
Users can use can use any R expression that evaluates to logical.
<code>TRUE</code> values will be relabeled to expression name.
Updates are done in asynchronous manner, that is, all expressions
are evaluated using original classified values. Expressions are
evaluated sequentially and resulting values are assigned to
output cube. Last expressions has precedence over first ones.
</p>


<h3>Value</h3>

<p>An object of class &quot;class_cube&quot; (reclassified cube).
</p>


<h3>Author(s)</h3>

<p>Rolf Simoes, <a href="mailto:rolf.simoes@inpe.br">rolf.simoes@inpe.br</a>
</p>
<p>Gilberto Camara, <a href="mailto:gilberto.camara@inpe.br">gilberto.camara@inpe.br</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (sits_run_examples()) {
# Open mask map
data_dir &lt;- system.file("extdata/raster/prodes", package = "sits")
prodes2021 &lt;- sits_cube(
    source = "USGS",
    collection = "LANDSAT-C2L2-SR",
    data_dir = data_dir,
    parse_info = c(
        "X1", "X2", "tile", "start_date", "end_date",
        "band", "version"
    ),
    bands = "class",
    version = "v20220606",
    labels = c("1" = "Forest", "2" = "Water", "3" = "NonForest",
               "4" = "NonForest2", "6" = "d2007", "7" = "d2008",
               "8" = "d2009", "9" = "d2010", "10" = "d2011",
               "11" = "d2012", "12" = "d2013", "13" = "d2014",
               "14" = "d2015", "15" = "d2016", "16" = "d2017",
               "17" = "d2018", "18" = "r2010", "19" = "r2011",
               "20" = "r2012", "21" = "r2013", "22" = "r2014",
               "23" = "r2015", "24" = "r2016", "25" = "r2017",
               "26" = "r2018", "27" = "d2019", "28" = "r2019",
               "29" = "d2020", "31" = "r2020", "32" = "Clouds2021",
               "33" = "d2021", "34" = "r2021"),
    progress = FALSE
)
#' Open classification map
data_dir &lt;- system.file("extdata/raster/classif", package = "sits")
ro_class &lt;- sits_cube(
    source = "MPC",
    collection = "SENTINEL-2-L2A",
    data_dir = data_dir,
    parse_info = c(
        "X1", "X2", "tile", "start_date", "end_date",
        "band", "version"
    ),
    bands = "class",
    labels = c(
        "1" = "ClearCut_Fire", "2" = "ClearCut_Soil",
        "3" = "ClearCut_Veg", "4" = "Forest"
    ),
    progress = FALSE
)
# Reclassify cube
ro_mask &lt;- sits_reclassify(
    cube = ro_class,
    mask = prodes2021,
    rules = list(
        "Old_Deforestation" = mask %in% c(
            "d2007", "d2008", "d2009",
            "d2010", "d2011", "d2012",
            "d2013", "d2014", "d2015",
            "d2016", "d2017", "d2018",
            "r2010", "r2011", "r2012",
            "r2013", "r2014", "r2015",
            "r2016", "r2017", "r2018",
            "d2019", "r2019", "d2020",
            "r2020", "r2021"
        ),
        "Water_Mask" = mask == "Water",
        "NonForest_Mask" = mask %in% c("NonForest", "NonForest2")
    ),
    memsize = 4,
    multicores = 2,
    output_dir = tempdir(),
    version = "ex_reclassify"
)
}

</code></pre>

<hr>
<h2 id='sits_reduce_imbalance'>Reduce imbalance in a set of samples</h2><span id='topic+sits_reduce_imbalance'></span>

<h3>Description</h3>

<p>Takes a sits tibble with different labels and
returns a new tibble. Deals with class imbalance
using the synthetic minority oversampling technique (SMOTE)
for oversampling. Undersampling is done using the SOM methods available in
the sits package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sits_reduce_imbalance(
  samples,
  n_samples_over = 200,
  n_samples_under = 400,
  multicores = 2
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sits_reduce_imbalance_+3A_samples">samples</code></td>
<td>
<p>Sample set to rebalance</p>
</td></tr>
<tr><td><code id="sits_reduce_imbalance_+3A_n_samples_over">n_samples_over</code></td>
<td>
<p>Number of samples to oversample
for classes with samples less than this number.</p>
</td></tr>
<tr><td><code id="sits_reduce_imbalance_+3A_n_samples_under">n_samples_under</code></td>
<td>
<p>Number of samples to undersample
for classes with samples more than this number.</p>
</td></tr>
<tr><td><code id="sits_reduce_imbalance_+3A_multicores">multicores</code></td>
<td>
<p>Number of cores to process the data (default 2).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A sits tibble with reduced sample imbalance.
</p>


<h3>Author(s)</h3>

<p>Gilberto Camara, <a href="mailto:gilberto.camara@inpe.br">gilberto.camara@inpe.br</a>
</p>


<h3>References</h3>

<p>The reference paper on SMOTE is
N. V. Chawla, K. W. Bowyer, L. O.Hall, W. P. Kegelmeyer,
“SMOTE: synthetic minority over-sampling technique,”
Journal of artificial intelligence research, 321-357, 2002.
</p>
<p>Undersampling uses the SOM map developed by Lorena Santos and co-workers
and used in the sits_som_map() function.
The SOM map technique is described in the paper:
Lorena Santos, Karine Ferreira, Gilberto Camara, Michelle Picoli,
Rolf Simoes, “Quality control and class noise reduction of satellite
image time series”. ISPRS Journal of Photogrammetry and Remote Sensing,
vol. 177, pp 75-88, 2021. https://doi.org/10.1016/j.isprsjprs.2021.04.014.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (sits_run_examples()) {
    # print the labels summary for a sample set
    summary(samples_modis_ndvi)
    # reduce the sample imbalance
    new_samples &lt;- sits_reduce_imbalance(samples_modis_ndvi,
        n_samples_over = 200,
        n_samples_under = 200,
        multicores = 1
    )
    # print the labels summary for the rebalanced set
    summary(new_samples)
}
</code></pre>

<hr>
<h2 id='sits_regularize'>Build a regular data cube from an irregular one</h2><span id='topic+sits_regularize'></span><span id='topic+sits_regularize.raster_cube'></span><span id='topic+sits_regularize.mpc_cube_sentinel-1-grd'></span><span id='topic+sits_regularize.derived_cube'></span><span id='topic+sits_regularize.tbl_df'></span><span id='topic+sits_regularize.default'></span>

<h3>Description</h3>

<p>Produces regular data cubes for analysis-ready data (ARD)
image collections. Analysis-ready data (ARD) collections available in
AWS, MPC, USGS and DEAfrica are not regular in space and time.
Bands may have different resolutions,
images may not cover the entire time, and time intervals are not regular.
For this reason, subsets of these collection need to be converted to
regular data cubes before further processing and data analysis.
This function requires users to include the cloud band in their ARD-based
data cubes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sits_regularize(
  cube,
  period,
  res,
  output_dir,
  roi = NULL,
  multicores = 2L,
  progress = TRUE
)

## S3 method for class 'raster_cube'
sits_regularize(
  cube,
  period,
  res,
  output_dir,
  roi = NULL,
  multicores = 2L,
  progress = TRUE
)

## S3 method for class ''mpc_cube_sentinel-1-grd''
sits_regularize(
  cube,
  period,
  res,
  output_dir,
  roi = NULL,
  multicores = 2L,
  progress = TRUE
)

## S3 method for class 'derived_cube'
sits_regularize(
  cube,
  period,
  res,
  output_dir,
  roi = NULL,
  multicores = 2,
  progress = TRUE
)

## S3 method for class 'tbl_df'
sits_regularize(
  cube,
  period,
  res,
  output_dir,
  roi = NULL,
  multicores = 2,
  progress = TRUE
)

## Default S3 method:
sits_regularize(
  cube,
  period,
  res,
  output_dir,
  roi = NULL,
  multicores = 2,
  progress = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sits_regularize_+3A_cube">cube</code></td>
<td>
<p><code>raster_cube</code> object whose observation
period and/or spatial resolution is not constant.</p>
</td></tr>
<tr><td><code id="sits_regularize_+3A_period">period</code></td>
<td>
<p>ISO8601-compliant time period for regular
data cubes, with number and unit, where
&quot;D&quot;, &quot;M&quot; and &quot;Y&quot; stand for days, month and year;
e.g., &quot;P16D&quot; for 16 days.</p>
</td></tr>
<tr><td><code id="sits_regularize_+3A_res">res</code></td>
<td>
<p>Spatial resolution of regularized images (in meters).</p>
</td></tr>
<tr><td><code id="sits_regularize_+3A_output_dir">output_dir</code></td>
<td>
<p>Valid directory for storing regularized images.</p>
</td></tr>
<tr><td><code id="sits_regularize_+3A_roi">roi</code></td>
<td>
<p>A named <code>numeric</code> vector with a region of interest.
See more above.</p>
</td></tr>
<tr><td><code id="sits_regularize_+3A_multicores">multicores</code></td>
<td>
<p>Number of cores used for regularization;
used for parallel processing of input (integer)</p>
</td></tr>
<tr><td><code id="sits_regularize_+3A_progress">progress</code></td>
<td>
<p>show progress bar?</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code>raster_cube</code> object with aggregated images.
</p>


<h3>Note</h3>

<p>The &quot;roi&quot; parameter defines a region of interest. It can be
an sf_object, a shapefile, or a bounding box vector with
named XY values (&quot;xmin&quot;, &quot;xmax&quot;, &quot;ymin&quot;, &quot;ymax&quot;) or
named lat/long values (&quot;lat_min&quot;, &quot;lat_max&quot;, &quot;long_min&quot;, &quot;long_max&quot;).
<code>sits_regularize()</code> function will crop the images
that contain the region of interest().
</p>
<p>The aggregation method used in <code>sits_regularize</code>
sorts the images based on cloud cover, where images with the fewest
clouds at the top of the stack. Once
the stack of images is sorted, the method uses the first valid value to
create the temporal aggregation.
</p>
<p>The input (non-regular) ARD cube needs to include the cloud band for
the regularization to work.
</p>


<h3>References</h3>

<p>Appel, Marius; Pebesma, Edzer. On-demand processing of data cubes
from satellite image collections with the gdalcubes library. Data, v. 4,
n. 3, p. 92, 2019. DOI: 10.3390/data4030092.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (sits_run_examples()) {
    # define a non-regular Sentinel-2 cube in AWS
    s2_cube_open &lt;- sits_cube(
        source = "AWS",
        collection = "SENTINEL-2-L2A",
        tiles = c("20LKP", "20LLP"),
        bands = c("B8A", "CLOUD"),
        start_date = "2018-10-01",
        end_date = "2018-11-01"
    )
    # regularize the cube
    rg_cube &lt;- sits_regularize(
        cube = s2_cube_open,
        period = "P16D",
        res = 60,
        multicores = 2,
        output_dir = tempdir()
    )

    ## Sentinel-1 SAR
    roi &lt;- c("lon_min" = -50.410, "lon_max" = -50.379,
             "lat_min" = -10.1910, "lat_max" = -10.1573)
    s1_cube_open &lt;- sits_cube(
        source = "MPC",
        collection = "SENTINEL-1-GRD",
        bands = c("VV", "VH"),
        roi = roi,
        start_date = "2020-06-01",
        end_date = "2020-09-28"
    )
    # regularize the cube
    rg_cube &lt;- sits_regularize(
        cube = s1_cube_open,
        period = "P12D",
        res = 60,
        roi = roi,
        multicores = 2,
        output_dir = tempdir()
    )
}

</code></pre>

<hr>
<h2 id='sits_resnet'>Train ResNet classification models</h2><span id='topic+sits_resnet'></span>

<h3>Description</h3>

<p>Use a ResNet architecture for classifying image time series.
The ResNet (or deep residual network) was proposed by a team
in Microsoft Research for 2D image classification.
ResNet tries to address the degradation of accuracy
in a deep network. The idea is to replace a deep network
with a combination of shallow ones.
In the paper by Fawaz et al. (2019), ResNet was considered the best method
for time series classification, using the UCR dataset.
Please refer to the paper for more details.
</p>
<p>The R-torch version is based on the code made available by Zhiguang Wang,
author of the original paper. The code was developed in python using keras.
</p>
<p>https://github.com/cauchyturing
(repo: UCR_Time_Series_Classification_Deep_Learning_Baseline)
</p>
<p>The R-torch version also considered the code by Ignacio Oguiza,
whose implementation is available at
https://github.com/timeseriesAI/tsai/blob/main/tsai/models/ResNet.py.
</p>
<p>There are differences between Wang's Keras code and Oguiza torch code.
In this case, we have used Wang's keras code as the main reference.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sits_resnet(
  samples = NULL,
  samples_validation = NULL,
  blocks = c(64, 128, 128),
  kernels = c(7, 5, 3),
  epochs = 100,
  batch_size = 64,
  validation_split = 0.2,
  optimizer = torch::optim_adamw,
  opt_hparams = list(lr = 0.001, eps = 1e-08, weight_decay = 1e-06),
  lr_decay_epochs = 1,
  lr_decay_rate = 0.95,
  patience = 20,
  min_delta = 0.01,
  verbose = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sits_resnet_+3A_samples">samples</code></td>
<td>
<p>Time series with the training samples.</p>
</td></tr>
<tr><td><code id="sits_resnet_+3A_samples_validation">samples_validation</code></td>
<td>
<p>Time series with the validation samples. if the
<code>samples_validation</code> parameter is provided,
the <code>validation_split</code> parameter is ignored.</p>
</td></tr>
<tr><td><code id="sits_resnet_+3A_blocks">blocks</code></td>
<td>
<p>Number of 1D convolutional filters for
each block of three layers.</p>
</td></tr>
<tr><td><code id="sits_resnet_+3A_kernels">kernels</code></td>
<td>
<p>Size of the 1D convolutional kernels</p>
</td></tr>
<tr><td><code id="sits_resnet_+3A_epochs">epochs</code></td>
<td>
<p>Number of iterations to train the model.
for each layer of each block.</p>
</td></tr>
<tr><td><code id="sits_resnet_+3A_batch_size">batch_size</code></td>
<td>
<p>Number of samples per gradient update.</p>
</td></tr>
<tr><td><code id="sits_resnet_+3A_validation_split">validation_split</code></td>
<td>
<p>Fraction of training data
to be used as validation data.</p>
</td></tr>
<tr><td><code id="sits_resnet_+3A_optimizer">optimizer</code></td>
<td>
<p>Optimizer function to be used.</p>
</td></tr>
<tr><td><code id="sits_resnet_+3A_opt_hparams">opt_hparams</code></td>
<td>
<p>Hyperparameters for optimizer:
lr : Learning rate of the optimizer
eps: Term added to the denominator
to improve numerical stability.
weight_decay:       L2 regularization</p>
</td></tr>
<tr><td><code id="sits_resnet_+3A_lr_decay_epochs">lr_decay_epochs</code></td>
<td>
<p>Number of epochs to reduce learning rate.</p>
</td></tr>
<tr><td><code id="sits_resnet_+3A_lr_decay_rate">lr_decay_rate</code></td>
<td>
<p>Decay factor for reducing learning rate.</p>
</td></tr>
<tr><td><code id="sits_resnet_+3A_patience">patience</code></td>
<td>
<p>Number of epochs without improvements until
training stops.</p>
</td></tr>
<tr><td><code id="sits_resnet_+3A_min_delta">min_delta</code></td>
<td>
<p>Minimum improvement in loss function
to reset the patience counter.</p>
</td></tr>
<tr><td><code id="sits_resnet_+3A_verbose">verbose</code></td>
<td>
<p>Verbosity mode (TRUE/FALSE). Default is FALSE.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A fitted model to be used for classification.
</p>


<h3>Note</h3>

<p>Please refer to the sits documentation available in
&lt;https://e-sensing.github.io/sitsbook/&gt; for detailed examples.
</p>


<h3>Author(s)</h3>

<p>Gilberto Camara, <a href="mailto:gilberto.camara@inpe.br">gilberto.camara@inpe.br</a>
</p>
<p>Rolf Simoes, <a href="mailto:rolf.simoes@inpe.br">rolf.simoes@inpe.br</a>
</p>
<p>Felipe Souza, <a href="mailto:lipecaso@gmail.com">lipecaso@gmail.com</a>
</p>
<p>Alber Sanchez, <a href="mailto:alber.ipia@inpe.br">alber.ipia@inpe.br</a>
</p>
<p>Charlotte Pelletier, <a href="mailto:charlotte.pelletier@univ-ubs.fr">charlotte.pelletier@univ-ubs.fr</a>
</p>
<p>Daniel Falbel, <a href="mailto:dfalbel@gmail.com">dfalbel@gmail.com</a>
</p>


<h3>References</h3>

<p>Hassan Fawaz, Germain Forestier, Jonathan Weber,
Lhassane Idoumghar,  and Pierre-Alain Muller,
&quot;Deep learning for time series classification: a review&quot;,
Data Mining and Knowledge Discovery, 33(4): 917&ndash;963, 2019.
</p>
<p>Zhiguang Wang, Weizhong Yan, and Tim Oates,
&quot;Time series classification from scratch with deep neural networks:
A strong baseline&quot;,
2017 international joint conference on neural networks (IJCNN).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (sits_run_examples()) {
    # create a ResNet model
    torch_model &lt;- sits_train(samples_modis_ndvi, sits_resnet())
    # plot the model
    plot(torch_model)
    # create a data cube from local files
    data_dir &lt;- system.file("extdata/raster/mod13q1", package = "sits")
    cube &lt;- sits_cube(
        source = "BDC",
        collection = "MOD13Q1-6",
        data_dir = data_dir
    )
    # classify a data cube
    probs_cube &lt;- sits_classify(
        data = cube, ml_model = torch_model, output_dir = tempdir()
    )
    # plot the probability cube
    plot(probs_cube)
    # smooth the probability cube using Bayesian statistics
    bayes_cube &lt;- sits_smooth(probs_cube, output_dir = tempdir())
    # plot the smoothed cube
    plot(bayes_cube)
    # label the probability cube
    label_cube &lt;- sits_label_classification(
        bayes_cube,
        output_dir = tempdir()
    )
    # plot the labelled cube
    plot(label_cube)
}
</code></pre>

<hr>
<h2 id='sits_rfor'>Train random forest models</h2><span id='topic+sits_rfor'></span>

<h3>Description</h3>

<p>Use Random Forest algorithm to classify samples.
This function is a front-end to the <code>randomForest</code> package.
Please refer to the documentation in that package for more details.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sits_rfor(samples = NULL, num_trees = 100, mtry = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sits_rfor_+3A_samples">samples</code></td>
<td>
<p>Time series with the training samples
(tibble of class &quot;sits&quot;).</p>
</td></tr>
<tr><td><code id="sits_rfor_+3A_num_trees">num_trees</code></td>
<td>
<p>Number of trees to grow. This should not be set to too
small a number, to ensure that every input
row gets predicted at least a few times (default: 100)
(integer, min = 50, max = 150).</p>
</td></tr>
<tr><td><code id="sits_rfor_+3A_mtry">mtry</code></td>
<td>
<p>Number of variables randomly sampled as candidates at
each split (default: NULL - use default value of
<code>randomForest::randomForest()</code> function, i.e.
<code>floor(sqrt(features))</code>).</p>
</td></tr>
<tr><td><code id="sits_rfor_+3A_...">...</code></td>
<td>
<p>Other parameters to be passed
to 'randomForest::randomForest' function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Model fitted to input data
(to be passed to <code><a href="#topic+sits_classify">sits_classify</a></code>).
</p>


<h3>Author(s)</h3>

<p>Alexandre Ywata de Carvalho, <a href="mailto:alexandre.ywata@ipea.gov.br">alexandre.ywata@ipea.gov.br</a>
</p>
<p>Rolf Simoes, <a href="mailto:rolf.simoes@inpe.br">rolf.simoes@inpe.br</a>
</p>
<p>Gilberto Camara, <a href="mailto:gilberto.camara@inpe.br">gilberto.camara@inpe.br</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (sits_run_examples()) {
    # Example of training a model for time series classification
    # Retrieve the samples for Mato Grosso
    # train a random forest model
    rf_model &lt;- sits_train(samples_modis_ndvi,
        ml_method = sits_rfor(mtry = 20)
    )
    # classify the point
    point_ndvi &lt;- sits_select(point_mt_6bands, bands = "NDVI")
    # classify the point
    point_class &lt;- sits_classify(
        data = point_ndvi, ml_model = rf_model
    )
    plot(point_class)
}
</code></pre>

<hr>
<h2 id='sits_run_examples'>Informs if sits examples should run</h2><span id='topic+sits_run_examples'></span>

<h3>Description</h3>

<p>This function informs if sits examples should run.
To run the examples, set &quot;SITS_RUN_EXAMPLES&quot; to &quot;YES&quot; using
Sys.setenv(&quot;SITS_RUN_EXAMPLES&quot; = &quot;YES&quot;)
To come back to the default behaviour, please set
Sys.setenv(&quot;SITS_RUN_EXAMPLES&quot; = &quot;NO&quot;)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sits_run_examples()
</code></pre>


<h3>Value</h3>

<p>A logical value
</p>

<hr>
<h2 id='sits_run_tests'>Informs if sits tests should run</h2><span id='topic+sits_run_tests'></span>

<h3>Description</h3>

<p>To run the tests, set &quot;SITS_RUN_TESTS&quot; environment to &quot;YES&quot; using
Sys.setenv(&quot;SITS_RUN_TESTS&quot; = &quot;YES&quot;)
To come back to the default behaviour, please set
Sys.setenv(&quot;SITS_RUN_TESTS&quot; = &quot;NO&quot;)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sits_run_tests()
</code></pre>


<h3>Value</h3>

<p>TRUE/FALSE
</p>

<hr>
<h2 id='sits_sample'>Sample a percentage of a time series</h2><span id='topic+sits_sample'></span>

<h3>Description</h3>

<p>Takes a sits tibble with different labels and
returns a new tibble. For a given field as a group criterion,
this new tibble contains a percentage
of the total number of samples per group.
If frac &gt; 1 , all sampling will be done with replacement.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sits_sample(data, frac = 0.2, oversample = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sits_sample_+3A_data">data</code></td>
<td>
<p>Sits time series tibble (class = &quot;sits&quot;)</p>
</td></tr>
<tr><td><code id="sits_sample_+3A_frac">frac</code></td>
<td>
<p>Percentage of samples to extract
(range: 0.0 to 2.0, default = 0.2)</p>
</td></tr>
<tr><td><code id="sits_sample_+3A_oversample">oversample</code></td>
<td>
<p>Logical: oversample classes with small number of samples?
(TRUE/FALSE)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A sits tibble with a fixed quantity of samples.
</p>


<h3>Author(s)</h3>

<p>Rolf Simoes, <a href="mailto:rolf.simoes@inpe.br">rolf.simoes@inpe.br</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Retrieve a set of time series with 2 classes
data(cerrado_2classes)
# Print the labels of the resulting tibble
summary(cerrado_2classes)
# Sample by fraction
data_02 &lt;- sits_sample(cerrado_2classes, frac = 0.2)
# Print the labels
summary(data_02)
</code></pre>

<hr>
<h2 id='sits_segment'>Segment an image</h2><span id='topic+sits_segment'></span>

<h3>Description</h3>

<p>Apply a spatial-temporal segmentation on a data cube based on a user defined
segmentation function. The function applies the segmentation algorithm
&quot;seg_fn&quot; to each tile.
</p>
<p>Segmentation uses the following steps:
</p>

<ol>
<li><p> Create a regular data cube with <code><a href="#topic+sits_cube">sits_cube</a></code> and
<code><a href="#topic+sits_regularize">sits_regularize</a></code>;
</p>
</li>
<li><p> Run <code><a href="#topic+sits_segment">sits_segment</a></code> to obtain a vector data cube
with polygons that define the boundary of the segments;
</p>
</li>
<li><p> Classify the time series associated to the segments
with <code><a href="#topic+sits_classify">sits_classify</a></code>, to get obtain
a vector probability cube;
</p>
</li>
<li><p> Use <code><a href="#topic+sits_label_classification">sits_label_classification</a></code> to label the
vector probability cube;
</p>
</li>
<li><p> Display the results with <code><a href="#topic+plot">plot</a></code> or
<code><a href="#topic+sits_view">sits_view</a></code>.
</p>
</li></ol>



<h3>Usage</h3>

<pre><code class='language-R'>sits_segment(
  cube,
  seg_fn = sits_slic(),
  roi = NULL,
  start_date = NULL,
  end_date = NULL,
  memsize = 8,
  multicores = 2,
  output_dir,
  version = "v1",
  progress = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sits_segment_+3A_cube">cube</code></td>
<td>
<p>Regular data cube</p>
</td></tr>
<tr><td><code id="sits_segment_+3A_seg_fn">seg_fn</code></td>
<td>
<p>Function to apply the segmentation</p>
</td></tr>
<tr><td><code id="sits_segment_+3A_roi">roi</code></td>
<td>
<p>Region of interest (see below)</p>
</td></tr>
<tr><td><code id="sits_segment_+3A_start_date">start_date</code></td>
<td>
<p>Start date for the segmentation</p>
</td></tr>
<tr><td><code id="sits_segment_+3A_end_date">end_date</code></td>
<td>
<p>End date for the segmentation.</p>
</td></tr>
<tr><td><code id="sits_segment_+3A_memsize">memsize</code></td>
<td>
<p>Memory available for classification (in GB).</p>
</td></tr>
<tr><td><code id="sits_segment_+3A_multicores">multicores</code></td>
<td>
<p>Number of cores to be used for classification.</p>
</td></tr>
<tr><td><code id="sits_segment_+3A_output_dir">output_dir</code></td>
<td>
<p>Directory for output file.</p>
</td></tr>
<tr><td><code id="sits_segment_+3A_version">version</code></td>
<td>
<p>Version of the output (for multiple
segmentations).</p>
</td></tr>
<tr><td><code id="sits_segment_+3A_progress">progress</code></td>
<td>
<p>Show progress bar?</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tibble of class 'segs_cube' representing the
segmentation.
</p>


<h3>Note</h3>

<p>The &quot;roi&quot; parameter defines a region of interest. It can be
an sf_object, a shapefile, or a bounding box vector with
named XY values (&quot;xmin&quot;, &quot;xmax&quot;, &quot;ymin&quot;, &quot;ymax&quot;) or
named lat/long values (&quot;lon_min&quot;, &quot;lat_min&quot;, &quot;lon_max&quot;, &quot;lat_max&quot;)
</p>


<h3>Author(s)</h3>

<p>Gilberto Camara, <a href="mailto:gilberto.camara@inpe.br">gilberto.camara@inpe.br</a>
</p>
<p>Rolf Simoes, <a href="mailto:rolf.simoes@inpe.br">rolf.simoes@inpe.br</a>
</p>
<p>Felipe Carvalho, <a href="mailto:felipe.carvalho@inpe.br">felipe.carvalho@inpe.br</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (sits_run_examples()) {
    data_dir &lt;- system.file("extdata/raster/mod13q1", package = "sits")
    # create a data cube
    cube &lt;- sits_cube(
        source = "BDC",
        collection = "MOD13Q1-6",
        data_dir = data_dir
    )
    # segment the vector cube
    segments &lt;- sits_segment(
        cube = cube,
        output_dir = tempdir()
    )
    # create a classification model
    rfor_model &lt;- sits_train(samples_modis_ndvi, sits_rfor())
    # classify the segments
    seg_probs &lt;- sits_classify(
        data = segments,
        ml_model = rfor_model,
        output_dir = tempdir()
    )
    # label the probability segments
    seg_label &lt;- sits_label_classification(
        cube = seg_probs,
        output_dir = tempdir()
    )
}
</code></pre>

<hr>
<h2 id='sits_select'>Filter bands on a data set (tibble or cube)</h2><span id='topic+sits_select'></span><span id='topic+sits_select.sits'></span><span id='topic+sits_select.raster_cube'></span><span id='topic+sits_select.patterns'></span><span id='topic+sits_select.tbl_df'></span><span id='topic+sits_select.default'></span>

<h3>Description</h3>

<p>Filter only the selected bands and dates
from a set of time series or froam a data cube.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sits_select(data, bands = NULL, start_date = NULL, end_date = NULL, ...)

## S3 method for class 'sits'
sits_select(data, bands = NULL, start_date = NULL, end_date = NULL, ...)

## S3 method for class 'raster_cube'
sits_select(
  data,
  bands = NULL,
  start_date = NULL,
  end_date = NULL,
  ...,
  dates = NULL,
  tiles = NULL
)

## S3 method for class 'patterns'
sits_select(data, bands = NULL, start_date = NULL, end_date = NULL, ...)

## S3 method for class 'tbl_df'
sits_select(data, ...)

## Default S3 method:
sits_select(data, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sits_select_+3A_data">data</code></td>
<td>
<p>Tibble with time series or data cube.</p>
</td></tr>
<tr><td><code id="sits_select_+3A_bands">bands</code></td>
<td>
<p>Character vector with the names of the bands.</p>
</td></tr>
<tr><td><code id="sits_select_+3A_start_date">start_date</code></td>
<td>
<p>Date in YYYY-MM-DD format: start date to be filtered.</p>
</td></tr>
<tr><td><code id="sits_select_+3A_end_date">end_date</code></td>
<td>
<p>Date in YYYY-MM-DD format: end date to be filtered.</p>
</td></tr>
<tr><td><code id="sits_select_+3A_...">...</code></td>
<td>
<p>Additional parameters to be provided</p>
</td></tr>
<tr><td><code id="sits_select_+3A_dates">dates</code></td>
<td>
<p>Character vector with sparse dates to select.</p>
</td></tr>
<tr><td><code id="sits_select_+3A_tiles">tiles</code></td>
<td>
<p>Character vector with the names of the tiles.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Tibble with time series or data cube.
</p>


<h3>Author(s)</h3>

<p>Rolf Simoes, <a href="mailto:rolf.simoes@inpe.br">rolf.simoes@inpe.br</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Retrieve a set of time series with 2 classes
data(cerrado_2classes)
# Print the original bands
sits_bands(cerrado_2classes)
# Select only the NDVI band
data &lt;- sits_select(cerrado_2classes, bands = c("NDVI"))
# Print the labels of the resulting tibble
sits_bands(data)
# select start and end date
point_2010 &lt;- sits_select(point_mt_6bands,
              start_date = "2000-01-01",
              end_date = "2030-12-31")

</code></pre>

<hr>
<h2 id='sits_sgolay'>Filter time series with Savitzky-Golay filter</h2><span id='topic+sits_sgolay'></span>

<h3>Description</h3>

<p>An optimal polynomial for warping a time series.
The degree of smoothing depends on the filter order (usually 3.0).
The order of the polynomial uses the parameter 'order' (default = 3),
the size of the temporal window uses the parameter 'length' (default = 5).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sits_sgolay(data = NULL, order = 3, length = 5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sits_sgolay_+3A_data">data</code></td>
<td>
<p>Time series or matrix.</p>
</td></tr>
<tr><td><code id="sits_sgolay_+3A_order">order</code></td>
<td>
<p>Filter order (integer).</p>
</td></tr>
<tr><td><code id="sits_sgolay_+3A_length">length</code></td>
<td>
<p>Filter length (must be odd).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Filtered time series
</p>


<h3>Author(s)</h3>

<p>Rolf Simoes, <a href="mailto:rolf.simoes@inpe.br">rolf.simoes@inpe.br</a>
</p>
<p>Gilberto Camara, <a href="mailto:gilberto.camara@inpe.br">gilberto.camara@inpe.br</a>
</p>
<p>Felipe Carvalho, <a href="mailto:felipe.carvalho@inpe.br">felipe.carvalho@inpe.br</a>
</p>


<h3>References</h3>

<p>A. Savitzky, M. Golay, &quot;Smoothing and Differentiation
of Data by Simplified Least Squares Procedures&quot;.
Analytical Chemistry, 36 (8): 1627–39, 1964.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (sits_run_examples()) {
    # Retrieve a time series with values of NDVI
    point_ndvi &lt;- sits_select(point_mt_6bands, bands = "NDVI")

    # Filter the point using the Savitzky-Golay smoother
    point_sg &lt;- sits_filter(point_ndvi,
        filter = sits_sgolay(order = 3, length = 5)
    )
    # Merge time series
    point_ndvi &lt;- sits_merge(point_ndvi, point_sg, suffix = c("", ".SG"))

    # Plot the two points to see the smoothing effect
    plot(point_ndvi)
}
</code></pre>

<hr>
<h2 id='sits_show_prediction'>Shows the predicted labels for a classified tibble</h2><span id='topic+sits_show_prediction'></span>

<h3>Description</h3>

<p>This function takes a tibble with a classified time series
by a machine learning method and displays the result.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sits_show_prediction(class)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sits_show_prediction_+3A_class">class</code></td>
<td>
<p>A SITS tibble that has been classified.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Tibble with the columns &quot;from&quot;, &quot;to&quot;, &quot;class&quot;
</p>


<h3>Author(s)</h3>

<p>Gilberto Camara, <a href="mailto:gilberto.camara@inpe.br">gilberto.camara@inpe.br</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (sits_run_examples()) {
    # Retrieve the samples for Mato Grosso
    # train an SVM model
    ml_model &lt;- sits_train(samples_modis_ndvi, ml_method = sits_svm)
    # classify the point
    point_ndvi &lt;- sits_select(point_mt_6bands, bands = "NDVI")
    point_class &lt;- sits_classify(
        data = point_ndvi, ml_model = ml_model
    )
    sits_show_prediction(point_class)
}

</code></pre>

<hr>
<h2 id='sits_slic'>Segment an image using SLIC</h2><span id='topic+sits_slic'></span>

<h3>Description</h3>

<p>Apply a segmentation on a data cube based on the <code>supercells</code> package.
This is an adaptation and extension to remote sensing data of the
SLIC superpixels algorithm proposed by Achanta et al. (2012).
See references for more details.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sits_slic(
  data = NULL,
  step = 5,
  compactness = 1,
  dist_fun = "euclidean",
  avg_fun = "median",
  iter = 30,
  minarea = 10,
  verbose = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sits_slic_+3A_data">data</code></td>
<td>
<p>A matrix with time series.</p>
</td></tr>
<tr><td><code id="sits_slic_+3A_step">step</code></td>
<td>
<p>Distance (in number of cells) between initial
supercells' centers.</p>
</td></tr>
<tr><td><code id="sits_slic_+3A_compactness">compactness</code></td>
<td>
<p>A compactness value. Larger values cause clusters to
be more compact/even (square).</p>
</td></tr>
<tr><td><code id="sits_slic_+3A_dist_fun">dist_fun</code></td>
<td>
<p>Distance function. Currently implemented:
<code>euclidean, jsd, dtw</code>,
and any distance function from the
<code>philentropy</code> package.
See <code>philentropy::getDistMethods()</code>.</p>
</td></tr>
<tr><td><code id="sits_slic_+3A_avg_fun">avg_fun</code></td>
<td>
<p>Averaging function to calculate the values
of the supercells' centers.
Accepts any fitting R function
(e.g., base::mean() or stats::median())
or one of internally implemented &quot;mean&quot; and &quot;median&quot;.
Default: &quot;median&quot;</p>
</td></tr>
<tr><td><code id="sits_slic_+3A_iter">iter</code></td>
<td>
<p>Number of iterations to create the output.</p>
</td></tr>
<tr><td><code id="sits_slic_+3A_minarea">minarea</code></td>
<td>
<p>Specifies the minimal size of a supercell (in cells).</p>
</td></tr>
<tr><td><code id="sits_slic_+3A_verbose">verbose</code></td>
<td>
<p>Show the progress bar?</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Set of segments for a single tile
</p>


<h3>Author(s)</h3>

<p>Gilberto Camara, <a href="mailto:gilberto.camara@inpe.br">gilberto.camara@inpe.br</a>
</p>
<p>Rolf Simoes, <a href="mailto:rolf.simoes@inpe.br">rolf.simoes@inpe.br</a>
</p>
<p>Felipe Carvalho, <a href="mailto:felipe.carvalho@inpe.br">felipe.carvalho@inpe.br</a>
</p>


<h3>References</h3>

<p>Achanta, Radhakrishna, Appu Shaji, Kevin Smith, Aurelien Lucchi,
Pascal Fua, and Sabine Süsstrunk. 2012. “SLIC Superpixels Compared
to State-of-the-Art Superpixel Methods.” IEEE Transactions on
Pattern Analysis and Machine Intelligence 34 (11): 2274–82.
</p>
<p>Nowosad, Jakub, and Tomasz F. Stepinski. 2022. “Extended SLIC
Superpixels Algorithm for Applications to Non-Imagery Geospatial
Rasters.” International Journal of Applied Earth Observation
and Geoinformation 112 (August): 102935.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (sits_run_examples()) {
    data_dir &lt;- system.file("extdata/raster/mod13q1", package = "sits")
    # create a data cube
    cube &lt;- sits_cube(
        source = "BDC",
        collection = "MOD13Q1-6",
        data_dir = data_dir
    )
    # segment the vector cube
    segments &lt;- sits_segment(
        cube = cube,
        output_dir = tempdir(),
        version = "slic-demo"
    )
    # create a classification model
    rfor_model &lt;- sits_train(samples_modis_ndvi, sits_rfor())
    # classify the segments
    seg_probs &lt;- sits_classify(
        data = segments,
        ml_model = rfor_model,
        output_dir = tempdir(),
        version = "slic-demo"
    )
    # label the probability segments
    seg_label &lt;- sits_label_classification(
        cube = seg_probs,
        output_dir = tempdir(),
        version = "slic-demo"
    )
}
</code></pre>

<hr>
<h2 id='sits_smooth'>Smooth probability cubes with spatial predictors</h2><span id='topic+sits_smooth'></span><span id='topic+sits_smooth.probs_cube'></span><span id='topic+sits_smooth.raster_cube'></span><span id='topic+sits_smooth.derived_cube'></span><span id='topic+sits_smooth.tbl_df'></span><span id='topic+sits_smooth.default'></span>

<h3>Description</h3>

<p>Takes a set of classified raster layers with probabilities,
whose metadata is]created by <code><a href="#topic+sits_cube">sits_cube</a></code>,
and applies a Bayesian smoothing function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sits_smooth(
  cube,
  window_size = 7L,
  neigh_fraction = 0.5,
  smoothness = 10L,
  memsize = 4L,
  multicores = 2L,
  output_dir,
  version = "v1"
)

## S3 method for class 'probs_cube'
sits_smooth(
  cube,
  window_size = 7L,
  neigh_fraction = 0.5,
  smoothness = 10L,
  memsize = 4L,
  multicores = 2L,
  output_dir,
  version = "v1"
)

## S3 method for class 'raster_cube'
sits_smooth(
  cube,
  window_size = 7L,
  neigh_fraction = 0.5,
  smoothness = 10L,
  memsize = 4L,
  multicores = 2L,
  output_dir,
  version = "v1"
)

## S3 method for class 'derived_cube'
sits_smooth(
  cube,
  window_size = 7L,
  neigh_fraction = 0.5,
  smoothness = 10L,
  memsize = 4L,
  multicores = 2L,
  output_dir,
  version = "v1"
)

## S3 method for class 'tbl_df'
sits_smooth(
  cube,
  window_size = 7L,
  neigh_fraction = 0.5,
  smoothness = 10L,
  memsize = 4L,
  multicores = 2L,
  output_dir,
  version = "v1"
)

## Default S3 method:
sits_smooth(
  cube,
  window_size = 7L,
  neigh_fraction = 0.5,
  smoothness = 10L,
  memsize = 4L,
  multicores = 2L,
  output_dir,
  version = "v1"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sits_smooth_+3A_cube">cube</code></td>
<td>
<p>Probability data cube.</p>
</td></tr>
<tr><td><code id="sits_smooth_+3A_window_size">window_size</code></td>
<td>
<p>Size of the neighborhood
(integer, min = 3, max = 21)</p>
</td></tr>
<tr><td><code id="sits_smooth_+3A_neigh_fraction">neigh_fraction</code></td>
<td>
<p>Fraction of neighbors with high probabilities
to be used in Bayesian inference.
(numeric, min = 0.1, max = 1.0)</p>
</td></tr>
<tr><td><code id="sits_smooth_+3A_smoothness">smoothness</code></td>
<td>
<p>Estimated variance of logit of class probabilities
(Bayesian smoothing parameter)
(integer vector or scalar, min = 1, max = 200).</p>
</td></tr>
<tr><td><code id="sits_smooth_+3A_memsize">memsize</code></td>
<td>
<p>Memory available for classification in GB
(integer, min = 1, max = 16384).</p>
</td></tr>
<tr><td><code id="sits_smooth_+3A_multicores">multicores</code></td>
<td>
<p>Number of cores to be used for classification
(integer, min = 1, max = 2048).</p>
</td></tr>
<tr><td><code id="sits_smooth_+3A_output_dir">output_dir</code></td>
<td>
<p>Valid directory for output file.
(character vector of length 1).</p>
</td></tr>
<tr><td><code id="sits_smooth_+3A_version">version</code></td>
<td>
<p>Version of the output
(character vector of length 1).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data cube.
</p>


<h3>Author(s)</h3>

<p>Gilberto Camara, <a href="mailto:gilberto.camara@inpe.br">gilberto.camara@inpe.br</a>
</p>
<p>Rolf Simoes, <a href="mailto:rolf.simoes@inpe.br">rolf.simoes@inpe.br</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (sits_run_examples()) {
    # create am xgboost model
    xgb_model &lt;- sits_train(samples_modis_ndvi, sits_xgboost())
    # create a data cube from local files
    data_dir &lt;- system.file("extdata/raster/mod13q1", package = "sits")
    cube &lt;- sits_cube(
        source = "BDC",
        collection = "MOD13Q1-6",
        data_dir = data_dir
    )
    # classify a data cube
    probs_cube &lt;- sits_classify(
        data = cube, ml_model = xgb_model, output_dir = tempdir()
    )
    # plot the probability cube
    plot(probs_cube)
    # smooth the probability cube using Bayesian statistics
    bayes_cube &lt;- sits_smooth(probs_cube, output_dir = tempdir())
    # plot the smoothed cube
    plot(bayes_cube)
    # label the probability cube
    label_cube &lt;- sits_label_classification(
        bayes_cube,
        output_dir = tempdir()
    )
    # plot the labelled cube
    plot(label_cube)
}
</code></pre>

<hr>
<h2 id='sits_som'>Use SOM for quality analysis of time series samples</h2><span id='topic+sits_som'></span><span id='topic+sits_som_map'></span>

<h3>Description</h3>

<p>These function use self-organized maps to perform
quality analysis in satellite image time series
</p>
<p><code>sits_som_map()</code> creates a SOM map, where high-dimensional data
is mapped into a two dimensional map, keeping the topological relations
between data patterns. Each sample is assigned to a neuron,
and neurons are placed in the grid based on similarity.
</p>
<p><code>sits_som_evaluate_cluster()</code> analyses the neurons of the SOM map,
and builds clusters based on them. Each cluster is a neuron
or a set of neuron categorized with same label.
It produces a tibble with the percentage of mixture of classes
in each cluster.
</p>
<p><code>sits_som_clean_samples()</code> evaluates the quality of the samples
based on the results of the SOM map.  The algorithm identifies noisy samples,
using 'prior_threshold' for the prior probability
and 'posterior_threshold' for the posterior probability.
Each sample receives an evaluation tag, according to the following rule:
(a) If the prior probability is &lt; 'prior_threshold', the sample is tagged
as &quot;remove&quot;;
(b) If the prior probability is &gt;= 'prior_threshold' and the posterior
probability is &gt;='posterior_threshold', the sample is tagged as &quot;clean&quot;;
(c) If the prior probability is &gt;= 'posterior_threshold' and
the posterior probability is &lt; 'posterior_threshold', the sample is tagged as
&quot;analyze&quot; for further inspection.
The user can define which tagged samples will be returned using the &quot;keep&quot;
parameter, with the following options: &quot;clean&quot;, &quot;analyze&quot;, &quot;remove&quot;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sits_som_map(
  data,
  grid_xdim = 10,
  grid_ydim = 10,
  alpha = 1,
  rlen = 100,
  distance = "euclidean",
  som_radius = 2,
  mode = "online"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sits_som_+3A_data">data</code></td>
<td>
<p>A tibble with samples to be clustered.</p>
</td></tr>
<tr><td><code id="sits_som_+3A_grid_xdim">grid_xdim</code></td>
<td>
<p>X dimension of the SOM grid (default = 25).</p>
</td></tr>
<tr><td><code id="sits_som_+3A_grid_ydim">grid_ydim</code></td>
<td>
<p>Y dimension of the SOM grid.</p>
</td></tr>
<tr><td><code id="sits_som_+3A_alpha">alpha</code></td>
<td>
<p>Starting learning rate
(decreases according to number of iterations).</p>
</td></tr>
<tr><td><code id="sits_som_+3A_rlen">rlen</code></td>
<td>
<p>Number of iterations to produce the SOM.</p>
</td></tr>
<tr><td><code id="sits_som_+3A_distance">distance</code></td>
<td>
<p>The type of similarity measure (distance).</p>
</td></tr>
<tr><td><code id="sits_som_+3A_som_radius">som_radius</code></td>
<td>
<p>Radius of SOM neighborhood.</p>
</td></tr>
<tr><td><code id="sits_som_+3A_mode">mode</code></td>
<td>
<p>Type of learning algorithm (default = &quot;online&quot;).</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>sits_som_map()</code> produces a list with three members:
(1) the samples tibble, with one additional column indicating
to which neuron each sample has been mapped;
(2) the Kohonen map, used for plotting and cluster quality measures;
(3) a tibble with the labelled neurons,
where each class of each neuron is associated to two values:
(a) the prior probability that this class belongs to a cluster
based on the frequency of samples of this class allocated to the neuron;
(b) the posterior probability that this class belongs to a cluster,
using data for the neighbours on the SOM map.
</p>


<h3>Author(s)</h3>

<p>Lorena Alves, <a href="mailto:lorena.santos@inpe.br">lorena.santos@inpe.br</a>
</p>
<p>Karine Ferreira. <a href="mailto:karine.ferreira@inpe.br">karine.ferreira@inpe.br</a>
</p>


<h3>References</h3>

<p>Lorena Santos, Karine Ferreira, Gilberto Camara, Michelle Picoli,
Rolf Simoes, “Quality control and class noise reduction of satellite
image time series”. ISPRS Journal of Photogrammetry and Remote Sensing,
vol. 177, pp 75-88, 2021. https://doi.org/10.1016/j.isprsjprs.2021.04.014.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (sits_run_examples()) {
    # create a som map
    som_map &lt;- sits_som_map(samples_modis_ndvi)
    # plot the som map
    plot(som_map)
    # evaluate the som map and create clusters
    clusters_som &lt;- sits_som_evaluate_cluster(som_map)
    # plot the cluster evaluation
    plot(clusters_som)
    # clean the samples
    new_samples &lt;- sits_som_clean_samples(som_map)
}

</code></pre>

<hr>
<h2 id='sits_som_clean_samples'>Cleans the samples based on SOM map information</h2><span id='topic+sits_som_clean_samples'></span>

<h3>Description</h3>

<p>Cleans the samples based on SOM map information
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sits_som_clean_samples(
  som_map,
  prior_threshold = 0.6,
  posterior_threshold = 0.6,
  keep = c("clean", "analyze")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sits_som_clean_samples_+3A_som_map">som_map</code></td>
<td>
<p>Returned by <code><a href="#topic+sits_som_map">sits_som_map</a></code>.</p>
</td></tr>
<tr><td><code id="sits_som_clean_samples_+3A_prior_threshold">prior_threshold</code></td>
<td>
<p>Threshold of conditional probability
(frequency of samples assigned to the
same SOM neuron).</p>
</td></tr>
<tr><td><code id="sits_som_clean_samples_+3A_posterior_threshold">posterior_threshold</code></td>
<td>
<p>Threshold of posterior probability
(influenced by the SOM neighborhood).</p>
</td></tr>
<tr><td><code id="sits_som_clean_samples_+3A_keep">keep</code></td>
<td>
<p>Which types of evaluation to be maintained in the data.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>tibble with an two additional columns.
The first indicates if each sample is clean, should be analyzed or
should be removed. The second is the posterior probability of the sample.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (sits_run_examples()) {
    # create a som map
    som_map &lt;- sits_som_map(samples_modis_ndvi)
    # plot the som map
    plot(som_map)
    # evaluate the som map and create clusters
    clusters_som &lt;- sits_som_evaluate_cluster(som_map)
    # plot the cluster evaluation
    plot(clusters_som)
    # clean the samples
    new_samples &lt;- sits_som_clean_samples(som_map)
}

</code></pre>

<hr>
<h2 id='sits_som_evaluate_cluster'>Evaluate cluster</h2><span id='topic+sits_som_evaluate_cluster'></span>

<h3>Description</h3>

<p><code>sits_som_evaluate_cluster()</code> produces a tibble with the clusters
found by the SOM map. For each cluster, it provides the percentage
of classes inside it.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sits_som_evaluate_cluster(som_map)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sits_som_evaluate_cluster_+3A_som_map">som_map</code></td>
<td>
<p>A SOM map produced by the som_map() function</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tibble stating the purity for each cluster
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (sits_run_examples()) {
    # create a som map
    som_map &lt;- sits_som_map(samples_modis_ndvi)
    # plot the som map
    plot(som_map)
    # evaluate the som map and create clusters
    clusters_som &lt;- sits_som_evaluate_cluster(som_map)
    # plot the cluster evaluation
    plot(clusters_som)
    # clean the samples
    new_samples &lt;- sits_som_clean_samples(som_map)
}
</code></pre>

<hr>
<h2 id='sits_stats'>Obtain statistics for all sample bands</h2><span id='topic+sits_stats'></span>

<h3>Description</h3>

<p>Most machine learning algorithms require data to be
normalized. This applies to the &quot;SVM&quot; method and to all deep learning ones.
To normalize the predictors, it is necessary to extract the statistics
of each band of the samples. This function computes the 2
of the distribution of each band of the samples. This values are used as
minimum and maximum values in the normalization operation performed by
the sits_pred_normalize() function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sits_stats(samples)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sits_stats_+3A_samples">samples</code></td>
<td>
<p>Time series samples uses as training data.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with the 2
training data.
</p>


<h3>Note</h3>

<p>Please refer to the sits documentation available in
&lt;https://e-sensing.github.io/sitsbook/&gt; for detailed examples.
</p>


<h3>Author(s)</h3>

<p>Gilberto Camara, <a href="mailto:gilberto.camara@inpe.br">gilberto.camara@inpe.br</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (sits_run_examples()) {
    stats &lt;- sits_stats(samples_modis_ndvi)
}
</code></pre>

<hr>
<h2 id='sits_svm'>Train support vector machine models</h2><span id='topic+sits_svm'></span>

<h3>Description</h3>

<p>This function receives a tibble with a set of attributes X
for each observation Y. These attributes are the values of the time series
for each band.
The SVM algorithm is used for multiclass-classification.
For this purpose, it uses the &quot;one-against-one&quot; approach,
in which k(k-1)/2 binary classifiers are trained;
the appropriate class is found by a voting scheme.
This function is a front-end to the &quot;svm&quot; method in the &quot;e1071&quot; package.
Please refer to the documentation in that package for more details.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sits_svm(
  samples = NULL,
  formula = sits_formula_linear(),
  scale = FALSE,
  cachesize = 1000,
  kernel = "radial",
  degree = 3,
  coef0 = 0,
  cost = 10,
  tolerance = 0.001,
  epsilon = 0.1,
  cross = 10,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sits_svm_+3A_samples">samples</code></td>
<td>
<p>Time series with the training samples.</p>
</td></tr>
<tr><td><code id="sits_svm_+3A_formula">formula</code></td>
<td>
<p>Symbolic description of the model to be fit.
(default: sits_formula_linear).</p>
</td></tr>
<tr><td><code id="sits_svm_+3A_scale">scale</code></td>
<td>
<p>Logical vector indicating the variables to be scaled.</p>
</td></tr>
<tr><td><code id="sits_svm_+3A_cachesize">cachesize</code></td>
<td>
<p>Cache memory in MB (default = 1000).</p>
</td></tr>
<tr><td><code id="sits_svm_+3A_kernel">kernel</code></td>
<td>
<p>Kernel used in training and predicting.
options: &quot;linear&quot;, &quot;polynomial&quot;, &quot;radial&quot;, &quot;sigmoid&quot;
(default: &quot;radial&quot;).</p>
</td></tr>
<tr><td><code id="sits_svm_+3A_degree">degree</code></td>
<td>
<p>Exponential of polynomial type kernel (default: 3).</p>
</td></tr>
<tr><td><code id="sits_svm_+3A_coef0">coef0</code></td>
<td>
<p>Parameter needed for kernels of type polynomial
and sigmoid (default: 0).</p>
</td></tr>
<tr><td><code id="sits_svm_+3A_cost">cost</code></td>
<td>
<p>Cost of constraints violation (default: 10).</p>
</td></tr>
<tr><td><code id="sits_svm_+3A_tolerance">tolerance</code></td>
<td>
<p>Tolerance of termination criterion (default: 0.001).</p>
</td></tr>
<tr><td><code id="sits_svm_+3A_epsilon">epsilon</code></td>
<td>
<p>Epsilon in the insensitive-loss function
(default: 0.1).</p>
</td></tr>
<tr><td><code id="sits_svm_+3A_cross">cross</code></td>
<td>
<p>Number of cross validation folds applied
to assess the quality of the model (default: 10).</p>
</td></tr>
<tr><td><code id="sits_svm_+3A_...">...</code></td>
<td>
<p>Other parameters to be passed to e1071::svm function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Model fitted to input data
(to be passed to <code><a href="#topic+sits_classify">sits_classify</a></code>)
</p>


<h3>Note</h3>

<p>Please refer to the sits documentation available in
&lt;https://e-sensing.github.io/sitsbook/&gt; for detailed examples.
</p>


<h3>Author(s)</h3>

<p>Alexandre Ywata de Carvalho, <a href="mailto:alexandre.ywata@ipea.gov.br">alexandre.ywata@ipea.gov.br</a>
</p>
<p>Rolf Simoes, <a href="mailto:rolf.simoes@inpe.br">rolf.simoes@inpe.br</a>
</p>
<p>Gilberto Camara, <a href="mailto:gilberto.camara@inpe.br">gilberto.camara@inpe.br</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (sits_run_examples()) {
    # Example of training a model for time series classification
    # Retrieve the samples for Mato Grosso
    # train an SVM model
    ml_model &lt;- sits_train(samples_modis_ndvi, ml_method = sits_svm)
    # classify the point
    point_ndvi &lt;- sits_select(point_mt_6bands, bands = "NDVI")
    # classify the point
    point_class &lt;- sits_classify(
        data = point_ndvi, ml_model = ml_model
    )
    plot(point_class)
}
</code></pre>

<hr>
<h2 id='sits_tae'>Train a model using  Temporal Self-Attention Encoder</h2><span id='topic+sits_tae'></span>

<h3>Description</h3>

<p>Implementation of Temporal Attention Encoder (TAE)
for satellite image time series classification.
</p>
<p>This function is based on the paper by Vivien Garnot referenced below
and code available on github at
https://github.com/VSainteuf/pytorch-psetae.
</p>
<p>We also used the code made available by Maja Schneider in her work with
Marco Körner referenced below and available at
https://github.com/maja601/RC2020-psetae.
</p>
<p>If you use this method, please cite Garnot's and Schneider's work.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sits_tae(
  samples = NULL,
  samples_validation = NULL,
  epochs = 150,
  batch_size = 64,
  validation_split = 0.2,
  optimizer = torchopt::optim_adamw,
  opt_hparams = list(lr = 0.001, eps = 1e-08, weight_decay = 1e-06),
  lr_decay_epochs = 1,
  lr_decay_rate = 0.95,
  patience = 20,
  min_delta = 0.01,
  verbose = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sits_tae_+3A_samples">samples</code></td>
<td>
<p>Time series with the training samples.</p>
</td></tr>
<tr><td><code id="sits_tae_+3A_samples_validation">samples_validation</code></td>
<td>
<p>Time series with the validation samples. if the
<code>samples_validation</code> parameter is provided,
the <code>validation_split</code> parameter is ignored.</p>
</td></tr>
<tr><td><code id="sits_tae_+3A_epochs">epochs</code></td>
<td>
<p>Number of iterations to train the model.</p>
</td></tr>
<tr><td><code id="sits_tae_+3A_batch_size">batch_size</code></td>
<td>
<p>Number of samples per gradient update.</p>
</td></tr>
<tr><td><code id="sits_tae_+3A_validation_split">validation_split</code></td>
<td>
<p>Number between 0 and 1. Fraction of training data
to be used as validation data.</p>
</td></tr>
<tr><td><code id="sits_tae_+3A_optimizer">optimizer</code></td>
<td>
<p>Optimizer function to be used.</p>
</td></tr>
<tr><td><code id="sits_tae_+3A_opt_hparams">opt_hparams</code></td>
<td>
<p>Hyperparameters for optimizer:
lr : Learning rate of the optimizer
eps: Term added to the denominator
to improve numerical stability.
weight_decay:       L2 regularization</p>
</td></tr>
<tr><td><code id="sits_tae_+3A_lr_decay_epochs">lr_decay_epochs</code></td>
<td>
<p>Number of epochs to reduce learning rate.</p>
</td></tr>
<tr><td><code id="sits_tae_+3A_lr_decay_rate">lr_decay_rate</code></td>
<td>
<p>Decay factor for reducing learning rate.</p>
</td></tr>
<tr><td><code id="sits_tae_+3A_patience">patience</code></td>
<td>
<p>Number of epochs without improvements until
training stops.</p>
</td></tr>
<tr><td><code id="sits_tae_+3A_min_delta">min_delta</code></td>
<td>
<p>Minimum improvement to reset the patience counter.</p>
</td></tr>
<tr><td><code id="sits_tae_+3A_verbose">verbose</code></td>
<td>
<p>Verbosity mode (TRUE/FALSE). Default is FALSE.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A fitted model to be used for classification.
</p>


<h3>Author(s)</h3>

<p>Charlotte Pelletier, <a href="mailto:charlotte.pelletier@univ-ubs.fr">charlotte.pelletier@univ-ubs.fr</a>
</p>
<p>Gilberto Camara, <a href="mailto:gilberto.camara@inpe.br">gilberto.camara@inpe.br</a>
</p>
<p>Rolf Simoes, <a href="mailto:rolf.simoes@inpe.br">rolf.simoes@inpe.br</a>
</p>


<h3>References</h3>

<p>Vivien Garnot, Loic Landrieu, Sebastien Giordano, and Nesrine Chehata,
&quot;Satellite Image Time Series Classification with Pixel-Set Encoders
and Temporal Self-Attention&quot;,
2020 Conference on Computer Vision and Pattern Recognition.
pages 12322-12331.
DOI: 10.1109/CVPR42600.2020.01234
</p>
<p>Schneider, Maja; Körner, Marco,
&quot;[Re] Satellite Image Time Series Classification
with Pixel-Set Encoders and Temporal Self-Attention.&quot;
ReScience C 7 (2), 2021.
DOI: 10.5281/zenodo.4835356
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (sits_run_examples()) {
    # create a TAE model
    torch_model &lt;- sits_train(samples_modis_ndvi, sits_tae())
    # plot the model
    plot(torch_model)
    # create a data cube from local files
    data_dir &lt;- system.file("extdata/raster/mod13q1", package = "sits")
    cube &lt;- sits_cube(
        source = "BDC",
        collection = "MOD13Q1-6",
        data_dir = data_dir
    )
    # classify a data cube
    probs_cube &lt;- sits_classify(
        data = cube, ml_model = torch_model, output_dir = tempdir()
    )
    # plot the probability cube
    plot(probs_cube)
    # smooth the probability cube using Bayesian statistics
    bayes_cube &lt;- sits_smooth(probs_cube, output_dir = tempdir())
    # plot the smoothed cube
    plot(bayes_cube)
    # label the probability cube
    label_cube &lt;- sits_label_classification(
        bayes_cube,
        output_dir = tempdir()
    )
    # plot the labelled cube
    plot(label_cube)
}
</code></pre>

<hr>
<h2 id='sits_tempcnn'>Train temporal convolutional neural network models</h2><span id='topic+sits_tempcnn'></span>

<h3>Description</h3>

<p>Use a TempCNN algorithm to classify data, which has
two stages: a 1D CNN and a  multi-layer perceptron.
Users can define the depth of the 1D network, as well as
the number of perceptron layers.
</p>
<p>This function is based on the paper by Charlotte Pelletier referenced below.
If you use this method, please cite the original tempCNN paper.
</p>
<p>The torch version is based on the code made available by the BreizhCrops
team: Marc Russwurm, Charlotte Pelletier, Marco Korner, Maximilian Zollner.
The original python code is available at the website
https://github.com/dl4sits/BreizhCrops. This code is licensed as GPL-3.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sits_tempcnn(
  samples = NULL,
  samples_validation = NULL,
  cnn_layers = c(256, 256, 256),
  cnn_kernels = c(5, 5, 5),
  cnn_dropout_rates = c(0.2, 0.2, 0.2),
  dense_layer_nodes = 256,
  dense_layer_dropout_rate = 0.5,
  epochs = 150,
  batch_size = 64,
  validation_split = 0.2,
  optimizer = torch::optim_adamw,
  opt_hparams = list(lr = 0.005, eps = 1e-08, weight_decay = 1e-06),
  lr_decay_epochs = 1,
  lr_decay_rate = 0.95,
  patience = 20,
  min_delta = 0.01,
  verbose = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sits_tempcnn_+3A_samples">samples</code></td>
<td>
<p>Time series with the training samples.</p>
</td></tr>
<tr><td><code id="sits_tempcnn_+3A_samples_validation">samples_validation</code></td>
<td>
<p>Time series with the validation samples. if the
<code>samples_validation</code> parameter is provided,
the <code>validation_split</code> parameter is ignored.</p>
</td></tr>
<tr><td><code id="sits_tempcnn_+3A_cnn_layers">cnn_layers</code></td>
<td>
<p>Number of 1D convolutional filters per layer</p>
</td></tr>
<tr><td><code id="sits_tempcnn_+3A_cnn_kernels">cnn_kernels</code></td>
<td>
<p>Size of the 1D convolutional kernels.</p>
</td></tr>
<tr><td><code id="sits_tempcnn_+3A_cnn_dropout_rates">cnn_dropout_rates</code></td>
<td>
<p>Dropout rates for 1D convolutional filters.</p>
</td></tr>
<tr><td><code id="sits_tempcnn_+3A_dense_layer_nodes">dense_layer_nodes</code></td>
<td>
<p>Number of nodes in the dense layer.</p>
</td></tr>
<tr><td><code id="sits_tempcnn_+3A_dense_layer_dropout_rate">dense_layer_dropout_rate</code></td>
<td>
<p>Dropout rate (0,1) for the dense layer.</p>
</td></tr>
<tr><td><code id="sits_tempcnn_+3A_epochs">epochs</code></td>
<td>
<p>Number of iterations to train the model.</p>
</td></tr>
<tr><td><code id="sits_tempcnn_+3A_batch_size">batch_size</code></td>
<td>
<p>Number of samples per gradient update.</p>
</td></tr>
<tr><td><code id="sits_tempcnn_+3A_validation_split">validation_split</code></td>
<td>
<p>Fraction of training data to be used for
validation.</p>
</td></tr>
<tr><td><code id="sits_tempcnn_+3A_optimizer">optimizer</code></td>
<td>
<p>Optimizer function to be used.</p>
</td></tr>
<tr><td><code id="sits_tempcnn_+3A_opt_hparams">opt_hparams</code></td>
<td>
<p>Hyperparameters for optimizer:
lr : Learning rate of the optimizer
eps: Term added to the denominator
to improve numerical stability.
weight_decay:       L2 regularization</p>
</td></tr>
<tr><td><code id="sits_tempcnn_+3A_lr_decay_epochs">lr_decay_epochs</code></td>
<td>
<p>Number of epochs to reduce learning rate.</p>
</td></tr>
<tr><td><code id="sits_tempcnn_+3A_lr_decay_rate">lr_decay_rate</code></td>
<td>
<p>Decay factor for reducing learning rate.</p>
</td></tr>
<tr><td><code id="sits_tempcnn_+3A_patience">patience</code></td>
<td>
<p>Number of epochs without improvements until
training stops.</p>
</td></tr>
<tr><td><code id="sits_tempcnn_+3A_min_delta">min_delta</code></td>
<td>
<p>Minimum improvement in loss function
to reset the patience counter.</p>
</td></tr>
<tr><td><code id="sits_tempcnn_+3A_verbose">verbose</code></td>
<td>
<p>Verbosity mode (TRUE/FALSE). Default is FALSE.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A fitted model to be used for classification.
</p>


<h3>Note</h3>

<p>Please refer to the sits documentation available in
&lt;https://e-sensing.github.io/sitsbook/&gt; for detailed examples.
</p>


<h3>Author(s)</h3>

<p>Charlotte Pelletier, <a href="mailto:charlotte.pelletier@univ-ubs.fr">charlotte.pelletier@univ-ubs.fr</a>
</p>
<p>Gilberto Camara, <a href="mailto:gilberto.camara@inpe.br">gilberto.camara@inpe.br</a>
</p>
<p>Rolf Simoes, <a href="mailto:rolf.simoes@inpe.br">rolf.simoes@inpe.br</a>
</p>
<p>Felipe Souza, <a href="mailto:lipecaso@gmail.com">lipecaso@gmail.com</a>
</p>


<h3>References</h3>

<p>Charlotte Pelletier, Geoffrey Webb and François Petitjean,
&quot;Temporal Convolutional Neural Network for the Classification
of Satellite Image Time Series&quot;,
Remote Sensing, 11,523, 2019. DOI: 10.3390/rs11050523.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (sits_run_examples()) {
    # create a TempCNN model
    torch_model &lt;- sits_train(samples_modis_ndvi, sits_tempcnn())
    # plot the model
    plot(torch_model)
    # create a data cube from local files
    data_dir &lt;- system.file("extdata/raster/mod13q1", package = "sits")
    cube &lt;- sits_cube(
        source = "BDC",
        collection = "MOD13Q1-6",
        data_dir = data_dir
    )
    # classify a data cube
    probs_cube &lt;- sits_classify(
        data = cube, ml_model = torch_model, output_dir = tempdir()
    )
    # plot the probability cube
    plot(probs_cube)
    # smooth the probability cube using Bayesian statistics
    bayes_cube &lt;- sits_smooth(probs_cube, output_dir = tempdir())
    # plot the smoothed cube
    plot(bayes_cube)
    # label the probability cube
    label_cube &lt;- sits_label_classification(
        bayes_cube,
        output_dir = tempdir()
    )
    # plot the labelled cube
    plot(label_cube)
}
</code></pre>

<hr>
<h2 id='sits_timeline'>Get timeline of a cube or a set of time series</h2><span id='topic+sits_timeline'></span><span id='topic+sits_timeline.sits'></span><span id='topic+sits_timeline.sits_model'></span><span id='topic+sits_timeline.raster_cube'></span><span id='topic+sits_timeline.derived_cube'></span><span id='topic+sits_timeline.tbl_df'></span><span id='topic+sits_timeline.default'></span>

<h3>Description</h3>

<p>This function returns the timeline for a given data set, either
a set of time series, a data cube, or a trained model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sits_timeline(data)

## S3 method for class 'sits'
sits_timeline(data)

## S3 method for class 'sits_model'
sits_timeline(data)

## S3 method for class 'raster_cube'
sits_timeline(data)

## S3 method for class 'derived_cube'
sits_timeline(data)

## S3 method for class 'tbl_df'
sits_timeline(data)

## Default S3 method:
sits_timeline(data)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sits_timeline_+3A_data">data</code></td>
<td>
<p>Tibble of class &quot;sits&quot; or class &quot;raster_cube&quot;</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Vector of class Date with timeline of samples or data cube.
</p>


<h3>Author(s)</h3>

<p>Gilberto Camara, <a href="mailto:gilberto.camara@inpe.br">gilberto.camara@inpe.br</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>sits_timeline(samples_modis_ndvi)
</code></pre>

<hr>
<h2 id='sits_to_csv'>Export a sits tibble metadata to the CSV format</h2><span id='topic+sits_to_csv'></span><span id='topic+sits_to_csv.sits'></span><span id='topic+sits_to_csv.tbl_df'></span><span id='topic+sits_to_csv.default'></span>

<h3>Description</h3>

<p>Converts metadata from a sits tibble to a CSV file.
The CSV file will not contain the actual time
series. Its columns will be the same as those of a
CSV file used to retrieve data from
ground information (&quot;latitude&quot;, &quot;longitude&quot;, &quot;start_date&quot;,
&quot;end_date&quot;, &quot;cube&quot;, &quot;label&quot;).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sits_to_csv(data, file)

## S3 method for class 'sits'
sits_to_csv(data, file)

## S3 method for class 'tbl_df'
sits_to_csv(data, file)

## Default S3 method:
sits_to_csv(data, file)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sits_to_csv_+3A_data">data</code></td>
<td>
<p>Time series (tibble of class &quot;sits&quot;).</p>
</td></tr>
<tr><td><code id="sits_to_csv_+3A_file">file</code></td>
<td>
<p>Full path of the exported CSV file
(valid file name with extension &quot;.csv&quot;).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Called for side effects
</p>


<h3>Author(s)</h3>

<p>Gilberto Camara, <a href="mailto:gilberto.camara@inpe.br">gilberto.camara@inpe.br</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>csv_file &lt;- paste0(tempdir(), "/cerrado_2classes.csv")
sits_to_csv(cerrado_2classes, file = csv_file)
</code></pre>

<hr>
<h2 id='sits_to_xlsx'>Save accuracy assessments as Excel files</h2><span id='topic+sits_to_xlsx'></span>

<h3>Description</h3>

<p>Saves confusion matrices as Excel spreadsheets. This function
takes the a list of accuracy assessments generated
by <code><a href="#topic+sits_accuracy">sits_accuracy</a></code>
and saves them in an Excel spreadsheet.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sits_to_xlsx(acc_lst, file, data = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sits_to_xlsx_+3A_acc_lst">acc_lst</code></td>
<td>
<p>A list of accuracy statistics</p>
</td></tr>
<tr><td><code id="sits_to_xlsx_+3A_file">file</code></td>
<td>
<p>The file where the XLSX data is to be saved.</p>
</td></tr>
<tr><td><code id="sits_to_xlsx_+3A_data">data</code></td>
<td>
<p>(optional) Print information about the samples</p>
</td></tr>
</table>


<h3>Value</h3>

<p>No return value, called for side effects.
</p>


<h3>Note</h3>

<p>Please refer to the sits documentation available in
&lt;https://e-sensing.github.io/sitsbook/&gt; for detailed examples.
</p>


<h3>Author(s)</h3>

<p>Gilberto Camara, <a href="mailto:gilberto.camara@inpe.br">gilberto.camara@inpe.br</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (sits_run_examples()) {
    # A dataset containing a tibble with time series samples
    # for the Mato Grosso state in Brasil
    # create a list to store the results
    results &lt;- list()

    # accuracy assessment lightTAE
    acc_ltae &lt;- sits_kfold_validate(samples_modis_ndvi,
        folds = 5,
        multicores = 1,
        ml_method = sits_lighttae()
    )
    # use a name
    acc_ltae$name &lt;- "LightTAE"

    # put the result in a list
    results[[length(results) + 1]] &lt;- acc_ltae

    # save to xlsx file
    sits_to_xlsx(
        results,
        file = tempfile("accuracy_mato_grosso_dl_", fileext = ".xlsx")
    )
}
</code></pre>

<hr>
<h2 id='sits_train'>Train classification models</h2><span id='topic+sits_train'></span>

<h3>Description</h3>

<p>Given a tibble with a set of distance measures,
returns trained models. Currently, sits supports the following models:
'svm' (see <code><a href="#topic+sits_svm">sits_svm</a></code>),
random forests (see <code><a href="#topic+sits_rfor">sits_rfor</a></code>),
extreme gradient boosting (see <code><a href="#topic+sits_xgboost">sits_xgboost</a></code>),
and different deep learning functions, including multi-layer perceptrons
(see <code><a href="#topic+sits_mlp">sits_mlp</a></code>), 1D convolution neural
networks <code><a href="#topic+sits_tempcnn">sits_tempcnn</a></code>,
deep residual networks <code><a href="#topic+sits_resnet">sits_resnet</a></code> and
self-attention encoders <code><a href="#topic+sits_lighttae">sits_lighttae</a></code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sits_train(samples, ml_method = sits_svm())
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sits_train_+3A_samples">samples</code></td>
<td>
<p>Time series with the training samples.</p>
</td></tr>
<tr><td><code id="sits_train_+3A_ml_method">ml_method</code></td>
<td>
<p>Machine learning method.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Model fitted to input data
to be passed to <code><a href="#topic+sits_classify">sits_classify</a></code>
</p>


<h3>Author(s)</h3>

<p>Rolf Simoes, <a href="mailto:rolf.simoes@inpe.br">rolf.simoes@inpe.br</a>
</p>
<p>Gilberto Camara, <a href="mailto:gilberto.camara@inpe.br">gilberto.camara@inpe.br</a>
</p>
<p>Alexandre Ywata de Carvalho, <a href="mailto:alexandre.ywata@ipea.gov.br">alexandre.ywata@ipea.gov.br</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (sits_run_examples()) {
    # Retrieve the set of samples for Mato Grosso
    # fit a training model (rfor model)
    ml_model &lt;- sits_train(samples_modis_ndvi, sits_rfor(num_trees = 50))
    # get a point and classify the point with the ml_model
    point_ndvi &lt;- sits_select(point_mt_6bands, bands = "NDVI")
    class &lt;- sits_classify(
        data = point_ndvi, ml_model = ml_model
    )
}
</code></pre>

<hr>
<h2 id='sits_tuning'>Tuning machine learning models hyper-parameters</h2><span id='topic+sits_tuning'></span>

<h3>Description</h3>

<p>Machine learning models use stochastic gradient descent (SGD) techniques to
find optimal solutions. To perform SGD, models use optimization
algorithms which have hyperparameters that have to be adjusted
to achieve best performance for each application.
</p>
<p>This function performs a random search on values of selected hyperparameters.
Instead of performing an exhaustive test of all parameter combinations,
it selecting them randomly. Validation is done using an independent set
of samples or by a validation split.  The function returns the
best hyper-parameters in a list. Hyper-parameters passed to <code>params</code>
parameter should be passed by calling <code>sits_tuning_hparams()</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sits_tuning(
  samples,
  samples_validation = NULL,
  validation_split = 0.2,
  ml_method = sits_tempcnn(),
  params = sits_tuning_hparams(optimizer = torchopt::optim_adamw, opt_hparams = list(lr =
    loguniform(10^-2, 10^-4))),
  trials = 30,
  multicores = 2,
  progress = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sits_tuning_+3A_samples">samples</code></td>
<td>
<p>Time series set to be validated.</p>
</td></tr>
<tr><td><code id="sits_tuning_+3A_samples_validation">samples_validation</code></td>
<td>
<p>Time series set used for validation.</p>
</td></tr>
<tr><td><code id="sits_tuning_+3A_validation_split">validation_split</code></td>
<td>
<p>Percent of original time series set to be used
for validation (if samples_validation is NULL)</p>
</td></tr>
<tr><td><code id="sits_tuning_+3A_ml_method">ml_method</code></td>
<td>
<p>Machine learning method.</p>
</td></tr>
<tr><td><code id="sits_tuning_+3A_params">params</code></td>
<td>
<p>List with hyper parameters to be passed to
<code>ml_method</code>. User can use <code>uniform</code>, <code>choice</code>,
<code>randint</code>, <code>normal</code>, <code>lognormal</code>, <code>loguniform</code>,
and <code>beta</code> distribution functions to randomize parameters.</p>
</td></tr>
<tr><td><code id="sits_tuning_+3A_trials">trials</code></td>
<td>
<p>Number of random trials to perform the random search.</p>
</td></tr>
<tr><td><code id="sits_tuning_+3A_multicores">multicores</code></td>
<td>
<p>Number of cores to process in parallel</p>
</td></tr>
<tr><td><code id="sits_tuning_+3A_progress">progress</code></td>
<td>
<p>Show progress bar?</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tibble containing all parameters used to train on each trial
ordered by accuracy
</p>


<h3>Author(s)</h3>

<p>Rolf Simoes, <a href="mailto:rolf.simoes@inpe.br">rolf.simoes@inpe.br</a>
</p>


<h3>References</h3>

<p>James Bergstra, Yoshua Bengio,
&quot;Random Search for Hyper-Parameter Optimization&quot;.
Journal of Machine Learning Research. 13: 281–305, 2012.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (sits_run_examples()) {
    # find best learning rate parameters for TempCNN
    tuned &lt;- sits_tuning(
        samples_modis_ndvi,
        ml_method = sits_tempcnn(),
        params = sits_tuning_hparams(
            optimizer = choice(
                torch::optim_adamw
            ),
            opt_hparams = list(
                lr = loguniform(10^-2, 10^-4)
            )
        ),
        trials = 4,
        multicores = 2,
        progress = FALSE
    )
    # obtain best accuracy, kappa and best_lr
    accuracy &lt;- tuned$accuracy[[1]]
    kappa &lt;- tuned$kappa[[1]]
    best_lr &lt;- tuned$opt_hparams[[1]]$lr
}

</code></pre>

<hr>
<h2 id='sits_tuning_hparams'>Tuning machine learning models hyper-parameters</h2><span id='topic+sits_tuning_hparams'></span>

<h3>Description</h3>

<p>This function allow user building the hyper-parameters space used
by <code>sits_tuning()</code> function search randomly the best parameter
combination.
</p>
<p>Users should pass the possible values for hyper-parameters as
constants or by calling the following random functions:
</p>

<ul>
<li> <p><code>uniform(min = 0, max = 1, n = 1)</code>: returns random numbers
from a uniform distribution with parameters min and max.
</p>
</li>
<li> <p><code>choice(..., replace = TRUE, n = 1)</code>: returns random objects
passed to <code>...</code> with replacement or not (parameter <code>replace</code>).
</p>
</li>
<li> <p><code>randint(min, max, n = 1)</code>: returns random integers
from a uniform distribution with parameters min and max.
</p>
</li>
<li> <p><code>normal(mean = 0, sd = 1, n = 1)</code>: returns random numbers
from a normal distribution with parameters min and max.
</p>
</li>
<li> <p><code>lognormal(meanlog = 0, sdlog = 1, n = 1)</code>: returns random
numbers from a lognormal distribution with parameters min and max.
</p>
</li>
<li> <p><code>loguniform(minlog = 0, maxlog = 1, n = 1)</code>: returns random
numbers from a loguniform distribution with parameters min and max.
</p>
</li>
<li> <p><code>beta(shape1, shape2, n = 1)</code>: returns random numbers
from a beta distribution with parameters min and max.
</p>
</li></ul>

<p>These functions accepts <code>n</code> parameter to indicate how many values
should be returned.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sits_tuning_hparams(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sits_tuning_hparams_+3A_...">...</code></td>
<td>
<p>Used to prepare hyper-parameter space</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing the hyper-parameter space to be passed to
<code>sits_tuning()</code>'s <code>params</code> parameter.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (sits_run_examples()) {
    # find best learning rate parameters for TempCNN
    tuned &lt;- sits_tuning(
        samples_modis_ndvi,
        ml_method = sits_tempcnn(),
        params = sits_tuning_hparams(
            optimizer = choice(
                torchopt::optim_adamw,
                torchopt::optim_yogi
            ),
            opt_hparams = list(
                lr = beta(0.3, 5)
            )
        ),
        trials = 4,
        multicores = 2,
        progress = FALSE
    )
}

</code></pre>

<hr>
<h2 id='sits_uncertainty'>Estimate classification uncertainty based on probs cube</h2><span id='topic+sits_uncertainty'></span><span id='topic+sits_uncertainty.least'></span><span id='topic+sits_uncertainty.entropy'></span><span id='topic+sits_uncertainty.margin'></span><span id='topic+sits_uncertainty.default'></span>

<h3>Description</h3>

<p>Calculate the uncertainty cube based on the probabilities
produced by the classifier. Takes a probability cube as input.
The uncertainty measure is relevant in the context of active leaning,
and helps to increase the quantity and quality of training samples by
providing information about the confidence of the model.
The supported types of uncertainty are 'entropy', 'least', and 'margin'.
'entropy' is the difference between all predictions expressed as
entropy, 'least' is the difference between 100
prediction, and 'margin' is the difference between the two most confident
predictions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sits_uncertainty(
  cube,
  type = "entropy",
  multicores = 2,
  memsize = 4,
  output_dir,
  version = "v1"
)

## S3 method for class 'least'
sits_uncertainty(
  cube,
  type = "least",
  multicores = 2,
  memsize = 4,
  output_dir,
  version = "v1"
)

## S3 method for class 'entropy'
sits_uncertainty(
  cube,
  type = "entropy",
  multicores = 2,
  memsize = 4,
  output_dir,
  version = "v1"
)

## S3 method for class 'margin'
sits_uncertainty(
  cube,
  type = "margin",
  multicores = 2,
  memsize = 4,
  output_dir,
  version = "v1"
)

## Default S3 method:
sits_uncertainty(cube, type, multicores, memsize, output_dir, version)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sits_uncertainty_+3A_cube">cube</code></td>
<td>
<p>Probability data cube.</p>
</td></tr>
<tr><td><code id="sits_uncertainty_+3A_type">type</code></td>
<td>
<p>Method to measure uncertainty. See details.</p>
</td></tr>
<tr><td><code id="sits_uncertainty_+3A_multicores">multicores</code></td>
<td>
<p>Number of cores to run the function.</p>
</td></tr>
<tr><td><code id="sits_uncertainty_+3A_memsize">memsize</code></td>
<td>
<p>Maximum overall memory (in GB) to run the function.</p>
</td></tr>
<tr><td><code id="sits_uncertainty_+3A_output_dir">output_dir</code></td>
<td>
<p>Output directory for image files.</p>
</td></tr>
<tr><td><code id="sits_uncertainty_+3A_version">version</code></td>
<td>
<p>Version of resulting image (in the case of
multiple tests).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An uncertainty data cube
</p>


<h3>Author(s)</h3>

<p>Gilberto Camara, <a href="mailto:gilberto.camara@inpe.br">gilberto.camara@inpe.br</a>
</p>
<p>Rolf Simoes, <a href="mailto:rolf.simoes@inpe.br">rolf.simoes@inpe.br</a>
</p>
<p>Alber Sanchez, <a href="mailto:alber.ipia@inpe.br">alber.ipia@inpe.br</a>
</p>


<h3>References</h3>

<p>Monarch, Robert Munro. Human-in-the-Loop Machine Learning:
Active learning and annotation for human-centered AI. Simon and Schuster,
2021.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (sits_run_examples()) {
    # create a random forest model
    rfor_model &lt;- sits_train(samples_modis_ndvi, sits_rfor())
    # create a data cube from local files
    data_dir &lt;- system.file("extdata/raster/mod13q1", package = "sits")
    cube &lt;- sits_cube(
        source = "BDC",
        collection = "MOD13Q1-6",
        data_dir = data_dir
    )
    # classify a data cube
    probs_cube &lt;- sits_classify(
        data = cube, ml_model = rfor_model, output_dir = tempdir()
    )
    # calculate uncertainty
    uncert_cube &lt;- sits_uncertainty(probs_cube, output_dir = tempdir())
    # plot the resulting uncertainty cube
    plot(uncert_cube)
}
</code></pre>

<hr>
<h2 id='sits_uncertainty_sampling'>Suggest samples for enhancing classification accuracy</h2><span id='topic+sits_uncertainty_sampling'></span>

<h3>Description</h3>

<p>Suggest samples for regions of high uncertainty as predicted by the model.
The function selects data points that have confused an algorithm.
These points don't have labels and need be manually labelled by experts
and then used to increase the classification's training set.
</p>
<p>This function is best used in the following context:
1. Select an initial set of samples.
2. Train a machine learning model.
3. Build a data cube and classify it using the model.
4. Run a Bayesian smoothing in the resulting probability cube.
5. Create an uncertainty cube.
6. Perform uncertainty sampling.
</p>
<p>The Bayesian smoothing procedure will reduce the classification outliers
and thus increase the likelihood that the resulting pixels with high
uncertainty have meaningful information.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sits_uncertainty_sampling(
  uncert_cube,
  n = 100L,
  min_uncert = 0.4,
  sampling_window = 10L
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sits_uncertainty_sampling_+3A_uncert_cube">uncert_cube</code></td>
<td>
<p>An uncertainty cube.
See <code><a href="#topic+sits_uncertainty">sits_uncertainty</a></code>.</p>
</td></tr>
<tr><td><code id="sits_uncertainty_sampling_+3A_n">n</code></td>
<td>
<p>Number of suggested points.</p>
</td></tr>
<tr><td><code id="sits_uncertainty_sampling_+3A_min_uncert">min_uncert</code></td>
<td>
<p>Minimum uncertainty value to select a sample.</p>
</td></tr>
<tr><td><code id="sits_uncertainty_sampling_+3A_sampling_window">sampling_window</code></td>
<td>
<p>Window size for collecting points (in pixels).
The minimum window size is 10.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tibble with longitude and latitude in WGS84 with locations
which have high uncertainty and meet the minimum distance
criteria.
</p>


<h3>Author(s)</h3>

<p>Alber Sanchez, <a href="mailto:alber.ipia@inpe.br">alber.ipia@inpe.br</a>
</p>
<p>Rolf Simoes, <a href="mailto:rolf.simoes@inpe.br">rolf.simoes@inpe.br</a>
</p>
<p>Felipe Carvalho, <a href="mailto:felipe.carvalho@inpe.br">felipe.carvalho@inpe.br</a>
</p>
<p>Gilberto Camara, <a href="mailto:gilberto.camara@inpe.br">gilberto.camara@inpe.br</a>
</p>


<h3>References</h3>

<p>Robert Monarch, &quot;Human-in-the-Loop Machine Learning: Active learning
and annotation for human-centered AI&quot;. Manning Publications, 2021.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (sits_run_examples()) {
    # create a data cube
    data_dir &lt;- system.file("extdata/raster/mod13q1", package = "sits")
    cube &lt;- sits_cube(
        source = "BDC",
        collection = "MOD13Q1-6",
        data_dir = data_dir
    )
    # build a random forest model
    rfor_model &lt;- sits_train(samples_modis_ndvi, ml_method = sits_rfor())
    # classify the cube
    probs_cube &lt;- sits_classify(
        data = cube, ml_model = rfor_model, output_dir = tempdir()
    )
    # create an uncertainty cube
    uncert_cube &lt;- sits_uncertainty(probs_cube,
        type = "entropy",
        output_dir = tempdir()
    )
    # obtain a new set of samples for active learning
    # the samples are located in uncertain places
    new_samples &lt;- sits_uncertainty_sampling(
        uncert_cube,
        n = 10, min_uncert = 0.4
    )
}

</code></pre>

<hr>
<h2 id='sits_validate'>Validate time series samples</h2><span id='topic+sits_validate'></span>

<h3>Description</h3>

<p>One round of cross-validation involves partitioning a sample of data
into complementary subsets, performing the analysis on one subset
(called the training set), and validating the analysis on the other subset
(called the validation set or testing set).
</p>
<p>The function takes two arguments: a set of time series
with a machine learning model and another set with validation samples.
If the validation sample set is not provided,
The sample dataset is split into two parts, as defined by the parameter
validation_split. The accuracy is determined by the result of
the validation test set.
</p>
<p>This function returns the confusion matrix, and Kappa values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sits_validate(
  samples,
  samples_validation = NULL,
  validation_split = 0.2,
  ml_method = sits_rfor()
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sits_validate_+3A_samples">samples</code></td>
<td>
<p>Time series to be validated (class &quot;sits&quot;).</p>
</td></tr>
<tr><td><code id="sits_validate_+3A_samples_validation">samples_validation</code></td>
<td>
<p>Optional: Time series used for validation
(class &quot;sits&quot;)</p>
</td></tr>
<tr><td><code id="sits_validate_+3A_validation_split">validation_split</code></td>
<td>
<p>Percent of original time series set to be used
for validation if samples_validation is NULL
(numeric value).</p>
</td></tr>
<tr><td><code id="sits_validate_+3A_ml_method">ml_method</code></td>
<td>
<p>Machine learning method (function)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code>caret::confusionMatrix</code> object to be used for
validation assessment.
</p>


<h3>Author(s)</h3>

<p>Rolf Simoes, <a href="mailto:rolf.simoes@inpe.br">rolf.simoes@inpe.br</a>
</p>
<p>Gilberto Camara, <a href="mailto:gilberto.camara@inpe.br">gilberto.camara@inpe.br</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (sits_run_examples()) {
    samples &lt;- sits_sample(cerrado_2classes, frac = 0.5)
    samples_validation &lt;- sits_sample(cerrado_2classes, frac = 0.5)
    conf_matrix_1 &lt;- sits_validate(
         samples = samples,
         samples_validation = samples_validation,
         ml_method = sits_rfor()
   )
   conf_matrix_2 &lt;- sits_validate(
         samples = cerrado_2classes,
         validation_split = 0.2,
         ml_method = sits_rfor()
   )
}
</code></pre>

<hr>
<h2 id='sits_variance'>Calculate the variance of a probability cube</h2><span id='topic+sits_variance'></span><span id='topic+sits_variance.probs_cube'></span><span id='topic+sits_variance.raster_cube'></span><span id='topic+sits_variance.derived_cube'></span><span id='topic+sits_variance.tbl_df'></span><span id='topic+sits_variance.default'></span>

<h3>Description</h3>

<p>Takes a probability cube and estimate the local variance
of the logit of the probability,
to support the choice of parameters for Bayesian smoothing.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sits_variance(
  cube,
  window_size = 9L,
  neigh_fraction = 0.5,
  memsize = 4L,
  multicores = 2L,
  output_dir,
  version = "v1"
)

## S3 method for class 'probs_cube'
sits_variance(
  cube,
  window_size = 9L,
  neigh_fraction = 0.5,
  memsize = 4L,
  multicores = 2L,
  output_dir,
  version = "v1"
)

## S3 method for class 'raster_cube'
sits_variance(
  cube,
  window_size = 7L,
  neigh_fraction = 0.5,
  memsize = 4L,
  multicores = 2L,
  output_dir,
  version = "v1"
)

## S3 method for class 'derived_cube'
sits_variance(
  cube,
  window_size = 7L,
  neigh_fraction = 0.5,
  memsize = 4L,
  multicores = 2L,
  output_dir,
  version = "v1"
)

## S3 method for class 'tbl_df'
sits_variance(
  cube,
  window_size = 7L,
  neigh_fraction = 0.5,
  memsize = 4L,
  multicores = 2L,
  output_dir,
  version = "v1"
)

## Default S3 method:
sits_variance(
  cube,
  window_size = 7L,
  neigh_fraction = 0.5,
  memsize = 4L,
  multicores = 2L,
  output_dir,
  version = "v1"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sits_variance_+3A_cube">cube</code></td>
<td>
<p>Probability data cube (class &quot;probs_cube&quot;)</p>
</td></tr>
<tr><td><code id="sits_variance_+3A_window_size">window_size</code></td>
<td>
<p>Size of the neighborhood (odd integer)</p>
</td></tr>
<tr><td><code id="sits_variance_+3A_neigh_fraction">neigh_fraction</code></td>
<td>
<p>Fraction of neighbors with highest probability
for Bayesian inference (numeric from 0.0 to 1.0)</p>
</td></tr>
<tr><td><code id="sits_variance_+3A_memsize">memsize</code></td>
<td>
<p>Maximum overall memory (in GB) to run the
smoothing (integer, min = 1, max = 16384)</p>
</td></tr>
<tr><td><code id="sits_variance_+3A_multicores">multicores</code></td>
<td>
<p>Number of cores to run the smoothing function
(integer, min = 1, max = 2048)</p>
</td></tr>
<tr><td><code id="sits_variance_+3A_output_dir">output_dir</code></td>
<td>
<p>Output directory for image files
(character vector of length 1)</p>
</td></tr>
<tr><td><code id="sits_variance_+3A_version">version</code></td>
<td>
<p>Version of resulting image
(character vector of length 1)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A variance data cube.
</p>


<h3>Note</h3>

<p>Please refer to the sits documentation available in
&lt;https://e-sensing.github.io/sitsbook/&gt; for detailed examples.
</p>


<h3>Author(s)</h3>

<p>Gilberto Camara, <a href="mailto:gilberto.camara@inpe.br">gilberto.camara@inpe.br</a>
</p>
<p>Rolf Simoes, <a href="mailto:rolf.simoes@inpe.br">rolf.simoes@inpe.br</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (sits_run_examples()) {
    # create a ResNet model
    rfor_model &lt;- sits_train(samples_modis_ndvi, sits_rfor())
    # create a data cube from local files
    data_dir &lt;- system.file("extdata/raster/mod13q1", package = "sits")
    cube &lt;- sits_cube(
        source = "BDC",
        collection = "MOD13Q1-6",
        data_dir = data_dir
    )
    # classify a data cube
    probs_cube &lt;- sits_classify(
        data = cube, ml_model = rfor_model, output_dir = tempdir()
    )
    # plot the probability cube
    plot(probs_cube)
    # smooth the probability cube using Bayesian statistics
    var_cube &lt;- sits_variance(probs_cube, output_dir = tempdir())
    # plot the variance cube
    plot(var_cube)
}
</code></pre>

<hr>
<h2 id='sits_view'>View data cubes and samples in leaflet</h2><span id='topic+sits_view'></span><span id='topic+sits_view.sits'></span><span id='topic+sits_view.data.frame'></span><span id='topic+sits_view.som_map'></span><span id='topic+sits_view.raster_cube'></span><span id='topic+sits_view.vector_cube'></span><span id='topic+sits_view.uncertainty_cube'></span><span id='topic+sits_view.class_cube'></span><span id='topic+sits_view.probs_cube'></span><span id='topic+sits_view.default'></span>

<h3>Description</h3>

<p>Uses leaflet to visualize time series, raster cube and
classified images
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sits_view(x, ...)

## S3 method for class 'sits'
sits_view(x, ..., legend = NULL, palette = "Harmonic")

## S3 method for class 'data.frame'
sits_view(x, ..., legend = NULL, palette = "Harmonic")

## S3 method for class 'som_map'
sits_view(x, ..., id_neurons, legend = NULL, palette = "Harmonic")

## S3 method for class 'raster_cube'
sits_view(
  x,
  ...,
  band = NULL,
  red = NULL,
  green = NULL,
  blue = NULL,
  tiles = x$tile,
  dates = NULL,
  class_cube = NULL,
  legend = NULL,
  palette = "RdYlGn",
  opacity = 0.7,
  view_max_mb = NULL
)

## S3 method for class 'vector_cube'
sits_view(
  x,
  ...,
  band = NULL,
  red = NULL,
  green = NULL,
  blue = NULL,
  tiles = x$tile,
  dates = NULL,
  class_cube = NULL,
  legend = NULL,
  palette = "RdYlGn",
  opacity = 0.7,
  seg_color = "black",
  line_width = 1,
  view_max_mb = NULL
)

## S3 method for class 'uncertainty_cube'
sits_view(
  x,
  ...,
  tiles = x$tile,
  class_cube = NULL,
  legend = NULL,
  palette = "Blues",
  opacity = 0.7,
  view_max_mb = NULL
)

## S3 method for class 'class_cube'
sits_view(
  x,
  ...,
  tiles = NULL,
  legend = NULL,
  palette = "Spectral",
  opacity = 0.8,
  view_max_mb = NULL
)

## S3 method for class 'probs_cube'
sits_view(
  x,
  ...,
  tiles = x$tile,
  class_cube = NULL,
  legend = NULL,
  view_max_mb = NULL,
  opacity = 0.7,
  palette = "YlGnBu"
)

## Default S3 method:
sits_view(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sits_view_+3A_x">x</code></td>
<td>
<p>Object of class &quot;sits&quot;, &quot;data.frame&quot;, &quot;som_map&quot;,
&quot;raster_cube&quot; or &quot;classified image&quot;.</p>
</td></tr>
<tr><td><code id="sits_view_+3A_...">...</code></td>
<td>
<p>Further specifications for <a href="#topic+sits_view">sits_view</a>.</p>
</td></tr>
<tr><td><code id="sits_view_+3A_legend">legend</code></td>
<td>
<p>Named vector that associates labels to colors.</p>
</td></tr>
<tr><td><code id="sits_view_+3A_palette">palette</code></td>
<td>
<p>Color palette (if colors not in legend nor
in sits default colors)</p>
</td></tr>
<tr><td><code id="sits_view_+3A_id_neurons">id_neurons</code></td>
<td>
<p>Neurons from the SOM map to be shown.</p>
</td></tr>
<tr><td><code id="sits_view_+3A_band">band</code></td>
<td>
<p>For plotting grey images.</p>
</td></tr>
<tr><td><code id="sits_view_+3A_red">red</code></td>
<td>
<p>Band for red color.</p>
</td></tr>
<tr><td><code id="sits_view_+3A_green">green</code></td>
<td>
<p>Band for green color.</p>
</td></tr>
<tr><td><code id="sits_view_+3A_blue">blue</code></td>
<td>
<p>Band for blue color.</p>
</td></tr>
<tr><td><code id="sits_view_+3A_tiles">tiles</code></td>
<td>
<p>Tiles to be plotted (in case of a multi-tile cube).</p>
</td></tr>
<tr><td><code id="sits_view_+3A_dates">dates</code></td>
<td>
<p>Dates to be plotted.</p>
</td></tr>
<tr><td><code id="sits_view_+3A_class_cube">class_cube</code></td>
<td>
<p>Classified cube to be overlayed on top on image.</p>
</td></tr>
<tr><td><code id="sits_view_+3A_opacity">opacity</code></td>
<td>
<p>Opacity of segment fill or class cube</p>
</td></tr>
<tr><td><code id="sits_view_+3A_view_max_mb">view_max_mb</code></td>
<td>
<p>Maximum size of leaflet to be visualized</p>
</td></tr>
<tr><td><code id="sits_view_+3A_seg_color">seg_color</code></td>
<td>
<p>Color for segment boundaries</p>
</td></tr>
<tr><td><code id="sits_view_+3A_line_width">line_width</code></td>
<td>
<p>Line width for segments (in pixels)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A leaflet object containing either samples or
data cubes embedded in a global map that can
be visualized directly in an RStudio viewer.
</p>


<h3>Note</h3>

<p>Please refer to the sits documentation available in
&lt;https://e-sensing.github.io/sitsbook/&gt; for detailed examples.
</p>


<h3>Author(s)</h3>

<p>Gilberto Camara, <a href="mailto:gilberto.camara@inpe.br">gilberto.camara@inpe.br</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (sits_run_examples()) {
    # view samples
    sits_view(cerrado_2classes)
    # create a local data cube
    data_dir &lt;- system.file("extdata/raster/mod13q1", package = "sits")
    modis_cube &lt;- sits_cube(
        source = "BDC",
        collection = "MOD13Q1-6",
        data_dir = data_dir
    )
    # view the data cube
    sits_view(modis_cube,
        band = "NDVI"
    )
    # train a model
    rf_model &lt;- sits_train(samples_modis_ndvi, sits_rfor())
    # classify the cube
    modis_probs &lt;- sits_classify(
        data = modis_cube,
        ml_model = rf_model,
        output_dir = tempdir()
    )
    # view the probs
    sits_view(modis_probs)
    # generate a map
    modis_label &lt;- sits_label_classification(
        modis_probs,
        output_dir = tempdir()
    )
    # view the classified map
    sits_view(modis_label)
    # view the classified map with the B/W image
    sits_view(modis_cube,
        band = "NDVI",
        class_cube = modis_label,
        dates = sits_timeline(modis_cube)[[1]]
    )
    # view the classified map with the RGB image
    sits_view(modis_cube,
        red = "NDVI", green = "NDVI", blue = "NDVI",
        class_cube = modis_label,
        dates = sits_timeline(modis_cube)[[1]]
    )
    # create an uncertainty cube
    modis_uncert &lt;- sits_uncertainty(
        cube = modis_probs,
        output_dir = tempdir()
    )
    # view the uncertainty cube
    sits_view(modis_uncert)
}
</code></pre>

<hr>
<h2 id='sits_whittaker'>Filter time series with whittaker filter</h2><span id='topic+sits_whittaker'></span>

<h3>Description</h3>

<p>The algorithm searches for an optimal warping polynomial.
The degree of smoothing depends on smoothing factor lambda
(usually from 0.5 to 10.0). Use lambda = 0.5 for very slight smoothing
and lambda = 5.0 for strong smoothing.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sits_whittaker(data = NULL, lambda = 0.5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sits_whittaker_+3A_data">data</code></td>
<td>
<p>Time series or matrix.</p>
</td></tr>
<tr><td><code id="sits_whittaker_+3A_lambda">lambda</code></td>
<td>
<p>Smoothing factor to be applied (default 0.5).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Filtered time series
</p>


<h3>Author(s)</h3>

<p>Rolf Simoes, <a href="mailto:rolf.simoes@inpe.br">rolf.simoes@inpe.br</a>
</p>
<p>Gilberto Camara, <a href="mailto:gilberto.camara@inpe.br">gilberto.camara@inpe.br</a>
</p>
<p>Felipe Carvalho, <a href="mailto:felipe.carvalho@inpe.br">felipe.carvalho@inpe.br</a>
</p>


<h3>References</h3>

<p>Francesco Vuolo, Wai-Tim Ng, Clement Atzberger,
&quot;Smoothing and gap-filling of high resolution multi-spectral time series:
Example of Landsat data&quot;,
Int Journal of Applied Earth Observation and Geoinformation,
vol. 57, pg. 202-213, 2107.
</p>


<h3>See Also</h3>

<p><a href="#topic+sits_apply">sits_apply</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (sits_run_examples()) {
    # Retrieve a time series with values of NDVI
    point_ndvi &lt;- sits_select(point_mt_6bands, bands = "NDVI")
    # Filter the point using the Whittaker smoother
    point_whit &lt;- sits_filter(point_ndvi, sits_whittaker(lambda = 3.0))
    # Merge time series
    point_ndvi &lt;- sits_merge(point_ndvi, point_whit,
                            suffix = c("", ".WHIT"))
    # Plot the two points to see the smoothing effect
    plot(point_ndvi)
}
</code></pre>

<hr>
<h2 id='sits_xgboost'>Train extreme gradient boosting models</h2><span id='topic+sits_xgboost'></span>

<h3>Description</h3>

<p>This function uses the extreme gradient boosting algorithm.
Boosting iteratively adds basis functions in a greedy fashion
so that each new basis function further reduces the selected loss function.
This function is a front-end to the methods in the &quot;xgboost&quot; package.
Please refer to the documentation in that package for more details.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sits_xgboost(
  samples = NULL,
  learning_rate = 0.15,
  min_split_loss = 1,
  max_depth = 5,
  min_child_weight = 1,
  max_delta_step = 1,
  subsample = 0.8,
  nfold = 5,
  nrounds = 100,
  early_stopping_rounds = 20,
  verbose = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sits_xgboost_+3A_samples">samples</code></td>
<td>
<p>Time series with the training samples.</p>
</td></tr>
<tr><td><code id="sits_xgboost_+3A_learning_rate">learning_rate</code></td>
<td>
<p>Learning rate: scale the contribution
of each tree by a factor of 0 &lt; lr &lt; 1
when it is added to the current approximation.
Used to prevent overfitting. Default: 0.15</p>
</td></tr>
<tr><td><code id="sits_xgboost_+3A_min_split_loss">min_split_loss</code></td>
<td>
<p>Minimum loss reduction to make a further
partition of a leaf.  Default: 1.</p>
</td></tr>
<tr><td><code id="sits_xgboost_+3A_max_depth">max_depth</code></td>
<td>
<p>Maximum depth of a tree.
Increasing this value makes the model more complex
and more likely to overfit. Default: 5.</p>
</td></tr>
<tr><td><code id="sits_xgboost_+3A_min_child_weight">min_child_weight</code></td>
<td>
<p>If the leaf node has a minimum sum of instance
weights lower than min_child_weight,
tree splitting stops. The larger min_child_weight is,
the more conservative the algorithm is. Default: 1.</p>
</td></tr>
<tr><td><code id="sits_xgboost_+3A_max_delta_step">max_delta_step</code></td>
<td>
<p>Maximum delta step we allow each leaf output to be.
If the value is set to 0, there is no constraint.
If it is set to a positive value, it can help making
the update step more conservative. Default: 1.</p>
</td></tr>
<tr><td><code id="sits_xgboost_+3A_subsample">subsample</code></td>
<td>
<p>Percentage of samples supplied to a tree.
Default: 0.8.</p>
</td></tr>
<tr><td><code id="sits_xgboost_+3A_nfold">nfold</code></td>
<td>
<p>Number of the subsamples for the cross-validation.</p>
</td></tr>
<tr><td><code id="sits_xgboost_+3A_nrounds">nrounds</code></td>
<td>
<p>Number of rounds to iterate the cross-validation
(default: 100)</p>
</td></tr>
<tr><td><code id="sits_xgboost_+3A_early_stopping_rounds">early_stopping_rounds</code></td>
<td>
<p>Training with a validation set will stop
if the performance doesn't improve for k rounds.</p>
</td></tr>
<tr><td><code id="sits_xgboost_+3A_verbose">verbose</code></td>
<td>
<p>Print information on statistics during the process</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Model fitted to input data
(to be passed to <code><a href="#topic+sits_classify">sits_classify</a></code>)
</p>


<h3>Note</h3>

<p>Please refer to the sits documentation available in
&lt;https://e-sensing.github.io/sitsbook/&gt; for detailed examples.
</p>


<h3>Author(s)</h3>

<p>Rolf Simoes, <a href="mailto:rolf.simoes@inpe.br">rolf.simoes@inpe.br</a>
</p>
<p>Gilberto Camara, <a href="mailto:gilberto.camara@inpe.br">gilberto.camara@inpe.br</a>
</p>


<h3>References</h3>

<p>Tianqi Chen, Carlos Guestrin,
&quot;XGBoost : Reliable Large-scale Tree Boosting System&quot;,
SIG KDD 2016.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (sits_run_examples()) {
    # Example of training a model for time series classification
    # Retrieve the samples for Mato Grosso
    # train a xgboost model
    ml_model &lt;- sits_train(samples_modis_ndvi, ml_method = sits_xgboost)
    # classify the point
    point_ndvi &lt;- sits_select(point_mt_6bands, bands = "NDVI")
    # classify the point
    point_class &lt;- sits_classify(
        data = point_ndvi, ml_model = ml_model
    )
    plot(point_class)
}
</code></pre>

<hr>
<h2 id='summary.class_cube'>Summarize data cubes</h2><span id='topic+summary.class_cube'></span>

<h3>Description</h3>

<p>This is a generic function. Parameters depend on the specific
type of input.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'class_cube'
summary(object, ..., tile = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.class_cube_+3A_object">object</code></td>
<td>
<p>Object of class &quot;class_cube&quot;</p>
</td></tr>
<tr><td><code id="summary.class_cube_+3A_...">...</code></td>
<td>
<p>Further specifications for <a href="base.html#topic+summary">summary</a>.</p>
</td></tr>
<tr><td><code id="summary.class_cube_+3A_tile">tile</code></td>
<td>
<p>Tile to be summarized</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A summary of a classified cube
</p>


<h3>Author(s)</h3>

<p>Gilberto Camara, <a href="mailto:gilberto.camara@inpe.br">gilberto.camara@inpe.br</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (sits_run_examples()) {
    # create a data cube from local files
    data_dir &lt;- system.file("extdata/raster/mod13q1", package = "sits")
    cube &lt;- sits_cube(
        source = "BDC",
        collection = "MOD13Q1-6",
        data_dir = data_dir
    )
    # create a random forest model
    rfor_model &lt;- sits_train(samples_modis_ndvi, sits_rfor())
    # classify a data cube
    probs_cube &lt;- sits_classify(
        data = cube, ml_model = rfor_model, output_dir = tempdir()
    )
    # label the probability cube
    label_cube &lt;- sits_label_classification(
        probs_cube,
        output_dir = tempdir()
    )
    summary(label_cube)
}
</code></pre>

<hr>
<h2 id='summary.raster_cube'>Summarize data cubes</h2><span id='topic+summary.raster_cube'></span>

<h3>Description</h3>

<p>This is a generic function. Parameters depend on the specific
type of input.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'raster_cube'
summary(object, ..., tile = NULL, date = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.raster_cube_+3A_object">object</code></td>
<td>
<p>Object of classes &quot;raster_cube&quot;.</p>
</td></tr>
<tr><td><code id="summary.raster_cube_+3A_...">...</code></td>
<td>
<p>Further specifications for <a href="base.html#topic+summary">summary</a>.</p>
</td></tr>
<tr><td><code id="summary.raster_cube_+3A_tile">tile</code></td>
<td>
<p>Tile to be summarized</p>
</td></tr>
<tr><td><code id="summary.raster_cube_+3A_date">date</code></td>
<td>
<p>Date to be summarized</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A summary of the data cube.
</p>


<h3>Author(s)</h3>

<p>Gilberto Camara, <a href="mailto:gilberto.camara@inpe.br">gilberto.camara@inpe.br</a>
</p>
<p>Felipe Souza, <a href="mailto:felipe.souza@inpe.br">felipe.souza@inpe.br</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (sits_run_examples()) {
    # create a data cube from local files
    data_dir &lt;- system.file("extdata/raster/mod13q1", package = "sits")
    cube &lt;- sits_cube(
        source = "BDC",
        collection = "MOD13Q1-6",
        data_dir = data_dir
    )
    summary(cube)
}

</code></pre>

<hr>
<h2 id='summary.sits'>Summarize sits</h2><span id='topic+summary.sits'></span>

<h3>Description</h3>

<p>This is a generic function. Parameters depend on the specific
type of input.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'sits'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.sits_+3A_object">object</code></td>
<td>
<p>Object of classes &quot;sits&quot;.</p>
</td></tr>
<tr><td><code id="summary.sits_+3A_...">...</code></td>
<td>
<p>Further specifications for <a href="base.html#topic+summary">summary</a>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A summary of the sits tibble.
</p>


<h3>Author(s)</h3>

<p>Gilberto Camara, <a href="mailto:gilberto.camara@inpe.br">gilberto.camara@inpe.br</a>
</p>
<p>Felipe Souza, <a href="mailto:felipe.souza@inpe.br">felipe.souza@inpe.br</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (sits_run_examples()) {
    summary(samples_modis_ndvi)
}

</code></pre>

<hr>
<h2 id='summary.sits_accuracy'>Summarize accuracy matrix for training data</h2><span id='topic+summary.sits_accuracy'></span>

<h3>Description</h3>

<p>This is a generic function. Parameters depend on the specific
type of input.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'sits_accuracy'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.sits_accuracy_+3A_object">object</code></td>
<td>
<p>Object of classe &quot;sits_accuracy&quot;.</p>
</td></tr>
<tr><td><code id="summary.sits_accuracy_+3A_...">...</code></td>
<td>
<p>Further specifications for <a href="base.html#topic+summary">summary</a>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A summary of the sample accuracy
</p>


<h3>Author(s)</h3>

<p>Gilberto Camara, <a href="mailto:gilberto.camara@inpe.br">gilberto.camara@inpe.br</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (sits_run_examples()) {
    data(cerrado_2classes)
    # split training and test data
    train_data &lt;- sits_sample(cerrado_2classes, frac = 0.5)
    test_data  &lt;- sits_sample(cerrado_2classes, frac = 0.5)
    # train a random forest model
    rfor_model &lt;- sits_train(train_data, sits_rfor())
    # classify test data
    points_class &lt;- sits_classify(
        data = test_data,
        ml_model = rfor_model
    )
    # measure accuracy
    acc &lt;- sits_accuracy(points_class)
    summary(acc)
}

</code></pre>

<hr>
<h2 id='summary.sits_area_accuracy'>Summarize accuracy matrix for area data</h2><span id='topic+summary.sits_area_accuracy'></span>

<h3>Description</h3>

<p>This is a generic function. Parameters depend on the specific
type of input.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'sits_area_accuracy'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.sits_area_accuracy_+3A_object">object</code></td>
<td>
<p>Object of classe &quot;sits_accuracy&quot;.</p>
</td></tr>
<tr><td><code id="summary.sits_area_accuracy_+3A_...">...</code></td>
<td>
<p>Further specifications for <a href="base.html#topic+summary">summary</a>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A summary of the sample accuracy
</p>


<h3>Author(s)</h3>

<p>Gilberto Camara, <a href="mailto:gilberto.camara@inpe.br">gilberto.camara@inpe.br</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (sits_run_examples()) {
    # create a data cube from local files
    data_dir &lt;- system.file("extdata/raster/mod13q1", package = "sits")
    cube &lt;- sits_cube(
        source = "BDC",
        collection = "MOD13Q1-6",
        data_dir = data_dir
    )
    # create a random forest model
    rfor_model &lt;- sits_train(samples_modis_ndvi, sits_rfor())
    # classify a data cube
    probs_cube &lt;- sits_classify(
        data = cube, ml_model = rfor_model, output_dir = tempdir()
    )
    # label the probability cube
    label_cube &lt;- sits_label_classification(
        probs_cube,
        output_dir = tempdir()
    )
    # obtain the ground truth for accuracy assessment
    ground_truth &lt;- system.file("extdata/samples/samples_sinop_crop.csv",
        package = "sits"
    )
    # make accuracy assessment
    as &lt;- sits_accuracy(label_cube, validation = ground_truth)
    summary(as)
}

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
