<!DOCTYPE html><html lang="en"><head><title>Help for package TSLA</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {TSLA}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#TSLA-package'><p>Tree-Guided Rare Feature Selection and Logic Aggregation</p></a></li>
<li><a href='#cal2norm'><p>Calculate group norms</p></a></li>
<li><a href='#ClassificationExample'><p>Synthesic for the classification example</p></a></li>
<li><a href='#coef_TSLA'><p>Get coefficients from a fitted TSLA model</p></a></li>
<li><a href='#cv.TSLA'><p>Cross validation for TSLA</p></a></li>
<li><a href='#get_tree_object'><p>Tree-guided reparameterization</p></a></li>
<li><a href='#getaggr'><p>Generate aggregated features</p></a></li>
<li><a href='#getetmat'><p>Tree-guided expansion</p></a></li>
<li><a href='#getperform'><p>Get performance metrics for classification</p></a></li>
<li><a href='#plot_TSLA'><p>Plot aggregated structure</p></a></li>
<li><a href='#predict_cvTSLA'><p>Prediction from cross validation</p></a></li>
<li><a href='#predict_TSLA'><p>Prediction from TSLA with new data</p></a></li>
<li><a href='#RegressionExample'><p>Synthesic for the regression example</p></a></li>
<li><a href='#TSLA.fit'><p>Solve the TSLA optimization problem</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Tree-Guided Rare Feature Selection and Logic Aggregation</td>
</tr>
<tr>
<td>Version:</td>
<td>0.1.2</td>
</tr>
<tr>
<td>Imports:</td>
<td>stats, Matrix, Rcpp, pROC, PRROC, ape, phytools, data.tree</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp, RcppArmadillo</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Jianmin Chen &lt;jianminc000@gmail.com&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Implementation of the tree-guided feature selection and logic aggregation approach introduced in Chen et al. (2024) &lt;<a href="https://doi.org/10.1080%2F01621459.2024.2326621">doi:10.1080/01621459.2024.2326621</a>&gt;. The method enables the selection and aggregation of large-scale rare binary features with a known hierarchical structure using a convex, linearly-constrained regularized regression framework. The package facilitates the application of this method to both linear regression and binary classification problems by solving the optimization problem via the smoothing proximal gradient descent algorithm (Chen et al. (2012) &lt;<a href="https://doi.org/10.1214%2F11-AOAS514">doi:10.1214/11-AOAS514</a>&gt;).</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 4.1.0)</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.1</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2025-03-17 13:12:23 UTC; cjm</td>
</tr>
<tr>
<td>Author:</td>
<td>Jianmin Chen [aut, cre],
  Kun Chen [aut]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2025-03-17 20:20:05 UTC</td>
</tr>
</table>
<hr>
<h2 id='TSLA-package'>Tree-Guided Rare Feature Selection and Logic Aggregation</h2><span id='topic+TSLA-package'></span>

<h3>Description</h3>

<p>This package provides functions and visualization tools for fitting the
Tree-Guided Rare Feature Selection and Logic Aggregation model.
</p>


<h3>Author(s)</h3>

<p>Jianmin Chen <a href="mailto:jianminc000@gmail.com">jianminc000@gmail.com</a>, Kun Chen
</p>

<hr>
<h2 id='cal2norm'>Calculate group norms</h2><span id='topic+cal2norm'></span>

<h3>Description</h3>

<p>Function to output group norms on the gamma coefficients
based on <code>g_idx</code> and <code>C2</code> matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cal2norm(u, g_idx, type)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cal2norm_+3A_u">u</code></td>
<td>
<p><code>C2*gamma.coef</code>, <code>gamma.coef</code> is the estimated node coefficient vector,
<code>C2</code> matrix is the output from
function <code>get_tree_object()</code>, which gives the weights of the groups.</p>
</td></tr>
<tr><td><code id="cal2norm_+3A_g_idx">g_idx</code></td>
<td>
<p>Group structure matrix defined by the <code>C2</code> matrix.
See details in <code>get_tree_object()</code>.</p>
</td></tr>
<tr><td><code id="cal2norm_+3A_type">type</code></td>
<td>
<p>If <code>type == 1</code>, return sum of group norms; else return individual
norm for each group.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Sum of group norms or individual group norms.
</p>

<hr>
<h2 id='ClassificationExample'>Synthesic for the classification example</h2><span id='topic+ClassificationExample'></span>

<h3>Description</h3>

<p>Synthetic data used to illustrate how to use TSLA with classification.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(ClassificationExample)
</code></pre>


<h3>Format</h3>

<p>List containing the following elements:
</p>

<dl>
<dt>tree.org</dt><dd><p>Original tree structure with 42 leaf nodes and 5 different levels.</p>
</dd>
<dt>x.org</dt><dd><p>Original design matrix with 42 binary features and 400 observations.</p>
</dd>
<dt>x1</dt><dd><p>Unpenalized covariate.</p>
</dd>
<dt>y</dt><dd><p>Continuous response of length 400.</p>
</dd>
</dl>


<hr>
<h2 id='coef_TSLA'>Get coefficients from a fitted TSLA model</h2><span id='topic+coef_TSLA'></span>

<h3>Description</h3>

<p>Get coefficients from a TSLA.fit object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>coef_TSLA(object, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="coef_TSLA_+3A_object">object</code></td>
<td>
<p>A fit output from <code>TSLA.fit()</code>.</p>
</td></tr>
<tr><td><code id="coef_TSLA_+3A_...">...</code></td>
<td>
<p>Other parameters.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of coefficients for each combination of <code class="reqn">\lambda</code> and
<code class="reqn">\alpha</code>.
The first dimension is indexed by the coefficient,
the second dimension is indexed by <code class="reqn">\lambda</code>,
and the third dimension is
indexed by <code class="reqn">\alpha</code>.
</p>
<table role = "presentation">
<tr><td><code>Intercept</code></td>
<td>
<p>Intercept.</p>
</td></tr>
<tr><td><code>cov.coef</code></td>
<td>
<p>Coefficients for unpenalized features.</p>
</td></tr>
<tr><td><code>gamma.coef</code></td>
<td>
<p>Node coefficients. Also see details in <code>getetmat()</code>.</p>
</td></tr>
<tr><td><code>beta.coef</code></td>
<td>
<p>Regression coefficients. Each coefficient is multiplied by
<code class="reqn">(-1)^{r-1}</code>, where r is the order of the corresponding interaction term.
Also see details in <code>getetmat()</code>.</p>
</td></tr>
<tr><td><code>beta.coef.adj</code></td>
<td>
<p>Regression coefficients <code class="reqn">\beta</code>.
This is the common regression coefficient vector.
It corresponds to <code>x.expand.adj</code> and
<code>A.adj</code>.</p>
</td></tr>
</table>

<hr>
<h2 id='cv.TSLA'>Cross validation for TSLA</h2><span id='topic+cv.TSLA'></span>

<h3>Description</h3>

<p>Conduct cross validation to select the optimal tuning parameters in TSLA.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cv.TSLA(
  y,
  X_1 = NULL,
  X_2,
  treemat,
  family = c("ls", "logit"),
  penalty = c("CL2", "RFS-Sum"),
  pred.loss = c("MSE", "AUC", "deviance"),
  gamma.init = NULL,
  weight = NULL,
  nfolds = 5,
  group.weight = NULL,
  feature.weight = NULL,
  control = list(),
  modstr = list()
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cv.TSLA_+3A_y">y</code></td>
<td>
<p>Response in matrix form, continuous for <code>family = "ls"</code> and binary (0/1)
for <code>family = "logit"</code>.</p>
</td></tr>
<tr><td><code id="cv.TSLA_+3A_x_1">X_1</code></td>
<td>
<p>Design matrix for unpenalized features (excluding intercept). Need to be in the matrix form.</p>
</td></tr>
<tr><td><code id="cv.TSLA_+3A_x_2">X_2</code></td>
<td>
<p>Expanded design matrix for <code>penalty = "CL2"</code>; Original design matrix
for <code>penalty = "RFS-Sum"</code>. Need to be in the matrix form.</p>
</td></tr>
<tr><td><code id="cv.TSLA_+3A_treemat">treemat</code></td>
<td>
<p>Expanded tree structure in matrix form for
<code>penalty = "CL2"</code>; Original structure for <code>penalty = "RFS-Sum"</code>.</p>
</td></tr>
<tr><td><code id="cv.TSLA_+3A_family">family</code></td>
<td>
<p>Two options. Use &quot;ls&quot; for least square problems and &quot;logit&quot;
for logistic regression problems.</p>
</td></tr>
<tr><td><code id="cv.TSLA_+3A_penalty">penalty</code></td>
<td>
<p>Two options for group penalty on <code class="reqn">\gamma</code>, &quot;CL2&quot; or &quot;RFS-Sum&quot;.</p>
</td></tr>
<tr><td><code id="cv.TSLA_+3A_pred.loss">pred.loss</code></td>
<td>
<p>Model performance metrics. If <code>family="ls"</code>, default
is &quot;MSE&quot; (mean squared error). If <code>family="logit"</code>, default is &quot;AUC&quot;. For logistic
model, another option is &quot;deviance&quot;.</p>
</td></tr>
<tr><td><code id="cv.TSLA_+3A_gamma.init">gamma.init</code></td>
<td>
<p>Initial value for the optimization. Default is a zero vector.
The length should equal to 1+<code>ncol(X_1)</code>+<code>ncol(A)</code>.
See details of A in <code>get_tree_obj()</code>.</p>
</td></tr>
<tr><td><code id="cv.TSLA_+3A_weight">weight</code></td>
<td>
<p>A vector of length two and it is used for logistic regression
only. The first element corresponds to weight of y=1 and the
second element corresponds to weight of y=0.</p>
</td></tr>
<tr><td><code id="cv.TSLA_+3A_nfolds">nfolds</code></td>
<td>
<p>Number of cross validation folds. Default is 5.</p>
</td></tr>
<tr><td><code id="cv.TSLA_+3A_group.weight">group.weight</code></td>
<td>
<p>User-defined weights for group penalty. Need to be a vector
and the length equals to the number of groups.</p>
</td></tr>
<tr><td><code id="cv.TSLA_+3A_feature.weight">feature.weight</code></td>
<td>
<p>User-defined weights for each predictor after expansion.</p>
</td></tr>
<tr><td><code id="cv.TSLA_+3A_control">control</code></td>
<td>
<p>A list of parameters controlling algorithm convergence. Default values:
<code>tol = 1e-5</code>, convergence tolerance; <code>maxit = 10000</code>,
maximum number of iterations; <code>mu = 1e-3</code>, smoothness parameter in SPG.</p>
</td></tr>
<tr><td><code id="cv.TSLA_+3A_modstr">modstr</code></td>
<td>
<p>A list of parameters controlling tuning parameters. Default values:
<code>lambda = NULL</code>. If lambda is not provided, the package will give a default lambda sequence;
<code>lambda.min.ratio = 1e-04</code>, smallest value for lambda as
a fraction of lambda.max (given by default when lambda is NULL);
<code>nlambda = 50</code>,
number of lambda values (equal spacing on log scale) used when lambda is NULL;
<code>alpha = seq(0, 1, length.out = 10)</code>, sequence of alpha. Here, alpha is
tuning parameter for generalized lasso penalty and 1-alpha is the tuning
parameter for group lasso penalty.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of cross validation results.
</p>
<table role = "presentation">
<tr><td><code>lambda.min</code></td>
<td>
<p><code class="reqn">\lambda</code> value with best prediction performance.</p>
</td></tr>
<tr><td><code>alpha.min</code></td>
<td>
<p><code class="reqn">\alpha</code> value with best prediction performance.</p>
</td></tr>
<tr><td><code>cvm</code></td>
<td>
<p>A (number-of-lambda * number-of-alpha) matrix saving the means of cross validation loss across folds.</p>
</td></tr>
<tr><td><code>cvsd</code></td>
<td>
<p>A (number-of-lambda * number-of-alpha) matrix saving standard deviations of
cross validation loss across folds.</p>
</td></tr>
<tr><td><code>TSLA.fit</code></td>
<td>
<p>Outputs from <code>TSLA.fit()</code>.</p>
</td></tr>
<tr><td><code>Intercept.min</code></td>
<td>
<p>Intercept corresponding to <code>(lambda.min,alpha.min)</code>.</p>
</td></tr>
<tr><td><code>cov.min</code></td>
<td>
<p>Coefficients of unpenalized features
corresponding to <code>(lambda.min,alpha.min)</code>.</p>
</td></tr>
<tr><td><code>beta.min</code></td>
<td>
<p>Coefficients of binary features corresponding
to <code>(lambda.min,alpha.min)</code>.</p>
</td></tr>
<tr><td><code>gamma.min</code></td>
<td>
<p>Node coefficients corresponding to <code>(lambda.min,alpha.min)</code>.</p>
</td></tr>
<tr><td><code>groupnorm.min</code></td>
<td>
<p>Group norms of node coefficients corresponding to <code>(lambda.min,alpha.min)</code>.</p>
</td></tr>
<tr><td><code>lambda.min.index</code></td>
<td>
<p>Index of the best <code class="reqn">\lambda</code> in the sequence.</p>
</td></tr>
<tr><td><code>alpha.min.index</code></td>
<td>
<p>Index of the best <code class="reqn">\alpha</code> in the sequence.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'># Load the synthetic data
data(ClassificationExample)

tree.org &lt;- ClassificationExample$tree.org   # original tree structure
x2.org &lt;- ClassificationExample$x.org      # original design matrix
x1 &lt;- ClassificationExample$x1
y &lt;- ClassificationExample$y            # response

# Do the tree-guided expansion
expand.data &lt;- getetmat(tree.org, x2.org)
x2 &lt;- expand.data$x.expand              # expanded design matrix
tree.expand &lt;- expand.data$tree.expand  # expanded tree structure

# Do train-test split
idtrain &lt;- 1:200
x1.train &lt;- as.matrix(x1[idtrain, ])
x2.train &lt;- x2[idtrain, ]
y.train &lt;- y[idtrain, ]
x1.test &lt;- as.matrix(x1[-idtrain, ])
x2.test &lt;- x2[-idtrain, ]
y.test &lt;- y[-idtrain, ]

# specify some model parameters
set.seed(100)
control &lt;- list(maxit = 100, mu = 1e-3, tol = 1e-5, verbose = FALSE)
modstr &lt;- list(nlambda = 5,  alpha = seq(0, 1, length.out = 5))
simu.cv &lt;- cv.TSLA(y = y.train, as.matrix(x1[idtrain, ]),
                   X_2 = x2.train,
                   treemat = tree.expand, family = 'logit',
                   penalty = 'CL2', pred.loss = 'AUC',
                   gamma.init = NULL, weight = c(1, 1), nfolds = 5,
                   group.weight = NULL, feature.weight = NULL,
                   control = control, modstr =  modstr)
# Do prediction with the selected tuning parameters on the test set. Report AUC on the test set.
rmid &lt;- simu.cv$TSLA.fit$rmid  # remove all zero columns
if(length(rmid) &gt; 0){
  x2.test &lt;- x2.test[, -rmid]}
  y.new &lt;- predict_cvTSLA(simu.cv, as.matrix(x1[-idtrain, ]), x2.test)
  library(pROC)
  auc(as.vector(y.test), as.vector(y.new))


</code></pre>

<hr>
<h2 id='get_tree_object'>Tree-guided reparameterization</h2><span id='topic+get_tree_object'></span>

<h3>Description</h3>

<p>This function generates all the intermediate quantities
based on the tree-guided reparameterization.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_tree_object(
  X_2,
  treemat,
  penalty = c("CL2", "DL2", "RFS-Sum"),
  group.weight = NULL,
  feature.weight = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="get_tree_object_+3A_x_2">X_2</code></td>
<td>
<p>Expanded design matrix for <code>penalty = "CL2"</code>;
Original design matrix
for <code>penalty = "RFS-Sum"</code>. Need to be in the matrix form.</p>
</td></tr>
<tr><td><code id="get_tree_object_+3A_treemat">treemat</code></td>
<td>
<p>Expanded tree structure for
<code>penalty = "CL2"</code>; Original structure for <code>penalty = "RFS-Sum"</code>.
Need to be in the matrix form.</p>
</td></tr>
<tr><td><code id="get_tree_object_+3A_penalty">penalty</code></td>
<td>
<p>Two options for group penalty on <code class="reqn">\gamma</code>,
&quot;CL2&quot; or &quot;RFS-Sum&quot;.</p>
</td></tr>
<tr><td><code id="get_tree_object_+3A_group.weight">group.weight</code></td>
<td>
<p>User-defined weights for group penalty.
Need to be a vector and the length equals to the number of groups.</p>
</td></tr>
<tr><td><code id="get_tree_object_+3A_feature.weight">feature.weight</code></td>
<td>
<p>User-defined weights for each predictor
after expansion.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list consists of quantities needed for SPG optimization.
</p>
<table role = "presentation">
<tr><td><code>C_1</code></td>
<td>
<p>C_1 matrix for generalized lasso penalty.</p>
</td></tr>
<tr><td><code>CNorm_1</code></td>
<td>
<p>Nuclear norm of matrix <code>C_1</code>.</p>
</td></tr>
<tr><td><code>C_2</code></td>
<td>
<p>C_2 matrix for group lasso penalty.</p>
</td></tr>
<tr><td><code>CNorm_2</code></td>
<td>
<p>Nuclear norm of matrix <code>C_2</code>.</p>
</td></tr>
<tr><td><code>A</code></td>
<td>
<p>A (number-of-leaf * number-of-node) binary matrix containing linear constraints.
Recall that <code class="reqn">\beta=A\gamma</code>.
It is used with <code>beta.coef</code> and <code>x.expand</code>.</p>
</td></tr>
<tr><td><code>g_idx</code></td>
<td>
<p>A (number-of-group * 3) matrix.
Each column stands for starting row in <code>C_2</code> of a group,
end row in <code>C_2</code> of a group, and the group size.</p>
</td></tr>
<tr><td><code>M2</code></td>
<td>
<p>A (number-of-leaf * number-of-level) node index matrix,
with index going from 1 to the number of nodes.
Root node has index equal to the number of nodes.
Each row corresponds to a variable at the finest level,
each column corresponds to an ordered classification level;
the entry values in each column are the unique indices of the variables
at that level.
As we move to the right, the number of unique values becomes fewer.</p>
</td></tr>
<tr><td><code>Tree</code></td>
<td>
<p>A (number-of-group *  number-of-node) group index matrix.
Each row is a group and the column order is the same as the order of node
index in M2. If the jth node belongs to the ith group, then the (i, j)
element of the matrix is 1; otherwise the element is 0.</p>
</td></tr>
<tr><td><code>A.adj</code></td>
<td>
<p>A (number-of-leaf * number-of-node) binary matrix
containing linear constraints.
It is used with <code>beta.coef.adj</code> and <code>x.expand.adj</code>.</p>
</td></tr>
</table>

<hr>
<h2 id='getaggr'>Generate aggregated features</h2><span id='topic+getaggr'></span>

<h3>Description</h3>

<p>Function that generates aggregated features based on the TSLA output.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getaggr(TSLA.object, X_2, X_2.org, lambda.index, alpha.index)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="getaggr_+3A_tsla.object">TSLA.object</code></td>
<td>
<p>A fit output from <code>TSLA.fit()</code>,
or the <code>TSLA.fit</code> object in <code>cv.TSLA()</code>.</p>
</td></tr>
<tr><td><code id="getaggr_+3A_x_2">X_2</code></td>
<td>
<p>Expanded design matrix in matrix form.</p>
</td></tr>
<tr><td><code id="getaggr_+3A_x_2.org">X_2.org</code></td>
<td>
<p>Original design matrix in matrix form.</p>
</td></tr>
<tr><td><code id="getaggr_+3A_lambda.index">lambda.index</code></td>
<td>
<p>Index of the <code class="reqn">\lambda</code> value selected.</p>
</td></tr>
<tr><td><code id="getaggr_+3A_alpha.index">alpha.index</code></td>
<td>
<p>Index of the <code class="reqn">\alpha</code> value selected. The <code class="reqn">\alpha</code> is
the tuning parameter for generalized lasso penalty.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data.frame of the aggregated feature.
</p>
<table role = "presentation">
<tr><td><code>dataset</code></td>
<td>
<p>aggregated features.</p>
</td></tr>
</table>

<hr>
<h2 id='getetmat'>Tree-guided expansion</h2><span id='topic+getetmat'></span>

<h3>Description</h3>

<p>Give the expanded design matrix and the expanded tree structure
by adding interactions in conformity to the structure.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getetmat(tmatrix, dmatrix)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="getetmat_+3A_tmatrix">tmatrix</code></td>
<td>
<p>Tree structure of the original features in matrix form.</p>
</td></tr>
<tr><td><code id="getetmat_+3A_dmatrix">dmatrix</code></td>
<td>
<p>Original design matrix in matrix form.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is used by the TSLA method only when the <code>penalty</code> is
selected as &quot;CL2&quot;. The all zero columns produced by the
interactions are excluded in the output.
</p>
<p>For the TSLA method, the signs of the coefficients in the linear
constraints depend on the order of the term.
To better extend the method in implementation, we apply the signs on
the feature vectors instead of the regression coefficients.
For example, we use feature vector -<code class="reqn">x_{12}</code> instead of <code class="reqn">x_{12}</code>.
The expanded design matrix <code>x.expand</code> from this
function is adjusted by the signs. The <code>A</code> matrix and
all the coefficients estimated from the package
can be explained correspondingly. We also provide <code>x.expand.adj</code>,
<code>A.adj</code>, and <code>beta.coef.adj</code>
as the quantities with the effects of the signs removed.
</p>
<p>The input tree structure of the original features needs to be
constructed as the following:
each row corresponds to a variable at the finest level;
each column corresponds to an ordered classification level with the
leaf level at the left-most and the root level at the right-most;
the entry values in each column are the index of the ancestor node of
the variable at that level.
As we move from left to right, the number of unique values
in the column becomes fewer.
</p>


<h3>Value</h3>

<p>A list.
</p>
<table role = "presentation">
<tr><td><code>x.expand</code></td>
<td>
<p>The design matrix after expansion.
Each column is multiplied by <code class="reqn">(-1)^{r-1}</code>,
where r is the order of the corresponding interaction term.</p>
</td></tr>
<tr><td><code>tree.expand</code></td>
<td>
<p>The tree structure after expansion.</p>
</td></tr>
<tr><td><code>x.expand.adj</code></td>
<td>
<p>The design matrix after expansion with the
effects of signs removed.</p>
</td></tr>
</table>

<hr>
<h2 id='getperform'>Get performance metrics for classification</h2><span id='topic+getperform'></span>

<h3>Description</h3>

<p>Evaluate the prediction performance under the classification settings.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getperform(
  ytest,
  ypretest,
  family,
  threshold.method = c("youden", "specificity.control", "quantile"),
  specificity = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="getperform_+3A_ytest">ytest</code></td>
<td>
<p>Response vector for test data.</p>
</td></tr>
<tr><td><code id="getperform_+3A_ypretest">ypretest</code></td>
<td>
<p>Predicted probability for test data.</p>
</td></tr>
<tr><td><code id="getperform_+3A_family">family</code></td>
<td>
<p>&quot;ls&quot; or &quot;logic&quot;. Return MSE when &quot;ls&quot; is used.</p>
</td></tr>
<tr><td><code id="getperform_+3A_threshold.method">threshold.method</code></td>
<td>
<p>Method to get the threshold.</p>
</td></tr>
<tr><td><code id="getperform_+3A_specificity">specificity</code></td>
<td>
<p>User-defined specificity or quantile.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function supports three methods to select the threshold of the
predicted probability.
</p>
<p><code>threshold.method = "youden"</code>: The optimal threshold corresponds to
the point that maximizes the distance to the identity (diagonal) line on
the ROC curve.
</p>
<p><code>threshold.method = "specificity.control"</code>: The optimal threshold
corresponds to the smallest value that ensures the required specificity
value.
</p>
<p><code>threshold.method = "quantile"</code>: The optimal threshold corresponds to
the required quantile of the predicted probability.
</p>


<h3>Value</h3>

<p>List of measures.
</p>
<table role = "presentation">
<tr><td><code>AUC</code></td>
<td>
<p>Area under the ROC curve.</p>
</td></tr>
<tr><td><code>AUPRC</code></td>
<td>
<p>Area under the precision-recall curve.</p>
</td></tr>
<tr><td><code>threshold</code></td>
<td>
<p>Selected threshold of the probability.</p>
</td></tr>
<tr><td><code>sensitivity</code></td>
<td>
<p>Sensitivity with the selected threshold.</p>
</td></tr>
<tr><td><code>ppv</code></td>
<td>
<p>Positive predictive value with the selected threshold.</p>
</td></tr>
<tr><td><code>specificity</code></td>
<td>
<p>Specificity with the selected threshold.</p>
</td></tr>
<tr><td><code>true.positive</code></td>
<td>
<p>Number of true positive with the selected threshold.</p>
</td></tr>
<tr><td><code>false.positive</code></td>
<td>
<p>Number of false positive with the selected threshold.</p>
</td></tr>
</table>

<hr>
<h2 id='plot_TSLA'>Plot aggregated structure</h2><span id='topic+plot_TSLA'></span>

<h3>Description</h3>

<p>Return a tree plot.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot_TSLA(TSLA.object, X_2, X_2.org, lambda.index, alpha.index)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot_TSLA_+3A_tsla.object">TSLA.object</code></td>
<td>
<p>A fit output from <code>TSLA.fit()</code>,
or the <code>TSLA.fit</code> object in <code>cv.TSLA()</code>.</p>
</td></tr>
<tr><td><code id="plot_TSLA_+3A_x_2">X_2</code></td>
<td>
<p>Expanded design matrix in matrix form.</p>
</td></tr>
<tr><td><code id="plot_TSLA_+3A_x_2.org">X_2.org</code></td>
<td>
<p>Original design matrix in matrix form.</p>
</td></tr>
<tr><td><code id="plot_TSLA_+3A_lambda.index">lambda.index</code></td>
<td>
<p>Index of the <code class="reqn">\lambda</code> value selected.</p>
</td></tr>
<tr><td><code id="plot_TSLA_+3A_alpha.index">alpha.index</code></td>
<td>
<p>Index of the <code class="reqn">\alpha</code> value selected. The <code class="reqn">\alpha</code> is
the tuning parameter for generalized lasso penalty.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A plot
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Load the synthetic data
data(ClassificationExample)

tree.org &lt;- ClassificationExample$tree.org   # original tree structure
x2.org &lt;- ClassificationExample$x.org      # original design matrix
x1 &lt;- ClassificationExample$x1
y &lt;- ClassificationExample$y            # response

# Do the tree-guided expansion
expand.data &lt;- getetmat(tree.org, x2.org)
x2 &lt;- expand.data$x.expand              # expanded design matrix
tree.expand &lt;- expand.data$tree.expand  # expanded tree structure

# Do train-test split
idtrain &lt;- 1:200
x1.train &lt;- as.matrix(x1[idtrain, ])
x2.train &lt;- x2[idtrain, ]
y.train &lt;- y[idtrain, ]
x1.test &lt;- as.matrix(x1[-idtrain, ])
x2.test &lt;- x2[-idtrain, ]
y.test &lt;- y[-idtrain, ]

# specify some model parameters
set.seed(100)
control &lt;- list(maxit = 100, mu = 1e-3, tol = 1e-5, verbose = FALSE)
modstr &lt;- list(nlambda = 5,  alpha = seq(0, 1, length.out = 5))
simu.cv &lt;- cv.TSLA(y = y.train, as.matrix(x1[idtrain, ]),
                   X_2 = x2.train,
                   treemat = tree.expand, family = 'logit',
                   penalty = 'CL2', pred.loss = 'AUC',
                   gamma.init = NULL, weight = c(1, 1), nfolds = 5,
                   group.weight = NULL, feature.weight = NULL,
                   control = control, modstr =  modstr)
plot_TSLA(simu.cv$TSLA.fit, x2, x2.org, simu.cv$lambda.min.index, simu.cv$alpha.min.index)



</code></pre>

<hr>
<h2 id='predict_cvTSLA'>Prediction from cross validation</h2><span id='topic+predict_cvTSLA'></span>

<h3>Description</h3>

<p>A convenient function to get prediction from the
selected tuning parameters by cross validation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>predict_cvTSLA(
  object,
  X_1_new = NULL,
  X_2_new,
  type = c("response", "link"),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict_cvTSLA_+3A_object">object</code></td>
<td>
<p>A fit output from <code>cv.TSLA().</code></p>
</td></tr>
<tr><td><code id="predict_cvTSLA_+3A_x_1_new">X_1_new</code></td>
<td>
<p>New unpenalized features in matrix form.</p>
</td></tr>
<tr><td><code id="predict_cvTSLA_+3A_x_2_new">X_2_new</code></td>
<td>
<p>New binary features in matrix form.</p>
</td></tr>
<tr><td><code id="predict_cvTSLA_+3A_type">type</code></td>
<td>
<p>Two options: &quot;response&quot; or &quot;link&quot;. The two options only
differ for <code>family="logit"</code>.</p>
</td></tr>
<tr><td><code id="predict_cvTSLA_+3A_...">...</code></td>
<td>
<p>Other parameters.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Predictions.
</p>

<hr>
<h2 id='predict_TSLA'>Prediction from TSLA with new data</h2><span id='topic+predict_TSLA'></span>

<h3>Description</h3>

<p>Generate prediction for the response.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>predict_TSLA(
  object,
  X_1_new = NULL,
  X_2_new,
  type = c("response", "link"),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict_TSLA_+3A_object">object</code></td>
<td>
<p>A fit output from <code>TSLA.fit()</code>.</p>
</td></tr>
<tr><td><code id="predict_TSLA_+3A_x_1_new">X_1_new</code></td>
<td>
<p>New unpenalized features in matrix form.</p>
</td></tr>
<tr><td><code id="predict_TSLA_+3A_x_2_new">X_2_new</code></td>
<td>
<p>New binary features in matrix form.</p>
</td></tr>
<tr><td><code id="predict_TSLA_+3A_type">type</code></td>
<td>
<p>Two options: &quot;response&quot; or &quot;link&quot;. The two options only
differ for <code>family="logit"</code>.</p>
</td></tr>
<tr><td><code id="predict_TSLA_+3A_...">...</code></td>
<td>
<p>Other parameters.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Predictions. The first dimension is indexed by the observation,
the second dimension is indexed by <code class="reqn">\lambda</code>,
and the third dimension is indexed by <code class="reqn">\alpha</code>.
</p>

<hr>
<h2 id='RegressionExample'>Synthesic for the regression example</h2><span id='topic+RegressionExample'></span>

<h3>Description</h3>

<p>Synthetic data used to illustrate how to use TSLA with regression.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(RegressionExample)
</code></pre>


<h3>Format</h3>

<p>List containing the following elements:
</p>

<dl>
<dt>tree.org</dt><dd><p>Original tree structure with 42 leaf nodes and 5 different levels.</p>
</dd>
<dt>x.org</dt><dd><p>Original design matrix with 42 binary features and 400 observations.</p>
</dd>
<dt>y</dt><dd><p>Continuous response of length 400.</p>
</dd>
</dl>


<hr>
<h2 id='TSLA.fit'>Solve the TSLA optimization problem</h2><span id='topic+TSLA.fit'></span>

<h3>Description</h3>

<p>Find the solutions with a Smoothing Proximal Gradient (SPG) algorithm
for a sequence of <code class="reqn">\alpha</code> and <code class="reqn">\lambda</code> values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>TSLA.fit(
  y,
  X_1 = NULL,
  X_2,
  treemat,
  family = c("ls", "logit"),
  penalty = c("CL2", "RFS-Sum"),
  gamma.init = NULL,
  weight = NULL,
  group.weight = NULL,
  feature.weight = NULL,
  control = list(),
  modstr = list()
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="TSLA.fit_+3A_y">y</code></td>
<td>
<p>Response in matrix form, continuous for <code>family = "ls"</code> and binary (0/1)
for <code>family = "logit"</code>.</p>
</td></tr>
<tr><td><code id="TSLA.fit_+3A_x_1">X_1</code></td>
<td>
<p>Design matrix for unpenalized features (excluding intercept). Need to be in the matrix form.</p>
</td></tr>
<tr><td><code id="TSLA.fit_+3A_x_2">X_2</code></td>
<td>
<p>Expanded design matrix for <code>penalty = "CL2"</code>; Original design matrix
for <code>penalty = "RFS-Sum"</code>. Need to be in the matrix form.</p>
</td></tr>
<tr><td><code id="TSLA.fit_+3A_treemat">treemat</code></td>
<td>
<p>Expanded tree structure in matrix form for
<code>penalty = "CL2"</code>; Original structure for <code>penalty = "RFS-Sum"</code>.</p>
</td></tr>
<tr><td><code id="TSLA.fit_+3A_family">family</code></td>
<td>
<p>Two options. Use &quot;ls&quot; for least square problems and &quot;logit&quot;
for logistic regression problems.</p>
</td></tr>
<tr><td><code id="TSLA.fit_+3A_penalty">penalty</code></td>
<td>
<p>Two options for group penalty on <code class="reqn">\gamma</code>, &quot;CL2&quot; or &quot;RFS-Sum&quot;.</p>
</td></tr>
<tr><td><code id="TSLA.fit_+3A_gamma.init">gamma.init</code></td>
<td>
<p>Initial value for the optimization. Default is a zero vector.
The length should equal to 1+<code>ncol(X_1)</code>+<code>ncol(A)</code>.
See details of A in <code>get_tree_obj()</code>.</p>
</td></tr>
<tr><td><code id="TSLA.fit_+3A_weight">weight</code></td>
<td>
<p>A vector of length two and it is used for logistic regression
only. The first element corresponds to weight of y=1 and the
second element corresponds to weight of y=0.</p>
</td></tr>
<tr><td><code id="TSLA.fit_+3A_group.weight">group.weight</code></td>
<td>
<p>User-defined weights for group penalty. Need to be a vector
and the length equals to the number of groups.</p>
</td></tr>
<tr><td><code id="TSLA.fit_+3A_feature.weight">feature.weight</code></td>
<td>
<p>User-defined weights for each predictor after expansion.</p>
</td></tr>
<tr><td><code id="TSLA.fit_+3A_control">control</code></td>
<td>
<p>A list of parameters controlling algorithm convergence. Default values:
<code>tol = 1e-5</code>, convergence tolerance; <code>maxit = 10000</code>,
maximum number of iterations; <code>mu = 1e-3</code>, smoothness parameter in SPG.</p>
</td></tr>
<tr><td><code id="TSLA.fit_+3A_modstr">modstr</code></td>
<td>
<p>A list of parameters controlling tuning parameters. Default values:
<code>lambda = NULL</code>. If lambda is not provided, the package will give a default lambda sequence;
<code>lambda.min.ratio = 1e-04</code>, smallest value for lambda as
a fraction of lambda.max (given by default when lambda is NULL);
<code>nlambda = 50</code>,
number of lambda values (equal spacing on log scale) used when lambda is NULL;
<code>alpha = seq(0, 1, length.out = 10)</code>, sequence of alpha. Here, alpha is
tuning parameter for generalized lasso penalty and 1-alpha is the tuning
parameter for group lasso penalty.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>We adopt the warm start technique to speed up the calculation.
The warm start is applied with a fixed value of <code class="reqn">\alpha</code> and a
descending sequence of <code class="reqn">\lambda</code>.
</p>
<p>The objective function for &quot;ls&quot; is
</p>
<p style="text-align: center;"><code class="reqn">1/2 RSS+\lambda(\alpha P(\beta)+(1-\alpha) P(\gamma)),</code>
</p>

<p>subject to <code class="reqn">\beta=A\gamma</code>.
The objective function for &quot;logit&quot; is
</p>
<p style="text-align: center;"><code class="reqn">-loglik + \lambda(\alpha P(\beta)+(1-\alpha) P(\gamma)),</code>
</p>

<p>subject to <code class="reqn">\beta=A\gamma</code>. Note that, in this package, the input parameter &quot;alpha&quot; is the
tuning parameter for the generalized lasso penalty.
</p>
<p>Details for &quot;penalty&quot; option:
</p>
<p>For <code>penalty = "CL2"</code>, see details for the
&quot;Child-l2&quot; penalty in the main paper.
</p>
<p>For <code>penalty = "RFS-Sum"</code>, the theoretical optimal weights are used.
Please check the details in paper
&quot;Rare feature selection in high dimensions&quot;.
</p>


<h3>Value</h3>

<p>A list of model fitting results.
</p>
<table role = "presentation">
<tr><td><code>gammacoef</code></td>
<td>
<p>Estimation for <code class="reqn">\gamma</code>.</p>
</td></tr>
<tr><td><code>groupnorm</code></td>
<td>
<p>Weighted norms for each group.</p>
</td></tr>
<tr><td><code>lambda.seq</code></td>
<td>
<p>Sequence of <code class="reqn">\lambda</code> values.</p>
</td></tr>
<tr><td><code>alpha.seq</code></td>
<td>
<p>Tuning parameter sequence for the generalized lasso penalty.</p>
</td></tr>
<tr><td><code>rmid</code></td>
<td>
<p>Column index for all zero features.</p>
</td></tr>
<tr><td><code>family</code></td>
<td>
<p>Option of <code>family</code>.</p>
</td></tr>
<tr><td><code>cov.name</code></td>
<td>
<p>Names for unpenalized features.</p>
</td></tr>
<tr><td><code>bin.name</code></td>
<td>
<p>Names for binary feautres.</p>
</td></tr>
<tr><td><code>tree.object</code></td>
<td>
<p>Outputs from <code>get_tree_obj()</code>.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Chen, J., Aseltine, R. H., Wang, F., &amp; Chen, K. (2024).
<em>Tree-Guided Rare Feature Selection and Logic Aggregation with
Electronic Health Records Data. Journal of the American Statistical Association 119(547), 1765-1777</em>,
<a href="https://doi.org/10.1080/01621459.2024.2326621">doi:10.1080/01621459.2024.2326621</a>.<br />
Chen, X., Q. Lin, S. Kim, J. G. Carbonell, and E. P. Xing (2012).
<em>Smoothing proximal gradient method for general structured sparse regression.
The Annals of Applied Statistics 6(2), 719–752</em>,
<a href="https://doi.org/10.1214/11-AOAS514">doi:10.1214/11-AOAS514</a>.<br />
Yan, X. and J. Bien (2021).
<em>Rare feature selection in high dimensions.
Journal of the American Statistical Association 116(534), 887–900</em>,
<a href="https://doi.org/10.1080/01621459.2020.1796677">doi:10.1080/01621459.2020.1796677</a>.<br />
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Load the synthetic data
data(RegressionExample)

tree.org &lt;- RegressionExample$tree.org   # original tree structure
x2.org &lt;- RegressionExample$x.org      # original design matrix
y &lt;- RegressionExample$y            # response

# Do the tree-guided expansion
expand.data &lt;- getetmat(tree.org, x2.org)
x2 &lt;- expand.data$x.expand              # expanded design matrix
tree.expand &lt;- expand.data$tree.expand  # expanded tree structure

# specify some model parameters
set.seed(100)
control &lt;- list(maxit = 100, mu = 1e-3, tol = 1e-5, verbose = FALSE)
# fit model with a pair of lambda and alpha
modstr &lt;- list(lambda = 1,  alpha = 0.1)
x1 &lt;- NULL
fit1 &lt;- TSLA.fit(y, x1, x2, tree.expand, family = 'ls',
                 penalty = 'CL2',
                 gamma.init = NULL, weight = NULL,
                 group.weight = NULL, feature.weight = NULL,
                 control, modstr)
# get group norms from fit1
fit1$groupnorm
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
