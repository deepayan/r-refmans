<!DOCTYPE html><html lang="en"><head><title>Help for package sMTL</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {sMTL}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#cv.smtl'><p>cv.smtl: cross-validation function</p></a></li>
<li><a href='#grid.gen'><p>grid.gen: generate grid for cross-validation function. For internal package use only.</p></a></li>
<li><a href='#maxEigen'><p>maxEigen: maximum eigenvalue wrapper for Julia TSVD package. internal package use only</p></a></li>
<li><a href='#method_nm'><p>methods names: give name for printing. Internal package use only.</p></a></li>
<li><a href='#multiTaskRmse'><p>multiTaskRmse: RMSE for multi-task problems (averaged across tasks)</p></a></li>
<li><a href='#multiTaskRmse_MT'><p>multiTaskRmse: calculate average (across tasks) RMSE for multi-label prediction problems</p></a></li>
<li><a href='#predict'><p>predict: predict on smtl model object</p></a></li>
<li><a href='#reName_cv'><p>reName_cv: rename output from CV. For internal package use only.</p></a></li>
<li><a href='#rhoScale'><p>rhoScale: scale lambda_z depending on magnitude. For internal package use only.</p></a></li>
<li><a href='#seReturn'><p>seReturn: find smallest rho within 1 se of smallest cv error. For internal package use.</p></a></li>
<li><a href='#smtl'><p>smtl: make model-fitting function</p></a></li>
<li><a href='#smtl_setup'><p>smtl_setup: setup Julia path and/or install Julia or Julia packages using functions based on external package JuliaCall::julia_setup().</p></a></li>
<li><a href='#sparseCV'><p>sparseCV: cross-validation functions. For internal package use only.</p></a></li>
<li><a href='#sparseCV_MT'><p>sparseCV_MT: internal cross-validation functions. For internal package use only.</p></a></li>
<li><a href='#sparseL0Tn_iht'><p>sparseCV_L0: cross-validation functions. For internal package use only.</p></a></li>
<li><a href='#tuneZscale'><p>tuneZscale: scale lambda_z depending on magnitude. For internal package use only.</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Title:</td>
<td>Sparse Multi-Task Learning</td>
</tr>
<tr>
<td>Version:</td>
<td>0.1.0</td>
</tr>
<tr>
<td>Description:</td>
<td>Implements L0-constrained Multi-Task Learning and domain generalization algorithms. The algorithms are coded in Julia allowing for fast implementations of the coordinate descent and local combinatorial search algorithms. For more details, see a preprint of the paper: Loewinger et al., (2022) &lt;<a href="https://doi.org/10.48550/arXiv.2212.08697">doi:10.48550/arXiv.2212.08697</a>&gt;.</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/gloewing/sMTL">https://github.com/gloewing/sMTL</a>,
<a href="https://rpubs.com/gloewinger/996629">https://rpubs.com/gloewinger/996629</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/gloewing/sMTL/issues">https://github.com/gloewing/sMTL/issues</a></td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Gabriel Loewinger &lt;gloewinger@gmail.com&gt;</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0)</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Imports:</td>
<td>glmnet, JuliaCall, JuliaConnectoR, caret, dplyr</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.1</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, rmarkdown</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-02-04 22:58:56 UTC; loewingergc</td>
</tr>
<tr>
<td>Author:</td>
<td>Gabriel Loewinger <a href="https://orcid.org/0000-0002-0755-8520"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cre],
  Kayhan Behdin [aut],
  Giovanni Parmigiani [aut],
  Rahul Mazumder [aut],
  National Science Foundation Grant DMS1810829 [fnd],
  National Science Foundation Grant DMS2113707 [fnd],
  National Science Foundation Grant NSF-IIS1718258, [fnd],
  Office of Naval Research Grant ONR N000142112841 [fnd],
  National Institute on Drug Abuse (NIH) Grant F31DA052153 [fnd]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-02-06 11:20:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='cv.smtl'>cv.smtl: cross-validation function</h2><span id='topic+cv.smtl'></span>

<h3>Description</h3>

<p>cv.smtl: cross-validation function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cv.smtl(
  y,
  X,
  study = NA,
  grid = NA,
  nfolds = NA,
  commonSupp = FALSE,
  multiTask = TRUE,
  lambda_1 = TRUE,
  lambda_2 = FALSE,
  lambda_z = TRUE,
  maxIter = 2500,
  LocSrch_skip = 1,
  LocSrch_maxIter = 10,
  messageInd = FALSE,
  independent.regs = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cv.smtl_+3A_y">y</code></td>
<td>
<p>A numeric outcome vector or matrix (for multi-label problems)</p>
</td></tr>
<tr><td><code id="cv.smtl_+3A_x">X</code></td>
<td>
<p>A design (feature) matrix</p>
</td></tr>
<tr><td><code id="cv.smtl_+3A_study">study</code></td>
<td>
<p>An integer vector specifying the task ID</p>
</td></tr>
<tr><td><code id="cv.smtl_+3A_grid">grid</code></td>
<td>
<p>A dataframe with column names &quot;s&quot;, &quot;lambda_1&quot;, &quot;lambda_2&quot; and &quot;lambda_z&quot; (if commonSupp = FALSE) with tuning values</p>
</td></tr>
<tr><td><code id="cv.smtl_+3A_nfolds">nfolds</code></td>
<td>
<p>An integer specifying number of CV folds</p>
</td></tr>
<tr><td><code id="cv.smtl_+3A_commonsupp">commonSupp</code></td>
<td>
<p>A boolean specifying whether the task models should have the same support</p>
</td></tr>
<tr><td><code id="cv.smtl_+3A_multitask">multiTask</code></td>
<td>
<p>A boolean only used if study/task indices are provided: used to distinguish between a Multi-Task Learning Tuning (TRUE) or Domain Generalization Tuning (FALSE)</p>
</td></tr>
<tr><td><code id="cv.smtl_+3A_lambda_1">lambda_1</code></td>
<td>
<p>An optional boolean: if a grid is not provided, then set to TRUE if you want an automatic grid to be generated with non-zero values for this hyperparameter</p>
</td></tr>
<tr><td><code id="cv.smtl_+3A_lambda_2">lambda_2</code></td>
<td>
<p>An optional boolean: if a grid is not provided, then set to TRUE if you want an automatic grid to be generated with non-zero values for this hyperparameter</p>
</td></tr>
<tr><td><code id="cv.smtl_+3A_lambda_z">lambda_z</code></td>
<td>
<p>An optional boolean: if a grid is not provided, then set to TRUE if you want an automatic grid to be generated with non-zero values for this hyperparameter</p>
</td></tr>
<tr><td><code id="cv.smtl_+3A_maxiter">maxIter</code></td>
<td>
<p>An integer specifying the maximum number of coordinate descent iterations</p>
</td></tr>
<tr><td><code id="cv.smtl_+3A_locsrch_skip">LocSrch_skip</code></td>
<td>
<p>An integer specifying whether to use local search at every tuning value (set to 1), every other value (set to 2), every third (set to 3),...</p>
</td></tr>
<tr><td><code id="cv.smtl_+3A_locsrch_maxiter">LocSrch_maxIter</code></td>
<td>
<p>An integer specifying the maximum number of local search iterations</p>
</td></tr>
<tr><td><code id="cv.smtl_+3A_messageind">messageInd</code></td>
<td>
<p>A boolean (verbose) of whether to print messages</p>
</td></tr>
<tr><td><code id="cv.smtl_+3A_independent.regs">independent.regs</code></td>
<td>
<p>A boolean of whether models are completely indpendent (only set to TRUE for benchmarks)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
#####################################################################################
##### simulate data
#####################################################################################
set.seed(1) # fix the seed to get a reproducible result
K &lt;- 4 # number of datasets 
p &lt;- 100 # covariate dimension
s &lt;- 5 # support size
q &lt;- 7 # size of subset of covariates that can be non-zero for any task
n_k &lt;- 50 # task sample size
N &lt;- n_k * p # full dataset samplesize
X &lt;- matrix( rnorm(N * p), nrow = N, ncol=p) # full design matrix
B &lt;- matrix(1 + rnorm(K * (p+1) ), nrow = p + 1, ncol = K) # betas before making sparse
Z &lt;- matrix(0, nrow = p, ncol = K) # matrix of supports
y &lt;- vector(length = N) # outcome vector

# randomly sample support to make betas sparse
for(j in 1:K)     Z[1:q, j] &lt;- sample( c( rep(1,s), rep(0, q - s) ), q, replace = FALSE )
B[-1,] &lt;- B[-1,] * Z # make betas sparse and ensure all models have an intercept

task &lt;- rep(1:K, each = n_k) # vector of task labels (indices)

# iterate through and make each task specific dataset
for(j in 1:K){
    indx &lt;- which(task == j) # indices of task
    e &lt;- rnorm(n_k)
    y[indx] &lt;- B[1, j] + X[indx,] %*% B[-1,j] + e
    }
    
colnames(B) &lt;- paste0("beta_", 1:K)
rownames(B) &lt;- paste0("X_", 1:(p+1))
    
print("Betas")
print(round(B[1:8,],2))
    
    ###########################
    # custom tuning grid
    ###########################
    grid &lt;- data.frame(s = c(4, 4, 5, 5), 
                  lambda_1 = c(0.01, 0.1, 0.01, 0.1), 
                  lambda_2 = rep(0, 4), 
                  lambda_z = c(0.01, 0.1, 0.01, 0.1))
    
    #################################################
    # cross validation with custom tuning grid
    ##################################################
## Not run: 

if (identical(Sys.getenv("AUTO_JULIA_INSTALL"), "true")) { ## The examples are quite time consuming
## Do initiation for and automatic installation if necessary

    tn &lt;- cv.smtl(y = y, 
                  X = X, 
                  study = task, 
                  commonSupp = FALSE,
                  grid = grid,
                  nfolds = 5,
                  multiTask = FALSE) 
                  
     # model fitting
     mod &lt;- sMTL::smtl(y = y, 
                   X = X, 
                   study = task, 
                   s = tn$best.1se$s, 
                   commonSupp = TRUE,
                   lambda_1 = tn$best.1se$lambda_1,
                   lambda_z = tn$best.1se$lambda_z)
    
    ######################################################
    # cross validation with automatically generated grid
    #######################################################
    tn &lt;- cv.smtl(y = y, 
                  X = X, 
                  study = task, 
                  commonSupp = FALSE,
                  lambda_1 = TRUE,
                  lambda_w = FALSE,
                  lambda_z = TRUE,
                  nfolds = 5,
                  multiTask = FALSE) 
    
     # model fitting
     mod &lt;- sMTL::smtl(y = y, 
                   X = X, 
                   study = task, 
                   s = tn$best.1se$s, 
                   commonSupp = TRUE,
                   lambda_1 = tn$best.1se$lambda_1,
                   lambda_z = tn$best.1se$lambda_z)
                   
     print(round(mod$beta[1:8,],2))
                   }
                   
## End(Not run)
                   
    
</code></pre>

<hr>
<h2 id='grid.gen'>grid.gen: generate grid for cross-validation function. For internal package use only.</h2><span id='topic+grid.gen'></span>

<h3>Description</h3>

<p>grid.gen: generate grid for cross-validation function. For internal package use only.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>grid.gen(
  y,
  p,
  study = NA,
  lambda_1 = TRUE,
  lambda_2 = FALSE,
  lambda_z = TRUE,
  commonSupp = FALSE,
  multiTask = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="grid.gen_+3A_y">y</code></td>
<td>
<p>A numeric vector or matrix of outcomes</p>
</td></tr>
<tr><td><code id="grid.gen_+3A_p">p</code></td>
<td>
<p>An integer of covariate dimension</p>
</td></tr>
<tr><td><code id="grid.gen_+3A_study">study</code></td>
<td>
<p>An integer vector of task IDs</p>
</td></tr>
<tr><td><code id="grid.gen_+3A_lambda_1">lambda_1</code></td>
<td>
<p>A boolean</p>
</td></tr>
<tr><td><code id="grid.gen_+3A_lambda_2">lambda_2</code></td>
<td>
<p>A boolean</p>
</td></tr>
<tr><td><code id="grid.gen_+3A_lambda_z">lambda_z</code></td>
<td>
<p>A boolean</p>
</td></tr>
<tr><td><code id="grid.gen_+3A_commonsupp">commonSupp</code></td>
<td>
<p>A boolean</p>
</td></tr>
<tr><td><code id="grid.gen_+3A_multitask">multiTask</code></td>
<td>
<p>A boolean</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A dataframe
</p>

<hr>
<h2 id='maxEigen'>maxEigen: maximum eigenvalue wrapper for Julia TSVD package. internal package use only</h2><span id='topic+maxEigen'></span>

<h3>Description</h3>

<p>maxEigen: maximum eigenvalue wrapper for Julia TSVD package. internal package use only
</p>


<h3>Usage</h3>

<pre><code class='language-R'>maxEigen(X, intercept = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="maxEigen_+3A_x">X</code></td>
<td>
<p>A matrix.</p>
</td></tr>
<tr><td><code id="maxEigen_+3A_intercept">intercept</code></td>
<td>
<p>A boolean.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A numeric scalar of the maximum eigenvalue of provided matrix, X.
</p>

<hr>
<h2 id='method_nm'>methods names: give name for printing. Internal package use only.</h2><span id='topic+method_nm'></span>

<h3>Description</h3>

<p>methods names: give name for printing. Internal package use only.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>method_nm(method, multiLabel = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="method_nm_+3A_method">method</code></td>
<td>
<p>A string</p>
</td></tr>
<tr><td><code id="method_nm_+3A_multilabel">multiLabel</code></td>
<td>
<p>A boolean</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A string indicating what type of multi-task learning problem is being fit.
</p>

<hr>
<h2 id='multiTaskRmse'>multiTaskRmse: RMSE for multi-task problems (averaged across tasks)</h2><span id='topic+multiTaskRmse'></span>

<h3>Description</h3>

<p>multiTaskRmse: RMSE for multi-task problems (averaged across tasks)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>multiTaskRmse(data, beta)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="multiTaskRmse_+3A_data">data</code></td>
<td>
<p>A matrix including outcome vector/matrix and design matrix to test RMSE on</p>
</td></tr>
<tr><td><code id="multiTaskRmse_+3A_beta">beta</code></td>
<td>
<p>A matrix of estimated beta coefficients where each task is in a different column</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a scalar of average (across tasks) RMSE for predictions on data provided
</p>

<hr>
<h2 id='multiTaskRmse_MT'>multiTaskRmse: calculate average (across tasks) RMSE for multi-label prediction problems</h2><span id='topic+multiTaskRmse_MT'></span>

<h3>Description</h3>

<p>multiTaskRmse: calculate average (across tasks) RMSE for multi-label prediction problems
</p>


<h3>Usage</h3>

<pre><code class='language-R'>multiTaskRmse_MT(data, K = NA, beta)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="multiTaskRmse_MT_+3A_data">data</code></td>
<td>
<p>A matrix including outcome vector/matrix and design matrix to test RMSE on</p>
</td></tr>
<tr><td><code id="multiTaskRmse_MT_+3A_k">K</code></td>
<td>
<p>An integer of number of studies/tasks</p>
</td></tr>
<tr><td><code id="multiTaskRmse_MT_+3A_beta">beta</code></td>
<td>
<p>A matrix of estimated beta coefficients where each task is in a different column</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a scalar of average (across tasks) RMSE for predictions on data provided
</p>

<hr>
<h2 id='predict'>predict: predict on smtl model object</h2><span id='topic+predict'></span>

<h3>Description</h3>

<p>predict: predict on smtl model object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>predict(model, X, lambda_1 = NA, lambda_2 = NA, lambda_z = NA, stack = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict_+3A_model">model</code></td>
<td>
<p>An sMTL model object returned from the smtl() function</p>
</td></tr>
<tr><td><code id="predict_+3A_x">X</code></td>
<td>
<p>A matrix of deatures</p>
</td></tr>
<tr><td><code id="predict_+3A_lambda_1">lambda_1</code></td>
<td>
<p>A optional numeric scalar specifying which lambda_1 to use for prediction. Only needed if the model object is fit on a path (multiple hyperparameterr values)</p>
</td></tr>
<tr><td><code id="predict_+3A_lambda_2">lambda_2</code></td>
<td>
<p>A optional numeric scalar specifying which lambda_2 to use for prediction. Only needed if the model object is fit on a path (multiple hyperparameterr values)</p>
</td></tr>
<tr><td><code id="predict_+3A_lambda_z">lambda_z</code></td>
<td>
<p>A optional numeric scalar specifying which lambda_2 to use for prediction. Only needed if the model object is fit on a path (multiple hyperparameterr values)</p>
</td></tr>
<tr><td><code id="predict_+3A_stack">stack</code></td>
<td>
<p>An optional boolean specifying whether to calculate and apply stacking weights (only for Domain Generalization problems).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix of task-specific predictions for multi-task/multi-label or for Domain Generalization problems, average and multi-study stacking predictions.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
#####################################################################################
##### First Time Loading, Julia is Installed and Julia Path is Known ######
#####################################################################################
# fit model
## Not run: 

if (identical(Sys.getenv("AUTO_JULIA_INSTALL"), "true")) { ## The examples are quite time consuming
## Do initiation for and automatic installation if necessary
mod &lt;- smtl(y = y, 
            X = X, 
            study = task, 
            s = 5, 
            commonSupp = FALSE,
            lambda_1 = c(0.1, 0.2, 0.3),
            lambda_z = c(0.01, 0.05, 0.1))

# make predictions
preds &lt;- sMTL::predict.smtl(model = mod, 
                       X = X, 
                       lambda_1 = 0.1, 
                       lambda_z = 0.01) }
                       
## End(Not run)
                       
</code></pre>

<hr>
<h2 id='reName_cv'>reName_cv: rename output from CV. For internal package use only.</h2><span id='topic+reName_cv'></span>

<h3>Description</h3>

<p>reName_cv: rename output from CV. For internal package use only.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>reName_cv(x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="reName_cv_+3A_x">x</code></td>
<td>
<p>A list (S3 class) supplied from internal sMTL functions</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list (S3 class) with elements renamed. </p>
<table role = "presentation">
<tr><td><code>best</code></td>
<td>
<p> A list (S3 class) with hyperparameters that achieve lowest average RMSE.</p>
</td></tr> 
<tr><td><code>best.1se</code></td>
<td>
<p> A list (S3 class) with hyperparameters associated with lowest sparsity level within 1 standard deviation of hyperparameters that achieve lowest average RMSE.</p>
</td></tr>
<tr><td><code>lambda_1</code></td>
<td>
<p> Numeric hyperparameter for L2 (ridge penalty).</p>
</td></tr> <tr><td><code>lambda_2</code></td>
<td>
<p> Numeric hyperparameter for betabar penalty.</p>
</td></tr>
<tr><td><code>rho</code></td>
<td>
<p> Integer specifying sparsity level (s).</p>
</td></tr>
</table>

<hr>
<h2 id='rhoScale'>rhoScale: scale lambda_z depending on magnitude. For internal package use only.</h2><span id='topic+rhoScale'></span>

<h3>Description</h3>

<p>rhoScale: scale lambda_z depending on magnitude. For internal package use only.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rhoScale(K, p, rhoVec, itrs = 10000)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rhoScale_+3A_k">K</code></td>
<td>
<p>An integer - number of tasks</p>
</td></tr>
<tr><td><code id="rhoScale_+3A_p">p</code></td>
<td>
<p>An integer - dimension of covariates</p>
</td></tr>
<tr><td><code id="rhoScale_+3A_rhovec">rhoVec</code></td>
<td>
<p>A vector of integers</p>
</td></tr>
<tr><td><code id="rhoScale_+3A_itrs">itrs</code></td>
<td>
<p>An integer</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix or datafame with lambda_z hyperparameter scaled appropriately depending on sparsity level.
</p>

<hr>
<h2 id='seReturn'>seReturn: find smallest rho within 1 se of smallest cv error. For internal package use.</h2><span id='topic+seReturn'></span>

<h3>Description</h3>

<p>seReturn: find smallest rho within 1 se of smallest cv error. For internal package use.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>seReturn(x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="seReturn_+3A_x">x</code></td>
<td>
<p>dataframe</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a dataframe that includes summary statistics to choose the best sparsity level (s) according to the 1-standard deviation rule.
</p>

<hr>
<h2 id='smtl'>smtl: make model-fitting function</h2><span id='topic+smtl'></span>

<h3>Description</h3>

<p>smtl: make model-fitting function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>smtl(
  y,
  X,
  study = NA,
  s,
  commonSupp = FALSE,
  warmStart = TRUE,
  lambda_1 = 0,
  lambda_2 = 0,
  lambda_z = 0,
  scale = TRUE,
  maxIter = 10000,
  LocSrch_maxIter = 50,
  messageInd = TRUE,
  model = TRUE,
  independent.regs = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="smtl_+3A_y">y</code></td>
<td>
<p>A numeric outcome vector (for multi-task/domain generalization problems) or a numeric outcome matrix (for multi-label problems)</p>
</td></tr>
<tr><td><code id="smtl_+3A_x">X</code></td>
<td>
<p>A matrix of covariates</p>
</td></tr>
<tr><td><code id="smtl_+3A_study">study</code></td>
<td>
<p>A vector of integers specifying task (or study/domain) ID. This should be set to NA for Multi-Label problems, but is required for Multi-Task and Domain Generalization problems.</p>
</td></tr>
<tr><td><code id="smtl_+3A_s">s</code></td>
<td>
<p>An integer specifying the sparsity level</p>
</td></tr>
<tr><td><code id="smtl_+3A_commonsupp">commonSupp</code></td>
<td>
<p>A boolean specifying whether to constrain solutions to have a common support</p>
</td></tr>
<tr><td><code id="smtl_+3A_warmstart">warmStart</code></td>
<td>
<p>A boolean specifying whether a warm start model is fit internally before the final model. Warm starts improve solution quality but will be slower.</p>
</td></tr>
<tr><td><code id="smtl_+3A_lambda_1">lambda_1</code></td>
<td>
<p>A numeric vector of ridge penalty hyperparameter values</p>
</td></tr>
<tr><td><code id="smtl_+3A_lambda_2">lambda_2</code></td>
<td>
<p>A numeric vector of betaBar (to borrow strength across coefficient values) penalty hperparameter values</p>
</td></tr>
<tr><td><code id="smtl_+3A_lambda_z">lambda_z</code></td>
<td>
<p>A numeric vector zBar (to borrow strength across coefficient supports) penalty hperparameter values</p>
</td></tr>
<tr><td><code id="smtl_+3A_scale">scale</code></td>
<td>
<p>A boolean specifying whether to center and scale covariates before model fitting (either way coefficient estimates are returned on original scale before centering/scaling)</p>
</td></tr>
<tr><td><code id="smtl_+3A_maxiter">maxIter</code></td>
<td>
<p>An integer specifying the maximum number of coordinate descent iterations before</p>
</td></tr>
<tr><td><code id="smtl_+3A_locsrch_maxiter">LocSrch_maxIter</code></td>
<td>
<p>An integer specifying the number of maximum local search iterations</p>
</td></tr>
<tr><td><code id="smtl_+3A_messageind">messageInd</code></td>
<td>
<p>A boolean specifying whether to include messages (verbose)</p>
</td></tr>
<tr><td><code id="smtl_+3A_model">model</code></td>
<td>
<p>A boolean indicating whether to return design matrix and outcome vector</p>
</td></tr>
<tr><td><code id="smtl_+3A_independent.regs">independent.regs</code></td>
<td>
<p>A boolean specifying whether to fit independent regressions (instead of multi-task). This ensures there is NO information sharing via active sets or penalties</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list (object of S3 class). </p>
<table role = "presentation">
<tr><td><code>beta</code></td>
<td>
<p> Matrix with coefficient estimates where column j are estimates from task j.</p>
</td></tr>
<tr><td><code>reg_type</code></td>
<td>
<p> String specifying whether model is <code>"multiStudy"</code> denoting that there is a separate design matrix for each task, <code>"multiLabel"</code> where the design matrix is the same 
across tasks and <code>"L0"</code> indicating a single-task regression.</p>
</td></tr> <tr><td><code>K</code></td>
<td>
<p> Integer that indicates number of tasks.</p>
</td></tr> <tr><td><code>s</code></td>
<td>
<p> An integer that indicates sparsity level.</p>
</td></tr> <tr><td><code>commonSupp</code></td>
<td>
<p> Boolean 
indicating of supports are common across tasks.</p>
</td></tr> <tr><td><code>warmStart</code></td>
<td>
<p> A Boolean indicating whether to fit a MTL model as a warm start.</p>
</td></tr> <tr><td><code>grid</code></td>
<td>
<p> A dataframe including grid of hyperparameters that model
is fit on.</p>
</td></tr> <tr><td><code>maxIter</code></td>
<td>
<p> An integer specifying the maximum number of iterations of block CD.</p>
</td></tr> <tr><td><code>LocSrch_maxIter</code></td>
<td>
<p> An integer specify the maximum number of iterations of local search.</p>
</td></tr>
<tr><td><code>independent.regs</code></td>
<td>
<p> A boolean indicating whether to make each task independent of each other (no shared active sets).</p>
</td></tr> <tr><td><code>AS_multiplier</code></td>
<td>
<p> An integer specifying the active set multiplier.</p>
</td></tr> 
<tr><td><code>X_train</code></td>
<td>
<p> A Matrix: the design matrix (row concatenated across tasks).</p>
</td></tr> <tr><td><code>y_train</code></td>
<td>
<p> The outcome vector or matrix.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 

if (identical(Sys.getenv("AUTO_JULIA_INSTALL"), "true")) { ## The examples are quite time consuming
## Do initiation for and automatic installation if necessary

# load package
library(sMTL)
smtl_setup()

#####################################################################################
##### simulate data
#####################################################################################
set.seed(1) # fix the seed to get a reproducible result
K &lt;- 4 # number of datasets 
p &lt;- 100 # covariate dimension
s &lt;- 5 # support size
q &lt;- 7 # size of subset of covariates that can be non-zero for any task
n_k &lt;- 50 # task sample size
N &lt;- n_k * p # full dataset samplesize
X &lt;- matrix( rnorm(N * p), nrow = N, ncol=p) # full design matrix
B &lt;- matrix(1 + rnorm(K * (p+1) ), nrow = p + 1, ncol = K) # betas before making sparse
Z &lt;- matrix(0, nrow = p, ncol = K) # matrix of supports
y &lt;- vector(length = N) # outcome vector

# randomly sample support to make betas sparse
for(j in 1:K)     Z[1:q, j] &lt;- sample( c( rep(1,s), rep(0, q - s) ), q, replace = FALSE )
B[-1,] &lt;- B[-1,] * Z # make betas sparse and ensure all models have an intercept

task &lt;- rep(1:K, each = n_k) # vector of task labels (indices)

# iterate through and make each task specific dataset
for(j in 1:K){
    indx &lt;- which(task == j) # indices of task
    e &lt;- rnorm(n_k)
    y[indx] &lt;- B[1, j] + X[indx,] %*% B[-1,j] + e
    }
    colnames(B) &lt;- paste0("beta_", 1:K)
    rownames(B) &lt;- paste0("X_", 1:(p+1))
    
    print("Betas")
    print(round(B[1:8,],2))
    
#####################################################################################
##### fit Multi-Task Learning Model for Heterogeneous Support
#####################################################################################
  
    mod &lt;- sMTL::smtl(y = y, 
                      X = X, 
                      study = task, 
                      s = 5, 
                      commonSupp = FALSE,
                      lambda_1 = 0.001,
                      lambda_2 = 0,
                      lambda_z = 0.25)
    
    print(round(mod$beta[1:8,],2))
    
    # make predictions
    preds &lt;- sMTL::predict(model = mod, X = X[1:5,])
    
#####################################################################################
##### fit Multi-Task Learning Model for Common Support
#####################################################################################
    library(sMTL)
    sMTL::smtl_setup(path = "/Applications/Julia-1.5.app/Contents/Resources/julia/bin")
    mod &lt;- sMTL::smtl(y = y, 
                      X = X, 
                      study = task, 
                      s = 5, 
                      commonSupp = TRUE,
                      lambda_1 = 0.001,
                      lambda_2 = 0.5)
    
    print(round(mod$beta[1:8,],2))
    }
    
## End(Not run)
    
</code></pre>

<hr>
<h2 id='smtl_setup'>smtl_setup: setup Julia path and/or install Julia or Julia packages using functions based on external package JuliaCall::julia_setup().</h2><span id='topic+smtl_setup'></span>

<h3>Description</h3>

<p>smtl_setup: setup Julia path and/or install Julia or Julia packages using functions based on external package JuliaCall::julia_setup().
</p>


<h3>Usage</h3>

<pre><code class='language-R'>smtl_setup(path = NULL, installJulia = FALSE, installPackages = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="smtl_setup_+3A_path">path</code></td>
<td>
<p>A string</p>
</td></tr>
<tr><td><code id="smtl_setup_+3A_installjulia">installJulia</code></td>
<td>
<p>A boolean.</p>
</td></tr>
<tr><td><code id="smtl_setup_+3A_installpackages">installPackages</code></td>
<td>
<p>A boolean.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A message indicating either Julia language or package installation status or the path of Julia Binary on your computer. See vignette if you have problems
specifying the path of Julia binary correctly.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 

if (identical(Sys.getenv("AUTO_JULIA_INSTALL"), "true")) { ## The examples are quite time consuming
## Do initiation for and automatic installation if necessary
##################################################################
# First Time Loading, Julia is Installed and Julia Path is Known 
##################################################################
smtl_setup(path = "/Applications/Julia-1.5.app/Contents/Resources/julia/bin", 
           installJulia = FALSE, 
           installPackages = FALSE)

#####################################################################################
# If you have run smtl_setup() before, then path specification shouldn't be necessary
#####################################################################################
smtl_setup(path = NULL, installJulia = FALSE, installPackages = FALSE)

#####################################################################################
##### First Time Loading, Julia is Not Installed   ######
#####################################################################################
smtl_setup(path = NULL, installJulia = TRUE, installPackages = FALSE)

#####################################################################################
##### First Time Loading, Julia is Installed But Packages NEED INSTALLATION  ######
#####################################################################################
smtl_setup(path = "/Applications/Julia-1.5.app/Contents/Resources/julia/bin", 
           installJulia = TRUE, 
           installPackages = TRUE)
           
           }
           
 
## End(Not run)
           
</code></pre>

<hr>
<h2 id='sparseCV'>sparseCV: cross-validation functions. For internal package use only.</h2><span id='topic+sparseCV'></span>

<h3>Description</h3>

<p>sparseCV: cross-validation functions. For internal package use only.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sparseCV(
  data,
  tune.grid,
  hoso = "hoso",
  method = "L0",
  nfolds = "K",
  juliaFnPath = NA,
  messageInd = FALSE,
  LSitr = 50,
  LSspc = 1,
  maxIter = 2500
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="sparseCV_+3A_data">data</code></td>
<td>
<p>Matrix with outcome and design matrix</p>
</td></tr>
<tr><td><code id="sparseCV_+3A_tune.grid">tune.grid</code></td>
<td>
<p>A data.frame of tuning values</p>
</td></tr>
<tr><td><code id="sparseCV_+3A_hoso">hoso</code></td>
<td>
<p>String specifying tuning type</p>
</td></tr>
<tr><td><code id="sparseCV_+3A_method">method</code></td>
<td>
<p>Sting specifying regression method</p>
</td></tr>
<tr><td><code id="sparseCV_+3A_nfolds">nfolds</code></td>
<td>
<p>String or integer specifying number of folds</p>
</td></tr>
<tr><td><code id="sparseCV_+3A_juliafnpath">juliaFnPath</code></td>
<td>
<p>String specifying path to Julia binary</p>
</td></tr>
<tr><td><code id="sparseCV_+3A_messageind">messageInd</code></td>
<td>
<p>Boolean for message printing</p>
</td></tr>
<tr><td><code id="sparseCV_+3A_lsitr">LSitr</code></td>
<td>
<p>Integer specifying do &lt;LSitr&gt; local search iterations on parameter values where we do actually do LS; NA does no local search</p>
</td></tr>
<tr><td><code id="sparseCV_+3A_lsspc">LSspc</code></td>
<td>
<p>Integer specifying number of hyperparameters to conduct local search: conduct local search every &lt;LSspc&gt;^th iteration. NA does no local search</p>
</td></tr>
<tr><td><code id="sparseCV_+3A_maxiter">maxIter</code></td>
<td>
<p>Integer specifying max iterations of coordinate descent</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list (S3 class) with elements used for cross validation. </p>
<table role = "presentation">
<tr><td><code>best</code></td>
<td>
<p> A dataframe with the hyperparameters associated with the best prediction performance and summary statistics of performance.</p>
</td></tr>
<tr><td><code>best.1se</code></td>
<td>
<p> A dataframe including optimal hyperparameters according to 1-standard deviation rule.</p>
</td></tr>  <tr><td><code>rmse</code></td>
<td>
<p> A dataframe with prediction performance for hyperparamters in tuning grid for all folds.</p>
</td></tr>
<tr><td><code>avg</code></td>
<td>
<p> A dataframe with average performance at each of the hyperparameters in tuning grid (averaged across tasks).</p>
</td></tr>
</table>

<hr>
<h2 id='sparseCV_MT'>sparseCV_MT: internal cross-validation functions. For internal package use only.</h2><span id='topic+sparseCV_MT'></span>

<h3>Description</h3>

<p>sparseCV_MT: internal cross-validation functions. For internal package use only.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sparseCV_MT(
  data,
  tune.grid,
  hoso = "hoso",
  method = "L0",
  nfolds = "K",
  juliaFnPath = NA,
  messageInd = FALSE,
  LSitr = 50,
  LSspc = 1,
  maxIter = 2500
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="sparseCV_MT_+3A_data">data</code></td>
<td>
<p>Matrix with outcome and design matrix</p>
</td></tr>
<tr><td><code id="sparseCV_MT_+3A_tune.grid">tune.grid</code></td>
<td>
<p>A data.frame of tuning values</p>
</td></tr>
<tr><td><code id="sparseCV_MT_+3A_hoso">hoso</code></td>
<td>
<p>String specifying tuning type</p>
</td></tr>
<tr><td><code id="sparseCV_MT_+3A_method">method</code></td>
<td>
<p>Sting specifying regression method</p>
</td></tr>
<tr><td><code id="sparseCV_MT_+3A_nfolds">nfolds</code></td>
<td>
<p>String or integer specifying number of folds</p>
</td></tr>
<tr><td><code id="sparseCV_MT_+3A_juliafnpath">juliaFnPath</code></td>
<td>
<p>String specifying path to Julia binary</p>
</td></tr>
<tr><td><code id="sparseCV_MT_+3A_messageind">messageInd</code></td>
<td>
<p>Boolean for message printing</p>
</td></tr>
<tr><td><code id="sparseCV_MT_+3A_lsitr">LSitr</code></td>
<td>
<p>Integer specifying do &lt;LSitr&gt; local search iterations on parameter values where we do actually do LS; NA does no local search</p>
</td></tr>
<tr><td><code id="sparseCV_MT_+3A_lsspc">LSspc</code></td>
<td>
<p>Integer specifying number of hyperparameters to conduct local search: conduct local search every &lt;LSspc&gt;^th iteration. NA does no local search</p>
</td></tr>
<tr><td><code id="sparseCV_MT_+3A_maxiter">maxIter</code></td>
<td>
<p>Integer specifying max iterations of coordinate descent</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list (S3 class) with elements used for cross validation. </p>
<table role = "presentation">
<tr><td><code>best</code></td>
<td>
<p> A dataframe with the hyperparameters associated with the best prediction performance and summary statistics of performance.</p>
</td></tr>
<tr><td><code>best.1se</code></td>
<td>
<p> A dataframe including optimal hyperparameters according to 1-standard deviation rule.</p>
</td></tr>  <tr><td><code>rmse</code></td>
<td>
<p> A dataframe with prediction performance for hyperparamters in tuning grid for all folds.</p>
</td></tr>
<tr><td><code>avg</code></td>
<td>
<p> A dataframe with average performance at each of the hyperparameters in tuning grid (averaged across tasks).</p>
</td></tr>
</table>

<hr>
<h2 id='sparseL0Tn_iht'>sparseCV_L0: cross-validation functions. For internal package use only.</h2><span id='topic+sparseL0Tn_iht'></span>

<h3>Description</h3>

<p>sparseCV_L0: cross-validation functions. For internal package use only.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sparseL0Tn_iht(
  data,
  tune.grid,
  hoso = "hoso",
  nfolds = "K",
  juliaFnPath = "/Users/gabeloewinger/Desktop/Research Final/Sparse Multi-Study/",
  trainingStudy = NA,
  messageInd = FALSE,
  LSitr = 50,
  LSspc = 1,
  maxIter = 2500
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="sparseL0Tn_iht_+3A_data">data</code></td>
<td>
<p>Matrix with outcome and design matrix</p>
</td></tr>
<tr><td><code id="sparseL0Tn_iht_+3A_tune.grid">tune.grid</code></td>
<td>
<p>A data.frame of tuning values</p>
</td></tr>
<tr><td><code id="sparseL0Tn_iht_+3A_hoso">hoso</code></td>
<td>
<p>String specifying tuning type</p>
</td></tr>
<tr><td><code id="sparseL0Tn_iht_+3A_nfolds">nfolds</code></td>
<td>
<p>String or integer specifying number of folds</p>
</td></tr>
<tr><td><code id="sparseL0Tn_iht_+3A_juliafnpath">juliaFnPath</code></td>
<td>
<p>String specifying path to Julia binary</p>
</td></tr>
<tr><td><code id="sparseL0Tn_iht_+3A_trainingstudy">trainingStudy</code></td>
<td>
<p>Integer specifying index of training study</p>
</td></tr>
<tr><td><code id="sparseL0Tn_iht_+3A_messageind">messageInd</code></td>
<td>
<p>Boolean for message printing</p>
</td></tr>
<tr><td><code id="sparseL0Tn_iht_+3A_lsitr">LSitr</code></td>
<td>
<p>Integer specifying do &lt;LSitr&gt; local search iterations on parameter values where we do actually do LS; NA does no local search</p>
</td></tr>
<tr><td><code id="sparseL0Tn_iht_+3A_lsspc">LSspc</code></td>
<td>
<p>Integer specifying number of hyperparameters to conduct local search: conduct local search every &lt;LSspc&gt;^th iteration. NA does no local search</p>
</td></tr>
<tr><td><code id="sparseL0Tn_iht_+3A_maxiter">maxIter</code></td>
<td>
<p>Integer specifying max iterations of coordinate descent</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list (S3 class) with elements used for cross validation. </p>
<table role = "presentation">
<tr><td><code>best</code></td>
<td>
<p> A dataframe with the hyperparameters associated with the best prediction performance and summary statistics of performance.</p>
</td></tr>
<tr><td><code>best.1se</code></td>
<td>
<p> A dataframe including optimal hyperparameters according to 1-standard deviation rule.</p>
</td></tr>  <tr><td><code>rmse</code></td>
<td>
<p> A dataframe with prediction performance for hyperparamters in tuning grid for all folds.</p>
</td></tr>
<tr><td><code>avg</code></td>
<td>
<p> A dataframe with average performance at each of the hyperparameters in tuning grid (averaged across tasks).</p>
</td></tr>
</table>

<hr>
<h2 id='tuneZscale'>tuneZscale: scale lambda_z depending on magnitude. For internal package use only.</h2><span id='topic+tuneZscale'></span>

<h3>Description</h3>

<p>tuneZscale: scale lambda_z depending on magnitude. For internal package use only.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tuneZscale(tune.grid, rhoScale)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="tuneZscale_+3A_tune.grid">tune.grid</code></td>
<td>
<p>A dataframe</p>
</td></tr>
<tr><td><code id="tuneZscale_+3A_rhoscale">rhoScale</code></td>
<td>
<p>A dataframe</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A dataframe that includes tuning grid with the lambda_z hyperparameter re-scaled appropriately for sparsity levels (s).
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
