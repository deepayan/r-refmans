<!DOCTYPE html><html lang="en"><head><title>Help for package AdaSampling</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {AdaSampling}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#adaSample'><p>Implementation of AdaSampling for positive unlabelled and label noise</p>
learning.</a></li>
<li><a href='#adaSvmBenchmark'><p>Benchmarking AdaSampling efficacy on noisy labelled data.</p></a></li>
<li><a href='#brca'><p>Wisconsin Breast Cancer Database (1991)</p></a></li>
<li><a href='#singleIter'><p><code>singleIter()</code> applies a single iteraction of AdaSampling procedure. It</p>
returns the probabilities of all samples as being a positive (P) or negative
(N) instance, as a two column data frame.</a></li>
<li><a href='#weightedKNN'><p>Implementation of a feature weighted k-nearest neighbour classifier.</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Adaptive Sampling for Positive Unlabeled and Label Noise
Learning</td>
</tr>
<tr>
<td>Version:</td>
<td>1.3</td>
</tr>
<tr>
<td>Author:</td>
<td>Pengyi Yang</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Pengyi Yang &lt;yangpy7@gmail.com&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Implements the adaptive sampling procedure, a framework for both positive unlabeled learning and learning with class label noise. Yang, P., Ormerod, J., Liu, W., Ma, C., Zomaya, A., Yang, J. (2018) &lt;<a href="https://doi.org/10.1109%2FTCYB.2018.2816984">doi:10.1109/TCYB.2018.2816984</a>&gt;.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.4.0)</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>Imports:</td>
<td>caret (&ge; 6.0-78) , class (&ge; 7.3-14), e1071 (&ge; 1.6-8),
stats, MASS</td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/PengyiYang/AdaSampling/issues">https://github.com/PengyiYang/AdaSampling/issues</a></td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, rmarkdown</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/PengyiYang/AdaSampling/">https://github.com/PengyiYang/AdaSampling/</a></td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>6.1.1</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2019-05-21 08:02:40 UTC; pengyiyang</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2019-05-21 08:20:04 UTC</td>
</tr>
</table>
<hr>
<h2 id='adaSample'>Implementation of AdaSampling for positive unlabelled and label noise
learning.</h2><span id='topic+adaSample'></span>

<h3>Description</h3>

<p><code>adaSample()</code> applies the AdaSampling procedure to reduce noise
in the training set, and subsequently trains a classifier from
the new training set. For each row (observation) in the test set, it
returns the probabilities of it being a positive (&quot;P) or negative
(&quot;N&quot;) instance, as a two column data frame.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>adaSample(Ps, Ns, train.mat, test.mat, classifier = "svm", s = 1,
  C = 1, sampleFactor = 1, weights = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="adaSample_+3A_ps">Ps</code></td>
<td>
<p>names (each instance in the data has to be named) of positive examples</p>
</td></tr>
<tr><td><code id="adaSample_+3A_ns">Ns</code></td>
<td>
<p>names (each instance in the data has to be named) of negative examples</p>
</td></tr>
<tr><td><code id="adaSample_+3A_train.mat">train.mat</code></td>
<td>
<p>training data matrix, without class labels.</p>
</td></tr>
<tr><td><code id="adaSample_+3A_test.mat">test.mat</code></td>
<td>
<p>test data matrix, without class labels.</p>
</td></tr>
<tr><td><code id="adaSample_+3A_classifier">classifier</code></td>
<td>
<p>classification algorithm to be used for learning. Current options are
support vector machine, <code>"svm"</code>, k-nearest neighbour, <code>"knn"</code>, logistic regression <code>"logit"</code>,
linear discriminant analysis <code>"lda"</code>, and feature weighted knn, <code>"wKNN"</code>.</p>
</td></tr>
<tr><td><code id="adaSample_+3A_s">s</code></td>
<td>
<p>sets the seed.</p>
</td></tr>
<tr><td><code id="adaSample_+3A_c">C</code></td>
<td>
<p>sets how many times to run the classifier, C&gt;1 induces an ensemble learning model.</p>
</td></tr>
<tr><td><code id="adaSample_+3A_samplefactor">sampleFactor</code></td>
<td>
<p>provides a control on the sample size for resampling.</p>
</td></tr>
<tr><td><code id="adaSample_+3A_weights">weights</code></td>
<td>
<p>feature weights, required when using weighted knn.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>adaSample()</code> is an adaptive sampling-based noise reduction method
to deal with noisy class labelled data, which acts as a wrapper for
traditional classifiers, such as support vector machines,
k-nearest neighbours, logistic regression, and linear discriminant
analysis.
</p>
<p>This process is used to build up a noise-minimized training set
that is derived by iteratively resampling the training set,
(<code>train</code>) based on probabilities derived after its classification.
</p>
<p>This sampled training set is then used to train a classifier, which
is then executed on the test set. <code>adaSample()</code> returns a series of
predictions for each row of the test set.
</p>
<p>Note that this function does not evaluate the quality of the model
and thus does not compare its output to true values of the test set.
To assess please see <code>adaSvmBenchmark()</code>.
</p>


<h3>Value</h3>

<p>a two column matrix providing classification probabilities of each sample 
with respect to positive and negative classes
</p>


<h3>References</h3>

<p>Yang, P., Liu, W., Yang. J. (2017) Positive unlabeled learning via wrapper-based
adaptive sampling. <em>International Joint Conferences on Artificial Intelligence (IJCAI)</em>, 3272-3279
</p>
<p>Yang, P., Ormerod, J., Liu, W., Ma, C., Zomaya, A., Yang, J.(2018) 
AdaSampling for positive-unlabeled and label noise learning with bioinformatics applications. 
<em>IEEE Transactions on Cybernetics</em>, doi:10.1109/TCYB.2018.2816984
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Load the example dataset
data(brca)
head(brca)

# First, clean up the dataset to transform into the required format.
brca.mat &lt;- apply(X = brca[,-10], MARGIN = 2, FUN = as.numeric)
brca.cls &lt;- sapply(X = brca$cla, FUN = function(x) {ifelse(x == "malignant", 1, 0)})
rownames(brca.mat) &lt;- paste("p", 1:nrow(brca.mat), sep="_")

# Introduce 40% noise to positive class and 30% noise to the negative class
set.seed(1)
pos &lt;- which(brca.cls == 1)
neg &lt;- which(brca.cls == 0)
brca.cls.noisy &lt;- brca.cls
brca.cls.noisy[sample(pos, floor(length(pos) * 0.4))] &lt;- 0
brca.cls.noisy[sample(neg, floor(length(neg) * 0.3))] &lt;- 1

# Identify positive and negative examples from the noisy dataset
Ps &lt;- rownames(brca.mat)[which(brca.cls.noisy == 1)]
Ns &lt;- rownames(brca.mat)[which(brca.cls.noisy == 0)]

# Apply AdaSampling method on the noisy data
brca.preds &lt;- adaSample(Ps, Ns, train.mat=brca.mat, test.mat=brca.mat, classifier = "knn")
head(brca.preds)

# Orignal accuracy from the labels
accuracy &lt;- sum(brca.cls.noisy == brca.cls) / length(brca.cls)
accuracy

# Accuracy after applying AdaSampling method
accuracyWithAdaSample &lt;- sum(ifelse(brca.preds[,"P"] &gt; 0.5, 1, 0) == brca.cls) / length(brca.cls)
accuracyWithAdaSample

</code></pre>

<hr>
<h2 id='adaSvmBenchmark'>Benchmarking AdaSampling efficacy on noisy labelled data.</h2><span id='topic+adaSvmBenchmark'></span>

<h3>Description</h3>

<p><code>adaSvmBenchmark()</code> allows a comparison between the performance
of an AdaSampling-enhanced SVM (support vector machine)-
classifier against the SVM-classifier on its
own. It requires a matrix of features (extracted from a labelled dataset),
and two vectors of true labels and labels with noise added as desired.
It runs an SVM classifier and returns a matrix which displays the specificity
(Sp), sensitivity (Se) and F1 score for each of four conditions:
&quot;Original&quot; (classifying with true labels), &quot;Baseline&quot; (classifying with
noisy labels), &quot;AdaSingle&quot; (classifying using AdaSampling) and
&quot;AdaEnsemble&quot; (classifying using AdaSampling in conjunction with
an ensemble of models).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>adaSvmBenchmark(data.mat, data.cls, data.cls.truth, cvSeed, C = 50,
  sampleFactor = 1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="adaSvmBenchmark_+3A_data.mat">data.mat</code></td>
<td>
<p>a rectangular matrix or data frame that can be
coerced to a matrix, containing the
features of the dataset, without class labels. Rownames (possibly
containing unique identifiers) will be ignored.</p>
</td></tr>
<tr><td><code id="adaSvmBenchmark_+3A_data.cls">data.cls</code></td>
<td>
<p>a numeric vector containing class labels for the dataset
with added noise.
Must be in the same order and of the same length as <code>data.mat</code>. Labels
must be 1 for positive observations, and 0 for negative observations.</p>
</td></tr>
<tr><td><code id="adaSvmBenchmark_+3A_data.cls.truth">data.cls.truth</code></td>
<td>
<p>a numeric vector of true class labels for
the dataset. Must be the same order and of the same length as <code>data.mat</code>. Labels must
be 1, for positive observations, and 0 for negative observations.</p>
</td></tr>
<tr><td><code id="adaSvmBenchmark_+3A_cvseed">cvSeed</code></td>
<td>
<p>sets the seed for cross-validation.</p>
</td></tr>
<tr><td><code id="adaSvmBenchmark_+3A_c">C</code></td>
<td>
<p>sets how many times to run the classifier, for the AdaEnsemble
condition. See Description above.</p>
</td></tr>
<tr><td><code id="adaSvmBenchmark_+3A_samplefactor">sampleFactor</code></td>
<td>
<p>provides a control on the sample size for resampling.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>AdaSampling is an adaptive sampling-based noise reduction method
to deal with noisy class labelled data, which acts as a wrapper for
traditional classifiers, such as support vector machines,
k-nearest neighbours, logistic regression, and linear discriminant
analysis. For more details see <code>?adaSample()</code>.
</p>
<p>This function runs evaluates the AdaSampling procedure by adding noise
to a labelled dataset, and then running support vector machines on
the original and the noisy dataset. Note that this function is for
benchmarking AdaSampling performance using what is assumed to be
a well-labelled dataset. In order to run AdaSampling on a noisy dataset,
please see <code>adaSample()</code>.
</p>


<h3>Value</h3>

<p>performance matrix
</p>


<h3>References</h3>

<p>Yang, P., Liu, W., Yang. J. (2017) Positive unlabeled learning via wrapper-based
adaptive sampling. <em>International Joint Conferences on Artificial Intelligence (IJCAI)</em>, 3272-3279
</p>
<p>Yang, P., Ormerod, J., Liu, W., Ma, C., Zomaya, A., Yang, J.(2018) 
AdaSampling for positive-unlabeled and label noise learning with bioinformatics applications. 
<em>IEEE Transactions on Cybernetics</em>, doi:10.1109/TCYB.2018.2816984
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Load the example dataset
data(brca)
head(brca)

# First, clean up the dataset to transform into the required format.
brca.mat &lt;- apply(X = brca[,-10], MARGIN = 2, FUN = as.numeric)
brca.cls &lt;- sapply(X = brca$cla, FUN = function(x) {ifelse(x == "malignant", 1, 0)})
rownames(brca.mat) &lt;- paste("p", 1:nrow(brca.mat), sep="_")

# Introduce 40% noise to positive class and 30% noise to the negative class
set.seed(1)
pos &lt;- which(brca.cls == 1)
neg &lt;- which(brca.cls == 0)
brca.cls.noisy &lt;- brca.cls
brca.cls.noisy[sample(pos, floor(length(pos) * 0.4))] &lt;- 0
brca.cls.noisy[sample(neg, floor(length(neg) * 0.3))] &lt;- 1

# benchmark classification performance with different approaches

adaSvmBenchmark(data.mat = brca.mat, data.cls = brca.cls.noisy, data.cls.truth = brca.cls, cvSeed=1)


</code></pre>

<hr>
<h2 id='brca'>Wisconsin Breast Cancer Database (1991)</h2><span id='topic+brca'></span>

<h3>Description</h3>

<p>A cleaned version of the original Wisconsin Breast Cancer
dataset containing histological information about 683
breast cancer samples collected from patients at the
University of Wisconsin Hospitals, Madison by
Dr. William H. Wolberg between January
1989 and November 1991.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>brca
</code></pre>


<h3>Format</h3>

<p>A data frame with 683 rows and 10 variables:
</p>

<dl>
<dt>clt</dt><dd><p>Clump thickness, 1 - 10</p>
</dd>
<dt>ucs</dt><dd><p>Uniformity of cell size, 1 - 10</p>
</dd>
<dt>uch</dt><dd><p>Uniformity of cell shape, 1 - 10</p>
</dd>
<dt>mad</dt><dd><p>Marginal adhesion, 1 - 10</p>
</dd>
<dt>ecs</dt><dd><p>Single epithelial cell size, 1 - 10</p>
</dd>
<dt>nuc</dt><dd><p>Bare nuclei, 1 - 10</p>
</dd>
<dt>chr</dt><dd><p>Bland chromatin, 1 - 10</p>
</dd>
<dt>ncl</dt><dd><p>Normal nucleoli, 1 - 10</p>
</dd>
<dt>mit</dt><dd><p>Mitoses, 1 - 10</p>
</dd>
<dt>cla</dt><dd><p>Class, benign or malignant</p>
</dd>
</dl>


<h3>Source</h3>

<p><a href="https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/breast-cancer-wisconsin.data">https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/breast-cancer-wisconsin.data</a>
</p>


<h3>References</h3>

<p>O. L. Mangasarian and W. H. Wolberg: &quot;Cancer diagnosis via linear
programming&quot;, <em>SIAM News</em>, Volume 23, Number 5, September 1990, pp 1 &amp; 18.
</p>

<hr>
<h2 id='singleIter'><code>singleIter()</code> applies a single iteraction of AdaSampling procedure. It
returns the probabilities of all samples as being a positive (P) or negative
(N) instance, as a two column data frame.</h2><span id='topic+singleIter'></span>

<h3>Description</h3>

<p>Classification algorithms included are support vector machines (svm),
k-nearest neighbours (knn), logistic regression (logit), linear discriminant
analysis (lda), feature weighted knn (wKNN).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>singleIter(Ps, Ns, dat, test = NULL, pos.probs = NULL,
  una.probs = NULL, classifier = "svm", sampleFactor, seed, weights)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="singleIter_+3A_ps">Ps</code></td>
<td>
<p>names (name as index) of positive examples</p>
</td></tr>
<tr><td><code id="singleIter_+3A_ns">Ns</code></td>
<td>
<p>names (name as index) of negative examples</p>
</td></tr>
<tr><td><code id="singleIter_+3A_dat">dat</code></td>
<td>
<p>training data matrix, without class labels.</p>
</td></tr>
<tr><td><code id="singleIter_+3A_test">test</code></td>
<td>
<p>test data matrix, without class labels.
Training data matrix will be used for testing if this is NULL (default).</p>
</td></tr>
<tr><td><code id="singleIter_+3A_pos.probs">pos.probs</code></td>
<td>
<p>a numeric vector of containing probability of positive examples been positive</p>
</td></tr>
<tr><td><code id="singleIter_+3A_una.probs">una.probs</code></td>
<td>
<p>a numeric vector of containing probability of negative or unannotated examples been negative</p>
</td></tr>
<tr><td><code id="singleIter_+3A_classifier">classifier</code></td>
<td>
<p>classification algorithm to be used for learning. Current options are
support vector machine, <code>"svm"</code>, k-nearest neighbour, <code>"knn"</code>, logistic regression <code>"logit"</code>,
linear discriminant analysis <code>"lda"</code>, and feature weighted knn, <code>"wKNN"</code>.</p>
</td></tr>
<tr><td><code id="singleIter_+3A_samplefactor">sampleFactor</code></td>
<td>
<p>provides a control on the sample size for resampling.</p>
</td></tr>
<tr><td><code id="singleIter_+3A_seed">seed</code></td>
<td>
<p>sets the seed.</p>
</td></tr>
<tr><td><code id="singleIter_+3A_weights">weights</code></td>
<td>
<p>feature weights, required when using weighted knn.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Yang, P., Liu, W., Yang. J. (2017) Positive unlabeled learning via wrapper-based
adaptive sampling. <em>International Joint Conferences on Artificial Intelligence (IJCAI)</em>, 3272-3279
</p>
<p>Yang, P., Ormerod, J., Liu, W., Ma, C., Zomaya, A., Yang, J.(2018) 
AdaSampling for positive-unlabeled and label noise learning with bioinformatics applications. 
<em>IEEE Transactions on Cybernetics</em>, doi:10.1109/TCYB.2018.2816984
</p>

<hr>
<h2 id='weightedKNN'>Implementation of a feature weighted k-nearest neighbour classifier.</h2><span id='topic+weightedKNN'></span>

<h3>Description</h3>

<p>Implementation of a feature weighted k-nearest neighbour classifier.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>weightedKNN(train.mat, test.mat, cl, k = 3, weights)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="weightedKNN_+3A_train.mat">train.mat</code></td>
<td>
<p>training data matrix, without class labels.</p>
</td></tr>
<tr><td><code id="weightedKNN_+3A_test.mat">test.mat</code></td>
<td>
<p>test data matrix, without class labels.</p>
</td></tr>
<tr><td><code id="weightedKNN_+3A_cl">cl</code></td>
<td>
<p>class labels for training data.</p>
</td></tr>
<tr><td><code id="weightedKNN_+3A_k">k</code></td>
<td>
<p>number of nearest neighbour to be used.</p>
</td></tr>
<tr><td><code id="weightedKNN_+3A_weights">weights</code></td>
<td>
<p>weights to be assigned to each feautre.</p>
</td></tr>
</table>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
