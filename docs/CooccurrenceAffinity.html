<!DOCTYPE html><html lang="en"><head><title>Help for package CooccurrenceAffinity</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {CooccurrenceAffinity}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#AcceptAffCI'><p>Acceptability Interval</p></a></li>
<li><a href='#AcceptAffin'><p>Calculates the &quot;Acceptability Function&quot; used in defining Blaker's (2000) Acceptability Interval and computing the latter in the function AcceptAffCI().</p></a></li>
<li><a href='#affinity'><p>Computes alpha, probability, expected co-occurence, median interval, various confidence intervals, other indices of affinity, etc.</p></a></li>
<li><a href='#affinity2by2'><p>Maximum likelihood estimate and intervals of alpha, null expectation, p-value and traditional indices from a 2x2 table</p></a></li>
<li><a href='#AlphInts'><p>Median interval, four confidence intervals, null expectation of cooccurrence count, and p-value</p></a></li>
<li><a href='#Bisect'><p>Bisections for finding a root of a function</p></a></li>
<li><a href='#Covrg'><p>Coverage Probabilities for Confidence Intervals about alpha, for fixed true alpha</p></a></li>
<li><a href='#CovrgPlot'><p>Coverage probabilities of the confidence intervals, calculated and plotted</p></a></li>
<li><a href='#dataprep'><p>Occurrence matrix (e.g., species by site) data preparation for affinity() function</p></a></li>
<li><a href='#EHypMidP'><p>Quantile of the Extended Hypergeometric distribution approximated by the midP distribution function</p></a></li>
<li><a href='#EHypQuInt'><p>Interval of alpha values for which X is a specified q'th quantile</p></a></li>
<li><a href='#logLikExtHyp'><p>log of Extended Hypergeometric Likelihiood at (X, mA,mB,N, alpha)</p></a></li>
<li><a href='#MaxX.Int'><p>MaxX.Int computation</p></a></li>
<li><a href='#midP.EHyp'><p>midP.EHyp computation</p></a></li>
<li><a href='#minmaxAlpha.pFNCH'><p>integer-endpoint of range for which BiasedUrn::pFNCHHypergeo() works without error</p></a></li>
<li><a href='#MinX.Int'><p>MinX.Int computation</p></a></li>
<li><a href='#ML.Alpha'><p>Maximum likelihood estimate and intervals of alpha, null expectation and p-value of a 2x2 table</p></a></li>
<li><a href='#plotgg'><p>Heatmap plot of affinity() output</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Affinity in Co-Occurrence Data</td>
</tr>
<tr>
<td>Version:</td>
<td>1.0</td>
</tr>
<tr>
<td>Date:</td>
<td>2023-05-02</td>
</tr>
<tr>
<td>Description:</td>
<td>Computes a novel metric of affinity between two entities based on their co-occurrence 
  (using binary presence/absence data). The metric and its MLE, alpha hat, were advanced in 
  Mainali, Slud, et al, 2021 &lt;<a href="https://doi.org/10.1126%2Fsciadv.abj9204">doi:10.1126/sciadv.abj9204</a>&gt;. Various types of confidence intervals and median interval
  were developed in Mainali and Slud, 2022 &lt;<a href="https://doi.org/10.1101%2F2022.11.01.514801">doi:10.1101/2022.11.01.514801</a>&gt;.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 4.1), BiasedUrn (&ge; 2.0.9)</td>
</tr>
<tr>
<td>Imports:</td>
<td>cowplot, ggplot2, plyr, reshape</td>
</tr>
<tr>
<td>Suggests:</td>
<td>cooccur</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/kpmainali/CooccurrenceAffinity">https://github.com/kpmainali/CooccurrenceAffinity</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/kpmainali/CooccurrenceAffinity/issues">https://github.com/kpmainali/CooccurrenceAffinity/issues</a></td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.2</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-05-02 16:46:36 UTC; kpmainali</td>
</tr>
<tr>
<td>Author:</td>
<td>Kumar Mainali [aut, cre],
  Eric Slud [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Kumar Mainali &lt;kpmainali@gmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-05-03 18:45:42 UTC</td>
</tr>
</table>
<hr>
<h2 id='AcceptAffCI'>Acceptability Interval</h2><span id='topic+AcceptAffCI'></span>

<h3>Description</h3>

<p>This function calculates the &quot;Acceptability Interval&quot; of Blaker for the log-odds parameter alpha in the Extended Hypergeometric distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>AcceptAffCI(x, marg, lev, CPint)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="AcceptAffCI_+3A_x">x</code></td>
<td>
<p>integer co-occurrence count that should properly fall within the closed interval [max(0,mA+mB-N), min(mA,mB)]</p>
</td></tr>
<tr><td><code id="AcceptAffCI_+3A_marg">marg</code></td>
<td>
<p>a 3-entry integer vector (mA,mB,N) consisting of the first row and column totals and the table total for a 2x2 contingency table</p>
</td></tr>
<tr><td><code id="AcceptAffCI_+3A_lev">lev</code></td>
<td>
<p>a confidence level, generally somewhere from 0.8 to 0.95  (default 0.95)</p>
</td></tr>
<tr><td><code id="AcceptAffCI_+3A_cpint">CPint</code></td>
<td>
<p>the exact conservative (&quot;Clopper-Pearson-type&quot;) interval CI.CP calculated in the function AlphInts()</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function calculates the &quot;Acceptability Interval&quot; based on &quot;Acceptability Function&quot; computed by AcceptAffin().
This interval, developed by Blaker (2000), was proved in that paper's Theorem 1 in a more general class of estimation problems
to have three essential properties: it falls within the CI.CP confidence interval; it maintains the property of being conservative,
i.e., of having coverage probability under the Extended Hypergeometric (mA,mB,N, alpha) distribution at least as large as the nominal level;
and it is larger when the confidence level is larger.
</p>


<h3>Value</h3>

<p>This function returns the &quot;Acceptability Interval&quot; of Blaker (2000). The code is adapted from Blaker's Splus code for the case of an unknown binomial proportion.
</p>


<h3>Author(s)</h3>

<p>Eric Slud
</p>


<h3>References</h3>

<p>Blaker, H. (2000), “Confidence curves and improved exact confidence intervals for discrete distributions&quot;, Canadian Journal of Statistics 28, 783-798.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>auxCP = AlphInts(30,c(50,80,120), lev=0.9)$CI.CP
AcceptAffCI(30,c(50,80,120), 0.9, auxCP)

AlphInts(30,c(50,80,120), lev=0.9)$CI.Blaker
</code></pre>

<hr>
<h2 id='AcceptAffin'>Calculates the &quot;Acceptability Function&quot; used in defining Blaker's (2000) Acceptability Interval and computing the latter in the function AcceptAffCI().</h2><span id='topic+AcceptAffin'></span>

<h3>Description</h3>

<p>This function calculates the &quot;Acceptability Function&quot; of Blaker (2000, Thm.1, p.785) for the log-odds parameter alpha in the Extended Hypergeometric distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>AcceptAffin(x, marg, alph)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="AcceptAffin_+3A_x">x</code></td>
<td>
<p>integer co-occurrence count that should properly fall within the closed interval [max(0,mA+mB-N), min(mA,mB)]</p>
</td></tr>
<tr><td><code id="AcceptAffin_+3A_marg">marg</code></td>
<td>
<p>a 3-entry integer vector (mA,mB,N) consisting of the first row and column totals and the table total for a 2x2 contingency table</p>
</td></tr>
<tr><td><code id="AcceptAffin_+3A_alph">alph</code></td>
<td>
<p>a vector of (one or more) real-valued &quot;alpha&quot; values, where alpha  is the log-odds parameter in the Extended Hypergeometric distribution</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function calculates the &quot;Acceptability Function&quot; of Blaker (2000, Thm.1, p.785) for the log-odds parameter alpha
in the Extended Hypergeometric distribution, a function from which the &quot;Acceptability Interval&quot; is calculated by another CooccurrenceAffinity package function AcceptAffCI().
</p>


<h3>Value</h3>

<p>This function returns the &quot;Acceptability Function&quot; that is later used by another function AcceptAffCI() to compute &quot;Acceptability Interval&quot;.
</p>


<h3>Author(s)</h3>

<p>Eric Slud
</p>


<h3>References</h3>

<p>Blaker, H. (2000), “Confidence curves and improved exact confidence intervals for discrete distributions&quot;, Canadian Journal of Statistics 28, 783-798.
</p>

<hr>
<h2 id='affinity'>Computes alpha, probability, expected co-occurence, median interval, various confidence intervals, other indices of affinity, etc.</h2><span id='topic+affinity'></span>

<h3>Description</h3>

<p>This is the principal function of &quot;CooccurrenceAffinity&quot; package that analyzes occurrence or abundance data (e.g., species by site)
using other functions of this package and returns several quantities in one main dataframe and (optionally) up to 11 square matrices.
This function processes data using dataprep() function and then feeds the data to analytical pipeline which includes ML.Alpha() and AlphInts().
The outputs of the function in the $all dataframe include the following: <br />
</p>

<ul>
<li><p> alpha_mle: maximum likelihood estimate of the log-odds parameter alpha in the Extended Hypergeometric distribution with fixed margins (mA,mB) and
table-total N, which is the &quot;log-affinity&quot; index of co-occurrence championed in a paper by
Mainali et al. (2022) as an index of co-occurrence-based similarity; computed in ML.Alpha() <br />
</p>
</li>
<li><p> exp_cooccur: expected co-occurrence count under the null (hypergeometric, corresponding to alpha=0) distribution; computed as ML.Alpha()$Null.Exp <br />
</p>
</li>
<li><p> p_value: the commonly reported P-value of the observed co-occurrences; computed by AlphInts()$pval <br />
</p>
</li>
<li><p> alpha_medianInt: the interval of alpha values compatible with x as median for the Extended Hypergeometric distribution (Harkness 1965) <br />
with fixed margins and alpha; computed in AlphInts() as $MedianIntrvl <br />
</p>
</li>
<li><p> conf_level: confidence level for estimating the various types of confidence intervals <br />
</p>
</li>
<li><p> ci_: fout types of confidence intervals (see details below) <br />
</p>
</li>
<li><p> jaccard: Jaccard index <br />
</p>
</li>
<li><p> sorensen: Sørensen-Dice index <br />
</p>
</li>
<li><p> simpson: Simpson index <br />
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>affinity(
  data,
  row.or.col,
  which.row.or.col = NULL,
  datatype = NULL,
  threshold = NULL,
  class0.rule = NULL,
  sigPval = NULL,
  sigdigit = NULL,
  squarematrix = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="affinity_+3A_data">data</code></td>
<td>
<p>occurrence matrix (binary or abundance) in matrix or dataframe format</p>
</td></tr>
<tr><td><code id="affinity_+3A_row.or.col">row.or.col</code></td>
<td>
<p>specify if the pairs of rows or columns are analyzed for affinity. 'row' or 'column'.</p>
</td></tr>
<tr><td><code id="affinity_+3A_which.row.or.col">which.row.or.col</code></td>
<td>
<p>a vector of name or the number of row/column if a subset of the data is intended to be analyzed; optional argument with default of all rows/columns.</p>
</td></tr>
<tr><td><code id="affinity_+3A_datatype">datatype</code></td>
<td>
<p>specify if the datatype is 'abundance' or 'binary'; optional argument with default 'binary'.</p>
</td></tr>
<tr><td><code id="affinity_+3A_threshold">threshold</code></td>
<td>
<p>cutoff for converting an abundance data to binary; needed if datatype is 'abundance'</p>
</td></tr>
<tr><td><code id="affinity_+3A_class0.rule">class0.rule</code></td>
<td>
<p>'less.or.equal' or 'less'. 'less.or.equal' converts a threshold or lower values to zero and all the others to 1. 'less' converts a threshold and higher values to 1.</p>
</td></tr>
<tr><td><code id="affinity_+3A_sigpval">sigPval</code></td>
<td>
<p>acceptable rate of false positives or probability of rejecting the null hypothesis when it is true, commonly known as alpha in hypothesis testing</p>
</td></tr>
<tr><td><code id="affinity_+3A_sigdigit">sigdigit</code></td>
<td>
<p>the number of decimals for rouding alpha mle, its intervals, expected cooccurence under the null, jaccard, sorensen and simpson indices</p>
</td></tr>
<tr><td><code id="affinity_+3A_squarematrix">squarematrix</code></td>
<td>
<p>a vector of quantities so that a square matrix for each of them is generated on the top of the main long matrix of all outputs.
&quot;alpha_mle&quot;, &quot;alpha_mle_sig&quot;, &quot;p_value&quot;, &quot;cooccur.null&quot;, &quot;cooccur.obs&quot;, &quot;jaccard&quot;, &quot;jaccard_sig&quot;, &quot;sorensen&quot;, &quot;sorensen_sig&quot;, &quot;simpson&quot;, &quot;simpson_sig&quot;, &quot;all&quot;.</p>
</td></tr>
<tr><td><code id="affinity_+3A_...">...</code></td>
<td>
<p>Additional arguments to control behavior of the function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function calculates &quot;alpha_mle&quot;, which is the maximum likelihood estimate of the log-odds paramater alpha within the Extended Hypergeometric distribition (Harkness 1965)
based on the count x and fixed table margins (mA,mB) and total N, which is the &quot;affinity&quot; index of co-occurrence championed in the paper of Mainali et al. (2022)
as an index of cooccurrence-based similarity.
</p>
<p>This function calculates five intervals, three of them using EHypQuInt, one using EHypMidP, and one using AcceptAffCI.
First (&quot;alpha_medianInt&quot;) is the interval of alpha values compatible with x as median for the Extended Hypergeometric distribution (Harkness 1965)
with fixed margins and alpha. Computed as AlphInts()$MedianIntrvl.
This interval quantifies the underlying discreteness of the Extended Hypergeometric and its impact on the estimation of alpha.
MedianIntrvl is an interval that will contain the MLE alpha-hat, and the mid-point of that interval is another reasonable estimator of alpha from the data.
</p>
<p>There are four confidence intervals computed in AlphInts(), called ci_cp, ci_blaker, ci_midQ, ci_midP, matching name of the outputs in standalone outputs of AlphInts(),
except the differences in capital/small letters. The boolean &quot;bound&quot; parameter is an option to prevent the intervals containing alpha-estimates
to extend to plus or minus infinity, based on a Bayesian argument.
The bound substituted for the Infinite endpoints is provably larger than the largest value the MLE can take whenever x avoids the enpoints max(mA+mB-N,0) and min(mA,mB)
of its logical range. The recommended confidence interval for alpha is CI.Blaker if a reliably conservative (over-large) coverage probability is desired, and CI.midP otherwise.
</p>
<p>&quot;ci_cp&quot;, computed as AlphInts()$CI.CP is an &quot;exact&quot; conservative test-based 2-sided confidence interval (analogous to the Clopper-Pearson (1934)
confidence interval for unknown binomial proportion) for alpha based on data (x,mA,mB,N)
</p>
<p>&quot;ci_blaker&quot;, computed as AlphInts()$CI.Blaker is the Acceptability Confidence Interval of Blaker (2000, Theorem 1)
which is a better confidence interval than the CP-type interval &quot;CI.CP&quot; in the sense of being contained within &quot;CI.CP&quot;
but still probably conservative, i.e., with coverage probability always at least as large as the nominal level.
</p>
<p>&quot;ci_midQ&quot;, computed as AlphInts()$CI.midQ has the endpoints obtained as the midpoints of quantile intervals
respectively to the (1+lev)/2 and (1-lev)/2 quantiles of the Extended Hypergeometric distribution.
</p>
<p>&quot;ci_midP&quot;, computed as AlphInts()$CI.midQ, behaves very similarly to &quot;CI.midQ&quot; and is defined by the midP approach analogous
to the midP confidence interval for binomial proportions (Agresti 2013, p.605), and is calculated from EHypMidP().
</p>
<p>The recommended (slightly conservative) confidence interval is CI.Blaker, while the very similar intervals CI.midQ and CI.midP have
coverage generally closer than CI.CP or CI.Blaker to the nominal level of coverage, at the cost of occasionally under-covering
by as much as 0.04 or 0.05 for confidence levels 0.90 or 0.95. The comparison among intervals, and different possible goals that CIs of
conservative or close-to-nominal coverage can serve, are similar to those compared by  Brown et al. (2001) for interval estimation of an unknown binomial proportion.
</p>
<p>&quot;p_value&quot; is the two-sided p-value for the equal-tailed test of the null hypothesis alpha=0. This p-value is calculated when pval=&quot;Blaker&quot;
according to Blaker's (2000) &quot;Acceptability&quot; function; if the input parameter pvalType of AlphInts() is anything else,
the p-value is calculated using the same idea as the midP confidence interval.
</p>
<p>ADDITIONAL ARGUMENTS can be supplied from ML.Alpha() and AlphInts().
</p>


<h3>Value</h3>

<p>This function returns one main long dataframe ($all) with various outputs in columns (a list given under &quot;details&quot;) for each of the pairs of the entities in row.
This function also outputs optionally upto 11 square matrices of NxN entities.
</p>


<h3>Author(s)</h3>

<p>Kumar Mainali
</p>


<h3>References</h3>

<p>Agresti, A. (2013) Categorical Data Analysis, 3rd edition, Wiley.
</p>
<p>Blaker, H. (2000), “Confidence curves and improved exact confidence intervals for discrete distributions&quot;, Canadian Journal of Statistics 28, 783-798.
</p>
<p>Brown, L., T. Cai, and A. DasGupta (2001), “Interval Estimation for a Binomial Proportion,” Statistical Science, 16, 101–117.
</p>
<p>Clopper, C., and E. Pearson (1934), “The Use of Confidence or Fiducial Limits Illustrated in the Case of the Binomial,” Biometrika, 26, 404–413.
</p>
<p>Fog, A. (2015), BiasedUrn: Biased Urn Model Distributions. R package version 1.07.
</p>
<p>Harkness, W. (1965), “Properties of the extended hypergeometric distribution“, Annals of Mathematical Statistics, 36, 938-945.
</p>
<p>Mainali, K., Slud, E., Singer, M. and Fagan, W. (2022), &quot;A better index for analysis of co-occurrence and similarity&quot;, Science Advances, to appear.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># when you have a binary presence absence occurrence data
# -------------------------------------------------------

if(requireNamespace("cooccur", quietly = TRUE)) {
  data(finches, package = "cooccur")
} else {
  message("The cooccur package is not installed.
          You can install it with install.packages('cooccur').")
}

data(finches, package = "cooccur")



# the remainder of the script has been enclosed under \donttest{}
# to bypass the CRAN's 5 second limit on example files
# --------------------------------------------------------------




head(finches)
# this dataset carries the occurrence records of 13 species in row in 17 islands in columns
dim(finches)

# compute alpha and other quantities for island-pair affinity (beta diversity)
myout &lt;- affinity(data = finches, row.or.col = "col")
myout

# you can simply flip the analysis to rows to compute species-pair affinity
myout &lt;- affinity(data = finches, row.or.col = "row")
myout



# the rows of the outputs above include every single pair of the entities,
# producing many columns for various quantities.
# for several of these columns, the function allows outputing the square NxN matrix of the entities
# an example is here
myout &lt;- affinity(data = finches, row.or.col = "col", squarematrix = c("alpha_mle", "jaccard"))
# it is a list of three elements: one main dataframe and two square matrices
length(myout)
myout
head(myout)

# you can also compute all the square matrices with an "all"
myout &lt;- affinity(data = finches, row.or.col = "col", squarematrix = c("all"))
# this one has 12 elements
length(myout)
myout

# when you want to compute for only certain pairs
myout &lt;- affinity(data = finches, row.or.col = "col", which.row.or.col = 4:6,
                  squarematrix = c("alpha_mle"))
myout

myout &lt;- affinity(data = finches, row.or.col = "col",
                  which.row.or.col = c("Isabella", "Espanola"), squarematrix = c("alpha_mle"))
myout

 #end of \donttest{}



# if you select only one column, the computation stops
## Not run: 
  myout &lt;- affinity(data = finches, row.or.col = "col",
                    which.row.or.col = c("Darwin"), squarematrix = c("alpha_mle"))

## End(Not run)





# you can also add additional arguments bringing them from ML.Alpha() or AlphInts()
myout1 &lt;- affinity(data = finches, row.or.col = "col",
                   which.row.or.col = c("Isabella", "Espanola"), lev=0.95, pvalType="Blaker")
myout1
myout2 &lt;- affinity(data = finches, row.or.col = "col",
                   which.row.or.col = c("Isabella", "Espanola"), lev=0.90, pvalType="Blaker")
myout2
identical(myout1, myout2)
# myout1 and myout2 were generated with identical arguments except a difference in "lev",
# which gave different confidence intervals

myout3 &lt;- affinity(data = finches, row.or.col = "col",
                   which.row.or.col = 4:6, lev=0.95, pvalType="Blaker")
myout3
myout4 &lt;- affinity(data = finches, row.or.col = "col",
                   which.row.or.col = 4:6, lev=0.95, pvalType="midP")
myout4
myout3$all$p_value
myout4$all$p_value
# the p values are (or, can be) different

# when you have abundance data requiring conversion to binary
# -----------------------------------------------------------
# abundance data is converted to binary based on a threshold supplied.
# it might be a good idea to explore dataprep() function and its examples
# first before workign on affinity() for abundance data.
matrix.data &lt;- matrix(runif(400, 0, 10), nrow = 100, ncol = 4)
row.names(matrix.data) &lt;- paste0("id_", 1:nrow(matrix.data))
colnames(matrix.data) &lt;- paste0("variable_", 1:ncol(matrix.data))

# add some missing data and zero abundance
matrix.data[1,1] &lt;- matrix.data[2,3] &lt;- matrix.data[1,4] &lt;- matrix.data[1,2] &lt;- NA
matrix.data[10,4] &lt;- 0
head(matrix.data)
# now this is an abundance data with some missing and some zero occurrences

# inspecting how the abundance is converted to binary first
dataprep(data = matrix.data, row.or.col = "col", datatype = "abundance",
         threshold = 5, class0.rule = "less")
myout10 &lt;- affinity(data = matrix.data, row.or.col = "col",
                    datatype = "abundance", threshold = 5, class0.rule = "less")
myout10

# you can also feed the output of dataprep() to affinity()
myinput &lt;- dataprep(data = matrix.data, row.or.col = "col",
                    datatype = "abundance", threshold = 5, class0.rule = "less")
myout11 &lt;- affinity(data = myinput, row.or.col = "col", datatype = "binary")
myout11
# myout 10 and myout11 are identical
identical(myout10, myout11)

 # end of \donttest{}
</code></pre>

<hr>
<h2 id='affinity2by2'>Maximum likelihood estimate and intervals of alpha, null expectation, p-value and traditional indices from a 2x2 table</h2><span id='topic+affinity2by2'></span>

<h3>Description</h3>

<p>This function uses ML.Alpha() and supplements to the outcome with traditional indices of Jaccard, Sorenson, and Simpson.
ML.Alpha() calculates the maximum likelihood estimate and other quantities computed in AlphInts(),
for the log-odds parameter alpha in the Extended Hypergeometric distribution with fixed margins (mA,mB) and
table-total N, which is the &quot;log-affinity&quot; index of co-occurrence championed in a paper by Mainali et al. (2022) as an index of co-occurrence-based similarity.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>affinity2by2(
  x,
  marg,
  bound = TRUE,
  scal = log(2 * marg[3]^2),
  lev = 0.95,
  pvalType = "Blaker"
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="affinity2by2_+3A_x">x</code></td>
<td>
<p>integer co-occurrence count that should properly fall within the closed interval [max(0,mA+mB-N), min(mA,mB)]</p>
</td></tr>
<tr><td><code id="affinity2by2_+3A_marg">marg</code></td>
<td>
<p>a 3-entry integer vector (mA,mB,N) consisting of the first row and column totals and the table total for a 2x2 contingency table</p>
</td></tr>
<tr><td><code id="affinity2by2_+3A_bound">bound</code></td>
<td>
<p>a boolean parameter which when TRUE replaces the MLE of &quot;+/-Infinity&quot;, applicable when x is respectively at the upper extreme min(mA,mB)
or the lower extreme max(mA+mB-N,0) of its possible range, by a finite value with absolute value upper-bounding the value of
MLEs attainable for values of x not equal to its extremes</p>
</td></tr>
<tr><td><code id="affinity2by2_+3A_scal">scal</code></td>
<td>
<p>an integer parameter (default 2*N^2, capped at 10 within the function) that should be 2 or greater</p>
</td></tr>
<tr><td><code id="affinity2by2_+3A_lev">lev</code></td>
<td>
<p>a confidence level, generally somewhere from 0.8 to 0.95  (default 0.95)</p>
</td></tr>
<tr><td><code id="affinity2by2_+3A_pvaltype">pvalType</code></td>
<td>
<p>a character string telling what kind of p-value to calculate. ‘Blaker’ or “midP’.
If ‘pvalType=Blaker” (the default value), the p-value is calculated according to &quot;Acceptability&quot; function of Blaker (2000).
If ‘pvalType=midP’, the p-value is calculated using the same idea as the midP confidence interval.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See the details of ML.Alpha(). In addition to the output of ML.Alpha, this function also computes Jaccard, Sorenson and Simpson indices.
</p>


<h3>Value</h3>

<p>This function returns maximum likelihood estimate of alpha, the interval-endpoints of alpha values for which x is a median,
four confidence intervals for alpha, described in detail under documentation for AlphInts(), and traditional indices of Jaccard, Sorenson and Simpson.
In addition there are two output list-components for the null-distribution expected co-occurrence count and the p-value
for the test of the null hypothesis alpha=0, calculated as in AlphInts.
</p>


<h3>Author(s)</h3>

<p>Kumar Mainali and Eric Slud
</p>


<h3>References</h3>

<p>Fog, A. (2015), BiasedUrn: Biased Urn Model Distributions. R package version 1.07.
</p>
<p>Harkness, W. (1965), “Properties of the extended hypergeometric distribution“, Annals of Mathematical Statistics, 36, 938-945.
</p>
<p>Mainali, K., Slud, E., Singer, M. and Fagan, W. (2022), &quot;A better index for analysis of co-occurrence and similarity&quot;, Science Advances, to appear.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>ML.Alpha(x=35, c(mA=50, mB=70, N=150), lev=0.95)
affinity2by2(x=35, c(mA=50, mB=70, N=150), lev=0.95)
# ML.Alpha() is a subset of affinity2by2()
a &lt;- ML.Alpha(x=35, c(mA=50, mB=70, N=150), lev=0.95)
b &lt;- affinity2by2(x=35, c(mA=50, mB=70, N=150), lev=0.95)
identical(a, b[1:11])
</code></pre>

<hr>
<h2 id='AlphInts'>Median interval, four confidence intervals, null expectation of cooccurrence count, and p-value</h2><span id='topic+AlphInts'></span>

<h3>Description</h3>

<p>This function calculates
(i) MedianIntrvl, the interval of alpha values for which the co-occurrence count is a median,
(ii) four Confidence Intervals, two using EHypQuInt(), one using EHypMidP(), and one using AcceptAffCI(),
(iii) the Expected Co-occurrence count under the Null distribution, and
(iv) the p-value for the observed co-occurrence count.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>AlphInts(x, marg, scal = log(2 * marg[3]^2), lev = 0.95, pvalType = "Blaker")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="AlphInts_+3A_x">x</code></td>
<td>
<p>integer co-occurrence count that should properly fall within the closed interval [max(0,mA+mB-N), min(mA,mB)]</p>
</td></tr>
<tr><td><code id="AlphInts_+3A_marg">marg</code></td>
<td>
<p>a 3-entry integer vector (mA,mB,N) consisting of the first row and column totals and the table total for a 2x2 contingency table</p>
</td></tr>
<tr><td><code id="AlphInts_+3A_scal">scal</code></td>
<td>
<p>an integer parameter (default 2*N^2, capped at 10 within the function) that should be 2 or greater</p>
</td></tr>
<tr><td><code id="AlphInts_+3A_lev">lev</code></td>
<td>
<p>a confidence level, generally somewhere from 0.8 to 0.95  (default 0.95)</p>
</td></tr>
<tr><td><code id="AlphInts_+3A_pvaltype">pvalType</code></td>
<td>
<p>a character string telling what kind of p-value to calculate. ‘Blaker’ or “midP’.
If ‘pvalType=Blaker” (the default value), the p-value is calculated according to &quot;Acceptability&quot; function of Blaker (2000).
If ‘pvalType=midP’, the p-value is calculated using the same idea as the midP confidence interval.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function calculates five intervals, three of them using EHypQuInt, one using EHypMidP, and one using AcceptAffCI.
First (&quot;MedianIntrvl&quot;) is the interval of alpha values compatible with x as median for the Extended Hypergeometric distribution (Harkness 1965)
with fixed margins and alpha; second (&quot;CI.CP&quot;) an &quot;exact&quot; conservative test-based 2-sided confidence interval (analogous to the Clopper-Pearson (1934)
confidence interval for unknown binomial proportion) for alpha based on data (x,mA,mB,N); third the Acceptability Confidence Interval (&quot;CI.Blaker&quot;)
of Blaker (2000, Theorem 1) which is a better confidence interval than the CP-type interval &quot;CI.CP&quot; in the sense of being contained within &quot;CI.CP&quot;
but still provably conservative, i.e., with coverage probability always at least as large as the nominal level.
The fourth confidence interval (&quot;CI.midQ&quot;) is the one given in formula (2) above of the Introduction to this documentation,
with endpoints obtained as the midpoints of quantile intervals respectively to the (1+lev)/2 and (1-lev)/2 quantiles of the Extended Hypergeometric distribution;
and the fifth (&quot;CI.midP&quot;) which behaves very similarly to &quot;CI.midQ&quot; is defined by the midP approach analogous
to the midP confidence interval for binomial proportions (Agresti 2013, p.605), and is calculated from EHypMidP.
</p>
<p>The first of these intervals quantifies the underlying discreteness of the Extended Hypergeometric and its impact on the estimation of alpha.
MedianIntrvl is an interval that will contain the MLE alpha-hat, and the mid-point of that interval is another reasonable estimator of alpha from the data.
The recommended (slightly conservative) confidence interval is CI.Blaker, while the very similar intervals CI.midQ and CI.midP have
coverage generally closer than CI.CP or CI.Blaker to the nominal level of coverage, at the cost of occasionally under-covering
by as much as 0.04 or 0.05 for confidence levels 0.90 or 0.95. The comparison among intervals, and different possible goals that CIs of
conservative or close-to-nominal coverage can serve, are similar to those compared by  Brown et al. (2001) for interval estimation of an unknown binomial proportion.
</p>
<p>Two other output list components are computed. First is Null.Exp, the expected co-occurrence count under the null (hypergeometric, corresponding to alpha=0)
distribution, and second is the two-sided p-value for the equal-tailed test of the null hypothesis alpha=0. This p-value is calculated when pval=&quot;Blaker&quot;
according to Blaker's (2000) &quot;Acceptability&quot; function; if the input parameter pval is anything else, the p-value is calculated using the same idea as the midP confidence interval.
</p>


<h3>Value</h3>

<p>A list of seven components: the median interval MedianIntrvl; the four two-sided Confidence Intervals described above,
two (CI.CP and CI.Blaker) conservative and two (CI.midQ and CI.midP) with coverage probabilities generally closer to the nominal level;
the null expectation Null.Exp of the co-occurrence count associated with alpha=0; and pval, the two-sided p-value for the hypothesis test of alpha=0,
calculated by the method selectied, which is the Blaker acceptability-function method if pvalType=&quot;Blaker&quot; and otherwise
the &quot;midP&quot; p-value associated with the midP confidence-interval type.
</p>
<p>Of the four Confidence intervals produced, CI.Blaker is the recommended conservative interval and CI.midP the interval to use if coverage close to the nominal is desired.
</p>


<h3>Author(s)</h3>

<p>Eric Slud
</p>


<h3>References</h3>

<p>Agresti, A. (2013) Categorical Data Analysis, 3rd edition, Wiley.
</p>
<p>Blaker, H. (2000), “Confidence curves and improved exact confidence intervals for discrete distributions&quot;, Canadian Journal of Statistics 28, 783-798.
</p>
<p>Brown, L., T. Cai, and A. DasGupta (2001), “Interval Estimation for a Binomial Proportion,” Statistical Science, 16, 101–117.
</p>
<p>Clopper, C., and E. Pearson (1934), “The Use of Confidence or Fiducial Limits Illustrated in the Case of the Binomial,” Biometrika, 26, 404–413.
</p>
<p>Fog, A. (2015), BiasedUrn: Biased Urn Model Distributions. R package version 1.07.
</p>
<p>Harkness, W. (1965), “Properties of the extended hypergeometric distribution“, Annals of Mathematical Statistics, 36, 938-945.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>unlist(AlphInts(30,c(50,80,120), lev=0.9))

AlphInts(30,c(50,80,120), lev=0.9)$CI.CP
AlphInts(30,c(50,80,120), lev=0.9)$MedianIntrvl

EHypMidP(30,c(50,80,120), 0.9)
AlphInts(30,c(50,80,120), lev=0.9)$CI.midP
# NB the third argument of AlphInts is "scal" if not named,
# so must use "lev=0.9" to define the confidence level.

EHypQuInt(30,c(50,80,120), 0.5)
AlphInts(30,c(50,80,120), lev=0.9)$MedianIntrvl

# Alpha capped warning examples
AlphInts(60,c(80,80,100), lev=0.9)
ML.Alpha(60,c(80,80,100), lev=0.9)

AlphInts(80,c(80,80,100), lev=0.9)
ML.Alpha(80,c(80,80,100), lev=0.9)

# impossible x warning examples
AlphInts(81,c(80,80,100), lev=0.9)
ML.Alpha(81,c(80,80,100), lev=0.9)

# Degenerate distribution warning example
AlphInts(80,c(80,100,100), lev=0.9)
ML.Alpha(80,c(80,100,100), lev=0.9)

</code></pre>

<hr>
<h2 id='Bisect'>Bisections for finding a root of a function</h2><span id='topic+Bisect'></span>

<h3>Description</h3>

<p>Find a root of a function by the method of Bisections
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Bisect(ffnc, intrv, tol = 1e-08)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Bisect_+3A_ffnc">ffnc</code></td>
<td>
<p>an increasing function of a single scalar argument</p>
</td></tr>
<tr><td><code id="Bisect_+3A_intrv">intrv</code></td>
<td>
<p>an interval over which the root of ffnc is sought</p>
</td></tr>
<tr><td><code id="Bisect_+3A_tol">tol</code></td>
<td>
<p>a tolerance determining when the successive bisections of the interval within which the root will lie have become small enough to stop</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function finds the root of the increasing function ffnc over the scalar interval intrv by the Method of Bisections. The function must be increasing but need not be smooth, and it must have a negative sign (value less than -tol) at the left endpoint of  intrv  and positive sign (value greater than tol) at the right endpoint. The method of Bisection is used in successive iterations to successively halve the width of the interval in which the root lies.
</p>


<h3>Value</h3>

<p>This function returns a vector consisting of two numbers. The first named root is an estimate of the root x  solving ffnc(x) = 0, valid within an error of tol.
The second output vector element named fval is the value of the function ffnc at root.
It should be very close to 0 unless the function happens to jump from a value less than 0 to a value greater than 0 at  root.
</p>


<h3>Author(s)</h3>

<p>Eric Slud
</p>


<h3>References</h3>

<p>to be added
</p>


<h3>Examples</h3>

<pre><code class='language-R'>Bisect(function(x) x^2-1, c(0,2),1e-8)
</code></pre>

<hr>
<h2 id='Covrg'>Coverage Probabilities for Confidence Intervals about alpha, for fixed true alpha</h2><span id='topic+Covrg'></span>

<h3>Description</h3>

<p>This function calculates the coverage probability at the true value alpha of the four types of Cpnfidence Intervals (CI.CP, CI.Blaker, CI.midQ, CI.midP) computed in AlphInts().
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Covrg(marg, alph, scal = log(2 * marg[3]^2), lev = 0.95)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Covrg_+3A_marg">marg</code></td>
<td>
<p>a 3-entry integer vector (mA,mB,N) consisting of the first row and column totals and the table total for a 2x2 contingency table</p>
</td></tr>
<tr><td><code id="Covrg_+3A_alph">alph</code></td>
<td>
<p>True log-odds-ratio value alpha at which coverage probabilities (under Extended Hypergeometric with parameters mA,mB,N, exp(alp)) are to be calculated</p>
</td></tr>
<tr><td><code id="Covrg_+3A_scal">scal</code></td>
<td>
<p>an integer parameter (default 2*N^2, capped at 10 within the function) that should be 2 or greater</p>
</td></tr>
<tr><td><code id="Covrg_+3A_lev">lev</code></td>
<td>
<p>a confidence level, generally somewhere from 0.8 to 0.95 (default 0.95)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See AlphInts() documentation for details of computation of the four confidence intervals CI.CP, CI.Blaker, CI.midQ, CI.midP. The confidence intervals are calculated for each x in the allowed range from max(mA+mB-N,0) to min(mA,mB), and the probability that X=x times the indicator of alph falling in each of them is summed.
</p>


<h3>Value</h3>

<p>A vector covPrb containing the coverage propbabilities for the four Confidence Intervals
</p>


<h3>Author(s)</h3>

<p>Eric Slud
</p>


<h3>References</h3>

<p>to be added
</p>


<h3>Examples</h3>

<pre><code class='language-R'>Covrg(c(50,70,150), 1.2, lev=0.95)
Covrg(c(50,70,150), 0, lev=0.95)
Covrg(c(50,80,120), 1.5, lev=0.9)
</code></pre>

<hr>
<h2 id='CovrgPlot'>Coverage probabilities of the confidence intervals, calculated and plotted</h2><span id='topic+CovrgPlot'></span>

<h3>Description</h3>

<p>This function calculates and plots the coverage probabilities of the four confidence intervals CI.CP, CI.Blaker, CI.midQ and CI.midP
produced by functions AlphInts() and ML.Alpha(). The coverage plots are useful in showing how the conservative confidence intervals (CI.CP and CI.Blaker)
tend to have above-nominal coverage probabilities versus the intervals CI.midQ and CI.midP that have coverage much closer to the nominal confidence level lev.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CovrgPlot(
  marg,
  scal = log(2 * marg[3]^2),
  lev = 0.95,
  alim = 4,
  intpts = 1,
  plotCI = 1:4
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="CovrgPlot_+3A_marg">marg</code></td>
<td>
<p>a 3-entry integer vector containing (mA,mB,N)</p>
</td></tr>
<tr><td><code id="CovrgPlot_+3A_scal">scal</code></td>
<td>
<p>an integer parameter (default 2*N^2, capped at 10 within the function) that should be 2 or greater</p>
</td></tr>
<tr><td><code id="CovrgPlot_+3A_lev">lev</code></td>
<td>
<p>a confidence level, generally somewhere from 0.8 to 0.95 (default 0.95)</p>
</td></tr>
<tr><td><code id="CovrgPlot_+3A_alim">alim</code></td>
<td>
<p>the absolute value of alpha at which the plotted figure is cutoff; so the x-axis limits are (-alim, alim)</p>
</td></tr>
<tr><td><code id="CovrgPlot_+3A_intpts">intpts</code></td>
<td>
<p>an integer controlling how many points are used to interpolate between values alpha for which
the Extended Hypergeometric distribution function is equal exactly to (1+lev)/2 or (1-lev)/2 at some integer co-occurrence value x</p>
</td></tr>
<tr><td><code id="CovrgPlot_+3A_plotci">plotCI</code></td>
<td>
<p>a vector of up to 4 numbers out of the set 1,2,3,4, corresponding to which
Confidence Intervals (1=CP, 2=Blaker, 3=midQ, 4=midP) should have their coverage probability values plotted simultaneously (with different colors) in the figure</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function calculates and plots the coverage probabilities of the confidence intervals CI.CP, CI.Blaker, CI.midQ and CI.midQ produced by function AlphInts(),
for fixed marginals &quot;marg&quot; = (mA,mB,N) and confidence level &quot;lev&quot; as a function of alpha. The plots serve as a useful exhibit to show the range of always conservative
(and sometimes quite conservative) coverage probabilities for CI1, and the much closer-to-nominal coverage probabilities for the recommended Confidence Interval CI2.
The outputted vector &quot;avec&quot; of alpha values is the set of all discontinuities in the slope of the coverage-probability function together with
&quot;intpts: equally spaced values between them. The plotted coverage probabilities are the corresponding exact (not simulated) coverage probabilities
of each of the selected (up to 4) confidence intervals at the alphvec points in the four-column array &quot;covPrb&quot;.
</p>


<h3>Value</h3>

<p>This function plots a figure of overlaid coverage probabilities with differently colored lines, explained in the figure legend.
In addition, it returns &quot;avec&quot;, a vector of alpha values at which coverage probabilities are calculated,
an xn x 4 x 2 array &quot;arrCI&quot; where xn is the length of &quot;avec&quot; and for each index i in 1:xn the array arrCI[i,,] is the 4x2 matrix of 4 Confidence Interval
lower and upper alpha-value endpoints; and &quot;covPrb&quot;, the xn x 4 matrix of coverage probabilities for the four CI's at each of the alpha values avec[i] for i =1,...,xn.
</p>

<dl>
<dt>variable</dt><dd><p>Column name of the dataframe produced by reshape::melt</p>
</dd>
<dt>value</dt><dd><p>Column name of the dataframe produced by reshape::melt</p>
</dd>
<dt>abovethr</dt><dd><p>Column name of the dataframe produced by reshape::melt</p>
</dd>
<dt>belowthr</dt><dd><p>Column name of the dataframe produced by reshape::melt</p>
</dd>
<dt>aboveperc</dt><dd><p>Column name of the dataframe produced by plyr::ddply</p>
</dd>
<dt>belowperc</dt><dd><p>Column name of the dataframe produced by plyr::ddply</p>
</dd>
<dt>legendtext</dt><dd><p>Column name of the dataframe</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Eric Slud and Kumar Mainali
</p>


<h3>References</h3>

<p>to be added
</p>


<h3>Examples</h3>

<pre><code class='language-R'># True coverage probability by the 95% Confidence Interval
CovrgPlot(marg = c(50,70,150), lev = 0.95)

# the remainder of the script has been enclosed under \donttest{}
# to bypass the CRAN's 5 second limit on example files
# --------------------------------------------------------------



# If confidence level is not specified, it shows results for 95% CI
CovrgPlot(marg = c(50,70,150))

# True coverage probability by the 90% Confidence Interval
CovrgPlot(marg = c(50,70,150), lev = 0.90)

# Select some of the confidence intervals to plot
CovrgPlot(marg = c(50,70,150), lev = 0.95, plotCI=1:3)
CovrgPlot(marg = c(50,70,150), lev = 0.95, plotCI=c(1,3,4))
CovrgPlot(marg = c(50,70,150), lev = 0.95, plotCI=1)

 #end of \donttest{}
</code></pre>

<hr>
<h2 id='dataprep'>Occurrence matrix (e.g., species by site) data preparation for affinity() function</h2><span id='topic+dataprep'></span>

<h3>Description</h3>

<p>This function checks the format of the data for its appropriateness, converts abundance to binary and subsets the data for the selected columns or rows.
Note that the affinity can be computed between columns or between rows. In the latter case, the dataset is transposed to bring rows into the columns.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dataprep(
  data,
  row.or.col,
  which.row.or.col = NULL,
  datatype = NULL,
  threshold = NULL,
  class0.rule = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="dataprep_+3A_data">data</code></td>
<td>
<p>occurrence matrix (binary or abundance) in matrix or dataframe format</p>
</td></tr>
<tr><td><code id="dataprep_+3A_row.or.col">row.or.col</code></td>
<td>
<p>specify if the pairs of rows or columns are analyzed for affinity. 'row' or 'column'.</p>
</td></tr>
<tr><td><code id="dataprep_+3A_which.row.or.col">which.row.or.col</code></td>
<td>
<p>a vector of name or the number of row/column if a subset of the data is intended to be analyzed; optional argument with default of all rows/columns.</p>
</td></tr>
<tr><td><code id="dataprep_+3A_datatype">datatype</code></td>
<td>
<p>specify if the datatype is 'abundance' or 'binary'; optional argument with default 'binary'.</p>
</td></tr>
<tr><td><code id="dataprep_+3A_threshold">threshold</code></td>
<td>
<p>cutoff for converting an abundance data to binary; needed if datatype is 'abundance'</p>
</td></tr>
<tr><td><code id="dataprep_+3A_class0.rule">class0.rule</code></td>
<td>
<p>'less.or.equal' or 'less'. 'less.or.equal' converts a threshold or lower values to zero and all the others to 1. 'less' converts a threshold and higher values to 1.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function does the following:
</p>

<ol>
<li><p> checks if the supplied data is in matrix or dataframe formats which are the acceptable formats
</p>
</li>
<li><p> if rows are selected for affinity analysis, it transposes the dataframe
</p>
</li>
<li><p> subsets the data if specific columns or rows are selected for analysis; the selection can be made with number or name of the rows/columns
</p>
</li>
<li><p> checks if the selected cols/rows are in numeric or integer format or not
</p>
</li>
<li><p> checks if the selected cols/rows have data in binary 1/0 format or not; if datatype is specified as abundance, it converts it to binary format following the supplied rule
</p>
</li></ol>



<h3>Value</h3>

<p>A dataframe in binary 1/0 format ready to be analyzed by affinity(). Abundance data is converted to binary.
A subset of the input data is returned if certain rows or columns selected.
If rows are being analyzed for affinity between pairs, they are brought to columns by transposing the data.
</p>


<h3>Author(s)</h3>

<p>Kumar Mainali
</p>


<h3>Examples</h3>

<pre><code class='language-R'>matrix.data &lt;- matrix(1:40, nrow = 10, ncol = 4)

row.names(matrix.data) &lt;- paste0("id_", 1:nrow(matrix.data))
colnames(matrix.data) &lt;- paste0("variable_", 1:ncol(matrix.data))

# add some missing data and zero abundance
matrix.data[1,1] &lt;- matrix.data[2,3] &lt;- matrix.data[1,4] &lt;- matrix.data[1,2] &lt;- NA
matrix.data[10,4] &lt;- 0
matrix.data
# abundance data with some missing and some zero occurrences

# some good examples
dataprep(data = matrix.data, row.or.col = "col", datatype = "abundance",
         threshold = 9, class0.rule = "less")
dataprep(data = matrix.data, row.or.col = "row", which.row.or.col = c("id_2", "id_4"),
         datatype = "abundance", threshold = 10, class0.rule = "less")
dataprep(data = matrix.data, row.or.col = "col", which.row.or.col = c("variable_1", "variable_4"),
         datatype = "abundance", threshold = 8, class0.rule = "less")
dataprep(data = matrix.data, row.or.col = "col",
         which.row.or.col = c("variable_1", "variable_3", "variable_4"),
         datatype = "abundance", threshold = 8, class0.rule = "less.or.equal")
dataprep(data = matrix.data, row.or.col = "row", datatype = "abundance",
         threshold = 10, class0.rule = "less")
dataprep(data = matrix.data, row.or.col = "col", datatype = "abundance",
         threshold = 10, class0.rule = "less")

# bad examples of specifying the rows or cols that are not in the data
## Not run: 
  dataprep(data = matrix.data, row.or.col = "row",
           which.row.or.col = c("id_1", "id_4", "id_11", "id_39"), datatype = "abundance",
           threshold = 10, class0.rule = "less")
  dataprep(data = matrix.data, row.or.col = "row", which.row.or.col = c(4,7,17),
           datatype = "abundance", threshold = 10, class0.rule = "less")
  dataprep(data = matrix.data, row.or.col = "col", which.row.or.col = 2:12, datatype = "abundance",
           threshold = 10, class0.rule = "less")
  dataprep(data = matrix.data, row.or.col = "col",
           which.row.or.col = c("variable_1", "variable_9", "variable_6"), datatype = "abundance",
           threshold = 10, class0.rule = "less")

## End(Not run)


# what if you pick just one column or row
## Not run: 
  dataprep(data = matrix.data, row.or.col = "row", which.row.or.col = c("id_4"),
           datatype = "abundance", threshold = 10, class0.rule = "less")

## End(Not run)

# the function fails when a required argument is missing
## Not run: 
  dataprep(data = matrix.data, row.or.col = "col", which.row.or.col = c("variable_1", "variable_4"),
           datatype = "abundance", threshold = 10)
  dataprep(data = matrix.data, row.or.col = "col", which.row.or.col = c("variable_1", "variable_4"),
           datatype = "abundance", class0.rule = "less.or.equal")
  dataprep(data = matrix.data, row.or.col = "col", which.row.or.col = c("variable_1", "variable_4"),
           datatype = "abundance")

## End(Not run)

# what if you have abundance data but do not specify the datatype
## Not run: 
  dataprep(data = matrix.data, row.or.col = "col", which.row.or.col = c("variable_1", "variable_4"))

## End(Not run)

# however, if it is a binary data, it's okay to not specify the datatype
# although specifying is a good practice
matrix.bindata &lt;- dataprep(data = matrix.data, row.or.col = "col", datatype = "abundance",
                           threshold = 9, class0.rule = "less")
matrix.bindata
dataprep(data = matrix.bindata, row.or.col = "col")
dataprep(data = matrix.bindata, row.or.col = "row")
</code></pre>

<hr>
<h2 id='EHypMidP'>Quantile of the Extended Hypergeometric distribution approximated by the midP distribution function</h2><span id='topic+EHypMidP'></span>

<h3>Description</h3>

<p>This function does the analogous calculation to that of EHypQuInt, but with the Extended Hypergeometric distribution
function F(x) = F(x,mA,mB,N, exp(alpha)) replaced by (F(x) + F(x-1))/2.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>EHypMidP(x, marg, lev)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="EHypMidP_+3A_x">x</code></td>
<td>
<p>integer co-occurrence count that should properly fall within the closed interval [max(0,mA+mB-N), min(mA,mB)]</p>
</td></tr>
<tr><td><code id="EHypMidP_+3A_marg">marg</code></td>
<td>
<p>a 3-entry integer vector (mA,mB,N) consisting of the first row and column totals and the table total for a 2x2 contingency table</p>
</td></tr>
<tr><td><code id="EHypMidP_+3A_lev">lev</code></td>
<td>
<p>a confidence level, generally somewhere from 0.8 to 0.95  (default 0.95)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function does the analogous calculation to that of CI.CP, but with the Extended Hypergeometric distribution
function F(z, alpha) = F(z,mA,mB,N, exp(alpha)) replaced by (F(z,alpha) + F(z-1,alpha))/2.
</p>


<h3>Value</h3>

<p>This function returns the interval of alpha values with endpoints
(F(x,alpha)+F(x-1,alpha))/2 = (1+lev)/2   and  (F(x,alpha)+F(x+1,alpha))/2 = (1-lev)/2.
</p>
<p>The idea of calculating a Confidence Interval this way is analogous to the midP CI used for unknown binomial proportions (Agresti 2013, p.605).
</p>


<h3>Author(s)</h3>

<p>Eric Slud
</p>


<h3>References</h3>

<p>Agresti, A. (2013) Categorical Data Analysis, 3rd edition, Wiley.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>EHypMidP(30,c(50,80,120), 0.9)
AlphInts(30,c(50,80,120), lev=0.9)$CI.midP

EHypMidP(20, c(204,269,2016), 0.9)
</code></pre>

<hr>
<h2 id='EHypQuInt'>Interval of alpha values for which X is a specified q'th quantile</h2><span id='topic+EHypQuInt'></span>

<h3>Description</h3>

<p>This function outputs the largest interval of log-odds parameter values alpha for which
the Extended Hypergeometric distribution function at x is &gt;= q and the complementary distribution function 1 - F(x-) is &gt;= 1-q.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>EHypQuInt(x, marg, q, scal = log(2 * marg[3]^2))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="EHypQuInt_+3A_x">x</code></td>
<td>
<p>integer co-occurrence count that should properly fall within the closed interval [max(0,mA+mB-N), min(mA,mB)]</p>
</td></tr>
<tr><td><code id="EHypQuInt_+3A_marg">marg</code></td>
<td>
<p>a 3-entry integer vector (mA,mB,N) consisting of the first row and column totals and the table total for a 2x2 contingency table</p>
</td></tr>
<tr><td><code id="EHypQuInt_+3A_q">q</code></td>
<td>
<p>a quantile falling strictly between 0 and 1</p>
</td></tr>
<tr><td><code id="EHypQuInt_+3A_scal">scal</code></td>
<td>
<p>an integer parameter (default 2*N^2, capped at 10 within the function) that should be 2 or greater</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function outputs the endpoints  a1, a2 defined by
</p>
<p>F(x, a1) = q      and    F(x-1, a2) = q
</p>
<p>where  F(z, a) = F(z, mA,mB,N, exp(a)) is the extended Hypergeometric distribution function.
</p>
<p>The interval of alpha values with these endpoints a1, a2 is viewed as the set of alpha values &quot;compatible&quot; with x being a q'th quantile for the Extended Hypergeometric.
</p>


<h3>Value</h3>

<p>This function returns the vector (a1, a2) defined above, the endpoints of the set of alpha values for which x is a q'th quantile of the Extended Hypergeometric distribution.
</p>


<h3>Author(s)</h3>

<p>Eric Slud
</p>


<h3>Examples</h3>

<pre><code class='language-R'>EHypQuInt(30,c(50,80,120), 0.95)
EHypQuInt(30,c(50,80,120), 0.05)

EHypQuInt(30,c(50,80,120), 0.5)
AlphInts(30,c(50,80,120), lev=0.9)$MedianIntrvl
</code></pre>

<hr>
<h2 id='logLikExtHyp'>log of Extended Hypergeometric Likelihiood at (X, mA,mB,N, alpha)</h2><span id='topic+logLikExtHyp'></span>

<h3>Description</h3>

<p>This function calculates the logarithm of the Extended Hypergeometric likelihood at specified x and alpha, with marginal totals mA, mB, N fixed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>logLikExtHyp(x, marg, alpha)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="logLikExtHyp_+3A_x">x</code></td>
<td>
<p>integer co-occurrence count that should properly fall within the closed interval [max(0,mA+mB-N), min(mA,mB)]</p>
</td></tr>
<tr><td><code id="logLikExtHyp_+3A_marg">marg</code></td>
<td>
<p>a 3-entry integer vector (mA,mB,N) consisting of the first row and column totals and the table total for a 2x2 contingency table</p>
</td></tr>
<tr><td><code id="logLikExtHyp_+3A_alpha">alpha</code></td>
<td>
<p>a real number, the log odds ratio or affinity parameter for the 2x2 contingency table</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is simply the logarithm of the Extended Hypergeometric (Harkness 1965) or Fisher noncentral Hypergeometric, as calculated by the R package BiasedUrn. The formula is  log(pFNCHypergeo(x,mA,N-mA,mB,exp(alpha))
</p>


<h3>Value</h3>

<p>scalar loglikelihood value
</p>


<h3>Author(s)</h3>

<p>Eric Slud
</p>


<h3>References</h3>

<p>Fog, A. (2015), BiasedUrn: Biased Urn Model Distributions. R package version 1.07.
</p>
<p>Harkness, W. (1965), “Properties of the extended hypergeometric distribution“, Annals of Mathematical Statistics, 36, 938-945.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require(BiasedUrn)
c(logLikExtHyp(30,c(50,80,120),1),  log(dFNCHypergeo(30,50,70,80,exp(1))))
</code></pre>

<hr>
<h2 id='MaxX.Int'>MaxX.Int computation</h2><span id='topic+MaxX.Int'></span>

<h3>Description</h3>

<p>Helper function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MaxX.Int(marg, scal = log(2 * marg[3]^2), lev = 0.95)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="MaxX.Int_+3A_marg">marg</code></td>
<td>
<p>a 3-entry integer vector (mA,mB,N) consisting of the first row and column totals and the table total for a 2x2 contingency table</p>
</td></tr>
<tr><td><code id="MaxX.Int_+3A_scal">scal</code></td>
<td>
<p>an integer parameter (default 2*N^2, capped at 10 within the function) that should be 2 or greater</p>
</td></tr>
<tr><td><code id="MaxX.Int_+3A_lev">lev</code></td>
<td>
<p>a confidence level, generally somewhere from 0.8 to 0.95  (default 0.95)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is a helper function.
</p>


<h3>Value</h3>

<p>helper function
</p>


<h3>Author(s)</h3>

<p>Eric Slud
</p>

<hr>
<h2 id='midP.EHyp'>midP.EHyp computation</h2><span id='topic+midP.EHyp'></span>

<h3>Description</h3>

<p>Helper function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>midP.EHyp(alp)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="midP.EHyp_+3A_alp">alp</code></td>
<td>
<p>&quot;alpha&quot; parameter, the log-odds parameter in the Extended Hypergeometric distribution</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is a helper function.
</p>
<p>param x integer co-occurrence count that should properly fall within the closed interval [max(0,mA+mB-N), min(mA,mB)]
</p>


<h3>Value</h3>

<p>helper function for midP CI computation with EHypMidP
</p>


<h3>Author(s)</h3>

<p>Eric Slud
</p>

<hr>
<h2 id='minmaxAlpha.pFNCH'>integer-endpoint of range for which BiasedUrn::pFNCHHypergeo() works without error</h2><span id='topic+minmaxAlpha.pFNCH'></span>

<h3>Description</h3>

<p>This function calculates an integer-endpoint of range for which BiasedUrn::pFNCHHypergeo() works without error.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>minmaxAlpha.pFNCH(x, marg)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="minmaxAlpha.pFNCH_+3A_x">x</code></td>
<td>
<p>integer co-occurrence count that should properly fall within the closed interval [max(0,mA+mB-N), min(mA,mB)]</p>
</td></tr>
<tr><td><code id="minmaxAlpha.pFNCH_+3A_marg">marg</code></td>
<td>
<p>a 3-entry integer vector (mA,mB,N) consisting of the first row and column totals and the table total for a 2x2 contingency table</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Without this function, BiasedUrn::pFNCHHypergeo() returns inconsistency message for extreme examples like: AlphInts(20,c(204,269,2016), lev=0.9, scal=10).
This problem is solved within our package by restricting the range of allowed alpha to the computed (alphmin, alphmax) range.
</p>


<h3>Value</h3>

<p>minimum and maximum of Alpha
</p>


<h3>Author(s)</h3>

<p>Eric Slud
</p>


<h3>References</h3>

<p>Fog, A. (2015), BiasedUrn: Biased Urn Model Distributions. R package version 1.07.
</p>
<p>Harkness, W. (1965), “Properties of the extended hypergeometric distribution“, Annals of Mathematical Statistics, 36, 938-945.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>minmaxAlpha.pFNCH(10,c(100,200,300))
minmaxAlpha.pFNCH(20,c(204,269,2016))
minmaxAlpha.pFNCH(20,c(204,269,20160))
</code></pre>

<hr>
<h2 id='MinX.Int'>MinX.Int computation</h2><span id='topic+MinX.Int'></span>

<h3>Description</h3>

<p>Helper function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MinX.Int(marg, scal = log(2 * marg[3]^2), lev = 0.95)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="MinX.Int_+3A_marg">marg</code></td>
<td>
<p>a 3-entry integer vector (mA,mB,N) consisting of the first row and column totals and the table total for a 2x2 contingency table</p>
</td></tr>
<tr><td><code id="MinX.Int_+3A_scal">scal</code></td>
<td>
<p>an integer parameter (default 2*N^2, capped at 10 within the function) that should be 2 or greater</p>
</td></tr>
<tr><td><code id="MinX.Int_+3A_lev">lev</code></td>
<td>
<p>a confidence level, generally somewhere from 0.8 to 0.95  (default 0.95)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is a helper function.
</p>


<h3>Value</h3>

<p>helper function
</p>


<h3>Author(s)</h3>

<p>Eric Slud
</p>

<hr>
<h2 id='ML.Alpha'>Maximum likelihood estimate and intervals of alpha, null expectation and p-value of a 2x2 table</h2><span id='topic+ML.Alpha'></span>

<h3>Description</h3>

<p>This function calculates the maximum likelihood estimate and other quantities computed in AlphInts(),
for the log-odds parameter alpha in the Extended Hypergeometric distribution with fixed margins (mA,mB) and
table-total N, which is the &quot;log-affinity&quot; index of co-occurrence championed in a paper by Mainali et al. (2022) as an index of co-occurrence-based similarity.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ML.Alpha(
  x,
  marg,
  bound = TRUE,
  scal = log(2 * marg[3]^2),
  lev = 0.95,
  pvalType = "Blaker"
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ML.Alpha_+3A_x">x</code></td>
<td>
<p>integer co-occurrence count that should properly fall within the closed interval [max(0,mA+mB-N), min(mA,mB)]</p>
</td></tr>
<tr><td><code id="ML.Alpha_+3A_marg">marg</code></td>
<td>
<p>a 3-entry integer vector (mA,mB,N) consisting of the first row and column totals and the table total for a 2x2 contingency table</p>
</td></tr>
<tr><td><code id="ML.Alpha_+3A_bound">bound</code></td>
<td>
<p>a boolean parameter which when TRUE replaces the MLE of &quot;+/-Infinity&quot;, applicable when x is respectively at the upper extreme min(mA,mB)
or the lower extreme max(mA+mB-N,0) of its possible range, by a finite value with absolute value upper-bounding the value of
MLEs attainable for values of x not equal to its extremes</p>
</td></tr>
<tr><td><code id="ML.Alpha_+3A_scal">scal</code></td>
<td>
<p>an integer parameter (default 2*N^2, capped at 10 within the function) that should be 2 or greater</p>
</td></tr>
<tr><td><code id="ML.Alpha_+3A_lev">lev</code></td>
<td>
<p>a confidence level, generally somewhere from 0.8 to 0.95  (default 0.95)</p>
</td></tr>
<tr><td><code id="ML.Alpha_+3A_pvaltype">pvalType</code></td>
<td>
<p>a character string telling what kind of p-value to calculate. ‘Blaker’ or “midP’.
If ‘pvalType=Blaker” (the default value), the p-value is calculated according to &quot;Acceptability&quot; function of Blaker (2000).
If ‘pvalType=midP’, the p-value is calculated using the same idea as the midP confidence interval.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function calculates the maximum likelihood estimate of the log-odds paramater alpha within the Extended Hypergeometric distribition (Harkness 1965)
based on the count x and fixed table margins (mA,mB) and total N, which is the &quot;affinity&quot; index of co-occurrence championed in the paper of Mainali et al. (2022)
as an index of cooccurrence-based similarity, along with the intervals computed in AlphInts, called CI.CP, CI.Balker, CI.midQ and CI.midP.
The boolean &quot;bound&quot; parameter is an option to prevent the intervals containing alpha-estimates to extend to plus or minus infinity, based on a Bayesian argument. T
he bound substituted for the Infinite endpoints is provably larger than the largest value the MLE can take whenever x avoids the enpoints max(mA+mB-N,0) and min(mA,mB)
of its logical range. The recommended confidence interval for alpha is CI.Blaker if a reliably conservative (over-large) coverage probability is desired, and CI.midP otherwise.
</p>


<h3>Value</h3>

<p>This function returns maximum likelihood estimate of alpha, the interval-endpoints of alpha values for which x is a median,
and four confidence intervals for alpha, described in detail under documentation for AlphInts().
In addition there are two output list-components for the null-distribution expected co-occurrence count and the p-value
for the test of the null hypothesis alpha=0, calculated as in AlphInts.
</p>


<h3>Author(s)</h3>

<p>Eric Slud
</p>


<h3>References</h3>

<p>Fog, A. (2015), BiasedUrn: Biased Urn Model Distributions. R package version 1.07.
</p>
<p>Harkness, W. (1965), “Properties of the extended hypergeometric distribution“, Annals of Mathematical Statistics, 36, 938-945.
</p>
<p>Mainali, K., Slud, E., Singer, M. and Fagan, W. (2022), &quot;A better index for analysis of co-occurrence and similarity&quot;, Science Advances, to appear.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>unlist(ML.Alpha(30,c(50,80,120), lev=0.9))
AlphInts(30,c(50,80,120), lev=0.9)

AlphInts(61,c(80,80,100), lev=0.9)
ML.Alpha(61,c(80,80,100), lev=0.9)

# Alpha capped warning examples
AlphInts(60,c(80,80,100), lev=0.9)
ML.Alpha(60,c(80,80,100), lev=0.9)

AlphInts(80,c(80,80,100), lev=0.9)
ML.Alpha(80,c(80,80,100), lev=0.9)

# impossible x warning examples
AlphInts(81,c(80,80,100), lev=0.9)
ML.Alpha(81,c(80,80,100), lev=0.9)

# Degenerate distribution warning example
AlphInts(80,c(80,100,100), lev=0.9)
ML.Alpha(80,c(80,100,100), lev=0.9)
</code></pre>

<hr>
<h2 id='plotgg'>Heatmap plot of affinity() output</h2><span id='topic+plotgg'></span>

<h3>Description</h3>

<p>This function works on the output of affinity() and uses ggplot2::ggplot() to plot a heatmap plot for the numeric columns of $all dataframe except
the interval columns (median interval and confidence intervals) and confidence level (which is a constant for all pairs in one run of the code)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotgg(
  data,
  variable,
  legendlimit,
  col = NULL,
  show.value = NULL,
  value.digit = NULL,
  text.size = NULL,
  plot.margin = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plotgg_+3A_data">data</code></td>
<td>
<p>the output of affinity()</p>
</td></tr>
<tr><td><code id="plotgg_+3A_variable">variable</code></td>
<td>
<p>a column name in $all dataframe in affinity() output; should be a quantitative column;
can be one of the following: &quot;entity_1_count_mA&quot;, &quot;entity_2_count_mB&quot;, &quot;obs_cooccur_X&quot;, &quot;sites_total_N&quot;,
&quot;p_value&quot;, &quot;exp_cooccur&quot;, &quot;alpha_mle&quot;, &quot;jaccard&quot;, &quot;sorensen&quot;, &quot;simpson&quot;</p>
</td></tr>
<tr><td><code id="plotgg_+3A_legendlimit">legendlimit</code></td>
<td>
<p>&quot;datarange&quot; or &quot;balanced&quot;; if &quot;datarange&quot;, the legend spans to the range of data,
if &quot;balanced, the legend spans in equal magnitude from the center (= white by default) in both directions;
note that, irrespective of the value-span in legend, the color spectrum of the plot and legend always goes from the center (=white by default)
to two directions in equal magnitude. See details for more information.</p>
</td></tr>
<tr><td><code id="plotgg_+3A_col">col</code></td>
<td>
<p>a set of three colors c(&quot;#87beff&quot;, &quot;white&quot;, &quot;#fd6a6c&quot;) by default to represent low, mid and high values in the plot;
these colors are applied with ggplot::scale_fill_gradient2()</p>
</td></tr>
<tr><td><code id="plotgg_+3A_show.value">show.value</code></td>
<td>
<p>a boolean to show (&quot;TRUE&quot;) or hide (&quot;FALSE&quot;) values in the plot; &quot;TRUE&quot; by default if &lt;=20 entities to compare, otherwise &quot;FALSE&quot; by default</p>
</td></tr>
<tr><td><code id="plotgg_+3A_value.digit">value.digit</code></td>
<td>
<p>the number of digits in values if they are printed; default 2</p>
</td></tr>
<tr><td><code id="plotgg_+3A_text.size">text.size</code></td>
<td>
<p>the size of values if they are printed; default 2.5</p>
</td></tr>
<tr><td><code id="plotgg_+3A_plot.margin">plot.margin</code></td>
<td>
<p>same as ggplot's plot.margin which includes top, right, bottom and left margins as &quot;margin(1,1,5,2, &quot;cm&quot;)&quot;</p>
</td></tr>
<tr><td><code id="plotgg_+3A_...">...</code></td>
<td>
<p>Additional arguments to control behavior of the function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is really a ggplot behind the scene where I have taken care of the default value of many arguments for generating a useful plot.
It generates a plot for the lower triangle of an NxN square matrix where both row and columns carry the same set of entities,
such that all pairwise analyses are shown in the plot (upper triangle is the mirror image of the lower triange
and diagonals are the relation to the self which are excluded).
</p>
<p>The plots can be requested using the column names of $all of the main output of affinity(). The function can include additional arguments
either inside plot.gg() or by appending to it with a &quot;+&quot; that is characteristic of ggplot().
</p>
<p>&quot;legendlimit&quot; centers the legend color to white by default at null expectation in the case of alpha_mle,
and negative and positive values stretch between pastel blue and pastel red colors, respectively
such that the color spectrum is applied NOT to the range of data but to the same extent of values
on both sides of zero, which is max(abs(valrange)) and -(max(abs(valrange))). For example, if alpha_mle
ranges between -1.25 to 2.0, then the color spectrum always ranges between -2.0 and 2.0 but the legend can be printed
to span between -1.25 and 2.0 with &quot;dataframe&quot; and -2.0 and 2.0 with &quot;balanced&quot;.
</p>
<p>For &quot;entity_1_count_mA&quot;, &quot;entity_2_count_mB&quot;, and &quot;sites_total_N&quot;, there is no natural midpoint.
So, &quot;balanced&quot; and &quot;datarange&quot; both use the natural behavior of ggplot in creating the color spectrum that spans between the extremes of the data.
</p>
<p>For &quot;obs_cooccur_X&quot;, and &quot;exp_cooccur&quot; also, there is no natural midpoint.
To make the two plots of observed and expected cooccurrence counts comparable visually, one color scale has been applied in these two plots
such that the spectrum ranges between the extremes of &quot;obs_cooccur_X&quot;, and &quot;exp_cooccur&quot; collectively.
</p>


<h3>Value</h3>

<p>This function returns a heatmap plot generated with ggplot() behind the scene.
</p>


<h3>Author(s)</h3>

<p>Kumar Mainali
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if(requireNamespace("cooccur", quietly = TRUE)) {
  data(finches, package = "cooccur")
} else {
  message("The cooccur package is not installed.
          You can install it with install.packages('cooccur').")
}

# require(cooccur)
# data(finches)
data(finches, package = "cooccur")
head(finches)
require(ggplot2)



# the remainder of the script has been enclosed under \donttest{}
# to bypass the CRAN's 5 second limit on example files
# --------------------------------------------------------------



# plotting various variables
# ---------------------------------------------
# compute alpha and other quantities for island-pair affinity (beta diversity)
# the square matrices are not used for plotting
myout &lt;- affinity(data = finches, row.or.col = "col")
# myout

plotgg(data = myout, variable = "alpha_mle", legendlimit = "datarange")
# in the example above, null expectation of the alpha_mle (=0) has white color,
# and negative and positive values stretch between "#87beff" and "#fd6a6c", respectively
# so that the color spectrum is applied NOT to the range of data but to the same extent of values
# on both sides of zero, which is max(abs(valrange)) and -(max(abs(valrange))).
# however, the legend can be printed to show the extent of data with "datarange"
# or the entire spectrum where the color is applied with "balanced".
plotgg(data = myout, variable = "alpha_mle", legendlimit = "balanced")
# notice that the two plots above are identical but the legend has
# different range with the same color scale.


plotgg(data = myout, variable = "sorensen", legendlimit = "balanced")
plotgg(data = myout, variable = "jaccard", legendlimit = "balanced")

# in the case of observed and expected cooccurrences, one color scale is applied for both plots
# so that the shades of color across plots can be visually compared
plotgg(data = myout, variable = "exp_cooccur", legendlimit = "datarange")
plotgg(data = myout, variable = "exp_cooccur", legendlimit = "balanced")
plotgg(data = myout, variable = "obs_cooccur_X", legendlimit = "balanced")

plotgg(data = myout, variable = "entity_1_count_mA", legendlimit = "datarange")
plotgg(data = myout, variable = "entity_2_count_mB", legendlimit = "datarange")
plotgg(data = myout, variable = "total_N", legendlimit = "datarange")
# for "entity_1_count_mA", "entity_2_count_mB", "sites_total_N",
# if legendlimit is set to "balanced", it will be changed to "datarange"
plotgg(data = myout, variable = "entity_2_count_mB", legendlimit = "balanced")


# change color of the plot
# ---------------------------------------------
plotgg(data = myout, variable = "alpha_mle", legendlimit = "balanced")
plotgg(data = myout, variable = "alpha_mle", legendlimit = "balanced",
       col = c('#99cc33', 'white', '#ff9933'))

plotgg(data = myout, variable = "obs_cooccur_X", legendlimit = "balanced")
plotgg(data = myout, variable = "obs_cooccur_X", legendlimit = "balanced",
       col = c('#99cc33', 'white', '#ff9933'))


# change the characteristics of text printed in the plot
# ------------------------------------------------------
plotgg(data = myout, variable = "alpha_mle", legendlimit = "balanced")

# change the number of digits; the default is 2
plotgg(data = myout, variable = "alpha_mle", legendlimit = "balanced", value.digit = 3)

# make the fonts bigger; the default is 2.5
plotgg(data = myout, variable = "alpha_mle", legendlimit = "balanced", text.size = 3.5)



# hide values from the plot
plotgg(data = myout, variable = "alpha_mle", legendlimit = "balanced", show.value = FALSE)


# increase or decrease margin
# ---------------------------------------------

myout &lt;- affinity(data = finches, row.or.col = "row")
# myout

plotgg(data = myout, variable = "alpha_mle", legendlimit = "balanced")
plotgg(data = myout, variable = "alpha_mle", legendlimit = "balanced",
       plot.margin = ggplot2::margin(1,1,5,2, "cm"))


# change angle of x-axis tick label; the default is 35 degrees
# ------------------------------------------------------------
plotgg(data = myout, variable = "alpha_mle", legendlimit = "balanced")
plotgg(data = myout, variable = "alpha_mle", legendlimit = "balanced") +
  ggplot2::theme(axis.text.x = element_text(angle = 45))

# to change to 90 degrees, adjust vjust
plotgg(data = myout, variable = "alpha_mle", legendlimit = "balanced") +
  ggplot2::theme(axis.text.x = element_text(angle = 90))
plotgg(data = myout, variable = "alpha_mle", legendlimit = "balanced") +
  ggplot2::theme(axis.text.x = element_text(angle = 90, vjust = 0.5))


# additional elements in the plot
# ----------------------------------
# because it is ggplot output, you can use the arguments of ggplot() to make changes

# add plot title and change legend title
plotgg(data = myout, variable = "alpha_mle", legendlimit = "balanced") +
  ggplot2::theme(axis.text.x = element_text(angle = 90, vjust = 0.5)) +
  ggplot2::ggtitle("Affinity of island pairs measured with Alpha MLE") +
  ggplot2::labs(fill = 'Alpha MLE')


# an example of much bigger dataset
# -------------------------------------
data("beetles", package = "cooccur")
dim(beetles)
myout &lt;- affinity(data = beetles, row.or.col = "row")

plotgg(data = myout, variable = "alpha_mle", legendlimit = "balanced") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5))
plotgg(data = myout, variable = "alpha_mle", legendlimit = "balanced",
       show.value = TRUE, text.size = 1.5, value.digit = 1) +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5))

 #end of \donttest{}



</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
