<!DOCTYPE html><html><head><title>Help for package poolABC</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {poolABC}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#abba'><p>Calculate the abba portion of the D-statistic</p></a></li>
<li><a href='#ABC'><p>Parameter estimation with Approximate Bayesian Computation with several</p>
targets</a></li>
<li><a href='#baba'><p>Calculate the baba portion of the D-statistic</p></a></li>
<li><a href='#BTmatrix'><p>Back-transform matrix of parameter values</p></a></li>
<li><a href='#checkCoverage'><p>Remove sites with incorrect depths of coverage</p></a></li>
<li><a href='#checkMajor'><p>Check if the major allele is the same in all populations</p></a></li>
<li><a href='#checkMissing'><p>Remove sites with missing data</p></a></li>
<li><a href='#cleanData'><p>Import and clean a single file containing data in <code>popoolation2</code> format</p></a></li>
<li><a href='#cmd2pops'><p>Create SCRM command line for a model with two populations</p></a></li>
<li><a href='#cmdParallel'><p>Create SCRM command line for a parallel origin scenario</p></a></li>
<li><a href='#cmdSingle'><p>Create SCRM command line for a single origin scenario</p></a></li>
<li><a href='#createHeader'><p>Create a header for a _rc file of popoolation2</p></a></li>
<li><a href='#createParams'><p>Draw parameters from the priors</p></a></li>
<li><a href='#D.stat'><p>calculate D-statistic</p></a></li>
<li><a href='#D.statPool'><p>Perform D-statistics analysis</p></a></li>
<li><a href='#error_modelSel'><p>Compute error in model selection with Approximate Bayesian Computation</p></a></li>
<li><a href='#errorABC'><p>Calculate cross-validation prediction error of parameter estimation</p></a></li>
<li><a href='#euclidean'><p>Compute euclidean distance</p></a></li>
<li><a href='#exclusive'><p>Compute the fraction of exclusive sites</p></a></li>
<li><a href='#Expected_Het'><p>Compute expected heterozygosity within a population</p></a></li>
<li><a href='#filterData'><p>Filter the data by the frequency of the minor allele</p></a></li>
<li><a href='#fixed'><p>Compute the fraction of sites fixed between populations</p></a></li>
<li><a href='#forceLocus'><p>Force the simulations to contain the required number of loci</p></a></li>
<li><a href='#getFst'><p>Calculate FST</p></a></li>
<li><a href='#getmode'><p>Calculate the mode of a distribution</p></a></li>
<li><a href='#Het_Between'><p>Compute heterozygosity between all pairs of populations</p></a></li>
<li><a href='#importContigs'><p>Import multiple files containing data in PoPoolation2 format</p></a></li>
<li><a href='#importData'><p>Import a single file containing data in <code>popoolation2</code> format</p></a></li>
<li><a href='#index.rejABC'><p>Parameter estimation with Approximate Bayesian Computation using rejection</p>
sampling and recording just the index of accepted simulations</a></li>
<li><a href='#indexSNPs'><p>Obtain the index of SNPs inside a block with defined size</p></a></li>
<li><a href='#inverse_trans'><p>Back-transform the parameters values</p></a></li>
<li><a href='#limits'><p>Matrix of prior limits</p></a></li>
<li><a href='#meanExpected_Het'><p>Compute mean expected heterozygosity within a population</p></a></li>
<li><a href='#mergepost'><p>Merge posterior distributions</p></a></li>
<li><a href='#mode_locfit'><p>Compute mode of a locfit object</p></a></li>
<li><a href='#modelSelect'><p>Perform model selection with Approximate Bayesian Computation</p></a></li>
<li><a href='#multipleABC'><p>Parameter estimation with Approximate Bayesian Computation for multiple</p>
targets</a></li>
<li><a href='#myparams'><p>Matrix of simulated parameter values</p></a></li>
<li><a href='#normalise'><p>Normalize data - adjust values measured on different scales</p></a></li>
<li><a href='#organize.poststat'><p>Organize point estimates from multiple posterior distributions</p></a></li>
<li><a href='#organizeSCRM'><p>Organize scrm output</p></a></li>
<li><a href='#pairFST'><p>Pairwise FST among populations</p></a></li>
<li><a href='#params'><p>Matrix of simulated parameter values</p></a></li>
<li><a href='#pickWindows'><p>Randomly select blocks of a given size from several contigs</p></a></li>
<li><a href='#plot_error'><p>Prediction error plots for ABC</p></a></li>
<li><a href='#plot_errorABC'><p>Prediction error plots for ABC using a list</p></a></li>
<li><a href='#plot_msel'><p>Plot model misclassification</p></a></li>
<li><a href='#plot_param'><p>Plot the density estimation of a given parameter</p></a></li>
<li><a href='#plot_Posteriors'><p>Plot multiple posterior distributions</p></a></li>
<li><a href='#plot_stats'><p>Plot the fit of a summary statistic to the target</p></a></li>
<li><a href='#plot_weighted'><p>Plot the density estimation of a given parameter</p></a></li>
<li><a href='#poolSim'><p>Simulation of Pooled DNA sequencing</p></a></li>
<li><a href='#poolStats'><p>Compute summary statistics from Pooled DNA sequencing</p></a></li>
<li><a href='#popsFST'><p>Pairwise FST among populations and across multiple loci</p></a></li>
<li><a href='#poststat'><p>Calculate point estimates from the posterior distribution</p></a></li>
<li><a href='#prepareData'><p>Organize information by contig - for multiple data files</p></a></li>
<li><a href='#prepareFile'><p>Organize information by contigs - for a single data file</p></a></li>
<li><a href='#priorsMatrix'><p>Construct matrix of prior limits</p></a></li>
<li><a href='#rc1'><p>Data frame with an example of observed data</p></a></li>
<li><a href='#rc2'><p>Data frame with an example of observed data</p></a></li>
<li><a href='#regABC'><p>Parameter estimation with Approximate Bayesian Computation using local linear</p>
regression</a></li>
<li><a href='#rejABC'><p>Parameter estimation with Approximate Bayesian Computation using rejection</p>
sampling</a></li>
<li><a href='#remove_quantileReads'><p>Remove sites using quantiles of the depth of coverage</p></a></li>
<li><a href='#remove_realReads'><p>Remove sites, according to their coverage, from real data</p></a></li>
<li><a href='#removeVar'><p>Remove columns with zero variance</p></a></li>
<li><a href='#runSCRM'><p>Run scrm and obtain genotypes</p></a></li>
<li><a href='#scaled.migration'><p>Compute scaled migration rates</p></a></li>
<li><a href='#scaledPrior'><p>Compute scaled migration rate limits</p></a></li>
<li><a href='#shared'><p>Compute the fraction of sites shared between populations</p></a></li>
<li><a href='#sim_modelSel'><p>Leave-one-out cross validation of model selection</p></a></li>
<li><a href='#simulationABC'><p>Perform an Approximate Bayesian Computation simulation study</p></a></li>
<li><a href='#singleABC'><p>Parameter estimation with Approximate Bayesian Computation for a single</p>
target</a></li>
<li><a href='#statsContig'><p>Compute summary statistics from observed data</p></a></li>
<li><a href='#summary_modelSelect'><p>Posterior model probabilities</p></a></li>
<li><a href='#sumstats'><p>Matrix of summary statistics computed from simulated data</p></a></li>
<li><a href='#Tmatrix'><p>Transform matrix of parameter values</p></a></li>
<li><a href='#tranf'><p>Apply a transformation to the parameters</p></a></li>
<li><a href='#weighted_stats'><p>Compute weighted point estimates</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Title:</td>
<td>Approximate Bayesian Computation with Pooled Sequencing Data</td>
</tr>
<tr>
<td>Version:</td>
<td>1.0.0</td>
</tr>
<tr>
<td>Description:</td>
<td>Provides functions to simulate Pool-seq data under models of
    demographic formation and to import Pool-seq data from real populations.
    Implements two ABC algorithms for performing parameter estimation and 
    model selection using Pool-seq data. Cross-validation can also be 
    performed to assess the accuracy of ABC estimates and model choice.
    Carvalho et al., (2022) &lt;<a href="https://doi.org/10.1111%2F1755-0998.13834">doi:10.1111/1755-0998.13834</a>&gt;.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL (&ge; 3)</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.1</td>
</tr>
<tr>
<td>Imports:</td>
<td>doParallel, foreach, ggplot2, graphics, locfit,
MetricsWeighted, nnet, poolHelper (&ge; 1.1.0), RColorBrewer,
rlang, scrm, stats, utils</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 2.10)</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/joao-mcarvalho/poolABC">https://github.com/joao-mcarvalho/poolABC</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/joao-mcarvalho/poolABC/issues">https://github.com/joao-mcarvalho/poolABC/issues</a></td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, rmarkdown</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-07-21 10:38:00 UTC; jcarvalho</td>
</tr>
<tr>
<td>Author:</td>
<td>Jo√£o Carvalho <a href="https://orcid.org/0000-0002-1728-0075"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cre, cph],
  V√≠tor Sousa [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Jo√£o Carvalho &lt;jgcarvalho@fc.ul.pt&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-08-08 14:00:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='abba'>Calculate the abba portion of the D-statistic</h2><span id='topic+abba'></span>

<h3>Description</h3>

<p>Computes the value for the ‚ÄòABBA‚Äô allelic pattern.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>abba(p1, p2, p3)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="abba_+3A_p1">p1</code></td>
<td>
<p>is a numeric vector with the allele frequencies for population 1.
Each entry of the vector should be a different site.</p>
</td></tr>
<tr><td><code id="abba_+3A_p2">p2</code></td>
<td>
<p>is a numeric vector with the allele frequencies for population 2.
Each entry of the vector should be a different site.</p>
</td></tr>
<tr><td><code id="abba_+3A_p3">p3</code></td>
<td>
<p>is a numeric vector with the allele frequencies for population 3.
Each entry of the vector should be a different site.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a numeric vector with one value per site of the locus.
</p>

<hr>
<h2 id='ABC'>Parameter estimation with Approximate Bayesian Computation with several
targets</h2><span id='topic+ABC'></span>

<h3>Description</h3>

<p>Perform multivariate parameter estimation based on summary statistics using
an Approximate Bayesian Computation (ABC) algorithm. This function always
uses a rejection sampling algorithm while a local linear regression algorithm
might or might not be used.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ABC(
  nPops,
  ntrials,
  freqs,
  positions,
  range,
  rMajor,
  rMinor,
  coverage,
  window,
  nLoci,
  limits,
  params,
  sumstats,
  tol,
  method,
  parallel = FALSE,
  ncores = NA
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ABC_+3A_npops">nPops</code></td>
<td>
<p>is an integer indicating how many different populations are
present in the dataset you are analysing.</p>
</td></tr>
<tr><td><code id="ABC_+3A_ntrials">ntrials</code></td>
<td>
<p>indicates how many different trials should be performed. Each
trial corresponds to a different target for the parameter estimation.</p>
</td></tr>
<tr><td><code id="ABC_+3A_freqs">freqs</code></td>
<td>
<p>is a list containing the allelic frequencies. Each entry of that
list should represent a different contig and be a matrix where each row
corresponds to a different site and each column to a different population.</p>
</td></tr>
<tr><td><code id="ABC_+3A_positions">positions</code></td>
<td>
<p>is a list containing the position of the SNPs. Each entry
should represent a different contig and be a vector containing the position
of each SNP present in the contig.</p>
</td></tr>
<tr><td><code id="ABC_+3A_range">range</code></td>
<td>
<p>is a list containing the range of the contig. Each entry should
represent a different contig and be a vector with two entries: the first
detailing the minimum position of the contig and the second the maximum
position of the contig.</p>
</td></tr>
<tr><td><code id="ABC_+3A_rmajor">rMajor</code></td>
<td>
<p>a list containing the number of major allele reads. Each entry
should represent a different contig. For each contig (matrix), each row
should be a different site and each column a different population.</p>
</td></tr>
<tr><td><code id="ABC_+3A_rminor">rMinor</code></td>
<td>
<p>a list containing the number of minor allele reads. Each entry
should represent a different contig. For each contig (matrix), each row
should be a different site and each column a different population.</p>
</td></tr>
<tr><td><code id="ABC_+3A_coverage">coverage</code></td>
<td>
<p>is a list containing the depth of coverage. Each entry should
represent a different contig and be a matrix with the sites as rows and the
different populations as columns.</p>
</td></tr>
<tr><td><code id="ABC_+3A_window">window</code></td>
<td>
<p>is a non-negative integer indicating the size, in base pairs,
of the block of the contig to keep.</p>
</td></tr>
<tr><td><code id="ABC_+3A_nloci">nLoci</code></td>
<td>
<p>is a non-negative integer indicating how many different contigs
should be kept in the output. If each randomly selected <code>window</code> is a
different loci, then how many different <code>window</code> should be selected?</p>
</td></tr>
<tr><td><code id="ABC_+3A_limits">limits</code></td>
<td>
<p>is a matrix with two columns and as many rows as there are
parameters. Each row should contain the minimum value of the prior for a
given parameter in the first column and the maximum value in the second
column.</p>
</td></tr>
<tr><td><code id="ABC_+3A_params">params</code></td>
<td>
<p>is a vector or matrix of simulated parameter values i.e.
numbers from the simulations. Each row or vector entry should be a
different simulation and each column of a matrix should be a different
parameter. This is the dependent variable for the regression, if a
regression step is performed.</p>
</td></tr>
<tr><td><code id="ABC_+3A_sumstats">sumstats</code></td>
<td>
<p>is a vector or matrix of simulated summary statistics. Each
row or vector entry should be a different simulation and each column of a
matrix should be a different statistic. These act as the independent
variables if a regression step is performed.</p>
</td></tr>
<tr><td><code id="ABC_+3A_tol">tol</code></td>
<td>
<p>is the tolerance rate, indicating the required proportion of
points accepted nearest the target values.</p>
</td></tr>
<tr><td><code id="ABC_+3A_method">method</code></td>
<td>
<p>either &quot;rejection&quot; or &quot;regression&quot; indicating whether a
regression step should be performed during ABC parameter estimation.</p>
</td></tr>
<tr><td><code id="ABC_+3A_parallel">parallel</code></td>
<td>
<p>logical, indicating whether this function should be run using
parallel execution. The default setting is FALSE, meaning that this
function will utilize a single core.</p>
</td></tr>
<tr><td><code id="ABC_+3A_ncores">ncores</code></td>
<td>
<p>a non-negative integer that is required when <code>parallel</code> is
TRUE. It specifies the number of cores to use for parallel execution.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>To use this function, the usual steps of ABC parameter estimation have to be
performed. Briefly, data should have been simulated based on random draws
from the prior distributions of the parameters of interest and a set of
summary statistics should have been calculated from that data. This function
requires as input the observed data and computes the same set of summary
statistics from that observed data. Multiple sets of observed summary
statistics are computed from <code>ntrials</code> sets of <code>nLoci</code> blocks of size
<code>window</code>. Parameter estimation is performed for each one of those sets of
observed summary statistics i.e. each set corresponds to a different target.
</p>
<p>After computing this set of observed summary statistics, a simple rejection
is performed by calling the <code><a href="#topic+rejABC">rejABC()</a></code> function. In this step, parameter
values are accepted if the Euclidean distance between the set of summary
statistics computed from the simulated data and the set of summary statistics
computed from the observed data is sufficiently small. The percentage of
accepted simulations is determined by <code>tol</code>.
</p>
<p>When <code>method</code> is &quot;regression&quot;, a local linear regression method is used to
correct for the imperfect match between the summary statistics computed from
the simulated data and the summary statistics computed from the observed
data. The output of the <code><a href="#topic+rejABC">rejABC()</a></code> function is used as the input of the
<code><a href="#topic+regABC">regABC()</a></code> function to apply this correction. The parameter values accepted
in the rejection step are weighted by a smooth function (kernel) of the
distance between the simulated and observed summary statistics and corrected
according to a linear transformation.
</p>


<h3>Value</h3>

<p>a list with seven different entries.
</p>
<table>
<tr><td><code>target</code></td>
<td>
<p>observed summary statistics.</p>
</td></tr>
<tr><td><code>ss</code></td>
<td>
<p>set of accepted summary statistics from the simulations.</p>
</td></tr>
<tr><td><code>unadjusted</code></td>
<td>
<p>parameter estimates obtained with the rejection
sampling.</p>
</td></tr>
<tr><td><code>adjusted</code></td>
<td>
<p>regression adjusted parameter values.</p>
</td></tr>
<tr><td><code>predmean</code></td>
<td>
<p>estimates of the posterior mean for each parameter.</p>
</td></tr>
<tr><td><code>weights</code></td>
<td>
<p>regression weights.</p>
</td></tr>
<tr><td><code>position</code></td>
<td>
<p>position of each SNP used for calculating the observed
summary statistics.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>For more details see the poolABC vignette:
<code>vignette("poolABC", package = "poolABC")</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Note that this example is limited to a few of the options available
# you should check the poolABC vignette for more details

# this creates a variable with the path for the toy example data
mypath &lt;- system.file('extdata', package = 'poolABC')

# import data for two populations from all files
mydata &lt;- importContigs(path = mypath, pops = c(8, 10))

# to perform parameter inference for two populations using the rejection method
# and with a tolerance of 0.01
myabc &lt;- ABC(nPops = 2, ntrials = 10, freqs = mydata$freqs, positions = mydata$positions,
range = mydata$range, rMajor = mydata$rMajor, rMinor = mydata$rMinor, coverage = mydata$coverage,
window = 1000, nLoci = 4, limits, params, sumstats, tol = 0.01, method = "rejection")

# the previous will perform parameter inference for 10 different targets (ntrials = 100)
# each of those trials will be comprised of 4 loci, each with 1000 base pairs

# to perform parameter inference for two populations using the regression method
# and with a tolerance of 0.01
myabc &lt;- ABC(nPops = 2, ntrials = 10, freqs = mydata$freqs, positions = mydata$positions,
range = mydata$range, rMajor = mydata$rMajor, rMinor = mydata$rMinor, coverage = mydata$coverage,
window = 1000, nLoci = 4, limits, params, sumstats, tol = 0.01, method = "regression")

</code></pre>

<hr>
<h2 id='baba'>Calculate the baba portion of the D-statistic</h2><span id='topic+baba'></span>

<h3>Description</h3>

<p>Computes the value for the ‚ÄòBABA‚Äô allelic pattern.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>baba(p1, p2, p3)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="baba_+3A_p1">p1</code></td>
<td>
<p>is a numeric vector with the allele frequencies for population 1.
Each entry of the vector should be a different site.</p>
</td></tr>
<tr><td><code id="baba_+3A_p2">p2</code></td>
<td>
<p>is a numeric vector with the allele frequencies for population 2.
Each entry of the vector should be a different site.</p>
</td></tr>
<tr><td><code id="baba_+3A_p3">p3</code></td>
<td>
<p>is a numeric vector with the allele frequencies for population 3.
Each entry of the vector should be a different site.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a numeric vector with one value per site of the locus.
</p>

<hr>
<h2 id='BTmatrix'>Back-transform matrix of parameter values</h2><span id='topic+BTmatrix'></span>

<h3>Description</h3>

<p>This function applies a back-transformation to the parameter values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BTmatrix(transformed, limits)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="BTmatrix_+3A_transformed">transformed</code></td>
<td>
<p>a matrix of transformed parameter values. Each column
should be a different parameter and each row a different simulation. This
is the matrix that you wish to back-transform so that the parameter values
are all in the original scale.</p>
</td></tr>
<tr><td><code id="BTmatrix_+3A_limits">limits</code></td>
<td>
<p>is a matrix with two columns and as many rows as there are
parameters. Each row should contain the minimum value of the prior for a
given parameter in the first column and the maximum value in the second
column.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The back-transformation should be applied after parameter estimation using an
Approximate Bayesian Computation framework. It will return the parameter
values back to their original scale.
</p>


<h3>Value</h3>

<p>a matrix with the same dimensions as the <code>transformed</code> matrix
but with the parameter values back-transformed.
</p>

<hr>
<h2 id='checkCoverage'>Remove sites with incorrect depths of coverage</h2><span id='topic+checkCoverage'></span>

<h3>Description</h3>

<p>This functions checks if the sum of the number of major and minor allele
reads of a given population is equal to the total depth of coverage of that
population.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>checkCoverage(nPops, info, major, minor, rMajor, rMinor, coverage)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="checkCoverage_+3A_npops">nPops</code></td>
<td>
<p>is an integer indicating the total number of different
populations in the dataset.</p>
</td></tr>
<tr><td><code id="checkCoverage_+3A_info">info</code></td>
<td>
<p>is a matrix containing information about the dataset. This matrix
might contain several columns including one with the reference contig
(chromosome), the position of the SNP in the reference contig and the
reference character of the SNP. Note that each row of the matrix should be
a different SNP and each column a different type of information.</p>
</td></tr>
<tr><td><code id="checkCoverage_+3A_major">major</code></td>
<td>
<p>is a matrix with the reference character of the major allele.
Each column of the matrix should be a different population and each row a
different SNP.</p>
</td></tr>
<tr><td><code id="checkCoverage_+3A_minor">minor</code></td>
<td>
<p>is a matrix with the reference character of the minor allele.
Each column of the matrix should be a different population and each row a
different SNP.</p>
</td></tr>
<tr><td><code id="checkCoverage_+3A_rmajor">rMajor</code></td>
<td>
<p>is a matrix with the number of major allele reads. Each column
of the matrix should be a different population and each row a different
SNP.</p>
</td></tr>
<tr><td><code id="checkCoverage_+3A_rminor">rMinor</code></td>
<td>
<p>is a matrix with the number of minor allele reads. Each column
of the matrix should be a different population and each row a different
SNP.</p>
</td></tr>
<tr><td><code id="checkCoverage_+3A_coverage">coverage</code></td>
<td>
<p>is a matrix with the total number of reads i.e. the depth of
coverage. Each column of the matrix should be a different population and
each row a different SNP.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This verification is performed for all the populations included in the
dataset. Any site where this verification fails for any of the populations is
removed from the dataset. More precisely, if the sum of the number of major
and minor allele reads of one population is not equal to the coverage of that
population, then that site is removed from the data for all the populations.
</p>


<h3>Value</h3>

<p>a list with the following elements:
</p>
<table>
<tr><td><code>info</code></td>
<td>
<p>a matrix with the general information about the dataset. Each
row of this matrix corresponds to a different site.</p>
</td></tr>
<tr><td><code>major</code></td>
<td>
<p>a matrix with the reference character of the major allele.
Each column of this matrix corresponds to a different population and each
row to a different site.</p>
</td></tr>
<tr><td><code>minor</code></td>
<td>
<p>a matrix with the reference character of the minor allele.
Each column of this matrix corresponds to a different population and each
row to a different site.</p>
</td></tr>
<tr><td><code>rMajor</code></td>
<td>
<p>a matrix with the number of major-allele reads. Each row of
this matrix is a different site and each column a different population.</p>
</td></tr>
<tr><td><code>rMinor</code></td>
<td>
<p>a matrix with the number of minor-allele reads. Each row of
this matrix is a different site and each column a different population.</p>
</td></tr>
<tr><td><code>coverage</code></td>
<td>
<p>a matrix with the total coverage. Each row of this matrix
is a different site and each column a different population.</p>
</td></tr>
</table>
<p>Each of those matrices is similar to the corresponding input but without
any sites where the total depth of coverage does not match the sum of the
major and minor allele reads.
</p>

<hr>
<h2 id='checkMajor'>Check if the major allele is the same in all populations</h2><span id='topic+checkMajor'></span>

<h3>Description</h3>

<p>Checks if the reference character of the major allele is the same in all
populations present in the dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>checkMajor(nPops, major, minor, rMajor, rMinor)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="checkMajor_+3A_npops">nPops</code></td>
<td>
<p>is an integer indicating the total number of different
populations in the dataset.</p>
</td></tr>
<tr><td><code id="checkMajor_+3A_major">major</code></td>
<td>
<p>is a matrix with the reference character of the major allele.
Each column of the matrix should be a different population and each row a
different SNP.</p>
</td></tr>
<tr><td><code id="checkMajor_+3A_minor">minor</code></td>
<td>
<p>is a matrix with the reference character of the minor allele.
Each column of the matrix should be a different population and each row a
different SNP.</p>
</td></tr>
<tr><td><code id="checkMajor_+3A_rmajor">rMajor</code></td>
<td>
<p>is a matrix with the number of major allele reads. Each column
of the matrix should be a different population and each row a different
SNP.</p>
</td></tr>
<tr><td><code id="checkMajor_+3A_rminor">rMinor</code></td>
<td>
<p>is a matrix with the number of minor allele reads. Each column
of the matrix should be a different population and each row a different
SNP.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>When working with two populations, the reference character of the major
allele is compared between the two populations. If they are not the same,
this function switches the major and minor reference character of the second
population i.e. the original reference character of the major allele of the
second population is now the reference character of the minor allele of the
second population. It also switches the number of reads so that the number of
major-allele reads is now the number of minor-allele reads and vice-versa.
When working with four populations, and if the major reference character is
not the same at all populations, this function checks if any of the reference
characters appears in three populations. If it does, then the major and minor
reference character and reads are switched in the remaining population. If
not, then the reference character and reads of two random populations are
switched.
</p>
<p>Finally, for both datasets with two or four populations, this function checks
if the total number of major-allele reads, across all populations and after
the switch, is larger than the total number of minor-allele reads. If this is
not true, then we switch the major and minor allele so that the more frequent
one corresponds to the major allele.
</p>


<h3>Value</h3>

<p>a list with four named entries:
</p>
<table>
<tr><td><code>major</code></td>
<td>
<p>a matrix with the reference character of the major allele.
Each column of this matrix corresponds to a different population and each
row to a different site.</p>
</td></tr>
<tr><td><code>minor</code></td>
<td>
<p>a matrix with the reference character of the minor allele.
Each column of this matrix corresponds to a different population and each
row to a different site.</p>
</td></tr>
<tr><td><code>rMajor</code></td>
<td>
<p>a matrix with the number of major-allele reads. Each row of
this matrix is a different site and each column a different population.</p>
</td></tr>
<tr><td><code>rMinor</code></td>
<td>
<p>a matrix with the number of minor-allele reads. Each row of
this matrix is a different site and each column a different population.</p>
</td></tr>
</table>
<p>Each of those matrices is similar to the corresponding input but with the
major and minor allele switched when appropriate.
</p>

<hr>
<h2 id='checkMissing'>Remove sites with missing data</h2><span id='topic+checkMissing'></span>

<h3>Description</h3>

<p>This functions checks if there is any population with an &quot;N&quot; as the reference
character for the major allele.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>checkMissing(info, major, minor, rMajor, rMinor, coverage)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="checkMissing_+3A_info">info</code></td>
<td>
<p>is a matrix containing information about the dataset. This matrix
might contain several columns including one with the reference contig
(chromosome), the position of the SNP in the reference contig and the
reference character of the SNP. Note that each row of the matrix should be
a different SNP and each column a different type of information.</p>
</td></tr>
<tr><td><code id="checkMissing_+3A_major">major</code></td>
<td>
<p>is a matrix with the reference character of the major allele.
Each column of the matrix should be a different population and each row a
different SNP.</p>
</td></tr>
<tr><td><code id="checkMissing_+3A_minor">minor</code></td>
<td>
<p>is a matrix with the reference character of the minor allele.
Each column of the matrix should be a different population and each row a
different SNP.</p>
</td></tr>
<tr><td><code id="checkMissing_+3A_rmajor">rMajor</code></td>
<td>
<p>is a matrix with the number of major allele reads. Each column
of the matrix should be a different population and each row a different
SNP.</p>
</td></tr>
<tr><td><code id="checkMissing_+3A_rminor">rMinor</code></td>
<td>
<p>is a matrix with the number of minor allele reads. Each column
of the matrix should be a different population and each row a different
SNP.</p>
</td></tr>
<tr><td><code id="checkMissing_+3A_coverage">coverage</code></td>
<td>
<p>is a matrix with the total number of reads i.e. the depth of
coverage. Each column of the matrix should be a different population and
each row a different SNP.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This verification is performed for all the populations included in the
dataset. Any site where this verification fails for any of the populations is
removed from the dataset. More precisely, if a single population has an &quot;N&quot;
as the reference character of their major allele, then that site is removed
from the data for all the populations.
</p>


<h3>Value</h3>

<p>a list with the following elements:
</p>
<table>
<tr><td><code>info</code></td>
<td>
<p>a matrix with the general information about the dataset. Each
row of this matrix corresponds to a different site.</p>
</td></tr>
<tr><td><code>major</code></td>
<td>
<p>a matrix with the reference character of the major allele.
Each column of this matrix corresponds to a different population and each
row to a different site.</p>
</td></tr>
<tr><td><code>minor</code></td>
<td>
<p>a matrix with the reference character of the minor allele.
Each column of this matrix corresponds to a different population and each
row to a different site.</p>
</td></tr>
<tr><td><code>rMajor</code></td>
<td>
<p>a matrix with the number of major-allele reads. Each row of
this matrix is a different site and each column a different population.</p>
</td></tr>
<tr><td><code>rMinor</code></td>
<td>
<p>a matrix with the number of minor-allele reads. Each row of
this matrix is a different site and each column a different population.</p>
</td></tr>
<tr><td><code>coverage</code></td>
<td>
<p>a matrix with the total coverage. Each row of this matrix
is a different site and each column a different population.</p>
</td></tr>
</table>
<p>Each of those matrices is similar to the corresponding input but without
any sites where any of the populations has an &quot;N&quot; as the reference
character for the major allele.
</p>

<hr>
<h2 id='cleanData'>Import and clean a single file containing data in <code>popoolation2</code> format</h2><span id='topic+cleanData'></span>

<h3>Description</h3>

<p>Imports data for two or four populations from a single file containing data
in the _rc format. The data is then split so that the number of major-allele
reads, minor-allele reads, total depth of coverage and remaining relevant
information are kept on separate matrices.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cleanData(file, pops, header = NA, remove = NA, min.minor = NA)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cleanData_+3A_file">file</code></td>
<td>
<p>is a character string indicating the path to the file you wish to
import.</p>
</td></tr>
<tr><td><code id="cleanData_+3A_pops">pops</code></td>
<td>
<p>is a vector with the index of the populations that should be
imported. This function works for two or four populations and so this
vector must have either length 2 or 4.</p>
</td></tr>
<tr><td><code id="cleanData_+3A_header">header</code></td>
<td>
<p>is a character vector containing the names for the columns. If
set to NA (default), no column names will be added to the output.</p>
</td></tr>
<tr><td><code id="cleanData_+3A_remove">remove</code></td>
<td>
<p>is a character vector where each entry is a name of a contig to
be removed. These contigs are, obviously, removed from the imported
dataset. If NA (default), all contigs will be kept in the output.</p>
</td></tr>
<tr><td><code id="cleanData_+3A_min.minor">min.minor</code></td>
<td>
<p>what is the minimum allowed number of reads with the minor
allele across all populations? Sites where this threshold is not met are
removed from the data. The default (NA) means that no sites will be removed
because of their number of minor-allele reads.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The information in the _rc format is stored in a x/y format, where x
represents the observed reads and the y is the coverage. The initial step of
this function splits this string to separate the number of reads from the
total coverage. Then, the number of major plus minor allele reads is compared
to the total coverage and sites where both values are not equal are removed
from the dataset. Additionally, sites where any of the populations has an &quot;N&quot;
as the reference character of their major allele, are removed from the data.
This function also ensures that the major allele is the same and the most
frequent across all populations. Finally, if the <code>min.minor</code> input is
supplied, sites where the total number of minor-allele reads is below the
specified number, will be removed from the data set.
</p>
<p>Note also that all non biallelic sites and sites where the sum of deletions
in all populations is not zero will be removed from the dataset. Although
this function can only import 2 or 4 populations at the time, it is possible
to define which two or four populations to import. For instance, if we define
the first population as the first column for which we have data in the x/y
format, then you could wish to import the data for the 5th and 6th
populations, defined as the populations in the 6th and 7th columns. To do so,
you should define the <code>pops</code> input as <code>pops = c(5, 6)</code>.
</p>


<h3>Value</h3>

<p>a list with the following elements:
</p>
<table>
<tr><td><code>rMajor</code></td>
<td>
<p>a matrix with the number of major-allele reads. Each row of
this matrix is a different site and each column a different population.</p>
</td></tr>
<tr><td><code>rMinor</code></td>
<td>
<p>a matrix with the number of minor-allele reads. Each row of
this matrix is a different site and each column a different population.</p>
</td></tr>
<tr><td><code>coverage</code></td>
<td>
<p>a matrix with the total coverage. Each row of this matrix
is a different site and each column a different population.</p>
</td></tr>
<tr><td><code>info</code></td>
<td>
<p>a data frame with 5 different columns containing: the contig
name, the SNP position, the reference character of the SNP and the
reference character of the major and minor allele for each of the
populations. Each row of this data frame corresponds to a different site</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'># load the data from one rc file
data(rc1)
# clean and organize the data in this single file
cleanData(file = rc1, pops = 7:10)

</code></pre>

<hr>
<h2 id='cmd2pops'>Create SCRM command line for a model with two populations</h2><span id='topic+cmd2pops'></span>

<h3>Description</h3>

<p>This function creates a command line tailored for an isolation with migration
model with two populations. The command line can then be fed to the scrm
package to run the model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cmd2pops(parameters, nSites, nLoci, nDip, mutrate, extra = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cmd2pops_+3A_parameters">parameters</code></td>
<td>
<p>A vector where each entry corresponds to a different
parameter, e.g. one entry is the size of the reference population, another
is the time of recent split, etc. Please note that this functions depends
on the ordering of the parameters in the vector and thus, it should only be
used with a vector created with the <code>createParams</code> function.</p>
</td></tr>
<tr><td><code id="cmd2pops_+3A_nsites">nSites</code></td>
<td>
<p>An integer representing the number of base pairs that each
locus should have.</p>
</td></tr>
<tr><td><code id="cmd2pops_+3A_nloci">nLoci</code></td>
<td>
<p>An integer that represents how many independent loci should be
simulated.</p>
</td></tr>
<tr><td><code id="cmd2pops_+3A_ndip">nDip</code></td>
<td>
<p>An integer representing the total number of diploid individuals
to simulate. Note that scrm actually simulates haplotypes, so the number of
simulated haplotypes is double of this. Also note that this is the total
number of diploid individuals and this function will distribute the
individuals equally by the two populations.</p>
</td></tr>
<tr><td><code id="cmd2pops_+3A_mutrate">mutrate</code></td>
<td>
<p>A number representing the mutation rate assumed for the
simulations.</p>
</td></tr>
<tr><td><code id="cmd2pops_+3A_extra">extra</code></td>
<td>
<p>is a logical value indicating whether the required number of
loci should be enforced. The default is FALSE but, if set to TRUE, then
additional loci will be simulated. These additional loci are simulated to
try to have sufficient loci to keep the required number of loci after
filtering.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a character vector with two entries. The first entry is the scrm
command line for the loci without any barriers against migration, while the
second entry is the scrm command line for the loci without migration
between divergent ecotypes.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># create a vector with parameter values for a two populations model
params &lt;- createParams(Nref = c(25000, 25000), ratio = c(0.1, 3), pool = c(5, 250),
seq = c(0.0001, 0.001), split = c(0, 3), CW = c(1e-13, 1e-3), WC = c(1e-13, 1e-3),
bT = c(0, 0.2), model = "2pops")

# create the command line for the scrm package
cmd2pops(parameters = params, nSites = 2000, nLoci = 100, nDip = 100, mutrate = 2e-8)

</code></pre>

<hr>
<h2 id='cmdParallel'>Create SCRM command line for a parallel origin scenario</h2><span id='topic+cmdParallel'></span>

<h3>Description</h3>

<p>This function creates a command line tailored for a scenario of parallel
origin to explain ecotype formation. The command line can then be fed to the
scrm package to run the model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cmdParallel(parameters, nSites, nLoci, nDip, mutrate, extra = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cmdParallel_+3A_parameters">parameters</code></td>
<td>
<p>A vector where each entry corresponds to a different
parameter, e.g. one entry is the size of the reference population, another
is the time of recent split, etc. Please note that this functions depends
on the ordering of the parameters in the vector and thus, it should only be
used with a vector created with the <code>createParams</code> function.</p>
</td></tr>
<tr><td><code id="cmdParallel_+3A_nsites">nSites</code></td>
<td>
<p>An integer representing the number of base pairs that each
locus should have.</p>
</td></tr>
<tr><td><code id="cmdParallel_+3A_nloci">nLoci</code></td>
<td>
<p>An integer that represents how many independent loci should be
simulated.</p>
</td></tr>
<tr><td><code id="cmdParallel_+3A_ndip">nDip</code></td>
<td>
<p>An integer representing the total number of diploid individuals
to simulate. Note that scrm actually simulates haplotypes, so the number of
simulated haplotypes is double of this. Also note that this is the total
number of diploid individuals and this function will distribute the
individuals equally by the two populations.</p>
</td></tr>
<tr><td><code id="cmdParallel_+3A_mutrate">mutrate</code></td>
<td>
<p>A number representing the mutation rate assumed for the
simulations.</p>
</td></tr>
<tr><td><code id="cmdParallel_+3A_extra">extra</code></td>
<td>
<p>is a logical value indicating whether the required number of
loci should be enforced. The default is FALSE but, if set to TRUE, then
additional loci will be simulated. These additional loci are simulated to
try to have sufficient loci to keep the required number of loci after
filtering.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For convenience, imagine we have two divergent ecotypes, named C and W. This
model assumes that the first population corresponds to the C ecotype at the
first location, the second population to the W ecotype in the first location,
the third population to the C ecotype in the second location and the fourth
population to the W ecotype in the second location.
</p>


<h3>Value</h3>

<p>a character vector with four entries. The first entry is the scrm
command line for the loci without any barriers against migration. The
second entry is the command line for the loci without migration from the C
towards the W ecotype. The third entry is command line for the loci without
migration from the W towards the C ecotype and the last entry is the scrm
command line for the loci without migration between divergent ecotypes.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># create a vector with parameter values for the parallel origin scenario
params &lt;- createParams(Nref = c(25000, 25000), ratio = c(0.1, 3), pool = c(5, 250),
seq = c(0.0001, 0.001), split = c(0, 3), CW = c(1e-13, 1e-3), WC = c(1e-13, 1e-3),
CC =  c(1e-13, 1e-3), WW = c(1e-13, 1e-3), ANC = c(1e-13, 1e-3), bT = c(0, 0.2),
bCW = c(0, 0.5), bWC = c(0, 0.5), model = "Parallel")

# create the command line for the scrm package
cmdParallel(parameters = params, nSites = 2000, nLoci = 100, nDip = 400, mutrate = 2-8)

</code></pre>

<hr>
<h2 id='cmdSingle'>Create SCRM command line for a single origin scenario</h2><span id='topic+cmdSingle'></span>

<h3>Description</h3>

<p>This function creates a command line tailored for a scenario of single origin
to explain ecotype formation. The command line can then be fed to the scrm
package to run the model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cmdSingle(parameters, nSites, nLoci, nDip, mutrate, extra = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cmdSingle_+3A_parameters">parameters</code></td>
<td>
<p>A vector where each entry corresponds to a different
parameter, e.g. one entry is the size of the reference population, another
is the time of recent split, etc. Please note that this functions depends
on the ordering of the parameters in the vector and thus, it should only be
used with a vector created with the <code>createParams</code> function.</p>
</td></tr>
<tr><td><code id="cmdSingle_+3A_nsites">nSites</code></td>
<td>
<p>An integer representing the number of base pairs that each
locus should have.</p>
</td></tr>
<tr><td><code id="cmdSingle_+3A_nloci">nLoci</code></td>
<td>
<p>An integer that represents how many independent loci should be
simulated.</p>
</td></tr>
<tr><td><code id="cmdSingle_+3A_ndip">nDip</code></td>
<td>
<p>An integer representing the total number of diploid individuals
to simulate. Note that scrm actually simulates haplotypes, so the number of
simulated haplotypes is double of this. Also note that this is the total
number of diploid individuals and this function will distribute the
individuals equally by the two populations.</p>
</td></tr>
<tr><td><code id="cmdSingle_+3A_mutrate">mutrate</code></td>
<td>
<p>A number representing the mutation rate assumed for the
simulations.</p>
</td></tr>
<tr><td><code id="cmdSingle_+3A_extra">extra</code></td>
<td>
<p>is a logical value indicating whether the required number of
loci should be enforced. The default is FALSE but, if set to TRUE, then
additional loci will be simulated. These additional loci are simulated to
try to have sufficient loci to keep the required number of loci after
filtering.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For convenience, imagine we have two divergent ecotypes, named C and W. This
model assumes that the first population corresponds to the C ecotype at the
first location, the second population to the C ecotype in the second
location, the third population to the W ecotype in the first location and the
fourth population to the W ecotype in the second location.
</p>


<h3>Value</h3>

<p>a character vector with four entries. The first entry is the scrm
command line for the loci without any barriers against migration. The
second entry is the command line for the loci without migration from the C
towards the W ecotype. The third entry is command line for the loci without
migration from the W towards the C ecotype and the last entry is the scrm
command line for the loci without migration between divergent ecotypes.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># create a vector with parameter values for the single origin scenario
params &lt;- createParams(Nref = c(25000, 25000), ratio = c(0.1, 3), pool = c(5, 250),
seq = c(0.0001, 0.001), split = c(0, 3), CW = c(1e-13, 1e-3), WC = c(1e-13, 1e-3),
CC =  c(1e-13, 1e-3), WW = c(1e-13, 1e-3), ANC = c(1e-13, 1e-3), bT = c(0, 0.2),
bCW = c(0, 0.5), bWC = c(0, 0.5), model = "Single")

# create the command line for the scrm package
cmdSingle(parameters = params, nSites = 2000, nLoci = 100, nDip = 400, mutrate = 2-8)

</code></pre>

<hr>
<h2 id='createHeader'>Create a header for a _rc file of popoolation2</h2><span id='topic+createHeader'></span>

<h3>Description</h3>

<p>Creates a header for files in the _rc format of the <code>popoolation2</code>
software. This header can be applied to a matrix as column names.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>createHeader(nPops)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="createHeader_+3A_npops">nPops</code></td>
<td>
<p>is an integer specifying how many different populations exist in
the _rc file.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Please note that the first 9 columns are a default output of the
<code>popoolation2</code> software and thus this functions maintains the same
names.
</p>


<h3>Value</h3>

<p>a character vector with the column names for a _rc popoolation2 file.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>createHeader(nPops = 10)

</code></pre>

<hr>
<h2 id='createParams'>Draw parameters from the priors</h2><span id='topic+createParams'></span>

<h3>Description</h3>

<p>This function creates a named vector of parameters that can be used as input
in the command line of the scrm package. Please note that this function needs
to be adjusted if you wish to test the effect of different prior
distributions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>createParams(
  Nref,
  ratio,
  split,
  pool,
  seq,
  CW,
  WC,
  CC = NA,
  WW = NA,
  ANC = NA,
  bT,
  bCW = NA,
  bWC = NA,
  model,
  digits = 5
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="createParams_+3A_nref">Nref</code></td>
<td>
<p>The minimum and maximum value of the uniform distribution for the
effective population size of the reference population (Nref).</p>
</td></tr>
<tr><td><code id="createParams_+3A_ratio">ratio</code></td>
<td>
<p>The minimum and maximum value of the distribution from which the
relative size of the present-day and ancestral populations are drawn. The
size of these populations is set as a ratio of the size of the Nref
population. All of these ratios are drawn from a log10 uniform
distribution.</p>
</td></tr>
<tr><td><code id="createParams_+3A_split">split</code></td>
<td>
<p>The minimum and maximum values, at the 4Nref scale, of the
uniform distribution from which the values of the times of the split events
are draw. Both the time of the recent split event and the distance between
the two split events are drawn from this distribution.</p>
</td></tr>
<tr><td><code id="createParams_+3A_pool">pool</code></td>
<td>
<p>The minimum and maximum values of the uniform distribution from
which the value of the error associated with DNA pooling is drawn. More
specifically, this value is related with the unequal individual
contribution to the pool.</p>
</td></tr>
<tr><td><code id="createParams_+3A_seq">seq</code></td>
<td>
<p>The minimum and maximum values of the uniform distribution from
which the value of the error associated with DNA sequencing is drawn. This
parameter should be supplied as a decimal number between zero and one.</p>
</td></tr>
<tr><td><code id="createParams_+3A_cw">CW</code></td>
<td>
<p>The minimum and maximum value of the uniform distribution from
which the migration rate between the two divergent ecotypes inhabiting the
same location is drawn. We consider that this parameter is drawn on a m
scale. This is the migration rate from ecotype C to ecotype W.</p>
</td></tr>
<tr><td><code id="createParams_+3A_wc">WC</code></td>
<td>
<p>The minimum and maximum value of the uniform distribution from
which the migration rate between the two divergent ecotypes inhabiting the
same location is drawn. We consider that this parameter is drawn on a m
scale. This is the migration rate from ecotype W to ecotype C.</p>
</td></tr>
<tr><td><code id="createParams_+3A_cc">CC</code></td>
<td>
<p>The minimum and maximum value of the uniform distribution from
which the migration rate between similar ecotypes inhabiting different
locations is drawn. We consider that this parameter is drawn on a m scale.
This is the migration between the two C ecotypes at two different
locations.</p>
</td></tr>
<tr><td><code id="createParams_+3A_ww">WW</code></td>
<td>
<p>The minimum and maximum value of the uniform distribution from
which the migration rate between similar ecotypes inhabiting different
locations is drawn. We consider that this parameter is drawn on a m scale.
This is the migration between the two W ecotypes at two different
locations.</p>
</td></tr>
<tr><td><code id="createParams_+3A_anc">ANC</code></td>
<td>
<p>The minimum and maximum value of the uniform distribution from
which the migration rate between the two ancestral populations is drawn. We
consider that this parameter is drawn on a m scale.</p>
</td></tr>
<tr><td><code id="createParams_+3A_bt">bT</code></td>
<td>
<p>The minimum and maximum values of the distribution from which the
proportion of the simulated loci where no migration occurs between
divergent ecotypes is drawn. The maximum value should not be higher than
one.</p>
</td></tr>
<tr><td><code id="createParams_+3A_bcw">bCW</code></td>
<td>
<p>The minimum and maximum values of the distribution from which the
proportion of the simulated loci where no migration occurs from the C
ecotype towards the W ecotype is drawn. The maximum value should not be
higher than one.</p>
</td></tr>
<tr><td><code id="createParams_+3A_bwc">bWC</code></td>
<td>
<p>The minimum and maximum values of the distribution from which the
proportion of the simulated loci where no migration occurs from the W
ecotype towards the C ecotype is drawn. The maximum value should not be
higher than one.</p>
</td></tr>
<tr><td><code id="createParams_+3A_model">model</code></td>
<td>
<p>Either &quot;2pops&quot;, &quot;Single&quot; or &quot;Parallel&quot; indicating for which
model should parameters be drawn.</p>
</td></tr>
<tr><td><code id="createParams_+3A_digits">digits</code></td>
<td>
<p>An optional integer indicating the number of decimal places to
use when rounding certain parameters. The default is five.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a vector with one named entry per relevant parameter. Each entry is
the sampled value from the prior for that particular parameter.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># for a model with two populations
createParams(Nref = c(25000, 25000), ratio = c(0.1, 3), pool = c(5, 250), seq = c(0.0001, 0.001),
split = c(0, 3), CW = c(1e-13, 1e-3), WC = c(1e-13, 1e-3), bT = c(0, 0.2), model = "2pops")

# for a single origin scenario
createParams(Nref = c(25000, 25000), ratio = c(0.1, 3), pool = c(5, 250), seq = c(0.0001, 0.001),
split = c(0, 3), CW = c(1e-13, 1e-3), WC = c(1e-13, 1e-3), CC =  c(1e-13, 1e-3),
WW = c(1e-13, 1e-3), ANC = c(1e-13, 1e-3), bT = c(0, 0.2), bCW = c(0, 0.5),
bWC = c(0, 0.5), model = "Single")

</code></pre>

<hr>
<h2 id='D.stat'>calculate D-statistic</h2><span id='topic+D.stat'></span>

<h3>Description</h3>

<p>Computes the value of the D-statistic given the values of the two particular
allelic patterns.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>D.stat(ABBA, BABA)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="D.stat_+3A_abba">ABBA</code></td>
<td>
<p>is a numeric vector with the values for the ‚ÄòABBA‚Äô allelic
pattern.</p>
</td></tr>
<tr><td><code id="D.stat_+3A_baba">BABA</code></td>
<td>
<p>is a numeric vector with the values for the ‚ÄòBABA‚Äô allelic
pattern.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a numeric value representing the D-statistic value for a particular
conformation of the populations.
</p>

<hr>
<h2 id='D.statPool'>Perform D-statistics analysis</h2><span id='topic+D.statPool'></span>

<h3>Description</h3>

<p>This functions calculates 3 different D-statistic values from pooled
sequenced data, using the allelic frequencies of the minor allele.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>D.statPool(pop_pi)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="D.statPool_+3A_pop_pi">pop_pi</code></td>
<td>
<p>is a matrix of allele frequencies. Each row of that matrix
should correspond to a different population and each column to a different
SNP.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The three different combinations computed here are: D-statistic 1 sets the
the W ecotype in the first location (N2) as P1, the W ecotype in the second
location (N4) as P2 and the C ecotype at the first location (N1) as P3.
D-statistic 2 sets the W ecotype in the first location (N2) as P1, the C
ecotype in the second location (N3) as P2 and the C ecotype at the first
location (N1) as P3. D-statistic 3 sets the W ecotype at the first location
(N2) a P1, the C ecotype at the first location (N1) as P2 and the W ecotype
at the second location (N4) as P3.
</p>


<h3>Value</h3>

<p>a numeric vector with the three D-statistics values. Each
confirmation of the populations corresponds to a different entry of the
vector.
</p>

<hr>
<h2 id='error_modelSel'>Compute error in model selection with Approximate Bayesian Computation</h2><span id='topic+error_modelSel'></span>

<h3>Description</h3>

<p>This function calculates the confusion matrix and the mean misclassification
probabilities of models from the output of the <code><a href="#topic+sim_modelSel">sim_modelSel()</a></code> function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>error_modelSel(object, threshold = NA, print = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="error_modelSel_+3A_object">object</code></td>
<td>
<p>a list created by the <code><a href="#topic+sim_modelSel">sim_modelSel()</a></code> function, containing
results of a simulation study to evaluate the quality of model selection
with Approximate Bayesian Computation.</p>
</td></tr>
<tr><td><code id="error_modelSel_+3A_threshold">threshold</code></td>
<td>
<p>numeric value between 0 and 1 representing the minimum
posterior probability of assignment.</p>
</td></tr>
<tr><td><code id="error_modelSel_+3A_print">print</code></td>
<td>
<p>logical, if TRUE (default), then this function prints the mean
models probabilities.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>It is also possible to define a <code>threshold</code> for the posterior model
probabilities. This threshold sets the minimum posterior probability of
assignment. Thus, a simulation where the posterior probability of any model
is below the threshold will not be assigned to a model and will instead be
classified as &quot;unclear&quot;.
</p>


<h3>Value</h3>

<p>apart from directly displaying the results if print is TRUE, the
output object of this function is a list with the following elements:
</p>
<table>
<tr><td><code>confusion.matrix</code></td>
<td>
<p>the confusion matrix.</p>
</td></tr>
<tr><td><code>probs</code></td>
<td>
<p>the mean model misclassification probabilities.</p>
</td></tr>
<tr><td><code>postmeans</code></td>
<td>
<p>the mean model misclassification probabilities when each
model is correctly or incorrectly estimated.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'># load the matrix with simulated parameter values
data(sumstats)

# select a random simulation to act as target just to test the function
target &lt;- sumstats[10 ,]

# create a "fake" vector of model indices
# this assumes that half the simulations were from one model and the other half from other model
# this is not true but serves as an example of how to use this function
index &lt;- c(rep("model1", nrow(sumstats)/2), rep("model2", nrow(sumstats)/2))

# perform a leave-one-out cross validation of model selection
mysim &lt;- sim_modelSel(index = index, sumstats = sumstats, nval = 10, tol = 0.1)

# compute the confusion matrix and the mean misclassification probabilities
error_modelSel(object = mysim)

</code></pre>

<hr>
<h2 id='errorABC'>Calculate cross-validation prediction error of parameter estimation</h2><span id='topic+errorABC'></span>

<h3>Description</h3>

<p>This function calculates the prediction error between estimates obtained
after a leave-one-out cross validation for ABC and the true parameter values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>errorABC(true, estimated)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="errorABC_+3A_true">true</code></td>
<td>
<p>is a matrix where each row corresponds to the true parameter
values of a given simulation and each column to a different parameter.
These parameters where used as the pseudo-observed targets in the
simulation study.</p>
</td></tr>
<tr><td><code id="errorABC_+3A_estimated">estimated</code></td>
<td>
<p>is a matrix with the estimated parameter values. Each row
corresponds to the estimate of the true parameter values present in the
corresponding row of the <code>true</code> matrix. And each column should correspond
to a different parameter.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The prediction error is calculated as <code>sum((E-T)^2) / (nval * var(T))</code>,
where T is the true parameter value, E is the estimated parameter value, and
nval is the number of points where the true and predicted values were
compared.
</p>


<h3>Value</h3>

<p>a numeric vector with the prediction error for each parameter. If
column names are present in the input matrices, then this vector will also
be named with the parameter names.
</p>

<hr>
<h2 id='euclidean'>Compute euclidean distance</h2><span id='topic+euclidean'></span>

<h3>Description</h3>

<p>Computes the euclidean distance between two integers or numeric vectors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>euclidean(a, b)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="euclidean_+3A_a">a</code></td>
<td>
<p>is an integer or a numeric vector.</p>
</td></tr>
<tr><td><code id="euclidean_+3A_b">b</code></td>
<td>
<p>is another integer or numeric vector.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a numeric value representing the euclidean distance between the two
inputs.
</p>

<hr>
<h2 id='exclusive'>Compute the fraction of exclusive sites</h2><span id='topic+exclusive'></span>

<h3>Description</h3>

<p>This function will compute the fraction of sites showing an exclusive
polymorphism to a given population.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>exclusive(minor, total, nPops)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="exclusive_+3A_minor">minor</code></td>
<td>
<p>is a matrix with the number of minor-allele reads. Each row of
the matrix is a different population and each column a different site.</p>
</td></tr>
<tr><td><code id="exclusive_+3A_total">total</code></td>
<td>
<p>is a matrix with the total coverage. Each row of the matrix is a
different population and each column a different site.</p>
</td></tr>
<tr><td><code id="exclusive_+3A_npops">nPops</code></td>
<td>
<p>is an integer indicating the total number of populations.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>More precisely, we define exclusive polymorphisms as sites that are
segregating in only one of the populations. To clarify, we define segregating
sites as sites where the number of minor-allele reads of a given population
at a given site are not equal to zero or to the total coverage of that
population. We then check if those segregating sites are also segregating in
the other population.
</p>
<p>For models with two populations, this function compares the two present-day
populations. For models with four populations, this function performs a
pairwise comparison of the populations at each of the locations. For the
models with four populations, we also assess the fraction of sites that are
segregating only in one population and not in the other three.
</p>


<h3>Value</h3>

<p>a numeric vector with two entries when <code>nPops</code> is equal to 2 or
with five entries when <code>nPops</code> is set to 4.
</p>

<hr>
<h2 id='Expected_Het'>Compute expected heterozygosity within a population</h2><span id='topic+Expected_Het'></span>

<h3>Description</h3>

<p>This functions calculates the value of the expected heterozygosity for each
SNP.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Expected_Het(Pop_Pi)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Expected_Het_+3A_pop_pi">Pop_Pi</code></td>
<td>
<p>is a matrix or list of allele frequencies. When dealing with a
single locus, this input is a matrix and when dealing with multiple loci it
is a list. Each entry of that list is a matrix representing a different
locus. Each row of that matrix should correspond to a different population
and each column to a different SNP.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>if the input is a single matrix, the output will be a matrix where
each row represents a different population and each column is the expected
heterozygosity of a population at that site. If the input is a list, the
output will also be a list, with each entry corresponding to a different
locus. Each of those entries will be a matrix with different populations in
different rows and the expected heterozygosity of different sites at
different columns.
</p>

<hr>
<h2 id='filterData'>Filter the data by the frequency of the minor allele</h2><span id='topic+filterData'></span>

<h3>Description</h3>

<p>Computes the frequency of the minor allele across all populations and removes
sites where that frequency is below a certain threshold.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>filterData(rMajor, rMinor, coverage, info, threshold = NA)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="filterData_+3A_rmajor">rMajor</code></td>
<td>
<p>is a matrix containing the number of observed major-allele
reads. Each row of the matrix should be a different site and each column
should contain information for a single population</p>
</td></tr>
<tr><td><code id="filterData_+3A_rminor">rMinor</code></td>
<td>
<p>is a matrix containing the number of observed minor-allele
reads. Each row of the matrix should be a different site and each column
should contain information for a single population</p>
</td></tr>
<tr><td><code id="filterData_+3A_coverage">coverage</code></td>
<td>
<p>is a matrix containing the total depth of coverage. Each row
of the matrix should be a different site and each column should contain
information for a single population</p>
</td></tr>
<tr><td><code id="filterData_+3A_info">info</code></td>
<td>
<p>is a data frame containing the remaining relevant information,
such as the contig name and the position of each SNP. Each row of the
matrix should be a different site.</p>
</td></tr>
<tr><td><code id="filterData_+3A_threshold">threshold</code></td>
<td>
<p>is the maximum allowed frequency for the major allele. Sites
where the allelic frequency is above this threshold are removed from the
data.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The frequency of the minor allele is computed by dividing the total number of
minor-allele reads at each site and across all populations by the total
coverage of that site. The total coverage is obtained by adding the depth of
coverage of each population at each site. If a threshold is supplied, the
computed frequency is compared to that threshold and sites where the
frequency is below the threshold are removed from the dataset. If no
threshold is supplied, the threshold is assumed to be <code>1/total
coverage</code>, meaning that a site should have, at least, one minor-allele read.
</p>


<h3>Value</h3>

<p>a list with the following elements:
</p>
<table>
<tr><td><code>rMajor</code></td>
<td>
<p>a matrix with the number of major-allele reads. Each row of
this matrix is a different site and each column a different population.</p>
</td></tr>
<tr><td><code>rMinor</code></td>
<td>
<p>a matrix with the number of minor-allele reads. Each row of
this matrix is a different site and each column a different population.</p>
</td></tr>
<tr><td><code>coverage</code></td>
<td>
<p>a matrix with the total coverage. Each row of this matrix
is a different site and each column a different population.</p>
</td></tr>
<tr><td><code>info</code></td>
<td>
<p>a data frame with 5 different columns containing: the contig
name, the SNP position, the reference character of the SNP and the
reference character of the major and minor allele for each of the
populations. Each row of this data frame corresponds to a different site</p>
</td></tr>
</table>
<p>The <code>rMajor</code>, <code>rMinor</code> and <code>coverage</code> are similar to the corresponding
input but without any sites where the frequency of the minor-allele is
below a certain threshold.
</p>

<hr>
<h2 id='fixed'>Compute the fraction of sites fixed between populations</h2><span id='topic+fixed'></span>

<h3>Description</h3>

<p>This function will compute the fraction of sites that constitute a fixed
difference between populations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fixed(minor, total, nPops)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fixed_+3A_minor">minor</code></td>
<td>
<p>is a matrix with the number of minor-allele reads. Each row of
the matrix is a different population and each column a different site.</p>
</td></tr>
<tr><td><code id="fixed_+3A_total">total</code></td>
<td>
<p>is a matrix with the total coverage. Each row of the matrix is a
different population and each column a different site.</p>
</td></tr>
<tr><td><code id="fixed_+3A_npops">nPops</code></td>
<td>
<p>is an integer indicating the total number of populations.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>More precisely, we define fixed differences as sites where the number of
minor-allele reads of a given population is equal to the total coverage of
that population and equal to zero in the other population.
</p>
<p>For models with two populations, this function compares the two present-day
populations. For models with four populations, this function performs a
pairwise comparison of the populations at each of the locations. For the
models with four populations, we also assess the fraction of sites that
represent a fixed difference between any of the populations and the remaining
three populations.
</p>


<h3>Value</h3>

<p>a numeric vector with a single entry when <code>nPops</code> is equal to 2 or
with three entries when <code>nPops</code> is set to 4.
</p>

<hr>
<h2 id='forceLocus'>Force the simulations to contain the required number of loci</h2><span id='topic+forceLocus'></span>

<h3>Description</h3>

<p>This function attempts to force the required number of loci after the
filtering steps are performed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>forceLocus(
  model,
  parameters,
  nSites,
  nLoci,
  nDip,
  mutrate,
  mean,
  variance,
  minimum,
  maximum,
  size,
  min.minor
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="forceLocus_+3A_model">model</code></td>
<td>
<p>a character, either 2pops&quot;, &quot;Single&quot; or &quot;Parallel&quot; indicating
which model should be simulated.</p>
</td></tr>
<tr><td><code id="forceLocus_+3A_parameters">parameters</code></td>
<td>
<p>a vector of parameters used to create the command line for
the scrm package. Each entry of the vector is a different parameter. Note
that each vector entry should be named with the name of the corresponding
parameter. The output of the <code>CreateParameters</code> function is the intended
input.</p>
</td></tr>
<tr><td><code id="forceLocus_+3A_nsites">nSites</code></td>
<td>
<p>is an integer that specifies how many base pairs should scrm
simulate, i.e. how many sites per locus to simulate.</p>
</td></tr>
<tr><td><code id="forceLocus_+3A_nloci">nLoci</code></td>
<td>
<p>an integer that represents how many independent loci should be
simulated.</p>
</td></tr>
<tr><td><code id="forceLocus_+3A_ndip">nDip</code></td>
<td>
<p>an integer representing the total number of diploid individuals
to simulate. Note that scrm actually simulates haplotypes, so the number of
simulated haplotypes is double of this. Also note that this is the total
number of diploid individuals and this function will distribute the
individuals equally by the simulated populations.</p>
</td></tr>
<tr><td><code id="forceLocus_+3A_mutrate">mutrate</code></td>
<td>
<p>an integer representing the mutation rate assumed for the
simulations.</p>
</td></tr>
<tr><td><code id="forceLocus_+3A_mean">mean</code></td>
<td>
<p>an integer or a vector defining the mean value of the negative
binomial distribution from which different number of reads are drawn. It
represents the mean coverage across all sites. If a vector is supplied, the
function assumes that each entry of the vector is the mean for a different
population.</p>
</td></tr>
<tr><td><code id="forceLocus_+3A_variance">variance</code></td>
<td>
<p>an integer or a vector defining the variance of the negative
binomial distribution from which different number of reads are drawn. It
represents the variance of the total coverage across all sites. If a vector
is supplied, the function assumes that each entry of the vector is the
variance for a different population.</p>
</td></tr>
<tr><td><code id="forceLocus_+3A_minimum">minimum</code></td>
<td>
<p>an integer representing the minimum coverage allowed. Sites
where any population has a depth of coverage below this threshold are
removed from the data.</p>
</td></tr>
<tr><td><code id="forceLocus_+3A_maximum">maximum</code></td>
<td>
<p>an integer representing the maximum coverage allowed. Sites
where any population has a depth of coverage above this threshold are
removed from the data.</p>
</td></tr>
<tr><td><code id="forceLocus_+3A_size">size</code></td>
<td>
<p>a list with one entry per population. Each entry should be a
vector containing the size (in number of diploid individuals) of each pool.
Thus, if a population was sequenced using a single pool, the vector should
contain only one entry. If a population was sequenced using two pools, each
with 10 individuals, this vector should contain two entries and both will
be 10.</p>
</td></tr>
<tr><td><code id="forceLocus_+3A_min.minor">min.minor</code></td>
<td>
<p>is an integer representing the minimum allowed number of
minor-allele reads. Sites that, across all populations, have less
minor-allele reads than this threshold will be removed from the data.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is done by simulating extra loci for each of the different types of
simulations performed. The possible types of simulations include loci without
barriers against migration between divergent ecotypes, loci without migration
from the C towards the W ecotype, loci without migration from the W towards
the C ecotypes and loci where no migration occurs between divergent ecotypes.
Using this function, more loci than required are simulated for each of those
types of simulations.
</p>
<p>Then, a coverage-based filter is applied to the data, followed by a filter
based on a required number of minor-allele reads per site. Those filters
remove some loci from the data. The extra simulated loci should allow us to
keep the required number of loci per type of simulation even after filtering.
</p>


<h3>Value</h3>

<p>a list with two names entries
</p>
<table>
<tr><td><code>pool</code></td>
<td>
<p>a list with three different entries: major, minor and total.
This list is obtained by running the <code><a href="poolHelper.html#topic+forcePool">forcePool</a></code> function.</p>
</td></tr>
<tr><td><code>nPoly</code></td>
<td>
<p>a numeric value indicating the mean number of polymorphic
sites across all simulated locus.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'># create a vector with parameter values for a two populations model
params &lt;- createParams(Nref = c(25000, 25000), ratio = c(0.1, 3), pool = c(5, 250),
seq = c(0.0001, 0.001), split = c(0, 3), CW = c(1e-13, 1e-3), WC = c(1e-13, 1e-3),
bT = c(0, 0.2), model = "2pops")

# simulate exactly 10 loci - using an isolation with migration model with two populations
forceLocus(model = "2pops", parameters = params, nSites = 1000, nLoci = 10, nDip = 100,
mutrate = 2e-8, mean = c(100, 100), variance = c(250, 250), minimum = 10, maximum = 200,
size = list(50, 50), min.minor = 0)

</code></pre>

<hr>
<h2 id='getFst'>Calculate FST</h2><span id='topic+getFst'></span>

<h3>Description</h3>

<p>This function computes FST according to Hudson's estimator following Bathia.
Note that the frequencies for the two populations should be entered as
separate inputs.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getFst(freq1, freq2, ss1, ss2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getFst_+3A_freq1">freq1</code></td>
<td>
<p>is a numeric vector with the allele frequencies for population
</p>

<ol>
<li><p> Each entry of the vector should be a different site.
</p>
</li></ol>
</td></tr>
<tr><td><code id="getFst_+3A_freq2">freq2</code></td>
<td>
<p>is a numeric vector with the allele frequencies for population
2. Each entry of the vector should be a different site.</p>
</td></tr>
<tr><td><code id="getFst_+3A_ss1">ss1</code></td>
<td>
<p>vector with the sample size for population 1. Each entry of the
vector should contain the number of reads for a different site.</p>
</td></tr>
<tr><td><code id="getFst_+3A_ss2">ss2</code></td>
<td>
<p>vector with the sample size for population 2. Each entry of the
vector should contain the number of reads for a different site.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Note that this functions computes a single FST value between two populations
and does not perform pairwise comparisons of multiple populations.
</p>


<h3>Value</h3>

<p>a numeric value which is the FST between the two populations.
</p>

<hr>
<h2 id='getmode'>Calculate the mode of a distribution</h2><span id='topic+getmode'></span>

<h3>Description</h3>

<p>Computes and outputs the mode of the input distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getmode(x, xlim, weights = NULL, alpha = 0.7, precision = 1000)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getmode_+3A_x">x</code></td>
<td>
<p>is a numeric vector containing the values of the distribution.</p>
</td></tr>
<tr><td><code id="getmode_+3A_xlim">xlim</code></td>
<td>
<p>is a vector with two entries.The first entry is the minimum of
the <code>x</code> distribution and the second entry is the maximum value of the
<code>x</code> distribution. Ideally these values should be the minimum and
maximum value of the prior for this particular parameter.</p>
</td></tr>
<tr><td><code id="getmode_+3A_weights">weights</code></td>
<td>
<p>this is an optional input consisting of a vector with the
prior weights for the locfit function.</p>
</td></tr>
<tr><td><code id="getmode_+3A_alpha">alpha</code></td>
<td>
<p>numeric value with the alpha parameter of the locfit function.
The default value is 0.7</p>
</td></tr>
<tr><td><code id="getmode_+3A_precision">precision</code></td>
<td>
<p>value indicating the number of entries evaluated. The larger
the value the higher the precision. The default value is 1000.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code><a href="locfit.html#topic+locfit">locfit::locfit()</a></code> function is used to fit a local regression to the
distribution. The <code><a href="stats.html#topic+predict">stats::predict()</a></code> function is then used to predict the
y-axis values of the locfit and the mode is defined as the value where that
prediction is maximized. Note that if this function is not able to fit a
local regression to the distribution, then the mode of the distribution will
be assumed to be equal to the median.
</p>


<h3>Value</h3>

<p>a numeric value of the mode of the input distribution.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># create a random distribution
x &lt;- rnorm(n = 100, mean = 2, sd = 25)

# compute the mode of the distribution
getmode(x = x, xlim = c(min(x), max(x)))

</code></pre>

<hr>
<h2 id='Het_Between'>Compute heterozygosity between all pairs of populations</h2><span id='topic+Het_Between'></span>

<h3>Description</h3>

<p>This function computes the value of the mean expected heterozygosity between
all pairwise combinations of different populations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Het_Between(Pop_Pi)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Het_Between_+3A_pop_pi">Pop_Pi</code></td>
<td>
<p>is a matrix or list of allele frequencies. When dealing with a
single locus, this input is a matrix and when dealing with multiple loci it
is a list. Each entry of that list is a matrix representing a different
locus. Each row of that matrix should correspond to a different population
and each column to a different SNP.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If you wish to see what the different combinations are, please run
<code>combn(nrow(Pop_Pi), m = 2)</code>. It should also be noted that the order of
the combinations obtained by using that command is the same as the order of
the output vector. This functions works when the input is a matrix or a list.
</p>


<h3>Value</h3>

<p>if the input is a matrix, this will be a vector where each entry
represents the mean expected heterozygosity between two populations. When a
list is used as input, the output will also be a list and each entry of
that list will be a vector with the mean expected heterozygosity between
pairs of populations for that locus.
</p>

<hr>
<h2 id='importContigs'>Import multiple files containing data in PoPoolation2 format</h2><span id='topic+importContigs'></span>

<h3>Description</h3>

<p>Imports multiple files containing data in PoPoolation2 format and organize
that information into different entries for each contig.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>importContigs(
  path,
  pops,
  files = NA,
  header = NA,
  remove = NA,
  min.minor = NA,
  filter = FALSE,
  threshold = NA
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="importContigs_+3A_path">path</code></td>
<td>
<p>is a character string indicating the path to the folder where the
data you wish to import is located.</p>
</td></tr>
<tr><td><code id="importContigs_+3A_pops">pops</code></td>
<td>
<p>is a vector with the index of the populations that should be
imported. This function works for two or four populations and so this
vector must have either length 2 or 4.</p>
</td></tr>
<tr><td><code id="importContigs_+3A_files">files</code></td>
<td>
<p>is an integer or a numeric vector with the index of the files
you wish to import.</p>
</td></tr>
<tr><td><code id="importContigs_+3A_header">header</code></td>
<td>
<p>is a character vector containing the names for the columns. If
set to NA (default), no column names will be added to the output.</p>
</td></tr>
<tr><td><code id="importContigs_+3A_remove">remove</code></td>
<td>
<p>is a character vector where each entry is a name of a contig to
be removed. These contigs are, obviously, removed from the imported
dataset. If NA (default), all contigs will be kept in the output.</p>
</td></tr>
<tr><td><code id="importContigs_+3A_min.minor">min.minor</code></td>
<td>
<p>what is the minimum allowed number of reads with the minor
allele across all populations? Sites where this threshold is not met are
removed from the data.</p>
</td></tr>
<tr><td><code id="importContigs_+3A_filter">filter</code></td>
<td>
<p>is a logical switch, either TRUE or FALSE. If TRUE, then the
data is filtered by the frequency of the minor allele and if FALSE, that
filter is not applied.</p>
</td></tr>
<tr><td><code id="importContigs_+3A_threshold">threshold</code></td>
<td>
<p>is the minimum allowed frequency for the minor allele. Sites
where the allelic frequency is below this threshold are removed from the
data.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The data from two or four populations is split so that the number of
major-allele reads, minor-allele reads, total depth of coverage and remaining
relevant information are kept on separate list entries. Sites where the sum
of the major and minor allele reads does not match the total coverage and
sites where any population has an &quot;N&quot; as the reference character of their
major allele, are removed from the data. This function also ensures that the
major allele is the same and the most frequent across all populations. Note
also that all non biallelic sites and sites where the sum of deletions in all
populations is not zero will be removed from the dataset.
</p>
<p>If the <code>min.minor</code> input is supplied, sites where the total number of
minor-allele reads is below the specified number, will be removed from the
data set. Alternatively, if the filter input is set to TRUE, data will be
filtered by the frequency of the minor-allele. If a threshold is supplied,
the computed frequency is compared to that threshold and sites where the
frequency is below the threshold are removed from the dataset. If no
threshold is supplied, the threshold is assumed to be <code>1/total
coverage</code>, meaning that a site should have, at least, one minor-allele read.
</p>
<p>Finally, the name of each contig is used to organize the information in a per
contig basis. Thus, each output will be organized by contig. For example, the
list with the number of minor-allele reads will contain several entries and
each of those entries is a different contig.
</p>


<h3>Value</h3>

<p>a list with six named entries:
</p>
<table>
<tr><td><code>freqs</code></td>
<td>
<p>a list with the allele frequencies, computed by dividing the
number of minor-allele reads by the total coverage. Each entry of this list
corresponds to a different contig. Each entry is a matrix where each row is
a different site and each column is a different population.</p>
</td></tr>
<tr><td><code>positions</code></td>
<td>
<p>a list with the positions of each SNP. Each entry of this
list is a vector corresponding to a different contig.</p>
</td></tr>
<tr><td><code>range</code></td>
<td>
<p>a list with the minimum and maximum SNP position of each
contig. Each entry of this list is a vector corresponding to a different
contig.</p>
</td></tr>
<tr><td><code>rMajor</code></td>
<td>
<p>a list with the number of major-allele reads. Each entry of
this list corresponds to a different contig. Each entry is a matrix where
each row is a different site and each column is a different population.</p>
</td></tr>
<tr><td><code>rMinor</code></td>
<td>
<p>a list with the number of minor-allele reads. Each entry of
this list corresponds to a different contig. Each entry is a matrix where
each row is a different site and each column is a different population.</p>
</td></tr>
<tr><td><code>coverage</code></td>
<td>
<p>a list with the total coverage. Each entry of this list
corresponds to a different contig. Each entry is a matrix where each row is
a different site and each column is a different population.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>For more details see the poolABC vignette:
<code>vignette("poolABC", package = "poolABC")</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># this function should be used to import your data
# you should include the path to the folder your PoPoolation2 data is

# this creates a variable with the path for the toy example data
mypath &lt;- system.file('extdata', package = 'poolABC')

# an example of how to import data for two populations from all files
importContigs(path = mypath, pops = c(8, 10))

# to remove contigs from the data
importContigs(path = mypath, pops = c(8, 10), remove = "Contig1708")

</code></pre>

<hr>
<h2 id='importData'>Import a single file containing data in <code>popoolation2</code> format</h2><span id='topic+importData'></span>

<h3>Description</h3>

<p>Load a file that is in the _rc format of the <code>popoolation2</code> software.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>importData(file, pops = NA, header = NA, remove = NA)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="importData_+3A_file">file</code></td>
<td>
<p>is a character string indicating the path to the file you wish to
import.</p>
</td></tr>
<tr><td><code id="importData_+3A_pops">pops</code></td>
<td>
<p>is a vector with the index of the populations that should be
imported. Defaults to NA, meaning that data is imported for all
populations.</p>
</td></tr>
<tr><td><code id="importData_+3A_header">header</code></td>
<td>
<p>is a character vector containing the names for the columns. If
set to NA (default), no column names will be added to the output.</p>
</td></tr>
<tr><td><code id="importData_+3A_remove">remove</code></td>
<td>
<p>is a character vector where each entry is a name of a contig to
be removed. These contigs are, obviously, removed from the imported
dataset. If NA (default), all contigs will be kept in the output.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function will import a single file containing data in the _rc format.
Note that this function will remove all non biallelic sites and sites where
the sum of deletions in all populations is not zero.
</p>
<p>The first 9 columns of the matrix contain general information about the data
and the number of major-allele reads for each population starts on the 10th
column. Thus, the 10th column contains the number of major-allele reads for
the first population, the 11th column contains the number of major-allele
reads for the second population and so on. Thus if, for example, you wish to
import the data for the 5th and 6th population, then you should define the
<code>pops</code> input as <code>pops = c(5, 6)</code>. This will result in keeping only
the first 9 columns of the matrix plus the 15th and 16th columns and the
corresponding columns with the number of minor-allele reads for those
populations.
</p>


<h3>Value</h3>

<p>a matrix with general information about the data in the first 9
columns and the number of major and minor allele reads for the required
populations in the remaining columns. If an header was supplied then the
matrix will also contain column names as defined by the <code>header</code>
input.
</p>

<hr>
<h2 id='index.rejABC'>Parameter estimation with Approximate Bayesian Computation using rejection
sampling and recording just the index of accepted simulations</h2><span id='topic+index.rejABC'></span>

<h3>Description</h3>

<p>This function performs multivariate parameter estimation based on summary
statistics using an Approximate Bayesian Computation (ABC) algorithm. The
algorithm used here is the rejection sampling algorithm. This is a simplified
version of the <code><a href="#topic+rejABC">rejABC()</a></code> function that records only the index of the
accepted simulations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>index.rejABC(target, params, sumstats, tol)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="index.rejABC_+3A_target">target</code></td>
<td>
<p>a vector with the target summary statistics. These are usually
the set of observed summary statistics.</p>
</td></tr>
<tr><td><code id="index.rejABC_+3A_params">params</code></td>
<td>
<p>is a vector or matrix of simulated parameter values i.e.
numbers from the simulations. Each row or vector entry should be a
different simulation and each column of a matrix should be a different
parameter.</p>
</td></tr>
<tr><td><code id="index.rejABC_+3A_sumstats">sumstats</code></td>
<td>
<p>is a vector or matrix of simulated summary statistics. Each
row or vector entry should be a different simulation and each column of a
matrix should be a different statistic.</p>
</td></tr>
<tr><td><code id="index.rejABC_+3A_tol">tol</code></td>
<td>
<p>is the tolerance rate, indicating the required proportion of
points accepted nearest the target values.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The rejection sampling algorithm generates random samples from the posterior
distributions of the parameters of interest. Note that to use this function,
the usual steps of ABC parameter estimation have to be performed. Briefly,
data should have been simulated based on random draws from the prior
distributions of the parameters of interest and a set of summary statistics
should have been calculated from that data. The same set of summary
statistics should have been calculated from the observed data to be used as
the <code>target</code> input in this function. Parameter values are accepted if the
Euclidean distance between the set of summary statistics computed from the
simulated data and the set of summary statistics computed from the observed
data is sufficiently small. The percentage of accepted simulations is
determined by <code>tol</code>.
</p>


<h3>Value</h3>

<p>a list with two named entries
</p>
<table>
<tr><td><code>index</code></td>
<td>
<p>the index of the accepted simulations.</p>
</td></tr>
<tr><td><code>dst</code></td>
<td>
<p>euclidean distances in the region of interest.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'># load the matrix with parameter values
data(params)
# load the matrix with simulated parameter values
data(sumstats)

# select a random simulation to act as target just to test the function
target &lt;- sumstats[10 ,]

# Parameter estimation using rejection sampling
index.rejABC(target = target, params = params, sumstats = sumstats[-10, ], tol = 0.01)


</code></pre>

<hr>
<h2 id='indexSNPs'>Obtain the index of SNPs inside a block with defined size</h2><span id='topic+indexSNPs'></span>

<h3>Description</h3>

<p>Selects a random block of a smaller size from a larger contig and obtain the
index of the SNPs that are contained within that block.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>indexSNPs(positions, range, window)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="indexSNPs_+3A_positions">positions</code></td>
<td>
<p>is a numeric vector where each entry corresponds to the
position of a SNP present in the contig.</p>
</td></tr>
<tr><td><code id="indexSNPs_+3A_range">range</code></td>
<td>
<p>is a numeric vector with two entries: the first is the minimum
position of any SNP of the contig and the second is the maximum position of
any SNP in that same contig.</p>
</td></tr>
<tr><td><code id="indexSNPs_+3A_window">window</code></td>
<td>
<p>is a non-negative integer indicating the size, in base pairs,
of the block of the contig to keep.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function starts by removing the edges of the contig. The size of the
removed portion is equal to the size of the block to keep. Then, a SNP is
randomly pick from the vector of all possible SNP positions. An initial block
is constructed by selecting all SNPs contained in a window of <code>window</code>
size, both upstream and downstream from that SNP. Finally, SNPs are removed
from both ends of that initial block until all remaining SNPs are contained
within a block of <code>window</code> size.
</p>


<h3>Value</h3>

<p>a numeric vector containing the index of the SNPs present within a
randomly selected window of a given contig.
</p>

<hr>
<h2 id='inverse_trans'>Back-transform the parameters values</h2><span id='topic+inverse_trans'></span>

<h3>Description</h3>

<p>This function applies a back-transformation to the parameter values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>inverse_trans(y, min, max)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="inverse_trans_+3A_y">y</code></td>
<td>
<p>is the parameter vector (long vector of numbers from the
simulations). These are the values to be back-transformed.</p>
</td></tr>
<tr><td><code id="inverse_trans_+3A_min">min</code></td>
<td>
<p>is the minimum value of the prior for this parameter.</p>
</td></tr>
<tr><td><code id="inverse_trans_+3A_max">max</code></td>
<td>
<p>is the maximum value of the prior for this parameter.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The back-transformation should be applied after parameter estimation using an
Approximate Bayesian Computation framework. It will return the parameter
values back to their original scale.
</p>


<h3>Value</h3>

<p>a numeric vector with the same length as <code>y</code> with the parameter
values back-transformed.
</p>

<hr>
<h2 id='limits'>Matrix of prior limits</h2><span id='topic+limits'></span>

<h3>Description</h3>

<p>this imports a matrix with the limits of the prior distribution
for each parameter. Each row of the matrix is a different parameter,
indicated by the row name. The matrix contains two columns, the first being
the minimum value of the distribution and the second being the maximum
value.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>limits
</code></pre>


<h3>Format</h3>

<p>a matrix with 8 rows and 2 columns. Each of the rows corresponds to a
different parameter:
</p>

<dl>
<dt>N1</dt><dd><p>relative size of the first population. This population
corresponds to the C ecotype.</p>
</dd>
<dt>N2</dt><dd><p>relative size of the second population. This population
corresponds to the W ecotype.</p>
</dd>
<dt>Split</dt><dd><p>time, in 4Nref scale, of the split event that creates the two
populations.</p>
</dd>
<dt>PoolError</dt><dd><p>error associated with DNA pooling.</p>
</dd>
<dt>SeqError</dt><dd><p>error associated with DNA sequencing.</p>
</dd>
<dt>pM</dt><dd><p>proportion of the genome with no barriers against gene flow. This
is the proportion of simulated loci where migration occurs in both
directions between the divergent ecotypes.</p>
</dd>
<dt>mig_CW</dt><dd><p>scaled migration rate between the two divergent ecotypes This
is the migration rate from ecotype C to ecotype W.</p>
</dd>
<dt>mig_WC</dt><dd><p>scaled migration rate between the two divergent ecotypes This
is the migration rate from ecotype W to ecotype C.</p>
</dd> </dl>



<h3>Source</h3>

<p>simulations performed
</p>

<hr>
<h2 id='meanExpected_Het'>Compute mean expected heterozygosity within a population</h2><span id='topic+meanExpected_Het'></span>

<h3>Description</h3>

<p>This functions calculates the value of the expected heterozygosity for each
site and then computes the mean of those values in order to obtain the mean
expected heterozygosity within each population.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>meanExpected_Het(Pop_Pi)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="meanExpected_Het_+3A_pop_pi">Pop_Pi</code></td>
<td>
<p>is a matrix or list of allele frequencies. When dealing with a
single locus, this input is a matrix and when dealing with multiple loci it
is a list. Each entry of that list is a matrix representing a different
locus. Each row of that matrix should correspond to a different population
and each column to a different SNP.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>if the input is a single matrix, the output will be a vector where
the first entry is the mean expected heterozygosity of the first population
and the n entry is the mean expected heterozygosity of the nth population.
If the input is a list, the output will also be a list, with each entry
corresponding to a different locus. Each of those entries will be a vector
with the mean expected heterozygosity per population for that locus.
</p>

<hr>
<h2 id='mergepost'>Merge posterior distributions</h2><span id='topic+mergepost'></span>

<h3>Description</h3>

<p>After using the <code><a href="#topic+multipleABC">multipleABC()</a></code> function to perform parameter estimation with
Approximate Bayesian Computation for several targets, this function can be
used to merge the different posterior distributions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mergepost(target, global, post, a = 0.5, wtreg = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mergepost_+3A_target">target</code></td>
<td>
<p>a matrix or a list with target mean sumstat, where each entry
corresponds to a vector of size n (n = number of summary statistics) with
the summary statistics of each subset of loci.</p>
</td></tr>
<tr><td><code id="mergepost_+3A_global">global</code></td>
<td>
<p>numeric vector of size n with mean summary statistics across
all loci.</p>
</td></tr>
<tr><td><code id="mergepost_+3A_post">post</code></td>
<td>
<p>list with sample of posterior obtained for each subset of loci.
Each entry of the list is a matrix where each line corresponds to an
accepted simulations (size S) and each column corresponds to a parameter.</p>
</td></tr>
<tr><td><code id="mergepost_+3A_a">a</code></td>
<td>
<p>numeric value with the alpha parameter of the locfit function.</p>
</td></tr>
<tr><td><code id="mergepost_+3A_wtreg">wtreg</code></td>
<td>
<p>(optional) list with the weights of regression method. Each
entry of the list is a numeric vector with weights for each accepted
simulation (size S).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The posterior density will be estimated after simply merging the posteriors
computed from all target subset of loci and after weighting the posterior of
each target by its distance to the overall summary statistic mean. In other
words, each posterior will be weighted according to the distance between the
mean summary statistics of the subset of loci for which that posterior was
computed and the mean across all loci, giving more weight to sets of loci
with a mean closer to the overall mean.
</p>
<p>Additionally, if the regression weights are available, each accepted point
will be weighted by its regression weight and by distance of its associated
target. The combination of these weights will be used to merge the multiple
posteriors. The weighted mean, median, mode and quantiles will be computed
for each of these different posterior merging methods by using the
<code><a href="#topic+weighted_stats">weighted_stats()</a></code> and <code><a href="#topic+mode_locfit">mode_locfit()</a></code> functions. Note that this function
requires the package <span class="pkg">locfit</span>.
</p>


<h3>Value</h3>

<p>list of locfit objects with the density of the posterior for each
parameter and of mean, mode and quantiles obtained using weighted
quantiles. The list has the following elements:
</p>
<table>
<tr><td><code>merge</code></td>
<td>
<p>obtained by simply merging all the posteriors into a single
one and fitting a local regression without any prior weighting.</p>
</td></tr>
<tr><td><code>merged_stat</code></td>
<td>
<p>posterior point estimates for the corresponding merging
method, <code>merge</code>. This includes the median, mean, mode and various quantiles
of the posterior.</p>
</td></tr>
<tr><td><code>weighted</code></td>
<td>
<p>each target was weighted by its distance to the <code>global</code>
summary statistics mean, giving more weight to the target subset of loci
with mean summary statistics closer to the mean across the genome.</p>
</td></tr>
<tr><td><code>weighted_stat</code></td>
<td>
<p>posterior point estimates for the corresponding
merging method, <code>weighted</code>. This includes the median, mean, mode and
various quantiles of the posterior.</p>
</td></tr>
<tr><td><code>merge_reg</code></td>
<td>
<p>each accepted point was weighted by its regression
weight.</p>
</td></tr>
<tr><td><code>merge_reg_stat</code></td>
<td>
<p>posterior point estimates for the corresponding
merging method, <code>merge_reg</code>. This includes the median, mean, mode and
various quantiles of the posterior.</p>
</td></tr>
<tr><td><code>weighted_reg</code></td>
<td>
<p>each target was weighted according to its distance to
the overall mean and each point was weighted by its regression weight.</p>
</td></tr>
<tr><td><code>weighted_reg_stat</code></td>
<td>
<p>posterior point estimates for the corresponding
merging method, <code>weighted_reg</code>. This includes the median, mean, mode and
various quantiles of the posterior.</p>
</td></tr>
</table>
<p>Details about the output can be found at:
<a href="https://aakinshin.net/posts/weighted-quantiles/">https://aakinshin.net/posts/weighted-quantiles/</a> and
<a href="https://www.rdocumentation.org/packages/reldist/versions/1.6-6/topics/wtd.quantile">https://www.rdocumentation.org/packages/reldist/versions/1.6-6/topics/wtd.quantile</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load the matrix with parameter values
data(params)
# load the matrix with simulated parameter values
data(sumstats)
# load the matrix with the prior limits
data(limits)

# select some random simulations to act as target just to test the function
targets &lt;- sumstats[c(11:20) ,]
# we should remove those random simulation from the sumstats and params matrices
sumstats &lt;- sumstats[-c(11:20), ]; params &lt;- params[-c(11:20), ]

# parameter estimation for multiple targets
myabc &lt;- multipleABC(targets = targets, params = params, sumstats = sumstats, limits = limits,
tol = 0.01, method = "regression")

# select a random simulation to act as the global value of the summary statistics
# ideally this should be computed from the entirety of the observed data
global &lt;- sumstats[50, ]

# merge the posterior distributions obtained in the previous step
mergepost(target = targets, global = global, post = myabc$adjusted, wtreg = myabc$weights)

</code></pre>

<hr>
<h2 id='mode_locfit'>Compute mode of a locfit object</h2><span id='topic+mode_locfit'></span>

<h3>Description</h3>

<p>This function computes and outputs the the mode of a locfit object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mode_locfit(locx, xlim, precision = 1000)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mode_locfit_+3A_locx">locx</code></td>
<td>
<p>is a locfit object.</p>
</td></tr>
<tr><td><code id="mode_locfit_+3A_xlim">xlim</code></td>
<td>
<p>is a vector with two entries.The first entry is the minimum of
the distribution and the second entry is the maximum value of the
distribution.</p>
</td></tr>
<tr><td><code id="mode_locfit_+3A_precision">precision</code></td>
<td>
<p>value indicating the number of entries evaluated. The larger
the value the higher the precision. The default value is 1000.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code><a href="stats.html#topic+predict">stats::predict()</a></code> function is used to predict the y-axis values of the
locfit object and the mode is defined as the value where that prediction is
maximized.
</p>


<h3>Value</h3>

<p>a numeric value of the mode of the input locfit object.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># create a random distribution
x &lt;- rnorm(n = 1000, mean = 2, sd = 25)

# perform a local regression
loc &lt;- locfit::locfit(~x)

# compute the mode of the locfit object
mode_locfit(locx = loc, xlim = c(min(x), max(x)))

</code></pre>

<hr>
<h2 id='modelSelect'>Perform model selection with Approximate Bayesian Computation</h2><span id='topic+modelSelect'></span>

<h3>Description</h3>

<p>Estimates posterior model probabilities using Approximate Bayesian
Computation (ABC).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>modelSelect(target, index, sumstats, tol, method, warning = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="modelSelect_+3A_target">target</code></td>
<td>
<p>is a vector with the target summary statistics. These are
usually computed from observed data.</p>
</td></tr>
<tr><td><code id="modelSelect_+3A_index">index</code></td>
<td>
<p>is a vector of model indices. This can be a a character vector
of model names, repeated as many times as there are simulations for each
model. This vector will be coerced to factor and it must have the same
length as <code>nrow(sumstats)</code> to indicate which row of the <code>sumstats</code>
matrix belongs to which model.</p>
</td></tr>
<tr><td><code id="modelSelect_+3A_sumstats">sumstats</code></td>
<td>
<p>is a vector or matrix containing the simulated summary
statistics for all the models. Each row or vector entry should be a
different simulation and each column of a matrix should be a different
statistic. The order must be the same as the order of the models in the
<code>index</code> vector.</p>
</td></tr>
<tr><td><code id="modelSelect_+3A_tol">tol</code></td>
<td>
<p>is a numerical value, indicating the required proportion of points
nearest the target values (tolerance).</p>
</td></tr>
<tr><td><code id="modelSelect_+3A_method">method</code></td>
<td>
<p>a character string, either &quot;rejection&quot; or &quot;regression&quot;,
indicating which algorithm should be used for model selection.</p>
</td></tr>
<tr><td><code id="modelSelect_+3A_warning">warning</code></td>
<td>
<p>logical, if TRUE (default) warnings produced while running
this function, mainly related with accepting simulations for just one of
the models, will be displayed.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Prior to using this function, simulations must have been performed under, at
least, two different models. When <code>method</code> is &quot;rejection&quot;, the posterior
posterior probability of a given model is approximated by the proportion of
accepted simulations of that particular model. Note that this approximation
is only valid if all models where, a priori, equally likely and if the number
of simulations performed is the same for all models. When the <code>method</code> is set
to &quot;regression&quot;, a multinomial logistic regression is used to estimate the
posterior model probabilities. This multinomial regression is implemented in
the <a href="nnet.html#topic+multinom">multinom</a> function.
</p>


<h3>Value</h3>

<p>a list with the following elements:
</p>
<table>
<tr><td><code>method</code></td>
<td>
<p>the method used for model selection.</p>
</td></tr>
<tr><td><code>indices</code></td>
<td>
<p>a vector of model indices in the accepted region. In other
words, this vector contains the name of the accepted model for each
accepted point.</p>
</td></tr>
<tr><td><code>pred</code></td>
<td>
<p>a vector of model probabilities.</p>
</td></tr>
<tr><td><code>ss</code></td>
<td>
<p>the summary statistics in the accepted region.</p>
</td></tr>
<tr><td><code>weights</code></td>
<td>
<p>vector of regression weights when method is regression.</p>
</td></tr>
<tr><td><code>nmodels</code></td>
<td>
<p>the number of a priori simulations performed for each
model.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'># load the matrix with simulated parameter values
data(sumstats)

# select a random simulation to act as target just to test the function
target &lt;- sumstats[10 ,]

# create a "fake" vector of model indices
# this assumes that half the simulations were from one model and the other half from other model
# this is not true but serves as an example of how to use this function
index &lt;- c(rep("model1", nrow(sumstats)/2), rep("model2", nrow(sumstats)/2))

# perform model selection with ABC
modelSelect(target = target, index = index, sumstats = sumstats, tol = 0.01, method = "regression")

</code></pre>

<hr>
<h2 id='multipleABC'>Parameter estimation with Approximate Bayesian Computation for multiple
targets</h2><span id='topic+multipleABC'></span>

<h3>Description</h3>

<p>Perform multivariate parameter estimation based on summary statistics using
an Approximate Bayesian Computation (ABC) algorithm. This function always
uses a rejection sampling algorithm while a local linear regression algorithm
might or might not be used.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>multipleABC(
  targets,
  params,
  sumstats,
  limits,
  tol,
  method,
  parallel = FALSE,
  ncores = NA
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="multipleABC_+3A_targets">targets</code></td>
<td>
<p>a matrix of observed summary statistics. Each row will be
considered a different target for parameter estimation. Each column should
be a different summary statistics and these statistics should correspond to
the statistics in the <code>sumstats</code> input.</p>
</td></tr>
<tr><td><code id="multipleABC_+3A_params">params</code></td>
<td>
<p>is a vector or matrix of simulated parameter values i.e.
numbers from the simulations. Each row or vector entry should be a
different simulation and each column of a matrix should be a different
parameter. This is the dependent variable for the regression, if a
regression step is performed.</p>
</td></tr>
<tr><td><code id="multipleABC_+3A_sumstats">sumstats</code></td>
<td>
<p>is a vector or matrix of simulated summary statistics. Each
row or vector entry should be a different simulation and each column of a
matrix should be a different statistic. These act as the independent
variables if a regression step is performed.</p>
</td></tr>
<tr><td><code id="multipleABC_+3A_limits">limits</code></td>
<td>
<p>is a matrix with two columns and as many rows as there are
parameters. Each row should contain the minimum value of the prior for a
given parameter in the first column and the maximum value in the second
column.</p>
</td></tr>
<tr><td><code id="multipleABC_+3A_tol">tol</code></td>
<td>
<p>is the tolerance rate, indicating the required proportion of
points accepted nearest the target values.</p>
</td></tr>
<tr><td><code id="multipleABC_+3A_method">method</code></td>
<td>
<p>either &quot;rejection&quot; or &quot;regression&quot; indicating whether a
regression step should be performed during ABC parameter estimation.</p>
</td></tr>
<tr><td><code id="multipleABC_+3A_parallel">parallel</code></td>
<td>
<p>logical, indicating whether this function should be run using
parallel execution. The default setting is FALSE, meaning that this
function will utilize a single core.</p>
</td></tr>
<tr><td><code id="multipleABC_+3A_ncores">ncores</code></td>
<td>
<p>a non-negative integer that is required when <code>parallel</code> is
TRUE. It specifies the number of cores to use for parallel execution.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>To use this function, the usual steps of ABC parameter estimation have to be
performed. Briefly, data should have been simulated based on random draws
from the prior distributions of the parameters of interest and a set of
summary statistics should have been calculated from that data. The same set
of summary statistics should have been calculated from the observed data to
be used as the <code>targets</code> in this function. Parameter values are accepted if
the Euclidean distance between the set of summary statistics computed from
the simulated data and the set of summary statistics computed from the
observed data is sufficiently small. The percentage of accepted simulations
is determined by <code>tol</code>. This function performs a simple rejection by calling
the <code><a href="#topic+rejABC">rejABC()</a></code> function.
</p>
<p>When <code>method</code> is &quot;regression&quot;, a local linear regression method is used to
correct for the imperfect match between the summary statistics computed from
the simulated data and the summary statistics computed from the observed
data. The output of the <code><a href="#topic+rejABC">rejABC()</a></code> function is used as the input of the
<code><a href="#topic+regABC">regABC()</a></code> function to apply this correction. The parameter values accepted
in the rejection step are weighted by a smooth function (kernel) of the
distance between the simulated and observed summary statistics and corrected
according to a linear transformation.
</p>
<p>Please note that this functions performs parameter estimation for multiple
<code>targets</code>. The <code>targets</code> should contain multiple rows and each row will be
treated as an independent target for parameter estimation.
</p>


<h3>Value</h3>

<p>the returned object is a list containing the following components:
</p>
<table>
<tr><td><code>target</code></td>
<td>
<p>parameter estimates obtained with the rejection sampling.</p>
</td></tr>
<tr><td><code>ss</code></td>
<td>
<p>set of accepted summary statistics from the simulations.</p>
</td></tr>
<tr><td><code>unadjusted</code></td>
<td>
<p>parameter estimates obtained with the rejection
sampling.</p>
</td></tr>
<tr><td><code>adjusted</code></td>
<td>
<p>regression adjusted parameter values.</p>
</td></tr>
<tr><td><code>predmean</code></td>
<td>
<p>estimates of the posterior mean for each parameter.</p>
</td></tr>
<tr><td><code>weights</code></td>
<td>
<p>regression weights.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'># load the matrix with parameter values
data(params)
# load the matrix with simulated parameter values
data(sumstats)
# load the matrix with the prior limits
data(limits)

# select some random simulations to act as target just to test the function
targets &lt;- sumstats[c(11:20) ,]
# we should remove those random simulation from the sumstats and params matrices
sumstats &lt;- sumstats[-c(11:20), ]; params &lt;- params[-c(11:20), ]

# parameter estimation for multiple targets
multipleABC(targets = targets, params = params, sumstats = sumstats, limits = limits,
tol = 0.01, method = "regression")

</code></pre>

<hr>
<h2 id='myparams'>Matrix of simulated parameter values</h2><span id='topic+myparams'></span>

<h3>Description</h3>

<p>This data set contains a matrix of simulated parameter values.
These parameter values were sampled from prior distributions and used to
perform simulations under a isolation with migration model with two
populations. Each row of this matrix corresponds to a different simulation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>myparams
</code></pre>


<h3>Format</h3>

<p>a matrix with 5000 rows and 8 columns:
</p>

<dl>
<dt>N1</dt><dd><p>relative size of the first population. This population
corresponds to the C ecotype.</p>
</dd>
<dt>N2</dt><dd><p>relative size of the second population. This population
corresponds to the W ecotype.</p>
</dd>
<dt>Split</dt><dd><p>time, in 4Nref scale, of the split event that creates the two
populations.</p>
</dd>
<dt>PoolError</dt><dd><p>error associated with DNA pooling.</p>
</dd>
<dt>SeqError</dt><dd><p>error associated with DNA sequencing.</p>
</dd>
<dt>mCW</dt><dd><p>migration rate between the two divergent ecotypes This
is the migration rate from ecotype C to ecotype W.</p>
</dd>
<dt>mWC</dt><dd><p>migration rate between the two divergent ecotypes This
is the migration rate from ecotype W to ecotype C.</p>
</dd>
<dt>pM</dt><dd><p>proportion of the genome with no barriers against gene flow. This
is the proportion of simulated loci where migration occurs in both
directions between the divergent ecotypes.</p>
</dd> </dl>



<h3>Source</h3>

<p>simulations performed
</p>

<hr>
<h2 id='normalise'>Normalize data - adjust values measured on different scales</h2><span id='topic+normalise'></span>

<h3>Description</h3>

<p>Adjusts values that are measured over different scales.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>normalise(x, y)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="normalise_+3A_x">x</code></td>
<td>
<p>is a numeric vector.</p>
</td></tr>
<tr><td><code id="normalise_+3A_y">y</code></td>
<td>
<p>is a numeric vector.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is used to scale the summary statistics and the target for ABC
inference. This scaling ensures that the different summary statistics are all
in the same scale when performing model selection or parameter inference.
</p>


<h3>Value</h3>

<p>a numeric vector with the same length as <code>x</code>.
</p>

<hr>
<h2 id='organize.poststat'>Organize point estimates from multiple posterior distributions</h2><span id='topic+organize.poststat'></span>

<h3>Description</h3>

<p>Combines the point estimates of multiple posterior distributions into more
easily read matrices.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>organize.poststat(posterior_stats)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="organize.poststat_+3A_posterior_stats">posterior_stats</code></td>
<td>
<p>is a list where each entry corresponds to a different
trial i.e. each entry contains the information obtained for a different
target for ABC parameter estimation. Each entry should be a matrix
containing, in each row, the &quot;mode&quot;, &quot;median&quot; and &quot;mean&quot; of the posterior
distribution for each of the parameters.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is a purely organizational function that combines the mode, median and
mean point estimates of multiple posterior distributions into its own matrix.
Thus, each point estimate will have its own unique matrix. For instance, this
will create a &quot;median&quot; matrix with the median of each posterior.
</p>


<h3>Value</h3>

<p>a list with the following elements:
</p>
<table>
<tr><td><code>mode</code></td>
<td>
<p>mode of the posterior for each target and parameter.</p>
</td></tr>
<tr><td><code>median</code></td>
<td>
<p>median of the posterior for each target and parameter.</p>
</td></tr>
<tr><td><code>mean</code></td>
<td>
<p>mean of the posterior for each target and parameter.</p>
</td></tr>
</table>

<hr>
<h2 id='organizeSCRM'>Organize scrm output</h2><span id='topic+organizeSCRM'></span>

<h3>Description</h3>

<p>This function is utilized to sort out the scrm output. The order of the
populations changes accordingly to the model used (i.e. single or parallel
origin). Running this function will re-organize the output produced by scrm,
so that the populations are in the same order in both models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>organizeSCRM(seg_sites, nHap, nPops)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="organizeSCRM_+3A_seg_sites">seg_sites</code></td>
<td>
<p>a matrix of segregating sites as produced by scrm. Each
column of the matrix is a different site and each row is a different
haplotype.</p>
</td></tr>
<tr><td><code id="organizeSCRM_+3A_nhap">nHap</code></td>
<td>
<p>an integer representing the total number of haplotypes simulated.</p>
</td></tr>
<tr><td><code id="organizeSCRM_+3A_npops">nPops</code></td>
<td>
<p>an integer, representing the total number of populations of the
simulated model.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a matrix of segregating sites, similar to <code>seg_sites</code> but with the
populations organized so that the order is always the same, regardless of
the model used.
</p>

<hr>
<h2 id='pairFST'>Pairwise FST among populations</h2><span id='topic+pairFST'></span>

<h3>Description</h3>

<p>This functions calculates pairwise FST values according to Hudson's estimator
following Bathia. FST values are calculated for each pairwise combination of
the populations present in the data (defined by the <code>nPops</code> parameter).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pairFST(nPops, Pop_pi, coverage)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pairFST_+3A_npops">nPops</code></td>
<td>
<p>is an integer indicating how many populations are present in the
data.</p>
</td></tr>
<tr><td><code id="pairFST_+3A_pop_pi">Pop_pi</code></td>
<td>
<p>is a matrix of allele frequencies. Each row of that matrix
should correspond to a different population and each column to a different
site.</p>
</td></tr>
<tr><td><code id="pairFST_+3A_coverage">coverage</code></td>
<td>
<p>is a matrix containing depths of coverage. Each row of that
matrix should correspond to a different population and each column to a
different site.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This functions performs pairwise comparisons of multiple populations and thus
returns multiple FST values, one for each comparison. However, this function
computes FST for a single locus.
</p>


<h3>Value</h3>

<p>a upper triangular matrix with the pairwise FST values between each
population.
</p>

<hr>
<h2 id='params'>Matrix of simulated parameter values</h2><span id='topic+params'></span>

<h3>Description</h3>

<p>This data set contains a matrix of simulated parameter values.
These parameter values were sampled from prior distributions and used to
perform simulations under a isolation with migration model with two
populations. Each row of this matrix corresponds to a different simulation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>params
</code></pre>


<h3>Format</h3>

<p>a matrix with 10000 rows and 8 columns:
</p>

<dl>
<dt>N1</dt><dd><p>relative size of the first population. This population
corresponds to the C ecotype.</p>
</dd>
<dt>N2</dt><dd><p>relative size of the second population. This population
corresponds to the W ecotype.</p>
</dd>
<dt>Split</dt><dd><p>time, in 4Nref scale, of the split event that creates the two
populations.</p>
</dd>
<dt>PoolError</dt><dd><p>error associated with DNA pooling.</p>
</dd>
<dt>SeqError</dt><dd><p>error associated with DNA sequencing.</p>
</dd>
<dt>pM</dt><dd><p>proportion of the genome with no barriers against gene flow. This
is the proportion of simulated loci where migration occurs in both
directions between the divergent ecotypes.</p>
</dd>
<dt>mig_CW</dt><dd><p>scaled migration rate between the two divergent ecotypes This
is the migration rate from ecotype C to ecotype W.</p>
</dd>
<dt>mig_WC</dt><dd><p>scaled migration rate between the two divergent ecotypes This
is the migration rate from ecotype W to ecotype C.</p>
</dd> </dl>



<h3>Source</h3>

<p>simulations performed
</p>

<hr>
<h2 id='pickWindows'>Randomly select blocks of a given size from several contigs</h2><span id='topic+pickWindows'></span>

<h3>Description</h3>

<p>Selects one random block of a smaller size from multiple larger contigs and
obtain the index of the SNPs that are contained within that block.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pickWindows(freqs, positions, range, rMajor, rMinor, coverage, window, nLoci)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pickWindows_+3A_freqs">freqs</code></td>
<td>
<p>is a list containing the allelic frequencies. Each entry of that
list should represent a different contig and be a matrix where each row
corresponds to a different site and each column to a different population.</p>
</td></tr>
<tr><td><code id="pickWindows_+3A_positions">positions</code></td>
<td>
<p>is a list containing the position of the SNPs. Each entry
should represent a different contig and be a vector containing the position
of each SNP present in the contig.</p>
</td></tr>
<tr><td><code id="pickWindows_+3A_range">range</code></td>
<td>
<p>is a list containing the range of the contig. Each entry should
represent a different contig and be a vector with two entries: the first
detailing the minimum position of the contig and the second the maximum
position of the contig.</p>
</td></tr>
<tr><td><code id="pickWindows_+3A_rmajor">rMajor</code></td>
<td>
<p>is a list containing the number of major allele reads. Each
entry of that list should represent a different contig and be a matrix
where each row corresponds to a different site and each column to a
different population.</p>
</td></tr>
<tr><td><code id="pickWindows_+3A_rminor">rMinor</code></td>
<td>
<p>is a list containing the number of minor allele reads. Each
entry of that list should represent a different contig and be a matrix
where each row corresponds to a different site and each column to a
different population.</p>
</td></tr>
<tr><td><code id="pickWindows_+3A_coverage">coverage</code></td>
<td>
<p>is a list containing the depth of coverage. Each entry should
represent a different contig and be a matrix with the sites as rows and the
different populations as columns.</p>
</td></tr>
<tr><td><code id="pickWindows_+3A_window">window</code></td>
<td>
<p>is a non-negative integer indicating the size, in base pairs,
of the block of the contig to keep.</p>
</td></tr>
<tr><td><code id="pickWindows_+3A_nloci">nLoci</code></td>
<td>
<p>is a non-negative integer indicating how many different contigs
should be kept in the output. If each randomly selected <code>window</code> is a
different loci, then how many different <code>window</code> should be selected?</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function starts by removing the edges of the contigs. The size of the
removed portion is equal to the size of the block to keep. Then, a SNP is
randomly pick from the vector of all possible SNP positions. An initial block
is constructed by selecting all SNPs contained in a window of <code>window</code>
size, both upstream and downstream from that SNP. Finally, SNPs are removed
from both ends of that initial block until all remaining SNPs are contained
within a block of <code>window</code> size. All of these steps are performed for
each of the contigs present in the dataset, obtaining one window per contig.
Note that, in the end, only <code>nLoci</code> windows are kept.
</p>


<h3>Value</h3>

<p>a list with the following elements:
</p>
<table>
<tr><td><code>freqs</code></td>
<td>
<p>a list with the allele frequencies, computed by dividing the
number of minor-allele reads by the total coverage. Each entry of this list
corresponds to a different contig. Each entry is a matrix where each row is
a different site and each column is a different population.</p>
</td></tr>
<tr><td><code>positions</code></td>
<td>
<p>a list with the positions of each SNP. Each entry of this
list is a vector corresponding to a different contig.</p>
</td></tr>
<tr><td><code>rMajor</code></td>
<td>
<p>a list with the number of major-allele reads. Each entry of
this list corresponds to a different contig. Each entry is a matrix where
each row is a different site and each column is a different population.</p>
</td></tr>
<tr><td><code>rMinor</code></td>
<td>
<p>a list with the number of minor-allele reads. Each entry of
this list corresponds to a different contig. Each entry is a matrix where
each row is a different site and each column is a different population.</p>
</td></tr>
<tr><td><code>coverage</code></td>
<td>
<p>a list with the total coverage. Each entry of this list
corresponds to a different contig. Each entry is a matrix where each row is
a different site and each column is a different population.</p>
</td></tr>
</table>

<hr>
<h2 id='plot_error'>Prediction error plots for ABC</h2><span id='topic+plot_error'></span>

<h3>Description</h3>

<p>Plots the prediction error computed from a leave-one-out cross validation for
ABC parameter inference.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot_error(
  true,
  estimated,
  transformation = "none",
  param.name = NULL,
  main = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot_error_+3A_true">true</code></td>
<td>
<p>is a numeric vector containing the true parameter values.</p>
</td></tr>
<tr><td><code id="plot_error_+3A_estimated">estimated</code></td>
<td>
<p>a numeric vector containing the estimated parameter values.</p>
</td></tr>
<tr><td><code id="plot_error_+3A_transformation">transformation</code></td>
<td>
<p>default is none. It can also be 'log' if you wish to
transform both the true and estimated values using a log10 scale.</p>
</td></tr>
<tr><td><code id="plot_error_+3A_param.name">param.name</code></td>
<td>
<p>is an optional character input defining the name of the
parameter you are looking at.</p>
</td></tr>
<tr><td><code id="plot_error_+3A_main">main</code></td>
<td>
<p>is a optional character argument that will be used as the title
for the plot. If this input argument is not included, this function will do
its best to create an appropriate title.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>These plots help in visualizing the quality of the estimation and the effect
of the chosen tolerance level or point estimate statistic.
</p>


<h3>Value</h3>

<p>a plot of the estimated value of the parameter (in the y-axis) versus
the true parameter value (in the x-axis). A line marking the correspondence
between the true and estimated values is also plotted. Thus, the closer the
points are to that line, the lower the prediction error is.
</p>

<hr>
<h2 id='plot_errorABC'>Prediction error plots for ABC using a list</h2><span id='topic+plot_errorABC'></span>

<h3>Description</h3>

<p>Plots the prediction error computed from a leave-one-out cross validation for
ABC parameter inference. This function takes as input a list created when
performing cross validation and allows the user to select which ABC algorithm
and point estimate statistic to plot.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot_errorABC(
  x,
  method,
  statistic,
  index,
  transformation = "none",
  main = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot_errorABC_+3A_x">x</code></td>
<td>
<p>is a list produced by a leave-one-out cross validation of ABC. This
list should contain the prediction errors computed using the rejection
and/or regression algorithm. For each of those methods, the prediction
error obtained using three different point estimates of the posterior
should be included in this list.</p>
</td></tr>
<tr><td><code id="plot_errorABC_+3A_method">method</code></td>
<td>
<p>a character that can be either 'rej' or 'reg' indicating
whether you wish to plot the prediction error computed with a rejection or
regression based ABC algorithm.</p>
</td></tr>
<tr><td><code id="plot_errorABC_+3A_statistic">statistic</code></td>
<td>
<p>a character that can be 'mode', 'median' or 'mean'
indicating if you wish to plot the prediction error obtained using the
mode, median or mean as the point estimate of the posterior.</p>
</td></tr>
<tr><td><code id="plot_errorABC_+3A_index">index</code></td>
<td>
<p>an integer indicating which parameter to look at. It corresponds
to a column on a matrix. So, to plot the first parameter, corresponding to
the first column, select 1. To plot the second parameter, select 2 and so
on.</p>
</td></tr>
<tr><td><code id="plot_errorABC_+3A_transformation">transformation</code></td>
<td>
<p>default is none. It can also be 'log' if you wish to
transform both the true and estimated values using a log10 scale.</p>
</td></tr>
<tr><td><code id="plot_errorABC_+3A_main">main</code></td>
<td>
<p>is an optional character input. It will be used as the title of
the plot. If NULL (default), then a generic title will be used instead.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>These plots help in visualizing the quality of the estimation and the effect
of the chosen tolerance level or point estimate statistic.
</p>


<h3>Value</h3>

<p>a plot of the estimated value of the parameter (in the y-axis) versus
the true parameter value (in the x-axis). A line marking the perfect
correspondence between the true and estimated values is also plotted. Thus,
the closer the points are to that line, the lower the prediction error is.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load the matrix with parameter values
data(params)
# load the matrix with simulated parameter values
data(sumstats)
# load the matrix with the prior limits
data(limits)

# perform a leave-one-out cross validation for ABC
mysim &lt;- simulationABC(params = params, sumstats = sumstats, limits, nval = 10,
tol = 0.1, method = "regression")

# plot the prediction error for a given parameter
plot_errorABC(x = mysim, method = "reg", statistic = "median", index = 1)

</code></pre>

<hr>
<h2 id='plot_msel'>Plot model misclassification</h2><span id='topic+plot_msel'></span>

<h3>Description</h3>

<p>Displays a barplot of the confusion matrix obtained with a leave-one-out
cross validation for model selection.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot_msel(object, color = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot_msel_+3A_object">object</code></td>
<td>
<p>a list created by the <code><a href="#topic+error_modelSel">error_modelSel()</a></code> function, containing
the results of a leave-one-out cross validation for model selection.</p>
</td></tr>
<tr><td><code id="plot_msel_+3A_color">color</code></td>
<td>
<p>logical, if TRUE (default) then a colour version of the barplot
will be produced, if FALSE then a grey scale version will be produced.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The barplot shows the proportion of validation simulations classified to each
of the models. This function can produce either a colour or a grey scale
barplot. If the classification of models is perfect, meaning that the model
probability of each model is one for the correct model, then each bar will
have a single colour representing its corresponding model.
</p>


<h3>Value</h3>

<p>a barplot of the proportion of simulations classified to any of the
models. In other words, a barplot of the confusion matrix.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load the matrix with simulated parameter values
data(sumstats)

# select a random simulation to act as target just to test the function
target &lt;- sumstats[10 ,]

# create a "fake" vector of model indices
# this assumes that half the simulations were from one model and the other half from other model
# this is not true but serves as an example of how to use this function
index &lt;- c(rep("model1", nrow(sumstats)/2), rep("model2", nrow(sumstats)/2))

# perform a leave-one-out cross validation of model selection
mysim &lt;- sim_modelSel(index = index, sumstats = sumstats, nval = 10, tol = 0.1)

# compute the confusion matrix and the mean misclassification probabilities
myerror &lt;- error_modelSel(object = mysim, print = FALSE)

# barplot of model misclassification
plot_msel(object = myerror)

</code></pre>

<hr>
<h2 id='plot_param'>Plot the density estimation of a given parameter</h2><span id='topic+plot_param'></span>

<h3>Description</h3>

<p>Plots the density estimation of a single parameter for quick visualization of
the quality of an ABC analysis.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot_param(prior, posterior, limits, index, weights = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot_param_+3A_prior">prior</code></td>
<td>
<p>is a vector or matrix of simulated parameter values i.e. numbers
from the simulations. Each row or vector entry should be a different
simulation and each column of a matrix should be a different parameter.
This corresponds to the prior distribution and it should contain all the
simulated parameter values.</p>
</td></tr>
<tr><td><code id="plot_param_+3A_posterior">posterior</code></td>
<td>
<p>is either a list or a matrix with samples from the posterior
distributions obtained for each target. If in list format, each entry
should be a matrix where each row corresponds to a different accepted
simulations and each column corresponds to a different parameter.</p>
</td></tr>
<tr><td><code id="plot_param_+3A_limits">limits</code></td>
<td>
<p>is a matrix with two columns and as many rows as there are
parameters. Each row should contain the minimum value of the prior for a
given parameter in the first column and the maximum value in the second
column.</p>
</td></tr>
<tr><td><code id="plot_param_+3A_index">index</code></td>
<td>
<p>is an non-negative integer indicating which parameter to plot.
It corresponds to the desired column of a matrix in the <code>posteriors</code> input.
So, to plot the first parameter, corresponding to the first column in the
<code>posteriors</code> input select 1. To plot the second parameter, select 2 and so
on.</p>
</td></tr>
<tr><td><code id="plot_param_+3A_weights">weights</code></td>
<td>
<p>is an optional list input containing the weights from the
local linear regression method. Each entry of the list should be a numeric
vector with the weights for each accepted simulation.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function can be used for a quick visualization of the posterior
distribution obtained for a single target with the <code><a href="#topic+singleABC">singleABC()</a></code> function.
Alternatively, if parameter estimation was performed with the <code><a href="#topic+multipleABC">multipleABC()</a></code>
function, the multiple posterior distributions, each obtained for a different
target, will be combined into a single matrix and all values will be
considered samples from the same posterior distribution.
</p>


<h3>Value</h3>

<p>a plot of the density estimation of a given parameter. This plot will
include a title with the name of the parameter. It will also include the
density of the prior distribution for that parameter.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load the matrix with parameter values
data(params)
# load the matrix with simulated parameter values
data(sumstats)
# load the matrix with the prior limits
data(limits)

# select a random simulation to act as target just to test the function
target &lt;- sumstats[15 ,]
# we should remove the random simulation from the sumstats and params matrices
sumstats &lt;- sumstats[-15, ]; params &lt;- params[-15, ]

# parameter estimation for a single target
myabc &lt;- singleABC(target = target, params = params, sumstats = sumstats, limits = limits,
tol = 0.01, method = "regression")

# plot the density estimation of a given parameter
plot_param(prior = params, posterior = myabc$adjusted, limits = limits,
index = 6, weights = myabc$weights)

# note that this is just an example!
# we don't have enough simulations to obtain credible results

</code></pre>

<hr>
<h2 id='plot_Posteriors'>Plot multiple posterior distributions</h2><span id='topic+plot_Posteriors'></span>

<h3>Description</h3>

<p>Plots, in the same plot, the density of multiple posterior distributions of a
given parameter.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot_Posteriors(posteriors, index, limits, weights = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot_Posteriors_+3A_posteriors">posteriors</code></td>
<td>
<p>is a list with samples from the posterior distributions
obtained for each target. Each entry of the list is a matrix where each row
corresponds to a different accepted simulations and each column corresponds
to a different parameter.</p>
</td></tr>
<tr><td><code id="plot_Posteriors_+3A_index">index</code></td>
<td>
<p>an non-negative integer indicating which parameter to plot. It
corresponds to the desired column of a matrix in the <code>posteriors</code> input.
So, to plot the first parameter, corresponding to the first column in the
<code>posteriors</code> input select 1. To plot the second parameter, select 2 and so
on.</p>
</td></tr>
<tr><td><code id="plot_Posteriors_+3A_limits">limits</code></td>
<td>
<p>is a matrix with two columns and as many rows as there are
parameters. Each row should contain the minimum value of the prior for a
given parameter in the first column and the maximum value in the second
column.</p>
</td></tr>
<tr><td><code id="plot_Posteriors_+3A_weights">weights</code></td>
<td>
<p>is an optional list input containing the weights from the
local linear regression method. Each entry of the list should be a numeric
vector with the weights for each accepted simulation.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>After using the <code><a href="#topic+multipleABC">multipleABC()</a></code> or <code><a href="#topic+ABC">ABC()</a></code> functions to perform parameter
estimation with Approximate Bayesian Computation with several targets, this
function can be used for a quick visualization of the quality of an ABC
analysis. Multiple posterior distributions, each obtained for a different
target, are plotted in the same plot, allowing for a visualization of the
shape of the posteriors and a quick inspection of whether all the posteriors
converge to the same estimate.
</p>


<h3>Value</h3>

<p>a plot with multiple posterior distributions, each obtained for a
different target, for the selected parameter.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load the matrix with parameter values
data(params)
# load the matrix with simulated parameter values
data(sumstats)
# load the matrix with the prior limits
data(limits)

# select some random simulations to act as target just to test the function
targets &lt;- sumstats[c(11:20) ,]
# we should remove those random simulation from the sumstats and params matrices
sumstats &lt;- sumstats[-c(11:20), ]; params &lt;- params[-c(11:20), ]

# parameter estimation for a single target
myabc &lt;- multipleABC(targets = targets, params = params, sumstats = sumstats, limits = limits,
tol = 0.01, method = "regression")

# plot multiple posteriors
plot_Posteriors(posteriors = myabc$adjusted, index = 1, limits = limits, weights = myabc$weights)

# note that this is just an example!
# we don't have enough simulations to obtain credible results

</code></pre>

<hr>
<h2 id='plot_stats'>Plot the fit of a summary statistic to the target</h2><span id='topic+plot_stats'></span>

<h3>Description</h3>

<p>Plot the fit of a summary statistic to the target
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot_stats(sumstat, target, accepted, index = NA, colour = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot_stats_+3A_sumstat">sumstat</code></td>
<td>
<p>is a vector or matrix of simulated summary statistics. If this
input is a vector, then each entry should correspond to a different
simulation. If it is a matrix, then each row should be a different
simulation and each column a different statistic. Note that this should be
the entire set of simulated values.</p>
</td></tr>
<tr><td><code id="plot_stats_+3A_target">target</code></td>
<td>
<p>is an integer or a numeric vector containing the target of the
parameter inference. If a single integer, then this should be the target
summary statistic corresponding to the input <code>sumstat</code> vector. If this
input is a vector, then the order of the entries in the vector should be
the same as the order of the columns of the <code>sumstat</code> matrix input. Either
way, this input should contain the value of the summary statistics
calculated from observed data.</p>
</td></tr>
<tr><td><code id="plot_stats_+3A_accepted">accepted</code></td>
<td>
<p>is a vector or matrix of accepted summary statistics. If this
input is a vector, then each entry should correspond to a different
simulation. If it is a matrix, then each row should be a different
simulation and each column a different statistic. Note that this should be
summary statistics of the accepted simulations during parameter inference.</p>
</td></tr>
<tr><td><code id="plot_stats_+3A_index">index</code></td>
<td>
<p>is an optional non-negative integer. This input is only required
when the <code>sumstat</code> and <code>accepted</code> inputs are matrices. In that instance, it
will indicate which summary statistic to plot. It corresponds to the
desired column of the <code>sumstat</code> and <code>accepted</code> matrices and to the entry of
the <code>target</code> vector.</p>
</td></tr>
<tr><td><code id="plot_stats_+3A_colour">colour</code></td>
<td>
<p>logical, indicating whether the plot should be a colour version
(default) or a grayscale plot.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a plot with the fit of the simulated summary statistics to the
observed value. Both the density estimation of the entire simulated summary
statistics and the accepted summary statistics are contrasted with the
observed value.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load the matrix with parameter values
data(params)
# load the matrix with simulated parameter values
data(sumstats)
# load the matrix with the prior limits
data(limits)

# select a random simulation to act as target just to test the function
target &lt;- sumstats[10 ,]
# we should remove the random simulation from the sumstats and params matrices
sumstats &lt;- sumstats[-10, ]; params &lt;- params[-10, ]

# parameter estimation for a single target
myabc &lt;- singleABC(target = target, params = params, sumstats = sumstats,
limits = limits, tol = 0.01, method = "regression")

# check the fit of a summary statistic to the target
plot_stats(sumstat = sumstats, target = target, accepted = myabc$ss, index = 5)

# note that we performed parameter estimation for a single target
# because this function will only work when using a matrix

</code></pre>

<hr>
<h2 id='plot_weighted'>Plot the density estimation of a given parameter</h2><span id='topic+plot_weighted'></span>

<h3>Description</h3>

<p>Plots a locfit object obtained after parameter estimation with Approximate
Bayesian Computation using the <code><a href="#topic+multipleABC">multipleABC()</a></code> function and merging the
multiple posteriors with the <code><a href="#topic+mergepost">mergepost()</a></code> function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot_weighted(
  prior,
  merged_posterior,
  index,
  limits,
  regWeights = TRUE,
  weighted = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot_weighted_+3A_prior">prior</code></td>
<td>
<p>is a vector or matrix of simulated parameter values i.e. numbers
from the simulations. Each row or vector entry should be a different
simulation and each column of a matrix should be a different parameter.
This corresponds to the prior distribution and it should contain all the
simulated parameter values.</p>
</td></tr>
<tr><td><code id="plot_weighted_+3A_merged_posterior">merged_posterior</code></td>
<td>
<p>is a list obtained by the <code><a href="#topic+mergepost">mergepost()</a></code> function. The
output of that function produces a list with the locfit of the various
parameters. This function plots those locfits.</p>
</td></tr>
<tr><td><code id="plot_weighted_+3A_index">index</code></td>
<td>
<p>is an non-negative integer indicating which parameter to plot.
It corresponds to the desired entry of the <code>merged_posterior</code> list. So, to
plot the first parameter, corresponding to the first entry in the
<code>merged_posterior</code> input select 1. To plot the second parameter, select 2
and so on.</p>
</td></tr>
<tr><td><code id="plot_weighted_+3A_limits">limits</code></td>
<td>
<p>is a matrix with two columns and as many rows as there are
parameters. Each row should contain the minimum value of the prior for a
given parameter in the first column and the maximum value in the second
column.</p>
</td></tr>
<tr><td><code id="plot_weighted_+3A_regweights">regWeights</code></td>
<td>
<p>logical, indicating whether to plot the posterior density
obtained from merging the multiple posteriors with or without the weights
of the regression step. The default is TRUE.</p>
</td></tr>
<tr><td><code id="plot_weighted_+3A_weighted">weighted</code></td>
<td>
<p>logical, indicating whether to plot the posterior density
obtained from merging the multiple posteriors with or without weighting by
the overall distance to the global mean. The default is TRUE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code><a href="#topic+mergepost">mergepost()</a></code> function includes different posterior merging methods and
produces locfit objects for each parameter and method. It is possible to
select which parameter to plot, with the <code>index</code> input, and whether to plot
the density estimation after each accepted point was weighted by its
regression weight and by distance of its associated target to the overall
mean of the data. If <code>regWeights</code> is set to FALSE, the density estimation
obtained without considering the regression weights will be plotted. If
<code>weighted</code> is set to FALSE, the density estimation obtained without
considering the distance between the mean summary statistics of the target
and the mean across all loci.
</p>


<h3>Value</h3>

<p>a plot of the density estimation of a given parameter. This plot will
include a title with the name of the parameter. It will also include the
density of the prior distribution for that parameter. The density
estimation shown here is obtained after merging multiple posteriors for
that parameter.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load the matrix with parameter values
data(params)
# load the matrix with simulated parameter values
data(sumstats)
# load the matrix with the prior limits
data(limits)

# select some random simulations to act as target just to test the function
targets &lt;- sumstats[c(11:20) ,]
# we should remove those random simulation from the sumstats and params matrices
sumstats &lt;- sumstats[-c(11:20), ]; params &lt;- params[-c(11:20), ]

# parameter estimation for multiple targets
myabc &lt;- multipleABC(targets = targets, params = params, sumstats = sumstats, limits = limits,
tol = 0.01, method = "regression")

# select a random simulation to act as the global value of the summary statistics
# ideally this should be computed from the entirety of the observed data
global &lt;- sumstats[50, ]

# merge the posterior distributions obtained in the previous step
mymerge &lt;- mergepost(target = targets, global = global, post = myabc$adjusted,
wtreg = myabc$weights)

# plot the merged posterior distribution
plot_weighted(prior = params, merged_posterior = mymerge, index = 7, limits = limits)

# note that this is just an example!
# we don't have enough simulations to obtain credible results

</code></pre>

<hr>
<h2 id='poolSim'>Simulation of Pooled DNA sequencing</h2><span id='topic+poolSim'></span>

<h3>Description</h3>

<p>This is a master function that goes to all the steps required to obtain
summary statistics from pooled sequencing data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>poolSim(
  model,
  nDip,
  nPops,
  size,
  nLoci,
  nSites,
  mutrate,
  mean,
  variance,
  minimum,
  maximum,
  min.minor = NA,
  Nref,
  ratio,
  split,
  pool,
  seq,
  CW = NA,
  WC = NA,
  CC = NA,
  WW = NA,
  ANC = NA,
  bT = NA,
  bCW = NA,
  bWC = NA,
  force = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="poolSim_+3A_model">model</code></td>
<td>
<p>a character, either 2pops&quot;, &quot;Single&quot; or &quot;Parallel&quot; indicating
which model should be simulated.</p>
</td></tr>
<tr><td><code id="poolSim_+3A_ndip">nDip</code></td>
<td>
<p>an integer representing the total number of diploid individuals
to simulate. Note that scrm actually simulates haplotypes, so the number of
simulated haplotypes is double of this. Also note that this is the total
number of diploid individuals and this function will distribute the
individuals equally by the simulated populations.</p>
</td></tr>
<tr><td><code id="poolSim_+3A_npops">nPops</code></td>
<td>
<p>An integer, representing the total number of populations of the
simulated model.</p>
</td></tr>
<tr><td><code id="poolSim_+3A_size">size</code></td>
<td>
<p>a list with one entry per population. Each entry should be a
vector containing the size (in number of diploid individuals) of each pool.
Thus, if a population was sequenced using a single pool, the vector should
contain only one entry. If a population was sequenced using two pools, each
with 10 individuals, this vector should contain two entries and both will
be 10.</p>
</td></tr>
<tr><td><code id="poolSim_+3A_nloci">nLoci</code></td>
<td>
<p>an integer that represents how many independent loci should be
simulated.</p>
</td></tr>
<tr><td><code id="poolSim_+3A_nsites">nSites</code></td>
<td>
<p>is an integer that specifies how many base pairs should scrm
simulate, i.e. how many sites per locus to simulate.</p>
</td></tr>
<tr><td><code id="poolSim_+3A_mutrate">mutrate</code></td>
<td>
<p>an integer representing the mutation rate assumed for the
simulations.</p>
</td></tr>
<tr><td><code id="poolSim_+3A_mean">mean</code></td>
<td>
<p>an integer or a vector defining the mean value of the negative
binomial distribution from which different number of reads are drawn. It
represents the mean coverage across all sites. If a vector is supplied, the
function assumes that each entry of the vector is the mean for a different
population.</p>
</td></tr>
<tr><td><code id="poolSim_+3A_variance">variance</code></td>
<td>
<p>an integer or a vector defining the variance of the negative
binomial distribution from which different number of reads are drawn. It
represents the variance of the total coverage across all sites. If a vector
is supplied, the function assumes that each entry of the vector is the
variance for a different population.</p>
</td></tr>
<tr><td><code id="poolSim_+3A_minimum">minimum</code></td>
<td>
<p>an integer representing the minimum coverage allowed. Sites
where any population has a depth of coverage below this threshold are
removed from the data.</p>
</td></tr>
<tr><td><code id="poolSim_+3A_maximum">maximum</code></td>
<td>
<p>an integer representing the maximum coverage allowed. Sites
where any population has a depth of coverage above this threshold are
removed from the data.</p>
</td></tr>
<tr><td><code id="poolSim_+3A_min.minor">min.minor</code></td>
<td>
<p>is an integer representing the minimum allowed number of
minor-allele reads. Sites that, across all populations, have less
minor-allele reads than this threshold will be removed from the data.</p>
</td></tr>
<tr><td><code id="poolSim_+3A_nref">Nref</code></td>
<td>
<p>is the minimum and maximum value of the uniform distribution for
the effective population size of the reference population (Nref).</p>
</td></tr>
<tr><td><code id="poolSim_+3A_ratio">ratio</code></td>
<td>
<p>is the minimum and maximum value of the distribution from which
the relative size of the present-day and ancestral populations are drawn.
The size of these populations is set as a ratio of the size of the Nref
population. All of these ratios are drawn from a log10 uniform
distribution.</p>
</td></tr>
<tr><td><code id="poolSim_+3A_split">split</code></td>
<td>
<p>is the minimum and maximum values, at the 4Nref scale, of the
uniform distribution from which the values of the times of the split events
are draw. Both the time of the recent split event and the distance between
the two split events are drawn from this distribution.</p>
</td></tr>
<tr><td><code id="poolSim_+3A_pool">pool</code></td>
<td>
<p>is the the minimum and maximum values of the uniform distribution
from which the value of the error associated with DNA pooling is drawn.
More specifically, this value is related with the unequal individual
contribution to the pool. This parameter should be supplied as a decimal
number between zero and one.</p>
</td></tr>
<tr><td><code id="poolSim_+3A_seq">seq</code></td>
<td>
<p>is the minimum and maximum values of the uniform distribution from
which the value of the error associated with DNA sequencing is drawn. This
parameter should be supplied as a decimal number between zero and one.</p>
</td></tr>
<tr><td><code id="poolSim_+3A_cw">CW</code></td>
<td>
<p>is the minimum and maximum value of the uniform distribution from
which the migration rate between the two divergent ecotypes inhabiting the
same location is drawn. We consider that this parameter is drawn on a m
scale. This is the migration rate from ecotype C to ecotype W.</p>
</td></tr>
<tr><td><code id="poolSim_+3A_wc">WC</code></td>
<td>
<p>is the minimum and maximum value of the uniform distribution from
which the migration rate between the two divergent ecotypes inhabiting the
same location is drawn. We consider that this parameter is drawn on a m
scale. This is the migration rate from ecotype W to ecotype C.</p>
</td></tr>
<tr><td><code id="poolSim_+3A_cc">CC</code></td>
<td>
<p>is the minimum and maximum value of the uniform distribution from
which the migration rate between similar ecotypes inhabiting different
locations is drawn. We consider that this parameter is drawn on a m scale.
This is the migration between the two C ecotypes at two different
locations.</p>
</td></tr>
<tr><td><code id="poolSim_+3A_ww">WW</code></td>
<td>
<p>is the minimum and maximum value of the uniform distribution from
which the migration rate between similar ecotypes inhabiting different
locations is drawn. We consider that this parameter is drawn on a m scale.
This is the migration between the two W ecotypes at two different
locations.</p>
</td></tr>
<tr><td><code id="poolSim_+3A_anc">ANC</code></td>
<td>
<p>is the minimum and maximum value of the uniform distribution from
which the migration rate between similar ecotypes inhabiting different
locations is drawn. We consider that this parameter is drawn on a m scale.
This is the migration between the two W ecotypes at two different
locations.</p>
</td></tr>
<tr><td><code id="poolSim_+3A_bt">bT</code></td>
<td>
<p>is the minimum and maximum values of the distribution from which
the proportion of the simulated loci where no migration occurs between
divergent ecotypes is drawn. The maximum value should not be higher than
one.</p>
</td></tr>
<tr><td><code id="poolSim_+3A_bcw">bCW</code></td>
<td>
<p>is the minimum and maximum values of the distribution from which
the proportion of the simulated loci where no migration occurs from the C
ecotype towards the W ecotype is drawn. The maximum value should not be
higher than one.</p>
</td></tr>
<tr><td><code id="poolSim_+3A_bwc">bWC</code></td>
<td>
<p>is the minimum and maximum values of the distribution from which
the proportion of the simulated loci where no migration occurs from the W
ecotype towards the C ecotype is drawn. The maximum value should not be
higher than one.</p>
</td></tr>
<tr><td><code id="poolSim_+3A_force">force</code></td>
<td>
<p>is a logical value indicating whether the required number of
loci should be enforced. The default is FALSE but, if set to TRUE, then
additional loci will be simulated. These additional loci are simulated to
try to have sufficient loci to keep the required number of loci after
filtering.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Starts by creating a vector of parameters, with values drawn from the
respective prior distributions. Then those parameter values are used to
simulate genetic data under a coalescent approach. A series of steps is then
followed to turn that genetic data into pooled sequencing data. Finally, a
set of summary statistics is computed using the simulated pooled sequencing
data.
</p>


<h3>Value</h3>

<p>a list with several named entries. The number of entries depends of
the chosen model.
</p>
<table>
<tr><td><code>Nref</code></td>
<td>
<p>numeric, sampled value from the prior for the effective
population size of the reference population.</p>
</td></tr>
<tr><td><code>N1</code></td>
<td>
<p>numeric, sampled value from the prior for the relative size of
the present-day populations. This is the relative size of the first
population.</p>
</td></tr>
<tr><td><code>N2</code></td>
<td>
<p>numeric, sampled value from the prior for the relative size of
the present-day populations. This is the relative size of the second
population.</p>
</td></tr>
<tr><td><code>N3</code></td>
<td>
<p>numeric, sampled value from the prior for the relative size of
the present-day populations. This is the relative size of the third
population. This entry only exists when the selected model has four
populations.</p>
</td></tr>
<tr><td><code>N4</code></td>
<td>
<p>numeric, sampled value from the prior for the relative size of
the present-day populations. This is the relative size of the fourth
population. This entry only exists when the selected model has four
populations.</p>
</td></tr>
<tr><td><code>NA1</code></td>
<td>
<p>numeric, sampled value from the prior for the relative size of
the ancestral populations. This is the relative size of the ancestral
population of N1 and N2. This entry only exists when the selected model has
four populations.</p>
</td></tr>
<tr><td><code>NA2</code></td>
<td>
<p>numeric, sampled value from the prior for the relative size of
the ancestral populations. This is the relative size of the ancestral
population of N3 and N4. This entry only exists when the selected model has
four populations.</p>
</td></tr>
<tr><td><code>Split</code></td>
<td>
<p>numeric, sampled value from the prior for the time, in 4Nref
scale, of the recent split event.</p>
</td></tr>
<tr><td><code>Dsplit</code></td>
<td>
<p>numeric, sampled value from the prior for the time, in 4Nref
scale, of the distance between the two split events.</p>
</td></tr>
<tr><td><code>PoolError</code></td>
<td>
<p>numeric, sampled value from the prior for the error
associated with DNA pooling.</p>
</td></tr>
<tr><td><code>SeqError</code></td>
<td>
<p>numeric, sampled value from the prior for the error
associated with DNA sequencing.</p>
</td></tr>
<tr><td><code>mCW1</code></td>
<td>
<p>numeric, sampled value from the prior for the migration rate
between the two divergent ecotypes inhabiting the first location. This is
the migration rate from ecotype C to ecotype W. For a two population model,
this entry will be called mCW because that model considers a single
location.</p>
</td></tr>
<tr><td><code>mCW2</code></td>
<td>
<p>numeric, sampled value from the prior for the migration rate
between the two divergent ecotypes inhabiting the second location. This is
the migration rate from ecotype C to ecotype W. For a two population model,
this entry will not exist.</p>
</td></tr>
<tr><td><code>mWC1</code></td>
<td>
<p>numeric, sampled value from the prior for the migration rate
between the two divergent ecotypes inhabiting the first location. This is
the migration rate from ecotype W to ecotype C. For a two population model,
this entry will be called mWC because that model considers a single
location.</p>
</td></tr>
<tr><td><code>mWC2</code></td>
<td>
<p>numeric, sampled value from the prior for the migration rate
between the two divergent ecotypes inhabiting the second location. This is
the migration rate from ecotype W to ecotype C. For a two population model,
this entry will not exist.</p>
</td></tr>
<tr><td><code>mCC</code></td>
<td>
<p>numeric, sampled value from the prior for the migration rate
between similar ecotypes inhabiting different locations. This is the
migration between the two C ecotypes at two different locations. For a two
population model, this entry will not exist.</p>
</td></tr>
<tr><td><code>mWW</code></td>
<td>
<p>numeric, sampled value from the prior for the migration rate
between similar ecotypes inhabiting different locations. This is the
migration between the two W ecotypes at two different locations. For a two
population model, this entry will not exist.</p>
</td></tr>
<tr><td><code>mAA</code></td>
<td>
<p>numeric, sampled value from the prior for the migration rate
between the two ancestral populations. For a two population model, this
entry will not exist.</p>
</td></tr>
<tr><td><code>pM</code></td>
<td>
<p>numeric, sampled value from the prior for the proportion of the
genome with no barriers against gene flow. This is the proportion of
simulated loci where migration occurs in both directions between the
divergent ecotypes.</p>
</td></tr>
<tr><td><code>pCW</code></td>
<td>
<p>numeric, sampled value from the prior for the proportion of the
genome where no migration occurs from the C ecotype towards the W ecotype.
This is the proportion of simulated loci where migration occurs only from W
towards C. This entry does not exist for the two populations model.</p>
</td></tr>
<tr><td><code>pWC</code></td>
<td>
<p>numeric, sampled value from the prior for the proportion of the
genome where no migration occurs from the W ecotype towards the C ecotype.
This is the proportion of simulated loci where migration occurs only from C
towards W. This entry does not exist for the two populations model.</p>
</td></tr>
<tr><td><code>pNO</code></td>
<td>
<p>numeric, sampled value from the prior for the proportion of the
genome with no gene flow between divergent ecotypes. This is the proportion
of simulated loci where migration does not occur in both directions between
the C and W ecotypes.</p>
</td></tr>
<tr><td><code>nPoly</code></td>
<td>
<p>numeric, mean number of polymorphic sites across all simulated
locus.</p>
</td></tr>
<tr><td><code>nFilter</code></td>
<td>
<p>numeric, mean number of polymorphic sites retained after
filtering across all simulated locus.</p>
</td></tr>
<tr><td><code>nLoci</code></td>
<td>
<p>numeric, total number of loci retained after filtering.
Summary statistics are calculated for these loci.</p>
</td></tr>
<tr><td><code>Sf</code></td>
<td>
<p>numeric, fraction of sites fixed between populations. For the
model with two populations, this is a single value. For the four-population
models, this includes three values: the first is the fraction of fixed
sites between the two populations in the first location, the second value
is between the populations in the second location and the third value is
the overall fraction of fixed sites, obtained by comparing each population
against the other three.</p>
</td></tr>
<tr><td><code>Sx</code></td>
<td>
<p>numeric, fraction of exclusive sites per population. When running
the model with two populations, this entry has two values - one per
population. For the four-population models, there is also one value per
population, followed by a fifth value representing the fraction of sites
that are segregating in only one of the populations.</p>
</td></tr>
<tr><td><code>SS</code></td>
<td>
<p>numeric values representing the fraction of sites shared between
populations. For the model with two populations, this is a single value.
When running one of the four-population models, this entry has three
values. The first is the fraction of shared sites between the two
populations in the first location, the second value is between the
populations in the second location and the third value is the fraction of
shared sites across all four populations.</p>
</td></tr>
<tr><td><code>Mean_Het</code></td>
<td>
<p>numeric, expected heterozygosity within each population.
This entry has two values when using a two populations model and four when
running one of the four-populations model.</p>
</td></tr>
<tr><td><code>SD_Het</code></td>
<td>
<p>numeric, standard deviation of the expected heterozygosity
for each population. This entry has two values when using a two populations
model and four when running one of the four-populations model.</p>
</td></tr>
<tr><td><code>Mean_HetBet</code></td>
<td>
<p>numeric, mean heterozygosity between all pairs of
populations. For the two populations model, this is a single value
representing the heterozygosity between the two populations. For the
four-population models, this entry includes six values. The first value is
the heterozygosity between the first and the second population, the second
value is between the first and the third population, the third value is
between the first and fourth population, the fourth value is between the
second and third populations, the fifth value is between the second and
fourth population and the sixth value is between the third and fourth
populations.</p>
</td></tr>
<tr><td><code>SD_HetBet</code></td>
<td>
<p>numeric, standard deviation of the mean heterozygosity
between all pairs of populations. For the two populations model, this is a
single value representing the standard deviation of heterozygosity between
the two populations. When running one of the four-population models, this
entry includes six values. The order of those entries is the same as for
<code>Mean_HetBet</code>.</p>
</td></tr>
<tr><td><code>Mean_FST</code></td>
<td>
<p>numeric, mean pairwise FST between populations. For the two
populations model, this is a single value representing the mean FST between
the two populations. For the four-population models, this entry includes
six values. The first value is the mean FST between the first and second
populations, the second is between the first and third population, the
third is between the second and third populations, the fourth is between
the first and fourth populations, the fifth value is between the second and
fourth populations and the sixth is between the third and fourth
populations.</p>
</td></tr>
<tr><td><code>SD_FST</code></td>
<td>
<p>numeric, standard deviation of the mean pairwise FST between
populations. For the two populations model, this is a single value
representing the standard deviation of the FST between the two populations.
When running one of the four-population models, this entry includes six
values. The order of those entries is the same as for <code>Mean_FST</code>.</p>
</td></tr>
<tr><td><code>FSTQ1</code></td>
<td>
<p>numeric, it is the 5% quantile of the mean pairwise FST
distribution. For the two populations model, this is a single value
representing the 5% quantile of the FST between the two populations. When
running one of the four-population models, this entry includes six values.
The order of those entries is the same as for <code>Mean_FST</code>.</p>
</td></tr>
<tr><td><code>FSTQ2</code></td>
<td>
<p>numeric, it is the 95% quantile of the mean pairwise FST
distribution. For the two populations model, this is a single value
representing the 95% quantile of the FST between the two populations. For
the four-population models, this entry includes six values. The order of
those entries is the same as for <code>Mean_FST</code>.</p>
</td></tr>
<tr><td><code>Dstat</code></td>
<td>
<p>numeric, value of D-statistic for various combinations of
populations. This entry only exists if a four-population model was
selected. It includes three different values. For the first value, P1 was
the W ecotype in the first location P2 was the W ecotype in the second
location and P3 was the C ecotype at the first location. For the second
value P1 was again the W ecotype in the first location but P2 was the C
ecotype in the second ecotype and P3 was the C ecotype at the first
location. For the third value, P1 was also the W ecotype at the first
location, P2 was the C ecotype at the first location and P3 was the W
ecotype at the second location. For all combinations, P4 was assumed to be
an outgroup fixed, at all sites, for the major allele.</p>
</td></tr>
<tr><td><code>SD_dstat</code></td>
<td>
<p>numeric, standard deviation of D-statistic for various
combinations of populations. This entry only exists if a four-population
model was selected. Each entry is the standard deviation of the
corresponding D-statistic in the <code>Dstat</code> entry.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'># simulate Pool-seq data and compute summary statistics for a model with two populations
poolSim(model="2pops", nDip=400, nPops=2, nLoci=10, nSites=2000, mutrate=1.5e-8,
size=rep(list(rep(5, 20)), 2),mean=c(85, 65), variance=c(1400, 900), minimum=25,
maximum=165, min.minor=2, Nref=c(25000, 25000), ratio=c(0.1, 3), pool=c(5, 250),
seq=c(0.0001, 0.001), split=c(0, 3), CW=c(1e-13, 1e-3), WC=c(1e-13, 1e-3), bT=c(0, 0.5))

# simulate Pool-seq data and compute summary statistics for a model with four populations
poolSim(model="Single", nDip=400, nPops=4, nLoci=10, nSites=2000, mutrate=2e-8,
size=rep(list(rep(5, 20)), 4), mean=c(85, 65, 65, 70), variance=c(1400, 900, 850, 1000),
minimum=25, maximum=165, min.minor=2, Nref=c(25000, 25000), ratio=c(0.1, 3), pool=c(5, 250),
seq=c(0.0001, 0.001), split=c(0, 3), CW=c(1e-13, 1e-3), WC=c(1e-13, 1e-3), CC=c(1e-13, 1e-3),
WW=c(1e-13, 1e-3), ANC=c(1e-13, 1e-3), bT=c(0, 0.2), bCW=c(0, 0.5), bWC=c(0, 0.5))


</code></pre>

<hr>
<h2 id='poolStats'>Compute summary statistics from Pooled DNA sequencing</h2><span id='topic+poolStats'></span>

<h3>Description</h3>

<p>This function combines all the necessary steps to simulate pooled sequencing
data and compute summary statistics from that data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>poolStats(
  parameters,
  model,
  nDip,
  size,
  nLoci,
  nSites,
  mutrate,
  mean,
  variance,
  minimum,
  maximum,
  min.minor = NA,
  force = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="poolStats_+3A_parameters">parameters</code></td>
<td>
<p>a vector of parameters used to create the command line for
the scrm package. Each entry of the vector is a different parameter. Note
that each vector entry should be named with the name of the corresponding
parameter. The output of the <code>CreateParameters</code> function is the intended
input.</p>
</td></tr>
<tr><td><code id="poolStats_+3A_model">model</code></td>
<td>
<p>a character, either 2pops&quot;, &quot;Single&quot; or &quot;Parallel&quot; indicating
which model should be simulated.</p>
</td></tr>
<tr><td><code id="poolStats_+3A_ndip">nDip</code></td>
<td>
<p>an integer representing the total number of diploid individuals
to simulate. Note that scrm actually simulates haplotypes, so the number of
simulated haplotypes is double of this. Also note that this is the total
number of diploid individuals and this function will distribute the
individuals equally by the simulated populations.</p>
</td></tr>
<tr><td><code id="poolStats_+3A_size">size</code></td>
<td>
<p>a list with one entry per population. Each entry should be a
vector containing the size (in number of diploid individuals) of each pool.
Thus, if a population was sequenced using a single pool, the vector should
contain only one entry. If a population was sequenced using two pools, each
with 10 individuals, this vector should contain two entries and both will
be 10.</p>
</td></tr>
<tr><td><code id="poolStats_+3A_nloci">nLoci</code></td>
<td>
<p>an integer that represents how many independent loci should be
simulated.</p>
</td></tr>
<tr><td><code id="poolStats_+3A_nsites">nSites</code></td>
<td>
<p>is an integer that specifies how many base pairs should scrm
simulate, i.e. how many sites per locus to simulate.</p>
</td></tr>
<tr><td><code id="poolStats_+3A_mutrate">mutrate</code></td>
<td>
<p>an integer representing the mutation rate assumed for the
simulations.</p>
</td></tr>
<tr><td><code id="poolStats_+3A_mean">mean</code></td>
<td>
<p>an integer or a vector defining the mean value of the negative
binomial distribution from which different number of reads are drawn. It
represents the mean coverage across all sites. If a vector is supplied, the
function assumes that each entry of the vector is the mean for a different
population.</p>
</td></tr>
<tr><td><code id="poolStats_+3A_variance">variance</code></td>
<td>
<p>an integer or a vector defining the variance of the negative
binomial distribution from which different number of reads are drawn. It
represents the variance of the total coverage across all sites. If a vector
is supplied, the function assumes that each entry of the vector is the
variance for a different population.</p>
</td></tr>
<tr><td><code id="poolStats_+3A_minimum">minimum</code></td>
<td>
<p>an integer representing the minimum coverage allowed. Sites
where any population has a depth of coverage below this threshold are
removed from the data.</p>
</td></tr>
<tr><td><code id="poolStats_+3A_maximum">maximum</code></td>
<td>
<p>an integer representing the maximum coverage allowed. Sites
where any population has a depth of coverage above this threshold are
removed from the data.</p>
</td></tr>
<tr><td><code id="poolStats_+3A_min.minor">min.minor</code></td>
<td>
<p>is an integer representing the minimum allowed number of
minor-allele reads. Sites that, across all populations, have less
minor-allele reads than this threshold will be removed from the data.</p>
</td></tr>
<tr><td><code id="poolStats_+3A_force">force</code></td>
<td>
<p>is a logical value indicating whether the required number of
loci should be enforced. The default is FALSE but, if set to TRUE, then
additional loci will be simulated. These additional loci are simulated to
try to have sufficient loci to keep the required number of loci after
filtering.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The sampled parameter values are incorporated into a command line for the
scrm package. Then, genetic data is simulated according to a model of ecotype
formation and the sampled parameters. Finally, various summary statistics are
calculated from the simulated data.
</p>


<h3>Value</h3>

<p>a list with several named entries. The number of entries depends of
the chosen model.
</p>
<table>
<tr><td><code>nPoly</code></td>
<td>
<p>numeric, mean number of polymorphic sites across all simulated
locus.</p>
</td></tr>
<tr><td><code>nFilter</code></td>
<td>
<p>numeric, mean number of polymorphic sites retained after
filtering across all simulated locus.</p>
</td></tr>
<tr><td><code>nLoci</code></td>
<td>
<p>numeric, total number of loci retained after filtering.
Summary statistics are calculated for these loci.</p>
</td></tr>
<tr><td><code>Sf</code></td>
<td>
<p>numeric, fraction of sites fixed between populations. For the
model with two populations, this is a single value. For the four-population
models, this includes three values: the first is the fraction of fixed
sites between the two populations in the first location, the second value
is between the populations in the second location and the third value is
the overall fraction of fixed sites, obtained by comparing each population
against the other three.</p>
</td></tr>
<tr><td><code>Sx</code></td>
<td>
<p>numeric, fraction of exclusive sites per population. When running
the model with two populations, this entry has two values - one per
population. For the four-population models, there is also one value per
population, followed by a fifth value representing the fraction of sites
that are segregating in only one of the populations.</p>
</td></tr>
<tr><td><code>SS</code></td>
<td>
<p>numeric values representing the fraction of sites shared between
populations. For the model with two populations, this is a single value.
When running one of the four-population models, this entry has three
values. The first is the fraction of shared sites between the two
populations in the first location, the second value is between the
populations in the second location and the third value is the fraction of
shared sites across all four populations.</p>
</td></tr>
<tr><td><code>Mean_Het</code></td>
<td>
<p>numeric, expected heterozygosity within each population.
This entry has two values when using a two populations model and four when
running one of the four-populations model.</p>
</td></tr>
<tr><td><code>SD_Het</code></td>
<td>
<p>numeric, standard deviation of the expected heterozygosity
for each population. This entry has two values when using a two populations
model and four when running one of the four-populations model.</p>
</td></tr>
<tr><td><code>Mean_HetBet</code></td>
<td>
<p>numeric, mean heterozygosity between all pairs of
populations. For the two populations model, this is a single value
representing the heterozygosity between the two populations. For the
four-population models, this entry includes six values. The first value is
the heterozygosity between the first and the second population, the second
value is between the first and the third population, the third value is
between the first and fourth population, the fourth value is between the
second and third populations, the fifth value is between the second and
fourth population and the sixth value is between the third and fourth
populations.</p>
</td></tr>
<tr><td><code>SD_HetBet</code></td>
<td>
<p>numeric, standard deviation of the mean heterozygosity
between all pairs of populations. For the two populations model, this is a
single value representing the standard deviation of heterozygosity between
the two populations. When running one of the four-population models, this
entry includes six values. The order of those entries is the same as for
<code>Mean_HetBet</code>.</p>
</td></tr>
<tr><td><code>Mean_FST</code></td>
<td>
<p>numeric, mean pairwise FST between populations. For the two
populations model, this is a single value representing the mean FST between
the two populations. For the four-population models, this entry includes
six values. The first value is the mean FST between the first and second
populations, the second is between the first and third population, the
third is between the second and third populations, the fourth is between
the first and fourth populations, the fifth value is between the second and
fourth populations and the sixth is between the third and fourth
populations.</p>
</td></tr>
<tr><td><code>SD_FST</code></td>
<td>
<p>numeric, standard deviation of the mean pairwise FST between
populations. For the two populations model, this is a single value
representing the standard deviation of the FST between the two populations.
When running one of the four-population models, this entry includes six
values. The order of those entries is the same as for <code>Mean_FST</code>.</p>
</td></tr>
<tr><td><code>FSTQ1</code></td>
<td>
<p>numeric, it is the 5% quantile of the mean pairwise FST
distribution. For the two populations model, this is a single value
representing the 5% quantile of the FST between the two populations. When
running one of the four-population models, this entry includes six values.
The order of those entries is the same as for <code>Mean_FST</code>.</p>
</td></tr>
<tr><td><code>FSTQ2</code></td>
<td>
<p>numeric, it is the 95% quantile of the mean pairwise FST
distribution. For the two populations model, this is a single value
representing the 95% quantile of the FST between the two populations. For
the four-population models, this entry includes six values. The order of
those entries is the same as for <code>Mean_FST</code>.</p>
</td></tr>
<tr><td><code>Dstat</code></td>
<td>
<p>numeric, value of D-statistic for various combinations of
populations. This entry only exists if a four-population model was
selected. It includes three different values. For the first value, P1 was
the W ecotype in the first location P2 was the W ecotype in the second
location and P3 was the C ecotype at the first location. For the second
value P1 was again the W ecotype in the first location but P2 was the C
ecotype in the second ecotype and P3 was the C ecotype at the first
location. For the third value, P1 was also the W ecotype at the first
location, P2 was the C ecotype at the first location and P3 was the W
ecotype at the second location. For all combinations, P4 was assumed to be
an outgroup fixed, at all sites, for the major allele.</p>
</td></tr>
<tr><td><code>SD_dstat</code></td>
<td>
<p>numeric, standard deviation of D-statistic for various
combinations of populations. This entry only exists if a four-population
model was selected. Each entry is the standard deviation of the
corresponding D-statistic in the <code>Dstat</code> entry.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'># create a vector of parameters for a model with two populations
parameters &lt;- createParams(Nref = c(25000, 25000), ratio = c(0.1, 3), pool = c(5, 250),
seq = c(0.0001, 0.001), split = c(0, 3), CW = c(1e-13, 1e-3), WC = c(1e-13, 1e-3),
bT = c(0, 0.2), model = "2pops")

# simulate a two populations model:
# note that we are using two pools for each population, each with 50 individuals
poolStats(parameters = parameters, model = "2pops", nDip = 200, size = rep(list(rep(50, 2)), 2),
nLoci = 100, nSites = 2000, mutrate = 2e-8, mean = c(100, 80), variance = c(200, 180), minimum = 10,
maximum = 150, min.minor = 1)

</code></pre>

<hr>
<h2 id='popsFST'>Pairwise FST among populations and across multiple loci</h2><span id='topic+popsFST'></span>

<h3>Description</h3>

<p>This functions calculates pairwise FST values according to Hudson's estimator
following Bathia. FST values are calculated for each pairwise combination of
the populations present in the data (defined by the <code>nPops</code> parameter).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>popsFST(nPops, Pop_pi, coverage)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="popsFST_+3A_npops">nPops</code></td>
<td>
<p>is an integer indicating how many populations are present in the
data.</p>
</td></tr>
<tr><td><code id="popsFST_+3A_pop_pi">Pop_pi</code></td>
<td>
<p>is a list of allele frequencies. Each entry of that list is a
matrix representing a different locus. Each row of that matrix should
correspond to a different population and each column to a different site</p>
</td></tr>
<tr><td><code id="popsFST_+3A_coverage">coverage</code></td>
<td>
<p>is a list containing depths of coverage. Each entry of that
list is a matrix representing a different locus. Each row of that matrix
should correspond to a different population and each column to a different
site</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This functions performs pairwise comparisons of multiple populations and thus
returns multiple FST values, one for each comparison. Additionally, this
function computes FST for multiple loci, returning a value for each pairwise
comparison per locus.
</p>


<h3>Value</h3>

<p>a list where each entry corresponds to a different locus. Each of
those entries is a upper triangular matrix with the pairwise FST values
between each population.
</p>

<hr>
<h2 id='poststat'>Calculate point estimates from the posterior distribution</h2><span id='topic+poststat'></span>

<h3>Description</h3>

<p>Given a set of samples from the posterior distribution, computes the mean,
median and mode of the posterior.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>poststat(posterior, limits, method, wtreg = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="poststat_+3A_posterior">posterior</code></td>
<td>
<p>is a matrix or a vector with samples from the posterior
distribution obtained from ABC parameter estimation. If this input is a
matrix, then each row should correspond to an accepted simulation (size S)
and each column to a different parameter.</p>
</td></tr>
<tr><td><code id="poststat_+3A_limits">limits</code></td>
<td>
<p>is a vector if there is only one parameter or a matrix if there
are multiple parameters. In this latter instance, each row should
correspond to a different parameter. In either instance, and considering
matrix rows as vectors, then the first entry of the vector should be the
minimum value of the prior and the second entry should be the maximum value
(for any given parameter).</p>
</td></tr>
<tr><td><code id="poststat_+3A_method">method</code></td>
<td>
<p>either &quot;rejection&quot; or &quot;regression&quot; indicating whether a
rejection sampling algorithm or a local linear regression algorithm were
used during ABC parameter estimation.</p>
</td></tr>
<tr><td><code id="poststat_+3A_wtreg">wtreg</code></td>
<td>
<p>is a required numeric vector if the method is &quot;regression&quot;. It
should contain the weights for each accepted simulation (size S).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If <code>method</code> is &quot;regression&quot;, the regression weights must also be made
available. These will be used to compute the weighted mean, weighted median
and weighted mode of the posterior.
</p>


<h3>Value</h3>

<p>a matrix with the mode, median and mean of the posterior distribution
for each parameter. Each point estimate is a different row and each
parameter a different column.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load the matrix with parameter values
data(params)
# load the matrix with simulated parameter values
data(sumstats)
# load the matrix with the prior limits
data(limits)

# select a random simulation to act as target just to test the function
target &lt;- sumstats[10 ,]
# we should remove the random simulation from the sumstats and params matrices
sumstats &lt;- sumstats[-10, ]; params &lt;- params[-10, ]

# parameter estimation for a single target
myabc &lt;- singleABC(target = target, params = params, sumstats = sumstats,
limits = limits, tol = 0.01, method = "regression")

# compute point estimates from the posterior distribution
poststat(posterior = myabc$adjusted, limits = limits, method = "regression", wtreg = myabc$wt)

</code></pre>

<hr>
<h2 id='prepareData'>Organize information by contig - for multiple data files</h2><span id='topic+prepareData'></span>

<h3>Description</h3>

<p>Organize the information of multiple _rc files into different entries for
each contig.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>prepareData(data, nPops, filter = FALSE, threshold = NA)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="prepareData_+3A_data">data</code></td>
<td>
<p>is a list with four different entries. The entries should be
named as &quot;rMajor&quot;, &quot;rMinor&quot;, &quot;coverage&quot; and &quot;info&quot;. The <code>rMajor</code> entry
should be a matrix containing the number of observed major-allele reads.
The <code>rMinor</code> entry should be a matrix containing the number of
observed minor-allele reads. The <code>coverage</code> entry should be a matrix
containing the total depth of coverage. The <code>info</code> entry should be a
matrix or a data frame containing the remaining relevant information, such
as the contig name and the position of each SNP. Each row of these matrices
should be a different site and each column should be a different
population.</p>
</td></tr>
<tr><td><code id="prepareData_+3A_npops">nPops</code></td>
<td>
<p>is an integer indicating the total number of different
populations in the dataset.</p>
</td></tr>
<tr><td><code id="prepareData_+3A_filter">filter</code></td>
<td>
<p>is a logical switch, either TRUE or FALSE. If TRUE, then the
data is filtered by the frequency of the minor allele and if FALSE, that
filter is not applied.</p>
</td></tr>
<tr><td><code id="prepareData_+3A_threshold">threshold</code></td>
<td>
<p>is the minimum allowed frequency for the minor allele. Sites
where the allelic frequency is below this threshold are removed from the
data.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function removes all monomorphic sites from the dataset. Monomorphic
sites are those where the frequency for all populations is 1 or 0. Then, the
name of each contig is used to organize the information in a per contig
basis. Thus, each output will be organized by contig. For example, the list
with the number of minor-allele reads will contain several entries and each
of those entries is a different contig.
</p>
<p>If the filter input is set to TRUE, this function also filters the data by
the frequency of the minor-allele. If a threshold is supplied, the computed
frequency is compared to that threshold and sites where the frequency is
below the threshold are removed from the dataset. If no threshold is
supplied, the threshold is assumed to be <code>1/total coverage</code>, meaning
that a site should have, at least, one minor-allele read.
</p>


<h3>Value</h3>

<p>a list with six named entries:
</p>
<table>
<tr><td><code>freqs</code></td>
<td>
<p>a list with the allele frequencies, computed by dividing the
number of minor-allele reads by the total coverage. Each entry of this list
corresponds to a different contig. Each entry is a matrix where each row is
a different site and each column is a different population.</p>
</td></tr>
<tr><td><code>positions</code></td>
<td>
<p>a list with the positions of each SNP. Each entry of this
list is a vector corresponding to a different contig.</p>
</td></tr>
<tr><td><code>range</code></td>
<td>
<p>a list with the minimum and maximum SNP position of each
contig. Each entry of this list is a vector corresponding to a different
contig.</p>
</td></tr>
<tr><td><code>rMajor</code></td>
<td>
<p>a list with the number of major-allele reads. Each entry of
this list corresponds to a different contig. Each entry is a matrix where
each row is a different site and each column is a different population.</p>
</td></tr>
<tr><td><code>rMinor</code></td>
<td>
<p>a list with the number of minor-allele reads. Each entry of
this list corresponds to a different contig. Each entry is a matrix where
each row is a different site and each column is a different population.</p>
</td></tr>
<tr><td><code>coverage</code></td>
<td>
<p>a list with the total coverage. Each entry of this list
corresponds to a different contig. Each entry is a matrix where each row is
a different site and each column is a different population.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'># load the data from two rc files
data(rc1, rc2)
# combine both files into a single list
mydata &lt;- list(rc1, rc2)

# clean and organize the data for both files
mydata &lt;- lapply(mydata, function(i) cleanData(file = i, pops = 7:10))

# organize the information by contigs
prepareData(data = mydata, nPops = 4)

</code></pre>

<hr>
<h2 id='prepareFile'>Organize information by contigs - for a single data file</h2><span id='topic+prepareFile'></span>

<h3>Description</h3>

<p>Organize the information of a single _rc file into different entries for each
contig.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>prepareFile(data, nPops, filter = FALSE, threshold = NA)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="prepareFile_+3A_data">data</code></td>
<td>
<p>is a list with four different entries. The entries should be
named as &quot;rMajor&quot;, &quot;rMinor&quot;, &quot;coverage&quot; and &quot;info&quot;. The <code>rMajor</code> entry
should be a matrix containing the number of observed major-allele reads.
The <code>rMinor</code> entry should be a matrix containing the number of
observed minor-allele reads. The <code>coverage</code> entry should be a matrix
containing the total depth of coverage. The <code>info</code> entry should be a
matrix or a data frame containing the remaining relevant information, such
as the contig name and the position of each SNP. Each row of these matrices
should be a different site and each column should be a different
population.</p>
</td></tr>
<tr><td><code id="prepareFile_+3A_npops">nPops</code></td>
<td>
<p>is an integer indicating the total number of different
populations in the dataset.</p>
</td></tr>
<tr><td><code id="prepareFile_+3A_filter">filter</code></td>
<td>
<p>is a logical switch, either TRUE or FALSE. If TRUE, then the
data is filtered by the frequency of the minor allele and if FALSE, that
filter is not applied.</p>
</td></tr>
<tr><td><code id="prepareFile_+3A_threshold">threshold</code></td>
<td>
<p>is the minimum allowed frequency for the minor allele. Sites
where the allelic frequency is below this threshold are removed from the
data.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function removes all monomorphic sites from the dataset. Monomorphic
sites are those where the frequency for all populations is 1 or 0. Then, the
name of each contig is used to organize the information in a per contig
basis. Thus, each output will be organized by contig. For example, the list
with the number of minor-allele reads will contain several entries and each
of those entries is a different contig.
</p>
<p>If the filter input is set to TRUE, this function also filters the data by
the frequency of the minor-allele. If a threshold is supplied, the computed
frequency is compared to that threshold and sites where the frequency is
below the threshold are removed from the dataset. If no threshold is
supplied, the threshold is assumed to be <code>1/total coverage</code>, meaning
that a site should have, at least, one minor-allele read.
</p>


<h3>Value</h3>

<p>a list with six named entries:
</p>
<table>
<tr><td><code>freqs</code></td>
<td>
<p>a list with the allele frequencies, computed by dividing the
number of minor-allele reads by the total coverage. Each entry of this list
corresponds to a different contig. Each entry is a matrix where each row is
a different site and each column is a different population.</p>
</td></tr>
<tr><td><code>positions</code></td>
<td>
<p>a list with the positions of each SNP. Each entry of this
list is a vector corresponding to a different contig.</p>
</td></tr>
<tr><td><code>range</code></td>
<td>
<p>a list with the minimum and maximum SNP position of each
contig. Each entry of this list is a vector corresponding to a different
contig.</p>
</td></tr>
<tr><td><code>rMajor</code></td>
<td>
<p>a list with the number of major-allele reads. Each entry of
this list corresponds to a different contig. Each entry is a matrix where
each row is a different site and each column is a different population.</p>
</td></tr>
<tr><td><code>rMinor</code></td>
<td>
<p>a list with the number of minor-allele reads. Each entry of
this list corresponds to a different contig. Each entry is a matrix where
each row is a different site and each column is a different population.</p>
</td></tr>
<tr><td><code>coverage</code></td>
<td>
<p>a list with the total coverage. Each entry of this list
corresponds to a different contig. Each entry is a matrix where each row is
a different site and each column is a different population.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'># load the data from one rc file
data(rc1)

# clean and organize the data in this single file
mydata &lt;- cleanData(file = rc1, pops = 7:10)

# organize the information by contigs
prepareFile(data = mydata, nPops = 4)

</code></pre>

<hr>
<h2 id='priorsMatrix'>Construct matrix of prior limits</h2><span id='topic+priorsMatrix'></span>

<h3>Description</h3>

<p>Takes as input the minimum and maximum values of the prior distribution for
all relevant parameters and constructs a matrix of prior limits.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>priorsMatrix(model, inputParams)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="priorsMatrix_+3A_model">model</code></td>
<td>
<p>a character, either 2pops&quot;, &quot;Single&quot; or &quot;Parallel&quot; indicating
which model was simulated.</p>
</td></tr>
<tr><td><code id="priorsMatrix_+3A_inputparams">inputParams</code></td>
<td>
<p>A vector containing the minimum and maximum values of the
prior distribution for each parameter in the model. The input of the
<code>CreateParameters</code> function can be converted into a vector and used
here.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The output matrix contains all parameters of a given model and, for each
parameter, it contains the minimum and maximum value of the prior.
</p>


<h3>Value</h3>

<p>a matrix where each row is a different parameter. Note also that each
row is named after the corresponding parameter. For each row, the first
column contains the minimum value of that parameter and the second column
contains the maximum value.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># create a vector of input parameters for a model with two populations
inputs &lt;- c(Nref = c(25000, 25000), ratio = c(0.1, 3), pool = c(5, 250), seq = c(0.0001, 0.001),
split = c(0, 3), CW = c(1e-13, 1e-3), WC = c(1e-13, 1e-3), bT = c(0, 0.2))

# construct a matrix with the limits of the prior distribution
priorsMatrix(model = "2pops", inputParams = inputs)

</code></pre>

<hr>
<h2 id='rc1'>Data frame with an example of observed data</h2><span id='topic+rc1'></span>

<h3>Description</h3>

<p>Data frame with data in the <code style="white-space: pre;">&#8288;_rc&#8288;</code> format for 25 populations Each
row of the data frame is a different site. The first 9 columns contain
general information about the site, while the remaining contain the number
of reads observed at that site for each of the 25 populations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rc1
</code></pre>


<h3>Format</h3>

<p>a data frame with 5000 rows and 59 columns. Each of the columns
corresponds to :
</p>

<dl>
<dt>col1</dt><dd><p>reference chromosome (contig).</p>
</dd>
<dt>col2</dt><dd><p>reference position.</p>
</dd>
<dt>col3</dt><dd><p>reference character.</p>
</dd>
<dt>col4</dt><dd><p>number of alleles found in all populations.</p>
</dd>
<dt>col5</dt><dd><p>allele characters in all populations (sorted by counts in all
populations).</p>
</dd>
<dt>col6</dt><dd><p>sum of deletions in all populations (should be zero, if not the
position may not be reliable).</p>
</dd>
<dt>col7</dt><dd><p>SNP type: <code>[pop, rc, rc|pop]</code>; pop: a SNP within or
between the populations; rc: a SNP between the reference sequence character
and the consensus of at least one populaton; rc|pop: both.</p>
</dd>
<dt>col8</dt><dd><p>most frequent allele in all populations <code>[12345..]</code>.</p>
</dd>
<dt>col9</dt><dd><p>second most frequent allele in all populations
<code>[12345..]</code>.</p>
</dd>
<dt>col10 - col34</dt><dd><p>frequencies of the most frequent allele (major) in the
form &quot;allele-count/coverage.</p>
</dd>
<dt>col35 - col59</dt><dd><p>frequencies of the second most frequent allele (minor)
in the form &quot;allele-count/coverage&quot;.</p>
</dd> </dl>



<h3>Source</h3>

<p>Hern√°n E. Morales et al., Genomic architecture of parallel ecological
divergence: Beyond a single environmental contrast. Sci. Adv.5,
eaav9963(2019). DOI:10.1126/sciadv.aav9963
</p>

<hr>
<h2 id='rc2'>Data frame with an example of observed data</h2><span id='topic+rc2'></span>

<h3>Description</h3>

<p>Data frame with data in the <code style="white-space: pre;">&#8288;_rc&#8288;</code> format for 25 populations Each
row of the data frame is a different site. The first 9 columns contain
general information about the site, while the remaining contain the number
of reads observed at that site for each of the 25 populations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rc2
</code></pre>


<h3>Format</h3>

<p>a data frame with 5000 rows and 59 columns. Each of the columns
corresponds to :
</p>

<dl>
<dt>col1</dt><dd><p>reference chromosome (contig).</p>
</dd>
<dt>col2</dt><dd><p>reference position.</p>
</dd>
<dt>col3</dt><dd><p>reference character.</p>
</dd>
<dt>col4</dt><dd><p>number of alleles found in all populations.</p>
</dd>
<dt>col5</dt><dd><p>allele characters in all populations (sorted by counts in all
populations).</p>
</dd>
<dt>col6</dt><dd><p>sum of deletions in all populations (should be zero, if not the
position may not be reliable).</p>
</dd>
<dt>col7</dt><dd><p>SNP type: <code>[pop, rc, rc|pop]</code>; pop: a SNP within or
between the populations; rc: a SNP between the reference sequence character
and the consensus of at least one populaton; rc|pop: both.</p>
</dd>
<dt>col8</dt><dd><p>most frequent allele in all populations <code>[12345..]</code>.</p>
</dd>
<dt>col9</dt><dd><p>second most frequent allele in all populations
<code>[12345..]</code>.</p>
</dd>
<dt>col10 - col34</dt><dd><p>frequencies of the most frequent allele (major) in the
form &quot;allele-count/coverage.</p>
</dd>
<dt>col35 - col59</dt><dd><p>frequencies of the second most frequent allele (minor)
in the form &quot;allele-count/coverage&quot;.</p>
</dd> </dl>



<h3>Source</h3>

<p>Hern√°n E. Morales et al., Genomic architecture of parallel ecological
divergence: Beyond a single environmental contrast. Sci. Adv.5,
eaav9963(2019). DOI:10.1126/sciadv.aav9963
</p>

<hr>
<h2 id='regABC'>Parameter estimation with Approximate Bayesian Computation using local linear
regression</h2><span id='topic+regABC'></span>

<h3>Description</h3>

<p>This function performs multivariate parameter estimation based on summary
statistics using an Approximate Bayesian Computation (ABC) algorithm. The
algorithm used here is the local linear regression algorithm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>regABC(rej, parameter, tol = 1, simple = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="regABC_+3A_rej">rej</code></td>
<td>
<p>is a list with the results of the rejection sampling algorithm.
The output of the <code><a href="#topic+rejABC">rejABC()</a></code> function is the ideal input here.</p>
</td></tr>
<tr><td><code id="regABC_+3A_parameter">parameter</code></td>
<td>
<p>is a parameter vector (long vector of numbers from the
simulations). Each vector entry should correspond to a different
simulation. This is the dependent variable for the regression.</p>
</td></tr>
<tr><td><code id="regABC_+3A_tol">tol</code></td>
<td>
<p>is the tolerance rate, indicating the required proportion of
points accepted nearest the target values. Note that the default value here
is 1 because all points accepted in the rejection step should be used for
the regression.</p>
</td></tr>
<tr><td><code id="regABC_+3A_simple">simple</code></td>
<td>
<p>logical, if TRUE a simplified output with only the essential
information will be produced. If FALSE (default) the output will contain
more information.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Note that to use this function, the usual steps of ABC parameter estimation
have to be performed. Briefly, data should have been simulated based on
random draws from the prior distributions of the parameters of interest and a
set of summary statistics should have been calculated from that data. The
same set of summary statistics should have been calculated from the observed
data to be used as the target for parameter inference. A previous rejection
sampling step should also have been performed, where parameter values were
accepted if the Euclidean distance between the set of summary statistics
computed from the simulated data and the set of summary statistics computed
from the observed data was sufficiently small. Then, the output of the
rejection step is used as the input for this function and a local linear
regression method is used to correct for the imperfect match between the
summary statistics computed from the simulated data and the summary
statistics computed from the observed data.
</p>
<p>The parameter values accepted in the rejection step are weighted by a smooth
function (kernel) of the distance between the simulated and observed summary
statistics and corrected according to a linear transformation. This function
calls the function <code><a href="stats.html#topic+lm">stats::lm()</a></code> to accomplish this.
</p>


<h3>Value</h3>

<p>a list with the results from the regression correction
</p>
<table>
<tr><td><code>adjusted</code></td>
<td>
<p>regression adjusted parameter values.</p>
</td></tr>
<tr><td><code>unadjusted</code></td>
<td>
<p>parameter estimates obtained with the rejection
sampling.</p>
</td></tr>
<tr><td><code>wt</code></td>
<td>
<p>regression weights.</p>
</td></tr>
<tr><td><code>ss</code></td>
<td>
<p>set of accepted summary statistics from the simulations.</p>
</td></tr>
<tr><td><code>predmean</code></td>
<td>
<p>estimates of the posterior mean for each parameter.</p>
</td></tr>
<tr><td><code>fv</code></td>
<td>
<p>fitted value from the regression.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'># load the matrix with parameter values
data(params)
# load the matrix with simulated parameter values
data(sumstats)

# select a random simulation to act as target just to test the function
target &lt;- sumstats[10 ,]

# parameter estimation using rejection sampling
rej &lt;- rejABC(target = target, params = params, sumstats = sumstats[-10, ],
tol = 0.01, regression = TRUE)

# parameter estimation using local linear regression
# note that you should select a parameter from the unadjusted matrix
regABC(rej = rej, parameter = rej$unadjusted[, 1])

</code></pre>

<hr>
<h2 id='rejABC'>Parameter estimation with Approximate Bayesian Computation using rejection
sampling</h2><span id='topic+rejABC'></span>

<h3>Description</h3>

<p>This function performs multivariate parameter estimation based on summary
statistics using an Approximate Bayesian Computation (ABC) algorithm. The
algorithm used here is the rejection sampling algorithm. The output of this
function can be tailored towards a posterior local linear regression method
correction.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rejABC(target, params, sumstats, tol, regression = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rejABC_+3A_target">target</code></td>
<td>
<p>a vector with the target summary statistics. These are usually
the set of observed summary statistics.</p>
</td></tr>
<tr><td><code id="rejABC_+3A_params">params</code></td>
<td>
<p>is a vector or matrix of simulated parameter values i.e.
numbers from the simulations. Each row or vector entry should be a
different simulation and each column of a matrix should be a different
parameter.</p>
</td></tr>
<tr><td><code id="rejABC_+3A_sumstats">sumstats</code></td>
<td>
<p>is a vector or matrix of simulated summary statistics. Each
row or vector entry should be a different simulation and each column of a
matrix should be a different statistic.</p>
</td></tr>
<tr><td><code id="rejABC_+3A_tol">tol</code></td>
<td>
<p>is the tolerance rate, indicating the required proportion of
points accepted nearest the target values.</p>
</td></tr>
<tr><td><code id="rejABC_+3A_regression">regression</code></td>
<td>
<p>logical, indicating whether the user intends to perform a
local linear regression correction after the rejection step. If set to
FALSE (default) the output of this function will contain just the results
of the rejection step. If set to TRUE, the output will contain more details
required for the regression step.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The rejection sampling algorithm generates random samples from the posterior
distributions of the parameters of interest. Note that to use this function,
the usual steps of ABC parameter estimation have to be performed. Briefly,
data should have been simulated based on random draws from the prior
distributions of the parameters of interest and a set of summary statistics
should have been calculated from that data. The same set of summary
statistics should have been calculated from the observed data to be used as
the <code>target</code> input in this function. Parameter values are accepted if the
Euclidean distance between the set of summary statistics computed from the
simulated data and the set of summary statistics computed from the observed
data is sufficiently small. The percentage of accepted simulations is
determined by <code>tol</code>.
</p>


<h3>Value</h3>

<p>a list with the results of the rejection sampling algorithm. The
elements of the list depend of the logical value of <code>regression</code>.
</p>
<table>
<tr><td><code>s.target</code></td>
<td>
<p>a scaled vector of the observed summary statistics. This
element only exists if regression is TRUE.</p>
</td></tr>
<tr><td><code>unadjusted</code></td>
<td>
<p>parameter estimates obtained with the rejection
sampling.</p>
</td></tr>
<tr><td><code>ss</code></td>
<td>
<p>set of accepted summary statistics from the simulations.</p>
</td></tr>
<tr><td><code>s.sumstat</code></td>
<td>
<p>set of scaled accepted summary statistics from the
simulations. This element only exists if regression is TRUE.</p>
</td></tr>
<tr><td><code>dst</code></td>
<td>
<p>euclidean distances in the region of interest.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'># load the matrix with parameter values
data(params)
# load the matrix with simulated parameter values
data(sumstats)

# select a random simulation to act as target just to test the function
target &lt;- sumstats[10 ,]

# Parameter estimation using rejection sampling
rejABC(target = target, params = params, sumstats = sumstats[-10, ], tol = 0.01)

</code></pre>

<hr>
<h2 id='remove_quantileReads'>Remove sites using quantiles of the depth of coverage</h2><span id='topic+remove_quantileReads'></span>

<h3>Description</h3>

<p>Removes sites that have too many or too few reads from the dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>remove_quantileReads(nPops, data)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="remove_quantileReads_+3A_npops">nPops</code></td>
<td>
<p>is an integer representing the total number of populations in
the dataset.</p>
</td></tr>
<tr><td><code id="remove_quantileReads_+3A_data">data</code></td>
<td>
<p>is a dataset containing information about real populations. This
dataset should have lists with the allelic frequencies, the position of the
SNPs, the range of the contig, the number of major allele reads, the number
of minor allele reads and the depth of coverage.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The 25% and the 75% quantiles of the coverage distribution is computed for
each population in the dataset. Then, the lowest 25% quantile across all
populations is considered the minimum depth of coverage allowed. Similarly,
the highest 75% quantile across all populations is considered the maximum
depth of coverage allowed. The coverage of each population at each site is
compared with those threshold values and any site, where the coverage of at
least one population is below or above that threshold, is completely removed
from the dataset.
</p>


<h3>Value</h3>

<p>a list with the following elements:
</p>
<table>
<tr><td><code>freqs</code></td>
<td>
<p>a list with the allele frequencies, computed by dividing the
number of minor-allele reads by the total coverage. Each entry of this list
corresponds to a different contig. Each entry is a matrix where each row is
a different site and each column is a different population.</p>
</td></tr>
<tr><td><code>positions</code></td>
<td>
<p>a list with the positions of each SNP. Each entry of this
list is a vector corresponding to a different contig.</p>
</td></tr>
<tr><td><code>range</code></td>
<td>
<p>a list with the minimum and maximum SNP position of each
contig. Each entry of this list is a vector corresponding to a different
contig.</p>
</td></tr>
<tr><td><code>rMajor</code></td>
<td>
<p>a list with the number of major-allele reads. Each entry of
this list corresponds to a different contig. Each entry is a matrix where
each row is a different site and each column is a different population.</p>
</td></tr>
<tr><td><code>rMinor</code></td>
<td>
<p>a list with the number of minor-allele reads. Each entry of
this list corresponds to a different contig. Each entry is a matrix where
each row is a different site and each column is a different population.</p>
</td></tr>
<tr><td><code>coverage</code></td>
<td>
<p>a list with the total coverage. Each entry of this list
corresponds to a different contig. Each entry is a matrix where each row is
a different site and each column is a different population.</p>
</td></tr>
</table>
<p>This output is identical to the <code>data</code> input, the only difference being the
removal of sites with too many or too few reads.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load the data from one rc file
data(rc1)

# clean and organize the data in this single file
mydata &lt;- cleanData(file = rc1, pops = 7:10)

# organize the information by contigs
mydata &lt;- prepareFile(data = mydata, nPops = 4)

# remove sites according to the coverage quantile
remove_quantileReads(nPops = 4, data = mydata)

</code></pre>

<hr>
<h2 id='remove_realReads'>Remove sites, according to their coverage, from real data</h2><span id='topic+remove_realReads'></span>

<h3>Description</h3>

<p>Removes sites that have too many or too few reads from the dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>remove_realReads(nPops, data, minimum, maximum)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="remove_realReads_+3A_npops">nPops</code></td>
<td>
<p>is an integer representing the total number of populations in
the dataset.</p>
</td></tr>
<tr><td><code id="remove_realReads_+3A_data">data</code></td>
<td>
<p>is a dataset containing information about real populations. This
dataset should have lists with the allelic frequencies, the position of the
SNPs, the range of the contig, the number of major allele reads, the number
of minor allele reads and the depth of coverage.</p>
</td></tr>
<tr><td><code id="remove_realReads_+3A_minimum">minimum</code></td>
<td>
<p>the minimum depth of coverage allowed i.e. sites where the
depth of coverage of any population is below this threshold are removed.</p>
</td></tr>
<tr><td><code id="remove_realReads_+3A_maximum">maximum</code></td>
<td>
<p>he maximum depth of coverage allowed i.e. sites where the
depth of coverage of any population is above this threshold are removed.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>minimum</code> and <code>maximum</code> inputs define, respectively, the minimum and
maximum allowed coverage for the dataset. The coverage of each population at
each site is compared with those threshold values and any site, where the
coverage of at least one population is below or above the user defined
threshold, is completely removed from the dataset.
</p>


<h3>Value</h3>

<p>a list with the following elements:
</p>
<table>
<tr><td><code>freqs</code></td>
<td>
<p>a list with the allele frequencies, computed by dividing the
number of minor-allele reads by the total coverage. Each entry of this list
corresponds to a different contig. Each entry is a matrix where each row is
a different site and each column is a different population.</p>
</td></tr>
<tr><td><code>positions</code></td>
<td>
<p>a list with the positions of each SNP. Each entry of this
list is a vector corresponding to a different contig.</p>
</td></tr>
<tr><td><code>range</code></td>
<td>
<p>a list with the minimum and maximum SNP position of each
contig. Each entry of this list is a vector corresponding to a different
contig.</p>
</td></tr>
<tr><td><code>rMajor</code></td>
<td>
<p>a list with the number of major-allele reads. Each entry of
this list corresponds to a different contig. Each entry is a matrix where
each row is a different site and each column is a different population.</p>
</td></tr>
<tr><td><code>rMinor</code></td>
<td>
<p>a list with the number of minor-allele reads. Each entry of
this list corresponds to a different contig. Each entry is a matrix where
each row is a different site and each column is a different population.</p>
</td></tr>
<tr><td><code>coverage</code></td>
<td>
<p>a list with the total coverage. Each entry of this list
corresponds to a different contig. Each entry is a matrix where each row is
a different site and each column is a different population.</p>
</td></tr>
</table>
<p>This output is identical to the <code>data</code> input, the only difference being the
removal of sites with too many or too few reads.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load the data from one rc file
data(rc1)

# clean and organize the data in this single file
mydata &lt;- cleanData(file = rc1, pops = 7:10)

# organize the information by contigs
mydata &lt;- prepareFile(data = mydata, nPops = 4)

# remove sites with less than 10 reads or more than 180
remove_realReads(nPops = 4, data = mydata, minimum = 10, maximum = 180)

</code></pre>

<hr>
<h2 id='removeVar'>Remove columns with zero variance</h2><span id='topic+removeVar'></span>

<h3>Description</h3>

<p>Removes summary statistics with zero variance.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>removeVar(observed, sumstats)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="removeVar_+3A_observed">observed</code></td>
<td>
<p>is a matrix of observed summary statistics. Each column
should be a different summary statistic.</p>
</td></tr>
<tr><td><code id="removeVar_+3A_sumstats">sumstats</code></td>
<td>
<p>is a matrix of simulated summary statistics. Each column
should be a different summary statistic and each row a different
simulation.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Checks the variance of the summary statistics in the observed data and
removes summary statistics with zero variance. Those summary statistics are
removed from both the matrix of observed values and the matrix of simulated
values.
</p>


<h3>Value</h3>

<p>a list with two named entries. One entry contains the matrix of
observed summary statistics and the other the simulated summary statistics.
</p>

<hr>
<h2 id='runSCRM'>Run scrm and obtain genotypes</h2><span id='topic+runSCRM'></span>

<h3>Description</h3>

<p>This function will run the scrm package, according to the command line
supplied as input. It will also combine haplotypes into genotypes and
re-organize the output if the simulations were performed under a single
origin scenario. This is to ensure that the output of the four-population
models will always follow the same order: the two divergent ecotypes in the
first location, followed by the two divergent ecotypes in the second
location.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>runSCRM(commands, nDip, nPops, model)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="runSCRM_+3A_commands">commands</code></td>
<td>
<p>A character string containing the commands for the scrm
package. This string can be created using the <code>cmd2pops</code>, the <code>cmdSingle</code>
or the <code>cmdParallel</code> functions.</p>
</td></tr>
<tr><td><code id="runSCRM_+3A_ndip">nDip</code></td>
<td>
<p>An integer representing the total number of diploid individuals
to simulate. Note that scrm actually simulates haplotypes, so the number of
simulated haplotypes is double of this.</p>
</td></tr>
<tr><td><code id="runSCRM_+3A_npops">nPops</code></td>
<td>
<p>An integer that informs of how many populations exist on the
model you are trying to run.</p>
</td></tr>
<tr><td><code id="runSCRM_+3A_model">model</code></td>
<td>
<p>Either &quot;2pops&quot;, &quot;Single&quot; or &quot;Parallel&quot; indicating which model
should be simulated.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list with the simulated genotypes. Each entry is a different locus
and, for each locus, different rows represent different individuals and
each column is a different site.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># create a vector with parameter values for a two populations model
params &lt;- createParams(Nref = c(25000, 25000), ratio = c(0.1, 3), pool = c(5, 250),
seq = c(0.0001, 0.001), split = c(0, 3), CW = c(1e-13, 1e-3), WC = c(1e-13, 1e-3),
bT = c(0, 0.2), model = "2pops")

# create the command line for the scrm package
cmds &lt;- cmd2pops(parameters = params, nSites = 2000, nLoci = 10, nDip = 100, mutrate = 2e-8)

# run SCRM and obtain the genotypes
runSCRM(commands = cmds, nDip = 100, nPops = 2, model = "2pops")

</code></pre>

<hr>
<h2 id='scaled.migration'>Compute scaled migration rates</h2><span id='topic+scaled.migration'></span>

<h3>Description</h3>

<p>Computes and adds scaled migration rates to a matrix of simulated parameter
values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>scaled.migration(parameters, model, Nref = NA)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="scaled.migration_+3A_parameters">parameters</code></td>
<td>
<p>is a matrix of simulated parameter values i.e. numbers from
the simulations. Each row or vector entry should be a different simulation
and each column of a matrix should be a different parameter.</p>
</td></tr>
<tr><td><code id="scaled.migration_+3A_model">model</code></td>
<td>
<p>a character, either 2pops&quot;, &quot;Single&quot; or &quot;Parallel&quot; indicating
which model was simulated.</p>
</td></tr>
<tr><td><code id="scaled.migration_+3A_nref">Nref</code></td>
<td>
<p>a numeric value indicating the effective population size of the
reference population.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Migration rates are scaled according to the size of the population receiving
the migrants and added to a matrix with the simulated parameter values. This
is performed for the three available models and according to the specific
model conformation.
</p>


<h3>Value</h3>

<p>a matrix of simulated parameter values with added columns containing
the scaled migration rates.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># compute scaled migration for a two-population model
scaled.migration(parameters = myparams, model = "2pops", Nref = 10000)

</code></pre>

<hr>
<h2 id='scaledPrior'>Compute scaled migration rate limits</h2><span id='topic+scaledPrior'></span>

<h3>Description</h3>

<p>Computes and adds scaled migration rates to a matrix with the limits of the
prior distributions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>scaledPrior(limits, model, Nref = NA)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="scaledPrior_+3A_limits">limits</code></td>
<td>
<p>is a matrix with two columns and as many rows as there are
parameters. Each row should contain the minimum value of the prior for a
given parameter in the first column and the maximum value in the second
column.</p>
</td></tr>
<tr><td><code id="scaledPrior_+3A_model">model</code></td>
<td>
<p>a character, either 2pops&quot;, &quot;Single&quot; or &quot;Parallel&quot; indicating
which model was simulated.</p>
</td></tr>
<tr><td><code id="scaledPrior_+3A_nref">Nref</code></td>
<td>
<p>a numeric value indicating the effective population size of the
reference population.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Migration rates are scaled according to the size of the population receiving
the migrants and added to a matrix with the prior limits. The minimum and
maximum possible size of the population and of the migration rate are used to
compute the minimum and maximum possible values of the scaled migration
rates. This is performed for the three available models and according to the
specific model conformation.
</p>


<h3>Value</h3>

<p>a matrix where each row is a different parameter. This matrix is
similar to the input argument <code>limits</code> but with added rows containing the
scaled migration rates.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># create a vector of input parameters for a model with two populations
inputs &lt;- c(Nref = c(25000, 25000), ratio = c(0.1, 3), pool = c(5, 250), seq = c(0.0001, 0.001),
split = c(0, 3), CW = c(1e-13, 1e-3), WC = c(1e-13, 1e-3), bT = c(0, 0.2))

# construct a matrix with the limits of the prior distribution
limits &lt;- priorsMatrix(model = "2pops", inputParams = inputs)

# compute and add the prior limits of the scaled migration
scaledPrior(limits = limits, model = "2pops")

</code></pre>

<hr>
<h2 id='shared'>Compute the fraction of sites shared between populations</h2><span id='topic+shared'></span>

<h3>Description</h3>

<p>This function will compute the fraction of sites with a shared polymorphism
between populations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>shared(minor, total, nPops)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="shared_+3A_minor">minor</code></td>
<td>
<p>is a matrix with the number of minor-allele reads. Each row of
the matrix is a different population and each column a different site.</p>
</td></tr>
<tr><td><code id="shared_+3A_total">total</code></td>
<td>
<p>is a matrix with the total coverage. Each row of the matrix is a
different population and each column a different site.</p>
</td></tr>
<tr><td><code id="shared_+3A_npops">nPops</code></td>
<td>
<p>is an integer indicating the total number of populations.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>More precisely, we define shared polymorphisms as sites that are segregating
in both populations. To clarify, we define segregating sites as sites where
the number of minor-allele reads of a given population at a given site are
not equal to zero or to the total coverage of that population. We then check
if those segregating sites are also segregating in the other population.
</p>
<p>For models with two populations, this function compares the two present-day
populations. For models with four populations, this function performs a
pairwise comparison of the populations at each of the locations. For the
models with four populations, we also assess the fraction of sites that are
segregating only in one population and not in the other three.
</p>


<h3>Value</h3>

<p>a numeric vector with a single entry when <code>nPops</code> is equal to 2 or
with three entries when <code>nPops</code> is set to 4.
</p>

<hr>
<h2 id='sim_modelSel'>Leave-one-out cross validation of model selection</h2><span id='topic+sim_modelSel'></span>

<h3>Description</h3>

<p>This function performs a simulation study to assess the quality of model
selection with ABC. This is done by performing a leave-one-out cross
validation via subsequent calls to the function <code><a href="#topic+modelSelect">modelSelect()</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sim_modelSel(index, sumstats, nval, tol, warning = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sim_modelSel_+3A_index">index</code></td>
<td>
<p>is a vector of model indices. This can be a a character vector
of model names, repeated as many times as there are simulations for each
model. This vector will be coerced to factor and it must have the same
length as <code>nrow(sumstats)</code> to indicate which row of the <code>sumstats</code>
matrix belongs to which model.</p>
</td></tr>
<tr><td><code id="sim_modelSel_+3A_sumstats">sumstats</code></td>
<td>
<p>is a vector or matrix containing the simulated summary
statistics for all the models. Each row or vector entry should be a
different simulation and each column of a matrix should be a different
statistic. The order must be the same as the order of the models in the
<code>index</code> vector.</p>
</td></tr>
<tr><td><code id="sim_modelSel_+3A_nval">nval</code></td>
<td>
<p>a numerical value defining the the size of the cross-validation
sample for each model.</p>
</td></tr>
<tr><td><code id="sim_modelSel_+3A_tol">tol</code></td>
<td>
<p>is a numerical value, indicating the required proportion of points
nearest the target values (tolerance).</p>
</td></tr>
<tr><td><code id="sim_modelSel_+3A_warning">warning</code></td>
<td>
<p>logical, if FALSE (default) warnings produced while running
this function, mainly related with accepting simulations for just one of
the models, will not be displayed.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>One simulation is randomly selected from each model to be a validation
simulation, while all the other simulations are used as training simulations.
This random simulation is used as the target of the <code><a href="#topic+modelSelect">modelSelect()</a></code> function
and posterior model probabilities are estimated.
</p>
<p>Please note that the actual size of the cross-validation sample is
<code>nval*the number of models</code>. This is because <code>nval</code> cross-validation
estimation steps are performed for each model.
</p>


<h3>Value</h3>

<p>a list with the following elements:
</p>
<table>
<tr><td><code>cvsamples</code></td>
<td>
<p>is a vector of length <code>nval*the number of models</code>
indicating which rows of the <code>sumstat</code> input were used as validation values
for each model.</p>
</td></tr>
<tr><td><code>true</code></td>
<td>
<p>a character vector of the true models.</p>
</td></tr>
<tr><td><code>estimated</code></td>
<td>
<p>a character vector of the estimated models.</p>
</td></tr>
<tr><td><code>model.probs</code></td>
<td>
<p>a matrix with the estimated model probabilities. Each
row of the matrix represents a different cross-validation trial.</p>
</td></tr>
<tr><td><code>models</code></td>
<td>
<p>a character vector with the designation of the models.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'># load the matrix with simulated parameter values
data(sumstats)

# select a random simulation to act as target just to test the function
target &lt;- sumstats[10 ,]

# create a "fake" vector of model indices
# this assumes that half the simulations were from one model and the other half from other model
# this is not true but serves as an example of how to use this function
index &lt;- c(rep("model1", nrow(sumstats)/2), rep("model2", nrow(sumstats)/2))

# perform a leave-one-out cross validation of model selection
sim_modelSel(index = index, sumstats = sumstats, nval = 10, tol = 0.1)

</code></pre>

<hr>
<h2 id='simulationABC'>Perform an Approximate Bayesian Computation simulation study</h2><span id='topic+simulationABC'></span>

<h3>Description</h3>

<p>Perform a leave-one-out cross validation for ABC via subsequent calls to the
<code><a href="#topic+singleABC">singleABC()</a></code> function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simulationABC(
  params,
  sumstats,
  limits,
  nval,
  tol,
  method,
  parallel = FALSE,
  ncores = NA
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="simulationABC_+3A_params">params</code></td>
<td>
<p>is a vector or matrix of simulated parameter values i.e.
numbers from the simulations. Each row or vector entry should be a
different simulation and each column of a matrix should be a different
parameter. This is the dependent variable for the regression, if a
regression step is performed.</p>
</td></tr>
<tr><td><code id="simulationABC_+3A_sumstats">sumstats</code></td>
<td>
<p>is a vector or matrix of simulated summary statistics. Each
row or vector entry should be a different simulation and each column of a
matrix should be a different statistic. These act as the independent
variables if a regression step is performed.</p>
</td></tr>
<tr><td><code id="simulationABC_+3A_limits">limits</code></td>
<td>
<p>is a matrix with two columns and as many rows as there are
parameters. Each row should contain the minimum value of the prior for a
given parameter in the first column and the maximum value in the second
column.</p>
</td></tr>
<tr><td><code id="simulationABC_+3A_nval">nval</code></td>
<td>
<p>size of the cross-validation sample i.e. how many different
evaluations should be performed. Each evaluation corresponds to a different
target for the parameter estimation.</p>
</td></tr>
<tr><td><code id="simulationABC_+3A_tol">tol</code></td>
<td>
<p>is the tolerance rate, indicating the required proportion of
points accepted nearest the target values.</p>
</td></tr>
<tr><td><code id="simulationABC_+3A_method">method</code></td>
<td>
<p>either &quot;rejection&quot; or &quot;regression&quot; indicating whether a
regression step should be performed during ABC parameter estimation.</p>
</td></tr>
<tr><td><code id="simulationABC_+3A_parallel">parallel</code></td>
<td>
<p>logical, indicating whether this function should be run using
parallel execution. The default setting is FALSE, meaning that this
function will utilize a single core.</p>
</td></tr>
<tr><td><code id="simulationABC_+3A_ncores">ncores</code></td>
<td>
<p>a non-negative integer that is required when <code>parallel</code> is
TRUE. It specifies the number of cores to use for parallel execution.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function allows users to evaluate the impact of different tolerance rate
on the quality of the estimation with ABC and whether a local linear
regression algorithm improves the estimates. In subsequent steps, different
point estimates of the posterior estimates can be compared with the true
values, allowing the users to select the point estimate that leads to lower
errors. Thus, performing a leave-one-out cross validation aids in selecting
which point estimate is best - the mean, median or mode.
</p>


<h3>Value</h3>

<p>a list with the following elements:
</p>
<table>
<tr><td><code>true</code></td>
<td>
<p>The parameter values of the simulations that served as
validation.</p>
</td></tr>
<tr><td><code>rej</code></td>
<td>
<p>a list with the estimated parameter values under the rejection
algorithm and using three different point estimates: mode, median and mean.
The final entry of the list is the prediction error for each parameter,
considering each of those point estimates as the estimated value.</p>
</td></tr>
<tr><td><code>reg</code></td>
<td>
<p>if method is &quot;regression&quot; then this is a list with the estimated
parameter values under the regression algorithm and using three different
point estimates: mode, median and mean. The final entry of the list is the
prediction error for each parameter, considering each of those point
estimates as the estimated value.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'># load the matrix with parameter values
data(params)
# load the matrix with simulated parameter values
data(sumstats)
# load the matrix with the prior limits
data(limits)

# perform a leave-one-out cross validation for ABC
simulationABC(params = params, sumstats = sumstats, limits, nval = 10,
tol = 0.01, method = "regression")

</code></pre>

<hr>
<h2 id='singleABC'>Parameter estimation with Approximate Bayesian Computation for a single
target</h2><span id='topic+singleABC'></span>

<h3>Description</h3>

<p>Perform multivariate parameter estimation based on summary statistics using
an Approximate Bayesian Computation (ABC) algorithm. This function always
uses a rejection sampling algorithm while a local linear regression algorithm
might or might not be used.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>singleABC(target, params, sumstats, limits, tol, method)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="singleABC_+3A_target">target</code></td>
<td>
<p>a vector with the target summary statistics. These are usually
computed from observed data or selected from a random simulation when
performing cross-validation.</p>
</td></tr>
<tr><td><code id="singleABC_+3A_params">params</code></td>
<td>
<p>is a vector or matrix of simulated parameter values i.e.
numbers from the simulations. Each row or vector entry should be a
different simulation and each column of a matrix should be a different
parameter. This is the dependent variable for the regression, if a
regression step is performed.</p>
</td></tr>
<tr><td><code id="singleABC_+3A_sumstats">sumstats</code></td>
<td>
<p>is a vector or matrix of simulated summary statistics. Each
row or vector entry should be a different simulation and each column of a
matrix should be a different statistic. These act as the independent
variables if a regression step is performed.</p>
</td></tr>
<tr><td><code id="singleABC_+3A_limits">limits</code></td>
<td>
<p>is a matrix with two columns and as many rows as there are
parameters. Each row should contain the minimum value of the prior for a
given parameter in the first column and the maximum value in the second
column.</p>
</td></tr>
<tr><td><code id="singleABC_+3A_tol">tol</code></td>
<td>
<p>is the tolerance rate, indicating the required proportion of
points accepted nearest the target values.</p>
</td></tr>
<tr><td><code id="singleABC_+3A_method">method</code></td>
<td>
<p>either &quot;rejection&quot; or &quot;regression&quot; indicating whether a
regression step should be performed during ABC parameter estimation.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>To use this function, the usual steps of ABC parameter estimation have to be
performed. Briefly, data should have been simulated based on random draws
from the prior distributions of the parameters of interest and a set of
summary statistics should have been calculated from that data. The same set
of summary statistics should have been calculated from the observed data to
be used as the <code>target</code> input in this function. Parameter values are accepted
if the Euclidean distance between the set of summary statistics computed from
the simulated data and the set of summary statistics computed from the
observed data is sufficiently small. The percentage of accepted simulations
is determined by <code>tol</code>. This function performs a simple rejection by calling
the <code><a href="#topic+rejABC">rejABC()</a></code> function.
</p>
<p>When <code>method</code> is &quot;regression&quot;, a local linear regression method is used to
correct for the imperfect match between the summary statistics computed from
the simulated data and the summary statistics computed from the observed
data. The output of the <code><a href="#topic+rejABC">rejABC()</a></code> function is used as the input of the
<code><a href="#topic+regABC">regABC()</a></code> function to apply this correction. The parameter values accepted
in the rejection step are weighted by a smooth function (kernel) of the
distance between the simulated and observed summary statistics and corrected
according to a linear transformation.
</p>


<h3>Value</h3>

<p>the returned object is a list containing the following components:
</p>
<table>
<tr><td><code>unadjusted</code></td>
<td>
<p>parameter estimates obtained with the rejection
sampling.</p>
</td></tr>
<tr><td><code>rej.prediction</code></td>
<td>
<p>point estimates of the posterior obtained with the
rejection sampling.</p>
</td></tr>
<tr><td><code>adjusted</code></td>
<td>
<p>regression adjusted parameter values.</p>
</td></tr>
<tr><td><code>loc.prediction</code></td>
<td>
<p>point estimates of the regression adjusted
posterior.</p>
</td></tr>
<tr><td><code>ss</code></td>
<td>
<p>set of accepted summary statistics from the simulations.</p>
</td></tr>
<tr><td><code>wt</code></td>
<td>
<p>regression weights.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'># load the matrix with parameter values
data(params)
# load the matrix with simulated parameter values
data(sumstats)
# load the matrix with the prior limits
data(limits)

# select a random simulation to act as target just to test the function
target &lt;- sumstats[10 ,]
# we should remove the random simulation from the sumstats and params matrices
sumstats &lt;- sumstats[-10, ]; params &lt;- params[-10, ]

# parameter estimation for a single target
singleABC(target = target, params = params, sumstats = sumstats, limits = limits,
tol = 0.01, method = "regression")

</code></pre>

<hr>
<h2 id='statsContig'>Compute summary statistics from observed data</h2><span id='topic+statsContig'></span>

<h3>Description</h3>

<p>Computes a defined set of summary statistics from observed data. Those
summary statistics can then be used as the target for parameter estimation or
model selection with Approximate Bayesian Computation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>statsContig(randomWindows, nPops, stat.names = NA)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="statsContig_+3A_randomwindows">randomWindows</code></td>
<td>
<p>a list with randomly selected loci of observed data.
This list should contain five elements: <code>freqs</code>, <code>positions</code>, <code>rMajor</code>,
<code>rMinor</code> and <code>coverage</code>. Each of those elements should contain one entry
per locus with the appropriate information.</p>
</td></tr>
<tr><td><code id="statsContig_+3A_npops">nPops</code></td>
<td>
<p>is an integer indicating how many different populations are
present in the dataset you are analysing.</p>
</td></tr>
<tr><td><code id="statsContig_+3A_stat.names">stat.names</code></td>
<td>
<p>optional character vector with the names of the summary
statistics from the simulated data. If available, these names will be added
to the summary statistics computed from the observed data.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Summary statistics are computed for a given subset of the data. Ideally, this
subset is composed of randomly selected windows of the observed data. Those
random windows should be selected from multiple contigs, treating each contig
as a different locus.
</p>


<h3>Value</h3>

<p>a vector of observed summary statistics. These summary statistics are
computed from blocks of observed data present in the <code>randomWindows</code> input
argument. If the <code>stat.names</code> input argument is available, the summary
statistics will be named.
</p>

<hr>
<h2 id='summary_modelSelect'>Posterior model probabilities</h2><span id='topic+summary_modelSelect'></span>

<h3>Description</h3>

<p>Extract the posterior model probabilities and obtain a summary of model
selection performed with Approximate Bayesian Computation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>summary_modelSelect(object, print = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary_modelSelect_+3A_object">object</code></td>
<td>
<p>a list created by the <code><a href="#topic+modelSelect">modelSelect()</a></code> function, containing
results of model selection with Approximate Bayesian Computation.</p>
</td></tr>
<tr><td><code id="summary_modelSelect_+3A_print">print</code></td>
<td>
<p>logical, if TRUE (default), then this function prints the mean
models probabilities.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function produces an easy-to-read output of the model selection step. It
also computes the Bayes factors.
</p>


<h3>Value</h3>

<p>a list with two main elements if model selection used the regression
algorithm or a single element if only the rejection step was used:
</p>
<table>
<tr><td><code>rejection</code></td>
<td>
<p>results of model selection based on the rejection method.
This element contains two entries, the first is an object of class numeric
with the posterior model probabilities and the second are the Bayes factors
between pairs of models.</p>
</td></tr>
<tr><td><code>mnlogistic</code></td>
<td>
<p>results of model selection based on the regression
method. This element contains two entries, the first is an object of class
numeric with the posterior model probabilities and the second are the Bayes
factors between pairs of models.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'># load the matrix with simulated parameter values
data(sumstats)

# select a random simulation to act as target just to test the function
target &lt;- sumstats[10 ,]

# create a "fake" vector of model indices
# this assumes that half the simulations were from one model and the other half from other model
# this is not true but serves as an example of how to use this function
index &lt;- c(rep("model1", nrow(sumstats)/2), rep("model2", nrow(sumstats)/2))

# perform model selection with ABC
mysel &lt;- modelSelect(target = target, index = index, sumstats = sumstats,
tol = 0.01, method = "regression")

# compute posterior model probabilities
summary_modelSelect(object = mysel)

</code></pre>

<hr>
<h2 id='sumstats'>Matrix of summary statistics computed from simulated data</h2><span id='topic+sumstats'></span>

<h3>Description</h3>

<p>This data set contains a set of 14 summary statistics computed
from data simulated under an isolation with migration model of two
populations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sumstats
</code></pre>


<h3>Format</h3>

<p>a matrix with 10000 rows and 14 columns:
</p>

<dl>
<dt>Sf</dt><dd><p>fraction of sites fixed between populations.</p>
</dd>
<dt>Sx1</dt><dd><p>fraction of exclusive sites for the first population.</p>
</dd>
<dt>Sx2</dt><dd><p>fraction of exclusive sites for the second population.</p>
</dd>
<dt>SS</dt><dd><p>fraction of sites shared between the two populations.</p>
</dd>
<dt>Mean_Het1</dt><dd><p>mean expected heterozygosity of the first population.</p>
</dd>
<dt>Mean_Het2</dt><dd><p>mean expected heterozygosity of the second population.</p>
</dd>
<dt>SD_Het1</dt><dd><p>standard deviation across loci of the mean expected
heterozygosity of the first population.</p>
</dd>
<dt>SD_Het2</dt><dd><p>standard deviation across loci of the mean expected
heterozygosity of the second population.</p>
</dd>
<dt>Mean_HetBet</dt><dd><p>mean heterozygosity between the two populations.</p>
</dd>
<dt>SD_HetBet</dt><dd><p>standard deviation across loci of the mean heterozygosity
between the two populations.</p>
</dd>
<dt>Mean_FST</dt><dd><p>mean pairwise FST between the two populations.</p>
</dd>
<dt>SD_FST</dt><dd><p>standard deviation across loci of the mean pairwise FST
between the two populations.</p>
</dd>
<dt>FSTQ1</dt><dd><p>5% quantile of the mean pairwise FST distribution.</p>
</dd>
<dt>FSTQ2</dt><dd><p>95% quantile of the mean pairwise FST distribution.</p>
</dd> </dl>



<h3>Source</h3>

<p>simulations performed
</p>

<hr>
<h2 id='Tmatrix'>Transform matrix of parameter values</h2><span id='topic+Tmatrix'></span>

<h3>Description</h3>

<p>This function applies a transformation to the parameter values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Tmatrix(original, limits)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Tmatrix_+3A_original">original</code></td>
<td>
<p>a matrix of parameter values i.e. numbers obtained from the
simulations. Each column should be a different parameter and each row a
different simulation. This is the matrix that you wish to transform so that
the parameter values are all in the same scale.</p>
</td></tr>
<tr><td><code id="Tmatrix_+3A_limits">limits</code></td>
<td>
<p>is a matrix with two columns and as many rows as there are
parameters. Each row should contain the minimum value of the prior for a
given parameter in the first column and the maximum value in the second
column.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The transformation should be applied before parameter estimation using an
Approximate Bayesian Computation framework to ensure that the estimates do
not fall outside the boundaries set by the prior distribution.
</p>


<h3>Value</h3>

<p>a matrix with the same dimensions as the <code>original</code> matrix but
with the parameter values transformed.
</p>

<hr>
<h2 id='tranf'>Apply a transformation to the parameters</h2><span id='topic+tranf'></span>

<h3>Description</h3>

<p>This function applies a transformation to the parameter values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tranf(x, min, max)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tranf_+3A_x">x</code></td>
<td>
<p>is the parameter vector (long vector of numbers from the
simulations). These are the values to be transformed.</p>
</td></tr>
<tr><td><code id="tranf_+3A_min">min</code></td>
<td>
<p>is the minimum value of the prior for this parameter.</p>
</td></tr>
<tr><td><code id="tranf_+3A_max">max</code></td>
<td>
<p>is the maximum value of the prior for this parameter.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The transformation should be applied before parameter estimation using an
Approximate Bayesian Computation framework to ensure that the estimates do
not fall outside the boundaries set by the prior distribution.
</p>


<h3>Value</h3>

<p>a numeric vector with the same length as <code>x</code> with the parameter
values transformed.
</p>

<hr>
<h2 id='weighted_stats'>Compute weighted point estimates</h2><span id='topic+weighted_stats'></span>

<h3>Description</h3>

<p>Computes the weighted mean, median and quantiles of a distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>weighted_stats(x, w, prob = c(0.05, 0.25, 0.75, 0.95))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="weighted_stats_+3A_x">x</code></td>
<td>
<p>numeric vector of size n with the observations.</p>
</td></tr>
<tr><td><code id="weighted_stats_+3A_w">w</code></td>
<td>
<p>numeric vector of size n with non-negative weights. Note that this
vector needs to have the same length as the <code>x</code> vector.</p>
</td></tr>
<tr><td><code id="weighted_stats_+3A_prob">prob</code></td>
<td>
<p>numeric vector of probabilities with values in <code>[0,1]</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function requires the <code><a href="MetricsWeighted.html#topic+weighted_quantile">MetricsWeighted::weighted_quantile()</a></code> function
and the weights to compute the weighted arithmetic mean and the weighted
quantiles. By default, this function computes the 5%, 25%, 50% (corresponding
to the median), 75% and 95% quantiles.
</p>


<h3>Value</h3>

<p>numeric vector with weighted mean, median and quantiles of size
<code>2 + length(prob)</code>.
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
