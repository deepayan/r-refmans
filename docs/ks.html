<!DOCTYPE html><html lang="en"><head><title>Help for package ks</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {ks}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#ks-package'><p>ks</p></a></li>
<li><a href='#air'><p>Air quality measurements in an underground train station</p></a></li>
<li><a href='#binning'><p>Linear binning for multivariate data</p></a></li>
<li><a href='#cardio'><p>Foetal cardiotocograms</p></a></li>
<li><a href='#contour'><p>Contour functions</p></a></li>
<li><a href='#grevillea'><p>Geographical locations of grevillea plants</p></a></li>
<li><a href='#Hbcv'><p>Biased cross-validation (BCV) bandwidth matrix selector</p>
for bivariate data</a></li>
<li><a href='#histde'><p>Histogram density estimate</p></a></li>
<li><a href='#Hlscv'><p>Least-squares cross-validation (LSCV) bandwidth matrix selector</p>
for multivariate data</a></li>
<li><a href='#Hnm'><p>Normal mixture bandwidth</p></a></li>
<li><a href='#Hns'><p>Normal scale bandwidth</p></a></li>
<li><a href='#Hpi'><p>Plug-in bandwidth selector</p></a></li>
<li><a href='#hsct'><p>Haematopoietic stem cell transplant</p></a></li>
<li><a href='#Hscv'><p>Smoothed cross-validation (SCV) bandwidth selector</p></a></li>
<li><a href='#ise.mixt'><p>Squared error bandwidth matrix selectors for normal</p>
mixture densities</a></li>
<li><a href='#kcde'><p>Kernel cumulative distribution/survival function estimate</p></a></li>
<li><a href='#kcopula'><p>Kernel copula (density) estimate</p></a></li>
<li><a href='#kda'><p>Kernel discriminant analysis (kernel classification)</p></a></li>
<li><a href='#kdcde'><p>Deconvolution kernel density derivative estimate</p></a></li>
<li><a href='#kdde'><p>Kernel density derivative estimate</p></a></li>
<li><a href='#kde'><p>Kernel density estimate</p></a></li>
<li><a href='#kde.boundary'><p>Kernel density estimate for bounded data</p></a></li>
<li><a href='#kde.local.test'><p>Kernel density based local two-sample comparison test</p></a></li>
<li><a href='#kde.test'><p>Kernel density based global two-sample comparison test</p></a></li>
<li><a href='#kde.truncate'><p>Truncated kernel density derivative estimate</p></a></li>
<li><a href='#kdr'><p>Kernel density ridge estimation</p></a></li>
<li><a href='#kfe'><p>Kernel functional estimate</p></a></li>
<li><a href='#kfs'><p>Kernel feature significance</p></a></li>
<li><a href='#kms'><p>Kernel mean shift clustering</p></a></li>
<li><a href='#kroc'><p>Kernel receiver operating characteristic (ROC) curve</p></a></li>
<li><a href='#ks-internal'><p>Internal functions in the ks library</p></a></li>
<li><a href='#ksupp'><p>Kernel support estimate</p></a></li>
<li><a href='#mixt'><p>Normal and t-mixture distributions</p></a></li>
<li><a href='#plot.histde'><p>Plot for histogram density estimate</p></a></li>
<li><a href='#plot.kcde'><p>Plot for kernel cumulative distribution estimate</p></a></li>
<li><a href='#plot.kda'><p>Plot for kernel discriminant analysis</p></a></li>
<li><a href='#plot.kdde'><p>Plot for kernel density derivative estimate</p></a></li>
<li><a href='#plot.kde'><p>Plot for kernel density estimate</p></a></li>
<li><a href='#plot.kde.loctest'><p>Plot for kernel local significant difference regions</p></a></li>
<li><a href='#plot.kde.part'><p>Partition plot for kernel density clustering</p></a></li>
<li><a href='#plot.kfs'><p>Plot for kernel feature significance</p></a></li>
<li><a href='#plot.kroc'><p>Plot for kernel receiver operating characteristic curve (ROC) estimate</p></a></li>
<li><a href='#plotmixt'><p>Plot for 1- to 3-dimensional normal and t-mixture density functions</p></a></li>
<li><a href='#pre.transform'><p>Pre-sphering and pre-scaling</p></a></li>
<li><a href='#quake'><p>Geographical locations of earthquakes and tectonic plates</p></a></li>
<li><a href='#rkde'><p>Derived quantities from kernel density estimates</p></a></li>
<li><a href='#tempb'><p>Daily temperature</p></a></li>
<li><a href='#unicef'><p>Unicef child mortality - life expectancy data</p></a></li>
<li><a href='#vector'><p>Vector and vector half operators</p></a></li>
<li><a href='#vkde'><p>Variable kernel density estimate.</p></a></li>
<li><a href='#worldbank'><p>Development indicators from the World Bank Group</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Version:</td>
<td>1.14.3</td>
</tr>
<tr>
<td>Date:</td>
<td>2024-09-20</td>
</tr>
<tr>
<td>Title:</td>
<td>Kernel Smoothing</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Tarn Duong &lt;tarn.duong@gmail.com&gt;</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 2.10.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>FNN (&ge; 1.1), kernlab, KernSmooth (&ge; 2.22), Matrix, mclust,
mgcv, multicool, mvtnorm (&ge; 1.0-0), pracma</td>
</tr>
<tr>
<td>Suggests:</td>
<td>geometry, MASS, misc3d (&ge; 0.4-0), oz, plot3D, rgl (&ge; 0.66)</td>
</tr>
<tr>
<td>Description:</td>
<td>Kernel smoothers for univariate and multivariate data, with comprehensive visualisation and bandwidth selection capabilities, including for densities, density derivatives, cumulative distributions, clustering, classification, density ridges, significant modal regions, and two-sample hypothesis tests. Chacon &amp; Duong (2018) &lt;<a href="https://doi.org/10.1201%2F9780429485572">doi:10.1201/9780429485572</a>&gt;.   </td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://www.mvstat.net/mvksa/">https://www.mvstat.net/mvksa/</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-09-20 13:32:31 UTC; tduong</td>
</tr>
<tr>
<td>Author:</td>
<td>Tarn Duong <a href="https://orcid.org/0000-0002-1198-3482"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut,
    cre],
  Matt Wand <a href="https://orcid.org/0000-0003-2555-896X"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [ctb],
  Jose Chacon [ctb],
  Artur Gramacki <a href="https://orcid.org/0000-0002-1610-9743"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [ctb]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-09-20 17:00:01 UTC</td>
</tr>
</table>
<hr>
<h2 id='ks-package'>ks</h2><span id='topic+ks'></span><span id='topic+ks-package'></span>

<h3>Description</h3>

<p>Kernel smoothing for data from 1- to 6-dimensions.
</p>


<h3>Details</h3>

<p>There are three main types of functions in this package:
</p>

<ul>
<li><p> computing kernel estimators - these function names begin with &lsquo;k&rsquo;
</p>
</li>
<li><p> computing bandwidth selectors - these begin with &lsquo;h&rsquo; (1-d) or
&lsquo;H&rsquo; (&gt;1-d)
</p>
</li>
<li><p> displaying kernel estimators - these begin with &lsquo;plot&rsquo;.
</p>
</li></ul>

<p>The kernel used throughout is the normal (Gaussian) kernel <code class="reqn">K</code>.
For 1-d data, the bandwidth <code class="reqn">h</code> is the standard deviation of
the normal kernel, whereas for multivariate data, the bandwidth matrix 
<code class="reqn">\bold{{\rm H}}</code> is the variance matrix.
</p>
<p>&ndash;For kernel density estimation, <code><a href="#topic+kde">kde</a></code> computes  
</p>
<p style="text-align: center;"><code class="reqn">\hat{f}(\bold{x}) = n^{-1} \sum_{i=1}^n K_{\bold{{\rm H}}} (\bold{x} - \bold{X}_i).</code>
</p>
 
<p>The bandwidth matrix <code class="reqn">\bold{{\rm H}}</code> is a matrix of smoothing
parameters and its choice is crucial for the performance of kernel
estimators. For display, its <code>plot</code> method calls <code><a href="#topic+plot.kde">plot.kde</a></code>.
</p>
<p>&ndash;For kernel density estimation, there are several varieties of bandwidth selectors 
</p>

<ul>
<li><p> plug-in <code><a href="#topic+hpi">hpi</a></code> (1-d); 
<code><a href="#topic+Hpi">Hpi</a></code>, <code><a href="#topic+Hpi.diag">Hpi.diag</a></code> (2- to 6-d) 
</p>
</li>
<li><p> least squares (or unbiased) cross validation (LSCV or UCV) <code><a href="#topic+hlscv">hlscv</a></code> (1-d);
<code><a href="#topic+Hlscv">Hlscv</a></code>, <code><a href="#topic+Hlscv.diag">Hlscv.diag</a></code> (2- to 6-d) 
</p>
</li>
<li><p> biased cross validation (BCV) 
<code><a href="#topic+Hbcv">Hbcv</a></code>, <code><a href="#topic+Hbcv.diag">Hbcv.diag</a></code> (2- to 6-d) 
</p>
</li>
<li><p> smoothed cross validation (SCV) <code><a href="#topic+hscv">hscv</a></code> (1-d);
<code><a href="#topic+Hscv">Hscv</a></code>, <code><a href="#topic+Hscv.diag">Hscv.diag</a></code> (2- to 6-d) 
</p>
</li>
<li><p> normal scale <code><a href="#topic+hns">hns</a></code> (1-d); <code><a href="#topic+Hns">Hns</a></code> (2- to 6-d).
</p>
</li></ul>

<p>&ndash;For kernel density support estimation, the main function is
<code><a href="#topic+ksupp">ksupp</a></code> which is (the convex hull of) 
</p>
<p style="text-align: center;"><code class="reqn">\{\bold{x}: \hat{f}(\bold{x}) &gt;
    \tau\}</code>
</p>

<p>for a suitable level <code class="reqn">\tau</code>. This is closely related to the <code class="reqn">\tau</code>-level set of
<code class="reqn">\hat{f}</code>. 
</p>
<p>&ndash;For truncated kernel density estimation, the main function is
<code><a href="#topic+kde.truncate">kde.truncate</a></code>
</p>
<p style="text-align: center;"><code class="reqn">\hat{f} (\bold{x}) \bold{1}\{\bold{x} \in \Omega\} /
  \int_{\Omega}\hat{f} (\bold{x}) \, d\bold{x}</code>
</p>

<p>for a bounded data support <code class="reqn">\Omega</code>. The standard density
estimate <code class="reqn">\hat{f}</code> is truncated and rescaled to give
unit integral over <code class="reqn">\Omega</code>. Its <code>plot</code> method calls <code><a href="#topic+plot.kde">plot.kde</a></code>.
</p>
<p>&ndash;For boundary kernel density estimation where the kernel function is
modified explicitly in the boundary region, the main function is
<code><a href="#topic+kde.boundary">kde.boundary</a></code>
</p>
<p style="text-align: center;"><code class="reqn"> n^{-1} \sum_{i=1}^n K^*_{\bold{{\rm H}}} (\bold{x} - \bold{X}_i)</code>
</p>
 
<p>for a boundary kernel <code class="reqn">K^*</code>. Its <code>plot</code> method calls <code><a href="#topic+plot.kde">plot.kde</a></code>.
</p>
<p>&ndash;For variable kernel density estimation where the bandwidth is not a
constant matrix, the main functions are <code><a href="#topic+kde.balloon">kde.balloon</a></code>
</p>
<p style="text-align: center;"><code class="reqn">\hat{f}_{\rm ball}(\bold{x}) = n^{-1} \sum_{i=1}^n K_{\bold{{\rm H}}(\bold{x})} (\bold{x} - \bold{X}_i)</code>
</p>

<p>and
<code><a href="#topic+kde.sp">kde.sp</a></code> 
</p>
<p style="text-align: center;"><code class="reqn">\hat{f}_{\rm SP}(\bold{x}) = n^{-1} \sum_{i=1}^n K_{\bold{{\rm H}}(\bold{X}_i)} (\bold{x} - \bold{X}_i).</code>
</p>

<p>For the balloon estimation <code class="reqn">\hat{f}_{\rm ball}</code> the
bandwidth varies with the estimation point <code class="reqn">\bold{x}</code>, whereas
for the sample point estimation  <code class="reqn">\hat{f}_{\rm SP}</code>
the bandwidth varies with the data point
<code class="reqn">\bold{X}_i, i=1,\dots,n</code>. 
Their <code>plot</code> methods call <code><a href="#topic+plot.kde">plot.kde</a></code>. The bandwidth
selectors for <code>kde.balloon</code> are based on the normal scale bandwidth
<code>Hns(,deriv.order=2)</code> via the MSE minimal formula, and for
<code>kde.SP</code> on <code>Hns(,deriv.order=4)</code> via the Abramson formula.
</p>
<p>&ndash;For kernel density derivative estimation, the main function is <code><a href="#topic+kdde">kdde</a></code>
</p>
<p style="text-align: center;"><code class="reqn">{\sf D}^{\otimes r}\hat{f}(\bold{x}) = n^{-1} \sum_{i=1}^n {\sf
  D}^{\otimes r}K_{\bold{{\rm H}}} (\bold{x} -
\bold{X}_i).</code>
</p>
 
<p>The bandwidth selectors are a modified subset of those for
<code><a href="#topic+kde">kde</a></code>, i.e. <code><a href="#topic+Hlscv">Hlscv</a></code>, <code><a href="#topic+Hns">Hns</a></code>, <code><a href="#topic+Hpi">Hpi</a></code>, <code><a href="#topic+Hscv">Hscv</a></code> with <code>deriv.order&gt;0</code>. 
Its <code>plot</code> method is <code><a href="#topic+plot.kdde">plot.kdde</a></code> for plotting each
partial derivative singly.
</p>
<p>&ndash;For kernel summary curvature estimation, the main function is
<code><a href="#topic+kcurv">kcurv</a></code>
</p>
<p style="text-align: center;"><code class="reqn">\hat{s}(\bold{x})= - \bold{1}\{{\sf D}^2 \hat{f}(\bold{x}) &lt;
    0\} \mathrm{abs}(|{\sf D}^2 \hat{f}(\bold{x})|)</code>
</p>
<p> where <code class="reqn">{\sf D}^2
    \hat{f}(\bold{x})</code> is the kernel Hessian matrix estimate.
It has the same structure as a kernel density estimate so its <code>plot</code>
method calls <code><a href="#topic+plot.kde">plot.kde</a></code>. 
</p>
<p>&ndash;For kernel discriminant analysis, the main function is
<code><a href="#topic+kda">kda</a></code> which computes density estimates for each the 
groups in the training data, and the discriminant surface. 
Its <code>plot</code> method is <code><a href="#topic+plot.kda">plot.kda</a></code>. The wrapper function
<code><a href="#topic+hkda">hkda</a></code>, <code><a href="#topic+Hkda">Hkda</a></code> computes 
bandwidths for each group in the training data for <code>kde</code>,
e.g. <code>hpi</code>, <code>Hpi</code>.
</p>
<p>&ndash;For kernel functional estimation, the main function is
<code>kfe</code> which computes the <code class="reqn">r</code>-th order integrated density functional  
</p>
<p style="text-align: center;"><code class="reqn">\hat{{\bold \psi}}_r  = n^{-2} \sum_{i=1}^n \sum_{j=1}^n {\sf D}^{\otimes r}K_{\bold{{\rm H}}}(\bold{X}_i-\bold{X}_j).</code>
</p>
<p> The plug-in selectors are <code><a href="#topic+hpi.kfe">hpi.kfe</a></code> (1-d), <code><a href="#topic+Hpi.kfe">Hpi.kfe</a></code> (2- to 6-d).
Kernel functional estimates are usually not required to computed
directly by the user, but only within other functions in the package.
</p>
<p>&ndash;For kernel-based 2-sample testing, the main function is
<code><a href="#topic+kde.test">kde.test</a></code> which computes the integrated 
<code class="reqn">L_2</code> distance between the two density estimates as the test
statistic, comprising a linear combination of 0-th order kernel
functional estimates:
</p>
<p style="text-align: center;"><code class="reqn">\hat{T} = \hat{\psi}_{0,1} + \hat{\psi}_{0,2} - (\hat{\psi}_{0,12} +
  \hat{\psi}_{0,21}),</code>
</p>
<p> and the corresponding p-value. The <code class="reqn">\psi</code> are
zero order kernel functional estimates with the subscripts indicating
that 1 = sample 1 only, 2 = sample 2 only, and 12, 21 =
samples 1 and 2.  The bandwidth selectors are <code><a href="#topic+hpi.kfe">hpi.kfe</a></code>,
<code><a href="#topic+Hpi.kfe">Hpi.kfe</a></code> with <code>deriv.order=0</code>. 
</p>
<p>&ndash;For kernel-based local 2-sample testing, the main function is
<code><a href="#topic+kde.local.test">kde.local.test</a></code> which computes the squared distance
between the two density estimates as the test  
statistic </p>
<p style="text-align: center;"><code class="reqn">\hat{U}(\bold{x}) = [\hat{f}_1(\bold{x}) -
     \hat{f}_2(\bold{x})]^2</code>
</p>
<p> and the corresponding local
p-values.  The bandwidth selectors are those used with <code><a href="#topic+kde">kde</a></code>,
e.g. <code><a href="#topic+hpi">hpi</a>, <a href="#topic+Hpi">Hpi</a></code>.  
</p>
<p>&ndash;For kernel cumulative distribution function estimation, the main
function is <code><a href="#topic+kcde">kcde</a></code>
</p>
<p style="text-align: center;"><code class="reqn">\hat{F}(\bold{x}) = n^{-1} \sum_{i=1}^n
    \mathcal{K}_{\bold{{\rm H}}} (\bold{x} - \bold{X}_i)</code>
</p>

<p>where <code class="reqn">\mathcal{K}</code> is the integrated kernel.  
The bandwidth selectors are <code><a href="#topic+hpi.kcde">hpi.kcde</a></code>,
<code><a href="#topic+Hpi.kcde">Hpi.kcde</a></code>.  Its <code>plot</code> method is
<code><a href="#topic+plot.kcde">plot.kcde</a></code>.
There exist analogous functions for the survival function <code class="reqn">\hat{\bar{F}}</code>.
</p>
<p>&ndash;For kernel estimation of a ROC (receiver operating characteristic)
curve to compare two samples from <code class="reqn">\hat{F}_1,
  \hat{F}_2</code>, the main function is <code><a href="#topic+kroc">kroc</a></code>
</p>
<p style="text-align: center;"><code class="reqn">\{\hat{F}_{\hat{Y}_1}(z),
  \hat{F}_{\hat{Y}_2}(z)\}</code>
</p>
<p> based on the cumulative distribution functions of
<code class="reqn">\hat{Y}_j = \hat{\bar{F}}_1(\bold{X}_j), j=1,2</code>.
</p>
<p>The bandwidth selectors are those used with <code><a href="#topic+kcde">kcde</a></code>,
e.g. <code><a href="#topic+hpi.kcde">hpi.kcde</a>, <a href="#topic+Hpi.kcde">Hpi.kcde</a></code>  for
<code class="reqn">\hat{F}_{\hat{Y}_j}, \hat{\bar{F}}_1</code>. Its <code>plot</code> method
is <code><a href="#topic+plot.kroc">plot.kroc</a></code>.   
</p>
<p>&ndash;For kernel estimation of a copula, the
main function is <code><a href="#topic+kcopula">kcopula</a></code>
</p>
<p style="text-align: center;"><code class="reqn">\hat{C}(\bold{z}) = \hat{F}(\hat{F}_1^{-1}(z_1), \dots,
  \hat{F}_d^{-1}(z_d))</code>
</p>

<p>where <code class="reqn">\hat{F}_j^{-1}(z_j)</code> is
the <code class="reqn">z_j</code>-th quantile of of the <code class="reqn">j</code>-th marginal
distribution <code class="reqn">\hat{F}_j</code>.
The bandwidth selectors are those used with <code><a href="#topic+kcde">kcde</a></code> for
<code class="reqn">\hat{F}, \hat{F}_j</code>.
Its <code>plot</code> method is <code><a href="#topic+plot.kcde">plot.kcde</a></code>.
</p>










<p>&ndash;For kernel mean shift clustering, the main function is
<code><a href="#topic+kms">kms</a></code>. The mean shift recurrence relation of the candidate
point <code class="reqn">{\bold x}</code>   
</p>
<p style="text-align: center;"><code class="reqn">{\bold x}_{j+1} = {\bold x}_j + \bold{{\rm H}} {\sf D} \hat{f}({\bold
      x}_j)/\hat{f}({\bold x}_j),</code>
</p>

<p>where <code class="reqn">j\geq 0</code> and <code class="reqn">{\bold x}_0 = {\bold x}</code>,
is iterated until <code class="reqn">{\bold x}</code> converges to its
local mode in the density estimate <code class="reqn">\hat{f}</code> by following
the density gradient ascent paths. This mode determines the cluster
label for <code class="reqn">\bold{x}</code>.  The bandwidth selectors are those used with
<code><a href="#topic+kdde">kdde</a>(,deriv.order=1)</code>.  
</p>
<p>&ndash;For kernel density ridge estimation, the main function is
<code><a href="#topic+kdr">kdr</a></code>. The kernel density ridge recurrence relation of
the candidate point <code class="reqn">{\bold x}</code> 
</p>
<p style="text-align: center;"><code class="reqn">{\bold x}_{j+1} = {\bold x}_j + \bold{{\rm U}}_{(d-1)}({\bold
    x}_j)\bold{{\rm U}}_{(d-1)}({\bold x}_j)^T \bold{{\rm H}} {\sf D}
    \hat{f}({\bold x}_j)/\hat{f}({\bold x}_j),</code>
</p>

<p>where <code class="reqn">j\geq 0</code>, <code class="reqn">{\bold x}_0 = {\bold x}</code> and <code class="reqn">\bold{{\rm U}}_{(d-1)}</code> is the 1-dimensional projected
density gradient, 
is iterated until <code class="reqn">{\bold x}</code> converges to the ridge in the
density estimate. The bandwidth selectors are those used with 
<code><a href="#topic+kdde">kdde</a>(,deriv.order=2)</code>. 
</p>
<p>&ndash; For kernel feature significance, the main function
<code><a href="#topic+kfs">kfs</a></code>.  The hypothesis test at a point <code class="reqn">\bold{x}</code> is
<code class="reqn">H_0(\bold{x}): \mathsf{H} f(\bold{x}) &lt; 0</code>,
i.e. the density Hessian matrix <code class="reqn">\mathsf{H} f(\bold{x})</code> is negative definite.
The test statistic is  
</p>
<p style="text-align: center;"><code class="reqn">W(\bold{x}) = \Vert 
    \mathbf{S}(\bold{x})^{-1/2} \mathrm{vech} \ \mathsf{H} \hat{f} (\bold{x})\Vert ^2</code>
</p>

<p>where <code class="reqn">{\sf H}\hat{f}</code> is the
Hessian estimate, vech is the vector-half operator, and
<code class="reqn">\mathbf{S}</code> is an estimate of the null variance.
<code class="reqn">W(\bold{x})</code> is
approximately <code class="reqn">\chi^2</code> distributed with
<code class="reqn">d(d+1)/2</code> degrees of freedom.
If <code class="reqn">H_0(\bold{x})</code> is rejected, then <code class="reqn">\bold{x}</code>
belongs to a significant modal region.
The bandwidth selectors are those used with
<code><a href="#topic+kdde">kdde</a>(,deriv.order=2)</code>. Its <code>plot</code> method is
<code><a href="#topic+plot.kfs">plot.kfs</a></code>.
</p>
<p>&ndash;For deconvolution density estimation, the main function is
<code><a href="#topic+kdcde">kdcde</a></code>. A weighted kernel density
estimation with the contaminated data <code class="reqn">{\bold W}_1, \dots, {\bold
  W}_n</code>, 
</p>
<p style="text-align: center;"><code class="reqn">\hat{f}_w({\bold x}) = n^{-1} \sum_{i=1}^n
    \alpha_i K_{\bold{{\rm H}}}({\bold x} - {\bold W}_i),</code>
</p>

<p>is utilised, where the weights <code class="reqn">\alpha_1, \dots,
  \alpha_n</code> are chosen via a
quadratic optimisation involving the error variance and the
regularisation parameter. The bandwidth selectors are those used with
<code><a href="#topic+kde">kde</a></code>.
</p>
<p>&ndash;Binned kernel estimation is an approximation to the exact kernel
estimation and is available for d=1, 2, 3, 4. This makes
kernel estimators feasible for large samples. 
</p>
<p>&ndash;For an overview of this package with 2-d density estimation, see 
<code>vignette("kde")</code>.
</p>
<p>&ndash;For <span class="pkg">ks</span> <code class="reqn">\geq</code> 1.11.1, the <span class="pkg">misc3d</span> and
<span class="pkg">rgl</span> (3-d plot), <span class="pkg">oz</span> (Australian map) packages, and for <span class="pkg">ks</span> <code class="reqn">\geq</code> 1.14.2, the <span class="pkg">plot3D</span> (3-d plot) package, have been moved from
Depends to Suggests. This was done to allow <span class="pkg">ks</span> to be installed
on systems where these latter graphical-based packages can't be
installed. Furthermore, since the future of OpenGL in R is not certain, 
<span class="pkg">plot3D</span> becomes the default for 3D plotting for <span class="pkg">ks</span> <code class="reqn">\geq</code> 1.12.0. RGL plots are still supported though these may be deprecated in the 
future.  
</p>


<h3>Author(s)</h3>

<p>Tarn Duong for most of the package. 
M. P. Wand for the binned estimation, univariate plug-in selector and 
univariate density derivative estimator code.
J. E. Chacon for the unconstrained pilot functional estimation and fast implementation of derivative-based estimation code.
A. and J. Gramacki for the binned estimation for unconstrained bandwidth 
matrices. 
</p>


<h3>References</h3>

<p>Bowman, A. &amp; Azzalini, A. (1997) <em>Applied Smoothing Techniques
for Data Analysis</em>. Oxford University Press, Oxford.
</p>
<p>Chacon, J.E. &amp; Duong, T. (2018) <em>Multivariate Kernel Smoothing
and Its Applications</em>. Chapman &amp; Hall/CRC, Boca Raton. 
</p>
<p>Duong, T. (2004) <em>Bandwidth Matrices for Multivariate Kernel Density 
Estimation.</em> Ph.D. Thesis, University of Western Australia. 
</p>
<p>Scott, D.W. (2015) <em>Multivariate Density Estimation: Theory,
Practice, and Visualization (2nd edn)</em>. John Wiley &amp; Sons, New York.
</p>
<p>Silverman, B. (1986) <em>Density Estimation for Statistics and
Data Analysis</em>. Chapman &amp; Hall/CRC, London.
</p>
<p>Simonoff, J. S. (1996) <em>Smoothing Methods in Statistics</em>.
Springer-Verlag, New York.
</p>
<p>Wand, M.P. &amp; Jones, M.C. (1995) <em>Kernel Smoothing</em>. Chapman &amp;
Hall/CRC, London.
</p>


<h3>See Also</h3>

<p><span class="pkg">feature</span>, <span class="pkg">sm</span>, <span class="pkg">KernSmooth</span></p>

<hr>
<h2 id='air'>Air quality measurements in an underground train station</h2><span id='topic+air'></span>

<h3>Description</h3>

<p>This data set contains the hourly mean air
quality measurements from 01 January 2013 to 31 December 2016 in the
Chatelet underground train station in the Paris metro. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(air)</code></pre>


<h3>Format</h3>

<p>A matrix with 35039 rows and 8 columns.
Each row corresponds to an hourly measurement. 
The first column is the date (yyyy-mm-dd),
the second is the time (hh:mm),
the third is the nitric oxide NO concentration (g/m3),
the fourth is the nitrogen dioxide NO<code class="reqn">_2</code> concentration (g/m3),
the fifth is the concentration of particulate matter less than 10
microns PM10 (ppm),
the sixth is the carbon dioxide concentration CO<code class="reqn">_2</code> (g/m3),
the seventh is the temperature (degrees Celsius),
the eighth is the relative humidity (percentage). </p>


<h3>Source</h3>

<p>RATP (2016) Qualite de l'air mesuree dans la station Chatelet, 
<a href="https://data.iledefrance.fr/explore/dataset/qualite-de-l-air-mesuree-dans-la-station-chatelet-rer-a">https://data.iledefrance.fr/explore/dataset/qualite-de-l-air-mesuree-dans-la-station-chatelet-rer-a</a>. Regie autonome des transports parisiens - Departement Developpement, Innovation et Territoires. Accessed 2017-09-27.
</p>

<hr>
<h2 id='binning'>Linear binning for multivariate data</h2><span id='topic+binning'></span>

<h3>Description</h3>

<p>Linear binning for 1- to 4-dimensional data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>binning(x, H, h, bgridsize, xmin, xmax, supp=3.7, w, gridtype="linear")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="binning_+3A_x">x</code></td>
<td>
<p>matrix of data values</p>
</td></tr>
<tr><td><code id="binning_+3A_h">H</code>, <code id="binning_+3A_h">h</code></td>
<td>
<p>bandwidth matrix, scalar bandwidth</p>
</td></tr>
<tr><td><code id="binning_+3A_xmin">xmin</code>, <code id="binning_+3A_xmax">xmax</code></td>
<td>
<p>vector of minimum/maximum values for grid</p>
</td></tr>
<tr><td><code id="binning_+3A_supp">supp</code></td>
<td>
<p>effective support for standard normal is [-supp,supp]</p>
</td></tr>
<tr><td><code id="binning_+3A_bgridsize">bgridsize</code></td>
<td>
<p>vector of binning grid sizes</p>
</td></tr>
<tr><td><code id="binning_+3A_w">w</code></td>
<td>
<p>vector of weights. Default is a vector of all ones.</p>
</td></tr>
<tr><td><code id="binning_+3A_gridtype">gridtype</code></td>
<td>
<p>not yet implemented</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For <span class="pkg">ks</span> <code class="reqn">\geq</code> 1.10.0, binning is available for unconstrained
(non-diagonal) bandwidth matrices. Code is used courtesy of A. &amp;
J. Gramacki, and M.P. Wand. Default <code>bgridsize</code> are 
d=1: 401; d=2: rep(151, 2); d=3: rep(51, 3); d=4: rep(21, 4). 
</p>


<h3>Value</h3>

<p>Returns a list with 2 fields
</p>
<table role = "presentation">
<tr><td><code>counts</code></td>
<td>
<p>linear binning counts</p>
</td></tr>
<tr><td><code>eval.points</code></td>
<td>
<p>vector (d=1) or list (d&gt;=2) of grid points in each
dimension </p>
</td></tr>
</table>


<h3>References</h3>

<p>Gramacki, A. &amp; Gramacki, J. (2016) FFT-based fast computation of
multivariate kernel estimators with unconstrained bandwidth
matrices. <em>Journal of Computational &amp; Graphical Statistics</em>,
<b>26</b>, 459-462.
</p>
<p>Wand, M.P. &amp; Jones, M.C. (1995) <em>Kernel Smoothing</em>.
Chapman &amp; Hall. London.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(unicef)
ubinned &lt;- binning(x=unicef)
</code></pre>

<hr>
<h2 id='cardio'>Foetal cardiotocograms</h2><span id='topic+cardio'></span>

<h3>Description</h3>

<p>This data set contains the cardiotocographic measurements from healthy,
suspect and pathological foetuses. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(cardio)</code></pre>


<h3>Format</h3>

<p>A matrix with 2126 rows and 8 columns.
Each row corresponds to a foetal cardiotocogram. The
class label for the foetal state is the last column: N = normal, S =
suspect, P = pathological. Details for all variables are found in the
link below.  
</p>


<h3>Source</h3>

<p>Lichman, M. (2013) UCI Machine learning repository: cardiotocography data set.
University of California, Irvine, School of Information and Computer
Sciences. Accessed 2017-05-18.
</p>

<hr>
<h2 id='contour'>Contour functions</h2><span id='topic+contourLevels'></span><span id='topic+contourLevels.kde'></span><span id='topic+contourLevels.kda'></span><span id='topic+contourLevels.kdde'></span><span id='topic+contourSizes'></span><span id='topic+contourProbs'></span>

<h3>Description</h3>

<p>Contour levels and sizes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>contourLevels(x, ...)
## S3 method for class 'kde'
 contourLevels(x, prob, cont, nlevels=5, approx=TRUE, ...)
## S3 method for class 'kda'
 contourLevels(x, prob, cont, nlevels=5, approx=TRUE, ...)
## S3 method for class 'kdde'
contourLevels(x, prob, cont, nlevels=5, approx=TRUE, which.deriv.ind=1, ...) 

contourSizes(x, abs.cont, cont=c(25,50,75), approx=TRUE)
contourProbs(x, abs.cont, cont=c(25,50,75), approx=TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="contour_+3A_x">x</code></td>
<td>
<p>object of class <code>kde</code>, <code>kdde</code> or <code>kda</code></p>
</td></tr>
<tr><td><code id="contour_+3A_prob">prob</code></td>
<td>
<p>vector of probabilities corresponding to highest density regions</p>
</td></tr>
<tr><td><code id="contour_+3A_cont">cont</code></td>
<td>
<p>vector of percentages which correspond to the complement
of <code>prob</code></p>
</td></tr>
<tr><td><code id="contour_+3A_abs.cont">abs.cont</code></td>
<td>
<p>vector of absolute contour levels</p>
</td></tr>
<tr><td><code id="contour_+3A_nlevels">nlevels</code></td>
<td>
<p>number of pretty contour levels</p>
</td></tr> 
<tr><td><code id="contour_+3A_approx">approx</code></td>
<td>
<p>flag to compute approximate contour levels. Default is
TRUE.</p>
</td></tr> 
<tr><td><code id="contour_+3A_which.deriv.ind">which.deriv.ind</code></td>
<td>
<p>partial derivative index. Default is 1.</p>
</td></tr> 
<tr><td><code id="contour_+3A_...">...</code></td>
<td>
<p>other parameters</p>
</td></tr>
</table>


<h3>Details</h3>

<p>&ndash;For <code>contourLevels</code>, the most straightforward is to specify <code>prob</code>.
The heights of the corresponding highest density region with probability <code>prob</code> are
computed. The <code>cont</code> parameter here is consistent with
<code>cont</code> parameter from <code>plot.kde</code>, <code>plot.kdde</code>, and <code>plot.kda</code>
i.e. <code>cont=(1-prob)*100%</code>. 
If both <code>prob</code> and <code>cont</code> are missing then a pretty set of
<code>nlevels</code> contours are computed.
</p>
<p>&ndash;For <code>contourSizes</code>, the length, area, volume etc. and for <code>contourProbs</code>, 
the probability, are approximated by Riemann sums. These are rough approximations and
depend highly on the estimation grid, and so should be interpreted carefully. 
</p>
<p>If <code>approx=FALSE</code>, then the exact KDE is computed. Otherwise
it is interpolated from an existing KDE grid: this can dramatically
reduce computation time for large data sets. 
</p>


<h3>Value</h3>

<p>&ndash;For <code>contourLevels</code>, for <code>kde</code> objects, returns vector of
heights.  For <code>kda</code> objects, returns a list of vectors, one for
each training group. For <code>kdde</code> objects, returns a matrix of
vectors, one row for each partial derivative. 
</p>
<p>&ndash;For <code>contourSizes</code>, returns an approximation of the Lebesgue measure of 
level set, i.e. length (d=1), area (d=2), volume (d=3), hyper-volume (d&gt;4).
</p>
<p>&ndash;For <code>contourProbs</code>, returns an approximation of the probability measure of 
level set. 
</p>


<h3>See Also</h3>

<p><code><a href="graphics.html#topic+contour">contour</a></code>, <code><a href="grDevices.html#topic+contourLines">contourLines</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(8192)
x &lt;- rmvnorm.mixt(n=1000, mus=c(0,0), Sigmas=diag(2), props=1)
fhat &lt;- kde(x=x, binned=TRUE)
contourLevels(fhat, cont=c(75, 50, 25))
contourProbs(fhat, abs.cont=contourLevels(fhat, cont=50))
  ## compare approx prob with target prob=0.5
contourSizes(fhat, cont=25, approx=TRUE) 
   ## compare to approx circle of radius=0.75 with area=1.77
</code></pre>

<hr>
<h2 id='grevillea'>Geographical locations of grevillea plants</h2><span id='topic+grevillea'></span>

<h3>Description</h3>

<p>This data set contains the geographical locations 
of the specimens of <em>Grevillea uncinulata</em>,
more commonly known as the Hook leaf grevillea, which is an endemic floral
species to south Western Australia. This region is
one of the 25 &lsquo;biodiversity hotspots&rsquo; which are 'areas featuring exceptional
concentrations of endemic species and experiencing exceptional loss of habitat'.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(grevillea)</code></pre>


<h3>Format</h3>

<p>A matrix with 222 rows and 2 columns. Each row corresponds to an
observed plant. The first column is the longitude (decimal degrees),
the second is the latitude (decimal degrees). </p>


<h3>Source</h3>

<p>CSIRO (2016) Atlas of Living Australia: <em>Grevillea uncinulata Diels</em>,
<a href="https://bie.ala.org.au/species/https://id.biodiversity.org.au/node/apni/2895039">https://bie.ala.org.au/species/https://id.biodiversity.org.au/node/apni/2895039</a>. Commonwealth Scientific and Industrial Research Organisation. Accessed 2016-03-11. 
</p>

<hr>
<h2 id='Hbcv'>Biased cross-validation (BCV) bandwidth matrix selector
for bivariate data</h2><span id='topic+Hbcv'></span><span id='topic+Hbcv.diag'></span>

<h3>Description</h3>

<p>BCV bandwidth matrix for bivariate data.</p>


<h3>Usage</h3>

<pre><code class='language-R'>Hbcv(x, whichbcv=1, Hstart, binned=FALSE, amise=FALSE, verbose=FALSE)
Hbcv.diag(x, whichbcv=1, Hstart, binned=FALSE, amise=FALSE, verbose=FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Hbcv_+3A_x">x</code></td>
<td>
<p>matrix of data values</p>
</td></tr>
<tr><td><code id="Hbcv_+3A_whichbcv">whichbcv</code></td>
<td>
<p>1 = BCV1, 2 = BCV2.  See details below.</p>
</td></tr>
<tr><td><code id="Hbcv_+3A_hstart">Hstart</code></td>
<td>
<p>initial bandwidth matrix, used in numerical optimisation</p>
</td></tr>
<tr><td><code id="Hbcv_+3A_binned">binned</code></td>
<td>
<p>flag for binned kernel estimation. Default is FALSE.</p>
</td></tr>
<tr><td><code id="Hbcv_+3A_amise">amise</code></td>
<td>
<p>flag to return the minimal BCV value. Default is FALSE.</p>
</td></tr>
<tr><td><code id="Hbcv_+3A_verbose">verbose</code></td>
<td>
<p>flag to print out progress information. Default is FALSE.</p>
</td></tr>  
</table>


<h3>Details</h3>

<p>Use <code>Hbcv</code> for unconstrained bandwidth matrices and <code>Hbcv.diag</code>
for diagonal bandwidth matrices. These selectors are only
available for bivariate data. Two types of BCV criteria are
considered here.  They are known as BCV1 and BCV2, from Sain, Baggerly
&amp; Scott (1994) and only differ slightly. These BCV
surfaces can have multiple minima and so it can be quite difficult to
locate the most appropriate minimum. Some times, there can be no local minimum at all so there
may be no finite BCV selector.
</p>
<p>For details about the advanced options for <code>binned</code>, <code>Hstart</code>, see <code><a href="#topic+Hpi">Hpi</a></code>.
</p>


<h3>Value</h3>

<p>BCV bandwidth matrix. If <code>amise=TRUE</code> then the minimal BCV value is returned too. 
</p>


<h3>References</h3>

<p>Sain, S.R, Baggerly, K.A. &amp; Scott, D.W. (1994)
Cross-validation of multivariate densities. <em>Journal of the
American Statistical Association</em>, <b>82</b>, 1131-1146.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Hlscv">Hlscv</a></code>, <code><a href="#topic+Hpi">Hpi</a></code>, <code><a href="#topic+Hscv">Hscv</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>data(unicef)
Hbcv(unicef)
Hbcv.diag(unicef)
</code></pre>

<hr>
<h2 id='histde'>Histogram density estimate</h2><span id='topic+histde'></span><span id='topic+predict.histde'></span>

<h3>Description</h3>

<p>Histogram density estimate for 1- and 2-dimensional data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>histde(x, binw, xmin, xmax, adj=0)

## S3 method for class 'histde'
predict(object, ..., x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="histde_+3A_x">x</code></td>
<td>
<p>matrix of data values</p>
</td></tr>
<tr><td><code id="histde_+3A_binw">binw</code></td>
<td>
<p>(vector) of binwidths</p>
</td></tr>
<tr><td><code id="histde_+3A_xmin">xmin</code>, <code id="histde_+3A_xmax">xmax</code></td>
<td>
<p>vector of minimum/maximum values for grid</p>
</td></tr>
<tr><td><code id="histde_+3A_adj">adj</code></td>
<td>
<p>displacement of default anchor point, in percentage of 1
bin</p>
</td></tr>
<tr><td><code id="histde_+3A_object">object</code></td>
<td>
<p>object of class <code>histde</code></p>
</td></tr>
<tr><td><code id="histde_+3A_...">...</code></td>
<td>
<p>other parameters</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If <code>binw</code> is missing, the default binwidth is <code class="reqn">\hat{b}_i = 2 \cdot 3^{1/(d+2)} \pi^{d/(2d+4)} S_i
  n^{-1/(d+2)}</code>, the
normal scale selector.  
</p>
<p>If <code>xmin</code> is missing then it defaults to the data minimum.  If
<code>xmax</code> is missing then it defaults to the data maximum.  
</p>


<h3>Value</h3>

<p>A histogram density estimate is an object of class <code>histde</code> which is a
list with fields: 
</p>
<table role = "presentation">
<tr><td><code>x</code></td>
<td>
<p>data points - same as input</p>
</td></tr>
<tr><td><code>eval.points</code></td>
<td>
<p>vector or list of points at which the estimate is evaluated</p>
</td></tr>
<tr><td><code>estimate</code></td>
<td>
<p>density estimate at <code>eval.points</code></p>
</td></tr>
<tr><td><code>binw</code></td>
<td>
<p>(vector of) bandwidths</p>
</td></tr>
<tr><td><code>nbin</code></td>
<td>
<p>(vector of) number of bins</p>
</td></tr>
<tr><td><code>names</code></td>
<td>
<p>variable names</p>
</td></tr>   
</table>


<h3>See Also</h3>

<p><code><a href="#topic+plot.histde">plot.histde</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## positive data example
set.seed(8192)
x &lt;- 2^rnorm(100)
fhat &lt;- histde(x=x)
plot(fhat, border=6)
points(c(0.5, 1), predict(fhat, x=c(0.5, 1)))

## large data example on a non-default grid
set.seed(8192)
x &lt;- rmvnorm.mixt(10000, mus=c(0,0), Sigmas=invvech(c(1,0.8,1)))
fhat &lt;- histde(x=x, xmin=c(-5,-5), xmax=c(5,5))
plot(fhat)

## See other examples in ? plot.histde
</code></pre>

<hr>
<h2 id='Hlscv'>Least-squares cross-validation (LSCV) bandwidth matrix selector
for multivariate data</h2><span id='topic+Hlscv'></span><span id='topic+Hlscv.diag'></span><span id='topic+Hucv'></span><span id='topic+Hucv.diag'></span><span id='topic+hlscv'></span><span id='topic+hucv'></span>

<h3>Description</h3>

<p>LSCV bandwidth for 1- to 6-dimensional data</p>


<h3>Usage</h3>

<pre><code class='language-R'>Hlscv(x, Hstart, binned, bgridsize, amise=FALSE, deriv.order=0, 
      verbose=FALSE, optim.fun="optim", trunc)
Hlscv.diag(x, Hstart, binned, bgridsize, amise=FALSE, deriv.order=0, 
      verbose=FALSE, optim.fun="optim", trunc)
hlscv(x, binned=TRUE, bgridsize, amise=FALSE, deriv.order=0, bw.ucv=TRUE)
Hucv(...)
Hucv.diag(...)
hucv(...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Hlscv_+3A_x">x</code></td>
<td>
<p>vector or matrix of data values</p>
</td></tr>
<tr><td><code id="Hlscv_+3A_hstart">Hstart</code></td>
<td>
<p>initial bandwidth matrix, used in numerical
optimisation</p>
</td></tr>
<tr><td><code id="Hlscv_+3A_binned">binned</code></td>
<td>
<p>flag for binned kernel estimation</p>
</td></tr>
<tr><td><code id="Hlscv_+3A_bgridsize">bgridsize</code></td>
<td>
<p>vector of binning grid sizes</p>
</td></tr>
<tr><td><code id="Hlscv_+3A_amise">amise</code></td>
<td>
<p>flag to return the minimal LSCV value. Default is FALSE.</p>
</td></tr>	
<tr><td><code id="Hlscv_+3A_deriv.order">deriv.order</code></td>
<td>
<p>derivative order</p>
</td></tr> 
<tr><td><code id="Hlscv_+3A_verbose">verbose</code></td>
<td>
<p>flag to print out progress information. Default is FALSE.</p>
</td></tr>
<tr><td><code id="Hlscv_+3A_optim.fun">optim.fun</code></td>
<td>
<p>optimiser function: one of <code>nlm</code> or <code>optim</code></p>
</td></tr>
<tr><td><code id="Hlscv_+3A_trunc">trunc</code></td>
<td>
<p>parameter to control truncation for numerical
optimisation. Default is 4 for density.deriv&gt;0, otherwise no
truncation. For details see below.</p>
</td></tr>
<tr><td><code id="Hlscv_+3A_bw.ucv">bw.ucv</code></td>
<td>
<p>flag to use <code>stats::bw.ucv</code> as minimiser function. Default is TRUE.</p>
</td></tr>
<tr><td><code id="Hlscv_+3A_...">...</code></td>
<td>
<p>parameters as above</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>hlscv</code> is the univariate LSCV
selector of Bowman (1984) and Rudemo (1982). <code>Hlscv</code> is a
multivariate generalisation of this. Use <code>Hlscv</code> for unconstrained
bandwidth matrices and <code>Hlscv.diag</code> for diagonal bandwidth matrices. 
<code>Hucv</code>, <code>Hucv.diag</code> and <code>hucv</code> are aliases with UCV
(unbiased cross validation) instead of LSCV. 
</p>
<p>For <span class="pkg">ks</span> <code class="reqn">\geq</code> 1.13.0, the default minimiser in <code>hlscv</code> is based on the UCV minimiser 
<code>stats::bw.ucv</code>. To reproduce prior behaviour, set <code>bw.ucv=FALSE</code>. 
</p>
<p>Truncation of the parameter space is usually required for the LSCV selector,
for r &gt; 0, to find a reasonable solution to the numerical optimisation. 
If a candidate matrix <code>H</code> is
such that <code>det(H)</code> is not in <code>[1/trunc, trunc]*det(H0)</code> or  
<code>abs(LSCV(H)) &gt; trunc*abs(LSCV0)</code> then the <code>LSCV(H)</code> is reset to <code>LSCV0</code> where 
<code>H0=Hns(x)</code> and <code>LSCV0=LSCV(H0)</code>.
</p>
<p>For details about the advanced options for <code>binned,Hstart,optim.fun</code>, 
see <code><a href="#topic+Hpi">Hpi</a></code>. 
</p>


<h3>Value</h3>

<p>LSCV bandwidth. If <code>amise=TRUE</code> then the minimal LSCV value is returned too. 
</p>


<h3>References</h3>

<p>Bowman, A. (1984) An alternative method of cross-validation for the
smoothing of kernel density estimates. <em>Biometrika</em>, <b>71</b>,
353-360.
</p>
<p>Rudemo, M. (1982) Empirical choice of histograms and kernel density
estimators. <em>Scandinavian Journal of Statistics</em>, <b>9</b>,
65-78.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Hbcv">Hbcv</a></code>, <code><a href="#topic+Hpi">Hpi</a></code>, <code><a href="#topic+Hscv">Hscv</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>data(forbes, package="MASS")
Hlscv(forbes)
hlscv(forbes$bp)
</code></pre>

<hr>
<h2 id='Hnm'>Normal mixture bandwidth</h2><span id='topic+Hnm'></span><span id='topic+hnm'></span><span id='topic+Hnm.diag'></span>

<h3>Description</h3>

<p>Normal mixture bandwidth.  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Hnm(x, deriv.order=0, G=1:9, subset.ind, mise.flag=FALSE, verbose, ...)
Hnm.diag(x, deriv.order=0, G=1:9, subset.ind, mise.flag=FALSE, verbose, ...)
hnm(x, deriv.order=0, G=1:9, subset.ind, mise.flag=FALSE, verbose, ... )
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Hnm_+3A_x">x</code></td>
<td>
<p>vector/matrix of data values</p>
</td></tr>
<tr><td><code id="Hnm_+3A_deriv.order">deriv.order</code></td>
<td>
<p>derivative order</p>
</td></tr>
<tr><td><code id="Hnm_+3A_g">G</code></td>
<td>
<p>range of number of mixture components</p>
</td></tr>
<tr><td><code id="Hnm_+3A_subset.ind">subset.ind</code></td>
<td>
<p>index vector of subset of <code>x</code> for fitting</p>
</td></tr>
<tr><td><code id="Hnm_+3A_mise.flag">mise.flag</code></td>
<td>
<p>flag to use MISE or AMISE minimisation. Default is FALSE.</p>
</td></tr>
<tr><td><code id="Hnm_+3A_verbose">verbose</code></td>
<td>
<p>flag to print out progress information. Default is FALSE.</p>
</td></tr>
<tr><td><code id="Hnm_+3A_...">...</code></td>
<td>
<p>other parameters for <code>Mclust</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>The normal mixture fit is provided by the <code>Mclust</code> function in
the <span class="pkg">mclust</span> package. <code>Hnm</code> is then <code>Hmise.mixt</code> (if
<code>mise.flag=TRUE</code>) or <code>Hamise.mixt</code> (if <code>mise.flag=FALSE</code>) with
these fitted normal mixture parameters. Likewise for 
<code>Hnm.diag</code>, <code>hnm</code>.   
</p>


<h3>Value</h3>

<p>Normal mixture bandwidth. If <code>mise=TRUE</code> then the minimal MISE value is returned too. 
</p>


<h3>References</h3>

<p>Cwik, J. &amp; Koronacki, J.  (1997). A combined
adaptive-mixtures/plug-in estimator of multivariate probability
densities. <em>Computational Statistics and Data Analysis</em>,
<b>26</b>, 199-218.   
</p>


<h3>See Also</h3>

 <p><a href="#topic+Hmise.mixt">Hmise.mixt</a>, <a href="#topic+Hamise.mixt">Hamise.mixt</a> </p>


<h3>Examples</h3>

<pre><code class='language-R'>data(unicef)
Hnm(unicef) 
</code></pre>

<hr>
<h2 id='Hns'>Normal scale bandwidth</h2><span id='topic+Hns'></span><span id='topic+Hns.diag'></span><span id='topic+hns'></span><span id='topic+Hns.kcde'></span><span id='topic+hns.kcde'></span>

<h3>Description</h3>

<p>Normal scale bandwidth.  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Hns(x, deriv.order=0)
Hns.diag(x)
hns(x, deriv.order=0)
Hns.kcde(x)
hns.kcde(x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Hns_+3A_x">x</code></td>
<td>
<p>vector/matrix of data values</p>
</td></tr>
<tr><td><code id="Hns_+3A_deriv.order">deriv.order</code></td>
<td>
<p>derivative order</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>Hns</code> is equal to <code>(4/(n*(d+2*r+2)))^(2/(d+2*r+4))*var(x)</code>,
n = sample size, d = dimension of data, r = derivative
order. <code>hns</code> is the analogue  of <code>Hns</code> for 1-d data. These
can be used for density (derivative) estimators
<code><a href="#topic+kde">kde</a></code>, <code><a href="#topic+kdde">kdde</a></code>. 
The equivalents for distribution estimators <code><a href="#topic+kcde">kcde</a></code> are
<code>Hns.kcde</code> and <code>hns.cde</code>. 
</p>


<h3>Value</h3>

<p>Normal scale bandwidth. 
</p>


<h3>References</h3>

<p>Chacon J.E., Duong, T. &amp; Wand, M.P. (2011). Asymptotics for
general multivariate kernel density derivative
estimators. <em>Statistica Sinica</em>, <b>21</b>, 807-840.   
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(forbes, package="MASS")
Hns(forbes, deriv.order=2)
hns(forbes$bp, deriv.order=2)
</code></pre>

<hr>
<h2 id='Hpi'>Plug-in bandwidth selector</h2><span id='topic+Hpi'></span><span id='topic+Hpi.diag'></span><span id='topic+hpi'></span>

<h3>Description</h3>

<p>Plug-in bandwidth for for 1- to 6-dimensional data.</p>


<h3>Usage</h3>

<pre><code class='language-R'>Hpi(x, nstage=2, pilot, pre="sphere", Hstart, binned, bgridsize,
   amise=FALSE, deriv.order=0, verbose=FALSE, optim.fun="optim")
Hpi.diag(x, nstage=2, pilot, pre="scale", Hstart, binned, bgridsize,
   amise=FALSE, deriv.order=0, verbose=FALSE, optim.fun="optim")
hpi(x, nstage=2, binned=TRUE, bgridsize, deriv.order=0)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Hpi_+3A_x">x</code></td>
<td>
<p>vector or matrix of data values</p>
</td></tr>
<tr><td><code id="Hpi_+3A_nstage">nstage</code></td>
<td>
<p>number of stages in the plug-in bandwidth selector (1 or 2)</p>
</td></tr>
<tr><td><code id="Hpi_+3A_pilot">pilot</code></td>
<td>
<p>&quot;amse&quot; = AMSE pilot bandwidths <br />
&quot;samse&quot; = single SAMSE pilot bandwidth <br /> 
&quot;unconstr&quot; = single unconstrained pilot bandwidth <br />
&quot;dscalar&quot; = single pilot bandwidth for deriv.order &gt;= 0 <br />
&quot;dunconstr&quot; = single unconstrained pilot bandwidth for deriv.order &gt;= 0</p>
</td></tr>
<tr><td><code id="Hpi_+3A_pre">pre</code></td>
<td>
<p>&quot;scale&quot; = <code><a href="#topic+pre.scale">pre.scale</a></code>, &quot;sphere&quot; = <code><a href="#topic+pre.sphere">pre.sphere</a></code></p>
</td></tr>
<tr><td><code id="Hpi_+3A_hstart">Hstart</code></td>
<td>
<p>initial bandwidth matrix, used in numerical
optimisation</p>
</td></tr>
<tr><td><code id="Hpi_+3A_binned">binned</code></td>
<td>
<p>flag for binned kernel estimation</p>
</td></tr>
<tr><td><code id="Hpi_+3A_bgridsize">bgridsize</code></td>
<td>
<p>vector of binning grid sizes</p>
</td></tr>
<tr><td><code id="Hpi_+3A_amise">amise</code></td>
<td>
<p>flag to return the minimal scaled PI value</p>
</td></tr>
<tr><td><code id="Hpi_+3A_deriv.order">deriv.order</code></td>
<td>
<p>derivative order</p>
</td></tr>
<tr><td><code id="Hpi_+3A_verbose">verbose</code></td>
<td>
<p>flag to print out progress information. Default is FALSE.</p>
</td></tr>
<tr><td><code id="Hpi_+3A_optim.fun">optim.fun</code></td>
<td>
<p>optimiser function: one of <code>nlm</code> or <code>optim</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>hpi(,deriv.order=0)</code> is the univariate plug-in 
selector of Wand &amp; Jones (1994), i.e. it is exactly the same as
<span class="pkg">KernSmooth</span>'s <code>dpik</code>. For deriv.order&gt;0, the formula is
taken from Wand &amp; Jones (1995). <code>Hpi</code> is a multivariate
generalisation of this. Use <code>Hpi</code> for unconstrained bandwidth matrices and
<code>Hpi.diag</code> for diagonal bandwidth matrices.
</p>
<p>The default pilot is <code>"samse"</code> for d=2,r=0, and
<code>"dscalar"</code> otherwise.
For AMSE pilot bandwidths, see Wand &amp; Jones (1994). For
SAMSE pilot bandwidths, see Duong &amp; Hazelton (2003).  The latter is a
modification of the former, in order to remove any possible problems
with non-positive definiteness. Unconstrained and higher order
derivative pilot bandwidths are from Chacon &amp; Duong (2010). 
</p>
<p>For d=1, 2, 3, 4 and <code>binned=TRUE</code>, 
estimates are computed over a binning grid defined 
by <code>bgridsize</code>. Otherwise it's computed exactly.  
If <code>Hstart</code> is not given then it defaults to <code>Hns(x)</code>.
</p>
<p>For <span class="pkg">ks</span> <code class="reqn">\geq</code> 1.11.1, the default optimisation function is
<code>optim.fun="optim"</code>. To reinstate the previous functionality, use
<code>optim.fun="nlm"</code>.  
</p>


<h3>Value</h3>

<p>Plug-in bandwidth. 
If <code>amise=TRUE</code> then the minimal scaled PI value is returned too.</p>


<h3>References</h3>

<p>Chacon, J.E. &amp; Duong, T. (2010) Multivariate plug-in bandwidth
selection with unconstrained pilot matrices. <em>Test</em>, <b>19</b>, 375-398.
</p>
<p>Duong, T. &amp; Hazelton, M.L. (2003) Plug-in bandwidth matrices for
bivariate kernel density estimation. <em>Journal of Nonparametric
Statistics</em>, <b>15</b>, 17-30.
</p>
<p>Sheather, S.J. &amp; Jones, M.C. (1991) A reliable data-based bandwidth selection
method for kernel density estimation. <em>Journal of the Royal
Statistical Society Series B</em>, <b>53</b>, 683-690.
</p>
<p>Wand, M.P. &amp; Jones, M.C. (1994) Multivariate plug-in bandwidth
selection. <em>Computational Statistics</em>, <b>9</b>, 97-116.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Hbcv">Hbcv</a></code>, <code><a href="#topic+Hlscv">Hlscv</a></code>, <code><a href="#topic+Hscv">Hscv</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>data(unicef)
Hpi(unicef, pilot="dscalar")
hpi(unicef[,1])
</code></pre>

<hr>
<h2 id='hsct'>Haematopoietic stem cell transplant</h2><span id='topic+hsct'></span>

<h3>Description</h3>

<p>This data set contains the haematopoietic stem cell transplant (HSCT)
measurements obtained by a flow cytometer from mouse subjects. A flow
cytometer measures the spectra of fluorescent signals from biological
cell samples to study their properties.    
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(hsct)</code></pre>


<h3>Format</h3>

<p>A matrix with 39128 rows and 6 columns.
The first column is the FITC-CD45.1 fluorescence (0-1023), 
the second is the PE-Ly65/Mac1 fluorescence (0-1023),
the third is the PI-LiveDead fluorescence (0-1023),
the fourth is the APC-CD45.2 fluorescence (0-1023),
the fifth is the class label of the cell type (1, 2, 3, 4, 5),
the sixth the mouse subject number (5, 6, 9, 12).
</p>


<h3>Source</h3>

<p>Aghaeepour, N., Finak, G., The FlowCAP Consortium, The DREAM Consortium,
Hoos, H., Mosmann, T. R., Brinkman, R., Gottardo, R. &amp; Scheuermann, R. H. (2013) Critical assessment of automated flow cytometry data analysis techniques, <em>Nature Methods</em> <b>10</b>, 228-238.
</p>

<hr>
<h2 id='Hscv'>Smoothed cross-validation (SCV) bandwidth selector</h2><span id='topic+Hscv'></span><span id='topic+Hscv.diag'></span><span id='topic+hscv'></span>

<h3>Description</h3>

<p>SCV bandwidth for 1- to 6-dimensional data.</p>


<h3>Usage</h3>

<pre><code class='language-R'>Hscv(x, nstage=2, pre="sphere", pilot, Hstart, binned, 
     bgridsize, amise=FALSE, deriv.order=0, verbose=FALSE, optim.fun="optim")
Hscv.diag(x, nstage=2, pre="scale", pilot, Hstart, binned, 
     bgridsize, amise=FALSE, deriv.order=0, verbose=FALSE, optim.fun="optim")
hscv(x, nstage=2, binned=TRUE, bgridsize, plot=FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Hscv_+3A_x">x</code></td>
<td>
<p>vector or matrix of data values</p>
</td></tr>
<tr><td><code id="Hscv_+3A_pre">pre</code></td>
<td>
<p>&quot;scale&quot; = <code><a href="#topic+pre.scale">pre.scale</a></code>, &quot;sphere&quot; = <code><a href="#topic+pre.sphere">pre.sphere</a></code></p>
</td></tr>
<tr><td><code id="Hscv_+3A_pilot">pilot</code></td>
<td>
<p>&quot;amse&quot; = AMSE pilot bandwidths <br />
&quot;samse&quot; = single SAMSE pilot bandwidth <br /> 
&quot;unconstr&quot; = single unconstrained pilot bandwidth <br />
&quot;dscalar&quot; = single pilot bandwidth for deriv.order&gt;0 <br />
&quot;dunconstr&quot; = single unconstrained pilot bandwidth for deriv.order&gt;0</p>
</td></tr>
<tr><td><code id="Hscv_+3A_hstart">Hstart</code></td>
<td>
<p>initial bandwidth matrix, used in numerical
optimisation</p>
</td></tr>
<tr><td><code id="Hscv_+3A_binned">binned</code></td>
<td>
<p>flag for binned kernel estimation</p>
</td></tr>
<tr><td><code id="Hscv_+3A_bgridsize">bgridsize</code></td>
<td>
<p>vector of binning grid sizes</p>
</td></tr>
<tr><td><code id="Hscv_+3A_amise">amise</code></td>
<td>
<p>flag to return the minimal scaled SCV value. Default is FALSE.</p>
</td></tr>
<tr><td><code id="Hscv_+3A_deriv.order">deriv.order</code></td>
<td>
<p>derivative order</p>
</td></tr>
<tr><td><code id="Hscv_+3A_verbose">verbose</code></td>
<td>
<p>flag to print out progress information. Default is FALSE.</p>
</td></tr>
<tr><td><code id="Hscv_+3A_optim.fun">optim.fun</code></td>
<td>
<p>optimiser function: one of <code>nlm</code> or <code>optim</code></p>
</td></tr>
<tr><td><code id="Hscv_+3A_nstage">nstage</code></td>
<td>
<p>number of stages in the SCV bandwidth selector (1 or 2)</p>
</td></tr>
<tr><td><code id="Hscv_+3A_plot">plot</code></td>
<td>
<p>flag to display plot of SCV(h) vs h (1-d only). Default is FALSE.</p>
</td></tr>
</table>


<h3>Details</h3>

 <p><code>hscv</code> is the univariate SCV
selector of Jones, Marron &amp; Park (1991). <code>Hscv</code> is a
multivariate generalisation of this, see Duong &amp; Hazelton (2005).
Use <code>Hscv</code> for unconstrained bandwidth matrices and <code>Hscv.diag</code>
for diagonal bandwidth matrices. 
</p>
<p>The default pilot is <code>"samse"</code> for d=2, r=0, and
<code>"dscalar"</code> otherwise. For SAMSE pilot bandwidths, see Duong &amp;
Hazelton (2005). Unconstrained and higher order derivative pilot
bandwidths are from Chacon &amp; Duong (2011).  
</p>
<p>For d=1, the selector <code>hscv</code> is not always stable for large
sample sizes with binning.
Examine the plot from <code>hscv(, plot=TRUE)</code> to
determine the appropriate smoothness of the SCV function. Any
non-smoothness is due to the discretised nature of binned estimation.
</p>
<p>For details about the advanced options for <code>binned, Hstart, optim.fun</code>, 
see <code><a href="#topic+Hpi">Hpi</a></code>.
</p>


<h3>Value</h3>

<p>SCV bandwidth. If <code>amise=TRUE</code> then the minimal scaled SCV value is returned too. 
</p>


<h3>References</h3>

<p>Chacon, J.E. &amp; Duong, T. (2011) Unconstrained pilot selectors for
smoothed cross validation. <em>Australian &amp; New Zealand Journal of
Statistics</em>, <b>53</b>, 331-351. 
</p>
<p>Duong, T. &amp; Hazelton, M.L. (2005) Cross-validation bandwidth
matrices for multivariate kernel density
estimation. <em>Scandinavian Journal of Statistics</em>, <b>32</b>, 485-506.
</p>
<p>Jones, M.C., Marron, J.S. &amp; Park, B.U. (1991) A simple root <code class="reqn">n</code>
bandwidth selector. <em>Annals of Statistics</em>, <b>19</b>, 1919-1932.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Hbcv">Hbcv</a></code>, <code><a href="#topic+Hlscv">Hlscv</a></code>, <code><a href="#topic+Hpi">Hpi</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>data(unicef)
Hscv(unicef)
hscv(unicef[,1])
</code></pre>

<hr>
<h2 id='ise.mixt'>Squared error bandwidth matrix selectors for normal
mixture densities</h2><span id='topic+Hmise.mixt'></span><span id='topic+Hamise.mixt'></span><span id='topic+Hmise.mixt.diag'></span><span id='topic+Hamise.mixt.diag'></span><span id='topic+hmise.mixt'></span><span id='topic+hamise.mixt'></span><span id='topic+ise.mixt'></span><span id='topic+amise.mixt'></span><span id='topic+mise.mixt'></span>

<h3>Description</h3>

<p>The global errors
ISE (Integrated Squared Error), MISE (Mean Integrated Squared Error) and the 
AMISE (Asymptotic Mean Integrated Squared Error) for 1- to 6-dimensional
data. Normal mixture densities have closed form expressions for the MISE and
AMISE. So in these cases, we can numerically minimise these criteria
to find MISE- and AMISE-optimal matrices.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Hamise.mixt(mus, Sigmas, props, samp, Hstart, deriv.order=0)
Hmise.mixt(mus, Sigmas, props, samp, Hstart, deriv.order=0)
Hamise.mixt.diag(mus, Sigmas, props, samp, Hstart, deriv.order=0)
Hmise.mixt.diag(mus, Sigmas, props, samp, Hstart, deriv.order=0)
hamise.mixt(mus, sigmas, props, samp, hstart, deriv.order=0)
hmise.mixt(mus, sigmas, props, samp, hstart, deriv.order=0)
amise.mixt(H, mus, Sigmas, props, samp, h, sigmas, deriv.order=0)
ise.mixt(x, H, mus, Sigmas, props, h, sigmas, deriv.order=0, binned=FALSE, 
         bgridsize)  
mise.mixt(H, mus, Sigmas, props, samp, h, sigmas, deriv.order=0)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ise.mixt_+3A_mus">mus</code></td>
<td>
<p>(stacked) matrix of mean vectors (&gt;1-d), vector of means (1-d)</p>
</td></tr>
<tr><td><code id="ise.mixt_+3A_sigmas">Sigmas</code>, <code id="ise.mixt_+3A_sigmas">sigmas</code></td>
<td>
<p>(stacked) matrix of variance matrices (&gt;1-d), vector of standard deviations (1-d)</p>
</td></tr>
<tr><td><code id="ise.mixt_+3A_props">props</code></td>
<td>
<p>vector of mixing proportions</p>
</td></tr>
<tr><td><code id="ise.mixt_+3A_samp">samp</code></td>
<td>
<p>sample size</p>
</td></tr>
<tr><td><code id="ise.mixt_+3A_hstart">Hstart</code>, <code id="ise.mixt_+3A_hstart">hstart</code></td>
<td>
<p>initial bandwidth (matrix), used in numerical optimisation</p>
</td></tr>
<tr><td><code id="ise.mixt_+3A_deriv.order">deriv.order</code></td>
<td>
<p>derivative order</p>
</td></tr>
<tr><td><code id="ise.mixt_+3A_x">x</code></td>
<td>
<p>matrix of data values</p>
</td></tr>
<tr><td><code id="ise.mixt_+3A_h">H</code>, <code id="ise.mixt_+3A_h">h</code></td>
<td>
<p>bandwidth (matrix)</p>
</td></tr>
<tr><td><code id="ise.mixt_+3A_binned">binned</code></td>
<td>
<p>flag for binned kernel estimation. Default is FALSE.</p>
</td></tr>
<tr><td><code id="ise.mixt_+3A_bgridsize">bgridsize</code></td>
<td>
<p>vector of binning grid sizes</p>
</td></tr>
</table>


<h3>Details</h3>

<p>ISE is a random variable that depends on the data
<code>x</code>. MISE and AMISE are non-random and don't
depend on the data. For normal mixture densities, ISE, MISE and AMISE 
have exact formulas for all dimensions.
</p>


<h3>Value</h3>

<p>MISE- or AMISE-optimal bandwidth matrix. ISE, MISE or AMISE value. 
</p>


<h3>References</h3>

<p>Chacon J.E., Duong, T. &amp; Wand, M.P. (2011). Asymptotics for
general multivariate kernel density derivative
estimators. <em>Statistica Sinica</em>, <b>21</b>, 807-840.  
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- rmvnorm.mixt(100)
Hamise.mixt(samp=nrow(x), mus=rep(0,2), Sigmas=var(x), props=1, deriv.order=1)
</code></pre>

<hr>
<h2 id='kcde'>Kernel cumulative distribution/survival function estimate</h2><span id='topic+kcde'></span><span id='topic+Hpi.kcde'></span><span id='topic+Hpi.diag.kcde'></span><span id='topic+hpi.kcde'></span><span id='topic+predict.kcde'></span>

<h3>Description</h3>

<p>Kernel cumulative distribution/survival function estimate for 1- to 3-dimensional data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>kcde(x, H, h, gridsize, gridtype, xmin, xmax, supp=3.7, eval.points, binned, 
  bgridsize, positive=FALSE, adj.positive, w, verbose=FALSE, 
  tail.flag="lower.tail")
Hpi.kcde(x, nstage=2, pilot, Hstart, binned, bgridsize, amise=FALSE, 
  verbose=FALSE, optim.fun="optim", pre=TRUE)
Hpi.diag.kcde(x, nstage=2, pilot, Hstart, binned, bgridsize, amise=FALSE,
  verbose=FALSE, optim.fun="optim", pre=TRUE)
hpi.kcde(x, nstage=2, binned, amise=FALSE)

## S3 method for class 'kcde'
predict(object, ..., x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="kcde_+3A_x">x</code></td>
<td>
<p>matrix of data values</p>
</td></tr>
<tr><td><code id="kcde_+3A_h">H</code>, <code id="kcde_+3A_h">h</code></td>
<td>
<p>bandwidth matrix/scalar bandwidth. If these are missing, then
<code>Hpi.kcde</code> or <code>hpi.kcde</code> is called by default.</p>
</td></tr>
<tr><td><code id="kcde_+3A_gridsize">gridsize</code></td>
<td>
<p>vector of number of grid points</p>
</td></tr>
<tr><td><code id="kcde_+3A_gridtype">gridtype</code></td>
<td>
<p>not yet implemented</p>
</td></tr>
<tr><td><code id="kcde_+3A_xmin">xmin</code>, <code id="kcde_+3A_xmax">xmax</code></td>
<td>
<p>vector of minimum/maximum values for grid</p>
</td></tr>
<tr><td><code id="kcde_+3A_supp">supp</code></td>
<td>
<p>effective support for standard normal</p>
</td></tr>
<tr><td><code id="kcde_+3A_eval.points">eval.points</code></td>
<td>
<p>vector or matrix of points at which estimate is evaluated</p>
</td></tr>
<tr><td><code id="kcde_+3A_binned">binned</code></td>
<td>
<p>flag for binned estimation. Default is FALSE.</p>
</td></tr>
<tr><td><code id="kcde_+3A_bgridsize">bgridsize</code></td>
<td>
<p>vector of binning grid sizes</p>
</td></tr>
<tr><td><code id="kcde_+3A_positive">positive</code></td>
<td>
<p>flag if 1-d data are positive. Default is FALSE.</p>
</td></tr>
<tr><td><code id="kcde_+3A_adj.positive">adj.positive</code></td>
<td>
<p>adjustment applied to positive 1-d data</p>
</td></tr>
<tr><td><code id="kcde_+3A_w">w</code></td>
<td>
<p>not yet implemented</p>
</td></tr>
<tr><td><code id="kcde_+3A_verbose">verbose</code></td>
<td>
<p>flag to print out progress information. Default is
FALSE.</p>
</td></tr>
<tr><td><code id="kcde_+3A_tail.flag">tail.flag</code></td>
<td>
<p>&quot;lower.tail&quot; = cumulative distribution, &quot;upper.tail&quot; =
survival function</p>
</td></tr>
<tr><td><code id="kcde_+3A_nstage">nstage</code></td>
<td>
<p>number of stages in the plug-in bandwidth selector (1 or 2)</p>
</td></tr>
<tr><td><code id="kcde_+3A_pilot">pilot</code></td>
<td>
<p>&quot;dscalar&quot; = single pilot bandwidth (default for
<code>Hpi.diag.kcde</code> <br />
&quot;dunconstr&quot; = single unconstrained pilot bandwidth (default for
<code>Hpi.kcde</code></p>
</td></tr> 
<tr><td><code id="kcde_+3A_hstart">Hstart</code></td>
<td>
<p>initial bandwidth matrix, used in numerical
optimisation</p>
</td></tr>
<tr><td><code id="kcde_+3A_amise">amise</code></td>
<td>
<p>flag to return the minimal scaled PI value</p>
</td></tr>
<tr><td><code id="kcde_+3A_optim.fun">optim.fun</code></td>
<td>
<p>optimiser function: one of <code>nlm</code> or
<code>optim</code></p>
</td></tr>
<tr><td><code id="kcde_+3A_pre">pre</code></td>
<td>
<p>flag for pre-scaling data. Default is TRUE.</p>
</td></tr>
<tr><td><code id="kcde_+3A_object">object</code></td>
<td>
<p>object of class <code>kcde</code></p>
</td></tr>
<tr><td><code id="kcde_+3A_...">...</code></td>
<td>
<p>other parameters</p>
</td></tr> 
</table>


<h3>Details</h3>

<p>If <code>tail.flag="lower.tail"</code> then the cumulative distribution
function <code class="reqn">\mathrm{Pr}(\bold{X}\leq\bold{x})</code> is estimated, otherwise
if <code>tail.flag="upper.tail"</code>, it is the survival function
<code class="reqn">\mathrm{Pr}(\bold{X}&gt;\bold{x})</code>. For <code class="reqn">d&gt;1</code>,
<code class="reqn">\mathrm{Pr}(\bold{X}\leq\bold{x}) \neq 1 - \mathrm{Pr}(\bold{X}&gt;\bold{x})</code>.
</p>
<p>If the bandwidth <code>H</code> is missing in <code>kcde</code>, then
the default bandwidth is the plug-in selector
<code>Hpi.kcde</code>. Likewise for missing <code>h</code>.
No pre-scaling/pre-sphering is used since the <code>Hpi.kcde</code> is not
invariant to translation/dilation.
</p>
<p>The effective support, binning, grid size, grid range, positive, optimisation function
parameters are the same as <code><a href="#topic+kde">kde</a></code>.
</p>


<h3>Value</h3>

<p>A kernel cumulative distribution estimate is an object of class
<code>kcde</code> which is a list with fields:
</p>
<table role = "presentation">
<tr><td><code>x</code></td>
<td>
<p>data points - same as input</p>
</td></tr>
<tr><td><code>eval.points</code></td>
<td>
<p>vector or list of points at which the estimate is evaluated</p>
</td></tr>
<tr><td><code>estimate</code></td>
<td>
<p>cumulative distribution/survival function estimate at
<code>eval.points</code></p>
</td></tr> 
<tr><td><code>h</code></td>
<td>
<p>scalar bandwidth (1-d only)</p>
</td></tr>
<tr><td><code>H</code></td>
<td>
<p>bandwidth matrix</p>
</td></tr>
<tr><td><code>gridtype</code></td>
<td>
<p>&quot;linear&quot;</p>
</td></tr>
<tr><td><code>gridded</code></td>
<td>
<p>flag for estimation on a grid</p>
</td></tr>
<tr><td><code>binned</code></td>
<td>
<p>flag for binned estimation</p>
</td></tr>
<tr><td><code>names</code></td>
<td>
<p>variable names</p>
</td></tr>
<tr><td><code>w</code></td>
<td>
<p>vector of weights</p>
</td></tr>
<tr><td><code>tail</code></td>
<td>
<p>&quot;lower.tail&quot;=cumulative distribution, &quot;upper.tail&quot;=survival function</p>
</td></tr>
</table>


<h3>References</h3>

<p>Duong, T. (2016) Non-parametric smoothed estimation of multivariate
cumulative distribution and survival functions, and receiver operating
characteristic curves. <em>Journal of the Korean Statistical
Society</em>, <b>45</b>, 33-50.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+kde">kde</a></code>, <code><a href="#topic+plot.kcde">plot.kcde</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>data(iris)
Fhat &lt;- kcde(iris[,1:2])  
predict(Fhat, x=as.matrix(iris[,1:2]))

## See other examples in ? plot.kcde
</code></pre>

<hr>
<h2 id='kcopula'>Kernel copula (density) estimate</h2><span id='topic+kcopula'></span><span id='topic+kcopula.de'></span>

<h3>Description</h3>

<p>Kernel copula and copula density estimator for 2-dimensional data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>kcopula(x, H, hs, gridsize, gridtype, xmin, xmax, supp=3.7, eval.points,
  binned, bgridsize, w, marginal="kernel", verbose=FALSE)
kcopula.de(x, H, gridsize, gridtype, xmin, xmax, supp=3.7, eval.points, 
  binned, bgridsize, w, compute.cont=TRUE, approx.cont=TRUE,
  marginal="kernel", boundary.supp, boundary.kernel="beta", verbose=FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="kcopula_+3A_x">x</code></td>
<td>
<p>matrix of data values</p>
</td></tr>
<tr><td><code id="kcopula_+3A_h">H</code>, <code id="kcopula_+3A_hs">hs</code></td>
<td>
<p>bandwidth matrix. If these are missing, <code>Hpi.kcde</code>/<code>Hpi</code> or <code>hpi.kcde</code>/<code>hpi</code> is called by default.</p>
</td></tr>
<tr><td><code id="kcopula_+3A_gridsize">gridsize</code></td>
<td>
<p>vector of number of grid points</p>
</td></tr>
<tr><td><code id="kcopula_+3A_gridtype">gridtype</code></td>
<td>
<p>not yet implemented</p>
</td></tr>
<tr><td><code id="kcopula_+3A_xmin">xmin</code>, <code id="kcopula_+3A_xmax">xmax</code></td>
<td>
<p>vector of minimum/maximum values for grid</p>
</td></tr>
<tr><td><code id="kcopula_+3A_supp">supp</code></td>
<td>
<p>effective support for standard normal</p>
</td></tr>
<tr><td><code id="kcopula_+3A_eval.points">eval.points</code></td>
<td>
<p>matrix of points at which estimate is evaluated</p>
</td></tr>
<tr><td><code id="kcopula_+3A_binned">binned</code></td>
<td>
<p>flag for binned estimation</p>
</td></tr>
<tr><td><code id="kcopula_+3A_bgridsize">bgridsize</code></td>
<td>
<p>vector of binning grid sizes</p>
</td></tr>
<tr><td><code id="kcopula_+3A_w">w</code></td>
<td>
<p>vector of weights. Default is a vector of all ones.</p>
</td></tr>
<tr><td><code id="kcopula_+3A_marginal">marginal</code></td>
<td>
<p>&quot;kernel&quot; = kernel cdf or &quot;empirical&quot; = empirical cdf
to calculate pseudo-uniform values. Default is &quot;kernel&quot;.</p>
</td></tr>
<tr><td><code id="kcopula_+3A_compute.cont">compute.cont</code></td>
<td>
<p>flag for computing 1% to 99% probability contour levels. Default is TRUE.</p>
</td></tr>
<tr><td><code id="kcopula_+3A_approx.cont">approx.cont</code></td>
<td>
<p>flag for computing approximate probability contour
levels. Default is TRUE.</p>
</td></tr>
<tr><td><code id="kcopula_+3A_boundary.supp">boundary.supp</code></td>
<td>
<p>effective support for boundary region</p>
</td></tr>
<tr><td><code id="kcopula_+3A_boundary.kernel">boundary.kernel</code></td>
<td>
<p>&quot;beta&quot; = beta boundary kernel, &quot;linear&quot; = linear boundary kernel</p>
</td></tr>
<tr><td><code id="kcopula_+3A_verbose">verbose</code></td>
<td>
<p>flag to print out progress information. Default is FALSE.</p>
</td></tr>  
</table>


<h3>Details</h3>

<p>For kernel copula estimates, a transformation approach is used to
account for the boundary effects. If <code>H</code> is missing, the default
is <code>Hpi.kcde</code>; if <code>hs</code> are missing, the default is
<code>hpi.kcde</code>.  
</p>
<p>For kernel copula density estimates, for those points which are in
the interior region, the usual kernel density estimator
(<code><a href="#topic+kde">kde</a></code>) is used. For those points in the boundary region,
a product beta kernel based on the boundary corrected univariate beta
kernel of Chen (1999) is used (<code><a href="#topic+kde.boundary">kde.boundary</a></code>). If <code>H</code>
is missing, the default is <code>Hpi.kcde</code>; if <code>hs</code> are missing,
the default is <code>hpi</code>.
</p>
<p>The effective support, binning, grid size, grid range parameters are
the same  as for <code><a href="#topic+kde">kde</a></code>.  
</p>


<h3>Value</h3>

<p>A kernel copula estimate, output from <code>kcopula</code>, is an object of
class <code>kcopula</code>. A kernel copula density estimate, output from
<code>kcopula.de</code>, is an object of class <code>kde</code>. These two classes
of objects have the same fields as <code>kcde</code> and <code>kde</code> objects
respectively, except for
</p>
<table role = "presentation">
<tr><td><code>x</code></td>
<td>
<p>pseudo-uniform data points</p>
</td></tr>
<tr><td><code>x.orig</code></td>
<td>
<p>data points - same as input</p>
</td></tr>
<tr><td><code>marginal</code></td>
<td>
<p>marginal function used to compute pseudo-uniform data</p>
</td></tr>
<tr><td><code>boundary</code></td>
<td>
<p>flag for data points in the boundary region
(<code>kcopula.de</code> only)</p>
</td></tr>
</table>


<h3>References</h3>

<p>Duong, T. (2014) Optimal data-based smoothing for non-parametric
estimation of copula functions and their densities. Submitted.
</p>
<p>Chen, S.X. (1999). Beta kernel estimator for density
functions. <em>Computational Statistics &amp; Data Analysis</em>,
<b>31</b>, 131&ndash;145.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+kcde">kcde</a></code>, <code><a href="#topic+kde">kde</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>data(fgl, package="MASS")
x &lt;- fgl[,c("RI", "Na")]
Chat &lt;- kcopula(x=x)
plot(Chat, display="persp", border=1)
plot(Chat, display="filled.contour", lwd=1)
</code></pre>

<hr>
<h2 id='kda'>Kernel discriminant analysis (kernel classification)</h2><span id='topic+Hkda'></span><span id='topic+Hkda.diag'></span><span id='topic+kda'></span><span id='topic+hkda'></span><span id='topic+predict.kda'></span><span id='topic+compare'></span><span id='topic+compare.kda.diag.cv'></span><span id='topic+compare.kda.cv'></span>

<h3>Description</h3>

<p>Kernel discriminant analysis (kernel classification) for 1- to d-dimensional data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>kda(x, x.group, Hs, hs, prior.prob=NULL, gridsize, xmin, xmax, supp=3.7,
  eval.points, binned, bgridsize, w, compute.cont=TRUE, approx.cont=TRUE,
  kde.flag=TRUE)
Hkda(x, x.group, Hstart, bw="plugin", ...)
Hkda.diag(x, x.group, bw="plugin", ...)
hkda(x, x.group, bw="plugin", ...)

## S3 method for class 'kda'
predict(object, ..., x)

compare(x.group, est.group, by.group=FALSE)
compare.kda.cv(x, x.group, bw="plugin", prior.prob=NULL, Hstart, by.group=FALSE,
   verbose=FALSE, recompute=FALSE, ...)
compare.kda.diag.cv(x, x.group, bw="plugin", prior.prob=NULL, by.group=FALSE, 
   verbose=FALSE, recompute=FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="kda_+3A_x">x</code></td>
<td>
<p>matrix of training data values</p>
</td></tr>
<tr><td><code id="kda_+3A_x.group">x.group</code></td>
<td>
<p>vector of group labels for training data</p>
</td></tr>
<tr><td><code id="kda_+3A_hs">Hs</code>, <code id="kda_+3A_hs">hs</code></td>
<td>
<p>(stacked) matrix of bandwidth matrices/vector of scalar
bandwidths. If these are missing, <code>Hkda</code> or <code>hkda</code> is called by default.</p>
</td></tr>
<tr><td><code id="kda_+3A_prior.prob">prior.prob</code></td>
<td>
<p>vector of prior probabilities</p>
</td></tr>
<tr><td><code id="kda_+3A_gridsize">gridsize</code></td>
<td>
<p>vector of grid sizes</p>
</td></tr>
<tr><td><code id="kda_+3A_xmin">xmin</code>, <code id="kda_+3A_xmax">xmax</code></td>
<td>
<p>vector of minimum/maximum values for grid</p>
</td></tr>
<tr><td><code id="kda_+3A_supp">supp</code></td>
<td>
<p>effective support for standard normal</p>
</td></tr>
<tr><td><code id="kda_+3A_eval.points">eval.points</code></td>
<td>
<p>vector or matrix of points at which estimate is evaluated</p>
</td></tr>
<tr><td><code id="kda_+3A_binned">binned</code></td>
<td>
<p>flag for binned estimation</p>
</td></tr>
<tr><td><code id="kda_+3A_bgridsize">bgridsize</code></td>
<td>
<p>vector of binning grid sizes</p>
</td></tr>
<tr><td><code id="kda_+3A_w">w</code></td>
<td>
<p>vector of weights. Not yet implemented.</p>
</td></tr>
<tr><td><code id="kda_+3A_compute.cont">compute.cont</code></td>
<td>
<p>flag for computing 1% to 99% probability contour levels. Default is TRUE.</p>
</td></tr>
<tr><td><code id="kda_+3A_approx.cont">approx.cont</code></td>
<td>
<p>flag for computing approximate probability contour
levels. Default is TRUE.</p>
</td></tr>
<tr><td><code id="kda_+3A_kde.flag">kde.flag</code></td>
<td>
<p>flag for computing KDE on grid. Default is TRUE.</p>
</td></tr>
<tr><td><code id="kda_+3A_object">object</code></td>
<td>
<p>object of class <code>kda</code></p>
</td></tr>
<tr><td><code id="kda_+3A_bw">bw</code></td>
<td>
<p>bandwidth: &quot;plugin&quot; = plug-in, &quot;lscv&quot; = LSCV, 
&quot;scv&quot; = SCV</p>
</td></tr>
<tr><td><code id="kda_+3A_hstart">Hstart</code></td>
<td>
<p>(stacked) matrix of initial bandwidth matrices, used in
numerical optimisation</p>
</td></tr>
<tr><td><code id="kda_+3A_est.group">est.group</code></td>
<td>
<p>vector of estimated group labels</p>
</td></tr>
<tr><td><code id="kda_+3A_by.group">by.group</code></td>
<td>
<p>flag to give results also within each group</p>
</td></tr>
<tr><td><code id="kda_+3A_verbose">verbose</code></td>
<td>
<p>flag for printing progress information. Default is FALSE.</p>
</td></tr>
<tr><td><code id="kda_+3A_recompute">recompute</code></td>
<td>
<p>flag for recomputing the bandwidth matrix after
excluding the i-th data item</p>
</td></tr>
<tr><td><code id="kda_+3A_...">...</code></td>
<td>
<p>other optional parameters for bandwidth selection, see
<code><a href="#topic+Hpi">Hpi</a></code>, <code><a href="#topic+Hlscv">Hlscv</a></code>, <code><a href="#topic+Hscv">Hscv</a></code></p>
</td></tr> 
</table>


<h3>Details</h3>

<p>If the bandwidths <code>Hs</code> are missing from <code>kda</code>, then the
default bandwidths are the plug-in selectors <code>Hkda(, bw="plugin")</code>.
Likewise for missing <code>hs</code>. Valid options for <code>bw</code>
are <code>"plugin"</code>, <code>"lscv"</code> and <code>"scv"</code> which in turn call
<code><a href="#topic+Hpi">Hpi</a></code>, <code><a href="#topic+Hlscv">Hlscv</a></code> and <code><a href="#topic+Hscv">Hscv</a></code>.
</p>
<p>The effective support, binning, grid size, grid range, positive
parameters are the same as <code><a href="#topic+kde">kde</a></code>.
</p>
<p>If prior probabilities are known then set <code>prior.prob</code> to these.
Otherwise <code>prior.prob=NULL</code> uses the sample
proportions as estimates of the prior probabilities.
</p>
<p>For <span class="pkg">ks</span> <code class="reqn">\geq</code> 1.8.11, <code>kda.kde</code> has been subsumed
into <code>kda</code>, so all prior calls to <code>kda.kde</code> can be replaced
by <code>kda</code>. To reproduce the previous behaviour of <code>kda</code>, the
command is <code>kda(, kde.flag=FALSE)</code>.
</p>


<h3>Value</h3>

<p>&ndash;For <code>kde.flag=TRUE</code>, a kernel discriminant analysis is an object of class <code>kda</code> which is a list with fields
</p>
<table role = "presentation">
<tr><td><code>x</code></td>
<td>
<p>list of data points, one for each group label</p>
</td></tr>
<tr><td><code>estimate</code></td>
<td>
<p>list of density estimates at <code>eval.points</code>, one for each group label</p>
</td></tr>  
<tr><td><code>eval.points</code></td>
<td>
<p>vector or list of points that the estimate is evaluated at, one
for each group label</p>
</td></tr>
<tr><td><code>h</code></td>
<td>
<p>vector of bandwidths (1-d only)</p>
</td></tr>
<tr><td><code>H</code></td>
<td>
<p>stacked matrix of bandwidth matrices or vector of bandwidths</p>
</td></tr>
<tr><td><code>gridded</code></td>
<td>
<p>flag for estimation on a grid</p>
</td></tr>
<tr><td><code>binned</code></td>
<td>
<p>flag for binned estimation</p>
</td></tr>
<tr><td><code>w</code></td>
<td>
<p>vector of weights</p>
</td></tr>
<tr><td><code>prior.prob</code></td>
<td>
<p>vector of prior probabilities</p>
</td></tr>
<tr><td><code>x.group</code></td>
<td>
<p>vector of group labels - same as input</p>
</td></tr>
<tr><td><code>x.group.estimate</code></td>
<td>
<p>vector of estimated group labels. If the test data
<code>eval.points</code> are given then these are classified. Otherwise
the training data <code>x</code> are classified.</p>
</td></tr>
</table>
<p>For <code>kde.flag=FALSE</code>, which is always the case for <code class="reqn">d&gt;3</code>,
then only the vector of estimated group labels is returned. 
</p>
<p>&ndash;The result from <code>Hkda</code> and <code>Hkda.diag</code> is a stacked matrix
of bandwidth matrices, one for each training data group. The result
from <code>hkda</code> is a vector of bandwidths, one for each training group.  
</p>
<p>&ndash;The <code>compare</code> functions create a comparison between the true
group labels <code>x.group</code> and the estimated ones. 
It returns a list with fields
</p>
<table role = "presentation">
<tr><td><code>cross</code></td>
<td>
<p>cross-classification table with the rows
indicating the true group and the columns the estimated group</p>
</td></tr>
<tr><td><code>error</code></td>
<td>
<p>misclassification rate (MR)</p>
</td></tr>
</table>
<p>In the case where the test data are independent of the
training data, <code>compare</code> computes MR = (number of points wrongly
classified)/(total number of points). In the case where the test data
are not independent e.g. 
we are classifying the training data set itself, then the cross
validated estimate of MR is more appropriate. These
are implemented as <code>compare.kda.cv</code> (unconstrained bandwidth
selectors) and <code>compare.kda.diag.cv</code> (for diagonal bandwidth
selectors). These functions are only available for d &gt; 1.
</p>
<p>If <code>by.group=FALSE</code> then only the total MR rate is given. If it
is set to TRUE, then the MR rates for each class are also given
(estimated number in group divided by true number).
</p>


<h3>References</h3>

<p>Simonoff, J. S. (1996) <em>Smoothing Methods in Statistics</em>.
Springer-Verlag. New York
</p>


<h3>See Also</h3>

<p><code><a href="#topic+plot.kda">plot.kda</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(8192)
x &lt;- c(rnorm.mixt(n=100, mus=1), rnorm.mixt(n=100, mus=-1))
x.gr &lt;- rep(c(1,2), times=c(100,100))
y &lt;- c(rnorm.mixt(n=100, mus=1), rnorm.mixt(n=100, mus=-1))
y.gr &lt;- rep(c(1,2), times=c(100,100))
kda.gr &lt;- kda(x, x.gr)
y.gr.est &lt;- predict(kda.gr, x=y)
compare(y.gr, y.gr.est)

## See other examples in ? plot.kda
</code></pre>

<hr>
<h2 id='kdcde'>Deconvolution kernel density derivative estimate</h2><span id='topic+kdcde'></span><span id='topic+dckde'></span>

<h3>Description</h3>

<p>Deconvolution kernel density derivative estimate for 1- to 6-dimensional data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>kdcde(x, H, h, Sigma, sigma, reg, bgridsize, gridsize, binned, 
      verbose=FALSE, ...)
dckde(...) 
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="kdcde_+3A_x">x</code></td>
<td>
<p>matrix of data values</p>
</td></tr>
<tr><td><code id="kdcde_+3A_h">H</code>, <code id="kdcde_+3A_h">h</code></td>
<td>
<p>bandwidth matrix/scalar bandwidth. If these are missing, <code>Hpi</code> or <code>hpi</code> is called by default.</p>
</td></tr>
<tr><td><code id="kdcde_+3A_sigma">Sigma</code>, <code id="kdcde_+3A_sigma">sigma</code></td>
<td>
<p>error variance matrix</p>
</td></tr>
<tr><td><code id="kdcde_+3A_reg">reg</code></td>
<td>
<p>regularisation parameter</p>
</td></tr>
<tr><td><code id="kdcde_+3A_gridsize">gridsize</code></td>
<td>
<p>vector of number of grid points</p>
</td></tr>
<tr><td><code id="kdcde_+3A_binned">binned</code></td>
<td>
<p>flag for binned estimation</p>
</td></tr>
<tr><td><code id="kdcde_+3A_bgridsize">bgridsize</code></td>
<td>
<p>vector of binning grid sizes</p>
</td></tr>
<tr><td><code id="kdcde_+3A_verbose">verbose</code></td>
<td>
<p>flag to print out progress information. Default is
FALSE.</p>
</td></tr>
<tr><td><code id="kdcde_+3A_...">...</code></td>
<td>
<p>other parameters to <code><a href="#topic+kde">kde</a></code></p>
</td></tr> 
</table>


<h3>Details</h3>

 
<p>A weighted kernel density estimate is utilised to perform the
deconvolution. The weights <code>w</code> are the solution to a
quadratic programming problem, and then input into <code>kde(,w=w)</code>.
This weighted estimate also requires an estimate of the error
variance matrix from repeated observations, and of the regularisation
parameter. If the latter is missing, it is calculated internally using
a 5-fold cross validation method. See Hazelton &amp; Turlach (2009).
<code>dckde</code> is an alias for <code>kdcde</code>.
</p>
<p>If the bandwidth <code>H</code> is missing from <code>kde</code>, then
the default bandwidth is the plug-in selector
<code>Hpi</code>. Likewise for missing <code>h</code>.
</p>
<p>The effective support, binning, grid size, grid range, positive
parameters are the same as <code><a href="#topic+kde">kde</a></code>.
</p>


<h3>Value</h3>

<p>A deconvolution kernel density derivative estimate is an object of class
<code>kde</code> which is a list with fields:
</p>
<table role = "presentation">
<tr><td><code>x</code></td>
<td>
<p>data points - same as input</p>
</td></tr>
<tr><td><code>eval.points</code></td>
<td>
<p>vector or list of points at which the estimate is evaluated</p>
</td></tr>
<tr><td><code>estimate</code></td>
<td>
<p>density estimate at <code>eval.points</code></p>
</td></tr>
<tr><td><code>h</code></td>
<td>
<p>scalar bandwidth (1-d only)</p>
</td></tr>
<tr><td><code>H</code></td>
<td>
<p>bandwidth matrix</p>
</td></tr>
<tr><td><code>gridtype</code></td>
<td>
<p>&quot;linear&quot;</p>
</td></tr>
<tr><td><code>gridded</code></td>
<td>
<p>flag for estimation on a grid</p>
</td></tr>
<tr><td><code>binned</code></td>
<td>
<p>flag for binned estimation</p>
</td></tr>
<tr><td><code>names</code></td>
<td>
<p>variable names</p>
</td></tr> 
<tr><td><code>w</code></td>
<td>
<p>vector of weights</p>
</td></tr>
<tr><td><code>cont</code></td>
<td>
<p>vector of probability contour levels</p>
</td></tr>   
</table>


<h3>References</h3>

<p>Hazelton, M. L. &amp; Turlach, B. A. (2009), Nonparametric density
deconvolution by weighted kernel density estimators, <em>Statistics
and Computing</em>, <b>19</b>, 217-228.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+kde">kde</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(air)
air &lt;- air[, c("date", "time", "co2", "pm10")]
air2 &lt;- reshape(air, idvar="date", timevar="time", direction="wide")
air &lt;- as.matrix(na.omit(air2[,c("co2.20:00", "pm10.20:00")]))
Sigma.air &lt;- diag(c(var(air2[,"co2.19:00"] - air2["co2.21:00"], na.rm=TRUE),
   var(air2[,"pm10.19:00"] - air2[,"pm10.21:00"], na.rm=TRUE)))
fhat.air.dec &lt;- kdcde(x=air, Sigma=Sigma.air, reg=0.00021, verbose=TRUE)
plot(fhat.air.dec, drawlabels=FALSE, display="filled.contour", lwd=1)
</code></pre>

<hr>
<h2 id='kdde'>Kernel density derivative estimate</h2><span id='topic+kdde'></span><span id='topic+predict.kdde'></span><span id='topic+kcurv'></span>

<h3>Description</h3>

<p>Kernel density derivative estimate for 1- to 6-dimensional data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>kdde(x, H, h, deriv.order=0, gridsize, gridtype, xmin, xmax, supp=3.7, 
    eval.points, binned, bgridsize, positive=FALSE, adj.positive, w,
    deriv.vec=TRUE, verbose=FALSE)
kcurv(fhat, compute.cont=TRUE)

## S3 method for class 'kdde'
predict(object, ..., x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="kdde_+3A_x">x</code></td>
<td>
<p>matrix of data values</p>
</td></tr>
<tr><td><code id="kdde_+3A_h">H</code>, <code id="kdde_+3A_h">h</code></td>
<td>
<p>bandwidth matrix/scalar bandwidth. If these are missing, <code>Hpi</code> or <code>hpi</code> is called by default.</p>
</td></tr>
<tr><td><code id="kdde_+3A_deriv.order">deriv.order</code></td>
<td>
<p>derivative order (scalar)</p>
</td></tr>
<tr><td><code id="kdde_+3A_gridsize">gridsize</code></td>
<td>
<p>vector of number of grid points</p>
</td></tr>
<tr><td><code id="kdde_+3A_gridtype">gridtype</code></td>
<td>
<p>not yet implemented</p>
</td></tr>
<tr><td><code id="kdde_+3A_xmin">xmin</code>, <code id="kdde_+3A_xmax">xmax</code></td>
<td>
<p>vector of minimum/maximum values for grid</p>
</td></tr>
<tr><td><code id="kdde_+3A_supp">supp</code></td>
<td>
<p>effective support for standard normal</p>
</td></tr>
<tr><td><code id="kdde_+3A_eval.points">eval.points</code></td>
<td>
<p>vector or matrix of points at which estimate is evaluated</p>
</td></tr>
<tr><td><code id="kdde_+3A_binned">binned</code></td>
<td>
<p>flag for binned estimation</p>
</td></tr>
<tr><td><code id="kdde_+3A_bgridsize">bgridsize</code></td>
<td>
<p>vector of binning grid sizes</p>
</td></tr>
<tr><td><code id="kdde_+3A_positive">positive</code></td>
<td>
<p>flag if data are positive (1-d, 2-d). Default is FALSE.</p>
</td></tr>
<tr><td><code id="kdde_+3A_adj.positive">adj.positive</code></td>
<td>
<p>adjustment applied to positive 1-d data</p>
</td></tr>
<tr><td><code id="kdde_+3A_w">w</code></td>
<td>
<p>vector of weights. Default is a vector of all ones.</p>
</td></tr>
<tr><td><code id="kdde_+3A_deriv.vec">deriv.vec</code></td>
<td>
<p>flag to compute all derivatives in vectorised
derivative. Default is TRUE. If FALSE then only the unique derivatives are computed.</p>
</td></tr>
<tr><td><code id="kdde_+3A_verbose">verbose</code></td>
<td>
<p>flag to print out progress information. Default is
FALSE.</p>
</td></tr>
<tr><td><code id="kdde_+3A_compute.cont">compute.cont</code></td>
<td>
<p>flag for computing 1% to 99% probability contour
levels. Default is TRUE.</p>
</td></tr>
<tr><td><code id="kdde_+3A_fhat">fhat</code></td>
<td>
<p>object of class <code>kdde</code> with <code>deriv.order=2</code></p>
</td></tr> 
<tr><td><code id="kdde_+3A_object">object</code></td>
<td>
<p>object of class <code>kdde</code></p>
</td></tr>
<tr><td><code id="kdde_+3A_...">...</code></td>
<td>
<p>other parameters</p>
</td></tr> 
</table>


<h3>Details</h3>

 
<p>For each partial derivative, for grid estimation, the estimate is a
list whose elements  
correspond to the partial derivative indices in the rows of <code>deriv.ind</code>. 
For points estimation, the estimate is a matrix whose columns correspond to 
the rows of <code>deriv.ind</code>.
</p>
<p>If the bandwidth <code>H</code> is missing from <code>kdde</code>, then
the default bandwidth is the  plug-in selector
<code>Hpi</code>. Likewise for missing <code>h</code>.
</p>
<p>The effective support, binning, grid size, grid range, positive
parameters are the same as <code><a href="#topic+kde">kde</a></code>.
</p>
<p>The summary curvature is computed by <code>kcurv</code>, i.e.
</p>
<p style="text-align: center;"><code class="reqn">\hat{s}(\bold{x})= - \bold{1}\{\mathsf{D}^2 \hat{f}(\bold{x}) &lt;
  0\} \mathrm{abs}(|\mathsf{D}^2 \hat{f}(\bold{x})|)</code>
</p>
<p> where <code class="reqn">\mathsf{D}^2
  \hat{f}(\bold{x})</code> is the kernel Hessian matrix
estimate. So <code class="reqn">\hat{s}</code> calculates the absolute value of
the determinant of the Hessian matrix and whose sign is the opposite of
the negative definiteness indicator.
</p>


<h3>Value</h3>

<p>A kernel density derivative estimate is an object of class
<code>kdde</code> which is a list with fields:
</p>
<table role = "presentation">
<tr><td><code>x</code></td>
<td>
<p>data points - same as input</p>
</td></tr>
<tr><td><code>eval.points</code></td>
<td>
<p>vector or list of points at which the estimate is evaluated</p>
</td></tr>
<tr><td><code>estimate</code></td>
<td>
<p>density derivative estimate at <code>eval.points</code></p>
</td></tr>
<tr><td><code>h</code></td>
<td>
<p>scalar bandwidth (1-d only)</p>
</td></tr>
<tr><td><code>H</code></td>
<td>
<p>bandwidth matrix</p>
</td></tr>
<tr><td><code>gridtype</code></td>
<td>
<p>&quot;linear&quot;</p>
</td></tr>
<tr><td><code>gridded</code></td>
<td>
<p>flag for estimation on a grid</p>
</td></tr>
<tr><td><code>binned</code></td>
<td>
<p>flag for binned estimation</p>
</td></tr>
<tr><td><code>names</code></td>
<td>
<p>variable names</p>
</td></tr>
<tr><td><code>w</code></td>
<td>
<p>vector of weights</p>
</td></tr>
<tr><td><code>deriv.order</code></td>
<td>
<p>derivative order (scalar)</p>
</td></tr>
<tr><td><code>deriv.ind</code></td>
<td>
<p>martix where each row is a vector of partial derivative indices</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+kde">kde</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(8192)
x &lt;- rmvnorm.mixt(1000, mus=c(0,0), Sigmas=invvech(c(1,0.8,1)))
fhat &lt;- kdde(x=x, deriv.order=1) ## gradient [df/dx, df/dy]
predict(fhat, x=x[1:5,])

## See other examples in ? plot.kdde
</code></pre>

<hr>
<h2 id='kde'>Kernel density estimate</h2><span id='topic+kde'></span><span id='topic+predict.kde'></span>

<h3>Description</h3>

<p>Kernel density estimate for 1- to 6-dimensional data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>kde(x, H, h, gridsize, gridtype, xmin, xmax, supp=3.7, eval.points, binned, 
    bgridsize, positive=FALSE, adj.positive, w, compute.cont=TRUE, 
    approx.cont=TRUE, unit.interval=FALSE, density=FALSE, verbose=FALSE)

## S3 method for class 'kde'
predict(object, ..., x, zero.flag=TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="kde_+3A_x">x</code></td>
<td>
<p>matrix of data values</p>
</td></tr>
<tr><td><code id="kde_+3A_h">H</code>, <code id="kde_+3A_h">h</code></td>
<td>
<p>bandwidth matrix/scalar bandwidth. If these are missing, <code>Hpi</code> or <code>hpi</code> is called by default.</p>
</td></tr>
<tr><td><code id="kde_+3A_gridsize">gridsize</code></td>
<td>
<p>vector of number of grid points</p>
</td></tr>
<tr><td><code id="kde_+3A_gridtype">gridtype</code></td>
<td>
<p>not yet implemented</p>
</td></tr>
<tr><td><code id="kde_+3A_xmin">xmin</code>, <code id="kde_+3A_xmax">xmax</code></td>
<td>
<p>vector of minimum/maximum values for grid</p>
</td></tr>
<tr><td><code id="kde_+3A_supp">supp</code></td>
<td>
<p>effective support for standard normal</p>
</td></tr>
<tr><td><code id="kde_+3A_eval.points">eval.points</code></td>
<td>
<p>vector or matrix of points at which estimate is evaluated</p>
</td></tr>
<tr><td><code id="kde_+3A_binned">binned</code></td>
<td>
<p>flag for binned estimation.</p>
</td></tr>
<tr><td><code id="kde_+3A_bgridsize">bgridsize</code></td>
<td>
<p>vector of binning grid sizes</p>
</td></tr>
<tr><td><code id="kde_+3A_positive">positive</code></td>
<td>
<p>flag if data are positive (1-d, 2-d). Default is FALSE.</p>
</td></tr>
<tr><td><code id="kde_+3A_adj.positive">adj.positive</code></td>
<td>
<p>adjustment applied to positive 1-d data</p>
</td></tr>
<tr><td><code id="kde_+3A_w">w</code></td>
<td>
<p>vector of weights. Default is a vector of all ones.</p>
</td></tr>
<tr><td><code id="kde_+3A_compute.cont">compute.cont</code></td>
<td>
<p>flag for computing 1% to 99% probability contour levels. Default is TRUE.</p>
</td></tr>
<tr><td><code id="kde_+3A_approx.cont">approx.cont</code></td>
<td>
<p>flag for computing approximate probability contour
levels. Default is TRUE.</p>
</td></tr>
<tr><td><code id="kde_+3A_unit.interval">unit.interval</code></td>
<td>
<p>flag for computing log transformation KDE on 1-d data bounded on unit interval [0,1]. Default is FALSE.</p>
</td></tr> 
<tr><td><code id="kde_+3A_density">density</code></td>
<td>
<p>flag if density estimate values are forced to be non-negative function. Default is FALSE.</p>
</td></tr> 
<tr><td><code id="kde_+3A_verbose">verbose</code></td>
<td>
<p>flag to print out progress information. Default is
FALSE.</p>
</td></tr>
<tr><td><code id="kde_+3A_object">object</code></td>
<td>
<p>object of class <code>kde</code></p>
</td></tr>
<tr><td><code id="kde_+3A_zero.flag">zero.flag</code></td>
<td>
<p>deprecated (retained for backwards compatibilty)</p>
</td></tr>
<tr><td><code id="kde_+3A_...">...</code></td>
<td>
<p>other parameters</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For d=1, if <code>h</code> is missing, the default bandwidth is <code>hpi</code>.
For d&gt;1, if <code>H</code> is missing, the default is <code>Hpi</code>.
</p>
<p>For d=1, if <code>positive=TRUE</code> then <code>x</code> is transformed to
<code>log(x+adj.positive)</code> where the default <code>adj.positive</code> is
the minimum of <code>x</code>. This is known as a log transformation density
estimate. If <code>unit.interval=TRUE</code> then <code>x</code> is transformed to 
<code>qnorm(x)</code>. See <code><a href="#topic+kde.boundary">kde.boundary</a></code> for boundary kernel density estimates, as these tend to be more robust than transformation density estimates. 
</p>
<p>For d=1, 2, 3, and if <code>eval.points</code> is not specified, then the
density estimate is computed over a grid 
defined by <code>gridsize</code> (if <code>binned=FALSE</code>) or
by <code>bgridsize</code> (if <code>binned=TRUE</code>). This form is suitable for
visualisation in conjunction with the <code>plot</code> method.
</p>
<p>For d=4, 5, 6,  and if <code>eval.points</code> is not specified, then the
density estimate is computed over a grid defined by <code>gridsize</code>. 
</p>
<p>If <code>eval.points</code> is specified, as a vector (d=1) or 
as a matrix (d=2, 3, 4), then the density estimate is computed at
<code>eval.points</code>. This form is suitable for numerical summaries
(e.g. maximum likelihood), and is not compatible with the <code>plot</code>
method. Despite that the density estimate is returned only at
<code>eval.points</code>, by default, a binned gridded estimate is
calculated first and then the density estimate at <code>eval.points</code>
is computed using the <code>predict</code> method. If this default intermediate
binned grid estimate is not required, then set <code>binned=FALSE</code> to
compute directly the exact density estimate at <code>eval.points</code>.   
</p>
<p>Binned kernel estimation is an approximation to the exact kernel
estimation and is available for d=1, 2, 3, 4. This makes
kernel estimators feasible for large samples. The default value of the
binning flag <code>binned</code> is n&gt;1 (d=1), n&gt;500 (d=2), n&gt;1000 (d&gt;=3). 
Some times binned estimation leads to negative density values: if non-negative
values are required, then set <code>density=TRUE</code>. 
</p>
<p>The default <code>bgridsize,gridsize</code> are d=1: 401; d=2: rep(151, 2); d=3: 
rep(51, 3); d=4: rep(21, 4). 
</p>
<p>The effective support for a normal kernel is where  
all values outside <code>[-supp,supp]^d</code> are zero. 
</p>
<p>The default <code>xmin</code> is <code>min(x)-Hmax*supp</code> and <code>xmax</code>
is <code>max(x)+Hmax*supp</code>  where <code>Hmax</code> is the maximum of the
diagonal elements of <code>H</code>. The grid produced is the outer
product of <code>c(xmin[1], xmax[1])</code>, ..., <code>c(xmin[d], xmax[d])</code>. 
For <span class="pkg">ks</span> <code class="reqn">\geq</code> 1.14.0, when <code>binned=TRUE</code> and <code>xmin,xmax</code> 
are not missing, the data values <code>x</code> are clipped to the estimation grid 
delimited by <code>xmin,xmax</code> to prevent potential memory leaks. 
</p>


<h3>Value</h3>

<p>A kernel density estimate is an object of class <code>kde</code> which is a
list with fields: 
</p>
<table role = "presentation">
<tr><td><code>x</code></td>
<td>
<p>data points - same as input</p>
</td></tr>
<tr><td><code>eval.points</code></td>
<td>
<p>vector or list of points at which the estimate is evaluated</p>
</td></tr>
<tr><td><code>estimate</code></td>
<td>
<p>density estimate at <code>eval.points</code></p>
</td></tr>
<tr><td><code>h</code></td>
<td>
<p>scalar bandwidth (1-d only)</p>
</td></tr>
<tr><td><code>H</code></td>
<td>
<p>bandwidth matrix</p>
</td></tr>
<tr><td><code>gridtype</code></td>
<td>
<p>&quot;linear&quot;</p>
</td></tr>
<tr><td><code>gridded</code></td>
<td>
<p>flag for estimation on a grid</p>
</td></tr>
<tr><td><code>binned</code></td>
<td>
<p>flag for binned estimation</p>
</td></tr>
<tr><td><code>names</code></td>
<td>
<p>variable names</p>
</td></tr> 
<tr><td><code>w</code></td>
<td>
<p>vector of weights</p>
</td></tr>
<tr><td><code>cont</code></td>
<td>
<p>vector of probability contour levels</p>
</td></tr>    
</table>


<h3>See Also</h3>

<p><code><a href="#topic+plot.kde">plot.kde</a></code>, <code><a href="#topic+kde.boundary">kde.boundary</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## unit interval data 
set.seed(8192)             
fhat &lt;- kde(runif(10000,0,1), unit.interval=TRUE)
plot(fhat, ylim=c(0,1.2))

## positive data 
data(worldbank)
wb &lt;- as.matrix(na.omit(worldbank[,2:3]))
wb[,2] &lt;- wb[,2]/1000
fhat &lt;- kde(x=wb)
fhat.trans &lt;- kde(x=wb, adj.positive=c(0,0), positive=TRUE)
plot(fhat, col=1, xlim=c(0,20), ylim=c(0,80))
plot(fhat.trans, add=TRUE, col=2)
rect(0,0,100,100, lty=2)

## large data on non-default grid
## 151 x 151 grid = [-5,-4.933,..,5] x [-5,-4.933,..,5]
set.seed(8192)
x &lt;- rmvnorm.mixt(10000, mus=c(0,0), Sigmas=invvech(c(1,0.8,1)))
fhat &lt;- kde(x=x, compute.cont=TRUE, xmin=c(-5,-5), xmax=c(5,5), bgridsize=c(151,151))
plot(fhat)

## See other examples in ? plot.kde
</code></pre>

<hr>
<h2 id='kde.boundary'>Kernel density estimate for bounded data</h2><span id='topic+kde.boundary'></span>

<h3>Description</h3>

<p>Kernel density estimate for bounded 1- to 3-dimensional data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>kde.boundary(x, H, h, gridsize, gridtype, xmin, xmax, supp=3.7, eval.points, 
   binned=FALSE, bgridsize, w, compute.cont=TRUE, approx.cont=TRUE,
   boundary.supp, boundary.kernel="beta", verbose=FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="kde.boundary_+3A_x">x</code></td>
<td>
<p>matrix of data values</p>
</td></tr>
<tr><td><code id="kde.boundary_+3A_h">H</code>, <code id="kde.boundary_+3A_h">h</code></td>
<td>
<p>bandwidth matrix/scalar bandwidth. If these are missing, <code>Hpi</code> or <code>hpi</code> is called by default.</p>
</td></tr>
<tr><td><code id="kde.boundary_+3A_gridsize">gridsize</code></td>
<td>
<p>vector of number of grid points</p>
</td></tr>
<tr><td><code id="kde.boundary_+3A_gridtype">gridtype</code></td>
<td>
<p>not yet implemented</p>
</td></tr>
<tr><td><code id="kde.boundary_+3A_xmin">xmin</code>, <code id="kde.boundary_+3A_xmax">xmax</code></td>
<td>
<p>vector of minimum/maximum values for grid</p>
</td></tr>
<tr><td><code id="kde.boundary_+3A_supp">supp</code></td>
<td>
<p>effective support for standard normal</p>
</td></tr>
<tr><td><code id="kde.boundary_+3A_eval.points">eval.points</code></td>
<td>
<p>vector or matrix of points at which estimate is evaluated</p>
</td></tr>
<tr><td><code id="kde.boundary_+3A_binned">binned</code></td>
<td>
<p>flag for binned estimation.</p>
</td></tr>
<tr><td><code id="kde.boundary_+3A_bgridsize">bgridsize</code></td>
<td>
<p>vector of binning grid sizes</p>
</td></tr>
<tr><td><code id="kde.boundary_+3A_w">w</code></td>
<td>
<p>vector of weights. Default is a vector of all ones.</p>
</td></tr>
<tr><td><code id="kde.boundary_+3A_compute.cont">compute.cont</code></td>
<td>
<p>flag for computing 1% to 99% probability contour levels. Default is TRUE.</p>
</td></tr>
<tr><td><code id="kde.boundary_+3A_approx.cont">approx.cont</code></td>
<td>
<p>flag for computing approximate probability contour
levels. Default is TRUE.</p>
</td></tr>
<tr><td><code id="kde.boundary_+3A_boundary.supp">boundary.supp</code></td>
<td>
<p>effective support for boundary region</p>
</td></tr>
<tr><td><code id="kde.boundary_+3A_boundary.kernel">boundary.kernel</code></td>
<td>
<p>&quot;beta&quot; = beta boundary kernel, &quot;linear&quot; = linear boundary kernel</p>
</td></tr>
<tr><td><code id="kde.boundary_+3A_verbose">verbose</code></td>
<td>
<p>flag to print out progress information. Default is
FALSE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>There are two forms of density estimates which are suitable for
bounded data, based on the modifying the kernel function.
For <code>boundary.kernel="beta"</code>, the 2nd
form of the Beta boundary kernel of Chen (1999) is employed. It is suited for
rectangular data  boundaries.  
</p>
<p>For <code>boundary.kernel="linear"</code>, the linear boundary kernel of
Hazelton &amp; Marshall (2009) is employed. It is suited for arbitrarily
shaped data boundaries, though it 
is currently only implemented for rectangular boundaries.   
</p>


<h3>Value</h3>

<p>A kernel density estimate for bounded data is an object of class <code>kde</code>.    
</p>


<h3>References</h3>

<p>Chen, S. X. (1999) Beta kernel estimators for density functions. 
<em>Computational Statistics and Data Analysis</em>, <b>31</b>, 131-145.
</p>
<p>Hazelton, M. L. &amp; Marshall, J. C. (2009) Linear boundary kernels for
bivariate density estimation. <em>Statistics and Probability
Letters</em>, <b>79</b>, 999-1003.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+kde">kde</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>data(worldbank)
wb &lt;- as.matrix(na.omit(worldbank[,c("internet", "ag.value")]))
fhat &lt;- kde(x=wb)
fhat.beta &lt;- kde.boundary(x=wb, xmin=c(0,0), xmax=c(100,100), boundary.kernel="beta")  
fhat.LB &lt;- kde.boundary(x=wb, xmin=c(0,0), xmax=c(100,100), boundary.kernel="linear")

plot(fhat, col=1, xlim=c(0,100), ylim=c(0,100))
plot(fhat.beta, add=TRUE, col=2)
rect(0,0,100,100, lty=2)
plot(fhat, col=1, xlim=c(0,100), ylim=c(0,100))
plot(fhat.LB, add=TRUE, col=3)
rect(0,0,100,100, lty=2) 
</code></pre>

<hr>
<h2 id='kde.local.test'>Kernel density based local two-sample comparison test</h2><span id='topic+kde.local.test'></span>

<h3>Description</h3>

<p>Kernel density based local two-sample comparison test for 1- to 6-dimensional data.</p>


<h3>Usage</h3>

<pre><code class='language-R'>kde.local.test(x1, x2, H1, H2, h1, h2, fhat1, fhat2, gridsize, binned, 
   bgridsize, verbose=FALSE, supp=3.7, mean.adj=FALSE, signif.level=0.05,
   min.ESS, xmin, xmax)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="kde.local.test_+3A_x1">x1</code>, <code id="kde.local.test_+3A_x2">x2</code></td>
<td>
<p>vector/matrix of data values</p>
</td></tr>
<tr><td><code id="kde.local.test_+3A_h1">H1</code>, <code id="kde.local.test_+3A_h2">H2</code>, <code id="kde.local.test_+3A_h1">h1</code>, <code id="kde.local.test_+3A_h2">h2</code></td>
<td>
<p>bandwidth matrices/scalar bandwidths.  If these are missing, <code>Hpi</code> or <code>hpi</code> is called by default.</p>
</td></tr>
<tr><td><code id="kde.local.test_+3A_fhat1">fhat1</code>, <code id="kde.local.test_+3A_fhat2">fhat2</code></td>
<td>
<p>objects of class <code>kde</code></p>
</td></tr>
<tr><td><code id="kde.local.test_+3A_binned">binned</code></td>
<td>
<p>flag for binned estimation</p>
</td></tr>
<tr><td><code id="kde.local.test_+3A_gridsize">gridsize</code></td>
<td>
<p>vector of grid sizes</p>
</td></tr>
<tr><td><code id="kde.local.test_+3A_bgridsize">bgridsize</code></td>
<td>
<p>vector of binning grid sizes</p>
</td></tr>
<tr><td><code id="kde.local.test_+3A_verbose">verbose</code></td>
<td>
<p>flag to print out progress information. Default is FALSE.</p>
</td></tr>
<tr><td><code id="kde.local.test_+3A_supp">supp</code></td>
<td>
<p>effective support for normal kernel</p>
</td></tr>
<tr><td><code id="kde.local.test_+3A_mean.adj">mean.adj</code></td>
<td>
<p>flag to compute second order correction for mean value of critical sampling distribution. Default is FALSE. Currently implemented for d&lt;=2 only.</p>
</td></tr>
<tr><td><code id="kde.local.test_+3A_signif.level">signif.level</code></td>
<td>
<p>significance level. Default is 0.05.</p>
</td></tr>
<tr><td><code id="kde.local.test_+3A_min.ess">min.ESS</code></td>
<td>
<p>minimum effective sample size. See below for details.</p>
</td></tr>
<tr><td><code id="kde.local.test_+3A_xmin">xmin</code>, <code id="kde.local.test_+3A_xmax">xmax</code></td>
<td>
<p>vector of minimum/maximum values for grid</p>
</td></tr> 
</table>


<h3>Details</h3>

<p>The null hypothesis is <code class="reqn">H_0(\bold{x}): f_1(\bold{x}) = f_2(\bold{x})</code> where <code class="reqn">f_1, f_2</code> 
are the respective density functions. The measure of discrepancy is  
<code class="reqn">U(\bold{x}) = [f_1(\bold{x}) - f_2(\bold{x})]^2</code>. 
Duong (2013) shows that the test statistic obtained, by substituting the
KDEs for the true densities, has a null 
distribution which is asymptotically chi-squared with 1 d.f.
</p>
<p>The required input is either <code>x1,x2</code> and <code>H1,H2</code>, or
<code>fhat1,fhat2</code>, i.e. the data values and bandwidths or objects of class
<code>kde</code>. In the former case, the <code>kde</code> objects are created.
If the <code>H1,H2</code> are missing then the default are the plug-in
selectors <code>Hpi</code>.  Likewise for missing <code>h1,h2</code>. 
</p>
<p>The <code>mean.adj</code> flag determines whether the
second order correction to the mean value of the test statistic should be computed. 
<code>min.ESS</code> is borrowed from Godtliebsen et al. (2002)
to reduce spurious significant results in the tails, though by it is usually
not required for small to moderate sample sizes. 
</p>


<h3>Value</h3>

<p>A kernel two-sample local significance is an object of class
<code>kde.loctest</code> which is a list with fields:
</p>
<table role = "presentation">
<tr><td><code>fhat1</code>, <code>fhat2</code></td>
<td>
<p>kernel density estimates, objects of class <code>kde</code></p>
</td></tr>
<tr><td><code>chisq</code></td>
<td>
<p>chi squared test statistic</p>
</td></tr>
<tr><td><code>pvalue</code></td>
<td>
<p>matrix of local <code class="reqn">p</code>-values at each grid point</p>
</td></tr>
<tr><td><code>fhat.diff</code></td>
<td>
<p>difference of KDEs</p>
</td></tr>
<tr><td><code>mean.fhat.diff</code></td>
<td>
<p>mean of the test statistic</p>
</td></tr>  
<tr><td><code>var.fhat.diff</code></td>
<td>
<p>variance of the test statistic</p>
</td></tr>
<tr><td><code>fhat.diff.pos</code></td>
<td>
<p>binary matrix to indicate locally significant fhat1 &gt; fhat2</p>
</td></tr>
<tr><td><code>fhat.diff.neg</code></td>
<td>
<p>binary matrix to indicate locally significant fhat1 &lt; fhat2</p>
</td></tr>
<tr><td><code>n1</code>, <code>n2</code></td>
<td>
<p>sample sizes</p>
</td></tr>
<tr><td><code>H1</code>, <code>H2</code>, <code>h1</code>, <code>h2</code></td>
<td>
<p>bandwidth matrices/scalar bandwidths</p>
</td></tr>
</table>


<h3>References</h3>

<p>Duong, T. (2013) Local significant differences from non-parametric
two-sample tests. <em>Journal of Nonparametric Statistics</em>,
<b>25</b>, 635-645.
</p>
<p>Godtliebsen, F., Marron, J.S. &amp; Chaudhuri, P. (2002) 
Significance in scale space for bivariate density estimation.
<em>Journal of Computational and Graphical Statistics</em>,
<b>11</b>, 1-22.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+kde.test">kde.test</a></code>, <code><a href="#topic+plot.kde.loctest">plot.kde.loctest</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>data(crabs, package="MASS")
x1 &lt;- crabs[crabs$sp=="B", 4]
x2 &lt;- crabs[crabs$sp=="O", 4]
loct &lt;- kde.local.test(x1=x1, x2=x2)
plot(loct, ylim=c(-0.08,0.12))
cols &lt;- hcl.colors(palette="Dark2",2)
plot(loct$fhat1, add=TRUE, col=cols[1])
plot(loct$fhat2, add=TRUE, col=cols[2])

## see examples in ? plot.kde.loctest
</code></pre>

<hr>
<h2 id='kde.test'>Kernel density based global two-sample comparison test</h2><span id='topic+kde.test'></span>

<h3>Description</h3>

<p>Kernel density based global two-sample comparison test for 1- to 6-dimensional data.</p>


<h3>Usage</h3>

<pre><code class='language-R'>kde.test(x1, x2, H1, H2, h1, h2, psi1, psi2, var.fhat1, var.fhat2, 
    binned=FALSE, bgridsize, verbose=FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="kde.test_+3A_x1">x1</code>, <code id="kde.test_+3A_x2">x2</code></td>
<td>
<p>vector/matrix of data values</p>
</td></tr>
<tr><td><code id="kde.test_+3A_h1">H1</code>, <code id="kde.test_+3A_h2">H2</code>, <code id="kde.test_+3A_h1">h1</code>, <code id="kde.test_+3A_h2">h2</code></td>
<td>
<p>bandwidth matrices/scalar bandwidths. If these are
missing, <code>Hpi.kfe</code>, <code>hpi.kfe</code> is called by default.</p>
</td></tr>
<tr><td><code id="kde.test_+3A_psi1">psi1</code>, <code id="kde.test_+3A_psi2">psi2</code></td>
<td>
<p>zero-th order kernel functional estimates</p>
</td></tr>
<tr><td><code id="kde.test_+3A_var.fhat1">var.fhat1</code>, <code id="kde.test_+3A_var.fhat2">var.fhat2</code></td>
<td>
<p>sample variance of KDE estimates evaluated at x1, x2</p>
</td></tr>
<tr><td><code id="kde.test_+3A_binned">binned</code></td>
<td>
<p>flag for binned estimation. Default is FALSE.</p>
</td></tr>
<tr><td><code id="kde.test_+3A_bgridsize">bgridsize</code></td>
<td>
<p>vector of binning grid sizes</p>
</td></tr>
<tr><td><code id="kde.test_+3A_verbose">verbose</code></td>
<td>
<p>flag to print out progress information. Default is FALSE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The null hypothesis is <code class="reqn">H_0: f_1 \equiv f_2</code> where <code class="reqn">f_1, f_2</code> 
are the respective density functions. The measure of discrepancy is
the integrated squared error (ISE)
<code class="reqn">T = \int [f_1(\bold{x}) - f_2(\bold{x})]^2 \, d \bold{x}</code>. If 
we rewrite this as <code class="reqn">T = \psi_{0,1} - \psi_{0,12} - \psi_{0,21} + \psi_{0,2}</code> 
where <code class="reqn">\psi_{0,uv} = \int f_u (\bold{x}) f_v (\bold{x})  \, d \bold{x}</code>,
then we can use kernel functional estimators. This test statistic has a null 
distribution which is asymptotically normal, so no bootstrap
resampling is required to compute an approximate <code class="reqn">p</code>-value.     
</p>
<p>If <code>H1,H2</code> are missing then the  plug-in selector <code><a href="#topic+Hpi.kfe">Hpi.kfe</a></code>
is automatically called by <code>kde.test</code> to estimate the
functionals with <code>kfe(, deriv.order=0)</code>. Likewise for missing
<code>h1,h2</code>. 
</p>
<p>For <span class="pkg">ks</span> <code class="reqn">\geq</code> 1.8.8, <code>kde.test(,binned=TRUE)</code> invokes binned
estimation for the computation of the bandwidth selectors, and not the
test statistic and <code class="reqn">p</code>-value.  
</p>


<h3>Value</h3>

<p>A kernel two-sample global significance test is a list with fields:
</p>
<table role = "presentation">
<tr><td><code>Tstat</code></td>
<td>
<p>T statistic</p>
</td></tr>
<tr><td><code>zstat</code></td>
<td>
<p>z statistic - normalised version of Tstat</p>
</td></tr>
<tr><td><code>pvalue</code></td>
<td>
<p><code class="reqn">p</code>-value of the double sided test</p>
</td></tr>
<tr><td><code>mean</code>, <code>var</code></td>
<td>
<p>mean and variance of null distribution</p>
</td></tr>
<tr><td><code>var.fhat1</code>, <code>var.fhat2</code></td>
<td>
<p>sample variances of KDE values evaluated at data points</p>
</td></tr>
<tr><td><code>n1</code>, <code>n2</code></td>
<td>
<p>sample sizes</p>
</td></tr>
<tr><td><code>H1</code>, <code>H2</code></td>
<td>
<p>bandwidth matrices</p>
</td></tr>
<tr><td><code>psi1</code>, <code>psi12</code>, <code>psi21</code>, <code>psi2</code></td>
<td>
<p>kernel functional estimates</p>
</td></tr>
</table>


<h3>References</h3>

<p>Duong, T., Goud, B. &amp; Schauer, K. (2012) Closed-form density-based framework for automatic detection of cellular morphology changes. <em>PNAS</em>, <b>109</b>, 8382-8387. 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+kde.local.test">kde.local.test</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(8192)
samp &lt;- 1000
x &lt;- rnorm.mixt(n=samp, mus=0, sigmas=1, props=1)
y &lt;- rnorm.mixt(n=samp, mus=0, sigmas=1, props=1)
kde.test(x1=x, x2=y)$pvalue   ## accept H0: f1=f2

data(crabs, package="MASS")
x1 &lt;- crabs[crabs$sp=="B", c(4,6)]
x2 &lt;- crabs[crabs$sp=="O", c(4,6)]
kde.test(x1=x1, x2=x2)$pvalue  ## reject H0: f1=f2
</code></pre>

<hr>
<h2 id='kde.truncate'>Truncated kernel density derivative estimate</h2><span id='topic+kde.truncate'></span><span id='topic+kdde.truncate'></span>

<h3>Description</h3>

<p>Truncated kernel density derivative estimate for 2-dimensional data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>kde.truncate(fhat, boundary) 
kdde.truncate(fhat, boundary) 
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="kde.truncate_+3A_fhat">fhat</code></td>
<td>
<p>object of class <code>kde</code> or <code>kdde</code></p>
</td></tr>
<tr><td><code id="kde.truncate_+3A_boundary">boundary</code></td>
<td>
<p>two column matrix delimiting the boundary for truncation</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A simple truncation is performed on the kernel estimator. All the
points in the estimation grid which are outside of the regions
delimited by <code>boundary</code> are set to 0, and their probability
mass is distributed proportionally to the remaining density (derivative) values.
</p>


<h3>Value</h3>

<p>A truncated kernel density (derivative) estimate inherits the same
object class as the input estimate. 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+kde">kde</a></code>, <code><a href="#topic+kdde">kdde</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>data(worldbank)
wb &lt;- as.matrix(na.omit(worldbank[,c("internet", "ag.value")]))
fhat &lt;- kde(x=wb)
rectb &lt;- cbind(x=c(0,100,100,0,0), y=c(0,0,100,100,0))
fhat.b &lt;- kde.truncate(fhat, boundary=rectb)
plot(fhat, col=1, xlim=c(0,100), ylim=c(0,100))
plot(fhat.b, add=TRUE, col=4)
rect(0,0,100,100, lty=2)

library(oz)
data(grevillea)
wa.coast &lt;- ozRegion(section=1)
wa.polygon &lt;- cbind(wa.coast$lines[[1]]$x, wa.coast$lines[[1]]$y)
fhat1 &lt;- kdde(x=grevillea, deriv.order=1)
fhat1 &lt;- kdde.truncate(fhat1, wa.polygon)
oz(section=1, xlim=c(113,122), ylim=c(-36,-29))
plot(fhat1, add=TRUE, display="filled.contour")
</code></pre>

<hr>
<h2 id='kdr'>Kernel density ridge estimation</h2><span id='topic+kdr'></span><span id='topic+kdr.segment'></span><span id='topic+plot.kdr'></span>

<h3>Description</h3>

<p>Kernel density ridge estimation for 2- to 3-dimensional data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>kdr(x, y, H, p=1, max.iter=400, tol.iter, segment=TRUE, k, kmax, min.seg.size,
    keep.path=FALSE, gridsize, xmin, xmax, binned, bgridsize, w, fhat,
    density.cutoff, pre=TRUE, verbose=FALSE) 
kdr.segment(x, k, kmax, min.seg.size, verbose=FALSE) 

## S3 method for class 'kdr'
plot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="kdr_+3A_x">x</code></td>
<td>
<p>matrix of data values or an object of class <code>kdr</code></p>
</td></tr>
<tr><td><code id="kdr_+3A_y">y</code></td>
<td>
<p>matrix of initial values</p>
</td></tr>
<tr><td><code id="kdr_+3A_p">p</code></td>
<td>
<p>dimension of density ridge</p>
</td></tr>
<tr><td><code id="kdr_+3A_h">H</code></td>
<td>
<p>bandwidth matrix/scalar bandwidth. If missing,
<code>Hpi(x,deriv,order=2)</code> is called by default.</p>
</td></tr>
<tr><td><code id="kdr_+3A_max.iter">max.iter</code></td>
<td>
<p>maximum number of iterations. Default is 400.</p>
</td></tr>
<tr><td><code id="kdr_+3A_tol.iter">tol.iter</code></td>
<td>
<p>distance under which two successive iterations are
considered convergent. Default is 0.001*min marginal IQR of <code>x</code>.</p>
</td></tr>
<tr><td><code id="kdr_+3A_segment">segment</code></td>
<td>
<p>flag to compute segments of density ridge. Default is TRUE.</p>
</td></tr>
<tr><td><code id="kdr_+3A_k">k</code></td>
<td>
<p>number of segments to partition density ridge</p>
</td></tr>
<tr><td><code id="kdr_+3A_kmax">kmax</code></td>
<td>
<p>maximum number of segments to partition density ridge. Default is 30.</p>
</td></tr>


<tr><td><code id="kdr_+3A_min.seg.size">min.seg.size</code></td>
<td>
<p>minimum length of a segment of a density
ridge. Default is <code>round(0.001*nrow(y),0)</code>.</p>
</td></tr>
<tr><td><code id="kdr_+3A_keep.path">keep.path</code></td>
<td>
<p>flag to store the density gradient ascent
paths. Default is FALSE.</p>
</td></tr>
<tr><td><code id="kdr_+3A_gridsize">gridsize</code></td>
<td>
<p>vector of number of grid points</p>
</td></tr>
<tr><td><code id="kdr_+3A_xmin">xmin</code>, <code id="kdr_+3A_xmax">xmax</code></td>
<td>
<p>vector of minimum/maximum values for grid</p>
</td></tr>
<tr><td><code id="kdr_+3A_binned">binned</code></td>
<td>
<p>flag for binned estimation.</p>
</td></tr>
<tr><td><code id="kdr_+3A_bgridsize">bgridsize</code></td>
<td>
<p>vector of binning grid sizes</p>
</td></tr>
<tr><td><code id="kdr_+3A_w">w</code></td>
<td>
<p>vector of weights. Default is a vector of all ones.</p>
</td></tr>
<tr><td><code id="kdr_+3A_fhat">fhat</code></td>
<td>
<p>kde of <code>x</code>. If missing <code>kde(x=x,w=w)</code> is
executed.</p>
</td></tr>
<tr><td><code id="kdr_+3A_density.cutoff">density.cutoff</code></td>
<td>
<p>density threshold under which the <code>y</code> are
excluded from the density ridge estimation. Default is
<code>contourLevels(fhat, cont=99)</code>.</p>
</td></tr>
<tr><td><code id="kdr_+3A_pre">pre</code></td>
<td>
<p>flag for pre-scaling data. Default is TRUE.</p>
</td></tr>
<tr><td><code id="kdr_+3A_verbose">verbose</code></td>
<td>
<p>flag to print out progress information. Default is
FALSE.</p>
</td></tr>
<tr><td><code id="kdr_+3A_...">...</code></td>
<td>
<p>other graphics parameters</p>
</td></tr>
</table>


<h3>Details</h3>

 
<p>Kernel density ridge estimation is based on reduced dimension kernel
mean shift. See Ozertem &amp; Erdogmus (2011). 
</p>
<p>If <code>y</code> is missing, then it defaults to the grid of size
<code>gridsize</code> spanning from <code>xmin</code> to <code>xmax</code>.
</p>
<p>If the bandwidth <code>H</code> is missing, then
the default bandwidth is the plug-in selector for the density gradient
<code>Hpi(x,deriv.order=2)</code>. Any bandwidth that is suitable for the
density Hessian is also suitable for the kernel density ridge. 
</p>
<p><code>kdr(, segment=TRUE)</code> or <code>kdr.segment()</code> carries out the segmentation of the density ridge points in <code>end.points</code>. If <code>k</code> is set, then <code>k</code> segments are created. If <code>k</code> is not set, then the optimal number of segments is chosen from 1:<code>kmax</code>, with <code>kmax=30</code> by default. The segments are created via a hierarchical clustering with single linkage. *Experimental: following the segmentation, the points within each segment are ordered to facilitate a line plot in <code>plot(, type="l")</code>. The optimal ordering is not always achieved in this experimental implementation, though a scatterplot <code>plot(, type="p")</code> always suffices, regardless of this ordering.*    
</p>


<h3>Value</h3>

<p>A kernel density ridge set is an object of class <code>kdr</code>
which is a list with fields: 
</p>
<table role = "presentation">
<tr><td><code>x</code>, <code>y</code></td>
<td>
<p>data points - same as input</p>
</td></tr>
<tr><td><code>end.points</code></td>
<td>
<p>matrix of final iterates starting from <code>y</code></p>
</td></tr>
<tr><td><code>H</code></td>
<td>
<p>bandwidth matrix</p>
</td></tr>
<tr><td><code>names</code></td>
<td>
<p>variable names</p>
</td></tr>
<tr><td><code>tol.iter</code>, <code>tol.clust</code>, <code>min.seg.size</code></td>
<td>
<p>tuning parameter values -
same as input</p>
</td></tr>
<tr><td><code>binned</code></td>
<td>
<p>flag for binned estimation</p>
</td></tr>
<tr><td><code>names</code></td>
<td>
<p>variable names</p>
</td></tr> 
<tr><td><code>w</code></td>
<td>
<p>vector of weights</p>
</td></tr>
<tr><td><code>path</code></td>
<td>
<p>list of density gradient ascent paths where <code>path[[i]]</code> is
the path of <code>y[i,]</code> (only if <code>keep.path=TRUE</code>)</p>
</td></tr>
</table>


<h3>References</h3>

<p>Ozertem, U. &amp; Erdogmus, D. (2011) Locally defined principal curves and
surfaces, <em>Journal of Machine Learning Research</em>, <b>12</b>, 
1249-1286. 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(cardio)
set.seed(8192)
cardio.train.ind &lt;- sample(1:nrow(cardio), round(nrow(cardio)/4,0))
cardio2 &lt;- cardio[cardio.train.ind,c(8,18)]
cardio.dr2 &lt;- kdr(x=cardio2, gridsize=c(21,21))
## gridsize=c(21,21) is for illustrative purposes only
plot(cardio2, pch=16, col=3)
plot(cardio.dr2, cex=0.5, pch=16, col=6, add=TRUE)

## Not run: cardio3 &lt;- cardio[cardio.train.ind,c(8,18,11)]
cardio.dr3 &lt;- kdr(x=cardio3)
plot(cardio.dr3, pch=16, col=6, xlim=c(10,90), ylim=c(70,180), zlim=c(0,40))
plot3D::points3D(cardio3[,1], cardio3[,2], cardio3[,3], pch=16, col=3, add=TRUE)

library(maps)
data(quake) 
quake &lt;- quake[quake$prof==1,]  ## Pacific Ring of Fire 
quake$long[quake$long&lt;0] &lt;- quake$long[quake$long&lt;0] + 360
quake &lt;- quake[, c("long", "lat")]
data(plate)                     ## tectonic plate boundaries
plate &lt;- plate[plate$long &lt; -20 | plate$long &gt; 20,]
plate$long[plate$long&lt;0 &amp; !is.na(plate$long)] &lt;- plate$long[plate$long&lt;0
&amp; !is.na(plate$long)] + 360

quake.dr &lt;- kdr(x=quake, xmin=c(70,-70), xmax=c(310, 80))
map(wrap=c(0,360), lty=2)
lines(plate[,1:2], col=4, lwd=2)
plot(quake.dr, type="p", cex=0.5, pch=16, col=6, add=TRUE)
## End(Not run)
</code></pre>

<hr>
<h2 id='kfe'>Kernel functional estimate</h2><span id='topic+kfe'></span><span id='topic+Hpi.kfe'></span><span id='topic+Hpi.diag.kfe'></span><span id='topic+hpi.kfe'></span>

<h3>Description</h3>

<p>Kernel functional estimate for 1- to 6-dimensional data.</p>


<h3>Usage</h3>

<pre><code class='language-R'>kfe(x, G, deriv.order, inc=1, binned, bin.par, bgridsize, deriv.vec=TRUE,
    add.index=TRUE, verbose=FALSE)
Hpi.kfe(x, nstage=2, pilot, pre="sphere", Hstart, binned=FALSE, 
    bgridsize, amise=FALSE, deriv.order=0, verbose=FALSE, optim.fun="optim")
Hpi.diag.kfe(x, nstage=2, pilot, pre="scale", Hstart, binned=FALSE,
    bgridsize, amise=FALSE, deriv.order=0, verbose=FALSE, optim.fun="optim")
hpi.kfe(x, nstage=2, binned=FALSE, bgridsize, amise=FALSE, deriv.order=0)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="kfe_+3A_x">x</code></td>
<td>
<p>vector/matrix of data values</p>
</td></tr>
<tr><td><code id="kfe_+3A_nstage">nstage</code></td>
<td>
<p>number of stages in the plug-in bandwidth selector (1 or 2)</p>
</td></tr>
<tr><td><code id="kfe_+3A_pilot">pilot</code></td>
<td>
<p>&quot;dscalar&quot; = single pilot bandwidth (default) <br />
&quot;dunconstr&quot; = single unconstrained pilot bandwidth</p>
</td></tr>
<tr><td><code id="kfe_+3A_pre">pre</code></td>
<td>
<p>&quot;scale&quot; = <code><a href="#topic+pre.scale">pre.scale</a></code>, &quot;sphere&quot; = <code><a href="#topic+pre.sphere">pre.sphere</a></code></p>
</td></tr>
<tr><td><code id="kfe_+3A_hstart">Hstart</code></td>
<td>
<p>initial bandwidth matrix, used in numerical optimisation</p>
</td></tr>
<tr><td><code id="kfe_+3A_binned">binned</code></td>
<td>
<p>flag for binned estimation</p>
</td></tr>
<tr><td><code id="kfe_+3A_bgridsize">bgridsize</code></td>
<td>
<p>vector of binning grid sizes</p>
</td></tr>
<tr><td><code id="kfe_+3A_amise">amise</code></td>
<td>
<p>flag to return the minimal scaled PI value</p>
</td></tr>
<tr><td><code id="kfe_+3A_deriv.order">deriv.order</code></td>
<td>
<p>derivative order</p>
</td></tr>
<tr><td><code id="kfe_+3A_verbose">verbose</code></td>
<td>
<p>flag to print out progress information. Default is FALSE.</p>
</td></tr>
<tr><td><code id="kfe_+3A_optim.fun">optim.fun</code></td>
<td>
<p>optimiser function: one of <code>nlm</code> or <code>optim</code></p>
</td></tr>
<tr><td><code id="kfe_+3A_g">G</code></td>
<td>
<p>pilot bandwidth matrix</p>
</td></tr>
<tr><td><code id="kfe_+3A_inc">inc</code></td>
<td>
<p>0=exclude diagonal, 1=include diagonal terms in kfe
calculation</p>
</td></tr>
<tr><td><code id="kfe_+3A_bin.par">bin.par</code></td>
<td>
<p>binning parameters - output from <code><a href="#topic+binning">binning</a></code></p>
</td></tr>
<tr><td><code id="kfe_+3A_deriv.vec">deriv.vec</code></td>
<td>
<p>flag to compute duplicated partial derivatives in the 
vectorised form. Default is FALSE.</p>
</td></tr>
<tr><td><code id="kfe_+3A_add.index">add.index</code></td>
<td>
<p>flag to output derivative indices matrix. Default is true.</p>
</td></tr>  
</table>


<h3>Details</h3>

<p><code>Hpi.kfe</code> is the optimal plug-in bandwidth for <code class="reqn">r</code>-th order kernel functional estimator
based on the unconstrained pilot selectors of Chacon &amp; Duong (2010).
<code>hpi.kfe</code> is the 1-d equivalent, using the formulas from
Wand &amp; Jones (1995, p.70).
</p>
<p><code>kfe</code> does not usually need to be called explicitly by the user.     
</p>


<h3>Value</h3>

<p>Plug-in bandwidth matrix for <code class="reqn">r</code>-th order kernel functional estimator.
</p>


<h3>References</h3>

<p>Chacon, J.E. &amp; Duong, T. (2010) Multivariate plug-in bandwidth
selection with unconstrained pilot matrices. <em>Test</em>, <b>19</b>,
375-398.
</p>
<p>Wand, M.P. &amp; Jones, M.C. (1995) <em>Kernel Smoothing</em>. Chapman &amp;
Hall/CRC, London. 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+kde.test">kde.test</a></code></p>

<hr>
<h2 id='kfs'>Kernel feature significance </h2><span id='topic+kfs'></span>

<h3>Description</h3>

<p>Kernel feature significance for 1- to 6-dimensional data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>kfs(x, H, h, deriv.order=2, gridsize, gridtype, xmin, xmax, supp=3.7,
    eval.points, binned, bgridsize, positive=FALSE, adj.positive, w, 
    verbose=FALSE, signif.level=0.05)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="kfs_+3A_x">x</code></td>
<td>
<p>matrix of data values</p>
</td></tr>
<tr><td><code id="kfs_+3A_h">H</code>, <code id="kfs_+3A_h">h</code></td>
<td>
<p>bandwidth matrix/scalar bandwidth. If these are missing, <code>Hpi</code> or <code>hpi</code> is called by default.</p>
</td></tr>
<tr><td><code id="kfs_+3A_deriv.order">deriv.order</code></td>
<td>
<p>derivative order (scalar)</p>
</td></tr>
<tr><td><code id="kfs_+3A_gridsize">gridsize</code></td>
<td>
<p>vector of number of grid points</p>
</td></tr>
<tr><td><code id="kfs_+3A_gridtype">gridtype</code></td>
<td>
<p>not yet implemented</p>
</td></tr>
<tr><td><code id="kfs_+3A_xmin">xmin</code>, <code id="kfs_+3A_xmax">xmax</code></td>
<td>
<p>vector of minimum/maximum values for grid</p>
</td></tr>
<tr><td><code id="kfs_+3A_supp">supp</code></td>
<td>
<p>effective support for standard normal</p>
</td></tr>
<tr><td><code id="kfs_+3A_eval.points">eval.points</code></td>
<td>
<p>vector or matrix of points at which estimate is evaluated</p>
</td></tr>
<tr><td><code id="kfs_+3A_binned">binned</code></td>
<td>
<p>flag for binned estimation</p>
</td></tr>
<tr><td><code id="kfs_+3A_bgridsize">bgridsize</code></td>
<td>
<p>vector of binning grid sizes</p>
</td></tr>
<tr><td><code id="kfs_+3A_positive">positive</code></td>
<td>
<p>flag if 1-d data are positive. Default is FALSE.</p>
</td></tr>
<tr><td><code id="kfs_+3A_adj.positive">adj.positive</code></td>
<td>
<p>adjustment applied to positive 1-d data</p>
</td></tr>
<tr><td><code id="kfs_+3A_w">w</code></td>
<td>
<p>vector of weights. Default is a vector of all ones.</p>
</td></tr>
<tr><td><code id="kfs_+3A_verbose">verbose</code></td>
<td>
<p>flag to print out progress information. Default is
FALSE.</p>
</td></tr>
<tr><td><code id="kfs_+3A_signif.level">signif.level</code></td>
<td>
<p>overall level of significance for hypothesis
tests. Default is 0.05.</p>
</td></tr> 
</table>


<h3>Details</h3>

<p>Feature significance is based on significance testing of the gradient
(first derivative) and curvature (second derivative) of a kernel
density estimate. Only the latter is currently implemented, and is
also known as significant modal regions.
</p>
<p>The hypothesis test at a grid point <code class="reqn">\bold{x}</code> is
<code class="reqn">H_0(\bold{x}): \mathsf{H} f(\bold{x}) &lt; 0</code>,
i.e.  the density Hessian matrix <code class="reqn">\mathsf{H} f(\bold{x})</code> is negative definite.
The <code class="reqn">p</code>-values are computed for each <code class="reqn">\bold{x}</code> using that
the test statistic is
approximately chi-squared distributed with <code class="reqn">d(d+1)/2</code> d.f.
We then use a Hochberg-type simultaneous testing procedure, based on the
ordered <code class="reqn">p</code>-values, to control the
overall level of significance to be <code>signif.level</code>. If
<code class="reqn">H_0(\bold{x})</code> is rejected then <code class="reqn">\bold{x}</code>
belongs to a significant modal region. 
</p>
<p>The computations are based on <code>kdde(x, deriv.order=2)</code> so
<code>kfs</code> inherits its behaviour from <code><a href="#topic+kdde">kdde</a></code>.
If the bandwidth <code>H</code> is missing, then
the default bandwidth is the plug-in selector
<code>Hpi(,deriv.order=2)</code>. Likewise for missing <code>h</code>.
The effective support, binning, grid size, grid range, positive
parameters are the same as <code><a href="#topic+kde">kde</a></code>.
</p>
<p>This function is similar to the <code>featureSignif</code> function in the
<span class="pkg">feature</span> package, except that it accepts unconstrained bandwidth
matrices. 
</p>


<h3>Value</h3>

<p>A kernel feature significance estimate is an object of class
<code>kfs</code> which is a list with fields 
</p>
<table role = "presentation">
<tr><td><code>x</code></td>
<td>
<p>data points - same as input</p>
</td></tr>
<tr><td><code>eval.points</code></td>
<td>
<p>vector or list of points at which the estimate is evaluated</p>
</td></tr>
<tr><td><code>estimate</code></td>
<td>
<p>binary matrix for significant feature at
<code>eval.points</code>: 0 = not signif.,  1 = signif.</p>
</td></tr>
<tr><td><code>h</code></td>
<td>
<p>scalar bandwidth (1-d only)</p>
</td></tr>
<tr><td><code>H</code></td>
<td>
<p>bandwidth matrix</p>
</td></tr>
<tr><td><code>gridtype</code></td>
<td>
<p>&quot;linear&quot;</p>
</td></tr>
<tr><td><code>gridded</code></td>
<td>
<p>flag for estimation on a grid</p>
</td></tr>
<tr><td><code>binned</code></td>
<td>
<p>flag for binned estimation</p>
</td></tr>
<tr><td><code>names</code></td>
<td>
<p>variable names</p>
</td></tr>
<tr><td><code>w</code></td>
<td>
<p>vector of weights</p>
</td></tr>
<tr><td><code>deriv.order</code></td>
<td>
<p>derivative order (scalar)</p>
</td></tr>
<tr><td><code>deriv.ind</code></td>
<td>
<p>martix where each row is a vector of partial derivative indices.</p>
</td></tr>
</table>
<p>This is the same structure as a <code>kdde</code> object, except that
<code>estimate</code> is a binary matrix rather than real-valued. 
</p>


<h3>References</h3>

<p>Chaudhuri, P. &amp; Marron, J.S. (1999) 
SiZer for exploration of structures in curves.
<em>Journal of the American Statistical Association</em>,
<b>94</b>,  807-823.
</p>
<p>Duong, T., Cowling, A., Koch, I. &amp; Wand, M.P. (2008)
Feature significance for multivariate kernel density estimation.
<em>Computational Statistics and Data Analysis</em>, <b>52</b>,
4225-4242. 
</p>
<p>Godtliebsen, F., Marron, J.S. &amp; Chaudhuri, P. (2002) 
Significance in scale space for bivariate density estimation.
<em>Journal of Computational and Graphical Statistics</em>,
<b>11</b>, 1-22.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+kdde">kdde</a></code>, <code><a href="#topic+plot.kfs">plot.kfs</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>data(geyser, package="MASS")
geyser.fs &lt;- kfs(geyser$duration, binned=TRUE)
plot(geyser.fs, xlab="duration")

## see example in ? plot.kfs
</code></pre>

<hr>
<h2 id='kms'>Kernel mean shift clustering</h2><span id='topic+kms'></span><span id='topic+summary.kms'></span><span id='topic+plot.kms'></span>

<h3>Description</h3>

<p>Kernel mean shift clustering for 2- to 6-dimensional data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>kms(x, y, H, max.iter=400, tol.iter, tol.clust, min.clust.size, merge=TRUE,
    keep.path=FALSE, verbose=FALSE)

## S3 method for class 'kms'
plot(x, display="splom", col, col.fun, alpha=1, xlab, ylab, zlab, theta=-30, 
    phi=40, add=FALSE, ...)
## S3 method for class 'kms'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="kms_+3A_x">x</code></td>
<td>
<p>matrix of data values or object of class <code>kms</code></p>
</td></tr>
<tr><td><code id="kms_+3A_y">y</code></td>
<td>
<p>matrix of candidate data values for which the mean shift will
estimate their cluster labels. If missing, <code>y=x</code>.</p>
</td></tr>
<tr><td><code id="kms_+3A_h">H</code></td>
<td>
<p>bandwidth matrix/scalar bandwidth. If missing,
<code>Hpi(x,deriv.order=1,nstage=2-(d&gt;2))</code> is called by default.</p>
</td></tr>
<tr><td><code id="kms_+3A_max.iter">max.iter</code></td>
<td>
<p>maximum number of iterations. Default is 400.</p>
</td></tr>
<tr><td><code id="kms_+3A_tol.iter">tol.iter</code></td>
<td>
<p>distance under which two successive iterations are
considered convergent. Default is 0.001*min marginal IQR of <code>x</code>.</p>
</td></tr>
<tr><td><code id="kms_+3A_tol.clust">tol.clust</code></td>
<td>
<p>distance under which two cluster modes are considered
to form one cluster. Default is 0.01*max marginal IQR of <code>x</code>.</p>
</td></tr>
<tr><td><code id="kms_+3A_min.clust.size">min.clust.size</code></td>
<td>
<p>minimum cluster size (cardinality). Default is <code>0.01*nrow(y)</code>.</p>
</td></tr>
<tr><td><code id="kms_+3A_merge">merge</code></td>
<td>
<p>flag to merge clusters which are smaller than
<code>min.clust.size</code>. Default is TRUE.</p>
</td></tr>
<tr><td><code id="kms_+3A_keep.path">keep.path</code></td>
<td>
<p>flag to store the density gradient ascent paths. Default is FALSE.</p>
</td></tr>
<tr><td><code id="kms_+3A_verbose">verbose</code></td>
<td>
<p>flag to print out progress information. Default is
FALSE.</p>
</td></tr>
<tr><td><code id="kms_+3A_object">object</code></td>
<td>
<p>object of class <code>kms</code></p>
</td></tr>
<tr><td><code id="kms_+3A_display">display</code></td>
<td>
<p>type of display, &quot;splom&quot; (&gt;=2-d) or &quot;plot3D&quot; (3-d)</p>
</td></tr>
<tr><td><code id="kms_+3A_col">col</code>, <code id="kms_+3A_col.fun">col.fun</code></td>
<td>
<p>vector or colours (one for each group) or colour function</p>
</td></tr>
<tr><td><code id="kms_+3A_alpha">alpha</code></td>
<td>
<p>colour transparency. Default is 1.</p>
</td></tr>
<tr><td><code id="kms_+3A_xlab">xlab</code>, <code id="kms_+3A_ylab">ylab</code>, <code id="kms_+3A_zlab">zlab</code></td>
<td>
<p>axes labels</p>
</td></tr>
<tr><td><code id="kms_+3A_theta">theta</code>, <code id="kms_+3A_phi">phi</code></td>
<td>
<p>graphics parameters for perspective plots (3-d)</p>
</td></tr>
<tr><td><code id="kms_+3A_add">add</code></td>
<td>
<p>flag to add to current plot. Default is FALSE.</p>
</td></tr>
<tr><td><code id="kms_+3A_...">...</code></td>
<td>
<p>other (graphics) parameters</p>
</td></tr>
</table>


<h3>Details</h3>

 
<p>Mean shift clustering belongs to the class of modal or density-based
clustering methods.
The mean shift recurrence of the candidate point <code class="reqn">{\bold x}</code> is
<code class="reqn">{\bold x}_{j+1} = {\bold x}_j + \bold{{\rm H}} {\sf D} \hat{f}({\bold
      x}_j)/\hat{f}({\bold x}_j)</code>
where <code class="reqn">j\geq 0</code> and <code class="reqn">{\bold x}_0 = {\bold x}</code>.
The sequence <code class="reqn">\{{\bold x}_0, {\bold
  x}_1, \dots \}</code> follows the density gradient ascent
paths to converge to a local mode of the
density estimate <code class="reqn">\hat{f}</code>. Hence <code class="reqn">{\bold x}</code> is
iterated until it converges to its local mode, and this determines its
cluster label.  
</p>
<p>The mean shift recurrence is terminated if successive iterations are
less than <code>tol.iter</code> or the maximum number of iterations
<code>max.iter</code> is reached. Final iterates which are less than
<code>tol.clust</code> distance apart are considered to form a single
cluster. If <code>merge=TRUE</code> then the clusters whose cardinality is less
than <code>min.clust.size</code> are iteratively merged with their nearest cluster.   
</p>
<p>If the bandwidth <code>H</code> is missing, then
the default bandwidth is the plug-in selector for the density gradient
<code>Hpi(x,deriv.order=1)</code>. Any bandwidth that is suitable for the
density gradient is also suitable for the mean shift. 
</p>


<h3>Value</h3>

<p>A kernel mean shift clusters set is an object of class <code>kms</code>
which is a list with fields: 
</p>
<table role = "presentation">
<tr><td><code>x</code>, <code>y</code></td>
<td>
<p>data points - same as input</p>
</td></tr>
<tr><td><code>end.points</code></td>
<td>
<p>matrix of final iterates starting from <code>y</code></p>
</td></tr>
<tr><td><code>H</code></td>
<td>
<p>bandwidth matrix</p>
</td></tr>
<tr><td><code>label</code></td>
<td>
<p>vector of cluster labels</p>
</td></tr>
<tr><td><code>nclust</code></td>
<td>
<p>number of clusters</p>
</td></tr>
<tr><td><code>nclust.table</code></td>
<td>
<p>frequency table of cluster labels</p>
</td></tr>
<tr><td><code>mode</code></td>
<td>
<p>matrix of cluster modes</p>
</td></tr>
<tr><td><code>names</code></td>
<td>
<p>variable names</p>
</td></tr>
<tr><td><code>tol.iter</code>, <code>tol.clust</code>, <code>min.clust.size</code></td>
<td>
<p>tuning parameter values -
same as input</p>
</td></tr>
<tr><td><code>path</code></td>
<td>
<p>list of density gradient ascent paths where <code>path[[i]]</code> is
the path of <code>y[i,]</code> (only if <code>keep.path=TRUE</code>)</p>
</td></tr>
</table>


<h3>References</h3>

<p>Chacon, J.E. &amp; Duong, T. (2013) Data-driven density estimation, with
applications to nonparametric clustering and bump hunting. <em>Electronic
Journal of Statistics</em>, <b>7</b>, 499-532.
</p>
<p>Comaniciu, D. &amp; Meer, P. (2002). Mean shift: a robust approach
toward feature space analysis. <em> IEEE Transactions on Pattern
Analysis and Machine Intelligence</em>, <b>24</b>, 603-619.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+kde">kde</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>data(crabs, package="MASS")
kms.crabs &lt;- kms(x=crabs[,c("FL","CW")])
plot(kms.crabs, pch=16)
summary(kms.crabs)

kms.crabs &lt;- kms(x=crabs[,c("FL","CW","RW")])
plot(kms.crabs, pch=16)
plot(kms.crabs, display="plot3D", pch=16) 
</code></pre>

<hr>
<h2 id='kroc'>Kernel receiver operating characteristic (ROC) curve</h2><span id='topic+kroc'></span><span id='topic+predict.kroc'></span><span id='topic+summary.kroc'></span>

<h3>Description</h3>

<p> Kernel receiver operating characteristic (ROC) curve for 1- to 3-dimensional data.</p>


<h3>Usage</h3>

<pre><code class='language-R'>kroc(x1, x2, H1, h1, hy, gridsize, gridtype, xmin, xmax, supp=3.7, eval.points,
   binned, bgridsize, positive=FALSE, adj.positive, w, verbose=FALSE)

## S3 method for class 'kroc'
predict(object, ..., x)
## S3 method for class 'kroc'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="kroc_+3A_x">x</code>, <code id="kroc_+3A_x1">x1</code>, <code id="kroc_+3A_x2">x2</code></td>
<td>
<p>vector/matrix of data values</p>
</td></tr>
<tr><td><code id="kroc_+3A_h1">H1</code>, <code id="kroc_+3A_h1">h1</code>, <code id="kroc_+3A_hy">hy</code></td>
<td>
<p>bandwidth matrix/scalar bandwidths. If these are
missing, <code>Hpi.kcde</code>, <code>hpi.kcde</code> is called by default.</p>
</td></tr> 
<tr><td><code id="kroc_+3A_gridsize">gridsize</code></td>
<td>
<p>vector of number of grid points</p>
</td></tr>
<tr><td><code id="kroc_+3A_gridtype">gridtype</code></td>
<td>
<p>not yet implemented</p>
</td></tr>
<tr><td><code id="kroc_+3A_xmin">xmin</code>, <code id="kroc_+3A_xmax">xmax</code></td>
<td>
<p>vector of minimum/maximum values for grid</p>
</td></tr>
<tr><td><code id="kroc_+3A_supp">supp</code></td>
<td>
<p>effective support for standard normal</p>
</td></tr>
<tr><td><code id="kroc_+3A_eval.points">eval.points</code></td>
<td>
<p>not yet implemented</p>
</td></tr>
<tr><td><code id="kroc_+3A_binned">binned</code></td>
<td>
<p>flag for binned estimation</p>
</td></tr>
<tr><td><code id="kroc_+3A_bgridsize">bgridsize</code></td>
<td>
<p>vector of binning grid sizes</p>
</td></tr>
<tr><td><code id="kroc_+3A_positive">positive</code></td>
<td>
<p>flag if 1-d data are positive. Default is FALSE.</p>
</td></tr>
<tr><td><code id="kroc_+3A_adj.positive">adj.positive</code></td>
<td>
<p>adjustment applied to positive 1-d data</p>
</td></tr>
<tr><td><code id="kroc_+3A_w">w</code></td>
<td>
<p>vector of weights. Default is a vector of all ones.</p>
</td></tr>
<tr><td><code id="kroc_+3A_verbose">verbose</code></td>
<td>
<p>flag to print out progress information. Default is
FALSE.</p>
</td></tr>
<tr><td><code id="kroc_+3A_object">object</code></td>
<td>
<p>object of class <code>kroc</code>, output from <code>kroc</code></p>
</td></tr>
<tr><td><code id="kroc_+3A_...">...</code></td>
<td>
<p>other parameters</p>
</td></tr> 
</table>


<h3>Details</h3>

<p>In this set-up, the values in the first sample <code>x1</code> should
be larger in general that those in the second sample <code>x2</code>. The
usual method for computing 1-d ROC curves is not valid for
multivariate data. Duong (2014), 
based on Lloyd (1998), develops an alternative formulation
<code class="reqn">(F_{Y_1}(z), F_{Y_2}(z))</code> based on the
cumulative distribution functions of <code class="reqn">Y_j = \bar{F}_1(\bold{X}_j), j=1,2</code>.
</p>
<p>If the bandwidth <code>H1</code> is missing from <code>kroc</code>, then
the default bandwidth is the  plug-in selector
<code>Hpi.kcde</code>. Likewise for missing <code>h1,hy</code>. A bandwidth matrix
<code>H1</code> is required for <code>x1</code> for d&gt;1, but the second bandwidth <code>hy</code> is always a scalar since <code class="reqn">Y_j</code> are 1-d variables.
</p>
<p>The effective support, binning, grid size, grid range, positive
parameters are the same as <code><a href="#topic+kde">kde</a></code>. 
</p>
<p>&ndash;The <code>summary</code> method for <code>kroc</code> objects prints out the
summary indices of the ROC curve, as contained in the <code>indices</code>
field, namely the AUC (area under the curve) and Youden index.
</p>


<h3>Value</h3>

<p>A kernel ROC curve is an object of class <code>kroc</code> which is a list
with fields:
</p>
<table role = "presentation">
<tr><td><code>x</code></td>
<td>
<p>list of data values <code>x1, x2</code> - same as input</p>
</td></tr>
<tr><td><code>eval.points</code></td>
<td>
<p>vector or list of points at which the estimate is evaluated</p>
</td></tr>
<tr><td><code>estimate</code></td>
<td>
<p>ROC curve estimate at <code>eval.points</code></p>
</td></tr>
<tr><td><code>gridtype</code></td>
<td>
<p>&quot;linear&quot;</p>
</td></tr>
<tr><td><code>gridded</code></td>
<td>
<p>flag for estimation on a grid</p>
</td></tr>
<tr><td><code>binned</code></td>
<td>
<p>flag for binned estimation</p>
</td></tr>
<tr><td><code>names</code></td>
<td>
<p>variable names</p>
</td></tr>
<tr><td><code>w</code></td>
<td>
<p>vector of weights</p>
</td></tr>
<tr><td><code>tail</code></td>
<td>
<p>&quot;lower.tail&quot;</p>
</td></tr>
<tr><td><code>h1</code></td>
<td>
<p>scalar bandwidth for first sample (1-d only)</p>
</td></tr>
<tr><td><code>H1</code></td>
<td>
<p>bandwidth matrix for first sample</p>
</td></tr>
<tr><td><code>hy</code></td>
<td>
<p>scalar bandwidth for ROC curve</p>
</td></tr>
<tr><td><code>indices</code></td>
<td>
<p>summary indices of ROC curve.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Duong, T. (2016) Non-parametric smoothed estimation of multivariate
cumulative distribution and survival functions, and receiver operating
characteristic curves. <em>Journal of the Korean Statistical
Society</em>, <b>45</b>, 33-50.
</p>
<p>Lloyd, C. (1998) Using smoothed receiver operating curves to summarize
and compare diagnostic systems. <em>Journal of the American
Statistical Association</em>, <b>93</b>, 1356-1364.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+kcde">kcde</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>samp &lt;- 1000
x &lt;- rnorm.mixt(n=samp, mus=0, sigmas=1, props=1)
y &lt;- rnorm.mixt(n=samp, mus=0.5, sigmas=1, props=1)
Rhat &lt;- kroc(x1=x, x2=y)
summary(Rhat)
predict(Rhat, x=0.5) 
</code></pre>

<hr>
<h2 id='ks-internal'>Internal functions in the ks library</h2><span id='topic+getRow'></span><span id='topic+Lpdiff'></span><span id='topic+matrix.sqrt'></span><span id='topic+mur'></span><span id='topic+nur'></span><span id='topic+nurs'></span><span id='topic+Qr'></span><span id='topic+rowKpow'></span><span id='topic+Sdr'></span><span id='topic+Sdrv'></span><span id='topic+symconv.1d'></span><span id='topic+symconv.nd'></span><span id='topic+dwsupp'></span><span id='topic+reg.ucv'></span><span id='topic+kr'></span>

<h3>Description</h3>

<p>These functions are user-level but which the user is not required to use directly.
</p>


<h3>Value</h3>

<p>The user is not required to use directly these outputs.</p>

<hr>
<h2 id='ksupp'>Kernel support estimate</h2><span id='topic+ksupp'></span><span id='topic+plot.ksupp'></span>

<h3>Description</h3>

<p>Kernel support estimate for 2 and 3-dimensional data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ksupp(fhat, cont=95, abs.cont, convex.hull=TRUE)

## S3 method for class 'ksupp'
plot(x, display="plot3D", ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ksupp_+3A_fhat">fhat</code></td>
<td>
<p>object of class <code>kde</code></p>
</td></tr>
<tr><td><code id="ksupp_+3A_cont">cont</code></td>
<td>
<p>percentage for contour level curve. Default
is 95.</p>
</td></tr>
<tr><td><code id="ksupp_+3A_abs.cont">abs.cont</code></td>
<td>
<p>absolute density estimate height for contour level curve</p>
</td></tr>
<tr><td><code id="ksupp_+3A_convex.hull">convex.hull</code></td>
<td>
<p>flag to compute convex hull of contour level
curve. Default is TRUE.</p>
</td></tr>
<tr><td><code id="ksupp_+3A_x">x</code></td>
<td>
<p>object of class <code>ksupp</code></p>
</td></tr>
<tr><td><code id="ksupp_+3A_display">display</code></td>
<td>
<p>one of &quot;plot3D&quot;, &quot;rgl&quot; (required for 3-d only)</p>
</td></tr>
<tr><td><code id="ksupp_+3A_...">...</code></td>
<td>
<p>other graphics parameters</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The kernel support estimate is the level set of the density estimate
that exceeds the <code>cont</code> percent contour level. If this level set
is a simply connected region, then this can suffice to be a
conservative estimate of the density support. Otherwise, the convex
hull of the level set is advised. For 2-d data, the convex hull is computed by <code>chull</code>; for 3-d data, it is computed by <code>geometry::convhulln</code>.
</p>


<h3>Value</h3>

<p>A kernel support estimate is an object of class <code>ksupp</code>, i.e. a 2- or 3-column matrix which delimits the (convex hull of the) level set of the density estimate <code>fhat</code>.  
</p>


<h3>See Also</h3>

<p><code><a href="#topic+kde">kde</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>data(grevillea)
fhat &lt;- kde(x=grevillea)
fhat.supp &lt;- ksupp(fhat)
plot(fhat, display="filled.contour", cont=seq(10,90,by=10))
plot(fhat, cont=95, add=TRUE, col=1)
plot(fhat.supp, lty=2)

data(iris)
fhat &lt;- kde(x=iris[,1:3])
fhat.supp &lt;- ksupp(fhat)
plot(fhat)
plot(fhat.supp, add=TRUE, col=3, alpha=0.1)
</code></pre>

<hr>
<h2 id='mixt'>Normal and t-mixture distributions</h2><span id='topic+rnorm.mixt'></span><span id='topic+dnorm.mixt'></span><span id='topic+rmvnorm.mixt'></span><span id='topic+dmvnorm.mixt'></span><span id='topic+rmvt.mixt'></span><span id='topic+dmvt.mixt'></span><span id='topic+mvnorm.mixt.mode'></span>

<h3>Description</h3>

<p>Random generation and density values from normal and t-mixture distributions.</p>


<h3>Usage</h3>

<pre><code class='language-R'>dnorm.mixt(x, mus=0, sigmas=1, props=1)
rnorm.mixt(n=100, mus=0, sigmas=1, props=1, mixt.label=FALSE)
dmvnorm.mixt(x, mus, Sigmas, props=1, verbose=FALSE)
rmvnorm.mixt(n=100, mus=c(0,0), Sigmas=diag(2), props=1, mixt.label=FALSE)
rmvt.mixt(n=100, mus=c(0,0), Sigmas=diag(2), dfs=7, props=1)
dmvt.mixt(x, mus, Sigmas, dfs, props)
mvnorm.mixt.mode(mus, Sigmas, props=1, verbose=FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mixt_+3A_n">n</code></td>
<td>
<p>number of random variates</p>
</td></tr>
<tr><td><code id="mixt_+3A_x">x</code></td>
<td>
<p>matrix of quantiles</p>
</td></tr>
<tr><td><code id="mixt_+3A_mus">mus</code></td>
<td>
<p>(stacked) matrix of mean vectors (&gt;1-d) or vector of means (1-d)</p>
</td></tr>
<tr><td><code id="mixt_+3A_sigmas">Sigmas</code></td>
<td>
<p>(stacked) matrix of variance matrices (&gt;1-d)</p>
</td></tr>
<tr><td><code id="mixt_+3A_sigmas">sigmas</code></td>
<td>
<p>vector of standard deviations (1-d)</p>
</td></tr>
<tr><td><code id="mixt_+3A_props">props</code></td>
<td>
<p>vector of mixing proportions</p>
</td></tr>
<tr><td><code id="mixt_+3A_mixt.label">mixt.label</code></td>
<td>
<p>flag to output numeric label indicating mixture
component. Default is FALSE.</p>
</td></tr>
<tr><td><code id="mixt_+3A_verbose">verbose</code></td>
<td>
<p>flag to print out progress information. Default is FALSE.</p>
</td></tr>
<tr><td><code id="mixt_+3A_dfs">dfs</code></td>
<td>
<p>vector of degrees of freedom</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>rmvnorm.mixt</code> and <code>dmvnorm.mixt</code> are based on the
<code>rmvnorm</code> and <code>dmvnorm</code> functions from the <span class="pkg">mvtnorm</span>
package. Likewise for <code>rmvt.mixt</code> and <code>dmvt.mixt</code>.
</p>
<p>For the normal mixture densities, <code>mvnorm.mixt.mode</code> computes the
local modes: these are usually very close but not exactly equal to the
component means.
</p>


<h3>Value</h3>

<p>Normal and t-mixture random vectors and density values.</p>


<h3>Examples</h3>

<pre><code class='language-R'>## univariate normal mixture
x &lt;- rnorm.mixt(1000, mus=c(-1,1), sigmas=c(0.5, 0.5), props=c(1/2, 1/2))

## bivariate mixtures 
mus &lt;- rbind(c(-1,0), c(1, 2/sqrt(3)), c(1,-2/sqrt(3)))
Sigmas &lt;- 1/25*rbind(invvech(c(9, 63/10, 49/4)), invvech(c(9,0,49/4)), invvech(c(9,0,49/4)))
props &lt;- c(3,3,1)/7
dfs &lt;- c(7,3,2)
x &lt;- rmvnorm.mixt(1000, mus=mus, Sigmas=Sigmas, props=props)
y &lt;- rmvt.mixt(1000, mus=mus, Sigmas=Sigmas, dfs=dfs, props=props)

mvnorm.mixt.mode(mus=mus, Sigmas=Sigmas, props=props)
</code></pre>

<hr>
<h2 id='plot.histde'>Plot for histogram density estimate</h2><span id='topic+plot.histde'></span>

<h3>Description</h3>

<p>Plot for histogram density estimate for 1- and 2-dimensional data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'histde'
plot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot.histde_+3A_x">x</code></td>
<td>
<p>object of class <code>histde</code> (output from <code><a href="#topic+histde">histde</a></code>)</p>
</td></tr>
<tr><td><code id="plot.histde_+3A_...">...</code></td>
<td>
<p>other graphics parameters:
</p>

<dl>
<dt><code>col</code></dt><dd><p>plotting colour for density estimate</p>
</dd>
<dt><code>col.fun</code></dt><dd><p>plotting colour function for levels</p>
</dd>
<dt><code>col.pt</code></dt><dd><p>plotting colour for data points</p>
</dd>
<dt><code>jitter</code></dt><dd><p>flag to jitter rug plot (1-d). Default is TRUE.</p>
</dd>
<dt><code>xlim,ylim</code></dt><dd><p>axes limits</p>
</dd>
<dt><code>xlab,ylab</code></dt><dd><p>axes labels</p>
</dd>
<dt><code>add</code></dt><dd><p>flag to add to current plot. Default is FALSE.</p>
</dd>
<dt><code>drawpoints</code></dt><dd><p>flag to draw data points on density estimate. Default is FALSE.</p>
</dd>
<dt><code>breaks</code></dt><dd><p>vector of break values of density estimate. Default is an <code>nbreaks</code> equilinear sequence over the data range.</p>
</dd>
<dt><code>nbreaks</code></dt><dd><p>number of breaks in <code>breaks</code> sequence</p>
</dd>
<dt><code>lty.rect</code>,<code>lwd.rect</code></dt><dd><p>line type/width for histogram box lines (2-d)</p>
</dd>
<dt><code>border</code></dt><dd><p>colour of histogram box lines (2-d)</p>
</dd>
<dt><code>col.rect</code></dt><dd><p>colour of histogram bars (1-d)</p>
</dd>
<dt><code>add.grid</code></dt><dd><p>flag to add histogram grid (2-d). Default is TRUE.</p>
</dd>
</dl>

</td></tr>
</table>


<h3>Details</h3>

<p>For <code>histde</code> objects, the function headers for the different dimensional data are  
</p>
<pre>
  ## univariate
  plot(fhat, xlab, ylab="Density function", add=FALSE, drawpoints=FALSE,
     col.pt=4, jitter=FALSE, border=1, alpha=1, ...) 
  
  ## bivariate
  plot(fhat, breaks, nbreaks=11, xlab, ylab, zlab="Density function", cex=1, 
     pch=1, add=FALSE, drawpoints=FALSE, col, col.fun, alpha=1, col.pt=4,
     lty.rect=2, cex.text=1, border, lwd.rect=1, col.rect="transparent",
     add.grid=TRUE, ...)</pre>
<p>The 1-d plot is a standard plot of a histogram generated by <code>hist</code>. If
<code>drawpoints=TRUE</code> then a rug plot is added.
</p>
<p>The 2-d plot is similar to the <code>display="filled.contour"</code> option from
<code><a href="#topic+plot.kde">plot.kde</a></code> with the default <code>nbreaks=11</code> contour
levels. 
</p>


<h3>Value</h3>

<p>Plots for 1-d and 2-d are sent to graphics window. 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+plot.kde">plot.kde</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>data(iris)

## univariate example
fhat &lt;- histde(x=iris[,2])
plot(fhat, xlab="Sepal length")

## bivariate example
fhat &lt;- histde(x=iris[,2:3])
plot(fhat, drawpoints=TRUE)
box()
</code></pre>

<hr>
<h2 id='plot.kcde'>Plot for kernel cumulative distribution estimate</h2><span id='topic+plot.kcde'></span>

<h3>Description</h3>

<p>Plot for kernel cumulative distribution estimate 1- to 3-dimensional data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'kcde'
plot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot.kcde_+3A_x">x</code></td>
<td>
<p>object of class <code>kcde</code> (output from <code><a href="#topic+kcde">kcde</a></code>)</p>
</td></tr>
<tr><td><code id="plot.kcde_+3A_...">...</code></td>
<td>
<p>other graphics parameters used in <code><a href="#topic+plot.kde">plot.kde</a></code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>For <code>kcde</code> objects, the function headers for the different dimensional data are  
</p>
<pre>
  ## univariate
  plot(Fhat, xlab, ylab="Distribution function", add=FALSE, drawpoints=FALSE, 
       col.pt=4, jitter=FALSE, alpha=1, ...) 

  ## bivariate
  plot(Fhat, display="persp", cont=seq(10,90, by=10), abs.cont, xlab, ylab,    
       zlab="Distribution function", cex=1, pch=1, add=FALSE, drawpoints=FALSE, 
       drawlabels=TRUE, theta=-30, phi=40, d=4, col.pt=4, col, col.fun, alpha=1, 
       lwd=1, border=NA, thin=3, lwd.fc=5, ...) 
  
  ## trivariate     
  plot(Fhat, display="plot3D", cont=c(25,50,75), colors, col, alphavec, 
       size=3, cex=1, pch=1, theta=-30, phi=40, d=4, ticktype="detailed", 
       bty="f", col.pt=4, add=FALSE, xlab, ylab, zlab, drawpoints=FALSE, 
       alpha, box=TRUE, axes=TRUE, ...)</pre>


<h3>Value</h3>

<p>Plots for 1-d and 2-d are sent to graphics window. Plot for 3-d is sent to
graphics/RGL window.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+plot.kde">plot.kde</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>data(iris)
Fhat &lt;- kcde(x=iris[,1])
plot(Fhat, xlab="Sepal.Length")
Fhat &lt;- kcde(x=iris[,1:2])
plot(Fhat)
Fhat &lt;- kcde(x=iris[,1:3])
plot(Fhat, alpha=0.3)
</code></pre>

<hr>
<h2 id='plot.kda'>Plot for kernel discriminant analysis</h2><span id='topic+plot.kda'></span>

<h3>Description</h3>

<p>Plot for kernel discriminant analysis for 1- to 3-dimensional data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'kda'
plot(x, y, y.group, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot.kda_+3A_x">x</code></td>
<td>
<p> object of class <code>kda</code> (output from <code><a href="#topic+kda">kda</a></code>)</p>
</td></tr>
<tr><td><code id="plot.kda_+3A_y">y</code></td>
<td>
<p>matrix of test data points</p>
</td></tr>
<tr><td><code id="plot.kda_+3A_y.group">y.group</code></td>
<td>
<p>vector of group labels for test data points</p>
</td></tr>
<tr><td><code id="plot.kda_+3A_...">...</code></td>
<td>
<p>other graphics parameters:
</p>

<dl>
<dt><code>rugsize</code></dt><dd><p>height of rug-like plot for partition classes (1-d)</p>
</dd>
<dt><code>prior.prob</code></dt><dd><p>vector of prior probabilities</p>
</dd>
<dt><code>col.part</code></dt><dd><p>vector of colours for partition classes (1-d, 2-d)</p>
</dd>
</dl>

<p>and those used in <code><a href="#topic+plot.kde">plot.kde</a></code>
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For <code>kda</code> objects, the function headers for the different dimensional data are 
</p>
<pre>
  ## univariate
  plot(x, y, y.group, prior.prob=NULL, xlim, ylim, xlab, 
       ylab="Weighted density function", drawpoints=FALSE, col, col.fun, 
       col.part, col.pt, lty, jitter=TRUE, rugsize, add=FALSE, alpha=1, ...)

  ## bivariate
  plot(x, y, y.group, prior.prob=NULL, display.part="filled.contour",
       cont=c(25,50,75), abs.cont, approx.cont=TRUE, xlim, ylim, xlab, ylab,
       drawpoints=FALSE, drawlabels=TRUE, cex=1, pch, lty, part=TRUE, col, 
       col.fun, col.part, col.pt, alpha=1, lwd=1, lwd.part=0, add=FALSE, ...)

  ## trivariate
  plot(x, y, y.group, prior.prob=NULL, display="plot3D", cont=c(25,50,75), 
       abs.cont, approx.cont=TRUE, colors, col, col.fun, col.pt, alpha=0.5, 
       alphavec, xlab, ylab, zlab, drawpoints=FALSE, size=3, cex=1, pch, 
       theta=-30, phi=40, d=4, ticktype="detailed", bty="f", add=FALSE, ...)</pre>


<h3>Value</h3>

<p>Plots for 1-d and 2-d are sent to graphics window. Plot for 3-d is sent to
graphics/RGL window. 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+kda">kda</a></code>, <code><a href="#topic+kde">kde</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>data(iris)

## univariate example
ir &lt;- iris[,1]
ir.gr &lt;- iris[,5]
kda.fhat &lt;- kda(x=ir, x.group=ir.gr, xmin=3, xmax=9)
plot(kda.fhat, xlab="Sepal length")

## bivariate example
ir &lt;- iris[,1:2]
ir.gr &lt;- iris[,5]
kda.fhat &lt;- kda(x=ir, x.group=ir.gr)
plot(kda.fhat, alpha=0.2, drawlabels=FALSE)

## trivariate example
ir &lt;- iris[,1:3]
ir.gr &lt;- iris[,5]
kda.fhat &lt;- kda(x=ir, x.group=ir.gr)
plot(kda.fhat) 
   ## colour=species, transparency=density heights</code></pre>

<hr>
<h2 id='plot.kdde'>Plot for kernel density derivative estimate</h2><span id='topic+plot.kdde'></span>

<h3>Description</h3>

<p>Plot for kernel density derivative estimate for 1- to 3-dimensional data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'kdde'
plot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot.kdde_+3A_x">x</code></td>
<td>
<p>object of class <code>kdde</code> (output from <code><a href="#topic+kdde">kdde</a></code>)</p>
</td></tr>
<tr><td><code id="plot.kdde_+3A_...">...</code></td>
<td>
<p>other graphics parameters:
</p>

<dl>
<dt><code>which.deriv.ind</code></dt><dd><p>index of the partial derivative to
be plotted (&gt;1-d)</p>
</dd>
</dl>

<p>and those used in <code><a href="#topic+plot.kde">plot.kde</a></code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>For <code>kdde</code> objects, the function headers for the different dimensional data are  
</p>
<pre>
  ## univariate
  plot(fhat, ylab="Density derivative function", cont=50, abs.cont, alpha=1, ...)

  ## bivariate
  plot(fhat, which.deriv.ind=1, cont=c(25,50,75), abs.cont, display="slice", 
       zlab="Density derivative function", col, col.fun, alpha=1, kdde.flag=TRUE, 
       thin=3, transf=1, neg.grad=FALSE, ...)
  
  ## trivariate 
  plot(fhat, which.deriv.ind=1, display="plot3D", cont=c(25,50,75), abs.cont, 
       colors, col, col.fun, ...)</pre>


<h3>Value</h3>

<p>Plots for 1-d and 2-d are sent to graphics window. Plot for 3-d is sent to
graphics/RGL window.
</p>
<p>In addition to the display options inherited from <code>plot.kde</code>, the
first derivative has <code>display="quiver"</code>. This is a quiver plot
where the size and direction of the arrow indicates the
magnitude/direction of the density gradient. See <code>quiver</code> from
the <span class="pkg">pracma</span> package for more details. 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+plot.kde">plot.kde</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## univariate example
data(tempb)
fhat1 &lt;- kdde(x=tempb[,"tmin"], deriv.order=1)   ## gradient [df/dx, df/dy]
plot(fhat1, xlab="Min. temp.", col.cont=4)       ## df/dx
points(20,predict(fhat1, x=20))

## bivariate example
fhat1 &lt;- kdde(x=tempb[,c("tmin", "tmax")], deriv.order=1)
plot(fhat1, display="quiver")
  ## gradient [df/dx, df/dy]

fhat2 &lt;- kdde(x=tempb[,c("tmin", "tmax")], deriv.order=2)
plot(fhat2, which.deriv.ind=2, display="persp", phi=10)
plot(fhat2, which.deriv.ind=2, display="filled.contour")
  ## d^2 f/(dx dy): blue=-ve, red=+ve
s2 &lt;- kcurv(fhat2)
plot(s2, display="filled.contour", alpha=0.5, lwd=1)
  ## summary curvature 

## trivariate example  
data(iris)
fhat1 &lt;- kdde(iris[,2:4], deriv.order=1)
plot(fhat1)</code></pre>

<hr>
<h2 id='plot.kde'>Plot for kernel density estimate</h2><span id='topic+plot.kde'></span>

<h3>Description</h3>

<p>Plot for kernel density estimate for 1- to 3-dimensional data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'kde'
plot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot.kde_+3A_x">x</code></td>
<td>
<p>object of class <code>kde</code> (output from <code><a href="#topic+kde">kde</a></code>)</p>
</td></tr>
<tr><td><code id="plot.kde_+3A_...">...</code></td>
<td>
<p>other graphics parameters:
</p>

<dl>
<dt><code>display</code></dt><dd><p>type of display, &quot;slice&quot; for contour plot,
&quot;persp&quot; for perspective plot, &quot;image&quot; for image plot, &quot;filled.contour&quot;
for filled contour plot (2-d); &quot;plot3D&quot;, &quot;rgl&quot; (3-d)</p>
</dd>
<dt><code>cont</code></dt><dd><p>vector of percentages for contour level curves</p>
</dd>
<dt><code>abs.cont</code></dt><dd><p>vector of absolute density estimate heights for contour level curves</p>
</dd>
<dt><code>approx.cont</code></dt><dd><p>flag to compute approximate contour levels. Default is FALSE.</p>
</dd>
<dt><code>col</code></dt><dd><p>plotting colour for density estimate (1-d, 2-d)</p>
</dd>
<dt><code>col.cont</code></dt><dd><p>plotting colour for contours</p>
</dd>
<dt><code>col.fun</code></dt><dd><p>plotting colour function for contours</p>
</dd>
<dt><code>col.pt</code></dt><dd><p>plotting colour for data points</p>
</dd>
<dt><code>colors</code></dt><dd><p>vector of colours for each contour (3-d)</p>
</dd>
<dt><code>jitter</code></dt><dd><p>flag to jitter rug plot (1-d). Default is TRUE.</p>
</dd>
<dt><code>lwd.fc</code></dt><dd><p>line width for filled contours (2-d)</p>
</dd>
<dt><code>xlim,ylim,zlim</code></dt><dd><p>axes limits</p>
</dd>
<dt><code>xlab,ylab,zlab</code></dt><dd><p>axes labels</p>
</dd>
<dt><code>add</code></dt><dd><p>flag to add to current plot. Default is FALSE.</p>
</dd>
<dt><code>theta,phi,d,border</code></dt><dd><p>graphics parameters for perspective plots (2-d)</p>
</dd>
<dt><code>drawpoints</code></dt><dd><p>flag to draw data points on density estimate. Default is FALSE.</p>
</dd>
<dt><code>drawlabels</code></dt><dd><p>flag to draw contour labels (2-d). Default is TRUE.</p>
</dd> 
<dt><code>alpha</code></dt><dd><p>transparency value of plotting symbol</p>
</dd>
<dt><code>alphavec</code></dt><dd><p>vector of transparency values for contours (3-d)</p>
</dd>
<dt><code>size</code></dt><dd><p>size of plotting symbol (3-d).</p>
</dd>
</dl>

</td></tr>
</table>


<h3>Details</h3>

<p>For <code>kde</code> objects, the function headers for the different dimensional data are  
</p>
<pre>
  ## univariate
  plot(fhat, xlab, ylab="Density function", add=FALSE, drawpoints=FALSE, col=1,
       col.pt=4, col.cont=1, cont.lwd=1, jitter=FALSE, cont, abs.cont, 
       approx.cont=TRUE, alpha=1, ...)
  
  ## bivariate
  plot(fhat, display="slice", cont=c(25,50,75), abs.cont, approx.cont=TRUE, 
       xlab, ylab, zlab="Density function", cex=1, pch=1, add=FALSE, 
       drawpoints=FALSE, drawlabels=TRUE, theta=-30, phi=40, d=4, col.pt=4, 
       col, col.fun, alpha=1, lwd=1, border=1, thin=3, kdde.flag=FALSE, 
       ticktype="detailed", ...) 

  ## trivariate
  plot(fhat, display="plot3D", cont=c(25,50,75), abs.cont, approx.cont=TRUE, 
       colors, col, col.fun, alphavec, size=3, cex=1, pch=1, theta=-30, phi=40, 
       d=4, ticktype="detailed", bty="f", col.pt=4, add=FALSE, xlab, ylab, 
       zlab, drawpoints=FALSE, alpha, box=TRUE, axes=TRUE, ...)</pre>
<p>For 1-dimensional data, the plot is a standard plot of a 1-d curve. If
<code>drawpoints=TRUE</code> then a rug plot is added. If <code>cont</code> is specified,
the horizontal line on the x-axis indicates the <code>cont</code>% highest 
density level set.  
</p>
<p>For 2-dimensional data, the different types of plotting displays are 
controlled by the <code>display</code> parameter.
(a) If <code>display="slice"</code> then a slice/contour plot
is generated using <code>contour</code>.  
(b) If <code>display</code> is <code>"filled.contour"</code> 
then a filled contour plot is generated.
The default contours are at 25%, 50%, 75% or
<code>cont=c(25,50,75)</code> which are upper percentages of
highest density regions. 
(c) If <code>display="persp"</code> then a perspective/wire-frame plot
is generated.  The default z-axis limits <code>zlim</code> are the default
from the usual <code>persp</code> command.
(d) If <code>display="image"</code> then an image plot
is generated. 
</p>
<p>For 3-dimensional data, the plot is a series of nested
3-d contours. The default contours are <code>cont=c(25,50,75)</code>. The
default opacity <code>alphavec</code> ranges from 0.1 to 0.5. 
For <span class="pkg">ks</span> <code class="reqn">\geq</code> 1.12.0, base R graphics becomes the default plotting engine: 
to create an <span class="pkg">rgl</span> plot like in previous versions, set <code>display="rgl"</code>. 
</p>
<p>To specify contours, either one of <code>cont</code> or <code>abs.cont</code>
is required. <code>cont</code> specifies upper percentages which
correspond to probability contour regions. If <code>abs.cont</code> is set
to particular values, then contours at these levels are drawn.
This second option is useful for plotting
multiple density estimates with common contour levels. See
<code><a href="#topic+contourLevels">contourLevels</a></code> for details on computing contour levels.   
If <code>approx=FALSE</code>, then the exact KDE is computed. Otherwise
it is interpolated from an existing KDE grid, which can dramatically
reduce computation time for large data sets. 
</p>
<p>If a colour function is specified in <code>col.fun</code>, it should have the number of colours as a single argument, e.g. <code>function(n){hcl.colors(n, ...)}</code>. The transparent background colour is automatically concatenated before this colour function. If <code>col</code> is specified, it overrides <code>col.fun</code>. There should be one more colour than the number of contours, i.e. background colour plus one for each contour. 
</p>


<h3>Value</h3>

<p>Plots for 1-d and 2-d are sent to graphics window. Plot for 3-d is sent to
graphics/RGL window. 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(iris)

## univariate example
fhat &lt;- kde(x=iris[,2])
plot(fhat, cont=50, col.cont=4, cont.lwd=2, xlab="Sepal length")

## bivariate example
fhat &lt;- kde(x=iris[,2:3])
plot(fhat, display="filled.contour", cont=seq(10,90,by=10), lwd=1, alpha=0.5)
plot(fhat, display="persp", border=1, alpha=0.5)

## trivariate example
fhat &lt;- kde(x=iris[,2:4])
plot(fhat)
if (interactive()) plot(fhat, display="rgl")
</code></pre>

<hr>
<h2 id='plot.kde.loctest'>Plot for kernel local significant difference regions</h2><span id='topic+plot.kde.loctest'></span>

<h3>Description</h3>

<p>Plot for kernel local significant difference regions for 1- to 3-dimensional data. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'kde.loctest'
plot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot.kde.loctest_+3A_x">x</code></td>
<td>
<p>object of class <code>kde.loctest</code> (output from <code><a href="#topic+kde.local.test">kde.local.test</a></code>)</p>
</td></tr>
<tr><td><code id="plot.kde.loctest_+3A_...">...</code></td>
<td>
<p>other graphics parameters:
</p>

<dl>
<dt><code>lcol</code></dt><dd><p>colour for KDE curve (1-d)</p>
</dd>
<dt><code>col</code></dt><dd><p>vector of 2 colours. First colour: sample 1&gt;sample 2, second colour:
sample 1&lt;sample2.</p>
</dd>
<dt><code>add</code></dt><dd><p>flag to add to current plot. Default is FALSE.</p>
</dd>
<dt><code>rugsize</code></dt><dd><p>height of rug-like plot (1-d)</p>
</dd>
<dt><code>add.legend</code></dt><dd><p>flag to add legend. Default is TRUE.</p>
</dd>
<dt><code>pos.legend</code></dt><dd><p>position label for legend (1-d, 2-d)</p>
</dd>
<dt><code>alphavec</code></dt><dd><p>vector of transparency values for contour (3-d)</p>
</dd>    
</dl>

<p>and those used in <code><a href="#topic+plot.kde">plot.kde</a></code>
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For <code>kde.loctest</code> objects, the function headers are  
</p>
<pre>
   ## univariate
   plot(x, lcol, col, add=FALSE, xlab="x", ylab, rugsize, add.legend=TRUE, 
        pos.legend="topright", alpha=1, ...)
   
   ## bivariate
   plot(x, col, add=FALSE, add.legend=TRUE, pos.legend="topright", alpha=1, 
        ...)

   ## trivariate 
   plot(x, col, color, add=FALSE, box=TRUE, axes=TRUE, alphavec=c(0.5, 0.5), 
        add.legend=TRUE, ...)</pre>


<h3>Value</h3>

<p>Plots for 1-d and 2-d are sent to graphics window. Plot for 3-d is
sent to graphics/RGL window. 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+kde.local.test">kde.local.test</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## bivariate
data(air)
air.var &lt;- c("co2","pm10","no")
air &lt;- air[, c("date","time",air.var)]
air2 &lt;- reshape(air, idvar="date", timevar="time", direction="wide")
a1 &lt;- as.matrix(na.omit(air2[, paste0(air.var, ".08:00")]))
a2 &lt;- as.matrix(na.omit(air2[, paste0(air.var, ".20:00")]))
colnames(a1) &lt;- air.var
colnames(a2) &lt;- air.var
loct &lt;- kde.local.test(x1=a1[,c("co2","pm10")], x2=a2[,c("co2","pm10")])
plot(loct, lwd=1)

## trivariate
loct &lt;- kde.local.test(x1=a1, x2=a2)
plot(loct, xlim=c(0,800), ylim=c(0,300), zlim=c(0,300))
</code></pre>

<hr>
<h2 id='plot.kde.part'>Partition plot for kernel density clustering</h2><span id='topic+plot.kde.part'></span><span id='topic+kms.part'></span><span id='topic+mvnorm.mixt.part'></span>

<h3>Description</h3>

<p>Plot of partition for kernel density clustering for 2-dimensional data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mvnorm.mixt.part(mus, Sigmas, props=1, xmin, xmax, gridsize, max.iter=100,
   verbose=FALSE)
kms.part(x, H, xmin, xmax, gridsize, verbose=FALSE, ...)

## S3 method for class 'kde.part'
plot(x, display="filled.contour", col, col.fun, alpha=1, add=FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot.kde.part_+3A_mus">mus</code></td>
<td>
<p>(stacked) matrix of mean vectors</p>
</td></tr>
<tr><td><code id="plot.kde.part_+3A_sigmas">Sigmas</code></td>
<td>
<p>(stacked) matrix of variance matrices</p>
</td></tr>
<tr><td><code id="plot.kde.part_+3A_props">props</code></td>
<td>
<p>vector of mixing proportions</p>
</td></tr>
<tr><td><code id="plot.kde.part_+3A_xmin">xmin</code>, <code id="plot.kde.part_+3A_xmax">xmax</code></td>
<td>
<p>vector of minimum/maximum values for grid</p>
</td></tr>
<tr><td><code id="plot.kde.part_+3A_gridsize">gridsize</code></td>
<td>
<p>vector of number of grid points</p>
</td></tr>
<tr><td><code id="plot.kde.part_+3A_max.iter">max.iter</code></td>
<td>
<p>maximum number of iterations</p>
</td></tr>
<tr><td><code id="plot.kde.part_+3A_verbose">verbose</code></td>
<td>
<p>flag to print out progress information. Default is FALSE.</p>
</td></tr>
<tr><td><code id="plot.kde.part_+3A_x">x</code></td>
<td>
<p>matrix of data values or an object of class <code>kde.part</code></p>
</td></tr>
<tr><td><code id="plot.kde.part_+3A_h">H</code></td>
<td>
<p>bandwidth matrix. If missing,
<code>Hpi(x,deriv,order=1)</code> is called by default.</p>
</td></tr>
<tr><td><code id="plot.kde.part_+3A_display">display</code></td>
<td>
<p>type of display, &quot;filled.contour&quot; for filled contour plot</p>
</td></tr> 
<tr><td><code id="plot.kde.part_+3A_col">col</code>, <code id="plot.kde.part_+3A_col.fun">col.fun</code></td>
<td>
<p>vector of plotting colours or colour function</p>
</td></tr>
<tr><td><code id="plot.kde.part_+3A_alpha">alpha</code></td>
<td>
<p>colour transparency. Default is 1.</p>
</td></tr>
<tr><td><code id="plot.kde.part_+3A_add">add</code></td>
<td>
<p>flag to add to current plot. Default is FALSE.</p>
</td></tr>
<tr><td><code id="plot.kde.part_+3A_...">...</code></td>
<td>
<p>other parameters</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For 2-d data, <code>kms.part</code> and <code>mvnorm.mixt.part</code> produce a
<code>kde.part</code> object whose 
values are the class labels, rather than probability density values.   
</p>


<h3>Value</h3>

<p>A kernel partition is an object of class <code>kde.part</code> which is a
list with fields:
</p>
<table role = "presentation">
<tr><td><code>x</code></td>
<td>
<p>data points - same as input</p>
</td></tr>
<tr><td><code>eval.points</code></td>
<td>
<p>vector or list of points at which the estimate is evaluated</p>
</td></tr>
<tr><td><code>estimate</code></td>
<td>
<p>density estimate at <code>eval.points</code></p>
</td></tr>
<tr><td><code>H</code></td>
<td>
<p>bandwidth matrix</p>
</td></tr>
<tr><td><code>gridtype</code></td>
<td>
<p>&quot;linear&quot;</p>
</td></tr>
<tr><td><code>gridded</code></td>
<td>
<p>flag for estimation on a grid</p>
</td></tr>
<tr><td><code>binned</code></td>
<td>
<p>flag for binned estimation</p>
</td></tr>
<tr><td><code>names</code></td>
<td>
<p>variable names</p>
</td></tr> 
<tr><td><code>w</code></td>
<td>
<p>vector of weights</p>
</td></tr>
<tr><td><code>cont</code></td>
<td>
<p>vector of probability contour levels</p>
</td></tr>   
<tr><td><code>end.points</code></td>
<td>
<p>matrix of final iterates starting from <code>x</code></p>
</td></tr>
<tr><td><code>label</code></td>
<td>
<p>vector of cluster labels</p>
</td></tr>
<tr><td><code>mode</code></td>
<td>
<p>matrix of cluster modes</p>
</td></tr>
<tr><td><code>nclust</code></td>
<td>
<p>number of clusters</p>
</td></tr>
<tr><td><code>nclust.table</code></td>
<td>
<p>frequency table of cluster labels</p>
</td></tr>
<tr><td><code>tol.iter</code>, <code>tol.clust</code>, <code>min.clust.size</code></td>
<td>
<p>tuning parameter values -
same as input</p>
</td></tr>
</table>
<p>Plot is sent to graphics window. 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+plot.kde">plot.kde</a></code>, <code><a href="#topic+kms">kms</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## normal mixture partition
mus &lt;- rbind(c(-1,0), c(1, 2/sqrt(3)), c(1,-2/sqrt(3)))
Sigmas &lt;- 1/25*rbind(invvech(c(9, 63/10, 49/4)), invvech(c(9,0,49/4)), invvech(c(9,0,49/4)))
props &lt;- c(3,3,1)/7
gridsize &lt;- c(11,11) ## small gridsize illustrative purposes only 
nmixt.part &lt;- mvnorm.mixt.part(mus=mus, Sigmas=Sigmas, props=props, gridsize=gridsize)
plot(nmixt.part, asp=1, xlim=c(-3,3), ylim=c(-3,3), alpha=0.5)

## kernel mean shift partition
set.seed(81928192)
x &lt;- rmvnorm.mixt(n=10000, mus=mus, Sigmas=Sigmas, props=props)
msize &lt;- round(prod(gridsize)*0.1)
kms.nmixt.part &lt;- kms.part(x=x, min.clust.size=msize, gridsize=gridsize)
plot(kms.nmixt.part, asp=1, xlim=c(-3,3), ylim=c(-3,3), alpha=0.5)</code></pre>

<hr>
<h2 id='plot.kfs'>Plot for kernel feature significance</h2><span id='topic+plot.kfs'></span>

<h3>Description</h3>

<p>Plot for kernel significant regions for 1- to 3-dimensional data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'kfs'
plot(x, display="filled.contour", col=7, colors, abs.cont,
   alpha=1, alphavec=0.4, add=FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot.kfs_+3A_x">x</code></td>
<td>
<p>object of class <code>kfs</code> (output from
<code><a href="#topic+kfs">kfs</a></code>)</p>
</td></tr>
<tr><td><code id="plot.kfs_+3A_display">display</code></td>
<td>
<p>type of display, &quot;slice&quot; for contour plot,
&quot;persp&quot; for perspective plot, &quot;image&quot; for image plot, &quot;filled.contour&quot;
for filled contour plot (2-d); &quot;plot3D&quot;, &quot;rgl&quot; (3-d)</p>
</td></tr>
<tr><td><code id="plot.kfs_+3A_col">col</code>, <code id="plot.kfs_+3A_colors">colors</code></td>
<td>
<p>colour for contour region</p>
</td></tr>
<tr><td><code id="plot.kfs_+3A_abs.cont">abs.cont</code></td>
<td>
<p>absolute contour height. Default is 0.5.</p>
</td></tr>
<tr><td><code id="plot.kfs_+3A_alpha">alpha</code></td>
<td>
<p>transparency value for contour (2-d)</p>
</td></tr>
<tr><td><code id="plot.kfs_+3A_alphavec">alphavec</code></td>
<td>
<p>vector of transparency values for contour (3-d)</p>
</td></tr>
<tr><td><code id="plot.kfs_+3A_add">add</code></td>
<td>
<p>flag to add to current plot. Default is FALSE.</p>
</td></tr>
<tr><td><code id="plot.kfs_+3A_...">...</code></td>
<td>
<p>other graphics parameters used in <code><a href="#topic+plot.kde">plot.kde</a></code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>Plots for 1-d and 2-d are sent to graphics window. Plot for 3-d is sent to
graphics/RGL window.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+plot.kde">plot.kde</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>data(geyser, package="MASS")
geyser.fs &lt;- kfs(geyser, binned=TRUE)
plot(geyser.fs)
</code></pre>

<hr>
<h2 id='plot.kroc'>Plot for kernel receiver operating characteristic curve (ROC) estimate</h2><span id='topic+plot.kroc'></span>

<h3>Description</h3>

<p>Plot for kernel receiver operating characteristic curve (ROC) estimate 1- to 3-dimensional data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'kroc'
plot(x, add=FALSE, add.roc.ref=FALSE, xlab, ylab, 
   alpha=1, col=1, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot.kroc_+3A_x">x</code></td>
<td>
<p>object of class <code>kroc</code> (output from <code><a href="#topic+kroc">kroc</a></code>)</p>
</td></tr>
<tr><td><code id="plot.kroc_+3A_add">add</code></td>
<td>
<p>flag to add to current plot. Default is FALSE.</p>
</td></tr>
<tr><td><code id="plot.kroc_+3A_add.roc.ref">add.roc.ref</code></td>
<td>
<p>flag to add reference ROC curve. Default is FALSE.</p>
</td></tr> 
<tr><td><code id="plot.kroc_+3A_xlab">xlab</code></td>
<td>
<p>x-axis label. Default is &quot;False positive rate
(bar(specificity))&quot;.</p>
</td></tr>
<tr><td><code id="plot.kroc_+3A_ylab">ylab</code></td>
<td>
<p>y-axis label. Default is &quot;True positive rate (sensitivity)&quot;.</p>
</td></tr> 
<tr><td><code id="plot.kroc_+3A_alpha">alpha</code>, <code id="plot.kroc_+3A_col">col</code></td>
<td>
<p>transparency value and colour of line</p>
</td></tr>
<tr><td><code id="plot.kroc_+3A_...">...</code></td>
<td>
<p>other graphics parameters used in <code><a href="#topic+plot.kde">plot.kde</a></code>.</p>
</td></tr> 
</table>


<h3>Value</h3>

<p>Plots for 1-d and 2-d are sent to graphics window. Plot for 3-d is sent to
graphics/RGL window. 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+plot.kde">plot.kde</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>data(fgl, package="MASS")
x1 &lt;- fgl[fgl[,"type"]=="WinF",c("RI", "Na")]
x2 &lt;- fgl[fgl[,"type"]=="Head",c("RI", "Na")]
Rhat &lt;- kroc(x1=x1, x2=x2) 
plot(Rhat, add.roc.ref=TRUE)
</code></pre>

<hr>
<h2 id='plotmixt'>Plot for 1- to 3-dimensional normal and t-mixture density functions</h2><span id='topic+plotmixt'></span>

<h3>Description</h3>

<p>Plot for 1- to 3-dimensional normal and t-mixture density functions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotmixt(mus, sigmas, Sigmas, props, dfs, dist="normal", draw=TRUE,
   deriv.order=0, which.deriv.ind=1, binned=TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plotmixt_+3A_mus">mus</code></td>
<td>
<p>(stacked) matrix of mean vectors</p>
</td></tr>
<tr><td><code id="plotmixt_+3A_sigmas">sigmas</code></td>
<td>
<p>vector of standard deviations (1-d)</p>
</td></tr>
<tr><td><code id="plotmixt_+3A_sigmas">Sigmas</code></td>
<td>
<p>(stacked) matrix of variance matrices (2-d, 3-d)</p>
</td></tr>
<tr><td><code id="plotmixt_+3A_props">props</code></td>
<td>
<p>vector of mixing proportions</p>
</td></tr>
<tr><td><code id="plotmixt_+3A_dfs">dfs</code></td>
<td>
<p>vector of degrees of freedom</p>
</td></tr>
<tr><td><code id="plotmixt_+3A_dist">dist</code></td>
<td>
<p>&quot;normal&quot; - normal mixture, &quot;t&quot; - t-mixture</p>
</td></tr>
<tr><td><code id="plotmixt_+3A_draw">draw</code></td>
<td>
<p>flag to draw plot. Default is TRUE.</p>
</td></tr>
<tr><td><code id="plotmixt_+3A_deriv.order">deriv.order</code></td>
<td>
<p>derivative order</p>
</td></tr>
<tr><td><code id="plotmixt_+3A_which.deriv.ind">which.deriv.ind</code></td>
<td>
<p>index of which partial derivative to plot</p>
</td></tr>
<tr><td><code id="plotmixt_+3A_binned">binned</code></td>
<td>
<p>flag for binned estimation of contour levels. Default is TRUE.</p>
</td></tr> 
<tr><td><code id="plotmixt_+3A_...">...</code></td>
<td>
<p>other graphics parameters, see <code><a href="#topic+plot.kde">plot.kde</a></code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>If <code>draw=TRUE</code>, the 1-d, 2-d plot is sent to graphics window, 3-d plot to 
graphics/RGL window. If <code>draw=FALSE</code>, then a <code>kdde</code>-like object is returned.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## bivariate 
mus &lt;- rbind(c(0,0), c(-1,1))
Sigma &lt;- matrix(c(1, 0.7, 0.7, 1), nr=2, nc=2) 
Sigmas &lt;- rbind(Sigma, Sigma)
props &lt;- c(1/2, 1/2)
plotmixt(mus=mus, Sigmas=Sigmas, props=props, display="filled.contour", lwd=1)

## trivariate 
mus &lt;- rbind(c(0,0,0), c(-1,0.5,1.5))
Sigma &lt;- matrix(c(1, 0.7, 0.7, 0.7, 1, 0.7, 0.7, 0.7, 1), nr=3, nc=3) 
Sigmas &lt;- rbind(Sigma, Sigma)
props &lt;- c(1/2, 1/2)
plotmixt(mus=mus, Sigmas=Sigmas, props=props, dfs=c(11,8), dist="t")
</code></pre>

<hr>
<h2 id='pre.transform'>Pre-sphering and pre-scaling</h2><span id='topic+pre.sphere'></span><span id='topic+pre.scale'></span>

<h3>Description</h3>

<p>Pre-sphered or pre-scaled version of data.</p>


<h3>Usage</h3>

<pre><code class='language-R'>pre.sphere(x, mean.centred=FALSE)
pre.scale(x, mean.centred=FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="pre.transform_+3A_x">x</code></td>
<td>
<p>matrix of data values</p>
</td></tr>
<tr><td><code id="pre.transform_+3A_mean.centred">mean.centred</code></td>
<td>
<p>flag to centre the data values to have zero mean. Default is FALSE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p> For pre-scaling, the data values are pre-multiplied by
<code class="reqn">\mathbf{S}^{-1/2}</code> and for pre-scaling, by
<code class="reqn">\mathbf{S}_D^{-1/2}</code> where
<code class="reqn">\mathbf{S}</code> is the sample variance and <code class="reqn">\mathbf{S}_D</code>
is <code class="reqn">\mathrm{diag} \, (S_1^2, S_2^2, \dots, S_d^2)</code> where
<code class="reqn">S_i^2</code> is the i-th marginal sample variance. 
</p>


<h3>Value</h3>

<p>Pre-sphered or pre-scaled version of data. These
pre-transformations are required for implementing the plug-in
<code><a href="#topic+Hpi">Hpi</a></code> selectors and the smoothed cross validation
<code><a href="#topic+Hscv">Hscv</a></code> selectors. 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(unicef)
unicef.sp &lt;- pre.sphere(as.matrix(unicef))
</code></pre>

<hr>
<h2 id='quake'>Geographical locations of earthquakes and tectonic plates</h2><span id='topic+quake'></span><span id='topic+quakesf'></span><span id='topic+plate'></span><span id='topic+platesf'></span>

<h3>Description</h3>

<p>The <code>quake</code> data set contains the geographical locations 
of severe earthquakes in the years 100 and 2016 inclusive. The
<code>plate</code> data set contains the geographical locations of the tectonic
plate boundaries.    
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(quake)
data(plate)
data(quakesf)
data(platesf)
</code></pre>


<h3>Format</h3>

<p>&ndash;For <code>quake</code>, a matrix with 5871 rows and 5 columns.
Each row corresponds to an earthquake.
The first column is the year (negative years indicate B.C.E.),
the second is the longitude (decimal degrees),
the third is the latitude (decimal degrees),
the fourth is the depth beneath the Earth's surface (km),
the fifth is a flag for the location inside the circum-Pacific belt
(aka Pacific Ring of Fire). <code>quakesf</code> is a WGS84 <code>sf</code> version with a point geometry.
</p>
<p>&ndash;For <code>plate</code>, a matrix with 6276 rows and 3 columns.
Each row corresponds to an location of the tectonic plate boundaries.
The first is the longitude,
the second is the latitude,
the third is the label of the tectonic plate. 
<code>platesf</code> is a WGS84 <code>sf</code> spatial version with a multipolygon geometry, where the individual plate line segments have been merged into a single multipolygon.</p>


<h3>Source</h3>

<p>Alhenius, H., Nordpil and Bird, P. (2014). World Tectonic Plates and Boundaries. 
<a href="https://github.com/fraxen/tectonicplates">https://github.com/fraxen/tectonicplates</a>. Accessed 2021-03-11.
</p>
<p>Bird, P. (2003) An updated digital model of plate boundaries,
<em>Geochemistry, Geophysics, Geosystems</em> <b>4(3)</b>, 1-52. 1027.
</p>
<p>NGDC/WDS (2017) Global significant earthquake database, National
Geophysical Data Center, NOAA, doi:10.7289/V5TD9V7K.
National Geophysical Data Center/World Data Service. Accessed 2017-03-30.
</p>

<hr>
<h2 id='rkde'>Derived quantities from kernel density estimates</h2><span id='topic+dkde'></span><span id='topic+pkde'></span><span id='topic+qkde'></span><span id='topic+rkde'></span>

<h3>Description</h3>

<p>Derived quantities from kernel density estimates.
</p>


<h3>Usage</h3>

<pre><code class='language-R'> dkde(x, fhat)
 pkde(q, fhat)
 qkde(p, fhat)
 rkde(n, fhat, positive=FALSE) 
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rkde_+3A_x">x</code>, <code id="rkde_+3A_q">q</code></td>
<td>
<p>vector of quantiles</p>
</td></tr>
<tr><td><code id="rkde_+3A_p">p</code></td>
<td>
<p>vector of probabilities</p>
</td></tr>
<tr><td><code id="rkde_+3A_n">n</code></td>
<td>
<p>number of observations</p>
</td></tr>
<tr><td><code id="rkde_+3A_positive">positive</code></td>
<td>
<p>flag to compute KDE on the positive real
line. Default is FALSE.</p>
</td></tr>  
<tr><td><code id="rkde_+3A_fhat">fhat</code></td>
<td>
<p>kernel density estimate, object of class <code>kde</code></p>
</td></tr>
</table>


<h3>Details</h3>

 
<p><code>pkde</code> uses the trapezoidal rule for the numerical
integration. <code>rkde</code> uses
Silverman (1986)'s method to generate a random sample from a KDE. 
</p>


<h3>Value</h3>

<p>For the 1-d kernel density estimate <code>fhat</code>,
<code>pkde</code> computes the cumulative probability for the quantile
<code>q</code>, <code>qkde</code> computes the quantile corresponding to the probability
<code>p</code>.
</p>
<p>For any kernel density estimate, <code>dkde</code> computes the density value at
<code>x</code> (it is an alias for <code>predict.kde</code>), <code>rkde</code>
computes a random sample of size <code>n</code>.   
</p>


<h3>References</h3>

<p> Silverman, B. (1986) <em>Density Estimation for Statistics and
Data Analysis</em>. Chapman &amp; Hall/CRC. London.</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(8192)
x &lt;- rnorm.mixt(n=10000, mus=0, sigmas=1, props=1)
fhat &lt;- kde(x=x)
p1 &lt;- pkde(fhat=fhat, q=c(-1, 0, 0.5))
qkde(fhat=fhat, p=p1)    
y &lt;- rkde(fhat=fhat, n=100)

x &lt;- rmvnorm.mixt(n=10000, mus=c(0,0), Sigmas=invvech(c(1,0.8,1)))
fhat &lt;- kde(x=x)
y &lt;- rkde(fhat=fhat, n=1000)
fhaty &lt;- kde(x=y)
plot(fhat, col=1)
plot(fhaty, add=TRUE, col=2)
</code></pre>

<hr>
<h2 id='tempb'>Daily temperature</h2><span id='topic+tempb'></span>

<h3>Description</h3>

<p>This data set contains the daily minimum and maximum temperatures from
the weather station in Badajoz, Spain, from 1 January 1955 to 31 December
2015.  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(tempb)</code></pre>


<h3>Format</h3>

<p>A matrix with  21908 rows and 5 columns.
Each row corresponds to a daily measurement. 
The first column is the year (yyyy), 
the second is the month (mm),
the third is the day (dd), 
the fourth is the minimum temperature (degrees Celsius),
the fifth is the maximum temperature (degrees Celsius).
</p>


<h3>Source</h3>

<p>Menne, M. J., Durre, I., Vose, R. S., Gleason, B. E. &amp; Houston,
T. (2012) An overview of the global historical climatology network-daily
database, <em>Journal of Atmospheric and Oceanic Technology</em>
<b>429</b>, 897 - 910. <a href="https://climexp.knmi.nl/selectdailyseries.cgi">https://climexp.knmi.nl/selectdailyseries.cgi</a>. Accessed 2016-10-20.
</p>

<hr>
<h2 id='unicef'>Unicef child mortality - life expectancy data</h2><span id='topic+unicef'></span>

<h3>Description</h3>

<p>This data set contains the number of deaths of children under 5 years of
age per 1000 live births and the average life expectancy (in years) at birth
for 73 countries with GNI (Gross National Income) less
than 1000 US dollars per annum per capita.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(unicef)</code></pre>


<h3>Format</h3>

<p>A matrix with 2 columns and 73 rows. Each row corresponds to a country.
The first column is the under 5 mortality rate and the second is the average
life expectancy.</p>


<h3>Source</h3>

<p>Unicef (2003). <em>State of the World's Children Report 2003</em>, Oxford University Press, for Unicef.
</p>

<hr>
<h2 id='vector'>Vector and vector half operators</h2><span id='topic+vec'></span><span id='topic+vech'></span><span id='topic+invvec'></span><span id='topic+invvech'></span>

<h3>Description</h3>

<p>The vec (vector) operator takes a <code class="reqn">d \times d</code> matrix and stacks the
columns into a single vector of length <code class="reqn">d^2</code>. The vech (vector
half) operator
takes a symmetric <code class="reqn">d \times d</code> matrix and stacks the lower
triangular half into a single vector of length <code class="reqn">d(d+1)/2</code>.
The functions invvec and invvech are the inverses of vec and
vech i.e. they form matrices from vectors. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>vec(x, byrow=FALSE)
vech(x)
invvec(x, ncol, nrow, byrow=FALSE)
invvech(x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="vector_+3A_x">x</code></td>
<td>
<p>vector or matrix</p>
</td></tr>
<tr><td><code id="vector_+3A_ncol">ncol</code>, <code id="vector_+3A_nrow">nrow</code></td>
<td>
<p>number of columns and rows for inverse of vech</p>
</td></tr>
<tr><td><code id="vector_+3A_byrow">byrow</code></td>
<td>
<p>flag for stacking row-wise or column-wise. Default is FALSE.</p>
</td></tr>  
</table>


<h3>References</h3>

<p> Magnus, J.R. &amp; Neudecker H.M. (2007) <em>Matrix
Differential Calculus with Applications in Statistics and
Econometrics (3rd edition)</em>, Wiley &amp; Sons. Chichester.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- matrix(1:9, nrow=3, ncol=3)
vec(x)
invvec(vec(x))
</code></pre>

<hr>
<h2 id='vkde'>Variable kernel density estimate.</h2><span id='topic+kde.balloon'></span><span id='topic+kde.sp'></span>

<h3>Description</h3>

<p>Variable kernel density estimate for 2-dimensional data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>kde.balloon(x, H, h, gridsize, gridtype, xmin, xmax, supp=3.7, eval.points, 
   binned, bgridsize, w, compute.cont=TRUE, approx.cont=TRUE, verbose=FALSE)
kde.sp(x, H, h, gridsize, gridtype, xmin, xmax, supp=3.7, eval.points, 
   binned, bgridsize, w, compute.cont=TRUE, approx.cont=TRUE, verbose=FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="vkde_+3A_x">x</code></td>
<td>
<p>matrix of data values</p>
</td></tr>
<tr><td><code id="vkde_+3A_h">H</code></td>
<td>
<p>bandwidth matrix. If this missing, <code>Hns</code>
is called by default.</p>
</td></tr>
<tr><td><code id="vkde_+3A_h">h</code></td>
<td>
<p>not yet implemented</p>
</td></tr>
<tr><td><code id="vkde_+3A_gridsize">gridsize</code></td>
<td>
<p>vector of number of grid points</p>
</td></tr>
<tr><td><code id="vkde_+3A_gridtype">gridtype</code></td>
<td>
<p>not yet implemented</p>
</td></tr>
<tr><td><code id="vkde_+3A_xmin">xmin</code>, <code id="vkde_+3A_xmax">xmax</code></td>
<td>
<p>vector of minimum/maximum values for grid</p>
</td></tr>
<tr><td><code id="vkde_+3A_supp">supp</code></td>
<td>
<p>effective support for standard normal</p>
</td></tr>
<tr><td><code id="vkde_+3A_eval.points">eval.points</code></td>
<td>
<p>vector or matrix of points at which estimate is evaluated</p>
</td></tr>
<tr><td><code id="vkde_+3A_binned">binned</code></td>
<td>
<p>flag for binned estimation.</p>
</td></tr>
<tr><td><code id="vkde_+3A_bgridsize">bgridsize</code></td>
<td>
<p>vector of binning grid sizes</p>
</td></tr>
<tr><td><code id="vkde_+3A_w">w</code></td>
<td>
<p>vector of weights. Default is a vector of all ones.</p>
</td></tr>
<tr><td><code id="vkde_+3A_compute.cont">compute.cont</code></td>
<td>
<p>flag for computing 1% to 99% probability contour levels. Default is TRUE.</p>
</td></tr>
<tr><td><code id="vkde_+3A_approx.cont">approx.cont</code></td>
<td>
<p>flag for computing approximate probability contour
levels. Default is TRUE.</p>
</td></tr>
<tr><td><code id="vkde_+3A_verbose">verbose</code></td>
<td>
<p>flag to print out progress information. Default is
FALSE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The balloon density estimate <code>kde.balloon</code> employs bandwidths
which vary at each 
estimation point (Loftsgaarden &amp; Quesenberry, 1965). There are as many bandwidths as there are estimation
grid points. The default bandwidth is <code>Hns(,deriv.order=2)</code> and
the subsequent bandwidths are derived via a minimal MSE formula.  
</p>
<p>The sample point density estimate <code>kde.sp</code> employs bandwidths
which vary for each data point (Abramson, 1982).
There are as many bandwidths as there are data
points. The default bandwidth is <code>Hns(,deriv.order=4)</code> and the 
subsequent bandwidths are derived via the Abramson formula.
</p>


<h3>Value</h3>

<p>A variable kernel density estimate for bounded data is an object of class <code>kde</code>.    
</p>


<h3>References</h3>

<p>Abramson, I. S. (1982) On bandwidth variation in kernel estimates - a
square root law. <em>Annals of Statistics</em>, <b>10</b>, 1217-1223.
</p>
<p>Loftsgaarden, D. O. &amp; Quesenberry, C. P. (1965) A nonparametric
estimate of a multivariate density function. <em>Annals of
Mathematical Statistics</em>, <b>36</b>, 1049-1051.  
</p>


<h3>See Also</h3>

<p><code><a href="#topic+kde">kde</a></code>, <code><a href="#topic+plot.kde">plot.kde</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>data(worldbank)
wb &lt;- as.matrix(na.omit(worldbank[,4:5]))
xmin &lt;- c(-70,-35); xmax &lt;- c(35,70)
fhat &lt;- kde(x=wb, xmin=xmin, xmax=xmax)
fhat.sp &lt;- kde.sp(x=wb, xmin=xmin, xmax=xmax)
zmax &lt;- max(fhat.sp$estimate)
plot(fhat, display="persp", box=TRUE, phi=20, thin=1, border=grey(0,0.2), zlim=c(0,zmax))
plot(fhat.sp, display="persp", box=TRUE, phi=20, thin=1, border=grey(0,0.2), zlim=c(0,zmax))
## Not run: 
fhat.ball &lt;- kde.balloon(x=wb, xmin=xmin, xmax=xmax)
plot(fhat.ball, display="persp", box=TRUE, phi=20, zlim=c(0,zmax))
## End(Not run)
</code></pre>

<hr>
<h2 id='worldbank'>Development indicators from the World Bank Group</h2><span id='topic+worldbank'></span>

<h3>Description</h3>

<p>This data set contains six development indicators for national
entities for the year 2011, which is the latest year for which they are
consistently available. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(worldbank)</code></pre>


<h3>Format</h3>

<p>A matrix with 7 columns and 218 rows.
Each row corresponds to a country.
The first column is the country,
the second is the per capita carbon dioxide emissions (thousands Kg),
the third is the per capita GDP (thousands of current USD),
the fourth is the annual GDP growth rate (%),
the fifth is the annual inflation rate (%),
the sixth is the percentage of internet users in the population (%),
the seventh is the added value agricultural production as a ratio of the total GDP (%). </p>


<h3>Source</h3>

<p>World Bank Group (2016) World development indicators. 
<a href="http://databank.worldbank.org/data/reports.aspx?source=world-development-indicators">http://databank.worldbank.org/data/reports.aspx?source=world-development-indicators</a>. Accessed 2016-10-03.
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
