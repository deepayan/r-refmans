<!DOCTYPE html><html><head><title>Help for package GJRM</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {GJRM}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#GJRM-package'><p>Generalised Joint Regression Modelling</p></a></li>
<li><a href='#adjCov'><p>Adjustment for the covariance matrix from a fitted gjrm model</p></a></li>
<li><a href='#adjCovSD'><p>Adjustment for the covariance matrix from a gjrm model fitted to complex survey data.</p></a></li>
<li><a href='#areds'><p>AREDS</p></a></li>
<li><a href='#AT'><p>Average treatment effect of a binary/continuous/discrete endogenous variable</p></a></li>
<li><a href='#BCDF'><p>Internal Function</p></a></li>
<li><a href='#bcont'><p>Internal Function</p></a></li>
<li><a href='#bdiscrcont'><p>Internal Function</p></a></li>
<li><a href='#bdiscrdiscr'><p>Internal Function</p></a></li>
<li><a href='#bprobgHs'><p>Internal Function</p></a></li>
<li><a href='#bprobgHsCont'><p>Internal Function</p></a></li>
<li><a href='#bprobgHsContSS'><p>Internal Function</p></a></li>
<li><a href='#bprobgHsContUniv'><p>Internal Function</p></a></li>
<li><a href='#bprobgHsDiscr1'><p>Internal Function</p></a></li>
<li><a href='#bprobgHsDiscr1SS'><p>Internal Function</p></a></li>
<li><a href='#bprobgHsPO'><p>Internal Function</p></a></li>
<li><a href='#bprobgHsSS'><p>Internal Function</p></a></li>
<li><a href='#conv.check'><p>Some convergence diagnostics</p></a></li>
<li><a href='#copgHs'><p>Internal Function</p></a></li>
<li><a href='#copula.prob'><p>Copula probabilities (joint and conditional) from a fitted simultaneous model</p></a></li>
<li><a href='#CopulaCLM'><p>Internal fitting function</p></a></li>
<li><a href='#copulaSampleSel'><p>Internal fitting function</p></a></li>
<li><a href='#cv.inform'><p>Cross validation for informative censoring univariate survival models</p></a></li>
<li><a href='#distrHs'><p>Internal Function</p></a></li>
<li><a href='#Dpens'><p>Differentiable penalties</p></a></li>
<li><a href='#eta.tr'><p>Internal Function</p></a></li>
<li><a href='#g.tri'><p>Internal Function</p></a></li>
<li><a href='#gamlss'><p>Generalised Additive Models for Location, Scale and Shape</p></a></li>
<li><a href='#gamlssObject'><p>Fitted gamlssObject object</p></a></li>
<li><a href='#ggmtrust'><p>ggmtrust for penalised network</p></a></li>
<li><a href='#gjrm'><p>Generalised Joint Regression Models with Binary/Continuous/Discrete/Survival Margins</p></a></li>
<li><a href='#gjrmObject'><p>Fitted gjrm object</p></a></li>
<li><a href='#gt.bpm'><p>Gradient test</p></a></li>
<li><a href='#H.tri'><p>Internal Function</p></a></li>
<li><a href='#hazsurv'><p>Post-estimation calculation of hazard, cumulative hazard and survival functions</p></a></li>
<li><a href='#hiv'><p>HIV Zambian data</p></a></li>
<li><a href='#imputeCounter'><p>Imputation of Counterfactual</p></a></li>
<li><a href='#imputeSS'><p>Missing values' imputation</p></a></li>
<li><a href='#llpsi'><p>Internal Function</p></a></li>
<li><a href='#LM.bpm'><p>Lagrange Multiplier Test (Score Test)</p></a></li>
<li><a href='#lmc'><p>Linear Model Fitting with Constraints</p></a></li>
<li><a href='#logLik.SemiParBIV'><p>Extract the log likelihood for a fitted copula model</p></a></li>
<li><a href='#mb'><p>Nonparametric (worst-case and IV) Manski's bounds</p></a></li>
<li><a href='#meps'><p>MEPS data</p></a></li>
<li><a href='#numgh'><p>Internal Function</p></a></li>
<li><a href='#OR'><p>Causal odds ratio of a binary/continuous/discrete endogenous variable</p></a></li>
<li><a href='#PE'><p>Partial effect from a binary bivariate model</p></a></li>
<li><a href='#pen'><p>Internal Function</p></a></li>
<li><a href='#plot.SemiParBIV'><p>Plotting function</p></a></li>
<li><a href='#polys.map'><p>Geographic map with regions defined as polygons</p></a></li>
<li><a href='#polys.setup'><p>Set up geographic polygons</p></a></li>
<li><a href='#post.check'><p>Diagnostic plots for discrete/continuous response margin</p></a></li>
<li><a href='#pred.gp'><p>Function to predict quantiles from GP and DGP distributions</p></a></li>
<li><a href='#pred.mvt'><p>Function to predict mean and variance of marginal distributions, as well as Kendall's tau</p></a></li>
<li><a href='#predict.CopulaCLM'><p>Prediction function</p></a></li>
<li><a href='#predict.SemiParBIV'><p>Prediction function</p></a></li>
<li><a href='#prev'><p>Estimated overall prevalence from sample selection model</p></a></li>
<li><a href='#print.AT'><p>Print an AT object</p></a></li>
<li><a href='#print.copulaSampleSel'><p>Print a copulaSampleSel object</p></a></li>
<li><a href='#print.gamlss'><p>Print a gamlss object</p></a></li>
<li><a href='#print.gjrm'><p>Print a gjrm object</p></a></li>
<li><a href='#print.mb'><p>Print an mb object</p></a></li>
<li><a href='#print.OR'><p>Print an OR object</p></a></li>
<li><a href='#print.PE'><p>Print an PE object</p></a></li>
<li><a href='#print.prev'><p>Print an prev object</p></a></li>
<li><a href='#print.RR'><p>Print an RR object</p></a></li>
<li><a href='#print.SemiParBIV'><p>Print a SemiParBIV object</p></a></li>
<li><a href='#print.SemiParROY'><p>Print a SemiParROY object</p></a></li>
<li><a href='#print.SemiParTRIV'><p>Print a SemiParTRIV object</p></a></li>
<li><a href='#probm'><p>Internal Function</p></a></li>
<li><a href='#regH'><p>Internal Function</p></a></li>
<li><a href='#resp.check'><p>Plots for response variable</p></a></li>
<li><a href='#rMVN'><p>Multivariate Normal Variates</p></a></li>
<li><a href='#rob.const'><p>Bootstrap procedure to help select the robust constant in a GAMLSS</p></a></li>
<li><a href='#rob.int'><p>Tool for tuning bounds of integral in robust models</p></a></li>
<li><a href='#RR'><p>Causal risk ratio of a binary/continuous/discrete endogenous variable</p></a></li>
<li><a href='#S.m'><p>Internal Function</p></a></li>
<li><a href='#SemiParBIV'><p>Internal fitting function</p></a></li>
<li><a href='#SemiParBIV.fit'><p>Internal Function</p></a></li>
<li><a href='#SemiParBIV.fit.post'><p>Internal Function</p></a></li>
<li><a href='#SemiParROY'><p>Internal fitting function</p></a></li>
<li><a href='#SemiParTRIV'><p>Internal fitting function</p></a></li>
<li><a href='#summary.copulaSampleSel'><p>copulaSampleSel summary</p></a></li>
<li><a href='#summary.gamlss'><p>gamlss summary</p></a></li>
<li><a href='#summary.gjrm'><p>gjrm summary</p></a></li>
<li><a href='#summary.SemiParBIV'><p>SemiParBIV summary</p></a></li>
<li><a href='#summary.SemiParROY'><p>SemiParROY summary</p></a></li>
<li><a href='#summary.SemiParTRIV'><p>SemiParTRIV summary</p></a></li>
<li><a href='#TRIapprox'><p>Internal Function</p></a></li>
<li><a href='#triprobgHs'><p>Internal Function</p></a></li>
<li><a href='#vis.gjrm'><p>Visualization function</p></a></li>
<li><a href='#VuongClarke'><p>Vuong and Clarke tests</p></a></li>
<li><a href='#war'><p>Civil war data</p></a></li>
<li><a href='#working.comp'><p>Internal Function</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Version:</td>
<td>0.2-6.5</td>
</tr>
<tr>
<td>Author:</td>
<td>Giampiero Marra &lt;giampiero.marra@ucl.ac.uk&gt; and Rosalba Radice &lt;rosalba.radice@city.ac.uk&gt;</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Giampiero Marra &lt;giampiero.marra@ucl.ac.uk&gt;</td>
</tr>
<tr>
<td>Title:</td>
<td>Generalised Joint Regression Modelling</td>
</tr>
<tr>
<td>Description:</td>
<td>Routines for fitting various joint (and univariate) regression models, with several types of covariate effects, in the presence of equations' errors association, endogeneity, non-random sample selection or partial observability.</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0), mgcv</td>
</tr>
<tr>
<td>Imports:</td>
<td>magic, VGAM, survey, trust, VineCopula, graphics, stats,
utils, grDevices, ggplot2, matrixStats, mnormt, gamlss.dist,
Rmpfr, scam, survival, psych, copula, numDeriv, evd, ismev,
methods</td>
</tr>
<tr>
<td>Enhances:</td>
<td>sp</td>
</tr>
<tr>
<td>LazyLoad:</td>
<td>yes</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://www.ucl.ac.uk/statistics/people/giampieromarra">https://www.ucl.ac.uk/statistics/people/giampieromarra</a></td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-01-25 14:30:06 UTC</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-01-25 13:41:59 UTC; GM</td>
</tr>
</table>
<hr>
<h2 id='GJRM-package'>Generalised Joint Regression Modelling</h2><span id='topic+GJRM-package'></span>

<h3>Description</h3>

<p>This package provides a function for fitting various generalised joint regression models with several types of covariate 
effects and distributions. Many modelling options are supported and all parameters of the joint distribution can be specified as 
flexible functions of covariates.
</p>
<p>The orginal name of this package was <code>SemiParBIVProbit</code> which was designed 
to fit flexible bivariate binary response models. However, since then the package has expanded so much that its orginal name 
no longer gave a clue about all modelling options available. The new name should more closely reflect past, current and future developments.
</p>
<p>The main fitting functions are listed below.
</p>
<p><code>gjrm()</code> which fits bivariate regression models with binary responses (useful for fitting bivariate binary models in the presence of 
(i) non-random sample selection or (ii) associated responses/endogeneity or (iii) partial observability), bivariate models with 
binary/discrete/continuous/survival margins in the presence of 
associated responses/endogeneity, bivariate sample selection models with continuous/discrete response, trivariate binary 
models (with and without double sample selection). This function essentially merges all previously available fitting functions, namely
<code>SemiParBIV()</code>, <code>SemiParTRIV()</code>, <code>copulaReg()</code> and <code>copulaSampleSel()</code>.
</p>
<p><code>gamlss()</code> fits flexible univariate regression models where the response can be 
binary (only the extreme value distribution is allowed for), continuous, discrete and survival. The 
purpose of this function was only to provide, in some cases, starting values 
for the above functions, but it has now been made available in the form of a proper function should the user wish to fit 
univariate models using the general estimation approach of this package.
</p>
<p>We are currently working on several multivariate extensions.
</p>


<h3>Details</h3>

<p><code>GJRM</code> provides functions for fitting general joint models in various situations. The estimation approach is
based on a very generic penalized maximum likelihood based framework, where any (parametric) distribution can in principle be employed,
and the smoothers (representing several types of covariate effects) are set up using penalised regression splines.
Several marginal and copula distributions are available and the 
numerical routine carries out function minimization using a trust region algorithm in combination with
an adaptation of an automatic multiple smoothing parameter estimation procedure for GAMs (see <code>mgcv</code> for more details on this last point). The smoothers 
supported by this package are those available in <code>mgcv</code>. 
</p>
<p>Confidence intervals for smooth components and nonlinear functions of the model
parameters are derived using a Bayesian approach. P-values for testing 
individual smooth terms for equality to the zero function are also provided and based on the approach
implemented in <code>mgcv</code>. The usual plotting and summary functions are also available. Model/variable 
selection is also possible via the use of shrinakge smoothers and/or information criteria. 
</p>


<h3>Author(s)</h3>

<p>Giampiero Marra (University College London, Department of Statistical Science) and Rosalba Radice (Bayes Business School, Faculty of Actuarial Science and Insurance, City, University of London)
</p>
<p>with help and contributions from Panagiota Filippou (trivariate binary models), Francesco Donat (bivariate models with ordinal and 
continuous margins, and ordinal margins), Matteo Fasiolo (pdf and cdf, and related 
derivatives, of the Tweedie distribution), Alessia Eletti (survival models with mixed censoring and excess hazards), Kiron Das
(Galambos copula), Eva Cantoni and William Aeberhard (robust gamlss), 
Alessia Eletti and Danilo Petti (copula survival model with general censoring scheme).
</p>
<p>Thanks to Bear Braumoeller for suggesting the implementation of 
bivariate models with partial observability, and Carmen Cadarso for suggesting the inclusion of various modelling extensions.
</p>
<p>Maintainer: Giampiero Marra <a href="mailto:giampiero.marra@ucl.ac.uk">giampiero.marra@ucl.ac.uk</a>
</p>
<p>Part funded by EPSRC: EP/J006742/1 and EP/T033061/1
</p>


<h3>References</h3>

<p>Key methodological references (ordered by year of publication):
</p>
<p>Marra G., Radice R., Zimmer D. (2024), A Unifying Switching Regime Regression Framework with Applications in Health Economics. <em>Econometric Reviews</em>, 43(1), 52-70.
</p>
<p>Marra G., Fasiolo M., Radice R., Winkelmann R. (2023), A Flexible Copula Regression Model with Bernoulli and Tweedie Margins for Estimating the Effect of Spending on Mental Health. <em>Health Economics</em>, 32(6), 1305-1322.
</p>
<p>Eletti A., Marra G., Quaresma M., Radice R., Rubio F.J. (2022), A Unifying Framework for Flexible Excess Hazard Modeling with Applications in Cancer Epidemiology. <em>Journal of the Royal Statistical Society Series C</em>, 71(4), 1044-1062.
</p>
<p>Petti D., Eletti A., Marra G., Radice R. (2022), Copula Link-Based Additive Models for Bivariate Time-to-Event Outcomes with General Censoring Scheme. <em>Computational Statistics and Data Analysis</em>, 107550.
</p>
<p>Ranjbar S., Cantoni E., Chavez-Demoulin V., Marra G., Radice R., Jaton-Ogay K. (2022), Modelling the Extremes of Seasonal Viruses and Hospital Congestion: The Example of Flu in a Swiss Hospital. <em>Journal of the Royal Statistical Society Series C</em>, 71(4), 884-905.
</p>
<p>Aeberhard W.H., Cantoni E., Marra G., Radice R. (2021), Robust Fitting for Generalized Additive Models for Location, Scale and Shape. <em>Statistics and Computing</em>, 31(11), 1-16.
</p>
<p>Marra G., Farcomeni A., Radice R. (2021), Link-Based Survival Additive Models under Mixed Censoring to Assess Risks of Hospital-Acquired Infections. <em>Computational Statistics and Data Analysis</em>, 155, 107092.
</p>
<p>Hohberg M., Donat F., Marra G., Kneib T. (2021), Beyond Unidimensional Poverty Analysis Using Distributional Copula Models for Mixed Ordered-Continuous Outcomes. <em>Journal of the Royal Statistical Society Series C</em>, 70(5), 1365-1390.
</p>
<p>Marra G., Radice R., Zimmer D. (2020), Estimating the Binary Endogenous Effect of Insurance on Doctor Visits by Copula-Based Regression Additive Models. <em>Journal of the Royal Statistical Society Series C</em>, 69(4), 953-971.
</p>
<p>Dettoni R., Marra G., Radice R. (2020), Generalized Link-Based Additive Survival Models with Informative Censoring. <em>Journal of Computational and Graphical Statistics</em>, 29(3), 503-512.
</p>
<p>Marra G., Radice R. (2020), Copula Link-Based Additive Models for Right-Censored Event Time Data. <em>Journal of the American Statistical Association</em>, 115(530), 886-895.
</p>
<p>Filippou P., Kneib T., Marra G., Radice R. (2019), A Trivariate Additive Regression Model with Arbitrary Link Functions and Varying Correlation Matrix. <em>Journal of Statistical Planning and Inference</em>, 199, 236-248.
</p>
<p>Gomes M., Radice R., Camarena-Brenes J., Marra G. (2019), Copula Selection Models for Non-Gaussian Outcomes that Are Missing Not at Random. <em>Statistics in Medicine</em>, 38(3), 480-496.
</p>
<p>Klein N., Kneib T., Marra G., Radice R., Rokicki S., McGovern M.E. (2019), Mixed Binary-Continuous Copula Regression Models with Application to Adverse Birth Outcomes. <em>Statistics in Medicine</em>, 38(3), 413-436.
</p>
<p>Wojtys M., Marra G., Radice R. (2018), Copula Based Generalized Additive Models for Location, Scale and Shape with Non-Random Sample Selection. <em>Computational Statistics and Data Analysis</em>, 127, 1-14.
</p>
<p>Filippou P., Marra G., Radice R. (2017), Penalized Likelihood Estimation of a Trivariate Additive Probit Model. <em>Biostatistics</em>, 18(3), 569-585.
</p>
<p>Marra G., Radice R. (2017), Bivariate Copula Additive Models for Location, Scale and Shape. <em>Computational Statistics and Data Analysis</em>, 112, 99-113.
</p>
<p>Marra G., Radice R., Barnighausen T., Wood S.N., McGovern M.E. (2017), A Simultaneous Equation Approach to Estimating HIV Prevalence with Non-Ignorable Missing Responses. <em>Journal of the American Statistical Association</em>, 112(518), 484-496.
</p>
<p>Marra G., Radice R., Filippou P. (2017), Testing the Hypothesis of Exogeneity in Regression Spline Bivariate Probit Models. <em>Communications in Statistics - Simulation and Computation</em>, 46(3), 2283-2298.
</p>
<p>Marra G., Wyszynski K. (2016), Semi-Parametric Copula Sample Selection Models for Count Responses. <em>Computational Statistics and Data Analysis</em>, 104, 110-129.
</p>
<p>Radice R., Marra G., Wojtys M. (2016), Copula Regression Spline Models for Binary Outcomes. <em>Statistics and Computing</em>, 26(5), 981-995. 
</p>
<p>Marra G., Radice R. (2013), A Penalized Likelihood Estimation Approach to Semiparametric Sample Selection Binary Response Modeling. <em>Electronic Journal of Statistics</em>, 7, 1432-1455.
</p>
<p>Marra G., Radice R. (2013), Estimation of a Regression Spline Sample Selection Model. <em>Computational Statistics and Data Analysis</em>, 61, 158-173.
</p>
<p>Marra G., Radice R. (2011), Estimation of a Semiparametric Recursive Bivariate Probit in the Presence of Endogeneity. <em>Canadian Journal of Statistics</em>, 39(2), 259-279.
</p>
<p>For applied case studies see <a href="https://www.homepages.ucl.ac.uk/~ucakgm0/pubs.htm">https://www.homepages.ucl.ac.uk/~ucakgm0/pubs.htm</a>.  
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+gjrm">gjrm</a></code>, <code><a href="#topic+gamlss">gamlss</a></code> </p>

<hr>
<h2 id='adjCov'>Adjustment for the covariance matrix from a fitted gjrm model</h2><span id='topic+adjCov'></span><span id='topic+aCov'></span>

<h3>Description</h3>

 
<p><code>adjCov</code> can be used to adjust the covariance matrix of a fitted <code>gjrm</code> object.</p>


<h3>Usage</h3>

<pre><code class='language-R'>
adjCov(x, id)

</code></pre>


<h3>Arguments</h3>

 
<table>
<tr><td><code id="adjCov_+3A_x">x</code></td>
<td>
<p>A fitted <code>gjrm</code> object as produced by the respective fitting function.</p>
</td></tr>
<tr><td><code id="adjCov_+3A_id">id</code></td>
<td>
<p>Cluster identifier.</p>
</td></tr> 
</table>


<h3>Details</h3>

<p>This adjustment can be made when dealing with clustered data and the cluster structure is neglected when fitting the model. The basic idea is that 
the model is fitted as though observations were independent, and subsequently adjust the covariance matrix of the parameter estimates. Using the
terminology of Liang and Zeger (1986), this would correspond to using an independence structure within 
the context of generalized estimating equations. The parameter estimators are still consistent but are inefficient as compared
to a model which accounts for the correct cluster dependence structure. The covariance matrix of the independence estimators can be adjusted 
as described in Liang and Zeger (1986, Section 2). 
</p>


<h3>Value</h3>

<p>This function returns a fitted object which is identical to that supplied in <code>adjCov</code> but with adjusted covariance matrix.
</p>


<h3>WARNINGS</h3>

<p>This correction may not be appropriate for models fitted using penalties.
</p>


<h3>Author(s)</h3>

<p>Maintainer: Giampiero Marra <a href="mailto:giampiero.marra@ucl.ac.uk">giampiero.marra@ucl.ac.uk</a>
</p>


<h3>References</h3>

<p>Liang K.-Y. and Zeger S. (1986), Longitudinal Data Analysis Using Generalized Linear Models. <em>Biometrika</em>, 73(1), 13-22.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+GJRM-package">GJRM-package</a></code>, <code><a href="#topic+gjrm">gjrm</a></code>
</p>

<hr>
<h2 id='adjCovSD'>Adjustment for the covariance matrix from a gjrm model fitted to complex survey data.</h2><span id='topic+adjCovSD'></span>

<h3>Description</h3>

 
<p><code>adjCovSD</code> can be used to adjust the covariance matrix of a fitted <code>gjrm</code> object.</p>


<h3>Usage</h3>

<pre><code class='language-R'>
adjCovSD(x, design)

</code></pre>


<h3>Arguments</h3>

 
<table>
<tr><td><code id="adjCovSD_+3A_x">x</code></td>
<td>
<p>A fitted <code>gjrm</code> object as produced by the respective fitting function.</p>
</td></tr>
<tr><td><code id="adjCovSD_+3A_design">design</code></td>
<td>
<p>A <code>svydesign</code> object as produced by <code>svydesign()</code> from the <code>survey</code> package.</p>
</td></tr> 
</table>


<h3>Details</h3>

<p>This function has been extracted from the <code>survey</code> package and adapted to the class of this package's models. It computes the sandwich 
variance estimator for a copula model fitted to data from a complex sample survey (Lumley, 2004).
</p>


<h3>Value</h3>

<p>This function returns a fitted object which is identical to that supplied in <code>adjCovSD</code> but with adjusted covariance matrix.
</p>


<h3>WARNINGS</h3>

<p>This correction may not be appropriate for models fitted using penalties.
</p>


<h3>Author(s)</h3>

<p>Maintainer: Giampiero Marra <a href="mailto:giampiero.marra@ucl.ac.uk">giampiero.marra@ucl.ac.uk</a>
</p>


<h3>References</h3>

<p>Lumley T. (2004), Analysis of Complex Survey Samples. <em>Journal of Statistical Software</em>, 9(8), 1-19.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+GJRM-package">GJRM-package</a></code>, <code><a href="#topic+gjrm">gjrm</a></code>
</p>

<hr>
<h2 id='areds'>AREDS</h2><span id='topic+areds'></span>

<h3>Description</h3>

<p>Real dataset of bivariate interval and right censored data with 628 subjects 
and three covariates. The dataset is a reshaped version of the AREDS data from the <code>CopulaCenR</code> package. The dataset 
was selected from the Age-related Eye Disease Study (AREDS) (AREDS Group, 1999). The two events are the 
progression times (in years) to late-AMD in the left and right eyes.</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(areds)
</code></pre>


<h3>Format</h3>

<p><code>war</code> is a 628 row data frame with the following columns 
</p>

<dl>
<dt>t11, t12</dt><dd><p>left and right bounds of the intervals for the left eye. If <code>t12 = NA</code> then the observation is right-censored.</p>
</dd>
<dt>t21, t22</dt><dd><p>left and right bounds of the intervals for the right eye. If <code>t22 = NA</code> then the observation is right-censored.</p>
</dd>
<dt>SevScore1, SevScore2</dt><dd><p>baseline AMD severity scores for left and right eyes, respectively. Possible values are: 4, 5, 6, 7, 8.</p>
</dd>
<dt>age</dt><dd><p>age at baseline.</p>
</dd>
<dt>rs2284665</dt><dd><p>a genetic variant covariate highly associated with late-AMD progression. Possible values are: 0, 1, 2.</p>
</dd>
<dt>cens1, cens2</dt><dd><p>type of censoring for left and right eyes.</p>
</dd>
<dt>cens</dt><dd><p>joint censoring indicator for left and right eyes.</p>
</dd>
</dl>



<h3>Source</h3>

<p>Data are from:
</p>
<p>AREDS Group (1999), The Age-Related Eye Disease Study (AREDS): design implications. AREDS report no. 1. <em>Control Clinical Trials</em>, 20, 573-600.
</p>

<hr>
<h2 id='AT'>Average treatment effect of a binary/continuous/discrete endogenous variable</h2><span id='topic+AT'></span>

<h3>Description</h3>

 
<p><code>AT</code> can be used to calculate the treatment effect of a binary/continuous/discrete endogenous predictor/treatment, with 
corresponding interval obtained using posterior simulation.</p>


<h3>Usage</h3>

<pre><code class='language-R'>
AT(x, nm.end, eq = NULL, E = TRUE, treat = TRUE, type = "joint", ind = NULL, 
   percentage = FALSE, n.sim = 100, prob.lev = 0.05, length.out = NULL,
   hd.plot = FALSE, te.plot = FALSE, 
   main = "Histogram and Kernel Density of Simulated Average Effects", 
   xlab = "Simulated Average Effects", ...)

</code></pre>


<h3>Arguments</h3>

 
<table>
<tr><td><code id="AT_+3A_x">x</code></td>
<td>
<p>A fitted <code>gjrm</code> object as produced by the respective fitting function.</p>
</td></tr>
<tr><td><code id="AT_+3A_nm.end">nm.end</code></td>
<td>
<p>Name of the endogenous variable.</p>
</td></tr> 
<tr><td><code id="AT_+3A_eq">eq</code></td>
<td>
<p>Number of equation containing the endogenous variable. This is only used for trivariate models.</p>
</td></tr> 
<tr><td><code id="AT_+3A_e">E</code></td>
<td>
<p>If <code>TRUE</code> then <code>AT</code> calculates the sample ATE. If <code>FALSE</code> then it calculates the sample AT 
for the treated individuals only.</p>
</td></tr>  
<tr><td><code id="AT_+3A_treat">treat</code></td>
<td>
<p>If <code>TRUE</code> then <code>AT</code> calculates the AT using the treated only. If <code>FALSE</code> then it calculates the effect on 
the control group. This only makes sense if <code>E = FALSE</code>.</p>
</td></tr>  
<tr><td><code id="AT_+3A_type">type</code></td>
<td>
<p>This argument can take three values: <code>"naive"</code> (the effect is calculated ignoring the presence of observed and unobserved 
confounders), <code>"univariate"</code> (the effect is obtained from the univariate model 
which neglects the presence of unobserved confounders) and <code>"joint"</code> (the effect is obtained from 
the simultaneous model which accounts for observed and unobserved confounders).</p>
</td></tr>
<tr><td><code id="AT_+3A_ind">ind</code></td>
<td>
<p>Binary logical variable. It can be used to calculate the AT for a subset of the data. Note that it does not make sense to 
use <code>ind</code> when some observations are excluded from the AT calculation (e.g., when using <code>E = FALSE</code>).</p>
</td></tr>  
<tr><td><code id="AT_+3A_percentage">percentage</code></td>
<td>
<p>Only for the Roy model, when <code>TRUE</code> it provides results in terms of percentage.</p>
</td></tr>
<tr><td><code id="AT_+3A_n.sim">n.sim</code></td>
<td>
<p>Number of simulated coefficient vectors from the posterior distribution of the estimated model parameters. This is used 
when <code>delta = FALSE</code>. It may be increased if more precision is required.</p>
</td></tr> 
<tr><td><code id="AT_+3A_prob.lev">prob.lev</code></td>
<td>
<p>Overall probability of the left and right tails of the AT distribution used for interval calculations.</p>
</td></tr> 
<tr><td><code id="AT_+3A_length.out">length.out</code></td>
<td>
<p>Ddesired length of the sequence to be used when calculating the effect that a continuous/discrete
treatment has on a binary outcome.</p>
</td></tr>
<tr><td><code id="AT_+3A_hd.plot">hd.plot</code></td>
<td>
<p>If <code>TRUE</code> then a plot of the histogram and kernel density estimate of the simulated average effects is produced. This can 
only be produced when when binary responses are used.</p>
</td></tr>
<tr><td><code id="AT_+3A_te.plot">te.plot</code></td>
<td>
<p>For the case of continuous/discrete endogenous variable and binary outcome, if <code>TRUE</code> then a plot  
showing the treatment effects that the binary outcome is equal to 1 for each incremental value of the endogenous variable 
and respective intervals is produced.</p>
</td></tr>
<tr><td><code id="AT_+3A_main">main</code></td>
<td>
<p>Title for the plot.</p>
</td></tr>
<tr><td><code id="AT_+3A_xlab">xlab</code></td>
<td>
<p>Title for the x axis.</p>
</td></tr>
<tr><td><code id="AT_+3A_...">...</code></td>
<td>
<p>Other graphics parameters to pass on to plotting commands. These are used only when <code>hd.plot = TRUE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>AT measures the average difference in outcomes under 
treatment (the binary predictor or treatment assumes value 1) and under 
control (the binary treatment assumes value 0). Posterior simulation 
is used to obtain a confidence/credible interval. See the references below for details. 
</p>
<p>AT can also calculate the effect that a continuous/discrete endogenous variable has on a binary outcome. In 
this case the effect will depend on the 
unit increment chosen (as shown by the plot produced). 
</p>


<h3>Value</h3>

<table>
<tr><td><code>res</code></td>
<td>
<p>It returns three values: lower confidence interval limit, estimated AT and upper interval limit.</p>
</td></tr>
<tr><td><code>prob.lev</code></td>
<td>
<p>Probability level used.</p>
</td></tr>
<tr><td><code>sim.AT</code></td>
<td>
<p>It returns a vector containing simulated values of the average treatment effect. This 
is used to calculate intervals.</p>
</td></tr>
<tr><td><code>Effects</code></td>
<td>
<p>For the case of continuous/discrete endogenous variable and binary outcome, it returns a matrix made up of 
three columns containing the effects for each incremental value in the endogenous variable and respective intervals.</p>
</td></tr>            
</table>


<h3>Author(s)</h3>

<p>Maintainer: Giampiero Marra <a href="mailto:giampiero.marra@ucl.ac.uk">giampiero.marra@ucl.ac.uk</a>
</p>


<h3>References</h3>

<p>Marra G. and Radice R. (2011), Estimation of a Semiparametric Recursive Bivariate Probit in the Presence of Endogeneity. <em>Canadian Journal of Statistics</em>, 39(2), 259-279.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+GJRM-package">GJRM-package</a></code>, <code><a href="#topic+gjrm">gjrm</a></code> 
</p>

<hr>
<h2 id='BCDF'>Internal Function</h2><span id='topic+BCDF'></span><span id='topic+BiCDF'></span>

<h3>Description</h3>

<p>It evaluates the cdf of several copulae.</p>


<h3>Author(s)</h3>

<p>Maintainer: Giampiero Marra <a href="mailto:giampiero.marra@ucl.ac.uk">giampiero.marra@ucl.ac.uk</a>
</p>

<hr>
<h2 id='bcont'>Internal Function</h2><span id='topic+bcont'></span><span id='topic+bcont3'></span><span id='topic+bcont23'></span><span id='topic+bcont32'></span><span id='topic+bcontROB'></span><span id='topic+ggm.Deriv'></span>

<h3>Description</h3>

<p>This and other similar internal functions provide the log-likelihood, gradient and observed information matrix for 
penalized/unpenalized maximum likelihood optimization when copula models with continuous margins are employed.
</p>


<h3>Author(s)</h3>

<p>Maintainer: Giampiero Marra <a href="mailto:giampiero.marra@ucl.ac.uk">giampiero.marra@ucl.ac.uk</a>
</p>

<hr>
<h2 id='bdiscrcont'>Internal Function</h2><span id='topic+bdiscrcont'></span><span id='topic+bdiscrcont12'></span><span id='topic+bdiscrcont13'></span><span id='topic+bdiscrcont23'></span>

<h3>Description</h3>

<p>This and other similar internal functions provide the log-likelihood, gradient and observed information matrix for 
penalized/unpenalized maximum likelihood optimization when copula models with discrete and continuous margins are employed.
</p>


<h3>Author(s)</h3>

<p>Maintainer: Giampiero Marra <a href="mailto:giampiero.marra@ucl.ac.uk">giampiero.marra@ucl.ac.uk</a>
</p>

<hr>
<h2 id='bdiscrdiscr'>Internal Function</h2><span id='topic+bdiscrdiscr11'></span><span id='topic+bdiscrdiscr12'></span>

<h3>Description</h3>

<p>This and other similar internal functions provide the log-likelihood, gradient and observed information matrix for 
penalized/unpenalized maximum likelihood optimization when copula models with discrete margins are employed.
</p>


<h3>Author(s)</h3>

<p>Maintainer: Giampiero Marra <a href="mailto:giampiero.marra@ucl.ac.uk">giampiero.marra@ucl.ac.uk</a>
</p>

<hr>
<h2 id='bprobgHs'>Internal Function</h2><span id='topic+bprobgHs'></span><span id='topic+bprobgHstwoParC'></span><span id='topic+bprobgHsBinROY'></span>

<h3>Description</h3>

<p>It provides the log-likelihood, gradient and observed/Fisher information matrix for 
penalized/unpenalized maximum likelihood optimization when copula models with binary outcomes are employed.</p>


<h3>Author(s)</h3>

<p>Maintainer: Giampiero Marra <a href="mailto:giampiero.marra@ucl.ac.uk">giampiero.marra@ucl.ac.uk</a>
</p>

<hr>
<h2 id='bprobgHsCont'>Internal Function</h2><span id='topic+bprobgHsCont'></span><span id='topic+bprobgHsCont3'></span><span id='topic+bCopulaCLMgHsCont'></span><span id='topic+bCopulaCLMgHsOrd'></span><span id='topic+bprobgHsCont3binTW'></span><span id='topic+bprobgHsCont2ROY'></span><span id='topic+bprobgHsCont3ROY'></span>

<h3>Description</h3>

<p>It provides the log-likelihood, gradient and observed information matrix for 
penalized/unpenalized maximum likelihood optimization when copula models with binary and continuous margins are employed.</p>


<h3>Author(s)</h3>

<p>Maintainer: Giampiero Marra <a href="mailto:giampiero.marra@ucl.ac.uk">giampiero.marra@ucl.ac.uk</a>
</p>

<hr>
<h2 id='bprobgHsContSS'>Internal Function</h2><span id='topic+bprobgHsContSS'></span><span id='topic+bprobgHsCont3SS'></span><span id='topic+bprobgHsCont3binTWSS'></span>

<h3>Description</h3>

<p>It provides the log-likelihood, gradient and observed information matrix for 
penalized/unpenalized maximum likelihood optimization when copula sample selection models with continuous margins are employed.</p>


<h3>Author(s)</h3>

<p>Maintainer: Giampiero Marra <a href="mailto:giampiero.marra@ucl.ac.uk">giampiero.marra@ucl.ac.uk</a>
</p>

<hr>
<h2 id='bprobgHsContUniv'>Internal Function</h2><span id='topic+bprobgHsContUniv'></span><span id='topic+bprobgHsContUniv3'></span><span id='topic+bprobgHsContUnivBIN'></span><span id='topic+bcontSurvGunivInform'></span><span id='topic+bcontSurvGunivI'></span><span id='topic+bcontSurvGunivL'></span><span id='topic+bcontSurvGunivMIXED'></span><span id='topic+bcontSurvGunivMIXED_ExcessHazard'></span><span id='topic+bcontSurvGunivL_ExcessHazard'></span><span id='topic+bcontSurvGuniv_ExcessHazard'></span><span id='topic+bcontSurvGunivI_ExcessHazard'></span><span id='topic+bcontSurvGunivMIXED_LeftTruncation'></span><span id='topic+bcontSurvGunivMIXED_ExcessHazard_LeftTruncation'></span><span id='topic+bcontSurvG_extended'></span>

<h3>Description</h3>

<p>It provides the log-likelihood, gradient and observed information matrix for 
penalized/unpenalized maximum likelihood optimization when fitting univariate models with discrete/continuous response.</p>


<h3>Author(s)</h3>

<p>Maintainer: Giampiero Marra <a href="mailto:giampiero.marra@ucl.ac.uk">giampiero.marra@ucl.ac.uk</a>
</p>

<hr>
<h2 id='bprobgHsDiscr1'>Internal Function</h2><span id='topic+bprobgHsDiscr1'></span><span id='topic+bprobgHsDiscr2'></span><span id='topic+bprobgHsDiscr1ROY'></span><span id='topic+bprobgHsDiscr2ROY'></span>

<h3>Description</h3>

<p>It provides the log-likelihood, gradient and observed information matrix for 
penalized/unpenalized maximum likelihood optimization when copula models with binary and discrete margins are employed.</p>


<h3>Author(s)</h3>

<p>Maintainer: Giampiero Marra <a href="mailto:giampiero.marra@ucl.ac.uk">giampiero.marra@ucl.ac.uk</a>
</p>

<hr>
<h2 id='bprobgHsDiscr1SS'>Internal Function</h2><span id='topic+bprobgHsDiscr1SS'></span><span id='topic+bprobgHsDiscr2SS'></span>

<h3>Description</h3>

<p>It provides the log-likelihood, gradient and observed information matrix for 
penalized/unpenalized maximum likelihood optimization when copula sample selection models with discrete margins are employed.</p>


<h3>Author(s)</h3>

<p>Maintainer: Giampiero Marra <a href="mailto:giampiero.marra@ucl.ac.uk">giampiero.marra@ucl.ac.uk</a>
</p>

<hr>
<h2 id='bprobgHsPO'>Internal Function</h2><span id='topic+bprobgHsPO'></span><span id='topic+bprobgHsPO0'></span>

<h3>Description</h3>

<p>It provides the log-likelihood, gradient and observed or expected information matrix for 
penalized/unpenalized maximum likelihood optimization when bivariate probit models with partial
observability are employed.  
</p>


<h3>Author(s)</h3>

<p>Maintainer: Giampiero Marra <a href="mailto:giampiero.marra@ucl.ac.uk">giampiero.marra@ucl.ac.uk</a>
</p>

<hr>
<h2 id='bprobgHsSS'>Internal Function</h2><span id='topic+bprobgHsSS'></span>

<h3>Description</h3>

<p>It provides the log-likelihood, gradient and observed/Fisher information matrix for 
penalized/unpenalized maximum likelihood optimization when copula sample selection models with binary outcomes are employed.
</p>


<h3>Author(s)</h3>

<p>Maintainer: Giampiero Marra <a href="mailto:giampiero.marra@ucl.ac.uk">giampiero.marra@ucl.ac.uk</a>
</p>

<hr>
<h2 id='conv.check'>Some convergence diagnostics</h2><span id='topic+conv.check'></span>

<h3>Description</h3>

<p>It takes a fitted model object and produces some 
diagnostic information about the fitting procedure.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
conv.check(x)


</code></pre>


<h3>Arguments</h3>

 
<table>
<tr><td><code id="conv.check_+3A_x">x</code></td>
<td>
<p><code>gjrm</code> object.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Maintainer: Giampiero Marra <a href="mailto:giampiero.marra@ucl.ac.uk">giampiero.marra@ucl.ac.uk</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gamlss">gamlss</a></code>, <code><a href="#topic+gjrm">gjrm</a></code>
</p>

<hr>
<h2 id='copgHs'>Internal Function</h2><span id='topic+copgHs'></span><span id='topic+copgHs2'></span><span id='topic+copgHs3'></span><span id='topic+copgHsAT'></span><span id='topic+copgHsCont'></span><span id='topic+copgHsCond'></span>

<h3>Description</h3>

<p>This and other similar internal functions evaluate the first and second derivatives with respect to the margins and association 
parameter of several copulae.
</p>


<h3>Author(s)</h3>

<p>Maintainer: Giampiero Marra <a href="mailto:giampiero.marra@ucl.ac.uk">giampiero.marra@ucl.ac.uk</a>
</p>

<hr>
<h2 id='copula.prob'>Copula probabilities (joint and conditional) from a fitted simultaneous model</h2><span id='topic+copula.prob'></span><span id='topic+jc.probs1'></span><span id='topic+jc.probs2'></span><span id='topic+jc.probs3'></span><span id='topic+jc.probs4'></span><span id='topic+jc.probs5'></span><span id='topic+jc.probs6'></span><span id='topic+jc.probs7'></span><span id='topic+jc.probs8'></span>

<h3>Description</h3>

 
<p><code>copula.prob</code> can be used to calculate the joint or conditional copula probabilities from a fitted simultaneous model with intervals obtained 
via posterior simulation.</p>


<h3>Usage</h3>

<pre><code class='language-R'>
copula.prob(x, y1, y2, y3 = NULL, newdata, joint = TRUE, cond = 0,
            type = "surv", intervals = FALSE, n.sim = 100, prob.lev = 0.05, 
            min.pr = 1e-323, max.pr = 1, cumul = "no")

</code></pre>


<h3>Arguments</h3>

 
<table>
<tr><td><code id="copula.prob_+3A_x">x</code></td>
<td>
<p>A fitted <code>gjrm</code> object as 
produced by the respective fitting function.</p>
</td></tr>
<tr><td><code id="copula.prob_+3A_y1">y1</code></td>
<td>
<p>Value of response for first margin.</p>
</td></tr>
<tr><td><code id="copula.prob_+3A_y2">y2</code></td>
<td>
<p>Value of response for second margin.</p>
</td></tr>
<tr><td><code id="copula.prob_+3A_y3">y3</code></td>
<td>
<p>Value of response for third margin if a trivariate model is employed.</p>
</td></tr>
<tr><td><code id="copula.prob_+3A_newdata">newdata</code></td>
<td>
<p>A data frame or list containing the values of the model covariates at which predictions are required. 
If not provided then predictions corresponding to the original data are returned.
When newdata is provided, it should contain all the variables needed for prediction.</p>
</td></tr>
<tr><td><code id="copula.prob_+3A_joint">joint</code></td>
<td>
<p>If <code>TRUE</code> then the calculation is done using the fitted joint model. If <code>FALSE</code> then 
the calculation is done from univariate fits.</p>
</td></tr>
<tr><td><code id="copula.prob_+3A_cond">cond</code></td>
<td>
<p>There are three possible values: 0 (joint probabilities are delivered), 1 (conditional probabilities are delivered and 
conditioning is with the respect to the first margin), 2 (as before but conditioning is with the respect to 
the second margin).</p>
</td></tr>  
<tr><td><code id="copula.prob_+3A_type">type</code></td>
<td>
<p>This argument is only valid for survival copula models. It can take values: &quot;surv&quot;, &quot;hazard&quot;, &quot;cumhaz&quot;.</p>
</td></tr>  
<tr><td><code id="copula.prob_+3A_intervals">intervals</code></td>
<td>
<p>If <code>TRUE</code> then intervals for the probabilities are also produced.</p>
</td></tr>   
<tr><td><code id="copula.prob_+3A_n.sim">n.sim</code></td>
<td>
<p>Number of simulated coefficient vectors from the posterior distribution of the estimated model parameters. This is used
for interval calculations.</p>
</td></tr> 
<tr><td><code id="copula.prob_+3A_prob.lev">prob.lev</code></td>
<td>
<p>Overall probability of the left and right tails of the probabilities' distributions used for interval calculations.</p>
</td></tr> 
<tr><td><code id="copula.prob_+3A_min.pr">min.pr</code>, <code id="copula.prob_+3A_max.pr">max.pr</code></td>
<td>
<p>Allowed minimum and maximum for estimated probabities.</p>
</td></tr>
<tr><td><code id="copula.prob_+3A_cumul">cumul</code></td>
<td>
<p>Only used for discrete and continuous margins' case.</p>
</td></tr> 
</table>


<h3>Details</h3>

<p>This function calculates joint or conditional copula probabilities from a fitted simultaneous model or a model assuming independence, with intervals 
obtained via posterior simulation.
</p>


<h3>Value</h3>

<table>
<tr><td><code>res</code></td>
<td>
<p>It returns several values including: estimated probabilities (<code>p12</code>), with lower and upper interval limits (<code>CIpr</code>) 
if <code>intervals = TRUE</code>, and <code>p1</code>, <code>p2</code> and <code>p3</code> (the marginal probabilities).</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Maintainer: Giampiero Marra <a href="mailto:giampiero.marra@ucl.ac.uk">giampiero.marra@ucl.ac.uk</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+GJRM-package">GJRM-package</a></code>, <code><a href="#topic+gjrm">gjrm</a></code>  
</p>

<hr>
<h2 id='CopulaCLM'>Internal fitting function</h2><span id='topic+CopulaCLM'></span>

<h3>Description</h3>

<p>Internal fitting and set up function.</p>


<h3>Author(s)</h3>

<p>Maintainer: Giampiero Marra <a href="mailto:giampiero.marra@ucl.ac.uk">giampiero.marra@ucl.ac.uk</a>
</p>

<hr>
<h2 id='copulaSampleSel'>Internal fitting function</h2><span id='topic+copulaSampleSel'></span>

<h3>Description</h3>

<p>Internal fitting and set up function.</p>


<h3>Author(s)</h3>

<p>Maintainer: Giampiero Marra <a href="mailto:giampiero.marra@ucl.ac.uk">giampiero.marra@ucl.ac.uk</a>
</p>

<hr>
<h2 id='cv.inform'>Cross validation for informative censoring univariate survival models</h2><span id='topic+cv.inform'></span>

<h3>Description</h3>

 
<p><code>cv.inform</code> carries out cross validation to help choosing the set of informative covariates.</p>


<h3>Usage</h3>

<pre><code class='language-R'>
cv.inform(x, K = 5, data, informative = "yes")

</code></pre>


<h3>Arguments</h3>

 
<table>
<tr><td><code id="cv.inform_+3A_x">x</code></td>
<td>
<p>A fitted <code>gamlss</code> object as produced by the respective fitting function.</p>
</td></tr>
<tr><td><code id="cv.inform_+3A_k">K</code></td>
<td>
<p>No. of folds.</p>
</td></tr> 
<tr><td><code id="cv.inform_+3A_data">data</code></td>
<td>
<p>Data.</p>
</td></tr> 
<tr><td><code id="cv.inform_+3A_informative">informative</code></td>
<td>
<p>If no then cv is carried out for the case of no informative censoring. This is useful for comparison purposes.</p>
</td></tr> 
</table>


<h3>Details</h3>

<p><code>cv.inform</code> carries out cross validation to help choosing the set of informative covariates.
</p>


<h3>Value</h3>

<table>
<tr><td><code>sl</code></td>
<td>
<p>Overall sum of predicted likelihood contributions.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Maintainer: Giampiero Marra <a href="mailto:giampiero.marra@ucl.ac.uk">giampiero.marra@ucl.ac.uk</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+GJRM-package">GJRM-package</a></code>, <code><a href="#topic+gamlss">gamlss</a></code> 
</p>

<hr>
<h2 id='distrHs'>Internal Function</h2><span id='topic+distrHs'></span><span id='topic+distrHsAT'></span><span id='topic+distrHsAT1'></span><span id='topic+distrHsATDiscr'></span><span id='topic+distrHsDiscr'></span><span id='topic+distrHsATDiscr2'></span><span id='topic+distrExIntegrate'></span>

<h3>Description</h3>

<p>This and other similar internal functions evaluate the margins' derivatives needed in the likelihood function for the 
binary, discrete and continuous cases.</p>


<h3>Author(s)</h3>

<p>Maintainer: Giampiero Marra <a href="mailto:giampiero.marra@ucl.ac.uk">giampiero.marra@ucl.ac.uk</a>
</p>

<hr>
<h2 id='Dpens'>Differentiable penalties</h2><span id='topic+Dpens'></span>

<h3>Description</h3>

 
<p>work in progress, temp function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
Dpens(params, type = "lasso", lambda = 1, w.alasso = NULL, 
      gamma = 1, a = 3.7, eps = 1e-08)
          
</code></pre>


<h3>Arguments</h3>

 
<table>
<tr><td><code id="Dpens_+3A_params">params</code></td>
<td>
<p>coefficients.</p>
</td></tr> 
<tr><td><code id="Dpens_+3A_type">type</code></td>
<td>
<p>lasso, alasso or scad.</p>
</td></tr> 
<tr><td><code id="Dpens_+3A_lambda">lambda</code></td>
<td>
<p>smoothing parameter.</p>
</td></tr> 
<tr><td><code id="Dpens_+3A_w.alasso">w.alasso</code></td>
<td>
<p>for alasso.</p>
</td></tr> 
<tr><td><code id="Dpens_+3A_gamma">gamma</code></td>
<td>
<p>default 1.</p>
</td></tr>
<tr><td><code id="Dpens_+3A_a">a</code></td>
<td>
<p>for scad.</p>
</td></tr>
<tr><td><code id="Dpens_+3A_eps">eps</code></td>
<td>
<p>tolerance.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>work in progress.
</p>


<h3>Value</h3>

<p>The function returns a penalty.
</p>

<hr>
<h2 id='eta.tr'>Internal Function</h2><span id='topic+eta.tr'></span><span id='topic+esp.tr'></span><span id='topic+enu.tr'></span><span id='topic+teta.tr'></span><span id='topic+dof.tr'></span><span id='topic+form.eq12'></span><span id='topic+ass.dp'></span><span id='topic+overall.sv'></span><span id='topic+overall.svG'></span><span id='topic+gamls.upsv'></span><span id='topic+pp'></span><span id='topic+susutsn'></span><span id='topic+susu'></span><span id='topic+pscr'></span><span id='topic+pscr0'></span><span id='topic+startsn'></span><span id='topic+bcorrec'></span><span id='topic+bcorrecDiscr'></span><span id='topic+Cop1Cop2'></span><span id='topic+Reg2Copost'></span><span id='topic+SS'></span><span id='topic+sim.resp'></span><span id='topic+r.resp'></span><span id='topic+probmS'></span><span id='topic+PosDefCor'></span><span id='topic+PDef'></span><span id='topic+bcorrecFuncs'></span><span id='topic+Xdpred'></span><span id='topic+mmf'></span><span id='topic+vis.gam2'></span><span id='topic+cov.c'></span><span id='topic+inform.setup'></span><span id='topic+intB'></span><span id='topic+mice.impute.copulaSS'></span><span id='topic+rIC'></span><span id='topic+resp.CLM'></span><span id='topic+approx.CLM'></span><span id='topic+ggmtrust.path'></span><span id='topic+ggm.DerivOPT1'></span><span id='topic+ggm.DerivOPT2'></span><span id='topic+Dpens2'></span><span id='topic+survExcInd'></span><span id='topic+pTweed'></span><span id='topic+pream.wm'></span>

<h3>Description</h3>

<p>This and other similar internal functions map certain key quantities into a feasible parameter space. Some functions carry out 
some general consistency checks.</p>


<h3>Author(s)</h3>

<p>Maintainer: Giampiero Marra <a href="mailto:giampiero.marra@ucl.ac.uk">giampiero.marra@ucl.ac.uk</a>
</p>

<hr>
<h2 id='g.tri'>Internal Function</h2><span id='topic+g.tri'></span><span id='topic+g.triSS'></span><span id='topic+g.triESS'></span>

<h3>Description</h3>

<p>This and other similar internal functions calculate the score for trivariate binary models.</p>


<h3>Author(s)</h3>

<p>Author: Panagiota Filippou
</p>
<p>Maintainer: Giampiero Marra <a href="mailto:giampiero.marra@ucl.ac.uk">giampiero.marra@ucl.ac.uk</a>
</p>

<hr>
<h2 id='gamlss'>Generalised Additive Models for Location, Scale and Shape</h2><span id='topic+gamlss'></span>

<h3>Description</h3>

 
<p><code>gamlss</code> fits flexible univariate regression models with several continuous and discrete distributions, and types of covariate 
effects. The purpose of this function was only to provide, in some cases, starting values 
for the simultaneous models in the package, but it has now been made available in the form of a proper function should the user wish to fit 
univariate models using the general estimation approach of this package. The distributions used here 
have been parametrised according to Rigby and Stasinopoulos (2005).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gamlss(formula, data = list(), weights = NULL, subset = NULL,  
       margin = "N", surv = FALSE, cens = NULL, type.cens = "R", upperB = NULL,
       robust = FALSE, rc = 3, lB = NULL, uB = NULL, infl.fac = 1, 
       rinit = 1, rmax = 100, iterlimsp = 50, tolsp = 1e-07,
       gc.l = FALSE, parscale, extra.regI = "t", gev.par = -0.25,
       chunk.size = 10000, k.tvc = 0, knots = NULL,
       informative = "no", inform.cov = NULL, margin2 = "PH", 
       fp = FALSE, sp = NULL,
       drop.unused.levels = TRUE, siginit = NULL, shinit = NULL,
       sp.method = "perf", hrate = NULL, d.lchrate = NULL, d.rchrate = NULL,
       d.lchrate.td = NULL, d.rchrate.td = NULL, truncation.time = NULL,
       min.dn = 1e-40, min.pr = 1e-16, max.pr = 0.9999999, ygrid.tol = 1e-08)
</code></pre>


<h3>Arguments</h3>

 
<table>
<tr><td><code id="gamlss_+3A_formula">formula</code></td>
<td>
<p>List of equations. This should contain one or more equations.</p>
</td></tr> 
<tr><td><code id="gamlss_+3A_data">data</code></td>
<td>
<p>An optional data frame, list or environment containing the variables in the model.  If not found in <code>data</code>, the
variables are taken from <code>environment(formula)</code>, typically the environment from which <code>gamlss</code> is called.</p>
</td></tr> 
<tr><td><code id="gamlss_+3A_weights">weights</code></td>
<td>
<p>Optional vector of prior weights to be used in fitting.</p>
</td></tr> 
<tr><td><code id="gamlss_+3A_subset">subset</code></td>
<td>
<p>Optional vector specifying a subset of observations to be used in the fitting process.</p>
</td></tr>
<tr><td><code id="gamlss_+3A_margin">margin</code></td>
<td>
<p>Possible distributions are normal (&quot;N&quot;), Tweedie (&quot;TW&quot;),
log-normal (&quot;LN&quot;), Gumbel (&quot;GU&quot;), reverse Gumbel (&quot;rGU&quot;), generelised Pareto (&quot;GP&quot;), 
generelised Pareto II (&quot;GPII&quot;) where the shape parameter is forced to be &gt; -0.5, 
generelised Pareto (with orthogonal parametrisation) (&quot;GPo&quot;) where the shape parameter is forced to be &gt; -0.5,
discrete generelised Pareto (&quot;DGP&quot;),
discrete generelised Pareto II (&quot;DGPII&quot;) where the shape parameter is forced to be positive, discrete generelised Pareto derived
under the scenario in which shape = 0 (&quot;DGP0&quot;), logistic (&quot;LO&quot;), Weibull (&quot;WEI&quot;), inverse Gaussian (&quot;iG&quot;), gamma (&quot;GA&quot;), Dagum (&quot;DAGUM&quot;), 
Singh-Maddala (&quot;SM&quot;), beta (&quot;BE&quot;), Fisk (&quot;FISK&quot;, also known as log-logistic distribution), Poisson (&quot;PO&quot;), zero truncated 
Poisson (&quot;ZTP&quot;), negative binomial - type I (&quot;NBI&quot;), negative 
binomial - type II (&quot;NBII&quot;), Poisson inverse Gaussian (&quot;PIG&quot;), generalised extreme value link function (&quot;GEVlink&quot;, this 
is used for binary responses and is more stable and faster than the <code>R</code> package <code>bgeva</code>).</p>
</td></tr>
<tr><td><code id="gamlss_+3A_surv">surv</code></td>
<td>
<p>If <code>TRUE</code> then a survival model is fitted. Here margin can be &quot;PH&quot; (generalised proportional hazards), &quot;PO&quot; (generalised proportional odds), 
&quot;probit&quot; (generalised probit).</p>
</td></tr>
<tr><td><code id="gamlss_+3A_cens">cens</code></td>
<td>
<p>This is required when <code>surv = TRUE</code>. When <code>type.cens</code> is different from <code>mixed</code>, this variable can be equal to 1 if the event occurred 
and 0 otherwise. If <code>type.cens = "mixed"</code> then <code>cens</code> is a mixed factor variable (made up of four possible 
categories: <code>I</code> for interval, <code>L</code> for left, <code>R</code> for right, and <code>U</code> for uncensored.</p>
</td></tr>
<tr><td><code id="gamlss_+3A_type.cens">type.cens</code></td>
<td>
<p>Type of censoring mechanism. This can be &quot;R&quot;, &quot;L&quot;, &quot;I&quot; or &quot;mixed&quot;.</p>
</td></tr>
<tr><td><code id="gamlss_+3A_upperb">upperB</code></td>
<td>
<p>Variable name of right/upper bound when <code>type.cens = "I"</code> or <code>type.cens = "mixed"</code> and interval censoring is present.</p>
</td></tr>
<tr><td><code id="gamlss_+3A_robust">robust</code></td>
<td>
<p>If <code>TRUE</code> then the robust version of the model is fitted.</p>
</td></tr>
<tr><td><code id="gamlss_+3A_rc">rc</code></td>
<td>
<p>Robust constant.</p>
</td></tr>       
<tr><td><code id="gamlss_+3A_lb">lB</code>, <code id="gamlss_+3A_ub">uB</code></td>
<td>
<p>Bounds for integral in robust case.</p>
</td></tr>  
<tr><td><code id="gamlss_+3A_infl.fac">infl.fac</code></td>
<td>
<p>Inflation factor for the model degrees of freedom in the approximate AIC. Smoother models can be obtained setting 
this parameter to a value greater than 1.</p>
</td></tr>
<tr><td><code id="gamlss_+3A_rinit">rinit</code></td>
<td>
<p>Starting trust region radius. The trust region radius is adjusted as the algorithm proceeds.</p>
</td></tr>
<tr><td><code id="gamlss_+3A_rmax">rmax</code></td>
<td>
<p>Maximum allowed trust region radius. This may be set very large. If set small, the algorithm traces a steepest 
descent path.</p>
</td></tr> 
<tr><td><code id="gamlss_+3A_iterlimsp">iterlimsp</code></td>
<td>
<p>A positive integer specifying the maximum number of loops to be performed before the smoothing parameter estimation 
step is terminated.</p>
</td></tr> 
<tr><td><code id="gamlss_+3A_tolsp">tolsp</code></td>
<td>
<p>Tolerance to use in judging convergence of the algorithm when automatic smoothing parameter estimation is used.</p>
</td></tr> 
<tr><td><code id="gamlss_+3A_gc.l">gc.l</code></td>
<td>
<p>This is relevant when working with big datasets. If <code>TRUE</code> then the garbage collector is called more often than it is 
usually done. This keeps the memory footprint down but it will slow down the routine.</p>
</td></tr>
<tr><td><code id="gamlss_+3A_parscale">parscale</code></td>
<td>
<p>The algorithm will operate as if optimizing objfun(x / parscale, ...) where parscale is a scalar. If missing then no 
rescaling is done. See the 
documentation of <code>trust</code> for more details.</p>
</td></tr>    
<tr><td><code id="gamlss_+3A_extra.regi">extra.regI</code></td>
<td>
<p>If &quot;t&quot; then regularization as from <code>trust</code> is applied to the information matrix if needed. 
If different from &quot;t&quot; then extra regularization is applied via the options &quot;pC&quot; (pivoted Choleski - this
will only work when the information matrix is semi-positive or positive definite) and &quot;sED&quot; (symmetric eigen-decomposition).</p>
</td></tr>  
<tr><td><code id="gamlss_+3A_gev.par">gev.par</code></td>
<td>
<p>GEV link parameter.</p>
</td></tr>
<tr><td><code id="gamlss_+3A_chunk.size">chunk.size</code></td>
<td>
<p>This is used for discrete robust models.</p>
</td></tr>  
<tr><td><code id="gamlss_+3A_k.tvc">k.tvc</code></td>
<td>
<p>Experimental. Only used for tvc ps smoothers when using survival models.</p>
</td></tr>  
<tr><td><code id="gamlss_+3A_knots">knots</code></td>
<td>
<p>Optional list containing user specified knot values to be used for basis construction.</p>
</td></tr>
<tr><td><code id="gamlss_+3A_informative">informative</code></td>
<td>
<p>If &quot;yes&quot; then informative censoring is assumed when using a survival model.</p>
</td></tr>
<tr><td><code id="gamlss_+3A_inform.cov">inform.cov</code></td>
<td>
<p>If above is &quot;yes&quot; then a set of informative covariates must be provided.</p>
</td></tr>
<tr><td><code id="gamlss_+3A_margin2">margin2</code></td>
<td>
<p>In the informative survival case, the margin for the censored equation can be different from that of the survival equation.</p>
</td></tr>
<tr><td><code id="gamlss_+3A_fp">fp</code></td>
<td>
<p>If <code>TRUE</code> then a fully parametric model with unpenalised regression splines if fitted.</p>
</td></tr>              
<tr><td><code id="gamlss_+3A_sp">sp</code></td>
<td>
<p>A vector of smoothing parameters can be provided here. Smoothing parameters must be supplied in the order that the smooth 
terms appear in the model equation(s).</p>
</td></tr>  
<tr><td><code id="gamlss_+3A_drop.unused.levels">drop.unused.levels</code></td>
<td>
<p>By default unused levels are dropped from factors before fitting. For some smooths involving factor variables 
this may have to be turned off (only use if you know what you are doing).</p>
</td></tr>  
<tr><td><code id="gamlss_+3A_siginit">siginit</code>, <code id="gamlss_+3A_shinit">shinit</code></td>
<td>
<p>For the GP and DGP distributions, initial values for sigma and shape may be provided.</p>
</td></tr>
<tr><td><code id="gamlss_+3A_sp.method">sp.method</code></td>
<td>
<p>Multiple smoothing automatic parameter selection is perf. efs is an alternative and only sensible option
for robust models.</p>
</td></tr>
<tr><td><code id="gamlss_+3A_hrate">hrate</code></td>
<td>
<p>Vector of population hazard rates computed at time of death of each uncensored patient. The length of <code>hrate</code> should be equal to the number of uncensored observations in the dataset. Needed in the context of excess hazard modelling when uncensored observations are present. Note that this includes left truncated uncensored observations as well.</p>
</td></tr>          
<tr><td><code id="gamlss_+3A_d.lchrate">d.lchrate</code></td>
<td>
<p>Vector of differences of population cumulative excess hazards computed at the age of the patient when the left 
censoring occurred and at the initial age of the patient. The length of <code>d.lchrate</code> should be equal to the number 
of left and/or interval censored observations in the dataset. Needed in the context of excess hazard modelling 
if left censored and/or interval censored observations are present. In the latter case, <code>d.rchrate</code> also need be provided.</p>
</td></tr>
<tr><td><code id="gamlss_+3A_d.rchrate">d.rchrate</code></td>
<td>
<p>Vector of differences of population cumulative excess hazards computed at the age of the patient when the at the right 
interval censoring time and at the initial age of the patient. The length of <code>d.rchrate</code> should be equal to the number 
of right censored and/or interval censored observations in the dataset. Needed in the context of excess hazard modelling 
if right censored and/or interval censored observations are present. In the latter case, <code>d.lchrate</code> also need be provided.</p>
</td></tr>
<tr><td><code id="gamlss_+3A_d.lchrate.td">d.lchrate.td</code></td>
<td>
<p>Vector of differences of population cumulative excess hazards computed at the age of the patient when the left 
censoring occurred and at the age of the patient when the truncation occurred. The length of <code>d.lchrate.td</code> should be 
equal to the number of left truncated left censored and/or left truncated interval censored observations in 
the dataset. Needed in the context of excess hazard modelling if left truncated left censored and/or left truncated 
interval censored observations are present. In the latter case, <code>d.rchrate.td</code> also need be provided.</p>
</td></tr>
<tr><td><code id="gamlss_+3A_d.rchrate.td">d.rchrate.td</code></td>
<td>
<p>Vector of differences of population cumulative excess hazards computed at the age of the patient when the right 
censoring occurred and at the age of the patient when the truncation occurred. The length of <code>d.rchrate.td</code> should be 
equal to the number of left truncated right censored and/or left truncated interval censored observations in the dataset. Needed in 
the context of excess hazard modelling if left truncated right censored and/or left truncated interval censored 
observations are present. In the latter case, <code>d.lchrate.td</code> also need be provided.</p>
</td></tr>
<tr><td><code id="gamlss_+3A_truncation.time">truncation.time</code></td>
<td>
<p>Variable name of truncation time.</p>
</td></tr>
<tr><td><code id="gamlss_+3A_min.dn">min.dn</code>, <code id="gamlss_+3A_min.pr">min.pr</code>, <code id="gamlss_+3A_max.pr">max.pr</code></td>
<td>
<p>These values are used to set, depending on the model used for modelling, the minimum and maximum allowed 
for the densities and probabilities. These
parameters are employed to avoid potential overflows/underflows in the calculations and the default 
values seem to offer a good compromise. Function <code>conv.check()</code> provides some relevant  
diagnostic information which can be used, for example, to check whether the lower bounds 
of <code>min.dn</code> and <code>min.pr</code> have been reached. So based on this or if the user wishes to do some sensitivity 
analysis then this can be easily carried out using these three arguments.
However, the user has to be cautious. For instance, it would not make much sense to choose for <code>min.dn</code> and <code>min.pr</code> 
values bigger than the default ones. Bear in mind that the bounds can be reached for ill-defined models. For 
certain distributions/models, if convergence failure occurs and the bounds have been reached then the user
can try a sensitivity analysis as mentioned above.</p>
</td></tr>
<tr><td><code id="gamlss_+3A_ygrid.tol">ygrid.tol</code></td>
<td>
<p>Tolerance used to choose grid of response values for robust discrete models. Values smaller than 1e-160 are not allowed for.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The underlying algorithm is described in ?gjrm. 
</p>
<p>There are many continuous/discrete/survival distributions to choose from and we plan to include more 
options. Get in touch if you are interested in a particular distribution.
</p>
<p>The <code>"GEVlink"</code> option is used for binary response additive models and is more stable and faster than the <code>R</code> package <code>bgeva</code>.
This model has been incorporated into this package to take advantage of the richer set of smoother choices, and of the 
estimation approach. Details on the model can be found in Calabrese, Marra and Osmetti (2016). 
</p>


<h3>Value</h3>

<p>The function returns an object of class <code>gamlss</code> as described in <code>gamlssObject</code>.
</p>


<h3>WARNINGS</h3>

<p>Convergence can be checked using <code><a href="#topic+conv.check">conv.check</a></code> which provides some 
information about 
the score and information matrix associated with the fitted model. The former should be close to 0 and the latter positive definite.
<code>gamlss()</code> will produce some warnings if there is a convergence issue.
</p>
<p>Convergence failure may sometimes occur. This is not necessarily a bad thing as it may indicate specific problems 
with a fitted model. In such a situation, the user may use some extra regularisation (see <code>extra.regI</code>) and/or
rescaling (see <code>parscale</code>). However, the user should especially consider
re-specifying/simplifying the model, and/or checking that the chosen distribution fits the response well.
In our experience, we found that convergence failure typically occurs 
when the model has been misspecified and/or the sample size is low compared to the complexity of the model. 
It is also worth bearing in mind that the use of three parameter distributions requires the data
to be more informative than a situation in which two parameter distributions are used instead.
</p>


<h3>Author(s)</h3>

<p>Maintainer: Giampiero Marra <a href="mailto:giampiero.marra@ucl.ac.uk">giampiero.marra@ucl.ac.uk</a>
</p>


<h3>References</h3>

<p>Aeberhard W.H., Cantoni E., Marra G., Radice R. (2021), Robust Fitting for Generalized Additive Models for Location, Scale and Shape. <em>Statistics and Computing</em>, 31(11), 1-16.
</p>
<p>Eletti A., Marra G., Quaresma M., Radice R., Rubio F.J. (2022), A Unifying Framework for Flexible Excess Hazard Modeling with Applications in Cancer Epidemiology. <em>Journal of the Royal Statistical Society Series C</em>, 71(4), 1044-1062.
</p>
<p>Marra G., Farcomeni A., Radice R. (2021), Link-Based Survival Additive Models under Mixed Censoring to Assess Risks of Hospital-Acquired Infections. <em>Computational Statistics and Data Analysis</em>, 155, 107092.
</p>
<p>Marra G., Radice R. (2017), Bivariate Copula Additive Models for Location, Scale and Shape. <em>Computational Statistics and Data Analysis</em>, 112, 99-113.
</p>
<p>Ranjbar S., Cantoni E., Chavez-Demoulin V., Marra G., Radice R., Jaton-Ogay K. (2022), Modelling the Extremes of Seasonal Viruses and Hospital Congestion: The Example of Flu in a Swiss Hospital. <em>Journal of the Royal Statistical Society Series C</em>, 71(4), 884-905.
</p>
<p>Rigby R.A., Stasinopoulos D.M. (2005). Generalized additive models for location, scale and shape (with discussion). <em>Journal of the Royal Statistical Society, Series C</em>, 54(3), 507-554.
</p>
<p>Calabrese R., Marra G., Osmetti SA (2016), Bankruptcy Prediction of Small and Medium Enterprises Using a Flexible Binary Generalized Extreme Value Model. <em>Journal of the Operational Research Society</em>, 67(4), 604-615.
</p>
<p>Marincioni V., Marra G., Altamirano-Medina H. (2018), Development of Predictive Models for the Probabilistic Moisture Risk Assessment of Internal Wall Insulation. <em>Building and Environment</em>, 137, 5257-267. 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+GJRM-package">GJRM-package</a></code>, <code><a href="#topic+gamlssObject">gamlssObject</a></code>, <code><a href="#topic+conv.check">conv.check</a></code>, <code><a href="#topic+summary.gamlss">summary.gamlss</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run:  

library(GJRM)

set.seed(0)

n &lt;- 400

x1 &lt;- round(runif(n))
x2 &lt;- runif(n)
x3 &lt;- runif(n)
f1 &lt;- function(x) cos(pi*2*x) + sin(pi*x)
y1 &lt;- -1.55 + 2*x1 + f1(x2) + rnorm(n)

dataSim &lt;- data.frame(y1, x1, x2, x3)
resp.check(y1, "N")

eq.mu &lt;- y1 ~ x1 + s(x2) + s(x3)
eq.s  &lt;-    ~ s(x3)
fl    &lt;- list(eq.mu, eq.s)

out &lt;- gamlss(fl, data = dataSim)

conv.check(out)
post.check(out)

plot(out, eq = 1, scale = 0, pages = 1, seWithMean = TRUE)
plot(out, eq = 2, seWithMean = TRUE)

summary(out)

AIC(out)
BIC(out)

################
# Robust example
################

eq.mu &lt;- y1 ~ x1 + x2 + x3
fl    &lt;- list(eq.mu)

out &lt;- gamlss(fl, data = dataSim, margin = "N", robust = TRUE, 
                  rc = 3, lB = -Inf, uB = Inf)

conv.check(out)
summary(out)
rob.const(out, 100)

##

eq.s  &lt;-    ~ x3
fl    &lt;- list(eq.mu, eq.s)

out &lt;- gamlss(fl, data = dataSim, margin = "N", robust = TRUE)

conv.check(out)
summary(out)

##

eq.mu &lt;- y1 ~ x1 + s(x2) + s(x3)
eq.s  &lt;-    ~ s(x3)
fl    &lt;- list(eq.mu, eq.s)

out1 &lt;- gamlss(fl, data = dataSim, margin = "N", robust = TRUE, 
               sp.method = "efs")

conv.check(out1)
summary(out1)
AIC(out, out1)

plot(out1, eq = 1, all.terms = TRUE, pages = 1, seWithMean = TRUE)
plot(out1, eq = 2, seWithMean = TRUE)

##########################
## GEV link binary example
##########################
# this incorporates the bgeva
# model implemented in the bgeva package
# however this implementation is more general 
# stable and efficient

set.seed(0)

n &lt;- 400

x1 &lt;- round(runif(n)); x2 &lt;- runif(n); x3 &lt;- runif(n)

f1 &lt;- function(x) cos(pi*2*x) + sin(pi*x)
f2 &lt;- function(x) x+exp(-30*(x-0.5)^2)   

y  &lt;- ifelse(-3.55 + 2*x1 + f1(x2) + rnorm(n) &gt; 0, 1, 0)

dataSim &lt;- data.frame(y, x1, x2, x3)

out1 &lt;- gamlss(list(y ~ x1 + x2 + x3), margin = "GEVlink", data = dataSim)
out2 &lt;- gamlss(list(y ~ x1 + s(x2) + s(x3)), margin = "GEVlink", data = dataSim)

conv.check(out1)
conv.check(out2)
summary(out1)
summary(out2)
AIC(out1, out2)
BIC(out1, out2)

plot(out2, eq = 1, all.terms = TRUE, pages = 1, seWithMean = TRUE)

##################
# prediction of Pr
##################

# Calculate eta (that is, X*model.coef)
# For a new data set the argument newdata should be used

eta &lt;- predict(out2, eq = 1, type = "link")

# extract gev tail parameter

gev.par &lt;- out2$gev.par

# multiply gev tail parameter by eta

gevpeta &lt;- gev.par*eta 
  
# establish for which values the model is defined   

gevpetaIND &lt;- ifelse(gevpeta &lt; -1, FALSE, TRUE) 
gevpeta &lt;- gevpeta[gevpetaIND]
    
# estimate probabilities  

pr &lt;- exp(-(1 + gevpeta)^(-1/gev.par))

###################################
## Flexible survival model examples
###################################

library(GJRM)

########################################
## Simulate proportional hazards data ##
########################################

set.seed(0)
n  &lt;- 2000
c  &lt;- runif(n, 3, 8)
u  &lt;- runif(n, 0, 1)
z1 &lt;- rbinom(n, 1, 0.5)
z2 &lt;- runif(n, 0, 1)
t  &lt;- rep(NA, n)

beta_0 &lt;- -0.2357
beta_1 &lt;- 1

f &lt;- function(t, beta_0, beta_1, u, z1, z2){ 
  S_0 &lt;- 0.7 * exp(-0.03*t^1.9) + 0.3*exp(-0.3*t^2.5)
  exp(-exp(log(-log(S_0))+beta_0*z1 + beta_1*z2))-u
}


for (i in 1:n){
   t[i] &lt;- uniroot(f, c(0, 8), tol = .Machine$double.eps^0.5, 
                   beta_0 = beta_0, beta_1 = beta_1, u = u[i], 
                   z1 = z1[i], z2 = z2[i], extendInt = "yes" )$root
}

delta   &lt;- ifelse(t &lt; c, 1, 0)
u       &lt;- apply(cbind(t, c), 1, min)
dataSim &lt;- data.frame(u, delta, z1, z2)
1-mean(delta) # average censoring rate

# log(u) helps obtaining smoother hazards

out &lt;- gamlss(list(u ~ s(log(u), bs = "mpi") + z1 + s(z2) ), data = dataSim, 
              surv = TRUE, margin = "PH", cens = delta)
post.check(out)
summary(out)
AIC(out)
BIC(out)
plot(out, eq = 1, scale = 0, pages = 1)
hazsurv(out, newdata = data.frame(z1 = 0, z2 = 0), shade = TRUE, 
        n.sim = 1000, baseline = TRUE)
hazsurv(out, type = "hazard", newdata = data.frame(z1 = 0, z2 = 0), 
        shade = TRUE, n.sim = 1000, baseline = TRUE)

out1 &lt;- gam(u ~ z1 + s(z2), family = cox.ph(), 
            data = dataSim, weights = delta)
summary(out1)
# estimates of z1 and s(z2) are
# nearly identical between out and out1 

# note that the Weibull is implemented as AFT
# as using the PH parametrisation makes
# computation unstable
out2 &lt;- gamlss(list(u ~ z1 + s(z2) ), data = dataSim, surv = TRUE, 
               margin = "WEI", cens = delta)
 
#####################################
## Simulate proportional odds data ##
#####################################

set.seed(0)

n &lt;- 2000
c &lt;- runif(n, 4, 8)
u &lt;- runif(n, 0, 1)
z &lt;- rbinom(n, 1, 0.5)
beta_0 &lt;- -1.05
t &lt;- rep(NA, n)

f &lt;- function(t, beta_0, u, z){ 
  S_0 &lt;- 0.7 * exp(-0.03*t^1.9) + 0.3*exp(-0.3*t^2.5)
  1/(1 + exp(log((1-S_0)/S_0)+beta_0*z))-u
}



for (i in 1:n){
    t[i] &lt;- uniroot(f, c(0, 8), tol = .Machine$double.eps^0.5, 
                    beta_0 = beta_0, u = u[i], z = z[i], 
                    extendInt="yes" )$root
}

delta   &lt;- ifelse(t &lt; c,1, 0)
u       &lt;- apply(cbind(t, c), 1, min)
dataSim &lt;- data.frame(u, delta, z)
1-mean(delta) # average censoring rate

out &lt;- gamlss(list(u ~ s(log(u), bs = "mpi") + z ), data = dataSim, surv = TRUE, 
              margin = "PO", cens = delta)
post.check(out)
summary(out)
AIC(out)
BIC(out)
plot(out, eq = 1, scale = 0)
hazsurv(out, newdata = data.frame(z = 0), shade = TRUE, n.sim = 1000,
        baseline = TRUE)
hazsurv(out, type = "hazard", newdata = data.frame(z = 0), 
        shade = TRUE, n.sim = 1000)
             
                          
#############################
## Mixed censoring example ##
#############################             
             
f1 &lt;- function(t, u, z1, z2, z3, z4, s1, s2){ 

    S_0 &lt;- 0.7 * exp(-0.03*t^1.8) + 0.3*exp(-0.3*t^2.5)
   
    exp( -exp(log(-log(S_0)) + 1.3*z1 + 0.5*z2 + s1(z3) + s2(z4)  ) ) - u   
            
  }
  
   
datagen &lt;- function(n, z1, z2, z3, z4, s1, s2, f1){
  
  u &lt;- runif(n, 0, 1)
  t &lt;- rep(NA, n)
  
  for (i in 1:n) t[i] &lt;- uniroot(f1, c(0, 100), tol = .Machine$double.eps^0.5, 
                                 u = u[i], s1 = s1, s2 = s2, z1 = z1[i], z2 = z2[i], 
                                 z3 = z3[i], z4 = z4[i], extendInt = "yes")$root
 
  c1 &lt;-      runif(n, 0, 2)
  c2 &lt;- c1 + runif(n, 0, 6) 
  
  df &lt;- data.frame(u1 = t, u2 = t, cens = character(n), stringsAsFactors = FALSE)

for (i in 1:n){

  if(t[i] &lt;= c1[i]) {
        df[i, 1] &lt;- c1[i]
        df[i, 2] &lt;- NA
        df[i, 3] &lt;- "L"
       
  }else if(c1[i] &lt; t[i] &amp;&amp; t[i] &lt;= c2[i]){
        df[i, 1] &lt;- c1[i]
        df[i, 2] &lt;- c2[i]
        df[i, 3] &lt;- "I"
        
  }else if(t[i] &gt; c2[i]){
        df[i, 1] &lt;- c2[i]
        df[i, 2] &lt;- NA
        df[i, 3] &lt;- "R"}

}

uncens &lt;- (df[, 3] %in% c("L", "I")) + (rbinom(n, 1, 0.2) == 1) == 2 

df[uncens, 1] &lt;- t[uncens]
df[uncens, 2] &lt;- NA
df[uncens, 3] &lt;- "U"

dataSim &lt;- data.frame(u1 = df$u1, u2 = df$u2, cens = as.factor(df$cens), z1, z2, z3, z4, t)
dataSim
  
}

set.seed(0)

n      &lt;- 1000
SigmaC &lt;- matrix(0.5, 4, 4); diag(SigmaC) &lt;- 1
cov    &lt;- rMVN(n, rep(0,4), SigmaC)
cov    &lt;- pnorm(cov)
z1     &lt;- round(cov[, 1])
z2     &lt;- round(cov[, 2])
z3     &lt;- cov[, 3]
z4     &lt;- cov[, 4]
s1     &lt;- function(x) -0.075*exp(3.2 * x) 
s2     &lt;- function(x) sin(2*pi*x) 
 
eq1    &lt;- u1 ~ s(log(u1), bs = "mpi") + z1 + z2 + s(z3) + s(z4)

dataSim &lt;- datagen(n, z1, z2, z3, z4, s1, s2, f1)

out &lt;- gamlss(list(eq1), data = dataSim, surv = TRUE, margin = "PH", 
              cens = cens, type.cen = "mixed", upperB = "u2")

conv.check(out)
summary(out)
plot(out, eq = 1, scale = 0, pages = 1)             
  
ndf &lt;- data.frame(z1 = 1, z2 = 0, z3 = 0.2, z4 = 0.5)

hazsurv(out, eq = 1, newdata = ndf, type = "surv")
hazsurv(out, eq = 1, newdata = ndf, type = "hazard", n.sim = 1000)         

## End(Not run)

</code></pre>

<hr>
<h2 id='gamlssObject'>Fitted gamlssObject object</h2><span id='topic+gamlssObject'></span>

<h3>Description</h3>

<p>A fitted gamlss object returned by function <code>gamlss</code> and of class &quot;gamlss&quot; and &quot;SemiParBIV&quot;.</p>


<h3>Value</h3>

 
<table>
<tr><td><code>fit</code></td>
<td>
<p>List of values and diagnostics extracted from the output of the algorithm.</p>
</td></tr>
<tr><td><code>gam1</code>, <code>gam2</code>, <code>gam3</code></td>
<td>
<p>Univariate starting values' fits.</p>
</td></tr>
<tr><td><code>coefficients</code></td>
<td>
<p>The coefficients of the fitted model.</p>
</td></tr>
<tr><td><code>weights</code></td>
<td>
<p>Prior weights used during model fitting.</p>
</td></tr>
<tr><td><code>sp</code></td>
<td>
<p>Estimated smoothing parameters of the smooth components.</p>
</td></tr>
<tr><td><code>iter.sp</code></td>
<td>
<p>Number of iterations performed for the smoothing parameter estimation step.</p>
</td></tr>
<tr><td><code>iter.if</code></td>
<td>
<p>Number of iterations performed in the initial step of the algorithm.</p>
</td></tr>
<tr><td><code>iter.inner</code></td>
<td>
<p>Number of iterations performed within the smoothing parameter estimation step.</p>
</td></tr>
<tr><td><code>n</code></td>
<td>
<p>Sample size.</p>
</td></tr>
<tr><td><code>X1</code>, <code>X2</code>, <code>X3</code>, <code>...</code></td>
<td>
<p>Design matrices associated with the linear predictors.</p>
</td></tr>
<tr><td><code>X1.d2</code>, <code>X2.d2</code>, <code>X3.d2</code>, <code>...</code></td>
<td>
<p>Number of columns of <code>X1</code>, <code>X2</code>, <code>X3</code>, etc.</p>
</td></tr>
<tr><td><code>l.sp1</code>, <code>l.sp2</code>, <code>l.sp3</code>, <code>...</code></td>
<td>
<p>Number of smooth components in the equations.</p>
</td></tr>
<tr><td><code>He</code></td>
<td>
<p>Penalized -hessian/Fisher. This is the same as <code>HeSh</code> for unpenalized models.</p>
</td></tr>
<tr><td><code>HeSh</code></td>
<td>
<p>Unpenalized -hessian/Fisher.</p>
</td></tr>
<tr><td><code>Vb</code></td>
<td>
<p>Inverse of <code>He</code>. This corresponds to the Bayesian variance-covariance matrix 
used for confidence/credible interval calculations.</p>
</td></tr>
<tr><td><code>F</code></td>
<td>
<p>This is obtained multiplying Vb by HeSh.</p>
</td></tr>  
<tr><td><code>t.edf</code></td>
<td>
<p>Total degrees of freedom of the estimated bivariate model. It is calculated as <code>sum(diag(F))</code>.</p>
</td></tr>
<tr><td><code>edf1</code>, <code>edf2</code>, <code>edf3</code>, <code>...</code></td>
<td>
<p>Degrees of freedom for the model's equations.</p>
</td></tr>
<tr><td><code>wor.c</code></td>
<td>
<p>Working model quantities.</p>
</td></tr>                
<tr><td><code>eta1</code>, <code>eta2</code>, <code>eta3</code>, <code>...</code></td>
<td>
<p>Estimated linear predictors.</p>
</td></tr>
<tr><td><code>y1</code></td>
<td>
<p>Response.</p>
</td></tr>
<tr><td><code>logLik</code></td>
<td>
<p>Value of the (unpenalized) log-likelihood evaluated at the (penalized or unpenalized) parameter 
estimates.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Maintainer: Giampiero Marra <a href="mailto:giampiero.marra@ucl.ac.uk">giampiero.marra@ucl.ac.uk</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gamlss">gamlss</a></code>, <code><a href="#topic+summary.gamlss">summary.gamlss</a></code>
</p>

<hr>
<h2 id='ggmtrust'>ggmtrust for penalised network</h2><span id='topic+ggmtrust'></span>

<h3>Description</h3>

 
<p>penalised network, work in progress.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
ggmtrust(s, n, data = NULL, lambda = 1, pen = "lasso", params = NULL, method = "BHHH", 
         w.alasso = NULL, gamma = 1, a = 3.7)
        
        
        
        
</code></pre>


<h3>Arguments</h3>

 
<table>
<tr><td><code id="ggmtrust_+3A_s">s</code></td>
<td>
<p>Sample covariance matrix.</p>
</td></tr> 
<tr><td><code id="ggmtrust_+3A_n">n</code></td>
<td>
<p>Sample size.</p>
</td></tr> 
<tr><td><code id="ggmtrust_+3A_data">data</code></td>
<td>
<p>Data.</p>
</td></tr> 
<tr><td><code id="ggmtrust_+3A_lambda">lambda</code></td>
<td>
<p>Regularisation parameter.</p>
</td></tr> 
<tr><td><code id="ggmtrust_+3A_pen">pen</code></td>
<td>
<p>Either &quot;lasso&quot; or &quot;ridge&quot;.</p>
</td></tr>
<tr><td><code id="ggmtrust_+3A_params">params</code></td>
<td>
<p>If different from null then these are taken as the starting values.</p>
</td></tr>
<tr><td><code id="ggmtrust_+3A_method">method</code></td>
<td>
<p>Either &quot;H&quot; or &quot;BHHH&quot;.</p>
</td></tr>
<tr><td><code id="ggmtrust_+3A_w.alasso">w.alasso</code></td>
<td>
<p>weight for alasso.</p>
</td></tr>
<tr><td><code id="ggmtrust_+3A_gamma">gamma</code></td>
<td>
<p>alasso param.</p>
</td></tr>
<tr><td><code id="ggmtrust_+3A_a">a</code></td>
<td>
<p>scad param.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>penalised network, work in progress.
</p>


<h3>Value</h3>

<p>The function returns an object of class <code>ggmtrust</code>.
</p>

<hr>
<h2 id='gjrm'>Generalised Joint Regression Models with Binary/Continuous/Discrete/Survival Margins</h2><span id='topic+gjrm'></span>

<h3>Description</h3>

 
<p><code>gjrm</code> fits flexible joint models with binary/continuous/discrete/survival margins, with several types of covariate 
effects, copula and marginal distributions. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gjrm(formula, data = list(), weights = NULL, subset = NULL,  
     copula = "N", copula2 = "N", margins, model, dof = 3, dof2 = 3, ordinal = FALSE,  
     surv = FALSE, cens1 = NULL, cens2 = NULL, cens3 = NULL, dep.cens = FALSE,
     upperBt1 = NULL, upperBt2 = NULL,   
     gamlssfit = FALSE, fp = FALSE, infl.fac = 1, 
     rinit = 1, rmax = 100, 
     iterlimsp = 50, tolsp = 1e-07,
     gc.l = FALSE, parscale, extra.regI = "t",
     k1.tvc = 0, k2.tvc = 0, knots = NULL,
     penCor = "unpen", sp.penCor = 3, 
     Chol = FALSE, gamma = 1, w.alasso = NULL,
     drop.unused.levels = TRUE, 
     min.dn = 1e-40, min.pr = 1e-16, max.pr = 0.999999)
</code></pre>


<h3>Arguments</h3>

 
<table>
<tr><td><code id="gjrm_+3A_formula">formula</code></td>
<td>
<p>In the basic setup this will be a list of two (or three) formulas, one for equation 1, the other for equation 2 and another one
for equation 3 if a trivariate model is fitted to the data. Otherwise, more equations can be used depending on the 
number of distributional parameters. <code>s</code> terms 
are used to specify smooth functions of 
predictors; see the documentation of <code>mgcv</code> for further 
details on formula specifications. Note that if a selection model is employed (that is, <code>model = "BSS"</code>
or <code>model = "TSS"</code>) then the first formula (and the second as well for trivariate models) MUST refer to the selection equation(s).
When one outcome is binary and the other continuous/discrete 
then the first equation should refer to the binary outcome whereas 
the second to the continuous/discrete one. When one outcome is discrete and the other continuous 
then the first equation has to be the discrete one.</p>
</td></tr> 
<tr><td><code id="gjrm_+3A_data">data</code></td>
<td>
<p>An optional data frame, list or environment containing the variables in the model.  If not found in <code>data</code>, the
variables are taken from <code>environment(formula)</code>, typically the environment from which <code>gjrm</code> is called.</p>
</td></tr> 
<tr><td><code id="gjrm_+3A_weights">weights</code></td>
<td>
<p>Optional vector of prior weights to be used in fitting.</p>
</td></tr> 
<tr><td><code id="gjrm_+3A_subset">subset</code></td>
<td>
<p>Optional vector specifying a subset of observations to be used in the fitting process.</p>
</td></tr>
<tr><td><code id="gjrm_+3A_copula">copula</code></td>
<td>
<p>Type of bivariate error distribution employed. Possible choices are &quot;N&quot;, &quot;C0&quot;, &quot;C90&quot;, &quot;C180&quot;, &quot;C270&quot;, &quot;GAL0&quot;, &quot;GAL90&quot;, &quot;GAL180&quot;, &quot;GAL270&quot;, &quot;J0&quot;, &quot;J90&quot;, &quot;J180&quot;, &quot;J270&quot;, 
&quot;G0&quot;, &quot;G90&quot;, &quot;G180&quot;, &quot;G270&quot;, &quot;F&quot;, &quot;AMH&quot;, &quot;FGM&quot;, &quot;T&quot;, &quot;PL&quot;, &quot;HO&quot; which stand for bivariate normal, Clayton, rotated Clayton (90 degrees), 
survival Clayton,
rotated Clayton (270 degrees), Galambos, rotated Galambos (90 degrees), 
survival Galambos,
rotated Galambos (270 degrees), Joe, rotated Joe (90 degrees), survival Joe, rotated Joe (270 degrees),
Gumbel, rotated Gumbel (90 degrees), survival Gumbel, rotated Gumbel (270 degrees), Frank, Ali-Mikhail-Haq,
Farlie-Gumbel-Morgenstern, Student-t with <code>dof</code>, Plackett, Hougaard. Each of the Clayton, Galambos, Joe and Gumbel copulae is allowed to be mixed with a rotated version of the same
family. The options are: &quot;C0C90&quot;, &quot;C0C270&quot;, &quot;C180C90&quot;, &quot;C180C270&quot;,  &quot;GAL0GAL90&quot;, &quot;GAL0GAL270&quot;, &quot;GAL180GAL90&quot;, &quot;GAL180GAL270&quot;, &quot;G0G90&quot;, &quot;G0G270&quot;, &quot;G180G90&quot;,
&quot;G180G270&quot;, &quot;J0J90&quot;, &quot;J0J270&quot;, &quot;J180J90&quot; and &quot;J180J270&quot;. This allows the user to model negative and positive tail dependencies.</p>
</td></tr>  
<tr><td><code id="gjrm_+3A_copula2">copula2</code></td>
<td>
<p>As above but used only for Roy models.</p>
</td></tr>
<tr><td><code id="gjrm_+3A_margins">margins</code></td>
<td>
<p>It indicates the distributions used for the two or three margins. Possible distributions are normal (&quot;N&quot;), Tweedie (&quot;TW&quot;), 
log-normal (&quot;LN&quot;), Gumbel (&quot;GU&quot;), reverse Gumbel (&quot;rGU&quot;), generelised Pareto (&quot;GP&quot;), 
generelised Pareto II (&quot;GPII&quot;) where the shape parameter is forced to be &gt; -0.5,
generelised Pareto (with orthogonal parametrisation) (&quot;GPo&quot;) where the shape parameter is forced to be &gt; -0.5,
discrete generelised Pareto (&quot;DGP&quot;), 
discrete generelised Pareto II (&quot;DGPII&quot;) where the shape parameter is forced to be positive, discrete generelised Pareto derived
under the scenario in which shape = 0 (&quot;DGP0&quot;), logistic (&quot;LO&quot;), Weibull (&quot;WEI&quot;), inverse Gaussian (&quot;iG&quot;), gamma (&quot;GA&quot;), Dagum (&quot;DAGUM&quot;), 
Singh-Maddala (&quot;SM&quot;), beta (&quot;BE&quot;), Fisk (&quot;FISK&quot;, also known as log-logistic distribution), Poisson (&quot;PO&quot;), zero truncated 
Poisson (&quot;ZTP&quot;), negative binomial - type I (&quot;NBI&quot;), negative 
binomial - type II (&quot;NBII&quot;), Poisson inverse Gaussian (&quot;PIG&quot;). If the responses are binary then
possible link functions are &quot;probit&quot;, &quot;logit&quot;, &quot;cloglog&quot;. For survival models, the margins can be proportional hazars (&quot;PH&quot;), odds (&quot;PO&quot;)
or &quot;probit&quot;.</p>
</td></tr>
<tr><td><code id="gjrm_+3A_model">model</code></td>
<td>
<p>Possible values are &quot;B&quot; (bivariate model), &quot;T&quot; (trivariate model) 
&quot;BSS&quot; (bivariate model with non-random sample selection), &quot;TSS&quot; (trivariate model with double non-random sample selection),
&quot;TESS&quot; (trivariate model with endogeneity and non-random sample selection),
&quot;BPO&quot; (bivariate model with partial observability)
and &quot;BPO0&quot; (bivariate model with partial observability and zero correlation).
Options &quot;T&quot;, &quot;TESS&quot; and &quot;TSS&quot; are currently for trivariate binary models only. &quot;BPO&quot; and &quot;BPO0&quot; are for bivariate binary models only.    
&quot;ROY&quot; is for the Roy switching regression model.
</p>
</td></tr> 
<tr><td><code id="gjrm_+3A_dof">dof</code></td>
<td>
<p>If <code>copula = "T"</code> then the degrees of freedom can be set to a value greater than 2 and smaller than 249. Only for continuous margins,
this will be taken as a starting value and the dof estimated from the data.</p>
</td></tr>   
<tr><td><code id="gjrm_+3A_dof2">dof2</code></td>
<td>
<p>As above but used only for Roy models.</p>
</td></tr> 
<tr><td><code id="gjrm_+3A_ordinal">ordinal</code></td>
<td>
<p>If <code>TRUE</code> then the ordinal model is employed.</p>
</td></tr>    
<tr><td><code id="gjrm_+3A_surv">surv</code></td>
<td>
<p>If <code>TRUE</code> then a bivariate survival model is fitted.</p>
</td></tr>    
<tr><td><code id="gjrm_+3A_cens1">cens1</code></td>
<td>
<p>Censoring indicator for the first equation. This is required when <code>surv = TRUE</code>. For the case of right censored data only, this variable can be equal to 1 if the event occurred 
and 0 otherwise. However, if there are several censoring mechanisms then <code>cens</code> will have to be specified as a factor 
variable made up of four possible categories: <code>I</code> for interval, <code>L</code> for left, <code>R</code> for right, and <code>U</code> for uncensored.</p>
</td></tr>
<tr><td><code id="gjrm_+3A_cens2">cens2</code></td>
<td>
<p>Same as above but for the second equation.</p>
</td></tr>
<tr><td><code id="gjrm_+3A_cens3">cens3</code></td>
<td>
<p>Binary censoring indicator employed only when <code>surv = TRUE</code>, <code>dep.cens = TRUE</code> and administrative censoring is present.</p>
</td></tr>
<tr><td><code id="gjrm_+3A_dep.cens">dep.cens</code></td>
<td>
<p>If TRUE then the dependence censored model is employed.</p>
</td></tr> 
<tr><td><code id="gjrm_+3A_upperbt1">upperBt1</code>, <code id="gjrm_+3A_upperbt2">upperBt2</code></td>
<td>
<p>Variable names of right/upper bounds when interval censoring is present.</p>
</td></tr>
<tr><td><code id="gjrm_+3A_gamlssfit">gamlssfit</code></td>
<td>
<p>If <code>gamlssfit = TRUE</code> then gamlss univariate models are also fitted. This is useful for obtaining 
starting values, for instance.</p>
</td></tr>               
<tr><td><code id="gjrm_+3A_fp">fp</code></td>
<td>
<p>If <code>TRUE</code> then a fully parametric model with unpenalised regression splines if fitted. See the Example 2 below.</p>
</td></tr>              
<tr><td><code id="gjrm_+3A_infl.fac">infl.fac</code></td>
<td>
<p>Inflation factor for the model degrees of freedom in the approximate AIC. Smoother models can be obtained setting 
this parameter to a value greater than 1.</p>
</td></tr>
<tr><td><code id="gjrm_+3A_rinit">rinit</code></td>
<td>
<p>Starting trust region radius. The trust region radius is adjusted as the algorithm proceeds. See the documentation
of <code>trust</code> for further details.</p>
</td></tr>
<tr><td><code id="gjrm_+3A_rmax">rmax</code></td>
<td>
<p>Maximum allowed trust region radius. This may be set very large. If set small, the algorithm traces a steepest 
descent path.</p>
</td></tr> 
<tr><td><code id="gjrm_+3A_iterlimsp">iterlimsp</code></td>
<td>
<p>A positive integer specifying the maximum number of loops to be performed before the smoothing parameter estimation 
step is terminated.</p>
</td></tr> 
<tr><td><code id="gjrm_+3A_tolsp">tolsp</code></td>
<td>
<p>Tolerance to use in judging convergence of the algorithm when automatic smoothing parameter estimation is used.</p>
</td></tr> 
<tr><td><code id="gjrm_+3A_gc.l">gc.l</code></td>
<td>
<p>This is relevant when working with big datasets. If <code>TRUE</code> then the garbage collector is called more often than it is 
usually done. This keeps the memory footprint down but it will slow down the routine.</p>
</td></tr>
<tr><td><code id="gjrm_+3A_parscale">parscale</code></td>
<td>
<p>The algorithm will operate as if optimizing objfun(x / parscale, ...) where parscale is a scalar. If missing then no 
rescaling is done. See the 
documentation of <code>trust</code> for more details.</p>
</td></tr>    
<tr><td><code id="gjrm_+3A_extra.regi">extra.regI</code></td>
<td>
<p>If &quot;t&quot; then regularization as from <code>trust</code> is applied to the information matrix if needed. 
If different from &quot;t&quot; then extra regularization is applied via the options &quot;pC&quot; (pivoted Choleski - this
will only work when the information matrix is semi-positive or positive definite) and &quot;sED&quot; (symmetric eigen-decomposition).</p>
</td></tr>  
<tr><td><code id="gjrm_+3A_k1.tvc">k1.tvc</code>, <code id="gjrm_+3A_k2.tvc">k2.tvc</code></td>
<td>
<p>Experimental. Only used for tvc ps smoothers when using survival models.</p>
</td></tr>  
<tr><td><code id="gjrm_+3A_knots">knots</code></td>
<td>
<p>Optional list containing user specified knot values to be used for basis construction.</p>
</td></tr>
<tr><td><code id="gjrm_+3A_pencor">penCor</code></td>
<td>
<p>This and the arguments below are only for trivariate binary models. Type of penalty for 
correlation coefficients. Possible values are &quot;unpen&quot;, &quot;lasso&quot;, &quot;ridge&quot;, &quot;alasso&quot;.</p>
</td></tr>
<tr><td><code id="gjrm_+3A_sp.pencor">sp.penCor</code></td>
<td>
<p>Starting value for smoothing parameter of <code>penCor</code>.</p>
</td></tr>
<tr><td><code id="gjrm_+3A_chol">Chol</code></td>
<td>
<p>If <code>TRUE</code> then the Cholesky method instead of the eigenvalue method is employed for the correlation matrix.</p>
</td></tr>
<tr><td><code id="gjrm_+3A_gamma">gamma</code></td>
<td>
<p>Inflation factor used only for the alasso penalty.</p>
</td></tr>
<tr><td><code id="gjrm_+3A_w.alasso">w.alasso</code></td>
<td>
<p>When using the alasso penalty a weight vector made up of three values must be provided.</p>
</td></tr> 
<tr><td><code id="gjrm_+3A_drop.unused.levels">drop.unused.levels</code></td>
<td>
<p>By default unused levels are dropped from factors before fitting. For some smooths involving factor variables 
this may have to be turned off (only use if you know what you are doing).</p>
</td></tr> 
<tr><td><code id="gjrm_+3A_min.dn">min.dn</code>, <code id="gjrm_+3A_min.pr">min.pr</code>, <code id="gjrm_+3A_max.pr">max.pr</code></td>
<td>
<p>These values are used to set, depending on the model used for modelling, the minimum and maximum allowed 
for the densities and probabilities; recall that the margins of copula models have to be in the range (0,1). These
parameters are employed to avoid potential overflows/underflows in the calculations and the default 
values seem to offer a good compromise. Function <code>conv.check()</code> provides some relevant  
diagnostic information which can be used, for example, to check whether the lower bounds 
of <code>min.dn</code> and <code>min.pr</code> have been reached. So based on this or if the user wishes to do some sensitivity 
analysis then this can be easily carried out using these three arguments.
However, the user has to be cautious. For instance, it would not make much sense to choose for <code>min.dn</code> and <code>min.pr</code> 
values bigger than the default ones. Bear in mind that the bounds can be reached for ill-defined models. For 
certain distributions/models, if convergence failure occurs and the bounds have been reached then the user
can try a sensitivity analysis as mentioned above.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The joint models considered by this function consist of two or three model equations which depend on flexible linear predictors and
whose dependence between the responses is modelled through one or more parameters of a chosen multivariate distribution. The additive predictors of the 
equations are flexibly specified using 
parametric components and smooth functions of covariates. The same can be done for the dependence parameter(s) if it makes sense.
Estimation is achieved within a penalized likelihood framework with integrated automatic multiple smoothing parameter selection. The use of 
penalty matrices allows for the suppression of that part of smooth term complexity which has no support 
from the data. The trade-off between smoothness 
and fitness is controlled by smoothing parameters associated with the penalty matrices. Smoothing parameters are chosen to 
minimise an approximate AIC.
</p>
<p>For sample selection models, if there are factors in the model then before fitting the user has to ensure 
that the numbers of factor variables' levels in the selected sample 
are the same as those in the complete dataset. Even if a model could be fitted in such a situation,
the model may produce fits which are 
not coherent with the nature of the correction sought. As an example consider the 
situation in which the complete dataset contains a factor variable with five levels and that only three of them   
appear in the selected sample. For the outcome equation (which is the one of interest) only three levels of such variable 
exist in the population, but their effects will be corrected for non-random selection using a selection equation 
in which five levels exist instead. Having differing numbers of factors' levels between complete and selected samples will also  
make prediction not feasible (an aspect which may be particularly important for selection models);
clearly it is not possible to predict the response of interest for the missing entries using a 
dataset that contains all levels of a factor variable but using an outcome model 
estimated using a subset of these levels. 
</p>
<p>There are many continuous/discrete/survival distributions and copula functions to choose from and we plan to include more 
options. Get in touch if you are interested in a particular distribution.
</p>


<h3>Value</h3>

<p>The function returns an object of class <code>gjrm</code> as described in <code>gjrmObject</code>.
</p>


<h3>WARNINGS</h3>

<p>Convergence can be checked using <code><a href="#topic+conv.check">conv.check</a></code> which provides some 
information about 
the score and information matrix associated with the fitted model. The former should be close to 0 and the latter positive definite.
<code>gjrm()</code> will produce some warnings if there is a convergence issue.
</p>
<p>Convergence failure may sometimes occur. This is not necessarily a bad thing as it may indicate specific problems 
with a fitted model.
In such a situation, the user may use some extra regularisation (see <code>extra.regI</code>) and/or
rescaling (see <code>parscale</code>). Using <code>gamlssfit = TRUE</code> is typically more effective than the first two options as
this will provide better calibrated starting values as compared to those obtained from the default starting value procedure.
The default option is, however, <code>gamlssfit = FALSE</code> only because it tends to be computationally cheaper and because the 
default procedure has typically been found to do a satisfactory job in most cases. 
(The results obtained when using 
<code>gamlssfit = FALSE</code> and <code>gamlssfit = TRUE</code> could also be compared to check if starting values make any difference.)
</p>
<p>The above suggestions may help, especially the latter option. However, the user should also consider
re-specifying/simplifying the model, and/or using a diferrent dependence structure and/or checking that the chosen marginal 
distributions fit the responses well.
In our experience, we found that convergence failure typically occurs 
when the model has been misspecified and/or the sample size is low compared to the complexity of the model. Examples
of misspecification include using a Clayton copula rotated by 90 degrees when a positive
association between the margins is present instead, using marginal distributions that do not fit
the responses, and 
employing a copula which does not accommodate the type and/or strength of
the dependence between the margins (e.g., using AMH when the association between the margins is strong). When using 
smooth functions, if the covariate's values are too sparse then convergence may be affected by this.
It is also worth bearing in mind that the use of three parameter marginal distributions requires the data
to be more informative than a situation in which two parameter distributions are used instead.
</p>
<p>In the contexts of endogeneity and non-random sample selection, extra attention is required when specifying
the dependence parameter as a function of covariates. This is because in these situations the dependence parameter mainly models the 
association between the unobserved confounders in the two equations. Therefore, this option would make sense when it 
is believed that the  
strength of the association between the unobservables in the two equations varies based on some grouping factor or across geographical 
areas, for instance. In any case, a clear rationale is typically needed in such cases.
</p>


<h3>Author(s)</h3>

<p>Maintainer: Giampiero Marra <a href="mailto:giampiero.marra@ucl.ac.uk">giampiero.marra@ucl.ac.uk</a>
</p>


<h3>References</h3>

<p>See help(&quot;GJRM-package&quot;).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+adjCov">adjCov</a></code>, <code><a href="#topic+VuongClarke">VuongClarke</a></code>, <code><a href="#topic+GJRM-package">GJRM-package</a></code>, <code><a href="#topic+gjrmObject">gjrmObject</a></code>, <code><a href="#topic+conv.check">conv.check</a></code>, <code><a href="#topic+summary.gjrm">summary.gjrm</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(GJRM)

####################################
####################################
####################################
# JOINT MODELS WITH BINARY MARGINS #
####################################
####################################
####################################

############
## Example 1
############

set.seed(0)

n &lt;- 400

Sigma &lt;- matrix(0.5, 2, 2); diag(Sigma) &lt;- 1
u     &lt;- rMVN(n, rep(0,2), Sigma)

x1 &lt;- round(runif(n)); x2 &lt;- runif(n); x3 &lt;- runif(n)

f1   &lt;- function(x) cos(pi*2*x) + sin(pi*x)
f2   &lt;- function(x) x+exp(-30*(x-0.5)^2)   

y1 &lt;- ifelse(-1.55 + 2*x1    + f1(x2) + u[,1] &gt; 0, 1, 0)
y2 &lt;- ifelse(-0.25 - 1.25*x1 + f2(x2) + u[,2] &gt; 0, 1, 0)

dataSim &lt;- data.frame(y1, y2, x1, x2, x3)

## CLASSIC BIVARIATE PROBIT

out  &lt;- gjrm(list(y1 ~ x1 + x2 + x3, 
                       y2 ~ x1 + x2 + x3), 
                       data = dataSim, 
                       margins = c("probit", "probit"),
                       model = "B")
conv.check(out)
summary(out)
AIC(out)
BIC(out)

## Not run:  


## BIVARIATE PROBIT with Splines

out  &lt;- gjrm(list(y1 ~ x1 + s(x2) + s(x3), 
                  y2 ~ x1 + s(x2) + s(x3)),  
                  data = dataSim,
                  margins = c("probit", "probit"),
                  model = "B")
conv.check(out)
summary(out)
AIC(out)


## estimated smooth function plots - red lines are true curves

x2 &lt;- sort(x2)
f1.x2 &lt;- f1(x2)[order(x2)] - mean(f1(x2))
f2.x2 &lt;- f2(x2)[order(x2)] - mean(f2(x2))
f3.x3 &lt;- rep(0, length(x3))

par(mfrow=c(2,2),mar=c(4.5,4.5,2,2))
plot(out, eq = 1, select = 1, seWithMean = TRUE, scale = 0)
lines(x2, f1.x2, col = "red")
plot(out, eq = 1, select = 2, seWithMean = TRUE, scale = 0)
lines(x3, f3.x3, col = "red")
plot(out, eq = 2, select = 1, seWithMean = TRUE, scale = 0)
lines(x2, f2.x2, col = "red")
plot(out, eq = 2, select = 2, seWithMean = TRUE, scale = 0)
lines(x3, f3.x3, col = "red")


## BIVARIATE PROBIT with Splines and 
## varying dependence parameter

eq.mu.1  &lt;- y1 ~ x1 + s(x2)
eq.mu.2  &lt;- y2 ~ x1 + s(x2)
eq.theta &lt;-    ~ x1 + s(x2)

fl &lt;- list(eq.mu.1, eq.mu.2, eq.theta)

outD &lt;- gjrm(fl, data = dataSim,
             margins = c("probit", "probit"),
             model = "B")
             
conv.check(outD)  
summary(outD)
summary(outD$theta)

plot(outD, eq = 1, seWithMean = TRUE)
plot(outD, eq = 2, seWithMean = TRUE)
plot(outD, eq = 3, seWithMean = TRUE)
graphics.off()

############
## Example 2
############
## Generate data with one endogenous variable 
## and exclusion restriction

set.seed(0)

n &lt;- 400

Sigma &lt;- matrix(0.5, 2, 2); diag(Sigma) &lt;- 1
u     &lt;- rMVN(n, rep(0,2), Sigma)

cov   &lt;- rMVN(n, rep(0,2), Sigma)
cov   &lt;- pnorm(cov)
x1 &lt;- round(cov[,1]); x2 &lt;- cov[,2]

f1   &lt;- function(x) cos(pi*2*x) + sin(pi*x)
f2   &lt;- function(x) x+exp(-30*(x-0.5)^2)   

y1 &lt;- ifelse(-1.55 + 2*x1    + f1(x2) + u[,1] &gt; 0, 1, 0)
y2 &lt;- ifelse(-0.25 - 1.25*y1 + f2(x2) + u[,2] &gt; 0, 1, 0)

dataSim &lt;- data.frame(y1, y2, x1, x2)

#
## Testing the hypothesis of absence of endogeneity... 
#

LM.bpm(list(y1 ~ x1 + s(x2), y2 ~ y1 + s(x2)), dataSim, model = "B")


## CLASSIC RECURSIVE BIVARIATE PROBIT

out &lt;- gjrm(list(y1 ~ x1 + x2, 
                 y2 ~ y1 + x2), 
                 data = dataSim,
                 margins = c("probit", "probit"),
                 model = "B")
conv.check(out)                        
summary(out)
AIC(out); BIC(out)

## FLEXIBLE RECURSIVE BIVARIATE PROBIT

out &lt;- gjrm(list(y1 ~ x1 + s(x2), 
                 y2 ~ y1 + s(x2)), 
                 data = dataSim,
                 margins = c("probit", "probit"),
                 model = "B")
conv.check(out)                        
summary(out)
AIC(out); BIC(out)

#
## Testing the hypothesis of absence of endogeneity post estimation... 

gt.bpm(out)

#
## treatment effect, risk ratio and odds ratio with CIs

mb(y1, y2, model = "B")
AT(out, nm.end = "y1", hd.plot = TRUE) 
RR(out, nm.end = "y1") 
OR(out, nm.end = "y1") 
AT(out, nm.end = "y1", type = "univariate") 
re.imp &lt;- imputeCounter(out, m = 10, "y1")
re.imp$AT

## try a Clayton copula model... 

outC &lt;- gjrm(list(y1 ~ x1 + s(x2), 
                  y2 ~ y1 + s(x2)), 
                  data = dataSim, copula = "C0",
                  margins = c("probit", "probit"),
                  model = "B")
conv.check(outC)                         
summary(outC)
AT(outC, nm.end = "y1") 
re.imp &lt;- imputeCounter(outC, m = 10, "y1")
re.imp$AT

## try a Joe copula model... 

outJ &lt;- gjrm(list(y1 ~ x1 + s(x2), 
                  y2 ~ y1 + s(x2)), 
                  data = dataSim, copula = "J0",
                  margins = c("probit", "probit"),
                  model = "B")
conv.check(outJ)
summary(outJ)
AT(outJ, "y1") 
re.imp &lt;- imputeCounter(outJ, m = 10, "y1")
re.imp$AT

VuongClarke(out, outJ)

#
## recursive bivariate probit modelling with unpenalized splines 
## can be achieved as follows

outFP &lt;- gjrm(list(y1 ~ x1 + s(x2, bs = "cr", k = 5), 
                   y2 ~ y1 + s(x2, bs = "cr", k = 6)), 
                   fp = TRUE, data = dataSim,
                   margins = c("probit", "probit"),
                   model = "B")
conv.check(outFP)                            
summary(outFP)

# in the above examples a third equation could be introduced
# as illustrated in Example 1

#
#################
## See also ?meps
#################

############
## Example 3
############
## Generate data with a non-random sample selection mechanism 
## and exclusion restriction

set.seed(0)

n &lt;- 2000

Sigma &lt;- matrix(0.5, 2, 2); diag(Sigma) &lt;- 1
u     &lt;- rMVN(n, rep(0,2), Sigma)

SigmaC &lt;- matrix(0.5, 3, 3); diag(SigmaC) &lt;- 1
cov    &lt;- rMVN(n, rep(0,3), SigmaC)
cov    &lt;- pnorm(cov)
bi &lt;- round(cov[,1]); x1 &lt;- cov[,2]; x2 &lt;- cov[,3]
  
f11 &lt;- function(x) -0.7*(4*x + 2.5*x^2 + 0.7*sin(5*x) + cos(7.5*x))
f12 &lt;- function(x) -0.4*( -0.3 - 1.6*x + sin(5*x))  
f21 &lt;- function(x) 0.6*(exp(x) + sin(2.9*x)) 

ys &lt;-  0.58 + 2.5*bi + f11(x1) + f12(x2) + u[, 1] &gt; 0
y  &lt;- -0.68 - 1.5*bi + f21(x1) +         + u[, 2] &gt; 0
yo &lt;- y*(ys &gt; 0)
  
dataSim &lt;- data.frame(y, ys, yo, bi, x1, x2)

#
## Testing the hypothesis of absence of non-random sample selection... 

LM.bpm(list(ys ~ bi + s(x1) + s(x2), yo ~ bi + s(x1)), dataSim, model = "BSS")

# p-value suggests presence of sample selection, hence fit a bivariate model

#
## SEMIPARAMETRIC SAMPLE SELECTION BIVARIATE PROBIT
## the first equation MUST be the selection equation

out &lt;- gjrm(list(ys ~ bi + s(x1) + s(x2), 
                 yo ~ bi + s(x1)), 
                 data = dataSim, model = "BSS",
                 margins = c("probit", "probit"))
conv.check(out)                          
gt.bpm(out)                        

## compare the two summary outputs
## the second output produces a summary of the results obtained when
## selection bias is not accounted for

summary(out)
summary(out$gam2)

## corrected predicted probability that 'yo' is equal to 1

mb(ys, yo, model = "BSS")
prev(out, hd.plot = TRUE)
prev(out, type = "univariate", hd.plot = TRUE)

## estimated smooth function plots
## the red line is the true curve
## the blue line is the univariate model curve not accounting for selection bias

x1.s &lt;- sort(x1[dataSim$ys&gt;0])
f21.x1 &lt;- f21(x1.s)[order(x1.s)]-mean(f21(x1.s))

plot(out, eq = 2, ylim = c(-1.65,0.95)); lines(x1.s, f21.x1, col="red")
par(new = TRUE)
plot(out$gam2, se = FALSE, col = "blue", ylim = c(-1.65,0.95), 
     ylab = "", rug = FALSE)

#
#
## try a Clayton copula model... 

outC &lt;- gjrm(list(ys ~ bi + s(x1) + s(x2), 
                  yo ~ bi + s(x1)), 
                  data = dataSim, model = "BSS", copula = "C0",
                  margins = c("probit", "probit"))
conv.check(outC)
summary(outC)
prev(outC)


#######################
# Impute using Mice
#######################

library(mice)

ys &lt;- dataSim$ys

dataSim$yo[dataSim$ys == FALSE] &lt;- NA  
dataSim &lt;- dataSim[, -c(1:2)]

imp &lt;- mice(dataSim, m = 1, method = c("copulaSS", "", "", ""),  
            mice.formula = outC$mice.formula, margins = outC$margins, 
            copula = outC$BivD, maxit = 1)

comp.yo &lt;- dataSim$yo
comp.yo[ys == 0] &lt;- imp$imp$yo[[1]]
mean(comp.yo)

#
################
## See also ?hiv
################

############
## Example 4
############
## Generate data with partial observability

set.seed(0)

n &lt;- 10000

Sigma &lt;- matrix(0.5, 2, 2); diag(Sigma) &lt;- 1
u     &lt;- rMVN(n, rep(0,2), Sigma)

x1 &lt;- round(runif(n)); x2 &lt;- runif(n); x3 &lt;- runif(n)

y1 &lt;- ifelse(-1.55 + 2*x1 + x2 + u[,1] &gt; 0, 1, 0)
y2 &lt;- ifelse( 0.45 - x3        + u[,2] &gt; 0, 1, 0)
y  &lt;- y1*y2

dataSim &lt;- data.frame(y, x1, x2, x3)


## BIVARIATE PROBIT with Partial Observability

out  &lt;- gjrm(list(y ~ x1 + x2, 
                  y ~ x3), 
                  data = dataSim, model = "BPO",
                  margins = c("probit", "probit"))
conv.check(out)
summary(out)

# first ten estimated probabilities for the four events from object out

cbind(out$p11, out$p10, out$p00, out$p01)[1:10,]


# case with smooth function 
# (more computationally intensive)  

f1 &lt;- function(x) cos(pi*2*x) + sin(pi*x)

y1 &lt;- ifelse(-1.55 + 2*x1 + f1(x2) + u[,1] &gt; 0, 1, 0)
y2 &lt;- ifelse( 0.45 - x3            + u[,2] &gt; 0, 1, 0)
y  &lt;- y1*y2

dataSim &lt;- data.frame(y, x1, x2, x3)

out  &lt;- gjrm(list(y ~ x1 + s(x2), 
                  y ~ x3), 
                  data = dataSim, model = "BPO",
                  margins = c("probit", "probit"))

conv.check(out)
summary(out)


# plot estimated and true functions

x2 &lt;- sort(x2); f1.x2 &lt;- f1(x2)[order(x2)] - mean(f1(x2))
plot(out, eq = 1, scale = 0); lines(x2, f1.x2, col = "red")

#
################
## See also ?war
################

## End(Not run)

## Not run: 

######################################################
######################################################
######################################################
# JOINT MODELS WITH BINARY AND/OR CONTINUOUS MARGINS #
######################################################
######################################################
######################################################

library(GJRM)

############
## Example 5
## Generate data
## Correlation between the two equations 0.5 - Sample size 400 

set.seed(0)

n &lt;- 400

Sigma &lt;- matrix(0.5, 2, 2); diag(Sigma) &lt;- 1
u     &lt;- rMVN(n, rep(0,2), Sigma)

x1 &lt;- round(runif(n)); x2 &lt;- runif(n); x3 &lt;- runif(n)

f1   &lt;- function(x) cos(pi*2*x) + sin(pi*x)
f2   &lt;- function(x) x+exp(-30*(x-0.5)^2)   

y1 &lt;- -1.55 + 2*x1    + f1(x2) + u[,1]
y2 &lt;- -0.25 - 1.25*x1 + f2(x2) + u[,2]

dataSim &lt;- data.frame(y1, y2, x1, x2, x3)

resp.check(y1, "N")
resp.check(y2, "N")

eq.mu.1     &lt;- y1 ~ x1 + s(x2) + s(x3)
eq.mu.2     &lt;- y2 ~ x1 + s(x2) + s(x3)
eq.sigma1   &lt;-    ~ 1
eq.sigma2   &lt;-    ~ 1
eq.theta    &lt;-    ~ x1

fl &lt;- list(eq.mu.1, eq.mu.2, eq.sigma1, eq.sigma2, eq.theta)

# the order above is the one to follow when
# using more than two equations

out  &lt;- gjrm(fl, data = dataSim, margins = c("N", "N"),
             model = "B")

conv.check(out)
post.check(out)
summary(out)
AIC(out)
BIC(out)
copula.prob(out, 1.4, 2.3, intervals = TRUE)[1:4,]

############
## Example 6
############
## Generate data with one endogenous binary variable 
## and continuous outcome

set.seed(0)

n &lt;- 1000

Sigma &lt;- matrix(0.5, 2, 2); diag(Sigma) &lt;- 1
u     &lt;- rMVN(n, rep(0,2), Sigma)

cov   &lt;- rMVN(n, rep(0,2), Sigma)
cov   &lt;- pnorm(cov)
x1 &lt;- round(cov[,1]); x2 &lt;- cov[,2]

f1   &lt;- function(x) cos(pi*2*x) + sin(pi*x)
f2   &lt;- function(x) x+exp(-30*(x-0.5)^2)   

y1 &lt;- ifelse(-1.55 + 2*x1    + f1(x2) + u[,1] &gt; 0, 1, 0)
y2 &lt;-        -0.25 - 1.25*y1 + f2(x2) + u[,2] 

dataSim &lt;- data.frame(y1, y2, x1, x2)


## RECURSIVE Model

rc &lt;- resp.check(y2, margin = "N", print.par = TRUE, loglik = TRUE)
AIC(rc); BIC(rc)

out &lt;- gjrm(list(y1 ~ x1 + x2, 
                 y2 ~ y1 + x2), 
                 data = dataSim, margins = c("probit","N"),
                 model = "B")
conv.check(out)                        
summary(out)
post.check(out)

## SEMIPARAMETRIC RECURSIVE Model

eq.mu.1   &lt;- y1 ~ x1 + s(x2) 
eq.mu.2   &lt;- y2 ~ y1 + s(x2)
eq.sigma  &lt;-    ~ 1
eq.theta  &lt;-    ~ 1

fl &lt;- list(eq.mu.1, eq.mu.2, eq.sigma, eq.theta)

out &lt;- gjrm(fl, data = dataSim, 
            margins = c("probit","N"), gamlssfit = TRUE,
            model = "B")
conv.check(out)                        
summary(out)
post.check(out)
copula.prob(out, 1, 1.5, intervals = TRUE)[1:4,]
AT(out, nm.end = "y1")
AT(out, nm.end = "y1", type = "univariate")

#
#

############
## Example 7
############
## Generate data with one endogenous continuous exposure 
## and binary outcome

set.seed(0)

n &lt;- 1000

Sigma &lt;- matrix(0.5, 2, 2); diag(Sigma) &lt;- 1
u     &lt;- rMVN(n, rep(0,2), Sigma)

cov   &lt;- rMVN(n, rep(0,2), Sigma)
cov   &lt;- pnorm(cov)
x1 &lt;- round(cov[,1]); x2 &lt;- cov[,2]

f1   &lt;- function(x) cos(pi*2*x) + sin(pi*x)
f2   &lt;- function(x) x+exp(-30*(x-0.5)^2) 

y1 &lt;-        -0.25 - 2*x1    + f2(x2) + u[,2] 
y2 &lt;- ifelse(-0.25 - 0.25*y1 + f1(x2) + u[,1] &gt; 0, 1, 0)

dataSim &lt;- data.frame(y1, y2, x1, x2)

eq.mu.1   &lt;- y2 ~ y1 + s(x2) 
eq.mu.2   &lt;- y1 ~ x1 + s(x2)
eq.sigma  &lt;-    ~ 1
eq.theta  &lt;-    ~ 1

fl &lt;- list(eq.mu.1, eq.mu.2, eq.sigma, eq.theta)

out &lt;- gjrm(fl, data = dataSim, 
            margins = c("probit","N"),
            model = "B")
conv.check(out)                        
summary(out)
post.check(out)
AT(out, nm.end = "y1")
AT(out, nm.end = "y1", type = "univariate")
RR(out, nm.end = "y1", rr.plot = TRUE)
RR(out, nm.end = "y1", type = "univariate")
OR(out, nm.end = "y1", or.plot = TRUE)
OR(out, nm.end = "y1", type = "univariate")

#
#

############
## Example 8
##################
## Survival models
##################

set.seed(0)

n  &lt;- 2000
c  &lt;- runif(n, 3, 8)
u  &lt;- runif(n, 0, 1)
z1 &lt;- rbinom(n, 1, 0.5)
z2 &lt;- runif(n, 0, 1)
t  &lt;- rep(NA, n)

beta_0 &lt;- -0.2357
beta_1 &lt;- 1

f &lt;- function(t, beta_0, beta_1, u, z1, z2){ 
  S_0 &lt;- 0.7 * exp(-0.03*t^1.9) + 0.3*exp(-0.3*t^2.5)
  exp(-exp(log(-log(S_0))+beta_0*z1 + beta_1*z2))-u
}


for (i in 1:n){
   t[i] &lt;- uniroot(f, c(0, 8), tol = .Machine$double.eps^0.5, 
                   beta_0 = beta_0, beta_1 = beta_1, u = u[i], 
                   z1 = z1[i], z2 = z2[i], extendInt = "yes" )$root
}

delta1  &lt;- ifelse(t &lt; c, 1, 0)
u1      &lt;- apply(cbind(t, c), 1, min)
dataSim &lt;- data.frame(u1, delta1, z1, z2)


c &lt;- runif(n, 4, 8)
u &lt;- runif(n, 0, 1)
z &lt;- rbinom(n, 1, 0.5)
beta_0 &lt;- -1.05
t      &lt;- rep(NA, n)

f &lt;- function(t, beta_0, u, z){ 
  S_0 &lt;- 0.7 * exp(-0.03*t^1.9) + 0.3*exp(-0.3*t^2.5)
  1/(1 + exp(log((1-S_0)/S_0)+beta_0*z))-u
}



for (i in 1:n){
    t[i] &lt;- uniroot(f, c(0, 8), tol = .Machine$double.eps^0.5, 
                    beta_0 = beta_0, u = u[i], z = z[i], 
                    extendInt="yes" )$root
}

delta2 &lt;- ifelse(t &lt; c,1, 0)
u2     &lt;- apply(cbind(t, c), 1, min)
dataSim$delta2 &lt;- delta2
dataSim$u2     &lt;- u2
dataSim$z      &lt;- z



eq1 &lt;- u1 ~ s(log(u1), bs = "mpi") + z1 + s(z2)
eq2 &lt;- u2 ~ s(log(u2), bs = "mpi") + z 
eq3 &lt;-    ~ s(z2)

out &lt;- gjrm(list(eq1, eq2), data = dataSim, surv = TRUE,
            margins = c("PH", "PO"), 
            cens1 = delta1, cens2 = delta2, model = "B")
                 
# PH margin fit can also be compared with cox.ph from mgcv
                 
conv.check(out)
res &lt;- post.check(out)

## martingale residuals
mr1 &lt;- out$cens1 - res$qr1
mr2 &lt;- out$cens2 - res$qr2

# can be plotted against covariates
# obs index, survival time, rank order of
# surv times

# to determine func form, one may use
# res from null model against covariate

# to test for PH, use:
# library(survival)
# fit &lt;- coxph(Surv(u1, delta1) ~ z1 + z2, data = dataSim) 
# temp &lt;- cox.zph(fit) 
# print(temp)                  
# plot(temp, resid = FALSE)     


summary(out)
AIC(out); BIC(out)
plot(out, eq = 1, scale = 0, pages = 1)
plot(out, eq = 2, scale = 0, pages = 1)

hazsurv(out, eq = 1, newdata = data.frame(z1 = 0, z2 = 0), 
        shade = TRUE, n.sim = 100, baseline = TRUE)
hazsurv(out, eq = 1, newdata = data.frame(z1 = 0, z2 = 0), 
        shade = TRUE, n.sim = 100, type = "hazard", baseline = TRUE, 
             intervals = FALSE)
hazsurv(out, eq = 2, newdata = data.frame(z = 0), 
        shade = FALSE, n.sim = 100, baseline = TRUE)
hazsurv(out, eq = 2, newdata = data.frame(z = 0), 
        shade = TRUE, n.sim = 100, type = "hazard", baseline = TRUE)
 
copula.prob(out, intervals = TRUE)[1:5,]
 
newd0 &lt;- newd1 &lt;- data.frame(z = 0, z1 = mean(dataSim$z1), 
                             z2 = mean(dataSim$z2), 
                             u1 =  mean(dataSim$u1) + 1, 
                             u2 =  mean(dataSim$u2) + 1) 
newd1$z &lt;- 1                   

copula.prob(out, newdata = newd0, intervals = TRUE)
copula.prob(out, newdata = newd1, intervals = TRUE)

out1 &lt;- gjrm(list(eq1, eq2, eq3), data = dataSim, surv = TRUE,
                  margins = c("PH", "PO"), 
                  cens1 = delta1, cens2 = delta2, gamlssfit = TRUE,
                  model = "B") 
  
                  
#########################################
## Joint continuous and survival outcomes
#########################################  
# work in progress
#
# eq1 &lt;- z2 ~ z1
# eq2 &lt;- u2 ~ s(u2, bs = "mpi") + z  
# eq3 &lt;-    ~ s(z2)                  
# eq4 &lt;-    ~ s(z2)                  
#                   
# f.l &lt;- list(eq1, eq2, eq3, eq4)                  
#   
# out3 &lt;- gjrm(f.l, data = dataSim, surv = TRUE,
#                   margins = c("N", "PO"), 
#                   cens1 = NULL, cens2 = delta2, 
#                   gamlssfit = TRUE, model = "B")   
# 
# conv.check(out3)
# post.check(out3)
# summary(out3)
# AIC(out3); BIC(out3)
# plot(out3, eq = 2, scale = 0, pages = 1)
# plot(out3, eq = 3, scale = 0, pages = 1)  
# plot(out3, eq = 4, scale = 0, pages = 1)                  
# 
# newd &lt;- newd1 &lt;- data.frame(z = 0, z1 = mean(dataSim$z1), 
#                              z2 = mean(dataSim$z2), 
#                              u2 =  mean(dataSim$u2) + 1) 
# 
# copula.prob(out3, y1 = 0.6, newdata = newd, intervals = TRUE)                

## End(Not run)

## Not run:  

##########################################
##########################################
##########################################
# JOINT MODELS WITH THREE BINARY MARGINS #
##########################################
##########################################
##########################################

library(GJRM)

############
## Example 9
############
## Generate data
## Correlation between the two equations 0.5 - Sample size 400 

set.seed(0)

n &lt;- 400

Sigma &lt;- matrix(0.5, 3, 3); diag(Sigma) &lt;- 1
u     &lt;- rMVN(n, rep(0,3), Sigma)

x1 &lt;- round(runif(n)); x2 &lt;- runif(n); x3 &lt;- runif(n)

f1   &lt;- function(x) cos(pi*2*x) + sin(pi*x)
f2   &lt;- function(x) x+exp(-30*(x-0.5)^2) 

y1 &lt;- ifelse(-1.55 +    2*x1 - f1(x2) + u[,1] &gt; 0, 1, 0)
y2 &lt;- ifelse(-0.25 - 1.25*x1 + f2(x2) + u[,2] &gt; 0, 1, 0)
y3 &lt;- ifelse(-0.75 + 0.25*x1          + u[,3] &gt; 0, 1, 0)

dataSim &lt;- data.frame(y1, y2, y3, x1, x2)

f.l &lt;- list(y1 ~ x1 + s(x2), 
            y2 ~ x1 + s(x2),
            y3 ~ x1)  

out  &lt;- gjrm(f.l, data = dataSim, model = "T",
             margins = c("probit", "probit", "probit"))
out1 &lt;- gjrm(f.l, data = dataSim, Chol = TRUE, model = "T",
             margins = c("probit", "probit", "probit"))

conv.check(out)
summary(out)
plot(out, eq = 1)
plot(out, eq = 2)
AIC(out)
BIC(out)

out  &lt;- gjrm(f.l, data = dataSim, model = "T", 
             margins = c("probit","logit","cloglog"))
out1 &lt;- gjrm(f.l, data = dataSim, Chol = TRUE, model = "T",
             margins = c("probit","logit","cloglog"))                    
conv.check(out)
summary(out)
plot(out, eq = 1)
plot(out, eq = 2)
AIC(out)
BIC(out)

f.l &lt;- list(y1 ~ x1 + s(x2), 
            y2 ~ x1 + s(x2),
            y3 ~ x1,
               ~ 1, ~ 1, ~ 1) 
               
out1 &lt;- gjrm(f.l, data = dataSim, Chol = TRUE, model = "T", 
             margins = c("probit", "probit", "probit"))
   
f.l &lt;- list(y1 ~ x1 + s(x2), 
            y2 ~ x1 + s(x2),
            y3 ~ x1,
               ~ 1, ~ s(x2), ~ 1) 
               
out2 &lt;- gjrm(f.l, data = dataSim, Chol = TRUE, model = "T", 
             margins = c("probit", "probit", "probit"))   

f.l &lt;- list(y1 ~ x1 + s(x2), 
            y2 ~ x1 + s(x2),
            y3 ~ x1,
               ~ x1, ~ s(x2), ~ x1 + s(x2)) 
               
out2 &lt;- gjrm(f.l, data = dataSim, Chol = TRUE, model = "T", 
             margins = c("probit", "probit", "probit"))   

f.l &lt;- list(y1 ~ x1 + s(x2), 
            y2 ~ x1 + s(x2),
            y3 ~ x1,
               ~ x1, ~ x1, ~ s(x2)) 
               
out2 &lt;- gjrm(f.l, data = dataSim, Chol = TRUE, model = "T", 
             margins = c("probit", "probit", "probit")) 

f.l &lt;- list(y1 ~ x1 + s(x2), 
            y2 ~ x1 + s(x2),
            y3 ~ x1,
               ~ x1, ~ x1 + x2, ~ s(x2)) 
               
out2 &lt;- gjrm(f.l, data = dataSim, Chol = TRUE, model = "T", 
             margins = c("probit", "probit", "probit")) 

f.l &lt;- list(y1 ~ x1 + s(x2), 
            y2 ~ x1 + s(x2),
            y3 ~ x1,
               ~ x1 + x2, ~ x1 + x2, ~ x1 + x2) 
               
out2 &lt;- gjrm(f.l, data = dataSim, Chol = TRUE, model = "T", 
             margins = c("probit", "probit", "probit")) 
       
       
jcres1 &lt;- copula.prob(out2, 1, 1, 1, joint = TRUE, cond = 0, 
                   intervals = TRUE, n.sim = 100)
       
nw &lt;- data.frame( x1 = 0, x2 = seq(0, 1, length.out = 100) )   
       
jcres2 &lt;- copula.prob(out2, 1, 1, 1, newdata = nw, 
                   cond = 0, intervals = TRUE, n.sim = 100)
      
#############
## Example 10
#############
## Generate data
## with double sample selection

set.seed(0)

n &lt;- 5000

Sigma &lt;- matrix(c(1,   0.5, 0.4,
                  0.5,   1, 0.6,
                  0.4, 0.6,   1 ), 3, 3)

u &lt;- rMVN(n, rep(0,3), Sigma)

f1   &lt;- function(x) cos(pi*2*x) + sin(pi*x)
f2   &lt;- function(x) x+exp(-30*(x-0.5)^2) 

x1 &lt;- runif(n)
x2 &lt;- runif(n)
x3 &lt;- runif(n)
x4 &lt;- runif(n)
  
y1 &lt;-  1    + 1.5*x1 -     x2 + 0.8*x3 - f1(x4) + u[, 1] &gt; 0
y2 &lt;-  1    - 2.5*x1 + 1.2*x2 +     x3          + u[, 2] &gt; 0
y3 &lt;-  1.58 + 1.5*x1 - f2(x2)                   + u[, 3] &gt; 0

dataSim &lt;- data.frame(y1, y2, y3, x1, x2, x3, x4)

f.l &lt;- list(y1 ~ x1 + x2 + x3 + s(x4), 
            y2 ~ x1 + x2 + x3, 
            y3 ~ x1 + s(x2))   
          
out &lt;- gjrm(f.l, data = dataSim, model = "TSS",
            margins = c("probit", "probit", "probit"))
conv.check(out)
summary(out)
plot(out, eq = 1)
plot(out, eq = 3)
prev(out)
prev(out, type = "univariate")
prev(out, type = "naive")

## End(Not run)

## Not run:  

###################################################
###################################################
###################################################
# JOINT MODELS WITH BINARY AND CONTINUOUS MARGINS #
# WITH SAMPLE SELECTION                           #
###################################################
###################################################
###################################################

library(GJRM)

######################################################################
## Generate data
## Correlation between the two equations and covariate correlation 0.5 
## Sample size 2000 
######################################################################
#############
## Example 11
#############
set.seed(0)

n &lt;- 2000

rh &lt;- 0.5      

sigmau &lt;- matrix(c(1, rh, rh, 1), 2, 2)
u      &lt;- rMVN(n, rep(0,2), sigmau)

sigmac &lt;- matrix(rh, 3, 3); diag(sigmac) &lt;- 1
cov    &lt;- rMVN(n, rep(0,3), sigmac)
cov    &lt;- pnorm(cov)

bi &lt;- round(cov[,1]); x1 &lt;- cov[,2]; x2 &lt;- cov[,3]
  
f11 &lt;- function(x) -0.7*(4*x + 2.5*x^2 + 0.7*sin(5*x) + cos(7.5*x))
f12 &lt;- function(x) -0.4*( -0.3 - 1.6*x + sin(5*x))  
f21 &lt;- function(x) 0.6*(exp(x) + sin(2.9*x)) 

ys &lt;-  0.58 + 2.5*bi + f11(x1) + f12(x2) + u[, 1] &gt; 0
y  &lt;- -0.68 - 1.5*bi + f21(x1) +           u[, 2]
yo &lt;- y*(ys &gt; 0)
  
dataSim &lt;- data.frame(ys, yo, bi, x1, x2)

## CLASSIC SAMPLE SELECTION MODEL
## the first equation MUST be the selection equation

resp.check(yo[ys &gt; 0], "N")

out &lt;- gjrm(list(ys ~ bi + x1 + x2, 
                 yo ~ bi + x1), 
                 data = dataSim, model = "BSS",
                 margins = c("probit", "N"))
conv.check(out)
post.check(out)
summary(out)

AIC(out)
BIC(out)


## SEMIPARAMETRIC SAMPLE SELECTION MODEL

out &lt;- gjrm(list(ys ~ bi + s(x1) + s(x2), 
                 yo ~ bi + s(x1)), 
                 data = dataSim, model = "BSS",
                 margins = c("probit", "N"))
conv.check(out) 
post.check(out)
AIC(out)

## compare the two summary outputs
## the second output produces a summary of the results obtained when only 
## the outcome equation is fitted, i.e. selection bias is not accounted for

summary(out)
summary(out$gam2)

## estimated smooth function plots
## the red line is the true curve
## the blue line is the naive curve not accounting for selection bias

x1.s &lt;- sort(x1[dataSim$ys&gt;0])
f21.x1 &lt;- f21(x1.s)[order(x1.s)] - mean(f21(x1.s))

plot(out, eq = 2, ylim = c(-1, 0.8)); lines(x1.s, f21.x1, col = "red")
par(new = TRUE)
plot(out$gam2, se = FALSE, lty = 3, lwd = 2, ylim = c(-1, 0.8), 
     ylab = "", rug = FALSE)


## IMPUTE MISSING VALUES

n.m &lt;- 10
res &lt;- imputeSS(out, n.m)
bet &lt;- NA

for(i in 1:n.m){

dataSim$yo[dataSim$ys == 0] &lt;- res[[i]]

outg &lt;- gamlss(list(yo ~ bi + s(x1)), data = dataSim)
bet[i] &lt;- coef(outg)["bi"]
print(i)
}

mean(bet)

##


## SEMIPARAMETRIC SAMPLE SELECTION MODEL with association 
## and dispersion parameters 
## depending on covariates as well

eq.mu.1   &lt;- ys ~ bi + s(x1) + s(x2)
eq.mu.2   &lt;- yo ~ bi + s(x1)
eq.sigma  &lt;-    ~ bi
eq.theta  &lt;-    ~ bi + x1

fl &lt;- list(eq.mu.1, eq.mu.2, eq.sigma, eq.theta)

out &lt;- gjrm(fl, data = dataSim, model = "BSS",
                 margins = c("probit", "N"))
conv.check(out)   
post.check(out)
summary(out)
summary(out$sigma)
summary(out$theta)

copula.prob(out, 0, 0.3, intervals = TRUE)[1:4,]

outC0 &lt;- gjrm(fl, data = dataSim, copula = "C0", model = "BSS",
              margins = c("probit", "N"))
conv.check(outC0)
post.check(outC0)
AIC(out, outC0)
BIC(out, outC0)

## IMPUTE MISSING VALUES

n.m &lt;- 10
res &lt;- imputeSS(outC0, n.m)

###############
# or using MICE
###############

library(mice)

ys &lt;- dataSim$ys

dataSim$yo[dataSim$ys == FALSE] &lt;- NA  
dataSim &lt;- dataSim[, -1]

imp &lt;- mice(dataSim, m = 1, method = c("copulaSS", "", "", ""),  
            mice.formula = outC0$mice.formula, margins = outC0$margins, 
            copula = outC0$BivD, maxit = 1)

comp.yo &lt;- dataSim$yo
comp.yo[ys == 0] &lt;- imp$imp$yo[[1]]
mean(comp.yo)


#
#
#######################################################
## example using Gumbel copula and normal-gamma margins
#######################################################
#############
## Example 12
#############
set.seed(1)

y  &lt;- exp(-0.68 - 1.5*bi + f21(x1) + u[, 2])
yo &lt;- y*(ys &gt; 0)
    
dataSim &lt;- data.frame(ys, yo, bi, x1, x2)


out &lt;- gjrm(list(ys ~ bi + s(x1) + s(x2), 
                 yo ~ bi + s(x1)), 
                 data = dataSim, copula = "G0", 
                 margins = c("probit", "GA"),
                 model = "BSS")
conv.check(out)
post.check(out)
summary(out)


ATE &lt;- NA
n.m &lt;- 10
res &lt;- imputeSS(out, n.m)

for(i in 1:n.m){

dataSim$yo[dataSim$ys == 0] &lt;- res[[i]]

outg &lt;- gamlss(list(yo ~ bi + s(x1)), margin = "GA", data = dataSim)

out$gamlss &lt;- outg
ATE[i] &lt;- AT(out, nm.end = "bi", type = "univariate")$res[2]

print(i)

}

AT(out, nm.end = "bi")
mean(ATE)

## End(Not run)

</code></pre>

<hr>
<h2 id='gjrmObject'>Fitted gjrm object</h2><span id='topic+gjrmObject'></span>

<h3>Description</h3>

<p>A fitted joint model returned by function <code>gjrm</code> and of class &quot;gjrm&quot;, &quot;SemiParBIV&quot;, &quot;SemiParTRIV&quot;, etc.</p>


<h3>Value</h3>

 
<table>
<tr><td><code>fit</code></td>
<td>
<p>List of values and diagnostics extracted from the output of the algorithm.</p>
</td></tr>
<tr><td><code>gam1</code></td>
<td>
<p>Univariate fit for equation 1. See the documentation of <code>mgcv</code> for full details.</p>
</td></tr>
<tr><td><code>gam2</code>, <code>gam3</code>, <code>...</code></td>
<td>
<p>Univariate fit for equation 2, equation 3, etc.</p>
</td></tr>
<tr><td><code>coefficients</code></td>
<td>
<p>The coefficients of the fitted model.</p>
</td></tr>
<tr><td><code>weights</code></td>
<td>
<p>Prior weights used during model fitting.</p>
</td></tr>
<tr><td><code>sp</code></td>
<td>
<p>Estimated smoothing parameters of the smooth components.</p>
</td></tr>
<tr><td><code>iter.sp</code></td>
<td>
<p>Number of iterations performed for the smoothing parameter estimation step.</p>
</td></tr>
<tr><td><code>iter.if</code></td>
<td>
<p>Number of iterations performed in the initial step of the algorithm.</p>
</td></tr>
<tr><td><code>iter.inner</code></td>
<td>
<p>Number of iterations performed within the smoothing parameter estimation step.</p>
</td></tr>
<tr><td><code>theta</code></td>
<td>
<p>Estimated dependence parameter linking the two equations.</p>
</td></tr>
<tr><td><code>n</code></td>
<td>
<p>Sample size.</p>
</td></tr>
<tr><td><code>X1</code>, <code>X2</code>, <code>X3</code>, <code>...</code></td>
<td>
<p>Design matrices associated with the linear predictors.</p>
</td></tr>
<tr><td><code>X1.d2</code>, <code>X2.d2</code>, <code>X3.d2</code>, <code>...</code></td>
<td>
<p>Number of columns of <code>X1</code>, <code>X2</code>, <code>X3</code>, etc.</p>
</td></tr>
<tr><td><code>l.sp1</code>, <code>l.sp2</code>, <code>l.sp3</code>, <code>...</code></td>
<td>
<p>Number of smooth components in the equations.</p>
</td></tr>
<tr><td><code>He</code></td>
<td>
<p>Penalized -hessian/Fisher. This is the same as <code>HeSh</code> for unpenalized models.</p>
</td></tr>
<tr><td><code>HeSh</code></td>
<td>
<p>Unpenalized -hessian/Fisher.</p>
</td></tr>
<tr><td><code>Vb</code></td>
<td>
<p>Inverse of <code>He</code>. This corresponds to the Bayesian variance-covariance matrix 
used for confidence/credible interval calculations.</p>
</td></tr>
<tr><td><code>F</code></td>
<td>
<p>This is obtained multiplying Vb by HeSh.</p>
</td></tr> 
<tr><td><code>t.edf</code></td>
<td>
<p>Total degrees of freedom of the estimated bivariate model. It is calculated as <code>sum(diag(F))</code>.</p>
</td></tr>
<tr><td><code>edf1</code>, <code>edf2</code>, <code>edf3</code>, <code>...</code></td>
<td>
<p>Degrees of freedom for the two equations of the fitted bivariate model (and for the third and fourth
equations if present. They  
are calculated when splines are used.</p>
</td></tr>
<tr><td><code>bs.mgfit</code></td>
<td>
<p>List of values and diagnostics extracted from <code>magic</code> in <code>mgcv</code>.</p>
</td></tr>
<tr><td><code>conv.sp</code></td>
<td>
<p>If <code>TRUE</code> then the smoothing parameter selection algorithm stopped before reaching the maximum number of iterations allowed.</p>
</td></tr>
<tr><td><code>wor.c</code></td>
<td>
<p>Working model quantities.</p>
</td></tr>                
<tr><td><code>eta1</code>, <code>eta2</code>, <code>eta3</code>, <code>...</code></td>
<td>
<p>Estimated linear predictors for the two equations (as well as the third and fourth equations if present).</p>
</td></tr>
<tr><td><code>y1</code>, <code>y2</code></td>
<td>
<p>Responses of the two equations.</p>
</td></tr>
<tr><td><code>logLik</code></td>
<td>
<p>Value of the (unpenalized) log-likelihood evaluated at the (penalized or unpenalized) parameter 
estimates.</p>
</td></tr>
<tr><td><code>respvec</code></td>
<td>
<p>List containing response vectors.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Maintainer: Giampiero Marra <a href="mailto:giampiero.marra@ucl.ac.uk">giampiero.marra@ucl.ac.uk</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gjrm">gjrm</a></code>, <code><a href="#topic+summary.gjrm">summary.gjrm</a></code>
</p>

<hr>
<h2 id='gt.bpm'>Gradient test</h2><span id='topic+gt.bpm'></span>

<h3>Description</h3>

 
<p><code>gt.bpm</code> can be used to test the hypothesis of absence of endogeneity, correlated model equations/errors or non-random sample selection
in binary bivariate probit models.</p>


<h3>Usage</h3>

<pre><code class='language-R'>
gt.bpm(x)

</code></pre>


<h3>Arguments</h3>

 
<table>
<tr><td><code id="gt.bpm_+3A_x">x</code></td>
<td>
<p>A fitted <code>gjrm</code> object.</p>
</td></tr> 
</table>


<h3>Details</h3>

<p>The gradient test was first proposed by Terrell (2002) and it is based on classic likelihood 
theory. See Marra et al. (in press) for full details. 
</p>


<h3>Value</h3>

<p>It returns a numeric p-value corresponding to the null hypothesis that the correlation, <code class="reqn">\theta</code>, is equal to 0. 
</p>


<h3>WARNINGS</h3>

<p>This test's implementation is only valid for bivariate binary probit models with normal errors.
</p>


<h3>Author(s)</h3>

<p>Maintainer: Giampiero Marra <a href="mailto:giampiero.marra@ucl.ac.uk">giampiero.marra@ucl.ac.uk</a>
</p>


<h3>References</h3>

<p>Marra G., Radice R. and Filippou P. (2017), Regression Spline Bivariate Probit Models: A Practical Approach to Testing for Exogeneity. <em>Communications in Statistics - Simulation and Computation</em>, 46(3), 2283-2298.
</p>
<p>Terrell G. (2002), The Gradient Statistic. <em>Computing Science and Statistics</em>, 34, 206-215.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## see examples for gjrm
</code></pre>

<hr>
<h2 id='H.tri'>Internal Function</h2><span id='topic+H.tri'></span><span id='topic+H.triSS'></span><span id='topic+H.triESS'></span>

<h3>Description</h3>

<p>This and other similar internal functions calculate the Hessian for trivariate binary models.
</p>


<h3>Author(s)</h3>

<p>Author: Panagiota Filippou
</p>
<p>Maintainer: Giampiero Marra <a href="mailto:giampiero.marra@ucl.ac.uk">giampiero.marra@ucl.ac.uk</a>
</p>

<hr>
<h2 id='hazsurv'>Post-estimation calculation of hazard, cumulative hazard and survival functions</h2><span id='topic+hazsurv'></span>

<h3>Description</h3>

<p>This function produces estimated values, intervals and plots for the hazard, cumulative hazard and survival functions.</p>


<h3>Usage</h3>

<pre><code class='language-R'>
hazsurv(x, eq, newdata, type = "surv", t.range = NULL, t.vec = NULL, 
        intervals = TRUE, n.sim = 100, prob.lev = 0.05, shade = FALSE, 
        bars = FALSE, ylim, ylab, xlab, pch, ls = 100, baseline = FALSE,
        min.dn = 1e-200, min.pr = 1e-200, max.pr = 1, plot.out = TRUE, 
        print.progress = TRUE, ...)



</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="hazsurv_+3A_x">x</code></td>
<td>
<p>A fitted <code>gamlss</code>/<code>gjrm</code> object.</p>
</td></tr>
<tr><td><code id="hazsurv_+3A_eq">eq</code></td>
<td>
<p>Equation number. This can be ignored for univariate models.</p>
</td></tr>
<tr><td><code id="hazsurv_+3A_newdata">newdata</code></td>
<td>
<p>A data frame or list containing the values of the model covariates at which predictions are required. This must always be provided.
</p>
<p>For the individual survival/hazard/cumulative hazard function, the data frame must have one row containing the values of the model covariates corresponding to the individual of interest. 
</p>
<p>For the (sub-)population survival/hazard/cumulative hazard function, the data frame must have as many rows as there are individuals in the (sub-)population of interest. Each row must contain the values of the model covariates of the corresponding individual.</p>
</td></tr>
<tr><td><code id="hazsurv_+3A_type">type</code></td>
<td>
<p>Either <code>"surv"</code>, <code>"hazard"</code> or <code>"cumhaz"</code>. In the excess hazard setting these are, respectively, the net survival, the excess hazard and the cumulative excess hazard.</p>
</td></tr>
<tr><td><code id="hazsurv_+3A_t.range">t.range</code></td>
<td>
<p>Time variable range. This must be a vector with only two elements: the minimum and maximum of the time range. If <code>NULL</code> then it is determined automatically based on the observed data.</p>
</td></tr>
<tr><td><code id="hazsurv_+3A_t.vec">t.vec</code></td>
<td>
<p>Vector of time values. This can also be a single time. Note you cannot provide both <code>t.range</code> and <code>t.vec</code> as they are two mutually exclusive ways of defining the time variable. If <code>NULL</code> then it is determined automatically based on the observed data. </p>
</td></tr>
<tr><td><code id="hazsurv_+3A_intervals">intervals</code></td>
<td>
<p>If <code>TRUE</code> then intervals are also produced.</p>
</td></tr>
<tr><td><code id="hazsurv_+3A_n.sim">n.sim</code></td>
<td>
<p>Number of simulated coefficient vectors from the posterior distribution of the estimated model parameters. This is used
for interval calculations.</p>
</td></tr>
<tr><td><code id="hazsurv_+3A_prob.lev">prob.lev</code></td>
<td>
<p>Overall probability of the left and right tails of the probabilities' distributions used for interval calculations.</p>
</td></tr>  
<tr><td><code id="hazsurv_+3A_shade">shade</code></td>
<td>
<p>If <code>TRUE</code> then it produces shaded regions as confidence bands.</p>
</td></tr>
<tr><td><code id="hazsurv_+3A_bars">bars</code></td>
<td>
<p>If <code>TRUE</code> then the confidence intervals are plotted as bars rather than continuous curves. If <code>t.vec</code> is used and only one time value is provided, this is the only possible plotting option for the confidence intervals. Note <code>shade</code> and <code>bars</code> are mutually exclusive.</p>
</td></tr>
<tr><td><code id="hazsurv_+3A_ylim">ylim</code>, <code id="hazsurv_+3A_ylab">ylab</code>, <code id="hazsurv_+3A_xlab">xlab</code>, <code id="hazsurv_+3A_pch">pch</code></td>
<td>
<p>Usual plot arguments.</p>
</td></tr>
<tr><td><code id="hazsurv_+3A_ls">ls</code></td>
<td>
<p>Length of sequence to use for time variable.</p>
</td></tr>
<tr><td><code id="hazsurv_+3A_baseline">baseline</code></td>
<td>
<p>If baseline is desired; this will set all covariate/smooth effects to zero.</p>
</td></tr>
<tr><td><code id="hazsurv_+3A_min.dn">min.dn</code>, <code id="hazsurv_+3A_min.pr">min.pr</code>, <code id="hazsurv_+3A_max.pr">max.pr</code></td>
<td>
<p>Allowed minimum and maximum for estimated probabities and densities for survival, hazard and cumulative hazard calculations.</p>
</td></tr>
<tr><td><code id="hazsurv_+3A_plot.out">plot.out</code></td>
<td>
<p>If <code>FALSE</code> then the function does not produce a plot. The default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="hazsurv_+3A_print.progress">print.progress</code></td>
<td>
<p>If <code>FALSE</code> then the function does not print progress made. The default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="hazsurv_+3A_...">...</code></td>
<td>
<p>Other arguments to pass to plot.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>It produces estimated values, intervals and plots for the hazard, cumulative hazard and survival functions.</p>


<h3>Author(s)</h3>

<p>Maintainer: Giampiero Marra <a href="mailto:giampiero.marra@ucl.ac.uk">giampiero.marra@ucl.ac.uk</a>
</p>

<hr>
<h2 id='hiv'>HIV Zambian data</h2><span id='topic+hiv'></span><span id='topic+hiv.polys'></span>

<h3>Description</h3>

<p>HIV Zambian data by region, together with polygons describing the regions' shapes.</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(hiv)
data(hiv.polys)
</code></pre>


<h3>Format</h3>

 <p><code>hiv</code> is a 6416 row data frame with the following columns 
</p>

<dl>
<dt>hivconsent</dt><dd><p>binary variable indicating consent to test for HIV.</p>
</dd>
<dt>hiv</dt><dd><p>binary variable indicating whether an individual is HIV positive.</p>
</dd>
<dt>age</dt><dd><p>age in years.</p>
</dd>
<dt>education</dt><dd><p>years of education.</p>
</dd>
<dt>region</dt><dd><p>code identifying region, and matching <code>names(hiv.polys)</code>. It can take nine possible values: 1 central, 2 copperbelt, 3 eastern, 
4 luapula, 5 lusaka, 6 northwestern, 7 northern, 8 southern, 9 western.</p>
</dd>
<dt>marital</dt><dd><p>never married, currently married, formerly married.</p>
</dd>
<dt>std</dt><dd><p>had a sexually transmitted disease.</p>
</dd>
<dt>highhiv</dt><dd><p>had high risk sex.</p>
</dd>
<dt>condom</dt><dd><p>used condom during last intercourse.</p>
</dd>
<dt>aidscare</dt><dd><p>equal to 1 if would care for an HIV-infected relative.</p>
</dd>
<dt>knowsdiedofaids</dt><dd><p>equal to 1 if know someone who died of HIV.</p>
</dd>
<dt>evertestedHIV</dt><dd><p>equal to 1 if previously tested for HIV.</p>
</dd>           
<dt>smoke</dt><dd><p>smoker.</p>
</dd>         
<dt>ethnicity</dt><dd><p>bemba, lunda (luapula), lala, ushi, lamba, tonga, luvale,
lunda (northwestern), mbunda, kaonde, lozi, chewa, nsenga,
ngoni, mambwe, namwanga, tumbuka, other.</p>
</dd>              
<dt>language</dt><dd><p>English, Bemba, Lozi, Nyanja, Tonga, other.</p>
</dd>                     
<dt>interviewerID</dt><dd><p>interviewer identifier.</p>
</dd>                        
<dt>sw</dt><dd><p>survey weights.</p>
</dd>  
</dl>

<p><code>hiv.polys</code> contains the polygons defining the areas in the format described below.
</p>


<h3>Details</h3>

<p>The data frame <code>hiv</code> relates to the regions whose boundaries are coded in <code>hiv.polys</code>.
<code>hiv.polys[[i]]</code> is a 2 column matrix, containing the vertices of the polygons defining the boundary of the ith 
region. <code>names(hiv.polys)</code> matches <code>hiv$region</code> (order unimportant).
</p>


<h3>Source</h3>

<p>The data have been produced as described in: 
</p>
<p>McGovern M.E., Barnighausen T., Marra G. and Radice R. (2015), On the Assumption of Joint Normality in Selection Models: A Copula Approach Applied to Estimating HIV Prevalence. <em>Epidemiology</em>, 26(2), 229-237.
</p>


<h3>References</h3>

<p>Marra G., Radice R., Barnighausen T., Wood S.N. and McGovern M.E. (2017), A Simultaneous Equation Approach to Estimating HIV Prevalence with Non-Ignorable Missing Responses. <em>Journal of the American Statistical Association</em>, 112(518), 484-496.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run:  

#########################################################
#########################################################

library("GJRM")

data("hiv", package = "GJRM")        
data("hiv.polys", package = "GJRM")  

#########################################################
#########################################################
## The stuff below is useful if the user wishes to employ  
## a Markov Random Field (MRF) smoother. It provides
## the instructions to set up polygons automatically
## and the dataset variable needed to fit a model with 
## MRF.
#########################################################
#########################################################
#
# ## hiv.polys was already created and
# ## made available via the call 
# ## data("hiv.polys", package = "GJRM") 
# ## hiv.polys was created using the code below
#
# obj &lt;- readRDS("ZMB_adm1.rds") 
# ## RDS Zambian Level 1 file obtained from 
# ## http://www.gadm.org. 
#
# pol &lt;- polys.setup(obj)
#
# hiv.polys &lt;- pol$polys   
# name &lt;- cbind(names(hiv.polys), pol$names1)
# name
#
## last step was to create a factor variable with range
## range(name[,1]) where the numerical values were linked   
## to the regions in name[, 2]. This is what was done in 
## the hiv dataset; see hiv$region. Specifically,
## the procedure used was
##
# reg &lt;- NULL
# 
# for(i in 1:dim(hiv)[1]){
# 
# if(hiv$region[i] == "Central")       reg[i] &lt;- 1
# if(hiv$region[i] == "Copperbelt")    reg[i] &lt;- 2
# if(hiv$region[i] == "Eastern")       reg[i] &lt;- 3
# if(hiv$region[i] == "Luapula")       reg[i] &lt;- 4
# if(hiv$region[i] == "Lusaka")        reg[i] &lt;- 5
# if(hiv$region[i] == "North-Western") reg[i] &lt;- 6
# if(hiv$region[i] == "Northern")      reg[i] &lt;- 7
# if(hiv$region[i] == "Southern")      reg[i] &lt;- 8
# if(hiv$region[i] == "Western")       reg[i] &lt;- 9
# 
# }
# 
# hiv$region &lt;- as.factor(reg)
# 
# 
#########################################################
#########################################################

xt &lt;- list(polys = hiv.polys) 

# neighbourhood structure info for MRF  
# to use in model specification

#########################################################
# Bivariate brobit model with non-random sample selection
#########################################################          
     
sel.eq &lt;- hivconsent ~ s(age) + s(education) + s(wealth) + 
                       s(region, bs = "mrf", xt = xt, k = 7) + 
                       marital + std + age1sex_cat + highhiv + 
                       partner + condom + aidscare + 
                       knowsdiedofaids + evertestedHIV + 
                       smoke + religion + ethnicity + 
                       language + s(interviewerID, bs = "re")
 
out.eq &lt;- hiv        ~ s(age) + s(education) + s(wealth) + 
                       s(region, bs = "mrf", xt = xt, k = 7) + 
                       marital + std + age1sex_cat + highhiv + 
                       partner + condom + aidscare + 
                       knowsdiedofaids + evertestedHIV + 
                       smoke + religion + ethnicity + 
                       language      

theta.eq &lt;-          ~ s(region, bs = "mrf", xt = xt, k = 7)                       
    
fl &lt;- list(sel.eq, out.eq, theta.eq)    
     
# the above model specification is fairly
# complex and it serves to illustrate the 
# flexibility of the modelling approach
     
bss &lt;- gjrm(fl, data = hiv, copula = "J90", model = "BSS",
            margins = c("probit", "probit"))

conv.check(bss)

set.seed(1)
sb &lt;- summary(bss)
sb

plot(bss, eq = 1, seWithMean = TRUE, scheme = 1,   
     scale = 0, pages = 1, jit = TRUE)
                    
plot(bss, eq = 2, seWithMean = TRUE, scheme = 1,
     scale = 0, pages = 1, jit = TRUE)


prev(bss, sw = hiv$sw, type = "naive") 

set.seed(1)
prev(bss, sw = hiv$sw, type = "univariate") 

prev(bss, sw = hiv$sw) 


lr &lt;- length(hiv.polys) 
prevBYreg  &lt;- matrix(NA, lr, 2)
thetaBYreg &lt;- NA

for(i in 1:lr) {
prevBYreg[i,1] &lt;- prev(bss, sw = hiv$sw, ind = hiv$region==i, 
                       type = "univariate")$res[2]
prevBYreg[i,2] &lt;- prev(bss, sw = hiv$sw, ind = hiv$region==i)$res[2]
thetaBYreg[i]  &lt;- bss$theta[hiv$region==i][1]
}


zlim &lt;- range(prevBYreg)  # to establish a common prevalence range

par(mfrow = c(1, 3), cex.axis = 1.3)

polys.map(hiv.polys, prevBYreg[,1], zlim = zlim, lab = "",  
          cex.lab = 1.5, cex.main = 1.5, 
          main = "HIV - Imputation Model")
          
polys.map(hiv.polys, prevBYreg[,2], zlim = zlim, cex.main = 1.5, 
          main = "HIV - Selection Model")
          
polys.map(hiv.polys, thetaBYreg, rev.col = FALSE, cex.main = 1.7, 
          main = expression(paste("Copula parameter (",hat(theta),")")))
          
sb$CItheta[1,]

## End(Not run)

#

</code></pre>

<hr>
<h2 id='imputeCounter'>Imputation of Counterfactual</h2><span id='topic+imputeCounter'></span>

<h3>Description</h3>

 
<p><code>imputeCounter</code> imputes counterfactual missing values for a gjrm model object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
imputeCounter(x, m = 10, nm.end)

</code></pre>


<h3>Arguments</h3>

 
<table>
<tr><td><code id="imputeCounter_+3A_x">x</code></td>
<td>
<p>A fitted <code>gjrm</code> object.</p>
</td></tr>
<tr><td><code id="imputeCounter_+3A_m">m</code></td>
<td>
<p>Number of imputed response vectors.</p>
</td></tr> 
<tr><td><code id="imputeCounter_+3A_nm.end">nm.end</code></td>
<td>
<p>Name endogenous variable.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function generates m sets of imputed values for the outcome of interest under a fitted joint causal model. The 
algorithm draws parameters from the posterior distribution of the model which are then used to obtain simulated
responses (from the posterior predictive distribution of the missing values) via a rejection algorithm. The 
bound for acceptance/rejection is obtained via a trust region optimisation.
</p>
<p>The imputed values are used to create m complete imputed datasets and perform complete data 
analysis and inference about the parameters of interest using any summary statistics.
</p>


<h3>Value</h3>

<p>It returns a list containing m imputed response vectors.
</p>


<h3>Author(s)</h3>

<p>Maintainer: Giampiero Marra <a href="mailto:giampiero.marra@ucl.ac.uk">giampiero.marra@ucl.ac.uk</a>
</p>


<h3>References</h3>

<p>Robert C. and  Casella G. (2004). Monte Carlo Statistical Methods. New York: Springer-Verlag.
</p>
<p>Ripley B. D. (1987) Stochastic Simulation. New York: John Wiley &amp; Sons, Inc.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gjrm">gjrm</a></code> 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## see examples for gjrm
</code></pre>

<hr>
<h2 id='imputeSS'>Missing values' imputation</h2><span id='topic+imputeSS'></span>

<h3>Description</h3>

 
<p><code>imputeSS</code> imputes missing values for a gjrm model object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
imputeSS(x, m = 10)

</code></pre>


<h3>Arguments</h3>

 
<table>
<tr><td><code id="imputeSS_+3A_x">x</code></td>
<td>
<p>A fitted <code>gjrm</code> object.</p>
</td></tr>
<tr><td><code id="imputeSS_+3A_m">m</code></td>
<td>
<p>Number of imputed response vectors.</p>
</td></tr> 
</table>


<h3>Details</h3>

<p>This function generates m sets of imputed values for the outcome of interest under a fitted copulaSampleSel model. The 
algorithm draws parameters from the posterior distribution of copulaSampleSel which are then used to obtain simulated
responses (from the posterior predictive distribution of the missing values) via a rejection algorithm. The 
bound for acceptance/rejection is obtained via a trust region optimisation.
</p>
<p>The imputed values are used to create m complete imputed datasets and perform complete data 
analysis and inference about the parameters of interest using function <code>gamlss()</code> within this package.
</p>


<h3>Value</h3>

<p>It returns a list containing m imputed response vectors.
</p>


<h3>Author(s)</h3>

<p>Authors: Jose Camarena, Giampiero Marra and Rosalba Radice
</p>
<p>Maintainer: Giampiero Marra <a href="mailto:giampiero.marra@ucl.ac.uk">giampiero.marra@ucl.ac.uk</a>
</p>


<h3>References</h3>

<p>Robert C. and  Casella G. (2004). Monte Carlo Statistical Methods. New York: Springer-Verlag.
</p>
<p>Ripley B. D. (1987) Stochastic Simulation. New York: John Wiley &amp; Sons, Inc.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gjrm">gjrm</a></code> 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## see examples for gjrm
</code></pre>

<hr>
<h2 id='llpsi'>Internal Function</h2><span id='topic+llpsi'></span>

<h3>Description</h3>

<p>Log-logistic robust function.</p>


<h3>Author(s)</h3>

<p>Maintainer: Giampiero Marra <a href="mailto:giampiero.marra@ucl.ac.uk">giampiero.marra@ucl.ac.uk</a>
</p>

<hr>
<h2 id='LM.bpm'>Lagrange Multiplier Test (Score Test)</h2><span id='topic+LM.bpm'></span>

<h3>Description</h3>

 
<p>Before fitting a bivariate probit model, <code>LM.bpm</code> can be used to test the hypothesis of absence of endogeneity, 
correlated model equations/errors 
or non-random sample selection.</p>


<h3>Usage</h3>

<pre><code class='language-R'>
LM.bpm(formula, data = list(), weights = NULL, subset = NULL, model, 
       hess = TRUE)

</code></pre>


<h3>Arguments</h3>

 
<table>
<tr><td><code id="LM.bpm_+3A_formula">formula</code></td>
<td>
<p>A list of two formulas, one for equation 1 and the other for equation 2. <code>s</code> terms are used to specify 
smooth smooth functions of predictors. Note that if <code>model = "BSS"</code> then the first formula MUST refer 
to the selection equation.</p>
</td></tr> 
<tr><td><code id="LM.bpm_+3A_data">data</code></td>
<td>
<p>An optional data frame, list or environment containing the variables in the model.  If not found in <code>data</code>, the
variables are taken from <code>environment(formula)</code>.</p>
</td></tr> 
<tr><td><code id="LM.bpm_+3A_weights">weights</code></td>
<td>
<p>Optional vector of prior weights to be used in fitting.</p>
</td></tr> 
<tr><td><code id="LM.bpm_+3A_subset">subset</code></td>
<td>
<p>Optional vector specifying a subset of observations to be used in the fitting process.</p>
</td></tr>
<tr><td><code id="LM.bpm_+3A_model">model</code></td>
<td>
<p>It indicates the type of model to be used in the analysis. Possible values are &quot;B&quot; (bivariate model) and 
&quot;BSS&quot; (bivariate model with sample selection). The two marginal equations have probit links.</p>
</td></tr>
<tr><td><code id="LM.bpm_+3A_hess">hess</code></td>
<td>
<p>If <code>FALSE</code> then the expected (rather than observed) information matrix is employed.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This Lagrange multiplier test (also known as score test) is used here for testing the null 
hypothesis that <code class="reqn">\theta</code> is equal to 0 (i.e. no endogeneity, non-random sample selection or 
correlated model equations/errors, depending 
on  the model being fitted). Its main advantage is that it does 
not require an estimate of the model parameter vector under the alternative hypothesis. Asymptotically, it takes a Chi-squared distribution 
with one degree of freedom. Full details can be found in Marra et al. (2014) and Marra et al. (2017).
</p>


<h3>Value</h3>

<p>It returns a numeric p-value corresponding to the null hypothesis that the correlation, <code class="reqn">\theta</code>, is equal to 0.
</p>


<h3>WARNINGS</h3>

<p>This test's implementation is ONLY valid for bivariate binary probit models with normal errors.
</p>


<h3>Author(s)</h3>

<p>Maintainer: Giampiero Marra <a href="mailto:giampiero.marra@ucl.ac.uk">giampiero.marra@ucl.ac.uk</a>
</p>


<h3>References</h3>

<p>Marra G., Radice R. and Filippou P. (2017), Regression Spline Bivariate Probit Models: A Practical Approach to Testing for Exogeneity. <em>Communications in Statistics - Simulation and Computation</em>, 46(3), 2283-2298.
</p>
<p>Marra G., Radice R. and Missiroli S. (2014), Testing the Hypothesis of Absence of Unobserved Confounding in Semiparametric Bivariate Probit Models. <em>Computational Statistics</em>, 29(3-4), 715-741.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gjrm">gjrm</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## see examples for gjrm
</code></pre>

<hr>
<h2 id='lmc'>Linear Model Fitting with Constraints</h2><span id='topic+lmc'></span>

<h3>Description</h3>

 
<p>Linear model fitting with positivity and sum-to-one constraints on the model's coefficients. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
lmc(y, X, start.v = NULL, lambda = 1, pen = "none", gamma = 1, a = 3.7) 
        
        
</code></pre>


<h3>Arguments</h3>

 
<table>
<tr><td><code id="lmc_+3A_y">y</code></td>
<td>
<p>Response vector.</p>
</td></tr> 
<tr><td><code id="lmc_+3A_x">X</code></td>
<td>
<p>Design matrix.</p>
</td></tr> 
<tr><td><code id="lmc_+3A_start.v">start.v</code></td>
<td>
<p>Starting values.</p>
</td></tr>
<tr><td><code id="lmc_+3A_lambda">lambda</code></td>
<td>
<p>Tuning parameter.</p>
</td></tr> 
<tr><td><code id="lmc_+3A_pen">pen</code></td>
<td>
<p>Type of penalty. Choices are: none, ridge, lasso, alasso, scad.</p>
</td></tr> 
<tr><td><code id="lmc_+3A_gamma">gamma</code></td>
<td>
<p>Power parameter of adaptive lasso.</p>
</td></tr> 
<tr><td><code id="lmc_+3A_a">a</code></td>
<td>
<p>Scad parameter.</p>
</td></tr> 
</table>


<h3>Details</h3>

<p>Linear model fitting with positivity and sum-to-one constraints on the model's coefficients.
</p>


<h3>Value</h3>

<p>The function returns an object of class <code>lmc</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run:  

library(GJRM)

set.seed(1)

n    &lt;- 1000
beta &lt;- c(0.07, 0.08, 0.21, 0.12, 0.15, 0.17, 0.2)
l    &lt;- length(beta)
X    &lt;- matrix(runif(n*l), n, l)

y    &lt;- X%*%beta + rnorm(n)

out &lt;- lmc(y, X)
conv.check(out)

out1 &lt;- lmc(y, X, start.v = beta)
conv.check(out1)


coef(out)                    # estimated   coefficients
round(out$c.coefficients, 3) # constrained coefficients
sum(out$c.coefficients)

round(out1$c.coefficients, 3) 
sum(out1$c.coefficients)


# penalised estimation

out1 &lt;- lmc(y, X, pen = "alasso", lambda = 0.02)
conv.check(out1)

coef(out1)                    
round(out1$c.coefficients, 3)
sum(out1$c.coefficients)


AIC(out, out1)
BIC(out, out1)

round(cbind(out$c.coefficients, out1$c.coefficients), 3)

# scad

n    &lt;- 10000
beta &lt;- c(0.2, 0, 0, 0.02, 0.01, 0.01, 0.01, 0.08, 0.21, 0.12, 0.15, 0.17, 0.02)
l    &lt;- length(beta)
X    &lt;- matrix(runif(n*l), n, l)

y    &lt;- X%*%beta + rnorm(n)

out1 &lt;- lmc(y, X, pen = "scad", lambda = 0.01)
conv.check(out1)

coef(out1)  
sum(out1$c.coefficients)
                  
round(cbind(beta, out1$c.coefficients), 2)


## End(Not run)

</code></pre>

<hr>
<h2 id='logLik.SemiParBIV'>Extract the log likelihood for a fitted copula model</h2><span id='topic+logLik.SemiParBIV'></span><span id='topic+logLik.ggmtrust'></span><span id='topic+logLik.lmc'></span>

<h3>Description</h3>

<p>It extracts the log-likelihood for a fitted <code>gjrm</code> model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'SemiParBIV'
logLik(object, ...)
</code></pre>


<h3>Arguments</h3>

 
<table>
<tr><td><code id="logLik.SemiParBIV_+3A_object">object</code></td>
<td>
<p>A fitted <code>gjrm</code> object.</p>
</td></tr>
<tr><td><code id="logLik.SemiParBIV_+3A_...">...</code></td>
<td>
<p>Un-used for this function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Modification of the classic <code>logLik</code> which accounts for the estimated degrees of freedom used in <code>gjrm</code>.
This function is provided so that information criteria work correctly by using the correct number of degrees 
of freedom. 
</p>


<h3>Value</h3>

<p>Standard <code><a href="stats.html#topic+logLik">logLik</a></code> object.
</p>


<h3>Author(s)</h3>

<p>Maintainer: Giampiero Marra <a href="mailto:giampiero.marra@ucl.ac.uk">giampiero.marra@ucl.ac.uk</a>
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+AIC">AIC</a></code>, <code><a href="stats.html#topic+BIC">BIC</a></code>
</p>

<hr>
<h2 id='mb'>Nonparametric (worst-case and IV) Manski's bounds</h2><span id='topic+mb'></span>

<h3>Description</h3>

 
<p><code>mb</code> can be used to calculate the (worst-case and IV) Manski's bounds and confidence interval covering the true effect of interest
with a fixed probability.</p>


<h3>Usage</h3>

<pre><code class='language-R'>
mb(treat, outc, IV = NULL, model, B = 100, sig.lev = 0.05)

</code></pre>


<h3>Arguments</h3>

 
<table>
<tr><td><code id="mb_+3A_treat">treat</code></td>
<td>
<p>Binary treatment/selection variable.</p>
</td></tr>
<tr><td><code id="mb_+3A_outc">outc</code></td>
<td>
<p>Binary outcome variable.</p>
</td></tr> 
<tr><td><code id="mb_+3A_iv">IV</code></td>
<td>
<p>An instrumental binary variable can be used if available.</p>
</td></tr> 
<tr><td><code id="mb_+3A_model">model</code></td>
<td>
<p>Possible values are &quot;B&quot; (model with endogenous variable) and &quot;BSS&quot; (model with non-random sample selection).</p>
</td></tr>
<tr><td><code id="mb_+3A_b">B</code></td>
<td>
<p>Number of bootstrap replicates. This is used to obtain some components needed for confidence interval calculations.</p>
</td></tr> 
<tr><td><code id="mb_+3A_sig.lev">sig.lev</code></td>
<td>
<p>Significance level.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Based on Manski (1990), this function returns the nonparametric lower and upper (worst-case) Manski's bounds for the average 
treatment effect (ATE) when <code>model = "B"</code> or prevalence when <code>model = "BSS"</code>. When an IV is employed
the function returns IV Manski bounds.
</p>
<p>For comparison, it also returns the estimated effect assuming random assignment (i.e., the treatment received or selection relies 
on the assumption of ignorable observed and unobserved selection). Note that this is equivalent to 
what provided by <code><a href="#topic+AT">AT</a></code> or <code><a href="#topic+prev">prev</a></code> when <code>type = "naive"</code>, and is different from what obtained
by <code><a href="#topic+AT">AT</a></code> or <code><a href="#topic+prev">prev</a></code> when <code>type = "univariate"</code> as observed confounders are accounted for
and the assumption here is of ignorable unobserved selection.
</p>
<p>A confidence interval covering the true ATE/prevalence with a fixed probability is also provided. This is based on the approach 
described in Imbens and Manski (2004). NOTE that this interval is typically very close (if not identical) to the lower
and upper bounds.
</p>
<p>The ATE can be at most 1 (or 100 in percentage) and the worst-case Manski's bounds have width 1. This means that 
0 is always included within the possibilites of these bounds. Nevertheless, this may be useful to check whether 
the effect from a bivariate recursive model is included within the possibilites of the bounds. 
</p>
<p>When estimating a prevalance the worst-case Manski's bounds have width equal to 
the non-response probability,
which provides a measure of the uncertainty about the prevalence caused by non-response. Again, this may be useful to check whether 
the prevalence from a bivariate non-random sample selection model is included within the possibilites of the bounds.
</p>
<p>See <code><a href="#topic+gjrm">gjrm</a></code> for some examples.
</p>


<h3>Value</h3>

<table>
<tr><td><code>LB</code>, <code>UP</code></td>
<td>
<p>Lower and upper bounds for the true effect of interest.</p>
</td></tr>
<tr><td><code>CI</code></td>
<td>
<p>Confidence interval covering the true effect of interest with a fixed probability.</p>
</td></tr>
<tr><td><code>ate.ra</code></td>
<td>
<p>Estimated effect of interest assuming random assignment.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Maintainer: Giampiero Marra <a href="mailto:giampiero.marra@ucl.ac.uk">giampiero.marra@ucl.ac.uk</a>
</p>


<h3>References</h3>

<p>Manski C.F. (1990), Nonparametric Bounds on Treatment Effects. <em>American Economic Review, Papers and Proceedings</em>, 80(2), 319-323.
</p>
<p>Imbens G.W. and Manski C.F (2004), Confidence Intervals for Partially Identified Parameters. <em>Econometrica</em>, 72(6), 1845-1857.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gjrm">gjrm</a></code>  
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## see examples for gjrm
</code></pre>

<hr>
<h2 id='meps'>MEPS data</h2><span id='topic+meps'></span>

<h3>Description</h3>

<p>2008 MEPS data.</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(meps)
</code></pre>


<h3>Format</h3>

 <p><code>meps</code> is a 18592 row data frame with the following columns 
</p>

<dl>
<dt>bmi</dt><dd><p>body mass index.</p>
</dd>
<dt>age</dt><dd><p>age in years.</p>
</dd>
<dt>gender</dt><dd><p>equal to 1 if male.</p>
</dd>
<dt>race</dt><dd><p>levels: 2 white, 3 black, 4 native American, 5 others.</p>
</dd>
<dt>education</dt><dd><p>years of education.</p>
</dd>
<dt>health</dt><dd><p>levels: 5 excellent, 6 very good, 7 good, 8 fair, 9 poor.</p>
</dd>
<dt>limitation</dt><dd><p>equal to 1 if health limits physical activity.</p>
</dd>
<dt>region</dt><dd><p>levels: 2 northeast, 3 mid-west, 4 south, 5 west.</p>
</dd>
<dt>private</dt><dd><p>equal to 1 if individual has private health insurance.</p>
</dd>
<dt>visits.hosp</dt><dd><p>equal to 1 if at least one visit to hospital outpatient departments.</p>
</dd>
<dt>diabetes</dt><dd><p>equal to 1 if diabetic.</p>
</dd>
<dt>hypertension</dt><dd><p>equal to 1 if hypertensive.</p>
</dd>
<dt>hyperlipidemia</dt><dd><p>equal to 1 if hyperlipidemic.</p>
</dd>
<dt>income</dt><dd><p>income (000's).</p>
</dd>
</dl>



<h3>Source</h3>

<p>The data have been obtained from http://www.meps.ahrq.gov/. 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run:  

###################################################
###################################################

library("GJRM")
data("meps", package = "GJRM") 

###################################################
# Bivariate brobit models with endogenous treatment
###################################################

treat.eq &lt;- private ~ s(bmi) + s(income) + s(age) + s(education) +
                      as.factor(health) + as.factor(race) +
                      as.factor(limitation) + as.factor(region) + 
                      gender  + hypertension + hyperlipidemia + diabetes
out.eq &lt;- visits.hosp ~ private + s(bmi) + s(income) + s(age) + 
                        s(education) + as.factor(health) + 
                        as.factor(race) + as.factor(limitation) + 
                        as.factor(region) + gender + hypertension + 
                        hyperlipidemia + diabetes

f.list &lt;- list(treat.eq, out.eq) 
mr     &lt;- c("probit", "probit")
bpN    &lt;- gjrm(f.list, data = meps, margins = mr,                  model = "B")
bpF    &lt;- gjrm(f.list, data = meps, margins = mr, copula = "F",    model = "B")
bpC0   &lt;- gjrm(f.list, data = meps, margins = mr, copula = "C0",   model = "B")
bpC180 &lt;- gjrm(f.list, data = meps, margins = mr, copula = "C180", model = "B")
bpJ0   &lt;- gjrm(f.list, data = meps, margins = mr, copula = "J0",   model = "B")
bpJ180 &lt;- gjrm(f.list, data = meps, margins = mr, copula = "J180", model = "B")
bpG0   &lt;- gjrm(f.list, data = meps, margins = mr, copula = "G0",   model = "B")
bpG180 &lt;- gjrm(f.list, data = meps, margins = mr, copula = "G180", model = "B")

conv.check(bpJ0)

AIC(bpN, bpF, bpC0, bpC180, bpJ0, bpJ180, bpG0, bpG180) 

set.seed(1)
summary(bpJ0)

#dev.copy(postscript, "contplot.eps")
#dev.off()

par(mfrow = c(2, 2), mar = c(4.5, 4.5, 2, 2), 
    cex.axis = 1.6, cex.lab = 1.6)
plot(bpJ0, eq = 1, seWithMean = TRUE, scale = 0, shade = TRUE, 
     pages = 1, jit = TRUE)

#dev.copy(postscript, "spline1.eps")
#dev.off() 

par(mfrow = c(2, 2), mar = c(4.5, 4.5, 2, 2), 
    cex.axis = 1.6, cex.lab = 1.6)
plot(bpJ0, eq = 2, seWithMean = TRUE, scale = 0, shade = TRUE, 
     pages = 1, jit = TRUE)

#dev.copy(postscript, "spline2.eps")
#dev.off() 

set.seed(1)
AT(bpJ0, nm.end = "private", hd.plot = TRUE, cex.axis = 1.5, 
   cex.lab = 1.5, cex.main = 1.6)

#dev.copy(postscript, "hd.plotAT.eps")
#dev.off()

AT(bpJ0, nm.end = "private", type = "univariate")

AT(bpJ0, nm.end = "private", type = "naive")


## End(Not run)

#

</code></pre>

<hr>
<h2 id='numgh'>Internal Function</h2><span id='topic+numgh'></span><span id='topic+numch'></span><span id='topic+mm'></span>

<h3>Description</h3>

<p>This and other similar internal functions calculate numerical derivatives.</p>


<h3>Author(s)</h3>

<p>Maintainer: Giampiero Marra <a href="mailto:giampiero.marra@ucl.ac.uk">giampiero.marra@ucl.ac.uk</a>
</p>

<hr>
<h2 id='OR'>Causal odds ratio of a binary/continuous/discrete endogenous variable</h2><span id='topic+OR'></span>

<h3>Description</h3>

 
<p><code>OR</code> can be used to calculate the causal odds ratio of a binary/continuous/discrete endogenous predictor/treatment, with 
corresponding interval obtained using posterior simulation.</p>


<h3>Usage</h3>

<pre><code class='language-R'>
OR(x, nm.end, E = TRUE, treat = TRUE, type = "joint", ind = NULL, 
   n.sim = 100, prob.lev = 0.05, length.out = NULL, hd.plot = FALSE,
   or.plot = FALSE, 
   main = "Histogram and Kernel Density of Simulated Odds Ratios", 
   xlab = "Simulated Odds Ratios", ...)

</code></pre>


<h3>Arguments</h3>

 
<table>
<tr><td><code id="OR_+3A_x">x</code></td>
<td>
<p>A fitted <code>gjrm</code> object.</p>
</td></tr>
<tr><td><code id="OR_+3A_nm.end">nm.end</code></td>
<td>
<p>Name of the endogenous variable.</p>
</td></tr> 
<tr><td><code id="OR_+3A_e">E</code></td>
<td>
<p>If <code>TRUE</code> then <code>OR</code> calculates the sample OR. If <code>FALSE</code> then it calculates the sample OR 
for the treated individuals only.</p>
</td></tr>  
<tr><td><code id="OR_+3A_treat">treat</code></td>
<td>
<p>If <code>TRUE</code> then <code>OR</code> calculates the OR using the treated only. If <code>FALSE</code> then it calculates the ratio using  
the control group. This only makes sense if <code>E = FALSE</code>.</p>
</td></tr>  
<tr><td><code id="OR_+3A_type">type</code></td>
<td>
<p>This argument can take three values: <code>"naive"</code> (the effect is calculated ignoring the presence of observed and 
unobserved confounders), <code>"univariate"</code> (the effect is obtained from the univariate model which neglects 
the presence of unobserved confounders) and <code>"joint"</code> (the effect is obtained from the bivariate model which accounts for observed and unobserved confounders).</p>
</td></tr>
<tr><td><code id="OR_+3A_ind">ind</code></td>
<td>
<p>Binary logical variable. It can be used to calculate the OR for a subset of the data. Note that it does not make sense to use <code>ind</code> 
when some observations are excluded from the OR calculation (e.g., when using <code>E = FALSE</code>).</p>
</td></tr>  
<tr><td><code id="OR_+3A_n.sim">n.sim</code></td>
<td>
<p>Number of simulated coefficient vectors from the posterior distribution of the estimated model parameters. This is used 
when <code>delta = FALSE</code>. It may be increased if more precision is required.</p>
</td></tr> 
<tr><td><code id="OR_+3A_prob.lev">prob.lev</code></td>
<td>
<p>Overall probability of the left and right tails of the OR distribution used for interval calculations.</p>
</td></tr> 
<tr><td><code id="OR_+3A_length.out">length.out</code></td>
<td>
<p>Ddesired length of the sequence to be used when calculating the effect that a continuous/discrete
treatment has on a binary outcome.</p>
</td></tr>
<tr><td><code id="OR_+3A_hd.plot">hd.plot</code></td>
<td>
<p>If <code>TRUE</code> then a plot of the histogram and kernel density estimate of the simulated odds ratios is produced. This can 
only be produced when binary responses are used.</p>
</td></tr>
<tr><td><code id="OR_+3A_or.plot">or.plot</code></td>
<td>
<p>For the case of continuous/discrete endogenous variable and binary outcome, if <code>TRUE</code> then a plot (on the log scale)  
showing the odd ratios that the binary outcome is equal to 1 for each incremental value of the endogenous variable 
and respective intervals is produced.</p>
</td></tr>
<tr><td><code id="OR_+3A_main">main</code></td>
<td>
<p>Title for the plot.</p>
</td></tr>
<tr><td><code id="OR_+3A_xlab">xlab</code></td>
<td>
<p>Title for the x axis.</p>
</td></tr>
<tr><td><code id="OR_+3A_...">...</code></td>
<td>
<p>Other graphics parameters to pass on to plotting commands. These are used only when <code>hd.plot = TRUE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>OR calculates the causal odds ratio for a binary/continuous/discrete treatment. Posterior simulation is used to obtain a 
confidence/credible interval. 
</p>


<h3>Value</h3>

<table>
<tr><td><code>prob.lev</code></td>
<td>
<p>Probability level used.</p>
</td></tr>
<tr><td><code>sim.OR</code></td>
<td>
<p>It returns a vector containing simulated values of the average OR. This 
is used to calculate intervals.</p>
</td></tr>           
<tr><td><code>Ratios</code></td>
<td>
<p>For the case of continuous/discrete endogenous treatment and binary outcome, it returns a matrix made up of 
three columns containing the odds ratios for each incremental value in the endogenous variable and respective intervals.</p>
</td></tr>            
</table>


<h3>Author(s)</h3>

<p>Maintainer: Giampiero Marra <a href="mailto:giampiero.marra@ucl.ac.uk">giampiero.marra@ucl.ac.uk</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+GJRM-package">GJRM-package</a></code>, <code><a href="#topic+gjrm">gjrm</a></code>  
</p>

<hr>
<h2 id='PE'>Partial effect from a binary bivariate model</h2><span id='topic+PE'></span>

<h3>Description</h3>

 
<p><code>PE</code> can be used to calculate the sample treatment effect from a a binary bivariate model, with 
corresponding interval obtained using posterior simulation.</p>


<h3>Usage</h3>

<pre><code class='language-R'>
PE(x1, idx, n.sim = 100, prob.lev = 0.05, 
   hd.plot = FALSE, 
   main = "Histogram and Kernel Density of Simulated Average Effects", 
   xlab = "Simulated Average Effects", ...)

</code></pre>


<h3>Arguments</h3>

 
<table>
<tr><td><code id="PE_+3A_x1">x1</code></td>
<td>
<p>A fitted <code>gjrm</code> object.</p>
</td></tr>
<tr><td><code id="PE_+3A_idx">idx</code></td>
<td>
<p>This is useful to pick a particular individual and must be provided.</p>
</td></tr>
<tr><td><code id="PE_+3A_n.sim">n.sim</code></td>
<td>
<p>Number of simulated coefficient vectors from the posterior distribution of the estimated model parameters. This is used 
when <code>delta = FALSE</code>. It may be increased if more precision is required.</p>
</td></tr> 
<tr><td><code id="PE_+3A_prob.lev">prob.lev</code></td>
<td>
<p>Overall probability of the left and right tails of the AT distribution used for interval calculations.</p>
</td></tr> 
<tr><td><code id="PE_+3A_hd.plot">hd.plot</code></td>
<td>
<p>If <code>TRUE</code> then a plot of the histogram and kernel density estimate of the simulated average effects is produced.</p>
</td></tr>
<tr><td><code id="PE_+3A_main">main</code></td>
<td>
<p>Title for the plot.</p>
</td></tr>
<tr><td><code id="PE_+3A_xlab">xlab</code></td>
<td>
<p>Title for the x axis.</p>
</td></tr>
<tr><td><code id="PE_+3A_...">...</code></td>
<td>
<p>Other graphics parameters to pass on to plotting commands. These are used only when <code>hd.plot = TRUE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>PE measures the sample average effect from a binary bivariate model when a binary response (associated 
with a continuous outcome) takes values 0 and 1. Posterior simulation is used to obtain a confidence/credible interval. 
</p>


<h3>Author(s)</h3>

<p>Maintainer: Giampiero Marra <a href="mailto:giampiero.marra@ucl.ac.uk">giampiero.marra@ucl.ac.uk</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+GJRM-package">GJRM-package</a></code>, <code><a href="#topic+gjrm">gjrm</a></code>
</p>

<hr>
<h2 id='pen'>Internal Function</h2><span id='topic+pen'></span><span id='topic+penCor'></span>

<h3>Description</h3>

<p>It provides an overall penalty matrix in a format suitable for estimation conditional on smoothing parameters.</p>


<h3>Author(s)</h3>

<p>Maintainer: Giampiero Marra <a href="mailto:giampiero.marra@ucl.ac.uk">giampiero.marra@ucl.ac.uk</a>
</p>

<hr>
<h2 id='plot.SemiParBIV'>Plotting function</h2><span id='topic+plot.SemiParBIV'></span>

<h3>Description</h3>

<p>It takes a fitted <code>gjrm</code> object produced 
by <code>gjrm()</code> and 
plots the estimated smooth functions on the scale of the linear predictors. This function is a 
wrapper of <code>plot.gam()</code> in <code>mgcv</code>. Please see 
the documentation of <code>plot.gam()</code> for full details. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'SemiParBIV'
plot(x, eq, ...)

</code></pre>


<h3>Arguments</h3>

 
<table>
<tr><td><code id="plot.SemiParBIV_+3A_x">x</code></td>
<td>
<p>A fitted <code>gjrm</code> object.</p>
</td></tr>
<tr><td><code id="plot.SemiParBIV_+3A_eq">eq</code></td>
<td>
<p>The equation from which smooth terms should be considered for printing.</p>
</td></tr>
<tr><td><code id="plot.SemiParBIV_+3A_...">...</code></td>
<td>
<p>Other graphics parameters to pass on to plotting commands, as described for <code>plot.gam()</code> in <code>mgcv</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function produces plots showing the smooth terms of a fitted semiparametric bivariate probit model. In the case of 1-D smooths, the 
x axis of each plot is labelled using the name of the regressor, while the y axis is labelled as <code>s(regr, edf)</code> 
where <code>regr</code> is the regressor's name, and <code>edf</code> the effective degrees of freedom of the smooth. For 2-D smooths, perspective 
plots are produced with the x axes labelled with the first and second variable names and the y axis 
is labelled as <code>s(var1, var2, edf)</code>, which indicates the variables of which the term is a function and the <code>edf</code> for the term. 
</p>
<p>If <code>seWithMean = TRUE</code> then the intervals include the uncertainty about the overall mean. Note that the smooths are still shown 
centred. The theoretical arguments 
and simulation study of Marra and Wood (2012) suggest that <code>seWithMean = TRUE</code> results in intervals with
close to nominal frequentist coverage probabilities. 
</p>


<h3>Value</h3>

<p>The function generates plots.
</p>


<h3>WARNING</h3>

 
<p>The function can not deal with smooths of more than 2 variables. 
</p>


<h3>Author(s)</h3>

<p>Maintainer: Giampiero Marra <a href="mailto:giampiero.marra@ucl.ac.uk">giampiero.marra@ucl.ac.uk</a>
</p>


<h3>References</h3>

<p>Marra G. and Wood S.N. (2012), Coverage Properties of Confidence Intervals for Generalized Additive Model Components. <em>Scandinavian Journal of Statistics</em>, 39(1), 53-74.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gjrm">gjrm</a></code>
</p>

<hr>
<h2 id='polys.map'>Geographic map with regions defined as polygons</h2><span id='topic+polys.map'></span>

<h3>Description</h3>

 
<p>This function produces a map with geographic regions defined by polygons. It is essentially the same function as
<code>polys.plot()</code> in <code>mgcv</code> but with added arguments <code>zlim</code> and <code>rev.col</code> and a wider set of choices for 
<code>scheme</code>. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
polys.map(lm, z, scheme = "gray", lab = "", zlim, rev.col = TRUE, ...)



</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="polys.map_+3A_lm">lm</code></td>
<td>
<p>Named list of matrices where each matrix has two columns. The matrix rows each define the 
vertex of a boundary polygon.</p>
</td></tr>
<tr><td><code id="polys.map_+3A_z">z</code></td>
<td>
<p>A vector of values associated with each area (item) of <code>lm</code>. </p>
</td></tr>
<tr><td><code id="polys.map_+3A_scheme">scheme</code></td>
<td>
<p>Possible values are <code>"heat"</code>, <code>"terrain"</code>, <code>"topo"</code>, <code>"cm"</code> and <code>"gray"</code>, indicating how to fill 
the polygons in accordance with the value of <code>z</code>.</p>
</td></tr>
<tr><td><code id="polys.map_+3A_lab">lab</code></td>
<td>
<p>label for plot.</p>
</td></tr>
<tr><td><code id="polys.map_+3A_zlim">zlim</code></td>
<td>
<p>If missing then the range of z will be chosen using <code>pretty(z)</code> otherwise the range provided will be used.</p>
</td></tr>  
<tr><td><code id="polys.map_+3A_rev.col">rev.col</code></td>
<td>
<p>If <code>FALSE</code> then coloring scheme is not reversed.</p>
</td></tr>  
<tr><td><code id="polys.map_+3A_...">...</code></td>
<td>
<p>other arguments to pass to plot.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See help file of <code>polys.plot</code> in <code>mgcv</code>.
</p>


<h3>Value</h3>

<p>It produces a plot.</p>


<h3>Author(s)</h3>

<p>Maintainer: Giampiero Marra <a href="mailto:giampiero.marra@ucl.ac.uk">giampiero.marra@ucl.ac.uk</a>
</p>

<hr>
<h2 id='polys.setup'>Set up geographic polygons</h2><span id='topic+polys.setup'></span>

<h3>Description</h3>

 
<p>This function creates geographic polygons in a format suitable for smoothing. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
polys.setup(object)



</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="polys.setup_+3A_object">object</code></td>
<td>
<p>An RDS file object as extracted from http://www.gadm.org.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>It produces a list with polygons (<code>polys</code>), and various names (<code>names0</code>, <code>names1</code> - first level of aggregation, 
<code>names2</code> - second level of aggregation).</p>


<h3>Author(s)</h3>

<p>Maintainer: Giampiero Marra <a href="mailto:giampiero.marra@ucl.ac.uk">giampiero.marra@ucl.ac.uk</a>
</p>
<p>Thanks to Guy Harling for suggesting the implementation of this function.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
?hiv

</code></pre>

<hr>
<h2 id='post.check'>Diagnostic plots for discrete/continuous response margin</h2><span id='topic+post.check'></span><span id='topic+int.postcheck'></span>

<h3>Description</h3>

 
<p>It produces diagnostic plots based on (randomised) quantile residuals. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
post.check(x, main = "Histogram and Density Estimate of Residuals", 
           main2 = "Histogram and Density Estimate of Residuals",
           xlab = "Quantile Residuals", xlab2 = "Quantile Residuals", 
           intervals = FALSE, n.sim = 100, prob.lev = 0.05, ...)

</code></pre>


<h3>Arguments</h3>

 
<table>
<tr><td><code id="post.check_+3A_x">x</code></td>
<td>
<p>A fitted <code>gjrm</code> object.</p>
</td></tr>
<tr><td><code id="post.check_+3A_main">main</code></td>
<td>
<p>Title for the plot.</p>
</td></tr>
<tr><td><code id="post.check_+3A_main2">main2</code></td>
<td>
<p>Title for the plot in the second row. This comes into play only when fitting models with two non-binary margins.</p>
</td></tr>
<tr><td><code id="post.check_+3A_xlab">xlab</code></td>
<td>
<p>Title for the x axis.</p>
</td></tr>
<tr><td><code id="post.check_+3A_xlab2">xlab2</code></td>
<td>
<p>Title for the x axis in the second row. As above.</p>
</td></tr>
<tr><td><code id="post.check_+3A_intervals">intervals</code></td>
<td>
<p>If <code>TRUE</code> then intervals for the qqplots are produced.</p>
</td></tr>   
<tr><td><code id="post.check_+3A_n.sim">n.sim</code></td>
<td>
<p>Number of replicate datasets used to simulate quantiles of the residual distribution.</p>
</td></tr> 
<tr><td><code id="post.check_+3A_prob.lev">prob.lev</code></td>
<td>
<p>Overall probability of the left and right tails of the probabilities' distributions used for interval calculations.</p>
</td></tr> 
<tr><td><code id="post.check_+3A_...">...</code></td>
<td>
<p>Other graphics parameters to pass on to plotting commands.</p>
</td></tr>
</table>


<h3>Details</h3>

 
<p>If the model fits the response well then the plots should look normally distributed.
When fitting models with discrete and/or continuous margins, four plots will be produced. In this case,
the arguments <code>main2</code> and <code>xlab2</code> come into play and allow for different
labelling across the plots. 
</p>


<h3>Value</h3>

<table>
<tr><td><code>qr</code></td>
<td>
<p>It returns the (randomised) quantile residuals for the continuous or discrete margin when 
fitting a model that involves a binary response.</p>
</td></tr>
<tr><td><code>qr1</code></td>
<td>
<p>As above but for first equation (this applies when fitting models with continuous/discrete margins).</p>
</td></tr>
<tr><td><code>qr2</code></td>
<td>
<p>As above but for second equation.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Maintainer: Giampiero Marra <a href="mailto:giampiero.marra@ucl.ac.uk">giampiero.marra@ucl.ac.uk</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gjrm">gjrm</a></code>  
</p>

<hr>
<h2 id='pred.gp'>Function to predict quantiles from GP and DGP distributions</h2><span id='topic+pred.gp'></span>

<h3>Description</h3>

<p>It takes a fitted <code>gamlss</code> object produced 
by <code>gamlss()</code> and 
produces the desired quntities and respective intervals. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pred.gp(x, p = 0.5, newdata, n.sim = 100, prob.lev = 0.05)
</code></pre>


<h3>Arguments</h3>

 
<table>
<tr><td><code id="pred.gp_+3A_x">x</code></td>
<td>
<p>A fitted <code>gamlss</code> object.</p>
</td></tr>
<tr><td><code id="pred.gp_+3A_p">p</code></td>
<td>
<p>Value of p.</p>
</td></tr>
<tr><td><code id="pred.gp_+3A_newdata">newdata</code></td>
<td>
<p>A data frame or list containing the values of the model covariates at which predictions are required. 
If not provided then predictions corresponding to the original data are returned.
When newdata is provided, it should contain all the variables needed for prediction.</p>
</td></tr>
<tr><td><code id="pred.gp_+3A_n.sim">n.sim</code></td>
<td>
<p>The number of simulated coefficient vectors from the posterior distribution of the estimated model parameters. This is used 
to calculate intervals. It may be increased if
more precision is required.</p>
</td></tr> 
<tr><td><code id="pred.gp_+3A_prob.lev">prob.lev</code></td>
<td>
<p>Probability of the left and right tails of the posterior distribution used for interval calculations.</p>
</td></tr> 
</table>


<h3>Author(s)</h3>

<p>Maintainer: Giampiero Marra <a href="mailto:giampiero.marra@ucl.ac.uk">giampiero.marra@ucl.ac.uk</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gamlss">gamlss</a></code>
</p>

<hr>
<h2 id='pred.mvt'>Function to predict mean and variance of marginal distributions, as well as Kendall's tau</h2><span id='topic+pred.mvt'></span>

<h3>Description</h3>

<p>It takes a fitted <code>gjrm</code> object produced 
by <code>gjrm()</code> and 
produces predictions and respective intervals. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pred.mvt(x, eq, fun = "mean", n.sim = 100, prob.lev = 0.05, smooth.no = NULL, ...)
</code></pre>


<h3>Arguments</h3>

 
<table>
<tr><td><code id="pred.mvt_+3A_x">x</code></td>
<td>
<p>A fitted <code>gjrm</code> object.</p>
</td></tr>
<tr><td><code id="pred.mvt_+3A_eq">eq</code></td>
<td>
<p>The equation number.</p>
</td></tr>
<tr><td><code id="pred.mvt_+3A_fun">fun</code></td>
<td>
<p>Either mean, variance or tau.</p>
</td></tr>
<tr><td><code id="pred.mvt_+3A_n.sim">n.sim</code></td>
<td>
<p>The number of simulated coefficient vectors from the posterior distribution of the estimated model parameters. This is used 
to calculate intervals. It may be increased if
more precision is required.</p>
</td></tr> 
<tr><td><code id="pred.mvt_+3A_prob.lev">prob.lev</code></td>
<td>
<p>Probability of the left and right tails of the posterior distribution used for interval calculations.</p>
</td></tr> 
<tr><td><code id="pred.mvt_+3A_smooth.no">smooth.no</code></td>
<td>
<p>Smooth number if the interest is in a particular smooth and not the additive predictor(s).</p>
</td></tr> 
<tr><td><code id="pred.mvt_+3A_...">...</code></td>
<td>
<p>Other parameters.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Maintainer: Giampiero Marra <a href="mailto:giampiero.marra@ucl.ac.uk">giampiero.marra@ucl.ac.uk</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gjrm">gjrm</a></code>
</p>

<hr>
<h2 id='predict.CopulaCLM'>Prediction function</h2><span id='topic+predict.CopulaCLM'></span>

<h3>Description</h3>

<p>It takes a fitted <code>gjrm</code> object for the ordinal-continuous case and, 
for each equation, produces predictions 
for a new set of values of the model covariates or the original values used for the model fit. 
Standard errors of predictions can be produced and are based on the posterior distribution of the model coefficients.  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
## S3 method for class 'CopulaCLM'
predict(object, eq, type = "link", ...)


</code></pre>


<h3>Arguments</h3>

 
<table>
<tr><td><code id="predict.CopulaCLM_+3A_object">object</code></td>
<td>
<p>A fitted <code>gjrm</code> object.</p>
</td></tr>
<tr><td><code id="predict.CopulaCLM_+3A_eq">eq</code></td>
<td>
<p>The equation to be considered for prediction.</p>
</td></tr>
<tr><td><code id="predict.CopulaCLM_+3A_type">type</code></td>
<td>
<p>Type of prediction.</p>
</td></tr>
<tr><td><code id="predict.CopulaCLM_+3A_...">...</code></td>
<td>
<p>Other arguments as in <code>predict.gam()</code> in <code>mgcv</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Maintainer: Giampiero Marra <a href="mailto:giampiero.marra@ucl.ac.uk">giampiero.marra@ucl.ac.uk</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gjrm">gjrm</a></code>
</p>

<hr>
<h2 id='predict.SemiParBIV'>Prediction function</h2><span id='topic+predict.SemiParBIV'></span>

<h3>Description</h3>

<p>It takes a fitted <code>gjrm</code> object and, 
for each equation, produces predictions 
for a new set of values of the model covariates or the original values used for the model fit. 
Standard errors of predictions can be produced and are based on the posterior distribution of the model coefficients. This function is a 
wrapper for <code>predict.gam()</code> in <code>mgcv</code>. Please see the documentation of <code>predict.gam()</code> for full details. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
## S3 method for class 'SemiParBIV'
predict(object, eq, ...)


</code></pre>


<h3>Arguments</h3>

 
<table>
<tr><td><code id="predict.SemiParBIV_+3A_object">object</code></td>
<td>
<p>A fitted <code>gjrm</code> object.</p>
</td></tr>
<tr><td><code id="predict.SemiParBIV_+3A_eq">eq</code></td>
<td>
<p>The equation to be considered for prediction.</p>
</td></tr>
<tr><td><code id="predict.SemiParBIV_+3A_...">...</code></td>
<td>
<p>Other arguments as in <code>predict.gam()</code> in <code>mgcv</code>.</p>
</td></tr>
</table>


<h3>WARNINGS</h3>

<p>When <code>type = "response"</code> this function will provide prediction assuming that the identity link function is adopted.
This means that <code>type = "link"</code> and <code>type = "response"</code> will produce the same results, which for some distributions is fine.
This is because, for internal reasons, the model object used always assumes an identity link. There are other functions in the package
which will produce predictions for the response correctly and we are currently working on extending them to all models in the package.
For all the other <code>type</code> values the function will produce the correct results. 
</p>
<p>When predicting based on a new data set, this function can not return correct predictions for models based 
on a copula value of &quot;C0C90&quot;, &quot;C0C270&quot;, &quot;C180C90&quot;, &quot;C180C270&quot;, &quot;G0G90&quot;, &quot;G0G270&quot;, &quot;G180G90&quot;,
&quot;G180G270&quot;, &quot;J0J90&quot;, &quot;J0J270&quot;, &quot;J180J90&quot; or &quot;J180J270&quot;.
</p>


<h3>Author(s)</h3>

<p>Maintainer: Giampiero Marra <a href="mailto:giampiero.marra@ucl.ac.uk">giampiero.marra@ucl.ac.uk</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gjrm">gjrm</a></code>
</p>

<hr>
<h2 id='prev'>Estimated overall prevalence from sample selection model</h2><span id='topic+prev'></span>

<h3>Description</h3>

 
<p><code>prev</code> can be used to calculate the overall estimated prevalence from a sample selection model 
with binay outcome, with corresponding interval
obtained using the delta method or posterior simulation.</p>


<h3>Usage</h3>

<pre><code class='language-R'>
prev(x, sw = NULL, type = "joint", ind = NULL, delta = FALSE,  
     n.sim = 100, prob.lev = 0.05, hd.plot = FALSE, 
     main = "Histogram and Kernel Density of Simulated Prevalences", 
     xlab = "Simulated Prevalences", ...)

</code></pre>


<h3>Arguments</h3>

 
<table>
<tr><td><code id="prev_+3A_x">x</code></td>
<td>
<p>A fitted <code>gjrm</code> object.</p>
</td></tr>
<tr><td><code id="prev_+3A_sw">sw</code></td>
<td>
<p>Survey weights.</p>
</td></tr>  
<tr><td><code id="prev_+3A_type">type</code></td>
<td>
<p>This argument can take three values: <code>"naive"</code> (the prevalence is calculated ignoring the presence of observed 
and unobserved confounders), <code>"univariate"</code> (the prevalence is obtained from the univariate probit/single imputation model 
which neglects the presence of unobserved confounders) and <code>"joint"</code> (the prevalence is obtained from the 
bivariate/trivariate model 
which accounts for observed and unobserved confounders).</p>
</td></tr>
<tr><td><code id="prev_+3A_ind">ind</code></td>
<td>
<p>Binary logical variable. It can be used to calculate the prevalence for a subset of the data.</p>
</td></tr> 
<tr><td><code id="prev_+3A_delta">delta</code></td>
<td>
<p>If <code>TRUE</code> then the delta method is used for confidence interval calculations, otherwise Bayesian posterior 
simulation is employed.</p>
</td></tr> 
<tr><td><code id="prev_+3A_n.sim">n.sim</code></td>
<td>
<p>Number of simulated coefficient vectors from the posterior distribution of the estimated model parameters. This is used 
when <code>delta = FALSE</code>. It may be increased if more precision is required.</p>
</td></tr>  
<tr><td><code id="prev_+3A_prob.lev">prob.lev</code></td>
<td>
<p>Overall probability of the left and right tails of the prevalence distribution used for interval calculations.</p>
</td></tr>
<tr><td><code id="prev_+3A_hd.plot">hd.plot</code></td>
<td>
<p>If <code>TRUE</code> then a plot of the histogram and kernel density estimate of the simulated prevalences is produced. This can only 
be produced when <code>delta = FALSE</code>.</p>
</td></tr>
<tr><td><code id="prev_+3A_main">main</code></td>
<td>
<p>Title for the plot.</p>
</td></tr>
<tr><td><code id="prev_+3A_xlab">xlab</code></td>
<td>
<p>Title for the x axis.</p>
</td></tr>
<tr><td><code id="prev_+3A_...">...</code></td>
<td>
<p>Other graphics parameters to pass on to plotting commands. These are used only when <code>hd.plot = TRUE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>prev</code> estimates the overall prevalence of a disease (e.g., HIV) when there are missing values that are not at random. 
An interval for the estimated prevalence can be obtained using the delta method or posterior simulation. 
</p>


<h3>Value</h3>

<table>
<tr><td><code>res</code></td>
<td>
<p>It returns three values: lower confidence interval limit, estimated prevalence and upper confidence interval limit.</p>
</td></tr>
<tr><td><code>prob.lev</code></td>
<td>
<p>Probability level used.</p>
</td></tr>
<tr><td><code>sim.prev</code></td>
<td>
<p>If <code>delta = FALSE</code> then it returns a vector containing simulated values of the prevalence. This 
is used to calculate an interval.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Authors: Giampiero Marra, Rosalba Radice, Guy Harling, Mark E McGovern 
</p>
<p>Maintainer: Giampiero Marra <a href="mailto:giampiero.marra@ucl.ac.uk">giampiero.marra@ucl.ac.uk</a>
</p>


<h3>References</h3>

<p>Marra G., Radice R., Barnighausen T., Wood S.N. and McGovern M.E. (2017), A Simultaneous Equation Approach to Estimating HIV Prevalence with Non-Ignorable Missing Responses. <em>Journal of the American Statistical Association</em>, 112(518), 484-496.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+GJRM-package">GJRM-package</a></code>, <code><a href="#topic+gjrm">gjrm</a></code>  
</p>

<hr>
<h2 id='print.AT'>Print an AT object</h2><span id='topic+print.AT'></span>

<h3>Description</h3>

<p>The print method for an <code>AT</code> object.</p>


<h3>Usage</h3>

<pre><code class='language-R'>

## S3 method for class 'AT'
print(x, ...)


</code></pre>


<h3>Arguments</h3>

 
<table>
<tr><td><code id="print.AT_+3A_x">x</code></td>
<td>
<p><code>AT</code> object produced by <code>AT()</code>.</p>
</td></tr>
<tr><td><code id="print.AT_+3A_...">...</code></td>
<td>
<p>Other arguments.</p>
</td></tr>
</table>


<h3>Details</h3>

 
<p><code>print.AT</code> prints the lower confidence interval limit, estimated AT and upper confidence interval limit. 
</p>


<h3>Author(s)</h3>

<p>Maintainer: Giampiero Marra <a href="mailto:giampiero.marra@ucl.ac.uk">giampiero.marra@ucl.ac.uk</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+AT">AT</a></code>
</p>

<hr>
<h2 id='print.copulaSampleSel'>Print a copulaSampleSel object</h2><span id='topic+print.copulaSampleSel'></span>

<h3>Description</h3>

<p>The print method for a <code>copulaSampleSel</code> object.</p>


<h3>Usage</h3>

<pre><code class='language-R'>

## S3 method for class 'copulaSampleSel'
print(x, ...)


</code></pre>


<h3>Arguments</h3>

 
<table>
<tr><td><code id="print.copulaSampleSel_+3A_x">x</code></td>
<td>
<p><code>copulaSampleSel</code> object.</p>
</td></tr>
<tr><td><code id="print.copulaSampleSel_+3A_...">...</code></td>
<td>
<p>Other arguments.</p>
</td></tr>
</table>


<h3>Details</h3>

 
<p>It prints out the family, model equations, total number of observations, estimated association 
coefficient, etc for the penalized or unpenalized model. 
</p>


<h3>Author(s)</h3>

<p>Maintainer: Giampiero Marra <a href="mailto:giampiero.marra@ucl.ac.uk">giampiero.marra@ucl.ac.uk</a>
</p>

<hr>
<h2 id='print.gamlss'>Print a gamlss object</h2><span id='topic+print.gamlss'></span>

<h3>Description</h3>

<p>The print method for a <code>gamlss</code> object.</p>


<h3>Usage</h3>

<pre><code class='language-R'>

## S3 method for class 'gamlss'
print(x, ...)


</code></pre>


<h3>Arguments</h3>

 
<table>
<tr><td><code id="print.gamlss_+3A_x">x</code></td>
<td>
<p><code>gamlss</code> object produced by <code>gamlss()</code>.</p>
</td></tr>
<tr><td><code id="print.gamlss_+3A_...">...</code></td>
<td>
<p>Other arguments.</p>
</td></tr>
</table>


<h3>Details</h3>

 
<p><code>print.gamlss</code> prints out the family, model equations, total number of observations, etc for the penalized or unpenalized model. 
</p>


<h3>Author(s)</h3>

<p>Maintainer: Giampiero Marra <a href="mailto:giampiero.marra@ucl.ac.uk">giampiero.marra@ucl.ac.uk</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gamlss">gamlss</a></code>
</p>

<hr>
<h2 id='print.gjrm'>Print a gjrm object</h2><span id='topic+print.gjrm'></span>

<h3>Description</h3>

<p>The print method for a <code>gjrm</code> object.</p>


<h3>Usage</h3>

<pre><code class='language-R'>

## S3 method for class 'gjrm'
print(x, ...)


</code></pre>


<h3>Arguments</h3>

 
<table>
<tr><td><code id="print.gjrm_+3A_x">x</code></td>
<td>
<p><code>gjrm</code> object produced by <code>gjrm()</code>.</p>
</td></tr>
<tr><td><code id="print.gjrm_+3A_...">...</code></td>
<td>
<p>Other arguments.</p>
</td></tr>
</table>


<h3>Details</h3>

 
<p><code>print.gjrm</code> prints out the family, model equations, total number of observations, estimated association 
coefficient, etc for the penalized or unpenalized model. 
</p>


<h3>Author(s)</h3>

<p>Maintainer: Giampiero Marra <a href="mailto:giampiero.marra@ucl.ac.uk">giampiero.marra@ucl.ac.uk</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gjrm">gjrm</a></code>
</p>

<hr>
<h2 id='print.mb'>Print an mb object</h2><span id='topic+print.mb'></span>

<h3>Description</h3>

<p>The print method for an <code>mb</code> object.</p>


<h3>Usage</h3>

<pre><code class='language-R'>

## S3 method for class 'mb'
print(x, ...)


</code></pre>


<h3>Arguments</h3>

 
<table>
<tr><td><code id="print.mb_+3A_x">x</code></td>
<td>
<p><code>mb</code> object produced by <code>mb()</code>.</p>
</td></tr>
<tr><td><code id="print.mb_+3A_...">...</code></td>
<td>
<p>Other arguments.</p>
</td></tr>
</table>


<h3>Details</h3>

 
<p><code>print.mb</code> prints the lower and upper bounds, confidence interval, and effect assuming random assignment. 
</p>


<h3>Author(s)</h3>

<p>Maintainer: Giampiero Marra <a href="mailto:giampiero.marra@ucl.ac.uk">giampiero.marra@ucl.ac.uk</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mb">mb</a></code>
</p>

<hr>
<h2 id='print.OR'>Print an OR object</h2><span id='topic+print.OR'></span>

<h3>Description</h3>

<p>The print method for an <code>OR</code> object.</p>


<h3>Usage</h3>

<pre><code class='language-R'>

## S3 method for class 'OR'
print(x, ...)


</code></pre>


<h3>Arguments</h3>

 
<table>
<tr><td><code id="print.OR_+3A_x">x</code></td>
<td>
<p><code>OR</code> object produced by <code>OR()</code>.</p>
</td></tr>
<tr><td><code id="print.OR_+3A_...">...</code></td>
<td>
<p>Other arguments.</p>
</td></tr>
</table>


<h3>Details</h3>

 
<p><code>print.OR</code> prints the lower confidence interval limit, estimated OR and upper confidence interval limit. 
</p>


<h3>Author(s)</h3>

<p>Maintainer: Giampiero Marra <a href="mailto:giampiero.marra@ucl.ac.uk">giampiero.marra@ucl.ac.uk</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+OR">OR</a></code>
</p>

<hr>
<h2 id='print.PE'>Print an PE object</h2><span id='topic+print.PE'></span>

<h3>Description</h3>

<p>The print method for an <code>PE</code> object.</p>


<h3>Usage</h3>

<pre><code class='language-R'>

## S3 method for class 'PE'
print(x, ...)


</code></pre>


<h3>Arguments</h3>

 
<table>
<tr><td><code id="print.PE_+3A_x">x</code></td>
<td>
<p><code>PE</code> object produced by <code>PE()</code>.</p>
</td></tr>
<tr><td><code id="print.PE_+3A_...">...</code></td>
<td>
<p>Other arguments.</p>
</td></tr>
</table>


<h3>Details</h3>

 
<p><code>print.PE</code> prints the lower confidence interval limit, estimated PE and upper confidence interval limit. 
</p>


<h3>Author(s)</h3>

<p>Maintainer: Giampiero Marra <a href="mailto:giampiero.marra@ucl.ac.uk">giampiero.marra@ucl.ac.uk</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+PE">PE</a></code>
</p>

<hr>
<h2 id='print.prev'>Print an prev object</h2><span id='topic+print.prev'></span>

<h3>Description</h3>

<p>The print method for an <code>prev</code> object.</p>


<h3>Usage</h3>

<pre><code class='language-R'>

## S3 method for class 'prev'
print(x, ...)


</code></pre>


<h3>Arguments</h3>

 
<table>
<tr><td><code id="print.prev_+3A_x">x</code></td>
<td>
<p><code>prev</code> object produced by <code>prev()</code>.</p>
</td></tr>
<tr><td><code id="print.prev_+3A_...">...</code></td>
<td>
<p>Other arguments.</p>
</td></tr>
</table>


<h3>Details</h3>

 
<p><code>print.prev</code> prints the lower interval limit, estimated prevalence and upper interval limit. 
</p>


<h3>Author(s)</h3>

<p>Maintainer: Giampiero Marra <a href="mailto:giampiero.marra@ucl.ac.uk">giampiero.marra@ucl.ac.uk</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+prev">prev</a></code>
</p>

<hr>
<h2 id='print.RR'>Print an RR object</h2><span id='topic+print.RR'></span>

<h3>Description</h3>

<p>The print method for an <code>RR</code> object.</p>


<h3>Usage</h3>

<pre><code class='language-R'>

## S3 method for class 'RR'
print(x, ...)


</code></pre>


<h3>Arguments</h3>

 
<table>
<tr><td><code id="print.RR_+3A_x">x</code></td>
<td>
<p><code>RR</code> object produced by <code>RR()</code>.</p>
</td></tr>
<tr><td><code id="print.RR_+3A_...">...</code></td>
<td>
<p>Other arguments.</p>
</td></tr>
</table>


<h3>Details</h3>

 
<p><code>print.RR</code> prints the lower confidence interval limit, estimated RR and upper confidence interval limit. 
</p>


<h3>Author(s)</h3>

<p>Maintainer: Giampiero Marra <a href="mailto:giampiero.marra@ucl.ac.uk">giampiero.marra@ucl.ac.uk</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+RR">RR</a></code>
</p>

<hr>
<h2 id='print.SemiParBIV'>Print a SemiParBIV object</h2><span id='topic+print.SemiParBIV'></span>

<h3>Description</h3>

<p>The print method for a <code>SemiParBIV</code> object.</p>


<h3>Usage</h3>

<pre><code class='language-R'>

## S3 method for class 'SemiParBIV'
print(x, ...)


</code></pre>


<h3>Arguments</h3>

 
<table>
<tr><td><code id="print.SemiParBIV_+3A_x">x</code></td>
<td>
<p><code>SemiParBIV</code> object.</p>
</td></tr>
<tr><td><code id="print.SemiParBIV_+3A_...">...</code></td>
<td>
<p>Other arguments.</p>
</td></tr>
</table>


<h3>Details</h3>

 
<p>It prints out the family, model equations, total number of observations, estimated association 
coefficient and total effective degrees of freedom for the penalized or unpenalized model. 
</p>


<h3>Author(s)</h3>

<p>Maintainer: Giampiero Marra <a href="mailto:giampiero.marra@ucl.ac.uk">giampiero.marra@ucl.ac.uk</a>
</p>

<hr>
<h2 id='print.SemiParROY'>Print a SemiParROY object</h2><span id='topic+print.SemiParROY'></span>

<h3>Description</h3>

<p>The print method for a <code>SemiParROY</code> object.</p>


<h3>Usage</h3>

<pre><code class='language-R'>

## S3 method for class 'SemiParROY'
print(x, ...)


</code></pre>


<h3>Arguments</h3>

 
<table>
<tr><td><code id="print.SemiParROY_+3A_x">x</code></td>
<td>
<p><code>SemiParROY</code> object.</p>
</td></tr>
<tr><td><code id="print.SemiParROY_+3A_...">...</code></td>
<td>
<p>Other arguments.</p>
</td></tr>
</table>


<h3>Details</h3>

 
<p>It prints out the family, model equations, total number of observations, estimated association 
coefficient, etc for the penalized or unpenalized model. 
</p>


<h3>Author(s)</h3>

<p>Maintainer: Giampiero Marra <a href="mailto:giampiero.marra@ucl.ac.uk">giampiero.marra@ucl.ac.uk</a>
</p>

<hr>
<h2 id='print.SemiParTRIV'>Print a SemiParTRIV object</h2><span id='topic+print.SemiParTRIV'></span>

<h3>Description</h3>

<p>The print method for a <code>SemiParTRIV</code> object.</p>


<h3>Usage</h3>

<pre><code class='language-R'>

## S3 method for class 'SemiParTRIV'
print(x, ...)


</code></pre>


<h3>Arguments</h3>

 
<table>
<tr><td><code id="print.SemiParTRIV_+3A_x">x</code></td>
<td>
<p><code>SemiParTRIV</code> object.</p>
</td></tr>
<tr><td><code id="print.SemiParTRIV_+3A_...">...</code></td>
<td>
<p>Other arguments.</p>
</td></tr>
</table>


<h3>Details</h3>

 
<p>It prints out the family, model equations, total number of observations, estimated association 
coefficient and total effective degrees of freedom for the penalized or unpenalized model. 
</p>


<h3>Author(s)</h3>

<p>Maintainer: Giampiero Marra <a href="mailto:giampiero.marra@ucl.ac.uk">giampiero.marra@ucl.ac.uk</a>
</p>

<hr>
<h2 id='probm'>Internal Function</h2><span id='topic+probm'></span>

<h3>Description</h3>

<p>Internal fitting function.</p>


<h3>Author(s)</h3>

<p>Maintainer: Giampiero Marra <a href="mailto:giampiero.marra@ucl.ac.uk">giampiero.marra@ucl.ac.uk</a>
</p>

<hr>
<h2 id='regH'>Internal Function</h2><span id='topic+regH'></span>

<h3>Description</h3>

<p>It applies one of two regularisations on the information matrix if desired. 
These are based on the Cholesky and eigen decompositions. 
</p>


<h3>Author(s)</h3>

<p>Maintainer: Giampiero Marra <a href="mailto:giampiero.marra@ucl.ac.uk">giampiero.marra@ucl.ac.uk</a>
</p>

<hr>
<h2 id='resp.check'>Plots for response variable</h2><span id='topic+resp.check'></span>

<h3>Description</h3>

 
<p>It produces a histogram of the response along with the estimated density from the assumed distribution as well as a normal Q-Q plot for 
the (randomised) normalised quantile response. It also provides the log-likelihood for AIC calculation, for instance.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
resp.check(y, margin = "N", main = "Histogram and Density of Response",
           xlab = "Response", print.par = FALSE, plots = TRUE, 
           loglik = FALSE, os = FALSE,  
           intervals = FALSE, n.sim = 100, prob.lev = 0.05, 
           i.f = FALSE, 
           min.dn = 1e-40, min.pr = 1e-16, max.pr = 0.999999, ...)

</code></pre>


<h3>Arguments</h3>

 
<table>
<tr><td><code id="resp.check_+3A_y">y</code></td>
<td>
<p>Response.</p>
</td></tr>
<tr><td><code id="resp.check_+3A_margin">margin</code></td>
<td>
<p>The distributions allowed are: normal (&quot;N&quot;), log-normal (&quot;LN&quot;), generelised Pareto (&quot;GP&quot;), discrete generelised Pareto (&quot;DGP&quot;),
Gumbel (&quot;GU&quot;), reverse Gumbel (&quot;rGU&quot;), logistic (&quot;LO&quot;), Weibull (&quot;WEI&quot;), inverse Gaussian (&quot;iG&quot;), gamma (&quot;GA&quot;),
Dagum (&quot;DAGUM&quot;), Singh-Maddala (&quot;SM&quot;), beta (&quot;BE&quot;), Fisk (&quot;FISK&quot;), Poisson (&quot;PO&quot;), zero truncated Poisson (&quot;ZTP&quot;), 
negative binomial - type I (&quot;NBI&quot;), negative 
binomial - type II (&quot;NBII&quot;), Poisson inverse Gaussian (&quot;PIG&quot;).</p>
</td></tr> 
<tr><td><code id="resp.check_+3A_main">main</code></td>
<td>
<p>Title for the plot.</p>
</td></tr>
<tr><td><code id="resp.check_+3A_xlab">xlab</code></td>
<td>
<p>Title for the x axis.</p>
</td></tr>
<tr><td><code id="resp.check_+3A_print.par">print.par</code></td>
<td>
<p>If <code>TRUE</code> then the estimated parameters used to construct the plots are returned.</p>
</td></tr>
<tr><td><code id="resp.check_+3A_plots">plots</code></td>
<td>
<p>If <code>FALSE</code> then no plots are produced and only parameter estimates returned.</p>
</td></tr>
<tr><td><code id="resp.check_+3A_loglik">loglik</code></td>
<td>
<p>If <code>TRUE</code> then it returns the logLik.</p>
</td></tr>
<tr><td><code id="resp.check_+3A_os">os</code></td>
<td>
<p>If <code>TRUE</code> then the estimated parameters are returned on the original scale.</p>
</td></tr>
<tr><td><code id="resp.check_+3A_intervals">intervals</code></td>
<td>
<p>If <code>TRUE</code> then intervals for the qqplot are produced.</p>
</td></tr>   
<tr><td><code id="resp.check_+3A_n.sim">n.sim</code></td>
<td>
<p>Number of replicate datasets used to simulate quantiles of the residual distribution.</p>
</td></tr> 
<tr><td><code id="resp.check_+3A_prob.lev">prob.lev</code></td>
<td>
<p>Overall probability of the left and right tails of the probabilities' distribution used for interval calculations.</p>
</td></tr> 
<tr><td><code id="resp.check_+3A_i.f">i.f</code></td>
<td>
<p>Internal fitting option. This is not for user purposes.</p>
</td></tr>
<tr><td><code id="resp.check_+3A_min.dn">min.dn</code>, <code id="resp.check_+3A_min.pr">min.pr</code>, <code id="resp.check_+3A_max.pr">max.pr</code></td>
<td>
<p>Allowed minimum and maximum for estimated probabities and densities for parameter estimation.</p>
</td></tr>
<tr><td><code id="resp.check_+3A_...">...</code></td>
<td>
<p>Other graphics parameters to pass on to plotting commands.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Prior to fitting a model with discrete and/or continuous margins, the distributions for the responses
may be chosen by looking at the histogram of the response along with the estimated density from the assumed distribution, and at the
normalised quantile responses. These will provide a rough guide to the adequacy of the chosen distribution.
The latter are defined as the quantile standard normal function of the cumulative distribution function of the response with scale and location
estimated by MLE. These should behave approximately as normally distributed variables (even though the original 
observations are not). Therefore, a normal Q-Q plot is appropriate here. 
</p>
<p>If <code>loglik = TRUE</code> then this function also provides the log-likelihood for AIC calculation, for instance.
</p>
<p>The shapiro test can also be performed. 
</p>


<h3>Author(s)</h3>

<p>Maintainer: Giampiero Marra <a href="mailto:giampiero.marra@ucl.ac.uk">giampiero.marra@ucl.ac.uk</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gjrm">gjrm</a></code>  
</p>

<hr>
<h2 id='rMVN'>Multivariate Normal Variates</h2><span id='topic+rMVN'></span>

<h3>Description</h3>

<p>This function simply generates random multivariate normal variates.
</p>


<h3>Author(s)</h3>

<p>Maintainer: Giampiero Marra <a href="mailto:giampiero.marra@ucl.ac.uk">giampiero.marra@ucl.ac.uk</a>
</p>

<hr>
<h2 id='rob.const'>Bootstrap procedure to help select the robust constant in a GAMLSS</h2><span id='topic+rob.const'></span><span id='topic+rob.const'></span>

<h3>Description</h3>

 
<p>It helps finding the robust constant for a GAMLSS. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
rob.const(x, B = 100)

</code></pre>


<h3>Arguments</h3>

 
<table>
<tr><td><code id="rob.const_+3A_x">x</code></td>
<td>
<p>A fitted <code>gjrm</code> object.</p>
</td></tr>
<tr><td><code id="rob.const_+3A_b">B</code></td>
<td>
<p>Number of bootstrap replicates.</p>
</td></tr>
</table>


<h3>Details</h3>

 
<p>It helps finding the robust constant for a GAMLSS based on the mean or median.
</p>


<h3>Value</h3>

<table>
<tr><td><code>rc</code></td>
<td>
<p>Robust constant used in fitting.</p>
</td></tr>
<tr><td><code>sw</code></td>
<td>
<p>Sum of weights for each bootstrap replicate.</p>
</td></tr>
<tr><td><code>m1</code></td>
<td>
<p>Mean.</p>
</td></tr>
<tr><td><code>m2</code></td>
<td>
<p>Median.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Maintainer: Giampiero Marra <a href="mailto:giampiero.marra@ucl.ac.uk">giampiero.marra@ucl.ac.uk</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gamlss">gamlss</a></code>  
</p>

<hr>
<h2 id='rob.int'>Tool for tuning bounds of integral in robust models</h2><span id='topic+rob.int'></span><span id='topic+rob.int'></span>

<h3>Description</h3>

 
<p>Tool for tuning bounds of integral in robust GAMLSS. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
rob.int(x, rc, l.grid = 1000, tol = 1e-4, var.range = NULL)

</code></pre>


<h3>Arguments</h3>

 
<table>
<tr><td><code id="rob.int_+3A_x">x</code></td>
<td>
<p>A fitted <code>gjrm</code> object, typically from a non-robust fit.</p>
</td></tr>
<tr><td><code id="rob.int_+3A_rc">rc</code></td>
<td>
<p>Robust tuning constant.</p>
</td></tr>
<tr><td><code id="rob.int_+3A_l.grid">l.grid</code></td>
<td>
<p>Length of grid.</p>
</td></tr>
<tr><td><code id="rob.int_+3A_tol">tol</code></td>
<td>
<p>Tolerance</p>
</td></tr>
<tr><td><code id="rob.int_+3A_var.range">var.range</code></td>
<td>
<p>Range of values, min and max, to use in calculations.</p>
</td></tr>
</table>


<h3>Details</h3>

 
<p>Tool for tuning bounds of integral in robust GAMLSS. 
</p>


<h3>Value</h3>

<table>
<tr><td><code>lB</code>, <code>uB</code></td>
<td>
<p>Lower and upper bounds.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Maintainer: Giampiero Marra <a href="mailto:giampiero.marra@ucl.ac.uk">giampiero.marra@ucl.ac.uk</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gamlss">gamlss</a></code>  
</p>

<hr>
<h2 id='RR'>Causal risk ratio of a binary/continuous/discrete endogenous variable</h2><span id='topic+RR'></span>

<h3>Description</h3>

 
<p><code>RR</code> can be used to calculate the causal risk ratio of a binary/continuous/discrete endogenous predictor/treatment, with 
corresponding interval obtained using posterior simulation.</p>


<h3>Usage</h3>

<pre><code class='language-R'>
RR(x, nm.end, E = TRUE, treat = TRUE, type = "joint", ind = NULL, 
   n.sim = 100, prob.lev = 0.05, length.out = NULL, hd.plot = FALSE,
   rr.plot = FALSE, 
   main = "Histogram and Kernel Density of Simulated Risk Ratios", 
   xlab = "Simulated Risk Ratios", ...)

</code></pre>


<h3>Arguments</h3>

 
<table>
<tr><td><code id="RR_+3A_x">x</code></td>
<td>
<p>A fitted <code>gjrm</code> object.</p>
</td></tr>
<tr><td><code id="RR_+3A_nm.end">nm.end</code></td>
<td>
<p>Name of the endogenous variable.</p>
</td></tr> 
<tr><td><code id="RR_+3A_e">E</code></td>
<td>
<p>If <code>TRUE</code> then <code>RR</code> calculates the sample RR. If <code>FALSE</code> then it calculates the sample RR 
for the treated individuals only.</p>
</td></tr>  
<tr><td><code id="RR_+3A_treat">treat</code></td>
<td>
<p>If <code>TRUE</code> then <code>RR</code> calculates the RR using the treated only. If <code>FALSE</code> then it calculates the ratio using  
the control group. This only makes sense if <code>E = FALSE</code>.</p>
</td></tr>  
<tr><td><code id="RR_+3A_type">type</code></td>
<td>
<p>This argument can take three values: <code>"naive"</code> (the effect is calculated ignoring the presence of observed and 
unobserved confounders), <code>"univariate"</code> (the effect is obtained 
from the univariate model which neglects the presence of unobserved confounders) and <code>"joint"</code> (the effect is obtained from the bivariate model 
which accounts for observed and unobserved confounders).</p>
</td></tr>
<tr><td><code id="RR_+3A_ind">ind</code></td>
<td>
<p>Binary logical variable. It can be used to calculate the RR for a subset of the data. Note that it does not make sense to use <code>ind</code> 
when some observations are excluded from the RR calculation (e.g., when using <code>E = FALSE</code>).</p>
</td></tr>  
<tr><td><code id="RR_+3A_n.sim">n.sim</code></td>
<td>
<p>Number of simulated coefficient vectors from the posterior distribution of the estimated model parameters. This is used 
when <code>delta = FALSE</code>. It may be increased if more precision is required.</p>
</td></tr> 
<tr><td><code id="RR_+3A_prob.lev">prob.lev</code></td>
<td>
<p>Overall probability of the left and right tails of the RR distribution used for interval calculations.</p>
</td></tr> 
<tr><td><code id="RR_+3A_length.out">length.out</code></td>
<td>
<p>Ddesired length of the sequence to be used when calculating the effect that a continuous/discrete
treatment has on a binary outcome.</p>
</td></tr>
<tr><td><code id="RR_+3A_hd.plot">hd.plot</code></td>
<td>
<p>If <code>TRUE</code> then a plot of the histogram and kernel density estimate of the simulated risk ratios is produced. This can 
only be produced when binary responses are used.</p>
</td></tr>
<tr><td><code id="RR_+3A_rr.plot">rr.plot</code></td>
<td>
<p>For the case of continuous/discrete endogenous variable and binary outcome, if <code>TRUE</code> then a plot (on the log scale)  
showing the risk ratios that the binary outcome is equal to 1 for each incremental value of the endogenous variable 
and respective intervals is produced.</p>
</td></tr>
<tr><td><code id="RR_+3A_main">main</code></td>
<td>
<p>Title for the plot.</p>
</td></tr>
<tr><td><code id="RR_+3A_xlab">xlab</code></td>
<td>
<p>Title for the x axis.</p>
</td></tr>
<tr><td><code id="RR_+3A_...">...</code></td>
<td>
<p>Other graphics parameters to pass on to plotting commands. These are used only when <code>hd.plot = TRUE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>RR calculates the causal risk ratio of the probabilities of positive outcome under 
treatment (the binary predictor or treatment assumes value 1) and under 
control (the binary treatment assumes value 0). Posterior simulation is used to obtain a 
confidence/credible interval. 
</p>
<p>RR works also for the case of continuous/discrete endogenous treatment variable.
</p>


<h3>Value</h3>

<table>
<tr><td><code>prob.lev</code></td>
<td>
<p>Probability level used.</p>
</td></tr>
<tr><td><code>sim.RR</code></td>
<td>
<p>It returns a vector containing simulated values of the average RR. This 
is used to calculate intervals.</p>
</td></tr>           
<tr><td><code>Ratios</code></td>
<td>
<p>For the case of continuous/discrete endogenous variable and binary outcome, it returns a matrix made up of 
three columns containing the risk ratios for each incremental value in the endogenous variable and respective intervals.</p>
</td></tr>            
</table>


<h3>Author(s)</h3>

<p>Maintainer: Giampiero Marra <a href="mailto:giampiero.marra@ucl.ac.uk">giampiero.marra@ucl.ac.uk</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+GJRM-package">GJRM-package</a></code>, <code><a href="#topic+gjrm">gjrm</a></code> 
</p>

<hr>
<h2 id='S.m'>Internal Function</h2><span id='topic+S.m'></span>

<h3>Description</h3>

<p>It provides penalty matrices in a format suitable for automatic multiple smoothing parameter estimation.</p>


<h3>Author(s)</h3>

<p>Maintainer: Giampiero Marra <a href="mailto:giampiero.marra@ucl.ac.uk">giampiero.marra@ucl.ac.uk</a>
</p>

<hr>
<h2 id='SemiParBIV'>Internal fitting function</h2><span id='topic+SemiParBIV'></span>

<h3>Description</h3>

<p>Internal fitting set up function.</p>


<h3>Author(s)</h3>

<p>Maintainer: Giampiero Marra <a href="mailto:giampiero.marra@ucl.ac.uk">giampiero.marra@ucl.ac.uk</a>
</p>

<hr>
<h2 id='SemiParBIV.fit'>Internal Function</h2><span id='topic+SemiParBIV.fit'></span>

<h3>Description</h3>

<p>Wrapper of core algorithm.</p>


<h3>Author(s)</h3>

<p>Maintainer: Giampiero Marra <a href="mailto:giampiero.marra@ucl.ac.uk">giampiero.marra@ucl.ac.uk</a>
</p>

<hr>
<h2 id='SemiParBIV.fit.post'>Internal Function</h2><span id='topic+SemiParBIV.fit.post'></span><span id='topic+copulaReg.fit.post'></span><span id='topic+copulaSampleSel.fit.post'></span><span id='topic+SemiParTRIV.fit.post'></span><span id='topic+SemiParROY.fit.post'></span><span id='topic+gamlss.fit.post'></span><span id='topic+postVb'></span><span id='topic+ass.ms'></span><span id='topic+edf.loop'></span><span id='topic+form.check'></span><span id='topic+pred.var'></span>

<h3>Description</h3>

<p>This and other similar internal functions calculate useful post estimation quantities.</p>


<h3>Author(s)</h3>

<p>Maintainer: Giampiero Marra <a href="mailto:giampiero.marra@ucl.ac.uk">giampiero.marra@ucl.ac.uk</a>
</p>

<hr>
<h2 id='SemiParROY'>Internal fitting function</h2><span id='topic+SemiParROY'></span>

<h3>Description</h3>

<p>Internal fitting set up function.</p>


<h3>Author(s)</h3>

<p>Maintainer: Giampiero Marra <a href="mailto:giampiero.marra@ucl.ac.uk">giampiero.marra@ucl.ac.uk</a>
</p>

<hr>
<h2 id='SemiParTRIV'>Internal fitting function</h2><span id='topic+SemiParTRIV'></span>

<h3>Description</h3>

<p>Internal fitting set up function.</p>


<h3>Author(s)</h3>

<p>Maintainer: Giampiero Marra <a href="mailto:giampiero.marra@ucl.ac.uk">giampiero.marra@ucl.ac.uk</a>
</p>

<hr>
<h2 id='summary.copulaSampleSel'>copulaSampleSel summary</h2><span id='topic+summary.copulaSampleSel'></span><span id='topic+print.summary.copulaSampleSel'></span>

<h3>Description</h3>

<p>It takes a fitted <code>copulaSampleSel</code> object and produces some summaries from it.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
## S3 method for class 'copulaSampleSel'
summary(object, n.sim = 100, prob.lev = 0.05, ...)
  
## S3 method for class 'summary.copulaSampleSel'
print(x, digits = max(3, getOption("digits") - 3), 
           signif.stars = getOption("show.signif.stars"), ...)  
  
</code></pre>


<h3>Arguments</h3>

 
<table>
<tr><td><code id="summary.copulaSampleSel_+3A_object">object</code></td>
<td>
<p>A fitted <code>copulaSampleSel</code> object.</p>
</td></tr>
<tr><td><code id="summary.copulaSampleSel_+3A_x">x</code></td>
<td>
<p><code>summary.copulaSampleSel</code> object produced by <code>summary.copulaSampleSel()</code>.</p>
</td></tr>
<tr><td><code id="summary.copulaSampleSel_+3A_n.sim">n.sim</code></td>
<td>
<p>The number of simulated coefficient vectors from the posterior distribution of the estimated model parameters. This is used 
to calculate intervals for the association parameter, dispersion coefficient, for instance It may be increased if
more precision is required.</p>
</td></tr> 
<tr><td><code id="summary.copulaSampleSel_+3A_prob.lev">prob.lev</code></td>
<td>
<p>Probability of the left and right tails of the posterior distribution used for interval calculations.</p>
</td></tr> 
<tr><td><code id="summary.copulaSampleSel_+3A_digits">digits</code></td>
<td>
<p>Number of digits printed in output.</p>
</td></tr> 
<tr><td><code id="summary.copulaSampleSel_+3A_signif.stars">signif.stars</code></td>
<td>
<p>By default significance stars are printed alongside output.</p>
</td></tr>           
<tr><td><code id="summary.copulaSampleSel_+3A_...">...</code></td>
<td>
<p>Other arguments.</p>
</td></tr>
</table>


<h3>Details</h3>

 
<p><code>print.summary.copulaSampleSel</code> prints model term summaries. 
</p>


<h3>Author(s)</h3>

<p>Maintainer: Giampiero Marra <a href="mailto:giampiero.marra@ucl.ac.uk">giampiero.marra@ucl.ac.uk</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## see examples for gjrm
</code></pre>

<hr>
<h2 id='summary.gamlss'>gamlss summary</h2><span id='topic+summary.gamlss'></span><span id='topic+print.summary.gamlss'></span>

<h3>Description</h3>

<p>It takes a fitted <code>gamlss</code> object and produces some summaries from it.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
## S3 method for class 'gamlss'
summary(object, n.sim = 100, prob.lev = 0.05, ...)
   


## S3 method for class 'summary.gamlss'
print(x, digits = max(3, getOption("digits") - 3), 
           signif.stars = getOption("show.signif.stars"), ...)
 
</code></pre>


<h3>Arguments</h3>

 
<table>
<tr><td><code id="summary.gamlss_+3A_object">object</code></td>
<td>
<p>A fitted <code>gamlss</code> object.</p>
</td></tr>
<tr><td><code id="summary.gamlss_+3A_x">x</code></td>
<td>
<p><code>summary.gamlss</code> object produced by <code>summary.gamlss()</code>.</p>
</td></tr>
<tr><td><code id="summary.gamlss_+3A_n.sim">n.sim</code></td>
<td>
<p>The number of simulated coefficient vectors from the posterior distribution of the estimated model parameters. This is used 
to calculate intervals for various parameters. It may be increased if
more precision is required.</p>
</td></tr> 
<tr><td><code id="summary.gamlss_+3A_prob.lev">prob.lev</code></td>
<td>
<p>Probability of the left and right tails of the posterior distribution used for interval calculations.</p>
</td></tr> 
<tr><td><code id="summary.gamlss_+3A_digits">digits</code></td>
<td>
<p>Number of digits printed in output.</p>
</td></tr> 
<tr><td><code id="summary.gamlss_+3A_signif.stars">signif.stars</code></td>
<td>
<p>By default significance stars are printed alongside output.</p>
</td></tr> 
<tr><td><code id="summary.gamlss_+3A_...">...</code></td>
<td>
<p>Other arguments.</p>
</td></tr>
</table>


<h3>Details</h3>

 
<p><code>print.summary.gamlss</code> prints model term summaries. 
</p>


<h3>Value</h3>

<table>
<tr><td><code>tableP1</code></td>
<td>
<p>Table containing parametric estimates, their standard errors, z-values and p-values for equation 1.</p>
</td></tr>
<tr><td><code>tableP2</code>, <code>tableP3</code></td>
<td>
<p>As above but for equations 2 and 3 if present.</p>
</td></tr>
<tr><td><code>tableNP1</code></td>
<td>
<p>Table of nonparametric summaries for each smooth component including effective degrees of freedom, estimated rank, 
approximate Wald statistic for testing the null hypothesis that the smooth term is zero and 
corresponding p-value, for equation 1.</p>
</td></tr>
<tr><td><code>tableNP2</code>, <code>tableNP3</code></td>
<td>
<p>As above but for equations 2 and 3.</p>
</td></tr>
<tr><td><code>n</code></td>
<td>
<p>Sample size.</p>
</td></tr>
<tr><td><code>sigma</code>, <code>nu</code></td>
<td>
<p>Estimated distribution specific parameters.</p>
</td></tr>
<tr><td><code>formula1</code>, <code>formula2</code>, <code>formula3</code></td>
<td>
<p>Formulas used for the model equations.</p>
</td></tr>
<tr><td><code>l.sp1</code>, <code>l.sp2</code>, <code>l.sp3</code></td>
<td>
<p>Number of smooth components in model equation.</p>
</td></tr>
<tr><td><code>t.edf</code></td>
<td>
<p>Total degrees of freedom of the estimated bivariate model.</p>
</td></tr>
<tr><td><code>CIsig</code>, <code>CInu</code></td>
<td>
<p>Intervals for distribution specific parameters.</p>
</td></tr> 
</table>


<h3>Author(s)</h3>

<p>Maintainer: Giampiero Marra <a href="mailto:giampiero.marra@ucl.ac.uk">giampiero.marra@ucl.ac.uk</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## see examples for gamlss
</code></pre>

<hr>
<h2 id='summary.gjrm'>gjrm summary</h2><span id='topic+summary.gjrm'></span><span id='topic+print.summary.gjrm'></span>

<h3>Description</h3>

<p>It takes a fitted <code>gjrm</code> object and produces some summaries from it.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
## S3 method for class 'gjrm'
summary(object, n.sim = 100, prob.lev = 0.05, ...)
   


## S3 method for class 'summary.gjrm'
print(x, digits = max(3, getOption("digits") - 3), 
           signif.stars = getOption("show.signif.stars"), ...)
 
</code></pre>


<h3>Arguments</h3>

 
<table>
<tr><td><code id="summary.gjrm_+3A_object">object</code></td>
<td>
<p>A fitted <code>gjrm</code> object.</p>
</td></tr>
<tr><td><code id="summary.gjrm_+3A_x">x</code></td>
<td>
<p><code>summary.gjrm</code> object produced by <code>summary.gjrm()</code>.</p>
</td></tr>
<tr><td><code id="summary.gjrm_+3A_n.sim">n.sim</code></td>
<td>
<p>The number of simulated coefficient vectors from the posterior distribution of the estimated model parameters. This is used 
to calculate intervals for the association parameter, dispersion coefficient etc. It may be increased if
more precision is required.</p>
</td></tr> 
<tr><td><code id="summary.gjrm_+3A_prob.lev">prob.lev</code></td>
<td>
<p>Probability of the left and right tails of the posterior distribution used for interval calculations.</p>
</td></tr> 
<tr><td><code id="summary.gjrm_+3A_digits">digits</code></td>
<td>
<p>Number of digits printed in output.</p>
</td></tr> 
<tr><td><code id="summary.gjrm_+3A_signif.stars">signif.stars</code></td>
<td>
<p>By default significance stars are printed alongside output.</p>
</td></tr>     
<tr><td><code id="summary.gjrm_+3A_...">...</code></td>
<td>
<p>Other arguments.</p>
</td></tr>
</table>


<h3>Details</h3>

 
<p><code>print.summary.gjrm</code> prints model term summaries. 
</p>


<h3>Value</h3>

<table>
<tr><td><code>tableP1</code></td>
<td>
<p>Table containing parametric estimates, their standard errors, z-values and p-values for equation 1.</p>
</td></tr>
<tr><td><code>tableP2</code>, <code>tableP3</code>, <code>...</code></td>
<td>
<p>As above but for equation 2 and equations 3 and 4 if present.</p>
</td></tr>
<tr><td><code>tableNP1</code></td>
<td>
<p>Table of nonparametric summaries for each smooth component including effective degrees of freedom, estimated rank, 
approximate Wald statistic for testing the null hypothesis that the smooth term is zero and 
corresponding p-value, for equation 1.</p>
</td></tr>
<tr><td><code>tableNP2</code>, <code>tableNP3</code>, <code>...</code></td>
<td>
<p>As above but for equation 2 and equations 3 and 4 if present.</p>
</td></tr>
<tr><td><code>n</code></td>
<td>
<p>Sample size.</p>
</td></tr>
<tr><td><code>theta</code></td>
<td>
<p>Estimated dependence parameter linking the two equations.</p>
</td></tr>
<tr><td><code>tau</code></td>
<td>
<p>Estimated Kendall's tau dependence measure between the two equations.</p>
</td></tr>
<tr><td><code>sigma1</code>, <code>sigma2</code></td>
<td>
<p>Estimated distribution specific parameters for equations 1 and 2.</p>
</td></tr>
<tr><td><code>nu1</code>, <code>nu2</code></td>
<td>
<p>Estimated distribution specific parameters for equations 1 and 2.</p>
</td></tr>
<tr><td><code>formula1</code>, <code>formula2</code>, <code>formula3</code>, <code>...</code></td>
<td>
<p>Formulas used for the model equations.</p>
</td></tr>
<tr><td><code>l.sp1</code>, <code>l.sp2</code>, <code>l.sp3</code>, <code>...</code></td>
<td>
<p>Number of smooth components in model equations.</p>
</td></tr>
<tr><td><code>t.edf</code></td>
<td>
<p>Total degrees of freedom of the estimated bivariate model.</p>
</td></tr>
<tr><td><code>CItheta</code>, <code>CItau</code></td>
<td>
<p>Interval(s) for <code class="reqn">\theta</code> and Kendall's tau.</p>
</td></tr>
<tr><td><code>CIsig1</code>, <code>CIsig2</code>, <code>CInu1</code>, <code>CInu2</code></td>
<td>
<p>Intervals for distribution specific parameters</p>
</td></tr> 
</table>


<h3>WARNINGS</h3>

<p>Note that the summary output will also indeed provide the Kendall's tau and related interval. This is a valid measure of dependence for continuous margins
but it may not for discrete margins, for instance. However, it is still displayed for the sake of keeping the printed output consistent with that of
other models in the package. Also, it still provides an approximate measure of dependence under certan scenarios.
</p>


<h3>Author(s)</h3>

<p>Maintainer: Giampiero Marra <a href="mailto:giampiero.marra@ucl.ac.uk">giampiero.marra@ucl.ac.uk</a>
</p>

<hr>
<h2 id='summary.SemiParBIV'>SemiParBIV summary</h2><span id='topic+summary.SemiParBIV'></span><span id='topic+print.summary.SemiParBIV'></span>

<h3>Description</h3>

<p>It takes a fitted <code>SemiParBIV</code> object and produces some summaries from it.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
## S3 method for class 'SemiParBIV'
summary(object, n.sim = 100, prob.lev = 0.05, gm = FALSE, ...)
        
## S3 method for class 'summary.SemiParBIV'
print(x, digits = max(3, getOption("digits") - 3), 
           signif.stars = getOption("show.signif.stars"), ...)    
                      
</code></pre>


<h3>Arguments</h3>

 
<table>
<tr><td><code id="summary.SemiParBIV_+3A_object">object</code></td>
<td>
<p>A fitted <code>SemiParBIV</code> object.</p>
</td></tr>
<tr><td><code id="summary.SemiParBIV_+3A_x">x</code></td>
<td>
<p><code>summary.SemiParBIV</code> object produced by <code>summary.SemiParBIV()</code>.</p>
</td></tr>
<tr><td><code id="summary.SemiParBIV_+3A_n.sim">n.sim</code></td>
<td>
<p>The number of simulated coefficient vectors from the posterior distribution of the estimated model parameters. This is used 
to calculate intervals for the association parameter, dispersion coefficient and other measures (e.g., gamma measure). It may be increased if
more precision is required.</p>
</td></tr> 
<tr><td><code id="summary.SemiParBIV_+3A_prob.lev">prob.lev</code></td>
<td>
<p>Probability of the left and right tails of the posterior distribution used for interval calculations.</p>
</td></tr> 
<tr><td><code id="summary.SemiParBIV_+3A_gm">gm</code></td>
<td>
<p>If TRUE then intervals for the gamma measure and odds ratio are calculated.</p>
</td></tr>     
<tr><td><code id="summary.SemiParBIV_+3A_digits">digits</code></td>
<td>
<p>Number of digits printed in output.</p>
</td></tr> 
<tr><td><code id="summary.SemiParBIV_+3A_signif.stars">signif.stars</code></td>
<td>
<p>By default significance stars are printed alongside output.</p>
</td></tr> 
<tr><td><code id="summary.SemiParBIV_+3A_...">...</code></td>
<td>
<p>Other arguments.</p>
</td></tr>
</table>


<h3>Details</h3>

 
<p>Using some low level functions in <code>mgcv</code>, based on the results of Marra and Wood (2012), &lsquo;Bayesian p-values&rsquo; are returned for the 
smooth terms. These have better frequentist performance than their frequentist counterpart. See the help file of 
<code>summary.gam</code> in <code>mgcv</code> for further details. Covariate selection can also be achieved 
using a single penalty shrinkage approach as shown in Marra and Wood (2011). 
</p>
<p>Posterior simulation is used to obtain intervals of nonlinear functions of parameters, such as the association and dispersion parameters
as well as the odds ratio and gamma measure discussed by Tajar et al. (2001) if <code>gm = TRUE</code>. 
</p>
<p><code>print.summary.SemiParBIV</code> prints model term summaries. 
</p>


<h3>Value</h3>

<table>
<tr><td><code>tableP1</code></td>
<td>
<p>Table containing parametric estimates, their standard errors, z-values and p-values for equation 1.</p>
</td></tr>
<tr><td><code>tableP2</code>, <code>tableP3</code>, <code>...</code></td>
<td>
<p>As above but for equation 2 and equations 3 and 4 if present.</p>
</td></tr>
<tr><td><code>tableNP1</code></td>
<td>
<p>Table of nonparametric summaries for each smooth component including effective degrees of freedom, estimated rank, 
approximate Wald statistic for testing the null hypothesis that the smooth term is zero and 
corresponding p-value, for equation 1.</p>
</td></tr>
<tr><td><code>tableNP2</code>, <code>tableNP3</code>, <code>...</code></td>
<td>
<p>As above but for equation 2 and equations 3 and 4 if present.</p>
</td></tr>
<tr><td><code>n</code></td>
<td>
<p>Sample size.</p>
</td></tr>
<tr><td><code>theta</code></td>
<td>
<p>Estimated dependence parameter linking the two equations.</p>
</td></tr>
<tr><td><code>formula1</code>, <code>formula2</code>, <code>formula3</code>, <code>...</code></td>
<td>
<p>Formulas used for the model equations.</p>
</td></tr>
<tr><td><code>l.sp1</code>, <code>l.sp2</code>, <code>l.sp3</code>, <code>...</code></td>
<td>
<p>Number of smooth components in model equations.</p>
</td></tr>
<tr><td><code>t.edf</code></td>
<td>
<p>Total degrees of freedom of the estimated bivariate model.</p>
</td></tr>
<tr><td><code>CItheta</code></td>
<td>
<p>Interval(s) for <code class="reqn">\theta</code>.</p>
</td></tr>
<tr><td><code>n.sel</code></td>
<td>
<p>Number of selected observations in the sample selection case.</p>
</td></tr>
<tr><td><code>OR</code>, <code>CIor</code></td>
<td>
<p>Odds ratio and related CI. The odds ratio is a measure of association between binary random variables and is defined as 
p00p11/p10p01. In the case of independence this ratio is equal to 1. It can take values in the range (-Inf, Inf) and 
it does not depend on the marginal probabilities (Tajar et al., 2001). Interval is calculated using posterior simulation.</p>
</td></tr>
<tr><td><code>GM</code>, <code>CIgm</code></td>
<td>
<p>Gamma measure and related CI. This measure of association was proposed by Goodman and Kruskal (1954). It is defined as 
(<code>OR</code> - 1)/(<code>OR</code> + 1), can take values in the range (-1, 1) and does not depend on the marginal probabilities.
Interval is calculated using posterior simulation.</p>
</td></tr>
<tr><td><code>tau</code>, <code>CItau</code></td>
<td>
<p>Kendall's tau and respective intervals.</p>
</td></tr>                
</table>


<h3>WARNINGS</h3>

<p>Note that the summary output will also indeed provide the Kendall's tau and related interval. This is a valid measure of dependence for continuous margins
but it is typically not for binary margins. However, it is still displayed for the sake of keeping the printed output consistent with that of
other models in the package.
</p>


<h3>Author(s)</h3>

<p>Maintainer: Giampiero Marra <a href="mailto:giampiero.marra@ucl.ac.uk">giampiero.marra@ucl.ac.uk</a>
</p>


<h3>References</h3>

<p>Marra G. and Wood S.N. (2011), Practical Variable Selection for Generalized Additive Models. <em>Computational Statistics and Data Analysis</em>, 55(7), 2372-2387.
</p>
<p>Marra G. and Wood S.N. (2012), Coverage Properties of Confidence Intervals for Generalized Additive Model Components. <em>Scandinavian Journal of Statistics</em>, 39(1), 53-74.
</p>
<p>Tajar M., Denuit M. and Lambert P. (2001), Copula-Type Representation for Random Couples with Bernoulli Margins. Discussion Papaer 0118, Universite Catholique De Louvain.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+AT">AT</a></code>, <code><a href="#topic+prev">prev</a></code>
</p>

<hr>
<h2 id='summary.SemiParROY'>SemiParROY summary</h2><span id='topic+summary.SemiParROY'></span><span id='topic+print.summary.SemiParROY'></span>

<h3>Description</h3>

<p>It takes a fitted <code>SemiParROY</code> object and produces some summaries from it.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
## S3 method for class 'SemiParROY'
summary(object, n.sim = 100, prob.lev = 0.05, ...)
  
## S3 method for class 'summary.SemiParROY'
print(x, digits = max(3, getOption("digits") - 3), 
           signif.stars = getOption("show.signif.stars"), ...)  
  
</code></pre>


<h3>Arguments</h3>

 
<table>
<tr><td><code id="summary.SemiParROY_+3A_object">object</code></td>
<td>
<p>A fitted <code>SemiParROY</code> object.</p>
</td></tr>
<tr><td><code id="summary.SemiParROY_+3A_x">x</code></td>
<td>
<p><code>summary.SemiParROY</code> object produced by <code>summary.SemiParROY()</code>.</p>
</td></tr>
<tr><td><code id="summary.SemiParROY_+3A_n.sim">n.sim</code></td>
<td>
<p>The number of simulated coefficient vectors from the posterior distribution of the estimated model parameters. This is used 
to calculate intervals for the association parameter, dispersion coefficient, for instance It may be increased if
more precision is required.</p>
</td></tr> 
<tr><td><code id="summary.SemiParROY_+3A_prob.lev">prob.lev</code></td>
<td>
<p>Probability of the left and right tails of the posterior distribution used for interval calculations.</p>
</td></tr> 
<tr><td><code id="summary.SemiParROY_+3A_digits">digits</code></td>
<td>
<p>Number of digits printed in output.</p>
</td></tr> 
<tr><td><code id="summary.SemiParROY_+3A_signif.stars">signif.stars</code></td>
<td>
<p>By default significance stars are printed alongside output.</p>
</td></tr>           
<tr><td><code id="summary.SemiParROY_+3A_...">...</code></td>
<td>
<p>Other arguments.</p>
</td></tr>
</table>


<h3>Details</h3>

 
<p><code>print.summary.SemiParROY</code> prints model term summaries. 
</p>


<h3>Author(s)</h3>

<p>Maintainer: Giampiero Marra <a href="mailto:giampiero.marra@ucl.ac.uk">giampiero.marra@ucl.ac.uk</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## see examples for gjrm
</code></pre>

<hr>
<h2 id='summary.SemiParTRIV'>SemiParTRIV summary</h2><span id='topic+summary.SemiParTRIV'></span><span id='topic+print.summary.SemiParTRIV'></span>

<h3>Description</h3>

<p>It takes a fitted <code>SemiParTRIV</code> object and produces some summaries from it.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
## S3 method for class 'SemiParTRIV'
summary(object, n.sim = 100, prob.lev = 0.05, ...)

## S3 method for class 'summary.SemiParTRIV'
print(x, digits = max(3, getOption("digits") - 3), 
           signif.stars = getOption("show.signif.stars"), ...)                      
</code></pre>


<h3>Arguments</h3>

 
<table>
<tr><td><code id="summary.SemiParTRIV_+3A_object">object</code></td>
<td>
<p>A fitted <code>SemiParTRIV</code> object.</p>
</td></tr>
<tr><td><code id="summary.SemiParTRIV_+3A_x">x</code></td>
<td>
<p><code>summary.SemiParTRIV</code> object produced by <code>summary.SemiParTRIV()</code>.</p>
</td></tr>
<tr><td><code id="summary.SemiParTRIV_+3A_n.sim">n.sim</code></td>
<td>
<p>The number of simulated coefficient vectors from the posterior distribution of the estimated model parameters. This is used 
to calculate intervals for the association parameter and other measures. It may be increased if
more precision is required.</p>
</td></tr> 
<tr><td><code id="summary.SemiParTRIV_+3A_prob.lev">prob.lev</code></td>
<td>
<p>Probability of the left and right tails of the posterior distribution used for interval calculations.</p>
</td></tr> 
<tr><td><code id="summary.SemiParTRIV_+3A_digits">digits</code></td>
<td>
<p>Number of digits printed in output.</p>
</td></tr> 
<tr><td><code id="summary.SemiParTRIV_+3A_signif.stars">signif.stars</code></td>
<td>
<p>By default significance stars are printed alongside output.</p>
</td></tr> 
<tr><td><code id="summary.SemiParTRIV_+3A_...">...</code></td>
<td>
<p>Other arguments.</p>
</td></tr>            
</table>


<h3>Details</h3>

 
<p><code>print.summary.SemiParTRIV</code> prints model term summaries. 
</p>


<h3>Author(s)</h3>

<p>Maintainer: Giampiero Marra <a href="mailto:giampiero.marra@ucl.ac.uk">giampiero.marra@ucl.ac.uk</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## see examples for gjrm
</code></pre>

<hr>
<h2 id='TRIapprox'>Internal Function</h2><span id='topic+TRIapprox'></span>

<h3>Description</h3>

<p>It approximates the trivariate normal integral.</p>


<h3>Author(s)</h3>

<p>Maintainer: Giampiero Marra <a href="mailto:giampiero.marra@ucl.ac.uk">giampiero.marra@ucl.ac.uk</a>
</p>

<hr>
<h2 id='triprobgHs'>Internal Function</h2><span id='topic+triprobgHs'></span><span id='topic+triprobgHsSS'></span><span id='topic+triprobgHsESS'></span>

<h3>Description</h3>

<p>It provides score and Hessian for trivariate binary models.
</p>


<h3>Author(s)</h3>

<p>Author: Panagiota Filippou
</p>
<p>Maintainer: Giampiero Marra <a href="mailto:giampiero.marra@ucl.ac.uk">giampiero.marra@ucl.ac.uk</a>
</p>

<hr>
<h2 id='vis.gjrm'>Visualization function</h2><span id='topic+vis.gjrm'></span>

<h3>Description</h3>

<p>It takes a fitted <code>gjrm</code> object produced 
by <code>gjrm()</code> and 
produces perspective or contour plot views of model predictions. This function is a 
wrapper of <code>vis.gam()</code> in <code>mgcv</code>. Please see 
the documentation of <code>vis.gam()</code> for full details. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>vis.gjrm(x, eq, fun = NULL, ...)
</code></pre>


<h3>Arguments</h3>

 
<table>
<tr><td><code id="vis.gjrm_+3A_x">x</code></td>
<td>
<p>A fitted <code>gjrm</code> object.</p>
</td></tr>
<tr><td><code id="vis.gjrm_+3A_eq">eq</code></td>
<td>
<p>The equation number.</p>
</td></tr>
<tr><td><code id="vis.gjrm_+3A_fun">fun</code></td>
<td>
<p>Either mean or variance. If left as equal to NULL then predictions on the scale of the predictor will be produced.</p>
</td></tr>
<tr><td><code id="vis.gjrm_+3A_...">...</code></td>
<td>
<p>Other graphics parameters to pass on to plotting commands, as described for <code>vis.gam()</code> in <code>mgcv</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function generates plots.
</p>


<h3>Author(s)</h3>

<p>Maintainer: Giampiero Marra <a href="mailto:giampiero.marra@ucl.ac.uk">giampiero.marra@ucl.ac.uk</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gjrm">gjrm</a></code>
</p>

<hr>
<h2 id='VuongClarke'>Vuong and Clarke tests</h2><span id='topic+VuongClarke'></span>

<h3>Description</h3>

 
<p>The Vuong and Clarke tests are likelihood-ratio-based tests that can be used for choosing between two non-nested models.</p>


<h3>Usage</h3>

<pre><code class='language-R'>
VuongClarke(obj1, obj2, sig.lev = 0.05)

</code></pre>


<h3>Arguments</h3>

 
<table>
<tr><td><code id="VuongClarke_+3A_obj1">obj1</code>, <code id="VuongClarke_+3A_obj2">obj2</code></td>
<td>
<p>Objects of the two fitted bivariate non-nested models.</p>
</td></tr> 
<tr><td><code id="VuongClarke_+3A_sig.lev">sig.lev</code></td>
<td>
<p>Significance level used for testing.</p>
</td></tr> 
</table>


<h3>Details</h3>

<p>The Vuong (1989) and Clarke (2007) tests are likelihood-ratio-based tests for model selection that use the 
Kullback-Leibler information criterion. The implemented tests can be used for choosing between two bivariate models which 
are non-nested. 
</p>
<p>In the Vuong test, the null hypothesis is that the two models are equally close to the actual model, whereas 
the alternative is that one model is closer. The test follows asymptotically a standard normal 
distribution under the null. Assume that the critical region is <code class="reqn">(-c,c)</code>, where <code class="reqn">c</code> is typically set to 1.96. If the value 
of the test is higher than <code class="reqn">c</code> then we reject the null hypothesis 
that the models are equivalent in favor of model <code>obj1</code>. Viceversa if the value is smaller than <code class="reqn">c</code>. If 
the value falls in <code class="reqn">[-c,c]</code> then we cannot discriminate between the two competing models given the data. 
</p>
<p>In the Clarke test, if the two models are statistically equivalent then the log-likelihood ratios of the 
observations should be evenly distributed around zero 
and around half of the ratios should be larger than zero. The test follows asymptotically a binomial distribution with 
parameters <code class="reqn">n</code> and 0.5. Critical values can be obtained as shown in Clarke (2007). Intuitively, 
model <code>obj1</code> is preferred over <code>obj2</code> if the value of the test 
is significantly larger than its expected value under the null hypothesis (<code class="reqn">n/2</code>), and vice versa. If 
the value is not significantly different from <code class="reqn">n/2</code> then <code>obj1</code> can be thought of as equivalent to <code>obj2</code>.
</p>


<h3>Value</h3>

<p>It returns two decisions based on the tests and criteria discussed above.
</p>


<h3>Author(s)</h3>

<p>Maintainer: Giampiero Marra <a href="mailto:giampiero.marra@ucl.ac.uk">giampiero.marra@ucl.ac.uk</a>
</p>


<h3>References</h3>

<p>Clarke K. (2007), A Simple Distribution-Free Test for Non-Nested Model Selection. <em>Political Analysis</em>, 15, 347-363.
</p>
<p>Vuong Q.H. (1989), Likelihood Ratio Tests for Model Selection and Non-Nested Hypotheses. <em>Econometrica</em>, 57(2), 307-333. 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## see examples for gjrm
</code></pre>

<hr>
<h2 id='war'>Civil war data</h2><span id='topic+war'></span>

<h3>Description</h3>

<p>Civil war data from Fearon and Laitin (2003).</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(war)
</code></pre>


<h3>Format</h3>

 <p><code>war</code> is a 6326 row data frame with the following columns 
</p>

<dl>
<dt>onset</dt><dd><p>equal to 1 for all country-years in which a civil war started.</p>
</dd>
<dt>instab</dt><dd><p>equal to 1 if unstable government.</p>
</dd>
<dt>oil</dt><dd><p>equal to 1 for oil exporter country.</p>
</dd>
<dt>warl</dt><dd><p>equal to 1 if the country had a distinct civil war ongoing in the previous year.</p>
</dd>
<dt>gdpenl</dt><dd><p>GDP per capita (measured as thousands of 1985 U.S. dollars) lagged one year.</p>
</dd>
<dt>ncontig</dt><dd><p>equal to 1 for non-contiguous state.</p>
</dd>
<dt>nwstate</dt><dd><p>equal to 1 for new state.</p>
</dd>
<dt>lpopl</dt><dd><p>log(population size).</p>
</dd>
<dt>lmtnest</dt><dd><p>log(mountainous).</p>
</dd>
<dt>ethfrac</dt><dd><p>measure of ethnic fractionalization (calculated as the probability that two randomly drawn individuals from a country are not from the same ethnicity).</p>
</dd>
<dt>relfrac</dt><dd><p>measure of religious fractionalization.</p>
</dd>
<dt>polity2l</dt><dd><p>measure of political democracy (ranges from -10 to 10) lagged one year.</p>
</dd>
</dl>



<h3>Source</h3>

<p>Data are from:
</p>
<p>Fearon J.D., Laitin D.D. (2003), Ethnicity, Insurgency, and Civil War. <em>The American Political Science Review</em>, 97, 75-90.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run:  

#########################################################
#########################################################

library("GJRM")

data("war", package = "GJRM")        

###################################################
# Bivariate brobit model with partial observability
###################################################  

reb.eq &lt;- onset ~ instab + oil + warl + lpopl + lmtnest + ethfrac +
                  polity2l + s(gdpenl) + s(relfrac) 
gov.eq &lt;- onset ~ instab + oil + warl + ncontig + nwstate + s(gdpenl)   

bpo &lt;- gjrm(list(reb.eq, gov.eq), data = war, model = "BPO",
            margins = c("probit", "probit"))
conv.check(bpo)

# perhaps model is to complex

set.seed(1)
sbpo &lt;- summary(bpo)
sbpo$theta; sbpo$CItheta

# let's exclude the correlation parameter in fitting

bpo0 &lt;- gjrm(list(reb.eq, gov.eq), data = war, model = "BPO0",
             margins = c("probit", "probit"))
conv.check(bpo0)

summary(bpo0)


war.eq &lt;- onset ~ instab + oil + warl +  ncontig + nwstate + lpopl +
                  lmtnest + ethfrac + polity2l + s(gdpenl) + s(relfrac)    
Probit &lt;- gam(war.eq, family = binomial(link = "probit"), data = war)                 
summary(Probit)


coef(Probit)[(which(names(coef(Probit)) == "s(gdpenl).9"))]

coef(bpo0)[(which(names(coef(bpo)) == "s(gdpenl).9"))]


probitW &lt;- bpoW &lt;- bpoReb &lt;- bpoGov &lt;- NA
gdp.grid &lt;- seq(0, 8)

median.values &lt;- data.frame(t(apply(war, 2, FUN = median)))

for (i in 1:length(gdp.grid)){

newd &lt;- median.values; newd$gdpenl &lt;- gdp.grid[i]
eta1 &lt;- predict(bpo0, eq = 1, newd)
eta2 &lt;- predict(bpo0, eq = 2, newd)
probitW[i] &lt;- predict(Probit, newd, type = "response") 
bpoW[i]    &lt;- pnorm(eta1)*pnorm(eta2) 
bpoReb[i]  &lt;- pnorm(eta1) 
bpoGov[i]  &lt;- pnorm(eta2) 

}


plot(gdp.grid, probitW, type = "l", ylim = c(0, 0.55), lwd = 2, 
     col = "grey", xlab = "GDP per Capita (in thousands)", 
     ylab = "Pr(Outcome)", main = "Probabilities for All Outcomes", 
     cex.main = 1.5, cex.lab = 1.3, cex.axis = 1.3)
lines(gdp.grid, bpoW,   lwd = 2)
lines(gdp.grid, bpoReb, lwd = 2, lty = 2)
lines(gdp.grid, bpoGov, lwd = 2, lty = 3)

#dev.copy(postscript, "probWAR.eps", width = 8)
#dev.off() 


## End(Not run)

#

</code></pre>

<hr>
<h2 id='working.comp'>Internal Function</h2><span id='topic+working.comp'></span>

<h3>Description</h3>

<p>It efficiently calculates the working model quantities needed to implement the automatic multiple smoothing parameter estimation 
procedure by exploiting a result which leads to very fast and stable calculations.</p>


<h3>Author(s)</h3>

<p>Maintainer: Giampiero Marra <a href="mailto:giampiero.marra@ucl.ac.uk">giampiero.marra@ucl.ac.uk</a>
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
