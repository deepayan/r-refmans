<!DOCTYPE html><html><head><title>Help for package gmtFD</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {gmtFD}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#gmtFD'><p>General multiple tests for univariate and multivariate functional data</p></a></li>
<li><a href='#ph_test_statistic'><p>Pointwise Hotelling's <code class="reqn">T^2</code>-test statistic</p></a></li>
<li><a href='#summary.multifmanova'><p>Print &quot;multifmanova&quot; object</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>General Multiple Tests for Univariate and Multivariate
Functional Data</td>
</tr>
<tr>
<td>Version:</td>
<td>0.1.0</td>
</tr>
<tr>
<td>Date:</td>
<td>2024-06-05</td>
</tr>
<tr>
<td>Description:</td>
<td>The multiple contrast tests for univariate were proposed by Munko, Ditzhaus, Pauly, Smaga, and Zhang (2023) &lt;<a href="https://doi.org/10.48550%2FarXiv.2306.15259">doi:10.48550/arXiv.2306.15259</a>&gt;. Recently, they were extended to the multivariate functional data in Munko, Ditzhaus, Pauly, and Smaga (2024) &lt;<a href="https://doi.org/10.48550%2FarXiv.2406.01242">doi:10.48550/arXiv.2406.01242</a>&gt;. These procedures enable us to evaluate the overall hypothesis regarding equality, as well as specific hypotheses defined by contrasts. In particular, we can perform post hoc tests to examine particular comparisons of interest. Different experimental designs are supported, e.g., one-way and multi-way analysis of variance for functional data.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/LGPL-2">LGPL-2</a> | <a href="https://www.r-project.org/Licenses/LGPL-3">LGPL-3</a> | <a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>Imports:</td>
<td>Rcpp (&ge; 1.0.11), doParallel, MASS, foreach, Matrix, GFDmcv,
fda</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp, RcppArmadillo</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.1</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-06-07 14:19:57 UTC; ls</td>
</tr>
<tr>
<td>Author:</td>
<td>Marc Ditzhaus [aut],
  Merle Munko [aut],
  Markus Pauly [aut],
  Lukasz Smaga [aut, cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Lukasz Smaga &lt;ls@amu.edu.pl&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-06-10 16:50:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='gmtFD'>General multiple tests for univariate and multivariate functional data</h2><span id='topic+gmtFD'></span>

<h3>Description</h3>

<p>The function <code>gmtFD()</code> calculates the statistical tests based on globalizing and supremum 
pointwise Hotelling's <code class="reqn">T^2</code>-test statistics (GPH and SPH) for the global null hypothesis and 
multiple local null hypotheses. Respective <code class="reqn">p</code>-values are obtained by a parametric bootstrap strategy.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gmtFD(
  x,
  h,
  blocks_contrasts,
  n_boot = 1000,
  alpha = 0.05,
  parallel = FALSE,
  n_cores = NULL,
  multi_gen = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gmtFD_+3A_x">x</code></td>
<td>
<p>a list of <code class="reqn">k</code> elements corresponding to groups. Each element representing a group 
is a list of <code class="reqn">p</code> elements corresponding to functional variables, and each such element
(representing a functional variable) is a matrix of size <code class="reqn">n_i\times ntp</code> of descrete observations 
in design time points. <code class="reqn">ntp</code> denotes a number of design time points.</p>
</td></tr>
<tr><td><code id="gmtFD_+3A_h">h</code></td>
<td>
<p>contrast matrix. For contrast matrices based on Dunnett’s and Tukey’s contrasts, 
it can be created by the <code>contr_mat()</code> function from the package <code>GFDmcv</code> (see examples).</p>
</td></tr>
<tr><td><code id="gmtFD_+3A_blocks_contrasts">blocks_contrasts</code></td>
<td>
<p>a vector with blocks of contrasts labels. The integer labels (from 1 to a number 
of blocks of contrasts) should be used in non-decreasing order. For univariate case (<code class="reqn">p=1</code>), 
this is the vector representing group labels, e.g., for <code class="reqn">k=3</code> and Tukey's contrasts, we have <code>c(1, 2, 3)</code>.
For multivariate case (<code class="reqn">p&gt;1</code>), we have more possibilities. Mainly, we compare samples (groups) rather 
than particular functional variables, and then we use the vector grouping all variables in samples
taking into account contrasts, e.g., for <code class="reqn">k=4</code>, <code class="reqn">p=2</code> and Tukey's contrasts,
we have <code>c(1, 1, 2, 2, 3, 3, 4, 4, 5, 5, 6, 6)</code>, where pairs <code>(i,i)</code> for <code>i=1,...,6</code> 
represent the two variables of observations in the <code>i</code>th contrast. See examples.</p>
</td></tr>
<tr><td><code id="gmtFD_+3A_n_boot">n_boot</code></td>
<td>
<p>number of bootstrap samples.</p>
</td></tr>
<tr><td><code id="gmtFD_+3A_alpha">alpha</code></td>
<td>
<p>significance level.</p>
</td></tr>
<tr><td><code id="gmtFD_+3A_parallel">parallel</code></td>
<td>
<p>a logical indicating whether to use parallelization.</p>
</td></tr>
<tr><td><code id="gmtFD_+3A_n_cores">n_cores</code></td>
<td>
<p>if <code>parallel = TRUE</code>, a number of processes used in parallel computation.
Its default value means that it will be equal to the number of cores of a computer used.</p>
</td></tr>
<tr><td><code id="gmtFD_+3A_multi_gen">multi_gen</code></td>
<td>
<p>a logical indicating of whether to use separate multiple generations of Gaussian processes
for the parametric bootstrap tests. The default is FALSE, which means that the processes will be
generated once in a big matrix. This method is much faster, but for larger <code class="reqn">n=n_1+\dots+n_k</code> and <code class="reqn">p</code>
the generated data can be too large for RAM. In such a case, we suggest using separate generation
(<code>multi_gen = TRUE</code>), which is slower, but possible to calculate.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function <code>gmtFD()</code> concerns the tests for the heteroscedastic
contrast testing problem for univariate and multivariate functional data. The details are 
presented in Munko et al. (2023, 2024), but here we present some summary of the problem 
and its solutions implemented in the package.
</p>
<p>Suppose we have <code class="reqn">k</code> independent functional samples <code class="reqn">\mathbf{x}_{i1},\dots,\mathbf{x}_{in_i}</code>,
which consist of independent and identically distributed <code class="reqn">p</code>-dimensional stochastic processes defined
on interval <code class="reqn">\mathcal{T}</code> with mean function vector <code class="reqn">\boldsymbol{\eta}_i</code> and covariance function
<code class="reqn">\boldsymbol{\Gamma}_i</code> for each <code class="reqn">i\in\{1,\dots,k\}</code>. Note that the covariance functions
of the different groups may differ from each other, i.e., heteroscedasticity is explicitly allowed.
</p>
<p>We consider the null and alternative hypothesis
</p>
<p style="text-align: center;"><code class="reqn">\mathcal H_0: \mathbf{H}\boldsymbol{\eta}(t) =\mathbf{0}_r \text{ for all }
t\in \mathcal{T} \quad \text{vs.} \quad \mathcal H_1: \mathbf{H}\boldsymbol{\eta}(t) \neq
\mathbf{0}_r \text{ for some } t\in \mathcal{T},</code>
</p>
<p> where <code class="reqn">\mathbf{H} \in \mathbb{R}^{r \times pk}</code>
denotes a known contrast matrix, i.e., <code class="reqn">\mathbf{H}\mathbf{1}_{pk} = \mathbf{0}_r</code>, and 
<code class="reqn">\boldsymbol{\eta} := (\boldsymbol{\eta}_1^{\top},\dots,\boldsymbol{\eta}_k^{\top})^{\top}</code> 
is the vector of the mean functions. The formulation of this testing framework is very general
and contains many special cases like the analysis of variance for univariate and multivariate functional data
(FANOVA and FMANOVA) problems. 
</p>
<p>For univariate functional data (<code class="reqn">p=1</code>), we may choose <code class="reqn">\mathbf{H} = \mathbf{P}_k</code> 
for the one-way FANOVA problem to test the null hypothesis of no main effect, where 
<code class="reqn">\mathbf{P}_k:=\mathbf{I}_k-\mathbf{J}_k/k</code> with <code class="reqn">\mathbf{I}_k \in\mathbb{R}^{k\times k}</code> 
denoting the unit matrix and <code class="reqn">\mathbf{J}_k := \mathbf{1}_k\mathbf{1}_k^{\top} \in\mathbb{R}^{k\times k}</code>
denoting the matrix of ones. However, there are different possible choices of the
contrast matrix <code class="reqn">\mathbf{H}</code> which lead to this global null hypothesis.
Many-to-one comparisons can be considered by choosing Dunnett's contrast matrix
<code class="reqn">\mathbf{H} = [-\mathbf{1}_{k-1}, \mathbf{I}_{k-1}]</code>, where the mean
functions <code class="reqn">\eta_2,\dots,\eta_k</code> are compared to the mean function <code class="reqn">\eta_1</code>
of the first group regarding the different contrasts. To compare all pairs
of mean functions <code class="reqn">\eta_{i_1},\eta_{i_2}, i_1,i_2 \in\{1,\dots,k\}</code> with
<code class="reqn">i_1 \neq i_2</code>, the Tukey's contrast matrix:
</p>
<p style="text-align: center;"><code class="reqn">\mathbf{H} = \begin{bmatrix}
 -1 &amp; 1 &amp; 0 &amp; 0 &amp; \cdots &amp; \cdots &amp; 0 \\
 -1 &amp; 0 &amp; 1 &amp; 0 &amp;\cdots &amp; \cdots &amp; 0 \\
 \vdots  &amp; \vdots &amp;\vdots &amp; \vdots &amp; \ddots &amp; \vdots &amp; \vdots  \\
 -1 &amp; 0 &amp; 0 &amp; 0&amp; \cdots &amp; \cdots &amp; 1\\
 0 &amp; -1 &amp; 1 &amp; 0&amp; \cdots &amp; \cdots &amp; 0 \\
 0 &amp; -1 &amp; 0 &amp; 1&amp; \cdots &amp; \cdots &amp; 0 \\
 \vdots  &amp; \vdots &amp; \vdots  &amp; \vdots &amp; \ddots &amp; \vdots &amp; \vdots \\
 0 &amp; 0 &amp; 0 &amp; 0 &amp; \cdots &amp; -1 &amp; 1
 \end{bmatrix}  \in \mathbb{R}^{k(k-1)/2 \times k}</code>
</p>
<p> can be used.
</p>
<p>For multivariate functional data (<code class="reqn">p&gt;1</code>), we extend the matrices for <code class="reqn">p=1</code> given above
as follows: <code class="reqn">\mathbf{H}=\mathbf{H}_1\otimes \mathbf{I}_p</code>, where <code class="reqn">\mathbf{H}_1</code> is the
contrast matrix for the univariate case. For more examples of contrast matrices in different
settings, see Merle et al. (2023, 2024).
</p>
<p>For this testing problem, we consider the pointwise Hotelling's <code class="reqn">T^2</code>-test statistic
</p>
<p style="text-align: center;"><code class="reqn">\mathrm{PH}_{n,\mathbf{H}}(t):= n(\mathbf{H}\boldsymbol{\widehat\eta}(t))^{\top}
 (\mathbf{H}\mathbf{\widehat \Gamma}(t,t) \mathbf{H}^{\top})^+
 \mathbf{H} \boldsymbol{\widehat\eta}(t)</code>
</p>

<p>for all <code class="reqn">t \in\mathcal{T}</code>, where 
<code class="reqn">\boldsymbol{\widehat\eta} := (\boldsymbol{\widehat\eta}_1^{\top},\dots,\boldsymbol{\widehat\eta}_k^{\top})^{\top}</code>
denotes the vector of all mean function estimators, <code class="reqn">\mathbf{A}^+</code> denotes the
Moore-Penrose inverse of the matrix <code class="reqn">\mathbf{A}</code>, and
</p>
<p style="text-align: center;"><code class="reqn">\boldsymbol{\widehat{\Gamma}}(t,s):= \mathrm{diag}\left( \frac{n}{n_1}\widehat{\boldsymbol{\Gamma}}_1(t,s),
 \ldots,\frac{n}{n_k}\widehat{\boldsymbol{\Gamma}}_k(t,s)\right),</code>
</p>
 <p><code class="reqn">n=n_1+\dots+n_k</code>, 
<code class="reqn">\widehat{\boldsymbol{\Gamma}}_i(t,s)</code> is the sample covariance function for the <code class="reqn">i</code>-th group, 
<code class="reqn">i\in\{1,\dots,k\}</code>. Based on this pointwise Hotelling's <code class="reqn">T^2</code>-test statistic, we construct the globalizing
and supremum of pointwise Hotelling's <code class="reqn">T^2</code>-test (GPH and SPH) statistics by integrating and supremum over 
the pointwise Hotelling's <code class="reqn">T^2</code>-test statistic, that is
</p>
<p style="text-align: center;"><code class="reqn">I_{n}(\mathbf{H}) := \int_{\mathcal{T}} \mathrm{PH}_{n,\mathbf{H}}(t) \,\mathrm{ d }t,\ \ 
 T_{n}(\mathbf{H}) := \mathrm{sup}_{t\in\mathcal{T}} \mathrm{PH}_{n,\mathbf{H}}(t).</code>
</p>

<p>We consider the parametric bootstrap test based on these test statistics. However, for better post hoc
analysis, we also consider the multiple contrast testing procedures. The main idea of multiple contrast
tests is to split up the global null hypothesis with matrix
<code class="reqn">\mathbf{H}= [\mathbf{H}_1^{\top}, \dots, \mathbf{H}_R^{\top}]^{\top}</code> into <code class="reqn">R</code> matrices 
<code class="reqn">\mathbf{H}_{\ell}\in\mathbb{R}^{r_{\ell}\times k}</code> with <code class="reqn">\mathrm{rank}(\mathbf{H}_{\ell})\geq 1</code>, 
<code class="reqn">\ell\in\{1,\dots,R\}</code>, where <code class="reqn">R,r_{\ell}\in\{1,\dots,r\}</code>, and <code class="reqn">\sum_{\ell=1}^Rr_{\ell}=r</code>.
This leads to the multiple testing problem with null hypotheses
</p>
<p style="text-align: center;"><code class="reqn">\mathcal H_{0,{\ell}} : \; \mathbf{H}_{\ell} \boldsymbol{\eta}(t) =
 \mathbf{0}_{r_{\ell}} \;\text{ for all }t\in\mathcal{T},	\text{for }\ell\in \{1,\ldots,R\}.</code>
</p>

<p>To verify this family of null hypotheses, we adopt two approaches. First, we simply apply
the above test to each hypothesis <code class="reqn">\mathcal H_{0,{\ell}}</code>, and the resulting <code class="reqn">p</code>-values
are then corrected by the Bonferroni's method. However, this approach, denoted in the package as
GPH and SPH, may give conservative test and loss of power. Thus, we also consider the test adopting the
idea for the construction of simultaneous confidence bands proposed by Buhlmann (1998).
This test is denoted by mGPH and mSPH in the package and is a more powerful solution than the GPH and SPH
procedures, which was shown in Munko et al. (2023, 2024).
</p>
<p>Note that the value of the test statistics for the mGPH and mSPH tests for global hypotheses are
equal to </p>
<p style="text-align: center;"><code class="reqn">\max_{\ell\in\{1,\ldots,R\}}\frac{I_{n}(\mathbf{H}_{\ell})}{q_{GPH,\ell,\widetilde{\beta}}^{\mathcal{P}}}\text{ and }
\max_{\ell\in\{1,\ldots,R\}}\frac{T_{n}(\mathbf{H}_{\ell})}{q_{SPH,\ell,\widetilde{\beta}}^{\mathcal{P}}},</code>
</p>

<p>respectively, where <code class="reqn">q_{GPH,\ell,\widetilde{\beta}}^{\mathcal{P}}</code> and <code class="reqn">q_{SPH,\ell,\widetilde{\beta}}^{\mathcal{P}}</code> 
are the quantiles calculated using the adaptation of the method by Buhlmann (1998). 
The critical value for it is always 1.
</p>
<p>Please have a look at a summary function designed for this package. It can be used
to simplify the output of <code>gmtFD()</code> function.
</p>


<h3>Value</h3>

<p>A list of class <code>multifmanova</code> containing the following components:
</p>
<table>
<tr><td><code>res_global</code></td>
<td>
<p>a data frame containing the results for testing the global null hypothesis,
i.e., test statistics and <code class="reqn">p</code>-values.</p>
</td></tr>
<tr><td><code>res_multi</code></td>
<td>
<p>all results of multiple contrasts tests for particular hypothesis in
a contrast matrix <code>h</code>, i.e., test statistics, critical values and <code class="reqn">p</code>-values.</p>
</td></tr>
<tr><td><code>k</code></td>
<td>
<p>a number of groups.</p>
</td></tr>
<tr><td><code>p</code></td>
<td>
<p>a number of variables.</p>
</td></tr>
<tr><td><code>ntp</code></td>
<td>
<p>a number of design time points.</p>
</td></tr>
<tr><td><code>n</code></td>
<td>
<p>a vector of sample sizes.</p>
</td></tr>
<tr><td><code>h</code></td>
<td>
<p>an argument <code>h</code>.</p>
</td></tr>
<tr><td><code>n_boot</code></td>
<td>
<p>an argument <code>n_boot</code>.</p>
</td></tr>
<tr><td><code>alpha</code></td>
<td>
<p>an argument <code>alpha</code>.</p>
</td></tr>
<tr><td><code>multi_gen</code></td>
<td>
<p>an argument <code>multi_gen</code>.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Buhlmann P. (1998) Sieve bootstrap for smoothing in nonstationary time series.
Annals of Statistics 26, 48-83.
</p>
<p>Dunnett C. (1955) A multiple comparison procedure for comparing several treatments
with a control. Journal of the American Statistical Association 50, 1096-1121.
</p>
<p>Munko M., Ditzhaus M., Pauly M., Smaga L., Zhang J.T. (2023) General multiple tests for functional data. 
Preprint https://arxiv.org/abs/2306.15259
</p>
<p>Munko M., Ditzhaus M., Pauly M., Smaga L. (2024) Multiple comparison procedures for simultaneous inference 
in functional MANOVA. Preprint https://arxiv.org/abs/2406.01242
</p>
<p>Tukey J.W. (1953) The problem of multiple comparisons. Princeton University.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Some of the examples may run some time.

# Canadian weather data set
# There are three samples of mean temperature and precipitations for
# fifteen weather stations in Western Canada, another fifteen in Eastern Canada, 
# and the remaining five in Northern Canada.

# one functional variable - temperature
library(fda)
data_set_t &lt;- t(CanadianWeather$dailyAv[,, "Temperature.C"])
# number of samples
k &lt;- 3
# number of variables
p &lt;- 1
# preparing data set
gr_label &lt;- rep(c(1, 2, 3), c(15, 15, 5))
data_set &lt;- list(list(data_set_t[gr_label == 1, ]),
                 list(data_set_t[gr_label == 2, ]),
                 list(data_set_t[gr_label == 3, ]))
# trajectories of mean temperature and precipitation
oldpar &lt;- par(mar = c(4, 4, 2, 0.1))
matplot(t(data_set_t), type = "l", col = gr_label, lty = 1,
        xlab = "Day", ylab = "Temperature (C)",
        main = "Canadian weather data set")
legend("bottom", legend = c("Western Canada", "Eastern Canada", "Northern Canada"),
       col = 1:3, lty = 1)
par(oldpar)

# Tukey's contrast matrix
h_tukey &lt;- GFDmcv::contr_mat(k, type = "Tukey")
h_tukey_m &lt;- kronecker(h_tukey, diag(p))
# vector of blocks of contrasts labels
blocks_contrasts &lt;- rep(1:(nrow(h_tukey_m) / p), each = p)

# testing without parallel computing
res &lt;- gmtFD(data_set, h_tukey_m, blocks_contrasts)
summary(res, digits = 3)
# plots for pointwise Hotelling's T^2-test statistics
oldpar &lt;- par(mfrow = c(2, 2), mar = c(4, 2, 2, 0.1))
plot(ph_test_statistic(data_set, h_tukey_m), type = "l",
     ylim = c(0, max(ph_test_statistic(data_set, h_tukey_m))),
     main = "Global hypothesis", xlab = "Day")
plot(ph_test_statistic(data_set, matrix(h_tukey_m[1, ], 1)), type = "l",
     ylim = c(0, max(ph_test_statistic(data_set, h_tukey_m))),
     main = "Contrast 1", xlab = "Day")
plot(ph_test_statistic(data_set, matrix(h_tukey_m[2, ], 1)), type = "l",
     ylim = c(0, max(ph_test_statistic(data_set, h_tukey_m))),
     main = "Contrast 2", xlab = "Day")
plot(ph_test_statistic(data_set, matrix(h_tukey_m[3, ], 1)), type = "l",
     ylim = c(0, max(ph_test_statistic(data_set, h_tukey_m))),
     main = "Contrast 3", xlab = "Day")
par(oldpar)

# Dunnett's contrast matrix
h_dunnett &lt;- GFDmcv::contr_mat(k, type = "Dunnett")
h_dunnett_m &lt;- kronecker(h_dunnett, diag(p))
# vector of blocks of contrasts labels
blocks_contrasts &lt;- rep(1:(nrow(h_dunnett_m) / p), each = p)

# testing without parallel computing
res &lt;- gmtFD(data_set, h_dunnett_m, blocks_contrasts)
summary(res, digits = 3)
# plots for pointwise Hotelling's T^2-test statistics
oldpar &lt;- par(mfrow = c(3, 1), mar = c(4, 2, 2, 0.1))
plot(ph_test_statistic(data_set, h_dunnett_m), type = "l",
     ylim = c(0, max(ph_test_statistic(data_set, h_dunnett_m))),
     main = "Global hypothesis", xlab = "Day")
plot(ph_test_statistic(data_set, matrix(h_dunnett_m[1, ], 1)), type = "l",
     ylim = c(0, max(ph_test_statistic(data_set, h_dunnett_m))),
     main = "Contrast 1", xlab = "Day")
plot(ph_test_statistic(data_set, matrix(h_dunnett_m[2, ], 1)), type = "l",
     ylim = c(0, max(ph_test_statistic(data_set, h_dunnett_m))),
     main = "Contrast 2", xlab = "Day")
par(oldpar)

# two functional variables - temperature and precipitation
library(fda)
data_set_t &lt;- t(CanadianWeather$dailyAv[,, "Temperature.C"])
data_set_p &lt;- t(CanadianWeather$dailyAv[,, "Precipitation.mm"])
# number of samples
k &lt;- 3
# number of variables
p &lt;- 2
# preparing data set
gr_label &lt;- rep(c(1, 2, 3), c(15, 15, 5))
data_set &lt;- list(list(data_set_t[gr_label == 1, ], data_set_p[gr_label == 1, ]),
                 list(data_set_t[gr_label == 2, ], data_set_p[gr_label == 2, ]),
                 list(data_set_t[gr_label == 3, ], data_set_p[gr_label == 3, ]))
# trajectories of mean temperature and precipitation
oldpar &lt;- par(mfrow = c(1, 2), mar = c(4, 4, 2, 0.1))
matplot(t(data_set_t), type = "l", col = gr_label, lty = 1,
        xlab = "Day", ylab = "Temperature (C)",
        main = "Canadian weather data set")
legend("bottom", legend = c("Western Canada", "Eastern Canada", "Northern Canada"),
       col = 1:3, lty = 1)
matplot(t(data_set_p), type = "l", col = gr_label, lty = 1,
        xlab = "Day", ylab = "Precipitation (mm)",
        main = "Canadian weather data set")
legend("topleft", legend = c("Western Canada", "Eastern Canada", "Northern Canada"),
       col = 1:3, lty = 1)
par(oldpar)

# Tukey's contrast matrix
h_tukey &lt;- GFDmcv::contr_mat(k, type = "Tukey")
h_tukey_m &lt;- kronecker(h_tukey, diag(p))
# vector of blocks of contrasts labels
blocks_contrasts &lt;- rep(1:(nrow(h_tukey_m) / p), each = p)

# testing without parallel computing
res &lt;- gmtFD(data_set, h_tukey_m, blocks_contrasts)
summary(res, digits = 3)
# plots for pointwise Hotelling's T^2-test statistics
oldpar &lt;- par(mfrow = c(2, 2), mar = c(4, 2, 2, 0.1))
plot(ph_test_statistic(data_set, h_tukey_m), type = "l",
     ylim = c(0, max(ph_test_statistic(data_set, h_tukey_m))),
     main = "Global hypothesis", xlab = "Day")
plot(ph_test_statistic(data_set, h_tukey_m[1:2, ]), type = "l",
     ylim = c(0, max(ph_test_statistic(data_set, h_tukey_m))),
     main = "Contrast 1", xlab = "Day")
plot(ph_test_statistic(data_set, h_tukey_m[3:4, ]), type = "l",
     ylim = c(0, max(ph_test_statistic(data_set, h_tukey_m))),
     main = "Contrast 2", xlab = "Day")
plot(ph_test_statistic(data_set, h_tukey_m[5:6, ]), type = "l",
     ylim = c(0, max(ph_test_statistic(data_set, h_tukey_m))),
     main = "Contrast 3", xlab = "Day")
par(oldpar)

# Dunnett's contrast matrix
h_dunnett &lt;- GFDmcv::contr_mat(k, type = "Dunnett")
h_dunnett_m &lt;- kronecker(h_dunnett, diag(p))
# vector of blocks of contrasts labels
blocks_contrasts &lt;- rep(1:(nrow(h_dunnett_m) / p), each = p)

# testing without parallel computing
res &lt;- gmtFD(data_set, h_dunnett_m, blocks_contrasts)
summary(res, digits = 3)
# plots for pointwise Hotelling's T^2-test statistics
oldpar &lt;- par(mfrow = c(3, 1), mar = c(4, 2, 2, 0.1))
plot(ph_test_statistic(data_set, h_dunnett_m), type = "l",
     ylim = c(0, max(ph_test_statistic(data_set, h_dunnett_m))),
     main = "Global hypothesis", xlab = "Day")
plot(ph_test_statistic(data_set, matrix(h_dunnett_m[1, ], 1)), type = "l",
     ylim = c(0, max(ph_test_statistic(data_set, h_dunnett_m))),
     main = "Contrast 1", xlab = "Day")
plot(ph_test_statistic(data_set, matrix(h_dunnett_m[2, ], 1)), type = "l",
     ylim = c(0, max(ph_test_statistic(data_set, h_dunnett_m))),
     main = "Contrast 2", xlab = "Day")
par(oldpar)

# testing with parallel computing
library(doParallel)
blocks_contrasts &lt;- rep(1:(nrow(h_tukey_m) / p), each = p)
res &lt;- gmtFD(data_set, h_tukey_m, blocks_contrasts, parallel = TRUE, n_cores = 2)
summary(res, digits = 3)

</code></pre>

<hr>
<h2 id='ph_test_statistic'>Pointwise Hotelling's <code class="reqn">T^2</code>-test statistic</h2><span id='topic+ph_test_statistic'></span>

<h3>Description</h3>

<p>The function <code>ph_test_statistic()</code> calculates the pointwise Hotelling's <code class="reqn">T^2</code>-test statistic.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ph_test_statistic(x, h)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ph_test_statistic_+3A_x">x</code></td>
<td>
<p>a list of <code class="reqn">k</code> elements corresponding to groups. Each element representing a group 
is a list of <code class="reqn">p</code> elements corresponding to functional variables, and each such element
(representing a functional variable) is a matrix of size <code class="reqn">n_i\times ntp</code> of descrete observations 
in design time points. <code class="reqn">ntp</code> denotes a number of design time points.</p>
</td></tr>
<tr><td><code id="ph_test_statistic_+3A_h">h</code></td>
<td>
<p>contrast matrix. For contrast matrices based on Dunnett’s and Tukey’s contrasts, 
it can be created by the <code>contr_mat()</code> function from the package <code>GFDmcv</code> (see examples).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For details, see the documentation of the <code>gmtFD()</code> function or
the papers Munko et al. (2023, 2024).
</p>


<h3>Value</h3>

<p>A vector of values of the pointwise Hotelling's <code class="reqn">T^2</code>-test statistic.
</p>


<h3>References</h3>

<p>Dunnett C. (1955) A multiple comparison procedure for comparing several treatments
with a control. Journal of the American Statistical Association 50, 1096-1121.
</p>
<p>Munko M., Ditzhaus M., Pauly M., Smaga L., Zhang J.T. (2023) General multiple tests for functional data. 
Preprint https://arxiv.org/abs/2306.15259
</p>
<p>Munko M., Ditzhaus M., Pauly M., Smaga L. (2024) Multiple comparison procedures for simultaneous inference 
in functional MANOVA. Preprint https://arxiv.org/abs/2406.01242
</p>
<p>Tukey J.W. (1953) The problem of multiple comparisons. Princeton University.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Some of the examples may run some time.

# Canadian weather data set
# There are three samples of mean temperature and precipitations for
# fifteen weather stations in Western Canada, another fifteen in Eastern Canada, 
# and the remaining five in Northern Canada.

# one functional variable - temperature
library(fda)
data_set_t &lt;- t(CanadianWeather$dailyAv[,, "Temperature.C"])
# number of samples
k &lt;- 3
# number of variables
p &lt;- 1
# preparing data set
gr_label &lt;- rep(c(1, 2, 3), c(15, 15, 5))
data_set &lt;- list(list(data_set_t[gr_label == 1, ]),
                 list(data_set_t[gr_label == 2, ]),
                 list(data_set_t[gr_label == 3, ]))

# Tukey's contrast matrix
h_tukey &lt;- GFDmcv::contr_mat(k, type = "Tukey")
h_tukey_m &lt;- kronecker(h_tukey, diag(p))
# plots for pointwise Hotelling's T^2-test statistics
oldpar &lt;- par(mfrow = c(2, 2), mar = c(4, 2, 2, 0.1))
plot(ph_test_statistic(data_set, h_tukey_m), type = "l",
     ylim = c(0, max(ph_test_statistic(data_set, h_tukey_m))),
     main = "Global hypothesis", xlab = "Day")
plot(ph_test_statistic(data_set, matrix(h_tukey_m[1, ], 1)), type = "l",
     ylim = c(0, max(ph_test_statistic(data_set, h_tukey_m))),
     main = "Contrast 1", xlab = "Day")
plot(ph_test_statistic(data_set, matrix(h_tukey_m[2, ], 1)), type = "l",
     ylim = c(0, max(ph_test_statistic(data_set, h_tukey_m))),
     main = "Contrast 2", xlab = "Day")
plot(ph_test_statistic(data_set, matrix(h_tukey_m[3, ], 1)), type = "l",
     ylim = c(0, max(ph_test_statistic(data_set, h_tukey_m))),
     main = "Contrast 3", xlab = "Day")
par(oldpar)

# Dunnett's contrast matrix
h_dunnett &lt;- GFDmcv::contr_mat(k, type = "Dunnett")
h_dunnett_m &lt;- kronecker(h_dunnett, diag(p))
# plots for pointwise Hotelling's T^2-test statistics
oldpar &lt;- par(mfrow = c(3, 1), mar = c(4, 2, 2, 0.1))
plot(ph_test_statistic(data_set, h_dunnett_m), type = "l",
     ylim = c(0, max(ph_test_statistic(data_set, h_dunnett_m))),
     main = "Global hypothesis", xlab = "Day")
plot(ph_test_statistic(data_set, matrix(h_dunnett_m[1, ], 1)), type = "l",
     ylim = c(0, max(ph_test_statistic(data_set, h_dunnett_m))),
     main = "Contrast 1", xlab = "Day")
plot(ph_test_statistic(data_set, matrix(h_dunnett_m[2, ], 1)), type = "l",
     ylim = c(0, max(ph_test_statistic(data_set, h_dunnett_m))),
     main = "Contrast 2", xlab = "Day")
par(oldpar)

# two functional variables - temperature and precipitation
library(fda)
data_set_t &lt;- t(CanadianWeather$dailyAv[,, "Temperature.C"])
data_set_p &lt;- t(CanadianWeather$dailyAv[,, "Precipitation.mm"])
# number of samples
k &lt;- 3
# number of variables
p &lt;- 2
# preparing data set
gr_label &lt;- rep(c(1, 2, 3), c(15, 15, 5))
data_set &lt;- list(list(data_set_t[gr_label == 1, ], data_set_p[gr_label == 1, ]),
                 list(data_set_t[gr_label == 2, ], data_set_p[gr_label == 2, ]),
                 list(data_set_t[gr_label == 3, ], data_set_p[gr_label == 3, ]))

# Tukey's contrast matrix
h_tukey &lt;- GFDmcv::contr_mat(k, type = "Tukey")
h_tukey_m &lt;- kronecker(h_tukey, diag(p))
# plots for pointwise Hotelling's T^2-test statistics
oldpar &lt;- par(mfrow = c(2, 2), mar = c(4, 2, 2, 0.1))
plot(ph_test_statistic(data_set, h_tukey_m), type = "l",
     ylim = c(0, max(ph_test_statistic(data_set, h_tukey_m))),
     main = "Global hypothesis", xlab = "Day")
plot(ph_test_statistic(data_set, h_tukey_m[1:2, ]), type = "l",
     ylim = c(0, max(ph_test_statistic(data_set, h_tukey_m))),
     main = "Contrast 1", xlab = "Day")
plot(ph_test_statistic(data_set, h_tukey_m[3:4, ]), type = "l",
     ylim = c(0, max(ph_test_statistic(data_set, h_tukey_m))),
     main = "Contrast 2", xlab = "Day")
plot(ph_test_statistic(data_set, h_tukey_m[5:6, ]), type = "l",
     ylim = c(0, max(ph_test_statistic(data_set, h_tukey_m))),
     main = "Contrast 3", xlab = "Day")
par(oldpar)

# Dunnett's contrast matrix
h_dunnett &lt;- GFDmcv::contr_mat(k, type = "Dunnett")
h_dunnett_m &lt;- kronecker(h_dunnett, diag(p))
# plots for pointwise Hotelling's T^2-test statistics
oldpar &lt;- par(mfrow = c(3, 1), mar = c(4, 2, 2, 0.1))
plot(ph_test_statistic(data_set, h_dunnett_m), type = "l",
     ylim = c(0, max(ph_test_statistic(data_set, h_dunnett_m))),
     main = "Global hypothesis", xlab = "Day")
plot(ph_test_statistic(data_set, matrix(h_dunnett_m[1, ], 1)), type = "l",
     ylim = c(0, max(ph_test_statistic(data_set, h_dunnett_m))),
     main = "Contrast 1", xlab = "Day")
plot(ph_test_statistic(data_set, matrix(h_dunnett_m[2, ], 1)), type = "l",
     ylim = c(0, max(ph_test_statistic(data_set, h_dunnett_m))),
     main = "Contrast 2", xlab = "Day")
par(oldpar)

</code></pre>

<hr>
<h2 id='summary.multifmanova'>Print &quot;multifmanova&quot; object</h2><span id='topic+summary.multifmanova'></span>

<h3>Description</h3>

<p>Prints the summary of the global and multiple contrasts testing for functional data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'multifmanova'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.multifmanova_+3A_object">object</code></td>
<td>
<p>a &quot;multifmanova&quot; object.</p>
</td></tr>
<tr><td><code id="summary.multifmanova_+3A_...">...</code></td>
<td>
<p>integer indicating the number of decimal places to be used to present the numerical results.
It can be named <code>digits</code> as in the <code>round()</code> function (see examples).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function prints out the information about the number of functional variables, 
number of samples, number of observations in each sample, number of design time points, 
contrasts used, test statistics, critical values, <code class="reqn">p</code>-values of tests performed by the
<code>gmtFD()</code> function. It also gives the decisions.
</p>


<h3>Value</h3>

<p>No return value, called for side effects.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Some of the examples may run some time.

# Canadian weather data set
# There are three samples of mean temperature and precipitations for
# fifteen weather stations in Western Canada, another fifteen in Eastern Canada, 
# and the remaining five in Northern Canada.

# one functional variable - temperature
library(fda)
data_set_t &lt;- t(CanadianWeather$dailyAv[,, "Temperature.C"])
# number of samples
k &lt;- 3
# number of variables
p &lt;- 1
# preparing data set
gr_label &lt;- rep(c(1, 2, 3), c(15, 15, 5))
data_set &lt;- list(list(data_set_t[gr_label == 1, ]),
                 list(data_set_t[gr_label == 2, ]),
                 list(data_set_t[gr_label == 3, ]))

# Tukey's contrast matrix
h_tukey &lt;- GFDmcv::contr_mat(k, type = "Tukey")
h_tukey_m &lt;- kronecker(h_tukey, diag(p))
# vector of blocks of contrasts labels
blocks_contrasts &lt;- rep(1:(nrow(h_tukey_m) / p), each = p)

# testing without parallel computing
res &lt;- gmtFD(data_set, h_tukey_m, blocks_contrasts)
summary(res, digits = 3)

# two functional variables - temperature and precipitation
library(fda)
data_set_t &lt;- t(CanadianWeather$dailyAv[,, "Temperature.C"])
data_set_p &lt;- t(CanadianWeather$dailyAv[,, "Precipitation.mm"])
# number of samples
k &lt;- 3
# number of variables
p &lt;- 2
# preparing data set
gr_label &lt;- rep(c(1, 2, 3), c(15, 15, 5))
data_set &lt;- list(list(data_set_t[gr_label == 1, ], data_set_p[gr_label == 1, ]),
                 list(data_set_t[gr_label == 2, ], data_set_p[gr_label == 2, ]),
                 list(data_set_t[gr_label == 3, ], data_set_p[gr_label == 3, ]))

# Tukey's contrast matrix
h_tukey &lt;- GFDmcv::contr_mat(k, type = "Tukey")
h_tukey_m &lt;- kronecker(h_tukey, diag(p))
# vector of blocks of contrasts labels
blocks_contrasts &lt;- rep(1:(nrow(h_tukey_m) / p), each = p)

# testing without parallel computing
res &lt;- gmtFD(data_set, h_tukey_m, blocks_contrasts)
summary(res, digits = 3)

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
