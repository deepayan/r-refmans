<!DOCTYPE html><html><head><title>Help for package TSclust</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {TSclust}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#TSclust'>
<p>Package for Time Series Clustering.</p></a></li>
<li><a href='#cluster.evaluation'>
<p>Clustering Evaluation Index Based on Known Ground Truth</p></a></li>
<li><a href='#diss'>
<p>TSclust Dissimilarity Computation</p></a></li>
<li><a href='#diss.ACF'>
<p>Autocorrelation-based Dissimilarity</p></a></li>
<li><a href='#diss.AR.LPC.CEPS'>
<p>Dissimilarity Based on LPC Cepstral Coefficients</p></a></li>
<li><a href='#diss.AR.MAH'>
<p>Model-based Dissimilarity Proposed by Maharaj (1996, 2000)</p></a></li>
<li><a href='#diss.AR.PIC'>
<p>Model-based Dissimilarity Measure Proposed by Piccolo (1990)</p></a></li>
<li><a href='#diss.CDM'>
<p>Compression-based Dissimilarity measure</p></a></li>
<li><a href='#diss.CID'>
<p>Complexity-Invariant Distance Measure For Time Series</p></a></li>
<li><a href='#diss.COR'>
<p>Correlation-based Dissimilarity</p></a></li>
<li><a href='#diss.CORT'>
<p>Dissimilarity Index Combining Temporal Correlation and Raw Values Behaviors</p></a></li>
<li><a href='#diss.DTWARP'>
<p>Dynamic Time Warping Distance</p></a></li>
<li><a href='#diss.DWT'>
<p>Dissimilarity for Time Series Based on Wavelet Feature Extraction</p></a></li>
<li><a href='#diss.EUCL'>
<p>Euclidean Distance</p></a></li>
<li><a href='#diss.FRECHET'>
<p>Frechet Distance</p></a></li>
<li><a href='#diss.INT.PER'>
<p>Integrated Periodogram Based Dissimilarity</p></a></li>
<li><a href='#diss.MINDIST.SAX'>
<p>Symbolic Aggregate Aproximation related functions</p></a></li>
<li><a href='#diss.NCD'>
<p>Normalized Compression Distance</p></a></li>
<li><a href='#diss.PDC'>
<p>Permutation Distribution Distance</p></a></li>
<li><a href='#diss.PER'>
<p>Periodogram Based Dissimilarity</p></a></li>
<li><a href='#diss.PRED'>
<p>Dissimilarity Measure Based on Nonparametric Forecast</p></a></li>
<li><a href='#diss.SPEC.GLK'>
<p>Dissimilarity based on the Generalized Likelihood Ratio Test</p></a></li>
<li><a href='#diss.SPEC.ISD'>
<p>Dissimilarity Based on the Integrated Squared Difference between the Log-Spectra</p></a></li>
<li><a href='#diss.SPEC.LLR'>
<p>General Spectral Dissimilarity Measure Using Local-Linear Estimation of the Log-Spectra</p></a></li>
<li><a href='#electricity'>
<p>Hourly Electricity Prices in the Spanish Market</p></a></li>
<li><a href='#interest.rates'>
<p>Long-Term Interest Rates from 1995 to 2012</p></a></li>
<li><a href='#loo1nn.cv'>
<p>Clustering Evaluation Index Based on Leave-one-out One-nearest-neighbor Evaluation</p></a></li>
<li><a href='#paired.tseries'>
<p>Pairs of Time Series from Different Domains</p></a></li>
<li><a href='#pvalues.clust'>
<p>Clustering Algorithm Based on p-values.</p></a></li>
<li><a href='#synthetic.tseries'>
<p>Synthetic Time Series for Clustering Performace Comparisons.</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Time Series Clustering Utilities</td>
</tr>
<tr>
<td>Version:</td>
<td>1.3.1</td>
</tr>
<tr>
<td>Date:</td>
<td>2020-7-16</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Description:</td>
<td>A set of measures of dissimilarity between time series to perform time series clustering. Metrics based on raw data, on generating models and on the forecast behavior are implemented. Some additional utilities related to time series clustering are also provided, such as clustering algorithms and cluster evaluation metrics.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a></td>
</tr>
<tr>
<td>URL:</td>
<td><a href="http://www.jstatsoft.org/v62/i01/">http://www.jstatsoft.org/v62/i01/</a></td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.0.2), pdc, cluster</td>
</tr>
<tr>
<td>Imports:</td>
<td>locpol, KernSmooth, dtw, longitudinalData, forecast</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>6.0.1.9000</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2020-07-21 06:28:15 UTC; pmon0003</td>
</tr>
<tr>
<td>Author:</td>
<td>Pablo Montero Manso [cre],
  Jose Vilar Fernandez [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Pablo Montero Manso &lt;pmontm@gmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2020-07-22 21:10:21 UTC</td>
</tr>
</table>
<hr>
<h2 id='TSclust'>
Package for Time Series Clustering.
</h2><span id='topic+TSclust-package'></span><span id='topic+TSclust'></span>

<h3>Description</h3>

<p>This package contains several measures of dissimilarity between time series, some examples of time series datasets, specific clustering algorithms, and dimension reduction algorithms.
dissimilarities begin with diss.*, and a wrapper function <code>diss</code> is available. Cluster evaluation methods include <code>cluster.evaluation</code> and <code>loo1nn.cv</code>. A clustering algorithm based on pairwise p-values is implemented in <code>pvalues.clust</code>. The package should be used along with other existing clustering packages and function such as <code>hclust</code>, packages <code>cluster</code>, ...
</p>


<h3>Author(s)</h3>

<p>Pablo Montero Manso, José Antonio Vilar. 
</p>


<h3>References</h3>

<p>Montero, P and Vilar, J.A. (2014) <em>TSclust: An R Package for Time Series Clustering.</em>  Journal of Statistical Software, 62(1), 1-43. <a href="http://www.jstatsoft.org/v62/i01/.">http://www.jstatsoft.org/v62/i01/.</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+diss">diss</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#the available dissimilarities can be found in the diss help, page (?diss)
#and their individual pages from there.

### The most common use case begins with a set of time series we want to cluster.
### This package includes several example datasets.
### 
data(interest.rates)
###transformation of the interest rates
trans.inter.rates &lt;- log(interest.rates[2:215,]) - log(interest.rates[1:214,])

##use the dist function of the proxy package to easily create the dist object
#applying ACF with geometric decaying to each pair of time series
tsdist &lt;- diss( t(trans.inter.rates) , "ACF", p=0.05)

names(tsdist) &lt;- colnames(interest.rates)

#perform hierachical clustering to the dist object
hc &lt;- hclust(tsdist)

#show the results
plot(hc)

mahdist &lt;- diss( t(trans.inter.rates) , "AR.MAH", p=0.05)$p_value

pvalues.clust(mahdist, 0.05)




</code></pre>

<hr>
<h2 id='cluster.evaluation'>
Clustering Evaluation Index Based on Known Ground Truth
</h2><span id='topic+cluster.evaluation'></span>

<h3>Description</h3>

<p>Computes the similarity between the true cluster solution and the one obtained with a method under evaluation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cluster.evaluation(G, S)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cluster.evaluation_+3A_g">G</code></td>
<td>

<p>Integer vector with the labels of the true cluster solution. Each element of the vector specifies the cluster 'id' that the element belongs to.
</p>
</td></tr>
<tr><td><code id="cluster.evaluation_+3A_s">S</code></td>
<td>

<p>Integer vector with the labels of the cluster solution to be evaluated. Each element of the vector specifies the cluster 'id' that the element belongs to.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The measure of clustering evaluation is defined as </p>
<p style="text-align: center;"><code class="reqn"> Sim(G,C) = 1/k \sum_{i=1}^k \max_{1\leq j\leq k} Sim(G_i,C_j),  </code>
</p>
<p> where </p>
<p style="text-align: center;"><code class="reqn">Sim(G_i, C_j) = \frac{ 2 | G_i \cap C_j|}{ |G_i| + |C_j|}</code>
</p>

<p>with |.| denoting the cardinality of the elements in the set. This measure has been used for comparing different clusterings, e.g. in Kalpakis et al. (2001) and Pértega and Vilar (2010). 
</p>


<h3>Value</h3>

<p>The computed index.
</p>


<h3>Note</h3>

<p>This index is not simmetric.
</p>


<h3>Author(s)</h3>

<p>Pablo Montero Manso, José Antonio Vilar.
</p>


<h3>References</h3>

<p>Larsen, B. and Aone, C. (1999) Fast and effective text mining using linear-time document clustering. <em>Proc. KDD' 99</em>.16&ndash;22. <br />
</p>
<p>Kalpakis, K., Gada D. and Puttagunta, V. (2001) Distance measures for effective clustering of arima time-series. <em>Proceedings 2001 IEEE International Conference on Data Mining</em>, 273&ndash;280. <br />
</p>
<p>Pértega S. and Vilar, J.A (2010) Comparing several parametric and nonparametric approaches to time series clustering: A simulation study. <em>J. Classification</em>, <b>27(3)</b>, 333-362.
</p>
<p>Montero, P and Vilar, J.A. (2014) <em>TSclust: An R Package for Time Series Clustering.</em>  Journal of Statistical Software, 62(1), 1-43. <a href="http://www.jstatsoft.org/v62/i01/.">http://www.jstatsoft.org/v62/i01/.</a>
</p>


<h3>See Also</h3>

<p><code><a href="fpc.html#topic+cluster.stats">cluster.stats</a></code>,  <code><a href="clValid.html#topic+clValid">clValid</a></code>, <code><a href="clv.html#topic+std.ext">std.ext</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
 #create a true cluster 
 #(first 4 elements belong to cluster '1', next 4 to cluster '2' and the last 4 to cluster '3'.
 true_cluster &lt;- c(1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3)
 #the cluster to be tested
 new_cluster &lt;- c( 2, 1, 2, 3, 3, 2, 2, 1, 3, 3, 3, 3)
 
 #get the index
 cluster.evaluation(true_cluster, new_cluster)
 
 #it can be seen that the index is not simmetric
 cluster.evaluation(new_cluster, true_cluster)
</code></pre>

<hr>
<h2 id='diss'>
TSclust Dissimilarity Computation
</h2><span id='topic+diss'></span>

<h3>Description</h3>

<p>Computes the dissimilarity matrix of the given numeric matrix, list, data.frame or <code>mts</code> object using the selected TSclust dissimilarity method.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>diss(SERIES, METHOD, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="diss_+3A_series">SERIES</code></td>
<td>

<p>Numeric matrix, <code>list</code>, <code>data.frame</code> or <code>mts</code> object. Numeric matrices are interpreted row-wise (one series per row) meanwhile <code>data.frame</code> and <code>mts</code> objects are interpredted column-wise.
</p>
</td></tr>
<tr><td><code id="diss_+3A_method">METHOD</code></td>
<td>

<p>the dissimilarity measure to be used. This must be one of &quot;ACF&quot;, &quot;AR.LPC.CEPS&quot;, &quot;AR.MAH&quot;, &quot;AR.PIC&quot;, &quot;CDM&quot;, &quot;CID&quot;, &quot;COR&quot;, &quot;CORT&quot;, &quot;DTWARP&quot;, &quot;DWT&quot;, &quot;EUCL&quot;, &quot;FRECHET&quot;, INT.PER&quot;,
&quot;NCD&quot;, &quot;PACF&quot;, &quot;PDC&quot;,  PER&quot;, &quot;PRED&quot;, &quot;MINDIST.SAX&quot;, &quot;SPEC.LLR&quot;, &quot;SPEC.GLK&quot; or &quot;SPEC.ISD&quot;. Any unambiguous substring can be given.
See details for individual usage.
</p>
</td></tr>
<tr><td><code id="diss_+3A_...">...</code></td>
<td>

<p>Additional arguments for the selected method.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>SERIES</code> argument can be a numeric matrix, with one row per series, a <code>list</code> object with one numeric vector per element, a <code>data.frame</code> or a <code>mts</code> object.
Some methods can have additional arguments. See the individual help page for each dissimilarity method, detailed below.
Methods that have arguments that require one value per time series in <code>series</code> must provide so using a vector, a matrix (in the case of a multivalued argument) or a list when appropiate. In the case of a matrix, the values are conveyed row-wise. See the AR.LPC.CEPS example below.
</p>

<ul>
<li><p> &quot;ACF&quot; Autocorrelation-based method. See <code><a href="#topic+diss.ACF">diss.ACF</a></code>.
</p>
</li>
<li><p> &quot;AR.LPC.CEPS&quot; Linear Predictive Coding ARIMA method. This method has two value-per-series arguments, the ARIMA order, and the seasonality.See <code><a href="#topic+diss.AR.LPC.CEPS">diss.AR.LPC.CEPS</a></code>.
</p>
</li>
<li><p> &quot;AR.MAH&quot; Model-based ARMA method. See <code><a href="#topic+diss.AR.MAH">diss.AR.MAH</a></code>.
</p>
</li>
<li><p> &quot;AR.PIC&quot; Model-based ARMA method. This method has a value-per-series argument, the ARIMA order. See <code><a href="#topic+diss.AR.PIC">diss.AR.PIC</a></code>.
</p>
</li>
<li><p> &quot;CDM&quot; Compression-based dissimilarity method. See <code><a href="#topic+diss.CDM">diss.CDM</a></code>.
</p>
</li>
<li><p> &quot;CID&quot; Complexity-Invariant distance. See <code><a href="#topic+diss.CID">diss.CID</a></code>.
</p>
</li>
<li><p> &quot;COR&quot; Correlation-based method. See <code><a href="#topic+diss.COR">diss.COR</a></code>.
</p>
</li>
<li><p> &quot;CORT&quot; Temporal Correlation and Raw values method. See <code><a href="#topic+diss.CORT">diss.CORT</a></code>.
</p>
</li>
<li><p> &quot;DTWARP&quot; Dynamic Time Warping method. See <code><a href="#topic+diss.DTWARP">diss.DTWARP</a></code>.
</p>
</li>
<li><p> &quot;DWT&quot; Discrete wavelet transform method. See <code><a href="#topic+diss.DWT">diss.DWT</a></code>.
</p>
</li>
<li><p> &quot;EUCL&quot; Euclidean distance. See <code><a href="#topic+diss.EUCL">diss.EUCL</a></code>. For many more convetional distances, see <code>link[stats]{dist}</code>, though you may need to transpose the dataset.
</p>
</li>
<li><p> &quot;FRECHET&quot; Frechet distance. See <code><a href="#topic+diss.FRECHET">diss.FRECHET</a></code>.
</p>
</li>
<li><p> &quot;INT.PER&quot; Integrate Periodogram-based method. See <code><a href="#topic+diss.INT.PER">diss.INT.PER</a></code>.
</p>
</li>
<li><p> &quot;NCD&quot; Normalized Compression Distance. See <code><a href="#topic+diss.NCD">diss.NCD</a></code>.
</p>
</li>
<li><p> &quot;PACF&quot; Partial Autocorrelation-based method. See <code><a href="#topic+diss.PACF">diss.PACF</a></code>.
</p>
</li>
<li><p> &quot;PDC&quot; Permutation distribution divergence. Uses the <code><a href="pdc.html#topic+pdc">pdc</a></code> package. See <code><a href="pdc.html#topic+pdcDist">pdcDist</a></code> for 
additional arguments and details. Note that series given by numeric matrices are interpreted row-wise and not column-wise, opposite as in <code><a href="pdc.html#topic+pdcDist">pdcDist</a></code>.
</p>
</li>
<li><p> &quot;PER&quot; Periodogram-based method. See <code><a href="#topic+diss.PER">diss.PER</a></code>.
</p>
</li>
<li><p> &quot;PRED&quot; Prediction Density-based method. This method has two value-per-series agument, the logarithm and difference transform. See <code><a href="#topic+diss.PRED">diss.PRED</a></code>.
</p>
</li>
<li><p> &quot;MINDIST.SAX&quot; Distance that lower bounds the Euclidean, based on the Symbolic Aggregate approXimation measure. See <code><a href="#topic+diss.MINDIST.SAX">diss.MINDIST.SAX</a></code>.
</p>
</li>
<li><p> &quot;SPEC.LLR&quot; Spectral Density by Local-Linear Estimation method. See <code><a href="#topic+diss.SPEC.LLR">diss.SPEC.LLR</a></code>.
</p>
</li>
<li><p> &quot;SPEC.GLK&quot; Log-Spectra Generalized Likelihood Ratio test method. See <code><a href="#topic+diss.SPEC.GLK">diss.SPEC.GLK</a></code>.
</p>
</li>
<li><p> &quot;SPEC.ISD&quot; Intregated Squared Differences between Log-Spectras method. See <code><a href="#topic+diss.SPEC.ISD">diss.SPEC.ISD</a></code>.
</p>
</li></ul>



<h3>Value</h3>

<table>
<tr><td><code>dist</code></td>
<td>
<p>A <code>dist</code> object with the pairwise dissimilarities between <code>series</code>.</p>
</td></tr>
</table>
<p>Some methods produce additional output, see their respective documentation pages for more information.
</p>


<h3>Author(s)</h3>

<p>Pablo Montero Manso, José Antonio Vilar. 
</p>


<h3>References</h3>

<p>Montero, P and Vilar, J.A. (2014) <em>TSclust: An R Package for Time Series Clustering.</em>  Journal of Statistical Software, 62(1), 1-43. <a href="http://www.jstatsoft.org/v62/i01/.">http://www.jstatsoft.org/v62/i01/.</a>
</p>


<h3>See Also</h3>

<p><code><a href="pdc.html#topic+pdc">pdc</a></code>, <code><a href="stats.html#topic+dist">dist</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(electricity)
diss(electricity, METHOD="INT.PER", normalize=FALSE)

## Example of multivalued, one per series argument
## The AR.LPC.CEPS dissimilarity allows the specification of the ARIMA model for each series
## Create three sample time series and a mts object
x &lt;- arima.sim(model=list(ar=c(0.4,-0.1)), n =100, n.start=100)
y &lt;- arima.sim(model=list(ar=c(0.9)), n =100, n.start=100)
z &lt;- arima.sim(model=list(ar=c(0.5, 0.2)), n =100, n.start=100)
seriests &lt;- rbind(x,y,z)

## If we want to provide the ARIMA order for each series
## and use it with AR.LPC.CEPS, we create a matrix with the row-wise orders
orderx &lt;- c(2,0,0) 
ordery &lt;- c(1,0,0)
orderz &lt;- c(2,0,0)
orders = rbind(orderx, ordery, orderz)

diss( seriests, METHOD="AR.LPC.CEPS", k=30, order= orders )

##other examples
diss( seriests, METHOD="MINDIST.SAX", w=10, alpha=4 )
diss( seriests, METHOD="PDC" )
</code></pre>

<hr>
<h2 id='diss.ACF'>
Autocorrelation-based Dissimilarity
</h2><span id='topic+diss.ACF'></span><span id='topic+diss.PACF'></span>

<h3>Description</h3>

<p>Computes the dissimilarity between two time series as the distance between their estimated simple (ACF) or partial (PACF) autocorrelation coefficients.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>diss.ACF(x, y, p = NULL, omega=NULL, lag.max=50)
diss.PACF(x, y, p = NULL, omega=NULL, lag.max=50)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="diss.ACF_+3A_x">x</code></td>
<td>

<p>Numeric vector containing the first of the two time series.
</p>
</td></tr>
<tr><td><code id="diss.ACF_+3A_y">y</code></td>
<td>

<p>Numeric vector containing the second of the two time series.
</p>
</td></tr>
<tr><td><code id="diss.ACF_+3A_p">p</code></td>
<td>

<p>If not NULL, sets the weight for the geometric decaying of the autocorrelation coefficients. Ranging  from <code>0</code> to <code>1</code>.
</p>
</td></tr>
<tr><td><code id="diss.ACF_+3A_lag.max">lag.max</code></td>
<td>

<p>Maximum number of simple or partial autocorrelation coefficients to be considered.
</p>
</td></tr>
<tr><td><code id="diss.ACF_+3A_omega">omega</code></td>
<td>

<p>If not NULL, completely specifies the weighting matrix for the autocorrelation coefficients. <code>p</code> is ignored if <code>omega</code> is used.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Performs the weighted Euclidean distance between the simple autocorrelation ( <code>dist.ACF</code>) or partial autocorrelation ( <code>dist.PACF</code> ) coefficients.
If neither <code>p</code> nor <code>omega</code> are specified, uniform weighting is used. If <code>p</code> is specified, geometric wights decaying with the lag in the form <code class="reqn"> p(1-p)^i</code> are applied. If <code>omega</code> (<code class="reqn">\Omega</code>) is specified, </p>
<p style="text-align: center;"><code class="reqn"> d(x,y) = {\{ ( \hat{\rho}_{x} - \hat{\rho}_{y} )^t \bm{\Omega} (\hat{\rho}_{x} - \hat{\rho}_{y} ) \}}^\frac{1}{2} </code>
</p>
<p> with <code class="reqn">\hat{\rho}_{x}</code> and <code class="reqn">\hat{\rho}_{y}</code> the respective (partial) autocorrelation coefficient vectors.
</p>


<h3>Value</h3>

<p>The computed distance.
</p>


<h3>Author(s)</h3>

<p>Pablo Montero Manso, José Antonio Vilar.
</p>


<h3>References</h3>

<p>Galeano, P. and Peña, D. (2000). Multivariate analysis in vector time series. <em>Resenhas</em>, <b>4 (4)</b>, 383&ndash;403.
</p>
<p>Montero, P and Vilar, J.A. (2014) <em>TSclust: An R Package for Time Series Clustering.</em>  Journal of Statistical Software, 62(1), 1-43. <a href="http://www.jstatsoft.org/v62/i01/.">http://www.jstatsoft.org/v62/i01/.</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+diss.COR">diss.COR</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Create three sample time series
x &lt;- cumsum(rnorm(100))
y &lt;- cumsum(rnorm(100))
z &lt;- sin(seq(0, pi, length.out=100))
## Compute the distance and check for coherent results
diss.PACF(x, y)
diss.ACF(x, z)
diss.PACF(y, z)
#create a dist object for its use with clustering functions like pam or hclust
diss( rbind(x,y,z), "ACF", p=0.05)

</code></pre>

<hr>
<h2 id='diss.AR.LPC.CEPS'>
Dissimilarity Based on LPC Cepstral Coefficients
</h2><span id='topic+diss.AR.LPC.CEPS'></span>

<h3>Description</h3>

<p>Computes the dissimilarity between two time series in terms of their Linear Predicitive Coding (LPC) ARIMA processes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>diss.AR.LPC.CEPS(x, y, k = 50, order.x=NULL, order.y=NULL,
 seasonal.x=list(order=c(0, 0, 0), period=NA),
 seasonal.y=list(order=c(0, 0, 0), period=NA),
 permissive=TRUE)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="diss.AR.LPC.CEPS_+3A_x">x</code></td>
<td>

<p>Numeric vector containing the first of the two time series.
</p>
</td></tr>
<tr><td><code id="diss.AR.LPC.CEPS_+3A_y">y</code></td>
<td>

<p>Numeric vector containing the second of the two time series.
</p>
</td></tr>
<tr><td><code id="diss.AR.LPC.CEPS_+3A_k">k</code></td>
<td>

<p>Number of cepstral coefficients to be considered.
</p>
</td></tr>
<tr><td><code id="diss.AR.LPC.CEPS_+3A_order.x">order.x</code></td>
<td>
<p> Numeric matrix. Specifies the ARIMA models to be fitted for the series x. When using <code>diss</code> wrapper, use <code>order</code> argument instead. See details.</p>
</td></tr>
<tr><td><code id="diss.AR.LPC.CEPS_+3A_order.y">order.y</code></td>
<td>
<p> Numeric matrix. Specifies the ARIMA ARIMA models to be fitted for the series y. When using <code>diss</code> wrapper, use <code>order</code> argument instead. See details.</p>
</td></tr>
<tr><td><code id="diss.AR.LPC.CEPS_+3A_seasonal.x">seasonal.x</code></td>
<td>
<p> A list of <code>arima</code> seasonal elements for series x. When using <code>diss</code> wrapper, use <code>seasonal</code> argument instead. See details.</p>
</td></tr>
<tr><td><code id="diss.AR.LPC.CEPS_+3A_seasonal.y">seasonal.y</code></td>
<td>
<p> A list of <code>arima</code> seasonal elements for series x. When using <code>diss</code> wrapper, use <code>seasonal</code> argument instead. See details.</p>
</td></tr>
<tr><td><code id="diss.AR.LPC.CEPS_+3A_permissive">permissive</code></td>
<td>
<p> Specifies whether to force an AR order of 1 if no order is found. Ignored if neither order.x or order.y are NULL</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If <code>order.x</code> or order.y are <code>NULL</code>, their respective series will be fitted automatically using a AR model.
<code>order.x</code> and <code>order.y</code> contain the three components of the ARIMA model: the AR order, the degree of differencing and the MA order, specified as in the function <code><a href="stats.html#topic+arima">arima</a></code>.
</p>
<p><code>seasonal.x</code> and <code>seasonal.y</code> are lists with two components: 'order' and 'period'. See <code>seasonal</code> parameter of <code><a href="stats.html#topic+arima">arima</a></code>, except that specification using a numeric <code>vector</code> of length 3 is not allowed.
</p>
<p>If using <code>diss</code> function with &quot;AR.LPC.CEPS&quot; <code>method</code>, the argument <code>order</code> must be used instead of <code>order.x</code> and <code>order.y</code>. <code>order</code> is a matrix with one row per series, specified as in <code><a href="stats.html#topic+arima">arima</a></code>. If <code>order</code> is <code>NULL</code>, automatic fitting imposing a AR model is performed. The argument <code>seasonal</code> is used instead of <code>seasonal.x</code> and <code>seasonal.y</code>. <code>seasonal</code> is a list of elements, one per series in the same order that the series are input. Each element of <code>seasonal</code> must have the same format as the one in <code><a href="stats.html#topic+arima">arima</a></code>.
</p>


<h3>Value</h3>

<p>The computed distance.
</p>


<h3>Author(s)</h3>

<p>Pablo Montero Manso, José Antonio Vilar. 
</p>


<h3>References</h3>

<p>Kalpakis, K., Gada D. and Puttagunta, V. (2001) Distance measures for effective clustering of arima time-series. <em>Proceedings 2001 IEEE International Conference on Data Mining</em>, 273&ndash;280. <br />
</p>
<p>Montero, P and Vilar, J.A. (2014) <em>TSclust: An R Package for Time Series Clustering.</em>  Journal of Statistical Software, 62(1), 1-43. <a href="http://www.jstatsoft.org/v62/i01/.">http://www.jstatsoft.org/v62/i01/.</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+diss.AR.PIC">diss.AR.PIC</a></code>, <code><a href="#topic+diss.AR.MAH">diss.AR.MAH</a></code>, <code><a href="#topic+diss">diss</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Create three sample time series
x &lt;- arima.sim(model=list(ar=c(0.4,-0.1)), n =100, n.start=100)
y &lt;- arima.sim(model=list(ar=c(0.9)), n =100, n.start=100)
z &lt;- arima.sim(model=list(ar=c(0.5, 0.2)), n =100, n.start=100)
## Compute the distance and check for coherent results
diss.AR.LPC.CEPS(x, y, 25) #impose an AR automatically selected for both series
#impose an ARIMA(2,0,0) for series x and an AR automatically selected for z
diss.AR.LPC.CEPS(x, z, 25, order.x = c(2,0,0), order.y = NULL ) 
diss.AR.LPC.CEPS(y, z, 25)
#create a dist object for its use with clustering functions like pam or hclust

diss( rbind(x,y,z), METHOD="AR.LPC.CEPS", k=20, order=rbind(c(2,0,0), c(1,0,0), c(2,0,0)),
 seasonal=list( list(order=c(1,0,0), period=1), list(order=c(2,0,0), period=3),
  list(order=c(1,0,0), period=1)) )

</code></pre>

<hr>
<h2 id='diss.AR.MAH'>
Model-based Dissimilarity Proposed by Maharaj (1996, 2000)
</h2><span id='topic+diss.AR.MAH'></span>

<h3>Description</h3>

<p>Computes the dissimilarity between two time series by testing whether both series are or not generated by the same ARMA model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>diss.AR.MAH(x, y, dependence=FALSE, permissive=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="diss.AR.MAH_+3A_x">x</code></td>
<td>

<p>Numeric vector containing the first of the two time series.
</p>
</td></tr>
<tr><td><code id="diss.AR.MAH_+3A_y">y</code></td>
<td>

<p>Numeric vector containing the second of the two time series.
</p>
</td></tr>
<tr><td><code id="diss.AR.MAH_+3A_dependence">dependence</code></td>
<td>

<p>Boolean for considering dependence between observations of the series at the same point in time.
</p>
</td></tr>
<tr><td><code id="diss.AR.MAH_+3A_permissive">permissive</code></td>
<td>

<p>Boolean for continuing with the method even if no valid order is selected by AIC.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Assuming that the time series x and y belong to the class of invertible and stationary ARMA processes, this dissimilarity measure is based on checking the equality of their underlying ARMA models by following the testing procedures proposed by Maharaj (1996,2000). The ARMA structures are approximated by truncated AR(<code class="reqn">\infty</code>) models with a common order <code class="reqn">k = \max{(k_x, k_y)}</code>, where <code class="reqn">k_x</code> and <code class="reqn">k_y</code> are determined by the AIC criterion. The AR coefficients are automatically fitted. The dissimilarity can be evaluated by using the value of the test statistic or alternatively the associated p-value. If <code>dependence</code> is <code>FALSE</code>, the dissimilarity measure is constructed by following the procedure introduced by Maharaj (1996), which is designed to compare independent time series. Otherwise, a more general testing procedure is used (Maharaj, 2000), which assumes that both models are correlated at the same time points but uncorrelated across observations (Maharaj, 2000).
When <code>permissive</code> argument is <code>TRUE</code>, if the automatic fitting of the AR order fails, the method shows a warning and then forces an AR of order 1. If <code>permissive</code> is <code>FALSE</code> the method produces an error if no AR order is found by AIC.
</p>


<h3>Value</h3>

<table>
<tr><td><code>statistic</code></td>
<td>
<p>The statistic of the homogeneity test.</p>
</td></tr>
<tr><td><code>p_value</code></td>
<td>
<p>The p-value of the homogeneity test.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Pablo Montero Manso, José Antonio Vilar.
</p>


<h3>References</h3>

<p>Maharaj, E.A. (1996) A significance test for classifying ARMA models. <em>J. Statist. Comput. Simulation</em>, <b>54(4)</b>, 305&ndash;331.<br />
</p>
<p>Maharaj E.A. (2000) Clusters of time series. <em>J. Classification</em>, <b>17(2)</b>, 297&ndash;314.
</p>
<p>Montero, P and Vilar, J.A. (2014) <em>TSclust: An R Package for Time Series Clustering.</em>  Journal of Statistical Software, 62(1), 1-43. <a href="http://www.jstatsoft.org/v62/i01/.">http://www.jstatsoft.org/v62/i01/.</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+diss.AR.PIC">diss.AR.PIC</a></code>,  <code><a href="#topic+diss.AR.LPC.CEPS">diss.AR.LPC.CEPS</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Create three sample time series
x &lt;- arima.sim(model=list(ar=c(0.4,-0.1)), n =100, n.start=100)
y &lt;- arima.sim(model=list(ar=c(0.9)), n =100, n.start=100)
z &lt;- arima.sim(model=list(ar=c(0.5, 0.2)), n =100, n.start=100)
## Compute the distance and check for coherent results
diss.AR.MAH(x, y)
diss.AR.MAH(x, z)
diss.AR.MAH(y, z)

#create a dist object for its use with clustering functions like pam or hclust
diss( rbind(x,y,z), "AR.MAH")$statistic

</code></pre>

<hr>
<h2 id='diss.AR.PIC'>
Model-based Dissimilarity Measure Proposed by Piccolo (1990)
</h2><span id='topic+diss.AR.PIC'></span>

<h3>Description</h3>

<p>Computes the distance between two time series as the Euclidean distance between the truncated AR operators approximating their ARMA structures.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>diss.AR.PIC(x, y, order.x=NULL, order.y=NULL, permissive=TRUE)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="diss.AR.PIC_+3A_x">x</code></td>
<td>

<p>Numeric vector containing the first of the two time series.
</p>
</td></tr>
<tr><td><code id="diss.AR.PIC_+3A_y">y</code></td>
<td>

<p>Numeric vector containing the second of the two time series.
</p>
</td></tr>
<tr><td><code id="diss.AR.PIC_+3A_order.x">order.x</code></td>
<td>
<p> Specifies the ARIMA model to be fitted for the series x. When using <code>diss</code> wrapper, use <code>order</code> argument instead. See details.</p>
</td></tr>
<tr><td><code id="diss.AR.PIC_+3A_order.y">order.y</code></td>
<td>
<p> Specifies the ARIMA model to be fitted for the series y. When using <code>diss</code> wrapper, use <code>order</code> argument instead. See details.</p>
</td></tr>
<tr><td><code id="diss.AR.PIC_+3A_permissive">permissive</code></td>
<td>
<p> Specifies whether to force an AR order of 1 if no order is found. Ignored if neither order.x or order.y are NULL</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If <code>order.x</code> or order.y are <code>NULL</code>, their respective series will be fitted automatically using a AR model. If <code>permissive</code> is <code>TRUE</code> and no AR order is found automatically, an AR order of 1 will be imposed, if this case fails, then no order can be found and the function produces an error.
<code>order.x</code> and <code>order.y</code> contain the three components of the ARIMA model: the AR order, the degree of differencing and the MA order, specified as in the function <code><a href="stats.html#topic+arima">arima</a></code>.
</p>
<p>If using <code>diss</code> function with &quot;AR.PIC&quot; <code>method</code>, the argument <code>order</code> must be used instead of <code>order.x</code> and <code>order.y</code>. <code>orders</code> is a matrix with one row per ARIMA, specified as in <code><a href="stats.html#topic+arima">arima</a></code>. If <code>order</code> is <code>NULL</code>, automatic fitting imposing a AR model is performed.
</p>


<h3>Value</h3>

<p>The computed distance.
</p>


<h3>Author(s)</h3>

<p>Pablo Montero Manso, José Antonio Vilar.
</p>


<h3>References</h3>

<p>Piccolo, D. (1990) A distance measure for classifying arima models. <em>J. Time Series
Anal.</em>, <b>11(2)</b>, 153&ndash;164.
</p>
<p>Montero, P and Vilar, J.A. (2014) <em>TSclust: An R Package for Time Series Clustering.</em>  Journal of Statistical Software, 62(1), 1-43. <a href="http://www.jstatsoft.org/v62/i01/.">http://www.jstatsoft.org/v62/i01/.</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+diss.AR.MAH">diss.AR.MAH</a></code>, <code><a href="#topic+diss.AR.LPC.CEPS">diss.AR.LPC.CEPS</a></code>, <code><a href="#topic+diss">diss</a></code>, <code><a href="stats.html#topic+arima">arima</a></code>, <code><a href="stats.html#topic+ar">ar</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Create three sample time series
x &lt;- arima.sim(model=list(ar=c(0.4,-0.1)), n =100, n.start=100)
y &lt;- arima.sim(model=list(ar=c(0.9)), n =100, n.start=100)
z &lt;- arima.sim(model=list(ar=c(0.5, 0.2)), n =100, n.start=100)
## Compute the distance and check for coherent results
#ARIMA(2,0,0) for x and ARIMA(1,0,0) for y
diss.AR.PIC( x, y, order.x = c(2,0,0), order.y = c(1,0,0) )
diss.AR.PIC( x, z, order.x = c(2,0,0), order.y = c(2,0,0) )
# AR for y (automatically selected) and ARIMA(2,0,0) for z
diss.AR.PIC( y, z, order.x=NULL, order.y=c(2,0,0) ) 
#create a dist object for its use with clustering functions like pam or hclust
diss( rbind(x,y,z), METHOD="AR.PIC", order=rbind(c(2,0,0), c(1,0,0), c(2,0,0)) )

</code></pre>

<hr>
<h2 id='diss.CDM'>
Compression-based Dissimilarity measure
</h2><span id='topic+diss.CDM'></span>

<h3>Description</h3>

<p>Computes the dissimilarity based on the sizes of the compressed time series.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>diss.CDM(x, y, type = "min")

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="diss.CDM_+3A_x">x</code></td>
<td>

<p>Numeric vector containing the first of the two time series.
</p>
</td></tr>
<tr><td><code id="diss.CDM_+3A_y">y</code></td>
<td>

<p>Numeric vector containing the second of the two time series.
</p>
</td></tr>
<tr><td><code id="diss.CDM_+3A_type">type</code></td>
<td>

<p>Character string, the type of compression. May be abbreviated to a single letter, defaults to the first of the alternatives.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The compression based  dissimilarity is calculated: </p>
<p style="text-align: center;"><code class="reqn"> d(x,y) = C(xy) / ( C(x) + C(y) ) </code>
</p>
<p> where <code class="reqn">C(x)</code>, <code class="reqn">C(y)</code> are the sizes in bytes of the compressed series <code class="reqn">x</code> and <code class="reqn">y</code>.
<code class="reqn">C(xy)</code> is the size in bytes of the series <code class="reqn">x</code> and <code class="reqn">y</code> concatenated. The algorithm used for compressing the series is chosen with <code>type</code>.
<code>type</code> can be &quot;gzip&quot;, &quot;bzip2&quot; or &quot;xz&quot;, see <code><a href="base.html#topic+memCompress">memCompress</a></code>. &quot;min&quot; selects the best separately for <code>x</code>, <code>y</code> and the concatenation.
Since the compression methods are character-based, a symbolic representation can be used, see details for an example using SAX as the symbolic representation.
The series are transformed to a text representation prior to compression using <code>as.character</code>, so small numeric differences may produce significantly different text representations. 
While this dissimilarity is asymptotically symmetric, for short series the differences between <code>diss.CDM(x,y)</code> and <code>diss.CDM(y,x)</code> may be noticeable.
</p>


<h3>Value</h3>

<p>The computed dissimilarity.
</p>


<h3>Author(s)</h3>

<p>Pablo Montero Manso, José Antonio Vilar. 
</p>


<h3>References</h3>

<p>Keogh, E., Lonardi, S., &amp; Ratanamahatana, C. A. (2004). Towards parameter-free data mining. Proceedings of the tenth ACM SIGKDD international conference on Knowledge discovery and data mining (pp. 206-215).
</p>
<p>Montero, P and Vilar, J.A. (2014) <em>TSclust: An R Package for Time Series Clustering.</em>  Journal of Statistical Software, 62(1), 1-43. <a href="http://www.jstatsoft.org/v62/i01/.">http://www.jstatsoft.org/v62/i01/.</a>
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+memCompress">memCompress</a></code>, <code><a href="#topic+diss">diss</a></code>, <code><a href="#topic+diss.NCD">diss.NCD</a></code>, <code><a href="#topic+PAA">PAA</a></code>, <code><a href="#topic+convert.to.SAX.symbol">convert.to.SAX.symbol</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n = 50
x &lt;- rnorm(n)  #generate sample series, white noise and a wiener process
y &lt;- cumsum(rnorm(n))

diss.CDM(x, y)

z &lt;- rnorm(n)
w &lt;- cumsum(rnorm(n))
series = rbind(x, y, z, w)
diss(series, "CDM", type="bzip2")

################################################################
#####symbolic representation prior to compression, using SAX####
####simpler symbolization, such as round() could also be used###
################################################################
#normalization function, required for SAX
z.normalize = function(x) {
    (x - mean(x)) / sd(x)
}

sx &lt;- convert.to.SAX.symbol( z.normalize(x), alpha=4 )
sy &lt;- convert.to.SAX.symbol( z.normalize(y), alpha=4 )
sz &lt;- convert.to.SAX.symbol( z.normalize(z), alpha=4 )
sw &lt;- convert.to.SAX.symbol( z.normalize(w), alpha=4 )

diss(rbind(sx, sy, sz, sw), "CDM", type="bzip2")
</code></pre>

<hr>
<h2 id='diss.CID'>
Complexity-Invariant Distance Measure For Time Series
</h2><span id='topic+diss.CID'></span>

<h3>Description</h3>

<p>Computes the distance based on the Euclidean distance corrected by the complexity estimation of the series.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>diss.CID(x, y)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="diss.CID_+3A_x">x</code></td>
<td>

<p>Numeric vector containing the first of the two time series.
</p>
</td></tr>
<tr><td><code id="diss.CID_+3A_y">y</code></td>
<td>

<p>Numeric vector containing the second of the two time series.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This distance is defined </p>
<p style="text-align: center;"><code class="reqn">CID(x,y) = ED(x,y) \times CF(x,y)</code>
</p>
<p> where <code class="reqn">CF(x,y)</code> is a complexity correction factor defined as: </p>
<p style="text-align: center;"><code class="reqn"> max(CE(x), CE(y)) / min(CE(x), CE(y)) </code>
</p>
<p> and <code class="reqn">CE(x)</code> is a compexity estimate of a time series <code class="reqn">x</code>. <code>diss.CID</code> therefore increases the distance between series with different complexities. If the series have the same complexity estimate, the distance defenerates Euclidean distance. The complexity is defined in <code>diss.CID</code> as:
</p>
<p style="text-align: center;"><code class="reqn"> CE(x) = \sqrt{ \sum_{t=1} (x_{t+1} - x_t)^2  } </code>
</p>



<h3>Value</h3>

<p>The computed dissimilarity.
</p>


<h3>Author(s)</h3>

<p>Pablo Montero Manso, José Antonio Vilar. 
</p>


<h3>References</h3>

<p>Batista, G. E., Wang, X., &amp; Keogh, E. J. (2011). A Complexity-Invariant Distance Measure for Time Series. In SDM (Vol. 31, p. 32).
</p>
<p>Montero, P and Vilar, J.A. (2014) <em>TSclust: An R Package for Time Series Clustering.</em>  Journal of Statistical Software, 62(1), 1-43. <a href="http://www.jstatsoft.org/v62/i01/.">http://www.jstatsoft.org/v62/i01/.</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+diss">diss</a></code>, <code><a href="#topic+diss.CORT">diss.CORT</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n = 100
x &lt;- rnorm(n)  #generate sample series, white noise and a wiener process
y &lt;- cumsum(rnorm(n))

diss.CID(x, y)

z &lt;- rnorm(n)
w &lt;- cumsum(rnorm(n))
series = rbind(x, y, z, w)
diss(series, "CID")


</code></pre>

<hr>
<h2 id='diss.COR'>
Correlation-based Dissimilarity
</h2><span id='topic+diss.COR'></span>

<h3>Description</h3>

<p>Computes dissimilarities based on the estimated Pearson's correlation of two given time series.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>diss.COR(x, y, beta = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="diss.COR_+3A_x">x</code></td>
<td>

<p>Numeric vector containing the first of the two time series.
</p>
</td></tr>
<tr><td><code id="diss.COR_+3A_y">y</code></td>
<td>

<p>Numeric vector containing the second of the two time series.
</p>
</td></tr>
<tr><td><code id="diss.COR_+3A_beta">beta</code></td>
<td>

<p>If not NULL, specifies the regulation of the convergence in the second method.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Two different measures of dissimilarity between two time series based on the estimated Pearson's correlation can be computed.
If <code>beta</code> is not specified, the value <code class="reqn"> d_1 = \sqrt{ 2 ( 1 - \rho) } </code> is computed, where <code class="reqn">(\rho)</code> denotes the Pearson's correlation between series <code>x</code> and <code>y</code>.
If <code>beta</code> is specified, the function <code class="reqn"> d_2 = \sqrt{ (\frac{ 1 - \rho}{ 1 + \rho})^\beta } </code> is used, where <code class="reqn">\beta</code> is <code>beta</code> .
</p>


<h3>Value</h3>

<p>The computed distance.
</p>


<h3>Author(s)</h3>

<p>Pablo Montero Manso, José Antonio Vilar.  
</p>


<h3>References</h3>

<p>Golay, X., Kollias, S., Stoll, G., Meier, D., Valavanis, A., and Boesiger, P. (2005) A new correlation-based fuzzy logic clustering algorithm for FMRI. <em>Magnetic Resonance in Medicine</em>, <b>40.2</b>, 249&ndash;260.
</p>
<p>Montero, P and Vilar, J.A. (2014) <em>TSclust: An R Package for Time Series Clustering.</em>  Journal of Statistical Software, 62(1), 1-43. <a href="http://www.jstatsoft.org/v62/i01/.">http://www.jstatsoft.org/v62/i01/.</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+diss.PACF">diss.PACF</a></code>, <code><a href="#topic+diss.ACF">diss.ACF</a></code>, <code><a href="#topic+diss">diss</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Create three sample time series
x &lt;- cumsum(rnorm(100))
y &lt;- cumsum(rnorm(100))
z &lt;- sin(seq(0, pi, length.out=100))
## Compute the distance and check for coherent results
diss.COR(x, y)
diss.COR(x, z)
#create a dist object for its use with clustering functions like pam or hclust

diss( rbind(x,y,z), "COR")

</code></pre>

<hr>
<h2 id='diss.CORT'>
Dissimilarity Index Combining Temporal Correlation and Raw Values Behaviors
</h2><span id='topic+diss.CORT'></span>

<h3>Description</h3>

<p>Computes an adaptive dissimilarity index between two time series that covers both dissimilarity
on raw values and dissimilarity on temporal correlation behaviors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>diss.CORT(x, y, k = 2, deltamethod="Euclid")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="diss.CORT_+3A_x">x</code></td>
<td>

<p>Numeric vector containing the first of the two time series.
</p>
</td></tr>
<tr><td><code id="diss.CORT_+3A_y">y</code></td>
<td>

<p>Numeric vector containing the second of the two time series.
</p>
</td></tr>
<tr><td><code id="diss.CORT_+3A_k">k</code></td>
<td>

<p>Parameter controlling the weight of the dissimilarity between dynamic behaviors (See Details).
</p>
</td></tr>
<tr><td><code id="diss.CORT_+3A_deltamethod">deltamethod</code></td>
<td>

<p>Defines the method for the raw data discrepancy. Either <code>"Euclid"</code>, <code>"Frechet"</code> or <code>"DTW"</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The dissimilarity between  time series <code>x</code>  and <code>y</code> is given by:
</p>
<p style="text-align: center;"><code class="reqn"> d(x,y) = \Phi[CORT(x,y)] \delta(x,y) </code>
</p>

<p>where:
</p>
<p>CORT(x,y) measures the proximity between the dynamic behaviors of x and y by means of the first order temporal correlation coefficient defined by:
</p>
<p style="text-align: center;"><code class="reqn"> CORT(x,y) = \frac{ \sum_{t=1} (x_{t+1} - x_t) ( y_{t+1} - y_t) }{ \sqrt{ \sum_{t=1} (x_{t+1} - x_t)^2}  \sqrt{ \sum_{t=1} (y_{t+1} - y_t)^2  } } </code>
</p>

<p><code class="reqn">\Phi[u]</code> is an adaptive tuning function taking the form:
</p>
<p style="text-align: center;"><code class="reqn">  \frac{2}{1+e^{ku}} </code>
</p>
<p> with <code class="reqn">k \geq 0</code> so that both <code class="reqn">\Phi</code> and <code>k</code> modulate the weight that CORT(x,y) has on d(x,y).
</p>
<p><code class="reqn">\delta(x,y)</code> denotes a dissimilarity measure between the raw values of series <code>x</code> and <code>y</code>, such as the Euclidean distance, the Frechet distance or the Dynamic Time Warping distance. Note that <code class="reqn"> d(x,y) = \delta(x,y)</code> if <code>k=0</code>.
</p>
<p>More details of the procedure can be seen in Chouakria-Douzal and Nagabhushan (2007).
</p>
<p><code>deltamethod</code> (<code class="reqn">\delta</code>) can be either Euclidean (<code>deltamethod = "Euclid"</code>), Frechet (<code> deltamethod = "Frechet"</code>) or Dynamic Time Warping (<code>deltamethod ="DTW"</code>) distances. When calling from <code>dis.CORT</code>, DTW uses Manhattan as local distance.
</p>


<h3>Value</h3>

<p>The computed distance.
</p>


<h3>Author(s)</h3>

<p>Pablo Montero Manso, José Antonio Vilar. 
</p>


<h3>References</h3>

<p>Chouakria-Douzal, A. and Nagabhushan P. N. (2007) Adaptive dissimilarity index for measuring time series proximity. <em>Adv. Data Anal. Classif.</em>, <b>1(1)</b>, 5&ndash;21.
</p>
<p>Montero, P and Vilar, J.A. (2014) <em>TSclust: An R Package for Time Series Clustering.</em>  Journal of Statistical Software, 62(1), 1-43. <a href="http://www.jstatsoft.org/v62/i01/.">http://www.jstatsoft.org/v62/i01/.</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+diss.COR">diss.COR</a></code>, <code><a href="#topic+diss.DTWARP">diss.DTWARP</a></code>, <code><a href="#topic+diss.FRECHET">diss.FRECHET</a></code>, <code><a href="longitudinalData.html#topic+distFrechet">distFrechet</a></code>, <code><a href="dtw.html#topic+dtw">dtw</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Create three sample time series
x &lt;- cumsum(rnorm(100))
y &lt;- cumsum(rnorm(100))
z &lt;- sin(seq(0, pi, length.out=100))
## Compute the distance and check for coherent results
diss.CORT(x, y, 2)
diss.CORT(x, z, 2)
diss.CORT(y, z, 2)
#create a dist object for its use with clustering functions like pam or hclust

diss( rbind(x,y,z), "CORT", k=3, deltamethod="DTW")

</code></pre>

<hr>
<h2 id='diss.DTWARP'>
Dynamic Time Warping Distance
</h2><span id='topic+diss.DTWARP'></span>

<h3>Description</h3>

<p>Computes Dynamic Time Warping distance between time series.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>diss.DTWARP(x, y, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="diss.DTWARP_+3A_x">x</code></td>
<td>

<p>Numeric vector containing the first of the two time series.
</p>
</td></tr>
<tr><td><code id="diss.DTWARP_+3A_y">y</code></td>
<td>

<p>Numeric vector containing the second of the two time series.
</p>
</td></tr>
<tr><td><code id="diss.DTWARP_+3A_...">...</code></td>
<td>

<p>Additional parameters for the function. See <code>link[dtw]{dtw}</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is basically a wrapper for <code>dtw</code> of the <code><a href="pdc.html#topic+pdc">pdc</a></code> package, intended for an easier discovery of the functionalities used in TSclust.
</p>


<h3>Value</h3>

<p>The computed distance.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+diss">diss</a></code>, <code>link[dtw]{dtw}</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Create three sample time series
x &lt;- cumsum(rnorm(100))
y &lt;- cumsum(rnorm(100))
diss.DTWARP(x, y)

</code></pre>

<hr>
<h2 id='diss.DWT'>
Dissimilarity for Time Series Based on Wavelet Feature Extraction
</h2><span id='topic+diss.DWT'></span>

<h3>Description</h3>

<p>Performs an unsupervised feature extration using orthogonal wavelets on the series and returns the Euclidean distance between the wavelet approximations in an appropriate scale.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>diss.DWT(series)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="diss.DWT_+3A_series">series</code></td>
<td>

<p>Numeric matrix with row order time series
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This method differs from other dissimilarities in that pairwise dissimilaries depend on the whole dataset that is given to <code>diss.DWT</code>, hence, there is no pairwise version of the function defined, only accepts whole datasets.
The set of original series is replaced by their wavelet approximation coefficients in an appropriate scale, and the dissimilarity between two series is computed as the Euclidean distance between these coefficients.  The appropriate scale is automatically determined by using an algorithm addressed to obtain an efficient reduction of the dimensionality but preserving as much information from the original data as possible. The algorithm is introduced by Zhang, Ho, Zhang, and Lin (2006).
</p>


<h3>Value</h3>

<p>Returns an object of type <code>dist</code> with the pairwise distances.
</p>


<h3>Author(s)</h3>

<p>Pablo Montero Manso, José Antonio Vilar.
</p>


<h3>References</h3>

<p>Zhang, H., Ho, T. B., Zhang, Y., and Lin, M. (2006) Unsupervised feature extraction for time series clustering using orthogonal wavelet transform. <em>INFORMATICA-LJUBLJANA-</em>, <b>30(3)</b>, 305.
</p>
<p>Montero, P and Vilar, J.A. (2014) <em>TSclust: An R Package for Time Series Clustering.</em>  Journal of Statistical Software, 62(1), 1-43. <a href="http://www.jstatsoft.org/v62/i01/.">http://www.jstatsoft.org/v62/i01/.</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Create three sample time series
x &lt;- cumsum(rnorm(100))
y &lt;- cumsum(rnorm(100))
z &lt;- sin(seq(0, pi, length.out=100))

#compute the distance
diss.DWT(rbind(x, y, z))
</code></pre>

<hr>
<h2 id='diss.EUCL'>
Euclidean Distance
</h2><span id='topic+diss.EUCL'></span>

<h3>Description</h3>

<p>Computes Euclidean distance between time series.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>diss.EUCL(x, y)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="diss.EUCL_+3A_x">x</code></td>
<td>

<p>Numeric vector containing the first of the two time series.
</p>
</td></tr>
<tr><td><code id="diss.EUCL_+3A_y">y</code></td>
<td>

<p>Numeric vector containing the second of the two time series.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The computed distance.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+diss">diss</a></code>, <code><a href="stats.html#topic+dist">dist</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Create three sample time series
x &lt;- cumsum(rnorm(100))
y &lt;- cumsum(rnorm(100))
diss.EUCL(x, y)
</code></pre>

<hr>
<h2 id='diss.FRECHET'>
Frechet Distance
</h2><span id='topic+diss.FRECHET'></span>

<h3>Description</h3>

<p>Computes the Frechet distance between time series.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>diss.FRECHET(x, y, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="diss.FRECHET_+3A_x">x</code></td>
<td>

<p>Numeric vector containing the first of the two time series.
</p>
</td></tr>
<tr><td><code id="diss.FRECHET_+3A_y">y</code></td>
<td>

<p>Numeric vector containing the second of the two time series.
</p>
</td></tr>
<tr><td><code id="diss.FRECHET_+3A_...">...</code></td>
<td>

<p>Additional parameters for the function. See <code>link[longitudinalData]{distFrechet}</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is basically a wrapper for <code>distFrechet</code> of the <code><a href="longitudinalData.html#topic+longitudinalData">longitudinalData</a></code> package, intended for an easier discovery of the functionalities used in TSclust.
</p>


<h3>Value</h3>

<p>The computed distance.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+diss">diss</a></code>, <code>link[longitudinalData]{distFrechet}</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Create three sample time series
x &lt;- cumsum(rnorm(100))
y &lt;- cumsum(rnorm(100))
diss.FRECHET(x, y)

</code></pre>

<hr>
<h2 id='diss.INT.PER'>
Integrated Periodogram Based Dissimilarity
</h2><span id='topic+diss.INT.PER'></span>

<h3>Description</h3>

<p>Computes the dissimilarity between two time series in terms of the distance between their integrated periodograms.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>diss.INT.PER(x, y, normalize=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="diss.INT.PER_+3A_x">x</code></td>
<td>

<p>Numeric vector containing the first of the two time series.
</p>
</td></tr>
<tr><td><code id="diss.INT.PER_+3A_y">y</code></td>
<td>

<p>Numeric vector containing the second of the two time series.
</p>
</td></tr>
<tr><td><code id="diss.INT.PER_+3A_normalize">normalize</code></td>
<td>

<p>If <code>TRUE</code> the normalized version is computed.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The distance is computed as:
</p>
<p style="text-align: center;"><code class="reqn"> d(x,y) = \int_{-\pi}^{\pi} | F_x(\lambda) - F_y(\lambda) | \, d\lambda, </code>
</p>

<p>where <code class="reqn"> F_x(\lambda_j) = C_x^{-1} \sum_{i=1}^{j} I_x(\lambda_i)</code> and <code class="reqn">F_y(\lambda_j) = C_y^{-1} \sum_{i=1}^{j} I_y(\lambda_i)</code>, with <code class="reqn">C_x = \sum_i I_x(\lambda_i)</code>  and <code class="reqn">C_y = \sum_i I_y(\lambda_i)</code> in the normalized version. <code class="reqn">C_x = 1</code>  and <code class="reqn">C_y = 1</code> in the non-normalized version. <code class="reqn">I_x(\lambda_k)</code> and <code class="reqn">I_y(\lambda_k)</code> denote the periodograms of <code>x</code> and <code>y</code>, respectively.
</p>


<h3>Value</h3>

<p>The computed distance.
</p>


<h3>Author(s)</h3>

<p>Pablo Montero Manso, José Antonio Vilar. 
</p>


<h3>References</h3>

<p>Casado de Lucas, D. (2010) Classification techniques for time series and functional data.
</p>
<p>Montero, P and Vilar, J.A. (2014) <em>TSclust: An R Package for Time Series Clustering.</em>  Journal of Statistical Software, 62(1), 1-43. <a href="http://www.jstatsoft.org/v62/i01/.">http://www.jstatsoft.org/v62/i01/.</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+diss.PER">diss.PER</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Create three sample time series
x &lt;- cumsum(rnorm(100))
y &lt;- cumsum(rnorm(100))
z &lt;- sin(seq(0, pi, length.out=100))
## Compute the distance and check for coherent results
diss.INT.PER(x, y, normalize=TRUE)
diss.INT.PER(x, y, normalize=TRUE)
diss.INT.PER(x, y, normalize=TRUE)

diss( rbind(x,y,z), "INT.PER", normalize=FALSE )

</code></pre>

<hr>
<h2 id='diss.MINDIST.SAX'>
Symbolic Aggregate Aproximation related functions
</h2><span id='topic+diss.MINDIST.SAX'></span><span id='topic+diss.SAX'></span><span id='topic+PAA'></span><span id='topic+convert.to.SAX.symbol'></span><span id='topic+MINDIST.SAX'></span><span id='topic+SAX.plot'></span>

<h3>Description</h3>

<p><code>diss.MINDIST.SAX</code> computes a dissimilarity that lower bounds the Euclidean on the discretized, dimensionality reduced series. Function <code>PAA</code> produces the dimension reduction. Function <code>convert.to.SAX.symbol</code> produces the discretization.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>diss.MINDIST.SAX(x, y, w, alpha=4, plot=FALSE)
PAA(x, w)
convert.to.SAX.symbol(x, alpha)
MINDIST.SAX(x, y, alpha, n)
SAX.plot(series, w, alpha, col.ser=rainbow(ncol(as.matrix(series))))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="diss.MINDIST.SAX_+3A_x">x</code></td>
<td>

<p>Numeric vector containing the first of the two time series.
</p>
</td></tr>
<tr><td><code id="diss.MINDIST.SAX_+3A_y">y</code></td>
<td>

<p>Numeric vector containing the second of the two time series.
</p>
</td></tr>
<tr><td><code id="diss.MINDIST.SAX_+3A_w">w</code></td>
<td>

<p>The amount of equal sized frames that the series will be reduced to.
</p>
</td></tr>
<tr><td><code id="diss.MINDIST.SAX_+3A_alpha">alpha</code></td>
<td>

<p>The size of the alphabet, the amount of symbols used to represents the values of the series.
</p>
</td></tr>
<tr><td><code id="diss.MINDIST.SAX_+3A_plot">plot</code></td>
<td>

<p>If <code>TRUE</code>, plot a graphic of the reduced series, with their corresponding symbols.
</p>
</td></tr>
<tr><td><code id="diss.MINDIST.SAX_+3A_n">n</code></td>
<td>

<p>The original size of the series.
</p>
</td></tr>
<tr><td><code id="diss.MINDIST.SAX_+3A_series">series</code></td>
<td>

<p>A <code>ts</code> or <code>mts</code> object with the series to plot.
</p>
</td></tr>
<tr><td><code id="diss.MINDIST.SAX_+3A_col.ser">col.ser</code></td>
<td>

<p>Colors for the series. One per series.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>SAX is a symbolic representation of continuous time series.
</p>
<p><code>w</code> must be an integer but it does not need to divide the length of the series. If <code>w</code> divides the length of the series, the <code>diss.MINDIST.SAX</code> plot uses this to show the size of the frames.
</p>
<p><code>PAA</code> performs the Piecewise Aggregate Approximation of the series, reducing it to <code>w</code> elements, called frames. Each frame is composed by <code class="reqn">n/w</code> observations of the original series, averaged. Observations are weighted when <code>w</code> does not divide <code>n</code>.
</p>
<p><code>convert.to.SAX.symbol</code> performs SAX discretization: Discretizes the series <code>x</code> to an alphabet of size <code>alpha</code>, <code>x</code> should be z-normalized in this case. The <code class="reqn">N(0,1)</code> distribution is divided in <code>alpha</code> equal probability parts, if an observation falls into the <code class="reqn">i</code>th part (starting from minus infinity), it is assigned the <code class="reqn">i</code> symbol.
</p>
<p><code>MINDIST.SAX</code> calculates the MINDIST dissimilarity between symbolic representations.
</p>
<p><code>diss.MINDIST.SAX</code> combines the previous procedures to compute a dissimilarity between series. The series are z-normalized at first. Then the dimensionality is reduced uusin <code>PAA</code> to produce series of length <code>w</code>. The series are discretized to an alphabet of size <code>alpha</code> using <code>convert.to.SAX.symbol</code>. Finally the dissimilarity value is produced using <code>MINDIST.SAX</code>.
</p>
<p><code>SAX.plot</code> produces a plot of the SAX representation of the given <code>series</code>.
</p>


<h3>Value</h3>

<p>The computed dissimilarity.
</p>


<h3>Author(s)</h3>

<p>Pablo Montero Manso, José Antonio Vilar. 
</p>


<h3>References</h3>

<p>Lin, J., Keogh, E., Lonardi, S. &amp; Chiu, B. (2003) A Symbolic Representation of Time Series, with Implications for Streaming Algorithms. In Proceedings of the 8th ACM SIGMOD Workshop on Research Issues in Data Mining and Knowledge Discovery.
</p>
<p>Keogh, E., Chakrabarti, K., Pazzani, M., &amp; Mehrotra, S. (2001). Dimensionality reduction for fast similarity search in large time series databases. <em>Knowledge and information Systems</em>, <b>3(3)</b>, 263-286.
</p>
<p>Montero, P and Vilar, J.A. (2014) <em>TSclust: An R Package for Time Series Clustering.</em>  Journal of Statistical Software, 62(1), 1-43. <a href="http://www.jstatsoft.org/v62/i01/.">http://www.jstatsoft.org/v62/i01/.</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+diss">diss</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(12349)
n = 100
x &lt;- rnorm(n)  #generate sample series, white noise and a wiener process
y &lt;- cumsum(rnorm(n))
w &lt;- 20 #amount of equal-sized frames to divide the series, parameters for PAA
alpha &lt;- 4 #size of the alphabet, parameter for SAX

#normalize
x &lt;- (x - mean(x)) /sd(x)
y &lt;- (y - mean(y)) /sd(y)

paax &lt;- PAA(x, w) #generate PAA reductions
paay &lt;- PAA(y, w)

plot(x, type="l", main="PAA reduction of series x") #plot an example of PAA reduction
p &lt;- rep(paax,each=length(x)/length(paax)) #just for plotting the PAA
lines(p, col="red")

#repeat the example with y
plot(y, type="l", main="PAA reduction of series y") 
py &lt;- rep(paay,each=length(y)/length(paay))
lines(py, col="blue")

#convert to SAX representation
SAXx &lt;- convert.to.SAX.symbol( paax, alpha)
SAXy &lt;- convert.to.SAX.symbol( paay, alpha)

#CALC THE SAX DISTANCE
MINDIST.SAX(SAXx, SAXy, alpha, n)

#this whole process can be computed using diss.MINDIST.SAX
diss.MINDIST.SAX(x, y, w, alpha, plot=TRUE)

z &lt;- rnorm(n)^2

diss(rbind(x,y,z), "MINDIST.SAX", w, alpha)

SAX.plot( as.ts(cbind(x,y,z)), w=w, alpha=alpha)

</code></pre>

<hr>
<h2 id='diss.NCD'>
Normalized Compression Distance
</h2><span id='topic+diss.NCD'></span>

<h3>Description</h3>

<p>Computes the distance based on the sizes of the compressed time series.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>diss.NCD(x, y, type = "min")

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="diss.NCD_+3A_x">x</code></td>
<td>

<p>Numeric vector containing the first of the two time series.
</p>
</td></tr>
<tr><td><code id="diss.NCD_+3A_y">y</code></td>
<td>

<p>Numeric vector containing the second of the two time series.
</p>
</td></tr>
<tr><td><code id="diss.NCD_+3A_type">type</code></td>
<td>

<p>Character string, the type of compression.  May be abbreviated to a single letter, defaults to the first of the alternatives.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The compression based  dissimilarity is calculated: </p>
<p style="text-align: center;"><code class="reqn"> d(x,y) = C(xy) - max(C(x),C(y))/ min(C(x),C(y)) </code>
</p>
<p> where <code class="reqn">C(x)</code>, <code class="reqn">C(y)</code> are the sizes in bytes of the compressed series <code class="reqn">x</code> and <code class="reqn">y</code>.
<code class="reqn">C(xy)</code> is the size in bytes of the series <code class="reqn">x</code> and <code class="reqn">y</code> concatenated. The algorithm used for compressing the series is chosen with <code>type</code>.
<code>type</code> can be &quot;gzip&quot;, &quot;bzip2&quot; or &quot;xz&quot;, see <code><a href="base.html#topic+memCompress">memCompress</a></code>. &quot;min&quot; selects the best separately for <code>x</code>, <code>y</code> and the concatenation.
Since the compression methods are character-based, a symbolic representation can be used, see details for an example using SAX as the symbolic representation.
The series are transformed to a text representation prior to compression using <code>as.character</code>, so small numeric differences may produce significantly different text representations.
While this dissimilarity is asymptotically symmetric, for short series the differences between <code>diss.NCD(x,y)</code> and <code>diss.NCD(y,x)</code> may be noticeable.
</p>


<h3>Value</h3>

<p>The computed distance.
</p>


<h3>Author(s)</h3>

<p>Pablo Montero Manso, José Antonio Vilar. 
</p>


<h3>References</h3>

<p>Cilibrasi, R., &amp; Vitányi, P. M. (2005). Clustering by compression. <em>Information Theory, IEEE Transactions on</em>, <b>51(4)</b>, 1523-1545.
</p>
<p>Keogh, E., Lonardi, S., &amp; Ratanamahatana, C. A. (2004). Towards parameter-free data mining. Proceedings of the tenth ACM SIGKDD international conference on Knowledge discovery and data mining (pp. 206-215).
</p>
<p>Montero, P and Vilar, J.A. (2014) <em>TSclust: An R Package for Time Series Clustering.</em>  Journal of Statistical Software, 62(1), 1-43. <a href="http://www.jstatsoft.org/v62/i01/.">http://www.jstatsoft.org/v62/i01/.</a>
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+memCompress">memCompress</a></code>, <code><a href="#topic+diss">diss</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n = 50
x &lt;- rnorm(n)  #generate sample series, white noise and a wiener process
y &lt;- cumsum(rnorm(n))

diss.NCD(x, y)

z &lt;- rnorm(n)
w &lt;- cumsum(rnorm(n))
series = rbind(x, y, z, w)
diss(series, "NCD", type="bzip2")

################################################################
#####symbolic representation prior to compression, using SAX####
####simpler symbolization, such as round() could also be used###
################################################################
#normalization function, required for SAX
z.normalize = function(x) {
    (x - mean(x)) / sd(x)
}

sx &lt;- convert.to.SAX.symbol( z.normalize(x), alpha=4 )
sy &lt;- convert.to.SAX.symbol( z.normalize(y), alpha=4 )
sz &lt;- convert.to.SAX.symbol( z.normalize(z), alpha=4 )
sw &lt;- convert.to.SAX.symbol( z.normalize(w), alpha=4 )

diss(rbind(sx, sy, sz, sw), "NCD", type="bzip2")

</code></pre>

<hr>
<h2 id='diss.PDC'>
Permutation Distribution Distance
</h2><span id='topic+diss.PDC'></span>

<h3>Description</h3>

<p>Computes the Permutation Distribution distance between time series.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>diss.PDC(x, y, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="diss.PDC_+3A_x">x</code></td>
<td>

<p>Numeric vector containing the first of the two time series.
</p>
</td></tr>
<tr><td><code id="diss.PDC_+3A_y">y</code></td>
<td>

<p>Numeric vector containing the second of the two time series.
</p>
</td></tr>
<tr><td><code id="diss.PDC_+3A_...">...</code></td>
<td>

<p>Additional parameters for the function. See <code>link[pdc]{pdcDist}</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is basically a wrapper for <code>pdcDist</code> of the <code><a href="pdc.html#topic+pdc">pdc</a></code> package, intended for an easier discovery of the functionalities used in TSclust.
</p>


<h3>Value</h3>

<p>The computed distance.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+diss">diss</a></code>, <code>link[pdc]{pdcDist}</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Create three sample time series
x &lt;- cumsum(rnorm(100))
y &lt;- cumsum(rnorm(100))
diss.PDC(x, y)

</code></pre>

<hr>
<h2 id='diss.PER'>
Periodogram Based Dissimilarity
</h2><span id='topic+diss.PER'></span>

<h3>Description</h3>

<p>Computes the distance between two time series based on their periodograms.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>diss.PER(x, y, logarithm=FALSE, normalize=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="diss.PER_+3A_x">x</code></td>
<td>

<p>Numeric vector containing the first of the two time series.
</p>
</td></tr>
<tr><td><code id="diss.PER_+3A_y">y</code></td>
<td>

<p>Numeric vector containing the second of the two time series.
</p>
</td></tr>
<tr><td><code id="diss.PER_+3A_logarithm">logarithm</code></td>
<td>

<p>Boolean. If <code>TRUE</code> logarithm of the periodogram coefficients will be taken.
</p>
</td></tr>
<tr><td><code id="diss.PER_+3A_normalize">normalize</code></td>
<td>

<p>Boolean. If <code>TRUE</code>, the periodograms will be normalized by the variance of their respective series.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Computes the Euclidean distance between the periodogram coefficients of the series <code>x</code> and <code>y</code>. Additional transformations can be performed on the coefficients depending on the values of <code>logarithm</code> and <code>normalize</code>.
</p>


<h3>Value</h3>

<p>The computed distance.
</p>


<h3>Author(s)</h3>

<p>Pablo Montero Manso, José Antonio Vilar.
</p>


<h3>References</h3>

<p>Caiado, J., Crato, N. and Peña, D. (2006) A periodogram-based metric for time series classification. <em>Comput. Statist. Data Anal.</em>, <b>50(10)</b>, 2668&ndash;2684.
</p>
<p>Montero, P and Vilar, J.A. (2014) <em>TSclust: An R Package for Time Series Clustering.</em>  Journal of Statistical Software, 62(1), 1-43. <a href="http://www.jstatsoft.org/v62/i01/.">http://www.jstatsoft.org/v62/i01/.</a>
</p>


<h3>See Also</h3>

<p><code>link{diss.INT.PER}</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Create three sample time series
x &lt;- cumsum(rnorm(100))
y &lt;- cumsum(rnorm(100))
z &lt;- sin(seq(0, pi, length.out=100))
## Compute the distance and check for coherent results
diss.PER(x, y)
diss.PER(x, z)
diss.PER(y, z)
diss.PER(x, y, TRUE, TRUE)
diss.PER(x, z, TRUE, TRUE)
diss.PER(y, z, TRUE, TRUE)
#create a dist object for its use with clustering functions like pam or hclust
diss( rbind(x,y,z), "PER", logarithm=TRUE, normalize=TRUE)
</code></pre>

<hr>
<h2 id='diss.PRED'>
Dissimilarity Measure Based on Nonparametric Forecast
</h2><span id='topic+diss.PRED'></span>

<h3>Description</h3>

<p>Computes the dissimilarity between two time series as the L1 distance between the kernel estimators of their forecast densities at a pre-specified horizon.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>diss.PRED(x, y, h, B=500, logarithm.x=FALSE, logarithm.y=FALSE,
differences.x=0, differences.y=0, plot=FALSE, models = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="diss.PRED_+3A_x">x</code></td>
<td>

<p>Numeric vector containing the first of the two time series.
</p>
</td></tr>
<tr><td><code id="diss.PRED_+3A_y">y</code></td>
<td>

<p>Numeric vector containing the second of the two time series.
</p>
</td></tr>
<tr><td><code id="diss.PRED_+3A_h">h</code></td>
<td>

<p>The horizon of interest, i.e the number of steps-ahead where the prediction is evaluated. 
</p>
</td></tr>
<tr><td><code id="diss.PRED_+3A_b">B</code></td>
<td>

<p>The amount of bootstrap resamples. 
</p>
</td></tr>
<tr><td><code id="diss.PRED_+3A_logarithm.x">logarithm.x</code></td>
<td>

<p>Boolean. Specifies whether to transform series x by taking logarithms or not. When using <code>diss</code> wrapper, use <code>logarithms</code> argument instead. See details.
</p>
</td></tr>
<tr><td><code id="diss.PRED_+3A_logarithm.y">logarithm.y</code></td>
<td>

<p>Boolean. Specifies whether to transform series y by taking logarithms or not.  When using <code>diss</code> wrapper, use <code>logarithms</code> argument instead. See details.
</p>
</td></tr>
<tr><td><code id="diss.PRED_+3A_differences.x">differences.x</code></td>
<td>

<p>Specifies the amount of differences to apply to series x.  When using <code>diss</code> wrapper, use <code>differences</code> argument instead. See details.
</p>
</td></tr>
<tr><td><code id="diss.PRED_+3A_differences.y">differences.y</code></td>
<td>

<p>Specifies the amount of differences to apply to series y.  When using <code>diss</code> wrapper, use <code>differences</code> argument instead. See details.
</p>
</td></tr>
<tr><td><code id="diss.PRED_+3A_plot">plot</code></td>
<td>

<p>If <code>TRUE</code>, plot the resulting forecast densities.
</p>
</td></tr>
<tr><td><code id="diss.PRED_+3A_models">models</code></td>
<td>

<p>A list containing either <code>"ets"</code>, <code>"arima"</code> or a fitted model object from the <code>forecast</code> package. The list must have one element per series. In the case of the <code>x</code> and <code>y</code> version, a list with two elements. If models is not null <code>logarithm</code> and <code>differences</code> parameters are ignored.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The dissimilarity between the time series <code>x</code> and <code>y</code>  is given by </p>
<p style="text-align: center;"><code class="reqn"> d(x,y) = \int{ | f_{x,h}(u) - f_{y,h}(u) | du} </code>
</p>
<p> where <code class="reqn">f_{x,h}</code> and <code class="reqn">f_{y,h}</code> are kernel density estimators of the forecast densities h-steps ahead of <code>x</code> and <code>y</code>, respectively. The horizon of interest h is pre-specified by the user.
If <code>models</code> is specified, the given model for each series is used for obtaining 
the forecast densities. Currently, each element of the <code>models</code> list can be the string <code>"ets"</code>, which will fit a ets model using the function <code>ets</code> in the <code>forecast</code> package. If the element of <code>models</code> is the string &quot;arima&quot;, an ARIMA model using <code>auto.arima</code> from the forecast package will be used. Finally, the elements of models can be a fitted model on the series using a method from the <code>forecast</code> package which can be simulated, see <code>link[forecast]{simulate.ets}</code>.
The kernel density estimators are based on B bootstrap replicates obtained by using a resampling procedure that mimics the generating processes, which are assumed to follow an arbitrary autoregressive structure (parametric or non-parametric). The procedure is completely detailed in Vilar et al. (2010). This function has high computational cost due to the bootstrapping procedure. 
</p>
<p>The procedure uses a bootstrap method that requires stationary time series. In order to support a wider range of time series, the method allows some transformations on the series before proceeding with the bootstrap resampling. This transformations are inverted before calculating the densities. The transformations allowed are logarithm and differenciation.
The parameters <code>logarithm.x</code>, <code>logarithm.y</code>, <code>differences.x</code>, <code>differences.y</code> can be specified with this purpose.
</p>
<p>If using <code>diss</code> function with &quot;PRED&quot; <code>method</code>, the argument <code>logarithms</code> must be used instead of <code>logarithm.x</code> and <code>logarithm.y</code>. <code>logarithms</code> is a boolean vector specifying if the logarithm transform should be taken for each one of the <code>series</code>. The argument <code>differences</code>, a numeric vector specifying the amount of differences to apply the <code>series</code>, is used instead of <code>differences.x</code> and <code>differences.y</code>. The plot is also different, showing all the densities in the same plot.
</p>


<h3>Value</h3>

<p><code>diss.PRED</code> returns a list with the following components.
</p>
<table>
<tr><td><code>L1dist</code></td>
<td>
<p> The computed distance.</p>
</td></tr>
<tr><td><code>dens.x</code></td>
<td>
<p> A 2-column matrix with the density of predicion of series <code>x</code>. First column is the base (x) and the second column is the value (y) of the density.</p>
</td></tr>
<tr><td><code>dens.y</code></td>
<td>
<p> A 2-column matrix with the density of predicion of series <code>y</code>. First column is the base (x) and the second column is the value (y) of the density.</p>
</td></tr>
</table>
<p>When used from the <code>diss</code> wrapper function, it returns a list with the following components.
</p>
<table>
<tr><td><code>dist</code></td>
<td>
<p>A <code>dist</code> object with the pairwise L1 distances between series.</p>
</td></tr>
<tr><td><code>densities</code></td>
<td>
<p> A list of 2-column matrices containing the densities of each series, in the same format as 'dens.x' or 'dens.y' of <code>diss.PRED</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>José Antonio Vilar, Pablo Montero Manso. 
</p>


<h3>References</h3>

<p>Alonso, A.M., Berrendero, J.R., Hernandez, A. and Justel, A. (2006) Time series clustering based on forecast densities. <em>Comput. Statist. Data Anal.</em>, <b>51</b>,762&ndash;776.<br />
</p>
<p>Vilar, J.A.,  Alonso, A. M. and Vilar, J.M. (2010) Non-linear time series clustering based on non-parametric forecast densities. <em>Comput. Statist. Data Anal.</em>, <b>54 (11)</b>, 2850&ndash;2865.
</p>
<p>Montero, P and Vilar, J.A. (2014) <em>TSclust: An R Package for Time Series Clustering.</em>  Journal of Statistical Software, 62(1), 1-43. <a href="http://www.jstatsoft.org/v62/i01/.">http://www.jstatsoft.org/v62/i01/.</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+diss">diss</a></code>, <code>link[forecast]{auto.arima}</code>, <code>link[forecast]{ets}</code>, <code>link[forecast]{simulate.ets}</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- (rnorm(100))
x &lt;- x + abs(min(x)) + 1 #shift to produce values greater than 0, for a correct logarithm transform
y &lt;- (rnorm(100))
z &lt;- sin(seq(0, pi, length.out=100))
## Compute the distance and check for coherent results
diss.PRED(x, y, h=6, logarithm.x=FALSE, logarithm.y=FALSE, differences.x=1, differences.y=0)
#create a dist object for its use with clustering functions like pam or hclust
diss( rbind(x,y,z), METHOD="PRED", h=3, B=200,
 logarithms=c(TRUE,FALSE, FALSE), differences=c(1,1,2) )
#test the forecast package predictions
diss.PRED(x,y, h=5, models = list("ets", "arima"))

</code></pre>

<hr>
<h2 id='diss.SPEC.GLK'>
Dissimilarity based on the Generalized Likelihood Ratio Test
</h2><span id='topic+diss.SPEC.GLK'></span>

<h3>Description</h3>

<p>The dissimilarity between two time series is computed by using an adaptation of the generalized likelihood ratio test to check the equality of two log-spectra.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>diss.SPEC.GLK(x, y, plot=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="diss.SPEC.GLK_+3A_x">x</code></td>
<td>

<p>Numeric vector containing the first of the two time series.
</p>
</td></tr>
<tr><td><code id="diss.SPEC.GLK_+3A_y">y</code></td>
<td>

<p>Numeric vector containing the second of the two time series.
</p>
</td></tr>
<tr><td><code id="diss.SPEC.GLK_+3A_plot">plot</code></td>
<td>

<p>If <code>TRUE</code>, the smoothed spectral densities of the two series are plotted.	
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The dissimilarity between two series <code>x</code> and <code>y</code> is measured in terms of the vaue of a test statistic to check the equality of their log-spectra, <code class="reqn">m_X(\lambda)</code> and <code class="reqn">m_Y(\lambda)</code> respectivelty. The test statistic is constructed by using the generalized likelihood ratio test criterion (Fan and Zhang, 2004). Specifically, the test statistic takes the form:
</p>
<p style="text-align: center;"><code class="reqn"> d(x,y) = \sum_{k=1}^T [ Z_k - \hat{\mu}( \lambda_k) - 2 \log( 1 + e^{ \{ Z_k - \hat{\mu}(\lambda_k)\}})] - \sum_{k=1}^T[Z_k - 2 \log(1 + e^{Z_k})],</code>
</p>

<p>where <code class="reqn">I_x(\lambda_k)</code> and <code class="reqn">I_y(\lambda_k)</code> are the periodograms of <code>x</code> and <code>y</code>, <code class="reqn"> Z_k = \log(I_x(\lambda_k)) - \log( I_y(\lambda_k))</code>, and <code class="reqn">\hat{\mu}(\lambda_k)</code> is the local maximum log-likelihood estimator of <code class="reqn">\mu(\lambda_k)= m_x(\lambda_k) - m_y(\lambda_k)</code> computed by local linear fitting.
</p>


<h3>Value</h3>

<p>The computed distance.
</p>


<h3>Author(s)</h3>

<p>Pablo Montero Manso, José Antonio Vilar.
</p>


<h3>References</h3>

<p>Fan, J. and Zhang, W. (2004) Generalised likelihood ratio tests for spectral density. <em>Biometrika</em>, 195&ndash;209.<br />
</p>
<p>Pértega, S. and Vilar, J.A. (2010) Comparing several parametric and nonparametric approaches to time series clustering: A simulation study. <em>J. Classification</em>, <b>27(3)</b>, 333&ndash;362.
</p>
<p>Montero, P and Vilar, J.A. (2014) <em>TSclust: An R Package for Time Series Clustering.</em>  Journal of Statistical Software, 62(1), 1-43. <a href="http://www.jstatsoft.org/v62/i01/.">http://www.jstatsoft.org/v62/i01/.</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+diss.SPEC.ISD">diss.SPEC.ISD</a></code>, <code><a href="#topic+diss.SPEC.LLR">diss.SPEC.LLR</a></code> 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Create two sample time series
x &lt;- cumsum(rnorm(50))
y &lt;- cumsum(rnorm(50))
z &lt;- sin(seq(0, pi, length.out=50))
## Compute the distance and check for coherent results
diss.SPEC.GLK(x, y, plot=TRUE)
#create a dist object for its use with clustering functions like pam or hclust

diss( rbind(x,y,z), "SPEC.GLK" )

</code></pre>

<hr>
<h2 id='diss.SPEC.ISD'>
Dissimilarity Based on the Integrated Squared Difference between the Log-Spectra
</h2><span id='topic+diss.SPEC.ISD'></span>

<h3>Description</h3>

<p>Computes the dissimilarity between two time series in terms of the integrated squared difference between non-parametric estimators of their log-spectra.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>diss.SPEC.ISD(x, y, plot=FALSE, n=length(x))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="diss.SPEC.ISD_+3A_x">x</code></td>
<td>

<p>Numeric vector containing the first of the two time series.
</p>
</td></tr>
<tr><td><code id="diss.SPEC.ISD_+3A_y">y</code></td>
<td>

<p>Numeric vector containing the second of the two time series.
</p>
</td></tr>
<tr><td><code id="diss.SPEC.ISD_+3A_plot">plot</code></td>
<td>

<p>If <code>TRUE</code>, plot the smoothed spectral densities of the two series.
</p>
</td></tr>
<tr><td><code id="diss.SPEC.ISD_+3A_n">n</code></td>
<td>

<p>The number of points to use for the linear interpolation. A value of n=0 uses numerical integration instead of linear interpolation. See details.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p style="text-align: center;"><code class="reqn"> d(x,y) = \int ( \hat{m}_x(\lambda) - \hat{m}_y(\lambda))^2 \, d\lambda, </code>
</p>

<p>where <code class="reqn"> \hat{m}_x(\lambda) </code> and <code class="reqn"> \hat{m}_y(\lambda) </code> are local linear smoothers of the log-periodograms, obtained using the maximum local likelihood criterion.
</p>
<p>By default, for performance reasons, the spectral densities are estimated using linear interpolation using <code>n</code> points. If <code>n</code> is 0, no linear interpolation is performed, and <code>integrate</code> is used to calculate the integral, using as many points as <code>integrate</code> sees fit.
</p>


<h3>Value</h3>

<p>The computed distance.
</p>


<h3>Author(s)</h3>

<p>Pablo Montero Manso, José Antonio Vilar.
</p>


<h3>References</h3>

<p>Pértega, S. and Vilar, J.A. (2010) Comparing several parametric and nonparametric approaches to time series clustering: A simulation study. <em>J. Classification</em>, <b>27(3)</b>, 333&ndash;362.
</p>
<p>Montero, P and Vilar, J.A. (2014) <em>TSclust: An R Package for Time Series Clustering.</em>  Journal of Statistical Software, 62(1), 1-43. <a href="http://www.jstatsoft.org/v62/i01/.">http://www.jstatsoft.org/v62/i01/.</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+diss.SPEC.GLK">diss.SPEC.GLK</a></code>, <code><a href="#topic+diss.SPEC.LLR">diss.SPEC.LLR</a></code> 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Create two sample time series
x &lt;- cumsum(rnorm(50))
y &lt;- cumsum(rnorm(50))
z &lt;- sin(seq(0, pi, length.out=50))
## Compute the distance and check for coherent results
diss.SPEC.ISD(x, y, plot=TRUE) 
#create a dist object for its use with clustering functions like pam or hclust

diss.SPEC.ISD(x, y, plot=TRUE, n=0)#try integrate instead of interpolation
diss( rbind(x,y,z), "SPEC.ISD" )


</code></pre>

<hr>
<h2 id='diss.SPEC.LLR'>
General Spectral Dissimilarity Measure Using Local-Linear Estimation of the Log-Spectra
</h2><span id='topic+diss.SPEC.LLR'></span>

<h3>Description</h3>

<p>Computes a general dissimilarity measure based on the ratio of local linear spectral estimators.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>diss.SPEC.LLR(x, y, alpha=0.5, method="DLS", plot=FALSE, n=length(x))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="diss.SPEC.LLR_+3A_x">x</code></td>
<td>

<p>Numeric vector containing the first of the two time series.
</p>
</td></tr>
<tr><td><code id="diss.SPEC.LLR_+3A_y">y</code></td>
<td>

<p>Numeric vector containing the second of the two time series.
</p>
</td></tr>
<tr><td><code id="diss.SPEC.LLR_+3A_alpha">alpha</code></td>
<td>
<p> Power for the ratio of densities in the Chernoff information measure. Between 0 and 1.</p>
</td></tr>
<tr><td><code id="diss.SPEC.LLR_+3A_method">method</code></td>
<td>

<p><code>"DLS"</code> for least squares estimation of the spectral density and <code>"LK"</code> for maximum likelihood estimation.
</p>
</td></tr>
<tr><td><code id="diss.SPEC.LLR_+3A_plot">plot</code></td>
<td>

<p>if <code>TRUE</code>, plot the smoothed spectral densities of the two series.	
</p>
</td></tr>
<tr><td><code id="diss.SPEC.LLR_+3A_n">n</code></td>
<td>

<p>The number of points to use for the linear interpolation. A value of n=0 uses numerical integration instead of linear interpolation. See details.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p style="text-align: center;"><code class="reqn"> d_W = \int_{-\pi}^{\pi} W^{\prime}\Bigg( \frac{f_x(\lambda) } { f_y(\lambda) } \Bigg) d\lambda </code>
</p>

<p>where:
</p>

<ul>
<li>  <p><code class="reqn">f_x</code> and <code class="reqn">f_y</code> are nonparametric approximations of spectral densities of <code>x</code> and <code>y</code> respectively.
</p>
</li>
<li> <p><code class="reqn">W^{\prime}(x) = W(x) + W(1/x)</code> with <code class="reqn">W(x) = \log( \alpha x + (1- \alpha) x) - \alpha \log(x)</code>, so that <code class="reqn">W(.)</code> is a divergence function depending on <code class="reqn">\alpha</code>. 
</p>
</li></ul>

<p>This dissimilarity measure corresponds to the limiting spectral approximation of the Chernoff information measure in the time domain (see Kakizawa et al., 1998). The spectral densities are approximated by using local linear fitting by generalized least squared if <code>method=”DLS”</code> or by maximum likelihood if <code>method=”LK”</code> (in this case, higher computational cost is required).
</p>
<p>By default, for performance reasons, the spectral densities are estimated using linear interpolation using <code>n</code> points. If <code>n</code> is 0, no linear interpolation is performed, and <code>integrate</code> is used to calculate the integral, using as many points as <code>integrate</code> sees fit.
If the dissimilarity will be calculated for more than two series, calling SPEC.LLR from the <code>diss</code> wrapper function is preferred, since it saves some computations.
</p>


<h3>Value</h3>

<p>The computed distance.
</p>


<h3>Author(s)</h3>

<p>Pablo Montero Manso, José Antonio Vilar.
</p>


<h3>References</h3>

<p>Vilar, J.A. and Pértega, S. (2004) Discriminant and cluster analysis for gaussian stationary processes:
local linear fitting approach. <em>J. Nonparametr. Stat.</em>, <b>16(3-4)</b> 443&ndash;462.<br />
</p>
<p>Kakizawa, Y.,  Shumway, R. H. and Taniguchi M. (1998) Discrimination and clustering for multivariate time series. <em>J. Amer. Statist. Assoc.</em>, <b>93(441)</b>, 328&ndash;
340.
</p>
<p>Montero, P and Vilar, J.A. (2014) <em>TSclust: An R Package for Time Series Clustering.</em>  Journal of Statistical Software, 62(1), 1-43. <a href="http://www.jstatsoft.org/v62/i01/.">http://www.jstatsoft.org/v62/i01/.</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+diss.SPEC.GLK">diss.SPEC.GLK</a></code>, <code><a href="#topic+diss.SPEC.ISD">diss.SPEC.ISD</a></code>, <code><a href="stats.html#topic+integrate">integrate</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Create three sample time series
x &lt;- cumsum(rnorm(50))
y &lt;- cumsum(rnorm(50))
z &lt;- sin(seq(0, pi, length.out=50))
## Compute the distance and check for coherent results
diss.SPEC.LLR(x, y, plot=TRUE)
diss.SPEC.LLR(x, z, n=0) #try integrate instead of interpolation
diss.SPEC.LLR(y, z, method="LK", n=0) #maximum likelihood with integration
#create a dist object for its use with clustering functions like pam or hclust
diss(rbind(x,y,z), METHOD="SPEC.LLR", method="DLS", alpha=0.5, n=50)

</code></pre>

<hr>
<h2 id='electricity'>
Hourly Electricity Prices in the Spanish Market 
</h2><span id='topic+electricity'></span>

<h3>Description</h3>

<p>Partial realizations of time series of hourly electricity prices (Cent/kWh) in the Spanish market.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(electricity)</code></pre>


<h3>Format</h3>

<p>A matrix with 365 observations of the hourly electricity cost readings.
</p>


<h3>Details</h3>

<p>The dataset consists of hourly electricity prices in the Spanish market
during weekdays of the period December 31, 2007 - May 25, 2009.
</p>


<h3>References</h3>

<p>Montero, P and Vilar, J.A. (2014) <em>TSclust: An R Package for Time Series Clustering.</em>  Journal of Statistical Software, 62(1), 1-43. <a href="http://www.jstatsoft.org/v62/i01/.">http://www.jstatsoft.org/v62/i01/.</a>
</p>

<hr>
<h2 id='interest.rates'>
Long-Term Interest Rates from 1995 to 2012
</h2><span id='topic+interest.rates'></span>

<h3>Description</h3>

<p>Partial realizations of time series of long-term interest rates (10-year bonds) for several countries. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(interest.rates)</code></pre>


<h3>Format</h3>

<p>A <code>ts</code> object with 215 observations of the monthly long-term interest rates (10-year bonds) from January 1995 to November 2012 of several countries.
</p>


<h3>References</h3>

<p>Montero, P and Vilar, J.A. (2014) <em>TSclust: An R Package for Time Series Clustering.</em>  Journal of Statistical Software, 62(1), 1-43. <a href="http://www.jstatsoft.org/v62/i01/.">http://www.jstatsoft.org/v62/i01/.</a>
</p>

<hr>
<h2 id='loo1nn.cv'>
Clustering Evaluation Index Based on Leave-one-out One-nearest-neighbor Evaluation
</h2><span id='topic+loo1nn.cv'></span>

<h3>Description</h3>

<p>Computes the leave-one-out one-nearest-neighbor cross-validation of an arbitrary distance matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>loo1nn.cv(d, G)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="loo1nn.cv_+3A_d">d</code></td>
<td>

<p>A <code>dist</code> object.
</p>
</td></tr>
<tr><td><code id="loo1nn.cv_+3A_g">G</code></td>
<td>

<p>Integer vector with the labels of the true cluster solution. Each element of the vector specifies the cluster 'id' that the element belongs to.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Computes the proportion of succesful clusters that the given distance matrix produces using leave-one-out one-nearest-neighbor cross-validation. Distance ties are solved by majority vote. A tie while voting produces a warning and is solved by selecting a candidate cluster at random. 
</p>


<h3>Value</h3>

<p>The computed proportion.
</p>


<h3>Author(s)</h3>

<p>Pablo Montero Manso, José Antonio Vilar.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cluster.evaluation">cluster.evaluation</a></code>, <code><a href="pdc.html#topic+loo1nn">loo1nn</a></code>,  <code><a href="class.html#topic+knn.cv">knn.cv</a></code>,
</p>


<h3>Examples</h3>

<pre><code class='language-R'> data(synthetic.tseries)
 
 #create the ground thruth cluster 
 G &lt;- rep(1:6, each = 3)
 
 #obtain candidate distance matrix (dist object)
 dACF &lt;- diss(synthetic.tseries, "ACF")
 
 #calculate the cross-validation
 loo1nn.cv(dACF, G)
 
</code></pre>

<hr>
<h2 id='paired.tseries'>
Pairs of Time Series from Different Domains
</h2><span id='topic+paired.tseries'></span>

<h3>Description</h3>

<p>Dataset formed by pairs of time series from different domains. Series were selected from the UCR Time Series Archive.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(paired.tseries)</code></pre>


<h3>Format</h3>

<p>A <code>mts</code> object with 36 series of length 1000.
</p>


<h3>Details</h3>

<p>Each pair of series in the dataset (Series 1 and 2, Series 3 and 4, etc.) comes from the same domain, so this pairing could constitute a possible ground truth solution.
</p>


<h3>Note</h3>

<p><code>abbreviate</code> can be used on the <code>colnames</code>.
</p>


<h3>Source</h3>

<p>http://www.cs.ucr.edu/~eamonn/SIGKDD2004/All_datasets/</p>


<h3>References</h3>

<p>Keogh, E., Lonardi, S., &amp; Ratanamahatana, C. A. (2004). Towards parameter-free data mining. Proceedings of the tenth ACM SIGKDD international conference on Knowledge discovery and data mining (pp. 206-215).
</p>
<p>Montero, P and Vilar, J.A. (2014) <em>TSclust: An R Package for Time Series Clustering.</em>  Journal of Statistical Software, 62(1), 1-43. <a href="http://www.jstatsoft.org/v62/i01/.">http://www.jstatsoft.org/v62/i01/.</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(paired.tseries)
#Create the true solution, the pairs
true_cluster &lt;- rep(1:18, each=2)
#test a dissimilarity metric and a cluster algorithm
intperdist &lt;- diss( paired.tseries, "INT.PER") #create the distance matrix
#use hierarchical clustering and divide the tree in 18 clusters
intperclust &lt;- cutree( hclust(intperdist), k=18 )
#use a cluster simmilarity index to rate the solution
cluster.evaluation( true_cluster, intperclust)

#### other evaluation criterion used in this dataset  consist in counting the correct pairs
#### formed during agglomerative hierarchical cluster (see references)
true_pairs = (-matrix(1:36, ncol=2, byrow=TRUE))
hcintper &lt;- hclust(intperdist, "complete")
#count within the hierarchical cluster the pairs
sum( match(data.frame(t(true_pairs)), data.frame(t(hcintper$merge)), nomatch=0) &gt; 0 ) / 18

</code></pre>

<hr>
<h2 id='pvalues.clust'>
Clustering Algorithm Based on p-values.
</h2><span id='topic+pvalues.clust'></span>

<h3>Description</h3>

<p>Clustering algorithm based on p-values. Each group in the cluster solution is formed by
series with associated p-values greater than a pre-specified level of significance.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pvalues.clust(pvalues, significance)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pvalues.clust_+3A_pvalues">pvalues</code></td>
<td>

<p>A <code>dist</code> object containing the p-values from testing the equality of each pair of time series under study.
</p>
</td></tr>
<tr><td><code id="pvalues.clust_+3A_significance">significance</code></td>
<td>

<p>The significance level.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Each element (i,j) in <code>pvalues</code> corresponds to the p-value obtained from checking whether or not the <code class="reqn">i</code>-th and <code class="reqn">j</code>-th series come from the same generating
model. The clustering algorithm will only group together those series whose associated p-values are greater than the pre-specified significance level. The algorithm was originally developed for its use with the p-values obtained with in <code>diss.AR.MAH</code> (see Maharaj, 2000), but it can be applied to any similar test.
</p>


<h3>Value</h3>

<p>An integer vector of length n, the number of observations, giving for each observation the number (id) of the cluster to which it belongs.
</p>


<h3>Author(s)</h3>

<p>Pablo Montero Manso, José Antonio Vilar. 
</p>


<h3>References</h3>

<p>Maharaj E.A. (2000) Clusters of time series. <em>J. Classification</em>, <b>17(2)</b>, 297&ndash;314.
</p>
<p>Montero, P and Vilar, J.A. (2014) <em>TSclust: An R Package for Time Series Clustering.</em>  Journal of Statistical Software, 62(1), 1-43. <a href="http://www.jstatsoft.org/v62/i01/.">http://www.jstatsoft.org/v62/i01/.</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+diss.AR.MAH">diss.AR.MAH</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Create three sample time series
x &lt;- cumsum(rnorm(100))
y &lt;- cumsum(rnorm(100))
z &lt;- sin(seq(0, pi, length.out=100))
##

## Compute the distance and check for coherent results
dd &lt;- diss( rbind(x,y,z), "AR.MAH")
pvalues.clust( dd$p_value, 0.05 )

</code></pre>

<hr>
<h2 id='synthetic.tseries'>
Synthetic Time Series for Clustering Performace Comparisons.
</h2><span id='topic+synthetic.tseries'></span>

<h3>Description</h3>

<p>This dataset features three repetitions of several models of time series.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(synthetic.tseries)</code></pre>


<h3>Details</h3>

<p>The dataset is a <code>mts</code> object, formed by several repetitions of each of the following models.
</p>

<table>
<tr>
 <td style="text-align: center;"> 
M1 </td><td style="text-align: left;"> AR </td><td style="text-align: left;">   <code class="reqn">X_t = 0.6 X_{t-1} + \varepsilon_{t}</code>  </td>
</tr>
<tr>
 <td style="text-align: center;">
M2 </td><td style="text-align: left;"> Bilinear  </td><td style="text-align: left;">  <code class="reqn">X_t = \left( 0.3 -0.2 \varepsilon_{t-1} \right) X_{t-1} + 1.0 +\varepsilon_{t}</code> </td>
</tr>
<tr>
 <td style="text-align: center;">
M3 </td><td style="text-align: left;"> EXPAR </td><td style="text-align: left;"> <code class="reqn">X_t =\left( 0.9 \exp \left( - X_{t-1}^2 \right) -0.6 \right) X_{t-1} + 1.0 + \varepsilon_{t}</code> </td>
</tr>
<tr>
 <td style="text-align: center;">
M4 </td><td style="text-align: left;"> SETAR </td><td style="text-align: left;">  <code class="reqn"> X_t =\left( 0.3 X_{t-1} +1.0 \right) I \left( X_{t-1} \geq 0.2 \right) - </code> </td>
</tr>
<tr>
 <td style="text-align: center;">
   </td><td style="text-align: left;">      </td><td style="text-align: left;">  <code class="reqn"> \left( 0.3 X_{t-1} -1.0 \right) I \left( X_{t-1} &lt; 0.2 \right) + \varepsilon_{t}</code> </td>
</tr>
<tr>
 <td style="text-align: center;">
M5 </td><td style="text-align: left;"> NLAR </td><td style="text-align: left;">  <code class="reqn"> X_t = 0.7 \left| X_{t-1} \right| \left( 2 + \left| X_{t-1} \right| \right)^{-1} + \varepsilon_{t}</code> </td>
</tr>
<tr>
 <td style="text-align: center;">
M6 </td><td style="text-align: left;"> STAR </td><td style="text-align: left;">  <code class="reqn"> X_t = 0.8 X_{t-1} -0.8 X_{t-1} \left( 1 + \exp \left( -10 X_{t-1} \right) \right)^{-1}  + \varepsilon_{t}</code> </td>
</tr>
<tr>
 <td style="text-align: center;">
</td>
</tr>

</table>

<p>Three simulations of each model are included. This dataset can be used for comparing the performance of different dissimilarity measures between time series  or clustering algorithms.
</p>


<h3>References</h3>

<p>Montero, P and Vilar, J.A. (2014) <em>TSclust: An R Package for Time Series Clustering.</em>  Journal of Statistical Software, 62(1), 1-43. <a href="http://www.jstatsoft.org/v62/i01/.">http://www.jstatsoft.org/v62/i01/.</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(synthetic.tseries)
#Create the true solution, for this dataset, there are three series of each model
true_cluster &lt;- c(1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5, 5, 6, 6, 6)
#test a dissimilarity metric and a cluster algorithm
intperdist &lt;- diss( synthetic.tseries, "INT.PER") #create the distance matrix
#use hierarchical clustering and divide the tree in 6 clusters
intperclust &lt;- cutree( hclust(intperdist), 6 ) 
#use a cluster simmilarity index to rate the solution
cluster.evaluation( true_cluster, intperclust)

#test another dissimilarity metric and a cluster algorithm
acfdist &lt;- diss( synthetic.tseries, "ACF", p=0.05) 
acfcluster &lt;- pam( acfdist, 6 )$clustering #use pam clustering to form 6 clusters
cluster.evaluation( true_cluster, acfcluster)

#test another dissimilarity metric and a cluster algorithm
chernoffdist &lt;- diss( synthetic.tseries, "SPEC.LLR")
chernoffclust &lt;- pam( chernoffdist, 6 )$clustering 
cluster.evaluation( true_cluster, chernoffclust)


</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
