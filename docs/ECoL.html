<!DOCTYPE html><html><head><title>Help for package ECoL</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {ECoL}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#balance'><p>Measures of class balance</p></a></li>
<li><a href='#complexity'><p>Extract the complexity measures from datasets</p></a></li>
<li><a href='#correlation'><p>Measures of feature correlation</p></a></li>
<li><a href='#dimensionality'><p>Measures of dimensionality</p></a></li>
<li><a href='#linearity'><p>Measures of linearity</p></a></li>
<li><a href='#neighborhood'><p>Measures of neighborhood</p></a></li>
<li><a href='#network'><p>Measures of network</p></a></li>
<li><a href='#overlapping'><p>Measures of overlapping</p></a></li>
<li><a href='#smoothness'><p>Measures of smoothness</p></a></li>
<li><a href='#summarization'><p>Post processing complexity measures</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Version:</td>
<td>0.3.0</td>
</tr>
<tr>
<td>Date:</td>
<td>2019-11-04</td>
</tr>
<tr>
<td>Title:</td>
<td>Complexity Measures for Supervised Problems</td>
</tr>
<tr>
<td>Description:</td>
<td>Provides measures to characterize the complexity of classification 
    and regression problems based on aspects that quantify the linearity of the 
    data, the presence of informative feature, the sparsity and dimensionality 
    of the datasets. This package provides bug fixes, generalizations and 
    implementations of many state of the art measures. The measures are 
    described in the papers: Lorena et al. (2019) &lt;<a href="https://doi.org/10.1145%2F3347711">doi:10.1145/3347711</a>&gt; and 
    Lorena et al. (2018) &lt;<a href="https://doi.org/10.1007%2Fs10994-017-5681-1">doi:10.1007/s10994-017-5681-1</a>&gt;.</td>
</tr>
<tr>
<td>Author:</td>
<td>Luis Garcia [aut, cre],
  Ana Lorena [aut, ctb]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Luis Garcia &lt;lpfgarcia@icmc.usp.br&gt;</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/lpfgarcia/ECoL/">https://github.com/lpfgarcia/ECoL/</a></td>
</tr>
<tr>
<td>Imports:</td>
<td>cluster, e1071, FNN, igraph, MASS</td>
</tr>
<tr>
<td>Suggests:</td>
<td>testthat</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/lpfgarcia/ECoL/issues">https://github.com/lpfgarcia/ECoL/issues</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>6.1.1</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2019-11-04 23:09:18 UTC; lpfgarcia</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2019-11-05 05:10:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='balance'>Measures of class balance</h2><span id='topic+balance'></span><span id='topic+balance.default'></span><span id='topic+balance.formula'></span>

<h3>Description</h3>

<p>Classification task. These measures capture the differences in the number of 
examples per class in the dataset. When these differences are severe, 
problems related to generalization of the ML classification techniques could 
happen because of the imbalance ratio.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>balance(...)

## Default S3 method:
balance(x, y, measures = "all", ...)

## S3 method for class 'formula'
balance(formula, data, measures = "all", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="balance_+3A_...">...</code></td>
<td>
<p>Not used.</p>
</td></tr>
<tr><td><code id="balance_+3A_x">x</code></td>
<td>
<p>A data.frame contained only the input attributes.</p>
</td></tr>
<tr><td><code id="balance_+3A_y">y</code></td>
<td>
<p>A factor response vector with one label for each row/component of x.</p>
</td></tr>
<tr><td><code id="balance_+3A_measures">measures</code></td>
<td>
<p>A list of measures names or <code>"all"</code> to include all them.</p>
</td></tr>
<tr><td><code id="balance_+3A_formula">formula</code></td>
<td>
<p>A formula to define the class column.</p>
</td></tr>
<tr><td><code id="balance_+3A_data">data</code></td>
<td>
<p>A data.frame dataset contained the input attributes and class.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The following measures are allowed for this method:
</p>

<dl>
<dt>&quot;C1&quot;</dt><dd><p>The entropy of class proportions (C1) capture the imbalance in
a dataset based on the proportions of examples per class.</p>
</dd>
<dt>&quot;C2&quot;</dt><dd><p>The imbalance ratio (C2) is an index computed for measuring
class balance. This is a version of the measure that is also suited for 
multiclass classification problems.</p>
</dd>
</dl>



<h3>Value</h3>

<p>A list named by the requested class balance measure.
</p>


<h3>References</h3>

<p>Ana C Lorena, Ivan G Costa, Newton Spolaor and Marcilio C P Souto. (2012). 
Analysis of complexity indices for classification problems: Cancer gene 
expression data. Neurocomputing 75, 1, 33&ndash;42.
</p>
<p>Ajay K Tanwani and Muddassar Farooq. (2010). Classification potential vs. 
classification accuracy: a comprehensive study of evolutionary algorithms 
with biomedical datasets. Learning Classifier Systems 6471, 127&ndash;144.
</p>


<h3>See Also</h3>

<p>Other complexity-measures: <code><a href="#topic+correlation">correlation</a></code>,
<code><a href="#topic+dimensionality">dimensionality</a></code>, <code><a href="#topic+linearity">linearity</a></code>,
<code><a href="#topic+neighborhood">neighborhood</a></code>, <code><a href="#topic+network">network</a></code>,
<code><a href="#topic+overlapping">overlapping</a></code>, <code><a href="#topic+smoothness">smoothness</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Extract all balance measures for classification task
data(iris)
balance(Species ~ ., iris)
</code></pre>

<hr>
<h2 id='complexity'>Extract the complexity measures from datasets</h2><span id='topic+complexity'></span><span id='topic+complexity.default'></span><span id='topic+complexity.formula'></span>

<h3>Description</h3>

<p>This function is responsable to extract the complexity measures from the 
classification and regression tasks. For such, they take into account the 
overlap between classes imposed by feature values, the separability and 
distribution of the data points and the value of structural measures based on
the representation of the dataset as a graph structure. To set specific 
parameters for each group, use the characterization function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>complexity(...)

## Default S3 method:
complexity(x, y, groups = "all", summary = c("mean",
  "sd"), ...)

## S3 method for class 'formula'
complexity(formula, data, groups = "all",
  summary = c("mean", "sd"), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="complexity_+3A_...">...</code></td>
<td>
<p>Not used.</p>
</td></tr>
<tr><td><code id="complexity_+3A_x">x</code></td>
<td>
<p>A data.frame contained only the input attributes.</p>
</td></tr>
<tr><td><code id="complexity_+3A_y">y</code></td>
<td>
<p>A response vector with one value for each row/component of x.</p>
</td></tr>
<tr><td><code id="complexity_+3A_groups">groups</code></td>
<td>
<p>A list of complexity measures groups or <code>"all"</code> to include
all of them.</p>
</td></tr>
<tr><td><code id="complexity_+3A_summary">summary</code></td>
<td>
<p>A list of summarization functions or empty for all values. See
<a href="#topic+summarization">summarization</a> method to more information. (Default: 
<code>c("mean", "sd")</code>)</p>
</td></tr>
<tr><td><code id="complexity_+3A_formula">formula</code></td>
<td>
<p>A formula to define the output column.</p>
</td></tr>
<tr><td><code id="complexity_+3A_data">data</code></td>
<td>
<p>A data.frame dataset contained the input and output attributes.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The following groups are allowed for this method:
</p>

<dl>
<dt>&quot;overlapping&quot;</dt><dd><p>The feature overlapping measures characterize how 
informative the available features are to separate the classes See 
<a href="#topic+overlapping">overlapping</a> for more details.</p>
</dd>
<dt>&quot;neighborhood&quot;</dt><dd><p>Neighborhood measures characterize the presence and 
density of same or different classes in local neighborhoods. See 
<a href="#topic+neighborhood">neighborhood</a> for more details.</p>
</dd>
<dt>&quot;linearity&quot;</dt><dd><p>Linearity measures try to quantify whether the labels 
can be linearly separated. See <a href="#topic+linearity">linearity</a> for more details.</p>
</dd>
<dt>&quot;dimensionality&quot;</dt><dd><p>The dimensionality measures compute information on
how smoothly the examples are distributed within the attributes. See 
<a href="#topic+dimensionality">dimensionality</a> for more details.</p>
</dd>
<dt>&quot;balance&quot;</dt><dd><p>Class balance measures take into account the numbers of 
examples per class in the dataset. See <a href="#topic+balance">balance</a> for more details.</p>
</dd>
<dt>&quot;network&quot;</dt><dd><p>Network measures represent the dataset as a graph and 
extract structural information from it. See <a href="#topic+network">network</a> for more 
details.</p>
</dd>
<dt>&quot;correlation&quot;</dt><dd><p>Capture the relationship of the feature values with 
the outputs. See <a href="#topic+correlation">correlation</a> for more details.</p>
</dd>
<dt>&quot;smoothness&quot;</dt><dd><p>Estimate the smoothness of the function that must be 
fitted to the data. See <a href="#topic+smoothness">smoothness</a> for more details.</p>
</dd>
</dl>



<h3>Value</h3>

<p>A numeric vector named by the requested complexity measures.
</p>


<h3>References</h3>

<p>Tin K Ho and Mitra Basu. (2002). Complexity measures of supervised 
classification problems. IEEE Transactions on Pattern Analysis and Machine
Intelligence, 24, 3, 289&ndash;300.
</p>
<p>Albert Orriols-Puig, Nuria Macia and Tin K Ho. (2010). Documentation for 
the data complexity library in C++. Technical Report. La Salle - 
Universitat Ramon Llull.
</p>
<p>Ana C Lorena and Aron I Maciel and Pericles B C Miranda and Ivan G Costa and
Ricardo B C Prudencio. (2018). Data complexity meta-features for 
regression problems. Machine Learning, 107, 1, 209&ndash;246.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Extract all complexity measures for classification task
data(iris)
complexity(Species ~ ., iris)

## Extract all complexity measures for regression task
data(cars)
complexity(speed ~ ., cars)
</code></pre>

<hr>
<h2 id='correlation'>Measures of feature correlation</h2><span id='topic+correlation'></span><span id='topic+correlation.default'></span><span id='topic+correlation.formula'></span>

<h3>Description</h3>

<p>Regression task. These measures calculate the correlation of the values of 
the features to the outputs. If at least one feature is highly correlated to 
the output, this indicates that simpler functions can be fitted to the data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>correlation(...)

## Default S3 method:
correlation(x, y, measures = "all",
  summary = c("mean", "sd"), ...)

## S3 method for class 'formula'
correlation(formula, data, measures = "all",
  summary = c("mean", "sd"), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="correlation_+3A_...">...</code></td>
<td>
<p>Not used.</p>
</td></tr>
<tr><td><code id="correlation_+3A_x">x</code></td>
<td>
<p>A data.frame contained only the input attributes.</p>
</td></tr>
<tr><td><code id="correlation_+3A_y">y</code></td>
<td>
<p>A response vector with one value for each row/component of x.</p>
</td></tr>
<tr><td><code id="correlation_+3A_measures">measures</code></td>
<td>
<p>A list of measures names or <code>"all"</code> to include all them.</p>
</td></tr>
<tr><td><code id="correlation_+3A_summary">summary</code></td>
<td>
<p>A list of summarization functions or empty for all values. See
<a href="#topic+summarization">summarization</a> method to more information. (Default: 
<code>c("mean", "sd")</code>)</p>
</td></tr>
<tr><td><code id="correlation_+3A_formula">formula</code></td>
<td>
<p>A formula to define the output column.</p>
</td></tr>
<tr><td><code id="correlation_+3A_data">data</code></td>
<td>
<p>A data.frame dataset contained the input and output attributes.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The following measures are allowed for this method:
</p>

<dl>
<dt>&quot;C1&quot;</dt><dd><p>Maximum feature correlation to the output (C1) calculate the 
maximum absolute value of the Spearman correlation between each feature 
and the outputs.</p>
</dd>
<dt>&quot;C2&quot;</dt><dd><p>Average feature correlation to the output (C2) computes the 
average of the Spearman correlations of all features to the output.</p>
</dd>
<dt>&quot;C3&quot;</dt><dd><p>Individual feature efficiency (C3) calculates, for each 
feature, the number of examples that must be removed from the dataset 
until a high Spearman correlation value to the output is achieved.</p>
</dd>
<dt>&quot;C4&quot;</dt><dd><p>Collective feature efficiency (C4) computes the ratio of 
examples removed from the dataset based on an iterative process of 
linear fitting between the features and the target attribute.</p>
</dd>
</dl>



<h3>Value</h3>

<p>A list named by the requested correlation measure.
</p>


<h3>References</h3>

<p>Ana C Lorena and Aron I Maciel and Pericles B C Miranda and Ivan G Costa and
Ricardo B C Prudencio. (2018). Data complexity meta-features for 
regression problems. Machine Learning, 107, 1, 209&ndash;246.
</p>


<h3>See Also</h3>

<p>Other complexity-measures: <code><a href="#topic+balance">balance</a></code>,
<code><a href="#topic+dimensionality">dimensionality</a></code>, <code><a href="#topic+linearity">linearity</a></code>,
<code><a href="#topic+neighborhood">neighborhood</a></code>, <code><a href="#topic+network">network</a></code>,
<code><a href="#topic+overlapping">overlapping</a></code>, <code><a href="#topic+smoothness">smoothness</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Extract all correlation measures for regression task
data(cars)
correlation(speed ~ ., cars)
</code></pre>

<hr>
<h2 id='dimensionality'>Measures of dimensionality</h2><span id='topic+dimensionality'></span><span id='topic+dimensionality.default'></span><span id='topic+dimensionality.formula'></span>

<h3>Description</h3>

<p>These measures give an indicative of data sparsity. They capture how sparse 
a datasets tend to have regions of low density. These regions are know to be 
more difficult to extract good classification and regression models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dimensionality(...)

## Default S3 method:
dimensionality(x, y, measures = "all", ...)

## S3 method for class 'formula'
dimensionality(formula, data, measures = "all", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dimensionality_+3A_...">...</code></td>
<td>
<p>Not used.</p>
</td></tr>
<tr><td><code id="dimensionality_+3A_x">x</code></td>
<td>
<p>A data.frame contained only the input attributes.</p>
</td></tr>
<tr><td><code id="dimensionality_+3A_y">y</code></td>
<td>
<p>A response vector with one value for each row/component of x.</p>
</td></tr>
<tr><td><code id="dimensionality_+3A_measures">measures</code></td>
<td>
<p>A list of measures names or <code>"all"</code> to include all them.</p>
</td></tr>
<tr><td><code id="dimensionality_+3A_formula">formula</code></td>
<td>
<p>A formula to define the output column.</p>
</td></tr>
<tr><td><code id="dimensionality_+3A_data">data</code></td>
<td>
<p>A data.frame dataset contained the input and output attributes.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The following measures are allowed for this method:
</p>

<dl>
<dt>&quot;T2&quot;</dt><dd><p>Average number of points per dimension (T2) is given by the 
ratio between the number of examples and dimensionality of the dataset.</p>
</dd>
<dt>&quot;T3&quot;</dt><dd><p>Average number of points per PCA (T3) is similar to T2, but 
uses the number of PCA components needed to represent 95
variability as the base of data sparsity assessment.</p>
</dd>
<dt>&quot;T4&quot;</dt><dd><p>Ratio of the PCA Dimension to the Original (T4) estimates the
proportion of relevant and the original dimensions for a dataset.</p>
</dd>
</dl>



<h3>Value</h3>

<p>A list named by the requested dimensionality measure.
</p>


<h3>References</h3>

<p>Ana C Lorena, Ivan G Costa, Newton Spolaor and Marcilio C P Souto. (2012). 
Analysis of complexity indices for classification problems: Cancer gene 
expression data. Neurocomputing 75, 1, 33&ndash;42.
</p>


<h3>See Also</h3>

<p>Other complexity-measures: <code><a href="#topic+balance">balance</a></code>,
<code><a href="#topic+correlation">correlation</a></code>, <code><a href="#topic+linearity">linearity</a></code>,
<code><a href="#topic+neighborhood">neighborhood</a></code>, <code><a href="#topic+network">network</a></code>,
<code><a href="#topic+overlapping">overlapping</a></code>, <code><a href="#topic+smoothness">smoothness</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Extract all dimensionality measures for classification task
data(iris)
dimensionality(Species ~ ., iris)

## Extract all dimensionality measures for regression task
data(cars)
dimensionality(speed ~ ., cars)
</code></pre>

<hr>
<h2 id='linearity'>Measures of linearity</h2><span id='topic+linearity'></span><span id='topic+linearity.default'></span><span id='topic+linearity.formula'></span>

<h3>Description</h3>

<p>The linearity measures try to quantify if it is possible to separate the 
labels by a hyperplane or linear function. The underlying assumption is that 
a linearly separable problem can be considered simpler than a problem
requiring a non-linear decision boundary.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>linearity(...)

## Default S3 method:
linearity(x, y, measures = "all", summary = c("mean",
  "sd"), ...)

## S3 method for class 'formula'
linearity(formula, data, measures = "all",
  summary = c("mean", "sd"), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="linearity_+3A_...">...</code></td>
<td>
<p>Not used.</p>
</td></tr>
<tr><td><code id="linearity_+3A_x">x</code></td>
<td>
<p>A data.frame contained only the input attributes.</p>
</td></tr>
<tr><td><code id="linearity_+3A_y">y</code></td>
<td>
<p>A response vector with one value for each row/component of x.</p>
</td></tr>
<tr><td><code id="linearity_+3A_measures">measures</code></td>
<td>
<p>A list of measures names or <code>"all"</code> to include all them.</p>
</td></tr>
<tr><td><code id="linearity_+3A_summary">summary</code></td>
<td>
<p>A list of summarization functions or empty for all values. See
<a href="#topic+summarization">summarization</a> method to more information. (Default: 
<code>c("mean", "sd")</code>)</p>
</td></tr>
<tr><td><code id="linearity_+3A_formula">formula</code></td>
<td>
<p>A formula to define the output column.</p>
</td></tr>
<tr><td><code id="linearity_+3A_data">data</code></td>
<td>
<p>A data.frame dataset contained the input attributes and class.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The following classification measures are allowed for this method:
</p>

<dl>
<dt>&quot;L1&quot;</dt><dd><p>Sum of the error distance by linear programming (L1) computes 
the sum of the distances of incorrectly classified examples to a linear 
boundary used in their classification.</p>
</dd>
<dt>&quot;L2&quot;</dt><dd><p>Error rate of linear classifier (L2) computes the error rate 
of the linear SVM classifier induced from dataset.</p>
</dd>
<dt>&quot;L3&quot;</dt><dd><p>Non-linearity of a linear classifier (L3) creates a new 
dataset randomly interpolating pairs of training examples of the same 
class and then induce a linear SVM on the original data and measure 
the error rate in the new data points.</p>
</dd>
</dl>

<p>The following regression measures are allowed for this method:
</p>

<dl>
<dt>&quot;L1&quot;</dt><dd><p>Mean absolute error (L1) averages the absolute values of the 
residues of a multiple linear regressor.</p>
</dd>
<dt>&quot;L2&quot;</dt><dd><p>Residuals variance (L2) averages the square of the residuals 
from a multiple linear regression.</p>
</dd>
<dt>&quot;L3&quot;</dt><dd><p>Non-linearity of a linear regressor (L3) measures how 
sensitive the regressor is to the new randomly interpolated points.</p>
</dd>
</dl>



<h3>Value</h3>

<p>A list named by the requested linearity measure.
</p>


<h3>References</h3>

<p>Albert Orriols-Puig, Nuria Macia and Tin K Ho. (2010). Documentation for the
data complexity library in C++. Technical Report. La Salle - Universitat 
Ramon Llull.
</p>


<h3>See Also</h3>

<p>Other complexity-measures: <code><a href="#topic+balance">balance</a></code>,
<code><a href="#topic+correlation">correlation</a></code>, <code><a href="#topic+dimensionality">dimensionality</a></code>,
<code><a href="#topic+neighborhood">neighborhood</a></code>, <code><a href="#topic+network">network</a></code>,
<code><a href="#topic+overlapping">overlapping</a></code>, <code><a href="#topic+smoothness">smoothness</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Extract all linearity measures for classification task
data(iris)
linearity(Species ~ ., iris)

## Extract all linearity measures for regression task
data(cars)
linearity(speed ~ ., cars)
</code></pre>

<hr>
<h2 id='neighborhood'>Measures of neighborhood</h2><span id='topic+neighborhood'></span><span id='topic+neighborhood.default'></span><span id='topic+neighborhood.formula'></span>

<h3>Description</h3>

<p>Classification task. The Neighborhood measures analyze the neighborhoods of 
the data items and try to capture class overlapping and the shape of the 
decision boundary. They work over a distance matrix storing the distances 
between all pairs of data points in the dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>neighborhood(...)

## Default S3 method:
neighborhood(x, y, measures = "all",
  summary = c("mean", "sd"), ...)

## S3 method for class 'formula'
neighborhood(formula, data, measures = "all",
  summary = c("mean", "sd"), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="neighborhood_+3A_...">...</code></td>
<td>
<p>Not used.</p>
</td></tr>
<tr><td><code id="neighborhood_+3A_x">x</code></td>
<td>
<p>A data.frame contained only the input attributes.</p>
</td></tr>
<tr><td><code id="neighborhood_+3A_y">y</code></td>
<td>
<p>A factor response vector with one label for each row/component of x.</p>
</td></tr>
<tr><td><code id="neighborhood_+3A_measures">measures</code></td>
<td>
<p>A list of measures names or <code>"all"</code> to include all them.</p>
</td></tr>
<tr><td><code id="neighborhood_+3A_summary">summary</code></td>
<td>
<p>A list of summarization functions or empty for all values. See
<a href="#topic+summarization">summarization</a> method to more information. (Default: 
<code>c("mean", "sd")</code>)</p>
</td></tr>
<tr><td><code id="neighborhood_+3A_formula">formula</code></td>
<td>
<p>A formula to define the class column.</p>
</td></tr>
<tr><td><code id="neighborhood_+3A_data">data</code></td>
<td>
<p>A data.frame dataset contained the input attributes and class.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The following measures are allowed for this method:
</p>

<dl>
<dt>&quot;N1&quot;</dt><dd><p>Fraction of borderline points (N1) computes the percentage of 
vertexes incident to edges connecting examples of opposite classes in 
a Minimum Spanning Tree (MST).</p>
</dd>
<dt>&quot;N2&quot;</dt><dd><p>Ratio of intra/extra class nearest neighbor distance (N2)  
computes the ratio of two sums: intra-class and inter-class. The former 
corresponds to the sum of the distances between each example and its 
closest neighbor from the same class. The later is the sum of the 
distances between each example and its closest neighbor from another 
class (nearest enemy).</p>
</dd>
<dt>&quot;N3&quot;</dt><dd><p>Error rate of the nearest neighbor (N3) classifier corresponds
to the error rate of a one Nearest Neighbor (1NN) classifier, estimated 
using a leave-one-out procedure in dataset.</p>
</dd>
<dt>&quot;N4&quot;</dt><dd><p>Non-linearity of the nearest neighbor classifier (N4) creates 
a new dataset randomly interpolating pairs of training examples of the 
same class and then induce a the 1NN classifier on the original data and
measure the error rate in the new data points.</p>
</dd>
<dt>&quot;T1&quot;</dt><dd><p>Fraction of hyperspheres covering data (T1) builds 
hyperspheres centered at each one of the training examples, which have 
their radios growth until the hypersphere reaches an example of another 
class. Afterwards, smaller hyperspheres contained in larger hyperspheres 
are eliminated. T1 is finally defined as the ratio between the number of 
the remaining hyperspheres and the total number of examples in the 
dataset.</p>
</dd>
<dt>&quot;LSC&quot;</dt><dd><p>Local Set Average Cardinality (LSC) is based on Local Set 
(LS) and defined as the set of points from the dataset whose distance of
each example is smaller than the distance from the exemples of the 
different class. LSC is the average of the LS.</p>
</dd>
</dl>



<h3>Value</h3>

<p>A list named by the requested neighborhood measure.
</p>


<h3>References</h3>

<p>Albert Orriols-Puig, Nuria Macia and Tin K Ho. (2010). Documentation for the
data complexity library in C++. Technical Report. La Salle - Universitat 
Ramon Llull.
</p>
<p>Enrique Leyva, Antonio Gonzalez and Raul Perez. (2014). A Set of Complexity
Measures Designed for Applying Meta-Learning to Instance Selection. IEEE
Transactions on Knowledge and Data Engineering 27, 2, 354&ndash;367.
</p>


<h3>See Also</h3>

<p>Other complexity-measures: <code><a href="#topic+balance">balance</a></code>,
<code><a href="#topic+correlation">correlation</a></code>, <code><a href="#topic+dimensionality">dimensionality</a></code>,
<code><a href="#topic+linearity">linearity</a></code>, <code><a href="#topic+network">network</a></code>,
<code><a href="#topic+overlapping">overlapping</a></code>, <code><a href="#topic+smoothness">smoothness</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Extract all neighborhood measures for classification task
data(iris)
neighborhood(Species ~ ., iris)
</code></pre>

<hr>
<h2 id='network'>Measures of network</h2><span id='topic+network'></span><span id='topic+network.default'></span><span id='topic+network.formula'></span>

<h3>Description</h3>

<p>Classification task. The network measures represent the dataset as a graph 
and extract structural information from it. The transformation between raw 
data and the graph representation is based on the epsilon-NN algorithm. Next,
a post-processing step is applied to the graph, pruning edges between 
examples of opposite classes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>network(...)

## Default S3 method:
network(x, y, measures = "all", eps = 0.15,
  summary = c("mean", "sd"), ...)

## S3 method for class 'formula'
network(formula, data, measures = "all", eps = 0.15,
  summary = c("mean", "sd"), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="network_+3A_...">...</code></td>
<td>
<p>Not used.</p>
</td></tr>
<tr><td><code id="network_+3A_x">x</code></td>
<td>
<p>A data.frame contained only the input attributes.</p>
</td></tr>
<tr><td><code id="network_+3A_y">y</code></td>
<td>
<p>A factor response vector with one label for each row/component of x.</p>
</td></tr>
<tr><td><code id="network_+3A_measures">measures</code></td>
<td>
<p>A list of measures names or <code>"all"</code> to include all them.</p>
</td></tr>
<tr><td><code id="network_+3A_eps">eps</code></td>
<td>
<p>The percentage of nodes in the graph to be connected.</p>
</td></tr>
<tr><td><code id="network_+3A_summary">summary</code></td>
<td>
<p>A list of summarization functions or empty for all values. See
<a href="#topic+summarization">summarization</a> method to more information. (Default: 
<code>c("mean", "sd")</code>)</p>
</td></tr>
<tr><td><code id="network_+3A_formula">formula</code></td>
<td>
<p>A formula to define the class column.</p>
</td></tr>
<tr><td><code id="network_+3A_data">data</code></td>
<td>
<p>A data.frame dataset contained the input attributes and class.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The following measures are allowed for this method:
</p>

<dl>
<dt>&quot;Density&quot;</dt><dd><p>Average Density of the network (Density) represents the 
number of edges in the graph, divided by the maximum number of edges 
between pairs of data points.</p>
</dd>
<dt>&quot;ClsCoef&quot;</dt><dd><p>Clustering coefficient (ClsCoef) averages the clustering 
tendency of the vertexes by the ratio of existent edges between its 
neighbors and the total number of edges that could possibly exist 
between them.</p>
</dd>
<dt>&quot;Hubs&quot;</dt><dd><p>Hubs score (Hubs) is given by the number of connections it  
has to other nodes, weighted by the number of connections these 
neighbors have.</p>
</dd>
</dl>



<h3>Value</h3>

<p>A list named by the requested network measure.
</p>


<h3>References</h3>

<p>Gleison Morais and Ronaldo C Prati. (2013). Complex Network Measures for 
Data Set Characterization. In 2nd Brazilian Conference on Intelligent 
Systems (BRACIS). 12&ndash;18.
</p>
<p>Luis P F Garcia, Andre C P L F de Carvalho and Ana C Lorena. (2015). Effect
of label noise in the complexity of classification problems. 
Neurocomputing 160, 108&ndash;119.
</p>


<h3>See Also</h3>

<p>Other complexity-measures: <code><a href="#topic+balance">balance</a></code>,
<code><a href="#topic+correlation">correlation</a></code>, <code><a href="#topic+dimensionality">dimensionality</a></code>,
<code><a href="#topic+linearity">linearity</a></code>, <code><a href="#topic+neighborhood">neighborhood</a></code>,
<code><a href="#topic+overlapping">overlapping</a></code>, <code><a href="#topic+smoothness">smoothness</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Extract all network measures for classification task
data(iris)
network(Species ~ ., iris)
</code></pre>

<hr>
<h2 id='overlapping'>Measures of overlapping</h2><span id='topic+overlapping'></span><span id='topic+overlapping.default'></span><span id='topic+overlapping.formula'></span>

<h3>Description</h3>

<p>Classification task. The overlapping measures evaluate how informative the 
available features are to separate the classes. If there is at least one very
discriminative feature in the dataset, the problem can be considered simpler 
than if there is no such an attribute.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>overlapping(...)

## Default S3 method:
overlapping(x, y, measures = "all",
  summary = c("mean", "sd"), ...)

## S3 method for class 'formula'
overlapping(formula, data, measures = "all",
  summary = c("mean", "sd"), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="overlapping_+3A_...">...</code></td>
<td>
<p>Not used.</p>
</td></tr>
<tr><td><code id="overlapping_+3A_x">x</code></td>
<td>
<p>A data.frame contained only the input attributes.</p>
</td></tr>
<tr><td><code id="overlapping_+3A_y">y</code></td>
<td>
<p>A factor response vector with one label for each row/component of x.</p>
</td></tr>
<tr><td><code id="overlapping_+3A_measures">measures</code></td>
<td>
<p>A list of measures names or <code>"all"</code> to include all them.</p>
</td></tr>
<tr><td><code id="overlapping_+3A_summary">summary</code></td>
<td>
<p>A list of summarization functions or empty for all values. See
<a href="#topic+summarization">summarization</a> method to more information. (Default: 
<code>c("mean", "sd")</code>)</p>
</td></tr>
<tr><td><code id="overlapping_+3A_formula">formula</code></td>
<td>
<p>A formula to define the class column.</p>
</td></tr>
<tr><td><code id="overlapping_+3A_data">data</code></td>
<td>
<p>A data.frame dataset contained the input attributes and class.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The following measures are allowed for this method:
</p>

<dl>
<dt>&quot;F1&quot;</dt><dd><p>Maximum Fisher's Discriminant Ratio (F1) measures the overlap 
between the values of the features and takes the value of the largest 
discriminant ratio among all the available features.</p>
</dd>
<dt>&quot;F1v&quot;</dt><dd><p>Directional-vector maximum Fisher's discriminant ratio (F1v)
complements F1 by searching for a vector able to separate two classes 
after the training examples have been projected into it.</p>
</dd>
<dt>&quot;F2&quot;</dt><dd><p>Volume of the overlapping region (F2) computes the overlap of 
the distributions of the features values within the classes. F2 can be 
determined by finding, for each feature its minimum and maximum values 
in the classes.</p>
</dd>
<dt>&quot;F3&quot;</dt><dd><p>The maximum individual feature efficiency (F3) of each 
feature is given by the ratio between the number of examples that are 
not in the overlapping region of two classes and the total number of 
examples. This measure returns the maximum of the values found among 
the input features.</p>
</dd>
<dt>&quot;F4&quot;</dt><dd><p>Collective feature efficiency (F4) get an overview on how 
various features may work together in data separation. First the most 
discriminative feature according to F3 is selected and all examples that
can be separated by this feature are removed from the dataset. The 
previous step is repeated on the remaining dataset until all the 
features have been considered or no example remains. F4 returns the 
ratio of examples that have been discriminated.</p>
</dd>
</dl>



<h3>Value</h3>

<p>A list named by the requested overlapping measure.
</p>


<h3>References</h3>

<p>Albert Orriols-Puig, Nuria Macia and Tin K Ho. (2010). Documentation for the
data complexity library in C++. Technical Report. La Salle - Universitat
Ramon Llull.
</p>


<h3>See Also</h3>

<p>Other complexity-measures: <code><a href="#topic+balance">balance</a></code>,
<code><a href="#topic+correlation">correlation</a></code>, <code><a href="#topic+dimensionality">dimensionality</a></code>,
<code><a href="#topic+linearity">linearity</a></code>, <code><a href="#topic+neighborhood">neighborhood</a></code>,
<code><a href="#topic+network">network</a></code>, <code><a href="#topic+smoothness">smoothness</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Extract all overlapping measures for classification task
data(iris)
overlapping(Species ~ ., iris)
</code></pre>

<hr>
<h2 id='smoothness'>Measures of smoothness</h2><span id='topic+smoothness'></span><span id='topic+smoothness.default'></span><span id='topic+smoothness.formula'></span>

<h3>Description</h3>

<p>Regression task. In regression problems, the smoother the function to be 
fitted to the data, the simpler it shall be. Larger variations in the inputs
and/or outputs, on the other hand, usually indicate the existence of more 
intricate relationships between them.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>smoothness(...)

## Default S3 method:
smoothness(x, y, measures = "all",
  summary = c("mean", "sd"), ...)

## S3 method for class 'formula'
smoothness(formula, data, measures = "all",
  summary = c("mean", "sd"), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="smoothness_+3A_...">...</code></td>
<td>
<p>Not used.</p>
</td></tr>
<tr><td><code id="smoothness_+3A_x">x</code></td>
<td>
<p>A data.frame contained only the input attributes.</p>
</td></tr>
<tr><td><code id="smoothness_+3A_y">y</code></td>
<td>
<p>A response vector with one value for each row/component of x.</p>
</td></tr>
<tr><td><code id="smoothness_+3A_measures">measures</code></td>
<td>
<p>A list of measures names or <code>"all"</code> to include all them.</p>
</td></tr>
<tr><td><code id="smoothness_+3A_summary">summary</code></td>
<td>
<p>A list of summarization functions or empty for all values. See
<a href="#topic+summarization">summarization</a> method to more information. (Default: 
<code>c("mean", "sd")</code>)</p>
</td></tr>
<tr><td><code id="smoothness_+3A_formula">formula</code></td>
<td>
<p>A formula to define the output column.</p>
</td></tr>
<tr><td><code id="smoothness_+3A_data">data</code></td>
<td>
<p>A data.frame dataset contained the input and output attributes.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The following measures are allowed for this method:
</p>

<dl>
<dt>&quot;S1&quot;</dt><dd><p>Output distribution (S1) monitors whether the examples 
joined in the MST have similar output values. Lower values indicate 
simpler problems, where the outputs of similar examples in the input 
space are also next to each other.</p>
</dd>
<dt>&quot;S2&quot;</dt><dd><p>Input distribution (S2) measure how similar in the input space
are data items with similar outputs based on distance.</p>
</dd>
<dt>&quot;S3&quot;</dt><dd><p>Error of a nearest neighbor regressor (S3) calculates the mean
squared error of a 1-nearest neighbor regressor  using leave-one-out.</p>
</dd>
<dt>&quot;S4&quot;</dt><dd><p>Non-linearity of nearest neighbor regressor (S4) calculates 
the mean squared error of a 1-nearest neighbor regressor to the new 
randomly interpolated points.</p>
</dd>
</dl>



<h3>Value</h3>

<p>A list named by the requested smoothness measure.
</p>


<h3>References</h3>

<p>Ana C Lorena and Aron I Maciel and Pericles B C Miranda and Ivan G Costa and
Ricardo B C Prudencio. (2018). Data complexity meta-features for 
regression problems. Machine Learning, 107, 1, 209&ndash;246.
</p>


<h3>See Also</h3>

<p>Other complexity-measures: <code><a href="#topic+balance">balance</a></code>,
<code><a href="#topic+correlation">correlation</a></code>, <code><a href="#topic+dimensionality">dimensionality</a></code>,
<code><a href="#topic+linearity">linearity</a></code>, <code><a href="#topic+neighborhood">neighborhood</a></code>,
<code><a href="#topic+network">network</a></code>, <code><a href="#topic+overlapping">overlapping</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Extract all smoothness measures for regression task
data(cars)
smoothness(speed ~ ., cars)
</code></pre>

<hr>
<h2 id='summarization'>Post processing complexity measures</h2><span id='topic+summarization'></span>

<h3>Description</h3>

<p>Post-processing alternatives to deal with multiples values. This method is 
used by the complexity measures to summarize the obtained values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>summarization(measure, summary = c("mean", "sd"), multiple = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summarization_+3A_measure">measure</code></td>
<td>
<p>A list with the complexity measures values.</p>
</td></tr>
<tr><td><code id="summarization_+3A_summary">summary</code></td>
<td>
<p>The functions to post processing the data. See the details
to more information. Default: <code>c("mean", "sd")</code></p>
</td></tr>
<tr><td><code id="summarization_+3A_multiple">multiple</code></td>
<td>
<p>A logical value defining if the measure should return
multiple values. (Default: <code>TRUE</code>)</p>
</td></tr>
<tr><td><code id="summarization_+3A_...">...</code></td>
<td>
<p>Extra values used to the functions of summarization.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The post processing functions are used to summarize the complexity measures.
They are organized into three groups: return, descriptive statistic and 
distribution. Currently, the hypothesis testing post processing are not 
supported.
</p>
<p>In practice, there are no difference among the types, so that more than one
type and functions can be combined. Usually, these function are used to
summarize a set of values for each complexity measures. For instance, a 
measure computed for each attribute can be summarized using the 
<code>"mean"</code> and/or <code>"sd"</code>.
</p>
<p>In addition to the native functions available in R, the following functions
can be used:
</p>

<dl>
<dt>&quot;histogram&quot;</dt><dd><p>Computes a histogram of the given data value. The extra
parameters '<code>bins</code>' can be used to define the number of values to
be returned. The parameters '<code>max</code>' and '<code>min</code>' are used to
define the range of the data. The default value for these parameters
are respectively <code>10, min(x)</code> and <code>max(x)</code>.</p>
</dd>
<dt>&quot;kurtosis&quot;</dt><dd><p>See <code><a href="e1071.html#topic+kurtosis">kurtosis</a></code></p>
</dd>
<dt>&quot;max&quot;</dt><dd><p>See <code><a href="base.html#topic+max">max</a></code></p>
</dd>
<dt>&quot;mean&quot;</dt><dd><p>See <code><a href="base.html#topic+mean">mean</a></code></p>
</dd>
<dt>&quot;median&quot;</dt><dd><p>See <code><a href="stats.html#topic+median">median</a></code></p>
</dd>
<dt>&quot;min&quot;</dt><dd><p>See <code><a href="base.html#topic+min">min</a></code></p>
</dd>
<dt>&quot;quantiles&quot;</dt><dd><p>See <code><a href="stats.html#topic+quantile">quantile</a></code></p>
</dd>
<dt>&quot;sd&quot;</dt><dd><p>See <code><a href="stats.html#topic+sd">sd</a></code></p>
</dd>
<dt>&quot;skewness&quot;</dt><dd><p>See <code><a href="e1071.html#topic+skewness">skewness</a></code></p>
</dd>
<dt>&quot;var&quot;</dt><dd><p>See <code><a href="stats.html#topic+var">var</a></code></p>
</dd>
<dt>&quot;return&quot;</dt><dd><p>Returns the original value(s) of the complexity measure.</p>
</dd>
</dl>

<p>These functions are not restrictive, thus another functions can be applied
as post-processing summarization function.
</p>


<h3>Value</h3>

<p>A list with the post-processed complexity measures.
</p>


<h3>References</h3>

<p>Albert Orriols-Puig, Nuria Macia and Tin K Ho. (2010). Documentation for the
data complexity library in C++. Technical Report. La Salle - Universitat 
Ramon Llull.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>summarization(runif(15))
summarization(runif(15), c("min", "max"))
summarization(runif(15), c("quantiles", "skewness"))
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
