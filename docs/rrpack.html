<!DOCTYPE html><html><head><title>Help for package rrpack</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {rrpack}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#cv.mrrr'><p>Mixed-response reduced-rank regression with rank selected by</p>
cross validation</a></li>
<li><a href='#cv.rrr'><p>Reduced-rank regression with rank selected by cross validation</p></a></li>
<li><a href='#cv.sofar'><p>Sparse orthognal factor regression tuned by cross validation</p></a></li>
<li><a href='#cv.srrr'><p>Row-sparse reduced-rank regression tuned by cross validation</p></a></li>
<li><a href='#mrrr'><p>Generalized or mixed-response reduced-rank regression</p></a></li>
<li><a href='#plot'><p>Scatter Plot</p></a></li>
<li><a href='#r4'><p>Robust reduced-rank regression</p></a></li>
<li><a href='#rrpack-coef'><p>Estimated coefficients</p></a></li>
<li><a href='#rrr'><p>Multivariate reduced-rank linear regression</p></a></li>
<li><a href='#rrr.cookD'><p>Cook's distance in reduced-rank regression for model diagnostics</p></a></li>
<li><a href='#rrr.fit'><p>Fitting reduced-rank regression with a specific rank</p></a></li>
<li><a href='#rrr.leverage'><p>Leverage scores and Cook's distance in reduced-rank regression</p>
for model diagnostics</a></li>
<li><a href='#rrr.sim1'><p>Simulation model 1</p></a></li>
<li><a href='#rrr.sim2'><p>Simulation model 2</p></a></li>
<li><a href='#rrr.sim3'><p>Simulation model 3</p></a></li>
<li><a href='#rrr.sim4'><p>Simulation model 4</p></a></li>
<li><a href='#rrr.sim5'><p>Simulation model 5</p></a></li>
<li><a href='#rrs.fit'><p>Fitting reduced-rank ridge regression with given rank and shrinkage penalty</p></a></li>
<li><a href='#rssvd'><p>Reduced-rank regression with a sparse singular value decomposition</p></a></li>
<li><a href='#sofar'><p>Sparse orthogonal factor regression</p></a></li>
<li><a href='#srrr'><p>Row-sparse reduced-eank regresssion</p></a></li>
<li><a href='#summary'><p>Summarize rrpack Objects</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Title:</td>
<td>Reduced-Rank Regression</td>
</tr>
<tr>
<td>Version:</td>
<td>0.1-13</td>
</tr>
<tr>
<td>Description:</td>
<td>Multivariate regression methodologies including
    classical reduced-rank regression (RRR)
    studied by Anderson (1951) &lt;<a href="https://doi.org/10.1214%2Faoms%2F1177729580">doi:10.1214/aoms/1177729580</a>&gt; and
    Reinsel and Velu (1998) &lt;<a href="https://doi.org/10.1007%2F978-1-4757-2853-8">doi:10.1007/978-1-4757-2853-8</a>&gt;,
    reduced-rank regression via adaptive nuclear norm penalization
    proposed by Chen et al. (2013) &lt;<a href="https://doi.org/10.1093%2Fbiomet%2Fast036">doi:10.1093/biomet/ast036</a>&gt; and
    Mukherjee et al. (2015) &lt;<a href="https://doi.org/10.1093%2Fbiomet%2Fasx080">doi:10.1093/biomet/asx080</a>&gt;,
    robust reduced-rank regression (R4) proposed by
    She and Chen (2017) &lt;<a href="https://doi.org/10.1093%2Fbiomet%2Fasx032">doi:10.1093/biomet/asx032</a>&gt;,
    generalized/mixed-response reduced-rank regression (mRRR) proposed by
    Luo et al. (2018) &lt;<a href="https://doi.org/10.1016%2Fj.jmva.2018.04.011">doi:10.1016/j.jmva.2018.04.011</a>&gt;,
    row-sparse reduced-rank regression (SRRR) proposed by
    Chen and Huang (2012) &lt;<a href="https://doi.org/10.1080%2F01621459.2012.734178">doi:10.1080/01621459.2012.734178</a>&gt;,
    reduced-rank regression with a sparse singular value decomposition (RSSVD)
    proposed by Chen et al. (2012) &lt;<a href="https://doi.org/10.1111%2Fj.1467-9868.2011.01002.x">doi:10.1111/j.1467-9868.2011.01002.x</a>&gt;
    and sparse and orthogonal factor regression (SOFAR) proposed by
    Uematsu et al. (2019) &lt;<a href="https://doi.org/10.1109%2FTIT.2019.2909889">doi:10.1109/TIT.2019.2909889</a>&gt;.</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.4.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>ggplot2, glmnet, MASS, Rcpp (&ge; 0.12.0)</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp, RcppArmadillo</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL (&ge; 3)</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.0</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2022-06-15 15:49:54 UTC; wenjie</td>
</tr>
<tr>
<td>Author:</td>
<td>Kun Chen <a href="https://orcid.org/0000-0003-3579-5467"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut,
    cre],
  Wenjie Wang <a href="https://orcid.org/0000-0003-0363-3180"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut],
  Jun Yan <a href="https://orcid.org/0000-0003-4401-7296"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [ctb]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Kun Chen &lt;kun.chen@uconn.edu&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2022-06-16 06:40:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='cv.mrrr'>Mixed-response reduced-rank regression with rank selected by
cross validation</h2><span id='topic+cv.mrrr'></span>

<h3>Description</h3>

<p>Mixed-response reduced-rank regression with rank selected by
cross validation
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cv.mrrr(
  Y,
  X,
  is.pca = NULL,
  offset = NULL,
  ctrl.id = c(),
  family = list(gaussian(), binomial(), poisson()),
  familygroup = NULL,
  maxrank = min(ncol(Y), ncol(X)),
  penstr = list(),
  init = list(),
  control = list(),
  nfold = 5,
  foldid = NULL,
  nlam = 20,
  warm = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cv.mrrr_+3A_y">Y</code></td>
<td>
<p>response matrix</p>
</td></tr>
<tr><td><code id="cv.mrrr_+3A_x">X</code></td>
<td>
<p>covariate matrix</p>
</td></tr>
<tr><td><code id="cv.mrrr_+3A_is.pca">is.pca</code></td>
<td>
<p>If TRUE, mixed principal component analysis with X=I</p>
</td></tr>
<tr><td><code id="cv.mrrr_+3A_offset">offset</code></td>
<td>
<p>matrix of the same dimension as Y for offset</p>
</td></tr>
<tr><td><code id="cv.mrrr_+3A_ctrl.id">ctrl.id</code></td>
<td>
<p>indices of unpenalized predictors</p>
</td></tr>
<tr><td><code id="cv.mrrr_+3A_family">family</code></td>
<td>
<p>a list of family functions as used in <code>glm</code></p>
</td></tr>
<tr><td><code id="cv.mrrr_+3A_familygroup">familygroup</code></td>
<td>
<p>a list of family indices of the responses</p>
</td></tr>
<tr><td><code id="cv.mrrr_+3A_maxrank">maxrank</code></td>
<td>
<p>integer giving the maximum rank allowed.</p>
</td></tr>
<tr><td><code id="cv.mrrr_+3A_penstr">penstr</code></td>
<td>
<p>a list of penalty structure of SVD.</p>
</td></tr>
<tr><td><code id="cv.mrrr_+3A_init">init</code></td>
<td>
<p>a list of initial values of kappaC0, kappaS0, C0, and S0</p>
</td></tr>
<tr><td><code id="cv.mrrr_+3A_control">control</code></td>
<td>
<p>a list of controling parameters for the fitting</p>
</td></tr>
<tr><td><code id="cv.mrrr_+3A_nfold">nfold</code></td>
<td>
<p>number of folds in cross validation</p>
</td></tr>
<tr><td><code id="cv.mrrr_+3A_foldid">foldid</code></td>
<td>
<p>to specify the folds if desired</p>
</td></tr>
<tr><td><code id="cv.mrrr_+3A_nlam">nlam</code></td>
<td>
<p>number of tuning parameters; not effective when using rank
constrained estimation</p>
</td></tr>
<tr><td><code id="cv.mrrr_+3A_warm">warm</code></td>
<td>
<p>if TRUE, use warm start in fitting the solution paths</p>
</td></tr>
</table>


<h3>Value</h3>

<p>S3 <code>mrrr</code> object, a list containing </p>
<table>
<tr><td><code>fit</code></td>
<td>
<p>the output from
the selected model</p>
</td></tr> <tr><td><code>dev</code></td>
<td>
<p>deviance measures</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(rrpack)
simdata &lt;- rrr.sim3(n = 100, p = 30, q.mix = c(5, 20, 5),
                    nrank = 2, mis.prop = 0.2)
Y &lt;- simdata$Y
Y_mis &lt;- simdata$Y.mis
X &lt;- simdata$X
X0 &lt;- cbind(1,X)
C &lt;- simdata$C
family &lt;- simdata$family
familygroup &lt;- simdata$familygroup
svdX0d1 &lt;- svd(X0)$d[1]
init1 = list(kappaC0 = svdX0d1 * 5)
offset = NULL
control = list(epsilon = 1e-4, sv.tol = 1e-2, maxit = 2000,
               trace = FALSE, gammaC0 = 1.1, plot.cv = TRUE,
               conv.obj = TRUE)
fit.cv.mrrr &lt;- cv.mrrr(Y_mis, X, family = family,
                       familygroup = familygroup,
                       maxrank = 20,
                       penstr = list(penaltySVD = "rankCon",
                                     lambdaSVD = c(1 : 6)),
                       control = control, init = init1,
                       nfold = 10, nlam = 50)
summary(fit.cv.mrrr)
coef(fit.cv.mrrr)
fit.mrrr &lt;- fit.cv.mrrr$fit

## plot(svd(fit.mrrr$coef[- 1,])$d)
plot(C ~ fit.mrrr$coef[- 1, ])
abline(a = 0, b = 1)

## End(Not run)
</code></pre>

<hr>
<h2 id='cv.rrr'>Reduced-rank regression with rank selected by cross validation</h2><span id='topic+cv.rrr'></span>

<h3>Description</h3>

<p>Reduced-rank regression with rank selected by cross validation
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cv.rrr(
  Y,
  X,
  nfold = 10,
  maxrank = min(dim(Y), dim(X)),
  norder = NULL,
  coefSVD = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cv.rrr_+3A_y">Y</code></td>
<td>
<p>response matrix</p>
</td></tr>
<tr><td><code id="cv.rrr_+3A_x">X</code></td>
<td>
<p>covariate matrix</p>
</td></tr>
<tr><td><code id="cv.rrr_+3A_nfold">nfold</code></td>
<td>
<p>number of folds</p>
</td></tr>
<tr><td><code id="cv.rrr_+3A_maxrank">maxrank</code></td>
<td>
<p>maximum rank allowed</p>
</td></tr>
<tr><td><code id="cv.rrr_+3A_norder">norder</code></td>
<td>
<p>for constructing the folds</p>
</td></tr>
<tr><td><code id="cv.rrr_+3A_coefsvd">coefSVD</code></td>
<td>
<p>If TRUE, svd of the coefficient is retuned</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list containing rr estimates from cross validation
</p>


<h3>References</h3>

<p>Chen, K., Dong, H. and Chan, K.-S. (2013) Reduced rank regression via
adaptive nuclear norm penalization. <em>Biometrika</em>, 100, 901&ndash;920.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(rrpack)
p &lt;- 50; q &lt;- 50; n &lt;- 100; nrank &lt;- 3
mydata &lt;- rrr.sim1(n, p, q, nrank, s2n = 1, sigma = NULL,
                   rho_X = 0.5, rho_E = 0.3)
rfit_cv &lt;- with(mydata, cv.rrr(Y, X, nfold = 10, maxrank = 10))
summary(rfit_cv)
coef(rfit_cv)
</code></pre>

<hr>
<h2 id='cv.sofar'>Sparse orthognal factor regression tuned by cross validation</h2><span id='topic+cv.sofar'></span>

<h3>Description</h3>

<p>Sparse orthognal factor regression tuned by cross validation
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cv.sofar(
  Y,
  X,
  nrank = 1,
  su = NULL,
  sv = NULL,
  nfold = 5,
  norder = NULL,
  modstr = list(),
  control = list(),
  screening = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cv.sofar_+3A_y">Y</code></td>
<td>
<p>response matrix</p>
</td></tr>
<tr><td><code id="cv.sofar_+3A_x">X</code></td>
<td>
<p>covariate matrix</p>
</td></tr>
<tr><td><code id="cv.sofar_+3A_nrank">nrank</code></td>
<td>
<p>an integer specifying the desired rank/number of factors</p>
</td></tr>
<tr><td><code id="cv.sofar_+3A_su">su</code></td>
<td>
<p>a scaling vector for U such that <code class="reqn">U^{T}U = diag(s_{u})</code></p>
</td></tr>
<tr><td><code id="cv.sofar_+3A_sv">sv</code></td>
<td>
<p>a scaling vector for V such that <code class="reqn">V^{T}V = diag(s_{v})</code></p>
</td></tr>
<tr><td><code id="cv.sofar_+3A_nfold">nfold</code></td>
<td>
<p>number of fold; used for cv.sofar</p>
</td></tr>
<tr><td><code id="cv.sofar_+3A_norder">norder</code></td>
<td>
<p>observation orders to constrct data folds; used for cv.sofar</p>
</td></tr>
<tr><td><code id="cv.sofar_+3A_modstr">modstr</code></td>
<td>
<p>a list of internal model parameters controlling the model
fitting</p>
</td></tr>
<tr><td><code id="cv.sofar_+3A_control">control</code></td>
<td>
<p>a list of internal computation parameters controlling
optimization</p>
</td></tr>
<tr><td><code id="cv.sofar_+3A_screening">screening</code></td>
<td>
<p>If TRUE, marginal screening via lasso is performed before
sofar fitting.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The model parameters can be specified through argument <code>modstr</code>.
The available elements include
</p>

<ul>
<li><p>mu: parameter in the augmented Lagrangian function.
</p>
</li>
<li><p>mugamma: increament of mu along iterations to speed up
computation.
</p>
</li>
<li><p>WA: weight matrix for A.
</p>
</li>
<li><p>WB: weight matrix for B.
</p>
</li>
<li><p>Wd: weight matrix for d.
</p>
</li>
<li><p>wgamma: power parameter in constructing adaptive weights.
</p>
</li></ul>

<p>The model fitting can be controled through argument <code>control</code>.
The avilable elements include
</p>

<ul>
<li><p>nlam: number of lambda triplets to be used.
</p>
</li>
<li><p>lam.min.factor: set the smallest lambda triplets as a fraction of
the estimation lambda.max triplets.
</p>
</li>
<li><p>lam.max.factor: set the largest lambda triplets as a multiple of
the estimation lambda.max triplets.
</p>
</li>
<li><p>lam.AB.factor: set the relative penalty level between A/B and D.
</p>
</li>
<li><p>penA,penB,penD: if TRUE, penalty is applied.
</p>
</li>
<li><p>lamA: sequence of tuning parameters for A.
</p>
</li>
<li><p>lamB: sequence of tuning parameters for B.
</p>
</li>
<li><p>lamD: sequence of tuning parameters for d.
</p>
</li>
<li><p>methodA: penalty for penalizing A.
</p>
</li>
<li><p>methodB: penalty for penalizing B.
</p>
</li>
<li><p>epsilon: convergence tolerance.
</p>
</li>
<li><p>maxit: maximum number of iterations.
</p>
</li>
<li><p>innerEpsilon: convergence tolerance for inner subroutines.
</p>
</li>
<li><p>innerMaxit: maximum number of iterations for inner subroutines.
</p>
</li>
<li><p>sv.tol: tolerance for singular values.
</p>
</li></ul>


<hr>
<h2 id='cv.srrr'>Row-sparse reduced-rank regression tuned by cross validation</h2><span id='topic+cv.srrr'></span>

<h3>Description</h3>

<p>Row-sparse reduced-rank regression tuned by cross validation
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cv.srrr(
  Y,
  X,
  nrank = 1,
  method = c("glasso", "adglasso"),
  nfold = 5,
  norder = NULL,
  A0 = NULL,
  V0 = NULL,
  modstr = list(),
  control = list()
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cv.srrr_+3A_y">Y</code></td>
<td>
<p>response matrix</p>
</td></tr>
<tr><td><code id="cv.srrr_+3A_x">X</code></td>
<td>
<p>covariate matrix</p>
</td></tr>
<tr><td><code id="cv.srrr_+3A_nrank">nrank</code></td>
<td>
<p>prespecified rank</p>
</td></tr>
<tr><td><code id="cv.srrr_+3A_method">method</code></td>
<td>
<p>group lasso or adaptive group lasso</p>
</td></tr>
<tr><td><code id="cv.srrr_+3A_nfold">nfold</code></td>
<td>
<p>fold number</p>
</td></tr>
<tr><td><code id="cv.srrr_+3A_norder">norder</code></td>
<td>
<p>for constructing the folds</p>
</td></tr>
<tr><td><code id="cv.srrr_+3A_a0">A0</code></td>
<td>
<p>initial value</p>
</td></tr>
<tr><td><code id="cv.srrr_+3A_v0">V0</code></td>
<td>
<p>initial value</p>
</td></tr>
<tr><td><code id="cv.srrr_+3A_modstr">modstr</code></td>
<td>
<p>a list of model parameters controlling the model
fitting</p>
</td></tr>
<tr><td><code id="cv.srrr_+3A_control">control</code></td>
<td>
<p>a list of parameters for controlling the fitting process</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Model parameters controlling the model fitting can be specified through
argument <code>modstr</code>. The available elements include
</p>

<ul>
<li><p>lamA: tuning parameter sequence.
</p>
</li>
<li><p>nlam: number of tuning parameters; no effect if <code>lamA</code> is
specified.
</p>
</li>
<li><p>minLambda: minimum lambda value, no effect if <code>lamA</code> is
specified.
</p>
</li>
<li><p>maxLambda: maxmum lambda value, no effect if lamA is specified.
</p>
</li>
<li><p>WA: adaptive weights. If NULL, the weights are constructed from
RRR.
</p>
</li>
<li><p>wgamma: power parameter for constructing adaptive weights.
</p>
</li></ul>

<p>Similarly, the computational parameters controlling optimization can be
specified through argument <code>control</code>. The available elements include
</p>

<ul>
<li><p>epsilon: epsilonergence tolerance.
</p>
</li>
<li><p>maxit: maximum number of iterations.
</p>
</li>
<li><p>inner.eps: used in inner loop.
</p>
</li>
<li><p>inner.maxit: used in inner loop.
</p>
</li></ul>



<h3>Value</h3>

<p>A list of fitting results
</p>


<h3>References</h3>

<p>Chen, L. and Huang, J.Z. (2012) Sparse reduced-rank regression for
simultaneous dimension reduction and variable selection. <em>Journal of
the American Statistical Association</em>. 107:500, 1533&ndash;1545.
</p>

<hr>
<h2 id='mrrr'>Generalized or mixed-response reduced-rank regression</h2><span id='topic+mrrr'></span>

<h3>Description</h3>

<p>Peforms either rank constrained maximum likelihood estimation or
singular value penalized estimation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mrrr(
  Y,
  X,
  is.pca = NULL,
  offset = NULL,
  ctrl.id = c(),
  family = list(gaussian(), binomial()),
  familygroup = NULL,
  maxrank = min(ncol(Y), ncol(X)),
  penstr = list(),
  init = list(),
  control = list()
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mrrr_+3A_y">Y</code></td>
<td>
<p>response matrix</p>
</td></tr>
<tr><td><code id="mrrr_+3A_x">X</code></td>
<td>
<p>covariate matrix</p>
</td></tr>
<tr><td><code id="mrrr_+3A_is.pca">is.pca</code></td>
<td>
<p>If TRUE, mixed principal component analysis with X=I</p>
</td></tr>
<tr><td><code id="mrrr_+3A_offset">offset</code></td>
<td>
<p>matrix of the same dimension as Y for offset</p>
</td></tr>
<tr><td><code id="mrrr_+3A_ctrl.id">ctrl.id</code></td>
<td>
<p>indices of unpenalized predictors</p>
</td></tr>
<tr><td><code id="mrrr_+3A_family">family</code></td>
<td>
<p>a list of family functions as used in <code>glm</code></p>
</td></tr>
<tr><td><code id="mrrr_+3A_familygroup">familygroup</code></td>
<td>
<p>a list of family indices of the responses</p>
</td></tr>
<tr><td><code id="mrrr_+3A_maxrank">maxrank</code></td>
<td>
<p>integer giving the maximum rank allowed. Usually this can be
set to min(n,p,q)</p>
</td></tr>
<tr><td><code id="mrrr_+3A_penstr">penstr</code></td>
<td>
<p>a list of penalty structure of SVD, contains penstr$penaltySVD
is the penalty of SVD, penstr$lambdaSVD is the regularization parameter</p>
</td></tr>
<tr><td><code id="mrrr_+3A_init">init</code></td>
<td>
<p>a list of initial values of kappaC0, kappaS0, C0, and S0</p>
</td></tr>
<tr><td><code id="mrrr_+3A_control">control</code></td>
<td>
<p>a list of controling parameters for the fitting</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The model fitting process can be fine tuned through argument <code>control</code>.
The available elements for <code>control</code> include
</p>

<ul>
<li><p>epsilon: positive convergence tolerance epsilon; the
iterations converge when |new - old | / (old + 0.1) &lt; epsilon.
treated as zero.
</p>
</li>
<li><p>sv.tol: tolerance for singular values.
</p>
</li>
<li><p>maxit: integer giving the maximal number of iterations.
</p>
</li>
<li><p>trace:logical indicating if tracing the objective is needed.
</p>
</li>
<li><p>conv.obj:if TRUE, track objective function.
</p>
</li>
<li><p>equal.phi:if TRUE, use a single dispersion parameter for Gaussian
responses.
</p>
</li>
<li><p>plot.obj:if TRUE, plot obj values along iterations; for checking
only
</p>
</li>
<li><p>plot.cv:if TRUE, plot cross validation error.
</p>
</li>
<li><p>gammaC0:adaptive scaling to speed up computation.
</p>
</li></ul>

<p>Similarly, the available elements for arguments <code>penstr</code> specifying
penalty structure of SVD include
</p>

<ul>
<li><p>penaltySVD: penalty for reducing rank
</p>
</li>
<li><p>lambdaSVD: tuning parameter. For penaltySVD = rankCon, this is the
specified rank.
</p>
</li></ul>



<h3>Value</h3>

<p>S3 <code>mrrr</code> object, a list containing
</p>
<table>
<tr><td><code>obj</code></td>
<td>
<p>the objective function tracking</p>
</td></tr>
<tr><td><code>converged</code></td>
<td>
<p>TRUE/FALSE for convergence</p>
</td></tr>
<tr><td><code>coef</code></td>
<td>
<p>the estimated coefficient matrix</p>
</td></tr>
<tr><td><code>outlier</code></td>
<td>
<p>the estimated outlier matrix</p>
</td></tr>
<tr><td><code>nrank</code></td>
<td>
<p>the rank of the fitted model</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>library(rrpack)
simdata &lt;- rrr.sim3(n = 100, p = 30, q.mix = c(5, 20, 5),
                    nrank = 2, mis.prop = 0.2)
Y &lt;- simdata$Y
Y_mis &lt;- simdata$Y.mis
X &lt;- simdata$X
X0 &lt;- cbind(1, X)
C &lt;- simdata$C
family &lt;- simdata$family
familygroup &lt;- simdata$familygroup
svdX0d1 &lt;- svd(X0)$d[1]
init1 = list(kappaC0 = svdX0d1 * 5)
offset = NULL
control = list(epsilon = 1e-4, sv.tol = 1e-2, maxit = 2000,
               trace = FALSE, gammaC0 = 1.1, plot.cv = TRUE,
               conv.obj = TRUE)
fit.mrrr &lt;- mrrr(Y_mis, X, family = family, familygroup = familygroup,
                 penstr = list(penaltySVD = "rankCon", lambdaSVD = 2),
                 control = control, init = init1)
summary(fit.mrrr)
coef(fit.mrrr)
par(mfrow = c(1, 2))
plot(fit.mrrr$obj)
plot(C ~ fit.mrrr$coef[- 1 ,])
abline(a = 0, b = 1)
</code></pre>

<hr>
<h2 id='plot'>Scatter Plot</h2><span id='topic+plot'></span><span id='topic+plot.rrr'></span><span id='topic+plot.sofar'></span><span id='topic+plot.cv.sofar'></span><span id='topic+plot.srrr'></span><span id='topic+plot.cv.srrr'></span><span id='topic+plot.rssvd'></span>

<h3>Description</h3>

<p>S3 methods generating scatter plot for some objects generated by
<code>rrpack</code> using <code>ggplot2</code>. An <code>ggplot2</code> object is returned so
that users are allowed to easily further customize the plot.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'rrr'
plot(
  x,
  y = NULL,
  layer = 1L,
  xlab = paste("latent predictor ", layer, sep = ""),
  ylab = paste("latent response ", layer, sep = ""),
  ...
)

## S3 method for class 'sofar'
plot(
  x,
  y = NULL,
  layer = 1L,
  xlab = paste("latent predictor ", layer, sep = ""),
  ylab = paste("latent response ", layer, sep = ""),
  ...
)

## S3 method for class 'cv.sofar'
plot(
  x,
  y = NULL,
  layer = 1L,
  xlab = paste("latent predictor ", layer, sep = ""),
  ylab = paste("latent response ", layer, sep = ""),
  ...
)

## S3 method for class 'srrr'
plot(
  x,
  y = NULL,
  layer = 1L,
  xlab = paste("latent predictor ", layer, sep = ""),
  ylab = paste("latent response ", layer, sep = ""),
  ...
)

## S3 method for class 'cv.srrr'
plot(
  x,
  y = NULL,
  layer = 1L,
  xlab = paste("latent predictor ", layer, sep = ""),
  ylab = paste("latent response ", layer, sep = ""),
  ...
)

## S3 method for class 'rssvd'
plot(
  x,
  y = NULL,
  layer = 1L,
  xlab = paste("latent predictor ", layer, sep = ""),
  ylab = paste("latent response ", layer, sep = ""),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot_+3A_x">x</code></td>
<td>
<p>Some object generated by <code>rrpack</code>.</p>
</td></tr>
<tr><td><code id="plot_+3A_y">y</code></td>
<td>
<p>NULL. Do not need to specify.</p>
</td></tr>
<tr><td><code id="plot_+3A_layer">layer</code></td>
<td>
<p>The unit-rank layer to plot; cannot be larger than the estimated rank</p>
</td></tr>
<tr><td><code id="plot_+3A_xlab">xlab</code></td>
<td>
<p>Label of X axis.</p>
</td></tr>
<tr><td><code id="plot_+3A_ylab">ylab</code></td>
<td>
<p>Label of Y axis.</p>
</td></tr>
<tr><td><code id="plot_+3A_...">...</code></td>
<td>
<p>Other argumnts for future usage.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>ggplot2 object.
</p>

<hr>
<h2 id='r4'>Robust reduced-rank regression</h2><span id='topic+r4'></span>

<h3>Description</h3>

<p>Perform robust reduced-rank regression.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>r4(
  Y,
  X,
  maxrank = min(dim(Y), dim(X)),
  method = c("rowl0", "rowl1", "entrywise"),
  Gamma = NULL,
  ic.type = c("AIC", "BIC", "PIC"),
  modstr = list(),
  control = list()
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="r4_+3A_y">Y</code></td>
<td>
<p>a matrix of response (n by q)</p>
</td></tr>
<tr><td><code id="r4_+3A_x">X</code></td>
<td>
<p>a matrix of covariate (n by p)</p>
</td></tr>
<tr><td><code id="r4_+3A_maxrank">maxrank</code></td>
<td>
<p>maximum rank for fitting</p>
</td></tr>
<tr><td><code id="r4_+3A_method">method</code></td>
<td>
<p>outlier detection method, either entrywise or rowwise</p>
</td></tr>
<tr><td><code id="r4_+3A_gamma">Gamma</code></td>
<td>
<p>weighting matrix in the loss function</p>
</td></tr>
<tr><td><code id="r4_+3A_ic.type">ic.type</code></td>
<td>
<p>information criterion, AIC, BIC or PIC</p>
</td></tr>
<tr><td><code id="r4_+3A_modstr">modstr</code></td>
<td>
<p>a list of model parameters controlling the model
fitting</p>
</td></tr>
<tr><td><code id="r4_+3A_control">control</code></td>
<td>
<p>a list of parameters for controlling the fitting process</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The model parameters can be controlled through argument <code>modstr</code>.
The available elements include
</p>

<ul>
<li><p>nlam: parameter in the augmented Lagrangian function.
</p>
</li>
<li><p>adaptive: if <code>TRUE</code>, use leverage values for adaptive
penalization.  The default value is <code>FALSE</code>.
</p>
</li>
<li><p>weights: user supplied weights for adaptive penalization.
</p>
</li>
<li><p>minlam: maximum proportion of outliers.
</p>
</li>
<li><p>maxlam: maximum proportion of good observations.
</p>
</li>
<li><p>delid: discarded observation indices for initial estimation.
</p>
</li></ul>

<p>The model fitting can be controlled through argument <code>control</code>.
The available elements include
</p>

<ul>
<li><p>epsilon: convergence tolerance.
</p>
</li>
<li><p>maxit: maximum number of iterations.
</p>
</li>
<li><p>qr.tol: tolerance for qr decomposition.
</p>
</li>
<li><p>tol: tolerance.
</p>
</li></ul>



<h3>Value</h3>

<p>a list consisting of
</p>
<table>
<tr><td><code>coef.path</code></td>
<td>
<p>solutuon path of regression coefficients</p>
</td></tr>
<tr><td><code>s.path</code></td>
<td>
<p>solutuon path of sparse mean shifts</p>
</td></tr>
<tr><td><code>s.norm.path</code></td>
<td>
<p>solutuon path of the norms of sparse mean shifts</p>
</td></tr>
<tr><td><code>ic.path</code></td>
<td>
<p>paths of information criteria</p>
</td></tr>
<tr><td><code>ic.smooth.path</code></td>
<td>
<p>smoothed paths of information criteria</p>
</td></tr>
<tr><td><code>lambda.path</code></td>
<td>
<p>paths of the tuning parameter</p>
</td></tr>
<tr><td><code>id.solution</code></td>
<td>
<p>ids of the selected solutions on the path</p>
</td></tr>
<tr><td><code>ic.best</code></td>
<td>
<p>lowest values of the information criteria</p>
</td></tr>
<tr><td><code>rank.best</code></td>
<td>
<p>rank values of selected solutions</p>
</td></tr>
<tr><td><code>coef</code></td>
<td>
<p>estimated regression coefficients</p>
</td></tr>
<tr><td><code>s</code></td>
<td>
<p>estimated sparse mean shifts</p>
</td></tr>
<tr><td><code>rank</code></td>
<td>
<p>rank estimate</p>
</td></tr>
</table>


<h3>References</h3>

<p>She, Y. and Chen, K. (2017) Robust reduced-rank regression.
<em>Biometrika</em>, 104 (3), 633&ndash;647.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(rrpack)
n &lt;- 100; p &lt;- 500; q &lt;- 50
xrank &lt;- 10; nrank &lt;- 3; rmax &lt;- min(n, p, q, xrank)
nlam &lt;- 100; gamma &lt;- 2
rho_E &lt;- 0.3
rho_X &lt;- 0.5
nlev &lt;- 0
vlev &lt;- 0
vout &lt;- NULL
vlevsd &lt;- NULL
nout &lt;- 0.1 * n
s2n &lt;- 1
voutsd &lt;- 2
simdata &lt;- rrr.sim5(n, p, q, nrank, rx = xrank, s2n = s2n,
                    rho_X = rho_X, rho_E = rho_E, nout = nout, vout = vout,
                    voutsd = voutsd,nlev = nlev,vlev=vlev,vlevsd=vlevsd)
Y &lt;- simdata$Y
X &lt;- simdata$X
fit &lt;- r4(Y, X, maxrank = rmax,
               method = "rowl0", ic.type= "PIC")
summary(fit)
coef(fit)
which(apply(fit$s,1,function(a)sum(a^2))!=0)

## End(Not run)
</code></pre>

<hr>
<h2 id='rrpack-coef'>Estimated coefficients</h2><span id='topic+rrpack-coef'></span><span id='topic+coef.mrrr'></span><span id='topic+coef.cv.mrrr'></span><span id='topic+coef.r4'></span><span id='topic+coef.rrr'></span><span id='topic+coef.rrr.fit'></span><span id='topic+coef.cv.rrr'></span><span id='topic+coef.srrr'></span><span id='topic+coef.sofar'></span><span id='topic+coef.rssvd'></span>

<h3>Description</h3>

<p>S3 methods extracting estimated coefficients for objects generated by
<code>rrpack</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'mrrr'
coef(object, ...)

## S3 method for class 'cv.mrrr'
coef(object, ...)

## S3 method for class 'r4'
coef(object, ...)

## S3 method for class 'rrr'
coef(object, ...)

## S3 method for class 'rrr.fit'
coef(object, ...)

## S3 method for class 'cv.rrr'
coef(object, ...)

## S3 method for class 'srrr'
coef(object, ...)

## S3 method for class 'sofar'
coef(object, ...)

## S3 method for class 'rssvd'
coef(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rrpack-coef_+3A_object">object</code></td>
<td>
<p>Object generated by <code>rrpack</code>.</p>
</td></tr>
<tr><td><code id="rrpack-coef_+3A_...">...</code></td>
<td>
<p>Other argumnts for future usage.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A numeric matrix.
</p>

<hr>
<h2 id='rrr'>Multivariate reduced-rank linear regression</h2><span id='topic+rrr'></span>

<h3>Description</h3>

<p>Produce solution paths of reduced-rank estimators and adaptive nuclear norm
penalized estimators; compute the degrees of freeom of the RRR estimators
and select a solution via certain information criterion.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rrr(
  Y,
  X,
  penaltySVD = c("rank", "ann"),
  ic.type = c("GIC", "AIC", "BIC", "BICP", "GCV"),
  df.type = c("exact", "naive"),
  maxrank = min(dim(Y), dim(X)),
  modstr = list(),
  control = list()
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rrr_+3A_y">Y</code></td>
<td>
<p>a matrix of response (n by q)</p>
</td></tr>
<tr><td><code id="rrr_+3A_x">X</code></td>
<td>
<p>a matrix of covariate (n by p)</p>
</td></tr>
<tr><td><code id="rrr_+3A_penaltysvd">penaltySVD</code></td>
<td>
<p>&lsquo;rank&rsquo;: rank-constrainted estimation; &lsquo;ann&rsquo;: adaptive
nuclear norm estimation.</p>
</td></tr>
<tr><td><code id="rrr_+3A_ic.type">ic.type</code></td>
<td>
<p>the information criterion to be used; currently supporting
&lsquo;AIC&rsquo;, &lsquo;BIC&rsquo;, &lsquo;BICP&rsquo;, &lsquo;GCV&rsquo;, and &lsquo;GIC&rsquo;.</p>
</td></tr>
<tr><td><code id="rrr_+3A_df.type">df.type</code></td>
<td>
<p>&lsquo;exact&rsquo;: the exact degrees of freedoms based on SURE theory;
&lsquo;naive&rsquo;: the naive degress of freedoms based on counting number of free
parameters</p>
</td></tr>
<tr><td><code id="rrr_+3A_maxrank">maxrank</code></td>
<td>
<p>an integer of maximum desired rank.</p>
</td></tr>
<tr><td><code id="rrr_+3A_modstr">modstr</code></td>
<td>
<p>a list of model parameters controlling the model fitting</p>
</td></tr>
<tr><td><code id="rrr_+3A_control">control</code></td>
<td>
<p>a list of parameters for controlling the fitting process:
&lsquo;sv.tol&rsquo; controls the tolerence of singular values; &lsquo;qr.tol&rsquo; controls
the tolerence of QR decomposition for the LS fit</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Model parameters can be specified through argument <code>modstr</code>.  The
available include
</p>

<ul>
<li><p>gamma: A scalar power parameter of the adaptive weights in
<code>penalty == "ann"</code>.
</p>
</li>
<li><p>nlambda: The number of lambda values; no effect if
<code>penalty == "count"</code>.
</p>
</li>
<li><p>lambda: A vector of user-specified rank values if
<code>penalty == "count"</code> or a vector of penalty values if <code>penalty ==
"ann"</code>.
</p>
</li></ul>

<p>The available elements for argument <code>control</code> include
</p>

<ul>
<li><p>sv.tol: singular value tolerence.
</p>
</li>
<li><p>qr.tol: QR decomposition tolerence.
</p>
</li></ul>



<h3>Value</h3>

<p>S3 <code>rrr</code> object, a list consisting of
</p>
<table>
<tr><td><code>call</code></td>
<td>
<p>original function call</p>
</td></tr>
<tr><td><code>Y</code></td>
<td>
<p>input matrix of response</p>
</td></tr>
<tr><td><code>X</code></td>
<td>
<p>input matrix of covariate</p>
</td></tr>
<tr><td><code>A</code></td>
<td>
<p>right singular matri x of the least square fitted matrix</p>
</td></tr>
<tr><td><code>Ad</code></td>
<td>
<p>a vector of squared singular values of the least square
fitted matrix</p>
</td></tr>
<tr><td><code>coef.ls</code></td>
<td>
<p>coefficient estimate from LS</p>
</td></tr>
<tr><td><code>Spath</code></td>
<td>
<p>a matrix, each column containing shrinkage factors of the
singular values of a solution; the first four objects can be
used to recover all reduced-rank solutions</p>
</td></tr>
<tr><td><code>df.exact</code></td>
<td>
<p>the exact degrees of freedom</p>
</td></tr>
<tr><td><code>df.naive</code></td>
<td>
<p>the naive degrees of freedom</p>
</td></tr>
<tr><td><code>penaltySVD</code></td>
<td>
<p>the method of low-rank estimation</p>
</td></tr>
<tr><td><code>sse</code></td>
<td>
<p>a vecotr of sum of squard errors</p>
</td></tr>
<tr><td><code>ic</code></td>
<td>
<p>a vector of information criterion</p>
</td></tr>
<tr><td><code>coef</code></td>
<td>
<p>estimated coefficient matrix</p>
</td></tr>
<tr><td><code>U</code></td>
<td>
<p>estimated left singular matrix such that XU/sqrtn is orthogonal</p>
</td></tr>
<tr><td><code>V</code></td>
<td>
<p>estimated right singular matrix that is orthogonal</p>
</td></tr>
<tr><td><code>D</code></td>
<td>
<p>estimated singular value matrix such that C = UDVt</p>
</td></tr>
<tr><td><code>rank</code></td>
<td>
<p>estimated rank</p>
</td></tr>
</table>


<h3>References</h3>

<p>Chen, K., Dong, H. and Chan, K.-S. (2013) Reduced rank regression via
adaptive nuclear norm penalization. <em>Biometrika</em>, 100, 901&ndash;920.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(rrpack)
p &lt;- 50; q &lt;- 50; n &lt;- 100; nrank &lt;- 3
mydata &lt;- rrr.sim1(n, p, q, nrank, s2n = 1, sigma = NULL,
                   rho_X = 0.5, rho_E = 0.3)
rfit &lt;- with(mydata, rrr(Y, X, maxrank = 10))
summary(rfit)
coef(rfit)
plot(rfit)
</code></pre>

<hr>
<h2 id='rrr.cookD'>Cook's distance in reduced-rank regression for model diagnostics</h2><span id='topic+rrr.cookD'></span>

<h3>Description</h3>

<p>Compute Cook's distance for model diagnostics in <code>rrr</code> estimation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rrr.cookD(Y, X = NULL, nrank = 1, qr.tol = 1e-07)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rrr.cookD_+3A_y">Y</code></td>
<td>
<p>response matrix</p>
</td></tr>
<tr><td><code id="rrr.cookD_+3A_x">X</code></td>
<td>
<p>covariate matrix</p>
</td></tr>
<tr><td><code id="rrr.cookD_+3A_nrank">nrank</code></td>
<td>
<p>model rank</p>
</td></tr>
<tr><td><code id="rrr.cookD_+3A_qr.tol">qr.tol</code></td>
<td>
<p>tolerance</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list containing diagnostics measures
</p>


<h3>References</h3>

<p>Chen, K. Model diagnostics in reduced-rank estimation. <em>Statistics and
Its interface</em>, 9, 469&ndash;484.
</p>

<hr>
<h2 id='rrr.fit'>Fitting reduced-rank regression with a specific rank</h2><span id='topic+rrr.fit'></span>

<h3>Description</h3>

<p>Given a response matrix and a covariate matrix, this function fits reduced
rank regression for a specified rank. It reduces to singular value
decomposition if the covariate matrix is the identity matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rrr.fit(Y, X, nrank = 1, weight = NULL, coefSVD = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rrr.fit_+3A_y">Y</code></td>
<td>
<p>a matrix of response (n by q)</p>
</td></tr>
<tr><td><code id="rrr.fit_+3A_x">X</code></td>
<td>
<p>a matrix of covariate (n by p)</p>
</td></tr>
<tr><td><code id="rrr.fit_+3A_nrank">nrank</code></td>
<td>
<p>an integer specifying the desired rank</p>
</td></tr>
<tr><td><code id="rrr.fit_+3A_weight">weight</code></td>
<td>
<p>a square matrix of weight (q by q); The default is the
identity matrix</p>
</td></tr>
<tr><td><code id="rrr.fit_+3A_coefsvd">coefSVD</code></td>
<td>
<p>logical indicating the need for SVD for the coeffient matrix
in the output; used in ssvd estimation</p>
</td></tr>
</table>


<h3>Value</h3>

<p>S3 <code>rrr</code> object, a list consisting of </p>
<table>
<tr><td><code>coef</code></td>
<td>
<p>coefficient
of rrr</p>
</td></tr> <tr><td><code>coef.ls</code></td>
<td>
<p>coefficient of least square</p>
</td></tr> <tr><td><code>fitted</code></td>
<td>
<p>fitted
value of rrr</p>
</td></tr> <tr><td><code>fitted.ls</code></td>
<td>
<p>fitted value of least square</p>
</td></tr>
<tr><td><code>A</code></td>
<td>
<p>right singular matrix</p>
</td></tr> <tr><td><code>Ad</code></td>
<td>
<p>a vector of sigular values</p>
</td></tr>
<tr><td><code>rank</code></td>
<td>
<p>rank of the fitted rrr</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>Y &lt;- matrix(rnorm(400), 100, 4)
X &lt;- matrix(rnorm(800), 100, 8)
rfit &lt;- rrr.fit(Y, X, nrank = 2)
coef(rfit)
</code></pre>

<hr>
<h2 id='rrr.leverage'>Leverage scores and Cook's distance in reduced-rank regression
for model diagnostics</h2><span id='topic+rrr.leverage'></span>

<h3>Description</h3>

<p>Compute leverage scores and Cook's distance for model diagnostics
in <code>rrr</code> estimation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rrr.leverage(Y, X = NULL, nrank = 1, qr.tol = 1e-07)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rrr.leverage_+3A_y">Y</code></td>
<td>
<p>a matrix of response (n by q)</p>
</td></tr>
<tr><td><code id="rrr.leverage_+3A_x">X</code></td>
<td>
<p>a matrix of covariate (n by p)</p>
</td></tr>
<tr><td><code id="rrr.leverage_+3A_nrank">nrank</code></td>
<td>
<p>an integer specifying the desired rank</p>
</td></tr>
<tr><td><code id="rrr.leverage_+3A_qr.tol">qr.tol</code></td>
<td>
<p>tolerence to be passed to &lsquo;qr&rsquo;</p>
</td></tr>
</table>


<h3>Value</h3>

<p>&lsquo;rrr.leverage&rsquo; returns a list containing a vector of leverages
and a scalar of the degrees of freedom (sum of leverages).
&lsquo;rrr.cooks&rsquo; returns a list containing
</p>
<table>
<tr><td><code>residuals</code></td>
<td>
<p>resisuals matrix</p>
</td></tr>
<tr><td><code>mse</code></td>
<td>
<p>mean squared error</p>
</td></tr>
<tr><td><code>leverage</code></td>
<td>
<p>leverage</p>
</td></tr>
<tr><td><code>cookD</code></td>
<td>
<p>Cook's distance</p>
</td></tr>
<tr><td><code>df</code></td>
<td>
<p>degrees of freedom</p>
</td></tr>
</table>


<h3>References</h3>

<p>Chen, K. Model diagnostics in reduced-rank estimation. <em>Statistics and
Its interface</em>, 9, 469&ndash;484.
</p>

<hr>
<h2 id='rrr.sim1'>Simulation model 1</h2><span id='topic+rrr.sim1'></span>

<h3>Description</h3>

<p>Similar to the the RSSVD simulation model in Chen, Chan, Stenseth (2012),
JRSSB.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rrr.sim1(
  n = 50,
  p = 25,
  q = 25,
  nrank = 3,
  s2n = 1,
  sigma = NULL,
  rho_X = 0.5,
  rho_E = 0
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rrr.sim1_+3A_n">n</code>, <code id="rrr.sim1_+3A_p">p</code>, <code id="rrr.sim1_+3A_q">q</code></td>
<td>
<p>model dimensions</p>
</td></tr>
<tr><td><code id="rrr.sim1_+3A_nrank">nrank</code></td>
<td>
<p>model rank</p>
</td></tr>
<tr><td><code id="rrr.sim1_+3A_s2n">s2n</code></td>
<td>
<p>signal to noise ratio</p>
</td></tr>
<tr><td><code id="rrr.sim1_+3A_sigma">sigma</code></td>
<td>
<p>error variance. If specfied, then s2n has no effect</p>
</td></tr>
<tr><td><code id="rrr.sim1_+3A_rho_x">rho_X</code></td>
<td>
<p>correlation parameter in the generation of predictors</p>
</td></tr>
<tr><td><code id="rrr.sim1_+3A_rho_e">rho_E</code></td>
<td>
<p>correlation parameter in the generation of random errors</p>
</td></tr>
</table>


<h3>Value</h3>

<p>similated model and data
</p>


<h3>References</h3>

<p>Chen, K., Chan, K.-S. and Stenseth, N. C. (2012) Reduced rank stochastic
regression with a sparse singular value decomposition.  <em>Journal of the
Royal Statistical Society: Series B</em>, 74, 203&ndash;221.
</p>

<hr>
<h2 id='rrr.sim2'>Simulation model 2</h2><span id='topic+rrr.sim2'></span>

<h3>Description</h3>

<p>Similar to the the SRRR simulation model in Chen and Huang (2012), JASA
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rrr.sim2(
  n = 100,
  p = 50,
  p0 = 10,
  q = 50,
  q0 = 10,
  nrank = 3,
  s2n = 1,
  sigma = NULL,
  rho_X = 0.5,
  rho_E = 0
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rrr.sim2_+3A_n">n</code></td>
<td>
<p>sample size</p>
</td></tr>
<tr><td><code id="rrr.sim2_+3A_p">p</code></td>
<td>
<p>number of predictors</p>
</td></tr>
<tr><td><code id="rrr.sim2_+3A_p0">p0</code></td>
<td>
<p>number of relevant predictors</p>
</td></tr>
<tr><td><code id="rrr.sim2_+3A_q">q</code></td>
<td>
<p>number of responses</p>
</td></tr>
<tr><td><code id="rrr.sim2_+3A_q0">q0</code></td>
<td>
<p>number of relevant responses</p>
</td></tr>
<tr><td><code id="rrr.sim2_+3A_nrank">nrank</code></td>
<td>
<p>model rank</p>
</td></tr>
<tr><td><code id="rrr.sim2_+3A_s2n">s2n</code></td>
<td>
<p>signal to noise ratio</p>
</td></tr>
<tr><td><code id="rrr.sim2_+3A_sigma">sigma</code></td>
<td>
<p>error variance. If specfied, then s2n has no effect</p>
</td></tr>
<tr><td><code id="rrr.sim2_+3A_rho_x">rho_X</code></td>
<td>
<p>correlation parameter in the generation of predictors</p>
</td></tr>
<tr><td><code id="rrr.sim2_+3A_rho_e">rho_E</code></td>
<td>
<p>correlation parameter in the generation of random errors</p>
</td></tr>
</table>


<h3>Value</h3>

<p>similated model and data
</p>


<h3>References</h3>

<p>Chen, L. and Huang, J.Z. (2012) Sparse reduced-rank regression for
simultaneous dimension reduction and variable selection. <em>Journal of
the American Statistical Association</em>, 107:500, 1533&ndash;1545.
</p>

<hr>
<h2 id='rrr.sim3'>Simulation model 3</h2><span id='topic+rrr.sim3'></span>

<h3>Description</h3>

<p>Generate data from a mixed-response reduced-rank regression model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rrr.sim3(
  n = 100,
  p = 30,
  q.mix = c(5, 20, 5),
  nrank = 2,
  intercept = rep(0.5, 30),
  mis.prop = 0.2
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rrr.sim3_+3A_n">n</code></td>
<td>
<p>sample size</p>
</td></tr>
<tr><td><code id="rrr.sim3_+3A_p">p</code></td>
<td>
<p>number of predictors</p>
</td></tr>
<tr><td><code id="rrr.sim3_+3A_q.mix">q.mix</code></td>
<td>
<p>numbers of Gaussian, Bernolli and Poisson responses</p>
</td></tr>
<tr><td><code id="rrr.sim3_+3A_nrank">nrank</code></td>
<td>
<p>model rank</p>
</td></tr>
<tr><td><code id="rrr.sim3_+3A_intercept">intercept</code></td>
<td>
<p>a vector of intercept</p>
</td></tr>
<tr><td><code id="rrr.sim3_+3A_mis.prop">mis.prop</code></td>
<td>
<p>missing proportion</p>
</td></tr>
</table>


<h3>Value</h3>

<p>similated model and data
</p>


<h3>References</h3>

<p>Chen, K., Luo, C., and Liang, J. (2017) Leveraging mixed and incomplete outcomes
through a mixed-response reduced-rank regression. <em>Technical report</em>.
</p>

<hr>
<h2 id='rrr.sim4'>Simulation model 4</h2><span id='topic+rrr.sim4'></span>

<h3>Description</h3>

<p>Generate data from a mean-shifted reduced-rank regression model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rrr.sim4(
  n = 100,
  p = 12,
  q = 8,
  nrank = 3,
  s2n = 1,
  rho_X = 0,
  rho_E = 0,
  nout = 10,
  vout = NULL,
  voutsd = 2,
  nlev = 10,
  vlev = 10,
  vlevsd = NULL,
  SigmaX = "CorrCS",
  SigmaE = "CorrCS"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rrr.sim4_+3A_n">n</code></td>
<td>
<p>sample size</p>
</td></tr>
<tr><td><code id="rrr.sim4_+3A_p">p</code></td>
<td>
<p>number of predictors</p>
</td></tr>
<tr><td><code id="rrr.sim4_+3A_q">q</code></td>
<td>
<p>numbers of responses</p>
</td></tr>
<tr><td><code id="rrr.sim4_+3A_nrank">nrank</code></td>
<td>
<p>model rank</p>
</td></tr>
<tr><td><code id="rrr.sim4_+3A_s2n">s2n</code></td>
<td>
<p>signal to noise ratio</p>
</td></tr>
<tr><td><code id="rrr.sim4_+3A_rho_x">rho_X</code></td>
<td>
<p>correlation parameter for predictors</p>
</td></tr>
<tr><td><code id="rrr.sim4_+3A_rho_e">rho_E</code></td>
<td>
<p>correlation parameter for errors</p>
</td></tr>
<tr><td><code id="rrr.sim4_+3A_nout">nout</code></td>
<td>
<p>number of outliers; should be smaller than n</p>
</td></tr>
<tr><td><code id="rrr.sim4_+3A_vout">vout</code></td>
<td>
<p>control mean-shifted value of outliers</p>
</td></tr>
<tr><td><code id="rrr.sim4_+3A_voutsd">voutsd</code></td>
<td>
<p>control mean-shifted magnitude of outliers</p>
</td></tr>
<tr><td><code id="rrr.sim4_+3A_nlev">nlev</code></td>
<td>
<p>number of high-leverage outliers</p>
</td></tr>
<tr><td><code id="rrr.sim4_+3A_vlev">vlev</code></td>
<td>
<p>control value of leverage</p>
</td></tr>
<tr><td><code id="rrr.sim4_+3A_vlevsd">vlevsd</code></td>
<td>
<p>control magnitude of leverage</p>
</td></tr>
<tr><td><code id="rrr.sim4_+3A_sigmax">SigmaX</code></td>
<td>
<p>correlation structure of predictors</p>
</td></tr>
<tr><td><code id="rrr.sim4_+3A_sigmae">SigmaE</code></td>
<td>
<p>correlation structure of errors</p>
</td></tr>
</table>


<h3>Value</h3>

<p>similated model and data
</p>


<h3>References</h3>

<p>She, Y. and Chen, K. (2017) Robust reduced-rank regression. <em>Biometrika</em>, 104 (3), 633&ndash;647.
</p>

<hr>
<h2 id='rrr.sim5'>Simulation model 5</h2><span id='topic+rrr.sim5'></span>

<h3>Description</h3>

<p>Generate data from a mean-shifted reduced-rank regression model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rrr.sim5(
  n = 40,
  p = 100,
  q = 50,
  nrank = 5,
  rx = 10,
  s2n = 1,
  rho_X = 0,
  rho_E = 0,
  nout = 10,
  vout = NULL,
  voutsd = 2,
  nlev = 10,
  vlev = 10,
  vlevsd = NULL,
  SigmaX = "CorrCS",
  SigmaE = "CorrCS"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rrr.sim5_+3A_n">n</code></td>
<td>
<p>sample size</p>
</td></tr>
<tr><td><code id="rrr.sim5_+3A_p">p</code></td>
<td>
<p>number of predictors</p>
</td></tr>
<tr><td><code id="rrr.sim5_+3A_q">q</code></td>
<td>
<p>numbers of responses</p>
</td></tr>
<tr><td><code id="rrr.sim5_+3A_nrank">nrank</code></td>
<td>
<p>model rank</p>
</td></tr>
<tr><td><code id="rrr.sim5_+3A_rx">rx</code></td>
<td>
<p>rank of the design matrix</p>
</td></tr>
<tr><td><code id="rrr.sim5_+3A_s2n">s2n</code></td>
<td>
<p>signal to noise ratio</p>
</td></tr>
<tr><td><code id="rrr.sim5_+3A_rho_x">rho_X</code></td>
<td>
<p>correlation parameter for predictors</p>
</td></tr>
<tr><td><code id="rrr.sim5_+3A_rho_e">rho_E</code></td>
<td>
<p>correlation parameter for errors</p>
</td></tr>
<tr><td><code id="rrr.sim5_+3A_nout">nout</code></td>
<td>
<p>number of outliers; should be smaller than n</p>
</td></tr>
<tr><td><code id="rrr.sim5_+3A_vout">vout</code></td>
<td>
<p>control mean-shifted value of outliers</p>
</td></tr>
<tr><td><code id="rrr.sim5_+3A_voutsd">voutsd</code></td>
<td>
<p>control mean-shifted magnitude of outliers</p>
</td></tr>
<tr><td><code id="rrr.sim5_+3A_nlev">nlev</code></td>
<td>
<p>number of high-leverage outliers</p>
</td></tr>
<tr><td><code id="rrr.sim5_+3A_vlev">vlev</code></td>
<td>
<p>control value of leverage</p>
</td></tr>
<tr><td><code id="rrr.sim5_+3A_vlevsd">vlevsd</code></td>
<td>
<p>control magnitude of leverage</p>
</td></tr>
<tr><td><code id="rrr.sim5_+3A_sigmax">SigmaX</code></td>
<td>
<p>correlation structure of predictors</p>
</td></tr>
<tr><td><code id="rrr.sim5_+3A_sigmae">SigmaE</code></td>
<td>
<p>correlation structure of errors</p>
</td></tr>
</table>


<h3>Value</h3>

<p>similated model and data
</p>


<h3>References</h3>

<p>She, Y. and Chen, K. (2017) Robust reduced-rank regression. <em>Biometrika</em>, 104 (3), 633&ndash;647.
</p>

<hr>
<h2 id='rrs.fit'>Fitting reduced-rank ridge regression with given rank and shrinkage penalty</h2><span id='topic+rrs.fit'></span>

<h3>Description</h3>

<p>Fitting reduced-rank ridge regression with given rank and shrinkage penalty
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rrs.fit(Y, X, nrank = min(ncol(Y), ncol(X)), lambda = 1, coefSVD = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rrs.fit_+3A_y">Y</code></td>
<td>
<p>a matrix of response (n by q)</p>
</td></tr>
<tr><td><code id="rrs.fit_+3A_x">X</code></td>
<td>
<p>a matrix of covariate (n by p)</p>
</td></tr>
<tr><td><code id="rrs.fit_+3A_nrank">nrank</code></td>
<td>
<p>an integer specifying the desired rank</p>
</td></tr>
<tr><td><code id="rrs.fit_+3A_lambda">lambda</code></td>
<td>
<p>tunging parameter for the ridge penalty</p>
</td></tr>
<tr><td><code id="rrs.fit_+3A_coefsvd">coefSVD</code></td>
<td>
<p>logical indicating the need for SVD for the
coeffient matrix int the output</p>
</td></tr>
</table>


<h3>Value</h3>

<p>S3 <code>rrr</code> object, a list consisting of
</p>
<table>
<tr><td><code>coef</code></td>
<td>
<p>coefficient of rrs</p>
</td></tr>
<tr><td><code>coef.ls</code></td>
<td>
<p>coefficient of least square</p>
</td></tr>
<tr><td><code>fitted</code></td>
<td>
<p>fitted value of rrs</p>
</td></tr>
<tr><td><code>fitted.ls</code></td>
<td>
<p>fitted value of least square</p>
</td></tr>
<tr><td><code>A</code></td>
<td>
<p>right singular matrix</p>
</td></tr>
<tr><td><code>Ad</code></td>
<td>
<p>sigular value vector</p>
</td></tr>
<tr><td><code>nrank</code></td>
<td>
<p>rank of the fitted rrr</p>
</td></tr>
</table>


<h3>References</h3>

<p>Mukherjee, A. and Zhu, J. (2011) Reduced rank ridge regression and its
kernal extensions.
</p>
<p>Mukherjee, A., Chen, K., Wang, N. and Zhu, J. (2015) On the degrees of
freedom of reduced-rank estimators in multivariate
regression. <em>Biometrika</em>, 102, 457&ndash;477.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(rrpack)
Y &lt;- matrix(rnorm(400), 100, 4)
X &lt;- matrix(rnorm(800), 100, 8)
rfit &lt;- rrs.fit(Y, X)
</code></pre>

<hr>
<h2 id='rssvd'>Reduced-rank regression with a sparse singular value decomposition</h2><span id='topic+rssvd'></span>

<h3>Description</h3>

<p>Reduced-rank regression with a sparse singular value decomposition using the
iterative exclusive extraction algorithm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rssvd(
  Y,
  X,
  nrank,
  ic.type = c("BIC", "BICP", "AIC"),
  orthX = FALSE,
  control = list(),
  screening = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rssvd_+3A_y">Y</code></td>
<td>
<p>response matrix</p>
</td></tr>
<tr><td><code id="rssvd_+3A_x">X</code></td>
<td>
<p>covariate matrix</p>
</td></tr>
<tr><td><code id="rssvd_+3A_nrank">nrank</code></td>
<td>
<p>integer specification of the desired rank</p>
</td></tr>
<tr><td><code id="rssvd_+3A_ic.type">ic.type</code></td>
<td>
<p>character specifying which information criterion to use to
select the best: &lsquo;BIC&rsquo;, &lsquo;BICP&rsquo;, and &lsquo;AIC&rsquo;</p>
</td></tr>
<tr><td><code id="rssvd_+3A_orthx">orthX</code></td>
<td>
<p>logical indicating if X is orthogonal, in which case a faster
algorithm is used</p>
</td></tr>
<tr><td><code id="rssvd_+3A_control">control</code></td>
<td>
<p>a list of parameters controlling the fitting process</p>
</td></tr>
<tr><td><code id="rssvd_+3A_screening">screening</code></td>
<td>
<p>If TRUE, marginal screening via glm is performed before
srrr fitting.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The model fitting can be controled through argument <code>control</code>.
The available elements include
</p>

<ul>
<li><p>maxit: maximum number of iterations.
</p>
</li>
<li><p>epsilon: convergence tolerance.
</p>
</li>
<li><p>innerMaxit: maximum number of iterations for inner steps.
</p>
</li>
<li><p>innerEpsilon: convergence tolerance for inner steps.
</p>
</li>
<li><p>nlambda: number of tuning parameters.
</p>
</li>
<li><p>adaptive: if Ture, use adaptive penalization.
</p>
</li>
<li><p>gamma0: power parameter for constructing adaptive weights.
</p>
</li>
<li><p>minLambda: multiplicate factor to determine the minimum lambda.
</p>
</li>
<li><p>niter.eea: the number of iterations in the iterative exclusive
extraction algorithm.
</p>
</li>
<li><p>df.tol: tolerance.
</p>
</li></ul>



<h3>Value</h3>

<p>S3 <code>rssvd.path</code> object, a list consisting of
</p>
<table>
<tr><td><code>Upath</code></td>
<td>
<p>solution path of U</p>
</td></tr>
<tr><td><code>Vpath</code></td>
<td>
<p>solution path of V</p>
</td></tr>
<tr><td><code>Dpath</code></td>
<td>
<p>solution path of D</p>
</td></tr>
<tr><td><code>U</code></td>
<td>
<p>estimated left singular matrix that is orthogonal</p>
</td></tr>
<tr><td><code>V</code></td>
<td>
<p>estimated right singular matrix that is orthogonal</p>
</td></tr>
<tr><td><code>D</code></td>
<td>
<p>estimated singular values such that C=UDVt</p>
</td></tr>
<tr><td><code>rank</code></td>
<td>
<p>estimated rank</p>
</td></tr>
</table>


<h3>References</h3>

<p>Chen, K., Chan, K.-S. and Stenseth, N. C. (2012) Reduced rank stochastic
regression with a sparse singular value decomposition.  <em>Journal of the
Royal Statistical Society: Series B</em>, 74, 203&ndash;221.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(rrpack)
## Simulate data from a sparse factor regression model
p &lt;- 50; q &lt;- 50; n &lt;- 100; nrank &lt;- 3
mydata &lt;- rrr.sim1(n, p, q, nrank, s2n = 1, sigma = NULL,
                   rho_X = 0.5, rho_E = 0.3)
fit1 &lt;- with(mydata, rssvd(Y, X, nrank = nrank + 1))
summary(fit1)
plot(fit1)
</code></pre>

<hr>
<h2 id='sofar'>Sparse orthogonal factor regression</h2><span id='topic+sofar'></span>

<h3>Description</h3>

<p>Compute solution paths of sparse orthogonal factor regression
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sofar(
  Y,
  X,
  nrank = 1,
  su = NULL,
  sv = NULL,
  ic.type = c("GIC", "BIC", "AIC", "GCV"),
  modstr = list(),
  control = list(),
  screening = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sofar_+3A_y">Y</code></td>
<td>
<p>response matrix</p>
</td></tr>
<tr><td><code id="sofar_+3A_x">X</code></td>
<td>
<p>covariate matrix</p>
</td></tr>
<tr><td><code id="sofar_+3A_nrank">nrank</code></td>
<td>
<p>an integer specifying the desired rank/number of factors</p>
</td></tr>
<tr><td><code id="sofar_+3A_su">su</code></td>
<td>
<p>a scaling vector for U such that <code class="reqn">U^TU = diag(s_u)</code>.</p>
</td></tr>
<tr><td><code id="sofar_+3A_sv">sv</code></td>
<td>
<p>a scaling vector for V such that <code class="reqn">V^TV = diag(s_v)</code>.</p>
</td></tr>
<tr><td><code id="sofar_+3A_ic.type">ic.type</code></td>
<td>
<p>select tuning method; the default is GIC</p>
</td></tr>
<tr><td><code id="sofar_+3A_modstr">modstr</code></td>
<td>
<p>a list of internal model parameters controlling the model
fitting</p>
</td></tr>
<tr><td><code id="sofar_+3A_control">control</code></td>
<td>
<p>a list of internal computation parameters controlling
optimization</p>
</td></tr>
<tr><td><code id="sofar_+3A_screening">screening</code></td>
<td>
<p>If TRUE, marginal screening via lasso is performed before
sofar fitting.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The model parameters can be specified through argument <code>modstr</code>.
The available elements include
</p>

<ul>
<li><p>mu: parameter in the augmented Lagrangian function.
</p>
</li>
<li><p>mugamma: increament of mu along iterations to speed up
computation.
</p>
</li>
<li><p>WA: weight matrix for A.
</p>
</li>
<li><p>WB: weight matrix for B.
</p>
</li>
<li><p>Wd: weight matrix for d.
</p>
</li>
<li><p>wgamma: power parameter in constructing adaptive weights.
</p>
</li></ul>

<p>The model fitting can be controled through argument <code>control</code>.
The avilable elements include
</p>

<ul>
<li><p>nlam: number of lambda triplets to be used.
</p>
</li>
<li><p>lam.min.factor: set the smallest lambda triplets as a fraction of the
estimation lambda.max triplets.
</p>
</li>
<li><p>lam.max.factor: set the largest lambda triplets as a multiple of the
estimation lambda.max triplets.
</p>
</li>
<li><p>lam.AB.factor: set the relative penalty level between A/B and D.
</p>
</li>
<li><p>penA,penB,penD: if TRUE, penalty is applied.
</p>
</li>
<li><p>lamA: sequence of tuning parameters for A.
</p>
</li>
<li><p>lamB: sequence of tuning parameters for B.
</p>
</li>
<li><p>lamD: sequence of tuning parameters for d.
</p>
</li>
<li><p>methodA: penalty for penalizing A.
</p>
</li>
<li><p>methodB: penalty for penalizing B.
</p>
</li>
<li><p>epsilon: convergence tolerance.
</p>
</li>
<li><p>maxit: maximum number of iterations.
</p>
</li>
<li><p>innerEpsilon: convergence tolerance for inner subroutines.
</p>
</li>
<li><p>innerMaxit: maximum number of iterations for inner subroutines.
</p>
</li>
<li><p>sv.tol: tolerance for singular values.
</p>
</li></ul>



<h3>Value</h3>

<p>A <code>sofar</code> object containing
</p>
<table>
<tr><td><code>call</code></td>
<td>
<p>original function call</p>
</td></tr>
<tr><td><code>Y</code></td>
<td>
<p>input response matrix</p>
</td></tr>
<tr><td><code>X</code></td>
<td>
<p>input predictor matrix</p>
</td></tr>
<tr><td><code>Upath</code></td>
<td>
<p>solution path of U</p>
</td></tr>
<tr><td><code>Dpath</code></td>
<td>
<p>solution path of D</p>
</td></tr>
<tr><td><code>Vpath</code></td>
<td>
<p>solution path of D</p>
</td></tr>
<tr><td><code>Rpath</code></td>
<td>
<p>path of estimated rank</p>
</td></tr>
<tr><td><code>icpath</code></td>
<td>
<p>path of information criteria</p>
</td></tr>
<tr><td><code>lam.id</code></td>
<td>
<p>ids of selected lambda for GIC, BIC, AIC and GCV</p>
</td></tr>
<tr><td><code>p.index</code></td>
<td>
<p>ids of predictors which passed screening</p>
</td></tr>
<tr><td><code>q.index</code></td>
<td>
<p>ids of responses which passed screening</p>
</td></tr>
<tr><td><code>lamA</code></td>
<td>
<p>tuning sequence for A</p>
</td></tr>
<tr><td><code>lamB</code></td>
<td>
<p>tuning sequence for B</p>
</td></tr>
<tr><td><code>lamD</code></td>
<td>
<p>tuning sequence for D</p>
</td></tr>
<tr><td><code>U</code></td>
<td>
<p>estimated left singular matrix that is orthogonal (factor weights)</p>
</td></tr>
<tr><td><code>V</code></td>
<td>
<p>estimated right singular matrix that is orthogonal (factor loadings)</p>
</td></tr>
<tr><td><code>D</code></td>
<td>
<p>estimated singular values</p>
</td></tr>
<tr><td><code>rank</code></td>
<td>
<p>estimated rank</p>
</td></tr>
</table>


<h3>References</h3>

<p>Uematsu, Y., Fan, Y., Chen, K., Lv, J., &amp; Lin, W. (2019). SOFAR: large-scale
association network learning. <em>IEEE Transactions on Information
Theory</em>, 65(8), 4924&ndash;4939.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(rrpack)
## Simulate data from a sparse factor regression model
p &lt;- 100; q &lt;- 50; n &lt;- 100; nrank &lt;- 3
mydata &lt;- rrr.sim1(n, p, q, nrank, s2n = 1,
                   sigma = NULL, rho_X = 0.5, rho_E = 0.3)
Y &lt;- mydata$Y
X &lt;- mydata$X

fit1 &lt;- sofar(Y, X, ic.type = "GIC", nrank = nrank + 2,
              control = list(methodA = "adlasso", methodB = "adlasso"))
summary(fit1)
plot(fit1)

fit1$U
crossprod(fit1$U) #check orthogonality
fit1$V
crossprod(fit1$V) #check orthogonality

## End(Not run)

</code></pre>

<hr>
<h2 id='srrr'>Row-sparse reduced-eank regresssion</h2><span id='topic+srrr'></span>

<h3>Description</h3>

<p>Row-sparse reduced-rank regresssion for a prespecified rank; produce a
solution path for selecting predictors
</p>


<h3>Usage</h3>

<pre><code class='language-R'>srrr(
  Y,
  X,
  nrank = 2,
  method = c("glasso", "adglasso"),
  ic.type = c("BIC", "BICP", "AIC", "GCV", "GIC"),
  A0 = NULL,
  V0 = NULL,
  modstr = list(),
  control = list(),
  screening = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="srrr_+3A_y">Y</code></td>
<td>
<p>response matrix</p>
</td></tr>
<tr><td><code id="srrr_+3A_x">X</code></td>
<td>
<p>covariate matrix</p>
</td></tr>
<tr><td><code id="srrr_+3A_nrank">nrank</code></td>
<td>
<p>prespecified rank</p>
</td></tr>
<tr><td><code id="srrr_+3A_method">method</code></td>
<td>
<p>group lasso or adaptive group lasso</p>
</td></tr>
<tr><td><code id="srrr_+3A_ic.type">ic.type</code></td>
<td>
<p>information criterion</p>
</td></tr>
<tr><td><code id="srrr_+3A_a0">A0</code></td>
<td>
<p>initial value</p>
</td></tr>
<tr><td><code id="srrr_+3A_v0">V0</code></td>
<td>
<p>initial value</p>
</td></tr>
<tr><td><code id="srrr_+3A_modstr">modstr</code></td>
<td>
<p>a list of model parameters controlling the model fitting</p>
</td></tr>
<tr><td><code id="srrr_+3A_control">control</code></td>
<td>
<p>a list of parameters for controlling the fitting process</p>
</td></tr>
<tr><td><code id="srrr_+3A_screening">screening</code></td>
<td>
<p>If TRUE, marginal screening via glm is performed before
srrr fitting.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Model parameters controlling the model fitting can be specified through
argument <code>modstr</code>. The available elements include
</p>

<ul>
<li><p>lamA: tuning parameter sequence.
</p>
</li>
<li><p>nlam: number of tuning parameters; no effect if <code>lamA</code> is
specified.
</p>
</li>
<li><p>minLambda: minimum lambda value, no effect if <code>lamA</code> is
specified.
</p>
</li>
<li><p>maxLambda: maxmum lambda value, no effect if lamA is specified.
</p>
</li>
<li><p>WA: adaptive weights. If NULL, the weights are constructed from
RRR.
</p>
</li>
<li><p>wgamma: power parameter for constructing adaptive weights.
</p>
</li></ul>

<p>Similarly, the computational parameters controlling optimization can be
specified through argument <code>control</code>. The available elements include
</p>

<ul>
<li><p>epsilon: epsilonergence tolerance.
</p>
</li>
<li><p>maxit: maximum number of iterations.
</p>
</li>
<li><p>inner.eps: used in inner loop.
</p>
</li>
<li><p>inner.maxit: used in inner loop.
</p>
</li></ul>



<h3>Value</h3>

<p>A list of fitting results
</p>


<h3>References</h3>

<p>Chen, L. and Huang, J. Z. (2012) Sparse reduced-rank regression for
simultaneous dimension reduction and variable selection. <em>Journal of
the American Statistical Association</em>. 107:500, 1533&ndash;1545.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(rrpack)
p &lt;- 100; n &lt;- 100; nrank &lt;- 3
mydata &lt;- rrr.sim2(n, p, p0 = 10,q = 50, q0 = 10, nrank = 3,
                   s2n = 1, sigma = NULL, rho_X = 0.5, rho_E = 0)
fit1 &lt;- with(mydata, srrr(Y, X, nrank = 3))
summary(fit1)
coef(fit1)
plot(fit1)
</code></pre>

<hr>
<h2 id='summary'>Summarize rrpack Objects</h2><span id='topic+summary'></span><span id='topic+summary.mrrr'></span><span id='topic+summary.cv.mrrr'></span><span id='topic+summary.r4'></span><span id='topic+summary.rrr'></span><span id='topic+summary.cv.rrr'></span><span id='topic+summary.sofar'></span><span id='topic+summary.cv.sofar'></span><span id='topic+summary.srrr'></span><span id='topic+summary.cv.srrr'></span><span id='topic+summary.rssvd'></span>

<h3>Description</h3>

<p>S3 methods summarizing objects generated by <code>rrpack</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'mrrr'
summary(object, ...)

## S3 method for class 'cv.mrrr'
summary(object, ...)

## S3 method for class 'r4'
summary(object, ...)

## S3 method for class 'rrr'
summary(object, ...)

## S3 method for class 'cv.rrr'
summary(object, ...)

## S3 method for class 'sofar'
summary(object, ...)

## S3 method for class 'cv.sofar'
summary(object, ...)

## S3 method for class 'srrr'
summary(object, ...)

## S3 method for class 'cv.srrr'
summary(object, ...)

## S3 method for class 'rssvd'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary_+3A_object">object</code></td>
<td>
<p>Object generated from <code>rrpack</code>.</p>
</td></tr>
<tr><td><code id="summary_+3A_...">...</code></td>
<td>
<p>Other argumnts for future usage.</p>
</td></tr>
</table>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
