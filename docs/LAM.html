<!DOCTYPE html><html lang="en"><head><title>Help for package LAM</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {LAM}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#LAM-package'>
<p>Some Latent Variable Models</p></a></li>
<li><a href='#amh'>
<p>Bayesian Model Estimation with Adaptive Metropolis Hastings Sampling</p>
(<code>amh</code>) or Penalized Maximum Likelihood Estimation (<code>pmle</code>)</a></li>
<li><a href='#clpm_to_ctm'>
<p>Transformation of Path Coefficients of Cross-Lagged Panel Model</p></a></li>
<li><a href='#data.HT'>
<p>Datasets from Heck and Thomas (2015)</p></a></li>
<li><a href='#loglike_mvnorm'>
<p>Log-Likelihood Value of a Multivariate Normal Distribution</p></a></li>
<li><a href='#mlnormal'>
<p>(Restricted) Maximum Likelihood Estimation with Prior Distributions</p>
and Penalty Functions under Multivariate Normality</a></li>
<li><a href='#suff_stat_NA_pattern'>
<p>Sufficient Statistics for Dataset with Missing Response Pattern</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Some Latent Variable Models</td>
</tr>
<tr>
<td>Version:</td>
<td>0.7-22</td>
</tr>
<tr>
<td>Date:</td>
<td>2024-07-15 11:56:28</td>
</tr>
<tr>
<td>Author:</td>
<td>Alexander Robitzsch [aut,cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Alexander Robitzsch &lt;robitzsch@ipn.uni-kiel.de&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>
    Includes some procedures for latent variable modeling with a 
    particular focus on multilevel data.
    The 'LAM' package contains mean and covariance structure modelling
    for multivariate normally distributed data (mlnormal(); Longford, 1987;
    &lt;<a href="https://doi.org/10.1093%2Fbiomet%2F74.4.817">doi:10.1093/biomet/74.4.817</a>&gt;), a general Metropolis-Hastings algorithm 
    (amh(); Roberts &amp; Rosenthal, 2001, &lt;<a href="https://doi.org/10.1214%2Fss%2F1015346320">doi:10.1214/ss/1015346320</a>&gt;) and 
    penalized maximum likelihood estimation (pmle(); Cole, Chu &amp; Greenland, 
    2014; &lt;<a href="https://doi.org/10.1093%2Faje%2Fkwt245">doi:10.1093/aje/kwt245</a>&gt;).</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.1)</td>
</tr>
<tr>
<td>Imports:</td>
<td>CDM, graphics, Rcpp, sirt, stats, utils</td>
</tr>
<tr>
<td>Suggests:</td>
<td>coda, expm, MASS, numDeriv, TAM</td>
</tr>
<tr>
<td>Enhances:</td>
<td>lavaan, lme4</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp, RcppArmadillo</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/alexanderrobitzsch/LAM">https://github.com/alexanderrobitzsch/LAM</a>,
<a href="https://sites.google.com/site/alexanderrobitzsch2/software">https://sites.google.com/site/alexanderrobitzsch2/software</a></td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-07-15 09:58:09 UTC; sunpn563</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-07-15 10:30:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='LAM-package'>
Some Latent Variable Models
</h2><span id='topic+LAM-package'></span><span id='topic+LAM'></span>

<h3>Description</h3>


<p>    Includes some procedures for latent variable modeling with a 
    particular focus on multilevel data.
    The 'LAM' package contains mean and covariance structure modelling
    for multivariate normally distributed data (mlnormal(); Longford, 1987;
    &lt;doi:10.1093/biomet/74.4.817&gt;), a general Metropolis-Hastings algorithm 
    (amh(); Roberts &amp; Rosenthal, 2001, &lt;doi:10.1214/ss/1015346320&gt;) and 
    penalized maximum likelihood estimation (pmle(); Cole, Chu &amp; Greenland, 
    2014; &lt;doi:10.1093/aje/kwt245&gt;).
</p>


<h3>Details</h3>

<p>The <span class="pkg">LAM</span> package contains the following main functions:
</p>

<ul>
<li><p> A general fitting method for mean and covariance structure for
multivariate normally distributed data is the <code><a href="#topic+mlnormal">mlnormal</a></code>
function. Prior distributions or regularization methods (lasso penalties)
are also accommodated. Missing values on dependent variables can be
treated by applying the full information maximum likelihood method
implemented in this function.
</p>
</li>
<li><p> A general (but experimental) Metropolis-Hastings sampler for Bayesian
analysis based on MCMC is implemented in the <code><a href="#topic+amh">amh</a></code> function.
Deterministic optimization of the posterior distribution (maximum
posterior estimation or penalized maximum likelihood estimation) can be
conduction with the <code><a href="#topic+pmle">pmle</a></code> function which is based on
<code><a href="stats.html#topic+optim">stats::optim</a></code>.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Alexander Robitzsch [aut,cre]
</p>
<p>Maintainer: Alexander Robitzsch &lt;robitzsch@ipn.uni-kiel.de&gt;
</p>


<h3>References</h3>

<p>Cole, S. R., Chu, H., &amp; Greenland, S. (2013). Maximum likelihood, profile likelihood,
and penalized likelihood: a primer. <em>American Journal of Epidemiology, 179</em>(2), 252-260.
<a href="https://doi.org/10.1093/aje/kwt245">doi:10.1093/aje/kwt245</a>
</p>
<p>Longford, N. T. (1987). A fast scoring algorithm for maximum likelihood estimation in
unbalanced mixed models with nested random effects. <em>Biometrika, 74</em>(4), 817-827.
<a href="https://doi.org/10.1093/biomet/74.4.817">doi:10.1093/biomet/74.4.817</a>
</p>
<p>Roberts, G. O., &amp; Rosenthal, J. S. (2001). Optimal scaling for various Metropolis-Hastings
algorithms. <em>Statistical Science, 16</em>(4), 351-367.
<a href="https://doi.org/10.1214/ss/1015346320">doi:10.1214/ss/1015346320</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  ##  &gt; library(LAM)
  ##  ## LAM 0.0-4 (2017-03-03 16:53:46)
  ##
  ##   __         ______     __    __
  ##  /\ \       /\  __ \   /\ "-./  \
  ##  \ \ \____  \ \  __ \  \ \ \-./\ \
  ##   \ \_____\  \ \_\ \_\  \ \_\ \ \_\
  ##    \/_____/   \/_/\/_/   \/_/  \/_/
  ##
</code></pre>

<hr>
<h2 id='amh'>
Bayesian Model Estimation with Adaptive Metropolis Hastings Sampling
(<code>amh</code>) or Penalized Maximum Likelihood Estimation (<code>pmle</code>)
</h2><span id='topic+amh'></span><span id='topic+summary.amh'></span><span id='topic+plot.amh'></span><span id='topic+logLik.amh'></span><span id='topic+coef.amh'></span><span id='topic+vcov.amh'></span><span id='topic+confint.amh'></span><span id='topic+pmle'></span><span id='topic+summary.pmle'></span><span id='topic+plot.pmle'></span><span id='topic+logLik.pmle'></span><span id='topic+coef.pmle'></span><span id='topic+vcov.pmle'></span><span id='topic+confint.pmle'></span>

<h3>Description</h3>

<p>The function <code>amh</code> conducts a Bayesian statistical analysis using
the adaptive Metropolis-Hastings
as the estimation procedure (Hoff, 2009; Roberts &amp; Rosenthal, 2001). Only univariate prior
distributions are allowed.
Note that this function is intended just for experimental purpose, not to
replace general purpose packages like <span class="pkg">WinBUGS</span>, <span class="pkg">JAGS</span>,
<span class="pkg">Stan</span> or <span class="pkg">MHadaptive</span>. <br />
</p>
<p>The function <code>pmle</code> optimizes the penalized likelihood (Cole, Chu &amp; Greenland, 2014)
which means that
the posterior is maximized and the maximum a posterior estimate is
obtained. The optimization functions <a href="stats.html#topic+optim">stats::optim</a> or
<a href="stats.html#topic+nlminb">stats::nlminb</a> can be used.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>amh(data, nobs, pars, model,  prior, proposal_sd,  pars_lower=NULL,
      pars_upper=NULL, derivedPars=NULL, n.iter=5000, n.burnin=1000,
      n.sims=3000, acceptance_bounds=c(.45,.55), proposal_refresh=50,
      proposal_equal=4, print_iter=50, boundary_ignore=FALSE )

pmle( data, nobs, pars, model,  prior=NULL, model_grad=NULL, pars_lower=NULL,
      pars_upper=NULL, method="L-BFGS-B", control=list(), verbose=TRUE, hessian=TRUE,
      optim_fct="nlminb", h=1e-4, ... )

## S3 method for class 'amh'
summary(object, digits=3, file=NULL, ...)

## S3 method for class 'amh'
plot(x, conflevel=.95, digits=3, lag.max=.1,
    col.smooth="red", lwd.smooth=2, col.split="blue", lwd.split=2,
    lty.split=1, col.ci="orange", cex.summ=1, ask=FALSE, ... )

## S3 method for class 'amh'
coef(object, ...)

## S3 method for class 'amh'
logLik(object, ...)

## S3 method for class 'amh'
vcov(object, ...)

## S3 method for class 'amh'
confint(object, parm, level=.95, ... )

## S3 method for class 'pmle'
summary(object, digits=3, file=NULL, ...)

## S3 method for class 'pmle'
coef(object, ...)

## S3 method for class 'pmle'
logLik(object, ...)

## S3 method for class 'pmle'
vcov(object, ...)

## S3 method for class 'pmle'
confint(object, parm, level=.95, ... )
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="amh_+3A_data">data</code></td>
<td>

<p>Object which contains data
</p>
</td></tr>
<tr><td><code id="amh_+3A_nobs">nobs</code></td>
<td>
<p>Number of observations</p>
</td></tr>
<tr><td><code id="amh_+3A_pars">pars</code></td>
<td>

<p>Named vector of initial values for parameters
</p>
</td></tr>
<tr><td><code id="amh_+3A_model">model</code></td>
<td>

<p>Function defining the log-likelihood of the model
</p>
</td></tr>
<tr><td><code id="amh_+3A_prior">prior</code></td>
<td>

<p>List with prior distributions for the parameters to be sampled (see Examples).
See <code><a href="sirt.html#topic+prior_model_parse">sirt::prior_model_parse</a></code>
for more convenient specifications of the prior distributions. Setting the prior
argument to <code>NULL</code> corresponds to improper (constant) prior distributions
for all parameters.
</p>
</td></tr>
<tr><td><code id="amh_+3A_proposal_sd">proposal_sd</code></td>
<td>

<p>Vector with initial standard deviations for proposal distribution
</p>
</td></tr>
<tr><td><code id="amh_+3A_pars_lower">pars_lower</code></td>
<td>

<p>Vector with lower bounds for parameters
</p>
</td></tr>
<tr><td><code id="amh_+3A_pars_upper">pars_upper</code></td>
<td>

<p>Vector with upper bounds for parameters
</p>
</td></tr>
<tr><td><code id="amh_+3A_derivedpars">derivedPars</code></td>
<td>
<p>Optional list containing derived parameters from sampled chain</p>
</td></tr>
<tr><td><code id="amh_+3A_n.iter">n.iter</code></td>
<td>

<p>Number of iterations
</p>
</td></tr>
<tr><td><code id="amh_+3A_n.burnin">n.burnin</code></td>
<td>

<p>Number of burn-in iterations
</p>
</td></tr>
<tr><td><code id="amh_+3A_n.sims">n.sims</code></td>
<td>
<p>Number of sampled iterations for parameters</p>
</td></tr>
<tr><td><code id="amh_+3A_acceptance_bounds">acceptance_bounds</code></td>
<td>

<p>Bounds for acceptance probabilities of sampled parameters
</p>
</td></tr>
<tr><td><code id="amh_+3A_proposal_refresh">proposal_refresh</code></td>
<td>

<p>Number of iterations for computation of adaptation of proposal
standard deviation
</p>
</td></tr>
<tr><td><code id="amh_+3A_proposal_equal">proposal_equal</code></td>
<td>
<p>Number of intervals in which the proposal SD should be constant
for fixing the SD</p>
</td></tr>
<tr><td><code id="amh_+3A_print_iter">print_iter</code></td>
<td>

<p>Display progress every <code>print_iter</code>th iteration
</p>
</td></tr>
<tr><td><code id="amh_+3A_boundary_ignore">boundary_ignore</code></td>
<td>
<p>Logical indicating whether sampled values outside the
specified boundaries should be ignored.</p>
</td></tr>
<tr><td><code id="amh_+3A_model_grad">model_grad</code></td>
<td>
<p>Optional function which evaluates the gradient of
the log-likelihood function (must be a function of <code>pars</code>.</p>
</td></tr>
<tr><td><code id="amh_+3A_method">method</code></td>
<td>
<p>Optimization method in <code><a href="stats.html#topic+optim">stats::optim</a></code></p>
</td></tr>
<tr><td><code id="amh_+3A_control">control</code></td>
<td>
<p>Control parameters <code><a href="stats.html#topic+optim">stats::optim</a></code></p>
</td></tr>
<tr><td><code id="amh_+3A_verbose">verbose</code></td>
<td>
<p>Logical indicating whether progress should be displayed.</p>
</td></tr>
<tr><td><code id="amh_+3A_hessian">hessian</code></td>
<td>
<p>Logical indicating whether the Hessian matrix
should be computed</p>
</td></tr>
<tr><td><code id="amh_+3A_optim_fct">optim_fct</code></td>
<td>
<p>Type of optimization: <code>"optim"</code> (<a href="stats.html#topic+optim">stats::optim</a>)
or the default <code>"nlminb"</code> (<a href="stats.html#topic+nlminb">stats::nlminb</a>)
</p>
</td></tr>
<tr><td><code id="amh_+3A_h">h</code></td>
<td>
<p>Numerical differentiation parameter for prior distributions if
<code>model_grad</code> is provided.</p>
</td></tr>
<tr><td><code id="amh_+3A_object">object</code></td>
<td>
<p>Object of class <code>amh</code></p>
</td></tr>
<tr><td><code id="amh_+3A_digits">digits</code></td>
<td>
<p>Number of digits used for rounding</p>
</td></tr>
<tr><td><code id="amh_+3A_file">file</code></td>
<td>
<p>File name</p>
</td></tr>
<tr><td><code id="amh_+3A_...">...</code></td>
<td>
<p>Further arguments to be passed</p>
</td></tr>
<tr><td><code id="amh_+3A_x">x</code></td>
<td>
<p>Object of class <code>amh</code></p>
</td></tr>
<tr><td><code id="amh_+3A_conflevel">conflevel</code></td>
<td>
<p>Confidence level</p>
</td></tr>
<tr><td><code id="amh_+3A_lag.max">lag.max</code></td>
<td>
<p>Percentage of iterations used for calculation of
autocorrelation function</p>
</td></tr>
<tr><td><code id="amh_+3A_col.smooth">col.smooth</code></td>
<td>
<p>Color moving average</p>
</td></tr>
<tr><td><code id="amh_+3A_lwd.smooth">lwd.smooth</code></td>
<td>
<p>Line thickness moving average</p>
</td></tr>
<tr><td><code id="amh_+3A_col.split">col.split</code></td>
<td>
<p>Color split chain</p>
</td></tr>
<tr><td><code id="amh_+3A_lwd.split">lwd.split</code></td>
<td>
<p>Line thickness splitted chain</p>
</td></tr>
<tr><td><code id="amh_+3A_lty.split">lty.split</code></td>
<td>
<p>Line type splitted chain</p>
</td></tr>
<tr><td><code id="amh_+3A_col.ci">col.ci</code></td>
<td>
<p>Color confidence interval</p>
</td></tr>
<tr><td><code id="amh_+3A_cex.summ">cex.summ</code></td>
<td>
<p>Point size summary</p>
</td></tr>
<tr><td><code id="amh_+3A_ask">ask</code></td>
<td>
<p>Logical. If <code>TRUE</code> the user is asked for input,
before a new figure is drawn.</p>
</td></tr>
<tr><td><code id="amh_+3A_parm">parm</code></td>
<td>
<p>Optional vector of parameters.</p>
</td></tr>
<tr><td><code id="amh_+3A_level">level</code></td>
<td>
<p>Confidence level.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>List of class <code>amh</code> including entries
</p>
<table role = "presentation">
<tr><td><code>pars_chain</code></td>
<td>
<p>Data frame with sampled parameters</p>
</td></tr>
<tr><td><code>acceptance_parameters</code></td>
<td>
<p>Acceptance probabilities</p>
</td></tr>
<tr><td><code>amh_summary</code></td>
<td>
<p>Summary of parameters</p>
</td></tr>
<tr><td><code>coef</code></td>
<td>
<p>Coefficient obtained from marginal MAP estimation</p>
</td></tr>
<tr><td><code>pmle_pars</code></td>
<td>
<p>Object of parameters and posterior values corresponding
to multivariate maximum of posterior distribution.</p>
</td></tr>
<tr><td><code>comp_estimators</code></td>
<td>
<p>Estimates for univariate MAP, multivariate MAP
and mean estimator and corresponding posterior estimates.</p>
</td></tr>
<tr><td><code>ic</code></td>
<td>
<p>Information criteria</p>
</td></tr>
<tr><td><code>mcmcobj</code></td>
<td>
<p>Object of class <code>mcmc</code> for <span class="pkg">coda</span> package</p>
</td></tr>
<tr><td><code>proposal_sd</code></td>
<td>
<p>Used proposal standard deviations</p>
</td></tr>
<tr><td><code>proposal_sd_history</code></td>
<td>
<p>History of proposal standard
deviations during burn-in iterations</p>
</td></tr>
<tr><td><code>acceptance_rates_history</code></td>
<td>
<p>History of acceptance rates for all parameters
during burn-in phase</p>
</td></tr>
<tr><td><code>...</code></td>
<td>
<p>More values</p>
</td></tr> </table>
<p><br /> <br />
</p>


<h3>References</h3>

<p>Cole, S. R., Chu, H., &amp; Greenland, S. (2013). Maximum likelihood, profile likelihood,
and penalized likelihood: a primer. <em>American Journal of Epidemiology, 179</em>(2), 252-260.
<a href="https://doi.org/10.1093/aje/kwt245">doi:10.1093/aje/kwt245</a>
</p>
<p>Hoff, P. D. (2009). <em>A first course in Bayesian statistical methods</em>.
New York: Springer.
</p>
<p>Roberts, G. O., &amp; Rosenthal, J. S. (2001). Optimal scaling for various Metropolis-Hastings
algorithms. <em>Statistical Science, 16</em>(4), 351-367.
<a href="https://doi.org/10.1214/ss/1015346320">doi:10.1214/ss/1015346320</a>
</p>


<h3>See Also</h3>

<p>See the Bayesian CRAN Task View for lot of information about
alternative <span class="rlang"><b>R</b></span> packages.
</p>
<p><code><a href="sirt.html#topic+prior_model_parse">sirt::prior_model_parse</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
#############################################################################
# EXAMPLE 1: Constrained multivariate normal distribution
#############################################################################

#--- simulate data
Sigma &lt;- matrix( c(
    1, .55, .5,
    .55, 1, .45,
    .5, .45, 1 ), nrow=3, ncol=3, byrow=TRUE )
mu &lt;- c(0,1,1.2)
N &lt;- 400
set.seed(9875)
dat &lt;- MASS::mvrnorm( N, mu, Sigma )
colnames(dat) &lt;- paste0("Y",1:3)
S &lt;- stats::cov(dat)
M &lt;- colMeans(dat)

#-- define maximum likelihood function for normal distribution
fit_ml &lt;- function( S, Sigma, M, mu, n, log=TRUE){
    Sigma1 &lt;- solve(Sigma)
    p &lt;- ncol(Sigma)
    det_Sigma &lt;- det( Sigma )
    eps &lt;- 1E-30
    if ( det_Sigma &lt; eps ){
            det_Sigma &lt;- eps
    }
    l1 &lt;- - p * log( 2*pi ) - t( M - mu ) %*% Sigma1 %*% ( M - mu ) -
                  log( det_Sigma )  - sum( diag( Sigma1 %*% S ) )
    l1 &lt;- n/2 * l1
    if (! log){
        l1 &lt;- exp(l1)
    }
    l1 &lt;- l1[1,1]
    return(l1)
}
# This likelihood function can be directly accessed by the loglike_mvnorm function.

#--- define data input
data &lt;- list( "S"=S, "M"=M, "n"=N )

#--- define list of prior distributions
prior &lt;- list()
prior[["mu1"]] &lt;- list( "dnorm", list( x=NA, mean=0, sd=1 ) )
prior[["mu2"]] &lt;- list( "dnorm", list( x=NA, mean=0, sd=5 ) )
prior[["sig1"]] &lt;- list( "dunif", list( x=NA, 0, 10 ) )
prior[["rho"]] &lt;- list( "dunif", list( x=NA,-1, 1  ) )

#** alternatively, one can specify the prior as a string and uses
#   the 'prior_model_parse' function
prior_model2 &lt;- "
   mu1 ~ dnorm(x=NA, mean=0, sd=1)
   mu2 ~ dnorm(x=NA, mean=0, sd=5)
   sig1 ~ dunif(x=NA, 0,10)
   rho ~ dunif(x=NA,-1,1)
   "
# convert string
prior2 &lt;- sirt::prior_model_parse( prior_model2 )
prior2  # should be equal to prior

#--- define log likelihood function for model to be fitted
model &lt;- function( pars, data ){
    # mean vector
    mu &lt;- pars[ c("mu1", rep("mu2",2) ) ]
    # covariance matrix
    m1 &lt;- matrix( pars["rho"] * pars["sig1"]^2, 3, 3 )
    diag(m1) &lt;- rep( pars["sig1"]^2, 3 )
    Sigma &lt;- m1
    # evaluate log-likelihood
    ll &lt;- fit_ml( S=data$S, Sigma=Sigma, M=data$M, mu=mu, n=data$n)
    return(ll)
}

#--- initial parameter values
pars &lt;- c(1,2,2,0)
names(pars) &lt;- c("mu1", "mu2", "sig1", "rho")
#--- initial proposal distributions
proposal_sd &lt;- c( .4, .1, .05, .1 )
names(proposal_sd) &lt;- names(pars)
#--- lower and upper bound for parameters
pars_lower &lt;- c( -10, -10, .001, -.999 )
pars_upper &lt;- c( 10, 10, 1E100, .999 )

#--- define list with derived parameters
derivedPars &lt;- list( "var1"=~ I( sig1^2 ), "d1"=~ I( ( mu2 - mu1 ) / sig1 ) )

#*** start Metropolis-Hastings sampling
mod &lt;- LAM::amh( data, nobs=data$n, pars=pars, model=model,
          prior=prior, proposal_sd=proposal_sd,
          n.iter=1000, n.burnin=300, derivedPars=derivedPars,
          pars_lower=pars_lower, pars_upper=pars_upper )

# some S3 methods
summary(mod)
plot(mod, ask=TRUE)
coef(mod)
vcov(mod)
logLik(mod)

#--- compare Bayesian credibility intervals and HPD intervals
ci &lt;- cbind( confint(mod), coda::HPDinterval(mod$mcmcobj)[-1, ] )
ci
# interval lengths
cbind( ci[,2]-ci[,1], ci[,4] - ci[,3] )

#--- plot update history of proposal standard deviations
graphics::matplot( x=rownames(mod$proposal_sd_history),
          y=mod$proposal_sd_history, type="o", pch=1:6)

#**** compare results with lavaan package
library(lavaan)
lavmodel &lt;- "
    F=~ 1*Y1 + 1*Y2 + 1*Y3
    F ~~ rho*F
    Y1 ~~ v1*Y1
    Y2 ~~ v1*Y2
    Y3 ~~ v1*Y3
    Y1 ~ mu1 * 1
    Y2 ~ mu2 * 1
    Y3 ~ mu2 * 1
    # total standard deviation
    sig1 :=sqrt( rho + v1 )
    "
# estimate model
mod2 &lt;- lavaan::sem( data=as.data.frame(dat), lavmodel )
summary(mod2)
logLik(mod2)

#*** compare results with penalized maximum likelihood estimation
mod3 &lt;- LAM::pmle( data=data, nobs=data$n, pars=pars, model=model,  prior=prior,
            pars_lower=pars_lower, pars_upper=pars_upper, verbose=TRUE  )
# model summaries
summary(mod3)
confint(mod3)
vcov(mod3)

#*** penalized likelihood estimation with provided gradient of log-likelihood

library(CDM)
fct &lt;- function(x){
    model(pars=x, data=data )
}
# use numerical gradient (just for illustration)
grad &lt;- function(pars){
    CDM::numerical_Hessian(par=pars, FUN=fct, gradient=TRUE, hessian=FALSE)
}
#- estimate model
mod3b &lt;- LAM::pmle( data=data, nobs=data$n, pars=pars, model=model,  prior=prior, model_grad=grad,
            pars_lower=pars_lower, pars_upper=pars_upper, verbose=TRUE  )
summary(mod3b)

#--- lavaan with covariance and mean vector input
mod2a &lt;- lavaan::sem( sample.cov=data$S, sample.mean=data$M, sample.nobs=data$n,
                model=lavmodel )
coef(mod2)
coef(mod2a)

#--- fit covariance and mean structure by fitting a transformed
#    covariance structure
#* create an expanded covariance matrix
p &lt;- ncol(S)
S1 &lt;- matrix( NA, nrow=p+1, ncol=p+1 )
S1[1:p,1:p] &lt;- S + outer( M, M )
S1[p+1,1:p] &lt;- S1[1:p, p+1] &lt;- M
S1[p+1,p+1] &lt;- 1
vars &lt;- c( colnames(S), "MY" )
rownames(S1) &lt;- colnames(S1) &lt;- vars
#* lavaan model
lavmodel &lt;- "
    # indicators
    F=~ 1*Y1 + 1*Y2 + 1*Y3
    # pseudo-indicator representing mean structure
    FM=~ 1*MY
    MY ~~ 0*MY
    FM ~~ 1*FM
    F ~~ 0*FM
    # mean structure
    FM=~ mu1*Y1 + mu2*Y2 + mu2*Y3
    # variance structure
    F ~~ rho*F
    Y1 ~~ v1*Y1
    Y2 ~~ v1*Y2
    Y3 ~~ v1*Y3
    sig1 :=sqrt( rho + v1 )
    "

# estimate model
mod2b &lt;- lavaan::sem( sample.cov=S1,sample.nobs=data$n,
                model=lavmodel )
summary(mod2b)
summary(mod2)

#############################################################################
# EXAMPLE 2: Estimation of a linear model with Box-Cox transformation of response
#############################################################################

#*** simulate data with Box-Cox transformation
set.seed(875)
N &lt;- 1000
b0 &lt;- 1.5
b1 &lt;- .3
sigma &lt;- .5
lambda &lt;- 0.3
# apply inverse Box-Cox transformation
  # yl=( y^lambda - 1 ) / lambda
  # -&gt; y=( lambda * yl + 1 )^(1/lambda)
x &lt;- stats::rnorm( N,  mean=0, sd=1 )
yl &lt;- stats::rnorm( N, mean=b0, sd=sigma ) + b1*x
# truncate at zero
eps &lt;- .01
yl &lt;- ifelse( yl &lt; eps, eps, yl )
y &lt;- ( lambda * yl + 1 ) ^(1/lambda )

#-- display distributions of transformed and untransformed data
   graphics::par(mfrow=c(1,2))
graphics::hist(yl, breaks=20)
graphics::hist(y, breaks=20)
   graphics::par(mfrow=c(1,1))

#*** define vector of parameters
pars &lt;- c( 0, 0,  1, -.2 )
names(pars) &lt;- c("b0", "b1", "sigma", "lambda" )
#*** input data
data &lt;- list( "y"=y, "x"=x)
#*** define model with log-likelihood function
model &lt;- function( pars, data ){
    sigma &lt;- pars["sigma"]
    b0 &lt;- pars["b0"]
    b1 &lt;- pars["b1"]
    lambda &lt;- pars["lambda"]
    if ( abs(lambda) &lt; .01){ lambda &lt;- .01 * sign(lambda) }
    y &lt;- data$y
    x &lt;- data$x
    n &lt;- length(y)
    y_lambda &lt;- ( y^lambda - 1 ) / lambda
    ll &lt;- - n/2 * log(2*pi) - n * log( sigma ) -
            1/(2*sigma^2)* sum( (y_lambda - b0 - b1*x)^2 ) +
            ( lambda - 1 ) * sum( log( y ) )
    return(ll)
}
#-- test model function
model( pars, data )

#*** define prior distributions
prior &lt;- list()
prior[["b0"]] &lt;- list( "dnorm", list( x=NA, mean=0, sd=10 ) )
prior[["b1"]] &lt;- list( "dnorm", list( x=NA, mean=0, sd=10 ) )
prior[["sigma"]] &lt;- list( "dunif", list( x=NA, 0, 10  ) )
prior[["lambda"]] &lt;- list( "dunif", list( x=NA, -2, 2 ) )
#*** define proposal SDs
proposal_sd &lt;- c( .1, .1, .1, .1 )
names(proposal_sd) &lt;- names(pars)
#*** define bounds for parameters
pars_lower &lt;- c( -100, -100, .01, -2 )
pars_upper &lt;- c( 100, 100, 100, 2 )

#*** sampling routine
mod &lt;- LAM::amh( data, nobs=N, pars, model,  prior, proposal_sd,
        n.iter=10000, n.burnin=2000, n.sims=5000,
        pars_lower=pars_lower, pars_upper=pars_upper )
#-- S3 methods
summary(mod)
plot(mod, ask=TRUE )

#*** estimating Box-Cox transformation in MASS package
library(MASS)
mod2 &lt;- MASS::boxcox( stats::lm( y ~ x ), lambda=seq(-1,2,length=100) )
mod2$x[ which.max( mod2$y ) ]

#*** estimate Box-Cox parameter lambda with car package
library(car)
mod3 &lt;- car::powerTransform( y ~ x )
summary(mod3)
# fit linear model with transformed response
mod3a &lt;- stats::lm( car::bcPower( y, mod3$roundlam) ~ x )
summary(mod3a)

#############################################################################
# EXAMPLE 3: STARTS model directly specified in LAM or lavaan
#############################################################################

## Data from Wu (2016)

library(LAM)
library(sirt)
library(STARTS)

## define list with input data
## S ... covariance matrix, M ... mean vector

# read covariance matrix of data in Wu (older cohort, positive affect)
S &lt;- matrix( c( 12.745, 7.046, 6.906, 6.070, 5.047, 6.110,
    7.046, 14.977, 8.334, 6.714, 6.91, 6.624,
    6.906, 8.334, 13.323, 7.979, 8.418, 7.951,
    6.070, 6.714, 7.979, 12.041, 7.874, 8.099,
    5.047, 6.91, 8.418, 7.874, 13.838, 9.117,
    6.110, 6.624, 7.951, 8.099, 9.117, 15.132 ),
    nrow=6, ncol=6, byrow=TRUE )
#* standardize S such that the average SD is 1 (for ease of interpretation)
M_SD &lt;- mean( sqrt( diag(S) ))
S &lt;- S / M_SD^2
colnames(S) &lt;- rownames(S) &lt;- paste0("W",1:6)
W &lt;- 6   # number of measurement waves
data &lt;- list( "S"=S, "M"=rep(0,W), "n"=660, "W"=W  )

#*** likelihood function for the STARTS model
model &lt;- function( pars, data ){
    # mean vector
    mu &lt;- data$M
    # covariance matrix
    W &lt;- data$W
    var_trait &lt;- pars["vt"]
    var_ar &lt;- pars["va"]
    var_state &lt;- pars["vs"]
    a &lt;- pars["b"]
    Sigma &lt;- STARTS::starts_uni_cov( W=W, var_trait=var_trait,
                var_ar=var_ar, var_state=var_state, a=a )
    # evaluate log-likelihood
    ll &lt;- LAM::loglike_mvnorm( S=data$S, Sigma=Sigma, M=data$M, mu=mu,
                n=data$n, lambda=1E-5)
    return(ll)
}
#** Note:
#   (1) The function starts_uni_cov calculates the model implied covariance matrix
#       for the STARTS model.
#   (2) The function loglike_mvnorm evaluates the loglikelihood for a multivariate
#       normal distribution given sample and population means M and mu, and sample
#       and population covariance matrix S and Sigma.

#*** starting values for parameters
pars &lt;- c( .33, .33, .33, .75)
names(pars) &lt;- c("vt","va","vs","b")
#*** bounds for acceptance rates
acceptance_bounds &lt;- c( .45, .55 )
#*** starting values for proposal standard deviations
proposal_sd &lt;- c( .1, .1, .1, .1 )
names(proposal_sd) &lt;- names(pars)
#*** lower and upper bounds for parameter estimates
pars_lower &lt;- c( .001, .001, .001, .001 )
pars_upper &lt;- c( 10, 10, 10, .999 )
#*** define prior distributions | use prior sample size of 3
prior_model &lt;- "
    vt ~ dinvgamma2(NA, 3, .33 )
    va ~ dinvgamma2(NA, 3, .33 )
    vs ~ dinvgamma2(NA, 3, .33 )
    b ~ dbeta(NA, 4, 4 )
        "
#*** define number of iterations
n.burnin &lt;- 5000
n.iter &lt;- 20000
set.seed(987)    # fix random seed
#*** estimate model with 'LAM::amh' function
mod &lt;- LAM::amh( data=data, nobs=data$n, pars=pars, model=model,
            prior=prior_model, proposal_sd=proposal_sd, n.iter=n.iter,
            n.burnin=n.burnin, pars_lower=pars_lower, pars_upper=pars_upper)
#*** model summary
summary(mod)
  ##  Parameter Summary (Marginal MAP estimation)
  ##    parameter   MAP    SD  Q2.5 Q97.5  Rhat SERatio effSize accrate
  ##  1        vt 0.352 0.088 0.122 0.449 1.014   0.088     128   0.557
  ##  2        va 0.335 0.080 0.238 0.542 1.015   0.090     123   0.546
  ##  3        vs 0.341 0.018 0.297 0.367 1.005   0.042     571   0.529
  ##  4         b 0.834 0.065 0.652 0.895 1.017   0.079     161   0.522
  ##
  ##  Comparison of Different Estimators
  ##
  ##  MAP: Univariate marginal MAP estimation
  ##  mMAP: Multivariate MAP estimation (penalized likelihood estimate)
  ##  Mean: Mean of posterior distributions
  ##
  ##    Parameter Summary:
  ##    parm   MAP  mMAP  Mean
  ##  1   vt 0.352 0.294 0.300
  ##  2   va 0.335 0.371 0.369
  ##  3   vs 0.341 0.339 0.335
  ##  4    b 0.834 0.822 0.800

#* inspect convergence
plot(mod, ask=TRUE)

#---------------------------
# fitting the STARTS model with penalized maximum likelihood estimation
mod2 &lt;- LAM::pmle( data=data, nobs=data$n, pars=pars, model=model,  prior=prior_model,
            pars_lower=pars_lower, pars_upper=pars_upper, method="L-BFGS-B",
            control=list( trace=TRUE )  )
# model summaries
summary(mod2)
  ##  Parameter Summary
  ##    parameter   est    se      t     p active
  ##  1        vt 0.298 0.110  2.712 0.007      1
  ##  2        va 0.364 0.102  3.560 0.000      1
  ##  3        vs 0.337 0.018 18.746 0.000      1
  ##  4         b 0.818 0.074 11.118 0.000      1

#---------------------------
# fitting the STARTS model in lavaan

library(lavaan)

## define lavaan model
lavmodel &lt;- "
     #*** stable trait
     T=~ 1*W1 + 1*W2 + 1*W3 + 1*W4 + 1*W5 + 1*W6
     T ~~ vt * T
     W1 ~~ 0*W1
     W2 ~~ 0*W2
     W3 ~~ 0*W3
     W4 ~~ 0*W4
     W5 ~~ 0*W5
     W6 ~~ 0*W6
     #*** autoregressive trait
     AR1=~ 1*W1
     AR2=~ 1*W2
     AR3=~ 1*W3
     AR4=~ 1*W4
     AR5=~ 1*W5
     AR6=~ 1*W6
     #*** state component
     S1=~ 1*W1
     S2=~ 1*W2
     S3=~ 1*W3
     S4=~ 1*W4
     S5=~ 1*W5
     S6=~ 1*W6
     S1 ~~ vs * S1
     S2 ~~ vs * S2
     S3 ~~ vs * S3
     S4 ~~ vs * S4
     S5 ~~ vs * S5
     S6 ~~ vs * S6
     AR2 ~ b * AR1
     AR3 ~ b * AR2
     AR4 ~ b * AR3
     AR5 ~ b * AR4
     AR6 ~ b * AR5
     AR1 ~~ va * AR1
     AR2 ~~ v1 * AR2
     AR3 ~~ v1 * AR3
     AR4 ~~ v1 * AR4
     AR5 ~~ v1 * AR5
     AR6 ~~ v1 * AR6
     #*** nonlinear constraint
     v1==va * ( 1 - b^2 )
     #*** force variances to be positive
     vt &gt; 0.001
     va &gt; 0.001
     vs &gt; 0.001
     #*** variance proportions
     var_total :=vt + vs + va
     propt :=vt / var_total
     propa :=va / var_total
     props :=vs / var_total
    "
# estimate lavaan model
mod &lt;- lavaan::lavaan(model=lavmodel, sample.cov=S, sample.nobs=660)
# summary and fit measures
summary(mod)
lavaan::fitMeasures(mod)
coef(mod)[ ! duplicated( names(coef(mod))) ]
  ##           vt          vs           b          va          v1
  ##  0.001000023 0.349754630 0.916789054 0.651723144 0.103948711

## End(Not run)
</code></pre>

<hr>
<h2 id='clpm_to_ctm'>
Transformation of Path Coefficients of Cross-Lagged Panel Model
</h2><span id='topic+clpm_to_ctm'></span>

<h3>Description</h3>

<p>Transforms path coefficients <code class="reqn">\bold{\Phi}(\Delta t_1)</code> of a cross-lagged panel model
(CLPM) based on time interval <code class="reqn">\Delta t_1</code> into a time interval <code class="reqn">\Delta t_2</code>.
The transformation is based on the assumption of a continuous time model (CTM;
Voelkle, Oud, Davidov, &amp; Schmidt, 2012) including a drift matrix <code class="reqn">\bold{A}</code>.
The transformation relies on the matrix exponential function
(see Kuiper &amp; Ryan, 2018),
i.e. <code class="reqn">\bold{\Phi}(\Delta t_1)=\exp( \bold{A} \Delta t_1 ) </code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>clpm_to_ctm(Phi1, delta1=1, delta2=2, Phi1_vcov=NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="clpm_to_ctm_+3A_phi1">Phi1</code></td>
<td>
<p>Matrix of path coefficients <code class="reqn">\bold{\Phi}(\Delta t_1)</code></p>
</td></tr>
<tr><td><code id="clpm_to_ctm_+3A_delta1">delta1</code></td>
<td>
<p>Numeric <code class="reqn">\Delta t_1</code></p>
</td></tr>
<tr><td><code id="clpm_to_ctm_+3A_delta2">delta2</code></td>
<td>
<p>Numeric <code class="reqn">\Delta t_2</code></p>
</td></tr>
<tr><td><code id="clpm_to_ctm_+3A_phi1_vcov">Phi1_vcov</code></td>
<td>
<p>Optional covariance matrix for parameter estimates of
<code class="reqn">\bold{\Phi}(\Delta t_1)</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with following entries
</p>
<table role = "presentation">
<tr><td><code>A</code></td>
<td>
<p>Drift matrix</p>
</td></tr>
<tr><td><code>A_se</code></td>
<td>
<p>Standard errors of drift matrix</p>
</td></tr>
<tr><td><code>A_vcov</code></td>
<td>
<p>Covariance matrix of drift matrix</p>
</td></tr>
<tr><td><code>Phi2</code></td>
<td>
<p>Path coefficients <code class="reqn">\bold{\Phi}(\Delta t_2)</code></p>
</td></tr>
<tr><td><code>Phi2_se</code></td>
<td>
<p>Standard errors for <code class="reqn">\bold{\Phi}(\Delta t_2)</code></p>
</td></tr>
<tr><td><code>Phi2_vcov</code></td>
<td>
<p>Covariance matrix for <code class="reqn">\bold{\Phi}(\Delta t_2)</code></p>
</td></tr>
</table>


<h3>References</h3>

<p>Kuiper, R. M., &amp; Ryan, O. (2018). Drawing conclusions from cross-lagged relationships:
Re-considering the role of the time-interval.
<em>Structural Equation Modeling, 25</em>(5), 809-823.
<a href="https://doi.org/10.1080/10705511.2018.1431046">doi:10.1080/10705511.2018.1431046</a>
</p>
<p>Voelkle, M. C., Oud, J. H., Davidov, E., &amp; Schmidt, P. (2012). An SEM approach to
continuous time modeling of panel data: Relating authoritarianism and anomia.
<em>Psychological Methods, 17</em>(2), 176-192.
<a href="https://doi.org/10.1037/a0027543">doi:10.1037/a0027543</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#############################################################################
# EXAMPLE 1: Example of Voelkle et al. (2012)
#############################################################################

library(expm)

# path coefficient matrix of Voelkle et al. (2012), but see
# also Kuiper and Ryan (2018)
Phi1 &lt;- matrix( c( .64, .18,
                  .03, .89 ), nrow=2, ncol=2, byrow=TRUE )
# transformation to time interval 2
mod &lt;- LAM::clpm_to_ctm(Phi1, delta1=1, delta2=2)
print(mod)

## Not run: 
#############################################################################
# EXAMPLE 2: Example with two dimensions
#############################################################################

library(STARTS)
library(lavaan)

data(data.starts02, package="STARTS")
dat &lt;- data.starts02$younger_cohort
cormat &lt;- cov2cor(as.matrix(dat$covmat))

#-- estimate CLPM
lavmodel &lt;- "
       a2 ~ a1 + b1
       b2 ~ a1 + b1
       "
mod &lt;- lavaan::sem(lavmodel, sample.cov=cormat, sample.nobs=500)
summary(mod)

#- select parameters
pars &lt;- c("a2~a1", "a2~b1", "b2~a1", "b2~b1")
Phi1 &lt;- matrix( coef(mod)[pars], 2, 2, byrow=TRUE)
Phi1_vcov &lt;- vcov(mod)[ pars, pars ]

# conversion to time interval 1.75
LAM::clpm_to_ctm(Phi1=Phi1, delta1=1, delta2=1.75, Phi1_vcov=Phi1_vcov)

#############################################################################
# EXAMPLE 3: Example with three dimensions
#############################################################################

library(STARTS)
library(lavaan)

data(data.starts02, package="STARTS")
dat &lt;- data.starts02$younger_cohort
cormat &lt;- cov2cor(as.matrix(dat$covmat))

#-- estimate CLPM
lavmodel &lt;- "
       a4 ~ a1 + b1 + c1
       b4 ~ a1 + b1 + c1
       c4 ~ a1 + b1 + c1
       "
mod &lt;- lavaan::sem(lavmodel, sample.cov=cormat, sample.nobs=500)
summary(mod)

#- select parameters
pars &lt;- 1:9
Phi1 &lt;- matrix( coef(mod)[pars], 3, 3, byrow=TRUE)
Phi1_vcov &lt;- vcov(mod)[ pars, pars ]

# conversion frpm time interval 3 to time interval 1
LAM::clpm_to_ctm(Phi1=Phi1, delta1=3, delta2=1, Phi1_vcov=Phi1_vcov)

## End(Not run)
</code></pre>

<hr>
<h2 id='data.HT'>
Datasets from Heck and Thomas (2015)
</h2><span id='topic+data.HT'></span><span id='topic+data.HT12'></span>

<h3>Description</h3>

<p>Selected datasets from Heck and Thomas (2015).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(data.HT12)
</code></pre>


<h3>Format</h3>


<ul>
<li><p> The format of the dataset <code>data.HT12</code> from Chapter 1 is:
</p>
<p><code>'data.frame':   120 obs. of  11 variables:</code> <br />
<code> $ schcode: num  100 100 100 100 100 107 107 107 107 107 ...</code> <br />
<code> $ read   : num  682 644 651 710 673 593 660 640 646 634 ...</code> <br />
<code> $ math   : num  714 661 670 786 719 598 660 622 647 696 ...</code> <br />
<code> $ lang   : num  673 670 648 677 698 596 673 613 618 645 ...</code> <br />
<code> $ ess    : num  -2.8 -2.8 -2.8 -2.8 -2.8 3.19 3.19 3.19 3.19 3.19 ...</code> <br />
<code> $ cses   : num  -2.4 -2.4 -2.4 -2.4 -2.4 1.67 1.67 1.67 1.67 1.67 ...</code> <br />
<code> $ female : num  0 0 0 0 0 0 1 1 1 0 ...</code> <br />
<code> $ lowses : num  0 0 0 0 1 0 0 1 1 0 ...</code> <br />
<code> $ lgsch  : num  0 0 0 0 0 0 0 0 0 0 ...</code> <br />
<code> $ age    : num  135 140 135 151 138 138 140 141 144 146 ...</code> <br />
<code> $ ncses  : num  2.4 2.4 2.4 2.4 2.4 -1.67 -1.67 -1.67 -1.67 -1.67 ...</code> <br />
</p>
</li></ul>



<h3>Source</h3>

<p>https://www.routledge.com/An-Introduction-to-Multilevel-Modeling-Techniques-MLM-and-SEM-Approaches/Heck-Thomas/p/book/9781848725522
</p>


<h3>References</h3>

<p>Heck, R. H. &amp; Thomas, S. L. (2015). <em>An introduction to multilevel modeling
techniques</em>. Routledge, New York.
</p>

<hr>
<h2 id='loglike_mvnorm'>
Log-Likelihood Value of a Multivariate Normal Distribution
</h2><span id='topic+loglike_mvnorm'></span><span id='topic+loglike_mvnorm_NA_pattern'></span>

<h3>Description</h3>

<p>Computes log-likelihood value of a multivariate normal distribution
given the empirical mean vector and the empirical covariance matrix
as sufficient statistics.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>loglike_mvnorm(M, S, mu, Sigma, n, log=TRUE, lambda=0, ginv=FALSE, eps=1e-30,
       use_rcpp=FALSE )

loglike_mvnorm_NA_pattern( suff_stat, mu, Sigma, log=TRUE, lambda=0, ginv=FALSE,
       eps=1e-30, use_rcpp=FALSE )
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="loglike_mvnorm_+3A_m">M</code></td>
<td>

<p>Empirical mean vector
</p>
</td></tr>
<tr><td><code id="loglike_mvnorm_+3A_s">S</code></td>
<td>

<p>Empirical covariance matrix
</p>
</td></tr>
<tr><td><code id="loglike_mvnorm_+3A_mu">mu</code></td>
<td>

<p>Population mean vector
</p>
</td></tr>
<tr><td><code id="loglike_mvnorm_+3A_sigma">Sigma</code></td>
<td>

<p>Population covariance matrix
</p>
</td></tr>
<tr><td><code id="loglike_mvnorm_+3A_n">n</code></td>
<td>

<p>Sample size
</p>
</td></tr>
<tr><td><code id="loglike_mvnorm_+3A_log">log</code></td>
<td>

<p>Optional logical indicating whether the logarithm of the likelihood
should be calculated.
</p>
</td></tr>
<tr><td><code id="loglike_mvnorm_+3A_lambda">lambda</code></td>
<td>

<p>Regularization parameter of the covariance matrix (see Details).
</p>
</td></tr>
<tr><td><code id="loglike_mvnorm_+3A_ginv">ginv</code></td>
<td>
<p>Logical indicating whether generalized inverse matrix of
<code class="reqn">\bold{\Sigma}</code> should be used</p>
</td></tr>
<tr><td><code id="loglike_mvnorm_+3A_eps">eps</code></td>
<td>
<p>Threshold for determinant value of <code class="reqn">\bold{\Sigma}</code></p>
</td></tr>
<tr><td><code id="loglike_mvnorm_+3A_use_rcpp">use_rcpp</code></td>
<td>
<p>Logical indicating whether <span class="pkg">Rcpp</span> function should be used</p>
</td></tr>
<tr><td><code id="loglike_mvnorm_+3A_suff_stat">suff_stat</code></td>
<td>
<p>List with sufficient statistics as generated by
<code><a href="#topic+suff_stat_NA_pattern">suff_stat_NA_pattern</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The population covariance matrix <code class="reqn">\bold{\Sigma}</code> is regularized if
<code class="reqn">\lambda</code> (<code>lambda</code>) is chosen larger than zero.
Let <code class="reqn">\bold{\Delta _\Sigma}</code> denote a diagonal matrix containing
the diagonal entries of <code class="reqn">\bold{\Sigma}</code>. Then, a regularized matrix
<code class="reqn">\bold{\Sigma}^\ast</code> is defined as
<code class="reqn">\bold{\Sigma}^\ast=w \bold{\Sigma} + (1-w)\bold{\Delta _\Sigma }</code>
with <code class="reqn">w=n/(n+\lambda)</code>.
</p>


<h3>Value</h3>

<p>Log-likelihood value
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#############################################################################
# EXAMPLE 1: Multivariate normal distribution
#############################################################################

library(MASS)

#--- simulate data
Sigma &lt;- c( 1, .55, .5, .55, 1, .5,.5, .5, 1 )
Sigma &lt;- matrix( Sigma, nrow=3, ncol=3 )
mu &lt;- c(0,1,1.2)
N &lt;- 400
set.seed(9875)
dat &lt;- MASS::mvrnorm( N, mu, Sigma )
colnames(dat) &lt;- paste0("Y",1:3)
S &lt;- stats::cov(dat)
M &lt;- colMeans(dat)

#--- evaulate likelihood
res1 &lt;- LAM::loglike_mvnorm( M=M, S=S, mu=mu, Sigma=Sigma, n=N, lambda=0 )
# compare log likelihood with somewhat regularized covariance matrix
res2 &lt;- LAM::loglike_mvnorm( M=M, S=S, mu=mu, Sigma=Sigma, n=N, lambda=1 )
print(res1)
print(res2)

## Not run: 

#############################################################################
# EXAMPLE 2: Multivariate normal distribution with missing data patterns
#############################################################################

library(STARTS)
data(data.starts01b, package="STARTS")
dat &lt;- data.starts01b
dat1 &lt;- dat[, paste0("E",1:3)]

#-- compute sufficient statistics
suff_stat &lt;- LAM::suff_stat_NA_pattern(dat1)
#-- define some population mean and covariance
mu &lt;- colMeans(dat1, na.rm=TRUE)
Sigma &lt;- stats::cov(dat1, use="pairwise.complete.obs")

#-- compute log-likelihood
LAM::loglike_mvnorm_NA_pattern( suff_stat=suff_stat, mu=mu, Sigma=Sigma)

## End(Not run)
</code></pre>

<hr>
<h2 id='mlnormal'>
(Restricted) Maximum Likelihood Estimation with Prior Distributions
and Penalty Functions under Multivariate Normality
</h2><span id='topic+mlnormal'></span><span id='topic+summary.mlnormal'></span><span id='topic+print.mlnormal'></span><span id='topic+logLik.mlnormal'></span><span id='topic+coef.mlnormal'></span><span id='topic+vcov.mlnormal'></span><span id='topic+confint.mlnormal'></span>

<h3>Description</h3>

<p>The <code>mlnormal</code> estimates statistical model for multivariate normally
distributed outcomes with specified mean structure and
covariance structure (see Details and Examples). Model classes include
multilevel models, factor analysis, structural equation models,
multilevel structural equation models, social relations model and
perhaps more.
</p>
<p>The estimation can be conducted under maximum likelihood,
restricted maximum likelihood and
maximum posterior estimation with prior distribution.
Regularization (i.e. LASSO penalties) is also accomodated.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mlnormal(y, X, id, Z_list, Z_index, beta=NULL, theta, method="ML", prior=NULL,
    lambda_beta=NULL, weights_beta=NULL, lambda_theta=NULL, weights_theta=NULL,
    beta_lower=NULL, beta_upper=NULL,    theta_lower=NULL, theta_upper=NULL,
    maxit=800, globconv=1e-05, conv=1e-06, verbose=TRUE, REML_shortcut=NULL,
    use_ginverse=FALSE, vcov=TRUE, variance_shortcut=TRUE, use_Rcpp=TRUE,
    level=0.95, numdiff.parm=1e-04, control_beta=NULL, control_theta=NULL)

## S3 method for class 'mlnormal'
summary(object, digits=4, file=NULL, ...)

## S3 method for class 'mlnormal'
print(x, digits=4, ...)

## S3 method for class 'mlnormal'
coef(object, ...)

## S3 method for class 'mlnormal'
logLik(object, ...)

## S3 method for class 'mlnormal'
vcov(object, ...)

## S3 method for class 'mlnormal'
confint(object, parm, level=.95, ... )
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mlnormal_+3A_y">y</code></td>
<td>

<p>Vector of outcomes
</p>
</td></tr>
<tr><td><code id="mlnormal_+3A_x">X</code></td>
<td>

<p>Matrix of covariates
</p>
</td></tr>
<tr><td><code id="mlnormal_+3A_id">id</code></td>
<td>

<p>Vector of identifiers (subjects or clusters, see Details)
</p>
</td></tr>
<tr><td><code id="mlnormal_+3A_z_list">Z_list</code></td>
<td>

<p>List of design matrices for covariance matrix (see Details)
</p>
</td></tr>
<tr><td><code id="mlnormal_+3A_z_index">Z_index</code></td>
<td>

<p>Array containing loadings of design matrices (see Details).
The dimensions are units <code class="reqn">\times</code> matrices <code class="reqn">\times</code> parameters.
</p>
</td></tr>
<tr><td><code id="mlnormal_+3A_beta">beta</code></td>
<td>

<p>Initial vector for <code class="reqn">\bold{\beta}</code>
</p>
</td></tr>
<tr><td><code id="mlnormal_+3A_theta">theta</code></td>
<td>

<p>Initial vector for <code class="reqn">\bold{\theta}</code>
</p>
</td></tr>
<tr><td><code id="mlnormal_+3A_method">method</code></td>
<td>

<p>Estimation method. Can be either <code>"ML"</code> or <code>"REML"</code>.
</p>
</td></tr>
<tr><td><code id="mlnormal_+3A_prior">prior</code></td>
<td>

<p>Prior distributions. Can be conveniently specified in a string
which is processed by the function <code>prior_model_parse</code>. Only
univariate prior distributions can be specified.
</p>
</td></tr>
<tr><td><code id="mlnormal_+3A_lambda_beta">lambda_beta</code></td>
<td>

<p>Parameter <code class="reqn">\lambda_{\bold{\beta}}</code> for penalty function
<code class="reqn">P( \bold{\beta} )=\lambda_{\bold{\beta}} \sum_h w_{\bold{\beta}h} | \beta _h |</code>
</p>
</td></tr>
<tr><td><code id="mlnormal_+3A_weights_beta">weights_beta</code></td>
<td>

<p>Parameter vector <code class="reqn">\bold{w}_{\bold{\beta}}</code> for penalty function
<code class="reqn">P( \bold{\beta} )=\lambda_{\bold{\beta}} \sum_h w_{\bold{\beta}h} | \beta _h |</code>
</p>
</td></tr>
<tr><td><code id="mlnormal_+3A_lambda_theta">lambda_theta</code></td>
<td>

<p>Parameter <code class="reqn">\lambda_{\bold{\theta}}</code> for penalty function
<code class="reqn">P( \bold{\theta} )=\lambda_{\bold{\theta}}
            \sum_h w_{\bold{\theta}h} | \theta _h | </code>
</p>
</td></tr>
<tr><td><code id="mlnormal_+3A_weights_theta">weights_theta</code></td>
<td>

<p>Parameter vector <code class="reqn">\bold{w}_{\bold{\theta}}</code> for penalty function
<code class="reqn">P( \bold{\theta} )=\lambda_{\bold{\theta}}
          \sum_h w_{\bold{\theta}h} | \theta _h | </code>
</p>
</td></tr>
<tr><td><code id="mlnormal_+3A_beta_lower">beta_lower</code></td>
<td>
<p>Vector containing lower bounds for <code class="reqn">\bold{\beta}</code> parameter</p>
</td></tr>
<tr><td><code id="mlnormal_+3A_beta_upper">beta_upper</code></td>
<td>
<p>Vector containing upper bounds for <code class="reqn">\bold{\beta}</code> parameter</p>
</td></tr>
<tr><td><code id="mlnormal_+3A_theta_lower">theta_lower</code></td>
<td>
<p>Vector containing lower bounds for <code class="reqn">\bold{\theta}</code> parameter</p>
</td></tr>
<tr><td><code id="mlnormal_+3A_theta_upper">theta_upper</code></td>
<td>
<p>Vector containing upper bounds for <code class="reqn">\bold{\theta}</code> parameter</p>
</td></tr>
<tr><td><code id="mlnormal_+3A_maxit">maxit</code></td>
<td>

<p>Maximum number of iterations
</p>
</td></tr>
<tr><td><code id="mlnormal_+3A_globconv">globconv</code></td>
<td>

<p>Convergence criterion deviance
</p>
</td></tr>
<tr><td><code id="mlnormal_+3A_conv">conv</code></td>
<td>

<p>Maximum parameter change
</p>
</td></tr>
<tr><td><code id="mlnormal_+3A_verbose">verbose</code></td>
<td>

<p>Print progress?
</p>
</td></tr>
<tr><td><code id="mlnormal_+3A_reml_shortcut">REML_shortcut</code></td>
<td>

<p>Logical indicating whether computational shortcuts should be used for
REML estimation
</p>
</td></tr>
<tr><td><code id="mlnormal_+3A_use_ginverse">use_ginverse</code></td>
<td>

<p>Logical indicating whether a generalized inverse should be used
</p>
</td></tr>
<tr><td><code id="mlnormal_+3A_vcov">vcov</code></td>
<td>

<p>Logical indicating whether a covariance matrix of
<code class="reqn">\bold{\theta}</code> parameter estimates should be computed in
case of REML (which is computationally demanding)
</p>
</td></tr>
<tr><td><code id="mlnormal_+3A_variance_shortcut">variance_shortcut</code></td>
<td>

<p>Logical indicating whether computational shortcuts for calculating
covariance matrices should be used
</p>
</td></tr>
<tr><td><code id="mlnormal_+3A_use_rcpp">use_Rcpp</code></td>
<td>

<p>Logical indicating whether the <span class="pkg">Rcpp</span> package should be used
</p>
</td></tr>
<tr><td><code id="mlnormal_+3A_level">level</code></td>
<td>

<p>Confidence level
</p>
</td></tr>
<tr><td><code id="mlnormal_+3A_numdiff.parm">numdiff.parm</code></td>
<td>

<p>Numerical differentiation parameter
</p>
</td></tr>
<tr><td><code id="mlnormal_+3A_control_beta">control_beta</code></td>
<td>

<p>List with control arguments for <code class="reqn">\bold{\beta}</code> estimation. The default
is <br /> <code>list( maxiter=10, conv=1E-4, ridge=1E-6)</code>.
</p>
</td></tr>
<tr><td><code id="mlnormal_+3A_control_theta">control_theta</code></td>
<td>

<p>List with control arguments for <code class="reqn">\bold{\theta}</code> estimation. The default
is <br /> <code>list( maxiter=10, conv=1E-4, ridge=1E-6)</code>.
</p>
</td></tr>
<tr><td><code id="mlnormal_+3A_object">object</code></td>
<td>
<p>Object of class <code>mlnormal</code></p>
</td></tr>
<tr><td><code id="mlnormal_+3A_digits">digits</code></td>
<td>
<p>Number of digits used for rounding</p>
</td></tr>
<tr><td><code id="mlnormal_+3A_file">file</code></td>
<td>
<p>File name</p>
</td></tr>
<tr><td><code id="mlnormal_+3A_parm">parm</code></td>
<td>
<p>Parameter to be selected for <code>confint</code> method</p>
</td></tr>
<tr><td><code id="mlnormal_+3A_...">...</code></td>
<td>
<p>Further arguments to be passed</p>
</td></tr>
<tr><td><code id="mlnormal_+3A_x">x</code></td>
<td>
<p>Object of class <code>mlnormal</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>The data consists of outcomes <code class="reqn">\bold{y}_i</code> and covariates <code class="reqn">\bold{X}_i</code>
for unit <code class="reqn">i</code>. The unit can be subjects, clusters (like schools)
or the full outcome vector. It is assumed that <code class="reqn">\bold{y}_i</code> is normally
distributed as <code class="reqn">N( \bold{\mu}_i, \bold{V}_i )</code> where the mean structure is
modelled as </p>
<p style="text-align: center;"><code class="reqn"> \bold{\mu}_i=\bold{X}_i \bold{\beta} </code>
</p>
<p> and the covariance
structure <code class="reqn"> \bold{V}_i</code> depends on a parameter vector <code class="reqn">\bold{\theta}</code>.
More specifically, the covariance matrix <code class="reqn"> \bold{V}_i</code>  is modelled as
a sum of functions of the parameter <code class="reqn">\bold{\theta}</code> and known design matrices
<code class="reqn">\bold{Z}_{im}</code> for unit <code class="reqn">i</code> (<code class="reqn">m=1,\ldots,M</code>). The model is
</p>
<p style="text-align: center;"><code class="reqn">\bold{V}_i=\sum_{m=1}^M \bold{Z}_{im} \gamma_{im}  \qquad \mathrm{with}
\qquad \gamma_{im}=\prod_{h=1}^H \theta_h^{q_{imh}} </code>
</p>

<p>where <code class="reqn">q_{imh}</code> are non-negative known integers specified in
<code>Z_index</code> and <code class="reqn">\bold{Z}_{im}</code> are design matrices specified
in <code>Z_list</code>.
</p>
<p>The estimation follows Fisher scoring (Jiang, 2007; for applications see also
Longford, 1987; Lee, 1990; Gill &amp; Swartz, 2001) and the
regularization approach is as described in Lin, Pang and Jiang (2013)
(see also Krishnapuram, Carin, Figueiredo, &amp; Hartemink, 2005).
</p>


<h3>Value</h3>

<p>List with entries
</p>
<table role = "presentation">
<tr><td><code>theta</code></td>
<td>
<p>Estimated <code class="reqn">\bold{\theta}</code> parameter</p>
</td></tr>
<tr><td><code>beta</code></td>
<td>
<p>Estimated <code class="reqn">\bold{\beta}</code> parameter</p>
</td></tr>
<tr><td><code>theta_summary</code></td>
<td>
<p>Summary of <code class="reqn">\bold{\theta}</code> parameters</p>
</td></tr>
<tr><td><code>beta_summary</code></td>
<td>
<p>Summary of <code class="reqn">\bold{\beta}</code> parameters</p>
</td></tr>
<tr><td><code>coef</code></td>
<td>
<p>Estimated parameters</p>
</td></tr>
<tr><td><code>vcov</code></td>
<td>
<p>Covariance matrix of estimated parameters</p>
</td></tr>
<tr><td><code>ic</code></td>
<td>
<p>Information criteria</p>
</td></tr>
<tr><td><code>V_list</code></td>
<td>
<p>List with fitted covariance matrices <code class="reqn">\bold{V}_i</code></p>
</td></tr>
<tr><td><code>V1_list</code></td>
<td>
<p>List with inverses of fitted covariance matrices <code class="reqn">\bold{V}_i</code></p>
</td></tr>
<tr><td><code>prior_args</code></td>
<td>
<p>Some arguments in case of prior distributions</p>
</td></tr>
<tr><td><code>...</code></td>
<td>
<p>More values</p>
</td></tr>
</table>


<h3>References</h3>

<p>Gill, P. S., &amp; Swartz, T. B. (2001). Statistical analyses for round
robin interaction data.
<em>Canadian Journal of Statistics, 29</em>, 321-331.
<a href="https://doi.org/10.2307/3316080">doi:10.2307/3316080</a>
</p>
<p>Jiang, J. (2007). <em>Linear and generalized linear mixed models and their
applications</em>. New York: Springer.
</p>
<p>Krishnapuram, B., Carin, L., Figueiredo, M. A., &amp; Hartemink, A. J. (2005).
Sparse multinomial logistic regression: Fast algorithms and generalization
bounds. <em>IEEE Transactions on Pattern Analysis and Machine Intelligence, 27</em>, 957-968.
<a href="https://doi.org/10.1109/TPAMI.2005.127">doi:10.1109/TPAMI.2005.127</a>
</p>
<p>Lee, S. Y. (1990). Multilevel analysis of structural equation models.
<em>Biometrika, 77</em>, 763-772.
<a href="https://doi.org/10.1093/biomet/77.4.763">doi:10.1093/biomet/77.4.763</a>
</p>
<p>Lin, B., Pang, Z., &amp; Jiang, J. (2013). Fixed and random effects selection
by REML and pathwise coordinate optimization.
<em>Journal of Computational and Graphical Statistics, 22</em>, 341-355.
<a href="https://doi.org/10.1080/10618600.2012.681219">doi:10.1080/10618600.2012.681219</a>
</p>
<p>Longford, N. T. (1987). A fast scoring algorithm for maximum likelihood
estimation in unbalanced mixed models with nested random effects.
<em>Biometrika, 74</em>, 817-827.
<a href="https://doi.org/10.1093/biomet/74.4.817">doi:10.1093/biomet/74.4.817</a>
</p>


<h3>See Also</h3>

<p>See <span class="pkg">lavaan</span>, <span class="pkg">sem</span>, <span class="pkg">lava</span>, <span class="pkg">OpenMx</span> or <span class="pkg">nlsem</span>
packages for estimation of
(single level) structural equation models.
</p>
<p>See the <span class="pkg">regsem</span>
and <span class="pkg">lsl</span> packages for regularized structural equation models.
</p>
<p>See <span class="pkg">lme4</span> or <span class="pkg">nlme</span> package for estimation of multilevel
models.
</p>
<p>See the <span class="pkg">lmmlasso</span> and <span class="pkg">glmmLasso</span> packages for regularized
mixed effects models.
</p>
<p>See <span class="pkg">OpenMx</span> and <span class="pkg">xxM</span> packages (<em>http://xxm.times.uh.edu/</em>) for
estimation of multilevel structural equation models.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
#############################################################################
# EXAMPLE 1: Two-level random intercept model
#############################################################################

#--------------------------------------------------------------
# Simulate data
#--------------------------------------------------------------

set.seed(976)
G &lt;- 150 ; rg &lt;- c(10,20)   # 150 groups with group sizes ranging from 10 to 20
#* simulate group sizes
ng &lt;- round( stats::runif( G, min=rg[1], max=rg[2] ) )
idcluster &lt;- rep(1:G, ng )
#* simulate covariate
iccx &lt;- .3
x &lt;- rep( stats::rnorm( G, sd=sqrt( iccx) ), ng ) +
            stats::rnorm( sum(ng), sd=sqrt( 1 - iccx) )
#* simulate outcome
b0 &lt;- 1.5 ; b1 &lt;- .4 ; iccy &lt;- .2
y &lt;- b0 + b1*x + rep( stats::rnorm( G, sd=sqrt( iccy) ), ng ) +
         stats::rnorm( sum(ng), sd=sqrt( 1 - iccy) )

#-----------------------
#--- arrange input for mlnormal function

id &lt;- idcluster          # cluster is identifier
X &lt;- cbind( 1, x )      # matrix of covariates
N &lt;- length(id)          # number of units (clusters), which is G

MD &lt;- max(ng)   # maximum number of persons in a group
NP &lt;- 2         # number of covariance parameters theta

#* list of design matrix for covariance matrix
#  In the case of the random intercept model, the covariance structure is
#  tau^2 * J + sigma^2 * I, where J is a matrix of ones and I is the
#  identity matrix
Z &lt;- as.list(1:G)
for (gg in 1:G){
    Ngg &lt;- ng[gg]
    Z[[gg]] &lt;- as.list( 1:2 )
    Z[[gg]][[1]] &lt;- matrix( 1, nrow=Ngg, ncol=Ngg )  # level 2 variance
    Z[[gg]][[2]] &lt;- diag(1,Ngg)            # level 1 variance
}
Z_list &lt;- Z
#* parameter list containing the powers of parameters
Z_index &lt;- array( 0, dim=c(G,2,2) )
Z_index[ 1:G, 1, 1] &lt;- Z_index[ 1:G, 2, 2] &lt;- 1

#** starting values and parameter names
beta &lt;- c( 1, 0 )
names(beta) &lt;- c("int", "x")
theta &lt;- c( .05, 1 )
names(theta) &lt;- c("tau2", "sig2" )

#** create dataset for lme4 for comparison
dat &lt;- data.frame(y=y, x=x, id=id )

#--------------------------------------------------------------
# Model 1: Maximum likelihood estimation
#--------------------------------------------------------------

#** mlnormal function
mod1a &lt;- LAM::mlnormal( y=y, X=X, id=id, Z_list=Z_list, Z_index=Z_index,
            beta=beta, theta=theta, method="ML" )
summary(mod1a)

# lme4::lmer function
library(lme4)
mod1b &lt;- lme4::lmer( y ~ x + (1 | id ), data=dat, REML=FALSE )
summary(mod1b)

#--------------------------------------------------------------
# Model 2: Restricted maximum likelihood estimation
#--------------------------------------------------------------

#** mlnormal function
mod2a &lt;- LAM::mlnormal( y=y, X=X, id=id, Z_list=Z_list, Z_index=Z_index,
            beta=beta, theta=theta, method="REML" )
summary(mod2a)

# lme4::lmer function
mod2b &lt;- lme4::lmer( y ~ x + (1 | id ), data=dat, REML=TRUE )
summary(mod2b)

#--------------------------------------------------------------
# Model 3: Estimation of standard deviation instead of variances
#--------------------------------------------------------------

# The model is now parametrized in standard deviations
# Variances are then modeled as tau^2 and sigma^2, respectively.
Z_index2 &lt;- 2*Z_index       # change loading matrix

# estimate model
mod3 &lt;- LAM::mlnormal( y=y, X=X, id=id, Z_list=Z_list, Z_index=Z_index2,
            beta=beta, theta=theta )
summary(mod3)

#--------------------------------------------------------------
# Model 4: Maximum posterior estimation
#--------------------------------------------------------------

# specify prior distributions for parameters
prior &lt;- "
    tau2 ~ dgamma(NA, 2, .5 )
    sig2 ~ dinvgamma(NA, .1, .1 )
    x ~ dnorm( NA, .2, 1000 )
    "

# estimate model in mlnormal
mod4 &lt;- LAM::mlnormal( y=y, X=X, id=id, Z_list=Z_list, Z_index=Z_index,
            beta=beta, theta=theta, method="REML", prior=prior, vcov=FALSE )
summary(mod4)

#--------------------------------------------------------------
# Model 5: Estimation with regularization on beta and theta parameters
#--------------------------------------------------------------

#*** penalty on theta parameter
lambda_theta &lt;- 10
weights_theta &lt;- 1 + 0 * theta
#*** penalty on beta parameter
lambda_beta &lt;- 3
weights_beta &lt;- c( 0, 1.8 )

# estimate model
mod5 &lt;- LAM::mlnormal( y=y, X=X, id=id, Z_list=Z_list, Z_index=Z_index,
            beta=beta, theta=theta, method="ML", maxit=maxit,
            lambda_theta=lambda_theta, weights_theta=weights_theta,
            lambda_beta=lambda_beta, weights_beta=weights_beta  )
summary(mod5)

#############################################################################
# EXAMPLE 2: Latent covariate model, two-level regression
#############################################################################

# Yb=beta_0 + beta_b*Xb + eb (between level) and
# Yw=beta_w*Xw + ew (within level)

#--------------------------------------------------------------
# Simulate data from latent covariate model
#--------------------------------------------------------------

set.seed(865)
# regression parameters
beta_0 &lt;- 1 ; beta_b &lt;- .7 ; beta_w &lt;- .3
G &lt;- 200      # number of groups
n &lt;- 15      # group size
iccx &lt;- .2   # intra class correlation x
iccy &lt;- .35  # (conditional) intra class correlation y
# simulate latent variables
xb &lt;- stats::rnorm(G, sd=sqrt( iccx ) )
yb &lt;- beta_0 + beta_b * xb + stats::rnorm(G, sd=sqrt( iccy ) )
xw &lt;- stats::rnorm(G*n, sd=sqrt( 1-iccx ) )
yw &lt;- beta_w * xw + stats::rnorm(G*n, sd=sqrt( 1-iccy ) )
group &lt;- rep( 1:G, each=n )
x &lt;- xw + xb[ group ]
y &lt;- yw + yb[ group ]
# test results on true data
lm( yb ~ xb )
lm( yw ~ xw )

# create vector of outcomes in the form
# ( y_11, x_11, y_21, x_21, ... )
dat &lt;- cbind( y, x )
dat
Y &lt;- as.vector( t(dat) )    # outcome vector
ny &lt;- length(Y)
X &lt;- matrix( 0, nrow=ny, ncol=2 )
X[ seq(1,ny,2), 1 ] &lt;- 1   # design vector for mean y
X[ seq(2,ny,2), 2 ] &lt;- 1   # design vector for mean x
id &lt;- rep( group, each=2 )

#--------------------------------------------------------------
# Model 1: Linear regression ignoring multilevel structure
#--------------------------------------------------------------

# y=beta_0 + beta_t *x + e
# Var(y)=beta_t^2 * var_x + var_e
# Cov(y,x)=beta_t * var_x
# Var(x)=var_x

#** initial parameter values
theta &lt;- c( 0, 1, .5 )
names(theta) &lt;- c( "beta_t", "var_x", "var_e")
beta &lt;- c(0,0)
names(beta) &lt;- c("mu_y","mu_x")

# The unit i is a cluster in this example.

#--- define design matrices | list Z_list
Hlist &lt;- list(  matrix( c(1,0,0,0), 2, 2 ), # var(y)
                matrix( c(1,0,0,0), 2, 2 ), # var(y) (two terms)
                matrix( c(0,1,1,0), 2, 2 ), # cov(x,y)
                matrix( c(0,0,0,1), 2, 2 ) ) # var(x)

U0 &lt;- matrix( 0, nrow=2*n,ncol=2*n )
Ulist &lt;- list( U0, U0, U0, U0 )
M &lt;- length(Hlist)
for (mm in 1:M){    # mm &lt;- 1
    for (nn in 1:n){     # nn &lt;- 0
        Ulist[[ mm ]][ 2*(nn-1) + 1:2, 2*(nn-1) + 1:2 ] &lt;- Hlist[[ mm ]]
    }
}
Z_list &lt;- as.list(1:G)
for (gg in 1:G){
    Z_list[[gg]] &lt;- Ulist
}

#--- define index vectors
Z_index &lt;- array( 0, dim=c(G, 4, 3 ) )
K0 &lt;- matrix( 0, nrow=4, ncol=3 )
colnames(K0) &lt;- names(theta)
# Var(y)=beta_t^2 * var_x + var_e  (matrices withn indices 1 and 2)
K0[ 1, c("beta_t","var_x") ] &lt;- c(2,1)  # beta_t^2 * var_x
K0[ 2, c("var_e") ] &lt;- c(1)  # var_e
# Cov(y,x)=beta_t * var_x
K0[ 3, c("beta_t","var_x")] &lt;- c(1,1)
# Var(x)=var_x
K0[ 4, c("var_x") ] &lt;- c(1)
for (gg in 1:G){
    Z_index[gg,,] &lt;- K0
}

#*** estimate model with mlnormal
mod1a &lt;- LAM::mlnormal( y=Y, X=X, id=id, Z_list=Z_list, Z_index=Z_index,
            beta=beta, theta=theta, method="REML", vcov=FALSE )
summary(mod1a)

#*** estimate linear regression with stats::lm
mod1b &lt;- stats::lm( y ~ x )
summary(mod1b)

#--------------------------------------------------------------
# Model 2: Latent covariate model
#--------------------------------------------------------------

#** initial parameters
theta &lt;- c( 0.12, .6, .5, 0, .2, .2 )
names(theta) &lt;- c( "beta_w", "var_xw", "var_ew",
                "beta_b", "var_xb", "var_eb")

#--- define design matrices | list Z_list
Hlist &lt;- list(  matrix( c(1,0,0,0), 2, 2 ), # var(y)
                matrix( c(1,0,0,0), 2, 2 ), # var(y) (two terms)
                matrix( c(0,1,1,0), 2, 2 ), # cov(x,y)
                matrix( c(0,0,0,1), 2, 2 ) ) # var(x)
U0 &lt;- matrix( 0, nrow=2*n,ncol=2*n )
Ulist &lt;- list( U0, U0, U0, U0,  # within structure
               U0, U0, U0, U0  )  # between structure
M &lt;- length(Hlist)
#*** within structure
design_within &lt;- diag(n)  # design matrix within structure
for (mm in 1:M){    # mm &lt;- 1
    Ulist[[ mm ]] &lt;- base::kronecker( design_within, Hlist[[mm]] )
}
#*** between structure
design_between &lt;- matrix(1, nrow=n, ncol=n)
      # matrix of ones corresponding to group size
for (mm in 1:M){    # mm &lt;- 1
    Ulist[[ mm + M ]] &lt;-  base::kronecker( design_between, Hlist[[ mm ]] )
}
Z_list &lt;- as.list(1:G)
for (gg in 1:G){
    Z_list[[gg]] &lt;- Ulist
}

#--- define index vectors Z_index
Z_index &lt;- array( 0, dim=c(G, 8, 6 ) )
K0 &lt;- matrix( 0, nrow=8, ncol=6 )
colnames(K0) &lt;- names(theta)
# Var(y)=beta^2 * var_x + var_e  (matrices withn indices 1 and 2)
K0[ 1, c("beta_w","var_xw") ] &lt;- c(2,1)  # beta_t^2 * var_x
K0[ 2, c("var_ew") ] &lt;- c(1)  # var_e
K0[ 5, c("beta_b","var_xb") ] &lt;- c(2,1)  # beta_t^2 * var_x
K0[ 6, c("var_eb") ] &lt;- c(1)  # var_e
# Cov(y,x)=beta * var_x
K0[ 3, c("beta_w","var_xw")] &lt;- c(1,1)
K0[ 7, c("beta_b","var_xb")] &lt;- c(1,1)
# Var(x)=var_x
K0[ 4, c("var_xw") ] &lt;- c(1)
K0[ 8, c("var_xb") ] &lt;- c(1)
for (gg in 1:G){
    Z_index[gg,,] &lt;- K0
}

#--- estimate model with mlnormal
mod2a &lt;- LAM::mlnormal( y=Y, X=X, id=id, Z_list=Z_list, Z_index=Z_index,
            beta=beta, theta=theta, method="ML" )
summary(mod2a)

#############################################################################
# EXAMPLE 3: Simple linear regression, single level
#############################################################################

#--------------------------------------------------------------
# Simulate data
#--------------------------------------------------------------

set.seed(875)
N &lt;- 300
x &lt;- stats::rnorm( N, sd=1.3 )
y &lt;- .4 + .7 * x + stats::rnorm( N, sd=.5 )
dat &lt;- data.frame( x, y )

#--------------------------------------------------------------
# Model 1: Linear regression modelled with residual covariance structure
#--------------------------------------------------------------

# matrix of predictros
X &lt;- cbind( 1, x )
# list with design matrices
Z &lt;- as.list(1:N)
for (nn in 1:N){
    Z[[nn]] &lt;- as.list( 1 )
    Z[[nn]][[1]] &lt;- matrix( 1, nrow=1, ncol=1 )  # residual variance
}
#* loading matrix
Z_index &lt;- array( 0, dim=c(N,1,1) )
Z_index[ 1:N, 1, 1] &lt;- 2  # parametrize residual standard deviation
#** starting values and parameter names
beta &lt;- c( 0, 0 )
names(beta) &lt;- c("int", "x")
theta &lt;- c(1)
names(theta) &lt;- c("sig2" )
# id vector
id &lt;- 1:N

#** mlnormal function
mod1a &lt;- LAM::mlnormal( y=y, X=X, id=id, Z_list=Z, Z_index=Z_index,
            beta=beta, theta=theta, method="ML" )
summary(mod1a)

# estimate linear regression with stats::lm
mod1b &lt;- stats::lm( y ~ x )
summary(mod1b)

#--------------------------------------------------------------
# Model 2: Linear regression modelled with bivariate covariance structure
#--------------------------------------------------------------

#** define design matrix referring to mean structure
X &lt;- matrix( 0, nrow=2*N, ncol=2 )
X[ seq(1,2*N,2), 1 ] &lt;- X[ seq(2,2*N,2), 2 ] &lt;- 1

#** create outcome vector
y1 &lt;- dat[ cbind( rep(1:N, each=2), rep(1:2, N ) ) ]
#** list with design matrices
Z &lt;- as.list(1:N)
Z0 &lt;- 0*matrix( 0, nrow=2,ncol=2)
ZXY &lt;- ZY &lt;- ZX &lt;- Z0
# design matrix Var(X)
ZX[1,1] &lt;- 1
# design matrix Var(Y)
ZY[2,2] &lt;- 1
# design matrix covariance
ZXY[1,2] &lt;- ZXY[2,1] &lt;- 1
# Var(X)=sigx^2
# Cov(X,Y)=beta * sigx^2
# Var(Y)=beta^2 * sigx^2 + sige^2
Z_list0 &lt;- list( ZY, ZY, ZXY, ZX )
for (nn in 1:N){
    Z[[nn]] &lt;- Z_list0
}
#* parameter list containing the powers of parameters
theta &lt;- c(1,0.3,1)
names(theta) &lt;- c("sigx", "beta", "sige" )
Z_index &lt;- array( 0, dim=c(N,4,3) )
for (nn in 1:N){
    # Var(X)
    Z_index[nn, 4, ] &lt;- c(2,0,0)
    # Cov(X,Y)
    Z_index[nn, 3, ] &lt;- c(2,1,0)
    # Var(Y)
    Z_index[nn,1,] &lt;- c(2,2,0)
    Z_index[nn,2,] &lt;- c(0,0,2)
}
#** starting values and parameter names
beta &lt;- c( 0, 0 )
names(beta) &lt;- c("Mx", "My")
# id vector
id &lt;- rep( 1:N, each=2 )

#** mlnormal function
mod2a &lt;- LAM::mlnormal( y=y1, X=X, id=id, Z_list=Z, Z_index=Z_index,
            beta=beta, theta=theta, method="ML" )
summary(mod2a)

#--------------------------------------------------------------
# Model 3: Bivariate normal distribution in (sigma_X, sigma_Y, sigma_XY) parameters
#--------------------------------------------------------------

# list with design matrices
Z &lt;- as.list(1:N)
Z0 &lt;- 0*matrix( 0, nrow=2,ncol=2)
ZXY &lt;- ZY &lt;- ZX &lt;- Z0
# design matrix Var(X)
ZX[1,1] &lt;- 1
# design matrix Var(Y)
ZY[2,2] &lt;- 1
# design matrix covariance
ZXY[1,2] &lt;- ZXY[2,1] &lt;- 1
Z_list0 &lt;- list( ZX, ZY, ZXY  )
for (nn in 1:N){
    Z[[nn]] &lt;- Z_list0
}

#* parameter list
theta &lt;- c(1,1,.3)
names(theta) &lt;- c("sigx", "sigy", "sigxy" )
Z_index &lt;- array( 0, dim=c(N,3,3) )
for (nn in 1:N){
    # Var(X)
    Z_index[nn, 1, ] &lt;- c(2,0,0)
    # Var(Y)
    Z_index[nn, 2, ] &lt;- c(0,2,0)
    # Cov(X,Y)
    Z_index[nn, 3, ] &lt;- c(0,0,1)
}

#** starting values and parameter names
beta &lt;- c( 0, 0 )
names(beta) &lt;- c("Mx", "My")

#** mlnormal function
mod3a &lt;- LAM::mlnormal( y=y1, X=X, id=id, Z_list=Z, Z_index=Z_index,
            beta=beta, theta=theta, method="ML" )
summary(mod3a)

#--------------------------------------------------------------
# Model 4: Bivariate normal distribution in parameters of Cholesky decomposition
#--------------------------------------------------------------

# list with design matrices
Z &lt;- as.list(1:N)
Z0 &lt;- 0*matrix( 0, nrow=2,ncol=2)
ZXY &lt;- ZY &lt;- ZX &lt;- Z0
# design matrix Var(X)
ZX[1,1] &lt;- 1
# design matrix Var(Y)
ZY[2,2] &lt;- 1
# design matrix covariance
ZXY[1,2] &lt;- ZXY[2,1] &lt;- 1
Z_list0 &lt;- list( ZX, ZXY, ZY, ZY  )
for (nn in 1:N){
    Z[[nn]] &lt;- Z_list0
}

#* parameter list containing the powers of parameters
theta &lt;- c(1,0.3,1)
names(theta) &lt;- c("L11", "L21", "L22" )
Z_index &lt;- array( 0, dim=c(N,4,3) )
for (nn in 1:N){
    Z_index[nn,1,] &lt;- c(2,0,0)
    Z_index[nn,2,] &lt;- c(1,1,0)
    Z_index[nn,3,] &lt;- c(0,2,0)
    Z_index[nn,4,] &lt;- c(0,0,2)
}
#** starting values and parameter names
beta &lt;- c( 0, 0 )
names(beta) &lt;- c("Mx", "My")
# id vector
id &lt;- rep( 1:N, each=2 )
#** mlnormal function
mod4a &lt;- LAM::mlnormal( y=y1, X=X, id=id, Z_list=Z, Z_index=Z_index,
            beta=beta, theta=theta, method="ML" )
# parameter with lower diagonal entries of Cholesky matrix
mod4a$theta
# fill-in parameters for Cholesky matrix
L &lt;- matrix(0,2,2)
L[ ! upper.tri(L) ] &lt;- mod4a$theta
#** reconstruct covariance matrix
L 
stats::cov.wt(dat, method="ML")$cov

## End(Not run)
</code></pre>

<hr>
<h2 id='suff_stat_NA_pattern'>
Sufficient Statistics for Dataset with Missing Response Pattern
</h2><span id='topic+suff_stat_NA_pattern'></span>

<h3>Description</h3>

<p>Computes sufficient statistics for a dataset with an arbitrary missing
response pattern.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>suff_stat_NA_pattern(dat)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="suff_stat_NA_pattern_+3A_dat">dat</code></td>
<td>

<p>Numeric data frame
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with following entries
</p>
<table role = "presentation">
<tr><td><code>nobs</code></td>
<td>
<p>List with number of observations for each missing response pattern</p>
</td></tr>
<tr><td><code>M</code></td>
<td>
<p>List with mean vectors</p>
</td></tr>
<tr><td><code>S</code></td>
<td>
<p>List with covariance matrices</p>
</td></tr>
<tr><td><code>varindex</code></td>
<td>
<p>List with indices of observed variables</p>
</td></tr>
<tr><td><code>NP</code></td>
<td>
<p>Number of missing data patterns</p>
</td></tr>
<tr><td><code>N</code></td>
<td>
<p>Total sample size</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

#############################################################################
# EXAMPLE 1: Toy example for computation of sufficient statistics
#############################################################################

library(STARTS)

data(data.starts01b, package="STARTS")
dat &lt;- data.starts01b
dat1 &lt;- dat[, paste0("E",1:3)]

#-- compute sufficient statistics
res &lt;- LAM::suff_stat_NA_pattern(dat1)
str(res)

## End(Not run)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
