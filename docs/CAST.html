<!DOCTYPE html><html lang="en"><head><title>Help for package CAST</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {CAST}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#CAST'><p>'caret' Applications for Spatial-Temporal Models</p></a></li>
<li><a href='#aoa'><p>Area of Applicability</p></a></li>
<li><a href='#bss'><p>Best subset feature selection</p></a></li>
<li><a href='#clustered_sample'><p>Clustered samples simulation</p></a></li>
<li><a href='#cookfarm'><p>Cookfarm soil logger data</p></a></li>
<li><a href='#CreateSpacetimeFolds'><p>Create Space-time Folds</p></a></li>
<li><a href='#errorProfiles'><p>Model and inspect the relationship between the prediction error and measures of dissimilarities and distances</p></a></li>
<li><a href='#ffs'><p>Forward feature selection</p></a></li>
<li><a href='#geodist'><p>Calculate euclidean nearest neighbor distances in geographic space or feature space</p></a></li>
<li><a href='#global_validation'><p>Evaluate 'global' cross-validation</p></a></li>
<li><a href='#knndm'><p>K-fold Nearest Neighbour Distance Matching</p></a></li>
<li><a href='#nndm'><p>Nearest Neighbour Distance Matching (NNDM) algorithm</p></a></li>
<li><a href='#normalize_DI'><p>Normalize DI values</p></a></li>
<li><a href='#plot'><p>Plot CAST classes</p></a></li>
<li><a href='#print'><p>Print CAST classes</p></a></li>
<li><a href='#splotdata'><p>sPlotOpen Data of Species Richness</p></a></li>
<li><a href='#trainDI'><p>Calculate Dissimilarity Index of training data</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>'caret' Applications for Spatial-Temporal Models</td>
</tr>
<tr>
<td>Version:</td>
<td>1.0.3</td>
</tr>
<tr>
<td>Author:</td>
<td>Hanna Meyer [cre, aut],
  Carles Milà [aut],
  Marvin Ludwig [aut],
  Jan Linnenbrink [aut],
  Fabian Schumacher [aut],
  Philipp Otto [ctb],
  Chris Reudenbach [ctb],
  Thomas Nauss [ctb],
  Edzer Pebesma [ctb],
  Jakub Nowosad [ctb]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Hanna Meyer &lt;hanna.meyer@uni-muenster.de&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Supporting functionality to run 'caret' with spatial or spatial-temporal data. 'caret' is a frequently used package for model training and prediction using machine learning. CAST includes functions to improve spatial or spatial-temporal modelling tasks using 'caret'. It includes the newly suggested 'Nearest neighbor distance matching' cross-validation to estimate the performance of spatial prediction models and allows for spatial variable selection to selects suitable predictor variables in view to their contribution to the spatial model performance. CAST further includes functionality to estimate the (spatial) area of applicability of prediction models. Methods are described in Meyer et al. (2018) &lt;<a href="https://doi.org/10.1016%2Fj.envsoft.2017.12.001">doi:10.1016/j.envsoft.2017.12.001</a>&gt;; Meyer et al. (2019) &lt;<a href="https://doi.org/10.1016%2Fj.ecolmodel.2019.108815">doi:10.1016/j.ecolmodel.2019.108815</a>&gt;; Meyer and Pebesma (2021) &lt;<a href="https://doi.org/10.1111%2F2041-210X.13650">doi:10.1111/2041-210X.13650</a>&gt;; Milà et al. (2022) &lt;<a href="https://doi.org/10.1111%2F2041-210X.13851">doi:10.1111/2041-210X.13851</a>&gt;; Meyer and Pebesma (2022) &lt;<a href="https://doi.org/10.1038%2Fs41467-022-29838-9">doi:10.1038/s41467-022-29838-9</a>&gt;; Linnenbrink et al. (2023) &lt;<a href="https://doi.org/10.5194%2Fegusphere-2023-1308">doi:10.5194/egusphere-2023-1308</a>&gt;; Schumacher et al. (2024) &lt;<a href="https://doi.org/10.5194%2Fegusphere-2024-2730">doi:10.5194/egusphere-2024-2730</a>&gt;. The package is described in detail in Meyer et al. (2024) &lt;<a href="https://doi.org/10.48550%2FarXiv.2404.06978">doi:10.48550/arXiv.2404.06978</a>&gt;.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/HannaMeyer/CAST">https://github.com/HannaMeyer/CAST</a>,
<a href="https://hannameyer.github.io/CAST/">https://hannameyer.github.io/CAST/</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>false</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 4.1.0)</td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/HannaMeyer/CAST/issues/">https://github.com/HannaMeyer/CAST/issues/</a></td>
</tr>
<tr>
<td>Imports:</td>
<td>caret, stats, utils, ggplot2, graphics, FNN, plyr, zoo,
methods, grDevices, data.table, sf, forcats, twosamples, terra,
sp</td>
</tr>
<tr>
<td>Suggests:</td>
<td>doParallel, lubridate, randomForest, knitr, geodata, mapview,
rmarkdown, scales, parallel, gridExtra, viridis, stars, scam,
rnaturalearth, MASS, RColorBrewer, tmap, PCAmixdata, gower,
clustMixType, testthat (&ge; 3.0.0)</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.2</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2025-01-09 19:38:28 UTC; hanna</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2025-01-09 23:00:05 UTC</td>
</tr>
</table>
<hr>
<h2 id='CAST'>'caret' Applications for Spatial-Temporal Models</h2><span id='topic+CAST'></span><span id='topic+CAST-package'></span>

<h3>Description</h3>

<p>Supporting functionality to run 'caret' with spatial or spatial-temporal data.
'caret' is a frequently used package for model training and prediction using machine learning.
CAST includes functions to improve spatial-temporal modelling tasks using 'caret'.
It includes the newly suggested 'Nearest neighbor distance matching' cross-validation to estimate the performance
of spatial prediction models and allows for spatial variable selection to selects suitable predictor variables
in view to their contribution to the spatial model performance.
CAST further includes functionality to estimate the (spatial) area of applicability of prediction models
by analysing the similarity between new data and training data.
Methods are described in Meyer et al. (2018); Meyer et al. (2019); Meyer and Pebesma (2021); Milà et al. (2022); Meyer and Pebesma (2022); Linnenbrink et al. (2023).
The package is described in detail in Meyer et al. (2024).
</p>


<h3>Details</h3>

<p>'caret' Applications for Spatio-Temporal models
</p>


<h3>Author(s)</h3>

<p>Hanna Meyer, Carles Milà, Marvin Ludwig, Jan Linnenbrink, Fabian Schumacher
</p>


<h3>References</h3>


<ul>
<li><p> Meyer, H., Ludwig, L., Milà, C., Linnenbrink, J., Schumacher, F. (2024): The CAST package for training and assessment of spatial prediction models in R. arXiv, https://doi.org/10.48550/arXiv.2404.06978.
</p>
</li>
<li><p> Linnenbrink, J., Milà, C., Ludwig, M., and Meyer, H.: kNNDM: k-fold Nearest Neighbour Distance Matching Cross-Validation for map accuracy estimation, EGUsphere [preprint], https://doi.org/10.5194/egusphere-2023-1308, 2023.
</p>
</li>
<li><p> Milà, C., Mateu, J., Pebesma, E., Meyer, H. (2022): Nearest Neighbour Distance Matching Leave-One-Out Cross-Validation for map validation. Methods in Ecology and Evolution 00, 1– 13.
</p>
</li>
<li><p> Meyer, H., Pebesma, E. (2022): Machine learning-based global maps of ecological variables and the challenge of assessing them. Nature Communications. 13.
</p>
</li>
<li><p> Meyer, H., Pebesma, E. (2021): Predicting into unknown space? Estimating the area of applicability of spatial prediction models. Methods in Ecology and Evolution. 12, 1620– 1633.
</p>
</li>
<li><p> Meyer, H., Reudenbach, C., Wöllauer, S., Nauss, T. (2019): Importance of spatial predictor variable selection in machine learning applications - Moving from data reproduction to spatial prediction. Ecological Modelling. 411, 108815.
</p>
</li>
<li><p> Meyer, H., Reudenbach, C., Hengl, T., Katurji, M., Nauß, T. (2018): Improving performance of spatio-temporal machine learning models using forward feature selection and target-oriented validation. Environmental Modelling &amp; Software 101: 1-9.
</p>
</li></ul>



<h3>See Also</h3>

<p>Useful links:
</p>

<ul>
<li> <p><a href="https://github.com/HannaMeyer/CAST">https://github.com/HannaMeyer/CAST</a>
</p>
</li>
<li> <p><a href="https://hannameyer.github.io/CAST/">https://hannameyer.github.io/CAST/</a>
</p>
</li>
<li><p> Report bugs at <a href="https://github.com/HannaMeyer/CAST/issues/">https://github.com/HannaMeyer/CAST/issues/</a>
</p>
</li></ul>


<hr>
<h2 id='aoa'>Area of Applicability</h2><span id='topic+aoa'></span>

<h3>Description</h3>

<p>This function estimates the Dissimilarity Index (DI) and the derived
Area of Applicability (AOA) of spatial prediction models by
considering the distance of new data (i.e. a SpatRaster of spatial predictors
used in the models) in the predictor variable space to the data used for model
training. Predictors can be weighted based on the internal
variable importance of the machine learning algorithm used for model training.
The AOA is derived by applying a threshold on the DI which is the (outlier-removed)
maximum DI of the cross-validated training data.
Optionally, the local point density is calculated which indicates the number of similar training data points up to the DI threshold.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>aoa(
  newdata,
  model = NA,
  trainDI = NA,
  train = NULL,
  weight = NA,
  variables = "all",
  CVtest = NULL,
  CVtrain = NULL,
  method = "L2",
  useWeight = TRUE,
  useCV = TRUE,
  LPD = FALSE,
  maxLPD = 1,
  indices = FALSE,
  verbose = TRUE,
  algorithm = "brute"
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="aoa_+3A_newdata">newdata</code></td>
<td>
<p>A SpatRaster, stars object or data.frame containing the data
the model was meant to make predictions for.</p>
</td></tr>
<tr><td><code id="aoa_+3A_model">model</code></td>
<td>
<p>A train object created with caret used to extract weights from (based on variable importance) as well as cross-validation folds.
See examples for the case that no model is available or for models trained via e.g. mlr3.</p>
</td></tr>
<tr><td><code id="aoa_+3A_traindi">trainDI</code></td>
<td>
<p>A trainDI object. Optional if <code><a href="#topic+trainDI">trainDI</a></code> was calculated beforehand.</p>
</td></tr>
<tr><td><code id="aoa_+3A_train">train</code></td>
<td>
<p>A data.frame containing the data used for model training. Optional. Only required when no model is given</p>
</td></tr>
<tr><td><code id="aoa_+3A_weight">weight</code></td>
<td>
<p>A data.frame containing weights for each variable. Optional. Only required if no model is given.</p>
</td></tr>
<tr><td><code id="aoa_+3A_variables">variables</code></td>
<td>
<p>character vector of predictor variables. if &quot;all&quot; then all variables
of the model are used or if no model is given then of the train dataset.</p>
</td></tr>
<tr><td><code id="aoa_+3A_cvtest">CVtest</code></td>
<td>
<p>list or vector. Either a list where each element contains the data points used for testing during the cross validation iteration (i.e. held back data).
Or a vector that contains the ID of the fold for each training point.
Only required if no model is given.</p>
</td></tr>
<tr><td><code id="aoa_+3A_cvtrain">CVtrain</code></td>
<td>
<p>list. Each element contains the data points used for training during the cross validation iteration (i.e. held back data).
Only required if no model is given and only required if CVtrain is not the opposite of CVtest (i.e. if a data point is not used for testing, it is used for training).
Relevant if some data points are excluded, e.g. when using <code><a href="#topic+nndm">nndm</a></code>.</p>
</td></tr>
<tr><td><code id="aoa_+3A_method">method</code></td>
<td>
<p>Character. Method used for distance calculation. Currently euclidean distance (L2) and Mahalanobis distance (MD) are implemented but only L2 is tested. Note that MD takes considerably longer.</p>
</td></tr>
<tr><td><code id="aoa_+3A_useweight">useWeight</code></td>
<td>
<p>Logical. Only if a model is given. Weight variables according to importance in the model?</p>
</td></tr>
<tr><td><code id="aoa_+3A_usecv">useCV</code></td>
<td>
<p>Logical. Only if a model is given. Use the CV folds to calculate the DI threshold?</p>
</td></tr>
<tr><td><code id="aoa_+3A_lpd">LPD</code></td>
<td>
<p>Logical. Indicates whether the local point density should be calculated or not.</p>
</td></tr>
<tr><td><code id="aoa_+3A_maxlpd">maxLPD</code></td>
<td>
<p>numeric or integer. Only if <code>LPD = TRUE</code>. Number of nearest neighbors to be considered for the calculation of the LPD. Either define a number between 0 and 1 to use a percentage of the number of training samples for the LPD calculation or a whole number larger than 1 and smaller than the number of training samples. CAUTION! If not all training samples are considered, a fitted relationship between LPD and error metric will not make sense (@seealso <code><a href="#topic+DItoErrormetric">DItoErrormetric</a></code>)</p>
</td></tr>
<tr><td><code id="aoa_+3A_indices">indices</code></td>
<td>
<p>logical. Calculate indices of the training data points that are responsible for the LPD of a new prediction location? Output is a matrix with the dimensions num(raster_cells) x maxLPD. Each row holds the indices of the training data points that are relevant for the specific LPD value at that location. Can be used in combination with exploreAOA(aoa) function from the <a href="https://github.com/fab-scm/CASTvis">CASTvis package</a> for a better visual interpretation of the results. Note that the matrix can be quite big for examples with a high resolution and a larger number of training samples, which can cause memory issues.</p>
</td></tr>
<tr><td><code id="aoa_+3A_verbose">verbose</code></td>
<td>
<p>Logical. Print progress or not?</p>
</td></tr>
<tr><td><code id="aoa_+3A_algorithm">algorithm</code></td>
<td>
<p>see <code><a href="FNN.html#topic+knnx.dist">knnx.dist</a></code> and <code><a href="FNN.html#topic+knnx.index">knnx.index</a></code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Dissimilarity Index (DI), the Local Data Point Density (LPD) and the corresponding Area of Applicability (AOA) are calculated.
If variables are factors, dummy variables are created prior to weighting and distance calculation.
</p>
<p>Interpretation of results: If a location is very similar to the properties
of the training data it will have a low distance in the predictor variable space
(DI towards 0) while locations that are very different in their properties
will have a high DI. For easier interpretation see <code><a href="#topic+normalize_DI">normalize_DI</a></code>
See Meyer and Pebesma (2021) for the full documentation of the methodology.
</p>


<h3>Value</h3>

<p>An object of class <code>aoa</code> containing:
</p>
<table role = "presentation">
<tr><td><code>parameters</code></td>
<td>
<p>object of class trainDI. see <code><a href="#topic+trainDI">trainDI</a></code></p>
</td></tr>
<tr><td><code>DI</code></td>
<td>
<p>SpatRaster, stars object or data frame. Dissimilarity index of newdata</p>
</td></tr>
<tr><td><code>LPD</code></td>
<td>
<p>SpatRaster, stars object or data frame. Local Point Density of newdata.</p>
</td></tr>
<tr><td><code>AOA</code></td>
<td>
<p>SpatRaster, stars object or data frame. Area of Applicability of newdata. AOA has values 0 (outside AOA) and 1 (inside AOA)</p>
</td></tr>
</table>


<h3>Note</h3>

<p>If classification models are used, currently the variable importance can only
be automatically retrieved if models were trained via train(predictors,response) and not via the formula-interface.
Will be fixed.
</p>


<h3>Author(s)</h3>

<p>Hanna Meyer, Fabian Schumacher
</p>


<h3>References</h3>

<p>Meyer, H., Pebesma, E. (2021): Predicting into unknown space?
Estimating the area of applicability of spatial prediction models.
Methods in Ecology and Evolution 12: 1620-1633. <a href="https://doi.org/10.1111/2041-210X.13650">doi:10.1111/2041-210X.13650</a>
</p>
<p>Schumacher, F., Knoth, C., Ludwig, M., Meyer, H. (2024):
Estimation of local training data point densities to support the assessment
of spatial prediction uncertainty. EGUsphere. <a href="https://doi.org/10.5194/egusphere-2024-2730">doi:10.5194/egusphere-2024-2730</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+trainDI">trainDI</a></code>, <code><a href="#topic+normalize_DI">normalize_DI</a></code>, <code><a href="#topic+errorProfiles">errorProfiles</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(sf)
library(terra)
library(caret)
library(viridis)

# prepare sample data:
data(cookfarm)
dat &lt;- aggregate(cookfarm[,c("VW","Easting","Northing")],
   by=list(as.character(cookfarm$SOURCEID)),mean)
pts &lt;- st_as_sf(dat,coords=c("Easting","Northing"),crs=26911)
pts$ID &lt;- 1:nrow(pts)
set.seed(100)
pts &lt;- pts[1:30,]
studyArea &lt;- rast(system.file("extdata","predictors_2012-03-25.tif",package="CAST"))[[1:8]]
trainDat &lt;- extract(studyArea,pts,na.rm=FALSE)
trainDat &lt;- merge(trainDat,pts,by.x="ID",by.y="ID")

# visualize data spatially:
plot(studyArea)
plot(studyArea$DEM)
plot(pts[,1],add=TRUE,col="black")

# train a model:
set.seed(100)
variables &lt;- c("DEM","NDRE.Sd","TWI")
model &lt;- train(trainDat[,which(names(trainDat)%in%variables)],
trainDat$VW, method="rf", importance=TRUE, tuneLength=1,
trControl=trainControl(method="cv",number=5,savePredictions=T))
print(model) #note that this is a quite poor prediction model
prediction &lt;- predict(studyArea,model,na.rm=TRUE)
plot(varImp(model,scale=FALSE))

#...then calculate the AOA of the trained model for the study area:
AOA &lt;- aoa(studyArea, model)
plot(AOA)
plot(AOA$AOA)
#... or if preferred calculate the aoa and the LPD of the study area:
AOA &lt;- aoa(studyArea, model, LPD = TRUE, maxLPD = 1)
plot(AOA$LPD)

####
#The AOA can also be calculated without a trained model.
#All variables are weighted equally in this case:
####
AOA &lt;- aoa(studyArea,train=trainDat,variables=variables)


####
# The AOA can also be used for models trained via mlr3 (parameters have to be assigned manually):
####

library(mlr3)
library(mlr3learners)
library(mlr3spatial)
library(mlr3spatiotempcv)
library(mlr3extralearners)

# initiate and train model:
train_df &lt;- trainDat[, c("DEM","NDRE.Sd","TWI", "VW")]
backend &lt;- as_data_backend(train_df)
task &lt;- as_task_regr(backend, target = "VW")
lrn &lt;- lrn("regr.randomForest", importance = "mse")
lrn$train(task)

# cross-validation folds
rsmp_cv &lt;- rsmp("cv", folds = 5L)$instantiate(task)

## predict:
prediction &lt;- predict(studyArea,lrn$model,na.rm=TRUE)

### Estimate AOA
AOA &lt;- aoa(studyArea,
           train = as.data.frame(task$data()),
           variables = task$feature_names,
           weight = data.frame(t(lrn$importance())),
           CVtest = rsmp_cv$instance[order(row_id)]$fold)


## End(Not run)
</code></pre>

<hr>
<h2 id='bss'>Best subset feature selection</h2><span id='topic+bss'></span>

<h3>Description</h3>

<p>Evaluate all combinations of predictors during model training
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bss(
  predictors,
  response,
  method = "rf",
  metric = ifelse(is.factor(response), "Accuracy", "RMSE"),
  maximize = ifelse(metric == "RMSE", FALSE, TRUE),
  globalval = FALSE,
  trControl = caret::trainControl(),
  tuneLength = 3,
  tuneGrid = NULL,
  seed = 100,
  verbose = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="bss_+3A_predictors">predictors</code></td>
<td>
<p>see <code><a href="caret.html#topic+train">train</a></code></p>
</td></tr>
<tr><td><code id="bss_+3A_response">response</code></td>
<td>
<p>see <code><a href="caret.html#topic+train">train</a></code></p>
</td></tr>
<tr><td><code id="bss_+3A_method">method</code></td>
<td>
<p>see <code><a href="caret.html#topic+train">train</a></code></p>
</td></tr>
<tr><td><code id="bss_+3A_metric">metric</code></td>
<td>
<p>see <code><a href="caret.html#topic+train">train</a></code></p>
</td></tr>
<tr><td><code id="bss_+3A_maximize">maximize</code></td>
<td>
<p>see <code><a href="caret.html#topic+train">train</a></code></p>
</td></tr>
<tr><td><code id="bss_+3A_globalval">globalval</code></td>
<td>
<p>Logical. Should models be evaluated based on 'global' performance? See <code><a href="#topic+global_validation">global_validation</a></code></p>
</td></tr>
<tr><td><code id="bss_+3A_trcontrol">trControl</code></td>
<td>
<p>see <code><a href="caret.html#topic+train">train</a></code></p>
</td></tr>
<tr><td><code id="bss_+3A_tunelength">tuneLength</code></td>
<td>
<p>see <code><a href="caret.html#topic+train">train</a></code></p>
</td></tr>
<tr><td><code id="bss_+3A_tunegrid">tuneGrid</code></td>
<td>
<p>see <code><a href="caret.html#topic+train">train</a></code></p>
</td></tr>
<tr><td><code id="bss_+3A_seed">seed</code></td>
<td>
<p>A random number</p>
</td></tr>
<tr><td><code id="bss_+3A_verbose">verbose</code></td>
<td>
<p>Logical. Should information about the progress be printed?</p>
</td></tr>
<tr><td><code id="bss_+3A_...">...</code></td>
<td>
<p>arguments passed to the classification or regression routine
(such as randomForest).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>bss is an alternative to <code><a href="#topic+ffs">ffs</a></code> and ideal if the training
set is small. Models are iteratively fitted using all different combinations
of predictor variables. Hence, 2^X models are calculated. Don't try running bss
on very large datasets because the computation time is much higher compared to
<code><a href="#topic+ffs">ffs</a></code>.
</p>
<p>The internal cross validation can be run in parallel. See information
on parallel processing of carets train functions for details.
</p>


<h3>Value</h3>

<p>A list of class train. Beside of the usual train content
the object contains the vector &quot;selectedvars&quot; and &quot;selectedvars_perf&quot;
that give the best variables selected as well as their corresponding
performance. It also contains &quot;perf_all&quot; that gives the performance of all model runs.
</p>


<h3>Note</h3>

<p>This variable selection is particularly suitable for spatial
cross validations where variable selection
MUST be based on the performance of the model for predicting new spatial units.
Note that bss is very slow since all combinations of variables are tested.
A more time efficient alternative is the forward feature selection (<code><a href="#topic+ffs">ffs</a></code>).
</p>


<h3>Author(s)</h3>

<p>Hanna Meyer
</p>


<h3>See Also</h3>

<p><code><a href="caret.html#topic+train">train</a></code>,<code><a href="#topic+ffs">ffs</a></code>,
<code><a href="caret.html#topic+trainControl">trainControl</a></code>,<code><a href="#topic+CreateSpacetimeFolds">CreateSpacetimeFolds</a></code>,
<code><a href="#topic+nndm">nndm</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(iris)
bssmodel &lt;- bss(iris[,1:4],iris$Species)
bssmodel$perf_all
plot(bssmodel)

## End(Not run)
</code></pre>

<hr>
<h2 id='clustered_sample'>Clustered samples simulation</h2><span id='topic+clustered_sample'></span>

<h3>Description</h3>

<p>A simple procedure to simulate clustered points based on a two-step sampling.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>clustered_sample(sarea, nsamples, nparents, radius)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="clustered_sample_+3A_sarea">sarea</code></td>
<td>
<p>polygon. Area where samples should be simulated.</p>
</td></tr>
<tr><td><code id="clustered_sample_+3A_nsamples">nsamples</code></td>
<td>
<p>integer. Number of samples to be simulated.</p>
</td></tr>
<tr><td><code id="clustered_sample_+3A_nparents">nparents</code></td>
<td>
<p>integer. Number of parents.</p>
</td></tr>
<tr><td><code id="clustered_sample_+3A_radius">radius</code></td>
<td>
<p>integer. Radius of the buffer around each parent for offspring simulation.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A simple procedure to simulate clustered points based on a two-step sampling.
First, a pre-specified number of parents are simulated using random sampling.
For each parent, '(nsamples-nparents)/nparents' are simulated within a radius of the parent point using random sampling.
</p>


<h3>Value</h3>

<p>sf object with the simulated points and the parent to which each point belongs to.
</p>


<h3>Author(s)</h3>

<p>Carles Milà
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Simulate 100 points in a 100x100 square with 5 parents and a radius of 10.
library(sf)
library(ggplot2)

set.seed(1234)
simarea &lt;- list(matrix(c(0,0,0,100,100,100,100,0,0,0), ncol=2, byrow=TRUE))
simarea &lt;- sf::st_polygon(simarea)
simpoints &lt;- clustered_sample(simarea, 100, 5, 10)
simpoints$parent &lt;- as.factor(simpoints$parent)
ggplot() +
    geom_sf(data = simarea, alpha = 0) +
    geom_sf(data = simpoints, aes(col = parent))

</code></pre>

<hr>
<h2 id='cookfarm'>Cookfarm soil logger data</h2><span id='topic+cookfarm'></span>

<h3>Description</h3>

<p>spatio-temporal data of soil properties and associated predictors for the Cookfarm in Washington, USA.
The data are a subset of the cookfarm dataset provided with the <a href="https://CRAN.R-project.org/package=GSIF">GSIF package</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(cookfarm)
</code></pre>


<h3>Format</h3>

<p>A sf data.frame with 128545 rows and 17 columns:
</p>

<dl>
<dt>SOURCEID</dt><dd><p>ID of the logger</p>
</dd>
<dt>VW</dt><dd><p>Response Variable - Soil Moisture</p>
</dd>
<dt>altitude</dt><dd><p>Measurement depth of VW</p>
</dd>
<dt>Date, cdata</dt><dd><p>Measurement Date, Cumulative Date</p>
</dd>
<dt>Easting, Northing</dt><dd><p>Location Coordinates (EPSG:26911)</p>
</dd>
<dt>DEM, TWI, NDRE.M, NDRE.Sd, Precip_wrcc, MaxT_wrcc, MinT_wrcc, Precip_cum</dt><dd><p>Predictor Variables</p>
</dd>
</dl>



<h3>References</h3>


<ul>
<li><p>Gash et al. 2015 - Spatio-temporal interpolation of soil water, temperature, and electrical conductivity in 3D + T: The Cook Agronomy Farm data set <a href="https://doi.org/10.1016/j.spasta.2015.04.001">doi:10.1016/j.spasta.2015.04.001</a>
</p>
</li>
<li><p>Meyer et al. 2018 - Improving performance of spatio-temporal machine learning models using forward feature selection and target-oriented validation <a href="https://doi.org/10.1016/j.envsoft.2017.12.001">doi:10.1016/j.envsoft.2017.12.001</a>
</p>
</li></ul>


<hr>
<h2 id='CreateSpacetimeFolds'>Create Space-time Folds</h2><span id='topic+CreateSpacetimeFolds'></span>

<h3>Description</h3>

<p>Create spatial, temporal or spatio-temporal Folds for cross validation based on pre-defined groups
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CreateSpacetimeFolds(
  x,
  spacevar = NA,
  timevar = NA,
  k = 10,
  class = NA,
  seed = sample(1:1000, 1)
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="CreateSpacetimeFolds_+3A_x">x</code></td>
<td>
<p>data.frame containing spatio-temporal data</p>
</td></tr>
<tr><td><code id="CreateSpacetimeFolds_+3A_spacevar">spacevar</code></td>
<td>
<p>Character indicating which column of x identifies the
spatial units (e.g. ID of weather stations)</p>
</td></tr>
<tr><td><code id="CreateSpacetimeFolds_+3A_timevar">timevar</code></td>
<td>
<p>Character indicating which column of x identifies the
temporal units (e.g. the day of the year)</p>
</td></tr>
<tr><td><code id="CreateSpacetimeFolds_+3A_k">k</code></td>
<td>
<p>numeric. Number of folds. If spacevar or timevar is NA and a
leave one location out or leave one time step out cv should be performed,
set k to the number of unique spatial or temporal units.</p>
</td></tr>
<tr><td><code id="CreateSpacetimeFolds_+3A_class">class</code></td>
<td>
<p>Character indicating which column of x identifies a class unit (e.g. land cover)</p>
</td></tr>
<tr><td><code id="CreateSpacetimeFolds_+3A_seed">seed</code></td>
<td>
<p>numeric. See ?seed</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function creates train and test sets by taking (spatial and/or temporal) groups into account.
In contrast to <code><a href="#topic+nndm">nndm</a></code>, it requires that the groups are already defined (e.g. spatial clusters or blocks or temporal units).
Using &quot;class&quot; is helpful in the case that data are clustered in space
and are categorical. E.g This is the case for land cover classifications when
training data come as training polygons. In this case the data should be split in a way
that entire polygons are held back (spacevar=&quot;polygonID&quot;) but at the same time the distribution of classes
should be similar in each fold (class=&quot;LUC&quot;).
</p>


<h3>Value</h3>

<p>A list that contains a list for model training and a list for
model validation that can directly be used as &quot;index&quot; and &quot;indexOut&quot; in
caret's trainControl function
</p>


<h3>Note</h3>

<p>Standard k-fold cross-validation can lead to considerable misinterpretation in spatial-temporal modelling tasks.
This function can be used to prepare a Leave-Location-Out, Leave-Time-Out or Leave-Location-and-Time-Out cross-validation
as target-oriented validation strategies for spatial-temporal prediction tasks.
See Meyer et al. (2018) for further information. CreateSpaceTiemFolds is just a evry simple approach and the suitability depends on the choice of the groups.
You may check the suitability with <code><a href="#topic+geodist">geodist</a></code>. Consider <code><a href="#topic+nndm">nndm</a></code> or <code><a href="#topic+knndm">knndm</a></code> as alternatives or other approaches such as Spatial Blocks.
</p>


<h3>Author(s)</h3>

<p>Hanna Meyer
</p>


<h3>References</h3>

<p>Meyer, H., Reudenbach, C., Hengl, T., Katurji, M., Nauß, T. (2018): Improving performance of spatio-temporal machine learning models using forward feature selection and target-oriented validation. Environmental Modelling &amp; Software 101: 1-9.
</p>


<h3>See Also</h3>

<p><code><a href="caret.html#topic+trainControl">trainControl</a></code>,<code><a href="#topic+ffs">ffs</a></code>, <code><a href="#topic+nndm">nndm</a></code>, <code><a href="#topic+geodist">geodist</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(cookfarm)
### Prepare for 10-fold Leave-Location-and-Time-Out cross validation
indices &lt;- CreateSpacetimeFolds(cookfarm,"SOURCEID","Date")
str(indices)
### Prepare for 10-fold Leave-Location-Out cross validation
indices &lt;- CreateSpacetimeFolds(dat,spacevar="SOURCEID")
str(indices)
### Prepare for leave-One-Location-Out cross validation
indices &lt;- CreateSpacetimeFolds(dat,spacevar="SOURCEID",
    k=length(unique(dat$SOURCEID)))
str(indices)

## End(Not run)
</code></pre>

<hr>
<h2 id='errorProfiles'>Model and inspect the relationship between the prediction error and measures of dissimilarities and distances</h2><span id='topic+errorProfiles'></span><span id='topic+DItoErrormetric'></span>

<h3>Description</h3>

<p>Performance metrics are calculated for moving windows of dissimilarity values based on cross-validated training data
</p>


<h3>Usage</h3>

<pre><code class='language-R'>errorProfiles(
  model,
  trainDI = NULL,
  locations = NULL,
  variable = "DI",
  multiCV = FALSE,
  length.out = 10,
  window.size = 5,
  calib = "scam",
  method = "L2",
  useWeight = TRUE,
  k = 6,
  m = 2
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="errorProfiles_+3A_model">model</code></td>
<td>
<p>the model used to get the AOA</p>
</td></tr>
<tr><td><code id="errorProfiles_+3A_traindi">trainDI</code></td>
<td>
<p>the result of <code><a href="#topic+trainDI">trainDI</a></code> or aoa object <code><a href="#topic+aoa">aoa</a></code></p>
</td></tr>
<tr><td><code id="errorProfiles_+3A_locations">locations</code></td>
<td>
<p>Optional. sf object for the training data used in model. Only used if variable==&quot;geodist&quot;. Note that they must be in the same order as model$trainingData.</p>
</td></tr>
<tr><td><code id="errorProfiles_+3A_variable">variable</code></td>
<td>
<p>Character. Which dissimilarity or distance measure to use for the error metric. Current options are &quot;DI&quot; or &quot;LPD&quot;</p>
</td></tr>
<tr><td><code id="errorProfiles_+3A_multicv">multiCV</code></td>
<td>
<p>Logical. Re-run model fitting and validation with different CV strategies. See details.</p>
</td></tr>
<tr><td><code id="errorProfiles_+3A_length.out">length.out</code></td>
<td>
<p>Numeric. Only used if multiCV=TRUE. Number of cross-validation folds. See details.</p>
</td></tr>
<tr><td><code id="errorProfiles_+3A_window.size">window.size</code></td>
<td>
<p>Numeric. Size of the moving window. See <code><a href="zoo.html#topic+rollapply">rollapply</a></code>.</p>
</td></tr>
<tr><td><code id="errorProfiles_+3A_calib">calib</code></td>
<td>
<p>Character. Function to model the DI/LPD~performance relationship. Currently lm and scam are supported</p>
</td></tr>
<tr><td><code id="errorProfiles_+3A_method">method</code></td>
<td>
<p>Character. Method used for distance calculation. Currently euclidean distance (L2) and Mahalanobis distance (MD) are implemented but only L2 is tested. Note that MD takes considerably longer. See ?aoa for further explanation</p>
</td></tr>
<tr><td><code id="errorProfiles_+3A_useweight">useWeight</code></td>
<td>
<p>Logical. Only if a model is given. Weight variables according to importance in the model?</p>
</td></tr>
<tr><td><code id="errorProfiles_+3A_k">k</code></td>
<td>
<p>Numeric. See mgcv::s</p>
</td></tr>
<tr><td><code id="errorProfiles_+3A_m">m</code></td>
<td>
<p>Numeric. See mgcv::s</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If multiCV=TRUE the model is re-fitted and validated by length.out new cross-validations where the cross-validation folds are defined by clusters in the predictor space,
ranging from three clusters to LOOCV. Hence, a large range of dissimilarity values is created during cross-validation.
If the AOA threshold based on the calibration data from multiple CV is larger than the original AOA threshold (which is likely if extrapolation situations are created during CV),
the AOA threshold changes accordingly. See Meyer and Pebesma (2021) for the full documentation of the methodology.
</p>


<h3>Value</h3>

<p>A scam, linear model or exponential model
</p>


<h3>Author(s)</h3>

<p>Hanna Meyer, Marvin Ludwig, Fabian Schumacher
</p>


<h3>References</h3>

<p>Meyer, H., Pebesma, E. (2021): Predicting into unknown space?
Estimating the area of applicability of spatial prediction models.
<a href="https://doi.org/10.1111/2041-210X.13650">doi:10.1111/2041-210X.13650</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+aoa">aoa</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(CAST)
library(sf)
library(terra)
library(caret)

data(splotdata)
predictors &lt;- terra::rast(system.file("extdata","predictors_chile.tif", package="CAST"))

model &lt;- caret::train(st_drop_geometry(splotdata)[,6:16], splotdata$Species_richness,
   ntree = 10, trControl = trainControl(method = "cv", savePredictions = TRUE))

AOA &lt;- aoa(predictors, model, LPD = TRUE, maxLPD = 1)

### DI ~ error
errormodel_DI &lt;- errorProfiles(model, AOA, variable = "DI")
plot(errormodel_DI)
summary(errormodel_DI)

expected_error_DI = terra::predict(AOA$DI, errormodel_DI)
plot(expected_error_DI)

### LPD ~ error
errormodel_LPD &lt;- errorProfiles(model, AOA, variable = "LPD")
plot(errormodel_LPD)
summary(errormodel_DI)

expected_error_LPD = terra::predict(AOA$LPD, errormodel_LPD)
plot(expected_error_LPD)

### geodist ~ error
errormodel_geodist = errorProfiles(model, locations=splotdata, variable = "geodist")
plot(errormodel_geodist)
summary(errormodel_DI)

dist &lt;- terra::distance(predictors[[1]],vect(splotdata))
names(dist) &lt;- "geodist"
expected_error_DI &lt;- terra::predict(dist, errormodel_geodist)
plot(expected_error_DI)


### with multiCV = TRUE (for DI ~ error)
errormodel_DI = errorProfiles(model, AOA, multiCV = TRUE, length.out = 3, variable = "DI")
plot(errormodel_DI)

expected_error_DI = terra::predict(AOA$DI, errormodel_DI)
plot(expected_error_DI)

# mask AOA based on new threshold from multiCV
mask_aoa = terra::mask(expected_error_DI, AOA$DI &gt; attr(errormodel_DI, 'AOA_threshold'),
  maskvalues = 1)
plot(mask_aoa)

## End(Not run)


</code></pre>

<hr>
<h2 id='ffs'>Forward feature selection</h2><span id='topic+ffs'></span>

<h3>Description</h3>

<p>A simple forward feature selection algorithm
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ffs(
  predictors,
  response,
  method = "rf",
  metric = ifelse(is.factor(response), "Accuracy", "RMSE"),
  maximize = ifelse(metric == "RMSE", FALSE, TRUE),
  globalval = FALSE,
  withinSE = FALSE,
  minVar = 2,
  trControl = caret::trainControl(),
  tuneLength = 3,
  tuneGrid = NULL,
  seed = sample(1:1000, 1),
  verbose = TRUE,
  cores = 1,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ffs_+3A_predictors">predictors</code></td>
<td>
<p>see <code><a href="caret.html#topic+train">train</a></code></p>
</td></tr>
<tr><td><code id="ffs_+3A_response">response</code></td>
<td>
<p>see <code><a href="caret.html#topic+train">train</a></code></p>
</td></tr>
<tr><td><code id="ffs_+3A_method">method</code></td>
<td>
<p>see <code><a href="caret.html#topic+train">train</a></code></p>
</td></tr>
<tr><td><code id="ffs_+3A_metric">metric</code></td>
<td>
<p>see <code><a href="caret.html#topic+train">train</a></code></p>
</td></tr>
<tr><td><code id="ffs_+3A_maximize">maximize</code></td>
<td>
<p>see <code><a href="caret.html#topic+train">train</a></code></p>
</td></tr>
<tr><td><code id="ffs_+3A_globalval">globalval</code></td>
<td>
<p>Logical. Should models be evaluated based on 'global' performance? See <code><a href="#topic+global_validation">global_validation</a></code></p>
</td></tr>
<tr><td><code id="ffs_+3A_withinse">withinSE</code></td>
<td>
<p>Logical Models are only selected if they are better than the
currently best models Standard error</p>
</td></tr>
<tr><td><code id="ffs_+3A_minvar">minVar</code></td>
<td>
<p>Numeric. Number of variables to combine for the first selection.
See Details.</p>
</td></tr>
<tr><td><code id="ffs_+3A_trcontrol">trControl</code></td>
<td>
<p>see <code><a href="caret.html#topic+train">train</a></code></p>
</td></tr>
<tr><td><code id="ffs_+3A_tunelength">tuneLength</code></td>
<td>
<p>see <code><a href="caret.html#topic+train">train</a></code></p>
</td></tr>
<tr><td><code id="ffs_+3A_tunegrid">tuneGrid</code></td>
<td>
<p>see <code><a href="caret.html#topic+train">train</a></code></p>
</td></tr>
<tr><td><code id="ffs_+3A_seed">seed</code></td>
<td>
<p>A random number used for model training</p>
</td></tr>
<tr><td><code id="ffs_+3A_verbose">verbose</code></td>
<td>
<p>Logical. Should information about the progress be printed?</p>
</td></tr>
<tr><td><code id="ffs_+3A_cores">cores</code></td>
<td>
<p>Numeric. If &gt; 2, mclapply will be used. see <code><a href="parallel.html#topic+mclapply">mclapply</a></code></p>
</td></tr>
<tr><td><code id="ffs_+3A_...">...</code></td>
<td>
<p>arguments passed to the classification or regression routine
(such as randomForest).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Models with two predictors are first trained using all possible
pairs of predictor variables. The best model of these initial models is kept.
On the basis of this best model the predictor variables are iteratively
increased and each of the remaining variables is tested for its improvement
of the currently best model. The process stops if none of the remaining
variables increases the model performance when added to the current best model.
</p>
<p>The forward feature selection can be run in parallel with forking on Linux systems (mclapply).
Each fork computes a model, which drastically speeds up the runtime -
especially of the initial predictor search.
The internal cross validation can be run in parallel on all systems. See information
on parallel processing of carets train functions for details.
</p>
<p>Using withinSE will favour models with less variables and
probably shorten the calculation time
</p>
<p>Per Default, the ffs starts with all possible 2-pair combinations.
minVar allows to start the selection with more than 2 variables, e.g.
minVar=3 starts the ffs testing all combinations of 3 (instead of 2) variables
first and then increasing the number. This is important for e.g. neural networks
that often cannot make sense of only two variables. It is also relevant if
it is assumed that the optimal variables can only be found if more than 2
are considered at the same time.
</p>


<h3>Value</h3>

<p>A list of class train. Beside of the usual train content
the object contains the vector &quot;selectedvars&quot; and &quot;selectedvars_perf&quot;
that give the order of the best variables selected as well as their corresponding
performance (starting from the first two variables). It also contains &quot;perf_all&quot;
that gives the performance of all model runs.
</p>


<h3>Note</h3>

<p>This variable selection is particularly suitable for spatial
cross validations where variable selection
MUST be based on the performance of the model for predicting new spatial units.
See Meyer et al. (2018) and Meyer et al. (2019) for further details.
</p>


<h3>Author(s)</h3>

<p>Hanna Meyer
</p>


<h3>References</h3>


<ul>
<li><p> Gasch, C.K., Hengl, T., Gräler, B., Meyer, H., Magney, T., Brown, D.J. (2015): Spatio-temporal interpolation of soil water, temperature, and electrical conductivity in 3D+T: the Cook Agronomy Farm data set. Spatial Statistics 14: 70-90.
</p>
</li>
<li><p> Meyer, H., Reudenbach, C., Hengl, T., Katurji, M., Nauß, T. (2018): Improving performance of spatio-temporal machine learning models using forward feature selection and target-oriented validation. Environmental Modelling &amp; Software 101: 1-9.  <a href="https://doi.org/10.1016/j.envsoft.2017.12.001">doi:10.1016/j.envsoft.2017.12.001</a>
</p>
</li>
<li><p> Meyer, H., Reudenbach, C., Wöllauer, S., Nauss, T. (2019): Importance of spatial predictor variable selection in machine learning applications - Moving from data reproduction to spatial prediction. Ecological Modelling. 411, 108815. <a href="https://doi.org/10.1016/j.ecolmodel.2019.108815">doi:10.1016/j.ecolmodel.2019.108815</a>.
</p>
</li>
<li><p> Ludwig, M., Moreno-Martinez, A., Hölzel, N., Pebesma, E., Meyer, H. (2023): Assessing and improving the transferability of current global spatial prediction models. Global Ecology and Biogeography. <a href="https://doi.org/10.1111/geb.13635">doi:10.1111/geb.13635</a>.
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="caret.html#topic+train">train</a></code>,<code><a href="#topic+bss">bss</a></code>,
<code><a href="caret.html#topic+trainControl">trainControl</a></code>,<code><a href="#topic+CreateSpacetimeFolds">CreateSpacetimeFolds</a></code>,<code><a href="#topic+nndm">nndm</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(splotdata)
ffsmodel &lt;- ffs(splotdata[,6:12], splotdata$Species_richness, ntree = 20)

ffsmodel$selectedvars
ffsmodel$selectedvars_perf
plot(ffsmodel)
#or only selected variables:
plot(ffsmodel,plotType="selected")

## End(Not run)

# or perform model with target-oriented validation (LLO CV)
#the example is described in Gasch et al. (2015). The ffs approach for this dataset is described in
#Meyer et al. (2018). Due to high computation time needed, only a small and thus not robust example
#is shown here.

## Not run: 
# run the model on three cores (see vignette for details):
library(doParallel)
library(lubridate)
cl &lt;- makeCluster(3)
registerDoParallel(cl)

#load and prepare dataset:
data(cookfarm)
trainDat &lt;- cookfarm[cookfarm$altitude==-0.3&amp;
  year(cookfarm$Date)==2012&amp;week(cookfarm$Date)%in%c(13:14),]

#visualize dataset:
ggplot(data = trainDat, aes(x=Date, y=VW)) + geom_line(aes(colour=SOURCEID))

#create folds for Leave Location Out Cross Validation:
set.seed(10)
indices &lt;- CreateSpacetimeFolds(trainDat,spacevar = "SOURCEID",k=3)
ctrl &lt;- trainControl(method="cv",index = indices$index)

#define potential predictors:
predictors &lt;- c("DEM","TWI","BLD","Precip_cum","cday","MaxT_wrcc",
"Precip_wrcc","NDRE.M","Bt","MinT_wrcc","Northing","Easting")

#run ffs model with Leave Location out CV
set.seed(10)
ffsmodel &lt;- ffs(trainDat[,predictors],trainDat$VW,method="rf",
tuneLength=1,trControl=ctrl)
ffsmodel
plot(ffsmodel)
#or only selected variables:
plot(ffsmodel,plotType="selected")

#compare to model without ffs:
model &lt;- train(trainDat[,predictors],trainDat$VW,method="rf",
tuneLength=1, trControl=ctrl)
model
stopCluster(cl)

## End(Not run)

## Not run: 
## on linux machines, you can also run the ffs in parallel with forks:
data("splotdata")
spatial_cv = CreateSpacetimeFolds(splotdata, spacevar = "Biome", k = 5)
ctrl &lt;- trainControl(method="cv",index = spatial_cv$index)

ffsmodel &lt;- ffs(predictors = splotdata[,6:16],
               response = splotdata$Species_richness,
               tuneLength = 1,
               method = "rf",
               trControl = ctrl,
               ntree = 20,
               seed = 1,
               cores = 4)

## End(Not run)


</code></pre>

<hr>
<h2 id='geodist'>Calculate euclidean nearest neighbor distances in geographic space or feature space</h2><span id='topic+geodist'></span>

<h3>Description</h3>

<p>Calculates nearest neighbor distances in geographic space or feature space between training data as well as between training data and prediction locations.
Optional, the nearest neighbor distances between training data and test data or between training data and CV iterations is computed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>geodist(
  x,
  modeldomain = NULL,
  type = "geo",
  cvfolds = NULL,
  cvtrain = NULL,
  testdata = NULL,
  preddata = NULL,
  samplesize = 2000,
  sampling = "regular",
  variables = NULL,
  timevar = NULL,
  time_unit = "auto",
  algorithm = "brute"
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="geodist_+3A_x">x</code></td>
<td>
<p>object of class sf, training data locations</p>
</td></tr>
<tr><td><code id="geodist_+3A_modeldomain">modeldomain</code></td>
<td>
<p>SpatRaster, stars or sf object defining the prediction area (see Details)</p>
</td></tr>
<tr><td><code id="geodist_+3A_type">type</code></td>
<td>
<p>&quot;geo&quot; or &quot;feature&quot;. Should the distance be computed in geographic space or in the normalized multivariate predictor space (see Details)</p>
</td></tr>
<tr><td><code id="geodist_+3A_cvfolds">cvfolds</code></td>
<td>
<p>optional. list or vector. Either a list where each element contains the data points used for testing during the cross validation iteration (i.e. held back data).
Or a vector that contains the ID of the fold for each training point. See e.g. ?createFolds or ?CreateSpacetimeFolds or ?nndm</p>
</td></tr>
<tr><td><code id="geodist_+3A_cvtrain">cvtrain</code></td>
<td>
<p>optional. List of row indices of x to fit the model to in each CV iteration. If cvtrain is null but cvfolds is not, all samples but those included in cvfolds are used as training data</p>
</td></tr>
<tr><td><code id="geodist_+3A_testdata">testdata</code></td>
<td>
<p>optional. object of class sf: Point data used for independent validation</p>
</td></tr>
<tr><td><code id="geodist_+3A_preddata">preddata</code></td>
<td>
<p>optional. object of class sf: Point data indicating the locations within the modeldomain to be used as target prediction points. Useful when the prediction objective is a subset of
locations within the modeldomain rather than the whole area.</p>
</td></tr>
<tr><td><code id="geodist_+3A_samplesize">samplesize</code></td>
<td>
<p>numeric. How many prediction samples should be used?</p>
</td></tr>
<tr><td><code id="geodist_+3A_sampling">sampling</code></td>
<td>
<p>character. How to draw prediction samples? See <a href="sp.html#topic+spsample">spsample</a>. Use sampling = &quot;Fibonacci&quot; for global applications.</p>
</td></tr>
<tr><td><code id="geodist_+3A_variables">variables</code></td>
<td>
<p>character vector defining the predictor variables used if type=&quot;feature. If not provided all variables included in modeldomain are used.</p>
</td></tr>
<tr><td><code id="geodist_+3A_timevar">timevar</code></td>
<td>
<p>optional. character. Column that indicates the date. Only used if type=&quot;time&quot;.</p>
</td></tr>
<tr><td><code id="geodist_+3A_time_unit">time_unit</code></td>
<td>
<p>optional. Character. Unit for temporal distances See ?difftime.Only used if type=&quot;time&quot;.</p>
</td></tr>
<tr><td><code id="geodist_+3A_algorithm">algorithm</code></td>
<td>
<p>see <code><a href="FNN.html#topic+knnx.dist">knnx.dist</a></code> and <code><a href="FNN.html#topic+knnx.index">knnx.index</a></code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>The modeldomain is a sf polygon or a raster that defines the prediction area. The function takes a regular point sample (amount defined by samplesize) from the spatial extent.
If type = &quot;feature&quot;, the argument modeldomain (and if provided then also the testdata and/or preddata) has to include predictors. Predictor values for x, testdata and preddata are optional if modeldomain is a raster.
If not provided they are extracted from the modeldomain rasterStack. If some predictors are categorical (i.e., of class factor or character), gower distances will be used.
W statistic describes the match between the distributions. See Linnenbrink et al (2023) for further details.
</p>


<h3>Value</h3>

<p>A data.frame containing the distances. Unit of returned geographic distances is meters. attributes contain W statistic between prediction area and either sample data, CV folds or test data. See details.
</p>


<h3>Note</h3>

<p>See Meyer and Pebesma (2022) for an application of this plotting function
</p>


<h3>Author(s)</h3>

<p>Hanna Meyer, Edzer Pebesma, Marvin Ludwig, Jan Linnenbrink
</p>


<h3>See Also</h3>

<p><code><a href="#topic+nndm">nndm</a></code> <code><a href="#topic+knndm">knndm</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(CAST)
library(sf)
library(terra)
library(caret)
library(rnaturalearth)
library(ggplot2)

data(splotdata)
studyArea &lt;- rnaturalearth::ne_countries(continent = "South America", returnclass = "sf")

########### Distance between training data and new data:
dist &lt;- geodist(splotdata, studyArea)
# With density functions
plot(dist)
# Or ECDFs (relevant for nndm and knnmd methods)
plot(dist, stat="ecdf")

########### Distance between training data, new data and test data (here Chile):
plot(splotdata[,"Country"])
dist &lt;- geodist(splotdata[splotdata$Country != "Chile",], studyArea,
                testdata = splotdata[splotdata$Country == "Chile",])
plot(dist)

########### Distance between training data, new data and CV folds:
folds &lt;- createFolds(1:nrow(splotdata), k=3, returnTrain=FALSE)
dist &lt;- geodist(x=splotdata, modeldomain=studyArea, cvfolds=folds)
# Using density functions
plot(dist)
# Using ECDFs (relevant for nndm and knnmd methods)
plot(dist, stat="ecdf")

########### Distances in the feature space:
predictors &lt;- terra::rast(system.file("extdata","predictors_chile.tif", package="CAST"))
dist &lt;- geodist(x = splotdata,
                modeldomain = predictors,
                type = "feature",
                variables = c("bio_1","bio_12", "elev"))
plot(dist)

dist &lt;- geodist(x = splotdata[splotdata$Country != "Chile",],
                modeldomain = predictors, cvfolds = folds,
                testdata = splotdata[splotdata$Country == "Chile",],
                type = "feature",
                variables=c("bio_1","bio_12", "elev"))
plot(dist)

############Distances in temporal space
library(lubridate)
library(ggplot2)
data(cookfarm)
dat &lt;- st_as_sf(cookfarm,coords=c("Easting","Northing"))
st_crs(dat) &lt;- 26911
trainDat &lt;- dat[dat$altitude==-0.3&amp;lubridate::year(dat$Date)==2010,]
predictionDat &lt;- dat[dat$altitude==-0.3&amp;lubridate::year(dat$Date)==2011,]
trainDat$week &lt;- lubridate::week(trainDat$Date)
cvfolds &lt;- CreateSpacetimeFolds(trainDat,timevar = "week")

dist &lt;- geodist(trainDat,preddata = predictionDat,cvfolds = cvfolds$indexOut,
   type="time",time_unit="days")
plot(dist)+ xlim(0,10)


############ Example for a random global dataset
############ (refer to figure in Meyer and Pebesma 2022)

### Define prediction area (here: global):
ee &lt;- st_crs("+proj=eqearth")
co &lt;- ne_countries(returnclass = "sf")
co.ee &lt;- st_transform(co, ee)

### Simulate a spatial random sample
### (alternatively replace pts_random by a real sampling dataset (see Meyer and Pebesma 2022):
sf_use_s2(FALSE)
pts_random &lt;- st_sample(co.ee, 2000, exact=FALSE)

### See points on the map:
ggplot() + geom_sf(data = co.ee, fill="#00BFC4",col="#00BFC4") +
  geom_sf(data = pts_random, color = "#F8766D",size=0.5, shape=3) +
  guides(fill = "none", col = "none") +
  labs(x = NULL, y = NULL)

### plot distances:
dist &lt;- geodist(pts_random,co.ee)
plot(dist) + scale_x_log10(labels=round)





## End(Not run)
</code></pre>

<hr>
<h2 id='global_validation'>Evaluate 'global' cross-validation</h2><span id='topic+global_validation'></span>

<h3>Description</h3>

<p>Calculate validation metric using all held back predictions at once
</p>


<h3>Usage</h3>

<pre><code class='language-R'>global_validation(model)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="global_validation_+3A_model">model</code></td>
<td>
<p>an object of class <code><a href="caret.html#topic+train">train</a></code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>Relevant when folds are not representative for the entire area of interest.
In this case, metrics like R2 are not meaningful since it doesn't reflect the general ability of
the model to explain the entire gradient of the response.
Comparable to LOOCV, predictions from all held back folds are used here together to calculate validation statistics.
</p>


<h3>Value</h3>

<p>regression (<code><a href="caret.html#topic+postResample">postResample</a></code>) or classification  (<code><a href="caret.html#topic+confusionMatrix">confusionMatrix</a></code>) statistics
</p>


<h3>Author(s)</h3>

<p>Hanna Meyer
</p>


<h3>See Also</h3>

<p><code><a href="#topic+CreateSpacetimeFolds">CreateSpacetimeFolds</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(caret)
data(cookfarm)
dat &lt;- cookfarm[sample(1:nrow(cookfarm),500),]
indices &lt;- CreateSpacetimeFolds(dat,"SOURCEID","Date")
ctrl &lt;- caret::trainControl(method="cv",index = indices$index,savePredictions="final")
model &lt;- caret::train(dat[,c("DEM","TWI","BLD")],dat$VW, method="rf", trControl=ctrl, ntree=10)
global_validation(model)

## End(Not run)
</code></pre>

<hr>
<h2 id='knndm'>K-fold Nearest Neighbour Distance Matching</h2><span id='topic+knndm'></span>

<h3>Description</h3>

<p>This function implements the kNNDM algorithm and returns the necessary
indices to perform a k-fold NNDM CV for map validation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>knndm(
  tpoints,
  modeldomain = NULL,
  predpoints = NULL,
  space = "geographical",
  k = 10,
  maxp = 0.5,
  clustering = "hierarchical",
  linkf = "ward.D2",
  samplesize = 1000,
  sampling = "regular",
  useMD = FALSE,
  algorithm = "brute"
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="knndm_+3A_tpoints">tpoints</code></td>
<td>
<p>sf or sfc point object, or data.frame if space = &quot;feature&quot;. Contains the training points samples.</p>
</td></tr>
<tr><td><code id="knndm_+3A_modeldomain">modeldomain</code></td>
<td>
<p>sf polygon object or SpatRaster defining the prediction area. Optional; alternative to predpoints (see Details).</p>
</td></tr>
<tr><td><code id="knndm_+3A_predpoints">predpoints</code></td>
<td>
<p>sf or sfc point object, or data.frame if space = &quot;feature&quot;. Contains the target prediction points. Optional; alternative to modeldomain (see Details).</p>
</td></tr>
<tr><td><code id="knndm_+3A_space">space</code></td>
<td>
<p>character. Either &quot;geographical&quot; or &quot;feature&quot;.</p>
</td></tr>
<tr><td><code id="knndm_+3A_k">k</code></td>
<td>
<p>integer. Number of folds desired for CV. Defaults to 10.</p>
</td></tr>
<tr><td><code id="knndm_+3A_maxp">maxp</code></td>
<td>
<p>numeric. Maximum fold size allowed, defaults to 0.5, i.e. a single fold can hold a maximum of half of the training points.</p>
</td></tr>
<tr><td><code id="knndm_+3A_clustering">clustering</code></td>
<td>
<p>character. Possible values include &quot;hierarchical&quot; and &quot;kmeans&quot;. See details.</p>
</td></tr>
<tr><td><code id="knndm_+3A_linkf">linkf</code></td>
<td>
<p>character. Only relevant if clustering = &quot;hierarchical&quot;. Link function for agglomerative hierarchical clustering.
Defaults to &quot;ward.D2&quot;. Check 'stats::hclust' for other options.</p>
</td></tr>
<tr><td><code id="knndm_+3A_samplesize">samplesize</code></td>
<td>
<p>numeric. How many points in the modeldomain should be sampled as prediction points?
Only required if modeldomain is used instead of predpoints.</p>
</td></tr>
<tr><td><code id="knndm_+3A_sampling">sampling</code></td>
<td>
<p>character. How to draw prediction points from the modeldomain? See 'sf::st_sample'.
Only required if modeldomain is used instead of predpoints.</p>
</td></tr>
<tr><td><code id="knndm_+3A_usemd">useMD</code></td>
<td>
<p>boolean. Only for 'space'=feature: shall the Mahalanobis distance be calculated instead of Euclidean?
Only works with numerical variables.</p>
</td></tr>
<tr><td><code id="knndm_+3A_algorithm">algorithm</code></td>
<td>
<p>see <code><a href="FNN.html#topic+knnx.dist">knnx.dist</a></code> and <code><a href="FNN.html#topic+knnx.index">knnx.index</a></code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>knndm is a k-fold version of NNDM LOO CV for medium and large datasets. Brielfy, the algorithm tries to
find a k-fold configuration such that the integral of the absolute differences (Wasserstein W statistic)
between the empirical nearest neighbour distance distribution function between the test and training data during CV (Gj*),
and the empirical nearest neighbour distance distribution function between the prediction and training points (Gij),
is minimised. It does so by performing clustering of the training points' coordinates for different numbers of
clusters that range from k to N (number of observations), merging them into k final folds,
and selecting the configuration with the lowest W.
</p>
<p>Using a projected CRS in 'knndm' has large computational advantages since fast nearest neighbour search can be
done via the 'FNN' package, while working with geographic coordinates requires computing the full
spherical distance matrices. As a clustering algorithm, 'kmeans' can only be used for
projected CRS while 'hierarchical' can work with both projected and geographical coordinates, though it requires
calculating the full distance matrix of the training points even for a projected CRS.
</p>
<p>In order to select between clustering algorithms and number of folds 'k', different 'knndm' configurations can be run
and compared, being the one with a lower W statistic the one that offers a better match. W statistics between 'knndm'
runs are comparable as long as 'tpoints' and 'predpoints' or 'modeldomain' stay the same.
</p>
<p>Map validation using 'knndm' should be used using 'CAST::global_validation', i.e. by stacking all out-of-sample
predictions and evaluating them all at once. The reasons behind this are 1) The resulting folds can be
unbalanced and 2) nearest neighbour functions are constructed and matched using all CV folds simultaneously.
</p>
<p>If training data points are very clustered with respect to the prediction area and the presented 'knndm'
configuration still show signs of Gj* &gt; Gij, there are several things that can be tried. First, increase
the 'maxp' parameter; this may help to control for strong clustering (at the cost of having unbalanced folds).
Secondly, decrease the number of final folds 'k', which may help to have larger clusters.
</p>
<p>The 'modeldomain' is either a sf polygon that defines the prediction area, or alternatively a SpatRaster out of which a polygon,
transformed into the CRS of the training points, is defined as the outline of all non-NA cells.
Then, the function takes a regular point sample (amount defined by 'samplesize') from the spatial extent.
As an alternative use 'predpoints' instead of 'modeldomain', if you have already defined the prediction locations (e.g. raster pixel centroids).
When using either 'modeldomain' or 'predpoints', we advise to plot the study area polygon and the training/prediction points as a previous step to ensure they are aligned.
</p>
<p>'knndm' can also be performed in the feature space by setting 'space' to &quot;feature&quot;.
Euclidean distances or Mahalanobis distances can be used for distance calculation, but only Euclidean are tested.
In this case, nearest neighbour distances are calculated in n-dimensional feature space rather than in geographical space.
'tpoints' and 'predpoints' can be data frames or sf objects containing the values of the features. Note that the names of 'tpoints' and 'predpoints' must be the same.
'predpoints' can also be missing, if 'modeldomain' is of class SpatRaster. In this case, the values of of the SpatRaster will be extracted to the 'predpoints'.
In the case of any categorical features, Gower distances will be used to calculate the Nearest Neighbour distances [Experimental]. If categorical
features are present, and 'clustering' = &quot;kmeans&quot;, K-Prototype clustering will be performed instead.
</p>


<h3>Value</h3>

<p>An object of class <em>knndm</em> consisting of a list of eight elements:
indx_train, indx_test (indices of the observations to use as
training/test data in each kNNDM CV iteration), Gij (distances for
G function construction between prediction and target points), Gj
(distances for G function construction during LOO CV), Gjstar (distances
for modified G function during kNNDM CV), clusters (list of cluster IDs),
W (Wasserstein statistic), and space (stated by the user in the function call).
</p>


<h3>Author(s)</h3>

<p>Carles Milà and Jan Linnenbrink
</p>


<h3>References</h3>


<ul>
<li><p> Linnenbrink, J., Milà, C., Ludwig, M., and Meyer, H.: kNNDM: k-fold Nearest Neighbour Distance Matching Cross-Validation for map accuracy estimation, EGUsphere [preprint], https://doi.org/10.5194/egusphere-2023-1308, 2023.
</p>
</li>
<li><p> Milà, C., Mateu, J., Pebesma, E., Meyer, H. (2022): Nearest Neighbour Distance Matching Leave-One-Out Cross-Validation for map validation. Methods in Ecology and Evolution 00, 1– 13.
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+geodist">geodist</a></code>, <code><a href="#topic+nndm">nndm</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>########################################################################
# Example 1: Simulated data - Randomly-distributed training points
########################################################################

library(sf)
library(ggplot2)

# Simulate 1000 random training points in a 100x100 square
set.seed(1234)
simarea &lt;- list(matrix(c(0,0,0,100,100,100,100,0,0,0), ncol=2, byrow=TRUE))
simarea &lt;- sf::st_polygon(simarea)
train_points &lt;- sf::st_sample(simarea, 1000, type = "random")
pred_points &lt;- sf::st_sample(simarea, 1000, type = "regular")
plot(simarea)
plot(pred_points, add = TRUE, col = "blue")
plot(train_points, add = TRUE, col = "red")

# Run kNNDM for the whole domain, here the prediction points are known.
knndm_folds &lt;- knndm(train_points, predpoints = pred_points, k = 5)
knndm_folds
plot(knndm_folds)
plot(knndm_folds, type = "simple") # For more accessible legend labels
plot(knndm_folds, type = "simple", stat = "density") # To visualize densities rather than ECDFs
folds &lt;- as.character(knndm_folds$clusters)
ggplot() +
  geom_sf(data = simarea, alpha = 0) +
  geom_sf(data = train_points, aes(col = folds))

########################################################################
# Example 2: Simulated data - Clustered training points
########################################################################
## Not run: 
library(sf)
library(ggplot2)

# Simulate 1000 clustered training points in a 100x100 square
set.seed(1234)
simarea &lt;- list(matrix(c(0,0,0,100,100,100,100,0,0,0), ncol=2, byrow=TRUE))
simarea &lt;- sf::st_polygon(simarea)
train_points &lt;- clustered_sample(simarea, 1000, 50, 5)
pred_points &lt;- sf::st_sample(simarea, 1000, type = "regular")
plot(simarea)
plot(pred_points, add = TRUE, col = "blue")
plot(train_points, add = TRUE, col = "red")

# Run kNNDM for the whole domain, here the prediction points are known.
knndm_folds &lt;- knndm(train_points, predpoints = pred_points, k = 5)
knndm_folds
plot(knndm_folds)
plot(knndm_folds, type = "simple") # For more accessible legend labels
plot(knndm_folds, type = "simple", stat = "density") # To visualize densities rather than ECDFs
folds &lt;- as.character(knndm_folds$clusters)
ggplot() +
  geom_sf(data = simarea, alpha = 0) +
  geom_sf(data = train_points, aes(col = folds))

## End(Not run)
########################################################################
# Example 3: Real- world example; using a modeldomain instead of previously
# sampled prediction locations
########################################################################
## Not run: 
library(sf)
library(terra)
library(ggplot2)

### prepare sample data:
data(cookfarm)
dat &lt;- aggregate(cookfarm[,c("DEM","TWI", "NDRE.M", "Easting", "Northing","VW")],
   by=list(as.character(cookfarm$SOURCEID)),mean)
pts &lt;- dat[,-1]
pts &lt;- st_as_sf(pts,coords=c("Easting","Northing"))
st_crs(pts) &lt;- 26911
studyArea &lt;- rast(system.file("extdata","predictors_2012-03-25.tif",package="CAST"))
pts &lt;- st_transform(pts, crs = st_crs(studyArea))
terra::plot(studyArea[["DEM"]])
terra::plot(vect(pts), add = T)

knndm_folds &lt;- knndm(pts, modeldomain=studyArea, k = 5)
knndm_folds
plot(knndm_folds)
folds &lt;- as.character(knndm_folds$clusters)
ggplot() +
  geom_sf(data = pts, aes(col = folds))

#use for cross-validation:
library(caret)
ctrl &lt;- trainControl(method="cv",
   index=knndm_folds$indx_train,
   savePredictions='final')
model_knndm &lt;- train(dat[,c("DEM","TWI", "NDRE.M")],
   dat$VW,
   method="rf",
   trControl = ctrl)
global_validation(model_knndm)

## End(Not run)
########################################################################
# Example 4: Real- world example; kNNDM in feature space
########################################################################
## Not run: 
library(sf)
library(terra)
library(ggplot2)

data(splotdata)
splotdata &lt;- splotdata[splotdata$Country == "Chile",]

predictors &lt;- c("bio_1", "bio_4", "bio_5", "bio_6",
               "bio_8", "bio_9", "bio_12", "bio_13",
               "bio_14", "bio_15", "elev")

trainDat &lt;- sf::st_drop_geometry(splotdata)
predictors_sp &lt;- terra::rast(system.file("extdata", "predictors_chile.tif",package="CAST"))


terra::plot(predictors_sp[["bio_1"]])
terra::plot(vect(splotdata), add = T)

knndm_folds &lt;- knndm(trainDat[,predictors], modeldomain = predictors_sp, space = "feature",
                    clustering="kmeans", k=4, maxp=0.8)
plot(knndm_folds)


## End(Not run)
</code></pre>

<hr>
<h2 id='nndm'>Nearest Neighbour Distance Matching (NNDM) algorithm</h2><span id='topic+nndm'></span>

<h3>Description</h3>

<p>This function implements the NNDM algorithm and returns the necessary indices to perform a NNDM LOO CV for map validation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nndm(
  tpoints,
  modeldomain = NULL,
  predpoints = NULL,
  space = "geographical",
  samplesize = 1000,
  sampling = "regular",
  phi = "max",
  min_train = 0.5,
  algorithm = "brute"
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="nndm_+3A_tpoints">tpoints</code></td>
<td>
<p>sf or sfc point object, or data.frame if space = &quot;feature&quot;. Contains the training points samples.</p>
</td></tr>
<tr><td><code id="nndm_+3A_modeldomain">modeldomain</code></td>
<td>
<p>sf polygon object or SpatRaster defining the prediction area. Optional; alternative to predpoints (see Details).</p>
</td></tr>
<tr><td><code id="nndm_+3A_predpoints">predpoints</code></td>
<td>
<p>sf or sfc point object, or data.frame if space = &quot;feature&quot;. Contains the target prediction points. Optional; alternative to modeldomain (see Details).</p>
</td></tr>
<tr><td><code id="nndm_+3A_space">space</code></td>
<td>
<p>character. Either &quot;geographical&quot; or &quot;feature&quot;. Feature space is still experimental, so use with caution.</p>
</td></tr>
<tr><td><code id="nndm_+3A_samplesize">samplesize</code></td>
<td>
<p>numeric. How many points in the modeldomain should be sampled as prediction points?
Only required if modeldomain is used instead of predpoints.</p>
</td></tr>
<tr><td><code id="nndm_+3A_sampling">sampling</code></td>
<td>
<p>character. How to draw prediction points from the modeldomain? See 'sf::st_sample'.
Only required if modeldomain is used instead of predpoints.</p>
</td></tr>
<tr><td><code id="nndm_+3A_phi">phi</code></td>
<td>
<p>Numeric. Estimate of the landscape autocorrelation range in the
same units as the tpoints and predpoints for projected CRS, in meters for geographic CRS.
Per default (phi=&quot;max&quot;), the maximum distance found in the training and prediction points is used. See Details.</p>
</td></tr>
<tr><td><code id="nndm_+3A_min_train">min_train</code></td>
<td>
<p>Numeric between 0 and 1. Minimum proportion of training
data that must be used in each CV fold. Defaults to 0.5 (i.e. half of the training points).</p>
</td></tr>
<tr><td><code id="nndm_+3A_algorithm">algorithm</code></td>
<td>
<p>see <code><a href="FNN.html#topic+knnx.dist">knnx.dist</a></code> and <code><a href="FNN.html#topic+knnx.index">knnx.index</a></code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>NNDM proposes a LOO CV scheme such that the nearest neighbour distance distribution function between the test and training data during the CV process is matched to the nearest neighbour
distance distribution function between the prediction and training points. Details of the method can be found in Milà et al. (2022).
</p>
<p>Specifying <em>phi</em> allows limiting distance matching to the area where this is assumed to be relevant due to spatial autocorrelation.
Distances are only matched up to <em>phi</em>. Beyond that range, all data points are used for training, without exclusions.
When <em>phi</em> is set to &quot;max&quot;, nearest neighbor distance matching is performed for the entire prediction area. Euclidean distances are used for projected
and non-defined CRS, great circle distances are used for geographic CRS (units in meters).
</p>
<p>The <em>modeldomain</em> is either a sf polygon that defines the prediction area, or alternatively a SpatRaster out of which a polygon,
transformed into the CRS of the training points, is defined as the outline of all non-NA cells.
Then, the function takes a regular point sample (amount defined by <em>samplesize)</em> from the spatial extent.
As an alternative use <em>predpoints</em> instead of <em>modeldomain</em>, if you have already defined the prediction locations (e.g. raster pixel centroids).
When using either <em>modeldomain</em> or <em>predpoints</em>, we advise to plot the study area polygon and the training/prediction points as a previous step to ensure they are aligned.
</p>


<h3>Value</h3>

<p>An object of class <em>nndm</em> consisting of a list of six elements:
indx_train, indx_test, and indx_exclude (indices of the observations to use as
training/test/excluded data in each NNDM LOO CV iteration), Gij (distances for
G function construction between prediction and target points), Gj
(distances for G function construction during LOO CV), Gjstar (distances
for modified G function during NNDM LOO CV), phi (landscape autocorrelation range).
indx_train and indx_test can directly be used as &quot;index&quot; and &quot;indexOut&quot; in
caret's <code><a href="caret.html#topic+trainControl">trainControl</a></code> function or used to initiate a custom validation strategy in mlr3.
</p>


<h3>Note</h3>

<p>NNDM is a variation of LOOCV and therefore may take a long time for large training data sets. See <code><a href="#topic+knndm">knndm</a></code> for a more efficient k-fold variant of the method.
</p>


<h3>Author(s)</h3>

<p>Carles Milà
</p>


<h3>References</h3>


<ul>
<li><p> Milà, C., Mateu, J., Pebesma, E., Meyer, H. (2022): Nearest Neighbour Distance Matching Leave-One-Out Cross-Validation for map validation. Methods in Ecology and Evolution 00, 1– 13.
</p>
</li>
<li><p> Meyer, H., Pebesma, E. (2022): Machine learning-based global maps of ecological variables and the challenge of assessing them. Nature Communications. 13.
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+geodist">geodist</a></code>, <code><a href="#topic+knndm">knndm</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>########################################################################
# Example 1: Simulated data - Randomly-distributed training points
########################################################################

library(sf)

# Simulate 100 random training points in a 100x100 square
set.seed(123)
poly &lt;- list(matrix(c(0,0,0,100,100,100,100,0,0,0), ncol=2, byrow=TRUE))
sample_poly &lt;- sf::st_polygon(poly)
train_points &lt;- sf::st_sample(sample_poly, 100, type = "random")
pred_points &lt;- sf::st_sample(sample_poly, 100, type = "regular")
plot(sample_poly)
plot(pred_points, add = TRUE, col = "blue")
plot(train_points, add = TRUE, col = "red")

# Run NNDM for the whole domain, here the prediction points are known
nndm_pred &lt;- nndm(train_points, predpoints=pred_points)
nndm_pred
plot(nndm_pred)
plot(nndm_pred, type = "simple") # For more accessible legend labels

# ...or run NNDM with a known autocorrelation range of 10
# to restrict the matching to distances lower than that.
nndm_pred &lt;- nndm(train_points, predpoints=pred_points, phi = 10)
nndm_pred
plot(nndm_pred)

########################################################################
# Example 2: Simulated data - Clustered training points
########################################################################

library(sf)

# Simulate 100 clustered training points in a 100x100 square
set.seed(123)
poly &lt;- list(matrix(c(0,0,0,100,100,100,100,0,0,0), ncol=2, byrow=TRUE))
sample_poly &lt;- sf::st_polygon(poly)
train_points &lt;- clustered_sample(sample_poly, 100, 10, 5)
pred_points &lt;- sf::st_sample(sample_poly, 100, type = "regular")
plot(sample_poly)
plot(pred_points, add = TRUE, col = "blue")
plot(train_points, add = TRUE, col = "red")

# Run NNDM for the whole domain
nndm_pred &lt;- nndm(train_points, predpoints=pred_points)
nndm_pred
plot(nndm_pred)
plot(nndm_pred, type = "simple") # For more accessible legend labels

########################################################################
# Example 3: Real- world example; using a SpatRast modeldomain instead
# of previously sampled prediction locations
########################################################################
## Not run: 
library(sf)
library(terra)

### prepare sample data:
data(cookfarm)
dat &lt;- aggregate(cookfarm[,c("DEM","TWI", "NDRE.M", "Easting", "Northing","VW")],
   by=list(as.character(cookfarm$SOURCEID)),mean)
pts &lt;- dat[,-1]
pts &lt;- st_as_sf(pts,coords=c("Easting","Northing"))
st_crs(pts) &lt;- 26911
studyArea &lt;- rast(system.file("extdata","predictors_2012-03-25.tif",package="CAST"))
pts &lt;- st_transform(pts, crs = st_crs(studyArea))
terra::plot(studyArea[["DEM"]])
terra::plot(vect(pts), add = T)

nndm_folds &lt;- nndm(pts, modeldomain = studyArea)
plot(nndm_folds)

#use for cross-validation:
library(caret)
ctrl &lt;- trainControl(method="cv",
   index=nndm_folds$indx_train,
   indexOut=nndm_folds$indx_test,
   savePredictions='final')
model_nndm &lt;- train(dat[,c("DEM","TWI", "NDRE.M")],
   dat$VW,
   method="rf",
   trControl = ctrl)
global_validation(model_nndm)

## End(Not run)

########################################################################
# Example 4: Real- world example; nndm in feature space
########################################################################
## Not run: 
library(sf)
library(terra)
library(ggplot2)

# Prepare the splot dataset for Chile
data(splotdata)
splotdata &lt;- splotdata[splotdata$Country == "Chile",]

# Select a series of bioclimatic predictors
predictors &lt;- c("bio_1", "bio_4", "bio_5", "bio_6",
               "bio_8", "bio_9", "bio_12", "bio_13",
               "bio_14", "bio_15", "elev")

predictors_sp &lt;- terra::rast(system.file("extdata", "predictors_chile.tif", package="CAST"))

# Data visualization
terra::plot(predictors_sp[["bio_1"]])
terra::plot(vect(splotdata), add = T)

# Run and visualise the nndm results
nndm_folds &lt;- nndm(splotdata[,predictors], modeldomain = predictors_sp, space = "feature")
plot(nndm_folds)


#use for cross-validation:
library(caret)
ctrl &lt;- trainControl(method="cv",
   index=nndm_folds$indx_train,
   indexOut=nndm_folds$indx_test,
   savePredictions='final')
model_nndm &lt;- train(st_drop_geometry(splotdata[,predictors]),
   splotdata$Species_richness,
   method="rf",
   trControl = ctrl)
global_validation(model_nndm)


## End(Not run)
</code></pre>

<hr>
<h2 id='normalize_DI'>Normalize DI values</h2><span id='topic+normalize_DI'></span>

<h3>Description</h3>

<p>The DI is normalized by the DI threshold to allow for a more straightforward interpretation.
A value in the resulting DI larger 1 means that the data are more dissimilar than what has been observed during cross-validation.
The returned threshold is adjusted accordingly and is, as a consequence, 1.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>normalize_DI(AOA)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="normalize_DI_+3A_aoa">AOA</code></td>
<td>
<p>An AOA object</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code>aoa</code>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+aoa">aoa</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(sf)
library(terra)
library(caret)

# prepare sample data:
data(cookfarm)
dat &lt;- aggregate(cookfarm[,c("VW","Easting","Northing")],
   by=list(as.character(cookfarm$SOURCEID)),mean)
pts &lt;- st_as_sf(dat,coords=c("Easting","Northing"))
pts$ID &lt;- 1:nrow(pts)
set.seed(100)
pts &lt;- pts[1:30,]
studyArea &lt;- rast(system.file("extdata","predictors_2012-03-25.tif",package="CAST"))[[1:8]]
trainDat &lt;- extract(studyArea,pts,na.rm=FALSE)
trainDat &lt;- merge(trainDat,pts,by.x="ID",by.y="ID")

# train a model:
set.seed(100)
variables &lt;- c("DEM","NDRE.Sd","TWI")
model &lt;- train(trainDat[,which(names(trainDat)%in%variables)],
trainDat$VW, method="rf", importance=TRUE, tuneLength=1,
trControl=trainControl(method="cv",number=5,savePredictions=T))

#...then calculate the AOA of the trained model for the study area:
AOA &lt;- aoa(studyArea, model)
plot(AOA)
plot(AOA$DI)

#... then normalize the DI
DI_norm &lt;- normalize_DI(AOA)
plot(DI_norm)
plot(DI_norm$DI)


## End(Not run)
</code></pre>

<hr>
<h2 id='plot'>Plot CAST classes</h2><span id='topic+plot'></span><span id='topic+plot.trainDI'></span><span id='topic+plot.aoa'></span><span id='topic+plot.nndm'></span><span id='topic+plot.knndm'></span><span id='topic+plot.ffs'></span><span id='topic+plot.geodist'></span><span id='topic+plot.errorModel'></span>

<h3>Description</h3>

<p>Generic plot function for CAST Classes
</p>
<p>A plotting function for a forward feature selection result.
Each point is the mean performance of a model run. Error bars represent
the standard errors from cross validation.
Marked points show the best model from each number of variables until a further variable
could not improve the results.
If type==&quot;selected&quot;, the contribution of the selected variables to the model
performance is shown.
</p>
<p>Density plot of nearest neighbor distances in geographic space or feature space between training data as well as between training data and
prediction locations.
Optional, the nearest neighbor distances between training data and test data or between training data and CV iterations is shown.
The plot can be used to check the suitability of a chosen CV method to be representative to estimate map accuracy.
</p>
<p>Plot the DI/LPD and errormetric from Cross-Validation with the modeled relationship
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'trainDI'
plot(x, ...)

## S3 method for class 'aoa'
plot(x, samplesize = 1000, variable = "DI", ...)

## S3 method for class 'nndm'
plot(x, type = "strict", stat = "ecdf", ...)

## S3 method for class 'knndm'
plot(x, type = "strict", stat = "ecdf", ...)

## S3 method for class 'ffs'
plot(
  x,
  plotType = "all",
  palette = rainbow,
  reverse = FALSE,
  marker = "black",
  size = 1.5,
  lwd = 0.5,
  pch = 21,
  ...
)

## S3 method for class 'geodist'
plot(x, unit = "m", stat = "density", ...)

## S3 method for class 'errorModel'
plot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot_+3A_x">x</code></td>
<td>
<p>errorModel, see <code><a href="#topic+DItoErrormetric">DItoErrormetric</a></code></p>
</td></tr>
<tr><td><code id="plot_+3A_...">...</code></td>
<td>
<p>other params</p>
</td></tr>
<tr><td><code id="plot_+3A_samplesize">samplesize</code></td>
<td>
<p>numeric. How many prediction samples should be plotted?</p>
</td></tr>
<tr><td><code id="plot_+3A_variable">variable</code></td>
<td>
<p>character. Variable for which to generate the density plot. 'DI' or 'LPD'</p>
</td></tr>
<tr><td><code id="plot_+3A_type">type</code></td>
<td>
<p>String, defaults to &quot;strict&quot; to show the original nearest neighbour distance definitions in the legend.
Alternatively, set to &quot;simple&quot; to have more intuitive labels.</p>
</td></tr>
<tr><td><code id="plot_+3A_stat">stat</code></td>
<td>
<p>&quot;density&quot; for density plot or &quot;ecdf&quot; for empirical cumulative distribution function plot.</p>
</td></tr>
<tr><td><code id="plot_+3A_plottype">plotType</code></td>
<td>
<p>character. Either &quot;all&quot; or &quot;selected&quot;</p>
</td></tr>
<tr><td><code id="plot_+3A_palette">palette</code></td>
<td>
<p>A color palette</p>
</td></tr>
<tr><td><code id="plot_+3A_reverse">reverse</code></td>
<td>
<p>Character. Should the palette be reversed?</p>
</td></tr>
<tr><td><code id="plot_+3A_marker">marker</code></td>
<td>
<p>Character. Color to mark the best models</p>
</td></tr>
<tr><td><code id="plot_+3A_size">size</code></td>
<td>
<p>Numeric. Size of the points</p>
</td></tr>
<tr><td><code id="plot_+3A_lwd">lwd</code></td>
<td>
<p>Numeric. Width of the error bars</p>
</td></tr>
<tr><td><code id="plot_+3A_pch">pch</code></td>
<td>
<p>Numeric. Type of point marking the best models</p>
</td></tr>
<tr><td><code id="plot_+3A_unit">unit</code></td>
<td>
<p>character. Only if type==&quot;geo&quot; and only applied to the plot. Supported: &quot;m&quot; or &quot;km&quot;.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a ggplot
</p>
<p>a ggplot
</p>


<h3>Author(s)</h3>

<p>Marvin Ludwig, Hanna Meyer
</p>
<p>Carles Milà
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(splotdata)
splotdata &lt;- st_drop_geometry(splotdata)
ffsmodel &lt;- ffs(splotdata[,6:16], splotdata$Species_richness, ntree = 10)
plot(ffsmodel)
#plot performance of selected variables only:
plot(ffsmodel,plotType="selected")

## End(Not run)
</code></pre>

<hr>
<h2 id='print'>Print CAST classes</h2><span id='topic+print'></span><span id='topic+print.trainDI'></span><span id='topic+show.trainDI'></span><span id='topic+print.aoa'></span><span id='topic+show.aoa'></span><span id='topic+print.nndm'></span><span id='topic+show.nndm'></span><span id='topic+print.knndm'></span><span id='topic+show.knndm'></span><span id='topic+print.ffs'></span><span id='topic+show.ffs'></span>

<h3>Description</h3>

<p>Generic print function for trainDI and aoa
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'trainDI'
print(x, ...)

show.trainDI(x, ...)

## S3 method for class 'aoa'
print(x, ...)

show.aoa(x, ...)

## S3 method for class 'nndm'
print(x, ...)

show.nndm(x, ...)

## S3 method for class 'knndm'
print(x, ...)

show.knndm(x, ...)

## S3 method for class 'ffs'
print(x, ...)

show.ffs(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="print_+3A_x">x</code></td>
<td>
<p>An object of type <em>ffs</em></p>
</td></tr>
<tr><td><code id="print_+3A_...">...</code></td>
<td>
<p>other arguments.</p>
</td></tr>
</table>

<hr>
<h2 id='splotdata'>sPlotOpen Data of Species Richness</h2><span id='topic+splotdata'></span>

<h3>Description</h3>

<p>sPlotOpen Species Richness for South America with associated predictors
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(splotdata)
</code></pre>


<h3>Format</h3>

<p>A sf points / data.frame with 703 rows and 17 columns:
</p>

<dl>
<dt>PlotObeservationID, GIVD_ID, Country, Biome</dt><dd><p>sPlotOpen Metadata</p>
</dd>
<dt>Species_richness</dt><dd><p>Response Variable - Plant species richness from sPlotOpen</p>
</dd>
<dt>bio_x, elev</dt><dd><p>Predictor Variables - Worldclim and SRTM elevation</p>
</dd>
<dt>geometry</dt><dd><p>Lat/Lon</p>
</dd>
</dl>



<h3>Source</h3>


<ul>
<li><p>Plot with Species_richness from <a href="https://onlinelibrary.wiley.com/doi/full/10.1111/geb.13346">sPlotOpen</a>
</p>
</li>
<li><p>predictors acquired via R package <a href="https://github.com/rspatial/geodata">geodata</a>
</p>
</li></ul>



<h3>References</h3>


<ul>
<li><p>Sabatini, F. M. et al. sPlotOpen – An environmentally balanced, open‐access, global dataset of vegetation plots. (2021). <a href="https://doi.org/10.1111/geb.13346">doi:10.1111/geb.13346</a>
</p>
</li>
<li><p>Lopez-Gonzalez, G. et al. ForestPlots.net: a web application and research tool to manage and analyse tropical forest plot data: ForestPlots.net.
Journal of Vegetation Science (2011).
</p>
</li>
<li><p>Pauchard, A. et al. Alien Plants Homogenise Protected Areas: Evidence from the Landscape and Regional Scales in South Central Chile. in Plant Invasions in Protected Areas (2013).
</p>
</li>
<li><p>Peyre, G. et al. VegPáramo, a flora and vegetation database for the Andean páramo. phytocoenologia (2015).
</p>
</li>
<li><p>Vibrans, A. C. et al. Insights from a large-scale inventory in the southern Brazilian Atlantic Forest. Scientia Agricola (2020).
</p>
</li></ul>


<hr>
<h2 id='trainDI'>Calculate Dissimilarity Index of training data</h2><span id='topic+trainDI'></span>

<h3>Description</h3>

<p>This function estimates the Dissimilarity Index (DI)
within the training data set used for a prediction model.
Optionally, the local point density can also be calculated.
Predictors can be weighted based on the internal
variable importance of the machine learning algorithm used for model training.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>trainDI(
  model = NA,
  train = NULL,
  variables = "all",
  weight = NA,
  CVtest = NULL,
  CVtrain = NULL,
  method = "L2",
  useWeight = TRUE,
  useCV = TRUE,
  LPD = FALSE,
  verbose = TRUE,
  algorithm = "brute"
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="trainDI_+3A_model">model</code></td>
<td>
<p>A train object created with caret used to extract weights from (based on variable importance) as well as cross-validation folds</p>
</td></tr>
<tr><td><code id="trainDI_+3A_train">train</code></td>
<td>
<p>A data.frame containing the data used for model training. Only required when no model is given</p>
</td></tr>
<tr><td><code id="trainDI_+3A_variables">variables</code></td>
<td>
<p>character vector of predictor variables. if &quot;all&quot; then all variables
of the model are used or if no model is given then of the train dataset.</p>
</td></tr>
<tr><td><code id="trainDI_+3A_weight">weight</code></td>
<td>
<p>A data.frame containing weights for each variable. Only required if no model is given.</p>
</td></tr>
<tr><td><code id="trainDI_+3A_cvtest">CVtest</code></td>
<td>
<p>list or vector. Either a list where each element contains the data points used for testing during the cross validation iteration (i.e. held back data).
Or a vector that contains the ID of the fold for each training point.
Only required if no model is given.</p>
</td></tr>
<tr><td><code id="trainDI_+3A_cvtrain">CVtrain</code></td>
<td>
<p>list. Each element contains the data points used for training during the cross validation iteration (i.e. held back data).
Only required if no model is given and only required if CVtrain is not the opposite of CVtest (i.e. if a data point is not used for testing, it is used for training).
Relevant if some data points are excluded, e.g. when using <code><a href="#topic+nndm">nndm</a></code>.</p>
</td></tr>
<tr><td><code id="trainDI_+3A_method">method</code></td>
<td>
<p>Character. Method used for distance calculation. Currently euclidean distance (L2) and Mahalanobis distance (MD) are implemented but only L2 is tested. Note that MD takes considerably longer.</p>
</td></tr>
<tr><td><code id="trainDI_+3A_useweight">useWeight</code></td>
<td>
<p>Logical. Only if a model is given. Weight variables according to importance in the model?</p>
</td></tr>
<tr><td><code id="trainDI_+3A_usecv">useCV</code></td>
<td>
<p>Logical. Only if a model is given. Use the CV folds to calculate the DI threshold?</p>
</td></tr>
<tr><td><code id="trainDI_+3A_lpd">LPD</code></td>
<td>
<p>Logical. Indicates whether the local point density should be calculated or not.</p>
</td></tr>
<tr><td><code id="trainDI_+3A_verbose">verbose</code></td>
<td>
<p>Logical. Print progress or not?</p>
</td></tr>
<tr><td><code id="trainDI_+3A_algorithm">algorithm</code></td>
<td>
<p>see <code><a href="FNN.html#topic+knnx.dist">knnx.dist</a></code> and <code><a href="FNN.html#topic+knnx.index">knnx.index</a></code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of class <code>trainDI</code> containing:
</p>
<table role = "presentation">
<tr><td><code>train</code></td>
<td>
<p>A data frame containing the training data</p>
</td></tr>
<tr><td><code>weight</code></td>
<td>
<p>A data frame with weights based on the variable importance.</p>
</td></tr>
<tr><td><code>variables</code></td>
<td>
<p>Names of the used variables</p>
</td></tr>
<tr><td><code>catvars</code></td>
<td>
<p>Which variables are categorial</p>
</td></tr>
<tr><td><code>scaleparam</code></td>
<td>
<p>Scaling parameters. Output from <code>scale</code></p>
</td></tr>
<tr><td><code>trainDist_avrg</code></td>
<td>
<p>A data frame with the average distance of each training point to every other point</p>
</td></tr>
<tr><td><code>trainDist_avrgmean</code></td>
<td>
<p>The mean of trainDist_avrg. Used for normalizing the DI</p>
</td></tr>
<tr><td><code>trainDI</code></td>
<td>
<p>Dissimilarity Index of the training data</p>
</td></tr>
<tr><td><code>threshold</code></td>
<td>
<p>The DI threshold used for inside/outside AOA</p>
</td></tr>
<tr><td><code>trainLPD</code></td>
<td>
<p>LPD of the training data</p>
</td></tr>
<tr><td><code>avrgLPD</code></td>
<td>
<p>Average LPD of the training data</p>
</td></tr>
</table>


<h3>Note</h3>

<p>This function is called within <code><a href="#topic+aoa">aoa</a></code> to estimate the DI and AOA of new data.
However, it may also be used on its own if only the DI of training data is of interest,
or to facilitate a parallelization of <code><a href="#topic+aoa">aoa</a></code> by avoiding a repeated calculation of the DI within the training data.
</p>


<h3>Author(s)</h3>

<p>Hanna Meyer, Marvin Ludwig, Fabian Schumacher
</p>


<h3>References</h3>

<p>Meyer, H., Pebesma, E. (2021): Predicting into unknown space?
Estimating the area of applicability of spatial prediction models.
<a href="https://doi.org/10.1111/2041-210X.13650">doi:10.1111/2041-210X.13650</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+aoa">aoa</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(sf)
library(terra)
library(caret)
library(CAST)

# prepare sample data:
data("splotdata")
splotdata = st_drop_geometry(splotdata)

# train a model:
set.seed(100)
model &lt;- caret::train(splotdata[,6:16],
                      splotdata$Species_richness,
                      importance=TRUE, tuneLength=1, ntree = 15, method = "rf",
                      trControl = trainControl(method="cv", number=5, savePredictions=T))
# variable importance is used for scaling predictors
plot(varImp(model,scale=FALSE))

# calculate the DI of the trained model:
DI = trainDI(model=model)
plot(DI)

#...or calculate the DI and LPD of the trained model:
# DI = trainDI(model=model, LPD = TRUE)

# the DI can now be used to compute the AOA (here with LPD):
studyArea = rast(system.file("extdata/predictors_chile.tif", package = "CAST"))
AOA = aoa(studyArea, model = model, trainDI = DI, LPD = TRUE, maxLPD = 1)
print(AOA)
plot(AOA)
plot(AOA$AOA)
plot(AOA$LPD)

## End(Not run)

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
