<!DOCTYPE html><html><head><title>Help for package CAST</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {CAST}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#aoa'><p>Area of Applicability</p></a></li>
<li><a href='#bss'><p>Best subset feature selection</p></a></li>
<li><a href='#calibrate_aoa'><p>Calibrate the AOA based on the relationship between the DI and the prediction error</p></a></li>
<li><a href='#CAST'><p>'caret' Applications for Spatial-Temporal Models</p></a></li>
<li><a href='#clustered_sample'><p>Clustered samples simulation</p></a></li>
<li><a href='#CreateSpacetimeFolds'><p>Create Space-time Folds</p></a></li>
<li><a href='#DItoErrormetric'><p>Model the relationship between the DI and the prediction error</p></a></li>
<li><a href='#errorModel'><p>Model expected error between Metric and DI</p></a></li>
<li><a href='#ffs'><p>Forward feature selection</p></a></li>
<li><a href='#geodist'><p>Calculate euclidean nearest neighbor distances in geographic space or feature space</p></a></li>
<li><a href='#get_preds_all'><p>Get Preds all</p></a></li>
<li><a href='#global_validation'><p>Evaluate 'global' cross-validation</p></a></li>
<li><a href='#knndm'><p>K-fold Nearest Neighbour Distance Matching</p></a></li>
<li><a href='#multiCV'><p>MultiCV</p></a></li>
<li><a href='#nndm'><p>Nearest Neighbour Distance Matching (NNDM) algorithm</p></a></li>
<li><a href='#plot'><p>Plot CAST classes</p></a></li>
<li><a href='#plot_ffs'><p>Plot results of a Forward feature selection or best subset selection</p></a></li>
<li><a href='#plot_geodist'><p>Plot euclidean nearest neighbor distances in geographic space or feature space</p></a></li>
<li><a href='#print'><p>Print CAST classes</p></a></li>
<li><a href='#splotdata'><p>sPlotOpen Data of Species Richness</p></a></li>
<li><a href='#trainDI'><p>Calculate Dissimilarity Index of training data</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>'caret' Applications for Spatial-Temporal Models</td>
</tr>
<tr>
<td>Version:</td>
<td>0.9.0</td>
</tr>
<tr>
<td>Author:</td>
<td>Hanna Meyer [cre, aut],
  Carles Milà [aut],
  Marvin Ludwig [aut],
  Jan Linnenbrink [aut],
  Philipp Otto [ctb],
  Chris Reudenbach [ctb],
  Thomas Nauss [ctb],
  Edzer Pebesma [ctb]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Hanna Meyer &lt;hanna.meyer@uni-muenster.de&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Supporting functionality to run 'caret' with spatial or spatial-temporal data. 'caret' is a frequently used package for model training and prediction using machine learning. CAST includes functions to improve spatial or spatial-temporal modelling tasks using 'caret'. It includes the newly suggested 'Nearest neighbor distance matching' cross-validation to estimate the performance of spatial prediction models and allows for spatial variable selection to selects suitable predictor variables in view to their contribution to the spatial model performance. CAST further includes functionality to estimate the (spatial) area of applicability of prediction models. Methods are described in Meyer et al. (2018) &lt;<a href="https://doi.org/10.1016%2Fj.envsoft.2017.12.001">doi:10.1016/j.envsoft.2017.12.001</a>&gt;; Meyer et al. (2019) &lt;<a href="https://doi.org/10.1016%2Fj.ecolmodel.2019.108815">doi:10.1016/j.ecolmodel.2019.108815</a>&gt;; Meyer and Pebesma (2021) &lt;<a href="https://doi.org/10.1111%2F2041-210X.13650">doi:10.1111/2041-210X.13650</a>&gt;; Milà et al. (2022) &lt;<a href="https://doi.org/10.1111%2F2041-210X.13851">doi:10.1111/2041-210X.13851</a>&gt;; Meyer and Pebesma (2022) &lt;<a href="https://doi.org/10.1038%2Fs41467-022-29838-9">doi:10.1038/s41467-022-29838-9</a>&gt;; Linnenbrink et al. (2023) &lt;<a href="https://doi.org/10.5194%2Fegusphere-2023-1308">doi:10.5194/egusphere-2023-1308</a>&gt;.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/HannaMeyer/CAST">https://github.com/HannaMeyer/CAST</a>,
<a href="https://hannameyer.github.io/CAST/">https://hannameyer.github.io/CAST/</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>false</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 4.1.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>caret, stats, utils, ggplot2, graphics, FNN, plyr, zoo,
methods, grDevices, data.table, lattice, sf, forcats</td>
</tr>
<tr>
<td>Suggests:</td>
<td>doParallel, randomForest, lubridate, sp, knitr, mapview,
rmarkdown, scales, parallel, gridExtra, viridis, stars, scam,
terra, rnaturalearth, MASS, twosamples, testthat (&ge; 3.0.0)</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-01-08 13:20:41 UTC; hanna</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-01-09 05:40:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='aoa'>Area of Applicability</h2><span id='topic+aoa'></span>

<h3>Description</h3>

<p>This function estimates the Dissimilarity Index (DI) and the derived
Area of Applicability (AOA) of spatial prediction models by
considering the distance of new data (i.e. a SpatRaster of spatial predictors
used in the models) in the predictor variable space to the data used for model
training. Predictors can be weighted based on the internal
variable importance of the machine learning algorithm used for model training.
The AOA is derived by applying a threshold on the DI which is the (outlier-removed)
maximum DI of the cross-validated training data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>aoa(
  newdata,
  model = NA,
  trainDI = NA,
  train = NULL,
  weight = NA,
  variables = "all",
  CVtest = NULL,
  CVtrain = NULL,
  method = "L2",
  useWeight = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="aoa_+3A_newdata">newdata</code></td>
<td>
<p>A SpatRaster, stars object or data.frame containing the data
the model was meant to make predictions for.</p>
</td></tr>
<tr><td><code id="aoa_+3A_model">model</code></td>
<td>
<p>A train object created with caret used to extract weights from (based on variable importance) as well as cross-validation folds.
See examples for the case that no model is available or for models trained via e.g. mlr3.</p>
</td></tr>
<tr><td><code id="aoa_+3A_traindi">trainDI</code></td>
<td>
<p>A trainDI object. Optional if <code><a href="#topic+trainDI">trainDI</a></code> was calculated beforehand.</p>
</td></tr>
<tr><td><code id="aoa_+3A_train">train</code></td>
<td>
<p>A data.frame containing the data used for model training. Optional. Only required when no model is given</p>
</td></tr>
<tr><td><code id="aoa_+3A_weight">weight</code></td>
<td>
<p>A data.frame containing weights for each variable. Optional. Only required if no model is given.</p>
</td></tr>
<tr><td><code id="aoa_+3A_variables">variables</code></td>
<td>
<p>character vector of predictor variables. if &quot;all&quot; then all variables
of the model are used or if no model is given then of the train dataset.</p>
</td></tr>
<tr><td><code id="aoa_+3A_cvtest">CVtest</code></td>
<td>
<p>list or vector. Either a list where each element contains the data points used for testing during the cross validation iteration (i.e. held back data).
Or a vector that contains the ID of the fold for each training point.
Only required if no model is given.</p>
</td></tr>
<tr><td><code id="aoa_+3A_cvtrain">CVtrain</code></td>
<td>
<p>list. Each element contains the data points used for training during the cross validation iteration (i.e. held back data).
Only required if no model is given and only required if CVtrain is not the opposite of CVtest (i.e. if a data point is not used for testing, it is used for training).
Relevant if some data points are excluded, e.g. when using <code><a href="#topic+nndm">nndm</a></code>.</p>
</td></tr>
<tr><td><code id="aoa_+3A_method">method</code></td>
<td>
<p>Character. Method used for distance calculation. Currently euclidean distance (L2) and Mahalanobis distance (MD) are implemented but only L2 is tested. Note that MD takes considerably longer.</p>
</td></tr>
<tr><td><code id="aoa_+3A_useweight">useWeight</code></td>
<td>
<p>Logical. Only if a model is given. Weight variables according to importance in the model?</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Dissimilarity Index (DI) and the corresponding Area of Applicability (AOA) are calculated.
If variables are factors, dummy variables are created prior to weighting and distance calculation.
</p>
<p>Interpretation of results: If a location is very similar to the properties
of the training data it will have a low distance in the predictor variable space
(DI towards 0) while locations that are very different in their properties
will have a high DI.
See Meyer and Pebesma (2021) for the full documentation of the methodology.
</p>


<h3>Value</h3>

<p>An object of class <code>aoa</code> containing:
</p>
<table>
<tr><td><code>parameters</code></td>
<td>
<p>object of class trainDI. see <code><a href="#topic+trainDI">trainDI</a></code></p>
</td></tr>
<tr><td><code>DI</code></td>
<td>
<p>SpatRaster, stars object or data frame. Dissimilarity index of newdata</p>
</td></tr>
<tr><td><code>AOA</code></td>
<td>
<p>SpatRaster, stars object or data frame. Area of Applicability of newdata.
AOA has values 0 (outside AOA) and 1 (inside AOA)</p>
</td></tr>
</table>


<h3>Note</h3>

<p>If classification models are used, currently the variable importance can only
be automatically retrieved if models were trained via train(predictors,response) and not via the formula-interface.
Will be fixed.
</p>


<h3>Author(s)</h3>

<p>Hanna Meyer
</p>


<h3>References</h3>

<p>Meyer, H., Pebesma, E. (2021): Predicting into unknown space?
Estimating the area of applicability of spatial prediction models.
Methods in Ecology and Evolution 12: 1620-1633. <a href="https://doi.org/10.1111/2041-210X.13650">doi:10.1111/2041-210X.13650</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+calibrate_aoa">calibrate_aoa</a></code>, <code><a href="#topic+trainDI">trainDI</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(sf)
library(terra)
library(caret)
library(viridis)

# prepare sample data:
dat &lt;- readRDS(system.file("extdata","Cookfarm.RDS",package="CAST"))
dat &lt;- aggregate(dat[,c("VW","Easting","Northing")],by=list(as.character(dat$SOURCEID)),mean)
pts &lt;- st_as_sf(dat,coords=c("Easting","Northing"))
pts$ID &lt;- 1:nrow(pts)
set.seed(100)
pts &lt;- pts[1:30,]
studyArea &lt;- rast(system.file("extdata","predictors_2012-03-25.tif",package="CAST"))[[1:8]]
trainDat &lt;- extract(studyArea,pts,na.rm=FALSE)
trainDat &lt;- merge(trainDat,pts,by.x="ID",by.y="ID")

# visualize data spatially:
plot(studyArea)
plot(studyArea$DEM)
plot(pts[,1],add=TRUE,col="black")

# train a model:
set.seed(100)
variables &lt;- c("DEM","NDRE.Sd","TWI")
model &lt;- train(trainDat[,which(names(trainDat)%in%variables)],
trainDat$VW, method="rf", importance=TRUE, tuneLength=1,
trControl=trainControl(method="cv",number=5,savePredictions=T))
print(model) #note that this is a quite poor prediction model
prediction &lt;- predict(studyArea,model,na.rm=TRUE)
plot(varImp(model,scale=FALSE))

#...then calculate the AOA of the trained model for the study area:
AOA &lt;- aoa(studyArea,model)
plot(AOA)

####
#The AOA can also be calculated without a trained model.
#All variables are weighted equally in this case:
####
AOA &lt;- aoa(studyArea,train=trainDat,variables=variables)


####
# The AOA can also be used for models trained via mlr3 (parameters have to be assigned manually):
####

library(mlr3)
library(mlr3learners)
library(mlr3spatial)
library(mlr3spatiotempcv)
library(mlr3extralearners)

# initiate and train model:
train_df &lt;- trainDat[, c("DEM","NDRE.Sd","TWI", "VW")]
backend &lt;- as_data_backend(train_df)
task &lt;- as_task_regr(backend, target = "VW")
lrn &lt;- lrn("regr.randomForest", importance = "mse")
lrn$train(task)

# cross-validation folds
rsmp_cv &lt;- rsmp("cv", folds = 5L)$instantiate(task)

## predict:
prediction &lt;- predict(studyArea,lrn$model,na.rm=TRUE)

### Estimate AOA
AOA &lt;- aoa(studyArea,
           train = as.data.frame(task$data()),
           variables = task$feature_names,
           weight = data.frame(t(lrn$importance())),
           CVtest = rsmp_cv$instance[order(row_id)]$fold)


## End(Not run)
</code></pre>

<hr>
<h2 id='bss'>Best subset feature selection</h2><span id='topic+bss'></span>

<h3>Description</h3>

<p>Evaluate all combinations of predictors during model training
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bss(
  predictors,
  response,
  method = "rf",
  metric = ifelse(is.factor(response), "Accuracy", "RMSE"),
  maximize = ifelse(metric == "RMSE", FALSE, TRUE),
  globalval = FALSE,
  trControl = caret::trainControl(),
  tuneLength = 3,
  tuneGrid = NULL,
  seed = 100,
  verbose = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bss_+3A_predictors">predictors</code></td>
<td>
<p>see <code><a href="caret.html#topic+train">train</a></code></p>
</td></tr>
<tr><td><code id="bss_+3A_response">response</code></td>
<td>
<p>see <code><a href="caret.html#topic+train">train</a></code></p>
</td></tr>
<tr><td><code id="bss_+3A_method">method</code></td>
<td>
<p>see <code><a href="caret.html#topic+train">train</a></code></p>
</td></tr>
<tr><td><code id="bss_+3A_metric">metric</code></td>
<td>
<p>see <code><a href="caret.html#topic+train">train</a></code></p>
</td></tr>
<tr><td><code id="bss_+3A_maximize">maximize</code></td>
<td>
<p>see <code><a href="caret.html#topic+train">train</a></code></p>
</td></tr>
<tr><td><code id="bss_+3A_globalval">globalval</code></td>
<td>
<p>Logical. Should models be evaluated based on 'global' performance? See <code><a href="#topic+global_validation">global_validation</a></code></p>
</td></tr>
<tr><td><code id="bss_+3A_trcontrol">trControl</code></td>
<td>
<p>see <code><a href="caret.html#topic+train">train</a></code></p>
</td></tr>
<tr><td><code id="bss_+3A_tunelength">tuneLength</code></td>
<td>
<p>see <code><a href="caret.html#topic+train">train</a></code></p>
</td></tr>
<tr><td><code id="bss_+3A_tunegrid">tuneGrid</code></td>
<td>
<p>see <code><a href="caret.html#topic+train">train</a></code></p>
</td></tr>
<tr><td><code id="bss_+3A_seed">seed</code></td>
<td>
<p>A random number</p>
</td></tr>
<tr><td><code id="bss_+3A_verbose">verbose</code></td>
<td>
<p>Logical. Should information about the progress be printed?</p>
</td></tr>
<tr><td><code id="bss_+3A_...">...</code></td>
<td>
<p>arguments passed to the classification or regression routine
(such as randomForest).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>bss is an alternative to <code><a href="#topic+ffs">ffs</a></code> and ideal if the training
set is small. Models are iteratively fitted using all different combinations
of predictor variables. Hence, 2^X models are calculated. Don't try running bss
on very large datasets because the computation time is much higher compared to
<code><a href="#topic+ffs">ffs</a></code>.
</p>
<p>The internal cross validation can be run in parallel. See information
on parallel processing of carets train functions for details.
</p>


<h3>Value</h3>

<p>A list of class train. Beside of the usual train content
the object contains the vector &quot;selectedvars&quot; and &quot;selectedvars_perf&quot;
that give the best variables selected as well as their corresponding
performance. It also contains &quot;perf_all&quot; that gives the performance of all model runs.
</p>


<h3>Note</h3>

<p>This variable selection is particularly suitable for spatial
cross validations where variable selection
MUST be based on the performance of the model for predicting new spatial units.
Note that bss is very slow since all combinations of variables are tested.
A more time efficient alternative is the forward feature selection (<code><a href="#topic+ffs">ffs</a></code>)
(<code><a href="#topic+ffs">ffs</a></code>).
</p>


<h3>Author(s)</h3>

<p>Hanna Meyer
</p>


<h3>See Also</h3>

<p><code><a href="caret.html#topic+train">train</a></code>,<code><a href="#topic+ffs">ffs</a></code>,
<code><a href="caret.html#topic+trainControl">trainControl</a></code>,<code><a href="#topic+CreateSpacetimeFolds">CreateSpacetimeFolds</a></code>,
<code><a href="#topic+nndm">nndm</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(iris)
bssmodel &lt;- bss(iris[,1:4],iris$Species)
bssmodel$perf_all

## End(Not run)
</code></pre>

<hr>
<h2 id='calibrate_aoa'>Calibrate the AOA based on the relationship between the DI and the prediction error</h2><span id='topic+calibrate_aoa'></span>

<h3>Description</h3>

<p>Performance metrics are calculated for moving windows of DI values of cross-validated training data
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calibrate_aoa(
  AOA,
  model,
  window.size = 5,
  calib = "scam",
  multiCV = FALSE,
  length.out = 10,
  maskAOA = TRUE,
  method = "L2",
  useWeight = TRUE,
  showPlot = TRUE,
  k = 6,
  m = 2
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="calibrate_aoa_+3A_aoa">AOA</code></td>
<td>
<p>the result of <code><a href="#topic+aoa">aoa</a></code></p>
</td></tr>
<tr><td><code id="calibrate_aoa_+3A_model">model</code></td>
<td>
<p>the model used to get the AOA</p>
</td></tr>
<tr><td><code id="calibrate_aoa_+3A_window.size">window.size</code></td>
<td>
<p>Numeric. Size of the moving window. See <code><a href="data.table.html#topic+rollapply">rollapply</a></code>.</p>
</td></tr>
<tr><td><code id="calibrate_aoa_+3A_calib">calib</code></td>
<td>
<p>Character. Function to model the DI~performance relationship. Currently lm and scam are supported</p>
</td></tr>
<tr><td><code id="calibrate_aoa_+3A_multicv">multiCV</code></td>
<td>
<p>Logical. Re-run model fitting and validation with different CV strategies. See details.</p>
</td></tr>
<tr><td><code id="calibrate_aoa_+3A_length.out">length.out</code></td>
<td>
<p>Numeric. Only used if multiCV=TRUE. Number of cross-validation folds. See details.</p>
</td></tr>
<tr><td><code id="calibrate_aoa_+3A_maskaoa">maskAOA</code></td>
<td>
<p>Logical. Should areas outside the AOA set to NA?</p>
</td></tr>
<tr><td><code id="calibrate_aoa_+3A_method">method</code></td>
<td>
<p>Character. Method used for distance calculation. Currently euclidean distance (L2) and Mahalanobis distance (MD) are implemented but only L2 is tested. Note that MD takes considerably longer. See ?aoa for further explanation</p>
</td></tr>
<tr><td><code id="calibrate_aoa_+3A_useweight">useWeight</code></td>
<td>
<p>Logical. Only if a model is given. Weight variables according to importance in the model?</p>
</td></tr>
<tr><td><code id="calibrate_aoa_+3A_showplot">showPlot</code></td>
<td>
<p>Logical.</p>
</td></tr>
<tr><td><code id="calibrate_aoa_+3A_k">k</code></td>
<td>
<p>Numeric. See mgcv::s</p>
</td></tr>
<tr><td><code id="calibrate_aoa_+3A_m">m</code></td>
<td>
<p>Numeric. See mgcv::s</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If multiCV=TRUE the model is re-fitted and validated by length.out new cross-validations where the cross-validation folds are defined by clusters in the predictor space,
ranging from three clusters to LOOCV. Hence, a large range of DI values is created during cross-validation.
If the AOA threshold based on the calibration data from multiple CV is larger than the original AOA threshold (which is likely if extrapolation situations are created during CV),
the AOA is updated accordingly. See Meyer and Pebesma (2021) for the full documentation of the methodology.
</p>


<h3>Value</h3>

<p>A list of length 2 with the elements &quot;AOA&quot;: SpatRaster or stars object which contains the original DI and the AOA (which might be updated if new test data indicate this option), as well as the expected performance based on the relationship.
Data used for calibration are stored in the attributes. The second element is a plot showing the relationship.
</p>


<h3>Author(s)</h3>

<p>Hanna Meyer
</p>


<h3>References</h3>

<p>Meyer, H., Pebesma, E. (2021): Predicting into unknown space?
Estimating the area of applicability of spatial prediction models.
<a href="https://doi.org/10.1111/2041-210X.13650">doi:10.1111/2041-210X.13650</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+aoa">aoa</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(sf)
library(terra)
library(caret)
library(viridis)
library(latticeExtra)

#' # prepare sample data:
dat &lt;- readRDS(system.file("extdata","Cookfarm.RDS",package="CAST"))
dat &lt;- aggregate(dat[,c("VW","Easting","Northing")],by=list(as.character(dat$SOURCEID)),mean)
pts &lt;- st_as_sf(dat,coords=c("Easting","Northing"))
pts$ID &lt;- 1:nrow(pts)
studyArea &lt;- rast(system.file("extdata","predictors_2012-03-25.tif",package="CAST"))[[1:8]]
dat &lt;- extract(studyArea,pts,na.rm=TRUE)
trainDat &lt;- merge(dat,pts,by.x="ID",by.y="ID")

# train a model:
variables &lt;- c("DEM","NDRE.Sd","TWI")
set.seed(100)
model &lt;- train(trainDat[,which(names(trainDat)%in%variables)],
  trainDat$VW,method="rf",importance=TRUE,tuneLength=1,
  trControl=trainControl(method="cv",number=5,savePredictions=TRUE))

#...then calculate the AOA of the trained model for the study area:
AOA &lt;- aoa(studyArea,model)

AOA_new &lt;- calibrate_aoa(AOA,model)
plot(AOA_new$AOA$expected_RMSE)

## End(Not run)
</code></pre>

<hr>
<h2 id='CAST'>'caret' Applications for Spatial-Temporal Models</h2><span id='topic+CAST'></span><span id='topic+CAST-package'></span>

<h3>Description</h3>

<p>Supporting functionality to run 'caret' with spatial or spatial-temporal data.
'caret' is a frequently used package for model training and prediction using machine learning.
CAST includes functions to improve spatial-temporal modelling tasks using 'caret'.
It includes the newly suggested 'Nearest neighbor distance matching' cross-validation to estimate the performance
of spatial prediction models and allows for spatial variable selection to selects suitable predictor variables
in view to their contribution to the spatial model performance.
CAST further includes functionality to estimate the (spatial) area of applicability of prediction models
by analysing the similarity between new data and training data.
Methods are described in Meyer et al. (2018); Meyer et al. (2019); Meyer and Pebesma (2021); Milà et al. (2022); Meyer and Pebesma (2022).
</p>


<h3>Details</h3>

<p>'caret' Applications for Spatio-Temporal models
</p>


<h3>Author(s)</h3>

<p>Hanna Meyer, Carles Milà, Marvin Ludwig, Lan Linnenbrink
</p>


<h3>References</h3>


<ul>
<li><p> Linnenbrink, J., Milà, C., Ludwig, M., and Meyer, H.: kNNDM: k-fold Nearest Neighbour Distance Matching Cross-Validation for map accuracy estimation, EGUsphere [preprint], https://doi.org/10.5194/egusphere-2023-1308, 2023.
</p>
</li>
<li><p> Milà, C., Mateu, J., Pebesma, E., Meyer, H. (2022): Nearest Neighbour Distance Matching Leave-One-Out Cross-Validation for map validation. Methods in Ecology and Evolution 00, 1– 13.
</p>
</li>
<li><p> Meyer, H., Pebesma, E. (2022): Machine learning-based global maps of ecological variables and the challenge of assessing them. Nature Communications. 13.
</p>
</li>
<li><p> Meyer, H., Pebesma, E. (2021): Predicting into unknown space? Estimating the area of applicability of spatial prediction models. Methods in Ecology and Evolution. 12, 1620– 1633.
</p>
</li>
<li><p> Meyer, H., Reudenbach, C., Wöllauer, S., Nauss, T. (2019): Importance of spatial predictor variable selection in machine learning applications - Moving from data reproduction to spatial prediction. Ecological Modelling. 411, 108815.
</p>
</li>
<li><p> Meyer, H., Reudenbach, C., Hengl, T., Katurji, M., Nauß, T. (2018): Improving performance of spatio-temporal machine learning models using forward feature selection and target-oriented validation. Environmental Modelling &amp; Software 101: 1-9.
</p>
</li></ul>


<hr>
<h2 id='clustered_sample'>Clustered samples simulation</h2><span id='topic+clustered_sample'></span>

<h3>Description</h3>

<p>A simple procedure to simulate clustered points based on a two-step sampling.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>clustered_sample(sarea, nsamples, nparents, radius)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="clustered_sample_+3A_sarea">sarea</code></td>
<td>
<p>polygon. Area where samples should be simulated.</p>
</td></tr>
<tr><td><code id="clustered_sample_+3A_nsamples">nsamples</code></td>
<td>
<p>integer. Number of samples to be simulated.</p>
</td></tr>
<tr><td><code id="clustered_sample_+3A_nparents">nparents</code></td>
<td>
<p>integer. Number of parents.</p>
</td></tr>
<tr><td><code id="clustered_sample_+3A_radius">radius</code></td>
<td>
<p>integer. Radius of the buffer around each parent for offspring simulation.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A simple procedure to simulate clustered points based on a two-step sampling.
First, a pre-specified number of parents are simulated using random sampling.
For each parent, '(nsamples-nparents)/nparents' are simulated within a radius of the parent point using random sampling.
</p>


<h3>Value</h3>

<p>sf object with the simulated points and the parent to which each point belongs to.
</p>


<h3>Author(s)</h3>

<p>Carles Milà
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Simulate 100 points in a 100x100 square with 5 parents and a radius of 10.
library(sf)
library(ggplot2)

set.seed(1234)
simarea &lt;- list(matrix(c(0,0,0,100,100,100,100,0,0,0), ncol=2, byrow=TRUE))
simarea &lt;- sf::st_polygon(simarea)
simpoints &lt;- clustered_sample(simarea, 100, 5, 10)
simpoints$parent &lt;- as.factor(simpoints$parent)
ggplot() +
    geom_sf(data = simarea, alpha = 0) +
    geom_sf(data = simpoints, aes(col = parent))

</code></pre>

<hr>
<h2 id='CreateSpacetimeFolds'>Create Space-time Folds</h2><span id='topic+CreateSpacetimeFolds'></span>

<h3>Description</h3>

<p>Create spatial, temporal or spatio-temporal Folds for cross validation based on pre-defined groups
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CreateSpacetimeFolds(
  x,
  spacevar = NA,
  timevar = NA,
  k = 10,
  class = NA,
  seed = sample(1:1000, 1)
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CreateSpacetimeFolds_+3A_x">x</code></td>
<td>
<p>data.frame containing spatio-temporal data</p>
</td></tr>
<tr><td><code id="CreateSpacetimeFolds_+3A_spacevar">spacevar</code></td>
<td>
<p>Character indicating which column of x identifies the
spatial units (e.g. ID of weather stations)</p>
</td></tr>
<tr><td><code id="CreateSpacetimeFolds_+3A_timevar">timevar</code></td>
<td>
<p>Character indicating which column of x identifies the
temporal units (e.g. the day of the year)</p>
</td></tr>
<tr><td><code id="CreateSpacetimeFolds_+3A_k">k</code></td>
<td>
<p>numeric. Number of folds. If spacevar or timevar is NA and a
leave one location out or leave one time step out cv should be performed,
set k to the number of unique spatial or temporal units.</p>
</td></tr>
<tr><td><code id="CreateSpacetimeFolds_+3A_class">class</code></td>
<td>
<p>Character indicating which column of x identifies a class unit (e.g. land cover)</p>
</td></tr>
<tr><td><code id="CreateSpacetimeFolds_+3A_seed">seed</code></td>
<td>
<p>numeric. See ?seed</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function creates train and test sets by taking (spatial and/or temporal) groups into account.
In contrast to <code><a href="#topic+nndm">nndm</a></code>, it requires that the groups are already defined (e.g. spatial clusters or blocks or temporal units).
Using &quot;class&quot; is helpful in the case that data are clustered in space
and are categorical. E.g This is the case for land cover classifications when
training data come as training polygons. In this case the data should be split in a way
that entire polygons are held back (spacevar=&quot;polygonID&quot;) but at the same time the distribution of classes
should be similar in each fold (class=&quot;LUC&quot;).
</p>


<h3>Value</h3>

<p>A list that contains a list for model training and a list for
model validation that can directly be used as &quot;index&quot; and &quot;indexOut&quot; in
caret's trainControl function
</p>


<h3>Note</h3>

<p>Standard k-fold cross-validation can lead to considerable misinterpretation in spatial-temporal modelling tasks. This function can be used to prepare a Leave-Location-Out, Leave-Time-Out or Leave-Location-and-Time-Out cross-validation as target-oriented validation strategies for spatial-temporal prediction tasks. See Meyer et al. (2018) for further information.
</p>


<h3>Author(s)</h3>

<p>Hanna Meyer
</p>


<h3>References</h3>

<p>Meyer, H., Reudenbach, C., Hengl, T., Katurji, M., Nauß, T. (2018): Improving performance of spatio-temporal machine learning models using forward feature selection and target-oriented validation. Environmental Modelling &amp; Software 101: 1-9.
</p>


<h3>See Also</h3>

<p><code><a href="caret.html#topic+trainControl">trainControl</a></code>,<code><a href="#topic+ffs">ffs</a></code>, <code><a href="#topic+nndm">nndm</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
dat &lt;- readRDS(system.file("extdata","Cookfarm.RDS",package="CAST"))
### Prepare for 10-fold Leave-Location-and-Time-Out cross validation
indices &lt;- CreateSpacetimeFolds(dat,"SOURCEID","Date")
str(indices)
### Prepare for 10-fold Leave-Location-Out cross validation
indices &lt;- CreateSpacetimeFolds(dat,spacevar="SOURCEID")
str(indices)
### Prepare for leave-One-Location-Out cross validation
indices &lt;- CreateSpacetimeFolds(dat,spacevar="SOURCEID",
    k=length(unique(dat$SOURCEID)))
str(indices)

## End(Not run)
</code></pre>

<hr>
<h2 id='DItoErrormetric'>Model the relationship between the DI and the prediction error</h2><span id='topic+DItoErrormetric'></span>

<h3>Description</h3>

<p>Performance metrics are calculated for moving windows of DI values of cross-validated training data
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DItoErrormetric(
  model,
  trainDI,
  multiCV = FALSE,
  length.out = 10,
  window.size = 5,
  calib = "scam",
  method = "L2",
  useWeight = TRUE,
  k = 6,
  m = 2
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="DItoErrormetric_+3A_model">model</code></td>
<td>
<p>the model used to get the AOA</p>
</td></tr>
<tr><td><code id="DItoErrormetric_+3A_traindi">trainDI</code></td>
<td>
<p>the result of <code><a href="#topic+trainDI">trainDI</a></code> or aoa object <code><a href="#topic+aoa">aoa</a></code></p>
</td></tr>
<tr><td><code id="DItoErrormetric_+3A_multicv">multiCV</code></td>
<td>
<p>Logical. Re-run model fitting and validation with different CV strategies. See details.</p>
</td></tr>
<tr><td><code id="DItoErrormetric_+3A_length.out">length.out</code></td>
<td>
<p>Numeric. Only used if multiCV=TRUE. Number of cross-validation folds. See details.</p>
</td></tr>
<tr><td><code id="DItoErrormetric_+3A_window.size">window.size</code></td>
<td>
<p>Numeric. Size of the moving window. See <code><a href="data.table.html#topic+rollapply">rollapply</a></code>.</p>
</td></tr>
<tr><td><code id="DItoErrormetric_+3A_calib">calib</code></td>
<td>
<p>Character. Function to model the DI~performance relationship. Currently lm and scam are supported</p>
</td></tr>
<tr><td><code id="DItoErrormetric_+3A_method">method</code></td>
<td>
<p>Character. Method used for distance calculation. Currently euclidean distance (L2) and Mahalanobis distance (MD) are implemented but only L2 is tested. Note that MD takes considerably longer. See ?aoa for further explanation</p>
</td></tr>
<tr><td><code id="DItoErrormetric_+3A_useweight">useWeight</code></td>
<td>
<p>Logical. Only if a model is given. Weight variables according to importance in the model?</p>
</td></tr>
<tr><td><code id="DItoErrormetric_+3A_k">k</code></td>
<td>
<p>Numeric. See mgcv::s</p>
</td></tr>
<tr><td><code id="DItoErrormetric_+3A_m">m</code></td>
<td>
<p>Numeric. See mgcv::s</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If multiCV=TRUE the model is re-fitted and validated by length.out new cross-validations where the cross-validation folds are defined by clusters in the predictor space,
ranging from three clusters to LOOCV. Hence, a large range of DI values is created during cross-validation.
If the AOA threshold based on the calibration data from multiple CV is larger than the original AOA threshold (which is likely if extrapolation situations are created during CV),
the AOA threshold changes accordingly. See Meyer and Pebesma (2021) for the full documentation of the methodology.
</p>


<h3>Value</h3>

<p>A scam or linear model
</p>


<h3>Author(s)</h3>

<p>Hanna Meyer, Marvin Ludwig
</p>


<h3>References</h3>

<p>Meyer, H., Pebesma, E. (2021): Predicting into unknown space?
Estimating the area of applicability of spatial prediction models.
<a href="https://doi.org/10.1111/2041-210X.13650">doi:10.1111/2041-210X.13650</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+aoa">aoa</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

  library(CAST)
  library(sf)
  library(terra)
  library(caret)


  data(splotdata)
  splotdata &lt;- st_drop_geometry(splotdata)
  predictors &lt;- terra::rast(system.file("extdata","predictors_chile.tif", package="CAST"))

  model &lt;- caret::train(splotdata[,6:16], splotdata$Species_richness, ntree = 10,
                        trControl = trainControl(method = "cv", savePredictions = TRUE))

  AOA &lt;- aoa(predictors, model)

  errormodel &lt;- DItoErrormetric(model, AOA)
  plot(errormodel)

  expected_error = terra::predict(AOA$DI, errormodel)
  plot(expected_error)


  # with multiCV = TRUE
  errormodel = DItoErrormetric(model, AOA, multiCV = TRUE, length.out = 3)
  plot(errormodel)

  expected_error = terra::predict(AOA$DI, errormodel)
  plot(expected_error)

  # mask AOA based on new threshold from multiCV
  mask_aoa = terra::mask(expected_error, AOA$DI &gt; attr(errormodel, 'AOA_threshold'), maskvalues = 1)
  plot(mask_aoa)





## End(Not run)

</code></pre>

<hr>
<h2 id='errorModel'>Model expected error between Metric and DI</h2><span id='topic+errorModel'></span>

<h3>Description</h3>

<p>Model expected error between Metric and DI
</p>


<h3>Usage</h3>

<pre><code class='language-R'>errorModel(preds_all, model, window.size, calib, k, m)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="errorModel_+3A_preds_all">preds_all</code></td>
<td>
<p>data.frame: pred, obs, DI</p>
</td></tr>
<tr><td><code id="errorModel_+3A_model">model</code></td>
<td>
<p>the model used to get the AOA</p>
</td></tr>
<tr><td><code id="errorModel_+3A_window.size">window.size</code></td>
<td>
<p>Numeric. Size of the moving window. See <code><a href="data.table.html#topic+rollapply">rollapply</a></code>.</p>
</td></tr>
<tr><td><code id="errorModel_+3A_calib">calib</code></td>
<td>
<p>Character. Function to model the DI~performance relationship. Currently lm and scam are supported</p>
</td></tr>
<tr><td><code id="errorModel_+3A_k">k</code></td>
<td>
<p>Numeric. See mgcv::s</p>
</td></tr>
<tr><td><code id="errorModel_+3A_m">m</code></td>
<td>
<p>Numeric. See mgcv::s</p>
</td></tr>
</table>


<h3>Value</h3>

<p>scam or lm
</p>

<hr>
<h2 id='ffs'>Forward feature selection</h2><span id='topic+ffs'></span>

<h3>Description</h3>

<p>A simple forward feature selection algorithm
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ffs(
  predictors,
  response,
  method = "rf",
  metric = ifelse(is.factor(response), "Accuracy", "RMSE"),
  maximize = ifelse(metric == "RMSE", FALSE, TRUE),
  globalval = FALSE,
  withinSE = FALSE,
  minVar = 2,
  trControl = caret::trainControl(),
  tuneLength = 3,
  tuneGrid = NULL,
  seed = sample(1:1000, 1),
  verbose = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ffs_+3A_predictors">predictors</code></td>
<td>
<p>see <code><a href="caret.html#topic+train">train</a></code></p>
</td></tr>
<tr><td><code id="ffs_+3A_response">response</code></td>
<td>
<p>see <code><a href="caret.html#topic+train">train</a></code></p>
</td></tr>
<tr><td><code id="ffs_+3A_method">method</code></td>
<td>
<p>see <code><a href="caret.html#topic+train">train</a></code></p>
</td></tr>
<tr><td><code id="ffs_+3A_metric">metric</code></td>
<td>
<p>see <code><a href="caret.html#topic+train">train</a></code></p>
</td></tr>
<tr><td><code id="ffs_+3A_maximize">maximize</code></td>
<td>
<p>see <code><a href="caret.html#topic+train">train</a></code></p>
</td></tr>
<tr><td><code id="ffs_+3A_globalval">globalval</code></td>
<td>
<p>Logical. Should models be evaluated based on 'global' performance? See <code><a href="#topic+global_validation">global_validation</a></code></p>
</td></tr>
<tr><td><code id="ffs_+3A_withinse">withinSE</code></td>
<td>
<p>Logical Models are only selected if they are better than the
currently best models Standard error</p>
</td></tr>
<tr><td><code id="ffs_+3A_minvar">minVar</code></td>
<td>
<p>Numeric. Number of variables to combine for the first selection.
See Details.</p>
</td></tr>
<tr><td><code id="ffs_+3A_trcontrol">trControl</code></td>
<td>
<p>see <code><a href="caret.html#topic+train">train</a></code></p>
</td></tr>
<tr><td><code id="ffs_+3A_tunelength">tuneLength</code></td>
<td>
<p>see <code><a href="caret.html#topic+train">train</a></code></p>
</td></tr>
<tr><td><code id="ffs_+3A_tunegrid">tuneGrid</code></td>
<td>
<p>see <code><a href="caret.html#topic+train">train</a></code></p>
</td></tr>
<tr><td><code id="ffs_+3A_seed">seed</code></td>
<td>
<p>A random number used for model training</p>
</td></tr>
<tr><td><code id="ffs_+3A_verbose">verbose</code></td>
<td>
<p>Logical. Should information about the progress be printed?</p>
</td></tr>
<tr><td><code id="ffs_+3A_...">...</code></td>
<td>
<p>arguments passed to the classification or regression routine
(such as randomForest).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Models with two predictors are first trained using all possible
pairs of predictor variables. The best model of these initial models is kept.
On the basis of this best model the predictor variables are iteratively
increased and each of the remaining variables is tested for its improvement
of the currently best model. The process stops if none of the remaining
variables increases the model performance when added to the current best model.
</p>
<p>The internal cross validation can be run in parallel. See information
on parallel processing of carets train functions for details.
</p>
<p>Using withinSE will favour models with less variables and
probably shorten the calculation time
</p>
<p>Per Default, the ffs starts with all possible 2-pair combinations.
minVar allows to start the selection with more than 2 variables, e.g.
minVar=3 starts the ffs testing all combinations of 3 (instead of 2) variables
first and then increasing the number. This is important for e.g. neural networks
that often cannot make sense of only two variables. It is also relevant if
it is assumed that the optimal variables can only be found if more than 2
are considered at the same time.
</p>


<h3>Value</h3>

<p>A list of class train. Beside of the usual train content
the object contains the vector &quot;selectedvars&quot; and &quot;selectedvars_perf&quot;
that give the order of the best variables selected as well as their corresponding
performance (starting from the first two variables). It also contains &quot;perf_all&quot;
that gives the performance of all model runs.
</p>


<h3>Note</h3>

<p>This variable selection is particularly suitable for spatial
cross validations where variable selection
MUST be based on the performance of the model for predicting new spatial units.
See Meyer et al. (2018) and Meyer et al. (2019) for further details.
</p>


<h3>Author(s)</h3>

<p>Hanna Meyer
</p>


<h3>References</h3>


<ul>
<li><p> Gasch, C.K., Hengl, T., Gräler, B., Meyer, H., Magney, T., Brown, D.J. (2015): Spatio-temporal interpolation of soil water, temperature, and electrical conductivity in 3D+T: the Cook Agronomy Farm data set. Spatial Statistics 14: 70-90.
</p>
</li>
<li><p> Meyer, H., Reudenbach, C., Hengl, T., Katurji, M., Nauß, T. (2018): Improving performance of spatio-temporal machine learning models using forward feature selection and target-oriented validation. Environmental Modelling &amp; Software 101: 1-9.  <a href="https://doi.org/10.1016/j.envsoft.2017.12.001">doi:10.1016/j.envsoft.2017.12.001</a>
</p>
</li>
<li><p> Meyer, H., Reudenbach, C., Wöllauer, S., Nauss, T. (2019): Importance of spatial predictor variable selection in machine learning applications - Moving from data reproduction to spatial prediction. Ecological Modelling. 411, 108815. <a href="https://doi.org/10.1016/j.ecolmodel.2019.108815">doi:10.1016/j.ecolmodel.2019.108815</a>.
</p>
</li>
<li><p> Ludwig, M., Moreno-Martinez, A., Hölzel, N., Pebesma, E., Meyer, H. (2023): Assessing and improving the transferability of current global spatial prediction models. Global Ecology and Biogeography. <a href="https://doi.org/10.1111/geb.13635">doi:10.1111/geb.13635</a>.
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="caret.html#topic+train">train</a></code>,<code><a href="#topic+bss">bss</a></code>,
<code><a href="caret.html#topic+trainControl">trainControl</a></code>,<code><a href="#topic+CreateSpacetimeFolds">CreateSpacetimeFolds</a></code>,<code><a href="#topic+nndm">nndm</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(iris)
ffsmodel &lt;- ffs(iris[,1:4],iris$Species)
ffsmodel$selectedvars
ffsmodel$selectedvars_perf

## End(Not run)

# or perform model with target-oriented validation (LLO CV)
#the example is described in Gasch et al. (2015). The ffs approach for this dataset is described in
#Meyer et al. (2018). Due to high computation time needed, only a small and thus not robust example
#is shown here.

## Not run: 
#run the model on three cores:
library(doParallel)
library(lubridate)
cl &lt;- makeCluster(3)
registerDoParallel(cl)

#load and prepare dataset:
dat &lt;- readRDS(system.file("extdata","Cookfarm.RDS",package="CAST"))
trainDat &lt;- dat[dat$altitude==-0.3&amp;year(dat$Date)==2012&amp;week(dat$Date)%in%c(13:14),]

#visualize dataset:
ggplot(data = trainDat, aes(x=Date, y=VW)) + geom_line(aes(colour=SOURCEID))

#create folds for Leave Location Out Cross Validation:
set.seed(10)
indices &lt;- CreateSpacetimeFolds(trainDat,spacevar = "SOURCEID",k=3)
ctrl &lt;- trainControl(method="cv",index = indices$index)

#define potential predictors:
predictors &lt;- c("DEM","TWI","BLD","Precip_cum","cday","MaxT_wrcc",
"Precip_wrcc","NDRE.M","Bt","MinT_wrcc","Northing","Easting")

#run ffs model with Leave Location out CV
set.seed(10)
ffsmodel &lt;- ffs(trainDat[,predictors],trainDat$VW,method="rf",
tuneLength=1,trControl=ctrl)
ffsmodel
plot(ffsmodel)
#or only selected variables:
plot(ffsmodel,plotType="selected")

#compare to model without ffs:
model &lt;- train(trainDat[,predictors],trainDat$VW,method="rf",
tuneLength=1, trControl=ctrl)
model
stopCluster(cl)

## End(Not run)
</code></pre>

<hr>
<h2 id='geodist'>Calculate euclidean nearest neighbor distances in geographic space or feature space</h2><span id='topic+geodist'></span>

<h3>Description</h3>

<p>Calculates nearest neighbor distances in geographic space or feature space between training data as well as between training data and prediction locations.
Optional, the nearest neighbor distances between training data and test data or between training data and CV iterations is computed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>geodist(
  x,
  modeldomain,
  type = "geo",
  cvfolds = NULL,
  cvtrain = NULL,
  testdata = NULL,
  preddata = NULL,
  samplesize = 2000,
  sampling = "regular",
  variables = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="geodist_+3A_x">x</code></td>
<td>
<p>object of class sf, training data locations</p>
</td></tr>
<tr><td><code id="geodist_+3A_modeldomain">modeldomain</code></td>
<td>
<p>SpatRaster, stars or sf object defining the prediction area (see Details)</p>
</td></tr>
<tr><td><code id="geodist_+3A_type">type</code></td>
<td>
<p>&quot;geo&quot; or &quot;feature&quot;. Should the distance be computed in geographic space or in the normalized multivariate predictor space (see Details)</p>
</td></tr>
<tr><td><code id="geodist_+3A_cvfolds">cvfolds</code></td>
<td>
<p>optional. list or vector. Either a list where each element contains the data points used for testing during the cross validation iteration (i.e. held back data).
Or a vector that contains the ID of the fold for each training point. See e.g. ?createFolds or ?CreateSpacetimeFolds or ?nndm</p>
</td></tr>
<tr><td><code id="geodist_+3A_cvtrain">cvtrain</code></td>
<td>
<p>optional. List of row indices of x to fit the model to in each CV iteration. If cvtrain is null but cvfolds is not, all samples but those included in cvfolds are used as training data</p>
</td></tr>
<tr><td><code id="geodist_+3A_testdata">testdata</code></td>
<td>
<p>optional. object of class sf: Point data used for independent validation</p>
</td></tr>
<tr><td><code id="geodist_+3A_preddata">preddata</code></td>
<td>
<p>optional. object of class sf: Point data indicating the locations within the modeldomain to be used as target prediction points. Useful when the prediction objective is a subset of
locations within the modeldomain rather than the whole area.</p>
</td></tr>
<tr><td><code id="geodist_+3A_samplesize">samplesize</code></td>
<td>
<p>numeric. How many prediction samples should be used?</p>
</td></tr>
<tr><td><code id="geodist_+3A_sampling">sampling</code></td>
<td>
<p>character. How to draw prediction samples? See <a href="sp.html#topic+spsample">spsample</a>. Use sampling = &quot;Fibonacci&quot; for global applications.</p>
</td></tr>
<tr><td><code id="geodist_+3A_variables">variables</code></td>
<td>
<p>character vector defining the predictor variables used if type=&quot;feature. If not provided all variables included in modeldomain are used.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The modeldomain is a sf polygon or a raster that defines the prediction area. The function takes a regular point sample (amount defined by samplesize) from the spatial extent.
If type = &quot;feature&quot;, the argument modeldomain (and if provided then also the testdata and/or preddata) has to include predictors. Predictor values for x, testdata and preddata are optional if modeldomain is a raster.
If not provided they are extracted from the modeldomain rasterStack.
W statistic describes the match between the distributions. See Linnenbrink et al (2023) for further details.
</p>


<h3>Value</h3>

<p>A data.frame containing the distances. Unit of returned geographic distances is meters. attributes contain W statistic between prediction area and either sample data, CV folds or test data. See details.
</p>


<h3>Note</h3>

<p>See Meyer and Pebesma (2022) for an application of this plotting function
</p>


<h3>Author(s)</h3>

<p>Hanna Meyer, Edzer Pebesma, Marvin Ludwig
</p>


<h3>See Also</h3>

<p><code><a href="#topic+nndm">nndm</a></code> <code><a href="#topic+knndm">knndm</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(CAST)
library(sf)
library(terra)
library(caret)
library(rnaturalearth)
library(ggplot2)

data(splotdata)
studyArea &lt;- rnaturalearth::ne_countries(continent = "South America", returnclass = "sf")

########### Distance between training data and new data:
dist &lt;- geodist(splotdata, studyArea)
plot(dist)

########### Distance between training data, new data and test data (here Chile):
plot(splotdata[,"Country"])
dist &lt;- geodist(splotdata[splotdata$Country != "Chile",], studyArea,
                testdata = splotdata[splotdata$Country == "Chile",])
plot(dist)

########### Distance between training data, new data and CV folds:
folds &lt;- createFolds(1:nrow(splotdata), k=3, returnTrain=FALSE)
dist &lt;- geodist(x=splotdata, modeldomain=studyArea, cvfolds=folds)
plot(dist)

########### Distances in the feature space:
predictors &lt;- terra::rast(system.file("extdata","predictors_chile.tif", package="CAST"))
dist &lt;- geodist(x = splotdata,
                modeldomain = predictors,
                type = "feature",
                variables = c("bio_1","bio_12", "elev"))
plot(dist)

dist &lt;- geodist(x = splotdata[splotdata$Country != "Chile",],
                modeldomain = predictors, cvfolds = folds,
                testdata = splotdata[splotdata$Country == "Chile",],
                type = "feature",
                variables=c("bio_1","bio_12", "elev"))
plot(dist)

############ Example for a random global dataset
############ (refer to figure in Meyer and Pebesma 2022)

### Define prediction area (here: global):
ee &lt;- st_crs("+proj=eqearth")
co &lt;- ne_countries(returnclass = "sf")
co.ee &lt;- st_transform(co, ee)

### Simulate a spatial random sample
### (alternatively replace pts_random by a real sampling dataset (see Meyer and Pebesma 2022):
sf_use_s2(FALSE)
pts_random &lt;- st_sample(co.ee, 2000, exact=FALSE)

### See points on the map:
ggplot() + geom_sf(data = co.ee, fill="#00BFC4",col="#00BFC4") +
  geom_sf(data = pts_random, color = "#F8766D",size=0.5, shape=3) +
  guides(fill = "none", col = "none") +
  labs(x = NULL, y = NULL)

### plot distances:
dist &lt;- geodist(pts_random,co.ee)
plot(dist) + scale_x_log10(labels=round)





## End(Not run)
</code></pre>

<hr>
<h2 id='get_preds_all'>Get Preds all</h2><span id='topic+get_preds_all'></span>

<h3>Description</h3>

<p>Get Preds all
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_preds_all(model, trainDI)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_preds_all_+3A_model">model</code></td>
<td>
<p>a model</p>
</td></tr>
<tr><td><code id="get_preds_all_+3A_traindi">trainDI</code></td>
<td>
<p>a trainDI</p>
</td></tr>
</table>

<hr>
<h2 id='global_validation'>Evaluate 'global' cross-validation</h2><span id='topic+global_validation'></span>

<h3>Description</h3>

<p>Calculate validation metric using all held back predictions at once
</p>


<h3>Usage</h3>

<pre><code class='language-R'>global_validation(model)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="global_validation_+3A_model">model</code></td>
<td>
<p>an object of class <code><a href="caret.html#topic+train">train</a></code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>Relevant when folds are not representative for the entire area of interest.
In this case, metrics like R2 are not meaningful since it doesn't reflect the general ability of
the model to explain the entire gradient of the response.
Comparable to LOOCV, predictions from all held back folds are used here together to calculate validation statistics.
</p>


<h3>Value</h3>

<p>regression (<code><a href="caret.html#topic+postResample">postResample</a></code>) or classification  (<code><a href="caret.html#topic+confusionMatrix">confusionMatrix</a></code>) statistics
</p>


<h3>Author(s)</h3>

<p>Hanna Meyer
</p>


<h3>See Also</h3>

<p><code><a href="#topic+CreateSpacetimeFolds">CreateSpacetimeFolds</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>dat &lt;- readRDS(system.file("extdata","Cookfarm.RDS",package="CAST"))
dat &lt;- dat[sample(1:nrow(dat),500),]
indices &lt;- CreateSpacetimeFolds(dat,"SOURCEID","Date")
ctrl &lt;- caret::trainControl(method="cv",index = indices$index,savePredictions="final")
model &lt;- caret::train(dat[,c("DEM","TWI","BLD")],dat$VW, method="rf", trControl=ctrl, ntree=10)
global_validation(model)
</code></pre>

<hr>
<h2 id='knndm'>K-fold Nearest Neighbour Distance Matching</h2><span id='topic+knndm'></span>

<h3>Description</h3>

<p>This function implements the kNNDM algorithm and returns the necessary
indices to perform a k-fold NNDM CV for map validation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>knndm(
  tpoints,
  modeldomain = NULL,
  ppoints = NULL,
  space = "geographical",
  k = 10,
  maxp = 0.5,
  clustering = "hierarchical",
  linkf = "ward.D2",
  samplesize = 1000,
  sampling = "regular"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="knndm_+3A_tpoints">tpoints</code></td>
<td>
<p>sf or sfc point object. Contains the training points samples.</p>
</td></tr>
<tr><td><code id="knndm_+3A_modeldomain">modeldomain</code></td>
<td>
<p>sf polygon object defining the prediction area. Optional; alternative to ppoints (see Details).</p>
</td></tr>
<tr><td><code id="knndm_+3A_ppoints">ppoints</code></td>
<td>
<p>sf or sfc point object. Contains the target prediction points. Optional; alternative to modeldomain (see Details).</p>
</td></tr>
<tr><td><code id="knndm_+3A_space">space</code></td>
<td>
<p>character. Only &quot;geographical&quot; knndm, i.e. kNNDM in the geographical space, is currently implemented.</p>
</td></tr>
<tr><td><code id="knndm_+3A_k">k</code></td>
<td>
<p>integer. Number of folds desired for CV. Defaults to 10.</p>
</td></tr>
<tr><td><code id="knndm_+3A_maxp">maxp</code></td>
<td>
<p>numeric. Maximum fold size allowed, defaults to 0.5, i.e. a single fold can hold a maximum of half of the training points.</p>
</td></tr>
<tr><td><code id="knndm_+3A_clustering">clustering</code></td>
<td>
<p>character. Possible values include &quot;hierarchical&quot; and &quot;kmeans&quot;. See details.</p>
</td></tr>
<tr><td><code id="knndm_+3A_linkf">linkf</code></td>
<td>
<p>character. Only relevant if clustering = &quot;hierarchical&quot;. Link function for agglomerative hierarchical clustering.
Defaults to &quot;ward.D2&quot;. Check 'stats::hclust' for other options.</p>
</td></tr>
<tr><td><code id="knndm_+3A_samplesize">samplesize</code></td>
<td>
<p>numeric. How many points in the modeldomain should be sampled as prediction points?
Only required if modeldomain is used instead of ppoints.</p>
</td></tr>
<tr><td><code id="knndm_+3A_sampling">sampling</code></td>
<td>
<p>character. How to draw prediction points from the modeldomain? See 'sf::st_sample'.
Only required if modeldomain is used instead of ppoints.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>knndm is a k-fold version of NNDM LOO CV for medium and large datasets. Brielfy, the algorithm tries to
find a k-fold configuration such that the integral of the absolute differences (Wasserstein W statistic)
between the empirical nearest neighbour distance distribution function between the test and training data during CV (Gj*),
and the empirical nearest neighbour distance distribution function between the prediction and training points (Gij),
is minimised. It does so by performing clustering of the training points' coordinates for different numbers of
clusters that range from k to N (number of observations), merging them into k final folds,
and selecting the configuration with the lowest W.
</p>
<p>Using a projected CRS in 'knndm' has large computational advantages since fast nearest neighbour search can be
done via the 'FNN' package, while working with geographic coordinates requires computing the full
spherical distance matrices. As a clustering algorithm, 'kmeans' can only be used for
projected CRS while 'hierarchical' can work with both projected and geographical coordinates, though it requires
calculating the full distance matrix of the training points even for a projected CRS.
</p>
<p>In order to select between clustering algorithms and number of folds 'k', different 'knndm' configurations can be run
and compared, being the one with a lower W statistic the one that offers a better match. W statistics between 'knndm'
runs are comparable as long as 'tpoints' and 'ppoints' or 'modeldomain' stay the same.
</p>
<p>Map validation using knndm should be used using 'CAST::global_validation', i.e. by stacking all out-of-sample
predictions and evaluating them all at once. The reasons behind this are 1) The resulting folds can be
unbalanced and 2) nearest neighbour functions are constructed and matched using all CV folds simultaneously.
</p>
<p>If training data points are very clustered with respect to the prediction area and the presented knndm
configuration still show signs of Gj* &gt; Gij, there are several things that can be tried. First, increase
the 'maxp' parameter; this may help to control for strong clustering (at the cost of having unbalanced folds).
Secondly, decrease the number of final folds 'k', which may help to have larger clusters.
</p>
<p>The 'modeldomain' is a sf polygon that defines the prediction area. The function takes a regular point sample
(amount defined by 'samplesize') from the spatial extent. As an alternative use 'ppoints' instead of
'modeldomain', if you have already defined the prediction locations (e.g. raster pixel centroids).
When using either 'modeldomain' or 'ppoints', we advise to plot the study area polygon and the
training/prediction points as a previous step to ensure they are aligned.
</p>


<h3>Value</h3>

<p>An object of class <em>knndm</em> consisting of a list of eight elements:
indx_train, indx_test (indices of the observations to use as
training/test data in each kNNDM CV iteration), Gij (distances for
G function construction between prediction and target points), Gj
(distances for G function construction during LOO CV), Gjstar (distances
for modified G function during kNNDM CV), clusters (list of cluster IDs),
W (Wasserstein statistic), and space (stated by the user in the function call).
</p>


<h3>Note</h3>

<p>Experimental cycle. Article describing and testing the algorithm in preparation.
</p>


<h3>Author(s)</h3>

<p>Carles Milà and Jan Linnenbrink
</p>


<h3>References</h3>


<ul>
<li><p> Linnenbrink, J., Milà, C., Ludwig, M., and Meyer, H.: kNNDM: k-fold Nearest Neighbour Distance Matching Cross-Validation for map accuracy estimation, EGUsphere [preprint], https://doi.org/10.5194/egusphere-2023-1308, 2023.
</p>
</li>
<li><p> Milà, C., Mateu, J., Pebesma, E., Meyer, H. (2022): Nearest Neighbour Distance Matching Leave-One-Out Cross-Validation for map validation. Methods in Ecology and Evolution 00, 1– 13.
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+geodist">geodist</a></code>, <code><a href="#topic+nndm">nndm</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>########################################################################
# Example 1: Simulated data - Randomly-distributed training points
########################################################################

library(sf)
library(ggplot2)

# Simulate 1000 random training points in a 100x100 square
set.seed(1234)
simarea &lt;- list(matrix(c(0,0,0,100,100,100,100,0,0,0), ncol=2, byrow=TRUE))
simarea &lt;- sf::st_polygon(simarea)
train_points &lt;- sf::st_sample(simarea, 1000, type = "random")
pred_points &lt;- sf::st_sample(simarea, 1000, type = "regular")
plot(simarea)
plot(pred_points, add = TRUE, col = "blue")
plot(train_points, add = TRUE, col = "red")

# Run kNNDM for the whole domain, here the prediction points are known.
knndm_folds &lt;- knndm(train_points, ppoints = pred_points, k = 5)
knndm_folds
plot(knndm_folds)
folds &lt;- as.character(knndm_folds$clusters)
ggplot() +
  geom_sf(data = simarea, alpha = 0) +
  geom_sf(data = train_points, aes(col = folds))

########################################################################
# Example 2: Simulated data - Clustered training points
########################################################################
## Not run: 
library(sf)
library(ggplot2)

# Simulate 1000 clustered training points in a 100x100 square
set.seed(1234)
simarea &lt;- list(matrix(c(0,0,0,100,100,100,100,0,0,0), ncol=2, byrow=TRUE))
simarea &lt;- sf::st_polygon(simarea)
train_points &lt;- clustered_sample(simarea, 1000, 50, 5)
pred_points &lt;- sf::st_sample(simarea, 1000, type = "regular")
plot(simarea)
plot(pred_points, add = TRUE, col = "blue")
plot(train_points, add = TRUE, col = "red")

# Run kNNDM for the whole domain, here the prediction points are known.
knndm_folds &lt;- knndm(train_points, ppoints = pred_points, k = 5)
knndm_folds
plot(knndm_folds)
folds &lt;- as.character(knndm_folds$clusters)
ggplot() +
  geom_sf(data = simarea, alpha = 0) +
  geom_sf(data = train_points, aes(col = folds))

## End(Not run)
########################################################################
# Example 3: Real- world example; using a modeldomain instead of previously
# sampled prediction locations
########################################################################
## Not run: 
library(sf)
library(terra)
library(ggplot2)

### prepare sample data:
dat &lt;- readRDS(system.file("extdata","Cookfarm.RDS",package="CAST"))
dat &lt;- aggregate(dat[,c("DEM","TWI", "NDRE.M", "Easting", "Northing","VW")],
   by=list(as.character(dat$SOURCEID)),mean)
pts &lt;- dat[,-1]
pts &lt;- st_as_sf(pts,coords=c("Easting","Northing"))
st_crs(pts) &lt;- 26911
studyArea &lt;- rast(system.file("extdata","predictors_2012-03-25.tif",package="CAST"))
studyArea[!is.na(studyArea)] &lt;- 1
studyArea &lt;- as.polygons(studyArea, values = FALSE, na.all = TRUE) |&gt;
    st_as_sf() |&gt;
    st_union()
pts &lt;- st_transform(pts, crs = st_crs(studyArea))
plot(studyArea)
plot(st_geometry(pts), add = TRUE, col = "red")

knndm_folds &lt;- knndm(pts, modeldomain=studyArea, k = 5)
knndm_folds
plot(knndm_folds)
folds &lt;- as.character(knndm_folds$clusters)
ggplot() +
  geom_sf(data = pts, aes(col = folds))

#use for cross-validation:
library(caret)
ctrl &lt;- trainControl(method="cv",
   index=knndm_folds$indx_train,
   savePredictions='final')
model_knndm &lt;- train(dat[,c("DEM","TWI", "NDRE.M")],
   dat$VW,
   method="rf",
   trControl = ctrl)
global_validation(model_knndm)

## End(Not run)
</code></pre>

<hr>
<h2 id='multiCV'>MultiCV</h2><span id='topic+multiCV'></span>

<h3>Description</h3>

<p>Multiple Cross-Validation with increasing feature space clusteres
</p>


<h3>Usage</h3>

<pre><code class='language-R'>multiCV(model, length.out, method, useWeight, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="multiCV_+3A_model">model</code></td>
<td>
<p>the model used to get the AOA</p>
</td></tr>
<tr><td><code id="multiCV_+3A_length.out">length.out</code></td>
<td>
<p>Numeric. Only used if multiCV=TRUE. Number of cross-validation folds. See details.</p>
</td></tr>
<tr><td><code id="multiCV_+3A_method">method</code></td>
<td>
<p>Character. Method used for distance calculation. Currently euclidean distance (L2) and Mahalanobis distance (MD) are implemented but only L2 is tested. Note that MD takes considerably longer. See ?aoa for further explanation</p>
</td></tr>
<tr><td><code id="multiCV_+3A_useweight">useWeight</code></td>
<td>
<p>Logical. Only if a model is given. Weight variables according to importance in the model?</p>
</td></tr>
<tr><td><code id="multiCV_+3A_...">...</code></td>
<td>
<p>additional parameters to trainDI</p>
</td></tr>
</table>


<h3>Value</h3>

<p>preds_all
</p>

<hr>
<h2 id='nndm'>Nearest Neighbour Distance Matching (NNDM) algorithm</h2><span id='topic+nndm'></span>

<h3>Description</h3>

<p>This function implements the NNDM algorithm and returns the necessary
indices to perform a NNDM LOO CV for map validation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nndm(
  tpoints,
  modeldomain = NULL,
  ppoints = NULL,
  samplesize = 1000,
  sampling = "regular",
  phi = "max",
  min_train = 0.5
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="nndm_+3A_tpoints">tpoints</code></td>
<td>
<p>sf or sfc point object. Contains the training points samples.</p>
</td></tr>
<tr><td><code id="nndm_+3A_modeldomain">modeldomain</code></td>
<td>
<p>sf polygon object defining the prediction area (see Details).</p>
</td></tr>
<tr><td><code id="nndm_+3A_ppoints">ppoints</code></td>
<td>
<p>sf or sfc point object. Contains the target prediction points.
Optional. Alternative to modeldomain (see Details).</p>
</td></tr>
<tr><td><code id="nndm_+3A_samplesize">samplesize</code></td>
<td>
<p>numeric. How many points in the modeldomain should be sampled as prediction points?
Only required if modeldomain is used instead of ppoints.</p>
</td></tr>
<tr><td><code id="nndm_+3A_sampling">sampling</code></td>
<td>
<p>character. How to draw prediction points from the modeldomain? See 'sf::st_sample'.
Only required if modeldomain is used instead of ppoints.</p>
</td></tr>
<tr><td><code id="nndm_+3A_phi">phi</code></td>
<td>
<p>Numeric. Estimate of the landscape autocorrelation range in the
same units as the tpoints and ppoints for projected CRS, in meters for geographic CRS.
Per default (phi=&quot;max&quot;), the size of the prediction area is used. See Details.</p>
</td></tr>
<tr><td><code id="nndm_+3A_min_train">min_train</code></td>
<td>
<p>Numeric between 0 and 1. Minimum proportion of training
data that must be used in each CV fold. Defaults to 0.5 (i.e. half of the training points).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>NNDM proposes a LOO CV scheme such that the nearest neighbour distance distribution function between the test and training data during the CV process is matched to the nearest neighbour
distance distribution function between the prediction and training points. Details of the method can be found in Milà et al. (2022).
</p>
<p>Specifying <em>phi</em> allows limiting distance matching to the area where this is assumed to be relevant due to spatial autocorrelation.
Distances are only matched up to <em>phi</em>. Beyond that range, all data points are used for training, without exclusions.
When <em>phi</em> is set to &quot;max&quot;, nearest neighbor distance matching is performed for the entire prediction area. Euclidean distances are used for projected
and non-defined CRS, great circle distances are used for geographic CRS (units in meters).
</p>
<p>The <em>modeldomain</em> is a sf polygon that defines the prediction area. The function takes a regular point sample (amount defined by <em>samplesize)</em> from the spatial extent.
As an alternative use <em>ppoints</em> instead of <em>modeldomain</em>, if you have already defined the prediction locations (e.g. raster pixel centroids).
When using either <em>modeldomain</em> or <em>ppoints</em>, we advise to plot the study area polygon and the training/prediction points as a previous step to ensure they are aligned.
</p>


<h3>Value</h3>

<p>An object of class <em>nndm</em> consisting of a list of six elements:
indx_train, indx_test, and indx_exclude (indices of the observations to use as
training/test/excluded data in each NNDM LOO CV iteration), Gij (distances for
G function construction between prediction and target points), Gj
(distances for G function construction during LOO CV), Gjstar (distances
for modified G function during NNDM LOO CV), phi (landscape autocorrelation range).
indx_train and indx_test can directly be used as &quot;index&quot; and &quot;indexOut&quot; in
caret's <code><a href="caret.html#topic+trainControl">trainControl</a></code> function or used to initiate a custom validation strategy in mlr3.
</p>


<h3>Note</h3>

<p>NNDM is a variation of LOOCV and therefore may take a long time for large training data sets.
A k-fold variant will be implemented shortly.
</p>


<h3>Author(s)</h3>

<p>Carles Milà
</p>


<h3>References</h3>


<ul>
<li><p> Milà, C., Mateu, J., Pebesma, E., Meyer, H. (2022): Nearest Neighbour Distance Matching Leave-One-Out Cross-Validation for map validation. Methods in Ecology and Evolution 00, 1– 13.
</p>
</li>
<li><p> Meyer, H., Pebesma, E. (2022): Machine learning-based global maps of ecological variables and the challenge of assessing them. Nature Communications. 13.
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+geodist">geodist</a></code>, <code><a href="#topic+knndm">knndm</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>########################################################################
# Example 1: Simulated data - Randomly-distributed training points
########################################################################

library(sf)

# Simulate 100 random training points in a 100x100 square
set.seed(123)
poly &lt;- list(matrix(c(0,0,0,100,100,100,100,0,0,0), ncol=2, byrow=TRUE))
sample_poly &lt;- sf::st_polygon(poly)
train_points &lt;- sf::st_sample(sample_poly, 100, type = "random")
pred_points &lt;- sf::st_sample(sample_poly, 100, type = "regular")
plot(sample_poly)
plot(pred_points, add = TRUE, col = "blue")
plot(train_points, add = TRUE, col = "red")

# Run NNDM for the whole domain, here the prediction points are known
nndm_pred &lt;- nndm(train_points, ppoints=pred_points)
nndm_pred
plot(nndm_pred)

# ...or run NNDM with a known autocorrelation range of 10
# to restrict the matching to distances lower than that.
nndm_pred &lt;- nndm(train_points, ppoints=pred_points, phi = 10)
nndm_pred
plot(nndm_pred)

########################################################################
# Example 2: Simulated data - Clustered training points
########################################################################

library(sf)

# Simulate 100 clustered training points in a 100x100 square
set.seed(123)
poly &lt;- list(matrix(c(0,0,0,100,100,100,100,0,0,0), ncol=2, byrow=TRUE))
sample_poly &lt;- sf::st_polygon(poly)
train_points &lt;- clustered_sample(sample_poly, 100, 10, 5)
pred_points &lt;- sf::st_sample(sample_poly, 100, type = "regular")
plot(sample_poly)
plot(pred_points, add = TRUE, col = "blue")
plot(train_points, add = TRUE, col = "red")

# Run NNDM for the whole domain
nndm_pred &lt;- nndm(train_points, ppoints=pred_points)
nndm_pred
plot(nndm_pred)

########################################################################
# Example 3: Real- world example; using a modeldomain instead of previously
# sampled prediction locations
########################################################################
## Not run: 
library(sf)
library(terra)

### prepare sample data:
dat &lt;- readRDS(system.file("extdata","Cookfarm.RDS",package="CAST"))
dat &lt;- aggregate(dat[,c("DEM","TWI", "NDRE.M", "Easting", "Northing","VW")],
   by=list(as.character(dat$SOURCEID)),mean)
pts &lt;- dat[,-1]
pts &lt;- st_as_sf(pts,coords=c("Easting","Northing"))
st_crs(pts) &lt;- 26911
studyArea &lt;- rast(system.file("extdata","predictors_2012-03-25.tif",package="CAST"))
studyArea[!is.na(studyArea)] &lt;- 1
studyArea &lt;- as.polygons(studyArea, values = FALSE, na.all = TRUE) |&gt;
    st_as_sf() |&gt;
    st_union()
pts &lt;- st_transform(pts, crs = st_crs(studyArea))
plot(studyArea)
plot(st_geometry(pts), add = TRUE, col = "red")

nndm_folds &lt;- nndm(pts, modeldomain= studyArea)
plot(nndm_folds)

#use for cross-validation:
library(caret)
ctrl &lt;- trainControl(method="cv",
   index=nndm_folds$indx_train,
   indexOut=nndm_folds$indx_test,
   savePredictions='final')
model_nndm &lt;- train(dat[,c("DEM","TWI", "NDRE.M")],
   dat$VW,
   method="rf",
   trControl = ctrl)
global_validation(model_nndm)

## End(Not run)

</code></pre>

<hr>
<h2 id='plot'>Plot CAST classes</h2><span id='topic+plot'></span><span id='topic+plot.trainDI'></span><span id='topic+plot.aoa'></span><span id='topic+plot.nndm'></span><span id='topic+plot.knndm'></span><span id='topic+plot.ffs'></span><span id='topic+plot.geodist'></span><span id='topic+plot.errorModel'></span>

<h3>Description</h3>

<p>Generic plot function for CAST Classes
</p>
<p>A plotting function for a forward feature selection result.
Each point is the mean performance of a model run. Error bars represent
the standard errors from cross validation.
Marked points show the best model from each number of variables until a further variable
could not improve the results.
If type==&quot;selected&quot;, the contribution of the selected variables to the model
performance is shown.
</p>
<p>Density plot of nearest neighbor distances in geographic space or feature space between training data as well as between training data and prediction locations.
Optional, the nearest neighbor distances between training data and test data or between training data and CV iterations is shown.
The plot can be used to check the suitability of a chosen CV method to be representative to estimate map accuracy.
</p>
<p>Plot the DI and errormetric from Cross-Validation with the modelled relationship
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'trainDI'
plot(x, ...)

## S3 method for class 'aoa'
plot(x, samplesize = 1000, ...)

## S3 method for class 'nndm'
plot(x, ...)

## S3 method for class 'knndm'
plot(x, ...)

## S3 method for class 'ffs'
plot(
  x,
  plotType = "all",
  palette = rainbow,
  reverse = FALSE,
  marker = "black",
  size = 1.5,
  lwd = 0.5,
  pch = 21,
  ...
)

## S3 method for class 'geodist'
plot(x, unit = "m", stat = "density", ...)

## S3 method for class 'errorModel'
plot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot_+3A_x">x</code></td>
<td>
<p>errorModel, see <code><a href="#topic+DItoErrormetric">DItoErrormetric</a></code></p>
</td></tr>
<tr><td><code id="plot_+3A_...">...</code></td>
<td>
<p>other params</p>
</td></tr>
<tr><td><code id="plot_+3A_samplesize">samplesize</code></td>
<td>
<p>numeric. How many prediction samples should be plotted?</p>
</td></tr>
<tr><td><code id="plot_+3A_plottype">plotType</code></td>
<td>
<p>character. Either &quot;all&quot; or &quot;selected&quot;</p>
</td></tr>
<tr><td><code id="plot_+3A_palette">palette</code></td>
<td>
<p>A color palette</p>
</td></tr>
<tr><td><code id="plot_+3A_reverse">reverse</code></td>
<td>
<p>Character. Should the palette be reversed?</p>
</td></tr>
<tr><td><code id="plot_+3A_marker">marker</code></td>
<td>
<p>Character. Color to mark the best models</p>
</td></tr>
<tr><td><code id="plot_+3A_size">size</code></td>
<td>
<p>Numeric. Size of the points</p>
</td></tr>
<tr><td><code id="plot_+3A_lwd">lwd</code></td>
<td>
<p>Numeric. Width of the error bars</p>
</td></tr>
<tr><td><code id="plot_+3A_pch">pch</code></td>
<td>
<p>Numeric. Type of point marking the best models</p>
</td></tr>
<tr><td><code id="plot_+3A_unit">unit</code></td>
<td>
<p>character. Only if type==&quot;geo&quot; and only applied to the plot. Supported: &quot;m&quot; or &quot;km&quot;.</p>
</td></tr>
<tr><td><code id="plot_+3A_stat">stat</code></td>
<td>
<p>&quot;density&quot; for density plot or &quot;ecdf&quot; for empirical cumulative distribution function plot.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a ggplot
</p>
<p>a ggplot
</p>


<h3>Author(s)</h3>

<p>Marvin Ludwig, Hanna Meyer
</p>
<p>Carles Milà
</p>
<p>Marvin Ludwig and Hanna Meyer
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ffs">ffs</a></code>, <code><a href="#topic+bss">bss</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(splotdata)
splotdata &lt;- st_drop_geometry(splotdata)
ffsmodel &lt;- ffs(splotdata[,6:16], splotdata$Species_richness, ntree = 10)
plot(ffsmodel)
#plot performance of selected variables only:
plot(ffsmodel,plotType="selected")

## End(Not run)
</code></pre>

<hr>
<h2 id='plot_ffs'>Plot results of a Forward feature selection or best subset selection</h2><span id='topic+plot_ffs'></span>

<h3>Description</h3>

<p>plot_ffs() is deprecated and will be removed soon. Please use generic plot() function on ffs object.
A plotting function for a forward feature selection result.
Each point is the mean performance of a model run. Error bars represent
the standard errors from cross validation.
Marked points show the best model from each number of variables until a further variable
could not improve the results.
If type==&quot;selected&quot;, the contribution of the selected variables to the model
performance is shown.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot_ffs(
  ffs_model,
  plotType = "all",
  palette = rainbow,
  reverse = FALSE,
  marker = "black",
  size = 1.5,
  lwd = 0.5,
  pch = 21,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot_ffs_+3A_ffs_model">ffs_model</code></td>
<td>
<p>Result of a forward feature selection see <code><a href="#topic+ffs">ffs</a></code></p>
</td></tr>
<tr><td><code id="plot_ffs_+3A_plottype">plotType</code></td>
<td>
<p>character. Either &quot;all&quot; or &quot;selected&quot;</p>
</td></tr>
<tr><td><code id="plot_ffs_+3A_palette">palette</code></td>
<td>
<p>A color palette</p>
</td></tr>
<tr><td><code id="plot_ffs_+3A_reverse">reverse</code></td>
<td>
<p>Character. Should the palette be reversed?</p>
</td></tr>
<tr><td><code id="plot_ffs_+3A_marker">marker</code></td>
<td>
<p>Character. Color to mark the best models</p>
</td></tr>
<tr><td><code id="plot_ffs_+3A_size">size</code></td>
<td>
<p>Numeric. Size of the points</p>
</td></tr>
<tr><td><code id="plot_ffs_+3A_lwd">lwd</code></td>
<td>
<p>Numeric. Width of the error bars</p>
</td></tr>
<tr><td><code id="plot_ffs_+3A_pch">pch</code></td>
<td>
<p>Numeric. Type of point marking the best models</p>
</td></tr>
<tr><td><code id="plot_ffs_+3A_...">...</code></td>
<td>
<p>Further arguments for base plot if type=&quot;selected&quot;</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Marvin Ludwig and Hanna Meyer
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ffs">ffs</a></code>, <code><a href="#topic+bss">bss</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(iris)
ffsmodel &lt;- ffs(iris[,1:4],iris$Species)
plot(ffsmodel)
#plot performance of selected variables only:
plot(ffsmodel,plotType="selected")

## End(Not run)
</code></pre>

<hr>
<h2 id='plot_geodist'>Plot euclidean nearest neighbor distances in geographic space or feature space</h2><span id='topic+plot_geodist'></span>

<h3>Description</h3>

<p>Density plot of nearest neighbor distances in geographic space or feature space between training data as well as between training data and prediction locations.
Optional, the nearest neighbor distances between training data and test data or between training data and CV iterations is shown.
The plot can be used to check the suitability of a chosen CV method to be representative to estimate map accuracy. Alternatively distances can also be calculated in the multivariate feature space.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot_geodist(
  x,
  modeldomain,
  type = "geo",
  cvfolds = NULL,
  cvtrain = NULL,
  testdata = NULL,
  samplesize = 2000,
  sampling = "regular",
  variables = NULL,
  unit = "m",
  stat = "density",
  showPlot = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot_geodist_+3A_x">x</code></td>
<td>
<p>object of class sf, training data locations</p>
</td></tr>
<tr><td><code id="plot_geodist_+3A_modeldomain">modeldomain</code></td>
<td>
<p>SpatRaster, stars or sf object defining the prediction area (see Details)</p>
</td></tr>
<tr><td><code id="plot_geodist_+3A_type">type</code></td>
<td>
<p>&quot;geo&quot; or &quot;feature&quot;. Should the distance be computed in geographic space or in the normalized multivariate predictor space (see Details)</p>
</td></tr>
<tr><td><code id="plot_geodist_+3A_cvfolds">cvfolds</code></td>
<td>
<p>optional. list or vector. Either a list where each element contains the data points used for testing during the cross validation iteration (i.e. held back data).
Or a vector that contains the ID of the fold for each training point. See e.g. ?createFolds or ?CreateSpacetimeFolds or ?nndm</p>
</td></tr>
<tr><td><code id="plot_geodist_+3A_cvtrain">cvtrain</code></td>
<td>
<p>optional. List of row indices of x to fit the model to in each CV iteration. If cvtrain is null but cvfolds is not, all samples but those included in cvfolds are used as training data</p>
</td></tr>
<tr><td><code id="plot_geodist_+3A_testdata">testdata</code></td>
<td>
<p>optional. object of class sf: Data used for independent validation</p>
</td></tr>
<tr><td><code id="plot_geodist_+3A_samplesize">samplesize</code></td>
<td>
<p>numeric. How many prediction samples should be used?</p>
</td></tr>
<tr><td><code id="plot_geodist_+3A_sampling">sampling</code></td>
<td>
<p>character. How to draw prediction samples? See <a href="sp.html#topic+spsample">spsample</a>. Use sampling = &quot;Fibonacci&quot; for global applications.</p>
</td></tr>
<tr><td><code id="plot_geodist_+3A_variables">variables</code></td>
<td>
<p>character vector defining the predictor variables used if type=&quot;feature. If not provided all variables included in modeldomain are used.</p>
</td></tr>
<tr><td><code id="plot_geodist_+3A_unit">unit</code></td>
<td>
<p>character. Only if type==&quot;geo&quot; and only applied to the plot. Supported: &quot;m&quot; or &quot;km&quot;.</p>
</td></tr>
<tr><td><code id="plot_geodist_+3A_stat">stat</code></td>
<td>
<p>&quot;density&quot; for density plot or &quot;ecdf&quot; for empirical cumulative distribution function plot.</p>
</td></tr>
<tr><td><code id="plot_geodist_+3A_showplot">showPlot</code></td>
<td>
<p>logical</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The modeldomain is a sf polygon or a raster that defines the prediction area. The function takes a regular point sample (amount defined by samplesize) from the spatial extent.
If type = &quot;feature&quot;, the argument modeldomain (and if provided then also the testdata) has to include predictors. Predictor values for x are optional if modeldomain is a raster.
If not provided they are extracted from the modeldomain rasterStack.
</p>


<h3>Value</h3>

<p>A list including the plot and the corresponding data.frame containing the distances. Unit of returned geographic distances is meters.
</p>


<h3>Note</h3>

<p>See Meyer and Pebesma (2022) for an application of this plotting function
</p>


<h3>Author(s)</h3>

<p>Hanna Meyer, Edzer Pebesma, Marvin Ludwig
</p>


<h3>See Also</h3>

<p><code><a href="#topic+nndm">nndm</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(sf)
library(terra)
library(caret)

########### prepare sample data:
dat &lt;- readRDS(system.file("extdata","Cookfarm.RDS",package="CAST"))
dat &lt;- aggregate(dat[,c("DEM","TWI", "NDRE.M", "Easting", "Northing")],
  by=list(as.character(dat$SOURCEID)),mean)
pts &lt;- st_as_sf(dat,coords=c("Easting","Northing"))
st_crs(pts) &lt;- 26911
pts_train &lt;- pts[1:29,]
pts_test &lt;- pts[30:42,]
studyArea &lt;- terra::rast(system.file("extdata","predictors_2012-03-25.tif",package="CAST"))
studyArea &lt;- studyArea[[c("DEM","TWI", "NDRE.M", "NDRE.Sd", "Bt")]]

########### Distance between training data and new data:
dist &lt;- plot_geodist(pts_train,studyArea)

########### Distance between training data, new data and test data:
#mapview(pts_train,col.regions="blue")+mapview(pts_test,col.regions="red")
dist &lt;- plot_geodist(pts_train,studyArea,testdata=pts_test)

########### Distance between training data, new data and CV folds:
folds &lt;- createFolds(1:nrow(pts_train),k=3,returnTrain=FALSE)
dist &lt;- plot_geodist(x=pts_train, modeldomain=studyArea, cvfolds=folds)

## or use nndm to define folds
AOI &lt;- as.polygons(rast(studyArea), values = F) |&gt;
  st_as_sf() |&gt;
  st_union() |&gt;
  st_transform(crs = st_crs(pts_train))
nndm_pred &lt;- nndm(pts_train, AOI)
dist &lt;- plot_geodist(x=pts_train, modeldomain=studyArea,
    cvfolds=nndm_pred$indx_test, cvtrain=nndm_pred$indx_train)

########### Distances in the feature space:
plot_geodist(x=pts_train, modeldomain=studyArea,
    type = "feature",variables=c("DEM","TWI", "NDRE.M"))

dist &lt;- plot_geodist(x=pts_train, modeldomain=studyArea, cvfolds = folds, testdata = pts_test,
    type = "feature",variables=c("DEM","TWI", "NDRE.M"))

############ Example for a random global dataset
############ (refer to figure in Meyer and Pebesma 2022)
library(sf)
library(rnaturalearth)
library(ggplot2)

### Define prediction area (here: global):
ee &lt;- st_crs("+proj=eqearth")
co &lt;- ne_countries(returnclass = "sf")
co.ee &lt;- st_transform(co, ee)

### Simulate a spatial random sample
### (alternatively replace pts_random by a real sampling dataset (see Meyer and Pebesma 2022):
sf_use_s2(FALSE)
pts_random &lt;- st_sample(co.ee, 2000, exact=FALSE)

### See points on the map:
ggplot() + geom_sf(data = co.ee, fill="#00BFC4",col="#00BFC4") +
     geom_sf(data = pts_random, color = "#F8766D",size=0.5, shape=3) +
     guides(fill = FALSE, col = FALSE) +
     labs(x = NULL, y = NULL)

### plot distances:
dist &lt;- plot_geodist(pts_random,co.ee,showPlot=FALSE)
dist$plot+scale_x_log10(labels=round)

## End(Not run)
</code></pre>

<hr>
<h2 id='print'>Print CAST classes</h2><span id='topic+print'></span><span id='topic+print.trainDI'></span><span id='topic+show.trainDI'></span><span id='topic+print.aoa'></span><span id='topic+show.aoa'></span><span id='topic+print.nndm'></span><span id='topic+show.nndm'></span><span id='topic+print.knndm'></span><span id='topic+show.knndm'></span><span id='topic+print.ffs'></span><span id='topic+show.ffs'></span>

<h3>Description</h3>

<p>Generic print function for trainDI and aoa
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'trainDI'
print(x, ...)

show.trainDI(x, ...)

## S3 method for class 'aoa'
print(x, ...)

show.aoa(x, ...)

## S3 method for class 'nndm'
print(x, ...)

show.nndm(x, ...)

## S3 method for class 'knndm'
print(x, ...)

show.knndm(x, ...)

## S3 method for class 'ffs'
print(x, ...)

show.ffs(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print_+3A_x">x</code></td>
<td>
<p>An object of type <em>ffs</em></p>
</td></tr>
<tr><td><code id="print_+3A_...">...</code></td>
<td>
<p>other arguments.</p>
</td></tr>
</table>

<hr>
<h2 id='splotdata'>sPlotOpen Data of Species Richness</h2><span id='topic+splotdata'></span>

<h3>Description</h3>

<p>sPlotOpen Species Richness for South America with associated predictors
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(splotdata)
</code></pre>


<h3>Format</h3>

<p>A sf points / data.frame with 703 rows and 17 columns:
</p>

<dl>
<dt>PlotObeservationID, GIVD_ID, Country, Biome</dt><dd><p>sPlotOpen Metadata</p>
</dd>
<dt>Species_richness</dt><dd><p>Response Variable - Plant species richness from sPlotOpen</p>
</dd>
<dt>bio_x, elev</dt><dd><p>Predictor Variables - Worldclim and SRTM elevation</p>
</dd>
<dt>geometry</dt><dd><p>Lat/Lon</p>
</dd>
</dl>



<h3>Source</h3>


<ul>
<li><p>Plot with Species_richness from <a href="https://onlinelibrary.wiley.com/doi/full/10.1111/geb.13346">sPlotOpen</a>
</p>
</li>
<li><p>predictors acquired via R package <a href="https://github.com/rspatial/geodata">geodata</a>
</p>
</li></ul>



<h3>References</h3>


<ul>
<li><p>Sabatini, F. M. et al. sPlotOpen – An environmentally balanced, open‐access, global dataset of vegetation plots. (2021). <a href="https://doi.org/10.1111/geb.13346">doi:10.1111/geb.13346</a>
</p>
</li>
<li><p>Lopez-Gonzalez, G. et al. ForestPlots.net: a web application and research tool to manage and analyse tropical forest plot data: ForestPlots.net.
Journal of Vegetation Science (2011).
</p>
</li>
<li><p>Pauchard, A. et al. Alien Plants Homogenise Protected Areas: Evidence from the Landscape and Regional Scales in South Central Chile. in Plant Invasions in Protected Areas (2013).
</p>
</li>
<li><p>Peyre, G. et al. VegPáramo, a flora and vegetation database for the Andean páramo. phytocoenologia (2015).
</p>
</li>
<li><p>Vibrans, A. C. et al. Insights from a large-scale inventory in the southern Brazilian Atlantic Forest. Scientia Agricola (2020).
</p>
</li></ul>


<hr>
<h2 id='trainDI'>Calculate Dissimilarity Index of training data</h2><span id='topic+trainDI'></span>

<h3>Description</h3>

<p>This function estimates the Dissimilarity Index (DI) of
within the training data set used for a prediction model.
Predictors can be weighted based on the internal
variable importance of the machine learning algorithm used for model training.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>trainDI(
  model = NA,
  train = NULL,
  variables = "all",
  weight = NA,
  CVtest = NULL,
  CVtrain = NULL,
  method = "L2",
  useWeight = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="trainDI_+3A_model">model</code></td>
<td>
<p>A train object created with caret used to extract weights from (based on variable importance) as well as cross-validation folds</p>
</td></tr>
<tr><td><code id="trainDI_+3A_train">train</code></td>
<td>
<p>A data.frame containing the data used for model training. Only required when no model is given</p>
</td></tr>
<tr><td><code id="trainDI_+3A_variables">variables</code></td>
<td>
<p>character vector of predictor variables. if &quot;all&quot; then all variables
of the model are used or if no model is given then of the train dataset.</p>
</td></tr>
<tr><td><code id="trainDI_+3A_weight">weight</code></td>
<td>
<p>A data.frame containing weights for each variable. Only required if no model is given.</p>
</td></tr>
<tr><td><code id="trainDI_+3A_cvtest">CVtest</code></td>
<td>
<p>list or vector. Either a list where each element contains the data points used for testing during the cross validation iteration (i.e. held back data).
Or a vector that contains the ID of the fold for each training point.
Only required if no model is given.</p>
</td></tr>
<tr><td><code id="trainDI_+3A_cvtrain">CVtrain</code></td>
<td>
<p>list. Each element contains the data points used for training during the cross validation iteration (i.e. held back data).
Only required if no model is given and only required if CVtrain is not the opposite of CVtest (i.e. if a data point is not used for testing, it is used for training).
Relevant if some data points are excluded, e.g. when using <code><a href="#topic+nndm">nndm</a></code>.</p>
</td></tr>
<tr><td><code id="trainDI_+3A_method">method</code></td>
<td>
<p>Character. Method used for distance calculation. Currently euclidean distance (L2) and Mahalanobis distance (MD) are implemented but only L2 is tested. Note that MD takes considerably longer.</p>
</td></tr>
<tr><td><code id="trainDI_+3A_useweight">useWeight</code></td>
<td>
<p>Logical. Only if a model is given. Weight variables according to importance in the model?</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of class <code>trainDI</code> containing:
</p>
<table>
<tr><td><code>train</code></td>
<td>
<p>A data frame containing the training data</p>
</td></tr>
<tr><td><code>weight</code></td>
<td>
<p>A data frame with weights based on the variable importance.</p>
</td></tr>
<tr><td><code>variables</code></td>
<td>
<p>Names of the used variables</p>
</td></tr>
<tr><td><code>catvars</code></td>
<td>
<p>Which variables are categorial</p>
</td></tr>
<tr><td><code>scaleparam</code></td>
<td>
<p>Scaling parameters. Output from <code>scale</code></p>
</td></tr>
<tr><td><code>trainDist_avrg</code></td>
<td>
<p>A data frame with the average distance of each training point to every other point</p>
</td></tr>
<tr><td><code>trainDist_avrgmean</code></td>
<td>
<p>The mean of trainDist_avrg. Used for normalizing the DI</p>
</td></tr>
<tr><td><code>trainDI</code></td>
<td>
<p>Dissimilarity Index of the training data</p>
</td></tr>
<tr><td><code>threshold</code></td>
<td>
<p>The DI threshold used for inside/outside AOA</p>
</td></tr>
</table>


<h3>Note</h3>

<p>This function is called within <code><a href="#topic+aoa">aoa</a></code> to estimate the DI and AOA of new data.
However, it may also be used on its own if only the DI of training data is of interest,
or to facilitate a parallelization of <code><a href="#topic+aoa">aoa</a></code> by avoiding a repeated calculation of the DI within the training data.
</p>


<h3>Author(s)</h3>

<p>Hanna Meyer, Marvin Ludwig
</p>


<h3>References</h3>

<p>Meyer, H., Pebesma, E. (2021): Predicting into unknown space?
Estimating the area of applicability of spatial prediction models.
<a href="https://doi.org/10.1111/2041-210X.13650">doi:10.1111/2041-210X.13650</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+aoa">aoa</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(sf)
library(terra)
library(caret)
library(viridis)
library(ggplot2)

# prepare sample data:
dat &lt;- readRDS(system.file("extdata","Cookfarm.RDS",package="CAST"))
dat &lt;- aggregate(dat[,c("VW","Easting","Northing")],by=list(as.character(dat$SOURCEID)),mean)
pts &lt;- st_as_sf(dat,coords=c("Easting","Northing"))
pts$ID &lt;- 1:nrow(pts)
set.seed(100)
pts &lt;- pts[1:30,]
studyArea &lt;- rast(system.file("extdata","predictors_2012-03-25.tif",package="CAST"))[[1:8]]
trainDat &lt;- extract(studyArea,pts,na.rm=FALSE)
trainDat &lt;- merge(trainDat,pts,by.x="ID",by.y="ID")

# visualize data spatially:
plot(studyArea)
plot(studyArea$DEM)
plot(pts[,1],add=TRUE,col="black")

# train a model:
set.seed(100)
variables &lt;- c("DEM","NDRE.Sd","TWI")
model &lt;- train(trainDat[,which(names(trainDat)%in%variables)],
trainDat$VW, method="rf", importance=TRUE, tuneLength=1,
trControl=trainControl(method="cv",number=5,savePredictions=T))
print(model) #note that this is a quite poor prediction model
prediction &lt;- predict(studyArea,model,na.rm=TRUE)
plot(varImp(model,scale=FALSE))

#...then calculate the DI of the trained model:
DI = trainDI(model=model)
plot(DI)

# the DI can now be used to compute the AOA:
AOA = aoa(studyArea, model = model, trainDI = DI)
print(AOA)
plot(AOA)

## End(Not run)

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
