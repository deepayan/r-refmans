<!DOCTYPE html><html><head><title>Help for package statcheck</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {statcheck}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#checkHTML'><p>Extract statistics from PDF/HTML articles and recalculate p-values</p></a></li>
<li><a href='#checkHTMLdir'><p>Extract statistics from folders with PDF/HTML articles and recalculate</p>
p-values</a></li>
<li><a href='#identify.statcheck'><p>Identify specific points in a statcheck plot.</p></a></li>
<li><a href='#plot.statcheck'><p>Plot method for statcheck</p></a></li>
<li><a href='#statcheck'><p>Extract statistics and recompute p-values</p></a></li>
<li><a href='#statcheck-package'><p>statcheck: Extract statistics from articles and recompute p-values</p></a></li>
<li><a href='#statcheckReport'><p>Generate HTML report for statcheck output</p></a></li>
<li><a href='#summary.statcheck'><p>Summary method for statcheck</p></a></li>
<li><a href='#trim'><p>Trimming method for statcheck output</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Title:</td>
<td>Extract Statistics from Articles and Recompute P-Values</td>
</tr>
<tr>
<td>Version:</td>
<td>1.5.0</td>
</tr>
<tr>
<td>Date:</td>
<td>2024-02-16</td>
</tr>
<tr>
<td>Description:</td>
<td>A "spellchecker" for statistics. It checks whether your
    p-values match their accompanying test statistic and degrees of
    freedom. statcheck searches for null-hypothesis significance test
    (NHST) in APA style (e.g., t(28) = 2.2, p &lt; .05). It recalculates the
    p-value using the reported test statistic and degrees of freedom. If
    the reported and computed p-values don't match, statcheck will flag
    the result as an error. If the reported p-value is statistically
    significant and the recomputed one is not, or vice versa, the result
    will be flagged as a decision error.  You can use statcheck directly
    on a string of text, but you can also scan a PDF or HTML file, or even
    a folder of PDF and/or HTML files.  Statcheck needs an external
    program to convert PDF to text: Xpdf. Instructions on where and how to
    download this program, how to install statcheck, and more details on
    what statcheck can and cannot do can be found in the online manual:
    <a href="https://rpubs.com/michelenuijten/statcheckmanual">https://rpubs.com/michelenuijten/statcheckmanual</a>.  You can find a
    point-and-click web interface to scan PDF or HTML or DOCX articles on
    <a href="http://statcheck.io">http://statcheck.io</a>.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 2.14.2)</td>
</tr>
<tr>
<td>Imports:</td>
<td>ggplot2, plyr, rlang, rmarkdown, stringi, tcltk</td>
</tr>
<tr>
<td>Suggests:</td>
<td>testthat</td>
</tr>
<tr>
<td>ByteCompile:</td>
<td>yes</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyLoad:</td>
<td>yes</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.1</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/MicheleNuijten/statcheck">https://github.com/MicheleNuijten/statcheck</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/MicheleNuijten/statcheck/issues">https://github.com/MicheleNuijten/statcheck/issues</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-02-16 19:18:37 UTC; miche</td>
</tr>
<tr>
<td>Author:</td>
<td>Michele B. Nuijten
    <a href="https://orcid.org/0000-0002-1468-8585"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut, cre],
  Sacha Epskamp <a href="https://orcid.org/0000-0003-4884-8118"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut],
  Willem Sleegers <a href="https://orcid.org/0000-0001-9058-3817"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [ctb],
  Edoardo Costantini [ctb],
  Paul van der Laken
    <a href="https://orcid.org/0000-0002-0404-9114"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [ctb],
  Sean Rife <a href="https://orcid.org/0000-0002-6748-0841"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [ctb],
  John Sakaluk <a href="https://orcid.org/0000-0002-2515-9822"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [ctb],
  Chris Hartgerink <a href="https://orcid.org/0000-0003-1050-6809"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [ctb],
  Steve Haroz <a href="https://orcid.org/0000-0002-2725-9173"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [ctb]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Michele B. Nuijten &lt;m.b.nuijten@uvt.nl&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-02-16 19:30:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='checkHTML'>Extract statistics from PDF/HTML articles and recalculate p-values</h2><span id='topic+checkHTML'></span><span id='topic+checkPDF'></span><span id='topic+checkfiles'></span>

<h3>Description</h3>

<p>These functions search for NHST results in PDF and/or HTML articles and send 
the extracted statistics to <code>statcheck</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>checkHTML(files, ...)

checkPDF(files, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="checkHTML_+3A_files">files</code></td>
<td>
<p>Vector of strings containing file paths to HTML files to check.</p>
</td></tr>
<tr><td><code id="checkHTML_+3A_...">...</code></td>
<td>
<p>Arguments sent to <code>statcheck</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A statcheck data frame with the extracted statistics. See 
<code><a href="#topic+statcheck">statcheck</a></code> for details.
</p>

<hr>
<h2 id='checkHTMLdir'>Extract statistics from folders with PDF/HTML articles and recalculate 
p-values</h2><span id='topic+checkHTMLdir'></span><span id='topic+checkPDFdir'></span><span id='topic+checkdir'></span><span id='topic+checkdirs'></span>

<h3>Description</h3>

<p>These functions search for NHST results in all PDF and/or HTML articles in a 
certain folder and send the extracted statistics to <code>statcheck</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>checkHTMLdir(dir, subdir = TRUE, extension = TRUE, ...)

checkPDFdir(dir, subdir = TRUE, ...)

checkdir(dir, subdir = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="checkHTMLdir_+3A_dir">dir</code></td>
<td>
<p>String indicating the directory to be used. If this is left empty, 
a window will pop up from which you can choose a directory.</p>
</td></tr>
<tr><td><code id="checkHTMLdir_+3A_subdir">subdir</code></td>
<td>
<p>Logical. Indicates whether you also want to check subfolders. 
Defaults to TRUE</p>
</td></tr>
<tr><td><code id="checkHTMLdir_+3A_extension">extension</code></td>
<td>
<p>Logical. Indicates whether the HTML extension should be 
checked. Defaults to TRUE</p>
</td></tr>
<tr><td><code id="checkHTMLdir_+3A_...">...</code></td>
<td>
<p>Arguments sent to <code>statcheck</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A statcheck data frame with the extracted statistics. See 
<code><a href="#topic+statcheck">statcheck</a></code> for details.
</p>

<hr>
<h2 id='identify.statcheck'>Identify specific points in a statcheck plot.</h2><span id='topic+identify.statcheck'></span>

<h3>Description</h3>

<p>With this function you can simply point and click on the datapoints in the 
plot to see the corresponding statcheck details, such as the paper from which 
the data came and the exact statistical results.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'statcheck'
identify(x, alpha = 0.05, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="identify.statcheck_+3A_x">x</code></td>
<td>
<p>A statcheck object. See <code><a href="#topic+statcheck">statcheck</a></code>.</p>
</td></tr>
<tr><td><code id="identify.statcheck_+3A_alpha">alpha</code></td>
<td>
<p>assumed level of significance in the scanned texts. Defaults to 
.05.</p>
</td></tr>
<tr><td><code id="identify.statcheck_+3A_...">...</code></td>
<td>
<p>arguments to be passed to methods, such as graphical parameters 
(see <code><a href="graphics.html#topic+par">par</a></code>).</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

# First we need a statcheck object
# Here, we create one by running statcheck on some raw text

txt &lt;- "This test is consistent t(28) = 0.2, p = .84, but this one is 
inconsistent: F(2, 28) = 4.2, p = .01. This final test is even a
gross/decision inconsistency: z = 1.23, p = .03"

result &lt;- statcheck(txt)

# Now, we can run identify.statcheck(), or shorter, simply identify():
identify(result)

# Further instructions:
# click on one or multiple points of interest
# press Esc
# a dataframe with information on the selected points will appear


## End(Not run)

</code></pre>

<hr>
<h2 id='plot.statcheck'>Plot method for statcheck</h2><span id='topic+plot.statcheck'></span>

<h3>Description</h3>

<p>Function for plotting of <code>statcheck</code> objects. Reported p values are 
plotted against recalculated p values, which allows the user to easily spot 
if articles contain miscalculations of statistical results.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'statcheck'
plot(x, alpha = 0.05, APAstyle = TRUE, group = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.statcheck_+3A_x">x</code></td>
<td>
<p>A statcheck object. See <code><a href="#topic+statcheck">statcheck</a></code>.</p>
</td></tr>
<tr><td><code id="plot.statcheck_+3A_alpha">alpha</code></td>
<td>
<p>assumed level of significance in the scanned texts. Defaults to 
.05.</p>
</td></tr>
<tr><td><code id="plot.statcheck_+3A_apastyle">APAstyle</code></td>
<td>
<p>If TRUE, prints plot in APA style.</p>
</td></tr>
<tr><td><code id="plot.statcheck_+3A_group">group</code></td>
<td>
<p>Indicate grouping variable to facet plot. Only works when 
<code>APAstyle==TRUE</code></p>
</td></tr>
<tr><td><code id="plot.statcheck_+3A_...">...</code></td>
<td>
<p>arguments to be passed to methods, such as graphical parameters 
(see <code><a href="graphics.html#topic+par">par</a></code>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If APAstyle = FALSE, inconsistencies between the reported and the recalculated p value are indicated with an orange dot. Recalculations of the p value that render a previously non significant result (p &gt;= .5) as significant (p &lt; .05), and vice versa, are considered decision errors, and are indicated with a red dot. Exactly reported p values (i.e. p = ..., as opposed to p &lt; ... or p &gt; ...) are indicated with a diamond.
</p>


<h3>Acknowledgements</h3>

<p>Many thanks to John Sakaluk who adapted the plot code to create graphs in 
APA style.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+statcheck">statcheck</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># First we need a statcheck object
# Here, we create one by running statcheck on some raw text

txt &lt;- "This test is consistent t(28) = 0.2, p = .84, but this one is 
inconsistent: F(2, 28) = 4.2, p = .01. This final test is even a
gross/decision inconsistency: z = 1.23, p = .03"

result &lt;- statcheck(txt)

# We can then plot the statcheck object 'result' by simply calling plot() on 
# "result". R will know what kind of plot to make, because "result" is of 
# class "statcheck"
plot(result)

</code></pre>

<hr>
<h2 id='statcheck'>Extract statistics and recompute p-values</h2><span id='topic+statcheck'></span>

<h3>Description</h3>

<p><code>statcheck</code> extracts Null Hypothesis Significance (NHST) results from 
strings and returns the extracted values, reported p-values and recomputed 
p-values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>statcheck(
  texts,
  stat = c("t", "F", "cor", "chisq", "Z", "Q"),
  OneTailedTests = FALSE,
  alpha = 0.05,
  pEqualAlphaSig = TRUE,
  pZeroError = TRUE,
  OneTailedTxt = FALSE,
  AllPValues = FALSE,
  messages = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="statcheck_+3A_texts">texts</code></td>
<td>
<p>A vector of strings.</p>
</td></tr>
<tr><td><code id="statcheck_+3A_stat">stat</code></td>
<td>
<p>Specify which test types you want to extract. &quot;t&quot; to extract 
t-values, &quot;F&quot; to extract F-values, &quot;cor&quot; to extract correlations, &quot;chisq&quot;to 
extract <code class="reqn">\chi2</code> values, &quot;Z&quot; to extract Z-values, and &quot;Q&quot; to extract 
Q-values. Using <code>c()</code> you can specify multiple tests. Defaults to all
tests.</p>
</td></tr>
<tr><td><code id="statcheck_+3A_onetailedtests">OneTailedTests</code></td>
<td>
<p>Logical. Do you want to assume that all reported tests 
are one-tailed (TRUE) or two-tailed (FALSE, default)?</p>
</td></tr>
<tr><td><code id="statcheck_+3A_alpha">alpha</code></td>
<td>
<p>Assumed level of significance in the scanned texts. Defaults to 
.05.</p>
</td></tr>
<tr><td><code id="statcheck_+3A_pequalalphasig">pEqualAlphaSig</code></td>
<td>
<p>Logical. If TRUE, statcheck counts p &lt;= alpha as
significant (default), if FALSE, statcheck counts p &lt; alpha as significant.</p>
</td></tr>
<tr><td><code id="statcheck_+3A_pzeroerror">pZeroError</code></td>
<td>
<p>Logical. If TRUE, statcheck counts p = .000 as an error 
(because a p-value is never exactly zero, and should be reported as &lt; .001), 
if FALSE, statcheck does not count p = .000 automatically as an error.</p>
</td></tr>
<tr><td><code id="statcheck_+3A_onetailedtxt">OneTailedTxt</code></td>
<td>
<p>Logical. If TRUE, statcheck searches the text for 
&quot;one-sided&quot;, &quot;one-tailed&quot;, and &quot;directional&quot; to identify the possible use of 
one-sided tests. If one or more of these strings is found in the text AND the 
result would have been correct if it was a one-sided test, the result is 
assumed to be indeed one-sided and is counted as correct.</p>
</td></tr>
<tr><td><code id="statcheck_+3A_allpvalues">AllPValues</code></td>
<td>
<p>Logical. If TRUE, the output will consist of a dataframe 
with all detected p values, also the ones that were not part of the full 
results in APA format.</p>
</td></tr>
<tr><td><code id="statcheck_+3A_messages">messages</code></td>
<td>
<p>Logical. If TRUE, statcheck will print a progress bar while 
it's extracting statistics from text.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>statcheck</code> roughly works in three steps.
</p>
<p><strong>1. Scan text for statistical results</strong>
</p>
<p><code>statcheck</code> uses regular expressions to recognizes statistical results 
from t-tests, F-tests, <code class="reqn">\chi2</code>-tests, Z-tests, Q-tests, and correlations. 
statcheck can only recognize these results if the results are reported 
exactly according to the APA guidelines:
</p>

<ul>
<li> <p><em>t</em>(df) = value, <em>p</em> = value
</p>
</li>
<li> <p><em>F</em>(df1, df2) = value, <em>p</em> = value
</p>
</li>
<li> <p><em>r</em>(df) = value, p = value
</p>
</li>
<li> <p><em><code class="reqn">\chi2</code></em> (df, N = value) = value, <em>p</em> = value 
(N is optional)
</p>
</li>
<li> <p><em>Z</em> = value, <em>p</em> = value
</p>
</li>
<li> <p><em>Q</em>(df) = value, <em>p</em> = value (statcheck can distinguish
between Q, Qw / Q-within, and Qb / Q-between)
</p>
</li></ul>

<p><code>statcheck</code> takes into account that test statistics and p values may be 
exactly (=) or inexactly (&lt; or &gt;) reported. Different spacing has also been 
taken into account.
</p>
<p><strong>2. Recompute p-value</strong>
</p>
<p><code>statcheck</code> uses the reported test statistic and degrees of freedom to
recompute the p-value. By default, the recomputed p-value is two-sided
</p>
<p><strong>3. Compare reported and recomputed p-value</strong>
</p>
<p>This comparison takes into account how the results were reported, e.g., 
p &lt; .05 is treated differently than p = .05. Incongruent p values are marked 
as an <code>error</code>. If the reported result is significant and the recomputed 
result is not, or vice versa, the result is marked as a 
<code>decision_error</code>.
</p>
<p>Correct rounding is taken into account. For instance, a reported t-value of 
2.35 could correspond to an actual value of 2.345 to 2.354 with a range of 
p-values that can slightly deviate from the recomputed p-value. 
<code>statcheck</code> will not count cases like this as errors.
</p>
<p>Note that when <code>statcheck</code> flags an <code>error</code> or 
<code>decision_error</code>, it implicitly assumes that the p-value is the 
inconsistent value, but it could just as well be the case that the test 
statistic or degrees of freedom contain a reporting error. <code>statcheck</code>
merely detects wether a set of numbers is consistent with each other.
</p>


<h3>Value</h3>

<p>A data frame containing for each extracted statistic:
</p>

<dl>
<dt>source</dt><dd><p>Name of the file of which the statistic is extracted</p>
</dd>
<dt>test_type</dt><dd><p>Character indicating the statistic that is extracted</p>
</dd>
<dt>df1</dt><dd><p>First degree of freedom (if applicable)</p>
</dd>
<dt>df2</dt><dd><p>Second degree of freedom</p>
</dd>
<dt>test_comp</dt><dd><p>Reported comparison of the test statistic, when 
importing from pdf this will often not be converted properly</p>
</dd>
<dt>test_value</dt><dd><p>Reported value of the statistic</p>
</dd>
<dt>p_comp</dt><dd><p>Reported comparison, when importing from pdf this might not 
be converted properly</p>
</dd>
<dt>reported_p</dt><dd><p>The reported p-value, or NA if the reported value was 
n.s.</p>
</dd>
<dt>computed_p</dt><dd><p>The recomputed p-value</p>
</dd>
<dt>raw</dt><dd><p>Raw string of the statistical reference that is extracted</p>
</dd>
<dt>error</dt><dd><p>The computed p value is not congruent with the reported 
p-value</p>
</dd>
<dt>decision_error</dt><dd><p>The reported result is significant whereas the 
recomputed result is not, or vice versa.</p>
</dd>
<dt>one_tailed_in_txt</dt><dd><p>Logical. Does the text contain the string 
&quot;sided&quot;, &quot;tailed&quot;, and/or &quot;directional&quot;?</p>
</dd>
<dt>apa_factor</dt><dd><p>What proportion of all detected p-values was part of a 
fully APA reported result?</p>
</dd>
</dl>



<h3>See Also</h3>

<p>For more details, see the 
<a href="https://rpubs.com/michelenuijten/statcheckmanual">online manual</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>txt &lt;- "blablabla the effect was very significant (t(100)=1, p &lt; 0.001)"
statcheck(txt)

</code></pre>

<hr>
<h2 id='statcheck-package'>statcheck: Extract statistics from articles and recompute p-values</h2><span id='topic+statcheck-package'></span>

<h3>Description</h3>

<p>The package <code>statcheck</code> can extract Null Hypothesis Significance Test
(NHST) results from articles (or plain text) and recomputes p-values to check 
whether a reported NHST result is internally consistent or not.
</p>


<h3>Details</h3>

<p><code>statcheck</code> can be used for multiple purposes, including:
</p>

<ul>
<li> <p><strong>Self-checks</strong>: you can use statcheck to make sure your 
manuscript doesn't contain copy-paste errors or other inconsistencies 
before you submit it to a journal.
</p>
</li>
<li> <p><strong>Peer review</strong>: editors and reviewers can use statcheck to 
check submitted manuscripts for statistical inconsistencies. They can ask 
authors for a correction or clarification before publishing a manuscript.
</p>
</li>
<li> <p><strong>Research</strong>: statcheck can be used to automatically extract 
statistical test results from articles that can then be analyzed. You can 
for instance investigate whether you can predict statistical 
inconsistencies (see e.g., Nuijten et al., 2017 &lt;doi:10.1525/collabra.102&gt;), 
or use it to analyze p-value distributions (see e.g., 
Hartgerink et al., 2016 &lt;doi:10.7717/peerj.1935&gt;).
</p>
</li></ul>



<h3>Using statcheck on a string of text</h3>

<p>The most basic usage of <code>statcheck</code> is to directly extract NHST results 
and check for inconsistencies in a string of text. See 
<code><a href="#topic+statcheck">statcheck</a></code> for details and an example of how to do this.
</p>


<h3>Using statcheck on an article</h3>

<p>Another option is to run <code>statcheck</code> on an article (PDF or HTML). This 
is a useful option if you want to check for inconsistencies in a single 
article (e.g., as a final check before you submit it). Depending on whether
you want to check an article in HTML or PDF, you can use 
<code><a href="#topic+checkHTML">checkHTML</a></code> or <code><a href="#topic+checkPDF">checkPDF</a></code>, respectively. Note: it is
recommended to check articles in HTML, as converting PDF files to plain text
sometimes results in some conversion errors.
</p>


<h3>Using statcheck on a folder of articles</h3>

<p>Finally, it is possible to run <code>statcheck</code> on an entire folder of 
articles. This is often useful for meta-research. To do so, you can use
<code><a href="#topic+checkPDFdir">checkPDFdir</a></code> to check all PDF articles in a folder, 
<code><a href="#topic+checkHTMLdir">checkHTMLdir</a></code> to check all PDF articles in a folder, and 
<code><a href="#topic+checkdir">checkdir</a></code> to check both PDF and HTML articles in a folder.
</p>


<h3>Accuracy of the algorithm in detecting inconsistencies</h3>

<p>It is important to note that <code>statcheck</code> is not perfect. Its performance
in detecting NHST results depends on the type-setting and reporting style of 
an article and can vary widely. However, <code>statcheck</code> performs well in 
classifying the retrieved statistics in different consistency categories. We 
found that statcheck’s sensitivity (true positive rate) and specificity (true 
negative rate) were high: between 85.3
respectively, depending on the assumptions and settings. The overall accuracy 
of statcheck ranged from 96.2
can be found in <a href="https://osf.io/preprints/psyarxiv/tcxaj/">Nuijten et al., 2017</a>.
</p>


<h3>Manual</h3>

<p>Details on what statcheck can and cannot do, and how to install the package
and the necessary program Xpdf can be found in the 
<a href="https://rpubs.com/michelenuijten/statcheckmanual">online manual</a>.
</p>


<h3>Web app</h3>

<p><code>statcheck</code> is also available as a free, online web app at 
<a href="http://statcheck.io">http://statcheck.io</a>.
</p>


<h3>Author(s)</h3>

<p><strong>Maintainer</strong>: Michele B. Nuijten <a href="mailto:m.b.nuijten@uvt.nl">m.b.nuijten@uvt.nl</a> (<a href="https://orcid.org/0000-0002-1468-8585">ORCID</a>)
</p>
<p>Authors:
</p>

<ul>
<li><p> Sacha Epskamp <a href="mailto:mail@sachaepskamp.com">mail@sachaepskamp.com</a> (<a href="https://orcid.org/0000-0003-4884-8118">ORCID</a>)
</p>
</li></ul>

<p>Other contributors:
</p>

<ul>
<li><p> Willem Sleegers (<a href="https://orcid.org/0000-0001-9058-3817">ORCID</a>) [contributor]
</p>
</li>
<li><p> Edoardo Costantini [contributor]
</p>
</li>
<li><p> Paul van der Laken (<a href="https://orcid.org/0000-0002-0404-9114">ORCID</a>) [contributor]
</p>
</li>
<li><p> Sean Rife (<a href="https://orcid.org/0000-0002-6748-0841">ORCID</a>) [contributor]
</p>
</li>
<li><p> John Sakaluk (<a href="https://orcid.org/0000-0002-2515-9822">ORCID</a>) [contributor]
</p>
</li>
<li><p> Chris Hartgerink (<a href="https://orcid.org/0000-0003-1050-6809">ORCID</a>) [contributor]
</p>
</li>
<li><p> Steve Haroz (<a href="https://orcid.org/0000-0002-2725-9173">ORCID</a>) [contributor]
</p>
</li></ul>



<h3>References</h3>

<p>Hartgerink, C. H. J., Van Aert, R. C. M., Nuijten, M. B., Wicherts, J. M., 
Van Assen, M. A. L. M. (2016). Distributions of p-values smaller than .05 in 
psychology: What is going on? <em>PeerJ</em>, <em>4</em>, e1935. 
doi: 10.7717/peerj.1935
</p>
<p>Nuijten, M. B., Borghuis, J., Veldkamp, C. L. S., Dominguez-Alvarez, L., Van 
Assen, M. A. L. M., &amp; Wicherts, J. M. (2017).  Journal data sharing policies 
and statistical reporting inconsistencies in psychology. 
<em>Collabra: Psychology</em>, <em>3</em>(1), 1-22. doi: 10.1525/collabra.102.
</p>
<p>Nuijten, M. B., Van Assen, M. A. L. M., Hartgerink, C. H. J., Epskamp, S., &amp; 
Wicherts, J. M. (2017). The validity of the tool &quot;statcheck&quot; in discovering 
statistical reporting inconsistencies. <em>Preprint retrieved from 
https://osf.io/preprints/psyarxiv/tcxaj/.</em>
</p>


<h3>See Also</h3>

<p>Useful links:
</p>

<ul>
<li> <p><a href="https://github.com/MicheleNuijten/statcheck">https://github.com/MicheleNuijten/statcheck</a>
</p>
</li>
<li><p> Report bugs at <a href="https://github.com/MicheleNuijten/statcheck/issues">https://github.com/MicheleNuijten/statcheck/issues</a>
</p>
</li></ul>


<hr>
<h2 id='statcheckReport'>Generate HTML report for statcheck output</h2><span id='topic+statcheckReport'></span>

<h3>Description</h3>

<p>This function uses R Markdown to generate a nicely formatted HTML report of 
<code><a href="#topic+statcheck">statcheck</a></code> output.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>statcheckReport(statcheckOutput, outputFileName, outputDir)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="statcheckReport_+3A_statcheckoutput">statcheckOutput</code></td>
<td>
<p>statcheck output of one of the following functions: 
<code><a href="#topic+statcheck">statcheck</a></code>, <code><a href="#topic+checkPDFdir">checkPDFdir</a></code>, <code><a href="#topic+checkPDF">checkPDF</a></code>, 
<code><a href="#topic+checkHTMLdir">checkHTMLdir</a></code>, <code><a href="#topic+checkHTML">checkHTML</a></code>, or
<code><a href="#topic+checkdir">checkdir</a></code>.</p>
</td></tr>
<tr><td><code id="statcheckReport_+3A_outputfilename">outputFileName</code></td>
<td>
<p>String specifying the file name under which you want to 
save the generated HTML report. The extension &quot;.html&quot; is automatically added, 
so doesn't need to be specified in this argument.</p>
</td></tr>
<tr><td><code id="statcheckReport_+3A_outputdir">outputDir</code></td>
<td>
<p>String specifying the directory in which you want to save 
the generated HTML report.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function temporarily saves the inserted <code>statcheck</code> output as an 
.RData file in the &quot;output&quot; folder in the statcheck package directory. This 
file is then called by the .Rmd template that is saved in the folder &quot;rmd&quot;, 
also in the statcheck package directory. After the HTML report is generated, 
the .RData file is removed again.
</p>


<h3>Value</h3>

<p>An HTML report, saved in the directory specified in the argument 
&quot;outputDir&quot;.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

# first generate statcheck output, for instance by using the statcheck() 
function

txt &lt;- "blablabla the effect was very significant (t(100)=1, p &lt; 0.001)"
stat &lt;- statcheck(txt)

# next, use this output to generate a nice HTML report of the results
statcheckReport(stat, outputFileName="statcheckHTMLReport", 
                outputDir="C:/mydocuments/results")

# you can now find your HTML report in the folder 
# "C:/mydocuments/results" under the name "statcheckHTMLReport.html".


## End(Not run)

</code></pre>

<hr>
<h2 id='summary.statcheck'>Summary method for statcheck</h2><span id='topic+summary.statcheck'></span>

<h3>Description</h3>

<p>Gives the summaries for a <code>statcheck</code> object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'statcheck'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.statcheck_+3A_object">object</code></td>
<td>
<p>a <code>statcheck</code> object.</p>
</td></tr>
<tr><td><code id="summary.statcheck_+3A_...">...</code></td>
<td>
<p>additional arguments affecting the summary produced.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame containing for each source of statistics:
</p>

<dl>
<dt>source</dt><dd><p>Name of the file/origin of which the statistics are 
extracted</p>
</dd>
<dt>nr_p_values</dt><dd><p>The number of extracted reported p values per article</p>
</dd>
<dt>nr_errors</dt><dd><p>The number of errors per article</p>
</dd>
<dt>nr_decision_errors</dt><dd><p>The number of decision errors per article</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>txt &lt;- "blablabla the effect was very significant (t(100)=1, p &lt; 0.001)"
stat &lt;- statcheck(txt)
summary(stat)

</code></pre>

<hr>
<h2 id='trim'>Trimming method for statcheck output</h2><span id='topic+trim'></span>

<h3>Description</h3>

<p>Returns a subset of columns of a <code>statcheck</code> object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>trim(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="trim_+3A_object">object</code></td>
<td>
<p>a <code>statcheck</code> object.</p>
</td></tr>
<tr><td><code id="trim_+3A_...">...</code></td>
<td>
<p>additional arguments affecting the trimmed output.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame containing for each source of statistics:
</p>

<dl>
<dt>source</dt><dd><p>Name of the file/origin of which the statistics are 
extracted</p>
</dd>
<dt>raw</dt><dd><p>Raw string of the statistical reference that is extracted</p>
</dd>
<dt>computed_p</dt><dd><p>The recomputed p-value</p>
</dd>
<dt>error</dt><dd><p>The computed p value is not congruent with the reported 
p-value</p>
</dd>
<dt>decision_error</dt><dd><p>The reported result is significant whereas the 
recomputed result is not, or vice versa.</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>txt &lt;- "blablabla the effect was very significant (t(100)=1, p &lt; 0.001)"
stat &lt;- statcheck(txt)
trim(stat)

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
