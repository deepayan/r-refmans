<!DOCTYPE html><html><head><title>Help for package parameters</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {parameters}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#.data_frame'><p>help-functions</p></a></li>
<li><a href='#.factor_to_dummy'><p>Safe transformation from factor/character to numeric</p></a></li>
<li><a href='#.filter_component'><p>for models with zero-inflation component, return required component of model-summary</p></a></li>
<li><a href='#.n_factors_bartlett'><p>Bartlett, Anderson and Lawley Procedures</p></a></li>
<li><a href='#.n_factors_bentler'><p>Bentler and Yuan's Procedure</p></a></li>
<li><a href='#.n_factors_cng'><p>Cattell-Nelson-Gorsuch CNG Indices</p></a></li>
<li><a href='#.n_factors_mreg'><p>Multiple Regression Procedure</p></a></li>
<li><a href='#.n_factors_scree'><p>Non Graphical Cattell's Scree Test</p></a></li>
<li><a href='#.n_factors_sescree'><p>Standard Error Scree and Coefficient of Determination Procedures</p></a></li>
<li><a href='#bootstrap_model'><p>Model bootstrapping</p></a></li>
<li><a href='#bootstrap_parameters'><p>Parameters bootstrapping</p></a></li>
<li><a href='#ci_betwithin'><p>Between-within approximation for SEs, CIs and p-values</p></a></li>
<li><a href='#ci_kenward'><p>Kenward-Roger approximation for SEs, CIs and p-values</p></a></li>
<li><a href='#ci_ml1'><p>&quot;m-l-1&quot; approximation for SEs, CIs and p-values</p></a></li>
<li><a href='#ci_satterthwaite'><p>Satterthwaite approximation for SEs, CIs and p-values</p></a></li>
<li><a href='#ci.default'><p>Confidence Intervals (CI)</p></a></li>
<li><a href='#cluster_analysis'><p>Cluster Analysis</p></a></li>
<li><a href='#cluster_centers'><p>Find the cluster centers in your data</p></a></li>
<li><a href='#cluster_discrimination'><p>Compute a linear discriminant analysis on classified cluster groups</p></a></li>
<li><a href='#cluster_meta'><p>Metaclustering</p></a></li>
<li><a href='#cluster_performance'><p>Performance of clustering models</p></a></li>
<li><a href='#compare_parameters'><p>Compare model parameters of multiple models</p></a></li>
<li><a href='#convert_efa_to_cfa'><p>Conversion between EFA results and CFA structure</p></a></li>
<li><a href='#degrees_of_freedom'><p>Degrees of Freedom (DoF)</p></a></li>
<li><a href='#display.parameters_model'><p>Print tables in different output formats</p></a></li>
<li><a href='#dominance_analysis'><p>Dominance Analysis</p></a></li>
<li><a href='#equivalence_test.lm'><p>Equivalence test</p></a></li>
<li><a href='#factor_analysis'><p>Principal Component Analysis (PCA) and Factor Analysis (FA)</p></a></li>
<li><a href='#fish'><p>Sample data set</p></a></li>
<li><a href='#format_df_adjust'><p>Format the name of the degrees-of-freedom adjustment methods</p></a></li>
<li><a href='#format_order'><p>Order (first, second, ...) formatting</p></a></li>
<li><a href='#format_p_adjust'><p>Format the name of the p-value adjustment methods</p></a></li>
<li><a href='#format_parameters'><p>Parameter names formatting</p></a></li>
<li><a href='#get_scores'><p>Get Scores from Principal Component Analysis (PCA)</p></a></li>
<li><a href='#model_parameters'><p>Model Parameters</p></a></li>
<li><a href='#model_parameters.aov'><p>Parameters from ANOVAs</p></a></li>
<li><a href='#model_parameters.befa'><p>Parameters from Bayesian Exploratory Factor Analysis</p></a></li>
<li><a href='#model_parameters.BFBayesFactor'><p>Parameters from BayesFactor objects</p></a></li>
<li><a href='#model_parameters.cgam'><p>Parameters from Generalized Additive (Mixed) Models</p></a></li>
<li><a href='#model_parameters.cpglmm'><p>Parameters from Mixed Models</p></a></li>
<li><a href='#model_parameters.dbscan'><p>Parameters from Cluster Models (k-means, ...)</p></a></li>
<li><a href='#model_parameters.default'><p>Parameters from (General) Linear Models</p></a></li>
<li><a href='#model_parameters.DirichletRegModel'><p>Parameters from multinomial or cumulative link models</p></a></li>
<li><a href='#model_parameters.glht'><p>Parameters from Hypothesis Testing</p></a></li>
<li><a href='#model_parameters.glimML'><p>Parameters from special models</p></a></li>
<li><a href='#model_parameters.htest'><p>Parameters from hypothesis tests</p></a></li>
<li><a href='#model_parameters.MCMCglmm'><p>Parameters from Bayesian Models</p></a></li>
<li><a href='#model_parameters.mipo'><p>Parameters from multiply imputed repeated analyses</p></a></li>
<li><a href='#model_parameters.PCA'><p>Parameters from PCA, FA, CFA, SEM</p></a></li>
<li><a href='#model_parameters.rma'><p>Parameters from Meta-Analysis</p></a></li>
<li><a href='#model_parameters.t1way'><p>Parameters from robust statistical objects in <code>WRS2</code></p></a></li>
<li><a href='#model_parameters.zcpglm'><p>Parameters from Zero-Inflated Models</p></a></li>
<li><a href='#n_clusters'><p>Find number of clusters in your data</p></a></li>
<li><a href='#n_factors'><p>Number of components/factors to retain in PCA/FA</p></a></li>
<li><a href='#p_calibrate'><p>Calculate calibrated p-values.</p></a></li>
<li><a href='#p_function'><p>p-value or consonance function</p></a></li>
<li><a href='#p_value'><p>p-values</p></a></li>
<li><a href='#p_value.BFBayesFactor'><p>p-values for Bayesian Models</p></a></li>
<li><a href='#p_value.DirichletRegModel'><p>p-values for Models with Special Components</p></a></li>
<li><a href='#p_value.poissonmfx'><p>p-values for Marginal Effects Models</p></a></li>
<li><a href='#p_value.zcpglm'><p>p-values for Models with Zero-Inflation</p></a></li>
<li><a href='#parameters_type'><p>Type of model parameters</p></a></li>
<li><a href='#parameters-package'><p>parameters: Extracting, Computing and Exploring the Parameters of Statistical Models using R</p></a></li>
<li><a href='#pool_parameters'><p>Pool Model Parameters</p></a></li>
<li><a href='#predict.parameters_clusters'><p>Predict method for parameters_clusters objects</p></a></li>
<li><a href='#print.parameters_model'><p>Print model parameters</p></a></li>
<li><a href='#qol_cancer'><p>Sample data set</p></a></li>
<li><a href='#random_parameters'><p>Summary information from random effects</p></a></li>
<li><a href='#reduce_parameters'><p>Dimensionality reduction (DR) / Features Reduction</p></a></li>
<li><a href='#reexports'><p>Objects exported from other packages</p></a></li>
<li><a href='#reshape_loadings'><p>Reshape loadings between wide/long formats</p></a></li>
<li><a href='#select_parameters'><p>Automated selection of model parameters</p></a></li>
<li><a href='#simulate_model'><p>Simulated draws from model coefficients</p></a></li>
<li><a href='#simulate_parameters.glmmTMB'><p>Simulate Model Parameters</p></a></li>
<li><a href='#sort_parameters'><p>Sort parameters by coefficient values</p></a></li>
<li><a href='#standard_error'><p>Standard Errors</p></a></li>
<li><a href='#standardize_info'><p>Get Standardization Information</p></a></li>
<li><a href='#standardize_parameters'><p>Parameters standardization</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Processing of Model Parameters</td>
</tr>
<tr>
<td>Version:</td>
<td>0.21.6</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Daniel Lüdecke &lt;d.luedecke@uke.de&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Utilities for processing the parameters of various
    statistical models. Beyond computing p values, CIs, and other indices
    for a wide variety of models (see list of supported models using the
    function 'insight::supported_models()'), this package implements
    features like bootstrapping or simulating of parameters and models,
    feature reduction (feature extraction and variable selection) as well
    as functions to describe data and variable characteristics (e.g.
    skewness, kurtosis, smoothness or distribution).</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://easystats.github.io/parameters/">https://easystats.github.io/parameters/</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/easystats/parameters/issues">https://github.com/easystats/parameters/issues</a></td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.6)</td>
</tr>
<tr>
<td>Imports:</td>
<td>bayestestR (&ge; 0.13.2), datawizard (&ge; 0.9.1), insight (&ge;
0.19.8), graphics, methods, stats, utils</td>
</tr>
<tr>
<td>Suggests:</td>
<td>AER, afex, aod, BayesFactor (&ge; 0.9.12-4.7), BayesFM, bbmle,
betareg, BH, biglm, blme, boot, brglm2, brms, broom, cAIC4,
car, carData, cgam, ClassDiscovery, clubSandwich, cluster,
coda, cplm, dbscan, domir (&ge; 0.2.0), drc, DRR, effectsize (&ge;
0.8.6), EGAnet, emmeans (&ge; 1.7.0), epiR, estimatr, factoextra,
FactoMineR, faraway, fastICA, fixest, fpc, gam, gamlss, gee,
geepack, ggeffects (&ge; 1.3.2), ggplot2, GLMMadaptive, glmmTMB,
GPArotation, gt, haven, httr, Hmisc, ivprobit, ivreg, knitr,
lavaan, lfe, lm.beta, lme4, lmerTest, lmtest, logistf,
logspline, lqmm, M3C, marginaleffects (&ge; 0.16.0), MASS,
Matrix, mclogit, mclust, MCMCglmm, mediation, merDeriv,
metaBMA, metafor, mfx, mgcv, mice, mmrm, multcomp, MuMIn,
NbClust, nFactors, nestedLogit, nlme, nnet, openxlsx, ordinal,
panelr, pbkrtest, PCDimension, performance (&ge; 0.10.8), plm,
PMCMRplus, poorman, posterior, PROreg (&ge; 1.3.0), pscl, psych,
pvclust, quantreg, randomForest, rmarkdown, rms, rstanarm,
sandwich, see (&ge; 0.8.1), serp, sparsepca, survey, survival,
testthat (&ge; 3.2.1), tidyselect, tinytable (&ge; 0.1.0), TMB,
truncreg, VGAM, withr, WRS2</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Language:</td>
<td>en-US</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.1</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>Config/testthat/parallel:</td>
<td>true</td>
</tr>
<tr>
<td>Config/Needs/website:</td>
<td>rstudio/bslib, r-lib/pkgdown,
easystats/easystatstemplate</td>
</tr>
<tr>
<td>Config/rcmdcheck/ignore-inconsequential-notes:</td>
<td>true</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-03-17 15:06:15 UTC; Daniel</td>
</tr>
<tr>
<td>Author:</td>
<td>Daniel Lüdecke <a href="https://orcid.org/0000-0002-8895-3206"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cre] (@strengejacke),
  Dominique Makowski
    <a href="https://orcid.org/0000-0001-5375-9967"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut]
    (@Dom_Makowski),
  Mattan S. Ben-Shachar
    <a href="https://orcid.org/0000-0002-4287-4801"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut],
  Indrajeet Patil <a href="https://orcid.org/0000-0003-1995-6531"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut] (@patilindrajeets),
  Søren Højsgaard [aut],
  Brenton M. Wiernik
    <a href="https://orcid.org/0000-0001-9560-6336"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut]
    (@bmwiernik),
  Zen J. Lau [ctb],
  Vincent Arel-Bundock
    <a href="https://orcid.org/0000-0003-1995-6531"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [ctb]
    (@vincentab),
  Jeffrey Girard <a href="https://orcid.org/0000-0002-7359-3746"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [ctb] (@jeffreymgirard),
  Christina Maimone [rev],
  Niels Ohlsen [rev] (@Niels_Bremen),
  Douglas Ezra Morrison
    <a href="https://orcid.org/0000-0002-7195-830X"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [ctb]
    (@demstats1),
  Joseph Luchman <a href="https://orcid.org/0000-0002-8886-9717"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [ctb]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-03-18 08:30:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='.data_frame'>help-functions</h2><span id='topic+.data_frame'></span>

<h3>Description</h3>

<p>help-functions
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.data_frame(...)
</code></pre>

<hr>
<h2 id='.factor_to_dummy'>Safe transformation from factor/character to numeric</h2><span id='topic+.factor_to_dummy'></span>

<h3>Description</h3>

<p>Safe transformation from factor/character to numeric
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.factor_to_dummy(x)
</code></pre>

<hr>
<h2 id='.filter_component'>for models with zero-inflation component, return required component of model-summary</h2><span id='topic+.filter_component'></span>

<h3>Description</h3>

<p>for models with zero-inflation component, return required component of model-summary
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.filter_component(dat, component)
</code></pre>

<hr>
<h2 id='.n_factors_bartlett'>Bartlett, Anderson and Lawley Procedures</h2><span id='topic+.n_factors_bartlett'></span>

<h3>Description</h3>

<p>Bartlett, Anderson and Lawley Procedures
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.n_factors_bartlett(eigen_values = NULL, model = "factors", nobs = NULL)
</code></pre>

<hr>
<h2 id='.n_factors_bentler'>Bentler and Yuan's Procedure</h2><span id='topic+.n_factors_bentler'></span>

<h3>Description</h3>

<p>Bentler and Yuan's Procedure
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.n_factors_bentler(eigen_values = NULL, model = "factors", nobs = NULL)
</code></pre>

<hr>
<h2 id='.n_factors_cng'>Cattell-Nelson-Gorsuch CNG Indices</h2><span id='topic+.n_factors_cng'></span>

<h3>Description</h3>

<p>Cattell-Nelson-Gorsuch CNG Indices
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.n_factors_cng(eigen_values = NULL, model = "factors")
</code></pre>

<hr>
<h2 id='.n_factors_mreg'>Multiple Regression Procedure</h2><span id='topic+.n_factors_mreg'></span>

<h3>Description</h3>

<p>Multiple Regression Procedure
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.n_factors_mreg(eigen_values = NULL, model = "factors")
</code></pre>

<hr>
<h2 id='.n_factors_scree'>Non Graphical Cattell's Scree Test</h2><span id='topic+.n_factors_scree'></span>

<h3>Description</h3>

<p>Non Graphical Cattell's Scree Test
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.n_factors_scree(eigen_values = NULL, model = "factors")
</code></pre>

<hr>
<h2 id='.n_factors_sescree'>Standard Error Scree and Coefficient of Determination Procedures</h2><span id='topic+.n_factors_sescree'></span>

<h3>Description</h3>

<p>Standard Error Scree and Coefficient of Determination Procedures
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.n_factors_sescree(eigen_values = NULL, model = "factors")
</code></pre>

<hr>
<h2 id='bootstrap_model'>Model bootstrapping</h2><span id='topic+bootstrap_model'></span><span id='topic+bootstrap_model.default'></span><span id='topic+bootstrap_model.merMod'></span>

<h3>Description</h3>

<p>Bootstrap a statistical model n times to return a data frame of estimates.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bootstrap_model(model, iterations = 1000, ...)

## Default S3 method:
bootstrap_model(
  model,
  iterations = 1000,
  type = "ordinary",
  parallel = c("no", "multicore", "snow"),
  n_cpus = 1,
  verbose = FALSE,
  ...
)

## S3 method for class 'merMod'
bootstrap_model(
  model,
  iterations = 1000,
  type = "parametric",
  parallel = c("no", "multicore", "snow"),
  n_cpus = 1,
  cluster = NULL,
  verbose = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bootstrap_model_+3A_model">model</code></td>
<td>
<p>Statistical model.</p>
</td></tr>
<tr><td><code id="bootstrap_model_+3A_iterations">iterations</code></td>
<td>
<p>The number of draws to simulate/bootstrap.</p>
</td></tr>
<tr><td><code id="bootstrap_model_+3A_...">...</code></td>
<td>
<p>Arguments passed to or from other methods.</p>
</td></tr>
<tr><td><code id="bootstrap_model_+3A_type">type</code></td>
<td>
<p>Character string specifying the type of bootstrap. For mixed models
of class <code>merMod</code> or <code>glmmTMB</code>, may be <code>"parametric"</code> (default) or
<code>"semiparametric"</code> (see <code>?lme4::bootMer</code> for details). For all
other models, see argument <code>sim</code> in <code>?boot::boot</code> (defaults to
<code>"ordinary"</code>).</p>
</td></tr>
<tr><td><code id="bootstrap_model_+3A_parallel">parallel</code></td>
<td>
<p>The type of parallel operation to be used (if any).</p>
</td></tr>
<tr><td><code id="bootstrap_model_+3A_n_cpus">n_cpus</code></td>
<td>
<p>Number of processes to be used in parallel operation.</p>
</td></tr>
<tr><td><code id="bootstrap_model_+3A_verbose">verbose</code></td>
<td>
<p>Toggle warnings and messages.</p>
</td></tr>
<tr><td><code id="bootstrap_model_+3A_cluster">cluster</code></td>
<td>
<p>Optional cluster when <code>parallel = "snow"</code>. See <code>?lme4::bootMer</code>
for details.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>By default, <code>boot::boot()</code> is used to generate bootstraps from
the model data, which are then used to <code>update()</code> the model, i.e. refit
the model with the bootstrapped samples. For <code>merMod</code> objects (<strong>lme4</strong>)
or models from <strong>glmmTMB</strong>, the <code>lme4::bootMer()</code> function is used to
obtain bootstrapped samples. <code>bootstrap_parameters()</code> summarizes the
bootstrapped model estimates.
</p>


<h3>Value</h3>

<p>A data frame of bootstrapped estimates.
</p>


<h3>Using with <strong>emmeans</strong></h3>

<p>The output can be passed directly to the various functions from the
<strong>emmeans</strong> package, to obtain bootstrapped estimates, contrasts, simple
slopes, etc. and their confidence intervals. These can then be passed to
<code>model_parameter()</code> to obtain standard errors, p-values, etc. (see
example).
</p>
<p>Note that that p-values returned here are estimated under the assumption of
<em>translation equivariance</em>: that shape of the sampling distribution is
unaffected by the null being true or not. If this assumption does not hold,
p-values can be biased, and it is suggested to use proper permutation tests
to obtain non-parametric p-values.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+bootstrap_parameters">bootstrap_parameters()</a></code>, <code><a href="#topic+simulate_model">simulate_model()</a></code>, <code><a href="#topic+simulate_parameters">simulate_parameters()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

model &lt;- lm(mpg ~ wt + factor(cyl), data = mtcars)
b &lt;- bootstrap_model(model)
print(head(b))

est &lt;- emmeans::emmeans(b, consec ~ cyl)
print(model_parameters(est))


</code></pre>

<hr>
<h2 id='bootstrap_parameters'>Parameters bootstrapping</h2><span id='topic+bootstrap_parameters'></span><span id='topic+bootstrap_parameters.default'></span>

<h3>Description</h3>

<p>Compute bootstrapped parameters and their related indices such as Confidence Intervals (CI) and p-values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bootstrap_parameters(model, ...)

## Default S3 method:
bootstrap_parameters(
  model,
  iterations = 1000,
  centrality = "median",
  ci = 0.95,
  ci_method = "quantile",
  test = "p-value",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bootstrap_parameters_+3A_model">model</code></td>
<td>
<p>Statistical model.</p>
</td></tr>
<tr><td><code id="bootstrap_parameters_+3A_...">...</code></td>
<td>
<p>Arguments passed to or from other methods.</p>
</td></tr>
<tr><td><code id="bootstrap_parameters_+3A_iterations">iterations</code></td>
<td>
<p>The number of draws to simulate/bootstrap.</p>
</td></tr>
<tr><td><code id="bootstrap_parameters_+3A_centrality">centrality</code></td>
<td>
<p>The point-estimates (centrality indices) to compute. Character
(vector) or list with one or more of these options: <code>"median"</code>, <code>"mean"</code>, <code>"MAP"</code>
(see <code><a href="bayestestR.html#topic+map_estimate">map_estimate()</a></code>), <code>"trimmed"</code> (which is just <code>mean(x, trim = threshold)</code>),
<code>"mode"</code> or <code>"all"</code>.</p>
</td></tr>
<tr><td><code id="bootstrap_parameters_+3A_ci">ci</code></td>
<td>
<p>Value or vector of probability of the CI (between 0 and 1)
to be estimated. Default to <code>0.95</code> (<code style="white-space: pre;">&#8288;95%&#8288;</code>).</p>
</td></tr>
<tr><td><code id="bootstrap_parameters_+3A_ci_method">ci_method</code></td>
<td>
<p>The type of index used for Credible Interval. Can be
<code>"ETI"</code> (default, see <code><a href="bayestestR.html#topic+eti">eti()</a></code>), <code>"HDI"</code>
(see <code><a href="bayestestR.html#topic+hdi">hdi()</a></code>), <code>"BCI"</code> (see
<code><a href="bayestestR.html#topic+bci">bci()</a></code>), <code>"SPI"</code> (see <code><a href="bayestestR.html#topic+spi">spi()</a></code>), or
<code>"SI"</code> (see <code><a href="bayestestR.html#topic+si">si()</a></code>).</p>
</td></tr>
<tr><td><code id="bootstrap_parameters_+3A_test">test</code></td>
<td>
<p>The indices to compute. Character (vector) with one or more of
these options: <code>"p-value"</code> (or <code>"p"</code>), <code>"p_direction"</code> (or <code>"pd"</code>), <code>"rope"</code>,
<code>"p_map"</code>, <code>"equivalence_test"</code> (or <code>"equitest"</code>), <code>"bayesfactor"</code> (or <code>"bf"</code>)
or <code>"all"</code> to compute all tests. For each &quot;test&quot;, the corresponding
<strong>bayestestR</strong> function is called (e.g. <code><a href="bayestestR.html#topic+rope">bayestestR::rope()</a></code> or
<code><a href="bayestestR.html#topic+p_direction">bayestestR::p_direction()</a></code>) and its results included in the summary output.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function first calls <code><a href="#topic+bootstrap_model">bootstrap_model()</a></code> to generate
bootstrapped coefficients. The resulting replicated for each coefficient
are treated as &quot;distribution&quot;, and is passed to <code><a href="bayestestR.html#topic+describe_posterior">bayestestR::describe_posterior()</a></code>
to calculate the related indices defined in the <code>"test"</code> argument.
</p>
<p>Note that that p-values returned here are estimated under the assumption of
<em>translation equivariance</em>: that shape of the sampling distribution is
unaffected by the null being true or not. If this assumption does not hold,
p-values can be biased, and it is suggested to use proper permutation tests
to obtain non-parametric p-values.
</p>


<h3>Value</h3>

<p>A data frame summarizing the bootstrapped parameters.
</p>


<h3>Using with <strong>emmeans</strong></h3>

<p>The output can be passed directly to the various functions from the
<strong>emmeans</strong> package, to obtain bootstrapped estimates, contrasts, simple
slopes, etc. and their confidence intervals. These can then be passed to
<code>model_parameter()</code> to obtain standard errors, p-values, etc. (see
example).
</p>
<p>Note that that p-values returned here are estimated under the assumption of
<em>translation equivariance</em>: that shape of the sampling distribution is
unaffected by the null being true or not. If this assumption does not hold,
p-values can be biased, and it is suggested to use proper permutation tests
to obtain non-parametric p-values.
</p>


<h3>References</h3>

<p>Davison, A. C., &amp; Hinkley, D. V. (1997). Bootstrap methods and their
application (Vol. 1). Cambridge university press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+bootstrap_model">bootstrap_model()</a></code>, <code><a href="#topic+simulate_parameters">simulate_parameters()</a></code>, <code><a href="#topic+simulate_model">simulate_model()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

set.seed(2)
model &lt;- lm(Sepal.Length ~ Species * Petal.Width, data = iris)
b &lt;- bootstrap_parameters(model)
print(b)

est &lt;- emmeans::emmeans(b, trt.vs.ctrl ~ Species)
print(model_parameters(est))


</code></pre>

<hr>
<h2 id='ci_betwithin'>Between-within approximation for SEs, CIs and p-values</h2><span id='topic+ci_betwithin'></span><span id='topic+dof_betwithin'></span><span id='topic+p_value_betwithin'></span>

<h3>Description</h3>

<p>Approximation of degrees of freedom based on a &quot;between-within&quot; heuristic.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ci_betwithin(model, ci = 0.95, ...)

dof_betwithin(model)

p_value_betwithin(model, dof = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ci_betwithin_+3A_model">model</code></td>
<td>
<p>A mixed model.</p>
</td></tr>
<tr><td><code id="ci_betwithin_+3A_ci">ci</code></td>
<td>
<p>Confidence Interval (CI) level. Default to <code>0.95</code> (<code style="white-space: pre;">&#8288;95%&#8288;</code>).</p>
</td></tr>
<tr><td><code id="ci_betwithin_+3A_...">...</code></td>
<td>
<p>Additional arguments</p>
</td></tr>
<tr><td><code id="ci_betwithin_+3A_dof">dof</code></td>
<td>
<p>Degrees of Freedom.</p>
</td></tr>
</table>


<h3>Details</h3>



<h4>Small Sample Cluster corrected Degrees of Freedom</h4>

<p>Inferential statistics (like p-values, confidence intervals and
standard errors) may be biased in mixed models when the number of clusters
is small (even if the sample size of level-1 units is high). In such cases
it is recommended to approximate a more accurate number of degrees of freedom
for such inferential statistics (see <em>Li and Redden 2015</em>). The
<em>Between-within</em> denominator degrees of freedom approximation is
recommended in particular for (generalized) linear mixed models with repeated
measurements (longitudinal design). <code>dof_betwithin()</code> implements a heuristic
based on the between-within approach. <strong>Note</strong> that this implementation
does not return exactly the same results as shown in <em>Li and Redden 2015</em>,
but similar.
</p>



<h4>Degrees of Freedom for Longitudinal Designs (Repeated Measures)</h4>

<p>In particular for repeated measure designs (longitudinal data analysis),
the <em>between-within</em> heuristic is likely to be more accurate than simply
using the residual or infinite degrees of freedom, because <code>dof_betwithin()</code>
returns different degrees of freedom for within-cluster and between-cluster
effects.
</p>



<h3>Value</h3>

<p>A data frame.
</p>


<h3>References</h3>


<ul>
<li><p> Elff, M.; Heisig, J.P.; Schaeffer, M.; Shikano, S. (2019). Multilevel
Analysis with Few Clusters: Improving Likelihood-based Methods to Provide
Unbiased Estimates and Accurate Inference, British Journal of Political Science.
</p>
</li>
<li><p> Li, P., Redden, D. T. (2015). Comparing denominator degrees of freedom
approximations for the generalized linear mixed model in analyzing binary
outcome in small sample cluster-randomized trials. BMC Medical Research
Methodology, 15(1), 38. <a href="https://doi.org/10.1186/s12874-015-0026-x">doi:10.1186/s12874-015-0026-x</a>
</p>
</li></ul>



<h3>See Also</h3>

<p><code>dof_betwithin()</code> is a small helper-function to calculate approximated
degrees of freedom of model parameters, based on the &quot;between-within&quot; heuristic.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
if (require("lme4")) {
  data(sleepstudy)
  model &lt;- lmer(Reaction ~ Days + (1 + Days | Subject), data = sleepstudy)
  dof_betwithin(model)
  p_value_betwithin(model)
}

</code></pre>

<hr>
<h2 id='ci_kenward'>Kenward-Roger approximation for SEs, CIs and p-values</h2><span id='topic+ci_kenward'></span><span id='topic+dof_kenward'></span><span id='topic+p_value_kenward'></span><span id='topic+se_kenward'></span>

<h3>Description</h3>

<p>An approximate F-test based on the Kenward-Roger (1997) approach.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ci_kenward(model, ci = 0.95)

dof_kenward(model)

p_value_kenward(model, dof = NULL)

se_kenward(model)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ci_kenward_+3A_model">model</code></td>
<td>
<p>A statistical model.</p>
</td></tr>
<tr><td><code id="ci_kenward_+3A_ci">ci</code></td>
<td>
<p>Confidence Interval (CI) level. Default to <code>0.95</code> (<code style="white-space: pre;">&#8288;95%&#8288;</code>).</p>
</td></tr>
<tr><td><code id="ci_kenward_+3A_dof">dof</code></td>
<td>
<p>Degrees of Freedom.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Inferential statistics (like p-values, confidence intervals and
standard errors) may be biased in mixed models when the number of clusters
is small (even if the sample size of level-1 units is high). In such cases
it is recommended to approximate a more accurate number of degrees of freedom
for such inferential statistics. Unlike simpler approximation heuristics
like the &quot;m-l-1&quot; rule (<code>dof_ml1</code>), the Kenward-Roger approximation is
also applicable in more complex multilevel designs, e.g. with cross-classified
clusters. However, the &quot;m-l-1&quot; heuristic also applies to generalized
mixed models, while approaches like Kenward-Roger or Satterthwaite are limited
to linear mixed models only.
</p>


<h3>Value</h3>

<p>A data frame.
</p>


<h3>References</h3>

<p>Kenward, M. G., &amp; Roger, J. H. (1997). Small sample inference for
fixed effects from restricted maximum likelihood. Biometrics, 983-997.
</p>


<h3>See Also</h3>

<p><code>dof_kenward()</code> and <code>se_kenward()</code> are small helper-functions
to calculate approximated degrees of freedom and standard errors for model
parameters, based on the Kenward-Roger (1997) approach.
</p>
<p><code><a href="#topic+dof_satterthwaite">dof_satterthwaite()</a></code> and <code><a href="#topic+dof_ml1">dof_ml1()</a></code> approximate degrees of freedom
based on Satterthwaite's method or the &quot;m-l-1&quot; rule.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
if (require("lme4", quietly = TRUE)) {
  model &lt;- lmer(Petal.Length ~ Sepal.Length + (1 | Species), data = iris)
  p_value_kenward(model)
}

</code></pre>

<hr>
<h2 id='ci_ml1'>&quot;m-l-1&quot; approximation for SEs, CIs and p-values</h2><span id='topic+ci_ml1'></span><span id='topic+dof_ml1'></span><span id='topic+p_value_ml1'></span>

<h3>Description</h3>

<p>Approximation of degrees of freedom based on a &quot;m-l-1&quot; heuristic
as suggested by Elff et al. (2019).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ci_ml1(model, ci = 0.95, ...)

dof_ml1(model)

p_value_ml1(model, dof = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ci_ml1_+3A_model">model</code></td>
<td>
<p>A mixed model.</p>
</td></tr>
<tr><td><code id="ci_ml1_+3A_ci">ci</code></td>
<td>
<p>Confidence Interval (CI) level. Default to <code>0.95</code> (<code style="white-space: pre;">&#8288;95%&#8288;</code>).</p>
</td></tr>
<tr><td><code id="ci_ml1_+3A_...">...</code></td>
<td>
<p>Additional arguments</p>
</td></tr>
<tr><td><code id="ci_ml1_+3A_dof">dof</code></td>
<td>
<p>Degrees of Freedom.</p>
</td></tr>
</table>


<h3>Details</h3>



<h4>Small Sample Cluster corrected Degrees of Freedom</h4>

<p>Inferential statistics (like p-values, confidence intervals and
standard errors) may be biased in mixed models when the number of clusters
is small (even if the sample size of level-1 units is high). In such cases
it is recommended to approximate a more accurate number of degrees of freedom
for such inferential statistics (see <em>Li and Redden 2015</em>). The
<em>m-l-1</em> heuristic is such an approach that uses a t-distribution with
fewer degrees of freedom (<code>dof_ml1()</code>) to calculate p-values
(<code>p_value_ml1()</code>) and confidence intervals (<code>ci(method = "ml1")</code>).
</p>



<h4>Degrees of Freedom for Longitudinal Designs (Repeated Measures)</h4>

<p>In particular for repeated measure designs (longitudinal data analysis),
the <em>m-l-1</em> heuristic is likely to be more accurate than simply using the
residual or infinite degrees of freedom, because <code>dof_ml1()</code> returns
different degrees of freedom for within-cluster and between-cluster effects.
</p>



<h4>Limitations of the &quot;m-l-1&quot; Heuristic</h4>

<p>Note that the &quot;m-l-1&quot; heuristic is not applicable (or at least less accurate)
for complex multilevel designs, e.g. with cross-classified clusters. In such cases,
more accurate approaches like the Kenward-Roger approximation (<code>dof_kenward()</code>)
is recommended. However, the &quot;m-l-1&quot; heuristic also applies to generalized
mixed models, while approaches like Kenward-Roger or Satterthwaite are limited
to linear mixed models only.
</p>



<h3>Value</h3>

<p>A data frame.
</p>


<h3>References</h3>


<ul>
<li><p> Elff, M.; Heisig, J.P.; Schaeffer, M.; Shikano, S. (2019). Multilevel
Analysis with Few Clusters: Improving Likelihood-based Methods to Provide
Unbiased Estimates and Accurate Inference, British Journal of Political
Science.
</p>
</li>
<li><p> Li, P., Redden, D. T. (2015). Comparing denominator degrees of freedom
approximations for the generalized linear mixed model in analyzing binary
outcome in small sample cluster-randomized trials. BMC Medical Research
Methodology, 15(1), 38. <a href="https://doi.org/10.1186/s12874-015-0026-x">doi:10.1186/s12874-015-0026-x</a>
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+dof_ml1">dof_ml1()</a></code> is a small helper-function to calculate approximated
degrees of freedom of model parameters, based on the &quot;m-l-1&quot; heuristic.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
if (require("lme4")) {
  model &lt;- lmer(Petal.Length ~ Sepal.Length + (1 | Species), data = iris)
  p_value_ml1(model)
}

</code></pre>

<hr>
<h2 id='ci_satterthwaite'>Satterthwaite approximation for SEs, CIs and p-values</h2><span id='topic+ci_satterthwaite'></span><span id='topic+dof_satterthwaite'></span><span id='topic+p_value_satterthwaite'></span><span id='topic+se_satterthwaite'></span>

<h3>Description</h3>

<p>An approximate F-test based on the Satterthwaite (1946) approach.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ci_satterthwaite(model, ci = 0.95, ...)

dof_satterthwaite(model)

p_value_satterthwaite(model, dof = NULL, ...)

se_satterthwaite(model)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ci_satterthwaite_+3A_model">model</code></td>
<td>
<p>A statistical model.</p>
</td></tr>
<tr><td><code id="ci_satterthwaite_+3A_ci">ci</code></td>
<td>
<p>Confidence Interval (CI) level. Default to <code>0.95</code> (<code style="white-space: pre;">&#8288;95%&#8288;</code>).</p>
</td></tr>
<tr><td><code id="ci_satterthwaite_+3A_...">...</code></td>
<td>
<p>Additional arguments</p>
</td></tr>
<tr><td><code id="ci_satterthwaite_+3A_dof">dof</code></td>
<td>
<p>Degrees of Freedom.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Inferential statistics (like p-values, confidence intervals and
standard errors) may be biased in mixed models when the number of clusters
is small (even if the sample size of level-1 units is high). In such cases
it is recommended to approximate a more accurate number of degrees of freedom
for such inferential statistics. Unlike simpler approximation heuristics
like the &quot;m-l-1&quot; rule (<code>dof_ml1</code>), the Satterthwaite approximation is
also applicable in more complex multilevel designs. However, the &quot;m-l-1&quot;
heuristic also applies to generalized mixed models, while approaches like
Kenward-Roger or Satterthwaite are limited to linear mixed models only.
</p>


<h3>Value</h3>

<p>A data frame.
</p>


<h3>References</h3>

<p>Satterthwaite FE (1946) An approximate distribution of estimates of variance components. Biometrics Bulletin 2 (6):110–4.
</p>


<h3>See Also</h3>

<p><code>dof_satterthwaite()</code> and <code>se_satterthwaite()</code> are small helper-functions
to calculate approximated degrees of freedom and standard errors for model
parameters, based on the Satterthwaite (1946) approach.
</p>
<p><code><a href="#topic+dof_kenward">dof_kenward()</a></code> and <code><a href="#topic+dof_ml1">dof_ml1()</a></code> approximate degrees of freedom based on
Kenward-Roger's method or the &quot;m-l-1&quot; rule.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
if (require("lme4", quietly = TRUE)) {
  model &lt;- lmer(Petal.Length ~ Sepal.Length + (1 | Species), data = iris)
  p_value_satterthwaite(model)
}

</code></pre>

<hr>
<h2 id='ci.default'>Confidence Intervals (CI)</h2><span id='topic+ci.default'></span><span id='topic+ci.glmmTMB'></span><span id='topic+ci.merMod'></span>

<h3>Description</h3>

<p><code>ci()</code> attempts to return confidence intervals of model parameters.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## Default S3 method:
ci(x, ci = 0.95, dof = NULL, method = NULL, ...)

## S3 method for class 'glmmTMB'
ci(
  x,
  ci = 0.95,
  dof = NULL,
  method = "wald",
  component = "all",
  verbose = TRUE,
  ...
)

## S3 method for class 'merMod'
ci(x, ci = 0.95, dof = NULL, method = "wald", iterations = 500, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ci.default_+3A_x">x</code></td>
<td>
<p>A statistical model.</p>
</td></tr>
<tr><td><code id="ci.default_+3A_ci">ci</code></td>
<td>
<p>Confidence Interval (CI) level. Default to <code>0.95</code> (<code style="white-space: pre;">&#8288;95%&#8288;</code>).</p>
</td></tr>
<tr><td><code id="ci.default_+3A_dof">dof</code></td>
<td>
<p>Number of degrees of freedom to be used when calculating
confidence intervals. If <code>NULL</code> (default), the degrees of freedom are
retrieved by calling <code><a href="#topic+degrees_of_freedom">degrees_of_freedom()</a></code> with
approximation method defined in <code>method</code>. If not <code>NULL</code>, use this argument
to override the default degrees of freedom used to compute confidence
intervals.</p>
</td></tr>
<tr><td><code id="ci.default_+3A_method">method</code></td>
<td>
<p>Method for computing degrees of freedom for
confidence intervals (CI) and the related p-values. Allowed are following
options (which vary depending on the model class): <code>"residual"</code>,
<code>"normal"</code>, <code>"likelihood"</code>, <code>"satterthwaite"</code>, <code>"kenward"</code>, <code>"wald"</code>,
<code>"profile"</code>, <code>"boot"</code>, <code>"uniroot"</code>, <code>"ml1"</code>, <code>"betwithin"</code>, <code>"hdi"</code>,
<code>"quantile"</code>, <code>"ci"</code>, <code>"eti"</code>, <code>"si"</code>, <code>"bci"</code>, or <code>"bcai"</code>. See section
<em>Confidence intervals and approximation of degrees of freedom</em> in
<code><a href="#topic+model_parameters">model_parameters()</a></code> for further details.</p>
</td></tr>
<tr><td><code id="ci.default_+3A_...">...</code></td>
<td>
<p>Additional arguments</p>
</td></tr>
<tr><td><code id="ci.default_+3A_component">component</code></td>
<td>
<p>Model component for which parameters should be shown. See
the documentation for your object's class in <code><a href="#topic+model_parameters">model_parameters()</a></code> or
<code><a href="#topic+p_value">p_value()</a></code> for further details.</p>
</td></tr>
<tr><td><code id="ci.default_+3A_verbose">verbose</code></td>
<td>
<p>Toggle warnings and messages.</p>
</td></tr>
<tr><td><code id="ci.default_+3A_iterations">iterations</code></td>
<td>
<p>The number of bootstrap replicates. Only applies to models
of class <code>merMod</code> when <code>method=boot</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame containing the CI bounds.
</p>


<h3>Confidence intervals and approximation of degrees of freedom</h3>

<p>There are different ways of approximating the degrees of freedom depending
on different assumptions about the nature of the model and its sampling
distribution. The <code>ci_method</code> argument modulates the method for computing degrees
of freedom (df) that are used to calculate confidence intervals (CI) and the
related p-values. Following options are allowed, depending on the model
class:
</p>
<p><strong>Classical methods:</strong>
</p>
<p>Classical inference is generally based on the <strong>Wald method</strong>.
The Wald approach to inference computes a test statistic by dividing the
parameter estimate by its standard error (Coefficient / SE),
then comparing this statistic against a t- or normal distribution.
This approach can be used to compute CIs and p-values.
</p>
<p><code>"wald"</code>:
</p>

<ul>
<li><p> Applies to <em>non-Bayesian models</em>. For <em>linear models</em>, CIs
computed using the Wald method (SE and a <em>t-distribution with residual df</em>);
p-values computed using the Wald method with a <em>t-distribution with residual df</em>.
For other models, CIs computed using the Wald method (SE and a <em>normal distribution</em>);
p-values computed using the Wald method with a <em>normal distribution</em>.
</p>
</li></ul>

<p><code>"normal"</code>
</p>

<ul>
<li><p> Applies to <em>non-Bayesian models</em>. Compute Wald CIs and p-values,
but always use a normal distribution.
</p>
</li></ul>

<p><code>"residual"</code>
</p>

<ul>
<li><p> Applies to <em>non-Bayesian models</em>. Compute Wald CIs and p-values,
but always use a <em>t-distribution with residual df</em> when possible. If the
residual df for a model cannot be determined, a normal distribution is
used instead.
</p>
</li></ul>

<p><strong>Methods for mixed models:</strong>
</p>
<p>Compared to fixed effects (or single-level) models, determining appropriate
df for Wald-based inference in mixed models is more difficult.
See <a href="https://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#what-are-the-p-values-listed-by-summaryglmerfit-etc.-are-they-reliable">the R GLMM FAQ</a>
for a discussion.
</p>
<p>Several approximate methods for computing df are available, but you should
also consider instead using profile likelihood (<code>"profile"</code>) or bootstrap (&quot;<code style="white-space: pre;">&#8288;boot"&#8288;</code>)
CIs and p-values instead.
</p>
<p><code>"satterthwaite"</code>
</p>

<ul>
<li><p> Applies to <em>linear mixed models</em>. CIs computed using the
Wald method (SE and a <em>t-distribution with Satterthwaite df</em>); p-values
computed using the Wald method with a <em>t-distribution with Satterthwaite df</em>.
</p>
</li></ul>

<p><code>"kenward"</code>
</p>

<ul>
<li><p> Applies to <em>linear mixed models</em>. CIs computed using the Wald
method (<em>Kenward-Roger SE</em> and a <em>t-distribution with Kenward-Roger df</em>);
p-values computed using the Wald method with <em>Kenward-Roger SE and t-distribution with Kenward-Roger df</em>.
</p>
</li></ul>

<p><code>"ml1"</code>
</p>

<ul>
<li><p> Applies to <em>linear mixed models</em>. CIs computed using the Wald
method (SE and a <em>t-distribution with m-l-1 approximated df</em>); p-values
computed using the Wald method with a <em>t-distribution with m-l-1 approximated df</em>.
See <code><a href="#topic+ci_ml1">ci_ml1()</a></code>.
</p>
</li></ul>

<p><code>"betwithin"</code>
</p>

<ul>
<li><p> Applies to <em>linear mixed models</em> and <em>generalized linear mixed models</em>.
CIs computed using the Wald method (SE and a <em>t-distribution with between-within df</em>);
p-values computed using the Wald method with a <em>t-distribution with between-within df</em>.
See <code><a href="#topic+ci_betwithin">ci_betwithin()</a></code>.
</p>
</li></ul>

<p><strong>Likelihood-based methods:</strong>
</p>
<p>Likelihood-based inference is based on comparing the likelihood for the
maximum-likelihood estimate to the the likelihood for models with one or more
parameter values changed (e.g., set to zero or a range of alternative values).
Likelihood ratios for the maximum-likelihood and alternative models are compared
to a <code class="reqn">\chi</code>-squared distribution to compute CIs and p-values.
</p>
<p><code>"profile"</code>
</p>

<ul>
<li><p> Applies to <em>non-Bayesian models</em> of class <code>glm</code>, <code>polr</code>, <code>merMod</code> or <code>glmmTMB</code>.
CIs computed by <em>profiling the likelihood curve for a parameter</em>, using
linear interpolation to find where likelihood ratio equals a critical value;
p-values computed using the Wald method with a <em>normal-distribution</em> (note:
this might change in a future update!)
</p>
</li></ul>

<p><code>"uniroot"</code>
</p>

<ul>
<li><p> Applies to <em>non-Bayesian models</em> of class <code>glmmTMB</code>. CIs
computed by <em>profiling the likelihood curve for a parameter</em>, using root
finding to find where likelihood ratio equals a critical value; p-values
computed using the Wald method with a <em>normal-distribution</em> (note: this
might change in a future update!)
</p>
</li></ul>

<p><strong>Methods for bootstrapped or Bayesian models:</strong>
</p>
<p>Bootstrap-based inference is based on <strong>resampling</strong> and refitting the model
to the resampled datasets. The distribution of parameter estimates across
resampled datasets is used to approximate the parameter's sampling
distribution. Depending on the type of model, several different methods for
bootstrapping and constructing CIs and p-values from the bootstrap
distribution are available.
</p>
<p>For Bayesian models, inference is based on drawing samples from the model
posterior distribution.
</p>
<p><code>"quantile"</code> (or <code>"eti"</code>)
</p>

<ul>
<li><p> Applies to <em>all models (including Bayesian models)</em>.
For non-Bayesian models, only applies if <code>bootstrap = TRUE</code>. CIs computed
as <em>equal tailed intervals</em> using the quantiles of the bootstrap or
posterior samples; p-values are based on the <em>probability of direction</em>.
See <code><a href="bayestestR.html#topic+eti">bayestestR::eti()</a></code>.
</p>
</li></ul>

<p><code>"hdi"</code>
</p>

<ul>
<li><p> Applies to <em>all models (including Bayesian models)</em>. For non-Bayesian
models, only applies if <code>bootstrap = TRUE</code>. CIs computed as <em>highest density intervals</em>
for the bootstrap or posterior samples; p-values are based on the <em>probability of direction</em>.
See <code><a href="bayestestR.html#topic+hdi">bayestestR::hdi()</a></code>.
</p>
</li></ul>

<p><code>"bci"</code> (or <code>"bcai"</code>)
</p>

<ul>
<li><p> Applies to <em>all models (including Bayesian models)</em>.
For non-Bayesian models, only applies if <code>bootstrap = TRUE</code>. CIs computed
as <em>bias corrected and accelerated intervals</em> for the bootstrap or
posterior samples; p-values are based on the <em>probability of direction</em>.
See <code><a href="bayestestR.html#topic+bci">bayestestR::bci()</a></code>.
</p>
</li></ul>

<p><code>"si"</code>
</p>

<ul>
<li><p> Applies to <em>Bayesian models</em> with proper priors. CIs computed as
<em>support intervals</em> comparing the posterior samples against the prior samples;
p-values are based on the <em>probability of direction</em>. See <code><a href="bayestestR.html#topic+si">bayestestR::si()</a></code>.
</p>
</li></ul>

<p><code>"boot"</code>
</p>

<ul>
<li><p> Applies to <em>non-Bayesian models</em> of class <code>merMod</code>. CIs computed
using <em>parametric bootstrapping</em> (simulating data from the fitted model);
p-values computed using the Wald method with a <em>normal-distribution)</em>
(note: this might change in a future update!).
</p>
</li></ul>

<p>For all iteration-based methods other than <code>"boot"</code>
(<code>"hdi"</code>, <code>"quantile"</code>, <code>"ci"</code>, <code>"eti"</code>, <code>"si"</code>, <code>"bci"</code>, <code>"bcai"</code>),
p-values are based on the probability of direction (<code><a href="bayestestR.html#topic+p_direction">bayestestR::p_direction()</a></code>),
which is converted into a p-value using <code><a href="bayestestR.html#topic+pd_to_p">bayestestR::pd_to_p()</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

library(parameters)
data(Salamanders, package = "glmmTMB")
model &lt;- glmmTMB::glmmTMB(
  count ~ spp + mined + (1 | site),
  ziformula = ~mined,
  family = poisson(),
  data = Salamanders
)

ci(model)
ci(model, component = "zi")


</code></pre>

<hr>
<h2 id='cluster_analysis'>Cluster Analysis</h2><span id='topic+cluster_analysis'></span>

<h3>Description</h3>

<p>Compute hierarchical or kmeans cluster analysis and return the group
assignment for each observation as vector.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cluster_analysis(
  x,
  n = NULL,
  method = "kmeans",
  include_factors = FALSE,
  standardize = TRUE,
  verbose = TRUE,
  distance_method = "euclidean",
  hclust_method = "complete",
  kmeans_method = "Hartigan-Wong",
  dbscan_eps = 15,
  iterations = 100,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cluster_analysis_+3A_x">x</code></td>
<td>
<p>A data frame (with at least two variables), or a matrix (with at
least two columns).</p>
</td></tr>
<tr><td><code id="cluster_analysis_+3A_n">n</code></td>
<td>
<p>Number of clusters used for supervised cluster methods. If <code>NULL</code>,
the number of clusters to extract is determined by calling <code><a href="#topic+n_clusters">n_clusters()</a></code>.
Note that this argument does not apply for unsupervised clustering methods
like <code>dbscan</code>, <code>hdbscan</code>, <code>mixture</code>, <code>pvclust</code>, or <code>pamk</code>.</p>
</td></tr>
<tr><td><code id="cluster_analysis_+3A_method">method</code></td>
<td>
<p>Method for computing the cluster analysis. Can be <code>"kmeans"</code>
(default; k-means using <code>kmeans()</code>), <code>"hkmeans"</code> (hierarchical k-means
using <code>factoextra::hkmeans()</code>), <code>pam</code> (K-Medoids using <code>cluster::pam()</code>),
<code>pamk</code> (K-Medoids that finds out the number of clusters), <code>"hclust"</code>
(hierarchical clustering using <code>hclust()</code> or <code>pvclust::pvclust()</code>),
<code>dbscan</code> (DBSCAN using <code>dbscan::dbscan()</code>), <code>hdbscan</code> (Hierarchical DBSCAN
using <code>dbscan::hdbscan()</code>), or <code>mixture</code> (Mixture modeling using
<code>mclust::Mclust()</code>, which requires the user to run <code>library(mclust)</code>
before).</p>
</td></tr>
<tr><td><code id="cluster_analysis_+3A_include_factors">include_factors</code></td>
<td>
<p>Logical, if <code>TRUE</code>, factors are converted to numerical
values in order to be included in the data for determining the number of
clusters. By default, factors are removed, because most methods that
determine the number of clusters need numeric input only.</p>
</td></tr>
<tr><td><code id="cluster_analysis_+3A_standardize">standardize</code></td>
<td>
<p>Standardize the dataframe before clustering (default).</p>
</td></tr>
<tr><td><code id="cluster_analysis_+3A_verbose">verbose</code></td>
<td>
<p>Toggle warnings and messages.</p>
</td></tr>
<tr><td><code id="cluster_analysis_+3A_distance_method">distance_method</code></td>
<td>
<p>Distance measure to be used for methods based on
distances (e.g., when <code>method = "hclust"</code> for hierarchical clustering. For
other methods, such as <code>"kmeans"</code>, this argument will be ignored). Must be
one of <code>"euclidean"</code>, <code>"maximum"</code>, <code>"manhattan"</code>, <code>"canberra"</code>, <code>"binary"</code>
or <code>"minkowski"</code>. See <code><a href="stats.html#topic+dist">dist()</a></code> and <code>pvclust::pvclust()</code> for more
information.</p>
</td></tr>
<tr><td><code id="cluster_analysis_+3A_hclust_method">hclust_method</code></td>
<td>
<p>Agglomeration method to be used when <code>method = "hclust"</code>
or <code>method = "hkmeans"</code> (for hierarchical clustering). This should be one
of <code>"ward"</code>, <code>"ward.D2"</code>, <code>"single"</code>, <code>"complete"</code>, <code>"average"</code>,
<code>"mcquitty"</code>, <code>"median"</code> or <code>"centroid"</code>. Default is <code>"complete"</code> (see
<code><a href="stats.html#topic+hclust">hclust()</a></code>).</p>
</td></tr>
<tr><td><code id="cluster_analysis_+3A_kmeans_method">kmeans_method</code></td>
<td>
<p>Algorithm used for calculating kmeans cluster. Only applies,
if <code>method = "kmeans"</code>. May be one of <code>"Hartigan-Wong"</code> (default),
<code>"Lloyd"</code> (used by SPSS), or <code>"MacQueen"</code>. See <code><a href="stats.html#topic+kmeans">kmeans()</a></code> for details on
this argument.</p>
</td></tr>
<tr><td><code id="cluster_analysis_+3A_dbscan_eps">dbscan_eps</code></td>
<td>
<p>The <code>eps</code> argument for DBSCAN method. See <code><a href="#topic+n_clusters_dbscan">n_clusters_dbscan()</a></code>.</p>
</td></tr>
<tr><td><code id="cluster_analysis_+3A_iterations">iterations</code></td>
<td>
<p>The number of replications.</p>
</td></tr>
<tr><td><code id="cluster_analysis_+3A_...">...</code></td>
<td>
<p>Arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>print()</code> and <code>plot()</code> methods show the (standardized) mean value for
each variable within each cluster. Thus, a higher absolute value indicates
that a certain variable characteristic is more pronounced within that
specific cluster (as compared to other cluster groups with lower absolute
mean values).
</p>
<p>Clusters classification can be obtained via <code>print(x, newdata = NULL, ...)</code>.
</p>


<h3>Value</h3>

<p>The group classification for each observation as vector. The
returned vector includes missing values, so it has the same length
as <code>nrow(x)</code>.
</p>


<h3>Note</h3>

<p>There is also a <a href="https://easystats.github.io/see/articles/parameters.html"><code>plot()</code>-method</a>
implemented in the <a href="https://easystats.github.io/see/"><strong>see</strong>-package</a>.
</p>


<h3>References</h3>


<ul>
<li><p> Maechler M, Rousseeuw P, Struyf A, Hubert M, Hornik K (2014) cluster: Cluster
Analysis Basics and Extensions. R package.
</p>
</li></ul>



<h3>See Also</h3>


<ul>
<li> <p><code><a href="#topic+n_clusters">n_clusters()</a></code> to determine the number of clusters to extract.
</p>
</li>
<li> <p><code><a href="#topic+cluster_discrimination">cluster_discrimination()</a></code> to determine the accuracy of cluster group
classification via linear discriminant analysis (LDA).
</p>
</li>
<li> <p><code><a href="performance.html#topic+check_clusterstructure">performance::check_clusterstructure()</a></code> to check suitability of data
for clustering.
</p>
</li>
<li><p> https://www.datanovia.com/en/lessons/
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>set.seed(33)
# K-Means ====================================================
rez &lt;- cluster_analysis(iris[1:4], n = 3, method = "kmeans")
rez # Show results
predict(rez) # Get clusters
summary(rez) # Extract the centers values (can use 'plot()' on that)
if (requireNamespace("MASS", quietly = TRUE)) {
  cluster_discrimination(rez) # Perform LDA
}

# Hierarchical k-means (more robust k-means)
if (require("factoextra", quietly = TRUE)) {
  rez &lt;- cluster_analysis(iris[1:4], n = 3, method = "hkmeans")
  rez # Show results
  predict(rez) # Get clusters
}

# Hierarchical Clustering (hclust) ===========================
rez &lt;- cluster_analysis(iris[1:4], n = 3, method = "hclust")
rez # Show results
predict(rez) # Get clusters

# K-Medoids (pam) ============================================
if (require("cluster", quietly = TRUE)) {
  rez &lt;- cluster_analysis(iris[1:4], n = 3, method = "pam")
  rez # Show results
  predict(rez) # Get clusters
}

# PAM with automated number of clusters
if (require("fpc", quietly = TRUE)) {
  rez &lt;- cluster_analysis(iris[1:4], method = "pamk")
  rez # Show results
  predict(rez) # Get clusters
}

# DBSCAN ====================================================
if (require("dbscan", quietly = TRUE)) {
  # Note that you can assimilate more outliers (cluster 0) to neighbouring
  # clusters by setting borderPoints = TRUE.
  rez &lt;- cluster_analysis(iris[1:4], method = "dbscan", dbscan_eps = 1.45)
  rez # Show results
  predict(rez) # Get clusters
}

# Mixture ====================================================
if (require("mclust", quietly = TRUE)) {
  library(mclust) # Needs the package to be loaded
  rez &lt;- cluster_analysis(iris[1:4], method = "mixture")
  rez # Show results
  predict(rez) # Get clusters
}
</code></pre>

<hr>
<h2 id='cluster_centers'>Find the cluster centers in your data</h2><span id='topic+cluster_centers'></span>

<h3>Description</h3>

<p>For each cluster, computes the mean (or other indices) of the variables. Can be used
to retrieve the centers of clusters. Also returns the within Sum of Squares.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cluster_centers(data, clusters, fun = mean, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cluster_centers_+3A_data">data</code></td>
<td>
<p>A data.frame.</p>
</td></tr>
<tr><td><code id="cluster_centers_+3A_clusters">clusters</code></td>
<td>
<p>A vector with clusters assignments (must be same length as rows in data).</p>
</td></tr>
<tr><td><code id="cluster_centers_+3A_fun">fun</code></td>
<td>
<p>What function to use, <code>mean</code> by default.</p>
</td></tr>
<tr><td><code id="cluster_centers_+3A_...">...</code></td>
<td>
<p>Other arguments to be passed to or from other functions.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A dataframe containing the cluster centers. Attributes include
performance statistics and distance between each observation and its
respective cluster centre.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>k &lt;- kmeans(iris[1:4], 3)
cluster_centers(iris[1:4], clusters = k$cluster)
cluster_centers(iris[1:4], clusters = k$cluster, fun = median)
</code></pre>

<hr>
<h2 id='cluster_discrimination'>Compute a linear discriminant analysis on classified cluster groups</h2><span id='topic+cluster_discrimination'></span>

<h3>Description</h3>

<p>Computes linear discriminant analysis (LDA) on classified cluster groups, and
determines the goodness of classification for each cluster group. See <code>MASS::lda()</code>
for details.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cluster_discrimination(x, cluster_groups = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cluster_discrimination_+3A_x">x</code></td>
<td>
<p>A data frame</p>
</td></tr>
<tr><td><code id="cluster_discrimination_+3A_cluster_groups">cluster_groups</code></td>
<td>
<p>Group classification of the cluster analysis, which can
be retrieved from the <code><a href="#topic+cluster_analysis">cluster_analysis()</a></code> function.</p>
</td></tr>
<tr><td><code id="cluster_discrimination_+3A_...">...</code></td>
<td>
<p>Other arguments to be passed to or from.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+n_clusters">n_clusters()</a></code> to determine the number of clusters to extract,
<code><a href="#topic+cluster_analysis">cluster_analysis()</a></code> to compute a cluster analysis and
<code><a href="performance.html#topic+check_clusterstructure">performance::check_clusterstructure()</a></code> to check suitability of data for
clustering.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Retrieve group classification from hierarchical cluster analysis
clustering &lt;- cluster_analysis(iris[, 1:4], n = 3)

# Goodness of group classification
cluster_discrimination(clustering)

</code></pre>

<hr>
<h2 id='cluster_meta'>Metaclustering</h2><span id='topic+cluster_meta'></span>

<h3>Description</h3>

<p>One of the core &quot;issue&quot; of statistical clustering is that, in many cases,
different methods will give different results. The <strong>metaclustering</strong> approach
proposed by <em>easystats</em> (that finds echoes in <em>consensus clustering</em>; see Monti
et al., 2003) consists of treating the unique clustering solutions as a ensemble,
from which we can derive a probability matrix. This matrix contains, for each
pair of observations, the probability of being in the same cluster. For instance,
if the 6th and the 9th row of a dataframe has been assigned to a similar cluster
by 5 our of 10 clustering methods, then its probability of being grouped together
is 0.5.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cluster_meta(list_of_clusters, rownames = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cluster_meta_+3A_list_of_clusters">list_of_clusters</code></td>
<td>
<p>A list of vectors with the clustering assignments from various methods.</p>
</td></tr>
<tr><td><code id="cluster_meta_+3A_rownames">rownames</code></td>
<td>
<p>An optional vector of row.names for the matrix.</p>
</td></tr>
<tr><td><code id="cluster_meta_+3A_...">...</code></td>
<td>
<p>Currently not used.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Metaclustering is based on the hypothesis that, as each clustering algorithm
embodies a different prism by which it sees the data, running an infinite
amount of algorithms would result in the emergence of the &quot;true&quot; clusters.
As the number of algorithms and parameters is finite, the probabilistic
perspective is a useful proxy. This method is interesting where there is no
obvious reasons to prefer one over another clustering method, as well as to
investigate how robust some clusters are under different algorithms.
</p>
<p>This metaclustering probability matrix can be transformed into a dissimilarity
matrix (such as the one produced by <code>dist()</code>) and submitted for instance to
hierarchical clustering (<code>hclust()</code>). See the example below.
</p>


<h3>Value</h3>

<p>A matrix containing all the pairwise (between each observation)
probabilities of being clustered together by the methods.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data &lt;- iris[1:4]

rez1 &lt;- cluster_analysis(data, n = 2, method = "kmeans")
rez2 &lt;- cluster_analysis(data, n = 3, method = "kmeans")
rez3 &lt;- cluster_analysis(data, n = 6, method = "kmeans")

list_of_clusters &lt;- list(rez1, rez2, rez3)

m &lt;- cluster_meta(list_of_clusters)

# Visualize matrix without reordering
heatmap(m, Rowv = NA, Colv = NA, scale = "none") # Without reordering
# Reordered heatmap
heatmap(m, scale = "none")

# Extract 3 clusters
predict(m, n = 3)

# Convert to dissimilarity
d &lt;- as.dist(abs(m - 1))
model &lt;- hclust(d)
plot(model, hang = -1)

</code></pre>

<hr>
<h2 id='cluster_performance'>Performance of clustering models</h2><span id='topic+cluster_performance'></span><span id='topic+cluster_performance.kmeans'></span><span id='topic+cluster_performance.hclust'></span><span id='topic+cluster_performance.dbscan'></span><span id='topic+cluster_performance.parameters_clusters'></span>

<h3>Description</h3>

<p>Compute performance indices for clustering solutions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cluster_performance(model, ...)

## S3 method for class 'kmeans'
cluster_performance(model, ...)

## S3 method for class 'hclust'
cluster_performance(model, data, clusters, ...)

## S3 method for class 'dbscan'
cluster_performance(model, data, ...)

## S3 method for class 'parameters_clusters'
cluster_performance(model, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cluster_performance_+3A_model">model</code></td>
<td>
<p>Cluster model.</p>
</td></tr>
<tr><td><code id="cluster_performance_+3A_...">...</code></td>
<td>
<p>Arguments passed to or from other methods.</p>
</td></tr>
<tr><td><code id="cluster_performance_+3A_data">data</code></td>
<td>
<p>A data.frame.</p>
</td></tr>
<tr><td><code id="cluster_performance_+3A_clusters">clusters</code></td>
<td>
<p>A vector with clusters assignments (must be same length as rows in data).</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'># kmeans
model &lt;- kmeans(iris[1:4], 3)
cluster_performance(model)
# hclust
data &lt;- iris[1:4]
model &lt;- hclust(dist(data))
clusters &lt;- cutree(model, 3)

rez &lt;- cluster_performance(model, data, clusters)
rez

# DBSCAN
model &lt;- dbscan::dbscan(iris[1:4], eps = 1.45, minPts = 10)

rez &lt;- cluster_performance(model, iris[1:4])
rez

# Retrieve performance from parameters
params &lt;- model_parameters(kmeans(iris[1:4], 3))
cluster_performance(params)
</code></pre>

<hr>
<h2 id='compare_parameters'>Compare model parameters of multiple models</h2><span id='topic+compare_parameters'></span><span id='topic+compare_models'></span>

<h3>Description</h3>

<p>Compute and extract model parameters of multiple regression
models. See <code><a href="#topic+model_parameters">model_parameters()</a></code> for further details.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>compare_parameters(
  ...,
  ci = 0.95,
  effects = "fixed",
  component = "conditional",
  standardize = NULL,
  exponentiate = FALSE,
  ci_method = "wald",
  p_adjust = NULL,
  select = NULL,
  column_names = NULL,
  pretty_names = TRUE,
  coefficient_names = NULL,
  keep = NULL,
  drop = NULL,
  include_reference = FALSE,
  groups = NULL,
  verbose = TRUE
)

compare_models(
  ...,
  ci = 0.95,
  effects = "fixed",
  component = "conditional",
  standardize = NULL,
  exponentiate = FALSE,
  ci_method = "wald",
  p_adjust = NULL,
  select = NULL,
  column_names = NULL,
  pretty_names = TRUE,
  coefficient_names = NULL,
  keep = NULL,
  drop = NULL,
  include_reference = FALSE,
  groups = NULL,
  verbose = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="compare_parameters_+3A_...">...</code></td>
<td>
<p>One or more regression model objects, or objects returned by
<code>model_parameters()</code>. Regression models may be of different model
types. Model objects may be passed comma separated, or as a list.
If model objects are passed with names or the list has named elements,
these names will be used as column names.</p>
</td></tr>
<tr><td><code id="compare_parameters_+3A_ci">ci</code></td>
<td>
<p>Confidence Interval (CI) level. Default to <code>0.95</code> (<code style="white-space: pre;">&#8288;95%&#8288;</code>).</p>
</td></tr>
<tr><td><code id="compare_parameters_+3A_effects">effects</code></td>
<td>
<p>Should parameters for fixed effects (<code>"fixed"</code>), random
effects (<code>"random"</code>), or both (<code>"all"</code>) be returned? Only applies
to mixed models. May be abbreviated. If the calculation of random effects
parameters takes too long, you may use <code>effects = "fixed"</code>.</p>
</td></tr>
<tr><td><code id="compare_parameters_+3A_component">component</code></td>
<td>
<p>Model component for which parameters should be shown. See
documentation for related model class in <code><a href="#topic+model_parameters">model_parameters()</a></code>.</p>
</td></tr>
<tr><td><code id="compare_parameters_+3A_standardize">standardize</code></td>
<td>
<p>The method used for standardizing the parameters. Can be
<code>NULL</code> (default; no standardization), <code>"refit"</code> (for re-fitting the model
on standardized data) or one of <code>"basic"</code>, <code>"posthoc"</code>, <code>"smart"</code>,
<code>"pseudo"</code>. See 'Details' in <code><a href="#topic+standardize_parameters">standardize_parameters()</a></code>.
<strong>Importantly</strong>:
</p>

<ul>
<li><p> The <code>"refit"</code> method does <em>not</em> standardize categorical predictors (i.e.
factors), which may be a different behaviour compared to other R packages
(such as <strong>lm.beta</strong>) or other software packages (like SPSS). to mimic
such behaviours, either use <code>standardize="basic"</code> or standardize the data
with <code>datawizard::standardize(force=TRUE)</code> <em>before</em> fitting the model.
</p>
</li>
<li><p> For mixed models, when using methods other than <code>"refit"</code>, only the fixed
effects will be standardized.
</p>
</li>
<li><p> Robust estimation (i.e., <code>vcov</code> set to a value other than <code>NULL</code>) of
standardized parameters only works when <code>standardize="refit"</code>.
</p>
</li></ul>
</td></tr>
<tr><td><code id="compare_parameters_+3A_exponentiate">exponentiate</code></td>
<td>
<p>Logical, indicating whether or not to exponentiate the
coefficients (and related confidence intervals). This is typical for
logistic regression, or more generally speaking, for models with log or
logit links. It is also recommended to use <code>exponentiate = TRUE</code> for models
with log-transformed response values. <strong>Note:</strong> Delta-method standard
errors are also computed (by multiplying the standard errors by the
transformed coefficients). This is to mimic behaviour of other software
packages, such as Stata, but these standard errors poorly estimate
uncertainty for the transformed coefficient. The transformed confidence
interval more clearly captures this uncertainty. For <code>compare_parameters()</code>,
<code>exponentiate = "nongaussian"</code> will only exponentiate coefficients from
non-Gaussian families.</p>
</td></tr>
<tr><td><code id="compare_parameters_+3A_ci_method">ci_method</code></td>
<td>
<p>Method for computing degrees of freedom for p-values
and confidence intervals (CI). See documentation for related model class
in <code><a href="#topic+model_parameters">model_parameters()</a></code>.</p>
</td></tr>
<tr><td><code id="compare_parameters_+3A_p_adjust">p_adjust</code></td>
<td>
<p>Character vector, if not <code>NULL</code>, indicates the method to
adjust p-values. See <code><a href="stats.html#topic+p.adjust">stats::p.adjust()</a></code> for details. Further
possible adjustment methods are <code>"tukey"</code>, <code>"scheffe"</code>,
<code>"sidak"</code> and <code>"none"</code> to explicitly disable adjustment for
<code>emmGrid</code> objects (from <strong>emmeans</strong>).</p>
</td></tr>
<tr><td><code id="compare_parameters_+3A_select">select</code></td>
<td>
<p>Determines which columns and and which layout columns are
printed. There are three options for this argument:
</p>

<ol>
<li><p> Selecting columns by name or index
<br />
<code>select</code> can be a character vector (or numeric index) of column names that
should be printed. There are two pre-defined options for selecting columns:
<code>select = "minimal"</code> prints coefficients, confidence intervals and p-values,
while <code>select = "short"</code> prints coefficients, standard errors and p-values.
</p>
</li>
<li><p> A string expression with layout pattern
<br />
<code>select</code> is a string with &quot;tokens&quot; enclosed in braces. These tokens will
be replaced by their associated columns, where the selected columns will
be collapsed into one column. However, it is possible to create multiple
columns as well. Following tokens are replaced by the related coefficients
or statistics: <code>{estimate}</code>, <code>{se}</code>, <code>{ci}</code> (or <code>{ci_low}</code> and <code>{ci_high}</code>),
<code>{p}</code> and <code>{stars}</code>. The token <code>{ci}</code> will be replaced by <code style="white-space: pre;">&#8288;{ci_low}, {ci_high}&#8288;</code>.
Furthermore, a <code>|</code> separates values into new cells/columns. If
<code>format = "html"</code>, a <code style="white-space: pre;">&#8288;&lt;br&gt;&#8288;</code> inserts a line break inside a cell. See
'Examples'.
</p>
</li>
<li><p> A string indicating a pre-defined layout
<br />
<code>select</code> can be one of the following string values, to create one of the
following pre-defined column layouts:
</p>

<ul>
<li> <p><code>"ci"</code>: Estimates and confidence intervals, no asterisks for p-values.
This is equivalent to <code>select = "{estimate} ({ci})"</code>.
</p>
</li>
<li> <p><code>"se"</code>: Estimates and standard errors, no asterisks for p-values. This is
equivalent to <code>select = "{estimate} ({se})"</code>.
</p>
</li>
<li> <p><code>"ci_p"</code>: Estimates, confidence intervals and asterisks for p-values. This
is equivalent to <code>select = "{estimate}{stars} ({ci})"</code>.
</p>
</li>
<li> <p><code>"se_p"</code>: Estimates, standard errors and asterisks for p-values. This is
equivalent to <code>select = "{estimate}{stars} ({se})"</code>..
</p>
</li>
<li> <p><code>"ci_p2"</code>: Estimates, confidence intervals and numeric p-values, in two
columns. This is equivalent to <code>select = "{estimate} ({ci})|{p}"</code>.
</p>
</li>
<li> <p><code>"se_p2"</code>: Estimate, standard errors and numeric p-values, in two columns.
This is equivalent to <code>select = "{estimate} ({se})|{p}"</code>.
</p>
</li></ul>

</li></ol>

<p>For <code>model_parameters()</code>, glue-like syntax is still experimental in the
case of more complex models (like mixed models) and may not return expected
results.</p>
</td></tr>
<tr><td><code id="compare_parameters_+3A_column_names">column_names</code></td>
<td>
<p>Character vector with strings that should be used as
column headers. Must be of same length as number of models in <code>...</code>.</p>
</td></tr>
<tr><td><code id="compare_parameters_+3A_pretty_names">pretty_names</code></td>
<td>
<p>Can be <code>TRUE</code>, which will return &quot;pretty&quot; (i.e. more human
readable) parameter names. Or <code>"labels"</code>, in which case value and variable
labels will be used as parameters names. The latter only works for &quot;labelled&quot;
data, i.e. if the data used to fit the model had <code>"label"</code> and <code>"labels"</code>
attributes. See also section <em>Global Options to Customize Messages when Printing</em>.</p>
</td></tr>
<tr><td><code id="compare_parameters_+3A_coefficient_names">coefficient_names</code></td>
<td>
<p>Character vector with strings that should be used
as column headers for the coefficient column. Must be of same length as
number of models in <code>...</code>, or length 1. If length 1, this name will be
used for all coefficient columns. If <code>NULL</code>, the name for the coefficient
column will detected automatically (as in <code>model_parameters()</code>).</p>
</td></tr>
<tr><td><code id="compare_parameters_+3A_keep">keep</code></td>
<td>
<p>Character containing a regular expression pattern that
describes the parameters that should be included (for <code>keep</code>) or excluded
(for <code>drop</code>) in the returned data frame. <code>keep</code> may also be a
named list of regular expressions. All non-matching parameters will be
removed from the output. If <code>keep</code> is a character vector, every parameter
name in the <em>&quot;Parameter&quot;</em> column that matches the regular expression in
<code>keep</code> will be selected from the returned data frame (and vice versa,
all parameter names matching <code>drop</code> will be excluded). Furthermore, if
<code>keep</code> has more than one element, these will be merged with an <code>OR</code>
operator into a regular expression pattern like this: <code>"(one|two|three)"</code>.
If <code>keep</code> is a named list of regular expression patterns, the names of the
list-element should equal the column name where selection should be
applied. This is useful for model objects where <code>model_parameters()</code>
returns multiple columns with parameter components, like in
<code><a href="#topic+model_parameters.lavaan">model_parameters.lavaan()</a></code>. Note that the regular expression pattern
should match the parameter names as they are stored in the returned data
frame, which can be different from how they are printed. Inspect the
<code style="white-space: pre;">&#8288;$Parameter&#8288;</code> column of the parameters table to get the exact parameter
names.</p>
</td></tr>
<tr><td><code id="compare_parameters_+3A_drop">drop</code></td>
<td>
<p>See <code>keep</code>.</p>
</td></tr>
<tr><td><code id="compare_parameters_+3A_include_reference">include_reference</code></td>
<td>
<p>Logical, if <code>TRUE</code>, the reference level of factors will
be added to the parameters table. This is only relevant for models with
categorical predictors. The coefficient for the reference level is always
<code>0</code> (except when <code>exponentiate = TRUE</code>, then the coefficient will be <code>1</code>),
so this is just for completeness.</p>
</td></tr>
<tr><td><code id="compare_parameters_+3A_groups">groups</code></td>
<td>
<p>Named list, can be used to group parameters in the printed output.
List elements may either be character vectors that match the name of those
parameters that belong to one group, or list elements can be row numbers
of those parameter rows that should belong to one group. The names of the
list elements will be used as group names, which will be inserted as &quot;header
row&quot;. A possible use case might be to emphasize focal predictors and control
variables, see 'Examples'. Parameters will be re-ordered according to the
order used in <code>groups</code>, while all non-matching parameters will be added
to the end.</p>
</td></tr>
<tr><td><code id="compare_parameters_+3A_verbose">verbose</code></td>
<td>
<p>Toggle warnings and messages.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is in an early stage and does not yet cope with more complex
models, and probably does not yet properly render all model components. It
should also be noted that when including models with interaction terms, not
only do the values of the parameters change, but so does their meaning (from
main effects, to simple slopes), thereby making such comparisons hard.
Therefore, you should not use this function to compare models with
interaction terms with models without interaction terms.
</p>


<h3>Value</h3>

<p>A data frame of indices related to the model's parameters.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(iris)
lm1 &lt;- lm(Sepal.Length ~ Species, data = iris)
lm2 &lt;- lm(Sepal.Length ~ Species + Petal.Length, data = iris)
compare_parameters(lm1, lm2)

# custom style
compare_parameters(lm1, lm2, select = "{estimate}{stars} ({se})")


# custom style, in HTML
result &lt;- compare_parameters(lm1, lm2, select = "{estimate}&lt;br&gt;({se})|{p}")
print_html(result)


data(mtcars)
m1 &lt;- lm(mpg ~ wt, data = mtcars)
m2 &lt;- glm(vs ~ wt + cyl, data = mtcars, family = "binomial")
compare_parameters(m1, m2)

# exponentiate coefficients, but not for lm
compare_parameters(m1, m2, exponentiate = "nongaussian")

# change column names
compare_parameters("linear model" = m1, "logistic reg." = m2)
compare_parameters(m1, m2, column_names = c("linear model", "logistic reg."))

# or as list
compare_parameters(list(m1, m2))
compare_parameters(list("linear model" = m1, "logistic reg." = m2))


</code></pre>

<hr>
<h2 id='convert_efa_to_cfa'>Conversion between EFA results and CFA structure</h2><span id='topic+convert_efa_to_cfa'></span><span id='topic+convert_efa_to_cfa.fa'></span><span id='topic+efa_to_cfa'></span>

<h3>Description</h3>

<p>Enables a conversion between Exploratory Factor Analysis (EFA) and
Confirmatory Factor Analysis (CFA) <code>lavaan</code>-ready structure.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>convert_efa_to_cfa(model, ...)

## S3 method for class 'fa'
convert_efa_to_cfa(
  model,
  threshold = "max",
  names = NULL,
  max_per_dimension = NULL,
  ...
)

efa_to_cfa(model, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="convert_efa_to_cfa_+3A_model">model</code></td>
<td>
<p>An EFA model (e.g., a <code>psych::fa</code> object).</p>
</td></tr>
<tr><td><code id="convert_efa_to_cfa_+3A_...">...</code></td>
<td>
<p>Arguments passed to or from other methods.</p>
</td></tr>
<tr><td><code id="convert_efa_to_cfa_+3A_threshold">threshold</code></td>
<td>
<p>A value between 0 and 1 indicates which (absolute) values
from the loadings should be removed. An integer higher than 1 indicates the
n strongest loadings to retain. Can also be <code>"max"</code>, in which case it
will only display the maximum loading per variable (the most simple
structure).</p>
</td></tr>
<tr><td><code id="convert_efa_to_cfa_+3A_names">names</code></td>
<td>
<p>Vector containing dimension names.</p>
</td></tr>
<tr><td><code id="convert_efa_to_cfa_+3A_max_per_dimension">max_per_dimension</code></td>
<td>
<p>Maximum number of variables to keep per dimension.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Converted index.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

library(parameters)
data(attitude)
efa &lt;- psych::fa(attitude, nfactors = 3)

model1 &lt;- efa_to_cfa(efa)
model2 &lt;- efa_to_cfa(efa, threshold = 0.3)
model3 &lt;- efa_to_cfa(efa, max_per_dimension = 2)

suppressWarnings(anova(
  lavaan::cfa(model1, data = attitude),
  lavaan::cfa(model2, data = attitude),
  lavaan::cfa(model3, data = attitude)
))


</code></pre>

<hr>
<h2 id='degrees_of_freedom'>Degrees of Freedom (DoF)</h2><span id='topic+degrees_of_freedom'></span><span id='topic+degrees_of_freedom.default'></span><span id='topic+dof'></span>

<h3>Description</h3>

<p>Estimate or extract degrees of freedom of models parameters.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>degrees_of_freedom(model, ...)

## Default S3 method:
degrees_of_freedom(model, method = "analytical", ...)

dof(model, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="degrees_of_freedom_+3A_model">model</code></td>
<td>
<p>A statistical model.</p>
</td></tr>
<tr><td><code id="degrees_of_freedom_+3A_...">...</code></td>
<td>
<p>Currently not used.</p>
</td></tr>
<tr><td><code id="degrees_of_freedom_+3A_method">method</code></td>
<td>
<p>Can be <code>"analytical"</code> (default, DoFs are estimated based
on the model type), <code>"residual"</code> in which case they are directly taken
from the model if available (for Bayesian models, the goal (looking for
help to make it happen) would be to refit the model as a frequentist one
before extracting the DoFs), <code>"ml1"</code> (see <code><a href="#topic+dof_ml1">dof_ml1()</a></code>), <code>"betwithin"</code>
(see <code><a href="#topic+dof_betwithin">dof_betwithin()</a></code>), <code>"satterthwaite"</code> (see <code><a href="#topic+dof_satterthwaite">dof_satterthwaite()</a></code>),
<code>"kenward"</code> (see <code><a href="#topic+dof_kenward">dof_kenward()</a></code>) or <code>"any"</code>, which tries to extract DoF
by any of those methods, whichever succeeds. See 'Details'.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Methods for calculating degrees of freedom:
</p>

<ul>
<li> <p><code>"analytical"</code> for models of class <code>lmerMod</code>, Kenward-Roger approximated
degrees of freedoms are calculated, for other models, <code>n-k</code> (number of
observations minus number of parameters).
</p>
</li>
<li> <p><code>"residual"</code> tries to extract residual degrees of freedom, and returns
<code>Inf</code> if residual degrees of freedom could not be extracted.
</p>
</li>
<li> <p><code>"any"</code> first tries to extract residual degrees of freedom, and if these
are not available, extracts analytical degrees of freedom.
</p>
</li>
<li> <p><code>"nokr"</code> same as <code>"analytical"</code>, but does not Kenward-Roger approximation
for models of class <code>lmerMod</code>. Instead, always uses <code>n-k</code> to calculate df
for any model.
</p>
</li>
<li> <p><code>"normal"</code> returns <code>Inf</code>.
</p>
</li>
<li> <p><code>"wald"</code> returns residual df for models with t-statistic, and <code>Inf</code> for all other models.
</p>
</li>
<li> <p><code>"kenward"</code> calls <code><a href="#topic+dof_kenward">dof_kenward()</a></code>.
</p>
</li>
<li> <p><code>"satterthwaite"</code> calls <code><a href="#topic+dof_satterthwaite">dof_satterthwaite()</a></code>.
</p>
</li>
<li> <p><code>"ml1"</code> calls <code><a href="#topic+dof_ml1">dof_ml1()</a></code>.
</p>
</li>
<li> <p><code>"betwithin"</code> calls <code><a href="#topic+dof_betwithin">dof_betwithin()</a></code>.
</p>
</li></ul>

<p>For models with z-statistic, the returned degrees of freedom for model parameters
is <code>Inf</code> (unless <code>method = "ml1"</code> or <code>method = "betwithin"</code>), because there is
only one distribution for the related test statistic.
</p>


<h3>Note</h3>

<p>In many cases, <code>degrees_of_freedom()</code> returns the same as <code>df.residuals()</code>,
or <code>n-k</code> (number of observations minus number of parameters). However,
<code>degrees_of_freedom()</code> refers to the model's <em>parameters</em> degrees of freedom
of the distribution for the related test statistic. Thus, for models with
z-statistic, results from <code>degrees_of_freedom()</code> and <code>df.residuals()</code> differ.
Furthermore, for other approximation methods like <code>"kenward"</code> or
<code>"satterthwaite"</code>, each model parameter can have a different degree of
freedom.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>model &lt;- lm(Sepal.Length ~ Petal.Length * Species, data = iris)
dof(model)

model &lt;- glm(vs ~ mpg * cyl, data = mtcars, family = "binomial")
dof(model)

if (require("lme4", quietly = TRUE)) {
  model &lt;- lmer(Sepal.Length ~ Petal.Length + (1 | Species), data = iris)
  dof(model)
}

if (require("rstanarm", quietly = TRUE)) {
  model &lt;- stan_glm(
    Sepal.Length ~ Petal.Length * Species,
    data = iris,
    chains = 2,
    refresh = 0
  )
  dof(model)
}

</code></pre>

<hr>
<h2 id='display.parameters_model'>Print tables in different output formats</h2><span id='topic+display.parameters_model'></span><span id='topic+display.parameters_sem'></span><span id='topic+display.parameters_efa_summary'></span><span id='topic+display.parameters_efa'></span><span id='topic+display.equivalence_test_lm'></span><span id='topic+format.parameters_model'></span><span id='topic+print_html.parameters_model'></span><span id='topic+print_md.parameters_model'></span><span id='topic+print_table'></span>

<h3>Description</h3>

<p>Prints tables (i.e. data frame) in different output formats.
<code>print_md()</code> is a alias for <code>display(format = "markdown")</code>, <code>print_html()</code>
is a alias for <code>display(format = "html")</code>. <code>print_table()</code> is for specific
use cases only, and currently only works for <code>compare_parameters()</code> objects.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'parameters_model'
display(
  object,
  format = "markdown",
  pretty_names = TRUE,
  split_components = TRUE,
  select = NULL,
  caption = NULL,
  subtitle = NULL,
  footer = NULL,
  align = NULL,
  digits = 2,
  ci_digits = digits,
  p_digits = 3,
  footer_digits = 3,
  ci_brackets = c("(", ")"),
  show_sigma = FALSE,
  show_formula = FALSE,
  zap_small = FALSE,
  font_size = "100%",
  line_padding = 4,
  column_labels = NULL,
  include_reference = FALSE,
  verbose = TRUE,
  ...
)

## S3 method for class 'parameters_sem'
display(
  object,
  format = "markdown",
  digits = 2,
  ci_digits = digits,
  p_digits = 3,
  ci_brackets = c("(", ")"),
  ...
)

## S3 method for class 'parameters_efa_summary'
display(object, format = "markdown", digits = 3, ...)

## S3 method for class 'parameters_efa'
display(
  object,
  format = "markdown",
  digits = 2,
  sort = FALSE,
  threshold = NULL,
  labels = NULL,
  ...
)

## S3 method for class 'equivalence_test_lm'
display(object, format = "markdown", digits = 2, ...)

## S3 method for class 'parameters_model'
format(
  x,
  pretty_names = TRUE,
  split_components = TRUE,
  select = NULL,
  digits = 2,
  ci_digits = digits,
  p_digits = 3,
  ci_width = NULL,
  ci_brackets = NULL,
  zap_small = FALSE,
  format = NULL,
  groups = NULL,
  include_reference = FALSE,
  ...
)

## S3 method for class 'parameters_model'
print_html(
  x,
  pretty_names = TRUE,
  split_components = TRUE,
  select = NULL,
  caption = NULL,
  subtitle = NULL,
  footer = NULL,
  align = NULL,
  digits = 2,
  ci_digits = digits,
  p_digits = 3,
  footer_digits = 3,
  ci_brackets = c("(", ")"),
  show_sigma = FALSE,
  show_formula = FALSE,
  zap_small = FALSE,
  groups = NULL,
  font_size = "100%",
  line_padding = 4,
  column_labels = NULL,
  include_reference = FALSE,
  verbose = TRUE,
  ...
)

## S3 method for class 'parameters_model'
print_md(
  x,
  pretty_names = TRUE,
  split_components = TRUE,
  select = NULL,
  caption = NULL,
  subtitle = NULL,
  footer = NULL,
  align = NULL,
  digits = 2,
  ci_digits = digits,
  p_digits = 3,
  footer_digits = 3,
  ci_brackets = c("(", ")"),
  show_sigma = FALSE,
  show_formula = FALSE,
  zap_small = FALSE,
  groups = NULL,
  include_reference = FALSE,
  verbose = TRUE,
  ...
)

print_table(x, digits = 2, p_digits = 3, theme = "default", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="display.parameters_model_+3A_object">object</code></td>
<td>
<p>An object returned by <code><a href="#topic+model_parameters">model_parameters()</a></code>,
<code><a href="#topic+simulate_parameters">simulate_parameters()</a></code>,
<code><a href="#topic+equivalence_test.lm">equivalence_test()</a></code> or
<code><a href="#topic+principal_components">principal_components()</a></code>.</p>
</td></tr>
<tr><td><code id="display.parameters_model_+3A_format">format</code></td>
<td>
<p>String, indicating the output format. Can be <code>"markdown"</code>
or <code>"html"</code>.</p>
</td></tr>
<tr><td><code id="display.parameters_model_+3A_pretty_names">pretty_names</code></td>
<td>
<p>Can be <code>TRUE</code>, which will return &quot;pretty&quot; (i.e. more human
readable) parameter names. Or <code>"labels"</code>, in which case value and variable
labels will be used as parameters names. The latter only works for &quot;labelled&quot;
data, i.e. if the data used to fit the model had <code>"label"</code> and <code>"labels"</code>
attributes. See also section <em>Global Options to Customize Messages when Printing</em>.</p>
</td></tr>
<tr><td><code id="display.parameters_model_+3A_split_components">split_components</code></td>
<td>
<p>Logical, if <code>TRUE</code> (default), For models with
multiple components (zero-inflation, smooth terms, ...), each component is
printed in a separate table. If <code>FALSE</code>, model parameters are printed
in a single table and a <code>Component</code> column is added to the output.</p>
</td></tr>
<tr><td><code id="display.parameters_model_+3A_select">select</code></td>
<td>
<p>Determines which columns and and which layout columns are
printed. There are three options for this argument:
</p>

<ol>
<li><p> Selecting columns by name or index
<br />
<code>select</code> can be a character vector (or numeric index) of column names that
should be printed. There are two pre-defined options for selecting columns:
<code>select = "minimal"</code> prints coefficients, confidence intervals and p-values,
while <code>select = "short"</code> prints coefficients, standard errors and p-values.
</p>
</li>
<li><p> A string expression with layout pattern
<br />
<code>select</code> is a string with &quot;tokens&quot; enclosed in braces. These tokens will
be replaced by their associated columns, where the selected columns will
be collapsed into one column. However, it is possible to create multiple
columns as well. Following tokens are replaced by the related coefficients
or statistics: <code>{estimate}</code>, <code>{se}</code>, <code>{ci}</code> (or <code>{ci_low}</code> and <code>{ci_high}</code>),
<code>{p}</code> and <code>{stars}</code>. The token <code>{ci}</code> will be replaced by <code style="white-space: pre;">&#8288;{ci_low}, {ci_high}&#8288;</code>.
Furthermore, a <code>|</code> separates values into new cells/columns. If
<code>format = "html"</code>, a <code style="white-space: pre;">&#8288;&lt;br&gt;&#8288;</code> inserts a line break inside a cell. See
'Examples'.
</p>
</li>
<li><p> A string indicating a pre-defined layout
<br />
<code>select</code> can be one of the following string values, to create one of the
following pre-defined column layouts:
</p>

<ul>
<li> <p><code>"ci"</code>: Estimates and confidence intervals, no asterisks for p-values.
This is equivalent to <code>select = "{estimate} ({ci})"</code>.
</p>
</li>
<li> <p><code>"se"</code>: Estimates and standard errors, no asterisks for p-values. This is
equivalent to <code>select = "{estimate} ({se})"</code>.
</p>
</li>
<li> <p><code>"ci_p"</code>: Estimates, confidence intervals and asterisks for p-values. This
is equivalent to <code>select = "{estimate}{stars} ({ci})"</code>.
</p>
</li>
<li> <p><code>"se_p"</code>: Estimates, standard errors and asterisks for p-values. This is
equivalent to <code>select = "{estimate}{stars} ({se})"</code>..
</p>
</li>
<li> <p><code>"ci_p2"</code>: Estimates, confidence intervals and numeric p-values, in two
columns. This is equivalent to <code>select = "{estimate} ({ci})|{p}"</code>.
</p>
</li>
<li> <p><code>"se_p2"</code>: Estimate, standard errors and numeric p-values, in two columns.
This is equivalent to <code>select = "{estimate} ({se})|{p}"</code>.
</p>
</li></ul>

</li></ol>

<p>For <code>model_parameters()</code>, glue-like syntax is still experimental in the
case of more complex models (like mixed models) and may not return expected
results.</p>
</td></tr>
<tr><td><code id="display.parameters_model_+3A_caption">caption</code></td>
<td>
<p>Table caption as string. If <code>NULL</code>, depending on the model,
either a default caption or no table caption is printed. Use <code>caption = ""</code>
to suppress the table caption.</p>
</td></tr>
<tr><td><code id="display.parameters_model_+3A_subtitle">subtitle</code></td>
<td>
<p>Table title (same as caption) and subtitle, as strings. If <code>NULL</code>,
no title or subtitle is printed, unless it is stored as attributes (<code>table_title</code>,
or its alias <code>table_caption</code>, and <code>table_subtitle</code>). If <code>x</code> is a list of
data frames, <code>caption</code> may be a list of table captions, one for each table.</p>
</td></tr>
<tr><td><code id="display.parameters_model_+3A_footer">footer</code></td>
<td>
<p>Can either be <code>FALSE</code> or an empty string (i.e. <code>""</code>) to
suppress the footer, <code>NULL</code> to print the default footer, or a string. The
latter will combine the string value with the default footer.</p>
</td></tr>
<tr><td><code id="display.parameters_model_+3A_align">align</code></td>
<td>
<p>Only applies to HTML tables. May be one of <code>"left"</code>,
<code>"right"</code> or <code>"center"</code>.</p>
</td></tr>
<tr><td><code id="display.parameters_model_+3A_digits">digits</code>, <code id="display.parameters_model_+3A_ci_digits">ci_digits</code>, <code id="display.parameters_model_+3A_p_digits">p_digits</code></td>
<td>
<p>Number of digits for rounding or
significant figures. May also be <code>"signif"</code> to return significant
figures or <code>"scientific"</code> to return scientific notation. Control the
number of digits by adding the value as suffix, e.g. <code>digits = "scientific4"</code>
to have scientific notation with 4 decimal places, or <code>digits = "signif5"</code>
for 5 significant figures (see also <code><a href="base.html#topic+signif">signif()</a></code>).</p>
</td></tr>
<tr><td><code id="display.parameters_model_+3A_footer_digits">footer_digits</code></td>
<td>
<p>Number of decimal places for values in the footer summary.</p>
</td></tr>
<tr><td><code id="display.parameters_model_+3A_ci_brackets">ci_brackets</code></td>
<td>
<p>Logical, if <code>TRUE</code> (default), CI-values are
encompassed in square brackets (else in parentheses).</p>
</td></tr>
<tr><td><code id="display.parameters_model_+3A_show_sigma">show_sigma</code></td>
<td>
<p>Logical, if <code>TRUE</code>, adds information about the residual
standard deviation.</p>
</td></tr>
<tr><td><code id="display.parameters_model_+3A_show_formula">show_formula</code></td>
<td>
<p>Logical, if <code>TRUE</code>, adds the model formula to the output.</p>
</td></tr>
<tr><td><code id="display.parameters_model_+3A_zap_small">zap_small</code></td>
<td>
<p>Logical, if <code>TRUE</code>, small values are rounded after
<code>digits</code> decimal places. If <code>FALSE</code>, values with more decimal
places than <code>digits</code> are printed in scientific notation.</p>
</td></tr>
<tr><td><code id="display.parameters_model_+3A_font_size">font_size</code></td>
<td>
<p>For HTML tables, the font size.</p>
</td></tr>
<tr><td><code id="display.parameters_model_+3A_line_padding">line_padding</code></td>
<td>
<p>For HTML tables, the distance (in pixel) between lines.</p>
</td></tr>
<tr><td><code id="display.parameters_model_+3A_column_labels">column_labels</code></td>
<td>
<p>Labels of columns for HTML tables. If <code>NULL</code>, automatic
column names are generated. See 'Examples'.</p>
</td></tr>
<tr><td><code id="display.parameters_model_+3A_include_reference">include_reference</code></td>
<td>
<p>Logical, if <code>TRUE</code>, the reference level of factors will
be added to the parameters table. This is only relevant for models with
categorical predictors. The coefficient for the reference level is always
<code>0</code> (except when <code>exponentiate = TRUE</code>, then the coefficient will be <code>1</code>),
so this is just for completeness.</p>
</td></tr>
<tr><td><code id="display.parameters_model_+3A_verbose">verbose</code></td>
<td>
<p>Toggle messages and warnings.</p>
</td></tr>
<tr><td><code id="display.parameters_model_+3A_...">...</code></td>
<td>
<p>Arguments passed to or from other methods.</p>
</td></tr>
<tr><td><code id="display.parameters_model_+3A_sort">sort</code></td>
<td>
<p>Sort the loadings.</p>
</td></tr>
<tr><td><code id="display.parameters_model_+3A_threshold">threshold</code></td>
<td>
<p>A value between 0 and 1 indicates which (absolute) values
from the loadings should be removed. An integer higher than 1 indicates the
n strongest loadings to retain. Can also be <code>"max"</code>, in which case it
will only display the maximum loading per variable (the most simple
structure).</p>
</td></tr>
<tr><td><code id="display.parameters_model_+3A_labels">labels</code></td>
<td>
<p>A character vector containing labels to be added to the
loadings data. Usually, the question related to the item.</p>
</td></tr>
<tr><td><code id="display.parameters_model_+3A_x">x</code></td>
<td>
<p>An object returned by <code><a href="#topic+model_parameters">model_parameters()</a></code>.</p>
</td></tr>
<tr><td><code id="display.parameters_model_+3A_ci_width">ci_width</code></td>
<td>
<p>Minimum width of the returned string for confidence
intervals. If not <code>NULL</code> and width is larger than the string's length,
leading whitespaces are added to the string. If <code>width="auto"</code>, width
will be set to the length of the longest string.</p>
</td></tr>
<tr><td><code id="display.parameters_model_+3A_groups">groups</code></td>
<td>
<p>Named list, can be used to group parameters in the printed output.
List elements may either be character vectors that match the name of those
parameters that belong to one group, or list elements can be row numbers
of those parameter rows that should belong to one group. The names of the
list elements will be used as group names, which will be inserted as &quot;header
row&quot;. A possible use case might be to emphasize focal predictors and control
variables, see 'Examples'. Parameters will be re-ordered according to the
order used in <code>groups</code>, while all non-matching parameters will be added
to the end.</p>
</td></tr>
<tr><td><code id="display.parameters_model_+3A_theme">theme</code></td>
<td>
<p>String, indicating the table theme. Can be one of <code>"default"</code>,
<code>"grid"</code>, <code>"striped"</code>, <code>"bootstrap"</code> or <code>"darklines"</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>display()</code> is useful when the table-output from functions,
which is usually printed as formatted text-table to console, should
be formatted for pretty table-rendering in markdown documents, or if
knitted from rmarkdown to PDF or Word files. See
<a href="https://easystats.github.io/parameters/articles/model_parameters_formatting.html">vignette</a>
for examples.
</p>
<p><code>print_table()</code> is a special function for <code>compare_parameters()</code> objects,
which prints the output as a formatted HTML table. It is still somewhat
experimental, thus, only a fixed layout-style is available at the moment
(columns for estimates, confidence intervals and p-values). However, it
is possible to include other model components, like zero-inflation, or random
effects in the table. See 'Examples'. An alternative is to set <code>engine = "tt"</code>
in <code>print_html()</code> to use the <em>tinytable</em> package for creating HTML tables.
</p>


<h3>Value</h3>

<p>If <code>format = "markdown"</code>, the return value will be a character
vector in markdown-table format. If <code>format = "html"</code>, an object of
class <code>gt_tbl</code>. For <code>print_table()</code>, an object of class <code>tinytable</code> is
returned.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+print.parameters_model">print.parameters_model()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
model &lt;- lm(mpg ~ wt + cyl, data = mtcars)
mp &lt;- model_parameters(model)
display(mp)


data(iris)
lm1 &lt;- lm(Sepal.Length ~ Species, data = iris)
lm2 &lt;- lm(Sepal.Length ~ Species + Petal.Length, data = iris)
lm3 &lt;- lm(Sepal.Length ~ Species * Petal.Length, data = iris)
out &lt;- compare_parameters(lm1, lm2, lm3)

print_html(
  out,
  select = "{coef}{stars}|({ci})",
  column_labels = c("Estimate", "95% CI")
)

# line break, unicode minus-sign
print_html(
  out,
  select = "{estimate}{stars}&lt;br&gt;({ci_low} \u2212 {ci_high})",
  column_labels = c("Est. (95% CI)")
)




data(iris)
data(Salamanders, package = "glmmTMB")
m1 &lt;- lm(Sepal.Length ~ Species * Petal.Length, data = iris)
m2 &lt;- lme4::lmer(
  Sepal.Length ~ Petal.Length + Petal.Width + (1 | Species),
  data = iris
)
m3 &lt;- glmmTMB::glmmTMB(
  count ~ spp + mined + (1 | site),
  ziformula = ~mined,
  family = poisson(),
  data = Salamanders
)
out &lt;- compare_parameters(m1, m2, m3, effects = "all", component = "all")
print_table(out)


</code></pre>

<hr>
<h2 id='dominance_analysis'>Dominance Analysis</h2><span id='topic+dominance_analysis'></span>

<h3>Description</h3>

<p>Computes Dominance Analysis Statistics and Designations
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dominance_analysis(
  model,
  sets = NULL,
  all = NULL,
  conditional = TRUE,
  complete = TRUE,
  quote_args = NULL,
  contrasts = model$contrasts,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dominance_analysis_+3A_model">model</code></td>
<td>
<p>A model object supported by <code>performance::r2()</code>. See 'Details'.</p>
</td></tr>
<tr><td><code id="dominance_analysis_+3A_sets">sets</code></td>
<td>
<p>A (named) list of formula objects with no left hand
side/response.  If the list has names, the name provided each element
will be used as the label for the set.  Unnamed list elements will be
provided a set number name based on its position among the sets as entered.
</p>
<p>Predictors in each formula are bound together as a set in the dominance
analysis and dominance statistics and designations are computed for
the predictors together.  Predictors in <code>sets</code> must be present in the model
submitted to the <code>model</code> argument and cannot be in the <code>all</code> argument.</p>
</td></tr>
<tr><td><code id="dominance_analysis_+3A_all">all</code></td>
<td>
<p>A formula with no left hand side/response.
</p>
<p>Predictors in the formula are included in each subset in the dominance
analysis and the R2 value associated with them is subtracted from the
overall value.  Predictors in <code>all</code> must be present in the model
submitted to the <code>model</code> argument and cannot be in the <code>sets</code> argument.</p>
</td></tr>
<tr><td><code id="dominance_analysis_+3A_conditional">conditional</code></td>
<td>
<p>Logical.  If <code>FALSE</code> then conditional dominance matrix is not computed.
</p>
<p>If conditional dominance is not desired as an importance criterion, avoiding computing the conditional dominance matrix can save computation time.</p>
</td></tr>
<tr><td><code id="dominance_analysis_+3A_complete">complete</code></td>
<td>
<p>Logical.  If <code>FALSE</code> then complete dominance matrix is not computed.
</p>
<p>If complete dominance is not desired as an importance criterion, avoiding computing complete dominance designations can save computation time.</p>
</td></tr>
<tr><td><code id="dominance_analysis_+3A_quote_args">quote_args</code></td>
<td>
<p>A character vector of arguments in the model submitted to
<code>model</code> to <code>quote()</code> prior to submitting to the dominance analysis.  This
is necessary for data masked arguments (e.g., <code>weights</code>) to prevent them
from being evaluated before being applied to the model and causing an error.</p>
</td></tr>
<tr><td><code id="dominance_analysis_+3A_contrasts">contrasts</code></td>
<td>
<p>A named list of <code><a href="stats.html#topic+contrasts">contrasts</a></code> used by the model object.
This list is required in order for the correct mapping of parameters to
predictors in the output when the model creates indicator codes for factor
variables using <code><a href="insight.html#topic+get_modelmatrix">insight::get_modelmatrix()</a></code>. By default, the <code>contrast</code>
element from the model object submitted is used. If the model object does
not have a <code>contrast</code> element the user can supply this named list.</p>
</td></tr>
<tr><td><code id="dominance_analysis_+3A_...">...</code></td>
<td>
<p>Not used at current.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Computes two decompositions of the model's R2 and returns
a matrix of designations from which predictor relative importance
determinations can be obtained.
</p>
<p>Note in the output that the &quot;constant&quot; subset is associated with a
component of the model that does not directly contribute to the R2 such
as an intercept. The &quot;all&quot; subset is apportioned a component of the fit
statistic but is not considered a part of the dominance analysis and
therefore does not receive a rank, conditional dominance statistics, or
complete dominance designations.
</p>
<p>The input model is parsed using <code>insight::find_predictors()</code>, does not
yet support interactions, transformations, or offsets applied in the R
formula, and will fail with an error if any such terms are detected.
</p>
<p>The model submitted must accept an formula object as a <code>formula</code>
argument.  In addition, the model object must accept the data on which
the model is estimated as a <code>data</code> argument.  Formulas submitted
using object references (i.e., <code>lm(mtcars$mpg ~ mtcars$vs)</code>) and
functions that accept data as a non-<code>data</code> argument
(e.g., <code>survey::svyglm()</code> uses <code>design</code>) will fail with an error.
</p>
<p>Models that return <code>TRUE</code> for the <code>insight::model_info()</code>
function's values &quot;is_bayesian&quot;, &quot;is_mixed&quot;, &quot;is_gam&quot;,
is_multivariate&quot;, &quot;is_zero_inflated&quot;,
or &quot;is_hurdle&quot; are not supported at current.
</p>
<p>When <code>performance::r2()</code> returns multiple values, only the first is used
by default.
</p>


<h3>Value</h3>

<p>Object of class <code>"parameters_da"</code>.
</p>
<p>An object of class <code>"parameters_da"</code> is a list of <code>data.frame</code>s composed
of the following elements:
</p>

<dl>
<dt><code>General</code></dt><dd><p>A <code>data.frame</code> which associates dominance statistics with
model parameters. The variables in this <code>data.frame</code> include:
</p>

<dl>
<dt><code>Parameter</code></dt><dd><p>Parameter names.</p>
</dd>
<dt><code>General_Dominance</code></dt><dd><p>Vector of general dominance statistics.
The R2 ascribed to variables in the <code>all</code> argument are also reported
here though they are not general dominance statistics.</p>
</dd>
<dt><code>Percent</code></dt><dd><p>Vector of general dominance statistics normalized
to sum to 1.</p>
</dd>
<dt><code>Ranks</code></dt><dd><p>Vector of ranks applied to the general dominance
statistics.</p>
</dd>
<dt><code>Subset</code></dt><dd><p>Names of the subset to which the parameter belongs in
the dominance analysis.  Each other <code>data.frame</code> returned will refer
to these subset names.</p>
</dd></dl>
</dd>
<dt><code>Conditional</code></dt><dd><p>A <code>data.frame</code> of conditional dominance
statistics.  Each observation represents a subset and each variable
represents an the average increment to R2 with a specific number of
subsets in the model.  <code>NULL</code> if <code>conditional</code> argument is <code>FALSE</code>.</p>
</dd>
<dt><code>Complete</code></dt><dd><p>A <code>data.frame</code> of complete dominance
designations. The subsets in the observations are compared to the
subsets referenced in each variable. Whether the subset
in each variable dominates the subset in each observation is
represented in the  logical value. <code>NULL</code> if <code>complete</code>
argument is <code>FALSE</code>.</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Joseph Luchman
</p>


<h3>References</h3>


<ul>
<li><p> Azen, R., &amp; Budescu, D. V. (2003). The dominance analysis approach
for comparing predictors in multiple regression. Psychological Methods,
8(2), 129-148. doi:10.1037/1082-989X.8.2.129
</p>
</li>
<li><p> Budescu, D. V. (1993). Dominance analysis: A new approach to the
problem of relative importance of predictors in multiple regression.
Psychological Bulletin, 114(3), 542-551. doi:10.1037/0033-2909.114.3.542
</p>
</li>
<li><p> Groemping, U. (2007). Estimators of relative importance in linear
regression based on variance decomposition. The American Statistician,
61(2), 139-147. doi:10.1198/000313007X188252
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="domir.html#topic+domin">domir::domin()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(mtcars)

# Dominance Analysis with Logit Regression
model &lt;- glm(vs ~ cyl + carb + mpg, data = mtcars, family = binomial())

performance::r2(model)
dominance_analysis(model)

# Dominance Analysis with Weighted Logit Regression
model_wt &lt;- glm(vs ~ cyl + carb + mpg,
  data = mtcars,
  weights = wt, family = quasibinomial()
)

dominance_analysis(model_wt, quote_args = "weights")

</code></pre>

<hr>
<h2 id='equivalence_test.lm'>Equivalence test</h2><span id='topic+equivalence_test.lm'></span><span id='topic+equivalence_test.merMod'></span><span id='topic+equivalence_test.ggeffects'></span>

<h3>Description</h3>

<p>Compute the (conditional) equivalence test for frequentist models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'lm'
equivalence_test(
  x,
  range = "default",
  ci = 0.95,
  rule = "classic",
  verbose = TRUE,
  ...
)

## S3 method for class 'merMod'
equivalence_test(
  x,
  range = "default",
  ci = 0.95,
  rule = "classic",
  effects = c("fixed", "random"),
  verbose = TRUE,
  ...
)

## S3 method for class 'ggeffects'
equivalence_test(
  x,
  range = "default",
  rule = "classic",
  test = "pairwise",
  verbose = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="equivalence_test.lm_+3A_x">x</code></td>
<td>
<p>A statistical model.</p>
</td></tr>
<tr><td><code id="equivalence_test.lm_+3A_range">range</code></td>
<td>
<p>The range of practical equivalence of an effect. May be
<code>"default"</code>, to automatically define this range based on properties of the
model's data.</p>
</td></tr>
<tr><td><code id="equivalence_test.lm_+3A_ci">ci</code></td>
<td>
<p>Confidence Interval (CI) level. Default to <code>0.95</code> (<code style="white-space: pre;">&#8288;95%&#8288;</code>).</p>
</td></tr>
<tr><td><code id="equivalence_test.lm_+3A_rule">rule</code></td>
<td>
<p>Character, indicating the rules when testing for practical
equivalence. Can be <code>"bayes"</code>, <code>"classic"</code> or <code>"cet"</code>. See
'Details'.</p>
</td></tr>
<tr><td><code id="equivalence_test.lm_+3A_verbose">verbose</code></td>
<td>
<p>Toggle warnings and messages.</p>
</td></tr>
<tr><td><code id="equivalence_test.lm_+3A_...">...</code></td>
<td>
<p>Arguments passed to or from other methods.</p>
</td></tr>
<tr><td><code id="equivalence_test.lm_+3A_effects">effects</code></td>
<td>
<p>Should parameters for fixed effects (<code>"fixed"</code>), random
effects (<code>"random"</code>), or both (<code>"all"</code>) be returned? Only applies
to mixed models. May be abbreviated. If the calculation of random effects
parameters takes too long, you may use <code>effects = "fixed"</code>.</p>
</td></tr>
<tr><td><code id="equivalence_test.lm_+3A_test">test</code></td>
<td>
<p>Hypothesis test for computing contrasts or pairwise comparisons.
See <a href="https://strengejacke.github.io/ggeffects/reference/test_predictions.html"><code>?ggeffects::test_predictions</code></a>
for details.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In classical null hypothesis significance testing (NHST) within a frequentist
framework, it is not possible to accept the null hypothesis, H0 - unlike
in Bayesian statistics, where such probability statements are possible.
&quot;<a href="base.html#topic+...">...</a> one can only reject the null hypothesis if the test
statistics falls into the critical region(s), or fail to reject this
hypothesis. In the latter case, all we can say is that no significant effect
was observed, but one cannot conclude that the null hypothesis is true.&quot;
(<em>Pernet 2017</em>). One way to address this issues without Bayesian methods
is <em>Equivalence Testing</em>, as implemented in <code>equivalence_test()</code>.
While you either can reject the null hypothesis or claim an inconclusive result
in NHST, the equivalence test - according to <em>Pernet</em> - adds a third category,
<em>&quot;accept&quot;</em>. Roughly speaking, the idea behind equivalence testing in a
frequentist framework is to check whether an estimate and its uncertainty
(i.e. confidence interval) falls within a region of &quot;practical equivalence&quot;.
Depending on the rule for this test (see below), statistical significance
does not necessarily indicate whether the null hypothesis can be rejected or
not, i.e. the classical interpretation of the p-value may differ from the
results returned from the equivalence test.
</p>


<h4>Calculation of equivalence testing</h4>


<ul>
<li><p> &quot;bayes&quot; - Bayesian rule (Kruschke 2018)
</p>
<p>This rule follows the &quot;HDI+ROPE decision rule&quot; (<em>Kruschke, 2014, 2018</em>) used
for the <code><a href="bayestestR.html#topic+equivalence_test">Bayesian counterpart()</a></code>. This
means, if the confidence intervals are completely outside the ROPE, the
&quot;null hypothesis&quot; for this parameter is &quot;rejected&quot;. If the ROPE
completely covers the CI, the null hypothesis is accepted. Else, it's
undecided whether to accept or reject the null hypothesis. Desirable
results are low proportions inside the ROPE (the closer to zero the
better).
</p>
</li>
<li><p> &quot;classic&quot; - The TOST rule (Lakens 2017)
</p>
<p>This rule follows the &quot;TOST rule&quot;, i.e. a two one-sided test procedure
(<em>Lakens 2017</em>). Following this rule, practical equivalence of an effect
(i.e. H0) is <em>rejected</em>, when the coefficient is statistically significant
<em>and</em> the narrow confidence intervals (i.e. <code>1-2*alpha</code>) <em>include</em> or
<em>exceed</em> the ROPE boundaries. Practical equivalence is assumed
(i.e. H0 &quot;accepted&quot;) when the narrow confidence intervals are completely
inside the ROPE, no matter if the effect is statistically significant
or not. Else, the decision whether to accept or reject practical
equivalence is undecided.
</p>
</li>
<li><p> &quot;cet&quot; - Conditional Equivalence Testing (Campbell/Gustafson 2018)
</p>
<p>The Conditional Equivalence Testing as described by <em>Campbell and
Gustafson 2018</em>. According to this rule, practical equivalence is
rejected when the coefficient is statistically significant. When the
effect is <em>not</em> significant and the narrow confidence intervals are
completely inside the ROPE, we accept (i.e. assume) practical equivalence,
else it is undecided.
</p>
</li></ul>




<h4>Levels of Confidence Intervals used for Equivalence Testing</h4>

<p>For <code>rule = "classic"</code>, &quot;narrow&quot; confidence intervals are used for
equivalence testing. &quot;Narrow&quot; means, the the intervals is not 1 - alpha,
but 1 - 2 * alpha. Thus, if <code>ci = .95</code>, alpha is assumed to be 0.05
and internally a ci-level of 0.90 is used. <code>rule = "cet"</code> uses
both regular and narrow confidence intervals, while <code>rule = "bayes"</code>
only uses the regular intervals.
</p>



<h4>p-Values</h4>

<p>The equivalence p-value is the area of the (cumulative) confidence
distribution that is outside of the region of equivalence. It can be
interpreted as p-value for <em>rejecting</em> the alternative hypothesis
and <em>accepting</em> the &quot;null hypothesis&quot; (i.e. assuming practical
equivalence). That is, a high p-value means we reject the assumption of
practical equivalence and accept the alternative hypothesis.
</p>



<h4>Second Generation p-Value (SGPV)</h4>

<p>Second generation p-values (SGPV) were proposed as a statistic that
represents <em>the proportion of data-supported hypotheses that are also null
hypotheses</em> <em>(Blume et al. 2018, Lakens and Delacre 2020)</em>. It represents the
proportion of the confidence interval range that is inside the ROPE.
</p>



<h4>ROPE range</h4>

<p>Some attention is required for finding suitable values for the ROPE limits
(argument <code>range</code>). See 'Details' in <code><a href="bayestestR.html#topic+rope_range">bayestestR::rope_range()</a></code>
for further information.
</p>



<h3>Value</h3>

<p>A data frame.
</p>


<h3>Note</h3>

<p>There is also a <a href="https://easystats.github.io/see/articles/parameters.html"><code>plot()</code>-method</a>
implemented in the <a href="https://easystats.github.io/see/"><strong>see</strong>-package</a>.
</p>


<h3>References</h3>


<ul>
<li><p> Blume, J. D., D'Agostino McGowan, L., Dupont, W. D., &amp; Greevy, R. A.
(2018). Second-generation p-values: Improved rigor, reproducibility, &amp;
transparency in statistical analyses. PLOS ONE, 13(3), e0188299.
https://doi.org/10.1371/journal.pone.0188299
</p>
</li>
<li><p> Campbell, H., &amp; Gustafson, P. (2018). Conditional equivalence
testing: An alternative remedy for publication bias. PLOS ONE, 13(4),
e0195145. doi: 10.1371/journal.pone.0195145
</p>
</li>
<li><p> Kruschke, J. K. (2014). Doing Bayesian data analysis: A tutorial with
R, JAGS, and Stan. Academic Press
</p>
</li>
<li><p> Kruschke, J. K. (2018). Rejecting or accepting parameter values in
Bayesian estimation. Advances in Methods and Practices in Psychological
Science, 1(2), 270-280. doi: 10.1177/2515245918771304
</p>
</li>
<li><p> Lakens, D. (2017). Equivalence Tests: A Practical Primer for t Tests,
Correlations, and Meta-Analyses. Social Psychological and Personality
Science, 8(4), 355–362. doi: 10.1177/1948550617697177
</p>
</li>
<li><p> Lakens, D., &amp; Delacre, M. (2020). Equivalence Testing and the Second
Generation P-Value. Meta-Psychology, 4.
https://doi.org/10.15626/MP.2018.933
</p>
</li>
<li><p> Pernet, C. (2017). Null hypothesis significance testing: A guide to
commonly misunderstood concepts and recommendations for good practice.
F1000Research, 4, 621. doi: 10.12688/f1000research.6963.5
</p>
</li></ul>



<h3>See Also</h3>

<p>For more details, see <code><a href="bayestestR.html#topic+equivalence_test">bayestestR::equivalence_test()</a></code>.
Further readings can be found in the references.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(qol_cancer)
model &lt;- lm(QoL ~ time + age + education, data = qol_cancer)

# default rule
equivalence_test(model)

# conditional equivalence test
equivalence_test(model, rule = "cet")

# plot method
if (require("see", quietly = TRUE)) {
  result &lt;- equivalence_test(model)
  plot(result)
}
</code></pre>

<hr>
<h2 id='factor_analysis'>Principal Component Analysis (PCA) and Factor Analysis (FA)</h2><span id='topic+factor_analysis'></span><span id='topic+principal_components'></span><span id='topic+rotated_data'></span><span id='topic+predict.parameters_efa'></span><span id='topic+print.parameters_efa'></span><span id='topic+sort.parameters_efa'></span><span id='topic+closest_component'></span>

<h3>Description</h3>

<p>The functions <code>principal_components()</code> and <code>factor_analysis()</code> can
be used to perform a principal component analysis (PCA) or a factor analysis
(FA). They return the loadings as a data frame, and various methods and
functions are available to access / display other information (see the
Details section).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>factor_analysis(
  x,
  n = "auto",
  rotation = "none",
  sort = FALSE,
  threshold = NULL,
  standardize = TRUE,
  cor = NULL,
  ...
)

principal_components(
  x,
  n = "auto",
  rotation = "none",
  sparse = FALSE,
  sort = FALSE,
  threshold = NULL,
  standardize = TRUE,
  ...
)

rotated_data(pca_results, verbose = TRUE)

## S3 method for class 'parameters_efa'
predict(
  object,
  newdata = NULL,
  names = NULL,
  keep_na = TRUE,
  verbose = TRUE,
  ...
)

## S3 method for class 'parameters_efa'
print(x, digits = 2, sort = FALSE, threshold = NULL, labels = NULL, ...)

## S3 method for class 'parameters_efa'
sort(x, ...)

closest_component(pca_results)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="factor_analysis_+3A_x">x</code></td>
<td>
<p>A data frame or a statistical model.</p>
</td></tr>
<tr><td><code id="factor_analysis_+3A_n">n</code></td>
<td>
<p>Number of components to extract. If <code>n="all"</code>, then <code>n</code> is set as
the number of variables minus 1 (<code>ncol(x)-1</code>). If <code>n="auto"</code> (default) or
<code>n=NULL</code>, the number of components is selected through <code><a href="#topic+n_factors">n_factors()</a></code> resp.
<code><a href="#topic+n_components">n_components()</a></code>. Else, if <code>n</code> is a number, <code>n</code> components are extracted.
If <code>n</code> exceeds number of variables in the data, it is automatically set to
the maximum number (i.e. <code>ncol(x)</code>). In <code><a href="#topic+reduce_parameters">reduce_parameters()</a></code>, can also
be <code>"max"</code>, in which case it will select all the components that are
maximally pseudo-loaded (i.e., correlated) by at least one variable.</p>
</td></tr>
<tr><td><code id="factor_analysis_+3A_rotation">rotation</code></td>
<td>
<p>If not <code>"none"</code>, the PCA / FA will be computed using the
<strong>psych</strong> package. Possible options include <code>"varimax"</code>,
<code>"quartimax"</code>, <code>"promax"</code>, <code>"oblimin"</code>, <code>"simplimax"</code>,
or <code>"cluster"</code> (and more). See <code><a href="psych.html#topic+fa">psych::fa()</a></code> for details.</p>
</td></tr>
<tr><td><code id="factor_analysis_+3A_sort">sort</code></td>
<td>
<p>Sort the loadings.</p>
</td></tr>
<tr><td><code id="factor_analysis_+3A_threshold">threshold</code></td>
<td>
<p>A value between 0 and 1 indicates which (absolute) values
from the loadings should be removed. An integer higher than 1 indicates the
n strongest loadings to retain. Can also be <code>"max"</code>, in which case it
will only display the maximum loading per variable (the most simple
structure).</p>
</td></tr>
<tr><td><code id="factor_analysis_+3A_standardize">standardize</code></td>
<td>
<p>A logical value indicating whether the variables should be
standardized (centered and scaled) to have unit variance before the
analysis (in general, such scaling is advisable).</p>
</td></tr>
<tr><td><code id="factor_analysis_+3A_cor">cor</code></td>
<td>
<p>An optional correlation matrix that can be used (note that the
data must still be passed as the first argument). If <code>NULL</code>, will
compute it by running <code>cor()</code> on the passed data.</p>
</td></tr>
<tr><td><code id="factor_analysis_+3A_...">...</code></td>
<td>
<p>Arguments passed to or from other methods.</p>
</td></tr>
<tr><td><code id="factor_analysis_+3A_sparse">sparse</code></td>
<td>
<p>Whether to compute sparse PCA (SPCA, using <code><a href="sparsepca.html#topic+spca">sparsepca::spca()</a></code>).
SPCA attempts to find sparse loadings (with few nonzero values), which improves
interpretability and avoids overfitting. Can be <code>TRUE</code> or <code>"robust"</code> (see
<code><a href="sparsepca.html#topic+robspca">sparsepca::robspca()</a></code>).</p>
</td></tr>
<tr><td><code id="factor_analysis_+3A_pca_results">pca_results</code></td>
<td>
<p>The output of the <code>principal_components()</code> function.</p>
</td></tr>
<tr><td><code id="factor_analysis_+3A_verbose">verbose</code></td>
<td>
<p>Toggle warnings.</p>
</td></tr>
<tr><td><code id="factor_analysis_+3A_object">object</code></td>
<td>
<p>An object of class <code>parameters_pca</code> or <code>parameters_efa</code></p>
</td></tr>
<tr><td><code id="factor_analysis_+3A_newdata">newdata</code></td>
<td>
<p>An optional data frame in which to look for variables with
which to predict. If omitted, the fitted values are used.</p>
</td></tr>
<tr><td><code id="factor_analysis_+3A_names">names</code></td>
<td>
<p>Optional character vector to name columns of the returned data
frame.</p>
</td></tr>
<tr><td><code id="factor_analysis_+3A_keep_na">keep_na</code></td>
<td>
<p>Logical, if <code>TRUE</code>, predictions also return observations
with missing values from the original data, hence the number of rows of
predicted data and original data is equal.</p>
</td></tr>
<tr><td><code id="factor_analysis_+3A_digits">digits</code>, <code id="factor_analysis_+3A_labels">labels</code></td>
<td>
<p>Arguments for <code>print()</code>.</p>
</td></tr>
</table>


<h3>Details</h3>



<h4>Methods and Utilities</h4>


<ul>
<li> <p><code><a href="#topic+n_components">n_components()</a></code> and <code><a href="#topic+n_factors">n_factors()</a></code> automatically estimates the optimal
number of dimensions to retain.
</p>
</li>
<li> <p><code><a href="performance.html#topic+check_factorstructure">performance::check_factorstructure()</a></code> checks the suitability of the
data for factor analysis using the sphericity (see
<code><a href="performance.html#topic+check_factorstructure">performance::check_sphericity_bartlett()</a></code>) and the KMO (see
<code><a href="performance.html#topic+check_factorstructure">performance::check_kmo()</a></code>) measure.
</p>
</li>
<li> <p><code><a href="performance.html#topic+check_itemscale">performance::check_itemscale()</a></code> computes various measures of internal
consistencies applied to the (sub)scales (i.e., components) extracted from
the PCA.
</p>
</li>
<li><p> Running <code>summary()</code> returns information related to each component/factor,
such as the explained variance and the Eivenvalues.
</p>
</li>
<li><p> Running <code><a href="#topic+get_scores">get_scores()</a></code> computes scores for each subscale.
</p>
</li>
<li><p> Running <code><a href="#topic+closest_component">closest_component()</a></code> will return a numeric vector with the
assigned component index for each column from the original data frame.
</p>
</li>
<li><p> Running <code><a href="#topic+rotated_data">rotated_data()</a></code> will return the rotated data, including missing
values, so it matches the original data frame.
</p>
</li>
<li><p> Running
<a href="https://easystats.github.io/see/articles/parameters.html#principal-component-analysis"><code>plot()</code></a>
visually displays the loadings (that requires the
<a href="https://easystats.github.io/see/"><strong>see</strong>-package</a> to work).
</p>
</li></ul>




<h4>Complexity</h4>

<p>Complexity represents the number of latent components needed to account
for the observed variables. Whereas a perfect simple structure solution
has a complexity of 1 in that each item would only load on one factor,
a solution with evenly distributed items has a complexity greater than 1
(<em>Hofman, 1978; Pettersson and Turkheimer, 2010</em>).
</p>



<h4>Uniqueness</h4>

<p>Uniqueness represents the variance that is 'unique' to the variable and
not shared with other variables. It is equal to <code style="white-space: pre;">&#8288;1 – communality&#8288;</code>
(variance that is shared with other variables). A uniqueness of <code>0.20</code>
suggests that <code style="white-space: pre;">&#8288;20%&#8288;</code> or that variable's variance is not shared with other
variables in the overall factor model. The greater 'uniqueness' the lower
the relevance of the variable in the factor model.
</p>



<h4>MSA</h4>

<p>MSA represents the Kaiser-Meyer-Olkin Measure of Sampling Adequacy
(<em>Kaiser and Rice, 1974</em>) for each item. It indicates whether there is
enough data for each factor give reliable results for the PCA. The value
should be &gt; 0.6, and desirable values are &gt; 0.8 (<em>Tabachnick and Fidell, 2013</em>).
</p>



<h4>PCA or FA?</h4>

<p>There is a simplified rule of thumb that may help do decide whether to run
a factor analysis or a principal component analysis:
</p>

<ul>
<li><p> Run <em>factor analysis</em> if you assume or wish to test a theoretical model of
<em>latent factors</em> causing observed variables.
</p>
</li>
<li><p> Run <em>principal component analysis</em> If you want to simply <em>reduce</em> your
correlated observed variables to a smaller set of important independent
composite variables.
</p>
</li></ul>

<p>(Source: <a href="https://stats.stackexchange.com/q/1576/54740">CrossValidated</a>)
</p>



<h4>Computing Item Scores</h4>

<p>Use <code><a href="#topic+get_scores">get_scores()</a></code> to compute scores for the &quot;subscales&quot; represented by the
extracted principal components. <code>get_scores()</code> takes the results from
<code>principal_components()</code> and extracts the variables for each component found
by the PCA. Then, for each of these &quot;subscales&quot;, raw means are calculated
(which equals adding up the single items and dividing by the number of items).
This results in a sum score for each component from the PCA, which is on the
same scale as the original, single items that were used to compute the PCA.
One can also use <code>predict()</code> to back-predict scores for each component,
to which one can provide <code>newdata</code> or a vector of <code>names</code> for the components.
</p>



<h4>Explained Variance and Eingenvalues</h4>

<p>Use <code>summary()</code> to get the Eigenvalues and the explained variance for each
extracted component. The eigenvectors and eigenvalues represent the &quot;core&quot;
of a PCA: The eigenvectors (the principal components) determine the
directions of the new feature space, and the eigenvalues determine their
magnitude. In other words, the eigenvalues explain the variance of the
data along the new feature axes.
</p>



<h3>Value</h3>

<p>A data frame of loadings.
</p>


<h3>References</h3>


<ul>
<li><p> Kaiser, H.F. and Rice. J. (1974). Little jiffy, mark iv. Educational
and Psychological Measurement, 34(1):111–117
</p>
</li>
<li><p> Hofmann, R. (1978). Complexity and simplicity as objective indices
descriptive of factor solutions. Multivariate Behavioral Research, 13:2,
247-250, <a href="https://doi.org/10.1207/s15327906mbr1302_9">doi:10.1207/s15327906mbr1302_9</a>
</p>
</li>
<li><p> Pettersson, E., &amp; Turkheimer, E. (2010). Item selection, evaluation,
and simple structure in personality data. Journal of research in
personality, 44(4), 407-420, <a href="https://doi.org/10.1016/j.jrp.2010.03.002">doi:10.1016/j.jrp.2010.03.002</a>
</p>
</li>
<li><p> Tabachnick, B. G., and Fidell, L. S. (2013). Using multivariate
statistics (6th ed.). Boston: Pearson Education.
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>
library(parameters)


# Principal Component Analysis (PCA) -------------------
principal_components(mtcars[, 1:7], n = "all", threshold = 0.2)

# Automated number of components
principal_components(mtcars[, 1:4], n = "auto")

# Sparse PCA
principal_components(mtcars[, 1:7], n = 4, sparse = TRUE)
principal_components(mtcars[, 1:7], n = 4, sparse = "robust")

# Rotated PCA
principal_components(mtcars[, 1:7],
  n = 2, rotation = "oblimin",
  threshold = "max", sort = TRUE
)
principal_components(mtcars[, 1:7], n = 2, threshold = 2, sort = TRUE)

pca &lt;- principal_components(mtcars[, 1:5], n = 2, rotation = "varimax")
pca # Print loadings
summary(pca) # Print information about the factors
predict(pca, names = c("Component1", "Component2")) # Back-predict scores

# which variables from the original data belong to which extracted component?
closest_component(pca)


# Factor Analysis (FA) ------------------------

factor_analysis(mtcars[, 1:7], n = "all", threshold = 0.2)
factor_analysis(mtcars[, 1:7], n = 2, rotation = "oblimin", threshold = "max", sort = TRUE)
factor_analysis(mtcars[, 1:7], n = 2, threshold = 2, sort = TRUE)

efa &lt;- factor_analysis(mtcars[, 1:5], n = 2)
summary(efa)
predict(efa, verbose = FALSE)


# Automated number of components
factor_analysis(mtcars[, 1:4], n = "auto")


</code></pre>

<hr>
<h2 id='fish'>Sample data set</h2><span id='topic+fish'></span>

<h3>Description</h3>

<p>A sample data set, used in tests and some examples.
</p>

<hr>
<h2 id='format_df_adjust'>Format the name of the degrees-of-freedom adjustment methods</h2><span id='topic+format_df_adjust'></span>

<h3>Description</h3>

<p>Format the name of the degrees-of-freedom adjustment methods.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>format_df_adjust(
  method,
  approx_string = "-approximated",
  dof_string = " degrees of freedom"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="format_df_adjust_+3A_method">method</code></td>
<td>
<p>Name of the method.</p>
</td></tr>
<tr><td><code id="format_df_adjust_+3A_approx_string">approx_string</code>, <code id="format_df_adjust_+3A_dof_string">dof_string</code></td>
<td>
<p>Suffix added to the name of the method in
the returned string.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A formatted string.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(parameters)

format_df_adjust("kenward")
format_df_adjust("kenward", approx_string = "", dof_string = " DoF")
</code></pre>

<hr>
<h2 id='format_order'>Order (first, second, ...) formatting</h2><span id='topic+format_order'></span>

<h3>Description</h3>

<p>Format order.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>format_order(order, textual = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="format_order_+3A_order">order</code></td>
<td>
<p>value or vector of orders.</p>
</td></tr>
<tr><td><code id="format_order_+3A_textual">textual</code></td>
<td>
<p>Return number as words. If <code>FALSE</code>, will run <code><a href="insight.html#topic+format_value">insight::format_value()</a></code>.</p>
</td></tr>
<tr><td><code id="format_order_+3A_...">...</code></td>
<td>
<p>Arguments to be passed to <code><a href="insight.html#topic+format_value">insight::format_value()</a></code> if <code>textual</code> is <code>FALSE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A formatted string.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>format_order(2)
format_order(8)
format_order(25, textual = FALSE)
</code></pre>

<hr>
<h2 id='format_p_adjust'>Format the name of the p-value adjustment methods</h2><span id='topic+format_p_adjust'></span>

<h3>Description</h3>

<p>Format the name of the p-value adjustment methods.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>format_p_adjust(method)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="format_p_adjust_+3A_method">method</code></td>
<td>
<p>Name of the method.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A string with the full surname(s) of the author(s), including year of publication, for the adjustment-method.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(parameters)

format_p_adjust("holm")
format_p_adjust("bonferroni")
</code></pre>

<hr>
<h2 id='format_parameters'>Parameter names formatting</h2><span id='topic+format_parameters'></span><span id='topic+format_parameters.default'></span>

<h3>Description</h3>

<p>This functions formats the names of model parameters (coefficients)
to make them more human-readable.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>format_parameters(model, ...)

## Default S3 method:
format_parameters(model, brackets = c("[", "]"), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="format_parameters_+3A_model">model</code></td>
<td>
<p>A statistical model.</p>
</td></tr>
<tr><td><code id="format_parameters_+3A_...">...</code></td>
<td>
<p>Currently not used.</p>
</td></tr>
<tr><td><code id="format_parameters_+3A_brackets">brackets</code></td>
<td>
<p>A character vector of length two, indicating the opening and closing brackets.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A (names) character vector with formatted parameter names. The value
names refer to the original names of the coefficients.
</p>


<h3>Interpretation of Interaction Terms</h3>

<p>Note that the <em>interpretation</em> of interaction terms depends on many
characteristics of the model. The number of parameters, and overall
performance of the model, can differ <em>or not</em> between <code>a * b</code>
<code>a : b</code>, and <code>a / b</code>, suggesting that sometimes interaction terms
give different parameterizations of the same model, but other times it gives
completely different models (depending on <code>a</code> or <code>b</code> being factors
of covariates, included as main effects or not, etc.). Their interpretation
depends of the full context of the model, which should not be inferred
from the parameters table alone - rather, we recommend to use packages
that calculate estimated marginal means or marginal effects, such as
<a href="https://CRAN.R-project.org/package=modelbased"><span class="pkg">modelbased</span></a>, <a href="https://CRAN.R-project.org/package=emmeans"><span class="pkg">emmeans</span></a>, <a href="https://CRAN.R-project.org/package=ggeffects"><span class="pkg">ggeffects</span></a>, or
<a href="https://CRAN.R-project.org/package=marginaleffects"><span class="pkg">marginaleffects</span></a>. To raise awareness for this issue, you may use
<code>print(...,show_formula=TRUE)</code> to add the model-specification to the output
of the <code><a href="#topic+print.parameters_model">print()</a></code> method for <code>model_parameters()</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>model &lt;- lm(Sepal.Length ~ Species * Sepal.Width, data = iris)
format_parameters(model)

model &lt;- lm(Sepal.Length ~ Petal.Length + (Species / Sepal.Width), data = iris)
format_parameters(model)

model &lt;- lm(Sepal.Length ~ Species + poly(Sepal.Width, 2), data = iris)
format_parameters(model)

model &lt;- lm(Sepal.Length ~ Species + poly(Sepal.Width, 2, raw = TRUE), data = iris)
format_parameters(model)
</code></pre>

<hr>
<h2 id='get_scores'>Get Scores from Principal Component Analysis (PCA)</h2><span id='topic+get_scores'></span>

<h3>Description</h3>

<p><code>get_scores()</code> takes <code>n_items</code> amount of items that load the most
(either by loading cutoff or number) on a component, and then computes their
average.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_scores(x, n_items = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_scores_+3A_x">x</code></td>
<td>
<p>An object returned by <code><a href="#topic+principal_components">principal_components()</a></code>.</p>
</td></tr>
<tr><td><code id="get_scores_+3A_n_items">n_items</code></td>
<td>
<p>Number of required (i.e. non-missing) items to build the sum
score. If <code>NULL</code>, the value is chosen to match half of the number of
columns in a data frame.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>get_scores()</code> takes the results from <code><a href="#topic+principal_components">principal_components()</a></code> and
extracts the variables for each component found by the PCA. Then, for each
of these &quot;subscales&quot;, row means are calculated (which equals adding up the
single items and dividing by the number of items). This results in a sum
score for each component from the PCA, which is on the same scale as the
original, single items that were used to compute the PCA.
</p>


<h3>Value</h3>

<p>A data frame with subscales, which are average sum scores for all
items from each component.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (require("psych")) {
  pca &lt;- principal_components(mtcars[, 1:7], n = 2, rotation = "varimax")

  # PCA extracted two components
  pca

  # assignment of items to each component
  closest_component(pca)

  # now we want to have sum scores for each component
  get_scores(pca)

  # compare to manually computed sum score for 2nd component, which
  # consists of items "hp" and "qsec"
  (mtcars$hp + mtcars$qsec) / 2
}
</code></pre>

<hr>
<h2 id='model_parameters'>Model Parameters</h2><span id='topic+model_parameters'></span><span id='topic+parameters'></span>

<h3>Description</h3>

<p>Compute and extract model parameters. The available options and arguments depend
on the modeling <strong>package</strong> and model <code>class</code>. Follow one of these links to read
the model-specific documentation:
</p>

<ul>
<li> <p><a href="#topic+model_parameters.default">Default method</a>: <code>lm</code>, <code>glm</code>, <strong>stats</strong>, <strong>censReg</strong>,
<strong>MASS</strong>, <strong>survey</strong>, ...
</p>
</li>
<li> <p><a href="#topic+model_parameters.cgam">Additive models</a>: <strong>bamlss</strong>, <strong>gamlss</strong>, <strong>mgcv</strong>,
<strong>scam</strong>, <strong>VGAM</strong>, <code>Gam</code>, <code>gamm</code>, ...
</p>
</li>
<li> <p><a href="#topic+model_parameters.aov">ANOVA</a>: <strong>afex</strong>, <code>aov</code>, <code>anova</code>, ...
</p>
</li>
<li> <p><a href="#topic+model_parameters.stanreg">Bayesian</a>: <strong>BayesFactor</strong>, <strong>blavaan</strong>, <strong>brms</strong>,
<strong>MCMCglmm</strong>, <strong>posterior</strong>, <strong>rstanarm</strong>, <code>bayesQR</code>, <code>bcplm</code>, <code>BGGM</code>, <code>blmrm</code>,
<code>blrm</code>, <code>mcmc.list</code>, <code>MCMCglmm</code>, ...
</p>
</li>
<li> <p><a href="#topic+model_parameters.kmeans">Clustering</a>: <strong>hclust</strong>, <strong>kmeans</strong>, <strong>mclust</strong>, <strong>pam</strong>, ...
</p>
</li>
<li> <p><a href="#topic+model_parameters.htest">Correlations, t-tests, etc.</a>: <strong>lmtest</strong>, <code>htest</code>,
<code>pairwise.htest</code>, ...
</p>
</li>
<li> <p><a href="#topic+model_parameters.rma">Meta-Analysis</a>: <strong>metaBMA</strong>, <strong>metafor</strong>, <strong>metaplus</strong>, ...
</p>
</li>
<li> <p><a href="#topic+model_parameters.merMod">Mixed models</a>: <strong>cplm</strong>, <strong>glmmTMB</strong>, <strong>lme4</strong>,
<strong>lmerTest</strong>, <strong>nlme</strong>, <strong>ordinal</strong>, <strong>robustlmm</strong>, <strong>spaMM</strong>, <code>mixed</code>, <code>MixMod</code>, ...
</p>
</li>
<li> <p><a href="#topic+model_parameters.mlm">Multinomial, ordinal and cumulative link</a>: <strong>brglm2</strong>,
<strong>DirichletReg</strong>, <strong>nnet</strong>, <strong>ordinal</strong>, <code>mlm</code>, ...
</p>
</li>
<li> <p><a href="#topic+model_parameters.mira">Multiple imputation</a>: <strong>mice</strong>
</p>
</li>
<li> <p><a href="#topic+model_parameters.principal">PCA, FA, CFA, SEM</a>: <strong>FactoMineR</strong>, <strong>lavaan</strong>,
<strong>psych</strong>, <code>sem</code>, ...
</p>
</li>
<li> <p><a href="#topic+model_parameters.zcpglm">Zero-inflated and hurdle</a>: <strong>cplm</strong>, <strong>mhurdle</strong>,
<strong>pscl</strong>, ...
</p>
</li>
<li> <p><a href="#topic+model_parameters.averaging">Other models</a>: <strong>aod</strong>, <strong>bbmle</strong>, <strong>betareg</strong>,
<strong>emmeans</strong>, <strong>epiR</strong>, <strong>ggeffects</strong>, <strong>glmx</strong>, <strong>ivfixed</strong>, <strong>ivprobit</strong>,
<strong>JRM</strong>, <strong>lmodel2</strong>, <strong>logitsf</strong>, <strong>marginaleffects</strong>, <strong>margins</strong>, <strong>maxLik</strong>,
<strong>mediation</strong>, <strong>mfx</strong>, <strong>multcomp</strong>, <strong>mvord</strong>, <strong>plm</strong>, <strong>PMCMRplus</strong>,
<strong>quantreg</strong>, <strong>selection</strong>, <strong>systemfit</strong>, <strong>tidymodels</strong>, <strong>varEST</strong>,
<strong>WRS2</strong>, <code>bfsl</code>, <code>deltaMethod</code>, <code>fitdistr</code>, <code>mjoint</code>, <code>mle</code>, <code>model.avg</code>, ...
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>model_parameters(model, ...)

parameters(model, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="model_parameters_+3A_model">model</code></td>
<td>
<p>Statistical Model.</p>
</td></tr>
<tr><td><code id="model_parameters_+3A_...">...</code></td>
<td>
<p>Arguments passed to or from other methods. Non-documented
arguments are <code>digits</code>, <code>p_digits</code>, <code>ci_digits</code> and <code>footer_digits</code> to set
the number of digits for the output. If <code>s_value = TRUE</code>, the p-value will
be replaced by the S-value in the output (cf. <em>Rafi and Greenland 2020</em>).
<code>pd</code> adds an additional column with the <em>probability of direction</em> (see
<code><a href="bayestestR.html#topic+p_direction">bayestestR::p_direction()</a></code> for details). <code>groups</code> can be used to group
coefficients. It will be passed to the print-method, or can directly be used
in <code>print()</code>, see documentation in <code><a href="#topic+print.parameters_model">print.parameters_model()</a></code>. Furthermore,
see 'Examples' in <code><a href="#topic+model_parameters.default">model_parameters.default()</a></code>. For developers, whose
interest mainly is to get a &quot;tidy&quot; data frame of model summaries, it is
recommended to set <code>pretty_names = FALSE</code> to speed up computation of the
summary table.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame of indices related to the model's parameters.
</p>


<h3>Standardization of model coefficients</h3>

<p>Standardization is based on <code><a href="#topic+standardize_parameters">standardize_parameters()</a></code>. In case
of <code>standardize = "refit"</code>, the data used to fit the model will be
standardized and the model is completely refitted. In such cases, standard
errors and confidence intervals refer to the standardized coefficient. The
default, <code>standardize = "refit"</code>, never standardizes categorical predictors
(i.e. factors), which may be a different behaviour compared to other R
packages or other software packages (like SPSS). To mimic behaviour of SPSS
or packages such as <strong>lm.beta</strong>, use <code>standardize = "basic"</code>.
</p>


<h3>Standardization Methods</h3>


<ul>
<li> <p><strong>refit</strong>: This method is based on a complete model re-fit with a
standardized version of the data. Hence, this method is equal to
standardizing the variables before fitting the model. It is the &quot;purest&quot; and
the most accurate (Neter et al., 1989), but it is also the most
computationally costly and long (especially for heavy models such as Bayesian
models). This method is particularly recommended for complex models that
include interactions or transformations (e.g., polynomial or spline terms).
The <code>robust</code> (default to <code>FALSE</code>) argument enables a robust standardization
of data, i.e., based on the <code>median</code> and <code>MAD</code> instead of the <code>mean</code> and
<code>SD</code>. <strong>See <code><a href="datawizard.html#topic+standardize">standardize()</a></code> for more details.</strong>
<strong>Note</strong> that <code>standardize_parameters(method = "refit")</code> may not return
the same results as fitting a model on data that has been standardized with
<code>standardize()</code>; <code>standardize_parameters()</code> used the data used by the model
fitting function, which might not be same data if there are missing values.
see the <code>remove_na</code> argument in <code>standardize()</code>.
</p>
</li>
<li> <p><strong>posthoc</strong>: Post-hoc standardization of the parameters, aiming at
emulating the results obtained by &quot;refit&quot; without refitting the model. The
coefficients are divided by the standard deviation (or MAD if <code>robust</code>) of
the outcome (which becomes their expression 'unit'). Then, the coefficients
related to numeric variables are additionally multiplied by the standard
deviation (or MAD if <code>robust</code>) of the related terms, so that they correspond
to changes of 1 SD of the predictor (e.g., &quot;A change in 1 SD of <code>x</code> is
related to a change of 0.24 of the SD of <code>y</code>). This does not apply to binary
variables or factors, so the coefficients are still related to changes in
levels. This method is not accurate and tend to give aberrant results when
interactions are specified.
</p>
</li>
<li> <p><strong>basic</strong>: This method is similar to <code>method = "posthoc"</code>, but treats all
variables as continuous: it also scales the coefficient by the standard
deviation of model's matrix' parameter of factors levels (transformed to
integers) or binary predictors. Although being inappropriate for these cases,
this method is the one implemented by default in other software packages,
such as <code><a href="lm.beta.html#topic+lm.beta">lm.beta::lm.beta()</a></code>.
</p>
</li>
<li> <p><strong>smart</strong> (Standardization of Model's parameters with Adjustment,
Reconnaissance and Transformation - <em>experimental</em>): Similar to <code>method = "posthoc"</code> in that it does not involve model refitting. The difference is
that the SD (or MAD if <code>robust</code>) of the response is computed on the relevant
section of the data. For instance, if a factor with 3 levels A (the
intercept), B and C is entered as a predictor, the effect corresponding to B
vs. A will be scaled by the variance of the response at the intercept only.
As a results, the coefficients for effects of factors are similar to a Glass'
delta.
</p>
</li>
<li> <p><strong>pseudo</strong> (<em>for 2-level (G)LMMs only</em>): In this (post-hoc) method, the
response and the predictor are standardized based on the level of prediction
(levels are detected with <code><a href="performance.html#topic+check_heterogeneity_bias">performance::check_heterogeneity_bias()</a></code>): Predictors
are standardized based on their SD at level of prediction (see also
<code><a href="datawizard.html#topic+demean">datawizard::demean()</a></code>); The outcome (in linear LMMs) is standardized based
on a fitted random-intercept-model, where <code>sqrt(random-intercept-variance)</code>
is used for level 2 predictors, and <code>sqrt(residual-variance)</code> is used for
level 1 predictors (Hoffman 2015, page 342). A warning is given when a
within-group variable is found to have access between-group variance.
</p>
</li></ul>

<p>See also <a href="https://easystats.github.io/parameters/articles/standardize_parameters_effsize.html">package vignette</a>.
</p>


<h3>Labeling the Degrees of Freedom</h3>

<p>Throughout the <strong>parameters</strong> package, we decided to label the residual
degrees of freedom <em>df_error</em>. The reason for this is that these degrees
of freedom not always refer to the residuals. For certain models, they refer
to the estimate error - in a linear model these are the same, but in - for
instance - any mixed effects model, this isn't strictly true. Hence, we
think that <code>df_error</code> is the most generic label for these degrees of
freedom.
</p>


<h3>Confidence intervals and approximation of degrees of freedom</h3>

<p>There are different ways of approximating the degrees of freedom depending
on different assumptions about the nature of the model and its sampling
distribution. The <code>ci_method</code> argument modulates the method for computing degrees
of freedom (df) that are used to calculate confidence intervals (CI) and the
related p-values. Following options are allowed, depending on the model
class:
</p>
<p><strong>Classical methods:</strong>
</p>
<p>Classical inference is generally based on the <strong>Wald method</strong>.
The Wald approach to inference computes a test statistic by dividing the
parameter estimate by its standard error (Coefficient / SE),
then comparing this statistic against a t- or normal distribution.
This approach can be used to compute CIs and p-values.
</p>
<p><code>"wald"</code>:
</p>

<ul>
<li><p> Applies to <em>non-Bayesian models</em>. For <em>linear models</em>, CIs
computed using the Wald method (SE and a <em>t-distribution with residual df</em>);
p-values computed using the Wald method with a <em>t-distribution with residual df</em>.
For other models, CIs computed using the Wald method (SE and a <em>normal distribution</em>);
p-values computed using the Wald method with a <em>normal distribution</em>.
</p>
</li></ul>

<p><code>"normal"</code>
</p>

<ul>
<li><p> Applies to <em>non-Bayesian models</em>. Compute Wald CIs and p-values,
but always use a normal distribution.
</p>
</li></ul>

<p><code>"residual"</code>
</p>

<ul>
<li><p> Applies to <em>non-Bayesian models</em>. Compute Wald CIs and p-values,
but always use a <em>t-distribution with residual df</em> when possible. If the
residual df for a model cannot be determined, a normal distribution is
used instead.
</p>
</li></ul>

<p><strong>Methods for mixed models:</strong>
</p>
<p>Compared to fixed effects (or single-level) models, determining appropriate
df for Wald-based inference in mixed models is more difficult.
See <a href="https://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#what-are-the-p-values-listed-by-summaryglmerfit-etc.-are-they-reliable">the R GLMM FAQ</a>
for a discussion.
</p>
<p>Several approximate methods for computing df are available, but you should
also consider instead using profile likelihood (<code>"profile"</code>) or bootstrap (&quot;<code style="white-space: pre;">&#8288;boot"&#8288;</code>)
CIs and p-values instead.
</p>
<p><code>"satterthwaite"</code>
</p>

<ul>
<li><p> Applies to <em>linear mixed models</em>. CIs computed using the
Wald method (SE and a <em>t-distribution with Satterthwaite df</em>); p-values
computed using the Wald method with a <em>t-distribution with Satterthwaite df</em>.
</p>
</li></ul>

<p><code>"kenward"</code>
</p>

<ul>
<li><p> Applies to <em>linear mixed models</em>. CIs computed using the Wald
method (<em>Kenward-Roger SE</em> and a <em>t-distribution with Kenward-Roger df</em>);
p-values computed using the Wald method with <em>Kenward-Roger SE and t-distribution with Kenward-Roger df</em>.
</p>
</li></ul>

<p><code>"ml1"</code>
</p>

<ul>
<li><p> Applies to <em>linear mixed models</em>. CIs computed using the Wald
method (SE and a <em>t-distribution with m-l-1 approximated df</em>); p-values
computed using the Wald method with a <em>t-distribution with m-l-1 approximated df</em>.
See <code><a href="#topic+ci_ml1">ci_ml1()</a></code>.
</p>
</li></ul>

<p><code>"betwithin"</code>
</p>

<ul>
<li><p> Applies to <em>linear mixed models</em> and <em>generalized linear mixed models</em>.
CIs computed using the Wald method (SE and a <em>t-distribution with between-within df</em>);
p-values computed using the Wald method with a <em>t-distribution with between-within df</em>.
See <code><a href="#topic+ci_betwithin">ci_betwithin()</a></code>.
</p>
</li></ul>

<p><strong>Likelihood-based methods:</strong>
</p>
<p>Likelihood-based inference is based on comparing the likelihood for the
maximum-likelihood estimate to the the likelihood for models with one or more
parameter values changed (e.g., set to zero or a range of alternative values).
Likelihood ratios for the maximum-likelihood and alternative models are compared
to a <code class="reqn">\chi</code>-squared distribution to compute CIs and p-values.
</p>
<p><code>"profile"</code>
</p>

<ul>
<li><p> Applies to <em>non-Bayesian models</em> of class <code>glm</code>, <code>polr</code>, <code>merMod</code> or <code>glmmTMB</code>.
CIs computed by <em>profiling the likelihood curve for a parameter</em>, using
linear interpolation to find where likelihood ratio equals a critical value;
p-values computed using the Wald method with a <em>normal-distribution</em> (note:
this might change in a future update!)
</p>
</li></ul>

<p><code>"uniroot"</code>
</p>

<ul>
<li><p> Applies to <em>non-Bayesian models</em> of class <code>glmmTMB</code>. CIs
computed by <em>profiling the likelihood curve for a parameter</em>, using root
finding to find where likelihood ratio equals a critical value; p-values
computed using the Wald method with a <em>normal-distribution</em> (note: this
might change in a future update!)
</p>
</li></ul>

<p><strong>Methods for bootstrapped or Bayesian models:</strong>
</p>
<p>Bootstrap-based inference is based on <strong>resampling</strong> and refitting the model
to the resampled datasets. The distribution of parameter estimates across
resampled datasets is used to approximate the parameter's sampling
distribution. Depending on the type of model, several different methods for
bootstrapping and constructing CIs and p-values from the bootstrap
distribution are available.
</p>
<p>For Bayesian models, inference is based on drawing samples from the model
posterior distribution.
</p>
<p><code>"quantile"</code> (or <code>"eti"</code>)
</p>

<ul>
<li><p> Applies to <em>all models (including Bayesian models)</em>.
For non-Bayesian models, only applies if <code>bootstrap = TRUE</code>. CIs computed
as <em>equal tailed intervals</em> using the quantiles of the bootstrap or
posterior samples; p-values are based on the <em>probability of direction</em>.
See <code><a href="bayestestR.html#topic+eti">bayestestR::eti()</a></code>.
</p>
</li></ul>

<p><code>"hdi"</code>
</p>

<ul>
<li><p> Applies to <em>all models (including Bayesian models)</em>. For non-Bayesian
models, only applies if <code>bootstrap = TRUE</code>. CIs computed as <em>highest density intervals</em>
for the bootstrap or posterior samples; p-values are based on the <em>probability of direction</em>.
See <code><a href="bayestestR.html#topic+hdi">bayestestR::hdi()</a></code>.
</p>
</li></ul>

<p><code>"bci"</code> (or <code>"bcai"</code>)
</p>

<ul>
<li><p> Applies to <em>all models (including Bayesian models)</em>.
For non-Bayesian models, only applies if <code>bootstrap = TRUE</code>. CIs computed
as <em>bias corrected and accelerated intervals</em> for the bootstrap or
posterior samples; p-values are based on the <em>probability of direction</em>.
See <code><a href="bayestestR.html#topic+bci">bayestestR::bci()</a></code>.
</p>
</li></ul>

<p><code>"si"</code>
</p>

<ul>
<li><p> Applies to <em>Bayesian models</em> with proper priors. CIs computed as
<em>support intervals</em> comparing the posterior samples against the prior samples;
p-values are based on the <em>probability of direction</em>. See <code><a href="bayestestR.html#topic+si">bayestestR::si()</a></code>.
</p>
</li></ul>

<p><code>"boot"</code>
</p>

<ul>
<li><p> Applies to <em>non-Bayesian models</em> of class <code>merMod</code>. CIs computed
using <em>parametric bootstrapping</em> (simulating data from the fitted model);
p-values computed using the Wald method with a <em>normal-distribution)</em>
(note: this might change in a future update!).
</p>
</li></ul>

<p>For all iteration-based methods other than <code>"boot"</code>
(<code>"hdi"</code>, <code>"quantile"</code>, <code>"ci"</code>, <code>"eti"</code>, <code>"si"</code>, <code>"bci"</code>, <code>"bcai"</code>),
p-values are based on the probability of direction (<code><a href="bayestestR.html#topic+p_direction">bayestestR::p_direction()</a></code>),
which is converted into a p-value using <code><a href="bayestestR.html#topic+pd_to_p">bayestestR::pd_to_p()</a></code>.
</p>


<h3>Interpretation of Interaction Terms</h3>

<p>Note that the <em>interpretation</em> of interaction terms depends on many
characteristics of the model. The number of parameters, and overall
performance of the model, can differ <em>or not</em> between <code>a * b</code>
<code>a : b</code>, and <code>a / b</code>, suggesting that sometimes interaction terms
give different parameterizations of the same model, but other times it gives
completely different models (depending on <code>a</code> or <code>b</code> being factors
of covariates, included as main effects or not, etc.). Their interpretation
depends of the full context of the model, which should not be inferred
from the parameters table alone - rather, we recommend to use packages
that calculate estimated marginal means or marginal effects, such as
<a href="https://CRAN.R-project.org/package=modelbased"><span class="pkg">modelbased</span></a>, <a href="https://CRAN.R-project.org/package=emmeans"><span class="pkg">emmeans</span></a>, <a href="https://CRAN.R-project.org/package=ggeffects"><span class="pkg">ggeffects</span></a>, or
<a href="https://CRAN.R-project.org/package=marginaleffects"><span class="pkg">marginaleffects</span></a>. To raise awareness for this issue, you may use
<code>print(...,show_formula=TRUE)</code> to add the model-specification to the output
of the <code><a href="#topic+print.parameters_model">print()</a></code> method for <code>model_parameters()</code>.
</p>


<h3>Global Options to Customize Messages and Tables when Printing</h3>

<p>The <code>verbose</code> argument can be used to display or silence messages and
warnings for the different functions in the <strong>parameters</strong> package. However,
some messages providing additional information can be displayed or suppressed
using <code>options()</code>:
</p>

<ul>
<li> <p><code>parameters_summary</code>: <code>options(parameters_summary = TRUE)</code> will override the
<code>summary</code> argument in <code>model_parameters()</code> and always show the model summary
for non-mixed models.
</p>
</li>
<li> <p><code>parameters_mixed_summary</code>: <code>options(parameters_mixed_summary = TRUE)</code> will
override the <code>summary</code> argument in <code>model_parameters()</code> for mixed models, and
will then always show the model summary.
</p>
</li>
<li> <p><code>parameters_cimethod</code>: <code>options(parameters_cimethod = TRUE)</code> will show the
additional information about the approximation method used to calculate
confidence intervals and p-values. Set to <code>FALSE</code> to hide this message when
printing <code>model_parameters()</code> objects.
</p>
</li>
<li> <p><code>parameters_exponentiate</code>: <code>options(parameters_exponentiate = TRUE)</code> will
show the additional information on how to interpret coefficients of models
with log-transformed response variables or with log-/logit-links when the
<code>exponentiate</code> argument in <code>model_parameters()</code> is not <code>TRUE</code>. Set this option
to <code>FALSE</code> to hide this message when printing <code>model_parameters()</code> objects.
</p>
</li></ul>

<p>There are further options that can be used to modify the default behaviour
for printed outputs:
</p>

<ul>
<li> <p><code>parameters_labels</code>: <code>options(parameters_labels = TRUE)</code> will use variable
and value labels for pretty names, if data is labelled. If no labels
available, default pretty names are used.
</p>
</li>
<li> <p><code>parameters_interaction</code>: <code style="white-space: pre;">&#8288;options(parameters_interaction = &lt;character&gt;)&#8288;</code>
will replace the interaction mark (by default, <code>*</code>) with the related character.
</p>
</li>
<li> <p><code>parameters_select</code>: <code style="white-space: pre;">&#8288;options(parameters_select = &lt;value&gt;)&#8288;</code> will set the
default for the <code>select</code> argument. See argument's documentation for available
options.
</p>
</li>
<li> <p><code>easystats_html_engine</code>: <code>options(easystats_html_engine = "gt")</code> will set
the default HTML engine for tables to <code>gt</code>, i.e. the <em>gt</em> package is used to
create HTML tables. If set to <code>tt</code>, the <em>tinytable</em> package is used.
</p>
</li></ul>



<h3>Note</h3>

<p>The <code><a href="#topic+print.parameters_model">print()</a></code> method has several
arguments to tweak the output. There is also a
<a href="https://easystats.github.io/see/articles/parameters.html"><code>plot()</code>-method</a>
implemented in the
<a href="https://easystats.github.io/see/"><strong>see</strong>-package</a>, and a dedicated
method for use inside rmarkdown files,
<code><a href="#topic+print_md.parameters_model">print_md()</a></code>. <br /> <br /> <strong>For developers</strong>, if
speed performance is an issue, you can use the (undocumented) <code>pretty_names</code>
argument, e.g. <code>model_parameters(..., pretty_names = FALSE)</code>. This will
skip the formatting of the coefficient names and make <code>model_parameters()</code>
faster.
</p>


<h3>References</h3>


<ul>
<li><p> Hoffman, L. (2015). Longitudinal analysis: Modeling within-person
fluctuation and change. Routledge.
</p>
</li>
<li><p> Neter, J., Wasserman, W., &amp; Kutner, M. H. (1989). Applied linear
regression models.
</p>
</li>
<li><p> Rafi Z, Greenland S. Semantic and cognitive tools to aid statistical
science: replace confidence and significance by compatibility and surprise.
BMC Medical Research Methodology (2020) 20:244.
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="insight.html#topic+standardize_names">insight::standardize_names()</a></code> to
rename columns into a consistent, standardized naming scheme.
</p>

<hr>
<h2 id='model_parameters.aov'>Parameters from ANOVAs</h2><span id='topic+model_parameters.aov'></span><span id='topic+model_parameters.afex_aov'></span>

<h3>Description</h3>

<p>Parameters from ANOVAs
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'aov'
model_parameters(
  model,
  type = NULL,
  df_error = NULL,
  ci = NULL,
  alternative = NULL,
  test = NULL,
  power = FALSE,
  effectsize_type = NULL,
  keep = NULL,
  drop = NULL,
  table_wide = FALSE,
  verbose = TRUE,
  omega_squared = NULL,
  eta_squared = NULL,
  epsilon_squared = NULL,
  ...
)

## S3 method for class 'afex_aov'
model_parameters(
  model,
  effectsize_type = NULL,
  df_error = NULL,
  type = NULL,
  keep = NULL,
  drop = NULL,
  verbose = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="model_parameters.aov_+3A_model">model</code></td>
<td>
<p>Object of class <code><a href="stats.html#topic+aov">aov()</a></code>, <code><a href="stats.html#topic+anova">anova()</a></code>,
<code>aovlist</code>, <code>Gam</code>, <code><a href="stats.html#topic+manova">manova()</a></code>, <code>Anova.mlm</code>,
<code>afex_aov</code> or <code>maov</code>.</p>
</td></tr>
<tr><td><code id="model_parameters.aov_+3A_type">type</code></td>
<td>
<p>Numeric, type of sums of squares. May be 1, 2 or 3. If 2 or 3,
ANOVA-tables using <code>car::Anova()</code> will be returned. (Ignored for
<code>afex_aov</code>.)</p>
</td></tr>
<tr><td><code id="model_parameters.aov_+3A_df_error">df_error</code></td>
<td>
<p>Denominator degrees of freedom (or degrees of freedom of the
error estimate, i.e., the residuals). This is used to compute effect sizes
for ANOVA-tables from mixed models. See 'Examples'. (Ignored for
<code>afex_aov</code>.)</p>
</td></tr>
<tr><td><code id="model_parameters.aov_+3A_ci">ci</code></td>
<td>
<p>Confidence Interval (CI) level for effect sizes specified in
<code>effectsize_type</code>. The default, <code>NULL</code>, will compute no confidence
intervals. <code>ci</code> should be a scalar between 0 and 1.</p>
</td></tr>
<tr><td><code id="model_parameters.aov_+3A_alternative">alternative</code></td>
<td>
<p>A character string specifying the alternative hypothesis;
Controls the type of CI returned: <code>"two.sided"</code> (default, two-sided CI),
<code>"greater"</code> or <code>"less"</code> (one-sided CI). Partial matching is allowed
(e.g., <code>"g"</code>, <code>"l"</code>, <code>"two"</code>...). See section <em>One-Sided CIs</em> in
the <a href="https://easystats.github.io/effectsize/">effectsize_CIs vignette</a>.</p>
</td></tr>
<tr><td><code id="model_parameters.aov_+3A_test">test</code></td>
<td>
<p>String, indicating the type of test for <code>Anova.mlm</code> to be
returned. If <code>"multivariate"</code> (or <code>NULL</code>), returns the summary of
the multivariate test (that is also given by the <code>print</code>-method). If
<code>test = "univariate"</code>, returns the summary of the univariate test.</p>
</td></tr>
<tr><td><code id="model_parameters.aov_+3A_power">power</code></td>
<td>
<p>Logical, if <code>TRUE</code>, adds a column with power for each
parameter.</p>
</td></tr>
<tr><td><code id="model_parameters.aov_+3A_effectsize_type">effectsize_type</code></td>
<td>
<p>The effect size of interest. Not that possibly not all
effect sizes are applicable to the model object. See 'Details'. For Anova
models, can also be a character vector with multiple effect size names.</p>
</td></tr>
<tr><td><code id="model_parameters.aov_+3A_keep">keep</code></td>
<td>
<p>Character containing a regular expression pattern that
describes the parameters that should be included (for <code>keep</code>) or excluded
(for <code>drop</code>) in the returned data frame. <code>keep</code> may also be a
named list of regular expressions. All non-matching parameters will be
removed from the output. If <code>keep</code> is a character vector, every parameter
name in the <em>&quot;Parameter&quot;</em> column that matches the regular expression in
<code>keep</code> will be selected from the returned data frame (and vice versa,
all parameter names matching <code>drop</code> will be excluded). Furthermore, if
<code>keep</code> has more than one element, these will be merged with an <code>OR</code>
operator into a regular expression pattern like this: <code>"(one|two|three)"</code>.
If <code>keep</code> is a named list of regular expression patterns, the names of the
list-element should equal the column name where selection should be
applied. This is useful for model objects where <code>model_parameters()</code>
returns multiple columns with parameter components, like in
<code><a href="#topic+model_parameters.lavaan">model_parameters.lavaan()</a></code>. Note that the regular expression pattern
should match the parameter names as they are stored in the returned data
frame, which can be different from how they are printed. Inspect the
<code style="white-space: pre;">&#8288;$Parameter&#8288;</code> column of the parameters table to get the exact parameter
names.</p>
</td></tr>
<tr><td><code id="model_parameters.aov_+3A_drop">drop</code></td>
<td>
<p>See <code>keep</code>.</p>
</td></tr>
<tr><td><code id="model_parameters.aov_+3A_table_wide">table_wide</code></td>
<td>
<p>Logical that decides whether the ANOVA table should be in
wide format, i.e. should the numerator and denominator degrees of freedom
be in the same row. Default: <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="model_parameters.aov_+3A_verbose">verbose</code></td>
<td>
<p>Toggle warnings and messages.</p>
</td></tr>
<tr><td><code id="model_parameters.aov_+3A_omega_squared">omega_squared</code>, <code id="model_parameters.aov_+3A_eta_squared">eta_squared</code>, <code id="model_parameters.aov_+3A_epsilon_squared">epsilon_squared</code></td>
<td>
<p>Deprecated. Please use <code>effectsize_type</code>.</p>
</td></tr>
<tr><td><code id="model_parameters.aov_+3A_...">...</code></td>
<td>
<p>Arguments passed to <code><a href="effectsize.html#topic+effectsize">effectsize::effectsize()</a></code>. For example,
to calculate <em>partial</em> effect sizes types, use <code>partial = TRUE</code>. For objects
of class <code>htest</code> or <code>BFBayesFactor</code>, <code>adjust = TRUE</code> can be used to return
bias-corrected effect sizes, which is advisable for small samples and large
tables. See also
<a href="https://easystats.github.io/effectsize/reference/eta_squared.html"><code>?effectsize::eta_squared</code></a>
for arguments <code>partial</code> and <code>generalized</code>;
<a href="https://easystats.github.io/effectsize/reference/phi.html"><code>?effectsize::phi</code></a>
for <code>adjust</code>; and
<a href="https://easystats.github.io/effectsize/reference/oddsratio.html"><code>?effectsize::oddratio</code></a>
for <code>log</code>.</p>
</td></tr>
</table>


<h3>Details</h3>


<ul>
<li><p> For an object of class <code>htest</code>, data is extracted via <code><a href="insight.html#topic+get_data">insight::get_data()</a></code>, and passed to the relevant function according to:
</p>

<ul>
<li><p> A <strong>t-test</strong> depending on <code>type</code>: <code>"cohens_d"</code> (default), <code>"hedges_g"</code>, or one of <code>"p_superiority"</code>, <code>"u1"</code>, <code>"u2"</code>, <code>"u3"</code>, <code>"overlap"</code>.
</p>

<ul>
<li><p> For a <strong>Paired t-test</strong>: depending on <code>type</code>: <code>"rm_rm"</code>, <code>"rm_av"</code>, <code>"rm_b"</code>, <code>"rm_d"</code>, <code>"rm_z"</code>.
</p>
</li></ul>

</li>
<li><p> A <strong>Chi-squared tests of independence</strong> or <strong>Fisher's Exact Test</strong>, depending on <code>type</code>: <code>"cramers_v"</code> (default), <code>"tschuprows_t"</code>, <code>"phi"</code>, <code>"cohens_w"</code>, <code>"pearsons_c"</code>, <code>"cohens_h"</code>, <code>"oddsratio"</code>, <code>"riskratio"</code>, <code>"arr"</code>, or <code>"nnt"</code>.
</p>
</li>
<li><p> A <strong>Chi-squared tests of goodness-of-fit</strong>, depending on <code>type</code>: <code>"fei"</code> (default) <code>"cohens_w"</code>, <code>"pearsons_c"</code>
</p>
</li>
<li><p> A <strong>One-way ANOVA test</strong>, depending on <code>type</code>: <code>"eta"</code> (default), <code>"omega"</code> or <code>"epsilon"</code> -squared, <code>"f"</code>, or <code>"f2"</code>.
</p>
</li>
<li><p> A <strong>McNemar test</strong> returns <em>Cohen's g</em>.
</p>
</li>
<li><p> A <strong>Wilcoxon test</strong> depending on <code>type</code>: returns &quot;<code>rank_biserial</code>&quot; correlation (default) or one of <code>"p_superiority"</code>, <code>"vda"</code>, <code>"u2"</code>, <code>"u3"</code>, <code>"overlap"</code>.
</p>
</li>
<li><p> A <strong>Kruskal-Wallis test</strong> depending on <code>type</code>: <code>"epsilon"</code> (default) or <code>"eta"</code>.
</p>
</li>
<li><p> A <strong>Friedman test</strong> returns <em>Kendall's W</em>.
(Where applicable, <code>ci</code> and <code>alternative</code> are taken from the <code>htest</code> if not otherwise provided.)
</p>
</li></ul>

</li>
<li><p> For an object of class <code>BFBayesFactor</code>, using <code><a href="bayestestR.html#topic+describe_posterior">bayestestR::describe_posterior()</a></code>,
</p>

<ul>
<li><p> A <strong>t-test</strong> depending on <code>type</code>: <code>"cohens_d"</code> (default) or one of <code>"p_superiority"</code>, <code>"u1"</code>, <code>"u2"</code>, <code>"u3"</code>, <code>"overlap"</code>.
</p>
</li>
<li><p> A <strong>correlation test</strong> returns <em>r</em>.
</p>
</li>
<li><p> A <strong>contingency table test</strong>, depending on <code>type</code>: <code>"cramers_v"</code> (default), <code>"phi"</code>, <code>"tschuprows_t"</code>, <code>"cohens_w"</code>, <code>"pearsons_c"</code>, <code>"cohens_h"</code>, <code>"oddsratio"</code>, or <code>"riskratio"</code>, <code>"arr"</code>, or <code>"nnt"</code>.
</p>
</li>
<li><p> A <strong>proportion test</strong> returns <em>p</em>.
</p>
</li></ul>

</li>
<li><p> Objects of class <code>anova</code>, <code>aov</code>, <code>aovlist</code> or <code>afex_aov</code>, depending on <code>type</code>: <code>"eta"</code> (default), <code>"omega"</code> or <code>"epsilon"</code> -squared, <code>"f"</code>, or <code>"f2"</code>.
</p>
</li>
<li><p> Other objects are passed to <code><a href="#topic+standardize_parameters">parameters::standardize_parameters()</a></code>.
</p>
</li></ul>

<p><strong>For statistical models it is recommended to directly use the listed
functions, for the full range of options they provide.</strong>
</p>


<h3>Value</h3>

<p>A data frame of indices related to the model's parameters.
</p>


<h3>Note</h3>

<p>For ANOVA-tables from mixed models (i.e. <code>anova(lmer())</code>), only
partial or adjusted effect sizes can be computed. Note that type 3 ANOVAs
with interactions involved only give sensible and informative results when
covariates are mean-centred and factors are coded with orthogonal contrasts
(such as those produced by <code>contr.sum</code>, <code>contr.poly</code>, or
<code>contr.helmert</code>, but <em>not</em> by the default <code>contr.treatment</code>).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
df &lt;- iris
df$Sepal.Big &lt;- ifelse(df$Sepal.Width &gt;= 3, "Yes", "No")

model &lt;- aov(Sepal.Length ~ Sepal.Big, data = df)
model_parameters(model)

model_parameters(model, effectsize_type = c("omega", "eta"), ci = 0.9)

model &lt;- anova(lm(Sepal.Length ~ Sepal.Big, data = df))
model_parameters(model)
model_parameters(
  model,
  effectsize_type = c("omega", "eta", "epsilon"),
  alternative = "greater"
)

model &lt;- aov(Sepal.Length ~ Sepal.Big + Error(Species), data = df)
model_parameters(model)



df &lt;- iris
df$Sepal.Big &lt;- ifelse(df$Sepal.Width &gt;= 3, "Yes", "No")
mm &lt;- lme4::lmer(Sepal.Length ~ Sepal.Big + Petal.Width + (1 | Species), data = df)
model &lt;- anova(mm)

# simple parameters table
model_parameters(model)

# parameters table including effect sizes
model_parameters(
  model,
  effectsize_type = "eta",
  ci = 0.9,
  df_error = dof_satterthwaite(mm)[2:3]
)


</code></pre>

<hr>
<h2 id='model_parameters.befa'>Parameters from Bayesian Exploratory Factor Analysis</h2><span id='topic+model_parameters.befa'></span>

<h3>Description</h3>

<p>Format Bayesian Exploratory Factor Analysis objects from the BayesFM package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'befa'
model_parameters(
  model,
  sort = FALSE,
  centrality = "median",
  dispersion = FALSE,
  ci = 0.95,
  ci_method = "eti",
  test = NULL,
  verbose = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="model_parameters.befa_+3A_model">model</code></td>
<td>
<p>Bayesian EFA created by the <code>BayesFM::befa</code>.</p>
</td></tr>
<tr><td><code id="model_parameters.befa_+3A_sort">sort</code></td>
<td>
<p>Sort the loadings.</p>
</td></tr>
<tr><td><code id="model_parameters.befa_+3A_centrality">centrality</code></td>
<td>
<p>The point-estimates (centrality indices) to compute. Character
(vector) or list with one or more of these options: <code>"median"</code>, <code>"mean"</code>, <code>"MAP"</code>
(see <code><a href="bayestestR.html#topic+map_estimate">map_estimate()</a></code>), <code>"trimmed"</code> (which is just <code>mean(x, trim = threshold)</code>),
<code>"mode"</code> or <code>"all"</code>.</p>
</td></tr>
<tr><td><code id="model_parameters.befa_+3A_dispersion">dispersion</code></td>
<td>
<p>Logical, if <code>TRUE</code>, computes indices of dispersion related
to the estimate(s) (<code>SD</code> and <code>MAD</code> for <code>mean</code> and <code>median</code>, respectively).
Dispersion is not available for <code>"MAP"</code> or <code>"mode"</code> centrality indices.</p>
</td></tr>
<tr><td><code id="model_parameters.befa_+3A_ci">ci</code></td>
<td>
<p>Value or vector of probability of the CI (between 0 and 1)
to be estimated. Default to <code>0.95</code> (<code style="white-space: pre;">&#8288;95%&#8288;</code>).</p>
</td></tr>
<tr><td><code id="model_parameters.befa_+3A_ci_method">ci_method</code></td>
<td>
<p>The type of index used for Credible Interval. Can be
<code>"ETI"</code> (default, see <code><a href="bayestestR.html#topic+eti">eti()</a></code>), <code>"HDI"</code>
(see <code><a href="bayestestR.html#topic+hdi">hdi()</a></code>), <code>"BCI"</code> (see
<code><a href="bayestestR.html#topic+bci">bci()</a></code>), <code>"SPI"</code> (see <code><a href="bayestestR.html#topic+spi">spi()</a></code>), or
<code>"SI"</code> (see <code><a href="bayestestR.html#topic+si">si()</a></code>).</p>
</td></tr>
<tr><td><code id="model_parameters.befa_+3A_test">test</code></td>
<td>
<p>The indices of effect existence to compute. Character (vector) or
list with one or more of these options: <code>"p_direction"</code> (or <code>"pd"</code>),
<code>"rope"</code>, <code>"p_map"</code>, <code>"equivalence_test"</code> (or <code>"equitest"</code>),
<code>"bayesfactor"</code> (or <code>"bf"</code>) or <code>"all"</code> to compute all tests.
For each &quot;test&quot;, the corresponding <span class="pkg">bayestestR</span> function is called
(e.g. <code><a href="bayestestR.html#topic+rope">rope()</a></code> or <code><a href="bayestestR.html#topic+p_direction">p_direction()</a></code>) and its results
included in the summary output.</p>
</td></tr>
<tr><td><code id="model_parameters.befa_+3A_verbose">verbose</code></td>
<td>
<p>Toggle warnings.</p>
</td></tr>
<tr><td><code id="model_parameters.befa_+3A_...">...</code></td>
<td>
<p>Arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame of loadings.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(parameters)

if (require("BayesFM")) {
  efa &lt;- BayesFM::befa(mtcars, iter = 1000)
  results &lt;- model_parameters(efa, sort = TRUE, verbose = FALSE)
  results
  efa_to_cfa(results, verbose = FALSE)
}

</code></pre>

<hr>
<h2 id='model_parameters.BFBayesFactor'>Parameters from BayesFactor objects</h2><span id='topic+model_parameters.BFBayesFactor'></span>

<h3>Description</h3>

<p>Parameters from <code>BFBayesFactor</code> objects from <code>{BayesFactor}</code> package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'BFBayesFactor'
model_parameters(
  model,
  centrality = "median",
  dispersion = FALSE,
  ci = 0.95,
  ci_method = "eti",
  test = "pd",
  rope_range = "default",
  rope_ci = 0.95,
  priors = TRUE,
  effectsize_type = NULL,
  include_proportions = FALSE,
  verbose = TRUE,
  cohens_d = NULL,
  cramers_v = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="model_parameters.BFBayesFactor_+3A_model">model</code></td>
<td>
<p>Object of class <code>BFBayesFactor</code>.</p>
</td></tr>
<tr><td><code id="model_parameters.BFBayesFactor_+3A_centrality">centrality</code></td>
<td>
<p>The point-estimates (centrality indices) to compute. Character
(vector) or list with one or more of these options: <code>"median"</code>, <code>"mean"</code>, <code>"MAP"</code>
(see <code><a href="bayestestR.html#topic+map_estimate">map_estimate()</a></code>), <code>"trimmed"</code> (which is just <code>mean(x, trim = threshold)</code>),
<code>"mode"</code> or <code>"all"</code>.</p>
</td></tr>
<tr><td><code id="model_parameters.BFBayesFactor_+3A_dispersion">dispersion</code></td>
<td>
<p>Logical, if <code>TRUE</code>, computes indices of dispersion related
to the estimate(s) (<code>SD</code> and <code>MAD</code> for <code>mean</code> and <code>median</code>, respectively).
Dispersion is not available for <code>"MAP"</code> or <code>"mode"</code> centrality indices.</p>
</td></tr>
<tr><td><code id="model_parameters.BFBayesFactor_+3A_ci">ci</code></td>
<td>
<p>Value or vector of probability of the CI (between 0 and 1)
to be estimated. Default to <code>0.95</code> (<code style="white-space: pre;">&#8288;95%&#8288;</code>).</p>
</td></tr>
<tr><td><code id="model_parameters.BFBayesFactor_+3A_ci_method">ci_method</code></td>
<td>
<p>The type of index used for Credible Interval. Can be
<code>"ETI"</code> (default, see <code><a href="bayestestR.html#topic+eti">eti()</a></code>), <code>"HDI"</code>
(see <code><a href="bayestestR.html#topic+hdi">hdi()</a></code>), <code>"BCI"</code> (see
<code><a href="bayestestR.html#topic+bci">bci()</a></code>), <code>"SPI"</code> (see <code><a href="bayestestR.html#topic+spi">spi()</a></code>), or
<code>"SI"</code> (see <code><a href="bayestestR.html#topic+si">si()</a></code>).</p>
</td></tr>
<tr><td><code id="model_parameters.BFBayesFactor_+3A_test">test</code></td>
<td>
<p>The indices of effect existence to compute. Character (vector) or
list with one or more of these options: <code>"p_direction"</code> (or <code>"pd"</code>),
<code>"rope"</code>, <code>"p_map"</code>, <code>"equivalence_test"</code> (or <code>"equitest"</code>),
<code>"bayesfactor"</code> (or <code>"bf"</code>) or <code>"all"</code> to compute all tests.
For each &quot;test&quot;, the corresponding <span class="pkg">bayestestR</span> function is called
(e.g. <code><a href="bayestestR.html#topic+rope">rope()</a></code> or <code><a href="bayestestR.html#topic+p_direction">p_direction()</a></code>) and its results
included in the summary output.</p>
</td></tr>
<tr><td><code id="model_parameters.BFBayesFactor_+3A_rope_range">rope_range</code></td>
<td>
<p>ROPE's lower and higher bounds. Should be a list of two
values (e.g., <code>c(-0.1, 0.1)</code>) or <code>"default"</code>. If <code>"default"</code>,
the bounds are set to <code>x +- 0.1*SD(response)</code>.</p>
</td></tr>
<tr><td><code id="model_parameters.BFBayesFactor_+3A_rope_ci">rope_ci</code></td>
<td>
<p>The Credible Interval (CI) probability, corresponding to the
proportion of HDI, to use for the percentage in ROPE.</p>
</td></tr>
<tr><td><code id="model_parameters.BFBayesFactor_+3A_priors">priors</code></td>
<td>
<p>Add the prior used for each parameter.</p>
</td></tr>
<tr><td><code id="model_parameters.BFBayesFactor_+3A_effectsize_type">effectsize_type</code></td>
<td>
<p>The effect size of interest. Not that possibly not all
effect sizes are applicable to the model object. See 'Details'. For Anova
models, can also be a character vector with multiple effect size names.</p>
</td></tr>
<tr><td><code id="model_parameters.BFBayesFactor_+3A_include_proportions">include_proportions</code></td>
<td>
<p>Logical that decides whether to include posterior
cell proportions/counts for Bayesian contingency table analysis (from
<code>BayesFactor::contingencyTableBF()</code>). Defaults to <code>FALSE</code>, as this
information is often redundant.</p>
</td></tr>
<tr><td><code id="model_parameters.BFBayesFactor_+3A_verbose">verbose</code></td>
<td>
<p>Toggle off warnings.</p>
</td></tr>
<tr><td><code id="model_parameters.BFBayesFactor_+3A_cohens_d">cohens_d</code>, <code id="model_parameters.BFBayesFactor_+3A_cramers_v">cramers_v</code></td>
<td>
<p>Deprecated. Please use <code>effectsize_type</code>.</p>
</td></tr>
<tr><td><code id="model_parameters.BFBayesFactor_+3A_...">...</code></td>
<td>
<p>Additional arguments to be passed to or from methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The meaning of the extracted parameters:
</p>

<ul>
<li><p> For <code><a href="BayesFactor.html#topic+ttestBF">BayesFactor::ttestBF()</a></code>: <code>Difference</code> is the raw difference between
the means.
</p>
</li>
<li><p> For <code><a href="BayesFactor.html#topic+correlationBF">BayesFactor::correlationBF()</a></code>: <code>rho</code> is the linear correlation
estimate (equivalent to Pearson's <em>r</em>).
</p>
</li>
<li><p> For <code><a href="BayesFactor.html#topic+lmBF">BayesFactor::lmBF()</a></code> / <code><a href="BayesFactor.html#topic+generalTestBF">BayesFactor::generalTestBF()</a></code>
/ <code><a href="BayesFactor.html#topic+regressionBF">BayesFactor::regressionBF()</a></code> / <code><a href="BayesFactor.html#topic+anovaBF">BayesFactor::anovaBF()</a></code>: in addition to
parameters of the fixed and random effects, there are: <code>mu</code> is the
(mean-centered) intercept; <code>sig2</code> is the model's sigma; <code>g</code> / <code style="white-space: pre;">&#8288;g_*&#8288;</code> are
the <em>g</em> parameters; See the <em>Bayes Factors for ANOVAs</em> paper
(<a href="https://doi.org/10.1016/j.jmp.2012.08.001">doi:10.1016/j.jmp.2012.08.001</a>).
</p>
</li></ul>



<h3>Value</h3>

<p>A data frame of indices related to the model's parameters.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
if (require("BayesFactor")) {
  # Bayesian t-test
  model &lt;- ttestBF(x = rnorm(100, 1, 1))
  model_parameters(model)
  model_parameters(model, cohens_d = TRUE, ci = .9)

  # Bayesian contingency table analysis
  data(raceDolls)
  bf &lt;- contingencyTableBF(raceDolls, sampleType = "indepMulti", fixedMargin = "cols")
  model_parameters(bf,
    centrality = "mean",
    dispersion = TRUE,
    verbose = FALSE,
    effectsize_type = "cramers_v"
  )
}

</code></pre>

<hr>
<h2 id='model_parameters.cgam'>Parameters from Generalized Additive (Mixed) Models</h2><span id='topic+model_parameters.cgam'></span><span id='topic+model_parameters.gamm'></span><span id='topic+model_parameters.Gam'></span><span id='topic+model_parameters.scam'></span>

<h3>Description</h3>

<p>Extract and compute indices and measures to describe parameters
of generalized additive models (GAM(M)s).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'cgam'
model_parameters(
  model,
  ci = 0.95,
  ci_method = "residual",
  bootstrap = FALSE,
  iterations = 1000,
  standardize = NULL,
  exponentiate = FALSE,
  p_adjust = NULL,
  keep = NULL,
  drop = NULL,
  verbose = TRUE,
  ...
)

## S3 method for class 'gamm'
model_parameters(
  model,
  ci = 0.95,
  bootstrap = FALSE,
  iterations = 1000,
  verbose = TRUE,
  ...
)

## S3 method for class 'Gam'
model_parameters(
  model,
  effectsize_type = NULL,
  df_error = NULL,
  type = NULL,
  table_wide = FALSE,
  verbose = TRUE,
  ...
)

## S3 method for class 'scam'
model_parameters(
  model,
  ci = 0.95,
  ci_method = "residual",
  bootstrap = FALSE,
  iterations = 1000,
  standardize = NULL,
  exponentiate = FALSE,
  p_adjust = NULL,
  keep = NULL,
  drop = NULL,
  verbose = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="model_parameters.cgam_+3A_model">model</code></td>
<td>
<p>A gam/gamm model.</p>
</td></tr>
<tr><td><code id="model_parameters.cgam_+3A_ci">ci</code></td>
<td>
<p>Confidence Interval (CI) level. Default to <code>0.95</code> (<code style="white-space: pre;">&#8288;95%&#8288;</code>).</p>
</td></tr>
<tr><td><code id="model_parameters.cgam_+3A_ci_method">ci_method</code></td>
<td>
<p>Method for computing degrees of freedom for
confidence intervals (CI) and the related p-values. Allowed are following
options (which vary depending on the model class): <code>"residual"</code>,
<code>"normal"</code>, <code>"likelihood"</code>, <code>"satterthwaite"</code>, <code>"kenward"</code>, <code>"wald"</code>,
<code>"profile"</code>, <code>"boot"</code>, <code>"uniroot"</code>, <code>"ml1"</code>, <code>"betwithin"</code>, <code>"hdi"</code>,
<code>"quantile"</code>, <code>"ci"</code>, <code>"eti"</code>, <code>"si"</code>, <code>"bci"</code>, or <code>"bcai"</code>. See section
<em>Confidence intervals and approximation of degrees of freedom</em> in
<code><a href="#topic+model_parameters">model_parameters()</a></code> for further details. When <code>ci_method=NULL</code>, in most
cases <code>"wald"</code> is used then.</p>
</td></tr>
<tr><td><code id="model_parameters.cgam_+3A_bootstrap">bootstrap</code></td>
<td>
<p>Should estimates be based on bootstrapped model? If
<code>TRUE</code>, then arguments of <a href="#topic+model_parameters.stanreg">Bayesian regressions</a> apply (see also
<code><a href="#topic+bootstrap_parameters">bootstrap_parameters()</a></code>).</p>
</td></tr>
<tr><td><code id="model_parameters.cgam_+3A_iterations">iterations</code></td>
<td>
<p>The number of bootstrap replicates. This only apply in the
case of bootstrapped frequentist models.</p>
</td></tr>
<tr><td><code id="model_parameters.cgam_+3A_standardize">standardize</code></td>
<td>
<p>The method used for standardizing the parameters. Can be
<code>NULL</code> (default; no standardization), <code>"refit"</code> (for re-fitting the model
on standardized data) or one of <code>"basic"</code>, <code>"posthoc"</code>, <code>"smart"</code>,
<code>"pseudo"</code>. See 'Details' in <code><a href="#topic+standardize_parameters">standardize_parameters()</a></code>.
<strong>Importantly</strong>:
</p>

<ul>
<li><p> The <code>"refit"</code> method does <em>not</em> standardize categorical predictors (i.e.
factors), which may be a different behaviour compared to other R packages
(such as <strong>lm.beta</strong>) or other software packages (like SPSS). to mimic
such behaviours, either use <code>standardize="basic"</code> or standardize the data
with <code>datawizard::standardize(force=TRUE)</code> <em>before</em> fitting the model.
</p>
</li>
<li><p> For mixed models, when using methods other than <code>"refit"</code>, only the fixed
effects will be standardized.
</p>
</li>
<li><p> Robust estimation (i.e., <code>vcov</code> set to a value other than <code>NULL</code>) of
standardized parameters only works when <code>standardize="refit"</code>.
</p>
</li></ul>
</td></tr>
<tr><td><code id="model_parameters.cgam_+3A_exponentiate">exponentiate</code></td>
<td>
<p>Logical, indicating whether or not to exponentiate the
coefficients (and related confidence intervals). This is typical for
logistic regression, or more generally speaking, for models with log or
logit links. It is also recommended to use <code>exponentiate = TRUE</code> for models
with log-transformed response values. <strong>Note:</strong> Delta-method standard
errors are also computed (by multiplying the standard errors by the
transformed coefficients). This is to mimic behaviour of other software
packages, such as Stata, but these standard errors poorly estimate
uncertainty for the transformed coefficient. The transformed confidence
interval more clearly captures this uncertainty. For <code>compare_parameters()</code>,
<code>exponentiate = "nongaussian"</code> will only exponentiate coefficients from
non-Gaussian families.</p>
</td></tr>
<tr><td><code id="model_parameters.cgam_+3A_p_adjust">p_adjust</code></td>
<td>
<p>Character vector, if not <code>NULL</code>, indicates the method to
adjust p-values. See <code><a href="stats.html#topic+p.adjust">stats::p.adjust()</a></code> for details. Further
possible adjustment methods are <code>"tukey"</code>, <code>"scheffe"</code>,
<code>"sidak"</code> and <code>"none"</code> to explicitly disable adjustment for
<code>emmGrid</code> objects (from <strong>emmeans</strong>).</p>
</td></tr>
<tr><td><code id="model_parameters.cgam_+3A_keep">keep</code></td>
<td>
<p>Character containing a regular expression pattern that
describes the parameters that should be included (for <code>keep</code>) or excluded
(for <code>drop</code>) in the returned data frame. <code>keep</code> may also be a
named list of regular expressions. All non-matching parameters will be
removed from the output. If <code>keep</code> is a character vector, every parameter
name in the <em>&quot;Parameter&quot;</em> column that matches the regular expression in
<code>keep</code> will be selected from the returned data frame (and vice versa,
all parameter names matching <code>drop</code> will be excluded). Furthermore, if
<code>keep</code> has more than one element, these will be merged with an <code>OR</code>
operator into a regular expression pattern like this: <code>"(one|two|three)"</code>.
If <code>keep</code> is a named list of regular expression patterns, the names of the
list-element should equal the column name where selection should be
applied. This is useful for model objects where <code>model_parameters()</code>
returns multiple columns with parameter components, like in
<code><a href="#topic+model_parameters.lavaan">model_parameters.lavaan()</a></code>. Note that the regular expression pattern
should match the parameter names as they are stored in the returned data
frame, which can be different from how they are printed. Inspect the
<code style="white-space: pre;">&#8288;$Parameter&#8288;</code> column of the parameters table to get the exact parameter
names.</p>
</td></tr>
<tr><td><code id="model_parameters.cgam_+3A_drop">drop</code></td>
<td>
<p>See <code>keep</code>.</p>
</td></tr>
<tr><td><code id="model_parameters.cgam_+3A_verbose">verbose</code></td>
<td>
<p>Toggle warnings and messages.</p>
</td></tr>
<tr><td><code id="model_parameters.cgam_+3A_...">...</code></td>
<td>
<p>Arguments passed to or from other methods. For instance, when
<code>bootstrap = TRUE</code>, arguments like <code>type</code> or <code>parallel</code> are
passed down to <code>bootstrap_model()</code>.</p>
</td></tr>
<tr><td><code id="model_parameters.cgam_+3A_effectsize_type">effectsize_type</code></td>
<td>
<p>The effect size of interest. Not that possibly not all
effect sizes are applicable to the model object. See 'Details'. For Anova
models, can also be a character vector with multiple effect size names.</p>
</td></tr>
<tr><td><code id="model_parameters.cgam_+3A_df_error">df_error</code></td>
<td>
<p>Denominator degrees of freedom (or degrees of freedom of the
error estimate, i.e., the residuals). This is used to compute effect sizes
for ANOVA-tables from mixed models. See 'Examples'. (Ignored for
<code>afex_aov</code>.)</p>
</td></tr>
<tr><td><code id="model_parameters.cgam_+3A_type">type</code></td>
<td>
<p>Numeric, type of sums of squares. May be 1, 2 or 3. If 2 or 3,
ANOVA-tables using <code>car::Anova()</code> will be returned. (Ignored for
<code>afex_aov</code>.)</p>
</td></tr>
<tr><td><code id="model_parameters.cgam_+3A_table_wide">table_wide</code></td>
<td>
<p>Logical that decides whether the ANOVA table should be in
wide format, i.e. should the numerator and denominator degrees of freedom
be in the same row. Default: <code>FALSE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The reporting of degrees of freedom <em>for the spline terms</em>
slightly differs from the output of <code>summary(model)</code>, for example in the
case of <code>mgcv::gam()</code>. The <em>estimated degrees of freedom</em>, column
<code>edf</code> in the summary-output, is named <code>df</code> in the returned data
frame, while the column <code>df_error</code> in the returned data frame refers to
the residual degrees of freedom that are returned by <code>df.residual()</code>.
Hence, the values in the the column <code>df_error</code> differ from the column
<code>Ref.df</code> from the summary, which is intentional, as these reference
degrees of freedom &ldquo;is not very interpretable&rdquo;
(<a href="https://stat.ethz.ch/pipermail/r-help/2019-March/462135.html">web</a>).
</p>


<h3>Value</h3>

<p>A data frame of indices related to the model's parameters.
</p>


<h3>See Also</h3>

<p><code><a href="insight.html#topic+standardize_names">insight::standardize_names()</a></code> to rename
columns into a consistent, standardized naming scheme.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(parameters)
if (require("mgcv")) {
  dat &lt;- gamSim(1, n = 400, dist = "normal", scale = 2)
  model &lt;- gam(y ~ s(x0) + s(x1) + s(x2) + s(x3), data = dat)
  model_parameters(model)
}
</code></pre>

<hr>
<h2 id='model_parameters.cpglmm'>Parameters from Mixed Models</h2><span id='topic+model_parameters.cpglmm'></span><span id='topic+model_parameters.glmmTMB'></span><span id='topic+model_parameters.merMod'></span><span id='topic+model_parameters.mixed'></span><span id='topic+model_parameters.MixMod'></span><span id='topic+model_parameters.lme'></span><span id='topic+model_parameters.clmm2'></span><span id='topic+model_parameters.clmm'></span>

<h3>Description</h3>

<p>Parameters from (linear) mixed models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'cpglmm'
model_parameters(
  model,
  ci = 0.95,
  ci_method = NULL,
  ci_random = NULL,
  bootstrap = FALSE,
  iterations = 1000,
  standardize = NULL,
  effects = "all",
  group_level = FALSE,
  exponentiate = FALSE,
  p_adjust = NULL,
  include_sigma = FALSE,
  keep = NULL,
  drop = NULL,
  verbose = TRUE,
  ...
)

## S3 method for class 'glmmTMB'
model_parameters(
  model,
  ci = 0.95,
  ci_method = "wald",
  ci_random = NULL,
  bootstrap = FALSE,
  iterations = 1000,
  standardize = NULL,
  effects = "all",
  component = "all",
  group_level = FALSE,
  exponentiate = FALSE,
  p_adjust = NULL,
  wb_component = TRUE,
  summary = getOption("parameters_mixed_summary", FALSE),
  keep = NULL,
  drop = NULL,
  verbose = TRUE,
  include_sigma = FALSE,
  ...
)

## S3 method for class 'merMod'
model_parameters(
  model,
  ci = 0.95,
  ci_method = NULL,
  ci_random = NULL,
  bootstrap = FALSE,
  iterations = 1000,
  standardize = NULL,
  effects = "all",
  group_level = FALSE,
  exponentiate = FALSE,
  p_adjust = NULL,
  wb_component = TRUE,
  summary = getOption("parameters_mixed_summary", FALSE),
  keep = NULL,
  drop = NULL,
  verbose = TRUE,
  include_sigma = FALSE,
  vcov = NULL,
  vcov_args = NULL,
  ...
)

## S3 method for class 'mixed'
model_parameters(
  model,
  ci = 0.95,
  ci_method = "wald",
  ci_random = NULL,
  bootstrap = FALSE,
  iterations = 1000,
  standardize = NULL,
  effects = "all",
  component = "all",
  group_level = FALSE,
  exponentiate = FALSE,
  p_adjust = NULL,
  wb_component = TRUE,
  summary = getOption("parameters_mixed_summary", FALSE),
  keep = NULL,
  drop = NULL,
  verbose = TRUE,
  include_sigma = FALSE,
  ...
)

## S3 method for class 'MixMod'
model_parameters(
  model,
  ci = 0.95,
  ci_method = "wald",
  ci_random = NULL,
  bootstrap = FALSE,
  iterations = 1000,
  standardize = NULL,
  effects = "all",
  component = "all",
  group_level = FALSE,
  exponentiate = FALSE,
  p_adjust = NULL,
  wb_component = TRUE,
  summary = getOption("parameters_mixed_summary", FALSE),
  keep = NULL,
  drop = NULL,
  verbose = TRUE,
  include_sigma = FALSE,
  ...
)

## S3 method for class 'lme'
model_parameters(
  model,
  ci = 0.95,
  ci_method = NULL,
  ci_random = NULL,
  bootstrap = FALSE,
  iterations = 1000,
  standardize = NULL,
  effects = "all",
  group_level = FALSE,
  exponentiate = FALSE,
  p_adjust = NULL,
  wb_component = TRUE,
  summary = getOption("parameters_mixed_summary", FALSE),
  keep = NULL,
  drop = NULL,
  verbose = TRUE,
  include_sigma = FALSE,
  vcov = NULL,
  vcov_args = NULL,
  ...
)

## S3 method for class 'clmm2'
model_parameters(
  model,
  ci = 0.95,
  bootstrap = FALSE,
  iterations = 1000,
  component = c("all", "conditional", "scale"),
  standardize = NULL,
  exponentiate = FALSE,
  p_adjust = NULL,
  summary = getOption("parameters_summary", FALSE),
  keep = NULL,
  drop = NULL,
  verbose = TRUE,
  ...
)

## S3 method for class 'clmm'
model_parameters(
  model,
  ci = 0.95,
  ci_method = NULL,
  ci_random = NULL,
  bootstrap = FALSE,
  iterations = 1000,
  standardize = NULL,
  effects = "all",
  group_level = FALSE,
  exponentiate = FALSE,
  p_adjust = NULL,
  include_sigma = FALSE,
  keep = NULL,
  drop = NULL,
  verbose = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="model_parameters.cpglmm_+3A_model">model</code></td>
<td>
<p>A mixed model.</p>
</td></tr>
<tr><td><code id="model_parameters.cpglmm_+3A_ci">ci</code></td>
<td>
<p>Confidence Interval (CI) level. Default to <code>0.95</code> (<code style="white-space: pre;">&#8288;95%&#8288;</code>).</p>
</td></tr>
<tr><td><code id="model_parameters.cpglmm_+3A_ci_method">ci_method</code></td>
<td>
<p>Method for computing degrees of freedom for
confidence intervals (CI) and the related p-values. Allowed are following
options (which vary depending on the model class): <code>"residual"</code>,
<code>"normal"</code>, <code>"likelihood"</code>, <code>"satterthwaite"</code>, <code>"kenward"</code>, <code>"wald"</code>,
<code>"profile"</code>, <code>"boot"</code>, <code>"uniroot"</code>, <code>"ml1"</code>, <code>"betwithin"</code>, <code>"hdi"</code>,
<code>"quantile"</code>, <code>"ci"</code>, <code>"eti"</code>, <code>"si"</code>, <code>"bci"</code>, or <code>"bcai"</code>. See section
<em>Confidence intervals and approximation of degrees of freedom</em> in
<code><a href="#topic+model_parameters">model_parameters()</a></code> for further details. When <code>ci_method=NULL</code>, in most
cases <code>"wald"</code> is used then.</p>
</td></tr>
<tr><td><code id="model_parameters.cpglmm_+3A_ci_random">ci_random</code></td>
<td>
<p>Logical, if <code>TRUE</code>, includes the confidence intervals for
random effects parameters. Only applies if <code>effects</code> is not <code>"fixed"</code> and
if <code>ci</code> is not <code>NULL</code>. Set <code>ci_random = FALSE</code> if computation of the model
summary is too much time consuming. By default, <code>ci_random = NULL</code>, which
uses a heuristic to guess if computation of confidence intervals for random
effects is fast enough or not. For models with larger sample size and/or
more complex random effects structures, confidence intervals will not be
computed by default, for simpler models or fewer observations, confidence
intervals will be included. Set explicitly to <code>TRUE</code> or <code>FALSE</code> to enforce
or omit calculation of confidence intervals.</p>
</td></tr>
<tr><td><code id="model_parameters.cpglmm_+3A_bootstrap">bootstrap</code></td>
<td>
<p>Should estimates be based on bootstrapped model? If
<code>TRUE</code>, then arguments of <a href="#topic+model_parameters.stanreg">Bayesian regressions</a> apply (see also
<code><a href="#topic+bootstrap_parameters">bootstrap_parameters()</a></code>).</p>
</td></tr>
<tr><td><code id="model_parameters.cpglmm_+3A_iterations">iterations</code></td>
<td>
<p>The number of draws to simulate/bootstrap.</p>
</td></tr>
<tr><td><code id="model_parameters.cpglmm_+3A_standardize">standardize</code></td>
<td>
<p>The method used for standardizing the parameters. Can be
<code>NULL</code> (default; no standardization), <code>"refit"</code> (for re-fitting the model
on standardized data) or one of <code>"basic"</code>, <code>"posthoc"</code>, <code>"smart"</code>,
<code>"pseudo"</code>. See 'Details' in <code><a href="#topic+standardize_parameters">standardize_parameters()</a></code>.
<strong>Importantly</strong>:
</p>

<ul>
<li><p> The <code>"refit"</code> method does <em>not</em> standardize categorical predictors (i.e.
factors), which may be a different behaviour compared to other R packages
(such as <strong>lm.beta</strong>) or other software packages (like SPSS). to mimic
such behaviours, either use <code>standardize="basic"</code> or standardize the data
with <code>datawizard::standardize(force=TRUE)</code> <em>before</em> fitting the model.
</p>
</li>
<li><p> For mixed models, when using methods other than <code>"refit"</code>, only the fixed
effects will be standardized.
</p>
</li>
<li><p> Robust estimation (i.e., <code>vcov</code> set to a value other than <code>NULL</code>) of
standardized parameters only works when <code>standardize="refit"</code>.
</p>
</li></ul>
</td></tr>
<tr><td><code id="model_parameters.cpglmm_+3A_effects">effects</code></td>
<td>
<p>Should parameters for fixed effects (<code>"fixed"</code>), random
effects (<code>"random"</code>), or both (<code>"all"</code>) be returned? Only applies
to mixed models. May be abbreviated. If the calculation of random effects
parameters takes too long, you may use <code>effects = "fixed"</code>.</p>
</td></tr>
<tr><td><code id="model_parameters.cpglmm_+3A_group_level">group_level</code></td>
<td>
<p>Logical, for multilevel models (i.e. models with random
effects) and when <code>effects = "all"</code> or <code>effects = "random"</code>,
include the parameters for each group level from random effects. If
<code>group_level = FALSE</code> (the default), only information on SD and COR
are shown.</p>
</td></tr>
<tr><td><code id="model_parameters.cpglmm_+3A_exponentiate">exponentiate</code></td>
<td>
<p>Logical, indicating whether or not to exponentiate the
coefficients (and related confidence intervals). This is typical for
logistic regression, or more generally speaking, for models with log or
logit links. It is also recommended to use <code>exponentiate = TRUE</code> for models
with log-transformed response values. <strong>Note:</strong> Delta-method standard
errors are also computed (by multiplying the standard errors by the
transformed coefficients). This is to mimic behaviour of other software
packages, such as Stata, but these standard errors poorly estimate
uncertainty for the transformed coefficient. The transformed confidence
interval more clearly captures this uncertainty. For <code>compare_parameters()</code>,
<code>exponentiate = "nongaussian"</code> will only exponentiate coefficients from
non-Gaussian families.</p>
</td></tr>
<tr><td><code id="model_parameters.cpglmm_+3A_p_adjust">p_adjust</code></td>
<td>
<p>Character vector, if not <code>NULL</code>, indicates the method to
adjust p-values. See <code><a href="stats.html#topic+p.adjust">stats::p.adjust()</a></code> for details. Further
possible adjustment methods are <code>"tukey"</code>, <code>"scheffe"</code>,
<code>"sidak"</code> and <code>"none"</code> to explicitly disable adjustment for
<code>emmGrid</code> objects (from <strong>emmeans</strong>).</p>
</td></tr>
<tr><td><code id="model_parameters.cpglmm_+3A_include_sigma">include_sigma</code></td>
<td>
<p>Logical, if <code>TRUE</code>, includes the residual standard
deviation. For mixed models, this is defined as the sum of the distribution-specific
variance and the variance for the additive overdispersion term (see
<code><a href="insight.html#topic+get_variance">insight::get_variance()</a></code> for details). Defaults to <code>FALSE</code> for mixed models
due to the longer computation time.</p>
</td></tr>
<tr><td><code id="model_parameters.cpglmm_+3A_keep">keep</code></td>
<td>
<p>Character containing a regular expression pattern that
describes the parameters that should be included (for <code>keep</code>) or excluded
(for <code>drop</code>) in the returned data frame. <code>keep</code> may also be a
named list of regular expressions. All non-matching parameters will be
removed from the output. If <code>keep</code> is a character vector, every parameter
name in the <em>&quot;Parameter&quot;</em> column that matches the regular expression in
<code>keep</code> will be selected from the returned data frame (and vice versa,
all parameter names matching <code>drop</code> will be excluded). Furthermore, if
<code>keep</code> has more than one element, these will be merged with an <code>OR</code>
operator into a regular expression pattern like this: <code>"(one|two|three)"</code>.
If <code>keep</code> is a named list of regular expression patterns, the names of the
list-element should equal the column name where selection should be
applied. This is useful for model objects where <code>model_parameters()</code>
returns multiple columns with parameter components, like in
<code><a href="#topic+model_parameters.lavaan">model_parameters.lavaan()</a></code>. Note that the regular expression pattern
should match the parameter names as they are stored in the returned data
frame, which can be different from how they are printed. Inspect the
<code style="white-space: pre;">&#8288;$Parameter&#8288;</code> column of the parameters table to get the exact parameter
names.</p>
</td></tr>
<tr><td><code id="model_parameters.cpglmm_+3A_drop">drop</code></td>
<td>
<p>See <code>keep</code>.</p>
</td></tr>
<tr><td><code id="model_parameters.cpglmm_+3A_verbose">verbose</code></td>
<td>
<p>Toggle warnings and messages.</p>
</td></tr>
<tr><td><code id="model_parameters.cpglmm_+3A_...">...</code></td>
<td>
<p>Arguments passed to or from other methods. For instance, when
<code>bootstrap = TRUE</code>, arguments like <code>type</code> or <code>parallel</code> are
passed down to <code>bootstrap_model()</code>.</p>
</td></tr>
<tr><td><code id="model_parameters.cpglmm_+3A_component">component</code></td>
<td>
<p>Should all parameters, parameters for the conditional model,
for the zero-inflation part of the model, or the dispersion model be returned?
Applies to models with zero-inflation and/or dispersion component. <code>component</code>
may be one of <code>"conditional"</code>, <code>"zi"</code>, <code>"zero-inflated"</code>, <code>"dispersion"</code> or
<code>"all"</code> (default). May be abbreviated.</p>
</td></tr>
<tr><td><code id="model_parameters.cpglmm_+3A_wb_component">wb_component</code></td>
<td>
<p>Logical, if <code>TRUE</code> and models contains within- and
between-effects (see <code>datawizard::demean()</code>), the <code>Component</code> column
will indicate which variables belong to the within-effects,
between-effects, and cross-level interactions. By default, the
<code>Component</code> column indicates, which parameters belong to the
conditional or zero-inflation component of the model.</p>
</td></tr>
<tr><td><code id="model_parameters.cpglmm_+3A_summary">summary</code></td>
<td>
<p>Logical, if <code>TRUE</code>, prints summary information about the
model (model formula, number of observations, residual standard deviation
and more).</p>
</td></tr>
<tr><td><code id="model_parameters.cpglmm_+3A_vcov">vcov</code></td>
<td>
<p>Variance-covariance matrix used to compute uncertainty estimates
(e.g., for robust standard errors). This argument accepts a covariance matrix,
a function which returns a covariance matrix, or a string which identifies
the function to be used to compute the covariance matrix.
</p>

<ul>
<li><p> A covariance matrix
</p>
</li>
<li><p> A function which returns a covariance matrix (e.g., <code>stats::vcov()</code>)
</p>
</li>
<li><p> A string which indicates the kind of uncertainty estimates to return.
</p>

<ul>
<li><p> Heteroskedasticity-consistent: <code>"vcovHC"</code>, <code>"HC"</code>, <code>"HC0"</code>, <code>"HC1"</code>,
<code>"HC2"</code>, <code>"HC3"</code>, <code>"HC4"</code>, <code>"HC4m"</code>, <code>"HC5"</code>. See <code>?sandwich::vcovHC</code>.
</p>
</li>
<li><p> Cluster-robust: <code>"vcovCR"</code>, <code>"CR0"</code>, <code>"CR1"</code>, <code>"CR1p"</code>, <code>"CR1S"</code>, <code>"CR2"</code>,
<code>"CR3"</code>. See <code>?clubSandwich::vcovCR</code>.
</p>
</li>
<li><p> Bootstrap: <code>"vcovBS"</code>, <code>"xy"</code>, <code>"residual"</code>, <code>"wild"</code>, <code>"mammen"</code>, <code>"webb"</code>.
See <code>?sandwich::vcovBS</code>.
</p>
</li>
<li><p> Other <code>sandwich</code> package functions: <code>"vcovHAC"</code>, <code>"vcovPC"</code>, <code>"vcovCL"</code>, <code>"vcovPL"</code>.
</p>
</li></ul>

</li></ul>
</td></tr>
<tr><td><code id="model_parameters.cpglmm_+3A_vcov_args">vcov_args</code></td>
<td>
<p>List of arguments to be passed to the function identified by
the <code>vcov</code> argument. This function is typically supplied by the <strong>sandwich</strong>
or <strong>clubSandwich</strong> packages. Please refer to their documentation (e.g.,
<code>?sandwich::vcovHAC</code>) to see the list of available arguments.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame of indices related to the model's parameters.
</p>


<h3>Confidence intervals for random effect variances</h3>

<p>For models of class <code>merMod</code> and <code>glmmTMB</code>, confidence intervals for random
effect variances can be calculated.
</p>

<ul>
<li><p> For models of from package <strong>lme4</strong>, when <code>ci_method</code> is either <code>"profile"</code>
or <code>"boot"</code>, and <code>effects</code> is either <code>"random"</code> or <code>"all"</code>, profiled resp.
bootstrapped confidence intervals are computed for the random effects.
</p>
</li>
<li><p> For all other options of <code>ci_method</code>, and only when the <strong>merDeriv</strong>
package is installed, confidence intervals for random effects are based on
normal-distribution approximation, using the delta-method to transform
standard errors for constructing the intervals around the log-transformed
SD parameters. These are than back-transformed, so that random effect
variances, standard errors and confidence intervals are shown on the original
scale. Due to the transformation, the intervals are asymmetrical, however,
they are within the correct bounds (i.e. no negative interval for the SD,
and the interval for the correlations is within the range from -1 to +1).
</p>
</li>
<li><p> For models of class <code>glmmTMB</code>, confidence intervals for random effect
variances always use a Wald t-distribution approximation.
</p>
</li></ul>



<h3>Dispersion parameters in <em>glmmTMB</em></h3>

<p>For some models from package <strong>glmmTMB</strong>, both the dispersion parameter and
the residual variance from the random effects parameters are shown. Usually,
these are the same but presented on different scales, e.g.
</p>
<div class="sourceCode"><pre>model &lt;- glmmTMB(Sepal.Width ~ Petal.Length + (1|Species), data = iris)
exp(fixef(model)$disp) # 0.09902987
sigma(model)^2         # 0.09902987
</pre></div>
<p>For models where the dispersion parameter and the residual variance are
the same, only the residual variance is shown in the output.
</p>


<h3>Confidence intervals and approximation of degrees of freedom</h3>

<p>There are different ways of approximating the degrees of freedom depending
on different assumptions about the nature of the model and its sampling
distribution. The <code>ci_method</code> argument modulates the method for computing degrees
of freedom (df) that are used to calculate confidence intervals (CI) and the
related p-values. Following options are allowed, depending on the model
class:
</p>
<p><strong>Classical methods:</strong>
</p>
<p>Classical inference is generally based on the <strong>Wald method</strong>.
The Wald approach to inference computes a test statistic by dividing the
parameter estimate by its standard error (Coefficient / SE),
then comparing this statistic against a t- or normal distribution.
This approach can be used to compute CIs and p-values.
</p>
<p><code>"wald"</code>:
</p>

<ul>
<li><p> Applies to <em>non-Bayesian models</em>. For <em>linear models</em>, CIs
computed using the Wald method (SE and a <em>t-distribution with residual df</em>);
p-values computed using the Wald method with a <em>t-distribution with residual df</em>.
For other models, CIs computed using the Wald method (SE and a <em>normal distribution</em>);
p-values computed using the Wald method with a <em>normal distribution</em>.
</p>
</li></ul>

<p><code>"normal"</code>
</p>

<ul>
<li><p> Applies to <em>non-Bayesian models</em>. Compute Wald CIs and p-values,
but always use a normal distribution.
</p>
</li></ul>

<p><code>"residual"</code>
</p>

<ul>
<li><p> Applies to <em>non-Bayesian models</em>. Compute Wald CIs and p-values,
but always use a <em>t-distribution with residual df</em> when possible. If the
residual df for a model cannot be determined, a normal distribution is
used instead.
</p>
</li></ul>

<p><strong>Methods for mixed models:</strong>
</p>
<p>Compared to fixed effects (or single-level) models, determining appropriate
df for Wald-based inference in mixed models is more difficult.
See <a href="https://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#what-are-the-p-values-listed-by-summaryglmerfit-etc.-are-they-reliable">the R GLMM FAQ</a>
for a discussion.
</p>
<p>Several approximate methods for computing df are available, but you should
also consider instead using profile likelihood (<code>"profile"</code>) or bootstrap (&quot;<code style="white-space: pre;">&#8288;boot"&#8288;</code>)
CIs and p-values instead.
</p>
<p><code>"satterthwaite"</code>
</p>

<ul>
<li><p> Applies to <em>linear mixed models</em>. CIs computed using the
Wald method (SE and a <em>t-distribution with Satterthwaite df</em>); p-values
computed using the Wald method with a <em>t-distribution with Satterthwaite df</em>.
</p>
</li></ul>

<p><code>"kenward"</code>
</p>

<ul>
<li><p> Applies to <em>linear mixed models</em>. CIs computed using the Wald
method (<em>Kenward-Roger SE</em> and a <em>t-distribution with Kenward-Roger df</em>);
p-values computed using the Wald method with <em>Kenward-Roger SE and t-distribution with Kenward-Roger df</em>.
</p>
</li></ul>

<p><code>"ml1"</code>
</p>

<ul>
<li><p> Applies to <em>linear mixed models</em>. CIs computed using the Wald
method (SE and a <em>t-distribution with m-l-1 approximated df</em>); p-values
computed using the Wald method with a <em>t-distribution with m-l-1 approximated df</em>.
See <code><a href="#topic+ci_ml1">ci_ml1()</a></code>.
</p>
</li></ul>

<p><code>"betwithin"</code>
</p>

<ul>
<li><p> Applies to <em>linear mixed models</em> and <em>generalized linear mixed models</em>.
CIs computed using the Wald method (SE and a <em>t-distribution with between-within df</em>);
p-values computed using the Wald method with a <em>t-distribution with between-within df</em>.
See <code><a href="#topic+ci_betwithin">ci_betwithin()</a></code>.
</p>
</li></ul>

<p><strong>Likelihood-based methods:</strong>
</p>
<p>Likelihood-based inference is based on comparing the likelihood for the
maximum-likelihood estimate to the the likelihood for models with one or more
parameter values changed (e.g., set to zero or a range of alternative values).
Likelihood ratios for the maximum-likelihood and alternative models are compared
to a <code class="reqn">\chi</code>-squared distribution to compute CIs and p-values.
</p>
<p><code>"profile"</code>
</p>

<ul>
<li><p> Applies to <em>non-Bayesian models</em> of class <code>glm</code>, <code>polr</code>, <code>merMod</code> or <code>glmmTMB</code>.
CIs computed by <em>profiling the likelihood curve for a parameter</em>, using
linear interpolation to find where likelihood ratio equals a critical value;
p-values computed using the Wald method with a <em>normal-distribution</em> (note:
this might change in a future update!)
</p>
</li></ul>

<p><code>"uniroot"</code>
</p>

<ul>
<li><p> Applies to <em>non-Bayesian models</em> of class <code>glmmTMB</code>. CIs
computed by <em>profiling the likelihood curve for a parameter</em>, using root
finding to find where likelihood ratio equals a critical value; p-values
computed using the Wald method with a <em>normal-distribution</em> (note: this
might change in a future update!)
</p>
</li></ul>

<p><strong>Methods for bootstrapped or Bayesian models:</strong>
</p>
<p>Bootstrap-based inference is based on <strong>resampling</strong> and refitting the model
to the resampled datasets. The distribution of parameter estimates across
resampled datasets is used to approximate the parameter's sampling
distribution. Depending on the type of model, several different methods for
bootstrapping and constructing CIs and p-values from the bootstrap
distribution are available.
</p>
<p>For Bayesian models, inference is based on drawing samples from the model
posterior distribution.
</p>
<p><code>"quantile"</code> (or <code>"eti"</code>)
</p>

<ul>
<li><p> Applies to <em>all models (including Bayesian models)</em>.
For non-Bayesian models, only applies if <code>bootstrap = TRUE</code>. CIs computed
as <em>equal tailed intervals</em> using the quantiles of the bootstrap or
posterior samples; p-values are based on the <em>probability of direction</em>.
See <code><a href="bayestestR.html#topic+eti">bayestestR::eti()</a></code>.
</p>
</li></ul>

<p><code>"hdi"</code>
</p>

<ul>
<li><p> Applies to <em>all models (including Bayesian models)</em>. For non-Bayesian
models, only applies if <code>bootstrap = TRUE</code>. CIs computed as <em>highest density intervals</em>
for the bootstrap or posterior samples; p-values are based on the <em>probability of direction</em>.
See <code><a href="bayestestR.html#topic+hdi">bayestestR::hdi()</a></code>.
</p>
</li></ul>

<p><code>"bci"</code> (or <code>"bcai"</code>)
</p>

<ul>
<li><p> Applies to <em>all models (including Bayesian models)</em>.
For non-Bayesian models, only applies if <code>bootstrap = TRUE</code>. CIs computed
as <em>bias corrected and accelerated intervals</em> for the bootstrap or
posterior samples; p-values are based on the <em>probability of direction</em>.
See <code><a href="bayestestR.html#topic+bci">bayestestR::bci()</a></code>.
</p>
</li></ul>

<p><code>"si"</code>
</p>

<ul>
<li><p> Applies to <em>Bayesian models</em> with proper priors. CIs computed as
<em>support intervals</em> comparing the posterior samples against the prior samples;
p-values are based on the <em>probability of direction</em>. See <code><a href="bayestestR.html#topic+si">bayestestR::si()</a></code>.
</p>
</li></ul>

<p><code>"boot"</code>
</p>

<ul>
<li><p> Applies to <em>non-Bayesian models</em> of class <code>merMod</code>. CIs computed
using <em>parametric bootstrapping</em> (simulating data from the fitted model);
p-values computed using the Wald method with a <em>normal-distribution)</em>
(note: this might change in a future update!).
</p>
</li></ul>

<p>For all iteration-based methods other than <code>"boot"</code>
(<code>"hdi"</code>, <code>"quantile"</code>, <code>"ci"</code>, <code>"eti"</code>, <code>"si"</code>, <code>"bci"</code>, <code>"bcai"</code>),
p-values are based on the probability of direction (<code><a href="bayestestR.html#topic+p_direction">bayestestR::p_direction()</a></code>),
which is converted into a p-value using <code><a href="bayestestR.html#topic+pd_to_p">bayestestR::pd_to_p()</a></code>.
</p>


<h3>Note</h3>

<p>If the calculation of random effects parameters takes too long, you may
use <code>effects = "fixed"</code>. There is also a <a href="https://easystats.github.io/see/articles/parameters.html"><code>plot()</code>-method</a>
implemented in the <a href="https://easystats.github.io/see/"><strong>see</strong>-package</a>.
</p>


<h3>See Also</h3>

<p><code><a href="insight.html#topic+standardize_names">insight::standardize_names()</a></code> to
rename columns into a consistent, standardized naming scheme.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(parameters)
data(mtcars)
model &lt;- lme4::lmer(mpg ~ wt + (1 | gear), data = mtcars)
model_parameters(model)


data(Salamanders, package = "glmmTMB")
model &lt;- glmmTMB::glmmTMB(
  count ~ spp + mined + (1 | site),
  ziformula = ~mined,
  family = poisson(),
  data = Salamanders
)
model_parameters(model, effects = "all")

model &lt;- lme4::lmer(mpg ~ wt + (1 | gear), data = mtcars)
model_parameters(model, bootstrap = TRUE, iterations = 50, verbose = FALSE)


</code></pre>

<hr>
<h2 id='model_parameters.dbscan'>Parameters from Cluster Models (k-means, ...)</h2><span id='topic+model_parameters.dbscan'></span><span id='topic+model_parameters.hclust'></span><span id='topic+model_parameters.pvclust'></span><span id='topic+model_parameters.kmeans'></span><span id='topic+model_parameters.hkmeans'></span><span id='topic+model_parameters.Mclust'></span><span id='topic+model_parameters.pam'></span>

<h3>Description</h3>

<p>Format cluster models obtained for example by <code><a href="stats.html#topic+kmeans">kmeans()</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'dbscan'
model_parameters(model, data = NULL, clusters = NULL, ...)

## S3 method for class 'hclust'
model_parameters(model, data = NULL, clusters = NULL, ...)

## S3 method for class 'pvclust'
model_parameters(model, data = NULL, clusters = NULL, ci = 0.95, ...)

## S3 method for class 'kmeans'
model_parameters(model, ...)

## S3 method for class 'hkmeans'
model_parameters(model, ...)

## S3 method for class 'Mclust'
model_parameters(model, data = NULL, clusters = NULL, ...)

## S3 method for class 'pam'
model_parameters(model, data = NULL, clusters = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="model_parameters.dbscan_+3A_model">model</code></td>
<td>
<p>Cluster model.</p>
</td></tr>
<tr><td><code id="model_parameters.dbscan_+3A_data">data</code></td>
<td>
<p>A data.frame.</p>
</td></tr>
<tr><td><code id="model_parameters.dbscan_+3A_clusters">clusters</code></td>
<td>
<p>A vector with clusters assignments (must be same length as rows in data).</p>
</td></tr>
<tr><td><code id="model_parameters.dbscan_+3A_...">...</code></td>
<td>
<p>Arguments passed to or from other methods.</p>
</td></tr>
<tr><td><code id="model_parameters.dbscan_+3A_ci">ci</code></td>
<td>
<p>Confidence Interval (CI) level. Default to <code>0.95</code> (<code style="white-space: pre;">&#8288;95%&#8288;</code>).</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>
# DBSCAN ---------------------------
if (require("dbscan", quietly = TRUE)) {
  model &lt;- dbscan::dbscan(iris[1:4], eps = 1.45, minPts = 10)

  rez &lt;- model_parameters(model, iris[1:4])
  rez

  # Get clusters
  predict(rez)

  # Clusters centers in long form
  attributes(rez)$means

  # Between and Total Sum of Squares
  attributes(rez)$Sum_Squares_Total
  attributes(rez)$Sum_Squares_Between

  # HDBSCAN
  model &lt;- dbscan::hdbscan(iris[1:4], minPts = 10)
  model_parameters(model, iris[1:4])
}

#
# Hierarchical clustering (hclust) ---------------------------
data &lt;- iris[1:4]
model &lt;- hclust(dist(data))
clusters &lt;- cutree(model, 3)

rez &lt;- model_parameters(model, data, clusters)
rez

# Get clusters
predict(rez)

# Clusters centers in long form
attributes(rez)$means

# Between and Total Sum of Squares
attributes(rez)$Total_Sum_Squares
attributes(rez)$Between_Sum_Squares

#
# pvclust (finds "significant" clusters) ---------------------------
if (require("pvclust", quietly = TRUE)) {
  data &lt;- iris[1:4]
  # NOTE: pvclust works on transposed data
  model &lt;- pvclust::pvclust(datawizard::data_transpose(data, verbose = FALSE),
    method.dist = "euclidean",
    nboot = 50,
    quiet = TRUE
  )

  rez &lt;- model_parameters(model, data, ci = 0.90)
  rez

  # Get clusters
  predict(rez)

  # Clusters centers in long form
  attributes(rez)$means

  # Between and Total Sum of Squares
  attributes(rez)$Sum_Squares_Total
  attributes(rez)$Sum_Squares_Between
}


#
# K-means -------------------------------
model &lt;- kmeans(iris[1:4], centers = 3)
rez &lt;- model_parameters(model)
rez

# Get clusters
predict(rez)

# Clusters centers in long form
attributes(rez)$means

# Between and Total Sum of Squares
attributes(rez)$Sum_Squares_Total
attributes(rez)$Sum_Squares_Between


#
# Hierarchical K-means (factoextra::hkclust) ----------------------
if (require("factoextra", quietly = TRUE)) {
  data &lt;- iris[1:4]
  model &lt;- factoextra::hkmeans(data, k = 3)

  rez &lt;- model_parameters(model)
  rez

  # Get clusters
  predict(rez)

  # Clusters centers in long form
  attributes(rez)$means

  # Between and Total Sum of Squares
  attributes(rez)$Sum_Squares_Total
  attributes(rez)$Sum_Squares_Between
}

if (require("mclust", quietly = TRUE)) {
  model &lt;- mclust::Mclust(iris[1:4], verbose = FALSE)
  model_parameters(model)
}

#
# K-Medoids (PAM and HPAM) ==============
if (require("cluster", quietly = TRUE)) {
  model &lt;- cluster::pam(iris[1:4], k = 3)
  model_parameters(model)
}
if (require("fpc", quietly = TRUE)) {
  model &lt;- fpc::pamk(iris[1:4], criterion = "ch")
  model_parameters(model)
}

</code></pre>

<hr>
<h2 id='model_parameters.default'>Parameters from (General) Linear Models</h2><span id='topic+model_parameters.default'></span><span id='topic+model_parameters.glm'></span><span id='topic+model_parameters.censReg'></span><span id='topic+model_parameters.ridgelm'></span>

<h3>Description</h3>

<p>Extract and compute indices and measures to describe parameters of (general)
linear models (GLMs).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## Default S3 method:
model_parameters(
  model,
  ci = 0.95,
  ci_method = NULL,
  bootstrap = FALSE,
  iterations = 1000,
  standardize = NULL,
  exponentiate = FALSE,
  p_adjust = NULL,
  summary = getOption("parameters_summary", FALSE),
  keep = NULL,
  drop = NULL,
  verbose = TRUE,
  vcov = NULL,
  vcov_args = NULL,
  ...
)

## S3 method for class 'glm'
model_parameters(
  model,
  ci = 0.95,
  ci_method = NULL,
  bootstrap = FALSE,
  iterations = 1000,
  standardize = NULL,
  exponentiate = FALSE,
  p_adjust = NULL,
  summary = getOption("parameters_summary", FALSE),
  keep = NULL,
  drop = NULL,
  vcov = NULL,
  vcov_args = NULL,
  verbose = TRUE,
  ...
)

## S3 method for class 'censReg'
model_parameters(
  model,
  ci = 0.95,
  ci_method = NULL,
  bootstrap = FALSE,
  iterations = 1000,
  standardize = NULL,
  exponentiate = FALSE,
  p_adjust = NULL,
  summary = getOption("parameters_summary", FALSE),
  keep = NULL,
  drop = NULL,
  verbose = TRUE,
  vcov = NULL,
  vcov_args = NULL,
  ...
)

## S3 method for class 'ridgelm'
model_parameters(model, verbose = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="model_parameters.default_+3A_model">model</code></td>
<td>
<p>Model object.</p>
</td></tr>
<tr><td><code id="model_parameters.default_+3A_ci">ci</code></td>
<td>
<p>Confidence Interval (CI) level. Default to <code>0.95</code> (<code style="white-space: pre;">&#8288;95%&#8288;</code>).</p>
</td></tr>
<tr><td><code id="model_parameters.default_+3A_ci_method">ci_method</code></td>
<td>
<p>Method for computing degrees of freedom for
confidence intervals (CI) and the related p-values. Allowed are following
options (which vary depending on the model class): <code>"residual"</code>,
<code>"normal"</code>, <code>"likelihood"</code>, <code>"satterthwaite"</code>, <code>"kenward"</code>, <code>"wald"</code>,
<code>"profile"</code>, <code>"boot"</code>, <code>"uniroot"</code>, <code>"ml1"</code>, <code>"betwithin"</code>, <code>"hdi"</code>,
<code>"quantile"</code>, <code>"ci"</code>, <code>"eti"</code>, <code>"si"</code>, <code>"bci"</code>, or <code>"bcai"</code>. See section
<em>Confidence intervals and approximation of degrees of freedom</em> in
<code><a href="#topic+model_parameters">model_parameters()</a></code> for further details. When <code>ci_method=NULL</code>, in most
cases <code>"wald"</code> is used then.</p>
</td></tr>
<tr><td><code id="model_parameters.default_+3A_bootstrap">bootstrap</code></td>
<td>
<p>Should estimates be based on bootstrapped model? If
<code>TRUE</code>, then arguments of <a href="#topic+model_parameters.stanreg">Bayesian regressions</a> apply (see also
<code><a href="#topic+bootstrap_parameters">bootstrap_parameters()</a></code>).</p>
</td></tr>
<tr><td><code id="model_parameters.default_+3A_iterations">iterations</code></td>
<td>
<p>The number of bootstrap replicates. This only apply in the
case of bootstrapped frequentist models.</p>
</td></tr>
<tr><td><code id="model_parameters.default_+3A_standardize">standardize</code></td>
<td>
<p>The method used for standardizing the parameters. Can be
<code>NULL</code> (default; no standardization), <code>"refit"</code> (for re-fitting the model
on standardized data) or one of <code>"basic"</code>, <code>"posthoc"</code>, <code>"smart"</code>,
<code>"pseudo"</code>. See 'Details' in <code><a href="#topic+standardize_parameters">standardize_parameters()</a></code>.
<strong>Importantly</strong>:
</p>

<ul>
<li><p> The <code>"refit"</code> method does <em>not</em> standardize categorical predictors (i.e.
factors), which may be a different behaviour compared to other R packages
(such as <strong>lm.beta</strong>) or other software packages (like SPSS). to mimic
such behaviours, either use <code>standardize="basic"</code> or standardize the data
with <code>datawizard::standardize(force=TRUE)</code> <em>before</em> fitting the model.
</p>
</li>
<li><p> For mixed models, when using methods other than <code>"refit"</code>, only the fixed
effects will be standardized.
</p>
</li>
<li><p> Robust estimation (i.e., <code>vcov</code> set to a value other than <code>NULL</code>) of
standardized parameters only works when <code>standardize="refit"</code>.
</p>
</li></ul>
</td></tr>
<tr><td><code id="model_parameters.default_+3A_exponentiate">exponentiate</code></td>
<td>
<p>Logical, indicating whether or not to exponentiate the
coefficients (and related confidence intervals). This is typical for
logistic regression, or more generally speaking, for models with log or
logit links. It is also recommended to use <code>exponentiate = TRUE</code> for models
with log-transformed response values. <strong>Note:</strong> Delta-method standard
errors are also computed (by multiplying the standard errors by the
transformed coefficients). This is to mimic behaviour of other software
packages, such as Stata, but these standard errors poorly estimate
uncertainty for the transformed coefficient. The transformed confidence
interval more clearly captures this uncertainty. For <code>compare_parameters()</code>,
<code>exponentiate = "nongaussian"</code> will only exponentiate coefficients from
non-Gaussian families.</p>
</td></tr>
<tr><td><code id="model_parameters.default_+3A_p_adjust">p_adjust</code></td>
<td>
<p>Character vector, if not <code>NULL</code>, indicates the method to
adjust p-values. See <code><a href="stats.html#topic+p.adjust">stats::p.adjust()</a></code> for details. Further
possible adjustment methods are <code>"tukey"</code>, <code>"scheffe"</code>,
<code>"sidak"</code> and <code>"none"</code> to explicitly disable adjustment for
<code>emmGrid</code> objects (from <strong>emmeans</strong>).</p>
</td></tr>
<tr><td><code id="model_parameters.default_+3A_summary">summary</code></td>
<td>
<p>Logical, if <code>TRUE</code>, prints summary information about the
model (model formula, number of observations, residual standard deviation
and more).</p>
</td></tr>
<tr><td><code id="model_parameters.default_+3A_keep">keep</code></td>
<td>
<p>Character containing a regular expression pattern that
describes the parameters that should be included (for <code>keep</code>) or excluded
(for <code>drop</code>) in the returned data frame. <code>keep</code> may also be a
named list of regular expressions. All non-matching parameters will be
removed from the output. If <code>keep</code> is a character vector, every parameter
name in the <em>&quot;Parameter&quot;</em> column that matches the regular expression in
<code>keep</code> will be selected from the returned data frame (and vice versa,
all parameter names matching <code>drop</code> will be excluded). Furthermore, if
<code>keep</code> has more than one element, these will be merged with an <code>OR</code>
operator into a regular expression pattern like this: <code>"(one|two|three)"</code>.
If <code>keep</code> is a named list of regular expression patterns, the names of the
list-element should equal the column name where selection should be
applied. This is useful for model objects where <code>model_parameters()</code>
returns multiple columns with parameter components, like in
<code><a href="#topic+model_parameters.lavaan">model_parameters.lavaan()</a></code>. Note that the regular expression pattern
should match the parameter names as they are stored in the returned data
frame, which can be different from how they are printed. Inspect the
<code style="white-space: pre;">&#8288;$Parameter&#8288;</code> column of the parameters table to get the exact parameter
names.</p>
</td></tr>
<tr><td><code id="model_parameters.default_+3A_drop">drop</code></td>
<td>
<p>See <code>keep</code>.</p>
</td></tr>
<tr><td><code id="model_parameters.default_+3A_verbose">verbose</code></td>
<td>
<p>Toggle warnings and messages.</p>
</td></tr>
<tr><td><code id="model_parameters.default_+3A_vcov">vcov</code></td>
<td>
<p>Variance-covariance matrix used to compute uncertainty estimates
(e.g., for robust standard errors). This argument accepts a covariance matrix,
a function which returns a covariance matrix, or a string which identifies
the function to be used to compute the covariance matrix.
</p>

<ul>
<li><p> A covariance matrix
</p>
</li>
<li><p> A function which returns a covariance matrix (e.g., <code>stats::vcov()</code>)
</p>
</li>
<li><p> A string which indicates the kind of uncertainty estimates to return.
</p>

<ul>
<li><p> Heteroskedasticity-consistent: <code>"vcovHC"</code>, <code>"HC"</code>, <code>"HC0"</code>, <code>"HC1"</code>,
<code>"HC2"</code>, <code>"HC3"</code>, <code>"HC4"</code>, <code>"HC4m"</code>, <code>"HC5"</code>. See <code>?sandwich::vcovHC</code>.
</p>
</li>
<li><p> Cluster-robust: <code>"vcovCR"</code>, <code>"CR0"</code>, <code>"CR1"</code>, <code>"CR1p"</code>, <code>"CR1S"</code>, <code>"CR2"</code>,
<code>"CR3"</code>. See <code>?clubSandwich::vcovCR</code>.
</p>
</li>
<li><p> Bootstrap: <code>"vcovBS"</code>, <code>"xy"</code>, <code>"residual"</code>, <code>"wild"</code>, <code>"mammen"</code>, <code>"webb"</code>.
See <code>?sandwich::vcovBS</code>.
</p>
</li>
<li><p> Other <code>sandwich</code> package functions: <code>"vcovHAC"</code>, <code>"vcovPC"</code>, <code>"vcovCL"</code>, <code>"vcovPL"</code>.
</p>
</li></ul>

</li></ul>
</td></tr>
<tr><td><code id="model_parameters.default_+3A_vcov_args">vcov_args</code></td>
<td>
<p>List of arguments to be passed to the function identified by
the <code>vcov</code> argument. This function is typically supplied by the <strong>sandwich</strong>
or <strong>clubSandwich</strong> packages. Please refer to their documentation (e.g.,
<code>?sandwich::vcovHAC</code>) to see the list of available arguments.</p>
</td></tr>
<tr><td><code id="model_parameters.default_+3A_...">...</code></td>
<td>
<p>Arguments passed to or from other methods. For instance, when
<code>bootstrap = TRUE</code>, arguments like <code>type</code> or <code>parallel</code> are
passed down to <code>bootstrap_model()</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame of indices related to the model's parameters.
</p>


<h3>Confidence intervals and approximation of degrees of freedom</h3>

<p>There are different ways of approximating the degrees of freedom depending
on different assumptions about the nature of the model and its sampling
distribution. The <code>ci_method</code> argument modulates the method for computing degrees
of freedom (df) that are used to calculate confidence intervals (CI) and the
related p-values. Following options are allowed, depending on the model
class:
</p>
<p><strong>Classical methods:</strong>
</p>
<p>Classical inference is generally based on the <strong>Wald method</strong>.
The Wald approach to inference computes a test statistic by dividing the
parameter estimate by its standard error (Coefficient / SE),
then comparing this statistic against a t- or normal distribution.
This approach can be used to compute CIs and p-values.
</p>
<p><code>"wald"</code>:
</p>

<ul>
<li><p> Applies to <em>non-Bayesian models</em>. For <em>linear models</em>, CIs
computed using the Wald method (SE and a <em>t-distribution with residual df</em>);
p-values computed using the Wald method with a <em>t-distribution with residual df</em>.
For other models, CIs computed using the Wald method (SE and a <em>normal distribution</em>);
p-values computed using the Wald method with a <em>normal distribution</em>.
</p>
</li></ul>

<p><code>"normal"</code>
</p>

<ul>
<li><p> Applies to <em>non-Bayesian models</em>. Compute Wald CIs and p-values,
but always use a normal distribution.
</p>
</li></ul>

<p><code>"residual"</code>
</p>

<ul>
<li><p> Applies to <em>non-Bayesian models</em>. Compute Wald CIs and p-values,
but always use a <em>t-distribution with residual df</em> when possible. If the
residual df for a model cannot be determined, a normal distribution is
used instead.
</p>
</li></ul>

<p><strong>Methods for mixed models:</strong>
</p>
<p>Compared to fixed effects (or single-level) models, determining appropriate
df for Wald-based inference in mixed models is more difficult.
See <a href="https://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#what-are-the-p-values-listed-by-summaryglmerfit-etc.-are-they-reliable">the R GLMM FAQ</a>
for a discussion.
</p>
<p>Several approximate methods for computing df are available, but you should
also consider instead using profile likelihood (<code>"profile"</code>) or bootstrap (&quot;<code style="white-space: pre;">&#8288;boot"&#8288;</code>)
CIs and p-values instead.
</p>
<p><code>"satterthwaite"</code>
</p>

<ul>
<li><p> Applies to <em>linear mixed models</em>. CIs computed using the
Wald method (SE and a <em>t-distribution with Satterthwaite df</em>); p-values
computed using the Wald method with a <em>t-distribution with Satterthwaite df</em>.
</p>
</li></ul>

<p><code>"kenward"</code>
</p>

<ul>
<li><p> Applies to <em>linear mixed models</em>. CIs computed using the Wald
method (<em>Kenward-Roger SE</em> and a <em>t-distribution with Kenward-Roger df</em>);
p-values computed using the Wald method with <em>Kenward-Roger SE and t-distribution with Kenward-Roger df</em>.
</p>
</li></ul>

<p><code>"ml1"</code>
</p>

<ul>
<li><p> Applies to <em>linear mixed models</em>. CIs computed using the Wald
method (SE and a <em>t-distribution with m-l-1 approximated df</em>); p-values
computed using the Wald method with a <em>t-distribution with m-l-1 approximated df</em>.
See <code><a href="#topic+ci_ml1">ci_ml1()</a></code>.
</p>
</li></ul>

<p><code>"betwithin"</code>
</p>

<ul>
<li><p> Applies to <em>linear mixed models</em> and <em>generalized linear mixed models</em>.
CIs computed using the Wald method (SE and a <em>t-distribution with between-within df</em>);
p-values computed using the Wald method with a <em>t-distribution with between-within df</em>.
See <code><a href="#topic+ci_betwithin">ci_betwithin()</a></code>.
</p>
</li></ul>

<p><strong>Likelihood-based methods:</strong>
</p>
<p>Likelihood-based inference is based on comparing the likelihood for the
maximum-likelihood estimate to the the likelihood for models with one or more
parameter values changed (e.g., set to zero or a range of alternative values).
Likelihood ratios for the maximum-likelihood and alternative models are compared
to a <code class="reqn">\chi</code>-squared distribution to compute CIs and p-values.
</p>
<p><code>"profile"</code>
</p>

<ul>
<li><p> Applies to <em>non-Bayesian models</em> of class <code>glm</code>, <code>polr</code>, <code>merMod</code> or <code>glmmTMB</code>.
CIs computed by <em>profiling the likelihood curve for a parameter</em>, using
linear interpolation to find where likelihood ratio equals a critical value;
p-values computed using the Wald method with a <em>normal-distribution</em> (note:
this might change in a future update!)
</p>
</li></ul>

<p><code>"uniroot"</code>
</p>

<ul>
<li><p> Applies to <em>non-Bayesian models</em> of class <code>glmmTMB</code>. CIs
computed by <em>profiling the likelihood curve for a parameter</em>, using root
finding to find where likelihood ratio equals a critical value; p-values
computed using the Wald method with a <em>normal-distribution</em> (note: this
might change in a future update!)
</p>
</li></ul>

<p><strong>Methods for bootstrapped or Bayesian models:</strong>
</p>
<p>Bootstrap-based inference is based on <strong>resampling</strong> and refitting the model
to the resampled datasets. The distribution of parameter estimates across
resampled datasets is used to approximate the parameter's sampling
distribution. Depending on the type of model, several different methods for
bootstrapping and constructing CIs and p-values from the bootstrap
distribution are available.
</p>
<p>For Bayesian models, inference is based on drawing samples from the model
posterior distribution.
</p>
<p><code>"quantile"</code> (or <code>"eti"</code>)
</p>

<ul>
<li><p> Applies to <em>all models (including Bayesian models)</em>.
For non-Bayesian models, only applies if <code>bootstrap = TRUE</code>. CIs computed
as <em>equal tailed intervals</em> using the quantiles of the bootstrap or
posterior samples; p-values are based on the <em>probability of direction</em>.
See <code><a href="bayestestR.html#topic+eti">bayestestR::eti()</a></code>.
</p>
</li></ul>

<p><code>"hdi"</code>
</p>

<ul>
<li><p> Applies to <em>all models (including Bayesian models)</em>. For non-Bayesian
models, only applies if <code>bootstrap = TRUE</code>. CIs computed as <em>highest density intervals</em>
for the bootstrap or posterior samples; p-values are based on the <em>probability of direction</em>.
See <code><a href="bayestestR.html#topic+hdi">bayestestR::hdi()</a></code>.
</p>
</li></ul>

<p><code>"bci"</code> (or <code>"bcai"</code>)
</p>

<ul>
<li><p> Applies to <em>all models (including Bayesian models)</em>.
For non-Bayesian models, only applies if <code>bootstrap = TRUE</code>. CIs computed
as <em>bias corrected and accelerated intervals</em> for the bootstrap or
posterior samples; p-values are based on the <em>probability of direction</em>.
See <code><a href="bayestestR.html#topic+bci">bayestestR::bci()</a></code>.
</p>
</li></ul>

<p><code>"si"</code>
</p>

<ul>
<li><p> Applies to <em>Bayesian models</em> with proper priors. CIs computed as
<em>support intervals</em> comparing the posterior samples against the prior samples;
p-values are based on the <em>probability of direction</em>. See <code><a href="bayestestR.html#topic+si">bayestestR::si()</a></code>.
</p>
</li></ul>

<p><code>"boot"</code>
</p>

<ul>
<li><p> Applies to <em>non-Bayesian models</em> of class <code>merMod</code>. CIs computed
using <em>parametric bootstrapping</em> (simulating data from the fitted model);
p-values computed using the Wald method with a <em>normal-distribution)</em>
(note: this might change in a future update!).
</p>
</li></ul>

<p>For all iteration-based methods other than <code>"boot"</code>
(<code>"hdi"</code>, <code>"quantile"</code>, <code>"ci"</code>, <code>"eti"</code>, <code>"si"</code>, <code>"bci"</code>, <code>"bcai"</code>),
p-values are based on the probability of direction (<code><a href="bayestestR.html#topic+p_direction">bayestestR::p_direction()</a></code>),
which is converted into a p-value using <code><a href="bayestestR.html#topic+pd_to_p">bayestestR::pd_to_p()</a></code>.
</p>


<h3>See Also</h3>

<p><code><a href="insight.html#topic+standardize_names">insight::standardize_names()</a></code> to
rename columns into a consistent, standardized naming scheme.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(parameters)
model &lt;- lm(mpg ~ wt + cyl, data = mtcars)

model_parameters(model)

# bootstrapped parameters
model_parameters(model, bootstrap = TRUE)

# standardized parameters
model_parameters(model, standardize = "refit")

# robust, heteroskedasticity-consistent standard errors
model_parameters(model, vcov = "HC3")

model_parameters(model,
  vcov = "vcovCL",
  vcov_args = list(cluster = mtcars$cyl)
)

# different p-value style in output
model_parameters(model, p_digits = 5)
model_parameters(model, digits = 3, ci_digits = 4, p_digits = "scientific")

# logistic regression model
model &lt;- glm(vs ~ wt + cyl, data = mtcars, family = "binomial")
model_parameters(model)

# show odds ratio / exponentiated coefficients
model_parameters(model, exponentiate = TRUE)

# bias-corrected logistic regression with penalized maximum likelihood
model &lt;- glm(
  vs ~ wt + cyl,
  data = mtcars,
  family = "binomial",
  method = "brglmFit"
)
model_parameters(model)


</code></pre>

<hr>
<h2 id='model_parameters.DirichletRegModel'>Parameters from multinomial or cumulative link models</h2><span id='topic+model_parameters.DirichletRegModel'></span><span id='topic+model_parameters.bifeAPEs'></span><span id='topic+model_parameters.bracl'></span><span id='topic+model_parameters.mlm'></span><span id='topic+model_parameters.clm2'></span>

<h3>Description</h3>

<p>Parameters from multinomial or cumulative link models
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'DirichletRegModel'
model_parameters(
  model,
  ci = 0.95,
  bootstrap = FALSE,
  iterations = 1000,
  component = c("all", "conditional", "precision"),
  standardize = NULL,
  exponentiate = FALSE,
  p_adjust = NULL,
  keep = NULL,
  drop = NULL,
  verbose = TRUE,
  ...
)

## S3 method for class 'bifeAPEs'
model_parameters(model, ...)

## S3 method for class 'bracl'
model_parameters(
  model,
  ci = 0.95,
  bootstrap = FALSE,
  iterations = 1000,
  standardize = NULL,
  exponentiate = FALSE,
  p_adjust = NULL,
  summary = getOption("parameters_summary", FALSE),
  keep = NULL,
  drop = NULL,
  verbose = TRUE,
  ...
)

## S3 method for class 'mlm'
model_parameters(
  model,
  ci = 0.95,
  vcov = NULL,
  vcov_args = NULL,
  bootstrap = FALSE,
  iterations = 1000,
  standardize = NULL,
  exponentiate = FALSE,
  p_adjust = NULL,
  keep = NULL,
  drop = NULL,
  verbose = TRUE,
  ...
)

## S3 method for class 'clm2'
model_parameters(
  model,
  ci = 0.95,
  bootstrap = FALSE,
  iterations = 1000,
  component = c("all", "conditional", "scale"),
  standardize = NULL,
  exponentiate = FALSE,
  p_adjust = NULL,
  summary = getOption("parameters_summary", FALSE),
  keep = NULL,
  drop = NULL,
  verbose = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="model_parameters.DirichletRegModel_+3A_model">model</code></td>
<td>
<p>A model with multinomial or categorical response value.</p>
</td></tr>
<tr><td><code id="model_parameters.DirichletRegModel_+3A_ci">ci</code></td>
<td>
<p>Confidence Interval (CI) level. Default to <code>0.95</code> (<code style="white-space: pre;">&#8288;95%&#8288;</code>).</p>
</td></tr>
<tr><td><code id="model_parameters.DirichletRegModel_+3A_bootstrap">bootstrap</code></td>
<td>
<p>Should estimates be based on bootstrapped model? If
<code>TRUE</code>, then arguments of <a href="#topic+model_parameters.stanreg">Bayesian regressions</a> apply (see also
<code><a href="#topic+bootstrap_parameters">bootstrap_parameters()</a></code>).</p>
</td></tr>
<tr><td><code id="model_parameters.DirichletRegModel_+3A_iterations">iterations</code></td>
<td>
<p>The number of bootstrap replicates. This only apply in the
case of bootstrapped frequentist models.</p>
</td></tr>
<tr><td><code id="model_parameters.DirichletRegModel_+3A_component">component</code></td>
<td>
<p>Should all parameters, parameters for the conditional model,
for the zero-inflation part of the model, or the dispersion model be returned?
Applies to models with zero-inflation and/or dispersion component. <code>component</code>
may be one of <code>"conditional"</code>, <code>"zi"</code>, <code>"zero-inflated"</code>, <code>"dispersion"</code> or
<code>"all"</code> (default). May be abbreviated.</p>
</td></tr>
<tr><td><code id="model_parameters.DirichletRegModel_+3A_standardize">standardize</code></td>
<td>
<p>The method used for standardizing the parameters. Can be
<code>NULL</code> (default; no standardization), <code>"refit"</code> (for re-fitting the model
on standardized data) or one of <code>"basic"</code>, <code>"posthoc"</code>, <code>"smart"</code>,
<code>"pseudo"</code>. See 'Details' in <code><a href="#topic+standardize_parameters">standardize_parameters()</a></code>.
<strong>Importantly</strong>:
</p>

<ul>
<li><p> The <code>"refit"</code> method does <em>not</em> standardize categorical predictors (i.e.
factors), which may be a different behaviour compared to other R packages
(such as <strong>lm.beta</strong>) or other software packages (like SPSS). to mimic
such behaviours, either use <code>standardize="basic"</code> or standardize the data
with <code>datawizard::standardize(force=TRUE)</code> <em>before</em> fitting the model.
</p>
</li>
<li><p> For mixed models, when using methods other than <code>"refit"</code>, only the fixed
effects will be standardized.
</p>
</li>
<li><p> Robust estimation (i.e., <code>vcov</code> set to a value other than <code>NULL</code>) of
standardized parameters only works when <code>standardize="refit"</code>.
</p>
</li></ul>
</td></tr>
<tr><td><code id="model_parameters.DirichletRegModel_+3A_exponentiate">exponentiate</code></td>
<td>
<p>Logical, indicating whether or not to exponentiate the
coefficients (and related confidence intervals). This is typical for
logistic regression, or more generally speaking, for models with log or
logit links. It is also recommended to use <code>exponentiate = TRUE</code> for models
with log-transformed response values. <strong>Note:</strong> Delta-method standard
errors are also computed (by multiplying the standard errors by the
transformed coefficients). This is to mimic behaviour of other software
packages, such as Stata, but these standard errors poorly estimate
uncertainty for the transformed coefficient. The transformed confidence
interval more clearly captures this uncertainty. For <code>compare_parameters()</code>,
<code>exponentiate = "nongaussian"</code> will only exponentiate coefficients from
non-Gaussian families.</p>
</td></tr>
<tr><td><code id="model_parameters.DirichletRegModel_+3A_p_adjust">p_adjust</code></td>
<td>
<p>Character vector, if not <code>NULL</code>, indicates the method to
adjust p-values. See <code><a href="stats.html#topic+p.adjust">stats::p.adjust()</a></code> for details. Further
possible adjustment methods are <code>"tukey"</code>, <code>"scheffe"</code>,
<code>"sidak"</code> and <code>"none"</code> to explicitly disable adjustment for
<code>emmGrid</code> objects (from <strong>emmeans</strong>).</p>
</td></tr>
<tr><td><code id="model_parameters.DirichletRegModel_+3A_keep">keep</code></td>
<td>
<p>Character containing a regular expression pattern that
describes the parameters that should be included (for <code>keep</code>) or excluded
(for <code>drop</code>) in the returned data frame. <code>keep</code> may also be a
named list of regular expressions. All non-matching parameters will be
removed from the output. If <code>keep</code> is a character vector, every parameter
name in the <em>&quot;Parameter&quot;</em> column that matches the regular expression in
<code>keep</code> will be selected from the returned data frame (and vice versa,
all parameter names matching <code>drop</code> will be excluded). Furthermore, if
<code>keep</code> has more than one element, these will be merged with an <code>OR</code>
operator into a regular expression pattern like this: <code>"(one|two|three)"</code>.
If <code>keep</code> is a named list of regular expression patterns, the names of the
list-element should equal the column name where selection should be
applied. This is useful for model objects where <code>model_parameters()</code>
returns multiple columns with parameter components, like in
<code><a href="#topic+model_parameters.lavaan">model_parameters.lavaan()</a></code>. Note that the regular expression pattern
should match the parameter names as they are stored in the returned data
frame, which can be different from how they are printed. Inspect the
<code style="white-space: pre;">&#8288;$Parameter&#8288;</code> column of the parameters table to get the exact parameter
names.</p>
</td></tr>
<tr><td><code id="model_parameters.DirichletRegModel_+3A_drop">drop</code></td>
<td>
<p>See <code>keep</code>.</p>
</td></tr>
<tr><td><code id="model_parameters.DirichletRegModel_+3A_verbose">verbose</code></td>
<td>
<p>Toggle warnings and messages.</p>
</td></tr>
<tr><td><code id="model_parameters.DirichletRegModel_+3A_...">...</code></td>
<td>
<p>Arguments passed to or from other methods. For instance, when
<code>bootstrap = TRUE</code>, arguments like <code>type</code> or <code>parallel</code> are
passed down to <code>bootstrap_model()</code>.</p>
</td></tr>
<tr><td><code id="model_parameters.DirichletRegModel_+3A_summary">summary</code></td>
<td>
<p>Logical, if <code>TRUE</code>, prints summary information about the
model (model formula, number of observations, residual standard deviation
and more).</p>
</td></tr>
<tr><td><code id="model_parameters.DirichletRegModel_+3A_vcov">vcov</code></td>
<td>
<p>Variance-covariance matrix used to compute uncertainty estimates
(e.g., for robust standard errors). This argument accepts a covariance matrix,
a function which returns a covariance matrix, or a string which identifies
the function to be used to compute the covariance matrix.
</p>

<ul>
<li><p> A covariance matrix
</p>
</li>
<li><p> A function which returns a covariance matrix (e.g., <code>stats::vcov()</code>)
</p>
</li>
<li><p> A string which indicates the kind of uncertainty estimates to return.
</p>

<ul>
<li><p> Heteroskedasticity-consistent: <code>"vcovHC"</code>, <code>"HC"</code>, <code>"HC0"</code>, <code>"HC1"</code>,
<code>"HC2"</code>, <code>"HC3"</code>, <code>"HC4"</code>, <code>"HC4m"</code>, <code>"HC5"</code>. See <code>?sandwich::vcovHC</code>.
</p>
</li>
<li><p> Cluster-robust: <code>"vcovCR"</code>, <code>"CR0"</code>, <code>"CR1"</code>, <code>"CR1p"</code>, <code>"CR1S"</code>, <code>"CR2"</code>,
<code>"CR3"</code>. See <code>?clubSandwich::vcovCR</code>.
</p>
</li>
<li><p> Bootstrap: <code>"vcovBS"</code>, <code>"xy"</code>, <code>"residual"</code>, <code>"wild"</code>, <code>"mammen"</code>, <code>"webb"</code>.
See <code>?sandwich::vcovBS</code>.
</p>
</li>
<li><p> Other <code>sandwich</code> package functions: <code>"vcovHAC"</code>, <code>"vcovPC"</code>, <code>"vcovCL"</code>, <code>"vcovPL"</code>.
</p>
</li></ul>

</li></ul>
</td></tr>
<tr><td><code id="model_parameters.DirichletRegModel_+3A_vcov_args">vcov_args</code></td>
<td>
<p>List of arguments to be passed to the function identified by
the <code>vcov</code> argument. This function is typically supplied by the <strong>sandwich</strong>
or <strong>clubSandwich</strong> packages. Please refer to their documentation (e.g.,
<code>?sandwich::vcovHAC</code>) to see the list of available arguments.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Multinomial or cumulative link models, i.e. models where the
response value (dependent variable) is categorical and has more than two
levels, usually return coefficients for each response level. Hence, the
output from <code>model_parameters()</code> will split the coefficient tables
by the different levels of the model's response.
</p>


<h3>Value</h3>

<p>A data frame of indices related to the model's parameters.
</p>


<h3>See Also</h3>

<p><code><a href="insight.html#topic+standardize_names">insight::standardize_names()</a></code> to rename
columns into a consistent, standardized naming scheme.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data("stemcell", package = "brglm2")
model &lt;- brglm2::bracl(
  research ~ as.numeric(religion) + gender,
  weights = frequency,
  data = stemcell,
  type = "ML"
)
model_parameters(model)

</code></pre>

<hr>
<h2 id='model_parameters.glht'>Parameters from Hypothesis Testing</h2><span id='topic+model_parameters.glht'></span>

<h3>Description</h3>

<p>Parameters from Hypothesis Testing.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'glht'
model_parameters(
  model,
  ci = 0.95,
  exponentiate = FALSE,
  keep = NULL,
  drop = NULL,
  verbose = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="model_parameters.glht_+3A_model">model</code></td>
<td>
<p>Object of class <code><a href="multcomp.html#topic+glht">multcomp::glht()</a></code> (<strong>multcomp</strong>)
or of class <code>PMCMR</code>, <code>trendPMCMR</code> or <code>osrt</code> (<strong>PMCMRplus</strong>).</p>
</td></tr>
<tr><td><code id="model_parameters.glht_+3A_ci">ci</code></td>
<td>
<p>Confidence Interval (CI) level. Default to <code>0.95</code> (<code style="white-space: pre;">&#8288;95%&#8288;</code>).</p>
</td></tr>
<tr><td><code id="model_parameters.glht_+3A_exponentiate">exponentiate</code></td>
<td>
<p>Logical, indicating whether or not to exponentiate the
coefficients (and related confidence intervals). This is typical for
logistic regression, or more generally speaking, for models with log or
logit links. It is also recommended to use <code>exponentiate = TRUE</code> for models
with log-transformed response values. <strong>Note:</strong> Delta-method standard
errors are also computed (by multiplying the standard errors by the
transformed coefficients). This is to mimic behaviour of other software
packages, such as Stata, but these standard errors poorly estimate
uncertainty for the transformed coefficient. The transformed confidence
interval more clearly captures this uncertainty. For <code>compare_parameters()</code>,
<code>exponentiate = "nongaussian"</code> will only exponentiate coefficients from
non-Gaussian families.</p>
</td></tr>
<tr><td><code id="model_parameters.glht_+3A_keep">keep</code></td>
<td>
<p>Character containing a regular expression pattern that
describes the parameters that should be included (for <code>keep</code>) or excluded
(for <code>drop</code>) in the returned data frame. <code>keep</code> may also be a
named list of regular expressions. All non-matching parameters will be
removed from the output. If <code>keep</code> is a character vector, every parameter
name in the <em>&quot;Parameter&quot;</em> column that matches the regular expression in
<code>keep</code> will be selected from the returned data frame (and vice versa,
all parameter names matching <code>drop</code> will be excluded). Furthermore, if
<code>keep</code> has more than one element, these will be merged with an <code>OR</code>
operator into a regular expression pattern like this: <code>"(one|two|three)"</code>.
If <code>keep</code> is a named list of regular expression patterns, the names of the
list-element should equal the column name where selection should be
applied. This is useful for model objects where <code>model_parameters()</code>
returns multiple columns with parameter components, like in
<code><a href="#topic+model_parameters.lavaan">model_parameters.lavaan()</a></code>. Note that the regular expression pattern
should match the parameter names as they are stored in the returned data
frame, which can be different from how they are printed. Inspect the
<code style="white-space: pre;">&#8288;$Parameter&#8288;</code> column of the parameters table to get the exact parameter
names.</p>
</td></tr>
<tr><td><code id="model_parameters.glht_+3A_drop">drop</code></td>
<td>
<p>See <code>keep</code>.</p>
</td></tr>
<tr><td><code id="model_parameters.glht_+3A_verbose">verbose</code></td>
<td>
<p>Toggle warnings and messages.</p>
</td></tr>
<tr><td><code id="model_parameters.glht_+3A_...">...</code></td>
<td>
<p>Arguments passed to or from other methods. For instance, when
<code>bootstrap = TRUE</code>, arguments like <code>type</code> or <code>parallel</code> are
passed down to <code>bootstrap_model()</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame of indices related to the model's parameters.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
if (require("multcomp", quietly = TRUE)) {
  # multiple linear model, swiss data
  lmod &lt;- lm(Fertility ~ ., data = swiss)
  mod &lt;- glht(
    model = lmod,
    linfct = c(
      "Agriculture = 0",
      "Examination = 0",
      "Education = 0",
      "Catholic = 0",
      "Infant.Mortality = 0"
    )
  )
  model_parameters(mod)
}
if (require("PMCMRplus", quietly = TRUE)) {
  model &lt;- suppressWarnings(
    kwAllPairsConoverTest(count ~ spray, data = InsectSprays)
  )
  model_parameters(model)
}

</code></pre>

<hr>
<h2 id='model_parameters.glimML'>Parameters from special models</h2><span id='topic+model_parameters.glimML'></span><span id='topic+model_parameters.averaging'></span><span id='topic+model_parameters.betareg'></span><span id='topic+model_parameters.emm_list'></span><span id='topic+model_parameters.glmx'></span><span id='topic+model_parameters.marginaleffects'></span><span id='topic+model_parameters.metaplus'></span><span id='topic+model_parameters.meta_random'></span><span id='topic+model_parameters.meta_bma'></span><span id='topic+model_parameters.betaor'></span><span id='topic+model_parameters.betamfx'></span><span id='topic+model_parameters.mjoint'></span><span id='topic+model_parameters.mvord'></span><span id='topic+model_parameters.selection'></span>

<h3>Description</h3>

<p>Parameters from special regression models not listed under one of the previous categories yet.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'glimML'
model_parameters(
  model,
  ci = 0.95,
  bootstrap = FALSE,
  iterations = 1000,
  component = c("conditional", "random", "dispersion", "all"),
  standardize = NULL,
  exponentiate = FALSE,
  p_adjust = NULL,
  summary = getOption("parameters_summary", FALSE),
  keep = NULL,
  drop = NULL,
  verbose = TRUE,
  ...
)

## S3 method for class 'averaging'
model_parameters(
  model,
  ci = 0.95,
  component = c("conditional", "full"),
  exponentiate = FALSE,
  p_adjust = NULL,
  summary = getOption("parameters_summary", FALSE),
  keep = NULL,
  drop = NULL,
  verbose = TRUE,
  ...
)

## S3 method for class 'betareg'
model_parameters(
  model,
  ci = 0.95,
  bootstrap = FALSE,
  iterations = 1000,
  component = c("conditional", "precision", "all"),
  standardize = NULL,
  exponentiate = FALSE,
  p_adjust = NULL,
  summary = getOption("parameters_summary", FALSE),
  keep = NULL,
  drop = NULL,
  verbose = TRUE,
  ...
)

## S3 method for class 'emm_list'
model_parameters(
  model,
  ci = 0.95,
  exponentiate = FALSE,
  p_adjust = NULL,
  verbose = TRUE,
  ...
)

## S3 method for class 'glmx'
model_parameters(
  model,
  ci = 0.95,
  bootstrap = FALSE,
  iterations = 1000,
  component = c("all", "conditional", "extra"),
  standardize = NULL,
  exponentiate = FALSE,
  p_adjust = NULL,
  keep = NULL,
  drop = NULL,
  verbose = TRUE,
  ...
)

## S3 method for class 'marginaleffects'
model_parameters(model, ci = 0.95, exponentiate = FALSE, ...)

## S3 method for class 'metaplus'
model_parameters(
  model,
  ci = 0.95,
  bootstrap = FALSE,
  iterations = 1000,
  standardize = NULL,
  exponentiate = FALSE,
  include_studies = TRUE,
  keep = NULL,
  drop = NULL,
  verbose = TRUE,
  ...
)

## S3 method for class 'meta_random'
model_parameters(
  model,
  ci = 0.95,
  ci_method = "eti",
  exponentiate = FALSE,
  include_studies = TRUE,
  verbose = TRUE,
  ...
)

## S3 method for class 'meta_bma'
model_parameters(
  model,
  ci = 0.95,
  ci_method = "eti",
  exponentiate = FALSE,
  include_studies = TRUE,
  verbose = TRUE,
  ...
)

## S3 method for class 'betaor'
model_parameters(
  model,
  ci = 0.95,
  bootstrap = FALSE,
  iterations = 1000,
  component = c("conditional", "precision", "all"),
  standardize = NULL,
  exponentiate = FALSE,
  p_adjust = NULL,
  verbose = TRUE,
  ...
)

## S3 method for class 'betamfx'
model_parameters(
  model,
  ci = 0.95,
  bootstrap = FALSE,
  iterations = 1000,
  component = c("all", "conditional", "precision", "marginal"),
  standardize = NULL,
  exponentiate = FALSE,
  p_adjust = NULL,
  keep = NULL,
  drop = NULL,
  verbose = TRUE,
  ...
)

## S3 method for class 'mjoint'
model_parameters(
  model,
  ci = 0.95,
  effects = "fixed",
  component = c("all", "conditional", "survival"),
  exponentiate = FALSE,
  p_adjust = NULL,
  keep = NULL,
  drop = NULL,
  verbose = TRUE,
  ...
)

## S3 method for class 'mvord'
model_parameters(
  model,
  ci = 0.95,
  component = c("all", "conditional", "thresholds", "correlation"),
  standardize = NULL,
  exponentiate = FALSE,
  p_adjust = NULL,
  summary = getOption("parameters_summary", FALSE),
  keep = NULL,
  drop = NULL,
  verbose = TRUE,
  ...
)

## S3 method for class 'selection'
model_parameters(
  model,
  ci = 0.95,
  component = c("all", "selection", "outcome", "auxiliary"),
  bootstrap = FALSE,
  iterations = 1000,
  standardize = NULL,
  exponentiate = FALSE,
  p_adjust = NULL,
  summary = getOption("parameters_summary", FALSE),
  keep = NULL,
  drop = NULL,
  verbose = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="model_parameters.glimML_+3A_model">model</code></td>
<td>
<p>Model object.</p>
</td></tr>
<tr><td><code id="model_parameters.glimML_+3A_ci">ci</code></td>
<td>
<p>Confidence Interval (CI) level. Default to <code>0.95</code> (<code style="white-space: pre;">&#8288;95%&#8288;</code>).</p>
</td></tr>
<tr><td><code id="model_parameters.glimML_+3A_bootstrap">bootstrap</code></td>
<td>
<p>Should estimates be based on bootstrapped model? If
<code>TRUE</code>, then arguments of <a href="#topic+model_parameters.stanreg">Bayesian regressions</a> apply (see also
<code><a href="#topic+bootstrap_parameters">bootstrap_parameters()</a></code>).</p>
</td></tr>
<tr><td><code id="model_parameters.glimML_+3A_iterations">iterations</code></td>
<td>
<p>The number of bootstrap replicates. This only apply in the
case of bootstrapped frequentist models.</p>
</td></tr>
<tr><td><code id="model_parameters.glimML_+3A_component">component</code></td>
<td>
<p>Model component for which parameters should be shown. May be
one of <code>"conditional"</code>, <code>"precision"</code> (<strong>betareg</strong>),
<code>"scale"</code> (<strong>ordinal</strong>), <code>"extra"</code> (<strong>glmx</strong>),
<code>"marginal"</code> (<strong>mfx</strong>), <code>"conditional"</code> or <code>"full"</code> (for
<code>MuMIn::model.avg()</code>) or <code>"all"</code>.</p>
</td></tr>
<tr><td><code id="model_parameters.glimML_+3A_standardize">standardize</code></td>
<td>
<p>The method used for standardizing the parameters. Can be
<code>NULL</code> (default; no standardization), <code>"refit"</code> (for re-fitting the model
on standardized data) or one of <code>"basic"</code>, <code>"posthoc"</code>, <code>"smart"</code>,
<code>"pseudo"</code>. See 'Details' in <code><a href="#topic+standardize_parameters">standardize_parameters()</a></code>.
<strong>Importantly</strong>:
</p>

<ul>
<li><p> The <code>"refit"</code> method does <em>not</em> standardize categorical predictors (i.e.
factors), which may be a different behaviour compared to other R packages
(such as <strong>lm.beta</strong>) or other software packages (like SPSS). to mimic
such behaviours, either use <code>standardize="basic"</code> or standardize the data
with <code>datawizard::standardize(force=TRUE)</code> <em>before</em> fitting the model.
</p>
</li>
<li><p> For mixed models, when using methods other than <code>"refit"</code>, only the fixed
effects will be standardized.
</p>
</li>
<li><p> Robust estimation (i.e., <code>vcov</code> set to a value other than <code>NULL</code>) of
standardized parameters only works when <code>standardize="refit"</code>.
</p>
</li></ul>
</td></tr>
<tr><td><code id="model_parameters.glimML_+3A_exponentiate">exponentiate</code></td>
<td>
<p>Logical, indicating whether or not to exponentiate the
coefficients (and related confidence intervals). This is typical for
logistic regression, or more generally speaking, for models with log or
logit links. It is also recommended to use <code>exponentiate = TRUE</code> for models
with log-transformed response values. <strong>Note:</strong> Delta-method standard
errors are also computed (by multiplying the standard errors by the
transformed coefficients). This is to mimic behaviour of other software
packages, such as Stata, but these standard errors poorly estimate
uncertainty for the transformed coefficient. The transformed confidence
interval more clearly captures this uncertainty. For <code>compare_parameters()</code>,
<code>exponentiate = "nongaussian"</code> will only exponentiate coefficients from
non-Gaussian families.</p>
</td></tr>
<tr><td><code id="model_parameters.glimML_+3A_p_adjust">p_adjust</code></td>
<td>
<p>Character vector, if not <code>NULL</code>, indicates the method to
adjust p-values. See <code><a href="stats.html#topic+p.adjust">stats::p.adjust()</a></code> for details. Further
possible adjustment methods are <code>"tukey"</code>, <code>"scheffe"</code>,
<code>"sidak"</code> and <code>"none"</code> to explicitly disable adjustment for
<code>emmGrid</code> objects (from <strong>emmeans</strong>).</p>
</td></tr>
<tr><td><code id="model_parameters.glimML_+3A_summary">summary</code></td>
<td>
<p>Logical, if <code>TRUE</code>, prints summary information about the
model (model formula, number of observations, residual standard deviation
and more).</p>
</td></tr>
<tr><td><code id="model_parameters.glimML_+3A_keep">keep</code></td>
<td>
<p>Character containing a regular expression pattern that
describes the parameters that should be included (for <code>keep</code>) or excluded
(for <code>drop</code>) in the returned data frame. <code>keep</code> may also be a
named list of regular expressions. All non-matching parameters will be
removed from the output. If <code>keep</code> is a character vector, every parameter
name in the <em>&quot;Parameter&quot;</em> column that matches the regular expression in
<code>keep</code> will be selected from the returned data frame (and vice versa,
all parameter names matching <code>drop</code> will be excluded). Furthermore, if
<code>keep</code> has more than one element, these will be merged with an <code>OR</code>
operator into a regular expression pattern like this: <code>"(one|two|three)"</code>.
If <code>keep</code> is a named list of regular expression patterns, the names of the
list-element should equal the column name where selection should be
applied. This is useful for model objects where <code>model_parameters()</code>
returns multiple columns with parameter components, like in
<code><a href="#topic+model_parameters.lavaan">model_parameters.lavaan()</a></code>. Note that the regular expression pattern
should match the parameter names as they are stored in the returned data
frame, which can be different from how they are printed. Inspect the
<code style="white-space: pre;">&#8288;$Parameter&#8288;</code> column of the parameters table to get the exact parameter
names.</p>
</td></tr>
<tr><td><code id="model_parameters.glimML_+3A_drop">drop</code></td>
<td>
<p>See <code>keep</code>.</p>
</td></tr>
<tr><td><code id="model_parameters.glimML_+3A_verbose">verbose</code></td>
<td>
<p>Toggle warnings and messages.</p>
</td></tr>
<tr><td><code id="model_parameters.glimML_+3A_...">...</code></td>
<td>
<p>Arguments passed to or from other methods. For instance, when
<code>bootstrap = TRUE</code>, arguments like <code>type</code> or <code>parallel</code> are
passed down to <code>bootstrap_model()</code>.</p>
</td></tr>
<tr><td><code id="model_parameters.glimML_+3A_include_studies">include_studies</code></td>
<td>
<p>Logical, if <code>TRUE</code> (default), includes parameters
for all studies. Else, only parameters for overall-effects are shown.</p>
</td></tr>
<tr><td><code id="model_parameters.glimML_+3A_ci_method">ci_method</code></td>
<td>
<p>Method for computing degrees of freedom for
confidence intervals (CI) and the related p-values. Allowed are following
options (which vary depending on the model class): <code>"residual"</code>,
<code>"normal"</code>, <code>"likelihood"</code>, <code>"satterthwaite"</code>, <code>"kenward"</code>, <code>"wald"</code>,
<code>"profile"</code>, <code>"boot"</code>, <code>"uniroot"</code>, <code>"ml1"</code>, <code>"betwithin"</code>, <code>"hdi"</code>,
<code>"quantile"</code>, <code>"ci"</code>, <code>"eti"</code>, <code>"si"</code>, <code>"bci"</code>, or <code>"bcai"</code>. See section
<em>Confidence intervals and approximation of degrees of freedom</em> in
<code><a href="#topic+model_parameters">model_parameters()</a></code> for further details. When <code>ci_method=NULL</code>, in most
cases <code>"wald"</code> is used then.</p>
</td></tr>
<tr><td><code id="model_parameters.glimML_+3A_effects">effects</code></td>
<td>
<p>Should results for fixed effects, random effects or both be
returned? Only applies to mixed models. May be abbreviated.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame of indices related to the model's parameters.
</p>


<h3>See Also</h3>

<p><code><a href="insight.html#topic+standardize_names">insight::standardize_names()</a></code> to rename
columns into a consistent, standardized naming scheme.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(parameters)
if (require("brglm2", quietly = TRUE)) {
  data("stemcell")
  model &lt;- bracl(
    research ~ as.numeric(religion) + gender,
    weights = frequency,
    data = stemcell,
    type = "ML"
  )
  model_parameters(model)
}
</code></pre>

<hr>
<h2 id='model_parameters.htest'>Parameters from hypothesis tests</h2><span id='topic+model_parameters.htest'></span><span id='topic+model_parameters.coeftest'></span>

<h3>Description</h3>

<p>Parameters of h-tests (correlations, t-tests, chi-squared, ...).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'htest'
model_parameters(
  model,
  ci = 0.95,
  alternative = NULL,
  bootstrap = FALSE,
  effectsize_type = NULL,
  verbose = TRUE,
  cramers_v = NULL,
  phi = NULL,
  standardized_d = NULL,
  hedges_g = NULL,
  omega_squared = NULL,
  eta_squared = NULL,
  epsilon_squared = NULL,
  cohens_g = NULL,
  rank_biserial = NULL,
  rank_epsilon_squared = NULL,
  kendalls_w = NULL,
  ...
)

## S3 method for class 'coeftest'
model_parameters(
  model,
  ci = 0.95,
  ci_method = "wald",
  keep = NULL,
  drop = NULL,
  verbose = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="model_parameters.htest_+3A_model">model</code></td>
<td>
<p>Object of class <code>htest</code> or <code>pairwise.htest</code>.</p>
</td></tr>
<tr><td><code id="model_parameters.htest_+3A_ci">ci</code></td>
<td>
<p>Level of confidence intervals for effect size statistic. Currently
only applies to objects from <code>chisq.test()</code> or <code>oneway.test()</code>.</p>
</td></tr>
<tr><td><code id="model_parameters.htest_+3A_alternative">alternative</code></td>
<td>
<p>A character string specifying the alternative hypothesis;
Controls the type of CI returned: <code>"two.sided"</code> (default, two-sided CI),
<code>"greater"</code> or <code>"less"</code> (one-sided CI). Partial matching is allowed
(e.g., <code>"g"</code>, <code>"l"</code>, <code>"two"</code>...). See section <em>One-Sided CIs</em> in
the <a href="https://easystats.github.io/effectsize/">effectsize_CIs vignette</a>.</p>
</td></tr>
<tr><td><code id="model_parameters.htest_+3A_bootstrap">bootstrap</code></td>
<td>
<p>Should estimates be bootstrapped?</p>
</td></tr>
<tr><td><code id="model_parameters.htest_+3A_effectsize_type">effectsize_type</code></td>
<td>
<p>The effect size of interest. Not that possibly not all
effect sizes are applicable to the model object. See 'Details'. For Anova
models, can also be a character vector with multiple effect size names.</p>
</td></tr>
<tr><td><code id="model_parameters.htest_+3A_verbose">verbose</code></td>
<td>
<p>Toggle warnings and messages.</p>
</td></tr>
<tr><td><code id="model_parameters.htest_+3A_cramers_v">cramers_v</code>, <code id="model_parameters.htest_+3A_phi">phi</code>, <code id="model_parameters.htest_+3A_cohens_g">cohens_g</code>, <code id="model_parameters.htest_+3A_standardized_d">standardized_d</code>, <code id="model_parameters.htest_+3A_hedges_g">hedges_g</code>, <code id="model_parameters.htest_+3A_omega_squared">omega_squared</code>, <code id="model_parameters.htest_+3A_eta_squared">eta_squared</code>, <code id="model_parameters.htest_+3A_epsilon_squared">epsilon_squared</code>, <code id="model_parameters.htest_+3A_rank_biserial">rank_biserial</code>, <code id="model_parameters.htest_+3A_rank_epsilon_squared">rank_epsilon_squared</code>, <code id="model_parameters.htest_+3A_kendalls_w">kendalls_w</code></td>
<td>
<p>Deprecated. Please use <code>effectsize_type</code>.</p>
</td></tr>
<tr><td><code id="model_parameters.htest_+3A_...">...</code></td>
<td>
<p>Arguments passed to or from other methods. For instance, when
<code>bootstrap = TRUE</code>, arguments like <code>type</code> or <code>parallel</code> are
passed down to <code>bootstrap_model()</code>.</p>
</td></tr>
<tr><td><code id="model_parameters.htest_+3A_ci_method">ci_method</code></td>
<td>
<p>Method for computing degrees of freedom for
confidence intervals (CI) and the related p-values. Allowed are following
options (which vary depending on the model class): <code>"residual"</code>,
<code>"normal"</code>, <code>"likelihood"</code>, <code>"satterthwaite"</code>, <code>"kenward"</code>, <code>"wald"</code>,
<code>"profile"</code>, <code>"boot"</code>, <code>"uniroot"</code>, <code>"ml1"</code>, <code>"betwithin"</code>, <code>"hdi"</code>,
<code>"quantile"</code>, <code>"ci"</code>, <code>"eti"</code>, <code>"si"</code>, <code>"bci"</code>, or <code>"bcai"</code>. See section
<em>Confidence intervals and approximation of degrees of freedom</em> in
<code><a href="#topic+model_parameters">model_parameters()</a></code> for further details. When <code>ci_method=NULL</code>, in most
cases <code>"wald"</code> is used then.</p>
</td></tr>
<tr><td><code id="model_parameters.htest_+3A_keep">keep</code></td>
<td>
<p>Character containing a regular expression pattern that
describes the parameters that should be included (for <code>keep</code>) or excluded
(for <code>drop</code>) in the returned data frame. <code>keep</code> may also be a
named list of regular expressions. All non-matching parameters will be
removed from the output. If <code>keep</code> is a character vector, every parameter
name in the <em>&quot;Parameter&quot;</em> column that matches the regular expression in
<code>keep</code> will be selected from the returned data frame (and vice versa,
all parameter names matching <code>drop</code> will be excluded). Furthermore, if
<code>keep</code> has more than one element, these will be merged with an <code>OR</code>
operator into a regular expression pattern like this: <code>"(one|two|three)"</code>.
If <code>keep</code> is a named list of regular expression patterns, the names of the
list-element should equal the column name where selection should be
applied. This is useful for model objects where <code>model_parameters()</code>
returns multiple columns with parameter components, like in
<code><a href="#topic+model_parameters.lavaan">model_parameters.lavaan()</a></code>. Note that the regular expression pattern
should match the parameter names as they are stored in the returned data
frame, which can be different from how they are printed. Inspect the
<code style="white-space: pre;">&#8288;$Parameter&#8288;</code> column of the parameters table to get the exact parameter
names.</p>
</td></tr>
<tr><td><code id="model_parameters.htest_+3A_drop">drop</code></td>
<td>
<p>See <code>keep</code>.</p>
</td></tr>
</table>


<h3>Details</h3>


<ul>
<li><p> For an object of class <code>htest</code>, data is extracted via <code><a href="insight.html#topic+get_data">insight::get_data()</a></code>, and passed to the relevant function according to:
</p>

<ul>
<li><p> A <strong>t-test</strong> depending on <code>type</code>: <code>"cohens_d"</code> (default), <code>"hedges_g"</code>, or one of <code>"p_superiority"</code>, <code>"u1"</code>, <code>"u2"</code>, <code>"u3"</code>, <code>"overlap"</code>.
</p>

<ul>
<li><p> For a <strong>Paired t-test</strong>: depending on <code>type</code>: <code>"rm_rm"</code>, <code>"rm_av"</code>, <code>"rm_b"</code>, <code>"rm_d"</code>, <code>"rm_z"</code>.
</p>
</li></ul>

</li>
<li><p> A <strong>Chi-squared tests of independence</strong> or <strong>Fisher's Exact Test</strong>, depending on <code>type</code>: <code>"cramers_v"</code> (default), <code>"tschuprows_t"</code>, <code>"phi"</code>, <code>"cohens_w"</code>, <code>"pearsons_c"</code>, <code>"cohens_h"</code>, <code>"oddsratio"</code>, <code>"riskratio"</code>, <code>"arr"</code>, or <code>"nnt"</code>.
</p>
</li>
<li><p> A <strong>Chi-squared tests of goodness-of-fit</strong>, depending on <code>type</code>: <code>"fei"</code> (default) <code>"cohens_w"</code>, <code>"pearsons_c"</code>
</p>
</li>
<li><p> A <strong>One-way ANOVA test</strong>, depending on <code>type</code>: <code>"eta"</code> (default), <code>"omega"</code> or <code>"epsilon"</code> -squared, <code>"f"</code>, or <code>"f2"</code>.
</p>
</li>
<li><p> A <strong>McNemar test</strong> returns <em>Cohen's g</em>.
</p>
</li>
<li><p> A <strong>Wilcoxon test</strong> depending on <code>type</code>: returns &quot;<code>rank_biserial</code>&quot; correlation (default) or one of <code>"p_superiority"</code>, <code>"vda"</code>, <code>"u2"</code>, <code>"u3"</code>, <code>"overlap"</code>.
</p>
</li>
<li><p> A <strong>Kruskal-Wallis test</strong> depending on <code>type</code>: <code>"epsilon"</code> (default) or <code>"eta"</code>.
</p>
</li>
<li><p> A <strong>Friedman test</strong> returns <em>Kendall's W</em>.
(Where applicable, <code>ci</code> and <code>alternative</code> are taken from the <code>htest</code> if not otherwise provided.)
</p>
</li></ul>

</li>
<li><p> For an object of class <code>BFBayesFactor</code>, using <code><a href="bayestestR.html#topic+describe_posterior">bayestestR::describe_posterior()</a></code>,
</p>

<ul>
<li><p> A <strong>t-test</strong> depending on <code>type</code>: <code>"cohens_d"</code> (default) or one of <code>"p_superiority"</code>, <code>"u1"</code>, <code>"u2"</code>, <code>"u3"</code>, <code>"overlap"</code>.
</p>
</li>
<li><p> A <strong>correlation test</strong> returns <em>r</em>.
</p>
</li>
<li><p> A <strong>contingency table test</strong>, depending on <code>type</code>: <code>"cramers_v"</code> (default), <code>"phi"</code>, <code>"tschuprows_t"</code>, <code>"cohens_w"</code>, <code>"pearsons_c"</code>, <code>"cohens_h"</code>, <code>"oddsratio"</code>, or <code>"riskratio"</code>, <code>"arr"</code>, or <code>"nnt"</code>.
</p>
</li>
<li><p> A <strong>proportion test</strong> returns <em>p</em>.
</p>
</li></ul>

</li>
<li><p> Objects of class <code>anova</code>, <code>aov</code>, <code>aovlist</code> or <code>afex_aov</code>, depending on <code>type</code>: <code>"eta"</code> (default), <code>"omega"</code> or <code>"epsilon"</code> -squared, <code>"f"</code>, or <code>"f2"</code>.
</p>
</li>
<li><p> Other objects are passed to <code><a href="#topic+standardize_parameters">parameters::standardize_parameters()</a></code>.
</p>
</li></ul>

<p><strong>For statistical models it is recommended to directly use the listed
functions, for the full range of options they provide.</strong>
</p>


<h3>Value</h3>

<p>A data frame of indices related to the model's parameters.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
model &lt;- cor.test(mtcars$mpg, mtcars$cyl, method = "pearson")
model_parameters(model)

model &lt;- t.test(iris$Sepal.Width, iris$Sepal.Length)
model_parameters(model, effectsize_type = "hedges_g")

model &lt;- t.test(mtcars$mpg ~ mtcars$vs)
model_parameters(model, effectsize_type = "hedges_g")

model &lt;- t.test(iris$Sepal.Width, mu = 1)
model_parameters(model, effectsize_type = "cohens_d")

data(airquality)
airquality$Month &lt;- factor(airquality$Month, labels = month.abb[5:9])
model &lt;- pairwise.t.test(airquality$Ozone, airquality$Month)
model_parameters(model)

smokers &lt;- c(83, 90, 129, 70)
patients &lt;- c(86, 93, 136, 82)
model &lt;- suppressWarnings(pairwise.prop.test(smokers, patients))
model_parameters(model)

model &lt;- suppressWarnings(chisq.test(table(mtcars$am, mtcars$cyl)))
model_parameters(model, effectsize_type = "cramers_v")

</code></pre>

<hr>
<h2 id='model_parameters.MCMCglmm'>Parameters from Bayesian Models</h2><span id='topic+model_parameters.MCMCglmm'></span><span id='topic+model_parameters.data.frame'></span><span id='topic+model_parameters.brmsfit'></span><span id='topic+model_parameters.draws'></span><span id='topic+model_parameters.stanreg'></span>

<h3>Description</h3>

<p>Parameters from Bayesian models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'MCMCglmm'
model_parameters(
  model,
  centrality = "median",
  dispersion = FALSE,
  ci = 0.95,
  ci_method = "eti",
  test = "pd",
  rope_range = "default",
  rope_ci = 0.95,
  bf_prior = NULL,
  diagnostic = c("ESS", "Rhat"),
  priors = TRUE,
  keep = NULL,
  drop = NULL,
  verbose = TRUE,
  ...
)

## S3 method for class 'data.frame'
model_parameters(model, as_draws = FALSE, verbose = TRUE, ...)

## S3 method for class 'brmsfit'
model_parameters(
  model,
  centrality = "median",
  dispersion = FALSE,
  ci = 0.95,
  ci_method = "eti",
  test = "pd",
  rope_range = "default",
  rope_ci = 0.95,
  bf_prior = NULL,
  diagnostic = c("ESS", "Rhat"),
  priors = FALSE,
  effects = "fixed",
  component = "all",
  exponentiate = FALSE,
  standardize = NULL,
  group_level = FALSE,
  keep = NULL,
  drop = NULL,
  verbose = TRUE,
  ...
)

## S3 method for class 'draws'
model_parameters(
  model,
  centrality = "median",
  dispersion = FALSE,
  ci = 0.95,
  ci_method = "eti",
  test = "pd",
  rope_range = "default",
  rope_ci = 0.95,
  keep = NULL,
  drop = NULL,
  verbose = TRUE,
  ...
)

## S3 method for class 'stanreg'
model_parameters(
  model,
  centrality = "median",
  dispersion = FALSE,
  ci = 0.95,
  ci_method = "eti",
  test = "pd",
  rope_range = "default",
  rope_ci = 0.95,
  bf_prior = NULL,
  diagnostic = c("ESS", "Rhat"),
  priors = TRUE,
  effects = "fixed",
  exponentiate = FALSE,
  standardize = NULL,
  group_level = FALSE,
  keep = NULL,
  drop = NULL,
  verbose = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="model_parameters.MCMCglmm_+3A_model">model</code></td>
<td>
<p>Bayesian model (including SEM from <strong>blavaan</strong>. May also be
a data frame with posterior samples, however, <code>as_draws</code> must be set to
<code>TRUE</code> (else, for data frames <code>NULL</code> is returned).</p>
</td></tr>
<tr><td><code id="model_parameters.MCMCglmm_+3A_centrality">centrality</code></td>
<td>
<p>The point-estimates (centrality indices) to compute. Character
(vector) or list with one or more of these options: <code>"median"</code>, <code>"mean"</code>, <code>"MAP"</code>
(see <code><a href="bayestestR.html#topic+map_estimate">map_estimate()</a></code>), <code>"trimmed"</code> (which is just <code>mean(x, trim = threshold)</code>),
<code>"mode"</code> or <code>"all"</code>.</p>
</td></tr>
<tr><td><code id="model_parameters.MCMCglmm_+3A_dispersion">dispersion</code></td>
<td>
<p>Logical, if <code>TRUE</code>, computes indices of dispersion related
to the estimate(s) (<code>SD</code> and <code>MAD</code> for <code>mean</code> and <code>median</code>, respectively).
Dispersion is not available for <code>"MAP"</code> or <code>"mode"</code> centrality indices.</p>
</td></tr>
<tr><td><code id="model_parameters.MCMCglmm_+3A_ci">ci</code></td>
<td>
<p>Credible Interval (CI) level. Default to <code>0.95</code> (<code style="white-space: pre;">&#8288;95%&#8288;</code>). See
<code><a href="bayestestR.html#topic+ci">bayestestR::ci()</a></code> for further details.</p>
</td></tr>
<tr><td><code id="model_parameters.MCMCglmm_+3A_ci_method">ci_method</code></td>
<td>
<p>Method for computing degrees of freedom for
confidence intervals (CI) and the related p-values. Allowed are following
options (which vary depending on the model class): <code>"residual"</code>,
<code>"normal"</code>, <code>"likelihood"</code>, <code>"satterthwaite"</code>, <code>"kenward"</code>, <code>"wald"</code>,
<code>"profile"</code>, <code>"boot"</code>, <code>"uniroot"</code>, <code>"ml1"</code>, <code>"betwithin"</code>, <code>"hdi"</code>,
<code>"quantile"</code>, <code>"ci"</code>, <code>"eti"</code>, <code>"si"</code>, <code>"bci"</code>, or <code>"bcai"</code>. See section
<em>Confidence intervals and approximation of degrees of freedom</em> in
<code><a href="#topic+model_parameters">model_parameters()</a></code> for further details. When <code>ci_method=NULL</code>, in most
cases <code>"wald"</code> is used then.</p>
</td></tr>
<tr><td><code id="model_parameters.MCMCglmm_+3A_test">test</code></td>
<td>
<p>The indices of effect existence to compute. Character (vector) or
list with one or more of these options: <code>"p_direction"</code> (or <code>"pd"</code>),
<code>"rope"</code>, <code>"p_map"</code>, <code>"equivalence_test"</code> (or <code>"equitest"</code>),
<code>"bayesfactor"</code> (or <code>"bf"</code>) or <code>"all"</code> to compute all tests.
For each &quot;test&quot;, the corresponding <span class="pkg">bayestestR</span> function is called
(e.g. <code><a href="bayestestR.html#topic+rope">rope()</a></code> or <code><a href="bayestestR.html#topic+p_direction">p_direction()</a></code>) and its results
included in the summary output.</p>
</td></tr>
<tr><td><code id="model_parameters.MCMCglmm_+3A_rope_range">rope_range</code></td>
<td>
<p>ROPE's lower and higher bounds. Should be a list of two
values (e.g., <code>c(-0.1, 0.1)</code>) or <code>"default"</code>. If <code>"default"</code>,
the bounds are set to <code>x +- 0.1*SD(response)</code>.</p>
</td></tr>
<tr><td><code id="model_parameters.MCMCglmm_+3A_rope_ci">rope_ci</code></td>
<td>
<p>The Credible Interval (CI) probability, corresponding to the
proportion of HDI, to use for the percentage in ROPE.</p>
</td></tr>
<tr><td><code id="model_parameters.MCMCglmm_+3A_bf_prior">bf_prior</code></td>
<td>
<p>Distribution representing a prior for the computation of
Bayes factors / SI. Used if the input is a posterior, otherwise (in the
case of models) ignored.</p>
</td></tr>
<tr><td><code id="model_parameters.MCMCglmm_+3A_diagnostic">diagnostic</code></td>
<td>
<p>Diagnostic metrics to compute.  Character (vector) or list
with one or more of these options: <code>"ESS"</code>, <code>"Rhat"</code>, <code>"MCSE"</code> or <code>"all"</code>.</p>
</td></tr>
<tr><td><code id="model_parameters.MCMCglmm_+3A_priors">priors</code></td>
<td>
<p>Add the prior used for each parameter.</p>
</td></tr>
<tr><td><code id="model_parameters.MCMCglmm_+3A_keep">keep</code></td>
<td>
<p>Character containing a regular expression pattern that
describes the parameters that should be included (for <code>keep</code>) or excluded
(for <code>drop</code>) in the returned data frame. <code>keep</code> may also be a
named list of regular expressions. All non-matching parameters will be
removed from the output. If <code>keep</code> is a character vector, every parameter
name in the <em>&quot;Parameter&quot;</em> column that matches the regular expression in
<code>keep</code> will be selected from the returned data frame (and vice versa,
all parameter names matching <code>drop</code> will be excluded). Furthermore, if
<code>keep</code> has more than one element, these will be merged with an <code>OR</code>
operator into a regular expression pattern like this: <code>"(one|two|three)"</code>.
If <code>keep</code> is a named list of regular expression patterns, the names of the
list-element should equal the column name where selection should be
applied. This is useful for model objects where <code>model_parameters()</code>
returns multiple columns with parameter components, like in
<code><a href="#topic+model_parameters.lavaan">model_parameters.lavaan()</a></code>. Note that the regular expression pattern
should match the parameter names as they are stored in the returned data
frame, which can be different from how they are printed. Inspect the
<code style="white-space: pre;">&#8288;$Parameter&#8288;</code> column of the parameters table to get the exact parameter
names.</p>
</td></tr>
<tr><td><code id="model_parameters.MCMCglmm_+3A_drop">drop</code></td>
<td>
<p>See <code>keep</code>.</p>
</td></tr>
<tr><td><code id="model_parameters.MCMCglmm_+3A_verbose">verbose</code></td>
<td>
<p>Toggle messages and warnings.</p>
</td></tr>
<tr><td><code id="model_parameters.MCMCglmm_+3A_...">...</code></td>
<td>
<p>Currently not used.</p>
</td></tr>
<tr><td><code id="model_parameters.MCMCglmm_+3A_as_draws">as_draws</code></td>
<td>
<p>Logical, if <code>TRUE</code> and <code>model</code> is of class <code>data.frame</code>,
the data frame is treated as posterior samples and handled similar to
Bayesian models. All arguments in <code>...</code> are passed to
<code>model_parameters.draws()</code>.</p>
</td></tr>
<tr><td><code id="model_parameters.MCMCglmm_+3A_effects">effects</code></td>
<td>
<p>Should results for fixed effects, random effects or both be
returned? Only applies to mixed models. May be abbreviated.</p>
</td></tr>
<tr><td><code id="model_parameters.MCMCglmm_+3A_component">component</code></td>
<td>
<p>Which type of parameters to return, such as parameters for the
conditional model, the zero-inflation part of the model, the dispersion
term, or other auxiliary parameters be returned? Applies to models with
zero-inflation and/or dispersion formula, or if parameters such as <code>sigma</code>
should be included. May be abbreviated. Note that the <em>conditional</em>
component is also called <em>count</em> or <em>mean</em> component, depending on the
model. There are three convenient shortcuts: <code>component = "all"</code> returns
all possible parameters. If <code>component = "location"</code>, location parameters
such as <code>conditional</code>, <code>zero_inflated</code>, or <code>smooth_terms</code>, are returned
(everything that are fixed or random effects - depending on the <code>effects</code>
argument - but no auxiliary parameters). For <code>component = "distributional"</code>
(or <code>"auxiliary"</code>), components like <code>sigma</code>, <code>dispersion</code>, or <code>beta</code>
(and other auxiliary parameters) are returned.</p>
</td></tr>
<tr><td><code id="model_parameters.MCMCglmm_+3A_exponentiate">exponentiate</code></td>
<td>
<p>Logical, indicating whether or not to exponentiate the
coefficients (and related confidence intervals). This is typical for
logistic regression, or more generally speaking, for models with log or
logit links. It is also recommended to use <code>exponentiate = TRUE</code> for models
with log-transformed response values. <strong>Note:</strong> Delta-method standard
errors are also computed (by multiplying the standard errors by the
transformed coefficients). This is to mimic behaviour of other software
packages, such as Stata, but these standard errors poorly estimate
uncertainty for the transformed coefficient. The transformed confidence
interval more clearly captures this uncertainty. For <code>compare_parameters()</code>,
<code>exponentiate = "nongaussian"</code> will only exponentiate coefficients from
non-Gaussian families.</p>
</td></tr>
<tr><td><code id="model_parameters.MCMCglmm_+3A_standardize">standardize</code></td>
<td>
<p>The method used for standardizing the parameters. Can be
<code>NULL</code> (default; no standardization), <code>"refit"</code> (for re-fitting the model
on standardized data) or one of <code>"basic"</code>, <code>"posthoc"</code>, <code>"smart"</code>,
<code>"pseudo"</code>. See 'Details' in <code><a href="#topic+standardize_parameters">standardize_parameters()</a></code>.
<strong>Importantly</strong>:
</p>

<ul>
<li><p> The <code>"refit"</code> method does <em>not</em> standardize categorical predictors (i.e.
factors), which may be a different behaviour compared to other R packages
(such as <strong>lm.beta</strong>) or other software packages (like SPSS). to mimic
such behaviours, either use <code>standardize="basic"</code> or standardize the data
with <code>datawizard::standardize(force=TRUE)</code> <em>before</em> fitting the model.
</p>
</li>
<li><p> For mixed models, when using methods other than <code>"refit"</code>, only the fixed
effects will be standardized.
</p>
</li>
<li><p> Robust estimation (i.e., <code>vcov</code> set to a value other than <code>NULL</code>) of
standardized parameters only works when <code>standardize="refit"</code>.
</p>
</li></ul>
</td></tr>
<tr><td><code id="model_parameters.MCMCglmm_+3A_group_level">group_level</code></td>
<td>
<p>Logical, for multilevel models (i.e. models with random
effects) and when <code>effects = "all"</code> or <code>effects = "random"</code>,
include the parameters for each group level from random effects. If
<code>group_level = FALSE</code> (the default), only information on SD and COR
are shown.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame of indices related to the model's parameters.
</p>


<h3>Confidence intervals and approximation of degrees of freedom</h3>

<p>There are different ways of approximating the degrees of freedom depending
on different assumptions about the nature of the model and its sampling
distribution. The <code>ci_method</code> argument modulates the method for computing degrees
of freedom (df) that are used to calculate confidence intervals (CI) and the
related p-values. Following options are allowed, depending on the model
class:
</p>
<p><strong>Classical methods:</strong>
</p>
<p>Classical inference is generally based on the <strong>Wald method</strong>.
The Wald approach to inference computes a test statistic by dividing the
parameter estimate by its standard error (Coefficient / SE),
then comparing this statistic against a t- or normal distribution.
This approach can be used to compute CIs and p-values.
</p>
<p><code>"wald"</code>:
</p>

<ul>
<li><p> Applies to <em>non-Bayesian models</em>. For <em>linear models</em>, CIs
computed using the Wald method (SE and a <em>t-distribution with residual df</em>);
p-values computed using the Wald method with a <em>t-distribution with residual df</em>.
For other models, CIs computed using the Wald method (SE and a <em>normal distribution</em>);
p-values computed using the Wald method with a <em>normal distribution</em>.
</p>
</li></ul>

<p><code>"normal"</code>
</p>

<ul>
<li><p> Applies to <em>non-Bayesian models</em>. Compute Wald CIs and p-values,
but always use a normal distribution.
</p>
</li></ul>

<p><code>"residual"</code>
</p>

<ul>
<li><p> Applies to <em>non-Bayesian models</em>. Compute Wald CIs and p-values,
but always use a <em>t-distribution with residual df</em> when possible. If the
residual df for a model cannot be determined, a normal distribution is
used instead.
</p>
</li></ul>

<p><strong>Methods for mixed models:</strong>
</p>
<p>Compared to fixed effects (or single-level) models, determining appropriate
df for Wald-based inference in mixed models is more difficult.
See <a href="https://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#what-are-the-p-values-listed-by-summaryglmerfit-etc.-are-they-reliable">the R GLMM FAQ</a>
for a discussion.
</p>
<p>Several approximate methods for computing df are available, but you should
also consider instead using profile likelihood (<code>"profile"</code>) or bootstrap (&quot;<code style="white-space: pre;">&#8288;boot"&#8288;</code>)
CIs and p-values instead.
</p>
<p><code>"satterthwaite"</code>
</p>

<ul>
<li><p> Applies to <em>linear mixed models</em>. CIs computed using the
Wald method (SE and a <em>t-distribution with Satterthwaite df</em>); p-values
computed using the Wald method with a <em>t-distribution with Satterthwaite df</em>.
</p>
</li></ul>

<p><code>"kenward"</code>
</p>

<ul>
<li><p> Applies to <em>linear mixed models</em>. CIs computed using the Wald
method (<em>Kenward-Roger SE</em> and a <em>t-distribution with Kenward-Roger df</em>);
p-values computed using the Wald method with <em>Kenward-Roger SE and t-distribution with Kenward-Roger df</em>.
</p>
</li></ul>

<p><code>"ml1"</code>
</p>

<ul>
<li><p> Applies to <em>linear mixed models</em>. CIs computed using the Wald
method (SE and a <em>t-distribution with m-l-1 approximated df</em>); p-values
computed using the Wald method with a <em>t-distribution with m-l-1 approximated df</em>.
See <code><a href="#topic+ci_ml1">ci_ml1()</a></code>.
</p>
</li></ul>

<p><code>"betwithin"</code>
</p>

<ul>
<li><p> Applies to <em>linear mixed models</em> and <em>generalized linear mixed models</em>.
CIs computed using the Wald method (SE and a <em>t-distribution with between-within df</em>);
p-values computed using the Wald method with a <em>t-distribution with between-within df</em>.
See <code><a href="#topic+ci_betwithin">ci_betwithin()</a></code>.
</p>
</li></ul>

<p><strong>Likelihood-based methods:</strong>
</p>
<p>Likelihood-based inference is based on comparing the likelihood for the
maximum-likelihood estimate to the the likelihood for models with one or more
parameter values changed (e.g., set to zero or a range of alternative values).
Likelihood ratios for the maximum-likelihood and alternative models are compared
to a <code class="reqn">\chi</code>-squared distribution to compute CIs and p-values.
</p>
<p><code>"profile"</code>
</p>

<ul>
<li><p> Applies to <em>non-Bayesian models</em> of class <code>glm</code>, <code>polr</code>, <code>merMod</code> or <code>glmmTMB</code>.
CIs computed by <em>profiling the likelihood curve for a parameter</em>, using
linear interpolation to find where likelihood ratio equals a critical value;
p-values computed using the Wald method with a <em>normal-distribution</em> (note:
this might change in a future update!)
</p>
</li></ul>

<p><code>"uniroot"</code>
</p>

<ul>
<li><p> Applies to <em>non-Bayesian models</em> of class <code>glmmTMB</code>. CIs
computed by <em>profiling the likelihood curve for a parameter</em>, using root
finding to find where likelihood ratio equals a critical value; p-values
computed using the Wald method with a <em>normal-distribution</em> (note: this
might change in a future update!)
</p>
</li></ul>

<p><strong>Methods for bootstrapped or Bayesian models:</strong>
</p>
<p>Bootstrap-based inference is based on <strong>resampling</strong> and refitting the model
to the resampled datasets. The distribution of parameter estimates across
resampled datasets is used to approximate the parameter's sampling
distribution. Depending on the type of model, several different methods for
bootstrapping and constructing CIs and p-values from the bootstrap
distribution are available.
</p>
<p>For Bayesian models, inference is based on drawing samples from the model
posterior distribution.
</p>
<p><code>"quantile"</code> (or <code>"eti"</code>)
</p>

<ul>
<li><p> Applies to <em>all models (including Bayesian models)</em>.
For non-Bayesian models, only applies if <code>bootstrap = TRUE</code>. CIs computed
as <em>equal tailed intervals</em> using the quantiles of the bootstrap or
posterior samples; p-values are based on the <em>probability of direction</em>.
See <code><a href="bayestestR.html#topic+eti">bayestestR::eti()</a></code>.
</p>
</li></ul>

<p><code>"hdi"</code>
</p>

<ul>
<li><p> Applies to <em>all models (including Bayesian models)</em>. For non-Bayesian
models, only applies if <code>bootstrap = TRUE</code>. CIs computed as <em>highest density intervals</em>
for the bootstrap or posterior samples; p-values are based on the <em>probability of direction</em>.
See <code><a href="bayestestR.html#topic+hdi">bayestestR::hdi()</a></code>.
</p>
</li></ul>

<p><code>"bci"</code> (or <code>"bcai"</code>)
</p>

<ul>
<li><p> Applies to <em>all models (including Bayesian models)</em>.
For non-Bayesian models, only applies if <code>bootstrap = TRUE</code>. CIs computed
as <em>bias corrected and accelerated intervals</em> for the bootstrap or
posterior samples; p-values are based on the <em>probability of direction</em>.
See <code><a href="bayestestR.html#topic+bci">bayestestR::bci()</a></code>.
</p>
</li></ul>

<p><code>"si"</code>
</p>

<ul>
<li><p> Applies to <em>Bayesian models</em> with proper priors. CIs computed as
<em>support intervals</em> comparing the posterior samples against the prior samples;
p-values are based on the <em>probability of direction</em>. See <code><a href="bayestestR.html#topic+si">bayestestR::si()</a></code>.
</p>
</li></ul>

<p><code>"boot"</code>
</p>

<ul>
<li><p> Applies to <em>non-Bayesian models</em> of class <code>merMod</code>. CIs computed
using <em>parametric bootstrapping</em> (simulating data from the fitted model);
p-values computed using the Wald method with a <em>normal-distribution)</em>
(note: this might change in a future update!).
</p>
</li></ul>

<p>For all iteration-based methods other than <code>"boot"</code>
(<code>"hdi"</code>, <code>"quantile"</code>, <code>"ci"</code>, <code>"eti"</code>, <code>"si"</code>, <code>"bci"</code>, <code>"bcai"</code>),
p-values are based on the probability of direction (<code><a href="bayestestR.html#topic+p_direction">bayestestR::p_direction()</a></code>),
which is converted into a p-value using <code><a href="bayestestR.html#topic+pd_to_p">bayestestR::pd_to_p()</a></code>.
</p>


<h3>Note</h3>

<p>When <code>standardize = "refit"</code>, columns <code>diagnostic</code>,
<code>bf_prior</code> and <code>priors</code> refer to the <em>original</em>
<code>model</code>. If <code>model</code> is a data frame, arguments <code>diagnostic</code>,
<code>bf_prior</code> and <code>priors</code> are ignored. <br /> <br /> There is also a
<a href="https://easystats.github.io/see/articles/parameters.html"><code>plot()</code>-method</a>
implemented in the
<a href="https://easystats.github.io/see/"><strong>see</strong>-package</a>.
</p>


<h3>See Also</h3>

<p><code><a href="insight.html#topic+standardize_names">insight::standardize_names()</a></code> to
rename columns into a consistent, standardized naming scheme.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(parameters)
if (require("rstanarm")) {
  model &lt;- suppressWarnings(stan_glm(
    Sepal.Length ~ Petal.Length * Species,
    data = iris, iter = 500, refresh = 0
  ))
  model_parameters(model)
}

</code></pre>

<hr>
<h2 id='model_parameters.mipo'>Parameters from multiply imputed repeated analyses</h2><span id='topic+model_parameters.mipo'></span><span id='topic+model_parameters.mira'></span>

<h3>Description</h3>

<p>Format models of class <code>mira</code>, obtained from <code>mice::width.mids()</code>, or of
class <code>mipo</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'mipo'
model_parameters(
  model,
  ci = 0.95,
  exponentiate = FALSE,
  p_adjust = NULL,
  keep = NULL,
  drop = NULL,
  verbose = TRUE,
  ...
)

## S3 method for class 'mira'
model_parameters(
  model,
  ci = 0.95,
  exponentiate = FALSE,
  p_adjust = NULL,
  keep = NULL,
  drop = NULL,
  verbose = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="model_parameters.mipo_+3A_model">model</code></td>
<td>
<p>An object of class <code>mira</code> or <code>mipo</code>.</p>
</td></tr>
<tr><td><code id="model_parameters.mipo_+3A_ci">ci</code></td>
<td>
<p>Confidence Interval (CI) level. Default to <code>0.95</code> (<code style="white-space: pre;">&#8288;95%&#8288;</code>).</p>
</td></tr>
<tr><td><code id="model_parameters.mipo_+3A_exponentiate">exponentiate</code></td>
<td>
<p>Logical, indicating whether or not to exponentiate the
coefficients (and related confidence intervals). This is typical for
logistic regression, or more generally speaking, for models with log or
logit links. It is also recommended to use <code>exponentiate = TRUE</code> for models
with log-transformed response values. <strong>Note:</strong> Delta-method standard
errors are also computed (by multiplying the standard errors by the
transformed coefficients). This is to mimic behaviour of other software
packages, such as Stata, but these standard errors poorly estimate
uncertainty for the transformed coefficient. The transformed confidence
interval more clearly captures this uncertainty. For <code>compare_parameters()</code>,
<code>exponentiate = "nongaussian"</code> will only exponentiate coefficients from
non-Gaussian families.</p>
</td></tr>
<tr><td><code id="model_parameters.mipo_+3A_p_adjust">p_adjust</code></td>
<td>
<p>Character vector, if not <code>NULL</code>, indicates the method to
adjust p-values. See <code><a href="stats.html#topic+p.adjust">stats::p.adjust()</a></code> for details. Further
possible adjustment methods are <code>"tukey"</code>, <code>"scheffe"</code>,
<code>"sidak"</code> and <code>"none"</code> to explicitly disable adjustment for
<code>emmGrid</code> objects (from <strong>emmeans</strong>).</p>
</td></tr>
<tr><td><code id="model_parameters.mipo_+3A_keep">keep</code></td>
<td>
<p>Character containing a regular expression pattern that
describes the parameters that should be included (for <code>keep</code>) or excluded
(for <code>drop</code>) in the returned data frame. <code>keep</code> may also be a
named list of regular expressions. All non-matching parameters will be
removed from the output. If <code>keep</code> is a character vector, every parameter
name in the <em>&quot;Parameter&quot;</em> column that matches the regular expression in
<code>keep</code> will be selected from the returned data frame (and vice versa,
all parameter names matching <code>drop</code> will be excluded). Furthermore, if
<code>keep</code> has more than one element, these will be merged with an <code>OR</code>
operator into a regular expression pattern like this: <code>"(one|two|three)"</code>.
If <code>keep</code> is a named list of regular expression patterns, the names of the
list-element should equal the column name where selection should be
applied. This is useful for model objects where <code>model_parameters()</code>
returns multiple columns with parameter components, like in
<code><a href="#topic+model_parameters.lavaan">model_parameters.lavaan()</a></code>. Note that the regular expression pattern
should match the parameter names as they are stored in the returned data
frame, which can be different from how they are printed. Inspect the
<code style="white-space: pre;">&#8288;$Parameter&#8288;</code> column of the parameters table to get the exact parameter
names.</p>
</td></tr>
<tr><td><code id="model_parameters.mipo_+3A_drop">drop</code></td>
<td>
<p>See <code>keep</code>.</p>
</td></tr>
<tr><td><code id="model_parameters.mipo_+3A_verbose">verbose</code></td>
<td>
<p>Toggle warnings and messages.</p>
</td></tr>
<tr><td><code id="model_parameters.mipo_+3A_...">...</code></td>
<td>
<p>Arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>model_parameters()</code> for objects of class <code>mira</code> works
similar to <code>summary(mice::pool())</code>, i.e. it generates the pooled summary
of multiple imputed repeated regression analyses.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(parameters)
if (require("mice", quietly = TRUE)) {
  data(nhanes2)
  imp &lt;- mice(nhanes2)
  fit &lt;- with(data = imp, exp = lm(bmi ~ age + hyp + chl))
  model_parameters(fit)
}

# model_parameters() also works for models that have no "tidy"-method in mice
if (require("mice", quietly = TRUE) &amp;&amp; require("gee", quietly = TRUE)) {
  data(warpbreaks)
  set.seed(1234)
  warpbreaks$tension[sample(1:nrow(warpbreaks), size = 10)] &lt;- NA
  imp &lt;- mice(warpbreaks)
  fit &lt;- with(data = imp, expr = gee(breaks ~ tension, id = wool))

  # does not work:
  # summary(pool(fit))

  model_parameters(fit)
}




# and it works with pooled results
if (require("mice")) {
  data("nhanes2")
  imp &lt;- mice(nhanes2)
  fit &lt;- with(data = imp, exp = lm(bmi ~ age + hyp + chl))
  pooled &lt;- pool(fit)

  model_parameters(pooled)
}
</code></pre>

<hr>
<h2 id='model_parameters.PCA'>Parameters from PCA, FA, CFA, SEM</h2><span id='topic+model_parameters.PCA'></span><span id='topic+model_parameters.lavaan'></span><span id='topic+model_parameters.principal'></span>

<h3>Description</h3>

<p>Format structural models from the <strong>psych</strong> or <strong>FactoMineR</strong> packages.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'PCA'
model_parameters(
  model,
  sort = FALSE,
  threshold = NULL,
  labels = NULL,
  verbose = TRUE,
  ...
)

## S3 method for class 'lavaan'
model_parameters(
  model,
  ci = 0.95,
  standardize = FALSE,
  component = c("regression", "correlation", "loading", "defined"),
  keep = NULL,
  drop = NULL,
  verbose = TRUE,
  ...
)

## S3 method for class 'principal'
model_parameters(
  model,
  sort = FALSE,
  threshold = NULL,
  labels = NULL,
  verbose = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="model_parameters.PCA_+3A_model">model</code></td>
<td>
<p>Model object.</p>
</td></tr>
<tr><td><code id="model_parameters.PCA_+3A_sort">sort</code></td>
<td>
<p>Sort the loadings.</p>
</td></tr>
<tr><td><code id="model_parameters.PCA_+3A_threshold">threshold</code></td>
<td>
<p>A value between 0 and 1 indicates which (absolute) values
from the loadings should be removed. An integer higher than 1 indicates the
n strongest loadings to retain. Can also be <code>"max"</code>, in which case it
will only display the maximum loading per variable (the most simple
structure).</p>
</td></tr>
<tr><td><code id="model_parameters.PCA_+3A_labels">labels</code></td>
<td>
<p>A character vector containing labels to be added to the
loadings data. Usually, the question related to the item.</p>
</td></tr>
<tr><td><code id="model_parameters.PCA_+3A_verbose">verbose</code></td>
<td>
<p>Toggle warnings and messages.</p>
</td></tr>
<tr><td><code id="model_parameters.PCA_+3A_...">...</code></td>
<td>
<p>Arguments passed to or from other methods.</p>
</td></tr>
<tr><td><code id="model_parameters.PCA_+3A_ci">ci</code></td>
<td>
<p>Confidence Interval (CI) level. Default to <code>0.95</code> (<code style="white-space: pre;">&#8288;95%&#8288;</code>).</p>
</td></tr>
<tr><td><code id="model_parameters.PCA_+3A_standardize">standardize</code></td>
<td>
<p>Return standardized parameters (standardized coefficients).
Can be <code>TRUE</code> (or <code>"all"</code> or <code>"std.all"</code>) for standardized
estimates based on both the variances of observed and latent variables;
<code>"latent"</code> (or <code>"std.lv"</code>) for standardized estimates based
on the variances of the latent variables only; or <code>"no_exogenous"</code>
(or <code>"std.nox"</code>) for standardized estimates based on both the
variances of observed and latent variables, but not the variances of
exogenous covariates. See <code>lavaan::standardizedsolution</code> for details.</p>
</td></tr>
<tr><td><code id="model_parameters.PCA_+3A_component">component</code></td>
<td>
<p>What type of links to return. Can be <code>"all"</code> or some of
<code>c("regression", "correlation", "loading", "variance", "mean")</code>.</p>
</td></tr>
<tr><td><code id="model_parameters.PCA_+3A_keep">keep</code></td>
<td>
<p>Character containing a regular expression pattern that
describes the parameters that should be included (for <code>keep</code>) or excluded
(for <code>drop</code>) in the returned data frame. <code>keep</code> may also be a
named list of regular expressions. All non-matching parameters will be
removed from the output. If <code>keep</code> is a character vector, every parameter
name in the <em>&quot;Parameter&quot;</em> column that matches the regular expression in
<code>keep</code> will be selected from the returned data frame (and vice versa,
all parameter names matching <code>drop</code> will be excluded). Furthermore, if
<code>keep</code> has more than one element, these will be merged with an <code>OR</code>
operator into a regular expression pattern like this: <code>"(one|two|three)"</code>.
If <code>keep</code> is a named list of regular expression patterns, the names of the
list-element should equal the column name where selection should be
applied. This is useful for model objects where <code>model_parameters()</code>
returns multiple columns with parameter components, like in
<code><a href="#topic+model_parameters.lavaan">model_parameters.lavaan()</a></code>. Note that the regular expression pattern
should match the parameter names as they are stored in the returned data
frame, which can be different from how they are printed. Inspect the
<code style="white-space: pre;">&#8288;$Parameter&#8288;</code> column of the parameters table to get the exact parameter
names.</p>
</td></tr>
<tr><td><code id="model_parameters.PCA_+3A_drop">drop</code></td>
<td>
<p>See <code>keep</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For the structural models obtained with <strong>psych</strong>, the following indices
are present:
</p>

<ul>
<li> <p><strong>Complexity</strong> (<cite>Hoffman's, 1978; Pettersson and Turkheimer,
2010</cite>) represents the number of latent components needed to account for
the observed variables. Whereas a perfect simple structure solution has a
complexity of 1 in that each item would only load on one factor, a
solution with evenly distributed items has a complexity greater than 1.
</p>
</li>
<li> <p><strong>Uniqueness</strong> represents the variance that is 'unique' to the
variable and not shared with other variables. It is equal to <code style="white-space: pre;">&#8288;1 – communality&#8288;</code> (variance that is shared with other variables). A uniqueness
of <code>0.20</code> suggests that <code style="white-space: pre;">&#8288;20%&#8288;</code> or that variable's variance is not shared
with other variables in the overall factor model. The greater 'uniqueness'
the lower the relevance of the variable in the factor model.
</p>
</li>
<li> <p><strong>MSA</strong> represents the Kaiser-Meyer-Olkin Measure of Sampling
Adequacy (<cite>Kaiser and Rice, 1974</cite>) for each item. It indicates
whether there is enough data for each factor give reliable results for the
PCA. The value should be &gt; 0.6, and desirable values are &gt; 0.8
(<cite>Tabachnick and Fidell, 2013</cite>).
</p>
</li></ul>



<h3>Value</h3>

<p>A data frame of indices or loadings.
</p>


<h3>Note</h3>

<p>There is also a
<a href="https://easystats.github.io/see/articles/parameters.html"><code>plot()</code>-method</a>
for <code>lavaan</code> models implemented in the
<a href="https://easystats.github.io/see/"><strong>see</strong>-package</a>.
</p>


<h3>References</h3>


<ul>
<li><p> Kaiser, H.F. and Rice. J. (1974). Little jiffy, mark iv. Educational and
Psychological Measurement, 34(1):111–117
</p>
</li>
<li><p> Pettersson, E., and Turkheimer, E. (2010). Item selection, evaluation, and
simple structure in personality data. Journal of research in personality,
44(4), 407-420.
</p>
</li>
<li><p> Revelle, W. (2016). How To: Use the psych package for Factor Analysis and
data reduction.
</p>
</li>
<li><p> Tabachnick, B. G., and Fidell, L. S. (2013). Using multivariate statistics
(6th ed.). Boston: Pearson Education.
</p>
</li>
<li><p> Rosseel Y (2012). lavaan: An R Package for Structural Equation
Modeling. Journal of Statistical Software, 48(2), 1-36.
</p>
</li>
<li><p> Merkle EC , Rosseel Y (2018). blavaan: Bayesian Structural Equation
Models via Parameter Expansion. Journal of Statistical Software, 85(4),
1-30. http://www.jstatsoft.org/v85/i04/
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>
library(parameters)
if (require("psych", quietly = TRUE)) {
  # Principal Component Analysis (PCA) ---------
  pca &lt;- psych::principal(attitude)
  model_parameters(pca)

  pca &lt;- psych::principal(attitude, nfactors = 3, rotate = "none")
  model_parameters(pca, sort = TRUE, threshold = 0.2)

  principal_components(attitude, n = 3, sort = TRUE, threshold = 0.2)


  # Exploratory Factor Analysis (EFA) ---------
  efa &lt;- psych::fa(attitude, nfactors = 3)
  model_parameters(efa,
    threshold = "max", sort = TRUE,
    labels = as.character(1:ncol(attitude))
  )


  # Omega ---------
  omega &lt;- psych::omega(mtcars, nfactors = 3)
  params &lt;- model_parameters(omega)
  params
  summary(params)
}


# lavaan

library(parameters)

# lavaan -------------------------------------
if (require("lavaan", quietly = TRUE)) {
  # Confirmatory Factor Analysis (CFA) ---------

  structure &lt;- " visual  =~ x1 + x2 + x3
                 textual =~ x4 + x5 + x6
                 speed   =~ x7 + x8 + x9 "
  model &lt;- lavaan::cfa(structure, data = HolzingerSwineford1939)
  model_parameters(model)
  model_parameters(model, standardize = TRUE)

  # filter parameters
  model_parameters(
    model,
    parameters = list(
      To = "^(?!visual)",
      From = "^(?!(x7|x8))"
    )
  )

  # Structural Equation Model (SEM) ------------

  structure &lt;- "
    # latent variable definitions
      ind60 =~ x1 + x2 + x3
      dem60 =~ y1 + a*y2 + b*y3 + c*y4
      dem65 =~ y5 + a*y6 + b*y7 + c*y8
    # regressions
      dem60 ~ ind60
      dem65 ~ ind60 + dem60
    # residual correlations
      y1 ~~ y5
      y2 ~~ y4 + y6
      y3 ~~ y7
      y4 ~~ y8
      y6 ~~ y8
  "
  model &lt;- lavaan::sem(structure, data = PoliticalDemocracy)
  model_parameters(model)
  model_parameters(model, standardize = TRUE)
}

</code></pre>

<hr>
<h2 id='model_parameters.rma'>Parameters from Meta-Analysis</h2><span id='topic+model_parameters.rma'></span>

<h3>Description</h3>

<p>Extract and compute indices and measures to describe parameters of meta-analysis models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'rma'
model_parameters(
  model,
  ci = 0.95,
  bootstrap = FALSE,
  iterations = 1000,
  standardize = NULL,
  exponentiate = FALSE,
  include_studies = TRUE,
  keep = NULL,
  drop = NULL,
  verbose = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="model_parameters.rma_+3A_model">model</code></td>
<td>
<p>Model object.</p>
</td></tr>
<tr><td><code id="model_parameters.rma_+3A_ci">ci</code></td>
<td>
<p>Confidence Interval (CI) level. Default to <code>0.95</code> (<code style="white-space: pre;">&#8288;95%&#8288;</code>).</p>
</td></tr>
<tr><td><code id="model_parameters.rma_+3A_bootstrap">bootstrap</code></td>
<td>
<p>Should estimates be based on bootstrapped model? If
<code>TRUE</code>, then arguments of <a href="#topic+model_parameters.stanreg">Bayesian regressions</a> apply (see also
<code><a href="#topic+bootstrap_parameters">bootstrap_parameters()</a></code>).</p>
</td></tr>
<tr><td><code id="model_parameters.rma_+3A_iterations">iterations</code></td>
<td>
<p>The number of bootstrap replicates. This only apply in the
case of bootstrapped frequentist models.</p>
</td></tr>
<tr><td><code id="model_parameters.rma_+3A_standardize">standardize</code></td>
<td>
<p>The method used for standardizing the parameters. Can be
<code>NULL</code> (default; no standardization), <code>"refit"</code> (for re-fitting the model
on standardized data) or one of <code>"basic"</code>, <code>"posthoc"</code>, <code>"smart"</code>,
<code>"pseudo"</code>. See 'Details' in <code><a href="#topic+standardize_parameters">standardize_parameters()</a></code>.
<strong>Importantly</strong>:
</p>

<ul>
<li><p> The <code>"refit"</code> method does <em>not</em> standardize categorical predictors (i.e.
factors), which may be a different behaviour compared to other R packages
(such as <strong>lm.beta</strong>) or other software packages (like SPSS). to mimic
such behaviours, either use <code>standardize="basic"</code> or standardize the data
with <code>datawizard::standardize(force=TRUE)</code> <em>before</em> fitting the model.
</p>
</li>
<li><p> For mixed models, when using methods other than <code>"refit"</code>, only the fixed
effects will be standardized.
</p>
</li>
<li><p> Robust estimation (i.e., <code>vcov</code> set to a value other than <code>NULL</code>) of
standardized parameters only works when <code>standardize="refit"</code>.
</p>
</li></ul>
</td></tr>
<tr><td><code id="model_parameters.rma_+3A_exponentiate">exponentiate</code></td>
<td>
<p>Logical, indicating whether or not to exponentiate the
coefficients (and related confidence intervals). This is typical for
logistic regression, or more generally speaking, for models with log or
logit links. It is also recommended to use <code>exponentiate = TRUE</code> for models
with log-transformed response values. <strong>Note:</strong> Delta-method standard
errors are also computed (by multiplying the standard errors by the
transformed coefficients). This is to mimic behaviour of other software
packages, such as Stata, but these standard errors poorly estimate
uncertainty for the transformed coefficient. The transformed confidence
interval more clearly captures this uncertainty. For <code>compare_parameters()</code>,
<code>exponentiate = "nongaussian"</code> will only exponentiate coefficients from
non-Gaussian families.</p>
</td></tr>
<tr><td><code id="model_parameters.rma_+3A_include_studies">include_studies</code></td>
<td>
<p>Logical, if <code>TRUE</code> (default), includes parameters
for all studies. Else, only parameters for overall-effects are shown.</p>
</td></tr>
<tr><td><code id="model_parameters.rma_+3A_keep">keep</code></td>
<td>
<p>Character containing a regular expression pattern that
describes the parameters that should be included (for <code>keep</code>) or excluded
(for <code>drop</code>) in the returned data frame. <code>keep</code> may also be a
named list of regular expressions. All non-matching parameters will be
removed from the output. If <code>keep</code> is a character vector, every parameter
name in the <em>&quot;Parameter&quot;</em> column that matches the regular expression in
<code>keep</code> will be selected from the returned data frame (and vice versa,
all parameter names matching <code>drop</code> will be excluded). Furthermore, if
<code>keep</code> has more than one element, these will be merged with an <code>OR</code>
operator into a regular expression pattern like this: <code>"(one|two|three)"</code>.
If <code>keep</code> is a named list of regular expression patterns, the names of the
list-element should equal the column name where selection should be
applied. This is useful for model objects where <code>model_parameters()</code>
returns multiple columns with parameter components, like in
<code><a href="#topic+model_parameters.lavaan">model_parameters.lavaan()</a></code>. Note that the regular expression pattern
should match the parameter names as they are stored in the returned data
frame, which can be different from how they are printed. Inspect the
<code style="white-space: pre;">&#8288;$Parameter&#8288;</code> column of the parameters table to get the exact parameter
names.</p>
</td></tr>
<tr><td><code id="model_parameters.rma_+3A_drop">drop</code></td>
<td>
<p>See <code>keep</code>.</p>
</td></tr>
<tr><td><code id="model_parameters.rma_+3A_verbose">verbose</code></td>
<td>
<p>Toggle warnings and messages.</p>
</td></tr>
<tr><td><code id="model_parameters.rma_+3A_...">...</code></td>
<td>
<p>Arguments passed to or from other methods. For instance, when
<code>bootstrap = TRUE</code>, arguments like <code>type</code> or <code>parallel</code> are
passed down to <code>bootstrap_model()</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame of indices related to the model's parameters.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(parameters)
mydat &lt;&lt;- data.frame(
  effectsize = c(-0.393, 0.675, 0.282, -1.398),
  stderr = c(0.317, 0.317, 0.13, 0.36)
)
if (require("metafor", quietly = TRUE)) {
  model &lt;- rma(yi = effectsize, sei = stderr, method = "REML", data = mydat)
  model_parameters(model)
}

# with subgroups
if (require("metafor", quietly = TRUE)) {
  data(dat.bcg)
  dat &lt;- escalc(
    measure = "RR",
    ai = tpos,
    bi = tneg,
    ci = cpos,
    di = cneg,
    data = dat.bcg
  )
  dat$alloc &lt;- ifelse(dat$alloc == "random", "random", "other")
  d &lt;&lt;- dat
  model &lt;- rma(yi, vi, mods = ~alloc, data = d, digits = 3, slab = author)
  model_parameters(model)
}

if (require("metaBMA", quietly = TRUE)) {
  data(towels)
  m &lt;- suppressWarnings(meta_random(logOR, SE, study, data = towels))
  model_parameters(m)
}


</code></pre>

<hr>
<h2 id='model_parameters.t1way'>Parameters from robust statistical objects in <code>WRS2</code></h2><span id='topic+model_parameters.t1way'></span>

<h3>Description</h3>

<p>Parameters from robust statistical objects in <code>WRS2</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 't1way'
model_parameters(model, keep = NULL, verbose = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="model_parameters.t1way_+3A_model">model</code></td>
<td>
<p>Object from <code>WRS2</code> package.</p>
</td></tr>
<tr><td><code id="model_parameters.t1way_+3A_keep">keep</code></td>
<td>
<p>Character containing a regular expression pattern that
describes the parameters that should be included (for <code>keep</code>) or excluded
(for <code>drop</code>) in the returned data frame. <code>keep</code> may also be a
named list of regular expressions. All non-matching parameters will be
removed from the output. If <code>keep</code> is a character vector, every parameter
name in the <em>&quot;Parameter&quot;</em> column that matches the regular expression in
<code>keep</code> will be selected from the returned data frame (and vice versa,
all parameter names matching <code>drop</code> will be excluded). Furthermore, if
<code>keep</code> has more than one element, these will be merged with an <code>OR</code>
operator into a regular expression pattern like this: <code>"(one|two|three)"</code>.
If <code>keep</code> is a named list of regular expression patterns, the names of the
list-element should equal the column name where selection should be
applied. This is useful for model objects where <code>model_parameters()</code>
returns multiple columns with parameter components, like in
<code><a href="#topic+model_parameters.lavaan">model_parameters.lavaan()</a></code>. Note that the regular expression pattern
should match the parameter names as they are stored in the returned data
frame, which can be different from how they are printed. Inspect the
<code style="white-space: pre;">&#8288;$Parameter&#8288;</code> column of the parameters table to get the exact parameter
names.</p>
</td></tr>
<tr><td><code id="model_parameters.t1way_+3A_verbose">verbose</code></td>
<td>
<p>Toggle warnings and messages.</p>
</td></tr>
<tr><td><code id="model_parameters.t1way_+3A_...">...</code></td>
<td>
<p>Arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame of indices related to the model's parameters.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (require("WRS2") &amp;&amp; packageVersion("WRS2") &gt;= "1.1.3") {
  model &lt;- t1way(libido ~ dose, data = viagra)
  model_parameters(model)
}
</code></pre>

<hr>
<h2 id='model_parameters.zcpglm'>Parameters from Zero-Inflated Models</h2><span id='topic+model_parameters.zcpglm'></span><span id='topic+model_parameters.mhurdle'></span>

<h3>Description</h3>

<p>Parameters from zero-inflated models (from packages like <strong>pscl</strong>,
<strong>cplm</strong> or <strong>countreg</strong>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'zcpglm'
model_parameters(
  model,
  ci = 0.95,
  bootstrap = FALSE,
  iterations = 1000,
  component = c("all", "conditional", "zi", "zero_inflated"),
  standardize = NULL,
  exponentiate = FALSE,
  p_adjust = NULL,
  keep = NULL,
  drop = NULL,
  summary = getOption("parameters_summary", FALSE),
  verbose = TRUE,
  ...
)

## S3 method for class 'mhurdle'
model_parameters(
  model,
  ci = 0.95,
  component = c("all", "conditional", "zi", "zero_inflated", "infrequent_purchase", "ip",
    "auxiliary"),
  exponentiate = FALSE,
  p_adjust = NULL,
  keep = NULL,
  drop = NULL,
  verbose = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="model_parameters.zcpglm_+3A_model">model</code></td>
<td>
<p>A model with zero-inflation component.</p>
</td></tr>
<tr><td><code id="model_parameters.zcpglm_+3A_ci">ci</code></td>
<td>
<p>Confidence Interval (CI) level. Default to <code>0.95</code> (<code style="white-space: pre;">&#8288;95%&#8288;</code>).</p>
</td></tr>
<tr><td><code id="model_parameters.zcpglm_+3A_bootstrap">bootstrap</code></td>
<td>
<p>Should estimates be based on bootstrapped model? If
<code>TRUE</code>, then arguments of <a href="#topic+model_parameters.stanreg">Bayesian regressions</a> apply (see also
<code><a href="#topic+bootstrap_parameters">bootstrap_parameters()</a></code>).</p>
</td></tr>
<tr><td><code id="model_parameters.zcpglm_+3A_iterations">iterations</code></td>
<td>
<p>The number of bootstrap replicates. This only apply in the
case of bootstrapped frequentist models.</p>
</td></tr>
<tr><td><code id="model_parameters.zcpglm_+3A_component">component</code></td>
<td>
<p>Should all parameters, parameters for the conditional model,
for the zero-inflation part of the model, or the dispersion model be returned?
Applies to models with zero-inflation and/or dispersion component. <code>component</code>
may be one of <code>"conditional"</code>, <code>"zi"</code>, <code>"zero-inflated"</code>, <code>"dispersion"</code> or
<code>"all"</code> (default). May be abbreviated.</p>
</td></tr>
<tr><td><code id="model_parameters.zcpglm_+3A_standardize">standardize</code></td>
<td>
<p>The method used for standardizing the parameters. Can be
<code>NULL</code> (default; no standardization), <code>"refit"</code> (for re-fitting the model
on standardized data) or one of <code>"basic"</code>, <code>"posthoc"</code>, <code>"smart"</code>,
<code>"pseudo"</code>. See 'Details' in <code><a href="#topic+standardize_parameters">standardize_parameters()</a></code>.
<strong>Importantly</strong>:
</p>

<ul>
<li><p> The <code>"refit"</code> method does <em>not</em> standardize categorical predictors (i.e.
factors), which may be a different behaviour compared to other R packages
(such as <strong>lm.beta</strong>) or other software packages (like SPSS). to mimic
such behaviours, either use <code>standardize="basic"</code> or standardize the data
with <code>datawizard::standardize(force=TRUE)</code> <em>before</em> fitting the model.
</p>
</li>
<li><p> For mixed models, when using methods other than <code>"refit"</code>, only the fixed
effects will be standardized.
</p>
</li>
<li><p> Robust estimation (i.e., <code>vcov</code> set to a value other than <code>NULL</code>) of
standardized parameters only works when <code>standardize="refit"</code>.
</p>
</li></ul>
</td></tr>
<tr><td><code id="model_parameters.zcpglm_+3A_exponentiate">exponentiate</code></td>
<td>
<p>Logical, indicating whether or not to exponentiate the
coefficients (and related confidence intervals). This is typical for
logistic regression, or more generally speaking, for models with log or
logit links. It is also recommended to use <code>exponentiate = TRUE</code> for models
with log-transformed response values. <strong>Note:</strong> Delta-method standard
errors are also computed (by multiplying the standard errors by the
transformed coefficients). This is to mimic behaviour of other software
packages, such as Stata, but these standard errors poorly estimate
uncertainty for the transformed coefficient. The transformed confidence
interval more clearly captures this uncertainty. For <code>compare_parameters()</code>,
<code>exponentiate = "nongaussian"</code> will only exponentiate coefficients from
non-Gaussian families.</p>
</td></tr>
<tr><td><code id="model_parameters.zcpglm_+3A_p_adjust">p_adjust</code></td>
<td>
<p>Character vector, if not <code>NULL</code>, indicates the method to
adjust p-values. See <code><a href="stats.html#topic+p.adjust">stats::p.adjust()</a></code> for details. Further
possible adjustment methods are <code>"tukey"</code>, <code>"scheffe"</code>,
<code>"sidak"</code> and <code>"none"</code> to explicitly disable adjustment for
<code>emmGrid</code> objects (from <strong>emmeans</strong>).</p>
</td></tr>
<tr><td><code id="model_parameters.zcpglm_+3A_keep">keep</code></td>
<td>
<p>Character containing a regular expression pattern that
describes the parameters that should be included (for <code>keep</code>) or excluded
(for <code>drop</code>) in the returned data frame. <code>keep</code> may also be a
named list of regular expressions. All non-matching parameters will be
removed from the output. If <code>keep</code> is a character vector, every parameter
name in the <em>&quot;Parameter&quot;</em> column that matches the regular expression in
<code>keep</code> will be selected from the returned data frame (and vice versa,
all parameter names matching <code>drop</code> will be excluded). Furthermore, if
<code>keep</code> has more than one element, these will be merged with an <code>OR</code>
operator into a regular expression pattern like this: <code>"(one|two|three)"</code>.
If <code>keep</code> is a named list of regular expression patterns, the names of the
list-element should equal the column name where selection should be
applied. This is useful for model objects where <code>model_parameters()</code>
returns multiple columns with parameter components, like in
<code><a href="#topic+model_parameters.lavaan">model_parameters.lavaan()</a></code>. Note that the regular expression pattern
should match the parameter names as they are stored in the returned data
frame, which can be different from how they are printed. Inspect the
<code style="white-space: pre;">&#8288;$Parameter&#8288;</code> column of the parameters table to get the exact parameter
names.</p>
</td></tr>
<tr><td><code id="model_parameters.zcpglm_+3A_drop">drop</code></td>
<td>
<p>See <code>keep</code>.</p>
</td></tr>
<tr><td><code id="model_parameters.zcpglm_+3A_summary">summary</code></td>
<td>
<p>Logical, if <code>TRUE</code>, prints summary information about the
model (model formula, number of observations, residual standard deviation
and more).</p>
</td></tr>
<tr><td><code id="model_parameters.zcpglm_+3A_verbose">verbose</code></td>
<td>
<p>Toggle warnings and messages.</p>
</td></tr>
<tr><td><code id="model_parameters.zcpglm_+3A_...">...</code></td>
<td>
<p>Arguments passed to or from other methods. For instance, when
<code>bootstrap = TRUE</code>, arguments like <code>type</code> or <code>parallel</code> are
passed down to <code>bootstrap_model()</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame of indices related to the model's parameters.
</p>


<h3>See Also</h3>

<p><code><a href="insight.html#topic+standardize_names">insight::standardize_names()</a></code> to rename
columns into a consistent, standardized naming scheme.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(parameters)
if (require("pscl")) {
  data("bioChemists")
  model &lt;- zeroinfl(art ~ fem + mar + kid5 + ment | kid5 + phd, data = bioChemists)
  model_parameters(model)
}
</code></pre>

<hr>
<h2 id='n_clusters'>Find number of clusters in your data</h2><span id='topic+n_clusters'></span><span id='topic+n_clusters_elbow'></span><span id='topic+n_clusters_gap'></span><span id='topic+n_clusters_silhouette'></span><span id='topic+n_clusters_dbscan'></span><span id='topic+n_clusters_hclust'></span>

<h3>Description</h3>

<p>Similarly to <code><a href="#topic+n_factors">n_factors()</a></code> for factor / principal component analysis,
<code>n_clusters()</code> is the main function to find out the optimal numbers of clusters
present in the data based on the maximum consensus of a large number of
methods.
</p>
<p>Essentially, there exist many methods to determine the optimal number of
clusters, each with pros and cons, benefits and limitations. The main
<code>n_clusters</code> function proposes to run all of them, and find out the number of
clusters that is suggested by the majority of methods (in case of ties, it
will select the most parsimonious solution with fewer clusters).
</p>
<p>Note that we also implement some specific, commonly used methods, like the
Elbow or the Gap method, with their own visualization functionalities. See
the examples below for more details.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>n_clusters(
  x,
  standardize = TRUE,
  include_factors = FALSE,
  package = c("easystats", "NbClust", "mclust"),
  fast = TRUE,
  nbclust_method = "kmeans",
  n_max = 10,
  ...
)

n_clusters_elbow(
  x,
  standardize = TRUE,
  include_factors = FALSE,
  clustering_function = stats::kmeans,
  n_max = 10,
  ...
)

n_clusters_gap(
  x,
  standardize = TRUE,
  include_factors = FALSE,
  clustering_function = stats::kmeans,
  n_max = 10,
  gap_method = "firstSEmax",
  ...
)

n_clusters_silhouette(
  x,
  standardize = TRUE,
  include_factors = FALSE,
  clustering_function = stats::kmeans,
  n_max = 10,
  ...
)

n_clusters_dbscan(
  x,
  standardize = TRUE,
  include_factors = FALSE,
  method = c("kNN", "SS"),
  min_size = 0.1,
  eps_n = 50,
  eps_range = c(0.1, 3),
  ...
)

n_clusters_hclust(
  x,
  standardize = TRUE,
  include_factors = FALSE,
  distance_method = "correlation",
  hclust_method = "average",
  ci = 0.95,
  iterations = 100,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="n_clusters_+3A_x">x</code></td>
<td>
<p>A data frame.</p>
</td></tr>
<tr><td><code id="n_clusters_+3A_standardize">standardize</code></td>
<td>
<p>Standardize the dataframe before clustering (default).</p>
</td></tr>
<tr><td><code id="n_clusters_+3A_include_factors">include_factors</code></td>
<td>
<p>Logical, if <code>TRUE</code>, factors are converted to numerical
values in order to be included in the data for determining the number of
clusters. By default, factors are removed, because most methods that
determine the number of clusters need numeric input only.</p>
</td></tr>
<tr><td><code id="n_clusters_+3A_package">package</code></td>
<td>
<p>Package from which methods are to be called to determine the
number of clusters. Can be <code>"all"</code> or a vector containing
<code>"easystats"</code>, <code>"NbClust"</code>, <code>"mclust"</code>, and <code>"M3C"</code>.</p>
</td></tr>
<tr><td><code id="n_clusters_+3A_fast">fast</code></td>
<td>
<p>If <code>FALSE</code>, will compute 4 more indices (sets <code>index = "allong"</code>
in <code>NbClust</code>). This has been deactivated by default as it is
computationally heavy.</p>
</td></tr>
<tr><td><code id="n_clusters_+3A_nbclust_method">nbclust_method</code></td>
<td>
<p>The clustering method (passed to <code>NbClust::NbClust()</code>
as <code>method</code>).</p>
</td></tr>
<tr><td><code id="n_clusters_+3A_n_max">n_max</code></td>
<td>
<p>Maximal number of clusters to test.</p>
</td></tr>
<tr><td><code id="n_clusters_+3A_...">...</code></td>
<td>
<p>Arguments passed to or from other methods. For instance, when
<code>bootstrap = TRUE</code>, arguments like <code>type</code> or <code>parallel</code> are
passed down to <code>bootstrap_model()</code>.</p>
</td></tr>
<tr><td><code id="n_clusters_+3A_clustering_function">clustering_function</code>, <code id="n_clusters_+3A_gap_method">gap_method</code></td>
<td>
<p>Other arguments passed to other
functions. <code>clustering_function</code> is used by <code>fviz_nbclust()</code> and
can be <code>kmeans</code>, <code>cluster::pam</code>, <code>cluster::clara</code>, <code>cluster::fanny</code>, and
more. <code>gap_method</code> is used by <code>cluster::maxSE</code> to extract the optimal
numbers of clusters (see its <code>method</code> argument).</p>
</td></tr>
<tr><td><code id="n_clusters_+3A_method">method</code>, <code id="n_clusters_+3A_min_size">min_size</code>, <code id="n_clusters_+3A_eps_n">eps_n</code>, <code id="n_clusters_+3A_eps_range">eps_range</code></td>
<td>
<p>Arguments for DBSCAN algorithm.</p>
</td></tr>
<tr><td><code id="n_clusters_+3A_distance_method">distance_method</code></td>
<td>
<p>The distance method (passed to <code><a href="stats.html#topic+dist">dist()</a></code>). Used by
algorithms relying on the distance matrix, such as <code>hclust</code> or <code>dbscan</code>.</p>
</td></tr>
<tr><td><code id="n_clusters_+3A_hclust_method">hclust_method</code></td>
<td>
<p>The hierarchical clustering method (passed to <code><a href="stats.html#topic+hclust">hclust()</a></code>).</p>
</td></tr>
<tr><td><code id="n_clusters_+3A_ci">ci</code></td>
<td>
<p>Confidence Interval (CI) level. Default to <code>0.95</code> (<code style="white-space: pre;">&#8288;95%&#8288;</code>).</p>
</td></tr>
<tr><td><code id="n_clusters_+3A_iterations">iterations</code></td>
<td>
<p>The number of bootstrap replicates. This only apply in the
case of bootstrapped frequentist models.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>There is also a <a href="https://easystats.github.io/see/articles/parameters.html"><code>plot()</code>-method</a> implemented in the <a href="https://easystats.github.io/see/"><strong>see</strong>-package</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(parameters)

# The main 'n_clusters' function ===============================
if (require("mclust", quietly = TRUE) &amp;&amp; require("NbClust", quietly = TRUE) &amp;&amp;
  require("cluster", quietly = TRUE) &amp;&amp; require("see", quietly = TRUE)) {
  n &lt;- n_clusters(iris[, 1:4], package = c("NbClust", "mclust")) # package can be "all"
  n
  summary(n)
  as.data.frame(n) # Duration is the time elapsed for each method in seconds
  plot(n)

  # The following runs all the method but it significantly slower
  # n_clusters(iris[1:4], standardize = FALSE, package = "all", fast = FALSE)
}



x &lt;- n_clusters_elbow(iris[1:4])
x
as.data.frame(x)
plot(x)



#
# Gap method --------------------
if (require("see", quietly = TRUE) &amp;&amp;
  require("cluster", quietly = TRUE) &amp;&amp;
  require("factoextra", quietly = TRUE)) {
  x &lt;- n_clusters_gap(iris[1:4])
  x
  as.data.frame(x)
  plot(x)
}


#
# Silhouette method --------------------------
if (require("factoextra", quietly = TRUE)) {
  x &lt;- n_clusters_silhouette(iris[1:4])
  x
  as.data.frame(x)
  plot(x)
}


#
if (require("dbscan", quietly = TRUE)) {
  # DBSCAN method -------------------------
  # NOTE: This actually primarily estimates the 'eps' parameter, the number of
  # clusters is a side effect (it's the number of clusters corresponding to
  # this 'optimal' EPS parameter).
  x &lt;- n_clusters_dbscan(iris[1:4], method = "kNN", min_size = 0.05) # 5 percent
  x
  head(as.data.frame(x))
  plot(x)

  x &lt;- n_clusters_dbscan(iris[1:4], method = "SS", eps_n = 100, eps_range = c(0.1, 2))
  x
  head(as.data.frame(x))
  plot(x)
}


#
# hclust method -------------------------------
if (require("pvclust", quietly = TRUE)) {
  # iterations should be higher for real analyses
  x &lt;- n_clusters_hclust(iris[1:4], iterations = 50, ci = 0.90)
  x
  head(as.data.frame(x), n = 10) # Print 10 first rows
  plot(x)
}

</code></pre>

<hr>
<h2 id='n_factors'>Number of components/factors to retain in PCA/FA</h2><span id='topic+n_factors'></span><span id='topic+n_components'></span>

<h3>Description</h3>

<p>This function runs many existing procedures for determining how many factors
to retain/extract from factor analysis (FA) or dimension reduction (PCA). It
returns the number of factors based on the maximum consensus between methods.
In case of ties, it will keep the simplest model and select the solution
with the fewer factors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>n_factors(
  x,
  type = "FA",
  rotation = "varimax",
  algorithm = "default",
  package = c("nFactors", "psych"),
  cor = NULL,
  safe = TRUE,
  n_max = NULL,
  ...
)

n_components(
  x,
  type = "PCA",
  rotation = "varimax",
  algorithm = "default",
  package = c("nFactors", "psych"),
  cor = NULL,
  safe = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="n_factors_+3A_x">x</code></td>
<td>
<p>A data frame.</p>
</td></tr>
<tr><td><code id="n_factors_+3A_type">type</code></td>
<td>
<p>Can be <code>"FA"</code> or <code>"PCA"</code>, depending on what you want to do.</p>
</td></tr>
<tr><td><code id="n_factors_+3A_rotation">rotation</code></td>
<td>
<p>Only used for VSS (Very Simple Structure criterion, see
<code><a href="psych.html#topic+VSS">psych::VSS()</a></code>). The rotation to apply. Can be <code>"none"</code>, <code>"varimax"</code>,
<code>"quartimax"</code>, <code>"bentlerT"</code>, <code>"equamax"</code>, <code>"varimin"</code>, <code>"geominT"</code> and
<code>"bifactor"</code> for orthogonal rotations, and <code>"promax"</code>, <code>"oblimin"</code>,
<code>"simplimax"</code>, <code>"bentlerQ"</code>, <code>"geominQ"</code>, <code>"biquartimin"</code> and <code>"cluster"</code>
for oblique transformations.</p>
</td></tr>
<tr><td><code id="n_factors_+3A_algorithm">algorithm</code></td>
<td>
<p>Factoring method used by VSS. Can be <code>"pa"</code> for Principal
Axis Factor Analysis, <code>"minres"</code> for minimum residual (OLS) factoring,
<code>"mle"</code> for Maximum Likelihood FA and <code>"pc"</code> for Principal Components.
<code>"default"</code> will select <code>"minres"</code> if <code>type = "FA"</code> and <code>"pc"</code> if
<code>type = "PCA"</code>.</p>
</td></tr>
<tr><td><code id="n_factors_+3A_package">package</code></td>
<td>
<p>Package from which respective methods are used. Can be
<code>"all"</code> or a vector containing <code>"nFactors"</code>, <code>"psych"</code>, <code>"PCDimension"</code>,
<code>"fit"</code> or <code>"EGAnet"</code>. Note that <code>"fit"</code> (which actually also relies on the
<code>psych</code> package) and <code>"EGAnet"</code> can be very slow for bigger datasets. Thus,
the default is <code>c("nFactors", "psych")</code>. You must have the respective
packages installed for the methods to be used.</p>
</td></tr>
<tr><td><code id="n_factors_+3A_cor">cor</code></td>
<td>
<p>An optional correlation matrix that can be used (note that the
data must still be passed as the first argument). If <code>NULL</code>, will
compute it by running <code>cor()</code> on the passed data.</p>
</td></tr>
<tr><td><code id="n_factors_+3A_safe">safe</code></td>
<td>
<p>If <code>TRUE</code>, the function will run all the procedures in try
blocks, and will only return those that work and silently skip the ones
that may fail.</p>
</td></tr>
<tr><td><code id="n_factors_+3A_n_max">n_max</code></td>
<td>
<p>If set to a value (e.g., <code>10</code>), will drop from the results all
methods that suggest a higher number of components. The interpretation becomes
'from all the methods that suggested a number lower than n_max, the results
are ...'.</p>
</td></tr>
<tr><td><code id="n_factors_+3A_...">...</code></td>
<td>
<p>Arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>n_components()</code> is actually an alias for <code>n_factors()</code>, with
different defaults for the function arguments.
</p>


<h3>Value</h3>

<p>A data frame.
</p>


<h3>Note</h3>

<p>There is also a
<a href="https://easystats.github.io/see/articles/parameters.html"><code>plot()</code>-method</a>
implemented in the <a href="https://easystats.github.io/see/"><strong>see</strong>-package</a>.
<code>n_components()</code> is a convenient short-cut  for <code>n_factors(type = "PCA")</code>.
</p>


<h3>References</h3>


<ul>
<li><p> Bartlett, M. S. (1950). Tests of significance in factor analysis.
British Journal of statistical psychology, 3(2), 77-85.
</p>
</li>
<li><p> Bentler, P. M., &amp; Yuan, K. H. (1996). Test of linear trend in
eigenvalues of a covariance matrix with application to data analysis.
British Journal of Mathematical and Statistical Psychology, 49(2), 299-312.
</p>
</li>
<li><p> Cattell, R. B. (1966). The scree test for the number of factors.
Multivariate behavioral research, 1(2), 245-276.
</p>
</li>
<li><p> Finch, W. H. (2019). Using Fit Statistic Differences to Determine the
Optimal Number of Factors to Retain in an Exploratory Factor Analysis.
Educational and Psychological Measurement.
</p>
</li>
<li><p> Zoski, K. W., &amp; Jurs, S. (1996). An objective counterpart to the
visual scree test for factor analysis: The standard error scree.
Educational and Psychological Measurement, 56(3), 443-451.
</p>
</li>
<li><p> Zoski, K., &amp; Jurs, S. (1993). Using multiple regression to determine
the number of factors to retain in factor analysis. Multiple Linear
Regression Viewpoints, 20(1), 5-9.
</p>
</li>
<li><p> Nasser, F., Benson, J., &amp; Wisenbaker, J. (2002). The performance of
regression-based variations of the visual scree for determining the number
of common factors. Educational and psychological measurement, 62(3),
397-419.
</p>
</li>
<li><p> Golino, H., Shi, D., Garrido, L. E., Christensen, A. P., Nieto, M.
D., Sadana, R., &amp; Thiyagarajan, J. A. (2018). Investigating the performance
of Exploratory Graph Analysis and traditional techniques to identify the
number of latent factors: A simulation and tutorial.
</p>
</li>
<li><p> Golino, H. F., &amp; Epskamp, S. (2017). Exploratory graph analysis: A
new approach for estimating the number of dimensions in psychological
research. PloS one, 12(6), e0174035.
</p>
</li>
<li><p> Revelle, W., &amp; Rocklin, T. (1979). Very simple structure: An
alternative procedure for estimating the optimal number of interpretable
factors. Multivariate Behavioral Research, 14(4), 403-414.
</p>
</li>
<li><p> Velicer, W. F. (1976). Determining the number of components from the
matrix of partial correlations. Psychometrika, 41(3), 321-327.
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>
library(parameters)
n_factors(mtcars, type = "PCA")

result &lt;- n_factors(mtcars[1:5], type = "FA")
as.data.frame(result)
summary(result)

# Setting package = 'all' will increase the number of methods (but is slow)
n_factors(mtcars, type = "PCA", package = "all")
n_factors(mtcars, type = "FA", algorithm = "mle", package = "all")


</code></pre>

<hr>
<h2 id='p_calibrate'>Calculate calibrated p-values.</h2><span id='topic+p_calibrate'></span><span id='topic+p_calibrate.default'></span>

<h3>Description</h3>

<p>Compute calibrated p-values that can be interpreted
probabilistically, i.e. as posterior probability of H0 (given that H0
and H1 have equal prior probabilities).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>p_calibrate(x, ...)

## Default S3 method:
p_calibrate(x, type = "frequentist", verbose = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="p_calibrate_+3A_x">x</code></td>
<td>
<p>A numeric vector of p-values, or a regression model object.</p>
</td></tr>
<tr><td><code id="p_calibrate_+3A_...">...</code></td>
<td>
<p>Currently not used.</p>
</td></tr>
<tr><td><code id="p_calibrate_+3A_type">type</code></td>
<td>
<p>Type of calibration. Can be <code>"frequentist"</code> or <code>"bayesian"</code>.
See 'Details'.</p>
</td></tr>
<tr><td><code id="p_calibrate_+3A_verbose">verbose</code></td>
<td>
<p>Toggle warnings.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Bayesian calibration, i.e. when <code>type = "bayesian"</code>, can be interpreted
as the lower bound of the Bayes factor for H0 to H1, based on the data.
The full Bayes factor would then require multiplying by the prior odds of
H0 to H1. The frequentist calibration also has a Bayesian interpretation; it
is the posterior probability of H0, assuming that H0 and H1 have equal
prior probabilities of 0.5 each (<em>Sellke et al. 2001</em>).
</p>
<p>The calibration only works for p-values lower than or equal to <code>1/e</code>.
</p>


<h3>Value</h3>

<p>A data frame with p-values and calibrated p-values.
</p>


<h3>References</h3>

<p>Thomas Sellke, M. J Bayarri and James O Berger (2001) Calibration of p Values
for Testing Precise Null Hypotheses, The American Statistician, 55:1, 62-71,
<a href="https://doi.org/10.1198/000313001300339950">doi:10.1198/000313001300339950</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>model &lt;- lm(mpg ~ wt + as.factor(gear) + am, data = mtcars)
p_calibrate(model, verbose = FALSE)
</code></pre>

<hr>
<h2 id='p_function'>p-value or consonance function</h2><span id='topic+p_function'></span><span id='topic+consonance_function'></span><span id='topic+confidence_curve'></span>

<h3>Description</h3>

<p>Compute p-values and compatibility (confidence) intervals for
statistical models, at different levels. This function is also called
consonance function. It allows to see which estimates are compatible with
the model at various compatibility levels. Use <code>plot()</code> to generate plots
of the <em>p</em> resp. <em>consonance</em> function and compatibility intervals at
different levels.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>p_function(
  model,
  ci_levels = c(0.25, 0.5, 0.75, emph = 0.95),
  exponentiate = FALSE,
  effects = "fixed",
  component = "all",
  keep = NULL,
  drop = NULL,
  verbose = TRUE,
  ...
)

consonance_function(
  model,
  ci_levels = c(0.25, 0.5, 0.75, emph = 0.95),
  exponentiate = FALSE,
  effects = "fixed",
  component = "all",
  keep = NULL,
  drop = NULL,
  verbose = TRUE,
  ...
)

confidence_curve(
  model,
  ci_levels = c(0.25, 0.5, 0.75, emph = 0.95),
  exponentiate = FALSE,
  effects = "fixed",
  component = "all",
  keep = NULL,
  drop = NULL,
  verbose = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="p_function_+3A_model">model</code></td>
<td>
<p>Statistical Model.</p>
</td></tr>
<tr><td><code id="p_function_+3A_ci_levels">ci_levels</code></td>
<td>
<p>Vector of scalars, indicating the different levels at which
compatibility intervals should be printed or plotted. In plots, these levels
are highlighted by vertical lines. It is possible to increase thickness for
one or more of these lines by providing a names vector, where the to be
highlighted values should be named <code>"emph"</code>, e.g
<code>ci_levels = c(0.25, 0.5, emph = 0.95)</code>.</p>
</td></tr>
<tr><td><code id="p_function_+3A_exponentiate">exponentiate</code></td>
<td>
<p>Logical, indicating whether or not to exponentiate the
coefficients (and related confidence intervals). This is typical for
logistic regression, or more generally speaking, for models with log or
logit links. It is also recommended to use <code>exponentiate = TRUE</code> for models
with log-transformed response values. <strong>Note:</strong> Delta-method standard
errors are also computed (by multiplying the standard errors by the
transformed coefficients). This is to mimic behaviour of other software
packages, such as Stata, but these standard errors poorly estimate
uncertainty for the transformed coefficient. The transformed confidence
interval more clearly captures this uncertainty. For <code>compare_parameters()</code>,
<code>exponentiate = "nongaussian"</code> will only exponentiate coefficients from
non-Gaussian families.</p>
</td></tr>
<tr><td><code id="p_function_+3A_effects">effects</code></td>
<td>
<p>Should parameters for fixed effects (<code>"fixed"</code>), random
effects (<code>"random"</code>), or both (<code>"all"</code>) be returned? Only applies
to mixed models. May be abbreviated. If the calculation of random effects
parameters takes too long, you may use <code>effects = "fixed"</code>.</p>
</td></tr>
<tr><td><code id="p_function_+3A_component">component</code></td>
<td>
<p>Should all parameters, parameters for the conditional model,
for the zero-inflation part of the model, or the dispersion model be returned?
Applies to models with zero-inflation and/or dispersion component. <code>component</code>
may be one of <code>"conditional"</code>, <code>"zi"</code>, <code>"zero-inflated"</code>, <code>"dispersion"</code> or
<code>"all"</code> (default). May be abbreviated.</p>
</td></tr>
<tr><td><code id="p_function_+3A_keep">keep</code></td>
<td>
<p>Character containing a regular expression pattern that
describes the parameters that should be included (for <code>keep</code>) or excluded
(for <code>drop</code>) in the returned data frame. <code>keep</code> may also be a
named list of regular expressions. All non-matching parameters will be
removed from the output. If <code>keep</code> is a character vector, every parameter
name in the <em>&quot;Parameter&quot;</em> column that matches the regular expression in
<code>keep</code> will be selected from the returned data frame (and vice versa,
all parameter names matching <code>drop</code> will be excluded). Furthermore, if
<code>keep</code> has more than one element, these will be merged with an <code>OR</code>
operator into a regular expression pattern like this: <code>"(one|two|three)"</code>.
If <code>keep</code> is a named list of regular expression patterns, the names of the
list-element should equal the column name where selection should be
applied. This is useful for model objects where <code>model_parameters()</code>
returns multiple columns with parameter components, like in
<code><a href="#topic+model_parameters.lavaan">model_parameters.lavaan()</a></code>. Note that the regular expression pattern
should match the parameter names as they are stored in the returned data
frame, which can be different from how they are printed. Inspect the
<code style="white-space: pre;">&#8288;$Parameter&#8288;</code> column of the parameters table to get the exact parameter
names.</p>
</td></tr>
<tr><td><code id="p_function_+3A_drop">drop</code></td>
<td>
<p>See <code>keep</code>.</p>
</td></tr>
<tr><td><code id="p_function_+3A_verbose">verbose</code></td>
<td>
<p>Toggle warnings and messages.</p>
</td></tr>
<tr><td><code id="p_function_+3A_...">...</code></td>
<td>
<p>Arguments passed to or from other methods. Non-documented
arguments are <code>digits</code>, <code>p_digits</code>, <code>ci_digits</code> and <code>footer_digits</code> to set
the number of digits for the output. If <code>s_value = TRUE</code>, the p-value will
be replaced by the S-value in the output (cf. <em>Rafi and Greenland 2020</em>).
<code>pd</code> adds an additional column with the <em>probability of direction</em> (see
<code><a href="bayestestR.html#topic+p_direction">bayestestR::p_direction()</a></code> for details). <code>groups</code> can be used to group
coefficients. It will be passed to the print-method, or can directly be used
in <code>print()</code>, see documentation in <code><a href="#topic+print.parameters_model">print.parameters_model()</a></code>. Furthermore,
see 'Examples' in <code><a href="#topic+model_parameters.default">model_parameters.default()</a></code>. For developers, whose
interest mainly is to get a &quot;tidy&quot; data frame of model summaries, it is
recommended to set <code>pretty_names = FALSE</code> to speed up computation of the
summary table.</p>
</td></tr>
</table>


<h3>Details</h3>



<h4>Compatibility intervals and continuous <em>p</em>-values for different estimate values</h4>

<p><code>p_function()</code> only returns the compatibility interval estimates, not the
related <em>p</em>-values. The reason for this is because the <em>p</em>-value for a
given estimate value is just <code>1 - CI_level</code>. The values indicating the lower
and upper limits of the intervals are the related estimates associated with
the <em>p</em>-value. E.g., if a parameter <code>x</code> has a 75% compatibility interval
of <code style="white-space: pre;">&#8288;(0.81, 1.05)&#8288;</code>, then the <em>p</em>-value for the estimate value of <code>0.81</code>
would be <code>1 - 0.75</code>, which is <code>0.25</code>. This relationship is more intuitive and
better to understand when looking at the plots (using <code>plot()</code>).
</p>



<h4>Conditional versus unconditional interpretation of <em>p</em>-values and intervals</h4>

<p><code>p_function()</code>, and in particular its <code>plot()</code> method, aims at re-interpreting
<em>p</em>-values and confidence intervals (better named: <em>compatibility</em> intervals)
in <em>unconditional</em> terms. Instead of referring to the long-term property and
repeated trials when interpreting interval estimates (so-called &quot;aleatory
probability&quot;, <em>Schweder 2018</em>), and assuming that all underlying assumptions
are correct and met, <code>p_function()</code> interprets <em>p</em>-values in a Fisherian way
as &quot;<em>continuous</em> measure of evidence against the very test hypothesis <em>and</em>
entire model (all assumptions) used to compute it&quot;
(<em>P-Values Are Tough and S-Values Can Help</em>, lesslikely.com/statistics/s-values;
see also <em>Amrhein and Greenland 2022</em>).
</p>
<p>This interpretation as a continuous measure of evidence against the test
hypothesis and the entire model used to compute it can be seen in the
figure below (taken from <em>P-Values Are Tough and S-Values Can Help</em>,
lesslikely.com/statistics/s-values). The &quot;conditional&quot; interpretation of
<em>p</em>-values and interval estimates (A) implicitly assumes certain assumptions
to be true, thus the interpretation is &quot;conditioned&quot; on these assumptions
(i.e. assumptions are taken as given). The unconditional interpretation (B),
however, questions all these assumptions.
</p>
<p><br /> <img src="../help/figures/unconditional_interpretation.png" alt="Conditional versus unconditional interpretations of P-values" /> <br />
</p>
<p>&quot;Emphasizing unconditional interpretations helps avoid overconfident and
misleading inferences in light of uncertainties about the assumptions used
to arrive at the statistical results.&quot; (<em>Greenland et al. 2022</em>).
</p>
<p><strong>Note:</strong> The term &quot;conditional&quot; as used by Rafi and Greenland probably has
a slightly different meaning than normally. &quot;Conditional&quot; in this notion
means that all model assumptions are taken as given - it should not be
confused with terms like &quot;conditional probability&quot;. See also <em>Greenland et al. 2022</em>
for a detailed elaboration on this issue.
</p>
<p>In other words, the term compatibility interval emphasizes &quot;the dependence
of the <em>p</em>-value on the assumptions as well as on the data, recognizing that
<em>p</em>&lt;0.05 can arise from assumption violations even if the effect under
study is null&quot; (<em>Gelman/Greenland 2019</em>).
</p>



<h4>Probabilistic interpretation of compatibility intervals</h4>

<p>Schweder (2018) resp. Schweder and Hjort (2016) (and others) argue that
confidence curves (as produced by <code>p_function()</code>) have a valid probabilistic
interpretation. They distinguish between <em>aleatory probability</em>, which
describes the aleatory stochastic element of a distribution <em>ex ante</em>, i.e.
before the data are obtained. This is the classical interpretation of
confidence intervals following the Neyman-Pearson school of statistics.
However, there is also an <em>ex post</em> probability, called <em>epistemic</em> probability,
for confidence curves. The shift in terminology from <em>confidence</em> intervals
to <em>compatibility</em> intervals may help emphasizing this interpretation.
</p>
<p>In this sense, the probabilistic interpretation of <em>p</em>-values and
compatibility intervals is &quot;conditional&quot; - on the data <em>and</em> model assumptions
(which is in line with the &quot;unconditional&quot; interpretation in the sense of
Rafi and Greenland).
</p>
<p>Ascribing a probabilistic interpretation to one realized confidence interval
is possible without repeated sampling of the specific experiment. Important
is the assumption that a <em>sampling distribution</em> is a good description of the
variability of the parameter (<em>Vos and Holbert 2022</em>). At the core, the
interpretation of a confidence interval is &quot;I assume that this sampling
distribution is a good description of the uncertainty of the parameter. If
that's a good assumption, then the values in this interval are the most
plausible or compatible with the data&quot;. The source of confidence in
probability statements is the assumption that the selected sampling
distribution is appropriate.
</p>
<p>&quot;The realized confidence distribution is clearly an epistemic probability
distribution&quot; (<em>Schweder 2018</em>). In Bayesian words, compatibility intervals
(or confidence distributons, or consonance curves) are &quot;posteriors without
priors&quot; (<em>Schweder, Hjort, 2003</em>). In this regard, interpretation of <em>p</em>-values
might be guided using <code><a href="bayestestR.html#topic+pd_to_p">bayestestR::p_to_pd()</a></code>.
</p>



<h4>Compatibility intervals - is their interpretation conditional or not?</h4>

<p>The fact that the term &quot;conditional&quot; is used in different meanings, is
confusing and unfortunate. Thus, we would summarize the probabilistic
interpretation of compatibility intervals as follows: The intervals are built
from the data <em>and</em> our modeling assumptions. The accuracy of the intervals
depends on our model assumptions. If a value is outside the interval, that
might be because (1) that parameter value isn't supported by the data, or
(2) the modeling assumptions are a poor fit for the situation. When we make
bad assumptions, the compatibility interval might be too wide or (more
commonly and seriously) too narrow, making us think we know more about the
parameter than is warranted.
</p>
<p>When we say &quot;there is a 95% chance the true value is in the interval&quot;, that is
a statement of <em>epistemic probability</em> (i.e. description of uncertainty related
to our knowledge or belief). When we talk about repeated samples or sampling
distributions, that is referring to <em>aleatoric</em> (physical properties) probability.
Frequentist inference is built on defining estimators with known <em>aleatoric</em>
probability properties, from which we can draw <em>epistemic</em> probabilistic
statements of uncertainty (<em>Schweder and Hjort 2016</em>).
</p>



<h3>Value</h3>

<p>A data frame with p-values and compatibility intervals.
</p>


<h3>Note</h3>

<p>Curently, <code>p_function()</code> computes intervals based on Wald t- or z-statistic.
For certain models (like mixed models), profiled intervals may be more
accurate, however, this is currently not supported.
</p>


<h3>References</h3>


<ul>
<li><p> Amrhein V, Greenland S. Discuss practical importance of results based on
interval estimates and p-value functions, not only on point estimates and
null p-values. Journal of Information Technology 2022;37:316–20.
<a href="https://doi.org/10.1177/02683962221105904">doi:10.1177/02683962221105904</a>
</p>
</li>
<li><p> Fraser DAS. The P-value function and statistical inference. The American
Statistician. 2019;73(sup1):135-147. <a href="https://doi.org/10.1080/00031305.2018.1556735">doi:10.1080/00031305.2018.1556735</a>
</p>
</li>
<li><p> Gelman A, Greenland S. Are confidence intervals better termed &quot;uncertainty
intervals&quot;? BMJ (2019)l5381. <a href="https://doi.org/10.1136/bmj.l5381">doi:10.1136/bmj.l5381</a>
</p>
</li>
<li><p> Greenland S, Rafi Z, Matthews R, Higgs M. To Aid Scientific Inference,
Emphasize Unconditional Compatibility Descriptions of Statistics. (2022)
https://arxiv.org/abs/1909.08583v7 (Accessed November 10, 2022)
</p>
</li>
<li><p> Rafi Z, Greenland S. Semantic and cognitive tools to aid statistical
science: Replace confidence and significance by compatibility and surprise.
BMC Medical Research Methodology. 2020;20(1):244. <a href="https://doi.org/10.1186/s12874-020-01105-9">doi:10.1186/s12874-020-01105-9</a>
</p>
</li>
<li><p> Schweder T. Confidence is epistemic probability for empirical science.
Journal of Statistical Planning and Inference (2018) 195:116–125.
<a href="https://doi.org/10.1016/j.jspi.2017.09.016">doi:10.1016/j.jspi.2017.09.016</a>
</p>
</li>
<li><p> Schweder T, Hjort NL. Confidence and Likelihood. Scandinavian Journal of
Statistics. 2002;29(2):309-332. <a href="https://doi.org/10.1111/1467-9469.00285">doi:10.1111/1467-9469.00285</a>
</p>
</li>
<li><p> Schweder T, Hjort NL. Frequentist analogues of priors and posteriors.
In Stigum, B. (ed.), Econometrics and the Philosophy of Economics: Theory
Data Confrontation in Economics, pp. 285-217. Princeton University Press,
Princeton, NJ, 2003
</p>
</li>
<li><p> Schweder T, Hjort NL. Confidence, Likelihood, Probability: Statistical
inference with confidence distributions. Cambridge University Press, 2016.
</p>
</li>
<li><p> Vos P, Holbert D. Frequentist statistical inference without repeated sampling.
Synthese 200, 89 (2022). <a href="https://doi.org/10.1007/s11229-022-03560-x">doi:10.1007/s11229-022-03560-x</a>
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>
model &lt;- lm(Sepal.Length ~ Species, data = iris)
p_function(model)

model &lt;- lm(mpg ~ wt + as.factor(gear) + am, data = mtcars)
result &lt;- p_function(model)

# single panels
plot(result, n_columns = 2)

# integrated plot, the default
plot(result)

</code></pre>

<hr>
<h2 id='p_value'>p-values</h2><span id='topic+p_value'></span><span id='topic+p_value.default'></span><span id='topic+p_value.emmGrid'></span>

<h3>Description</h3>

<p>This function attempts to return, or compute, p-values of a model's
parameters. See the documentation for your object's class:
</p>

<ul>
<li> <p><a href="#topic+p_value.BFBayesFactor">Bayesian models</a> (<strong>rstanarm</strong>, <strong>brms</strong>, <strong>MCMCglmm</strong>, ...)
</p>
</li>
<li> <p><a href="#topic+p_value.zeroinfl">Zero-inflated models</a> (<code>hurdle</code>, <code>zeroinfl</code>, <code>zerocount</code>, ...)
</p>
</li>
<li> <p><a href="#topic+p_value.poissonmfx">Marginal effects models</a> (<strong>mfx</strong>)
</p>
</li>
<li> <p><a href="#topic+p_value.DirichletRegModel">Models with special components</a> (<code>DirichletRegModel</code>, <code>clm2</code>, <code>cgam</code>, ...)
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>p_value(model, ...)

## Default S3 method:
p_value(
  model,
  dof = NULL,
  method = NULL,
  component = "all",
  vcov = NULL,
  vcov_args = NULL,
  verbose = TRUE,
  ...
)

## S3 method for class 'emmGrid'
p_value(model, ci = 0.95, adjust = "none", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="p_value_+3A_model">model</code></td>
<td>
<p>A statistical model.</p>
</td></tr>
<tr><td><code id="p_value_+3A_...">...</code></td>
<td>
<p>Additional arguments</p>
</td></tr>
<tr><td><code id="p_value_+3A_dof">dof</code></td>
<td>
<p>Number of degrees of freedom to be used when calculating
confidence intervals. If <code>NULL</code> (default), the degrees of freedom are
retrieved by calling <code><a href="#topic+degrees_of_freedom">degrees_of_freedom()</a></code> with
approximation method defined in <code>method</code>. If not <code>NULL</code>, use this argument
to override the default degrees of freedom used to compute confidence
intervals.</p>
</td></tr>
<tr><td><code id="p_value_+3A_method">method</code></td>
<td>
<p>Method for computing degrees of freedom for
confidence intervals (CI) and the related p-values. Allowed are following
options (which vary depending on the model class): <code>"residual"</code>,
<code>"normal"</code>, <code>"likelihood"</code>, <code>"satterthwaite"</code>, <code>"kenward"</code>, <code>"wald"</code>,
<code>"profile"</code>, <code>"boot"</code>, <code>"uniroot"</code>, <code>"ml1"</code>, <code>"betwithin"</code>, <code>"hdi"</code>,
<code>"quantile"</code>, <code>"ci"</code>, <code>"eti"</code>, <code>"si"</code>, <code>"bci"</code>, or <code>"bcai"</code>. See section
<em>Confidence intervals and approximation of degrees of freedom</em> in
<code><a href="#topic+model_parameters">model_parameters()</a></code> for further details.</p>
</td></tr>
<tr><td><code id="p_value_+3A_component">component</code></td>
<td>
<p>Model component for which parameters should be shown. See
the documentation for your object's class in <code><a href="#topic+model_parameters">model_parameters()</a></code> or
<code><a href="#topic+p_value">p_value()</a></code> for further details.</p>
</td></tr>
<tr><td><code id="p_value_+3A_vcov">vcov</code></td>
<td>
<p>Variance-covariance matrix used to compute uncertainty estimates
(e.g., for robust standard errors). This argument accepts a covariance matrix,
a function which returns a covariance matrix, or a string which identifies
the function to be used to compute the covariance matrix.
</p>

<ul>
<li><p> A covariance matrix
</p>
</li>
<li><p> A function which returns a covariance matrix (e.g., <code>stats::vcov()</code>)
</p>
</li>
<li><p> A string which indicates the kind of uncertainty estimates to return.
</p>

<ul>
<li><p> Heteroskedasticity-consistent: <code>"vcovHC"</code>, <code>"HC"</code>, <code>"HC0"</code>, <code>"HC1"</code>,
<code>"HC2"</code>, <code>"HC3"</code>, <code>"HC4"</code>, <code>"HC4m"</code>, <code>"HC5"</code>. See <code>?sandwich::vcovHC</code>.
</p>
</li>
<li><p> Cluster-robust: <code>"vcovCR"</code>, <code>"CR0"</code>, <code>"CR1"</code>, <code>"CR1p"</code>, <code>"CR1S"</code>, <code>"CR2"</code>,
<code>"CR3"</code>. See <code>?clubSandwich::vcovCR</code>.
</p>
</li>
<li><p> Bootstrap: <code>"vcovBS"</code>, <code>"xy"</code>, <code>"residual"</code>, <code>"wild"</code>, <code>"mammen"</code>, <code>"webb"</code>.
See <code>?sandwich::vcovBS</code>.
</p>
</li>
<li><p> Other <code>sandwich</code> package functions: <code>"vcovHAC"</code>, <code>"vcovPC"</code>, <code>"vcovCL"</code>, <code>"vcovPL"</code>.
</p>
</li></ul>

</li></ul>
</td></tr>
<tr><td><code id="p_value_+3A_vcov_args">vcov_args</code></td>
<td>
<p>List of arguments to be passed to the function identified by
the <code>vcov</code> argument. This function is typically supplied by the <strong>sandwich</strong>
or <strong>clubSandwich</strong> packages. Please refer to their documentation (e.g.,
<code>?sandwich::vcovHAC</code>) to see the list of available arguments.</p>
</td></tr>
<tr><td><code id="p_value_+3A_verbose">verbose</code></td>
<td>
<p>Toggle warnings and messages.</p>
</td></tr>
<tr><td><code id="p_value_+3A_ci">ci</code></td>
<td>
<p>Confidence Interval (CI) level. Default to <code>0.95</code> (<code style="white-space: pre;">&#8288;95%&#8288;</code>).</p>
</td></tr>
<tr><td><code id="p_value_+3A_adjust">adjust</code></td>
<td>
<p>Character value naming the method used to adjust p-values or
confidence intervals. See <code>?emmeans::summary.emmGrid</code> for details.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame with at least two columns: the parameter names and the
p-values. Depending on the model, may also include columns for model
components etc.
</p>


<h3>Confidence intervals and approximation of degrees of freedom</h3>

<p>There are different ways of approximating the degrees of freedom depending
on different assumptions about the nature of the model and its sampling
distribution. The <code>ci_method</code> argument modulates the method for computing degrees
of freedom (df) that are used to calculate confidence intervals (CI) and the
related p-values. Following options are allowed, depending on the model
class:
</p>
<p><strong>Classical methods:</strong>
</p>
<p>Classical inference is generally based on the <strong>Wald method</strong>.
The Wald approach to inference computes a test statistic by dividing the
parameter estimate by its standard error (Coefficient / SE),
then comparing this statistic against a t- or normal distribution.
This approach can be used to compute CIs and p-values.
</p>
<p><code>"wald"</code>:
</p>

<ul>
<li><p> Applies to <em>non-Bayesian models</em>. For <em>linear models</em>, CIs
computed using the Wald method (SE and a <em>t-distribution with residual df</em>);
p-values computed using the Wald method with a <em>t-distribution with residual df</em>.
For other models, CIs computed using the Wald method (SE and a <em>normal distribution</em>);
p-values computed using the Wald method with a <em>normal distribution</em>.
</p>
</li></ul>

<p><code>"normal"</code>
</p>

<ul>
<li><p> Applies to <em>non-Bayesian models</em>. Compute Wald CIs and p-values,
but always use a normal distribution.
</p>
</li></ul>

<p><code>"residual"</code>
</p>

<ul>
<li><p> Applies to <em>non-Bayesian models</em>. Compute Wald CIs and p-values,
but always use a <em>t-distribution with residual df</em> when possible. If the
residual df for a model cannot be determined, a normal distribution is
used instead.
</p>
</li></ul>

<p><strong>Methods for mixed models:</strong>
</p>
<p>Compared to fixed effects (or single-level) models, determining appropriate
df for Wald-based inference in mixed models is more difficult.
See <a href="https://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#what-are-the-p-values-listed-by-summaryglmerfit-etc.-are-they-reliable">the R GLMM FAQ</a>
for a discussion.
</p>
<p>Several approximate methods for computing df are available, but you should
also consider instead using profile likelihood (<code>"profile"</code>) or bootstrap (&quot;<code style="white-space: pre;">&#8288;boot"&#8288;</code>)
CIs and p-values instead.
</p>
<p><code>"satterthwaite"</code>
</p>

<ul>
<li><p> Applies to <em>linear mixed models</em>. CIs computed using the
Wald method (SE and a <em>t-distribution with Satterthwaite df</em>); p-values
computed using the Wald method with a <em>t-distribution with Satterthwaite df</em>.
</p>
</li></ul>

<p><code>"kenward"</code>
</p>

<ul>
<li><p> Applies to <em>linear mixed models</em>. CIs computed using the Wald
method (<em>Kenward-Roger SE</em> and a <em>t-distribution with Kenward-Roger df</em>);
p-values computed using the Wald method with <em>Kenward-Roger SE and t-distribution with Kenward-Roger df</em>.
</p>
</li></ul>

<p><code>"ml1"</code>
</p>

<ul>
<li><p> Applies to <em>linear mixed models</em>. CIs computed using the Wald
method (SE and a <em>t-distribution with m-l-1 approximated df</em>); p-values
computed using the Wald method with a <em>t-distribution with m-l-1 approximated df</em>.
See <code><a href="#topic+ci_ml1">ci_ml1()</a></code>.
</p>
</li></ul>

<p><code>"betwithin"</code>
</p>

<ul>
<li><p> Applies to <em>linear mixed models</em> and <em>generalized linear mixed models</em>.
CIs computed using the Wald method (SE and a <em>t-distribution with between-within df</em>);
p-values computed using the Wald method with a <em>t-distribution with between-within df</em>.
See <code><a href="#topic+ci_betwithin">ci_betwithin()</a></code>.
</p>
</li></ul>

<p><strong>Likelihood-based methods:</strong>
</p>
<p>Likelihood-based inference is based on comparing the likelihood for the
maximum-likelihood estimate to the the likelihood for models with one or more
parameter values changed (e.g., set to zero or a range of alternative values).
Likelihood ratios for the maximum-likelihood and alternative models are compared
to a <code class="reqn">\chi</code>-squared distribution to compute CIs and p-values.
</p>
<p><code>"profile"</code>
</p>

<ul>
<li><p> Applies to <em>non-Bayesian models</em> of class <code>glm</code>, <code>polr</code>, <code>merMod</code> or <code>glmmTMB</code>.
CIs computed by <em>profiling the likelihood curve for a parameter</em>, using
linear interpolation to find where likelihood ratio equals a critical value;
p-values computed using the Wald method with a <em>normal-distribution</em> (note:
this might change in a future update!)
</p>
</li></ul>

<p><code>"uniroot"</code>
</p>

<ul>
<li><p> Applies to <em>non-Bayesian models</em> of class <code>glmmTMB</code>. CIs
computed by <em>profiling the likelihood curve for a parameter</em>, using root
finding to find where likelihood ratio equals a critical value; p-values
computed using the Wald method with a <em>normal-distribution</em> (note: this
might change in a future update!)
</p>
</li></ul>

<p><strong>Methods for bootstrapped or Bayesian models:</strong>
</p>
<p>Bootstrap-based inference is based on <strong>resampling</strong> and refitting the model
to the resampled datasets. The distribution of parameter estimates across
resampled datasets is used to approximate the parameter's sampling
distribution. Depending on the type of model, several different methods for
bootstrapping and constructing CIs and p-values from the bootstrap
distribution are available.
</p>
<p>For Bayesian models, inference is based on drawing samples from the model
posterior distribution.
</p>
<p><code>"quantile"</code> (or <code>"eti"</code>)
</p>

<ul>
<li><p> Applies to <em>all models (including Bayesian models)</em>.
For non-Bayesian models, only applies if <code>bootstrap = TRUE</code>. CIs computed
as <em>equal tailed intervals</em> using the quantiles of the bootstrap or
posterior samples; p-values are based on the <em>probability of direction</em>.
See <code><a href="bayestestR.html#topic+eti">bayestestR::eti()</a></code>.
</p>
</li></ul>

<p><code>"hdi"</code>
</p>

<ul>
<li><p> Applies to <em>all models (including Bayesian models)</em>. For non-Bayesian
models, only applies if <code>bootstrap = TRUE</code>. CIs computed as <em>highest density intervals</em>
for the bootstrap or posterior samples; p-values are based on the <em>probability of direction</em>.
See <code><a href="bayestestR.html#topic+hdi">bayestestR::hdi()</a></code>.
</p>
</li></ul>

<p><code>"bci"</code> (or <code>"bcai"</code>)
</p>

<ul>
<li><p> Applies to <em>all models (including Bayesian models)</em>.
For non-Bayesian models, only applies if <code>bootstrap = TRUE</code>. CIs computed
as <em>bias corrected and accelerated intervals</em> for the bootstrap or
posterior samples; p-values are based on the <em>probability of direction</em>.
See <code><a href="bayestestR.html#topic+bci">bayestestR::bci()</a></code>.
</p>
</li></ul>

<p><code>"si"</code>
</p>

<ul>
<li><p> Applies to <em>Bayesian models</em> with proper priors. CIs computed as
<em>support intervals</em> comparing the posterior samples against the prior samples;
p-values are based on the <em>probability of direction</em>. See <code><a href="bayestestR.html#topic+si">bayestestR::si()</a></code>.
</p>
</li></ul>

<p><code>"boot"</code>
</p>

<ul>
<li><p> Applies to <em>non-Bayesian models</em> of class <code>merMod</code>. CIs computed
using <em>parametric bootstrapping</em> (simulating data from the fitted model);
p-values computed using the Wald method with a <em>normal-distribution)</em>
(note: this might change in a future update!).
</p>
</li></ul>

<p>For all iteration-based methods other than <code>"boot"</code>
(<code>"hdi"</code>, <code>"quantile"</code>, <code>"ci"</code>, <code>"eti"</code>, <code>"si"</code>, <code>"bci"</code>, <code>"bcai"</code>),
p-values are based on the probability of direction (<code><a href="bayestestR.html#topic+p_direction">bayestestR::p_direction()</a></code>),
which is converted into a p-value using <code><a href="bayestestR.html#topic+pd_to_p">bayestestR::pd_to_p()</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(iris)
model &lt;- lm(Petal.Length ~ Sepal.Length + Species, data = iris)
p_value(model)
</code></pre>

<hr>
<h2 id='p_value.BFBayesFactor'>p-values for Bayesian Models</h2><span id='topic+p_value.BFBayesFactor'></span>

<h3>Description</h3>

<p>This function attempts to return, or compute, p-values of Bayesian models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'BFBayesFactor'
p_value(model, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="p_value.BFBayesFactor_+3A_model">model</code></td>
<td>
<p>A statistical model.</p>
</td></tr>
<tr><td><code id="p_value.BFBayesFactor_+3A_...">...</code></td>
<td>
<p>Additional arguments</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For Bayesian models, the p-values corresponds to the <em>probability of
direction</em> (<code><a href="bayestestR.html#topic+p_direction">bayestestR::p_direction()</a></code>), which is converted to a p-value
using <code>bayestestR::convert_pd_to_p()</code>.
</p>


<h3>Value</h3>

<p>The p-values.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(iris)
model &lt;- lm(Petal.Length ~ Sepal.Length + Species, data = iris)
p_value(model)
</code></pre>

<hr>
<h2 id='p_value.DirichletRegModel'>p-values for Models with Special Components</h2><span id='topic+p_value.DirichletRegModel'></span><span id='topic+p_value.averaging'></span><span id='topic+p_value.betareg'></span><span id='topic+p_value.cgam'></span><span id='topic+p_value.clm2'></span>

<h3>Description</h3>

<p>This function attempts to return, or compute, p-values of models
with special model components.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'DirichletRegModel'
p_value(model, component = c("all", "conditional", "precision"), ...)

## S3 method for class 'averaging'
p_value(model, component = c("conditional", "full"), ...)

## S3 method for class 'betareg'
p_value(
  model,
  component = c("all", "conditional", "precision"),
  verbose = TRUE,
  ...
)

## S3 method for class 'cgam'
p_value(model, component = c("all", "conditional", "smooth_terms"), ...)

## S3 method for class 'clm2'
p_value(model, component = c("all", "conditional", "scale"), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="p_value.DirichletRegModel_+3A_model">model</code></td>
<td>
<p>A statistical model.</p>
</td></tr>
<tr><td><code id="p_value.DirichletRegModel_+3A_component">component</code></td>
<td>
<p>Should all parameters, parameters for the conditional model,
precision- or scale-component or smooth_terms be returned? <code>component</code>
may be one of <code>"conditional"</code>, <code>"precision"</code>, <code>"scale"</code>,
<code>"smooth_terms"</code>, <code>"full"</code> or <code>"all"</code> (default).</p>
</td></tr>
<tr><td><code id="p_value.DirichletRegModel_+3A_...">...</code></td>
<td>
<p>Additional arguments</p>
</td></tr>
<tr><td><code id="p_value.DirichletRegModel_+3A_verbose">verbose</code></td>
<td>
<p>Toggle warnings and messages.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The p-values.
</p>

<hr>
<h2 id='p_value.poissonmfx'>p-values for Marginal Effects Models</h2><span id='topic+p_value.poissonmfx'></span><span id='topic+p_value.betaor'></span><span id='topic+p_value.betamfx'></span>

<h3>Description</h3>

<p>This function attempts to return, or compute, p-values of marginal effects
models from package <strong>mfx</strong>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'poissonmfx'
p_value(model, component = c("all", "conditional", "marginal"), ...)

## S3 method for class 'betaor'
p_value(model, component = c("all", "conditional", "precision"), ...)

## S3 method for class 'betamfx'
p_value(
  model,
  component = c("all", "conditional", "precision", "marginal"),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="p_value.poissonmfx_+3A_model">model</code></td>
<td>
<p>A statistical model.</p>
</td></tr>
<tr><td><code id="p_value.poissonmfx_+3A_component">component</code></td>
<td>
<p>Should all parameters, parameters for the conditional model,
precision-component or marginal effects be returned? <code>component</code> may be one
of <code>"conditional"</code>, <code>"precision"</code>, <code>"marginal"</code> or <code>"all"</code> (default).</p>
</td></tr>
<tr><td><code id="p_value.poissonmfx_+3A_...">...</code></td>
<td>
<p>Currently not used.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame with at least two columns: the parameter names and the
p-values. Depending on the model, may also include columns for model
components etc.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (require("mfx", quietly = TRUE)) {
  set.seed(12345)
  n &lt;- 1000
  x &lt;- rnorm(n)
  y &lt;- rnegbin(n, mu = exp(1 + 0.5 * x), theta = 0.5)
  d &lt;- data.frame(y, x)
  model &lt;- poissonmfx(y ~ x, data = d)

  p_value(model)
  p_value(model, component = "marginal")
}
</code></pre>

<hr>
<h2 id='p_value.zcpglm'>p-values for Models with Zero-Inflation</h2><span id='topic+p_value.zcpglm'></span><span id='topic+p_value.zeroinfl'></span>

<h3>Description</h3>

<p>This function attempts to return, or compute, p-values of hurdle and
zero-inflated models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'zcpglm'
p_value(model, component = c("all", "conditional", "zi", "zero_inflated"), ...)

## S3 method for class 'zeroinfl'
p_value(
  model,
  component = c("all", "conditional", "zi", "zero_inflated"),
  method = NULL,
  verbose = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="p_value.zcpglm_+3A_model">model</code></td>
<td>
<p>A statistical model.</p>
</td></tr>
<tr><td><code id="p_value.zcpglm_+3A_component">component</code></td>
<td>
<p>Model component for which parameters should be shown. See
the documentation for your object's class in <code><a href="#topic+model_parameters">model_parameters()</a></code> or
<code><a href="#topic+p_value">p_value()</a></code> for further details.</p>
</td></tr>
<tr><td><code id="p_value.zcpglm_+3A_...">...</code></td>
<td>
<p>Additional arguments</p>
</td></tr>
<tr><td><code id="p_value.zcpglm_+3A_method">method</code></td>
<td>
<p>Method for computing degrees of freedom for
confidence intervals (CI) and the related p-values. Allowed are following
options (which vary depending on the model class): <code>"residual"</code>,
<code>"normal"</code>, <code>"likelihood"</code>, <code>"satterthwaite"</code>, <code>"kenward"</code>, <code>"wald"</code>,
<code>"profile"</code>, <code>"boot"</code>, <code>"uniroot"</code>, <code>"ml1"</code>, <code>"betwithin"</code>, <code>"hdi"</code>,
<code>"quantile"</code>, <code>"ci"</code>, <code>"eti"</code>, <code>"si"</code>, <code>"bci"</code>, or <code>"bcai"</code>. See section
<em>Confidence intervals and approximation of degrees of freedom</em> in
<code><a href="#topic+model_parameters">model_parameters()</a></code> for further details.</p>
</td></tr>
<tr><td><code id="p_value.zcpglm_+3A_verbose">verbose</code></td>
<td>
<p>Toggle warnings and messages.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame with at least two columns: the parameter names and the p-values.
Depending on the model, may also include columns for model components etc.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (require("pscl", quietly = TRUE)) {
  data("bioChemists")
  model &lt;- zeroinfl(art ~ fem + mar + kid5 | kid5 + phd, data = bioChemists)
  p_value(model)
  p_value(model, component = "zi")
}
</code></pre>

<hr>
<h2 id='parameters_type'>Type of model parameters</h2><span id='topic+parameters_type'></span>

<h3>Description</h3>

<p>In a regression model, the parameters do not all have the meaning. For
instance, the intercept has to be interpreted as theoretical outcome value
under some conditions (when predictors are set to 0), whereas other
coefficients are to be interpreted as amounts of change. Others, such as
interactions, represent changes in another of the parameter. The
<code>parameters_type</code> function attempts to retrieve information and meaning
of parameters. It outputs a dataframe of information for each parameters,
such as the <code>Type</code> (whether the parameter corresponds to a factor or a
numeric predictor, or whether it is a (regular) interaction or a nested
one), the <code>Link</code> (whether the parameter can be interpreted as a mean
value, the slope of an association or a difference between two levels) and,
in the case of interactions, which other parameters is impacted by which
parameter.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>parameters_type(model, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="parameters_type_+3A_model">model</code></td>
<td>
<p>A statistical model.</p>
</td></tr>
<tr><td><code id="parameters_type_+3A_...">...</code></td>
<td>
<p>Arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(parameters)

model &lt;- lm(Sepal.Length ~ Petal.Length + Species, data = iris)
parameters_type(model)

model &lt;- lm(Sepal.Length ~ Species + poly(Sepal.Width, 2), data = iris)
parameters_type(model)

model &lt;- lm(Sepal.Length ~ Species + poly(Sepal.Width, 2, raw = TRUE), data = iris)
parameters_type(model)

# Interactions
model &lt;- lm(Sepal.Length ~ Sepal.Width * Species, data = iris)
parameters_type(model)

model &lt;- lm(Sepal.Length ~ Sepal.Width * Species * Petal.Length, data = iris)
parameters_type(model)

model &lt;- lm(Sepal.Length ~ Species * Sepal.Width, data = iris)
parameters_type(model)

model &lt;- lm(Sepal.Length ~ Species / Sepal.Width, data = iris)
parameters_type(model)


# Complex interactions
data &lt;- iris
data$fac2 &lt;- ifelse(data$Sepal.Width &gt; mean(data$Sepal.Width), "A", "B")
model &lt;- lm(Sepal.Length ~ Species / fac2 / Petal.Length, data = data)
parameters_type(model)

model &lt;- lm(Sepal.Length ~ Species / fac2 * Petal.Length, data = data)
parameters_type(model)
</code></pre>

<hr>
<h2 id='parameters-package'>parameters: Extracting, Computing and Exploring the Parameters of Statistical Models using R</h2><span id='topic+parameters-package'></span>

<h3>Description</h3>

<p><strong>parameters</strong>' primary goal is to provide utilities for processing the
parameters of various statistical models (see <a href="https://easystats.github.io/insight/">here</a>
for a list of supported models). Beyond computing <em>p-values</em>, <em>CIs</em>,
<em>Bayesian indices</em> and other measures for a wide variety of models, this
package implements features like <em>bootstrapping</em> of parameters and models,
<em>feature reduction</em> (feature extraction and variable selection), or tools for
data reduction like functions to perform cluster, factor or principal
component analysis.
</p>
<p>Another important goal of the <strong>parameters</strong> package is to facilitate and
streamline the process of reporting results of statistical models, which
includes the easy and intuitive calculation of standardized estimates or
robust standard errors and p-values. <strong>parameters</strong> therefor offers a
simple and unified syntax to process a large variety of (model) objects
from many different packages.
</p>
<p>References: Lüdecke et al. (2020) <a href="https://doi.org/10.21105/joss.02445">doi:10.21105/joss.02445</a>
</p>


<h3>Author(s)</h3>

<p><strong>Maintainer</strong>: Daniel Lüdecke <a href="mailto:d.luedecke@uke.de">d.luedecke@uke.de</a> (<a href="https://orcid.org/0000-0002-8895-3206">ORCID</a>) (@strengejacke)
</p>
<p>Authors:
</p>

<ul>
<li><p> Dominique Makowski <a href="mailto:dom.makowski@gmail.com">dom.makowski@gmail.com</a> (<a href="https://orcid.org/0000-0001-5375-9967">ORCID</a>) (@Dom_Makowski)
</p>
</li>
<li><p> Mattan S. Ben-Shachar <a href="mailto:matanshm@post.bgu.ac.il">matanshm@post.bgu.ac.il</a> (<a href="https://orcid.org/0000-0002-4287-4801">ORCID</a>)
</p>
</li>
<li><p> Indrajeet Patil <a href="mailto:patilindrajeet.science@gmail.com">patilindrajeet.science@gmail.com</a> (<a href="https://orcid.org/0000-0003-1995-6531">ORCID</a>) (@patilindrajeets)
</p>
</li>
<li><p> Søren Højsgaard <a href="mailto:sorenh@math.aau.dk">sorenh@math.aau.dk</a>
</p>
</li>
<li><p> Brenton M. Wiernik <a href="mailto:brenton@wiernik.org">brenton@wiernik.org</a> (<a href="https://orcid.org/0000-0001-9560-6336">ORCID</a>) (@bmwiernik)
</p>
</li></ul>

<p>Other contributors:
</p>

<ul>
<li><p> Zen J. Lau <a href="mailto:zenjuen.lau@ntu.edu.sg">zenjuen.lau@ntu.edu.sg</a> [contributor]
</p>
</li>
<li><p> Vincent Arel-Bundock <a href="mailto:vincent.arel-bundock@umontreal.ca">vincent.arel-bundock@umontreal.ca</a> (<a href="https://orcid.org/0000-0003-1995-6531">ORCID</a>) (@vincentab) [contributor]
</p>
</li>
<li><p> Jeffrey Girard <a href="mailto:me@jmgirard.com">me@jmgirard.com</a> (<a href="https://orcid.org/0000-0002-7359-3746">ORCID</a>) (@jeffreymgirard) [contributor]
</p>
</li>
<li><p> Christina Maimone <a href="mailto:christina.maimone@northwestern.edu">christina.maimone@northwestern.edu</a> [reviewer]
</p>
</li>
<li><p> Niels Ohlsen (@Niels_Bremen) [reviewer]
</p>
</li>
<li><p> Douglas Ezra Morrison <a href="mailto:dmorrison01@ucla.edu">dmorrison01@ucla.edu</a> (<a href="https://orcid.org/0000-0002-7195-830X">ORCID</a>) (@demstats1) [contributor]
</p>
</li>
<li><p> Joseph Luchman <a href="mailto:jluchman@gmail.com">jluchman@gmail.com</a> (<a href="https://orcid.org/0000-0002-8886-9717">ORCID</a>) [contributor]
</p>
</li></ul>



<h3>See Also</h3>

<p>Useful links:
</p>

<ul>
<li> <p><a href="https://easystats.github.io/parameters/">https://easystats.github.io/parameters/</a>
</p>
</li>
<li><p> Report bugs at <a href="https://github.com/easystats/parameters/issues">https://github.com/easystats/parameters/issues</a>
</p>
</li></ul>


<hr>
<h2 id='pool_parameters'>Pool Model Parameters</h2><span id='topic+pool_parameters'></span>

<h3>Description</h3>

<p>This function &quot;pools&quot; (i.e. combines) model parameters in a similar fashion
as <code>mice::pool()</code>. However, this function pools parameters from
<code>parameters_model</code> objects, as returned by
<code><a href="#topic+model_parameters">model_parameters()</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pool_parameters(
  x,
  exponentiate = FALSE,
  effects = "fixed",
  component = "conditional",
  verbose = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pool_parameters_+3A_x">x</code></td>
<td>
<p>A list of <code>parameters_model</code> objects, as returned by
<code><a href="#topic+model_parameters">model_parameters()</a></code>, or a list of model-objects that is supported by
<code>model_parameters()</code>.</p>
</td></tr>
<tr><td><code id="pool_parameters_+3A_exponentiate">exponentiate</code></td>
<td>
<p>Logical, indicating whether or not to exponentiate the
coefficients (and related confidence intervals). This is typical for
logistic regression, or more generally speaking, for models with log or
logit links. It is also recommended to use <code>exponentiate = TRUE</code> for models
with log-transformed response values. <strong>Note:</strong> Delta-method standard
errors are also computed (by multiplying the standard errors by the
transformed coefficients). This is to mimic behaviour of other software
packages, such as Stata, but these standard errors poorly estimate
uncertainty for the transformed coefficient. The transformed confidence
interval more clearly captures this uncertainty. For <code>compare_parameters()</code>,
<code>exponentiate = "nongaussian"</code> will only exponentiate coefficients from
non-Gaussian families.</p>
</td></tr>
<tr><td><code id="pool_parameters_+3A_effects">effects</code></td>
<td>
<p>Should parameters for fixed effects (<code>"fixed"</code>), random
effects (<code>"random"</code>), or both (<code>"all"</code>) be returned? Only applies
to mixed models. May be abbreviated. If the calculation of random effects
parameters takes too long, you may use <code>effects = "fixed"</code>.</p>
</td></tr>
<tr><td><code id="pool_parameters_+3A_component">component</code></td>
<td>
<p>Should all parameters, parameters for the conditional model,
for the zero-inflation part of the model, or the dispersion model be returned?
Applies to models with zero-inflation and/or dispersion component. <code>component</code>
may be one of <code>"conditional"</code>, <code>"zi"</code>, <code>"zero-inflated"</code>, <code>"dispersion"</code> or
<code>"all"</code> (default). May be abbreviated.</p>
</td></tr>
<tr><td><code id="pool_parameters_+3A_verbose">verbose</code></td>
<td>
<p>Toggle warnings and messages.</p>
</td></tr>
<tr><td><code id="pool_parameters_+3A_...">...</code></td>
<td>
<p>Arguments passed down to <code>model_parameters()</code>, if <code>x</code> is a list
of model-objects. Can be used, for instance, to specify arguments like
<code>ci</code> or <code>ci_method</code> etc.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Averaging of parameters follows Rubin's rules (<em>Rubin, 1987, p. 76</em>).
The pooled degrees of freedom is based on the Barnard-Rubin adjustment for
small samples (<em>Barnard and Rubin, 1999</em>).
</p>


<h3>Value</h3>

<p>A data frame of indices related to the model's parameters.
</p>


<h3>Note</h3>

<p>Models with multiple components, (for instance, models with zero-inflation,
where predictors appear in the count and zero-inflation part) may fail in
case of identical names for coefficients in the different model components,
since the coefficient table is grouped by coefficient names for pooling. In
such cases, coefficients of count and zero-inflation model parts would be
combined. Therefore, the <code>component</code> argument defaults to
<code>"conditional"</code> to avoid this.
</p>
<p>Some model objects do not return standard errors (e.g. objects of class
<code>htest</code>). For these models, no pooled confidence intervals nor p-values
are returned.
</p>


<h3>References</h3>

<p>Barnard, J. and Rubin, D.B. (1999). Small sample degrees of freedom with
multiple imputation. Biometrika, 86, 948-955. Rubin, D.B. (1987). Multiple
Imputation for Nonresponse in Surveys. New York: John Wiley and Sons.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# example for multiple imputed datasets
data("nhanes2", package = "mice")
imp &lt;- mice::mice(nhanes2, printFlag = FALSE)
models &lt;- lapply(1:5, function(i) {
  lm(bmi ~ age + hyp + chl, data = mice::complete(imp, action = i))
})
pool_parameters(models)

# should be identical to:
m &lt;- with(data = imp, exp = lm(bmi ~ age + hyp + chl))
summary(mice::pool(m))

# For glm, mice used residual df, while `pool_parameters()` uses `Inf`
nhanes2$hyp &lt;- datawizard::slide(as.numeric(nhanes2$hyp))
imp &lt;- mice::mice(nhanes2, printFlag = FALSE)
models &lt;- lapply(1:5, function(i) {
  glm(hyp ~ age + chl, family = binomial, data = mice::complete(imp, action = i))
})
m &lt;- with(data = imp, exp = glm(hyp ~ age + chl, family = binomial))
# residual df
summary(mice::pool(m))$df
# df = Inf
pool_parameters(models)$df_error
# use residual df instead
pool_parameters(models, ci_method = "residual")$df_error

</code></pre>

<hr>
<h2 id='predict.parameters_clusters'>Predict method for parameters_clusters objects</h2><span id='topic+predict.parameters_clusters'></span>

<h3>Description</h3>

<p>Predict method for parameters_clusters objects
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'parameters_clusters'
predict(object, newdata = NULL, names = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.parameters_clusters_+3A_object">object</code></td>
<td>
<p>a model object for which prediction is desired.</p>
</td></tr>
<tr><td><code id="predict.parameters_clusters_+3A_newdata">newdata</code></td>
<td>
<p>data.frame</p>
</td></tr>
<tr><td><code id="predict.parameters_clusters_+3A_names">names</code></td>
<td>
<p>character vector or list</p>
</td></tr>
<tr><td><code id="predict.parameters_clusters_+3A_...">...</code></td>
<td>
<p>additional arguments affecting the predictions produced.</p>
</td></tr>
</table>

<hr>
<h2 id='print.parameters_model'>Print model parameters</h2><span id='topic+print.parameters_model'></span><span id='topic+summary.parameters_model'></span>

<h3>Description</h3>

<p>A <code>print()</code>-method for objects from <code><a href="#topic+model_parameters">model_parameters()</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'parameters_model'
print(
  x,
  pretty_names = TRUE,
  split_components = TRUE,
  select = NULL,
  caption = NULL,
  footer = NULL,
  digits = 2,
  ci_digits = digits,
  p_digits = 3,
  footer_digits = 3,
  show_sigma = FALSE,
  show_formula = FALSE,
  zap_small = FALSE,
  groups = NULL,
  column_width = NULL,
  ci_brackets = c("[", "]"),
  include_reference = FALSE,
  ...
)

## S3 method for class 'parameters_model'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.parameters_model_+3A_x">x</code>, <code id="print.parameters_model_+3A_object">object</code></td>
<td>
<p>An object returned by <code><a href="#topic+model_parameters">model_parameters()</a></code>.</p>
</td></tr>
<tr><td><code id="print.parameters_model_+3A_pretty_names">pretty_names</code></td>
<td>
<p>Can be <code>TRUE</code>, which will return &quot;pretty&quot; (i.e. more human
readable) parameter names. Or <code>"labels"</code>, in which case value and variable
labels will be used as parameters names. The latter only works for &quot;labelled&quot;
data, i.e. if the data used to fit the model had <code>"label"</code> and <code>"labels"</code>
attributes. See also section <em>Global Options to Customize Messages when Printing</em>.</p>
</td></tr>
<tr><td><code id="print.parameters_model_+3A_split_components">split_components</code></td>
<td>
<p>Logical, if <code>TRUE</code> (default), For models with
multiple components (zero-inflation, smooth terms, ...), each component is
printed in a separate table. If <code>FALSE</code>, model parameters are printed
in a single table and a <code>Component</code> column is added to the output.</p>
</td></tr>
<tr><td><code id="print.parameters_model_+3A_select">select</code></td>
<td>
<p>Determines which columns and and which layout columns are
printed. There are three options for this argument:
</p>

<ol>
<li><p> Selecting columns by name or index
<br />
<code>select</code> can be a character vector (or numeric index) of column names that
should be printed. There are two pre-defined options for selecting columns:
<code>select = "minimal"</code> prints coefficients, confidence intervals and p-values,
while <code>select = "short"</code> prints coefficients, standard errors and p-values.
</p>
</li>
<li><p> A string expression with layout pattern
<br />
<code>select</code> is a string with &quot;tokens&quot; enclosed in braces. These tokens will
be replaced by their associated columns, where the selected columns will
be collapsed into one column. However, it is possible to create multiple
columns as well. Following tokens are replaced by the related coefficients
or statistics: <code>{estimate}</code>, <code>{se}</code>, <code>{ci}</code> (or <code>{ci_low}</code> and <code>{ci_high}</code>),
<code>{p}</code> and <code>{stars}</code>. The token <code>{ci}</code> will be replaced by <code style="white-space: pre;">&#8288;{ci_low}, {ci_high}&#8288;</code>.
Furthermore, a <code>|</code> separates values into new cells/columns. If
<code>format = "html"</code>, a <code style="white-space: pre;">&#8288;&lt;br&gt;&#8288;</code> inserts a line break inside a cell. See
'Examples'.
</p>
</li>
<li><p> A string indicating a pre-defined layout
<br />
<code>select</code> can be one of the following string values, to create one of the
following pre-defined column layouts:
</p>

<ul>
<li> <p><code>"ci"</code>: Estimates and confidence intervals, no asterisks for p-values.
This is equivalent to <code>select = "{estimate} ({ci})"</code>.
</p>
</li>
<li> <p><code>"se"</code>: Estimates and standard errors, no asterisks for p-values. This is
equivalent to <code>select = "{estimate} ({se})"</code>.
</p>
</li>
<li> <p><code>"ci_p"</code>: Estimates, confidence intervals and asterisks for p-values. This
is equivalent to <code>select = "{estimate}{stars} ({ci})"</code>.
</p>
</li>
<li> <p><code>"se_p"</code>: Estimates, standard errors and asterisks for p-values. This is
equivalent to <code>select = "{estimate}{stars} ({se})"</code>..
</p>
</li>
<li> <p><code>"ci_p2"</code>: Estimates, confidence intervals and numeric p-values, in two
columns. This is equivalent to <code>select = "{estimate} ({ci})|{p}"</code>.
</p>
</li>
<li> <p><code>"se_p2"</code>: Estimate, standard errors and numeric p-values, in two columns.
This is equivalent to <code>select = "{estimate} ({se})|{p}"</code>.
</p>
</li></ul>

</li></ol>

<p>For <code>model_parameters()</code>, glue-like syntax is still experimental in the
case of more complex models (like mixed models) and may not return expected
results.</p>
</td></tr>
<tr><td><code id="print.parameters_model_+3A_caption">caption</code></td>
<td>
<p>Table caption as string. If <code>NULL</code>, depending on the model,
either a default caption or no table caption is printed. Use <code>caption = ""</code>
to suppress the table caption.</p>
</td></tr>
<tr><td><code id="print.parameters_model_+3A_footer">footer</code></td>
<td>
<p>Can either be <code>FALSE</code> or an empty string (i.e. <code>""</code>) to
suppress the footer, <code>NULL</code> to print the default footer, or a string. The
latter will combine the string value with the default footer.</p>
</td></tr>
<tr><td><code id="print.parameters_model_+3A_digits">digits</code>, <code id="print.parameters_model_+3A_ci_digits">ci_digits</code>, <code id="print.parameters_model_+3A_p_digits">p_digits</code></td>
<td>
<p>Number of digits for rounding or
significant figures. May also be <code>"signif"</code> to return significant
figures or <code>"scientific"</code> to return scientific notation. Control the
number of digits by adding the value as suffix, e.g. <code>digits = "scientific4"</code>
to have scientific notation with 4 decimal places, or <code>digits = "signif5"</code>
for 5 significant figures (see also <code><a href="base.html#topic+signif">signif()</a></code>).</p>
</td></tr>
<tr><td><code id="print.parameters_model_+3A_footer_digits">footer_digits</code></td>
<td>
<p>Number of decimal places for values in the footer summary.</p>
</td></tr>
<tr><td><code id="print.parameters_model_+3A_show_sigma">show_sigma</code></td>
<td>
<p>Logical, if <code>TRUE</code>, adds information about the residual
standard deviation.</p>
</td></tr>
<tr><td><code id="print.parameters_model_+3A_show_formula">show_formula</code></td>
<td>
<p>Logical, if <code>TRUE</code>, adds the model formula to the output.</p>
</td></tr>
<tr><td><code id="print.parameters_model_+3A_zap_small">zap_small</code></td>
<td>
<p>Logical, if <code>TRUE</code>, small values are rounded after
<code>digits</code> decimal places. If <code>FALSE</code>, values with more decimal
places than <code>digits</code> are printed in scientific notation.</p>
</td></tr>
<tr><td><code id="print.parameters_model_+3A_groups">groups</code></td>
<td>
<p>Named list, can be used to group parameters in the printed output.
List elements may either be character vectors that match the name of those
parameters that belong to one group, or list elements can be row numbers
of those parameter rows that should belong to one group. The names of the
list elements will be used as group names, which will be inserted as &quot;header
row&quot;. A possible use case might be to emphasize focal predictors and control
variables, see 'Examples'. Parameters will be re-ordered according to the
order used in <code>groups</code>, while all non-matching parameters will be added
to the end.</p>
</td></tr>
<tr><td><code id="print.parameters_model_+3A_column_width">column_width</code></td>
<td>
<p>Width of table columns. Can be either <code>NULL</code>, a named
numeric vector, or <code>"fixed"</code>. If <code>NULL</code>, the width for each table column is
adjusted to the minimum required width. If a named numeric vector, value
names are matched against column names, and for each match, the specified
width is used. If <code>"fixed"</code>, and table is split into multiple components,
columns across all table components are adjusted to have the same width.</p>
</td></tr>
<tr><td><code id="print.parameters_model_+3A_ci_brackets">ci_brackets</code></td>
<td>
<p>Logical, if <code>TRUE</code> (default), CI-values are
encompassed in square brackets (else in parentheses).</p>
</td></tr>
<tr><td><code id="print.parameters_model_+3A_include_reference">include_reference</code></td>
<td>
<p>Logical, if <code>TRUE</code>, the reference level of factors will
be added to the parameters table. This is only relevant for models with
categorical predictors. The coefficient for the reference level is always
<code>0</code> (except when <code>exponentiate = TRUE</code>, then the coefficient will be <code>1</code>),
so this is just for completeness.</p>
</td></tr>
<tr><td><code id="print.parameters_model_+3A_...">...</code></td>
<td>
<p>Arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>summary()</code> is a convenient shortcut for
<code>print(object, select = "minimal", show_sigma = TRUE, show_formula = TRUE)</code>.
</p>


<h3>Value</h3>

<p>Invisibly returns the original input object.
</p>


<h3>Global Options to Customize Messages and Tables when Printing</h3>

<p>The <code>verbose</code> argument can be used to display or silence messages and
warnings for the different functions in the <strong>parameters</strong> package. However,
some messages providing additional information can be displayed or suppressed
using <code>options()</code>:
</p>

<ul>
<li> <p><code>parameters_summary</code>: <code>options(parameters_summary = TRUE)</code> will override the
<code>summary</code> argument in <code>model_parameters()</code> and always show the model summary
for non-mixed models.
</p>
</li>
<li> <p><code>parameters_mixed_summary</code>: <code>options(parameters_mixed_summary = TRUE)</code> will
override the <code>summary</code> argument in <code>model_parameters()</code> for mixed models, and
will then always show the model summary.
</p>
</li>
<li> <p><code>parameters_cimethod</code>: <code>options(parameters_cimethod = TRUE)</code> will show the
additional information about the approximation method used to calculate
confidence intervals and p-values. Set to <code>FALSE</code> to hide this message when
printing <code>model_parameters()</code> objects.
</p>
</li>
<li> <p><code>parameters_exponentiate</code>: <code>options(parameters_exponentiate = TRUE)</code> will
show the additional information on how to interpret coefficients of models
with log-transformed response variables or with log-/logit-links when the
<code>exponentiate</code> argument in <code>model_parameters()</code> is not <code>TRUE</code>. Set this option
to <code>FALSE</code> to hide this message when printing <code>model_parameters()</code> objects.
</p>
</li></ul>

<p>There are further options that can be used to modify the default behaviour
for printed outputs:
</p>

<ul>
<li> <p><code>parameters_labels</code>: <code>options(parameters_labels = TRUE)</code> will use variable
and value labels for pretty names, if data is labelled. If no labels
available, default pretty names are used.
</p>
</li>
<li> <p><code>parameters_interaction</code>: <code style="white-space: pre;">&#8288;options(parameters_interaction = &lt;character&gt;)&#8288;</code>
will replace the interaction mark (by default, <code>*</code>) with the related character.
</p>
</li>
<li> <p><code>parameters_select</code>: <code style="white-space: pre;">&#8288;options(parameters_select = &lt;value&gt;)&#8288;</code> will set the
default for the <code>select</code> argument. See argument's documentation for available
options.
</p>
</li>
<li> <p><code>easystats_html_engine</code>: <code>options(easystats_html_engine = "gt")</code> will set
the default HTML engine for tables to <code>gt</code>, i.e. the <em>gt</em> package is used to
create HTML tables. If set to <code>tt</code>, the <em>tinytable</em> package is used.
</p>
</li></ul>



<h3>Interpretation of Interaction Terms</h3>

<p>Note that the <em>interpretation</em> of interaction terms depends on many
characteristics of the model. The number of parameters, and overall
performance of the model, can differ <em>or not</em> between <code>a * b</code>
<code>a : b</code>, and <code>a / b</code>, suggesting that sometimes interaction terms
give different parameterizations of the same model, but other times it gives
completely different models (depending on <code>a</code> or <code>b</code> being factors
of covariates, included as main effects or not, etc.). Their interpretation
depends of the full context of the model, which should not be inferred
from the parameters table alone - rather, we recommend to use packages
that calculate estimated marginal means or marginal effects, such as
<a href="https://CRAN.R-project.org/package=modelbased"><span class="pkg">modelbased</span></a>, <a href="https://CRAN.R-project.org/package=emmeans"><span class="pkg">emmeans</span></a>, <a href="https://CRAN.R-project.org/package=ggeffects"><span class="pkg">ggeffects</span></a>, or
<a href="https://CRAN.R-project.org/package=marginaleffects"><span class="pkg">marginaleffects</span></a>. To raise awareness for this issue, you may use
<code>print(...,show_formula=TRUE)</code> to add the model-specification to the output
of the <code><a href="#topic+print.parameters_model">print()</a></code> method for <code>model_parameters()</code>.
</p>


<h3>Labeling the Degrees of Freedom</h3>

<p>Throughout the <strong>parameters</strong> package, we decided to label the residual
degrees of freedom <em>df_error</em>. The reason for this is that these degrees
of freedom not always refer to the residuals. For certain models, they refer
to the estimate error - in a linear model these are the same, but in - for
instance - any mixed effects model, this isn't strictly true. Hence, we
think that <code>df_error</code> is the most generic label for these degrees of
freedom.
</p>


<h3>See Also</h3>

<p>There is a dedicated method to use inside rmarkdown files,
<code><a href="#topic+print_md.parameters_model">print_md()</a></code>. See also
<code><a href="#topic+display.parameters_model">display()</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

library(parameters)
model &lt;- glmmTMB::glmmTMB(
  count ~ spp + mined + (1 | site),
  ziformula = ~mined,
  family = poisson(),
  data = Salamanders
)
mp &lt;- model_parameters(model)

print(mp, pretty_names = FALSE)

print(mp, split_components = FALSE)

print(mp, select = c("Parameter", "Coefficient", "SE"))

print(mp, select = "minimal")


# group parameters ------

data(iris)
model &lt;- lm(
  Sepal.Width ~ Sepal.Length + Species + Petal.Length,
  data = iris
)
# don't select "Intercept" parameter
mp &lt;- model_parameters(model, parameters = "^(?!\\(Intercept)")
groups &lt;- list(
  "Focal Predictors" = c("Speciesversicolor", "Speciesvirginica"),
  "Controls" = c("Sepal.Length", "Petal.Length")
)
print(mp, groups = groups)

# or use row indices
print(mp, groups = list(
  "Focal Predictors" = c(1, 4),
  "Controls" = c(2, 3)
))

# only show coefficients, CI and p,
# put non-matched parameters to the end

data(mtcars)
mtcars$cyl &lt;- as.factor(mtcars$cyl)
mtcars$gear &lt;- as.factor(mtcars$gear)
model &lt;- lm(mpg ~ hp + gear * vs + cyl + drat, data = mtcars)

# don't select "Intercept" parameter
mp &lt;- model_parameters(model, parameters = "^(?!\\(Intercept)")
print(mp, groups = list(
  "Engine" = c("cyl6", "cyl8", "vs", "hp"),
  "Interactions" = c("gear4:vs", "gear5:vs")
))



# custom column layouts ------

data(iris)
lm1 &lt;- lm(Sepal.Length ~ Species, data = iris)
lm2 &lt;- lm(Sepal.Length ~ Species + Petal.Length, data = iris)

# custom style
result &lt;- compare_parameters(lm1, lm2, select = "{estimate}{stars} ({se})")
print(result)


# custom style, in HTML
result &lt;- compare_parameters(lm1, lm2, select = "{estimate}&lt;br&gt;({se})|{p}")
print_html(result)


</code></pre>

<hr>
<h2 id='qol_cancer'>Sample data set</h2><span id='topic+qol_cancer'></span>

<h3>Description</h3>

<p>A sample data set with longitudinal data, used in the vignette describing the <code>datawizard::demean()</code> function. Health-related quality of life from cancer-patients was measured at three time points (pre-surgery, 6 and 12 months after surgery).
</p>


<h3>Format</h3>

<p>A data frame with 564 rows and 7 variables:
</p>

<dl>
<dt>ID</dt><dd><p>Patient ID</p>
</dd>
<dt>QoL</dt><dd><p>Quality of Life Score</p>
</dd>
<dt>time</dt><dd><p>Timepoint of measurement</p>
</dd>
<dt>age</dt><dd><p>Age in years</p>
</dd>
<dt>phq4</dt><dd><p>Patients' Health Questionnaire, 4-item version</p>
</dd>
<dt>hospital</dt><dd><p>Hospital ID, where patient was treated</p>
</dd>
<dt>education</dt><dd><p>Patients' educational level</p>
</dd>
</dl>


<hr>
<h2 id='random_parameters'>Summary information from random effects</h2><span id='topic+random_parameters'></span>

<h3>Description</h3>

<p>This function extracts the different variance components of a
mixed model and returns the result as a data frame.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>random_parameters(model, component = "conditional")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="random_parameters_+3A_model">model</code></td>
<td>
<p>A mixed effects model (including <code>stanreg</code> models).</p>
</td></tr>
<tr><td><code id="random_parameters_+3A_component">component</code></td>
<td>
<p>Should all parameters, parameters for the conditional model,
for the zero-inflation part of the model, or the dispersion model be returned?
Applies to models with zero-inflation and/or dispersion component. <code>component</code>
may be one of <code>"conditional"</code>, <code>"zi"</code>, <code>"zero-inflated"</code>, <code>"dispersion"</code> or
<code>"all"</code> (default). May be abbreviated.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The variance components are obtained from <code><a href="insight.html#topic+get_variance">insight::get_variance()</a></code> and
are denoted as following:
</p>


<h4>Within-group (or residual) variance</h4>

<p>The residual variance, &sigma;<sup>2</sup><sub>&epsilon;</sub>,
is the sum of the distribution-specific variance and the variance due to additive dispersion.
It indicates the <em>within-group variance</em>.
</p>



<h4>Between-group random intercept variance</h4>

<p>The random intercept variance, or <em>between-group</em> variance
for the intercept (&tau;<sub>00</sub>),
is obtained from <code>VarCorr()</code>. It indicates how much groups
or subjects differ from each other.
</p>



<h4>Between-group random slope variance</h4>

<p>The random slope variance, or <em>between-group</em> variance
for the slopes (&tau;<sub>11</sub>)
is obtained from <code>VarCorr()</code>. This measure is only available
for mixed models with random slopes. It indicates how much groups
or subjects differ from each other according to their slopes.
</p>



<h4>Random slope-intercept correlation</h4>

<p>The random slope-intercept correlation
(&rho;<sub>01</sub>)
is obtained from <code>VarCorr()</code>. This measure is only available
for mixed models with random intercepts and slopes.
</p>
<p><strong>Note:</strong> For the within-group and between-group variance, variance
and standard deviations (which are simply the square root of the variance)
are shown.
</p>



<h3>Value</h3>

<p>A data frame with random effects statistics for the variance components,
including number of levels per random effect group, as well as complete
observations in the model.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (require("lme4")) {
  data(sleepstudy)
  model &lt;- lmer(Reaction ~ Days + (1 + Days | Subject), data = sleepstudy)
  random_parameters(model)
}
</code></pre>

<hr>
<h2 id='reduce_parameters'>Dimensionality reduction (DR) / Features Reduction</h2><span id='topic+reduce_parameters'></span><span id='topic+reduce_data'></span>

<h3>Description</h3>

<p>This function performs a reduction in the parameter space (the number of
variables). It starts by creating a new set of variables, based on the given
method (the default method is &quot;PCA&quot;, but other are available via the
<code>method</code> argument, such as &quot;cMDS&quot;, &quot;DRR&quot; or &quot;ICA&quot;). Then, it names this
new dimensions using the original variables that correlates the most with it.
For instance, a variable named <code>'V1_0.97/V4_-0.88'</code> means that the V1 and the
V4 variables correlate maximally (with respective coefficients of .97 and
-.88) with this dimension. Although this function can be useful in
exploratory data analysis, it's best to perform the dimension reduction step
in a separate and dedicated stage, as this is a very important process in the
data analysis workflow. <code>reduce_data()</code> is an alias for
<code>reduce_parameters.data.frame()</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>reduce_parameters(x, method = "PCA", n = "max", distance = "euclidean", ...)

reduce_data(x, method = "PCA", n = "max", distance = "euclidean", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="reduce_parameters_+3A_x">x</code></td>
<td>
<p>A data frame or a statistical model.</p>
</td></tr>
<tr><td><code id="reduce_parameters_+3A_method">method</code></td>
<td>
<p>The feature reduction method. Can be one of <code>"PCA"</code>, <code>"cMDS"</code>,
<code>"DRR"</code>, <code>"ICA"</code> (see the 'Details' section).</p>
</td></tr>
<tr><td><code id="reduce_parameters_+3A_n">n</code></td>
<td>
<p>Number of components to extract. If <code>n="all"</code>, then <code>n</code> is set as
the number of variables minus 1 (<code>ncol(x)-1</code>). If <code>n="auto"</code> (default) or
<code>n=NULL</code>, the number of components is selected through <code><a href="#topic+n_factors">n_factors()</a></code> resp.
<code><a href="#topic+n_components">n_components()</a></code>. Else, if <code>n</code> is a number, <code>n</code> components are extracted.
If <code>n</code> exceeds number of variables in the data, it is automatically set to
the maximum number (i.e. <code>ncol(x)</code>). In <code><a href="#topic+reduce_parameters">reduce_parameters()</a></code>, can also
be <code>"max"</code>, in which case it will select all the components that are
maximally pseudo-loaded (i.e., correlated) by at least one variable.</p>
</td></tr>
<tr><td><code id="reduce_parameters_+3A_distance">distance</code></td>
<td>
<p>The distance measure to be used. Only applies when
<code>method = "cMDS"</code>. This must be one of <code>"euclidean"</code>, <code>"maximum"</code>,
<code>"manhattan"</code>, <code>"canberra"</code>, <code>"binary"</code> or <code>"minkowski"</code>. Any unambiguous
substring can be given.</p>
</td></tr>
<tr><td><code id="reduce_parameters_+3A_...">...</code></td>
<td>
<p>Arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The different methods available are described below:
</p>


<h4>Supervised Methods</h4>


<ul>
<li> <p><strong>PCA</strong>: See <code><a href="#topic+principal_components">principal_components()</a></code>.
</p>
</li>
<li> <p><strong>cMDS / PCoA</strong>: Classical Multidimensional Scaling (cMDS) takes a
set of dissimilarities (i.e., a distance matrix) and returns a set of points
such that the distances between the points are approximately equal to the
dissimilarities.
</p>
</li>
<li> <p><strong>DRR</strong>: Dimensionality Reduction via Regression (DRR) is a very
recent technique extending PCA (<em>Laparra et al., 2015</em>). Starting from a
rotated PCA, it predicts redundant information from the remaining components
using non-linear regression. Some of the most notable advantages of
performing DRR are avoidance of multicollinearity between predictors and
overfitting mitigation. DRR tends to perform well when the first principal
component is enough to explain most of the variation in the predictors.
Requires the <strong>DRR</strong> package to be installed.
</p>
</li>
<li> <p><strong>ICA</strong>: Performs an Independent Component Analysis using the
FastICA algorithm. Contrary to PCA, which attempts to find uncorrelated
sources (through least squares minimization), ICA attempts to find
independent sources, i.e., the source space that maximizes the
&quot;non-gaussianity&quot; of all sources. Contrary to PCA, ICA does not rank each
source, which makes it a poor tool for dimensionality reduction. Requires the
<strong>fastICA</strong> package to be installed.
</p>
</li></ul>

<p>See also <a href="https://easystats.github.io/parameters/articles/parameters_reduction.html">package vignette</a>.
</p>



<h3>References</h3>


<ul>
<li><p> Nguyen, L. H., and Holmes, S. (2019). Ten quick tips for effective
dimensionality reduction. PLOS Computational Biology, 15(6).
</p>
</li>
<li><p> Laparra, V., Malo, J., and Camps-Valls, G. (2015). Dimensionality
reduction via regression in hyperspectral imagery. IEEE Journal of Selected
Topics in Signal Processing, 9(6), 1026-1036.
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>data(iris)
model &lt;- lm(Sepal.Width ~ Species * Sepal.Length + Petal.Width, data = iris)
model
reduce_parameters(model)

out &lt;- reduce_data(iris, method = "PCA", n = "max")
head(out)
</code></pre>

<hr>
<h2 id='reexports'>Objects exported from other packages</h2><span id='topic+reexports'></span><span id='topic+equivalence_test'></span><span id='topic+ci'></span><span id='topic+n_parameters'></span><span id='topic+standardize_names'></span><span id='topic+supported_models'></span><span id='topic+print_html'></span><span id='topic+print_md'></span><span id='topic+display'></span><span id='topic+describe_distribution'></span><span id='topic+demean'></span><span id='topic+rescale_weights'></span><span id='topic+visualisation_recipe'></span><span id='topic+kurtosis'></span><span id='topic+skewness'></span>

<h3>Description</h3>

<p>These objects are imported from other packages. Follow the links
below to see their documentation.
</p>

<dl>
<dt>bayestestR</dt><dd><p><code><a href="bayestestR.html#topic+ci">ci</a></code>, <code><a href="bayestestR.html#topic+equivalence_test">equivalence_test</a></code></p>
</dd>
<dt>datawizard</dt><dd><p><code><a href="datawizard.html#topic+demean">demean</a></code>, <code><a href="datawizard.html#topic+describe_distribution">describe_distribution</a></code>, <code><a href="datawizard.html#topic+skewness">kurtosis</a></code>, <code><a href="datawizard.html#topic+rescale_weights">rescale_weights</a></code>, <code><a href="datawizard.html#topic+skewness">skewness</a></code>, <code><a href="datawizard.html#topic+visualisation_recipe">visualisation_recipe</a></code></p>
</dd>
<dt>insight</dt><dd><p><code><a href="insight.html#topic+display">display</a></code>, <code><a href="insight.html#topic+n_parameters">n_parameters</a></code>, <code><a href="insight.html#topic+display">print_html</a></code>, <code><a href="insight.html#topic+display">print_md</a></code>, <code><a href="insight.html#topic+standardize_names">standardize_names</a></code>, <code><a href="insight.html#topic+is_model_supported">supported_models</a></code></p>
</dd>
</dl>

<hr>
<h2 id='reshape_loadings'>Reshape loadings between wide/long formats</h2><span id='topic+reshape_loadings'></span><span id='topic+reshape_loadings.parameters_efa'></span><span id='topic+reshape_loadings.data.frame'></span>

<h3>Description</h3>

<p>Reshape loadings between wide/long formats.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>reshape_loadings(x, ...)

## S3 method for class 'parameters_efa'
reshape_loadings(x, threshold = NULL, ...)

## S3 method for class 'data.frame'
reshape_loadings(x, threshold = NULL, loadings_columns = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="reshape_loadings_+3A_x">x</code></td>
<td>
<p>A data frame or a statistical model.</p>
</td></tr>
<tr><td><code id="reshape_loadings_+3A_...">...</code></td>
<td>
<p>Arguments passed to or from other methods.</p>
</td></tr>
<tr><td><code id="reshape_loadings_+3A_threshold">threshold</code></td>
<td>
<p>A value between 0 and 1 indicates which (absolute) values
from the loadings should be removed. An integer higher than 1 indicates the
n strongest loadings to retain. Can also be <code>"max"</code>, in which case it
will only display the maximum loading per variable (the most simple
structure).</p>
</td></tr>
<tr><td><code id="reshape_loadings_+3A_loadings_columns">loadings_columns</code></td>
<td>
<p>Vector indicating the columns corresponding to loadings.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>if (require("psych")) {
  pca &lt;- model_parameters(psych::fa(attitude, nfactors = 3))
  loadings &lt;- reshape_loadings(pca)

  loadings
  reshape_loadings(loadings)
}
</code></pre>

<hr>
<h2 id='select_parameters'>Automated selection of model parameters</h2><span id='topic+select_parameters'></span><span id='topic+select_parameters.lm'></span><span id='topic+select_parameters.merMod'></span>

<h3>Description</h3>

<p>This function performs an automated selection of the 'best' parameters,
updating and returning the &quot;best&quot; model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>select_parameters(model, ...)

## S3 method for class 'lm'
select_parameters(model, direction = "both", steps = 1000, k = 2, ...)

## S3 method for class 'merMod'
select_parameters(model, direction = "backward", steps = 1000, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="select_parameters_+3A_model">model</code></td>
<td>
<p>A statistical model (of class <code>lm</code>, <code>glm</code>, or <code>merMod</code>).</p>
</td></tr>
<tr><td><code id="select_parameters_+3A_...">...</code></td>
<td>
<p>Arguments passed to or from other methods.</p>
</td></tr>
<tr><td><code id="select_parameters_+3A_direction">direction</code></td>
<td>

<p>the mode of stepwise search, can be one of <code>"both"</code>,
<code>"backward"</code>, or <code>"forward"</code>, with a default of <code>"both"</code>.
If the <code>scope</code> argument is missing the default for
<code>direction</code> is <code>"backward"</code>.  Values can be abbreviated.
</p>
</td></tr>
<tr><td><code id="select_parameters_+3A_steps">steps</code></td>
<td>

<p>the maximum number of steps to be considered.  The default is 1000
(essentially as many as required).  It is typically used to stop the
process early.
</p>
</td></tr>
<tr><td><code id="select_parameters_+3A_k">k</code></td>
<td>

<p>the multiple of the number of degrees of freedom used for the penalty.
Only <code>k = 2</code> gives the genuine AIC: <code>k = log(n)</code> is sometimes
referred to as BIC or SBC.
</p>
</td></tr>
</table>


<h3>Details</h3>



<h4>Classical lm and glm</h4>

<p>For frequentist GLMs, <code>select_parameters()</code> performs an AIC-based
stepwise selection.
</p>



<h4>Mixed models</h4>

<p>For mixed-effects models of class <code>merMod</code>, stepwise selection is
based on <code><a href="cAIC4.html#topic+stepcAIC">cAIC4::stepcAIC()</a></code>. This step function
only searches the &quot;best&quot; model based on the random-effects structure,
i.e. <code>select_parameters()</code> adds or excludes random-effects until
the cAIC can't be improved further.
</p>



<h3>Value</h3>

<p>The model refitted with optimal number of parameters.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>model &lt;- lm(mpg ~ ., data = mtcars)
select_parameters(model)

model &lt;- lm(mpg ~ cyl * disp * hp * wt, data = mtcars)
select_parameters(model)

# lme4 -------------------------------------------
if (require("lme4")) {
  model &lt;- lmer(
    Sepal.Width ~ Sepal.Length * Petal.Width * Petal.Length + (1 | Species),
    data = iris
  )
  select_parameters(model)
}


</code></pre>

<hr>
<h2 id='simulate_model'>Simulated draws from model coefficients</h2><span id='topic+simulate_model'></span><span id='topic+simulate_model.glmmTMB'></span>

<h3>Description</h3>

<p>Simulate draws from a statistical model to return a data frame
of estimates.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simulate_model(model, iterations = 1000, ...)

## S3 method for class 'glmmTMB'
simulate_model(
  model,
  iterations = 1000,
  component = c("all", "conditional", "zi", "zero_inflated", "dispersion"),
  verbose = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="simulate_model_+3A_model">model</code></td>
<td>
<p>Statistical model (no Bayesian models).</p>
</td></tr>
<tr><td><code id="simulate_model_+3A_iterations">iterations</code></td>
<td>
<p>The number of draws to simulate/bootstrap.</p>
</td></tr>
<tr><td><code id="simulate_model_+3A_...">...</code></td>
<td>
<p>Arguments passed to <code><a href="insight.html#topic+get_varcov">insight::get_varcov()</a></code>, e.g. to allow simulated
draws to be based on heteroscedasticity consistent variance covariance matrices.</p>
</td></tr>
<tr><td><code id="simulate_model_+3A_component">component</code></td>
<td>
<p>Should all parameters, parameters for the conditional model,
for the zero-inflation part of the model, or the dispersion model be returned?
Applies to models with zero-inflation and/or dispersion component. <code>component</code>
may be one of <code>"conditional"</code>, <code>"zi"</code>, <code>"zero-inflated"</code>, <code>"dispersion"</code> or
<code>"all"</code> (default). May be abbreviated.</p>
</td></tr>
<tr><td><code id="simulate_model_+3A_verbose">verbose</code></td>
<td>
<p>Toggle warnings and messages.</p>
</td></tr>
</table>


<h3>Details</h3>



<h4>Technical Details</h4>

<p><code>simulate_model()</code> is a computationally faster alternative
to <code>bootstrap_model()</code>. Simulated draws for coefficients are based
on a multivariate normal distribution (<code>MASS::mvrnorm()</code>) with mean
<code>mu = coef(model)</code> and variance <code>Sigma = vcov(model)</code>.
</p>



<h4>Models with Zero-Inflation Component</h4>

<p>For models from packages <strong>glmmTMB</strong>, <strong>pscl</strong>, <strong>GLMMadaptive</strong> and
<strong>countreg</strong>, the <code>component</code> argument can be used to specify
which parameters should be simulated. For all other models, parameters
from the conditional component (fixed effects) are simulated. This may
include smooth terms, but not random effects.
</p>



<h3>Value</h3>

<p>A data frame.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+simulate_parameters">simulate_parameters()</a></code>, <code><a href="#topic+bootstrap_model">bootstrap_model()</a></code>, <code><a href="#topic+bootstrap_parameters">bootstrap_parameters()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>model &lt;- lm(Sepal.Length ~ Species * Petal.Width + Petal.Length, data = iris)
head(simulate_model(model))

if (require("glmmTMB", quietly = TRUE)) {
  model &lt;- glmmTMB(
    count ~ spp + mined + (1 | site),
    ziformula = ~mined,
    family = poisson(),
    data = Salamanders
  )
  head(simulate_model(model))
  head(simulate_model(model, component = "zero_inflated"))
}

</code></pre>

<hr>
<h2 id='simulate_parameters.glmmTMB'>Simulate Model Parameters</h2><span id='topic+simulate_parameters.glmmTMB'></span><span id='topic+simulate_parameters'></span><span id='topic+simulate_parameters.default'></span>

<h3>Description</h3>

<p>Compute simulated draws of parameters and their related indices
such as Confidence Intervals (CI) and p-values. Simulating parameter draws
can be seen as a (computationally faster) alternative to bootstrapping.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'glmmTMB'
simulate_parameters(
  model,
  iterations = 1000,
  centrality = "median",
  ci = 0.95,
  ci_method = "quantile",
  test = "p-value",
  ...
)

simulate_parameters(model, ...)

## Default S3 method:
simulate_parameters(
  model,
  iterations = 1000,
  centrality = "median",
  ci = 0.95,
  ci_method = "quantile",
  test = "p-value",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="simulate_parameters.glmmTMB_+3A_model">model</code></td>
<td>
<p>Statistical model (no Bayesian models).</p>
</td></tr>
<tr><td><code id="simulate_parameters.glmmTMB_+3A_iterations">iterations</code></td>
<td>
<p>The number of draws to simulate/bootstrap.</p>
</td></tr>
<tr><td><code id="simulate_parameters.glmmTMB_+3A_centrality">centrality</code></td>
<td>
<p>The point-estimates (centrality indices) to compute. Character
(vector) or list with one or more of these options: <code>"median"</code>, <code>"mean"</code>, <code>"MAP"</code>
(see <code><a href="bayestestR.html#topic+map_estimate">map_estimate()</a></code>), <code>"trimmed"</code> (which is just <code>mean(x, trim = threshold)</code>),
<code>"mode"</code> or <code>"all"</code>.</p>
</td></tr>
<tr><td><code id="simulate_parameters.glmmTMB_+3A_ci">ci</code></td>
<td>
<p>Value or vector of probability of the CI (between 0 and 1)
to be estimated. Default to <code>0.95</code> (<code style="white-space: pre;">&#8288;95%&#8288;</code>).</p>
</td></tr>
<tr><td><code id="simulate_parameters.glmmTMB_+3A_ci_method">ci_method</code></td>
<td>
<p>The type of index used for Credible Interval. Can be
<code>"ETI"</code> (default, see <code><a href="bayestestR.html#topic+eti">eti()</a></code>), <code>"HDI"</code>
(see <code><a href="bayestestR.html#topic+hdi">hdi()</a></code>), <code>"BCI"</code> (see
<code><a href="bayestestR.html#topic+bci">bci()</a></code>), <code>"SPI"</code> (see <code><a href="bayestestR.html#topic+spi">spi()</a></code>), or
<code>"SI"</code> (see <code><a href="bayestestR.html#topic+si">si()</a></code>).</p>
</td></tr>
<tr><td><code id="simulate_parameters.glmmTMB_+3A_test">test</code></td>
<td>
<p>The indices of effect existence to compute. Character (vector) or
list with one or more of these options: <code>"p_direction"</code> (or <code>"pd"</code>),
<code>"rope"</code>, <code>"p_map"</code>, <code>"equivalence_test"</code> (or <code>"equitest"</code>),
<code>"bayesfactor"</code> (or <code>"bf"</code>) or <code>"all"</code> to compute all tests.
For each &quot;test&quot;, the corresponding <span class="pkg">bayestestR</span> function is called
(e.g. <code><a href="bayestestR.html#topic+rope">rope()</a></code> or <code><a href="bayestestR.html#topic+p_direction">p_direction()</a></code>) and its results
included in the summary output.</p>
</td></tr>
<tr><td><code id="simulate_parameters.glmmTMB_+3A_...">...</code></td>
<td>
<p>Arguments passed to <code><a href="insight.html#topic+get_varcov">insight::get_varcov()</a></code>, e.g. to allow simulated
draws to be based on heteroscedasticity consistent variance covariance matrices.</p>
</td></tr>
</table>


<h3>Details</h3>



<h4>Technical Details</h4>

<p><code>simulate_parameters()</code> is a computationally faster alternative
to <code>bootstrap_parameters()</code>. Simulated draws for coefficients are based
on a multivariate normal distribution (<code>MASS::mvrnorm()</code>) with mean
<code>mu = coef(model)</code> and variance <code>Sigma = vcov(model)</code>.
</p>



<h4>Models with Zero-Inflation Component</h4>

<p>For models from packages <strong>glmmTMB</strong>, <strong>pscl</strong>, <strong>GLMMadaptive</strong> and
<strong>countreg</strong>, the <code>component</code> argument can be used to specify
which parameters should be simulated. For all other models, parameters
from the conditional component (fixed effects) are simulated. This may
include smooth terms, but not random effects.
</p>



<h3>Value</h3>

<p>A data frame with simulated parameters.
</p>


<h3>Note</h3>

<p>There is also a <a href="https://easystats.github.io/see/articles/parameters.html"><code>plot()</code>-method</a> implemented in the <a href="https://easystats.github.io/see/"><strong>see</strong>-package</a>.
</p>


<h3>References</h3>

<p>Gelman A, Hill J. Data analysis using regression and
multilevel/hierarchical models. Cambridge; New York: Cambridge University
Press 2007: 140-143
</p>


<h3>See Also</h3>

<p><code><a href="#topic+bootstrap_model">bootstrap_model()</a></code>, <code><a href="#topic+bootstrap_parameters">bootstrap_parameters()</a></code>, <code><a href="#topic+simulate_model">simulate_model()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>model &lt;- lm(Sepal.Length ~ Species * Petal.Width + Petal.Length, data = iris)
simulate_parameters(model)


if (require("glmmTMB", quietly = TRUE)) {
  model &lt;- glmmTMB(
    count ~ spp + mined + (1 | site),
    ziformula = ~mined,
    family = poisson(),
    data = Salamanders
  )
  simulate_parameters(model, centrality = "mean")
  simulate_parameters(model, ci = c(.8, .95), component = "zero_inflated")
}

</code></pre>

<hr>
<h2 id='sort_parameters'>Sort parameters by coefficient values</h2><span id='topic+sort_parameters'></span><span id='topic+sort_parameters.default'></span>

<h3>Description</h3>

<p>Sort parameters by coefficient values
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sort_parameters(x, ...)

## Default S3 method:
sort_parameters(x, sort = "none", column = "Coefficient", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sort_parameters_+3A_x">x</code></td>
<td>
<p>A data frame or a <code>parameters_model</code> object.</p>
</td></tr>
<tr><td><code id="sort_parameters_+3A_...">...</code></td>
<td>
<p>Arguments passed to or from other methods.</p>
</td></tr>
<tr><td><code id="sort_parameters_+3A_sort">sort</code></td>
<td>
<p>If <code>"none"</code> (default) do not sort, <code>"ascending"</code> sort by
increasing coefficient value, or <code>"descending"</code> sort by decreasing
coefficient value.</p>
</td></tr>
<tr><td><code id="sort_parameters_+3A_column">column</code></td>
<td>
<p>The column containing model parameter estimates. This will be
<code>"Coefficient"</code> (default) in <em>easystats</em> packages, <code>"estimate"</code> in <em>broom</em>
package, etc.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A sorted data frame or original object.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># creating object to sort (can also be a regular data frame)
mod &lt;- model_parameters(stats::lm(wt ~ am * cyl, data = mtcars))

# original output
mod

# sorted outputs
sort_parameters(mod, sort = "ascending")
sort_parameters(mod, sort = "descending")

</code></pre>

<hr>
<h2 id='standard_error'>Standard Errors</h2><span id='topic+standard_error'></span><span id='topic+standard_error.default'></span><span id='topic+standard_error.factor'></span><span id='topic+standard_error.glmmTMB'></span><span id='topic+standard_error.merMod'></span>

<h3>Description</h3>

<p><code>standard_error()</code> attempts to return standard errors of model
parameters.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>standard_error(model, ...)

## Default S3 method:
standard_error(
  model,
  component = "all",
  vcov = NULL,
  vcov_args = NULL,
  verbose = TRUE,
  ...
)

## S3 method for class 'factor'
standard_error(model, force = FALSE, verbose = TRUE, ...)

## S3 method for class 'glmmTMB'
standard_error(
  model,
  effects = "fixed",
  component = "all",
  verbose = TRUE,
  ...
)

## S3 method for class 'merMod'
standard_error(
  model,
  effects = "fixed",
  method = NULL,
  vcov = NULL,
  vcov_args = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="standard_error_+3A_model">model</code></td>
<td>
<p>A model.</p>
</td></tr>
<tr><td><code id="standard_error_+3A_...">...</code></td>
<td>
<p>Arguments passed to or from other methods.</p>
</td></tr>
<tr><td><code id="standard_error_+3A_component">component</code></td>
<td>
<p>Model component for which standard errors should be shown.
See the documentation for your object's class in <code><a href="#topic+model_parameters">model_parameters()</a></code> or
<code><a href="#topic+p_value">p_value()</a></code> for further details.</p>
</td></tr>
<tr><td><code id="standard_error_+3A_vcov">vcov</code></td>
<td>
<p>Variance-covariance matrix used to compute uncertainty estimates
(e.g., for robust standard errors). This argument accepts a covariance matrix,
a function which returns a covariance matrix, or a string which identifies
the function to be used to compute the covariance matrix.
</p>

<ul>
<li><p> A covariance matrix
</p>
</li>
<li><p> A function which returns a covariance matrix (e.g., <code>stats::vcov()</code>)
</p>
</li>
<li><p> A string which indicates the kind of uncertainty estimates to return.
</p>

<ul>
<li><p> Heteroskedasticity-consistent: <code>"vcovHC"</code>, <code>"HC"</code>, <code>"HC0"</code>, <code>"HC1"</code>,
<code>"HC2"</code>, <code>"HC3"</code>, <code>"HC4"</code>, <code>"HC4m"</code>, <code>"HC5"</code>. See <code>?sandwich::vcovHC</code>.
</p>
</li>
<li><p> Cluster-robust: <code>"vcovCR"</code>, <code>"CR0"</code>, <code>"CR1"</code>, <code>"CR1p"</code>, <code>"CR1S"</code>, <code>"CR2"</code>,
<code>"CR3"</code>. See <code>?clubSandwich::vcovCR</code>.
</p>
</li>
<li><p> Bootstrap: <code>"vcovBS"</code>, <code>"xy"</code>, <code>"residual"</code>, <code>"wild"</code>, <code>"mammen"</code>, <code>"webb"</code>.
See <code>?sandwich::vcovBS</code>.
</p>
</li>
<li><p> Other <code>sandwich</code> package functions: <code>"vcovHAC"</code>, <code>"vcovPC"</code>, <code>"vcovCL"</code>, <code>"vcovPL"</code>.
</p>
</li></ul>

</li></ul>
</td></tr>
<tr><td><code id="standard_error_+3A_vcov_args">vcov_args</code></td>
<td>
<p>List of arguments to be passed to the function identified by
the <code>vcov</code> argument. This function is typically supplied by the <strong>sandwich</strong>
or <strong>clubSandwich</strong> packages. Please refer to their documentation (e.g.,
<code>?sandwich::vcovHAC</code>) to see the list of available arguments.</p>
</td></tr>
<tr><td><code id="standard_error_+3A_verbose">verbose</code></td>
<td>
<p>Toggle warnings and messages.</p>
</td></tr>
<tr><td><code id="standard_error_+3A_force">force</code></td>
<td>
<p>Logical, if <code>TRUE</code>, factors are converted to numerical
values to calculate the standard error, with the lowest level being the
value <code>1</code> (unless the factor has numeric levels, which are converted
to the corresponding numeric value). By default, <code>NA</code> is returned for
factors or character vectors.</p>
</td></tr>
<tr><td><code id="standard_error_+3A_effects">effects</code></td>
<td>
<p>Should standard errors for fixed effects (<code>"fixed"</code>), random
effects (<code>"random"</code>), or both (<code>"all"</code>) be returned? Only applies
to mixed models. May be abbreviated. When standard errors for random
effects are requested, for each grouping factor a list of standard errors
(per group level) for random intercepts and slopes is returned.</p>
</td></tr>
<tr><td><code id="standard_error_+3A_method">method</code></td>
<td>
<p>Method for computing degrees of freedom for
confidence intervals (CI) and the related p-values. Allowed are following
options (which vary depending on the model class): <code>"residual"</code>,
<code>"normal"</code>, <code>"likelihood"</code>, <code>"satterthwaite"</code>, <code>"kenward"</code>, <code>"wald"</code>,
<code>"profile"</code>, <code>"boot"</code>, <code>"uniroot"</code>, <code>"ml1"</code>, <code>"betwithin"</code>, <code>"hdi"</code>,
<code>"quantile"</code>, <code>"ci"</code>, <code>"eti"</code>, <code>"si"</code>, <code>"bci"</code>, or <code>"bcai"</code>. See section
<em>Confidence intervals and approximation of degrees of freedom</em> in
<code><a href="#topic+model_parameters">model_parameters()</a></code> for further details.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame with at least two columns: the parameter names and the
standard errors. Depending on the model, may also include columns for model
components etc.
</p>


<h3>Note</h3>

<p>For Bayesian models (from <strong>rstanarm</strong> or <strong>brms</strong>), the standard
error is the SD of the posterior samples.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>model &lt;- lm(Petal.Length ~ Sepal.Length * Species, data = iris)
standard_error(model)

if (require("sandwich") &amp;&amp; require("clubSandwich")) {
  standard_error(model, vcov = "HC3")

  standard_error(model,
    vcov = "vcovCL",
    vcov_args = list(cluster = iris$Species)
  )
}
</code></pre>

<hr>
<h2 id='standardize_info'>Get Standardization Information</h2><span id='topic+standardize_info'></span><span id='topic+standardise_info'></span><span id='topic+standardize_info.default'></span>

<h3>Description</h3>

<p>This function extracts information, such as the deviations (SD or MAD) from
parent variables, that are necessary for post-hoc standardization of
parameters. This function gives a window on how standardized are obtained,
i.e., by what they are divided. The &quot;basic&quot; method of standardization uses.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>standardize_info(model, ...)

## Default S3 method:
standardize_info(
  model,
  robust = FALSE,
  two_sd = FALSE,
  include_pseudo = FALSE,
  verbose = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="standardize_info_+3A_model">model</code></td>
<td>
<p>A statistical model.</p>
</td></tr>
<tr><td><code id="standardize_info_+3A_...">...</code></td>
<td>
<p>Arguments passed to or from other methods.</p>
</td></tr>
<tr><td><code id="standardize_info_+3A_robust">robust</code></td>
<td>
<p>Logical, if <code>TRUE</code>, centering is done by subtracting the
median from the variables and dividing it by the median absolute deviation
(MAD). If <code>FALSE</code>, variables are standardized by subtracting the
mean and dividing it by the standard deviation (SD).</p>
</td></tr>
<tr><td><code id="standardize_info_+3A_two_sd">two_sd</code></td>
<td>
<p>If <code>TRUE</code>, the variables are scaled by two times the deviation
(SD or MAD depending on <code>robust</code>). This method can be useful to obtain
model coefficients of continuous parameters comparable to coefficients
related to binary predictors, when applied to <strong>the predictors</strong> (not the
outcome) (Gelman, 2008).</p>
</td></tr>
<tr><td><code id="standardize_info_+3A_include_pseudo">include_pseudo</code></td>
<td>
<p>(For (G)LMMs) Should Pseudo-standardized information be
included?</p>
</td></tr>
<tr><td><code id="standardize_info_+3A_verbose">verbose</code></td>
<td>
<p>Toggle warnings and messages on or off.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame with information on each parameter (see
<code><a href="#topic+parameters_type">parameters_type()</a></code>), and various standardization coefficients
for the post-hoc methods (see <code><a href="#topic+standardize_parameters">standardize_parameters()</a></code>) for the predictor
and the response.
</p>


<h3>See Also</h3>

<p>Other standardize: 
<code><a href="#topic+standardize_parameters">standardize_parameters</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>model &lt;- lm(mpg ~ ., data = mtcars)
standardize_info(model)
standardize_info(model, robust = TRUE)
standardize_info(model, two_sd = TRUE)
</code></pre>

<hr>
<h2 id='standardize_parameters'>Parameters standardization</h2><span id='topic+standardize_parameters'></span><span id='topic+standardise_parameters'></span><span id='topic+standardize_posteriors'></span><span id='topic+standardise_posteriors'></span>

<h3>Description</h3>

<p>Compute standardized model parameters (coefficients).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>standardize_parameters(
  model,
  method = "refit",
  ci = 0.95,
  robust = FALSE,
  two_sd = FALSE,
  include_response = TRUE,
  verbose = TRUE,
  ...
)

standardize_posteriors(
  model,
  method = "refit",
  robust = FALSE,
  two_sd = FALSE,
  include_response = TRUE,
  verbose = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="standardize_parameters_+3A_model">model</code></td>
<td>
<p>A statistical model.</p>
</td></tr>
<tr><td><code id="standardize_parameters_+3A_method">method</code></td>
<td>
<p>The method used for standardizing the parameters. Can be
<code>"refit"</code> (default), <code>"posthoc"</code>, <code>"smart"</code>, <code>"basic"</code>, <code>"pseudo"</code> or
<code>"sdy"</code>. See Details'.</p>
</td></tr>
<tr><td><code id="standardize_parameters_+3A_ci">ci</code></td>
<td>
<p>Confidence Interval (CI) level</p>
</td></tr>
<tr><td><code id="standardize_parameters_+3A_robust">robust</code></td>
<td>
<p>Logical, if <code>TRUE</code>, centering is done by subtracting the
median from the variables and dividing it by the median absolute deviation
(MAD). If <code>FALSE</code>, variables are standardized by subtracting the
mean and dividing it by the standard deviation (SD).</p>
</td></tr>
<tr><td><code id="standardize_parameters_+3A_two_sd">two_sd</code></td>
<td>
<p>If <code>TRUE</code>, the variables are scaled by two times the deviation
(SD or MAD depending on <code>robust</code>). This method can be useful to obtain
model coefficients of continuous parameters comparable to coefficients
related to binary predictors, when applied to <strong>the predictors</strong> (not the
outcome) (Gelman, 2008).</p>
</td></tr>
<tr><td><code id="standardize_parameters_+3A_include_response">include_response</code></td>
<td>
<p>If <code>TRUE</code> (default), the response value will also be
standardized. If <code>FALSE</code>, only the predictors will be standardized. For
GLMs the response value will never be standardized (see <em>Generalized Linear
Models</em> section).</p>
</td></tr>
<tr><td><code id="standardize_parameters_+3A_verbose">verbose</code></td>
<td>
<p>Toggle warnings and messages on or off.</p>
</td></tr>
<tr><td><code id="standardize_parameters_+3A_...">...</code></td>
<td>
<p>For <code>standardize_parameters()</code>, arguments passed to
<code><a href="#topic+model_parameters">model_parameters()</a></code>, such as:
</p>

<ul>
<li> <p><code>ci_method</code>, <code>centrality</code> for Mixed models and Bayesian models...
</p>
</li>
<li> <p><code>exponentiate</code>, ...
</p>
</li>
<li><p> etc.
</p>
</li></ul>
</td></tr>
</table>


<h3>Details</h3>



<h4>Standardization Methods</h4>


<ul>
<li> <p><strong>refit</strong>: This method is based on a complete model re-fit with a
standardized version of the data. Hence, this method is equal to
standardizing the variables before fitting the model. It is the &quot;purest&quot; and
the most accurate (Neter et al., 1989), but it is also the most
computationally costly and long (especially for heavy models such as Bayesian
models). This method is particularly recommended for complex models that
include interactions or transformations (e.g., polynomial or spline terms).
The <code>robust</code> (default to <code>FALSE</code>) argument enables a robust standardization
of data, i.e., based on the <code>median</code> and <code>MAD</code> instead of the <code>mean</code> and
<code>SD</code>. <strong>See <code><a href="datawizard.html#topic+standardize">standardize()</a></code> for more details.</strong>
</p>

<ul>
<li> <p><strong>Note</strong> that <code>standardize_parameters(method = "refit")</code> may not return
the same results as fitting a model on data that has been standardized with
<code>standardize()</code>; <code>standardize_parameters()</code> used the data used by the model
fitting function, which might not be same data if there are missing values.
see the <code>remove_na</code> argument in <code>standardize()</code>.
</p>
</li></ul>

</li>
<li> <p><strong>posthoc</strong>: Post-hoc standardization of the parameters, aiming at
emulating the results obtained by &quot;refit&quot; without refitting the model. The
coefficients are divided by the standard deviation (or MAD if <code>robust</code>) of
the outcome (which becomes their expression 'unit'). Then, the coefficients
related to numeric variables are additionally multiplied by the standard
deviation (or MAD if <code>robust</code>) of the related terms, so that they correspond
to changes of 1 SD of the predictor (e.g., &quot;A change in 1 SD of <code>x</code> is
related to a change of 0.24 of the SD of <code>y</code>). This does not apply to binary
variables or factors, so the coefficients are still related to changes in
levels. This method is not accurate and tend to give aberrant results when
interactions are specified.
</p>
</li>
<li> <p><strong>basic</strong>: This method is similar to <code>method = "posthoc"</code>, but treats all
variables as continuous: it also scales the coefficient by the standard
deviation of model's matrix' parameter of factors levels (transformed to
integers) or binary predictors. Although being inappropriate for these cases,
this method is the one implemented by default in other software packages,
such as <code><a href="lm.beta.html#topic+lm.beta">lm.beta::lm.beta()</a></code>.
</p>
</li>
<li> <p><strong>smart</strong> (Standardization of Model's parameters with Adjustment,
Reconnaissance and Transformation - <em>experimental</em>): Similar to <code>method = "posthoc"</code> in that it does not involve model refitting. The difference is
that the SD (or MAD if <code>robust</code>) of the response is computed on the relevant
section of the data. For instance, if a factor with 3 levels A (the
intercept), B and C is entered as a predictor, the effect corresponding to B
vs. A will be scaled by the variance of the response at the intercept only.
As a results, the coefficients for effects of factors are similar to a Glass'
delta.
</p>
</li>
<li> <p><strong>pseudo</strong> (<em>for 2-level (G)LMMs only</em>): In this (post-hoc) method, the
response and the predictor are standardized based on the level of prediction
(levels are detected with <code><a href="performance.html#topic+check_heterogeneity_bias">performance::check_heterogeneity_bias()</a></code>): Predictors
are standardized based on their SD at level of prediction (see also
<code><a href="datawizard.html#topic+demean">datawizard::demean()</a></code>); The outcome (in linear LMMs) is standardized based
on a fitted random-intercept-model, where <code>sqrt(random-intercept-variance)</code>
is used for level 2 predictors, and <code>sqrt(residual-variance)</code> is used for
level 1 predictors (Hoffman 2015, page 342). A warning is given when a
within-group variable is found to have access between-group variance.
</p>
</li>
<li> <p><strong>sdy</strong> (<em>for logistic regression models only</em>): This y-standardization
is useful when comparing coefficients of logistic regression models across
models for the same sample. Unobserved heterogeneity varies across models
with different independent variables, and thus, odds ratios from the same
predictor of different models cannot be compared directly. The
y-standardization makes coefficients &quot;comparable across models by dividing
them with the estimated standard deviation of the latent variable for each
model&quot; (Mood 2010). Thus, whenever one has multiple logistic regression models
that are fit to the same data and share certain predictors (e.g. nested
models), it can be useful to use this standardization approach to make
log-odds or odds ratios comparable.
</p>
</li></ul>




<h4>Transformed Variables</h4>

<p>When the model's formula contains transformations (e.g. <code>y ~ exp(X)</code>) <code>method = "refit"</code> will give different results compared to <code>method = "basic"</code>
(<code>"posthoc"</code> and <code>"smart"</code> do not support such transformations): While
<code>"refit"</code> standardizes the data <em>prior</em> to the transformation (e.g.
equivalent to <code>exp(scale(X))</code>), the <code>"basic"</code> method standardizes the
transformed data (e.g. equivalent to <code>scale(exp(X))</code>).
<br /><br />
See the <em>Transformed Variables</em> section in <code><a href="datawizard.html#topic+standardize.default">standardize.default()</a></code> for more
details on how different transformations are dealt with when <code>method = "refit"</code>.
</p>



<h4>Confidence Intervals</h4>

<p>The returned confidence intervals are re-scaled versions of the
unstandardized confidence intervals, and not &quot;true&quot; confidence intervals of
the standardized coefficients (cf. Jones &amp; Waller, 2015).
</p>



<h4>Generalized Linear Models</h4>

<p>Standardization for generalized linear models (GLM, GLMM, etc) is done only
with respect to the predictors (while the outcome remains as-is,
unstandardized) - maintaining the interpretability of the coefficients (e.g.,
in a binomial model: the exponent of the standardized parameter is the OR of
a change of 1 SD in the predictor, etc.)
</p>



<h4>Dealing with Factors</h4>

<p><code>standardize(model)</code> or <code>standardize_parameters(model, method = "refit")</code> do
<em>not</em> standardize categorical predictors (i.e. factors) / their
dummy-variables, which may be a different behaviour compared to other R
packages (such as <span class="pkg">lm.beta</span>) or other software packages (like SPSS). To
mimic such behaviours, either use <code>standardize_parameters(model, method = "basic")</code> to obtain post-hoc standardized parameters, or standardize the data
with <code>datawizard::standardize(data, force = TRUE)</code> <em>before</em> fitting the
model.
</p>



<h3>Value</h3>

<p>A data frame with the standardized parameters (<code style="white-space: pre;">&#8288;Std_*&#8288;</code>, depending on
the model type) and their CIs (<code>CI_low</code> and <code>CI_high</code>). Where applicable,
standard errors (SEs) are returned as an attribute (<code>attr(x, "standard_error")</code>).
</p>


<h3>References</h3>


<ul>
<li><p> Hoffman, L. (2015). Longitudinal analysis: Modeling within-person fluctuation
and change. Routledge.
</p>
</li>
<li><p> Jones, J. A., &amp; Waller, N. G. (2015). The normal-theory and asymptotic
distribution-free (ADF) covariance matrix of standardized regression
coefficients: theoretical extensions and finite sample behavior.
Psychometrika, 80(2), 365-378.
</p>
</li>
<li><p> Neter, J., Wasserman, W., &amp; Kutner, M. H. (1989). Applied linear
regression models.
</p>
</li>
<li><p> Gelman, A. (2008). Scaling regression inputs by dividing by two standard
deviations. Statistics in medicine, 27(15), 2865-2873.
</p>
</li>
<li><p> Mood C. Logistic Regression: Why We Cannot Do What We Think We Can Do, and
What We Can Do About It. European Sociological Review (2010) 26:67–82.
</p>
</li></ul>



<h3>See Also</h3>

<p>See also <a href="https://easystats.github.io/parameters/articles/standardize_parameters_effsize.html">package vignette</a>.
</p>
<p>Other standardize: 
<code><a href="#topic+standardize_info">standardize_info</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>model &lt;- lm(len ~ supp * dose, data = ToothGrowth)
standardize_parameters(model, method = "refit")

standardize_parameters(model, method = "posthoc")
standardize_parameters(model, method = "smart")
standardize_parameters(model, method = "basic")

# Robust and 2 SD
standardize_parameters(model, robust = TRUE)
standardize_parameters(model, two_sd = TRUE)

model &lt;- glm(am ~ cyl * mpg, data = mtcars, family = "binomial")
standardize_parameters(model, method = "refit")
standardize_parameters(model, method = "posthoc")
standardize_parameters(model, method = "basic", exponentiate = TRUE)




m &lt;- lme4::lmer(mpg ~ cyl + am + vs + (1 | cyl), mtcars)
standardize_parameters(m, method = "pseudo", ci_method = "satterthwaite")




model &lt;- rstanarm::stan_glm(rating ~ critical + privileges, data = attitude, refresh = 0)
standardize_posteriors(model, method = "refit", verbose = FALSE)
standardize_posteriors(model, method = "posthoc", verbose = FALSE)
standardize_posteriors(model, method = "smart", verbose = FALSE)
head(standardize_posteriors(model, method = "basic", verbose = FALSE))


</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
