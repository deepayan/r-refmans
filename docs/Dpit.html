<!DOCTYPE html><html lang="en"><head><title>Help for package Dpit</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {Dpit}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#Dpit-package'><p>Distribution Pitting</p></a></li>
<li><a href='#descriptives'>
<p>descriptives</p></a></li>
<li><a href='#Dpit'><p>Distribution Pitting</p></a></li>
<li><a href='#FourSamples'>
<p>A part of the data set used in Joo, Aguinis, &amp; Bradley (2017).</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Date:</td>
<td>2017-02-10</td>
</tr>
<tr>
<td>Version:</td>
<td>1.0</td>
</tr>
<tr>
<td>Title:</td>
<td>Distribution Pitting</td>
</tr>
<tr>
<td>Author:</td>
<td>Harry Joo [aut, cre], Herman Aguinis [aut, dtc], Kyle J. Bradley [aut], Takuya Noguchi [ctb]	</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Harry Joo &lt;harryjoo19@gmail.com&gt;</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.1.1)</td>
</tr>
<tr>
<td>Description:</td>
<td>Compares distributions with one another in terms of their fit to each sample in a dataset that contains multiple samples, as described in Joo, Aguinis, and Bradley (in press). Users can examine the fit of seven distributions per sample: pure power law, lognormal, exponential, power law with an exponential cutoff, normal, Poisson, and Weibull. Automation features allow the user to compare all distributions for all samples with a single command line, which creates a separate row containing results for each sample until the entire dataset has been analyzed.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>Imports:</td>
<td>VGAM, gsl, moments, utils, fitdistrplus</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2017-03-03 17:07:00 UTC; HarryJoo</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2017-03-03 21:25:42</td>
</tr>
</table>
<hr>
<h2 id='Dpit-package'>Distribution Pitting</h2><span id='topic+Dpit-package'></span>

<h3>Description</h3>

<p>Compares distributions with one another in terms of their fit to each sample in a dataset that contains multiple samples, as described in Joo, Aguinis, and Bradley (2017). Users can examine the fit of seven distributions per sample: pure power law, lognormal, exponential, power law with an exponential cutoff, normal, Poisson, and Weibull.
</p>


<h3>Details</h3>

<p>Based on the R code found at:
<a href="http://tuvalu.santafe.edu/~aaronc/powerlaws/">http://tuvalu.santafe.edu/~aaronc/powerlaws/</a>.  
In particular, we borrowed heavily from Cosma R. Shalizi's code. Finally, we owe much gratitude to Cosma R. Shalizi, Aaron Clauset, and Yogesh Virkar for their kind responses to our questions regarding the code we borrowed from.
</p>


<h3>Author(s)</h3>

<p>Harry Joo,
Herman Aguinis,
Kyle J. Bradley
</p>
<p>Maintainer: Harry Joo &lt;harryjoo19@gmail.com&gt;
</p>


<h3>References</h3>

<p>Joo, H., Aguinis, H., &amp; Bradley, K. J. 2017. Not all nonnormal distributions are created equal: Improved theoretical and measurement precision. Journal of Applied Psychology. Advance online publication. doi: 10.1037/apl0000214
</p>

<hr>
<h2 id='descriptives'>
descriptives
</h2><span id='topic+descriptives'></span>

<h3>Description</h3>

<p>Returns a data frame containing descriptive statistics per sample.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>descriptives(x)	
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="descriptives_+3A_x">x</code></td>
<td>
<p>A data set</p>
</td></tr>
</table>


<h3>Value</h3>


<dl>
<dt><code>Negative.values?</code></dt><dd><p>Whether or not there are any negative values in a sample. If there is at least one negative value, then the program will print out &quot;Negative values detected&quot; in the relevant cell. If there are no negative values, then the program will leave the cell blank.</p>
</dd>
<dt><code>zeros?</code></dt><dd><p>Whether or not there are any zero values in a sample. If there is at least one zero value, then the program will print out &quot;zero values detected&quot; in the relevant cell. If there are no negative values, then the program will leave the cell blank.</p>
</dd>
<dt><code>N</code></dt><dd><p>Number of observations in a sample&ndash;before the package removes any non-positive values that lead to incalculable expressions (e.g., the log of zero is undefined).</p>
</dd>
<dt><code>median</code></dt><dd><p>Median value of a sample&ndash;before removing any non-positive values.</p>
</dd>
<dt><code>mean</code></dt><dd><p>Mean value of a sample&ndash;before removing any non-positive values.</p>
</dd>
<dt><code>SD</code></dt><dd><p>Standard deviation in a sample&ndash;before removing any non-positive values.</p>
</dd>
<dt><code>skewness</code></dt><dd><p>Skew, or the amount of non-symmetry, in a sample&ndash;before removing any non-positive values.</p>
</dd>
<dt><code>kurtosis</code></dt><dd><p>Kurtosis in a sample&ndash;before removing any non-positive values.</p>
</dd>
<dt><code>minimum</code></dt><dd><p>Minimum value of a sample&ndash;before removing any non-positive values.</p>
</dd>
<dt><code>maximum</code></dt><dd><p>Maximum value of a sample&ndash;before removing any non-positive values.</p>
</dd>
<dt><code>No.of.SDs</code></dt><dd><p>Number of standard deviations contained by a sample. That is: (maximum value - minimum value) / standard deviation.</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
#The following example uses FourSamples.rda, which is a data set included in the package.

data(file = "FourSamples.rda")
out&lt;-descriptives(FourSamples)

## End(Not run)  
</code></pre>

<hr>
<h2 id='Dpit'>Distribution Pitting</h2><span id='topic+Dpit'></span>

<h3>Description</h3>

<p>Compares distributions with one another in terms of their fit to each sample in a dataset that contains multiple samples, as described in Joo, Aguinis, and Bradley (2017). Users can examine the fit of seven distributions per sample: pure power law, lognormal, exponential, power law with an exponential cutoff, normal, Poisson, and Weibull. Automation features allow the user to compare all distributions for all samples with a single command line, which creates a separate row containing results for each sample until the entire dataset has been analyzed. Automation features also skip over any unsuccessful calculations and continues analyzing the remainder of the samples. When calculations fail (e.g., sample size was too small), &quot;NA&quot; entries will be printed in the relevant cells of the results matrix before continuing with subsequent calculations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Dpit(x)	
	  </code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Dpit_+3A_x">x</code></td>
<td>
<p>A data set</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For a given sample, the Dpit() function does not truncate (i.e., discard) data points that fall below a certain threshold, or xmin. More precisely, Dpit() sets xmin at the lowest positive number in the sample. This is because, theoretically, the function focuses on assessing the fit of distributions in their entirety rather than their tail ends. In other words, the goal of Dpit() is to conclude whether a sample itself follows a certain type of distribution, not whether the tail end of the sample follows a certain type of distribution.
</p>


<h3>Value</h3>

<p>This function returns a data frame containing the complete detailed results of distribution pitting. In the data frame, each row corresponds to a sample, or data vector. That is, the first row in the data frame is sample #1, the second row is sample #2, etc. Each column in the data frame shows a distribution pitting statistic per sample. The data frame contains a large number of columns&ndash;as described in detail below:
</p>

<dl>
<dt><code>PLvCut.rawLR</code></dt><dd>
<p>A loglikelihood ratio (LR) quantifying the degree to which a pure power law (PL) fits the focal sample better than a power law with an exponential cutoff (Cut). So, a positive value means that the power law with an exponential cutoff fits worse, whereas a negative value means that the pure power law fits worse. This loglikelihood ratio is not normalized&ndash;hence, the word &quot;raw&quot; in the label.</p>
</dd>
<dt><code>PLvCut.p</code></dt><dd>
<p>The p value associated with the previously mentioned loglikelihood ratio, or PLvCut.rawLR. The p value indicates the extent to which random fluctuations alone likely explain the presence of a non-zero loglikelihood ratio, such that loglikelihood ratio = 0 constitutes the null hypothesis. The lower the p value, the less likely that the loglikelihood ratio is simply due to chance.</p>
</dd>
<dt><code>PLvWeib.rawLR</code></dt><dd>
<p>A loglikelihood ratio (LR) quantifying the degree to which a pure power law (PL) fits the focal sample better than a Weibull distribution (Weib). So, a positive value means that the Weibull distribution fits worse, whereas a negative value means that the pure power law fits worse.</p>
</dd>
<dt><code>PLvWeib.normLR</code></dt><dd>
<p>Normalized value of the previously mentioned loglikelihood ratio, or PLvWeib.rawLR.</p>
</dd>
<dt><code>PLvWeib.p</code></dt><dd>
<p>The p value associated with the previously mentioned loglikelihood ratio, or PLvWeib.normLR.</p>
</dd>
<dt><code>PLvLgN.rawLR</code></dt><dd>
<p>A loglikelihood ratio (LR) quantifying the degree to which a pure power law (PL) fits the focal sample better than a lognormal distribution (LgN). So, a positive value means that the lognormal distribution fits worse, whereas a negative value means that the pure power law fits worse.</p>
</dd>
<dt><code>PLvLgN.normLR</code></dt><dd>
<p>Normalized value of the previously mentioned loglikelihood ratio, or PLvLgN.rawLR.</p>
</dd>
<dt><code>PLvLgN.p</code></dt><dd>
<p>The p value associated with the previously mentioned loglikelihood ratio, or PLvLgN.normLR.</p>
</dd>
<dt><code>PLvExp.rawLR</code></dt><dd>
<p>A loglikelihood ratio (LR) quantifying the degree to which a pure power law (PL) fits the focal sample better than an exponential distribution (Exp). So, a positive value means that the exponential distribution fits worse, whereas a negative value means that the pure power law fits worse.</p>
</dd>
<dt><code>PLvExp.normLR</code></dt><dd>
<p>Normalized value of the previously mentioned loglikelihood ratio, or PLvExp.rawLR.</p>
</dd>
<dt><code>PLvExp.p</code></dt><dd>
<p>The p value associated with the previously mentioned loglikelihood ratio, or PLvExp.normLR.</p>
</dd>
<dt><code>PLvPoi.rawLR</code></dt><dd>
<p>A loglikelihood ratio (LR) quantifying the degree to which a pure power law (PL) fits the focal sample better than a Poisson distribution (Poi). So, a positive value means that the Poisson distribution fits worse, whereas a negative value means that the pure power law fits worse.</p>
</dd>
<dt><code>PLvPoi.normLR</code></dt><dd>
<p>Normalized value of the previously mentioned loglikelihood ratio, or PLvPoi.rawLR.</p>
</dd>
<dt><code>PLvPoi.p</code></dt><dd>
<p>The p value associated with the previously mentioned loglikelihood ratio, or PLvPoi.normLR.</p>
</dd>
<dt><code>CutvWeib.rawLR</code></dt><dd>
<p>A loglikelihood ratio (LR) quantifying the degree to which a power law with an exponential cutoff (Cut) fits the focal sample better than a Weibull distribution (Weib). So, a positive value means that the Weibull distribution fits worse, whereas a negative value means that the power law with an exponential cutoff fits worse.</p>
</dd>
<dt><code>CutvWeib.normLR</code></dt><dd>
<p>Normalized value of the previously mentioned loglikelihood ratio, or CutvWeib.rawLR.</p>
</dd>
<dt><code>CutvWeib.p</code></dt><dd>
<p>The p value associated with the previously mentioned loglikelihood ratio, or CutvWeib.normLR.</p>
</dd>
<dt><code>CutvLgN.rawLR</code></dt><dd>
<p>A loglikelihood ratio (LR) quantifying the degree to which a power law with an exponential cutoff (Cut) fits the focal sample better than a lognormal distribution (LgN). So, a positive value means that the lognormal distribution fits worse, whereas a negative value means that the power law with an exponential cutoff fits worse.</p>
</dd>
<dt><code>CutvLgN.normLR</code></dt><dd>
<p>Normalized value of the previously mentioned loglikelihood ratio, or CutvLgN.rawLR.</p>
</dd>
<dt><code>CutvLgN.p</code></dt><dd>
<p>The p value associated with the previously mentioned loglikelihood ratio, or CutvLgN.normLR.</p>
</dd>
<dt><code>CutvExp.rawLR</code></dt><dd>
<p>A loglikelihood ratio (LR) quantifying the degree to which a power law with an exponential cutoff (Cut) fits the focal sample better than an exponential distribution (Exp). So, a positive value means that the exponential distribution fits worse, whereas a negative value means that the power law with an exponential cutoff fits worse.</p>
</dd>
<dt><code>CutvExp.normLR</code></dt><dd>
<p>Normalized value of the previously mentioned loglikelihood ratio, or CutvExp.rawLR.</p>
</dd>
<dt><code>CutvExp.p</code></dt><dd>
<p>The p value associated with the previously mentioned loglikelihood ratio, or CutvExp.normLR.</p>
</dd>
<dt><code>CutvPoi.rawLR</code></dt><dd>
<p>A loglikelihood ratio (LR) quantifying the degree to which a power law with an exponential cutoff (Cut) fits the focal sample better than a Poisson distribution (Poi). So, a positive value means that the Poisson distribution fits worse, whereas a negative value means that the power law with an exponential cutoff fits worse.</p>
</dd>
<dt><code>CutvPoi.normLR</code></dt><dd>
<p>Normalized value of the previously mentioned loglikelihood ratio, or CutvPoi.rawLR.</p>
</dd>
<dt><code>CutvPoi.p</code></dt><dd>
<p>The p value associated with the previously mentioned loglikelihood ratio, or CutvPoi.normLR.</p>
</dd>
<dt><code>WeibvLgN.rawLR</code></dt><dd>
<p>A loglikelihood ratio (LR) quantifying the degree to which a Weibull distribution (Weib) fits the focal sample better than a lognormal distribution (LgN). So, a positive value means that the lognormal distribution fits worse, whereas a negative value means that the Weibull distribution fits worse.</p>
</dd>
<dt><code>WeibvLgN.normLR</code></dt><dd>
<p>Normalized value of the previously mentioned loglikelihood ratio, or WeibvLgN.rawLR.</p>
</dd>
<dt><code>WeibvLgN.p</code></dt><dd>
<p>The p value associated with the previously mentioned loglikelihood ratio, or WeibvLgN.normLR.</p>
</dd>
<dt><code>WeibvExp.rawLR</code></dt><dd>
<p>A loglikelihood ratio (LR) quantifying the degree to which a Weibull distribution (Weib) fits the focal sample better than an exponential distribution (Exp). So, a positive value means that the exponential distribution fits worse, whereas a negative value means that the Weibull distribution fits worse.</p>
</dd>
<dt><code>WeibvExp.normLR</code></dt><dd>
<p>Normalized value of the previously mentioned loglikelihood ratio, or WeibvExp.rawLR.</p>
</dd>
<dt><code>WeibvExp.p</code></dt><dd>
<p>The p value associated with the previously mentioned loglikelihood ratio, or WeibvExp.normLR.</p>
</dd>
<dt><code>WeibvPoi.rawLR</code></dt><dd>
<p>A loglikelihood ratio (LR) quantifying the degree to which a Weibull distribution (Weib) fits the focal sample better than a Poisson distribution (Poi). So, a positive value means that the Poisson distribution fits worse, whereas a negative value means that the Weibull distribution fits worse.</p>
</dd>
<dt><code>WeibvPoi.normLR</code></dt><dd>
<p>Normalized value of the previously mentioned loglikelihood ratio, or WeibvPoi.rawLR.</p>
</dd>
<dt><code>WeibvPoi.p</code></dt><dd>
<p>The p value associated with the previously mentioned loglikelihood ratio, or WeibvPoi.normLR.</p>
</dd>
<dt><code>LgNvExp.rawLR</code></dt><dd>
<p>A loglikelihood ratio (LR) quantifying the degree to which a lognormal distribution (LgN) fits the focal sample better than an exponential distribution (Exp). So, a positive value means that the exponential distribution fits worse, whereas a negative value means that the lognormal distribution fits worse.</p>
</dd>
<dt><code>LgNvExp.normLR</code></dt><dd>
<p>Normalized value of the previously mentioned loglikelihood ratio, or LgNvExp.rawLR.</p>
</dd>
<dt><code>LgNvExp.p</code></dt><dd>
<p>The p value associated with the previously mentioned loglikelihood ratio, or LgNvExp.normLR.</p>
</dd>
<dt><code>LgNvPoi.rawLR</code></dt><dd>
<p>A loglikelihood ratio (LR) quantifying the degree to which a lognormal distribution (LgN) fits the focal sample better than a Poisson distribution (Poi). So, a positive value means that the Poisson distribution fits worse, whereas a negative value means that the lognormal distribution fits worse.</p>
</dd>
<dt><code>LgNvPoi.normLR</code></dt><dd>
<p>Normalized value of the previously mentioned loglikelihood ratio, or LgNvPoi.rawLR.</p>
</dd>
<dt><code>LgNvPoi.p</code></dt><dd>
<p>The p value associated with the previously mentioned loglikelihood ratio, or LgNvPoi.normLR.</p>
</dd>
<dt><code>ExpvPoi.rawLR</code></dt><dd>
<p>A loglikelihood ratio (LR) quantifying the degree to which an exponential distribution (Exp) fits the focal sample better than a Poisson distribution (Poi). So, a positive value means that the Poisson distribution fits worse, whereas a negative value means that the exponential distribution fits worse.</p>
</dd>
<dt><code>ExpvPoi.normLR</code></dt><dd>
<p>Normalized value of the previously mentioned loglikelihood ratio, or ExpvPoi.rawLR.</p>
</dd>
<dt><code>ExpvPoi.p</code></dt><dd>
<p>The p value associated with the previously mentioned loglikelihood ratio, or ExpvPoi.normLR.</p>
</dd>
<dt><code>NvPL.rawLR</code></dt><dd>
<p>A loglikelihood ratio (LR) quantifying the degree to which a normal distribution (N) fits the focal sample better than a pure power law (PL). So, a positive value means that the pure power law fits worse, whereas a negative value means that the normal distribution fits worse.</p>
</dd>
<dt><code>NvPL.normLR</code></dt><dd>
<p>Normalized value of the previously mentioned loglikelihood ratio, or NvPL.rawLR.</p>
</dd>
<dt><code>NvPL.p</code></dt><dd>
<p>The p value associated with the previously mentioned loglikelihood ratio, or NvPL.normLR.</p>
</dd>
<dt><code>NvCut.rawLR</code></dt><dd>
<p>A loglikelihood ratio (LR) quantifying the degree to which a normal distribution (N) fits the focal sample better than a power law with an exponential cutoff (Cut). So, a positive value means that the power law with an exponential cutoff fits worse, whereas a negative value means that the normal distribution fits worse.</p>
</dd>
<dt><code>NvCut.normLR</code></dt><dd>
<p>Normalized value of the previously mentioned loglikelihood ratio, or NvCut.rawLR.</p>
</dd>
<dt><code>NvCut.p</code></dt><dd>
<p>The p value associated with the previously mentioned loglikelihood ratio, or NvCut.normLR.</p>
</dd>
<dt><code>NvWeib.rawLR</code></dt><dd>
<p>A loglikelihood ratio (LR) quantifying the degree to which a normal distribution (N) fits the focal sample better than a Weibull disribution (Weib). So, a positive value means that the Weibull distribution fits worse, whereas a negative value means that the normal distribution fits worse.</p>
</dd>
<dt><code>NvWeib.normLR</code></dt><dd>
<p>Normalized value of the previously mentioned loglikelihood ratio, or NvWeib.rawLR.</p>
</dd>
<dt><code>NvWeib.p</code></dt><dd>
<p>The p value associated with the previously mentioned loglikelihood ratio, or NvWeib.normLR.</p>
</dd>
<dt><code>NvLgN.rawLR</code></dt><dd>
<p>A loglikelihood ratio (LR) quantifying the degree to which a normal distribution (N) fits the focal sample better than a lognormal disribution (LgN). So, a positive value means that the lognormal distribution fits worse, whereas a negative value means that the normal distribution fits worse.</p>
</dd>
<dt><code>NvLgN.normLR</code></dt><dd>
<p>Normalized value of the previously mentioned loglikelihood ratio, or NvLgN.rawLR.</p>
</dd>
<dt><code>NvLgN.p</code></dt><dd>
<p>The p value associated with the previously mentioned loglikelihood ratio, or NvLgN.normLR.</p>
</dd>
<dt><code>NvExp.rawLR</code></dt><dd>
<p>A loglikelihood ratio (LR) quantifying the degree to which a normal distribution (N) fits the focal sample better than an exponential disribution (Exp). So, a positive value means that the exponential distribution fits worse, whereas a negative value means that the normal distribution fits worse.</p>
</dd>
<dt><code>NvExp.normLR</code></dt><dd>
<p>Normalized value of the previously mentioned loglikelihood ratio, or NvExp.rawLR.</p>
</dd>
<dt><code>NvExp.p</code></dt><dd>
<p>The p value associated with the previously mentioned loglikelihood ratio, or NvExp.normLR.</p>
</dd>
<dt><code>NvPoi.rawLR</code></dt><dd>
<p>A loglikelihood ratio (LR) quantifying the degree to which a normal distribution (N) fits the focal sample better than a Poisson disribution (Poi). So, a positive value means that the Poisson distribution fits worse, whereas a negative value means that the normal distribution fits worse.</p>
</dd>
<dt><code>NvPoi.normLR</code></dt><dd>
<p>Normalized value of the previously mentioned loglikelihood ratio, or NvPoi.rawLR.</p>
</dd>
<dt><code>NvPoi.p</code></dt><dd>
<p>The p value associated with the previously mentioned loglikelihood ratio, or NvPoi.normLR.</p>
</dd>
</dl>



<h3>Note</h3>

<p>The Dpit() function is based on the R code found at:
<a href="http://tuvalu.santafe.edu/~aaronc/powerlaws/">http://tuvalu.santafe.edu/~aaronc/powerlaws/</a>.  
In particular, we borrowed heavily from Cosma R. Shalizi's code. But our code differs from the aforementioned code in mainly three ways. First, the Dpit() function sets xmin at the lowest positive number in a sample to assess the fit of distributions in their entirety rather than their tail ends. Second, our code allows for the comparison of non-pure power law distributions with one another. Third, our code includes automation features that allow the user to compare all distributions for all samples with a single command line, which creates a separate row containing results for each sample until the entire dataset has been analyzed. Automation features clean each sample by removing missing cases and non-positive values that lead to incalculable expressions (e.g., the log of zero is undefined). Automation features also skip over any unsuccessful calculations and continues analyzing the remainder of the samples. When calculations fail (e.g., sample size was too small), &quot;NA&quot; entries will be printed in the relevant cells of the results matrix before continuing with subsequent calculations.
</p>


<h3>References</h3>

<p>Clauset, A., Shalizi, C. R., &amp; Newman, M. E. J. 2009. Power-law distributions in empirical data. SIAM Review, 51, 661-703. Available at: http://arxiv.org/abs/0706.1062
</p>
<p>Joo, H., Aguinis, H., &amp; Bradley, K. J. 2017. Not all nonnormal distributions are created equal: Improved theoretical and measurement precision. Journal of Applied Psychology. Advance online publication. doi: 10.1037/apl0000214
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
#The following example uses FourSamples.rda, which is a data set included in the package.

data(file = "FourSamples.rda")
out&lt;-Dpit(FourSamples)

#Full results are shown in Table 4 in Joo, Aguinis, and Bradley (2017)

#Next, to draw conclusions regarding the fit of a certain type of distribution per sample, 
#we suggest that users implement three decision rules, which are described in 
#the Analysis section in Joo, Aguinis, and Bradley (2017).

#Conclusions regarding the fit of distributions to the four samples in the focal data set
#--after applying the three decision rules--can be found in 
#the first two and last two rows in Table 3, in Joo, Aguinis, and Bradley (2017).

## End(Not run)
</code></pre>

<hr>
<h2 id='FourSamples'>
A part of the data set used in Joo, Aguinis, &amp; Bradley (2017).
</h2><span id='topic+FourSamples'></span>

<h3>Description</h3>

<p>A part of the data set used in Joo, Aguinis, &amp; Bradley (2017).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(FourSamples)</code></pre>


<h3>Format</h3>

<p>A data frame consisting of four variables with varying number of observations.
</p>

<dl>
<dt><code>v1</code></dt><dd><p>number of publications in top five journals in the field of Agriculture.</p>
</dd>
<dt><code>v2</code></dt><dd><p>number of publications in top five journals in the field of Agronomy.</p>
</dd>
<dt><code>v228</code></dt><dd><p>number electrical fixtures assembled by assemblers.</p>
</dd>
<dt><code>v229</code></dt><dd><p>wirer's ratio of production time per unit assembled to standard.</p>
</dd>
</dl>



<h3>Details</h3>

<p>Running the Dpit() function on the FourSamples dataset will produce the results reported in Table 4 in Joo, Aguinis, &amp; Bradley (2017). Though the precise results the user obtains may very slightly differ from those in Joo et al.'s Table 4 due to statistical fluctuations, substantive conclusions remain the same regardless of such fluctuations.  
</p>


<h3>Author(s)</h3>

<p>Harry Joo,
Herman Aguinis,
Kyle J. Bradley
</p>
<p>Maintainer: Harry Joo &lt;harryjoo19@gmail.com&gt;
</p>


<h3>Source</h3>

<p>Joo, H., Aguinis, H., &amp; Bradley, K. J. 2017. Not all nonnormal distributions are created equal: Improved theoretical and measurement precision. Journal of Applied Psychology. Advance online publication. doi: 10.1037/apl0000214
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
