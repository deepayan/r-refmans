<!DOCTYPE html><html lang="en"><head><title>Help for package paramhetero</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {paramhetero}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#coefficient_forestplot'><p>Create forest plot of model coefficients with confidence intervals</p></a></li>
<li><a href='#compare_coef_vectors'><p>Compare coefficient vectors across models</p></a></li>
<li><a href='#compare_coefs'><p>Compare shared coefficients across models</p></a></li>
<li><a href='#compare_resids'><p>Compare regression residual standard deviation across models</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Title:</td>
<td>Numeric and Visual Comparisons of Heterogeneity in Parametric
Models</td>
</tr>
<tr>
<td>Version:</td>
<td>1.0.0</td>
</tr>
<tr>
<td>Description:</td>
<td>Performs statistical tests to compare coefficients and residual 
    variance across models. Also provides graphical methods for 
    assessing heterogeneity in coefficients and residuals. Currently supports 
    linear and generalized linear models.</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 4.0.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>ggplot2, MASS, stats</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.1</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2022-04-25 18:56:49 UTC; loux</td>
</tr>
<tr>
<td>Author:</td>
<td>Travis Loux [aut, cre],
  Cara Wiskow [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Travis Loux &lt;travis.loux@slu.edu&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2022-04-25 19:10:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='coefficient_forestplot'>Create forest plot of model coefficients with confidence intervals</h2><span id='topic+coefficient_forestplot'></span>

<h3>Description</h3>

<p>Create a ggplot forest plot of model coefficients with confidence intervals.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>coefficient_forestplot(
  model_list,
  model_names = NULL,
  conflevel = 0.95,
  horiz = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="coefficient_forestplot_+3A_model_list">model_list</code></td>
<td>
<p>A list of regression models.</p>
</td></tr>
<tr><td><code id="coefficient_forestplot_+3A_model_names">model_names</code></td>
<td>
<p>A list of names for the regression models.</p>
</td></tr>
<tr><td><code id="coefficient_forestplot_+3A_conflevel">conflevel</code></td>
<td>
<p>Confidence level for intervals.</p>
</td></tr>
<tr><td><code id="coefficient_forestplot_+3A_horiz">horiz</code></td>
<td>
<p>Toggle whether confidence intervals are displayed horizontally or
vertically. Default is set to <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The forest plot groups variables along the axis determined by the <code>horiz</code>
parameter and colors the data by model. If <code>model_names = NULL</code>, the
default, models are numbered sequentially in the order they appear in
<code>model_list</code> (Model 1, Model 2, Model 3, etc.).
</p>


<h3>Value</h3>

<p>A ggplot object to compare model coefficient estimates with their
corresponding confidence interval(s), grouped by coefficient.
</p>


<h3>Examples</h3>

<pre><code class='language-R'> states = as.data.frame(state.x77)

 m1 = lm(`Life Exp` ~ Income + Illiteracy, data=states,
         subset=state.region=='Northeast')
 m2 = lm(`Life Exp` ~ Income + Illiteracy, data=states,
         subset=state.region=='South')
 m3 = lm(`Life Exp` ~ Income + Illiteracy, data=states,
         subset=state.region=='North Central')
 m4 = lm(`Life Exp` ~ Income + Illiteracy, data=states,
         subset=state.region=='West')

 mList = list(m1, m2, m3, m4)

 coefficient_forestplot(model_list = mList,
                        model_names =c('Northeast', 'South',
                                       'North Central', 'West'),
                        horiz = FALSE)

</code></pre>

<hr>
<h2 id='compare_coef_vectors'>Compare coefficient vectors across models</h2><span id='topic+compare_coef_vectors'></span>

<h3>Description</h3>

<p>Compare coefficient vectors, after removing intercept, across multiple models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>compare_coef_vectors(model_list)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="compare_coef_vectors_+3A_model_list">model_list</code></td>
<td>
<p>A list of regression models.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function currently supports comparing coefficient vectors from two
models. The intercepts of the models are removed, if they exist, and the
coefficient vectors are compared by Hotelling's <code class="reqn">T^2</code> test. This can be
considered as an initial omnibus test for differences among the coefficients
before searching through all coefficients for individual differences using,
for example, <code>compare_coefs</code>.
</p>


<h3>Value</h3>

<p>List of test results. This includes the chi-squared statistic, degrees
of freedom, and p-value.
</p>


<h3>Examples</h3>

<pre><code class='language-R'> ##Simulate data

 N = 500

 m = rep(1:2, each=N)

 x1 = rnorm(n=N*2)
 x2 = rnorm(n=N*2)
 x3 = rnorm(n=N*2)

 y = x1 + x2 + x3 + rnorm(n=N*2)

 dat = data.frame(m, x1, x2, x3, y)

 m1 = lm(y ~ x1 + x2 + x3, data=dat, subset=m==1)
 m2 = lm(y ~ x1 + x2 + x3, data=dat, subset=m==2)

 mList = list(m1, m2)

 compare_coef_vectors(model_list = mList)

</code></pre>

<hr>
<h2 id='compare_coefs'>Compare shared coefficients across models</h2><span id='topic+compare_coefs'></span>

<h3>Description</h3>

<p>Compares predictor coefficients across models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>compare_coefs(model_list, padj = "none")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="compare_coefs_+3A_model_list">model_list</code></td>
<td>
<p>A list of regression models.</p>
</td></tr>
<tr><td><code id="compare_coefs_+3A_padj">padj</code></td>
<td>
<p>A method from <code>p.adjust.methods</code> for adjusting coefficient
p-values for multiple testing.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function currently supports comparing coefficients from two models. For
each model predictor, coefficients are compared across models. P-values come
from a two-sided alternative hypothesis. They can, and should, be adjusted for
multiple testing to reduce the probability of chance significant findings.
</p>


<h3>Value</h3>

<p>Data frame of shared coefficients, the difference between them, the
standard error of the difference, the test statistic comparing them, and the
p-value adjusted using the method provided in <code>padj</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'> ##Simulate data

 N = 500

 m = rep(1:2, each=N)

 x1 = rnorm(n=N*2)
 x2 = rnorm(n=N*2)
 x3 = rnorm(n=N*2)

 y = x1 + x2 + x3 + rnorm(n=N*2)

 dat = data.frame(m, x1, x2, x3, y)

 m1 = lm(y ~ x1 + x2 + x3, data=dat, subset=m==1)
 m2 = lm(y ~ x1 + x2 + x3, data=dat, subset=m==2)

 mList = list(m1, m2)

 compare_coefs(model_list = mList, padj='fdr')

</code></pre>

<hr>
<h2 id='compare_resids'>Compare regression residual standard deviation across models</h2><span id='topic+compare_resids'></span>

<h3>Description</h3>

<p>Compare residual standard deviation across models. Works for linear regression
(<code><a href="stats.html#topic+lm">lm</a></code>) only.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>compare_resids(model_list)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="compare_resids_+3A_model_list">model_list</code></td>
<td>
<p>A list of regression models.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function currently supports comparing residual standard deviation from
two models. Residuals are assumed to be normally distributed (as also assumed
in the linear model itself) and are compared by an F test.
</p>


<h3>Value</h3>

<p>Vector of results. This includes the residual standard deviation from
each model, the F statistic comparing the standard deviations, the numerator
and denominator degrees of freedom, and the p-value.
</p>


<h3>Examples</h3>

<pre><code class='language-R'> ##Simulate data

 N = 500

 m = rep(1:2, each=N)

 x1 = rnorm(n=N*2)
 x2 = rnorm(n=N*2)
 x3 = rnorm(n=N*2)

 y = x1 + x2 + x3 + rnorm(n=N*2)

 dat = data.frame(m, x1, x2, x3, y)

 m1 = lm(y ~ x1 + x2 + x3, data=dat, subset=m==1)
 m2 = lm(y ~ x1 + x2 + x3, data=dat, subset=m==2)

 mList = list(m1, m2)

 compare_resids(model_list = mList)

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
