<!DOCTYPE html><html><head><title>Help for package generalCorr</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {generalCorr}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#abs_res'><p>Absolute residuals of kernel regression of x on y.</p></a></li>
<li><a href='#abs_stdapd'><p>Absolute values of gradients (apd's) of kernel regressions of x on y when</p>
both x and y are standardized.</a></li>
<li><a href='#abs_stdapdC'><p>Absolute values of gradients (apd's) of kernel regressions of x on y when</p>
both x and y are standardized and control variables are present.</a></li>
<li><a href='#abs_stdres'><p>Absolute values of residuals of kernel regressions of x on y when both x and</p>
y are standardized.</a></li>
<li><a href='#abs_stdresC'><p>Absolute values of residuals of kernel regressions of x on y when both x and</p>
y are standardized and control variables are present (C for control presence).</a></li>
<li><a href='#abs_stdrhserC'><p>Absolute residuals kernel regressions of standardized x on y and control</p>
variables, Cr1 has abs(RHS*y) not gradients.</a></li>
<li><a href='#abs_stdrhserr'><p>Absolute values of Hausman-Wu null in kernel regressions of x on y when</p>
both x and y are standardized.</a></li>
<li><a href='#absBstdres'><p>Block version of abs-stdres Absolute values of residuals of kernel regressions</p>
of  standardized x on  standardized y, no control variables.</a></li>
<li><a href='#absBstdresC'><p>Block version of Absolute values of residuals of kernel regressions of standardized x on</p>
standardized y and control variables.</a></li>
<li><a href='#absBstdrhserC'><p>Block version abs_stdrhser Absolute residuals kernel regressions of standardized x on y and control</p>
variables, Cr1 has abs(Resid*RHS).</a></li>
<li><a href='#allPairs'><p>Report causal identification for all pairs of variables in a matrix</p>
(deprecated function). It is better to choose a target variable and pair
it with all others, instead of considering all possible targets.</a></li>
<li><a href='#badCol'>
<p>internal badCol</p></a></li>
<li><a href='#bigfp'><p>Compute the numerical integration by the trapezoidal rule.</p></a></li>
<li><a href='#bootDom12'><p>bootstrap confidence intervals for (x2-x1) exact SD1 to SD4 stochastic dominance</p>
.</a></li>
<li><a href='#bootGcLC'><p>Compute vector of n999 nonlinear Granger causality paths</p></a></li>
<li><a href='#bootGcRsq'><p>Compute vector of n999 nonlinear Granger causality paths</p></a></li>
<li><a href='#bootPair2'><p>Compute matrix of n999 rows and p-1 columns of bootstrap &lsquo;sum&rsquo;</p>
(scores from Cr1 to Cr3).</a></li>
<li><a href='#bootPairs'><p>Compute matrix of n999 rows and p-1 columns of bootstrap &lsquo;sum&rsquo;</p>
(strength from Cr1 to Cr3).</a></li>
<li><a href='#bootPairs0'><p>Compute matrix of n999 rows and p-1 columns of bootstrap &lsquo;sum&rsquo; index</p>
(strength from older criterion Cr1, with newer Cr2 and Cr3).</a></li>
<li><a href='#bootQuantile'><p>Compute confidence intervals [quantile(s)] of indexes from bootPairs output</p></a></li>
<li><a href='#bootSign'><p>Probability of unambiguously correct (+ or -) sign from bootPairs output</p></a></li>
<li><a href='#bootSignPcent'><p>Probability of unambiguously correct (+ or -) sign from bootPairs output transformed</p>
to percentages.</a></li>
<li><a href='#bootSummary'><p>Compute usual summary stats of 'sum' indexes from bootPairs output</p></a></li>
<li><a href='#bootSummary2'><p>Compute usual summary stats of 'sum' index in (-100, 100) from bootPair2</p></a></li>
<li><a href='#canonRho'><p>Generalized canonical correlation, estimating alpha, beta, rho.</p></a></li>
<li><a href='#causeAllPair'><p>All Pair Version Kernel (block) causality summary paths from three criteria</p></a></li>
<li><a href='#causeSum2Blk'><p>Block Version 2: Kernel causality summary of causal paths from three criteria</p></a></li>
<li><a href='#causeSum2Panel'><p>Kernel regressions based causal paths in Panel Data.</p></a></li>
<li><a href='#causeSummary'><p>Kernel causality summary of evidence for causal paths from three criteria</p></a></li>
<li><a href='#causeSummary0'><p>Older Kernel causality summary of evidence for causal paths from three criteria</p></a></li>
<li><a href='#causeSummary2'><p>Kernel causality summary of evidence for causal paths</p>
from three criteria using new exact stochastic dominance.
</p>
<p>The function develops a unanimity index for deciding which</p>
flip (y on xi) or (xi on y) is best. Relevant signs determine the
causal direction and unanimity index among three criteria.
While allowing the researcher to keep some variables as controls,
or outside the scope of causal path determination
(e.g., age or latitude)  this function produces detailed causal path information
in a 5 column matrix identifying the names of variables,
causal path directions, path strengths re-scaled to be in the
range [&ndash;100, 100], (table reports absolute values of the strength)
plus Pearson correlation and its p-value.
The &lsquo;2&rsquo; in the name of the function suggests a second implementation
where exact stochastic dominance, decileVote, and momentVote are used
and where we avoid Anderson's trapezoidal approximation.</a></li>
<li><a href='#causeSummary2NoP'><p>No Print version Kernel causality summary of evidence for causal paths</p>
from three criteria using new exact stochastic dominance.</a></li>
<li><a href='#causeSummBlk'><p>Block Version 2: Kernel causality summary of causal paths from three criteria</p></a></li>
<li><a href='#causeSumNoP'><p>No print (NoP) version of causeSummBlk summary causal paths from three criteria</p></a></li>
<li><a href='#cofactor'><p>Compute cofactor of a matrix based on row r and column c.</p></a></li>
<li><a href='#comp_portfo2'><p>Compares two vectors (portfolios) using stochastic dominance of orders 1 to 4.</p></a></li>
<li><a href='#compPortfo'><p>Compares two vectors (portfolios) using</p>
momentVote, DecileVote and exactSdMtx functions.</a></li>
<li><a href='#da'>
<p>internal da</p></a></li>
<li><a href='#da2Lag'>
<p>internal da2Lag</p></a></li>
<li><a href='#decileVote'><p>Function compares nine deciles of stock return distributions.</p></a></li>
<li><a href='#depMeas'><p>depMeas Signed measure of nonlinear nonparametric dependence between two vectors.</p></a></li>
<li><a href='#dif4'><p>order 4 differencing of a time series vector</p></a></li>
<li><a href='#dif4mtx'><p>order four differencing of a matrix of time series</p></a></li>
<li><a href='#diff.e0'>
<p>Internal diff.e0</p></a></li>
<li><a href='#dig'>
<p>Internal dig</p></a></li>
<li><a href='#e0'>
<p>internal e0</p></a></li>
<li><a href='#EuroCrime'><p>European Crime Data</p></a></li>
<li><a href='#exactSdMtx'><p>Exact stochastic dominance computation from areas above ECDF pillars.</p></a></li>
<li><a href='#GcRsqX12'><p>Generalized Granger-Causality. If dif&gt;0, x2 Granger-causes x1.</p></a></li>
<li><a href='#GcRsqX12c'><p>Generalized Granger-Causality. If dif&gt;0, x2 Granger-causes x1.</p></a></li>
<li><a href='#GcRsqYX'><p>Nonlinear Granger causality between two time series workhorse function.</p></a></li>
<li><a href='#GcRsqYXc'><p>Nonlinear Granger causality between two time series workhorse function.(local</p>
constant version)</a></li>
<li><a href='#generalCorrInfo'><p>generalCorr package description:</p></a></li>
<li><a href='#get0outliers'><p>Function to compute outliers and their count using Tukey's method</p>
using 1.5 times interquartile range (IQR) to define boundaries.</a></li>
<li><a href='#getSeq'><p>Two sequences: starting+ending values from n and blocksize (internal use)</p></a></li>
<li><a href='#gmc0'>
<p>internal gmc0</p></a></li>
<li><a href='#gmc1'>
<p>internal gmc1</p></a></li>
<li><a href='#gmcmtx0'><p>Matrix R* of generalized correlation coefficients captures nonlinearities.</p></a></li>
<li><a href='#gmcmtxBlk'><p>Matrix R* of generalized correlation coefficients captures nonlinearities using blocks.</p></a></li>
<li><a href='#gmcmtxZ'><p>compute the matrix R* of generalized correlation coefficients.</p></a></li>
<li><a href='#gmcxy_np'><p>Function to compute generalized correlation coefficients r*(x|y) and</p>
r*(y|x) from two vectors (not matrices)</a></li>
<li><a href='#goodCol'>
<p>internal goodCol</p></a></li>
<li><a href='#heurist'><p>Heuristic t test of the difference between two generalized correlations.</p></a></li>
<li><a href='#i'>
<p>internal i</p></a></li>
<li><a href='#ibad'>
<p>internal object</p></a></li>
<li><a href='#ii'>
<p>internal ii</p></a></li>
<li><a href='#j'>
<p>internal j</p></a></li>
<li><a href='#kern'><p>Kernel regression with options for residuals and gradients.</p></a></li>
<li><a href='#kern_ctrl'><p>Kernel regression with control variables and optional residuals and gradients.</p></a></li>
<li><a href='#kern2'><p>Kernel regression version 2 with optional residuals and gradients</p>
with regtype=&quot;ll&quot; for local linear, bwmethod=&quot;cv.aic&quot; for AIC-based
bandwidth selection.</a></li>
<li><a href='#kern2ctrl'><p>Kernel regression with control variables and optional residuals and gradients.</p>
version 2 regtype=&quot;ll&quot; for local linear, bwmethod=&quot;cv.aic&quot; for AIC-based
bandwidth selection. It admits control variables.</a></li>
<li><a href='#mag'><p>Approximate overall magnitudes of kernel regression partials dx/dy and dy/dx.</p></a></li>
<li><a href='#mag_ctrl'><p>After removing control variables, magnitude of effect of x on y, and of y on x.</p></a></li>
<li><a href='#min.e0'>
<p>internal min.e0</p></a></li>
<li><a href='#minor'><p>Function to do compute the minor of a matrix defined by row r and column c.</p></a></li>
<li><a href='#momentVote'><p>Function compares Pearson Stats and Sharpe Ratio for a matrix of stock returns</p></a></li>
<li><a href='#mtx'>
<p>internal mtx</p></a></li>
<li><a href='#mtx0'>
<p>internal mtx0</p></a></li>
<li><a href='#mtx2'>
<p>internal mtx2</p></a></li>
<li><a href='#n'>
<p>internal n</p></a></li>
<li><a href='#nall'>
<p>internal nall</p></a></li>
<li><a href='#nam.badCol'>
<p>internal nam.badCol</p></a></li>
<li><a href='#nam.goodCol'>
<p>internal nam.goodCol</p></a></li>
<li><a href='#nam.mtx0'>
<p>internal nam.mtx0</p></a></li>
<li><a href='#napair'><p>Function to do pairwise deletion of missing rows.</p></a></li>
<li><a href='#naTriple'><p>Function to do matched deletion of missing rows from x, y</p>
and z variable(s).</a></li>
<li><a href='#naTriplet'><p>Function to do matched deletion of missing rows from x, y and control variable(s).</p></a></li>
<li><a href='#NLhat'><p>Compute fitted values from kernel regression of x on y and y on x</p></a></li>
<li><a href='#out1'>
<p>internal out1</p></a></li>
<li><a href='#outOFsamp'><p>Compare out-of-sample portfolio choice algorithms by a leave-percent-out method.</p></a></li>
<li><a href='#outOFsell'><p>Compare out-of-sample (short) selling algorithms by a leave-percent-out method.</p></a></li>
<li><a href='#p1'>
<p>internal p1</p></a></li>
<li><a href='#Panel2Lag'><p>Function to compute a vector of 2 lagged values of a variable from panel data.</p></a></li>
<li><a href='#PanelLag'><p>Function for computing a vector of one-lagged values of xj, a variable from panel data.</p></a></li>
<li><a href='#parcor_ijk'><p>Generalized partial correlation coefficients between Xi and Xj, after removing the</p>
effect of xk, via nonparametric regression residuals.</a></li>
<li><a href='#parcor_ijkOLD'><p>Generalized partial correlation coefficient between Xi and Xj after removing the</p>
effect of all others. (older version, deprecated)</a></li>
<li><a href='#parcor_linear'><p>Partial correlation coefficient between Xi and Xj after removing the linear</p>
effect of all others.</a></li>
<li><a href='#parcor_ridg'><p>Compute generalized (ridge-adjusted) partial correlation coefficients</p>
from matrix R*. (deprecated)</a></li>
<li><a href='#parcorBijk'><p>Block version of generalized partial correlation coefficients between Xi</p>
and Xj, after removing the
effect of xk, via nonparametric regression residuals.</a></li>
<li><a href='#parcorBMany'><p>Block version reports many generalized partial correlation coefficients</p>
allowing control variables.</a></li>
<li><a href='#parcorHijk'><p>Generalized partial correlation coefficients between Xi and Xj, after removing the</p>
effect of Xk, via OLS regression residuals.</a></li>
<li><a href='#parcorHijk2'><p>Generalized partial correlation coefficients between</p>
Xi and Xj,</a></li>
<li><a href='#parcorMany'><p>Report many generalized partial correlation coefficients</p>
allowing control variables.</a></li>
<li><a href='#parcorMtx'><p>Matrix of generalized partial correlation coefficients,</p>
always leaving out control variables, if any.</a></li>
<li><a href='#parcorSilent'><p>Silently compute generalized (ridge-adjusted) partial correlation coefficients from matrix R*.</p></a></li>
<li><a href='#parcorVec'><p>Vector of generalized partial correlation coefficients (GPCC),</p>
always leaving out control variables, if any.</a></li>
<li><a href='#parcorVecH'><p>Vector of hybrid generalized partial correlation coefficients.</p></a></li>
<li><a href='#parcorVecH2'><p>Vector of hybrid generalized partial correlation coefficients.</p></a></li>
<li><a href='#pcause'><p>Compute the bootstrap probability of correct causal direction.</p></a></li>
<li><a href='#pillar3D'><p>Create a 3D pillar chart to display (x, y, z) data coordinate surface.</p></a></li>
<li><a href='#prelec2'><p>Intermediate weighting function giving Non-Expected Utility theory weights.</p></a></li>
<li><a href='#probSign'><p>Compute probability of positive or negative sign from bootPairs output</p></a></li>
<li><a href='#rank2return'><p>Compute the portfolio return knowing the rank of a stock in the input &lsquo;mtx&rsquo;.</p></a></li>
<li><a href='#rank2sell'><p>Compute the portfolio return knowing the rank of a stock in the</p>
input &lsquo;mtx&rsquo;.
</p>
<p>This function computes the return earned knowing the rank of a stock</p>
computed elsewhere and named myrank associate with the data columns in
the input mtx of stock returns. For example, mtx has p=28 Dow Jones stocks
over n=169 monthly returns. Portfolio weights are assumed to be linearly
declining. If maxChosen=4, the weights are 1/10, 2/10, 3/10 and 4/10, which add
up to unity. These portfolio weights are assigned in their order
in the sense that first chosen stock (choice rank =p) gets portfolio weight=4/10.
The function computes return from the stocks using the &lsquo;myrank&rsquo; argument.
This helps in assessing out-of-sample performance of (short)
the strategy of selling lowest ranking stocks. It is mostly for internal use
by <code>outOFsell()</code>. This is a sell version of <code>rank2return()</code>.</a></li>
<li><a href='#rhs.lag2'>
<p>internal rhs.lag2</p></a></li>
<li><a href='#rhs1'>
<p>internal rhs1</p></a></li>
<li><a href='#ridgek'>
<p>internal ridgek</p></a></li>
<li><a href='#rij'>
<p>internal rij</p></a></li>
<li><a href='#rijMrji'>
<p>internal rijMrji</p></a></li>
<li><a href='#rji'>
<p>internal rji</p></a></li>
<li><a href='#rrij'>
<p>internal rrij</p></a></li>
<li><a href='#rrji'>
<p>internal rrji</p></a></li>
<li><a href='#rstar'><p>Function to compute generalized correlation coefficients r*(x,y).</p></a></li>
<li><a href='#sales2Lag'>
<p>internal sales2Lag</p></a></li>
<li><a href='#salesLag'>
<p>internal salesLag</p></a></li>
<li><a href='#seed'>
<p>internal seed</p></a></li>
<li><a href='#sgn.e0'>
<p>internal sgn.e0</p></a></li>
<li><a href='#silentMtx'><p>No-print kernel-causality unanimity score matrix with optional control variables</p></a></li>
<li><a href='#silentMtx0'><p>Older kernel-causality unanimity score matrix with optional control variables</p></a></li>
<li><a href='#silentPair2'><p>kernel causality (version 2) scores with control variables</p></a></li>
<li><a href='#silentPairs'><p>No-print kernel causality scores with control variables Hausman-Wu Criterion 1</p></a></li>
<li><a href='#silentPairs0'><p>Older version, kernel causality weighted sum allowing control variables</p></a></li>
<li><a href='#siPair2Blk'><p>Block Version of silentPair2 for causality scores with control variables</p></a></li>
<li><a href='#siPairsBlk'><p>Block Version of silentPairs for causality scores with control variables</p></a></li>
<li><a href='#some0Pairs'><p>Function reporting detailed kernel causality results in a 7-column matrix</p>
(uses deprecated criterion 1, no longer recommended but may be useful for
second and third criterion typ=2,3)</a></li>
<li><a href='#someCPairs'><p>Kernel causality computations admitting control variables.</p></a></li>
<li><a href='#someCPairs2'><p>Kernel causality computations admitting control variables reporting</p>
a 7-column matrix, version 2.</a></li>
<li><a href='#someMagPairs'><p>Summary magnitudes after removing control variables in several pairs where dependent</p>
variable is fixed.</a></li>
<li><a href='#somePairs'><p>Function reporting kernel causality results as a 7-column matrix.(deprecated)</p></a></li>
<li><a href='#somePairs2'><p>Function reporting kernel causality results as a 7-column matrix, version 2.</p></a></li>
<li><a href='#sort_matrix'><p>Sort all columns of matrix x with respect to the j-th column.</p></a></li>
<li><a href='#sort.abse0'>
<p>internal sort.abse0</p></a></li>
<li><a href='#sort.e0'>
<p>internal sort.e0</p></a></li>
<li><a href='#stdres'><p>Residuals of kernel regressions of x on y when both x and</p>
y are standardized.</a></li>
<li><a href='#stdz_xy'><p>Standardize x and y vectors to achieve zero mean and unit variance.</p></a></li>
<li><a href='#stochdom2'><p>Compute vectors measuring stochastic dominance of four orders.</p></a></li>
<li><a href='#sudoCoefParcor'><p>Pseudo regression coefficients from generalized partial correlation coefficients,</p>
(GPCC).</a></li>
<li><a href='#sudoCoefParcorH'><p>Peudo regression coefficients from hybrid generalized partial</p>
correlation coefficients (HGPCC).</a></li>
<li><a href='#summaryRank'><p>Compute ranks of rows of matrix and summarize them into a choice suggestion.</p></a></li>
<li><a href='#symmze'><p>Replace asymmetric matrix by max of abs values of [i,j] or [j,i] elements.</p></a></li>
<li><a href='#wtdpapb'><p>Creates input for the stochastic dominance function stochdom2</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Generalized Correlations, Causal Paths and Portfolio Selection</td>
</tr>
<tr>
<td>Version:</td>
<td>1.2.6</td>
</tr>
<tr>
<td>Date:</td>
<td>2023-10-09</td>
</tr>
<tr>
<td>Author:</td>
<td>Prof. H. D. Vinod, Fordham University, NY.</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>H. D. Vinod &lt;vinod@fordham.edu&gt;</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.0.0), np (&ge; 0.60), xtable (&ge; 1.8), meboot (&ge; 1.4),
psych, lattice</td>
</tr>
<tr>
<td>Suggests:</td>
<td>R.rsp</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>R.rsp</td>
</tr>
<tr>
<td>Description:</td>
<td>Function gmcmtx0() computes a more reliable (general) 
    correlation matrix. Since causal paths from data are important for all sciences, the
    package provides many sophisticated functions. causeSummBlk() and causeSum2Blk()
    give easy-to-interpret causal paths.  Let Z denote control variables and compare 
    two flipped kernel regressions: X=f(Y, Z)+e1 and Y=g(X, Z)+e2. Our criterion Cr1 
    says that if |e1*Y|&gt;|e2*X| then variation in X is more "exogenous or independent"
    than in Y, and the causal path is X to Y. Criterion Cr2 requires |e2|&lt;|e1|. These
    inequalities between many absolute values are quantified by four orders of 
    stochastic dominance. Our third criterion Cr3, for the causal path X to Y,
    requires new generalized partial correlations to satisfy |r*(x|y,z)|&lt; |r*(y|x,z)|.
    The function parcorVec() reports generalized partials between the first
    variable and all others.  The package provides several R functions including
    get0outliers() for outlier detection, bigfp() for numerical integration by the
    trapezoidal rule, stochdom2() for stochastic dominance, pillar3D() for 3D charts,
    canonRho() for generalized canonical correlations, depMeas() measures nonlinear
    dependence, and causeSummary(mtx) reports summary of causal paths among matrix 
    columns. Portfolio selection: decileVote(), momentVote(), dif4mtx(), exactSdMtx()
    can rank several stocks. Functions whose names begin with 'boot' provide bootstrap
    statistical inference, including a new bootGcRsq() test for "Granger-causality" 
    allowing nonlinear relations. A new tool for evaluation of out-of-sample
    portfolio performance is outOFsamp(). Panel data implementation is now included.
    See eight vignettes of the package for theory, examples, and
    usage tips. See Vinod (2019) \doi{10.1080/03610918.2015.1122048}.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-10-09 15:22:42 UTC; vinod</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-10-09 18:40:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='abs_res'>Absolute residuals of kernel regression of x on y.</h2><span id='topic+abs_res'></span>

<h3>Description</h3>

<p>This internal function calls the <code>kern</code> function to implement kernel regression
with the option <code>residuals=TRUE</code> and returns absolute residuals.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>abs_res(x, y)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="abs_res_+3A_x">x</code></td>
<td>
<p>vector of data on the dependent variable</p>
</td></tr>
<tr><td><code id="abs_res_+3A_y">y</code></td>
<td>
<p>vector of data on the regressor</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The first argument is assumed to be the dependent variable.  If
<code>abs_res(x,y)</code> is used, you are regressing x on y (not the usual y on
x)
</p>


<h3>Value</h3>

<p>absolute values of kernel regression residuals are returned.
</p>


<h3>Note</h3>

<p>This function is intended for internal use.
</p>


<h3>Author(s)</h3>

<p>Prof. H. D. Vinod, Economics Dept., Fordham University, NY
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
set.seed(330)
x=sample(20:50)
y=sample(20:50)
abs_res(x,y)

## End(Not run)
</code></pre>

<hr>
<h2 id='abs_stdapd'>Absolute values of gradients (apd's) of kernel regressions of x on y when
both x and y are standardized.</h2><span id='topic+abs_stdapd'></span>

<h3>Description</h3>

<p>1) standardize the data to force mean zero and variance unity, 2) kernel
regress x on y, with the option &lsquo;gradients = TRUE&rsquo; and finally 3) compute
the absolute values of gradients
</p>


<h3>Usage</h3>

<pre><code class='language-R'>abs_stdapd(x, y)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="abs_stdapd_+3A_x">x</code></td>
<td>
<p>vector of data on the dependent variable</p>
</td></tr>
<tr><td><code id="abs_stdapd_+3A_y">y</code></td>
<td>
<p>data on the regressors which can be a matrix</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The first argument is assumed to be the dependent variable.  If
<code>abs_stdapd(x,y)</code> is used, you are regressing x on y (not the usual y
on x). The regressors can be a matrix with 2 or more columns. The missing values
are suitably ignored by the standardization.
</p>


<h3>Value</h3>

<p>Absolute values of kernel regression gradients are returned after
standardizing the data on both sides so that the magnitudes of amorphous
partial derivatives (apd's) are comparable between regression of x on y on
the one hand and regression of y on x on the other.
</p>


<h3>Author(s)</h3>

<p>Prof. H. D. Vinod, Economics Dept., Fordham University, NY
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
set.seed(330)
x=sample(20:50)
y=sample(20:50)
abs_stdapd(x,y)

## End(Not run)
</code></pre>

<hr>
<h2 id='abs_stdapdC'>Absolute values of gradients (apd's) of kernel regressions of x on y when
both x and y are standardized and control variables are present.</h2><span id='topic+abs_stdapdC'></span>

<h3>Description</h3>

<p>1) standardize the data to force mean zero and variance unity, 2) kernel
regress x on y and a matrix of control variables, 
with the option &lsquo;gradients = TRUE&rsquo; and finally 3) compute
the absolute values of gradients
</p>


<h3>Usage</h3>

<pre><code class='language-R'>abs_stdapdC(x, y, ctrl)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="abs_stdapdC_+3A_x">x</code></td>
<td>
<p>vector of data on the dependent variable</p>
</td></tr>
<tr><td><code id="abs_stdapdC_+3A_y">y</code></td>
<td>
<p>data on the regressors which can be a matrix</p>
</td></tr>
<tr><td><code id="abs_stdapdC_+3A_ctrl">ctrl</code></td>
<td>
<p>Data matrix on the control variable(s) beyond causal path issues</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The first argument is assumed to be the dependent variable.  If
<code>abs_stdapdC(x,y)</code> is used, you are regressing x on y (not the usual y
on x). The regressors can be a matrix with 2 or more columns. The missing values
are suitably ignored by the standardization.
</p>


<h3>Value</h3>

<p>Absolute values of kernel regression gradients are returned after
standardizing the data on both sides so that the magnitudes of amorphous
partial derivatives (apd's) are comparable between regression of x on y on
the one hand and regression of y on x on the other.
</p>


<h3>Author(s)</h3>

<p>Prof. H. D. Vinod, Economics Dept., Fordham University, NY
</p>


<h3>See Also</h3>

<p>See  <code><a href="#topic+abs_stdapd">abs_stdapd</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
set.seed(330)
x=sample(20:50)
y=sample(20:50)
z=sample(20:50)
abs_stdapdC(x,y,ctrl=z)

## End(Not run)
</code></pre>

<hr>
<h2 id='abs_stdres'>Absolute values of residuals of kernel regressions of x on y when both x and
y are standardized.</h2><span id='topic+abs_stdres'></span>

<h3>Description</h3>

<p>1) Standardize the data to force mean zero and variance unity, 2) kernel
regress x on y, with the option &lsquo;residuals = TRUE&rsquo; and finally 3) compute
the absolute values of residuals.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>abs_stdres(x, y)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="abs_stdres_+3A_x">x</code></td>
<td>
<p>vector of data on the dependent variable</p>
</td></tr>
<tr><td><code id="abs_stdres_+3A_y">y</code></td>
<td>
<p>data on the regressors which can be a matrix</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The first argument is assumed to be the dependent variable.  If
<code>abs_stdres(x,y)</code> is used, you are regressing x on y (not the usual y
on x). The regressors can be a matrix with 2 or more columns. The missing values
are suitably ignored by the standardization.
</p>


<h3>Value</h3>

<p>Absolute values of kernel regression residuals are returned after
standardizing the data on both sides so that the magnitudes of residuals are
comparable between regression of x on y on the one hand and regression of y
on x on the other.
</p>


<h3>Author(s)</h3>

<p>Prof. H. D. Vinod, Economics Dept., Fordham University, NY
</p>


<h3>References</h3>

<p>Vinod, H. D. 'Generalized Correlation and Kernel Causality with
Applications in Development Economics' in Communications in
Statistics -Simulation and Computation, 2015,
<a href="https://doi.org/10.1080/03610918.2015.1122048">doi:10.1080/03610918.2015.1122048</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
set.seed(330)
x=sample(20:50)
y=sample(20:50)
abs_stdres(x,y)

## End(Not run)

</code></pre>

<hr>
<h2 id='abs_stdresC'>Absolute values of residuals of kernel regressions of x on y when both x and
y are standardized and control variables are present (C for control presence).</h2><span id='topic+abs_stdresC'></span>

<h3>Description</h3>

<p>1) standardize the data to force mean zero and variance unity, 2) kernel
regress x on y and a matrix of control variables, 
with the option &lsquo;residuals = TRUE&rsquo; and finally 3) compute
the absolute values of residuals.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>abs_stdresC(x, y, ctrl)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="abs_stdresC_+3A_x">x</code></td>
<td>
<p>vector of data on the dependent variable</p>
</td></tr>
<tr><td><code id="abs_stdresC_+3A_y">y</code></td>
<td>
<p>data on the regressors which can be a matrix</p>
</td></tr>
<tr><td><code id="abs_stdresC_+3A_ctrl">ctrl</code></td>
<td>
<p>Data matrix on the control variable(s) beyond causal path issues</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The first argument is assumed to be the dependent variable.  If
<code>abs_stdres(x,y)</code> is used, you are regressing x on y (not the usual y
on x). The regressors can be a matrix with two or more columns. The missing values
are suitably ignored by the standardization.
</p>


<h3>Value</h3>

<p>Absolute values of kernel regression residuals are returned after
standardizing the data on both sides so that the magnitudes of residuals are
comparable between regression of x on y on the one hand and regression of y
on x on the other.
</p>


<h3>Author(s)</h3>

<p>Prof. H. D. Vinod, Economics Dept., Fordham University, NY
</p>


<h3>References</h3>

<p>Vinod, H. D.'Generalized Correlation and Kernel Causality with
Applications in Development Economics' in Communications in
Statistics -Simulation and Computation, 2015,
<a href="https://doi.org/10.1080/03610918.2015.1122048">doi:10.1080/03610918.2015.1122048</a>
</p>


<h3>See Also</h3>

<p>See  <code><a href="#topic+abs_stdres">abs_stdres</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
set.seed(330)
x=sample(20:50)
y=sample(20:50)
z=sample(21:51)
abs_stdresC(x,y,ctrl=z)

## End(Not run)

</code></pre>

<hr>
<h2 id='abs_stdrhserC'>Absolute residuals kernel regressions of standardized x on y and control 
variables, Cr1 has abs(RHS*y) not gradients.</h2><span id='topic+abs_stdrhserC'></span>

<h3>Description</h3>

<p>1) standardize the data to force mean zero and variance unity, 2) kernel
regress x on y and a matrix of control variables, 
with the option &lsquo;residuals = TRUE&rsquo; and finally 3) compute
the absolute values of residuals.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>abs_stdrhserC(x, y, ctrl, ycolumn = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="abs_stdrhserC_+3A_x">x</code></td>
<td>
<p>vector of data on the dependent variable</p>
</td></tr>
<tr><td><code id="abs_stdrhserC_+3A_y">y</code></td>
<td>
<p>data on the regressors which can be a matrix</p>
</td></tr>
<tr><td><code id="abs_stdrhserC_+3A_ctrl">ctrl</code></td>
<td>
<p>Data matrix on the control variable(s) beyond causal path issues</p>
</td></tr>
<tr><td><code id="abs_stdrhserC_+3A_ycolumn">ycolumn</code></td>
<td>
<p>if y has more than one column, the 
column number used when multiplying residuals times
this column of y, default=1 or first column of y matrix is used</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The first argument is assumed to be the dependent variable.  If
<code>abs_stdrhserC(x,y)</code> is used, you are regressing x on y (not the usual y
on x). The regressors can be a matrix with 2 or more columns. The missing values
are suitably ignored by the standardization.
</p>


<h3>Value</h3>

<p>Absolute values of kernel regression residuals are returned after
standardizing the data on both sides so that the magnitudes of residuals are
comparable between regression of x on y on the one hand and regression of y
on x on the other.
</p>


<h3>Author(s)</h3>

<p>Prof. H. D. Vinod, Economics Dept., Fordham University, NY
</p>


<h3>References</h3>

<p>Vinod, H. D. 'Generalized Correlation and Kernel Causality with
Applications in Development Economics' in Communications in
Statistics -Simulation and Computation, 2015,
<a href="https://doi.org/10.1080/03610918.2015.1122048">doi:10.1080/03610918.2015.1122048</a>
</p>


<h3>See Also</h3>

<p>See  <code><a href="#topic+abs_stdres">abs_stdres</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
set.seed(330)
x=sample(20:50)
y=sample(20:50)
z=sample(21:51)
abs_stdrhserC(x,y,ctrl=z)

## End(Not run)

</code></pre>

<hr>
<h2 id='abs_stdrhserr'>Absolute values of Hausman-Wu null in kernel regressions of x on y when
both x and y are standardized.</h2><span id='topic+abs_stdrhserr'></span>

<h3>Description</h3>

<p>1) standardize the data to force mean zero and variance unity, 2) kernel
regress x on y, with the option &lsquo;gradients = TRUE&rsquo; and finally 3) compute
the absolute values of Hausman-Wu null hypothesis for testing exogeneity,
or E(RHS.regressor*error)=0 where error is approximated by kernel 
regression residuals
</p>


<h3>Usage</h3>

<pre><code class='language-R'>abs_stdrhserr(x, y)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="abs_stdrhserr_+3A_x">x</code></td>
<td>
<p>vector of data on the dependent variable</p>
</td></tr>
<tr><td><code id="abs_stdrhserr_+3A_y">y</code></td>
<td>
<p>data on the regressors which can be a matrix</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The first argument is assumed to be the dependent variable.  If
<code>abs_stdrhserr(x,y)</code> is used, you are regressing x on y (not the usual y
on x). The regressors can be a matrix with 2 or more columns. The missing values
are suitably ignored by the standardization.
</p>


<h3>Value</h3>

<p>Absolute values of kernel regression RHS*residuals are returned after
standardizing the data on both sides so that the magnitudes of 
Hausman-Wu null values are comparable between regression of x on y on
the one hand and flipped regression of y on x on the other.
</p>


<h3>Author(s)</h3>

<p>Prof. H. D. Vinod, Economics Dept., Fordham University, NY
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
set.seed(330)
x=sample(20:50)
y=sample(20:50)
abs_stdrhserr(x,y)

## End(Not run)
</code></pre>

<hr>
<h2 id='absBstdres'>Block version of abs-stdres Absolute values of residuals of kernel regressions 
of  standardized x on  standardized y, no control variables.</h2><span id='topic+absBstdres'></span>

<h3>Description</h3>

<p>1) Standardize the data to force mean zero and variance unity, 2) kernel
regress x on y, with the option &lsquo;residuals = TRUE&rsquo; and finally 3) compute
the absolute values of residuals.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>absBstdres(x, y, blksiz = 10)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="absBstdres_+3A_x">x</code></td>
<td>
<p>vector of data on the dependent variable</p>
</td></tr>
<tr><td><code id="absBstdres_+3A_y">y</code></td>
<td>
<p>data on the regressors which can be a matrix</p>
</td></tr>
<tr><td><code id="absBstdres_+3A_blksiz">blksiz</code></td>
<td>
<p>block size, default=10, if chosen blksiz &gt;n, where n=rows in matrix
then blksiz=n. That is, no blocking is done</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The first argument is assumed to be the dependent variable.  If
<code>abs_stdres(x,y)</code> is used, you are regressing x on y (not the usual y
on x). The regressors can be a matrix with 2 or more columns. The missing values
are suitably ignored by the standardization.
</p>


<h3>Value</h3>

<p>Absolute values of kernel regression residuals are returned after
standardizing the data on both sides so that the magnitudes of residuals are
comparable between regression of x on y on the one hand and regression of y
on x on the other.
</p>


<h3>Author(s)</h3>

<p>Prof. H. D. Vinod, Economics Dept., Fordham University, NY
</p>


<h3>References</h3>

<p>Vinod, H. D. 'Generalized Correlation and Kernel Causality with
Applications in Development Economics' in Communications in
Statistics -Simulation and Computation, 2015,
<a href="https://doi.org/10.1080/03610918.2015.1122048">doi:10.1080/03610918.2015.1122048</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
set.seed(330)
x=sample(20:50)
y=sample(20:50)
abs_stdres(x,y)

## End(Not run)

</code></pre>

<hr>
<h2 id='absBstdresC'>Block version of Absolute values of residuals of kernel regressions of standardized x on 
standardized y and control variables.</h2><span id='topic+absBstdresC'></span>

<h3>Description</h3>

<p>1) standardize the data to force mean zero and variance unity, 2) kernel
regress x on y and a matrix of control variables, 
with the option &lsquo;residuals = TRUE&rsquo; and finally 3) compute
the absolute values of residuals.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>absBstdresC(x, y, ctrl, blksiz = 10)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="absBstdresC_+3A_x">x</code></td>
<td>
<p>vector of data on the dependent variable</p>
</td></tr>
<tr><td><code id="absBstdresC_+3A_y">y</code></td>
<td>
<p>data on the regressors which can be a matrix</p>
</td></tr>
<tr><td><code id="absBstdresC_+3A_ctrl">ctrl</code></td>
<td>
<p>Data matrix on the control variable(s) beyond causal path issues</p>
</td></tr>
<tr><td><code id="absBstdresC_+3A_blksiz">blksiz</code></td>
<td>
<p>block size, default=10, if chosen blksiz &gt;n, where n=rows in matrix
then blksiz=n. That is, no blocking is done</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The first argument is assumed to be the dependent variable.  If
<code>abs_stdres(x,y)</code> is used, you are regressing x on y (not the usual y
on x). The regressors can be a matrix with two or more columns. The missing values
are suitably ignored by the standardization.
</p>


<h3>Value</h3>

<p>Absolute values of kernel regression residuals are returned after
standardizing the data on both sides so that the magnitudes of residuals are
comparable between regression of x on y on the one hand and regression of y
on x on the other.
</p>


<h3>Author(s)</h3>

<p>Prof. H. D. Vinod, Economics Dept., Fordham University, NY
</p>


<h3>References</h3>

<p>Vinod, H. D.'Generalized Correlation and Kernel Causality with
Applications in Development Economics' in Communications in
Statistics -Simulation and Computation, 2015,
<a href="https://doi.org/10.1080/03610918.2015.1122048">doi:10.1080/03610918.2015.1122048</a>
</p>


<h3>See Also</h3>

<p>See  <code><a href="#topic+abs_stdres">abs_stdres</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
set.seed(330)
x=sample(20:50)
y=sample(20:50)
z=sample(21:51)
absBstdresC(x,y,ctrl=z)

## End(Not run)

</code></pre>

<hr>
<h2 id='absBstdrhserC'>Block version abs_stdrhser Absolute residuals kernel regressions of standardized x on y and control 
variables, Cr1 has abs(Resid*RHS).</h2><span id='topic+absBstdrhserC'></span>

<h3>Description</h3>

<p>1) standardize the data to force mean zero and variance unity, 2) kernel
regress x on y and a matrix of control variables, 
with the option &lsquo;residuals = TRUE&rsquo; and finally 3) compute
the absolute values of residuals.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>absBstdrhserC(x, y, ctrl, ycolumn = 1, blksiz = 10)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="absBstdrhserC_+3A_x">x</code></td>
<td>
<p>vector of data on the dependent variable</p>
</td></tr>
<tr><td><code id="absBstdrhserC_+3A_y">y</code></td>
<td>
<p>data on the regressors which can be a matrix</p>
</td></tr>
<tr><td><code id="absBstdrhserC_+3A_ctrl">ctrl</code></td>
<td>
<p>Data matrix on the control variable(s) beyond causal path issues</p>
</td></tr>
<tr><td><code id="absBstdrhserC_+3A_ycolumn">ycolumn</code></td>
<td>
<p>if y has more than one column, the 
column number used when multiplying residuals times
this column of y, default=1 or first column of y matrix is used</p>
</td></tr>
<tr><td><code id="absBstdrhserC_+3A_blksiz">blksiz</code></td>
<td>
<p>block size, default=10, if chosen blksiz &gt;n, where n=rows in matrix
then blksiz=n. That is, no blocking is done</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The first argument is assumed to be the dependent variable.  If
<code>absBstdrhserC(x,y)</code> is used, you are regressing x on y (not the usual y
on x). The regressors can be a matrix with 2 or more columns. The missing values
are suitably ignored by the standardization.
</p>


<h3>Value</h3>

<p>Absolute values of kernel regression residuals are returned after
standardizing the data on both sides so that the magnitudes of residuals are
comparable between regression of x on y on the one hand and regression of y
on x on the other.
</p>


<h3>Author(s)</h3>

<p>Prof. H. D. Vinod, Economics Dept., Fordham University, NY
</p>


<h3>References</h3>

<p>Vinod, H. D. 'Generalized Correlation and Kernel Causality with
Applications in Development Economics' in Communications in
Statistics -Simulation and Computation, 2015,
<a href="https://doi.org/10.1080/03610918.2015.1122048">doi:10.1080/03610918.2015.1122048</a>
</p>


<h3>See Also</h3>

<p>See  <code><a href="#topic+abs_stdres">abs_stdres</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
set.seed(330)
x=sample(20:50)
y=sample(20:50)
z=sample(21:51)
absBstdrhserC(x,y,ctrl=z)

## End(Not run)

</code></pre>

<hr>
<h2 id='allPairs'>Report causal identification for all pairs of variables in a matrix 
(deprecated function). It is better to choose a target variable and pair
it with all others, instead of considering all possible targets.</h2><span id='topic+allPairs'></span>

<h3>Description</h3>

<p>This studies all possible (perhaps too many) causal directions in a matrix.
It is deprecated because it uses older criterion 1 by caling <code>abs_stdapd</code>
I recommend using <code>causeSummary</code> or its block version <code>cuseSummBlk</code>.
This uses <code>abs_stdres</code>, <code>comp_portfo2</code>, etc. and returns
a matrix with 7 columns having detailed output. Criterion 1 has been revised
as described in Vinod (2019) and is known to work better.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>allPairs(mtx, dig = 6, verbo = FALSE, typ = 1, rnam = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="allPairs_+3A_mtx">mtx</code></td>
<td>
<p>Input matrix with variable names</p>
</td></tr>
<tr><td><code id="allPairs_+3A_dig">dig</code></td>
<td>
<p>Digits of accuracy in reporting (=6, default)</p>
</td></tr>
<tr><td><code id="allPairs_+3A_verbo">verbo</code></td>
<td>
<p>Logical variable, set to 'TRUE' if printing is desired</p>
</td></tr>
<tr><td><code id="allPairs_+3A_typ">typ</code></td>
<td>
<p>Causal direction criterion number (typ=1 is default)
Criterion 1 (Cr1) compares kernel regression absolute values of gradients.
Criterion 2 (Cr2) compares kernel regression absolute values of residuals.
Criterion 3 (Cr3) compares kernel regression based r*(x|y) with r*(y|x).</p>
</td></tr>
<tr><td><code id="allPairs_+3A_rnam">rnam</code></td>
<td>
<p>Logical variable, default <code>rnam=FALSE</code> means the user does
not want the row names to be
(somewhat too cleverly) assigned by the function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A 7-column matrix called 'outcause' with names of variables
X and Y in the first two columns and the name of the 'causal' variable in 3rd col.
Remaining four columns report numerical computations of SD1 to SD4, r*(x|y),
r*(y|x).  Pearson r and p-values for its traditional significance testing.
</p>


<h3>Note</h3>

<p>The cause reported in the third column
is identified from the sign of the first SD1 only,
ignoring SD2, SD3 and SD4  under both Cr1 and Cr2. It is
a good idea to loop a call to this function with typ=1:3. One can print
the resulting 'outcause' matrix with the 
<code>xtable(outcause)</code> for the Latex output.
A similar deprecated function included in this package,
called <code>some0Pairs</code>, incorporates all SD1 to SD4 and all
three criteria Cr1 rto Cr3 to report a &lsquo;sum&rsquo; of indexes representing the signed 
number whose sign can more comprehensively help determine the causal direction(s).
Since the Cr1 here is revised in later work, this is deprecated.
</p>


<h3>Author(s)</h3>

<p>Prof. H. D. Vinod, Economics Dept., Fordham University, NY
</p>


<h3>References</h3>

<p>Vinod, H. D.'Generalized Correlation and Kernel Causality with
Applications in Development Economics' in Communications in
Statistics -Simulation and Computation, 2015,
<a href="https://doi.org/10.1080/03610918.2015.1122048">doi:10.1080/03610918.2015.1122048</a>
</p>
<p>Vinod, H. D. 'New exogeneity tests and causal paths,'
Chapter 2 in 'Handbook of Statistics: Conceptual Econometrics 
Using R', Vol.32, co-editors: H. D. Vinod and C.R. Rao. New York:
North Holland, Elsevier Science Publishers, 2019, pp. 33-64.
</p>


<h3>See Also</h3>

<p>See Also  <code>somePairs</code>, <code>some0Pairs</code> <code>causeSummary</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(mtcars)
options(np.messages=FALSE)
for(j in 1:3){
a1=allPairs(mtcars[,1:3], typ=j)
print(a1)}

</code></pre>

<hr>
<h2 id='badCol'>
internal badCol
</h2><span id='topic+badCol'></span>

<h3>Description</h3>

<p>intended for internal use
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(badCol)</code></pre>


<h3>Format</h3>

<p>The format is:
int 4
</p>

<hr>
<h2 id='bigfp'>Compute the numerical integration by the trapezoidal rule.</h2><span id='topic+bigfp'></span>

<h3>Description</h3>

<p>See page 220 of Vinod (2008) &ldquo;Hands-on Intermediate Econometrics Using R,&rdquo; 
for the trapezoidal integration formula
needed for stochastic dominance.  The book explains pre-multiplication by two
large sparse matrices denoted by <code class="reqn">I_F,  I_f</code>.  Here we accomplish the 
same computation without actually creating the large sparse matrices. For example, the
<code class="reqn">I_f</code> is replaced by <code>cumsum</code> in this code (unlike the R code in
my textbook).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bigfp(d, p)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bigfp_+3A_d">d</code></td>
<td>
<p>A vector of consecutive interval lengths, upon combining both data vectors</p>
</td></tr>
<tr><td><code id="bigfp_+3A_p">p</code></td>
<td>
<p>Vector of probabilities of the type 1/2T, 2/2T, 3/2T, etc. to 1.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a result after pre-multiplication by <code class="reqn">I_F,  I_f</code>
matrices, without actually creating the large sparse matrices. This is an internal function.
</p>


<h3>Note</h3>

<p>This is an internal function, called by the function <code>stochdom2</code>, for
comparison of two portfolios in terms of stochastic dominance (SD) of orders
1 to 4.
Typical usage is:
<code>sd1b=bigfp(d=dj, p=rhs)
sd2b=bigfp(d=dj, p=sd1b)
sd3b=bigfp(d=dj, p=sd2b)
sd4b=bigfp(d=dj, p=sd3b)</code>.
This produces numerical evaluation vectors for the four orders, SD1  to SD4.
</p>


<h3>Author(s)</h3>

<p>Prof. H. D. Vinod, Economics Dept., Fordham University, NY
</p>


<h3>References</h3>

<p>Vinod, H. D.', 'Hands-On Intermediate Econometrics
Using R'  (2008) World Scientific Publishers: Hackensack, NJ.
<a href="https://www.worldscientific.com/worldscibooks/10.1142/12831">https://www.worldscientific.com/worldscibooks/10.1142/12831</a>
</p>

<hr>
<h2 id='bootDom12'>bootstrap confidence intervals for (x2-x1) exact SD1 to SD4 stochastic dominance 
.</h2><span id='topic+bootDom12'></span>

<h3>Description</h3>

<p>This calls the meboot package to create J=999 replications of portfolio return
matrices and compute 95% confidence intervals on x1, x2 and their
difference (x2-x1).  If the interval on (x2-x1) conta.ins zero the choice
between the two can reverse due to sampling variation
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bootDom12(x1, x2, confLevel = 95, reps = 999)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bootDom12_+3A_x1">x1</code></td>
<td>
<p>a vector of n portfolio returns</p>
</td></tr>
<tr><td><code id="bootDom12_+3A_x2">x2</code></td>
<td>
<p>a vector of n portfolio returns</p>
</td></tr>
<tr><td><code id="bootDom12_+3A_conflevel">confLevel</code></td>
<td>
<p>confidene level confLevel=95 is default</p>
</td></tr>
<tr><td><code id="bootDom12_+3A_reps">reps</code></td>
<td>
<p>number of bootstrap resamples, default is reps=999</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix with six columns. First two Low1 and Upp1
are confidence interval limits for x1. Next two columns
have analogous limits for x2. The last but first columns entitled
Lowx2mx1 means lower confidence limit for (x2-x1), where m=minus.
The last column entitled
Uppx2mx1  means upper confidence limit for (x2-x1). 
</p>
<p>For strong stochastic dominance of x2 over x1
dominance beyond sampling variability, zero should not be inside
the confidence interval in the last two columns.
</p>


<h3>Author(s)</h3>

<p>Prof. H. D. Vinod, Economics Dept., Fordham University, NY
</p>


<h3>See Also</h3>

<p>see <code><a href="#topic+exactSdMtx">exactSdMtx</a></code>
</p>

<hr>
<h2 id='bootGcLC'>Compute vector of n999 nonlinear Granger causality paths</h2><span id='topic+bootGcLC'></span>

<h3>Description</h3>

<p>Maximum entropy bootstrap (meboot) package is used for statistical inference
The bootstrap output can be analyzed to estimate an approximate confidence
interval on sample-based direction of the causal path.
The LC in the function name stands for local constant.
Kernel regression np package options regtype=&quot;lc&quot; for local constant, 
and bwmethod=&quot;cv.ls&quot; for least squares-based bandwidth selection are fixed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bootGcLC(x1, x2, px2 = 4, px1 = 4, pwanted = 4, ctrl = 0, n999 = 9)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bootGcLC_+3A_x1">x1</code></td>
<td>
<p>The data vector x1</p>
</td></tr>
<tr><td><code id="bootGcLC_+3A_x2">x2</code></td>
<td>
<p>The data vector x2</p>
</td></tr>
<tr><td><code id="bootGcLC_+3A_px2">px2</code></td>
<td>
<p>number of lags of x2 in the data, default px2=4</p>
</td></tr>
<tr><td><code id="bootGcLC_+3A_px1">px1</code></td>
<td>
<p>number of lags of x1 in the data default px1=4</p>
</td></tr>
<tr><td><code id="bootGcLC_+3A_pwanted">pwanted</code></td>
<td>
<p>number of lags of both x2 and x1 wanted for 
Granger causal analysis, default =4</p>
</td></tr>
<tr><td><code id="bootGcLC_+3A_ctrl">ctrl</code></td>
<td>
<p>data matrix having control variable(s) if any</p>
</td></tr>
<tr><td><code id="bootGcLC_+3A_n999">n999</code></td>
<td>
<p>Number of bootstrap replications (default=9)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>out is  n999 X 3 matrix for 3 outputs of GcauseX12 resampled
</p>


<h3>Note</h3>

<p>This computation is computer intensive and generally very slow. 
It may be better to use this function
it at a later stage in the investigation, after a preliminary 
causal determination is already made. The 3 outputs of GauseX12 are
two Rsquares and the difference between after subtracting the second
from the first.  Col. 1 has (RsqX1onX2)
Col.2 has (RsqX2onX1), and Col.3 has dif=(RsqX1onX2 -RsqX2onX1)
Note that R-squares are always positive. 
If dif&gt;0, RsqX1onX2&gt;RsqX2onX1, implying that x2 on RHS performs better
that is, x2 &ndash;&gt; x1 is the path, or x2 Granger-causes x1.
If dif&lt;0, x1 &ndash;&gt; x2 holds. If dif is too close to zero,
we may have bidirectional causality  x1 &lt;&ndash;&gt; x2. The proportion of
resamples (out of n999) having dif&lt;0 suggests level of confidence in
the conclusion x1 &ndash;&gt; x2.  The proportion of
resamples (out of n999) having dif&gt;0 suggests level of confidence in
the conclusion x2 &ndash;&gt; x1.
</p>


<h3>Author(s)</h3>

<p>Prof. H. D. Vinod, Economics Dept., Fordham University, NY
</p>


<h3>References</h3>

<p>Vinod, H. D. 'Generalized Correlation and Kernel Causality with 
Applications in Development Economics' in Communications in 
Statistics -Simulation and Computation, 2015, 
<a href="https://doi.org/10.1080/03610918.2015.1122048">doi:10.1080/03610918.2015.1122048</a>
</p>
<p>Zheng, S., Shi, N.-Z., and Zhang, Z. (2012). Generalized measures 
of correlation for asymmetry, nonlinearity, and beyond. 
Journal of the American Statistical Association, vol. 107, pp. 1239-1252.
</p>
<p>Vinod, H. D. and Lopez-de-Lacalle, J. (2009). 'Maximum entropy bootstrap
for time series: The meboot R package.' Journal of Statistical Software,
Vol. 29(5), pp. 1-19.
</p>
<p>Vinod, H. D. Causal Paths and Exogeneity Tests 
in Generalcorr Package for Air Pollution and Monetary Policy 
(June 6, 2017). Available at SSRN: <a href="https://www.ssrn.com/abstract=2982128">https://www.ssrn.com/abstract=2982128</a>
</p>


<h3>See Also</h3>

<p>See Also <code><a href="#topic+GcRsqX12c">GcRsqX12c</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(Ecdat);options(np.messages=FALSE);attach(data.frame(MoneyUS))
bootGcLC(y,m,n999=9) 

## End(Not run)
## Not run: 
library(lmtest); data(ChickEgg);attach(data.frame(ChickEgg))
b2=bootGcLC(x1=chicken,x2=egg,pwanted=3,px1=3,px2=3,n999=99)

## End(Not run)


</code></pre>

<hr>
<h2 id='bootGcRsq'>Compute vector of n999 nonlinear Granger causality paths</h2><span id='topic+bootGcRsq'></span>

<h3>Description</h3>

<p>Maximum entropy bootstrap (meboot) package is used for statistical inference
The bootstrap output can be analyzed to estimate an approximate confidence
interval on sample-based direction of the causal path.
Kernel regression np package options regtype=&quot;ll&quot; for local linear, 
and bwmethod=&quot;cv.aic&quot; for AIC-based bandwidth selection are fixed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bootGcRsq(x1, x2, px2 = 4, px1 = 4, pwanted = 4, ctrl = 0, n999 = 9)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bootGcRsq_+3A_x1">x1</code></td>
<td>
<p>The data vector x1</p>
</td></tr>
<tr><td><code id="bootGcRsq_+3A_x2">x2</code></td>
<td>
<p>The data vector x2</p>
</td></tr>
<tr><td><code id="bootGcRsq_+3A_px2">px2</code></td>
<td>
<p>number of lags of x2 in the data, default px2=4</p>
</td></tr>
<tr><td><code id="bootGcRsq_+3A_px1">px1</code></td>
<td>
<p>number of lags of x1 in the data default px1=4</p>
</td></tr>
<tr><td><code id="bootGcRsq_+3A_pwanted">pwanted</code></td>
<td>
<p>number of lags of both x2 and x1 wanted for 
Granger causal analysis, default =4</p>
</td></tr>
<tr><td><code id="bootGcRsq_+3A_ctrl">ctrl</code></td>
<td>
<p>data matrix having control variable(s) if any</p>
</td></tr>
<tr><td><code id="bootGcRsq_+3A_n999">n999</code></td>
<td>
<p>Number of bootstrap replications (default=9)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>out is  n999 X 3 matrix for 3 outputs of GcauseX12 resampled
</p>


<h3>Note</h3>

<p>This computation is computer intensive and generally very slow. 
It may be better to use this function
it at a later stage in the investigation, after a preliminary 
causal determination is already made. The 3 outputs of GauseX12 are
two Rsquares and the difference between them after subtracting the second
from the first.  Col. 1 has (RsqX1onX2),
Col.2 has (RsqX2onX1), and Col.3 has dif=(RsqX1onX2 -RsqX2onX1)
Note that R-squares are always positive. 
If dif&gt;0, RsqX1onX2&gt;RsqX2onX1, implying that x2 on RHS performs better
that is, x2 &ndash;&gt; x1 is the causal path.
If dif&lt;0, x1 &ndash;&gt; x2 holds. If dif is too close to zero,
we may have bidirectional causality  x1 &lt;&ndash;&gt; x2. The proportion of
resamples (out of n999) having dif&lt;0 suggests level of confidence in
the conclusion x1 &ndash;&gt; x2.  The proportion of
resamples (out of n999) having dif&gt;0 suggests level of confidence in
the conclusion x2 &ndash;&gt; x1.
</p>


<h3>Author(s)</h3>

<p>Prof. H. D. Vinod, Economics Dept., Fordham University, NY
</p>


<h3>References</h3>

<p>Vinod, H. D. 'Generalized Correlation and Kernel Causality with 
Applications in Development Economics' in Communications in 
Statistics -Simulation and Computation, 2015, 
<a href="https://doi.org/10.1080/03610918.2015.1122048">doi:10.1080/03610918.2015.1122048</a>
</p>
<p>Zheng, S., Shi, N.-Z., and Zhang, Z. (2012). Generalized measures 
of correlation for asymmetry, nonlinearity, and beyond. 
Journal of the American Statistical Association, vol. 107, pp. 1239-1252.
</p>
<p>Vinod, H. D. and Lopez-de-Lacalle, J. (2009). 'Maximum entropy bootstrap
for time series: The meboot R package.' Journal of Statistical Software,
Vol. 29(5), pp. 1-19.
</p>
<p>Vinod, H. D. Causal Paths and Exogeneity Tests 
in Generalcorr Package for Air Pollution and Monetary Policy 
(June 6, 2017). Available at SSRN: <a href="https://www.ssrn.com/abstract=2982128">https://www.ssrn.com/abstract=2982128</a>
</p>


<h3>See Also</h3>

<p>See Also <code><a href="#topic+GcRsqX12">GcRsqX12</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(Ecdat);options(np.messages=FALSE);attach(data.frame(MoneyUS))
bootGcRsq(y,m,n999=9) 

## End(Not run)
## Not run: 
library(lmtest); data(ChickEgg);attach(data.frame(ChickEgg))
options(np.messages=FALSE)
b2=bootGcLC(x1=chicken,x2=egg,pwanted=3,px1=3,px2=3,n999=99)
Fn=function(x)quantile(x,prob=c(0.025, 0.975))#confInt
apply(b1,2,Fn)#reports 95 percent confidence interval

## End(Not run)
</code></pre>

<hr>
<h2 id='bootPair2'>Compute matrix of n999 rows and p-1 columns of bootstrap &lsquo;sum&rsquo; 
(scores from Cr1 to Cr3).</h2><span id='topic+bootPair2'></span>

<h3>Description</h3>

<p>The &lsquo;2&rsquo; in the name of the function suggests a second implementation of &lsquo;bootPair,&rsquo;
where exact stochastic dominance, decileVote, and momentVote are used.
Maximum entropy bootstrap (meboot) package is used for statistical inference
using the sum of three signs sg1 to sg3, from the three criteria Cr1 to Cr3, to
assess preponderance of evidence in favor of a sign, (+1, 0, -1).
The bootstrap output can be analyzed to assess the approximate
preponderance of a particular sign which determines
the causal direction.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bootPair2(mtx, ctrl = 0, n999 = 9)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bootPair2_+3A_mtx">mtx</code></td>
<td>
<p>data matrix with two or more columns</p>
</td></tr>
<tr><td><code id="bootPair2_+3A_ctrl">ctrl</code></td>
<td>
<p>data matrix having control variable(s) if any</p>
</td></tr>
<tr><td><code id="bootPair2_+3A_n999">n999</code></td>
<td>
<p>Number of bootstrap replications (default=9)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Function creates a matrix called &lsquo;out&rsquo;. If
the input to the function called <code>mtx</code> has p columns, the output <code>out</code>
of <code>bootPair2(mtx)</code> is a matrix of n999 rows and p-1 columns,
each containing resampled &lsquo;sum&rsquo; values summarizing the weighted sums 
associated with all three  criteria from the function <code>silentPair2(mtx)</code>
applied to each bootstrap sample separately.
</p>


<h3>Note</h3>

<p>This computation is computer-intensive and generally very slow. 
It may be better to use
it later in the investigation, after a preliminary 
causal determination 
is already made.
A positive sign for j-th weighted sum reported in the column &lsquo;sum&rsquo; means
that the first variable listed in the argument matrix <code>mtx</code> is the 
&lsquo;kernel cause&rsquo; of the variable in the (j+1)-th column of <code>mtx</code>.
</p>


<h3>Author(s)</h3>

<p>Prof. H. D. Vinod, Economics Dept., Fordham University, NY
</p>


<h3>References</h3>

<p>Vinod, H. D. 'Generalized Correlation and Kernel Causality with 
Applications in Development Economics' in Communications in 
Statistics -Simulation and Computation, 2015, 
<a href="https://doi.org/10.1080/03610918.2015.1122048">doi:10.1080/03610918.2015.1122048</a>
</p>
<p>Zheng, S., Shi, N.-Z., and Zhang, Z. (2012). Generalized measures 
of correlation for asymmetry, nonlinearity, and beyond. 
Journal of the American Statistical Association, vol. 107, pp. 1239-1252.
</p>
<p>Vinod, H. D. and Lopez-de-Lacalle, J. (2009). 'Maximum entropy bootstrap
for time series: The meboot R package.' Journal of Statistical Software,
Vol. 29(5), pp. 1-19.
</p>
<p>Vinod, H. D. Causal Paths and Exogeneity Tests 
in Generalcorr Package for Air Pollution and Monetary Policy 
(June 6, 2017). Available at SSRN: <a href="https://www.ssrn.com/abstract=2982128">https://www.ssrn.com/abstract=2982128</a>
</p>
<p>Vinod, Hrishikesh D., R Package GeneralCorr 
Functions for Portfolio Choice 
(November 11, 2021). Available at SSRN: 
https://ssrn.com/abstract=3961683
</p>
<p>Vinod, Hrishikesh D., Stochastic Dominance 
Without Tears (January 26, 2021). Available at 
SSRN: https://ssrn.com/abstract=3773309
</p>


<h3>See Also</h3>

<p>See Also <code><a href="#topic+silentPair2">silentPair2</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
options(np.messages = FALSE)
set.seed(34);x=sample(1:10);y=sample(2:11)
bb=bootPair2(cbind(x,y),n999=29)
apply(bb,2,summary) #gives summary stats for n999 bootstrap sum computations

bb=bootPair2(airquality,n999=999);options(np.messages=FALSE)
apply(bb,2,summary) #gives summary stats for n999 bootstrap sum computations

data('EuroCrime')
attach(EuroCrime)
bootPair2(cbind(crim,off),n999=29)#First col. crim causes officer deployment,
#hence positives signs are most sensible for such call to bootPairs
#note that n999=29 is too small for real problems, chosen for quickness here.

## End(Not run)
</code></pre>

<hr>
<h2 id='bootPairs'>Compute matrix of n999 rows and p-1 columns of bootstrap &lsquo;sum&rsquo; 
(strength from Cr1 to Cr3).</h2><span id='topic+bootPairs'></span>

<h3>Description</h3>

<p>Maximum entropy bootstrap (meboot) package is used for statistical inference
using the sum of three signs sg1 to sg3 from the three criteria Cr1 to Cr3 to
assess preponderance of evidence in favor of a sign. (+1, 0, -1).
The bootstrap output can be analyzed to assess approximate
preponderance of a particular sign which determines
the causal direction.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bootPairs(mtx, ctrl = 0, n999 = 9)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bootPairs_+3A_mtx">mtx</code></td>
<td>
<p>data matrix with two or more columns</p>
</td></tr>
<tr><td><code id="bootPairs_+3A_ctrl">ctrl</code></td>
<td>
<p>data matrix having control variable(s) if any</p>
</td></tr>
<tr><td><code id="bootPairs_+3A_n999">n999</code></td>
<td>
<p>Number of bootstrap replications (default=9)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>out When <code>mtx</code> has p columns, <code>out</code>
of <code>bootPairs(mtx)</code> is a matrix of n999 rows and p-1 columns
each containing resampled &lsquo;sum&rsquo; values summarizing the weighted sums 
associated with all three  criteria from the function <code>silentPairs(mtx)</code>
applied to each bootstrap sample separately.
</p>


<h3>Note</h3>

<p>This computation is computer intensive and generally very slow. 
It may be better to use
it at a later stage in the investigation when a preliminary 
causal determination 
is already made.
A positive sign for j-th weighted sum reported in the column &lsquo;sum&rsquo; means
that the first variable listed in the argument matrix <code>mtx</code> is the 
&lsquo;kernel cause&rsquo; of the variable in the (j+1)-th column of <code>mtx</code>.
</p>


<h3>Author(s)</h3>

<p>Prof. H. D. Vinod, Economics Dept., Fordham University, NY
</p>


<h3>References</h3>

<p>Vinod, H. D. 'Generalized Correlation and Kernel Causality with 
Applications in Development Economics' in Communications in 
Statistics -Simulation and Computation, 2015, 
<a href="https://doi.org/10.1080/03610918.2015.1122048">doi:10.1080/03610918.2015.1122048</a>
</p>
<p>Zheng, S., Shi, N.-Z., and Zhang, Z. (2012). Generalized measures 
of correlation for asymmetry, nonlinearity, and beyond. 
Journal of the American Statistical Association, vol. 107, pp. 1239-1252.
</p>
<p>Vinod, H. D. and Lopez-de-Lacalle, J. (2009). 'Maximum entropy bootstrap
for time series: The meboot R package.' Journal of Statistical Software,
Vol. 29(5), pp. 1-19.
</p>
<p>Vinod, H. D. Causal Paths and Exogeneity Tests 
in Generalcorr Package for Air Pollution and Monetary Policy 
(June 6, 2017). Available at SSRN: <a href="https://www.ssrn.com/abstract=2982128">https://www.ssrn.com/abstract=2982128</a>
</p>


<h3>See Also</h3>

<p>See Also <code><a href="#topic+silentPairs">silentPairs</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
options(np.messages = FALSE)
set.seed(34);x=sample(1:10);y=sample(2:11)
bb=bootPairs(cbind(x,y),n999=29)
apply(bb,2,summary) #gives summary stats for n999 bootstrap sum computations

bb=bootPairs(airquality,n999=999);options(np.messages=FALSE)
apply(bb,2,summary) #gives summary stats for n999 bootstrap sum computations

data('EuroCrime')
attach(EuroCrime)
bootPairs(cbind(crim,off),n999=29)#First col. crim causes officer deployment,
#hence positives signs are most sensible for such call to bootPairs
#note that n999=29 is too small for real problems, chosen for quickness here.

## End(Not run)
</code></pre>

<hr>
<h2 id='bootPairs0'>Compute matrix of n999 rows and p-1 columns of bootstrap &lsquo;sum&rsquo; index
(strength from older criterion Cr1, with newer Cr2 and Cr3).</h2><span id='topic+bootPairs0'></span>

<h3>Description</h3>

<p>Maximum entropy bootstrap (meboot) package is used for statistical inference
using the sum of three signs sg1 to sg3 from the three criteria Cr1 to Cr3 to
assess preponderance of evidence in favor of a sign. (+1, 0, -1).
The bootstrap output can be analyzed to assess approximate
preponderance of a particular sign which determines
the causal direction.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bootPairs0(mtx, ctrl = 0, n999 = 9)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bootPairs0_+3A_mtx">mtx</code></td>
<td>
<p>data matrix with two or more columns</p>
</td></tr>
<tr><td><code id="bootPairs0_+3A_ctrl">ctrl</code></td>
<td>
<p>data matrix having control variable(s) if any</p>
</td></tr>
<tr><td><code id="bootPairs0_+3A_n999">n999</code></td>
<td>
<p>Number of bootstrap replications (default=9)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>out When <code>mtx</code> has p columns, <code>out</code>
of <code>bootPairs(mtx)</code> is a matrix of n999 rows and p-1 columns
each containing resampled &lsquo;sum&rsquo; values summarizing the weighted sums 
associated with all three  criteria from the function <code>silentPairs(mtx)</code>
applied to each bootstrap sample separately.
</p>


<h3>Note</h3>

<p>This computation is computer intensive and generally very slow. 
It may be better to use
it at a later stage in the investigation when a preliminary 
causal determination 
is already made.
A positive sign for j-th weighted sum reported in the column &lsquo;sum&rsquo; means
that the first variable listed in the argument matrix <code>mtx</code> is the 
&lsquo;kernel cause&rsquo; of the variable in the (j+1)-th column of <code>mtx</code>.
</p>


<h3>Author(s)</h3>

<p>Prof. H. D. Vinod, Economics Dept., Fordham University, NY
</p>


<h3>References</h3>

<p>Vinod, H. D. 'Generalized Correlation and Kernel Causality with 
Applications in Development Economics' in Communications in 
Statistics -Simulation and Computation, 2015, 
<a href="https://doi.org/10.1080/03610918.2015.1122048">doi:10.1080/03610918.2015.1122048</a>
</p>
<p>Zheng, S., Shi, N.-Z., and Zhang, Z. (2012). Generalized measures 
of correlation for asymmetry, nonlinearity, and beyond. 
Journal of the American Statistical Association, vol. 107, pp. 1239-1252.
</p>
<p>Vinod, H. D. and Lopez-de-Lacalle, J. (2009). 'Maximum entropy bootstrap
for time series: The meboot R package.' Journal of Statistical Software,
Vol. 29(5), pp. 1-19.
</p>
<p>Vinod, H. D. Causal Paths and Exogeneity Tests 
in Generalcorr Package for Air Pollution and Monetary Policy 
(June 6, 2017). Available at SSRN: <a href="https://www.ssrn.com/abstract=2982128">https://www.ssrn.com/abstract=2982128</a>
</p>


<h3>See Also</h3>

<p>See Also <code><a href="#topic+silentPairs0">silentPairs0</a></code>, <code><a href="#topic+bootPairs">bootPairs</a></code>
has the version with later version of Cr1.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
options(np.messages = FALSE)
set.seed(34);x=sample(1:10);y=sample(2:11)
bb=bootPairs0(cbind(x,y),n999=29)
apply(bb,2,summary) #gives summary stats for n999 bootstrap sum computations

bb=bootPairs0(airquality,n999=999);options(np.messages=FALSE)
apply(bb,2,summary) #gives summary stats for n999 bootstrap sum computations

data('EuroCrime')
attach(EuroCrime)
bootPairs0(cbind(crim,off),n999=29)#First col. crim causes officer deployment,
#hence positives signs are most sensible for such call to bootPairs
#note that n999=29 is too small for real problems, chosen for quickness here.

## End(Not run)
</code></pre>

<hr>
<h2 id='bootQuantile'>Compute confidence intervals [quantile(s)] of indexes from bootPairs output</h2><span id='topic+bootQuantile'></span>

<h3>Description</h3>

<p>Begin with the output of bootPairs function, a (n999 by p-1) matrix when
there are p columns of data, <code>bootQuantile</code> produces a (k by p-1) mtx
of quantile(s) of bootstrap ouput assuming that there are k quantiles needed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bootQuantile(out, probs = c(0.025, 0.975), per100 = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bootQuantile_+3A_out">out</code></td>
<td>
<p>output from bootPairs with p-1 columns and n999 rows</p>
</td></tr>
<tr><td><code id="bootQuantile_+3A_probs">probs</code></td>
<td>
<p>quantile evaluation probabilities. The default is k=2,
probs=c(.025,0.975) for a 95 percent confidence interval. Note
that there are k=2 quantiles desired for each column with this specification</p>
</td></tr>
<tr><td><code id="bootQuantile_+3A_per100">per100</code></td>
<td>
<p>logical (default per100=TRUE) to change the range of
'sum' to [-100, 100] values which are easier to interpret</p>
</td></tr>
</table>


<h3>Value</h3>

<p>CI k quantiles evaluated at probs as a matrix with k rows 
and quantile of pairwise p-1 indexes representing p-1 column pairs
(fixing the first column in each pair)
This function summarizes the 
output of of <code>bootPairs(mtx)</code> (a n999 by p-1 matrix)
each containing resampled &lsquo;sum&rsquo; values summarizing the weighted sums 
associated with all three  criteria from the 
function <code>silentPairs(mtx)</code>
applied to each bootstrap sample separately. #'
</p>


<h3>Author(s)</h3>

<p>Prof. H. D. Vinod, Economics Dept., Fordham University, NY
</p>


<h3>References</h3>

<p>Vinod, H. D. 'Generalized Correlation and Kernel Causality with 
Applications in Development Economics' in Communications in 
Statistics -Simulation and Computation, 2015, 
<a href="https://doi.org/10.1080/03610918.2015.1122048">doi:10.1080/03610918.2015.1122048</a>
</p>
<p>Vinod, H. D. and Lopez-de-Lacalle, J. (2009). 'Maximum entropy bootstrap
for time series: The meboot R package.' Journal of Statistical Software,
Vol. 29(5), pp. 1-19.
</p>
<p>Vinod, H. D. Causal Paths and Exogeneity Tests 
in Generalcorr Package for Air Pollution and Monetary Policy 
(June 6, 2017). Available at SSRN: <a href="https://www.ssrn.com/abstract=2982128">https://www.ssrn.com/abstract=2982128</a>
</p>


<h3>See Also</h3>

<p>See Also <code><a href="#topic+silentPairs">silentPairs</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
options(np.messages = FALSE)
set.seed(34);x=sample(1:10);y=sample(2:11)
bb=bootPairs(cbind(x,y),n999=29)
bootQuantile(bb) #gives summary stats for n999 bootstrap sum computations

bb=bootPairs(airquality,n999=999);options(np.messages=FALSE)
bootQuantile(bb,tau=0.476)#signs for n999 bootstrap sum computations

data('EuroCrime')
attach(EuroCrime)
bb=bootPairs(cbind(crim,off),n999=29) #col.1= crim causes off 
#hence positive signs are more intuitively meaningful.
#note that n999=29 is too small for real problems, chosen for quickness here.
bootQuantile(bb)# quantile matrix for n999 bootstrap sum computations

## End(Not run)
</code></pre>

<hr>
<h2 id='bootSign'>Probability of unambiguously correct (+ or -) sign from bootPairs output</h2><span id='topic+bootSign'></span>

<h3>Description</h3>

<p>If there are p columns of data, <code>bootSign</code> produces a p-1 by 1 vector
of probabilities of correct signs assuming that the mean of n999 values
has the correct sign and assuming that m of the 'sum' index values inside the
range [-tau, tau] are neither positive nor negative but 
indeterminate or ambiguous (being too close to zero). That is,
the denominator of P(+1) or P(-1) is (n999-m) if m signs are too close to zero. 
Thus it measures the bootstrap success rate in identifying the correct sign, when the sign
of the average of n999 bootstraps is assumed to be correct.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bootSign(out, tau = 0.476)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bootSign_+3A_out">out</code></td>
<td>
<p>output from bootPairs with p-1 columns and n999 rows</p>
</td></tr>
<tr><td><code id="bootSign_+3A_tau">tau</code></td>
<td>
<p>threshold to determine what value is too close to
zero, default tau=0.476 is equivalent to 15 percent threshold for 
the unanimity index ui</p>
</td></tr>
</table>


<h3>Value</h3>

<p>sgn When <code>mtx</code> has p columns, <code>sgn</code>
reports pairwise p-1 signs  representing 
(fixing the first column in each pair)
the average sign after averaging the
output of of <code>bootPairs(mtx)</code> (a n999 by p-1 matrix)
each containing resampled &lsquo;sum&rsquo; values summarizing the weighted sums 
associated with all three  criteria from the 
function <code>silentPairs(mtx)</code>
applied to each bootstrap sample separately. #'
</p>


<h3>Author(s)</h3>

<p>Prof. H. D. Vinod, Economics Dept., Fordham University, NY
</p>


<h3>References</h3>

<p>Vinod, H. D. 'Generalized Correlation and Kernel Causality with 
Applications in Development Economics' in Communications in 
Statistics -Simulation and Computation, 2015, 
<a href="https://doi.org/10.1080/03610918.2015.1122048">doi:10.1080/03610918.2015.1122048</a>
</p>
<p>Vinod, H. D. and Lopez-de-Lacalle, J. (2009). 'Maximum entropy bootstrap
for time series: The meboot R package.' Journal of Statistical Software,
Vol. 29(5), pp. 1-19.
</p>
<p>Vinod, H. D. Causal Paths and Exogeneity Tests 
in Generalcorr Package for Air Pollution and Monetary Policy 
(June 6, 2017). Available at SSRN: <a href="https://www.ssrn.com/abstract=2982128">https://www.ssrn.com/abstract=2982128</a>
</p>


<h3>See Also</h3>

<p>See Also <code><a href="#topic+silentPairs">silentPairs</a></code>, <code><a href="#topic+bootQuantile">bootQuantile</a></code>,
<code><a href="#topic+bootSignPcent">bootSignPcent</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
options(np.messages = FALSE)
set.seed(34);x=sample(1:10);y=sample(2:11)
bb=bootPairs(cbind(x,y),n999=29)
bootSign(bb,tau=0.476) #gives success rate in n999 bootstrap sum computations

bb=bootPairs(airquality,n999=999);options(np.messages=FALSE)
bootSign(bb,tau=0.476)#signs for n999 bootstrap sum computations

data('EuroCrime');options(np.messages=FALSE)
attach(EuroCrime)
bb=bootPairs(cbind(crim,off),n999=29) #col.1= crim causes off 
#hence positive signs are more intuitively meaningful.
#note that n999=29 is too small for real problems, chosen for quickness here.
bootSign(bb,tau=0.476)#gives success rate in n999 bootstrap sum computations

## End(Not run)
</code></pre>

<hr>
<h2 id='bootSignPcent'>Probability of unambiguously correct (+ or -) sign from bootPairs output transformed
to percentages.</h2><span id='topic+bootSignPcent'></span>

<h3>Description</h3>

<p>If there are p columns of data, <code>bootSignPcent</code> produces a p-1 by 1 vector
of probabilities of correct signs assuming that the mean of n999 values
has the correct sign and assuming that m of the 'ui' index values inside the
range [-tau, tau] are neither positive nor negative but 
indeterminate or ambiguous (being too close to zero). That is,
the denominator of P(+1) or P(-1) is (n999-m) if m signs are too close to zero. 
Thus it measures the bootstrap success rate in identifying the correct sign,  when the sign
of the average of n999 bootstraps is assumed to be correct.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bootSignPcent(out, tau = 5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bootSignPcent_+3A_out">out</code></td>
<td>
<p>output from bootPairs with p-1 columns and n999 rows</p>
</td></tr>
<tr><td><code id="bootSignPcent_+3A_tau">tau</code></td>
<td>
<p>threshold to determine what value is too close to
zero, default tau=5 is 5 percent threshold for the unanimity index ui</p>
</td></tr>
</table>


<h3>Value</h3>

<p>sgn When <code>mtx</code> has p columns, <code>sgn</code>
reports pairwise p-1 signs  representing 
(fixing the first column in each pair)
the average sign after averaging the
output of of <code>bootPairs(mtx)</code> (a n999 by p-1 matrix)
each containing resampled &lsquo;sum&rsquo; values summarizing the weighted sums 
associated with all three  criteria from the 
function <code>silentPairs(mtx)</code>
applied to each bootstrap sample separately. #'
</p>


<h3>Author(s)</h3>

<p>Prof. H. D. Vinod, Economics Dept., Fordham University, NY
</p>


<h3>References</h3>

<p>Vinod, H. D. 'Generalized Correlation and Kernel Causality with 
Applications in Development Economics' in Communications in 
Statistics -Simulation and Computation, 2015, 
<a href="https://doi.org/10.1080/03610918.2015.1122048">doi:10.1080/03610918.2015.1122048</a>
</p>
<p>Vinod, H. D. and Lopez-de-Lacalle, J. (2009). 'Maximum entropy bootstrap
for time series: The meboot R package.' Journal of Statistical Software,
Vol. 29(5), pp. 1-19.
</p>
<p>Vinod, H. D. Causal Paths and Exogeneity Tests 
in Generalcorr Package for Air Pollution and Monetary Policy 
(June 6, 2017). Available at SSRN: <a href="https://www.ssrn.com/abstract=2982128">https://www.ssrn.com/abstract=2982128</a>
</p>


<h3>See Also</h3>

<p>See Also <code><a href="#topic+silentPairs">silentPairs</a></code>, <code><a href="#topic+bootQuantile">bootQuantile</a></code>,
<code><a href="#topic+bootSign">bootSign</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
options(np.messages = FALSE)
set.seed(34);x=sample(1:10);y=sample(2:11)
bb=bootPairs(cbind(x,y),n999=29)
bootSignPcent(bb,tau=5) #gives success rate in n999 bootstrap sum computations

bb=bootPairs(airquality,n999=999);options(np.messages=FALSE)
bootSignPcent(bb,tau=5)#success rate for signs from n999 bootstraps

data('EuroCrime');options(np.messages=FALSE)
attach(EuroCrime)
bb=bootPairs(cbind(crim,off),n999=29) #col.1= crim causes off 
#hence positive signs are more intuitively meaningful.
#note that n999=29 is too small for real problems, chosen for quickness here.
bootSignPcent(bb,tau=5)#successful signs from n999 bootstraps

## End(Not run)
</code></pre>

<hr>
<h2 id='bootSummary'>Compute usual summary stats of 'sum' indexes from bootPairs output</h2><span id='topic+bootSummary'></span>

<h3>Description</h3>

<p>Begin with the output of bootPairs function, a (n999 by p-1) matrix when
there are p columns of data, <code>bootSummary</code> produces a (6 by p-1) mtx
of summary of bootstrap ouput (Min, 1st Qu,Median, Mean, 3rd Qi.,Max)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bootSummary(out, per100 = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bootSummary_+3A_out">out</code></td>
<td>
<p>output from bootPairs with p-1 columns and n999 rows in input here</p>
</td></tr>
<tr><td><code id="bootSummary_+3A_per100">per100</code></td>
<td>
<p>logical (default per100=TRUE) to change the range of
'sum' to [-100, 100] values which are easier to interpret</p>
</td></tr>
</table>


<h3>Value</h3>

<p>summ summary output from the (n999 by p-1) matrix
output of <code>bootPairs(mtx)</code> 
each containing resampled &lsquo;sum&rsquo; values summarizing the weighted sums 
associated with all three  criteria from the 
function <code>silentPairs(mtx)</code>
applied to each bootstrap sample separately.
</p>


<h3>Author(s)</h3>

<p>Prof. H. D. Vinod, Economics Dept., Fordham University, NY
</p>


<h3>References</h3>

<p>Vinod, H. D. 'Generalized Correlation and Kernel Causality with 
Applications in Development Economics' in Communications in 
Statistics -Simulation and Computation, 2015, 
<a href="https://doi.org/10.1080/03610918.2015.1122048">doi:10.1080/03610918.2015.1122048</a>
</p>
<p>Vinod, H. D. and Lopez-de-Lacalle, J. (2009). 'Maximum entropy bootstrap
for time series: The meboot R package.' Journal of Statistical Software,
Vol. 29(5), pp. 1-19.
</p>
<p>Vinod, H. D. Causal Paths and Exogeneity Tests 
in Generalcorr Package for Air Pollution and Monetary Policy 
(June 6, 2017). Available at SSRN: <a href="https://www.ssrn.com/abstract=2982128">https://www.ssrn.com/abstract=2982128</a>
</p>


<h3>See Also</h3>

<p>See Also <code><a href="#topic+silentPairs">silentPairs</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
options(np.messages = FALSE)
set.seed(34);x=sample(1:10);y=sample(2:11)
bb=bootPairs(cbind(x,y),n999=29)
bootSummary(bb) #gives summary stats for n999 bootstrap sum computations

bb=bootPairs(airquality,n999=999);options(np.messages=FALSE)
bootSummary(bb)#signs for n999 bootstrap sum computations

data('EuroCrime')
attach(EuroCrime)
bb=bootPairs(cbind(crim,off),n999=29) #col.1= crim causes off 
#hence positive signs are more intuitively meaningful.
#note that n999=29 is too small for real problems, chosen for quickness here.
bootSummary(bb)#signs for n999 bootstrap sum computations

## End(Not run)
</code></pre>

<hr>
<h2 id='bootSummary2'>Compute usual summary stats of 'sum' index in (-100, 100) from bootPair2</h2><span id='topic+bootSummary2'></span>

<h3>Description</h3>

<p>The &lsquo;2&rsquo; in the name of the function suggests a second implementation
where exact stochastic dominance, decileVote and momentVote are used.
Begin with the output of bootPairs function, a (n999 by p-1) matrix when
there are p columns of data, <code>bootSummary</code> produces a (6 by p-1) mtx
of summary of bootstrap ouput (Min, 1st Qu,Median, Mean, 3rd Qi.,Max)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bootSummary2(out, per100 = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bootSummary2_+3A_out">out</code></td>
<td>
<p>output from bootPair2 with p-1 columns and n999 rows in input here</p>
</td></tr>
<tr><td><code id="bootSummary2_+3A_per100">per100</code></td>
<td>
<p>logical (default per100=TRUE) to change the range of
'sum' to [-100, 100] values which are easier to interpret</p>
</td></tr>
</table>


<h3>Value</h3>

<p>summ a summary matrix (n999 by p-1) having usual parameters
using the output of <code>bootPair2(mtx)</code> 
Each containing resampled &lsquo;sum&rsquo; values summarizing the weighted sums 
associated with all three  criteria from the 
function <code>silentPair2(mtx)</code>
applied to each bootstrap sample separately.
</p>


<h3>Author(s)</h3>

<p>Prof. H. D. Vinod, Economics Dept., Fordham University, NY
</p>


<h3>References</h3>

<p>Vinod, H. D. 'Generalized Correlation and Kernel Causality with 
Applications in Development Economics' in Communications in 
Statistics -Simulation and Computation, 2015, 
<a href="https://doi.org/10.1080/03610918.2015.1122048">doi:10.1080/03610918.2015.1122048</a>
</p>
<p>Vinod, H. D. and Lopez-de-Lacalle, J. (2009). 'Maximum entropy bootstrap
for time series: The meboot R package.' Journal of Statistical Software,
Vol. 29(5), pp. 1-19.
</p>
<p>Vinod, H. D. Causal Paths and Exogeneity Tests 
in Generalcorr Package for Air Pollution and Monetary Policy 
(June 6, 2017). Available at SSRN: <a href="https://www.ssrn.com/abstract=2982128">https://www.ssrn.com/abstract=2982128</a>
</p>


<h3>See Also</h3>

<p>See Also <code><a href="#topic+silentPairs">silentPairs</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
options(np.messages = FALSE)
set.seed(34);x=sample(1:10);y=sample(2:11)
bb=bootPair2(cbind(x,y),n999=29)
bootSummary2(bb) #gives summary stats for n999 bootstrap sum computations

bb=bootPair2(airquality,n999=999);options(np.messages=FALSE)
bootSummary2(bb)#signs for n999 bootstrap sum computations

data('EuroCrime')
attach(EuroCrime)
bb=bootPair2(cbind(crim,off),n999=29) #col.1= crim causes off 
#hence positive signs are more intuitively meaningful.
#note that n999=29 is too small for real problems, chosen for quickness here.
bootSummary2(bb)#signs for n999 bootstrap sum computations

## End(Not run)
</code></pre>

<hr>
<h2 id='canonRho'>Generalized canonical correlation, estimating alpha, beta, rho.</h2><span id='topic+canonRho'></span>

<h3>Description</h3>

<p>What exactly is generalized? Canonical correlations start with Rij, a
symmetric matrix of Pearson correlation coefficients based on linear
relations. This function starts with a more general non-symmetric R*ij
produced by <code>gmcmtx0()</code> as an input. This is a superior measure
of dependence, allowing for nonlinear dependencies. It generalizes Hotelling's
derivation for the nonlinear case.
This function uses data on two sets of column vectors. LHS set [x1, x2 .. xr]
has r=nLHS number of columns 
with coefficients alpha, and 
the larger RHS set [xr+1, xr+2, .. xp] has nRHS=(p-r) columns and RHS
coefficients beta.  Must arrange the sets so that the larger set
in on RHS with coefficients beta estimated first from an eigenvector
of the problem [A* beta = rho^2 beta], where A* is a partitioning of our
generalized matrix of (non-symmetric) correlation coefficients.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>canonRho(mtx, nLHS = 2, sgn = 1, verbo = FALSE, ridg = c(0, 0))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="canonRho_+3A_mtx">mtx</code></td>
<td>
<p>Input matrix of generalized correlation coefficients R*</p>
</td></tr>
<tr><td><code id="canonRho_+3A_nlhs">nLHS</code></td>
<td>
<p>number of columns in the LHS set, default=2</p>
</td></tr>
<tr><td><code id="canonRho_+3A_sgn">sgn</code></td>
<td>
<p>preferred sign of coefficients default=1 for positive, 
use sgn= -1 if prior knowledge suggests that negative signs of 
coefficients are more realistic</p>
</td></tr>
<tr><td><code id="canonRho_+3A_verbo">verbo</code></td>
<td>
<p>logical, verbo=FALSE default means do not print results</p>
</td></tr>
<tr><td><code id="canonRho_+3A_ridg">ridg</code></td>
<td>
<p>two regularization constants added 
before computing matrix inverses of S11 and S22, respectively, with
default=c(0,0). Some suggest ridg=c(0.01,0.01) for stable results</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>A</code></td>
<td>
<p>eigenvalue computing matrix for Generalized canonical correlations</p>
</td></tr>
<tr><td><code>rho</code></td>
<td>
<p>Generalized canonical correlation coefficient</p>
</td></tr>
<tr><td><code>bet</code></td>
<td>
<p>RHS coefficient vector</p>
</td></tr>
<tr><td><code>alp</code></td>
<td>
<p>LHS coefficient vector</p>
</td></tr>
</table>


<h3>Note</h3>

<p>This function calls <code><a href="#topic+kern">kern</a></code>,
</p>


<h3>Author(s)</h3>

<p>Prof. H. D. Vinod, Economics Dept., Fordham University, NY.
</p>


<h3>References</h3>

<p>Vinod, H. D. 'Matrix Algebra Topics in Statistics and Economics
Using R', Chapter 4 in 'Handbook of Statistics: Computational Statistics
with R', Vol.32, co-editors: M. B. Rao and C.R. Rao. New York:
North Holland, Elsevier Science Publishers, 2014, pp. 143-176.
</p>
<p>Vinod, H. D. 'Canonical ridge and econometrics of joint production,'
Journal of Econometrics, vol. 4, 147&ndash;166.
</p>
<p>Vinod, H. D. 'New exogeneity tests and causal paths,'
Chapter 2 in 'Handbook of Statistics: Conceptual Econometrics 
Using R', Vol.32, co-editors: H. D. Vinod and C.R. Rao. New York:
North Holland, Elsevier Science Publishers, 2019, pp. 33-64.
</p>


<h3>See Also</h3>

<p>See  <code><a href="#topic+gmcmtx0">gmcmtx0</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
set.seed(99)
mtx2=matrix(sample(1:25),nrow=5)
g1=gmcmtx0(mtx2)
canonRho(g1,verbo=TRUE)

## End(Not run)#' 
</code></pre>

<hr>
<h2 id='causeAllPair'>All Pair Version Kernel (block) causality summary paths from three criteria</h2><span id='topic+causeAllPair'></span>

<h3>Description</h3>

<p>Allowing input matrix of control variables, this function produces 
a 5 column matrix
summarizing the results where the estimated signs of
stochastic dominance order values, (+1, 0, -1), are weighted by 
<code>wt=c(1.2,1.1, 1.05, 1)</code> to
compute an overall result for all orders of stochastic dominance by 
a weighted sum for
the criteria Cr1 and Cr2 and added to the Cr3 estimate as: (+1, 0, -1).
The final range for the unanimity of sign index is [&ndash;100, 100].
</p>


<h3>Usage</h3>

<pre><code class='language-R'>causeAllPair(
  mtx,
  nam = colnames(mtx),
  blksiz = 10,
  ctrl = 0,
  dig = 6,
  wt = c(1.2, 1.1, 1.05, 1),
  sumwt = 4
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="causeAllPair_+3A_mtx">mtx</code></td>
<td>
<p>The data matrix with many columns, We consider causal paths
among all
possible pairs of mtx columns.</p>
</td></tr>
<tr><td><code id="causeAllPair_+3A_nam">nam</code></td>
<td>
<p>vector of column names for <code>mtx</code>. Default: colnames(mtx)</p>
</td></tr>
<tr><td><code id="causeAllPair_+3A_blksiz">blksiz</code></td>
<td>
<p>block size, default=10, if chosen blksiz &gt;n, where n=rows in matrix
then blksiz=n. That is, no blocking is done</p>
</td></tr>
<tr><td><code id="causeAllPair_+3A_ctrl">ctrl</code></td>
<td>
<p>data matrix for designated control variable(s) outside causal paths</p>
</td></tr>
<tr><td><code id="causeAllPair_+3A_dig">dig</code></td>
<td>
<p>Number of digits for reporting (default <code>dig</code>=6).</p>
</td></tr>
<tr><td><code id="causeAllPair_+3A_wt">wt</code></td>
<td>
<p>Allows user to choose a vector of four alternative weights for SD1 to SD4.</p>
</td></tr>
<tr><td><code id="causeAllPair_+3A_sumwt">sumwt</code></td>
<td>
<p> Sum of weights can be changed here =4(default).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The reason for slightly declining weights on the signs from
SD1 to SD4 stochastic dominance orders is simply their
slightly increasing sampling
unreliability due to higher order trapezoidal approximations of
integrals of densities involved in definitions of SD1 to SD4.
The summary results for all
three criteria are reported in one matrix called <code>out</code>:
</p>


<h3>Value</h3>

<p>If there are p columns in the input matrix, x1, x2, .., xp, say,
there are choose(p,2) or  [p*(p-1)/2] possible pairs and as many causal paths.
This function returns
a matrix of p*(p-1)/2 rows and 5 columns entitled: 
&ldquo;cause&quot;, &ldquo;response&quot;, &ldquo;strength&quot;, &ldquo;corr.&quot; and &ldquo;p-value&quot;, respectively
with self-explanatory titles. The first two columns have names of variables
x1 or x(1+j), depending on which is the cause. The &lsquo;strength&rsquo; column
has absolute value of summary index in range [0,100]  
providing summary of causal results
based on preponderance of evidence from criteria  Cr1 to Cr3 
from four orders of stochastic dominance, etc.  
The fourth column &lsquo;corr.&rsquo; reports the Pearson correlation coefficient while
the fifth column has the p-value for testing the null of zero Pearson coeff.
This function merely calls <code>causeSumNoP</code> repeatedly to include all pairs.
The background function <code>siPairsBlk</code> allows for control variables.
The output of this function can be sent to &lsquo;xtable&rsquo; for a nice Latex table.
</p>


<h3>Note</h3>

<p>The European Crime data has all three criteria correctly suggesting that
high crime rate kernel causes the deployment of a large number of police officers.
Since Cr1 to Cr3 near unanimously suggest &lsquo;crim&rsquo; as the cause of &lsquo;off&rsquo;, 
strength index 100 suggests unanimity. 
<code>attach(EuroCrime); causeSummary(cbind(crim,off))</code>
</p>


<h3>Author(s)</h3>

<p>Prof. H. D. Vinod, Economics Dept., Fordham University, NY.
</p>


<h3>References</h3>

<p>Vinod, H. D. 'Generalized Correlation and Kernel Causality with
Applications in Development Economics' in Communications in
Statistics -Simulation and Computation, 2015,
<a href="https://doi.org/10.1080/03610918.2015.1122048">doi:10.1080/03610918.2015.1122048</a>
</p>
<p>Vinod, H. D. 'New exogeneity tests and causal paths,'
Chapter 2 in 'Handbook of Statistics: Conceptual Econometrics 
Using R', Vol.32, co-editors: H. D. Vinod and C.R. Rao. New York:
North Holland, Elsevier Science Publishers, 2019, pp. 33-64.
</p>
<p>Vinod, H. D. Causal Paths and Exogeneity Tests 
in Generalcorr Package for Air Pollution and Monetary Policy 
(June 6, 2017). Available at SSRN: 
<a href="https://www.ssrn.com/abstract=2982128">https://www.ssrn.com/abstract=2982128</a>
</p>


<h3>See Also</h3>

<p>See  <code><a href="#topic+bootPairs">bootPairs</a></code>,  <code><a href="#topic+causeSummBlk">causeSummBlk</a></code>
</p>
<p>See  <code><a href="#topic+someCPairs">someCPairs</a></code>
</p>
<p><code><a href="#topic+siPairsBlk">siPairsBlk</a></code>, <code><a href="#topic+causeSummary">causeSummary</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

## Not run: 
mtx=data.frame(mtcars[,1:3]) #make sure columns of mtx have names
ctrl=data.frame(mtcars[,4:5])
 causeAllPair(mtx=mtx,ctrl=ctrl)

## End(Not run)

options(np.messages=FALSE)
set.seed(234)
z=runif(10,2,11)# z is independently created
x=sample(1:10)+z/10 #x is somewhat indep and affected by z
y=1+2*x+3*z+rnorm(10)
w=runif(10)
x2=x;x2[4]=NA;y2=y;y2[8]=NA;w2=w;w2[4]=NA
causeAllPair(mtx=cbind(x2,y2), ctrl=cbind(z,w2))


</code></pre>

<hr>
<h2 id='causeSum2Blk'>Block Version 2: Kernel causality summary of causal paths from three criteria</h2><span id='topic+causeSum2Blk'></span>

<h3>Description</h3>

<p>The &lsquo;2&rsquo; in the name of the function suggests a second implementation
where exact stochastic dominance, &lsquo;decileVote&rsquo; and &lsquo;momentVote&rsquo; functions are used,
Block version allows a new bandwidth (chosen by the np package)
while fitting kernel regressions for each block of data. This may
not be appropriate in all situations.  Block size is flexible. 
The function develops a unanimity index regarding which regression
flip, (y on xi) or (xi on y) is the best. The &ldquo;cause&rdquo; is 
always on the right-hand side of a regression equation, and
the superior flip gives the correct sign. The summary of all signs determines the
causal direction and unanimity index among three criteria. This is
a block version of <code>causeSummary2()</code>.
While allowing the researcher to keep some variables as controls,
or outside the scope of causal path determination 
(e.g., age or latitude)  this function produces detailed causal path information 
in a 5 column matrix identifying the names of variables,
causal path directions, path strengths re-scaled to be in the 
range [&ndash;100, 100], (table reports absolute values of the strength)
plus Pearson correlation and its p-value.
</p>
<p>The algorithm determines causal path directions from the sign
of the strength index and strength index values by comparing 
three aspects of flipped kernel regressions: 
[x1 on (x2, x3, .. xp)] and its flipped version [x2 on (x1, x3, .. xp)]
We compare (i) formal exogeneity test criterion, (ii) absolute residuals, and
(iii) R-squares of the flipped regressions implying three criteria Cr1, to Cr3.
The criteria are quantified by new methods using four orders
of stochastic dominance, SD1 to SD4. See Vinod (2021) two SSRN papers.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>causeSum2Blk(mtx, nam = colnames(mtx), blksiz = 10, ctrl = 0, dig = 6)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="causeSum2Blk_+3A_mtx">mtx</code></td>
<td>
<p>The data matrix with many columns, y the first column 
is a fixed target, and then it is
paired with all other columns, one by one, and still called x for
flipping.</p>
</td></tr>
<tr><td><code id="causeSum2Blk_+3A_nam">nam</code></td>
<td>
<p>vector of column names for <code>mtx</code>. Default: colnames(mtx)</p>
</td></tr>
<tr><td><code id="causeSum2Blk_+3A_blksiz">blksiz</code></td>
<td>
<p>block size, default=10, if chosen blksiz &gt;n, where n=rows 
in the matrix then blksiz=n. That is, no blocking is done</p>
</td></tr>
<tr><td><code id="causeSum2Blk_+3A_ctrl">ctrl</code></td>
<td>
<p>data matrix for designated control variable(s) outside causal paths</p>
</td></tr>
<tr><td><code id="causeSum2Blk_+3A_dig">dig</code></td>
<td>
<p>The number of digits for reporting (default <code>dig</code>=6).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>If there are p columns in the input matrix, x1, x2, .., xp, say,
and if we keep x1 as a common member of all causal-direction-pairs
(x1, x(1+j)) for (j=1, 2, .., p-1) which can be flipped. That is, either x1 is
the cause or x(1+j) is the cause in a chosen pair.
The control
variables are not flipped. The printed output of this function
reports the results for p-1 pairs indicating which variable
(by name) causes which other variable (also by name).
It also prints the strength or signed summary strength index in 
the range [-100,100]. 
A positive sign of the strength index means x1 kernel causes x(1+j),
whereas negative strength index means x(1+j) kernel causes x1. The function 
also prints Pearson correlation and its p-value. This function also returns
a matrix of p-1 rows and 5 columns entitled: 
&ldquo;cause&quot;, &ldquo;response&quot;, &ldquo;strength&quot;, &ldquo;corr.&quot; and &ldquo;p-value&quot;, respectively
with self-explanatory titles. The first two columns have names of variables
x1 or x(1+j), depending on which is the cause. The &lsquo;strength&rsquo; column
has an absolute value of the summary index in the range [0,100],  
providing a summary of causal results
based on the preponderance of evidence from Cr1 to Cr3 from deciles, moments,
from four orders of stochastic dominance.  
The order of input columns in &quot;mtx&quot; matters.
The fourth column, &lsquo;corr.&rsquo;, reports the Pearson correlation coefficient, while
the fifth column has the p-value for testing the null of zero Pearson coefficient.
This function calls  <code>siPairsBlk</code>, allowing for control variables.
The output of this function can be sent to &lsquo;xtable&rsquo; for a nice Latex table.
</p>


<h3>Note</h3>

<p>The European Crime data has all three criteria correctly suggesting that
high crime rate kernel causes the deployment of a large number of police officers.
If Cr1 to Cr3 near-unanimously suggest &lsquo;crim&rsquo; as the cause of &lsquo;off&rsquo;, 
strength index would be near 100 suggesting unanimity. 
<code>attach(EuroCrime); causeSum2Blk(cbind(crim,off))</code>
</p>


<h3>Author(s)</h3>

<p>Prof. H. D. Vinod, Economics Dept., Fordham University, NY.
</p>


<h3>References</h3>

<p>Vinod, H. D. 'Generalized Correlation and Kernel Causality with
Applications in Development Economics' in Communications in
Statistics -Simulation and Computation, 2015,
<a href="https://doi.org/10.1080/03610918.2015.1122048">doi:10.1080/03610918.2015.1122048</a>
</p>
<p>Vinod, H. D. 'New exogeneity tests and causal paths,'
Chapter 2 in 'Handbook of Statistics: Conceptual Econometrics 
Using R', Vol.32, co-editors: H. D. Vinod and C.R. Rao. New York:
North Holland, Elsevier Science Publishers, 2019, pp. 33-64.
</p>
<p>Vinod, H. D. Causal Paths and Exogeneity Tests 
in Generalcorr Package for Air Pollution and Monetary Policy 
(June 6, 2017). Available at SSRN: 
<a href="https://www.ssrn.com/abstract=2982128">https://www.ssrn.com/abstract=2982128</a>
</p>
<p>Vinod, Hrishikesh D., R Package GeneralCorr 
Functions for Portfolio Choice 
(November 11, 2021). Available at SSRN: 
https://ssrn.com/abstract=3961683
</p>
<p>Vinod, Hrishikesh D., Stochastic Dominance 
Without Tears (January 26, 2021). Available at 
SSRN: https://ssrn.com/abstract=3773309
</p>


<h3>See Also</h3>

<p>See  <code><a href="#topic+bootPairs">bootPairs</a></code>,  <code><a href="#topic+causeSummary">causeSummary</a></code> has
an older version of this function.
</p>
<p>See  <code><a href="#topic+someCPairs">someCPairs</a></code>
</p>
<p><code><a href="#topic+siPair2Blk">siPair2Blk</a></code>, <code><a href="#topic+causeSummary2">causeSummary2</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
mtx=as.matrix(mtcars[,1:3])
ctrl=as.matrix(mtcars[,4:5])
causeSum2Blk(mtx,ctrl,nam=colnames(mtx))

## End(Not run)


</code></pre>

<hr>
<h2 id='causeSum2Panel'>Kernel regressions based causal paths in Panel Data.</h2><span id='topic+causeSum2Panel'></span>

<h3>Description</h3>

<p>The algorithm of this function uses an internal function
fminmax=function(x)min(x)==max(x).
The subsets mtx2 of the original data da for a specific time or space
can become degenerate if the columns of mtx2 have no variability.
The apply function of R is applied to the columns of mtx2 as follows.
&quot;ap1=apply(mtx2,2,fminmax).&quot; Now, &quot;sumap1=sum(ap1)&quot; counts how many
columns of the data matrix are degenerate.  We have a degeneracy
problem only if sumap1 is &gt;1 or =1. For example, the panel consists
of data on 50 United States and 20 years. Now, consumer price index
(cpi) data may be common for all states. That is, the min(cpi)
equals max(cpi) for all states. Then, the variance of cpi is zero,
and we have degeneracy. When this happens, the regressor cpi should
not be involved in determining causal paths.
We identify degeneracy using &quot;fminmax=function(x)min(x)==max(x)&quot;
</p>


<h3>Usage</h3>

<pre><code class='language-R'>causeSum2Panel(
  da,
  fn = causeSummary2NoP,
  rowfnout,
  colfnout,
  fnoutNames,
  namXs,
  namXt,
  namXy,
  namXc = 0,
  namXjmtx,
  chosenTimes = NULL,
  chosenSpaces = NULL,
  ylag = 0,
  verbo = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="causeSum2Panel_+3A_da">da</code></td>
<td>
<p>panel dat having a named column for space and time</p>
</td></tr>
<tr><td><code id="causeSum2Panel_+3A_fn">fn</code></td>
<td>
<p>an R function causeSummary2NoP(mtx)</p>
</td></tr>
<tr><td><code id="causeSum2Panel_+3A_rowfnout">rowfnout</code></td>
<td>
<p>the number of rows output by fn</p>
</td></tr>
<tr><td><code id="causeSum2Panel_+3A_colfnout">colfnout</code></td>
<td>
<p>the number of columns output by fn</p>
</td></tr>
<tr><td><code id="causeSum2Panel_+3A_fnoutnames">fnoutNames</code></td>
<td>
<p>the column names of output by fn, for example,
fnoutNames=c(&quot;cause&quot;,&quot;effect&quot;,&quot;strength&quot;,&quot;r&quot;,&quot;p-val&quot;)</p>
</td></tr>
<tr><td><code id="causeSum2Panel_+3A_namxs">namXs</code></td>
<td>
<p>title of the column in da having the space variable</p>
</td></tr>
<tr><td><code id="causeSum2Panel_+3A_namxt">namXt</code></td>
<td>
<p>title of the column in da having the time variable</p>
</td></tr>
<tr><td><code id="causeSum2Panel_+3A_namxy">namXy</code></td>
<td>
<p>title of the column in da having the dependent y variable</p>
</td></tr>
<tr><td><code id="causeSum2Panel_+3A_namxc">namXc</code></td>
<td>
<p>title(s) of the column(s) in da 
having control variable(s), default=0 means none specified</p>
</td></tr>
<tr><td><code id="causeSum2Panel_+3A_namxjmtx">namXjmtx</code></td>
<td>
<p>title(s) of the column(s) in da having regressor(s)</p>
</td></tr>
<tr><td><code id="causeSum2Panel_+3A_chosentimes">chosenTimes</code></td>
<td>
<p>subset of values of time variable chosen for quick
results, There are NchosenTimes values chosen in the subset.
default=NULL means all time identifiers in the data are included.</p>
</td></tr>
<tr><td><code id="causeSum2Panel_+3A_chosenspaces">chosenSpaces</code></td>
<td>
<p>subset of values of space variable chosen for quick
results, There are NchosenSpaces values chosen in the subset.
default=NULL means all space identifiers are included. The degrees
of freedom for Studentized statistic for Granger causality tests 
are df=(NchosenSpaces -1).</p>
</td></tr>
<tr><td><code id="causeSum2Panel_+3A_ylag">ylag</code></td>
<td>
<p>time lag in Granger causality study of time dimension
the default ylag=0 is not really zero. It means ylag=
min(4, round(NchosenTimes/5,0)),
where NchosenTimes is the length of chosenTimes vector</p>
</td></tr>
<tr><td><code id="causeSum2Panel_+3A_verbo">verbo</code></td>
<td>
<p>print detail results along the way, default=FALSE</p>
</td></tr>
</table>


<h3>Details</h3>

<p>We assume that panel data have space (space=individual region)
and time (e.g., year) dimensions. We use upper case
X to denote a common prefix in the panel data.
Xs =name of the space variable, e.g., state or individual.
The range of values for s is 1 to nspace.
Xt =name of the time variable, e.g., year.
The range of values for t is 1 to ntime.
Xy =the dependent variable(s) value at time t in state s.
Since panel data causal analysis can take a long computer time,
we allow the user to choose subsets of time and space values
called chosenTimes and chosenSpaces, respectively.
Various input parameters starting with &quot;nam&quot; specify the names
of variables in the panel study.
</p>
<p>The algorithm calls some function fn(mtx) where mtx is the data matrix,
and fn is causeSummary2NoP(mtx). The causal paths between (y, xj)
pairs of variables in mtx are computed following 3 sophisticated
criteria involving exact stochastic dominance. Type &quot;?causeSummary2&quot;
on the R console to get details (omitted here for brevity).
Panel data consist of a time
series of cross-sections and are also called longitudinal data.
We provide estimates of causal path directions and strengths
for both the time-series and cross-sectional
views of panel data. Since our regressions are kernel type
with no functional forms, fixed effects for time and space
are being suppressed when computing the causality.
</p>


<h3>Value</h3>

<p>The causeSum2Panel(.) produces many output matrices and vectors. 
The first
&quot;outt&quot; gives a 3-dimensional array of panel causal path output focused on 
time series for each space value using fixed space value.
It reports causal path directions, and strengths for (y, xj) pairs.
The second output array, called
&quot;outs&quot;, gives similar 3D panel causal path output focused on 
space cross sections using fixed time value.
The third output matrix called
&quot;outdif&quot; gives causal paths using Granger causality for each
pair (y, xj). They are not causal strengths but differences 
between Rsquare values of two flipped kernel regressions.
The summary of Granger causality answer is an output matrix called
grangerAns (first row average of differences in R-squares and
second row has its test statistic with degrees of freedom n-1),
and grangerStat for related t-statistic for formal inference.
based on column means and variances of &quot;outdif&quot;. This function
also produces a matrix summarizing &quot;outt&quot; and &quot;outs&quot; into two-dimensional
matrices reporting averages of signed strengths as  &quot;strentime&quot;
and &quot;strenspace&quot;, Also, &quot;pearsontime&quot; reports the Pearson
correlation coefficients for various time values and their average in the
last column. It determines the overall direction of
the causal relation between y and xj.
For example, a negative average correlation means y and xj are negatively
correlated (xj goes up, y goes down). Similarly, &quot;pearsonspace&quot;
summarizes &quot;outs&quot; correlations.
</p>


<h3>Note</h3>

<p>The function prints to the screen some summaries of the three
output matrices. It reports how often a variable is a cause in
various pairs as time series or as cross sections. It also reports the
average strengths of causal paths for &quot;outt&quot; and &quot;outs&quot; matrices.
We compute the difference between two R-square values to find which
causal direction is more plausible.  This involves kernel regressions
of y on its own lags and lags of a regressor. Unlike the usual Granger
causality we estimate better-fitting nonlinear kernel regressions.
If the averages in &quot;outdif&quot; matrix are negative, the Granger causal
paths go from y to xj. This may be unexpected when the model assumes
that y depends on x1 to xp, that is, the causal paths go from xj to y.
In studying the causal pairs, the function creates mixtures of
names y and xj. Character vectors containing the mixed names are
are column names or row names depending on the context. For example,
the output matrix grangerAns column names help identify the relevant
regressor name. The first row of the grangerAns matrix has column averages
of outdiff matrix to help get an overall estimate of the Granger-causal paths.
The second row of the grangerAns has the Studentized test
statistic for formal testing of the significance of Granger causal paths.
Collecting the results for the time dimension strengths with
suitable sign (negative strength means cause reversal xj-&gt;y) is output
named strentime.  The corresponding Pearson
correlations as an output is named pearsontime.
Collecting the results for the space dimension strengths with
suitable sign (negative strength means cause reversal xj-&gt;y) is output
named strenspace.  The corresponding Pearson
correlations are named pearsonspace. A grand summary of average
strengths and correlations is output matrix named grandsum.
It is intended to provide an overall picture of causal paths in Panel
data. These paths should not be confused with Granger causal paths which
always involve time lags and causes are presumed to precede effects in time.
</p>


<h3>Author(s)</h3>

<p>Prof. H. D. Vinod, Economics Dept., Fordham University, NY.
</p>


<h3>References</h3>

<p>Vinod, H. D. 'Generalized Correlation and Kernel Causality with
Applications in Development Economics' in Communications in
Statistics -Simulation and Computation, 2015,
<a href="https://doi.org/10.1080/03610918.2015.1122048">doi:10.1080/03610918.2015.1122048</a>
</p>
<p>Vinod, H. D. 'New exogeneity tests and causal paths,'
Chapter 2 in 'Handbook of Statistics: Conceptual Econometrics 
Using R', Vol.32, co-editors: H. D. Vinod and C.R. Rao. New York:
North Holland, Elsevier Science Publishers, 2019, pp. 33-64.
</p>
<p>Vinod, H. D. Causal Paths and Exogeneity Tests 
in Generalcorr Package for Air Pollution and Monetary Policy 
(June 6, 2017). Available at SSRN: 
<a href="https://www.ssrn.com/abstract=2982128">https://www.ssrn.com/abstract=2982128</a>
</p>
<p>Vinod, Hrishikesh D., R Package GeneralCorr 
Functions for Portfolio Choice 
(November 11, 2021). Available at SSRN: 
https://ssrn.com/abstract=3961683
</p>
<p>Vinod, Hrishikesh D., Stochastic Dominance 
Without Tears (January 26, 2021). Available at 
SSRN: https://ssrn.com/abstract=3773309
</p>


<h3>See Also</h3>

<p>See  <code><a href="#topic+causeSummary2">causeSummary2</a></code>
</p>
<p>See  <code><a href="#topic+causeSummary">causeSummary</a></code> is subject to trapezoidal approximation.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

## Not run: 
library(plm);data(Grunfeld)
options(np.messages=FALSE)
namXs="firm"
print("initial values identifying the space variable")
head(da[,namXs],3)
print(str(da[,namXs]))
chosenSpaces=(3:10)                        
if(is.numeric(da[,namXs])){
  chosenSpaces=as.numeric(chosenSpaces)}
if(!is.numeric(da[,namXs])){
  chosenSpaces=as.character(chosenSpaces)}

namXt="year"
print("initial values identifying the time variable")
head(da[,namXt],3)
print(str(da[,namXt]))
chosenTimes=1940:1949
if(is.numeric(da[,namXt])){
  chosenTimes=as.numeric(chosenTimes)}
if(!is.numeric(da[,namXt])){
  chosenTimes=as.character(chosenTimes)}

namXy="inv"
namXc=0
namXjmtx=c("value","capital")
p=length(namXjmtx)
fn=causeSummary2NoP
fnout=matrix(NA,nrow=p,ncol=5)
fnoutNames=c("cause","effect","strength","r","p-val")
causeSum2Panel(da, fn=causeSummary2NoP,
               rowfnout=p, colfnout=5, 
               fnoutNames=c("cause","effect","strength","r","p-val"),
               namXs=namXs,
               namXt=namXt,
               namXy=namXy,
               namXc=namXc,
               namXjmtx=namXjmtx,
               chosenTimes=chosenTimes,
               chosenSpaces=chosenSpaces,
               verbo=FALSE)

## End(Not run)


</code></pre>

<hr>
<h2 id='causeSummary'>Kernel causality summary of evidence for causal paths from three criteria</h2><span id='topic+causeSummary'></span>

<h3>Description</h3>

<p>While allowing the researcher to keep some variables as controls,
or outside the scope of causal path determination 
(e.g., age or latitude)  this function produces detailed causal path information 
in a 5 column matrix identifying the names of variables,
causal path directions, path strengths re-scaled to be in the 
range [&ndash;100, 100], (table reports absolute values of the strength)
plus Pearson correlation and its p-value.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>causeSummary(
  mtx,
  nam = colnames(mtx),
  ctrl = 0,
  dig = 6,
  wt = c(1.2, 1.1, 1.05, 1),
  sumwt = 4
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="causeSummary_+3A_mtx">mtx</code></td>
<td>
<p>The data matrix with many columns, y the first column 
is fixed and then 
paired with all columns, one by one, and still called x for the 
purpose of flipping.</p>
</td></tr>
<tr><td><code id="causeSummary_+3A_nam">nam</code></td>
<td>
<p>vector of column names for <code>mtx</code>. Default: colnames(mtx)</p>
</td></tr>
<tr><td><code id="causeSummary_+3A_ctrl">ctrl</code></td>
<td>
<p>data matrix for designated control variable(s) outside causal paths</p>
</td></tr>
<tr><td><code id="causeSummary_+3A_dig">dig</code></td>
<td>
<p>Number of digits for reporting (default <code>dig</code>=6).</p>
</td></tr>
<tr><td><code id="causeSummary_+3A_wt">wt</code></td>
<td>
<p>Allows user to choose a vector of four alternative weights for SD1 to SD4.</p>
</td></tr>
<tr><td><code id="causeSummary_+3A_sumwt">sumwt</code></td>
<td>
<p> Sum of weights can be changed here =4(default).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The algorithm determines causal path directions from the sign
of the strength index and strength index values by comparing 
three aspects of flipped kernel regressions: 
[x1 on (x2, x3, .. xp)] and its flipped version [x2 on (x1, x3, .. xp)]
We compare (i) formal exogeneity test criterion, (ii) absolute residuals, and
(iii) R-squares of the flipped regressions implying three criteria Cr1, to Cr3.
The criteria are quantified by sophisticated methods using four orders
of stochastic dominance, SD1 to SD4. We assume slightly declining weights on 
causal path signs because known reliability ranking. SD1 is better than SD2,
better than SD3, better than SD4. The user can optionally change our weights.
</p>


<h3>Value</h3>

<p>If there are p columns in the input matrix, x1, x2, .., xp, say,
and if we keep x1 as a common member of all causal direction pairs
(x1, x(1+j)) for (j=1, 2, .., p-1) which can be flipped. That is, either x1 is
the cause or x(1+j) is the cause in a chosen pair.
The control
variables are not flipped. The printed output of this function
reports the results for p-1 pairs indicating which variable
(by name) causes which another variable (also by name).
It also prints a signed summary strength index in the range [-100,100]. 
A positive sign of the strength index means x1 kernel causes x(1+j),
whereas negative strength index means x(1+j) kernel causes x1. The function 
also prints Pearson correlation and its p-value. In short, function returns
a matrix of p-1 rows and 5 columns entitled: 
&ldquo;cause&quot;, &ldquo;response&quot;, &ldquo;strength&quot;, &ldquo;corr.&quot; and &ldquo;p-value&quot;, respectively
with self-explanatory titles. The first two columns have names of variables
x1 or x(1+j), depending on which is the cause. The &lsquo;strength&rsquo; column
reports the absolute value of summary index, now in the range [0,100]  
providing summary of causal results
based on preponderance of evidence from Cr1 to Cr3 
from four orders of stochastic dominance, etc.  The order of input columns matters.
The fourth column &lsquo;corr.&rsquo; reports the Pearson correlation coefficient while
the fifth column has the p-value for testing the null of zero Pearson coeff.
This function calls  <code>silentPairs</code> allowing for control variables.
The output of this function can be sent to &lsquo;xtable&rsquo; for a nice Latex table.
</p>


<h3>Note</h3>

<p>The European Crime data has all three criteria correctly suggesting that
high crime rate kernel causes the deployment of a large number of police officers.
Since Cr1 to Cr3 near unanimously suggest &lsquo;crim&rsquo; as the cause of &lsquo;off&rsquo;, 
strength index 100 suggests unanimity. In portfolio
applications of stochastic dominance one wants higher returns.  Here we are
comparing two probability distributions of absolute residuals for two
flipped models. We choose that flip which has smaller absolute residuals
or better fit.
<code>attach(EuroCrime); causeSummary(cbind(crim,off))</code>
</p>


<h3>Author(s)</h3>

<p>Prof. H. D. Vinod, Economics Dept., Fordham University, NY.
</p>


<h3>References</h3>

<p>Vinod, H. D. 'Generalized Correlation and Kernel Causality with
Applications in Development Economics' in Communications in
Statistics -Simulation and Computation, 2015,
<a href="https://doi.org/10.1080/03610918.2015.1122048">doi:10.1080/03610918.2015.1122048</a>
</p>
<p>Vinod, H. D. 'New exogeneity tests and causal paths,'
Chapter 2 in 'Handbook of Statistics: Conceptual Econometrics 
Using R', Vol.32, co-editors: H. D. Vinod and C.R. Rao. New York:
North Holland, Elsevier Science Publishers, 2019, pp. 33-64.
</p>
<p>Vinod, H. D. Causal Paths and Exogeneity Tests 
in Generalcorr Package for Air Pollution and Monetary Policy 
(June 6, 2017). Available at SSRN: 
<a href="https://www.ssrn.com/abstract=2982128">https://www.ssrn.com/abstract=2982128</a>
</p>


<h3>See Also</h3>

<p>See  <code><a href="#topic+bootPairs">bootPairs</a></code>,  <code><a href="#topic+causeSummary0">causeSummary0</a></code> has
an older version of this function.
</p>
<p>See  <code><a href="#topic+someCPairs">someCPairs</a></code>
</p>
<p><code><a href="#topic+silentPairs">silentPairs</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

## Not run: 
mtx=as.matrix(mtcars[,1:3])
ctrl=as.matrix(mtcars[,4:5])
 causeSummary(mtx,ctrl,nam=colnames(mtx))

## End(Not run)

options(np.messages=FALSE)
set.seed(234)
z=runif(10,2,11)# z is independently created
x=sample(1:10)+z/10 #x is somewhat indep and affected by z
y=1+2*x+3*z+rnorm(10)
w=runif(10)
x2=x;x2[4]=NA;y2=y;y2[8]=NA;w2=w;w2[4]=NA
causeSummary(mtx=cbind(x2,y2), ctrl=cbind(z,w2))


</code></pre>

<hr>
<h2 id='causeSummary0'>Older Kernel causality summary of evidence for causal paths from three criteria</h2><span id='topic+causeSummary0'></span>

<h3>Description</h3>

<p>Allowing input matrix of control variables, this function produces 
a 5 column matrix
summarizing the results where the estimated signs of
stochastic dominance order values, (+1, 0, -1), are weighted by 
<code>wt=c(1.2,1.1, 1.05, 1)</code> to
compute an overall result for all orders of stochastic dominance by 
a weighted sum for
the criteria Cr1 and Cr2 and added to the Cr3 estimate as: (+1, 0, -1).
The final range for the unanimity of sign index is [&ndash;100, 100].
</p>


<h3>Usage</h3>

<pre><code class='language-R'>causeSummary0(
  mtx,
  nam = colnames(mtx),
  ctrl = 0,
  dig = 6,
  wt = c(1.2, 1.1, 1.05, 1),
  sumwt = 4
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="causeSummary0_+3A_mtx">mtx</code></td>
<td>
<p>The data matrix with many columns, y the first column 
is fixed and then 
paired with all columns, one by one, and still called x for the 
purpose of flipping.</p>
</td></tr>
<tr><td><code id="causeSummary0_+3A_nam">nam</code></td>
<td>
<p>vector of column names for <code>mtx</code>. Default: colnames(mtx)</p>
</td></tr>
<tr><td><code id="causeSummary0_+3A_ctrl">ctrl</code></td>
<td>
<p>data matrix for designated control variable(s) outside causal paths</p>
</td></tr>
<tr><td><code id="causeSummary0_+3A_dig">dig</code></td>
<td>
<p>Number of digits for reporting (default <code>dig</code>=6).</p>
</td></tr>
<tr><td><code id="causeSummary0_+3A_wt">wt</code></td>
<td>
<p>Allows user to choose a vector of four alternative weights for SD1 to SD4.</p>
</td></tr>
<tr><td><code id="causeSummary0_+3A_sumwt">sumwt</code></td>
<td>
<p> Sum of weights can be changed here =4(default).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The reason for slightly declining weights on the signs from
SD1 to SD4 is simply that the local mean comparisons 
implicit in SD1 are known to be
more reliable than local variance implicit in SD2, local skewness implicit in
SD3 and local kurtosis implicit in SD4. The reason for 
slightly declining sampling
unreliability of higher moments is simply that SD4 involves fourth power
of the deviations from the mean and SD3 involves 3rd power, etc.
The summary results for all
three criteria are reported in one matrix called <code>out</code>:
</p>


<h3>Value</h3>

<p>If there are p columns in the input matrix, x1, x2, .., xp, say,
and if we keep x1 as a common member of all causal direction pairs
(x1, x(1+j)) for (j=1, 2, .., p-1) which can be flipped. That is, either x1 is
the cause or x(1+j) is the cause in a chosen pair.
The control
variables are not flipped. The printed output of this function
reports the results for p-1 pairs indicating which variable
(by name) causes which other variable (also by name).
It also prints strength or signed summary strength index in range [-100,100]. 
A positive sign of the strength index means x1 kernel causes x(1+j),
whereas negative strength index means x(1+j) kernel causes x1. The function 
also prints Pearson correlation and its p-value. This function also returns
a matrix of p-1 rows and 5 columns entitled: 
&ldquo;cause&quot;, &ldquo;response&quot;, &ldquo;strength&quot;, &ldquo;corr.&quot; and &ldquo;p-value&quot;, respectively
with self-explanatory titles. The first two columns have names of variables
x1 or x(1+j), depending on which is the cause. The &lsquo;strength&rsquo; column
has absolute value of summary index in range [0,100]  
providing summary of causal results
based on preponderance of evidence from Cr1 to Cr3 
from four orders of stochastic dominance, etc.  The order of input columns matters.
The fourth column &lsquo;corr.&rsquo; reports the Pearson correlation coefficient while
the fifth column has the p-value for testing the null of zero Pearson coeff.
This function calls  <code>silentPairs0</code> 
(the older version) allowing for control variables.
The output of this function can be sent to &lsquo;xtable&rsquo; for a nice Latex table.
</p>


<h3>Note</h3>

<p>The European Crime data has all three criteria correctly suggesting that
high crime rate kernel causes the deployment of a large number of police officers.
Since Cr1 to Cr3 near unanimously suggest &lsquo;crim&rsquo; as the cause of &lsquo;off&rsquo;, 
strength index 100 suggests unanimity. 
<code>attach(EuroCrime); causeSummary0(cbind(crim,off))</code>. Both versions
give identical result for this example. Old version of Cr1 using
gradients was also motivated by the same Hausman-Wu test statistic.
</p>


<h3>Author(s)</h3>

<p>Prof. H. D. Vinod, Economics Dept., Fordham University, NY.
</p>


<h3>References</h3>

<p>Vinod, H. D. 'Generalized Correlation and Kernel Causality with
Applications in Development Economics' in Communications in
Statistics -Simulation and Computation, 2015,
<a href="https://doi.org/10.1080/03610918.2015.1122048">doi:10.1080/03610918.2015.1122048</a>
</p>
<p>Vinod, H. D. Causal Paths and Exogeneity Tests 
in Generalcorr Package for Air Pollution and Monetary Policy 
(June 6, 2017). Available at SSRN: 
<a href="https://www.ssrn.com/abstract=2982128">https://www.ssrn.com/abstract=2982128</a>
</p>


<h3>See Also</h3>

<p>See  <code><a href="#topic+bootPairs">bootPairs</a></code>
</p>
<p>See  <code><a href="#topic+someCPairs">someCPairs</a></code>
</p>
<p><code><a href="#topic+silentPairs">silentPairs</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

## Not run: 
mtx=as.matrix(mtcars[,1:3])
ctrl=as.matrix(mtcars[,4:5])
 causeSummary0(mtx,ctrl,nam=colnames(mtx))

## End(Not run)

options(np.messages=FALSE)
set.seed(234)
z=runif(10,2,11)# z is independently created
x=sample(1:10)+z/10 #x is somewhat indep and affected by z
y=1+2*x+3*z+rnorm(10)
w=runif(10)
x2=x;x2[4]=NA;y2=y;y2[8]=NA;w2=w;w2[4]=NA
causeSummary0(mtx=cbind(x2,y2), ctrl=cbind(z,w2))


</code></pre>

<hr>
<h2 id='causeSummary2'>Kernel causality summary of evidence for causal paths 
from three criteria using new exact stochastic dominance.
The function develops a unanimity index for deciding which
flip (y on xi) or (xi on y) is best. Relevant signs determine the
causal direction and unanimity index among three criteria.
While allowing the researcher to keep some variables as controls,
or outside the scope of causal path determination 
(e.g., age or latitude)  this function produces detailed causal path information 
in a 5 column matrix identifying the names of variables,
causal path directions, path strengths re-scaled to be in the 
range [&ndash;100, 100], (table reports absolute values of the strength)
plus Pearson correlation and its p-value.
The &lsquo;2&rsquo; in the name of the function suggests a second implementation
where exact stochastic dominance, decileVote, and momentVote are used
and where we avoid Anderson's trapezoidal approximation.</h2><span id='topic+causeSummary2'></span>

<h3>Description</h3>

<p>The algorithm determines causal path directions 
from the sign
of the strength index and strength index values by comparing 
three aspects of flipped kernel regressions: 
[x1 on f(x2, x3, .. xp)] and its flipped version [x2 on f(x1, x3, .. xp)]
We compare (i) formal exogeneity test criterion, (ii) absolute residuals, and
(iii) R-squares of the flipped regressions implying three criteria Cr1, to Cr3.
The criteria are quantified by newer exact methods using four orders
of stochastic dominance, SD1 to SD4. See Vinod's (2021) SSRN papers. In portfolio
applications of stochastic dominance, one wants higher values.  Here, we are
comparing two probability distributions of absolute residuals for two
flipped models. We choose that flip, which has smaller absolute residuals
that will have a better fit.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>causeSummary2(mtx, nam = colnames(mtx), ctrl = 0, dig = 6)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="causeSummary2_+3A_mtx">mtx</code></td>
<td>
<p>The data matrix with many columns, y the first column 
is fixed and then 
paired with all columns, one by one, and still called x for the 
purpose of flipping.</p>
</td></tr>
<tr><td><code id="causeSummary2_+3A_nam">nam</code></td>
<td>
<p>vector of column names for <code>mtx</code>. Default: colnames(mtx)</p>
</td></tr>
<tr><td><code id="causeSummary2_+3A_ctrl">ctrl</code></td>
<td>
<p>data matrix for designated control variable(s) outside causal paths</p>
</td></tr>
<tr><td><code id="causeSummary2_+3A_dig">dig</code></td>
<td>
<p>Number of digits for reporting (default <code>dig</code>=6).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>If there are p columns in the input matrix, x1, x2, .., xp, say,
and if we keep x1 as a common member of all causal direction pairs
(x1, x(1+j)) for (j=1, 2, .., p-1) which can be flipped. That is, either x1 is
the cause or x(1+j) is the cause in a chosen pair.
The control
variables are not flipped. The printed output of this function
reports the results for p-1 pairs indicating which variable
(by name) causes which other variable (also by name).
It also prints a signed summary strength index in the range [-100,100]. 
A positive sign of the strength index means x1 kernel causes x(1+j),
whereas a negative strength index means x(1+j) kernel causes x1. The function 
also prints the Pearson correlation and its p-value. In short, function returns
a matrix of p-1 rows and 5 columns entitled: 
&ldquo;cause&quot;, &ldquo;response&quot;, &ldquo;strength&quot;, &ldquo;corr.&quot; and &ldquo;p-value&quot;, respectively
with self-explanatory titles. The first two columns have names of variables
x1 or x(1+j), depending on which is the cause. The &lsquo;strength&rsquo; column
reports the absolute value of the summary index, in the range [0,100],  
providing a summary of causal results
based on the preponderance of evidence from Cr1 to Cr3 
from four orders of stochastic dominance, moments, deciles,
etc.  The order of input columns in mtx matters.
The fourth column, &lsquo;corr.&rsquo; of &lsquo;out&rsquo;, reports the Pearson correlation coefficient.
The fifth column has the p-value for testing the null of zero Pearson coeff.
This function calls  <code>silentPair2</code>, allowing for control variables.
The output of this function can be sent to &lsquo;xtable&rsquo; for a nice Latex table.
</p>


<h3>Note</h3>

<p>The European Crime data has all three criteria correctly suggesting that a
high crime rate kernel causes the deployment of a large number of police officers.
Since Cr1 to Cr3 nearly unanimously suggest &lsquo;crim&rsquo; as the cause of &lsquo;off&rsquo;, 
strength index 100 suggests unanimity among the criteria. 
<code>attach(EuroCrime); causeSummary(cbind(crim,off))</code>
</p>


<h3>Author(s)</h3>

<p>Prof. H. D. Vinod, Economics Dept., Fordham University, NY.
</p>


<h3>References</h3>

<p>Vinod, H. D. 'Generalized Correlation and Kernel Causality with
Applications in Development Economics' in Communications in
Statistics -Simulation and Computation, 2015,
<a href="https://doi.org/10.1080/03610918.2015.1122048">doi:10.1080/03610918.2015.1122048</a>
</p>
<p>Vinod, H. D. 'New exogeneity tests and causal paths,'
Chapter 2 in 'Handbook of Statistics: Conceptual Econometrics 
Using R', Vol.32, co-editors: H. D. Vinod and C.R. Rao. New York:
North Holland, Elsevier Science Publishers, 2019, pp. 33-64.
</p>
<p>Vinod, H. D. Causal Paths and Exogeneity Tests 
in Generalcorr Package for Air Pollution and Monetary Policy 
(June 6, 2017). Available at SSRN: 
<a href="https://www.ssrn.com/abstract=2982128">https://www.ssrn.com/abstract=2982128</a>
</p>
<p>Vinod, Hrishikesh D., R Package GeneralCorr 
Functions for Portfolio Choice 
(November 11, 2021). Available at SSRN: 
https://ssrn.com/abstract=3961683
</p>
<p>Vinod, Hrishikesh D., Stochastic Dominance 
Without Tears (January 26, 2021). Available at 
SSRN: https://ssrn.com/abstract=3773309
</p>


<h3>See Also</h3>

<p>See  <code><a href="#topic+siPair2Blk">siPair2Blk</a></code> for a block version
</p>
<p>See  <code><a href="#topic+causeSummary">causeSummary</a></code> is subject to trapezoidal approximation.
</p>
<p>see <code><a href="#topic+silentPair2">silentPair2</a></code> called by this function.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

## Not run: 
mtx=as.matrix(mtcars[,1:3])
ctrl=as.matrix(mtcars[,4:5])
 causeSummary2(mtx,ctrl,nam=colnames(mtx))

## End(Not run)

options(np.messages=FALSE)
set.seed(234)
z=runif(10,2,11)# z is independently created
x=sample(1:10)+z/10 #x is somewhat indep and affected by z
y=1+2*x+3*z+rnorm(10)
w=runif(10)
x2=x;x2[4]=NA;y2=y;y2[8]=NA;w2=w;w2[4]=NA
causeSummary2(mtx=cbind(x2,y2), ctrl=cbind(z,w2))
 

</code></pre>

<hr>
<h2 id='causeSummary2NoP'>No Print version Kernel causality summary of evidence for causal paths 
from three criteria using new exact stochastic dominance.</h2><span id='topic+causeSummary2NoP'></span>

<h3>Description</h3>

<p>The function develops a unanimity index for deciding which
flip (y on xi) or (xi on y) is best. Relevant signs determine the
causal direction and unanimity index among three criteria.
While allowing the researcher to keep some variables as controls,
or outside the scope of causal path determination 
(e.g., age or latitude)  this function produces detailed causal path information 
in a 5 column matrix identifying the names of variables,
causal path directions, path strengths re-scaled to be in the 
range [&ndash;100, 100], (table reports absolute values of the strength)
plus Pearson correlation and its p-value.
The &lsquo;2&rsquo; in the name of the function suggests a second implementation
where exact stochastic dominance, decileVote, and momentVote are used
and where we avoid Anderson's trapezoidal approximation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>causeSummary2NoP(mtx, nam = colnames(mtx), ctrl = 0, dig = 6)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="causeSummary2NoP_+3A_mtx">mtx</code></td>
<td>
<p>The data matrix with many columns, y the first column 
is fixed and then 
paired with all columns, one by one, and still called x for the 
purpose of flipping.</p>
</td></tr>
<tr><td><code id="causeSummary2NoP_+3A_nam">nam</code></td>
<td>
<p>vector of column names for <code>mtx</code>. Default: colnames(mtx)</p>
</td></tr>
<tr><td><code id="causeSummary2NoP_+3A_ctrl">ctrl</code></td>
<td>
<p>data matrix for designated control variable(s) outside causal paths</p>
</td></tr>
<tr><td><code id="causeSummary2NoP_+3A_dig">dig</code></td>
<td>
<p>Number of digits for reporting (default <code>dig</code>=6).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The algorithm determines causal path directions 
from the sign
of the strength index and strength index values by comparing 
three aspects of flipped kernel regressions: 
[x1 on f(x2, x3, .. xp)] and its flipped version [x2 on f(x1, x3, .. xp)]
We compare (i) formal exogeneity test criterion, (ii) absolute residuals, and
(iii) R-squares of the flipped regressions implying three criteria Cr1, to Cr3.
The criteria are quantified by newer exact methods using four orders
of stochastic dominance, SD1 to SD4. See Vinod's (2021) SSRN papers. In portfolio
applications of stochastic dominance, one wants higher values.  Here, we are
comparing two probability distributions of absolute residuals for two
flipped models. We choose that flip, which has smaller absolute residuals
that will have a better fit.
</p>


<h3>Value</h3>

<p>If there are p columns in the input matrix, x1, x2, .., xp, say,
and if we keep x1 as a common member of all causal direction pairs
(x1, x(1+j)) for (j=1, 2, .., p-1) which can be flipped. That is, either x1 is
the cause or x(1+j) is the cause in a chosen pair.
The control
variables are not flipped. The printed output of this function
reports the results for p-1 pairs indicating which variable
(by name) causes which other variable (also by name).
It also prints a signed summary strength index in the range [-100,100]. 
A positive sign of the strength index means x1 kernel causes x(1+j),
whereas a negative strength index means x(1+j) kernel causes x1. The function 
also prints the Pearson correlation and its p-value. In short, function returns
a matrix of p-1 rows and 5 columns entitled: 
&ldquo;cause&quot;, &ldquo;response&quot;, &ldquo;strength&quot;, &ldquo;corr.&quot; and &ldquo;p-value&quot;, respectively
with self-explanatory titles. The first two columns have names of variables
x1 or x(1+j), depending on which is the cause. The &lsquo;strength&rsquo; column
reports the absolute value of the summary index, in the range [0,100],  
providing a summary of causal results
based on the preponderance of evidence from Cr1 to Cr3 
from four orders of stochastic dominance, moments, deciles,
etc.  The order of input columns in mtx matters.
The fourth column, &lsquo;corr.&rsquo; of &lsquo;out&rsquo;, reports the Pearson correlation coefficient.
The fifth column has the p-value for testing the null of zero Pearson coeff.
This function calls  <code>silentPair2</code>, allowing for control variables.
The output of this function can be sent to &lsquo;xtable&rsquo; for a nice Latex table.
</p>


<h3>Note</h3>

<p>The European Crime data has all three criteria correctly suggesting that a
high crime rate kernel causes the deployment of a large number of police officers.
Since Cr1 to Cr3 nearly unanimously suggest &lsquo;crim&rsquo; as the cause of &lsquo;off&rsquo;, 
strength index 100 suggests unanimity among the criteria. 
<code>attach(EuroCrime); causeSummary(cbind(crim,off))</code>
</p>


<h3>Author(s)</h3>

<p>Prof. H. D. Vinod, Economics Dept., Fordham University, NY.
</p>


<h3>References</h3>

<p>Vinod, H. D. 'Generalized Correlation and Kernel Causality with
Applications in Development Economics' in Communications in
Statistics -Simulation and Computation, 2015,
<a href="https://doi.org/10.1080/03610918.2015.1122048">doi:10.1080/03610918.2015.1122048</a>
</p>
<p>Vinod, H. D. 'New exogeneity tests and causal paths,'
Chapter 2 in 'Handbook of Statistics: Conceptual Econometrics 
Using R', Vol.32, co-editors: H. D. Vinod and C.R. Rao. New York:
North Holland, Elsevier Science Publishers, 2019, pp. 33-64.
</p>
<p>Vinod, H. D. Causal Paths and Exogeneity Tests 
in Generalcorr Package for Air Pollution and Monetary Policy 
(June 6, 2017). Available at SSRN: 
<a href="https://www.ssrn.com/abstract=2982128">https://www.ssrn.com/abstract=2982128</a>
</p>
<p>Vinod, Hrishikesh D., R Package GeneralCorr 
Functions for Portfolio Choice 
(November 11, 2021). Available at SSRN: 
https://ssrn.com/abstract=3961683
</p>
<p>Vinod, Hrishikesh D., Stochastic Dominance 
Without Tears (January 26, 2021). Available at 
SSRN: https://ssrn.com/abstract=3773309
</p>


<h3>See Also</h3>

<p>See  <code><a href="#topic+siPair2Blk">siPair2Blk</a></code> for a block version
</p>
<p>See  <code><a href="#topic+causeSummary">causeSummary</a></code> is subject to trapezoidal approximation.
</p>
<p>see <code><a href="#topic+silentPair2">silentPair2</a></code> called by this function.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

## Not run: 
mtx=as.matrix(mtcars[,1:3])
ctrl=as.matrix(mtcars[,4:5])
 causeSummary2(mtx,ctrl,nam=colnames(mtx))

## End(Not run)

options(np.messages=FALSE)
set.seed(234)
z=runif(10,2,11)# z is independently created
x=sample(1:10)+z/10 #x is somewhat indep and affected by z
y=1+2*x+3*z+rnorm(10)
w=runif(10)
x2=x;x2[4]=NA;y2=y;y2[8]=NA;w2=w;w2[4]=NA
causeSummary2(mtx=cbind(x2,y2), ctrl=cbind(z,w2))
 

</code></pre>

<hr>
<h2 id='causeSummBlk'>Block Version 2: Kernel causality summary of causal paths from three criteria</h2><span id='topic+causeSummBlk'></span>

<h3>Description</h3>

<p>A block version of <code>causeSummary()</code> chooses new bandwidth for every
ten (blksiz=10) observations chosen by the &lsquo;np&rsquo; package injecting flexibility.
While allowing the researcher to keep some variables as controls,
or outside the scope of causal path determination 
(e.g., age or latitude), this function produces detailed causal path information. 
The output table is a 5-column matrix identifying the names of variables,
causal path directions, and path strengths re-scaled to be in the 
range [&ndash;100, 100], (table reports absolute values of the strength)
plus Pearson correlation coefficient and its p-value.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>causeSummBlk(
  mtx,
  nam = colnames(mtx),
  blksiz = 10,
  ctrl = 0,
  dig = 6,
  wt = c(1.2, 1.1, 1.05, 1),
  sumwt = 4
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="causeSummBlk_+3A_mtx">mtx</code></td>
<td>
<p>The data matrix with many columns, y the first column 
is a fixed target, and then it is
paired with all other columns, one by one, and still called x for the 
purpose of flipping.</p>
</td></tr>
<tr><td><code id="causeSummBlk_+3A_nam">nam</code></td>
<td>
<p>vector of column names for <code>mtx</code>. Default: colnames(mtx)</p>
</td></tr>
<tr><td><code id="causeSummBlk_+3A_blksiz">blksiz</code></td>
<td>
<p>block size, default=10, if chosen blksiz &gt;n, where n=rows in the matrix
then blksiz=n. That is, no blocking is done</p>
</td></tr>
<tr><td><code id="causeSummBlk_+3A_ctrl">ctrl</code></td>
<td>
<p>data matrix for designated control variable(s) outside causal paths</p>
</td></tr>
<tr><td><code id="causeSummBlk_+3A_dig">dig</code></td>
<td>
<p>The number of digits for reporting (default <code>dig</code>=6).</p>
</td></tr>
<tr><td><code id="causeSummBlk_+3A_wt">wt</code></td>
<td>
<p>Allows user to choose a vector of four alternative weights for SD1 to SD4.</p>
</td></tr>
<tr><td><code id="causeSummBlk_+3A_sumwt">sumwt</code></td>
<td>
<p> Sum of weights can be changed here =4(default).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The algorithm determines causal path directions from the sign
of the strength index. The strength index magnitudes are computed by comparing 
three aspects of flipped kernel regressions: 
[x1 on (x2, x3, .. xp)] and its flipped version [x2 on (x1, x3, .. xp)].
The cause should be on the right-hand side of
the regression equation. The properties
of regression fit determine which flip is superior.
We compare (Cr1) formal exogeneity test criterion, (residuals times RHS
regressor, where smaller in absolute value is better) 
(Cr2) absolute values of residuals, where 
smaller in absolute value is better, and
(Cr3) R-squares of the flipped regressions implying three criteria Cr1, to Cr3.
The criteria are quantified by sophisticated methods using four orders
of stochastic dominance, SD1 to SD4. We assume slightly declining weights on 
the sign observed by Cr1 to Cr3. The user can change default weights.
</p>


<h3>Value</h3>

<p>If there are p columns in the input matrix, x1, x2, .., xp, say,
and if we keep x1 as a common member of all causal-direction-pairs
(x1, x(1+j)) for (j=1, 2, .., p-1) which can be flipped. That is, either x1 is
the cause or x(1+j) is the cause in a chosen pair.
The control
variables are not flipped. The printed output of this function
reports the results for p-1 pairs indicating which variable
(by name) causes which other variable (also by name).
It also prints a strength, or signed summary strength 
index forced to be in the range [-100,100] for easy interpretation. 
A positive sign of the strength index means x1 kernel causes x(1+j),
whereas negative strength index means x(1+j) kernel causes x1. The function 
also prints Pearson correlation and its p-value. This function also returns
a matrix of p-1 rows and 5 columns entitled: 
&ldquo;cause&quot;, &ldquo;response&quot;, &ldquo;strength&quot;, &ldquo;corr.&quot; and &ldquo;p-value&quot;, respectively
with self-explanatory titles. The first two columns have names of variables
x1 or x(1+j), depending on which is the cause. The &lsquo;strength&rsquo; column
has the absolute value of a summary index in the range [0,100],  
providing a summary of causal results
based on the preponderance of evidence from Cr1 to Cr3 
from four orders of stochastic dominance, etc.  The order of input columns matters.
The fourth column of the output matrix entitled &lsquo;corr.&rsquo; reports the Pearson 
correlation coefficient, while
the fifth column of the output matrix has the p-value for testing the 
null hypothesis of a zero Pearson coefficient.
This function calls  <code>siPairsBlk</code>, allowing for control variables.
The output of this function can be sent to &lsquo;xtable&rsquo; for a nice Latex table.
</p>


<h3>Note</h3>

<p>The European Crime data has all three criteria correctly suggesting that
a high crime rate kernel causes the deployment of a large number of police officers.
Since Cr1 to Cr3 near-unanimously suggest &lsquo;crim&rsquo; as the cause of &lsquo;off&rsquo;, 
a strength index of 100 suggests unanimity. 
<code>attach(EuroCrime); causeSummBlk(cbind(crim,off))</code>
</p>


<h3>Author(s)</h3>

<p>Prof. H. D. Vinod, Economics Dept., Fordham University, NY.
</p>


<h3>References</h3>

<p>Vinod, H. D. 'Generalized Correlation and Kernel Causality with
Applications in Development Economics' in Communications in
Statistics -Simulation and Computation, 2015,
<a href="https://doi.org/10.1080/03610918.2015.1122048">doi:10.1080/03610918.2015.1122048</a>
</p>
<p>Vinod, H. D. 'New exogeneity tests and causal paths,'
Chapter 2 in 'Handbook of Statistics: Conceptual Econometrics 
Using R', Vol.32, co-editors: H. D. Vinod and C.R. Rao. New York:
North Holland, Elsevier Science Publishers, 2019, pp. 33-64.
</p>
<p>Vinod, H. D. Causal Paths and Exogeneity Tests 
in Generalcorr Package for Air Pollution and Monetary Policy 
(June 6, 2017). Available at SSRN: 
<a href="https://www.ssrn.com/abstract=2982128">https://www.ssrn.com/abstract=2982128</a>
</p>


<h3>See Also</h3>

<p>See  <code><a href="#topic+bootPairs">bootPairs</a></code>,  <code><a href="#topic+causeSummary">causeSummary</a></code> has
an older version of this function.
</p>
<p>See  <code><a href="#topic+someCPairs">someCPairs</a></code>
</p>
<p><code><a href="#topic+siPairsBlk">siPairsBlk</a></code>, <code><a href="#topic+causeSummary">causeSummary</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

## Not run: 
mtx=as.matrix(mtcars[,1:3])
ctrl=as.matrix(mtcars[,4:5])
 causeSummBlk(mtx,ctrl,nam=colnames(mtx))

## End(Not run)

options(np.messages=FALSE)
set.seed(234)
z=runif(10,2,11)# z is independently created
x=sample(1:10)+z/10 #x is somewhat indep and affected by z
y=1+2*x+3*z+rnorm(10)
w=runif(10)
x2=x;x2[4]=NA;y2=y;y2[8]=NA;w2=w;w2[4]=NA
causeSummBlk(mtx=cbind(x2,y2), ctrl=cbind(z,w2))


</code></pre>

<hr>
<h2 id='causeSumNoP'>No print (NoP) version of causeSummBlk summary causal paths from three criteria</h2><span id='topic+causeSumNoP'></span>

<h3>Description</h3>

<p>Allowing input matrix of control variables, this function produces 
a 5 column matrix
summarizing the results where the estimated signs of
stochastic dominance order values, (+1, 0, -1), are weighted by 
<code>wt=c(1.2,1.1, 1.05, 1)</code> to
compute an overall result for all orders of stochastic dominance by 
a weighted sum for
the criteria Cr1 and Cr2 and added to the Cr3 estimate as: (+1, 0, -1).
The final range for the unanimity of sign index is [&ndash;100, 100].
</p>


<h3>Usage</h3>

<pre><code class='language-R'>causeSumNoP(
  mtx,
  nam = colnames(mtx),
  blksiz = 10,
  ctrl = 0,
  dig = 6,
  wt = c(1.2, 1.1, 1.05, 1),
  sumwt = 4
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="causeSumNoP_+3A_mtx">mtx</code></td>
<td>
<p>The data matrix with many columns, y the first column 
is a fixed target and then it is
paired with all other columns, one by one, and still called x for the 
purpose of flipping.</p>
</td></tr>
<tr><td><code id="causeSumNoP_+3A_nam">nam</code></td>
<td>
<p>vector of column names for <code>mtx</code>. Default: colnames(mtx)</p>
</td></tr>
<tr><td><code id="causeSumNoP_+3A_blksiz">blksiz</code></td>
<td>
<p>block size, default=10, if chosen blksiz &gt;n, where n=rows in matrix
then blksiz=n. That is, no blocking is done</p>
</td></tr>
<tr><td><code id="causeSumNoP_+3A_ctrl">ctrl</code></td>
<td>
<p>data matrix for designated control variable(s) outside causal paths</p>
</td></tr>
<tr><td><code id="causeSumNoP_+3A_dig">dig</code></td>
<td>
<p>Number of digits for reporting (default <code>dig</code>=6).</p>
</td></tr>
<tr><td><code id="causeSumNoP_+3A_wt">wt</code></td>
<td>
<p>Allows user to choose a vector of four alternative weights for SD1 to SD4.</p>
</td></tr>
<tr><td><code id="causeSumNoP_+3A_sumwt">sumwt</code></td>
<td>
<p> Sum of weights can be changed here =4(default).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The reason for slightly declining weights on the signs from
SD1 to SD4 is simply that the higher order stochastic dominance
numbers are less reliable.
The summary results for all
three criteria are reported in one matrix called <code>out</code> but not printed:
</p>


<h3>Value</h3>

<p>If there are p columns in the input matrix, x1, x2, .., xp, say,
and if we keep x1 as a common member of all causal-direction-pairs
(x1, x(1+j)) for (j=1, 2, .., p-1) which can be flipped. That is, either x1 is
the cause or x(1+j) is the cause in a chosen pair.
The control
variables are not flipped. The printed output of this function
reports the results for p-1 pairs indicating which variable
(by name) causes which other variable (also by name).
It also prints strength or signed summary strength index in range [-100,100]. 
A positive sign of the strength index means x1 kernel causes x(1+j),
whereas negative strength index means x(1+j) kernel causes x1. The function 
also prints Pearson correlation and its p-value. This function also returns
a matrix of p-1 rows and 5 columns entitled: 
&ldquo;cause&quot;, &ldquo;response&quot;, &ldquo;strength&quot;, &ldquo;corr.&quot; and &ldquo;p-value&quot;, respectively
with self-explanatory titles. The first two columns have names of variables
x1 or x(1+j), depending on which is the cause. The &lsquo;strength&rsquo; column
has absolute value of summary index in range [0,100]  
providing summary of causal results
based on preponderance of evidence from Cr1 to Cr3 
from four orders of stochastic dominance, etc.  The order of input columns matters.
The fourth column &lsquo;corr.&rsquo; reports the Pearson correlation coefficient while
the fifth column has the p-value for testing the null of zero Pearson coeff.
This function calls  <code>siPairsBlk</code> allowing for control variables.
The output of this function can be sent to &lsquo;xtable&rsquo; for a nice Latex table.
</p>


<h3>Note</h3>

<p>The European Crime data has all three criteria correctly suggesting that
high crime rate kernel causes the deployment of a large number of police officers.
Since Cr1 to Cr3 near unanimously suggest &lsquo;crim&rsquo; as the cause of &lsquo;off&rsquo;, 
strength index 100 suggests unanimity. 
<code>attach(EuroCrime); causeSummary(cbind(crim,off))</code>
</p>


<h3>Author(s)</h3>

<p>Prof. H. D. Vinod, Economics Dept., Fordham University, NY.
</p>


<h3>References</h3>

<p>Vinod, H. D. 'Generalized Correlation and Kernel Causality with
Applications in Development Economics' in Communications in
Statistics -Simulation and Computation, 2015,
<a href="https://doi.org/10.1080/03610918.2015.1122048">doi:10.1080/03610918.2015.1122048</a>
</p>
<p>Vinod, H. D. 'New exogeneity tests and causal paths,'
Chapter 2 in 'Handbook of Statistics: Conceptual Econometrics 
Using R', Vol.32, co-editors: H. D. Vinod and C.R. Rao. New York:
North Holland, Elsevier Science Publishers, 2019, pp. 33-64.
</p>
<p>Vinod, H. D. Causal Paths and Exogeneity Tests 
in Generalcorr Package for Air Pollution and Monetary Policy 
(June 6, 2017). Available at SSRN: 
<a href="https://www.ssrn.com/abstract=2982128">https://www.ssrn.com/abstract=2982128</a>
</p>


<h3>See Also</h3>

<p>See  <code><a href="#topic+bootPairs">bootPairs</a></code>,  <code><a href="#topic+causeSummary0">causeSummary0</a></code> has
an older version of this function.
</p>
<p>See  <code><a href="#topic+causeAllPair">causeAllPair</a></code>
</p>
<p><code><a href="#topic+siPairsBlk">siPairsBlk</a></code>, <code><a href="#topic+causeSummary">causeSummary</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

## Not run: 
mtx=data.frame(mtcars[,1:3])
ctrl=data.frame(mtcars[,4:5])
 causeSumNoP(mtx=mtx,ctrl=ctrl)

## End(Not run)

options(np.messages=FALSE)
set.seed(234)
z=runif(10,2,11)# z is independently created
x=sample(1:10)+z/10 #x is somewhat indep and affected by z
y=1+2*x+3*z+rnorm(10)
w=runif(10)
x2=x;x2[4]=NA;y2=y;y2[8]=NA;w2=w;w2[4]=NA
causeSumNoP(mtx=cbind(x2,y2), ctrl=cbind(z,w2))


</code></pre>

<hr>
<h2 id='cofactor'>Compute cofactor of a matrix based on row r and column c.</h2><span id='topic+cofactor'></span>

<h3>Description</h3>

<p>Compute cofactor of a matrix based on row r and column c.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cofactor(x, r, c)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cofactor_+3A_x">x</code></td>
<td>
<p>matrix whose cofactor is desired to be computed</p>
</td></tr>
<tr><td><code id="cofactor_+3A_r">r</code></td>
<td>
<p>row number</p>
</td></tr>
<tr><td><code id="cofactor_+3A_c">c</code></td>
<td>
<p>column number</p>
</td></tr>
</table>


<h3>Value</h3>

<p>cofactor of x,  w.r.t. row r and column c.
</p>


<h3>Note</h3>

<p>needs the function 'minor&rdquo; in memory. attaches sign (-1)^(r+c) to the minor.
</p>


<h3>Author(s)</h3>

<p>Prof. H. D. Vinod, Economics Dept., Fordham University, NY
</p>


<h3>See Also</h3>

<p><code>minor(x,r,c)</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## The function is currently defined as
function (x, r, c) 
{
    out = minor(x, r, c) * ((-1)^(r + c))
    return(out)
  }
</code></pre>

<hr>
<h2 id='comp_portfo2'>Compares two vectors (portfolios) using stochastic dominance of orders 1 to 4.</h2><span id='topic+comp_portfo2'></span>

<h3>Description</h3>

<p>Given two vectors of portfolio returns this function calls the internal function wtdpapb
to report the simple means of four sophisticated measures of stochastic dominance.
as explained in Vinod (2008).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>comp_portfo2(xa, xb)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="comp_portfo2_+3A_xa">xa</code></td>
<td>
<p>Data on returns for portfolio A in the form of a T by 1 vector</p>
</td></tr>
<tr><td><code id="comp_portfo2_+3A_xb">xb</code></td>
<td>
<p>Data on returns for portfolio B in the form of a T by 1 vector</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns four numbers which are averages of four sophisticated measures of stochastic
dominance measurements called SD1 to SD4.
</p>


<h3>Note</h3>

<p>It is possible to modify this function to report the median or standard
deviation or any other descriptive statistic by changing the line in the
code '<code>oumean = apply(outb, 2, mean)</code>' toward the end of this function.
A trimmed mean may be of interest when outliers are suspected.
</p>
<p>require(np)
</p>
<p>Make sure that functions wtdpapb, bigfp, stochdom2 are in the memory.
and options(np.messages=FALSE)
</p>


<h3>Author(s)</h3>

<p>Prof. H. D. Vinod, Economics Dept., Fordham University, NY
</p>


<h3>References</h3>

<p>Vinod, H. D.&quot;, &quot;Hands-On Intermediate Econometrics 
Using R&quot;  (2008) World Scientific Publishers: Hackensack, NJ. (Chapter 4)
<a href="https://www.worldscientific.com/worldscibooks/10.1142/12831">https://www.worldscientific.com/worldscibooks/10.1142/12831</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+stochdom2">stochdom2</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(30)
xa=sample(20:30)#generally lower returns
xb=sample(32:40)# higher returns in xb
gp = comp_portfo2(xa, xb)#all Av(sdi) positive means xb dominates
##positive SD1 to SD4 means xb dominates xa as it should

</code></pre>

<hr>
<h2 id='compPortfo'>Compares two vectors (portfolios) using
momentVote, DecileVote and exactSdMtx functions.</h2><span id='topic+compPortfo'></span>

<h3>Description</h3>

<p>Given two vectors of portfolio returns this function summarizes their ranks
based on moments, deciles and exact measures of stochastic dominance.
as explained in Vinod (2021). This algorithm has model selection applications.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>compPortfo(xa, xb)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="compPortfo_+3A_xa">xa</code></td>
<td>
<p>Data on returns for portfolio A in the form of a T by 1 vector</p>
</td></tr>
<tr><td><code id="compPortfo_+3A_xb">xb</code></td>
<td>
<p>Data on returns for portfolio B in the form of a T by 1 vector</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns three numbers which represent signs based differences in
ranks (rank=1 for most desirable) measured by [rank(xa)-rank(xb)] using
momentVote, decileVote, and  exactSdMtx which are weighted
averages of four moments, nine deciles and exact measures of stochastic
dominance (from ECDFs of four orders, SD1 to SD4) respectively.
</p>


<h3>Note</h3>

<p>There are model-selection applications where two models A and B are
compared and one wants to choose the model smaller absolute value of
residuals. This function when applied for model-selection will have
he inputs xa and xb as absolute residuals. We can compare the entire
probability distributions of absolute residuals by moments, deciles
or SD1 to SD4. Of course, care must be taken to choose xa or
xb depending on which model has smaller absolute residuals. This choice
is the exact opposite of portfolio choice application where
larger return is more desirable.  <code>silentPair2()</code>
and <code>siPair2Blk</code> call this
function for model selection application.
</p>


<h3>Author(s)</h3>

<p>Prof. H. D. Vinod, Economics Dept., Fordham University, NY
</p>


<h3>References</h3>

<p>Vinod, H. D.&quot;, &quot;Hands-On Intermediate Econometrics 
Using R&quot;  (2008) World Scientific Publishers: Hackensack, NJ. (Chapter 4)
<a href="https://www.worldscientific.com/worldscibooks/10.1142/12831">https://www.worldscientific.com/worldscibooks/10.1142/12831</a>
</p>
<p>Vinod, Hrishikesh D., R Package GeneralCorr 
Functions for Portfolio Choice 
(November 11, 2021). Available at SSRN: 
https://ssrn.com/abstract=3961683
</p>


<h3>See Also</h3>

<p><code><a href="#topic+exactSdMtx">exactSdMtx</a></code>
</p>
<p><code><a href="#topic+momentVote">momentVote</a></code>
</p>
<p><code><a href="#topic+decileVote">decileVote</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(30)
xa=sample(20:30)#generally lower returns
xb=sample(32:40)# higher returns in xb
gp = compPortfo(xa, xb)#all Av(sdi) positive means xb dominates
##output (1,1,1) means xb dominates xa. xb are larger by consruction

</code></pre>

<hr>
<h2 id='da'>
internal da
</h2><span id='topic+da'></span>

<h3>Description</h3>

<p>intended for internal use only
</p>


<h3>Usage</h3>

<pre><code class='language-R'>da</code></pre>

<hr>
<h2 id='da2Lag'>
internal da2Lag
</h2><span id='topic+da2Lag'></span>

<h3>Description</h3>

<p>intended for internal use
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(da2Lag)</code></pre>


<h3>Format</h3>

<p>The format is:
int 4
</p>

<hr>
<h2 id='decileVote'>Function compares nine deciles of stock return distributions.</h2><span id='topic+decileVote'></span>

<h3>Description</h3>

<p>The first step computes a minimum reference return and  nine deciles.
The input x must be a matrix having p columns (with a name for each column)
and n rows as in the data.  If data are missing for some columns, insert NA's.
Thus x has p column of the data matrix ready for comparison and ranking. 
For example, x has a matrix of stock returns.
The output matrix produced by this function also has p columns for each 
column (i.e., for each stock being compared). The output matrix has
nineteen rows. The top nine rows have the magnitudes of deciles.
Rows 10 to 18 have respective ranks of the decile magnitudes. 
The next (19-th) row  of the output reports a weighted sum
of ranks.  
Ranking always gives the smallest number 1 to the most desirable outcome.  
We suggest that a higher portfolio weight
be given to the column having smallest rank value (along the 19th line).
The 20-th row further ranks the weighted sums of ranks in row 19. Investor
should choose the stock (column) representing the smallest rank 
value along the last (20th) row of the &lsquo;out&rsquo; matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>decileVote(mtx, howManySd = 0.1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="decileVote_+3A_mtx">mtx</code></td>
<td>
<p> (n X p) matrix of data. For example, returns on p stocks n months</p>
</td></tr>
<tr><td><code id="decileVote_+3A_howmanysd">howManySd</code></td>
<td>
<p>used to define &lsquo;fixmin&rsquo;= imaginary lowest return defined by going
howManySd=default=0.1 maximum of standard deviations of all stocks below 
the minimum return for all stocks in the data</p>
</td></tr>
</table>


<h3>Value</h3>

<p>out is a matrix with p columns (same as in the input matrix) and
twenty rows. Top nine rows have 9 deciles, next nine rows have their ranks.
The 19-th row of &lsquo;out&rsquo; has a weighted sum of 9 ranks. All columns refer to
one stock. The weighted sum for each stock is then ranked. A
portfolio manager is assumed to prefer higher return represented by
high decile values represented by the column with the largest weighted sum. 
can give largest weight to the column with the smallest bottom line.
The bottom line (20-th) labeled &ldquo;choice&quot; of the &lsquo;out&rsquo; matrix is
defined so that choice =1 suggests the stock deserving 
the highest weight in the portfolio. The portfolio manager will
generally give the lowest weight (=0?) to the stock representing column 
having number p as the choice number. The manager may want to sell this stock. 
Another output of the &lsquo;decileVote&rsquo; function is &lsquo;fixmin&rsquo; representing the
smallest possible return of all the stocks in the input &lsquo;mtx&rsquo; of returns.
It is useful as a reference stock. We compute stochastic dominance numbers
for each stock with this imaginary stock yielding fixmin return for all time
periods.
</p>


<h3>Author(s)</h3>

<p>Prof. H. D. Vinod, Economics Dept., Fordham University, NY
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x1=c(1,4,7,2,6)
x2=c(3,4,8,4,7)
decileVote(cbind(x1,x2))

</code></pre>

<hr>
<h2 id='depMeas'>depMeas Signed measure of nonlinear nonparametric dependence between two vectors.</h2><span id='topic+depMeas'></span>

<h3>Description</h3>

<p>An infant may depend on the mother for survival, but not vice versa.
Dependence relations need not be symmetric, yet correlation coefficients
are symmetric. One way to measure the extent of dependence is to find
the max of the absolute values of the two asymmetric correlations
using Vinod's (2015) definition of generalized (asymmetric) correlation
coefficients.  It requires a kernel regression of x on y obtained by using 
the &lsquo;np&rsquo; package and its flipped version
(regress y on x).  We use a block version of
&lsquo;gmcmtx0&rsquo;  called 'gmcmtxBlk' to admit several bandwidths for every ten
observations if the user sets blksiz=10, a recommended choice here.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>depMeas(x, y, blksiz = length(x))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="depMeas_+3A_x">x</code></td>
<td>
<p>Vector of data on the first variable</p>
</td></tr>
<tr><td><code id="depMeas_+3A_y">y</code></td>
<td>
<p>Vector of data on the second variable</p>
</td></tr>
<tr><td><code id="depMeas_+3A_blksiz">blksiz</code></td>
<td>
<p>block size, default blksiz =n, where n=rows in the matrix
or no blocking is done</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A measure of dependence having the same sign as Pearson correlation. Its
magnitude equals the larger of the two generalized correlation coefficients.
</p>


<h3>Note</h3>

<p>This function needs the gmcmtxBlk function, which in turn needs the np package.
</p>


<h3>Author(s)</h3>

<p>Prof. H. D. Vinod, Economics Dept., Fordham University, NY
</p>


<h3>References</h3>

<p>Vinod, H. D. 'Generalized Correlation and Kernel Causality with
Applications in Development Economics' in Communications in
Statistics -Simulation and Computation, 2015,
<a href="https://doi.org/10.1080/03610918.2015.1122048">doi:10.1080/03610918.2015.1122048</a>
</p>
<p>Vinod, H. D. 'Matrix Algebra Topics in Statistics and Economics
Using R', Chapter 4 in Handbook of Statistics: Computational Statistics
with R, Vol.32, co-editors: M. B. Rao and C.R. Rao. New York:
North Holland, Elsevier Science Publishers, 2014, pp. 143-176.
</p>
<p>Vinod, H. D. (2021) 'Generalized, Partial and Canonical Correlation
Coefficients' Computational Economics, 59(1), 1&ndash;28.
</p>


<h3>See Also</h3>

<p>See Also <code><a href="#topic+gmcmtx0">gmcmtx0</a></code> and <code><a href="#topic+gmcmtxBlk">gmcmtxBlk</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(generalCorr)
options(np.messages = FALSE)
x=1:20;y=sin(x)
depMeas(x,y,blksiz=20)

</code></pre>

<hr>
<h2 id='dif4'>order 4 differencing of a time series vector</h2><span id='topic+dif4'></span>

<h3>Description</h3>

<p>This is for momentum traders who focus on growth, acceleration, its gorwth
and further acceleration. The diff function of R seems to do 
recycling of available numbers, not wanted for our purposes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dif4(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dif4_+3A_x">x</code></td>
<td>
<p>(n X 1) vector of time series (market returns) with n items each</p>
</td></tr>
</table>


<h3>Value</h3>

<p>ou2 matrix having five columns, first for x, the next four
columns have diff(x), diff-squared(x), diff-cubed(x) and diff-fourth(x)
</p>


<h3>Author(s)</h3>

<p>Prof. H. D. Vinod, Economics Dept., Fordham University, NY
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x=c(2,8,3,5,1,8,19,22,23)
dif4(x)

</code></pre>

<hr>
<h2 id='dif4mtx'>order four differencing of a matrix of time series</h2><span id='topic+dif4mtx'></span>

<h3>Description</h3>

<p>This is for momentum traders who focus on growth, acceleration, its growth
and further acceleration. The diff function of R seems to do 
recycling of available numbers, not wanted for our purposes. Hence, this
function is needed in portfolio studies based on time series.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dif4mtx(mtx)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dif4mtx_+3A_mtx">mtx</code></td>
<td>
<p>(n X p) matrix of p time series (market returns) with n items each</p>
</td></tr>
</table>


<h3>Value</h3>

<p>out matrix having 12 rows, (data, D1 to D4
and ranks of D1 to D4
The column names of out are those of input matrix mtx.
</p>


<h3>Author(s)</h3>

<p>Prof. H. D. Vinod, Economics Dept., Fordham University, NY
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x=c(2,8,3,5,1,8,19,22,23)
y=c(3,11,2,6,7,9,20,25,21)
dif4mtx(cbind(x,y))

</code></pre>

<hr>
<h2 id='diff.e0'>
Internal diff.e0</h2><span id='topic+diff.e0'></span>

<h3>Description</h3>

<p>Internal diff.e0
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(diff.e0)</code></pre>

<hr>
<h2 id='dig'>
Internal dig
</h2><span id='topic+dig'></span>

<h3>Description</h3>

<p>Intended for internal use
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(dig)</code></pre>


<h3>Format</h3>

<p>The format digs:
int 78
</p>

<hr>
<h2 id='e0'>
internal e0
</h2><span id='topic+e0'></span>

<h3>Description</h3>

<p>intended for internal use only
</p>


<h3>Usage</h3>

<pre><code class='language-R'>e0</code></pre>

<hr>
<h2 id='EuroCrime'>European Crime Data</h2><span id='topic+EuroCrime'></span>

<h3>Description</h3>

<p>This data set refers to crime in European countries during 2008.
The sources are World Bank and Eurostat.  The crime statistics refers
to homicides. It avoids possible reporting bias from the presence
of police officers, because homicide reporting in most countries is
standardized.  Typical usage is: <code>data(EuroCrime);attach(EuroCrime)</code>.
The secondary source &lsquo;quandl.com&rsquo; was used for collecting these data.
</p>


<h3>Details</h3>

<p>The variables included in the dataset are:
</p>

<ul>
<li><p><code>Country</code> Name of the European country
</p>
</li>
<li><p><code>crim</code> Per capita crime rate
</p>
</li>
<li><p><code>off</code> Per capita deployment of police officers
</p>
</li></ul>


<hr>
<h2 id='exactSdMtx'>Exact stochastic dominance computation from areas above ECDF pillars.</h2><span id='topic+exactSdMtx'></span>

<h3>Description</h3>

<p>ECDF=empirical cumulative distribution functions. These are sufficient
statistics representing probability density functions
defined by observable finite data (e.g., stock returns). The exact computation
of stochastic dominance orders SD1 to SD4 needs areas between two ECDFs,
since such areas represent integrals. Higher-order SDs with continuous 
variables involve repeated integrals. Our quantification needs
areas of ECDFs defined from areas of lower-order ECDFs. We argue that these
computations are convenient if there is an ECDF of an imaginary
reference minimum (x.ref) return, whose ECDF is a rectangle 
common for all stock comparisons. A common (x.ref) avoids having to compute
all possible pairs of p stocks. Choosing a common reference as SP500 index
stock cannot avoid a slower trapezoidal approximation for integrals,
since its returns vary over time. We want exact areas of rectangles and fast.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>exactSdMtx(mtx, howManySd = 0.1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="exactSdMtx_+3A_mtx">mtx</code></td>
<td>
<p>(n X p) matrix of data. For example, returns on p stocks
over n months</p>
</td></tr>
<tr><td><code id="exactSdMtx_+3A_howmanysd">howManySd</code></td>
<td>
<p>used to define (x.ref)= lowest return number.
If the grand minimum of all returns in &lsquo;mtx&rsquo; is denoted GrMin, then
howManySd equals the number of max(sd) (maximum standard deviation for data
columns) below the GrMin used to define (x.ref). Thus,
(x.ref)=GrMin-howManySd*max(sd). default howManySd=0.1 </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>exactSdMtx</code> function inputs &lsquo;mtx&rsquo; (n X p) matrix data 
(e.g., n monthly returns on p stocks).
Its output has four matrices SD1 to SD4, each with dimension (n X p). They measure
exact dominance areas between empirical CDF for each column to the ECDF of
(x.ref), an artificial stock with minimal return in all time periods. A fifth
output matrix called &lsquo;out&rsquo; produced by <code>exactSdMtx</code>
has 4 rows and p columns containing column sums of SD1 to SD4. 
We intend that this
&lsquo;out&rsquo; matrix produced by <code>exactSdMtx</code> is then input to another
function <code>summaryRank()</code> in the package designed for practitioners.
For example, it indicates the best and the worst columns 
representing (the best stock to buy and best stock to sell)
from the input data &lsquo;mtx&rsquo; for investment based on a sophisticated computation
of their ranks.
</p>


<h3>Value</h3>

<p>five matrices. SD1 to SD4 contain four orders of stochastic 
dominance areas using the ECDF pillars and 
a common (x.ref). The fifth &quot;out&quot; matrix is another output with 4 rows for
SD1 to SD4, and p columns (p=No. of columns in data matrix mtx) having a 
summary of ranks using all four, SD1 to SD4.
</p>


<h3>Author(s)</h3>

<p>Prof. H. D. Vinod, Economics Dept., Fordham University, NY
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x1=c(2,5,6,9,13,18,21)
x2=c(3,6,9,12,14,19,27) 
st1=exactSdMtx(cbind(x1,x2))


</code></pre>

<hr>
<h2 id='GcRsqX12'>Generalized Granger-Causality. If dif&gt;0, x2 Granger-causes x1.</h2><span id='topic+GcRsqX12'></span>

<h3>Description</h3>

<p>The usual Granger-causality assumes linear regressions. This function allows
nonlinear nonparametric kernel regressions using a local linear (ll) option.
Granger-causality (Gc) is generalized using nonlinear kernel 
regressions using local linear (ll) option. This
functionn computes two R^2 values. (i) R12 or kernel regression  R^2 of x1t on its
own lags and x2t and its lags. (ii) R21 or kernel regression R^2 of x2t on its
own lags and x1t and its lags. (iii) dif=R12-R21, the difference between the
two R^2 values. If dif&gt;0 then x2 Granger-causes x1.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>GcRsqX12(x1, x2, px1 = 4, px2 = 4, pwanted = 4, ctrl = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="GcRsqX12_+3A_x1">x1</code></td>
<td>
<p>The data vector x1</p>
</td></tr>
<tr><td><code id="GcRsqX12_+3A_x2">x2</code></td>
<td>
<p>The data vector x2</p>
</td></tr>
<tr><td><code id="GcRsqX12_+3A_px1">px1</code></td>
<td>
<p>The number of lags of x1 in the data default px1=4</p>
</td></tr>
<tr><td><code id="GcRsqX12_+3A_px2">px2</code></td>
<td>
<p>The number of lags of x2 in the data, default px2=4</p>
</td></tr>
<tr><td><code id="GcRsqX12_+3A_pwanted">pwanted</code></td>
<td>
<p>number of lags of both x2 and x1 wanted for Granger causal analysis, default =4</p>
</td></tr>
<tr><td><code id="GcRsqX12_+3A_ctrl">ctrl</code></td>
<td>
<p>data matrix for designated control variable(s) outside causal paths
default=0 means no control variables are present</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Calls GcRsqYX for R-square from kernel regression (local linear version)
R^2[x1=f(x1,x2)] choosing GcRsqYX(y=x1, x=x2). It predicts x1 from 
both x1 and x2 using all information till time (t-1).
It also calls GcRsqYX again after flipping x1 and x2.
It returns RsqX1onX2, RsqX2onX1 and the difference dif=(RsqX1onX2-RsqX2onX1)
If (dif&gt;0) the regression y=f(x1,x2) is better than the flipped
version implying that x1 is more predictable or x2 Granger-causes x1,
x2 &ndash;&gt; x1, rather than vice versa. The kernel regressions use
regtype=&quot;ll&quot; for local linear, bwmethod=&quot;cv.aic&quot; for AIC-based
bandwidth selection.
</p>


<h3>Value</h3>

<p>This function returns 3 numbers: RsqX1onX2, RsqX2onX1 and dif
</p>
<p>returns a list of 3 numbers. RsqX1onX2=(Rsquare of
kernel regression of X1 on lags of X1 and X2 and its lags), 
RsqX2onX1= (Rsquare of kernel regression of x2 on own lags of X2 and X1), and 
the difference between the two Rquares (first minus second) called &lsquo;dif.&rsquo;
If dif&gt;0 then x2 Granger-causes x1
</p>


<h3>Author(s)</h3>

<p>Prof. H. D. Vinod, Economics Dept., Fordham University, NY.
</p>


<h3>References</h3>

<p>Vinod, H. D. 'Generalized Correlation and Kernel Causality with
Applications in Development Economics' in Communications in
Statistics -Simulation and Computation, 2015,
<a href="https://doi.org/10.1080/03610918.2015.1122048">doi:10.1080/03610918.2015.1122048</a>
</p>
<p>Vinod, H. D. 'New exogeneity tests and causal paths,'
Chapter 2 in 'Handbook of Statistics: Conceptual Econometrics 
Using R', Vol.32, co-editors: H. D. Vinod and C.R. Rao. New York:
North-Holland, Elsevier Science Publishers, 2019, pp. 33-64.
</p>
<p>Vinod, H. D. Causal Paths and Exogeneity Tests 
in Generalcorr Package for Air Pollution and Monetary Policy 
(June 6, 2017). Available at SSRN: 
<a href="https://www.ssrn.com/abstract=2982128">https://www.ssrn.com/abstract=2982128</a>
</p>
<p>Zheng, S., Shi, N.-Z., Zhang, Z., 2012. 
Generalized measures of correlation for
asymmetry, nonlinearity, and beyond. Journal of the American Statistical
Association 107, 1239-1252.
-at-note internal routine
</p>


<h3>See Also</h3>

<p><code><a href="#topic+bootGcRsq">bootGcRsq</a></code>, 
<code><a href="#topic+causeSummary">causeSummary</a></code>, 
<code><a href="#topic+GcRsqYX">GcRsqYX</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

## Not run: 
library(Ecdat);options(np.messages=FALSE);attach(data.frame(MoneyUS))
GcRsqX12(y,m)   

## End(Not run)



</code></pre>

<hr>
<h2 id='GcRsqX12c'>Generalized Granger-Causality. If dif&gt;0, x2 Granger-causes x1.</h2><span id='topic+GcRsqX12c'></span>

<h3>Description</h3>

<p>The usual Granger-causality assumes linear regressions. This allows
nonlinear nonparametric kernel regressions using a local constat (lc) option.
Calls GcRsqYXc for R square from kernel regression.
R^2[x1=f(x1,x2)] choosing GcRsqYXc(y=x1, x=x2). The name &lsquo;c&rsquo; in the function
refers to local constant option of kernel regressions.'
It predicts x1 from 
both x1 and x2 using all information till time (t-1).
It also calls GcRsqYXc again after flipping x1 and x2.
It returns RsqX1onX2, RsqX2onX1 and the difference dif=(RsqX1onX2-RsqX2onX1)
If (dif&gt;0) the regression x1=f(x1,x2) is better than the flipped
version implying that x1 is more predictable or x2 Granger-causes x1
x2 &ndash;&gt; x1, rather than vice versa. The kernel regressions use
regtype=&quot;lc&quot; for local constant, bwmethod=&quot;cv.ls&quot; for least squares-based
bandwidth selection.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>GcRsqX12c(x1, x2, px1 = 4, px2 = 4, pwanted = 4, ctrl = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="GcRsqX12c_+3A_x1">x1</code></td>
<td>
<p>The data vector x1</p>
</td></tr>
<tr><td><code id="GcRsqX12c_+3A_x2">x2</code></td>
<td>
<p>The data vector x2</p>
</td></tr>
<tr><td><code id="GcRsqX12c_+3A_px1">px1</code></td>
<td>
<p>number of lags of x1 in the data default px1=4</p>
</td></tr>
<tr><td><code id="GcRsqX12c_+3A_px2">px2</code></td>
<td>
<p>number of lags of x2 in the data, default px2=4</p>
</td></tr>
<tr><td><code id="GcRsqX12c_+3A_pwanted">pwanted</code></td>
<td>
<p>number of lags of both x2 and x1 wanted for Granger causal analysis, default =4</p>
</td></tr>
<tr><td><code id="GcRsqX12c_+3A_ctrl">ctrl</code></td>
<td>
<p>data matrix for designated control variable(s) outside causal paths
default=0 means no control variables are present</p>
</td></tr>
</table>


<h3>Value</h3>

<p>This function returns 3 numbers: RsqX1onX2, RsqX2onX1 and dif
</p>
<p>returns a list of 3 numbers. RsqX1onX2=(Rsquare of
kernel regression of X1 on X1 and X2), 
RsqX2onX1= (Rsquare of kernel regression of x2 on X2 and X1), and 
the difference between the two Rquares called dif
</p>


<h3>Author(s)</h3>

<p>Prof. H. D. Vinod, Economics Dept., Fordham University, NY.
</p>


<h3>References</h3>

<p>Vinod, H. D. 'Generalized Correlation and Kernel Causality with
Applications in Development Economics' in Communications in
Statistics -Simulation and Computation, 2015,
<a href="https://doi.org/10.1080/03610918.2015.1122048">doi:10.1080/03610918.2015.1122048</a>
</p>
<p>Vinod, H. D. 'New exogeneity tests and causal paths,'
Chapter 2 in 'Handbook of Statistics: Conceptual Econometrics 
Using R', Vol.32, co-editors: H. D. Vinod and C.R. Rao. New York:
North Holland, Elsevier Science Publishers, 2019, pp. 33-64.
</p>
<p>Vinod, H. D. Causal Paths and Exogeneity Tests 
in Generalcorr Package for Air Pollution and Monetary Policy 
(June 6, 2017). Available at SSRN: 
<a href="https://www.ssrn.com/abstract=2982128">https://www.ssrn.com/abstract=2982128</a>
</p>
<p>Zheng, S., Shi, N.-Z., Zhang, Z., 2012. 
Generalized measures of correlation for
asymmetry, nonlinearity, and beyond. Journal of the American Statistical
Association 107, 1239-1252.
-at-note internal routine
</p>


<h3>See Also</h3>

<p><code><a href="#topic+causeSummary">causeSummary</a></code>
</p>
<p><code><a href="#topic+GcRsqYXc">GcRsqYXc</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

## Not run: 
library(Ecdat);options(np.messages=FALSE);attach(data.frame(MoneyUS))
GcRsqX12c(y,m)   

## End(Not run)



</code></pre>

<hr>
<h2 id='GcRsqYX'>Nonlinear Granger causality between two time series workhorse function.</h2><span id='topic+GcRsqYX'></span>

<h3>Description</h3>

<p>Function input is y=LHS=First time series and x=RHS=Second time series.
Kernel regression np package options regtype=&quot;ll&quot; for local linear, 
and bwmethod=&quot;cv.aic&quot; for AIC-based bandwidth selection are fixed.
Denote Rsq=Rsquare=R^2 in nonlinear kernel regression.
GcRsqYX(.) computes the following two R^2 values.
out[1]=Rsqyyx = R^2 when we regress y on own lags of y and x.
out[2]=Rsqyy = R^2 when we regress y on lags of y alone.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>GcRsqYX(y, x, px = 4, py = 4, pwanted = 4, ctrl = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="GcRsqYX_+3A_y">y</code></td>
<td>
<p>The data vector y for the Left side or dependent or first variable</p>
</td></tr>
<tr><td><code id="GcRsqYX_+3A_x">x</code></td>
<td>
<p>The data vector x for the right side or explanatory or second variable</p>
</td></tr>
<tr><td><code id="GcRsqYX_+3A_px">px</code></td>
<td>
<p>number of lags of x in the data</p>
</td></tr>
<tr><td><code id="GcRsqYX_+3A_py">py</code></td>
<td>
<p>number of lags of y in the data. px=4 for quarterly data</p>
</td></tr>
<tr><td><code id="GcRsqYX_+3A_pwanted">pwanted</code></td>
<td>
<p>number of lags of both x and y wanted for Granger causal analysis</p>
</td></tr>
<tr><td><code id="GcRsqYX_+3A_ctrl">ctrl</code></td>
<td>
<p>data matrix for designated control variable(s) outside causal paths
default=0 means no control variables are present</p>
</td></tr>
</table>


<h3>Value</h3>

<p>This function returns a set of 2 numbers measuring nonlinear Granger-causality 
for time series. out[1]=Rsqyyx, out[2]=Rsqyy.
</p>


<h3>Note</h3>

<p>If data are annual or if no quarterly-type structure is present,
use this function with pwanted=px=py.  For example, the egg or chicken
data from lmtest package.
</p>


<h3>Author(s)</h3>

<p>Prof. H. D. Vinod, Economics Dept., Fordham University, NY.
</p>


<h3>References</h3>

<p>Vinod, H. D. 'Generalized Correlation and Kernel Causality with
Applications in Development Economics' in Communications in
Statistics -Simulation and Computation, 2015,
<a href="https://doi.org/10.1080/03610918.2015.1122048">doi:10.1080/03610918.2015.1122048</a>
</p>
<p>Vinod, H. D. 'New exogeneity tests and causal paths,'
Chapter 2 in 'Handbook of Statistics: Conceptual Econometrics 
Using R', Vol.32, co-editors: H. D. Vinod and C.R. Rao. New York:
North Holland, Elsevier Science Publishers, 2019, pp. 33-64.
</p>
<p>Vinod, H. D. Causal Paths and Exogeneity Tests 
in Generalcorr Package for Air Pollution and Monetary Policy 
(June 6, 2017). Available at SSRN: 
<a href="https://www.ssrn.com/abstract=2982128">https://www.ssrn.com/abstract=2982128</a>
</p>
<p>Zheng, S., Shi, N.-Z., Zhang, Z., 2012. 
Generalized measures of correlation for
asymmetry, nonlinearity, and beyond. Journal of the American Statistical
Association 107, 1239-1252.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+GcRsqX12">GcRsqX12</a></code>, 
<code><a href="#topic+kern2">kern2</a></code>,
<code><a href="#topic+kern2ctrl">kern2ctrl</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

## Not run: 
library(Ecdat);options(np.messages=FALSE);attach(data.frame(MoneyUS))
GcRsqYX(y,m)  

## End(Not run)



</code></pre>

<hr>
<h2 id='GcRsqYXc'>Nonlinear Granger causality between two time series workhorse function.(local 
constant version)</h2><span id='topic+GcRsqYXc'></span>

<h3>Description</h3>

<p>Function input is y=LHS=First time series and x=RHS=Second time series.
Kernel regression np package options regtype=&quot;lc&quot; for local constant, 
and bwmethod=&quot;cv.ls&quot; for least squares-based bandwidth selection are fixed.
Denote Rsq=Rsquare=R^2 in nonlinear kernel regression.
GcRsqYXc(.) computes the following two R^2 values.
out[1]=Rsqyyx = R^2 when we regress y on own lags of y and x.
out[2]=Rsqyy = R^2 when we regress y on own lags of y alone.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>GcRsqYXc(y, x, px = 4, py = 4, pwanted = 4, ctrl = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="GcRsqYXc_+3A_y">y</code></td>
<td>
<p>The data vector y for the Left side or dependent or first variable</p>
</td></tr>
<tr><td><code id="GcRsqYXc_+3A_x">x</code></td>
<td>
<p>The data vector x for the right side or explanatory or second variable</p>
</td></tr>
<tr><td><code id="GcRsqYXc_+3A_px">px</code></td>
<td>
<p>number of lags of x in the data</p>
</td></tr>
<tr><td><code id="GcRsqYXc_+3A_py">py</code></td>
<td>
<p>number of lags of y in the data. px=4 for quarterly data</p>
</td></tr>
<tr><td><code id="GcRsqYXc_+3A_pwanted">pwanted</code></td>
<td>
<p>number of lags of both x and y wanted for Granger causal analysis</p>
</td></tr>
<tr><td><code id="GcRsqYXc_+3A_ctrl">ctrl</code></td>
<td>
<p>data matrix for designated control variable(s) outside causal paths
default=0 means no control variables are present</p>
</td></tr>
</table>


<h3>Value</h3>

<p>This function returns a set of 2 numbers measuring nonlinear Granger-causality 
for time series. out[1]=Rsqyyx, out[2]=Rsqyy.
</p>


<h3>Note</h3>

<p>If data are annual or if no quarterly-type structure is present,
use this function with pwanted=px=py.  For example, the egg or chicken
data from lmtest package, Thurman W.N. and Fisher M.E. (1988)
</p>


<h3>Author(s)</h3>

<p>Prof. H. D. Vinod, Economics Dept., Fordham University, NY.
</p>


<h3>References</h3>

<p>Vinod, H. D. 'Generalized Correlation and Kernel Causality with
Applications in Development Economics' in Communications in
Statistics -Simulation and Computation, 2015,
<a href="https://doi.org/10.1080/03610918.2015.1122048">doi:10.1080/03610918.2015.1122048</a>
</p>
<p>Vinod, H. D. 'New exogeneity tests and causal paths,'
Chapter 2 in 'Handbook of Statistics: Conceptual Econometrics 
Using R', Vol.32, co-editors: H. D. Vinod and C.R. Rao. New York:
North Holland, Elsevier Science Publishers, 2019, pp. 33-64.
</p>
<p>Vinod, H. D. Causal Paths and Exogeneity Tests 
in Generalcorr Package for Air Pollution and Monetary Policy 
(June 6, 2017). Available at SSRN: 
<a href="https://www.ssrn.com/abstract=2982128">https://www.ssrn.com/abstract=2982128</a>
</p>
<p>Zheng, S., Shi, N.-Z., Zhang, Z., 2012. 
Generalized measures of correlation for
asymmetry, nonlinearity, and beyond. Journal of the American Statistical
Association 107, 1239-1252.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+GcRsqX12c">GcRsqX12c</a></code>
</p>
<p><code><a href="#topic+kern_ctrl">kern_ctrl</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

## Not run: 
library(Ecdat);options(np.messages=FALSE);attach(data.frame(MoneyUS))
GcRsqYXc(y,m) 

## End(Not run)



</code></pre>

<hr>
<h2 id='generalCorrInfo'>generalCorr package description:</h2><span id='topic+generalCorrInfo'></span><span id='topic+generalCorr-package'></span>

<h3>Description</h3>

<p>This package provides convenient software tools for causal path determinations
using Vinod (2014, 2015, 2018, 2021) and is explained in many package vignettes.
<code>causeSummary(mtx)</code>, <code>causeSummary2(mtx)</code>,<code>causeSum2Blk(mtx)</code>,
<code>causeSummBlk</code> are various versions reporting pair-wise causal 
path directions and causal strengths. We fit
a kernel regression of X1 on (X2, X3,..Xk) and another flipped regression
of X2 on (X1, x3, ..Xk).  We compare the two fits using three sophisticated criteria
called Cr1 to Cr3. We rescale the
weighted sum of the quantified three criteria to the [-100, 100] range.
The sign of the weighted sum gives the direction of the causal path, and 
the magnitude of the weighted sum gives the strength of the causal path.
A matrix of non-symmetric generalized correlations r*(x|y) is reported by the
functions <code>rstar()</code> and <code>gmcmtx0()</code>. 
<code>sudoCoefParcor()</code> computes pseudo kernel regression coefficients based on
generalized partial correlation coefficients (GPCC)
<code>depMeas()</code> a measure of nonlinear nonparametric dependence between two vectors.
<code>parcorVec()</code> has generalized partial correlation coefficients, Vinod (2021)
<code>parcorVecH()</code> has a hybrid version of the above (using HGPCC).
The usual partial correlations r(x,y|z) for regression of y on (x, z) measure
the effect of y on x after removing the effect of z, where z can have several variables.
Vinod (2021) suggests new generalized partial correlation coefficients (GPCC)
using kernel regressions, r*(x,y|z).
</p>


<h3>Details</h3>

<p>The criterion Cr1 uses observable values of standard exogeneity test criterion,
namely, (kernel regression residual) times (regressor values)
Cr2 computes absolute values kernel regression residuals.
The quantification of Cr1 and Cr2 further uses four orders of stochastic 
dominance measures.
Cr3 compares the R-square of the two fits.
The package provides additional tools for matrix algebra, such as 
<code>cofactor()</code>, for outlier detection <code>get0outlier()</code>, 
for numerical integration by the trapezoidal rule, stochastic dominance
<code>stochdom2()</code> and <code>comp_portfo2()</code>, etc.
The package has a function <code>pcause()</code> for bootstrap-based statistical 
inference and another one 
for a heuristic t-test called <code>heurist()</code>.  Pairwise deletion of missing data
is done in <code>napair()</code>, while triplet-wise deletion is in <code>naTriplet()</code>
intended for use when control variable(s) are also present. If one has
panel data, functions <code>PanelLag()</code> and <code>Panel2Lag()</code> are relevant.
<code>pillar3D</code> provides 3-dimensional plots of data that look
more like surfaces, than usual plots with vertical pins.
</p>
<p>Recent 2020 additions include <code>canonRho()</code> for generalized canonical 
correlations, and many 
functions for Granger causality between lagged time series including
<code>GcRsqX12()</code>, <code>bootGcRsq()</code> and <code>GcRsqYXc()</code>.
</p>
<p>Recent additions include several functions for portfolio choice.
<code>causeSum2Panel()</code> for panel data, 
<code>sudoCoefParcor()</code> for pseudo regression coefficients for kernel regressions.
<code>decileVote()</code>, <code>momentVote()</code>, <code>exactSdMtx()</code> for exact
computation of stochastic dominance from ECDF areas. The newer stochastic
dominance tools are used in <code>causeSummary2(mtx)</code>,<code>causeSum2Blk(mtx)</code>
<code>dif4mtx()</code>
computes growth, change in growth etc. up-to order 4 differencing of time series.
<code>outOFsamp()</code> and <code>outOFsell()</code> pandemic-proof 
out-of-sample evaluation of portfolio returns using randomization.
<code>causeSum2Panel()</code> exploits panel data features for causal paths.
</p>


<h3>Note</h3>

<p>Eight vignettes provided with this package at CRAN
describe the theory and usage of the package with examples. Read them using
the command: 
<code>vignette("generalCorr-vignette")</code> to read the first vignette. 
vignettes 2 to 6 can be read by including the vignette number. For 
example, 
<code>vignette("generalCorr-vignette6")</code> to read the sixth vignette.
</p>


<h3>References</h3>

<p>Vinod, H. D.'Generalized Correlation and Kernel Causality with 
Applications in Development Economics' in Communications in 
Statistics -Simulation and Computation, 2015, 
<a href="https://doi.org/10.1080/03610918.2015.1122048">doi:10.1080/03610918.2015.1122048</a>
</p>
<p>Vinod, H. D. 'Matrix Algebra Topics in Statistics and Economics
Using R', Chapter 4 in 'Handbook of Statistics: Computational Statistics
with R', Vol.32, co-editors: M. B. Rao and C.R. Rao. New York:
North Holland, Elsevier Science Publishers, 2014, pp. 143-176.
</p>
<p>Zheng, S., Shi, N.-Z., and Zhang, Z. (2012). 'Generalized measures 
of correlation for asymmetry, nonlinearity, and beyond,' 
Journal of the American Statistical Association, vol. 107, pp. 1239-1252.
</p>
<p>Vinod, H. D. (2021) 'Generalized, Partial and Canonical Correlation
Coefficients' Computational Economics, 59(1), 1&ndash;28.
</p>
<p>Vinod, H. D. Causal Paths and Exogeneity Tests 
in Generalcorr Package for Air Pollution and Monetary Policy 
(June 6, 2017). Available at SSRN: 
<a href="https://www.ssrn.com/abstract=2982128">https://www.ssrn.com/abstract=2982128</a>
</p>
<p>Vinod, H. D. 'New exogeneity tests and causal paths,'
Chapter 2 in 'Handbook of Statistics: Conceptual Econometrics 
Using R', Vol.32, co-editors: H. D. Vinod and C.R. Rao. New York:
North Holland, Elsevier Science Publishers, 2019, pp. 33-64.
</p>

<hr>
<h2 id='get0outliers'>Function to compute outliers and their count using Tukey's method
using 1.5 times interquartile range (IQR) to define boundaries.</h2><span id='topic+get0outliers'></span>

<h3>Description</h3>

<p>Function to compute outliers and their count using Tukey's method
using 1.5 times interquartile range (IQR) to define boundaries.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get0outliers(x, verbo = TRUE, mult = 1.5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get0outliers_+3A_x">x</code></td>
<td>
<p>vector of data.</p>
</td></tr>
<tr><td><code id="get0outliers_+3A_verbo">verbo</code></td>
<td>
<p>set to TRUE(default) assuming printed details are desired.</p>
</td></tr>
<tr><td><code id="get0outliers_+3A_mult">mult</code></td>
<td>
<p>=1.5(default), the number of times IQR is used 
in defining outlier boundaries.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>below</code></td>
<td>
<p>which items are lower than the lower limit</p>
</td></tr> 
<tr><td><code>above</code></td>
<td>
<p>which items are larger than the upper limit</p>
</td></tr> 
<tr><td><code>low.lim</code></td>
<td>
<p>the lower boundary for outlier detection</p>
</td></tr> 
<tr><td><code>up.lim</code></td>
<td>
<p>the upper boundary for outlier detection</p>
</td></tr> 
<tr><td><code>nUP</code></td>
<td>
<p>count of number of data points above upper boundary</p>
</td></tr> 
<tr><td><code>nLO</code></td>
<td>
<p>count of number of data points below lower boundary</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The function removes the missing data before checking for outliers.
</p>


<h3>Author(s)</h3>

<p>Prof. H. D. Vinod, Economics Dept., Fordham University, NY
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(101);x=sample(1:100)[1:15];x[16]=150;x[17]=NA
get0outliers(x)#correctly identifies outlier=150


</code></pre>

<hr>
<h2 id='getSeq'>Two sequences: starting+ending values from n and blocksize (internal use)</h2><span id='topic+getSeq'></span>

<h3>Description</h3>

<p>This is an auxiliary function for gmcmtxBlk. It gives sequences of starting
and ending values
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getSeq(n, blksiz)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getSeq_+3A_n">n</code></td>
<td>
<p>length of the range</p>
</td></tr>
<tr><td><code id="getSeq_+3A_blksiz">blksiz</code></td>
<td>
<p>blocksize</p>
</td></tr>
</table>


<h3>Value</h3>

<p>two vectors sqLO and sqUP
</p>


<h3>Author(s)</h3>

<p>Prof. H. D. Vinod, Economics Dept., Fordham University, NY
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gmcmtxBlk">gmcmtxBlk</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
getSeq(n=99, blksiz=10)

</code></pre>

<hr>
<h2 id='gmc0'>
internal gmc0
</h2><span id='topic+gmc0'></span>

<h3>Description</h3>

<p>intended for internal use only
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gmc0</code></pre>

<hr>
<h2 id='gmc1'>
internal gmc1
</h2><span id='topic+gmc1'></span>

<h3>Description</h3>

<p>intended for internal use only
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gmc1</code></pre>

<hr>
<h2 id='gmcmtx0'>Matrix R* of generalized correlation coefficients captures nonlinearities.</h2><span id='topic+gmcmtx0'></span>

<h3>Description</h3>

<p>This function checks for missing data for each pair individually. It then uses the
<code>kern</code> function to kernel regress x on y, and conversely y on x. It
needs the R package &lsquo;np&rsquo;, which reports the R-squares of each regression. 
<code>gmcmtx0()</code> function
reports their square roots after assigning them the observed sign of the Pearson 
correlation coefficient. Its threefold advantages are: (i)
It is asymmetric, yielding causal direction information
by relaxing the assumption of linearity implicit in usual correlation coefficients.
(ii) The r* correlation coefficients are generally larger upon admitting 
arbitrary nonlinearities.  (iii) max(|R*ij|, |R*ji|) measures (nonlinear) 
dependence.
For example, let x=1:20 and y=sin(x). This y has a perfect (100 percent)
nonlinear dependence on x, and yet Pearson correlation coefficient r(xy)
-0.0948372 is near zero, and the 95% confidence interval (-0.516, 0.363)
includes zero, implying that r(xy) is not significantly different from zero.  
This shows a miserable failure of traditional r(x,y) to measure dependence
when nonlinearities are present. 
<code>gmcmtx0(cbind(x,y))</code> will correctly reveal
perfect (nonlinear) dependence with generalized correlation coefficient =-1.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gmcmtx0(mym, nam = colnames(mym))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gmcmtx0_+3A_mym">mym</code></td>
<td>
<p>A matrix of data on variables in columns</p>
</td></tr>
<tr><td><code id="gmcmtx0_+3A_nam">nam</code></td>
<td>
<p>Column names of the variables in the data matrix</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A non-symmetric R* matrix of generalized correlation coefficients
</p>


<h3>Author(s)</h3>

<p>Prof. H. D. Vinod, Economics Dept., Fordham University, NY
</p>


<h3>References</h3>

<p>Vinod, H. D.'Generalized Correlation and Kernel Causality with 
Applications in Development Economics' in Communications in 
Statistics -Simulation and Computation, 2015, 
<a href="https://doi.org/10.1080/03610918.2015.1122048">doi:10.1080/03610918.2015.1122048</a>
</p>
<p>Vinod, H. D. 'Matrix Algebra Topics in Statistics and Economics
Using R', Chapter 4 in 'Handbook of Statistics: Computational Statistics
with R', Vol.32, co-editors: M. B. Rao and C.R. Rao. New York:
North Holland, Elsevier Science Publishers, 2014, pp. 143-176.
</p>
<p>Vinod, H. D. 'New exogeneity tests and causal paths,'
Chapter 2 in 'Handbook of Statistics: Conceptual Econometrics 
Using R', Vol.32, co-editors: H. D. Vinod and C.R. Rao. New York:
North Holland, Elsevier Science Publishers, 2019, pp. 33-64.
</p>
<p>Zheng, S., Shi, N.-Z., and Zhang, Z. (2012). 'Generalized measures 
of correlation for asymmetry, nonlinearity, and beyond,' 
Journal of the American Statistical Association, vol. 107, pp. 1239-1252.
</p>


<h3>See Also</h3>

<p>See Also as <code><a href="#topic+gmcmtxBlk">gmcmtxBlk</a></code> for a more general version using
blocking allowing several bandwidths.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
gmcmtx0(mtcars[,1:3])

## Not run: 
set.seed(34);x=matrix(sample(1:600)[1:99],ncol=3)
colnames(x)=c('V1', 'v2', 'V3')
gmcmtx0(x)
## End(Not run)

</code></pre>

<hr>
<h2 id='gmcmtxBlk'>Matrix R* of generalized correlation coefficients captures nonlinearities using blocks.</h2><span id='topic+gmcmtxBlk'></span>

<h3>Description</h3>

<p>The algorithm uses
two auxiliary functions, <code>getSeq</code> and <code>NLhat</code>. The latter 
uses the
<code>kern</code> function to kernel regress x on y, and conversely y on x. It
needs the package &lsquo;np,&rsquo; which reports residuals and allows one to
compute fitted values (xhat, yhat). Unlike <code>gmcmtx0</code>, this function
considers blocks of blksiz=10 (default) pairs of data points
separately with distinct bandwidths for each block, usually creating superior local fits.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gmcmtxBlk(mym, nam = colnames(mym), blksiz = 10)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gmcmtxBlk_+3A_mym">mym</code></td>
<td>
<p>A matrix of data on selected variables arranged in columns</p>
</td></tr>
<tr><td><code id="gmcmtxBlk_+3A_nam">nam</code></td>
<td>
<p>Column names of the variables in the data matrix</p>
</td></tr>
<tr><td><code id="gmcmtxBlk_+3A_blksiz">blksiz</code></td>
<td>
<p>block size, default=10, if chosen blksiz &gt;n, where n=rows in matrix
then blksiz=n. That is, no blocking is done</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function does pairwise checks of missing data for all pairs. 
Assume that there are n rows in the input matrix &lsquo;mym&rsquo; with some missing rows.
If the columns of mym are denoted (X1, X2, ...Xp), we are considering all
pairs (Xi, Xj), treated as (x, y), with &lsquo;nv&rsquo; number of valid (non-missing) rows
Note that each x and y is an (nv by 1) vector.  This function further
splits these (x, y) vectors into as many subgroups or blocks as are needed
for the nv paired valid data points for the chosen block length (blksiz)
</p>
<p>Next, the algorithm strings together various blocks of
fitted value vectors (xhat, yhat) also of dimension nv by 1. 
Now for each pair of Xi Xj (column Xj= cause, row Xi=response, treated 
as x and y), the algorithm computes R*ij the simple Pearson 
correlation coefficient between (x, xhat) and as R*ji the correlation coeff.
between (y, yhat). Next, it assigns |R*ij| and |R*ji| the observed sign 
of the Pearson correlation coefficient between x and y. 
</p>
<p>Its advantages discussed in Vinod (2015, 2019) are: (i)
It is asymmetric yielding causal direction information,
by relaxing the assumption of linearity implicit in usual correlation coefficients.
(ii) The R* correlation coefficients are generally larger upon admitting 
arbitrary nonlinearities. (iii) max(|R*ij|, |R*ji|) measures (nonlinear) dependence.
For example, let x=1:20 and y=sin(x). This y has a perfect (100 percent)
nonlinear dependence on x and yet Pearson correlation coefficient r(x y)=
-0.0948372 is near zero, and its 95% confidence interval (-0.516, 0.363)
includes zero, implying that the population r(x,y) is not significantly
different from zero.  This example highlights a serious
failure of the traditional r(x,y) in measuring dependence between x and y
when nonlinearities are present.
<code>gmcmtx0</code> without blocking does work if x=1:n, and y=f(x)=sin(x) is used
with n&lt;20.  But for larger n, the fixed bandwidth used by the <code>kern</code> function
becomes a problem. The block version has additional bandwidths for each block, and 
hence it correctly quantifies the presence of high dependence even when 
x=1:n, and y=f(x) are defined for large n and
complicated nonlinear functional forms for f(x).
</p>


<h3>Value</h3>

<p>A non-symmetric R* matrix of generalized correlation coefficients
</p>


<h3>Author(s)</h3>

<p>Prof. H. D. Vinod, Economics Dept., Fordham University, NY
</p>


<h3>References</h3>

<p>Vinod, H. D.'Generalized Correlation and Kernel Causality with 
Applications in Development Economics' in Communications in 
Statistics -Simulation and Computation, 2015, 
<a href="https://doi.org/10.1080/03610918.2015.1122048">doi:10.1080/03610918.2015.1122048</a>
</p>
<p>Vinod, H. D. 'Matrix Algebra Topics in Statistics and Economics
Using R', Chapter 4 in 'Handbook of Statistics: Computational Statistics
with R', Vol.32, co-editors: M. B. Rao and C.R. Rao. New York:
North Holland, Elsevier Science Publishers, 2014, pp. 143-176.
</p>
<p>Vinod, H. D. 'New exogeneity tests and causal paths,'
Chapter 2 in 'Handbook of Statistics: Conceptual Econometrics 
Using R', Vol.32, co-editors: H. D. Vinod and C.R. Rao. New York:
North Holland, Elsevier Science Publishers, 2019, pp. 33-64.
</p>
<p>Zheng, S., Shi, N.-Z., and Zhang, Z. (2012). 'Generalized measures 
of correlation for asymmetry, nonlinearity, and beyond,' 
Journal of the American Statistical Association, vol. 107, pp. 1239-1252.
</p>


<h3>Examples</h3>

<pre><code class='language-R'> 
## Not run: 
x=1:20; y=sin(x)
gmcmtxBlk(cbind(x,y),blksiz=10)
## End(Not run)

</code></pre>

<hr>
<h2 id='gmcmtxZ'>compute the matrix R* of generalized correlation coefficients.</h2><span id='topic+gmcmtxZ'></span>

<h3>Description</h3>

<p>This function checks for missing data separately for each pair using
<code>kern</code> function to kernel regress x on y, and conversely y on x. It
needs the library &lsquo;np&rsquo; which reports R-squares of each regression. This function
reports their square roots with the sign of the Pearson correlation coefficients.
Its appeal is that it is asymmetric yielding causal direction information.
It avoids the assumption of linearity implicit in the usual correlation 
coefficients.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gmcmtxZ(mym, nam = colnames(mym))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gmcmtxZ_+3A_mym">mym</code></td>
<td>
<p>A matrix of data on variables in columns</p>
</td></tr>
<tr><td><code id="gmcmtxZ_+3A_nam">nam</code></td>
<td>
<p>Column names of the variables in the data matrix</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A non-symmetric R* matrix of generalized correlation coefficients
</p>


<h3>Note</h3>

<p>This allows the user to change <code>gmcmtx0</code> and further experiment with my code.
</p>


<h3>Author(s)</h3>

<p>Prof. H. D. Vinod, Economics Dept., Fordham University, NY
</p>


<h3>References</h3>

<p>Vinod, H. D. 'Generalized Correlation and Kernel Causality with 
Applications in Development Economics' in Communications in 
Statistics -Simulation and Computation, 2015, 
<a href="https://doi.org/10.1080/03610918.2015.1122048">doi:10.1080/03610918.2015.1122048</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
set.seed(34);x=matrix(sample(1:600)[1:99],ncol=3)
colnames(x)=c('V1', 'v2', 'V3')
gmcmtxZ(x)

## End(Not run)

</code></pre>

<hr>
<h2 id='gmcxy_np'>Function to compute generalized correlation coefficients r*(x|y) and 
r*(y|x) from two vectors (not matrices)</h2><span id='topic+gmcxy_np'></span>

<h3>Description</h3>

<p>This function uses the &lsquo;np&rsquo; package and assumes that there are no missing data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gmcxy_np(x, y)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gmcxy_np_+3A_x">x</code></td>
<td>
<p>vector of x data</p>
</td></tr>
<tr><td><code id="gmcxy_np_+3A_y">y</code></td>
<td>
<p>vector of y data</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>corxy</code></td>
<td>
<p>r*(x|y)  from regressing x on y, where y is the kernel cause.</p>
</td></tr>
<tr><td><code>coryx</code></td>
<td>
<p>r*(y|x) from regressing y on x, where x is the cause.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>This is provided if the user want to avoid calling <code>kern</code>.
</p>


<h3>Author(s)</h3>

<p>Prof. H. D. Vinod, Economics Dept., Fordham University, NY
</p>


<h3>References</h3>

<p>Vinod, H. D. 'Generalized Correlation and Kernel Causality with
Applications in Development Economics' in Communications in
Statistics -Simulation and Computation, 2015,
<a href="https://doi.org/10.1080/03610918.2015.1122048">doi:10.1080/03610918.2015.1122048</a>
</p>
<p>Vinod, H. D. 'Matrix Algebra Topics in Statistics and Economics
Using R,' Chapter 4 in 'Handbook of Statistics: Computational Statistics
with R,' Vol.32, co-editors: M. B. Rao and C.R. Rao. New York:
North Holland, Elsevier Science Publishers, 2014, pp. 143-176.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
set.seed(34);x=sample(1:10);y=sample(2:11)
gmcxy_np(x,y)
## End(Not run)

</code></pre>

<hr>
<h2 id='goodCol'>
internal goodCol
</h2><span id='topic+goodCol'></span>

<h3>Description</h3>

<p>intended for internal use only
</p>


<h3>Usage</h3>

<pre><code class='language-R'>goodCol</code></pre>

<hr>
<h2 id='heurist'>Heuristic t test of the difference between two generalized correlations.</h2><span id='topic+heurist'></span>

<h3>Description</h3>

<p>Function to run a heuristic t test of the difference between two generalized correlations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>heurist(rxy, ryx, n)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="heurist_+3A_rxy">rxy</code></td>
<td>
<p>generalized correlation r*(x|y) where y is the kernel cause.</p>
</td></tr>
<tr><td><code id="heurist_+3A_ryx">ryx</code></td>
<td>
<p>generalized correlation r*(y|x) where x is the kernel cause.</p>
</td></tr>
<tr><td><code id="heurist_+3A_n">n</code></td>
<td>
<p>Sample size needed to determine the degrees of freedom for the t test.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Prints the t statistics and p-values.
</p>


<h3>Note</h3>

<p>This function requires Revele's R package called &lsquo;psych&rsquo; in memory. This test
is known to be conservative (i.e., often fails to reject 
the null hypothesis of zero difference between the two generalized 
correlation coefficients.)
</p>


<h3>Author(s)</h3>

<p>Prof. H. D. Vinod, Economics Dept., Fordham University, NY
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(34);x=sample(1:10);y=sample(2:11)
g1=gmcxy_np(x,y)
n=length(x)
h1=heurist(g1$corxy,g1$coryx,n)
print(h1)
print(h1$t) #t statistic
print(h1$p) #p-value
</code></pre>

<hr>
<h2 id='i'>
internal i
</h2><span id='topic+i'></span>

<h3>Description</h3>

<p>intended for internal use
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(i)</code></pre>


<h3>Format</h3>

<p>The format is:
int 78
</p>

<hr>
<h2 id='ibad'>
internal object</h2><span id='topic+ibad'></span>

<h3>Description</h3>

<p>intended for internal use
</p>

<hr>
<h2 id='ii'>
internal ii</h2><span id='topic+ii'></span>

<h3>Description</h3>

<p>intended for internal use
</p>

<hr>
<h2 id='j'>
internal j
</h2><span id='topic+j'></span>

<h3>Description</h3>

<p>intended for internal use
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(j)</code></pre>


<h3>Format</h3>

<p>The format is:
int 4
</p>

<hr>
<h2 id='kern'>Kernel regression with options for residuals and gradients.</h2><span id='topic+kern'></span>

<h3>Description</h3>

<p>Function to run kernel regression with options for residuals and gradients
asssuming no missing data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>kern(dep.y, reg.x, tol = 0.1, ftol = 0.1, gradients = FALSE, residuals = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="kern_+3A_dep.y">dep.y</code></td>
<td>
<p>Data on the dependent (response) variable</p>
</td></tr>
<tr><td><code id="kern_+3A_reg.x">reg.x</code></td>
<td>
<p>Data on the regressor (stimulus) variables</p>
</td></tr>
<tr><td><code id="kern_+3A_tol">tol</code></td>
<td>
<p>Tolerance on the position of located minima of the cross-validation 
function (default =0.1)</p>
</td></tr>
<tr><td><code id="kern_+3A_ftol">ftol</code></td>
<td>
<p>Fractional tolerance on the value of cross validation function
evaluated at local minima (default =0.1)</p>
</td></tr>
<tr><td><code id="kern_+3A_gradients">gradients</code></td>
<td>
<p>Make this TRUE if gradients computations are desired</p>
</td></tr>
<tr><td><code id="kern_+3A_residuals">residuals</code></td>
<td>
<p>Make this TRUE if residuals are desired</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Creates a model object &lsquo;mod&rsquo; containing the entire kernel regression output.
Type <code>names(mod)</code> to reveal the variety of outputs produced by &lsquo;npreg&rsquo; of the &lsquo;np&rsquo; package.
The user can access all of them at will by using the dollar notation of R.
</p>


<h3>Note</h3>

<p>This is a work horse for causal identification.
</p>


<h3>Author(s)</h3>

<p>Prof. H. D. Vinod, Economics Dept., Fordham University, NY
</p>


<h3>References</h3>

<p>Vinod, H. D.'Generalized Correlation and Kernel Causality with 
Applications in Development Economics' in Communications in 
Statistics -Simulation and Computation, 2015, 
<a href="https://doi.org/10.1080/03610918.2015.1122048">doi:10.1080/03610918.2015.1122048</a>
</p>


<h3>See Also</h3>

<p>See <code><a href="#topic+kern_ctrl">kern_ctrl</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
set.seed(34);x=matrix(sample(1:600)[1:50],ncol=2)
require(np); options(np.messages=FALSE)
k1=kern(x[,1],x[,2])
print(k1$R2) #prints the R square of the kernel regression

## End(Not run)

</code></pre>

<hr>
<h2 id='kern_ctrl'>Kernel regression with control variables and optional residuals and gradients.</h2><span id='topic+kern_ctrl'></span>

<h3>Description</h3>

<p>Allowing matrix input of control variables, this function runs kernel regression 
with options for residuals and gradients.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>kern_ctrl(
  dep.y,
  reg.x,
  ctrl,
  tol = 0.1,
  ftol = 0.1,
  gradients = FALSE,
  residuals = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="kern_ctrl_+3A_dep.y">dep.y</code></td>
<td>
<p>Data on the dependent (response) variable</p>
</td></tr>
<tr><td><code id="kern_ctrl_+3A_reg.x">reg.x</code></td>
<td>
<p>Data on the regressor (stimulus) variable</p>
</td></tr>
<tr><td><code id="kern_ctrl_+3A_ctrl">ctrl</code></td>
<td>
<p>Data matrix on the control variable(s) kept outside the 
causal paths.
A constant vector is not allowed as a control variable.</p>
</td></tr>
<tr><td><code id="kern_ctrl_+3A_tol">tol</code></td>
<td>
<p>Tolerance on the position of located minima of the cross-validation 
function (default=0.1)</p>
</td></tr>
<tr><td><code id="kern_ctrl_+3A_ftol">ftol</code></td>
<td>
<p>Fractional tolerance on the value of cross validation function
evaluated at local minima  (default=0.1)</p>
</td></tr>
<tr><td><code id="kern_ctrl_+3A_gradients">gradients</code></td>
<td>
<p>Set to TRUE if gradients computations are desired</p>
</td></tr>
<tr><td><code id="kern_ctrl_+3A_residuals">residuals</code></td>
<td>
<p>Set to TRUE if residuals are desired</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Creates a model object &lsquo;mod&rsquo; containing the entire kernel regression output.
If this function is called as <code>mod=kern_ctrl(x,y,ctrl=z)</code>, the researcher can
simply type <code>names(mod)</code> to reveal the large variety of outputs produced by &lsquo;npreg&rsquo; 
of the &lsquo;np&rsquo; package.
The user can access all of them at will using the dollar notation of R.
</p>


<h3>Note</h3>

<p>This is a work horse for causal identification.
</p>


<h3>Author(s)</h3>

<p>Prof. H. D. Vinod, Economics Dept., Fordham University, NY
</p>


<h3>References</h3>

<p>Vinod, H. D. 'Generalized Correlation and Kernel Causality with 
Applications in Development Economics' in Communications in 
Statistics -Simulation and Computation, 2015, 
<a href="https://doi.org/10.1080/03610918.2015.1122048">doi:10.1080/03610918.2015.1122048</a>
</p>


<h3>See Also</h3>

<p>See <code><a href="#topic+kern">kern</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
set.seed(34);x=matrix(sample(1:600)[1:50],ncol=5)
require(np)
k1=kern_ctrl(x[,1],x[,2],ctrl=x[,4:5])
print(k1$R2) #prints the R square of the kernel regression

## End(Not run)

</code></pre>

<hr>
<h2 id='kern2'>Kernel regression version 2 with optional residuals and gradients
with regtype=&quot;ll&quot; for local linear, bwmethod=&quot;cv.aic&quot; for AIC-based
bandwidth selection.</h2><span id='topic+kern2'></span>

<h3>Description</h3>

<p>Kernel regression version 2 with optional residuals and gradients
with regtype=&quot;ll&quot; for local linear, bwmethod=&quot;cv.aic&quot; for AIC-based
bandwidth selection.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>kern2(
  dep.y,
  reg.x,
  tol = 0.1,
  ftol = 0.1,
  gradients = FALSE,
  residuals = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="kern2_+3A_dep.y">dep.y</code></td>
<td>
<p>Data on the dependent (response) variable</p>
</td></tr>
<tr><td><code id="kern2_+3A_reg.x">reg.x</code></td>
<td>
<p>Data on the regressor (stimulus) variables</p>
</td></tr>
<tr><td><code id="kern2_+3A_tol">tol</code></td>
<td>
<p>Tolerance on the position of located minima of the cross-validation 
function (default =0.1)</p>
</td></tr>
<tr><td><code id="kern2_+3A_ftol">ftol</code></td>
<td>
<p>Fractional tolerance on the value of cross validation function
evaluated at local minima (default =0.1)</p>
</td></tr>
<tr><td><code id="kern2_+3A_gradients">gradients</code></td>
<td>
<p>Make this TRUE if gradients computations are desired</p>
</td></tr>
<tr><td><code id="kern2_+3A_residuals">residuals</code></td>
<td>
<p>Make this TRUE if residuals are desired</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Creates a model object &lsquo;mod&rsquo; containing the entire kernel regression output.
Type <code>names(mod)</code> to reveal the variety of outputs produced by &lsquo;npreg&rsquo; of the &lsquo;np&rsquo; package.
The user can access all of them at will by using the dollar notation of R.
</p>


<h3>Note</h3>

<p>This is version 2 (&quot;ll&quot;,&quot;cv.aic&quot;) of a work horse for causal identification.
</p>


<h3>Author(s)</h3>

<p>Prof. H. D. Vinod, Economics Dept., Fordham University, NY
</p>


<h3>References</h3>

<p>Vinod, H. D.'Generalized Correlation and Kernel Causality with 
Applications in Development Economics' in Communications in 
Statistics -Simulation and Computation, 2015, 
<a href="https://doi.org/10.1080/03610918.2015.1122048">doi:10.1080/03610918.2015.1122048</a>
</p>


<h3>See Also</h3>

<p>See <code><a href="#topic+kern_ctrl">kern_ctrl</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
set.seed(34);x=matrix(sample(1:600)[1:50],ncol=2)
require(np); options(np.messages=FALSE)
k1=kern(x[,1],x[,2])
print(k1$R2) #prints the R square of the kernel regression

## End(Not run)

</code></pre>

<hr>
<h2 id='kern2ctrl'>Kernel regression with control variables and optional residuals and gradients.
version 2 regtype=&quot;ll&quot; for local linear, bwmethod=&quot;cv.aic&quot; for AIC-based
bandwidth selection. It admits control variables.</h2><span id='topic+kern2ctrl'></span>

<h3>Description</h3>

<p>Kernel regression with control variables and optional residuals and gradients.
version 2 regtype=&quot;ll&quot; for local linear, bwmethod=&quot;cv.aic&quot; for AIC-based
bandwidth selection. It admits control variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>kern2ctrl(
  dep.y,
  reg.x,
  ctrl,
  tol = 0.1,
  ftol = 0.1,
  gradients = FALSE,
  residuals = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="kern2ctrl_+3A_dep.y">dep.y</code></td>
<td>
<p>Data on the dependent (response) variable</p>
</td></tr>
<tr><td><code id="kern2ctrl_+3A_reg.x">reg.x</code></td>
<td>
<p>Data on the regressor (stimulus) variable</p>
</td></tr>
<tr><td><code id="kern2ctrl_+3A_ctrl">ctrl</code></td>
<td>
<p>Data matrix on the control variable(s) kept outside the 
causal paths.
A constant vector is not allowed as a control variable.</p>
</td></tr>
<tr><td><code id="kern2ctrl_+3A_tol">tol</code></td>
<td>
<p>Tolerance on the position of located minima of the cross-validation 
function (default=0.1)</p>
</td></tr>
<tr><td><code id="kern2ctrl_+3A_ftol">ftol</code></td>
<td>
<p>Fractional tolerance on the value of cross validation function
evaluated at local minima  (default=0.1)</p>
</td></tr>
<tr><td><code id="kern2ctrl_+3A_gradients">gradients</code></td>
<td>
<p>Set to TRUE if gradients computations are desired</p>
</td></tr>
<tr><td><code id="kern2ctrl_+3A_residuals">residuals</code></td>
<td>
<p>Set to TRUE if residuals are desired</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Creates a model object &lsquo;mod&rsquo; containing the entire kernel regression output.
If this function is called as <code>mod=kern_ctrl(x,y,ctrl=z)</code>, the researcher can
simply type <code>names(mod)</code> to reveal the large variety of outputs produced by &lsquo;npreg&rsquo; 
of the &lsquo;np&rsquo; package.
The user can access all of them at will using the dollar notation of R.
</p>


<h3>Note</h3>

<p>This is version 2 (&quot;ll&quot;,&quot;cv.aic&quot;) of a work horse for causal identification.
</p>


<h3>Author(s)</h3>

<p>Prof. H. D. Vinod, Economics Dept., Fordham University, NY
</p>


<h3>References</h3>

<p>Vinod, H. D. 'Generalized Correlation and Kernel Causality with 
Applications in Development Economics' in Communications in 
Statistics -Simulation and Computation, 2015, 
<a href="https://doi.org/10.1080/03610918.2015.1122048">doi:10.1080/03610918.2015.1122048</a>
</p>


<h3>See Also</h3>

<p>See <code><a href="#topic+kern">kern</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
set.seed(34);x=matrix(sample(1:600)[1:50],ncol=5)
require(np)
k1=kern_ctrl(x[,1],x[,2],ctrl=x[,4:5])
print(k1$R2) #prints the R square of the kernel regression

## End(Not run)

</code></pre>

<hr>
<h2 id='mag'>Approximate overall magnitudes of kernel regression partials dx/dy and dy/dx.</h2><span id='topic+mag'></span>

<h3>Description</h3>

<p>Uses Vinod (2015) and runs kernel regression of x on y,  and also of y on x
by using the &lsquo;np&rsquo; package. The function goes on to compute a summary magnitude
of the overall approximate partial derivative dx/dy (and dy/dx), 
after adjusting for units by using
an appropriate  ratio of standard deviations.  Of course, 
the real partial derivatives of nonlinear functions
are generally  distinct for each observation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mag(x, y)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mag_+3A_x">x</code></td>
<td>
<p>Vector of data on the dependent variable</p>
</td></tr>
<tr><td><code id="mag_+3A_y">y</code></td>
<td>
<p>Vector of data on the regressor</p>
</td></tr>
</table>


<h3>Value</h3>

<p>vector of two magnitudes of kernel regression partials dx/dy and dy/dx.
</p>


<h3>Note</h3>

<p>This function is intended for use only after the direction of causal path
is already determined by various functions in this package (e.g. <code>somePairs</code>).
For example, if the researcher knows that x causes y, then only 
dy/dx denoted by dydx is relevant.
The other output of the function dxdy is to be ignored.
Similarly, only &lsquo;dxdy&rsquo; is relevant if y is known to be the cause of x.
</p>


<h3>Author(s)</h3>

<p>Prof. H. D. Vinod, Economics Dept., Fordham University, NY
</p>


<h3>References</h3>

<p>Vinod, H. D. 'Generalized Correlation and Kernel Causality with
Applications in Development Economics' in Communications in
Statistics -Simulation and Computation, 2015,
<a href="https://doi.org/10.1080/03610918.2015.1122048">doi:10.1080/03610918.2015.1122048</a>
</p>
<p>Vinod, H. D. 'Matrix Algebra Topics in Statistics and Economics
Using R', Chapter 4 in Handbook of Statistics: Computational Statistics
with R, Vol.32, co-editors: M. B. Rao and C.R. Rao. New York:
North Holland, Elsevier Science Publishers, 2014, pp. 143-176.
</p>


<h3>See Also</h3>

<p>See  <code><a href="#topic+mag_ctrl">mag_ctrl</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(123);x=sample(1:10);y=1+2*x+rnorm(10)
mag(x,y)#dxdy approx=.5 and dydx approx=2 will be nice.

</code></pre>

<hr>
<h2 id='mag_ctrl'>After removing control variables, magnitude of effect of x on y, and of y on x.</h2><span id='topic+mag_ctrl'></span>

<h3>Description</h3>

<p>Uses Vinod (2015) and runs kernel regressions: <code>x~ y + ctrl</code>
and  <code>x~ ctrl</code> to evaluate the &lsquo;incremental change&rsquo; in R-squares.
Let (rxy;ctrl) denote the square root of that &lsquo;incremental change&rsquo; after its sign is made the
same as that of the Pearson correlation coefficient from
<code>cor(x,y)</code>). One can interpret (rxy;ctrl) as
a generalized partial correlation coefficient when x is regressed on y after removing
the effect of control variable(s) in <code>ctrl</code>.  It is more general than the usual partial 
correlation coefficient, since this one
allows for nonlinear relations among variables. 
Next, the function computes &lsquo;dxdy&rsquo; obtained by multiplying (rxy;ctrl) by the ratio of
standard deviations, <code>sd(x)/sd(y)</code>. Now our &lsquo;dxdy&rsquo; approximates the magnitude of the
partial derivative (dx/dy) in a causal model where y is the cause and x is the effect.
The function also reports entirely analogous &lsquo;dydx&rsquo; obtained by interchanging x and y.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mag_ctrl(x, y, ctrl)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mag_ctrl_+3A_x">x</code></td>
<td>
<p>Vector of data on the dependent variable.</p>
</td></tr>
<tr><td><code id="mag_ctrl_+3A_y">y</code></td>
<td>
<p>Vector of data on the regressor.</p>
</td></tr>
<tr><td><code id="mag_ctrl_+3A_ctrl">ctrl</code></td>
<td>
<p>data matrix for designated control variable(s) outside causal paths.
A constant vector is not allowed as a control variable.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>vector of two magnitudes &lsquo;dxdy&rsquo; (effect when x is regressed on y) and 
&lsquo;dydx&rsquo; for reverse regression.  Both regressions remove the effect of control variable(s).
</p>


<h3>Note</h3>

<p>This function is intended for use only after the causal path direction 
is already determined by various functions in this package (e.g. <code>someCPairs</code>).
That is, after the researcher knows whether x causes y or vice versa.
The output of this function is a vector of two numbers: (dxdy, dydx), in that order,
representing the magnitude of effect of one variable on the other.
We expect the researcher to use only &lsquo;dxdy&rsquo; if y is the 
known cause, or &lsquo;dydx&rsquo; if x is the cause. These approximate overall measures
may not be well-defined in some applications, because 
the real partial derivatives of nonlinear functions
are generally  distinct for each evaluation point.
</p>


<h3>Author(s)</h3>

<p>Prof. H. D. Vinod, Economics Dept., Fordham University, NY
</p>


<h3>References</h3>

<p>Vinod, H. D. 'Generalized Correlation and Kernel Causality with
Applications in Development Economics' in Communications in
Statistics -Simulation and Computation, 2015,
<a href="https://doi.org/10.1080/03610918.2015.1122048">doi:10.1080/03610918.2015.1122048</a>
</p>
<p>Vinod, H. D. 'Matrix Algebra Topics in Statistics and Economics
Using R', Chapter 4 in Handbook of Statistics: Computational Statistics
with R, Vol.32, co-editors: M. B. Rao and C. R. Rao. New York:
North Holland, Elsevier Science Publishers, 2014, pp. 143-176.
</p>


<h3>See Also</h3>

<p>See  <code><a href="#topic+mag">mag</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(123);x=sample(1:10); z=runif(10); y=1+2*x+3*z+rnorm(10)
options(np.messages=FALSE)
mag_ctrl(x,y,z)#dx/dy=0.47 is approximately 0.5, but dy/dx=1.41 is not approx=2,

</code></pre>

<hr>
<h2 id='min.e0'>
internal min.e0
</h2><span id='topic+min.e0'></span>

<h3>Description</h3>

<p>intended for internal use only
</p>


<h3>Usage</h3>

<pre><code class='language-R'>min.e0</code></pre>

<hr>
<h2 id='minor'>Function to do compute the minor of a matrix defined by row r and column c.</h2><span id='topic+minor'></span>

<h3>Description</h3>

<p>Function to do compute the minor of a matrix defined by row r and column c.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>minor(x, r, c)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="minor_+3A_x">x</code></td>
<td>
<p>The input matrix</p>
</td></tr>
<tr><td><code id="minor_+3A_r">r</code></td>
<td>
<p>The row number</p>
</td></tr>
<tr><td><code id="minor_+3A_c">c</code></td>
<td>
<p>The column number</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The appropriate &lsquo;minor&rsquo; matrix defined from the input matrix.
</p>


<h3>Note</h3>

<p>This function is needed by the cofactor function.
</p>


<h3>Author(s)</h3>

<p>Prof. H. D. Vinod, Economics Dept., Fordham University, NY
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
 x=matrix(1:20,ncol=4)
minor(x,1,2)
## End(Not run)

</code></pre>

<hr>
<h2 id='momentVote'>Function compares Pearson Stats and Sharpe Ratio for a matrix of stock returns</h2><span id='topic+momentVote'></span>

<h3>Description</h3>

<p>The first step computes mean, std.dev, skewness, kurtosis (kurt),and
the Sharpe Ratio (mean/sd) representing risk-adjusted return where sd measures
the risk. The input x must be a matrix having p columns (col.names recommended).
and n rows as in the data.  If data are missing for some columns, insert NA's.
Thus x has p column of data matrix ready for comparison and ranking. 
For example, x has a matrix of stock returns.
The output matrix produced by this function has p columns for each data
column (i.e. for each stock being compared). The output matrix has
twelve rows. Top five rows have the magnitudes of 
mean, sd, skew, kurt, Sharpe ratios.  Output matrix 
rows 6 to 10 have respective ranks of moment stats. 
The output 11-th row  reports a weighted sum
of ranks with following weights mean=1,sd=-1,skew=0.5,kurt=-0.5,Sharpe Ratio=1.
User has the option to change the weights. They measure relative importance.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>momentVote(mtx, weight = c(1, -1, 0.5, -0.5, 1))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="momentVote_+3A_mtx">mtx</code></td>
<td>
<p>n by p matrix of data, For example, n stock returns
for p stocks. The mtx columns
should have some names (ticker symbols)</p>
</td></tr>
<tr><td><code id="momentVote_+3A_weight">weight</code></td>
<td>
<p>vector of reliability weights. default: mean=1, sd=-1,
skew=0.5,kurt=-0.5,sharpe=1</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Since skewness and kurtosis are measured relatively less
reliably (have greater sampling variation due to higher powers) their weight
is 0.5. Our ranking gives the smallest number 1 to the most desirable outcome.  
The 11-th line of the
output matrix has weighted sum of ranks and we suggest higher portfolio weight
be given to the column having smallest value (in the bottom line).
The 12-th row of output matrix has &lsquo;choice,&rsquo; where input weights give
the number 1 is for the top choice column of data and all other choice numbers.
The (p+1)-th column of the output matrix has the chosen weights.  The argument
weight to the &lsquo;momentVote&rsquo; function allows one to change these weights.
</p>


<h3>Value</h3>

<p>a matrix with same number of columns as in the input matrix x and
eleven rows. Top five rows have moment quantities, next five are their ranks
the eleventh row has weighted sum of ranks with the input weights (see default)
and the 12-th row has choice numbers (choice=1 is best)
</p>


<h3>Author(s)</h3>

<p>Prof. H. D. Vinod, Economics Dept., Fordham University, NY
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x1=c(1,4,7,2,6)
x2=c(3,4,8,4,7)
momentVote(cbind(x1,x2))

</code></pre>

<hr>
<h2 id='mtx'>
internal mtx
</h2><span id='topic+mtx'></span>

<h3>Description</h3>

<p>intended for internal use only
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mtx</code></pre>

<hr>
<h2 id='mtx0'>
internal mtx0
</h2><span id='topic+mtx0'></span>

<h3>Description</h3>

<p>intended for internal use only
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mtx0</code></pre>

<hr>
<h2 id='mtx2'>
internal mtx2
</h2><span id='topic+mtx2'></span>

<h3>Description</h3>

<p>intended for internal use only
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mtx2</code></pre>

<hr>
<h2 id='n'>
internal n
</h2><span id='topic+n'></span>

<h3>Description</h3>

<p>intended for internal use
</p>


<h3>Usage</h3>

<pre><code class='language-R'>n</code></pre>


<h3>Format</h3>

<p>The format is:
int 78
</p>

<hr>
<h2 id='nall'>
internal nall
</h2><span id='topic+nall'></span>

<h3>Description</h3>

<p>intended for internal use only
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nall</code></pre>

<hr>
<h2 id='nam.badCol'>
internal nam.badCol
</h2><span id='topic+nam.badCol'></span>

<h3>Description</h3>

<p>intended for internal use only
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nam.badCol</code></pre>

<hr>
<h2 id='nam.goodCol'>
internal nam.goodCol
</h2><span id='topic+nam.goodCol'></span>

<h3>Description</h3>

<p>intended for internal use only
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nam.goodCol</code></pre>

<hr>
<h2 id='nam.mtx0'>
internal nam.mtx0
</h2><span id='topic+nam.mtx0'></span>

<h3>Description</h3>

<p>intended for internal use only
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nam.mtx0</code></pre>

<hr>
<h2 id='napair'>Function to do pairwise deletion of missing rows.</h2><span id='topic+napair'></span>

<h3>Description</h3>

<p>The aim in pair-wise deletions is to retain the largest 
number of available data pairs with all non-missing data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>napair(x, y)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="napair_+3A_x">x</code></td>
<td>
<p>Vector of x data</p>
</td></tr>
<tr><td><code id="napair_+3A_y">y</code></td>
<td>
<p>Vector of y data</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>newx</code></td>
<td>
<p>A new vector x after removing pairwise missing data</p>
</td></tr> 
<tr><td><code>newy</code></td>
<td>
<p>A new vector y after removing pairwise missing data</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Prof. H. D. Vinod, Economics Dept., Fordham University, NY
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
x=sample(1:10);y=sample(1:10);x[2]=NA; y[3]=NA
napair(x,y)
## End(Not run)

</code></pre>

<hr>
<h2 id='naTriple'>Function to do matched deletion of missing rows from x, y 
and z variable(s).</h2><span id='topic+naTriple'></span>

<h3>Description</h3>

<p>The aim in three-way deletions is to retain only the largest 
number of available data triplets with all non-missing data.
This works where naTriplet fails (e.g.parcorVecH()). This is
called by parcorHijk
</p>


<h3>Usage</h3>

<pre><code class='language-R'>naTriple(x, y, z)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="naTriple_+3A_x">x</code></td>
<td>
<p>Vector of x data</p>
</td></tr>
<tr><td><code id="naTriple_+3A_y">y</code></td>
<td>
<p>Vector of y data</p>
</td></tr>
<tr><td><code id="naTriple_+3A_z">z</code></td>
<td>
<p>vector or a matrix of additional variable(s)</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>newx</code></td>
<td>
<p>A new vector x after removing triplet-wise missing data</p>
</td></tr> 
<tr><td><code>newy</code></td>
<td>
<p>A new vector or matrix y after removing triplet-wise missing data</p>
</td></tr> 
<tr><td><code>newz</code></td>
<td>
<p>A new vector or matrix ctrl after removing triplet-wise missing data</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Prof. H. D. Vinod, Economics Dept., Fordham University, NY
</p>


<h3>See Also</h3>

<p>See <code><a href="#topic+napair">napair</a></code> <code><a href="#topic+naTriplet">naTriplet</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
x=sample(1:10);y=sample(1:10);x[2]=NA; y[3]=NA
w=sample(2:11)
naTriple(x,y,w)
## End(Not run)

</code></pre>

<hr>
<h2 id='naTriplet'>Function to do matched deletion of missing rows from x, y and control variable(s).</h2><span id='topic+naTriplet'></span>

<h3>Description</h3>

<p>The aim in three-way deletions is to retain only the largest 
number of available data triplets with all non-missing data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>naTriplet(x, y, ctrl)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="naTriplet_+3A_x">x</code></td>
<td>
<p>Vector of x data</p>
</td></tr>
<tr><td><code id="naTriplet_+3A_y">y</code></td>
<td>
<p>Vector of y data</p>
</td></tr>
<tr><td><code id="naTriplet_+3A_ctrl">ctrl</code></td>
<td>
<p>Data matrix on the control variable(s) kept beyond causal path determinations</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>newx</code></td>
<td>
<p>A new vector x after removing triplet-wise missing data</p>
</td></tr> 
<tr><td><code>newy</code></td>
<td>
<p>A new vector or matrix y after removing triplet-wise missing data</p>
</td></tr> 
<tr><td><code>newctrl</code></td>
<td>
<p>A new vector or matrix ctrl after removing triplet-wise missing data</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Prof. H. D. Vinod, Economics Dept., Fordham University, NY
</p>


<h3>See Also</h3>

<p>See <code><a href="#topic+napair">napair</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
x=sample(1:10);y=sample(1:10);x[2]=NA; y[3]=NA
w=sample(2:11)
naTriplet(x,y,w)
## End(Not run)

</code></pre>

<hr>
<h2 id='NLhat'>Compute fitted values from kernel regression of x on y and y on x</h2><span id='topic+NLhat'></span>

<h3>Description</h3>

<p>This is an auxiliary function for &lsquo;gmcmtxBlk.&rsquo; It uses 
two numerical vectors (x, y) of same length to create two vectors
(xhat, yhat) of fitted values using nonlinear kernel regressions.
It
uses package &lsquo;np&rsquo; called by 
<code>kern</code> function to kernel regress x on y, and conversely y on x. 
It uses the option &lsquo;residuals=TRUE&rsquo; of &lsquo;kern&rsquo;
</p>


<h3>Usage</h3>

<pre><code class='language-R'>NLhat(x, y)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="NLhat_+3A_x">x</code></td>
<td>
<p>A column vector of x data</p>
</td></tr>
<tr><td><code id="NLhat_+3A_y">y</code></td>
<td>
<p>A column vector of y data</p>
</td></tr>
</table>


<h3>Value</h3>

<p>two vectors named xhat and yhat for fitted values
</p>


<h3>Author(s)</h3>

<p>Prof. H. D. Vinod, Economics Dept., Fordham University, NY
</p>


<h3>See Also</h3>

<p>See Also as <code><a href="#topic+gmcmtxBlk">gmcmtxBlk</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

## Not run: 
set.seed(34);x=sample(1:15);y=sample(1:15)
NLhat(x,y)
## End(Not run)

</code></pre>

<hr>
<h2 id='out1'>
internal out1
</h2><span id='topic+out1'></span>

<h3>Description</h3>

<p>intended for internal use only
</p>


<h3>Usage</h3>

<pre><code class='language-R'>out1</code></pre>

<hr>
<h2 id='outOFsamp'>Compare out-of-sample portfolio choice algorithms by a leave-percent-out method.</h2><span id='topic+outOFsamp'></span>

<h3>Description</h3>

<p>This function randomly leaves out 5 percent (&lsquo;pctOut&rsquo;=5 by default) 
data and finds portfolio choice by seven different
portfolio selection algorithms using the data on the remaining 95 percent (say). 
The randomization removes any bias in time series definitions of &lsquo;out-of-sample&rsquo; data.
For example, the input to <code>outOFsamp(.)</code> named &lsquo;mtx&rsquo; is a matrix with 
p columns for p stocks and n returns. Also, let  the maximum number of
stocks admitted to belong in the portfolio be four, or &lsquo;maxChosen=4&rsquo;.
Now <code>outOFsamp</code> function computes the returns earned by the
seven portfolio selection algorithms, called
&quot;SD1&quot;, &quot;SD2&quot;, &quot;SD3&quot;, &quot;SD4&quot;, &quot;SDAll4&quot;, &quot;decile,&quot; and &quot;moment,&quot; where SDAll4 refers
to a weighted sum of SD1 to SD4 algorithms. Each algorithm provides
a choice ranking of p stocks with choice values 1,2,3,..,p where stock ranked
1 should get the highest portfolio weight.
The <code>outOFsamp</code> function then calls the
function &lsquo;rank2return,&rsquo; which uses these rank choice numbers to the selected
&lsquo;maxChosen&rsquo; stocks.  The allocation is linearly declining. For example, it is
4/10, 3/10, 2/10, and 1/10, with the top choice stock receiving 4/10 of the capital.
Each choice of &lsquo;pctOut&rsquo; rows of the &lsquo;mtx&rsquo; data yields an outOFsamp return for each
of the seven portfolio selection algorithms.  These outOFsamp return
computations are repeated <code>reps</code> times. 
A new random selection of &lsquo;pctOut&rsquo; rows (must be 2 or more) of data is made
for each repetition. We set 
reps=20 by default. The low default is set
to save processing time in early phases, but we recommend reps=100+. 
The final choice of stock-picking algorithm out of seven
is suggested by the one yielding the largest average out-of-sample 
return over the &lsquo;reps&rsquo; repetitions.'Its standard deviation
measures the variability of performance over the &lsquo;reps&rsquo; repetitions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>outOFsamp(mtx, pctOut = 5, reps = 10, seed = 23, maxChosen = 2, verbo = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="outOFsamp_+3A_mtx">mtx</code></td>
<td>
<p>matrix size n by p of data on n returns from p stocks</p>
</td></tr>
<tr><td><code id="outOFsamp_+3A_pctout">pctOut</code></td>
<td>
<p>percent of n randomly chosen rows left out as out-of-sample, default=5
percent. One must leave out at least two rows of data</p>
</td></tr>
<tr><td><code id="outOFsamp_+3A_reps">reps</code></td>
<td>
<p>number of random repetitions of left-out rows over which we average
the out-of-sample performance of a stock-picking algorithm,
default reps=20</p>
</td></tr>
<tr><td><code id="outOFsamp_+3A_seed">seed</code></td>
<td>
<p>seed for random number generation, default =23</p>
</td></tr>
<tr><td><code id="outOFsamp_+3A_maxchosen">maxChosen</code></td>
<td>
<p>number of stocks (out of p) with nonzero weights in the portfolio</p>
</td></tr>
<tr><td><code id="outOFsamp_+3A_verbo">verbo</code></td>
<td>
<p>logical, TRUE means print details, default=FALSE</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a matrix called &lsquo;avgRet&rsquo; with seven columns for seven stock-picking
algorithms &quot;SD1&quot;,&quot;SD2&quot;,&quot;SD3&quot;,&quot;SD4&quot;,&quot;SDAll4&quot;,&quot;decile&quot;,and &quot;moment,&quot; containing
out-of-sample average returns for linearly declining allocation in a portfolio.
The user needs to change rank2return() for alternate portfolio allocations.
</p>


<h3>Note</h3>

<p>The traditional time-series out-of-sample leaves out the last few
time periods, and estimates the stock-picking model using part of the data
time periods. The pandemic of 2019 has revealed that the traditional
out-of-sample would have a severe bias in favor of pessimistic stock-picking
algorithms.  The traditional method is fundamentally flawed since it is
sensitive to the trends (ups and downs) in the out-of-sample period. The
method proposed here is free from such biases. The stock-picking algorithm
recommended by our outOFsamp() is claimed to be robust against such biases.
</p>


<h3>Author(s)</h3>

<p>Prof. H. D. Vinod, Economics Dept., Fordham University, NY
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rank2return">rank2return</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
x1=c(2,5,6,9,13,18,21,5,11,14,4,7,12,13,6,3,8,1,15,2,10,9)
x2=c(3,6,9,12,14,19,27,9,11,2,3,8,1,6,15,10,13,14,5,7,4,12)
x3=c(2,6,NA,11,13,25,25,11,9,10,12,6,4,3,2,1,7,8,5,15,14,13)
mtx=cbind(x1,x2,x3)
mtx=mtx[complete.cases(mtx),]
os=outOFsamp(mtx,verbo=FALSE,maxChosen=2, reps=3)
apply(os,2,mean)
## End(Not run)
</code></pre>

<hr>
<h2 id='outOFsell'>Compare out-of-sample (short) selling algorithms by a leave-percent-out method.</h2><span id='topic+outOFsell'></span>

<h3>Description</h3>

<p>This function randomly leaves out 5 percent (&lsquo;pctOut&rsquo;=5 by default) 
data and finds portfolio choice to sell by seven different
portfolio selection algorithms using the data on the remaining 95 percent (say). 
The randomization removes any bias in time series definitions of &lsquo;out-of-sample&rsquo; data.
For example, the input to <code>outOFsamp(.)</code> named &lsquo;mtx&rsquo; is a matrix with 
p columns for p stocks and n returns. Also, let  the maximum number of
stocks admitted to belong in the sell portfolio be four, or &lsquo;maxChosen=4&rsquo;.
Now <code>outOFsamp</code> function computes the returns earned by the
seven portfolio selection algorithms, called
&quot;SD1&quot;, &quot;SD2&quot;, &quot;SD3&quot;, &quot;SD4&quot;, &quot;SDAll4&quot;, &quot;decile,&quot; and &quot;moment,&quot; where SDAll4 refers
to a weighted sum of SD1 to SD4 algorithms. Each algorithm provides
a choice ranking of p stocks with choice values 1,2,3,..,p where stock ranked
p should get the highest portfolio weight. (worst is sold)
The <code>outOFsamp</code> function then calls the
function &lsquo;rank2sell,&rsquo; which uses these rank choice numbers to the selected
&lsquo;maxChosen&rsquo; stocks.  The allocation is linearly declining. For example, it is
1/10, 2/10, 3/10, and 4/10, with the worst return stock
(top choice for selling)  receiving highest proportion of the capital
designated for selling.
Each choice of &lsquo;pctOut&rsquo; rows of the &lsquo;mtx&rsquo; data yields an outOFsamp return for each
of the seven portfolio selection algorithms.  These outOFsamp return
computations are repeated <code>reps</code> times. 
A new random selection of &lsquo;pctOut&rsquo; rows (must be 2 or more) of data is made
for each repetition. We set 
reps=20 by default. The low default is set
to save processing time in early phases, but we recommend reps=100+. 
The final choice of stock-selling algorithm out of seven
is suggested by the average out-of-sample return over the &lsquo;reps&rsquo; repetitions.
This function is sell version of <code>outOFsamp()</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>outOFsell(mtx, pctOut = 5, reps = 10, seed = 23, maxChosen = 2, verbo = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="outOFsell_+3A_mtx">mtx</code></td>
<td>
<p>matrix size n by p of data on n returns from p stocks</p>
</td></tr>
<tr><td><code id="outOFsell_+3A_pctout">pctOut</code></td>
<td>
<p>percent of n randomly chosen rows left out as out-of-sample, default=5
percent. One must leave out at least two rows of data</p>
</td></tr>
<tr><td><code id="outOFsell_+3A_reps">reps</code></td>
<td>
<p>number of random repetitions of left-out rows over which we average
the out-of-sample performance of a stock-picking algorithm,
default reps=20</p>
</td></tr>
<tr><td><code id="outOFsell_+3A_seed">seed</code></td>
<td>
<p>seed for random number generation, default =23</p>
</td></tr>
<tr><td><code id="outOFsell_+3A_maxchosen">maxChosen</code></td>
<td>
<p>number of stocks (out of p) with nonzero weights in the portfolio</p>
</td></tr>
<tr><td><code id="outOFsell_+3A_verbo">verbo</code></td>
<td>
<p>logical, TRUE means print details, default=FALSE</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a matrix called &lsquo;avgRet&rsquo; with seven columns for seven stock-picking
algorithms &quot;SD1&quot;,&quot;SD2&quot;,&quot;SD3&quot;,&quot;SD4&quot;,&quot;SDAll4&quot;,&quot;decile&quot;,and &quot;moment,&quot; containing
out-of-sample average returns for linearly declining allocation in a portfolio.
User needs to change rank2sell() for alternate portfolio allocations.
</p>


<h3>Note</h3>

<p>The traditional time-series out-of-sample leaves out the last few
time periods, and estimates the stock-picking model using part of the data
time periods. The pandemic of 2019 has revealed that the traditional
out-of-sample would have a severe bias in favor of pessimistic stock-picking
algorithms.  The traditional method is fundamentally flawed since it is
sensitive to the trends (ups and downs) in the out-of-sample period. The
method proposed here is free from such biases. The stock-picking algorithm
recommended by our outOFsamp() is claimed to be robust against such biases.
</p>


<h3>Author(s)</h3>

<p>Prof. H. D. Vinod, Economics Dept., Fordham University, NY
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rank2sell">rank2sell</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
x1=c(2,5,6,9,13,18,21,5,11,14,4,7,12,13,6,3,8,1,15,2,10,9)
x2=c(3,6,9,12,14,19,27,9,11,2,3,8,1,6,15,10,13,14,5,7,4,12)
x3=c(2,6,NA,11,13,25,25,11,9,10,12,6,4,3,2,1,7,8,5,15,14,13)
mtx=cbind(x1,x2,x3)
mtx=mtx[complete.cases(mtx),]
os=outOFsell(mtx,verbo=FALSE,maxChosen=2, reps=3)
apply(os,2,mean)
## End(Not run)
</code></pre>

<hr>
<h2 id='p1'>
internal p1
</h2><span id='topic+p1'></span>

<h3>Description</h3>

<p>intended for internal use only
</p>


<h3>Usage</h3>

<pre><code class='language-R'>p1</code></pre>

<hr>
<h2 id='Panel2Lag'>Function to compute a vector of 2 lagged values of a variable from panel data.</h2><span id='topic+Panel2Lag'></span>

<h3>Description</h3>

<p>The panel data have a set of time series for each entity (e.g. country)
arranged such that all time series data for one entity is together. The
data for the second entity should be below the entire data for first entity.
When a variable is lagged twice, special care is needed to insert NA's for
the first two time points (e.g. weeks) for each entity (country).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Panel2Lag(ID, xj)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Panel2Lag_+3A_id">ID</code></td>
<td>
<p>Location of the column having time identities (e.g. the week number)</p>
</td></tr>
<tr><td><code id="Panel2Lag_+3A_xj">xj</code></td>
<td>
<p>Data on variable to be lagged linked to ID</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Vector containing  2 lagged values of xj.
</p>


<h3>Note</h3>

<p>This function is provided for convenient user modifications.
</p>


<h3>Author(s)</h3>

<p>Prof. H. D. Vinod, Economics Dept., Fordham University, NY
</p>


<h3>See Also</h3>

<p>A more general function <code><a href="#topic+PanelLag">PanelLag</a></code> has examples.
</p>

<hr>
<h2 id='PanelLag'>Function for computing a vector of one-lagged values of xj, a variable from panel data.</h2><span id='topic+PanelLag'></span>

<h3>Description</h3>

<p>Panel data have a set of time series for each entity (e.g. country)
arranged such that all time series data for one entity is together, and the
data for the second entity should be below the entire data for first entity
and so on for entities. In such a data setup,
When a variable is lagged once, special care is needed to insert an NA for
the first time point in the data (e.g. week) for each entity.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PanelLag(ID, xj, lag = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PanelLag_+3A_id">ID</code></td>
<td>
<p>Location of the column having time identities (e.g. week number).</p>
</td></tr>
<tr><td><code id="PanelLag_+3A_xj">xj</code></td>
<td>
<p>Data vector of variable to be lagged and is linked with the ID.</p>
</td></tr>
<tr><td><code id="PanelLag_+3A_lag">lag</code></td>
<td>
<p>Number of lags desired (lag=1 is the default).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Vector containing one-lagged values of variable xj.
</p>


<h3>Author(s)</h3>

<p>Prof. H. D. Vinod, Economics Dept., Fordham University, NY
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
indiv=gl(6,12,labels=LETTERS[1:6])  
#creates A,A,A 12 times B B B also 12 times etc.
set.seed(99);cost=sample(30:90, 72, replace=TRUE)
revenu=sample(50:110, 72, replace=TRUE); month=rep(1:12,6)
df=data.frame(indiv,month,cost,revenu);head(df);tail(df)
L2cost=PanelLag(ID=month,xj=df[,'cost'], lag=2)
head(L2cost)
tail(L2cost)

gmcmtx0(cbind(revenu,cost,L2cost))

gmcxy_np(revenu,cost)

## End(Not run)

</code></pre>

<hr>
<h2 id='parcor_ijk'>Generalized partial correlation coefficients between Xi and Xj, after removing the
effect of xk, via nonparametric regression residuals.</h2><span id='topic+parcor_ijk'></span>

<h3>Description</h3>

<p>This function uses data on two column vectors, xi, xj and a third
xk which can be a vector or a matrix, usually of the remaining 
variables in the model, including control variables, if any.
It first removes missing data from all input variables. Then,
it computes residuals of kernel regression (xi on xk) and (xj on xk). 
The function reports the generalized correlation between two kernel residuals.
This version avoids ridge type adjustment present in an older version.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>parcor_ijk(xi, xj, xk)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="parcor_ijk_+3A_xi">xi</code></td>
<td>
<p>Input vector of data for variable xi</p>
</td></tr>
<tr><td><code id="parcor_ijk_+3A_xj">xj</code></td>
<td>
<p>Input vector of data for variable xj</p>
</td></tr>
<tr><td><code id="parcor_ijk_+3A_xk">xk</code></td>
<td>
<p>Input data for variables in xk, usually control variables</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>ouij</code></td>
<td>
<p>Generalized partial correlation Xi with Xj (=cause) after removing xk</p>
</td></tr>
<tr><td><code>ouji</code></td>
<td>
<p>Generalized partial correlation Xj with Xi (=cause) after removing xk</p>
</td></tr>
</table>
<p>allowing for control variables.
</p>


<h3>Note</h3>

<p>This function calls <code><a href="#topic+kern">kern</a></code>,
</p>


<h3>Author(s)</h3>

<p>Prof. H. D. Vinod, Economics Dept., Fordham University, NY.
</p>


<h3>See Also</h3>

<p>See  <code><a href="#topic+parcor_linear">parcor_linear</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
set.seed(34);x=matrix(sample(1:600)[1:99],ncol=3)
options(np.messages=FALSE)
parcor_ijk(x[,1], x[,2], x[,3])

## End(Not run)#' 
</code></pre>

<hr>
<h2 id='parcor_ijkOLD'>Generalized partial correlation coefficient between Xi and Xj after removing the
effect of all others. (older version, deprecated)</h2><span id='topic+parcor_ijkOLD'></span>

<h3>Description</h3>

<p>This function uses a generalized correlation matrix R* as input to compute
generalized partial correlations between <code class="reqn">X_i</code> and <code class="reqn">X_j</code>
where j can be any one of the remaining
variables. Computation removes the effect of all other variables in the matrix.
The user is encouraged to remove all known irrelevant rows and columns 
from the R* matrix before submitting it to this function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>parcor_ijkOLD(x, i, j)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="parcor_ijkOLD_+3A_x">x</code></td>
<td>
<p>Input a p by p matrix R* of generalized correlation coefficients.</p>
</td></tr>
<tr><td><code id="parcor_ijkOLD_+3A_i">i</code></td>
<td>
<p>A column number identifying the first variable.</p>
</td></tr>
<tr><td><code id="parcor_ijkOLD_+3A_j">j</code></td>
<td>
<p>A column number identifying the second variable.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>ouij</code></td>
<td>
<p>Partial correlation Xi with Xj (=cause) after removing all other X's</p>
</td></tr>
<tr><td><code>ouji</code></td>
<td>
<p>Partial correlation Xj with Xi (=cause) after removing all other X's</p>
</td></tr>
<tr><td><code>myk</code></td>
<td>
<p>A list of column numbers whose effect has been removed</p>
</td></tr>
</table>


<h3>Note</h3>

<p>This function calls <code><a href="#topic+minor">minor</a></code>, and <code><a href="#topic+cofactor">cofactor</a></code> and is called 
by <code>parcor_ridge</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
set.seed(34);x=matrix(sample(1:600)[1:99],ncol=3)
colnames(x)=c('V1', 'v2', 'V3')
gm1=gmcmtx0(x)
parcor_ijkOLD(gm1, 2,3)

## End(Not run)#' 
</code></pre>

<hr>
<h2 id='parcor_linear'>Partial correlation coefficient between Xi and Xj after removing the linear
effect of all others.</h2><span id='topic+parcor_linear'></span>

<h3>Description</h3>

<p>This function uses a symmetric correlation matrix R as input to compute
usual partial correlations between <code class="reqn">X_i</code> and <code class="reqn">X_j</code>
where j can be any one of the remaining
variables. Computation removes the effect of all other variables in the matrix.
The user is encouraged to remove all known irrelevant rows and columns 
from the R matrix before submitting it to this function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>parcor_linear(x, i, j)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="parcor_linear_+3A_x">x</code></td>
<td>
<p>Input a p by p matrix R of symmetric correlation coefficients.</p>
</td></tr>
<tr><td><code id="parcor_linear_+3A_i">i</code></td>
<td>
<p>A column number identifying the first variable.</p>
</td></tr>
<tr><td><code id="parcor_linear_+3A_j">j</code></td>
<td>
<p>A column number identifying the second variable.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>ouij</code></td>
<td>
<p>Partial correlation Xi with Xj after removing all other X's</p>
</td></tr>
<tr><td><code>ouji</code></td>
<td>
<p>Partial correlation Xj with Xi after removing all other X's</p>
</td></tr>
<tr><td><code>myk</code></td>
<td>
<p>A list of column numbers whose effect has been removed</p>
</td></tr>
</table>


<h3>Note</h3>

<p>This function calls <code><a href="#topic+minor">minor</a></code>, and <code><a href="#topic+cofactor">cofactor</a></code>
</p>


<h3>Author(s)</h3>

<p>Prof. H. D. Vinod, Economics Dept., Fordham University, NY.
</p>


<h3>See Also</h3>

<p>See  <code><a href="#topic+parcor_ijk">parcor_ijk</a></code> for generalized partial
correlation coefficients useful for causal path determinations.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
set.seed(34);x=matrix(sample(1:600)[1:99],ncol=3)
colnames(x)=c('V1', 'v2', 'V3')
c1=cor(x)
parcor_linear(c1, 2,3)

## End(Not run)

</code></pre>

<hr>
<h2 id='parcor_ridg'>Compute generalized (ridge-adjusted) partial correlation coefficients 
from matrix R*. (deprecated)</h2><span id='topic+parcor_ridg'></span>

<h3>Description</h3>

<p>This function calls <code>parcor_ijkOLD</code> function which
uses a generalized correlation matrix R* as input to compute
generalized partial correlations between <code class="reqn">X_i</code> and <code class="reqn">X_j</code>
where j can be any one of the remaining
variables. Computation removes the effect of all other variables in the matrix.
It further adjusts the resulting partial correlation coefficients to be in the
appropriate [-1,1] range by using an additive constant in the fashion 
of ridge regression.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>parcor_ridg(gmc0, dig = 4, idep = 1, verbo = FALSE, incr = 3)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="parcor_ridg_+3A_gmc0">gmc0</code></td>
<td>
<p>This must be a p by p matrix R* of generalized correlation coefficients.</p>
</td></tr>
<tr><td><code id="parcor_ridg_+3A_dig">dig</code></td>
<td>
<p>The number of digits for reporting (=4, default)</p>
</td></tr>
<tr><td><code id="parcor_ridg_+3A_idep">idep</code></td>
<td>
<p>The column number of the first variable (=1, default)</p>
</td></tr>
<tr><td><code id="parcor_ridg_+3A_verbo">verbo</code></td>
<td>
<p>Make this TRUE for detailed printing of computational steps</p>
</td></tr>
<tr><td><code id="parcor_ridg_+3A_incr">incr</code></td>
<td>
<p>incremental constant for iteratively adjusting &lsquo;ridgek&rsquo;
where ridgek is the constant times the identity matrix used to
make sure that the gmc0 matrix is positive definite. If not iteratively
increas the <code>incr</code> till all partial correlations are within the [-1,1] interval.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A five column &lsquo;out&rsquo; matrix containing partials. The first column
has the name of the <code>idep</code> variable. The
second column has the name of the j variable, while the third column has  r*(i,j | k).
The 4-th column has  r*(j,i | k) (denoted partji), and the 5-th column has rijMrji,
that is the difference in absolute values (abs(partij) - abs(partji)).
</p>


<h3>Note</h3>

<p>The ridgek constant created by the function during the first round
may not be large enough to make sure that
that other pairs of r*(i,j | k) are within the [-1,1] interval. The user may have to choose
a suitably larger input <code>incr</code> to get all relevant partial
correlation coefficients in  the correct [-1,1] interval.
</p>


<h3>Author(s)</h3>

<p>Prof. H. D. Vinod, Economics Dept., Fordham University, NY.
</p>


<h3>References</h3>

<p>Vinod, H. D. 'Generalized Correlations and Instantaneous
Causality for Data Pairs Benchmark,' (March 8, 2015)
<a href="https://www.ssrn.com/abstract=2574891">https://www.ssrn.com/abstract=2574891</a>
</p>
<p>Vinod, H. D. 'Matrix Algebra Topics in Statistics and Economics
Using R', Chapter 4 in Handbook of Statistics: Computational Statistics
with R, Vol.32, co-editors: M. B. Rao and C.R. Rao. New York:
North Holland, Elsevier Science Publishers, 2014, pp. 143-176.
</p>
<p>Vinod, H. D. &quot;A Survey of Ridge Regression and Related Techniques 
for Improvements over Ordinary Least Squares,&quot; Review of Economics and Statistics, 
Vol. 60, February 1978, pp. 121-131.
</p>


<h3>See Also</h3>

<p>See Also <code><a href="#topic+parcor_ijkOLD">parcor_ijkOLD</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(234)
z=runif(10,2,11)# z is independently created
x=sample(1:10)+z/10  #x is partly indep and partly affected by z
y=1+2*x+3*z+rnorm(10)# y depends on x and z not vice versa
mtx=cbind(x,y,z)
g1=gmcmtx0(mtx)
parcor_ijkOLD(g1,1,2) # ouji&gt; ouij implies i=x is the cause of j=y
parcor_ridg(g1,idep=1)
 
   
## Not run: 
set.seed(34);x=matrix(sample(1:600)[1:99],ncol=3)
colnames(x)=c('V1', 'v2', 'V3')
gm1=gmcmtx0(x)
parcor_ridg(gm1, idep=1)

## End(Not run)

</code></pre>

<hr>
<h2 id='parcorBijk'>Block version of generalized partial correlation coefficients between Xi 
and Xj, after removing the
effect of xk, via nonparametric regression residuals.</h2><span id='topic+parcorBijk'></span>

<h3>Description</h3>

<p>This function uses data on two column vectors, xi, xj and a third
xk which can be a vector or a matrix, usually of the remaining 
variables in the model, including control variables, if any.
It first removes missing data from all input variables. Then,
it computes residuals of kernel regression (xi on xk) and (xj on xk). 
This is a block version of parcor_ijk.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>parcorBijk(xi, xj, xk, blksiz = 10)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="parcorBijk_+3A_xi">xi</code></td>
<td>
<p>Input vector of data for variable xi</p>
</td></tr>
<tr><td><code id="parcorBijk_+3A_xj">xj</code></td>
<td>
<p>Input vector of data for variable xj</p>
</td></tr>
<tr><td><code id="parcorBijk_+3A_xk">xk</code></td>
<td>
<p>Input data for variables in xk, usually control variables</p>
</td></tr>
<tr><td><code id="parcorBijk_+3A_blksiz">blksiz</code></td>
<td>
<p>block size, default=10, if chosen blksiz &gt;n, where n=rows in matrix
then blksiz=n. That is, no blocking is done</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>ouij</code></td>
<td>
<p>Generalized partial correlation Xi with Xj (=cause) after removing xk</p>
</td></tr>
<tr><td><code>ouji</code></td>
<td>
<p>Generalized partial correlation Xj with Xi (=cause) after removing xk</p>
</td></tr>
</table>
<p>allowing for control variables.
</p>


<h3>Note</h3>

<p>This function calls <code><a href="#topic+kern">kern</a></code>,
</p>


<h3>Author(s)</h3>

<p>Prof. H. D. Vinod, Economics Dept., Fordham University, NY.
</p>


<h3>See Also</h3>

<p>See  <code><a href="#topic+parcor_ijk">parcor_ijk</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
set.seed(34);x=matrix(sample(1:600)[1:99],ncol=3)
options(np.messages=FALSE)
parcorBijk(x[,1], x[,2], x[,3], blksi=10)

## End(Not run)#' 
</code></pre>

<hr>
<h2 id='parcorBMany'>Block version reports many generalized partial correlation coefficients 
allowing control variables.</h2><span id='topic+parcorBMany'></span>

<h3>Description</h3>

<p>This function calls a block version <code>parcorBijk</code> of the function which
uses original data to compute
generalized partial correlations between <code class="reqn">X_{idep}</code> and <code class="reqn">X_j</code>
where j can be any one of the remaining
variables in the input matrix <code>mtx</code>. Partial correlations remove the effect of
variables <code class="reqn">X_k</code> other than <code class="reqn">X_i</code> and <code class="reqn">X_j</code>. Calculation further 
allows for the presence of control variable(s) (if any) to remain always outside
the input matrix and whose effect is also removed in computing partial correlations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>parcorBMany(mtx, ctrl = 0, dig = 4, idep = 1, blksiz = 10, verbo = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="parcorBMany_+3A_mtx">mtx</code></td>
<td>
<p>Input data matrix with at least 3 columns.</p>
</td></tr>
<tr><td><code id="parcorBMany_+3A_ctrl">ctrl</code></td>
<td>
<p>Input vector or matrix of data for control variable(s), 
default is ctrl=0 when control variables are absent</p>
</td></tr>
<tr><td><code id="parcorBMany_+3A_dig">dig</code></td>
<td>
<p>The number of digits for reporting (=4, default)</p>
</td></tr>
<tr><td><code id="parcorBMany_+3A_idep">idep</code></td>
<td>
<p>The column number of the dependent variable (=1, default)</p>
</td></tr>
<tr><td><code id="parcorBMany_+3A_blksiz">blksiz</code></td>
<td>
<p>block size, default=10, if chosen blksiz &gt;n, where n=rows in matrix
then blksiz=n. That is, no blocking is done</p>
</td></tr>
<tr><td><code id="parcorBMany_+3A_verbo">verbo</code></td>
<td>
<p>Make this TRUE for detailed printing of computational steps</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A five column &lsquo;out&rsquo; matrix containing partials. The first column
has the name of the <code>idep</code> variable. The
second column has the name of the j variable, while the third column 
has partial correlation coefficients  r*(i,j | k).The last column
reports the absolute difference between two partial correlations.
</p>


<h3>Note</h3>

<p>This function reports all partial
correlation coefficients, while avoiding ridge type adjustment.
</p>


<h3>Author(s)</h3>

<p>Prof. H. D. Vinod, Economics Dept., Fordham University, NY.
</p>


<h3>References</h3>

<p>Vinod, H. D. 'Generalized Correlations and Instantaneous
Causality for Data Pairs Benchmark,' (March 8, 2015)
<a href="https://www.ssrn.com/abstract=2574891">https://www.ssrn.com/abstract=2574891</a>
</p>
<p>Vinod, H. D. (2021) 'Generalized, Partial and Canonical Correlation
Coefficients' Computational Economics, 59(1), 1&ndash;28.
</p>
<p>Vinod, H. D. 'Matrix Algebra Topics in Statistics and Economics
Using R', Chapter 4 in Handbook of Statistics: Computational Statistics
with R, Vol.32, co-editors: M. B. Rao and C.R. Rao. New York:
North Holland, Elsevier Science Publishers, 2014, pp. 143-176.
</p>


<h3>See Also</h3>

<p>See Also <code><a href="#topic+parcor_ijk">parcor_ijk</a></code>, <code><a href="#topic+parcorMany">parcorMany</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(234)
z=runif(10,2,11)# z is independently created
x=sample(1:10)+z/10  #x is partly indep and partly affected by z
y=1+2*x+3*z+rnorm(10)# y depends on x and z not vice versa
mtx=cbind(x,y,z)
parcorBMany(mtx, blksiz=10)
 
   
## Not run: 
set.seed(34);x=matrix(sample(1:600)[1:99],ncol=3)
colnames(x)=c('V1', 'v2', 'V3')
parcorBMany(x, idep=1)

## End(Not run)

</code></pre>

<hr>
<h2 id='parcorHijk'>Generalized partial correlation coefficients between Xi and Xj, after removing the
effect of Xk, via OLS regression residuals.</h2><span id='topic+parcorHijk'></span>

<h3>Description</h3>

<p>This function uses data on two column vectors, xi, xj, and a third set
xk, which can be a vector or a matrix. xk usually has the remaining 
variables in the model, including control variables, if any. This function
first removes missing data from all input variables. Then,
it computes residuals of OLS (no kernel) regression (xi on xk) and (xj on xk). 
This hybrid version uses both OLS and then generalized correlation among
OLS residuals. This solves the potential problem of having too little
information content in kernel regression residuals, since kernel fits are
sometimes too close, especially when there are many variables in xk.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>parcorHijk(xi, xj, xk)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="parcorHijk_+3A_xi">xi</code></td>
<td>
<p>Input vector of data for variable xi</p>
</td></tr>
<tr><td><code id="parcorHijk_+3A_xj">xj</code></td>
<td>
<p>Input vector of data for variable xj</p>
</td></tr>
<tr><td><code id="parcorHijk_+3A_xk">xk</code></td>
<td>
<p>Input data for all variables in xk, usually control variables</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>ouij</code></td>
<td>
<p>Generalized partial correlation Xi with Xj (=cause) after removing xk</p>
</td></tr>
<tr><td><code>ouji</code></td>
<td>
<p>Generalized partial correlation Xj with Xi (=cause) after removing xk</p>
</td></tr>
</table>
<p>allowing for control variables.
</p>


<h3>Note</h3>

<p>This function calls <code><a href="#topic+kern">kern</a></code>,
</p>


<h3>Author(s)</h3>

<p>Prof. H. D. Vinod, Economics Dept., Fordham University, NY.
</p>


<h3>See Also</h3>

<p>See  <code><a href="#topic+parcor_ijk">parcor_ijk</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
set.seed(34);x=matrix(sample(1:600)[1:99],ncol=3)
options(np.messages=FALSE)
parcorHijk(x[,1], x[,2], x[,3])

## End(Not run)#' 
</code></pre>

<hr>
<h2 id='parcorHijk2'>Generalized partial correlation coefficients between 
Xi and Xj,</h2><span id='topic+parcorHijk2'></span>

<h3>Description</h3>

<p>The 2 in the name of the function means second version.
The H in the function name means hybrid. This removes the
effect of Xk, via OLS regression residuals.
This function uses data on two column vectors, xi, xj, and a third set
xk, which can be a vector or a matrix, usually of the remaining 
variables in the model, including control variables, if any.
It first removes missing data from all input variables. Then,
it computes residuals of OLS regression (xi on xk) and (xj on xk).
The function reports the generalized correlation between two OLS residuals.
This hybrid version uses both OLS and then generalized correlation among
OLS residuals. This second version works when 'parcorVecH' fails.
It is called by the function &lsquo;parcorVecH2&rsquo;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>parcorHijk2(xi, xj, xk)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="parcorHijk2_+3A_xi">xi</code></td>
<td>
<p>Input vector of data for variable xi</p>
</td></tr>
<tr><td><code id="parcorHijk2_+3A_xj">xj</code></td>
<td>
<p>Input vector of data for variable xj</p>
</td></tr>
<tr><td><code id="parcorHijk2_+3A_xk">xk</code></td>
<td>
<p>Input data for variables in xk, usually control variables</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>ouij</code></td>
<td>
<p>Generalized partial correlation Xi with Xj (=cause) after removing xk</p>
</td></tr>
<tr><td><code>ouji</code></td>
<td>
<p>Generalized partial correlation Xj with Xi (=cause) after removing xk</p>
</td></tr>
</table>
<p>allowing for control variables.
</p>


<h3>Note</h3>

<p>This function calls <code><a href="#topic+kern">kern</a></code>,
</p>


<h3>Author(s)</h3>

<p>Prof. H. D. Vinod, Economics Dept., Fordham University, NY.
</p>


<h3>See Also</h3>

<p>See  <code><a href="#topic+parcor_ijk">parcor_ijk</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
set.seed(34);x=matrix(sample(1:600)[1:99],ncol=3)
options(np.messages=FALSE)
parcorHijk2(x[,1], x[,2], x[,3])

## End(Not run)#' 
</code></pre>

<hr>
<h2 id='parcorMany'>Report many generalized partial correlation coefficients 
allowing control variables.</h2><span id='topic+parcorMany'></span>

<h3>Description</h3>

<p>This function calls <code>parcor_ijk</code> function which
uses original data to compute
generalized partial correlations between <code class="reqn">X_{idep}</code> and <code class="reqn">X_j</code>
where j can be any one of the remaining
variables in the input matrix <code>mtx</code>. Partial correlations remove the effect of
variables <code class="reqn">x_k</code> other than <code class="reqn">X_i</code> and <code class="reqn">X_j</code>. Calculation further 
allows for the presence of control variable(s) (if any) to remain always outside
the input matrix and whose effect is also removed in computing partial correlations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>parcorMany(mtx, ctrl = 0, dig = 4, idep = 1, verbo = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="parcorMany_+3A_mtx">mtx</code></td>
<td>
<p>Input data matrix with at least 3 columns.</p>
</td></tr>
<tr><td><code id="parcorMany_+3A_ctrl">ctrl</code></td>
<td>
<p>Input vector or matrix of data for control variable(s), 
default is ctrl=0 when control variables are absent</p>
</td></tr>
<tr><td><code id="parcorMany_+3A_dig">dig</code></td>
<td>
<p>The number of digits for reporting (=4, default)</p>
</td></tr>
<tr><td><code id="parcorMany_+3A_idep">idep</code></td>
<td>
<p>The column number of the first variable (=1, default)</p>
</td></tr>
<tr><td><code id="parcorMany_+3A_verbo">verbo</code></td>
<td>
<p>Make this TRUE for detailed printing of computational steps</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A five column &lsquo;out&rsquo; matrix containing partials. The first column
has the name of the <code>idep</code> variable. The
second column has the name of the j variable, while the third column 
has partial correlation coefficients  r*(i,j | k). The last column
reports the absolute difference between two partial correlations.
</p>


<h3>Note</h3>

<p>This function reports all partial
correlation coefficients, while avoiding ridge type adjustment.
</p>


<h3>Author(s)</h3>

<p>Prof. H. D. Vinod, Economics Dept., Fordham University, NY.
</p>


<h3>References</h3>

<p>Vinod, H. D. 'Generalized Correlations and Instantaneous
Causality for Data Pairs Benchmark,' (March 8, 2015)
<a href="https://www.ssrn.com/abstract=2574891">https://www.ssrn.com/abstract=2574891</a>
</p>
<p>Vinod, H. D. 'Matrix Algebra Topics in Statistics and Economics
Using R', Chapter 4 in Handbook of Statistics: Computational Statistics
with R, Vol.32, co-editors: M. B. Rao and C.R. Rao. New York:
North Holland, Elsevier Science Publishers, 2014, pp. 143-176.
</p>


<h3>See Also</h3>

<p>See Also <code><a href="#topic+parcor_ijk">parcor_ijk</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(234)
z=runif(10,2,11)# z is independently created
x=sample(1:10)+z/10  #x is partly indep and partly affected by z
y=1+2*x+3*z+rnorm(10)# y depends on x and z not vice versa
mtx=cbind(x,y,z)
parcorMany(mtx)
 
   
## Not run: 
set.seed(34);x=matrix(sample(1:600)[1:99],ncol=3)
colnames(x)=c('V1', 'v2', 'V3')
parcorMany(x, idep=1)

## End(Not run)

</code></pre>

<hr>
<h2 id='parcorMtx'>Matrix of generalized partial correlation coefficients, 
always leaving out control variables, if any.</h2><span id='topic+parcorMtx'></span>

<h3>Description</h3>

<p>This function calls  <code>parcor_ijk</code> function which
uses original data to compute
generalized partial correlations between <code class="reqn">X_i</code> and <code class="reqn">X_j</code>
where j can be any one of the remaining
variables in the input matrix <code>mtx</code>. Partial correlations remove the effect of
variables <code class="reqn">x_k</code> other than <code class="reqn">X_i</code> and <code class="reqn">X_j</code>. Calculation further 
allows for the presence of control variable(s) (if any) to remain always outside
the input matrix and whose effect is also removed in computing partial correlations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>parcorMtx(mtx, ctrl = 0, dig = 4, verbo = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="parcorMtx_+3A_mtx">mtx</code></td>
<td>
<p>Input data matrix with p columns. p is at least 3 columns.</p>
</td></tr>
<tr><td><code id="parcorMtx_+3A_ctrl">ctrl</code></td>
<td>
<p>Input vector or matrix of data for control variable(s), 
default is ctrl=0 when control variables are absent</p>
</td></tr>
<tr><td><code id="parcorMtx_+3A_dig">dig</code></td>
<td>
<p>The number of digits for reporting (=4, default)</p>
</td></tr>
<tr><td><code id="parcorMtx_+3A_verbo">verbo</code></td>
<td>
<p>Make this TRUE for detailed printing of computational steps</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A p by p &lsquo;out&rsquo; matrix containing partials  r*(i,j | k).
and  r*(j,i | k).
</p>


<h3>Note</h3>

<p>We want to get all partial
correlation coefficient pairs removing other column effects. Vinod (2018) 
shows why one needs more than one criterion to decide the causal paths or exogeneity.
</p>


<h3>Author(s)</h3>

<p>Prof. H. D. Vinod, Economics Dept., Fordham University, NY.
</p>


<h3>References</h3>

<p>Vinod, H. D. 'Generalized Correlations and Instantaneous
Causality for Data Pairs Benchmark,' (March 8, 2015)
<a href="https://www.ssrn.com/abstract=2574891">https://www.ssrn.com/abstract=2574891</a>
</p>
<p>Vinod, H. D. 'Matrix Algebra Topics in Statistics and Economics
Using R', Chapter 4 in Handbook of Statistics: Computational Statistics
with R, Vol.32, co-editors: M. B. Rao and C.R. Rao. New York:
North Holland, Elsevier Science Publishers, 2014, pp. 143-176.
</p>
<p>Vinod, H. D. 'New Exogeneity Tests and Causal Paths,' 
(June 30, 2018). Available at SSRN: 
<a href="https://www.ssrn.com/abstract=3206096">https://www.ssrn.com/abstract=3206096</a>
</p>


<h3>See Also</h3>

<p>See Also <code><a href="#topic+parcor_ijk">parcor_ijk</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(234)
z=runif(10,2,11)# z is independently created
x=sample(1:10)+z/10  #x is partly indep and partly affected by z
y=1+2*x+3*z+rnorm(10)# y depends on x and z not vice versa
mtx=cbind(x,y,z)
parcorMtx(mtx)
 
   
## Not run: 
set.seed(34);x=matrix(sample(1:600)[1:99],ncol=3)
colnames(x)=c('V1', 'v2', 'V3')
parcorMtx(x)

## End(Not run)

</code></pre>

<hr>
<h2 id='parcorSilent'>Silently compute generalized (ridge-adjusted) partial correlation coefficients from matrix R*.</h2><span id='topic+parcorSilent'></span>

<h3>Description</h3>

<p>This function calls <code>parcor_ijkOLD</code> function which
uses a generalized correlation matrix R* as input to compute
generalized partial correlations between <code class="reqn">X_i</code> and <code class="reqn">X_j</code>
where j can be any one of the remaining
variables. Computation removes the effect of all other variables in the matrix.
It further adjusts the resulting partial correlation coefficients to be in the
appropriate [-1,1] range by using an additive constant in the fashion of ridge regression.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>parcorSilent(gmc0, dig = 4, idep = 1, verbo = FALSE, incr = 3)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="parcorSilent_+3A_gmc0">gmc0</code></td>
<td>
<p>This must be a p by p matrix R* of generalized correlation coefficients.</p>
</td></tr>
<tr><td><code id="parcorSilent_+3A_dig">dig</code></td>
<td>
<p>The number of digits for reporting (=4, default)</p>
</td></tr>
<tr><td><code id="parcorSilent_+3A_idep">idep</code></td>
<td>
<p>The column number of the first variable (=1, default)</p>
</td></tr>
<tr><td><code id="parcorSilent_+3A_verbo">verbo</code></td>
<td>
<p>Make this TRUE for detailed printing of computational steps</p>
</td></tr>
<tr><td><code id="parcorSilent_+3A_incr">incr</code></td>
<td>
<p>incremental constant for iteratively adjusting &lsquo;ridgek&rsquo;
where ridgek is the constant times the identity matrix used to
make sure that the gmc0 matrix is positive definite. If not, this function iteratively
increases the <code>incr</code> till relevant partial correlations are within the [-1,1] interval.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A five column &lsquo;out&rsquo; matrix containing partials. The first column
has the name of the <code>idep</code> variable. The
second column has the name of the j variable, while the third column has  r*(i,j | k).
The 4-th column has  r*(j,i | k) (denoted partji), and the 5-th column has rijMrji,
that is the difference in absolute values (abs(partij) - abs(partji)).
</p>


<h3>Note</h3>

<p>The ridgek constant created by the function during the first round
may not be large enough to make sure that
that other pairs of r*(i,j | k) are within the [-1,1] interval. The user may have to choose
a suitably larger input <code>incr</code> to get all relevant partial
correlation coefficients in  the correct [-1,1] interval.
</p>


<h3>Author(s)</h3>

<p>Prof. H. D. Vinod, Economics Dept., Fordham University, NY.
</p>


<h3>References</h3>

<p>Vinod, H. D. 'Generalized Correlations and Instantaneous
Causality for Data Pairs Benchmark,' (March 8, 2015)
<a href="https://www.ssrn.com/abstract=2574891">https://www.ssrn.com/abstract=2574891</a>
</p>
<p>Vinod, H. D. 'Matrix Algebra Topics in Statistics and Economics
Using R', Chapter 4 in Handbook of Statistics: Computational Statistics
with R, Vol.32, co-editors: M. B. Rao and C.R. Rao. New York:
North Holland, Elsevier Science Publishers, 2014, pp. 143-176.
</p>
<p>Vinod, H. D. &quot;A Survey of Ridge Regression and Related Techniques 
for Improvements over Ordinary Least Squares,&quot; Review of Economics and Statistics, 
Vol. 60, February 1978, pp. 121-131.
</p>


<h3>See Also</h3>

<p>See Also <code><a href="#topic+parcor_ijk">parcor_ijk</a></code> for a better version using original data as input.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(234)
z=runif(10,2,11)# z is independently created
x=sample(1:10)+z/10  #x is partly indep and partly affected by z
y=1+2*x+3*z+rnorm(10)# y depends on x and z not vice versa
mtx=cbind(x,y,z)
g1=gmcmtx0(mtx)
parcor_ijkOLD(g1,1,2) # ouji&gt; ouij implies i=x is the cause of j=y
parcor_ridg(g1,idep=1)
parcorSilent(g1,idep=1)
 
   
## Not run: 
set.seed(34);x=matrix(sample(1:600)[1:99],ncol=3)
colnames(x)=c('V1', 'v2', 'V3')
gm1=gmcmtx0(x)
parcorSilent(gm1, idep=1)

## End(Not run)

</code></pre>

<hr>
<h2 id='parcorVec'>Vector of generalized partial correlation coefficients (GPCC), 
always leaving out control variables, if any.</h2><span id='topic+parcorVec'></span>

<h3>Description</h3>

<p>This function calls  <code>parcor_ijk</code> function which
uses original data to compute
generalized partial correlations between <code class="reqn">X_i</code>, the dependent variable,
and <code class="reqn">X_j</code> which is the current regressor of interest. Note that
j can be any one of the remaining
variables in the input matrix <code>mtx</code>. Partial correlations remove the effect of
variables <code class="reqn">X_k</code> other than <code class="reqn">X_i</code> and <code class="reqn">X_j</code>. 
Calculation merges control variable(s) (if any) into <code class="reqn">X_k</code>.
Let the remainder effect
from kernel regressions of <code class="reqn">X_i</code> on <code class="reqn">X_k</code> equal the  
residuals u*(i,k). Analogously define u*(j,k). (asterisk for kernel regressions) 
Now partial correlation is generalized correlation
between  u*(i,k) and u*(j,k).
Calculation merges control variable(s) (if any) into <code class="reqn">X_k</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>parcorVec(mtx, ctrl = 0, verbo = FALSE, idep = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="parcorVec_+3A_mtx">mtx</code></td>
<td>
<p>Input data matrix with p (&gt; or = 3) columns</p>
</td></tr>
<tr><td><code id="parcorVec_+3A_ctrl">ctrl</code></td>
<td>
<p>Input vector or matrix of data for control variable(s), 
default is ctrl=0 when control variables are absent</p>
</td></tr>
<tr><td><code id="parcorVec_+3A_verbo">verbo</code></td>
<td>
<p>Make this TRUE for detailed printing of computational steps</p>
</td></tr>
<tr><td><code id="parcorVec_+3A_idep">idep</code></td>
<td>
<p>The column number of the dependent variable (=1, default)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A p by 1 &lsquo;out&rsquo; vector containing partials  r*(i,j | k).
</p>


<h3>Note</h3>

<p>Generalized Partial Correlation Coefficients (GPCC) allow comparison of
the relative contribution of each <code class="reqn">X_j</code> to the explanation of <code class="reqn">X_i</code>,
because GPCC are scale-free pure numbers
</p>
<p>We want to get all partial
correlation coefficient pairs removing other column effects. Vinod (2018) 
shows why one needs more than one criterion to decide the causal paths or exogeneity.
</p>


<h3>Author(s)</h3>

<p>Prof. H. D. Vinod, Economics Dept., Fordham University, NY.
</p>


<h3>References</h3>

<p>Vinod, H. D. 'Generalized Correlations and Instantaneous
Causality for Data Pairs Benchmark,' (March 8, 2015)
<a href="https://www.ssrn.com/abstract=2574891">https://www.ssrn.com/abstract=2574891</a>
</p>
<p>Vinod, H. D. 'Matrix Algebra Topics in Statistics and Economics
Using R', Chapter 4 in Handbook of Statistics: Computational Statistics
with R, Vol.32, co-editors: M. B. Rao and C.R. Rao. New York:
North Holland, Elsevier Science Publishers, 2014, pp. 143-176.
</p>
<p>Vinod, H. D. 'New Exogeneity Tests and Causal Paths,' 
(June 30, 2018). Available at SSRN: 
<a href="https://www.ssrn.com/abstract=3206096">https://www.ssrn.com/abstract=3206096</a>
</p>
<p>Vinod, H. D. (2021) 'Generalized, Partial and Canonical Correlation
Coefficients' Computational Economics, 59(1), 1&ndash;28.
</p>


<h3>See Also</h3>

<p>See Also <code><a href="#topic+parcor_ijk">parcor_ijk</a></code>.
</p>
<p>See Also a hybrid version <code><a href="#topic+parcorVecH">parcorVecH</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(234)
z=runif(10,2,11)# z is independently created
x=sample(1:10)+z/10  #x is partly indep and partly affected by z
y=1+2*x+3*z+rnorm(10)# y depends on x and z not vice versa
mtx=cbind(x,y,z)
parcorVec(mtx)
 
   
## Not run: 
set.seed(34);x=matrix(sample(1:600)[1:99],ncol=3)
colnames(x)=c('V1', 'v2', 'V3')#some names needed
parcorVec(x)

## End(Not run)

</code></pre>

<hr>
<h2 id='parcorVecH'>Vector of hybrid generalized partial correlation coefficients.</h2><span id='topic+parcorVecH'></span>

<h3>Description</h3>

<p>This is a hybrid version of parcorVec subtracting only the linear effects
(OLS residuals instead of kernel regression residuals), but using the
generalized correlation between the OLS residuals for the last stage
of the generalized partial correlation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>parcorVecH(mtx, ctrl = 0, dig = 4, verbo = FALSE, idep = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="parcorVecH_+3A_mtx">mtx</code></td>
<td>
<p>Input data matrix with p (&gt; or = 3) columns, the first column
must have the dependent variable</p>
</td></tr>
<tr><td><code id="parcorVecH_+3A_ctrl">ctrl</code></td>
<td>
<p>Input vector or matrix of data for control variable(s), 
default is ctrl=0 when control variables are absent</p>
</td></tr>
<tr><td><code id="parcorVecH_+3A_dig">dig</code></td>
<td>
<p>The number of digits for reporting (=4, default)</p>
</td></tr>
<tr><td><code id="parcorVecH_+3A_verbo">verbo</code></td>
<td>
<p>Make this TRUE for detailed printing of computational steps</p>
</td></tr>
<tr><td><code id="parcorVecH_+3A_idep">idep</code></td>
<td>
<p>The column number of the dependent variable (=1, default)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function calls  <code>parcor_ijk</code> function, which
uses original data to compute
generalized partial correlations between <code class="reqn">X_i</code>, the dependent variable,
and <code class="reqn">X_j</code>, which is the current regressor of interest. Note that
j can be any one of the remaining
variables in the input matrix <code>mtx</code>. Partial correlations remove the effect of
variables <code class="reqn">X_k</code> other than <code class="reqn">X_i</code> and <code class="reqn">X_j</code>. 
Calculation merges control variable(s) (if any) into <code class="reqn">X_k</code>.
Let the remainder effect
from OLS regressions of <code class="reqn">X_i</code> on <code class="reqn">X_k</code> equal the  
residuals u(i,k). Analogously define u(j,k). It is a hybrid of OLS and generalized.  
Finally, partial correlation is generalized (kernel) correlation
between  u(i,k) and u(j,k).
</p>


<h3>Value</h3>

<p>A p by 1 &lsquo;out&rsquo; vector containing hybrid partials  r*(i,j | k).
</p>


<h3>Note</h3>

<p>Hybrid Generalized Partial Correlation Coefficients 
(HGPCC) allow comparison of
the relative contribution of each <code class="reqn">X_j</code> to the explanation of <code class="reqn">X_i</code>,
because HGPCC has scale-free pure numbers.
</p>
<p>We want to get all partial
correlation coefficient pairs removing other column effects. Vinod (2018) 
shows why one needs more than one criterion to decide the causal paths or exogeneity.
</p>


<h3>Author(s)</h3>

<p>Prof. H. D. Vinod, Economics Dept., Fordham University, NY.
</p>


<h3>References</h3>

<p>Vinod, H. D. 'Generalized Correlations and Instantaneous
Causality for Data Pairs Benchmark,' (March 8, 2015)
<a href="https://www.ssrn.com/abstract=2574891">https://www.ssrn.com/abstract=2574891</a>
</p>
<p>Vinod, H. D. 'Matrix Algebra Topics in Statistics and Economics
Using R', Chapter 4 in Handbook of Statistics: Computational Statistics
with R, Vol.32, co-editors: M. B. Rao and C.R. Rao. New York:
North Holland, Elsevier Science Publishers, 2014, pp. 143-176.
</p>
<p>Vinod, H. D. 'New Exogeneity Tests and Causal Paths,' 
(June 30, 2018). Available at SSRN: 
<a href="https://www.ssrn.com/abstract=3206096">https://www.ssrn.com/abstract=3206096</a>
</p>
<p>Vinod, H. D. (2021) 'Generalized, Partial and Canonical Correlation
Coefficients' Computational Economics, 59(1), 1&ndash;28.
</p>


<h3>See Also</h3>

<p>See Also <code><a href="#topic+parcor_ijk">parcor_ijk</a></code>.
</p>
<p>See Also <code><a href="#topic+parcorVec">parcorVec</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(234)
z=runif(10,2,11)# z is independently created
x=sample(1:10)+z/10  #x is partly indep and partly affected by z
y=1+2*x+3*z+rnorm(10)# y depends on x and z not vice versa
mtx=cbind(x,y,z)
parcorVecH(mtx)
 
   
## Not run: 
set.seed(34);mtx=matrix(sample(1:600)[1:80],ncol=4)
colnames(mtx)=c('V1', 'v2', 'V3', 'V4')
parcorVecH(mtx,verbo=TRUE, idep=2)

## End(Not run)

</code></pre>

<hr>
<h2 id='parcorVecH2'>Vector of hybrid generalized partial correlation coefficients.</h2><span id='topic+parcorVecH2'></span>

<h3>Description</h3>

<p>This is a second version to be used when &lsquo;parcorVecH&rsquo; fails. (H=hybrid). 
This hybrid version of parcorVec subtracting only linear effects but using
generlized correlation between OLS residuals
</p>


<h3>Usage</h3>

<pre><code class='language-R'>parcorVecH2(mtx, dig = 4, verbo = FALSE, idep = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="parcorVecH2_+3A_mtx">mtx</code></td>
<td>
<p>Input data matrix with p (&gt; or = 3) columns, first column
must have the dependent variable</p>
</td></tr>
<tr><td><code id="parcorVecH2_+3A_dig">dig</code></td>
<td>
<p>The number of digits for reporting (=4, default)</p>
</td></tr>
<tr><td><code id="parcorVecH2_+3A_verbo">verbo</code></td>
<td>
<p>Make this TRUE for detailed printing of computational steps</p>
</td></tr>
<tr><td><code id="parcorVecH2_+3A_idep">idep</code></td>
<td>
<p>The column number of the dependent variable (=1, default)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function calls  <code>parcorHijk2</code> function which
uses original data to compute
generalized partial correlations between <code class="reqn">X_i</code>, the dependent variable,
and <code class="reqn">X_j</code> which is the current regressor of interest. Note that
j can be any one of the remaining
variables in the input matrix <code>mtx</code>. Partial correlations remove the effect of
variables <code class="reqn">X_k</code> other than <code class="reqn">X_i</code> and <code class="reqn">X_j</code>. 
Calculation merges control variable(s) (if any) into <code class="reqn">X_k</code>.
Let the remainder effect
from OLS regressions of <code class="reqn">X_i</code> on <code class="reqn">X_k</code> equal the  
residuals u(i,k). Analogously define u(j,k). It is a hybrid of OLS and generalized.  
Finally, partial correlation is generalized (kernel) correlation
between  u(i,k) and u(j,k).
</p>


<h3>Value</h3>

<p>A p by 1 &lsquo;out&rsquo; vector containing hybrid partials  r*(i,j | k).
</p>


<h3>Note</h3>

<p>Hybrid Generalized Partial Correlation Coefficients 
(HGPCC) allow comparison of
the relative contribution of each <code class="reqn">X_j</code> to the explanation of <code class="reqn">X_i</code>,
because HGPCC are scale-free pure numbers.
</p>
<p>We want to get all partial
correlation coefficient pairs removing other column effects. Vinod (2018) 
shows why one needs more than one criterion to decide the causal paths or exogeneity.
</p>


<h3>Author(s)</h3>

<p>Prof. H. D. Vinod, Economics Dept., Fordham University, NY.
</p>


<h3>References</h3>

<p>Vinod, H. D. 'Generalized Correlations and Instantaneous
Causality for Data Pairs Benchmark,' (March 8, 2015)
<a href="https://www.ssrn.com/abstract=2574891">https://www.ssrn.com/abstract=2574891</a>
</p>
<p>Vinod, H. D. 'Matrix Algebra Topics in Statistics and Economics
Using R', Chapter 4 in Handbook of Statistics: Computational Statistics
with R, Vol.32, co-editors: M. B. Rao and C.R. Rao. New York:
North Holland, Elsevier Science Publishers, 2014, pp. 143-176.
</p>
<p>Vinod, H. D. 'New Exogeneity Tests and Causal Paths,' 
(June 30, 2018). Available at SSRN: 
<a href="https://www.ssrn.com/abstract=3206096">https://www.ssrn.com/abstract=3206096</a>
</p>
<p>Vinod, H. D. (2021) 'Generalized, Partial and Canonical Correlation
Coefficients' Computational Economics, 59(1), 1&ndash;28.
</p>


<h3>See Also</h3>

<p>See Also <code><a href="#topic+parcor_ijk">parcor_ijk</a></code>.
</p>
<p>See Also <code><a href="#topic+parcorVec">parcorVec</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(234)
z=runif(10,2,11)# z is independently created
x=sample(1:10)+z/10  #x is partly indep and partly affected by z
y=1+2*x+3*z+rnorm(10)# y depends on x and z not vice versa
mtx=cbind(x,y,z)
parcorVecH2(mtx)
 
   
## Not run: 
set.seed(34);mtx=matrix(sample(1:600)[1:80],ncol=4)
colnames(mtx)=c('V1', 'v2', 'V3', 'V4')
parcorVecH2(mtx,verbo=TRUE, idep=2)

## End(Not run)

</code></pre>

<hr>
<h2 id='pcause'>Compute the bootstrap probability of correct causal direction.</h2><span id='topic+pcause'></span>

<h3>Description</h3>

<p>Maximum entropy bootstrap (&lsquo;meboot&rsquo;) package is used for statistical inference
regarding <code class="reqn">\delta</code> which equals GMC(X|Y)-GMC(Y|X) defined by Zheng et al (2012).
The bootstrap provides an approximation to chances of correct determination of
the causal direction.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pcause(x, y, n999 = 999)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pcause_+3A_x">x</code></td>
<td>
<p>Vector of x data</p>
</td></tr>
<tr><td><code id="pcause_+3A_y">y</code></td>
<td>
<p>Vector of y data</p>
</td></tr>
<tr><td><code id="pcause_+3A_n999">n999</code></td>
<td>
<p>Number of bootstrap replications (default=999)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>P(cause) the bootstrap proportion of correct causal determinations.
</p>


<h3>Note</h3>

<p>'pcause' is computer intensive and generally slow. It is better to use
it at a later stage in the investigation when a preliminary causal determination 
is already made.  Its use may slow the exploratory phase. In my experience, if
P(cause) is less than 0.55, there is a cause for concern.
</p>


<h3>Author(s)</h3>

<p>Prof. H. D. Vinod, Economics Dept., Fordham University, NY
</p>


<h3>References</h3>

<p>Vinod, H. D. 'Generalized Correlation and Kernel Causality with 
Applications in Development Economics' in Communications in 
Statistics -Simulation and Computation, 2015, 
<a href="https://doi.org/10.1080/03610918.2015.1122048">doi:10.1080/03610918.2015.1122048</a>
</p>
<p>Zheng, S., Shi, N.-Z., and Zhang, Z. (2012). Generalized measures 
of correlation for asymmetry, nonlinearity, and beyond. 
Journal of the American Statistical Association, vol. 107, pp. 1239-1252.
</p>
<p>Vinod, H. D. and Lopez-de-Lacalle, J. (2009). 'Maximum entropy bootstrap
for time series: The meboot R package.' Journal of Statistical Software,
Vol. 29(5), pp. 1-19.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
set.seed(34);x=sample(1:10);y=sample(2:11)
pcause(x,y,n999=29)

data('EuroCrime')
attach(EuroCrime)
pcause(crim,off,n999=29)

## End(Not run)
</code></pre>

<hr>
<h2 id='pillar3D'>Create a 3D pillar chart to display (x, y, z) data coordinate surface.</h2><span id='topic+pillar3D'></span>

<h3>Description</h3>

<p>Given data on (x, y, z) coordinate values of a 3D surface, one can directly
plot a 3D plot with pins of the height z. By contrast, this function
fattens each pin by creating pillars near each z value by adding and
subtracting small amounts of dz. By eliminating the pins of the height z, this
depicts pillars that better resemble a surface. It uses the
wireframe() function of the &lsquo;lattice&rsquo; package to do the plotting.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pillar3D(
  z = c(657, 936, 1111, 1201),
  x = c(280, 542, 722, 1168),
  y = c(162, 214, 186, 246),
  drape = TRUE,
  xlab = "y",
  ylab = "x",
  zlab = "z",
  mymain = "Pillar Chart"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pillar3D_+3A_z">z</code></td>
<td>
<p>z-coordinate values</p>
</td></tr>
<tr><td><code id="pillar3D_+3A_x">x</code></td>
<td>
<p>x-coordinate values</p>
</td></tr>
<tr><td><code id="pillar3D_+3A_y">y</code></td>
<td>
<p>y-coordinate values</p>
</td></tr>
<tr><td><code id="pillar3D_+3A_drape">drape</code></td>
<td>
<p>logical value, default drape=TRUE to give color to heights</p>
</td></tr>
<tr><td><code id="pillar3D_+3A_xlab">xlab</code></td>
<td>
<p>default &quot;x&quot; label on the x axis</p>
</td></tr>
<tr><td><code id="pillar3D_+3A_ylab">ylab</code></td>
<td>
<p>default &quot;y&quot; label on the y axis</p>
</td></tr>
<tr><td><code id="pillar3D_+3A_zlab">zlab</code></td>
<td>
<p>default &quot;z&quot; label on the z axis</p>
</td></tr>
<tr><td><code id="pillar3D_+3A_mymain">mymain</code></td>
<td>
<p>default &quot;Pillar Chart&quot; main label on the plot</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For additional plotting features the user should 
type &lsquo;pillar3D()&rsquo; on the R console to
get my code and adjust my wireframe() function defaults.
</p>


<h3>Value</h3>

<p>A 3D plot
</p>


<h3>Author(s)</h3>

<p>Prof. H. D. Vinod, Economics Dept., Fordham University, NY
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
pillar3D())
## End(Not run)

</code></pre>

<hr>
<h2 id='prelec2'>Intermediate weighting function giving Non-Expected Utility theory weights.</h2><span id='topic+prelec2'></span>

<h3>Description</h3>

<p>Computes cumulative probabilities and difference between consecutive
cumulative probabilities described in Vinod (2008) textbook.  This is a simpler version
of the version in the book without mapping to non-expected utility theory weights
as explained in Vinod (2008).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>prelec2(n)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="prelec2_+3A_n">n</code></td>
<td>
<p>A (usually small) integer.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>x</code></td>
<td>
<p>sequence 1:n</p>
</td></tr>
<tr><td><code>p</code></td>
<td>
<p>probabilities p= x[i]/n</p>
</td></tr>
<tr><td><code>pdif</code></td>
<td>
<p>consecutive differences p[i] - p[i - 1]</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Prof. H. D. Vinod, Economics Dept., Fordham University, NY
</p>


<h3>References</h3>

<p>Vinod, H. D. 'Hands-On Intermediate Econometrics
Using R'  (2008) World Scientific Publishers: Hackensack, NJ.
<a href="https://www.worldscientific.com/worldscibooks/10.1142/12831">https://www.worldscientific.com/worldscibooks/10.1142/12831</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
 ## Not run: prelec2(10)

</code></pre>

<hr>
<h2 id='probSign'>Compute probability of positive or negative sign from bootPairs output</h2><span id='topic+probSign'></span>

<h3>Description</h3>

<p>If there are p columns of data, <code>probSign</code> produces a p-1 by 1 vector
of probabilities of correct signs assuming that the mean of n999 values
has the correct sign and assuming that m of the 'sum' index values inside the
range [-tau, tau] are neither positive nor negative but 
indeterminate or ambiguous (being too close to zero). That is,
the denominator of P(+1) or P(-1) is (n999-m) if m signs are too close to zero.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>probSign(out, tau = 0.476)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="probSign_+3A_out">out</code></td>
<td>
<p>output from bootPairs with p-1 columns and n999 rows</p>
</td></tr>
<tr><td><code id="probSign_+3A_tau">tau</code></td>
<td>
<p>threshold to determine what value is too close to
zero, default tau=0.476 is equivalent to 15 percent threshold for 
the unanimity index ui</p>
</td></tr>
</table>


<h3>Value</h3>

<p>sgn When <code>mtx</code> has p columns, <code>sgn</code>
reports pairwise p-1 signs  representing 
(fixing the first column in each pair)
the average sign after averaging the
output of of <code>bootPairs(mtx)</code> (a n999 by p-1 matrix)
each containing resampled &lsquo;sum&rsquo; values summarizing the weighted sums 
associated with all three  criteria from the 
function <code>silentPairs(mtx)</code>
applied to each bootstrap sample separately. #'
</p>


<h3>Author(s)</h3>

<p>Prof. H. D. Vinod, Economics Dept., Fordham University, NY
</p>


<h3>References</h3>

<p>Vinod, H. D. 'Generalized Correlation and Kernel Causality with 
Applications in Development Economics' in Communications in 
Statistics -Simulation and Computation, 2015, 
<a href="https://doi.org/10.1080/03610918.2015.1122048">doi:10.1080/03610918.2015.1122048</a>
</p>
<p>Vinod, H. D. and Lopez-de-Lacalle, J. (2009). 'Maximum entropy bootstrap
for time series: The meboot R package.' Journal of Statistical Software,
Vol. 29(5), pp. 1-19.
</p>
<p>Vinod, H. D. Causal Paths and Exogeneity Tests 
in Generalcorr Package for Air Pollution and Monetary Policy 
(June 6, 2017). Available at SSRN: <a href="https://www.ssrn.com/abstract=2982128">https://www.ssrn.com/abstract=2982128</a>
</p>


<h3>See Also</h3>

<p>See Also <code><a href="#topic+silentPairs">silentPairs</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
options(np.messages = FALSE)
set.seed(34);x=sample(1:10);y=sample(2:11)
bb=bootPairs(cbind(x,y),n999=29)
probSign(bb,tau=0.476) #gives summary stats for n999 bootstrap sum computations

bb=bootPairs(airquality,n999=999);options(np.messages=FALSE)
probSign(bb,tau=0.476)#signs for n999 bootstrap sum computations

data('EuroCrime')
attach(EuroCrime)
bb=bootPairs(cbind(crim,off),n999=29) #col.1= crim causes off 
#hence positive signs are more intuitively meaningful.
#note that n999=29 is too small for real problems, chosen for quickness here.
probSign(bb,tau=0.476)#signs for n999 bootstrap sum computations

## End(Not run)
</code></pre>

<hr>
<h2 id='rank2return'>Compute the portfolio return knowing the rank of a stock in the input &lsquo;mtx&rsquo;.</h2><span id='topic+rank2return'></span>

<h3>Description</h3>

<p>This function computes the return earned knowing the rank of a stock in
the input mtx of stock returns. For example, mtx has p=28 Dow Jones stocks
over n=169 monthly returns. Portfolio weights are assumed to be linearly
declining. If maxChosen=4, the weights are 4/10, 3/10, 2/10 and 1/10, which add
up to unity. These portfolio weights are assigned in reverse order
in the sense that first chosen stock (choice rank =1) gets portfolio weight=4/10.
The function computes return from the stocks using the &lsquo;myrank&rsquo; argument.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rank2return(mtx, myrank, maxChosen = 0, pctChoose = 20, verbo = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rank2return_+3A_mtx">mtx</code></td>
<td>
<p>a matrix with n rows (number of returns) p columns (number of stocks)</p>
</td></tr>
<tr><td><code id="rank2return_+3A_myrank">myrank</code></td>
<td>
<p>vector of p integers listing the rank of each stock, 1=best</p>
</td></tr>
<tr><td><code id="rank2return_+3A_maxchosen">maxChosen</code></td>
<td>
<p>number of stocks in the portfolio (with nonzero weights)
default=0. When maxChosen=0, we let pctChoose determine the maxChosen</p>
</td></tr>
<tr><td><code id="rank2return_+3A_pctchoose">pctChoose</code></td>
<td>
<p>percent of p stocks chosen inside the portfolio, default=20</p>
</td></tr>
<tr><td><code id="rank2return_+3A_verbo">verbo</code></td>
<td>
<p>logical if TRUE, print, default=TRUE</p>
</td></tr>
</table>


<h3>Value</h3>

<p>average return from the linearly declining
portfolio implied by the myrank vector.
</p>


<h3>Author(s)</h3>

<p>Prof. H. D. Vinod, Economics Dept., Fordham University, NY
</p>


<h3>See Also</h3>

<p><code><a href="#topic+outOFsamp">outOFsamp</a></code>
</p>

<hr>
<h2 id='rank2sell'>Compute the portfolio return knowing the rank of a stock in the 
input &lsquo;mtx&rsquo;.
This function computes the return earned knowing the rank of a stock 
computed elsewhere and named myrank associate with the data columns in
the input mtx of stock returns. For example, mtx has p=28 Dow Jones stocks
over n=169 monthly returns. Portfolio weights are assumed to be linearly
declining. If maxChosen=4, the weights are 1/10, 2/10, 3/10 and 4/10, which add
up to unity. These portfolio weights are assigned in their order
in the sense that first chosen stock (choice rank =p) gets portfolio weight=4/10.
The function computes return from the stocks using the &lsquo;myrank&rsquo; argument.
This helps in assessing out-of-sample performance of (short) 
the strategy of selling lowest ranking stocks. It is mostly for internal use
by <code>outOFsell()</code>. This is a sell version of <code>rank2return()</code>.</h2><span id='topic+rank2sell'></span>

<h3>Description</h3>

<p>Compute the portfolio return knowing the rank of a stock in the 
input &lsquo;mtx&rsquo;.
</p>
<p>This function computes the return earned knowing the rank of a stock 
computed elsewhere and named myrank associate with the data columns in
the input mtx of stock returns. For example, mtx has p=28 Dow Jones stocks
over n=169 monthly returns. Portfolio weights are assumed to be linearly
declining. If maxChosen=4, the weights are 1/10, 2/10, 3/10 and 4/10, which add
up to unity. These portfolio weights are assigned in their order
in the sense that first chosen stock (choice rank =p) gets portfolio weight=4/10.
The function computes return from the stocks using the &lsquo;myrank&rsquo; argument.
This helps in assessing out-of-sample performance of (short) 
the strategy of selling lowest ranking stocks. It is mostly for internal use
by <code>outOFsell()</code>. This is a sell version of <code>rank2return()</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rank2sell(mtx, myrank, maxChosen = 0, pctChoose = 20, verbo = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rank2sell_+3A_mtx">mtx</code></td>
<td>
<p>a matrix with n rows (number of returns) p columns (number of stocks)</p>
</td></tr>
<tr><td><code id="rank2sell_+3A_myrank">myrank</code></td>
<td>
<p>vector of p integers listing the rank of each stock, 1=best</p>
</td></tr>
<tr><td><code id="rank2sell_+3A_maxchosen">maxChosen</code></td>
<td>
<p>number of stocks in the portfolio (with nonzero weights)
default=0. When maxChosen=0, we let pctChoose determine the maxChosen</p>
</td></tr>
<tr><td><code id="rank2sell_+3A_pctchoose">pctChoose</code></td>
<td>
<p>percent of p stocks chosen inside the portfolio, default=20</p>
</td></tr>
<tr><td><code id="rank2sell_+3A_verbo">verbo</code></td>
<td>
<p>logical if TRUE, print, default=TRUE</p>
</td></tr>
</table>


<h3>Value</h3>

<p>average return from the linearly declining
portfolio implied by the myrank vector.
</p>


<h3>Author(s)</h3>

<p>Prof. H. D. Vinod, Economics Dept., Fordham University, NY
</p>


<h3>See Also</h3>

<p><code><a href="#topic+outOFsell">outOFsell</a></code>
</p>

<hr>
<h2 id='rhs.lag2'>
internal rhs.lag2
</h2><span id='topic+rhs.lag2'></span>

<h3>Description</h3>

<p>intended for internal use only
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rhs.lag2</code></pre>

<hr>
<h2 id='rhs1'>
internal rhs1
</h2><span id='topic+rhs1'></span>

<h3>Description</h3>

<p>intended for internal use only
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rhs1</code></pre>

<hr>
<h2 id='ridgek'>
internal ridgek
</h2><span id='topic+ridgek'></span>

<h3>Description</h3>

<p>intended for internal use only
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ridgek</code></pre>

<hr>
<h2 id='rij'>
internal rij
</h2><span id='topic+rij'></span>

<h3>Description</h3>

<p>intended for internal use only
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rij</code></pre>

<hr>
<h2 id='rijMrji'>
internal rijMrji
</h2><span id='topic+rijMrji'></span>

<h3>Description</h3>

<p>intended for internal use only
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rijMrji</code></pre>

<hr>
<h2 id='rji'>
internal rji
</h2><span id='topic+rji'></span>

<h3>Description</h3>

<p>intended for internal use only
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rji</code></pre>

<hr>
<h2 id='rrij'>
internal rrij
</h2><span id='topic+rrij'></span>

<h3>Description</h3>

<p>intended for internal use only
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rrij</code></pre>

<hr>
<h2 id='rrji'>
internal rrji
</h2><span id='topic+rrji'></span>

<h3>Description</h3>

<p>intended for internal use only
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rrji</code></pre>

<hr>
<h2 id='rstar'>Function to compute generalized correlation coefficients r*(x,y).</h2><span id='topic+rstar'></span>

<h3>Description</h3>

<p>Uses Vinod (2015) definition of generalized (asymmetric) correlation
coefficients.  It requires kernel regression of x on y obtained by using the &lsquo;np&rsquo; package.
It also reports usual Pearson correlation coefficient r and p-value for testing
the null hypothesis that (population r)=0.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rstar(x, y)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rstar_+3A_x">x</code></td>
<td>
<p>Vector of data on the dependent variable</p>
</td></tr>
<tr><td><code id="rstar_+3A_y">y</code></td>
<td>
<p>Vector of data on the regressor</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Four objects created by this function are:
</p>
<table>
<tr><td><code>corxy</code></td>
<td>
<p>r*x|y or regressing x on y</p>
</td></tr>
<tr><td><code>coryx</code></td>
<td>
<p>r*y|x or regressing y on x</p>
</td></tr>
<tr><td><code>pearson.r</code></td>
<td>
<p>Pearson's product moment correlation coefficient</p>
</td></tr>
<tr><td><code>pv</code></td>
<td>
<p>The p-value for testing the Pearson r</p>
</td></tr>
</table>


<h3>Note</h3>

<p>This function needs the kern function which in turn needs the np package.
</p>


<h3>Author(s)</h3>

<p>Prof. H. D. Vinod, Economics Dept., Fordham University, NY
</p>


<h3>References</h3>

<p>Vinod, H. D. 'Generalized Correlation and Kernel Causality with
Applications in Development Economics' in Communications in
Statistics -Simulation and Computation, 2015,
<a href="https://doi.org/10.1080/03610918.2015.1122048">doi:10.1080/03610918.2015.1122048</a>
</p>
<p>Vinod, H. D. 'Matrix Algebra Topics in Statistics and Economics
Using R', Chapter 4 in Handbook of Statistics: Computational Statistics
with R, Vol.32, co-editors: M. B. Rao and C.R. Rao. New York:
North Holland, Elsevier Science Publishers, 2014, pp. 143-176.
</p>


<h3>See Also</h3>

<p>See Also <code><a href="#topic+gmcmtx0">gmcmtx0</a></code> and  <code><a href="#topic+gmcmtxBlk">gmcmtxBlk</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x=sample(1:30);y=sample(1:30); rstar(x,y)

</code></pre>

<hr>
<h2 id='sales2Lag'>
internal sales2Lag
</h2><span id='topic+sales2Lag'></span>

<h3>Description</h3>

<p>intended for internal use only
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sales2Lag</code></pre>

<hr>
<h2 id='salesLag'>
internal salesLag
</h2><span id='topic+salesLag'></span>

<h3>Description</h3>

<p>intended for internal use only
</p>


<h3>Usage</h3>

<pre><code class='language-R'>salesLag</code></pre>

<hr>
<h2 id='seed'>
internal seed
</h2><span id='topic+seed'></span>

<h3>Description</h3>

<p>intended for internal use only
</p>


<h3>Usage</h3>

<pre><code class='language-R'>seed</code></pre>

<hr>
<h2 id='sgn.e0'>
internal sgn.e0
</h2><span id='topic+sgn.e0'></span>

<h3>Description</h3>

<p>intended for internal use only
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sgn.e0</code></pre>

<hr>
<h2 id='silentMtx'>No-print kernel-causality unanimity score matrix with optional control variables</h2><span id='topic+silentMtx'></span>

<h3>Description</h3>

<p>Allowing input matrix of control variables and missing data, this function produces a
p by p matrix summarizing the results, where the estimated signs of
stochastic dominance order values (+1, 0, &ndash;1) are weighted by 
<code>wt=c(1.2, 1.1, 1.05, 1)</code> to
compute an overall result for all orders of stochastic dominance by a weighted sum for
the criteria Cr1 and Cr2 and added to the Cr3 estimate as: (+1, 0, &ndash;1).
Final weighted index is always in the range [&ndash;3.175, 3.175]. It is converted
to the more intuitive range [&ndash;100, 100].
</p>


<h3>Usage</h3>

<pre><code class='language-R'>silentMtx(mtx, ctrl = 0, dig = 6, wt = c(1.2, 1.1, 1.05, 1), sumwt = 4)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="silentMtx_+3A_mtx">mtx</code></td>
<td>
<p>The data matrix with p columns. Denote x1 as the first column 
which is fixed and then 
paired with all other columns, say: x2, x3, .., xp, one by one for the 
purpose of flipping with x1. p must be 2 or more</p>
</td></tr>
<tr><td><code id="silentMtx_+3A_ctrl">ctrl</code></td>
<td>
<p>data matrix for designated control variable(s) outside causal paths</p>
</td></tr>
<tr><td><code id="silentMtx_+3A_dig">dig</code></td>
<td>
<p>Number of digits for reporting (default <code>dig</code>=6).</p>
</td></tr>
<tr><td><code id="silentMtx_+3A_wt">wt</code></td>
<td>
<p>Allows user to choose a vector of four alternative weights for SD1 to SD4.</p>
</td></tr>
<tr><td><code id="silentMtx_+3A_sumwt">sumwt</code></td>
<td>
<p> Sum of weights can be changed here =4(default).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The reason for slightly declining weights on the signs from
SD1 to SD4 is simply that the local mean comparisons 
implicit in SD1 are known to be
more reliable than local variance implicit in SD2, local skewness implicit in
SD3 and local kurtosis implicit in SD4. Why are higher moment
estimates less reliable? The 
higher power of the deviations from the mean needed in their computations
lead to greater sampling variability.
The summary results for all
three criteria are reported in a vector of numbers internally called <code>crall</code>:
</p>


<h3>Value</h3>

<p>With p columns in <code>mtx</code> argument to this function, x1 can be 
paired with a total of p-1 columns (x2, x3, .., xp). Note
we never flip any of the control variables with x1.  This function
produces i=1,2,..,p-1 numbers representing the summary sign, or &lsquo;sum&rsquo; from 
the signs sg1 to sg3 associated with the three criteria:
Cr1, Cr2 and Cr3.  Note that sg1 and sg2 themselves are weighted signs using
weighted sum of signs from four orders of stochastic dominance.
In general, a positive sign in the i-th location of the &lsquo;sum&rsquo; output of this function
means that x1 is the kernel cause while the variable in (i+1)-th column of <code>mtx</code> is the
&lsquo;effect&rsquo; or &lsquo;response&rsquo; or &lsquo;endogenous.&rsquo; The magnitude represents the strength (unanimity)
of the evidence for a particular sign. Conversely a negative sign
in the i-th location of the &lsquo;sum&rsquo; output of this function means that
that the first variable listed as the input to this function is the &lsquo;effect,&rsquo;
while the variable in (i+1)-th column of <code>mtx</code> is the exogenous kernel cause.
This function is a summary of <code>someCPairs</code> 
allowing for control variables.
</p>


<h3>Note</h3>

<p>The European Crime data has all three criteria correctly suggesting that
high crime rate kernel causes the deployment of a large number of police officers.
The command <code>attach(EuroCrime); silentPairs(cbind(crim,off))</code>
returns only one number: 3.175, implying a high unanimity strength.
The index 3.175 is the highest.
The positive sign of the index suggests that &lsquo;crim&rsquo; 
variable in the first column of the matrix input to this function kernel causes
&lsquo;off&rsquo; in the second column of the matrix argument <code>mtx</code> to this function.
</p>
<p>Interpretation of the output matrix produced by this function is as follows.
A negative index means the variable named in the column kernel-causes 
the variable named in the row. A
positive index means the row name variable kernel-causes 
the column name variable. The
abs(index) measures unanimity by three criteria, Cr1 to Cr3 representing
the strength of evidence for the identified causal path.
</p>


<h3>Author(s)</h3>

<p>Prof. H. D. Vinod, Economics Dept., Fordham University, NY.
</p>


<h3>References</h3>

<p>H. D. Vinod 'Generalized Correlation and Kernel Causality with
Applications in Development Economics' in Communications in
Statistics -Simulation and Computation, 2015,
<a href="https://doi.org/10.1080/03610918.2015.1122048">doi:10.1080/03610918.2015.1122048</a>
</p>
<p>Vinod, H. D. Causal Paths and Exogeneity Tests 
in Generalcorr Package for Air Pollution and Monetary Policy 
(June 6, 2017). Available at SSRN: 
<a href="https://www.ssrn.com/abstract=2982128">https://www.ssrn.com/abstract=2982128</a>
</p>


<h3>See Also</h3>

<p>See  <code><a href="#topic+silentPairs">silentPairs</a></code>.
</p>
<p>See  <code><a href="#topic+someCPairs">someCPairs</a></code>, <code><a href="#topic+some0Pairs">some0Pairs</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

## Not run: 
options(np.messages=FALSE)
colnames(mtcars[2:ncol(mtcars)])
silentMtx(mtcars[,1:3],ctrl=mtcars[,4:5]) # mpg paired with others

## End(Not run)

options(np.messages=FALSE)
set.seed(234)
z=runif(10,2,11)# z is independently created
x=sample(1:10)+z/10 #x is somewhat indep and affected by z
y=1+2*x+3*z+rnorm(10)
w=runif(10)
x2=x;x2[4]=NA;y2=y;y2[8]=NA;w2=w;w2[4]=NA
silentMtx(mtx=cbind(x2,y2), ctrl=cbind(z,w2))


</code></pre>

<hr>
<h2 id='silentMtx0'>Older kernel-causality unanimity score matrix with optional control variables</h2><span id='topic+silentMtx0'></span>

<h3>Description</h3>

<p>Allowing input matrix of control variables and missing data, this function produces a
p by p matrix summarizing the results, where the estimated signs of
stochastic dominance order values (+1, 0, &ndash;1) are weighted by 
<code>wt=c(1.2, 1.1, 1.05, 1)</code> to
compute an overall result for all orders of stochastic dominance by a weighted sum for
the criteria Cr1 and Cr2 and added to the Cr3 estimate as: (+1, 0, &ndash;1).
Final weighted index is always in the range [&ndash;3.175, 3.175]. It is converted
to the more intuitive range [&ndash;100, 100].
</p>


<h3>Usage</h3>

<pre><code class='language-R'>silentMtx0(mtx, ctrl = 0, dig = 6, wt = c(1.2, 1.1, 1.05, 1), sumwt = 4)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="silentMtx0_+3A_mtx">mtx</code></td>
<td>
<p>The data matrix with p columns. Denote x1 as the first column 
which is fixed and then 
paired with all other columns, say: x2, x3, .., xp, one by one for the 
purpose of flipping with x1. p must be 2 or more</p>
</td></tr>
<tr><td><code id="silentMtx0_+3A_ctrl">ctrl</code></td>
<td>
<p>data matrix for designated control variable(s) outside causal paths</p>
</td></tr>
<tr><td><code id="silentMtx0_+3A_dig">dig</code></td>
<td>
<p>Number of digits for reporting (default <code>dig</code>=6).</p>
</td></tr>
<tr><td><code id="silentMtx0_+3A_wt">wt</code></td>
<td>
<p>Allows user to choose a vector of four alternative weights for SD1 to SD4.</p>
</td></tr>
<tr><td><code id="silentMtx0_+3A_sumwt">sumwt</code></td>
<td>
<p> Sum of weights can be changed here =4(default).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The reason for slightly declining weights on the signs from
SD1 to SD4 is simply that the local mean comparisons 
implicit in SD1 are known to be
more reliable than local variance implicit in SD2, local skewness implicit in
SD3 and local kurtosis implicit in SD4. Why are higher moment
estimates less reliable? The 
higher power of the deviations from the mean needed in their computations
lead to greater sampling variability.
The summary results for all
three criteria are reported in a vector of numbers internally called <code>crall</code>:
</p>


<h3>Value</h3>

<p>With p columns in <code>mtx</code> argument to this function, x1 can be 
paired with a total of p-1 columns (x2, x3, .., xp). Note
we never flip any of the control variables with x1.  This function
produces i=1,2,..,p-1 numbers representing the summary sign, or &lsquo;sum&rsquo; from 
the signs sg1 to sg3 associated with the three criteria:
Cr1, Cr2 and Cr3.  Note that sg1 and sg2 themselves are weighted signs using
weighted sum of signs from four orders of stochastic dominance.
In general, a positive sign in the i-th location of the &lsquo;sum&rsquo; output of this function
means that x1 is the kernel cause while the variable in (i+1)-th column of <code>mtx</code> is the
&lsquo;effect&rsquo; or &lsquo;response&rsquo; or &lsquo;endogenous.&rsquo; The magnitude represents the strength (unanimity)
of the evidence for a particular sign. Conversely a negative sign
in the i-th location of the &lsquo;sum&rsquo; output of this function means that
that the first variable listed as the input to this function is the &lsquo;effect,&rsquo;
while the variable in (i+1)-th column of <code>mtx</code> is the exogenous kernel cause.
This function 
allows for control variables.
</p>


<h3>Note</h3>

<p>The European Crime data has all three criteria correctly suggesting that
high crime rate kernel causes the deployment of a large number of police officers.
The command <code>attach(EuroCrime); silentPairs(cbind(crim,off))</code>
returns only one number: 3.175, implying a high unanimity strength.
The index 3.175 is the highest.
The positive sign of the index suggests that &lsquo;crim&rsquo; 
variable in the first column of the matrix input to this function kernel causes
&lsquo;off&rsquo; in the second column of the matrix argument <code>mtx</code> to this function.
</p>
<p>Interpretation of the output matrix produced by this function is as follows.
A negative index means the variable named in the column kernel-causes 
the variable named in the row. A
positive index means the row name variable kernel-causes 
the column name variable. The
abs(index) measures unanimity by three criteria, Cr1 to Cr3 representing
the strength of evidence for the identified causal path.
</p>


<h3>Author(s)</h3>

<p>Prof. H. D. Vinod, Economics Dept., Fordham University, NY.
</p>


<h3>References</h3>

<p>H. D. Vinod 'Generalized Correlation and Kernel Causality with
Applications in Development Economics' in Communications in
Statistics -Simulation and Computation, 2015,
<a href="https://doi.org/10.1080/03610918.2015.1122048">doi:10.1080/03610918.2015.1122048</a>
</p>
<p>Vinod, H. D. Causal Paths and Exogeneity Tests 
in Generalcorr Package for Air Pollution and Monetary Policy 
(June 6, 2017). Available at SSRN: 
<a href="https://www.ssrn.com/abstract=2982128">https://www.ssrn.com/abstract=2982128</a>
</p>


<h3>See Also</h3>

<p>See  <code><a href="#topic+silentPairs0">silentPairs0</a></code> using older Cr1 criterion based
on kernel regression local gradients.
</p>
<p>See  <code><a href="#topic+someCPairs">someCPairs</a></code>, <code><a href="#topic+some0Pairs">some0Pairs</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

## Not run: 
options(np.messages=FALSE)
colnames(mtcars[2:ncol(mtcars)])
silentMtx0(mtcars[,1:3],ctrl=mtcars[,4:5]) # mpg paired with others

## End(Not run)

## Not run: 
options(np.messages=FALSE)
set.seed(234)
z=runif(10,2,11)# z is independently created
x=sample(1:10)+z/10 #x is somewhat indep and affected by z
y=1+2*x+3*z+rnorm(10)
w=runif(10)
x2=x;x2[4]=NA;y2=y;y2[8]=NA;w2=w;w2[4]=NA
silentMtx0(mtx=cbind(x2,y2), ctrl=cbind(z,w2))

## End(Not run)


</code></pre>

<hr>
<h2 id='silentPair2'>kernel causality (version 2) scores with control variables</h2><span id='topic+silentPair2'></span>

<h3>Description</h3>

<p>This function uses flipped kernel regressions to decide causal directions. 
This version 2 avoids Anderson's trapezoidal approximation used in
&lsquo;silenPairs.&rsquo; It calls functions: decileVote, momentVote, exactSdMtx, 
and summaryRank
after stochastic dominance is computed. It computes 
an average of ranks used. The column with the &ldquo;choice&rdquo; rank
value helps in choosing the flip having the lowest 
Hausman-Wu (residual times RHS regressor)
and secondly the lowest absolute 
residual. The chosen  flipped regression defines
the &ldquo;cause&quot; based on the variable on its right-hand side. In portfolio
selection, choice rank 1 has the highest return. Here we want low residuals and
low Hausman-Wu value, hence we choose choice=2 as the desirable flip.
</p>
<p>The function develops a unanimity index regarding the particular
flip (y on xi) or (xi on y) is best. A summary of all relevant signs determines the
causal direction and unanimity index among three criteria.
The &lsquo;2&rsquo; in the name of the function suggests a second implementation
where exact stochastic dominance, decileVote, and momentVote algorithms are used.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>silentPair2(mtx, ctrl = 0, dig = 6)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="silentPair2_+3A_mtx">mtx</code></td>
<td>
<p>The data matrix with p columns. Denote x1 as the first column, 
which is fixed in all rows of the output and then it is
paired with all other columns, say: x2, x3, .., xp, one by one for the 
purpose of flipping with x1. p must be 2 or more</p>
</td></tr>
<tr><td><code id="silentPair2_+3A_ctrl">ctrl</code></td>
<td>
<p>data matrix for designated control variable(s) outside causal paths,
default is ctrl=0, which means that there are no control variables used.</p>
</td></tr>
<tr><td><code id="silentPair2_+3A_dig">dig</code></td>
<td>
<p>Number of digits for reporting (default <code>dig</code>=6).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix with p columns in <code>mtx</code> argument to this function, x1 can be 
paired with a total of p-1 columns (x2, x3, .., xp). Note
we never flip any of the control variables with x1.  This function
produces i=1,2,..,p-1 numbers representing the summary sign, or &lsquo;sum&rsquo; from 
the signs sg1 to sg3 associated with the three criteria:
Cr1, Cr2, and Cr3.  Note that sg1 and sg2 themselves are weighted signs using 
a weighted sum of signs from four orders of stochastic dominance.
In general, a positive sign in the i-th location of the &lsquo;sum&rsquo; output of this function
means that x1 is the kernel cause while the variable in (i+1)-th column of <code>mtx</code> is the
&lsquo;effect&rsquo; or &lsquo;response&rsquo; or &lsquo;endogenous.&rsquo; The magnitude represents the strength (unanimity)
of the evidence for a particular sign. Conversely, a negative sign
in the i-th location of the &lsquo;sum&rsquo; output of this function means 
that the first variable listed as the input to this function is the &lsquo;effect,&rsquo;
while the variable in (i+1)-th column of <code>mtx</code> is the exogenous kernel cause.
</p>


<h3>Note</h3>

<p>The European Crime data has all three criteria correctly suggesting that a
high crime rate kernel causes the deployment of a large number of police officers.
The command <code>attach(EuroCrime); silentPairs(cbind(crim,off))</code>
returns only one number: 3.175, implying the highest unanimity strength index,
with the positive sign suggesting &lsquo;crim&rsquo; in the first column kernel causes
&lsquo;off&rsquo; in the second column of the argument <code>mtx</code> to this function.
</p>


<h3>Author(s)</h3>

<p>Prof. H. D. Vinod, Economics Dept., Fordham University, NY.
</p>


<h3>References</h3>

<p>H. D. Vinod  'Generalized Correlation and Kernel Causality with
Applications in Development Economics' in Communications in
Statistics -Simulation and Computation, 2015,
<a href="https://doi.org/10.1080/03610918.2015.1122048">doi:10.1080/03610918.2015.1122048</a>
</p>
<p>Vinod, H. D. Causal Paths and Exogeneity Tests 
in Generalcorr Package for Air Pollution and Monetary Policy 
(June 6, 2017). Available at SSRN: 
<a href="https://www.ssrn.com/abstract=2982128">https://www.ssrn.com/abstract=2982128</a>
</p>


<h3>See Also</h3>

<p>See  <code><a href="#topic+summaryRank">summaryRank</a></code>, <code><a href="#topic+decileVote">decileVote</a></code>
</p>
<p>See  <code><a href="#topic+momentVote">momentVote</a></code>, <code><a href="#topic+exactSdMtx">exactSdMtx</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

## Not run: 
options(np.messages=FALSE)
colnames(mtcars[2:ncol(mtcars)])
silentPair2(mtcars[,1:3],ctrl=mtcars[,4:5]) # mpg paired with others

## End(Not run)

options(np.messages=FALSE)
set.seed(234)
z=runif(10,2,11)# z is independently created
x=sample(1:10)+z/10 #x is somewhat indep and affected by z
y=1+2*x+3*z+rnorm(10)
w=runif(10)
x2=x;x2[4]=NA;y2=y;y2[8]=NA;w2=w;w2[4]=NA
silentPair2(mtx=cbind(x2,y2), ctrl=cbind(z,w2))


</code></pre>

<hr>
<h2 id='silentPairs'>No-print kernel causality scores with control variables Hausman-Wu Criterion 1</h2><span id='topic+silentPairs'></span>

<h3>Description</h3>

<p>Allowing input matrix of control variables and missing data, this function produces a
3 column matrix summarizing the results where the estimated signs of
stochastic dominance order values (+1, 0, -1) are weighted by 
<code>wt=c(1.2,1.1, 1.05, 1)</code> to
compute an overall result for all orders of stochastic dominance by a weighted sum for
the criteria Cr1 and Cr2 and added to the Cr3 estimate as: (+1, 0, -1),
always in the range [&ndash;3.175, 3.175].
</p>


<h3>Usage</h3>

<pre><code class='language-R'>silentPairs(mtx, ctrl = 0, dig = 6, wt = c(1.2, 1.1, 1.05, 1), sumwt = 4)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="silentPairs_+3A_mtx">mtx</code></td>
<td>
<p>The data matrix with p columns. Denote x1 as the first column 
which is fixed and then 
paired with all other columns, say: x2, x3, .., xp, one by one for the 
purpose of flipping with x1. p must be 2 or more</p>
</td></tr>
<tr><td><code id="silentPairs_+3A_ctrl">ctrl</code></td>
<td>
<p>data matrix for designated control variable(s) outside causal paths
default ctrl=0 which means that there are no control variables used.</p>
</td></tr>
<tr><td><code id="silentPairs_+3A_dig">dig</code></td>
<td>
<p>Number of digits for reporting (default <code>dig</code>=6).</p>
</td></tr>
<tr><td><code id="silentPairs_+3A_wt">wt</code></td>
<td>
<p>Allows user to choose a vector of four alternative weights for SD1 to SD4.</p>
</td></tr>
<tr><td><code id="silentPairs_+3A_sumwt">sumwt</code></td>
<td>
<p> Sum of weights can be changed here =4(default).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The reason for slightly declining weights on the signs from
SD1 to SD4 is simply that the local mean comparisons 
implicit in SD1 are known to be
more reliable than local variance implicit in SD2, local skewness implicit in
SD3 and local kurtosis implicit in SD4. The source of slightly declining sampling
unreliability of higher moments is the
higher power of the deviations from the mean needed in their computations.
The summary results for all
three criteria are reported in a vector of numbers internally called <code>crall</code>:
</p>


<h3>Value</h3>

<p>With p columns in <code>mtx</code> argument to this function, x1 can be 
paired with a total of p-1 columns (x2, x3, .., xp). Note
we never flip any of the control variables with x1.  This function
produces i=1,2,..,p-1 numbers representing the summary sign, or &lsquo;sum&rsquo; from 
the signs sg1 to sg3 associated with the three criteria:
Cr1, Cr2 and Cr3.  Note that sg1 and sg2 themselves are weighted signs using
weighted sum of signs from four orders of stochastic dominance.
In general, a positive sign in the i-th location of the &lsquo;sum&rsquo; output of this function
means that x1 is the kernel cause while the variable in (i+1)-th column of <code>mtx</code> is the
&lsquo;effect&rsquo; or &lsquo;response&rsquo; or &lsquo;endogenous.&rsquo; The magnitude represents the strength (unanimity)
of the evidence for a particular sign. Conversely a negative sign
in the i-th location of the &lsquo;sum&rsquo; output of this function means that
that the first variable listed as the input to this function is the &lsquo;effect,&rsquo;
while the variable in (i+1)-th column of <code>mtx</code> is the exogenous kernel cause.
</p>


<h3>Note</h3>

<p>The European Crime data has all three criteria correctly suggesting that
high crime rate kernel causes the deployment of a large number of police officers.
The command <code>attach(EuroCrime); silentPairs(cbind(crim,off))</code>
returns only one number: 3.175, implying the highest unanimity strength index,
with the positive sign suggesting &lsquo;crim&rsquo; in the first column kernel causes
&lsquo;off&rsquo; in the second column of the argument <code>mtx</code> to this function.
</p>


<h3>Author(s)</h3>

<p>Prof. H. D. Vinod, Economics Dept., Fordham University, NY.
</p>


<h3>References</h3>

<p>H. D. Vinod  'Generalized Correlation and Kernel Causality with
Applications in Development Economics' in Communications in
Statistics -Simulation and Computation, 2015,
<a href="https://doi.org/10.1080/03610918.2015.1122048">doi:10.1080/03610918.2015.1122048</a>
</p>
<p>Vinod, H. D. Causal Paths and Exogeneity Tests 
in Generalcorr Package for Air Pollution and Monetary Policy 
(June 6, 2017). Available at SSRN: 
<a href="https://www.ssrn.com/abstract=2982128">https://www.ssrn.com/abstract=2982128</a>
</p>


<h3>See Also</h3>

<p>See  <code><a href="#topic+bootPairs">bootPairs</a></code>, <code><a href="#topic+silentMtx">silentMtx</a></code>
</p>
<p>See  <code><a href="#topic+someCPairs">someCPairs</a></code>, <code><a href="#topic+some0Pairs">some0Pairs</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

## Not run: 
options(np.messages=FALSE)
colnames(mtcars[2:ncol(mtcars)])
silentPairs(mtcars[,1:3],ctrl=mtcars[,4:5]) # mpg paired with others

## End(Not run)

options(np.messages=FALSE)
set.seed(234)
z=runif(10,2,11)# z is independently created
x=sample(1:10)+z/10 #x is somewhat indep and affected by z
y=1+2*x+3*z+rnorm(10)
w=runif(10)
x2=x;x2[4]=NA;y2=y;y2[8]=NA;w2=w;w2[4]=NA
silentPairs(mtx=cbind(x2,y2), ctrl=cbind(z,w2))


</code></pre>

<hr>
<h2 id='silentPairs0'>Older version, kernel causality weighted sum allowing control variables</h2><span id='topic+silentPairs0'></span>

<h3>Description</h3>

<p>Allowing input matrix of control variables and missing data, this function produces a
3 column matrix summarizing the results where the estimated signs of
stochastic dominance order values (+1, 0, -1) are weighted by 
<code>wt=c(1.2,1.1, 1.05, 1)</code> to
compute an overall result for all orders of stochastic dominance by a weighted sum for
the criteria Cr1 and Cr2 and added to the Cr3 estimate as: (+1, 0, -1),
always in the range [&ndash;3.175, 3.175].
</p>


<h3>Usage</h3>

<pre><code class='language-R'>silentPairs0(mtx, ctrl = 0, dig = 6, wt = c(1.2, 1.1, 1.05, 1), sumwt = 4)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="silentPairs0_+3A_mtx">mtx</code></td>
<td>
<p>The data matrix with p columns. Denote x1 as the first column 
which is fixed and then 
paired with all other columns, say: x2, x3, .., xp, one by one for the 
purpose of flipping with x1. p must be 2 or more</p>
</td></tr>
<tr><td><code id="silentPairs0_+3A_ctrl">ctrl</code></td>
<td>
<p>data matrix for designated control variable(s) outside causal paths
default ctrl=0 which means that there are no control variables used.</p>
</td></tr>
<tr><td><code id="silentPairs0_+3A_dig">dig</code></td>
<td>
<p>Number of digits for reporting (default <code>dig</code>=6).</p>
</td></tr>
<tr><td><code id="silentPairs0_+3A_wt">wt</code></td>
<td>
<p>Allows user to choose a vector of four alternative weights for SD1 to SD4.</p>
</td></tr>
<tr><td><code id="silentPairs0_+3A_sumwt">sumwt</code></td>
<td>
<p> Sum of weights can be changed here =4(default).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This uses an older version of the first criterion Cr1 based on absolute
values of local gradients of kernel regressions, not absolute
Hausman-Wu statistic (RHS variable times kernel residuals).
It calls <code>abs_stdapd</code> and <code>abs_stdapdC</code>
The reason for slightly declining weights on the signs from
SD1 to SD4 is simply that the local mean comparisons 
implicit in SD1 are known to be
more reliable than local variance implicit in SD2, local skewness implicit in
SD3 and local kurtosis implicit in SD4. The source of slightly declining sampling
unreliability of higher moments is the
higher power of the deviations from the mean needed in their computations.
The summary results for all
three criteria are reported in a vector of numbers internally called <code>crall</code>:
</p>


<h3>Value</h3>

<p>With p columns in <code>mtx</code> argument to this function, x1 can be 
paired with a total of p-1 columns (x2, x3, .., xp). Note
we never flip any of the control variables with x1.  This function
produces i=1,2,..,p-1 numbers representing the summary sign, or &lsquo;sum&rsquo; from 
the signs sg1 to sg3 associated with the three criteria:
Cr1, Cr2 and Cr3.  Note that sg1 and sg2 themselves are weighted signs using
weighted sum of signs from four orders of stochastic dominance.
In general, a positive sign in the i-th location of the &lsquo;sum&rsquo; output of this function
means that x1 is the kernel cause while the variable in (i+1)-th column of <code>mtx</code> is the
&lsquo;effect&rsquo; or &lsquo;response&rsquo; or &lsquo;endogenous.&rsquo; The magnitude represents the strength (unanimity)
of the evidence for a particular sign. Conversely a negative sign
in the i-th location of the &lsquo;sum&rsquo; output of this function means that
that the first variable listed as the input to this function is the &lsquo;effect,&rsquo;
while the variable in (i+1)-th column of <code>mtx</code> is the exogenous kernel cause.
This function is a summary of <code>someCPairs</code> 
allowing for control variables.
</p>


<h3>Note</h3>

<p>The European Crime data has all three criteria correctly suggesting that
high crime rate kernel causes the deployment of a large number of police officers.
The command <code>attach(EuroCrime); silentPairs(cbind(crim,off))</code>
returns only one number: 3.175, implying the highest unanimity strength index,
with the positive sign suggesting &lsquo;crim&rsquo; in the first column kernel causes
&lsquo;off&rsquo; in the second column of the argument <code>mtx</code> to this function.
</p>


<h3>Author(s)</h3>

<p>Prof. H. D. Vinod, Economics Dept., Fordham University, NY.
</p>


<h3>References</h3>

<p>H. D. Vinod 'Generalized Correlation and Kernel Causality with
Applications in Development Economics' in Communications in
Statistics -Simulation and Computation, 2015,
<a href="https://doi.org/10.1080/03610918.2015.1122048">doi:10.1080/03610918.2015.1122048</a>
</p>
<p>Vinod, H. D. Causal Paths and Exogeneity Tests 
in Generalcorr Package for Air Pollution and Monetary Policy 
(June 6, 2017). Available at SSRN: 
<a href="https://www.ssrn.com/abstract=2982128">https://www.ssrn.com/abstract=2982128</a>
</p>


<h3>See Also</h3>

<p>See  <code><a href="#topic+bootPairs">bootPairs</a></code>, <code><a href="#topic+silentMtx">silentMtx</a></code>
</p>
<p>See  <code><a href="#topic+someCPairs">someCPairs</a></code>, <code><a href="#topic+some0Pairs">some0Pairs</a></code>
</p>
<p>See  <code><a href="#topic+silentPairs">silentPairs</a></code> for newer version using
more direct Hausman-Wu exogeneity test statistic.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

## Not run: 
options(np.messages=FALSE)
colnames(mtcars[2:ncol(mtcars)])
silentPairs0(mtcars[,1:3],ctrl=mtcars[,4:5]) # mpg paired with others

## End(Not run)

options(np.messages=FALSE)
set.seed(234)
z=runif(10,2,11)# z is independently created
x=sample(1:10)+z/10 #x is somewhat indep and affected by z
y=1+2*x+3*z+rnorm(10)
w=runif(10)
x2=x;x2[4]=NA;y2=y;y2[8]=NA;w2=w;w2[4]=NA
silentPairs0(mtx=cbind(x2,y2), ctrl=cbind(z,w2))


</code></pre>

<hr>
<h2 id='siPair2Blk'>Block Version of silentPair2 for causality scores with control variables</h2><span id='topic+siPair2Blk'></span>

<h3>Description</h3>

<p>Block version allows a new bandwidth (chosen by the np package)
while fitting kernel regressions for each block of data. This may
not be appropriate in all situations.  Block size is flexible. 
The function develops a unanimity index regarding the particular
flip (y on xi) or (xi on y) is best. Relevant signs determine the
causal direction and unanimity index among three criteria.
The &lsquo;2&rsquo; in the name of the function suggests a second implementation
where exact stochastic dominance, decileVote, and momentVote are used.
It avoids Anderson's trapezoidal approximation.
The summary results for all
three criteria are reported in a vector of numbers 
internally called <code>crall</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>siPair2Blk(mtx, ctrl = 0, dig = 6, blksiz = 10)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="siPair2Blk_+3A_mtx">mtx</code></td>
<td>
<p>The data matrix with p columns. Denote x1 as the first column, 
which is fixed and then 
paired with all other columns, say: x2, x3, .., xp, one by one  
flipping with x1.The number of columns, p, must be 2 or more</p>
</td></tr>
<tr><td><code id="siPair2Blk_+3A_ctrl">ctrl</code></td>
<td>
<p>data matrix for designated control variable(s) outside causal paths.
The default ctrl=0 means that there are no control variables used.</p>
</td></tr>
<tr><td><code id="siPair2Blk_+3A_dig">dig</code></td>
<td>
<p>Number of digits for reporting (default <code>dig</code>=6).</p>
</td></tr>
<tr><td><code id="siPair2Blk_+3A_blksiz">blksiz</code></td>
<td>
<p>block size, default=10, if chosen blksiz &gt;n, where n=rows in the
matrix, then blksiz=n. That is, no blocking is done</p>
</td></tr>
</table>


<h3>Value</h3>

<p>With p columns in <code>mtx</code> argument to this function, x1 can be 
paired with a total of p-1 columns (x2, x3, .., xp). Note
we never flip any of the control variables with x1.  This function
produces i=1,2,..,p-1 numbers representing the summary sign, or &lsquo;sum&rsquo; from 
the signs sg1 to sg3 associated with the three criteria:
Cr1, Cr2 and Cr3.  Note that sg1 and sg2 themselves are weighted signs using
the weighted sum of signs from four orders of stochastic dominance.
In general, a positive sign in the i-th location of the &lsquo;sum&rsquo; output of this function
means that x1 is the kernel cause while the variable in (i+1)-th column of <code>mtx</code> is the
&lsquo;effect&rsquo; or &lsquo;response&rsquo; or &lsquo;endogenous.&rsquo; The magnitude represents the strength (unanimity)
of the evidence for a particular sign. Conversely, a negative sign
in the i-th location of the &lsquo;sum&rsquo; output of this function means that
that the first variable listed as the input to this function is the &lsquo;effect,&rsquo;
while the variable in (i+1)-th column of <code>mtx</code> is the exogenous kernel cause.
</p>


<h3>Note</h3>

<p>The European Crime data has all three criteria correctly suggesting that
high crime rate kernel causes the deployment of a large number of police officers.
The command <code>attach(EuroCrime); silentPairs(cbind(crim,off))</code>
returns only one number: 3.175, implying the highest unanimity strength index,
with the positive sign suggesting &lsquo;crim&rsquo; in the first column kernel causes
&lsquo;off&rsquo; in the second column of the argument <code>mtx</code> to this function.
</p>


<h3>Author(s)</h3>

<p>Prof. H. D. Vinod, Economics Dept., Fordham University, NY.
</p>


<h3>References</h3>

<p>H. D. Vinod  'Generalized Correlation and Kernel Causality with
Applications in Development Economics' in Communications in
Statistics -Simulation and Computation, 2015,
<a href="https://doi.org/10.1080/03610918.2015.1122048">doi:10.1080/03610918.2015.1122048</a>
</p>
<p>Vinod, H. D. Causal Paths and Exogeneity Tests 
in Generalcorr Package for Air Pollution and Monetary Policy 
(June 6, 2017). Available at SSRN: 
<a href="https://www.ssrn.com/abstract=2982128">https://www.ssrn.com/abstract=2982128</a>
</p>


<h3>See Also</h3>

<p>See  <code><a href="#topic+bootPairs">bootPairs</a></code>, <code><a href="#topic+silentMtx">silentMtx</a></code>
</p>
<p>See  <code><a href="#topic+someCPairs">someCPairs</a></code>, <code><a href="#topic+compPortfo">compPortfo</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

## Not run: 
options(np.messages=FALSE)
colnames(mtcars[2:ncol(mtcars)])
siPair2Blk(mtcars[,1:3],ctrl=mtcars[,4:5]) # mpg paired with others

## End(Not run)

options(np.messages=FALSE)
set.seed(234)
z=runif(10,2,11)# z is independently created
x=sample(1:10)+z/10 #x is somewhat indep and affected by z
y=1+2*x+3*z+rnorm(10)
w=runif(10)
x2=x;x2[4]=NA;y2=y;y2[8]=NA;w2=w;w2[4]=NA
siPair2Blk(mtx=cbind(x2,y2), ctrl=cbind(z,w2))


</code></pre>

<hr>
<h2 id='siPairsBlk'>Block Version of silentPairs for causality scores with control variables</h2><span id='topic+siPairsBlk'></span>

<h3>Description</h3>

<p>Allowing input matrix of control variables and missing data, this function produces a
3 column matrix summarizing the results where the estimated signs of
stochastic dominance order values (+1, 0, -1) are weighted by 
<code>wt=c(1.2,1.1, 1.05, 1)</code> to
compute an overall result for all orders of stochastic dominance by a weighted sum for
the criteria Cr1 and Cr2 and added to the Cr3 estimate as: (+1, 0, -1),
always in the range [&ndash;3.175, 3.175].
</p>


<h3>Usage</h3>

<pre><code class='language-R'>siPairsBlk(
  mtx,
  ctrl = 0,
  dig = 6,
  blksiz = 10,
  wt = c(1.2, 1.1, 1.05, 1),
  sumwt = 4
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="siPairsBlk_+3A_mtx">mtx</code></td>
<td>
<p>The data matrix with p columns. Denote x1 as the first column 
which is fixed and then 
paired with all other columns, say: x2, x3, .., xp, one by one for the 
purpose of flipping with x1. p must be 2 or more</p>
</td></tr>
<tr><td><code id="siPairsBlk_+3A_ctrl">ctrl</code></td>
<td>
<p>data matrix for designated control variable(s) outside causal paths
default ctrl=0 which means that there are no control variables used.</p>
</td></tr>
<tr><td><code id="siPairsBlk_+3A_dig">dig</code></td>
<td>
<p>Number of digits for reporting (default <code>dig</code>=6).</p>
</td></tr>
<tr><td><code id="siPairsBlk_+3A_blksiz">blksiz</code></td>
<td>
<p>block size, default=10, if chosen blksiz &gt;n, where n=rows in matrix
then blksiz=n. That is, no blocking is done</p>
</td></tr>
<tr><td><code id="siPairsBlk_+3A_wt">wt</code></td>
<td>
<p>Allows user to choose a vector of four alternative weights for SD1 to SD4.</p>
</td></tr>
<tr><td><code id="siPairsBlk_+3A_sumwt">sumwt</code></td>
<td>
<p> Sum of weights can be changed here =4(default).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The reason for slightly declining weights on the signs from
SD1 to SD4 is simply that the local mean comparisons 
implicit in SD1 are known to be
more reliable than local variance implicit in SD2, local skewness implicit in
SD3 and local kurtosis implicit in SD4. The source of slightly declining sampling
unreliability of higher moments is the
higher power of the deviations from the mean needed in their computations.
The summary results for all
three criteria are reported in a vector of numbers internally called <code>crall</code>:
</p>


<h3>Value</h3>

<p>With p columns in <code>mtx</code> argument to this function, x1 can be 
paired with a total of p-1 columns (x2, x3, .., xp). Note
we never flip any of the control variables with x1.  This function
produces i=1,2,..,p-1 numbers representing the summary sign, or &lsquo;sum&rsquo; from 
the signs sg1 to sg3 associated with the three criteria:
Cr1, Cr2 and Cr3.  Note that sg1 and sg2 themselves are weighted signs using
weighted sum of signs from four orders of stochastic dominance.
In general, a positive sign in the i-th location of the &lsquo;sum&rsquo; output of this function
means that x1 is the kernel cause while the variable in (i+1)-th column of <code>mtx</code> is the
&lsquo;effect&rsquo; or &lsquo;response&rsquo; or &lsquo;endogenous.&rsquo; The magnitude represents the strength (unanimity)
of the evidence for a particular sign. Conversely a negative sign
in the i-th location of the &lsquo;sum&rsquo; output of this function means that
that the first variable listed as the input to this function is the &lsquo;effect,&rsquo;
while the variable in (i+1)-th column of <code>mtx</code> is the exogenous kernel cause.
</p>


<h3>Note</h3>

<p>The European Crime data has all three criteria correctly suggesting that
high crime rate kernel causes the deployment of a large number of police officers.
The command <code>attach(EuroCrime); silentPairs(cbind(crim,off))</code>
returns only one number: 3.175, implying the highest unanimity strength index,
with the positive sign suggesting &lsquo;crim&rsquo; in the first column kernel causes
&lsquo;off&rsquo; in the second column of the argument <code>mtx</code> to this function.
</p>


<h3>Author(s)</h3>

<p>Prof. H. D. Vinod, Economics Dept., Fordham University, NY.
</p>


<h3>References</h3>

<p>H. D. Vinod  'Generalized Correlation and Kernel Causality with
Applications in Development Economics' in Communications in
Statistics -Simulation and Computation, 2015,
<a href="https://doi.org/10.1080/03610918.2015.1122048">doi:10.1080/03610918.2015.1122048</a>
</p>
<p>Vinod, H. D. Causal Paths and Exogeneity Tests 
in Generalcorr Package for Air Pollution and Monetary Policy 
(June 6, 2017). Available at SSRN: 
<a href="https://www.ssrn.com/abstract=2982128">https://www.ssrn.com/abstract=2982128</a>
</p>


<h3>See Also</h3>

<p>See  <code><a href="#topic+bootPairs">bootPairs</a></code>, <code><a href="#topic+silentMtx">silentMtx</a></code>
</p>
<p>See  <code><a href="#topic+someCPairs">someCPairs</a></code>, <code><a href="#topic+some0Pairs">some0Pairs</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

## Not run: 
options(np.messages=FALSE)
colnames(mtcars[2:ncol(mtcars)])
siPairsBlk(mtcars[,1:3],ctrl=mtcars[,4:5]) # mpg paired with others

## End(Not run)

options(np.messages=FALSE)
set.seed(234)
z=runif(10,2,11)# z is independently created
x=sample(1:10)+z/10 #x is somewhat indep and affected by z
y=1+2*x+3*z+rnorm(10)
w=runif(10)
x2=x;x2[4]=NA;y2=y;y2[8]=NA;w2=w;w2[4]=NA
siPairsBlk(mtx=cbind(x2,y2), ctrl=cbind(z,w2))


</code></pre>

<hr>
<h2 id='some0Pairs'>Function reporting detailed kernel causality results in a 7-column matrix 
(uses deprecated criterion 1, no longer recommended but may be useful for
second and third criterion typ=2,3)</h2><span id='topic+some0Pairs'></span>

<h3>Description</h3>

<p>The seven columns produced by this function summarize the results where the signs of
stochastic dominance order values (+1 or -1) are weighted by <code>wt=c(1.2,1.1, 1.05, 1)</code> to
compute an overall result for all orders of stochastic dominance by a weighted sum for
the criteria Cr1 and Cr2. The weighting is obviously not needed for the third criterion Cr3.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>some0Pairs(
  mtx,
  dig = 6,
  verbo = TRUE,
  rnam = FALSE,
  wt = c(1.2, 1.1, 1.05, 1),
  sumwt = 4
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="some0Pairs_+3A_mtx">mtx</code></td>
<td>
<p>The data matrix in the first column is paired with all others.</p>
</td></tr>
<tr><td><code id="some0Pairs_+3A_dig">dig</code></td>
<td>
<p>Number of digits for reporting (default <code>dig</code>=6).</p>
</td></tr>
<tr><td><code id="some0Pairs_+3A_verbo">verbo</code></td>
<td>
<p>Make <code>verbo= TRUE</code> for printing detailed steps.</p>
</td></tr>
<tr><td><code id="some0Pairs_+3A_rnam">rnam</code></td>
<td>
<p>Make <code>rnam= TRUE</code> if cleverly created row-names are desired.</p>
</td></tr>
<tr><td><code id="some0Pairs_+3A_wt">wt</code></td>
<td>
<p>Allows user to choose a vector of four alternative weights for SD1 to SD4.</p>
</td></tr>
<tr><td><code id="some0Pairs_+3A_sumwt">sumwt</code></td>
<td>
<p> Sum of weights can be changed here =4(default).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The reason for slightly declining weights on the signs from
SD1 to SD4 is simply that the local mean comparisons 
implicit in SD1 are known to be
more reliable than local variance implicit in SD2, local skewness implicit in
SD3 and local kurtosis implicit in SD4. The source of slightly declining sampling
unreliability of higher moments is the
higher power of the deviations from the mean needed in their computations.
The summary results for all
three criteria are reported in one matrix called <code>outVote</code>: 
</p>
<p>typ=1 reports ('Y', 'X', 'Cause',
'SD1apd', 'SD2apd', 'SD3apd', 'SD4apd') naming variables identifying 'cause'
and measures of stochastic dominance using absolute values of kernel
regression gradients (or amorphous partial derivatives, apd-s) being minimized by
the kernel regression algorithm while
comparing the kernel regression of X on Y with that of Y on X.
</p>
<p>typ=2 reports ('Y', 'X', 'Cause', 'SD1res', 'SD2res', 'SD3res', 'SD4res')
and measures of stochastic dominance using absolute values of kernel
regression residuals comparing regression of X on Y with that of Y on X.
</p>
<p>typ=3 reports ('Y', 'X', 'Cause', 'r*x|y', 'r*y|x', 'r', 'p-val')
containing generalized correlation coefficients r*, 'r' refers to.
Pearson correlation coefficient p-val is the p-value for 
testing the significance of 'r'
</p>


<h3>Value</h3>

<p>Prints three matrices detailing results for Cr1, Cr2 and Cr3.
It also returns a grand summary matrix called &lsquo;outVote&rsquo; which summarizes all three criteria.
In general, a positive sign for weighted sum reported in the column &lsquo;sum&rsquo; means
that the first variable listed as the input to this function is the &lsquo;kernel cause.&rsquo;  
For example, crime &lsquo;kernel causes&rsquo; police officer deployment (not vice versa) is indicated by 
the positive sign of &lsquo;sum&rsquo; (=3.175) reported for that example included in this package.
</p>


<h3>Note</h3>

<p>The output matrix last column for &lsquo;mtcars&rsquo; example
has the sum of the scores by the three criteria
combined. If &lsquo;sum&rsquo; is positive, then variable X (mpg) is more likely to have been
engineered to kernel cause the response variable Y, rather than vice versa.
</p>
<p>The European Crime data has all three criteria correctly suggesting that
high crime rate kernel causes the deployment of a large number of police officers.
</p>


<h3>Author(s)</h3>

<p>Prof. H. D. Vinod, Economics Dept., Fordham University, NY.
</p>


<h3>References</h3>

<p>Vinod, H. D. 'Generalized Correlation and Kernel Causality with
Applications in Development Economics' in Communications in
Statistics -Simulation and Computation, 2015,
<a href="https://doi.org/10.1080/03610918.2015.1122048">doi:10.1080/03610918.2015.1122048</a>
</p>


<h3>See Also</h3>

<p>See Also <code><a href="#topic+somePairs">somePairs</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

## Not run: 
some0Pairs(mtcars) # first variable is mpg and effect on mpg is of interest

## End(Not run)

## Not run: 
data(EuroCrime)
attach(EuroCrime)
some0Pairs(cbind(crim,off))

## End(Not run)


</code></pre>

<hr>
<h2 id='someCPairs'>Kernel causality computations admitting control variables.</h2><span id='topic+someCPairs'></span>

<h3>Description</h3>

<p>This function reports a 7-column matrix (has the older version of criterion Cr1).
It allows an additional input matrix having control variables. It
produces a 7-column matrix
summarizing the results, where the signs of
stochastic dominance order values (+1 or -1) are weighted 
by <code>wt=c(1.2,1.1, 1.05, 1)</code> to
compute an overall result for all orders of stochastic dominance 
by a weighted sum for
the criteria Cr1 and Cr2. The weighting is obviously not needed for 
the third criterion Cr3 which compares asymmetric correlation coefficients.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>someCPairs(
  mtx,
  ctrl,
  dig = 6,
  verbo = TRUE,
  rnam = FALSE,
  wt = c(1.2, 1.1, 1.05, 1),
  sumwt = 4
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="someCPairs_+3A_mtx">mtx</code></td>
<td>
<p>The data matrix with many columns where the first column is fixed and then 
paired with all other columns, one by one.</p>
</td></tr>
<tr><td><code id="someCPairs_+3A_ctrl">ctrl</code></td>
<td>
<p>data matrix for designated control variable(s) outside causal paths</p>
</td></tr>
<tr><td><code id="someCPairs_+3A_dig">dig</code></td>
<td>
<p>Number of digits for reporting (default <code>dig</code>=6).</p>
</td></tr>
<tr><td><code id="someCPairs_+3A_verbo">verbo</code></td>
<td>
<p>Make <code>verbo= TRUE</code> for printing detailed steps.</p>
</td></tr>
<tr><td><code id="someCPairs_+3A_rnam">rnam</code></td>
<td>
<p>Make <code>rnam= TRUE</code> if cleverly created rownames are desired.</p>
</td></tr>
<tr><td><code id="someCPairs_+3A_wt">wt</code></td>
<td>
<p>Allows user to choose a vector of four alternative weights for SD1 to SD4.</p>
</td></tr>
<tr><td><code id="someCPairs_+3A_sumwt">sumwt</code></td>
<td>
<p> Sum of weights can be changed here =4(default).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The reason for slightly declining weights on the signs from
SD1 to SD4 is somewhat arbitrary.
The summary results for all
three criteria are reported in one matrix called <code>outVote</code>: 
</p>
<p>typ=1 reports ('Y', 'X', 'Cause',
'SD1apdC', 'SD2apdC', 'SD3apdC', 'SD4apdC') naming variables identifying 'cause'
and measures of stochastic dominance using absolute values of kernel
regression gradients (or amorphous partial derivatives, apd-s) being minimized by
the kernel regression algorithm while
comparing the kernel regression of X on Y with that of Y on X.
The letter C in the titles reminds presence of control variable(s).
</p>
<p>typ=2 reports ('Y', 'X', 'Cause', 'SD1resC', 'SD2resC', 'SD3resC', 'SD4resC')
and measures of stochastic dominance using absolute values of kernel
regression residuals comparing regression of X on Y with that of Y on X.
</p>
<p>typ=3 reports ('Y', 'X', 'Cause', 'r*x|yC', 'r*y|xC', 'r', 'p-val')
containing generalized correlation coefficients r*, 'r' refers to.
Pearson correlation coefficient p-val is the p-value for 
testing the significance of 'r'. 
The letter C in the titles reminds the presence of control variable(s).
</p>


<h3>Value</h3>

<p>Prints three matrices detailing results for Cr1, Cr2 and Cr3.
It also returns a grand summary matrix called &lsquo;outVote&rsquo; which summarizes all three criteria.
In general, a positive sign for weighted sum reported in the column &lsquo;sum&rsquo; means
that the first variable listed as the input to this function is the &lsquo;kernel cause.&rsquo; 
This function is an extension of <code>some0Pairs</code> to allow for control variables. 
For example, crime &lsquo;kernel causes&rsquo; police officer deployment (not vice versa) is indicated by 
the positive sign of &lsquo;sum&rsquo; (=3.175) reported for that example included in this package.
</p>


<h3>Note</h3>

<p>The output matrix last column for &lsquo;mtcars&rsquo; example
has the sum of the scores by the three criteria
combined. If &lsquo;sum&rsquo; is positive, then variable X (mpg) is more likely to have been
engineerd to kernel cause the response variable Y, rather than vice versa.
</p>
<p>The European Crime data has all three criteria correctly suggesting that
high crime rate kernel causes the deployment of a large number of police officers.
</p>


<h3>Author(s)</h3>

<p>Prof. H. D. Vinod, Economics Dept., Fordham University, NY.
</p>


<h3>References</h3>

<p>Vinod, H. D. 'Generalized Correlation and Kernel Causality with
Applications in Development Economics' in Communications in
Statistics -Simulation and Computation, 2015,
<a href="https://doi.org/10.1080/03610918.2015.1122048">doi:10.1080/03610918.2015.1122048</a>
</p>


<h3>See Also</h3>

<p>See Also <code><a href="#topic+somePairs">somePairs</a></code>, <code><a href="#topic+some0Pairs">some0Pairs</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

## Not run: 
someCPairs(mtcars[,1:3],ctrl=mtcars[4:5]) # first variable is mpg and effect on mpg is of interest

## End(Not run)

## Not run: 
set.seed(234)
z=runif(10,2,11)# z is independently created
x=sample(1:10)+z/10  #x is somewhat indep and affected by z
y=1+2*x+3*z+rnorm(10)
w=runif(10)
x2=x;x2[4]=NA;y2=y;y2[8]=NA;w2=w;w2[4]=NA
someCPairs(cbind(x2,y2), cbind(z,w2)) #yields x2 as correct cause

## End(Not run)


</code></pre>

<hr>
<h2 id='someCPairs2'>Kernel causality computations admitting control variables reporting 
a 7-column matrix, version 2.</h2><span id='topic+someCPairs2'></span>

<h3>Description</h3>

<p>Second version of <code>someCPairs</code> also allows input matrix of 
control variables, produce 7 column matrix
summarizing the results where the signs of
stochastic dominance order values (+1 or -1) are weighted by 
<code>wt=c(1.2,1.1, 1.05, 1)</code> to
compute an overall result for all orders of stochastic dominance by 
a weighted sum for the criteria Cr1 and Cr2. 
The weighting is obviously not needed for the third criterion Cr3.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>someCPairs2(
  mtx,
  ctrl,
  dig = 6,
  verbo = TRUE,
  rnam = FALSE,
  wt = c(1.2, 1.1, 1.05, 1),
  sumwt = 4
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="someCPairs2_+3A_mtx">mtx</code></td>
<td>
<p>The data matrix with many columns where the first column is fixed and then 
paired with all other columns, one by one.</p>
</td></tr>
<tr><td><code id="someCPairs2_+3A_ctrl">ctrl</code></td>
<td>
<p>data matrix for designated control variable(s) outside causal paths</p>
</td></tr>
<tr><td><code id="someCPairs2_+3A_dig">dig</code></td>
<td>
<p>Number of digits for reporting (default <code>dig</code>=6).</p>
</td></tr>
<tr><td><code id="someCPairs2_+3A_verbo">verbo</code></td>
<td>
<p>Make <code>verbo= TRUE</code> for printing detailed steps.</p>
</td></tr>
<tr><td><code id="someCPairs2_+3A_rnam">rnam</code></td>
<td>
<p>Make <code>rnam= TRUE</code> if cleverly created rownames are desired.</p>
</td></tr>
<tr><td><code id="someCPairs2_+3A_wt">wt</code></td>
<td>
<p>Allows user to choose a vector of four alternative weights for SD1 to SD4.</p>
</td></tr>
<tr><td><code id="someCPairs2_+3A_sumwt">sumwt</code></td>
<td>
<p> Sum of weights can be changed here =4(default).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The reason for slightly declining weights on the signs from
SD1 to SD4 is simply that the local mean comparisons 
implicit in SD1 are known to be
more reliable than local variance implicit in SD2, local skewness implicit in
SD3 and local kurtosis implicit in SD4. The source of slightly declining sampling
unreliability of higher moments is the
higher power of the deviations from the mean needed in their computations.
The summary results for all
three criteria are reported in one matrix called <code>outVote</code>: 
</p>
<p>(typ=1) reports ('Y', 'X', 'Cause',
'SD1.rhserr', 'SD2.rhserr', 'SD3.rhserr', 'SD4.rhserr') 
naming variables identifying the 'cause'
and measures of stochastic dominance using absolute values of kernel
regression abs(RHS first regressor*residual) values
comparing flipped regressions X on Y versus Y on X.
The letter C in the titles reminds presence of control variable(s).
</p>
<p>typ=2 reports ('Y', 'X', 'Cause', 'SD1resC', 'SD2resC', 'SD3resC', 'SD4resC')
and measures of stochastic dominance using absolute values of kernel
regression residuals comparing regression of X on Y with that of Y on X.
</p>
<p>typ=3 reports ('Y', 'X', 'Cause', 'r*x|yC', 'r*y|xC', 'r', 'p-val')
containing generalized correlation coefficients r*, 'r' refers to.
Pearson correlation coefficient p-val is the p-value for 
testing the significance of 'r'. 
The letter C in the titles reminds the presence of control variable(s).
</p>


<h3>Value</h3>

<p>Prints three matrices detailing results for Cr1, Cr2 and Cr3.
It also returns a grand summary matrix called &lsquo;outVote&rsquo; which summarizes all three criteria.
In general, a positive sign for weighted sum reported in the column &lsquo;sum&rsquo; means
that the first variable listed as the input to this function is the &lsquo;kernel cause.&rsquo; 
This function is an extension of <code>some0Pairs</code> to allow for control variables. 
For example, crime &lsquo;kernel causes&rsquo; police officer deployment (not vice versa) is indicated by 
the positive sign of &lsquo;sum&rsquo; (=3.175) reported for that example included in this package.
</p>


<h3>Note</h3>

<p>The output matrix last column for &lsquo;mtcars&rsquo; example
has the sum of the scores by the three criteria
combined. If &lsquo;sum&rsquo; is positive, then variable X (mpg) is more likely to have been
engineered to kernel cause the response variable Y, rather than vice versa.
</p>
<p>The European Crime data has all three criteria correctly suggesting that
high crime rate kernel causes the deployment of a large number of police officers.
</p>


<h3>Author(s)</h3>

<p>Prof. H. D. Vinod, Economics Dept., Fordham University, NY.
</p>


<h3>References</h3>

<p>Vinod, H. D. 'Generalized Correlation and Kernel Causality with
Applications in Development Economics' in Communications in
Statistics -Simulation and Computation, 2015,
<a href="https://doi.org/10.1080/03610918.2015.1122048">doi:10.1080/03610918.2015.1122048</a>
</p>


<h3>See Also</h3>

<p>See Also <code><a href="#topic+somePairs">somePairs</a></code>, <code><a href="#topic+some0Pairs">some0Pairs</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

## Not run: 
someCPairs2(mtcars[,1:3],ctrl=mtcars[4:5]) # first variable is mpg and effect on mpg is of interest

## End(Not run)

## Not run: 
set.seed(234)
z=runif(10,2,11)# z is independently created
x=sample(1:10)+z/10  #x is somewhat indep and affected by z
y=1+2*x+3*z+rnorm(10)
w=runif(10)
x2=x;x2[4]=NA;y2=y;y2[8]=NA;w2=w;w2[4]=NA
someCPairs2(cbind(x2,y2), cbind(z,w2)) #yields x2 as correct cause

## End(Not run)


</code></pre>

<hr>
<h2 id='someMagPairs'>Summary magnitudes after removing control variables in several pairs where dependent 
variable is fixed.</h2><span id='topic+someMagPairs'></span>

<h3>Description</h3>

<p>This builds on the function <code>mag_ctrl</code>, where the input matrix <code>mtx</code>
has p columns. The first column is present in each of the (p-1) pairs. Its
output is a matrix with four columns containing the names of variables 
and approximate overall estimates of the magnitudes of
partial derivatives (dy/dx) and (dx/dy) for a distinct (x,y) pair in a row.  
The estimated overall derivatives are not always well-defined, because 
the real partial derivatives of nonlinear functions
are generally  distinct for each observation point.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>someMagPairs(mtx, ctrl, dig = 6, verbo = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="someMagPairs_+3A_mtx">mtx</code></td>
<td>
<p>The data matrix with many columns where the first column is fixed and then 
paired with all other columns, one by one.</p>
</td></tr>
<tr><td><code id="someMagPairs_+3A_ctrl">ctrl</code></td>
<td>
<p>data matrix for designated control variable(s) outside causal paths.
A constant vector is not allowed as a control variable.</p>
</td></tr>
<tr><td><code id="someMagPairs_+3A_dig">dig</code></td>
<td>
<p>Number of digits for reporting (default <code>dig</code>=6).</p>
</td></tr>
<tr><td><code id="someMagPairs_+3A_verbo">verbo</code></td>
<td>
<p>Make <code>verbo= TRUE</code> for printing detailed steps.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function <code>mag_ctrl</code> has kernel regressions: <code>x~ y + ctrl</code>
and  <code>x~ ctrl</code> to evaluate the&lsquo;incremental change&rsquo; in R-squares.
Let (rxy;ctrl) denote the square root of that &lsquo;incremental change&rsquo; after its sign is made the
same as that of the Pearson correlation coefficient from
<code>cor(x,y)</code>). One can interpret (rxy;ctrl) as
a generalized partial correlation coefficient when x is regressed on y after removing
the effect of control variable(s) in <code>ctrl</code>.  It is more general than the usual partial 
correlation coefficient, since this one
allows for nonlinear relations among variables. 
Next, the function computes &lsquo;dxdy&rsquo; obtained by multiplying (rxy;ctrl) by the ratio of
standard deviations, <code>sd(x)/sd(y)</code>. Now our &lsquo;dxdy&rsquo; approximates the magnitude of the
partial derivative (dx/dy) in a causal model where y is the cause and x is the effect.
The function also reports entirely analogous &lsquo;dydx&rsquo; obtained by interchanging x and y.
</p>
<p><code>someMegPairs</code> function runs  the function <code>mag_ctrl</code> on several column
pairs in a matrix input <code>mtx</code> where the first column is held fixed and all others
are changed one by one, reporting two partial derivatives for each row.
</p>


<h3>Value</h3>

<p>Table containing names of Xi and Xj and two magnitudes: (dXidXj, dXjdXi).
dXidXj is the magnitude of the effect on Xi when Xi is regressed on Xj 
(i.e., when Xj is the cause).  The analogous dXjdXi is the magnitude
when Xj is regressed on Xi.
</p>


<h3>Note</h3>

<p>This function is intended for use only after the causal path direction 
is already determined by various functions in this package (e.g. <code>someCPairs</code>).
That is, after the researcher knows whether Xi causes Xj or vice versa.
The output of this function is a matrix of 4 columns, where first columns list
the names of Xi and Xj and the next two numbers in each row are
dXidXj, dXjdXi, respectively,
representing the magnitude of effect of one variable on the other.
</p>


<h3>Author(s)</h3>

<p>Prof. H. D. Vinod, Economics Dept., Fordham University, NY
</p>


<h3>References</h3>

<p>Vinod, H. D. 'Generalized Correlation and Kernel Causality with
Applications in Development Economics' in Communications in
Statistics -Simulation and Computation, 2015,
<a href="https://doi.org/10.1080/03610918.2015.1122048">doi:10.1080/03610918.2015.1122048</a>
</p>
<p>Vinod, H. D. 'Matrix Algebra Topics in Statistics and Economics
Using R', Chapter 4 in Handbook of Statistics: Computational Statistics
with R, Vol.32, co-editors: M. B. Rao and C. R. Rao. New York:
North Holland, Elsevier Science Publishers, 2014, pp. 143-176.
</p>


<h3>See Also</h3>

<p>See  <code><a href="#topic+mag_ctrl">mag_ctrl</a></code>, <code><a href="#topic+someCPairs">someCPairs</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
  set.seed(34);x=sample(1:10);y=1+2*x+rnorm(10);z=sample(2:11)
  w=runif(10)
  ss=someMagPairs(cbind(y,x,z),ctrl=w)

</code></pre>

<hr>
<h2 id='somePairs'>Function reporting kernel causality results as a 7-column matrix.(deprecated)</h2><span id='topic+somePairs'></span>

<h3>Description</h3>

<p>This function lets the user choose one of three criteria to determine causal direction
by setting <code>typ</code> as 1, 2 or 3.  This function reports results for 
only one criterion at a time unlike the function <code>some0Pairs</code> which
summarizes the resulting causal directions for all criteria with suitable weights.
If some variables are &lsquo;control&rsquo; variables, use <code>someCPairs</code>, C=control.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>somePairs(mtx, dig = 6, verbo = FALSE, typ = 1, rnam = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="somePairs_+3A_mtx">mtx</code></td>
<td>
<p>The data matrix in the first column is paired with all others.</p>
</td></tr>
<tr><td><code id="somePairs_+3A_dig">dig</code></td>
<td>
<p>Number of digits for reporting (default <code>dig</code>=6).</p>
</td></tr>
<tr><td><code id="somePairs_+3A_verbo">verbo</code></td>
<td>
<p>Make <code>verbo= TRUE</code> for printing detailed steps.</p>
</td></tr>
<tr><td><code id="somePairs_+3A_typ">typ</code></td>
<td>
<p>Must be 1 (default), 2 or 3 for the three criteria.</p>
</td></tr>
<tr><td><code id="somePairs_+3A_rnam">rnam</code></td>
<td>
<p>Make <code>rnam= TRUE</code> if cleverly created rownames are desired.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>(typ=1) reports ('Y', 'X', 'Cause',
'SD1apd', 'SD2apd', 'SD3apd', 'SD4apd') nameing variables identifying 'cause'
and measures of stochastic dominance using absolute values of kernel
regression gradients comparing regresson of X on Y with that of Y on X.
</p>
<p>(typ=2) 
reports ('Y', 'X', 'Cause', 'SD1res', 'SD2res', 'SD3res', 'SD4res')
and measures of stochastic dominance using absolute values of kernel
regression residuals comparing regresson of X on Y with that of Y on X.
</p>
<p>(typ=3) 
reports ('Y', 'X', 'Cause', 'r*X|Y', 'r*Y|X', 'r', 'p-val')
containing generalized correlation coefficients r*, 'r' refers to the
Pearson correlation coefficient and p-val column has the p-values for 
testing the significance of Pearson's 'r'.
</p>


<h3>Value</h3>

<p>A matrix containing causal identification results for one criterion.
The first column of the input <code>mtx</code> having p columns
is paired with (p-1) other columns  The output matrix headings are
self-explanatory and distinct for each criterion Cr1 to Cr3.
</p>


<h3>Author(s)</h3>

<p>Prof. H. D. Vinod, Economics Dept., Fordham University, NY
</p>


<h3>References</h3>

<p>H. D. Vinod 'Generalized Correlation and Kernel Causality with
Applications in Development Economics' in Communications in
Statistics -Simulation and Computation, 2015,
<a href="https://doi.org/10.1080/03610918.2015.1122048">doi:10.1080/03610918.2015.1122048</a>
</p>


<h3>See Also</h3>

<p>The related function <code><a href="#topic+some0Pairs">some0Pairs</a></code> may be more useful, since it
reports on all three criteria (by choosing typ=1,2,3) and
further summarizes their results by weighting to help choose causal paths.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
data(mtcars)
somePairs(mtcars)

## End(Not run)

</code></pre>

<hr>
<h2 id='somePairs2'>Function reporting kernel causality results as a 7-column matrix, version 2.</h2><span id='topic+somePairs2'></span>

<h3>Description</h3>

<p>This function is an alternative implementation of <code>somePairs</code>
which also lets the user choose one of three criteria to determine causal direction
by setting <code>typ</code> as 1, 2 or 3.  This function reports results for 
only one criterion at a time unlike the function <code>some0Pairs</code> which
summarizes the resulting causal directions for all criteria with suitable weights.
If some variables are &lsquo;control&rsquo; variables, use <code>someCPairs</code>, 
where notation C=control.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>somePairs2(mtx, dig = 6, verbo = FALSE, typ = 1, rnam = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="somePairs2_+3A_mtx">mtx</code></td>
<td>
<p>The data matrix in the first column is paired with all others.</p>
</td></tr>
<tr><td><code id="somePairs2_+3A_dig">dig</code></td>
<td>
<p>Number of digits for reporting (default <code>dig</code>=6).</p>
</td></tr>
<tr><td><code id="somePairs2_+3A_verbo">verbo</code></td>
<td>
<p>Make <code>verbo= TRUE</code> for printing detailed steps.</p>
</td></tr>
<tr><td><code id="somePairs2_+3A_typ">typ</code></td>
<td>
<p>Must be 1 (default), 2 or 3 for the three criteria.</p>
</td></tr>
<tr><td><code id="somePairs2_+3A_rnam">rnam</code></td>
<td>
<p>Make <code>rnam= TRUE</code> if cleverly created rownames are desired.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>(typ=1) reports ('Y', 'X', 'Cause',
'SD1.rhserr', 'SD2.rhserr', 'SD3.rhserr', 'SD4.rhserr') 
naming variables identifying the 'cause,' using Hausman-Wu criterion.
It measures of stochastic dominance using absolute values of kernel
regression abs(RHS first regressor*residual),  
comparing flipped regressions X on Y versus Y on X.
</p>
<p>(typ=2) 
reports ('Y', 'X', 'Cause', 'SD1res', 'SD2res', 'SD3res', 'SD4res')
and measures of stochastic dominance using absolute values of kernel
regression residuals comparing regression of X on Y with that of Y on X.
</p>
<p>(typ=3) 
reports ('Y', 'X', 'Cause', 'r*X|Y', 'r*Y|X', 'r', 'p-val')
containing generalized correlation coefficients r*, 'r' refers to the
Pearson correlation coefficient and p-val column has the p-values for 
testing the significance of Pearson's 'r'.
</p>


<h3>Value</h3>

<p>A matrix containing causal identification results for one criterion.
The first column of the input <code>mtx</code> having p columns
is paired with (p-1) other columns  The output matrix headings are
self-explanatory and distinct for each criterion Cr1 to Cr3.
</p>


<h3>Author(s)</h3>

<p>Prof. H. D. Vinod, Economics Dept., Fordham University, NY
</p>


<h3>References</h3>

<p>H. D. Vinod 'Generalized Correlation and Kernel Causality with
Applications in Development Economics' in Communications in
Statistics -Simulation and Computation, 2015,
<a href="https://doi.org/10.1080/03610918.2015.1122048">doi:10.1080/03610918.2015.1122048</a>
</p>


<h3>See Also</h3>

<p>The related function <code><a href="#topic+some0Pairs">some0Pairs</a></code> may be more useful, since it
reports on all three criteria (by choosing typ=1,2,3) and
further summarizes their results by weighting to help choose causal paths.
</p>
<p>Alternative and revised function <code><a href="#topic+somePairs2">somePairs2</a></code> 
implements the Cr1 (first criterion) with a direct estimate of
the Hausman-Wu statistic for testing exogeneity.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
data(mtcars)
somePairs2(mtcars)

## End(Not run)

</code></pre>

<hr>
<h2 id='sort_matrix'>Sort all columns of matrix x with respect to the j-th column.</h2><span id='topic+sort_matrix'></span>

<h3>Description</h3>

<p>This function can use the sort.list function in R. The reason
for using it is that one wants the sort to carry along all columns.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sort_matrix(x, j)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sort_matrix_+3A_x">x</code></td>
<td>
<p>An input matrix with several columns</p>
</td></tr>
<tr><td><code id="sort_matrix_+3A_j">j</code></td>
<td>
<p>The column number with reference to which one wants to sort</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A sorted matrix
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(30)
x=matrix(sample(1:50),ncol=5)
y=sort_matrix(x,3);y
</code></pre>

<hr>
<h2 id='sort.abse0'>
internal sort.abse0
</h2><span id='topic+sort.abse0'></span>

<h3>Description</h3>

<p>intended for internal use only
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sort.abse0</code></pre>

<hr>
<h2 id='sort.e0'>
internal sort.e0
</h2><span id='topic+sort.e0'></span>

<h3>Description</h3>

<p>intended for internal use only
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sort.e0</code></pre>

<hr>
<h2 id='stdres'>Residuals of kernel regressions of x on y when both x and
y are standardized.</h2><span id='topic+stdres'></span>

<h3>Description</h3>

<p>1) Standardize the data to force mean zero and variance unity, 2) kernel
regress x on y, with the option &lsquo;residuals = TRUE&rsquo;, and finally 3) compute
the residuals. The standardization yields comparable residuals.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>stdres(x, y)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="stdres_+3A_x">x</code></td>
<td>
<p>vector of data on the dependent variable</p>
</td></tr>
<tr><td><code id="stdres_+3A_y">y</code></td>
<td>
<p>data on the regressors which can be a matrix</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The first argument is assumed to be the dependent variable.  If
<code>stdres(x,y)</code> is used, you are regressing x on y (not the usual y
on x). The regressors can be a matrix with 2 or more columns. The missing values
are suitably ignored by the standardization.
</p>


<h3>Value</h3>

<p>kernel regression residuals are returned after
standardizing the data on both sides so that the magnitudes of residuals are
comparable between regression of x on y on the one hand, and 
the flipped regression of y
on x on the other.
</p>


<h3>Author(s)</h3>

<p>Prof. H. D. Vinod, Economics Dept., Fordham University, NY
</p>


<h3>References</h3>

<p>Vinod, H. D. 'Generalized Correlation and Kernel Causality with
Applications in Development Economics' in Communications in
Statistics -Simulation and Computation, 2015,
<a href="https://doi.org/10.1080/03610918.2015.1122048">doi:10.1080/03610918.2015.1122048</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
set.seed(330)
x=sample(20:50)
y=sample(20:50)
stdres(x,y)

## End(Not run)

</code></pre>

<hr>
<h2 id='stdz_xy'>Standardize x and y vectors to achieve zero mean and unit variance.</h2><span id='topic+stdz_xy'></span>

<h3>Description</h3>

<p>Standardize x and y vectors to achieve zero mean and unit variance.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>stdz_xy(x, y)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="stdz_xy_+3A_x">x</code></td>
<td>
<p>Vector of data which can have NA's</p>
</td></tr>
<tr><td><code id="stdz_xy_+3A_y">y</code></td>
<td>
<p>Vector of data which can have NA's</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>stdx</code></td>
<td>
<p>standardized values of x</p>
</td></tr>
<tr><td><code>stdy</code></td>
<td>
<p>standardized values of y</p>
</td></tr>
</table>


<h3>Note</h3>

<p>This works even if there are missing x or y values.
</p>


<h3>Author(s)</h3>

<p>Prof. H. D. Vinod, Economics Dept., Fordham University, NY
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
set.seed(30)
x=sample(20:30)
y=sample(21:31)
stdz_xy(x,y) 
## End(Not run)

</code></pre>

<hr>
<h2 id='stochdom2'>Compute vectors measuring stochastic dominance of four orders.</h2><span id='topic+stochdom2'></span>

<h3>Description</h3>

<p>Stochastic dominance originated as a sophisticated comparison of two distributions of
stock market returns.  The dominating distribution is superior in terms of local
mean, variance, skewness, and kurtosis, respectively. However, stochastic 
dominance orders 1 to 4 are really not related to the four moments. 
Some details are in Vinod (2022, sec. 4.3) and vignettes. Nevertheless, 
this function uses the output of &lsquo;wtdpapb.&rsquo; and Anderson's
algorithm. Of course, Anderson's method
remains subject to the trapezoidal approximation avoided by exact stochastic
dominance methods.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>stochdom2(dj, wpa, wpb)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="stochdom2_+3A_dj">dj</code></td>
<td>
<p>Vector of (unequal) distances of consecutive intervals defined on common support
of two probability distributions being compared</p>
</td></tr>
<tr><td><code id="stochdom2_+3A_wpa">wpa</code></td>
<td>
<p>Vector of the first set of (weighted) probabilities</p>
</td></tr>
<tr><td><code id="stochdom2_+3A_wpb">wpb</code></td>
<td>
<p>Vector of the second set of (weighted) probabilities</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>sd1b</code></td>
<td>
<p>Vector measuring stochastic dominance of order 1, SD1</p>
</td></tr> 
<tr><td><code>sd2b</code></td>
<td>
<p>Vector measuring stochastic dominance of order 2, SD2</p>
</td></tr> 
<tr><td><code>sd3b</code></td>
<td>
<p>Vector measuring stochastic dominance of order 3, SD3</p>
</td></tr> 
<tr><td><code>sd4b</code></td>
<td>
<p>Vector measuring stochastic dominance of order 4, SD4</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The input to this function is the output of the function <code>wtdpapb</code>.
</p>


<h3>Author(s)</h3>

<p>Prof. H. D. Vinod, Economics Dept., Fordham University, NY
</p>


<h3>References</h3>

<p>Vinod, H. D.', 'Hands-On Intermediate Econometrics 
Using R'  (2008) World Scientific Publishers: Hackensack, NJ.
<a href="https://www.worldscientific.com/worldscibooks/10.1142/12831">https://www.worldscientific.com/worldscibooks/10.1142/12831</a>
</p>
<p>Vinod, H. D. 'Ranking Mutual Funds Using 
Unconventional Utility Theory and Stochastic Dominance,'
Journal of Empirical Finance Vol. 11(3) 2004, pp. 353-377.
</p>


<h3>See Also</h3>

<p>See Also <code><a href="#topic+wtdpapb">wtdpapb</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
 ## Not run: 
 set.seed(234);x=sample(1:30);y=sample(5:34)
 w1=wtdpapb(x,y) #y should dominate x with mostly positive SDs
 stochdom2(w1$dj, w1$wpa, w1$wpb) 
## End(Not run)

</code></pre>

<hr>
<h2 id='sudoCoefParcor'>Pseudo regression coefficients from generalized partial correlation coefficients, 
(GPCC).</h2><span id='topic+sudoCoefParcor'></span>

<h3>Description</h3>

<p>This function gets the GPCCs by calling  the <code>parcorVec</code> function. The
pseudo regression coefficient of a kernel regression is then obtained by
[GPCC*(sd dep.var)/(sd regressor)], that is, by
multiplying the GPCC by
the standard deviation (sd) of the dependent variable, and dividing by the
sd of the regressor.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sudoCoefParcor(mtx, ctrl = 0, verbo = FALSE, idep = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sudoCoefParcor_+3A_mtx">mtx</code></td>
<td>
<p>Input data matrix with p (&gt; or = 3) columns,</p>
</td></tr>
<tr><td><code id="sudoCoefParcor_+3A_ctrl">ctrl</code></td>
<td>
<p>Input vector or matrix of data for control variable(s), 
default is ctrl=0, when control variables are absent</p>
</td></tr>
<tr><td><code id="sudoCoefParcor_+3A_verbo">verbo</code></td>
<td>
<p>Make this TRUE for detailed printing of computational steps</p>
</td></tr>
<tr><td><code id="sudoCoefParcor_+3A_idep">idep</code></td>
<td>
<p>The column number of the dependent variable (=1, default)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A p by 1 &lsquo;out&rsquo; vector pseudo partial derivatives.
</p>


<h3>Note</h3>

<p>Generalized Partial Correlation Coefficients (GPCC) allow comparison of
the relative contribution of each <code class="reqn">X_j</code> to the explanation of <code class="reqn">X_i</code>,
because GPCC are scale-free. The pseudo regression
coefficient are not scale-free since they equal GPCC*(sd dep.var)/(sd regressor)
</p>
<p>We want to get all partial
correlation coefficient pairs removing other column effects. Vinod (2018) 
shows why one needs more than one criterion to decide the causal paths or exogeneity.
</p>


<h3>Author(s)</h3>

<p>Prof. H. D. Vinod, Economics Dept., Fordham University, NY.
</p>


<h3>References</h3>

<p>Vinod, H. D. 'Generalized Correlations and Instantaneous
Causality for Data Pairs Benchmark,' (March 8, 2015)
<a href="https://www.ssrn.com/abstract=2574891">https://www.ssrn.com/abstract=2574891</a>
</p>
<p>Vinod, H. D. 'Matrix Algebra Topics in Statistics and Economics
Using R', Chapter 4 in Handbook of Statistics: Computational Statistics
with R, Vol.32, co-editors: M. B. Rao and C.R. Rao. New York:
North Holland, Elsevier Science Publishers, 2014, pp. 143-176.
</p>
<p>Vinod, H. D. 'New Exogeneity Tests and Causal Paths,' 
(June 30, 2018). Available at SSRN: 
<a href="https://www.ssrn.com/abstract=3206096">https://www.ssrn.com/abstract=3206096</a>
</p>
<p>Vinod, H. D. (2021) 'Generalized, Partial and Canonical Correlation
Coefficients' Computational Economics, 59(1), 1&ndash;28.
</p>


<h3>See Also</h3>

<p>See Also <code><a href="#topic+parcor_ijk">parcor_ijk</a></code>.
</p>
<p>See Also a hybrid version <code><a href="#topic+parcorVecH">parcorVecH</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(234)
z=runif(10,2,11)# z is independently created
x=sample(1:10)+z/10  #x is partly indep and partly affected by z
y=1+2*x+3*z+rnorm(10)# y depends on x and z not vice versa
mtx=cbind(x,y,z)
sudoCoefParcor(mtx, idep=2)
 
   
## Not run: 
set.seed(34);x=matrix(sample(1:600)[1:99],ncol=3)
colnames(x)=c('V1', 'v2', 'V3')#some names needed
sudoCoefParcor(x)

## End(Not run)

</code></pre>

<hr>
<h2 id='sudoCoefParcorH'>Peudo regression coefficients from hybrid generalized partial 
correlation coefficients (HGPCC).</h2><span id='topic+sudoCoefParcorH'></span>

<h3>Description</h3>

<p>This function gets HGPCCs by calling  <code>parcorVecH</code> function.
Pseudo regression coefficient of a kernel regression is obtained by
HGPCC*(sd dep.var)/(sd regressor), that is
multiplying the HGPCC by
the standard deviation (sd) of the dependent variable and dividing by the
sd of the regressor.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sudoCoefParcorH(mtx, ctrl = 0, verbo = FALSE, idep = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sudoCoefParcorH_+3A_mtx">mtx</code></td>
<td>
<p>Input data matrix with p (&gt; or = 3) columns,</p>
</td></tr>
<tr><td><code id="sudoCoefParcorH_+3A_ctrl">ctrl</code></td>
<td>
<p>Input vector or matrix of data for control variable(s), 
default is ctrl=0 when control variables are absent</p>
</td></tr>
<tr><td><code id="sudoCoefParcorH_+3A_verbo">verbo</code></td>
<td>
<p>Make this TRUE for detailed printing of computational steps</p>
</td></tr>
<tr><td><code id="sudoCoefParcorH_+3A_idep">idep</code></td>
<td>
<p>The column number of the dependent variable (=1, default)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A p by 1 &lsquo;out&rsquo; vector pseudo partial derivatives
</p>


<h3>Note</h3>

<p>Hybrid Generalized Partial Correlation Coefficients (HGPCC) allow comparison of
the relative contribution of each <code class="reqn">X_j</code> to the explanation of <code class="reqn">X_i</code>,
because GPCC are scale-free. Hybrid refers to use of OLS residuals.
Now pseudo hybrid regr coeff are HGPCC*(sd dep.var)/(sd regressor)
</p>
<p>We want to get all partial
correlation coefficient pairs removing other column effects. Vinod (2018) 
shows why one needs more than one criterion to decide the causal paths or exogeneity.
</p>


<h3>Author(s)</h3>

<p>Prof. H. D. Vinod, Economics Dept., Fordham University, NY.
</p>


<h3>References</h3>

<p>Vinod, H. D. 'Generalized Correlations and Instantaneous
Causality for Data Pairs Benchmark,' (March 8, 2015)
<a href="https://www.ssrn.com/abstract=2574891">https://www.ssrn.com/abstract=2574891</a>
</p>
<p>Vinod, H. D. 'Matrix Algebra Topics in Statistics and Economics
Using R', Chapter 4 in Handbook of Statistics: Computational Statistics
with R, Vol.32, co-editors: M. B. Rao and C.R. Rao. New York:
North Holland, Elsevier Science Publishers, 2014, pp. 143-176.
</p>
<p>Vinod, H. D. 'New Exogeneity Tests and Causal Paths,' 
(June 30, 2018). Available at SSRN: 
<a href="https://www.ssrn.com/abstract=3206096">https://www.ssrn.com/abstract=3206096</a>
</p>
<p>Vinod, H. D. (2021) 'Generalized, Partial and Canonical Correlation
Coefficients' Computational Economics, 59(1), 1&ndash;28.
</p>


<h3>See Also</h3>

<p>See Also <code><a href="#topic+parcor_ijk">parcor_ijk</a></code>.
</p>
<p>See Also a hybrid version <code><a href="#topic+parcorVecH">parcorVecH</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(234)
z=runif(10,2,11)# z is independently created
x=sample(1:10)+z/10  #x is partly indep and partly affected by z
y=1+2*x+3*z+rnorm(10)# y depends on x and z not vice versa
mtx=cbind(x,y,z)
sudoCoefParcor(mtx, idep=2)
 
   
## Not run: 
set.seed(34);x=matrix(sample(1:600)[1:99],ncol=3)
colnames(x)=c('V1', 'v2', 'V3')#some names needed
sudoCoefParcorH(x)

## End(Not run)

</code></pre>

<hr>
<h2 id='summaryRank'>Compute ranks of rows of matrix and summarize them into a choice suggestion.</h2><span id='topic+summaryRank'></span>

<h3>Description</h3>

<p>This function allows getting out the choice (of a column representing a stock) from four
rows of numbers quantifying the four orders of exact stochastic dominance comparisons.
If the last or 10-th row for &ldquo;choice&quot; has 1 then the stock representing
that column is to be chosen. That is it should get the largest
(portfolio) weight. If the original matrix row names are SD1 to SD4, 
the same names are repeated for the extra rows representing their ranks.  
The row name for &ldquo;sum of ranks&quot; is
sumRanks. Finally, the ranks associated with sumRanks provide the row named choice
along the bottom (10-th) row of the output matrix called &quot;out.&quot;
</p>


<h3>Usage</h3>

<pre><code class='language-R'>summaryRank(mtx)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summaryRank_+3A_mtx">mtx</code></td>
<td>
<p>matrix to be ranked by row and summarized</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a matrix called &lsquo;out&rsquo; having 10 rows and p columns (p=No.of stocks). 
Row Numbers 1 to 4 have SD1 to SD4 evaluation of areas over ECDFs. 
There are 6 more rows. Row No.5= SD1 ranks,
Row No.6= SD2 ranks, Row No.7= SD3 ranks, Row No.8= SD4 ranks
Row No.9= sum of the ranks in earlier four rows for ranks of SD1 to SD4
Row No.10= choice rank based on all four (SD1 to SD4) added together
Thus, the tenth row yields choice priority number for each stock (asset)
after combining the all four criteria.
</p>


<h3>Author(s)</h3>

<p>Prof. H. D. Vinod, Economics Dept., Fordham University, NY
</p>


<h3>See Also</h3>

<p><code><a href="#topic+exactSdMtx">exactSdMtx</a></code>
</p>

<hr>
<h2 id='symmze'>Replace asymmetric matrix by max of abs values of [i,j] or [j,i] elements.</h2><span id='topic+symmze'></span>

<h3>Description</h3>

<p>It is useful in symmetrizing the gmcmtx0 matrix containing a non-symmetric
generalized correlation matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>symmze(mtx)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="symmze_+3A_mtx">mtx</code></td>
<td>
<p>non-symmetric matrix</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>mtx2</code></td>
<td>
<p>replace [i,j] and [j,i] by the max of absolute values
with common sign</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Prof. H. D. Vinod, Economics Dept., Fordham University, NY.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
example 
mtx=matrix(1:16,nrow=4)
symmze(mtx)

## End(Not run)#' 
</code></pre>

<hr>
<h2 id='wtdpapb'>Creates input for the stochastic dominance function stochdom2</h2><span id='topic+wtdpapb'></span>

<h3>Description</h3>

<p>Stochastic dominance is a sophisticated comparison of two distributions of
stock market returns.  The dominating distribution is superior in terms of
mean, variance, skewness and kurtosis respectively, representing dominance
orders 1 to 4, without directly computing four moments.  Vinod(2008) sec. 4.3
explains the details.  The &lsquo;wtdpapb&rsquo; function creates the input
for stochdom2 which in turn computes the stochastic dominance.
See Vinod (2004) for details about quantitative stochastic dominance.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>wtdpapb(xa, xb)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="wtdpapb_+3A_xa">xa</code></td>
<td>
<p>Vector of (excess) returns for the first investment option A or
values of any random variable being compared to another.</p>
</td></tr>
<tr><td><code id="wtdpapb_+3A_xb">xb</code></td>
<td>
<p>Vector of returns for the second option B</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>wpa</code></td>
<td>
<p>Weighted vector of probabilities for option A</p>
</td></tr> 
<tr><td><code>wpb</code></td>
<td>
<p>Weighted vector of probabilities for option B</p>
</td></tr> 
<tr><td><code>dj</code></td>
<td>
<p>Vector of interval widths (distances) when both sets of data are forced on a common support</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Function is needed before using stochastic dominance
</p>
<p>In Vinod (2008) where the purpose of <code>wtdpapb</code> is to map from standard
&lsquo;expected utility theory&rsquo; weights to more sophisticated 'non-expected utility
theory' weights using Prelec's (1998, Econometrica, p. 497) method.  These
weights are not needed here. Hence we provide the function <code>prelec2</code>
which does not use Prelec weights at all, thereby simplifying and speeding up
the R code provided in Vinod (2008). This function avoids sophisticated &lsquo;non-expected&rsquo;
utility theory which incorporates commonly observed human behavior favoring
loss aversion and other anomalies inconsistent with precepts of the
expected utility theory. Such weighting is not needed for our application.
</p>


<h3>Author(s)</h3>

<p>Prof. H. D. Vinod, Economics Dept., Fordham University, NY
</p>


<h3>References</h3>

<p>Vinod, H. D.', 'Hands-On Intermediate Econometrics 
Using R'  (2008) World Scientific Publishers: Hackensack, NJ.
<a href="https://www.worldscientific.com/worldscibooks/10.1142/12831">https://www.worldscientific.com/worldscibooks/10.1142/12831</a>
</p>
<p>Vinod, H. D. 'Ranking Mutual Funds Using 
Unconventional Utility Theory and Stochastic Dominance,'
Journal of Empirical Finance Vol. 11(3) 2004, pp. 353-377.
</p>


<h3>See Also</h3>

<p>See Also <code><a href="#topic+stochdom2">stochdom2</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
 ## Not run: 
 set.seed(234);x=sample(1:30);y=sample(5:34)
 wtdpapb(x,y)
## End(Not run)

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
