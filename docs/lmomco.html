<!DOCTYPE html><html><head><title>Help for package lmomco</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {lmomco}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#lmomco-package'><p>L-moments, Censored L-moments, Trimmed L-moments, L-comoments, and Many Distributions</p></a></li>
<li><a href='#.lmomcohash'><p>Storage of Lookup Tables for the lmomco Package</p></a></li>
<li><a href='#add.lmomco.axis'><p>Add an lmomco Axis to a Plot</p></a></li>
<li><a href='#add.log.axis'><p>Add a Polished Logarthimic Axis to a Plot</p></a></li>
<li><a href='#amarilloprecip'><p>Annual Maximum Precipitation Data for Amarillo, Texas</p></a></li>
<li><a href='#Apwm2BpwmRC'><p>Conversion between A- and B-Type Probability-Weighted Moments for Right-Tail Censoring of an Appropriate Distribution</p></a></li>
<li><a href='#are.lmom.valid'><p>Are the L-moments valid</p></a></li>
<li><a href='#are.par.valid'><p>Are the Distribution Parameters Consistent with the Distribution</p></a></li>
<li><a href='#are.paraep4.valid'><p>Are the Distribution Parameters Consistent with the 4-Parameter Asymmetric Exponential Power Distribution</p></a></li>
<li><a href='#are.parcau.valid'><p>Are the Distribution Parameters Consistent with the Cauchy Distribution</p></a></li>
<li><a href='#are.paremu.valid'><p>Are the Distribution Parameters Consistent with the Eta-Mu Distribution</p></a></li>
<li><a href='#are.parexp.valid'><p>Are the Distribution Parameters Consistent with the Exponential Distribution</p></a></li>
<li><a href='#are.pargam.valid'><p>Are the Distribution Parameters Consistent with the Gamma Distribution</p></a></li>
<li><a href='#are.pargep.valid'><p>Are the Distribution Parameters Consistent with the Generalized Exponential Poisson Distribution</p></a></li>
<li><a href='#are.pargev.valid'><p>Are the Distribution Parameters Consistent with the Generalized Extreme Value Distribution</p></a></li>
<li><a href='#are.pargld.valid'><p>Are the Distribution Parameters Consistent with the Generalized Lambda Distribution</p></a></li>
<li><a href='#are.parglo.valid'><p>Are the Distribution Parameters Consistent with the Generalized Logistic Distribution</p></a></li>
<li><a href='#are.pargno.valid'><p>Are the Distribution Parameters Consistent with the Generalized Normal Distribution</p></a></li>
<li><a href='#are.pargov.valid'><p>Are the Distribution Parameters Consistent with the Govindarajulu Distribution</p></a></li>
<li><a href='#are.pargpa.valid'><p>Are the Distribution Parameters Consistent with the Generalized Pareto Distribution</p></a></li>
<li><a href='#are.pargum.valid'><p>Are the Distribution Parameters Consistent with the Gumbel Distribution</p></a></li>
<li><a href='#are.parkap.valid'><p>Are the Distribution Parameters Consistent with the Kappa Distribution</p></a></li>
<li><a href='#are.parkmu.valid'><p>Are the Distribution Parameters Consistent with the Kappa-Mu Distribution</p></a></li>
<li><a href='#are.parkur.valid'><p>Are the Distribution Parameters Consistent with the Kumaraswamy Distribution</p></a></li>
<li><a href='#are.parlap.valid'><p>Are the Distribution Parameters Consistent with the Laplace Distribution</p></a></li>
<li><a href='#are.parlmrq.valid'><p>Are the Distribution Parameters Consistent with the Linear Mean Residual Quantile Function Distribution</p></a></li>
<li><a href='#are.parln3.valid'><p>Are the Distribution Parameters Consistent with the 3-Parameter Log-Normal Distribution</p></a></li>
<li><a href='#are.parnor.valid'><p>Are the Distribution Parameters Consistent with the Normal Distribution</p></a></li>
<li><a href='#are.parpdq3.valid'><p>Are the Distribution Parameters Consistent with the Polynomial Density-Quantile#</p></a></li>
<li><a href='#are.parpdq4.valid'><p>Are the Distribution Parameters Consistent with the Polynomial Density-Quantile4</p></a></li>
<li><a href='#are.parpe3.valid'><p>Are the Distribution Parameters Consistent with the Pearson Type III Distribution</p></a></li>
<li><a href='#are.parray.valid'><p>Are the Distribution Parameters Consistent with the Rayleigh Distribution</p></a></li>
<li><a href='#are.parrevgum.valid'><p>Are the Distribution Parameters Consistent with the Reverse Gumbel Distribution</p></a></li>
<li><a href='#are.parrice.valid'><p>Are the Distribution Parameters Consistent with the Rice Distribution</p></a></li>
<li><a href='#are.parsla.valid'><p>Are the Distribution Parameters Consistent with the Slash Distribution</p></a></li>
<li><a href='#are.parsmd.valid'><p>Are the Distribution Parameters Consistent with the Singh&ndash;Maddala Distribution</p></a></li>
<li><a href='#are.parst3.valid'><p>Are the Distribution Parameters Consistent with the 3-Parameter Student t Distribution</p></a></li>
<li><a href='#are.partexp.valid'><p>Are the Distribution Parameters Consistent with the Truncated Exponential Distribution</p></a></li>
<li><a href='#are.partri.valid'><p>Are the Distribution Parameters Consistent with the Asymmetric Triangular Distribution</p></a></li>
<li><a href='#are.parwak.valid'><p>Are the Distribution Parameters Consistent with the Wakeby Distribution</p></a></li>
<li><a href='#are.parwei.valid'><p>Are the Distribution Parameters Consistent with the Weibull Distribution</p></a></li>
<li><a href='#BEhypergeo'><p>Barnes Extended Hypergeometric Function</p></a></li>
<li><a href='#bfrlmomco'><p>Bonferroni Curve of the Distributions</p></a></li>
<li><a href='#Bpwm2ApwmRC'><p>Conversion between B- and A-Type Probability-Weighted Moments for Right-Tail Censoring of an Appropriate Distribution</p></a></li>
<li><a href='#canyonprecip'><p>Annual Maximum Precipitation Data for Canyon, Texas</p></a></li>
<li><a href='#cdf2lmom'><p>Compute an L-moment from Cumulative Distribution Function</p></a></li>
<li><a href='#cdf2lmoms'><p>Compute L-moments from Cumulative Distribution Function</p></a></li>
<li><a href='#cdfaep4'><p>Cumulative Distribution Function of the 4-Parameter Asymmetric Exponential Power Distribution</p></a></li>
<li><a href='#cdfcau'><p>Cumulative Distribution Function of the Cauchy Distribution</p></a></li>
<li><a href='#cdfemu'><p>Cumulative Distribution Function of the Eta-Mu Distribution</p></a></li>
<li><a href='#cdfexp'><p>Cumulative Distribution Function of the Exponential Distribution</p></a></li>
<li><a href='#cdfgam'><p>Cumulative Distribution Function of the Gamma Distribution</p></a></li>
<li><a href='#cdfgep'><p>Cumulative Distribution Function of the Generalized Exponential Poisson Distribution</p></a></li>
<li><a href='#cdfgev'><p>Cumulative Distribution Function of the Generalized Extreme Value Distribution</p></a></li>
<li><a href='#cdfgld'><p>Cumulative Distribution Function of the Generalized Lambda Distribution</p></a></li>
<li><a href='#cdfglo'><p>Cumulative Distribution Function of the Generalized Logistic Distribution</p></a></li>
<li><a href='#cdfgno'><p>Cumulative Distribution Function of the Generalized Normal Distribution</p></a></li>
<li><a href='#cdfgov'><p>Cumulative Distribution Function of the Govindarajulu Distribution</p></a></li>
<li><a href='#cdfgpa'><p>Cumulative Distribution Function of the Generalized Pareto Distribution</p></a></li>
<li><a href='#cdfgum'><p>Cumulative Distribution Function of the Gumbel Distribution</p></a></li>
<li><a href='#cdfkap'><p>Cumulative Distribution Function of the Kappa Distribution</p></a></li>
<li><a href='#cdfkmu'><p>Cumulative Distribution Function of the Kappa-Mu Distribution</p></a></li>
<li><a href='#cdfkur'><p>Cumulative Distribution Function of the Kumaraswamy Distribution</p></a></li>
<li><a href='#cdflap'><p>Cumulative Distribution Function of the Laplace Distribution</p></a></li>
<li><a href='#cdflmrq'><p>Cumulative Distribution Function of the  Linear Mean Residual Quantile Function Distribution</p></a></li>
<li><a href='#cdfln3'><p>Cumulative Distribution Function of the 3-Parameter Log-Normal Distribution</p></a></li>
<li><a href='#cdfnor'><p>Cumulative Distribution Function of the Normal Distribution</p></a></li>
<li><a href='#cdfpdq3'><p>Cumulative Distribution Function of the Polynomial Density-Quantile3 Distribution</p></a></li>
<li><a href='#cdfpdq4'><p>Cumulative Distribution Function of the Polynomial Density-Quantile4 Distribution</p></a></li>
<li><a href='#cdfpe3'><p>Cumulative Distribution Function of the Pearson Type III Distribution</p></a></li>
<li><a href='#cdfray'><p>Cumulative Distribution Function of the Rayleigh Distribution</p></a></li>
<li><a href='#cdfrevgum'><p>Cumulative Distribution Function of the Reverse Gumbel Distribution</p></a></li>
<li><a href='#cdfrice'><p>Cumulative Distribution Function of the Rice Distribution</p></a></li>
<li><a href='#cdfsla'><p>Cumulative Distribution Function of the Slash Distribution</p></a></li>
<li><a href='#cdfsmd'><p>Cumulative Distribution Function of the Singh&ndash;Maddala Distribution</p></a></li>
<li><a href='#cdfst3'><p>Cumulative Distribution Function of the 3-Parameter Student t Distribution</p></a></li>
<li><a href='#cdftexp'><p>Cumulative Distribution Function of the Truncated Exponential Distribution</p></a></li>
<li><a href='#cdftri'><p>Cumulative Distribution Function of the Asymmetric Triangular Distribution</p></a></li>
<li><a href='#cdfwak'><p>Cumulative Distribution Function of the Wakeby Distribution</p></a></li>
<li><a href='#cdfwei'><p>Cumulative Distribution Function of the Weibull Distribution</p></a></li>
<li><a href='#check.fs'><p>Check Vector of Nonexceedance Probabilities</p></a></li>
<li><a href='#check.pdf'><p>Check and Potentially Graph Probability Density Functions</p></a></li>
<li><a href='#claudeprecip'><p>Annual Maximum Precipitation Data for Claude, Texas</p></a></li>
<li><a href='#clearforkporosity'><p>Porosity Data</p></a></li>
<li><a href='#cmlmomco'><p>Conditional Mean Residual Quantile Function of the Distributions</p></a></li>
<li><a href='#cvm.test.lmomco'><p>Cramér&ndash;von Mises Test for Goodness-of-Fit</p></a></li>
<li><a href='#dat2bernqua'><p>Observed Data to Empirical Quantiles through Bernstein or Kantorovich Polynomials</p></a></li>
<li><a href='#dat2bernquaf'><p>Equivalent Nonexceedance Probability for a Given Value through Observed Data to Empirical Quantiles through Bernstein or Kantorovich Polynomials</p></a></li>
<li><a href='#disfitgovloc'><p>Fit a Govindarajulu Distribution to Bounds and Location</p></a></li>
<li><a href='#disfitqua'><p>Fit a Distribution using Minimization of Available Quantiles</p></a></li>
<li><a href='#dist.list'><p>List of Distribution Names</p></a></li>
<li><a href='#dlmomco'><p>Probability Density Function of the Distributions</p></a></li>
<li><a href='#DrillBitLifetime'><p>Lifetime of Drill Bits</p></a></li>
<li><a href='#expect.max.ostat'><p>Compute the Expectation of a Maximum (or Minimum and others) Order Statistic</p></a></li>
<li><a href='#f2f'><p>Subsetting of Nonexceedance Probabilities Related to Conditional Probability Adjustment</p></a></li>
<li><a href='#f2flo'><p>Conversion of Annual Nonexceedance Probability to Conditional Probability Nonexceedance Probabilities</p></a></li>
<li><a href='#f2fpds'><p>Conversion of Annual Nonexceedance Probability to Partial Duration Nonexceedance Probability</p></a></li>
<li><a href='#fliplmoms'><p>Flip L-moments by Flip Attribute in L-moment Vector</p></a></li>
<li><a href='#flo2f'><p>Conversion of Conditional Nonexceedance Probability to Annual Nonexceedance Probability</p></a></li>
<li><a href='#fpds2f'><p>Conversion of Partial-Duration Nonexceedance Probability to Annual Nonexceedance Probability</p></a></li>
<li><a href='#freq.curve.all'><p>Compute Frequency Curve for Almost All Distributions</p></a></li>
<li><a href='#gen.freq.curves'><p>Plot Randomly Generated Frequency Curves from a Parent Distribution</p></a></li>
<li><a href='#genci.simple'><p>Generate (Estimate) Confidence Intervals for Quantiles of a Parent Distribution</p></a></li>
<li><a href='#gini.mean.diff'><p>Gini Mean Difference Statistic</p></a></li>
<li><a href='#grv2prob'><p>Convert a Vector of Gumbel Reduced Variates to Annual Nonexceedance Probabilities</p></a></li>
<li><a href='#harmonic.mean'><p>The Harmonic Mean with Zero-Value Correction</p></a></li>
<li><a href='#headrick.sheng.lalpha'><p>Sample Headrick and Sheng L-alpha</p></a></li>
<li><a href='#herefordprecip'><p>Annual Maximum Precipitation Data for Hereford, Texas</p></a></li>
<li><a href='#hlmomco'><p>Hazard Functions of the Distributions</p></a></li>
<li><a href='#IRSrefunds.by.state'><p>U.S. Internal Revenue Service Refunds by State for Fiscal Year 2006</p></a></li>
<li><a href='#is.aep4'><p>Is a Distribution Parameter Object Typed as 4-Parameter Asymmetric Exponential Power</p></a></li>
<li><a href='#is.cau'><p>Is a Distribution Parameter Object Typed as Cauchy</p></a></li>
<li><a href='#is.emu'><p>Is a Distribution Parameter Object Typed as Eta-Mu</p></a></li>
<li><a href='#is.exp'><p>Is a Distribution Parameter Object Typed as Exponential</p></a></li>
<li><a href='#is.gam'><p>Is a Distribution Parameter Object Typed as Gamma</p></a></li>
<li><a href='#is.gep'><p>Is a Distribution Parameter Object Typed as Generalized Extreme Value</p></a></li>
<li><a href='#is.gev'><p>Is a Distribution Parameter Object Typed as Generalized Extreme Value</p></a></li>
<li><a href='#is.gld'><p>Is a Distribution Parameter Object Typed as Generalized Lambda</p></a></li>
<li><a href='#is.glo'><p>Is a Distribution Parameter Object Typed as Generalized Logistic</p></a></li>
<li><a href='#is.gno'><p>Is a Distribution Parameter Object Typed as Generalized Normal</p></a></li>
<li><a href='#is.gov'><p>Is a Distribution Parameter Object Typed as Govindarajulu</p></a></li>
<li><a href='#is.gpa'><p>Is a Distribution Parameter Object Typed as Generalized Pareto</p></a></li>
<li><a href='#is.gum'><p>Is a Distribution Parameter Object Typed as Gumbel</p></a></li>
<li><a href='#is.kap'><p>Is a Distribution Parameter Object Typed as Kappa</p></a></li>
<li><a href='#is.kmu'><p>Is a Distribution Parameter Object Typed as Kappa-Mu</p></a></li>
<li><a href='#is.kur'><p>Is a Distribution Parameter Object Typed as Kumaraswamy</p></a></li>
<li><a href='#is.lap'><p>Is a Distribution Parameter Object Typed as Laplace</p></a></li>
<li><a href='#is.lmrq'><p>Is a Distribution Parameter Object Typed as Linear Mean Residual Quantile Function</p></a></li>
<li><a href='#is.ln3'><p>Is a Distribution Parameter Object Typed as 3-Parameter Log-Normal</p></a></li>
<li><a href='#is.nor'><p>Is a Distribution Parameter Object Typed as Normal</p></a></li>
<li><a href='#is.pdq3'><p>Is a Distribution Parameter Object Typed as Polynomial Density-Quantile3</p></a></li>
<li><a href='#is.pdq4'><p>Is a Distribution Parameter Object Typed as Polynomial Density-Quantile4</p></a></li>
<li><a href='#is.pe3'><p>Is a Distribution Parameter Object Typed as Pearson Type III</p></a></li>
<li><a href='#is.ray'><p>Is a Distribution Parameter Object Typed as Rayleigh</p></a></li>
<li><a href='#is.revgum'><p>Is a Distribution Parameter Object Typed as Reverse Gumbel</p></a></li>
<li><a href='#is.rice'><p>Is a Distribution Parameter Object Typed as Rice</p></a></li>
<li><a href='#is.sla'><p>Is a Distribution Parameter Object Typed as Slash</p></a></li>
<li><a href='#is.smd'><p>Is a Distribution Parameter Object Typed as Singh&ndash;Maddala</p></a></li>
<li><a href='#is.st3'><p>Is a Distribution Parameter Object Typed as 3-Parameter Student t Distribution</p></a></li>
<li><a href='#is.texp'><p>Is a Distribution Parameter Object Typed as Truncated Exponential</p></a></li>
<li><a href='#is.tri'><p>Is a Distribution Parameter Object Typed as Asymmetric Triangular</p></a></li>
<li><a href='#is.wak'><p>Is a Distribution Parameter Object Typed as Wakeby</p></a></li>
<li><a href='#is.wei'><p>Is a Distribution Parameter Object Typed as Weibull</p></a></li>
<li><a href='#LaguerreHalf'><p>Laguerre Polynomial (Half)</p></a></li>
<li><a href='#Lcomoment.coefficients'><p>L-comoment Coefficient Matrix</p></a></li>
<li><a href='#Lcomoment.correlation'><p>L-correlation Matrix (L-correlation through Sample L-comoments)</p></a></li>
<li><a href='#Lcomoment.Lk12'><p>Compute a Single Sample L-comoment</p></a></li>
<li><a href='#Lcomoment.matrix'><p>Compute Sample L-comoment Matrix</p></a></li>
<li><a href='#Lcomoment.Wk'><p>Weighting Coefficient for Sample L-comoment</p></a></li>
<li><a href='#lcomoms2'><p>The Sample L-comoments for Two Variables</p></a></li>
<li><a href='#lkhlmomco'><p>Leimkuhler Curve of the Distributions</p></a></li>
<li><a href='#lmom.ub'><p>Unbiased Sample L-moments by Direct Sample Estimators</p></a></li>
<li><a href='#lmom2par'><p>Convert L-moments to the Parameters of a Distribution</p></a></li>
<li><a href='#lmom2pwm'><p>L-moments to Probability-Weighted Moments</p></a></li>
<li><a href='#lmom2vec'><p>Convert an L-moment object to a Vector of L-moments</p></a></li>
<li><a href='#lmomaep4'><p>L-moments of the 4-Parameter Asymmetric Exponential Power Distribution</p></a></li>
<li><a href='#lmomcau'><p>Trimmed L-moments of the Cauchy Distribution</p></a></li>
<li><a href='#lmomemu'><p>L-moments of the Eta-Mu Distribution</p></a></li>
<li><a href='#lmomexp'><p>L-moments of the Exponential Distribution</p></a></li>
<li><a href='#lmomgam'><p>L-moments of the Gamma Distribution</p></a></li>
<li><a href='#lmomgep'><p>L-moments of the Generalized Exponential Poisson Distribution</p></a></li>
<li><a href='#lmomgev'><p>L-moments of the Generalized Extreme Value Distribution</p></a></li>
<li><a href='#lmomgld'><p>L-moments of the Generalized Lambda Distribution</p></a></li>
<li><a href='#lmomglo'><p>L-moments of the Generalized Logistic Distribution</p></a></li>
<li><a href='#lmomgno'><p>L-moments of the Generalized Normal Distribution</p></a></li>
<li><a href='#lmomgov'><p>L-moments of the Govindarajulu Distribution</p></a></li>
<li><a href='#lmomgpa'><p>L-moments of the Generalized Pareto Distribution</p></a></li>
<li><a href='#lmomgpaRC'><p>B-type L-moments of the Generalized Pareto Distribution with Right-Tail Censoring</p></a></li>
<li><a href='#lmomgum'><p>L-moments of the Gumbel Distribution</p></a></li>
<li><a href='#lmomkap'><p>L-moments of the Kappa Distribution</p></a></li>
<li><a href='#lmomkmu'><p>L-moments of the Kappa-Mu Distribution</p></a></li>
<li><a href='#lmomkur'><p>L-moments of the Kumaraswamy Distribution</p></a></li>
<li><a href='#lmomlap'><p>L-moments of the Laplace Distribution</p></a></li>
<li><a href='#lmomlmrq'><p>L-moments of the Linear Mean Residual Quantile Function Distribution</p></a></li>
<li><a href='#lmomln3'><p>L-moments of the 3-Parameter Log-Normal Distribution</p></a></li>
<li><a href='#lmomnor'><p>L-moments of the Normal Distribution</p></a></li>
<li><a href='#lmompdq3'><p>L-moments of the Polynomial Density-Quantile3 Distribution</p></a></li>
<li><a href='#lmompdq4'><p>L-moments of the Polynomial Density-Quantile4 Distribution</p></a></li>
<li><a href='#lmompe3'><p>L-moments of the Pearson Type III Distribution</p></a></li>
<li><a href='#lmomray'><p>L-moments of the Rayleigh Distribution</p></a></li>
<li><a href='#lmomRCmark'><p>Sample L-moment for Right-Tail Censoring by a Marking Variable</p></a></li>
<li><a href='#lmomrevgum'><p>L-moments of the Reverse Gumbel Distribution</p></a></li>
<li><a href='#lmomrice'><p>L-moments of the Rice Distribution</p></a></li>
<li><a href='#lmoms'><p>The Sample L-moments and L-moment Ratios</p></a></li>
<li><a href='#lmoms.bernstein'><p>Numerically Integrated L-moments of Smoothed Quantiles from Bernstein or Kantorovich Polynomials</p></a></li>
<li><a href='#lmoms.bootbarvar'><p>Exact Bootstrap Mean and Variance of L-moments</p></a></li>
<li><a href='#lmoms.cov'><p>Distribution-Free Variance-Covariance Structure of Sample L-moments</p></a></li>
<li><a href='#lmomsla'><p>Trimmed L-moments of the Slash Distribution</p></a></li>
<li><a href='#lmomsmd'><p>L-moments of the Singh&ndash;Maddala Distribution</p></a></li>
<li><a href='#lmomsRCmark'><p>Sample L-moments Moments for Right-Tail Censoring by a Marking Variable</p></a></li>
<li><a href='#lmomst3'><p>L-moments of the 3-Parameter Student t Distribution</p></a></li>
<li><a href='#lmomtexp'><p>L-moments of the Truncated Exponential Distribution</p></a></li>
<li><a href='#lmomTLgld'><p>Trimmed L-moments of the Generalized Lambda Distribution</p></a></li>
<li><a href='#lmomTLgpa'><p>Trimmed L-moments of the Generalized Pareto Distribution</p></a></li>
<li><a href='#lmomtri'><p>L-moments of the Asymmetric Triangular Distribution</p></a></li>
<li><a href='#lmomwak'><p>L-moments of the Wakeby Distribution</p></a></li>
<li><a href='#lmomwei'><p>L-moments of the Weibull Distribution</p></a></li>
<li><a href='#lmorph'><p>Morph an L-moment Object</p></a></li>
<li><a href='#lmrdia'><p>L-moment Ratio Diagram Components</p></a></li>
<li><a href='#lmrdia46'><p>L-moment Ratio Diagram Components of Tau4 and Tau6</p></a></li>
<li><a href='#lmrdiscord'><p>Compute Discordance on L-CV, L-skew, and L-kurtosis</p></a></li>
<li><a href='#lmrloc'><p>Line-of-Organic Correlation</p></a></li>
<li><a href='#lrv2prob'><p>Convert a Vector of Logistic Reduced Variates to Annual Nonexceedance Probabilities</p></a></li>
<li><a href='#lrzlmomco'><p>Lorenz Curve  of the Distributions</p></a></li>
<li><a href='#mle2par'><p>Use Maximum Likelihood to Estimate Parameters of a Distribution</p></a></li>
<li><a href='#mps2par'><p>Use Maximum Product of Spacings to Estimate the Parameters of a Distribution</p></a></li>
<li><a href='#nonexceeds'><p>Some Common or Useful Nonexceedance Probabilities</p></a></li>
<li><a href='#par2cdf'><p>Cumulative Distribution Function of the Distributions</p></a></li>
<li><a href='#par2cdf2'><p>Equivalent Cumulative Distribution Function of Two Distributions</p></a></li>
<li><a href='#par2lmom'><p>Convert the Parameters of a Distribution to the L-moments</p></a></li>
<li><a href='#par2pdf'><p>Probability Density Function of the Distributions</p></a></li>
<li><a href='#par2qua'><p>Quantile Function of the Distributions</p></a></li>
<li><a href='#par2qua2'><p>Equivalent Quantile Function of Two Distributions</p></a></li>
<li><a href='#par2qua2lo'><p>Equivalent Quantile Function of Two Distributions Stemming from Left-Hand Threshold to Setup Conditional Probability Computations</p></a></li>
<li><a href='#par2vec'><p>Convert a Parameter Object to a Vector of Parameters</p></a></li>
<li><a href='#paraep4'><p>Estimate the Parameters of the 4-Parameter Asymmetric Exponential Power Distribution</p></a></li>
<li><a href='#parcau'><p>Estimate the Parameters of the Cauchy Distribution</p></a></li>
<li><a href='#paremu'><p>Estimate the Parameters of the Eta-Mu Distribution</p></a></li>
<li><a href='#parexp'><p>Estimate the Parameters of the Exponential Distribution</p></a></li>
<li><a href='#pargam'><p>Estimate the Parameters of the Gamma Distribution</p></a></li>
<li><a href='#pargep'><p>Estimate the Parameters of the Generalized Exponential Poisson Distribution</p></a></li>
<li><a href='#pargev'><p>Estimate the Parameters of the Generalized Extreme Value Distribution</p></a></li>
<li><a href='#pargld'><p>Estimate the Parameters of the Generalized Lambda Distribution</p></a></li>
<li><a href='#parglo'><p>Estimate the Parameters of the Generalized Logistic Distribution</p></a></li>
<li><a href='#pargno'><p>Estimate the Parameters of the Generalized Normal Distribution</p></a></li>
<li><a href='#pargov'><p>Estimate the Parameters of the Govindarajulu Distribution</p></a></li>
<li><a href='#pargpa'><p>Estimate the Parameters of the Generalized Pareto Distribution</p></a></li>
<li><a href='#pargpaRC'><p>Estimate the Parameters of the Generalized Pareto Distribution with Right-Tail Censoring</p></a></li>
<li><a href='#pargum'><p>Estimate the Parameters of the Gumbel Distribution</p></a></li>
<li><a href='#parkap'><p>Estimate the Parameters of the Kappa Distribution</p></a></li>
<li><a href='#parkmu'><p>Estimate the Parameters of the Kappa-Mu Distribution</p></a></li>
<li><a href='#parkur'><p>Estimate the Parameters of the Kumaraswamy Distribution</p></a></li>
<li><a href='#parlap'><p>Estimate the Parameters of the Laplace Distribution</p></a></li>
<li><a href='#parlmrq'><p>Estimate the Parameters of the Linear Mean Residual Quantile Function Distribution</p></a></li>
<li><a href='#parln3'><p>Estimate the Parameters of the 3-Parameter Log-Normal Distribution</p></a></li>
<li><a href='#parnor'><p>Estimate the Parameters of the Normal Distribution</p></a></li>
<li><a href='#parpdq3'><p>Estimate the Parameters of the Polynomial Density-Quantile3 Distribution</p></a></li>
<li><a href='#parpdq4'><p>Estimate the Parameters of the Polynomial Density-Quantile4 Distribution</p></a></li>
<li><a href='#parpe3'><p>Estimate the Parameters of the Pearson Type III Distribution</p></a></li>
<li><a href='#parray'><p>Estimate the Parameters of the Rayleigh Distribution</p></a></li>
<li><a href='#parrevgum'><p>Estimate the Parameters of the Reverse Gumbel Distribution</p></a></li>
<li><a href='#parrice'><p>Estimate the Parameters of the Rice Distribution</p></a></li>
<li><a href='#pars2x'><p>Estimate Quantiles from an Ensemble of Parameters</p></a></li>
<li><a href='#parsla'><p>Estimate the Parameters of the Slash Distribution</p></a></li>
<li><a href='#parsmd'><p>Estimate the Parameters of the Singh&ndash;Maddala Distribution</p></a></li>
<li><a href='#parst3'><p>Estimate the Parameters of the 3-Parameter Student t Distribution</p></a></li>
<li><a href='#partexp'><p>Estimate the Parameters of the Truncated Exponential Distribution</p></a></li>
<li><a href='#parTLgld'><p>Estimate the Parameters of the Generalized Lambda Distribution using Trimmed L-moments (t=1)</p></a></li>
<li><a href='#parTLgpa'><p>Estimate the Parameters of the Generalized Pareto Distribution using Trimmed L-moments</p></a></li>
<li><a href='#partri'><p>Estimate the Parameters of the Asymmetric Triangular Distribution</p></a></li>
<li><a href='#parwak'><p>Estimate the Parameters of the Wakeby Distribution</p></a></li>
<li><a href='#parwei'><p>Estimate the Parameters of the Weibull Distribution</p></a></li>
<li><a href='#pdfaep4'><p>Probability Density Function of the 4-Parameter Asymmetric Exponential Power Distribution</p></a></li>
<li><a href='#pdfcau'><p>Probability Density Function of the Cauchy Distribution</p></a></li>
<li><a href='#pdfemu'><p>Probability Density Function of the Eta-Mu Distribution</p></a></li>
<li><a href='#pdfexp'><p>Probability Density Function of the Exponential Distribution</p></a></li>
<li><a href='#pdfgam'><p>Probability Density Function of the Gamma Distribution</p></a></li>
<li><a href='#pdfgep'><p>Probability Density Function of the Generalized Exponential Poisson Distribution</p></a></li>
<li><a href='#pdfgev'><p>Probability Density Function of the Generalized Extreme Value Distribution</p></a></li>
<li><a href='#pdfgld'><p>Probability Density Function of the Generalized Lambda Distribution</p></a></li>
<li><a href='#pdfglo'><p>Probability Density Function of the Generalized Logistic Distribution</p></a></li>
<li><a href='#pdfgno'><p>Probability Density Function of the Generalized Normal Distribution</p></a></li>
<li><a href='#pdfgov'><p>Probability Density Function of the Govindarajulu Distribution</p></a></li>
<li><a href='#pdfgpa'><p>Probability Density Function of the Generalized Pareto Distribution</p></a></li>
<li><a href='#pdfgum'><p>Probability Density Function of the Gumbel Distribution</p></a></li>
<li><a href='#pdfkap'><p>Probability Density Function of the Kappa Distribution</p></a></li>
<li><a href='#pdfkmu'><p>Probability Density Function of the Kappa-Mu Distribution</p></a></li>
<li><a href='#pdfkur'><p>Probability Density Function of the Kumaraswamy Distribution</p></a></li>
<li><a href='#pdflap'><p>Probability Density Function of the Laplace Distribution</p></a></li>
<li><a href='#pdflmrq'><p>Probability Density Function of the Linear Mean Residual Quantile Function Distribution</p></a></li>
<li><a href='#pdfln3'><p>Probability Density Function of the 3-Parameter Log-Normal Distribution</p></a></li>
<li><a href='#pdfnor'><p>Probability Density Function of the Normal Distribution</p></a></li>
<li><a href='#pdfpdq3'><p>Probability Density Function of the Polynomial Density-Quantile3 Distribution</p></a></li>
<li><a href='#pdfpdq4'><p>Probability Density Function of the Polynomial Density-Quantile4 Distribution</p></a></li>
<li><a href='#pdfpe3'><p>Probability Density Function of the Pearson Type III Distribution</p></a></li>
<li><a href='#pdfray'><p>Probability Density Function of the Rayleigh Distribution</p></a></li>
<li><a href='#pdfrevgum'><p>Probability Density Function of the Reverse Gumbel Distribution</p></a></li>
<li><a href='#pdfrice'><p>Probability Density Function of the Rice Distribution</p></a></li>
<li><a href='#pdfsla'><p>Probability Density Function of the Slash Distribution</p></a></li>
<li><a href='#pdfsmd'><p>Probability Density Function of the Singh&ndash;Maddala Distribution</p></a></li>
<li><a href='#pdfst3'><p>Probability Density Function of the 3-Parameter Student t Distribution</p></a></li>
<li><a href='#pdftexp'><p>Probability Density Function of the Truncated Exponential Distribution</p></a></li>
<li><a href='#pdftri'><p>Probability Density Function of the Asymmetric Triangular Distribution</p></a></li>
<li><a href='#pdfwak'><p>Probability Density Function of the Wakeby Distribution</p></a></li>
<li><a href='#pdfwei'><p>Probability Density Function of the Weibull Distribution</p></a></li>
<li><a href='#pfactor.bernstein'><p>Estimation of Optimal p-factor of Distributional Support Estimation for Smoothed Quantiles from the Bernstein or Kantorovich Polynomials</p></a></li>
<li><a href='#plmomco'><p>Cumulative Distribution Function of the Distributions</p></a></li>
<li><a href='#plotlmrdia'><p>Plot L-moment Ratio Diagram (Tau3 and Tau4)</p></a></li>
<li><a href='#plotlmrdia46'><p>Plot L-moment Ratio Diagram (Tau4 and Tau6)</p></a></li>
<li><a href='#plotradarlmr'><p>Plot L-moment Radar Plot (Chart) Graphic</p></a></li>
<li><a href='#pmoms'><p>The Sample Product Moments: Mean, Standard Deviation, Skew, and Excess Kurtosis</p></a></li>
<li><a href='#pp'><p>Plotting-Position Formula</p></a></li>
<li><a href='#pp.f'><p>Quantile Function of the Ranks of Plotting Positions</p></a></li>
<li><a href='#pp.median'><p>Quantile Function of the Ranks of Plotting Positions</p></a></li>
<li><a href='#prettydist'><p>A Pretty List of Distribution Names</p></a></li>
<li><a href='#prob2grv'><p>Convert a Vector of Annual Nonexceedance Probabilities to Gumbel Reduced Variates</p></a></li>
<li><a href='#prob2lrv'><p>Convert a Vector of Annual Nonexceedance Probabilities to Logistic Reduced Variates</p></a></li>
<li><a href='#prob2T'><p>Convert a Vector of Annual Nonexceedance Probabilities to T-year Return Periods</p></a></li>
<li><a href='#pwm'><p>Unbiased Sample Probability-Weighted Moments</p></a></li>
<li><a href='#pwm.beta2alpha'><p>Conversion of Beta to Alpha Probability-Weighted Moments (PWMs) or Alpha to Beta PWMs</p></a></li>
<li><a href='#pwm.gev'><p>Generalized Extreme Value Plotting-Position Probability-Weighted Moments</p></a></li>
<li><a href='#pwm.pp'><p>Plotting-Position Sample Probability-Weighted Moments</p></a></li>
<li><a href='#pwm.ub'><p>Unbiased Sample Probability-Weighted Moments</p></a></li>
<li><a href='#pwm2lmom'><p>Probability-Weighted Moments to L-moments</p></a></li>
<li><a href='#pwm2vec'><p>Convert Probability-Weighted Moment object to a Vector</p></a></li>
<li><a href='#pwmLC'><p>Sample Probability-Weighted Moments for Left-Tail Censoring</p></a></li>
<li><a href='#pwmRC'><p>Sample Probability-Weighted Moments for Right-Tail Censoring</p></a></li>
<li><a href='#qlmomco'><p>Quantile Function of the Distributions</p></a></li>
<li><a href='#qua.ostat'><p>Compute the Quantiles of the Distribution of an Order Statistic</p></a></li>
<li><a href='#qua2ci.cov'><p>Estimate a Confidence Interval for Quantiles of a Parent Distribution using Sample Variance-Covariances of L-moments</p></a></li>
<li><a href='#qua2ci.simple'><p>Estimate a Confidence Interval for a Single Quantile of a Parent Distribution by a Simple Algorithm</p></a></li>
<li><a href='#quaaep4'><p>Quantile Function of the 4-Parameter Asymmetric Exponential Power Distribution</p></a></li>
<li><a href='#quaaep4kapmix'><p>Quantile Function Mixture Between the 4-Parameter Asymmetric Exponential Power and Kappa Distributions</p></a></li>
<li><a href='#quacau'><p>Quantile Function of the Cauchy Distribution</p></a></li>
<li><a href='#quaemu'><p>Quantile Function of the Eta-Mu Distribution</p></a></li>
<li><a href='#quaexp'><p>Quantile Function of the Exponential Distribution</p></a></li>
<li><a href='#quagam'><p>Quantile Function of the Gamma Distribution</p></a></li>
<li><a href='#quagep'><p>Quantile Function of the Generalized Exponential Poisson Distribution</p></a></li>
<li><a href='#quagev'><p>Quantile Function of the Generalized Extreme Value Distribution</p></a></li>
<li><a href='#quagld'><p>Quantile Function of the Generalized Lambda Distribution</p></a></li>
<li><a href='#quaglo'><p>Quantile Function of the Generalized Logistic Distribution</p></a></li>
<li><a href='#quagno'><p>Quantile Function of the Generalized Normal Distribution</p></a></li>
<li><a href='#quagov'><p>Quantile Function of the Govindarajulu Distribution</p></a></li>
<li><a href='#quagpa'><p>Quantile Function of the Generalized Pareto Distribution</p></a></li>
<li><a href='#quagum'><p>Quantile Function of the Gumbel Distribution</p></a></li>
<li><a href='#quakap'><p>Quantile Function of the Kappa Distribution</p></a></li>
<li><a href='#quakmu'><p>Quantile Function of the Kappa-Mu Distribution</p></a></li>
<li><a href='#quakur'><p>Quantile Function of the Kumaraswamy Distribution</p></a></li>
<li><a href='#qualap'><p>Quantile Function of the Laplace Distribution</p></a></li>
<li><a href='#qualmrq'><p>Quantile Function of the Linear Mean Residual Quantile Function Distribution</p></a></li>
<li><a href='#qualn3'><p>Quantile Function of the 3-Parameter Log-Normal Distribution</p></a></li>
<li><a href='#quanor'><p>Quantile Function of the Normal Distribution</p></a></li>
<li><a href='#quapdq3'><p>Quantile Function of the Polynomial Density-Quantile3 Distribution</p></a></li>
<li><a href='#quapdq4'><p>Quantile Function of the Polynomial Density-Quantile4 Distribution</p></a></li>
<li><a href='#quape3'><p>Quantile Function of the Pearson Type III Distribution</p></a></li>
<li><a href='#quaray'><p>Quantile Function of the Rayleigh Distribution</p></a></li>
<li><a href='#quarevgum'><p>Quantile Function of the Reverse Gumbel Distribution</p></a></li>
<li><a href='#quarice'><p>Quantile Function of the Rice Distribution</p></a></li>
<li><a href='#quasla'><p>Quantile Function of the Slash Distribution</p></a></li>
<li><a href='#quasmd'><p>Quantile Function of the Singh&ndash;Maddala Distribution</p></a></li>
<li><a href='#quast3'><p>Quantile Function of the 3-Parameter Student t Distribution</p></a></li>
<li><a href='#quatexp'><p>Quantile Function of the Truncated Exponential Distribution</p></a></li>
<li><a href='#quatri'><p>Quantile Function of the Asymmetric Triangular Distribution</p></a></li>
<li><a href='#quawak'><p>Quantile Function of the Wakeby Distribution</p></a></li>
<li><a href='#quawei'><p>Quantile Function of the Weibull Distribution</p></a></li>
<li><a href='#ralmomco'><p>Alpha-Percentile Residual Quantile Function of the Distributions</p></a></li>
<li><a href='#reslife.lmoms'><p>L-moments of Residual Life</p></a></li>
<li><a href='#riglmomco'><p>Income Gap Ratio Quantile Function for the Distributions</p></a></li>
<li><a href='#rlmomco'><p>Random Variates of a Distribution</p></a></li>
<li><a href='#rmlmomco'><p>Mean Residual Quantile Function of the Distributions</p></a></li>
<li><a href='#rmvarlmomco'><p>Variance Residual Quantile Function of the Distributions</p></a></li>
<li><a href='#rralmomco'><p>Reversed Alpha-Percentile Residual Quantile Function of the Distributions</p></a></li>
<li><a href='#rreslife.lmoms'><p>L-moments of Reversed Residual Life</p></a></li>
<li><a href='#rrmlmomco'><p>Reversed Mean Residual Quantile Function of the Distributions</p></a></li>
<li><a href='#rrmvarlmomco'><p>Reversed Variance Residual Quantile Function of the Distributions</p></a></li>
<li><a href='#sen.mean'><p>Sen Weighted Mean Statistic</p></a></li>
<li><a href='#sentiv.curve'><p>Compute the Sensitivity Curve for a Single Quantile</p></a></li>
<li><a href='#slmomco'><p>Reversed Cumulative Distribution Function (Survival Function) of the Distributions</p></a></li>
<li><a href='#stttlmomco'><p>Scaled Total Time on Test Transform of Distributions</p></a></li>
<li><a href='#supdist'><p>The Support of a Distribution based on the Parameters</p></a></li>
<li><a href='#T2prob'><p>Convert a Vector of T-year Return Periods to Annual Nonexceedance Probabilities</p></a></li>
<li><a href='#tau34sq.normtest'><p>The Tau34-squared Test: A Normality Test based on L-skew and L-kurtosis and an Elliptical Rejection Region on an L-moment Ratio Diagram</p></a></li>
<li><a href='#theoLmoms'><p>The Theoretical L-moments and L-moment Ratios using Integration of the Quantile Function</p></a></li>
<li><a href='#theoLmoms.max.ostat'><p>Compute the Theoretical L-moments of a Distribution Distribution based on System of Maximum Order Statistic Expectations</p></a></li>
<li><a href='#theopwms'><p>The Theoretical Probability-Weighted Moments using Integration of the Quantile Function</p></a></li>
<li><a href='#theoTLmoms'><p>The Theoretical Trimmed L-moments and TL-moment Ratios using Integration of the Quantile Function</p></a></li>
<li><a href='#TLmom'><p>A Sample Trimmed L-moment</p></a></li>
<li><a href='#TLmoms'><p>The Sample Trimmed L-moments and L-moment Ratios</p></a></li>
<li><a href='#tlmr2par'><p>Sample Trimmed L-moments to Fitted Distribution</p></a></li>
<li><a href='#tlmrcau'><p>Compute Select TL-moment ratios of the Cauchy Distribution</p></a></li>
<li><a href='#tlmrexp'><p>Compute Select TL-moment ratios of the Exponential Distribution</p></a></li>
<li><a href='#tlmrgev'><p>Compute Select TL-moment ratios of the Generalized Extreme Value Distribution</p></a></li>
<li><a href='#tlmrglo'><p>Compute Select TL-moment ratios of the Generalized Logistic Distribution</p></a></li>
<li><a href='#tlmrgno'><p>Compute Select TL-moment ratios of the Generalized Normal Distribution</p></a></li>
<li><a href='#tlmrgpa'><p>Compute Select TL-moment ratios of the Generalized Pareto</p></a></li>
<li><a href='#tlmrgum'><p>Compute Select TL-moment ratios of the Gumbel Distribution</p></a></li>
<li><a href='#tlmrln3'><p>Compute Select TL-moment ratios of the 3-Parameter Log-Normal Distribution</p></a></li>
<li><a href='#tlmrnor'><p>Compute Select TL-moment ratios of the Normal Distribution</p></a></li>
<li><a href='#tlmrpe3'><p>Compute Select TL-moment ratios of the Pearson Type III</p></a></li>
<li><a href='#tlmrray'><p>Compute Select TL-moment ratios of the Rayleigh Distribution</p></a></li>
<li><a href='#tttlmomco'><p>Total Time on Test Transform of Distributions</p></a></li>
<li><a href='#tulia6Eprecip'><p>Annual Maximum Precipitation Data for Tulia 6E, Texas</p></a></li>
<li><a href='#tuliaprecip'><p>Annual Maximum Precipitation Data for Tulia, Texas</p></a></li>
<li><a href='#TX38lgtrmFlow'><p>First six L-moments of logarithms of annual mean streamflow and variances for 35 selected long-term U.S. Geological Survey streamflow-gaging stations in Texas</p></a></li>
<li><a href='#USGSsta01515000peaks'><p>Annual Peak Streamflow Data for U.S. Geological Survey Streamflow-Gaging Station 01515000</p></a></li>
<li><a href='#USGSsta02366500peaks'><p>Annual Peak Streamflow Data for U.S. Geological Survey Streamflow-Gaging Station 02366500</p></a></li>
<li><a href='#USGSsta05405000peaks'><p>Annual Peak Streamflow Data for U.S. Geological Survey Streamflow-Gaging Station 05405000</p></a></li>
<li><a href='#USGSsta06766000dvs'><p>Daily Mean Streamflow Data for U.S. Geological Survey Streamflow-Gaging Station 06766000</p></a></li>
<li><a href='#USGSsta08151500peaks'><p>Annual Peak Streamflow Data for U.S. Geological Survey Streamflow-Gaging Station 08151500</p></a></li>
<li><a href='#USGSsta08167000peaks'><p>Annual Peak Streamflow Data for U.S. Geological Survey Streamflow-Gaging Station 08167000</p></a></li>
<li><a href='#USGSsta08190000peaks'><p>Annual Peak Streamflow Data for U.S. Geological Survey Streamflow-Gaging Station 08190000</p></a></li>
<li><a href='#USGSsta09442000peaks'><p>Annual Peak Streamflow Data for U.S. Geological Survey Streamflow-Gaging Station 09442000</p></a></li>
<li><a href='#USGSsta14321000peaks'><p>Annual Peak Streamflow Data for U.S. Geological Survey Streamflow-Gaging Station 14321000</p></a></li>
<li><a href='#vec2lmom'><p>Convert a Vector of L-moments to a L-moment Object</p></a></li>
<li><a href='#vec2par'><p>Convert a Vector of Parameters to a Parameter Object of a Distribution</p></a></li>
<li><a href='#vec2pwm'><p>Convert a Vector of Probability-Weighted Moments to a Probability-Weighted Moments Object</p></a></li>
<li><a href='#vec2TLmom'><p>Convert a Vector of TL-moments to a TL-moment Object</p></a></li>
<li><a href='#vegaprecip'><p>Annual Maximum Precipitation Data for Vega, Texas</p></a></li>
<li><a href='#x2pars'><p>Estimate an Ensemble of Parameters from Three Different Methods</p></a></li>
<li><a href='#x2xlo'><p>Conversion of a Vector through a Left-Hand Threshold to Setup Conditional Probability Computations</p></a></li>
<li><a href='#xlo2qua'><p>Conversion of a Vector through a Left-Hand Threshold to Setup Conditional Probability Computations</p></a></li>
<li><a href='#z.par2cdf'><p>Blipping Cumulative Distribution Functions</p></a></li>
<li><a href='#z.par2qua'><p>Blipping Quantile Functions</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>L-Moments, Censored L-Moments, Trimmed L-Moments, L-Comoments,
and Many Distributions</td>
</tr>
<tr>
<td>Version:</td>
<td>2.5.1</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0), utils</td>
</tr>
<tr>
<td>Imports:</td>
<td>goftest, Lmoments, MASS</td>
</tr>
<tr>
<td>Suggests:</td>
<td>copBasic</td>
</tr>
<tr>
<td>Date:</td>
<td>2024-05-02</td>
</tr>
<tr>
<td>Author:</td>
<td>William Asquith</td>
</tr>
<tr>
<td>Description:</td>
<td>Extensive functions for Lmoments (LMs) and probability-weighted moments (PWMs),
  distribution parameter estimation, LMs for distributions, LM ratio diagrams, multivariate
  Lcomoments, and asymmetric (asy) trimmed LMs (TLMs). Maximum likelihood and
  maximum product spacings estimation are available. Right-tail and left-tail LM censoring
  by threshold or indicator variable are available. LMs of residual (resid) and reversed
  (rev) residual life are implemented along with 13 quantile operators for reliability analyses.
  Exact analytical bootstrap estimates of order statistics, LMs, and LM var-covars are available.
  Harri-Coble Tau34-squared Normality Test is available. Distributions with L, TL, and added
  (+) support for right-tail censoring (RC) encompass: Asy Exponential (Exp) Power [L],
  Asy Triangular [L], Cauchy [TL], Eta-Mu [L], Exp. [L], Gamma [L], Generalized (Gen) Exp
  Poisson [L], Gen Extreme Value [L], Gen Lambda [L, TL], Gen Logistic [L], Gen Normal [L],
  Gen Pareto [L+RC, TL], Govindarajulu [L], Gumbel [L], Kappa [L], Kappa-Mu [L],
  Kumaraswamy [L], Laplace [L], Linear Mean Residual Quantile Function [L], Normal [L],
  3p log-Normal [L], Pearson Type III [L], Polynomial Density-Quantile 3 and 4 [L],
  Rayleigh [L], Rev-Gumbel [L+RC], Rice [L], Singh Maddala [L], Slash [TL], 3p Student t [L],
  Truncated Exponential [L], Wakeby [L], and Weibull [L].</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>William Asquith &lt;william.asquith@ttu.edu&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL]</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://www.amazon.com/dp/1463508417/">https://www.amazon.com/dp/1463508417/</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-05-03 17:12:02 UTC; wasquith</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-05-04 06:00:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='lmomco-package'>L-moments, Censored L-moments, Trimmed L-moments, L-comoments, and Many Distributions</h2><span id='topic+lmomco-package'></span>

<h3>Description</h3>

<p>The <span class="pkg">lmomco</span> package is a comparatively comprehensive implementation of L-moments in addition to probability-weighted moments, and parameter estimation for numerous familiar and not-so-familiar distributions. L-moments and their cousins are based on certain linear combinations of order statistic expectations. Being based on linear mathematics and thus especially robust compared to conventional moments, they are particular suitable for analysis of rare events of non-Normal data. L-moments are consistent and often have smaller sampling variances than maximum likelihood in small to moderate sample sizes. L-moments are especially useful in the context of quantile functions. The method of L-moments (<code><a href="#topic+lmr2par">lmr2par</a></code>) is augmented here with access to the methods of maximum likelihood (<code><a href="#topic+mle2par">mle2par</a></code>) and maximum product of spacings (<code><a href="#topic+mps2par">mps2par</a></code>) as alternatives for parameter estimation bound into the distributions of the <span class="pkg">lmomco</span> package.
</p>
<p>About 370 user-level functions are implemented in <span class="pkg">lmomco</span> that range from low-level utilities forming an application programming interface (API) to high-level sophisticated data analysis and visualization operators. The &ldquo;See Also&rdquo; section lists recommended function entry points for new users. The nomenclature (<code>d</code>, <code>p</code>, <code>r</code>, <code>q</code>)-<code>lmomco</code> is directly analogous to that for distributions built-in to <span class="rlang"><b>R</b></span>. To conclude, the <span class="rlang"><b>R</b></span> packages <span class="pkg">lmom</span> (Hosking), <span class="pkg">lmomRFA</span> (Hosking), <span class="pkg">Lmoments</span> (Karvanen) might also be of great interest.
</p>
<p>How does <span class="pkg">lmomco</span> basically work? The design of <span class="pkg">lmomco</span> is to fit distributions to the L-moments of sample data. Distributions are specified by a <code>type</code> argument for very many functions. The package stores both L-moments (see <code><a href="#topic+vec2lmom">vec2lmom</a></code>) and parameters (see <code><a href="#topic+vec2par">vec2par</a></code>) in simple <span class="rlang"><b>R</b></span> <code>list</code> structures&mdash;very elementary. The following code shows a comparison of parameter estimation for a random sample (<code><a href="#topic+rlmomco">rlmomco</a></code>) of a GEV distribution using L-moments (<code><a href="#topic+lmoms">lmoms</a></code> coupled with <code><a href="#topic+lmom2par">lmom2par</a></code> or simply <code><a href="#topic+lmr2par">lmr2par</a></code>), maximum likelihood (MLE, <code><a href="#topic+mle2par">mle2par</a></code>), and maximum product of spacings (MPS, <code><a href="#topic+mps2par">mps2par</a></code>). (A note of warning, the MLE and MPS algorithms might not converge with the initial parameters&mdash;for purposes of &ldquo;learning&rdquo; about this package just rerun the code below again for another random sample.)
</p>
<pre>
  parent.lmoments &lt;- vec2lmom(c(3.08, 0.568, -0.163)); ty &lt;- "gev"
  Q &lt;- rlmomco(63, lmom2par(parent.lmoments, type=ty)) # random sample
  init &lt;- lmoms(Q); init$ratios[3] &lt;- 0 # failure rates for mps and mle are
  # substantially lowered if starting from the middle of the distribution's
  # shape to form the initial parameters for init.para
  lmr  &lt;- lmr2par(Q, type=ty)                # method of L-moments
  mle  &lt;- mle2par(Q, type=ty, init.lmr=init) # method of MLE
  mps  &lt;- mps2par(Q, type=ty, init.lmr=init) # method of MPS
  lmr1 &lt;- lmr$para; mle1 &lt;- mle$para; mps1 &lt;- mps$para
</pre>
<p>The <code>lmr1</code>, <code>mle1</code>, and <code>mps1</code> variables each contain distribution parameter estimates, but before they are inspected, how about quick comparison to another <span class="rlang"><b>R</b></span> package (<span class="pkg">eva</span>)?
</p>
<pre>
  lmr2 &lt;- eva::gevrFit(Q, method="pwm")$par.ests # PWMs == L-moments
  mle2 &lt;- eva::gevrFit(Q, method="mle")$par.ests # method of MLE
  mps2 &lt;- eva::gevrFit(Q, method="mps")$par.ests # method of MPS
  # Package eva uses a different sign convention on the GEV shape parameter
  mle2[3] &lt;- -mle2[3]; mps2[3] &lt;- -mps2[3]; lmr2[3] &lt;- -lmr2[3];
</pre>
<p>Now let us inspect the contents of the six estimates of the three GEV parameters by three different methods:
</p>
<pre>
  message("LMR(lmomco): ", paste(round(lmr1, digits=5), collapse="  "))
  message("LMR(   eva): ", paste(round(lmr2, digits=5), collapse="  "))
  message("MLE(lmomco): ", paste(round(mle1, digits=5), collapse="  "))
  message("MLE(   eva): ", paste(round(mle2, digits=5), collapse="  "))
  message("MPS(lmomco): ", paste(round(mps1, digits=5), collapse="  "))
  message("MPS(   eva): ", paste(round(mps2, digits=5), collapse="  "))
</pre>
<p>The results show compatible estimates between the two packages. Lastly, let us plot what these distributions look like using the <span class="pkg">lmomco</span> functions: <code><a href="#topic+add.lmomco.axis">add.lmomco.axis</a></code>, <code><a href="#topic+nonexceeds">nonexceeds</a></code>, <code><a href="#topic+pp">pp</a></code>, and <code><a href="#topic+qlmomco">qlmomco</a></code>.
</p>
<pre>
  par(las=2, mgp=c(3, 0.5, 0)); FF &lt;- nonexceeds(); qFF &lt;- qnorm(FF)
  PP &lt;- pp(Q); qPP &lt;- qnorm(PP); Q &lt;- sort(Q)
  plot(  qFF, qlmomco(FF, lmr), xaxt="n", xlab="", tcl=0.5,
                                ylab="QUANTILE", type="l")
  lines( qFF, qlmomco(FF, mle), col="blue")
  lines( qFF, qlmomco(FF, mps), col="red" )
  points(qPP, Q, lwd=0.6, cex=0.8, col=grey(0.3)); par(las=1)
  add.lmomco.axis(las=2, tcl=0.5, side.type="NPP")
</pre>


<h3>Author(s)</h3>

<p>William Asquith <a href="mailto:william.asquith@ttu.edu">william.asquith@ttu.edu</a> </p>


<h3>References</h3>

<p>Asquith, W.H., 2007, L-moments and TL-moments of the generalized lambda distribution: Computational Statistics and Data Analysis, v. 51, no. 9, pp. 4484&ndash;4496, <a href="https://doi.org/10.1016/j.csda.2006.07.016">doi:10.1016/j.csda.2006.07.016</a>.
</p>
<p>Asquith, W.H., 2011, Distributional analysis with L-moment statistics using the R environment for statistical computing: Createspace Independent Publishing Platform, ISBN 978&ndash;146350841&ndash;8, <a href="https://www.amazon.com/dp/1463508417/">https://www.amazon.com/dp/1463508417/</a>.
</p>
<p>Asquith, W.H., 2014, Parameter estimation for the 4-parameter asymmetric exponential power distribution by the method of L-moments using R: Computational Statistics and Data Analysis, v. 71, pp. 955&ndash;970, <a href="https://doi.org/10.1016/j.csda.2012.12.013">doi:10.1016/j.csda.2012.12.013</a>.
</p>
<p>Dey, D.K., Roy, Dooti, Yan, Jun, 2016, Univariate extreme value analysis, chapter 1, <em>in</em> Dey, D.K., and Yan, Jun, eds., Extreme value modeling and risk analysis&mdash;Methods and applications: Boca Raton, FL, CRC Press, pp. 1&ndash;22.
</p>
<p>Elamir, E.A.H., and Seheult, A.H., 2003, Trimmed L-moments: Computational statistics and data analysis, vol. 43, pp. 299-314, <a href="https://doi.org/10.1016/S0167-9473%2802%2900250-5">doi:10.1016/S0167-9473(02)00250-5</a>.
</p>
<p>Hosking, J.R.M., 1990, L-moments&mdash;Analysis and estimation of
distributions using linear combinations of order statistics: Journal of the Royal Statistical Society, Series B, v. 52, pp. 105&ndash;124, <a href="https://doi.org/10.1111/j.2517-6161.1990.tb01775.x">doi:10.1111/j.2517-6161.1990.tb01775.x</a>.
</p>
<p>Hosking, J.R.M., 2007, Distributions with maximum entropy subject to constraints on their L-moments or expected order statistics: Journal of Statistical Planning and Inference, v. 137, no. 9, pp. 2870&ndash;2891, <a href="https://doi.org/10.1016/j.jspi.2006.10.010">doi:10.1016/j.jspi.2006.10.010</a>.
</p>
<p>Hosking, J.R.M., and Wallis, J.R., 1997, Regional frequency analysis&mdash;An approach based on L-moments: Cambridge University Press, <a href="https://www.amazon.com/dp/0521019400/">https://www.amazon.com/dp/0521019400/</a>.
</p>
<p>Nair, N.U., Sankaran, P.G., and Balakrishnan, N., 2013, Quantile-based reliability analysis: Springer, New York, <a href="https://www.amazon.com/dp/0817683607/">https://www.amazon.com/dp/0817683607/</a>.
</p>
<p>Serfling, R., and Xiao, P., 2007, A contribution to multivariate L-moments&mdash;L-comoment matrices: Journal of Multivariate Analysis, v. 98, pp. 1765&ndash;1781, <a href="https://doi.org/10.1016/j.jmva.2007.01.008">doi:10.1016/j.jmva.2007.01.008</a>.
</p>


<h3>See Also</h3>

   <p><code><a href="#topic+lmoms">lmoms</a></code>, <code><a href="#topic+dlmomco">dlmomco</a></code>, <code><a href="#topic+plmomco">plmomco</a></code>, <code><a href="#topic+rlmomco">rlmomco</a></code>, <code><a href="#topic+qlmomco">qlmomco</a></code>, <code><a href="#topic+lmom2par">lmom2par</a></code>,
<code><a href="#topic+plotlmrdia">plotlmrdia</a></code>, <code><a href="#topic+lcomoms2">lcomoms2</a></code>
</p>

<hr>
<h2 id='.lmomcohash'>Storage of Lookup Tables for the lmomco Package</h2><span id='topic+.lmomcohash'></span>

<h3>Description</h3>

<p>This is a hidden data object contained in the <code>R/sysdata.rda</code> file of the <span class="pkg">lmomco</span> package. The system files <code>inst/doc/</code><code>SysDataBuilder01.R</code> and <code>SysDataBuilder02.R</code> of the package are responsible for the construction of these data with the exception of the Eta-Mu and Kappa-Mu distribution content.
</p>


<h3>Format</h3>

<p>An <span class="rlang"><b>R</b></span> <code>environment</code> with entries:
</p>

<dl>
<dt>AEPkh2lmrTable</dt><dd><p>A <code>data.frame</code> of asymmetric exponential power (4-parameter) relations between its two shape parameters, numerical, and theoretical L-skew and L-kurtosis. The table stems from <code>inst/doc/SysDataBuilder01.R</code>. (See also <code><a href="#topic+paraep4">paraep4</a></code>)</p>
</dd>
<dt>EMU_lmompara_byeta</dt><dd><p>A <code>data.frame</code> of pre-computed table of relations between the parameters and L-moments of the Eta-Mu distribution. (See also <code><a href="#topic+lmomemu">lmomemu</a></code>, <code><a href="#topic+paremu">paremu</a></code>)</p>
</dd>
<dt>KMU_lmompara_bykappa</dt><dd><p>A <code>data.frame</code> of pre-computed table of relations between the parameters and L-moments of the Kappa-Mu distribution. (See also <code><a href="#topic+lmomkmu">lmomkmu</a></code>, <code><a href="#topic+parkmu">parkmu</a></code>)</p>
</dd>
<dt>RiceTable</dt><dd><p>A <code>data.frame</code> with coefficient of L-variation, signal to noise ratio, a parameter G, and L-skew and L-kurtosis of the Rice distribution. This is useful for quick parameter estimation. The table stems from <code>inst/doc/SysDataBuilder01.R</code>. (See also <code><a href="#topic+lmomrice">lmomrice</a></code>, <code><a href="#topic+parrice">parrice</a></code>)</p>
</dd>
<dt>RiceTable.maxLCV</dt><dd><p>Maximum coefficient of L-variation representable (or apparently so) within <span class="rlang"><b>R</b></span>. The value stems from <code>inst/doc/SysDataBuilder01.R</code>.</p>
</dd>
<dt>RiceTable.minLCV</dt><dd><p>Minimum coefficient of L-variation representable (or apparently so) within <span class="rlang"><b>R</b></span>. The value stems from <code>inst/doc/SysDataBuilder01.R</code>.</p>
</dd>
<dt>tau46list</dt><dd><p>Various relations of Tau4-Tau6 for symmetrical distributions and used to support the access layer provided by <code><a href="#topic+lmrdia46">lmrdia46</a></code> for Tau4-Tau6 L-moment ratio diagrams. The tables in the list stem from <code>inst/doc/SysDataBuilder02.R</code>, which is designed to be run after the <code>SysDataBuilder01.R</code>.</p>
</dd>
</dl>


<hr>
<h2 id='add.lmomco.axis'>Add an lmomco Axis to a Plot</h2><span id='topic+add.lmomco.axis'></span>

<h3>Description</h3>

<p>This function provides special support for adding probability-like axes to an existing plot. The function supports a recurrence interval (RI) axis, normal probability axis (NPP), and standard normal variate (SNV) axis. The function is built around the interface model that standard normal transformation of the values for the respective axis controlled by this function are being plotted; this means that <code>qnorm()</code> should be wrapped on the values of nonexceedance probability. This is an ease oversight to make (see Examples section below and note use of <code>qnorm(pp)</code>).
</p>
<p>The function provides a convenient interface for labeling and titling two axes, so adjustments to default margins might be desired. The pertinent control is achieved using the <code>par()</code> function, which might be of the form <code>par(mgp=c(3,0.5,0), mar=c(5,4,4,3))</code> say for plotting the <span class="pkg">lmomco</span> axis both on the left and right (see <code><a href="#topic+z.par2cdf">z.par2cdf</a></code> for an example).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>add.lmomco.axis(side=1, twoside=FALSE, twoside.suppress.labels=FALSE,
                side.type=c("NPP", "RI", "SNV"),
                otherside.type=c("NA", "RI", "SNV", "NPP"),
                alt.lab=NA, alt.other.lab=NA, npp.as.aep=FALSE,
                case=c("upper", "lower"),
                NPP.control=NULL, RI.control=NULL, SNV.control=NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="add.lmomco.axis_+3A_side">side</code></td>
<td>
<p>The side of the plot (1=bottom, 2=left, 3=top, 4=right).</p>
</td></tr>
<tr><td><code id="add.lmomco.axis_+3A_twoside">twoside</code></td>
<td>
<p>A logical triggering whether the tick marks are echoed on the opposite side. This value is forced to <code>FALSE</code> if <code>otherside.type</code> is not <code>"NA"</code>.</p>
</td></tr>
<tr><td><code id="add.lmomco.axis_+3A_twoside.suppress.labels">twoside.suppress.labels</code></td>
<td>
<p>A logical to turn off labeling on the opposite side. This is useful if only the ticks (major and minor) are desired.</p>
</td></tr>
<tr><td><code id="add.lmomco.axis_+3A_side.type">side.type</code></td>
<td>
<p>The axis type for the primary <code>side</code>.</p>
</td></tr>
<tr><td><code id="add.lmomco.axis_+3A_otherside.type">otherside.type</code></td>
<td>
<p>The optional axis type for the opposite side. The default is a literal not applicable.</p>
</td></tr>
<tr><td><code id="add.lmomco.axis_+3A_alt.lab">alt.lab</code></td>
<td>
<p>A short-cut to change the axis label without having to specify a <code>*.control</code> argument and its <code>label</code> attribute. The label attribute of <code>alt.lab</code> is not <code>NA</code> is used instead of the defaults. This argument overrides behavior of the <code>otherside.type</code> labeling so use of <code>alt.lab</code> only makes sense if <code>otherside.type</code> is left as <code>NA</code>.</p>
</td></tr>
<tr><td><code id="add.lmomco.axis_+3A_alt.other.lab">alt.other.lab</code></td>
<td>
<p>Similar to <code>alt.lab</code> but can house an alternative label (see <b>Examples</b>.</p>
</td></tr>
<tr><td><code id="add.lmomco.axis_+3A_npp.as.aep">npp.as.aep</code></td>
<td>
<p>Convert nonexceedance probability to exceedance probability, which is a que for <code>alt.other.lab</code> and nonexceedance probabilities are changed by <code class="reqn">1-F</code>, but the real coordinates for plotting remain in the nonexceedance probability context.</p>
</td></tr>
<tr><td><code id="add.lmomco.axis_+3A_case">case</code></td>
<td>
<p>The will switch between all upper case or mixed case for the default labels.</p>
</td></tr>
<tr><td><code id="add.lmomco.axis_+3A_npp.control">NPP.control</code></td>
<td>
<p>An optional <span class="rlang"><b>R</b></span> <code>list</code> used to influence the NPP axis.</p>
</td></tr>
<tr><td><code id="add.lmomco.axis_+3A_ri.control">RI.control</code></td>
<td>
<p>An optional <span class="rlang"><b>R</b></span> <code>list</code> used to influence the RI axis.</p>
</td></tr>
<tr><td><code id="add.lmomco.axis_+3A_snv.control">SNV.control</code></td>
<td>
<p>An optional <span class="rlang"><b>R</b></span> <code>list</code> used to influence the SNV axis.</p>
</td></tr>
<tr><td><code id="add.lmomco.axis_+3A_...">...</code></td>
<td>
<p>Additional arguments that are passed to the <span class="rlang"><b>R</b></span> function <code>Axis</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>No value is returned. This function is used for its side effects.
</p>


<h3>Note</h3>

<p>The <code>NPP.control</code>, <code>RI.control</code>, and <code>SNV.control</code> are <span class="rlang"><b>R</b></span> <code>list</code> structures that can be populated (and perhaps someday extended) to feed various settings into the respective axis types.  In brief:
</p>
<p>The <code>NPP.control</code> provides
</p>

<table>
<tr>
 <td style="text-align: left;">
  <code>label</code> </td><td style="text-align: left;"> The title for the NPP axis---be careful with value of <code>as.exceed</code>. </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code>probs</code> </td><td style="text-align: left;"> A vector of nonexceedance probabilities <code class="reqn">F</code>. </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code>probs.lab</code> </td><td style="text-align: left;"> A vector of nonexceedance probabilities <code class="reqn">F</code> to label. </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code>digits</code> </td><td style="text-align: left;"> The digits for the <span class="rlang"><b>R</b></span> function <code>format</code> to enhance appearance. </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code>line</code>  </td><td style="text-align: left;"> The line for the <span class="rlang"><b>R</b></span> function <code>mtext</code> to place <code>label</code>. </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code>as.exceed</code> </td><td style="text-align: left;"> A logical triggering <code class="reqn">S = 1 - F</code>.
</td>
</tr>

</table>

<p>The <code>RI.control</code> provides
</p>

<table>
<tr>
 <td style="text-align: left;">
  <code>label</code> </td><td style="text-align: left;"> The title for the RI axis. </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code>Tyear</code> </td><td style="text-align: left;"> A vector of <code class="reqn">T</code>-year recurrence intervals. </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code>line</code>  </td><td style="text-align: left;"> The line for the <span class="rlang"><b>R</b></span> function <code>mtext</code> to place <code>label</code>.
</td>
</tr>

</table>

<p>The <code>SNV.control</code> provides
</p>

<table>
<tr>
 <td style="text-align: left;">
  <code>label</code> </td><td style="text-align: left;"> The title for the SNV axis. </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code>begin</code> </td><td style="text-align: left;"> The beginning &ldquo;number of standard deviations&rdquo;. </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code>end</code>   </td><td style="text-align: left;"> The ending &ldquo;number of standard deviations&rdquo;. </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code>by</code>    </td><td style="text-align: left;"> The step between <code>begin</code> and <code>end</code>. </td>
</tr>
<tr>
 <td style="text-align: left;">
  <code>line</code>  </td><td style="text-align: left;"> The line for the <span class="rlang"><b>R</b></span> function <code>mtext</code> to place <code>label</code>.
</td>
</tr>

</table>

<p>The user is responsible for appropriate construction of the <code>control</code> lists. Very little error trapping is made to keep the code base tight. The defaults when the function definition are likely good for many types of applications. Lastly, the manipulation of the <code>mgp</code> parameter in the example is to show how to handle the offset between the numbers and the ticks when the ticks are moved to pointing inward, which is opposite of the default in <span class="rlang"><b>R</b></span>.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>See Also</h3>

<p><code><a href="#topic+prob2T">prob2T</a></code>, <code><a href="#topic+T2prob">T2prob</a></code>, <code><a href="#topic+add.log.axis">add.log.axis</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>par(mgp=c(3,0.5,0)) # going to tick to the inside, change some parameters
X &lt;- sort(rnorm(65)); pp &lt;- pp(X) # generate synthetic data
plot(qnorm(pp), X, xaxt="n", xlab="", ylab="QUANTILE", xlim=c(-2,3))
add.lmomco.axis(las=2, tcl=0.5, side.type="RI", otherside.type="NPP")
par(mgp=c(3,1,0)) # restore defaults

## Not run: 
opts &lt;- options(scipen=6); par(mgp=c(3,0.5,0))
X &lt;- sort(rexp(65, rate=.0001))*100; pp &lt;- pp(X) # generate synthetic data
plot(qnorm(pp), X, yaxt="n", xaxt="n", xlab="", ylab="", log="y")
add.log.axis(side=2,    tcl=+0.8*abs(par()$tcl),         two.sided=TRUE)
add.log.axis(logs=c(1), tcl=-0.5*abs(par()$tcl), side=2, two.sided=TRUE)
add.log.axis(logs=c(1), tcl=+1.3*abs(par()$tcl), side=2, two.sided=TRUE)
add.log.axis(logs=1:8, side=2, make.labs=TRUE, las=1, label="QUANTILE")
add.lmomco.axis(las=2, tcl=0.5, side.type="NPP", npp.as.aep=TRUE, case="lower")
options(opts)
par(mgp=c(3,1,0)) # restore defaults
## End(Not run)
</code></pre>

<hr>
<h2 id='add.log.axis'>Add a Polished Logarthimic Axis to a Plot</h2><span id='topic+add.log.axis'></span>

<h3>Description</h3>

<p>This function provides special support for adding superior looking base-10 logarithmic axes relative to <b>R</b>'s defaults, which are an embarassment. The <b>Examples</b> section shows an overly elaborate version made by repeated calls to this function with a drawback that each call redraws the line of the axis so deletion in editing software might be required. This function is indexed under the &ldquo;lmomco functions&rdquo; because of its relation to <code><a href="#topic+add.lmomco.axis">add.lmomco.axis</a></code> and is not named <code>add.lmomcolog.axis</code> because such a name is too cumbersome.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>add.log.axis(make.labs=FALSE, logs=c(2, 3, 4, 5, 6, 7, 8, 9), side=1,
             two.sided=FALSE, label=NULL, x=NULL, col.ticks=1, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="add.log.axis_+3A_make.labs">make.labs</code></td>
<td>
<p>A logical controlling whether the axis is labled according to the values in <code>logs</code>.</p>
</td></tr>
<tr><td><code id="add.log.axis_+3A_logs">logs</code></td>
<td>
<p>A numeric vector of log-cycles for which ticking and (or) labeling is made. These are normalized to the first log-cycle, so a value of <code class="reqn">3</code> would spawn values such as <code class="reqn">\cdots, 0.03, 0.3, 3, 30, \cdots</code> through a range exceeding the axis limits. The default anticipates that a second call to the function will be used to make longer ticks at the even log-cycles; hence, the value 1 is not in the default vector. The <b>Examples</b> section provides a thorough demonstration.</p>
</td></tr>
<tr><td><code id="add.log.axis_+3A_side">side</code></td>
<td>
<p>An integer specifying which side of the plot the axis is to be drawn on, and argument corresponds the axis side argument of the <code>axis</code> function. The axis is placed as follows: 1=below, 2=left, 3=above, and 4=right.</p>
</td></tr>
<tr><td><code id="add.log.axis_+3A_two.sided">two.sided</code></td>
<td>
<p>A logical controlling whether the side oppose of <code>side</code> also is to be drawn.</p>
</td></tr>
<tr><td><code id="add.log.axis_+3A_label">label</code></td>
<td>
<p>The label (title) of the axis, which is placed by a call to function <code>mtext</code>, and thus either the <code>xlab</code> or <code>ylab</code> arguments for <code>plot</code> should be set to the empty string <code>""</code>.</p>
</td></tr>
<tr><td><code id="add.log.axis_+3A_x">x</code></td>
<td>
<p>This is an optional data vector (untransformed!), which will compute nice axis limits and return them. These limits will align with (snap to) the integers within a log10-cycle.</p>
</td></tr>
<tr><td><code id="add.log.axis_+3A_col.ticks">col.ticks</code></td>
<td>
<p>This is the same argument as the <code>axis</code> function.</p>
</td></tr>
<tr><td><code id="add.log.axis_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass to <code>axis</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>No value is returned, except if argument <code>x</code> is given, for which nice axis limits are returned. By overall design, this function is used for its side effects.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>See Also</h3>

<p><code><a href="#topic+add.lmomco.axis">add.lmomco.axis</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
par(mgp=c(3,0.5,0)) # going to tick to the inside, change some parameters
X &lt;- 10^sort(rnorm(65)); pp &lt;- pp(X) # generate synthetic data
ylim &lt;- add.log.axis(x=X) # snap to some nice integers within the cycle
plot(qnorm(pp), X, xaxt="n", yaxt="n", xlab="", ylab="", log="y",
     xlim=c(-2,3), ylim=ylim, pch=6, yaxs="i", col=4)
add.lmomco.axis(las=2, tcl=0.5, side.type="RI", otherside.type="NPP")
# Logarithmic axis: the base ticks to show logarithms
add.log.axis(side=2,      tcl=0.8*abs(par()$tcl), two.sided=TRUE)
#                   the long even-cycle tick, set to inside and outside
add.log.axis(logs=c(1),   tcl=-0.5*abs(par()$tcl), side=2, two.sided=TRUE)
add.log.axis(logs=c(1),   tcl=+1.3*abs(par()$tcl), side=2, two.sided=TRUE)
#                   now a micro tick at the 1.5 logs but only on the right
add.log.axis(logs=c(1.5), tcl=+0.5*abs(par()$tcl), side=4)
#                   and only label the micro tick at 1.5 on the right
add.log.axis(logs=c(1.5), side=4, make.labs=TRUE, las=3) # but weird rotate
#                   add the bulk tick labeling and axis label.
add.log.axis(logs=c(1, 2, 3, 4, 6), side=2, make.labs=TRUE, las=1, label="QUANTILE")
par(mgp=c(3,1,0)) # restore defaults
## End(Not run)
</code></pre>

<hr>
<h2 id='amarilloprecip'>Annual Maximum Precipitation Data for Amarillo, Texas</h2><span id='topic+amarilloprecip'></span>

<h3>Description</h3>

<p>Annual maximum precipitation data for Amarillo, Texas
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(amarilloprecip)
</code></pre>


<h3>Format</h3>

<p>An <span class="rlang"><b>R</b></span> <code>data.frame</code> with
</p>

<dl>
<dt>YEAR</dt><dd><p>The calendar year of the annual maxima.</p>
</dd>
<dt>DEPTH</dt><dd><p>The depth of 7-day annual maxima rainfall in inches.</p>
</dd>
</dl>



<h3>References</h3>

<p>Asquith, W.H., 1998, Depth-duration frequency of precipitation for
Texas: U.S. Geological Survey Water-Resources Investigations Report
98&ndash;4044, 107 p.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(amarilloprecip)
summary(amarilloprecip)
</code></pre>

<hr>
<h2 id='Apwm2BpwmRC'>Conversion between A- and B-Type Probability-Weighted Moments for Right-Tail Censoring of an Appropriate Distribution</h2><span id='topic+Apwm2BpwmRC'></span>

<h3>Description</h3>

<p>This function converts &ldquo;A&rdquo;-type probability-weighted moments (PWMs, <code class="reqn">\beta^A_r</code>) to the &ldquo;B&rdquo;-type <code class="reqn">\beta^B_r</code>. The <code class="reqn">\beta^A_r</code> are the ordinary PWMs for the <code class="reqn">m</code> left noncensored or observed values. The <code class="reqn">\beta^B_r</code> are more complex and use the <code class="reqn">m</code> observed values and the <code class="reqn">m-n</code> right-tailed censored values for which the censoring threshold is known. The &ldquo;A&rdquo;- and &ldquo;B&rdquo;-type PWMs are described in the documentation for <code><a href="#topic+pwmRC">pwmRC</a></code>.
</p>
<p>This function uses the defined relation between to two PWM types when the <code class="reqn">\beta^A_r</code> are known along with the parameters (<code>para</code>) of a right-tail censored distribution inclusive of the censoring fraction <code class="reqn">\zeta=m/n</code>. The value <code class="reqn">\zeta</code> is the right-tail censor fraction or the probability <code class="reqn">\mathrm{Pr}\lbrace \rbrace</code> that <code class="reqn">x</code> is less than the quantile at <code class="reqn">\zeta</code> nonexceedance probability (<code class="reqn">\mathrm{Pr}\lbrace x &lt; X(\zeta) \rbrace</code>). The relation is
</p>
<p style="text-align: center;"><code class="reqn">\beta^B_{r-1} = r^{-1}\lbrace\zeta^r r \beta^A_{r-1} + (1-\zeta^r)X(\zeta)\rbrace \mbox{,}</code>
</p>

<p>where <code class="reqn">1 \le r \le n</code> and <code class="reqn">n</code> is the number of moments, and <code class="reqn">X(\zeta)</code> is the value of the quantile function at nonexceedance probability <code class="reqn">\zeta</code>. Finally, the <code>RC</code> in the function name is to denote <code>R</code>ight-tail <code>C</code>ensoring.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Apwm2BpwmRC(Apwm,para)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Apwm2BpwmRC_+3A_apwm">Apwm</code></td>
<td>
<p>A vector of A-type PWMs: <code class="reqn">\beta^A_r</code>.</p>
</td></tr>
<tr><td><code id="Apwm2BpwmRC_+3A_para">para</code></td>
<td>
<p>The parameters of the distribution from a function such as <code><a href="#topic+pargpaRC">pargpaRC</a></code> in which the <code class="reqn">\beta^A_r</code> are contained in a <code>list</code> element titled <code>betas</code> and the right-tail censoring fraction <code class="reqn">\zeta</code> is contained in an element titled <code>zeta</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> is returned.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Hosking, J.R.M., 1995, The use of L-moments in the analysis of censored data,
in Recent Advances in Life-Testing and Reliability, edited by N. Balakrishnan,
chapter 29, CRC Press, Boca Raton, Fla., pp. 546&ndash;560.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Bpwm2ApwmRC">Bpwm2ApwmRC</a></code>, <code><a href="#topic+pwmRC">pwmRC</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'># Data listed in Hosking (1995, table 29.2, p. 551)
H &lt;- c(3,4,5,6,6,7,8,8,9,9,9,10,10,11,11,11,13,13,13,13,13,
             17,19,19,25,29,33,42,42,51.9999,52,52,52)
      # 51.9999 was really 52, a real (noncensored) data point.
z &lt;-  pwmRC(H,52)
# The B-type PMWs are used for the parameter estimation of the
# Reverse Gumbel distribution. The parameter estimator requires
# conversion of the PWMs to L-moments by pwm2lmom().
para &lt;- parrevgum(pwm2lmom(z$Bbetas),z$zeta) # parameter object
Bbetas &lt;- Apwm2BpwmRC(z$Abetas,para)
Abetas &lt;- Bpwm2ApwmRC(Bbetas$betas,para)
# Assertion that both of the vectors of B-type PWMs should be the same.
str(Abetas)   # A-type PWMs of the distribution
str(z$Abetas) # A-type PWMs of the original data
</code></pre>

<hr>
<h2 id='are.lmom.valid'>Are the L-moments valid</h2><span id='topic+are.lmom.valid'></span>

<h3>Description</h3>

<p>The L-moments have particular constraints on magnitudes and relation to each other.  This function evaluates and L-moment object whether the bounds for <code class="reqn">\lambda_2 &gt; 0</code> (L-scale), <code class="reqn">|\tau_3| &lt; 1</code> (L-skew), <code class="reqn">\tau_4 &lt; 1</code> (L-kurtosis), and <code class="reqn">|\tau_5| &lt; 1</code> are satisfied. An optional check on <code class="reqn">\tau_4 \ge (5\tau_3^2 - 1)/4</code> is made. Also for further protection, the finitenesses of the mean (<code class="reqn">\lambda_1</code>) and <code class="reqn">\lambda_2</code> are also checked. These checks provide protection against say L-moments being computed on the logarithms of some data but the data themselves have values less than or equal to zero.
</p>
<p>The TL-moments as implemented by the <code>TL</code> functions (<code><a href="#topic+TLmoms">TLmoms</a></code>) are not applicable to the boundaries (well finiteness of course). The <code>are.lmom.valid</code> function should not be consulted on the TL-moments.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>are.lmom.valid(lmom, checkt3t4=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="are.lmom.valid_+3A_lmom">lmom</code></td>
<td>
<p>An L-moment object created by <code><a href="#topic+lmoms">lmoms</a></code>, <code><a href="#topic+lmom.ub">lmom.ub</a></code>, <code><a href="#topic+pwm2lmom">pwm2lmom</a></code>; and</p>
</td></tr>
<tr><td><code id="are.lmom.valid_+3A_checkt3t4">checkt3t4</code></td>
<td>
<p>A logical triggering the above test on L-skew to L-kurtosis. This bounds in very small samples can be violated&mdash;usually the user will want this set and until (first release in 2017, v2.2.6) this bounds check was standard in <span class="pkg">lmomco</span> for over a decade.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>TRUE</code></td>
<td>
<p>L-moments are valid.</p>
</td></tr>
<tr><td><code>FALSE</code></td>
<td>
<p>L-moments are not valid.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Hosking, J.R.M., 1990, L-moments&mdash;Analysis and estimation of distributions using linear combinations of order statistics: Journal of the Royal Statistical Society, Series B, v. 52, pp. 105&ndash;124.
</p>
<p>Hosking, J.R.M. and Wallis, J.R., 1997, Regional frequency analysis&mdash;An approach based on L-moments: Cambridge University Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lmom.ub">lmom.ub</a></code>, <code><a href="#topic+lmoms">lmoms</a></code>, <code><a href="#topic+pwm2lmom">pwm2lmom</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>lmr &lt;- lmoms(rnorm(20))
if(are.lmom.valid(lmr)) print("They are.")
## Not run: 
X &lt;- c(1.7106278,  1.7598761,  1.2111335,  0.3447490,  1.8312889,
       1.3938445, -0.5376054, -0.2341009, -0.4333601, -0.2545229)
are.lmom.valid(lmoms(X))
are.lmom.valid(pwm2lmom(pwm.pp(X, a=0.5)))

# Prior to version 2.2.6, the next line could leak through as TRUE. This was a problem.
# Nonfiniteness of the mean or L-scale should have been checked; they are for v2.2.6+
are.lmom.valid(lmoms(log10(c(1,23,235,652,0)), nmom=1)) # of other nmom

## End(Not run)
</code></pre>

<hr>
<h2 id='are.par.valid'>Are the Distribution Parameters Consistent with the Distribution</h2><span id='topic+are.par.valid'></span>

<h3>Description</h3>

<p>This function is a dispatcher on top of the <code>are.parCCC.valid</code> functions, where <code>CCC</code> represents the distribution type:  <code>aep4</code>, <code>cau</code>, <code>emu</code>, <code>exp</code>, <code>gam</code>, <code>gep</code>, <code>gev</code>, <code>glo</code>, <code>gno</code>, <code>gov</code>, <code>gpa</code>, <code>gum</code>, <code>kap</code>, <code>kmu</code>, <code>kur</code>, <code>lap</code>, <code>ln3</code>, <code>nor</code>, <code>pe3</code>, <code>ray</code>, <code>revgum</code>, <code>rice</code>, <code>sla</code>, <code>smd</code>, <code>st3</code>, <code>texp</code>, <code>tri</code>, <code>wak</code>, or <code>wei</code>. For <span class="pkg">lmomco</span> functionality, <code><a href="#topic+are.par.valid">are.par.valid</a></code> is called only by <code><a href="#topic+vec2par">vec2par</a></code> in the process of converting a vector into a proper distribution parameter object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>are.par.valid(para, paracheck=TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="are.par.valid_+3A_para">para</code></td>
<td>
<p>A distribution parameter object having at least attributes <code>type</code> and <code>para</code>.</p>
</td></tr>
<tr><td><code id="are.par.valid_+3A_paracheck">paracheck</code></td>
<td>
<p>A logical controlling whether the parameters are checked for validity and if <code>paracheck=TRUE</code> then effectively this whole function becomes turned off.</p>
</td></tr>
<tr><td><code id="are.par.valid_+3A_...">...</code></td>
<td>
<p>Additional arguments for the <code>are.parCCC.valid</code> call that is made internally.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>TRUE</code></td>
<td>
<p>If the parameters are consistent with the distribution specified by the <code>type</code> attribute of the parameter object.</p>
</td></tr>
<tr><td><code>FALSE</code></td>
<td>
<p>If the parameters are not consistent with the distribution specified by the <code>type</code> attribute of the parameter object.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Asquith, W.H., 2011, Distributional analysis with L-moment statistics using the R environment for statistical computing: Createspace Independent Publishing Platform, ISBN 978&ndash;146350841&ndash;8.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+vec2par">vec2par</a></code>, <code><a href="#topic+dist.list">dist.list</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>vec  &lt;- c(12, 120)           # parameters of exponential distribution
para &lt;- vec2par(vec, "exp")  # build exponential distribution parameter
                             # object
# The following two conditionals are equivalent as are.parexp.valid()
# is called within are.par.valid().
if(   are.par.valid(para)) Q &lt;- quaexp(0.5, para)
if(are.parexp.valid(para)) Q &lt;- quaexp(0.5, para)
</code></pre>

<hr>
<h2 id='are.paraep4.valid'>Are the Distribution Parameters Consistent with the 4-Parameter Asymmetric Exponential Power Distribution</h2><span id='topic+are.paraep4.valid'></span>

<h3>Description</h3>

<p>Is the distribution parameter object consistent with the corresponding distribution?  The distribution functions  (<code><a href="#topic+cdfaep4">cdfaep4</a></code>, <code><a href="#topic+pdfaep4">pdfaep4</a></code>, <code><a href="#topic+quaaep4">quaaep4</a></code>, and
<code><a href="#topic+lmomaep4">lmomaep4</a></code>) require consistent parameters to return the cumulative
probability (nonexceedance), density, quantile, and L-moments of the distribution,
respectively.  These functions internally use the <code><a href="#topic+are.paraep4.valid">are.paraep4.valid</a></code>
function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>are.paraep4.valid(para, nowarn=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="are.paraep4.valid_+3A_para">para</code></td>
<td>
<p>A distribution parameter list returned by <code><a href="#topic+paraep4">paraep4</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
<tr><td><code id="are.paraep4.valid_+3A_nowarn">nowarn</code></td>
<td>
<p>A logical switch on warning suppression. If <code>TRUE</code> then <code>options(warn=-1)</code> is made and restored on return. This switch is to permit calls in which warnings are not desired as the user knows how to handle the returned value&mdash;say in an optimization algorithm.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>TRUE</code></td>
<td>
<p>If the parameters are <code>aep4</code> consistent.</p>
</td></tr>
<tr><td><code>FALSE</code></td>
<td>
<p>If the parameters are not <code>aep4</code> consistent.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>This function calls <code><a href="#topic+is.aep4">is.aep4</a></code> to verify consistency between
the distribution parameter object and the intent of the user.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Asquith, W.H., 2014, Parameter estimation for the 4-parameter asymmetric exponential power distribution by the method of L-moments using R: Computational Statistics and Data Analysis, v. 71, pp. 955&ndash;970.
</p>
<p>Delicado, P., and Goria, M.N., 2008, A small sample comparison of maximum likelihood,
moments and L-moments methods for the asymmetric exponential power distribution:
Computational Statistics and Data Analysis, v. 52, no. 3, pp. 1661&ndash;1673.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+is.aep4">is.aep4</a></code>, <code><a href="#topic+paraep4">paraep4</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>para &lt;- vec2par(c(0,1, 0.5, 4), type="aep4")
if(are.paraep4.valid(para)) Q &lt;- quaaep4(0.5,para)
</code></pre>

<hr>
<h2 id='are.parcau.valid'>Are the Distribution Parameters Consistent with the Cauchy Distribution</h2><span id='topic+are.parcau.valid'></span>

<h3>Description</h3>

<p>Is the distribution parameter object consistent with the corresponding distribution?  The distribution functions  (<code><a href="#topic+cdfcau">cdfcau</a></code>, <code><a href="#topic+pdfcau">pdfcau</a></code>,  <code><a href="#topic+quacau">quacau</a></code>, and <code><a href="#topic+lmomcau">lmomcau</a></code>) require consistent parameters to return the cumulative
probability (nonexceedance), density, quantile, and L-moments of the distribution,
respectively. These functions internally use the <code><a href="#topic+are.parcau.valid">are.parcau.valid</a></code> function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>are.parcau.valid(para, nowarn=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="are.parcau.valid_+3A_para">para</code></td>
<td>
<p>A distribution parameter list returned by <code><a href="#topic+parcau">parcau</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
<tr><td><code id="are.parcau.valid_+3A_nowarn">nowarn</code></td>
<td>
<p>A logical switch on warning suppression. If <code>TRUE</code> then <code>options(warn=-1)</code> is made and restored on return. This switch is to permit calls in which warnings are not desired as the user knows how to handle the returned value&mdash;say in an optimization algorithm.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>TRUE</code></td>
<td>
<p>If the parameters are <code>cau</code> consistent.</p>
</td></tr>
<tr><td><code>FALSE</code></td>
<td>
<p>If the parameters are not <code>cau</code> consistent.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>This function calls <code><a href="#topic+is.cau">is.cau</a></code> to verify consistency between
the distribution parameter object and the intent of the user.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Elamir, E.A.H., and Seheult, A.H., 2003, Trimmed L-moments: Computational Statistics and Data Analysis, v. 43, pp. 299&ndash;314.
</p>
<p>Gilchrist, W.G., 2000, Statistical modeling with quantile functions: Chapman and Hall/CRC, Boca Raton, FL.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+is.cau">is.cau</a></code>, <code><a href="#topic+parcau">parcau</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>para &lt;- vec2par(c(12,12),type='cau')
if(are.parcau.valid(para)) Q &lt;- quacau(0.5,para)
</code></pre>

<hr>
<h2 id='are.paremu.valid'>Are the Distribution Parameters Consistent with the Eta-Mu Distribution</h2><span id='topic+are.paremu.valid'></span>

<h3>Description</h3>

<p>Is the distribution parameter object consistent with the corresponding distribution?  The distribution functions  (<code><a href="#topic+cdfemu">cdfemu</a></code>, <code><a href="#topic+pdfemu">pdfemu</a></code>, <code><a href="#topic+quaemu">quaemu</a></code>, <code><a href="#topic+lmomemu">lmomemu</a></code>), and <code><a href="#topic+lmomemu">lmomemu</a></code> require consistent parameters to return the cumulative probability (nonexceedance), density, quantile, and L-moments of the distribution, respectively.  These functions internally use the <code><a href="#topic+are.paremu.valid">are.paremu.valid</a></code> function. The documentation for <code><a href="#topic+pdfemu">pdfemu</a></code> provides the conditions for valid parameters.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>are.paremu.valid(para, nowarn=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="are.paremu.valid_+3A_para">para</code></td>
<td>
<p>A distribution parameter list returned by <code><a href="#topic+paremu">paremu</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
<tr><td><code id="are.paremu.valid_+3A_nowarn">nowarn</code></td>
<td>
<p>A logical switch on warning suppression. If <code>TRUE</code> then <code>options(warn=-1)</code> is made and restored on return. This switch is to permit calls in which warnings are not desired as the user knows how to handle the returned value&mdash;say in an optimization algorithm.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>TRUE</code></td>
<td>
<p>If the parameters are <code>emu</code> consistent.</p>
</td></tr>
<tr><td><code>FALSE</code></td>
<td>
<p>If the parameters are not <code>emu</code> consistent.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>This function calls <code><a href="#topic+is.emu">is.emu</a></code> to verify consistency between
the distribution parameter object and the intent of the user.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>See Also</h3>

<p><code><a href="#topic+is.emu">is.emu</a></code>, <code><a href="#topic+paremu">paremu</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
para &lt;- vec2par(c(0.4, .04), type="emu")
if(are.paremu.valid(para)) Q &lt;- quaemu(0.5,para) # 
## End(Not run)
</code></pre>

<hr>
<h2 id='are.parexp.valid'>Are the Distribution Parameters Consistent with the Exponential Distribution</h2><span id='topic+are.parexp.valid'></span>

<h3>Description</h3>

<p>Is the distribution parameter object consistent with the corresponding distribution?  The distribution functions  (<code><a href="#topic+cdfexp">cdfexp</a></code>, <code><a href="#topic+pdfexp">pdfexp</a></code>, <code><a href="#topic+quaexp">quaexp</a></code>, and
<code><a href="#topic+lmomexp">lmomexp</a></code>) require consistent parameters to return the cumulative
probability (nonexceedance), density, quantile, and L-moments of the distribution,
respectively.  These functions internally use the <code><a href="#topic+are.parexp.valid">are.parexp.valid</a></code>
function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>are.parexp.valid(para, nowarn=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="are.parexp.valid_+3A_para">para</code></td>
<td>
<p>A distribution parameter list returned by <code><a href="#topic+parexp">parexp</a></code>.</p>
</td></tr>
<tr><td><code id="are.parexp.valid_+3A_nowarn">nowarn</code></td>
<td>
<p>A logical switch on warning suppression. If <code>TRUE</code> then <code>options(warn=-1)</code> is made and restored on return. This switch is to permit calls in which warnings are not desired as the user knows how to handle the returned value&mdash;say in an optimization algorithm.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>TRUE</code></td>
<td>
<p>If the parameters are <code>exp</code> consistent.</p>
</td></tr>
<tr><td><code>FALSE</code></td>
<td>
<p>If the parameters are not <code>exp</code> consistent.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>This function calls <code><a href="#topic+is.exp">is.exp</a></code> to verify consistency between
the distribution parameter object and the intent of the user.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Hosking, J.R.M., 1996, FORTRAN routines for use with the method of L-moments:
Version 3, IBM Research Report RC20525, T.J. Watson Research Center,
Yorktown Heights, New York.
</p>
<p>Hosking, J.R.M., and Wallis, J.R., 1997, Regional frequency analysis&mdash;An
approach based on L-moments: Cambridge University Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+is.exp">is.exp</a></code>, <code><a href="#topic+parexp">parexp</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>para &lt;- parexp(lmoms(c(123,34,4,654,37,78)))
if(are.parexp.valid(para)) Q &lt;- quaexp(0.5,para)
</code></pre>

<hr>
<h2 id='are.pargam.valid'>Are the Distribution Parameters Consistent with the Gamma Distribution</h2><span id='topic+are.pargam.valid'></span>

<h3>Description</h3>

<p>Is the distribution parameter object consistent with the corresponding distribution?  The distribution functions  (<code><a href="#topic+cdfgam">cdfgam</a></code>, <code><a href="#topic+pdfgam">pdfgam</a></code>, <code><a href="#topic+quagam">quagam</a></code>, and
<code><a href="#topic+lmomgam">lmomgam</a></code>) require consistent parameters to return the cumulative
probability (nonexceedance), density, quantile, and L-moments of the distribution,
respectively.  These functions internally use the <code><a href="#topic+are.pargam.valid">are.pargam.valid</a></code>
function.  The parameters are restricted to the following conditions.
</p>
<p style="text-align: center;"><code class="reqn">\alpha &gt; 0 \mbox{ and } \beta &gt; 0\mbox{.}</code>
</p>

<p>Alternatively, a three-parameter version is available following the parameterization of the Generalized Gamma distribution used in the <span class="pkg">gamlss.dist</span> package and  and for <span class="pkg">lmomco</span> is documented under <code><a href="#topic+pdfgam">pdfgam</a></code>. The parameters for this version are 
</p>
<p style="text-align: center;"><code class="reqn">\mu &gt; 0;\;\; \sigma &gt; 0;\;\; -\infty &lt; \nu &lt; \infty</code>
</p>

<p>for parameters number 1, 2, 3, respectively.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>are.pargam.valid(para, nowarn=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="are.pargam.valid_+3A_para">para</code></td>
<td>
<p>A distribution parameter list returned by <code><a href="#topic+pargam">pargam</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
<tr><td><code id="are.pargam.valid_+3A_nowarn">nowarn</code></td>
<td>
<p>A logical switch on warning suppression. If <code>TRUE</code> then <code>options(warn=-1)</code> is made and restored on return. This switch is to permit calls in which warnings are not desired as the user knows how to handle the returned value&mdash;say in an optimization algorithm.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>TRUE</code></td>
<td>
<p>If the parameters are <code>gam</code> consistent.</p>
</td></tr>
<tr><td><code>FALSE</code></td>
<td>
<p>If the parameters are not <code>gam</code> consistent.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>This function calls <code><a href="#topic+is.gam">is.gam</a></code> to verify consistency between
the distribution parameter object and the intent of the user.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Hosking, J.R.M., and Wallis, J.R., 1997, Regional frequency analysis&mdash;An
approach based on L-moments: Cambridge University Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+is.gam">is.gam</a></code>, <code><a href="#topic+pargam">pargam</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>para &lt;- pargam(lmoms(c(123,34,4,654,37,78)))
if(are.pargam.valid(para)) Q &lt;- quagam(0.5,para)
</code></pre>

<hr>
<h2 id='are.pargep.valid'>Are the Distribution Parameters Consistent with the Generalized Exponential Poisson Distribution</h2><span id='topic+are.pargep.valid'></span>

<h3>Description</h3>

<p>Is the distribution parameter object consistent with the corresponding distribution?  The distribution functions  (<code><a href="#topic+cdfgep">cdfgep</a></code>, <code><a href="#topic+pdfgep">pdfgep</a></code>, <code><a href="#topic+quagep">quagep</a></code>, and
<code><a href="#topic+lmomgep">lmomgep</a></code>) require consistent parameters to return the cumulative
probability (nonexceedance), density, quantile, and L-moments of the distribution,
respectively.  These functions internally use the <code><a href="#topic+are.pargep.valid">are.pargep.valid</a></code>
function. The parameters must be <code class="reqn">\beta &gt; 0</code>, <code class="reqn">\kappa &gt; 0</code>, and <code class="reqn">h &gt; 0</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>are.pargep.valid(para, nowarn=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="are.pargep.valid_+3A_para">para</code></td>
<td>
<p>A distribution parameter list returned by <code><a href="#topic+pargep">pargep</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
<tr><td><code id="are.pargep.valid_+3A_nowarn">nowarn</code></td>
<td>
<p>A logical switch on warning suppression. If <code>TRUE</code> then <code>options(warn=-1)</code> is made and restored on return. This switch is to permit calls in which warnings are not desired as the user knows how to handle the returned value&mdash;say in an optimization algorithm.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>TRUE</code></td>
<td>
<p>If the parameters are <code>gep</code> consistent.</p>
</td></tr>
<tr><td><code>FALSE</code></td>
<td>
<p>If the parameters are not <code>gep</code> consistent.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>This function calls <code><a href="#topic+is.gep">is.gep</a></code> to verify consistency between
the distribution parameter object and the intent of the user.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Barreto-Souza, W., and Cribari-Neto, F., 2009, A generalization of the exponential-Poisson distribution: Statistics and Probability, 79, pp. 2493&ndash;2500.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+is.gep">is.gep</a></code>, <code><a href="#topic+pargep">pargep</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>#para &lt;- pargep(lmoms(c(123,34,4,654,37,78)))
#if(are.pargep.valid(para)) Q &lt;- quagep(0.5,para)
</code></pre>

<hr>
<h2 id='are.pargev.valid'>Are the Distribution Parameters Consistent with the Generalized Extreme Value Distribution</h2><span id='topic+are.pargev.valid'></span>

<h3>Description</h3>

<p>Is the distribution parameter object consistent with the corresponding distribution?  The distribution functions  (<code><a href="#topic+cdfgev">cdfgev</a></code>, <code><a href="#topic+pdfgev">pdfgev</a></code>, <code><a href="#topic+quagev">quagev</a></code>, and <code><a href="#topic+lmomgev">lmomgev</a></code>) require consistent parameters to return the cumulative probability (nonexceedance), density, quantile, and L-moments of the distribution, respectively. These functions internally use the <code><a href="#topic+are.pargev.valid">are.pargev.valid</a></code> function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>are.pargev.valid(para, nowarn=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="are.pargev.valid_+3A_para">para</code></td>
<td>
<p>A distribution parameter list returned by <code><a href="#topic+pargev">pargev</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
<tr><td><code id="are.pargev.valid_+3A_nowarn">nowarn</code></td>
<td>
<p>A logical switch on warning suppression. If <code>TRUE</code> then <code>options(warn=-1)</code> is made and restored on return. This switch is to permit calls in which warnings are not desired as the user knows how to handle the returned value&mdash;say in an optimization algorithm.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>TRUE</code></td>
<td>
<p>If the parameters are <code>gev</code> consistent.</p>
</td></tr>
<tr><td><code>FALSE</code></td>
<td>
<p>If the parameters are not <code>gev</code> consistent.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>This function calls <code><a href="#topic+is.gev">is.gev</a></code> to verify consistency between the distribution parameter object and the intent of the user.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Hosking, J.R.M., 1996, FORTRAN routines for use with the method of L-moments: Version 3, IBM Research Report RC20525, T.J. Watson Research Center, Yorktown Heights, New York.
</p>
<p>Hosking, J.R.M., and Wallis, J.R., 1997, Regional frequency analysis&mdash;An approach based on L-moments: Cambridge University Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+is.gev">is.gev</a></code>, <code><a href="#topic+pargev">pargev</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>para &lt;- pargev(lmoms(c(123, 34, 4, 654, 37, 78)))
if(are.pargev.valid(para)) Q &lt;- quagev(0.5, para)
</code></pre>

<hr>
<h2 id='are.pargld.valid'>Are the Distribution Parameters Consistent with the Generalized Lambda Distribution</h2><span id='topic+are.pargld.valid'></span>

<h3>Description</h3>

<p>Is the distribution parameter object consistent with the corresponding distribution?  The distribution functions  (<code><a href="#topic+cdfgld">cdfgld</a></code>, <code><a href="#topic+pdfgld">pdfgld</a></code>, <code>quagld</code>, and <code><a href="#topic+lmomgld">lmomgld</a></code>) require consistent parameters to return the cumulative probability (nonexceedance), density, quantile, and L-moments of the distribution, respectively.  These functions internally use the <code><a href="#topic+are.pargld.valid">are.pargld.valid</a></code> function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>are.pargld.valid(para, verbose=FALSE, nowarn=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="are.pargld.valid_+3A_para">para</code></td>
<td>
<p>A distribution parameter list returned by <code><a href="#topic+pargld">pargld</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
<tr><td><code id="are.pargld.valid_+3A_verbose">verbose</code></td>
<td>
<p>A logical switch on additional output to the user&mdash;default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="are.pargld.valid_+3A_nowarn">nowarn</code></td>
<td>
<p>A logical switch on warning suppression. If <code>TRUE</code> then <code>options(warn=-1)</code> is made and restored on return. This switch is to permit calls in which warnings are not desired as the user knows how to handle the returned value&mdash;say in an optimization algorithm.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Karian and Dudewicz (2000) outline valid parameter space of the Generalized Lambda distribution. First, according to Theorem 1.3.3 the distribution is valid if and only if
</p>
<p style="text-align: center;"><code class="reqn">\alpha(\kappa F^{\kappa - 1} + h(1-F)^{h -1 }) \ge 0 \mbox{.}</code>
</p>

<p>for all <code class="reqn">F \in [0,1]</code>. The <code>are.pargld.valid</code> function tests against this condition by incrementing through <code class="reqn">[0,1]</code> by <code class="reqn">dF = 0.0001</code>. This is a brute force method of course. Further, Karian and Dudewicz (2002) provide a diagrammatic representation of regions in <code class="reqn">\kappa</code> and <code class="reqn">h</code> space for suitable <code class="reqn">\alpha</code> in which the distribution is valid. The <code><a href="#topic+are.pargld.valid">are.pargld.valid</a></code> function subsequently checks against the 6 valid regions as a secondary check on Theorem 1.3.3. The regions of the distribution are defined for suitably choosen <code class="reqn">\alpha</code> by
</p>
<p style="text-align: center;"><code class="reqn">\mbox{Region 1:  } \kappa \le -1 \mbox{ and } h \ge 1 \mbox{,}</code>
</p>

<p style="text-align: center;"><code class="reqn">\mbox{Region 2:  } \kappa \ge 1 \mbox{ and } h \le -1 \mbox{,}</code>
</p>

<p style="text-align: center;"><code class="reqn">\mbox{Region 3:  } \kappa \ge 0 \mbox{ and } h \ge 0 \mbox{,}</code>
</p>

<p style="text-align: center;"><code class="reqn">\mbox{Region 4:  } \kappa \le 0 \mbox{ and } h \le 0 \mbox{,}</code>
</p>

<p style="text-align: center;"><code class="reqn">\mbox{Region 5:  } h \ge (-1/\kappa) \mbox{ and } -1 \ge \kappa \le 0 \mbox{, and}</code>
</p>

<p style="text-align: center;"><code class="reqn">\mbox{Region 6:  } h \le (-1/\kappa) \mbox{ and } h \ge -1 \mbox{ and } \kappa \ge 1 \mbox{.}</code>
</p>



<h3>Value</h3>

<table>
<tr><td><code>TRUE</code></td>
<td>
<p>If the parameters are <code>gld</code> consistent.</p>
</td></tr>
<tr><td><code>FALSE</code></td>
<td>
<p>If the parameters are not <code>gld</code> consistent.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>This function calls <code><a href="#topic+is.gld">is.gld</a></code> to verify consistency between the distribution parameter object and the intent of the user.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Asquith, W.H., 2007, L-moments and TL-moments of the generalized lambda distribution: Computational Statistics and Data Analysis, v. 51, no. 9, pp. 4484&ndash;4496.
</p>
<p>Karian, Z.A., and Dudewicz, E.J., 2000, Fitting statistical distributions&mdash;The generalized lambda distribution and generalized bootstrap methods: CRC Press, Boca Raton, FL, 438 p.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+is.gld">is.gld</a></code>, <code><a href="#topic+pargld">pargld</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
para &lt;- vec2par(c(123,34,4,3),type='gld')
if(are.pargld.valid(para)) Q &lt;- quagld(0.5,para)

# The following is an example of inconsistent L-moments for fitting but
# prior to lmomco version 2.1.2 and untrapped error was occurring.
lmr &lt;- lmoms(c(33, 37, 41, 54, 78, 91, 100, 120, 124))
para &lt;- pargld(lmr); are.pargld.valid(para)
## End(Not run)
</code></pre>

<hr>
<h2 id='are.parglo.valid'>Are the Distribution Parameters Consistent with the Generalized Logistic Distribution</h2><span id='topic+are.parglo.valid'></span>

<h3>Description</h3>

<p>Is the distribution parameter object consistent with the corresponding distribution?  The distribution functions  (<code><a href="#topic+cdfglo">cdfglo</a></code>, <code><a href="#topic+pdfglo">pdfglo</a></code>, <code><a href="#topic+quaglo">quaglo</a></code>, and
<code><a href="#topic+lmomglo">lmomglo</a></code>) require consistent parameters to return the cumulative
probability (nonexceedance), density, quantile, and L-moments of the distribution,
respectively.  These functions internally use the <code><a href="#topic+are.parglo.valid">are.parglo.valid</a></code>
function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>are.parglo.valid(para, nowarn=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="are.parglo.valid_+3A_para">para</code></td>
<td>
<p>A distribution parameter list returned by <code><a href="#topic+parglo">parglo</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
<tr><td><code id="are.parglo.valid_+3A_nowarn">nowarn</code></td>
<td>
<p>A logical switch on warning suppression. If <code>TRUE</code> then <code>options(warn=-1)</code> is made and restored on return. This switch is to permit calls in which warnings are not desired as the user knows how to handle the returned value&mdash;say in an optimization algorithm.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>TRUE</code></td>
<td>
<p>If the parameters are <code>glo</code> consistent.</p>
</td></tr>
<tr><td><code>FALSE</code></td>
<td>
<p>If the parameters are not <code>glo</code> consistent.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>This function calls <code><a href="#topic+is.glo">is.glo</a></code> to verify consistency between
the distribution parameter object and the intent of the user.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Hosking, J.R.M., 1996, FORTRAN routines for use with the method of L-moments:
Version 3, IBM Research Report RC20525, T.J. Watson Research Center,
Yorktown Heights, New York.
</p>
<p>Hosking, J.R.M., and Wallis, J.R., 1997, Regional frequency analysis&mdash;An
approach based on L-moments: Cambridge University Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+is.glo">is.glo</a></code>, <code><a href="#topic+parglo">parglo</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>para &lt;- parglo(lmoms(c(123,34,4,654,37,78)))
if(are.parglo.valid(para)) Q &lt;- quaglo(0.5,para)
</code></pre>

<hr>
<h2 id='are.pargno.valid'>Are the Distribution Parameters Consistent with the Generalized Normal Distribution</h2><span id='topic+are.pargno.valid'></span>

<h3>Description</h3>

<p>Is the distribution parameter object consistent with the corresponding distribution?  The distribution functions  (<code><a href="#topic+cdfgno">cdfgno</a></code>, <code><a href="#topic+pdfgno">pdfgno</a></code>, <code><a href="#topic+quagno">quagno</a></code>, and
<code><a href="#topic+lmomgno">lmomgno</a></code>) require consistent parameters to return the cumulative
probability (nonexceedance), density, quantile, and L-moments of the distribution,
respectively.  These functions internally use the <code><a href="#topic+are.pargno.valid">are.pargno.valid</a></code>
function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>are.pargno.valid(para, nowarn=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="are.pargno.valid_+3A_para">para</code></td>
<td>
<p>A distribution parameter list returned by <code><a href="#topic+pargno">pargno</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
<tr><td><code id="are.pargno.valid_+3A_nowarn">nowarn</code></td>
<td>
<p>A logical switch on warning suppression. If <code>TRUE</code> then <code>options(warn=-1)</code> is made and restored on return. This switch is to permit calls in which warnings are not desired as the user knows how to handle the returned value&mdash;say in an optimization algorithm.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>TRUE</code></td>
<td>
<p>If the parameters are <code>gno</code> consistent.</p>
</td></tr>
<tr><td><code>FALSE</code></td>
<td>
<p>If the parameters are not <code>gno</code> consistent.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>This function calls <code><a href="#topic+is.gno">is.gno</a></code> to verify consistency between
the distribution parameter object and the intent of the user.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Hosking, J.R.M., 1996, FORTRAN routines for use with the method of L-moments:
Version 3, IBM Research Report RC20525, T.J. Watson Research Center,
Yorktown Heights, New York.
</p>
<p>Hosking, J.R.M., and Wallis, J.R., 1997, Regional frequency analysis&mdash;An
approach based on L-moments: Cambridge University Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+is.gno">is.gno</a></code>, <code><a href="#topic+pargno">pargno</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>para &lt;- pargno(lmoms(c(123,34,4,654,37,78)))
if(are.pargno.valid(para)) Q &lt;- quagno(0.5,para)
</code></pre>

<hr>
<h2 id='are.pargov.valid'>Are the Distribution Parameters Consistent with the Govindarajulu Distribution</h2><span id='topic+are.pargov.valid'></span>

<h3>Description</h3>

<p>Is the distribution parameter object consistent with the corresponding distribution?  The distribution functions  (<code><a href="#topic+cdfgov">cdfgov</a></code>, <code><a href="#topic+pdfgov">pdfgov</a></code>, <code><a href="#topic+quagov">quagov</a></code>, and
<code><a href="#topic+lmomgov">lmomgov</a></code>) require consistent parameters to return the cumulative
probability (nonexceedance), density, quantile, and L-moments of the distribution,
respectively.  These functions internally use the <code><a href="#topic+are.pargov.valid">are.pargov.valid</a></code>
function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>are.pargov.valid(para, nowarn=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="are.pargov.valid_+3A_para">para</code></td>
<td>
<p>A distribution parameter list returned by <code><a href="#topic+pargov">pargov</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
<tr><td><code id="are.pargov.valid_+3A_nowarn">nowarn</code></td>
<td>
<p>A logical switch on warning suppression. If <code>TRUE</code> then <code>options(warn=-1)</code> is made and restored on return. This switch is to permit calls in which warnings are not desired as the user knows how to handle the returned value&mdash;say in an optimization algorithm.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>TRUE</code></td>
<td>
<p>If the parameters are <code>gov</code> consistent.</p>
</td></tr>
<tr><td><code>FALSE</code></td>
<td>
<p>If the parameters are not <code>gov</code> consistent.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>This function calls <code><a href="#topic+is.gov">is.gov</a></code> to verify consistency between
the distribution parameter object and the intent of the user.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Gilchrist, W.G., 2000, Statistical modelling with quantile functions: Chapman and Hall/CRC, Boca Raton.
</p>
<p>Nair, N.U., Sankaran, P.G., and Balakrishnan, N., 2013, Quantile-based reliability analysis: Springer, New York.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+is.gov">is.gov</a></code>, <code><a href="#topic+pargov">pargov</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>para &lt;- pargov(lmoms(c(123,34,4,654,37,78)))
if(are.pargov.valid(para)) Q &lt;- quagov(0.5,para)
</code></pre>

<hr>
<h2 id='are.pargpa.valid'>Are the Distribution Parameters Consistent with the Generalized Pareto Distribution</h2><span id='topic+are.pargpa.valid'></span>

<h3>Description</h3>

<p>Is the distribution parameter object consistent with the corresponding distribution?  The distribution functions  (<code><a href="#topic+cdfgpa">cdfgpa</a></code>, <code><a href="#topic+pdfgpa">pdfgpa</a></code>, <code><a href="#topic+quagpa">quagpa</a></code>, and
<code><a href="#topic+lmomgpa">lmomgpa</a></code>) require consistent parameters to return the cumulative
probability (nonexceedance), density, quantile, and L-moments of the distribution,
respectively.  These functions internally use the <code><a href="#topic+are.pargpa.valid">are.pargpa.valid</a></code>
function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>are.pargpa.valid(para, nowarn=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="are.pargpa.valid_+3A_para">para</code></td>
<td>
<p>A distribution parameter list returned by <code><a href="#topic+pargpa">pargpa</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
<tr><td><code id="are.pargpa.valid_+3A_nowarn">nowarn</code></td>
<td>
<p>A logical switch on warning suppression. If <code>TRUE</code> then <code>options(warn=-1)</code> is made and restored on return. This switch is to permit calls in which warnings are not desired as the user knows how to handle the returned value&mdash;say in an optimization algorithm.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>TRUE</code></td>
<td>
<p>If the parameters are <code>gpa</code> consistent.</p>
</td></tr>
<tr><td><code>FALSE</code></td>
<td>
<p>If the parameters are not <code>gpa</code> consistent.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>This function calls <code><a href="#topic+is.gpa">is.gpa</a></code> to verify consistency between
the distribution parameter object and the intent of the user.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Hosking, J.R.M., 1996, FORTRAN routines for use with the method of L-moments:
Version 3, IBM Research Report RC20525, T.J. Watson Research Center,
Yorktown Heights, New York.
</p>
<p>Hosking, J.R.M., and Wallis, J.R., 1997, Regional frequency analysis&mdash;An
approach based on L-moments: Cambridge University Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+is.gpa">is.gpa</a></code>, <code><a href="#topic+pargpa">pargpa</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>para &lt;- pargpa(lmoms(c(123,34,4,654,37,78)))
if(are.pargpa.valid(para)) Q &lt;- quagpa(0.5,para)
</code></pre>

<hr>
<h2 id='are.pargum.valid'>Are the Distribution Parameters Consistent with the Gumbel Distribution</h2><span id='topic+are.pargum.valid'></span>

<h3>Description</h3>

<p>Is the distribution parameter object consistent with the corresponding distribution?  The distribution functions  (<code><a href="#topic+cdfgum">cdfgum</a></code>, <code><a href="#topic+pdfgum">pdfgum</a></code>, <code><a href="#topic+quagum">quagum</a></code>, and
<code><a href="#topic+lmomgum">lmomgum</a></code>) require consistent parameters to return the cumulative
probability (nonexceedance), density, quantile, and L-moments of the distribution,
respectively.  These functions internally use the <code><a href="#topic+are.pargum.valid">are.pargum.valid</a></code>
function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>are.pargum.valid(para, nowarn=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="are.pargum.valid_+3A_para">para</code></td>
<td>
<p>A distribution parameter list returned by <code><a href="#topic+pargum">pargum</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
<tr><td><code id="are.pargum.valid_+3A_nowarn">nowarn</code></td>
<td>
<p>A logical switch on warning suppression. If <code>TRUE</code> then <code>options(warn=-1)</code> is made and restored on return. This switch is to permit calls in which warnings are not desired as the user knows how to handle the returned value&mdash;say in an optimization algorithm.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>TRUE</code></td>
<td>
<p>If the parameters are <code>gum</code> consistent.</p>
</td></tr>
<tr><td><code>FALSE</code></td>
<td>
<p>If the parameters are not <code>gum</code> consistent.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>This function calls <code><a href="#topic+is.gum">is.gum</a></code> to verify consistency between
the distribution parameter object and the intent of the user.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Hosking, J.R.M., 1996, FORTRAN routines for use with the method of L-moments:
Version 3, IBM Research Report RC20525, T.J. Watson Research Center,
Yorktown Heights, New York.
</p>
<p>Hosking, J.R.M., and Wallis, J.R., 1997, Regional frequency analysis&mdash;An
approach based on L-moments: Cambridge University Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+is.gum">is.gum</a></code>, <code><a href="#topic+pargum">pargum</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>para &lt;- pargum(lmoms(c(123,34,4,654,37,78)))
if(are.pargum.valid(para)) Q &lt;- quagum(0.5,para)
</code></pre>

<hr>
<h2 id='are.parkap.valid'>Are the Distribution Parameters Consistent with the Kappa Distribution</h2><span id='topic+are.parkap.valid'></span>

<h3>Description</h3>

<p>Is the distribution parameter object consistent with the corresponding distribution?  The distribution functions  (<code><a href="#topic+cdfkap">cdfkap</a></code>, <code><a href="#topic+pdfkap">pdfkap</a></code>, <code><a href="#topic+quakap">quakap</a></code>, and
<code><a href="#topic+lmomkap">lmomkap</a></code>) require consistent parameters to return the cumulative
probability (nonexceedance), density, quantile, and L-moments of the distribution,
respectively.  These functions internally use the <code><a href="#topic+are.parkap.valid">are.parkap.valid</a></code>
function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>are.parkap.valid(para, nowarn=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="are.parkap.valid_+3A_para">para</code></td>
<td>
<p>A distribution parameter list returned by <code><a href="#topic+parkap">parkap</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
<tr><td><code id="are.parkap.valid_+3A_nowarn">nowarn</code></td>
<td>
<p>A logical switch on warning suppression. If <code>TRUE</code> then <code>options(warn=-1)</code> is made and restored on return. This switch is to permit calls in which warnings are not desired as the user knows how to handle the returned value&mdash;say in an optimization algorithm.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>TRUE</code></td>
<td>
<p>If the parameters are <code>kap</code> consistent.</p>
</td></tr>
<tr><td><code>FALSE</code></td>
<td>
<p>If the parameters are not <code>kap</code> consistent.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>This function calls <code><a href="#topic+is.kap">is.kap</a></code> to verify consistency between
the distribution parameter object and the intent of the user.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Hosking, J.R.M., 1994, The four-parameter kappa distribution: IBM Journal of Reserach and Development, v. 38, no. 3, pp. 251&ndash;258.
</p>
<p>Hosking, J.R.M., and Wallis, J.R., 1997, Regional frequency analysis&mdash;An approach based on L-moments: Cambridge University Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+is.kap">is.kap</a></code>, <code><a href="#topic+parkap">parkap</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>para &lt;- parkap(lmoms(c(123,34,4,654,37,78)))
if(are.parkap.valid(para)) Q &lt;- quakap(0.5,para)
</code></pre>

<hr>
<h2 id='are.parkmu.valid'>Are the Distribution Parameters Consistent with the Kappa-Mu Distribution</h2><span id='topic+are.parkmu.valid'></span>

<h3>Description</h3>

<p>Is the distribution parameter object consistent with the corresponding distribution?  The distribution functions  (<code><a href="#topic+pdfkmu">pdfkmu</a></code>, <code><a href="#topic+cdfkmu">cdfkmu</a></code>, <code><a href="#topic+quakmu">quakmu</a></code>, and <code><a href="#topic+lmomkmu">lmomkmu</a></code>) require consistent parameters to return the cumulative probability (nonexceedance), density, quantile, and L-moments of the distribution, respectively.  These functions internally use the <code><a href="#topic+are.parkmu.valid">are.parkmu.valid</a></code> function. The documentation for <code><a href="#topic+pdfkmu">pdfkmu</a></code> provides the conditions for valid parameters.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>are.parkmu.valid(para, nowarn=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="are.parkmu.valid_+3A_para">para</code></td>
<td>
<p>A distribution parameter list returned by <code><a href="#topic+parkmu">parkmu</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
<tr><td><code id="are.parkmu.valid_+3A_nowarn">nowarn</code></td>
<td>
<p>A logical switch on warning suppression. If <code>TRUE</code> then <code>options(warn=-1)</code> is made and restored on return. This switch is to permit calls in which warnings are not desired as the user knows how to handle the returned value&mdash;say in an optimization algorithm.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>TRUE</code></td>
<td>
<p>If the parameters are <code>kmu</code> consistent.</p>
</td></tr>
<tr><td><code>FALSE</code></td>
<td>
<p>If the parameters are not <code>kmu</code> consistent.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>This function calls <code><a href="#topic+is.kmu">is.kmu</a></code> to verify consistency between
the distribution parameter object and the intent of the user.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>See Also</h3>

<p><code><a href="#topic+is.kmu">is.kmu</a></code>, <code><a href="#topic+parkmu">parkmu</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>para &lt;- vec2par(c(0.5, 1.5), type="kmu")
if(are.parkmu.valid(para)) Q &lt;- quakmu(0.5,para)
</code></pre>

<hr>
<h2 id='are.parkur.valid'>Are the Distribution Parameters Consistent with the Kumaraswamy Distribution</h2><span id='topic+are.parkur.valid'></span>

<h3>Description</h3>

<p>Is the distribution parameter object consistent with the corresponding distribution?  The distribution functions  (<code><a href="#topic+cdfkur">cdfkur</a></code>, <code><a href="#topic+pdfkur">pdfkur</a></code>, <code>quakur</code>, and
<code><a href="#topic+lmomkur">lmomkur</a></code>) require consistent parameters to return the cumulative
probability (nonexceedance), density, quantile, and L-moments of the distribution,
respectively.  These functions internally use the <code><a href="#topic+are.parkur.valid">are.parkur.valid</a></code>
function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>are.parkur.valid(para, nowarn=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="are.parkur.valid_+3A_para">para</code></td>
<td>
<p>A distribution parameter list returned by <code><a href="#topic+parkur">parkur</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
<tr><td><code id="are.parkur.valid_+3A_nowarn">nowarn</code></td>
<td>
<p>A logical switch on warning suppression. If <code>TRUE</code> then <code>options(warn=-1)</code> is made and restored on return. This switch is to permit calls in which warnings are not desired as the user knows how to handle the returned value&mdash;say in an optimization algorithm.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>TRUE</code></td>
<td>
<p>If the parameters are <code>kur</code> consistent.</p>
</td></tr>
<tr><td><code>FALSE</code></td>
<td>
<p>If the parameters are not <code>kur</code> consistent.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>This function calls <code><a href="#topic+is.kur">is.kur</a></code> to verify consistency between
the distribution parameter object and the intent of the user.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Jones, M.C., 2009, Kumaraswamy's distribution&mdash;A beta-type distribution with
some tractability advantages: Statistical Methodology, v. 6, pp. 70&ndash;81.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+is.kur">is.kur</a></code>, <code><a href="#topic+parkur">parkur</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>para &lt;- parkur(lmoms(c(0.25, 0.4, 0.6, 0.65, 0.67, 0.9)))
if(are.parkur.valid(para)) Q &lt;- quakur(0.5,para)
</code></pre>

<hr>
<h2 id='are.parlap.valid'>Are the Distribution Parameters Consistent with the Laplace Distribution</h2><span id='topic+are.parlap.valid'></span>

<h3>Description</h3>

<p>Is the distribution parameter object consistent with the corresponding distribution?  The distribution functions  (<code><a href="#topic+cdflap">cdflap</a></code>, <code><a href="#topic+pdflap">pdflap</a></code>, <code><a href="#topic+qualap">qualap</a></code>, and <code><a href="#topic+lmomlap">lmomlap</a></code>) require consistent parameters to return the cumulative probability (nonexceedance), density, quantile, and L-moments of the distribution, respectively.  These functions internally use the <code><a href="#topic+are.parlap.valid">are.parlap.valid</a></code> function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>are.parlap.valid(para, nowarn=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="are.parlap.valid_+3A_para">para</code></td>
<td>
<p>A distribution parameter list returned by <code><a href="#topic+parlap">parlap</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
<tr><td><code id="are.parlap.valid_+3A_nowarn">nowarn</code></td>
<td>
<p>A logical switch on warning suppression. If <code>TRUE</code> then <code>options(warn=-1)</code> is made and restored on return. This switch is to permit calls in which warnings are not desired as the user knows how to handle the returned value&mdash;say in an optimization algorithm.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>TRUE</code></td>
<td>
<p>If the parameters are <code>lap</code> consistent.</p>
</td></tr>
<tr><td><code>FALSE</code></td>
<td>
<p>If the parameters are not <code>lap</code> consistent.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>This function calls <code><a href="#topic+is.lap">is.lap</a></code> to verify consistency between
the distribution parameter object and the intent of the user.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Hosking, J.R.M., 1986, The theory of probability weighted moments: IBM Research Report RC12210, T.J. Watson Research Center, Yorktown Heights, New York.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+is.lap">is.lap</a></code>, <code><a href="#topic+parlap">parlap</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>para &lt;- parlap(lmoms(c(123,34,4,654,37,78)))
if(are.parlap.valid(para)) Q &lt;- qualap(0.5,para)
</code></pre>

<hr>
<h2 id='are.parlmrq.valid'>Are the Distribution Parameters Consistent with the Linear Mean Residual Quantile Function Distribution</h2><span id='topic+are.parlmrq.valid'></span>

<h3>Description</h3>

<p>Is the distribution parameter object consistent with the corresponding distribution?  The distribution functions (<code><a href="#topic+cdflmrq">cdflmrq</a></code>, <code><a href="#topic+pdflmrq">pdflmrq</a></code>, <code><a href="#topic+qualmrq">qualmrq</a></code>, and <code><a href="#topic+lmomlmrq">lmomlmrq</a></code>) require consistent parameters to return the cumulative probability (nonexceedance), density, quantile, and L-moments of the distribution, respectively.  These functions internally use the <code><a href="#topic+are.parlmrq.valid">are.parlmrq.valid</a></code> function. The constraints on the parameters are listed under <code><a href="#topic+qualmrq">qualmrq</a></code>. The documentation for <code><a href="#topic+qualmrq">qualmrq</a></code> provides the conditions for valid parameters.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>are.parlmrq.valid(para, nowarn=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="are.parlmrq.valid_+3A_para">para</code></td>
<td>
<p>A distribution parameter list returned by <code><a href="#topic+parlmrq">parlmrq</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
<tr><td><code id="are.parlmrq.valid_+3A_nowarn">nowarn</code></td>
<td>
<p>A logical switch on warning suppression. If <code>TRUE</code> then <code>options(warn=-1)</code> is made and restored on return. This switch is to permit calls in which warnings are not desired as the user knows how to handle the returned value&mdash;say in an optimization algorithm.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>TRUE</code></td>
<td>
<p>If the parameters are <code>lmrq</code> consistent.</p>
</td></tr>
<tr><td><code>FALSE</code></td>
<td>
<p>If the parameters are not <code>lmrq</code> consistent.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>This function calls <code><a href="#topic+is.lmrq">is.lmrq</a></code> to verify consistency between the distribution parameter object and the intent of the user.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Midhu, N.N., Sankaran, P.G., and Nair, N.U., 2013, A class of distributions with linear mean residual quantile function and it's generalizations: Statistical Methodology, v. 15, pp. 1&ndash;24.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+is.lmrq">is.lmrq</a></code>, <code><a href="#topic+parlmrq">parlmrq</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>para &lt;- parlmrq(lmoms(c(3, 0.05, 1.6, 1.37, 0.57, 0.36, 2.2)))
if(are.parlmrq.valid(para)) Q &lt;- qualmrq(0.5,para)
</code></pre>

<hr>
<h2 id='are.parln3.valid'>Are the Distribution Parameters Consistent with the 3-Parameter Log-Normal Distribution</h2><span id='topic+are.parln3.valid'></span>

<h3>Description</h3>

<p>Is the distribution parameter object consistent with the corresponding distribution?  The distribution functions  (<code><a href="#topic+cdfln3">cdfln3</a></code>, <code><a href="#topic+pdfln3">pdfln3</a></code>, <code><a href="#topic+qualn3">qualn3</a></code>, and <code><a href="#topic+lmomln3">lmomln3</a></code>) require consistent parameters to return the cumulative probability (nonexceedance), density, quantile, and L-moments of the distribution, respectively.  These functions internally use the <code><a href="#topic+are.parln3.valid">are.parln3.valid</a></code> function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>are.parln3.valid(para, nowarn=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="are.parln3.valid_+3A_para">para</code></td>
<td>
<p>A distribution parameter list returned by <code><a href="#topic+parln3">parln3</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
<tr><td><code id="are.parln3.valid_+3A_nowarn">nowarn</code></td>
<td>
<p>A logical switch on warning suppression. If <code>TRUE</code> then <code>options(warn=-1)</code> is made and restored on return. This switch is to permit calls in which warnings are not desired as the user knows how to handle the returned value&mdash;say in an optimization algorithm.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>TRUE</code></td>
<td>
<p>If the parameters are <code>ln3</code> consistent.</p>
</td></tr>
<tr><td><code>FALSE</code></td>
<td>
<p>If the parameters are not <code>ln3</code> consistent.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>This function calls <code><a href="#topic+is.ln3">is.ln3</a></code> to verify consistency between
the distribution parameter object and the intent of the user.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Asquith, W.H., 2011, Distributional analysis with L-moment statistics using the R environment for statistical computing: Createspace Independent Publishing Platform, ISBN 978&ndash;146350841&ndash;8.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+is.ln3">is.ln3</a></code>, <code><a href="#topic+parln3">parln3</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>para &lt;- parln3(lmoms(c(123,34,4,654,37,78)))
if(are.parln3.valid(para)) Q &lt;- qualn3(0.5,para)
</code></pre>

<hr>
<h2 id='are.parnor.valid'>Are the Distribution Parameters Consistent with the Normal Distribution</h2><span id='topic+are.parnor.valid'></span>

<h3>Description</h3>

<p>Is the distribution parameter object consistent with the corresponding distribution?  The distribution functions  (<code><a href="#topic+cdfnor">cdfnor</a></code>, <code><a href="#topic+pdfnor">pdfnor</a></code>, <code><a href="#topic+quanor">quanor</a></code>, and
<code><a href="#topic+lmomnor">lmomnor</a></code>) require consistent parameters to return the cumulative
probability (nonexceedance), density, quantile, and L-moments of the distribution,
respectively.  These functions internally use the <code><a href="#topic+are.parnor.valid">are.parnor.valid</a></code>
function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>are.parnor.valid(para, nowarn=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="are.parnor.valid_+3A_para">para</code></td>
<td>
<p>A distribution parameter list returned by <code><a href="#topic+parnor">parnor</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
<tr><td><code id="are.parnor.valid_+3A_nowarn">nowarn</code></td>
<td>
<p>A logical switch on warning suppression. If <code>TRUE</code> then <code>options(warn=-1)</code> is made and restored on return. This switch is to permit calls in which warnings are not desired as the user knows how to handle the returned value&mdash;say in an optimization algorithm.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>TRUE</code></td>
<td>
<p>If the parameters are <code>nor</code> consistent.</p>
</td></tr>
<tr><td><code>FALSE</code></td>
<td>
<p>If the parameters are not <code>nor</code> consistent.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>This function calls <code><a href="#topic+is.nor">is.nor</a></code> to verify consistency between
the distribution parameter object and the intent of the user.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Hosking, J.R.M., 1996, FORTRAN routines for use with the method of L-moments:
Version 3, IBM Research Report RC20525, T.J. Watson Research Center,
Yorktown Heights, New York.
</p>
<p>Hosking, J.R.M., and Wallis, J.R., 1997, Regional frequency analysis&mdash;An
approach based on L-moments: Cambridge University Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+is.nor">is.nor</a></code>, <code><a href="#topic+parnor">parnor</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>para &lt;- parnor(lmoms(c(123,34,4,654,37,78)))
if(are.parnor.valid(para)) Q &lt;- quanor(0.5,para)
</code></pre>

<hr>
<h2 id='are.parpdq3.valid'>Are the Distribution Parameters Consistent with the Polynomial Density-Quantile#</h2><span id='topic+are.parpdq3.valid'></span>

<h3>Description</h3>

<p>Is the distribution parameter object consistent with the corresponding distribution?  The distribution functions  (<code><a href="#topic+cdfpdq3">cdfpdq3</a></code>, <code><a href="#topic+pdfpdq3">pdfpdq3</a></code>, <code><a href="#topic+quapdq3">quapdq3</a></code>, and
<code><a href="#topic+lmompdq3">lmompdq3</a></code>) require consistent parameters to return the cumulative
probability (nonexceedance), density, quantile, and L-moments of the distribution,
respectively.  These functions internally use the <code><a href="#topic+are.parpdq3.valid">are.parpdq3.valid</a></code>
function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>are.parpdq3.valid(para, nowarn=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="are.parpdq3.valid_+3A_para">para</code></td>
<td>
<p>A distribution parameter list returned by <code><a href="#topic+parpdq3">parpdq3</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
<tr><td><code id="are.parpdq3.valid_+3A_nowarn">nowarn</code></td>
<td>
<p>A logical switch on warning suppression. If <code>TRUE</code> then <code>options(warn=-1)</code> is made and restored on return. This switch is to permit calls in which warnings are not desired as the user knows how to handle the returned value&mdash;say in an optimization algorithm.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>TRUE</code></td>
<td>
<p>If the parameters are <code>pdq3</code> consistent.</p>
</td></tr>
<tr><td><code>FALSE</code></td>
<td>
<p>If the parameters are not <code>pdq3</code> consistent.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>This function calls <code><a href="#topic+is.pdq3">is.pdq3</a></code> to verify consistency between
the distribution parameter object and the intent of the user.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>See Also</h3>

<p><code><a href="#topic+is.pdq3">is.pdq3</a></code>, <code><a href="#topic+parpdq3">parpdq3</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>para &lt;- parpdq3(lmoms(c(46, 70, 59, 36, 71, 48, 46, 63, 35, 52)))
if(are.parpdq3.valid(para)) Q &lt;- quapdq3(0.5, para)
</code></pre>

<hr>
<h2 id='are.parpdq4.valid'>Are the Distribution Parameters Consistent with the Polynomial Density-Quantile4</h2><span id='topic+are.parpdq4.valid'></span>

<h3>Description</h3>

<p>Is the distribution parameter object consistent with the corresponding distribution?  The distribution functions  (<code><a href="#topic+cdfpdq4">cdfpdq4</a></code>, <code><a href="#topic+pdfpdq4">pdfpdq4</a></code>, <code><a href="#topic+quapdq4">quapdq4</a></code>, and
<code><a href="#topic+lmompdq4">lmompdq4</a></code>) require consistent parameters to return the cumulative
probability (nonexceedance), density, quantile, and L-moments of the distribution,
respectively.  These functions internally use the <code><a href="#topic+are.parpdq4.valid">are.parpdq4.valid</a></code>
function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>are.parpdq4.valid(para, nowarn=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="are.parpdq4.valid_+3A_para">para</code></td>
<td>
<p>A distribution parameter list returned by <code><a href="#topic+parpdq4">parpdq4</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
<tr><td><code id="are.parpdq4.valid_+3A_nowarn">nowarn</code></td>
<td>
<p>A logical switch on warning suppression. If <code>TRUE</code> then <code>options(warn=-1)</code> is made and restored on return. This switch is to permit calls in which warnings are not desired as the user knows how to handle the returned value&mdash;say in an optimization algorithm.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>TRUE</code></td>
<td>
<p>If the parameters are <code>pdq4</code> consistent.</p>
</td></tr>
<tr><td><code>FALSE</code></td>
<td>
<p>If the parameters are not <code>pdq4</code> consistent.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>This function calls <code><a href="#topic+is.pdq4">is.pdq4</a></code> to verify consistency between
the distribution parameter object and the intent of the user.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>See Also</h3>

<p><code><a href="#topic+is.pdq4">is.pdq4</a></code>, <code><a href="#topic+parpdq4">parpdq4</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>para &lt;- parpdq4(lmoms(c(46, 70, 59, 36, 71, 48, 46, 63, 35, 52)))
if(are.parpdq4.valid(para)) Q &lt;- quapdq4(0.5, para)
</code></pre>

<hr>
<h2 id='are.parpe3.valid'>Are the Distribution Parameters Consistent with the Pearson Type III Distribution</h2><span id='topic+are.parpe3.valid'></span>

<h3>Description</h3>

<p>Is the distribution parameter object consistent with the corresponding distribution?  The distribution functions  (<code><a href="#topic+cdfpe3">cdfpe3</a></code>, <code><a href="#topic+pdfpe3">pdfpe3</a></code>, <code><a href="#topic+quape3">quape3</a></code>, and
<code><a href="#topic+lmompe3">lmompe3</a></code>) require consistent parameters to return the cumulative
probability (nonexceedance), density, quantile, and L-moments of the distribution,
respectively.  These functions internally use the <code><a href="#topic+are.parpe3.valid">are.parpe3.valid</a></code>
function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>are.parpe3.valid(para, nowarn=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="are.parpe3.valid_+3A_para">para</code></td>
<td>
<p>A distribution parameter list returned by <code><a href="#topic+parpe3">parpe3</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
<tr><td><code id="are.parpe3.valid_+3A_nowarn">nowarn</code></td>
<td>
<p>A logical switch on warning suppression. If <code>TRUE</code> then <code>options(warn=-1)</code> is made and restored on return. This switch is to permit calls in which warnings are not desired as the user knows how to handle the returned value&mdash;say in an optimization algorithm.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>TRUE</code></td>
<td>
<p>If the parameters are <code>pe3</code> consistent.</p>
</td></tr>
<tr><td><code>FALSE</code></td>
<td>
<p>If the parameters are not <code>pe3</code> consistent.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>This function calls <code><a href="#topic+is.pe3">is.pe3</a></code> to verify consistency between
the distribution parameter object and the intent of the user.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Hosking, J.R.M., 1996, FORTRAN routines for use with the method of L-moments:
Version 3, IBM Research Report RC20525, T.J. Watson Research Center,
Yorktown Heights, New York.
</p>
<p>Hosking, J.R.M., and Wallis, J.R., 1997, Regional frequency analysis&mdash;An
approach based on L-moments: Cambridge University Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+is.pe3">is.pe3</a></code>, <code><a href="#topic+parpe3">parpe3</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>para &lt;- parpe3(lmoms(c(123,34,4,654,37,78)))
if(are.parpe3.valid(para)) Q &lt;- quape3(0.5,para)
</code></pre>

<hr>
<h2 id='are.parray.valid'>Are the Distribution Parameters Consistent with the Rayleigh Distribution</h2><span id='topic+are.parray.valid'></span>

<h3>Description</h3>

<p>Is the distribution parameter object consistent with the corresponding distribution?  The distribution functions  (<code><a href="#topic+cdfray">cdfray</a></code>, <code><a href="#topic+pdfray">pdfray</a></code>, <code><a href="#topic+quaray">quaray</a></code>, and
<code><a href="#topic+lmomray">lmomray</a></code>) require consistent parameters to return the cumulative
probability (nonexceedance), density, quantile, and L-moments of the distribution,
respectively.  These functions internally use the <code><a href="#topic+are.parray.valid">are.parray.valid</a></code>
function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>are.parray.valid(para, nowarn=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="are.parray.valid_+3A_para">para</code></td>
<td>
<p>A distribution parameter list returned by <code><a href="#topic+parray">parray</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
<tr><td><code id="are.parray.valid_+3A_nowarn">nowarn</code></td>
<td>
<p>A logical switch on warning suppression. If <code>TRUE</code> then <code>options(warn=-1)</code> is made and restored on return. This switch is to permit calls in which warnings are not desired as the user knows how to handle the returned value&mdash;say in an optimization algorithm.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>TRUE</code></td>
<td>
<p>If the parameters are <code>ray</code> consistent.</p>
</td></tr>
<tr><td><code>FALSE</code></td>
<td>
<p>If the parameters are not <code>ray</code> consistent.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>This function calls <code><a href="#topic+is.ray">is.ray</a></code> to verify consistency between
the distribution parameter object and the intent of the user.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Hosking, J.R.M., 1986, The theory of probability weighted moments:
Research Report RC12210, IBM Research Division, Yorkton Heights, N.Y.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+is.ray">is.ray</a></code>, <code><a href="#topic+parray">parray</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>para &lt;- parray(lmoms(c(123,34,4,654,37,78)))
if(are.parray.valid(para)) Q &lt;- quaray(0.5,para)
</code></pre>

<hr>
<h2 id='are.parrevgum.valid'>Are the Distribution Parameters Consistent with the Reverse Gumbel Distribution</h2><span id='topic+are.parrevgum.valid'></span>

<h3>Description</h3>

<p>Is the distribution parameter object consistent with the corresponding distribution?  The distribution functions  (<code><a href="#topic+cdfrevgum">cdfrevgum</a></code>, <code><a href="#topic+pdfrevgum">pdfrevgum</a></code>, <code><a href="#topic+quarevgum">quarevgum</a></code>, and
<code><a href="#topic+lmomrevgum">lmomrevgum</a></code>) require consistent parameters to return the cumulative
probability (nonexceedance), density, quantile, and L-moments of the distribution,
respectively.  These functions internally use the <code><a href="#topic+are.parrevgum.valid">are.parrevgum.valid</a></code>
function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>are.parrevgum.valid(para, nowarn=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="are.parrevgum.valid_+3A_para">para</code></td>
<td>
<p>A distribution parameter list returned by <code><a href="#topic+parrevgum">parrevgum</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
<tr><td><code id="are.parrevgum.valid_+3A_nowarn">nowarn</code></td>
<td>
<p>A logical switch on warning suppression. If <code>TRUE</code> then <code>options(warn=-1)</code> is made and restored on return. This switch is to permit calls in which warnings are not desired as the user knows how to handle the returned value&mdash;say in an optimization algorithm.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>TRUE</code></td>
<td>
<p>If the parameters are <code>revgum</code> consistent.</p>
</td></tr>
<tr><td><code>FALSE</code></td>
<td>
<p>If the parameters are not <code>revgum</code> consistent.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>This function calls <code><a href="#topic+is.revgum">is.revgum</a></code> to verify consistency between
the distribution parameter object and the intent of the user.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Hosking, J.R.M., 1995, The use of L-moments in the analysis of censored data,
in Recent Advances in Life-Testing and Reliability, edited by N. Balakrishnan,
chapter 29, CRC Press, Boca Raton, Fla., pp. 546&ndash;560.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+is.revgum">is.revgum</a></code>, <code><a href="#topic+parrevgum">parrevgum</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>para &lt;- vec2par(c(.9252, .1636, .7),type='revgum')
if(are.parrevgum.valid(para)) Q &lt;- quarevgum(0.5,para)
</code></pre>

<hr>
<h2 id='are.parrice.valid'>Are the Distribution Parameters Consistent with the Rice Distribution</h2><span id='topic+are.parrice.valid'></span>

<h3>Description</h3>

<p>Is the distribution parameter object consistent with the corresponding distribution?  The distribution functions  (<code><a href="#topic+cdfrice">cdfrice</a></code>, <code><a href="#topic+pdfrice">pdfrice</a></code>, <code><a href="#topic+quarice">quarice</a></code>, and
<code><a href="#topic+lmomrice">lmomrice</a></code>) require consistent parameters to return the cumulative
probability (nonexceedance), density, quantile, and L-moments of the distribution,
respectively.  These functions internally use the <code><a href="#topic+are.parrice.valid">are.parrice.valid</a></code>
function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>are.parrice.valid(para, nowarn=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="are.parrice.valid_+3A_para">para</code></td>
<td>
<p>A distribution parameter list returned by <code><a href="#topic+parrice">parrice</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
<tr><td><code id="are.parrice.valid_+3A_nowarn">nowarn</code></td>
<td>
<p>A logical switch on warning suppression. If <code>TRUE</code> then <code>options(warn=-1)</code> is made and restored on return. This switch is to permit calls in which warnings are not desired as the user knows how to handle the returned value&mdash;say in an optimization algorithm.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>TRUE</code></td>
<td>
<p>If the parameters are <code>rice</code> consistent.</p>
</td></tr>
<tr><td><code>FALSE</code></td>
<td>
<p>If the parameters are not <code>rice</code> consistent.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>This function calls <code><a href="#topic+is.rice">is.rice</a></code> to verify consistency between the distribution parameter object and the intent of the user.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Asquith, W.H., 2011, Distributional analysis with L-moment statistics using the R environment for statistical computing: Createspace Independent Publishing Platform, ISBN 978&ndash;146350841&ndash;8.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+is.rice">is.rice</a></code>, <code><a href="#topic+parrice">parrice</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>#para &lt;- parrice(lmoms(c(123,34,4,654,37,78)))
#if(are.parrice.valid(para)) Q &lt;- quarice(0.5,para)
</code></pre>

<hr>
<h2 id='are.parsla.valid'>Are the Distribution Parameters Consistent with the Slash Distribution</h2><span id='topic+are.parsla.valid'></span>

<h3>Description</h3>

<p>Is the distribution parameter object consistent with the corresponding distribution?  The distribution functions  (<code><a href="#topic+cdfsla">cdfsla</a></code>, <code><a href="#topic+pdfsla">pdfsla</a></code>, <code><a href="#topic+quasla">quasla</a></code>, and <code><a href="#topic+lmomsla">lmomsla</a></code>) require consistent parameters to return the cumulative probability (nonexceedance), density, quantile, and L-moments of the distribution, respectively. These functions internally use the <code><a href="#topic+are.parsla.valid">are.parsla.valid</a></code> function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>are.parsla.valid(para, nowarn=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="are.parsla.valid_+3A_para">para</code></td>
<td>
<p>A distribution parameter list returned by <code><a href="#topic+parsla">parsla</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
<tr><td><code id="are.parsla.valid_+3A_nowarn">nowarn</code></td>
<td>
<p>A logical switch on warning suppression. If <code>TRUE</code> then <code>options(warn=-1)</code> is made and restored on return. This switch is to permit calls in which warnings are not desired as the user knows how to handle the returned value&mdash;say in an optimization algorithm.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>TRUE</code></td>
<td>
<p>If the parameters are <code>sla</code> consistent.</p>
</td></tr>
<tr><td><code>FALSE</code></td>
<td>
<p>If the parameters are not <code>sla</code> consistent.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>This function calls <code><a href="#topic+is.sla">is.sla</a></code> to verify consistency between
the distribution parameter object and the intent of the user.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Rogers, W.H., and Tukey, J.W., 1972, Understanding some long-tailed symmetrical distributions: Statistica Neerlandica, v. 26, no. 3, pp. 211&ndash;226.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+is.sla">is.sla</a></code>, <code><a href="#topic+parsla">parsla</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>para &lt;- vec2par(c(12,1.2),type='sla')
if(are.parsla.valid(para)) Q &lt;- quasla(0.5,para)
</code></pre>

<hr>
<h2 id='are.parsmd.valid'>Are the Distribution Parameters Consistent with the Singh&ndash;Maddala Distribution</h2><span id='topic+are.parsmd.valid'></span>

<h3>Description</h3>

<p>Is the distribution parameter object consistent with the corresponding distribution?  The distribution functions (<code><a href="#topic+cdfsmd">cdfsmd</a></code>, <code><a href="#topic+pdfsmd">pdfsmd</a></code>, <code><a href="#topic+quasmd">quasmd</a></code>, and <code><a href="#topic+lmomsmd">lmomsmd</a></code>) require consistent parameters to return the cumulative probability (nonexceedance), density, quantile, and L-moments of the distribution, respectively. These functions internally use the <code>are.parsmd.valid</code> function. The parameter constraints are simple <code class="reqn">a &gt; 0</code> (scale), <code class="reqn">b &gt; 0</code> (shape), and <code class="reqn">q &gt; 0</code> (shape).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>are.parsmd.valid(para, nowarn=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="are.parsmd.valid_+3A_para">para</code></td>
<td>
<p>A distribution parameter list returned by <code><a href="#topic+parsmd">parsmd</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
<tr><td><code id="are.parsmd.valid_+3A_nowarn">nowarn</code></td>
<td>
<p>A logical switch on warning suppression. If <code>TRUE</code> then <code>options(warn=-1)</code> is made and restored on return. This switch is to permit calls in which warnings are not desired as the user knows how to handle the returned value&mdash;say in an optimization algorithm.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>TRUE</code></td>
<td>
<p>If the parameters are <code>smd</code> consistent.</p>
</td></tr>
<tr><td><code>FALSE</code></td>
<td>
<p>If the parameters are not <code>smd</code> consistent.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>This function calls <code><a href="#topic+is.smd">is.smd</a></code> to verify consistency between
the distribution parameter object and the intent of the user.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Shahzad, M.N., and Zahid, A., 2013, Parameter estimation of Singh Maddala distribution by moments: International Journal of Advanced Statistics and Probability, v. 1, no. 3, pp. 121&ndash;131, <a href="https://doi.org/10.14419/ijasp.v1i3.1206">doi:10.14419/ijasp.v1i3.1206</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+is.smd">is.smd</a></code>, <code><a href="#topic+parsmd">parsmd</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>#para &lt;- parsmd(lmoms(c(123, 34, 4, 654, 37, 78)))
#if(are.parsmd.valid(para)) Q &lt;- quasmd(0.5, para)
</code></pre>

<hr>
<h2 id='are.parst3.valid'>Are the Distribution Parameters Consistent with the 3-Parameter Student t Distribution</h2><span id='topic+are.parst3.valid'></span>

<h3>Description</h3>

<p>Is the distribution parameter object consistent with the corresponding distribution?  The distribution functions  (<code><a href="#topic+cdfst3">cdfst3</a></code>, <code><a href="#topic+pdfst3">pdfst3</a></code>, <code><a href="#topic+quast3">quast3</a></code>, and <code><a href="#topic+lmomst3">lmomst3</a></code>) require consistent parameters to return the cumulative probability (nonexceedance), density, quantile, and L-moments of the distribution, respectively. These functions internally use the <code><a href="#topic+are.parst3.valid">are.parst3.valid</a></code> function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>are.parst3.valid(para, nowarn=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="are.parst3.valid_+3A_para">para</code></td>
<td>
<p>A distribution parameter list returned by <code><a href="#topic+parst3">parst3</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
<tr><td><code id="are.parst3.valid_+3A_nowarn">nowarn</code></td>
<td>
<p>A logical switch on warning suppression. If <code>TRUE</code> then <code>options(warn=-1)</code> is made and restored on return. This switch is to permit calls in which warnings are not desired as the user knows how to handle the returned value&mdash;say in an optimization algorithm.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>TRUE</code></td>
<td>
<p>If the parameters are <code>st3</code> consistent.</p>
</td></tr>
<tr><td><code>FALSE</code></td>
<td>
<p>If the parameters are not <code>st3</code> consistent.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>This function calls <code><a href="#topic+is.st3">is.st3</a></code> to verify consistency between the distribution parameter object and the intent of the user.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Asquith, W.H., 2011, Distributional analysis with L-moment statistics using the R environment for statistical computing: Createspace Independent Publishing Platform, ISBN 978&ndash;146350841&ndash;8.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+is.st3">is.st3</a></code>, <code><a href="#topic+parst3">parst3</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>para &lt;- parst3(lmoms(c(90,134,100,114,177,378)))
if(are.parst3.valid(para)) Q &lt;- quast3(0.5,para)
</code></pre>

<hr>
<h2 id='are.partexp.valid'>Are the Distribution Parameters Consistent with the Truncated Exponential Distribution</h2><span id='topic+are.partexp.valid'></span>

<h3>Description</h3>

<p>Is the distribution parameter object consistent with the corresponding distribution?  The distribution functions  (<code><a href="#topic+cdftexp">cdftexp</a></code>, <code><a href="#topic+pdftexp">pdftexp</a></code>, <code><a href="#topic+quatexp">quatexp</a></code>, and <code><a href="#topic+lmomtexp">lmomtexp</a></code>) require consistent parameters to return the cumulative probability (nonexceedance), density, quantile, and L-moments of the distribution, respectively. These functions internally use the <code><a href="#topic+are.partexp.valid">are.partexp.valid</a></code> function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>are.partexp.valid(para, nowarn=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="are.partexp.valid_+3A_para">para</code></td>
<td>
<p>A distribution parameter list returned by <code><a href="#topic+parexp">parexp</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
<tr><td><code id="are.partexp.valid_+3A_nowarn">nowarn</code></td>
<td>
<p>A logical switch on warning suppression. If <code>TRUE</code> then <code>options(warn=-1)</code> is made and restored on return. This switch is to permit calls in which warnings are not desired as the user knows how to handle the returned value&mdash;say in an optimization algorithm.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>TRUE</code></td>
<td>
<p>If the parameters are <code>texp</code> consistent.</p>
</td></tr>
<tr><td><code>FALSE</code></td>
<td>
<p>If the parameters are not <code>texp</code> consistent.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>This function calls <code><a href="#topic+is.texp">is.texp</a></code> to verify consistency between the distribution parameter object and the intent of the user.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Vogel, R.M., Hosking, J.R.M., Elphick, C.S., Roberts, D.L., and Reed, J.M., 2008, Goodness of fit of probability distributions for sightings as species approach extinction: Bulletin of Mathematical Biology, DOI 10.1007/s11538-008-9377-3, 19 p.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+is.texp">is.texp</a></code>, <code><a href="#topic+partexp">partexp</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>para &lt;- partexp(lmoms(c(90,134,100,114,177,378)))
if(are.partexp.valid(para)) Q &lt;- quatexp(0.5,para)
</code></pre>

<hr>
<h2 id='are.partri.valid'>Are the Distribution Parameters Consistent with the Asymmetric Triangular Distribution</h2><span id='topic+are.partri.valid'></span>

<h3>Description</h3>

<p>Is the distribution parameter object consistent with the corresponding distribution?  The distribution functions  (<code><a href="#topic+cdftri">cdftri</a></code>, <code><a href="#topic+pdftri">pdftri</a></code>, <code><a href="#topic+quatri">quatri</a></code>, and
<code><a href="#topic+lmomtri">lmomtri</a></code>) require consistent parameters to return the cumulative
probability (nonexceedance), density, quantile, and L-moments of the distribution,
respectively.  These functions internally use the <code><a href="#topic+are.partri.valid">are.partri.valid</a></code>
function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>are.partri.valid(para, nowarn=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="are.partri.valid_+3A_para">para</code></td>
<td>
<p>A distribution parameter list returned by <code><a href="#topic+partri">partri</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
<tr><td><code id="are.partri.valid_+3A_nowarn">nowarn</code></td>
<td>
<p>A logical switch on warning suppression. If <code>TRUE</code> then <code>options(warn=-1)</code> is made and restored on return. This switch is to permit calls in which warnings are not desired as the user knows how to handle the returned value&mdash;say in an optimization algorithm.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>TRUE</code></td>
<td>
<p>If the parameters are <code>tri</code> consistent.</p>
</td></tr>
<tr><td><code>FALSE</code></td>
<td>
<p>If the parameters are not <code>tri</code> consistent.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>This function calls <code><a href="#topic+is.tri">is.tri</a></code> to verify consistency between
the distribution parameter object and the intent of the user.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>See Also</h3>

<p><code><a href="#topic+is.tri">is.tri</a></code>, <code><a href="#topic+partri">partri</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>para &lt;- partri(lmoms(c(46, 70, 59, 36, 71, 48, 46, 63, 35, 52)))
if(are.partri.valid(para)) Q &lt;- quatri(0.5,para)
</code></pre>

<hr>
<h2 id='are.parwak.valid'>Are the Distribution Parameters Consistent with the Wakeby Distribution</h2><span id='topic+are.parwak.valid'></span>

<h3>Description</h3>

<p>Is the distribution parameter object consistent with the corresponding distribution?  The distribution functions  (<code><a href="#topic+cdfwak">cdfwak</a></code>, <code><a href="#topic+pdfwak">pdfwak</a></code>, <code><a href="#topic+quawak">quawak</a></code>, and
<code><a href="#topic+lmomwak">lmomwak</a></code>) require consistent parameters to return the cumulative
probability (nonexceedance), density, quantile, and L-moments of the distribution,
respectively.  These functions internally use the <code><a href="#topic+are.parwak.valid">are.parwak.valid</a></code>
function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>are.parwak.valid(para, nowarn=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="are.parwak.valid_+3A_para">para</code></td>
<td>
<p>A distribution parameter list returned by <code><a href="#topic+parwak">parwak</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
<tr><td><code id="are.parwak.valid_+3A_nowarn">nowarn</code></td>
<td>
<p>A logical switch on warning suppression. If <code>TRUE</code> then <code>options(warn=-1)</code> is made and restored on return. This switch is to permit calls in which warnings are not desired as the user knows how to handle the returned value&mdash;say in an optimization algorithm.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>TRUE</code></td>
<td>
<p>If the parameters are <code>wak</code> consistent.</p>
</td></tr>
<tr><td><code>FALSE</code></td>
<td>
<p>If the parameters are not <code>wak</code> consistent.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>This function calls <code><a href="#topic+is.wak">is.wak</a></code> to verify consistency between
the distribution parameter object and the intent of the user.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Hosking, J.R.M., 1996, FORTRAN routines for use with the method of L-moments:
Version 3, IBM Research Report RC20525, T.J. Watson Research Center,
Yorktown Heights, New York.
</p>
<p>Hosking, J.R.M., and Wallis, J.R., 1997, Regional frequency analysis&mdash;An
approach based on L-moments: Cambridge University Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+is.wak">is.wak</a></code>, <code><a href="#topic+parwak">parwak</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>para &lt;- parwak(lmoms(c(123,34,4,654,37,78)))
if(are.parwak.valid(para)) Q &lt;- quawak(0.5,para)
</code></pre>

<hr>
<h2 id='are.parwei.valid'>Are the Distribution Parameters Consistent with the Weibull Distribution</h2><span id='topic+are.parwei.valid'></span>

<h3>Description</h3>

<p>Is the distribution parameter object consistent with the corresponding distribution?  The distribution functions (<code><a href="#topic+cdfwei">cdfwei</a></code>, <code><a href="#topic+pdfwei">pdfwei</a></code>, <code><a href="#topic+quawei">quawei</a></code>, and <code><a href="#topic+lmomwei">lmomwei</a></code>) require consistent parameters to return the cumulative probability (nonexceedance), density, quantile, and L-moments of the distribution, respectively.  These functions internally use the <code><a href="#topic+are.parwei.valid">are.parwei.valid</a></code> function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>are.parwei.valid(para, nowarn=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="are.parwei.valid_+3A_para">para</code></td>
<td>
<p>A distribution parameter list returned by <code><a href="#topic+parwei">parwei</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
<tr><td><code id="are.parwei.valid_+3A_nowarn">nowarn</code></td>
<td>
<p>A logical switch on warning suppression. If <code>TRUE</code> then <code>options(warn=-1)</code> is made and restored on return. This switch is to permit calls in which warnings are not desired as the user knows how to handle the returned value&mdash;say in an optimization algorithm.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>TRUE</code></td>
<td>
<p>If the parameters are <code>wei</code> consistent.</p>
</td></tr>
<tr><td><code>FALSE</code></td>
<td>
<p>If the parameters are not <code>wei</code> consistent.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>This function calls <code><a href="#topic+is.wei">is.wei</a></code> to verify consistency between
the distribution parameter object and the intent of the user.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Hosking, J.R.M., and Wallis, J.R., 1997, Regional frequency analysis&mdash;An
approach based on L-moments: Cambridge University Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+is.wei">is.wei</a></code>, <code><a href="#topic+parwei">parwei</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>para &lt;- parwei(lmoms(c(123,34,4,654,37,78)))
if(are.parwei.valid(para)) Q &lt;- quawei(0.5,para)
</code></pre>

<hr>
<h2 id='BEhypergeo'>Barnes Extended Hypergeometric Function</h2><span id='topic+BEhypergeo'></span><span id='topic+BarnesExtendedHypergeometric'></span>

<h3>Description</h3>

<p>This function computes the Barnes Extended Hypergeometric function, which in <span class="pkg">lmomco</span> is useful in applications involving expectations of order statistics for the Generalized Exponential Poisson (GEP) distribution (see <code><a href="#topic+lmomgep">lmomgep</a></code>). The function is
</p>
<p style="text-align: center;"><code class="reqn">
F_{p,q}(\bm{\mathrm{n}},\bm{\mathrm{d}}; \lambda) = \sum_{k=0}^\infty \frac{\lambda^k}{\Gamma(k+1)}\frac{\Pi_{i=1}^{p} \Gamma(n_i + k)\Gamma^{-1}{(n_i)}}{\Pi_{i=1}^{q} \Gamma(d_i + k)\Gamma^{-1}{(d_i)}}\mbox{,} 
</code>
</p>

<p>where <code class="reqn">\bm{\mathrm{n}} = [n_1, n_2, \ldots, n_p]</code> for <code class="reqn">p</code> operands and <code class="reqn">\bm{\mathrm{d}} = [d_1, d_2, \ldots, d_q]</code> for <code class="reqn">q</code> operands, and <code class="reqn">\lambda &gt; 0</code> is a parameter.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BEhypergeo(p,q, N,D, lambda, eps=1E-12, maxit=500)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="BEhypergeo_+3A_p">p</code></td>
<td>
<p>An integer value.</p>
</td></tr>
<tr><td><code id="BEhypergeo_+3A_q">q</code></td>
<td>
<p>An integer value.</p>
</td></tr>
<tr><td><code id="BEhypergeo_+3A_n">N</code></td>
<td>
<p>A scalar or vector associated with the <code class="reqn">p</code> summation (see Details).</p>
</td></tr>
<tr><td><code id="BEhypergeo_+3A_d">D</code></td>
<td>
<p>A scalar or vector associated with the <code class="reqn">q</code> summation (see Details).</p>
</td></tr>
<tr><td><code id="BEhypergeo_+3A_lambda">lambda</code></td>
<td>
<p>A real value <code class="reqn">\lambda &gt; 0</code>.</p>
</td></tr>
<tr><td><code id="BEhypergeo_+3A_eps">eps</code></td>
<td>
<p>The relative convergence error on which to break an infinite loop.</p>
</td></tr>
<tr><td><code id="BEhypergeo_+3A_maxit">maxit</code></td>
<td>
<p>The maximum number of interations before a mandatory break on the loop, and a warning will be issued.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For the GEP both <code class="reqn">\bm{\mathrm{n}}</code> and <code class="reqn">\bm{\mathrm{d}}</code> are vectors of the same value, such as <code class="reqn">\bm{\mathrm{n}} = [1, \ldots, 1]</code> and <code class="reqn">\bm{\mathrm{d}} = [2, \ldots, 2]</code>. This implementation is built around this need by the GEP and if the length of either vector is not equal to the operand then the first value of the vector is repeated the operand times. For example for <code class="reqn">\bm{\mathrm{n}}</code>, if <code>n = 1</code>, then <code>n = rep(n[1], length(p))</code> and so on for <code class="reqn">\bm{\mathrm{d}}</code>. Given that <code>n</code> and <code>d</code> are vectorized for the GEP, then a shorthand is used for the GEP mathematics shown herein:
</p>
<p style="text-align: center;"><code class="reqn">F^{12}_{22}(h(j+1)) \equiv F_{2,2}([1,\ldots,1], [2,\ldots,2]; h(j+1))\mbox{,}</code>
</p>
 
<p>for the <code class="reqn">h</code> parameter of the distribution.
</p>
<p>Lastly, for <span class="pkg">lmomco</span> and the GEP the arguments only involve <code class="reqn">p = q = 2</code> and <code class="reqn">N = 1</code>, <code class="reqn">D = 2</code>, so the function is uniquely a function of the <code class="reqn">h</code> parameter of the distribution:
</p>
<pre>
  H &lt;- 10^seq(-10,10, by=0.01)
  F22 &lt;- sapply(1:length(H), function(i) BEhypergeo(2,2,1,1, H[i])$value
  plot(log10(H), log10(F22), type="l")
</pre>
<p>For this example, the solution increasingly wobbles towards large <code class="reqn">h</code>, which is further explored by
</p>
<pre>
  plot(log10(H[1:(length(H)-1)]), diff(log10(F22)), type="l", xlim=c(0,7))
  plot(log10(H[H &gt; 75 &amp; H &lt; 140]), c(NA,diff(log10(F22[H &gt; 75 &amp; H &lt; 140]))),
       type="b"); lines(c(2.11,2.11), c(0,10))
</pre>
<p>It can be provisionally concluded that the solution to <code class="reqn">F^{12}_{22}(\cdot)</code> begins to be suddenly questionable because of numerical difficulties beyond <code class="reqn">\log(h) = 2.11</code>. Therefore, it is given that <code class="reqn">h &lt; 128</code> might be an operational numerical upper limit.
</p>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> is returned.
</p>
<table>
<tr><td><code>value</code></td>
<td>
<p>The value for the function.</p>
</td></tr>
<tr><td><code>its</code></td>
<td>
<p>The number of iterations <code class="reqn">j</code>.</p>
</td></tr>
<tr><td><code>error</code></td>
<td>
<p>The error of convergence.</p>
</td></tr> 
</table>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Kus, C., 2007, A new lifetime distribution: Computational Statistics and Data Analysis, v. 51, pp. 4497&ndash;4509.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lmomgep">lmomgep</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>BEhypergeo(2,2,1,2,1.5)
</code></pre>

<hr>
<h2 id='bfrlmomco'>Bonferroni Curve of the Distributions</h2><span id='topic+bfrlmomco'></span>

<h3>Description</h3>

<p>This function computes the Bonferroni Curve for quantile function <code class="reqn">x(F)</code> (<code><a href="#topic+par2qua">par2qua</a></code>, <code><a href="#topic+qlmomco">qlmomco</a></code>). The function is defined by Nair et al. (2013, p. 179) as
</p>
<p style="text-align: center;"><code class="reqn">B(u) = \frac{1}{\mu u}\int_0^u x(p)\; \mathrm{d}p\mbox{,}</code>
</p>

<p>where <code class="reqn">B(u)</code> is Bonferroni curve for quantile function <code class="reqn">x(F)</code> and <code class="reqn">\mu</code> is the conditional mean for quantile <code class="reqn">u=0</code> (<code><a href="#topic+cmlmomco">cmlmomco</a></code>). The Bonferroni curve is related to the Lorenz curve (<code class="reqn">L(u)</code>, <code><a href="#topic+lrzlmomco">lrzlmomco</a></code>) by
</p>
<p style="text-align: center;"><code class="reqn">B(u) = \frac{L(u)}{u}\mbox{.}</code>
</p>



<h3>Usage</h3>

<pre><code class='language-R'>bfrlmomco(f, para)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bfrlmomco_+3A_f">f</code></td>
<td>
<p>Nonexceedance probability (<code class="reqn">0 \le F \le 1</code>).</p>
</td></tr>
<tr><td><code id="bfrlmomco_+3A_para">para</code></td>
<td>
<p>The parameters from <code><a href="#topic+lmom2par">lmom2par</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Bonferroni curve value for <code class="reqn">F</code>.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Nair, N.U., Sankaran, P.G., and Balakrishnan, N., 2013, Quantile-based reliability analysis: Springer, New York.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+qlmomco">qlmomco</a></code>, <code><a href="#topic+lrzlmomco">lrzlmomco</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># It is easiest to think about residual life as starting at the origin, units in days.
A &lt;- vec2par(c(0.0, 2649, 2.11), type="gov") # so set lower bounds = 0.0

"afunc" &lt;- function(u) { return(par2qua(u,A,paracheck=FALSE)) }
f &lt;- 0.65 # Both computations report: 0.5517342
Bu1 &lt;- 1/(cmlmomco(f=0,A)*f) * integrate(afunc, 0, f)$value
Bu2 &lt;- bfrlmomco(f, A)
</code></pre>

<hr>
<h2 id='Bpwm2ApwmRC'>Conversion between B- and A-Type Probability-Weighted Moments for Right-Tail Censoring of an Appropriate Distribution</h2><span id='topic+Bpwm2ApwmRC'></span>

<h3>Description</h3>

<p>This function converts &ldquo;B&rdquo;-type probability-weighted moments (PWMs, <code class="reqn">\beta^B_r</code>) to the &ldquo;A&rdquo;-type <code class="reqn">\beta^A_r</code>. The <code class="reqn">\beta^A_r</code> are the ordinary PWMs for the <code class="reqn">m</code> left noncensored or observed values. The <code class="reqn">\beta^B_r</code> are more complex and use the <code class="reqn">m</code> observed values and the <code class="reqn">m-n</code> right-tailed censored values for which the censoring threshold is known. The &ldquo;A&rdquo;- and &ldquo;B&rdquo;-type PWMs are described in the documentation for <code><a href="#topic+pwmRC">pwmRC</a></code>.
</p>
<p>This function uses the defined relation between to two PWM types when the <code class="reqn">\beta^B_r</code> are known along with the parameters (<code>para</code>) of a right-tail censored distribution inclusive of the censoring fraction <code class="reqn">\zeta=m/n</code>. The value <code class="reqn">\zeta</code> is the right-tail censor fraction or the probability <code class="reqn">\mathrm{Pr}\lbrace \rbrace</code> that <code class="reqn">x</code> is less than the quantile at <code class="reqn">\zeta</code> nonexceedance probability (<code class="reqn">\mathrm{Pr}\lbrace x &lt; X(\zeta) \rbrace</code>). The relation is
</p>
<p style="text-align: center;"><code class="reqn">\beta^A_{r-1} = \frac{r\beta^B_{r-1} - (1-\zeta^r)X(\zeta)}{r\zeta^r} \mbox{,}</code>
</p>

<p>where <code class="reqn">1 \le r \le n</code> and <code class="reqn">n</code> is the number of moments, and <code class="reqn">X(\zeta)</code> is the value of the quantile function at nonexceedance probability <code class="reqn">\zeta</code>. Finally, the <code>RC</code> in the function name is to denote <code>R</code>ight-tail <code>C</code>ensoring.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Bpwm2ApwmRC(Bpwm,para)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Bpwm2ApwmRC_+3A_bpwm">Bpwm</code></td>
<td>
<p>A vector of B-type PWMs: <code class="reqn">\beta^B_r</code>.</p>
</td></tr>
<tr><td><code id="Bpwm2ApwmRC_+3A_para">para</code></td>
<td>
<p>The parameters of the distribution from a function such as <code>pargpaRC</code> in which the <code class="reqn">\beta^B_r</code> are contained in a <code>list</code> element titled <code>betas</code> and the right-tail censoring fraction <code class="reqn">\zeta</code> is contained in an element titled <code>zeta</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> is returned.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Hosking, J.R.M., 1995, The use of L-moments in the analysis of censored data,
in Recent Advances in Life-Testing and Reliability, edited by N. Balakrishnan,
chapter 29, CRC Press, Boca Raton, Fla., pp. 546&ndash;560.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Apwm2BpwmRC">Apwm2BpwmRC</a></code> and <code><a href="#topic+pwmRC">pwmRC</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'># Data listed in Hosking (1995, table 29.2, p. 551)
H &lt;- c(3,4,5,6,6,7,8,8,9,9,9,10,10,11,11,11,13,13,13,13,13,
             17,19,19,25,29,33,42,42,51.9999,52,52,52)
      # 51.9999 was really 52, a real (noncensored) data point.
z &lt;-  pwmRC(H,52)
# The B-type PMWs are used for the parameter estimation of the
# Reverse Gumbel distribution. The parameter estimator requires
# conversion of the PWMs to L-moments by pwm2lmom().
para &lt;- parrevgum(pwm2lmom(z$Bbetas),z$zeta) # parameter object
Abetas &lt;- Bpwm2ApwmRC(z$Bbetas,para)
Bbetas &lt;- Apwm2BpwmRC(Abetas$betas,para)
# Assertion that both of the vectors of B-type PWMs should be the same.
str(Bbetas)   # B-type PWMs of the distribution
str(z$Bbetas) # B-type PWMs of the original data
</code></pre>

<hr>
<h2 id='canyonprecip'>Annual Maximum Precipitation Data for Canyon, Texas</h2><span id='topic+canyonprecip'></span>

<h3>Description</h3>

<p>Annual maximum precipitation data for Canyon, Texas
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(canyonprecip)
</code></pre>


<h3>Format</h3>

<p>An <span class="rlang"><b>R</b></span> <code>data.frame</code> with
</p>

<dl>
<dt>YEAR</dt><dd><p>The calendar year of the annual maxima.</p>
</dd>
<dt>DEPTH</dt><dd><p>The depth of 7-day annual maxima rainfall in inches.</p>
</dd>
</dl>



<h3>References</h3>

<p>Asquith, W.H., 1998, Depth-duration frequency of precipitation for
Texas: U.S. Geological Survey Water-Resources Investigations Report
98&ndash;4044, 107 p.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(canyonprecip)
summary(canyonprecip)
</code></pre>

<hr>
<h2 id='cdf2lmom'>Compute an L-moment from Cumulative Distribution Function </h2><span id='topic+cdf2lmom'></span>

<h3>Description</h3>

<p>Compute a single L-moment from a cumulative distribution function. This function is sequentially called by <code><a href="#topic+cdf2lmoms">cdf2lmoms</a></code> to mimic the output structure for multiple L-moments seen by other L-moment computation functions in <span class="pkg">lmomco</span>.
</p>
<p>For <code class="reqn">r = 1</code>, the quantile function is actually used for numerical integration to compute the mean. The expression for the mean is
</p>
<p style="text-align: center;"><code class="reqn">
\lambda_1 = \int_0^1 x(F)\; \mathrm{d} F\mbox{,}
</code>
</p>

<p>for quantile function <code class="reqn">x(F)</code> and nonexceedance probability <code class="reqn">F</code>. For <code class="reqn">r \ge 2</code>, the L-moments can be computed from the cumulative distribution function <code class="reqn">F(x)</code> by
</p>
<p style="text-align: center;"><code class="reqn">
\lambda_r = \frac{1}{r}\sum_{j=0}^{r-2} (-1)^j {r-2 \choose j}{r \choose j+1} \int_{-\infty}^{\infty} \! [F(x)]^{r-j-1}\times [1 - F(x)]^{j+1}\; \mathrm{d}x\mbox{.}
</code>
</p>

<p>This equation is described by Asquith (2011, eq. 6.8), Hosking (1996), and Jones (2004).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cdf2lmom(r, para, fdepth=0, silent=TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cdf2lmom_+3A_r">r</code></td>
<td>
<p>The order of the L-moment.</p>
</td></tr>
<tr><td><code id="cdf2lmom_+3A_para">para</code></td>
<td>
<p>The parameters from <code><a href="#topic+lmom2par">lmom2par</a></code> or similar.</p>
</td></tr>
<tr><td><code id="cdf2lmom_+3A_fdepth">fdepth</code></td>
<td>
<p>The depth of the nonexceedance/exceedance probabilities to determine the lower and upper integration limits for the integration involving <code class="reqn">F(x)</code> through a call to the <code><a href="#topic+par2qua">par2qua</a></code> function. The default of 0 implies the quantile for <code class="reqn">F=0</code> and quantile for <code class="reqn">F=1</code> as the respective lower and upper limits.</p>
</td></tr>
<tr><td><code id="cdf2lmom_+3A_silent">silent</code></td>
<td>
<p>A logical to be passed into <code><a href="#topic+cdf2lmom">cdf2lmom</a></code> and then onto the <code>try</code> functions encompassing the <code>integrate</code> function calls.</p>
</td></tr>
<tr><td><code id="cdf2lmom_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass to <code><a href="#topic+par2qua">par2qua</a></code> and <code><a href="#topic+par2cdf">par2cdf</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The value for the requested L-moment is returned (<code class="reqn">\lambda_r</code>).
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Asquith, W.H., 2011, Distributional analysis with L-moment statistics using the R environment for statistical computing: Createspace Independent Publishing Platform, ISBN 978&ndash;146350841&ndash;8.
</p>
<p>Hosking, J.R.M., 1996, Some theoretical results concerning L-moments: Research Report RC14492, IBM Research Division, T.J. Watson Research Center, Yorktown Heights, New York.
</p>
<p>Jones, M.C., 2004, On some expressions for variance, covariance, skewness and L-moments: Journal of Statistical Planning and Inference, v. 126, pp. 97&ndash;106.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cdf2lmoms">cdf2lmoms</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>para &lt;- vec2par(c(.9,.4), type="nor")
cdf2lmom(4, para) # summarize the value
</code></pre>

<hr>
<h2 id='cdf2lmoms'>Compute L-moments from Cumulative Distribution Function </h2><span id='topic+cdf2lmoms'></span>

<h3>Description</h3>

<p>Compute the L-moments from a cumulative distribution function. For <code class="reqn">r \ge 1</code>, the L-moments can be computed by sequential calling of <code><a href="#topic+cdf2lmom">cdf2lmom</a></code>. Consult the documentation of that function for mathematical definitions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cdf2lmoms(para, nmom=6, fdepth=0, silent=TRUE, lambegr=1, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cdf2lmoms_+3A_para">para</code></td>
<td>
<p>The parameters from <code><a href="#topic+lmom2par">lmom2par</a></code> or similar.</p>
</td></tr>
<tr><td><code id="cdf2lmoms_+3A_nmom">nmom</code></td>
<td>
<p>The number of moments to compute. Default is 6.</p>
</td></tr>
<tr><td><code id="cdf2lmoms_+3A_fdepth">fdepth</code></td>
<td>
<p>The depth of the nonexceedance/exceedance probabilities to determine the lower and upper integration limits through a call to the <code><a href="#topic+par2qua">par2qua</a></code> function. The default of 0 implies the quantile for <code class="reqn">F=0</code> and quantile for <code class="reqn">F=1</code> as the respective lower and upper limits.</p>
</td></tr>
<tr><td><code id="cdf2lmoms_+3A_silent">silent</code></td>
<td>
<p>A logical to be passed into <code><a href="#topic+cdf2lmom">cdf2lmom</a></code> and then onto the  <code>try</code> functions encompassing the <code>integrate</code> function calls.</p>
</td></tr>
<tr><td><code id="cdf2lmoms_+3A_lambegr">lambegr</code></td>
<td>
<p>The <code class="reqn">r</code>th order to begin the sequence for L-moment computation. Can be used as a means to bypass a mean computation if the user has an alternative method for the mean or other central tendency characterization in which case <code>lambegr = 2</code>.</p>
</td></tr>
<tr><td><code id="cdf2lmoms_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass to <code><a href="#topic+cdf2lmom">cdf2lmom</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> is returned.
</p>
<table>
<tr><td><code>lambdas</code></td>
<td>
<p>Vector of the L-moments. First element is
<code class="reqn">\hat{\lambda}^{(0,0)}_1</code>, second element is <code class="reqn">\hat{\lambda}^{(0,0)}_2</code>, and so on.</p>
</td></tr>
<tr><td><code>ratios</code></td>
<td>
<p>Vector of the L-moment ratios. Second element is
<code class="reqn">\hat{\tau}^{(0,0)}</code>, third element is <code class="reqn">\hat{\tau}^{(0,0)}_3</code> and so on.</p>
</td></tr>
<tr><td><code>trim</code></td>
<td>
<p>Level of symmetrical trimming used in the computation, which will equal <code>NULL</code> is not support for trimming is provided by this function.</p>
</td></tr>
<tr><td><code>leftrim</code></td>
<td>
<p>Level of left-tail trimming used in the computation, which will equal <code>NULL</code> is not support for trimming is provided by this function.</p>
</td></tr>
<tr><td><code>rightrim</code></td>
<td>
<p>Level of right-tail trimming used in the computation, which will equal <code>NULL</code> is not support for trimming is provided by this function.</p>
</td></tr>
<tr><td><code>source</code></td>
<td>
<p>An attribute identifying the computational source of the L-moments: &ldquo;cdf2lmoms&rdquo;.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>See Also</h3>

<p><code><a href="#topic+cdf2lmom">cdf2lmom</a></code>, <code><a href="#topic+lmoms">lmoms</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>cdf2lmoms(vec2par(c(10,40), type="ray"))
## Not run: 
# relatively slow computation
vec2par(c(.9,.4), type="emu"); cdf2lmoms(para, nmom=4)
vec2par(c(.9,.4), type="emu"); cdf2lmoms(para, nmom=4, fdepth=0)
## End(Not run)
</code></pre>

<hr>
<h2 id='cdfaep4'>Cumulative Distribution Function of the 4-Parameter Asymmetric Exponential Power Distribution</h2><span id='topic+cdfaep4'></span>

<h3>Description</h3>

<p>This function computes the cumulative probability or nonexceedance probability of the 4-parameter Asymmetric Exponential Power distribution given parameters (<code class="reqn">\xi</code>, <code class="reqn">\alpha</code>, <code class="reqn">\kappa</code>, and <code class="reqn">h</code>) computed by <code><a href="#topic+paraep4">paraep4</a></code>. The cumulative distribution function is
</p>
<p style="text-align: center;"><code class="reqn">F(x) = \frac{\kappa^2}{(1+\kappa^2)} \; \gamma([(\xi - x)/(\alpha\kappa)]^h,\; 1/h)\mbox{,}</code>
</p>

<p>for <code class="reqn">x &lt; \xi</code> and
</p>
<p style="text-align: center;"><code class="reqn">F(x) = 1 - \frac{1}{(1+\kappa^2)} \; \gamma([\kappa(x - \xi)/\alpha]^h,\; 1/h)\mbox{,} </code>
</p>

<p>for <code class="reqn">x \ge \xi</code>, where <code class="reqn">F(x)</code> is the nonexceedance probability for quantile <code class="reqn">x</code>, <code class="reqn">\xi</code> is a location parameter, <code class="reqn">\alpha</code> is a scale parameter, <code class="reqn">\kappa</code> is a shape parameter, <code class="reqn">h</code> is another shape parameter, and <code class="reqn">\gamma(Z, s)</code> is the upper tail of the incomplete gamma function for the two arguments. The upper tail of the incomplete gamma function is <code>pgamma(Z, shape, lower.tail=FALSE)</code> in <span class="rlang"><b>R</b></span> and mathematically is
</p>
<p style="text-align: center;"><code class="reqn">\gamma(Z, a) = \int_Z^\infty y^{a-1} \exp(-y)\, \mathrm{d}y \, /\, \Gamma(a)\mbox{.}</code>
</p>

<p>If the <code class="reqn">\tau_3</code> of the distribution is zero (symmetrical), then the distribution is known as the Exponential Power.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cdfaep4(x, para, paracheck=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cdfaep4_+3A_x">x</code></td>
<td>
<p>A real value vector.</p>
</td></tr>
<tr><td><code id="cdfaep4_+3A_para">para</code></td>
<td>
<p>The parameters from <code><a href="#topic+paraep4">paraep4</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
<tr><td><code id="cdfaep4_+3A_paracheck">paracheck</code></td>
<td>
<p>A logical controlling whether the parameters and checked for validity.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Nonexceedance probability (<code class="reqn">F</code>) for <code class="reqn">x</code>.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Asquith, W.H., 2014, Parameter estimation for the 4-parameter asymmetric exponential power distribution by the method of L-moments using R: Computational Statistics and Data Analysis, v. 71, pp. 955&ndash;970.
</p>
<p>Delicado, P., and Goria, M.N., 2008, A small sample comparison of maximum likelihood,
moments and L-moments methods for the asymmetric exponential power distribution:
Computational Statistics and Data Analysis, v. 52, no. 3, pp. 1661&ndash;1673.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pdfaep4">pdfaep4</a></code>, <code><a href="#topic+quaaep4">quaaep4</a></code>, <code><a href="#topic+lmomaep4">lmomaep4</a></code>, <code><a href="#topic+paraep4">paraep4</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- -0.1
para &lt;- vec2par(c(0, 100, 0.5, 4), type="aep4")
FF &lt;- cdfaep4(-.1,para)
cat(c("F=",FF,"  and estx=",quaaep4(FF, para),"\n"))
## Not run: 
delx &lt;- .1
x &lt;- seq(-20,20, by=delx);
K &lt;- 1;
PAR &lt;- list(para=c(0,1, K, 0.5), type="aep4");
plot(x,cdfaep4(x, PAR), type="n",ylim=c(0,1), xlim=range(x),
     ylab="NONEXCEEDANCE PROBABILITY");
lines(x,cdfaep4(x,PAR), lwd=4);
lines(quaaep4(cdfaep4(x,PAR),PAR), cdfaep4(x,PAR), col=2)
PAR &lt;- list(para=c(0,1, K, 1), type="aep4");
lines(x,cdfaep4(x, PAR), lty=2, lwd=4);
lines(quaaep4(cdfaep4(x,PAR),PAR), cdfaep4(x,PAR), col=2)
PAR &lt;- list(para=c(0,1, K, 2), type="aep4");
lines(x,cdfaep4(x, PAR), lty=3, lwd=4);
lines(quaaep4(cdfaep4(x,PAR),PAR), cdfaep4(x,PAR), col=2)
PAR &lt;- list(para=c(0,1, K, 4), type="aep4");
lines(x,cdfaep4(x, PAR), lty=4, lwd=4);
lines(quaaep4(cdfaep4(x,PAR),PAR), cdfaep4(x,PAR), col=2)
## End(Not run)
</code></pre>

<hr>
<h2 id='cdfcau'>Cumulative Distribution Function of the Cauchy Distribution</h2><span id='topic+cdfcau'></span>

<h3>Description</h3>

<p>This function computes the cumulative probability or nonexceedance probability of the Cauchy distribution given parameters (<code class="reqn">\xi</code> and <code class="reqn">\alpha</code>) computed by <code><a href="#topic+parcau">parcau</a></code>.  The cumulative distribution function is
</p>
<p style="text-align: center;"><code class="reqn">F(x) = \frac{\arctan(Y)}{\pi}+0.5 \mbox{,}</code>
</p>

<p>where <code class="reqn">Y</code> is
</p>
<p style="text-align: center;"><code class="reqn">Y = \frac{x - \xi}{\alpha}\mbox{, and}</code>
</p>

<p>where <code class="reqn">F(x)</code> is the nonexceedance probability for quantile <code class="reqn">x</code>,  <code class="reqn">\xi</code> is a location parameter, and <code class="reqn">\alpha</code> is a scale parameter.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cdfcau(x, para)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cdfcau_+3A_x">x</code></td>
<td>
<p>A real value vector.</p>
</td></tr>
<tr><td><code id="cdfcau_+3A_para">para</code></td>
<td>
<p>The parameters from <code><a href="#topic+parcau">parcau</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Nonexceedance probability (<code class="reqn">F</code>) for <code class="reqn">x</code>.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Elamir, E.A.H., and Seheult, A.H., 2003, Trimmed L-moments: Computational Statistics
and Data Analysis, v. 43, pp. 299&ndash;314.
</p>
<p>Gilchrist, W.G., 2000, Statistical modeling with quantile functions:
Chapman and Hall/CRC, Boca Raton, FL.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pdfcau">pdfcau</a></code>, <code><a href="#topic+quacau">quacau</a></code>, <code><a href="#topic+lmomcau">lmomcau</a></code>, <code><a href="#topic+parcau">parcau</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  para &lt;- c(12,12)
  cdfcau(50,vec2par(para,type='cau'))
</code></pre>

<hr>
<h2 id='cdfemu'>Cumulative Distribution Function of the Eta-Mu Distribution</h2><span id='topic+cdfemu'></span>

<h3>Description</h3>

<p>This function computes the cumulative probability or nonexceedance probability of the Eta-Mu (<code class="reqn">\eta:\mu</code>) distribution given parameters (<code class="reqn">\eta</code> and <code class="reqn">\mu</code>) computed by <code><a href="#topic+parkmu">parkmu</a></code>. The cumulative distribution function is complex and numerical integration of the probability density function <code><a href="#topic+pdfemu">pdfemu</a></code> is used or the Yacoub (2007) <code class="reqn">Y_\nu(a,b)</code> integral. The cumulative distribution function in terms of this integral is
</p>
<p style="text-align: center;"><code class="reqn">
F(x) = 1- Y_\nu\biggl( \frac{H}{h},\, x\sqrt{2h\mu} \biggr)\mbox{,}
</code>
</p>

<p>where
</p>
<p style="text-align: center;"><code class="reqn">
Y_\nu(a,b) = \frac{2^{3/2 - \nu}\sqrt{\pi}(1-a^2)^\nu}{a^{\nu - 1/2} \Gamma(\nu)} \int_b^\infty x^{2\nu}\,\mathrm{exp}(-x^2)\,I_{\nu-1/2}(ax^2) \; \mathrm{d}x\mbox{,}
</code>
</p>

<p>where <code class="reqn">I_{\nu}(a)</code>  is the &ldquo;<code class="reqn">\nu</code>th-order modified Bessel function of the first kind.&rdquo;
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cdfemu(x, para, paracheck=TRUE, yacoubsintegral=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cdfemu_+3A_x">x</code></td>
<td>
<p>A real value vector.</p>
</td></tr>
<tr><td><code id="cdfemu_+3A_para">para</code></td>
<td>
<p>The parameters from <code><a href="#topic+paremu">paremu</a></code> or  <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
<tr><td><code id="cdfemu_+3A_paracheck">paracheck</code></td>
<td>
<p>A logical controlling whether the parameters and checked for validity.</p>
</td></tr>
<tr><td><code id="cdfemu_+3A_yacoubsintegral">yacoubsintegral</code></td>
<td>
<p>A logical controlling whether the integral by Yacoub (2007) is used instead of numerical integration of <code><a href="#topic+pdfemu">pdfemu</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Nonexceedance probability (<code class="reqn">F</code>) for <code class="reqn">x</code>.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Yacoub, M.D., 2007, The kappa-mu distribution and the eta-mu distribution: IEEE Antennas and Propagation Magazine, v. 49, no. 1, pp. 68&ndash;81
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pdfemu">pdfemu</a></code>, <code><a href="#topic+quaemu">quaemu</a></code>, <code><a href="#topic+lmomemu">lmomemu</a></code>, <code><a href="#topic+paremu">paremu</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>para &lt;- vec2par(c(0.5, 1.4), type="emu")
cdfemu(1.2, para, yacoubsintegral=TRUE)
cdfemu(1.2, para, yacoubsintegral=FALSE)
## Not run: 
delx &lt;- 0.01; x &lt;- seq(0,3, by=delx)
nx &lt;- 20*log10(x)
plot(c(-30,10), 10^c(-3,0), log="y", xaxs="i", yaxs="i",
     xlab="RHO", ylab="cdfemu(RHO)", type="n")
m &lt;- 0.75
mus &lt;- c(0.7425, 0.7125, 0.675, 0.6, 0.5, 0.45)
for(mu in mus) {
   eta &lt;- sqrt((m / (2*mu))^-1 - 1)
   lines(nx, cdfemu(x, vec2par(c(eta, mu), type="emu")))
}
mtext("Yacoub (2007, figure 8)")

# Now add some last boundary lines
mu &lt;- m; eta &lt;- sqrt((m / (2*mu))^-1 - 1)
lines(nx, cdfemu(x, vec2par(c(eta, mu), type="emu")),  col=8, lwd=4)
mu &lt;- m/2; eta &lt;- sqrt((m / (2*mu))^-1 - 1)
lines(nx, cdfemu(x, vec2par(c(eta, mu), type="emu")), col=4, lwd=2, lty=2)


delx &lt;- 0.01; x &lt;- seq(0,3, by=delx)
nx &lt;- 20*log10(x)
m &lt;- 0.75; col &lt;- 4; lty &lt;- 2
plot(c(-30,10), 10^c(-3,0), log="y", xaxs="i", yaxs="i",
     xlab="RHO", ylab="cdfemu(RHO)", type="n")
for(mu in c(m/2,seq(m/2+0.01,m,by=0.01), m-0.001, m)) {
   if(mu &gt; 0.67) { col &lt;- 2; lty &lt;- 1 }
   eta &lt;- sqrt((m / (2*mu))^-1 - 1)
   lines(nx, cdfemu(x, vec2par(c(eta, mu), type="emu")),
         col=col, lwd=.75, lty=lty)
}
## End(Not run)
</code></pre>

<hr>
<h2 id='cdfexp'>Cumulative Distribution Function of the Exponential Distribution</h2><span id='topic+cdfexp'></span>

<h3>Description</h3>

<p>This function computes the cumulative probability or nonexceedance probability of the Exponential distribution given parameters (<code class="reqn">\xi</code> and <code class="reqn">\alpha</code>  computed by <code><a href="#topic+parexp">parexp</a></code>. The cumulative distribution function is
</p>
<p style="text-align: center;"><code class="reqn">F(x) = 1 - \exp(Y)\mbox{,}</code>
</p>

<p>where <code class="reqn">Y</code> is
</p>
<p style="text-align: center;"><code class="reqn">\frac{-(x - \xi)}{\alpha}\mbox{,}</code>
</p>

<p>where <code class="reqn">F(x)</code> is the nonexceedance probability for the quantile <code class="reqn">x</code>, 
<code class="reqn">\xi</code> is a location parameter, and <code class="reqn">\alpha</code> is a scale parameter.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cdfexp(x, para)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cdfexp_+3A_x">x</code></td>
<td>
<p>A real value vector.</p>
</td></tr>
<tr><td><code id="cdfexp_+3A_para">para</code></td>
<td>
<p>The parameters from <code><a href="#topic+parexp">parexp</a></code> or  <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Nonexceedance probability (<code class="reqn">F</code>) for <code class="reqn">x</code>.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Hosking, J.R.M., 1990, L-moments&mdash;Analysis and estimation of
distributions using linear combinations of order statistics: Journal
of the Royal Statistical Society, Series B, v. 52, p. 105&ndash;124.
</p>
<p>Hosking, J.R.M., 1996, FORTRAN routines for use with the method of L-moments:
Version 3, IBM Research Report RC20525, T.J. Watson Research Center,
Yorktown Heights, New York.
</p>
<p>Hosking, J.R.M., and Wallis, J.R., 1997, Regional frequency analysis&mdash;An
approach based on L-moments: Cambridge University Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pdfexp">pdfexp</a></code>, <code><a href="#topic+quaexp">quaexp</a></code>, <code><a href="#topic+lmomexp">lmomexp</a></code>, <code><a href="#topic+parexp">parexp</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>  lmr &lt;- lmoms(c(123,34,4,654,37,78))
  cdfexp(50,parexp(lmr))
</code></pre>

<hr>
<h2 id='cdfgam'>Cumulative Distribution Function of the Gamma Distribution</h2><span id='topic+cdfgam'></span>

<h3>Description</h3>

<p>This function computes the cumulative probability or nonexceedance probability of the Gamma distribution given parameters (<code class="reqn">\alpha</code> and <code class="reqn">\beta</code>) computed by <code><a href="#topic+pargam">pargam</a></code>.  The cumulative distribution function has no explicit form but is expressed as an integral:
</p>
<p style="text-align: center;"><code class="reqn">F(x) = \frac{\beta^{-\alpha}}{\Gamma(\alpha)}\int_0^x t^{\alpha - 1}
\exp(-t/\beta)\; \mbox{d}t \mbox{,}</code>
</p>

<p>where <code class="reqn">F(x)</code> is the nonexceedance probability for the quantile <code class="reqn">x</code>, <code class="reqn">\alpha</code> is a shape parameter, and <code class="reqn">\beta</code> is a scale parameter.
</p>
<p>Alternatively, a three-parameter version is available following the parameterization of the Generalized Gamma distribution used in the <span class="pkg">gamlss.dist</span> package and is
</p>
<p style="text-align: center;"><code class="reqn">F(x) =\frac{\theta^\theta\, |\nu|}{\Gamma(\theta)}\int_0^x \frac{z^\theta}{x}\,\mathrm{exp}(-z\theta)\; \mbox{d}x \mbox{,}</code>
</p>

<p>where <code class="reqn">z =(x/\mu)^\nu</code>, <code class="reqn">\theta = 1/(\sigma^2\,|\nu|^2)</code> for <code class="reqn">x &gt; 0</code>, location parameter <code class="reqn">\mu &gt; 0</code>, scale parameter <code class="reqn">\sigma &gt; 0</code>, and shape parameter <code class="reqn">-\infty &lt; \nu &lt; \infty</code>. The three parameter version is automatically triggered if the length of the <code>para</code> element is three and not two.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cdfgam(x, para)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cdfgam_+3A_x">x</code></td>
<td>
<p>A real value vector.</p>
</td></tr>
<tr><td><code id="cdfgam_+3A_para">para</code></td>
<td>
<p>The parameters from <code><a href="#topic+pargam">pargam</a></code> or  <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Nonexceedance probability (<code class="reqn">F</code>) for <code class="reqn">x</code>.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Hosking, J.R.M., 1990, L-moments&mdash;Analysis and estimation of
distributions using linear combinations of order statistics: Journal
of the Royal Statistical Society, Series B, v. 52, pp. 105&ndash;124.
</p>
<p>Hosking, J.R.M., and Wallis, J.R., 1997, Regional frequency analysis&mdash;An
approach based on L-moments: Cambridge University Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pdfgam">pdfgam</a></code>, <code><a href="#topic+quagam">quagam</a></code>, <code><a href="#topic+lmomgam">lmomgam</a></code>, <code><a href="#topic+pargam">pargam</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>  lmr &lt;- lmoms(c(123,34,4,654,37,78))
  cdfgam(50,pargam(lmr))

  # A manual demonstration of a gamma parent
  G  &lt;- vec2par(c(0.6333,1.579),type='gam') # the parent
  F1 &lt;- 0.25         # nonexceedance probability
  x  &lt;- quagam(F1,G) # the lower quartile (F=0.25)
  a  &lt;- 0.6333       # gamma parameter
  b  &lt;- 1.579        # gamma parameter
  # compute the integral
  xf &lt;- function(t,A,B) { t^(A-1)*exp(-t/B) }
  Q  &lt;- integrate(xf,0,x,A=a,B=b)
  # finish the math
  F2 &lt;- Q$val*b^(-a)/gamma(a)
  # check the result
  if(abs(F1-F2) &lt; 1e-8) print("yes")

## Not run: 
# 3-p Generalized Gamma Distribution and gamlss.dist package parameterization
gg &lt;- vec2par(c(7.4, 0.2, 14), type="gam"); X &lt;- seq(0.04,9, by=.01)
GGa &lt;- gamlss.dist::pGG(X, mu=7.4, sigma=0.2, nu=14)
GGb &lt;- cdfgam(X, gg) # lets compare the two cumulative probabilities
plot( X, GGa, type="l", xlab="X", ylab="PROBABILITY", col=3, lwd=6)
lines(X, GGb, col=2, lwd=2) #
## End(Not run)

## Not run: 
# 3-p Generalized Gamma Distribution and gamlss.dist package parameterization
gg &lt;- vec2par(c(4, 1.5, -.6), type="gam"); X &lt;- seq(0,1000, by=1)
GGa &lt;- 1-gamlss.dist::pGG(X, mu=4, sigma=1.5, nu=-.6) # Note 1-... (pGG bug?)
GGb &lt;- cdfgam(X, gg) # lets compare the two cumulative probabilities
plot( X, GGa, type="l", xlab="X", ylab="PROBABILITY", col=3, lwd=6)
lines(X, GGb, col=2, lwd=2) #
## End(Not run)
</code></pre>

<hr>
<h2 id='cdfgep'>Cumulative Distribution Function of the Generalized Exponential Poisson Distribution</h2><span id='topic+cdfgep'></span>

<h3>Description</h3>

<p>This function computes the cumulative probability or nonexceedance probability of the Generalized Exponential Poisson distribution given parameters (<code class="reqn">\beta</code>, <code class="reqn">\kappa</code>, and <code class="reqn">h</code>) computed by <code><a href="#topic+pargep">pargep</a></code>. The cumulative distribution function is
</p>
<p style="text-align: center;"><code class="reqn">F(x) =  \left(\frac{1 - \exp[-h + h\exp(-\eta x)]}{1 - \exp(-h)}\right)^\kappa\mbox{,}</code>
</p>

<p>where <code class="reqn">F(x)</code> is the nonexceedance probability for quantile <code class="reqn">x &gt; 0</code>, <code class="reqn">\eta = 1/\beta</code>, <code class="reqn">\beta &gt; 0</code> is a scale parameter, <code class="reqn">\kappa &gt; 0</code> is a shape parameter, and <code class="reqn">h &gt; 0</code> is another shape parameter.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cdfgep(x, para)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cdfgep_+3A_x">x</code></td>
<td>
<p>A real value vector.</p>
</td></tr>
<tr><td><code id="cdfgep_+3A_para">para</code></td>
<td>
<p>The parameters from <code><a href="#topic+pargep">pargep</a></code> or  <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Nonexceedance probability (<code class="reqn">F</code>) for <code class="reqn">x</code>.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Barreto-Souza, W., and Cribari-Neto, F., 2009, A generalization of the exponential-Poisson distribution: Statistics and Probability, 79, pp. 2493&ndash;2500.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pdfgep">pdfgep</a></code>, <code><a href="#topic+quagep">quagep</a></code>, <code><a href="#topic+lmomgep">lmomgep</a></code>, <code><a href="#topic+pargep">pargep</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>gep &lt;- list(para=c(2, 1.5, 3), type="gep")
cdfgep(0.48,gep)
</code></pre>

<hr>
<h2 id='cdfgev'>Cumulative Distribution Function of the Generalized Extreme Value Distribution</h2><span id='topic+cdfgev'></span>

<h3>Description</h3>

<p>This function computes the cumulative probability or nonexceedance probability of the Generalized Extreme Value distribution given parameters (<code class="reqn">\xi</code>, <code class="reqn">\alpha</code>, and <code class="reqn">\kappa</code>) computed by <code><a href="#topic+pargev">pargev</a></code>. The cumulative distribution function is
</p>
<p style="text-align: center;"><code class="reqn">F(x) = \mathrm{exp}(-\mathrm{exp}(-Y)) \mbox{,}</code>
</p>

<p>where <code class="reqn">Y</code> is
</p>
<p style="text-align: center;"><code class="reqn">Y = -\kappa^{-1} \log\left(1 - \frac{\kappa(x-\xi)}{\alpha}\right)\mbox{,}</code>
</p>

<p>for <code class="reqn">\kappa \ne 0</code> and
</p>
<p style="text-align: center;"><code class="reqn">Y = (x-\xi)/\alpha\mbox{,}</code>
</p>

<p>for <code class="reqn">\kappa = 0</code>, where <code class="reqn">F(x)</code> is the nonexceedance probability for quantile <code class="reqn">x</code>, <code class="reqn">\xi</code> is a location parameter, <code class="reqn">\alpha</code> is a scale parameter, and <code class="reqn">\kappa</code> is a shape parameter. The range of <code class="reqn">x</code> is <code class="reqn">-\infty &lt; x \le \xi + \alpha/\kappa</code> if <code class="reqn">k &gt; 0</code>; <code class="reqn">\xi + \alpha/\kappa \le x &lt; \infty</code> if <code class="reqn">\kappa \le 0</code>. Note that the shape parameter <code class="reqn">\kappa</code> parameterization of the distribution herein follows that in tradition by the greater L-moment community and others use a sign reversal on <code class="reqn">\kappa</code>. (The <span class="pkg">evd</span> package is one example.)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cdfgev(x, para, paracheck=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cdfgev_+3A_x">x</code></td>
<td>
<p>A real value vector.</p>
</td></tr>
<tr><td><code id="cdfgev_+3A_para">para</code></td>
<td>
<p>The parameters from <code><a href="#topic+pargev">pargev</a></code> or  <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
<tr><td><code id="cdfgev_+3A_paracheck">paracheck</code></td>
<td>
<p>A logical switch as to whether the validity of the parameters should be checked.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Nonexceedance probability (<code class="reqn">F</code>) for <code class="reqn">x</code>.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Hosking, J.R.M., 1990, L-moments&mdash;Analysis and estimation of distributions using linear combinations of order statistics: Journal of the Royal Statistical Society, Series B, v. 52, pp. 105&ndash;124, <a href="https://doi.org/10.1111/j.2517-6161.1990.tb01775.x">doi:10.1111/j.2517-6161.1990.tb01775.x</a>.
</p>
<p>Hosking, J.R.M., 1996, FORTRAN routines for use with the method of L-moments: Version 3, IBM Research Report RC20525, T.J. Watson Research Center, Yorktown Heights, New York.
</p>
<p>Hosking, J.R.M., and Wallis, J.R., 1997, Regional frequency analysis&mdash;An approach based on L-moments: Cambridge University Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pdfgev">pdfgev</a></code>, <code><a href="#topic+quagev">quagev</a></code>, <code><a href="#topic+lmomgev">lmomgev</a></code>, <code><a href="#topic+pargev">pargev</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>  lmr &lt;- lmoms(c(123, 34, 4, 654, 37, 78))
  cdfgev(50, pargev(lmr))
</code></pre>

<hr>
<h2 id='cdfgld'>Cumulative Distribution Function of the Generalized Lambda Distribution</h2><span id='topic+cdfgld'></span>

<h3>Description</h3>

<p>This function computes the cumulative probability or nonexceedance probability of the Generalized Lambda distribution given parameters (<code class="reqn">\xi</code>, <code class="reqn">\alpha</code>, <code class="reqn">\kappa</code>, and <code class="reqn">h</code>) computed by <code><a href="#topic+pargld">pargld</a></code>. The cumulative distribution function has no explicit form and requires numerical methods. The <span class="rlang"><b>R</b></span> function <code>uniroot</code> is used to root the quantile function <code><a href="#topic+quagld">quagld</a></code> to compute the nonexceedance probability. The function returns 0 or 1 if the <code>x</code> argument is at or beyond the limits of the distribution as specified by the parameters.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cdfgld(x, para, paracheck)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cdfgld_+3A_x">x</code></td>
<td>
<p>A real value vector.</p>
</td></tr>
<tr><td><code id="cdfgld_+3A_para">para</code></td>
<td>
<p>The parameters from <code><a href="#topic+pargld">pargld</a></code> or  <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
<tr><td><code id="cdfgld_+3A_paracheck">paracheck</code></td>
<td>
<p>A logical switch as to whether the validity of the parameters should be checked. Default is <code>paracheck=TRUE</code>. This switch is made so that the root solution needed for <code><a href="#topic+cdfgld">cdfgld</a></code> exhibits an extreme speed increase because of the repeated calls to <code>quagld</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Nonexceedance probability (<code class="reqn">F</code>) for <code class="reqn">x</code>.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Asquith, W.H., 2007, L-moments and TL-moments of the generalized lambda distribution: Computational Statistics and Data Analysis, v. 51, no. 9, pp. 4484&ndash;4496.
</p>
<p>Karian, Z.A., and Dudewicz, E.J., 2000, Fitting statistical distributions&mdash;The generalized lambda distribution and generalized bootstrap methods:
CRC Press, Boca Raton, FL, 438 p.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pdfgld">pdfgld</a></code>, <code><a href="#topic+quagld">quagld</a></code>, <code><a href="#topic+lmomgld">lmomgld</a></code>, <code><a href="#topic+pargld">pargld</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
  P &lt;- vec2par(c(123,340,0.4,0.654),type='gld')
  cdfgld(300,P, paracheck=FALSE)

  par &lt;- vec2par(c(0,-7.901925e+05, 6.871662e+01, -3.749302e-01), type="gld")
  supdist(par)

## End(Not run)
</code></pre>

<hr>
<h2 id='cdfglo'>Cumulative Distribution Function of the Generalized Logistic Distribution</h2><span id='topic+cdfglo'></span>

<h3>Description</h3>

<p>This function computes the cumulative probability or nonexceedance probability of the Generalized Logistic distribution given parameters (<code class="reqn">\xi</code>, <code class="reqn">\alpha</code>, and <code class="reqn">\kappa</code>) computed by <code><a href="#topic+parglo">parglo</a></code>. The cumulative distribution function is
</p>
<p style="text-align: center;"><code class="reqn">F(x) = 1/(1+\mathrm{exp}(-Y)) \mbox{,}</code>
</p>

<p>where <code class="reqn">Y</code> is
</p>
<p style="text-align: center;"><code class="reqn">Y = -\kappa^{-1} \log\left(1 - \frac{\kappa(x-\xi)}{\alpha}\right)\mbox{,}</code>
</p>

<p>for <code class="reqn">\kappa \ne 0</code> and
</p>
<p style="text-align: center;"><code class="reqn">Y = (x-\xi)/\alpha\mbox{,}</code>
</p>

<p>for <code class="reqn">\kappa = 0</code>,  where <code class="reqn">F(x)</code> is the nonexceedance probability for quantile <code class="reqn">x</code>, <code class="reqn">\xi</code> is a location parameter, <code class="reqn">\alpha</code> is a scale parameter, and <code class="reqn">\kappa</code> is a shape parameter.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cdfglo(x, para)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cdfglo_+3A_x">x</code></td>
<td>
<p>A real value vector.</p>
</td></tr>
<tr><td><code id="cdfglo_+3A_para">para</code></td>
<td>
<p>The parameters from <code><a href="#topic+parglo">parglo</a></code> or  <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Nonexceedance probability (<code class="reqn">F</code>) for <code class="reqn">x</code>.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Hosking, J.R.M., 1990, L-moments&mdash;Analysis and estimation of
distributions using linear combinations of order statistics: Journal
of the Royal Statistical Society, Series B, v. 52, pp. 105&ndash;124.
</p>
<p>Hosking, J.R.M., 1996, FORTRAN routines for use with the method of L-moments:
Version 3, IBM Research Report RC20525, T.J. Watson Research Center,
Yorktown Heights, New York.
</p>
<p>Hosking, J.R.M., and Wallis, J.R., 1997, Regional frequency analysis&mdash;An
approach based on L-moments: Cambridge University Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pdfglo">pdfglo</a></code>, <code><a href="#topic+quaglo">quaglo</a></code>, <code><a href="#topic+lmomglo">lmomglo</a></code>, <code><a href="#topic+parglo">parglo</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>  lmr &lt;- lmoms(c(123,34,4,654,37,78))
  cdfglo(50,parglo(lmr))
</code></pre>

<hr>
<h2 id='cdfgno'>Cumulative Distribution Function of the Generalized Normal Distribution</h2><span id='topic+cdfgno'></span>

<h3>Description</h3>

<p>This function computes the cumulative probability or nonexceedance probability of the Generalized Normal distribution given parameters (<code class="reqn">\xi</code>, <code class="reqn">\alpha</code>, and <code class="reqn">\kappa</code>) computed by <code><a href="#topic+pargno">pargno</a></code>. The cumulative distribution function is
</p>
<p style="text-align: center;"><code class="reqn">F(x) = \Phi(Y) \mbox{,} </code>
</p>

<p>where <code class="reqn">\Phi</code> is the cumulative distribution function of the Standard Normal distribution and <code class="reqn">Y</code> is
</p>
<p style="text-align: center;"><code class="reqn">Y = -\kappa^{-1} \log\left(1 - \frac{\kappa(x-\xi)}{\alpha}\right)\mbox{,}</code>
</p>

<p>for <code class="reqn">\kappa \ne 0</code> and
</p>
<p style="text-align: center;"><code class="reqn">Y = (x-\xi)/\alpha\mbox{,}</code>
</p>

<p>for <code class="reqn">\kappa = 0</code>, where <code class="reqn">F(x)</code> is the nonexceedance probability for quantile <code class="reqn">x</code>, <code class="reqn">\xi</code> is a location parameter, <code class="reqn">\alpha</code> is a scale parameter, and <code class="reqn">\kappa</code> is a shape parameter.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cdfgno(x, para)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cdfgno_+3A_x">x</code></td>
<td>
<p>A real value vector.</p>
</td></tr>
<tr><td><code id="cdfgno_+3A_para">para</code></td>
<td>
<p>The parameters from <code><a href="#topic+pargno">pargno</a></code> or  <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Nonexceedance probability (<code class="reqn">F</code>) for <code class="reqn">x</code>.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Hosking, J.R.M., 1990, L-moments&mdash;Analysis and estimation of
distributions using linear combinations of order statistics: Journal
of the Royal Statistical Society, Series B, v. 52, pp. 105&ndash;124.
</p>
<p>Hosking, J.R.M., 1996, FORTRAN routines for use with the method of L-moments:
Version 3, IBM Research Report RC20525, T.J. Watson Research Center,
Yorktown Heights, New York.
</p>
<p>Hosking, J.R.M., and Wallis, J.R., 1997, Regional frequency analysis&mdash;An
approach based on L-moments: Cambridge University Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pdfgno">pdfgno</a></code>, <code><a href="#topic+quagno">quagno</a></code>, <code><a href="#topic+lmomgno">lmomgno</a></code>, <code><a href="#topic+pargno">pargno</a></code>, <code><a href="#topic+cdfln3">cdfln3</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  lmr &lt;- lmoms(c(123,34,4,654,37,78))
  cdfgno(50,pargno(lmr))
</code></pre>

<hr>
<h2 id='cdfgov'>Cumulative Distribution Function of the Govindarajulu Distribution</h2><span id='topic+cdfgov'></span>

<h3>Description</h3>

<p>This function computes the cumulative probability or nonexceedance probability of the Govindarajulu distribution given parameters (<code class="reqn">\xi</code>, <code class="reqn">\alpha</code>, and <code class="reqn">\beta</code>) computed by <code><a href="#topic+pargov">pargov</a></code>. The cumulative distribution function has no explicit form and requires numerical methods. The <span class="rlang"><b>R</b></span> function <code>uniroot</code> is used to root the quantile function <code><a href="#topic+quagov">quagov</a></code> to compute the nonexceedance probability. The function returns 0 or 1 if the <code>x</code> argument is at or beyond the limits of the distribution as specified by the parameters.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cdfgov(x, para)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cdfgov_+3A_x">x</code></td>
<td>
<p>A real value vector.</p>
</td></tr>
<tr><td><code id="cdfgov_+3A_para">para</code></td>
<td>
<p>The parameters from <code><a href="#topic+pargov">pargov</a></code> or  <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Nonexceedance probability (<code class="reqn">F</code>) for <code class="reqn">x</code>.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Gilchrist, W.G., 2000, Statistical modelling with quantile functions: Chapman and Hall/CRC, Boca Raton.
</p>
<p>Nair, N.U., Sankaran, P.G., and Balakrishnan, N., 2013, Quantile-based reliability analysis: Springer, New York.
</p>
<p>Nair, N.U., Sankaran, P.G., and Vineshkumar, B., 2012, The Govindarajulu distribution&mdash;Some Properties and applications: Communications in Statistics, Theory and Methods, v. 41, no. 24, pp. 4391&ndash;4406.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pdfgov">pdfgov</a></code>, <code><a href="#topic+quagov">quagov</a></code>, <code><a href="#topic+lmomgov">lmomgov</a></code>, <code><a href="#topic+pargov">pargov</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>  lmr &lt;- lmoms(c(123,34,4,654,37,78))
  cdfgov(50,pargov(lmr))
</code></pre>

<hr>
<h2 id='cdfgpa'>Cumulative Distribution Function of the Generalized Pareto Distribution</h2><span id='topic+cdfgpa'></span>

<h3>Description</h3>

<p>This function computes the cumulative probability or nonexceedance probability of the Generalized Pareto distribution given parameters (<code class="reqn">\xi</code>, <code class="reqn">\alpha</code>, and <code class="reqn">\kappa</code>) computed by <code><a href="#topic+pargpa">pargpa</a></code>. The cumulative distribution function is
</p>
<p style="text-align: center;"><code class="reqn">F(x) = 1 - \mathrm{exp}(-Y) \mbox{,}</code>
</p>

<p>where <code class="reqn">Y</code> is
</p>
<p style="text-align: center;"><code class="reqn">Y = -\kappa^{-1} \log\left(1 - \frac{\kappa(x-\xi)}{\alpha}\right)\mbox{,}</code>
</p>

<p>for <code class="reqn">\kappa \ne 0</code> and
</p>
<p style="text-align: center;"><code class="reqn">Y = (x-\xi)/\alpha\mbox{,}</code>
</p>

<p>for <code class="reqn">\kappa = 0</code>, where <code class="reqn">F(x)</code> is the nonexceedance probability for quantile <code class="reqn">x</code>, <code class="reqn">\xi</code> is a location parameter, <code class="reqn">\alpha</code> is a scale parameter, and <code class="reqn">\kappa</code> is a shape parameter. The range of <code class="reqn">x</code> is <code class="reqn">\xi \le x \le \xi + \alpha/\kappa</code> if <code class="reqn">k &gt; 0</code>; <code class="reqn">\xi \le x &lt; \infty</code> if <code class="reqn">\kappa \le 0</code>. Note that the shape parameter <code class="reqn">\kappa</code> parameterization of the distribution herein follows that in tradition by the greater L-moment community and others use a sign reversal on <code class="reqn">\kappa</code>. (The <span class="pkg">evd</span> package is one example.)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cdfgpa(x, para)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cdfgpa_+3A_x">x</code></td>
<td>
<p>A real value vector.</p>
</td></tr>
<tr><td><code id="cdfgpa_+3A_para">para</code></td>
<td>
<p>The parameters from <code><a href="#topic+pargpa">pargpa</a></code> or  <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Nonexceedance probability (<code class="reqn">F</code>) for <code class="reqn">x</code>.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Hosking, J.R.M., 1990, L-moments&mdash;Analysis and estimation of distributions using linear combinations of order statistics: Journal of the Royal Statistical Society, Series B, v. 52, pp. 105&ndash;124, <a href="https://doi.org/10.1111/j.2517-6161.1990.tb01775.x">doi:10.1111/j.2517-6161.1990.tb01775.x</a>.
</p>
<p>Hosking, J.R.M., 1996, FORTRAN routines for use with the method of L-moments: Version 3, IBM Research Report RC20525, T.J. Watson Research Center, Yorktown Heights, New York.
</p>
<p>Hosking, J.R.M., and Wallis, J.R., 1997, Regional frequency analysis&mdash;An approach based on L-moments: Cambridge University Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pdfgpa">pdfgpa</a></code>, <code><a href="#topic+quagpa">quagpa</a></code>, <code><a href="#topic+lmomgpa">lmomgpa</a></code>, <code><a href="#topic+pargpa">pargpa</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>  lmr &lt;- lmoms(c(123, 34, 4, 654, 37, 78))
  cdfgpa(50, pargpa(lmr))
</code></pre>

<hr>
<h2 id='cdfgum'>Cumulative Distribution Function of the Gumbel Distribution</h2><span id='topic+cdfgum'></span>

<h3>Description</h3>

<p>This function computes the cumulative probability or nonexceedance probability of the Gumbel distribution given parameters (<code class="reqn">\xi</code> and <code class="reqn">\alpha</code>) computed by <code><a href="#topic+pargum">pargum</a></code>. The cumulative distribution function is
</p>
<p style="text-align: center;"><code class="reqn">F(x) = \mathrm{exp}(-\mathrm{exp}(Y)) \mbox{,}</code>
</p>

<p>where
</p>
<p style="text-align: center;"><code class="reqn">Y = -\frac{x - \xi}{\alpha} \mbox{,}</code>
</p>

<p>where <code class="reqn">F(x)</code> is the nonexceedance probability for quantile <code class="reqn">x</code>, <code class="reqn">\xi</code> is a location parameter, and <code class="reqn">\alpha</code> is a scale parameter.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cdfgum(x, para)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cdfgum_+3A_x">x</code></td>
<td>
<p>A real value vector.</p>
</td></tr>
<tr><td><code id="cdfgum_+3A_para">para</code></td>
<td>
<p>The parameters from <code><a href="#topic+pargum">pargum</a></code> or  <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Nonexceedance probability (<code class="reqn">F</code>) for <code class="reqn">x</code>.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Hosking, J.R.M., 1990, L-moments&mdash;Analysis and estimation of
distributions using linear combinations of order statistics: Journal
of the Royal Statistical Society, Series B, v. 52, pp. 105&ndash;124.
</p>
<p>Hosking, J.R.M., 1996, FORTRAN routines for use with the method of L-moments:
Version 3, IBM Research Report RC20525, T.J. Watson Research Center,
Yorktown Heights, New York.
</p>
<p>Hosking, J.R.M., and Wallis, J.R., 1997, Regional frequency analysis&mdash;An
approach based on L-moments: Cambridge University Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pdfgum">pdfgum</a></code>, <code><a href="#topic+quagum">quagum</a></code>, <code><a href="#topic+lmomgum">lmomgum</a></code>, <code><a href="#topic+pargum">pargum</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>  lmr &lt;- lmoms(c(123,34,4,654,37,78))
  cdfgum(50,pargum(lmr))
</code></pre>

<hr>
<h2 id='cdfkap'>Cumulative Distribution Function of the Kappa Distribution</h2><span id='topic+cdfkap'></span>

<h3>Description</h3>

<p>This function computes the cumulative probability or nonexceedance probability
of the Kappa of the distribution computed by <code><a href="#topic+parkap">parkap</a></code>. The cumulative distribution function is
</p>
<p style="text-align: center;"><code class="reqn">F(x) = \left(1-h\left(1-\frac{\kappa(x-\xi)}{\alpha}\right)^{1/\kappa}\right)^{1/h} \mbox{,}</code>
</p>

<p>where <code class="reqn">F(x)</code> is the nonexceedance probability for quantile <code class="reqn">x</code>,
<code class="reqn">\xi</code> is a location parameter, <code class="reqn">\alpha</code> is a scale parameter,
<code class="reqn">\kappa</code> is a shape parameter, and <code class="reqn">h</code> is another shape parameter.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cdfkap(x, para)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cdfkap_+3A_x">x</code></td>
<td>
<p>A real value vector.</p>
</td></tr>
<tr><td><code id="cdfkap_+3A_para">para</code></td>
<td>
<p>The parameters from <code><a href="#topic+parkap">parkap</a></code> or  <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Nonexceedance probability (<code class="reqn">F</code>) for <code class="reqn">x</code>.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Hosking, J.R.M., 1994, The four-parameter kappa distribution: IBM Journal of Reserach and Development, v. 38, no. 3, pp. 251&ndash;258.
</p>
<p>Hosking, J.R.M., and Wallis, J.R., 1997, Regional frequency analysis&mdash;An approach based on L-moments: Cambridge University Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pdfkap">pdfkap</a></code>, <code><a href="#topic+quakap">quakap</a></code>, <code><a href="#topic+lmomkap">lmomkap</a></code>, <code><a href="#topic+parkap">parkap</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>  lmr &lt;- lmoms(c(123,34,4,654,37,78,21,32,231,23))
  cdfkap(50,parkap(lmr))
</code></pre>

<hr>
<h2 id='cdfkmu'>Cumulative Distribution Function of the Kappa-Mu Distribution</h2><span id='topic+cdfkmu'></span>

<h3>Description</h3>

<p>This function computes the cumulative probability or nonexceedance probability of the Kappa-Mu (<code class="reqn">\kappa:\mu</code>)  distribution given parameters (<code class="reqn">\kappa</code> and <code class="reqn">\mu</code>) computed by <code><a href="#topic+parkmu">parkmu</a></code>. The cumulative distribution function is complex and numerical integration of the probability density function <code><a href="#topic+pdfkmu">pdfkmu</a></code> is used. Alternatively, the cumulative distribution function may be defined in terms of the Marcum Q function
</p>
<p style="text-align: center;"><code class="reqn">
F(x) = 1 - Q_\nu\biggl(\sqrt{2\kappa\mu},\, x\sqrt{2(1+\kappa)\mu}\biggr)\mbox{,}
</code>
</p>

<p>where <code class="reqn">F(x)</code> is the nonexceedance probability for quantile <code class="reqn">x</code> and <code class="reqn">Q_v(a,b)</code> is the Marcum Q function defined by
</p>
<p style="text-align: center;"><code class="reqn">
Q_\nu(a,b) = \frac{1}{\alpha^{\nu-1}}\int_b^\infty t^\nu \, \exp(-(t^2 + a^2)/2) \, I_{\nu-1}(at)\; \mathrm{d}t\mbox{,}
</code>
</p>

<p>which can be numerically difficult to work with and particularly so with real number values for <code class="reqn">\nu</code>. <code class="reqn">I_\nu(a)</code>  is the &ldquo;<code class="reqn">\nu</code>th-order modified Bessel function of the first kind.&rdquo;
</p>
<p>Following an apparent breakthrough(?) by Shi (2012), <code class="reqn">\nu</code> can be written as <code class="reqn">\nu = n + \Delta</code> where <code class="reqn">n</code> is an integer and <code class="reqn">0 &lt; \Delta \le 1</code>. The author of <span class="pkg">lmomco</span> refers to this alternative formulation as the &ldquo;delta nu method&rdquo;. The Marcum Q function for <code class="reqn">\nu &gt; 0</code> (<code class="reqn">n = 1,2,3, \cdots)</code> is
</p>
<p style="text-align: center;"><code class="reqn">
Q_\nu(a,b) = Q_\Delta(a,b) + \exp(-(a^2 + b^2)/2) \, \sum_{i=0}^{n-1}\biggl(\frac{b}{a}\biggr)^{i+\Delta} \, I_{i+\Delta}(ab)\mbox{,}
</code>
</p>

<p>and the function for <code class="reqn">\nu \le 0</code> (<code class="reqn">n=-1,-2,-3,\cdots</code>) is
</p>
<p style="text-align: center;"><code class="reqn">
Q_\nu(a,b) = Q_\Delta(a,b) - \mathrm{exp}(-(a^2 + b^2)/2) \times \sum_{i=n}^{-1}\biggl(\frac{b}{a}\biggr)^{i+\Delta} \mathrm{I}_{i+\Delta}(ab)\mbox{,}
</code>
</p>

<p>and the function for <code class="reqn">\nu = 0</code> is
</p>
<p style="text-align: center;"><code class="reqn">
Q_\nu(a,b) = Q_\Delta(a,b) + \mathrm{exp}(-(a^2 + b^2)/2)\mbox{.}
</code>
</p>

<p>Shi (2012) concludes that the &ldquo;merit&rdquo; of these two expressions is that the evaulation of the Marcum Q function is reduced to the numerical evaluation of <code class="reqn">Q_\Delta(a,b)</code>. This difference can result in measurably faster computation times (confirmed by limited analysis by the author of <span class="pkg">lmomco</span>) and possibly better numerical performance.
</p>
<p>Shi (2012) uses notation and text that implies evaluation of the far-right additive term (the summation) for <code class="reqn">n=0</code> as part of the condition <code class="reqn">\nu &gt; 0</code>. To clarify, Shi (2012) implies for <code class="reqn">\nu &gt; 0; n = 0</code> (but <code class="reqn">n=0</code> occurs also for <code class="reqn">-1 &lt; \nu &lt;= 0</code>) the following computation
</p>
<p style="text-align: center;"><code class="reqn">
Q_\nu(a,b) = Q_\Delta(a,b) + \mathrm{exp}(-(a^2 + b^2)/2) \times \biggl[\biggl(\frac{b}{a}\biggr)^{\Delta} \mathrm{I}_{\Delta}(ab) + \biggl(\frac{b}{a}\biggr)^{\Delta-1} \mathrm{I}_{\Delta-1}(ab)\biggr]
</code>
</p>

<p>This result produces incompatible cumulative distribution functions of the distribution using <code class="reqn">Q_\nu(a,b)</code> for <code class="reqn">-1 &lt; \nu &lt; 1</code>. Therefore, the author of <span class="pkg">lmomco</span> concludes that Shi (2012) is in error (or your author misinterprets the summation notation) and that the specific condition for <code class="reqn">\nu = 0</code> shown above and lacking <code class="reqn">\sum</code> is correct; there are three individual and separate conditions to support the Marcum Q function using the &ldquo;delta nu method&rdquo;: <code class="reqn">\nu \le -1</code>, <code class="reqn">-1 &lt; \nu &lt; 1</code>, and <code class="reqn">\nu \ge -1</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cdfkmu(x, para, paracheck=TRUE, getmed=TRUE, qualo=NA, quahi=NA,
                marcumQ=TRUE, marcumQmethod=c("chisq", "delta", "integral"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cdfkmu_+3A_x">x</code></td>
<td>
<p>A real value vector.</p>
</td></tr>
<tr><td><code id="cdfkmu_+3A_para">para</code></td>
<td>
<p>The parameters from <code><a href="#topic+parkmu">parkmu</a></code> or  <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
<tr><td><code id="cdfkmu_+3A_paracheck">paracheck</code></td>
<td>
<p>A logical controlling whether the parameters and checked for validity.</p>
</td></tr>
<tr><td><code id="cdfkmu_+3A_getmed">getmed</code></td>
<td>
<p>Numerical problems rolling onto the distribution from the right can result in erroneous <code class="reqn">F</code> being integrated of <code><a href="#topic+pdfkmu">pdfkmu</a></code>. This option is used to interrupt recurrsion, but if <code>TRUE</code>, then the median will be computed and for those <code class="reqn">x</code> values less than the median and <code class="reqn">F</code> initially computing as greater than 50 percent, are reset to 0.  Users are unlikely to need this option changed. But the hack can be turned off by setting <code>getmed=FALSE</code> as the user level.</p>
</td></tr>
<tr><td><code id="cdfkmu_+3A_qualo">qualo</code></td>
<td>
<p>A lower limit of the range of <code class="reqn">x</code> to look for a <code>uniroot</code> of <code class="reqn">F(x) = 0.5</code> to estimate the median quantile that is used to mitigate for erroneous numerical results. This argument is passed along to <code><a href="#topic+quakmu">quakmu</a></code> but also used as a truncation point for which <code class="reqn">F=1</code> is returned if <code class="reqn">x &lt;</code> <code>qualo</code>. Lastly, see the last example below.</p>
</td></tr>
<tr><td><code id="cdfkmu_+3A_quahi">quahi</code></td>
<td>
<p>An upper limit of the range of <code class="reqn">x</code> to look for a <code>uniroot</code> of <code class="reqn">F(x) = 0.5</code> to estimate the median quantile that is used to mitigate for erroneous numerical results. This argument is passed along to <code><a href="#topic+quakmu">quakmu</a></code> but also used as a truncation point for which <code class="reqn">F=1</code> is returned if <code class="reqn">x &gt;</code> <code>quahi</code>. Lastly, see the last example below.</p>
</td></tr>
<tr><td><code id="cdfkmu_+3A_marcumq">marcumQ</code></td>
<td>
<p>A logical controlling whether the Marcum Q function is used instead of numerical integration of <code><a href="#topic+pdfkmu">pdfkmu</a></code>.</p>
</td></tr>
<tr><td><code id="cdfkmu_+3A_marcumqmethod">marcumQmethod</code></td>
<td>
<p>Which method for Marcum Q computation is to be used (see source code).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Nonexceedance probability (<code class="reqn">F</code>) for <code class="reqn">x</code>.
</p>


<h3>Note</h3>

<p>Code developed from Weinberg (2006). The biascor feature is of my own devise and this Poisson method does not seem to accommodate nu &lt; 1 although Chornoboy claims valid for non-negative integer. The example implementation here will continue to use real values of nu.
</p>
<pre>
See NEWS file and entries for version 2.0.1 for this "R Marcum"
"marcumq" &lt;- function(a, b, nu=1) {
	      pchisq(b^2, df=2*nu, ncp=a^2, lower.tail=FALSE) }

"marcumq.poissons" &lt;-
   function(a,b, nu=NULL, nsim=10000, biascor=0.5) {
   asint &lt;- as.logical(nu 
   biascor &lt;- ifelse(! asint, 0, biascor)
   marcumQint &lt;- marcumq(a, b, nu=nu)
   B &lt;- rpois(nsim, b^2/2)
   A &lt;- nu - 1 + biascor + rpois(nsim, a^2/2)
   L &lt;- B &lt;= A
   marcumQppois &lt;- length(L[L == TRUE])/nsim
   z &lt;- list(MarcumQ.by.usingR = marcumQint,
             MarcumQ.by.poisson = marcumQppois)
   return(z)
}
x &lt;- y &lt;- vector()
for(i in 1:10000) {
   nu &lt;- i/100
   z &lt;- marcumq.poissons(12.4, 12.5, nu=nu)
   x[i] &lt;- z$MarcumQ.by.usingR
   y[i] &lt;- z$MarcumQ.by.poisson
}
plot(x,y, pch=16, col=rgb(x,0,0,.2),
     xlab="Marcum Q-function using R (ChiSq distribution)",
     ylab="Marcum Q-function by two Poisson random variables")
abline(0,1, lty=2)
</pre>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Shi, Q., 2012, Semi-infinite Gauss-Hermite quadrature based approximations to the generalized Marcum and Nuttall Q-functions and further applications: First IEEE International Conference on Communications in China&mdash;Communications Theory and Security (CTS), pp. 268&ndash;273, ISBN 978&ndash;1&ndash;4673&ndash;2815&ndash;9,12.
</p>
<p>Weinberg, G.V., 2006, Poisson representation and Monte Carlo estimation of generalized Marcum Q-function: IEEE Transactions on Aerospace and Electronic Systems, v. 42, no. 4, pp. 1520&ndash;1531.
</p>
<p>Yacoub, M.D., 2007, The kappa-mu distribution and the eta-mu distribution: IEEE Antennas and Propagation Magazine, v. 49, no. 1, pp. 68&ndash;81.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pdfkmu">pdfkmu</a></code>, <code><a href="#topic+quakmu">quakmu</a></code>, <code><a href="#topic+lmomkmu">lmomkmu</a></code>, <code><a href="#topic+parkmu">parkmu</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
x &lt;- seq(0,3, by=0.5)
para &lt;- vec2par(c(0.69, 0.625), type="kmu")
cdfkmu(x, para, marcumQ=TRUE, marcumQmethod="chisq")
cdfkmu(x, para, marcumQ=TRUE, marcumQmethod="delta")
cdfkmu(x, para, marcumQ=FALSE) # about 3 times slower
## End(Not run)
## Not run: 
para &lt;- vec2par(c(0.69, 0.625), type="kmu")
quahi &lt;- supdist(para, delexp=.1)$support[2]
cdfkmu(quahi, para, quahi=quahi)

## End(Not run)
## Not run: 
delx &lt;- 0.01
x &lt;- seq(0,3, by=delx)

plot(c(0,3), c(0,1), xlab="RHO", ylab="cdfkmu(RHO)", type="n")
para &lt;- list(para=c(0, 0.75), type="kmu")
cdf &lt;- cdfkmu(x, para)
lines(x, cdf, col=2, lwd=4)
para &lt;- list(para=c(1, 0.5625), type="kmu")
cdf &lt;- cdfkmu(x, para)
lines(x, cdf, col=3, lwd=4)

kappas &lt;- c(0.00000001, 0.69, 1.37,  2.41, 4.45, 10.48, 28.49)
mus    &lt;- c(0.75, 0.625,  0.5,  0.375, 0.25,  0.125, 0.05)
for(i in 1:length(kappas)) {
   kappa &lt;- kappas[i]
   mu    &lt;- mus[i]
   para &lt;- list(para=c(kappa, mu), type="kmu")
   cdf &lt;- cdfkmu(x, para)
   lines(x, cdf, col=i)
}

## End(Not run)
## Not run: 
delx &lt;- 0.005
x &lt;- seq(0,3, by=delx)
nx &lt;- 20*log10(x)
plot(c(-30,10), 10^c(-4,0), log="y", xaxs="i", yaxs="i",
     xlab="RHO", ylab="cdfkmu(RHO)", type="n")
m &lt;- 1.25
mus &lt;- c(0.25, 0.50, 0.75, 1, 1.25, 0)
for(mu in mus) {
   col &lt;- 1
   kappa &lt;- m/mu - 1 + sqrt((m/mu)*((m/mu)-1))
   para &lt;- vec2par(c(kappa, mu), type="kmu")
   if(! is.finite(kappa)) {
      para &lt;- vec2par(c(Inf,m), type="kmu")
      col &lt;- 2
   }
   lines(nx, cdfkmu(x, para), col=col)
}
mtext("Yacoub (2007, figure 4)")

## End(Not run)
## Not run: 
# The Marcum Q use for the CDF avoid numerical integration of pdfkmu(), but
# below is an example for which there is some failure that remains to be found.
para &lt;- vec2par(c(10, 23), type="kmu")
# The following are reliable but slower as they avoid the Marcum Q function
# and use traditional numerical integration of the PDF function.
A &lt;- cdfkmu(c(0.10, 0.35, 0.9, 1, 1.16), para, marcumQ=FALSE)
# Continuing, the first value in c() has an erroneous value for the next call.
B &lt;- cdfkmu(c(0.10, 0.35, 0.9, 1, 1.16), para, marcumQ=TRUE)
# But this distribution is tightly peaks and well away from the origin, so in
# order to snap the erroneous value to zero, we need a successful median
# computation.  We can try again using the qualo argument to pass through to
# quakmu() like the following:
C &lt;- cdfkmu(c(0.10, 0.35, 0.9, 1, 1.16), para, marcumQ=TRUE, qualo=0.4)
# The existance of the median for the last one also triggers a truncation of
# the CDF to 0 when negative solution results for the 0.35, although the
# negative is about -1E-14.

## End(Not run)
## Not run: 
# Does the discipline of the signal litature just "know" about the apparent
# upper support of the Kappa-Mu being quite near or even at pi?
"simKMU" &lt;- function() {
   km &lt;- 10^runif(2, min=-3, max=3)
   f &lt;- cdfkmu(pi, vec2par(km, type="kmu"))
   return(c(km, f))
}
EndStudy &lt;- sapply(1:1000, function(i) { simKMU() } )
boxplot(EndStudy[3,])

## End(Not run)
</code></pre>

<hr>
<h2 id='cdfkur'>Cumulative Distribution Function of the Kumaraswamy Distribution</h2><span id='topic+cdfkur'></span>

<h3>Description</h3>

<p>This function computes the cumulative probability or nonexceedance probability of the Kumaraswamy distribution given parameters (<code class="reqn">\alpha</code> and <code class="reqn">\beta</code>) computed by <code><a href="#topic+parkur">parkur</a></code>. The cumulative distribution function is
</p>
<p style="text-align: center;"><code class="reqn">F(x) = 1 - (1-x^\alpha)^\beta \mbox{,}</code>
</p>

<p>where <code class="reqn">F(x)</code> is the nonexceedance probability for quantile <code class="reqn">x</code>,
<code class="reqn">\alpha</code> is a shape parameter, and <code class="reqn">\beta</code> is a shape parameter.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cdfkur(x, para)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cdfkur_+3A_x">x</code></td>
<td>
<p>A real value vector.</p>
</td></tr>
<tr><td><code id="cdfkur_+3A_para">para</code></td>
<td>
<p>The parameters from <code><a href="#topic+parkur">parkur</a></code> or  <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Nonexceedance probability (<code class="reqn">F</code>) for <code class="reqn">x</code>.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Jones, M.C., 2009, Kumaraswamy's distribution&mdash;A beta-type distribution with
some tractability advantages: Statistical Methodology, v. 6, pp. 70&ndash;81.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pdfkur">pdfkur</a></code>, <code><a href="#topic+quakur">quakur</a></code>, <code><a href="#topic+lmomkur">lmomkur</a></code>, <code><a href="#topic+parkur">parkur</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>  lmr &lt;- lmoms(c(0.25, 0.4, 0.6, 0.65, 0.67, 0.9))
  cdfkur(0.5,parkur(lmr))
</code></pre>

<hr>
<h2 id='cdflap'>Cumulative Distribution Function of the Laplace Distribution</h2><span id='topic+cdflap'></span>

<h3>Description</h3>

<p>This function computes the cumulative probability or nonexceedance probability of the Laplace distribution given parameters (<code class="reqn">\xi</code> and <code class="reqn">\alpha</code>) computed by <code><a href="#topic+parlap">parlap</a></code>. The cumulative distribution function is
</p>
<p style="text-align: center;"><code class="reqn">F(x) = \frac{1}{2} \mathrm{exp}((x-\xi)/\alpha) \mbox{ for } x \le \xi \mbox{,}</code>
</p>

<p>and
</p>
<p style="text-align: center;"><code class="reqn">F(x) = 1 - \frac{1}{2} \mathrm{exp}(-(x-\xi)/\alpha)  \mbox{ for } x &gt; \xi \mbox{,}</code>
</p>

<p>where <code class="reqn">F(x)</code> is the nonexceedance probability for quantile <code class="reqn">x</code>,
<code class="reqn">\xi</code> is a location parameter, and <code class="reqn">\alpha</code> is a scale parameter.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cdflap(x, para)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cdflap_+3A_x">x</code></td>
<td>
<p>A real value vector.</p>
</td></tr>
<tr><td><code id="cdflap_+3A_para">para</code></td>
<td>
<p>The parameters from <code><a href="#topic+parlap">parlap</a></code> or  <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Nonexceedance probability (<code class="reqn">F</code>) for <code class="reqn">x</code>.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Hosking, J.R.M., 1986, The theory of probability weighted moments: IBM Research Report RC12210, T.J. Watson Research Center, Yorktown Heights, New York.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pdflap">pdflap</a></code>, <code><a href="#topic+qualap">qualap</a></code>, <code><a href="#topic+lmomlap">lmomlap</a></code>, <code><a href="#topic+parlap">parlap</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>  lmr &lt;- lmoms(c(123,34,4,654,37,78))
  cdflap(50,parlap(lmr))
</code></pre>

<hr>
<h2 id='cdflmrq'>Cumulative Distribution Function of the  Linear Mean Residual Quantile Function Distribution</h2><span id='topic+cdflmrq'></span>

<h3>Description</h3>

<p>This function computes the cumulative probability or nonexceedance probability of the &ldquo;Linear Mean Residual Quantile Function&rdquo; distribution given parameters computed by <code><a href="#topic+parlmrq">parlmrq</a></code>.  The cumulative distribution function  has no explicit form and requires numerical methods. The <span class="rlang"><b>R</b></span> function <code>uniroot</code> is used to root the quantile function <code><a href="#topic+qualmrq">qualmrq</a></code> to compute the nonexceedance probability. The function returns 0 or 1 if the <code>x</code> argument is at or beyond the limits of the distribution as specified by the parameters. The <code><a href="#topic+cdflmrq">cdflmrq</a></code> function is also used with numerical methods to solve the <code><a href="#topic+pdflmrq">pdflmrq</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cdflmrq(x, para, paracheck=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cdflmrq_+3A_x">x</code></td>
<td>
<p>A real value vector.</p>
</td></tr>
<tr><td><code id="cdflmrq_+3A_para">para</code></td>
<td>
<p>The parameters from <code><a href="#topic+parlmrq">parlmrq</a></code> or  <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
<tr><td><code id="cdflmrq_+3A_paracheck">paracheck</code></td>
<td>
<p>A logical switch as to whether the validity of the parameters should be checked. Default is <code>paracheck=TRUE</code>. This switch is made so that the root solution needed for <code><a href="#topic+cdflmrq">cdflmrq</a></code> exhibits an extreme speed increase because of the repeated calls to <code>qualmrq</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Nonexceedance probability (<code class="reqn">F</code>) for <code class="reqn">x</code>.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Midhu, N.N., Sankaran, P.G., and Nair, N.U., 2013, A class of distributions with linear mean residual quantile function and it's generalizations: Statistical Methodology, v. 15, pp. 1&ndash;24.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pdflmrq">pdflmrq</a></code>, <code><a href="#topic+qualmrq">qualmrq</a></code>, <code><a href="#topic+lmomlmrq">lmomlmrq</a></code>, <code><a href="#topic+parlmrq">parlmrq</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  lmr &lt;- lmoms(c(3, 0.05, 1.6, 1.37, 0.57, 0.36, 2.2))
  cdflmrq(2,parlmrq(lmr))
</code></pre>

<hr>
<h2 id='cdfln3'>Cumulative Distribution Function of the 3-Parameter Log-Normal Distribution</h2><span id='topic+cdfln3'></span>

<h3>Description</h3>

<p>This function computes the cumulative probability or nonexceedance probability of the Log-Normal3 distribution given parameters (<code class="reqn">\zeta</code>, lower bounds; <code class="reqn">\mu_{\mathrm{log}}</code>, location; and <code class="reqn">\sigma_{\mathrm{log}}</code>, scale) computed by <code><a href="#topic+parln3">parln3</a></code>. The cumulative distribution function (same as Generalized Normal distribution, <code><a href="#topic+cdfgno">cdfgno</a></code>) is
</p>
<p style="text-align: center;"><code class="reqn">F(x) = \Phi(Y) \mbox{,} </code>
</p>

<p>where <code class="reqn">\Phi</code> is the cumulative ditribution function of the
Standard Normal distribution and <code class="reqn">Y</code> is
</p>
<p style="text-align: center;"><code class="reqn">
Y = \frac{\log(x - \zeta) - \mu_{\mathrm{log}}}{\sigma_{\mathrm{log}}}\mbox{,}
</code>
</p>

<p>where <code class="reqn">\zeta</code> is the lower bounds (real space) for which <code class="reqn">\zeta &lt; \lambda_1 - \lambda_2</code> (checked in <code><a href="#topic+are.parln3.valid">are.parln3.valid</a></code>), <code class="reqn">\mu_{\mathrm{log}}</code> be the mean in natural logarithmic space, and <code class="reqn">\sigma_{\mathrm{log}}</code> be the standard deviation in natural logarithm space for which <code class="reqn">\sigma_{\mathrm{log}} &gt; 0</code> (checked in <code><a href="#topic+are.parln3.valid">are.parln3.valid</a></code>) is obvious because this parameter has an analogy to the second product moment. Letting <code class="reqn">\eta = \exp(\mu_{\mathrm{log}})</code>, the parameters of the Generalized Normal are <code class="reqn">\zeta + \eta</code>, <code class="reqn">\alpha = \eta\sigma_{\mathrm{log}}</code>, and <code class="reqn">\kappa = -\sigma_{\mathrm{log}}</code>. At this point, the algorithms (<code><a href="#topic+cdfgno">cdfgno</a></code>) for the Generalized Normal provide the functional core.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cdfln3(x, para)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cdfln3_+3A_x">x</code></td>
<td>
<p>A real value vector.</p>
</td></tr>
<tr><td><code id="cdfln3_+3A_para">para</code></td>
<td>
<p>The parameters from <code><a href="#topic+parln3">parln3</a></code> or  <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Nonexceedance probability (<code class="reqn">F</code>) for <code class="reqn">x</code>.
</p>


<h3>Note</h3>

<p>The parameterization of the Log-Normal3 results in ready support for either a known or unknown lower bounds. Details regarding the parameter fitting and control of the <code class="reqn">\zeta</code> parameter can be seen under the Details section in <code><a href="#topic+parln3">parln3</a></code>.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Asquith, W.H., 2011, Distributional analysis with L-moment statistics using the R environment for statistical computing: Createspace Independent Publishing Platform, ISBN 978&ndash;146350841&ndash;8.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pdfln3">pdfln3</a></code>, <code><a href="#topic+qualn3">qualn3</a></code>, <code><a href="#topic+lmomln3">lmomln3</a></code>, <code><a href="#topic+parln3">parln3</a></code>, <code><a href="#topic+cdfgno">cdfgno</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>  lmr &lt;- lmoms(c(123,34,4,654,37,78))
  cdfln3(50,parln3(lmr))
</code></pre>

<hr>
<h2 id='cdfnor'>Cumulative Distribution Function of the Normal Distribution</h2><span id='topic+cdfnor'></span>

<h3>Description</h3>

<p>This function computes the cumulative probability or nonexceedance probability of the Normal distribution given parameters of the distribution computed by <code><a href="#topic+parnor">parnor</a></code>.  The cumulative distribution function is
</p>
<p style="text-align: center;"><code class="reqn">F(x) = \Phi((x-\mu)/\sigma) \mbox{,}</code>
</p>

<p>where <code class="reqn">F(x)</code> is the nonexceedance probability for quantile <code class="reqn">x</code>, <code class="reqn">\mu</code> is the arithmetic mean, and <code class="reqn">\sigma</code> is the standard deviation, and <code class="reqn">\Phi</code> is the cumulative distribution function of the Standard Normal
distribution, and thus the <span class="rlang"><b>R</b></span> function <code>pnorm</code> is used.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cdfnor(x, para)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cdfnor_+3A_x">x</code></td>
<td>
<p>A real value vector.</p>
</td></tr>
<tr><td><code id="cdfnor_+3A_para">para</code></td>
<td>
<p>The parameters from <code><a href="#topic+parnor">parnor</a></code> or  <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Nonexceedance probability (<code class="reqn">F</code>) for <code class="reqn">x</code>.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Hosking, J.R.M., 1990, L-moments&mdash;Analysis and estimation of
distributions using linear combinations of order statistics: Journal
of the Royal Statistical Society, Series B, v. 52, pp. 105&ndash;124.
</p>
<p>Hosking, J.R.M., and Wallis, J.R., 1997, Regional frequency analysis&mdash;An
approach based on L-moments: Cambridge University Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pdfnor">pdfnor</a></code>, <code><a href="#topic+quanor">quanor</a></code>, <code><a href="#topic+lmomnor">lmomnor</a></code>, <code><a href="#topic+parnor">parnor</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>  lmr &lt;- lmoms(c(123,34,4,654,37,78))
  cdfnor(50,parnor(lmr))
</code></pre>

<hr>
<h2 id='cdfpdq3'>Cumulative Distribution Function of the Polynomial Density-Quantile3 Distribution</h2><span id='topic+cdfpdq3'></span>

<h3>Description</h3>

<p>This function computes the cumulative probability or nonexceedance probability of the Polynomial Density-Quantile3 (PDQ3) distribution given parameters (<code class="reqn">\xi</code>, <code class="reqn">\alpha</code>, <code class="reqn">\kappa</code>) computed by <code><a href="#topic+parpdq4">parpdq4</a></code>. The cumulative distribution function has no explicit form and requires numerical methods. The <span class="rlang"><b>R</b></span> function <code>uniroot()</code> is used to root the quantile function <code><a href="#topic+quapdq3">quapdq3</a></code> to compute the nonexceedance probability. The distribution's canonical definition is in terms of the quantile function (<code><a href="#topic+quapdq3">quapdq3</a></code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cdfpdq3(x, para, paracheck=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cdfpdq3_+3A_x">x</code></td>
<td>
<p>A real value vector.</p>
</td></tr>
<tr><td><code id="cdfpdq3_+3A_para">para</code></td>
<td>
<p>The parameters from <code><a href="#topic+parpdq3">parpdq3</a></code> or  <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
<tr><td><code id="cdfpdq3_+3A_paracheck">paracheck</code></td>
<td>
<p>A logical switch as to whether the validity of the parameters should be checked. Default is <code>paracheck=TRUE</code>. This switch is made so that the root solution needed for <code><a href="#topic+cdfpdq3">cdfpdq3</a></code> shows an extreme speed increase because of the repeated calls to <code>quapdq3</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Nonexceedance probability (<code class="reqn">F</code>) for <code class="reqn">x</code>.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Hosking, J.R.M., 2007, Distributions with maximum entropy subject to constraints on their L-moments or expected order statistics: Journal of Statistical Planning and Inference, v. 137, no. 9, pp. 2870&ndash;2891, <a href="https://doi.org/10.1016/j.jspi.2006.10.010">doi:10.1016/j.jspi.2006.10.010</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pdfpdq3">pdfpdq3</a></code>, <code><a href="#topic+quapdq3">quapdq3</a></code>, <code><a href="#topic+lmompdq3">lmompdq3</a></code>, <code><a href="#topic+parpdq3">parpdq3</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
  FF &lt;- seq(0.001, 0.999, by=0.001)
  para  &lt;- list(para=c(0.6933, 1.5495, 0.5488), type="pdq3")
  Fpdq3 &lt;- cdfpdq3(quapdq3(FF, para), para)
  plot(FF, Fpdq3, type="l", col=grey(0.8), lwd=4)
  # should be a 1:1 line, it is 
## End(Not run)

## Not run: 
  para &lt;- list(para=c(0.6933, 1.5495, 0.5488), type="pdq3")
  X &lt;- seq(-5, +12, by=(12 - -5) / 500)
  plot( X, cdfpdq3(X, para), type="l", col=grey(0.8), lwd=4, ylim=c(0, 1))
  lines(X, pf( exp(X), df1=7, df2=1), lty=2)
  lines(X, c(NA, diff( cdfpdq3(X, para))          / ((12 - -5) / 500)))
  lines(X, c(NA, diff(  pf(exp(X), df1=7, df2=1)) / ((12 - -5) / 500)), lty=2) # 
## End(Not run)
</code></pre>

<hr>
<h2 id='cdfpdq4'>Cumulative Distribution Function of the Polynomial Density-Quantile4 Distribution</h2><span id='topic+cdfpdq4'></span>

<h3>Description</h3>

<p>This function computes the cumulative probability or nonexceedance probability of the Polynomial Density-Quantile4 (PDQ4) distribution given parameters (<code class="reqn">\xi</code>, <code class="reqn">\alpha</code>, <code class="reqn">\kappa</code>) computed by <code><a href="#topic+parpdq4">parpdq4</a></code>. The cumulative distribution function has no explicit form and requires numerical methods. The <span class="rlang"><b>R</b></span> function <code>uniroot()</code> is used to root the quantile function <code><a href="#topic+quapdq4">quapdq4</a></code> to compute the nonexceedance probability. The distribution's canonical definition is in terms of the quantile function (<code><a href="#topic+quapdq4">quapdq4</a></code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cdfpdq4(x, para, paracheck=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cdfpdq4_+3A_x">x</code></td>
<td>
<p>A real value vector.</p>
</td></tr>
<tr><td><code id="cdfpdq4_+3A_para">para</code></td>
<td>
<p>The parameters from <code><a href="#topic+parpdq4">parpdq4</a></code> or  <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
<tr><td><code id="cdfpdq4_+3A_paracheck">paracheck</code></td>
<td>
<p>A logical switch as to whether the validity of the parameters should be checked. Default is <code>paracheck=TRUE</code>. This switch is made so that the root solution needed for <code><a href="#topic+cdfpdq4">cdfpdq4</a></code> shows an extreme speed increase because of the repeated calls to <code>quapdq4</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Nonexceedance probability (<code class="reqn">F</code>) for <code class="reqn">x</code>.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Hosking, J.R.M., 2007, Distributions with maximum entropy subject to constraints on their L-moments or expected order statistics: Journal of Statistical Planning and Inference, v. 137, no. 9, pp. 2870&ndash;2891, <a href="https://doi.org/10.1016/j.jspi.2006.10.010">doi:10.1016/j.jspi.2006.10.010</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pdfpdq4">pdfpdq4</a></code>, <code><a href="#topic+quapdq4">quapdq4</a></code>, <code><a href="#topic+lmompdq4">lmompdq4</a></code>, <code><a href="#topic+parpdq4">parpdq4</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
  FF &lt;- seq(0.001, 0.999, by=0.001)
  para  &lt;- list(para=c(0, 0.4332, -0.7029), type="pdq4")
  Fpdq4 &lt;- cdfpdq4(quapdq4(FF, para), para)
  plot(FF, Fpdq4, type="l", col=grey(0.8), lwd=4)
  # should be a 1:1 line, it is 
## End(Not run)

## Not run: 
  para &lt;- list(para=c(0, 0.4332, -0.7029), type="pdq4")
  X &lt;- seq(-5, +12, by=(12 - -5) / 500)
  plot( X, cdfpdq4(X, para), type="l", col=grey(0.8), lwd=4, ylim=c(0, 1))
  lines(X, pf( exp(X), df1=5, df2=4), lty=2)
  lines(X, c(NA, diff( cdfpdq4(X, para))          / ((12 - -5) / 500)))
  lines(X, c(NA, diff( pf( exp(X), df1=5, df2=4)) / ((12 - -5) / 500)), lty=2) # 
## End(Not run)
</code></pre>

<hr>
<h2 id='cdfpe3'>Cumulative Distribution Function of the Pearson Type III Distribution</h2><span id='topic+cdfpe3'></span>

<h3>Description</h3>

<p>This function computes the cumulative probability or nonexceedance probability of the Pearson Type III distribution given parameters (<code class="reqn">\mu</code>, <code class="reqn">\sigma</code>, and <code class="reqn">\gamma</code>) computed by <code><a href="#topic+parpe3">parpe3</a></code>. These parameters are equal to the product moments: mean, standard deviation, and skew (see <code><a href="#topic+pmoms">pmoms</a></code>). The cumulative distribution function is
</p>
<p style="text-align: center;"><code class="reqn">F(x) = \frac{G\left(\alpha,\frac{Y}{\beta}\right)}{\Gamma(\alpha)} \mbox{,}</code>
</p>

<p>for <code class="reqn">\gamma \ne 0</code> and where <code class="reqn">F(x)</code> is the nonexceedance probability for quantile <code class="reqn">x</code>, <code class="reqn">G</code> is defined below and is related to the incomplete gamma function of <span class="rlang"><b>R</b></span> (<code>pgamma()</code>), <code class="reqn">\Gamma</code> is the complete gamma function, <code class="reqn">\xi</code> is a location parameter, <code class="reqn">\beta</code> is a scale parameter, <code class="reqn">\alpha</code> is a shape parameter, and <code class="reqn">Y = x - \xi</code> if <code class="reqn">\gamma &gt; 0</code> and <code class="reqn">Y = \xi - x</code> if <code class="reqn">\gamma &lt; 0</code>. These three &ldquo;new&rdquo; parameters are related to the product moments by
</p>
<p style="text-align: center;"><code class="reqn">\alpha = 4/\gamma^2 \mbox{,}</code>
</p>

<p style="text-align: center;"><code class="reqn">\beta  = \frac{1}{2}\sigma |\gamma| \mbox{,}</code>
</p>

<p style="text-align: center;"><code class="reqn">\xi = \mu - 2\sigma/\gamma \mbox{.}</code>
</p>

<p>Lastly,  the function <code class="reqn">G(\alpha,x)</code> is
</p>
<p style="text-align: center;"><code class="reqn">G(\alpha,x) = \int_0^x t^{(a-1)} \exp(-t)\, \mathrm{d}t \mbox{.}</code>
</p>

<p>If <code class="reqn">\gamma = 0</code>, the distribution is symmetrical and simply is the normal distribution with mean and standard deviation of <code class="reqn">\mu</code> and <code class="reqn">\sigma</code>, respectively. Internally, the <code class="reqn">\gamma = 0</code> condition is implemented by <code>pnorm()</code>. If <code class="reqn">\gamma &gt; 0</code>, the distribution is right-tail heavy, and <code class="reqn">F(x)</code> is the returned nonexceedance probability. On the other hand if <code class="reqn">\gamma &lt; 0</code>, the distribution is left-tail heavy and <code class="reqn">1-F(x)</code> is the actual nonexceedance probability that is returned.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cdfpe3(x, para)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cdfpe3_+3A_x">x</code></td>
<td>
<p>A real value vector.</p>
</td></tr>
<tr><td><code id="cdfpe3_+3A_para">para</code></td>
<td>
<p>The parameters from <code><a href="#topic+parpe3">parpe3</a></code> or  <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Nonexceedance probability (<code class="reqn">F</code>) for <code class="reqn">x</code>.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Hosking, J.R.M., 1990, L-moments&mdash;Analysis and estimation of
distributions using linear combinations of order statistics: Journal
of the Royal Statistical Society, Series B, v. 52, pp. 105&ndash;124.
</p>
<p>Hosking, J.R.M., 1996, FORTRAN routines for use with the method of L-moments:
Version 3, IBM Research Report RC20525, T.J. Watson Research Center,
Yorktown Heights, New York.
</p>
<p>Hosking, J.R.M., and Wallis, J.R., 1997, Regional frequency analysis&mdash;An
approach based on L-moments: Cambridge University Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pdfpe3">pdfpe3</a></code>, <code><a href="#topic+quape3">quape3</a></code>, <code><a href="#topic+lmompe3">lmompe3</a></code>, <code><a href="#topic+parpe3">parpe3</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>  lmr &lt;- lmoms(c(123,34,4,654,37,78))
  cdfpe3(50,parpe3(lmr))
</code></pre>

<hr>
<h2 id='cdfray'>Cumulative Distribution Function of the Rayleigh Distribution</h2><span id='topic+cdfray'></span>

<h3>Description</h3>

<p>This function computes the cumulative probability or nonexceedance probability of the Rayleigh distribution given parameters (<code class="reqn">\xi</code> and <code class="reqn">\alpha</code>) computed by <code><a href="#topic+parray">parray</a></code>. The cumulative distribution function is
</p>
<p style="text-align: center;"><code class="reqn">F(x) =  1 - \mathrm{exp}[-(x - \xi)^2/(2\alpha^2)]\mbox{,}</code>
</p>
<p> where <code class="reqn">F(x)</code> is the nonexceedance probability for quantile <code class="reqn">x</code>, <code class="reqn">\xi</code> is a location parameter, and <code class="reqn">\alpha</code> is a scale parameter.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cdfray(x, para)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cdfray_+3A_x">x</code></td>
<td>
<p>A real value vector.</p>
</td></tr>
<tr><td><code id="cdfray_+3A_para">para</code></td>
<td>
<p>The parameters from <code><a href="#topic+parray">parray</a></code> or  <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Nonexceedance probability (<code class="reqn">F</code>) for <code class="reqn">x</code>.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Hosking, J.R.M., 1986, The theory of probability weighted moments:
Research Report RC12210, IBM Research Division, Yorkton Heights, N.Y.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pdfray">pdfray</a></code>, <code><a href="#topic+quaray">quaray</a></code>, <code><a href="#topic+lmomray">lmomray</a></code>, <code><a href="#topic+parray">parray</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>  lmr &lt;- lmoms(c(123,34,4,654,37,78))
  cdfray(50,parray(lmr))
</code></pre>

<hr>
<h2 id='cdfrevgum'>Cumulative Distribution Function of the Reverse Gumbel Distribution</h2><span id='topic+cdfrevgum'></span>

<h3>Description</h3>

<p>This function computes the cumulative probability or nonexceedance probability of the Reverse Gumbel distribution given parameters (<code class="reqn">\xi</code> and <code class="reqn">\alpha</code>) computed by <code><a href="#topic+parrevgum">parrevgum</a></code>. The cumulative distribution function is
</p>
<p style="text-align: center;"><code class="reqn">F(x) = 1 - \mathrm{exp}(-\mathrm{exp}(Y)) \mbox{,}</code>
</p>

<p>where
</p>
<p style="text-align: center;"><code class="reqn">Y = -\frac{x - \xi}{\alpha} \mbox{,}</code>
</p>

<p>where <code class="reqn">F(x)</code> is the nonexceedance probability for quantile <code class="reqn">x</code>, <code class="reqn">\xi</code> is a location parameter, and <code class="reqn">\alpha</code> is a scale parameter.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cdfrevgum(x, para)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cdfrevgum_+3A_x">x</code></td>
<td>
<p>A real value vector.</p>
</td></tr>
<tr><td><code id="cdfrevgum_+3A_para">para</code></td>
<td>
<p>The parameters from <code><a href="#topic+parrevgum">parrevgum</a></code> or  <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Nonexceedance probability (<code class="reqn">F</code>) for <code class="reqn">x</code>.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Hosking, J.R.M., 1990, L-moments&mdash;Analysis and estimation of
distributions using linear combinations of order statistics: Journal
of the Royal Statistical Society, Series B, v. 52, pp. 105&ndash;124.
</p>
<p>Hosking, J.R.M., 1995, The use of L-moments in the analysis of censored data,
in Recent Advances in Life-Testing and Reliability, edited by N. Balakrishnan,
chapter 29, CRC Press, Boca Raton, Fla., pp. 546&ndash;560.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pdfrevgum">pdfrevgum</a></code>, <code><a href="#topic+quarevgum">quarevgum</a></code>, <code><a href="#topic+lmomrevgum">lmomrevgum</a></code>, <code><a href="#topic+parrevgum">parrevgum</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'># See p. 553 of Hosking (1995)
# Data listed in Hosking (1995, table 29.3, p. 553)
D &lt;- c(-2.982, -2.849, -2.546, -2.350, -1.983, -1.492, -1.443,
       -1.394, -1.386, -1.269, -1.195, -1.174, -0.854, -0.620,
       -0.576, -0.548, -0.247, -0.195, -0.056, -0.013,  0.006,
        0.033,  0.037,  0.046,  0.084,  0.221,  0.245,  0.296)
D &lt;- c(D,rep(.2960001,40-28)) # 28 values, but Hosking mentions
                              # 40 values in total
z &lt;-  pwmRC(D,threshold=.2960001)
str(z)
# Hosking reports B-type L-moments for this sample are
# lamB1 = -0.516 and lamB2 = 0.523
btypelmoms &lt;- pwm2lmom(z$Bbetas)
# My version of R reports lamB1 = -0.5162 and lamB2 = 0.5218
str(btypelmoms)
rg.pars &lt;- parrevgum(btypelmoms,z$zeta)
str(rg.pars)
# Hosking reports xi=0.1636 and alpha=0.9252 for the sample
# My version of R reports xi = 0.1635 and alpha = 0.9254
F  &lt;- nonexceeds()
PP &lt;- pp(D) # plotting positions of the data
D  &lt;- sort(D)
plot(D,PP)
lines(D,cdfrevgum(D,rg.pars))
</code></pre>

<hr>
<h2 id='cdfrice'>Cumulative Distribution Function of the Rice Distribution</h2><span id='topic+cdfrice'></span>

<h3>Description</h3>

<p>This function computes the cumulative probability or nonexceedance probability of the Rice distribution given parameters (<code class="reqn">\nu</code> and <code class="reqn">\mathrm{SNR}</code>) computed by <code><a href="#topic+parrice">parrice</a></code>. The cumulative distribution function is complex and numerical integration of the probability density function <code><a href="#topic+pdfrice">pdfrice</a></code> is used.
</p>
<p style="text-align: center;"><code class="reqn">
F(x) = 1 - Q\biggl(\frac{\nu}{\alpha}, \frac{x}{\alpha}\biggr)\mbox{,}
</code>
</p>

<p>where <code class="reqn">F(x)</code> is the nonexceedance probability for quantile <code class="reqn">x</code>, <code class="reqn">Q(a,b)</code> is the Marcum Q-function, and <code class="reqn">\nu/\alpha</code> is a form of signal-to-noise ratio <code class="reqn">\mathrm{SNR}</code>. If <code class="reqn">\nu=0</code>, then the Rayleigh distribution results and <code><a href="#topic+pdfray">pdfray</a></code> is used. The Marcum Q-function is difficult to work with and the <span class="pkg">lmomco</span> uses the <code>integrate</code> function on <code><a href="#topic+pdfrice">pdfrice</a></code> (however, see the Note).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cdfrice(x, para)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cdfrice_+3A_x">x</code></td>
<td>
<p>A real value vector.</p>
</td></tr>
<tr><td><code id="cdfrice_+3A_para">para</code></td>
<td>
<p>The parameters from <code><a href="#topic+parrice">parrice</a></code> or  <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Nonexceedance probability (<code class="reqn">F</code>) for <code class="reqn">x</code>.
</p>


<h3>Note</h3>

<p>A user of <span class="pkg">lmomco</span> reported that the Marcum Q function can be computed using <span class="rlang"><b>R</b></span> functions. An implementation is shown in this note.
</p>
<pre>
See NEWS file and entries for version 2.0.1 for this "R Marcum"
"marcumq" &lt;- function(a, b, nu=1) {
      pchisq(b^2, df=2*nu, ncp=a^2, lower.tail=FALSE) }
</pre>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Asquith, W.H., 2011, Distributional analysis with L-moment statistics using the R environment for statistical computing: Createspace Independent Publishing Platform, ISBN 978&ndash;146350841&ndash;8.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pdfrice">pdfrice</a></code>, <code><a href="#topic+quarice">quarice</a></code>, <code><a href="#topic+lmomrice">lmomrice</a></code>, <code><a href="#topic+parrice">parrice</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>lmr &lt;- vec2lmom(c(45,0.27), lscale=FALSE)
cdfrice(35,parrice(lmr))
</code></pre>

<hr>
<h2 id='cdfsla'>Cumulative Distribution Function of the Slash Distribution</h2><span id='topic+cdfsla'></span>

<h3>Description</h3>

<p>This function computes the cumulative probability or nonexceedance probability of the Slash distribution given parameters (<code class="reqn">\xi</code> and <code class="reqn">\alpha</code>) of the distribution provided by <code><a href="#topic+parsla">parsla</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.  The cumulative distribution function is
</p>
<p style="text-align: center;"><code class="reqn">F(x) = \Phi(Y) - [\phi(0) - \phi(Y)]/Y \mbox{,}</code>
</p>

<p>for <code class="reqn">Y \ne 0</code> and
</p>
<p style="text-align: center;"><code class="reqn">F(x) = 1/2 \mbox{,}</code>
</p>

<p>for <code class="reqn">Y = 0</code>, where <code class="reqn">F(x)</code> is the nonexceedance probability for quantile <code class="reqn">x</code>, <code class="reqn">Y = (x - \xi)/\alpha</code>, <code class="reqn">\xi</code> is a location parameter, and <code class="reqn">\alpha</code> is a scale parameter. The function <code class="reqn">\Phi(Y)</code> is the cumulative distribution function of the Standard Normal distribution, and <code class="reqn">\phi(Y)</code> is the probability density function of the Standard Normal distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cdfsla(x, para)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cdfsla_+3A_x">x</code></td>
<td>
<p>A real value vector.</p>
</td></tr>
<tr><td><code id="cdfsla_+3A_para">para</code></td>
<td>
<p>The parameters from <code><a href="#topic+parsla">parsla</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Nonexceedance probability (<code class="reqn">F</code>) for <code class="reqn">x</code>.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Rogers, W.H., and Tukey, J.W., 1972, Understanding some long-tailed symmetrical distributions: Statistica Neerlandica, v. 26, no. 3, pp. 211&ndash;226.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pdfsla">pdfsla</a></code>, <code><a href="#topic+quasla">quasla</a></code>, <code><a href="#topic+lmomsla">lmomsla</a></code>, <code><a href="#topic+parsla">parsla</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>  para &lt;- c(12, 1.2)
  cdfsla(50, vec2par(para, type="sla"))
</code></pre>

<hr>
<h2 id='cdfsmd'>Cumulative Distribution Function of the Singh&ndash;Maddala Distribution</h2><span id='topic+cdfsmd'></span>

<h3>Description</h3>

<p>This function computes the cumulative probability or nonexceedance probability of the Singh&ndash;Maddala (Burr Type XII) distribution given parameters (<code class="reqn">a</code>, <code class="reqn">b</code>, and <code class="reqn">q</code>) of the distribution computed by <code><a href="#topic+parsmd">parsmd</a></code>. The cumulative distribution function is
</p>
<p style="text-align: center;"><code class="reqn">F(x) = 1 - \biggl(1 + \bigl[ (x - \xi) / a \bigr]^b \biggl)^{-q}\mbox{,}</code>
</p>

<p>where <code class="reqn">F(x)</code> is the nonexceedance probability for quantile <code class="reqn">x</code> with <code class="reqn">0 \le x \le \infty</code>, <code class="reqn">\xi</code> is a location parameter, <code class="reqn">a</code> is a scale parameter (<code class="reqn">a &gt; 0</code>), <code class="reqn">b</code> is a shape parameter (<code class="reqn">b &gt; 0</code>), and <code class="reqn">q</code> is another shape parameter (<code class="reqn">q &gt; 0</code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cdfsmd(x, para)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cdfsmd_+3A_x">x</code></td>
<td>
<p>A real value vector.</p>
</td></tr>
<tr><td><code id="cdfsmd_+3A_para">para</code></td>
<td>
<p>The parameters from <code><a href="#topic+parsmd">parsmd</a></code> or  <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Nonexceedance probability (<code class="reqn">F</code>) for <code class="reqn">x</code>.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Kumar, D., 2017, The Singh&ndash;Maddala distribution&mdash;Properties and estimation: International Journal of System Assurance Engineering and Management, v. 8, no. S2, 15 p., <a href="https://doi.org/10.1007/s13198-017-0600-1">doi:10.1007/s13198-017-0600-1</a>.
</p>
<p>Shahzad, M.N., and Zahid, A., 2013, Parameter estimation of Singh Maddala distribution by moments: International Journal of Advanced Statistics and Probability, v. 1, no. 3, pp. 121&ndash;131, <a href="https://doi.org/10.14419/ijasp.v1i3.1206">doi:10.14419/ijasp.v1i3.1206</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pdfsmd">pdfsmd</a></code>, <code><a href="#topic+quasmd">quasmd</a></code>, <code><a href="#topic+lmomsmd">lmomsmd</a></code>, <code><a href="#topic+parsmd">parsmd</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'># The SMD approximating the normal and use x=0
tau4_of_normal &lt;- 30 * pi^-1 * atan(sqrt(2)) - 9 # from theory
cdfsmd(0, parsmd( vec2lmom( c( -pi, pi, 0, tau4_of_normal ) ) ) ) # 0.7138779
pnorm( 0, mean=-pi, sd=pi*sqrt(pi))                               # 0.7136874

## Not run: 
t3 &lt;- 0.6
t4 &lt;- (t3 * (1 + 5 * t3))/(5 + t3) # L-kurtosis of GPA from lmrdia()
paraA &lt;- parsmd( vec2lmom( c( -1000, 200, t3, t4-0.02 ) ) )
paraB &lt;- parsmd( vec2lmom( c( -1000, 200, t3, t4      ) ) )
paraC &lt;- parsmd( vec2lmom( c( -1000, 200, t3, t4+0.02 ) ) )
FF &lt;- nonexceeds(); x &lt;- quasmd(FF, paraA)
plot( x, prob2grv(cdfsmd(x, paraA)), col="red", type="l",
      xlab="Quantile", ylab="Gumbel Reduced Variate, prob2grv()")
lines(x, prob2grv(cdfsmd(x, paraB)), col="green")
lines(x, prob2grv(cdfsmd(x, paraC)), col="blue" ) # 
## End(Not run)
</code></pre>

<hr>
<h2 id='cdfst3'>Cumulative Distribution Function of the 3-Parameter Student t Distribution</h2><span id='topic+cdfst3'></span>

<h3>Description</h3>

<p>This function computes the cumulative probability or nonexceedance probability of the  3-parameter Student t distribution given parameters (<code class="reqn">\xi</code>, <code class="reqn">\alpha</code>, <code class="reqn">\nu</code>) computed by <code><a href="#topic+parst3">parst3</a></code>.  There is no explicit solution for the cumulative distribution function for value <code>X</code> but built-in <span class="rlang"><b>R</b></span> functions can be used. For <code>U</code> = <code class="reqn">\xi</code> and <code>A</code> = <code class="reqn">\alpha</code> and  for <code class="reqn">1.001 \le \nu \le 10^5.5</code>, one can use <code>pt((X-U)/A, N)</code> for <code>N</code> = <code class="reqn">\nu</code>. The <span class="rlang"><b>R</b></span> function <code>pt</code> is used for the 1-parameter Student t cumulative distribution function. The limits for <code class="reqn">\nu</code> stem from study of ability for theoretical integration of the quantile function to produce viable <code class="reqn">\tau_4</code> and <code class="reqn">\tau_6</code> (see <code>inst/doc/t4t6/studyST3.R</code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cdfst3(x, para, paracheck=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cdfst3_+3A_x">x</code></td>
<td>
<p>A real value vector.</p>
</td></tr>
<tr><td><code id="cdfst3_+3A_para">para</code></td>
<td>
<p>The parameters from <code><a href="#topic+parst3">parst3</a></code> or  <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
<tr><td><code id="cdfst3_+3A_paracheck">paracheck</code></td>
<td>
<p>A logical on whether the parameter should be check for validity.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Nonexceedance probability (<code class="reqn">F</code>) for <code class="reqn">x</code>.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Asquith, W.H., 2011, Distributional analysis with L-moment statistics using the R environment for statistical computing: Createspace Independent Publishing Platform, ISBN 978&ndash;146350841&ndash;8.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pdfst3">pdfst3</a></code>, <code><a href="#topic+quast3">quast3</a></code>, <code><a href="#topic+lmomst3">lmomst3</a></code>, <code><a href="#topic+parst3">parst3</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  lmr &lt;- lmoms(c(123, 34, 4, 654, 37, 78))
  cdfst3(191.5143, parst3(lmr)) # 75th percentile
</code></pre>

<hr>
<h2 id='cdftexp'>Cumulative Distribution Function of the Truncated Exponential Distribution</h2><span id='topic+cdftexp'></span>

<h3>Description</h3>

<p>This function computes the cumulative probability or nonexceedance probability of the Truncated Exponential distribution given parameters (<code class="reqn">\psi</code> and <code class="reqn">\alpha</code>) computed by <code><a href="#topic+partexp">partexp</a></code>. The parameter <code class="reqn">\psi</code> is the right truncation of the distribution and <code class="reqn">\alpha</code> is a scale parameter. The cumulative distribution function, letting <code class="reqn">\beta = 1/\alpha</code> to match nomenclature of Vogel and others (2008), is
</p>
<p style="text-align: center;"><code class="reqn">F(x) = \frac{1-\mathrm{exp}(-\beta{t})}{1-\mathrm{exp}(-\beta\psi)}\mbox{,}</code>
</p>

<p>where <code class="reqn">F(x)</code> is the nonexceedance probability for the quantile <code class="reqn">0 \le x \le \psi</code> and <code class="reqn">\psi &gt; 0</code> and <code class="reqn">\alpha &gt; 0</code>. This distribution represents a nonstationary Poisson process.
</p>
<p>The distribution is restricted to a narrow range of L-CV (<code class="reqn">\tau_2 = \lambda_2/\lambda_1</code>). If <code class="reqn">\tau_2 = 1/3</code>, the process represented is a stationary Poisson for which the cumulative distribution function is simply the uniform distribution and <code class="reqn">F(x) = x/\psi</code>. If <code class="reqn">\tau_2 = 1/2</code>, then the distribution is represented as the usual exponential distribution with a location parameter of zero and a rate parameter <code class="reqn">\beta</code> (scale parameter <code class="reqn">\alpha = 1/\beta</code>). These two limiting conditions are supported.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cdftexp(x, para)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cdftexp_+3A_x">x</code></td>
<td>
<p>A real value vector.</p>
</td></tr>
<tr><td><code id="cdftexp_+3A_para">para</code></td>
<td>
<p>The parameters from <code><a href="#topic+partexp">partexp</a></code> or  <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Nonexceedance probability (<code class="reqn">F</code>) for <code class="reqn">x</code>.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Vogel, R.M., Hosking, J.R.M., Elphick, C.S., Roberts, D.L., and Reed, J.M., 2008, Goodness of fit of probability distributions for sightings as species approach extinction: Bulletin of Mathematical Biology, DOI 10.1007/s11538-008-9377-3, 19 p.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pdftexp">pdftexp</a></code>, <code><a href="#topic+quatexp">quatexp</a></code>, <code><a href="#topic+lmomtexp">lmomtexp</a></code>, <code><a href="#topic+partexp">partexp</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>cdftexp(50,partexp(vec2lmom(c(40,0.38), lscale=FALSE)))
## Not run: 
F &lt;- seq(0,1,by=0.001)
A &lt;- partexp(vec2lmom(c(100, 1/2), lscale=FALSE))
x &lt;- quatexp(F, A)
plot(x, cdftexp(x, A), pch=16, type='l')
by &lt;- 0.01; lcvs &lt;- c(1/3, seq(1/3+by, 1/2-by, by=by), 1/2)
reds &lt;- (lcvs - 1/3)/max(lcvs - 1/3)
for(lcv in lcvs) {
    A &lt;- partexp(vec2lmom(c(100, lcv), lscale=FALSE))
    x &lt;- quatexp(F, A)
    lines(x, cdftexp(x, A), pch=16, col=rgb(reds[lcvs == lcv],0,0))
}

  # Vogel and others (2008) example sighting times for the bird
  # Eskimo Curlew, inspection shows that these are fairly uniform.
  # There is a sighting about every year to two.
  T &lt;- c(1946, 1947, 1948, 1950, 1955, 1956, 1959, 1960, 1961,
         1962, 1963, 1964, 1968, 1970, 1972, 1973, 1974, 1976,
         1977, 1980, 1981, 1982, 1982, 1983, 1985)
  R &lt;- 1945 # beginning of record
  S &lt;- T - R
  lmr &lt;- lmoms(S)
  PARcurlew &lt;- partexp(lmr)
  # read the warning message and then force the texp to the
  # stationary process model (min(tau_2) = 1/3).
  lmr$ratios[2] &lt;- 1/3
  lmr$lambdas[2] &lt;- lmr$lambdas[1]*lmr$ratios[2]
  PARcurlew &lt;- partexp(lmr)
  Xmax &lt;- quatexp(1, PARcurlew)
  X &lt;- seq(0,Xmax, by=.1)
  plot(X, cdftexp(X,PARcurlew), type="l")
  # or use the MVUE estimator
  TE &lt;- max(S)*((length(S)+1)/length(S)) # Time of Extinction
  lines(X, punif(X, min=0, max=TE), col=2)
## End(Not run)
</code></pre>

<hr>
<h2 id='cdftri'>Cumulative Distribution Function of the Asymmetric Triangular Distribution</h2><span id='topic+cdftri'></span>

<h3>Description</h3>

<p>This function computes the cumulative probability or nonexceedance probability of the Asymmetric Triangular distribution given parameters (<code class="reqn">\nu</code>, <code class="reqn">\omega</code>, and <code class="reqn">\psi</code>) computed by <code><a href="#topic+partri">partri</a></code>. The cumulative distribution function is
</p>
<p style="text-align: center;"><code class="reqn">F(x) = \frac{(x - \nu)^2}{(\omega-\nu)(\psi-\nu)}\mbox{,}</code>
</p>

<p>for <code class="reqn">x &lt; \omega</code>,
</p>
<p style="text-align: center;"><code class="reqn">F(x) = 1 - \frac{(\psi - x)^2}{(\psi - \omega)(\psi - \nu)}\mbox{,}</code>
</p>

<p>for <code class="reqn">x &gt;  \omega</code>, and
</p>
<p style="text-align: center;"><code class="reqn">F(x) = \frac{(\omega - \nu)}{(\psi - \nu)}\mbox{,}</code>
</p>

<p>for <code class="reqn">x = \omega</code>
where <code class="reqn">x(F)</code> is the quantile for nonexceedance probability <code class="reqn">F</code>, <code class="reqn">\nu</code> is the minimum, <code class="reqn">\psi</code> is the maximum, and <code class="reqn">\omega</code> is the mode of the distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cdftri(x, para)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cdftri_+3A_x">x</code></td>
<td>
<p>A real value vector.</p>
</td></tr>
<tr><td><code id="cdftri_+3A_para">para</code></td>
<td>
<p>The parameters from <code><a href="#topic+partri">partri</a></code> or  <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Nonexceedance probability (<code class="reqn">F</code>) for <code class="reqn">x</code>.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>See Also</h3>

<p><code><a href="#topic+pdftri">pdftri</a></code>, <code><a href="#topic+quatri">quatri</a></code>, <code><a href="#topic+lmomtri">lmomtri</a></code>, <code><a href="#topic+partri">partri</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>  lmr &lt;- lmoms(c(46, 70, 59, 36, 71, 48, 46, 63, 35, 52))
  cdftri(50,partri(lmr))
</code></pre>

<hr>
<h2 id='cdfwak'>Cumulative Distribution Function of the Wakeby Distribution</h2><span id='topic+cdfwak'></span>

<h3>Description</h3>

<p>This function computes the cumulative probability or nonexceedance probability of the Wakeby distribution given parameters (<code class="reqn">\xi</code>, <code class="reqn">\alpha</code>, <code class="reqn">\beta</code>, <code class="reqn">\gamma</code>, and <code class="reqn">\delta</code>) computed by <code><a href="#topic+parwak">parwak</a></code>. The cumulative distribution function has no explicit form, but the <code><a href="#topic+pdfwak">pdfwak</a></code> (density) and <code><a href="#topic+quawak">quawak</a></code> (quantiles) do.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cdfwak(x, para)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cdfwak_+3A_x">x</code></td>
<td>
<p>A real value vector.</p>
</td></tr>
<tr><td><code id="cdfwak_+3A_para">para</code></td>
<td>
<p>The parameters from <code><a href="#topic+parwak">parwak</a></code> or  <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Nonexceedance probability (<code class="reqn">F</code>) for <code class="reqn">x</code>.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Hosking, J.R.M., 1990, L-moments&mdash;Analysis and estimation of
distributions using linear combinations of order statistics: Journal
of the Royal Statistical Society, Series B, v. 52, pp. 105&ndash;124.
</p>
<p>Hosking, J.R.M., 1996, FORTRAN routines for use with the method of L-moments:
Version 3, IBM Research Report RC20525, T.J. Watson Research Center,
Yorktown Heights, New York.
</p>
<p>Hosking, J.R.M., and Wallis, J.R., 1997, Regional frequency analysis&mdash;An
approach based on L-moments: Cambridge University Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pdfwak">pdfwak</a></code>, <code><a href="#topic+quawak">quawak</a></code>, <code><a href="#topic+lmomwak">lmomwak</a></code>, <code><a href="#topic+parwak">parwak</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>  lmr &lt;- lmoms(c(123,34,4,654,37,78))
  cdfwak(50,parwak(lmr))
</code></pre>

<hr>
<h2 id='cdfwei'>Cumulative Distribution Function of the Weibull Distribution</h2><span id='topic+cdfwei'></span>

<h3>Description</h3>

<p>This function computes the cumulative probability or nonexceedance probability of the Weibull distribution given parameters (<code class="reqn">\zeta</code>, <code class="reqn">\beta</code>, and <code class="reqn">\delta</code>) of the distribution computed by <code><a href="#topic+parwei">parwei</a></code>. The cumulative distribution function is
</p>
<p style="text-align: center;"><code class="reqn">F(x) = 1 - \exp(Y^\delta) \mbox{,}</code>
</p>

<p>where <code class="reqn">Y</code> is
</p>
<p style="text-align: center;"><code class="reqn">Y = -\frac{x+\zeta}{\beta}\mbox{,}</code>
</p>

<p>where <code class="reqn">F(x)</code> is the nonexceedance probability for quantile <code class="reqn">x</code>,
<code class="reqn">\zeta</code> is a location parameter, <code class="reqn">\beta</code> is a scale parameter, and
<code class="reqn">\delta</code> is a shape parameter.
</p>
<p>The Weibull distribution is a reverse Generalized Extreme Value distribution.  As result, the Generalized Extreme Value algorithms are used for implementation of the Weibull in this package. The relations between the Generalized Extreme Value parameters (<code class="reqn">\xi</code>, <code class="reqn">\alpha</code>, and <code class="reqn">\kappa</code>) are
</p>
<p style="text-align: center;"><code class="reqn">\kappa = 1/\delta \mbox{,}</code>
</p>

<p style="text-align: center;"><code class="reqn">\alpha = \beta/\delta \mbox{, and}</code>
</p>

<p style="text-align: center;"><code class="reqn">\xi = \zeta - \beta \mbox{,}</code>
</p>

<p>which are taken from Hosking and Wallis (1997).
</p>
<p>In <span class="rlang"><b>R</b></span>, the cumulative distribution function of the Weibull distribution is <code>pweibull</code>. Given a Weibull parameter object <code>para</code>, the <span class="rlang"><b>R</b></span> syntax is <code>pweibull(x+para$para[1], para$para[3],</code> <br /> <code>scale=para$para[2])</code>. For the current implementation for this package, the reversed Generalized Extreme Value distribution is used <code>1-cdfgev(-x,para)</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cdfwei(x, para)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cdfwei_+3A_x">x</code></td>
<td>
<p>A real value vector.</p>
</td></tr>
<tr><td><code id="cdfwei_+3A_para">para</code></td>
<td>
<p>The parameters from <code><a href="#topic+parwei">parwei</a></code> or  <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Nonexceedance probability (<code class="reqn">F</code>) for <code class="reqn">x</code>.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Hosking, J.R.M., and Wallis, J.R., 1997, Regional frequency analysis&mdash;An
approach based on L-moments: Cambridge University Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pdfwei">pdfwei</a></code>, <code><a href="#topic+quawei">quawei</a></code>, <code><a href="#topic+lmomwei">lmomwei</a></code>, <code><a href="#topic+parwei">parwei</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>  # Evaluate Weibull deployed here and within R (pweibull)
  lmr &lt;- lmoms(c(123,34,4,654,37,78))
  WEI &lt;- parwei(lmr)
  F1  &lt;- cdfwei(50,WEI)
  F2  &lt;- pweibull(50+WEI$para[1],shape=WEI$para[3],scale=WEI$para[2])
  if(F1 == F2) EQUAL &lt;- TRUE

  # The Weibull is a reversed generalized extreme value
  Q &lt;- sort(rlmomco(34,WEI)) # generate Weibull sample
  lm1 &lt;- lmoms(Q)    # regular L-moments
  lm2 &lt;- lmoms(-Q)   # L-moment of negated (reversed) data
  WEI &lt;- parwei(lm1) # parameters of Weibull
  GEV &lt;- pargev(lm2) # parameters of GEV
  F &lt;- nonexceeds()  # Get a vector of nonexceedance probs
  plot(pp(Q),Q)
  lines(cdfwei(Q,WEI),Q,lwd=5,col=8)
  lines(1-cdfgev(-Q,GEV),Q,col=2) # line overlaps previous
</code></pre>

<hr>
<h2 id='check.fs'>Check Vector of Nonexceedance Probabilities </h2><span id='topic+check.fs'></span>

<h3>Description</h3>

<p>This function checks that a nonexceedance probability (<code class="reqn">F</code>) is in the <code class="reqn">0 \le F \le 1</code> range.
It does not check that the distribution specified by parameters for <code class="reqn">F = 0</code> or <code class="reqn">F = 1</code> is valid. End point checking is left to additional internal checks within the functions implementing the distribution. The function is intended for internal use to build a flow of logic throughout the distribution functions. Users are not anticipated to need this function themselves. The <code><a href="#topic+check.fs">check.fs</a></code> function is separate because of the heavy use of the logic across a myriad of functions in <span class="pkg">lmomco</span>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>check.fs(fs)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="check.fs_+3A_fs">fs</code></td>
<td>
<p>A vector of nonexceedance probablity values.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>TRUE</code></td>
<td>
<p>The nonexceedance probabilities are valid.</p>
</td></tr>
<tr><td><code>FALSE</code></td>
<td>
<p>The nonexceedance probabilities are invalid.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>See Also</h3>

<p><code><a href="#topic+quaaep4">quaaep4</a></code>,
<code><a href="#topic+quaaep4kapmix">quaaep4kapmix</a></code>,
<code><a href="#topic+quacau">quacau</a></code>,
<code><a href="#topic+quaemu">quaemu</a></code>,
<code><a href="#topic+quaexp">quaexp</a></code>,
<code><a href="#topic+quagam">quagam</a></code>,
<code><a href="#topic+quagep">quagep</a></code>,
<code><a href="#topic+quagev">quagev</a></code>,
<code><a href="#topic+quagld">quagld</a></code>,
<code><a href="#topic+quaglo">quaglo</a></code>,
<code><a href="#topic+quagno">quagno</a></code>,
<code><a href="#topic+quagov">quagov</a></code>,
<code><a href="#topic+quagpa">quagpa</a></code>,
<code><a href="#topic+quagum">quagum</a></code>,
<code><a href="#topic+quakap">quakap</a></code>,
<code><a href="#topic+quakmu">quakmu</a></code>,
<code><a href="#topic+quakur">quakur</a></code>,
<code><a href="#topic+qualap">qualap</a></code>,
<code><a href="#topic+qualmrq">qualmrq</a></code>,
<code><a href="#topic+qualn3">qualn3</a></code>,
<code><a href="#topic+quanor">quanor</a></code>,
<code><a href="#topic+quape3">quape3</a></code>,
<code><a href="#topic+quaray">quaray</a></code>,
<code><a href="#topic+quarevgum">quarevgum</a></code>,
<code><a href="#topic+quarice">quarice</a></code>,
<code><a href="#topic+quasla">quasla</a></code>,
<code><a href="#topic+quast3">quast3</a></code>,
<code><a href="#topic+quatexp">quatexp</a></code>,
<code><a href="#topic+quawak">quawak</a></code>,
<code><a href="#topic+quawei">quawei</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>F &lt;- c(0.5,0.7,0.9,1.1)
if(check.fs(F) == FALSE) cat("Bad nonexceedances 0&lt;F&lt;1\n")
</code></pre>

<hr>
<h2 id='check.pdf'>Check and Potentially Graph Probability Density Functions </h2><span id='topic+check.pdf'></span>

<h3>Description</h3>

<p>This convenience function checks that a given probability density function (<code>pdf</code>) from <span class="pkg">lmomco</span> appears to numerically be valid. By definition a <code>pdf</code> function must integrate to unity. This function permits some flexibility in the limits of integration and provides a high-level interface from graphical display of the <code>pdf</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>check.pdf(pdf, para, lowerF=0.001, upperF=0.999,
               eps=0.02, verbose=FALSE, plot=FALSE, plotlowerF=0.001,
               plotupperF=0.999, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="check.pdf_+3A_pdf">pdf</code></td>
<td>
<p>A probability density function from <span class="pkg">lmomco</span>.</p>
</td></tr>
<tr><td><code id="check.pdf_+3A_lowerf">lowerF</code></td>
<td>
<p>The lower bounds of nonexceedance probability for the numerical integration.</p>
</td></tr>
<tr><td><code id="check.pdf_+3A_upperf">upperF</code></td>
<td>
<p>The upper bounds of nonexceedance probability for the numerical integration.</p>
</td></tr>
<tr><td><code id="check.pdf_+3A_para">para</code></td>
<td>
<p>The parameters of the distribution.</p>
</td></tr>
<tr><td><code id="check.pdf_+3A_eps">eps</code></td>
<td>
<p>An error term expressing allowable error (deviation) of the numerical integration from unity. (If that is the objective of the call to the <code><a href="#topic+check.pdf">check.pdf</a></code> function.)</p>
</td></tr>
<tr><td><code id="check.pdf_+3A_verbose">verbose</code></td>
<td>
<p>Is verbose output desired?</p>
</td></tr>
<tr><td><code id="check.pdf_+3A_plot">plot</code></td>
<td>
<p>Should a plot (polygon) of the <code>pdf</code> integration be produce?</p>
</td></tr>
<tr><td><code id="check.pdf_+3A_plotlowerf">plotlowerF</code></td>
<td>
<p>Alternative lower limit for the generation of the curve depicting the <code>pdf</code> function.</p>
</td></tr>
<tr><td><code id="check.pdf_+3A_plotupperf">plotupperF</code></td>
<td>
<p>Alternative upper limit for the generation of the curve depicting the <code>pdf</code> function.</p>
</td></tr>
<tr><td><code id="check.pdf_+3A_...">...</code></td>
<td>
<p>Additional arguments that are passed onto the <span class="rlang"><b>R</b></span> function <code>integration</code> function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> structure is returned
</p>
<table>
<tr><td><code>isunity</code></td>
<td>
<p>Given the <code>eps</code> is <code>F</code> close enough.</p>
</td></tr>
<tr><td><code>F</code></td>
<td>
<p>The numerical integration of <code>pdf</code> from <code>lowerF</code> to <code>upperF</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>Examples</h3>

<pre><code class='language-R'>lmrg &lt;- vec2lmom(c( 100, 40, 0.1)) # Arbitrary L-moments
lmrw &lt;- vec2lmom(c(-100, 40,-0.1)) # Reversed Arbitrary L-moments
gev  &lt;- pargev(lmrg) # parameters of Generalized Extreme Value distribution
wei  &lt;- parwei(lmrw) # parameters of Weibull distribution

# The Weibull is a reversed GEV and plots in the following examples show this.
# Two examples that should integrate to "unity" given default parameters.
layout(matrix(c(1,2), 2, 2, byrow = TRUE), respect = TRUE)
check.pdf(pdfgev,gev,plot=TRUE)
check.pdf(pdfwei,wei,plot=TRUE)
</code></pre>

<hr>
<h2 id='claudeprecip'>Annual Maximum Precipitation Data for Claude, Texas</h2><span id='topic+claudeprecip'></span>

<h3>Description</h3>

<p>Annual maximum precipitation data for Claude, Texas
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(claudeprecip)
</code></pre>


<h3>Format</h3>

<p>An <span class="rlang"><b>R</b></span> <code>data.frame</code> with
</p>

<dl>
<dt>YEAR</dt><dd><p>The calendar year of the annual maxima.</p>
</dd>
<dt>DEPTH</dt><dd><p>The depth of 7-day annual maxima rainfall in inches.</p>
</dd>
</dl>



<h3>References</h3>

<p>Asquith, W.H., 1998, Depth-duration frequency of precipitation for
Texas: U.S. Geological Survey Water-Resources Investigations Report
98&ndash;4044, 107 p.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(claudeprecip)
summary(claudeprecip)
</code></pre>

<hr>
<h2 id='clearforkporosity'>Porosity Data</h2><span id='topic+clearforkporosity'></span>

<h3>Description</h3>

<p>Porosity (fraction of void space) from neutron-density, well log for
5,350&ndash;5,400 feet below land surface for Permian Age Clear Fork formation,
Ector County, Texas.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(clearforkporosity)
</code></pre>


<h3>Format</h3>

<p>A data frame with
</p>

<dl>
<dt>POROSITY</dt><dd><p>The pre-sorted porosity data.</p>
</dd>
</dl>



<h3>Details</h3>

<p>Although the porosity data was collected at about 1-foot intervals, these
intervals are not provided in the data frame. Further, the porosity data
has been sorted to disrupt the specific depth to porosity relation to remove
the proprietary nature of the original data.
</p>

<hr>
<h2 id='cmlmomco'>Conditional Mean Residual Quantile Function of the Distributions</h2><span id='topic+cmlmomco'></span>

<h3>Description</h3>

<p>This function computes the Conditional Mean Residual Quantile Function for quantile function <code class="reqn">x(F)</code> (<code><a href="#topic+par2qua">par2qua</a></code>, <code><a href="#topic+qlmomco">qlmomco</a></code>). The function is defined by Nair et al. (2013, p. 68) as
</p>
<p style="text-align: center;"><code class="reqn">\mu(u) = \frac{1}{1-u}\int_u^1 x(p)\; \mathrm{d}p\mbox{,}</code>
</p>

<p>where <code class="reqn">\mu(u)</code> is the conditional mean for nonexceedance probability <code class="reqn">u</code>. The <code class="reqn">\mu(u)</code> is the expectation <code class="reqn">\mathrm{E}[X | X &gt; x]</code>.
The <code class="reqn">\mu(u)</code> also is known as the <em>vitality function</em>. Details can be found in Nair et al. (2013, p. 68) and Kupka and Loo (1989). Mathematically, the vitality function simply is
</p>
<p style="text-align: center;"><code class="reqn">\mu(u) = M(u) + x(u)\mbox{,}</code>
</p>

<p>where <code class="reqn">M(u)</code> is the mean residual quantile function (<code><a href="#topic+rmlmomco">rmlmomco</a></code>), <code class="reqn">x(u)</code> is a constant for <code class="reqn">x(F = u)</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cmlmomco(f, para)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cmlmomco_+3A_f">f</code></td>
<td>
<p>Nonexceedance probability (<code class="reqn">0 \le F \le 1</code>).</p>
</td></tr>
<tr><td><code id="cmlmomco_+3A_para">para</code></td>
<td>
<p>The parameters from <code><a href="#topic+lmom2par">lmom2par</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Conditional mean residual value for <code class="reqn">F</code> or conditional mean life for <code class="reqn">F</code>.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Kupka, J., and Loo, S., 1989, The hazard and vitality measures of ageing: Journal of Applied Probability, v. 26, pp. 532&ndash;542.
</p>
<p>Nair, N.U., Sankaran, P.G., and Balakrishnan, N., 2013, Quantile-based reliability analysis: Springer, New York.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+qlmomco">qlmomco</a></code>, <code><a href="#topic+rmlmomco">rmlmomco</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># It is easiest to think about residual life as starting at the origin, units in days.
A &lt;- vec2par(c(0.0, 2649, 2.11), type="gov") # so set lower bounds = 0.0
qlmomco(0.5, A)  # The median lifetime = 1261 days
rmlmomco(0.5, A) # The average remaining life given survival to the median = 861 days
cmlmomco(0.5, A) # The average total life given survival to the median = 2122 days

# Now create with a nonzero origin
A &lt;- vec2par(c(100, 2649, 2.11), type="gov") # so set lower bounds = 0.0
qlmomco(0.5, A)  # The median lifetime = 1361 days
rmlmomco(0.5, A) # The average remaining life given survival to the median = 861 days
cmlmomco(0.5, A) # The average total life given survival to the median = 2222 days

# Mean life (mu), which shows up in several expressions listed under rmlmomco.
mu1 &lt;- cmlmomco(0,A)
mu2 &lt;- par2lmom(A)$lambdas[1]
mu3 &lt;- reslife.lmoms(0,A)$lambdas[1]
# Each mu is 1289.051 days.
</code></pre>

<hr>
<h2 id='cvm.test.lmomco'>Cramér&ndash;von Mises Test for Goodness-of-Fit</h2><span id='topic+cvm.test.lmomco'></span>

<h3>Description</h3>

<p>The Cramér&ndash;von Mises test for goodness-of-fit is implemented for the order statistics <code class="reqn">x_{1:n} \le x_{i:n} \le x_{n:n}</code> of a sample of size <code class="reqn">n</code>. Define the test statistic (Csörgő and Faraway, 1996) as
</p>
<p style="text-align: center;"><code class="reqn">\omega^2 = \frac{1}{12n} + \sum_{i=1}^n \biggl[\frac{2i-1}{2n} - F_\theta(x_i)\biggr]\mbox{,}</code>
</p>

<p>where <code class="reqn">F_\theta(x)</code> is the cumulative distribution function (continuous) for some distribution having parameters <code class="reqn">\theta</code>. If the value for <code class="reqn">\omega^2</code> is larger than some critical value, reject the null hypothesis. The null hypothesis is that <code class="reqn">F</code> is the function specified by <code class="reqn">\theta</code>, while the alternative hypothesis is that <code class="reqn">F</code> is some other function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cvm.test.lmomco(x, para1, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cvm.test.lmomco_+3A_x">x</code></td>
<td>
<p>A vector of data values.</p>
</td></tr>
<tr><td><code id="cvm.test.lmomco_+3A_para1">para1</code></td>
<td>
<p>The parameters of the distribution.</p>
</td></tr>
<tr><td><code id="cvm.test.lmomco_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass to <code><a href="#topic+par2cdf">par2cdf</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The above definition for <code class="reqn">\omega^2</code> as the Cramér&ndash;von Mises test statistic is consistent with the notation in Csörgő and Faraway (1996) as well as that in package <span class="pkg">goftest</span>. Depending on how the null distribution is defined by other authors and attendant notation, the Cramér&ndash;von Mises statistic can be branded as <code class="reqn">T = n\omega^2</code>. The null distribution herein requires just <code class="reqn">\omega^2</code> and the sample size is delivered separately into the cumulative distribution function:
</p>
<pre>
  goftest::pCvM(omega.sq, n=n, lower.tail=FALSE)
</pre>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> is returned.
</p>
<table>
<tr><td><code>null.dist</code></td>
<td>
<p>The null distribution, which is an echoing of the <code>para</code> argument, which recall for <span class="pkg">lmomco</span> that is contains the distribution abbreviation.</p>
</td></tr>
<tr><td><code>text</code></td>
<td>
<p>The string &ldquo;Cramer&ndash;von Mises test of goodness-of-fit&rdquo;.</p>
</td></tr>
<tr><td><code>statistic</code></td>
<td>
<p>The <code class="reqn">\omega^2</code> as defined above (see <b>Note</b>).</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>The p-value computed from the <code>pCvM()</code> function from the <span class="pkg">goftest</span> package for the null distribution of the test statistic.</p>
</td></tr>
<tr><td><code>source</code></td>
<td>
<p>An attribute identifying the computational source of the L-moments:<br /> &ldquo;cvm.test.lmomco&rdquo;.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>An example of coverage probabilities demonstrating the differences in what the p-values mean on whether the parent is known or the &ldquo;parent&rdquo; is coming from the sample. The p-values are quite different and inference has subtle differences. In ensemble, comparing the test statistic amongst distribution choices might be more informative than a focus on p-values being below a critical alpha.
</p>
<pre>
  parent &lt;- vec2par(c(20, 120), type="gam"); nsim &lt;- 10000
  pp &lt;- nn &lt;- ee &lt;- rep(NA,nsim)
  for(i in 1:nsim) {
    x &lt;- rlmomco(56, parent); lmr &lt;- lmoms(x)
    pp[i] &lt;- cvm.test.lmomco(x,          parent          )$p.value
    nn[i] &lt;- cvm.test.lmomco(x, lmom2par(lmr, type="nor"))$p.value
    ee[i] &lt;- cvm.test.lmomco(x, lmom2par(lmr, type="exp"))$p.value
  }
  message("GAMMA PARENT KNOWN     'rejection rate'=", sum(pp &lt; 0.05)/nsim)
  message("ESTIMATED NORMAL       'rejection rate'=", sum(nn &lt; 0.05)/nsim)
  message("ESTIMATED EXPONENTIAL  'rejection rate'=", sum(ee &lt; 0.05)/nsim)
</pre>
<p>The rejection rate for the Gamma is about 5 percent, which matches the 0.05 specified in the conditional. The Normal is about zero, and the Exponential is about 21 percent. The fitted Normal almost always passes for the real parent, though Gamma, for the sample size and amount of L-skewness involved. The Exponential does not. This illustrates that the p-value can be misleading in the single-sample version of this test. Thus, when fit by parameters from the sample, the test statistic is nearly always smaller than the one for a prespecified set of parameters. The significance level will be smaller than intended.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Csörgő, S., and Faraway, J.J., 1996, The exact and asymptotic distributions of Cramér&ndash;von Mises statistics: Journal of the Royal Statistical Society, Series B, v. 58, pp. 221&ndash;234.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lmrdia">lmrdia</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'># An example in which the test is conducted on a sample but the parent is known.
# This will lead to more precise inference than if the sample parameters are used.
mu &lt;- 120; sd &lt;- 25; para &lt;- vec2par(c(120, 25), type="nor")
x &lt;- rnorm(56, mean=mu, sd=sd)
T1 &lt;- cvm.test.lmomco(x, para)$statistic
T2 &lt;- goftest::cvm.test(x, null="pnorm", mean=mu, sd=sd)$statistic
message("Cramer--von Mises: T1=", round(T1, digits=6), " and T2=", round(T2, digits=6))
</code></pre>

<hr>
<h2 id='dat2bernqua'>Observed Data to Empirical Quantiles through Bernstein or Kantorovich Polynomials </h2><span id='topic+dat2bernqua'></span>

<h3>Description</h3>

<p>The empirical quantile function can be &ldquo;smoothed&rdquo; (Hernández-Maldonado and others, 2012, p. 114) through the Kantorovich polynomial (Muñoz-Pérez and Fernández-Palacín, 1987) for the sample order statistics <code class="reqn">x_{k:n}</code> for a sample of size <code class="reqn">n</code> by
</p>
<p style="text-align: center;"><code class="reqn">\tilde{X}_n(F) = \frac{1}{2}\sum_{k=0}^n (x_{k:n} + x_{(k+1):n}) {n \choose k} F^k (1-F)^{n-k}\mbox{,}</code>
</p>

<p>where <code class="reqn">F</code> is nonexceedance probability, and <code class="reqn">(n\:k)</code> are the binomial coefficients from the <span class="rlang"><b>R</b></span> function <code>choose()</code>, and the special situations for <code class="reqn">k=0</code> and <code class="reqn">k=n</code> are described within the Note section. The form for the Bernstein polynomial is
</p>
<p style="text-align: center;"><code class="reqn">\tilde{X}_n(F) = \sum_{k=0}^{n+1} (x_{k:n}) {n+1 \choose k} F^k (1-F)^{n+1-k}\mbox{.}</code>
</p>
<p> There are subtle differences between the two and <code><a href="#topic+dat2bernqua">dat2bernqua</a></code> function supports each. Readers are also directed to the <em>Special Attention</em> section.
</p>
<p>Turnbull and Ghosh (2014) consider through the direction of a referee and recommendation of <code class="reqn">p=0.05</code> by that referee (and credit to ideas by de Carvalho [2012]) that the support of the probability density function for the Turnbull and Ghosh (2014) study of Bernstein polynomials can be computed letting <code class="reqn">\alpha = (1 - p)^{-2} - 1</code> by
</p>
<p style="text-align: center;"><code class="reqn"> \biggl(x_{1:n} - (x_{2:n} - x_{1:n})/\alpha,\: x_{n:n} + (x_{n:n} - x_{n-1:n})/\alpha\biggr)\mbox{,}</code>
</p>

<p>for the minimum and maximum, respectively. Evidently, the original support considered by Turnbull and Ghosh (2014) was
</p>
<p style="text-align: center;"><code class="reqn"> \biggl(x_{1:n} - \lambda_2\sqrt{\pi/n},\: x_{n:n} +  \lambda_2\sqrt{\pi/n}\biggr)\mbox{,}</code>
</p>

<p>for the minimum and maximum, respectively and where the standard deviation is estimated in the function using the 2nd L-moment as <code class="reqn">s = \lambda\sqrt{\pi}</code>.
</p>
<p>The <code class="reqn">p</code> is referred to by this author as the &ldquo;p-factor&rdquo; this value has great influence in the estimated support of the distribution and therefore distal-tail estimation or performance is sensitive to the value for <code class="reqn">p</code>. General exploratory analysis suggests that the <code class="reqn">p</code> can be optimized based on information external or internal to the data for shape restrained smoothing. For example, an analyst might have external information as to the expected L-skew of the phenomenon being studied or could use the sample L-skew of the data (internal information) for shape restraint (see <code><a href="#topic+pfactor.bernstein">pfactor.bernstein</a></code>).
</p>
<p>An alternative formula for smoothing is by Cheng (1995) and is
</p>
<p style="text-align: center;"><code class="reqn">\tilde{X}^{\mathrm{Cheng}}_n(F) = \sum_{k=1}^n x_{k:n}\:{n - 1 \choose k-1}\: F^{k-1}(1-F)^{n-k}\mbox{.}</code>
</p>



<h3>Usage</h3>

<pre><code class='language-R'>dat2bernqua(f, x, bern.control=NULL,
                  poly.type=c("Bernstein", "Kantorovich", "Cheng", "Parzen",
                              "bernstein", "kantorovich", "cheng", "parzen"),
                  bound.type=c("none", "sd", "Carv", "either", "carv"),
                  fix.lower=NULL, fix.upper=NULL, p=0.05, listem=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dat2bernqua_+3A_f">f</code></td>
<td>
<p>A vector of nonexceedance probabilities <code class="reqn">F</code>.</p>
</td></tr>
<tr><td><code id="dat2bernqua_+3A_x">x</code></td>
<td>
<p>A vector of data values.</p>
</td></tr>
<tr><td><code id="dat2bernqua_+3A_bern.control">bern.control</code></td>
<td>
<p>A <code>list</code> that holds <code>poly.type</code>, <code>bound.type</code>, <code>fix.lower</code>, and <code>fix.upper</code>. And this list will supersede the respective
values provided as separate arguments.</p>
</td></tr>
<tr><td><code id="dat2bernqua_+3A_poly.type">poly.type</code></td>
<td>
<p>The Bernstein or Kantorovich polynomial will be used. The two are quite closely related. Or the formula by Cheng (1995) will be used and <code>bound.type</code>, <code>fix.lower</code>, <code>fix.upper</code>, and <code>p</code> are not applicable. Or the formula credited by Nair et al. (2013, p. 17) to Parzen (1979) will be used.</p>
</td></tr>
<tr><td><code id="dat2bernqua_+3A_bound.type">bound.type</code></td>
<td>
<p>Triggers to the not involve alternative supports (<code>"none"</code>) then the minimum and maximum are used unless already provided by the <code>fix.lower</code> or <code>fix.upper</code>, the support based <code>"sd"</code> on the standard deviation, the support <code>"Carv"</code> based on the arguments of de Carvalho (2012), or <code>"either"</code> method.</p>
</td></tr>
<tr><td><code id="dat2bernqua_+3A_fix.lower">fix.lower</code></td>
<td>
<p>For <code class="reqn">k = 0</code>, either the known lower bounds is used if provided as non <code>NULL</code> or the observed minimum of the data. If the minimum of the data is less than the <code>fix.lower</code>, a warning is triggered and <code>fix.lower</code> is set to the minimum. Following Turnbull and Ghosh (2014) to avoid bounds that are extremely lower than the data, it will use the estimated lower bounds by the method <code>"sd"</code>, <code>"Carv"</code>, or <code>"either"</code> if these bounds are larger than the provided <code>fix.lower</code>.</p>
</td></tr>
<tr><td><code id="dat2bernqua_+3A_fix.upper">fix.upper</code></td>
<td>
<p>For <code class="reqn">k = n</code>, either the known upper bounds is used if provided as non <code>NULL</code> or the observed maximum of the data; If the maximum of the data is less than the <code>fix.upper</code>, a warning is triggered and <code>fix.upper</code> is set to the maximum.</p>
</td></tr>
<tr><td><code id="dat2bernqua_+3A_p">p</code></td>
<td>
<p>A small probability value to serve as the <code class="reqn">p</code> in the <code>"Carv"</code> support computation. The default is recommended as mentioned above. The program will return <code>NA</code> if <code class="reqn">10^{-6} &lt; p \ge (1-10^{-6})</code> is not met. The value <code>p</code> is the &ldquo;p-factor&rdquo; <code class="reqn">p</code>.</p>
</td></tr>
<tr><td><code id="dat2bernqua_+3A_listem">listem</code></td>
<td>
<p>A logical controlling whether (1) a vector of <code class="reqn">\tilde{X}_n(F)</code> is returned or (2) a list containing <code class="reqn">\tilde{X}_n(F)</code>, the <code>f</code>, original sample size <code class="reqn">n</code> of the data, the de Carvalho probability <code>p</code> (whether actually used internally or not), and both <code>fix.lower</code> and <code>fix.upper</code> as computed within the function or provided (less likely) by the function arguments.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Yet another alternative formula for smoothing if by Parzen (1979) and known as the &ldquo;Parzen weighting method&rdquo; is
</p>
<p style="text-align: center;"><code class="reqn">\tilde{X}^{\mathrm{Parzen}}_n(F) = n\left(\frac{r}{n} - F\right)x_{r-1:n} + n\left(F - \frac{r-1}{n}\right)x_{r:n}\mbox{,}</code>
</p>

<p>where <code class="reqn">(r-1)/n \le F \le (r/n)</code> for <code class="reqn">r = 1, 2, \ldots, n</code> and <code class="reqn">x_{0:n}</code> is taken as either the minimum of the data (<code class="reqn">\mathrm{min}(x)</code>) or the lower bounds <code>fix.lower</code> as externally set by the user.  For protection, the minimum of <code class="reqn">(\mathrm{min}(x),</code> <code>fix.lower</code><code class="reqn">)</code> is formally used. If the Parzen method is used, the only arguments considered are <code>poly.type</code> and <code>fix.lower</code>; all others are ignored including the <code>f</code> (see Value section). The user does not actually have to provide <code>f</code> in the arguments but a place holder such as <code>f=NULL</code> is required; internally the Parzen method takes over full control. The Parzen method in general is not smooth and not recommended like the others that rely on a polynomial basis function. Further the Parzen method has implicit asymmetry in the estimated <code class="reqn">F</code>. The method has <code class="reqn">F=0</code> and <code class="reqn">F &lt; 1</code> on output, but if the data are reversed, then the method has <code class="reqn">F &gt; 0</code> and <code class="reqn">F=1</code>. Data reversal is made in <code>-X</code> as this example illustrates:
</p>
<pre>
X &lt;- sort(rexp(30))
P &lt;- dat2bernqua(f=NULL,  X, poly.type="Parzen")
R &lt;- dat2bernqua(f=NULL, -X, poly.type="Parzen")
plot(pp(X, a=0.5), X, xlim=c(0, 1)) # Hazen plotting position to
lines(  P$f,  P$x, col="red" )      # basically split the horizontal
lines(1-R$f, -R$x, col="blue")      # differences between blue and red.
</pre>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>vector</code> is returned unless the Parzen weighting method is used and in that case an <span class="rlang"><b>R</b></span> <code>list</code> is returned with elements <code>f</code> and <code>x</code>, which respectively are the <code class="reqn">F</code> values as shown in the formula and the <code class="reqn">\tilde{X}^{\mathrm{Parzen}}_n(F)</code>.
</p>


<h3>Special Attention</h3>

<p>The limiting properties of the Bernstein and Kantorovich polynomials differ. The Kantorovich polynomial uses the average of the largest (smallest) value and the respective outer order statistics (<code class="reqn">x_{n+1:n}</code> or <code class="reqn">x_{0:n}</code>) unlike the Bernstein polynomial whose <code class="reqn">F = 0</code> or <code class="reqn">F = 1</code> are purely a function of the outer order statistics. Thus, the Bernstein polynomial can attain the <code>fix.lower</code> and(or) <code>fix.upper</code> whereas the Kantorovich fundamentally can not.  For a final comment, the function <code><a href="#topic+dat2bernquaf">dat2bernquaf</a></code> is an inverse of <code>dat2bernqua</code>.
</p>


<h3>Implentation Note</h3>

<p>The function makes use of <span class="rlang"><b>R</b></span> functions <code>lchoose</code> and <code>exp</code> and logarithmic expressions, such as <code class="reqn">(1-F)^{(n-k)} \rightarrow (n-k)\log(1-F)</code>, for numerical stability for large sample sizes.
</p>


<h3>Note</h3>

<p>Muñoz-Pérez and Fernández-Palacín (1987, p. 391) describe what to do with the condition of <code class="reqn">k = 0</code> but seemingly do not comment on the condition of <code class="reqn">k = n</code>. There is no 0th-order statistic nor is there a <code class="reqn">k &gt; n</code> order statistic. Muñoz-Pérez and Fernández-Palacín (1987) bring up the notion of a natural minimum for the data (for example, data that must be positive, <code>fix.lower = 0</code> could be set). Logic dictates that a similar argument must be made for the maximum to keep a critical error from occurring if one tries to access the not plausible <code>x[n+1]</code>-order statistic. Lastly, the argument names <code>bound.type</code>, <code>fix.lower</code>, and <code>fix.upper</code> mimic, as revisions were made to this function in December 2013, the nomenclature of software for probability density function smoothing by Turnbull and Ghosh (2014). The <code>dat2bernqua</code> function was originally added to <span class="pkg">lmomco</span> in May 2013 prior to the author learning about Turnbull and Ghosh (2014).
</p>
<p>Lastly, there can be many practical situations in which transformation is desired. Because of the logic structure related to how <code>fix.lower</code> and <code>fix.upper</code> are determined or provided by the user, it is highly recommended that this function not internally handle transformation and detransformation. See the second example for use of logarithms.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Cheng, C., 1995, The Bernstein polynomial estimator of a smooth quantile function: Statistics and Probability Letters, v. 24, pp. 321&ndash;330.
</p>
<p>de Carvalho, M., 2012, A generalization of the Solis-Wets method: Journal of Statistical Planning and Inference, v. 142, no. 3, pp. 633&ndash;644.
</p>
<p>Hernández-Maldonado, V., Díaz-Viera, M., and Erdely, A., 2012, A joint stochastic simulation method using the Bernstein copula as a flexible tool for modeling nonlinear dependence structures between petrophysical properties: Journal of Petroleum Science and Engineering, v. 90&ndash;91, pp. 112&ndash;123.
</p>
<p>Muñoz-Pérez, J., and Fernández-Palacín, A., 1987, Estimating the quantile function by Bernstein polynomials: Computational Statistics and Data Analysis, v. 5, pp. 391&ndash;397.
</p>
<p>Nair, N.U., Sankaran, P.G., and Balakrishnan, N., 2013, Quantile-based reliability analysis: Springer, New York.
</p>
<p>Turnbull, B.C., and Ghosh, S.K., 2014, Unimodal density estimation using Bernstein polynomials: Computational Statistics and Data Analysis, v. 72, pp. 13&ndash;29.
</p>
<p>Parzen, E., 1979, Nonparametric statistical data modeling: Journal American Statistical Association, v. 75, pp. 105&ndash;122.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lmoms.bernstein">lmoms.bernstein</a></code>, <code><a href="#topic+pfactor.bernstein">pfactor.bernstein</a></code>, <code><a href="#topic+dat2bernquaf">dat2bernquaf</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'># Compute smoothed extremes, quartiles, and median
# The smoothing seems to extend to F=0 and F=1.
set.seed(1); X &lt;- exp(rnorm(20)); F &lt;- c(0, .25, .50, .75, 1)
dat2bernqua(F, X, bound.type="none",   listem=TRUE)$x
dat2bernqua(F, X, bound.type="Carv",   listem=TRUE)$x
dat2bernqua(F, X, bound.type="sd",     listem=TRUE)$x
dat2bernqua(F, X, bound.type="either", listem=TRUE)$x
dat2bernqua(F, X, bound.type="sd",     listem=TRUE, fix.lower=0)$x

## Not run: 
X &lt;- sort(10^rnorm(20)); F &lt;- nonexceeds(f01=TRUE)
plot(qnorm(pp(X)), X, xaxt="n", xlab="", ylab="QUANTILE", log="y")
add.lmomco.axis(las=2, tcl=0.5, side.type="NPP", twoside=TRUE)
lines(qnorm(F),     dat2bernqua(F,    X,  bound.type="sd"), col="red", lwd=2)
lines(qnorm(F), exp(dat2bernqua(F,log(X), bound.type="sd"))) # 
## End(Not run)

## Not run: 
X &lt;- exp(rnorm(20)); F &lt;- seq(0.001, 0.999, by=.001)
dat2bernqua(0.9, X, poly.type="Bernstein",   listem=TRUE)$x
dat2bernqua(0.9, X, poly.type="Kantorovich", listem=TRUE)$x
dat2bernqua(0.9, X, poly.type="Cheng",       listem=TRUE)$x
plot(pp(X), sort(X), log="y", xlim=range(F))
lines(F, dat2bernqua(F, X, poly.type="Bernstein"  ), col="red"  )
lines(F, dat2bernqua(F, X, poly.type="Kantorovich"), col="green")
lines(F, dat2bernqua(F, X, poly.type="Cheng"      ), col="blue" ) #
## End(Not run)

## Not run: 
X &lt;- exp(rnorm(20)); F &lt;- nonexceeds()
plot(pp(X), sort(X))
lines(F, dat2bernqua(F,X, bound.type="sd", poly.type="Bernstein"))
lines(F, dat2bernqua(F,X, bound.type="sd", poly.type="Kantorovich"), col=2) #
## End(Not run)

## Not run: 
X &lt;- rnorm(25); F &lt;- nonexceeds()
Q &lt;- dat2bernqua(F, X) # the Bernstein estimates
plot( F, dat2bernqua(F, X, bound.type="Carv"), type="l"   )
lines(F, dat2bernqua(F, X, bound.type="sd"),   col="red"  )
lines(F, dat2bernqua(F, X, bound.type="none"), col="green")
points(pp(X),      sort(X), pch=16, cex=.75,   col="blue" ) #
## End(Not run)

## Not run: 
set.seed(13)
par &lt;- parkap(vec2lmom(c(1, .5, .4, .2)))
F &lt;- seq(0.001, 0.999, by=0.001)
X &lt;- sort(rlmomco(100, par))
pp &lt;- pp(X)
pdf("lmomco_example_dat2bernqua.pdf")
plot(qnorm(pp(X)), dat2bernqua(pp, X), col="blue", pch=1,
     ylim=c(0,qlmomco(0.9999, par)))
lines(qnorm(F), dat2bernqua(F, sort(X)), col="blue")
lines(qnorm(F),     qlmomco(F,     par), col="red" )
sampar  &lt;- parkap(lmoms(X))
sampar2 &lt;- parkap(lmoms(dat2bernqua(pp, X)))
lines( qnorm(pp(F)), qlmomco(F, sampar ), col="black")
lines( qnorm(pp(F)), qlmomco(F, sampar2), col="blue", lty=2)
points(qnorm(pp(X)), X, col="black", pch=16)
dev.off() #
## End(Not run)
</code></pre>

<hr>
<h2 id='dat2bernquaf'>Equivalent Nonexceedance Probability for a Given Value through Observed Data to Empirical Quantiles through Bernstein or Kantorovich Polynomials </h2><span id='topic+dat2bernquaf'></span>

<h3>Description</h3>

<p>This function computes an equivalent nonexceedance probability <code class="reqn">F</code> of a single value <code class="reqn">x</code> for the sample data set (<code class="reqn">\hat{X}</code>) through inversion of the empricial quantile function as computable through Bernstein or Kantorovich Polynomials by the <code><a href="#topic+dat2bernqua">dat2bernqua</a></code> function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dat2bernquaf(x, data, interval=NA, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dat2bernquaf_+3A_x">x</code></td>
<td>
<p>A scalar value for which the equivalent nonexceedance probability <code class="reqn">F</code> through the function <code><a href="#topic+dat2bernqua">dat2bernqua</a></code> is to be computed.</p>
</td></tr>
<tr><td><code id="dat2bernquaf_+3A_data">data</code></td>
<td>
<p>A vector of data values that directly correspond to the argument <code>x</code> in the function <code><a href="#topic+dat2bernqua">dat2bernqua</a></code>.</p>
</td></tr>
<tr><td><code id="dat2bernquaf_+3A_interval">interval</code></td>
<td>
<p>The search interval. If <code>NA</code>, then <code class="reqn">[1/(n+1), 1 - 1/(n+1)]</code> is used. If <code>interval</code> is a single value <code class="reqn">a</code>, then the interval is computed as <code class="reqn">[a, 1 - a]</code>.</p>
</td></tr>
<tr><td><code id="dat2bernquaf_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to <code><a href="#topic+dat2bernqua">dat2bernqua</a></code> through the <code>uniroot()</code> function in <span class="rlang"><b>R</b></span>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The basic logic is thus. The <code class="reqn">\hat{X}</code> in conjunction with the settings for the polynomials provides the empirical quantile function (EQF). The <code>dat2bernquaf</code> function then takes the EQF (through dynamic recomputation) and seeks a root for the single value also given.
</p>
<p>The critical piece likely is the search interval, which can be modified by the <code>interval</code> argument if the internal defaults are not sufficient. The default interval is determined as the first and last Weibull plotting positions of <code class="reqn">\hat{X}</code> having a sample size <code class="reqn">n</code>: <code class="reqn">[1/(n+1), 1 - 1/(n+1)]</code>.  Because the <code><a href="#topic+dat2bernqua">dat2bernqua</a></code> function has a substantial set of options that control how the empirical curve is (might be) extrapolated beyond the range of <code class="reqn">\hat{X}</code>, it is difficult to determine an always suitable interval for the rooting.  However, it should be considered obvious that the result is more of an interpolation if <code class="reqn">F(x)</code> is within <code class="reqn">F \in  [1/(n+1), 1 - 1/(n+1)]</code> and increasingly becomes an accurate interpolation as <code class="reqn">F(x) \rightarrow 1/2</code> (the median).
</p>
<p>If the value <code class="reqn">x</code> is too far beyond the data or if the search interval is not sufficient then the following error will be triggered:
</p>
<pre>
Error in uniroot(afunc, interval, ...) :
  f() values at end points not of opposite sign
</pre>
<p>The Examples section explores this aspect.
</p>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> is returned.
</p>
<table>
<tr><td><code>x</code></td>
<td>
<p>An echoing of the <code class="reqn">x</code> value via the <code>x</code> argument.</p>
</td></tr>
<tr><td><code>f</code></td>
<td>
<p>The equivalent nonexceedance probability <code class="reqn">F(x{\mid}\hat{X})</code>.</p>
</td></tr>
<tr><td><code>interval</code></td>
<td>
<p>The search interval of <code class="reqn">F</code> used.</p>
</td></tr>
<tr><td><code>afunc.root</code></td>
<td>
<p>Corresponds to the <code>f.root</code> element returned by the <code>uniroot()</code> function.</p>
</td></tr>
<tr><td><code>iter</code></td>
<td>
<p>Corresponds to the <code>iter</code> element returned by the <code>uniroot()</code> function.</p>
</td></tr>
<tr><td><code>estim.prec</code></td>
<td>
<p>Corresponds to the <code>estim.prec</code> element returned by the <code>uniroot()</code> function.</p>
</td></tr>
<tr><td><code>source</code></td>
<td>
<p>An attribute identifying the computational source: &ldquo;dat2bernquaf&rdquo;.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>See Also</h3>

<p><code><a href="#topic+dat2bernqua">dat2bernqua</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>dat2bernquaf(6, c(2,10)) # median 1/2 of 2 and 10 is 6 (trivial and fast)
## Not run: 
set.seed(5135)
lmr &lt;- vec2lmom(c(1000, 400, 0.2, 0.3, 0.045))
par &lt;- lmom2par(lmr, type="wak")
Q   &lt;- rlmomco(83, par) # n = 83 and extremely non-Normal data
lgQ &lt;- max(Q) # 5551.052 by theory
dat2bernquaf(median(Q), Q)$f  # returns 0.5100523 (nearly 1/2)
dat2bernquaf(lgQ,   Q)$f                   # unable to root
dat2bernquaf(lgQ,   Q, bound.type="sd")$f  # unable to root
itf &lt;- c(0.5, 0.99999)
f &lt;- dat2bernquaf(lgQ, Q, interval=itf, bound.type="sd")$f
print(f) # F=0.9961118
qlmomco(f, par) # 5045.784 for the estimate F=0.9961118
# If we were not using the maximum and something more near the center of the
# distribution then that estimate would be closer to qlmomco(f, par).
# You might consider lqQ &lt;- qlmomco(0.99, Q) # theoretical 99th percentile and
# let the random seed wander and see the various results. 
## End(Not run)
</code></pre>

<hr>
<h2 id='disfitgovloc'>Fit a Govindarajulu Distribution to Bounds and Location </h2><span id='topic+disfitgovloc'></span>

<h3>Description</h3>

<p>Fits a <em>Govindarajulu</em> distribution to specified lower and upper bounds and a given location measure (either mean and median). Fitting occurs through <code class="reqn">3</code>-dimensional minimization using the <code>optim</code> function. Objective function forms are either root mean-square error (RMSE) or mean absolute deviation (MAD), and the objective functions are expected to result in slightly different estimates of distribution parameters. The RMSE form (<code class="reqn">\sigma_{\mathrm{RMSE}}</code>) is defined as
</p>
<p style="text-align: center;"><code class="reqn">\sigma_{\mathrm{RMSE}} = \biggl[ \frac{1}{3}\,\sum_{i=1}^3 \bigl[x_i - \hat{x}_i\bigr]^2\biggr]^{1/2}\mbox{,}</code>
</p>

<p>where <code class="reqn">x_i</code> is a vector of the targeted lower bounds (<code>lwr</code> argument), location measure (<code>loc</code> argument), and upper bounds (<code>upr</code> argument), and <code class="reqn">\hat{x}_i</code> is a similar vector of Govindarajulu properties for &ldquo;current&rdquo; iteration of the optimization. Similarly, the MAD form (<code class="reqn">\sigma_{\mathrm{MAD}}</code>) is defined as
</p>
<p style="text-align: center;"><code class="reqn">\sigma_{\mathrm{MAD}} = \frac{1}{3}\,\sum_{i=1}^3 \mid x_i - \hat{x}_i \mid  \mbox{.}</code>
</p>

<p>The premise of this function is that situations might exist in practical applications wherein the user has an understanding or commitment to certain bounding conditions of a distribution. The user also has knowledge of a particular location measure (the mean or median) of a distribution. The bounded nature of the Govindarajulu might be particularly of interest because the quantile function (<code><a href="#topic+quagov">quagov</a></code>) is explicit. The curvatures that the distribution can attain also provide it more flexibility to fitting to a given location measure than say the <em>Triangular</em> distribution (<code><a href="#topic+quatri">quatri</a></code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>disfitgovloc(x=NULL, loc=NULL, lwr=0, upr=NA, init.para=NULL,
             loctype=c("mean", "median"), objfun=c("rmse", "mad"),
             ptransf=function(p) return(log(p)),
             pretransf=function(p) return(exp(p)),
             silent=TRUE, verbose=FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="disfitgovloc_+3A_x">x</code></td>
<td>
<p>Optional vector to help guide the initial parameter estimates for the optimization, if given and if <code>loc=NULL</code>, then <code>loc</code> by <code>loctype</code> will be computed from the <code>x</code>.</p>
</td></tr>
<tr><td><code id="disfitgovloc_+3A_loc">loc</code></td>
<td>
<p>Optional value for the location statistic, which if not given will be computed from mean or median of the <code>x</code>. The <code>loc</code> however can also be given if an <code>x</code> is given and at which point the user's setting prevails.</p>
</td></tr>
<tr><td><code id="disfitgovloc_+3A_lwr">lwr</code></td>
<td>
<p>Lower bounds for the distribution with default supposing that most often positive domain bounds might be of interest.</p>
</td></tr>
<tr><td><code id="disfitgovloc_+3A_upr">upr</code></td>
<td>
<p>Upper bounds for the distribution, which must be specified.</p>
</td></tr>
<tr><td><code id="disfitgovloc_+3A_init.para">init.para</code></td>
<td>
<p>Optional initial values for the parameters used for starting values for the <code>optim</code> function. If this argument is not set nor is <code>x</code>, then an unrigorous attempt is made to guess at the initial parameters using heuristics and the triangular quantile function (because the triangle is trivial and also bounded) (see sources).</p>
</td></tr>
<tr><td><code id="disfitgovloc_+3A_loctype">loctype</code></td>
<td>
<p>The type of location measure constraint.</p>
</td></tr>
<tr><td><code id="disfitgovloc_+3A_objfun">objfun</code></td>
<td>
<p>The form of the objective function as previously described.</p>
</td></tr>
<tr><td><code id="disfitgovloc_+3A_ptransf">ptransf</code></td>
<td>
<p>The parameter transformation function that is useful to guide the optimization run. The distribution requires its second and third parameters to be nonzero without constraint on the first parameter; however, the default treats the first parameter as also nonzero. This is potentially suboptimal for some situations (see <b>Examples</b>).</p>
</td></tr>
<tr><td><code id="disfitgovloc_+3A_pretransf">pretransf</code></td>
<td>
<p>The parameter retransformation function that is useful to guide the optimization run. The distribution requires its second and third parameters to be nonzero without constraint on the first parameter; however, the default treats the first parameter as also nonzero. This is potentially suboptimal for some situations (see <b>Examples</b>).</p>
</td></tr>
<tr><td><code id="disfitgovloc_+3A_silent">silent</code></td>
<td>
<p>A logical to silence the <code>try()</code> function wrapping the <code>optim()</code> function.</p>
</td></tr>
<tr><td><code id="disfitgovloc_+3A_verbose">verbose</code></td>
<td>
<p>A logical to trigger verbose output within the objective function.</p>
</td></tr>
<tr><td><code id="disfitgovloc_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass to the <code>optim</code> function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Support of the Govindarajulu for the optimized parameter set is computed by internally and reported as part of the returned values. This enhances the documentation a bit more&mdash;the computed parameters might not always have full convergence and result in slightly difference bounds than targeted. Finally, this function was developed using some heredity to <code><a href="#topic+disfitqua">disfitqua</a></code>.
</p>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> is returned.  This list should contain at least the following items.
</p>
<table>
<tr><td><code>type</code></td>
<td>
<p>The type of distribution in three character (minimum) format.</p>
</td></tr>
<tr><td><code>para</code></td>
<td>
<p>The parameters of the Govindarajulu distribution.</p>
</td></tr>
<tr><td><code>source</code></td>
<td>
<p>Attribute specifying source of the parameters.</p>
</td></tr>
<tr><td><code>supdist</code></td>
<td>
<p>A list of confirming the distribution support from <code>quagov(c(0,1), gov)</code> where <code>gov</code> are the final computed parameters before return.</p>
</td></tr>
<tr><td><code>init.para</code></td>
<td>
<p>A vector of the initial parameters actually passed to the <code>optim</code> function to serve only as a reminder.</p>
</td></tr>
<tr><td><code>optim</code></td>
<td>
<p>The returned <code>list</code> of the <code>optim()</code> function.</p>
</td></tr>
<tr><td><code>message</code></td>
<td>
<p>Helpful messages on the computations.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>See Also</h3>

<p><code><a href="#topic+disfitqua">disfitqua</a></code>, <code><a href="#topic+quagov">quagov</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'># EXAMPLE 1 --- Example of strictly positive domain.
disfitgovloc(loc=125, lwr=99, upr=175, loctype="mean")$para
#        xi     alpha      beta
# 99.000000 76.000000  3.846154
# These parameters have a lmomgov()$lambdas[1] mean of 124.9999999.

# EXAMPLE 2 --- Operations spanning zero and revision to the default parameter
# transform functions. Testing indicates that these, ideally align to need of
# the Govindarajulu, such do not work for all strictly positive domain, which
# led to a decision to have the defaults different than this example.
disfitgovloc(loc=100, lwr=-99, upr=175, loctype="median",
               ptransf=function(p) c(p[1], log(p[2:3])),
             pretransf=function(p) c(p[1], exp(p[2:3])))$para
#         xi        alpha         beta
# -99.000002   274.000004   1.08815151

## Not run: 
  # EXTENDED EXAMPLE 3
  r &lt;- function(r) round(r, 1)
  X &lt;- c(8751, 14507, 4061, 22056, 6330, 3130, 5180, 6700, 22409, 3380, 17902,
         8956,  4523, 1604,  4460, 4239, 3010, 9155, 5107, 4821,  5221, 20700)
  mu  &lt;-   mean(X); med &lt;- median(X)
  for(objfun in c("rmse", "mad")) {
    gov &lt;- disfitgovloc(x=X,  loc=mu,  upr=41000, objfun=objfun, loctype="mean"    )
    message(objfun, ": seek   mean=", r(mu),
                    ", GOV   mean=",  r(lmomgov(gov)$lambdas[1]))
    gov &lt;- disfitgovloc(x=X, loc=med,  upr=41000, objfun=objfun, loctype="median"  )
    message(objfun, ": seek median=", r(med),
                    ", GOV median=",  r(quagov(0.5, gov)))
  }
  for(objfun in c("rmse", "mad")) {
    gov &lt;- disfitgovloc(x=NULL,  loc=mu,  upr=41000, objfun=objfun, loctype="mean"  )
    message(objfun, ": seek   mean=", r(mu),
                    ", GOV   mean=",  r(lmomgov(gov)$lambdas[1]) )
    gov &lt;- disfitgovloc(x=NULL, loc=med,  upr=41000, objfun=objfun, loctype="median")
    message(objfun, ": seek median=", r(med),
                    ", GOV median=",  r(quagov(0.5, gov)))
  } # end of loop
  # *** That last message() : mad: seek median=5200.5, GOV median=5226.2
  print(gov$para) # 64.521326, 40935.479117, 4.740232 # last parameters in prior loop
  ngv &lt;- vec2par( c(64.521326, 40935.479117, 4.740232), type="gov") # for reuse
  # We see (at least in testing) that the last message in the sequence shows that
  # the median is not recovered via the guessed at initial parameters, let us turn
  # the gov parameters back into disfitgovloc() as the initial parameters.
  mgv &lt;- disfitgovloc(init.para=ngv, loc=med, upr=41000, objfun=objfun,loctype="median")
  message(objfun, ": seek median=", r(med),
                   ", GOV median=", r(quagov(0.5, mgv)))
  # *** BETTER FIT mad: seek median=5200.5, GOV median=5200.5
  print(mgv$para) # 1.227568, 40998.903644, 4.729768 # last parameters
  # So, conveniently in this example, we can see that there are cases wherein an
  # apparent convergence can be made even better. But, need to be aware that
  # feed fack a very good solution can in turn cause optim() itself to NULL out. 
## End(Not run)

## Not run: 
  # EXTENDED EXAMPLE 4 --- Continuing from the previous example
  FF    &lt;- seq(0.001, 0.999, by=0.001)
  maxes &lt;- as.integer(10^(seq(4, 5, by=0.02))); n &lt;- length(maxes)
  for(max in maxes) {
    govA &lt;- disfitgovloc(x=X,  loc=mu,     upr=max, loctype="mean"  , lwr=0)
    govB &lt;- disfitgovloc(x=X,  loc=median, upr=max, loctype="median", lwr=0)
    plot( FF, quagov(FF, govA), col="red",  lwd=2, type="l", ylim=c(0, maxes[n]),
         xlab="Nonexceedance probability", ylab="Quantile of Govindarajulu",
         main=paste0("Maximum = ", max))
    lines(FF, quagov(FF, govB), col="blue", lwd=2); quagov(0.5, govB)
    legend("topleft", c("Govindarajulu constrained given mean (dashed red)",
                        "Govindarajulu constrained given median (dashed blue)",
                        "disfitgovloc() computed mean (red dot)",
                        "disfitgovloc() computed median (blue dot)"),
                    lwd=c( 2,  2, NA, NA), col=c("red", "blue"), inset=0.02,
                    pch=c(NA, NA, 16, 16), pt.cex=1.5, cex=0.9)
    abline(h=mu,  lty=2, col="red" ); abline(h=med, lty=2, col="blue")
    tmu &lt;- lmomgov(govA)$lambdas[1]
    points(cdfgov(tmu, govA), tmu, cex=1.5, pch=16, col="red" )
    points(0.5, quagov(0.5, govB), cex=1.5, pch=16, col="blue")
  } # end of loop 
## End(Not run)
</code></pre>

<hr>
<h2 id='disfitqua'>Fit a Distribution using Minimization of Available Quantiles </h2><span id='topic+disfitqua'></span>

<h3>Description</h3>

<p>This function fits a distribution to available quantiles (or irregular quantiles) through <code class="reqn">n</code>-dimensional minimization using the <code>optim</code> function. Objective function forms are either root mean-square error (RMSE) or mean absolute deviation (MAD), and the objective functions are expected to result in slightly different estimates of distribution parameters. The RMSE form (<code class="reqn">\sigma_{\mathrm{RMSE}}</code>) is defined as
</p>
<p style="text-align: center;"><code class="reqn">\sigma_{\mathrm{RMSE}} = \biggl[ \frac{1}{m}\,\sum_{i=1}^m \bigl[x_o(f_i) - \hat{x}(f_i)\bigr]^2\biggr]^{1/2}\mbox{,}</code>
</p>

<p>where <code class="reqn">m</code> is the length of the vector of <code class="reqn">o</code>bserved quantiles <code class="reqn">x_o(f_i)</code> for nonexceedance probability <code class="reqn">f_i</code> for <code class="reqn">i \in 1, 2, \cdots, m</code>, and <code class="reqn">\hat{x}(f_i)</code> for <code class="reqn">i \in 1, 2, \cdots, m</code> are quantile estimates based on the &ldquo;current&rdquo; iteration of the parameters for the selected distribution having <code class="reqn">n</code> parameters for <code class="reqn">n \le m</code>. Similarly, the MAD form (<code class="reqn">\sigma_{\mathrm{MAD}}</code>) is defined as
</p>
<p style="text-align: center;"><code class="reqn">\sigma_{\mathrm{MAD}} = \frac{1}{m}\,\sum_{i=1}^m \mid x_o(f_i) - \hat{x}(f_i) \mid \mbox{.}</code>
</p>

<p>The <code>disfitqua</code> function is not intended to be an implementation of the <em>method of percentiles</em> but rather is intended for circumstances in which the available quantiles are restricted to either the left or right tails of the distribution. It is evident that a form of the method of percentiles however could be pursued by <code>disfitqua</code> when the length of <code class="reqn">x(f)</code> is equal to the number of distribution parameters (<code class="reqn">n = m</code>).  The situation of <code class="reqn">n &lt; m</code> however is thought to be the most common application.
</p>
<p>The right-tail restriction is the general case in flood-peak hydrology in which the median and select quantiles greater than the median can be available from empirical studies (e.g. Asquith and Roussel, 2009) or rainfall-runoff models. The available quantiles suit engineering needs and thus left-tail quantiles simply are not available. This circumstance might appear quite unusual to users from most statistical disciplines but quantile estimates can exist from regional study of observed data. The <b>Examples</b> section provides further motivation and discussion.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>disfitqua(x, f, objfun=c("rmse", "mad"),
                init.lmr=NULL, init.para=NULL, type=NA,
                ptransf=  function(t) return(t),
                pretransf=function(t) return(t), verbose=FALSE, ... )
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="disfitqua_+3A_x">x</code></td>
<td>
<p>The quantiles <code class="reqn">x_o(f)</code> for the nonexceedance probabilities in <code>f</code>.</p>
</td></tr>
<tr><td><code id="disfitqua_+3A_f">f</code></td>
<td>
<p>The nonexceedance probabilities <code class="reqn">f</code> of the quantiles <code class="reqn">x_o(f)</code> in <code>x</code>.</p>
</td></tr>
<tr><td><code id="disfitqua_+3A_objfun">objfun</code></td>
<td>
<p>The form of the objective function as previously described.</p>
</td></tr>
<tr><td><code id="disfitqua_+3A_init.lmr">init.lmr</code></td>
<td>
<p>Optional initial values for the L-moments from which the initial starting parameters for the optimization will be determined. The optimizations by this function are not performed on the L-moments during the optimization. The form of <code>init.lmr</code> is that of an L-moment object from the <span class="pkg">lmomco</span> package (e.g. <code><a href="#topic+lmoms">lmoms</a></code>).</p>
</td></tr>
<tr><td><code id="disfitqua_+3A_init.para">init.para</code></td>
<td>
<p>Optional initial values for the parameters used for starting values for the <code>optim</code> function. If this argument is not set nor is <code>init.lmr</code>, then unrigorous estimates of the mean <code class="reqn">\lambda_1</code> and L-scale <code class="reqn">\lambda_2</code> are made from the available quantiles, higher L-moment ratios <code class="reqn">\tau_r</code> for <code class="reqn">r \ge 3</code> are set to zero, and the L-moments converted to the initial parameters.</p>
</td></tr>
<tr><td><code id="disfitqua_+3A_type">type</code></td>
<td>
<p>The distribution type specified by the abbreviations listed under <code><a href="#topic+dist.list">dist.list</a></code>.</p>
</td></tr>
<tr><td><code id="disfitqua_+3A_ptransf">ptransf</code></td>
<td>
<p>An optional parameter transformation function (see <b>Examples</b>) that is useful to guide the optimization run. For example, suppose the first parameter of a three parameter distribution resides in the positive domain, then <br /> <code>ptransf(t) = </code>
<code>function(t) c(log(t[1]), t[2], t[3])</code>.</p>
</td></tr>
<tr><td><code id="disfitqua_+3A_pretransf">pretransf</code></td>
<td>
<p>An optional parameter retransformation function (see <b>Examples</b>) that is useful to guide the optimization run. For example, suppose the first parameter of a three parameter distribution resides in the positive domain, then <br /> <code>pretransf(t) = </code> <code>function(t) c(exp(t[1]), t[2], t[3])</code>.</p>
</td></tr>
<tr><td><code id="disfitqua_+3A_verbose">verbose</code></td>
<td>
<p>A logical switch on the verbosity of output.</p>
</td></tr>
<tr><td><code id="disfitqua_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass to the <code>optim</code> function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> is returned, and this <code>list</code> contains at least the following items:
</p>
<table>
<tr><td><code>type</code></td>
<td>
<p>The type of distribution in character format (see <code><a href="#topic+dist.list">dist.list</a></code>).</p>
</td></tr>
<tr><td><code>para</code></td>
<td>
<p>The parameters of the distribution.</p>
</td></tr>
<tr><td><code>source</code></td>
<td>
<p>Attribute specifying source of the parameters&mdash;&ldquo;disfitqua&rdquo;.</p>
</td></tr>
<tr><td><code>init.para</code></td>
<td>
<p>A vector of the initial parameters actually passed to the <code>optim</code> function to serve only as a reminder.</p>
</td></tr>
<tr><td><code>disfitqua</code></td>
<td>
<p>The returned <code>list</code> from the <code>optim</code> function. This <code>list</code> contains a repeat of the parameters, the value of the objective function (<code class="reqn">\sigma_{\mathrm{RMSE}}</code> or <code class="reqn">\sigma_{\mathrm{MAD}}</code>), the interation count, and convergence status.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The <code>disfitqua</code> function is likely more difficult to apply for <code class="reqn">n &gt; 3</code> (high parameter) distributions because of the inherent complexity of the mathematics of such distributions and their applicable parameter (and thus valid L-moment ranges). The complex interplay between parameters and L-moments can make identification of suitable initial parameters <code>init.para</code> or initial L-moments <code>init.lmr</code> more difficult than is the case for <code class="reqn">n \le 3</code> distributions. The default initial parameters are computed from an assumed condition that the L-moments ratios <code class="reqn">\tau_r = 0</code> for <code class="reqn">r \ge 3</code>. This is not ideal, however, and the <b>Examples</b> show how to move into high parameter distributions using the results from a previous fit.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Asquith, W.H., and Roussel, M.C., 2009, Regression equations for estimation of annual peak-streamflow frequency for undeveloped watersheds in Texas using an L-moment-based, PRESS-minimized, residual-adjusted approach: U.S. Geological Survey Scientific Investigations Report 2009&ndash;5087, 48 p., <a href="https://doi.org/10.3133/sir20095087">doi:10.3133/sir20095087</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+dist.list">dist.list</a></code>, <code><a href="#topic+lmoms">lmoms</a></code>, <code><a href="#topic+lmom2vec">lmom2vec</a></code>, <code><a href="#topic+par2lmom">par2lmom</a></code>, <code><a href="#topic+par2qua">par2qua</a></code>, <code><a href="#topic+vec2lmom">vec2lmom</a></code>, <code><a href="#topic+vec2par">vec2par</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'># Suppose the following quantiles are estimated using eight equations provided by
# Asquith and Roussel (2009) for some watershed in Texas:
Q &lt;- c(1480, 3230, 4670, 6750, 8700, 11000, 13600, 17500)
# These are real estimates from a suite of watershed properties; the watershed
# itself and location are not germane to demonstrate this function.
LQ &lt;- log10(Q) # transform to logarithms of cubic feet per second
# Convert the averge annual return periods for the quantiles into probability
P &lt;- T2prob(c(2, 5, 10, 25, 50, 100, 200, 500)); qP &lt;- qnorm(P) # std norm variates
# The log-Pearson type III (LPIII) is immensely popular for flood-risk computations.
# Let us compute LPIII parameters to the available quantiles and probabilities for
# the watershed. The log-Pearson type III is "pe3" in the lmomco with logarithms.
par1 &lt;- disfitqua(LQ, P, type="pe3", objfun="rmse") # root mean square error
par2 &lt;- disfitqua(LQ, P, type="pe3", objfun="mad" ) # mean absolute deviation
# Now express the fitted distributions in forms of an LPIII.
LQfit1 &lt;- qlmomco(P, par1); LQfit2 &lt;- qlmomco(P, par2)

plot( qP, LQ, pch=5, xlab="STANDARD NORMAL VARIATES",
                     ylab="FLOOD QUANTILES, CUBIC FEET PER SECOND")
lines(qP, LQfit1, col=2); lines(qP, LQfit2, col=4) # red and blue lines

## Not run: 
# Now demonstrate how a Wakeby distribution can be fit. This is an example of how a
# three parameter distribution might be fit, and then the general L-moments secured for
# an alternative fit using a far more complicated distribution. The Wakeby for the
# above situation does not fit out of the box.
lmr1 &lt;- theoLmoms(par1) # We need five L-moments but lmompe3() only gives four,
# therefore must compute the L-moment by numerical integration provided by theoLmoms().
par3 &lt;- disfitqua(LQ, P, type="wak", objfun="rmse", init.lmr=lmr1)
lines(qP, par2qua(P, par3), col=6, lty=2) # dashed line, par2qua alternative to qlmomco

# Finally, the initial L-moment equivalents and then the L-moments of the fitted
# distribution can be computed and compared.
par2lmom(vec2par(par3$init.para, type="wak"))$ratios # initial L-moments
par2lmom(vec2par(par3$para,      type="wak"))$ratios # final   L-moments
## End(Not run)
</code></pre>

<hr>
<h2 id='dist.list'>List of Distribution Names</h2><span id='topic+dist.list'></span>

<h3>Description</h3>

<p>Return a list of the three character syntax identifying distributions supported within the <span class="pkg">lmomco</span> package. The distributions are
<code>aep4</code>, <code>cau</code>, <code>emu</code>, <code>exp</code>, <code>gam</code>, <code>gep</code>,
<code>gev</code>, <code>gld</code>, <code>glo</code>, <code>gno</code>, <code>gov</code>,
<code>gpa</code>, <code>gum</code>, <code>kap</code>, <code>kmu</code>, <code>kur</code>,
<code>lap</code>, <code>lmrq</code>, <code>ln3</code>, <code>nor</code>, <code>pdq3</code>, <code>pdq4</code>,
<code>pe3</code>, <code>ray</code>, <code>revgum</code>, <code>rice</code>, <code>sla</code>, <code>smd</code>, <code>st3</code>,
<code>texp</code>, <code>tri</code>, <code>wak</code>, and <code>wei</code>. These abbreviations and only these are used in routing logic within <span class="pkg">lmomco</span>. There is no provision for fuzzy matching. The full distributions names are available in <code><a href="#topic+prettydist">prettydist</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dist.list(type=NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dist.list_+3A_type">type</code></td>
<td>
<p>If <code>type</code> is not <code>NULL</code> and is one of the abbreviations shown above, then the number of parameters of that distribution are returned or a warning message is issued. This subtle feature might be useful for developers.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of distribution identifiers as listed above or the number of parameters for a given distribution type.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>See Also</h3>

<p><code><a href="#topic+prettydist">prettydist</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>dist.list("gpa")

## Not run: 
# Build an L-moment object
LM &lt;- vec2lmom(c(10000, 1500, 0.3, 0.1, 0.04))
lm2 &lt;- lmorph(LM)  # convert to vectored format
lm1 &lt;- lmorph(lm2) # and back to named format
dist &lt;- dist.list()
# Demonstrate that lmom2par internally converts to needed L-moment object
for(i in 1:length(dist)) {
  # Skip Cauchy and Slash (need TL-moments).
  # Skip AEP4, Kumaraswamy, LMRQ, Student t (3-parameter), Truncated Exponential
  # are skipped because each is inapplicable to the given L-moments.
  # The Eta-Mu and Kappa-Mu are skipped for speed.
  if(dist[i] == 'aep4' | dist[i] == 'cau' | dist[i] == 'emu'  | dist[i] == 'gep' |
     dist[i] == 'kmu'  | dist[i] == 'kur' | dist[i] == 'lmrq' | dist[i] == 'tri' |
     dist[i] == 'sla'  | dist[i] == 'st3' | dist[i] == 'texp') next
  message(dist[i], " parameters : ",
          paste(round(lmom2par(lm1, type=dist[i])$para, digits=4), collapse=", "))
  message(dist[i], " parameters : ",
          paste(round(lmom2par(lm2, type=dist[i])$para, digits=4), collapse=", "))
} # 
## End(Not run)
</code></pre>

<hr>
<h2 id='dlmomco'>Probability Density Function of the Distributions</h2><span id='topic+dlmomco'></span>

<h3>Description</h3>

<p>This function acts as an alternative front end to <code><a href="#topic+par2pdf">par2pdf</a></code>. The nomenclature of the <code><a href="#topic+dlmomco">dlmomco</a></code> function is to mimic that of built-in <span class="rlang"><b>R</b></span> functions that interface with distributions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dlmomco(x, para)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dlmomco_+3A_x">x</code></td>
<td>
<p>A real value vector.</p>
</td></tr>
<tr><td><code id="dlmomco_+3A_para">para</code></td>
<td>
<p>The parameters from <code><a href="#topic+lmom2par">lmom2par</a></code> or similar.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Probability density for <code>x</code>.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>See Also</h3>

<p><code><a href="#topic+plmomco">plmomco</a></code>, <code><a href="#topic+qlmomco">qlmomco</a></code>, <code><a href="#topic+rlmomco">rlmomco</a></code>, <code><a href="#topic+slmomco">slmomco</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>para &lt;- vec2par(c(0,1),type="nor") # standard normal parameters
nonexceed &lt;- dlmomco(1,para) # percentile of one standard deviation
</code></pre>

<hr>
<h2 id='DrillBitLifetime'>Lifetime of Drill Bits</h2><span id='topic+DrillBitLifetime'></span>

<h3>Description</h3>

<p>Hamada (1995, table 9.3) provides a table of lifetime to breakage measured in cycles for drill bits used for producing small holes in printed circuit boards. The data were collected under various control and noise factors to perform reliability assessment to maximize bit reliability with minimization of hole diameter. Smaller holes permit higher density of placed circuitry, and are thus economically attractive. The testing was completed at 3,000 cycles&mdash;the right censoring threhold.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(DrillBitLifetime)
</code></pre>


<h3>Format</h3>

<p>A data frame with
</p>

<dl>
<dt>LIFETIME</dt><dd><p>Measured in cycles.</p>
</dd>
</dl>



<h3>References</h3>

<p>Hamada, M., 1995, Analysis of experiments for reliability improvement and robust reliability: in Balakrishnan, N. (ed.) Recent Advances in Life-Testing and Reliability: Boca Raton, Fla., CRC Press, ISBN 0&ndash;8493&ndash;8972&ndash;0, pp. 155&ndash;172.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(DrillBitLifetime)
summary(DrillBitLifetime)
## Not run: 
data(DrillBitLifetime)
X     &lt;- DrillBitLifetime$LIFETIME
lmr   &lt;- lmoms(X); par &lt;- lmom2par(lmr,  type="gpa")
pwm   &lt;- pwmRC(X, threshold=3000); zeta &lt;- pwm$zeta
lmrrc &lt;- pwm2lmom(pwm$Bbetas)
rcpar &lt;- pargpaRC(lmrrc, zeta=zeta)
XBAR  &lt;- lmomgpa(rcpar)$lambdas[1]
F &lt;- nonexceeds(); P &lt;- 100*F; x &lt;- seq(min(X), max(X))
plot(sort(X), 100*pp(X), xlab="LIFETIME", ylab="PERCENT", xlim=c(1,10000))
rug(X, col=rgb(0,0,0,0.5))
lines(c(XBAR, XBAR), range(P), lty=2) # mean (expectation of life)
lines(cmlmomco(F, rcpar),  P,  lty=2) # conditional mean
points(XBAR, 0, pch=16)
lines(x, 100*plmomco(x, par),   lwd=2, col=8) # fitted dist.
lines(x, 100*plmomco(x, rcpar), lwd=3, col=1) # fitted dist.

lines( rmlmomco(F, rcpar), P,   col=4) # residual mean life
lines(rrmlmomco(F, rcpar), P,   col=4, lty=2) # rev. residual mean life
lines(x, 1E4*hlmomco(x, rcpar), col=2) # hazard function
lines(x, 1E2*lrzlmomco(plmomco(x, rcpar), rcpar), col=3) # Lorenz func.
legend(4000, 40,
       c("Mean (vertical) or conditional mean (dot at intersect.)",
         "Fitted GPA naively to all data",
         "Fitted GPA to right-censoring PWMs",
         "Residual mean life", "Reversed residual mean life",
         "Hazard function x 1E4", "Lorenz curve x 100"
        ), cex=0.75,
       lwd=c(1, 2, 3, 1, 1, 1, 1), col=c(1, 8, 1, 4, 4, 2, 3),
       lty=c(2, 1, 1, 1, 2, 1, 1), pch=rep(NA, 8))

## End(Not run)
</code></pre>

<hr>
<h2 id='expect.max.ostat'>Compute the Expectation of a Maximum (or Minimum and others) Order Statistic</h2><span id='topic+expect.max.ostat'></span><span id='topic+expect.min.ostat'></span><span id='topic+eostat'></span>

<h3>Description</h3>

<p>The maximum (or minimum) expectation of an order statistic can be directly used for L-moment computation through either of the following two equations (Hosking, 2006) as dictated by using the maximum (<code class="reqn">\mathrm{E}[X_{k:k}]</code>, <code><a href="#topic+expect.max.ostat">expect.max.ostat</a></code>) or minimum (<code class="reqn">\mathrm{E}[X_{1:k}]</code>, <code><a href="#topic+expect.min.ostat">expect.min.ostat</a></code>):
</p>
<p style="text-align: center;"><code class="reqn">
\lambda_r = (-1)^{r-1} \sum_{k=1}^r (-1)^{r-k}k^{-1}{r-1 \choose k-1}{r+k-2 \choose k-1}\mathrm{E}[X_{1:k}]\mbox{,}
</code>
</p>

<p>and
</p>
<p style="text-align: center;"><code class="reqn">
\lambda_r = \sum_{k=1}^r (-1)^{r-k}k^{-1}{r-1 \choose k-1}{r+k-2 \choose k-1}\mathrm{E}[X_{k:k}]\mbox{.}
</code>
</p>

<p>In terms of the quantile function <code><a href="#topic+qlmomco">qlmomco</a></code>, the expectation of an order statistic (Asquith, 2011, p. 49) is
</p>
<p style="text-align: center;"><code class="reqn">
  \mathrm{E}[X_{j:n}] = n {n-1 \choose j - 1}\int^1_0 \! x(F)\times F^{j-1} \times (1-F)^{n-j}\; \mathrm{d}F\mbox{,}
</code>
</p>

<p>where <code class="reqn">x(F)</code> is the quantile function, <code class="reqn">F</code> is nonexceedance probability, <code class="reqn">n</code> is sample size, and <code class="reqn">j</code> is the <code class="reqn">j</code>th order statistic.
</p>
<p>In terms of the probability density function (PDF) <code><a href="#topic+dlmomco">dlmomco</a></code> and cumulative density function (CDF) <code><a href="#topic+plmomco">plmomco</a></code>, the expectation of an order statistic (Asquith, 2011, p. 50) is
</p>
<p style="text-align: center;"><code class="reqn">
\mathrm{E}[X_{j:n}] = \frac{1}{\mathrm{B}(j,n-j+1)}\int_{-\infty}^{\infty} [F(x)]^{j-1}[1-F(x)]^{n-j} x\, f(x)\;\mathrm{d} x\mbox{,}
</code>
</p>

<p>where <code class="reqn">F(x)</code> is the CDF, <code class="reqn">f(x)</code> is the PDF, and <code class="reqn">\mathrm{B}(j, n-j+1)</code> is the complete Beta function, which in <span class="rlang"><b>R</b></span> is <code>beta</code> with the same argument order as shown above.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>expect.max.ostat(n, para=NULL, cdf=NULL, pdf=NULL, qua=NULL,
                 j=NULL, lower=-Inf, upper=Inf, aslist=FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="expect.max.ostat_+3A_n">n</code></td>
<td>
<p>The sample size.</p>
</td></tr>
<tr><td><code id="expect.max.ostat_+3A_para">para</code></td>
<td>
<p>A distribution parameter list from a function such as <code><a href="#topic+vec2par">vec2par</a></code> or <code><a href="#topic+lmom2par">lmom2par</a></code>.</p>
</td></tr>
<tr><td><code id="expect.max.ostat_+3A_cdf">cdf</code></td>
<td>
<p>cumulative distribution function of the distribution.</p>
</td></tr>
<tr><td><code id="expect.max.ostat_+3A_pdf">pdf</code></td>
<td>
<p>probability density function of the distribution.</p>
</td></tr>
<tr><td><code id="expect.max.ostat_+3A_qua">qua</code></td>
<td>
<p>quantile function of the distribution. If this is defined, then <code>cdf</code> and <code>pdf</code> are ignored.</p>
</td></tr>
<tr><td><code id="expect.max.ostat_+3A_j">j</code></td>
<td>
<p>The <code class="reqn">j</code>th value of the order statistic, which defaults to <var>n=j</var> (the maximum order statistic) if <code>j=NULL</code>.</p>
</td></tr>
<tr><td><code id="expect.max.ostat_+3A_lower">lower</code></td>
<td>
<p>The lower limit for integration.</p>
</td></tr>
<tr><td><code id="expect.max.ostat_+3A_upper">upper</code></td>
<td>
<p>The upper limit for integration.</p>
</td></tr>
<tr><td><code id="expect.max.ostat_+3A_aslist">aslist</code></td>
<td>
<p>A logically triggering whether an <span class="rlang"><b>R</b></span> <code>list</code> is returned instead of just the expection.</p>
</td></tr>
<tr><td><code id="expect.max.ostat_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass to the three distribution functions.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If <code>qua != NULL</code>, then the first order-statistic expectation equation above is used, and any function that might have been set in <code>cdf</code> and <code>pdf</code> is <em>ignored</em>. If the limits are infinite (default), then the limits of the integration will be set to <code class="reqn">F\!\downarrow = 0</code> and  <code class="reqn">F\!\uparrow = 1</code>. The user can replace these by setting the limits to something &ldquo;near&rdquo; zero and(or) &ldquo;near&rdquo; 1. Please consult the <b>Note</b> below concerning more information about the limits of integration.
</p>
<p>If <code>qua == NULL</code>, then the second order-statistic expectation equation above is used and <code>cdf</code> and <code>pdf</code> must be set. The default <code class="reqn">\pm\infty</code> limits are used unless the user <em>knows</em> otherwise for the distribution or through supervision provides their meaning of <em>small</em> and <em>large</em>.
</p>
<p>This function requires the user to provide either the <code>qua</code> or the <code>cdf</code> and <code>pdf</code> functions, which is somewhat divergent from the typical flow of logic of <span class="pkg">lmomco</span>. This has been done so that <code><a href="#topic+expect.max.ostat">expect.max.ostat</a></code> can be used readily for experimental distribution functions. It is suggested that the parameter object be left in the <span class="pkg">lmomco</span> style (see <code><a href="#topic+vec2par">vec2par</a></code>) even if the user is providing their own distribution functions.
</p>
<p>Last comments: This function is built around the idea that either (1) the <code>cdf</code> and <code>pdf</code> ensemble or (2) <code>qua</code> exist in some clean analytical form and therefore the <code>qua=NULL</code> is the trigger on which order statistic expectation integral is used. This precludes an attempt to compute the support of the distribution  internally, and thus providing possibly superior (more refined) <code>lower</code> and <code>upper</code> limits. Here is a suggested re-implementation using the support of the Generalized Extreme Value distribution:
</p>
<pre>
para &lt;- vec2par(c(100, 23, -0.5), type="gev")
lo &lt;- quagev(0, para) # The value 54
hi &lt;- quagev(1, para) # Infinity
E22 &lt;- expect.max.ostat(2, para=para,cdf=cdfgev, pdf=pdfgev,
                           lower=lo, upper=hi)
E21 &lt;- expect.min.ostat(2, para=para,cdf=cdfgev, pdf=pdfgev,
                           lower=lo, upper=hi)
L2 &lt;- (E22 - E21)/2 # definition of L-scale
cat("L-scale: ", L2, "(integration)",
    lmomgev(para)$lambdas[2], "(theory)\n")
# The results show 33.77202 as L-scale.
</pre>
<p>The design intent makes it possible for some arbitrary and(or) new quantile function with difficult <code>cdf</code> and <code>pdf</code> expressions (or numerical approximations) to not be needed as the L-moments are explored. Contrarily, perhaps some new <code>pdf</code> exists and simple integration of it is made to get the <code>cdf</code> but the <code>qua</code> would need more elaborate numerics to invert the <code>cdf</code>. The user could then still explore the L-moments with supervision on the integration limits or foreknowledge of the support of the distribution.
</p>


<h3>Value</h3>

<p>The expectation of the maximum order statistic, unless <code class="reqn">j</code> is specified and then the expectation of that order statistic is returned. This similarly holds if the <code><a href="#topic+expect.min.ostat">expect.min.ostat</a></code> function is used except &ldquo;maximum&rdquo; becomes the &ldquo;minimum&rdquo;.
</p>
<p>Alternatively, an <span class="rlang"><b>R</b></span> <code>list</code> is returned.
</p>
<table>
<tr><td><code>type</code></td>
<td>
<p>The type of approach used: &ldquo;bypdfcdf&rdquo; means the PDF and CDF of the distribution were used, and alternatively &ldquo;byqua&rdquo; means that the quantile function was used.</p>
</td></tr>
<tr><td><code>value</code></td>
<td>
<p>See previous discussion of value.</p>
</td></tr>
<tr><td><code>abs.error</code></td>
<td>
<p>Estimate of the modulus of the absolute error from <span class="rlang"><b>R</b></span> function <code>integrate</code>.</p>
</td></tr>
<tr><td><code>subdivisions</code></td>
<td>
<p>The number of subintervals produced in the subdivision process from <span class="rlang"><b>R</b></span> function <code>integrate</code>.</p>
</td></tr>
<tr><td><code>message</code></td>
<td>
<p>&ldquo;OK&rdquo; or a character string giving the error message.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>A function such as this might be helpful for computations involving distribution mixtures. Mixtures are readily made using the algebra of quantile functions (Gilchrist, 2000; Asquith, 2011, sec. 2.1.5 &ldquo;The Algebra of Quantile Functions&rdquo;).
</p>
<p>Last comments: Internally, judicious use of logarithms and exponents for the terms involving the <code class="reqn">F</code> and <code class="reqn">1-F</code> and the quantities to the left of the intergrals shown above are made in an attempt to maximize stability of the function without the user having to become too invested in the <code>lower</code> and <code>upper</code> limits. For example, <code class="reqn">(1-F)^{n-j} \rightarrow \exp([n-j]\log(1-F))</code>. Testing indicates that this coding practice is quite useful. But there will undoubtedly be times for which the user needs to be informed enough about the expected value on return to identify that tweaking to the integration limits is needed. Also use of <span class="rlang"><b>R</b></span> functions <code>lbeta</code> and <code>lchoose</code> is made to maximize operations in logarithmic space.
</p>
<p>For <span class="pkg">lmomco</span> v.2.1.+: Because of the extensive use of exponents and logarithms as described, enhanced deep tail estimation of the extrema for large <code class="reqn">n</code> and large or small <code class="reqn">j</code> results. This has come at the expense that expectations can be computed when the expectations actually do not exist. An error in the integration no longer occurs in <span class="pkg">lmomco</span>. For example, the Cauchy distribution has infinite extrema but this function (for least for a selected parameter set and <code>n=10</code>) provides apparent values for the <code class="reqn">\mathrm{E}[X_{1:n}]</code> and <code class="reqn">\mathrm{E}[X_{n:n}]</code> when the <code>cdf</code> and <code>pdf</code> are used but not when the <code>qua</code> is used. Users are cautioned to not rely on <code><a href="#topic+expect.max.ostat">expect.max.ostat</a></code> &ldquo;knowing&rdquo; that a given distribution has undefined order statistic extrema. Now for the Cauchy case just described, the extrema for <code class="reqn">j = [1, n]</code> are hugely(!) greater in magnitude than for <code class="reqn">j = [2, (n-1)]</code>, so some resemblance of <em>infinity</em> remains.
</p>
<p>The alias <code><a href="#topic+eostat">eostat</a></code> is a shorter name dispatching to <code><a href="#topic+expect.max.ostat">expect.max.ostat</a></code> all of the arguments.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Asquith, W.H., 2011, Distributional analysis with L-moment statistics using the R environment for statistical computing: Createspace Independent Publishing Platform, ISBN 978&ndash;146350841&ndash;8.
</p>
<p>Gilchrist, W.G., 2000, Statistical modelling with quantile functions: Chapman and Hall/CRC, Boca Raton.
</p>
<p>Hosking, J.R.M., 2006, On the characterization of distributions by their L-moments: Journal of Statistical Planning and Inference, v. 136, no. 1, pp. 193&ndash;198.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+theoLmoms.max.ostat">theoLmoms.max.ostat</a></code>, <code><a href="#topic+expect.min.ostat">expect.min.ostat</a></code>, <code><a href="#topic+eostat">eostat</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>para &lt;- vec2par(c(10, 100), type="nor")
n &lt;- 12
# The three outputted values from should be similar:
# (1) theoretical, (2) theoretical, and (3) simulation
expect.max.ostat(n, para=para, cdf=cdfnor, pdf=pdfnor)
expect.max.ostat(n, para=para, qua=quanor)
mean(sapply(seq_len(1000), function(x) { max(rlmomco(n, para))}))

eostat(8, j=5, qua=quagum, para=vec2par(c(1670, 1000), type="gum"))

## Not run: 
para &lt;- vec2par(c(1280, 800), type="nor")
expect.max.ostat(10, j=9, para, qua=quanor)
[1] 2081.086      # SUCCESS ---------------------------
expect.max.ostat(10, j=9, para, pdf=pdfnor, cdf=cdfnor,
                                lower=-1E3, upper=1E6)
[1] 1.662701e-06  # FAILURE ---------------------------
expect.max.ostat(10, j=9, para, pdf=pdfnor, cdf=cdfnor,
                                lower=-1E3, upper=1E5)
[1] 2081.086      # SUCCESS ---------------------------
## End(Not run)
</code></pre>

<hr>
<h2 id='f2f'>Subsetting of Nonexceedance Probabilities Related to Conditional Probability Adjustment</h2><span id='topic+f2f'></span>

<h3>Description</h3>

<p>This function subsetting nonexceedance probability according to
</p>
<p style="text-align: center;"><code class="reqn">
F(x) &lt;- F(x | F(x) [&gt;,\ge] p)\mathrm{,}
</code>
</p>

<p>where <code class="reqn">F</code> is nonexceedance probability for <code class="reqn">x</code> and <code>pp</code> is the probability of a threshold. In <span class="rlang"><b>R</b></span> logic, this is simply <code>f &lt;- f[f &gt; pp]</code> for <code>type == "gt"</code> or <code>f &lt;- f[f &gt;= pp]</code> for <code>type == "ge"</code>.
</p>
<p>This function is particularly useful to shorten a commonly needed code logic related such as <code>FF[FF &gt;= XloALL$pp]</code>, which would be needed in conditional probability adjustements and <code>XloALL</code> is from <code><a href="#topic+x2xlo">x2xlo</a></code>. This could be replaced by syntax such as <code>f2f(FF, xlo=XloALL)</code>.  This function is very similar to <code><a href="#topic+f2flo">f2flo</a></code> with the only exception that the conditional probability adjustment is not made.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>f2f(f, pp=NA, xlo=NULL, type=c("ge", "gt"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="f2f_+3A_f">f</code></td>
<td>
<p>A vector of nonexceedance probabilities.</p>
</td></tr>
<tr><td><code id="f2f_+3A_pp">pp</code></td>
<td>
<p>The plotting position of the left-hand threshold and recommended to come from <code><a href="#topic+x2xlo">x2xlo</a></code>.</p>
</td></tr>
<tr><td><code id="f2f_+3A_xlo">xlo</code></td>
<td>
<p>An optional result from <code><a href="#topic+x2xlo">x2xlo</a></code> from which the <code>pp</code> will be take instead of from the argument <code>pp</code>.</p>
</td></tr>
<tr><td><code id="f2f_+3A_type">type</code></td>
<td>
<p>The type of the logical construction <code>gt</code> means greater than the <code>pp</code> and <code>ge</code> means greater than or equal to the <code>pp</code> for the computations. There can be subtle variations in conceptualization of the truncation need or purpose and hence this argument is provided for flexibility.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of conditional nonexceedance probabilities.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>See Also</h3>

<p><code><a href="#topic+x2xlo">x2xlo</a></code>, <code><a href="#topic+xlo2qua">xlo2qua</a></code>, <code><a href="#topic+f2flo">f2flo</a></code>, <code><a href="#topic+f2f">f2f</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'># See examples for x2xlo().
</code></pre>

<hr>
<h2 id='f2flo'>Conversion of Annual Nonexceedance Probability to Conditional Probability Nonexceedance Probabilities</h2><span id='topic+f2flo'></span>

<h3>Description</h3>

<p>This function converts the cumulative distribution function of <code class="reqn">F(x)</code> to a conditional cumulative distribution function <code class="reqn">P(x)</code> based on the probability level of the left-hand threshold. It is recommended that this threshold (as expressed as a probability) be that value returned from <code><a href="#topic+x2xlo">x2xlo</a></code> in element <code>pp</code>. The conversion is simple
</p>
<p style="text-align: center;"><code class="reqn">
P(x) &lt;- (F(x) - pp)/(1-pp)\mathrm{,}
</code>
</p>

<p>where the term <code class="reqn">\mathrm{pp}</code> corresponds to the estimated probability or plotting position of the left-hand threshold.
</p>
<p>This function is particularly useful for applications in which zero values in the data set require truncation so that logarithms of the data may be used. But also this function contributes to the isolation of the right-hand tail of the distribution for analysis. Finally, <code>f &lt;- f[f &gt;= pp]</code> for <code>type="ge"</code> or <code>f &lt;- f[f &gt; pp]</code> for <code>type="gt"</code> is used internally for probability subsetting, so the user does not have to do that with the nonexceedance probability before calling this function. The function <code><a href="#topic+f2f">f2f</a></code> does similar subsetting without converting <code class="reqn">F(x)</code> to <code class="reqn">P(x)</code>. Users are directed to <b>Examples</b> under <code><a href="#topic+par2qua2lo">par2qua2lo</a></code> and carefully note how <code>f2flo</code> and <code><a href="#topic+f2f">f2f</a></code> are used.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>f2flo(f, pp=NA, xlo=NULL, type=c("ge", "gt"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="f2flo_+3A_f">f</code></td>
<td>
<p>A vector of nonexceedance probabilities.</p>
</td></tr>
<tr><td><code id="f2flo_+3A_pp">pp</code></td>
<td>
<p>The plotting position of the left-hand threshold and recommended to come from <code><a href="#topic+x2xlo">x2xlo</a></code>.</p>
</td></tr>
<tr><td><code id="f2flo_+3A_xlo">xlo</code></td>
<td>
<p>An optional result from <code><a href="#topic+x2xlo">x2xlo</a></code> from which the <code>pp</code> will be take instead of from the argument <code>pp</code>.</p>
</td></tr>
<tr><td><code id="f2flo_+3A_type">type</code></td>
<td>
<p>The type of the logical construction <code>gt</code> means greater than the <code>pp</code> and <code>ge</code> means greater than or equal to the <code>pp</code> for the computations. There can be subtle variations in conceptualization of the truncation need or purpose and hence this argument is provided for flexibility.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of conditional nonexceedance probabilities.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>See Also</h3>

<p><code><a href="#topic+x2xlo">x2xlo</a></code>, <code><a href="#topic+flo2f">flo2f</a></code>, <code><a href="#topic+f2f">f2f</a></code>, <code><a href="#topic+xlo2qua">xlo2qua</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'># See examples for x2xlo().
</code></pre>

<hr>
<h2 id='f2fpds'>Conversion of Annual Nonexceedance Probability to Partial Duration Nonexceedance Probability</h2><span id='topic+f2fpds'></span>

<h3>Description</h3>

<p>This function takes an annual exceedance probability and converts it to a &ldquo;partial-duration series&rdquo; (a term in Hydrology) nonexceedance probability through a simple assumption that the Poisson distribution is appropriate for arrive modeling. The relation between the cumulative distribution function <code class="reqn">G(x)</code> for the partial-duration series is related to the cumulative distribution function <code class="reqn">F(x)</code> of the annual series (data on an annual basis and quite common in Hydrology) by
</p>
<p style="text-align: center;"><code class="reqn">G(x) = [\log(F(x)) + \eta]/\eta\mathrm{.}</code>
</p>

<p>The core assumption is that successive events in the partial-duration series can be considered as <em>independent</em>. The <code class="reqn">\eta</code> term is the arrival rate of the events. For example, suppose that 21 events have occurred in 15 years, then <code class="reqn">\eta = 21/15 = 1.4</code> events per year.
</p>
<p>A comprehensive demonstration is shown in the example for <code><a href="#topic+fpds2f">fpds2f</a></code>. That function performs the opposite conversion. Lastly, the cross reference to <code><a href="#topic+x2xlo">x2xlo</a></code> is made because the example contained therein provides another demonstration of partial-duration and annual series frequency analysis.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>f2fpds(f, rate=NA)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="f2fpds_+3A_f">f</code></td>
<td>
<p>A vector of annual nonexceedance probabilities.</p>
</td></tr>
<tr><td><code id="f2fpds_+3A_rate">rate</code></td>
<td>
<p>The number of events per year.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of converted nonexceedance probabilities.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Stedinger, J.R., Vogel, R.M., Foufoula-Georgiou, E., 1993, Frequency analysis of extreme events: <em>in</em> Handbook of Hydrology, ed. Maidment, D.R., McGraw-Hill, Section 18.6 Partial duration series, mixtures, and censored data, pp. 18.37&ndash;18.39.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+fpds2f">fpds2f</a></code>, <code><a href="#topic+x2xlo">x2xlo</a></code>, <code><a href="#topic+f2flo">f2flo</a></code>, <code><a href="#topic+flo2f">flo2f</a></code>  </p>


<h3>Examples</h3>

<pre><code class='language-R'># See examples for fpds2f().
</code></pre>

<hr>
<h2 id='fliplmoms'>Flip L-moments by Flip Attribute in L-moment Vector</h2><span id='topic+fliplmoms'></span>

<h3>Description</h3>

<p>This function flips the L-moments by a flip attribute within an L-moment object such as that returned by <code><a href="#topic+lmomsRCmark">lmomsRCmark</a></code>. The function will attempt to identify the L-moment object and <code><a href="#topic+lmorph">lmorph</a></code> as necessary, but this support is not guaranteed.  The flipping process is used to support left-tail censoring using the right-tail censoring alogrithms of <span class="pkg">lmomco</span>. The odd order (<code>seq(3,n,by2)</code>) <code class="reqn">\lambda_r</code> and <code class="reqn">\tau_r</code> are negated. The mean <code class="reqn">\hat\lambda_1</code> is computed by subtracting the <code class="reqn">\lambda_1</code> from the <var>lmom</var> argument from the flip <var>M</var>: <code class="reqn">\hat\lambda_1 = M - \lambda_1</code> and the <code class="reqn">\tau_2</code> is subsequently adjusted by the new mean. This function is written to provide a convenient method to re-transform or back flip the L-moments computed by <code><a href="#topic+lmomsRCmark">lmomsRCmark</a></code>. Detailed review of the example problem listed here is recommended.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fliplmoms(lmom, flip=NULL, checklmom=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fliplmoms_+3A_lmom">lmom</code></td>
<td>
<p>A L-moment object created by <code><a href="#topic+lmomsRCmark">lmomsRCmark</a></code> or other vectorize L-moment list.</p>
</td></tr>
<tr><td><code id="fliplmoms_+3A_flip">flip</code></td>
<td>
<p><code><a href="#topic+lmomsRCmark">lmomsRCmark</a></code> provides the flip, but for other vectorized L-moment list support, the flip can be set by this argument.</p>
</td></tr>
<tr><td><code id="fliplmoms_+3A_checklmom">checklmom</code></td>
<td>
<p>Should the <code>lmom</code> be checked for validity using the <code><a href="#topic+are.lmom.valid">are.lmom.valid</a></code> function. Normally this should be left as the default and it is very unlikely that the L-moments will not be viable (particularly in the <code class="reqn">\tau_4</code> and <code class="reqn">\tau_3</code> inequality). However, for some circumstances or large simulation exercises then one might want to bypass this check.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> is returned that matches the structure of the <var>lmom</var> argument (unless an <code><a href="#topic+lmorph">lmorph</a></code> was attempted). The structure is intended to match that coming from <code><a href="#topic+lmomsRCmark">lmomsRCmark</a></code>.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Wang, Dongliang, Hutson, A.D., and Miecznikowski, J.C., 2010,  L-moment estimation for parametric survival models given censored data: Statistical Methodology, v. 7, no. 6, pp. 655&ndash;667.
</p>
<p>Helsel, D.R., 2005, Nondetects and data analysis&mdash;Statistics for censored environmental data: Hoboken, New Jersey, John Wiley, 250 p.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lmomsRCmark">lmomsRCmark</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Create some data with **multiple detection limits**
# This is a left-tail censoring problem, and flipping will be required.
fakedat1 &lt;- rnorm(50, mean=16, sd=5)
fake1.left.censor.indicator &lt;- fakedat1 &lt;  14
fakedat1[fake1.left.censor.indicator]   &lt;- 14

fakedat2 &lt;- rnorm(50, mean=16, sd=5)
fake2.left.censor.indicator &lt;- fakedat2 &lt;  10
fakedat2[fake2.left.censor.indicator]   &lt;- 10

# combine the data sets
fakedat &lt;- c(fakedat1, fakedat2);
fake.left.censor.indicator &lt;- c(fake1.left.censor.indicator,
                                fake2.left.censor.indicator)
ix &lt;- order(fakedat)
fakedat &lt;- fakedat[ix]
fake.left.censor.indicator &lt;- fake.left.censor.indicator[ix]

lmr.usual       &lt;- lmoms(fakedat)
lmr.flipped     &lt;- lmomsRCmark(fakedat, flip=TRUE,
                               rcmark=fake.left.censor.indicator)
lmr.backflipped &lt;- fliplmoms(lmr.flipped); # re-transform
pch &lt;- as.numeric(fake.left.censor.indicator)*15 + 1
F &lt;- nonexceeds()
plot(pp(fakedat), sort(fakedat), pch=pch,
     xlab="NONEXCEEDANCE PROBABILITY", ylab="DATA VALUE")
lines(F, qlmomco(F, parnor(lmr.backflipped)), lwd=2)
lines(F, qlmomco(F, parnor(lmr.usual)), lty=2)
legend(0,20, c("Uncensored", "Left-tail censored"), pch=c(1,16))
# The solid line represented the Normal distribution fit by
# censoring indicator on the multiple left-tail detection limits.
## Not run: 
# see example in pwmRC
H &lt;- c(3,4,5,6,6,7,8,8,9,9,9,10,10,11,11,11,13,13,13,13,13,
       17,19,19,25,29,33,42,42,51.9999,52,52,52)
# 51.9999 was really 52, a real (noncensored) data point.
flip &lt;- 100
F &lt;- flip - H #
RCpwm &lt;- pwmRC(H, threshold=52)
lmorph(pwm2lmom(vec2pwm(RCpwm$Bbetas))) # OUTPUT1 STARTS HERE

LCpwm &lt;- pwmLC(F, threshold=(flip - 52))
LClmr &lt;- pwm2lmom(vec2pwm(LCpwm$Bbetas))
LClmr &lt;- lmorph(LClmr)
#LClmr$flip &lt;- 100; fliplmoms(LClmr) # would also work
fliplmoms(LClmr, flip=flip) # OUTPUT2 STARTS HERE

# The two outputs are the same showing how the flip argument works 
## End(Not run)
</code></pre>

<hr>
<h2 id='flo2f'>Conversion of Conditional Nonexceedance Probability to Annual Nonexceedance Probability</h2><span id='topic+flo2f'></span>

<h3>Description</h3>

<p>This function converts  the conditional cumulative distribution function of <code class="reqn">P(x)</code> to a cumulative distribution function <code class="reqn">F(x)</code> based on the probability level of the left-hand threshold. It is recommended that this threshold (as expressed as a probability) be that value returned from <code><a href="#topic+x2xlo">x2xlo</a></code> in attribute <code>pp</code>. The conversion is simple
</p>
<p style="text-align: center;"><code class="reqn">
F(x) = pp + (1 - pp)P(x)\mathrm{,}
</code>
</p>

<p>where the term <code class="reqn">pp</code> corresponds to the estimated probability or plotting position of the left-hand threshold.
</p>
<p>This function is particularly useful for applications in which zero values in the data set require truncation so that logarithms of the data may be used. But also this function  contributes to the isolation of the right-hand tail of the distribution for analysis by conditionally trimming out the left-hand tail at the analyst's discretion.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>flo2f(f, pp=NA, xlo=NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="flo2f_+3A_f">f</code></td>
<td>
<p>A vector of nonexceedance probabilities.</p>
</td></tr>
<tr><td><code id="flo2f_+3A_pp">pp</code></td>
<td>
<p>The plotting position of the left-hand threshold and recommended to come from <code><a href="#topic+x2xlo">x2xlo</a></code>.</p>
</td></tr>
<tr><td><code id="flo2f_+3A_xlo">xlo</code></td>
<td>
<p>An optional result from <code><a href="#topic+x2xlo">x2xlo</a></code> from which the <code>pp</code> will be take instead of from the argument <code>pp</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of converted nonexceedance probabilities.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>See Also</h3>

<p><code><a href="#topic+x2xlo">x2xlo</a></code>, <code><a href="#topic+f2flo">f2flo</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>flo2f(f2flo(.73,pp=.1),pp=.1)
# Also see examples for x2xlo().
</code></pre>

<hr>
<h2 id='fpds2f'>Conversion of Partial-Duration Nonexceedance Probability to Annual Nonexceedance Probability</h2><span id='topic+fpds2f'></span>

<h3>Description</h3>

<p>This function takes partial duration series nonexceedance probability and converts it to a  an annual exceedance probability through a simple assumption that the Poisson distribution is appropriate. The relation between the cumulative distribution function <code class="reqn">F(x)</code> for the annual series is related to the cumulative distribution function <code class="reqn">G(x)</code> of the partial-duration series by
</p>
<p style="text-align: center;"><code class="reqn">F(x) = \mathrm{exp}(-\eta[1 - G(x)])\mathrm{.}</code>
</p>

<p>The core assumption is that successive events in the partial-duration series can be considered as <em>independent</em>. The <code class="reqn">\eta</code> term is the arrival rate of the events. For example, suppose that 21 events have occurred in 15 years, then <code class="reqn">\eta = 21/15 = 1.4</code> events per year.
</p>
<p>The example documented here provides a comprehensive demonstration of the function along with a partnering function <code><a href="#topic+f2fpds">f2fpds</a></code>. That function performs the opposite conversion. Lastly, the cross reference to <code><a href="#topic+x2xlo">x2xlo</a></code> is made because the example contained therein provides another demonstration of partial-duration and annual series frequency analysis.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fpds2f(fpds, rate=NA)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fpds2f_+3A_fpds">fpds</code></td>
<td>
<p>A vector of partial-duration nonexceedance probabilities.</p>
</td></tr>
<tr><td><code id="fpds2f_+3A_rate">rate</code></td>
<td>
<p>The number of events per year.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of converted nonexceedance probabilities.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Stedinger, J.R., Vogel, R.M., Foufoula-Georgiou, E., 1993, Frequency analysis of extreme events: <em>in</em> Handbook of Hydrology, ed. Maidment, D.R., McGraw-Hill, Section 18.6 Partial duration series, mixtures, and censored data, pp. 18.37&ndash;18.39.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+f2fpds">f2fpds</a></code>, <code><a href="#topic+x2xlo">x2xlo</a></code>, <code><a href="#topic+f2flo">f2flo</a></code>, <code><a href="#topic+flo2f">flo2f</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
stream &lt;- "A Stream in West Texas"
Qpds    &lt;- c(61.8, 122, 47.3, 71.1, 211, 139, 244, 111, 233, 102)
Qann &lt;- c(61.8, 122, 71.1, 211, 244, 0, 233)
years  &lt;- length(Qann)  # gage has operated for about 7 years
visits &lt;- 27  # number of visits or "events"
rate   &lt;- visits/years
Z &lt;- rep(0, visits-length(Qpds))
Qpds &lt;- c(Qpds,Z) # The creation of a partial duration series
# that will contain numerous zero values.

Fs &lt;- seq(0.001,.999, by=.005) # used to generate curves

type &lt;- "pe3" # The Pearson type III distribution
PPpds &lt;- pp(Qpds); Qpds &lt;- sort(Qpds) # plotting positions (partials)
PPann &lt;- pp(Qann); Qann &lt;- sort(Qann) # plotting positions (annuals)
parann &lt;- lmom2par(lmoms(Qann), type=type) # parameter estimation (annuals)
parpsd &lt;- lmom2par(lmoms(Qpds), type=type) # parameter estimation (partials)

Fsplot    &lt;- qnorm(Fs) # in order to produce normal probability paper
PPpdsplot &lt;- qnorm(fpds2f(PPpds, rate=rate)) # ditto
PPannplot &lt;- qnorm(PPann) # ditto

# There are many zero values in this particular data set that require leaving
# them out in order to achieve appropriate curvature of the Pearson type III
# distribution. Conditional probability adjustments will be used.
Qlo &lt;- x2xlo(Qpds) # Create a left out object with an implied threshold of zero
parlo &lt;- lmom2par(lmoms(Qlo$xin), type=type) # parameter estimation for the
# partial duration series values that are greater than the threshold, which
# defaults to zero.

plot(PPpdsplot, Qpds, type="n", ylim=c(0,400), xlim=qnorm(c(.01,.99)),
     xlab="STANDARD NORMAL VARIATE", ylab="DISCHARGE, IN CUBIC FEET PER SECOND")
mtext(stream)
points(PPannplot, Qann, col=3, cex=2, lwd=2, pch=0)
points(qnorm(fpds2f(PPpds, rate=rate)), Qpds, pch=16, cex=0.5 )
points(qnorm(fpds2f(flo2f(pp(Qlo$xin), pp=Qlo$pp), rate=rate)),
       sort(Qlo$xin), col=2, lwd=2, cex=1.5, pch=1)
points(qnorm(fpds2f(Qlo$ppout, rate=rate)),
       Qlo$xout, pch=4, col=4)

lines(qnorm(fpds2f(Fs, rate=rate)),
      qlmomco(Fs, parpsd), lwd=1, lty=2)
lines(Fsplot, qlmomco(Fs, parann), col=3, lwd=2)
lines(qnorm(fpds2f(flo2f(Fs, pp=Qlo$pp), rate=rate)),
      qlmomco(Fs, parlo), col=2, lwd=3)

# The following represents a subtle application of the probability transform
# functions. The show how one starts with annual recurrence intervals
# converts into conventional annual nonexceedance probabilities as well as
# converting these to the partial duration nonexceedance probabilities.
Tann &lt;- c(2, 5, 10, 25, 50, 100)
Fann &lt;- T2prob(Tann); Gpds &lt;- f2fpds(Fann, rate=rate)
FFpds &lt;- qlmomco(f2flo(Gpds, pp=Qlo$pp), parlo)
FFann &lt;- qlmomco(Fann, parann)
points(qnorm(Fann), FFpds, col=2, pch=16)
points(qnorm(Fann), FFann, col=3, pch=16)

legend(-2.4,400, c("True annual series (with one zero year)",
                "Partial duration series (including 'visits' as 'events')",
                "Partial duration series (after conditional adjustment)",
                "Left-out values (&lt;= zero) (trigger of conditional probability)",
                "PE3 partial-duration frequency curve (PE3-PDS)",
                "PE3 annual-series frequency curve (PE3-ANN)",
                "PE3 partial-duration frequency curve (zeros removed) (PE3-PDSz)",
                "PE3-ANN  T-year event: 2, 5, 10, 25, 50, 100 years",
                "PE3-PDSz T-year event: 2, 5, 10, 25, 50, 100 years"),
       bty="n", cex=.75,
       pch=c(0,  16, 1, 4, NA, NA, NA, 16, 16),
       col=c(3,  1, 2,  4,  1,  3,  2,  3, 2),
       pt.lwd=c(2,1,2,1), pt.cex=c(2, 0.5, 1.5, 1, NA, NA, NA, 1, 1),
       lwd=c(0,0,0,0,1,2,3), lty=c(0,0,0,0,2,1,1))

## End(Not run)
</code></pre>

<hr>
<h2 id='freq.curve.all'>Compute Frequency Curve for Almost All Distributions</h2><span id='topic+freq.curve.all'></span>

<h3>Description</h3>

<p>This function is dispatcher on top of a select suite of <code>quaCCC</code> functions that compute frequency curves for the L-moments. The term &ldquo;frequency curves&rdquo; is common in hydrology and is a renaming of the more widenly known by statisticians term the &ldquo;quantile function.&rdquo; The notation <code>CCC</code> represents the character notation for the distribution: <code>exp</code>, <code>gam</code>, <code>gev</code>, <code>gld</code>, <code>glo</code>, <code>gno</code>, <code>gpa</code>, <code>gum</code>, <code>kap</code>, <code>nor</code>, <code>pe3</code>, <code>wak</code>, and <code>wei</code>. The nonexceedance probabilities to construct the curves are derived from <code><a href="#topic+nonexceeds">nonexceeds</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>freq.curve.all(lmom, aslog10=FALSE, asprob=TRUE,
                     no2para=FALSE, no3para=FALSE,
                     no4para=FALSE, no5para=FALSE,
                     step=FALSE, show=FALSE,
                     xmin=NULL, xmax=NULL, xlim=NULL,
                     ymin=NULL, ymax=NULL, ylim=NULL,
                     aep4=FALSE, exp=TRUE, gam=TRUE, gev=TRUE, gld=FALSE,
                     glo=TRUE, gno=TRUE, gpa=TRUE, gum=TRUE, kap=TRUE,
                     nor=TRUE, pe3=TRUE, wak=TRUE, wei=TRUE,...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="freq.curve.all_+3A_lmom">lmom</code></td>
<td>
<p>A L-moment object from <code><a href="#topic+lmoms">lmoms</a></code>, <code><a href="#topic+lmom.ub">lmom.ub</a></code>, or <code><a href="#topic+vec2lmom">vec2lmom</a></code>.</p>
</td></tr>
<tr><td><code id="freq.curve.all_+3A_aslog10">aslog10</code></td>
<td>
<p>Compute <code>log10</code> of quantiles&mdash;note that </p>
<pre>NaNs produced in: log(x, base)</pre><p> will be produced for less than zero values.</p>
</td></tr>
<tr><td><code id="freq.curve.all_+3A_asprob">asprob</code></td>
<td>
<p>The <span class="rlang"><b>R</b></span> <code>qnorm</code> function is used to convert nonexceedance probabilities, which are produced by <code><a href="#topic+nonexceeds">nonexceeds</a></code>, to standard normal variates. The Normal distribution will plot as straight line when this argument is <code>TRUE</code></p>
</td></tr>
<tr><td><code id="freq.curve.all_+3A_no2para">no2para</code></td>
<td>
<p>If <code>TRUE</code>, do not run the 2-parameter distributions: <code>exp</code>, <code>gam</code>, <code>gum</code>, and <code>nor</code>.</p>
</td></tr>
<tr><td><code id="freq.curve.all_+3A_no3para">no3para</code></td>
<td>
<p>If <code>TRUE</code>, do not run the 3-parameter distributions: <code>gev</code>, <code>glo</code>, <code>gno</code>, <code>gpa</code>, <code>pe3</code>, and <code>wei</code>.</p>
</td></tr>
<tr><td><code id="freq.curve.all_+3A_no4para">no4para</code></td>
<td>
<p>If <code>TRUE</code>, do not run the 4-parameter distributions: <code>kap</code>, <code>gld</code>, <code>aep4</code>.</p>
</td></tr>
<tr><td><code id="freq.curve.all_+3A_no5para">no5para</code></td>
<td>
<p>If <code>TRUE</code>, do not run the 5-parameter distributions: <code>wak</code>.</p>
</td></tr>
<tr><td><code id="freq.curve.all_+3A_step">step</code></td>
<td>
<p>Shows incremental processing of each distribution.</p>
</td></tr>
<tr><td><code id="freq.curve.all_+3A_show">show</code></td>
<td>
<p>Plots all the frequency curves in a simple (crowded) <code>plot</code>.</p>
</td></tr>
<tr><td><code id="freq.curve.all_+3A_xmin">xmin</code></td>
<td>
<p>Minimum x-axis value to use instead of the automatic value determined from the nonexceedance probabilities. This argument is only used is <code>show=TRUE</code>.</p>
</td></tr>
<tr><td><code id="freq.curve.all_+3A_xmax">xmax</code></td>
<td>
<p>Maximum x-axis value to use instead of the automatic value determined from the nonexceedance probabilities. This argument is only used is <code>show=TRUE</code>.</p>
</td></tr>
<tr><td><code id="freq.curve.all_+3A_xlim">xlim</code></td>
<td>
<p>Both limits of the x-axis. This argument is only used is <code>show=TRUE</code>.</p>
</td></tr>
<tr><td><code id="freq.curve.all_+3A_ymin">ymin</code></td>
<td>
<p>Minimum y-axis value to use instead of the automatic value determined from the nonexceedance probabilities. This argument is only used is <code>show=TRUE</code>.</p>
</td></tr>
<tr><td><code id="freq.curve.all_+3A_ymax">ymax</code></td>
<td>
<p>Maximum y-axis value to use instead of the automatic value determined from the nonexceedance probabilities. This argument is only used is <code>show=TRUE</code>.</p>
</td></tr>
<tr><td><code id="freq.curve.all_+3A_ylim">ylim</code></td>
<td>
<p>Both limits of the y-axis. This argument is only used is <code>show=TRUE</code>.</p>
</td></tr>
<tr><td><code id="freq.curve.all_+3A_aep4">aep4</code></td>
<td>
<p>A logical switch on computation of corresponding distribution&mdash;default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="freq.curve.all_+3A_exp">exp</code></td>
<td>
<p>A logical switch on computation of corresponding distribution&mdash;default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="freq.curve.all_+3A_gam">gam</code></td>
<td>
<p>A logical switch on computation of corresponding distribution&mdash;default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="freq.curve.all_+3A_gev">gev</code></td>
<td>
<p>A logical switch on computation of corresponding distribution&mdash;default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="freq.curve.all_+3A_gld">gld</code></td>
<td>
<p>A logical switch on computation of corresponding distribution&mdash;default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="freq.curve.all_+3A_glo">glo</code></td>
<td>
<p>A logical switch on computation of corresponding distribution&mdash;default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="freq.curve.all_+3A_gno">gno</code></td>
<td>
<p>A logical switch on computation of corresponding distribution&mdash;default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="freq.curve.all_+3A_gpa">gpa</code></td>
<td>
<p>A logical switch on computation of corresponding distribution&mdash;default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="freq.curve.all_+3A_gum">gum</code></td>
<td>
<p>A logical switch on computation of corresponding distribution&mdash;default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="freq.curve.all_+3A_kap">kap</code></td>
<td>
<p>A logical switch on computation of corresponding distribution&mdash;default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="freq.curve.all_+3A_nor">nor</code></td>
<td>
<p>A logical switch on computation of corresponding distribution&mdash;default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="freq.curve.all_+3A_pe3">pe3</code></td>
<td>
<p>A logical switch on computation of corresponding distribution&mdash;default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="freq.curve.all_+3A_wak">wak</code></td>
<td>
<p>A logical switch on computation of corresponding distribution&mdash;default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="freq.curve.all_+3A_wei">wei</code></td>
<td>
<p>A logical switch on computation of corresponding distribution&mdash;default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="freq.curve.all_+3A_...">...</code></td>
<td>
<p>Additional parameters are passed to the parameter estimation routines such as <code>parexp</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An extensive <span class="rlang"><b>R</b></span> <code>data.frame</code> of frequency curves. The nonexceedance probability values, which are provided by <code><a href="#topic+nonexceeds">nonexceeds</a></code>, are the first item in the <code>data.frame</code> under the heading of <code><a href="#topic+nonexceeds">nonexceeds</a></code>. If a particular distribution could not be fit to the L-moments of the data; this particular function returns zeros.
</p>


<h3>Note</h3>

<p>The distributions selected for this function represent a substantial fraction of, but not all, distributions supported by <span class="pkg">lmomco</span>. The <code>all</code> and &ldquo;all&rdquo; in the function name and the title of this documentation is a little misleading. The selection process was made near the beginning of <span class="pkg">lmomco</span> availability and distributions available in the earliest versions. Further the selected distributions are frequently encountered in hydrology and because these are also those considered in length by Hosking and Wallis (1997) and the <span class="pkg">lmom</span> package.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Hosking, J.R.M., and Wallis, J.R., 1997, Regional frequency analysis&mdash;An approach based on L-moments: Cambridge University Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+quaaep4">quaaep4</a></code>,
<code><a href="#topic+quaexp">quaexp</a></code>,
<code><a href="#topic+quagam">quagam</a></code>,
<code><a href="#topic+quagev">quagev</a></code>,
<code><a href="#topic+quagld">quagld</a></code>,
<code><a href="#topic+quaglo">quaglo</a></code>,
<code><a href="#topic+quagno">quagno</a></code>,
<code><a href="#topic+quagpa">quagpa</a></code>,
<code><a href="#topic+quagum">quagum</a></code>,
<code><a href="#topic+quakap">quakap</a></code>,
<code><a href="#topic+quanor">quanor</a></code>,
<code><a href="#topic+quape3">quape3</a></code>,
<code><a href="#topic+quawak">quawak</a></code>, and
<code><a href="#topic+quawei">quawei</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>L &lt;- vec2lmom(c(35612,23593,0.48,0.21,0.11))
Qtable1 &lt;- freq.curve.all(L, step=TRUE, no2para=TRUE, no4para=TRUE)
## Not run: 
Qtable2 &lt;- freq.curve.all(L, gld=TRUE, show=TRUE)
## End(Not run)
</code></pre>

<hr>
<h2 id='gen.freq.curves'>Plot Randomly Generated Frequency Curves from a Parent Distribution</h2><span id='topic+gen.freq.curves'></span>

<h3>Description</h3>

<p>This function generates random samples of specified size from a specified parent distribution. Subsequently, the type of parent distribution is fit to the L-moments of the generated sample. The fitted distribution is then plotted. It is the user's responsibility to have an active <code>plot</code> already drawn; unless the <code>callplot</code> option is <code>TRUE</code>. This function is useful to demonstration of sample size on the uncertainty of a fitted distribution&mdash;a motivation for this function is as a classroom exercise.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gen.freq.curves(n, para, F=NULL, nsim=10, callplot=TRUE, aslog=FALSE,
                asprob=FALSE, showsample=FALSE, showparent=FALSE,
                lowerCI=NA, upperCI=NA, FCI=NA, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gen.freq.curves_+3A_n">n</code></td>
<td>
<p>Sample size to draw from parent as specified by <code>para</code>.</p>
</td></tr>
<tr><td><code id="gen.freq.curves_+3A_para">para</code></td>
<td>
<p>The parameters from <code><a href="#topic+lmom2par">lmom2par</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
<tr><td><code id="gen.freq.curves_+3A_f">F</code></td>
<td>
<p>The nonexceedance probabilities for horizontal axis&mdash;defaults to <code><a href="#topic+nonexceeds">nonexceeds</a></code> when the argument is <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="gen.freq.curves_+3A_nsim">nsim</code></td>
<td>
<p>The number of simulations to perform (frequency curves to draw)&mdash;the default is 10.</p>
</td></tr>
<tr><td><code id="gen.freq.curves_+3A_callplot">callplot</code></td>
<td>
<p>Calls <code>plot</code> to acquire a graphics device&mdash;default is <code>TRUE</code>, but the called <code>plot</code> is left empty.</p>
</td></tr>
<tr><td><code id="gen.freq.curves_+3A_aslog">aslog</code></td>
<td>
<p>Compute <code>log10</code> of quantiles&mdash;note that </p>
<pre>NaNs produced in: log(x, base)</pre><p> will be produced for less than zero values. Otherwise this is a harmless message.</p>
</td></tr>
<tr><td><code id="gen.freq.curves_+3A_asprob">asprob</code></td>
<td>
<p>The <code>qnorm</code> function is used to convert nonexceedance probabilities, which are produced by <code><a href="#topic+nonexceeds">nonexceeds</a></code>, to Standard Normal variates. The Normal distribution will be a straight line when this argument is <code>TRUE</code> and <code>aslog=FALSE</code>.</p>
</td></tr>
<tr><td><code id="gen.freq.curves_+3A_showsample">showsample</code></td>
<td>
<p>Each simulated sample is drawn through plotting positions (<code><a href="#topic+pp">pp</a></code>).</p>
</td></tr>
<tr><td><code id="gen.freq.curves_+3A_showparent">showparent</code></td>
<td>
<p>The curve for the parent distribution is plotted on exit from the function if <code>TRUE</code>. Further plotting options can not be controlled&mdash;unlike the situation with the drawing of the simulated frequency curves.</p>
</td></tr>
<tr><td><code id="gen.freq.curves_+3A_lowerci">lowerCI</code></td>
<td>
<p>An optional estimate of the lower confidence limit for the <code>FCI</code> nonexceedance probability.</p>
</td></tr>
<tr><td><code id="gen.freq.curves_+3A_upperci">upperCI</code></td>
<td>
<p>An optional estimate of the upper confidence limit for the <code>FCI</code> nonexceedance probability.</p>
</td></tr>
<tr><td><code id="gen.freq.curves_+3A_fci">FCI</code></td>
<td>
<p>The nonexeedance probability of interest for the confidence limits provided in <code>lowerCI</code> and <code>upperCI</code>.</p>
</td></tr>
<tr><td><code id="gen.freq.curves_+3A_...">...</code></td>
<td>
<p>Additional parameters are passed to the <code>lines</code> call within the function&mdash;except for the drawing of the parent distribution (see argument <code>showparent</code>).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>This function is largely used for its graphical side effects, but if estimates of the lower and upper confidence limits are known (say from <code><a href="#topic+genci.simple">genci.simple</a></code>) then this function can be used to evaluate the counts of simulations at nonexceedance probability <code>FCI</code> outside the limits provided in <code>lowerCI</code> and <code>upperCI</code>.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>See Also</h3>

<p><code><a href="#topic+lmom2par">lmom2par</a></code>, <code><a href="#topic+nonexceeds">nonexceeds</a></code>, <code><a href="#topic+rlmomco">rlmomco</a></code>, <code><a href="#topic+lmoms">lmoms</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# 1-day rainfall Travis county, Texas
para &lt;- vec2par(c(3.00, 1.20, -.0954), type="gev")
F &lt;- .99 # the 100-year event
n &lt;- 46 # sample size derived from 75th percentile of record length distribution
# for Edwards Plateau from Figure 3 of USGS WRIR98-4044 (Asquith, 1998)
# Argument for 75th percentile is that the contours of distribution parameters
# in that report represent a regionalization of the parameters and hence
# record lengths such as the median or smaller for the region seem too small
# for reasonable exploration of confidence limits of precipitation.
nsim &lt;- 5000 # simulation size
seed &lt;- runif(1, min=1, max=10000)
set.seed(seed)
CI &lt;- genci.simple(para, n, F=F, nsim=nsim, edist="nor")
lo.nor &lt;- CI$lower; hi.nor &lt;- CI$upper

set.seed(seed)
CI &lt;- genci.simple(para, n, F=F, nsim=nsim, edist="aep4")
lo.aep4 &lt;- CI$lower; hi.aep4 &lt;- CI$upper
message("NORMAL ERROR DIST: lowerCI = ",lo.nor, " and upperCI = ",hi.nor)
message("  AEP4 ERROR DIST: lowerCI = ",lo.aep4," and upperCI = ",hi.aep4)
qF &lt;- qnorm(F)
# simulated are grey, parent is black
set.seed(seed)
counts.nor  &lt;- gen.freq.curves(n, para, nsim=nsim,
                   asprob=TRUE, showparent=TRUE, col=rgb(0,0,1,0.025),
                   lowerCI=lo.nor, upperCI=hi.nor, FCI=F)
set.seed(seed)
counts.aep4 &lt;- gen.freq.curves(n, para, nsim=nsim,
                   asprob=TRUE, showparent=TRUE, col=rgb(0,0,1,0.025),
                   lowerCI=lo.aep4, upperCI=hi.aep4, FCI=F)
lines( c(qF,qF), c(lo.nor, hi.nor),  lwd=2, col=2)
points(c(qF,qF), c(lo.nor, hi.nor),  pch=1, lwd=2, col=2)
lines( c(qF,qF), c(lo.aep4,hi.aep4), lwd=2, col=2)
points(c(qF,qF), c(lo.aep4,hi.aep4), pch=2, lwd=2, col=2)
percent.nor  &lt;- (counts.nor$count.above.upperCI +
                 counts.nor$count.below.lowerCI) /
                 counts.nor$count.valid.simulations
percent.aep4 &lt;- (counts.aep4$count.above.upperCI +
                 counts.aep4$count.below.lowerCI) /
                 counts.aep4$count.valid.simulations
percent.nor  &lt;- 100 * percent.nor
percent.aep4 &lt;- 100 * percent.aep4
message("NORMAL ERROR DIST: ",percent.nor)
message("  AEP4 ERROR DIST: ",percent.aep4)
# Continuing on, we are strictly focused on F being equal to 0.99
# Also we are no restricted to the example using the GEV distribution
# The vargev() function is from Handbook of Hydrology
"vargev" &lt;-
function(para, n, F=c("F080", "F090", "F095", "F099", "F998", "F999")) {
   F &lt;- as.character(F)
   if(! are.pargev.valid(para)) return()
   F &lt;- match.arg(F)
   A &lt;- para$para[2]
   K &lt;- para$para[3]
   AS &lt;- list(F080=c(-1.813,  3.017, -1.4010, 0.854),
              F090=c(-2.667,  4.491, -2.2070, 1.802),
              F095=c(-3.222,  5.732, -2.3670, 2.512),
              F098=c(-3.756,  7.185, -2.3140, 4.075),
              F099=c(-4.147,  8.216, -0.2033, 4.780),
              F998=c(-5.336, 10.711, -1.1930, 5.300),
              F999=c(-5.943, 11.815, -0.6300, 6.262))
   AS &lt;- as.environment(AS); CO &lt;- get(F, AS)
   varx &lt;- A^2 * exp( CO[1] + CO[2]*exp(-K) + CO[3]*K^2 + CO[4]*K^3 ) / n
   names(varx) &lt;- NULL
   return(varx)
}
sdx &lt;- sqrt(vargev(para, n, F="F099"))
VAL  &lt;- qlmomco(F, para)
lo.vargev &lt;- VAL + qt(0.05, df=n) * sdx # minus covered by return of qt()
hi.vargev &lt;- VAL + qt(0.95, df=n) * sdx

set.seed(seed)
counts.vargev &lt;- gen.freq.curves(n, para, nsim=nsim,
                   xlim=c(0,3), ylim=c(3,15),
                   asprob=TRUE, showparent=TRUE, col=rgb(0,0,1,0.01),
                   lowerCI=lo.vargev, upperCI=hi.vargev, FCI=F)
percent.vargev  &lt;- (counts.vargev$count.above.upperCI +
                    counts.vargev$count.below.lowerCI) /
                    counts.vargev$count.valid.simulations
percent.vargev  &lt;- 100 * percent.vargev
lines(c(qF,qF),  range(c(lo.nor,   hi.nor,
                         lo.aep4,  hi.aep4,
                         lo.vargev,hi.vargev)), col=2)
points(c(qF,qF), c(lo.nor,      hi.nor), pch=1, lwd=2, col=2)
points(c(qF,qF), c(lo.aep4,    hi.aep4), pch=3, lwd=2, col=2)
points(c(qF,qF), c(lo.vargev,hi.vargev), pch=2, lwd=2, col=2)
message("NORMAL ERROR DIST: ",percent.nor)
message("  AEP4 ERROR DIST: ",percent.aep4)
message("VARGEV ERROR DIST: ",percent.vargev)

## End(Not run)
</code></pre>

<hr>
<h2 id='genci.simple'>Generate (Estimate) Confidence Intervals for Quantiles of a Parent Distribution</h2><span id='topic+genci'></span><span id='topic+genci.simple'></span>

<h3>Description</h3>

<p>This function estimates the lower and upper limits of a specified confidence interval for a vector of nonexceedance probabilities <code class="reqn">F</code> of a specified parent distribution [quantile function <code class="reqn">Q(F,\theta)</code> with parameters <code class="reqn">\theta</code>] using Monte Carlo simulation. The <code class="reqn">F</code> are specified by the user. The user also provides <code class="reqn">\Theta</code> of the parent distribution (see <code><a href="#topic+lmom2par">lmom2par</a></code>). This function is a wrapper on <code><a href="#topic+qua2ci.simple">qua2ci.simple</a></code>; please consult the documentation for that function for further details of the simulations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>genci.simple(para, n, f=NULL, level=0.90, edist="gno", nsim=1000,
             expand=FALSE, verbose=FALSE, showpar=FALSE, quiet=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="genci.simple_+3A_para">para</code></td>
<td>
<p>The parameters from <code><a href="#topic+lmom2par">lmom2par</a></code> or similar.</p>
</td></tr>
<tr><td><code id="genci.simple_+3A_n">n</code></td>
<td>
<p>The sample size for each Monte Carlo simulation will use.</p>
</td></tr>
<tr><td><code id="genci.simple_+3A_f">f</code></td>
<td>
<p>Vector of nonexceedance probabilities (<code class="reqn">0 \le f \le 1</code>) of the quantiles for which the confidence interval are needed. If <code>NULL</code>, then the vector as returned by <code><a href="#topic+nonexceeds">nonexceeds</a></code> is used.</p>
</td></tr>
<tr><td><code id="genci.simple_+3A_level">level</code></td>
<td>
<p>The confidence interval (<code class="reqn">0 \le </code> <code>level</code> <code class="reqn"> &lt; 1</code>). The interval is specified as the size of the interval. The default is 0.90 or the 90th percentile. The function will return the 5th (<code class="reqn">(1-0.90)/2</code>) and 95th (<code class="reqn">1-(1-0.90)/2</code>) percentile cumulative probability of the error distribution for the parent quantile as specified by the nonexceedance probability argument (<code>f</code>). This argument is passed unused to <code><a href="#topic+qua2ci.simple">qua2ci.simple</a></code>.</p>
</td></tr>
<tr><td><code id="genci.simple_+3A_edist">edist</code></td>
<td>
<p>The model for the error distribution. Although the Normal (the default) commonly is  assumed in error analyses, it need not be, as support for other distributions supported by <span class="pkg">lmomco</span> is available. The default is the Generalized Normal so the not only is the Normal possible but asymmetry is also accomodated (<code><a href="#topic+lmomgno">lmomgno</a></code>).  For example, if the L-skew  (<code class="reqn">\tau_4</code>) or L-kurtosis (<code class="reqn">\tau_4</code>) values depart considerably from those of the Normal (<code class="reqn">\tau_3 = 0</code> and <code class="reqn">\tau_4 = 0.122602</code>), then the Generalized Normal or some alternative distribution would likely provide more reliable confidence interval estimation. This argument is passed unused to <code><a href="#topic+qua2ci.simple">qua2ci.simple</a></code>.</p>
</td></tr>
<tr><td><code id="genci.simple_+3A_nsim">nsim</code></td>
<td>
<p>The number of simulations (replications) for the sample size <code>n</code> to perform. Much larger simulation numbers are recommended&mdash;see discussion about<br /> <code><a href="#topic+qua2ci.simple">qua2ci.simple</a></code>. This argument is passed unused to <code><a href="#topic+qua2ci.simple">qua2ci.simple</a></code>. Users are encouraged to experiment with <code><a href="#topic+qua2ci.simple">qua2ci.simple</a></code> to get a feel for the value of <code>edist</code> and <code>nsim</code>.</p>
</td></tr>
<tr><td><code id="genci.simple_+3A_expand">expand</code></td>
<td>
<p>Should the returned values be expanded to include information relating to the distribution type and L-moments of the distribution at the corresponding nonexceedance probabilities&mdash;in other words the information necessary to reconstruct the reported confidence interval. The default is <code>FALSE</code>. If <code>expand=FALSE</code> then a single <code>data.frame</code> of the lower and upper limits along with the true quantile value of the parent is returned. If <code>expand=TRUE</code>, then a more complicated <code>list</code> containing multiple <code>data.frame</code>s is returned.</p>
</td></tr>
<tr><td><code id="genci.simple_+3A_verbose">verbose</code></td>
<td>
<p>The verbosity of the operation of the function. This argument is passed unused to <code><a href="#topic+qua2ci.simple">qua2ci.simple</a></code>.</p>
</td></tr>
<tr><td><code id="genci.simple_+3A_showpar">showpar</code></td>
<td>
<p>The parameters of the <code>edist</code> for each simulation for each <code class="reqn">F</code> value passed to <code><a href="#topic+qua2ci.simple">qua2ci.simple</a></code> are printed. This argument is passed unused to <code><a href="#topic+qua2ci.simple">qua2ci.simple</a></code>.</p>
</td></tr>
<tr><td><code id="genci.simple_+3A_quiet">quiet</code></td>
<td>
<p>Suppress incremental counter for a count down of the <code class="reqn">F</code> values.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>data.frame</code> or <code>list</code> is returned (see discussion of argument <code>expand</code>). The following elements could be available.
</p>
<table>
<tr><td><code>nonexceed</code></td>
<td>
<p>A vector of <code class="reqn">F</code> values, which is returned for convenience so that post operations such as plotting are easily coded.</p>
</td></tr>
<tr><td><code>lwr</code></td>
<td>
<p>The lower value of the confidence interval having nonexceedance probability equal to <code>(1-level)/2</code>.</p>
</td></tr>
<tr><td><code>true</code></td>
<td>
<p>The true quantile value from <code class="reqn">Q(F,\theta)</code> for the corresponding <code class="reqn">F</code> value.</p>
</td></tr>
<tr><td><code>upr</code></td>
<td>
<p>The upper value of the confidence interval having <code class="reqn">F</code> equal to <code>1-(1-level)/2</code>.</p>
</td></tr>
<tr><td><code>lscale</code></td>
<td>
<p>The second L-moment (L-scale, <code class="reqn">\lambda_2</code>) of the distribution of quantiles for the corresponding <code class="reqn">F</code>. This value is included in the primary returned <code>data.frame</code> because it measures the fundamental sampling variability.</p>
</td></tr>
<tr><td><code>parent</code></td>
<td>
<p>The paraments of the parent distribution if <code>expand=TRUE</code>.</p>
</td></tr>
<tr><td><code>edist</code></td>
<td>
<p>The type of error distribution used to model the confidence interval if the argument <code>expand=TRUE</code> is set.</p>
</td></tr>
<tr><td><code>elmoms</code></td>
<td>
<p>The L-moment of the distribution of quantiles for the corresponding <code class="reqn">F</code> if the argument  <code>expand=TRUE</code> is set.</p>
</td></tr>
<tr><td><code>epara</code></td>
<td>
<p>An environment containing the parameter lists of the error distribution fit to the <code>elmoms</code> for each of the <code>f</code> if the argument <code>expand=TRUE</code> is set.</p>
</td></tr>
<tr><td><code>ifail</code></td>
<td>
<p>A failure integer.</p>
</td></tr>
<tr><td><code>ifailtext</code></td>
<td>
<p>Text message associated with <code>ifail</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>See Also</h3>

<p><code><a href="#topic+genci">genci</a></code>, <code><a href="#topic+gen.freq.curves">gen.freq.curves</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# For all these examples, nsim is way too small.
mean   &lt;- 0; sigma &lt;- 100
parent &lt;- vec2par(c(mean,sigma), type='nor') # make parameter object
f      &lt;- c(0.5, 0.8, 0.9, 0.96, 0.98, 0.99) # nonexceed probabilities
# nsim is small for speed of example not accuracy.
CI     &lt;- genci.simple(parent, n=10, f=f, nsim=20); FF &lt;- CI$nonexceed
plot( FF, CI$true, type='l', lwd=2)
lines(FF, CI$lwr, col=2); lines(FF, CI$upr, col=3)

pdf("twoCIplots.pdf")
# The qnorm() call has been added to produce "normal probability"
# paper on the horizonal axis. The parent is heavy-tailed.
GEV  &lt;- vec2par(c(10000,1500,-0.3), type='gev') # a GEV distribution
CI   &lt;- genci.simple(GEV, n=20, nsim=200, edist='gno')
ymin &lt;- log10(min(CI$lwr[! is.na(CI$lwr)]))
ymax &lt;- log10(max(CI$upr[! is.na(CI$upr)]))
qFF  &lt;- qnorm(CI$nonexceed) 
plot( qFF, log10(CI$true), type='l', ylim=c(ymin,ymax),lwd=2)
lines(qFF, log10(CI$lwr), col=2); lines(qFF, log10(CI$upr), col=3)
# another error distribution model
CI   &lt;- genci.simple(GEV, n=20, nsim=200, edist='aep4')
lines(qFF,log10(CI$lwr),col=2,lty=2); lines(qFF,log10(CI$upr),col=3,lty=2)
dev.off() # 
## End(Not run)
</code></pre>

<hr>
<h2 id='gini.mean.diff'>Gini Mean Difference Statistic </h2><span id='topic+gini.mean.diff'></span>

<h3>Description</h3>

<p>The Gini mean difference statistic <code class="reqn">\mathcal{G}</code> is a robust estimator of distribution scale and is closely related to the second L-moment <code class="reqn">\lambda_2 = \mathcal{G}/2</code>.
</p>
<p style="text-align: center;"><code class="reqn">\mathcal{G} = \frac{2}{n(n-1)}\sum_{i=1}^n (2i - n - 1) x_{i:n}\mbox{,}</code>
</p>

<p>where <code class="reqn">x_{i:n}</code> are the sample order statistics.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gini.mean.diff(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gini.mean.diff_+3A_x">x</code></td>
<td>
<p>A vector of data values that will be reduced to non-missing values.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> is returned.
</p>
<table>
<tr><td><code>gini</code></td>
<td>
<p>The gini mean difference <code class="reqn">\mathcal{G}</code>.</p>
</td></tr>
<tr><td><code>L2</code></td>
<td>
<p>The L-scale (second L-moment) because <code class="reqn">\lambda_2 = 0.5\times\mathcal{G}</code> (see <code><a href="#topic+lmom.ub">lmom.ub</a></code>).</p>
</td></tr>
<tr><td><code>source</code></td>
<td>
<p>An attribute identifying the computational source of the Gini's Mean Difference: &ldquo;gini.mean.diff&rdquo;.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Hosking, J.R.M., 1990, L-moments&mdash;Analysis and estimation of
distributions using linear combinations of order statistics: Journal of the Royal Statistical Society, Series B, v. 52, pp. 105&ndash;124.
</p>
<p>Jurečková, J., and Picek, J., 2006, Robust statistical methods with R: Boca Raton, Fla., Chapman and Hall/CRC, ISBN 1&ndash;58488&ndash;454&ndash;1.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lmoms">lmoms</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>fake.dat &lt;- c(123, 34, 4, 654, 37, 78)
gini &lt;- gini.mean.diff(fake.dat)
lmr &lt;- lmoms(fake.dat)
str(gini)
print(abs(gini$L2 - lmr$lambdas[2]))
</code></pre>

<hr>
<h2 id='grv2prob'>Convert a Vector of Gumbel Reduced Variates to Annual Nonexceedance Probabilities</h2><span id='topic+grv2prob'></span>

<h3>Description</h3>

<p>This function converts a vector of Gumbel reduced variates (<code class="reqn">grv</code>) to annual nonexceedance probabilities <code class="reqn">F</code>
</p>
<p style="text-align: center;"><code class="reqn">F = \exp(-\exp(-grv))\mbox{,}</code>
</p>

<p>where <code class="reqn">0 \le F \le 1</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>grv2prob(grv)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="grv2prob_+3A_grv">grv</code></td>
<td>
<p>A vector of Gumbel reduced variates.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of annual nonexceedance probabilities.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>See Also</h3>

<p><code><a href="#topic+prob2grv">prob2grv</a></code>, <code><a href="#topic+prob2T">prob2T</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>T &lt;- c(1, 2, 5, 10, 25, 50, 100, 250, 500); grv &lt;- prob2grv(T2prob(T))
F &lt;- grv2prob(grv)
</code></pre>

<hr>
<h2 id='harmonic.mean'>The Harmonic Mean with Zero-Value Correction </h2><span id='topic+harmonic.mean'></span>

<h3>Description</h3>

<p>Compute the harmonic mean of a vector with a zero-value correction.
</p>
<p style="text-align: center;"><code class="reqn">\check{\mu} =
           \biggl(\frac{\sum^{N_T - N_0}_{i=1} 1/x_i}
                       {N_T - N_0}\biggr)^{-1} \times \frac{N_T - N_0}
                 {N_T} \mbox{,}</code>
</p>

<p>where <code class="reqn">\check{\mu}</code> is harmonic mean, <code class="reqn">x_i</code> is a nonzero value of the data vector, <code class="reqn">N_T</code> is the (total) sample size, <code class="reqn">N_0</code> is the number of zero values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>harmonic.mean(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="harmonic.mean_+3A_x">x</code></td>
<td>
<p>A vector of data values that will be reduced to non-missing values.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> is returned.
</p>
<table>
<tr><td><code>harmean</code></td>
<td>
<p>The harmonic mean with zero-value correction, <code class="reqn">\check{\mu}</code>.</p>
</td></tr>
<tr><td><code>correction</code></td>
<td>
<p>The zero-value correction, <code class="reqn">(N_T - N_0)/N_T</code>.</p>
</td></tr>
<tr><td><code>source</code></td>
<td>
<p>An attribute identifying the computational source of the harmonic mean: &ldquo;harmonic.mean&rdquo;.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The harmonic mean can not be computed when zero values are present. This situation is common in surface-water hydrology. As stated in the reference below, in order to calculate water-quality-based effluent limits (WQBELs) for human health protection, a harmonic mean flow is determined for all perennial streams and for streams that are intermittent with perennial pools. Sometimes these streams have days on which measured flow is zero. Because a zero flow cannot be used in the calculation of harmonic mean flow, the second term in the harmonic mean equation is an adjustment factor used to lower the harmonic mean to compensate for days on which the flow was zero. The zero-value correction is the same correction used by the EPA computer program DFLOW.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Texas Commission on Environmental Quality, 2003, Procedures to implement the Texas surface-water-quality standards: TCEQ RG&ndash;194, p. 47
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pmoms">pmoms</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>Q &lt;- c(0,0,5,6,7)
harmonic.mean(Q)
</code></pre>

<hr>
<h2 id='headrick.sheng.lalpha'>Sample Headrick and Sheng L-alpha</h2><span id='topic+headrick.sheng.lalpha'></span><span id='topic+lalpha'></span>

<h3>Description</h3>

<p>Compute the sample &ldquo;Headrick and Sheng L-alpha&rdquo; (<code class="reqn">\alpha_L</code>) (Headrick and Sheng, 2013) by
</p>
<p style="text-align: center;"><code class="reqn">\alpha_L = \frac{d}{d-1}
   \biggl(1 - \frac{\sum_j \lambda^{(j)}_2}{\sum_j \lambda^{(j)}_2 + \sum\sum_{j\ne j'} \lambda_2^{(jj')}} \biggr)\mathrm{,}</code>
</p>

<p>where <code class="reqn">j = 1,\ldots,d</code> for dimensions <code class="reqn">d</code>, the <code class="reqn">\sum_j \lambda^{(j)}_2</code> is the summation of all the 2nd order (univariate) L-moments (L-scales, <code class="reqn">\lambda^{(j)}_2</code>), and the double summation is the summation of all the 2nd-order L-comoments (<code class="reqn">\lambda_2^{(jj')}</code>). In other words, the double summation is the sum total of all entries in both the lower and upper triangles (not the primary diagonal) of the L-comoment matrix (the L-scale and L-coscale [L-covariance] matrix) (<code><a href="#topic+Lcomoment.matrix">Lcomoment.matrix</a></code>).
</p>
<p>The <code class="reqn">\alpha_L</code> is closely related in structural computation as the well-known &ldquo;Cronbach alpha&rdquo; (<code class="reqn">\alpha_C</code>). These are coefficients of reliability, which commonly ranges from 0 to 1, that provide what some methodologists portray as an overall assessment of a measure's reliability. If all of the scale items are entirely independent from one another, meaning that they are not correlated or share no covariance, then <code class="reqn">\alpha_C</code> is 0, and, if all of the items have high covariances, then <code class="reqn">\alpha_C</code> will approach 1 as the number of items in the scale approaches infinity. The higher the <code class="reqn">\alpha_C</code> coefficient, the more the items have shared covariance and probably measure the same underlying concept. Theoretically, there is no lower bounds for <code class="reqn">\alpha_{C,L}</code>, which can add complicating nuances in bootstrap or simulation study of both <code class="reqn">\alpha_C</code> and <code class="reqn">\alpha_L</code>. Negative values are considered a sign of something potentially wrong about the measure related to items not being positively correlated with each other, or a scoring system for a question item reversed. (This paragraph in part paraphrases <code>data.library.virginia.edu/using-and-interpreting-cronbachs-alpha/</code><br /> (accessed May 21, 2023; dead link April 18, 2024) and other general sources.)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>headrick.sheng.lalpha(x, bycovFF=FALSE, a=0.5, digits=8, ...)

lalpha(x, bycovFF=FALSE, a=0.5, digits=8, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="headrick.sheng.lalpha_+3A_x">x</code></td>
<td>
<p>An <span class="rlang"><b>R</b></span> <code>data.frame</code> of the random observations for the <code class="reqn">d</code> random variables <code class="reqn">X</code>, which must be suitable for internal dispatch to the <code><a href="#topic+Lcomoment.matrix">Lcomoment.matrix</a></code> function for computation of the 2nd-order L-comoment matrix. Alternatively, <code>x</code> can be a precomputed 2nd-order L-comoment matrix (L-scale and L-coscale matrix) as shown by the following usage: <code>lalpha(Lcomoment.matrix(x, k=2)$matrix).</code></p>
</td></tr>
<tr><td><code id="headrick.sheng.lalpha_+3A_bycovff">bycovFF</code></td>
<td>
<p>A logical triggering the covariance pathway for the computation and bypassing the call to the L-comoments. The additional arguments can be used to control the <code><a href="#topic+pp">pp</a></code> function that is called internally to estimate nonexceedance probabilities and the &ldquo;covariance pathway&rdquo; (see <b>Details</b>). If <code>bycovFF</code> is <code>FALSE</code>, then the direct to L-comoment computation is used.</p>
</td></tr>
<tr><td><code id="headrick.sheng.lalpha_+3A_a">a</code></td>
<td>
<p>The plotting position argument <code>a</code> to the <code><a href="#topic+pp">pp</a></code> function that is hardwired here to Hazen in contrast to the default <code>a=0</code> of <code><a href="#topic+pp">pp</a></code> (Weibull) for reasoning shown in this documentation.</p>
</td></tr>
<tr><td><code id="headrick.sheng.lalpha_+3A_digits">digits</code></td>
<td>
<p>Number of digits for rounding on the returned value(s).</p>
</td></tr>
<tr><td><code id="headrick.sheng.lalpha_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Headrick and Sheng (2013) propose <code class="reqn">\alpha_L</code> to be an alternative estimator of reliability based on L-comoments. Those authors describe its context as follows: &ldquo;Consider [a statistic] alpha (<code class="reqn">\alpha</code>) in terms of a model that decomposes an observed score into the sum of two independent components: a true unobservable score <code class="reqn">t_i</code> and a random error component <code class="reqn">\epsilon_{ij}</code>.&rdquo;
</p>
<p>Those authors continue &ldquo;The model can be summarized as
<code class="reqn">X_{ij} = t_i + \epsilon_{ij}\mathrm{,}</code> where <code class="reqn">X_{ij}</code> is the observed score associated with the <code class="reqn">i</code>th examinee on the <code class="reqn">j</code>th test item, and where <code class="reqn">i = 1,...,n</code> [for sample size <code class="reqn">n</code>]; <code class="reqn">j = 1,\ldots,d</code>; and the error terms (<code class="reqn">\epsilon_{ij}</code>) are independent with a mean of zero.&rdquo; Those authors comment that &ldquo;inspection of [this model] indicates that this particular model restricts the true score <code class="reqn">t_i</code> to be the same across all <code class="reqn">d</code> test items.&rdquo;
</p>
<p>Those authors show empirical results for a simulation study, which indicate that <code class="reqn">\alpha_L</code> can be &ldquo;substantially superior&rdquo; to [a different formulation of <code class="reqn">\alpha_C</code> (Cronbach's alpha) based on product moments (the variance-covariance matrix)] in &ldquo;terms of relative bias and relative standard error when distributions are heavy-tailed and sample sizes are small.&rdquo;
</p>
<p>Those authors show (Headrick and Sheng, 2013, eqs. 4 and 5) the reader that the second L-comoments of <code class="reqn">X_j</code> and <code class="reqn">X_{j'}</code> can alternatively be expressed as
<code class="reqn">\lambda_2(X_j) = 2\mathrm{Cov}(X_j, F(X_j))</code> and <code class="reqn">\lambda_2(X_{j'}) = 2\mathrm{Cov}(X_{j'}, F(X_{j'}))</code>. The second L-comoments of <code class="reqn">X_j</code> toward (with respect to) <code class="reqn">X_{j'}</code> and <code class="reqn">X_{j'}</code> toward (with respect to) <code class="reqn">X_j</code> are <code class="reqn">\lambda_2^{(jj')} = 2\mathrm{Cov}(X_j, F(X_{j'}))</code> and <code class="reqn">\lambda_2^{(j'j)} = 2\mathrm{Cov}(X_{j'}, F(X_j))</code>. The respective cumulative distribution functions are denoted <code class="reqn">F(x_j)</code> (nonexceedance probabilities). Evidently, those authors present the L-moments and L-comoments this way because their first example (thanks for detailed numerics!) already contain nonexceedance probabilities.
</p>
<p>This apparent numerical difference between the version using estimates of nonexceedance probabilities for the data (the &ldquo;covariance pathway&rdquo;) compared to a &ldquo;direct to L-comoment&rdquo; pathway might be more than academic concern.
</p>
<p>The <b>Examples</b> provide comparison and brief discussion of potential issues involved in the direct L-comoments and the covariance pathway. The discussion leads to interest in the effects of ties and their handling and the question of <code class="reqn">F(x_j)</code> estimation by plotting position (<code><a href="#topic+pp">pp</a></code>). The <b>Note</b> section of this documentation provides expanded information and insights to <code class="reqn">\alpha_L</code> computation.
</p>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> is returned.
</p>
<table>
<tr><td><code>alpha</code></td>
<td>
<p>The <code class="reqn">\alpha_L</code> statistic.</p>
</td></tr>
<tr><td><code>pitems</code></td>
<td>
<p>The number of items (column count) in the <code>x</code>.</p>
</td></tr>
<tr><td><code>n</code></td>
<td>
<p>The sample size (row count), if applicable, to the contents of <code>x</code>.</p>
</td></tr>
<tr><td><code>text</code></td>
<td>
<p>Any pertinent messages about the computations.</p>
</td></tr>
<tr><td><code>source</code></td>
<td>
<p>An attribute identifying the computational source of the Headrick and Sheng L-alpha: &ldquo;headrick.sheng.lalpha&rdquo; or &ldquo;lalpha.star()&rdquo;.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Headrick and Sheng (2013) use <code class="reqn">k</code> to represent <code class="reqn">d</code> as used here. The change is made because <code>k</code> is an L-comoment order argument already in use by <code><a href="#topic+Lcomoment.matrix">Lcomoment.matrix</a></code>.
</p>
<p><b>Demonstration of Nuances of L-alpha</b>&mdash;Consider Headrick and Sheng (2013, tables 1 and 2) and the effect of those authors' covariance pathway to <code class="reqn">\alpha_L</code>:
</p>
<pre>
  X1 &lt;- c(2, 5, 3, 6, 7, 5, 2, 4, 3, 4) # Table 1 in Headrick and Sheng (2013)
  X2 &lt;- c(4, 7, 5, 6, 7, 2, 3, 3, 5, 4)
  X3 &lt;- c(3, 7, 5, 6, 6, 6, 3, 6, 5, 5)
  X  &lt;- data.frame(X1=X1, X2=X2, X3=X3)
  lcm2 &lt;- Lcomoment.matrix(X, k=2)
  print(lcm2$matrix, 3)
  #       [,1]  [,2]  [,3]
  # [1,] 0.989 0.567 0.722
  # [2,] 0.444 1.022 0.222
  # [3,] 0.644 0.378 0.733
</pre>
<p>Now, compare the above matrix to Headrick and Sheng (2013, table 2) where it is immediately seen that the matrices are not the same before the summations are applied to compute <code class="reqn">\alpha_L</code>.
</p>
<pre>
  #       [,1]  [,2]  [,3]
  # [1,] 0.989 0.500 0.789
  # [2,] 0.500 1.022 0.411
  # [3,] 0.667 0.333 0.733
</pre>
<p>Now, consider how the nonexceedances in Headrick and Sheng (2013, table 1) might have been computed w/o following their citation to original sources. It can be shown with reference to the first example above that these nonexceedance probabilities match.
</p>
<pre>
  FX1 &lt;- rank(X$X1, ties.method="average") / length(X$X1)
  FX2 &lt;- rank(X$X2, ties.method="average") / length(X$X2)
  FX3 &lt;- rank(X$X3, ties.method="average") / length(X$X3)
</pre>
<p>Notice in Headrick and Sheng (2013, table 1) that there is no zero probability, but there is a unity and some of the probabilities are tied. Ties have numerical ramifications. Let us now look at other L-alphas using the nonexceedance pathway and use different definitions of nonexceedance estimation and inspect the results:
</p>
<pre>
  # lmomco documentation says pp() uses ties.method="first"
  lalpha(X, bycovFF=TRUE, a=0     )$alpha
  # [1] 0.7448583  # unbiased probs all distributions
  lalpha(X, bycovFF=TRUE, a=0.3173)$alpha
  # [1] 0.7671384  # Median probs for all distributions
  lalpha(X, bycovFF=TRUE, a=0.35  )$alpha
  # [1] 0.7695105  # Often used with probs-weighted moments
  lalpha(X, bycovFF=TRUE, a=0.375 )$alpha
  # [1] 0.771334   # Blom, nearly unbiased quantiles for normal
  lalpha(X, bycovFF=TRUE, a=0.40  )$alpha
  # [1] 0.7731661  # Cunnane, appox quantile unbiased
  lalpha(X, bycovFF=TRUE, a=0.44  )$alpha
  # [1] 0.7761157  # Gringorten, optimized for Gumbel
  lalpha(X, bycovFF=TRUE, a=0.5   )$alpha
  # [1] 0.7805825  # Hazen, traditional choice
                   # This the plotting position (i-0.5) / n
</pre>
<p>This is not a particularly pleasing situation because the choice of the plotting position affects the <code class="reqn">\alpha_L</code>. The Hazen definition <code>lalpha(X[,1:3], bycovFF=FALSE)</code> using direct to L-comoments matches the last computation shown (<code class="reqn">\alpha_L = 0.7805825</code>). A question, thus, is does this matching occur because of the nature of the ties and structure of the L-comoment algorithm itself? A note to this question involves a recognition that the answer is yes because L-comoments use a <code>sort()</code> operation and does not use <code>rank()</code> because the weights for the linear combinations are used and the covariance pathway <code>2*cov(x$X3, x$FX2)</code>, for instance.
</p>
<p>Recognizing that the direct to L-comoments alpha equals the covariance pathway with Hazen plotting positions, let us look at L-comoments:
</p>
<pre>
  lmomco::Lcomoment.Lk12 ------&gt; snippet
       X12 &lt;- X1[sort(X2, decreasing = FALSE, index.return = TRUE)$ix]
       n &lt;- length(X1)
       SUM &lt;- sum(sapply(1:n, function(r) { Lcomoment.Wk(k, r, n) * X12[r] }))
       return(SUM/n)
</pre>
<p>Notice that a <code>ties.method</code> is not present but kind of implicit as ties first by the index return of the <code>sort()</code> and notice the return of a <code>SUM/n</code> though this is an L-comoment and not an nonexceedance probability.
</p>
<p>Let us run through the tie options using a plotting position definition (<code class="reqn">i / n</code>) matching the computations of Headrick and Sheng (2013) (<code>"average"</code>, <code>A=0</code>, <code>B=0</code> for <code><a href="#topic+pp">pp</a></code>) and the first computation <code class="reqn">\alpha_L = 0.807</code> matches that reported by Headrick and Sheng (2013, p. 4):
</p>
<pre>
  for(tie in c("average", "first", "last", "min", "max")) { # random left out
    Lalpha &lt;- lalpha(X, bycovFF=TRUE,
                        a=NULL, A=0, B=0, ties.method=tie)$alpha
    message("Ties method ", stringr::str_pad(tie, 7, pad=" "),
            " provides L-alpha = ", Lalpha)
  }
  # Ties method average provides L-alpha = 0.80747664
  # Ties method   first provides L-alpha = 0.78058252
  # Ties method    last provides L-alpha = 0.83243243
  # Ties method     min provides L-alpha = 0.81363468
  # Ties method     max provides L-alpha = 0.80120709
</pre>
<p>Let us run through the tie options again using a different plotting position estimator (<code class="reqn">(n-0.5) / (n+0.5)</code>):
</p>
<pre>
  for(tie in c("average", "first", "last", "min", "max")) { # random left out
    Lalpha &lt;- lalpha(X, bycovFF=TRUE,
                        a=NULL, A=-0.5, B=0.5, ties.method=tie)$alpha
    message("Ties method ", stringr::str_pad(tie, 7, pad=" "),
            " provides L-alpha = ", Lalpha)
  }
  # Ties method average provides L-alpha = 0.78925733
  # Ties method   first provides L-alpha = 0.76230208
  # Ties method    last provides L-alpha = 0.81431215
  # Ties method     min provides L-alpha = 0.79543602
  # Ties method     max provides L-alpha = 0.78296931
</pre>
<p>We see obviously that the decision on how to treat ties has some influence on the computation involving the covariance pathway. This is not an entirely satisfactory situation, but perhaps the distinction does not matter much? The direct L-comoment pathway seems to avoid this issue because <code>sort()</code> is stable and like <code>ties.method="first"</code>. Experiments suggest that <code>a=0.5</code> (Hazen plotting positions) produces the same results as direct L-comoment (see the next section). However, as the following code set shows:
</p>
<pre>
  for(tie in c("average", "first", "last", "min", "max")) { # random left out
    Lalpha1 &lt;- lalpha(X, bycovFF=TRUE, a=0.5, ties.method=tie)$alpha
    Lalpha2 &lt;- lalpha(X, bycovFF=TRUE, a=NULL, A=-0.5, B=0, ties.method=tie)$alpha
    Lalpha3 &lt;- lalpha(X, bycovFF=TRUE, a=NULL, A=-1  , B=0, ties.method=tie)$alpha
    Lalpha4 &lt;- lalpha(X, bycovFF=TRUE, a=NULL, A=   0, B=0, ties.method=tie)$alpha
    print(c(Lalpha1, Lalpha2, Lalpha3, Lalpha4))
  }
</pre>
<p>The <code class="reqn">\alpha_L</code> for a given tie setting are all equal as long as the demoninator of the plotting position (<code class="reqn">(i + A) / (n + B)</code>) has <code>B=0</code>. The <code>a=0.5</code> produces Hazen, the <code>a=NULL, A=-0.5</code> produces Hazen, though <code>a=NULL, A=-1</code> (lower limit of <code>A</code>) and <code>a=NULL, A=0</code> (upper limit of <code>A</code> given <code>B</code>) also produces the same. This gives us as-implemented-proof that the sensitivity to the <code class="reqn">\alpha_L</code> computation is in the sorting and the denominator of the plotting position formula. The prudent default settings for when the <code>bycovFF</code> argument is true seems to have the <code class="reqn">a=-0.5</code> as nonexceedance probabilities are computed by the well-known Hazen description and with the tie method as first, the computations match direct to L-comoments.
</p>
<p><b>Demonstration of Computational Times</b>&mdash;A considerable amount of documentation and examples are provided here about the two pathways that <code class="reqn">\alpha_L</code> can be computed: (1) direct by L-comoments or (2) covariance pathway requiring precomputed estimates of the nonexceedance probabilities using a <code>ties.method="first"</code> (default <code><a href="#topic+pp">pp</a></code>). The following example shows numerical congruence between the two pathways if the so-called Hazen plotting positions (<code>a=0.5</code>, see <code><a href="#topic+pp">pp</a></code>) are requested with the implicit default of <code>ties.method="first"</code>. However, the computational time of the direct method is quite a bit longer because of latencies in the weight factor computations involved in the L-comoments and nested <code>for</code> loops.
</p>
<pre>
  set.seed(1)
  R &lt;- 1:10; nsam &lt;- 1E5 # random and uncorrelated scores in this measure
  Z &lt;- data.frame( I1=sample(R, nsam, replace=TRUE),
                   I2=sample(R, nsam, replace=TRUE),
                   I3=sample(R, nsam, replace=TRUE),
                   I4=sample(R, nsam, replace=TRUE) )
  system.time(AnF &lt;- headrick.sheng.lalpha(Z, bycovFF=FALSE)$alpha)
  system.time(AwF &lt;- headrick.sheng.lalpha(Z, bycovFF=TRUE )$alpha) # Hazen
  #    user  system elapsed
  #  30.382   0.095  30.501    AnF ---&gt; 0.01370302
  #    user  system elapsed
  #   5.054   0.030   5.092    AwF ---&gt; 0.01370302
</pre>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Headrick, T.C., and Sheng, Y., 2013, An alternative to Cronbach's alpha&mdash;An L-moment-based measure of internal-consistency reliability: <em>in</em> Millsap, R.E., van der Ark, L.A., Bolt, D.M., Woods, C.M. (eds) New Developments in Quantitative Psychology, Springer Proceedings in Mathematics and Statistics, v. 66, <a href="https://doi.org/10.1007/978-1-4614-9348-8_2">doi:10.1007/978-1-4614-9348-8_2</a>.
</p>
<p>Headrick, T.C., and Sheng, Y., 2013, A proposed measure of internal consistency reliability&mdash;Coefficient L-alpha: Behaviormetrika, v. 40, no. 1, pp. 57&ndash;68, <a href="https://doi.org/10.2333/bhmk.40.57">doi:10.2333/bhmk.40.57</a>.
</p>
<p>Béland, S., Cousineau, D., and Loye, N., 2017, Using the McDonald's omega coefficient instead of Cronbach's alpha [French]: McGill Journal of Education, v. 52, no. 3, pp. 791&ndash;804, <a href="https://doi.org/10.7202/1050915ar">doi:10.7202/1050915ar</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Lcomoment.matrix">Lcomoment.matrix</a></code>, <code><a href="#topic+pp">pp</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'># Table 1 in Headrick and Sheng (2013)
TV1 &lt;- # Observations in cols 1:3, estimated nonexceedance probabilities in cols 4:6
c(2, 4, 3, 0.15, 0.45, 0.15,       5, 7, 7, 0.75, 0.95, 1.00,
  3, 5, 5, 0.35, 0.65, 0.40,       6, 6, 6, 0.90, 0.80, 0.75,
  7, 7, 6, 1.00, 0.95, 0.75,       5, 2, 6, 0.75, 0.10, 0.75,
  2, 3, 3, 0.15, 0.25, 0.15,       4, 3, 6, 0.55, 0.25, 0.75,
  3, 5, 5, 0.35, 0.65, 0.40,       4, 4, 5, 0.55, 0.45, 0.40)
T1 &lt;- matrix(ncol=6, nrow=10)
for(r in seq(1,length(TV1), by=6)) T1[(r/6)+1, ] &lt;- TV1[r:(r+5)]
colnames(T1) &lt;- c("X1", "X2", "X3", "FX1", "FX2", "FX3"); T1 &lt;- as.data.frame(T1)

lco2 &lt;- matrix(nrow=3, ncol=3)
lco2[1,1] &lt;- lmoms(T1$X1)$lambdas[2]
lco2[2,2] &lt;- lmoms(T1$X2)$lambdas[2]
lco2[3,3] &lt;- lmoms(T1$X3)$lambdas[2]
lco2[1,2] &lt;- 2*cov(T1$X1, T1$FX2); lco2[1,3] &lt;- 2*cov(T1$X1, T1$FX3)
lco2[2,1] &lt;- 2*cov(T1$X2, T1$FX1); lco2[2,3] &lt;- 2*cov(T1$X2, T1$FX3)
lco2[3,1] &lt;- 2*cov(T1$X3, T1$FX1); lco2[3,2] &lt;- 2*cov(T1$X3, T1$FX2)
headrick.sheng.lalpha(lco2)$alpha     # Headrick and Sheng (2013): alpha = 0.807
# 0.8074766
headrick.sheng.lalpha(Lcomoment.matrix(T1[,1:3], k=2)$matrix)$alpha
# 0.7805825
headrick.sheng.lalpha(T1[,1:3])$alpha #              FXs not used: alpha = 0.781
# 0.7805825
headrick.sheng.lalpha(T1[,1:3], bycovFF=TRUE)$alpha  # a=0.5, Hazen by default
# 0.7805825
headrick.sheng.lalpha(T1[,1:3], bycovFF=TRUE, a=0.5)$alpha
# 0.7805825
</code></pre>

<hr>
<h2 id='herefordprecip'>Annual Maximum Precipitation Data for Hereford, Texas</h2><span id='topic+herefordprecip'></span>

<h3>Description</h3>

<p>Annual maximum precipitation data for Hereford, Texas
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(herefordprecip)
</code></pre>


<h3>Format</h3>

<p>An <span class="rlang"><b>R</b></span> <code>data.frame</code> with
</p>

<dl>
<dt>YEAR</dt><dd><p>The calendar year of the annual maxima.</p>
</dd>
<dt>DEPTH</dt><dd><p>The depth of 7-day annual maxima rainfall in inches.</p>
</dd>
</dl>



<h3>References</h3>

<p>Asquith, W.H., 1998, Depth-duration frequency of precipitation for
Texas: U.S. Geological Survey Water-Resources Investigations Report
98&ndash;4044, 107 p.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(herefordprecip)
summary(herefordprecip)
</code></pre>

<hr>
<h2 id='hlmomco'>Hazard Functions of the Distributions</h2><span id='topic+hlmomco'></span>

<h3>Description</h3>

<p>This function acts as a front end to <code><a href="#topic+dlmomco">dlmomco</a></code> and <code><a href="#topic+plmomco">plmomco</a></code> to compute the hazard function <code class="reqn">h(x)</code> or conditional failure rate. The function is defined by
</p>
<p style="text-align: center;"><code class="reqn">h(x) = \frac{f(x)}{1 - F(x)}\mbox{,}</code>
</p>

<p>where <code class="reqn">f(x)</code> is a probability density function and <code class="reqn">F(x)</code> is the cumulative distribution function.
</p>
<p>To help with intuitive understanding of what <code class="reqn">h(x)</code> means (Ugarte and others, 2008), let <code class="reqn">\mathrm{d}x</code> represent a small unit of measurement. Then the quantity <code class="reqn">h(x)\,\mathrm{d}x</code> can be conceptualized as the approximate probability that random variable <code class="reqn">X</code> takes on a value in the interval <code class="reqn">[x, x+\mathrm{d}x]</code>.
</p>
<p>Ugarte and others (2008) continue by stating that <code class="reqn">h(x)</code> represents the instantaneous rate of death or failure at time <code class="reqn">x</code>, given the survival to time <code class="reqn">x</code> has occurred. Emphasis is needed that <code class="reqn">h(x)</code> is a rate of probability change and not a probability itself.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hlmomco(x,para)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="hlmomco_+3A_x">x</code></td>
<td>
<p>A real value vector.</p>
</td></tr>
<tr><td><code id="hlmomco_+3A_para">para</code></td>
<td>
<p>The parameters from <code><a href="#topic+lmom2par">lmom2par</a></code> or similar.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Hazard rate for <code>x</code>.
</p>


<h3>Note</h3>

<p>The hazard function is numerically solved for the given cumulative distribution and probability density functions and not analytical expressions for the hazard function that do exist for many distributions.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Ugarte, M.D., Militino, A.F., and Arnholt, A.T., 2008, Probability and statistics with R: CRC Press, Boca Raton, FL.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+plmomco">plmomco</a></code>, <code><a href="#topic+dlmomco">dlmomco</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>my.lambda &lt;- 100
para &lt;- vec2par(c(0,my.lambda), type="exp")

x &lt;- seq(40:60)
hlmomco(x,para) # returns vector of 0.01
# because the exponential distribution has a constant
# failure rate equal to 1/scale or 1/100 as in this example.
</code></pre>

<hr>
<h2 id='IRSrefunds.by.state'>U.S. Internal Revenue Service Refunds by State for Fiscal Year 2006</h2><span id='topic+IRSrefunds.by.state'></span>

<h3>Description</h3>

<p>U.S. Internal Revenue Service refunds by state for fiscal year 2006.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(IRSrefunds.by.state)
</code></pre>


<h3>Format</h3>

<p>A data frame with
</p>

<dl>
<dt>STATE</dt><dd><p>State name.</p>
</dd>
<dt>REFUNDS</dt><dd><p>Dollars of refunds.</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>data(IRSrefunds.by.state)
summary(IRSrefunds.by.state)
</code></pre>

<hr>
<h2 id='is.aep4'>Is a Distribution Parameter Object Typed as 4-Parameter Asymmetric Exponential Power</h2><span id='topic+is.aep4'></span>

<h3>Description</h3>

<p>The distribution parameter object returned by functions of <span class="pkg">lmomco</span> such as by <code><a href="#topic+paraep4">paraep4</a></code> are typed by an attribute <code>type</code>. This function checks that <code>type</code> is <code>aep4</code> for the 4-parameter Asymmetric Exponential Power distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>is.aep4(para)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="is.aep4_+3A_para">para</code></td>
<td>
<p>A parameter <code>list</code> returned from <code><a href="#topic+paraep4">paraep4</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>TRUE</code></td>
<td>
<p>If the <code>type</code> attribute is <code>aep4</code>.</p>
</td></tr>
<tr><td><code>FALSE</code></td>
<td>
<p>If the <code>type</code> is not <code>aep4</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>See Also</h3>

<p><code><a href="#topic+paraep4">paraep4</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>para &lt;- vec2par(c(0,1, 0.5, 4), type="aep4")
if(is.aep4(para) == TRUE) {
  Q &lt;- quaaep4(0.55,para)
}
</code></pre>

<hr>
<h2 id='is.cau'>Is a Distribution Parameter Object Typed as Cauchy</h2><span id='topic+is.cau'></span>

<h3>Description</h3>

<p>The distribution parameter object returned by functions of <span class="pkg">lmomco</span> such as by <code><a href="#topic+parcau">parcau</a></code> are typed by an attribute <code>type</code>. This function checks that <code>type</code> is <code>cau</code> for the Cauchy distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>is.cau(para)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="is.cau_+3A_para">para</code></td>
<td>
<p>A parameter <code>list</code> returned from <code><a href="#topic+parcau">parcau</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>TRUE</code></td>
<td>
<p>If the <code>type</code> attribute is <code>cau</code>.</p>
</td></tr>
<tr><td><code>FALSE</code></td>
<td>
<p>If the <code>type</code> is not <code>cau</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>See Also</h3>

<p><code><a href="#topic+parcau">parcau</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>para &lt;- vec2par(c(12,12),type='cau')
if(is.cau(para) == TRUE) {
  Q &lt;- quacau(0.5,para)
}
</code></pre>

<hr>
<h2 id='is.emu'>Is a Distribution Parameter Object Typed as Eta-Mu</h2><span id='topic+is.emu'></span>

<h3>Description</h3>

<p>The distribution parameter object returned by functions of <span class="pkg">lmomco</span> such as by <code><a href="#topic+paremu">paremu</a></code> are typed by an attribute <code>type</code>. This function checks that <code>type</code> is <code>emu</code> for the Eta-Mu (<code class="reqn">\eta:\mu</code>) distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>is.emu(para)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="is.emu_+3A_para">para</code></td>
<td>
<p>A parameter <code>list</code> returned from <code><a href="#topic+paremu">paremu</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>TRUE</code></td>
<td>
<p>If the <code>type</code> attribute is <code>emu</code>.</p>
</td></tr>
<tr><td><code>FALSE</code></td>
<td>
<p>If the <code>type</code> is not <code>emu</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>See Also</h3>

<p><code><a href="#topic+paremu">paremu</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
para &lt;- vec2par(c(0.25, 1.4), type='emu')
if(is.emu(para)) Q &lt;- quaemu(0.5,para) #
## End(Not run)
</code></pre>

<hr>
<h2 id='is.exp'>Is a Distribution Parameter Object Typed as Exponential</h2><span id='topic+is.exp'></span>

<h3>Description</h3>

<p>The distribution parameter object returned by functions of <span class="pkg">lmomco</span> such as by <code><a href="#topic+parexp">parexp</a></code> are typed by an attribute <code>type</code>. This function checks that <code>type</code> is <code>exp</code> for the Exponential distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>is.exp(para)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="is.exp_+3A_para">para</code></td>
<td>
<p>A parameter <code>list</code> returned from <code><a href="#topic+parexp">parexp</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>TRUE</code></td>
<td>
<p>If the <code>type</code> attribute is <code>exp</code>.</p>
</td></tr>
<tr><td><code>FALSE</code></td>
<td>
<p>If the <code>type</code> is not <code>exp</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>See Also</h3>

<p><code><a href="#topic+parexp">parexp</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>para &lt;- parexp(lmoms(c(123,34,4,654,37,78)))
if(is.exp(para) == TRUE) {
  Q &lt;- quaexp(0.5,para)
}
</code></pre>

<hr>
<h2 id='is.gam'>Is a Distribution Parameter Object Typed as Gamma</h2><span id='topic+is.gam'></span>

<h3>Description</h3>

<p>The distribution parameter object returned by functions of <span class="pkg">lmomco</span> such as by <code><a href="#topic+pargam">pargam</a></code> are typed by an attribute <code>type</code>. This function checks that <code>type</code> is <code>gam</code> for the Gamma distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>is.gam(para)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="is.gam_+3A_para">para</code></td>
<td>
<p>A parameter <code>list</code> returned from <code><a href="#topic+pargam">pargam</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>TRUE</code></td>
<td>
<p>If the <code>type</code> attribute is <code>gam</code>.</p>
</td></tr>
<tr><td><code>FALSE</code></td>
<td>
<p>If the <code>type</code> is not <code>gam</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>See Also</h3>

<p><code><a href="#topic+pargam">pargam</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>para &lt;- pargam(lmoms(c(123,34,4,654,37,78)))
if(is.gam(para) == TRUE) {
  Q &lt;- quagam(0.5,para)
}
</code></pre>

<hr>
<h2 id='is.gep'>Is a Distribution Parameter Object Typed as Generalized Extreme Value</h2><span id='topic+is.gep'></span>

<h3>Description</h3>

<p>The distribution parameter object returned by functions of <span class="pkg">lmomco</span> such as by <code><a href="#topic+pargep">pargep</a></code> are typed by an attribute <code>type</code>. This function checks that <code>type</code> is <code>gep</code> for the Generalized Extreme Value distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>is.gep(para)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="is.gep_+3A_para">para</code></td>
<td>
<p>A parameter <code>list</code> returned from <code><a href="#topic+pargep">pargep</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>TRUE</code></td>
<td>
<p>If the <code>type</code> attribute is <code>gep</code>.</p>
</td></tr>
<tr><td><code>FALSE</code></td>
<td>
<p>If the <code>type</code> is not <code>gep</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>See Also</h3>

<p><code><a href="#topic+pargep">pargep</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>#para &lt;- pargep(lmoms(c(123,34,4,654,37,78)))
#if(is.gep(para) == TRUE) {
#  Q &lt;- quagep(0.5,para)
#}
</code></pre>

<hr>
<h2 id='is.gev'>Is a Distribution Parameter Object Typed as Generalized Extreme Value</h2><span id='topic+is.gev'></span>

<h3>Description</h3>

<p>The distribution parameter object returned by functions of <span class="pkg">lmomco</span> such as by <code><a href="#topic+pargev">pargev</a></code> are typed by an attribute <code>type</code>. This function checks that <code>type</code> is <code>gev</code> for the Generalized Extreme Value distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>is.gev(para)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="is.gev_+3A_para">para</code></td>
<td>
<p>A parameter <code>list</code> returned from <code><a href="#topic+pargev">pargev</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>TRUE</code></td>
<td>
<p>If the <code>type</code> attribute is <code>gev</code>.</p>
</td></tr>
<tr><td><code>FALSE</code></td>
<td>
<p>If the <code>type</code> is not <code>gev</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>See Also</h3>

<p><code><a href="#topic+pargev">pargev</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>para &lt;- pargev(lmoms(c(123,34,4,654,37,78)))
if(is.gev(para) == TRUE) {
  Q &lt;- quagev(0.5,para)
}
</code></pre>

<hr>
<h2 id='is.gld'>Is a Distribution Parameter Object Typed as Generalized Lambda</h2><span id='topic+is.gld'></span>

<h3>Description</h3>

<p>The distribution parameter object returned by functions of <span class="pkg">lmomco</span> such as by <code><a href="#topic+pargld">pargld</a></code> are typed by an attribute <code>type</code>. This function checks that <code>type</code> is <code>gld</code> for the Generalized Lambda distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>is.gld(para)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="is.gld_+3A_para">para</code></td>
<td>
<p>A parameter <code>list</code> returned from <code><a href="#topic+pargld">pargld</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>TRUE</code></td>
<td>
<p>If the <code>type</code> attribute is <code>gld</code>.</p>
</td></tr>
<tr><td><code>FALSE</code></td>
<td>
<p>If the <code>type</code> is not <code>gld</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>See Also</h3>

<p><code><a href="#topic+pargld">pargld</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
para &lt;- vec2par(c(123,120,3,2),type="gld")
if(is.gld(para) == TRUE) {
  Q &lt;- quagld(0.5,para)
}

## End(Not run)
</code></pre>

<hr>
<h2 id='is.glo'>Is a Distribution Parameter Object Typed as Generalized Logistic</h2><span id='topic+is.glo'></span>

<h3>Description</h3>

<p>The distribution parameter object returned by functions of <span class="pkg">lmomco</span> such as by <code><a href="#topic+parglo">parglo</a></code> are typed by an attribute <code>type</code>. This function checks that <code>type</code> is <code>glo</code> for the Generalized Logistic distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>is.glo(para)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="is.glo_+3A_para">para</code></td>
<td>
<p>A parameter <code>list</code> returned from <code><a href="#topic+parglo">parglo</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>TRUE</code></td>
<td>
<p>If the <code>type</code> attribute is <code>glo</code>.</p>
</td></tr>
<tr><td><code>FALSE</code></td>
<td>
<p>If the <code>type</code> is not <code>glo</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>See Also</h3>

<p><code><a href="#topic+parglo">parglo</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>para &lt;- parglo(lmoms(c(123,34,4,654,37,78)))
if(is.glo(para) == TRUE) {
  Q &lt;- quaglo(0.5,para)
}
</code></pre>

<hr>
<h2 id='is.gno'>Is a Distribution Parameter Object Typed as Generalized Normal</h2><span id='topic+is.gno'></span>

<h3>Description</h3>

<p>The distribution parameter object returned by functions of <span class="pkg">lmomco</span> such as by <code><a href="#topic+pargno">pargno</a></code> are typed by an attribute <code>type</code>. This function checks that <code>type</code> is <code>gno</code> for the Generalized Normal distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>is.gno(para)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="is.gno_+3A_para">para</code></td>
<td>
<p>A parameter <code>list</code> returned from <code><a href="#topic+pargno">pargno</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>TRUE</code></td>
<td>
<p>If the <code>type</code> attribute is <code>gno</code>.</p>
</td></tr>
<tr><td><code>FALSE</code></td>
<td>
<p>If the <code>type</code> is not <code>gno</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>See Also</h3>

<p><code><a href="#topic+pargno">pargno</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>para &lt;- pargno(lmoms(c(123,34,4,654,37,78)))
if(is.gno(para) == TRUE) {
  Q &lt;- quagno(0.5,para)
}
</code></pre>

<hr>
<h2 id='is.gov'>Is a Distribution Parameter Object Typed as Govindarajulu</h2><span id='topic+is.gov'></span>

<h3>Description</h3>

<p>The distribution parameter object returned by functions of <span class="pkg">lmomco</span> such as by <code><a href="#topic+pargov">pargov</a></code> are typed by an attribute <code>type</code>. This function checks that <code>type</code> is <code>gov</code> for the Govindarajulu distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>is.gov(para)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="is.gov_+3A_para">para</code></td>
<td>
<p>A parameter <code>list</code> returned from <code><a href="#topic+pargov">pargov</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>TRUE</code></td>
<td>
<p>If the <code>type</code> attribute is <code>gov</code>.</p>
</td></tr>
<tr><td><code>FALSE</code></td>
<td>
<p>If the <code>type</code> is not <code>gov</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>See Also</h3>

<p><code><a href="#topic+pargov">pargov</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>para &lt;- pargov(lmoms(c(123,34,4,654,37,78)))
if(is.gov(para) == TRUE) {
  Q &lt;- quagov(0.5,para)
}
</code></pre>

<hr>
<h2 id='is.gpa'>Is a Distribution Parameter Object Typed as Generalized Pareto</h2><span id='topic+is.gpa'></span>

<h3>Description</h3>

<p>The distribution parameter object returned by functions of <span class="pkg">lmomco</span> such as by <code><a href="#topic+pargpa">pargpa</a></code> are typed by an attribute <code>type</code>. This function checks that <code>type</code> is <code>gpa</code> for the Generalized Pareto distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>is.gpa(para)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="is.gpa_+3A_para">para</code></td>
<td>
<p>A parameter <code>list</code> returned from <code><a href="#topic+pargpa">pargpa</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>TRUE</code></td>
<td>
<p>If the <code>type</code> attribute is <code>gpa</code>.</p>
</td></tr>
<tr><td><code>FALSE</code></td>
<td>
<p>If the <code>type</code> is not <code>gpa</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>See Also</h3>

<p><code><a href="#topic+pargpa">pargpa</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>para &lt;- pargpa(lmoms(c(123,34,4,654,37,78)))
if(is.gpa(para) == TRUE) {
  Q &lt;- quagpa(0.5,para)
}
</code></pre>

<hr>
<h2 id='is.gum'>Is a Distribution Parameter Object Typed as Gumbel</h2><span id='topic+is.gum'></span>

<h3>Description</h3>

<p>The distribution parameter object returned by functions of <span class="pkg">lmomco</span> such as by <code><a href="#topic+pargum">pargum</a></code> are typed by an attribute <code>type</code>. This function checks that <code>type</code> is <code>gum</code> for the Gumbel distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>is.gum(para)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="is.gum_+3A_para">para</code></td>
<td>
<p>A parameter <code>list</code> returned from <code><a href="#topic+pargum">pargum</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>TRUE</code></td>
<td>
<p>If the <code>type</code> attribute is <code>gum</code>.</p>
</td></tr>
<tr><td><code>FALSE</code></td>
<td>
<p>If the <code>type</code> is not <code>gum</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>See Also</h3>

<p><code><a href="#topic+pargum">pargum</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>para &lt;- pargum(lmoms(c(123,34,4,654,37,78)))
if(is.gum(para) == TRUE) {
  Q &lt;- quagum(0.5,para)
}
</code></pre>

<hr>
<h2 id='is.kap'>Is a Distribution Parameter Object Typed as Kappa</h2><span id='topic+is.kap'></span>

<h3>Description</h3>

<p>The distribution parameter object returned by functions of <span class="pkg">lmomco</span> such as by <code><a href="#topic+parkap">parkap</a></code> are typed by an attribute <code>type</code>. This function checks that <code>type</code> is <code>kap</code> for the Kappa distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>is.kap(para)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="is.kap_+3A_para">para</code></td>
<td>
<p>A parameter <code>list</code> returned from <code><a href="#topic+parkap">parkap</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>TRUE</code></td>
<td>
<p>If the <code>type</code> attribute is <code>kap</code>.</p>
</td></tr>
<tr><td><code>FALSE</code></td>
<td>
<p>If the <code>type</code> is not <code>kap</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>See Also</h3>

<p><code><a href="#topic+parkap">parkap</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>para &lt;- parkap(lmoms(c(123,34,4,654,37,78)))
if(is.kap(para) == TRUE) {
  Q &lt;- quakap(0.5,para)
}
</code></pre>

<hr>
<h2 id='is.kmu'>Is a Distribution Parameter Object Typed as Kappa-Mu</h2><span id='topic+is.kmu'></span>

<h3>Description</h3>

<p>The distribution parameter object returned by functions of <span class="pkg">lmomco</span> such as by <code><a href="#topic+parkmu">parkmu</a></code> are typed by an attribute <code>type</code>. This function checks that <code>type</code> is <code>kmu</code> for the Kappa-Mu (<code class="reqn">\kappa:\mu</code>) distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>is.kmu(para)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="is.kmu_+3A_para">para</code></td>
<td>
<p>A parameter <code>list</code> returned from <code><a href="#topic+parkmu">parkmu</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>TRUE</code></td>
<td>
<p>If the <code>type</code> attribute is <code>kmu</code>.</p>
</td></tr>
<tr><td><code>FALSE</code></td>
<td>
<p>If the <code>type</code> is not <code>kmu</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>See Also</h3>

<p><code><a href="#topic+parkmu">parkmu</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>para &lt;- vec2par(c(3.1, 1.4), type='kmu')
if(is.kmu(para)) {
  Q &lt;- quakmu(0.5,para)
}
</code></pre>

<hr>
<h2 id='is.kur'>Is a Distribution Parameter Object Typed as Kumaraswamy</h2><span id='topic+is.kur'></span>

<h3>Description</h3>

<p>The distribution parameter object returned by functions of <span class="pkg">lmomco</span> such as by <code><a href="#topic+parkur">parkur</a></code> are typed by an attribute <code>type</code>. This function checks that <code>type</code> is <code>kur</code> for the Kumaraswamy distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>is.kur(para)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="is.kur_+3A_para">para</code></td>
<td>
<p>A parameter <code>list</code> returned from <code><a href="#topic+parkur">parkur</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>TRUE</code></td>
<td>
<p>If the <code>type</code> attribute is <code>kur</code>.</p>
</td></tr>
<tr><td><code>FALSE</code></td>
<td>
<p>If the <code>type</code> is not <code>kur</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>See Also</h3>

<p><code><a href="#topic+parkur">parkur</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>para &lt;- parkur(lmoms(c(0.25, 0.4, 0.6, 0.65, 0.67, 0.9)))
if(is.kur(para) == TRUE) {
  Q &lt;- quakur(0.5,para)
}
</code></pre>

<hr>
<h2 id='is.lap'>Is a Distribution Parameter Object Typed as Laplace</h2><span id='topic+is.lap'></span>

<h3>Description</h3>

<p>The distribution parameter object returned by functions of <span class="pkg">lmomco</span> such as by <code><a href="#topic+parlap">parlap</a></code> are typed by an attribute <code>type</code>. This function checks that <code>type</code> is <code>lap</code> for the Laplace distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>is.lap(para)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="is.lap_+3A_para">para</code></td>
<td>
<p>A parameter <code>list</code> returned from <code><a href="#topic+parlap">parlap</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>TRUE</code></td>
<td>
<p>If the <code>type</code> attribute is <code>lap</code>.</p>
</td></tr>
<tr><td><code>FALSE</code></td>
<td>
<p>If the <code>type</code> is not <code>lap</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>See Also</h3>

<p><code><a href="#topic+parlap">parlap</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>para &lt;- parlap(lmoms(c(123,34,4,654,37,78)))
if(is.lap(para) == TRUE) {
  Q &lt;- qualap(0.5,para)
}
</code></pre>

<hr>
<h2 id='is.lmrq'>Is a Distribution Parameter Object Typed as Linear Mean Residual Quantile Function</h2><span id='topic+is.lmrq'></span>

<h3>Description</h3>

<p>The distribution parameter object returned by functions of <span class="pkg">lmomco</span> such as by <code><a href="#topic+parlmrq">parlmrq</a></code> are typed by an attribute <code>type</code>. This function checks that <code>type</code> is <code>lmrq</code> for the Linear Mean Residual Quantile Function distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>is.lmrq(para)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="is.lmrq_+3A_para">para</code></td>
<td>
<p>A parameter <code>list</code> returned from <code><a href="#topic+parlmrq">parlmrq</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>TRUE</code></td>
<td>
<p>If the <code>type</code> attribute is <code>lmrq</code>.</p>
</td></tr>
<tr><td><code>FALSE</code></td>
<td>
<p>If the <code>type</code> is not <code>lmrq</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>See Also</h3>

<p><code><a href="#topic+parlmrq">parlmrq</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>para &lt;- parlmrq(lmoms(c(3, 0.05, 1.6, 1.37, 0.57, 0.36, 2.2)))
if(is.lmrq(para) == TRUE) {
  Q &lt;- qualmrq(0.5,para)
}
</code></pre>

<hr>
<h2 id='is.ln3'>Is a Distribution Parameter Object Typed as 3-Parameter Log-Normal</h2><span id='topic+is.ln3'></span>

<h3>Description</h3>

<p>The distribution parameter object returned by functions of <span class="pkg">lmomco</span> such as by <code><a href="#topic+parln3">parln3</a></code> are typed by an attribute <code>type</code>. This function checks that <code>type</code> is <code>ln3</code> for the 3-parameter Log-Normal distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>is.ln3(para)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="is.ln3_+3A_para">para</code></td>
<td>
<p>A parameter <code>list</code> returned from <code><a href="#topic+parln3">parln3</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>TRUE</code></td>
<td>
<p>If the <code>type</code> attribute is <code>ln3</code>.</p>
</td></tr>
<tr><td><code>FALSE</code></td>
<td>
<p>If the <code>type</code> is not <code>ln3</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>See Also</h3>

<p><code><a href="#topic+parln3">parln3</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>para &lt;- vec2par(c(.9252, .1636, .7),type='ln3')
if(is.ln3(para)) {
  Q &lt;- qualn3(0.5,para)
}
</code></pre>

<hr>
<h2 id='is.nor'>Is a Distribution Parameter Object Typed as Normal</h2><span id='topic+is.nor'></span>

<h3>Description</h3>

<p>The distribution parameter object returned by functions of <span class="pkg">lmomco</span> such as by <code><a href="#topic+parnor">parnor</a></code> are typed by an attribute <code>type</code>. This function checks that <code>type</code> is <code>nor</code> for the Normal distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>is.nor(para)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="is.nor_+3A_para">para</code></td>
<td>
<p>A parameter <code>list</code> returned from <code><a href="#topic+parnor">parnor</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>TRUE</code></td>
<td>
<p>If the <code>type</code> attribute is <code>nor</code>.</p>
</td></tr>
<tr><td><code>FALSE</code></td>
<td>
<p>If the <code>type</code> is not <code>nor</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>See Also</h3>

<p><code><a href="#topic+parnor">parnor</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>para &lt;- parnor(lmoms(c(123,34,4,654,37,78)))
if(is.nor(para) == TRUE) {
  Q &lt;- quanor(0.5,para)
}
</code></pre>

<hr>
<h2 id='is.pdq3'>Is a Distribution Parameter Object Typed as Polynomial Density-Quantile3</h2><span id='topic+is.pdq3'></span>

<h3>Description</h3>

<p>The distribution parameter object returned by functions of <span class="pkg">lmomco</span> such as by <code><a href="#topic+parpdq3">parpdq3</a></code> are typed by an attribute <code>type</code>. This function checks that <code>type</code> is <code>pdq3</code> for the Polynomial Density-Quantile3 distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>is.pdq3(para)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="is.pdq3_+3A_para">para</code></td>
<td>
<p>A parameter <code>list</code> returned from <code><a href="#topic+parpdq3">parpdq3</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>TRUE</code></td>
<td>
<p>If the <code>type</code> attribute is <code>pdq3</code>.</p>
</td></tr>
<tr><td><code>FALSE</code></td>
<td>
<p>If the <code>type</code> is not <code>pdq3</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>See Also</h3>

<p><code><a href="#topic+parpdq3">parpdq3</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>para &lt;- parpdq3(lmoms(c(46, 70, 59, 36, 71, 48, 46, 63, 35, 52)))
if(is.pdq3(para) == TRUE) {
  Q &lt;- quapdq3(0.5, para)
}
</code></pre>

<hr>
<h2 id='is.pdq4'>Is a Distribution Parameter Object Typed as Polynomial Density-Quantile4</h2><span id='topic+is.pdq4'></span>

<h3>Description</h3>

<p>The distribution parameter object returned by functions of <span class="pkg">lmomco</span> such as by <code><a href="#topic+parpdq4">parpdq4</a></code> are typed by an attribute <code>type</code>. This function checks that <code>type</code> is <code>pdq4</code> for the Polynomial Density-Quantile4 distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>is.pdq4(para)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="is.pdq4_+3A_para">para</code></td>
<td>
<p>A parameter <code>list</code> returned from <code><a href="#topic+parpdq4">parpdq4</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>TRUE</code></td>
<td>
<p>If the <code>type</code> attribute is <code>pdq4</code>.</p>
</td></tr>
<tr><td><code>FALSE</code></td>
<td>
<p>If the <code>type</code> is not <code>pdq4</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>See Also</h3>

<p><code><a href="#topic+parpdq4">parpdq4</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>para &lt;- parpdq4(lmoms(c(46, 70, 59, 36, 71, 48, 46, 63, 35, 52)))
if(is.pdq4(para) == TRUE) {
  Q &lt;- quapdq4(0.5, para)
}
</code></pre>

<hr>
<h2 id='is.pe3'>Is a Distribution Parameter Object Typed as Pearson Type III</h2><span id='topic+is.pe3'></span>

<h3>Description</h3>

<p>The distribution parameter object returned by functions of <span class="pkg">lmomco</span> such as by <code><a href="#topic+parpe3">parpe3</a></code> are typed by an attribute <code>type</code>. This function checks that <code>type</code> is <code>pe3</code> for the Pearson Type III distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>is.pe3(para)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="is.pe3_+3A_para">para</code></td>
<td>
<p>A parameter <code>list</code> returned from <code><a href="#topic+parpe3">parpe3</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>TRUE</code></td>
<td>
<p>If the <code>type</code> attribute is <code>pe3</code>.</p>
</td></tr>
<tr><td><code>FALSE</code></td>
<td>
<p>If the <code>type</code> is not <code>pe3</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>See Also</h3>

<p><code><a href="#topic+parpe3">parpe3</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>para &lt;- parpe3(lmoms(c(123,34,4,654,37,78)))
if(is.pe3(para) == TRUE) {
  Q &lt;- quape3(0.5,para)
}
</code></pre>

<hr>
<h2 id='is.ray'>Is a Distribution Parameter Object Typed as Rayleigh</h2><span id='topic+is.ray'></span>

<h3>Description</h3>

<p>The distribution parameter object returned by functions of this module such as by <code><a href="#topic+parray">parray</a></code> are typed by an attribute <code>type</code>. This function checks that <code>type</code> is <code>ray</code> for the Rayleigh distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>is.ray(para)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="is.ray_+3A_para">para</code></td>
<td>
<p>A parameter <code>list</code> returned from <code><a href="#topic+parray">parray</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>TRUE</code></td>
<td>
<p>If the <code>type</code> attribute is <code>ray</code>.</p>
</td></tr>
<tr><td><code>FALSE</code></td>
<td>
<p>If the <code>type</code> is not <code>ray</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>See Also</h3>

<p><code><a href="#topic+parray">parray</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>para &lt;- vec2par(c(.9252, .1636, .7),type='ray')
if(is.ray(para)) {
  Q &lt;- quaray(0.5,para)
}
</code></pre>

<hr>
<h2 id='is.revgum'>Is a Distribution Parameter Object Typed as Reverse Gumbel</h2><span id='topic+is.revgum'></span>

<h3>Description</h3>

<p>The distribution parameter object returned by functions of <span class="pkg">lmomco</span> such as by <code><a href="#topic+parrevgum">parrevgum</a></code> are typed by an attribute <code>type</code>. This function checks that <code>type</code> is <code>revgum</code> for the Reverse Gumbel distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>is.revgum(para)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="is.revgum_+3A_para">para</code></td>
<td>
<p>A parameter <code>list</code> returned from <code><a href="#topic+parrevgum">parrevgum</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>TRUE</code></td>
<td>
<p>If the <code>type</code> attribute is <code>revgum</code>.</p>
</td></tr>
<tr><td><code>FALSE</code></td>
<td>
<p>If the <code>type</code> is not <code>revgum</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>See Also</h3>

<p><code><a href="#topic+parrevgum">parrevgum</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>para &lt;- vec2par(c(.9252, .1636, .7),type='revgum')
if(is.revgum(para)) {
  Q &lt;- quarevgum(0.5,para)
}
</code></pre>

<hr>
<h2 id='is.rice'>Is a Distribution Parameter Object Typed as Rice</h2><span id='topic+is.rice'></span>

<h3>Description</h3>

<p>The distribution parameter object returned by functions of <span class="pkg">lmomco</span> such as by <code><a href="#topic+parrice">parrice</a></code> are typed by an attribute <code>type</code>. This function checks that <code>type</code> is <code>rice</code> for the Rice distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>is.rice(para)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="is.rice_+3A_para">para</code></td>
<td>
<p>A parameter <code>list</code> returned from <code><a href="#topic+parrice">parrice</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>TRUE</code></td>
<td>
<p>If the <code>type</code> attribute is <code>rice</code>.</p>
</td></tr>
<tr><td><code>FALSE</code></td>
<td>
<p>If the <code>type</code> is not <code>rice</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>See Also</h3>

<p><code><a href="#topic+parrice">parrice</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>para &lt;- vec2par(c(3, 4),type='rice')
if(is.rice(para)) {
  Q &lt;- quarice(0.5,para)
}
</code></pre>

<hr>
<h2 id='is.sla'>Is a Distribution Parameter Object Typed as Slash</h2><span id='topic+is.sla'></span>

<h3>Description</h3>

<p>The distribution parameter object returned by functions of <span class="pkg">lmomco</span> such as by <code><a href="#topic+parsla">parsla</a></code> are typed by an attribute <code>type</code>. This function checks that <code>type</code> is <code>sla</code> for the Slash distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>is.sla(para)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="is.sla_+3A_para">para</code></td>
<td>
<p>A parameter <code>list</code> returned from <code><a href="#topic+parsla">parsla</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>TRUE</code></td>
<td>
<p>If the <code>type</code> attribute is <code>sla</code>.</p>
</td></tr>
<tr><td><code>FALSE</code></td>
<td>
<p>If the <code>type</code> is not <code>sla</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>See Also</h3>

<p><code><a href="#topic+parsla">parsla</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>para &lt;- vec2par(c(12, 1.2), type="sla")
if(is.sla(para) == TRUE) {
  Q &lt;- quasla(0.5, para)
}
</code></pre>

<hr>
<h2 id='is.smd'>Is a Distribution Parameter Object Typed as Singh&ndash;Maddala</h2><span id='topic+is.smd'></span>

<h3>Description</h3>

<p>The distribution parameter object returned by functions of <span class="pkg">lmomco</span> such as by <code><a href="#topic+parsmd">parsmd</a></code> are typed by an attribute <code>type</code>. This function checks that <code>type</code> is <code>smd</code> for the Singh&ndash;Maddala distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>is.smd(para)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="is.smd_+3A_para">para</code></td>
<td>
<p>A parameter <code>list</code> returned from <code><a href="#topic+parsmd">parsmd</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>TRUE</code></td>
<td>
<p>If the <code>type</code> attribute is <code>smd</code>.</p>
</td></tr>
<tr><td><code>FALSE</code></td>
<td>
<p>If the <code>type</code> is not <code>smd</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>See Also</h3>

<p><code><a href="#topic+parsmd">parsmd</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>para &lt;- parsmd(lmoms(c(123, 34, 4, 654, 37, 78)))
if(is.smd(para) == TRUE) {
  Q &lt;- quasmd(0.5, para)
}
</code></pre>

<hr>
<h2 id='is.st3'>Is a Distribution Parameter Object Typed as 3-Parameter Student t Distribution</h2><span id='topic+is.st3'></span>

<h3>Description</h3>

<p>The distribution parameter object returned by functions of <span class="pkg">lmomco</span> such as by <code><a href="#topic+parst3">parst3</a></code> are typed by an attribute <code>type</code>. This function checks that <code>type</code> is <code>st3</code> for the 3-parameter Student t distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>is.st3(para)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="is.st3_+3A_para">para</code></td>
<td>
<p>A parameter <code>list</code> returned from <code><a href="#topic+parst3">parst3</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>TRUE</code></td>
<td>
<p>If the <code>type</code> attribute is <code>st3</code>.</p>
</td></tr>
<tr><td><code>FALSE</code></td>
<td>
<p>If the <code>type</code> is not <code>st3</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>See Also</h3>

<p><code><a href="#topic+parst3">parst3</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>para &lt;- vec2par(c(3, 4, 5), type='st3')
if(is.st3(para)) {
  Q &lt;- quast3(0.25,para)
}
</code></pre>

<hr>
<h2 id='is.texp'>Is a Distribution Parameter Object Typed as Truncated Exponential</h2><span id='topic+is.texp'></span>

<h3>Description</h3>

<p>The distribution parameter object returned by functions of <span class="pkg">lmomco</span> such as by <code><a href="#topic+partexp">partexp</a></code> are typed by an attribute <code>type</code>. This function checks that <code>type</code> is <code>texp</code> for the Truncated Exponential distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>is.texp(para)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="is.texp_+3A_para">para</code></td>
<td>
<p>A parameter <code>list</code> returned from <code><a href="#topic+partexp">partexp</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>TRUE</code></td>
<td>
<p>If the <code>type</code> attribute is <code>texp</code>.</p>
</td></tr>
<tr><td><code>FALSE</code></td>
<td>
<p>If the <code>type</code> is not <code>texp</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>See Also</h3>

<p><code><a href="#topic+partexp">partexp</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>yy &lt;- vec2par(c(123, 2.3, TRUE),  type="texp")
zz &lt;- vec2par(c(123, 2.3, FALSE), type="texp")
if(is.texp(yy) &amp; is.texp(zz)) {
   print(lmomtexp(yy)$lambdas)
   print(lmomtexp(zz)$lambdas)
}
</code></pre>

<hr>
<h2 id='is.tri'>Is a Distribution Parameter Object Typed as Asymmetric Triangular</h2><span id='topic+is.tri'></span>

<h3>Description</h3>

<p>The distribution parameter object returned by functions of <span class="pkg">lmomco</span> such as by <code><a href="#topic+partri">partri</a></code> are typed by an attribute <code>type</code>. This function checks that <code>type</code> is <code>tri</code> for the Asymmetric Triangular distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>is.tri(para)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="is.tri_+3A_para">para</code></td>
<td>
<p>A parameter <code>list</code> returned from <code><a href="#topic+partri">partri</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>TRUE</code></td>
<td>
<p>If the <code>type</code> attribute is <code>tri</code>.</p>
</td></tr>
<tr><td><code>FALSE</code></td>
<td>
<p>If the <code>type</code> is not <code>tri</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>See Also</h3>

<p><code><a href="#topic+partri">partri</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>para &lt;- partri(lmoms(c(46, 70, 59, 36, 71, 48, 46, 63, 35, 52)))
if(is.tri(para) == TRUE) {
  Q &lt;- quatri(0.5,para)
}
</code></pre>

<hr>
<h2 id='is.wak'>Is a Distribution Parameter Object Typed as Wakeby</h2><span id='topic+is.wak'></span>

<h3>Description</h3>

<p>The distribution parameter object returned by functions of <span class="pkg">lmomco</span> such as by <code><a href="#topic+parwak">parwak</a></code> are typed by an attribute <code>type</code>. This function checks that <code>type</code> is <code>wak</code> for the Wakeby distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>is.wak(para)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="is.wak_+3A_para">para</code></td>
<td>
<p>A parameter <code>list</code> returned from <code><a href="#topic+parwak">parwak</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>TRUE</code></td>
<td>
<p>If the <code>type</code> attribute is <code>wak</code>.</p>
</td></tr>
<tr><td><code>FALSE</code></td>
<td>
<p>If the <code>type</code> is not <code>wak</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>See Also</h3>

<p><code><a href="#topic+parwak">parwak</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>para &lt;- parwak(lmoms(c(123,34,4,654,37,78)))
if(is.wak(para) == TRUE) {
  Q &lt;- quawak(0.5,para)
}
</code></pre>

<hr>
<h2 id='is.wei'>Is a Distribution Parameter Object Typed as Weibull</h2><span id='topic+is.wei'></span>

<h3>Description</h3>

<p>The distribution parameter object returned by functions of <span class="pkg">lmomco</span> such as by <code><a href="#topic+parwei">parwei</a></code> are typed by an attribute <code>type</code>. This function checks that <code>type</code> is <code>wei</code> for the Weibull distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>is.wei(para)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="is.wei_+3A_para">para</code></td>
<td>
<p>A parameter <code>list</code> returned from <code><a href="#topic+parwei">parwei</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>TRUE</code></td>
<td>
<p>If the <code>type</code> attribute is <code>wei</code>.</p>
</td></tr>
<tr><td><code>FALSE</code></td>
<td>
<p>If the <code>type</code> is not <code>wei</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>See Also</h3>

<p><code><a href="#topic+parwei">parwei</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>para &lt;- parwei(lmoms(c(123,34,4,654,37,78)))
if(is.wei(para) == TRUE) {
  Q &lt;- quawei(0.5,para)
}
</code></pre>

<hr>
<h2 id='LaguerreHalf'>Laguerre Polynomial (Half)</h2><span id='topic+LaguerreHalf'></span>

<h3>Description</h3>

<p>This function computes the Laguerre polynomial, which is useful in applications involving the variance of the Rice distribution (see <code><a href="#topic+parrice">parrice</a></code>). The Laguerre polynomial is
</p>
<p style="text-align: center;"><code class="reqn">
L_{1/2}(x) = \exp^{x/2}\times[(1-x)I_0(-x/2) - xI_1(-x/2)]\mbox{,}
</code>
</p>

<p>where the modified Bessel function of the first kind is <code class="reqn">I_k(x)</code>, which has an <span class="rlang"><b>R</b></span> implementation in <code>besselI</code>, and for strictly integer <code class="reqn">k</code> is defined as
</p>
<p style="text-align: center;"><code class="reqn">I_k(x) = \frac{1}{\pi} \int_0^\pi \exp(x\cos(\theta)) \cos(k \theta)\; \mathrm{d}\theta\mbox{.}</code>
</p>



<h3>Usage</h3>

<pre><code class='language-R'>LaguerreHalf(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="LaguerreHalf_+3A_x">x</code></td>
<td>
<p>A value.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The value for the Laguerre polynomial is returned.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>See Also</h3>

<p><code><a href="#topic+pdfrice">pdfrice</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>LaguerreHalf(-100^2/(2*10^2))
</code></pre>

<hr>
<h2 id='Lcomoment.coefficients'>L-comoment Coefficient Matrix </h2><span id='topic+Lcomoment.coefficients'></span>

<h3>Description</h3>

<p>Compute the L-comoment coefficients from an L-comoment matrix of order <code class="reqn">k \ge 2</code> and the <code class="reqn">k = 2</code> (2nd order) L-comoment matrix. However, if the first argument is 1st-order then the coefficients of L-covariation are computed. The function requires that each matrix has already been computed by the function <code><a href="#topic+Lcomoment.matrix">Lcomoment.matrix</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Lcomoment.coefficients(Lk, L2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Lcomoment.coefficients_+3A_lk">Lk</code></td>
<td>
<p>A <code class="reqn"> k \ge 2</code> L-comoment matrix from <code><a href="#topic+Lcomoment.matrix">Lcomoment.matrix</a></code>.</p>
</td></tr>
<tr><td><code id="Lcomoment.coefficients_+3A_l2">L2</code></td>
<td>
<p>A <code class="reqn">k = 2</code> L-comoment matrix from <code>Lcomoment.matrix(Dataframe,k=2)</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The coefficient of L-variation is computed by <code>Lcomoment.coefficients(L1,L2)</code> where <code>L1</code> is a 1st-order L-moment matrix and <code>L2</code> is a <code class="reqn">k = 2</code> L-comoment matrix. Symbolically, the coefficient of L-covariation is
</p>
<p style="text-align: center;"><code class="reqn"> \hat{\tau}_{[12]} = \frac{\hat{\lambda}_{2[12]}}
                                   {\hat{\lambda}_{1[12]}} \mbox{.}</code>
</p>

<p>The higher L-comoment coefficients (L-coskew, L-cokurtosis, ...) are computed by the function <code>Lcomoment.coefficients(L3,L2)</code> (<code class="reqn">k=3</code>),  <code>Lcomoment.coefficients(L4,L2)</code> (<code class="reqn">k=4</code>), and so on. Symbolically, the higher L-comoment coefficients for <code class="reqn">k \ge 3</code> are
</p>
<p style="text-align: center;"><code class="reqn"> \hat{\tau}_{k[12]} = \frac{\hat{\lambda}_{k[12]}}
                                   {\hat{\lambda}_{2[12]}}\mbox{.}</code>
</p>

<p>Finally, the usual univariate L-moment ratios as seen from <code><a href="#topic+lmom.ub">lmom.ub</a></code> or <code><a href="#topic+lmoms">lmoms</a></code> are along the diagonal. The <code><a href="#topic+Lcomoment.coefficients">Lcomoment.coefficients</a></code> function does not make use of <code><a href="#topic+lmom.ub">lmom.ub</a></code> or <code><a href="#topic+lmoms">lmoms</a></code>.
</p>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> is returned.
</p>
<table>
<tr><td><code>type</code></td>
<td>
<p>The type of L-comoment representation in the matrix: &ldquo;Lcomoment.coefficients&rdquo;.</p>
</td></tr>
<tr><td><code>order</code></td>
<td>
<p>The order of the coefficients. <code>order=2</code> L-covariation, <code>order=3</code> L-coskew, ...</p>
</td></tr>
<tr><td><code>matrix</code></td>
<td>
<p>A <code class="reqn">k \ge 2</code> L-comoment coefficient matrix.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The function begins with a capital letter. This is intentionally done so that lower case namespace is preserved. By using a capital letter now, then <code>lcomoment.coefficients</code> remains an available name in future releases.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Asquith, W.H., 2011, Distributional analysis with L-moment statistics using the R environment for statistical computing: Createspace Independent Publishing Platform, ISBN 978&ndash;146350841&ndash;8.
</p>
<p>Serfling, R., and Xiao, P., 2007, A contribution to multivariate L-moments&mdash;L-comoment matrices: Journal of Multivariate Analysis, v. 98, pp. 1765&ndash;1781.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Lcomoment.matrix">Lcomoment.matrix</a></code>, <code><a href="#topic+Lcomoment.coefficients">Lcomoment.coefficients</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>D      &lt;- data.frame(X1=rnorm(30), X2=rnorm(30), X3=rnorm(30))
L1     &lt;- Lcomoment.matrix(D,k=1)
L2     &lt;- Lcomoment.matrix(D,k=2)
L3     &lt;- Lcomoment.matrix(D,k=3)
LkLCV  &lt;- Lcomoment.coefficients(L1,L2)
LkTAU3 &lt;- Lcomoment.coefficients(L3,L2)
</code></pre>

<hr>
<h2 id='Lcomoment.correlation'>L-correlation Matrix (L-correlation through Sample L-comoments) </h2><span id='topic+Lcomoment.correlation'></span>

<h3>Description</h3>

<p>Compute the L-correlation from an L-comoment matrix of order <code class="reqn">k = 2</code>. This function assumes that the 2nd order matrix is already computed by the function <code><a href="#topic+Lcomoment.matrix">Lcomoment.matrix</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Lcomoment.correlation(L2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Lcomoment.correlation_+3A_l2">L2</code></td>
<td>
<p>A <code class="reqn">k = 2</code> L-comoment matrix from <code>Lcomoment.matrix(Dataframe,k=2)</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>L-correlation is computed by <code>Lcomoment.coefficients(L2,L2)</code> where <code>L2</code> is second order L-comoment matrix. The usual L-scale values as seen from <code><a href="#topic+lmom.ub">lmom.ub</a></code> or <code><a href="#topic+lmoms">lmoms</a></code> are along the diagonal. This function does not make use of <code><a href="#topic+lmom.ub">lmom.ub</a></code> or <code><a href="#topic+lmoms">lmoms</a></code> and can be used to verify  computation of <code class="reqn">\tau</code> (coefficient of L-variation).
</p>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> is returned.
</p>
<table>
<tr><td><code>type</code></td>
<td>
<p>The type of L-comoment representation in the matrix: &ldquo;Lcomoment.coefficients&rdquo;.</p>
</td></tr>
<tr><td><code>order</code></td>
<td>
<p>The order of the matrix&mdash;extracted from the first matrix in arguments.</p>
</td></tr>
<tr><td><code>matrix</code></td>
<td>
<p>A <code class="reqn">k \ge 2</code> L-comoment coefficient matrix.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The function begins with a capital letter. This is intentionally done so that lower case namespace is preserved. By using a capital letter now, then <code>lcomoment.correlation</code> remains an available name in future releases.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Asquith, W.H., 2011, Distributional analysis with L-moment statistics using the R environment for statistical computing: Createspace Independent Publishing Platform, ISBN 978&ndash;146350841&ndash;8.
</p>
<p>Serfling, R., and Xiao, P., 2007, A contribution to multivariate L-moments&mdash;L-comoment matrices: Journal of Multivariate Analysis, v. 98, pp. 1765&ndash;1781.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Lcomoment.matrix">Lcomoment.matrix</a></code>, <code><a href="#topic+Lcomoment.correlation">Lcomoment.correlation</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>D   &lt;- data.frame(X1=rnorm(30), X2=rnorm(30), X3=rnorm(30))
L2  &lt;- Lcomoment.matrix(D,k=2)
RHO &lt;- Lcomoment.correlation(L2)
## Not run: 
"SerfXiao.eq17" &lt;-
 function(n=25, A=10, B=2, k=4,
          method=c("pearson","lcorr"), wrt=c("12", "21")) {
   method &lt;- match.arg(method); wrt &lt;- match.arg(wrt)
   # X1 is a linear regression on X2
   X2 &lt;- rnorm(n); X1 &lt;- A + B*X2 + rnorm(n)
   r12p &lt;- cor(X1,X2) # Pearson's product moment correlation
   XX &lt;- data.frame(X1=X1, X2=X2) # for the L-comoments
   T2 &lt;- Lcomoment.correlation(Lcomoment.matrix(XX, k=2))$matrix
   LAMk &lt;- Lcomoment.matrix(XX, k=k)$matrix # L-comoments of order k
   if(wrt == "12") { # is X2 the sorted variable?
      lmr &lt;- lmoms(X1, nmom=k); Lamk &lt;- LAMk[1,2]; Lcor &lt;- T2[1,2]
   } else {          # no X1 is the sorted variable (21)
      lmr &lt;- lmoms(X2, nmom=k); Lamk &lt;- LAMk[2,1]; Lcor &lt;- T2[2,1]
   }
   # Serfling and Xiao (2007, eq. 17) state that
   # L-comoment_k[12] = corr.coeff * Lmoment_k[1] or
   # L-comoment_k[21] = corr.coeff * Lmoment_k[2]
   # And with the X1, X2 setup above, Pearson corr. == L-corr.
   # There will be some numerical differences for any given sample.
   ifelse(method == "pearson",
             return(lmr$lambdas[k]*r12p - Lamk),
             return(lmr$lambdas[k]*Lcor - Lamk))
   # If the above returns a expected value near zero then, their eq.
   # is numerically shown to be correct and the estimators are unbiased.
}

# The means should be near zero.
nrep &lt;- 2000; seed &lt;- rnorm(1); set.seed(seed)
mean(replicate(n=nrep, SerfXiao.eq17(method="pearson", k=4)))
set.seed(seed)
mean(replicate(n=nrep, SerfXiao.eq17(method="lcorr", k=4)))
# The variances should nearly be equal.
seed &lt;- rnorm(1); set.seed(seed)
var(replicate(n=nrep, SerfXiao.eq17(method="pearson", k=6)))
set.seed(seed)
var(replicate(n=nrep, SerfXiao.eq17(method="lcorr", k=6)))

## End(Not run)
</code></pre>

<hr>
<h2 id='Lcomoment.Lk12'>Compute a Single Sample L-comoment </h2><span id='topic+Lcomoment.Lk12'></span>

<h3>Description</h3>

<p>Compute the L-comoment (<code class="reqn">\lambda_{k[12]}</code>) for a given pair of sample of <code class="reqn">n</code> random variates <code class="reqn">\{(X_i^{(1)}, X_i^{(1)}), 1 \le i \le n \}</code> from a joint distribution <code class="reqn">H(x^{(1)}, x^{(2)})</code> with marginal distribution functions <code class="reqn">F_1</code> and <code class="reqn">F_2</code>. When the <code class="reqn">X^{(2)}</code> are sorted to form the sample order statistics <code class="reqn">X^{(2)}_{1:n} \le X^{(2)}_{2:n} \le \cdots \le X^{(2)}_{n:n}</code>, then the element of <code class="reqn">X^{(1)}</code> of the unordered (at leasted expected to be) but shuffled set <code class="reqn">\{X^{(1)}_1, \ldots, X^{(1)}_n\}</code> that is paired with <code class="reqn">X^{(2)}_{r:n}</code> the <em>concomitant</em> <code class="reqn">X^{(12)}_{[r:n]}</code> of <code class="reqn">X^{(2)}_{r:n}</code>. (The shuffling occurs by the sorting of <code class="reqn">X^{(2)}</code>.) The <code class="reqn">k \ge 1</code>-order L-comoments are defined (Serfling and Xiao, 2007, eq. 26) as
</p>
<p style="text-align: center;"><code class="reqn">\hat\lambda_{k[12]} = \frac{1}{n}\sum_{r=1}^n w^{(k)}_{r:n} X^{(12)}_{[r:n]}\mbox{,}</code>
</p>

<p>where <code class="reqn">w^{(k)}_{r:n}</code> is defined under <code><a href="#topic+Lcomoment.Wk">Lcomoment.Wk</a></code>. (The author is aware that <code class="reqn">k \ge 1</code> is <code class="reqn">k \ge 2</code> in Serfling and Xiao (2007) but <code class="reqn">k=1</code> returns sample means. This matters only in that the <span class="pkg">lmomco</span> package returns matrices for <code class="reqn">k \ge 1</code> by <code><a href="#topic+Lcomoment.matrix">Lcomoment.matrix</a></code> even though the off diagnonals are <code>NAs</code>.)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Lcomoment.Lk12(X1,X2,k=1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Lcomoment.Lk12_+3A_x1">X1</code></td>
<td>
<p>A vector of random variables (a sample of random variable 1).</p>
</td></tr>
<tr><td><code id="Lcomoment.Lk12_+3A_x2">X2</code></td>
<td>
<p>Another vector of random variables (a sample of random variable 2).</p>
</td></tr>
<tr><td><code id="Lcomoment.Lk12_+3A_k">k</code></td>
<td>
<p>The order of the L-comoment to compute. The default is 1.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Now directing explanation of L-comoments with some reference heading into <span class="rlang"><b>R</b></span> code. L-comoments of random variable <code>X1</code> (a vector) are computed from the concomitants of <code>X2</code> (another vector). That is, <code class="reqn">X2</code> is sorted in ascending order to create the order statistics of <code>X2</code>. During the sorting process, <code>X1</code> is reshuffled to the order of <code>X2</code> to form the concomitants of <code>X2</code> (denoted as <code>X12</code>). So the trailing <code>2</code> is the sorted variable and the leading <code>1</code> is the variable that is shuffled. The <code>X12</code> in turn are used in a weighted summation and expectation calculation to compute the L-comoment of <code>X1</code> with respect to <code>X2</code> such as by <code>Lk3.12 &lt;-</code> <code>Lcomoment.Lk12(X1,X2,k=3)</code>. The notation of <code>Lk12</code> is to read &ldquo;Lambda for kth order L-comoment&rdquo;, where the <code>12</code> portion of the notation reflects that of Serfling and Xiao (2007) and then Asquith (2011). The weights for the computation are derived from calls made by <code><a href="#topic+Lcomoment.Lk12">Lcomoment.Lk12</a></code> to the weight function <code><a href="#topic+Lcomoment.Wk">Lcomoment.Wk</a></code>. The L-comoments of <code>X2</code> are computed from the concomitants of <code>X1</code>, and the <code>X21</code> are formed by sorting <code>X1</code> in ascending order and in turn shuffling <code>X2</code> by the order of <code>X1</code>. The often asymmetrical L-comoment of <code>X2</code> with respect to <code>X1</code> is readily done (<code>Lk3.21 &lt;-</code> <code>Lcomoment.Lk12(X2,X1,k=3)</code>) and is not necessarily equal to (<code>Lk3.12 &lt;-</code> <code>Lcomoment.Lk12(X1,X2,k=3)</code>).
</p>


<h3>Value</h3>

<p>A single L-comoment.</p>


<h3>Note</h3>

<p>The function begins with a capital letter. This is intentionally done so that lower case namespace is preserved. By using a capital letter now, then <code>lcomoment.Lk12</code> or similar remains an available name in future releases.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Asquith, W.H., 2011, Distributional analysis with L-moment statistics using the R environment for statistical computing: Createspace Independent Publishing Platform, ISBN 978&ndash;146350841&ndash;8.
</p>
<p>Serfling, R., and Xiao, P., 2007, A contribution to multivariate L-moments&mdash;L-comoment matrices: Journal of Multivariate Analysis, v. 98, pp. 1765&ndash;1781.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Lcomoment.matrix">Lcomoment.matrix</a></code>, <code><a href="#topic+Lcomoment.Wk">Lcomoment.Wk</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>X1 &lt;- rnorm(101); X2 &lt;- rnorm(101) + X1
Lcoskew12 &lt;- Lcomoment.Lk12(X1,X2, k=3)
Lcorr12 &lt;- Lcomoment.Lk12(X1,X2,k=2)/Lcomoment.Lk12(X1,X1,k=2)
rhop12 &lt;- cor(X1, X2, method="pearson")
print(Lcorr12 - rhop12) # smallish number
</code></pre>

<hr>
<h2 id='Lcomoment.matrix'>Compute Sample L-comoment Matrix </h2><span id='topic+Lcomoment.matrix'></span>

<h3>Description</h3>

<p>Compute the L-comoments from a rectangular <code>data.frame</code> containing arrays of random variables. The order of the L-comoments is specified.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Lcomoment.matrix(DATAFRAME, k=1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Lcomoment.matrix_+3A_dataframe">DATAFRAME</code></td>
<td>
<p>A convential <code>data.frame</code> that is rectangular.</p>
</td></tr>
<tr><td><code id="Lcomoment.matrix_+3A_k">k</code></td>
<td>
<p>The order of the L-comoments to compute. Default is <code class="reqn">k = 1</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>L-comoments are computed for each item in the <code>data.frame</code>. L-comoments of order <code class="reqn">k = 1</code> are means and co-means. L-comoments of order <code class="reqn">k = 2</code> are L-scale and L-coscale values. L-comoments of order <code class="reqn">k = 3</code> are L-skew and L-coskews. L-comoments of order <code class="reqn">k = 4</code> are L-kurtosis and L-cokurtosis, and so on. The usual univariate L-moments of order <code class="reqn">k</code> as seen from <code><a href="#topic+lmom.ub">lmom.ub</a></code> or <code><a href="#topic+lmoms">lmoms</a></code> are along the diagonal. This function does not make use of <code><a href="#topic+lmom.ub">lmom.ub</a></code> or <code><a href="#topic+lmoms">lmoms</a></code>. The function <code><a href="#topic+Lcomoment.matrix">Lcomoment.matrix</a></code> calls <code><a href="#topic+Lcomoment.Lk12">Lcomoment.Lk12</a></code> for each cell in the matrix. The L-comoment matrix for <code class="reqn">d</code>-random variables is
</p>
<p style="text-align: center;"><code class="reqn"> \mathbf{\Lambda}_k = (\hat{\lambda}_{k[ij]})
       </code>
</p>

<p>computed over the pairs (<code class="reqn">X^{(i)},X^{(j)}</code>) where <code class="reqn">1 \le i \le j \le d</code>.
</p>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> is returned.
</p>
<table>
<tr><td><code>type</code></td>
<td>
<p>The type of L-comoment representation in the matrix: &ldquo;Lcomoments&rdquo;.</p>
</td></tr>
<tr><td><code>order</code></td>
<td>
<p>The order of the matrix&mdash;specified by k in the argument list.</p>
</td></tr>
<tr><td><code>matrix</code></td>
<td>
<p>A kth order L-comoment matrix.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The function begins with a capital letter. This is intentionally done so that lower case namespace is preserved. By using a capital letter now, then <code>lcomoment.matrix</code> remains an available name in future releases.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Asquith, W.H., 2011, Distributional analysis with L-moment statistics using the R environment for statistical computing: Createspace Independent Publishing Platform, ISBN 978&ndash;146350841&ndash;8.
</p>
<p>Serfling, R., and Xiao, P., 2007, A contribution to multivariate L-moments&mdash;L-comoment matrices: Journal of Multivariate Analysis, v. 98, pp. 1765&ndash;1781.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Lcomoment.Lk12">Lcomoment.Lk12</a></code>, <code><a href="#topic+Lcomoment.coefficients">Lcomoment.coefficients</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>D  &lt;- data.frame(X1=rnorm(30), X2=rnorm(30), X3=rnorm(30))
L1 &lt;- Lcomoment.matrix(D, k=1)
L2 &lt;- Lcomoment.matrix(D, k=2)
</code></pre>

<hr>
<h2 id='Lcomoment.Wk'>Weighting Coefficient for Sample L-comoment </h2><span id='topic+Lcomoment.Wk'></span>

<h3>Description</h3>

<p>Compute the weight factors for computation of an L-comoment for order <code>k</code>, order statistic <code>r</code>, and sample size <code>n</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Lcomoment.Wk(k,r,n)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Lcomoment.Wk_+3A_k">k</code></td>
<td>
<p>Order of L-comoment being computed by parent calls to <code><a href="#topic+Lcomoment.Wk">Lcomoment.Wk</a></code>.</p>
</td></tr>
<tr><td><code id="Lcomoment.Wk_+3A_r">r</code></td>
<td>
<p>Order statistic index involved.</p>
</td></tr>
<tr><td><code id="Lcomoment.Wk_+3A_n">n</code></td>
<td>
<p>Sample size.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function computes the weight factors needed to calculation L-comoments and is interfaced or used by <code><a href="#topic+Lcomoment.Lk12">Lcomoment.Lk12</a></code>. The weight factors are
</p>
<p style="text-align: center;"><code class="reqn"> w^{(k)}_{r:n} = \sum_{j=0}^{min\{r-1,k-1\}} (-1)^{k-1-j}
                                    \frac{{k-1 \choose j}{k-1+j \choose j}
          {r-1 \choose j}}
         {{n-1 \choose j}}
      \mbox{.}</code>
</p>

<p>The weight factor <code class="reqn">w^{(k)}_{r:n}</code> is the discrete Legendre polynomial. The weight factors are well illustrated in figure 6.1 of Asquith (2011). This function is not intended for end users.
</p>


<h3>Value</h3>

<p>A single L-comoment weight factor.</p>


<h3>Note</h3>

<p>The function begins with a capital letter. This is intentionally done so that lower case namespace is preserved.  By using a capital letter now, then <code>lcomoment.Wk</code> remains an available name in future releases.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Asquith, W.H., 2011, Distributional analysis with L-moment statistics using the R environment for statistical computing: Createspace Independent Publishing Platform, ISBN 978&ndash;146350841&ndash;8.
</p>
<p>Serfling, R., and Xiao, P., 2007, A contribution to multivariate L-moments&mdash;L-comoment matrices: Journal of Multivariate Analysis, v. 98, pp. 1765&ndash;1781.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Lcomoment.Lk12">Lcomoment.Lk12</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>Wk &lt;- Lcomoment.Wk(2,3,5)
print(Wk)

## Not run: 
# To compute the weight factors for L-skew and L-coskew (k=3) computation
# for a sample of size 20.
Wk &lt;- matrix(nrow=20,ncol=1)
for(r in seq(1,20)) Wk[r] &lt;- Lcomoment.Wk(3,r,20)
plot(seq(1,20),Wk, type="b")

## End(Not run)

# The following shows the actual weights used for computation of
# the first four L-moments. The sum of the each sample times the
# corresponding weight equals the L-moment.
fakedat &lt;- sort(c(-10, 20, 30, 40));  n &lt;- length(fakedat)
Wk1 &lt;- Wk2 &lt;- Wk3 &lt;- Wk4 &lt;- vector(mode="numeric", length=n);
for(i in 1:n) {
   Wk1[i] &lt;- Lcomoment.Wk(1,i,n)/n
   Wk2[i] &lt;- Lcomoment.Wk(2,i,n)/n
   Wk3[i] &lt;- Lcomoment.Wk(3,i,n)/n
   Wk4[i] &lt;- Lcomoment.Wk(4,i,n)/n
}
cat(c("Weights for mean",         round(Wk1, digits=4), "\n"))
cat(c("Weights for L-scale",      round(Wk2, digits=4), "\n"))
cat(c("Weights for 3rd L-moment", round(Wk3, digits=4), "\n"))
cat(c("Weights for 4th L-moment", round(Wk4, digits=4), "\n"))
my.lams &lt;- c(sum(fakedat*Wk1), sum(fakedat*Wk2),
             sum(fakedat*Wk3), sum(fakedat*Wk4))
cat(c("Manual L-moments:", my.lams, "\n"))
cat(c("lmomco L-moments:", lmoms(fakedat, nmom=4)$lambdas,"\n"))
# The last two lines of output should be the same---note that lmoms()
# does not utilize Lcomoment.Wk(). So a double check is made.
</code></pre>

<hr>
<h2 id='lcomoms2'>The Sample L-comoments for Two Variables </h2><span id='topic+lcomoms2'></span>

<h3>Description</h3>

<p>Compute the sample L-moments for the <span class="rlang"><b>R</b></span> two variable  <code>data.frame</code>. The &ldquo;2&rdquo; in the function name is to refer to fact that this function operates on only two variables. The length of the variables must be greater than the number of L-comoments requested.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lcomoms2(DATAFRAME, nmom=3, asdiag=FALSE, opdiag=FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lcomoms2_+3A_dataframe">DATAFRAME</code></td>
<td>
<p>An <span class="rlang"><b>R</b></span> <code>data.frame</code> housing column vectors of data values.</p>
</td></tr>
<tr><td><code id="lcomoms2_+3A_nmom">nmom</code></td>
<td>
<p>The number of L-comoments to compute. Default is 3.</p>
</td></tr>
<tr><td><code id="lcomoms2_+3A_asdiag">asdiag</code></td>
<td>
<p>Return the <code>diag</code>onal of the matrices. Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="lcomoms2_+3A_opdiag">opdiag</code></td>
<td>
<p>Return the opposing diagonal of the matrices. Default is <code>FALSE</code>. This function returns the opposing diagonal from first two to second.</p>
</td></tr>
<tr><td><code id="lcomoms2_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> is returned of the first
</p>
<table>
<tr><td><code>L1</code></td>
<td>
<p>Matrix or diagonals of first L-comoment.</p>
</td></tr>
<tr><td><code>L2</code></td>
<td>
<p>Matrix or diagonals of second L-comoment.</p>
</td></tr>
<tr><td><code>T2</code></td>
<td>
<p>Matrix or diagonals of L-comoment correlation.</p>
</td></tr>
<tr><td><code>T3</code></td>
<td>
<p>Matrix or diagonals of L-comoment skew.</p>
</td></tr>
<tr><td><code>T4</code></td>
<td>
<p>Matrix or diagonals of L-comoment kurtosis.</p>
</td></tr>
<tr><td><code>T5</code></td>
<td>
<p>Matrix or diagonals of L-comoment Tau5.</p>
</td></tr>
<tr><td><code>source</code></td>
<td>
<p>An attribute identifying the computational source of the L-comoments: &ldquo;lcomoms2&rdquo;.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>This function computes the L-comoments through the generalization of the <code><a href="#topic+Lcomoment.matrix">Lcomoment.matrix</a></code> and <code><a href="#topic+Lcomoment.coefficients">Lcomoment.coefficients</a></code> functions.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Asquith, W.H., 2011, Distributional analysis with L-moment statistics using the R environment for statistical computing: Createspace Independent Publishing Platform, ISBN 978&ndash;146350841&ndash;8.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Lcomoment.matrix">Lcomoment.matrix</a></code> and <code><a href="#topic+Lcomoment.coefficients">Lcomoment.coefficients</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Random simulation of standard normal and then combine with
# a random standard exponential distribution
X &lt;- rnorm(200); Y &lt;- X + rexp(200)
z &lt;- lcomoms2(data.frame(X=X, Y=Y))
print(z)

z &lt;- lcomoms2(data.frame(X=X, Y=Y), diag=TRUE)
print(z$T3) # the L-skew values of the margins

z &lt;- lcomoms2(data.frame(X=X, Y=Y), opdiag=TRUE)
print(z$T3) # the L-coskew values
## End(Not run)
</code></pre>

<hr>
<h2 id='lkhlmomco'>Leimkuhler Curve of the Distributions</h2><span id='topic+lkhlmomco'></span>

<h3>Description</h3>

<p>This function computes the Leimkuhler Curve  for quantile function <code class="reqn">x(F)</code> (<code><a href="#topic+par2qua">par2qua</a></code>, <code><a href="#topic+qlmomco">qlmomco</a></code>). The function is defined by Nair et al. (2013, p. 181) as
</p>
<p style="text-align: center;"><code class="reqn">K(u) = 1 - \frac{1}{\mu}\int_0^{1-u} x(p)\; \mathrm{d}p\mbox{,}</code>
</p>

<p>where <code class="reqn">K(u)</code> is Leimkuhler curve for nonexceedance probability <code class="reqn">u</code>. The Leimkuhler curve is related to the Lorenz curve (<code class="reqn">L(u)</code>, <code><a href="#topic+lrzlmomco">lrzlmomco</a></code>) by
</p>
<p style="text-align: center;"><code class="reqn">K(u) = 1-L(1-u)\mbox{,}</code>
</p>

<p>and related to the reversed residual mean quantile function (<code class="reqn">R(u)</code>, <code><a href="#topic+rrmlmomco">rrmlmomco</a></code>) and conditional mean (<code class="reqn">\mu</code>, <code><a href="#topic+cmlmomco">cmlmomco</a></code>) for <code class="reqn">u=0</code> by
</p>
<p style="text-align: center;"><code class="reqn">K(u) = \frac{1}{\mu} [\mu - (1-u)(x(1-u) - R(1-u))] \mbox{.}</code>
</p>



<h3>Usage</h3>

<pre><code class='language-R'>lkhlmomco(f, para)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lkhlmomco_+3A_f">f</code></td>
<td>
<p>Nonexceedance probability (<code class="reqn">0 \le F \le 1</code>).</p>
</td></tr>
<tr><td><code id="lkhlmomco_+3A_para">para</code></td>
<td>
<p>The parameters from <code><a href="#topic+lmom2par">lmom2par</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Leimkuhler curve value for <code class="reqn">F</code>.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Nair, N.U., Sankaran, P.G., and Balakrishnan, N., 2013, Quantile-based reliability analysis: Springer, New York.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+qlmomco">qlmomco</a></code>, <code><a href="#topic+lrzlmomco">lrzlmomco</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># It is easiest to think about residual life as starting at the origin, units in days.
A &lt;- vec2par(c(0.0, 2649, 2.11), type="gov") # so set lower bounds = 0.0

"afunc" &lt;- function(u) { return(par2qua(u,A,paracheck=FALSE)) }
f &lt;- 0.35 # All three computations report: Ku = 0.6413727
Ku1 &lt;- 1 - 1/cmlmomco(f=0,A) * integrate(afunc,0,1-f)$value
Ku2 &lt;- (cmlmomco(0,A) - (1-f)*(quagov(1-f,A) - rrmlmomco(1-f,A)))/cmlmomco(0,A)
Ku3 &lt;- lkhlmomco(f, A)
</code></pre>

<hr>
<h2 id='lmom.ub'>Unbiased Sample L-moments by Direct Sample Estimators </h2><span id='topic+lmom.ub'></span>

<h3>Description</h3>

<p>Unbiased sample L-moments are computed for a vector using the direct sample estimation method as opposed to the use of sample probability-weighted moments. The L-moments are the ordinary L-moments and not the trimmed L-moments (see <code><a href="#topic+TLmoms">TLmoms</a></code>). The mean, L-scale, coefficient of L-variation (<code class="reqn">\tau</code>, LCV, L-scale/mean), L-skew (<code class="reqn">\tau_3</code>, TAU3, L3/L2), L-kurtosis (<code class="reqn">\tau_4</code>, TAU4, L4/L2), and <code class="reqn">\tau_5</code> (TAU5, L5/L2) are computed. In conventional nomenclature, the L-moments are
</p>
<p style="text-align: center;"><code class="reqn"> \hat{\lambda}_1 = \mbox{L1} = \mbox{mean, }</code>
</p>

<p style="text-align: center;"><code class="reqn"> \hat{\lambda}_2 = \mbox{L2} = \mbox{L-scale, }</code>
</p>

<p style="text-align: center;"><code class="reqn"> \hat{\lambda}_3 = \mbox{L3} = \mbox{third L-moment, }</code>
</p>

<p style="text-align: center;"><code class="reqn"> \hat{\lambda}_4 = \mbox{L4} = \mbox{fourth L-moment, and }</code>
</p>

<p style="text-align: center;"><code class="reqn"> \hat{\lambda}_5 = \mbox{L5} = \mbox{fifth L-moment. }</code>
</p>

<p>The L-moment ratios are
</p>
<p style="text-align: center;"><code class="reqn"> \hat{\tau} = \mbox{LCV} = \lambda_2/\lambda_1 = \mbox{coefficient of L-variation, }</code>
</p>

<p style="text-align: center;"><code class="reqn"> \hat{\tau}_3 = \mbox{TAU3} = \lambda_3/\lambda_2 = \mbox{L-skew, }</code>
</p>

<p style="text-align: center;"><code class="reqn"> \hat{\tau}_4 = \mbox{TAU4} = \lambda_4/\lambda_2 = \mbox{L-kurtosis, and}</code>
</p>

<p style="text-align: center;"><code class="reqn"> \hat{\tau}_5 = \mbox{TAU5} = \lambda_5/\lambda_2 = \mbox{not named.}</code>
</p>

<p>It is common amongst practitioners to lump the L-moment ratios into the general term &ldquo;L-moments&rdquo; and remain inclusive of the L-moment ratios. For example, L-skew then is referred to as the 3rd L-moment when it technically is the 3rd L-moment ratio.  The first L-moment ratio has no definition; the <code><a href="#topic+lmoms">lmoms</a></code> function uses the <code>NA</code> of <span class="rlang"><b>R</b></span> in its vector representation of the ratios.
</p>
<p>The mathematical expression for sample L-moment computation is shown under <code><a href="#topic+TLmoms">TLmoms</a></code>. The formula jointly handles sample L-moment computation and sample TL-moment computation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lmom.ub(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lmom.ub_+3A_x">x</code></td>
<td>
<p>A vector of data values.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The L-moment ratios (<code class="reqn">\tau</code>, <code class="reqn">\tau_3</code>, <code class="reqn">\tau_4</code>, and <code class="reqn">\tau_5</code>) are the primary higher L-moments for application, such as for distribution parameter estimation. However, the actual L-moments (<code class="reqn">\lambda_3</code>, <code class="reqn">\lambda_4</code>, and <code class="reqn">\lambda_5</code>) are also reported. The implementation of <code><a href="#topic+lmom.ub">lmom.ub</a></code> requires a minimum of five data points. If more or fewer L-moments are needed then use the function <code><a href="#topic+lmoms">lmoms</a></code>.
</p>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> is returned.
</p>
<table>
<tr><td><code>L1</code></td>
<td>
<p>Arithmetic mean.</p>
</td></tr>
<tr><td><code>L2</code></td>
<td>
<p>L-scale&mdash;analogous to standard deviation (see also <code><a href="#topic+gini.mean.diff">gini.mean.diff</a></code>.</p>
</td></tr>
<tr><td><code>LCV</code></td>
<td>
<p>coefficient of L-variation&mdash;analogous to coe. of variation.</p>
</td></tr>
<tr><td><code>TAU3</code></td>
<td>
<p>The third L-moment ratio or L-skew&mdash;analogous to skew.</p>
</td></tr>
<tr><td><code>TAU4</code></td>
<td>
<p>The fourth L-moment ratio or L-kurtosis&mdash;analogous to kurtosis.</p>
</td></tr>
<tr><td><code>TAU5</code></td>
<td>
<p>The fifth L-moment ratio.</p>
</td></tr>
<tr><td><code>L3</code></td>
<td>
<p>The third L-moment.</p>
</td></tr>
<tr><td><code>L4</code></td>
<td>
<p>The fourth L-moment.</p>
</td></tr>
<tr><td><code>L5</code></td>
<td>
<p>The fifth L-moment.</p>
</td></tr>
<tr><td><code>source</code></td>
<td>
<p>An attribute identifying the computational source of the L-moments: &ldquo;lmom.ub&rdquo;.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The <code><a href="#topic+lmom.ub">lmom.ub</a></code> function was among the first functions written for <span class="pkg">lmomco</span> and actually written before <span class="pkg">lmomco</span> was initiated. The <code>ub</code> was to be contrasted with plotting-position-based estimation methods: <code><a href="#topic+pwm.pp">pwm.pp</a></code> <code class="reqn">\rightarrow</code> <code><a href="#topic+pwm2lmom">pwm2lmom</a></code>. Further, at the time of development the radical expansion of <span class="pkg">lmomco</span> beyond the Hosking (1996) FORTRAN libraries was not anticipated.  The author now exclusively uses <code><a href="#topic+lmoms">lmoms</a></code> but the numerical results should be identical. The direct sample estimator algorithm by Wang (1996) is used in <code><a href="#topic+lmom.ub">lmom.ub</a></code> and a more generalized algorithm is associated with <code><a href="#topic+lmoms">lmoms</a></code>.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>Source</h3>

<p>The Perl code base of W.H. Asquith
</p>


<h3>References</h3>

<p>Asquith, W.H., 2011, Distributional analysis with L-moment statistics using the R environment for statistical computing: Createspace Independent Publishing Platform, ISBN 978&ndash;146350841&ndash;8.
</p>
<p>Hosking, J.R.M., 1990, L-moments&mdash;Analysis and estimation of
distributions using linear combinations of order statistics: Journal of the Royal Statistical Society, Series B, v. 52, pp. 105&ndash;124.
</p>
<p>Wang, Q.J., 1996, Direct sample estimators of L-moments: Water Resources Research, v. 32, no. 12., pp. 3617&ndash;3619.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lmom2pwm">lmom2pwm</a></code>, <code><a href="#topic+pwm.ub">pwm.ub</a></code>, <code><a href="#topic+pwm2lmom">pwm2lmom</a></code>, <code><a href="#topic+lmoms">lmoms</a></code>, <code><a href="#topic+lmorph">lmorph</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>lmr &lt;- lmom.ub(c(123,34,4,654,37,78))
lmorph(lmr)
lmom.ub(rnorm(100))
</code></pre>

<hr>
<h2 id='lmom2par'>Convert L-moments to the Parameters of a Distribution</h2><span id='topic+lmom2par'></span><span id='topic+lmr2par'></span>

<h3>Description</h3>

<p>This function converts L-moments to the parameters of a distribution. The type of distribution is specified in the argument list:
<code>aep4</code>, <code>cau</code>, <code>emu</code>, <code>exp</code>, <code>gam</code>, <code>gep</code>,
<code>gev</code>, <code>gld</code>, <code>glo</code>, <code>gno</code>, <code>gov</code>,
<code>gpa</code>, <code>gum</code>, <code>kap</code>, <code>kmu</code>, <code>kur</code>,
<code>lap</code>, <code>lmrq</code>, <code>ln3</code>, <code>nor</code>, <code>pe3</code>,
<code>ray</code>, <code>revgum</code>, <code>rice</code>, <code>sla</code>, <code>st3</code>,
<code>texp</code>, <code>wak</code>, or <code>wei</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lmom2par(lmom, type, ...)
lmr2par(x, type, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lmom2par_+3A_lmom">lmom</code></td>
<td>
<p>An L-moment object such as that returned by <code><a href="#topic+lmoms">lmoms</a></code> or <code><a href="#topic+pwm2lmom">pwm2lmom</a></code>.</p>
</td></tr>
<tr><td><code id="lmom2par_+3A_type">type</code></td>
<td>
<p>Three character (minimum) distribution type (for example, <code>type="gev"</code>).</p>
</td></tr>
<tr><td><code id="lmom2par_+3A_...">...</code></td>
<td>
<p>Additional arguments for the <code>parCCC</code> functions.</p>
</td></tr>
<tr><td><code id="lmom2par_+3A_x">x</code></td>
<td>
<p>In the <code>lmr2par</code> call the L-moments are computed from the <code class="reqn">x</code> values. This function is a parallel to <code><a href="#topic+mle2par">mle2par</a></code> and <code><a href="#topic+mps2par">mps2par</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> is returned.  This list should contain at least the following items, but some distributions such as the <code>revgum</code> have extra.
</p>
<table>
<tr><td><code>type</code></td>
<td>
<p>The type of distribution in three character (minimum) format.</p>
</td></tr>
<tr><td><code>para</code></td>
<td>
<p>The parameters of the distribution.</p>
</td></tr>
<tr><td><code>source</code></td>
<td>
<p>Attribute specifying source of the parameters.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>See Also</h3>

<p><code><a href="#topic+par2lmom">par2lmom</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>lmr  &lt;- lmoms(rnorm(20))
para &lt;- lmom2par(lmr,type="nor")

# The lmom2par() calls will error if trim != 1.
X &lt;- rcauchy(20)
cauchy &lt;- lmom2par(TLmoms(X, trim=1), type="cau")
slash  &lt;- lmom2par(TLmoms(X, trim=1), type="sla")
## Not run: 
plot(pp(X), sort(X), xlab="PROBABILITY", ylab="CAUCHY")
lines(nonexceeds(), par2qua(nonexceeds(), cauchy))
lines(nonexceeds(), par2qua(nonexceeds(), slash), col=2)

## End(Not run)
</code></pre>

<hr>
<h2 id='lmom2pwm'>L-moments to Probability-Weighted Moments</h2><span id='topic+lmom2pwm'></span>

<h3>Description</h3>

<p>Converts the L-moments to the probability-weighted moments (PWMs) given the L-moments. The conversion is linear so procedures based on L-moments are identical to those based on PWMs. The expression linking PWMs to L-moments is
</p>
<p style="text-align: center;"><code class="reqn">
\lambda_{r+1} = \sum_{k=0}^r (-1)^{r-k} {r \choose k}{r+k \choose k}\beta_k\mbox{,}
</code>
</p>

<p>where <code class="reqn">\lambda_{r+1}</code> are the L-moments, <code class="reqn">\beta_r</code> are the PWMs, and <code class="reqn">r \ge 0</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lmom2pwm(lmom)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lmom2pwm_+3A_lmom">lmom</code></td>
<td>
<p> An L-moment object created by <code><a href="#topic+lmoms">lmoms</a></code>, <code><a href="#topic+lmom.ub">lmom.ub</a></code>, or <code><a href="#topic+vec2lmom">vec2lmom</a></code>. The function also supports <code>lmom</code> as a vector of L-moments (<code class="reqn">\lambda_1</code>, <code class="reqn">\lambda_2</code>, <code class="reqn">\tau_3</code>, <code class="reqn">\tau_4</code>, and <code class="reqn">\tau_5</code>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>PWMs are linear combinations of the L-moments and therefore contain the same statistical information of the data as the L-moments. However, the PWMs are harder to interpret as measures of probability distributions. The PWMs are included in <span class="pkg">lmomco</span> for theoretical completeness and are not intended for use with the majority of the other functions implementing the various probability distributions. The relations between L-moments (<code class="reqn">\lambda_r</code>) and PWMs (<code class="reqn">\beta_{r-1}</code>) for <code class="reqn">1 \le r \le 5</code> order are
</p>
<p style="text-align: center;"><code class="reqn">\lambda_1 = \beta_0 \mbox{,}</code>
</p>

<p style="text-align: center;"><code class="reqn">\lambda_2 = 2\beta_1 - \beta_0 \mbox{,}</code>
</p>

<p style="text-align: center;"><code class="reqn">\lambda_3 = 6\beta_2 - 6\beta_1 + \beta_0 \mbox{,}</code>
</p>

<p style="text-align: center;"><code class="reqn">\lambda_4 = 20\beta_3 - 30\beta_2 + 12\beta_1 - \beta_0\mbox{, and}</code>
</p>

<p style="text-align: center;"><code class="reqn">\lambda_5 = 70\beta_4  - 140\beta_3 + 90\beta_2 - 20\beta_1 + \beta_0\mbox{.}</code>
</p>

<p>The linearity between L-moments and PWMs means that procedures based on one are equivalent to the other. This function only accomodates the first five L-moments and PWMs. Therefore, at least five L-moments are required in the passed argument.
</p>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> is returned.
</p>
<table>
<tr><td><code>betas</code></td>
<td>
<p>The PWMs. Note that convention is the have a <code class="reqn">\beta_0</code>, but this is placed in the first index <code>i=1</code> of the <code>betas</code> vector.</p>
</td></tr>
<tr><td><code>source</code></td>
<td>
<p>Source of the PWMs: &ldquo;pwm&rdquo;.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>W.H. Asquith </p>


<h3>References</h3>

<p>Asquith, W.H., 2011, Distributional analysis with L-moment statistics using the R environment for statistical computing: Createspace Independent Publishing Platform, ISBN 978&ndash;146350841&ndash;8.
</p>
<p>Greenwood, J.A., Landwehr, J.M., Matalas, N.C., and Wallis, J.R., 1979, Probability weighted moments&mdash;Definition and relation to parameters of several distributions expressable in inverse form: Water Resources Research, v. 15, pp. 1,049&ndash;1,054.
</p>
<p>Hosking, J.R.M., 1990, L-moments&mdash;Analysis and estimation of distributions using linear combinations of order statistics: Journal of the Royal Statistical Society, Series B, v. 52, pp. 105&ndash;124.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lmom.ub">lmom.ub</a></code>, <code><a href="#topic+lmoms">lmoms</a></code>, <code><a href="#topic+pwm.ub">pwm.ub</a></code>, <code><a href="#topic+pwm2lmom">pwm2lmom</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>pwm &lt;- lmom2pwm(lmoms(c(123,34,4,654,37,78)))
lmom2pwm(lmom.ub(rnorm(100)))
lmom2pwm(lmoms(rnorm(100)))

lmomvec1 &lt;- c(1000,1300,0.4,0.3,0.2,0.1)
pwmvec   &lt;- lmom2pwm(lmomvec1)
print(pwmvec)
#$betas
#[1] 1000.0000 1150.0000 1070.0000  984.5000  911.2857
#
#$source
#[1] "lmom2pwm"

lmomvec2 &lt;- pwm2lmom(pwmvec)
print(lmomvec2)
#$lambdas
#[1] 1000 1300  520  390  260
#
#$ratios
#[1]  NA 1.3 0.4 0.3 0.2
#
#$source
#[1] "pwm2lmom"

pwm2lmom(lmom2pwm(list(L1=25, L2=20, TAU3=.45, TAU4=0.2, TAU5=0.1)))
</code></pre>

<hr>
<h2 id='lmom2vec'>Convert an L-moment object to a Vector of L-moments</h2><span id='topic+lmom2vec'></span>

<h3>Description</h3>

<p>This function converts an L-moment object in the structure used by <span class="pkg">lmomco</span> into a simple vector. The precise operation of this function is dependent on the L-moment object argument. The <code><a href="#topic+lmorph">lmorph</a></code> function is not used. This function is useful if one needs to use certain functions in the <span class="pkg">lmoms</span> package that are built around vectors of L-moments and L-moment ratios as arguments.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lmom2vec(lmom, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lmom2vec_+3A_lmom">lmom</code></td>
<td>
<p>L-moment object as from functions such as <code>lmoms</code>, <code>lmom.ub</code>, and <code>vec2lmom</code>.</p>
</td></tr>
<tr><td><code id="lmom2vec_+3A_...">...</code></td>
<td>
<p>Not presently used.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of the L-moments (<code class="reqn">\lambda_1</code>, <code class="reqn">\lambda_2</code>, <code class="reqn">\tau_3</code>, <code class="reqn">\tau_4</code>, <code class="reqn">\tau_5</code>, ..., <code class="reqn">\tau_r</code>).
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>See Also</h3>

<p><code><a href="#topic+lmom.ub">lmom.ub</a></code>, <code><a href="#topic+lmoms">lmoms</a></code>, <code><a href="#topic+lmorph">lmorph</a></code>, <code><a href="#topic+vec2lmom">vec2lmom</a></code>, <code><a href="#topic+pwm2vec">pwm2vec</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  lmr &lt;- lmoms(rnorm(40))
  lmom2vec(lmr)
  lmr &lt;- vec2lmom(c(140,150,.3,.2,-.1))
  lmom2vec(lmr)
</code></pre>

<hr>
<h2 id='lmomaep4'>L-moments of the 4-Parameter Asymmetric Exponential Power Distribution</h2><span id='topic+lmomaep4'></span>

<h3>Description</h3>

<p>This function computes the L-moments of the 4-parameter Asymmetric Exponential Power distribution given the parameters (<code class="reqn">\xi</code>, <code class="reqn">\alpha</code>, <code class="reqn">\kappa</code>, and <code class="reqn">h</code>) from <code><a href="#topic+paraep4">paraep4</a></code>. The first four L-moments are complex. The mean <code class="reqn">\lambda_1</code> is
</p>
<p style="text-align: center;"><code class="reqn">\lambda_1 = \xi + \alpha(1/\kappa - \kappa)\frac{\Gamma(2/h)}{\Gamma(1/h)}\mbox{,}</code>
</p>

<p>where <code class="reqn">\Gamma(x)</code> is the complete gamma function or <code>gamma()</code> in <span class="rlang"><b>R</b></span>.
</p>
<p>The L-scale <code class="reqn">\lambda_2</code> is
</p>
<p style="text-align: center;"><code class="reqn">\lambda_2 = -\frac{\alpha\kappa(1/\kappa - \kappa)^2\Gamma(2/h)}
                        {(1+\kappa^2)\Gamma(1/h)}
                + 2\frac{\alpha\kappa^2(1/\kappa^3 + \kappa^3)\Gamma(2/h)I_{1/2}(1/h,2/h)}
                        {(1+\kappa^2)^2\Gamma(1/h)}\mbox{,}</code>
</p>

<p>where <code class="reqn">I_{1/2}(1/h,2/h)</code> is the cumulative distribution function of the Beta distribution (<code class="reqn">I_x(a,b)</code>) or <code>pbeta(1/2,</code> <code>shape1=1/h,</code> <code>shape2=2/h)</code> in <span class="rlang"><b>R</b></span>. This function is also referred to as the normalized incomplete beta function (Delicado and Goria, 2008) and defined as
</p>
<p style="text-align: center;"><code class="reqn">I_x(a,b) =  \frac{\int_0^x t^{a-1} (1-t)^{b-1}\; \mathrm{d}t}{\beta(a,b)}\mbox{,}</code>
</p>

<p>where <code class="reqn">\beta(1/h, 2/h)</code> is the complete beta function or <code>beta(1/h, 2/h)</code> in <span class="rlang"><b>R</b></span>.
</p>
<p>The third L-moment <code class="reqn">\lambda_3</code> is
</p>
<p style="text-align: center;"><code class="reqn">\lambda_3 = A_1 + A_2 + A_3\mbox{,}</code>
</p>

<p>where the <code class="reqn">A_i</code> are
</p>
<p style="text-align: center;"><code class="reqn">A_1 = \frac{\alpha(1/\kappa - \kappa)(\kappa^4 - 4\kappa^2 + 1)\Gamma(2/h)}
                 {(1+\kappa^2)^2\Gamma(1/h)}\mbox{,}</code>
</p>

<p style="text-align: center;"><code class="reqn">A_2 = -6\frac{\alpha\kappa^3(1/\kappa - \kappa)(1/\kappa^3 + \kappa^3)\Gamma(2/h)I_{1/2}(1/h,2/h)}
                 {(1+\kappa^2)^3\Gamma(1/h)}\mbox{,}</code>
</p>

<p style="text-align: center;"><code class="reqn">A_3 = 6\frac{\alpha(1+\kappa^4)(1/\kappa - \kappa)\Gamma(2/h)\Delta}
                 {(1+\kappa^2)^2\Gamma(1/h)}\mbox{,}</code>
</p>

<p>and where <code class="reqn">\Delta</code> is
</p>
<p style="text-align: center;"><code class="reqn">\Delta = \frac{1}{\beta(1/h, 2/h)}\int_0^{1/2} t^{1/h - 1} (1-t)^{2/h - 1} I_{(1-t)/(2-t)}(1/h, 3/h) \; \mathrm{d}t\mbox{.}</code>
</p>

<p>The fourth L-moment <code class="reqn">\lambda_4</code> is
</p>
<p style="text-align: center;"><code class="reqn">\lambda_4 = B_1 + B_2 + B_3 + B_4\mbox{,}</code>
</p>

<p>where the <code class="reqn">B_i</code> are
</p>
<p style="text-align: center;"><code class="reqn">B_1 = -\frac{\alpha\kappa(1/\kappa - \kappa)^2(\kappa^4 - 8\kappa^2 + 1)\Gamma(2/h)}
                  {(1+\kappa^2)^3\Gamma(1/h)}\mbox{,}</code>
</p>

<p style="text-align: center;"><code class="reqn">B_2 = 12\frac{\alpha\kappa^2(\kappa^3 + 1/\kappa^3)(\kappa^4 - 3\kappa^2 + 1)\Gamma(2/h)I_{1/2}(1/h,2/h)}
                   {(1+\kappa^2)^4\Gamma(1/h)}\mbox{,}</code>
</p>

<p style="text-align: center;"><code class="reqn">B_3 = -30\frac{\alpha\kappa^3(1/\kappa - \kappa)^2(1/\kappa^2 + \kappa^2)\Gamma(2/h)\Delta}
                    {(1+\kappa^2)^3\Gamma(1/h)}\mbox{,}</code>
</p>

<p style="text-align: center;"><code class="reqn">B_4 = 20\frac{\alpha\kappa^4(1/\kappa^5 + \kappa^5)\Gamma(2/h)\Delta_1}
                   {(1+\kappa^2)^4\Gamma(1/h)}\mbox{,}</code>
</p>

<p>and where <code class="reqn">\Delta_1</code> is
</p>
<p style="text-align: center;"><code class="reqn">\Delta_1 =  \frac{\int_0^{1/2}  \int_0^{(1-y)/(2-y)}   y^{1/h - 1} (1-y)^{2/h - 1}
                       z^{1/h - 1} (1-z)^{3/h - 1}
        \;I'\; \mathrm{d}z\,\mathrm{d}y}{\beta(1/h, 2/h)\beta(1/h, 3/h)}\mbox{,}</code>
</p>

<p>for which <code class="reqn">I' = I_{(1-z)(1-y)/(1+(1-z)(1-y))}(1/h, 2/h)</code> is the cumulative distribution function of the beta distribution (<code class="reqn">I_x(a,b)</code>) or <code>pbeta((1-z)(1-y)/(1+(1-z)(1-y)), shape1=1/h, shape2=2/h)</code> in <span class="rlang"><b>R</b></span>. Finally, if the <code class="reqn">\tau_3</code> of the distribution is zero (symmetrical), then the distribution is known as the Exponential Power (see <code><a href="#topic+lmrdia46">lmrdia46</a></code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lmomaep4(para, paracheck=TRUE, t3t4only=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lmomaep4_+3A_para">para</code></td>
<td>
<p>The parameters of the distribution.</p>
</td></tr>
<tr><td><code id="lmomaep4_+3A_paracheck">paracheck</code></td>
<td>
<p>Should the parameters be checked for validity by the <code><a href="#topic+are.paraep4.valid">are.paraep4.valid</a></code> function.</p>
</td></tr>
<tr><td><code id="lmomaep4_+3A_t3t4only">t3t4only</code></td>
<td>
<p>Return only the <code class="reqn">\tau_3</code> and <code class="reqn">\tau_4</code> for the parameters <code class="reqn">\kappa</code> and <code class="reqn">h</code>. The <code class="reqn">\lambda_1</code> and <code class="reqn">\lambda_2</code> are not explicitly used although numerical values for these two L-moments are required only to avoid computational errors. Care is made so that the <code class="reqn">\alpha</code> parameter that is in numerator of <code class="reqn">\lambda_{2,3,4}</code> is not used in the computation of <code class="reqn">\tau_3</code> and <code class="reqn">\tau_4</code>. Hence, this option permits the computation of <code class="reqn">\tau_3</code> and <code class="reqn">\tau_4</code> when <code class="reqn">\alpha</code> is unknown. This features is largely available for research and development purposes. Mostly this feature was used for the <code class="reqn">\{\tau_3, \tau_4\}</code> trajectory for <code><a href="#topic+lmrdia">lmrdia</a></code></p>
</td></tr></table>
<p>.
</p>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> is returned.
</p>
<table>
<tr><td><code>lambdas</code></td>
<td>
<p>Vector of the L-moments. First element is
<code class="reqn">\lambda_1</code>, second element is <code class="reqn">\lambda_2</code>, and so on.</p>
</td></tr>
<tr><td><code>ratios</code></td>
<td>
<p>Vector of the L-moment ratios. Second element is
<code class="reqn">\tau</code>, third element is <code class="reqn">\tau_3</code> and so on. </p>
</td></tr>
<tr><td><code>trim</code></td>
<td>
<p>Level of symmetrical trimming used in the computation, which is <code>0</code>.</p>
</td></tr>
<tr><td><code>leftrim</code></td>
<td>
<p>Level of left-tail trimming used in the computation, which is <code>NULL</code>.</p>
</td></tr>
<tr><td><code>rightrim</code></td>
<td>
<p>Level of right-tail trimming used in the computation, which is <code>NULL</code>.</p>
</td></tr>
<tr><td><code>source</code></td>
<td>
<p>An attribute identifying the computational
source of the L-moments: &ldquo;lmomaep4&rdquo;.</p>
</td></tr>
</table>
<p>or an alternative <span class="rlang"><b>R</b></span> list is returned if <code>t3t4only=TRUE</code>
</p>
<table>
<tr><td><code>T3</code></td>
<td>
<p>L-skew, <code class="reqn">\tau_3</code>.</p>
</td></tr>
<tr><td><code>T4</code></td>
<td>
<p>L-kurtosis, <code class="reqn">\tau_4</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Asquith, W.H., 2014, Parameter estimation for the 4-parameter asymmetric exponential power distribution by the method of L-moments using R: Computational Statistics and Data Analysis, v. 71, pp. 955&ndash;970.
</p>
<p>Delicado, P., and Goria, M.N., 2008, A small sample comparison of maximum likelihood,
moments and L-moments methods for the asymmetric exponential power distribution:
Computational Statistics and Data Analysis, v. 52, no. 3, pp. 1661&ndash;1673.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+paraep4">paraep4</a></code>, <code><a href="#topic+cdfaep4">cdfaep4</a></code>, <code><a href="#topic+pdfaep4">pdfaep4</a></code>, <code><a href="#topic+quaaep4">quaaep4</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
para &lt;- vec2par(c(0, 1, 0.5, 4), type="aep4")
lmomaep4(para)

## End(Not run)
</code></pre>

<hr>
<h2 id='lmomcau'>Trimmed L-moments of the Cauchy Distribution</h2><span id='topic+lmomcau'></span>

<h3>Description</h3>

<p>This function estimates the trimmed L-moments of the Cauchy distribution given the parameters (<code class="reqn">\xi</code> and <code class="reqn">\alpha</code>) from <code><a href="#topic+parcau">parcau</a></code>. The trimmed L-moments in terms of the parameters are <code class="reqn">\lambda^{(1)}_1 = \xi</code>,
<code class="reqn">\lambda^{(1)}_2 = 0.69782723\alpha</code>, <code class="reqn">\tau^{(1)}_{3, 5, \cdots} = 0</code>, <code class="reqn">\tau^{(1)}_4 = 0.34280842</code>, and <code class="reqn">\tau^{(1)}_6 = 0.20274358</code>. These TL-moments (trim=1) are symmetrical for the first L-moments defined because <code class="reqn">\mathrm{E}[X_{1:n}]</code> and <code class="reqn">\mathrm{E}[X_{n:n}]</code> undefined expectations for the Cauchy.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lmomcau(para)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lmomcau_+3A_para">para</code></td>
<td>
<p>The parameters of the distribution.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> is returned.
</p>
<table>
<tr><td><code>lambdas</code></td>
<td>
<p>Vector of the trimmed L-moments. First element is
<code class="reqn">\lambda^{(1)}_1</code>, second element is <code class="reqn">\lambda^{(1)}_2</code>, and so on.</p>
</td></tr>
<tr><td><code>ratios</code></td>
<td>
<p>Vector of the L-moment ratios. Second element is
<code class="reqn">\tau^{(1)}</code>, third element is <code class="reqn">\tau^{(1)}_3</code> and so on. </p>
</td></tr>
<tr><td><code>trim</code></td>
<td>
<p>Level of symmetrical trimming used in the computation, which is unity.</p>
</td></tr>
<tr><td><code>leftrim</code></td>
<td>
<p>Level of left-tail trimming used in the computation, which is unity.</p>
</td></tr>
<tr><td><code>rightrim</code></td>
<td>
<p>Level of right-tail trimming used in the computation, which is unity.</p>
</td></tr>
<tr><td><code>source</code></td>
<td>
<p>An attribute identifying the computational source
of the L-moments: &ldquo;lmomcau&rdquo;.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Asquith, W.H., 2011, Distributional analysis with L-moment statistics using the R environment for statistical computing: Createspace Independent Publishing Platform, ISBN 978&ndash;146350841&ndash;8.
</p>
<p>Elamir, E.A.H., and Seheult, A.H., 2003, Trimmed L-moments: Computational Statistics and Data Analysis, v. 43, pp. 299&ndash;314.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+parcau">parcau</a></code>, <code><a href="#topic+cdfcau">cdfcau</a></code>, <code><a href="#topic+pdfcau">pdfcau</a></code>, <code><a href="#topic+quacau">quacau</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>X1 &lt;- rcauchy(20)
lmomcau( parcau( TLmoms(X1, trim=1) ) )

alpha &lt;- 30
tlmr &lt;- theoTLmoms(vec2par(c(100, alpha), type="cau"), nmom=6, trim=1)
print( c(tlmr$lambdas[2] / alpha, tlmr$ratios[c(4,6)]), 8 )
</code></pre>

<hr>
<h2 id='lmomemu'>L-moments of the Eta-Mu Distribution</h2><span id='topic+lmomemu'></span>

<h3>Description</h3>

<p>This function estimates the L-moments of the Eta-Mu (<code class="reqn">\eta:\mu</code>) distribution given the parameters (<code class="reqn">\eta</code> and <code class="reqn">\mu</code>) from <code><a href="#topic+paremu">paremu</a></code>. The L-moments in terms of the parameters are complex.  They are computed here by the <code class="reqn">\alpha_r</code> probability-weighted moments in terms of the Yacoub integral (see <code><a href="#topic+cdfemu">cdfemu</a></code>). The linear combination relating the L-moments to the conventional <code class="reqn">\beta_r</code> probability-weighted moments is
</p>
<p style="text-align: center;"><code class="reqn">
\lambda_{r+1} = \sum_{k=0}^{r} (-1)^{r-k} {r \choose k} { r + k \choose k } \beta_k\mbox{,}
</code>
</p>

<p>for <code class="reqn">r \ge 0</code> and the linear combination relating the less common <code class="reqn">\alpha_r</code> to <code class="reqn">\beta_r</code> is
</p>
<p style="text-align: center;"><code class="reqn">
\alpha_r = \sum_{k=0}^r (-1)^k { r \choose k } \beta_k\mbox{,}
</code>
</p>

<p>and by definition the <code class="reqn">\alpha_r</code> are the expectations
</p>
<p style="text-align: center;"><code class="reqn">
\alpha_r \equiv E\{ X\,[1-F(X)]^r\}\mbox{,}
</code>
</p>

<p>and thus
</p>
<p style="text-align: center;"><code class="reqn">
\alpha_r =  \int_{-\infty}^{\infty} x\, [1 - F(x)]^r f(x)\; \mathrm{d}x\mbox{,}
</code>
</p>

<p>in terms of <code class="reqn">x</code>, the PDF <code class="reqn">f(x)</code>, and the CDF <code class="reqn">F(x)</code>. Lastly, the <code class="reqn">\alpha_r</code> for the Eta-Mu distribution with substitution of the Yacoub integral are
</p>
<p style="text-align: center;"><code class="reqn">
\alpha_r = \int_{-\infty}^{\infty} Y_\mu\biggl( \eta,\; x\sqrt{2h\mu} \biggr)^r\,x\, f(x)\; \mathrm{d}x\mbox{.}
</code>
</p>

<p>Yacoub (2007, eq. 21) provides an expectation for the <code class="reqn">j</code>th moment of the distribution as given by
</p>
<p style="text-align: center;"><code class="reqn">
\mathrm{E}(x^j) = \frac{\Gamma(2\mu+j/2)}{h^{\mu+j/2}(2\mu)^{j/2}\Gamma(2\mu)}\times {}_2F_1(\mu+j/4+1/2, \mu+j/4; \mu+1/2; (H/h)^2)\mbox{,}
</code>
</p>

<p>where <code class="reqn">{}_2F_1(a,b;c;z)</code> is the Gauss hypergeometric function of Abramowitz and Stegun (1972, eq. 15.1.1) and <code class="reqn">h = 1/(1-\eta^2)</code> (format 2 of Yacoub's paper and the format exclusively used by <span class="pkg">lmomco</span>). The <code>lmomemu</code> function optionally solves for the mean (<code class="reqn">j=1</code>) using the above equation in conjunction with the mean as computed by the order statistic minimums. The <code class="reqn">{}_2F_1(a,b;c;z)</code> is defined as
</p>
<p style="text-align: center;"><code class="reqn">
{}_2F_1(a,b;c;z) = \frac{\Gamma(c)}{\Gamma(a)\Gamma{(b)}} \sum_{i=0}^\infty \frac{\Gamma(a+i)\Gamma{(b+i)}}{\Gamma{(c+i)}}\frac{z^i}{n!}\mbox{.}
</code>
</p>

<p>Yacoub (2007, eq. 21) is used to compute the mean.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lmomemu(para, nmom=5, paracheck=TRUE, tol=1E-6, maxn=100)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lmomemu_+3A_para">para</code></td>
<td>
<p>The parameters of the distribution.</p>
</td></tr>
<tr><td><code id="lmomemu_+3A_nmom">nmom</code></td>
<td>
<p>The number of L-moments to compute.</p>
</td></tr>
<tr><td><code id="lmomemu_+3A_paracheck">paracheck</code></td>
<td>
<p>A logical controlling whether the parameters and checked for validity.</p>
</td></tr>
<tr><td><code id="lmomemu_+3A_tol">tol</code></td>
<td>
<p>An absolute tolerance term for series convergence of the Gauss hypergeometric function when the Yacoub (2007) mean is to be computed.</p>
</td></tr>
<tr><td><code id="lmomemu_+3A_maxn">maxn</code></td>
<td>
<p>The maximum number of interations in the series of the Gauss hypergeometric function when the Yacoub (2007) mean is to be computed.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> is returned.
</p>
<table>
<tr><td><code>lambdas</code></td>
<td>
<p>Vector of the L-moments. First element is
<code class="reqn">\lambda_1</code>, second element is <code class="reqn">\lambda_2</code>, and so on.</p>
</td></tr>
<tr><td><code>ratios</code></td>
<td>
<p>Vector of the L-moment ratios. Second element is
<code class="reqn">\tau</code>, third element is <code class="reqn">\tau_3</code> and so on.</p>
</td></tr>
<tr><td><code>trim</code></td>
<td>
<p>Level of symmetrical trimming used in the computation, which is <code>0</code>.</p>
</td></tr>
<tr><td><code>leftrim</code></td>
<td>
<p>Level of left-tail trimming used in the computation, which is <code>NULL</code>.</p>
</td></tr>
<tr><td><code>rightrim</code></td>
<td>
<p>Level of right-tail trimming used in the computation, which is <code>NULL</code>.</p>
</td></tr>
<tr><td><code>source</code></td>
<td>
<p>An attribute identifying the computational
source of the L-moments: &ldquo;lmomemu&rdquo;.</p>
</td></tr>
<tr><td><code>yacoubsmean</code></td>
<td>
<p>A list containing the mean, convergence error, and number of iterations in the series until convergence.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Asquith, W.H., 2011, Distributional analysis with L-moment statistics using the R environment for statistical computing: Createspace Independent Publishing Platform, ISBN 978&ndash;146350841&ndash;8.
</p>
<p>Yacoub, M.D., 2007, The kappa-mu distribution and the eta-mu distribution: IEEE Antennas and Propagation Magazine, v. 49, no. 1, pp. 68&ndash;81
</p>


<h3>See Also</h3>

<p><code><a href="#topic+paremu">paremu</a></code>, <code><a href="#topic+cdfemu">cdfemu</a></code>, <code><a href="#topic+pdfemu">pdfemu</a></code>, <code><a href="#topic+quaemu">quaemu</a></code>  </p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
emu &lt;- vec2par(c(.19,2.3), type="emu")
lmomemu(emu)

par &lt;- vec2par(c(.67, .5), type="emu")
lmomemu(par)$lambdas
cdf2lmoms(par, nmom=4)$lambdas
system.time(lmomemu(par))
system.time(cdf2lmoms(par, nmom=4))

# This extensive sequence of operations provides very important
# perspective on the L-moment ratio diagram of L-skew and L-kurtosis.
# But more importantly this example demonstrates the L-moment
# domain of the Kappa-Mu and Eta-Mu distributions and their boundaries.
#
t3 &lt;- seq(-1,1,by=.0001)
plotlmrdia(lmrdia(), xlim=c(-0.05,0.5), ylim=c(-0.05,.2))
# The following polynomials are used to define the boundaries of
# both distributions. The applicable inequalities for these
# are not provided for these polynomials as would be in deeper
# implementation---so don't worry about wild looking trajectories.
"KMUup" &lt;- function(t3) {
             return(0.1227 - 0.004433*t3 - 2.845*t3^2 +
                    + 18.41*t3^3 - 50.08*t3^4 + 83.14*t3^5 +
                    - 81.38*t3^6 + 43.24*t3^7 - 9.600*t3^8)}

"KMUdnA" &lt;- function(t3) {
              return(0.1226 - 0.3206*t3 - 102.4*t3^2 - 4.753E4*t3^3 +
                     - 7.605E6*t3^4 - 5.244E8*t3^5 - 1.336E10*t3^6)}

"KMUdnB" &lt;- function(t3) {
              return(0.09328 - 1.488*t3 + 16.29*t3^2 - 205.4*t3^3 +
                     + 1545*t3^4 - 5595*t3^5 + 7726*t3^6)}

"KMUdnC" &lt;- function(t3) {
              return(0.07245 - 0.8631*t3 + 2.031*t3^2 - 0.01952*t3^3 +
                     - 0.7532*t3^4 + 0.7093*t3^5 - 0.2156*t3^6)}

"EMUup" &lt;- function(t3) {
              return(0.1229 - 0.03548*t3 - 0.1835*t3^2 + 2.524*t3^3 +
                     - 2.954*t3^4 + 2.001*t3^5 - 0.4746*t3^6)}

# Here, we are drawing the trajectories of the tabulated parameters
# and L-moments within the internal storage of lmomco.
lines(.lmomcohash$EMU_lmompara_byeta$T3,
      .lmomcohash$EMU_lmompara_byeta$T4,   col=7, lwd=0.5)
lines(.lmomcohash$KMU_lmompara_bykappa$T3,
      .lmomcohash$KMU_lmompara_bykappa$T4, col=8, lwd=0.5)

# Draw the polynomials
lines(t3, KMUdnA(t3), lwd=4, col=2, lty=4)
lines(t3, KMUdnB(t3), lwd=4, col=3, lty=4)
lines(t3, KMUdnC(t3), lwd=4, col=4, lty=4)
lines(t3, EMUup(t3),  lwd=4, col=5, lty=4)
lines(t3, KMUup(t3),  lwd=4, col=6, lty=4)

## End(Not run)
</code></pre>

<hr>
<h2 id='lmomexp'>L-moments of the Exponential Distribution</h2><span id='topic+lmomexp'></span>

<h3>Description</h3>

<p>This function estimates the L-moments of the Exponential distribution given the parameters (<code class="reqn">\xi</code> and <code class="reqn">\alpha</code>) from <code><a href="#topic+parexp">parexp</a></code>. The L-moments in terms of the parameters are <code class="reqn">\lambda_1 = \xi + \alpha</code>, <code class="reqn">\lambda_2 = \alpha/2</code>, <code class="reqn">\tau_3 = 1/3</code>, <code class="reqn">\tau_4 = 1/6</code>, and <code class="reqn">\tau_5 = 1/10</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lmomexp(para)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lmomexp_+3A_para">para</code></td>
<td>
<p>The parameters of the distribution.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> is returned.
</p>
<table>
<tr><td><code>lambdas</code></td>
<td>
<p>Vector of the L-moments. First element is
<code class="reqn">\lambda_1</code>, second element is <code class="reqn">\lambda_2</code>, and so on.</p>
</td></tr>
<tr><td><code>ratios</code></td>
<td>
<p>Vector of the L-moment ratios. Second element is
<code class="reqn">\tau</code>, third element is <code class="reqn">\tau_3</code> and so on.</p>
</td></tr>
<tr><td><code>trim</code></td>
<td>
<p>Level of symmetrical trimming used in the computation, which is <code>0</code>.</p>
</td></tr>
<tr><td><code>leftrim</code></td>
<td>
<p>Level of left-tail trimming used in the computation, which is <code>NULL</code>.</p>
</td></tr>
<tr><td><code>rightrim</code></td>
<td>
<p>Level of right-tail trimming used in the computation, which is <code>NULL</code>.</p>
</td></tr>
<tr><td><code>source</code></td>
<td>
<p>An attribute identifying the computational
source of the L-moments: &ldquo;lmomexp&rdquo;.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Asquith, W.H., 2011, Distributional analysis with L-moment statistics using the R environment for statistical computing: Createspace Independent Publishing Platform, ISBN 978&ndash;146350841&ndash;8.
</p>
<p>Hosking, J.R.M., 1990, L-moments&mdash;Analysis and estimation of distributions using linear combinations of order statistics: Journal of the Royal Statistical Society, Series B, v. 52, pp. 105&ndash;124.
</p>
<p>Hosking, J.R.M., 1996, FORTRAN routines for use with the method of L-moments: Version 3, IBM Research Report RC20525, T.J. Watson Research Center, Yorktown Heights, New York.
</p>
<p>Hosking, J.R.M., and Wallis, J.R., 1997, Regional frequency analysis&mdash;An approach based on L-moments: Cambridge University Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+parexp">parexp</a></code>, <code><a href="#topic+cdfexp">cdfexp</a></code>, <code><a href="#topic+pdfexp">pdfexp</a></code>, <code><a href="#topic+quaexp">quaexp</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>lmr &lt;- lmoms(c(123,34,4,654,37,78))
lmr
lmomexp(parexp(lmr))
</code></pre>

<hr>
<h2 id='lmomgam'>L-moments of the Gamma Distribution</h2><span id='topic+lmomgam'></span>

<h3>Description</h3>

<p>This function estimates the L-moments of the Gamma distribution given the parameters (<code class="reqn">\alpha</code> and <code class="reqn">\beta</code>) from <code><a href="#topic+pargam">pargam</a></code>. The L-moments in terms of the parameters are complicated and solved numerically. This function is adaptive to the 2-parameter and 3-parameter Gamma versions supported by this package.  For legacy reasons, <span class="pkg">lmomco</span> continues to use a port of Hosking's FORTRAN into R if the 2-parameter distribution is used but the 3-parameter generalized Gamma distribution calls upon <code><a href="#topic+theoLmoms.max.ostat">theoLmoms.max.ostat</a></code>. Alternatively, the <code><a href="#topic+theoTLmoms">theoTLmoms</a></code> could be used: <code>theoTLmoms(para)</code> is conceptually equivalent to the internal calls to <code><a href="#topic+theoLmoms.max.ostat">theoLmoms.max.ostat</a></code> made for the <code>lmomgam</code> implementation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lmomgam(para, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lmomgam_+3A_para">para</code></td>
<td>
<p>The parameters of the distribution.</p>
</td></tr>
<tr><td><code id="lmomgam_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass to <code><a href="#topic+theoLmoms.max.ostat">theoLmoms.max.ostat</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> is returned.
</p>
<table>
<tr><td><code>lambdas</code></td>
<td>
<p>Vector of the L-moments. First element is
<code class="reqn">\lambda_1</code>, second element is <code class="reqn">\lambda_2</code>, and so on.</p>
</td></tr>
<tr><td><code>ratios</code></td>
<td>
<p>Vector of the L-moment ratios. Second element is
<code class="reqn">\tau</code>, third element is <code class="reqn">\tau_3</code> and so on.</p>
</td></tr>
<tr><td><code>trim</code></td>
<td>
<p>Level of symmetrical trimming used in the computation, which is <code>0</code>.</p>
</td></tr>
<tr><td><code>leftrim</code></td>
<td>
<p>Level of left-tail trimming used in the computation, which is <code>NULL</code>.</p>
</td></tr>
<tr><td><code>rightrim</code></td>
<td>
<p>Level of right-tail trimming used in the computation, which is <code>NULL</code>.</p>
</td></tr>
<tr><td><code>source</code></td>
<td>
<p>An attribute identifying the computational
source of the L-moments: &ldquo;lmomgam&rdquo;.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Hosking, J.R.M., 1990, L-moments&mdash;Analysis and estimation of distributions using linear combinations of order statistics: Journal of the Royal Statistical Society, Series B, v. 52, p. 105&ndash;124.
</p>
<p>Hosking, J.R.M., 1996, FORTRAN routines for use with the method of L-moments: Version 3, IBM Research Report RC20525, T.J. Watson Research Center,
Yorktown Heights, New York.
</p>
<p>Hosking, J.R.M., and Wallis, J.R., 1997, Regional frequency analysis&mdash;An approach based on L-moments: Cambridge University Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pargam">pargam</a></code>, <code><a href="#topic+cdfgam">cdfgam</a></code>, <code><a href="#topic+pdfgam">pdfgam</a></code>, <code><a href="#topic+quagam">quagam</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>lmomgam(pargam(lmoms(c(123,34,4,654,37,78))))

## Not run: 
# 3-p Generalized Gamma Distribution and comparisons of 3-p Gam parameterization.
#     1st parameter A[lmomco] = A[gamlss] =  exp(A[flexsurv])
#     2nd parameter B[lmomco] = B[gamlss] =      B[flexsurv]
#     3rd parameter C[lmomco] = C[gamlss] --&gt;    C[flexsurv] = B[lmomco]/C[lmomco]
lmomgam(vec2par(c(7.4, 0.2, 14), type="gam"), nmom=5)$lambdas      # numerics
lmoms(gamlss.dist::rGG(50000, mu=7.4, sigma=0.2, nu=14))$lambdas   # simulation
lmoms(flexsurv::rgengamma(50000, log(7.4), 0.2, Q=0.2*14))$lambdas # simulation
#[1]  5.364557537  1.207492689 -0.110129217  0.067007941 -0.006747895
#[1]  5.366707749  1.209455502 -0.108354729  0.066360223 -0.006716783
#[1]  5.356166684  1.197942329 -0.106745364  0.069102821 -0.008293398#
## End(Not run)
</code></pre>

<hr>
<h2 id='lmomgep'>L-moments of the Generalized Exponential Poisson Distribution</h2><span id='topic+lmomgep'></span>

<h3>Description</h3>

<p>This function estimates the L-moments of the Generalized Exponential Poisson (GEP) distribution given the parameters (<code class="reqn">\beta</code>, <code class="reqn">\kappa</code>, and <code class="reqn">h</code>) from <code><a href="#topic+pargep">pargep</a></code>. The L-moments in terms of the parameters are best expressed in terms of the expectations of order statistic maxima <code class="reqn">\mathrm{E}[X_{n:n}]</code> for the distribution. The fundamental relation is
</p>
<p style="text-align: center;"><code class="reqn">\lambda_r = \sum_{k=1}^r (-1)^{r-k}k^{-1}{r-1 \choose k-1}{r+k-2 \choose k-1}\mathrm{E}[X_{k:k}]\mbox{.}</code>
</p>

<p>The L-moments do not seem to have been studied for the GEP. The challenge is the solution to <code class="reqn">\mathrm{E}[X_{n:n}]</code> through an expression by Barreto-Souza and Cribari-Neto (2009) that is
</p>
<p style="text-align: center;"><code class="reqn">\mathrm{E}[X_{n:n}] = \frac{\beta\,h\,\Gamma(\kappa+1)\,\Gamma(n\kappa + 1)}{n\,\Gamma(n)\,(1 - \exp(-h))^{n\kappa}}\sum_{j=0}^{\infty} \frac{(-1)^j\exp(-h(j+1))}{\Gamma(n\kappa - j)\,\Gamma(j+1)}\;F^{12}_{22}(h(j+1))\mbox{,}</code>
</p>

<p>where <code class="reqn">F^{12}_{22}(h(j+1))</code> is the Barnes Extended Hypergeometric function with arguments reflecting those needed for the GEP (see comments under <code><a href="#topic+BEhypergeo">BEhypergeo</a></code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lmomgep(para, byqua=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lmomgep_+3A_para">para</code></td>
<td>
<p>The parameters of the distribution.</p>
</td></tr>
<tr><td><code id="lmomgep_+3A_byqua">byqua</code></td>
<td>
<p>A logical triggering the <code><a href="#topic+theoLmoms.max.ostat">theoLmoms.max.ostat</a></code> instead of using the mathematics of Barreto-Souza and Cribari-Neto (2009) (see Details).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The mathematics (not of L-moments but <code class="reqn">\mathrm{E}[X_{n:n}]</code>) shown by Barreto-Souza and Cribari-Neto (2009) are correct but are apparently subject to considerable numerical issues even with substantial use of logarithms and exponentiation in favor of multiplication and division in the above formula for <code class="reqn">\mathrm{E}[X_{n:n}]</code>. Testing indicates that numerical performance is better if the non-<code class="reqn">j</code>-dependent terms in the infinite sum remain <em>inside</em> it.  Testing also indicates that the edges of performance can be readily hit with large <code class="reqn">\kappa</code> and less so with large <code class="reqn">h</code>. It actually seems superior to not use the above equation for L-moment computation based on <code class="reqn">\mathrm{E}[X_{n:n}]</code> but instead rely on expectations of maxima order statistics (<code><a href="#topic+expect.max.ostat">expect.max.ostat</a></code>) from numerical integration of the quantile function (<code><a href="#topic+quagep">quagep</a></code>) as is implementated in <code><a href="#topic+theoLmoms.max.ostat">theoLmoms.max.ostat</a></code>. This is the reason that the <code>byqua</code> argument is available and set to the shown default. Because the GEP is experimental, this function provides two approaches for <code class="reqn">\lambda_r</code> computation for research purposes.
</p>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> is returned.
</p>
<table>
<tr><td><code>lambdas</code></td>
<td>
<p>Vector of the L-moments. First element is
<code class="reqn">\lambda_1</code>, second element is <code class="reqn">\lambda_2</code>, and so on.</p>
</td></tr>
<tr><td><code>ratios</code></td>
<td>
<p>Vector of the L-moment ratios. Second element is
<code class="reqn">\tau</code>, third element is <code class="reqn">\tau_3</code> and so on.</p>
</td></tr>
<tr><td><code>trim</code></td>
<td>
<p>Level of symmetrical trimming used in the computation, which is <code>0</code>.</p>
</td></tr>
<tr><td><code>leftrim</code></td>
<td>
<p>Level of left-tail trimming used in the computation, which is <code>NULL</code>.</p>
</td></tr>
<tr><td><code>rightrim</code></td>
<td>
<p>Level of right-tail trimming used in the computation, which is <code>NULL</code>.</p>
</td></tr>
<tr><td><code>source</code></td>
<td>
<p>An attribute identifying the computational
source of the L-moments: &ldquo;lmomgep&rdquo;.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Barreto-Souza, W., and Cribari-Neto, F., 2009, A generalization of the exponential-Poisson distribution: Statistics and Probability, 79, pp. 2493&ndash;2500.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pargep">pargep</a></code>, <code><a href="#topic+cdfgep">cdfgep</a></code>, <code><a href="#topic+pdfgep">pdfgep</a></code>, <code><a href="#topic+quagep">quagep</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
gep &lt;- vec2par(c(2, 1.5, 3), type="gep")
lmrA &lt;- lmomgep(gep, byqua=TRUE);   print(lmrA)
lmrB &lt;- lmomgep(gep, byqua=FALSE);  print(lmrB)

# Because the L-moments of the Generalized Exponential Poisson are computed
# strictly from the expectations of the order statistic extrema, lets us evaluate
# by theoretical integration of the quantile function and simulation:
set.seed(10); gep &lt;- vec2par(c(2, 1.5, 3), type="gep")
lmr  &lt;- lmomgep(gep, byqua=FALSE)
E33a &lt;- (lmr$lambdas[3] + 3*lmr$lambdas[2] + 2*lmr$lambdas[1])/2  # 2.130797
E33b &lt;- expect.max.ostat(3, para=gep, qua=quagep)                 # 2.137250
E33c &lt;- mean(replicate(20000, max(quagep(runif(3), gep))))        # 2.140226
# See how the E[X_{3:3}] by the formula shown in this documentation results in
# a value that is about 0.007 too small. Now this might now seem large but it
# is a difference.  Try gep &lt;- list(para=c(2, 1.5, 13), type="gep") or
#  gep &lt;- list(para=c(2, .08, 21), type="gep"), which fails on byqua=TRUE
## End(Not run)
</code></pre>

<hr>
<h2 id='lmomgev'>L-moments of the Generalized Extreme Value Distribution</h2><span id='topic+lmomgev'></span>

<h3>Description</h3>

<p>This function estimates the L-moments of the Generalized Extreme Value distribution given the parameters
(<code class="reqn">\xi</code>, <code class="reqn">\alpha</code>, and <code class="reqn">\kappa</code>) from <code><a href="#topic+pargev">pargev</a></code>. The L-moments in terms of the parameters are
</p>
<p style="text-align: center;"><code class="reqn">\lambda_1 = \xi + \frac{\alpha}{\kappa}(1-\Gamma(1+\kappa)) \mbox{,}</code>
</p>

<p style="text-align: center;"><code class="reqn">\lambda_2 = \frac{\alpha}{\kappa}(1-2^{-\kappa})\Gamma(1+\kappa) \mbox{,}</code>
</p>

<p style="text-align: center;"><code class="reqn">\tau_3 = \frac{2(1-3^{-\kappa})}{1-2^{-\kappa}} - 3 \mbox{, and}</code>
</p>

<p style="text-align: center;"><code class="reqn">\tau_4 = \frac{5(1-4^{-\kappa})-10(1-3^{-\kappa})+6(1-2^{-\kappa})}{1-2^{-\kappa}} \mbox{.}</code>
</p>



<h3>Usage</h3>

<pre><code class='language-R'>lmomgev(para)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lmomgev_+3A_para">para</code></td>
<td>
<p>The parameters of the distribution.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> is returned.
</p>
<table>
<tr><td><code>lambdas</code></td>
<td>
<p>Vector of the L-moments. First element is
<code class="reqn">\lambda_1</code>, second element is <code class="reqn">\lambda_2</code>, and so on.</p>
</td></tr>
<tr><td><code>ratios</code></td>
<td>
<p>Vector of the L-moment ratios. Second element is
<code class="reqn">\tau</code>, third element is <code class="reqn">\tau_3</code> and so on.</p>
</td></tr>
<tr><td><code>trim</code></td>
<td>
<p>Level of symmetrical trimming used in the computation, which is <code>0</code>.</p>
</td></tr>
<tr><td><code>leftrim</code></td>
<td>
<p>Level of left-tail trimming used in the computation, which is <code>NULL</code>.</p>
</td></tr>
<tr><td><code>rightrim</code></td>
<td>
<p>Level of right-tail trimming used in the computation, which is <code>NULL</code>.</p>
</td></tr>
<tr><td><code>source</code></td>
<td>
<p>An attribute identifying the computational
source of the L-moments: &ldquo;lmomgev&rdquo;.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Hosking, J.R.M., 1990, L-moments&mdash;Analysis and estimation of distributions using linear combinations of order statistics: Journal of the Royal Statistical Society, Series B, v. 52, pp. 105&ndash;124.
</p>
<p>Hosking, J.R.M., 1996, FORTRAN routines for use with the method of L-moments: Version 3, IBM Research Report RC20525, T.J. Watson Research Center, Yorktown Heights, New York.
</p>
<p>Hosking, J.R.M., and Wallis, J.R., 1997, Regional frequency analysis&mdash;An approach based on L-moments: Cambridge University Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pargev">pargev</a></code>, <code><a href="#topic+cdfgev">cdfgev</a></code>, <code><a href="#topic+pdfgev">pdfgev</a></code>, <code><a href="#topic+quagev">quagev</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>lmr &lt;- lmoms(c(123,34,4,654,37,78))
lmomgev(pargev(lmr))

## Not run: 
# The Gumbel is a limiting version of the maxima regardless of parent. The GLO,
# PE3 (twice), and GPA are studied here. A giant number of events to simulate is made.
# Then numbers of events per year before the annual maxima are computed are specified.
# The Gumbel is a limiting version of the maxima regardless of parent. The GLO,
# PE3 (twice), and GPA are studied here. A giant number of events to simulate is made.
# Then numbers of events per year before the annual maxima are computed are specified.
nevents &lt;- 100000
nev_yr &lt;- c(1,2,3,4,5,6,10,15,20,30,50,100,200,500); n &lt;- length(nev_yr)
pdf("Gumbel_in_the_limit.pdf", useDingbats=FALSE)
# Draw the usually L-moment ratio diagram but only show a few of the
# three parameter families.
plotlmrdia(lmrdia(), xlim=c(-.5,0.5), ylim=c(0,0.3), nopoints=TRUE,
           autolegend=TRUE, noaep4=TRUE, nogov=TRUE, xleg=0.1, yleg=0.3)
gum &lt;- lmrdia()$gum # extract the L-skew and L-kurtosis of the Gumbel
points(gum[1], gum[2], pch=10, cex=3, col=2) # draw the Gumbel

para &lt;- parglo(vec2lmom(c(1,.1,0))) # generalized logistic
t3 &lt;- t4 &lt;- rep(NA, n) # define
for(k in 1:n) { # generate GLO time series of annual maxima with k-events per year
   lmr &lt;- lmoms(sapply(1:nevents/nev_yr[k], function(i) max(rlmomco(nev_yr[k], para))))
   t3[k] &lt;- lmr$ratios[3]; t4[k] &lt;- lmr$ratios[4]
}
lines(t3, t4, lwd=0.8); points(t3, t4, lwd=0.8, pch=21, bg=3)

para &lt;- parglo(vec2lmom(c(1,.1,0.3))) # generalized logistic
t3 &lt;- t4 &lt;- rep(NA, n) # define
for(k in 1:n) { # generate GLO time series of annual maxima with k-events per year
   lmr &lt;- lmoms(sapply(1:nevents/nev_yr[k], function(i) max(rlmomco(nev_yr[k], para))))
   t3[k] &lt;- lmr$ratios[3]; t4[k] &lt;- lmr$ratios[4]
}
lines(t3, t4, lwd=0.8); points(t3, t4, lwd=0.8, pch=21, bg=3)

para &lt;- parglo(vec2lmom(c(1,.1,-0.3))) # generalized logistic
t3 &lt;- t4 &lt;- rep(NA, n) # define
for(k in 1:n) { # generate GLO time series of annual maxima with k-events per year
   lmr &lt;- lmoms(sapply(1:nevents/nev_yr[k], function(i) max(rlmomco(nev_yr[k], para))))
   t3[k] &lt;- lmr$ratios[3]; t4[k] &lt;- lmr$ratios[4]
}
lines(t3, t4, lwd=0.8); points(t3, t4, lwd=0.8, pch=21, bg=3)

para &lt;- parpe3(vec2lmom(c(1,.1,.4))) # Pearson type III
t3 &lt;- t4 &lt;- rep(NA, n) # reset
for(k in 1:n) { # generate PE3 time series of annual maxima with k-events per year
   lmr &lt;- lmoms(sapply(1:nevents/k, function(i) max(rlmomco(nev_yr[k], para))))
   t3[k] &lt;- lmr$ratios[3]; t4[k] &lt;- lmr$ratios[4]
}
lines(t3, t4, lwd=0.8); points(t3, t4, lwd=0.8, pch=21, bg=6)

para &lt;- parpe3(vec2lmom(c(1,.1,0))) # Pearson type III
t3 &lt;- t4 &lt;- rep(NA, n) # reset
for(k in 1:n) { # generate another PE3 time series of annual maxima with k-events per year
   lmr &lt;- lmoms(sapply(1:nevents/k, function(i) max(rlmomco(nev_yr[k], para))))
   t3[k] &lt;- lmr$ratios[3]; t4[k] &lt;- lmr$ratios[4]
}
lines(t3, t4, lwd=0.8); points(t3, t4, lwd=0.8, pch=21, bg=6)

para &lt;- parpe3(vec2lmom(c(1,.1,-.4))) # Pearson type III
t3 &lt;- t4 &lt;- rep(NA, n) # reset
for(k in 1:n) { # generate PE3 time series of annual maxima with k-events per year
   lmr &lt;- lmoms(sapply(1:nevents/k, function(i) max(rlmomco(nev_yr[k], para))))
   t3[k] &lt;- lmr$ratios[3]; t4[k] &lt;- lmr$ratios[4]
}
lines(t3, t4, lwd=0.8); points(t3, t4, lwd=0.8, pch=21, bg=6)

para &lt;- pargpa(vec2lmom(c(1,.1,0))) # generalized Pareto
t3 &lt;- t4 &lt;- rep(NA, n) # reset
for(k in 1:n) { # generate GPA time series of annual maxima with k-events per year
   lmr &lt;- lmoms(sapply(1:nevents/k, function(i) max(rlmomco(nev_yr[k], para))))
   t3[k] &lt;- lmr$ratios[3]; t4[k] &lt;- lmr$ratios[4]
}
lines(t3, t4, lwd=0.8); points(t3, t4, lwd=0.8, pch=21, bg=4)

para &lt;- pargpa(vec2lmom(c(1,.1,.4))) # generalized Pareto
t3 &lt;- t4 &lt;- rep(NA, n) # reset
for(k in 1:n) { # generate GPA time series of annual maxima with k-events per year
   lmr &lt;- lmoms(sapply(1:nevents/k, function(i) max(rlmomco(nev_yr[k], para))))
   t3[k] &lt;- lmr$ratios[3]; t4[k] &lt;- lmr$ratios[4]
}
lines(t3, t4, lwd=0.8); points(t3, t4, lwd=0.8, pch=21, bg=4)

para &lt;- pargpa(vec2lmom(c(1,.1,-.4))) # generalized Pareto
t3 &lt;- t4 &lt;- rep(NA, n) # reset
for(k in 1:n) { # generate GPA time series of annual maxima with k-events per year
   lmr &lt;- lmoms(sapply(1:nevents/k, function(i) max(rlmomco(nev_yr[k], para))))
   t3[k] &lt;- lmr$ratios[3]; t4[k] &lt;- lmr$ratios[4]
}
lines(t3, t4, lwd=0.8); points(t3, t4, lwd=0.8, pch=21, bg=4)
dev.off() #
## End(Not run)
</code></pre>

<hr>
<h2 id='lmomgld'>L-moments of the Generalized Lambda Distribution</h2><span id='topic+lmomgld'></span>

<h3>Description</h3>

<p>This function estimates the L-moments of the Generalized Lambda distribution given the parameters (<code class="reqn">\xi</code>, <code class="reqn">\alpha</code>, <code class="reqn">\kappa</code>, and <code class="reqn">h</code>)  from <code><a href="#topic+vec2par">vec2par</a></code>. The L-moments in terms of the parameters are complicated; however, there are analytical solutions. There are no simple expressions of the parameters in terms of the L-moments. The first L-moment or the mean is
</p>
<p style="text-align: center;"><code class="reqn">\lambda_1 = \xi + \alpha
                              \left(\frac{1}{\kappa+1} -
			            \frac{1}{h+1} \right) \mbox{.}</code>
</p>

<p>The second L-moment or L-scale in terms of the parameters and the mean is
</p>
<p style="text-align: center;"><code class="reqn">\lambda_2 = \xi + \frac{2\alpha}{(\kappa+2)} -
                      2\alpha
                      \left( \frac{1}{h+1} -
		             \frac{1}{h+2} \right) - \xi \mbox{.}</code>
</p>

<p>The third L-moment in terms of the parameters, the mean, and L-scale is
</p>
<p style="text-align: center;"><code class="reqn">Y = 2\xi + \frac{6\alpha}{(\kappa+3)} -
                                         3(\alpha+\xi) + \xi \mbox{, and}</code>
</p>

<p style="text-align: center;"><code class="reqn">\lambda_3 = Y + 6\alpha
                      \left(\frac{2}{h+2} -
		            \frac{1}{h+3} -
			    \frac{1}{h+1}\right) \mbox{.}</code>
</p>

<p>The fourth L-moment in termes of the parameters and the first three L-moments is
</p>
<p style="text-align: center;"><code class="reqn">Y = \frac{-3}{h+4}\left(\frac{2}{h+2} -
                                \frac{1}{h+3} -
				\frac{1}{h+1}\right) \mbox{,}</code>
</p>

<p style="text-align: center;"><code class="reqn">Z = \frac{20\xi}{4} + \frac{20\alpha}{(\kappa+4)} -
                                              20 Y\alpha \mbox{, and}</code>
</p>

<p style="text-align: center;"><code class="reqn">\lambda_4 = Z -
                         5(\kappa + 3(\alpha+\xi) - \xi) +
                                6(\alpha + \xi) - \xi \mbox{.}</code>
</p>

<p>It is conventional to express L-moments in terms of only the parameters and not the other L-moments. Lengthy algebra and further manipulation yields such a system of equations. The L-moments are
</p>
<p style="text-align: center;"><code class="reqn">\lambda_1 = \xi + \alpha
                              \left(\frac{1}{\kappa+1} -
			            \frac{1}{h+1} \right) \mbox{,}</code>
</p>

<p style="text-align: center;"><code class="reqn">\lambda_2 = \alpha \left(\frac{\kappa}{(\kappa+2)(\kappa+1)} +
                                           \frac{h}{(h+2)(h+1)}\right) \mbox{,}</code>
</p>

<p style="text-align: center;"><code class="reqn">\lambda_3 =  \alpha \left(\frac{\kappa (\kappa - 1)}
                                                {(\kappa+3)(\kappa+2)(\kappa+1)} -
					   \frac{h (h - 1)}
					        {(h+3)(h+2)(h+1)} \right) \mbox{, and}</code>
</p>

<p style="text-align: center;"><code class="reqn">\lambda_4 = \alpha \left(\frac{\kappa (\kappa - 2)(\kappa - 1)}
                                                {(\kappa+4)(\kappa+3)(\kappa+2)(\kappa+1)} +
					   \frac{h (h - 2)(h - 1)}
					        {(h+4)(h+3)(h+2)(h+1)} \right) \mbox{.}</code>
</p>

<p>The L-moment ratios are
</p>
<p style="text-align: center;"><code class="reqn">\tau_3 = \frac{\kappa(\kappa-1)(h+3)(h+2)(h+1) -
                     h(h-1)(\kappa+3)(\kappa+2)(\kappa+1)}
		    {(\kappa+3)(h+3) \times [\kappa(h+2)(h+1) +
		                                h(\kappa+2)(\kappa+1)]
		    }
		    \mbox{, and}</code>
</p>

<p style="text-align: center;"><code class="reqn">\tau_4 = \frac{\kappa(\kappa-2)(\kappa-1)(h+4)(h+3)(h+2)(h+1) +
                     h(h-2)(h-1)(\kappa+4)(\kappa+3)(\kappa+2)(\kappa+1)}
		    {(\kappa+4)(h+4)(\kappa+3)(h+3) \times [\kappa(h+2)(h+1) +
		                                h(\kappa+2)(\kappa+1)]
		    }
		    \mbox{.}</code>
</p>

<p>The pattern being established through symmetry, even higher L-moment ratios are readily obtained. Note the alternating substraction and addition of the two terms in the numerator of the L-moment ratios (<code class="reqn">\tau_r</code>). For odd <code class="reqn">r \ge 3</code> substraction is seen and for even <code class="reqn">r \ge 3</code> addition is seen. For example, the fifth L-moment ratio is
</p>
<p style="text-align: center;"><code class="reqn">N1 = \kappa(\kappa-3)(\kappa-2)(\kappa-1)(h+5)(h+4)(h+3)(h+2)(h+1) \mbox{,}</code>
</p>

<p style="text-align: center;"><code class="reqn">N2 = h(h-3)(h-2)(h-1)(\kappa+5)(\kappa+4)(\kappa+3)(\kappa+2)(\kappa+1) \mbox{,}</code>
</p>

<p style="text-align: center;"><code class="reqn">D1 = (\kappa+5)(h+5)(\kappa+4)(h+4)(\kappa+3)(h+3) \mbox{,}</code>
</p>

<p style="text-align: center;"><code class="reqn">D2 = [\kappa(h+2)(h+1) + h(\kappa+2)(\kappa+1)] \mbox{, and}</code>
</p>

<p style="text-align: center;"><code class="reqn">\tau_5 = \frac{N1 - N2}{D1 \times D2} \mbox{.}</code>
</p>

<p>By inspection the <code class="reqn">\tau_r</code> equations are not applicable for negative integer values <code class="reqn">k=\{-1, -2, -3, -4, \dots \}</code> and <code class="reqn">h=\{-1, -2, -3, -4, \dots \}</code> as division by zero will result. There are additional, but difficult to formulate, restrictions on the parameters both to define a valid Generalized Lambda distribution as well as valid L-moments. Verification of the parameters is conducted through <code><a href="#topic+are.pargld.valid">are.pargld.valid</a></code>, and verification of the L-moment validity is conducted through <code><a href="#topic+are.lmom.valid">are.lmom.valid</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lmomgld(para)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lmomgld_+3A_para">para</code></td>
<td>
<p>The parameters of the distribution.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> list is returned.
</p>
<table>
<tr><td><code>lambdas</code></td>
<td>
<p>Vector of the L-moments. First element is
<code class="reqn">\lambda_1</code>, second element is <code class="reqn">\lambda_2</code>, and so on.</p>
</td></tr>
<tr><td><code>ratios</code></td>
<td>
<p>Vector of the L-moment ratios. Second element is
<code class="reqn">\tau</code>, third element is <code class="reqn">\tau_3</code> and so on.</p>
</td></tr>
<tr><td><code>trim</code></td>
<td>
<p>Level of symmetrical trimming used in the computation, which is <code>0</code>.</p>
</td></tr>
<tr><td><code>leftrim</code></td>
<td>
<p>Level of left-tail trimming used in the computation, which is <code>NULL</code>.</p>
</td></tr>
<tr><td><code>rightrim</code></td>
<td>
<p>Level of right-tail trimming used in the computation, which is <code>NULL</code>.</p>
</td></tr>
<tr><td><code>source</code></td>
<td>
<p>An attribute identifying the computational source
of the L-moments: &ldquo;lmomgld&rdquo;.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>Source</h3>

<p>Derivations conducted by W.H. Asquith on February 11 and 12, 2006.
</p>


<h3>References</h3>

<p>Asquith, W.H., 2007, L-moments and TL-moments of the generalized lambda distribution: Computational Statistics and Data Analysis, v. 51, no. 9, pp. 4484&ndash;4496.
</p>
<p>Karvanen, J., Eriksson, J., and Koivunen, V., 2002, Adaptive score functions for maximum likelihood ICA: Journal of VLSI Signal Processing, v. 32, pp. 82&ndash;92.
</p>
<p>Karian, Z.A., and Dudewicz, E.J., 2000, Fitting statistical distibutions&mdash;The generalized lambda distribution and generalized bootstrap methods: CRC Press, Boca Raton, FL, 438 p.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pargld">pargld</a></code>, <code><a href="#topic+cdfgld">cdfgld</a></code>, <code><a href="#topic+pdfgld">pdfgld</a></code>,  <code><a href="#topic+quagld">quagld</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
lmomgld(vec2par(c(10,10,0.4,1.3),type='gld'))

## End(Not run)

## Not run: 
PARgld &lt;- vec2par(c(0,1,1,.5), type="gld")
theoTLmoms(PARgld, nmom=6)
lmomgld(PARgld)

## End(Not run)
</code></pre>

<hr>
<h2 id='lmomglo'>L-moments of the Generalized Logistic Distribution</h2><span id='topic+lmomglo'></span>

<h3>Description</h3>

<p>This function estimates the L-moments of the Generalized Logistic distribution given the parameters (<code class="reqn">\xi</code>, <code class="reqn">\alpha</code>, and <code class="reqn">\kappa</code>) from <code><a href="#topic+parglo">parglo</a></code>. The L-moments in terms of the parameters are
</p>
<p style="text-align: center;"><code class="reqn">\lambda_1 = \xi + \alpha \left(\frac{1}{\kappa} - \frac{\pi}{\sin(\kappa\pi)}\right) \mbox{,}</code>
</p>

<p style="text-align: center;"><code class="reqn">\lambda_2 = \frac{\alpha \kappa \pi}{\sin(\kappa\pi)} \mbox{,}</code>
</p>

<p style="text-align: center;"><code class="reqn">\tau_3 = -\kappa \mbox{, and}</code>
</p>

<p style="text-align: center;"><code class="reqn">\tau_4 = \frac{(1+5\tau_3^2)}{6} = \frac{(1+5\kappa^2)}{6}\mbox{.}</code>
</p>



<h3>Usage</h3>

<pre><code class='language-R'>lmomglo(para)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lmomglo_+3A_para">para</code></td>
<td>
<p>The parameters of the distribution.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> is returned.
</p>
<table>
<tr><td><code>lambdas</code></td>
<td>
<p>Vector of the L-moments. First element is
<code class="reqn">\lambda_1</code>, second element is <code class="reqn">\lambda_2</code>, and so on.</p>
</td></tr>
<tr><td><code>ratios</code></td>
<td>
<p>Vector of the L-moment ratios. Second element is
<code class="reqn">\tau</code>, third element is <code class="reqn">\tau_3</code> and so on.</p>
</td></tr>
<tr><td><code>trim</code></td>
<td>
<p>Level of symmetrical trimming used in the computation, which is <code>0</code>.</p>
</td></tr>
<tr><td><code>leftrim</code></td>
<td>
<p>Level of left-tail trimming used in the computation, which is <code>NULL</code>.</p>
</td></tr>
<tr><td><code>rightrim</code></td>
<td>
<p>Level of right-tail trimming used in the computation, which is <code>NULL</code>.</p>
</td></tr>
<tr><td><code>source</code></td>
<td>
<p>An attribute identifying the computational
source of the L-moments: &ldquo;lmomglo&rdquo;.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Hosking, J.R.M., 1990, L-moments&mdash;Analysis and estimation of distributions using linear combinations of order statistics: Journal of the Royal Statistical Society, Series B, v. 52, pp. 105&ndash;124.
</p>
<p>Hosking, J.R.M., 1996, FORTRAN routines for use with the method of L-moments: Version 3, IBM Research Report RC20525, T.J. Watson Research Center, Yorktown Heights, New York.
</p>
<p>Hosking, J.R.M., and Wallis, J.R., 1997, Regional frequency analysis&mdash;An approach based on L-moments: Cambridge University Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+parglo">parglo</a></code>,  <code><a href="#topic+cdfglo">cdfglo</a></code>, <code><a href="#topic+pdfglo">pdfglo</a></code>, <code><a href="#topic+quaglo">quaglo</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>lmr &lt;- lmoms(c(123,34,4,654,37,78))
lmr
lmomglo(parglo(lmr))
</code></pre>

<hr>
<h2 id='lmomgno'>L-moments of the Generalized Normal Distribution</h2><span id='topic+lmomgno'></span>

<h3>Description</h3>

<p>This function estimates the L-moments of the Generalized Normal (Log-Normal3) distribution given the parameters (<code class="reqn">\xi</code>, <code class="reqn">\alpha</code>, and <code class="reqn">\kappa</code>) from <code><a href="#topic+pargno">pargno</a></code>. The L-moments in terms of the parameters are
</p>
<p style="text-align: center;"><code class="reqn">\lambda_1 = \xi + \frac{\alpha}{\kappa}(1-\mathrm{exp}(\kappa^2/2) \mbox{, and}</code>
</p>

<p style="text-align: center;"><code class="reqn">\lambda_2 = \frac{\alpha}{\kappa}(\mathrm{exp}(\kappa^2/2)(1-2\Phi(-\kappa/\sqrt{2})) \mbox{,}</code>
</p>

<p>where <code class="reqn">\Phi</code> is the cumulative distribution of the Standard Normal distribution. There are no simple expressions for <code class="reqn">\tau_3</code>, <code class="reqn">\tau_4</code>, and <code class="reqn">\tau_5</code>. Logarthmic transformation of the data prior to fitting of the Generalized Normal distribution is not required. The distribution is algorithmically the same with subtle parameter modifications as the Log-Normal3 distribution (see <code><a href="#topic+lmomln3">lmomln3</a></code>, <code><a href="#topic+parln3">parln3</a></code>). If desired for user-level control of the lower bounds of a Log-Normal-like distribution is required, then see <code><a href="#topic+parln3">parln3</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lmomgno(para)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lmomgno_+3A_para">para</code></td>
<td>
<p>The parameters of the distribution.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> is returned.
</p>
<table>
<tr><td><code>lambdas</code></td>
<td>
<p>Vector of the L-moments. First element is
<code class="reqn">\lambda_1</code>, second element is <code class="reqn">\lambda_2</code>, and so on.</p>
</td></tr>
<tr><td><code>ratios</code></td>
<td>
<p>Vector of the L-moment ratios. Second element is
<code class="reqn">\tau</code>, third element is <code class="reqn">\tau_3</code> and so on.</p>
</td></tr>
<tr><td><code>trim</code></td>
<td>
<p>Level of symmetrical trimming used in the computation, which is <code>0</code>.</p>
</td></tr>
<tr><td><code>leftrim</code></td>
<td>
<p>Level of left-tail trimming used in the computation, which is <code>NULL</code>.</p>
</td></tr>
<tr><td><code>rightrim</code></td>
<td>
<p>Level of right-tail trimming used in the computation, which is <code>NULL</code>.</p>
</td></tr>
<tr><td><code>source</code></td>
<td>
<p>An attribute identifying the computational
source of the L-moments: &ldquo;lmomgno&rdquo;.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Hosking, J.R.M., 1990, L-moments&mdash;Analysis and estimation of distributions using linear combinations of order statistics: Journal of the Royal Statistical Society, Series B, v. 52, pp. 105&ndash;124.
</p>
<p>Hosking, J.R.M., 1996, FORTRAN routines for use with the method of L-moments: Version 3, IBM Research Report RC20525, T.J. Watson Research Center, Yorktown Heights, New York.
</p>
<p>Hosking, J.R.M., and Wallis, J.R., 1997, Regional frequency analysis&mdash;An approach based on L-moments: Cambridge University Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pargno">pargno</a></code>, <code><a href="#topic+cdfgno">cdfgno</a></code>, <code><a href="#topic+pdfgno">pdfgno</a></code>, <code><a href="#topic+quagno">quagno</a></code>, <code><a href="#topic+lmomln3">lmomln3</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>lmr &lt;- lmoms(c(123,34,4,654,37,78))
lmr
lmomgno(pargno(lmr))
</code></pre>

<hr>
<h2 id='lmomgov'>L-moments of the Govindarajulu Distribution</h2><span id='topic+lmomgov'></span>

<h3>Description</h3>

<p>This function estimates the L-moments of the Govindarajulu distribution given the parameters (<code class="reqn">\xi</code>, <code class="reqn">\alpha</code>, and <code class="reqn">\beta</code>) from <code><a href="#topic+pargov">pargov</a></code>. The L-moments in terms of the parameters are
</p>
<p style="text-align: center;"><code class="reqn">\lambda_1 = \xi + \frac{2\alpha}{\beta+2} \mbox{,}</code>
</p>

<p style="text-align: center;"><code class="reqn">\lambda_2 = \frac{2\alpha\beta}{(\beta+2)(\beta+3)} \mbox{,}</code>
</p>

<p style="text-align: center;"><code class="reqn">\tau_3 = \frac{\beta-2}{\beta+4} \mbox{, and}</code>
</p>

<p style="text-align: center;"><code class="reqn">\tau_4 = \frac{(\beta-5)(\beta-1)}{(\beta+4)(\beta+5)} \mbox{.}</code>
</p>

<p>The limits of <code class="reqn">\tau_3</code> are <code class="reqn">(-1/2, 1)</code> for <code class="reqn">\beta \rightarrow 0</code> and <code class="reqn">\beta \rightarrow \infty</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lmomgov(para)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lmomgov_+3A_para">para</code></td>
<td>
<p>The parameters of the distribution.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> list is returned.
</p>
<table>
<tr><td><code>lambdas</code></td>
<td>
<p>Vector of the L-moments. First element is
<code class="reqn">\lambda_1</code>, second element is <code class="reqn">\lambda_2</code>, and so on.</p>
</td></tr>
<tr><td><code>ratios</code></td>
<td>
<p>Vector of the L-moment ratios. Second element is
<code class="reqn">\tau</code>, third element is <code class="reqn">\tau_3</code> and so on.</p>
</td></tr>
<tr><td><code>trim</code></td>
<td>
<p>Level of symmetrical trimming used in the computation, which is <code>0</code>.</p>
</td></tr>
<tr><td><code>leftrim</code></td>
<td>
<p>Level of left-tail trimming used in the computation, which is <code>NULL</code>.</p>
</td></tr>
<tr><td><code>rightrim</code></td>
<td>
<p>Level of right-tail trimming used in the computation, which is <code>NULL</code>.</p>
</td></tr>
<tr><td><code>source</code></td>
<td>
<p>An attribute identifying the computational source
of the L-moments: &ldquo;lmomgov&rdquo;.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Gilchrist, W.G., 2000, Statistical modelling with quantile functions: Chapman and Hall/CRC, Boca Raton.
</p>
<p>Nair, N.U., Sankaran, P.G., Balakrishnan, N., 2013, Quantile-based reliability analysis: Springer, New York.
</p>
<p>Nair, N.U., Sankaran, P.G., and Vineshkumar, B., 2012, The Govindarajulu distribution&mdash;Some Properties and applications: Communications in Statistics, Theory and Methods, v. 41, no. 24, pp. 4391&ndash;4406.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pargov">pargov</a></code>, <code><a href="#topic+cdfgov">cdfgov</a></code>, <code><a href="#topic+pdfgov">pdfgov</a></code>, <code><a href="#topic+quagov">quagov</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>lmr &lt;- lmoms(c(123,34,4,654,37,78))
lmorph(lmr)
lmomgov(pargov(lmr))
## Not run: 
Bs &lt;- exp(seq(log(.01),log(10000),by=.05))
T3 &lt;- (Bs-2)/(Bs+4)
T4 &lt;- (Bs-5)*(Bs-1)/((Bs+4)*(Bs+5))
plotlmrdia(lmrdia(), autolegend=TRUE)
points(T3, T4)
T3s &lt;- c(-0.5,T3,1)
T4s  &lt;- c(0.25,T4,1)
the.lm &lt;- lm(T4s~T3s+I(T3s^2)+I(T3s^3)+I(T3s^4)+I(T3s^5))
lines(T3s, predict(the.lm), col=2)
max(residuals(the.lm))
summary(the.lm)

## End(Not run)
</code></pre>

<hr>
<h2 id='lmomgpa'>L-moments of the Generalized Pareto Distribution</h2><span id='topic+lmomgpa'></span>

<h3>Description</h3>

<p>This function estimates the L-moments of the Generalized Pareto distribution given the parameters (<code class="reqn">\xi</code>, <code class="reqn">\alpha</code>, and <code class="reqn">\kappa</code>) from <code><a href="#topic+pargpa">pargpa</a></code>. The L-moments in terms of the parameters are
</p>
<p style="text-align: center;"><code class="reqn">\lambda_1 = \xi + \frac{\alpha}{\kappa+1} \mbox{,}</code>
</p>

<p style="text-align: center;"><code class="reqn">\lambda_2 = \frac{\alpha}{(\kappa+2)(\kappa+1)} \mbox{,}</code>
</p>

<p style="text-align: center;"><code class="reqn">\tau_3 = \frac{(1-\kappa)}{(\kappa+3)} \mbox{, and}</code>
</p>

<p style="text-align: center;"><code class="reqn">\tau_4 = \frac{(1-\kappa)(2-\kappa)}{(\kappa+4)(\kappa+3)} \mbox{.}</code>
</p>



<h3>Usage</h3>

<pre><code class='language-R'>lmomgpa(para)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lmomgpa_+3A_para">para</code></td>
<td>
<p>The parameters of the distribution.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> is returned.
</p>
<table>
<tr><td><code>lambdas</code></td>
<td>
<p>Vector of the L-moments. First element is
<code class="reqn">\lambda_1</code>, second element is <code class="reqn">\lambda_2</code>, and so on.</p>
</td></tr>
<tr><td><code>ratios</code></td>
<td>
<p>Vector of the L-moment ratios. Second element is
<code class="reqn">\tau</code>, third element is <code class="reqn">\tau_3</code> and so on.</p>
</td></tr>
<tr><td><code>trim</code></td>
<td>
<p>Level of symmetrical trimming used in the computation, which is <code>0</code>.</p>
</td></tr>
<tr><td><code>leftrim</code></td>
<td>
<p>Level of left-tail trimming used in the computation, which is <code>NULL</code>.</p>
</td></tr>
<tr><td><code>rightrim</code></td>
<td>
<p>Level of right-tail trimming used in the computation, which is <code>NULL</code>.</p>
</td></tr>
<tr><td><code>source</code></td>
<td>
<p>An attribute identifying the computational
source of the L-moments: &ldquo;lmomgpa&rdquo;.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Hosking, J.R.M., 1990, L-moments&mdash;Analysis and estimation of distributions using linear combinations of order statistics: Journal of the Royal Statistical Society, Series B, v. 52, pp. 105&ndash;124.
</p>
<p>Hosking, J.R.M., 1996, FORTRAN routines for use with the method of L-moments: Version 3, IBM Research Report RC20525, T.J. Watson Research Center, Yorktown Heights, New York.
</p>
<p>Hosking, J.R.M., and Wallis, J.R., 1997, Regional frequency analysis&mdash;An approach based on L-moments: Cambridge University Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pargpa">pargpa</a></code>, <code><a href="#topic+cdfgpa">cdfgpa</a></code>, <code><a href="#topic+pdfgpa">pdfgpa</a></code>, <code><a href="#topic+quagpa">quagpa</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>lmr &lt;- lmoms(c(123,34,4,654,37,78))
lmr
lmomgpa(pargpa(lmr))
</code></pre>

<hr>
<h2 id='lmomgpaRC'>B-type L-moments of the Generalized Pareto Distribution with Right-Tail Censoring</h2><span id='topic+lmomgpaRC'></span>

<h3>Description</h3>

<p>This function computes the &ldquo;B&rdquo;-type L-moments of the Generalized Pareto distribution given the parameters (<code class="reqn">\xi</code>, <code class="reqn">\alpha</code>, and <code class="reqn">\kappa</code>) from <code><a href="#topic+pargpaRC">pargpaRC</a></code> and the right-tail censoring fraction <code class="reqn">\zeta</code>. The B-type L-moments in terms of the parameters are
</p>
<p style="text-align: center;"><code class="reqn">\lambda^B_1 = \xi + \alpha m_1 \mbox{,}</code>
</p>

<p style="text-align: center;"><code class="reqn">\lambda^B_2 = \alpha (m_1 - m_2) \mbox{,}</code>
</p>

<p style="text-align: center;"><code class="reqn">\lambda^B_3 = \alpha (m_1 - 3m_2 + 2m_3)\mbox{,}</code>
</p>

<p style="text-align: center;"><code class="reqn">\lambda^B_4 = \alpha (m_1 - 6m_2 + 10m_3 - 5m_4)\mbox{, and}</code>
</p>

<p style="text-align: center;"><code class="reqn">\lambda^B_5 = \alpha (m_1 - 10m_2 + 30m_3 - 35m_4 + 14m_5)\mbox{,}</code>
</p>

<p>where <code class="reqn">m_r = \lbrace 1-(1-\zeta)^{r+\kappa}\rbrace/(r+\kappa)</code> and <code class="reqn">\zeta</code> is the right-tail censor fraction or the probability <code class="reqn">\mathrm{Pr}\lbrace \rbrace</code> that <code class="reqn">x</code> is less than the quantile at <code class="reqn">\zeta</code> nonexceedance probability: (<code class="reqn">\mathrm{Pr}\lbrace x &lt; X(\zeta) \rbrace</code>). In other words, if <code class="reqn">\zeta = 1</code>, then there is no right-tail censoring. Finally, the <code>RC</code> in the function name is to denote <code>R</code>ight-tail <code>C</code>ensoring.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lmomgpaRC(para)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lmomgpaRC_+3A_para">para</code></td>
<td>
<p>The parameters of the distribution. Note that if the <code class="reqn">\zeta</code> part of the parameters (see <code><a href="#topic+pargpaRC">pargpaRC</a></code>) is not present then <code>zeta=1</code> (no right-tail censoring) is assumed.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> is returned.
</p>
<table>
<tr><td><code>lambdas</code></td>
<td>
<p>Vector of the L-moments. First element is
<code class="reqn">\lambda_1</code>, second element is <code class="reqn">\lambda_2</code>, and so on.</p>
</td></tr>
<tr><td><code>ratios</code></td>
<td>
<p>Vector of the L-moment ratios. Second element is
<code class="reqn">\tau</code>, third element is <code class="reqn">\tau_3</code> and so on.</p>
</td></tr>
<tr><td><code>trim</code></td>
<td>
<p>Level of symmetrical trimming used in the computation, which is <code>0</code>.</p>
</td></tr>
<tr><td><code>leftrim</code></td>
<td>
<p>Level of left-tail trimming used in the computation, which is <code>NULL</code>.</p>
</td></tr>
<tr><td><code>rightrim</code></td>
<td>
<p>Level of right-tail trimming used in the computation, which is <code>NULL</code>.</p>
</td></tr>
<tr><td><code>source</code></td>
<td>
<p>An attribute identifying the computational
source of the L-moments: &ldquo;lmomgpaRC&rdquo;.</p>
</td></tr>
<tr><td><code>message</code></td>
<td>
<p>For clarity, this function adds the unusual message to an L-moment object that the <code>lambdas</code> and <code>ratios</code> are B-type L-moments.</p>
</td></tr>
<tr><td><code>zeta</code></td>
<td>
<p>The censoring fraction. Assumed equal to unity if not present in the <code>gpa</code> parameter object.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Hosking, J.R.M., 1990, L-moments&mdash;Analysis and estimation of distributions using linear combinations of order statistics: Journal of the Royal Statistical Society, Series B, v. 52, pp. 105&ndash;124.
</p>
<p>Hosking, J.R.M., 1995, The use of L-moments in the analysis of censored data, in Recent Advances in Life-Testing and Reliability, edited by N. Balakrishnan, chapter 29, CRC Press, Boca Raton, Fla., pp. 546&ndash;560.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pargpa">pargpa</a></code>, <code><a href="#topic+pargpaRC">pargpaRC</a></code>, <code><a href="#topic+lmomgpa">lmomgpa</a></code>, <code><a href="#topic+cdfgpa">cdfgpa</a></code>, <code><a href="#topic+pdfgpa">pdfgpa</a></code>, <code><a href="#topic+quagpa">quagpa</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>para &lt;- vec2par(c(1500,160,.3),type="gpa") # build a GPA parameter set
lmorph(lmomgpa(para))
lmomgpaRC(para) # zeta = 1 is internally assumed if not available
# The previous two commands should output the same parameter values from
# independent code bases.
# Now assume that we have the sample parameters, but the zeta is nonunity.
para$zeta = .8
lmomgpaRC(para) # The B-type L-moments.
</code></pre>

<hr>
<h2 id='lmomgum'>L-moments of the Gumbel Distribution</h2><span id='topic+lmomgum'></span>

<h3>Description</h3>

<p>This function estimates the L-moments of the Gumbel distribution given
the parameters (<code class="reqn">\xi</code> and <code class="reqn">\alpha</code>) from <code><a href="#topic+pargum">pargum</a></code>. The L-moments in terms of the parameters are 
<code class="reqn">\lambda_1 = [\xi + (0.5722\dots) \alpha]</code>, 
<code class="reqn">\lambda_2 = \alpha \log(2)</code>, 
<code class="reqn">\tau_3 = 0.169925</code>, 
<code class="reqn">\tau_4 = 0.150375</code>, and 
<code class="reqn">\tau_5 = 0.055868</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lmomgum(para)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lmomgum_+3A_para">para</code></td>
<td>
<p>The parameters of the distribution.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> is returned.
</p>
<table>
<tr><td><code>lambdas</code></td>
<td>
<p>Vector of the L-moments. First element is
<code class="reqn">\lambda_1</code>, second element is <code class="reqn">\lambda_2</code>, and so on.</p>
</td></tr>
<tr><td><code>ratios</code></td>
<td>
<p>Vector of the L-moment ratios. Second element is
<code class="reqn">\tau</code>, third element is <code class="reqn">\tau_3</code> and so on.</p>
</td></tr>
<tr><td><code>trim</code></td>
<td>
<p>Level of symmetrical trimming used in the computation, which is <code>0</code>.</p>
</td></tr>
<tr><td><code>leftrim</code></td>
<td>
<p>Level of left-tail trimming used in the computation, which is <code>NULL</code>.</p>
</td></tr>
<tr><td><code>rightrim</code></td>
<td>
<p>Level of right-tail trimming used in the computation, which is <code>NULL</code>.</p>
</td></tr>
<tr><td><code>source</code></td>
<td>
<p>An attribute identifying the computational
source of the L-moments: &ldquo;lmomgum&rdquo;.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Hosking, J.R.M., 1990, L-moments&mdash;Analysis and estimation of distributions using linear combinations of order statistics: Journal of the Royal Statistical Society, Series B, v. 52, pp. 105&ndash;124.
</p>
<p>Hosking, J.R.M., 1996, FORTRAN routines for use with the method of L-moments: Version 3, IBM Research Report RC20525, T.J. Watson Research Center, Yorktown Heights, New York.
</p>
<p>Hosking, J.R.M., and Wallis, J.R., 1997, Regional frequency analysis&mdash;An approach based on L-moments: Cambridge University Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pargum">pargum</a></code>, <code><a href="#topic+cdfgum">cdfgum</a></code>, <code><a href="#topic+pdfgum">pdfgum</a></code>, <code><a href="#topic+quagum">quagum</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>lmr &lt;- lmoms(c(123,34,4,654,37,78))
lmomgum(pargum(lmr))
</code></pre>

<hr>
<h2 id='lmomkap'>L-moments of the Kappa Distribution</h2><span id='topic+lmomkap'></span>

<h3>Description</h3>

<p>This function estimates the L-moments of the Kappa distribution given the parameters (<code class="reqn">\xi</code>, <code class="reqn">\alpha</code>, <code class="reqn">\kappa</code>, and <code class="reqn">h</code>) from <code><a href="#topic+parkap">parkap</a></code>. The L-moments in terms of the parameters are complicated and are solved numerically. If the parameter <code class="reqn">k = 0</code> (is small or near zero) then let
</p>
<p style="text-align: center;"><code class="reqn">d_r = \gamma + \log(-h) + \mathrm{digamma}(-r/h)\ \mbox{for}\ h &lt; 0</code>
</p>

<p style="text-align: center;"><code class="reqn">d_r = \gamma + \log(r)\ \mbox{for}\ h = 0\ \mbox{(is small)}</code>
</p>

<p style="text-align: center;"><code class="reqn">d_r = \gamma + \log(h) + \mathrm{digamma}(1+r/h)\ \mbox{for}\ h &gt; 0</code>
</p>

<p>or if <code class="reqn">k &gt; -1</code> (nonzero) then let
</p>
<p style="text-align: center;"><code class="reqn">g_r = \frac{\Gamma(1+k)\Gamma(-r/h-k)}{-h^k\,\Gamma(-r/h)}\ \mbox{for}\ h &lt; 0</code>
</p>

<p style="text-align: center;"><code class="reqn">g_r = \frac{\Gamma(1+k)}{r^k} \times (1-0.5hk(1+k)/r)\ \mbox{for}\ h = 0\ \mbox{(is small)}</code>
</p>

<p style="text-align: center;"><code class="reqn">g_r = \frac{\Gamma(1+k)\Gamma(1+r/h)}{h^g\,\Gamma(1+k+r/h)}\ \mbox{for}\ h &gt; 0</code>
</p>

<p>where <code class="reqn">r</code> is L-moment order, <code class="reqn">\gamma</code> is Euler's constant, and for <code class="reqn">h = 0</code> the term to the right of the multiplication is not in Hosking (1994) or Hosking and Wallis (1997) for exists within Hosking's FORTRAN code base.
</p>
<p>The probability-weighted moments (<code class="reqn">\beta_r</code>; <code><a href="#topic+pwm2lmom">pwm2lmom</a></code>) for <code class="reqn">k = 0</code> (is small or near zero) are
</p>
<p style="text-align: center;"><code class="reqn">r\beta_{r-1} = \xi + (\alpha/\kappa)[1 - d_r]</code>
</p>

<p>or if <code class="reqn">k &gt; -1</code> (nonzero) then
</p>
<p style="text-align: center;"><code class="reqn">r\beta_{r-1} = \xi + (\alpha/\kappa)[1 - g_r]</code>
</p>



<h3>Usage</h3>

<pre><code class='language-R'>lmomkap(para, nmom=5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lmomkap_+3A_para">para</code></td>
<td>
<p>The parameters of the distribution.</p>
</td></tr>
<tr><td><code id="lmomkap_+3A_nmom">nmom</code></td>
<td>
<p>The number of moments to compute. Default is 5.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> is returned.
</p>
<table>
<tr><td><code>lambdas</code></td>
<td>
<p>Vector of the L-moments. First element is
<code class="reqn">\lambda_1</code>, second element is <code class="reqn">\lambda_2</code>, and so on.</p>
</td></tr>
<tr><td><code>ratios</code></td>
<td>
<p>Vector of the L-moment ratios. Second element is
<code class="reqn">\tau</code>, third element is <code class="reqn">\tau_3</code> and so on.</p>
</td></tr>
<tr><td><code>trim</code></td>
<td>
<p>Level of symmetrical trimming used in the computation, which is <code>0</code>.</p>
</td></tr>
<tr><td><code>leftrim</code></td>
<td>
<p>Level of left-tail trimming used in the computation, which is <code>NULL</code>.</p>
</td></tr>
<tr><td><code>rightrim</code></td>
<td>
<p>Level of right-tail trimming used in the computation, which is <code>NULL</code>.</p>
</td></tr>
<tr><td><code>source</code></td>
<td>
<p>An attribute identifying the computational
source of the L-moments: &ldquo;lmomkap&rdquo;.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Hosking, J.R.M., 1994, The four-parameter kappa distribution: IBM Journal of Reserach and Development, v. 38, no. 3, pp. 251&ndash;258.
</p>
<p>Hosking, J.R.M., and Wallis, J.R., 1997, Regional frequency analysis&mdash;An approach based on L-moments: Cambridge University Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+parkap">parkap</a></code>, <code><a href="#topic+cdfkap">cdfkap</a></code>, <code><a href="#topic+pdfkap">pdfkap</a></code>, <code><a href="#topic+quakap">quakap</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>lmr &lt;- lmoms(c(123, 34, 4,78, 45, 234, 65, 2, 3, 5, 76, 7, 80))
lmomkap(parkap(lmr))
</code></pre>

<hr>
<h2 id='lmomkmu'>L-moments of the Kappa-Mu Distribution</h2><span id='topic+lmomkmu'></span>

<h3>Description</h3>

<p>This function estimates the L-moments of the Kappa-Mu (<code class="reqn">\kappa:\mu</code>)  distribution given the parameters (<code class="reqn">\nu</code> and <code class="reqn">\alpha</code>) from <code><a href="#topic+parkmu">parkmu</a></code>. The L-moments in terms of the parameters are complex. They are computed here by the <code class="reqn">\alpha_r</code> probability-weighted moments in terms of the Marcum Q-function (see <code><a href="#topic+cdfkmu">cdfkmu</a></code>). The linear combination relating the L-moments to the <code class="reqn">\beta_r</code> probability-weighted moments is
</p>
<p style="text-align: center;"><code class="reqn">
\lambda_{r+1} = \sum_{k=0}^{r} (-1)^{r-k} {r \choose k} { r + k \choose k } \beta_k
\mbox{,}</code>
</p>

<p>for <code class="reqn">r \ge 0</code> and the linear combination relating <code class="reqn">\alpha_r</code> to <code class="reqn">\beta_r</code> is
</p>
<p style="text-align: center;"><code class="reqn">
\alpha_r = \sum_{k=0}^r (-1)^k { r \choose k } \beta_k
\mbox{,}</code>
</p>

<p>and by definition the <code class="reqn">\alpha_r</code> are the expectations
</p>
<p style="text-align: center;"><code class="reqn">
\alpha_r \equiv E\{ X\,[1-F(X)]^r\}
\mbox{,}</code>
</p>

<p>and thus
</p>
<p style="text-align: center;"><code class="reqn">
\alpha_r =  \int_{-\infty}^{\infty} x\, [1 - F(x)]^r f(x)\; \mathrm{d}x
\mbox{,}</code>
</p>

<p>in terms of <code class="reqn">x</code>, the PDF <code class="reqn">f(x)</code>, and the CDF <code class="reqn">F(x)</code>. Lastly, the <code class="reqn">\alpha_r</code> for the Kappa-Mu distribution with substitutions of the Marcum Q-function are
</p>
<p style="text-align: center;"><code class="reqn">
\alpha_r = \int_{-\infty}^{\infty} Q_\mu\biggl(\sqrt{2\kappa\mu},\; x\sqrt{2(1+\kappa)\mu}\biggr)^r\,x\, f(x)\; \mathrm{d}x\mbox{.}
</code>
</p>

<p>Although multiple methods for Marcum Q-function computation are in <code><a href="#topic+cdfkmu">cdfkmu</a></code> and discussed in that documentation, the <code>lmomkmu</code> presenting is built only using the &ldquo;chisq&rdquo; approach.
</p>
<p>Yacoub (2007, eq. 5) provides an expectation for the <code class="reqn">j</code>th moment of the distribution as given by
</p>
<p style="text-align: center;"><code class="reqn">
\mathrm{E}(x^j) = \frac{\Gamma(\mu+j/2)\mathrm{exp}(-\kappa\mu)}{\Gamma(\mu)[(1+\kappa)\mu]^{j/2}} \times {}_1F_1(\mu+j/2; \mu; \kappa\mu)
\mbox{,}</code>
</p>

<p>where <code class="reqn">{}_1F_1(a;b;z)</code> is the confluent hypergeometric function of Abramowitz and Stegun (1972, eq. 13.1.2). The <code>lmomkmu</code> function optionally solves for the mean (<code class="reqn">j=1</code>) using the above equation in conjunction with the mean as computed by the order statistic minimums. The <code class="reqn">{}_1F_1(a;b;z)</code> is defined as
</p>
<p style="text-align: center;"><code class="reqn">
{}_1F_1(a;b;z) = \sum_{i=0}^\infty \frac{a^{(i)}}{b^{(i)}}\frac{z^i}{n!}
\mbox{,}</code>
</p>

<p>where the notation <code class="reqn">a^{(n)}</code> represents &ldquo;rising factorials&rdquo; that are defined as <code class="reqn">a^{(0)} = 1</code> and <code class="reqn">a^{(n)} = a(a+1)(a+2)\ldots(a+n-1)</code>. The rising factorials are readily computed by <code class="reqn"> a^{(n)} = \Gamma(n+1)/\Gamma(n)</code> without resorting to a series computation. Yacoub (2007, eq. 5) is used to compute the mean.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lmomkmu(para, nmom=5, paracheck=TRUE, tol=1E-6, maxn=100)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lmomkmu_+3A_para">para</code></td>
<td>
<p>The parameters of the distribution.</p>
</td></tr>
<tr><td><code id="lmomkmu_+3A_nmom">nmom</code></td>
<td>
<p>The number of moments to compute.</p>
</td></tr>
<tr><td><code id="lmomkmu_+3A_paracheck">paracheck</code></td>
<td>
<p>A logical controlling whether the parameters and checked for validity.</p>
</td></tr>
<tr><td><code id="lmomkmu_+3A_tol">tol</code></td>
<td>
<p>An absolute tolerance term for series convergence of the confluent hypergeometric function when the Yacoub (2007) mean is to be computed.</p>
</td></tr>
<tr><td><code id="lmomkmu_+3A_maxn">maxn</code></td>
<td>
<p>The maximum number of interations in the series of the confluent hypergeometric function when the Yacoub (2007) mean is to be computed.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> is returned.
</p>
<table>
<tr><td><code>lambdas</code></td>
<td>
<p>Vector of the L-moments. First element is
<code class="reqn">\lambda_1</code>, second element is <code class="reqn">\lambda_2</code>, and so on.</p>
</td></tr>
<tr><td><code>ratios</code></td>
<td>
<p>Vector of the L-moment ratios. Second element is
<code class="reqn">\tau</code>, third element is <code class="reqn">\tau_3</code> and so on.</p>
</td></tr>
<tr><td><code>trim</code></td>
<td>
<p>Level of symmetrical trimming used in the computation, which is <code>0</code>.</p>
</td></tr>
<tr><td><code>leftrim</code></td>
<td>
<p>Level of left-tail trimming used in the computation, which is <code>NULL</code>.</p>
</td></tr>
<tr><td><code>rightrim</code></td>
<td>
<p>Level of right-tail trimming used in the computation, which is <code>NULL</code>.</p>
</td></tr>
<tr><td><code>source</code></td>
<td>
<p>An attribute identifying the computational
source of the L-moments: &ldquo;lmomkmu&rdquo;.</p>
</td></tr>
<tr><td><code>yacoubsmean</code></td>
<td>
<p>A list containing the mean, convergence error, and number of iterations in the series until convergence.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Yacoub, M.D., 2007, The kappa-mu distribution and the eta-mu distribution: IEEE Antennas and Propagation Magazine, v. 49, no. 1, pp. 68&ndash;81.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+parkmu">parkmu</a></code>, <code><a href="#topic+cdfkmu">cdfkmu</a></code>, <code><a href="#topic+pdfkmu">pdfkmu</a></code>, <code><a href="#topic+quakmu">quakmu</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>kmu &lt;- vec2par(c(1.19,2.3), type="kmu")
lmomkmu(kmu)
## Not run: 
par &lt;- vec2par(c(1.67, .5), type="kmu")
lmomkmu(par)$lambdas
cdf2lmoms(par, nmom=4)$lambdas

system.time(lmomkmu(par))
system.time(cdf2lmoms(par, nmom=4))

## End(Not run)
# See the examples under lmomemu() so visualize L-moment
# relations on the L-skew and L-kurtosis diagram
</code></pre>

<hr>
<h2 id='lmomkur'>L-moments of the Kumaraswamy Distribution</h2><span id='topic+lmomkur'></span>

<h3>Description</h3>

<p>This function estimates the L-moments of the Kumaraswamy distribution given the parameters (<code class="reqn">\alpha</code> and <code class="reqn">\beta</code>) from <code><a href="#topic+parkur">parkur</a></code>. The L-moments in terms of the parameters with <code class="reqn">\eta = 1 + 1/\alpha</code> are
</p>
<p style="text-align: center;"><code class="reqn">\lambda_1 = \beta B(\eta, \beta) \mbox{,}</code>
</p>

<p style="text-align: center;"><code class="reqn">\lambda_2 = \beta [B(\eta, \beta) - 2B(\eta, 2\beta)] \mbox{,}</code>
</p>

<p style="text-align: center;"><code class="reqn">\tau_3 = \frac{B(\eta,\beta) - 6B(\eta,2\beta) + 6B(\eta,3\beta)}{B(\eta,\beta) - 2B(\eta,2\beta)} \mbox{,}</code>
</p>

<p style="text-align: center;"><code class="reqn">\tau_4 = \frac{B(\eta,\beta) - 12B(\eta,2\beta) + 30B(\eta,3\beta) - 40B(\eta,4\beta)}{B(\eta,\beta) - 2B(\eta,2\beta)} \mbox{, and}</code>
</p>

<p style="text-align: center;"><code class="reqn">\tau_5 = \frac{B(\eta,\beta) - 20B(\eta,2\beta) + 90B(\eta,3\beta) - 140B(\eta,4\beta) + 70B(\eta,5\beta)}{B(\eta,\beta) - 2B(\eta,2\beta)} \mbox{.}</code>
</p>

<p>where <code class="reqn">B(a,b)</code> is the complete beta function or <code>beta()</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lmomkur(para)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lmomkur_+3A_para">para</code></td>
<td>
<p>The parameters of the distribution.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> is returned.
</p>
<table>
<tr><td><code>lambdas</code></td>
<td>
<p>Vector of the L-moments. First element is
<code class="reqn">\lambda_1</code>, second element is <code class="reqn">\lambda_2</code>, and so on.</p>
</td></tr>
<tr><td><code>ratios</code></td>
<td>
<p>Vector of the L-moment ratios. Second element is
<code class="reqn">\tau</code>, third element is <code class="reqn">\tau_3</code> and so on.</p>
</td></tr>
<tr><td><code>trim</code></td>
<td>
<p>Level of symmetrical trimming used in the computation, which is <code>0</code>.</p>
</td></tr>
<tr><td><code>leftrim</code></td>
<td>
<p>Level of left-tail trimming used in the computation, which is <code>NULL</code>.</p>
</td></tr>
<tr><td><code>rightrim</code></td>
<td>
<p>Level of right-tail trimming used in the computation, which is <code>NULL</code>.</p>
</td></tr>
<tr><td><code>source</code></td>
<td>
<p>An attribute identifying the computational
source of the L-moments: &ldquo;lmomkur&rdquo;.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Jones, M.C., 2009, Kumaraswamy's distribution&mdash;A beta-type distribution with some tractability advantages: Statistical Methodology, v. 6, pp. 70&ndash;81.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+parkur">parkur</a></code>,  <code><a href="#topic+cdfkur">cdfkur</a></code>, <code><a href="#topic+pdfkur">pdfkur</a></code>, <code><a href="#topic+quakur">quakur</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>lmr &lt;- lmoms(c(0.25, 0.4, 0.6, 0.65, 0.67, 0.9))
lmomkur(parkur(lmr))
## Not run: 
A &lt;- B &lt;- exp(seq(-3,5, by=.05))
logA &lt;- logB &lt;- T3 &lt;- T4 &lt;- c();
i &lt;- 0
for(a in A) {
  for(b in B) {
    i &lt;- i + 1
    parkur &lt;- list(para=c(a,b), type="kur");
    lmr &lt;- lmomkur(parkur)
    logA[i] &lt;- log(a); logB[i] &lt;- log(b)
    T3[i] &lt;- lmr$ratios[3]; T4[i] &lt;- lmr$ratios[4]
  }
}
library(lattice)
contourplot(T3~logA+logB, cuts=20, lwd=0.5, label.style="align",
            xlab="LOG OF ALPHA", ylab="LOG OF BETA",
            xlim=c(-3,5), ylim=c(-3,5),
            main="L-SKEW FOR KUMARASWAMY DISTRIBUTION")
contourplot(T4~logA+logB, cuts=10, lwd=0.5, label.style="align",
            xlab="LOG OF ALPHA", ylab="LOG OF BETA",
            xlim=c(-3,5), ylim=c(-3,5),
            main="L-KURTOSIS FOR KUMARASWAMY DISTRIBUTION")

## End(Not run)
</code></pre>

<hr>
<h2 id='lmomlap'>L-moments of the Laplace Distribution</h2><span id='topic+lmomlap'></span>

<h3>Description</h3>

<p>This function estimates the L-moments of the Laplace distribution given the parameters (<code class="reqn">\xi</code> and <code class="reqn">\alpha</code>) from <code><a href="#topic+parlap">parlap</a></code>. The L-moments in terms of the parameters are 
<code class="reqn">\lambda_1 = \xi</code>, 
<code class="reqn">\lambda_2 = 3\alpha/4</code>, 
<code class="reqn">\tau_3 = 0</code>, 
<code class="reqn">\tau_4 = 17/22</code>, 
<code class="reqn">\tau_5 = 0</code>, and 
<code class="reqn">\tau_6 = 31/360</code>.
</p>
<p>For <code class="reqn">r</code> odd and <code class="reqn">r \ge 3</code>, <code class="reqn">\lambda_r = 0</code>, and for <code class="reqn">r</code> even and <code class="reqn">r \ge 4</code>, the L-moments using the hypergeometric function <code class="reqn">{}_2F_1()</code> are
</p>
<p style="text-align: center;"><code class="reqn">\lambda_r = \frac{2\alpha}{r(r-1)}[1 - {}_2F_1(-r, r-1, 1, 1/2)]\mbox{,}</code>
</p>

<p>where <code class="reqn">{}_2F_1(a, b, c, z)</code> is defined as 
</p>
<p style="text-align: center;"><code class="reqn">{}_2F_1(a, b, c, z) = \sum_{n=0}^\infty \frac{(a)_n(b)_n}{(c)_n}\frac{z^n}{n!}\mbox{,}</code>
</p>

<p>where <code class="reqn">(x)_n</code> is the <em>rising</em> Pochhammer symbol, which is defined by
</p>
<p style="text-align: center;"><code class="reqn">(x)_n =  1 \mbox{\ for\ } n = 0\mbox{, and}</code>
</p>

<p style="text-align: center;"><code class="reqn">(x)_n = x(x+1)\cdots(x+n-1) \mbox{\ for\ } n &gt; 0\mbox{.}</code>
</p>



<h3>Usage</h3>

<pre><code class='language-R'>lmomlap(para)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lmomlap_+3A_para">para</code></td>
<td>
<p>The parameters of the distribution.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> is returned.
</p>
<table>
<tr><td><code>lambdas</code></td>
<td>
<p>Vector of the L-moments. First element is
<code class="reqn">\lambda_1</code>, second element is <code class="reqn">\lambda_2</code>, and so on.</p>
</td></tr>
<tr><td><code>ratios</code></td>
<td>
<p>Vector of the L-moment ratios. Second element is
<code class="reqn">\tau</code>, third element is <code class="reqn">\tau_3</code> and so on.</p>
</td></tr>
<tr><td><code>trim</code></td>
<td>
<p>Level of symmetrical trimming used in the computation, which is <code>0</code>.</p>
</td></tr>
<tr><td><code>leftrim</code></td>
<td>
<p>Level of left-tail trimming used in the computation, which is <code>NULL</code>.</p>
</td></tr>
<tr><td><code>rightrim</code></td>
<td>
<p>Level of right-tail trimming used in the computation, which is <code>NULL</code>.</p>
</td></tr>
<tr><td><code>source</code></td>
<td>
<p>An attribute identifying the computational source of the L-moments: &ldquo;lmomlap&rdquo;.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Hosking, J.R.M., 1986, The theory of probability weighted moments: IBM Research Report RC12210, T.J. Watson Research Center, Yorktown Heights, New York.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+parlap">parlap</a></code>, <code><a href="#topic+cdflap">cdflap</a></code>, <code><a href="#topic+pdflap">pdflap</a></code>, <code><a href="#topic+qualap">qualap</a></code>  </p>


<h3>Examples</h3>

<pre><code class='language-R'>lmr &lt;- lmoms(c(123,34,4,654,37,78))
lmr
lmomlap(parlap(lmr))
</code></pre>

<hr>
<h2 id='lmomlmrq'>L-moments of the Linear Mean Residual Quantile Function Distribution</h2><span id='topic+lmomlmrq'></span>

<h3>Description</h3>

<p>This function estimates the L-moments of the Linear Mean Residual Quantile Function distribution given the parameters (<code class="reqn">\mu</code> and <code class="reqn">\alpha</code>) from <code><a href="#topic+parlmrq">parlmrq</a></code>. The first six L-moments in terms of the parameters are
</p>
<p style="text-align: center;"><code class="reqn">\lambda_1 = \mu \mbox{,}</code>
</p>

<p style="text-align: center;"><code class="reqn">\lambda_2 = (\alpha + 3\mu)/6 \mbox{,}</code>
</p>

<p style="text-align: center;"><code class="reqn">\lambda_3 = 0 \mbox{,}</code>
</p>

<p style="text-align: center;"><code class="reqn">\lambda_4 = (\alpha + \mu)/12 \mbox{,}</code>
</p>

<p style="text-align: center;"><code class="reqn">\lambda_5 = (\alpha + \mu)/20 \mbox{, and}</code>
</p>

<p style="text-align: center;"><code class="reqn">\lambda_6 = (\alpha + \mu)/30 \mbox{.}</code>
</p>

<p>Because <code class="reqn">\alpha + \mu &gt; 0</code>, then <code class="reqn">\tau_3 &gt; 0</code>, so the distribution is positively skewed.  The coefficient of L-variation is in the interval <code class="reqn">(1/3, 2/3)</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lmomlmrq(para)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lmomlmrq_+3A_para">para</code></td>
<td>
<p>The parameters of the distribution.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> is returned.
</p>
<table>
<tr><td><code>lambdas</code></td>
<td>
<p>Vector of the L-moments. First element is
<code class="reqn">\lambda_1</code>, second element is <code class="reqn">\lambda_2</code>, and so on.</p>
</td></tr>
<tr><td><code>ratios</code></td>
<td>
<p>Vector of the L-moment ratios. Second element is
<code class="reqn">\tau</code>, third element is <code class="reqn">\tau_3</code> and so on.</p>
</td></tr>
<tr><td><code>trim</code></td>
<td>
<p>Level of symmetrical trimming used in the computation, which is <code>0</code>.</p>
</td></tr>
<tr><td><code>leftrim</code></td>
<td>
<p>Level of left-tail trimming used in the computation, which is <code>NULL</code>.</p>
</td></tr>
<tr><td><code>rightrim</code></td>
<td>
<p>Level of right-tail trimming used in the computation, which is <code>NULL</code>.</p>
</td></tr>
<tr><td><code>source</code></td>
<td>
<p>An attribute identifying the computational source of the L-moments: &ldquo;lmomlmrq&rdquo;.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Midhu, N.N., Sankaran, P.G., and Nair, N.U., 2013, A class of distributions with linear mean residual quantile function and it's generalizations: Statistical Methodology, v. 15, pp. 1&ndash;24.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+parlmrq">parlmrq</a></code>, <code><a href="#topic+cdflmrq">cdflmrq</a></code>, <code><a href="#topic+pdflmrq">pdflmrq</a></code>, <code><a href="#topic+qualmrq">qualmrq</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>lmr &lt;- lmoms(c(3, 0.05, 1.6, 1.37, 0.57, 0.36, 2.2))
lmr
lmomlmrq(parlmrq(lmr))
</code></pre>

<hr>
<h2 id='lmomln3'>L-moments of the 3-Parameter Log-Normal Distribution</h2><span id='topic+lmomln3'></span>

<h3>Description</h3>

<p>This function estimates the L-moments of the Log-Normal3 distribution given the parameters (<code class="reqn">\zeta</code>, lower bounds; <code class="reqn">\mu_{\mathrm{log}}</code>, location; and <code class="reqn">\sigma_{\mathrm{log}}</code>, scale) from <code><a href="#topic+parln3">parln3</a></code>.  The distribution is the same as the Generalized Normal with algebraic manipulation of the parameters, and <span class="pkg">lmomco</span> does not have truly separate algorithms for the Log-Normal3 but uses those of the Generalized Normal. The discussion begins with the later distribution.
</p>
<p>The two L-moments in terms of the Generalized Normal distribution parameters (<code><a href="#topic+lmomgno">lmomgno</a></code>) are
</p>
<p style="text-align: center;"><code class="reqn">\lambda_1 = \xi + \frac{\alpha}{\kappa}[1-\mathrm{exp}(\kappa^2/2)] \mbox{, and}</code>
</p>

<p style="text-align: center;"><code class="reqn">\lambda_2 = \frac{\alpha}{\kappa}(\mathrm{exp}(\kappa^2/2)(1-2\Phi(-\kappa/\sqrt{2})) \mbox{,}</code>
</p>

<p>where <code class="reqn">\Phi</code> is the cumulative distribution of the Standard Normal distribution. There are no simple expressions for <code class="reqn">\tau_3</code>, <code class="reqn">\tau_4</code>, and <code class="reqn">\tau_5</code>, and numerical methods are used.
</p>
<p>Let <code class="reqn">\zeta</code> be the lower bounds (real space) for which <code class="reqn">\zeta &lt; \lambda_1 - \lambda_2</code> (checked in <code><a href="#topic+are.parln3.valid">are.parln3.valid</a></code>), <code class="reqn">\mu_{\mathrm{log}}</code> be the mean in natural logarithmic space, and <code class="reqn">\sigma_{\mathrm{log}}</code> be the standard deviation in natural logarithm space for which <code class="reqn">\sigma_{\mathrm{log}} &gt; 0</code> (checked in <code><a href="#topic+are.parln3.valid">are.parln3.valid</a></code>) is obvious because this parameter has an analogy to the second product moment. Letting <code class="reqn">\eta = \exp(\mu_{\mathrm{log}})</code>, the parameters of the Generalized Normal are <code class="reqn">\zeta + \eta</code>, <code class="reqn">\alpha = \eta\sigma_{\mathrm{log}}</code>, and <code class="reqn">\kappa = -\sigma_{\mathrm{log}}</code>. At this point the L-moments can be solved for using algorithms for the Generalized Normal.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lmomln3(para)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lmomln3_+3A_para">para</code></td>
<td>
<p>The parameters of the distribution.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> is returned.
</p>
<table>
<tr><td><code>lambdas</code></td>
<td>
<p>Vector of the L-moments. First element is
<code class="reqn">\lambda_1</code>, second element is <code class="reqn">\lambda_2</code>, and so on.</p>
</td></tr>
<tr><td><code>ratios</code></td>
<td>
<p>Vector of the L-moment ratios. Second element is
<code class="reqn">\tau</code>, third element is <code class="reqn">\tau_3</code> and so on.</p>
</td></tr>
<tr><td><code>trim</code></td>
<td>
<p>Level of symmetrical trimming used in the computation, which is <code>0</code>.</p>
</td></tr>
<tr><td><code>leftrim</code></td>
<td>
<p>Level of left-tail trimming used in the computation, which is <code>NULL</code>.</p>
</td></tr>
<tr><td><code>rightrim</code></td>
<td>
<p>Level of right-tail trimming used in the computation, which is <code>NULL</code>.</p>
</td></tr>
<tr><td><code>source</code></td>
<td>
<p>An attribute identifying the computational
source of the L-moments: &ldquo;lmomln3&rdquo;.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Asquith, W.H., 2011, Distributional analysis with L-moment statistics using the R environment for statistical computing: Createspace Independent Publishing Platform, ISBN 978&ndash;146350841&ndash;8.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+parln3">parln3</a></code>, <code><a href="#topic+cdfln3">cdfln3</a></code>, <code><a href="#topic+pdfln3">pdfln3</a></code>, <code><a href="#topic+qualn3">qualn3</a></code>, <code><a href="#topic+lmomgno">lmomgno</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>X &lt;- exp(rnorm(10))
pargno(lmoms(X))$para
parln3(lmoms(X))$para
</code></pre>

<hr>
<h2 id='lmomnor'>L-moments of the Normal Distribution</h2><span id='topic+lmomnor'></span>

<h3>Description</h3>

<p>This function estimates the L-moments of the Normal distribution given the parameters (<code class="reqn">\mu</code> and <code class="reqn">\sigma</code>) from <code><a href="#topic+parnor">parnor</a></code>. The L-moments in terms of the parameters are
<code class="reqn">\lambda_1 = \mu</code>,
<code class="reqn">\lambda_2 = \sigma / \sqrt{pi}</code>,
<code class="reqn">\tau_3 = 0</code>,
<code class="reqn">\tau_4 = 0.122602</code>, and
<code class="reqn">\tau_5 = 0</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lmomnor(para)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lmomnor_+3A_para">para</code></td>
<td>
<p>The parameters of the distribution.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> is returned.
</p>
<table>
<tr><td><code>lambdas</code></td>
<td>
<p>Vector of the L-moments. First element is
<code class="reqn">\lambda_1</code>, second element is <code class="reqn">\lambda_2</code>, and so on.</p>
</td></tr>
<tr><td><code>ratios</code></td>
<td>
<p>Vector of the L-moment ratios. Second element is
<code class="reqn">\tau</code>, third element is <code class="reqn">\tau_3</code> and so on.</p>
</td></tr>
<tr><td><code>trim</code></td>
<td>
<p>Level of symmetrical trimming used in the computation, which is <code>0</code>.</p>
</td></tr>
<tr><td><code>leftrim</code></td>
<td>
<p>Level of left-tail trimming used in the computation, which is <code>NULL</code>.</p>
</td></tr>
<tr><td><code>rightrim</code></td>
<td>
<p>Level of right-tail trimming used in the computation, which is <code>NULL</code>.</p>
</td></tr>
<tr><td><code>source</code></td>
<td>
<p>An attribute identifying the computational
source of the L-moments: &ldquo;lmomnor&rdquo;.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Hosking, J.R.M., 1990, L-moments&mdash;Analysis and estimation of distributions using linear combinations of order statistics: Journal of the Royal Statistical Society, Series B, v. 52, pp. 105&ndash;124.
</p>
<p>Hosking, J.R.M., 1996, FORTRAN routines for use with the method of L-moments: Version 3, IBM Research Report RC20525, T.J. Watson Research Center, Yorktown Heights, New York.
</p>
<p>Hosking, J.R.M., and Wallis, J.R., 1997, Regional frequency analysis&mdash;An approach based on L-moments: Cambridge University Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+parnor">parnor</a></code>, <code><a href="#topic+cdfnor">cdfnor</a></code>, <code><a href="#topic+pdfnor">pdfnor</a></code>, <code><a href="#topic+quanor">quanor</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>lmr &lt;- lmoms(c(123, 34, 4, 654, 37, 78))
lmr
lmomnor(parnor(lmr))
</code></pre>

<hr>
<h2 id='lmompdq3'>L-moments of the Polynomial Density-Quantile3 Distribution</h2><span id='topic+lmompdq3'></span>

<h3>Description</h3>

<p>This function estimates the L-moments of the Polynomial Density-Quantile3 distribution given the parameters (<code class="reqn">\xi</code>, <code class="reqn">\alpha</code>, and <code class="reqn">\kappa</code>) from <code><a href="#topic+parpdq3">parpdq3</a></code>. The L-moments in terms of the parameters are
</p>
<p style="text-align: center;"><code class="reqn">\lambda_1 = \xi + \alpha\bigl[(1+\kappa)\log(1+\kappa) - (1-\kappa)\log(1-\kappa) - \kappa\log(4)\bigr]\mbox{,}</code>
</p>

<p style="text-align: center;"><code class="reqn">\lambda_2 = \frac{\alpha(1-\kappa^2)}{(1-\kappa\tau_3)}\mbox{,}</code>
</p>

<p style="text-align: center;"><code class="reqn">\tau_3 = \frac{1}{\kappa} - \frac{1}{\mathrm{arctanh}(\kappa)} \mbox{, and}</code>
</p>

<p style="text-align: center;"><code class="reqn">\tau_4 = (5\tau_3/\kappa) - 1\mbox{.}</code>
</p>



<h3>Usage</h3>

<pre><code class='language-R'>lmompdq3(para, paracheck=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lmompdq3_+3A_para">para</code></td>
<td>
<p>The parameters of the distribution.</p>
</td></tr>
<tr><td><code id="lmompdq3_+3A_paracheck">paracheck</code></td>
<td>
<p>A logical switch as to whether the validity of the parameters should be checked. Default is <code>paracheck=TRUE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> is returned.
</p>
<table>
<tr><td><code>lambdas</code></td>
<td>
<p>Vector of the L-moments. First element is
<code class="reqn">\lambda_1</code>, second element is <code class="reqn">\lambda_2</code>, and so on.</p>
</td></tr>
<tr><td><code>ratios</code></td>
<td>
<p>Vector of the L-moment ratios. Second element is
<code class="reqn">\tau</code>, third element is <code class="reqn">\tau_3</code> and so on.</p>
</td></tr>
<tr><td><code>trim</code></td>
<td>
<p>Level of symmetrical trimming used in the computation, which is <code>0</code>.</p>
</td></tr>
<tr><td><code>leftrim</code></td>
<td>
<p>Level of left-tail trimming used in the computation, which is <code>NULL</code>.</p>
</td></tr>
<tr><td><code>rightrim</code></td>
<td>
<p>Level of right-tail trimming used in the computation, which is <code>NULL</code>.</p>
</td></tr>
<tr><td><code>source</code></td>
<td>
<p>An attribute identifying the computational
source of the L-moments: &ldquo;lmompdq3&rdquo;.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Polynomial approximations for the <code class="reqn">\tau_3</code> and <code class="reqn">\tau_4</code> are developed here. First, the author's monograph (Asquith, 2011, table 10.1) shows five digits for such approximates for other distributions, so the code below will used the core basis, five digits. Second, an approximation means that <code><a href="#topic+lmrdia">lmrdia</a></code> does not have the internal burden of using <code>uniroot()</code> to solve for the coordinates for the L-moment ratio diagram. The following code represents an exploration towards the definition of a helper function, <code>t4pdq3()</code>, which is repeated inside the internals of <code><a href="#topic+lmrdia">lmrdia</a></code> in order to support the PDQ3. The trajectory of the PDQ3 resides at or above that for the generalized logistic distribution (<code><a href="#topic+quaglo">quaglo</a></code>) that is well known to L-moment theory. In conclusion, the 5-digit approximation provides a maximum absolute <code class="reqn">\tau_4</code> error of about 0.00055.
</p>
<pre>
  fn &lt;- function(k, tau3=NA) { t3 &lt;- (1/k - 1/atanh(k))
                               if(is.nan(t3)) t3 &lt;- 0
                               return(t3-tau3) }
  t3s &lt;- seq(-1, 1, by=0.005)
  t4s &lt;- NULL
  for(t3 in t3s) {
    rt  &lt;- uniroot(fn, interval=c(-1,1), tau3=t3)
    t4  &lt;- ((5*t3 / rt$root) - 1) / 4 # Hosking (2007)
    t4s &lt;- c(t4s, t4)
  }
  t4s[is.nan(t4s)] &lt;- 1/6 # by distribution properties

  plotlmrdia(lmrdia())
  points(t3s, t4s, pch=21, cex=0.5, bg=8, col="lightgreen")
  lines( t3s, t4s, col="darkgreen") # above GLO and see Hosking (2007, fig. 1)

  # eight powers as in Hosking and Wallis (1997) coefficient table for
  # many other distributions
  pdq3 &lt;- stats::lm(t4s~I(t3s^1)+I(t3s^2)+I(t3s^3)+I(t3s^4)+
                        I(t3s^5)+I(t3s^6)+I(t3s^7)+I(t3s^8))
  lines(t3s, fitted.values(pdq3), lwd=2, col=grey(0.8))
  pdq3$coefficients # Ah, see the odd coefficients are near zero, so define
  # as such in a repeated linear model but with skips on the odd orders:
  pdq3 &lt;- stats::lm(t4s~I(t3s^2)+I(t3s^4)+I(t3s^6)+I(t3s^8))
  lines(t3s, fitted.values(pdq3), lwd=1, col="red")
  max(abs(t4s - fitted.values(pdq3))) # show the max error in Rs resolution

  # we desire to compare "full resolution" to 5-digit truncation
  print(pdq3$coefficients,       16)  # in the 5 in the next line, c.2022,
  # we can  make new column in Asquith (2011, table 10.1) if ever needed for
  print(round(pdq3$coefficients,  5)) # a second edition

  t4pdq3 &lt;- function(t3, use5digits=TRUE) { # helper to repeat within lmrdia()
    c05 &lt;- c( 0.16688, 0, 0.98951, 0, -0.00526, 0, -0.24074, 0, 0.08906)
    c16 &lt;- c( 0.166875136751297809, 0,  0.989506002306983601, 0,
             -0.005255434641059076, 0, -0.240744479052170501, 0,
              0.089060315246257210)
    ifelse(use5digits, myc &lt;- c05, myc &lt;- c16)
    t4 &lt;- vector(mode="numeric", length(t3))
    for(i in 1:length(t3)) {
      t4[i] &lt;- sum(sapply(2:length(myc), function(k) myc[k]*t3[i]^(k-1)))
    }
    return(t4 + myc[1]) # end with the intercept being added on
  }
  lines(t3s, t4pdq3(t3s), col="darkgreen", lty=2)
  summary(abs(t4s - t4pdq3(t3s, use5digits=TRUE )))
  summary(abs(t4s - t4pdq3(t3s, use5digits=FALSE)))
  max(    abs(t4s - t4pdq3(t3s, use5digits=TRUE )))
  max(    abs(t4s - t4pdq3(t3s, use5digits=FALSE)))
  # further comparisons as needed to understand the aforementioned operations
  plot(  t4s, t4s - t4pdq3(t3s, use5digits=TRUE ), col="red", type="l")
  lines( t4s, t4s - t4pdq3(t3s, use5digits=FALSE), col="blue")
  abline(h=0)
</pre>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Asquith, W.H., 2011, Distributional analysis with L-moment statistics using the R environment for statistical computing: Createspace Independent Publishing Platform, ISBN 978&ndash;146350841&ndash;8.
</p>
<p>Hosking, J.R.M., 2007, Distributions with maximum entropy subject to constraints on their L-moments or expected order statistics: Journal of Statistical Planning and Inference, v. 137, no. 9, pp. 2870&ndash;2891, <a href="https://doi.org/10.1016/j.jspi.2006.10.010">doi:10.1016/j.jspi.2006.10.010</a>.
</p>
<p>Hosking, J.R.M., and Wallis, J.R., 1997, Regional frequency analysis&mdash;An approach based on L-moments: Cambridge University Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+parpdq3">parpdq3</a></code>, <code><a href="#topic+cdfpdq3">cdfpdq3</a></code>, <code><a href="#topic+pdfpdq3">pdfpdq3</a></code>, <code><a href="#topic+quapdq3">quapdq3</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
  para &lt;- list(para=c(20, 1, -0.5), type="pdq3")
  lmoms(quapdq3(runif(100000), para))$lambdas
  lmompdq3(para)$lambdas #
## End(Not run)

## Not run: 
  para &lt;- list(para=c(20, 1, +0.5), type="pdq3")
  lmoms(quapdq3(runif(100000), para))$lambdas
  lmompdq3(para)$lambdas #
## End(Not run)
</code></pre>

<hr>
<h2 id='lmompdq4'>L-moments of the Polynomial Density-Quantile4 Distribution</h2><span id='topic+lmompdq4'></span>

<h3>Description</h3>

<p>This function estimates the L-moments of the Polynomial Density-Quantile4 distribution given the parameters (<code class="reqn">\xi</code>, <code class="reqn">\alpha</code>, and <code class="reqn">\kappa</code>) from <code><a href="#topic+parpdq4">parpdq4</a></code>. The L-moments in terms of the parameters are
</p>
<p style="text-align: center;"><code class="reqn">\lambda_1 = \xi\mbox{,}</code>
</p>

<p style="text-align: center;"><code class="reqn">\lambda_2 = \frac{\alpha}{\kappa} \bigl(1-\kappa^2\bigr)\, \mathrm{atanh}(\kappa)\mathrm{\ for\ } \kappa &gt; 0\mbox{,}</code>
</p>

<p style="text-align: center;"><code class="reqn">\lambda_2 = \frac{\alpha}{\kappa} \bigl(1+\kappa^2\bigr)\, \mathrm{atan}(\kappa)\mathrm{\ for\ } \kappa &lt; 0\mbox{,}</code>
</p>

<p style="text-align: center;"><code class="reqn">\tau_3 = 0 \mbox{, and}</code>
</p>

<p style="text-align: center;"><code class="reqn">\tau_4 = -\frac{1}{4} + \frac{5}{4\kappa}\biggl(\frac{1}{\kappa} - \frac{1}{\mathrm{atanh}(\kappa)} \biggr) \mathrm{\ for\ } \kappa &gt; 0\mbox{,}</code>
</p>

<p style="text-align: center;"><code class="reqn">\tau_4 = -\frac{1}{4} - \frac{5}{4\kappa}\biggl(\frac{1}{\kappa} - \frac{1}{\mathrm{atan}(\kappa)} \biggr) \mathrm{\ for\ } \kappa &lt; 0\mbox{,}</code>
</p>



<h3>Usage</h3>

<pre><code class='language-R'>lmompdq4(para, paracheck=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lmompdq4_+3A_para">para</code></td>
<td>
<p>The parameters of the distribution.</p>
</td></tr>
<tr><td><code id="lmompdq4_+3A_paracheck">paracheck</code></td>
<td>
<p>A logical switch as to whether the validity of the parameters should be checked. Default is <code>paracheck=TRUE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> is returned.
</p>
<table>
<tr><td><code>lambdas</code></td>
<td>
<p>Vector of the L-moments. First element is
<code class="reqn">\lambda_1</code>, second element is <code class="reqn">\lambda_2</code>, and so on.</p>
</td></tr>
<tr><td><code>ratios</code></td>
<td>
<p>Vector of the L-moment ratios. Second element is
<code class="reqn">\tau</code>, third element is <code class="reqn">\tau_3</code> and so on.</p>
</td></tr>
<tr><td><code>trim</code></td>
<td>
<p>Level of symmetrical trimming used in the computation, which is <code>0</code>.</p>
</td></tr>
<tr><td><code>leftrim</code></td>
<td>
<p>Level of left-tail trimming used in the computation, which is <code>NULL</code>.</p>
</td></tr>
<tr><td><code>rightrim</code></td>
<td>
<p>Level of right-tail trimming used in the computation, which is <code>NULL</code>.</p>
</td></tr>
<tr><td><code>ifail</code></td>
<td>
<p>A numeric field connected to the <code>ifailtext</code>; a value of 0 indicates fully successful operation of the function.</p>
</td></tr>
<tr><td><code>ifailtext</code></td>
<td>
<p>A message, instead of a warning, about the internal operations or operational limits of the function.</p>
</td></tr>
<tr><td><code>source</code></td>
<td>
<p>An attribute identifying the computational
source of the L-moments: &ldquo;lmompdq4&rdquo;.</p>
</td></tr>
</table>


<h3>Note</h3>

<p><b>What L-kurtosis produces the widest 95th-percentile bounds?</b>&mdash;Study of the shapes of the PDQ4 will show that with support for <code class="reqn">\tau_4</code> much less and even negative and much more than the <code class="reqn">\tau_4 = 0.122602</code> defined into the Normal distribution considerable variation. The widths or spreads between quantiles moderately deep into the tails might be interesting to study. Consider the code that follows that seeks the <code class="reqn">\tau_4</code> that will produce the widest 95th-percentile bounds:
</p>
<pre>
  ofunc &lt;- function(t4,  lscale=NA) {
    lmr &lt;- vec2lmom(c(0, lscale, 0, t4))
    if(! are.lmom.valid(lmr)) return(-Inf)
    pdq4  &lt;- lmomco::parpdq4(lmr, snapt4uplimit=FALSE)
    return(-diff(lmomco::quapdq4(c(0.025, 0.975), pdq4)))
  }
  optim(0.2, ofunc, lscale=1)$par # [1] 0.4079688
</pre>
<p>The code maximizes at about <code class="reqn">\tau_4 = 0.4079688</code>. It is informative to visualizing the nature of the objective function. In the code below, we standardize the width by division of the <code class="reqn">\lambda_2 = 1</code> for generality and because of symmetry only the 97.5th percentile requires study:
</p>
<pre>
  lscale &lt;- 1
  tau4s  &lt;- seq(-1/4, 0.9, by=0.01)
  qua975s &lt;- rep(NA, length(tau4s))
  for(i in 1:length(tau4s)) {
    lmr &lt;- vec2lmom(c(0, lscale, 0, tau4s[i]))
    if(! are.lmom.valid(lmr)) next
    pdq4 &lt;- lmomco::parpdq4(lmr, snapt4uplimit=FALSE)
    quas &lt;- lmomco::quapdq4(c(0.025, 0.975), pdq4)
    qua975s[i] &lt;- quas[2] / lscale
  }
  plot(tau4s, qua975s, ylim=c(-0.1, 5), col="blue")
  abline(v=0.845, lty=2) # supporting the "snaptau4uplimit" in parpdq4().
  abline(v=0.4079688, col=2, lwd=2)
  abline(h=qnorm(0.975, sd=sqrt(pi)), col="green", lty=3, lwd=3)
</pre>
<p>The figure so produces shows that the maximum at the red vertical line for <code class="reqn">\tau_4</code> is at the crest of the blue points. The figure shows that for <code class="reqn">\tau_4 &gt;= 0.845</code> that numerical problems manifest and contribute to an snapping limit of <code class="reqn">\tau_4</code> in <code><a href="#topic+parpdq4">parpdq4</a></code>. The figure also shows with a dotted green line that the equivalent percentile of the Normal distribution with a standard deviation equivalent to the <code class="reqn">\lambda_2 = 1</code> has two intersections on the widths of the PDQ4.
</p>
<p>Now some further experiments on the apparent computational limits to <code class="reqn">\tau_4</code> can be made using the code that follows. This support the threshold of <code class="reqn">\tau_4 \le 0.845</code> embedded into <code><a href="#topic+parpdq4">parpdq4</a></code> through the use of the <code><a href="#topic+theoTLmoms">theoTLmoms</a></code> function.
</p>
<pre>
  t4s &lt;- seq(-1/4, 1, by=0.02)
  t4s &lt;- t4s[t4s &gt; -1/4 &amp; t4s &lt; 1]
  l2s_theo &lt;- t4s_theo &lt;- t6s_theo &lt;- rep(NA, length(t4s))
  for(i in 1:length(t4s)) {
    lmr  &lt;- vec2lmom(c(0, 1, 0, t4s[i]))
    suppressWarnings(par &lt;- parpdq4(lmr, snapt4uplimit=FALSE))
    tlmr &lt;- theoTLmoms(par, nmom=6, trim=0)
    l2s_theo[i] &lt;- tlmr$lambdas[2]
    t4s_theo[i] &lt;- tlmr$ratios[ 4]
    t6s_theo[i] &lt;- tlmr$ratios[ 6]
  }
  plot(  t4s_theo, l2s_theo, type="l")
  points(t4s_theo, l2s_theo)
    abline(v=0.864, lty=2) # see "snaptau4uplimit" in parpdq4()
    abline(v=0.845, lty=2) # see "snaptau4uplimit" in parpdq4()
  plot(  t4s_theo, t4s,      type="l")
  points(t4s_theo, t4s)
    abline(v=0.864, lty=2) # see "snaptau4uplimit" in parpdq4()
    abline(v=0.845, lty=2) # see "snaptau4uplimit" in parpdq4()
  plot(  t4s_theo, t6s_theo, type="l")
  points(t4s_theo, t6s_theo)
    abline(v=0.864, lty=2) # see "snaptau4uplimit" in parpdq4()
    abline(v=0.845, lty=2) # see "snaptau4uplimit" in parpdq4()
</pre>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Hosking, J.R.M., 2007, Distributions with maximum entropy subject to constraints on their L-moments or expected order statistics: Journal of Statistical Planning and Inference, v. 137, no. 9, pp. 2870&ndash;2891, <a href="https://doi.org/10.1016/j.jspi.2006.10.010">doi:10.1016/j.jspi.2006.10.010</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+parpdq4">parpdq4</a></code>, <code><a href="#topic+cdfpdq4">cdfpdq4</a></code>, <code><a href="#topic+pdfpdq4">pdfpdq4</a></code>, <code><a href="#topic+quapdq4">quapdq4</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>para &lt;- vec2par(c(0, 1, -100), type="pdq4")
lmompdq4(  para)$ratios[4]                 # -0.2421163
theoTLmoms(para, nmom=6, trim=0)$ratios[4] # -0.2421163
theoTLmoms(para, nmom=6, trim=1)$ratios[4] # -0.2022106
theoTLmoms(para, nmom=6, trim=2)$ratios[4] # -0.1697186

## Not run: 
  para &lt;- list(para=c(20, 1, -0.5), type="pdq4")
  lmoms(quapdq4(runif(100000), para))$lambdas
  lmompdq4(para)$lambdas #
## End(Not run)

## Not run: 
  para &lt;- list(para=c(20, 1, +0.5), type="pdq4")
  lmoms(quapdq4(runif(100000), para))$lambdas
  lmompdq4(para)$lambdas #
## End(Not run)

## Not run: 
  K1 &lt;- seq(-5, 0, by=0.001)
  K2 &lt;- seq( 0, 1, by=0.001)
  suppressWarnings(mono_decrease_part1 &lt;- -(1/4) + (5/(4*K1)) * (1/K1 - 1/atanh(K1)))
                   mono_increase_part2 &lt;- -(1/4) - (5/(4*K1)) * (1/K1 - 1/atan( K1))
                   mono_increase_part1 &lt;- -(1/4) + (5/(4*K2)) * (1/K2 - 1/atanh(K2))
                   mono_decrease_part2 &lt;- -(1/4) - (5/(4*K2)) * (1/K2 - 1/atan( K2))

  plot( 0, 0, type="n", xlim=range(c(K1, K2)), ylim=c(-0.25, 1),
       xlab="Kappa shape parameter PDQ4 distribution", ylab="L-kurtosis (Tau4)")
  lines(K1, mono_decrease_part1, col=4, lwd=0.3)
  lines(K2, mono_increase_part1, col=4, lwd=3)
  lines(K2, mono_decrease_part2, col=2, lwd=0.3)
  lines(K1, mono_increase_part2, col=2, lwd=3)

  abline(h= 1/6, lty=2, lwd=0.6)
  abline(h=-1/4, lty=2, lwd=0.6)
  text(-5, -1/4, "Tau4 lower bounds", pos=4, cex=0.8)
  abline(v=0,    lty=2, lwd=0.6)
  abline(v=1,    lty=1, lwd=0.9)
  points(-0.7029, 0.1226, pch=15, col="darkgreen")

  # bigTAU4 &lt;- 0.845 # see parpdq4.R and parpdq4.Rd
  pdq4 &lt;- parpdq4(vec2lmom(c(0, 1, 0, 0.845)), snapt4uplimit=FALSE)
  points(pdq4$para[3], 0.845, cex=1.5, pch=17, col="blue")

  legend("topleft", c("Monotonic increasing for kappa &lt; 0 (used for PDQ4)",
                      "Monotonic increasing for kappa &gt; 0 (used for PDQ4)",
                      "Monotonic decreasing for kappa &gt; 0 (not used for PDQ4)",
                      "Monotonic decreasing for kappa &lt; 0 (not used for PDQ4)",
                      "Normal distribution (Tau4=0.122602 by definition)",
                      "Operational upper limit of Tau4 before numerical problems"), cex=0.8,
     pch=c(NA, NA, NA, NA, 15, 17), lwd=c(3,3, 0.3, 0.3, NA, NA),
     pt.cex=c(NA, NA, NA, NA, 1, 1.5), col=c(2, 4, 2, 4, "darkgreen", "blue")) # 
## End(Not run)
</code></pre>

<hr>
<h2 id='lmompe3'>L-moments of the Pearson Type III Distribution</h2><span id='topic+lmompe3'></span>

<h3>Description</h3>

<p>This function estimates the L-moments of the Pearson Type III distribution given the parameters (<code class="reqn">\mu</code>, <code class="reqn">\sigma</code>, and <code class="reqn">\gamma</code>) from <code><a href="#topic+parpe3">parpe3</a></code> as the product moments: mean, standard deviation, and skew. The first three L-moments in terms of these parameters are complex and numerical methods are required. For simplier expression of the distribution functions (<code><a href="#topic+cdfpe3">cdfpe3</a></code>, <code><a href="#topic+pdfpe3">pdfpe3</a></code>, and <code><a href="#topic+quape3">quape3</a></code>) the &ldquo;moment parameters&rdquo; are expressed differently.
</p>
<p>The Pearson Type III distribution is of considerable theoretical interest because the parameters, which are estimated via the L-moments, are in fact the product moments. Although, these values fitted by the method of L-moments will not be numerically equal to the sample product moments.  Further details are provided in the Examples section of the <code><a href="#topic+pmoms">pmoms</a></code> function documentation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lmompe3(para)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lmompe3_+3A_para">para</code></td>
<td>
<p>The parameters of the distribution.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> is returned.
</p>
<table>
<tr><td><code>lambdas</code></td>
<td>
<p>Vector of the L-moments. First element is
<code class="reqn">\lambda_1</code>, second element is <code class="reqn">\lambda_2</code>, and so on.</p>
</td></tr>
<tr><td><code>ratios</code></td>
<td>
<p>Vector of the L-moment ratios. Second element is
<code class="reqn">\tau</code>, third element is <code class="reqn">\tau_3</code> and so on.</p>
</td></tr>
<tr><td><code>trim</code></td>
<td>
<p>Level of symmetrical trimming used in the computation, which is <code>0</code>.</p>
</td></tr>
<tr><td><code>leftrim</code></td>
<td>
<p>Level of left-tail trimming used in the computation, which is <code>NULL</code>.</p>
</td></tr>
<tr><td><code>rightrim</code></td>
<td>
<p>Level of right-tail trimming used in the computation, which is <code>NULL</code>.</p>
</td></tr>
<tr><td><code>source</code></td>
<td>
<p>An attribute identifying the computational
source of the L-moments: &ldquo;lmompe3&rdquo;.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Hosking, J.R.M., 1990, L-moments&mdash;Analysis and estimation of distributions using linear combinations of order statistics: Journal of the Royal Statistical Society, Series B, v. 52, pp. 105&ndash;124.
</p>
<p>Hosking, J.R.M., 1996, FORTRAN routines for use with the method of L-moments: Version 3, IBM Research Report RC20525, T.J. Watson Research Center, Yorktown Heights, New York.
</p>
<p>Hosking, J.R.M., and Wallis, J.R., 1997, Regional frequency analysis&mdash;An approach based on L-moments: Cambridge University Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+parpe3">parpe3</a></code>, <code><a href="#topic+cdfpe3">cdfpe3</a></code>, <code><a href="#topic+pdfpe3">pdfpe3</a></code>, <code><a href="#topic+quape3">quape3</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>lmr &lt;- lmoms(c(123,34,4,654,37,78))
lmr
lmompe3(parpe3(lmr))
</code></pre>

<hr>
<h2 id='lmomray'>L-moments of the Rayleigh Distribution</h2><span id='topic+lmomray'></span>

<h3>Description</h3>

<p>This function estimates the L-moments of the Rayleigh distribution given the parameters (<code class="reqn">\xi</code> and <code class="reqn">\alpha</code>) from <code><a href="#topic+parray">parray</a></code>. The L-moments in terms of the parameters are
</p>
<p style="text-align: center;"><code class="reqn">\lambda_1 = \xi + \alpha\sqrt{\pi/2} \mbox{,}</code>
</p>

<p style="text-align: center;"><code class="reqn">\lambda_2 = \frac{1}{2} \alpha(\sqrt{2} - 1)\sqrt{\pi}\mbox{,}</code>
</p>

<p style="text-align: center;"><code class="reqn">\tau_3 = \frac{1 - 3/\sqrt{2} + 2/\sqrt{3}}{1 - 1/\sqrt{2}} = 0.1140 \mbox{, and}</code>
</p>

<p style="text-align: center;"><code class="reqn">\tau_4 = \frac{1 - 6/\sqrt{2} +  10/\sqrt{3} - 5\sqrt{4}}{1 - 1/\sqrt{2}} = 0.1054 \mbox{.}</code>
</p>



<h3>Usage</h3>

<pre><code class='language-R'>lmomray(para)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lmomray_+3A_para">para</code></td>
<td>
<p>The parameters of the distribution.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> is returned.
</p>
<table>
<tr><td><code>lambdas</code></td>
<td>
<p>Vector of the L-moments. First element is
<code class="reqn">\lambda_1</code>, second element is <code class="reqn">\lambda_2</code>, and so on.</p>
</td></tr>
<tr><td><code>ratios</code></td>
<td>
<p>Vector of the L-moment ratios. Second element is
<code class="reqn">\tau</code>, third element is <code class="reqn">\tau_3</code> and so on.</p>
</td></tr>
<tr><td><code>trim</code></td>
<td>
<p>Level of symmetrical trimming used in the computation, which is <code>0</code>.</p>
</td></tr>
<tr><td><code>leftrim</code></td>
<td>
<p>Level of left-tail trimming used in the computation, which is <code>NULL</code>.</p>
</td></tr>
<tr><td><code>rightrim</code></td>
<td>
<p>Level of right-tail trimming used in the computation, which is <code>NULL</code>.</p>
</td></tr>
<tr><td><code>source</code></td>
<td>
<p>An attribute identifying the computational
source of the L-moments: &ldquo;lmomray&rdquo;.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Hosking, J.R.M., 1986, The theory of probability weighted moments: Research Report RC12210, IBM Research Division, Yorkton Heights, N.Y.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+parray">parray</a></code>, <code><a href="#topic+cdfray">cdfray</a></code>, <code><a href="#topic+pdfray">pdfray</a></code>, <code><a href="#topic+quaray">quaray</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>lmr &lt;- lmoms(c(123,34,4,654,37,78))
lmr
lmomray(parray(lmr))
</code></pre>

<hr>
<h2 id='lmomRCmark'>Sample L-moment for Right-Tail Censoring by a Marking Variable </h2><span id='topic+lmomRCmark'></span>

<h3>Description</h3>

<p>Compute the sample L-moments for right-tail censored data set in which censored data values are identified by a marking variable.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lmomRCmark(x, rcmark=NULL, r=1, sort=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lmomRCmark_+3A_x">x</code></td>
<td>
<p>A vector of data values.</p>
</td></tr>
<tr><td><code id="lmomRCmark_+3A_rcmark">rcmark</code></td>
<td>
<p>The right-tail censoring (upper) marking variable for unknown threshold: 1 is uncensored, 0 is censored.</p>
</td></tr>
<tr><td><code id="lmomRCmark_+3A_r">r</code></td>
<td>
<p>The L-moment order to return, default is the mean.</p>
</td></tr>
<tr><td><code id="lmomRCmark_+3A_sort">sort</code></td>
<td>
<p>Do the data need sorting? The availability of this option is to avoid unnecessary overhead of sorting on each call to this function by the primary higher-level function <code><a href="#topic+lmomsRCmark">lmomsRCmark</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> is returned.
</p>
<table>
<tr><td><code>lambdas</code></td>
<td>
<p>Vector of the L-moments. First element is
<code class="reqn">\hat{\lambda}^{(0,0)}_1</code>, second element is <code class="reqn">\hat{\lambda}^{(0,0)}_2</code>, and so on.</p>
</td></tr>
<tr><td><code>ratios</code></td>
<td>
<p>Vector of the L-moment ratios. Second element is
<code class="reqn">\hat{\tau}^{(0,0)}</code>, third element is <code class="reqn">\hat{\tau}^{(0,0)}_3</code> and so on.</p>
</td></tr>
<tr><td><code>trim</code></td>
<td>
<p>Level of symmetrical trimming used in the computation, which will equal <code>NULL</code> if asymmetrical trimming was used.</p>
</td></tr>
<tr><td><code>leftrim</code></td>
<td>
<p>Level of left-tail trimming used in the computation.</p>
</td></tr>
<tr><td><code>rightrim</code></td>
<td>
<p>Level of right-tail trimming used in the computation.</p>
</td></tr>
<tr><td><code>source</code></td>
<td>
<p>An attribute identifying the computational source of the L-moments: &ldquo;lmomsRCmark&rdquo;.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Wang, Dongliang, Hutson, A.D., Miecznikowski, J.C., 2010, L-moment estimation for parametric survival models given censored data: Statistical Methodology, v. 7, no. 6, pp. 655&ndash;667.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lmomsRCmark">lmomsRCmark</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'># See example under lmomsRCmark
</code></pre>

<hr>
<h2 id='lmomrevgum'>L-moments of the Reverse Gumbel Distribution</h2><span id='topic+lmomrevgum'></span>

<h3>Description</h3>

<p>This function estimates the L-moments of the Reverse Gumbel distribution given the parameters (<code class="reqn">\xi</code> and <code class="reqn">\alpha</code>) from <code><a href="#topic+parrevgum">parrevgum</a></code>. The first two type-B L-moments in terms of the parameters are
</p>
<p style="text-align: center;"><code class="reqn">\lambda^B_1 = \xi - (0.5722\dots) \alpha  - \alpha\lbrace\mathrm{Ei}(-\log(1-\zeta))\rbrace\mbox{and}</code>
</p>

<p style="text-align: center;"><code class="reqn">\lambda^B_2 = \alpha\lbrace\log(2) + \mathrm{Ei}(-2\log(1-\zeta)) - \mathrm{Ei}(-\log(1-\zeta))\rbrace\mbox{,}</code>
</p>

<p>where <code class="reqn">\zeta</code> is the right-tail censoring fraction of the sample or the nonexceedance probability of the right-tail censoring threshold, and <code class="reqn">\mathrm{Ei}(x)</code> is the exponential integral defined as
</p>
<p style="text-align: center;"><code class="reqn"> \mathrm{Ei}(X) = \int_X^{\infty} x^{-1}\mathrm{exp}(-x)\mathrm{d}x \mbox{,}</code>
</p>

<p>where <code class="reqn">\mathrm{Ei}(-\log(1-\zeta)) \rightarrow 0</code> as <code class="reqn">\zeta \rightarrow 1</code> and <code class="reqn">\mathrm{Ei}(-\log(1-\zeta))</code> can not be evaluated as <code class="reqn">\zeta \rightarrow 0</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lmomrevgum(para)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lmomrevgum_+3A_para">para</code></td>
<td>
<p>The parameters of the distribution.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> is returned.
</p>
<table>
<tr><td><code>lambdas</code></td>
<td>
<p>Vector of the L-moments. First element is
<code class="reqn">\lambda_1</code>, second element is <code class="reqn">\lambda_2</code>, and so on.</p>
</td></tr>
<tr><td><code>ratios</code></td>
<td>
<p>Vector of the L-moment ratios. Second element is
<code class="reqn">\tau</code>, third element is <code class="reqn">\tau_3</code> and so on.</p>
</td></tr>
<tr><td><code>trim</code></td>
<td>
<p>Level of symmetrical trimming used in the computation, which is <code>0</code>.</p>
</td></tr>
<tr><td><code>leftrim</code></td>
<td>
<p>Level of left-tail trimming used in the computation, which is <code>NULL</code>.</p>
</td></tr>
<tr><td><code>rightrim</code></td>
<td>
<p>Level of right-tail trimming used in the computation, which is <code>NULL</code>.</p>
</td></tr>
<tr><td><code>zeta</code></td>
<td>
<p>Number of samples observed (noncensored) divided by the total number of samples.</p>
</td></tr>
<tr><td><code>source</code></td>
<td>
<p>An attribute identifying the computational
source of the L-moments: &ldquo;lmomrevgum&rdquo;.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Hosking, J.R.M., 1995, The use of L-moments in the analysis of censored data, in Recent Advances in Life-Testing and Reliability, edited by N. Balakrishnan, chapter 29, CRC Press, Boca Raton, Fla., pp. 546&ndash;560.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+parrevgum">parrevgum</a></code>, <code><a href="#topic+cdfrevgum">cdfrevgum</a></code>, <code><a href="#topic+pdfrevgum">pdfrevgum</a></code>, <code><a href="#topic+quarevgum">quarevgum</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>lmr &lt;- lmoms(c(123,34,4,654,37,78))
rev.para &lt;- lmom2par(lmr,type='revgum')
lmomrevgum(rev.para)
</code></pre>

<hr>
<h2 id='lmomrice'>L-moments of the Rice Distribution</h2><span id='topic+lmomrice'></span>

<h3>Description</h3>

<p>This function estimates the L-moments of the Rice distribution given the parameters (<code class="reqn">\nu</code> and <code class="reqn">\alpha</code>) from <code><a href="#topic+parrice">parrice</a></code>. The L-moments in terms of the parameters are complex. They are computed here by the system of maximum order statistic expectations from <code><a href="#topic+theoLmoms.max.ostat">theoLmoms.max.ostat</a></code>, which uses <code><a href="#topic+expect.max.ostat">expect.max.ostat</a></code>. The connection between <code class="reqn">\tau_2</code> and <code class="reqn">\nu/\alpha</code> and a special function (the Laguerre polynomial, <code><a href="#topic+LaguerreHalf">LaguerreHalf</a></code>) of <code class="reqn">\nu^2/\alpha^2</code> and additional algebraic terms is tabulated in the <span class="rlang"><b>R</b></span> <code>data.frame</code> located within <span class="env">.lmomcohash$RiceTable</span>. The file &lsquo;<span class="file">SysDataBuilder01.R</span>&rsquo; provides additional details.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lmomrice(para, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lmomrice_+3A_para">para</code></td>
<td>
<p>The parameters of the distribution.</p>
</td></tr>
<tr><td><code id="lmomrice_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to <code><a href="#topic+theoLmoms.max.ostat">theoLmoms.max.ostat</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> is returned.
</p>
<table>
<tr><td><code>lambdas</code></td>
<td>
<p>Vector of the L-moments. First element is
<code class="reqn">\lambda_1</code>, second element is <code class="reqn">\lambda_2</code>, and so on.</p>
</td></tr>
<tr><td><code>ratios</code></td>
<td>
<p>Vector of the L-moment ratios. Second element is
<code class="reqn">\tau</code>, third element is <code class="reqn">\tau_3</code> and so on.</p>
</td></tr>
<tr><td><code>trim</code></td>
<td>
<p>Level of symmetrical trimming used in the computation, which is <code>0</code>.</p>
</td></tr>
<tr><td><code>leftrim</code></td>
<td>
<p>Level of left-tail trimming used in the computation, which is <code>NULL</code>.</p>
</td></tr>
<tr><td><code>rightrim</code></td>
<td>
<p>Level of right-tail trimming used in the computation, which is <code>NULL</code>.</p>
</td></tr>
<tr><td><code>source</code></td>
<td>
<p>An attribute identifying the computational
source of the L-moments: &ldquo;lmomrice&rdquo;, but the exact contents of the remainder of the string might vary as limiting distributions of Normal and Rayleigh can be involved for <code class="reqn">\nu/\alpha &gt; 52</code> (super high SNR, Normal) or <code class="reqn">24 &lt; \nu/\alpha \le 52</code> (high SNR, Normal) or <code class="reqn">\nu/\alpha &lt; 0.08</code> (very low SNR, Rayleigh).</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Asquith, W.H., 2011, Distributional analysis with L-moment statistics using the R environment for statistical computing: Createspace Independent Publishing Platform, ISBN 978&ndash;146350841&ndash;8.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+parrice">parrice</a></code>, <code><a href="#topic+cdfrice">cdfrice</a></code>, <code><a href="#topic+cdfrice">cdfrice</a></code>, <code><a href="#topic+quarice">quarice</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
lmomrice(vec2par(c(65,34), type="rice"))

# Use the additional arguments to show how to avoid unnecessary overhead
# when using the Rice, which only has two parameters.
  rice &lt;- vec2par(c(15,14), type="rice")
  system.time(lmomrice(rice, nmom=2)); system.time(lmomrice(rice, nmom=6))

  lcvs &lt;- vector(mode="numeric"); i &lt;- 0
  SNR  &lt;- c(seq(7,0.25, by=-0.25), 0.1)
  for(snr in SNR) {
    i &lt;- i + 1
    rice    &lt;- vec2par(c(10,10/snr), type="rice")
    lcvs[i] &lt;- lmomrice(rice, nmom=2)$ratios[2]
  }
  plot(lcvs, SNR,
       xlab="COEFFICIENT OF L-VARIATION",
       ylab="LOCAL SIGNAL TO NOISE RATIO (NU/ALPHA)")
  lines(.lmomcohash$RiceTable$LCV,
        .lmomcohash$RiceTable$SNR)
  abline(1,0, lty=2)
  mtext("Rice Distribution")
  text(0.15,0.5, "More noise than signal")
  text(0.15,1.5, "More signal than noise")

## End(Not run)
## Not run: 
# A polynomial expression for the relation between L-skew and
# L-kurtosis for the Rice distribution can be readily constructed.
T3 &lt;- .lmomcohash$RiceTable$TAU3
T4 &lt;- .lmomcohash$RiceTable$TAU4
LM &lt;- lm(T4~T3+I(T3^2)+I(T3^3)+I(T3^4)+
               I(T3^5)+I(T3^6)+I(T3^7)+I(T3^8))
summary(LM) # note shown
## End(Not run)
</code></pre>

<hr>
<h2 id='lmoms'>The Sample L-moments and L-moment Ratios </h2><span id='topic+lmoms'></span>

<h3>Description</h3>

<p>Compute the sample L-moments. The mathematical expression for sample L-moment computation is shown under <code><a href="#topic+TLmoms">TLmoms</a></code>. The formula jointly handles sample L-moment computation and sample TL-moment (Elamir and Seheult, 2003) computation. A description of the most common L-moments is provided under <code><a href="#topic+lmom.ub">lmom.ub</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lmoms(x, nmom=5, no.stop=FALSE, vecit=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lmoms_+3A_x">x</code></td>
<td>
<p>A vector of data values.</p>
</td></tr>
<tr><td><code id="lmoms_+3A_nmom">nmom</code></td>
<td>
<p>The number of moments to compute. Default is 5.</p>
</td></tr>
<tr><td><code id="lmoms_+3A_no.stop">no.stop</code></td>
<td>
<p>A logical to return <code>NULL</code> instead of issuing a <code>stop()</code> if <code>nmom</code> is greater than the sample size or if all the values are equal. This is a very late change (decade+) to the foundational function in the package. Auxiliary coding to above this function to avoid the internal <code>stop()</code> became non-ignorable in large data mining exercises. It was a design mistake to have the <code>stop()</code> and not a <code>warning()</code> instead.</p>
</td></tr>
<tr><td><code id="lmoms_+3A_vecit">vecit</code></td>
<td>
<p>A logical to return the first two <code class="reqn">\lambda_i \in 1,2</code> and then the <code class="reqn">\tau_i \in 3,\cdots</code> where the length of the returned vector is controlled by the <code>nmom</code> argument. This argument will store the trims (see <code><a href="#topic+TLmoms">TLmoms</a></code>) as <code>NULL</code> used (see the <b>Example</b> that follows).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> is returned.
</p>
<table>
<tr><td><code>lambdas</code></td>
<td>
<p>Vector of the L-moments. First element is
<code class="reqn">\hat{\lambda}^{(0,0)}_1</code>, second element is <code class="reqn">\hat{\lambda}^{(0,0)}_2</code>, and so on.</p>
</td></tr>
<tr><td><code>ratios</code></td>
<td>
<p>Vector of the L-moment ratios. Second element is
<code class="reqn">\hat{\tau}^{(0,0)}</code>, third element is <code class="reqn">\hat{\tau}^{(0,0)}_3</code> and so on.</p>
</td></tr>
<tr><td><code>trim</code></td>
<td>
<p>Level of symmetrical trimming used in the computation, which will equal <code>NULL</code> if asymmetrical trimming was used.</p>
</td></tr>
<tr><td><code>leftrim</code></td>
<td>
<p>Level of left-tail trimming used in the computation.</p>
</td></tr>
<tr><td><code>rightrim</code></td>
<td>
<p>Level of right-tail trimming used in the computation.</p>
</td></tr>
<tr><td><code>source</code></td>
<td>
<p>An attribute identifying the computational source of the L-moments: &ldquo;lmoms&rdquo;.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>This function computes the L-moments through the generalization of the TL-moments (<code><a href="#topic+TLmoms">TLmoms</a></code>). In fact, this function calls the default TL-moments with no trimming of the sample. This function is equivalent to <code><a href="#topic+lmom.ub">lmom.ub</a></code>, but returns a different data structure. The <code><a href="#topic+lmoms">lmoms</a></code> function is preferred by the author.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Asquith, W.H., 2011, Distributional analysis with L-moment statistics using the R environment for statistical computing: Createspace Independent Publishing Platform, ISBN 978&ndash;146350841&ndash;8.
</p>
<p>Elamir, E.A.H., and Seheult, A.H., 2003, Trimmed L-moments: Computational statistics and data analysis, vol. 43, pp. 299-314.
</p>
<p>Hosking, J.R.M., 1990, L-moments&mdash;Analysis and estimation of
distributions using linear combinations of order statistics: Journal of the Royal Statistical Society, Series B, v. 52, pp. 105&ndash;124.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lmom.ub">lmom.ub</a></code>, <code><a href="#topic+TLmoms">TLmoms</a></code>, <code><a href="#topic+lmorph">lmorph</a></code>, <code><a href="#topic+lmoms.bernstein">lmoms.bernstein</a></code>, <code><a href="#topic+vec2lmom">vec2lmom</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>lmoms(rnorm(30),nmom=4)

vec2lmom(lmoms(rexp(30), nmom=3, vecit=TRUE)) # re-vector
</code></pre>

<hr>
<h2 id='lmoms.bernstein'>Numerically Integrated L-moments of Smoothed Quantiles from Bernstein or Kantorovich Polynomials </h2><span id='topic+lmoms.bernstein'></span>

<h3>Description</h3>

<p>Compute the L-moment by numerical integration of the smoothed quantiles from Bernstein or Kantorovich polynomials (see <code><a href="#topic+dat2bernqua">dat2bernqua</a></code>). Letting <code class="reqn">\tilde{X}_n(F)</code> be the smoothed quantile function for nonexceedance probability <code class="reqn">F</code> for a sample of size <code class="reqn">n</code>, from Asquith (2011) the first five L-moments in terms of quantile function integration are
</p>
<p style="text-align: center;"><code class="reqn">\lambda_1 = \int_0^1 \tilde{X}_n(F)\;\mathrm{d}F \mbox{,}</code>
</p>

<p style="text-align: center;"><code class="reqn">\lambda_2 = \int_0^1 \tilde{X}_n(F)\times(2F - 1)\;\mathrm{d}F\mbox{,}</code>
</p>

<p style="text-align: center;"><code class="reqn">\lambda_3 = \int_0^1 \tilde{X}_n(F)\times(6F^2 - 6F + 1)\;\mathrm{d}F\mbox{,}</code>
</p>

<p style="text-align: center;"><code class="reqn">\lambda_4 = \int_0^1 \tilde{X}_n(F)\times(20F^3 - 30F^2 + 12F - 1)\;\mathrm{d}F\mbox{, and}</code>
</p>

<p style="text-align: center;"><code class="reqn">\lambda_5 = \int_0^1 \tilde{X}_n(F)\times(70F^4 - 140F^3 + 90F^2 - 20F + 1)\;\mathrm{d}F\mbox{.}</code>
</p>



<h3>Usage</h3>

<pre><code class='language-R'>lmoms.bernstein(x, bern.control=NULL,
                   poly.type=c("Bernstein", "Kantorovich", "Cheng"),
                   bound.type=c("none", "sd", "Carv", "either"),
                   fix.lower=NULL, fix.upper=NULL, p=0.05)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lmoms.bernstein_+3A_x">x</code></td>
<td>
<p>A vector of data values.</p>
</td></tr>
<tr><td><code id="lmoms.bernstein_+3A_bern.control">bern.control</code></td>
<td>
<p>A <code>list</code> that holds <code>poly.type</code>, <code>bound.type</code>, <code>fix.lower</code>, and <code>fix.upper</code>. And this list will supersede the respective
values provided as separate arguments.</p>
</td></tr>
<tr><td><code id="lmoms.bernstein_+3A_poly.type">poly.type</code></td>
<td>
<p>Same argument as for <code><a href="#topic+dat2bernqua">dat2bernqua</a></code>.</p>
</td></tr>
<tr><td><code id="lmoms.bernstein_+3A_bound.type">bound.type</code></td>
<td>
<p>Same argument as for <code><a href="#topic+dat2bernqua">dat2bernqua</a></code>.</p>
</td></tr>
<tr><td><code id="lmoms.bernstein_+3A_fix.lower">fix.lower</code></td>
<td>
<p>Same argument as for <code><a href="#topic+dat2bernqua">dat2bernqua</a></code>.</p>
</td></tr>
<tr><td><code id="lmoms.bernstein_+3A_fix.upper">fix.upper</code></td>
<td>
<p>Same argument as for <code><a href="#topic+dat2bernqua">dat2bernqua</a></code>.</p>
</td></tr>
<tr><td><code id="lmoms.bernstein_+3A_p">p</code></td>
<td>
<p>The &ldquo;p-factor&rdquo; is the same argument as for <code><a href="#topic+dat2bernqua">dat2bernqua</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>vector</code> is returned.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Asquith, W.H., 2011, Distributional analysis with L-moment statistics using the R environment for statistical computing: Createspace Independent Publishing Platform, ISBN 978&ndash;146350841&ndash;8.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+dat2bernqua">dat2bernqua</a></code>, <code><a href="#topic+pfactor.bernstein">pfactor.bernstein</a></code>, <code><a href="#topic+lmoms">lmoms</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
X &lt;- exp(rnorm(100))
lmoms.bernstein(X)$ratios
lmoms.bernstein(X, fix.lower=0)$ratios
lmoms.bernstein(X, fix.lower=0, bound.type="sd")$ratios
lmoms.bernstein(X, fix.lower=0, bound.type="Carv")$ratios
lmoms(X)$ratios

lmoms.bernstein(X, poly.type="Kantorovich")$ratios
lmoms.bernstein(X, fix.lower=0, poly.type="Kantorovich")$ratios
lmoms.bernstein(X, fix.lower=0, bound.type="sd", poly.type="Kantorovich")$ratios
lmoms.bernstein(X, fix.lower=0, bound.type="Carv", poly.type="Kantorovich")$ratios
lmoms(X)$ratios

## End(Not run)

## Not run: 
lmr &lt;- vec2lmom(c(1,.2,.3))
par &lt;- lmom2par(lmr, type="gev")
lmr &lt;- lmorph(par2lmom(par))
lmT &lt;- c(lmr$lambdas[1:2], lmr$ratios[3:5])
ns  &lt;- 200; nsim &lt;- 1000; empty &lt;- rep(NA, nsim)

sink("ChengLmomentTest.txt")
cat(c("N errmeanA  errlscaleA  errtau3A  errtau4A  errtau5A",
        "errmeanB  errlscaleB  errtau3B  errtau4B  errtau5B\n"))
for(n in 1:ns) {
   message(n);
   SIM &lt;- data.frame(errmeanA=empty, errlscaleA=empty,   errtau3A=empty, errtau4A=empty,
                     errtau5A=empty,   errmeanB=empty, errlscaleB=empty, errtau3B=empty,
                     errtau4B=empty,   errtau5B=empty)
   for(i in 1:nsim) {
      X &lt;- rlmomco(30, par)
      lmrA &lt;- lmoms(X)
      lmA &lt;- c(lmrA$lambdas[1:2], lmrA$ratios[3:5])
      lmrB &lt;- lmoms.bernstein(X, poly.type="Cheng")
      lmB &lt;- c(lmrB$lambdas[1:2], lmrB$ratios[3:5])
      EA &lt;- lmA - lmT; EB &lt;- lmB - lmT
      SIM[i,] &lt;- c(EA,EB)
   }
   MeanErr &lt;- sapply(1:length(SIM[1,]), function(x) { return(mean(SIM[,x])) })
   line &lt;- paste(c(n, round(MeanErr, digits=6), "\n"), sep=" ")
   cat(line)
}
sink()

## End(Not run)
</code></pre>

<hr>
<h2 id='lmoms.bootbarvar'>Exact Bootstrap Mean and Variance of L-moments </h2><span id='topic+lmoms.bootbarvar'></span>

<h3>Description</h3>

<p>This function computes the exact bootstrap mean and variance of L-moments using the exact analytical expressions for the bootstrap mean and variance of any L-estimator described by Hutson and Ernst (2000). The approach by those authors is to use the bootstrap distribution of the single order statistic in conjunction with the joint distribution of two order statistics. The key component is the bootstrap mean vector as well as the variance-covariance matrix of all the order statistics and then performing specific linear combinations of a basic L-estimator combined with the proportion weights used in the computation of L-moments (<code><a href="#topic+Lcomoment.Wk">Lcomoment.Wk</a></code>, see those examples and division by <code class="reqn">n</code>). Reasonably complex algorithms are used; however, what makes those authors' contribution so interesting is that neither simulation, resampling, or numerical methods are needed as long as the sample size is not too large.
</p>
<p>This function provides a uniquely independent method to compute the L-moments of a sample from the vector of exact bootstrap order statistics. It is anticipated that several of the intermediate computations of this function would be of interest in further computations or graphical visualization. Therefore, this function returns many more numerical values than other L-moment functions of <span class="pkg">lmomco</span>. The variance-covariance matrix for large samples requires considerable CPU time; as the matrix is filled, status output is generated.
</p>
<p>The example section of this function contains the verification of the implementation as well as provides to additional computations of variance through resampling with replacement and simulation from the parent distribution that generated the sample vector shown in the example.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lmoms.bootbarvar(x, nmom=6, covarinverse=TRUE, verbose=TRUE,
                    force.exact=FALSE, nohatSIGMA=FALSE, nsim=500, bign=40, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lmoms.bootbarvar_+3A_x">x</code></td>
<td>
<p>A vector of data values.</p>
</td></tr>
<tr><td><code id="lmoms.bootbarvar_+3A_nmom">nmom</code></td>
<td>
<p>The number of moments to compute. Default is 6 and can not be less than 3.</p>
</td></tr>
<tr><td><code id="lmoms.bootbarvar_+3A_covarinverse">covarinverse</code></td>
<td>
<p>Logical on computation of the matrix inversions: <br /> <code>inverse.varcovar.tau23</code>, <br /> <code>inverse.varcovar.tau34</code>, and <br /> <code>inverse.varcovar.tau46</code>.</p>
</td></tr>
<tr><td><code id="lmoms.bootbarvar_+3A_verbose">verbose</code></td>
<td>
<p>A logical switch on the verbosity of the construction of the variance-covariance matrix of the order statisitics. This operation is the most time consuming of those inside the function and is provided at default of <code>verbose=TRUE</code> to make a general user comfortable.</p>
</td></tr>
<tr><td><code id="lmoms.bootbarvar_+3A_force.exact">force.exact</code></td>
<td>
<p>A logical switch to attempt a <em>forced exact bootstrap computation</em> (empirical bootstrap controlled by <code>nsim</code> thus is <em>not</em> used) even if the sample size is too large as controlled by <code>bign</code>. See messages during the execution for guidance.</p>
</td></tr>
<tr><td><code id="lmoms.bootbarvar_+3A_nohatsigma">nohatSIGMA</code></td>
<td>
<p>A logical to bypass most of the interesting matrix functions and results. If <code>TRUE</code>, then only <code>lambdas</code>, <code>ratios</code>, and <code>bootstrap.orderstatistics</code> are populated. This feature is useful if a user is only interested in get the bootstrap estimates of the order statistics.</p>
</td></tr>
<tr><td><code id="lmoms.bootbarvar_+3A_nsim">nsim</code></td>
<td>
<p>Simulation size in case simulations and not the exact bootstrap are used.</p>
</td></tr>
<tr><td><code id="lmoms.bootbarvar_+3A_bign">bign</code></td>
<td>
<p>A sample size threshold that triggers simulation using <code>nsim</code> replications for estimation by empirical bootstrap. Some of the &ldquo;exact&rdquo; operations are extremely expensive and numerical problems in the matrices are known for non-normal data.</p>
</td></tr>
<tr><td><code id="lmoms.bootbarvar_+3A_...">...</code></td>
<td>
<p>Additional arguments but not implemented.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> is returned.
</p>
<table>
<tr><td><code>lambdas</code></td>
<td>
<p>Vector of the exact bootstrap L-moments. First element is
<code class="reqn">\hat{\lambda}_1</code>, second element is <code class="reqn">\hat{\lambda}_2</code>, and so on. This vector is from equation 1.3 and 2.4 of Hutson and Ernst (2000).</p>
</td></tr>
<tr><td><code>ratios</code></td>
<td>
<p>Vector of the exact bootstrap L-moment ratios. Second element is
<code class="reqn">\hat{\tau}</code>, third element is <code class="reqn">\hat{\tau}_3</code> and so on.</p>
</td></tr>
<tr><td><code>lambdavars</code></td>
<td>
<p>The exact bootstrap variances of the L-moments from equation 1.4 of Hutson and Ernst (2000) via <code>crossprod</code> matrix operations.</p>
</td></tr>
<tr><td><code>ratiovars</code></td>
<td>
<p>The exact bootstrap variances of the L-moment ratios with <code>NA</code> inserted for <code class="reqn">r=1,2</code> because <code class="reqn">r=1</code> is the mean and <code class="reqn">r=2</code> for L-CV is unknown to this author.</p>
</td></tr>
<tr><td><code>varcovar.lambdas</code></td>
<td>
<p>The variance-covariance matrix of the L-moments from which the diagonal are the values <code>lambdavars</code>.</p>
</td></tr>
<tr><td><code>varcovar.lambdas.and.ratios</code></td>
<td>
<p>The variance-covariance matrix of the first two L-moments and for the L-moment ratios (if <code>nmom</code><code class="reqn">&gt;=3</code>) from which select diagonal are the values <code>ratiovars</code>.</p>
</td></tr>
<tr><td><code>bootstrap.orderstatistics</code></td>
<td>
<p>The exact bootstrap estimate of the order statistics from equation 2.2 of Hutson and Ernst (2000).</p>
</td></tr>
<tr><td><code>varcovar.orderstatistics</code></td>
<td>
<p>The variance-covariance matrix of the order statistics from equations 3.1 and 3.2 of Hutson and Ernst (2000). The diagonal of this matrix represents the variances of each order statistic.</p>
</td></tr>
<tr><td><code>inverse.varcovar.tau23</code></td>
<td>
<p>The inversion of the variance-covariance matrix of <code class="reqn">\tau_2</code> and <code class="reqn">\tau_3</code> by Cholesky decomposition. This matrix may be used to estimate a joint confidence region of (<code class="reqn">\tau_2, \tau_3</code>) based on asymptotic normality of L-moments.</p>
</td></tr>
<tr><td><code>inverse.varcovar.tau34</code></td>
<td>
<p>The inversion of the variance-covariance matrix of <code class="reqn">\tau_3</code> and <code class="reqn">\tau_4</code> by Cholesky decomposition. This matrix may be used to estimate a joint confidence region of (<code class="reqn">\tau_3, \tau_4</code>) based on asymptotic normality of L-moments; these two L-moment ratios likely represent the most common ratios used in general L-moment ratio diagrams.</p>
</td></tr>
<tr><td><code>inverse.varcovar.tau46</code></td>
<td>
<p>The inversion of the variance-covariance matrix of <code class="reqn">\tau_4</code> and <code class="reqn">\tau_6</code> by Cholesky decomposition. This matrix may be used to estimate a joint confidence region of (<code class="reqn">\tau_4, \tau_6</code>) based on asymptotic normality of L-moments; these two L-moment ratios represent those ratios used in L-moment ratio diagrams of symmetrical distributions.</p>
</td></tr>
<tr><td><code>source</code></td>
<td>
<p>An attribute identifying the computational source of the results: <br /> &ldquo;lmoms.bootbarvar&rdquo;.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>This function internally defines several functions that provide a direct nomenclature connection to Hutson and Ernst (2000). Interested users are invited to adapt these functions as they might see fit. A reminder is made to sort the data vector as needed; the vector is only sorted once within the <code>lmoms.bootbarvar</code> function.
</p>
<p>The <code class="reqn">100(1-\alpha)</code> percent confidence region of the vector <code class="reqn">{\bm \eta} = (\tau_3, \tau_4)</code> (for example) based on the sample L-skew and L-kurtosis of the vector <code class="reqn">\hat{\bm \eta} = (\hat\tau_3, \hat\tau_4)</code> is expressed as
</p>
<p style="text-align: center;"><code class="reqn">({\bm \eta} - \hat{\bm \eta})'\hat{\bm P}^{-1}_{(3,4)}({\bm \eta} - \hat{\bm \eta}) \le \chi^2_{2,\alpha}</code>
</p>

<p>where <code class="reqn">\hat{\bm P}_{(3,4)}</code> is the variance-covariance matrix of these L-moment ratios subselected from the resulting matrix titled <code>varcovar.lambdas.and.ratios</code> but extracted and inverted in the resulting matrix titled <code>inverse.varcovar.tau34</code>, which is <code class="reqn">\hat{\bm P}^{-1}_{(3,4)}</code>. The value  <code class="reqn">\chi^2_{2,\alpha}</code> is the upper quantile of the Chi-squared distribution. The inequality represents a standard equal probable ellipse from a Bivariate Normal distribution.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Hutson, A.D., and Ernst, M.D., 2000, The exact bootstrap mean and variance
of an L-estimator: Journal Royal Statistical Society B, v. 62, part 1, pp. 89&ndash;94.
</p>
<p>Wang, D., and Hutson, A.D., 2013, Joint confidence region estimation of L-moments with an extension to right censored data: Journal of Applied Statistics, v. 40, no. 2, pp. 368&ndash;379.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lmoms">lmoms</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
   para &lt;- vec2par(c(0,1), type="gum") # Parameters of Gumbel
   n &lt;- 10; nmom &lt;- 6; nsim &lt;- 2000
   # X &lt;- rlmomco(n, para) # This is commented out because
   # the sample below is from the Gumbel distribution as in para.
   # However, the seed for the random number generator was not recorded.
   X &lt;- c( -1.4572506, -0.7864515, -0.5226538,  0.1756959,  0.2424514,
            0.5302202,  0.5741403,  0.7708819,  1.9804254,  2.1535666)
   EXACT.BOOTLMR &lt;- lmoms.bootbarvar(X, nmom=nmom)
   LA &lt;- EXACT.BOOTLMR$lambdavars
   LB &lt;- LC &lt;- rep(NA, length(LA))
   set.seed(n)
   for(i in 1:length(LB)) {
     LB[i] &lt;- var(replicate(nsim,
                  lmoms(sample(X, n, replace=TRUE), nmom=nmom)$lambdas[i]))
   }
   set.seed(n)
   for(i in 1:length(LC)) {
     LC[i] &lt;- var(replicate(nsim,
                  lmoms(rlmomco(n, para), nmom=nmom)$lambdas[i]))
   }
   print(LA) # The exact bootstrap variances of the L-moments.
   print(LB) # Bootstrap variances of the L-moments by actual resampling.
   print(LC) # Simulation of the variances from the parent distribution.

   # The variances for this example are as follows:
   #&gt; print(LA)
   #[1] 0.115295563 0.018541395 0.007922893 0.010726508 0.016459913 0.029079202
   #&gt; print(LB)
   #[1] 0.117719198 0.018945827 0.007414461 0.010218291 0.016290100 0.028338396
   #&gt; print(LC)
   #[1] 0.17348653 0.04113861 0.02156847 0.01443939 0.01723750 0.02512031
   # The variances, when using simulation of parent distribution,
   # appear to be generally larger than those based only on resampling
   # of the available sample of only 10 values.

   # Interested users may inspect the exact bootstrap estimates of the
   # order statistics and the variance-covariance matrix.
   # print(EXACT.BOOTLMR$bootstrap.orderstatistics)
   # print(EXACT.BOOTLMR$varcovar.orderstatistics)

   # The output for these two print functions is not shown, but what follows
   # are the numerical confirmations from A.D. Hutson (personnal commun., 2012)
   # using his personnal algorithms (outside of R).
   # Date: Jul 2012, From: ahutson, To: Asquith
   # expected values the same
   # -1.174615143125091, -0.7537760316881618, -0.3595651823632459,
   # -0.028951905838698,  0.2360931764028858,  0.4614289985084462,
   #  0.713957210869635,  1.0724040932920058,  1.5368435379648948,
   #  1.957207045977329
   # and the first two values on the first row of the matrix are
   # 0.1755400544274771,  0.1306634198810892

## End(Not run)
## Not run: 
# Wang and Hutson (2013): Attempt to reproduce first entry of
# row 9 (n=35) in Table 1 of the reference, which is 0.878.
Xsq  &lt;- qchisq(1-0.05, 2); n &lt;- 35; nmom &lt;- 4; nsim &lt;- 1000
para &lt;- vec2par(c(0,1), type="gum") # Parameters of Gumbel
eta  &lt;- as.vector(lmorph(par2lmom(para))$ratios[3:4])
h &lt;- 0
for(i in 1:nsim) {
   X &lt;- rlmomco(n,para); message(i)
   EB &lt;- lmoms.bootbarvar(X, nmom=nmom, verbose=FALSE)
   lmr    &lt;- lmoms(X); etahat &lt;- as.vector(lmr$ratios[c(3,4)])
   Pinv   &lt;- EB$inverse.varcovar.tau34
   deta   &lt;- (eta - etahat)
   LHS &lt;- t(deta) 
   if(LHS &gt; Xsq) { # Comparison to Chi-squared distribution
      h &lt;- h + 1 # increment because outside ellipse
      message("Outside: ",i, " ", h, " ", round(h/i, digits=3))
   }
}
message("Empirical Coverage Probability with Alpha=0.05 is ",
        round(1 - h/nsim, digits=3), " and count is", h)
# I have run this loop and recorded an h=123 for the above settings. I compute a
# coverage probability of 0.877, which agrees with Wang and Hutson (2013) within 0.001.
# Hence "very down the line" computations of lmoms.bootbarvar appear to be verified.

## End(Not run)
</code></pre>

<hr>
<h2 id='lmoms.cov'>Distribution-Free Variance-Covariance Structure of Sample L-moments </h2><span id='topic+lmoms.cov'></span>

<h3>Description</h3>

<p>Compute the distribution-free, variance-covariance matrix (<code class="reqn">\widehat{\mathrm{var}}(\lambda)</code>) of the sample L-moments (<code class="reqn">\hat\lambda_r</code>) or alternatively the sample probability-weighted moments (<code class="reqn">\hat\beta_k</code>, Elamir and Seheult, 2004, sec. 5). The <code class="reqn">\widehat{\mathrm{var}}(\lambda)</code> is defined by the matrix product
</p>
<p style="text-align: center;"><code class="reqn">\widehat{\mathrm{var}}(\lambda) = \mathbf{C}\,\mathbf{\hat\Theta}\,\mathbf{C}^{\mathrm{T}}\mbox{,}</code>
</p>

<p>where the <code class="reqn">r \times r</code> matrix <code class="reqn">\mathbf{C}</code> for number of moments <code class="reqn">r</code> represents the coefficients of the linear combinations converting <code class="reqn">\beta_k</code> to <code class="reqn">\lambda_r</code> and the <code class="reqn">r</code>th row in the matrix is defined as
</p>
<p style="text-align: center;"><code class="reqn">\mathbf{C}[r,]_{k{=}0:(r-1)} = (-1)^{(r-1-k)} {r-1 \choose k} {r-1+k \choose k}\mbox{,}</code>
</p>

<p>where the row is padded from the right with zeros for <code class="reqn">k &lt; r</code> to form the required lower triangular structure.  Elamir and Seheult (2004) list the <code class="reqn">\mathbf{C}</code> matrix for <code class="reqn">r = 4</code>.
</p>
<p>Letting the <em>falling factorial</em> be defined (matching Elamir and Seheult's nomenclature) as
</p>
<p style="text-align: center;"><code class="reqn">a^{(b)} = \Gamma(b+1) {a \choose b}\mbox{,}</code>
</p>

<p>and letting an entry in the <code class="reqn">\mathbf{\hat\Theta}</code> matrix denoted as <code class="reqn">\hat\theta_{kl}</code> be defined as
</p>
<p style="text-align: center;"><code class="reqn">\hat\theta_{kl} = \hat\beta_k\hat\beta_l - \frac{A}{n^{(k+l+2)}}\mbox{,}</code>
</p>

<p>where <code class="reqn">\hat\beta_k</code> are again the sample probability-weighted moments and are computed by <code><a href="#topic+pwm">pwm</a></code>, and finally <code class="reqn">A</code> is defined as
</p>
<p style="text-align: center;"><code class="reqn">A = \sum_{i=1}^{n-1}\sum_{j=i+1}^{n}
  \bigl[ (i-1)^{(k)} (j-k-2)^{(l)} +
          (i-1)^{(l)} (i-l-2)^{(k)}
  \bigr] X_{i:n}X_{j:n}\mbox{,}</code>
</p>

<p>where <code class="reqn">X_{i:n}</code> are the sample order statistics for a sample of size <code class="reqn">n</code>.
</p>
<p>Incidentally, the matrix <code class="reqn">\mathbf{\hat\Theta}</code> is the variance-covariance structure (<code class="reqn">\widehat{\mathrm{var}}</code>) of the <code class="reqn">\hat\beta</code>, thus <code class="reqn">\widehat{\mathrm{var}}(\beta) = \mathbf{\hat\Theta}</code>, which can be returned by a logical function argument (<code>as.pwm=TRUE</code>) instead of <code class="reqn">\widehat{\mathrm{var}}(\lambda)</code>. The last example in <b>Examples</b> provides a demonstration.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lmoms.cov(x, nmom=5, as.pwm=FALSE, showC=FALSE,
             se=c("NA", "lamse", "lmrse", "pwmse"), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lmoms.cov_+3A_x">x</code></td>
<td>
<p>A vector of data values.</p>
</td></tr>
<tr><td><code id="lmoms.cov_+3A_nmom">nmom</code></td>
<td>
<p>The number of moments to compute. Default is 5.</p>
</td></tr>
<tr><td><code id="lmoms.cov_+3A_as.pwm">as.pwm</code></td>
<td>
<p>A logical controlling whether the distribution-free, variance-covariance of sample probability-weighted moments (<code class="reqn">\mathbf{\hat\Theta}</code>) is returned instead.</p>
</td></tr>
<tr><td><code id="lmoms.cov_+3A_showc">showC</code></td>
<td>
<p>A logical controlling whether the matrix <code class="reqn">\mathbf{C}</code> is printed during function operation, and this matrix is not returned as a presumed safety feature.</p>
</td></tr>
<tr><td><code id="lmoms.cov_+3A_se">se</code></td>
<td>
<p>Compute standard errors (<code class="reqn">SE</code>) for the respective moments. The default of <code>"NA"</code> retains the return of either <code class="reqn">\widehat{\mathrm{var}}(\beta)</code> or <code class="reqn">\widehat{\mathrm{var}}(\lambda)</code> depending on setting of <code>as.pwm</code>. The <code>"lamse"</code> returns the square root of the diagonal of <code class="reqn">\widehat{\mathrm{var}}(\lambda)</code>, and notationally these are <code class="reqn">\lambda_r^{SE}</code>. Similarly, <code>"pwmse"</code> returns the square root of the diagonal of <code class="reqn">\widehat{\mathrm{var}}(\beta)</code> by internally setting <code>as.pwm</code> to <code>TRUE</code>, and notationally these are <code class="reqn">\beta_{r-1}^{SE}</code>. (Remember that <code class="reqn">\beta_0 \equiv \lambda_1</code>&mdash;the indexing of the former starts at 0 and at the later at 1). The <code>"lmrse"</code> returns the square root of the first two terms of the <code class="reqn">\widehat{\mathrm{var}}(\lambda)</code> diagonal (<code class="reqn">\lambda_{1,2}^{SE}</code>) but computes <code class="reqn">SE</code> for the L-moment ratios (<code class="reqn">\tau_r^{SE}</code>) for <code class="reqn">r \ge 3</code> using the Taylor-series-based approximation (see <b>Note</b>) shown by Elamir and Seheult (2004, p. 348). (Remember that L-moment ratios are <code class="reqn">\tau_r = \lambda_r/\lambda_2</code> for <code class="reqn">r \ge 3</code> and that <code class="reqn">\tau_2 = \lambda_2/\lambda_1</code> [coefficient of L-variation].)</p>
</td></tr>
<tr><td><code id="lmoms.cov_+3A_...">...</code></td>
<td>
<p>Other arguments to pass should they be needed (none were at first implementation).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>matrix</code> is returned. In small samples and substantially sized <code class="reqn">r</code>, one or more <code class="reqn">\hat\theta_{kl}</code> will be <code>NaN</code> starting from the lower right corner of the matrix.  The function does not test for this nor reduce the number of moments declared in <code>nmom</code> itself. To reiterate, the square roots along the <code class="reqn">\widehat{\mathrm{var}}(\lambda)</code> diagonal are <code class="reqn">SE</code> for the respective L-moments.
</p>


<h3>Note</h3>

<p>Function <code>lmoms.cov</code> was developed as a double check on the evidently separately developed <code class="reqn">r \le 4</code> (<code>nmom</code>) implementations of <code class="reqn">\widehat{\mathrm{var}}(\lambda)</code> in packages <span class="pkg">Lmoments</span> and <span class="pkg">nsRFA</span>. Also the internal structure closely matches the symbolic mathematics by Elamir and Seheult (2004), but this practice comes at the expense of more than an order of magnitude slower execution times than say either of the functions <code>Lmomcov()</code> (package <span class="pkg">Lmoments</span>) or <code>varLmoments()</code> (package <span class="pkg">nsRFA</span>). For a high speed and recommended implementation, please use the <span class="pkg">Lmoments</span> package by Karvanen (2016)&mdash;Karvanen extended this implementation to larger <code class="reqn">r</code> for the <span class="pkg">lmomco</span> package.
</p>
<p>For <code>se="lmrse"</code>, the Taylor-series-based approximation is suggested by Elamir and Seheult (2004, p. 348) to estimate the variance of an L-moment ratio (<code class="reqn">\tau_r</code> for <code class="reqn">r \ge 3</code>) is based on structure of the variance of the ratio of two uniform variables in which the numerator is the <code class="reqn">r</code>th L-moment and the denominator is <code class="reqn">\lambda_2</code>:
</p>
<p style="text-align: center;"><code class="reqn">\mathrm{var}(\tau_r) \cong
\biggl[ \frac{\mathrm{var}(\lambda_r)}{\mathrm{E}(\lambda_r)^2} + \frac{\mathrm{var}(\lambda_2)}{\mathrm{E}(\lambda_2)^2} - \frac{2\mathrm{cov}(\lambda_r,\lambda_2)}{\mathrm{E}(\lambda_r)\mathrm{E}(\lambda_2)} \biggr]
\biggl[\frac{\mathrm{E}(\lambda_r)}{\mathrm{E}(\lambda_2)} \biggr]^2\mbox{,}</code>
</p>

<p>where <code class="reqn">\mathrm{var}(\cdots)</code> are the along the diagonal of <code class="reqn">\widehat{\mathrm{var}}(\lambda)</code> and <code class="reqn">\mathrm{cov}(\cdots)</code> are the off-diagonal covariances. The expectations <code class="reqn">\mathrm{E}(\cdots)</code> are replaced with the sample estimates. Only for <code>se="lmrse"</code> the <code class="reqn">SE</code> of the coefficient of L-variation (<code class="reqn">\tau_2^{SE}</code>) is computed but retained as an attribute (<code>attr()</code> function) of the returned vector and not housed within the vector&mdash;the <code class="reqn">\lambda_2^{SE}</code> continues to be held in the 2nd position of the returned vector.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Elamir, E.A.H., and Seheult, A.H., 2004, Exact variance structure of sample L-moments: Journal of Statistical Planning and Inference, v. 124, pp. 337&ndash;359.
</p>
<p>Karvanen, Juha, 2016, Lmoments&mdash;L-moments and quantile mixtures: R package version 1.2-3, accessed February 22, 2016 at https://cran.r-project.org/web/packages/Lmoments/index.html
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lmoms">lmoms</a></code>, <code><a href="#topic+pwm">pwm</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
nsim &lt;- 1000; n &lt;- 10 # Let us compute variance of lambda_3
VL3sample &lt;- mean(replicate(nsim, { zz &lt;- lmoms.cov(rexp(n),nmom=3); zz[3,3] }))
falling.factorial &lt;- function(a, b) gamma(b+1)*choose(a,b)
VL3exact  &lt;- ((4*n^2 - 3*n - 2)/30)/falling.factorial (10, 3) # Exact variance is from
print(c(VL3sample, VL3exact)) # Elamir and Seheult (2004, table 1, line 8)
#[1] 0.01755058 0.01703704  # the values obviously are consistent
## End(Not run)
## Not run: 
# Data considered by Elamir and Seheult (2004, p. 348)
library(MASS); data(michelson); Light &lt;- michelson$Speed
lmoms(Light, nmom=4)$lambdas # 852.4, 44.3, 0.83, 6.5 # matches those authors
lmoms.cov(Light) # [1, ] ==&gt; 62.4267, 0.7116, 2.5912, -3.9847 # again matches
# The authors report standard error of L-kurtosis as 0.03695, which matches
lmoms.cov(Light, se="lmrse")[4] # 0.03695004 
## End(Not run)
## Not run: 
D &lt;- rnorm(100) # Check results of Lmoments package.
lmoms.cov(D, rmax=5)[,5]
#        lam1         lam2         lam3         lam4         lam5
#3.662721e-04 3.118812e-05 5.769509e-05 6.574662e-05 1.603578e-04
Lmoments::Lmomcov(D, rmax=5)[,5]
#          L1           L2           L3           L4           L5
#3.662721e-04 3.118812e-05 5.769509e-05 6.574662e-05 1.603578e-04
## End(Not run)
</code></pre>

<hr>
<h2 id='lmomsla'>Trimmed L-moments of the Slash Distribution</h2><span id='topic+lmomsla'></span>

<h3>Description</h3>

<p>This function estimates the trimmed L-moments of the Slash distribution given the parameters (<code class="reqn">\xi</code> and <code class="reqn">\alpha</code>) from <code><a href="#topic+parsla">parsla</a></code>. The relation between the TL-moments (<code>trim=1</code>) and the parameters have been numerically determined and are
<code class="reqn">\lambda^{(1)}_1 = \xi</code>,
<code class="reqn">\lambda^{(1)}_2 = 0.93686275\alpha</code>,
<code class="reqn">\tau^{(1)}_3 = 0</code>,
<code class="reqn">\tau^{(1)}_4 = 0.30420472</code>,
<code class="reqn">\tau^{(1)}_5 = 0</code>, and
<code class="reqn">\tau^{(1)}_6 = 0.18900723</code>.
These TL-moments (trim=1) are symmetrical for the first L-moments defined because <code class="reqn">\mathrm{E}[X_{1:n}]</code> and <code class="reqn">\mathrm{E}[X_{n:n}]</code> are undefined expectations for the Slash.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lmomsla(para)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lmomsla_+3A_para">para</code></td>
<td>
<p>The parameters of the distribution.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> is returned.
</p>
<table>
<tr><td><code>lambdas</code></td>
<td>
<p>Vector of the trimmed L-moments. First element is <code class="reqn">\lambda^{(1)}_1</code>, second element is <code class="reqn">\lambda^{(1)}_2</code>, and so on.</p>
</td></tr>
<tr><td><code>ratios</code></td>
<td>
<p>Vector of the L-moment ratios. Second element is <code class="reqn">\tau^{(1)}</code>, third element is <code class="reqn">\tau^{(1)}_3</code> and so on. </p>
</td></tr>
<tr><td><code>trim</code></td>
<td>
<p>Level of symmetrical trimming used in the computation, which is <code>1</code>.</p>
</td></tr>
<tr><td><code>leftrim</code></td>
<td>
<p>Level of left-tail trimming used in the computation, which is <code>1</code>.</p>
</td></tr>
<tr><td><code>rightrim</code></td>
<td>
<p>Level of right-tail trimming used in the computation, which is <code>1</code>.</p>
</td></tr>
<tr><td><code>source</code></td>
<td>
<p>An attribute identifying the computational source of the L-moments: &ldquo;lmomsla&rdquo;</p>
</td></tr>
<tr><td><code>trim</code></td>
<td>
<p>Level of symmetrical trimming used.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Rogers, W.H., and Tukey, J.W., 1972, Understanding some long-tailed symmetrical distributions: Statistica Neerlandica, v. 26, no. 3, pp. 211&ndash;226.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+parsla">parsla</a></code>, <code><a href="#topic+cdfsla">cdfsla</a></code>, <code><a href="#topic+pdfsla">pdfsla</a></code>, <code><a href="#topic+quasla">quasla</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# This example was used to numerically back into the TL-moments and the
# relation between \alpha and \lambda_2.
"lmomtrim1" &lt;- function(para) {
    bigF &lt;- 0.9999
    minX &lt;- para$para[1] - para$para[2]*qnorm(1 - bigF) / qunif(1 - bigF)
    maxX &lt;- para$para[1] + para$para[2]*qnorm(    bigF) / qunif(1 - bigF)
    minF &lt;- cdfsla(minX, para); maxF &lt;- cdfsla(maxX, para)
    lmr &lt;- theoTLmoms(para, nmom = 6, leftrim = 1, rightrim = 1)
}

U &lt;- -10; i &lt;- 0
As &lt;- seq(.1,abs(10),by=.2)
L1s &lt;- L2s &lt;- T3s &lt;- T4s &lt;- T5s &lt;- T6s &lt;- vector(mode="numeric", length=length(As))
for(A in As) {
   i &lt;- i + 1
   lmr &lt;- lmomtrim1(vec2par(c(U, A), type="sla"))
   L1s[i] &lt;- lmr$lambdas[1]; L2s[i] &lt;- lmr$lambdas[2]
   T3s[i] &lt;- lmr$ratios[3];  T4s[i] &lt;- lmr$ratios[4]
   T5s[i] &lt;- lmr$ratios[5];  T6s[i] &lt;- lmr$ratios[6]
}
print(summary(lm(L2s~As-1))$coe)
print(mean(T4s))
print(mean(T6s)) # 
## End(Not run)

## Not run: 
  alpha &lt;- 30
  tlmr &lt;- theoTLmoms(vec2par(c(100, alpha), type="cau"), nmom=6, trim=1)
  print( c(tlmr$lambdas[2] / alpha, tlmr$ratios[c(4,6)]), 8 ) # 
## End(Not run)
</code></pre>

<hr>
<h2 id='lmomsmd'>L-moments of the Singh&ndash;Maddala Distribution</h2><span id='topic+lmomsmd'></span>

<h3>Description</h3>

<p>This function computes the L-moments of the Singh&ndash;Maddala (Burr Type XII) distribution given the parameters (<code class="reqn">\xi</code>, <code class="reqn">a</code>, <code class="reqn">b</code>, and <code class="reqn">q</code>) from <code><a href="#topic+parsmd">parsmd</a></code>. The first L-moment (<code class="reqn">\lambda_1</code>) for <code class="reqn">b' = 1/b</code> and <code class="reqn">R = a\Gamma(1 + b')</code> is
</p>
<p style="text-align: center;"><code class="reqn">\lambda_1 = R\times\biggl[\frac{a\Gamma(1q-b')}{\Gamma(1q)}\biggr] + \xi\mbox{.}</code>
</p>

<p>The second L-moment (<code class="reqn">\lambda_2</code>) is
</p>
<p style="text-align: center;"><code class="reqn">\lambda_2 = R\times\biggl[\frac{1\Gamma(1q - b')}{\Gamma(1q)} -
                                \frac{1\Gamma(2q - b')}{\Gamma(2q)}\biggr]\mbox{.}</code>
</p>

<p>The third L-moment (<code class="reqn">\lambda_3</code>) is
</p>
<p style="text-align: center;"><code class="reqn">\lambda_3 = R\times\biggl[\frac{1\Gamma(1q - b')}{\Gamma(1q)} -
                                \frac{3\Gamma(2q - b')}{\Gamma(2q)} +
                                \frac{2\Gamma(3q - b')}{\Gamma(3q)}\biggr]\mbox{.}</code>
</p>

<p>The fourth L-moment (<code class="reqn">\lambda_4</code>) is
</p>
<p style="text-align: center;"><code class="reqn">\lambda_4 = R\times\biggl[\frac{ 1\Gamma(1q - b')}{\Gamma(1q)} -
                                \frac{ 6\Gamma(2q - b')}{\Gamma(2q)} +
                                \frac{10\Gamma(3q - b')}{\Gamma(3q)} -
                                \frac{ 5\Gamma(4q - b')}{\Gamma(4q)}\biggr]\mbox{.}</code>
</p>

<p>The fifth L-moment (<code class="reqn">\lambda_5</code>) (unique to <span class="pkg">lmomco</span> development) is
</p>
<p style="text-align: center;"><code class="reqn">\lambda_5 = R\times\biggl[\frac{ 1\Gamma(1q - b')}{\Gamma(1q)} -
                                \frac{10\Gamma(2q - b')}{\Gamma(2q)} +
                                \frac{30\Gamma(3q - b')}{\Gamma(3q)} -
                                \frac{35\Gamma(4q - b')}{\Gamma(4q)} +
                                \frac{14\Gamma(5q - b')}{\Gamma(5q)}\biggr]\mbox{.}</code>
</p>

<p>The sixth L-moment (<code class="reqn">\lambda_6</code>) (unique to <span class="pkg">lmomco</span> development) is
</p>
<p style="text-align: center;"><code class="reqn">\lambda_6 = R\times\biggl[\frac{  1\Gamma(1q - b')}{\Gamma(1q)} -
                                \frac{ 15\Gamma(2q - b')}{\Gamma(2q)} +
                                \frac{ 70\Gamma(3q - b')}{\Gamma(3q)} -
                                \frac{140\Gamma(4q - b')}{\Gamma(4q)} +</code>
</p>

<p style="text-align: center;"><code class="reqn">\frac{126\Gamma(5q - b')}{\Gamma(5q)} -
      \frac{ 42\Gamma(6q - b')}{\Gamma(6q)}\biggr]\mbox{.}</code>
</p>



<h3>Usage</h3>

<pre><code class='language-R'>lmomsmd(para)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lmomsmd_+3A_para">para</code></td>
<td>
<p>The parameters of the distribution.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> is returned.
</p>
<table>
<tr><td><code>lambdas</code></td>
<td>
<p>Vector of the L-moments. First element is
<code class="reqn">\lambda_1</code>, second element is <code class="reqn">\lambda_2</code>, and so on.</p>
</td></tr>
<tr><td><code>ratios</code></td>
<td>
<p>Vector of the L-moment ratios. Second element is
<code class="reqn">\tau</code>, third element is <code class="reqn">\tau_3</code> and so on.</p>
</td></tr>
<tr><td><code>trim</code></td>
<td>
<p>Level of symmetrical trimming used in the computation, which is <code>0</code>.</p>
</td></tr>
<tr><td><code>leftrim</code></td>
<td>
<p>Level of left-tail trimming used in the computation, which is <code>NULL</code>.</p>
</td></tr>
<tr><td><code>rightrim</code></td>
<td>
<p>Level of right-tail trimming used in the computation, which is <code>NULL</code>.</p>
</td></tr>
<tr><td><code>source</code></td>
<td>
<p>An attribute identifying the computational
source of the L-moments: &ldquo;lmomsmd&rdquo;.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Bhatti, F.A., Hamedani, G.G., Korkmaz, M.C., and Munir Ahmad, M., 2019, New modified Singh&ndash;Maddala distribution&mdash;Development, properties, characterizations, and applications: Journal of Data Science, v. 17, no. 3, pp. 551&ndash;574, <a href="https://doi.org/10.6339/JDS.201907_17%283%29.0006">doi:10.6339/JDS.201907_17(3).0006</a>.
</p>
<p>Shahzad, M.N., and Zahid, A., 2013, Parameter estimation of Singh Maddala distribution by moments: International Journal of Advanced Statistics and Probability, v. 1, no. 3, pp. 121&ndash;131, <a href="https://doi.org/10.14419/ijasp.v1i3.1206">doi:10.14419/ijasp.v1i3.1206</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+parsmd">parsmd</a></code>, <code><a href="#topic+cdfsmd">cdfsmd</a></code>, <code><a href="#topic+pdfsmd">pdfsmd</a></code>, <code><a href="#topic+quasmd">quasmd</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>lmr &lt;- lmoms(c(123, 34, 4, 654, 37, 78), nmom=6)
lmr$source &lt;- lmr$trim &lt;- lmr$leftrim &lt;- lmr$rightrim &lt;-NULL
# The parsmd() reports Tau4 is too big and snaps it to an empirical boundary.
# "Tau4(~Tau3) snapped to upper limit, Tau4=0.65483 for Tau3=0.75126"
bmr &lt;- lmomsmd(parsmd(lmr, snap.tau4=TRUE))
dmr &lt;- data.frame(bmr$lambdas, bmr$ratios)
cbind(as.data.frame(lmr), dmr) # See in table that row 4 has different Tau4s
#  lambdas    ratios bmr.lambdas bmr.ratios
# 1   155.0        NA   155.00000         NA
# 2   118.6 0.7651613   118.60000  0.7651613
# 3    89.1 0.7512648    89.18739  0.7520016
# 4    82.1 0.6922428    77.59904  0.6542921 # see different Tau4s (snapping)
# 5    69.5 0.5860034    68.40150  0.5767411 # We are not fitting to these
# 6   102.5 0.8642496    62.58792  0.5277228 # higher L-moments.

# T3 and T4 of the Gumbel distribution, which is inside the SMD domain.
gumt3t4 &lt;- c(log(9/8)/log(2), (16 * log(2) - 10 * log(3))/log(2))
lmr &lt;- theoLmoms(pargum(vec2lmom(c(155, 118.6, gumt3t4))), nmom=6)
lmr$source &lt;- lmr$trim &lt;- lmr$leftrim &lt;- lmr$rightrim &lt;-NULL
bmr &lt;- lmomsmd(parsmd(lmr, snap.tau4=TRUE))
dmr &lt;- data.frame(bmr$lambdas, bmr$ratios)
cbind(as.data.frame(lmr), dmr)
#      lambdas     ratios bmr.lambdas bmr.ratios
# 1 155.000000         NA  155.000000         NA
# 2 118.600005 0.76516132  118.600005  0.7651613
# 3  20.153103 0.16992498   20.153104  0.1699250
# 4  17.834464 0.15037490   17.834464  0.1503749 # see same Tau4s (no snapping)
# 5   6.625972 0.05586823    7.688957  0.0648310 # We are not fitting to these
# 6   6.891842 0.05810997    7.213039  0.0608182 # higher L-moments.

## Not run: 
  # T3 and T4 of the Gumbel distribution, which is inside the SMD domain.
  gumt3t4 &lt;- c(log(9/8)/log(2), (16 * log(2) - 10 * log(3))/log(2))
  FF &lt;- nonexceeds(); qFF &lt;- qnorm(FF)
  gumx &lt;- qlmomco(FF, pargum(vec2lmom(c(155, 118.6, gumt3t4))))
  smdx &lt;- qlmomco(FF, parsmd(lmr, snap.tau4=TRUE))
  plot( qFF, gumx, col="blue", type="l",
       xlab="Standard normal variate", ylab="Quantile")
  lines(qFF, smdx, col="red") # 
## End(Not run)
</code></pre>

<hr>
<h2 id='lmomsRCmark'>Sample L-moments Moments for Right-Tail Censoring by a Marking Variable </h2><span id='topic+lmomsRCmark'></span>

<h3>Description</h3>

<p>Compute the sample L-moments for right-tail censored data set in which censored data values are identified by a marking variable. Extension of left-tail censoring can be made using <code><a href="#topic+fliplmoms">fliplmoms</a></code> and the example therein.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lmomsRCmark(x, rcmark=NULL, nmom=5, flip=NA, flipfactor=1.1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lmomsRCmark_+3A_x">x</code></td>
<td>
<p>A vector of data values.</p>
</td></tr>
<tr><td><code id="lmomsRCmark_+3A_rcmark">rcmark</code></td>
<td>
<p>The right-tail censoring (upper) marking variable for unknown threshold: 0 is uncensored, 1 is censored.</p>
</td></tr>
<tr><td><code id="lmomsRCmark_+3A_nmom">nmom</code></td>
<td>
<p>Number of L-moments to return.</p>
</td></tr>
<tr><td><code id="lmomsRCmark_+3A_flip">flip</code></td>
<td>
<p>Do the data require flipping so that left-censored data can be processed as such. If the flip is a logical and <code>TRUE</code>, then <code>flipfactor</code> <code class="reqn">\times</code> <code class="reqn">\mathrm{max}(x)</code> (the maximum of <code>x</code>) is used. If the <code>flip</code> is a numeric, then it is used as the flip.</p>
</td></tr>
<tr><td><code id="lmomsRCmark_+3A_flipfactor">flipfactor</code></td>
<td>
<p>The value that is greater than 1, which is multiplied on the maximum of <code>x</code> to determine the flip, if the <code>flip</code> is not otherwise provided.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> is returned.
</p>
<table>
<tr><td><code>lambdas</code></td>
<td>
<p>Vector of the L-moments. First element is
<code class="reqn">\hat{\lambda}^{(0,0)}_1</code>, second element is <code class="reqn">\hat{\lambda}^{(0,0)}_2</code>, and so on.  <em>The returned mean is NOT unflipped.</em></p>
</td></tr>
<tr><td><code>ratios</code></td>
<td>
<p>Vector of the L-moment ratios. Second element is
<code class="reqn">\hat{\tau}^{(0,0)}</code>, third element is <code class="reqn">\hat{\tau}^{(0,0)}_3</code> and so on.</p>
</td></tr>
<tr><td><code>trim</code></td>
<td>
<p>Level of symmetrical trimming used in the computation, which will equal <code>NULL</code> if asymmetrical trimming was used. This is not currently implemented as no one has done the derivations.</p>
</td></tr>
<tr><td><code>leftrim</code></td>
<td>
<p>Level of left-tail trimming used in the computation. This is not currently implemented as no one has done the derivations.</p>
</td></tr>
<tr><td><code>rightrim</code></td>
<td>
<p>Level of right-tail trimming used in the computation. This is not currently implemented as no one has done the derivations.</p>
</td></tr>
<tr><td><code>n</code></td>
<td>
<p>The complete sample size.</p>
</td></tr>
<tr><td><code>n.cen</code></td>
<td>
<p>The number of right-censored data values.</p>
</td></tr>
<tr><td><code>flip</code></td>
<td>
<p>The flip used in the computations for support of left-tail censoring.</p>
</td></tr>
<tr><td><code>source</code></td>
<td>
<p>An attribute identifying the computational source of the L-moments: &ldquo;lmomsRCmark&rdquo;.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Wang, Dongliang, Hutson, A.D., Miecznikowski, J.C., 2010, L-moment estimation for parametric survival models given censored data: Statistical Methodology, v. 7, no. 6, pp. 655&ndash;667.
</p>
<p>Helsel, D.R., 2005, Nondetects and data analysis&mdash;Statistics for censored environmental data: Hoboken, New Jersey, John Wiley, 250 p.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lmomRCmark">lmomRCmark</a></code>, <code><a href="#topic+fliplmoms">fliplmoms</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'># Efron, B., 1988, Logistic regression, survival analysis, and the
# Kaplan-Meier curve: Journal of the American Statistical Association,
# v. 83, no. 402, pp.414--425
# Survival time measured in days for 51 patients with a marking
# variable in the "time,mark" ensemble. If marking variable is 1,
# then the time is right-censored by an unknown censoring threshold.
Efron &lt;-
c(7,0,  34,0,  42,0,  63,0,  64,0,  74,1,  83,0,  84,0,  91,0,
108,0,  112,0,  129,0,  133,0,  133,0,  139,0,  140,0,  140,0,
146,0,  149,0,  154,0,  157,0,  160,0,  160,0,  165,0,  173,0,
176,0,  185,1,  218,0,  225,0,  241,0,  248,0,  273,0,  277,0,
279,1,  297,0,  319,1,  405,0,  417,0,  420,0,  440,0,  523,1,
523,0,  583,0,  594,0,  1101,0,  1116,1,  1146,0,  1226,1,
1349,1,  1412,1, 1417,1);

# Break up the ensembles into to vectors
ix &lt;- seq(1,length(Efron),by=2)
T  &lt;- Efron[ix]
Efron.data &lt;- T;
Efron.rcmark &lt;- Efron[(ix+1)]

lmr.RC &lt;- lmomsRCmark(Efron.data, rcmark=Efron.rcmark)
lmr.ub &lt;- lmoms(Efron.data)
lmr.noRC &lt;- lmomsRCmark(Efron.data)
PP &lt;- pp(Efron.data)
plot(PP, Efron.data, col=(Efron.rcmark+1), ylab="DATA")
lines(PP, qlmomco(PP, lmom2par(lmr.noRC, type="kap")), lwd=3, col=8)
lines(PP, qlmomco(PP, lmom2par(lmr.ub, type="kap")))
lines(PP, qlmomco(PP, lmom2par(lmr.RC, type="kap")), lwd=2, col=2)
legend(0,1000,c("uncensored L-moments by indicator (Kappa distribution)",
                "unbiased L-moments (Kappa)",
           "right-censored L-moments by indicator (Kappa distribution)"),
                lwd=c(3,1,2), col=c(8,1,2))

########
ZF &lt;- 5 # discharge of undetection of streamflow
Q &lt;- c(rep(ZF,8), 116, 34, 56, 78, 909, 12, 56, 45, 560, 300, 2500)
Qc &lt;- Q == ZF; Qc &lt;- as.numeric(Qc)
lmr     &lt;- lmoms(Q)
lmr.cen &lt;- lmomsRCmark(Q, rcmark=Qc, flip=TRUE)
flip &lt;- lmr.cen$flip
fit  &lt;- pargev(lmr);                     fit.cen &lt;- pargev(lmr.cen)
F &lt;- seq(0.001, 0.999, by=0.001)
Qfit     &lt;-        qlmomco(    F, fit    )
Qfit.cen &lt;- flip - qlmomco(1 - F, fit.cen) # remember to reverse qdf
plot(pp(Q),sort(Q), log="y", xlab="NONEXCEED PROB.", ylab="QUANTILE")
lines(F, Qfit);   lines(F, Qfit.cen,col=2)
</code></pre>

<hr>
<h2 id='lmomst3'>L-moments of the 3-Parameter Student t Distribution</h2><span id='topic+lmomst3'></span>

<h3>Description</h3>

<p>This function estimates the first six L-moments of the 3-parameter Student t distribution given the parameters (<code class="reqn">\xi</code>, <code class="reqn">\alpha</code>, <code class="reqn">\nu</code>) from <code><a href="#topic+parst3">parst3</a></code>. The L-moments in terms of the parameters are
</p>
<p style="text-align: center;"><code class="reqn">\lambda_1 = \xi\mbox{,}</code>
</p>

<p style="text-align: center;"><code class="reqn">\lambda_2 = 2^{6-4\nu}\pi\alpha\nu^{1/2}\,\Gamma(2\nu-2)/[\Gamma(\frac{1}{2}\nu)]^4\mbox{\, and}</code>
</p>

<p style="text-align: center;"><code class="reqn">\tau_4 = \frac{15}{2} \frac{\Gamma(\nu)}{\Gamma(\frac{1}{2})\Gamma(\nu - \frac{1}{2})} \int_0^1 \! \frac{(1-x)^{\nu - 3/2}[I_x(\frac{1}{2},\frac{1}{2}\nu)]^2}{\sqrt{x}}\; \mathrm{d} x - \frac{3}{2}\mbox{,}</code>
</p>

<p>where <code class="reqn">I_x(\frac{1}{2}, \frac{1}{2}\nu)</code> is the cumulative distribution function of the Beta distribution.  The distribution is symmetrical so that <code class="reqn">\tau_r = 0</code> for odd values of <code class="reqn">r: r \ge 3</code>.
</p>
<p>Numerical integration of is made to estimate <code class="reqn">\tau_4</code>. The other two parameters are readily solved for when <code class="reqn">\nu</code> is available. A polynomial approximation is used to estimate the <code class="reqn">\tau_6</code> as a function of <code class="reqn">\tau_4</code>; the polynomial was based on the <code><a href="#topic+theoLmoms">theoLmoms</a></code> estimating <code class="reqn">\tau_4</code> and <code class="reqn">\tau_6</code>. The <code class="reqn">\tau_6</code> polynomial has nine coefficients with a maximum absolute residual value of 2.065e-06 for 4,000 degrees of freedom (see <code>inst/doc/t4t6/studyST3.R</code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lmomst3(para, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lmomst3_+3A_para">para</code></td>
<td>
<p>The parameters of the distribution.</p>
</td></tr>
<tr><td><code id="lmomst3_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> is returned.
</p>
<table>
<tr><td><code>lambdas</code></td>
<td>
<p>Vector of the L-moments. First element is <code class="reqn">\lambda_1</code>, second element is <code class="reqn">\lambda_2</code>, and so on.</p>
</td></tr>
<tr><td><code>ratios</code></td>
<td>
<p>Vector of the L-moment ratios. Second element is <code class="reqn">\tau</code>, third element is <code class="reqn">\tau_3</code> and so on.</p>
</td></tr>
<tr><td><code>trim</code></td>
<td>
<p>Level of symmetrical trimming used in the computation, which is <code>0</code>.</p>
</td></tr>
<tr><td><code>leftrim</code></td>
<td>
<p>Level of left-tail trimming used in the computation, which is <code>NULL</code>.</p>
</td></tr>
<tr><td><code>rightrim</code></td>
<td>
<p>Level of right-tail trimming used in the computation, which is <code>NULL</code>.</p>
</td></tr>
<tr><td><code>source</code></td>
<td>
<p>An attribute identifying the computational source of the L-moments: &ldquo;lmomst3&rdquo;.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>W.H. Asquith with A.R. Biessen</p>


<h3>References</h3>

<p>Asquith, W.H., 2011, Distributional analysis with L-moment statistics using the R environment for statistical computing: Createspace Independent Publishing Platform, ISBN 978&ndash;146350841&ndash;8.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+parst3">parst3</a></code>, <code><a href="#topic+cdfst3">cdfst3</a></code>, <code><a href="#topic+pdfst3">pdfst3</a></code>, <code><a href="#topic+quast3">quast3</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>lmomst3(vec2par(c(1124, 12.123, 10), type="st3"))
</code></pre>

<hr>
<h2 id='lmomtexp'>L-moments of the Truncated Exponential Distribution</h2><span id='topic+lmomtexp'></span>

<h3>Description</h3>

<p>This function estimates the L-moments of the Truncated Exponential distribution. The parameter <code class="reqn">\psi</code> is the right truncation of the distribution and <code class="reqn">\alpha</code> is a scale parameter, letting <code class="reqn">\beta = 1/\alpha</code> to match nomenclature of Vogel and others (2008), the L-moments in terms of the parameters, letting <code class="reqn">\eta = \mathrm{exp}(-\alpha\psi)</code>, are
</p>
<p style="text-align: center;"><code class="reqn">\lambda_1 = \frac{1}{\beta} - \frac{\psi\eta}{1-\eta} \mbox{,}</code>
</p>

<p style="text-align: center;"><code class="reqn">\lambda_2 = \frac{1}{1-\eta}\biggl[\frac{1+\eta}{2\beta} -
                                         \frac{\psi\eta}{1-\eta}\biggr] \mbox{,}</code>
</p>

<p style="text-align: center;"><code class="reqn">\lambda_3 = \frac{1}{(1-\eta)^2}\biggl[\frac{1+10\eta+\eta^2}{6\alpha} -
                                         \frac{\psi\eta(1+\eta)}{1-\eta}\biggr] \mbox{, and}</code>
</p>

<p style="text-align: center;"><code class="reqn">\lambda_4 = \frac{1}{(1-\eta)^3}\biggl[\frac{1+29\eta+29\eta^2+\eta^3}{12\alpha} -
                                         \frac{\psi\eta(1+3\eta+\eta^2)}{1-\eta}\biggr] \mbox{.}</code>
</p>

<p>The distribution is restricted to a narrow range of L-CV (<code class="reqn">\tau_2 = \lambda_2/\lambda_1</code>). If <code class="reqn">\tau_2 = 1/3</code>, the process represented is a stationary Poisson for which the probability density function is simply the uniform distribution and <code class="reqn">f(x) = 1/\psi</code>. If <code class="reqn">\tau_2 = 1/2</code>, then the distribution is represented as the usual exponential distribution with a location parameter of zero and a scale parameter <code class="reqn">1/\beta</code>. Both of these limiting conditions are supported.
</p>
<p>If the distribution shows to be Uniform (<code class="reqn">\tau_2 = 1/3</code>), then <code class="reqn">\lambda_1 = \psi/2</code>, <code class="reqn">\lambda_2 = \psi/6</code>, <code class="reqn">\tau_3 = 0</code>, and <code class="reqn">\tau_4 = 0</code>. If the distribution shows to be Exponential (<code class="reqn">\tau_2 = 1/2</code>), then <code class="reqn">\lambda_1 = \alpha</code>, <code class="reqn">\lambda_2 = \alpha/2</code>, <code class="reqn">\tau_3 = 1/3</code> and <code class="reqn">\tau_4 = 1/6</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lmomtexp(para)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lmomtexp_+3A_para">para</code></td>
<td>
<p>The parameters of the distribution.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> is returned.
</p>
<table>
<tr><td><code>lambdas</code></td>
<td>
<p>Vector of the L-moments. First element is
<code class="reqn">\lambda_1</code>, second element is <code class="reqn">\lambda_2</code>, and so on.</p>
</td></tr>
<tr><td><code>ratios</code></td>
<td>
<p>Vector of the L-moment ratios. Second element is
<code class="reqn">\tau</code>, third element is <code class="reqn">\tau_3</code> and so on.</p>
</td></tr>
<tr><td><code>trim</code></td>
<td>
<p>Level of symmetrical trimming used in the computation, which is <code>0</code>.</p>
</td></tr>
<tr><td><code>leftrim</code></td>
<td>
<p>Level of left-tail trimming used in the computation, which is <code>NULL</code>.</p>
</td></tr>
<tr><td><code>rightrim</code></td>
<td>
<p>Level of right-tail trimming used in the computation, which is <code>NULL</code>.</p>
</td></tr>
<tr><td><code>source</code></td>
<td>
<p>An attribute identifying the computational
source of the L-moments: &ldquo;lmomtexp&rdquo;.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Vogel, R.M., Hosking, J.R.M., Elphick, C.S., Roberts, D.L., and Reed, J.M., 2008, Goodness of fit of probability distributions for sightings as species approach extinction: Bulletin of Mathematical Biology, DOI 10.1007/s11538-008-9377-3, 19 p.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+partexp">partexp</a></code>, <code><a href="#topic+cdftexp">cdftexp</a></code>, <code><a href="#topic+pdftexp">pdftexp</a></code>, <code><a href="#topic+quatexp">quatexp</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1) # to get a suitable L-CV
X &lt;- rexp(1000, rate=.001) + 100
Y &lt;- X[X &lt;= 2000]
lmr &lt;- lmoms(Y)

print(lmr$lambdas)
print(lmomtexp(partexp(lmr))$lambdas)

print(lmr$ratios)
print(lmomtexp(partexp(lmr))$ratios)
</code></pre>

<hr>
<h2 id='lmomTLgld'>Trimmed L-moments of the Generalized Lambda Distribution</h2><span id='topic+lmomTLgld'></span>

<h3>Description</h3>

<p>This function estimates the symmetrical trimmed L-moments (TL-moments) for <code class="reqn">t=1</code> of the Generalized Lambda distribution given the parameters (<code class="reqn">\xi</code>, <code class="reqn">\alpha</code>, <code class="reqn">\kappa</code>, and <code class="reqn">h</code>) from <code><a href="#topic+parTLgld">parTLgld</a></code>. The TL-moments in terms of the parameters are complicated; however, there are analytical solutions. There are no simple expressions of the parameters in terms of the L-moments. The first four TL-moments (trim = 1) of the distribution are
</p>
<p style="text-align: center;"><code class="reqn">\lambda^{(1)}_1 = \xi + 6\alpha
                              \left(\frac{1}{(\kappa+3)(\kappa+2)} -
               \frac{1}{(h+3)(h+2)} \right) \mbox{,}</code>
</p>

<p style="text-align: center;"><code class="reqn">\lambda^{(1)}_2 = 6\alpha \left(\frac{\kappa}{(\kappa+4)(\kappa+3)(\kappa+2)} +
                                           \frac{h}{(h+4)(h+3)(h+2)}\right) \mbox{,}</code>
</p>

<p style="text-align: center;"><code class="reqn">\lambda^{(1)}_3 =  \frac{20\alpha}{3} \left(\frac{\kappa (\kappa - 1)}
                                                {(\kappa+5)(\kappa+4)(\kappa+3)(\kappa+2)} -
        \frac{h (h - 1)}
             {(h+5)(h+4)(h+3)(h+2)} \right) \mbox{,}</code>
</p>

<p style="text-align: center;"><code class="reqn">\lambda^{(1)}_4 = \frac{15\alpha}{2} \left(\frac{\kappa (\kappa - 2)(\kappa - 1)}
                                                {(\kappa+6)(\kappa+5)(\kappa+4)(\kappa+3)(\kappa+2)} +
        \frac{h (h - 2)(h - 1)}
             {(h+6)(h+5)(h+4)(h+3)(h+2)} \right) \mbox{,}</code>
</p>

<p style="text-align: center;"><code class="reqn">\lambda^{(1)}_5 = \frac{42\alpha}{5} \left(N1 - N2 \right) \mbox{,}</code>
</p>

<p>where
</p>
<p style="text-align: center;"><code class="reqn">N1 = \frac{\kappa (\kappa - 3)(\kappa - 2)(\kappa - 1) }
                {(\kappa+7)(\kappa+6)(\kappa+5)(\kappa+4)(\kappa+3)(\kappa+2)} \mbox{ and}</code>
</p>

<p style="text-align: center;"><code class="reqn">N2 = \frac{h (h - 3)(h - 2)(h - 1)}{(h+7)(h+6)(h+5)(h+4)(h+3)(h+2)} \mbox{.}</code>
</p>

<p>The TL-moment (<code class="reqn">t=1</code>) for <code class="reqn">\tau^{(1)}_3</code> is
</p>
<p style="text-align: center;"><code class="reqn">\tau^{(1)}_3 = \frac{10}{9} \left( \frac{\kappa(\kappa-1)(h+5)(h+4)(h+3)(h+2) -
                     h(h-1)(\kappa+5)(\kappa+4)(\kappa+3)(\kappa+2)}
      {(\kappa+5)(h+5) \times [\kappa(h+4)(h+3)(h+2) +
                                  h(\kappa+4)(\kappa+3)(\kappa+2)]
      } \right)
      \mbox{.}</code>
</p>

<p>The TL-moment (<code class="reqn">t=1</code>) for <code class="reqn">\tau^{(1)}_4</code> is
</p>
<p style="text-align: center;"><code class="reqn">N1 = \kappa(\kappa-2)(\kappa-1)(h+6)(h+5)(h+4)(h+3)(h+2) \mbox{,}</code>
</p>

<p style="text-align: center;"><code class="reqn">N2 = h(h-2)(h-1)(\kappa+6)(\kappa+5)(\kappa+4)(\kappa+3)(\kappa+2) \mbox{,}</code>
</p>

<p style="text-align: center;"><code class="reqn">D1 = (\kappa+6)(h+6)(\kappa+5)(h+5) \mbox{,}</code>
</p>

<p style="text-align: center;"><code class="reqn">D2 = [\kappa(h+4)(h+3)(h+2) + h(\kappa+4)(\kappa+3)(\kappa+2)] \mbox{, and}</code>
</p>

<p style="text-align: center;"><code class="reqn">\tau^{(1)}_4 = \frac{5}{4} \left( \frac{N1 +  N2}{D1 \times D2} \right) \mbox{.}</code>
</p>

<p>Finally the TL-moment (<code class="reqn">t=1</code>) for <code class="reqn">\tau^{(1)}_5</code> is
</p>
<p style="text-align: center;"><code class="reqn">N1 = \kappa(\kappa-3)(\kappa-2)(\kappa-1)(h+7)(h+6)(h+5)(h+4)(h+3)(h+2) \mbox{,}</code>
</p>

<p style="text-align: center;"><code class="reqn">N2 = h(h-3)(h-2)(h-1)(\kappa+7)(\kappa+6)(\kappa+5)(\kappa+4)(\kappa+3)(\kappa+2) \mbox{,}</code>
</p>

<p style="text-align: center;"><code class="reqn">D1 = (\kappa+7)(h+7)(\kappa+6)(h+6)(\kappa+5)(h+5) \mbox{,}</code>
</p>

<p style="text-align: center;"><code class="reqn">D2 = [\kappa(h+4)(h+3)(h+2) + h(\kappa+4)(\kappa+3)(\kappa+2)] \mbox{, and}</code>
</p>

<p style="text-align: center;"><code class="reqn">\tau^{(1)}_5 = \frac{7}{5} \left( \frac{N1 -  N2}{D1 \times D2} \right)\mbox{.}</code>
</p>

<p>By inspection the <code class="reqn">\tau_r</code> equations are not applicable for negative integer values <code class="reqn">k=\{-2, -3, -4, \dots \}</code> and <code class="reqn">h=\{-2, -3, -4, \dots \}</code> as division by zero will result. There are additional, but difficult to formulate, restrictions on the parameters both to define a valid Generalized Lambda distribution as well as valid L-moments. Verification of the parameters is conducted through <code><a href="#topic+are.pargld.valid">are.pargld.valid</a></code>, and verification of the L-moment validity is conducted through <code><a href="#topic+are.lmom.valid">are.lmom.valid</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lmomTLgld(para, nmom=6, trim=1, leftrim=NULL, rightrim=NULL, tau34=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lmomTLgld_+3A_para">para</code></td>
<td>
<p>The parameters of the distribution.</p>
</td></tr>
<tr><td><code id="lmomTLgld_+3A_nmom">nmom</code></td>
<td>
<p>Number of L-moments to compute.</p>
</td></tr>
<tr><td><code id="lmomTLgld_+3A_trim">trim</code></td>
<td>
<p>Symmetrical trimming level set to unity as the default.</p>
</td></tr>
<tr><td><code id="lmomTLgld_+3A_leftrim">leftrim</code></td>
<td>
<p>Left trimming level, <code class="reqn">t_1</code>.</p>
</td></tr>
<tr><td><code id="lmomTLgld_+3A_rightrim">rightrim</code></td>
<td>
<p>Right trimming level, <code class="reqn">t_2</code>.</p>
</td></tr>
<tr><td><code id="lmomTLgld_+3A_tau34">tau34</code></td>
<td>
<p>A logical controlling the level of L-moments returned by the function. If true, then this function returns only <code class="reqn">\tau_3</code> and <code class="reqn">\tau_4</code>; this feature might be useful in certain research applications of the Generalized Lambda distribution associated with the multiple solutions possible for the distribution.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The opening comments in the description pertain to single and symmetrical endpoint trimming, which has been extensively considered by Asquith (2007).  Deriviations backed by numerical proofing of variable arrangement in March 2011 led the the inclusion of the following generalization of the L-moments and TL-moments of the Generalized Lambda shown in Asquith (2011) that was squeezed in late ahead of the deadlines for that monograph.
</p>
<p style="text-align: center;"><code class="reqn">
\lambda^{(t_1,t_2)}_{r} = \alpha (r^{-1}) (r+t_1+t_2) \sum_{j=0}^{r-1} (-1)^{r}{r-1 \choose j}{r+t_1+t_2-1 \choose r+t_1-j-1} \times A\mbox{,}</code>
</p>

<p>where <code class="reqn">A</code> is
</p>
<p style="text-align: center;"><code class="reqn">A = \biggl(\frac{\Gamma(\kappa+r+t_1-j)\Gamma(t_2+j+1)}{\Gamma(\kappa+r+t_1+t_2+1)} - \frac{\Gamma(r+t_1-j)\Gamma(h+t_2+j+1)}{\Gamma(h+r+t_1+t_2+1)}\biggr)\mbox{,}</code>
</p>

<p>where for the special condition of <code class="reqn">r = 1</code>, the real mean is
</p>
<p style="text-align: center;"><code class="reqn">
\mathrm{mean} = \xi + \lambda^{(t_1,t_2)}_{1}\mbox{,}</code>
</p>

<p>but for <code class="reqn">r \ge 2</code> the <code class="reqn">\lambda^{(t_1,t_2)}</code> provides correct values.  So care is needed algorithmically also when <code class="reqn">\tau^{(t1, t2)}_2</code> is computed. Inspection of the <code class="reqn">\Gamma(\cdot)</code> arguments, which must be <code class="reqn"> &gt; 0</code>, shows that
</p>
<p style="text-align: center;"><code class="reqn">
\kappa &gt; -(1+t_1)</code>
</p>

<p>and
</p>
<p style="text-align: center;"><code class="reqn">h &gt; -(1+t_2)
\mbox{.}</code>
</p>



<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> is returned.
</p>
<table>
<tr><td><code>lambdas</code></td>
<td>
<p>Vector of the TL-moments. First element is
<code class="reqn">\lambda^{(t_1,t_2)}_1</code>, second element is <code class="reqn">\lambda^{(t_1,t_2)}_2</code>, and so on.</p>
</td></tr>
<tr><td><code>ratios</code></td>
<td>
<p>Vector of the TL-moment ratios. Second element is
<code class="reqn">\tau^{(1)}</code>, third element is <code class="reqn">\tau^{(1)}_3</code> and so on. </p>
</td></tr>
<tr><td><code>trim</code></td>
<td>
<p>Trim level = left or right values if they are equal. The default for this function is <code>trim = 1</code> because the <code><a href="#topic+lmomgld">lmomgld</a></code> provides for <code>trim = 0</code>. </p>
</td></tr>
<tr><td><code>leftrim</code></td>
<td>
<p>Left trimming level</p>
</td></tr>
<tr><td><code>rightrim</code></td>
<td>
<p>Right trimming level</p>
</td></tr>
<tr><td><code>source</code></td>
<td>
<p>An attribute identifying the computational source of the TL-moments: &ldquo;lmomTLgld&rdquo;.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>Source</h3>

<p>Derivations conducted by W.H. Asquith on February 18 and 19, 2006 and others in early March 2011.
</p>


<h3>References</h3>

<p>Asquith, W.H., 2007, L-moments and TL-moments of the generalized lambda distribution: Computational Statistics and Data Analysis, v. 51, no. 9, pp. 4484&ndash;4496.
</p>
<p>Asquith, W.H., 2011, Distributional analysis with L-moment statistics using the R environment for statistical computing: Createspace Independent Publishing Platform, ISBN 978&ndash;146350841&ndash;8.
</p>
<p>Elamir, E.A.H., and Seheult, A.H., 2003, Trimmed L-moments: Computational statistics and data analysis, v. 43, pp. 299&ndash;314.
</p>
<p>Karian, Z.A., and Dudewicz, E.J., 2000, Fitting statistical distributions&mdash;The generalized lambda distribution and generalized bootstrap methods: CRC Press, Boca Raton, FL, 438 p.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lmomgld">lmomgld</a></code>, <code><a href="#topic+parTLgld">parTLgld</a></code>, <code><a href="#topic+pargld">pargld</a></code>, <code><a href="#topic+cdfgld">cdfgld</a></code>, <code><a href="#topic+quagld">quagld</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
lmomgld(vec2par(c(10,10,0.4,1.3), type='gld'))

PARgld &lt;- vec2par(c(15,12,1,.5), type="gld")
theoTLmoms(PARgld, leftrim=0, rightrim=0, nmom=6)
lmomTLgld(PARgld, leftrim=0, rightrim=0)

theoTLmoms(PARgld, trim=2, nmom=6)
lmomTLgld(PARgld, trim=2)

theoTLmoms(PARgld, trim=3, nmom=6)
lmomTLgld(PARgld, leftrim=3, rightrim=3)

theoTLmoms(PARgld, leftrim=10, rightrim=2, nmom=6)
lmomTLgld(PARgld, leftrim=10, rightrim=2)

## End(Not run)
</code></pre>

<hr>
<h2 id='lmomTLgpa'>Trimmed L-moments of the Generalized Pareto Distribution</h2><span id='topic+lmomTLgpa'></span>

<h3>Description</h3>

<p>This function estimates the symmetrical trimmed L-moments (TL-moments) for <code class="reqn">t=1</code> of the Generalized Pareto distribution given the parameters (<code class="reqn">\xi</code>, <code class="reqn">\alpha</code>, and <code class="reqn">\kappa</code>) from <code><a href="#topic+parTLgpa">parTLgpa</a></code>.
The TL-moments in terms of the parameters are
</p>
<p style="text-align: center;"><code class="reqn">\lambda^{(1)}_1 = \xi + \frac{\alpha(\kappa+5)}{(\kappa+3)(\kappa+2)} \mbox{,}</code>
</p>

<p style="text-align: center;"><code class="reqn">\lambda^{(1)}_2 = \frac{6\alpha}{(\kappa+4)(\kappa+3)(\kappa+2)} \mbox{,}</code>
</p>

<p style="text-align: center;"><code class="reqn">\tau^{(1)}_3 = \frac{10(1-\kappa)}{9(\kappa+5)} \mbox{, and}</code>
</p>

<p style="text-align: center;"><code class="reqn">\tau^{(1)}_4 = \frac{5(\kappa-1)(\kappa-2)}{4(\kappa+6)(\kappa+5)}  \mbox{.}</code>
</p>



<h3>Usage</h3>

<pre><code class='language-R'>lmomTLgpa(para)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lmomTLgpa_+3A_para">para</code></td>
<td>
<p>The parameters of the distribution.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> is returned.
</p>
<table>
<tr><td><code>lambdas</code></td>
<td>
<p>Vector of the trimmed L-moments. First element is
<code class="reqn">\lambda^{(1)}_1</code>, second element is <code class="reqn">\lambda^{(1)}_2</code>, and so on.</p>
</td></tr>
<tr><td><code>ratios</code></td>
<td>
<p>Vector of the L-moment ratios. Second element is
<code class="reqn">\tau^{(1)}</code>, third element is <code class="reqn">\tau^{(1)}_3</code> and so on. </p>
</td></tr>
<tr><td><code>trim</code></td>
<td>
<p>Level of symmetrical trimming used in the computation, which is unity.</p>
</td></tr>
<tr><td><code>leftrim</code></td>
<td>
<p>Level of left-tail trimming used in the computation, which is unity.</p>
</td></tr>
<tr><td><code>rightrim</code></td>
<td>
<p>Level of right-tail trimming used in the computation, which is unity.</p>
</td></tr>
<tr><td><code>source</code></td>
<td>
<p>An attribute identifying the computational source of the TL-moments: &ldquo;lmomTLgpa&rdquo;.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Elamir, E.A.H., and Seheult, A.H., 2003, Trimmed L-moments: Computational Statistics and Data Analysis, v. 43, pp. 299&ndash;314.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lmomgpa">lmomgpa</a></code>, <code><a href="#topic+parTLgpa">parTLgpa</a></code>, <code><a href="#topic+cdfgpa">cdfgpa</a></code>, <code><a href="#topic+pdfgpa">pdfgpa</a></code>, <code><a href="#topic+quagpa">quagpa</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>TL &lt;- TLmoms(c(123,34,4,654,37,78,21,3400),trim=1)
TL
lmomTLgpa(parTLgpa(TL))
</code></pre>

<hr>
<h2 id='lmomtri'>L-moments of the Asymmetric Triangular Distribution</h2><span id='topic+lmomtri'></span>

<h3>Description</h3>

<p>This function estimates the L-moments of the Asymmetric Triangular distribution given the parameters (<code class="reqn">\nu</code>, <code class="reqn">\omega</code>, and <code class="reqn">\psi</code>) from <code><a href="#topic+partri">partri</a></code>. The first three L-moments in terms of the parameters are
</p>
<p style="text-align: center;"><code class="reqn">\lambda_1 = \frac{(\nu+\omega+\psi)}{3}\mbox{,}</code>
</p>

<p style="text-align: center;"><code class="reqn">\lambda_2 = \frac{1}{15}\biggl[\frac{(\nu-\omega)^2}{(\psi-\nu)^{\phantom{1}}} - (\nu+\omega) + 2\psi\biggr] \mbox{, and}</code>
</p>

<p style="text-align: center;"><code class="reqn">\lambda_3 = G + H_1 + H_2 + J \mbox{,}</code>
</p>

<p>where <code class="reqn">G</code> is dependent on the integral definining the L-moments in terms of the quantile function (Asquith, 2011, p. 92) with limits of integration of <code class="reqn">[0,P]</code>, <code class="reqn">H_1</code> and <code class="reqn">H_2</code> are dependent on the integral defining the L-moment in terms of the quantile function with limits of integration of <code class="reqn">[P,1]</code>, and <code class="reqn">J</code> is dependent on the <code class="reqn">\lambda_2</code> and <code class="reqn">\lambda_1</code>. Finally, the variables <code class="reqn">G</code>, <code class="reqn">H_1</code>, <code class="reqn">H_2</code>, and <code class="reqn">J</code> are
</p>
<p style="text-align: center;"><code class="reqn">G = \frac{2}{7}\frac{(\nu+6\omega)(\omega-\nu)^3}{(\psi-\nu)^3}\mbox{,}</code>
</p>

<p style="text-align: center;"><code class="reqn">H_1 = \frac{12}{7}\frac{(\omega-\psi)^4}{(\nu-\psi)^3} - 2\psi\frac{(\nu-\omega)^3}{(\nu-\psi)^3} + 2\psi\mbox{,}</code>
</p>

<p style="text-align: center;"><code class="reqn">H_2 = \frac{4}{5}\frac{(5\nu-6\omega+\psi)(\omega-\psi)^2}{(\nu-\psi)^2}\mbox{, and}</code>
</p>

<p style="text-align: center;"><code class="reqn">J = -\frac{1}{15}\biggl[\frac{3(\nu-\omega)^2}{(\psi-\nu)} + 7(\nu+\omega) + 16\psi\biggl]\mbox{.}</code>
</p>

<p>The higher L-moments are even more ponderous and simpler expressions for the L-moment ratios appear elusive. Bounds for <code class="reqn">\tau_3</code> and <code class="reqn">\tau_4</code> are <code class="reqn">|\tau_3| \le 0.14285710</code> and <code class="reqn">0.04757138 &lt; \tau_4 &lt; 0.09013605</code>. An approximation for <code class="reqn">\tau_4</code> is
</p>
<p style="text-align: center;"><code class="reqn">\tau_4 = 0.09012180 - 1.777361\tau_3^2 - 17.89864\tau_3^4 + 920.4924\tau_3^6 - 37793.50\tau_3^8 \mbox{,}</code>
</p>

<p>where the residual standard error is <code class="reqn">{&lt;}1.750\times 10^{-5}</code> and the absolute value of the maximum residual is <code class="reqn">&lt;9.338\times 10^{-5}</code>. The L-moments of the Symmetrical Triangular distribution for <code class="reqn">\tau_3 = 0</code> are considered by Nagaraja (2013) and therein for a symmetric triangular distribution having <code class="reqn">\lambda_1 = 0.5</code> then <code class="reqn">\lambda_4 = 0.0105</code> and <code class="reqn">\tau_4 = 0.09</code>. These L-kurtosis values agree with results of this function that are based on the <code><a href="#topic+theoLmoms.max.ostat">theoLmoms.max.ostat</a></code> function. The 4th and 5th L-moments <code class="reqn">\lambda_4</code> and <code class="reqn">\lambda_5</code>, respectively, are computed using expectations of order statistic maxima (<code><a href="#topic+expect.max.ostat">expect.max.ostat</a></code>) and are defined (Asquith, 2011, p. 95) as
</p>
<p style="text-align: center;"><code class="reqn">\lambda_4 = 5\mathrm{E}[X_{4:4}] - 10\mathrm{E}[X_{3:3}] +  6\mathrm{E}[X_{2:2}] - \mathrm{E}[X_{1:1}]</code>
</p>

<p>and
</p>
<p style="text-align: center;"><code class="reqn">\lambda_5 = 14\mathrm{E}[X_{5:5}] - 35\mathrm{E}[X_{4:4}] + 30\mathrm{E}[X_{3:3}] - 10\mathrm{E}[X_{2:2}] + \mathrm{E}[X_{1:1}]\mbox{.}</code>
</p>

<p>These expressions are solved using the <code><a href="#topic+expect.max.ostat">expect.max.ostat</a></code> function to compute the <code class="reqn">\mathrm{E}[X_{r:r}]</code>.
</p>
<p>For the symmetrical case of <code class="reqn">\omega = (\psi + \nu)/2</code>, then 
</p>
<p style="text-align: center;"><code class="reqn">\lambda_1 = \frac{(\nu+\psi)}{2}\mbox{\ and}</code>
</p>

<p style="text-align: center;"><code class="reqn">\lambda_2 = \frac{7}{60}\biggl[\psi - \nu\biggr]\mbox{,}</code>
</p>

<p>which might be useful for initial parameter estimation through
</p>
<p style="text-align: center;"><code class="reqn">\psi = \lambda_1 + \frac{30}{7}\lambda_2 \mbox{\ and}</code>
</p>

<p style="text-align: center;"><code class="reqn">\nu  = \lambda_1 - \frac{30}{7}\lambda_2 \mbox{.}</code>
</p>



<h3>Usage</h3>

<pre><code class='language-R'>lmomtri(para, paracheck=TRUE, nmom=c("3", "5"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lmomtri_+3A_para">para</code></td>
<td>
<p>The parameters of the distribution.</p>
</td></tr>
<tr><td><code id="lmomtri_+3A_paracheck">paracheck</code></td>
<td>
<p>A logical controlling whether the parameters and checked for validity. Overriding of this check might help in numerical optimization of parameters for modes near either the minimum or maximum. The argument here makes code base within <code><a href="#topic+partri">partri</a></code> a little shorter.</p>
</td></tr>
<tr><td><code id="lmomtri_+3A_nmom">nmom</code></td>
<td>
<p>The L-moments greater the <code class="reqn">r &gt; 3</code> require numerical integration using the expectations of the maxima order statistics of the fitted distribution. If this argument is set to <code>"3"</code> then executation of <code>lmomtri</code> is stopped at <code class="reqn">r = 3</code> and the first three L-moments returned, otherwise the 4th and 5th L-moments are computed.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> is returned.
</p>
<table>
<tr><td><code>lambdas</code></td>
<td>
<p>Vector of the L-moments. First element is
<code class="reqn">\lambda_1</code>, second element is <code class="reqn">\lambda_2</code>, and so on.</p>
</td></tr>
<tr><td><code>ratios</code></td>
<td>
<p>Vector of the L-moment ratios. Second element is
<code class="reqn">\tau</code>, third element is <code class="reqn">\tau_3</code> and so on.</p>
</td></tr>
<tr><td><code>trim</code></td>
<td>
<p>Level of symmetrical trimming used in the computation, which is <code>0</code>.</p>
</td></tr>
<tr><td><code>leftrim</code></td>
<td>
<p>Level of left-tail trimming used in the computation, which is <code>NULL</code>.</p>
</td></tr>
<tr><td><code>rightrim</code></td>
<td>
<p>Level of right-tail trimming used in the computation, which is <code>NULL</code>.</p>
</td></tr>
<tr><td><code>E33err</code></td>
<td>
<p>A percent error between the expectation of the <code class="reqn">X_{3:3}</code> order statistic by analytical expression versus a theoretical by numerical integration using the <br /> <code><a href="#topic+expect.max.ostat">expect.max.ostat</a></code> function. This will be <code>NA</code> if <code>nmom == "3"</code>.</p>
</td></tr>
<tr><td><code>source</code></td>
<td>
<p>An attribute identifying the computational
source of the L-moments: &ldquo;lmomtri&rdquo;.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The expression for <code class="reqn">\tau_4</code> in terms of <code class="reqn">\tau_3</code> is
</p>
<pre>
  "tau4tri" &lt;- function(t3) {
     t3[t3 &lt; -0.14285710 | t3 &gt;  0.14285710] &lt;- NA
     b &lt;- 0.09012180
     a &lt;- c(0, -1.777361, 0, -17.89864, 0,  920.4924, 0, -37793.50)
     t4 &lt;- b + a[2]*t3^2 + a[4]*t3^4 + a[6]*t3^6 + a[8]*t3^8
     return(t4)
  }
</pre>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Asquith, W.H., 2011, Distributional analysis with L-moment statistics using the R environment for statistical computing: Createspace Independent Publishing Platform, ISBN 978&ndash;146350841&ndash;8.
</p>
<p>Nagaraja, H.N., 2013, Moments of order statistics and L-moments for the symmetric triangular distribution: Statistics and Probability Letters, v. 83, no. 10, pp. 2357&ndash;2363.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+partri">partri</a></code>, <code><a href="#topic+cdftri">cdftri</a></code>, <code><a href="#topic+pdftri">pdftri</a></code>, <code><a href="#topic+quatri">quatri</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>lmr &lt;- lmoms(c(46, 70, 59, 36, 71, 48, 46, 63, 35, 52))
lmr
lmomtri(partri(lmr), nmom="5")

par &lt;- vec2par(c(-405, -390, -102), type="tri")
lmomtri(par, nmom="5")$lambdas
# -299           39.4495050    5.5670228    1.9317914    0.8007511
theoLmoms.max.ostat(para=par, qua=quatri, nmom=5)$lambdas
# -299.0000126   39.4494885    5.5670486    1.9318732    0.8002989
# The -299 is the correct by exact solution as are 39.4495050 and 5.5670228, the 4th and
# 5th L-moments diverge from theoLmoms.max.ostat() because the exact solutions and not
# numerical integration of the quantile function was used for E11, E22, and E33.
# So although E44 and E55 come from expect.max.ostat() within both lmomtri() and
# theoLmoms.max.ostat(), the Lambda4 and Lambda5 are not the same because the E11, E22,
# and E33 values are different.

## Not run: 
# At extreme limit of Tau3 for the triangular distribution, L-moment ratio diagram
# shows convergence to the trajectory of the Generalized Pareto distribution.
"tau4tri" &lt;- function(t3) { t3[t3 &lt; -0.14285710 | t3 &gt;  0.14285710] &lt;- NA
   b &lt;- 0.09012180; a &lt;- c(0, -1.777361, 0, -17.89864, 0,  920.4924, 0, -37793.50)
   t4 &lt;- b + a[2]*t3^2 + a[4]*t3^4 + a[6]*t3^6 + a[8]*t3^8; return(t4)
}
F &lt;- seq(0,1, by=0.001)
lmr  &lt;- vec2lmom(c(10,9,0.142857, tau4tri(0.142857)))
parA &lt;- partri(lmr); parB &lt;- pargpa(lmr)
xA &lt;- qlmomco(F,  parA); xB &lt;- qlmomco(F, parB); x &lt;- sort(unique(c(xA,xB)))
plot(x,  pdftri(x,parA), type="l", col=8, lwd=4) # Compare Asym. Tri. to 
lines(x, pdfgpa(x,parB),           col=2)        # Gen. Pareto

## End(Not run)
</code></pre>

<hr>
<h2 id='lmomwak'>L-moments of the Wakeby Distribution</h2><span id='topic+lmomwak'></span>

<h3>Description</h3>

<p>This function estimates the L-moments of the Wakeby distribution given the parameters (<code class="reqn">\xi</code>, <code class="reqn">\alpha</code>, <code class="reqn">\beta</code>, <code class="reqn">\gamma</code>, and <code class="reqn">\delta</code>) from <code><a href="#topic+parwak">parwak</a></code>. The L-moments in terms of the parameters are complicated and solved numerically.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lmomwak(wakpara)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lmomwak_+3A_wakpara">wakpara</code></td>
<td>
<p>The parameters of the distribution.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> is returned.
</p>
<table>
<tr><td><code>lambdas</code></td>
<td>
<p>Vector of the L-moments. First element is
<code class="reqn">\lambda_1</code>, second element is <code class="reqn">\lambda_2</code>, and so on.</p>
</td></tr>
<tr><td><code>ratios</code></td>
<td>
<p>Vector of the L-moment ratios. Second element is
<code class="reqn">\tau</code>, third element is <code class="reqn">\tau_3</code> and so on.</p>
</td></tr>
<tr><td><code>trim</code></td>
<td>
<p>Level of symmetrical trimming used in the computation, which is <code>0</code>.</p>
</td></tr>
<tr><td><code>leftrim</code></td>
<td>
<p>Level of left-tail trimming used in the computation, which is <code>NULL</code>.</p>
</td></tr>
<tr><td><code>rightrim</code></td>
<td>
<p>Level of right-tail trimming used in the computation, which is <code>NULL</code>.</p>
</td></tr>
<tr><td><code>source</code></td>
<td>
<p>An attribute identifying the computational
source of the L-moments: &ldquo;lmomwak&rdquo;.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Hosking, J.R.M., 1990, L-moments&mdash;Analysis and estimation of distributions using linear combinations of order statistics: Journal of the Royal Statistical Society, Series B, v. 52, pp. 105&ndash;124.
</p>
<p>Hosking, J.R.M., 1996, FORTRAN routines for use with the method of L-moments: Version 3, IBM Research Report RC20525, T.J. Watson Research Center, Yorktown Heights, New York.
</p>
<p>Hosking, J.R.M., and Wallis, J.R., 1997, Regional frequency analysis&mdash;An approach based on L-moments: Cambridge University Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+parwak">parwak</a></code>, <code><a href="#topic+cdfwak">cdfwak</a></code>, <code><a href="#topic+pdfwak">pdfwak</a></code>, <code><a href="#topic+quawak">quawak</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>lmr &lt;- lmoms(c(123,34,4,654,37,78))
lmr
lmomwak(parwak(lmr))
</code></pre>

<hr>
<h2 id='lmomwei'>L-moments of the Weibull Distribution</h2><span id='topic+lmomwei'></span>

<h3>Description</h3>

<p>This function estimates the L-moments of the Weibull distribution given the parameters
(<code class="reqn">\zeta</code>, <code class="reqn">\beta</code>, and <code class="reqn">\delta</code>) from <code><a href="#topic+parwei">parwei</a></code>. The Weibull distribution is a reverse Generalized Extreme Value distribution.  As result, the Generalized Extreme Value algorithms (<code><a href="#topic+lmomgev">lmomgev</a></code>) are used for computation of the L-moments of the Weibull in this package (see <code><a href="#topic+parwei">parwei</a></code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lmomwei(para)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lmomwei_+3A_para">para</code></td>
<td>
<p>The parameters of the distribution.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> is returned.
</p>
<table>
<tr><td><code>lambdas</code></td>
<td>
<p>Vector of the L-moments. First element is
<code class="reqn">\lambda_1</code>, second element is <code class="reqn">\lambda_2</code>, and so on.</p>
</td></tr>
<tr><td><code>ratios</code></td>
<td>
<p>Vector of the L-moment ratios. Second element is
<code class="reqn">\tau</code>, third element is <code class="reqn">\tau_3</code> and so on.</p>
</td></tr>
<tr><td><code>trim</code></td>
<td>
<p>Level of symmetrical trimming used in the computation, which is <code>0</code>.</p>
</td></tr>
<tr><td><code>leftrim</code></td>
<td>
<p>Level of left-tail trimming used in the computation, which is <code>NULL</code>.</p>
</td></tr>
<tr><td><code>rightrim</code></td>
<td>
<p>Level of right-tail trimming used in the computation, which is <code>NULL</code>.</p>
</td></tr>
<tr><td><code>source</code></td>
<td>
<p>An attribute identifying the computational
source of the L-moments: &ldquo;lmomwei&rdquo;.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Hosking, J.R.M. and Wallis, J.R., 1997, Regional frequency analysis&mdash;An approach based on L-moments: Cambridge University Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+parwei">parwei</a></code>, <code><a href="#topic+cdfwei">cdfwei</a></code>, <code><a href="#topic+pdfwei">pdfwei</a></code>, <code><a href="#topic+quawei">quawei</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>lmr &lt;- lmoms(c(123,34,4,654,37,78))
lmr
lmomwei(parwei(lmr))
</code></pre>

<hr>
<h2 id='lmorph'>Morph an L-moment Object </h2><span id='topic+lmorph'></span>

<h3>Description</h3>

<p>Morph or change one L-moment object type into another. The first L-moment object created for <span class="pkg">lmomco</span> used an <span class="rlang"><b>R</b></span> <code>list</code> with named L-moment values (<code><a href="#topic+lmom.ub">lmom.ub</a></code>) such as <code>L1</code> or <code>TAU3</code>. This object was bounded for L-moment orders less than or equal to five. However, subsequent <span class="pkg">lmomco</span> development in early 2006 that was related to the trimmed L-moments suggested that an alternative L-moment object structure be used that utilized two vectors for the L-moments and the L-moment ratios (<code><a href="#topic+lmorph">lmorph</a></code>). This second object type is not bounded by L-moment order. In turn it became important to seemlessly morph from one object structure to the other and back again. The canonical structure of the first L-moment object type is documented under <code><a href="#topic+lmom.ub">lmom.ub</a></code>; whereas, the canonical structure for the second L-moment object type is documented under <code><a href="#topic+lmoms">lmoms</a></code> (actually through <code><a href="#topic+TLmoms">TLmoms</a></code>). Because the first L-moment object is bounded by five, L-moment order larger than this will be ignored in the morphing process.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lmorph(lmom)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lmorph_+3A_lmom">lmom</code></td>
<td>
<p>An L-moment object of type like <code>lmom.ub</code> or <code>lmoms</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A two different <span class="rlang"><b>R</b></span> <code>list</code>s (L-moment objects), which are the opposite of the argument type&mdash;see the documentation for <code><a href="#topic+lmom.ub">lmom.ub</a></code> and <code><a href="#topic+lmoms">lmoms</a></code>.
</p>


<h3>Note</h3>

<p>If any of the trimming characteristics of the second type of L-moment object (<code>trim</code>, <code>leftrim</code>, or <code>rightrim</code>) have a greater than zero value, then conversion to the L-moment object with named values will not be performed. A message will be provided that the conversion was not performed.  In April 2014, it was decided that all <code>lmomCCC()</code> functions, such as <code><a href="#topic+lmomgev">lmomgev</a></code> or <code><a href="#topic+lmomnor">lmomnor</a></code>, would be standardized to the less limited and easier to maintain vector output style of <code><a href="#topic+lmoms">lmoms</a></code>.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>See Also</h3>

<p><code><a href="#topic+lmom.ub">lmom.ub</a></code>, <code><a href="#topic+lmoms">lmoms</a></code>, <code><a href="#topic+TLmoms">TLmoms</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>lmr &lt;- lmom.ub(c(123,34,4,654,37,78))
lmorph(lmr)
lmorph(lmorph(lmr))
</code></pre>

<hr>
<h2 id='lmrdia'>L-moment Ratio Diagram Components</h2><span id='topic+lmrdia'></span>

<h3>Description</h3>

<p>This function returns a list of the L-skew and L-kurtosis (<code class="reqn">\tau_3</code> and <code class="reqn">\tau_4</code>, respectively) ordinates for construction of L-moment Ratio (L-moment diagrams) that are useful in selecting a distribution to model the data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lmrdia()
</code></pre>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> is returned.
</p>
<table>
<tr><td><code>limits</code></td>
<td>
<p>The theoretical limits of <code class="reqn">\tau_3</code> and <code class="reqn">\tau_4</code>; below <code class="reqn">\tau_4</code> of the theoretical limits are theoretically
not possible.</p>
</td></tr>
<tr><td><code>aep4</code></td>
<td>
<p><code class="reqn">\tau_3</code> and <code class="reqn">\tau_4</code> lower limits of the Asymmetric Exponential Power distribution.</p>
</td></tr>
<tr><td><code>cau</code></td>
<td>
<p><code class="reqn">\tau^{(1)}_3 = 0</code> and <code class="reqn">\tau^{(1)}_4 = 0.34280842</code> of the Cauchy distribution (TL-moment [trim=1])  (see <b>Examples</b> <code><a href="#topic+lmomcau">lmomcau</a></code> for source).</p>
</td></tr>
<tr><td><code>exp</code></td>
<td>
<p><code class="reqn">\tau_3</code> and <code class="reqn">\tau_4</code> of the Exponential distribution.</p>
</td></tr>
<tr><td><code>gev</code></td>
<td>
<p><code class="reqn">\tau_3</code> and <code class="reqn">\tau_4</code> of the Generalized Extreme Value distribution.</p>
</td></tr>
<tr><td><code>glo</code></td>
<td>
<p><code class="reqn">\tau_3</code> and <code class="reqn">\tau_4</code> of the Generalized Logistic distribution.</p>
</td></tr>
<tr><td><code>gpa</code></td>
<td>
<p><code class="reqn">\tau_3</code> and <code class="reqn">\tau_4</code> of the Generalized Pareto distribution.</p>
</td></tr>
<tr><td><code>gum</code></td>
<td>
<p><code class="reqn">\tau_3</code> and <code class="reqn">\tau_4</code> of the Gumbel distribution.</p>
</td></tr>
<tr><td><code>gno</code></td>
<td>
<p><code class="reqn">\tau_3</code> and <code class="reqn">\tau_4</code> of the Generalized Normal distribution.</p>
</td></tr>
<tr><td><code>gov</code></td>
<td>
<p><code class="reqn">\tau_3</code> and <code class="reqn">\tau_4</code> of the Govindarajulu distribution.</p>
</td></tr>
<tr><td><code>ray</code></td>
<td>
<p><code class="reqn">\tau_3</code> and <code class="reqn">\tau_4</code> of the Rayleigh distribution.</p>
</td></tr>
<tr><td><code>lognormal</code></td>
<td>
<p><code class="reqn">\tau_3</code> and <code class="reqn">\tau_4</code> of the Generalized Normal (3-parameter Log-Normal) distribution.</p>
</td></tr>
<tr><td><code>nor</code></td>
<td>
<p><code class="reqn">\tau_3</code> and <code class="reqn">\tau_4</code> of the Normal distribution.</p>
</td></tr>
<tr><td><code>pe3</code></td>
<td>
<p><code class="reqn">\tau_3</code> and <code class="reqn">\tau_4</code> of the Pearson Type III distribution.</p>
</td></tr>
<tr><td><code>pdq3</code></td>
<td>
<p><code class="reqn">\tau_3</code> and <code class="reqn">\tau_4</code> of the Polynomial Density-Quantile3 distribution.</p>
</td></tr>
<tr><td><code>rgov</code></td>
<td>
<p><code class="reqn">\tau_3</code> and <code class="reqn">\tau_4</code> of the reversed Govindarajulu.</p>
</td></tr>
<tr><td><code>rgpa</code></td>
<td>
<p><code class="reqn">\tau_3</code> and <code class="reqn">\tau_4</code> of the reversed Generalized Pareto.</p>
</td></tr>
<tr><td><code>sla</code></td>
<td>
<p><code class="reqn">\tau^{(1)}_3 = 0</code> and <code class="reqn">\tau^{(1)}_4 = 0.30420472</code> of the Slash distribution (TL-moment [trim=1]) (see <b>Examples</b> <code><a href="#topic+lmomsla">lmomsla</a></code> for source).</p>
</td></tr>
<tr><td><code>uniform</code></td>
<td>
<p><code class="reqn">\tau_3</code> and <code class="reqn">\tau_4</code> of the uniform distribution.</p>
</td></tr>
<tr><td><code>wei</code></td>
<td>
<p><code class="reqn">\tau_3</code> and <code class="reqn">\tau_4</code> of the Weibull distribution (reversed Generalized Extreme Value).</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Asquith, W.H., 2011, Distributional analysis with L-moment statistics using the R environment for statistical computing: Createspace Independent Publishing Platform, ISBN 978&ndash;146350841&ndash;8.
</p>
<p>Asquith, W.H., 2014, Parameter estimation for the 4-parameter asymmetric exponential power distribution by the method of L-moments using R: Computational Statistics and Data Analysis, v. 71, pp. 955&ndash;970.
</p>
<p>Hosking, J.R.M., 1986, The theory of probability weighted moments: Research Report RC12210, IBM Research Division, Yorkton Heights, N.Y.
</p>
<p>Hosking, J.R.M., 1990, L-moments&mdash;Analysis and estimation of distributions using linear combinations of order statistics: Journal of the Royal Statistical Society, Series B, v. 52, pp. 105&ndash;124.
</p>
<p>Hosking, J.R.M., 1996, FORTRAN routines for use with the method of L-moments: Version 3, IBM Research Report RC20525, T.J. Watson Research Center, Yorktown Heights, New York.
</p>
<p>Hosking, J.R.M., 2007, Distributions with maximum entropy subject to constraints on their L-moments or expected order statistics: Journal of Statistical Planning and Inference, v. 137, no. 9, pp. 2,870&ndash;2,891, <a href="https://doi.org/10.1016/j.jspi.2006.10.010">doi:10.1016/j.jspi.2006.10.010</a>.
</p>
<p>Hosking, J.R.M., and Wallis, J.R., 1997, Regional frequency analysis&mdash;An approach based on L-moments: Cambridge University Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+plotlmrdia">plotlmrdia</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>lratios &lt;- lmrdia()
</code></pre>

<hr>
<h2 id='lmrdia46'>L-moment Ratio Diagram Components of Tau4 and Tau6</h2><span id='topic+lmrdia46'></span>

<h3>Description</h3>

<p>This function returns a list of the L-kurtosis (<code class="reqn">\tau_4</code> and sixth L-moment ratio <code class="reqn">\tau_6</code>, respectively) ordinates for construction of L-moment Ratio (L-moment diagrams) that are useful in selecting a distribution to model the data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lmrdia46()
</code></pre>


<h3>Details</h3>

<p>The <code><a href="#topic+lmrdia46">lmrdia46</a></code> returns a list of the tables for drawing the trajectories of the distributions by its access of <code>.lmomcohash$</code><code>t46list</code> created by the <code>inst/doc/SysDataBuilder02.R</code> script for <code>sysdata.rda</code> construction used by the <span class="pkg">lmomco</span> package itself. The lookup table references below are pointing to the <code>inst/doc/t4t6</code> subdirectory of the package.
</p>
<p>A lookup table for the Exponential Power distribution is provided as <code>PowerExponential.txt</code> (<code>.lmomcohash$</code><code>tau46list$</code><code>pwrexp</code>), and this distribution is a special case of the Asymmetric Exponential Power4 (<code><a href="#topic+lmomaep4">lmomaep4</a></code>) (<code>.lmomcohash$</code><code>tau46list$</code><code>aep4</code>).
</p>
<p>A lookup table for the Symmetric Stable distribution is provided as <code>StableDistribution.txt</code> (<code>.lmomcohash$</code><code>tau46list$</code><code>symstable</code>).
</p>
<p>A lookup table for the Student t distribution is provided as <code>StudentT.txt</code><br />(<code>.lmomcohash$</code><code>tau46list$</code><code>st2</code>), and this distribution is the same as the Student 3t (<code><a href="#topic+lmomst3">lmomst3</a></code>) (<code>.lmomcohash$</code><code>tau46list$</code><code>st3</code>).
</p>
<p>A lookup table for the Tukey Lamda  distribution is provided as <code>SymTukeyLambda.txt</code> <br />(<code>.lmomcohash$</code><code>tau46list$</code><code>tukeylam</code>), and this distribution is not quite the same as the Generalized Lambda distribution (<code><a href="#topic+lmomgld">lmomgld</a></code>) (<code>.lmomcohash$</code><code>tau46list$</code><code>gld</code>).
</p>
<p>The normal distribution plots as a point in a Tau4-Tau6 L-moment ratio diagram as<br /><code>.lmomcohash$</code><code>tau46list$</code><code>nor</code> for which <code class="reqn">\tau_4^\mathrm{nor} = 30/\pi\times \mathrm{atan}(\sqrt{2}) - 9</code> <code class="reqn">= 0.1226017</code> and <br /><code class="reqn">\tau_6^\mathrm{nor} = 0.04365901</code> (numerical integration).
</p>
<p>Finally, the Cauchy and Slade distributions are symmetrical and can be plotted as well on Tau4-Tau6 L-moment ratio diagram if we permit their trim=1 TL-moments to be shown instead. These are inserted into the returned list as part of the operation of <code>lmrdia46()</code>.
</p>
<p><b>Tukey Lambda Notes</b>&mdash;The Tukey Lambda distribution is a simpler formulation than the Generalized Lambda.
</p>
<p style="text-align: center;"><code class="reqn">Q(F) = \frac{1}{\lambda} \biggl[F^\lambda - (1-F)^\lambda \biggr]\mbox{,}</code>
</p>

<p>for nonexceedance probability <code class="reqn">F</code> and <code class="reqn">\lambda \ne 0</code> and
</p>
<p style="text-align: center;"><code class="reqn">Q(F) = \mathrm{log}\biggl(\frac{F}{1-F}\biggr)\mbox{,}</code>
</p>

<p>for <code class="reqn">\lambda = 0</code> using the natural logarithm.
</p>
<p>Inspection of the distribution formulae inform us that the variation in the distribution, the scaling factor <code class="reqn">1/\lambda</code> to far left in the first definition, for instance, implies that the L-scale (<code class="reqn">\lambda_2</code>) is not constant and varies with <code class="reqn">\lambda</code>. The second L-moment of the Tukey Lambda (all odd order L-moments are zero) is
</p>
<p style="text-align: center;"><code class="reqn">\lambda_2 = \frac{2}{\lambda}\biggl[ -\frac{1}{1+\lambda} + \frac{2}{2+\lambda}\biggr]\mbox{, and}</code>
</p>

<p>the fourth and sixth L-moments are
</p>
<p style="text-align: center;"><code class="reqn">\lambda_4 = \frac{2}{\lambda}\biggl[ -\frac{1}{1+\lambda} + \frac{12}{2+\lambda} - \frac{30}{3+\lambda} + \frac{20}{4+\lambda}\biggr]\mbox{,}</code>
</p>

<p style="text-align: center;"><code class="reqn">\lambda_6 = \frac{2}{\lambda}\biggl[ -\frac{1}{1+\lambda} + \frac{30}{2+\lambda} - \frac{210}{3+\lambda} + \frac{560}{4+\lambda} - \frac{630}{5+\lambda} + \frac{252}{6+\lambda}\biggr]\mbox{\, and}</code>
</p>

<p><code class="reqn">\tau_4 = \lambda_4 / \lambda_2</code> and <code class="reqn">\tau_6 = \lambda_6 / \lambda_2</code>. The Tukey Lambda is not separately implemented in the <span class="pkg">lmomco</span> package. It is provided herein for theoretical completeness, but it is possible to implement the Tukey Lambda by the following example:
</p>
<pre>
  tukeylam &lt;- .lmomcohash$tau46list$gld_byt6tukeylam
  lmr1 &lt;- tukeylam[tukeylam$lambda2 == 1, ] # L-scale equal to one (for instance)
  lmr1 &lt;- vec2lmom(c(0, lmr1$lambda2, 0, lmr1$tau4, 0, lmr1$tau6))
  tuk1 &lt;- pargld(lmr1, aux="tau6")
  print(tuk1$para, 12)
  #                 xi              alpha              kappa                  h
  #  2.50038766315e-04 -5.82180675380e+03 -1.71745206920e-04 -1.71702273015e-04
  lambda &lt;- mean(tuk1$para[3:4]) # remember optimization is used for parameters in
  # GLD parlance and so the two shape parameters are not constrained in pargld()
  # to be numerically identical. So, here, let us compute a mean of the two and then
  # use that as the Lambda in the distribution.
  eps &lt;- 1/tuk1$para[2] - lambda
  message("EPS should be very close to zero, eps = ", eps, " !!!!!")
  tuk2 &lt;- vec2par(c(0, 1/lambda, lambda, lambda), type="gld") # now Tukey Lambda
  lmr2 &lt;- lmomgld(tuk2)

  "ofunc" &lt;- function(lambda, lambda2=NA) {
    tukeyL2 &lt;- ( 2 / lambda ) * ( -1 / (1+lambda) + 2 / (2+lambda) )
    return(lambda2 - tukeyL2)
  }
  lam  &lt;- uniroot(ofunc, interval=c(-1, 1), lambda2=1)$root
  tuk3 &lt;- vec2par(c(0, 20/lam, lam, lam), type="gld")
  lmr3 &lt;- lmomgld(tuk3)

  gld5 &lt;- pargld(lmr3, aux="tau5"); gldlmr5 &lt;- theoLmoms(gld5, nmom=6)
  gld6 &lt;- pargld(lmr3, aux="tau6"); gldlmr6 &lt;- theoLmoms(gld6, nmom=6)
  plotlmrdia46(lmrdia46(), nogld_byt5opt=FALSE)
  points(gldlmr5$ratios[4], gldlmr5$ratios[6], pch=16, col="purple")
  points(gldlmr6$ratios[4], gldlmr6$ratios[6], pch=21, col="purple", bg="white")
  # See how GLD by tau5 optimization, which leaves Tau6 to float plots on the
  # "gld_byt5opt" trajectory, but GLD by tau6 optimization, plots on the Tukey
  # Lambda line, and gld6$para[2] / (1/gld6$para[3]) is equal to the 20 in the
  # parameter setting for tuk3.
</pre>
<p>The finally differences in the L-moments between the two <code>lmr</code> objects are all are reasonably close to zero with the recognition that <code>optim()</code> has been involved getting us close to the Tukey Lambda that we desire as a GLD with fixed shape parameters and scale factor equal to the inverse of the shape parameter. The demonstration to how to thus acquire a Tukey Lambda from GLD implementation in the <span class="pkg">lmomco</span> package is thus shown.
</p>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> is returned.
</p>
<table>
<tr><td><code>aep4</code></td>
<td>
<p><code class="reqn">\tau_4</code> and <code class="reqn">\tau_6</code> of the 4-parameter Asymmetric Exponential Power (AEP4) distribution given L-skew set as <code class="reqn">\tau_3 = 0</code>. This becomes then the (Symmetrical) Exponential Power. The complementary entry <code>pwrexp</code> are the effectively the same curve for the power exponential distribution based on lookup table archived in the <span class="pkg">lmomco</span> package. The table stems from <code>inst/doc/SysDataBuilder02.R</code>. The <code>aep4</code> and not <code>pwrexp</code> is used in the line drawing by <code><a href="#topic+plotlmrdia46">plotlmrdia46</a></code>.</p>
</td></tr>
<tr><td><code>gld_byt5opt</code></td>
<td>
<p><code class="reqn">\tau_4</code> and <code class="reqn">\tau_6</code> of the Generalized Lambda (GLD) distribution given L-skew set as <code class="reqn">\tau_3 = 0</code> and optimized by <code><a href="#topic+pargld">pargld</a></code> with <code>pargld(..., aux="tau5")</code> with <code class="reqn">\tau_5 = 0</code>. The table stems from <code>inst/doc/SysDataBuilder02.R</code>. The table <code>gld_byt5opt</code> is used in the line drawing by <code><a href="#topic+plotlmrdia46">plotlmrdia46</a></code> in relation to the argument therein of <code>nogld_byt5opt</code>. This is the trajectory of the symmetrical GLD having constant L-scale (<code class="reqn">\lambda_2</code>); this is different than the structurally similar by not identical Tukey Lambda distribution.</p>
</td></tr>
<tr><td><code>gld_byt6tukeylam</code></td>
<td>
<p><code class="reqn">\tau_4</code> and <code class="reqn">\tau_6</code> of the Generalized Lambda distribution given L-skew set as <code class="reqn">\tau_3 = 0</code> and optimized by <code><a href="#topic+pargld">pargld</a></code> with <code>pargld(..., aux="tau6")</code> with <code class="reqn">\tau_6(\tau_4)</code> (<code class="reqn">\tau_6</code> as a function of <code class="reqn">\tau_4</code>, see <code>gld_byt6tukeylam</code> table). The table stems from <code>inst/</code><code>doc/</code><br /><code>SysDataBuilder02.R</code>. The <code>gld_byt6tukeylam</code> is used in the line drawing by <code><a href="#topic+plotlmrdia46">plotlmrdia46</a></code> in relation to the argument therein of <code>notukey</code>. This relation between <code class="reqn">\{\tau_4, \tau_6\}</code> is that of the Tukey Lambda distribution; this is the trajectory of the symmetrical GLD having nonconstant L-scale (<code class="reqn">\lambda_2</code>).</p>
</td></tr>
<tr><td><code>nor</code></td>
<td>
<p><code class="reqn">\tau_4</code> and <code class="reqn">\tau_6</code> of the Normal distribution. The table stems from <code>inst/doc/</code><br /><code>SysDataBuilder02.R</code>. The <code>nor</code> is used in the point drawing by <br /><code><a href="#topic+plotlmrdia46">plotlmrdia46</a></code>.</p>
</td></tr>
<tr><td><code>pdq4</code></td>
<td>
<p><code class="reqn">\tau_4</code> and <code class="reqn">\tau_6</code> of the Polynomial Density-Quantile4 distribution, which implicitly is symmetrical, and therefore L-skew set as <code class="reqn">\tau_3 = 0</code>. The table stems from <code>inst/doc/SysDataBuilder02.R</code>. The <code>pdq4</code> is used in the line drawing by<br /><code><a href="#topic+plotlmrdia46">plotlmrdia46</a></code>.</p>
</td></tr>
<tr><td><code>pwrexp</code></td>
<td>
<p><code class="reqn">\tau_4</code> and <code class="reqn">\tau_6</code> of the Power Exponential distribution of which the Asymmetric Exponential Power distribution (see also <code><a href="#topic+lmomaep4">lmomaep4</a></code>). The lookup table archive in the <span class="pkg">lmomco</span> package for the Power Exponential (<code>PowerExponential.txt</code>) is confirmed to match the computation in <code>aep4</code> based on the AEP4 instead. The table stems from <code>inst/doc/</code><br /><code>SysDataBuilder02.R</code>.</p>
</td></tr>
<tr><td><code>st2</code></td>
<td>
<p><code class="reqn">\tau_4</code> and <code class="reqn">\tau_6</code> of the well-known Student t distribution. The lookup table archive in the <span class="pkg">lmomco</span> package for the Student t (<code>StudentT.txt</code>) is confirmed to match the computation in <code>st3</code> based on the ST3 instead. The table stems from <br /><code>inst/doc/SysDataBuilder02.R</code>. The <code>st3</code> and not <code>st2</code> is used in the line drawing by <code><a href="#topic+plotlmrdia46">plotlmrdia46</a></code>.</p>
</td></tr>
<tr><td><code>st3</code></td>
<td>
<p><code class="reqn">\tau_4</code> and <code class="reqn">\tau_6</code> of the Student 3t distribution (<code><a href="#topic+lmomst3">lmomst3</a></code>). The table stems from <br /><code>inst/doc/SysDataBuilder02.R</code>. The <code>st3</code> and not <code>st2</code> is used in the line drawing by <code><a href="#topic+plotlmrdia46">plotlmrdia46</a></code>.</p>
</td></tr>
<tr><td><code>symstable</code></td>
<td>
<p><code class="reqn">\tau_4</code> and <code class="reqn">\tau_6</code> of the Stable distribution, which is not otherwise supported in <span class="pkg">lmomco</span>. The lookup table archive in the <span class="pkg">lmomco</span> package for the Symmetrical Stable distribution is <code>StableDistribution.txt</code>. The table stems from <br /><code>inst/doc/SysDataBuilder02.R</code>. The <code>symstable</code> is used in the line drawing by <code><a href="#topic+plotlmrdia46">plotlmrdia46</a></code>.</p>
</td></tr>
<tr><td><code>tukeylam</code></td>
<td>
<p>(reference copy of <code>gld_byt6tukeylam</code>) <code class="reqn">\tau_4</code> and <code class="reqn">\tau_6</code> of the Tukey Lambda distribution (<a href="https://en.wikipedia.org/wiki/Tukey_lambda_distribution">https://en.wikipedia.org/wiki/Tukey_lambda_distribution</a>) that is not supported per se in <span class="pkg">lmomco</span> because the Generalized Lambda distribution is instead. The <code>SymTukeyLambda.txt</code> is the lookup table archive in the <span class="pkg">lmomco</span> package for the Tukey Lambda distribution confirmed to match the mathematics shown herein. The measure <code class="reqn">L-scale</code> or the second L-moment is not constant for the Symmetric Tukey Lambda as formulated. So, the trajectory of this distribution is not for a constant L-scale, which is unlike that for the Generalized Lambda. The table stems from <code>inst/doc/SysDataBuilder02.R</code>. The <code>tukeylam</code> is used in the line drawing by <code><a href="#topic+plotlmrdia46">plotlmrdia46</a></code>.</p>
</td></tr>
<tr><td><code>cau</code></td>
<td>
<p><code class="reqn">\tau^{(1)}_4 = 0.34280842</code> and <code class="reqn">\tau^{(1)}_6 = 0.20274358</code> (trim=1 TL-moments) of the Cauchy distribution (TL-moment [trim=1]) (see <b>Examples</b> <code><a href="#topic+lmomcau">lmomcau</a></code> for source).</p>
</td></tr>
<tr><td><code>sla</code></td>
<td>
<p><code class="reqn">\tau^{(1)}_4 = 0.30420472</code> and <code class="reqn">\tau^{(1)}_6 = 0.18900723</code> (trim=1 TL-moments) of the Slash distribution (TL-moment [trim=1]) (see <b>Examples</b> <code><a href="#topic+lmomsla">lmomsla</a></code> for source).</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>See Also</h3>

<p><code><a href="#topic+plotlmrdia46">plotlmrdia46</a></code>, <code><a href="#topic+lmrdia">lmrdia</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>lratios &lt;- lmrdia46()
</code></pre>

<hr>
<h2 id='lmrdiscord'>Compute Discordance on L-CV, L-skew, and L-kurtosis </h2><span id='topic+lmrdiscord'></span>

<h3>Description</h3>

<p>This function computes the Hosking and Wallis discordancy of the first three L-moment ratios (L-CV, L-skew, and L-kurtosis) according to their implementation in Hosking and Wallis (1997) and earlier. Discordancy triplets of these L-moment ratios is heuristically measured by effectively locating the triplet from the mean center of the 3-dimensional cloud of values. The <span class="pkg">lmomRFA</span> provides for discordancy embedded in the &ldquo;L-moment method&rdquo; of regional frequency analysis. The author of <span class="pkg">lmomco</span> chooses to have a separate &ldquo;high level&rdquo; implementation for emergent ideas of his in evaluating unusual sample distributions outside of the <code>regdata</code> object class envisioned by Hosking in the <span class="pkg">lmomRFA</span> package.
</p>
<p>Let <code class="reqn">\bm{\mu_i}</code> be a row vector of the values of <code class="reqn">\tau^{[i]}_2, \tau^{[i]}_3, \tau^{[i]}_4</code> and these are the L-moment ratios for the <code class="reqn">i</code>th group or site out of <code class="reqn">n</code> sites. Let <code class="reqn">\bm{\overline\mu}</code> be a row vector of mean values of all the <code class="reqn">n</code> sites. Defining a sum of squares and cross products  <code class="reqn">3\times 3</code> matrix as
</p>
<p style="text-align: center;"><code class="reqn">\bm{S} = \sum_i^n (\bm{\mu} - \bm{\overline\mu})(\bm{\mu} - \bm{\overline\mu})^{T}</code>
</p>

<p>compute the discorancy of the <code class="reqn">i</code>th site as
</p>
<p style="text-align: center;"><code class="reqn">
D_i = \frac{n}{3} (\bm{\mu} - \bm{\overline\mu})^T \bm{S}^{-1} (\bm{\mu} - \bm{\overline\mu}\mbox{.})
</code>
</p>

<p>The L-moments of a sample for a location are judged to be discordance if <code class="reqn">D_i</code> exceeds a critical value. The critical value is a function of sample size. Hosking and Wallis (1997, p. 47) provide a table for general application. By about <code class="reqn">n=14</code>, the critical value is taken as <code class="reqn">D_c = 3</code>, although the <code class="reqn">D_{max}</code> increases with sample size. Specifically, the <code class="reqn">D_i</code> has an upper limit of
</p>
<p style="text-align: center;"><code class="reqn">D_i \le (n-1)/3\mbox{.}</code>
</p>

<p>However, Hosking and Wallis (1997, p. 47) recommend &ldquo;that any site with <code class="reqn">D_i &gt; 3</code> be regarded as discordant.&rdquo; A statistical test of <code class="reqn">D_i</code> can be constructed. Hosking and Wallis (1997, p. 47) report that the <code class="reqn">D_{critical}</code> is
</p>
<p style="text-align: center;"><code class="reqn">D_{critical, n, \alpha} = \frac{(n - 1)Z}{n - 4 + 3Z}\mbox{,}</code>
</p>

<p>where
</p>
<p style="text-align: center;"><code class="reqn">Z = F(\alpha/n, 3, n - 4)\mbox{,}</code>
</p>

<p>upper-tail quantile of the F distribution with degrees of freedom 3 and <code class="reqn">n - 4</code>. A table of critical values is preloaded into the <code><a href="#topic+lmrdiscord">lmrdiscord</a></code> function as this mimics the table of Hosking and Wallis (1997, table 3.1) as a means for cross verification. This table corresponds to an <code class="reqn">\alpha = 0.1</code> significance.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lmrdiscord(site=NULL, t2=NULL, t3=NULL, t4=NULL,
           Dcrit=NULL, digits=4, lmrdigits=4, sort=TRUE,
           alpha1=0.10, alpha2=0.01, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lmrdiscord_+3A_site">site</code></td>
<td>
<p>An optional group or site identification; it will be sequenced from 1 to <code class="reqn">n</code> if <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="lmrdiscord_+3A_t2">t2</code></td>
<td>
<p>L-CV values; emphasis that L-scale is not used.</p>
</td></tr>
<tr><td><code id="lmrdiscord_+3A_t3">t3</code></td>
<td>
<p>L-skew values.</p>
</td></tr>
<tr><td><code id="lmrdiscord_+3A_t4">t4</code></td>
<td>
<p>L-kurtosis values.</p>
</td></tr>
<tr><td><code id="lmrdiscord_+3A_dcrit">Dcrit</code></td>
<td>
<p>An optional (user specified) critical value for discordance. This value will override the Hosking and Wallis (1997, table 3.1) critical values.</p>
</td></tr>
<tr><td><code id="lmrdiscord_+3A_digits">digits</code></td>
<td>
<p>The number of digits in rounding operations.</p>
</td></tr>
<tr><td><code id="lmrdiscord_+3A_lmrdigits">lmrdigits</code></td>
<td>
<p>The numer of digits in rounding operation for the echo of the L-moment ratios.</p>
</td></tr>
<tr><td><code id="lmrdiscord_+3A_sort">sort</code></td>
<td>
<p>A logical on the sort status of the returned data frame.</p>
</td></tr>
<tr><td><code id="lmrdiscord_+3A_alpha1">alpha1</code></td>
<td>
<p>A significance level that is greater (less significant, although in statistics we need to avoid assigning less or more in this context) than <code>alpha2</code>.</p>
</td></tr>
<tr><td><code id="lmrdiscord_+3A_alpha2">alpha2</code></td>
<td>
<p>A significance level that is less (more significant, although in statistics we need to avoid assigning less or more in this context) than <code>alpha1</code>.</p>
</td></tr>
<tr><td><code id="lmrdiscord_+3A_...">...</code></td>
<td>
<p>Other arguments that might be used. The author added these because it was found that the function was often called by higher level functions that aggregated much of the discordance computations.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>data.frame</code> is returned.
</p>
<table>
<tr><td><code>site</code></td>
<td>
<p>The group or site identification as used by the function.</p>
</td></tr>
<tr><td><code>t2</code></td>
<td>
<p>L-CV values.</p>
</td></tr>
<tr><td><code>t3</code></td>
<td>
<p>L-skew values.</p>
</td></tr>
<tr><td><code>t4</code></td>
<td>
<p>L-kurtosis.</p>
</td></tr>
<tr><td><code>Dmax</code></td>
<td>
<p>The maximum discordancy <code class="reqn">D_{max} = (n-1)/3</code>.</p>
</td></tr>
<tr><td><code>Dalpha1</code></td>
<td>
<p>The critical value of <code class="reqn">D</code> for <code class="reqn">\alpha_1 = 0.10</code> (default) significance as set by <code>alpha1</code> argument.</p>
</td></tr>
<tr><td><code>Dalpha2</code></td>
<td>
<p>The critical value of <code class="reqn">D</code> for <code class="reqn">\alpha_2 = 0.01</code> (default) significance as set by <code>alpha1</code> argument.</p>
</td></tr>
<tr><td><code>Dcrit</code></td>
<td>
<p>The critical value of discordancy (user or tabled).</p>
</td></tr>
<tr><td><code>D</code></td>
<td>
<p>The discordancy of the L-moment ratios used to trigger the logical in <code>isD</code>.</p>
</td></tr>
<tr><td><code>isD</code></td>
<td>
<p>Are the L-moment ratios discordant (if starred).</p>
</td></tr>
<tr><td><code>signif</code></td>
<td>
<p>A hyphen, star, or double star based on the <code>Dalpha1</code> and <code>Dalpha2</code> values.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>W.H. Asquith </p>


<h3>Source</h3>

<p>Consultation of the <code>lmomRFA.f</code> and <code>regtst()</code> function of the <span class="pkg">lmomRFA</span> <span class="rlang"><b>R</b></span> package by J.R.M. Hosking. Thanks Jon and Jim Wallis for such a long advocation of the discordancy issue that began at least as early as the 1993 Water Resources Research Paper (-wha).
</p>


<h3>References</h3>

<p>Hosking, J.R.M., and Wallis, J.R., 1997, Regional frequency analysis&mdash;An approach based on L-moments: Cambridge University Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lmoms">lmoms</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# This is the canonical test of lmrdiscord().
library(lmomRFA) # Import lmomRFA, needs lmom package too
data(Cascades)   # Extract Hosking's data use in his examples
data &lt;- as.regdata(Cascades) # A "regional" data structure
Dhosking &lt;- sort(regtst(data)$D, decreasing=TRUE) # Discordancy

Dlmomco &lt;- lmrdiscord(site=data$name, t2=data$t, t3=data$t_3, t4=data$t_4)

Dasquith &lt;- Dlmomco$D
# Now show the site id, and the two discordancy computations
print(data.frame(NAME=data$name, Dhosking=Dhosking,
                                 Dasquith=Dasquith))
# The Dhosking and Dasquith columns had better match!

set.seed(3) # This seed produces a "*" and "**", but users
# are strongly encouraged to repeat the folowing code block
# over and over with an unspecified seed and look at the table.
n &lt;- 30 # simulation sample size
par1 &lt;- lmom2par(vec2lmom(c(1, .23, .2, .1)), type="kap")
par2 &lt;- lmom2par(vec2lmom(c(1, .5, -.1)),      type="gev")
name &lt;- t2 &lt;- t3 &lt;- t4 &lt;- vector(mode="numeric")
for(i in 1:20) {
  X &lt;- rlmomco(n, par1); lmr &lt;- lmoms(X)
  t2[i] &lt;- lmr$ratios[2]
  t3[i] &lt;- lmr$ratios[3]
  t4[i] &lt;- lmr$ratios[4]
  name[i] &lt;- "kappa"
}
j &lt;- length(t2)
for(i in 1:3) {
  X &lt;- rlmomco(n, par2); lmr &lt;- lmoms(X)
  t2[j + i] &lt;- lmr$ratios[2]
  t3[j + i] &lt;- lmr$ratios[3]
  t4[j + i] &lt;- lmr$ratios[4]
  name[j + i] &lt;- "gev"
}
D &lt;- lmrdiscord(site=name, t2=t2, t3=t3, t4=t4)
print(D)

plotlmrdia(lmrdia(), xlim=c(-.2,.6), ylim=c(-.1, .4),
           autolegend=TRUE, xleg=0.1, yleg=.4)
points(D$t3,D$t4)
text(D$t3,D$t4,D$site, cex=0.75, pos=3)
text(D$t3,D$t4,D$D, cex=0.75, pos=1) #
## End(Not run)
</code></pre>

<hr>
<h2 id='lmrloc'>Line-of-Organic Correlation</h2><span id='topic+lmrloc'></span>

<h3>Description</h3>

<p>Compute the line-of-organic correlation (LOC) (Helsel and others, 2020, sec. 10.2.2, p. 280). The LOC is estimated by both L-moments and product moments. The LOC has other names in the literature including reduced major axis and line of diagonal correlation. When describing a functional relations between two variables without trying to predict one from the other, LOC is more appropriate than ordinary least squares (OLS).
</p>
<p>The LOC is a regression line whose slope is computed by the ratio between respective variations of the predictor variable and the response variable. The intercept of the line is computed such that the line passes through the familiar arithmetic mean (first L-moment) (<code class="reqn">\lambda_1</code>) each for the two variables. Relative variation is readily computed by the ratio of standard deviations or for more robust and less biased estimation by the ratio of the L-variations (second L-moment) (<code class="reqn">\lambda_2</code>) of the two variables.
</p>
<p>The <code class="reqn">\lambda_2</code> is generically based on the so-called Gini mean difference statistic (GMD) (<code class="reqn">\mathcal{G}</code>) by <code class="reqn">\lambda_2 = \mathcal{G}/2</code> (<code><a href="#topic+gini.mean.diff">gini.mean.diff</a></code>). Incidentally for the normal distribution, the well-known standard deviation is the product <code class="reqn">\lambda_2\sqrt{\pi}</code> (see also <code><a href="#topic+lmomnor">lmomnor</a></code>). Mathematically, GMD is defined as the linear combination
</p>
<p style="text-align: center;"><code class="reqn">\mathcal{G} = \frac{2}{n(n-1)}\sum_{i=1}^n (2i - n - 1) x_{i:n}\mbox{,}</code>
</p>

<p>where <code class="reqn">x_{i:n}</code> are the sample ascending order statistics.
</p>
<p>Returning to the need to estimate the LOC slope, algebra shows the slope is the ratio of the <code class="reqn">\mathcal{G}</code> values as
</p>
<p style="text-align: center;"><code class="reqn">m = \mathrm{sign[} \rho \mathrm{]}\cdot\frac{\sum_{i=1}^n (2i - n - 1) X_{i:n}}{\sum_{i=1}^n (2i - n - 1) Y_{i:n}}\mbox{,}</code>
</p>

<p>where <code class="reqn">X_{i:n}</code> is an ordered (ascending) vector of random variable <code class="reqn">X</code>, <code class="reqn">Y_{i:n}</code> is an ordered (ascending) vector of random variable <code class="reqn">Y</code>, and the slope sign can be computed by a correlation coefficient sign (Pearson R, Kendall Tau [computationally slowest], Spearman Rho would all work [implemented for the function, <code class="reqn">\rho</code>]). For applications, it is critical that the correlation coefficient is computed using the original correlated-ordering of <code class="reqn">X</code> and <code class="reqn">Y</code> and not after individual vector sorting that is needed for the GMD (L-moments). A developer, therefore, must be cognizant of the placement in code when the two variables are sorted to the order statistics for <code class="reqn">\mathcal{G}</code> computations.
</p>
<p>The LOC intercept is given by algebra by
</p>
<p style="text-align: center;"><code class="reqn">b = \frac{1}{n}\biggl(\sum_{i=1}^n X_{i:n} - m \cdot \sum_{i=1}^n Y_{i:n}\biggr)\mbox{.}</code>
</p>

<p>Helsel and others (2020, p. 281) enumerate some advantages to the use of the LOC: (1) it minimizes errors in both <code>x</code> and <code>y</code> directions, (2) it provides a single line regardless of which variable (x or y) is used as the response variable, and (3) its cumulative distribution function of the predictions, including the variance and probabilities, is correct (meaning not compressed as in OLS). The LOC is particularly useful for modeling the intrinsic functional relation between two variables, both of which are measured with error and (or) when neither variable is considered an independent variable appropriate to predict the other.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lmrloc(x, y=NULL, terse=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lmrloc_+3A_x">x</code></td>
<td>
<p>A numeric vector, matrix or data frame.</p>
</td></tr>
<tr><td><code id="lmrloc_+3A_y">y</code></td>
<td>
<p><code>NULL</code> (default) or a vector of same length of <code>x</code>.</p>
</td></tr>
<tr><td><code id="lmrloc_+3A_terse">terse</code></td>
<td>
<p>A logical triggering only return of the coefficients of the two lines; otherwise, the intermediate computations are also returned.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> is returned with <code>terse=TRUE</code> with two vectors of the intercept and slope coefficients for the L-moment and the product moment versions. The names on the vectors, respectively, are <code>"LMR_Intercept", "LMR_Slope"</code> and <code>"PMR_Intercept", "PMR_Slope"</code> for LMR (L-moment ratio) and PMR (product moment ratio) are monikers for the two approaches. An expanded <span class="rlang"><b>R</b></span> <code>list</code> is returned with <code>terse=FALSE</code> with the intermediate computations also provided.
</p>
<table>
<tr><td><code>loc_lmr</code></td>
<td>
<p>The LOC by L-moments (L-variations or equivalently Gini Mean Differences).</p>
</td></tr>
<tr><td><code>loc_pmr</code></td>
<td>
<p>The LOC by product moments (standard deviations).</p>
</td></tr>
<tr><td><code>srho</code></td>
<td>
<p>The sign on Spearman Rho.</p>
</td></tr>
<tr><td><code>mu_x</code></td>
<td>
<p>The arithmetic mean of the <code>x</code> variable.</p>
</td></tr>
<tr><td><code>mu_y</code></td>
<td>
<p>The arithmetic mean of the <code>y</code> variable.</p>
</td></tr>
<tr><td><code>gini_x</code></td>
<td>
<p>The GMD of the <code>x</code> variable.</p>
</td></tr>
<tr><td><code>gini_y</code></td>
<td>
<p>The GMD of the <code>y</code> variable.</p>
</td></tr>
<tr><td><code>sd_x</code></td>
<td>
<p>The standard deviation of the <code>x</code> variable.</p>
</td></tr>
<tr><td><code>sd_y</code></td>
<td>
<p>The standard deviation of the <code>y</code> variable.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Helsel, D.R., Hirsch, R.M., Ryberg, K.R., Archfield, S.A., and Gilroy, E.J., 2020, Statistical methods in water resources: U.S. Geological Survey Techniques and Methods, book 4, chap. A3, 458 p., <a href="https://doi.org/10.3133/tm4a3">doi:10.3133/tm4a3</a>.
</p>
<p>Hosking, J.R.M., 1990, L-moments&mdash;Analysis and estimation of
distributions using linear combinations of order statistics: Journal of the Royal Statistical Society, Series B, v. 52, pp. 105&ndash;124.
</p>
<p>Jurečková, J., and Picek, J., 2006, Robust statistical methods with R: Boca Raton, Fla., Chapman and Hall/CRC, ISBN 1&ndash;58488&ndash;454&ndash;1.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gini.mean.diff">gini.mean.diff</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 100; x &lt;- rnorm(n); y &lt;- -0.4 * x + rnorm(n, sd=0.2)
y[x == min(x)] &lt;- 2 * min(y) # throw in an outlier to help separate two lines
loc &lt;- lmrloc(x, y, terse=FALSE)
plot(x, y)
abline(loc$loc_lmr, lty=1)
abline(loc$loc_pmr, lty=2)
legend("topright", c("LOC by L-moments", "LOC by product moments"), lty=c(1,2))

olsxy &lt;- 1 / coefficients(stats::lm(x~y))[2] # yes inversion needed to show
olsyx &lt;-     coefficients(stats::lm(y~x))[2] # geometric mean in proper way
mstar &lt;- loc$srho * sqrt(abs(olsxy) * abs(olsyx)); names(mstar) &lt;- NULL
m_pmr &lt;- loc$loc_pmr[2]; names(m_pmr) &lt;- NULL
m_lmr &lt;- loc$loc_lmr[2]; names(m_lmr) &lt;- NULL
message("Geometric mean OLS slopes = ", mstar) # see that these two are
message("           PMR LOC slope  = ", m_pmr) # equivalent by theory
message("           LMR LOC slope  = ", m_lmr) # this one is not
</code></pre>

<hr>
<h2 id='lrv2prob'>Convert a Vector of Logistic Reduced Variates to Annual Nonexceedance Probabilities</h2><span id='topic+lrv2prob'></span>

<h3>Description</h3>

<p>This function converts a vector of logistic reduced variates (<code class="reqn">lrv</code>) to annual nonexceedance probabilities <code class="reqn">F</code>
</p>
<p style="text-align: center;"><code class="reqn">F = -\log((1-lrv)/lrv)\mbox{,}</code>
</p>

<p>where <code class="reqn">0 \le F \le 1</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lrv2prob(lrv)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lrv2prob_+3A_lrv">lrv</code></td>
<td>
<p>A vector of logistic reduced variates.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of annual nonexceedance probabilities.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Bradford, R.B., 2002, Volume-duration growth curves for flood estimation in permeable catchments: Hydrology and Earth System Sciences, v. 6, no. 5, pp. 939&ndash;947.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+prob2lrv">prob2lrv</a></code>, <code><a href="#topic+prob2T">prob2T</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>T &lt;- c(1, 2, 5, 10, 25, 50, 100, 250, 500); lrv &lt;- prob2grv(T2prob(T))
F &lt;- lrv2prob(lrv)
</code></pre>

<hr>
<h2 id='lrzlmomco'>Lorenz Curve  of the Distributions</h2><span id='topic+lrzlmomco'></span>

<h3>Description</h3>

<p>This function computes the Lorenz Curve for quantile function <code class="reqn">x(F)</code> (<code><a href="#topic+par2qua">par2qua</a></code>, <code><a href="#topic+qlmomco">qlmomco</a></code>). The function is defined by Nair et al. (2013, p. 174) as
</p>
<p style="text-align: center;"><code class="reqn">L(u) = \frac{1}{\mu}\int_0^u x(p)\; \mathrm{d}p\mbox{,}</code>
</p>

<p>where <code class="reqn">L(u)</code> is the Lorenz curve for nonexceedance probability <code class="reqn">u</code>. The Lorenz curve is related to the Bonferroni curve (<code class="reqn">B(u)</code>, <code><a href="#topic+bfrlmomco">bfrlmomco</a></code>) by
</p>
<p style="text-align: center;"><code class="reqn">L(u) = \mu B(u)\mbox{.}</code>
</p>



<h3>Usage</h3>

<pre><code class='language-R'>lrzlmomco(f, para)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lrzlmomco_+3A_f">f</code></td>
<td>
<p>Nonexceedance probability (<code class="reqn">0 \le F \le 1</code>).</p>
</td></tr>
<tr><td><code id="lrzlmomco_+3A_para">para</code></td>
<td>
<p>The parameters from <code><a href="#topic+lmom2par">lmom2par</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Lorzen curve value for <code class="reqn">F</code>.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Nair, N.U., Sankaran, P.G., and Balakrishnan, N., 2013, Quantile-based reliability analysis: Springer, New York.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+qlmomco">qlmomco</a></code>, <code><a href="#topic+bfrlmomco">bfrlmomco</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># It is easiest to think about residual life as starting at the origin, units in days.
A &lt;- vec2par(c(0.0, 2649, 2.11), type="gov") # so set lower bounds = 0.0
f &lt;- c(0.25, 0.75) # Both computations report: 0.02402977 and 0.51653731
Lu1 &lt;-   lrzlmomco(f, A)
Lu2 &lt;- f*bfrlmomco(f, A)

# The Lorenz curve is related to the Gini index (G), which is L-CV:
"afunc" &lt;- function(u) { return(lrzlmomco(f=u, A)) }
L &lt;- integrate(afunc, lower=0, upper=1)$value
G &lt;- 1 - 2*L                                                    # 0.4129159
G &lt;- 1 - expect.min.ostat(2,para=A,qua=quagov)*cmlmomco(f=0,A)  # 0.4129159
LCV &lt;- lmomgov(A)$ratios[2]                                     # 0.41291585
</code></pre>

<hr>
<h2 id='mle2par'>Use Maximum Likelihood to Estimate Parameters of a Distribution</h2><span id='topic+mle2par'></span>

<h3>Description</h3>

<p>This function uses the method of maximum likelihood (MLE) to estimate the parameters of a distribution. MLE is a straightforward optimization problem that is formed by maximizing the sum of the logarithms of probability densities. Let <code class="reqn">\Theta</code> represent a vector of parameters for a candidate fit to the specified probability density function <code class="reqn">g(x|\Theta)</code> and <code class="reqn">x_i</code> represent the observed data for a sample of size <code class="reqn">n</code>. The objective function is
</p>
<p style="text-align: center;"><code class="reqn">\mathcal{L}(\Theta) = -\sum_{i=1}^{n} \log\, g(x_i|\Theta)\mbox{,}</code>
</p>

<p>where the <code class="reqn">\Theta</code> for a maximized <code class="reqn">{-}\mathcal{L}</code> (note the 2nd negation for the adjective &ldquo;maximized&rdquo;, <code>optim()</code> defaults as a minimum optimizer) represents the parameters fit by MLE. The initial parameter estimate by default will be seeded by the method of L-moments.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mle2par(x, type, init.para=NULL, silent=TRUE, null.on.not.converge=TRUE,
                 ptransf=  function(t) return(t),
                 pretransf=function(t) return(t), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mle2par_+3A_x">x</code></td>
<td>
<p>A vector of data values.</p>
</td></tr>
<tr><td><code id="mle2par_+3A_type">type</code></td>
<td>
<p>Three character (minimum) distribution type (for example, <code>type="gev"</code>), see <code><a href="#topic+dist.list">dist.list</a></code>.</p>
</td></tr>
<tr><td><code id="mle2par_+3A_init.para">init.para</code></td>
<td>
<p>Initial parameters as a vector <code class="reqn">\Theta</code> or as an <span class="pkg">lmomco</span> parameter &ldquo;object&rdquo; from say <code><a href="#topic+vec2par">vec2par</a></code>. If a vector is given, then internally <code><a href="#topic+vec2par">vec2par</a></code> is called with distribution equal to <code>type</code>.</p>
</td></tr>
<tr><td><code id="mle2par_+3A_silent">silent</code></td>
<td>
<p>A logical to silence the <code>try()</code> function wrapping the <code>optim()</code> function.</p>
</td></tr>
<tr><td><code id="mle2par_+3A_null.on.not.converge">null.on.not.converge</code></td>
<td>
<p>A logical to trigging simple return of <code>NULL</code> if the <code>optim()</code> function returns a nonzero convergence status.</p>
</td></tr>
<tr><td><code id="mle2par_+3A_ptransf">ptransf</code></td>
<td>
<p>An optional parameter transformation function (see <b>Examples</b>) that is useful to guide the optimization run. For example, suppose the first parameter of a three parameter distribution resides in the positive domain, then <br /> <code>ptransf(t) = </code>
<code>function(t) c(log(t[1]), t[2], t[3])</code>.</p>
</td></tr>
<tr><td><code id="mle2par_+3A_pretransf">pretransf</code></td>
<td>
<p>An optional parameter retransformation function (see <b>Examples</b>) that is useful to guide the optimization run. For example, suppose the first parameter of a three parameter distribution resides in the positive domain, then <br /> <code>pretransf(t) = </code> <code>function(t) c(exp(t[1]), t[2], t[3])</code>.</p>
</td></tr>
<tr><td><code id="mle2par_+3A_...">...</code></td>
<td>
<p>Additional arguments for the <code>optim()</code> function and other uses.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> is returned.  This list should contain at least the following items, but some distributions such as the <code>revgum</code> have extra.
</p>
<table>
<tr><td><code>type</code></td>
<td>
<p>The type of distribution in three character (minimum) format.</p>
</td></tr>
<tr><td><code>para</code></td>
<td>
<p>The parameters of the distribution.</p>
</td></tr>
<tr><td><code>source</code></td>
<td>
<p>Attribute specifying source of the parameters.</p>
</td></tr>
<tr><td><code>AIC</code></td>
<td>
<p>The Akaike information criterion (AIC).</p>
</td></tr>
<tr><td><code>optim</code></td>
<td>
<p>The returned <code>list</code> of the <code>optim()</code> function.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>During the optimization process, the function requires evaluation at the initial parameters. The following error rarely will be seen:
</p>
<pre>
  Error in optim(init.para$para, afunc) :
    function cannot be evaluated at initial parameters
</pre>
<p>if <code>Inf</code> is returned on first call to the objective function. The <code>silent</code> by default though will silence this error.  Alternative starting parameters might help.  This function is not built around subordinate control functions to say keep the parameters within distribution-specific bounds.  However, in practice, the L-moment estimates should already be fairly close and the optimizer can take it from there.  More sophisticated MLE for many distributions is widely available in other <span class="rlang"><b>R</b></span> packages. The <span class="pkg">lmomco</span> package uses its own probability density functions.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>See Also</h3>

<p><code><a href="#topic+lmom2par">lmom2par</a></code>, <code><a href="#topic+mps2par">mps2par</a></code>, <code><a href="#topic+tlmr2par">tlmr2par</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# This example might fail on mle2par() or mps2par() depending on the values
# that stem from the simulation. Trapping for a NULL return is not made here.
father &lt;- vec2par(c(37,25,114), type="st3"); FF &lt;- nonexceeds(); qFF &lt;- qnorm(FF)
X &lt;- rlmomco(78, father) # rerun if MLE and MPS fail to get a solution
plot(qFF,  qlmomco(FF, father), type="l", xlim=c(-3,3),
     xlab="STANDARD NORMAL VARIATE", ylab="QUANTILE") # parent (black)
lines(qFF, qlmomco(FF, lmr2par(X, type="gev")), col="red"  ) # L-moments (red)
lines(qFF, qlmomco(FF, mps2par(X, type="gev")), col="green") #     MPS (green)
lines(qFF, qlmomco(FF, mle2par(X, type="gev")), col="blue" ) #     MLE  (blue)
points(qnorm(pp(X)), sort(X)) # the simulated data
## End(Not run)

## Not run: 
# REFLECTION SYMMETRY
set.seed(451)
X &lt;- rlmomco(78, vec2par(c(2.12, 0.5, 0.6), type="pe3"))
# MLE and MPS are almost reflection symmetric, but L-moments always are.
mle2par( X, type="pe3")$para #  2.1796827 0.4858027  0.7062808
mle2par(-X, type="pe3")$para # -2.1796656 0.4857890 -0.7063917
mps2par( X, type="pe3")$para #  2.1867551 0.5135882  0.6975195
mps2par(-X, type="pe3")$para # -2.1868252 0.5137325 -0.6978034
parpe3(lmoms( X))$para       #  2.1796630 0.4845216  0.7928016
parpe3(lmoms(-X))$para       # -2.1796630 0.4845216 -0.7928016 
## End(Not run)

## Not run: 
Ks &lt;- seq(-1,+1,by=0.02); n &lt;- 100; MLE &lt;- MPS &lt;- rep(NA, length(Ks))
for(i in 1:length(Ks)) {
  sdat   &lt;- rlmomco(n, vec2par(c(1,0.2,Ks[i]), type="pe3"))
  mle    &lt;- mle2par(sdat, type="pe3")$para[3]
  mps    &lt;- mps2par(sdat, type="pe3")$para[3]
  MLE[i] &lt;- ifelse(is.null(mle), NA, mle) # A couple of failures expected as NA's.
  MPS[i] &lt;- ifelse(is.null(mps), NA, mps) # Some amount fewer failures than MLE.
}
plot( MLE, MPS, xlab="SKEWNESS BY MLE", ylab="SKEWNESS BY MPS")#
## End(Not run)

## Not run: 
# Demonstration of parameter transformation and retransformation
set.seed(9209) # same seed used under mps2par() in parallel example
x &lt;- rlmomco(500, vec2par(c(1,1,3), type="gam")) # 3-p Generalized Gamma
guess &lt;- lmr2par(x, type="gam", p=3) # By providing a 3-p guess the 3-p
# Generalized Gamma will be triggered internally. There are problems passing
# "p" argument to optim() if that function is to pick up the ... argument.
mle2par(x, type="gam", init.para=guess, silent=FALSE,
           ptransf=  function(t) { c(log(t[1]), log(t[2]), t[3])},
           pretransf=function(t) { c(exp(t[1]), exp(t[2]), t[3])})$para
# Reports:       mu     sigma        nu   for some simulated data.
#         1.0341269 0.9731455 3.2727218 
## End(Not run)

## Not run: 
# Demonstration of parameter estimation with tails of density zero, which
# are intercepted internally to maintain finiteness. We explore the height
# distribution for male cats of the cats dataset from the MASS package and
# fit the generalized lambda. The log-likelihood is shown by silent=FALSE
# to see that the algorithm converges slowly. It is shown how to control
# the relative tolerance of the optim() function as shown below and
# investigate the convergence by reviewing the five fits to the data.
FF &lt;- nonexceeds(sig6=TRUE); qFF &lt;- qnorm(FF)
library(MASS); data(cats); x &lt;- cats$Hwt[cats$Sex == "M"]
p2 &lt;- mle2par(x, type="gld", silent=FALSE, control=list(reltol=1E-2))
p3 &lt;- mle2par(x, type="gld", silent=FALSE, control=list(reltol=1E-3))
p4 &lt;- mle2par(x, type="gld", silent=FALSE, control=list(reltol=1E-4))
p5 &lt;- mle2par(x, type="gld", silent=FALSE, control=list(reltol=1E-5))
p6 &lt;- mle2par(x, type="gld", silent=FALSE, control=list(reltol=1E-6))
plot( qFF,  quagld(FF, p2), type="l", col="black",  # see poorest fit
      xlab="Standard normal variable", ylab="Quantile")
points(qnorm(pp(x)), sort(x), lwd=0.6, col=grey(0.6))
lines(qFF,  quagld(FF, p3), col="red"    )
lines(qFF, par2qua(FF, p4), col="green"  )
lines(qFF,  quagld(FF, p5), col="blue"   )
lines(qFF, par2qua(FF, p6), col="magenta") #
## End(Not run)
</code></pre>

<hr>
<h2 id='mps2par'>Use Maximum Product of Spacings to Estimate the Parameters of a Distribution</h2><span id='topic+mps2par'></span>

<h3>Description</h3>

<p>This function uses the method of maximum product of spacings (MPS) (maximum spacing estimation or maximum product of spacings estimation) to estimate the parameters of a distribution. MPS is based on maximization of the <em>geometric mean</em> of probability spacings in the data where the spacings are defined as the differences between the values of the cumulative distribution function, <code class="reqn">F(x)</code>, at sequential data indices.
</p>
<p>MPS (Dey <em>et al.</em>, 2016, pp. 13&ndash;14) is an optimization problem formed by maximizing the geometric mean of the spacing between consecutively ordered observations standardized to a U-statistic. Let <code class="reqn">\Theta</code> represent a vector of parameters for a candidate fit of <code class="reqn">F(x|\Theta)</code>, and let <code class="reqn">U_i(\Theta) = F(X_{i:n}|\Theta)</code> be the nonexceedance probabilities of the observed values of the order statistics <code class="reqn">x_{i:n}</code> for a sample of size <code class="reqn">n</code>.  Define the differences
</p>
<p style="text-align: center;"><code class="reqn">D_i(\Theta) = U_i(\Theta) - U_{i-1}(\Theta)\mbox{\ for\ } i = 1, \ldots, n+1\mbox{,}</code>
</p>

<p>with the additions to the vector <code class="reqn">U</code> of <code class="reqn">U_0(\Theta) = 0</code> and <code class="reqn">U_{n+1}(\Theta) = 1</code>. The objective function is
</p>
<p style="text-align: center;"><code class="reqn">M_n(\Theta) = - \sum_{i=1}^{n+1} \log\, D_i(\Theta)\mbox{,}</code>
</p>

<p>where the <code class="reqn">\Theta</code> for a maximized <code class="reqn">{-}M_n</code> represents the parameters fit by MPS. Some authors to keep with the idea of geometric mean include factor of <code class="reqn">1/(n+1)</code> for the definition of <code class="reqn">M_n</code>. Whereas other authors (Shao and Hahn, 1999, eq. 2.0), show
</p>
<p style="text-align: center;"><code class="reqn">S_n(\Theta) = (n+1)^{-1} \sum_{i=1}^{n+1} \log[(n+1)D_i(\Theta)]\mbox{.}</code>
</p>

<p>So it seems that some care is needed when considering the implementation when the value of &ldquo;the summation of the logarithms&rdquo; is to be directly interpreted. Wong and Li (2006) provide a salient review of MPS in regards to an investigation of maximum likelihood (MLE), MPS, and probability-weighted moments (<code><a href="#topic+pwm">pwm</a></code>) for the GEV (<code><a href="#topic+quagev">quagev</a></code>) and GPA (<code><a href="#topic+quagpa">quagpa</a></code>) distributions. Finally, Soukissian and Tsalis (2015) also study MPS, MLE, L-moments, and several other methods for GEV fitting.
</p>
<p>If the initial parameters have a support inside the range of the data, infinity is returned immediately by the optimizer and further action stops and the parameters returned are <code>NULL</code>. For the implementation here, if <code>check.support</code> is true, and the initial parameter estimate (if not provided and acceptable by <code>init.para</code>) by default will be seeded through the method of L-moments (unbiased, <code><a href="#topic+lmoms">lmoms</a></code>), which should be close and convergence will be fairly fast if a solution is possible. If these parameters can not be used for spinup, the implementation will then attempt various probability-weighted moment by plotting position (<code><a href="#topic+pwm.pp">pwm.pp</a></code>) converted to L-moments (<code><a href="#topic+pwm2lmom">pwm2lmom</a></code>) as part of an extended attempt to find a support of the starting distribution encompass the data. Finally, if that approach fails, a last ditch effort using starting parameters from maximum likelihood computed by a default call to <code><a href="#topic+mle2par">mle2par</a></code> is made. Sometimes data are pathological and user supervision is needed but not always successful&mdash;MPS can show failure for certain samples and(or) choice of distribution.
</p>
<p>It is important to remark that the support of a fitted distribution is not checked within the loop for optimization once spun up. The reasons are twofold: (1) The speed hit by repeated calls to <code><a href="#topic+supdist">supdist</a></code>, but in reality (2) PDFs in <span class="pkg">lmomco</span> are supposed to report zero density for outside the support of a distribution (see NEWS) and for the <code class="reqn">-\log(D_i(\Theta)\rightarrow 0) \rightarrow \infty</code> and hence infinity is returned for that state of the optimization loop and alternative solution will be tried.
</p>
<p>As a note, if all <code class="reqn">U</code> are equally spaced, then <code class="reqn">|M(\Theta)| = I_o = (n+1)\log(n+1)</code>. This begins the concept towards goodness-of-fit. The <code class="reqn">M_n(\Theta)</code> is a form of the Moran-Darling statistic for goodness-of-fit. The <code class="reqn">M_n(\Theta)</code> is a Normal distribution with
</p>
<p style="text-align: center;"><code class="reqn">\mu_M \approx (n+1)[\log(n+1)+\gamma{}] - \frac{1}{2} - \frac{1}{12(n+1)}\mbox{,}</code>
</p>

<p style="text-align: center;"><code class="reqn">\sigma_M \approx (n+1)\biggl(\frac{\pi^2}{6\,{}} - 1\biggr)-\frac{1}{2} - \frac{1}{6(n+1)}\mbox{,}</code>
</p>

<p>where <code class="reqn">\gamma \approx 0.577221</code> (Euler&ndash;Mascheroni constant, <code>-digamma(1)</code>) or as the definite integral
</p>
<p style="text-align: center;"><code class="reqn">\gamma^\mathrm{Euler}_{\mathrm{Mascheroni}} = -\int_0^\infty \mathrm{exp}(-t) \log(t)\; \mathrm{d}{t}\mbox{,}</code>
</p>

<p>An extension into small samples using the Chi-Square distribution is
</p>
<p style="text-align: center;"><code class="reqn">A = C_1 + C_2\times\chi^2_n\mbox{,}</code>
</p>

<p>where
</p>
<p style="text-align: center;"><code class="reqn">C_1 = \mu_M - \sqrt{\frac{\sigma^2_M\,n}{2}}\mbox{\ and\ }C_2 = \sqrt{\frac{\sigma^2_M}{2n}}\mbox{,}</code>
</p>

<p>and where <code class="reqn">\chi^2_n</code> is the Chi-Square distribution with <code class="reqn">n</code> degrees of freedom. A test statistic is
</p>
<p style="text-align: center;"><code class="reqn">T(\Theta) = \frac{M_n(\Theta) - C_1 + \frac{p}{2}}{C_2}\mbox{,}</code>
</p>

<p>where the term <code class="reqn">p/2</code> is a bias correction based on the number of fitted distribution parameters <code class="reqn">p</code>. The null hypothesis that the fitted distribution is correct is to be rejected if <code class="reqn">T(\Theta)</code> exceeds a critical value from the Chi-Square distribution. The MPS method has a relation to maximum likelihood (<code><a href="#topic+mle2par">mle2par</a></code>) and the two are asymptotically equivalent.
</p>
<p><b>Important Remark Concerning Ties</b>&mdash;Ties in the data cause <em>instant degeneration</em> with MPS and must be mitigated for and thus attention to this documentation and even the source code itself is required.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mps2par(x, type, init.para=NULL, ties=c("bernstein", "rounding", "density"),
            delta=0, log10offset=3, get.untied=FALSE, check.support=TRUE,
            moran=TRUE, silent=TRUE, null.on.not.converge=TRUE,
            ptransf=  function(t) return(t),
            pretransf=function(t) return(t),
            mle2par=TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mps2par_+3A_x">x</code></td>
<td>
<p>A vector of data values.</p>
</td></tr>
<tr><td><code id="mps2par_+3A_type">type</code></td>
<td>
<p>Three character (minimum) distribution type (for example, <code>type="gev"</code>, see <code><a href="#topic+dist.list">dist.list</a></code>).</p>
</td></tr>
<tr><td><code id="mps2par_+3A_init.para">init.para</code></td>
<td>
<p>Initial parameters as a vector <code class="reqn">\Theta</code> or as an <span class="pkg">lmomco</span> parameter &ldquo;object&rdquo; from say <code><a href="#topic+vec2par">vec2par</a></code>. If a vector is given, then internally <code><a href="#topic+vec2par">vec2par</a></code> is called with distribution equal to <code>type</code>.</p>
</td></tr>
<tr><td><code id="mps2par_+3A_ties">ties</code></td>
<td>
<p>Ties cause degeneration in the computation of <code class="reqn">M(\Theta)</code>:<br />
Option <code>bernstein</code> triggers a smoothing of only the ties using the <code><a href="#topic+dat2bernqua">dat2bernqua</a></code> function&mdash;Bernstein-type smoothing for ties is likely near harmless when ties are near the center of the distribution, but of course caution is advised if ties exist near the extremal values; the settings for <code>log10offset</code> and <code>delta</code> are ignored if <code>bernstein</code> is selected Also for a tie-run having an odd number of elements, the middle tied value is left as original data.<br />
Option <code>rounding</code> triggers two types of adjustment: if <code>delta &gt; 0</code> then a round-off error approach inspired by Cheng and Stephens (1989, eq. 4.1) is used (see <b>Note</b>) and <code>log10offset</code> is ignored, but if <code>delta=0</code>, then <code>log10offset</code> is picked up as an order of magnitude offset (see <b>Note</b>). Use of options <code>log10offset</code> and <code>delta</code> are likely to not keep a middle unmodified in an odd-length, tie-run in contrast to use of <code>bernstein</code>.<br />
Option <code>density</code> triggers the substitution of the probability density <code class="reqn">g(x_{i:n}|\Theta)</code> at the <code class="reqn">i</code>th tie from the current fit of the distribution. <b>Warning</b>&mdash;It appears that inference is lost almost immediately because the magnitude of <code class="reqn">M_n</code> losses meaning because probability densities are not in the same scale as changes in probabilities exemplified by the <code class="reqn">D_i</code>. This author has not yet found literature discussing this, but density substitution is a recognized strategy.</p>
</td></tr>
<tr><td><code id="mps2par_+3A_delta">delta</code></td>
<td>
<p>The optional <code class="reqn">\delta</code> value if <code class="reqn">\delta &gt; 0</code> and if <code>ties=</code><code>"rounding"</code>.</p>
</td></tr>
<tr><td><code id="mps2par_+3A_log10offset">log10offset</code></td>
<td>
<p>The optional base-10 logarithmic offset approach to roundoff errors if <code>delta=0</code> and if <code>ties=</code><code>"rounding"</code>.</p>
</td></tr>
<tr><td><code id="mps2par_+3A_get.untied">get.untied</code></td>
<td>
<p>A logical to populate a <code>ties</code> element in the returned <code>list</code> with the untied-pseudo data as it was made available to the optimizer and the number of iternations required to exhaust all ties. An emergency break it implemented if the number of iterations appears to be blowing up.</p>
</td></tr>
<tr><td><code id="mps2par_+3A_check.support">check.support</code></td>
<td>
<p>A logical to trigger a call to <code><a href="#topic+supdist">supdist</a></code> to compute the support of the distribution at the initial parameters. As mentioned, MPS degenerates if <code>min(x)</code> <code class="reqn">&lt;</code> the lower support or if <code>max(x)</code> <code class="reqn">&gt;</code> the upper support. Regardless of the setting of <code>check.support</code> and <code>NULL</code> will be returned because this is what the optimizer will do anyway.</p>
</td></tr>
<tr><td><code id="mps2par_+3A_moran">moran</code></td>
<td>
<p>A logical to trigger the goodness-of-fit test described previously.</p>
</td></tr>
<tr><td><code id="mps2par_+3A_silent">silent</code></td>
<td>
<p>A logical to silence the <code>try()</code> function wrapping the <code>optim()</code> function and to provide a returned list of the optimization output.</p>
</td></tr>
<tr><td><code id="mps2par_+3A_null.on.not.converge">null.on.not.converge</code></td>
<td>
<p>A logical to trigging simple return of <code>NULL</code> if the <code>optim()</code> function returns a nonzero convergence status.</p>
</td></tr>
<tr><td><code id="mps2par_+3A_ptransf">ptransf</code></td>
<td>
<p>An optional parameter transformation function (see <b>Examples</b>) that is useful to guide the optimization run. For example, suppose the first parameter of a three parameter distribution resides in the positive domain, then <br /> <code>ptransf(t) = </code>
<code>function(t) c(log(t[1]), t[2], t[3])</code>.</p>
</td></tr>
<tr><td><code id="mps2par_+3A_pretransf">pretransf</code></td>
<td>
<p>An optional parameter retransformation function (see <b>Examples</b>) that is useful to guide the optimization run. For example, suppose the first parameter of a three parameter distribution resides in the positive domain, then <br /> <code>pretransf(t) = </code> <code>function(t) c(exp(t[1]), t[2], t[3])</code>.</p>
</td></tr>
<tr><td><code id="mps2par_+3A_mle2par">mle2par</code></td>
<td>
<p>A logical to turn off the potential last attempt at maximum likelihood estimates of a valid seed as part of <code>check.support=TRUE</code>.</p>
</td></tr>
<tr><td><code id="mps2par_+3A_...">...</code></td>
<td>
<p>Additional arguments for the <code>optim()</code> function and other uses.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> is returned.  This list should contain at least the following items, but some distributions such as the <code>revgum</code> have extra.
</p>
<table>
<tr><td><code>type</code></td>
<td>
<p>The type of distribution in three character (minimum) format.</p>
</td></tr>
<tr><td><code>para</code></td>
<td>
<p>The parameters of the distribution.</p>
</td></tr>
<tr><td><code>source</code></td>
<td>
<p>Attribute specifying source of the parameters.</p>
</td></tr>
<tr><td><code>init.para</code></td>
<td>
<p>The initial parameters. Warning to users, when inspecting returned values make sure that one is referencing the MPS parameters in <code>para</code> and not those shown in <code>init.para</code>!</p>
</td></tr>
<tr><td><code>optim</code></td>
<td>
<p>An optional <code>list</code> of returned content from the optimizer if not <code>silent</code>.</p>
</td></tr>
<tr><td><code>ties</code></td>
<td>
<p>An optional <code>list</code> of untied-pseudo data and number of iterations required to achieve no ties (usually unity!) if and only if there were ties in the original data, <code>get.untied</code> is true, and <code>ties != "density"</code>.</p>
</td></tr>
<tr><td><code>MoranTest</code></td>
<td>
<p>An optional <code>list</code> of returned values that will include both diagnostics and statistics. The diagnostics are the computed <code class="reqn">\mu_M(n)</code>, <code class="reqn">\sigma^2_M(n)</code>, <code class="reqn">C_1</code>, <code class="reqn">C_2</code>, and <code class="reqn">n</code>. The statistics are the minimum value <code class="reqn">I_o</code> theoretically attainable <code class="reqn">|M_n(\Theta)|</code> for equally spaced differences, the minimized value <code class="reqn">M_n(\Theta)</code>, the <code class="reqn">T(\Theta)</code>, and the corresponding <code>p.value</code> from the upper tail of the <code class="reqn">\chi^2_n</code> distribution.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>During optimization, the objective function requires evaluation at the initial parameters and must be finite. If <code>Inf</code> is returned on first call to the objective function, then a warning like this
</p>
<pre>
  optim() attempt is NULL
</pre>
<p>should be seen. The <code>silent</code> by default though will silence this error. Error trapping for the estimated support of the distribution from the initial parameter values is made by <code>check.support=TRUE</code> and verbose warnings given to help remind the user. Considerable attempt is made internally to circumvent the appearance of the above error.
</p>
<p>More specifically, an MPS solution degenerates when the fitted distribution has a narrower support than the underlying data and artificially &ldquo;ties&rdquo; show up within the objective function even if the original data lacked ties or were already mitigated for. The user's only real recourse is to try fitting another distribution either by starting parameters or even distribution type. Situations could arise for which carefully chosen starting parameters could permit the optimizer to keep its simplex within the viable domain. The MPS method is sensitive to tails of a distribution having asymoptic limits as <code class="reqn">F \rightarrow 0^{+}</code> or <code class="reqn">F \rightarrow 1^{-}</code>.
</p>
<p>The Moran test can be quickly checked with highly skewed and somewhat problematic data by
</p>
<pre>
  # CPU intensive experiment
  gev &lt;- vec2par(c(4,0.3,-0.2), type="gev"); nsim &lt;- 5000
  G &lt;- replicate(nsim, mps2par(rlmomco(100, gev), # extract the p-values
                               type="gev")$MoranTest$statistics[4])
  G &lt;- unlist(G) # unlisting required if NULLs came back from mps2par()
  length(G[G &lt;= 0.05])/length(G) # 0.0408 (!=0.05 but some fits not possible)
  V &lt;- replicate(nsim, mps2par(rlmomco(100, gev),
                               type="nor")$MoranTest$statistics[4])
  V &lt;- unlist(V) # A test run give 4,518 solutions
  length(V[V &lt;= 0.05])/length(V) # 0.820 higher because not gev used
  W &lt;- replicate(nsim, mps2par(rlmomco(100, gev),
                               type="glo")$MoranTest$statistics[4])
  W &lt;- unlist(W)
  length(W[W &lt;= 0.05])/length(W) # 0.0456 higher because not gev used but
  # very close because of the proximity of the glo to the gev for the given
  # L-skew of the parent: lmomgev(gev)$ratios[3] = 0.3051
</pre>
<p>Concerning round-off errors, the Cheng and Stephens (1989, eq. 4.1) approach is to assume that the round-off errors are <code class="reqn">x \pm \delta</code>, compute the upper and lower probabilities <code class="reqn">f</code> for <code class="reqn">f_L \mapsto x - \delta</code> and <code class="reqn">f_U \mapsto x + \delta</code>, and then prorate the <code class="reqn">D_i</code> in even spacings of <code class="reqn">1/(r-1)</code> where <code class="reqn">r</code> is the number of tied values in a given tie-run. The approach for <code>mps2par</code> is similar but simplies the algorithm to evenly prorate the <code class="reqn">x</code> values in a tie-run. In other words, the current implementation is to actually massage the data before passage into the optimizer.  If the <code class="reqn">\delta = 0</code>, a base-10 logarithmic approach will be used in which, the order of magnitude of the value in a tie-run is computed and the <code>log10offset</code> subtracted to approximate the roundoff but recognize that for skewed data the roundoff might be scale dependent. The default treats a tie of three <code class="reqn">x_i = 15{,}000</code> as <code class="reqn">x_{i|r}=14{,}965.50; 15{,}000.00; 15{,}034.58</code>. In either approach, an iterative loop is present to continue looping until no further ties are found&mdash;this is made to protect against the potential for the algorithm to create new ties. A sorted vector of the final data for the optimize is available in the <code>ties</code> element of the returned list if and only if ties were originally present, <code>get.untied=TRUE</code>, and <code>ties != "density"</code>. Ties and compensation likely these prorations can only make <code class="reqn">M(\Theta)</code> smaller, and hence the test becomes conservative.
</p>
<p>A note of other MPS implementations in <span class="rlang"><b>R</b></span> is needed. The <span class="pkg">fBasics</span> and <span class="pkg">gld</span> packages both provide for MPS estimation for the generalized lambda distribution. The salient source files and code chunks are shown. First, consider package <span class="pkg">fBasics</span>:
</p>
<pre>
  fBasics --&gt; dist-gldFit.R --&gt; .gldFit.mps --&gt;
            f = try(-typeFun(log(DH[DH &gt; 0])), silent = TRUE)
</pre>
<p>where it is seen that <code class="reqn">D_i = 0</code> are ignored! Such a practice does not appear efficacious during development and testing of the implementation in <span class="pkg">lmomco</span>, parameter solutions very substantially different than reason can occur or even failure of convergence by the <span class="pkg">fBasics</span> implementation. Further investigation is warranted. Second, consider package <span class="pkg">gld</span>:
</p>
<pre>
  gld --&gt; fit_fkml.R --&gt; fit_fkml.c --&gt; method.id == 2:
  # If F[i]-F[i-1] = 0, replace by f[i-1]
  #                      (ie the density at smaller observation)
</pre>
<p>which obviously make the density substitution for ties as well <code>ties=</code><code>"density"</code> for the implementation here. Testing indicates that viable parameter solutions will result with direct insertion of the density in the case of ties. Interference, however, of the <code class="reqn">M_n</code> is almost assuredly to be greatly weakened or destroyed depending on the shape of the probability density function or a large number of ties. The problem is that the sum of the <code class="reqn">D_i</code> are no longered ensured to sum to unity. The literature appears silent on this particular aspect of MPS, and further investigation is warranted.
</p>
<p>The <span class="pkg">eva</span> package provides MPS for GEV and GPD. The approach there does not appear to replace changes of zero by density but to insert a &ldquo;smallness&rdquo; in conjunction with other conditioning checking (only the <code>cond3</code> is shown below) and a curious penalty of <code>1e6</code>. The point is that different approaches have been made by others.
</p>
<pre>
  eva --&gt; gevrFit --&gt; method="mps"
  cdf[(is.nan(cdf) | is.infinite(cdf))] &lt;- 0
  cdf &lt;- c(0, cdf, 1); D &lt;- diff(cdf); cond3 &lt;- any(D &lt; 0)
  ## Check if any differences are zero due to rounding and adjust
  D &lt;- ifelse(D &lt;= 0, .Machine$double.eps, D)
  if(cond1 | cond2 | cond3) { abs(sum(log(D))) + 1e6 } else { -sum(log(D)) }
</pre>
<p>Let us conclude with an example for the GEV between <span class="pkg">eva</span> and <span class="pkg">lmomco</span> and note sign difference in definition of the GEV shape but otherwise a general similarity in results:
</p>
<pre>
  X &lt;- rlmomco(97, vec2par(c(100,12,-.5), type="gev"))
  pargev(lmoms(X))$para
       #                  xi                alpha                kappa
       #         100.4015424           12.6401335           -0.5926457
  eva::gevrFit(X, method="mps")$par.ests
       #Location (Intercept)    Scale (Intercept)    Shape (Intercept)
       #         100.5407709           13.5385491            0.6106928
</pre>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Cheng, R.C.H., Stephens, M.A., 1989, A goodness-of-fit test using Moran's statistic with estimated parameters: Biometrika, v. 76, no. 2, pp. 385&ndash;392.
</p>
<p>Dey, D.K., Roy, Dooti, Yan, Jun, 2016, Univariate extreme value analysis, chapter 1, <em>in</em> Dey, D.K., and Yan, Jun, eds., Extreme value modeling and risk analysis&mdash;Methods and applications: Boca Raton, FL, CRC Press, pp. 1&ndash;22.
</p>
<p>Shao, Y., and Hahn, M.G., 1999, Strong consistency of the maximum product of spacings estimates with applications in nonparametrics and in estimation of unimodal densities: Annals of the Institute of Statistical Mathematics, v. 51, no. 1, pp. 31&ndash;49.
</p>
<p>Soukissian, T.H., and Tsalis, C., 2015, The effect of the generalized extreme value distribution parameter estimation methods in extreme wind speed prediction: Natural Hazards, v. 78, pp. 1777&ndash;1809.
</p>
<p>Wong, T.S.T., and Li, W.K., 2006, A note on the estimation of extreme value distributions using maximum product of spacings: IMS Lecture Notes, v. 52, pp. 272&ndash;283.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lmom2par">lmom2par</a></code>, <code><a href="#topic+mle2par">mle2par</a></code>, <code><a href="#topic+tlmr2par">tlmr2par</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
pe3 &lt;- vec2par(c(4.2, 0.2, 0.6), type="pe3") # Simulated values should have at least
X &lt;- rlmomco(202, pe3); Xr  &lt;- round(sort(X), digits=3) # one tie-run after rounding,
mps2par(X,  type="pe3")$para      # and the user can observe the (minor in this case)
mps2par(Xr, type="pe3")$para      # effect on parameters.
# Another note on MPS is needed. It is not reflection symmetric.
mps2par( X, type="pe3")$para
mps2par(-X, type="pe3")$para 
## End(Not run)

## Not run: 
# Use 1,000 replications for sample size of 75 and estimate the bias and variance of
# the method of L-moments and maximum product spacing (MPS) for the 100-year event
# using the Pearson Type III distribution.
set.seed(1596)
nsim &lt;- 1000; n &lt;- 75; Tyear &lt;- 100; type &lt;- "pe3"
parent.lmr &lt;- vec2lmom(c(5.5, 0.15, 0.03))   # L-moments of the "parent"
parent  &lt;- lmom2par(parent.lmr, type="pe3")  # "the parent"
Q100tru &lt;- qlmomco(T2prob(Tyear), parent)    # "true value"
Q100lmr &lt;- Q100mps &lt;- rep(NA, nsim)          # empty vectors
T3lmr &lt;- T4lmr &lt;- T3mps &lt;- T4mps &lt;- rep(NA, nsim)
for(i in 1:nsim) { # simulate from the parent, compute L-moments
   tmpX &lt;- rlmomco(n, parent); lmrX &lt;- lmoms(tmpX)
   if(! are.lmom.valid(lmrX)) { # quiet check on viability
     lmrX &lt;- pwm2lmom(pwms.pp(tmpX)) # try a pwm by plotting positions instead
     if(! are.lmom.valid(lmrX)) next
   }
   lmrpar &lt;- lmom2par(lmrX, type=type)                  # Method of L-moments
   mpspar &lt;-  mps2par(tmpX, type=type, init.para=lmrpar) # Method of MPS
   if(! is.null(lmrpar)) {
      Q100lmr[i] &lt;- qlmomco(T2prob(Tyear), lmrpar); lmrlmr &lt;- par2lmom(lmrpar)
      T3lmr[i] &lt;- lmrlmr$ratios[3]; T4lmr[i] &lt;- lmrlmr$ratios[4]
   }
   if(! is.null(mpspar)) {
      Q100mps[i] &lt;- qlmomco(T2prob(Tyear), mpspar); mpslmr &lt;- par2lmom(mpspar)
      T3mps[i] &lt;- mpslmr$ratios[3]; T4mps[i] &lt;- mpslmr$ratios[4]
   }
}
print(summary(Q100tru - Q100lmr)) # Method of L-moment   (mean = -0.00176)
print(summary(Q100tru - Q100mps)) # Method of MPS        (mean = -0.02746)
print(var(Q100tru - Q100lmr, na.rm=TRUE)) # Method of L-moments (0.009053)
print(var(Q100tru - Q100mps, na.rm=TRUE)) # Method of MPS       (0.009880)
# CONCLUSION: MPS is very competitive to the mighty L-moments.

LMR &lt;- data.frame(METHOD=rep("Method L-moments",        nsim), T3=T3lmr, T4=T4lmr)
MPS &lt;- data.frame(METHOD=rep("Maximum Product Spacing", nsim), T3=T3mps, T4=T4mps)
ZZ &lt;- merge(LMR, MPS, all=TRUE)
boxplot(ZZ$T3~ZZ$METHOD, data=ZZ); mtext("L-skew Distributions")
boxplot(ZZ$T4~ZZ$METHOD, data=ZZ); mtext("L-kurtosis Distributions") #
## End(Not run)

## Not run: 
# Data shown in Cheng and Stephens (1989). They have typesetting error on their
# "sigma." Results mu=34.072 and sigma=sqrt(6.874)=2.6218
H590 &lt;- c(27.55, 31.82, 33.74, 34.15, 35.32, 36.78,
          29.89, 32.23, 33.74, 34.44, 35.44, 37.07,
          30.07, 32.28, 33.86, 34.62, 35.61, 37.36,
          30.65, 32.69, 33.86, 34.74, 35.61, 37.36,
          31.23, 32.98, 33.86, 34.74, 35.73, 37.36,
          31.53, 33.28, 34.15, 35.03, 35.90, 40.28,
          31.53, 33.28, 34.15, 35.03, 36.20) # breaking stress MPAx1E6 of carbon block.
mps2par(H590, type="nor", ties="rounding", delta=0.005)$para
mps2par(H590, type="nor", ties="rounding" )$para
mps2par(H590, type="nor", ties="bernstein")$para
#        mu     sigma
# 34.071424  2.622484 # using a slight variant on their eq. 4.1.
# 34.071424  2.622614 # using log10offset=3
# 34.088769  2.690781 # using Bernstein smooth and unaffecting middle of odd tie runs
# The MoranTest show rejection of the Normal distribution at alpha=0.05, with the
# "rounding" and "delta=0.005"" and T=63.8 compared to their result of T=63.1,
# which to be considered that the strategy here is not precisely the same as theirs.
## End(Not run)

## Not run: 
# Demonstration of parameter transformation and retransformation
set.seed(9209) # same seed used under mle2par() in parallel example
x &lt;- rlmomco(500, vec2par(c(1,1,3), type="gam")) # 3-p Generalized Gamma
guess &lt;- lmr2par(x, type="gam", p=3) # By providing a 3-p guess the 3-p
# Generalized Gamma will be triggered internally. There are problems passing
# "p" argument to optim() if that function is to pick up the ... argument.
mps2par(x, type="gam", init.para=guess, silent=FALSE,
           ptransf=  function(t) { c(log(t[1]), log(t[2]), t[3])},
           pretransf=function(t) { c(exp(t[1]), exp(t[2]), t[3])})$para
# Reports:       mu     sigma        nu   for some simulated data.
#         0.9997019 1.0135674 3.0259012 
## End(Not run)
</code></pre>

<hr>
<h2 id='nonexceeds'>Some Common or Useful Nonexceedance Probabilities </h2><span id='topic+nonexceeds'></span>

<h3>Description</h3>

<p>This function returns a vector nonexceedance probabilities.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nonexceeds(f01=FALSE, less=FALSE, sig6=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="nonexceeds_+3A_f01">f01</code></td>
<td>
<p>A logical and if <code>TRUE</code> then 0 and 1 are included in the returned vector.</p>
</td></tr>
<tr><td><code id="nonexceeds_+3A_less">less</code></td>
<td>
<p>A logical and if <code>TRUE</code> the default values are trimmed back.</p>
</td></tr>
<tr><td><code id="nonexceeds_+3A_sig6">sig6</code></td>
<td>
<p>A logical that will instead sweep <code class="reqn">\pm 6</code> standard deviations and transform standard normal variates to nonexceedance probabilities.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of selected nonexceedance probabilities <code class="reqn">F</code> useful in assessing the &ldquo;frequency curve&rdquo; in applications (noninclusive). This vector is intended to be helpful and self-documenting when common <code class="reqn">F</code> values are desired to explore deep into both distribution tails.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith </p>


<h3>See Also</h3>

<p><code><a href="#topic+check.fs">check.fs</a></code>, <code><a href="#topic+prob2T">prob2T</a></code>, <code><a href="#topic+T2prob">T2prob</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>lmr &lt;- lmoms(rnorm(20))
para &lt;- parnor(lmr)
quanor(nonexceeds(), para)
</code></pre>

<hr>
<h2 id='par2cdf'>Cumulative Distribution Function of the Distributions</h2><span id='topic+par2cdf'></span>

<h3>Description</h3>

<p>This function acts as a front end or dispatcher to the distribution-specific cumulative distribution functions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>par2cdf(x, para, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="par2cdf_+3A_x">x</code></td>
<td>
<p>A real value vector.</p>
</td></tr>
<tr><td><code id="par2cdf_+3A_para">para</code></td>
<td>
<p>The parameters from <code><a href="#topic+lmom2par">lmom2par</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
<tr><td><code id="par2cdf_+3A_...">...</code></td>
<td>
<p>The additional arguments are passed to the cumulative distribution function such as <code>paracheck=FALSE</code> for the Generalized Lambda distribution (<code><a href="#topic+cdfgld">cdfgld</a></code>).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Nonexceedance probability (<code class="reqn">0 \le F \le 1</code>) for <code>x</code>.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>See Also</h3>

<p><code><a href="#topic+par2pdf">par2pdf</a></code>, <code><a href="#topic+par2qua">par2qua</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>lmr       &lt;- lmoms(rnorm(20))
para      &lt;- parnor(lmr)
nonexceed &lt;- par2cdf(0,para)
</code></pre>

<hr>
<h2 id='par2cdf2'>Equivalent Cumulative Distribution Function of Two Distributions</h2><span id='topic+par2cdf2'></span>

<h3>Description</h3>

<p>This function computes the nonexceedance probability of a given quantile from a linear weighted combination of two quantile functions but accomplishes this from the perspective of cumulative distribitution functions (see <code><a href="#topic+par2qua2">par2qua2</a></code>).  For the current implementation simply <code>uniroot</code>'ing of a internally declared function and <code><a href="#topic+par2qua2">par2qua2</a></code> is made. Mathematical details are provided under <code><a href="#topic+par2qua2">par2qua2</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>par2cdf2(x, para1, para2, weight=NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="par2cdf2_+3A_x">x</code></td>
<td>
<p>A real value vector.</p>
</td></tr>
<tr><td><code id="par2cdf2_+3A_para1">para1</code></td>
<td>
<p>The first distribution parameters from <code><a href="#topic+lmom2par">lmom2par</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
<tr><td><code id="par2cdf2_+3A_para2">para2</code></td>
<td>
<p>The second distribution parameters from <code><a href="#topic+lmom2par">lmom2par</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
<tr><td><code id="par2cdf2_+3A_weight">weight</code></td>
<td>
<p>An optional weighting argument to use in lieu of the <code>F</code>. Consult the documentation for <code><a href="#topic+par2qua2">par2qua2</a></code> for the implementation details when <code>weight</code> is <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="par2cdf2_+3A_...">...</code></td>
<td>
<p>The additional arguments are passed to the quantile function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Nonexceedance probabilities (<code class="reqn">0 \le F \le 1</code>) for <code>x</code> from the two distributions.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>See Also</h3>

<p><code><a href="#topic+par2cdf">par2cdf</a></code>, <code><a href="#topic+lmom2par">lmom2par</a></code>, <code><a href="#topic+par2qua2">par2qua2</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>lmr &lt;- lmoms(rnorm(20)); left &lt;- parnor(lmr); right &lt;- pargev(lmr)
mixed.median    &lt;- par2qua2(0.5,          left, right)
mixed.nonexceed &lt;- par2cdf2(mixed.median, left, right)
</code></pre>

<hr>
<h2 id='par2lmom'>Convert the Parameters of a Distribution to the L-moments</h2><span id='topic+par2lmom'></span>

<h3>Description</h3>

<p>This function acts as a frontend or dispatcher to the distribution-specific L-moments of the parameter values. This function dispatches to <code>lmomCCC</code> where CCC represents the three character (minimum) distribution identifier:
<code>aep4</code>, <code>cau</code>, <code>emu</code>, <code>exp</code>, <code>gam</code>, <code>gev</code>, <code>gld</code>, <code>glo</code>, <code>gno</code>, <code>gov</code>, <code>gpa</code>, <code>gum</code>, <code>kap</code>, <code>kmu</code>, <code>kur</code>, <code>lap</code>, <code>lmrq</code>, <code>ln3</code>, <code>nor</code>, <code>pe3</code>, <code>ray</code>, <code>revgum</code>, <code>rice</code>, <code>sla</code>, <code>st3</code>, <code>texp</code>, <code>wak</code>, and <code>wei</code>.
</p>
<p>The conversion of parameters to TL-moments (<code><a href="#topic+TLmoms">TLmoms</a></code>) is not supported. Specific use of functions such as <code><a href="#topic+lmomTLgld">lmomTLgld</a></code> and <code><a href="#topic+lmomTLgpa">lmomTLgpa</a></code> for the TL-moments of the Generalized Lambda and Generalized Pareto distributions is required.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>par2lmom(para, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="par2lmom_+3A_para">para</code></td>
<td>
<p>A parameter object of a distribution.</p>
</td></tr>
<tr><td><code id="par2lmom_+3A_...">...</code></td>
<td>
<p>Other arguments to pass.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An L-moment object (an <span class="rlang"><b>R</b></span> <code>list</code>) is returned.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>See Also</h3>

<p><code><a href="#topic+lmom2par">lmom2par</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>lmr      &lt;- lmoms(rnorm(20))
para     &lt;- parnor(lmr)
frompara &lt;- par2lmom(para)
</code></pre>

<hr>
<h2 id='par2pdf'>Probability Density Function of the Distributions</h2><span id='topic+par2pdf'></span>

<h3>Description</h3>

<p>This function acts as a frontend or dispatcher to the distribution-specific probability density functions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>par2pdf(x, para, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="par2pdf_+3A_x">x</code></td>
<td>
<p>A real value vector.</p>
</td></tr>
<tr><td><code id="par2pdf_+3A_para">para</code></td>
<td>
<p>The parameters from <code><a href="#topic+lmom2par">lmom2par</a></code> or similar.</p>
</td></tr>
<tr><td><code id="par2pdf_+3A_...">...</code></td>
<td>
<p>The additional arguments are passed to the quantile function such as <br /> <code>paracheck = FALSE</code> for the Generalized Lambda distribution (<code><a href="#topic+quagld">quagld</a></code>).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Probability density (<code class="reqn">f</code>) for <code class="reqn">x</code>.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>See Also</h3>

<p><code><a href="#topic+par2cdf">par2cdf</a></code>, <code><a href="#topic+par2qua">par2qua</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>para    &lt;- parnor(lmoms(rnorm(20)))
density &lt;- par2pdf(par2qua(0.5, para), para)
</code></pre>

<hr>
<h2 id='par2qua'>Quantile Function of the Distributions</h2><span id='topic+par2qua'></span>

<h3>Description</h3>

<p>This function acts as a frontend or dispatcher to the distribution-specific quantile functions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>par2qua(f,para,...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="par2qua_+3A_f">f</code></td>
<td>
<p>Nonexceedance probability (<code class="reqn">0 \le F \le 1</code>).</p>
</td></tr>
<tr><td><code id="par2qua_+3A_para">para</code></td>
<td>
<p>The parameters from <code><a href="#topic+lmom2par">lmom2par</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
<tr><td><code id="par2qua_+3A_...">...</code></td>
<td>
<p>The additional arguments are passed to the quantile function such as <br /> <code>paracheck = FALSE</code> for the Generalized Lambda distribution (<code><a href="#topic+quagld">quagld</a></code>).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Quantile value for <code class="reqn">F</code>.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>See Also</h3>

<p><code><a href="#topic+par2cdf">par2cdf</a></code>, <code><a href="#topic+par2pdf">par2pdf</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>lmr     &lt;- lmoms(rnorm(20))
para    &lt;- parnor(lmr)
median  &lt;- par2qua(0.5,para)
</code></pre>

<hr>
<h2 id='par2qua2'>Equivalent Quantile Function of Two Distributions</h2><span id='topic+par2qua2'></span>

<h3>Description</h3>

<p>This function computes the nonexceedance probability of a given quantile from a linear weighted combination of two quantile functions&mdash;a mixed distribution:
</p>
<p style="text-align: center;"><code class="reqn">Q_\mathrm{mixed}(F; \Theta_1, \Theta_2, \omega) = (1-\omega)Q_1(F, \Theta_1) + \omega Q_2(F, \Theta2)\mbox{,}</code>
</p>

<p>where <code class="reqn">Q</code> is a quantile function for nonexceedance probability <code class="reqn">F</code>, the distributions have parameters <code class="reqn">\Theta_1</code> and <code class="reqn">\Theta_2</code>, and <code class="reqn">\omega</code> is a weight factor.
</p>
<p>The distributions are specified by the two parameter object arguments in usual <span class="pkg">lmomco</span> style. When proration by the nonexceedance probability is desired (<code>weight=</code><code>NULL</code>, default), the left-tail parameter object (<code>para1</code>) is the distribution obviously governing the left tail; the right-tail parameter object (<code>para2</code>) is of course governs the right tail. The quantile function algebra is
</p>
<p style="text-align: center;"><code class="reqn"> Q(F) = (1-F^\star) \times {\triangleleft}Q(F) + F^\star \times Q(F){\triangleright}\mbox{,}</code>
</p>

<p>where <code class="reqn">Q(F)</code> is the mixed quantile for nonexceedance probability <code class="reqn">F</code>. <code class="reqn">{\triangleleft}Q(F)</code> is the first or left-tail quantile function; <code class="reqn">Q(F){\triangleright}</code> is the second or right-tail quantile function. In otherwords, if <code>weight = NULL</code>, then <code class="reqn">F^\star = F =</code> <code>f</code> and the weight between the two quantile functions thus continuously varies from left to right. This is a probability proration from one to the other. A word of caution in this regard. The resulting weighted- or mixed-quantile function is not rigorously checked for monotonic increase with <code class="reqn">F</code>, which is a required property of quantile functions. However, a first-order difference on the mixed quantiles with the probabilities is computed and a warning issued if not monotonic increasing.
</p>
<p>If the optional <code>weight</code> argument is provided with length 1, then <code class="reqn">\omega</code> equals that weight. If <code>weight = 0</code>, then only the quantiles for <code class="reqn">Q_1(F)</code> are returned, and if <code>weight = 1</code>, then only the quantiles for the left tail <code class="reqn">Q_2(F)</code> are returned.
</p>
<p>If the optional <code>weight</code> argument is provided with length 2, then <code class="reqn">(1 - \omega)</code> is replaced by the first weight and <code class="reqn">\omega</code> is replaced by the second weight. These are internally rescaled to sum to unity before use and a warning is issued that this was done. Finally, the <code><a href="#topic+par2cdf2">par2cdf2</a></code> function inverses the above equation for <code class="reqn">F</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>par2qua2(f, para1, para2, wfunc=NULL, weight=NULL, as.list=FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="par2qua2_+3A_f">f</code></td>
<td>
<p>Nonexceedance probability (<code class="reqn">0 \le F \le 1</code>).</p>
</td></tr>
<tr><td><code id="par2qua2_+3A_para1">para1</code></td>
<td>
<p>The first or left-tail parameters from <code><a href="#topic+lmom2par">lmom2par</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
<tr><td><code id="par2qua2_+3A_para2">para2</code></td>
<td>
<p>The second or right-tail parameters from <code><a href="#topic+lmom2par">lmom2par</a></code> or similar.</p>
</td></tr>
<tr><td><code id="par2qua2_+3A_wfunc">wfunc</code></td>
<td>
<p>A function taking the argument <code>f</code> and computing a weight for the <code>para2</code> curve for which the complement of the computed weight is used for the weight on <code>para1</code>.</p>
</td></tr>
<tr><td><code id="par2qua2_+3A_weight">weight</code></td>
<td>
<p>An optional weighting argument to use in lieu of <code>F</code>. If <code>NULL</code> then prorated by the <code>f</code>, if <code>weight</code> has length 1, then weight on left distribution is the complement of the weight and weight on right distribution is <code>weight[1]</code>, and if <code>weight</code> had length 2, then <code>weight[1]</code> is the weight on the left distribution and <code>weight[2]</code> is the weight on the right distribution.</p>
</td></tr>
<tr><td><code id="par2qua2_+3A_as.list">as.list</code></td>
<td>
<p>A logical to control whether an <span class="rlang"><b>R</b></span> <code>data.frame</code> is returned having a column for <code>f</code> and for the mixed quantiles. This feature is provided for some design consistency with <code><a href="#topic+par2qua2lo">par2qua2lo</a></code>, which mandates a <code>data.frame</code> return.</p>
</td></tr>
<tr><td><code id="par2qua2_+3A_...">...</code></td>
<td>
<p>The additional arguments are passed to the quantile function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The weighted quantile value for <code class="reqn">F</code> from the two distributions.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>See Also</h3>

<p><code><a href="#topic+par2qua">par2qua</a></code>, <code><a href="#topic+par2cdf2">par2cdf2</a></code>, <code><a href="#topic+par2qua2lo">par2qua2lo</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>lmr &lt;- lmoms(rnorm(20)); left &lt;- parnor(lmr); right &lt;- pargev(lmr)
mixed.median &lt;- par2qua2(0.5, left, right)

# Bigger example--using Kappa fit to whole sample for the right tail and
# Normal fit to whole sample for the left tail
D   &lt;- c(123, 523, 345, 356, 2134, 345, 2365, 235, 12, 235, 61, 432, 843)
lmr &lt;- lmoms(D); KAP &lt;- parkap(lmr); NOR &lt;- parnor(lmr); PP &lt;- pp(D)
plot( PP, sort(D), ylim=c(-500, 2300))
lines(PP, par2qua( PP, KAP),      col=2)
lines(PP, par2qua( PP, NOR),      col=3)
lines(PP, par2qua2(PP, NOR, KAP), col=4)
</code></pre>

<hr>
<h2 id='par2qua2lo'>Equivalent Quantile Function of Two Distributions Stemming from Left-Hand Threshold to Setup Conditional Probability Computations</h2><span id='topic+par2qua2lo'></span>

<h3>Description</h3>

<p><b>EXPERIMENTAL!</b> This function computes the nonexceedance probability of a given quantile from a linear weighted combination of two quantile functions&mdash;a mixed distribution&mdash;when the data have been processed through the <code><a href="#topic+x2xlo">x2xlo</a></code> function setting up left-hand thresholding and conditional probability compuation. The <code>par2qua2lo</code> function is a partial generalization of the <code><a href="#topic+par2qua2">par2qua2</a></code> function (see there for the basic mathematics). The <b>Examples</b> section has an exhaustive demonstration. The resulting weighted- or mixed-quantile function is not rigorously checked for monotonic increase with <code class="reqn">F</code>, which is a required property of quantile functions. However, a first-order difference on the mixed quantiles with the probabilities is computed and a warning issued if not monotonic increasing.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>par2qua2lo(f, para1, para2, xlo1, xlo2,
              wfunc=NULL, weight=NULL, addouts=FALSE,
              inf.as.na=TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="par2qua2lo_+3A_f">f</code></td>
<td>
<p>Nonexceedance probability (<code class="reqn">0 \le F \le 1</code>).</p>
</td></tr>
<tr><td><code id="par2qua2lo_+3A_para1">para1</code></td>
<td>
<p>The first distribution parameters from <code><a href="#topic+lmom2par">lmom2par</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
<tr><td><code id="par2qua2lo_+3A_para2">para2</code></td>
<td>
<p>The second distribution parameters from <code><a href="#topic+x2xlo">x2xlo</a></code>.</p>
</td></tr>
<tr><td><code id="par2qua2lo_+3A_xlo1">xlo1</code></td>
<td>
<p>The first distribution parameters from <code><a href="#topic+x2xlo">x2xlo</a></code>.</p>
</td></tr>
<tr><td><code id="par2qua2lo_+3A_xlo2">xlo2</code></td>
<td>
<p>The second distribution parameters from <code><a href="#topic+lmom2par">lmom2par</a></code> or similar.</p>
</td></tr>
<tr><td><code id="par2qua2lo_+3A_wfunc">wfunc</code></td>
<td>
<p>A function taking the argument <code>f</code> and computing a weight for the <code>para2</code> curve for which the complement of the computed weight is used for the weight on <code>para1</code>.</p>
</td></tr>
<tr><td><code id="par2qua2lo_+3A_weight">weight</code></td>
<td>
<p>An optional weighting argument to use in lieu of <code>F</code>. If <code>NULL</code> then weights are a function of <code>length(xlo1$xin)</code> and <code>length(xlo2$xin)</code> for the first and second distribution respectively, if <code>weight</code> has length 1, then weight on first distribution is the complement of the weight, and the weight on second distribution is <code>weight[1]</code>, and if <code>weight</code> had length 2, then <code>weight[1]</code> is the weight on the first distribution, and <code>weight[2]</code> is the weight on the second distribution.</p>
</td></tr>
<tr><td><code id="par2qua2lo_+3A_addouts">addouts</code></td>
<td>
<p>In the computation of weight factors when the <code>xlo1$xin</code> and <code>xlo2$xin</code> are used by other argument settings, the <code>addouts</code> arguments triggers the inclusion of the lengths of the <code>xlo1$xout</code> and <code>xlo2$xout</code> (see source code).</p>
</td></tr>
<tr><td><code id="par2qua2lo_+3A_inf.as.na">inf.as.na</code></td>
<td>
<p>A logical controlling whether quantiles for each distribution that are non-finite are to be converted to <code>NA</code>s. If they are converter to <code>NA</code>s, then when the application of the weight or weights are made then that those indices of <code>NA</code> quantiles become a zero and the weight for the other quantile will become unity. It is suggested to review the source code.</p>
</td></tr>
<tr><td><code id="par2qua2lo_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass if needed.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The mixed quantile values for likely a subset of the provided <code>f</code> from the two distributions depending on the internals of <code>xlo1</code> and <code>xlo2</code> require the quantiles to actually start. This requires this function to return an <span class="rlang"><b>R</b></span> <code>data.frame</code> that was only optional for <code><a href="#topic+par2qua2">par2qua2</a></code>:
</p>
<table>
<tr><td><code>f</code></td>
<td>
<p>Nonexceedance probabilities.</p>
</td></tr>
<tr><td><code>quamix</code></td>
<td>
<p>The mixed quantiles.</p>
</td></tr>
<tr><td><code>delta_curve1</code></td>
<td>
<p>The computation <code>quamix</code> minus curve for <code>para1</code>.</p>
</td></tr>
<tr><td><code>delta_curve2</code></td>
<td>
<p>The computation <code>quamix</code> minus curve for <code>para2</code>.</p>
</td></tr>
</table>
<p>Alternatively, the returned value could be a weighting function for subsequent calls as <code>wfunc</code> to <code>par2qua2lo</code> (see <b>Examples</b>). This alternative operation is triggered by setting <code>wfunc</code> to an arbitrary character string, and internally the contents of <code>xlo1</code> and <code>xlo2</code>, which themselves have to be called as named arguments, are recombined. This means that the <code>xin</code> and <code>xout</code> are recombined, into their respective samples. Each data point is then categorized with probability zero for the <code>xlo1</code> values and probability unity for the <code>xlo2</code> values. A logistic regression is fit using logit-link function for a binomial family using a generalized linear model. The binomial (0 or 1) is regressed as a function of the plotting positions of a sample composed of <code>xlo1</code> and <code>xlo2</code>. The coefficients of the regression are extracted, and a function created to predict the probability of event &ldquo;<code>xlo2</code>&rdquo;. The <code>attributes</code> of the computed value inside the function store the coefficients, the regression model, and potentially useful for graphical review, a <code>data.frame</code> of the data used for the regression. This sounds more complicated than it really is (see source code and <b>Examples</b>).
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>See Also</h3>

<p><code><a href="#topic+par2qua">par2qua</a></code>, <code><a href="#topic+par2cdf2">par2cdf2</a></code>, <code><a href="#topic+par2qua2">par2qua2</a></code>, <code><a href="#topic+x2xlo">x2xlo</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
XloSNOW &lt;- list( # data from "snow events" from prior call to x2xlo()
   xin=c(4670, 3210, 4400, 4380, 4350, 3380, 2950, 2880, 4100),
   ppin=c(0.9444444, 0.6111111, 0.8888889, 0.8333333, 0.7777778, 0.6666667,
          0.5555556, 0.5000000, 0.7222222),
   xout=c(1750, 1610, 1750, 1460, 1950, 1000, 1110, 2600),
   ppout=c(0.27777778, 0.22222222, 0.33333333, 0.16666667, 0.38888889,
           0.05555556, 0.11111111, 0.44444444),
   pp=0.4444444, thres=2600, nin=9, nout=8, n=17, source="x2xlo")
# RAIN data from prior call to x2xlo() are
XloRAIN &lt;- list( # data from "rain events" from prior call to x2xlo()
   xin=c(5240, 6800, 5990, 4600, 5200, 6000, 4500, 4450, 4480, 4600,
         3290, 6700, 10600, 7230, 9200, 6540, 13500, 4250, 5070,
         6640, 6510, 3610, 6370, 5530, 4600, 6570, 6030, 7890, 8410),
   ppin=c(0.41935484, 0.77419355, 0.48387097, 0.25806452, 0.38709677, 0.51612903,
          0.22580645, 0.16129032, 0.19354839, 0.29032258, 0.06451613, 0.74193548,
          0.93548387, 0.80645161, 0.90322581, 0.64516129, 0.96774194, 0.12903226,
          0.35483871, 0.70967742, 0.61290323, 0.09677419, 0.58064516, 0.45161290,
          0.32258065, 0.67741935, 0.54838710, 0.83870968, 0.87096774),
   xout=c(1600), ppout=c(0.03225806),
   pp=0.03225806, thres=2599, nin=29, nout=1, n=30, source="x2xlo")

QSNOW &lt;- c(XloSNOW$xin,  XloSNOW$xout ) # collect all of the snow
QRAIN &lt;- c(XloRAIN$xin,  XloRAIN$xout ) # collect all of the rain
PSNOW &lt;- c(XloSNOW$ppin, XloSNOW$ppout) # probabilities collected
PRAIN &lt;- c(XloRAIN$ppin, XloRAIN$ppout) # probabilities collected

# Logistic regression to blend the proportion of snow versus rain events as
# ***also*** a function of nonexceedance probability
wfunc &lt;- par2qua2lo(xlo1=XloSNOW, xlo2=XloRAIN, wfunc="wfunc") # weight function

# Plotting the data and the logistic regression. This shows how to gain access
# to the attributes, in order to get the data, so that we can visualize the
# probability mixing between the two samples. If the two samples are not a
# function of probability, then each systematically would have a regression-
# predicted weight of 50/50. For the RAIN and SNOW, the SNOW is likely to
# produce the smaller events and RAIN the larger.
 opts &lt;- par(las=1) # Note the 0.5 in the next line is arbitrary, we simply
 bin &lt;- attr(wfunc(0.5), "data") # have to use wfunc() to get its attributes.
 FF &lt;- seq(0,1,by=0.01); HH &lt;- wfunc(FF); n &lt;- length(FF)
 plot(bin$f, bin$prob, tcl=0.5, col=2*bin$prob+2,
      xlab="NONEXCEEDANCE PROBABILITY", ylab="RAIN-CAUSED EVENT RELATIVE TO SNOW")
 lines(c(-0.04,1.04), rep(0.5,2), col=8, lwd=0.8) # origin line at 50/50 chance
 text(0, 0.5, "50/50 chance line", pos=4, cex=0.8)
 segments(FF[1:(n-1)], HH[1:(n-1)], x1=FF[2:n], y1=HH[2:n], lwd=1+4*abs(FF-0.5),
          col=rgb(1-FF,0,FF)) # line grades from one color to other
 text(1, 0.1, "Events caused by snow", col=2, cex=0.8, pos=2)
 text(0, 0.9, "Events caused by rain", col=4, cex=0.8, pos=4)
 par(opts)

# Suppose that the Pearson type III is thought applicable to the SNOW
# and the AEP4 for the RAIN, now estimate respective parameters.
parSNOW &lt;- lmr2par(log10(XloSNOW$xin), type="nor" )
parRAIN &lt;- lmr2par(log10(XloRAIN$xin), type="wak")
# Two distributions are chosen to show the user than we are not constrained to one.

Qall   &lt;- c(QSNOW, QRAIN)                # combine into a "whole" sample
XloALL &lt;- x2xlo(Qall, leftout=2600, a=0) # apply the low-outlier threshold
parALL &lt;- lmr2par(log10(XloALL$xin), type="nor") # estimate Wakeby
# Wakey has five parameters and is very flexible.

FF &lt;- nonexceeds() # useful nonexceedance probabilities
col &lt;- c(rep(0,length(QSNOW)), rep(2,length(QRAIN))) # for coloring
plot(0, 0, col=2+col, ylim=c(1000,20000), xlim=qnorm(range(FF)), log="y",
           xlab="STANDARD NORMAL VARIATE", ylab="QUANTILE", type="n")
lines(par()$usr[1:2], rep(2600, 2), col=6, lty=2, lwd=0.5) # draw threshold
points(qnorm(pp(Qall, sort=FALSE)), Qall, col=2+col, lwd=0.98) # all record
points(qnorm(PSNOW), QSNOW, pch=16, col=2) # snow events
points(qnorm(PRAIN), QRAIN, pch=16, col=4) # rain events
lines(     qnorm(f2f(  FF, xlo=XloSNOW)), # show fitted curve for snow events
      10^par2qua(f2flo(FF, xlo=XloSNOW ), parSNOW), col=2)
lines(     qnorm(f2f(  FF, xlo=XloRAIN)), # show fitted curve for rain events
      10^par2qua(f2flo(FF, xlo=XloRAIN ), parRAIN), col=4)
lines(     qnorm(f2f(  FF, xlo=XloALL )), # show fitted curve for all events combined
      10^par2qua(f2flo(FF, xlo=XloALL  ), parALL ), col=1, lty=3)
PQ &lt;- par2qua2lo(      FF, parSNOW, parRAIN, XloSNOW, XloRAIN, wfunc=wfunc)
lines(qnorm(PQ$f), 10^PQ$quamix, lwd=2)                  # draw the mixture
legend(-3,20000, c("Rain curve", "Snow curve", "All combined (all open circles)",
                    "MIXED CURVE by par2qua2lo()"),
                  bty="n", lwd=c(1,1,1,2), lty=c(1,1,3,1), col=c(4,2,1,1))
text(-3, 15000, "A low-outlier threshold of 2,600 is used throughout.", col=6, pos=4)
text(-3,  2600, "2,600", cex=0.8, col=6, pos=4)
mtext("Mixed population frequency computation of snow and rainfall streamflow")#
## End(Not run)

## Not run: 
nsim &lt;- 50000; FF &lt;- runif(nsim); WF &lt;- wfunc(FF)
rB &lt;- rbinom(nsim, 1, WF)
RF &lt;- FF[rB == 1]; SF &lt;- FF[rB == 0]
RAIN &lt;- 10^qlmomco(f2flo(runif(length(RF)), xlo=XloRAIN), parRAIN)
SNOW &lt;- 10^qlmomco(f2flo(runif(length(SF)), xlo=XloRAIN), parSNOW)
RAIN[RAIN &lt; XloRAIN$thres] &lt;- XloRAIN$thres
SNOW[SNOW &lt; XloSNOW$thres] &lt;- XloSNOW$thres
RAIN &lt;- c(RAIN,rep(XloRAIN$thres, length(RF)-length(RAIN)))
SNOW &lt;- c(SNOW,rep(XloSNOW$thres, length(SF)-length(SNOW)))
ALL &lt;- c(RAIN,SNOW)
lines(qnorm(pp(ALL)), sort(ALL), cex=0.6, lwd=0.8, col=3)

RF &lt;- FF[rB == 1]; SF &lt;- FF[rB == 0]
RAIN &lt;- 10^qlmomco(RF, parRAIN)
SNOW &lt;- 10^qlmomco(SF, parSNOW)
RAIN[RAIN &lt; XloRAIN$thres] &lt;- XloRAIN$thres
SNOW[SNOW &lt; XloSNOW$thres] &lt;- XloSNOW$thres
RAIN &lt;- c(RAIN,rep(XloRAIN$thres, length(RF)-length(RAIN)))
SNOW &lt;- c(SNOW,rep(XloSNOW$thres, length(SF)-length(SNOW)))
ALL &lt;- c(RAIN,SNOW)
lines(qnorm(pp(ALL)), sort(ALL), cex=0.6, lwd=0.8, col=3)

RF &lt;- FF[rB == 1]; SF &lt;- FF[rB == 0]
RAIN &lt;- 10^qlmomco(f2flo(RF, xlo=XloRAIN), parRAIN)
SNOW &lt;- 10^qlmomco(f2flo(SF, xlo=XloRAIN), parSNOW)
RAIN[RAIN &lt; XloRAIN$thres] &lt;- XloRAIN$thres
SNOW[SNOW &lt; XloSNOW$thres] &lt;- XloSNOW$thres
RAIN &lt;- c(RAIN,rep(XloRAIN$thres, length(RF)-length(RAIN)))
SNOW &lt;- c(SNOW,rep(XloSNOW$thres, length(SF)-length(SNOW)))
ALL &lt;- c(RAIN,SNOW)
lines(qnorm(pp(ALL)), sort(ALL), cex=0.6, lwd=0.8, col=3) #
## End(Not run)
</code></pre>

<hr>
<h2 id='par2vec'>Convert a Parameter Object to a Vector of Parameters</h2><span id='topic+par2vec'></span>

<h3>Description</h3>

<p>This function converts a parameter object to a vector of parameters using the <code>$para</code> component of the parameter list such as returned by <code><a href="#topic+vec2par">vec2par</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>par2vec(para, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="par2vec_+3A_para">para</code></td>
<td>
<p>A parameter object of a distribution.</p>
</td></tr>
<tr><td><code id="par2vec_+3A_...">...</code></td>
<td>
<p>Additional arguments should they even be needed.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>vector</code> is returned in moment order.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>See Also</h3>

<p><code><a href="#topic+vec2par">vec2par</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>para &lt;- vec2par(c(12,123,0.5), type="gev")
par2vec(para)
#   xi alpha kappa
# 12.0 123.0   0.5
</code></pre>

<hr>
<h2 id='paraep4'>Estimate the Parameters of the 4-Parameter Asymmetric Exponential Power Distribution</h2><span id='topic+paraep4'></span>

<h3>Description</h3>

<p>This function estimates the parameters of the 4-parameter Asymmetric Exponential Power distribution given the L-moments of the data in an L-moment object such as that returned by <code><a href="#topic+lmoms">lmoms</a></code>. The relation between distribution parameters and L-moments is seen under <code><a href="#topic+lmomaep4">lmomaep4</a></code>. Relatively straightforward, but difficult to numerically achieve, optimization is needed to extract the parameters from the L-moments. If the <code class="reqn">\tau_3</code> of the distribution is zero (symmetrical), then the distribution is known as the Exponential Power (see <code><a href="#topic+lmrdia46">lmrdia46</a></code>).
</p>
<p>Delicado and Goria (2008) argue for numerical methods to use the following objective function
</p>
<p style="text-align: center;"><code class="reqn">\epsilon(\alpha, \kappa, h) = \log(1 + \sum_{r=2}^4 (\hat\lambda_r - \lambda_r)^2)\mbox{,}</code>
</p>

<p>and subsequently solve directly for <code class="reqn">\xi</code>. This objective function was chosen by Delicado and Goria because the solution surface can become quite flat for away from the minimum.  The author of <span class="pkg">lmomco</span> agrees with the findings of those authors from limited exploratory analysis and the development of the algorithms used here under the rubic of the &ldquo;DG&rdquo; method. This exploration resulted in an alternative algorithm using tabulated initial guesses described below. An evident drawback of the Delicado-Goria algorithm, is that precision in <code class="reqn">\alpha</code> is may be lost according to the observation that this parameter can be analytically computed given <code class="reqn">\lambda_2</code>, <code class="reqn">\kappa</code>, and <code class="reqn">h</code>.
</p>
<p>It is established practice in L-moment theory of four (and similarly three) parameter distributions to see expressions for <code class="reqn">\tau_3</code> and <code class="reqn">\tau_4</code> used for numerical optimization to obtain the two higher parameters (<code class="reqn">\alpha</code> and <code class="reqn">h</code>) first and then see analytical expressions directly compute the two lower parameters (<code class="reqn">\xi</code> and <code class="reqn">\alpha</code>). The author made various exploratory studies by optimizing on <code class="reqn">\tau_3</code> and <code class="reqn">\tau_4</code> through a least squares objective function. Such a practice seems to perform acceptably when compared to that recommended by Delicado and Goria (2008) when the initial guesses for the parameters are drawn from pretabulation of the relation between <code class="reqn">\{\alpha, h\}</code> and <code class="reqn">\{\tau_3, \tau_4\}</code>.
</p>
<p>Another optimization, referred to here as the &ldquo;A&rdquo; (Asquith) method, is available for parameter estimation using the following objective function
</p>
<p style="text-align: center;"><code class="reqn">\epsilon(\kappa, h) = \sqrt{(\hat\tau_3 - \tau_3)^2 + (\hat\tau_4 - \tau_4)^2}\mbox{,}</code>
</p>

<p>and subsequently solve directly for <code class="reqn">\alpha</code> and then <code class="reqn">\xi</code>. The &ldquo;A&rdquo; method appears to perform better in <code class="reqn">\kappa</code> and <code class="reqn">h</code> estimation and quite a bit better in <code class="reqn">\alpha</code> and and <code class="reqn">\xi</code> as seemingly expected because these last two are analytically computed (Asquith, 2014). The objective function of the &ldquo;A&rdquo; method defaults to use of the <code class="reqn">\sqrt{x}</code> but this can be removed by setting <code>sqrt.t3t4=FALSE</code>.
</p>
<p>The initial guesses for the <code class="reqn">\kappa</code> and <code class="reqn">h</code> parameters derives from a hashed environment in in file <br /> &lsquo;<span class="file">sysdata.rda</span>&rsquo; (<span class="env">.lmomcohash$AEPkh2lmrTable</span>) in which the <code class="reqn">\{\kappa, h\}</code> pair having the minimum <code class="reqn">\epsilon(\kappa, h)</code> in which <code class="reqn">\tau_3</code> and <code class="reqn">\tau_4</code> derive from the table as well.  The file &lsquo;<span class="file">SysDataBuilder01.R</span>&rsquo; provides additional technical details on how the <code>AEPkh2lmrTable</code> was generated. The table represents a systematic double-loop sweep through <code><a href="#topic+lmomaep4">lmomaep4</a></code> for
</p>
<p style="text-align: center;"><code class="reqn">\kappa \mapsto \{-3 \le \log(\kappa) \le 3, \Delta\log(\kappa)=0.05\}\mbox{,}</code>
</p>

<p>and
</p>
<p style="text-align: center;"><code class="reqn">h \mapsto \{-3 \le \log(h) \le 3, \Delta\log(h)=0.05\}\mbox{.}</code>
</p>

<p>The function will not return parameters if the following lower (estimated) bounds of <code class="reqn">\tau_4</code> are not met: <br /> <code class="reqn">\tau_4 \ge 0.77555(|\tau_3|) - 3.3355(|\tau_3|)^2 + 14.196(|\tau_3|)^3 - 29.909(|\tau_3|)^4 + 37.214(|\tau_3|)^5 - 24.741(|\tau_3|)^6 + 6.7998(|\tau_3|)^7</code>. For this polynomial, the residual standard error is RSE = 0.0003125 and the maximum absolute error for <code class="reqn">\tau_3{:}[0,1] &lt; 0.0015</code>. The actual coefficients in <code><a href="#topic+paraep4">paraep4</a></code> have additional significant figures. However, the argument <code>snap.tau4</code>, if set, will set <code class="reqn">\tau_4</code> equal to the prediction from the polynomial. This value of <code class="reqn">\tau_4</code> should be close enough numerically to the boundary because the optimization is made using a log-transformation to ensure that <code class="reqn">\alpha</code>, <code class="reqn">\kappa</code>, and <code class="reqn">h</code> remain in the positive domain&mdash;though the argument <code>nudge.tau4</code> is provided to offset <code class="reqn">\tau_4</code> upward just incase of optimization problems.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>paraep4(lmom, checklmom=TRUE, method=c("A", "DG", "ADG"),
        sqrt.t3t4=TRUE, eps=1e-4, checkbounds=TRUE, kapapproved=TRUE,
        snap.tau4=FALSE, nudge.tau4=0,
        A.guess=NULL, K.guess=NULL, H.guess=NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="paraep4_+3A_lmom">lmom</code></td>
<td>
<p>An L-moment object created by <code><a href="#topic+lmoms">lmoms</a></code> or <code><a href="#topic+vec2lmom">vec2lmom</a></code>.</p>
</td></tr>
<tr><td><code id="paraep4_+3A_checklmom">checklmom</code></td>
<td>
<p>Should the L-moments be checked for validity using the <code><a href="#topic+are.lmom.valid">are.lmom.valid</a></code> function. Normally this should be left as the default and it is very unlikely that the L-moments will not be viable (particularly in the <code class="reqn">\tau_4</code> and <code class="reqn">\tau_3</code> inequality). However, for some circumstances or large simulation exercises then one might want to bypass this check.</p>
</td></tr>
<tr><td><code id="paraep4_+3A_method">method</code></td>
<td>
<p>Which method for parameter estimation should be used. The &ldquo;A&rdquo; or &ldquo;DG&rdquo; methods. The &ldquo;ADG&rdquo; method will run both methods and retains the salient optimization results of each but the official parameters in <code>para</code> are those from the &ldquo;A&rdquo; method. Lastly, all minimization is based on the <code>optim</code> function using the Nelder&ndash;Mead method and default arguments.</p>
</td></tr>
<tr><td><code id="paraep4_+3A_sqrt.t3t4">sqrt.t3t4</code></td>
<td>
<p>If true and the method is &ldquo;A&rdquo;, then the square root of the sum of square errors in <code class="reqn">\tau_3</code> and <code class="reqn">\tau_4</code> are used instead of sum of square differences alone.</p>
</td></tr>
<tr><td><code id="paraep4_+3A_eps">eps</code></td>
<td>
<p>A small term or threshold for which the square root of the sum of square errors in <code class="reqn">\tau_3</code> and <code class="reqn">\tau_4</code> is compared to to judge &ldquo;good enough&rdquo; for the alogrithm to set the <code>ifail</code> on return in addition to convergence flags coming from the <code>optim</code> function. Note that <code>eps</code> is only used if the &ldquo;A&rdquo; or &ldquo;ADG&rdquo; methods are triggered because the other method uses the scale parameter which in reality could be quite large relative to the other two shape parameters, and a reasonable default for such a secondary error threshold check would be ambiguous.</p>
</td></tr>
<tr><td><code id="paraep4_+3A_checkbounds">checkbounds</code></td>
<td>
<p>Should the lower bounds of <code class="reqn">\tau_4</code> be verified and if sample <code class="reqn">\hat\tau_3</code> and <code class="reqn">\hat\tau_4</code> are outside of these bounds, then <code>NA</code> are returned for the solutions.</p>
</td></tr>
<tr><td><code id="paraep4_+3A_kapapproved">kapapproved</code></td>
<td>
<p>Should the Kappa distribution be fit by <code><a href="#topic+parkap">parkap</a></code> if <code class="reqn">\hat\tau_4</code> is below the lower bounds of <code class="reqn">\tau_4</code>? This fitting is only possible if <code>checkbounds</code> is true. The Kappa and AEP4 overlap partially. The AEP4 extends <code class="reqn">\tau_4</code> above Generalized Logistic and Kappa extends <code class="reqn">\tau_4</code> below the lower bounds of <code class="reqn">\tau_4</code> for AEP4 and extends all the way to the theoretical limits as used within <code><a href="#topic+are.lmom.valid">are.lmom.valid</a></code>.</p>
</td></tr>
<tr><td><code id="paraep4_+3A_snap.tau4">snap.tau4</code></td>
<td>
<p>A logical to &ldquo;snap&rdquo; the <code class="reqn">\tau_4</code> upwards to the lower boundary if the given <code class="reqn">\tau_4</code> is lower than the boundary described in the polynomial.</p>
</td></tr>
<tr><td><code id="paraep4_+3A_nudge.tau4">nudge.tau4</code></td>
<td>
<p>An offset to the snapping of <code class="reqn">\tau_4</code> intended to move <code class="reqn">\tau_4</code> just above the lower bounds in case of optimization problems. (The absolute value of the nudge is made internally to ensure only upward adjustment by an addition operation.)</p>
</td></tr>
<tr><td><code id="paraep4_+3A_a.guess">A.guess</code></td>
<td>
<p>A user specified guess of the <code class="reqn">\alpha</code> parameter to provide to the optimization of any of the methods. This argument just superceeds the simple initial guess of <code class="reqn">\alpha = 1</code>.</p>
</td></tr>
<tr><td><code id="paraep4_+3A_k.guess">K.guess</code></td>
<td>
<p>A user specified guess of the <code class="reqn">\kappa</code> parameter to supercede that derived from the <span class="env">.lmomcohash$AEPkh2lmrTable</span> in file &lsquo;<span class="file">sysdata.rda</span>&rsquo;.</p>
</td></tr>
<tr><td><code id="paraep4_+3A_h.guess">H.guess</code></td>
<td>
<p>A user specified guess of the <code class="reqn">h</code> parameter to supercede that derived from the <span class="env">.lmomcohash$AEPkh2lmrTable</span> in file &lsquo;<span class="file">sysdata.rda</span>&rsquo;.</p>
</td></tr>
<tr><td><code id="paraep4_+3A_...">...</code></td>
<td>
<p>Other arguments to pass.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> is returned.
</p>
<table>
<tr><td><code>type</code></td>
<td>
<p>The type of distribution: <code>aep4</code>.</p>
</td></tr>
<tr><td><code>para</code></td>
<td>
<p>The parameters of the distribution.</p>
</td></tr>
<tr><td><code>source</code></td>
<td>
<p>The source of the parameters: &ldquo;paraep4&rdquo;.</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>The method as specified by the <code>method</code>.</p>
</td></tr>
<tr><td><code>ifail</code></td>
<td>
<p>A numeric failure code.</p>
</td></tr>
<tr><td><code>ifailtext</code></td>
<td>
<p>A text message for the failure code.</p>
</td></tr>
<tr><td><code>L234</code></td>
<td>
<p>Optional and dependent on method &ldquo;DG&rdquo; or &ldquo;ADG&rdquo;. Another <span class="rlang"><b>R</b></span> <code>list</code> containing the optimization details by the &ldquo;DG&rdquo; method along with the estimated parameters in <code>para_L234</code>. The &ldquo;_234&rdquo; is to signify that optimization is made using <code class="reqn">\lambda_2</code>, <code class="reqn">\lambda_3</code>, and <code class="reqn">\lambda_4</code>.  The parameter values in <code>para</code> are those only when the &ldquo;DG&rdquo; method is used.</p>
</td></tr>
<tr><td><code>T34</code></td>
<td>
<p>Optional and dependent on method &ldquo;A&rdquo; or &ldquo;ADG&rdquo;. Another <span class="rlang"><b>R</b></span> <code>list</code> containing the optimization details by the &ldquo;A&rdquo; method along with the estimated parameters in <code>para_T34</code>. The &ldquo;_T34&rdquo; is to signify that opimization is being conducted using <code class="reqn">\tau_3</code> and <code class="reqn">\tau_4</code> only. The parameter values in <code>para</code> are those by the &ldquo;A&rdquo; method.</p>
</td></tr>
</table>
<p>The values for <code>ifail</code> or produced by three mechanisms. First, the convergence number emanating from the <code>optim</code> function itself. Second, the integer 1 is used when the failure is attributable to the <code>optim</code> function. Third, the interger 2 is a general attempt to have a singular failure by sometype of <code>eps</code> outside of <code>optim</code>. Fourth, the integer 3 is used to show that the parameters fail against a parameter validity check in <code><a href="#topic+are.paraep4.valid">are.paraep4.valid</a></code>. And fifth, the integer 4 is used to show that the sample L-moments are below the lower bounds of the <code class="reqn">\tau_4</code> polynomial shown here.
</p>
<p>Additional and self explanatory elements on the returned list will be present if the Kappa distribution was fit instead.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Asquith, W.H., 2014, Parameter estimation for the 4-parameter asymmetric exponential power distribution by the method of L-moments using R: Computational Statistics and Data Analysis, v. 71, pp. 955&ndash;970.
</p>
<p>Delicado, P., and Goria, M.N., 2008, A small sample comparison of maximum likelihood,
moments and L-moments methods for the asymmetric exponential power distribution:
Computational Statistics and Data Analysis, v. 52, no. 3, pp. 1661&ndash;1673.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lmomaep4">lmomaep4</a></code>, <code><a href="#topic+cdfaep4">cdfaep4</a></code>, <code><a href="#topic+pdfaep4">pdfaep4</a></code>, <code><a href="#topic+quaaep4">quaaep4</a></code>, <code><a href="#topic+quaaep4kapmix">quaaep4kapmix</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># As a general rule AEP4 optimization can be CPU intensive

## Not run: 
lmr &lt;- vec2lmom(c(305, 263, 0.815, 0.631))
plotlmrdia(lmrdia()); points(lmr$ratios[3], lmr$ratios[4], pch=16, cex=3)
PAR &lt;- paraep4(lmr, snap.tau4=TRUE) # will just miss the default eps
FF &lt;- nonexceeds(sig6=TRUE)
plot(FF, quaaep4(FF, PAR), type="l", log="y")
lmomaep4(PAR) # 305, 263, 0.8150952, 0.6602706 (compare to those in lmr) 
## End(Not run)

## Not run: 
PAR &lt;- list(para=c(100, 1000, 1.7, 1.4), type="aep4")
lmr &lt;- lmomaep4(PAR)
aep4 &lt;- paraep4(lmr, method="ADG")
print(aep4) # 
## End(Not run)

## Not run: 
PARdg  &lt;- paraep4(lmr, method="DG")
PARasq &lt;- paraep4(lmr, method="A")
print(PARdg)
print(PARasq)
F &lt;- c(0.001, 0.005, seq(0.01,0.99, by=0.01), 0.995, 0.999)
qF &lt;- qnorm(F)
ylim &lt;- range( quaaep4(F, PAR), quaaep4(F, PARdg), quaaep4(F, PARasq) )
plot(qF, quaaep4(F, PARdg), type="n", ylim=ylim,
     xlab="STANDARD NORMAL VARIATE", ylab="QUANTILE")
lines(qF, quaaep4(F, PAR), col=8, lwd=10) # the true curve
lines(qF, quaaep4(F, PARdg),  col=2, lwd=3)
lines(qF, quaaep4(F, PARasq), col=3, lwd=2, lty=2)
# See how the red curve deviates, Delicado and Goria failed
# and the ifail attribute in PARdg is TRUE. Note for lmomco 2.3.1+
# that after movement to log-exp transform to the parameters during
# optimization that this "error" as described does not appear to occur.

print(PAR$para)
print(PARdg$para)
print(PARasq$para)

ePAR1dg &lt;- abs((PAR$para[1] - PARdg$para[1])/PAR$para[1])
ePAR2dg &lt;- abs((PAR$para[2] - PARdg$para[2])/PAR$para[2])
ePAR3dg &lt;- abs((PAR$para[3] - PARdg$para[3])/PAR$para[3])
ePAR4dg &lt;- abs((PAR$para[4] - PARdg$para[4])/PAR$para[4])

ePAR1asq &lt;- abs((PAR$para[1] - PARasq$para[1])/PAR$para[1])
ePAR2asq &lt;- abs((PAR$para[2] - PARasq$para[2])/PAR$para[2])
ePAR3asq &lt;- abs((PAR$para[3] - PARasq$para[3])/PAR$para[3])
ePAR4asq &lt;- abs((PAR$para[4] - PARasq$para[4])/PAR$para[4])

MADdg  &lt;- mean(ePAR1dg,  ePAR2dg,  ePAR3dg,  ePAR4dg)
MADasq &lt;- mean(ePAR1asq, ePAR2asq, ePAR3asq, ePAR4asq)

# We see that the Asquith method performs better for the example
# parameters in PAR and inspection of the graphic will show that
# the Delicado and Goria solution is obviously off. (See Note above)
print(MADdg)
print(MADasq)

# Repeat the above with this change in parameter to
# PAR &lt;- list(para=c(100, 1000, .7, 1.4), type="aep4")
# and the user will see that all three methods converged on the
# correct values. 
## End(Not run)
</code></pre>

<hr>
<h2 id='parcau'>Estimate the Parameters of the Cauchy Distribution</h2><span id='topic+parcau'></span>

<h3>Description</h3>

<p>This function estimates the parameters of the Cauchy distribution from the trimmed L-moments (TL-moments) having trim level 1. The relations between distribution parameters and the TL-moments (trim=1) are seen under <code><a href="#topic+lmomcau">lmomcau</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>parcau(lmom, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="parcau_+3A_lmom">lmom</code></td>
<td>
<p>A TL-moment object from <code><a href="#topic+TLmoms">TLmoms</a></code> with <code>trim=1</code>.</p>
</td></tr>
<tr><td><code id="parcau_+3A_...">...</code></td>
<td>
<p>Other arguments to pass.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> is returned.
</p>
<table>
<tr><td><code>type</code></td>
<td>
<p>The type of distribution: <code>cau</code>.</p>
</td></tr>
<tr><td><code>para</code></td>
<td>
<p>The parameters of the distribution.</p>
</td></tr>
<tr><td><code>source</code></td>
<td>
<p>The source of the parameters: &ldquo;parcau&rdquo;.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Elamir, E.A.H., and Seheult, A.H., 2003, Trimmed L-moments: Computational Statistics and Data Analysis, v. 43, pp. 299&ndash;314.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+TLmoms">TLmoms</a></code>, <code><a href="#topic+lmomcau">lmomcau</a></code>, <code><a href="#topic+cdfcau">cdfcau</a></code>, <code><a href="#topic+pdfcau">pdfcau</a></code>, <code><a href="#topic+quacau">quacau</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>X1 &lt;- rcauchy(20)
parcau(TLmoms(X1,trim=1))
</code></pre>

<hr>
<h2 id='paremu'>Estimate the Parameters of the Eta-Mu Distribution</h2><span id='topic+paremu'></span>

<h3>Description</h3>

<p>This function estimates the parameters (<code class="reqn">\eta</code> and <code class="reqn">\alpha</code>) of the Eta-Mu (<code class="reqn">\eta:\mu</code>)  distribution given the L-moments of the data in an L-moment object such as that returned by <code><a href="#topic+lmoms">lmoms</a></code>. The relations between distribution parameters and L-moments are seen under <code><a href="#topic+lmomemu">lmomemu</a></code>.
</p>
<p>The basic approach for parameter optimization is to extract initial guesses for the parameters from the table <code>EMU_lmompara_byeta</code> in the <code>.lmomcohash</code> environment. The parameters having a minimum Euclidean error as controlled by three arguments are used for initial guesses in a Nelder-Mead simplex multidimensional optimization using the <span class="rlang"><b>R</b></span> function <code>optim</code> and default arguments.
</p>
<p>Limited testing indicates that of the &ldquo;error term controlling options&rdquo; that the default values as shown in the Usage section seem to provide superior performance in terms of recovering the <em>a priori known</em> parameters in experiments. It seems that only Euclidean optimization using L-skew and L-kurtosis is preferable, but experiments show the general algorithm to be slow.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>paremu(lmom, checklmom=TRUE, checkbounds=TRUE,
         alsofitT3=FALSE, alsofitT3T4=FALSE, alsofitT3T4T5=FALSE,
         justfitT3T4=TRUE, boundary.tolerance=0.001,
         verbose=FALSE, trackoptim=TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="paremu_+3A_lmom">lmom</code></td>
<td>
<p>An L-moment object created by <code><a href="#topic+lmoms">lmoms</a></code> or <code><a href="#topic+vec2lmom">vec2lmom</a></code>.</p>
</td></tr>
<tr><td><code id="paremu_+3A_checklmom">checklmom</code></td>
<td>
<p>Should the <code>lmom</code> be checked for validity using the <code><a href="#topic+are.lmom.valid">are.lmom.valid</a></code> function. Normally this should be left as the default and it is very unlikely that the L-moments will not be viable (particularly in the <code class="reqn">\tau_4</code> and <code class="reqn">\tau_3</code> inequality).</p>
</td></tr>
<tr><td><code id="paremu_+3A_checkbounds">checkbounds</code></td>
<td>
<p>Should the L-skew and L-kurtosis boundaries of the distribution be checked.</p>
</td></tr>
<tr><td><code id="paremu_+3A_alsofitt3">alsofitT3</code></td>
<td>
<p>Logical when true will add the error term <code class="reqn">(\hat\tau_3 - \tau_3)^2</code> to the sum of square errors for the mean and L-CV.</p>
</td></tr>
<tr><td><code id="paremu_+3A_alsofitt3t4">alsofitT3T4</code></td>
<td>
<p>Logical when true will add the error term <code class="reqn">(\hat\tau_3 - \tau_3)^2 + (\hat\tau_4 - \tau_4)^2</code> to the sum of square errors for the mean and L-CV.</p>
</td></tr>
<tr><td><code id="paremu_+3A_alsofitt3t4t5">alsofitT3T4T5</code></td>
<td>
<p>Logical when true will add the error term <code class="reqn">(\hat\tau_3 - \tau_3)^2 + (\hat\tau_4 - \tau_4)^2 + (\hat\tau_5 - \tau_5)^2</code> to the sum of square errors for the mean and L-CV.</p>
</td></tr>
<tr><td><code id="paremu_+3A_justfitt3t4">justfitT3T4</code></td>
<td>
<p>Logical when true will only consider the sum of squares errors for L-skew and L-kurtosis as mathematically shown for <code>alsofitT3T4</code>.</p>
</td></tr>
<tr><td><code id="paremu_+3A_boundary.tolerance">boundary.tolerance</code></td>
<td>
<p>A fudge number to help guide how close to the boundaries an arbitrary list of <code class="reqn">\tau_3</code> and <code class="reqn">\tau_4</code> can be to consider them formally in or out of the attainable <code class="reqn">\{\tau_3, \tau_4\}</code> domain.</p>
</td></tr>
<tr><td><code id="paremu_+3A_verbose">verbose</code></td>
<td>
<p>A logical to control a level of diagnostic output.</p>
</td></tr>
<tr><td><code id="paremu_+3A_trackoptim">trackoptim</code></td>
<td>
<p>A logical to control specific messaging through each iteration of the objective function.</p>
</td></tr>
<tr><td><code id="paremu_+3A_...">...</code></td>
<td>
<p>Other arguments to pass.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> is returned.
</p>
<table>
<tr><td><code>type</code></td>
<td>
<p>The type of distribution: <code>emu</code>.</p>
</td></tr>
<tr><td><code>para</code></td>
<td>
<p>The parameters of the distribution.</p>
</td></tr>
<tr><td><code>source</code></td>
<td>
<p>The source of the parameters: &ldquo;paremu&rdquo;.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Yacoub, M.D., 2007, The kappa-mu distribution and the eta-mu distribution: IEEE Antennas and Propagation Magazine, v. 49, no. 1, pp. 68&ndash;81
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lmomemu">lmomemu</a></code>, <code><a href="#topic+cdfemu">cdfemu</a></code>, <code><a href="#topic+pdfemu">pdfemu</a></code>, <code><a href="#topic+quaemu">quaemu</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
   par1 &lt;- vec2par(c(.3, 2.15), type="emu")
   lmr1 &lt;- lmomemu(par1, nmom=4)
   par2.1 &lt;- paremu(lmr1, alsofitT3=FALSE, verbose=TRUE, trackoptim=TRUE)
   par2.1$para # correct parameters not found: eta=0.889 mu=3.54
   par2.2 &lt;- paremu(lmr1, alsofitT3=TRUE, verbose=TRUE, trackoptim=TRUE)
   par2.2$para # correct parameters not found: eta=0.9063 mu=3.607
   par2.3 &lt;- paremu(lmr1, alsofitT3T4=TRUE,  verbose=TRUE, trackoptim=TRUE)
   par2.3$para # correct parameters not found: eta=0.910 mu=3.62
   par2.4 &lt;- paremu(lmr1, justfitT3T4=TRUE,  verbose=TRUE, trackoptim=TRUE)
   par2.4$para # correct parameters not found: eta=0.559 mu=3.69

   x &lt;- seq(0,3,by=.01)
   plot(x,  pdfemu(x, par1), type="l", lwd=6, col=8, ylim=c(0,2))
   lines(x, pdfemu(x, par2.1), col=2, lwd=2, lty=2)
   lines(x, pdfemu(x, par2.2), col=4)
   lines(x, pdfemu(x, par2.3), col=3, lty=3, lwd=2)
   lines(x, pdfemu(x, par2.4), col=5, lty=2, lwd=2)

## End(Not run)
</code></pre>

<hr>
<h2 id='parexp'>Estimate the Parameters of the Exponential Distribution</h2><span id='topic+parexp'></span>

<h3>Description</h3>

<p>This function estimates the parameters of the Exponential distribution given the L-moments of the data in an L-moment object such as that returned by <code><a href="#topic+lmoms">lmoms</a></code>. The relations between distribution parameters and L-moments are seen under <code><a href="#topic+lmomexp">lmomexp</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>parexp(lmom, checklmom=TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="parexp_+3A_lmom">lmom</code></td>
<td>
<p>An L-moment object created by <code><a href="#topic+lmoms">lmoms</a></code> or <code><a href="#topic+vec2lmom">vec2lmom</a></code>.</p>
</td></tr>
<tr><td><code id="parexp_+3A_checklmom">checklmom</code></td>
<td>
<p>Should the <code>lmom</code> be checked for validity using the <code><a href="#topic+are.lmom.valid">are.lmom.valid</a></code> function. Normally this should be left as the default and it is very unlikely that the L-moments will not be viable (particularly in the <code class="reqn">\tau_4</code> and <code class="reqn">\tau_3</code> inequality). However, for some circumstances or large simulation exercises then one might want to bypass this check.</p>
</td></tr>
<tr><td><code id="parexp_+3A_...">...</code></td>
<td>
<p>Other arguments to pass.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> is returned.
</p>
<table>
<tr><td><code>type</code></td>
<td>
<p>The type of distribution: <code>exp</code>.</p>
</td></tr>
<tr><td><code>para</code></td>
<td>
<p>The parameters of the distribution.</p>
</td></tr>
<tr><td><code>source</code></td>
<td>
<p>The source of the parameters: &ldquo;parexp&rdquo;.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Hosking, J.R.M., 1990, L-moments&mdash;Analysis and estimation of distributions using linear combinations of order statistics: Journal of the Royal Statistical Society, Series B, v. 52, pp. 105&ndash;124.
</p>
<p>Hosking, J.R.M., 1996, FORTRAN routines for use with the method of L-moments: Version 3, IBM Research Report RC20525, T.J. Watson Research Center, Yorktown Heights, New York.
</p>
<p>Hosking, J.R.M., and Wallis, J.R., 1997, Regional frequency analysis&mdash;An approach based on L-moments: Cambridge University Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lmomexp">lmomexp</a></code>,
<code><a href="#topic+cdfexp">cdfexp</a></code>, <code><a href="#topic+pdfexp">pdfexp</a></code>, <code><a href="#topic+quaexp">quaexp</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>lmr &lt;- lmoms(rnorm(20))
parexp(lmr)
</code></pre>

<hr>
<h2 id='pargam'>Estimate the Parameters of the Gamma Distribution</h2><span id='topic+pargam'></span>

<h3>Description</h3>

<p>This function estimates the parameters of the Gamma distribution given the L-moments of the data in an L-moment object such as that returned by <code><a href="#topic+lmoms">lmoms</a></code>. Both the two-parameter Gamma and three-parameter Generalized Gamma distributions are supported based on the desired choice of the user, and numerical-hybrid methods are required. The <code><a href="#topic+pdfgam">pdfgam</a></code> documentation provides further details.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pargam(lmom, p=c("2", "3"), checklmom=TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pargam_+3A_lmom">lmom</code></td>
<td>
<p>A L-moment object created by <code><a href="#topic+lmoms">lmoms</a></code> or <code><a href="#topic+vec2lmom">vec2lmom</a></code>.</p>
</td></tr>
<tr><td><code id="pargam_+3A_p">p</code></td>
<td>
<p>The number of parameters to estimate for the 2-p Gamma or 3-p Generalized Gamma.</p>
</td></tr> 
<tr><td><code id="pargam_+3A_checklmom">checklmom</code></td>
<td>
<p>Should the <code>lmom</code> be checked for validity using the <code><a href="#topic+are.lmom.valid">are.lmom.valid</a></code> function. Normally this should be left as the default and it is very unlikely that the L-moments will not be viable (particularly in the <code class="reqn">\tau_4</code> and <code class="reqn">\tau_3</code> inequality). However, for some circumstances or large simulation exercises then one might want to bypass this check.</p>
</td></tr>
<tr><td><code id="pargam_+3A_...">...</code></td>
<td>
<p>Other arguments to pass.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> is returned.
</p>
<table>
<tr><td><code>type</code></td>
<td>
<p>The type of distribution: <code>gam</code>.</p>
</td></tr>
<tr><td><code>para</code></td>
<td>
<p>The parameters of the distribution.</p>
</td></tr>
<tr><td><code>source</code></td>
<td>
<p>The source of the parameters: &ldquo;pargam&rdquo;.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The two-parameter Gamma is supported by Hosking's code-based approximations to avoid direct numerical techniques. The three-parameter version is based on a dual approach to parameter optimization. The <code class="reqn">\log(\sigma)</code> and <code class="reqn">\sqrt{\log(\lambda_1/\lambda_2)}</code> conveniently has a relatively narrow range of variation. A polynomial approximation to provide a first estimate of <code class="reqn">\sigma</code> (named <code class="reqn">\sigma'</code>) is used through the <code>optim()</code> function to isolated the best estimates of <code class="reqn">\mu'</code> and <code class="reqn">\nu'</code> of the distribution holding <code class="reqn">\sigma</code> constant at <code class="reqn">\sigma = \sigma'</code>&mdash;a 2D approach is thus involved. Then, the initial parameter for a second three-dimensional optimization is made using the initial parameter estimates as the tuple <code class="reqn">\mu', \sigma', \nu'</code>. This 2D approach seems more robust and effectively canvases more of the Generalized Gamma parameter domain, though a doubled-optimization is not quite as fast as a direct 3D optimization. The following code was used to derive the polynomial coefficients used for the first approximation of <code class="reqn">sigma'</code>:
</p>
<pre>
  nsim &lt;- 10000; mu &lt;- sig &lt;- nu &lt;- l1 &lt;- l2 &lt;- t3 &lt;- t4 &lt;- rep(NA, nsim)
  for(i in 1:nsim) {
    m &lt;- exp(runif(1, min=-4, max=4)); s &lt;- exp(runif(1, min=-8, max=8))
    n &lt;- runif(1, min=-14, max=14); mu[i] &lt;- m; sig[i] &lt;- s; nu[i] &lt;- n
    para &lt;- vec2par(c(m,s,n), type="gam"); lmr &lt;- lmomgam(para)
    if(is.null(lmr)) next
    lam &lt;- lmr$lambdas[1:2]; rat &lt;- lmr$ratios[3:4]
    l1[i]&lt;-lam[1]; l2[i]&lt;-lam[2];t3[i]&lt;-rat[1]; t4[i]&lt;-rat[2]
  }
  ZZ &lt;- data.frame(mu=mu, sig=sig, nu=nu, l1=l1, l2=l2, t3=t3, t4=t4)
  ZZ$ETA &lt;- sqrt(log(ZZ$l1/ZZ$l2)); ZZ &lt;- ZZ[complete.cases(ZZ), ]
  ix &lt;- 1:length(ZZ$ETA);  ix &lt;- ix[(ZZ$ETA &lt; 0.025 &amp; log(ZZ$sig) &lt; 1)]
  ZZ &lt;- ZZ[-ix,]
  with(ZZ, plot(ETA, log(sig), xlim=c(0,4), ylim=c(-8,8)))
  LM &lt;- lm(log(sig)~
           I(1/ETA^1)+I(1/ETA^2)+I(1/ETA^3)+I(1/ETA^4)+I(1/ETA^5)+
               ETA   +I(  ETA^2)+I(  ETA^3)+I(  ETA^4)+I(  ETA^5), data=ZZ)
  ETA &lt;- seq(0,4,by=0.002) # so the line of fit can be seen
  lines(ETA, predict(LM, newdata=list(ETA=ETA)), col=2)
  The.Coefficients.In.pargam.Function &lt;- LM$coefficients
</pre>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Hosking, J.R.M., 1990, L-moments&mdash;Analysis and estimation of distributions using linear combinations of order statistics: Journal of the Royal Statistical Society, Series B, v. 52, pp. 105&ndash;124.
</p>
<p>Hosking, J.R.M., 1996, FORTRAN routines for use with the method of L-moments: Version 3, IBM Research Report RC20525, T.J. Watson Research Center, Yorktown Heights, New York.
</p>
<p>Hosking, J.R.M., and Wallis, J.R., 1997, Regional frequency analysis&mdash;An approach based on L-moments: Cambridge University Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lmomgam">lmomgam</a></code>,
<code><a href="#topic+cdfgam">cdfgam</a></code>, <code><a href="#topic+pdfgam">pdfgam</a></code>, <code><a href="#topic+quagam">quagam</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>pargam(lmoms(abs(rnorm(20, mean=10))))

## Not run: 
pargam(lmomgam(vec2par(c(0.3,0.4,+1.2), type="gam")), p=3)$para
pargam(lmomgam(vec2par(c(0.3,0.4,-1.2), type="gam")), p=3)$para
#        mu      sigma         nu 
# 0.2999994  0.3999990  1.1999696
# 0.2999994  0.4000020 -1.2000567
## End(Not run)
</code></pre>

<hr>
<h2 id='pargep'>Estimate the Parameters of the Generalized Exponential Poisson Distribution</h2><span id='topic+pargep'></span>

<h3>Description</h3>

<p>This function estimates the parameters of the Generalized Exponential Poisson distribution given the L-moments of the data in an L-moment object such as that returned by <code><a href="#topic+lmoms">lmoms</a></code>. The relations between distribution parameters and L-moments are seen under <code><a href="#topic+lmomgep">lmomgep</a></code>. However, the expectations of order statistic extrema are computed through numerical integration of the quantile function and the fundamental definition of L-moments (<code><a href="#topic+theoLmoms.max.ostat">theoLmoms.max.ostat</a></code>). The mean must be <code class="reqn">\lambda_1 &gt; 0</code>. The implementation here fits the first three L-moments. A distribution having two scale parameters produces more than one solution.  The higher L-moments are not consulted as yet in an effort to further enhance functionality. This function has deterministic starting points but on subsequent iterations the starting points do change. If a solution is not forthcoming, try running the whole function again.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pargep(lmom, checklmom=TRUE, checkdomain=TRUE, maxit=10, verbose=FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pargep_+3A_lmom">lmom</code></td>
<td>
<p>An L-moment object created by <code><a href="#topic+lmoms">lmoms</a></code> or <code><a href="#topic+vec2lmom">vec2lmom</a></code>.</p>
</td></tr>
<tr><td><code id="pargep_+3A_checklmom">checklmom</code></td>
<td>
<p>Should the <code>lmom</code> be checked for validity using the <code><a href="#topic+are.lmom.valid">are.lmom.valid</a></code> function. Normally this should be left as the default and it is very unlikely that the L-moments will not be viable (particularly in the <code class="reqn">\tau_4</code> and <code class="reqn">\tau_3</code> inequality). However, for some circumstances or large simulation exercises then one might want to bypass this check.</p>
</td></tr>
<tr><td><code id="pargep_+3A_checkdomain">checkdomain</code></td>
<td>
<p>A logical controlling whether the empirically derived (approximated) boundaries of the GEP in the <code class="reqn">\tau_2</code> and <code class="reqn">\tau_3</code> domain are used for early exiting if the <code>lmom</code> do not appear compatible with the distribution.</p>
</td></tr>
<tr><td><code id="pargep_+3A_maxit">maxit</code></td>
<td>
<p>The maximum number of iterations. The default should be about twice as big as necessary.</p>
</td></tr>
<tr><td><code id="pargep_+3A_verbose">verbose</code></td>
<td>
<p>A logical controlling intermediate results, which is useful given the experimental nature of GEP parameter estimation and if the user is evaluating results at each iteration. The verbosity is subject to change.</p>
</td></tr>
<tr><td><code id="pargep_+3A_...">...</code></td>
<td>
<p>Other arguments to pass.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> is returned.
</p>
<table>
<tr><td><code>type</code></td>
<td>
<p>The type of distribution: <code>gep</code>.</p>
</td></tr>
<tr><td><code>para</code></td>
<td>
<p>The parameters of the distribution.</p>
</td></tr>
<tr><td><code>convergence</code></td>
<td>
<p>A numeric code on covergence, a value of 0 means solution looks ok.</p>
</td></tr>
<tr><td><code>error</code></td>
<td>
<p>Sum of relative error: <code class="reqn">\epsilon = |(\lambda'_2 - \hat\lambda'_2)/\hat\lambda'_2|</code> <code class="reqn">+</code> <code class="reqn">|(\lambda_3 - \hat\lambda_3)/\hat\lambda_3|</code> for the fitted (prime) and sample (hat, given in <code>lmom</code>) 2nd and 3rd L-moments. A value of 10 means that the <code class="reqn">\tau_2</code> and <code class="reqn">\tau_3</code> values are outside the domain of the distribution as determined by brute force computations and custom polynomial fits.</p>
</td></tr>
<tr><td><code>its</code></td>
<td>
<p>Iteration count.</p>
</td></tr>
<tr><td><code>source</code></td>
<td>
<p>The source of the parameters: &ldquo;pargep&rdquo;.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>There are various inequalities and polynomials demarcating the <code class="reqn">\tau_2</code> and <code class="reqn">\tau_3</code> of the distribution. These were developed during a protracted period of investigation into the numerical limits of the distribution with a specific implementation in <span class="pkg">lmomco</span>. Some of these bounds may or may not be optimal as empirically-arrived estimates of theoretical bounds. The polynomials where carefully assembled however. The straight inequalities are a bit more ad hoc following supervision of domain exploration.  More research is needed but the domain constraint provided should generally produce parameter solutions.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>See Also</h3>

<p><code><a href="#topic+lmomgep">lmomgep</a></code>, <code><a href="#topic+cdfgep">cdfgep</a></code>, <code><a href="#topic+pdfgep">pdfgep</a></code>, <code><a href="#topic+quagep">quagep</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Two examples well inside the domain but known to produce difficulty in
# the optimization process; pargep() engineered with flexibility to usually
# hit the proper solutions.
mygepA &lt;- pargep(vec2lmom(c(1,0.305,0.270), lscale=FALSE))
mygepB &lt;- pargep(vec2lmom(c(1,0.280,0.320), lscale=FALSE))

## End(Not run)
## Not run: 
gep1 &lt;- vec2par(c(2708, 3, 52), type="gep")
 lmr &lt;- lmomgep(gep1);  print(lmr$lambdas)
gep2 &lt;- pargep(lmr);    print(lmomgep(gep2)$lambdas)
# Note that we are close on matching the L-moments but we do
# not recover the parameters given because to shape parameters.
gep3 &lt;- pargep(lmr, nk=1, nh=2);
x &lt;- quagep(nonexceeds(), gep1)
x &lt;- sort(c(x, quagep(nonexceeds(), gep2)))
plot(x, pdfgep(x, gep1), type="l", lwd=2)
lines(x, pdfgep(x, gep2), lwd=3, col=2)
lines(x, pdfgep(x, gep3), lwd=2, col=3)

## End(Not run)
</code></pre>

<hr>
<h2 id='pargev'>Estimate the Parameters of the Generalized Extreme Value Distribution</h2><span id='topic+pargev'></span>

<h3>Description</h3>

<p>This function estimates the parameters of the Generalized Extreme Value distribution given the L-moments of the data in an L-moment object such as that returned by <code><a href="#topic+lmoms">lmoms</a></code>. The relations between distribution parameters and L-moments are seen under <code><a href="#topic+lmomgev">lmomgev</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pargev(lmom, checklmom=TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pargev_+3A_lmom">lmom</code></td>
<td>
<p>An L-moment object created by <code><a href="#topic+lmoms">lmoms</a></code> or <code><a href="#topic+vec2lmom">vec2lmom</a></code>.</p>
</td></tr>
<tr><td><code id="pargev_+3A_checklmom">checklmom</code></td>
<td>
<p>Should the <code>lmom</code> be checked for validity using the <code><a href="#topic+are.lmom.valid">are.lmom.valid</a></code> function. Normally this should be left as the default and it is very unlikely that the L-moments will not be viable (particularly in the <code class="reqn">\tau_4</code> and <code class="reqn">\tau_3</code> inequality). However, for some circumstances or large simulation exercises then one might want to bypass this check.</p>
</td></tr>
<tr><td><code id="pargev_+3A_...">...</code></td>
<td>
<p>Other arguments to pass.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> is returned.
</p>
<table>
<tr><td><code>type</code></td>
<td>
<p>The type of distribution: <code>gev</code>.</p>
</td></tr>
<tr><td><code>para</code></td>
<td>
<p>The parameters of the distribution.</p>
</td></tr>
<tr><td><code>source</code></td>
<td>
<p>The source of the parameters: &ldquo;pargev&rdquo;.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Hosking, J.R.M., 1990, L-moments&mdash;Analysis and estimation of distributions using linear combinations of order statistics: Journal of the Royal Statistical Society, Series B, v. 52, pp. 105&ndash;124.
</p>
<p>Hosking, J.R.M., 1996, FORTRAN routines for use with the method of L-moments: Version 3, IBM Research Report RC20525, T.J. Watson Research Center, Yorktown Heights, New York.
</p>
<p>Hosking, J.R.M., and Wallis, J.R., 1997, Regional frequency analysis&mdash;An approach based on L-moments: Cambridge University Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lmomgev">lmomgev</a></code>,
<code><a href="#topic+cdfgev">cdfgev</a></code>, <code><a href="#topic+pdfgev">pdfgev</a></code>, <code><a href="#topic+quagev">quagev</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>lmr &lt;- lmoms(rnorm(20))
pargev(lmr)
</code></pre>

<hr>
<h2 id='pargld'>Estimate the Parameters of the Generalized Lambda Distribution</h2><span id='topic+pargld'></span>

<h3>Description</h3>

<p>This function estimates the parameters of the Generalized Lambda distribution given the L-moments of the data in an ordinary L-moment object (<code><a href="#topic+lmoms">lmoms</a></code>) or a trimmed L-moment object (<code><a href="#topic+TLmoms">TLmoms</a></code> for <code>t=1</code>). The relations between distribution parameters and L-moments are seen under <code><a href="#topic+lmomgld">lmomgld</a></code>. There are no simple expressions for the parameters in terms of the L-moments. Consider that multiple parameter solutions are possible with the Generalized Lambda so some expertise in the distribution and other aspects are needed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pargld(lmom, verbose=FALSE, initkh=NULL, eps=1e-3,
       aux=c("tau5", "tau6"), checklmom=TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pargld_+3A_lmom">lmom</code></td>
<td>
<p>An L-moment object created by <code><a href="#topic+lmoms">lmoms</a></code>, <code><a href="#topic+vec2lmom">vec2lmom</a></code>, or <code><a href="#topic+TLmoms">TLmoms</a></code> with <code>trim=0</code>.</p>
</td></tr>
<tr><td><code id="pargld_+3A_verbose">verbose</code></td>
<td>
<p>A logical switch on the verbosity of output.  Default is <code>verbose=FALSE</code>.</p>
</td></tr>
<tr><td><code id="pargld_+3A_initkh">initkh</code></td>
<td>
<p>A vector of the initial guess of the <code class="reqn">\kappa</code> and <code class="reqn">h</code> parameters. No other regions of parameter space are consulted.</p>
</td></tr>
<tr><td><code id="pargld_+3A_eps">eps</code></td>
<td>
<p>A small term or threshold for which the square root of the sum of square errors in <code class="reqn">\tau_3</code> and <code class="reqn">\tau_4</code> is compared to to judge &ldquo;good enough&rdquo; for the alogrithm to order solutions based on smallest error as explained in next argument.</p>
</td></tr>
<tr><td><code id="pargld_+3A_aux">aux</code></td>
<td>
<p>Control the algorithm to order solutions based on smallest error in <code class="reqn">\Delta \tau_5</code> or <code class="reqn">\Delta \tau_6</code>.</p>
</td></tr>
<tr><td><code id="pargld_+3A_checklmom">checklmom</code></td>
<td>
<p>Should the <code>lmom</code> be checked for validity using the <code><a href="#topic+are.lmom.valid">are.lmom.valid</a></code> function. Normally this should be left as the default and it is very unlikely that the L-moments will not be viable (particularly in the <code class="reqn">\tau_4</code> and <code class="reqn">\tau_3</code> inequality). However, for some circumstances or large simulation exercises then one might want to bypass this check.</p>
</td></tr>
<tr><td><code id="pargld_+3A_...">...</code></td>
<td>
<p>Other arguments to pass.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Karian and Dudewicz (2000) summarize six regions of the <code class="reqn">\kappa</code> and <code class="reqn">h</code> space in which the Generalized Lambda distribution is valid for suitably choosen <code class="reqn">\alpha</code>. Numerical experimentation suggestions that the L-moments are not valid in Regions 1 and 2. However, initial guesses of the parameters within each region are used with numerous separate <code>optim</code> (the <span class="rlang"><b>R</b></span> function) efforts to perform a least sum-of-square errors on the following objective function
</p>
<p style="text-align: center;"><code class="reqn">(\hat{\tau}_3 - \tilde{\tau}_3)^2 + (\hat{\tau}_4 - \tilde{\tau}_4)^2 \mbox{, }</code>
</p>

<p>where <code class="reqn">\hat{\tau}_r</code> is the L-moment ratio of the data, <code class="reqn">\tilde{\tau}_r</code> is the estimated value of the L-moment ratio for the fitted distribution <code class="reqn">\kappa</code> and <code class="reqn">h</code> and <code class="reqn">\tau_r</code> is the actual value of the L-moment ratio.
</p>
<p>For each optimization, a check on the validity of the parameters so produced is made&mdash;are the parameters consistent with the Generalized Lambda distribution? A second check is made on the validity of <code class="reqn">\tau_3</code> and <code class="reqn">\tau_4</code>. If both validity checks return <code>TRUE</code> then the optimization is retained if its sum-of-square error is less than the previous optimum value. It is possible for a given solution to be found outside the starting region of the initial guesses. The surface generated by the <code class="reqn">\tau_3</code> and <code class="reqn">\tau_4</code> equations seen in <code><a href="#topic+lmomgld">lmomgld</a></code> is complex&ndash;different initial guesses within a given region can yield what appear to be radically different <code class="reqn">\kappa</code> and <code class="reqn">h</code>. Users are encouraged to &ldquo;play&rdquo; with alternative solutions (see the <code>verbose</code> argument). A quick double check on the L-moments from the solved parameters using <code><a href="#topic+lmomgld">lmomgld</a></code> is encouraged as well. Karvanen and others (2002, eq. 25) provide an equation expressing <code class="reqn">\kappa</code> and <code class="reqn">h</code> as equal (a symmetrical Generalized Lambda distribution) in terms of <code class="reqn">\tau_4</code> and suggest that the equation be used to determine initial values for the parameters. The Karvanen equation is used on a semi-experimental basis for the final optimization attempt by <code>pargld</code>.
</p>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> is returned if <code>result='best'</code>.
</p>
<table>
<tr><td><code>type</code></td>
<td>
<p>The type of distribution: <code>gld</code>.</p>
</td></tr>
<tr><td><code>para</code></td>
<td>
<p>The parameters of the distribution.</p>
</td></tr>
<tr><td><code>delTau5</code></td>
<td>
<p>Difference between the <code class="reqn">\tilde{\tau}_5</code> of the fitted distribution and true <code class="reqn">\hat{\tau}_5</code>.</p>
</td></tr>
<tr><td><code>error</code></td>
<td>
<p>Smallest sum of square error found.</p>
</td></tr>
<tr><td><code>source</code></td>
<td>
<p>The source of the parameters: &ldquo;pargld&rdquo;.</p>
</td></tr>
<tr><td><code>rest</code></td>
<td>
<p>An <span class="rlang"><b>R</b></span> <code>data.frame</code> of other solutions if found.</p>
</td></tr>
</table>
<p>The rest of the solutions have the following:
</p>
<table>
<tr><td><code>xi</code></td>
<td>
<p>The location parameter of the distribution.</p>
</td></tr>
<tr><td><code>alpha</code></td>
<td>
<p>The scale parameter of the distribution.</p>
</td></tr>
<tr><td><code>kappa</code></td>
<td>
<p>The 1st shape parameter of the distribution.</p>
</td></tr>
<tr><td><code>h</code></td>
<td>
<p>The 2nd shape parameter of the distribution.</p>
</td></tr>
<tr><td><code>attempt</code></td>
<td>
<p>The attempt number that found valid TL-moments and parameters of GLD.</p>
</td></tr>
<tr><td><code>delTau5</code></td>
<td>
<p>The absolute difference between <code class="reqn">\hat{\tau}^{(1)}_5</code> of data to <code class="reqn">\tilde{\tau}^{(1)}_5</code> of the fitted distribution.</p>
</td></tr>
<tr><td><code>error</code></td>
<td>
<p>The sum of square error found.</p>
</td></tr>
<tr><td><code>initial_k</code></td>
<td>
<p>The starting point of the <code class="reqn">\kappa</code> parameter.</p>
</td></tr>
<tr><td><code>initial_h</code></td>
<td>
<p>The starting point of the <code class="reqn">h</code> parameter.</p>
</td></tr>
<tr><td><code>valid.gld</code></td>
<td>
<p>Logical on validity of the GLD&mdash;<code>TRUE</code> by this point.</p>
</td></tr>
<tr><td><code>valid.lmr</code></td>
<td>
<p>Logical on validity of the L-moments&mdash;<code>TRUE</code> by this point.</p>
</td></tr>
<tr><td><code>lowerror</code></td>
<td>
<p>Logical on whether error was less than <code>eps</code>&mdash;<code>TRUE</code> by this point.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>This function is a cumbersome method of parameter solution, but years of testing suggest that with supervision and the available options regarding the optimization that reliable parameter estimations result. The Tukey Lambda distribution is a special form of the GLD, see <b>Tukey Lambda Notes</b> section in <b>Details</b> of <code><a href="#topic+lmrdia46">lmrdia46</a></code> for more details.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>Source</h3>

<p>W.H. Asquith in Feb. 2006 with a copy of Karian and Dudewicz (2000) and again Feb. 2011.
</p>


<h3>References</h3>

<p>Asquith, W.H., 2007, L-moments and TL-moments of the generalized lambda distribution: Computational Statistics and Data Analysis, v. 51, no. 9, pp. 4484&ndash;4496.
</p>
<p>Karvanen, J., Eriksson, J., and Koivunen, V., 2002, Adaptive score functions for maximum likelihood ICA: Journal of VLSI Signal Processing, v. 32, pp. 82&ndash;92.
</p>
<p>Karian, Z.A., and Dudewicz, E.J., 2000, Fitting statistical distributions&mdash;The generalized lambda distribution and generalized bootstrap methods: CRC Press, Boca Raton, FL, 438 p.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lmomgld">lmomgld</a></code>, <code><a href="#topic+cdfgld">cdfgld</a></code>, <code><a href="#topic+pdfgld">pdfgld</a></code>,  <code><a href="#topic+quagld">quagld</a></code>, <code><a href="#topic+parTLgld">parTLgld</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
  X      &lt;- sort( rgamma(202, 2) ) # simulate a skewed distribution
  lmr    &lt;- lmoms(X)               # compute trimmed L-moments
  PARgld &lt;- pargld(lmr)            # fit the GLD
  FF     &lt;- pp(X)
  plot( FF,    X, col=8, cex=0.25)
  lines(FF, qlmomco(FF, PARgld)) # show the best estimate
  if(! is.null(PARgld$rest)) { #$
    n &lt;- length(PARgld$rest$xi)
    other &lt;- unlist(PARgld$rest[n, 1:4]) #$ # show alternative
    lines(FF, qlmomco(FF, vec2par(other, type="gld")), col="red")
  }
  # Note in the extraction of other solutions that no testing for whether
  # additional solutions were found is made. Also, it is quite possible
  # that the other solutions "[n,1:4]" is effectively another numerical
  # convergence on the primary solution. Some users of this example thus
  # might not see two separate lines. Users are encouraged to inspect the
  # rest of the solutions: print(PARgld$rest) # 
## End(Not run)

## Not run: 
  FF &lt;- seq(0.01, 0.99, 0.01)
  plot(FF,  qlmomco(FF, vec2par(c(3.1446434, 2.943469, 7.4211316, 1.050537),
                                type="gld")), col="blue", type="l")
  lines(FF, qlmomco(FF, vec2par(c(0.4962471, 8.794038, 0.0082958, 0.228352),
                                type="gld")), col="red"           ) # 
## End(Not run)
</code></pre>

<hr>
<h2 id='parglo'>Estimate the Parameters of the Generalized Logistic Distribution</h2><span id='topic+parglo'></span>

<h3>Description</h3>

<p>This function estimates the parameters of the Generalized Logistic distribution given the L-moments of the data in an L-moment object such as that returned by <code><a href="#topic+lmoms">lmoms</a></code>. The relations between distribution parameters and L-moments are seen under <code><a href="#topic+lmomglo">lmomglo</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>parglo(lmom, checklmom=TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="parglo_+3A_lmom">lmom</code></td>
<td>
<p>An L-moment object created by <code><a href="#topic+lmoms">lmoms</a></code> or <code><a href="#topic+vec2lmom">vec2lmom</a></code>.</p>
</td></tr>
<tr><td><code id="parglo_+3A_checklmom">checklmom</code></td>
<td>
<p>Should the <code>lmom</code> be checked for validity using the <code><a href="#topic+are.lmom.valid">are.lmom.valid</a></code> function. Normally this should be left as the default and it is very unlikely that the L-moments will not be viable (particularly in the <code class="reqn">\tau_4</code> and <code class="reqn">\tau_3</code> inequality). However, for some circumstances or large simulation exercises then one might want to bypass this check.</p>
</td></tr>
<tr><td><code id="parglo_+3A_...">...</code></td>
<td>
<p>Other arguments to pass.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> is returned.
</p>
<table>
<tr><td><code>type</code></td>
<td>
<p>The type of distribution: <code>glo</code>.</p>
</td></tr>
<tr><td><code>para</code></td>
<td>
<p>The parameters of the distribution.</p>
</td></tr>
<tr><td><code>source</code></td>
<td>
<p>The source of the parameters: &ldquo;parglo&rdquo;.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Hosking, J.R.M., 1990, L-moments&mdash;Analysis and estimation of distributions using linear combinations of order statistics: Journal of the Royal Statistical Society, Series B, v. 52, pp. 105&ndash;124.
</p>
<p>Hosking, J.R.M., 1996, FORTRAN routines for use with the method of L-moments: Version 3, IBM Research Report RC20525, T.J. Watson Research Center, Yorktown Heights, New York.
</p>
<p>Hosking, J.R.M., and Wallis, J.R., 1997, Regional frequency analysis&mdash;An approach based on L-moments: Cambridge University Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lmomglo">lmomglo</a></code>, <code><a href="#topic+cdfglo">cdfglo</a></code>,  <code><a href="#topic+pdfglo">pdfglo</a></code>, <code><a href="#topic+quaglo">quaglo</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>lmr &lt;- lmoms(rnorm(20))
parglo(lmr)
## Not run: 
# A then Ph.D. student, L. Read inquired in February 2014 about the relation between
# GLO and the "Log-Logistic" distributions:
par.glo  &lt;- vec2par(c(10, .56, 0), type="glo")         # Define GLO parameters
par.lnlo &lt;- c(exp(par.glo$para[1]), 1/par.glo$para[2]) # Equivalent LN-LO parameters
F &lt;- nonexceeds(); qF &lt;- qnorm(F) # use a real probability axis to show features
plot(qF, exp(quaglo(F, par.glo)), type="l", lwd=5, xaxt="n", log="y",
     xlab="", ylab="QUANTILE") # notice the exp() wrapper on the GLO quantiles
lines(qF, par.lnlo[1]*(F/(1-F))^(1/par.lnlo[2]), col=2, lwd=2) # eq. for LN-LO
add.lmomco.axis(las=2, tcl=0.5, side.type="RI", otherside.type="NPP")

## End(Not run)
</code></pre>

<hr>
<h2 id='pargno'>Estimate the Parameters of the Generalized Normal Distribution</h2><span id='topic+pargno'></span>

<h3>Description</h3>

<p>This function estimates the parameters of the Generalized Normal (Log-Normal3) distribution given the L-moments of the data in an L-moment object such as that returned by <code><a href="#topic+lmoms">lmoms</a></code>. The relations between distribution parameters and L-moments are seen under <code><a href="#topic+lmomgno">lmomgno</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pargno(lmom, checklmom=TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pargno_+3A_lmom">lmom</code></td>
<td>
<p>An L-moment object created by <code><a href="#topic+lmoms">lmoms</a></code> or <code><a href="#topic+vec2lmom">vec2lmom</a></code>.</p>
</td></tr>
<tr><td><code id="pargno_+3A_checklmom">checklmom</code></td>
<td>
<p>Should the <code>lmom</code> be checked for validity using the <code><a href="#topic+are.lmom.valid">are.lmom.valid</a></code> function. Normally this should be left as the default and it is very unlikely that the L-moments will not be viable (particularly in the <code class="reqn">\tau_4</code> and <code class="reqn">\tau_3</code> inequality). However, for some circumstances or large simulation exercises then one might want to bypass this check.</p>
</td></tr>
<tr><td><code id="pargno_+3A_...">...</code></td>
<td>
<p>Other arguments to pass.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> is returned.
</p>
<table>
<tr><td><code>type</code></td>
<td>
<p>The type of distribution: <code>gno</code>.</p>
</td></tr>
<tr><td><code>para</code></td>
<td>
<p>The parameters of the distribution.</p>
</td></tr>
<tr><td><code>source</code></td>
<td>
<p>The source of the parameters: &ldquo;pargno&rdquo;.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Hosking, J.R.M., 1990, L-moments&mdash;Analysis and estimation of distributions using linear combinations of order statistics: Journal of the Royal Statistical Society, Series B, v. 52, pp. 105&ndash;124.
</p>
<p>Hosking, J.R.M., 1996, FORTRAN routines for use with the method of L-moments: Version 3, IBM Research Report RC20525, T.J. Watson Research Center, Yorktown Heights, New York.
</p>
<p>Hosking, J.R.M., and Wallis, J.R., 1997, Regional frequency analysis&mdash;An approach based on L-moments: Cambridge University Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lmomgno">lmomgno</a></code>, <code><a href="#topic+cdfgno">cdfgno</a></code>, <code><a href="#topic+pdfgno">pdfgno</a></code>, <code><a href="#topic+quagno">quagno</a></code>, <code><a href="#topic+parln3">parln3</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>lmr &lt;- lmoms(rnorm(20))
pargno(lmr)

## Not run: 
x &lt;- c(2.4, 2.7, 2.3, 2.5, 2.2, 62.4, 3.8, 3.1)
gno &lt;- pargno(lmoms(x)) # triggers warning: Hosking's limit is Tau3=+-0.95 
## End(Not run)
</code></pre>

<hr>
<h2 id='pargov'>Estimate the Parameters of the Govindarajulu Distribution</h2><span id='topic+pargov'></span>

<h3>Description</h3>

<p>This function estimates the parameters of the Govindarajulu distribution given the L-moments of the data in an L-moment object such as that returned by <code><a href="#topic+lmoms">lmoms</a></code>. The relations between distribution parameters and L-moments also are seen under <code><a href="#topic+lmomgov">lmomgov</a></code>. The <code class="reqn">\beta</code> is estimated as
</p>
<p style="text-align: center;"><code class="reqn">\beta = -\frac{(4\tau_3 + 2)}{(\tau_3 - 1)}\mbox{,}</code>
</p>

<p>and <code class="reqn">\alpha</code> then <code class="reqn">\xi</code> are estimated for <em>unknown</em> <code class="reqn">\xi</code> as
</p>
<p style="text-align: center;"><code class="reqn">\alpha = \lambda_2\frac{(\beta+2)(\beta+3)}{2\beta}\mbox{, and}</code>
</p>

<p style="text-align: center;"><code class="reqn">\xi = \lambda_1 - \frac{2\alpha}{(\beta+2)}\mbox{,}</code>
</p>

<p>and <code class="reqn">\alpha</code> is estimated for <em>known</em> <code class="reqn">\xi</code> as 
</p>
<p style="text-align: center;"><code class="reqn">\alpha = (\lambda_1 - \xi)\frac{(\beta + 2)}{2}\mbox{.}</code>
</p>

<p>The shape preservation for this distribution is an ad hoc decision. It could be that for given <code class="reqn">\xi</code>, that solutions could fall back to estimating <code class="reqn">\xi</code> and <code class="reqn">\alpha</code> from <code class="reqn">\lambda_1</code> and <code class="reqn">\lambda_2</code> only. Such as solution would rely on <code class="reqn">\tau_2 = \lambda_2/\lambda_1</code> with <code class="reqn">\beta</code> estimated as
</p>
<p style="text-align: center;"><code class="reqn">\beta = \frac{3\tau_2}{(1-\tau_2)}\mbox{, and}</code>
</p>

<p style="text-align: center;"><code class="reqn">\alpha = \lambda_1\frac{(\beta+2)}{2}\mbox{,}</code>
</p>

<p>but such a practice yields remarkable changes in shape for this distribution even if the provided <code class="reqn">\xi</code> precisely matches that from a previous parameter estimation for which the <code class="reqn">\xi</code> was treated as unknown.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pargov(lmom, xi=NULL, checklmom=TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pargov_+3A_lmom">lmom</code></td>
<td>
<p>An L-moment object created by <code><a href="#topic+lmoms">lmoms</a></code> or <code><a href="#topic+vec2lmom">vec2lmom</a></code>.</p>
</td></tr>
<tr><td><code id="pargov_+3A_xi">xi</code></td>
<td>
<p>An optional lower limit of the distribution. If not <code>NULL</code>, the <code class="reqn">B</code> is still uniquely determined by <code class="reqn">\tau_3</code>, the <code class="reqn">\alpha</code> is adjusted so that the given lower bounds is honored. It is generally accepted to let the distribution fitting process determine its own lower bounds so <code>xi=NULL</code> should suffice in many circumstances.</p>
</td></tr>
<tr><td><code id="pargov_+3A_checklmom">checklmom</code></td>
<td>
<p>Should the <code>lmom</code> be checked for validity using the <code><a href="#topic+are.lmom.valid">are.lmom.valid</a></code> function. Normally this should be left as the default and it is very unlikely that the L-moments will not be viable (particularly in the <code class="reqn">\tau_4</code> and <code class="reqn">\tau_3</code> inequality). However, for some circumstances or large simulation exercises then one might want to bypass this check.</p>
</td></tr>
<tr><td><code id="pargov_+3A_...">...</code></td>
<td>
<p>Other arguments to pass.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> is returned.
</p>
<table>
<tr><td><code>type</code></td>
<td>
<p>The type of distribution: <code>gov</code>.</p>
</td></tr>
<tr><td><code>para</code></td>
<td>
<p>The parameters of the distribution.</p>
</td></tr>
<tr><td><code>source</code></td>
<td>
<p>The source of the parameters: &ldquo;pargov&rdquo;.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Gilchrist, W.G., 2000, Statistical modelling with quantile functions: Chapman and Hall/CRC, Boca Raton.
</p>
<p>Nair, N.U., Sankaran, P.G., Balakrishnan, N., 2013, Quantile-based reliability analysis: Springer, New York.
</p>
<p>Nair, N.U., Sankaran, P.G., and Vineshkumar, B., 2012, The Govindarajulu distribution&mdash;Some Properties and applications: Communications in Statistics, Theory and Methods, v. 41, no. 24, pp. 4391&ndash;4406.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lmomgov">lmomgov</a></code>,
<code><a href="#topic+cdfgov">cdfgov</a></code>, <code><a href="#topic+pdfgov">pdfgov</a></code>, <code><a href="#topic+quagov">quagov</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>lmr &lt;- lmoms(rnorm(20))
pargov(lmr)

lmr &lt;- vec2lmom(c(1391.8, 215.68, 0.01655, 0.09628))
pargov(lmr)$para             # see below
#         xi       alpha        beta 
# 868.148125 1073.740595    2.100971 
pargov(lmr, xi=868)$para     # see below
#         xi       alpha        beta 
# 868.000000 1074.044324    2.100971 
pargov(lmr, xi=100)$para     # see below
#         xi       alpha        beta 
# 100.000000 2648.817215    2.100971 
</code></pre>

<hr>
<h2 id='pargpa'>Estimate the Parameters of the Generalized Pareto Distribution</h2><span id='topic+pargpa'></span>

<h3>Description</h3>

<p>This function estimates the parameters of the Generalized Pareto distribution given the L-moments of the data in an ordinary L-moment object (<code><a href="#topic+lmoms">lmoms</a></code>) or a trimmed L-moment object (<code><a href="#topic+TLmoms">TLmoms</a></code> for <code>t=1</code>). The relations between distribution parameters and L-moments are seen under <code><a href="#topic+lmomgpa">lmomgpa</a></code> or <code><a href="#topic+lmomTLgpa">lmomTLgpa</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pargpa(lmom, zeta=1, xi=NULL, checklmom=TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pargpa_+3A_lmom">lmom</code></td>
<td>
<p>An L-moment object created by <code><a href="#topic+lmoms">lmoms</a></code>, <code><a href="#topic+TLmoms">TLmoms</a></code> with <code>trim=0</code>, or <code><a href="#topic+vec2lmom">vec2lmom</a></code>.</p>
</td></tr>
<tr><td><code id="pargpa_+3A_zeta">zeta</code></td>
<td>
<p>The right censoring fraction. If less than unity then a dispatch to the <code><a href="#topic+pargpaRC">pargpaRC</a></code> is made and the <code>lmom</code> argument must contain the B-type L-moments. If the data are not right censored, then this value must be left alone to the default of unity.</p>
</td></tr>
<tr><td><code id="pargpa_+3A_xi">xi</code></td>
<td>
<p>The lower limit of the distribution. If <code class="reqn">\xi</code> is known, then alternative algorithms are used.</p>
</td></tr>
<tr><td><code id="pargpa_+3A_checklmom">checklmom</code></td>
<td>
<p>Should the <code>lmom</code> be checked for validity using the <code><a href="#topic+are.lmom.valid">are.lmom.valid</a></code> function. Normally this should be left as the default and it is very unlikely that the L-moments will not be viable (particularly in the <code class="reqn">\tau_4</code> and <code class="reqn">\tau_3</code> inequality). However, for some circumstances or large simulation exercises then one might want to bypass this check.</p>
</td></tr>
<tr><td><code id="pargpa_+3A_...">...</code></td>
<td>
<p>Other arguments to pass.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> is returned.
</p>
<table>
<tr><td><code>type</code></td>
<td>
<p>The type of distribution: <code>gpa</code>.</p>
</td></tr>
<tr><td><code>para</code></td>
<td>
<p>The parameters of the distribution.</p>
</td></tr>
<tr><td><code>source</code></td>
<td>
<p>The source of the parameters: &ldquo;pargpa&rdquo;.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Hosking, J.R.M., 1990, L-moments&mdash;Analysis and estimation of distributions using linear combinations of order statistics: Journal of the Royal Statistical Society, Series B, v. 52, pp. 105&ndash;124.
</p>
<p>Hosking, J.R.M., 1996, FORTRAN routines for use with the method of L-moments: Version 3, IBM Research Report RC20525, T.J. Watson Research Center, Yorktown Heights, New York.
</p>
<p>Hosking, J.R.M., and Wallis, J.R., 1997, Regional frequency analysis&mdash;An approach based on L-moments: Cambridge University Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lmomgpa">lmomgpa</a></code>,
<code><a href="#topic+cdfgpa">cdfgpa</a></code>, <code><a href="#topic+pdfgpa">pdfgpa</a></code>, <code><a href="#topic+quagpa">quagpa</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>X   &lt;- rexp(200)
lmr &lt;- lmoms(X)
P1  &lt;- pargpa(lmr)
P2  &lt;- pargpa(lmr, xi=0.25)

## Not run: 
F &lt;- nonexceeds()
plot(pp(X), sort(X))
lines(F, quagpa(F,P1))         # black line
lines(F, quagpa(F,P2), col=2)  # red line

## End(Not run)
</code></pre>

<hr>
<h2 id='pargpaRC'>Estimate the Parameters of the Generalized Pareto Distribution with Right-Tail Censoring</h2><span id='topic+pargpaRC'></span>

<h3>Description</h3>

<p>This function estimates the parameters (<code class="reqn">\xi</code>, <code class="reqn">\alpha</code>, and <code class="reqn">\kappa</code>) of the Generalized Pareto distribution given the &ldquo;B&rdquo;-type L-moments (through the B-type probability-weighted moments) of the data under right censoring conditions (see <code><a href="#topic+pwmRC">pwmRC</a></code>). The relations between distribution parameters and L-moments are seen under <code><a href="#topic+lmomgpaRC">lmomgpaRC</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pargpaRC(lmom, zeta=1, xi=NULL, lower=-1, upper=20, checklmom=TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pargpaRC_+3A_lmom">lmom</code></td>
<td>
<p>A B-type L-moment object created by a function such as <code><a href="#topic+pwm2lmom">pwm2lmom</a></code> from B-type probability-weighted moments from <code><a href="#topic+pwmRC">pwmRC</a></code>.</p>
</td></tr>
<tr><td><code id="pargpaRC_+3A_zeta">zeta</code></td>
<td>
<p>The compliment of the right-tail censoring fraction. The number of samples observed (noncensored) divided by the total number of samples.</p>
</td></tr>
<tr><td><code id="pargpaRC_+3A_xi">xi</code></td>
<td>
<p>The lower limit of the distribution. If <code class="reqn">\xi</code> is known, then alternative algorithms are used.</p>
</td></tr>
<tr><td><code id="pargpaRC_+3A_lower">lower</code></td>
<td>
<p>The lower value for <code class="reqn">\kappa</code> for a call to the <code>optimize</code> function. For the L-moments of the distribution to be valid <code class="reqn">\kappa &gt; -1</code>.</p>
</td></tr>
<tr><td><code id="pargpaRC_+3A_upper">upper</code></td>
<td>
<p>The upper value for <code class="reqn">\kappa</code> for a call to the <code>optimize</code> function. Hopefully, a large enough default is chosen for real-world data sets.</p>
</td></tr>
<tr><td><code id="pargpaRC_+3A_checklmom">checklmom</code></td>
<td>
<p>Should the <code>lmom</code> be checked for validity using the <code><a href="#topic+are.lmom.valid">are.lmom.valid</a></code> function. Normally this should be left as the default and it is very unlikely that the L-moments will not be viable (particularly in the <code class="reqn">\tau_4</code> and <code class="reqn">\tau_3</code> inequality). However, for some circumstances or large simulation exercises then one might want to bypass this check.</p>
</td></tr>
<tr><td><code id="pargpaRC_+3A_...">...</code></td>
<td>
<p>Other arguments to pass.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>optimize</code> <span class="rlang"><b>R</b></span> function is used to numerically solve for the shape parameter <code class="reqn">\kappa</code>. No test or evaluation is made on the quality of the minimization. Users should consult the contents of the <code>optim</code> portion of the returned list. Finally, this function should return the same parameters if <code class="reqn">\zeta=1</code> as the <code><a href="#topic+pargpa">pargpa</a></code> function.
</p>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> is returned.
</p>
<table>
<tr><td><code>type</code></td>
<td>
<p>The type of distribution: <code>gpa</code>.</p>
</td></tr>
<tr><td><code>para</code></td>
<td>
<p>The parameters of the distribution.</p>
</td></tr>
<tr><td><code>zeta</code></td>
<td>
<p>The compliment of the right-tail censoring fraction.</p>
</td></tr>
<tr><td><code>source</code></td>
<td>
<p>The source of the parameters: &ldquo;pargpaRC&rdquo;.</p>
</td></tr>
<tr><td><code>optim</code></td>
<td>
<p>The <code>list</code> returned by the <span class="rlang"><b>R</b></span> function <code>optimize</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Hosking, J.R.M., 1990, L-moments&mdash;Analysis and estimation of distributions using linear combinations of order statistics: Journal of the Royal Statistical Society, Series B, v. 52, pp. 105&ndash;124.
</p>
<p>Hosking, J.R.M., 1995, The use of L-moments in the analysis of censored data, in Recent Advances in Life-Testing and Reliability, edited by N. Balakrishnan, chapter 29, CRC Press, Boca Raton, Fla., pp. 546&ndash;560.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lmomgpa">lmomgpa</a></code>, <code><a href="#topic+lmomgpaRC">lmomgpaRC</a></code>, <code><a href="#topic+pargpa">pargpa</a></code>, <code><a href="#topic+cdfgpa">cdfgpa</a></code>, <code><a href="#topic+pdfgpa">pdfgpa</a></code>, <code><a href="#topic+quagpa">quagpa</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n         &lt;- 60 # samplesize
para      &lt;- vec2par(c(1500,160,.3),type="gpa") # build a GPA parameter set
fakedata  &lt;- quagpa(runif(n),para) # generate n simulated values
threshold &lt;- 1700 # a threshold to apply the simulated censoring
fakedata  &lt;- sapply(fakedata,function(x) { if(x &gt; threshold)
                                           return(threshold) else return(x) })
lmr       &lt;- lmoms(fakedata) # Ordinary L-moments without considering
                             # that the data is censored
estpara   &lt;- pargpa(lmr) # Estimated parameters of parent

pwm2     &lt;- pwmRC(fakedata,threshold=threshold) # compute censored PWMs
typeBpwm &lt;- pwm2$Bbetas # the B-type PWMs
zeta     &lt;- pwm2$zeta # the censoring fraction

cenpara &lt;- pargpaRC(pwm2lmom(typeBpwm),zeta=zeta) # Estimated parameters
F       &lt;- nonexceeds() # nonexceedance probabilities for plotting purposes

# Visualize some data
plot(F,quagpa(F,para), type='l', lwd=3) # The true distribution
lines(F,quagpa(F,estpara), col=3) # Green estimated in the ordinary fashion
lines(F,quagpa(F,cenpara), col=2) # Red, consider that the data is censored
# now add in what the drawn sample looks like.
PP &lt;- pp(fakedata) # plotting positions of the data
points(PP,sort(fakedata)) # sorting is needed!
# Interpretation. You should see that the red line more closely matches
# the heavy black line. The green line should be deflected to the right
# and pass through the values equal to the threshold, which reflects the
# much smaller L-skew of the ordinary L-moments compared to the type-B
# L-moments.

# Assertion, given some PWMs or L-moments, if zeta=1 then the parameter
# estimates must be identical. The following provides a demonstration.
para1 &lt;- pargpaRC(pwm2lmom(typeBpwm),zeta=1)
para2 &lt;- pargpa(pwm2lmom(typeBpwm))
str(para1); str(para2)

# Assertion as previous assertion, let us trigger different optimizer
# algorithms with a non-NULL xi parameter and see if the two parameter
# lists are the same.
para1 &lt;- pargpaRC(pwm2lmom(typeBpwm), zeta=zeta)
para2 &lt;- pargpaRC(pwm2lmom(typeBpwm), xi=para1$para[1], zeta=zeta)
str(para1); str(para2)
</code></pre>

<hr>
<h2 id='pargum'>Estimate the Parameters of the Gumbel Distribution</h2><span id='topic+pargum'></span>

<h3>Description</h3>

<p>This function estimates the parameters of the Gumbel distribution given the L-moments of the data in an L-moment object such as that returned by
<code><a href="#topic+lmoms">lmoms</a></code>. The relations between distribution parameters and L-moments are seen under <code><a href="#topic+lmomgum">lmomgum</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pargum(lmom, checklmom=TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pargum_+3A_lmom">lmom</code></td>
<td>
<p>An L-moment object created by <code><a href="#topic+lmoms">lmoms</a></code> or <code><a href="#topic+vec2lmom">vec2lmom</a></code>.</p>
</td></tr>
<tr><td><code id="pargum_+3A_checklmom">checklmom</code></td>
<td>
<p>Should the <code>lmom</code> be checked for validity using the <code><a href="#topic+are.lmom.valid">are.lmom.valid</a></code> function. Normally this should be left as the default and it is very unlikely that the L-moments will not be viable (particularly in the <code class="reqn">\tau_4</code> and <code class="reqn">\tau_3</code> inequality). However, for some circumstances or large simulation exercises then one might want to bypass this check.</p>
</td></tr>
<tr><td><code id="pargum_+3A_...">...</code></td>
<td>
<p>Other arguments to pass.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> is returned.
</p>
<table>
<tr><td><code>type</code></td>
<td>
<p>The type of distribution: <code>gum</code>.</p>
</td></tr>
<tr><td><code>para</code></td>
<td>
<p>The parameters of the distribution.</p>
</td></tr>
<tr><td><code>source</code></td>
<td>
<p>The source of the parameters: &ldquo;pargum&rdquo;.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Hosking, J.R.M., 1990, L-moments&mdash;Analysis and estimation of distributions using linear combinations of order statistics: Journal of the Royal Statistical Society, Series B, v. 52, pp. 105&ndash;124.
</p>
<p>Hosking, J.R.M., 1996, FORTRAN routines for use with the method of L-moments: Version 3, IBM Research Report RC20525, T.J. Watson Research Center, Yorktown Heights, New York.
</p>
<p>Hosking, J.R.M., and Wallis, J.R., 1997, Regional frequency analysis&mdash;An approach based on L-moments: Cambridge University Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lmomgum">lmomgum</a></code>,
<code><a href="#topic+cdfgum">cdfgum</a></code>, <code><a href="#topic+pdfgum">pdfgum</a></code>, <code><a href="#topic+quagum">quagum</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>lmr &lt;- lmoms(rnorm(20))
pargum(lmr)
</code></pre>

<hr>
<h2 id='parkap'>Estimate the Parameters of the Kappa Distribution</h2><span id='topic+parkap'></span>

<h3>Description</h3>

<p>This function estimates the parameters of the Kappa distribution given the L-moments of the data in an L-moment object such as that returned by <code><a href="#topic+lmoms">lmoms</a></code>. The relations between distribution parameters and L-moments are seen under <code><a href="#topic+lmomkap">lmomkap</a></code>, but of relevance to this documentation, the upper bounds of L-kurtosis (<code class="reqn">\tau_4</code>) and a function of L-skew (<code class="reqn">\tau_3</code>) is given by
</p>
<p style="text-align: center;"><code class="reqn">\tau_4 &lt; \frac{5\tau_3^2+1}{6}</code>
</p>

<p>This bounds is equal to the Generalized Logistic distribution (<code><a href="#topic+parglo">parglo</a></code>) and failure occurs if this upper bounds is exceeded. However, the argument <code>snap.tau4</code>, if set, will set <code class="reqn">\tau_4</code> equal to the upper bounds of <code class="reqn">\tau_4</code> of the distribution to the relation above. This value of <code class="reqn">\tau_4</code> should be close enough numerically The argument <code>nudge.tau4</code> is provided to offset <code class="reqn">\tau_4</code> downward just a little. This keeps the relation operator as &ldquo;<code class="reqn">&lt;</code>&rdquo; in the bounds above to match Hosking's tradition as his sources declare &ldquo;<code class="reqn">\ge</code>&rdquo; as above the GLO. The nudge here hence is not zero, which is a little different compared to the conceptually similar snapping in <code><a href="#topic+paraep4">paraep4</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>parkap(lmom, checklmom=TRUE,
             snap.tau4=FALSE, nudge.tau4=sqrt(.Machine$double.eps), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="parkap_+3A_lmom">lmom</code></td>
<td>
<p>An L-moment object created by <code><a href="#topic+lmoms">lmoms</a></code> or <code><a href="#topic+vec2lmom">vec2lmom</a></code>.</p>
</td></tr>
<tr><td><code id="parkap_+3A_checklmom">checklmom</code></td>
<td>
<p>Should the <code>lmom</code> be checked for validity using the <code><a href="#topic+are.lmom.valid">are.lmom.valid</a></code> function. Normally this should be left as the default and it is very unlikely that the L-moments will not be viable (particularly in the <code class="reqn">\tau_4</code> and <code class="reqn">\tau_3</code> inequality). However, for some circumstances or large simulation exercises then one might want to bypass this check.</p>
</td></tr>
<tr><td><code id="parkap_+3A_snap.tau4">snap.tau4</code></td>
<td>
<p>A logical to &ldquo;snap&rdquo; the <code class="reqn">\tau_4</code> downwards to the lower boundary if the given <code class="reqn">\tau_4</code> is greater than the boundary described as above.</p>
</td></tr>
<tr><td><code id="parkap_+3A_nudge.tau4">nudge.tau4</code></td>
<td>
<p>An offset to the snapping of <code class="reqn">\tau_4</code> intended to move <code class="reqn">\tau_4</code> just below the upper bounds. (The absolute value of the nudge is made internally to ensure only downward adjustment by a subtraction operation.)</p>
</td></tr>
<tr><td><code id="parkap_+3A_...">...</code></td>
<td>
<p>Other arguments to pass.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> is returned.
</p>
<table>
<tr><td><code>type</code></td>
<td>
<p>The type of distribution: <code>kap</code>.</p>
</td></tr>
<tr><td><code>para</code></td>
<td>
<p>The parameters of the distribution.</p>
</td></tr>
<tr><td><code>source</code></td>
<td>
<p>The source of the parameters: &ldquo;parkap&rdquo;.</p>
</td></tr>
<tr><td><code>support</code></td>
<td>
<p>The support (or range) of the fitted distribution.</p>
</td></tr>
<tr><td><code>ifail</code></td>
<td>
<p>A numeric failure code.</p>
</td></tr>
<tr><td><code>ifailtext</code></td>
<td>
<p>A text message for the failure code.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Hosking, J.R.M., 1994, The four-parameter kappa distribution: IBM Journal of Reserach and Development, v. 38, no. 3, pp. 251&ndash;258.
</p>
<p>Hosking, J.R.M., and Wallis, J.R., 1997, Regional frequency analysis&mdash;An approach based on L-moments: Cambridge University Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lmomkap">lmomkap</a></code>,
<code><a href="#topic+cdfkap">cdfkap</a></code>, <code><a href="#topic+pdfkap">pdfkap</a></code>, <code><a href="#topic+quakap">quakap</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>lmr &lt;- lmoms(rnorm(20))
parkap(lmr)

## Not run: 
parkap(vec2lmom(c(0,1,.3,.8)), snap.tau4=TRUE) # Tau=0.8 is way above the GLO.
## End(Not run)
</code></pre>

<hr>
<h2 id='parkmu'>Estimate the Parameters of the Kappa-Mu Distribution</h2><span id='topic+parkmu'></span>

<h3>Description</h3>

<p>This function estimates the parameters (<code class="reqn">\nu</code> and <code class="reqn">\alpha</code>) of the Kappa-Mu (<code class="reqn">\kappa:\mu</code>)  distribution given the L-moments of the data in an L-moment object such as that returned by <code><a href="#topic+lmoms">lmoms</a></code>. The relations between distribution parameters and L-moments are seen under <code><a href="#topic+lmomkmu">lmomkmu</a></code>.
</p>
<p>The basic approach for parameter optimization is to extract initial guesses for the parameters from the table <code>KMU_lmompara_bykappa</code> in the <code>.lmomcohash</code> environment. The parameters having a minimum Euclidean error as controlled by three arguments are used for initial guesses in a Nelder-Mead simplex multidimensional optimization using the <span class="rlang"><b>R</b></span> function <code>optim</code> and default arguments.
</p>
<p>Limited testing indicates that of the &ldquo;error term controlling options&rdquo; that the default values as shown in the Usage section seem to provide superior performance in terms of recovering the <em>a priori known</em> parameters in experiments. It seems that only Euclidean optimization using L-skew and L-kurtosis is preferable, but experiments show the general algorithm to be slow.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>parkmu(lmom, checklmom=TRUE, checkbounds=TRUE,
         alsofitT3=FALSE, alsofitT3T4=FALSE, alsofitT3T4T5=FALSE,
         justfitT3T4=TRUE, boundary.tolerance=0.001,
         verbose=FALSE, trackoptim=TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="parkmu_+3A_lmom">lmom</code></td>
<td>
<p>An L-moment object created by <code><a href="#topic+lmoms">lmoms</a></code> or <code><a href="#topic+pwm2lmom">pwm2lmom</a></code>.</p>
</td></tr>
<tr><td><code id="parkmu_+3A_checklmom">checklmom</code></td>
<td>
<p>Should the <code>lmom</code> be checked for validity using the <code><a href="#topic+are.lmom.valid">are.lmom.valid</a></code> function. Normally this should be left as the default and it is very unlikely that the L-moments will not be viable (particularly in the <code class="reqn">\tau_4</code> and <code class="reqn">\tau_3</code> inequality).</p>
</td></tr>
<tr><td><code id="parkmu_+3A_checkbounds">checkbounds</code></td>
<td>
<p>Should the L-skew and L-kurtosis boundaries of the distribution be checked.</p>
</td></tr>
<tr><td><code id="parkmu_+3A_alsofitt3">alsofitT3</code></td>
<td>
<p>Logical when true will add the error term <code class="reqn">(\hat\tau_3 - \tau_3)^2</code> to the sum of square errors for the mean and L-CV.</p>
</td></tr>
<tr><td><code id="parkmu_+3A_alsofitt3t4">alsofitT3T4</code></td>
<td>
<p>Logical when true will add the error term <code class="reqn">(\hat\tau_3 - \tau_3)^2 + (\hat\tau_4 - \tau_4)^2</code> to the sum of square errors for the mean and L-CV.</p>
</td></tr>
<tr><td><code id="parkmu_+3A_alsofitt3t4t5">alsofitT3T4T5</code></td>
<td>
<p>Logical when true will add the error term <code class="reqn">(\hat\tau_3 - \tau_3)^2 + (\hat\tau_4 - \tau_4)^2 + (\hat\tau_5 - \tau_5)^2</code> to the sum of square errors for the mean and L-CV.</p>
</td></tr>
<tr><td><code id="parkmu_+3A_justfitt3t4">justfitT3T4</code></td>
<td>
<p>Logical when true will only consider the sum of squares errors for L-skew and L-kurtosis as mathematically shown for <code>alsofitT3T4</code>.</p>
</td></tr>
<tr><td><code id="parkmu_+3A_boundary.tolerance">boundary.tolerance</code></td>
<td>
<p>A fudge number to help guide how close to the boundaries an arbitrary list of <code class="reqn">\tau_3</code> and <code class="reqn">\tau_4</code> can be to consider them formally in or out of the attainable <code class="reqn">\{\tau_3, \tau_4\}</code> domain.</p>
</td></tr>
<tr><td><code id="parkmu_+3A_verbose">verbose</code></td>
<td>
<p>A logical to control a level of diagnostic output.</p>
</td></tr>
<tr><td><code id="parkmu_+3A_trackoptim">trackoptim</code></td>
<td>
<p>A logical to control specific messaging through each iteration of the objective function.</p>
</td></tr>
<tr><td><code id="parkmu_+3A_...">...</code></td>
<td>
<p>Other arguments to pass.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> is returned.
</p>
<table>
<tr><td><code>type</code></td>
<td>
<p>The type of distribution: <code>kmu</code>.</p>
</td></tr>
<tr><td><code>para</code></td>
<td>
<p>The parameters of the distribution.</p>
</td></tr>
<tr><td><code>source</code></td>
<td>
<p>The source of the parameters: &ldquo;parkmu&rdquo;.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Yacoub, M.D., 2007, The kappa-mu distribution and the eta-mu distribution: IEEE Antennas and Propagation Magazine, v. 49, no. 1, pp. 68&ndash;81
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lmomkmu">lmomkmu</a></code>, <code><a href="#topic+cdfkmu">cdfkmu</a></code>, <code><a href="#topic+pdfkmu">pdfkmu</a></code>, <code><a href="#topic+quakmu">quakmu</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
   par1 &lt;- vec2par(c(0.7, 0.2), type="kmu")
   lmr1 &lt;- lmomkmu(par1, nmom=4)
   par2.1 &lt;- parkmu(lmr1, alsofitT3=TRUE,   verbose=TRUE, trackoptim=TRUE)
   par2.1$para
   par2.2 &lt;- parkmu(lmr1, alsofitT3T4=TRUE, verbose=TRUE, trackoptim=TRUE)
   par2.2$para
   par2.3 &lt;- parkmu(lmr1, alsofitT3=FALSE,  verbose=TRUE, trackoptim=TRUE)
   par2.3$para
   par2.4 &lt;- parkmu(lmr1, justfitT3T4=TRUE, verbose=TRUE, trackoptim=TRUE)
   par2.4$para
   x &lt;- seq(0,3,by=.01)
   plot(x,  pdfkmu(x, par1), type="l", lwd=6, col=8, ylim=c(0,5))
   lines(x, pdfkmu(x, par2.1), col=2, lwd=2, lty=2)
   lines(x, pdfkmu(x, par2.2), col=4)
   lines(x, pdfkmu(x, par2.3), col=3, lty=3, lwd=2)
   lines(x, pdfkmu(x, par2.4), col=5, lty=2, lwd=2)

## End(Not run)
## Not run: 
   par1 &lt;- vec2par(c(1, 0.65), type="kmu")
   lmr1 &lt;- lmomkmu(par1, nmom=4)
   par2.1 &lt;- parkmu(lmr1, alsofitT3=TRUE,   verbose=TRUE, trackoptim=TRUE)
   par2.1$para # eta=1.0  mu=0.65
   par2.2 &lt;- parkmu(lmr1, alsofitT3T4=TRUE, verbose=TRUE, trackoptim=TRUE)
   par2.2$para # eta=1.0  mu=0.65
   par2.3 &lt;- parkmu(lmr1, alsofitT3=FALSE,  verbose=TRUE, trackoptim=TRUE)
   par2.3$para # eta=8.5779  mu=0.2060
   par2.4 &lt;- parkmu(lmr1, justfitT3T4=TRUE, verbose=TRUE, trackoptim=TRUE)
   par2.4$para # eta=1.0 mu=0.65
   x &lt;- seq(0,3,by=.01)
   plot(x,  pdfkmu(x, par1), type="l", lwd=6, col=8, ylim=c(0,1))
   lines(x, pdfkmu(x, par2.1), col=2, lwd=2, lty=2)
   lines(x, pdfkmu(x, par2.2), col=4)
   lines(x, pdfkmu(x, par2.3), col=3, lty=3, lwd=2)
   lines(x, pdfkmu(x, par2.4), col=5, lty=2, lwd=2)
   lines(x, dlmomco(x, lmom2par(lmr1, type="gam")),  lwd=2, col=2)
   lines(x, dlmomco(x, lmom2par(lmr1, type="ray")),  lwd=2, col=2, lty=2)
   lines(x, dlmomco(x, lmom2par(lmr1, type="rice")), lwd=2, col=4, lty=2)

## End(Not run)
</code></pre>

<hr>
<h2 id='parkur'>Estimate the Parameters of the Kumaraswamy Distribution</h2><span id='topic+parkur'></span>

<h3>Description</h3>

<p>This function estimates the parameters of the Kumaraswamy distribution given the L-moments of the data in an L-moment object such as that returned by <code><a href="#topic+lmoms">lmoms</a></code>. The relations between distribution parameters and L-moments are seen under <code><a href="#topic+lmomkur">lmomkur</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>parkur(lmom, checklmom=TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="parkur_+3A_lmom">lmom</code></td>
<td>
<p>An L-moment object created by <code><a href="#topic+lmoms">lmoms</a></code> or <code><a href="#topic+vec2lmom">vec2lmom</a></code>.</p>
</td></tr>
<tr><td><code id="parkur_+3A_checklmom">checklmom</code></td>
<td>
<p>Should the <code>lmom</code> be checked for validity using the <code><a href="#topic+are.lmom.valid">are.lmom.valid</a></code> function. Normally this should be left as the default and it is very unlikely that the L-moments will not be viable (particularly in the <code class="reqn">\tau_4</code> and <code class="reqn">\tau_3</code> inequality). However, for some circumstances or large simulation exercises then one might want to bypass this check.</p>
</td></tr>
<tr><td><code id="parkur_+3A_...">...</code></td>
<td>
<p>Other arguments to pass.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> is returned.
</p>
<table>
<tr><td><code>type</code></td>
<td>
<p>The type of distribution: <code>kur</code>.</p>
</td></tr>
<tr><td><code>para</code></td>
<td>
<p>The parameters of the distribution.</p>
</td></tr>
<tr><td><code>err</code></td>
<td>
<p>The convergence error.</p>
</td></tr>
<tr><td><code>convergence</code></td>
<td>
<p>Logical showing whether error convergence occurred.</p>
</td></tr>
<tr><td><code>source</code></td>
<td>
<p>The source of the parameters: &ldquo;parkur&rdquo;.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Jones, M.C., 2009, Kumaraswamy's distribution&mdash;A beta-type distribution with some tractability advantages: Statistical Methodology, v. 6, pp. 70&ndash;81.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lmomkur">lmomkur</a></code>,
<code><a href="#topic+cdfkur">cdfkur</a></code>, <code><a href="#topic+pdfkur">pdfkur</a></code>, <code><a href="#topic+quakur">quakur</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>lmr &lt;- lmoms(runif(20)^2)
parkur(lmr)

kurpar &lt;- list(para=c(1,1), type="kur");
lmr &lt;- lmomkur(kurpar)
parkur(lmr)

kurpar &lt;- list(para=c(0.1,1), type="kur");
lmr &lt;- lmomkur(kurpar)
parkur(lmr)

kurpar &lt;- list(para=c(1,0.1), type="kur");
lmr &lt;- lmomkur(kurpar)
parkur(lmr)

kurpar &lt;- list(para=c(0.1,0.1), type="kur");
lmr &lt;- lmomkur(kurpar)
parkur(lmr)
</code></pre>

<hr>
<h2 id='parlap'>Estimate the Parameters of the Laplace Distribution</h2><span id='topic+parlap'></span>

<h3>Description</h3>

<p>This function estimates the parameters of the Laplace distribution given the L-moments of the data in an L-moment object such as that returned by <code><a href="#topic+lmoms">lmoms</a></code>. The relations between distribution parameters and sample L-moments are simple, but there are two methods. The first method, which is the only one implemented in <span class="pkg">lmomco</span>, jointly uses <code class="reqn">\lambda_1, \lambda_2, \lambda_3</code>, and <code class="reqn">\lambda_4</code>. The mathematical expressions are
</p>
<p style="text-align: center;"><code class="reqn">\xi = \lambda_1 - 50/31\times\lambda_3 \mbox{and}</code>
</p>

<p style="text-align: center;"><code class="reqn">\alpha = 1.4741\lambda_2 - 0.5960\lambda_4 \mbox{.}</code>
</p>

<p>The alternative and even simpler method only uses <code class="reqn">\lambda_1</code> and <code class="reqn">\lambda_2</code>. The mathematical expressions are
</p>
<p style="text-align: center;"><code class="reqn">\xi = \lambda_1\mbox{\, and}</code>
</p>

<p style="text-align: center;"><code class="reqn">\alpha = \frac{4}{3}\lambda_2\mbox{.}</code>
</p>

<p>The user could easily estimate the parameters from the L-moments and use <code><a href="#topic+vec2par">vec2par</a></code> to create a parameter object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>parlap(lmom, checklmom=TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="parlap_+3A_lmom">lmom</code></td>
<td>
<p>An L-moment object created by <code><a href="#topic+lmoms">lmoms</a></code> or <code><a href="#topic+vec2lmom">vec2lmom</a></code>.</p>
</td></tr>
<tr><td><code id="parlap_+3A_checklmom">checklmom</code></td>
<td>
<p>Should the <code>lmom</code> be checked for validity using the <code><a href="#topic+are.lmom.valid">are.lmom.valid</a></code> function. Normally this should be left as the default and it is very unlikely that the L-moments will not be viable (particularly in the <code class="reqn">\tau_4</code> and <code class="reqn">\tau_3</code> inequality). However, for some circumstances or large simulation exercises then one might want to bypass this check.</p>
</td></tr>
<tr><td><code id="parlap_+3A_...">...</code></td>
<td>
<p>Other arguments to pass.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> is returned.
</p>
<table>
<tr><td><code>type</code></td>
<td>
<p>The type of distribution: <code>lap</code>.</p>
</td></tr>
<tr><td><code>para</code></td>
<td>
<p>The parameters of the distribution.</p>
</td></tr>
<tr><td><code>source</code></td>
<td>
<p>The source of the parameters: &ldquo;parlap&rdquo;.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The decision to use only one of the two systems of equations for Laplace fitting is largely arbitrary, but it seems most fitting to use four L-moments instead of two.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Hosking, J.R.M., 1986, The theory of probability weighted moments: IBM Research Report RC12210, T.J. Watson Research Center, Yorktown Heights, New York.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lmomlap">lmomlap</a></code>,
<code><a href="#topic+cdflap">cdflap</a></code>, <code><a href="#topic+pdflap">pdflap</a></code>, <code><a href="#topic+qualap">qualap</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>lmr &lt;- lmoms(rnorm(20))
parlap(lmr)
</code></pre>

<hr>
<h2 id='parlmrq'>Estimate the Parameters of the Linear Mean Residual Quantile Function Distribution
</h2><span id='topic+parlmrq'></span>

<h3>Description</h3>

<p>This function estimates the parameters of the Linear Mean Residual Quantile Function distribution given the L-moments of the data in an L-moment object such as that returned by <code>lmoms</code>. The relations between distribution parameters and L-moments are seen under <code><a href="#topic+lmomlmrq">lmomlmrq</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>parlmrq(lmom, checklmom=TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="parlmrq_+3A_lmom">lmom</code></td>
<td>
<p>An L-moment object created by <code><a href="#topic+lmoms">lmoms</a></code> or <code><a href="#topic+vec2lmom">vec2lmom</a></code>.</p>
</td></tr>
<tr><td><code id="parlmrq_+3A_checklmom">checklmom</code></td>
<td>
<p>Should the <code>lmom</code> be checked for validity using the <code><a href="#topic+are.lmom.valid">are.lmom.valid</a></code> function. Normally this should be left as the default.</p>
</td></tr>
<tr><td><code id="parlmrq_+3A_...">...</code></td>
<td>
<p>Other arguments to pass.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> is returned.
</p>
<table>
<tr><td><code>type</code></td>
<td>
<p>The type of distribution: <code>lmrq</code>.</p>
</td></tr>
<tr><td><code>para</code></td>
<td>
<p>The parameters of the distribution.</p>
</td></tr>
<tr><td><code>source</code></td>
<td>
<p>The source of the parameters: &ldquo;parlmrq&rdquo;.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Midhu, N.N., Sankaran, P.G., and Nair, N.U., 2013, A class of distributions with linear mean residual quantile function and it's generalizations: Statistical Methodology, v. 15, pp. 1&ndash;24.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lmomlmrq">lmomlmrq</a></code>, <code><a href="#topic+cdflmrq">cdflmrq</a></code>, <code><a href="#topic+pdflmrq">pdflmrq</a></code>, <code><a href="#topic+qualmrq">qualmrq</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>lmr &lt;- lmoms(c(3, 0.05, 1.6, 1.37, 0.57, 0.36, 2.2))
parlmrq(lmr)
</code></pre>

<hr>
<h2 id='parln3'>Estimate the Parameters of the 3-Parameter Log-Normal Distribution</h2><span id='topic+parln3'></span>

<h3>Description</h3>

<p>This function estimates the parameters (<code class="reqn">\zeta</code>, lower bounds; <code class="reqn">\mu_{\mathrm{log}}</code>, location; and <code class="reqn">\sigma_{\mathrm{log}}</code>, scale) of the Log-Normal3 distribution given the L-moments of the data in an L-moment object such as that returned by <code><a href="#topic+lmoms">lmoms</a></code>. The relations between distribution parameters and L-moments are seen under <code><a href="#topic+lmomln3">lmomln3</a></code>. The function uses algorithms of the Generalized Normal for core computations. Also, if <code class="reqn">\tau_3 \le 0</code>, then the Log-Normal3 distribution can not be fit, however reversing the data alleviates this problem.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>parln3(lmom, zeta=NULL, checklmom=TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="parln3_+3A_lmom">lmom</code></td>
<td>
<p>An L-moment object created by <code><a href="#topic+lmoms">lmoms</a></code> or <code><a href="#topic+vec2lmom">vec2lmom</a></code>.</p>
</td></tr>
<tr><td><code id="parln3_+3A_zeta">zeta</code></td>
<td>
<p>Lower bounds, if <code>NULL</code> then solved for.</p>
</td></tr>
<tr><td><code id="parln3_+3A_checklmom">checklmom</code></td>
<td>
<p>Should the <code>lmom</code> be checked for validity using the <code><a href="#topic+are.lmom.valid">are.lmom.valid</a></code> function. Normally this should be left as the default and it is very unlikely that the L-moments will not be viable (particularly in the <code class="reqn">\tau_4</code> and <code class="reqn">\tau_3</code> inequality). However, for some circumstances or large simulation exercises then one might want to bypass this check.</p>
</td></tr>
<tr><td><code id="parln3_+3A_...">...</code></td>
<td>
<p>Other arguments to pass.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Let the L-moments by in variable <code>lmr</code>, if the <code class="reqn">\zeta</code> (lower bounds) is unknown, then the algorithms return the same fit as the Generalized Normal will attain. However, <code><a href="#topic+pargno">pargno</a></code> does not have intrinsic control on the lower bounds and <code><a href="#topic+parln3">parln3</a></code> does. The <code class="reqn">\lambda_1</code>, <code class="reqn">\lambda_2</code>, and <code class="reqn">\tau_3</code> are used in the fitting for <code><a href="#topic+pargno">pargno</a></code> and <code><a href="#topic+parln3">parln3</a></code> but only <code class="reqn">\lambda_1</code> and <code class="reqn">\lambda_2</code> are used when the <code class="reqn">\zeta</code> is provided as in <code>parln3(lmr, zeta=0)</code>. In otherwords, if <code class="reqn">\zeta</code> is known, then <code class="reqn">\tau_3</code> is not used and shaping comes from the choice of <code class="reqn">\zeta</code>.
</p>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> is returned.
</p>
<table>
<tr><td><code>type</code></td>
<td>
<p>The type of distribution: <code>ln3</code>.</p>
</td></tr>
<tr><td><code>para</code></td>
<td>
<p>The parameters of the distribution.</p>
</td></tr>
<tr><td><code>source</code></td>
<td>
<p>The source of the parameters: &ldquo;parln3&rdquo;.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Asquith, W.H., 2011, Distributional analysis with L-moment statistics using the R environment for statistical computing: Createspace Independent Publishing Platform, ISBN 978&ndash;146350841&ndash;8.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lmomln3">lmomln3</a></code>,
<code><a href="#topic+cdfln3">cdfln3</a></code>, <code><a href="#topic+pdfln3">pdfln3</a></code>, <code><a href="#topic+qualn3">qualn3</a></code>, <code><a href="#topic+pargno">pargno</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>lmr &lt;- lmoms(rnorm(20))
parln3(lmr)

## Not run: 
# Handling condition of negative L-skew
# Data reversal looks like: Y &lt;- -X, but let us use an example
# on the L-moments themselves.
lmr.pos &lt;- vec2lmom(c(100, 45, -0.1)) # parln3(lmr.pos) fails
lmr.neg &lt;- lmr.pos
lmr.neg$lambdas[1] &lt;- -lmr.neg$lambdas[1]
lmr.neg$ratios[3]  &lt;- -lmr.neg$ratios[3]
F &lt;- nonexceeds()
plot(F, -qualn3(1-F, parln3(lmr.neg)), type="l", lwd=3, col=2) # red line
lines(F, quagno(F, pargno(lmr.pos))) # black line 
## End(Not run)
</code></pre>

<hr>
<h2 id='parnor'>Estimate the Parameters of the Normal Distribution</h2><span id='topic+parnor'></span>

<h3>Description</h3>

<p>This function estimates the parameters of the Normal distribution given the L-moments of the data in an L-moment object such as that returned by <code><a href="#topic+lmoms">lmoms</a></code>. The relation between distribution parameters and L-moments is seen under <code><a href="#topic+lmomnor">lmomnor</a></code>. 
</p>
<p>There are interesting parallels between <code class="reqn">\lambda_2</code> (L-scale) and <code class="reqn">\sigma</code> (standard deviation). The <code class="reqn">\sigma</code> estimated from this function will not necessarily equal the output of the <code>sd</code> function of <span class="rlang"><b>R</b></span>, and in fact such equality is not expected. This disconnect between the parameters of the Normal distribution and the moments (sample) of the same name can be most confusing to young trainees in statistics. The Pearson Type III is similar. See the extended example for further illustration.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>parnor(lmom, checklmom=TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="parnor_+3A_lmom">lmom</code></td>
<td>
<p>An L-moment object created by <code><a href="#topic+lmoms">lmoms</a></code>
or <code><a href="#topic+vec2lmom">vec2lmom</a></code>.</p>
</td></tr>
<tr><td><code id="parnor_+3A_checklmom">checklmom</code></td>
<td>
<p>Should the <code>lmom</code> be checked for validity using the <code><a href="#topic+are.lmom.valid">are.lmom.valid</a></code> function. Normally this should be left as the default and it is very unlikely that the L-moments will not be viable (particularly in the <code class="reqn">\tau_4</code> and <code class="reqn">\tau_3</code> inequality). However, for some circumstances or large simulation exercises then one might want to bypass this check.</p>
</td></tr>
<tr><td><code id="parnor_+3A_...">...</code></td>
<td>
<p>Other arguments to pass.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> is returned.
</p>
<table>
<tr><td><code>type</code></td>
<td>
<p>The type of distribution: <code>nor</code>.</p>
</td></tr>
<tr><td><code>para</code></td>
<td>
<p>The parameters of the distribution.</p>
</td></tr>
<tr><td><code>source</code></td>
<td>
<p>The source of the parameters: &ldquo;parnor&rdquo;.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Hosking, J.R.M., 1990, L-moments&mdash;Analysis and estimation of distributions using linear combinations of order statistics: Journal of the Royal Statistical Society, Series B, v. 52, pp. 105&ndash;124.
</p>
<p>Hosking, J.R.M., 1996, FORTRAN routines for use with the method of L-moments: Version 3, IBM Research Report RC20525, T.J. Watson Research Center,
Yorktown Heights, New York.
</p>
<p>Hosking, J.R.M., and Wallis, J.R., 1997, Regional frequency analysis&mdash;An approach based on L-moments: Cambridge University Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lmomnor">lmomnor</a></code>,
<code><a href="#topic+cdfnor">cdfnor</a></code>, <code><a href="#topic+pdfnor">pdfnor</a></code>, <code><a href="#topic+quanor">quanor</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>lmr &lt;- lmoms(rnorm(20))
parnor(lmr)

# A more extended example to explore the differences between an
# L-moment derived estimate of the standard deviation and R's sd()
true.std &lt;- 15000 # select a large standard deviation
std         &lt;- vector(mode = "numeric") # vector of sd()
std.by.lmom &lt;- vector(mode = "numeric") # vector of L-scale values
sam &lt;- 7   # number of samples to simulate
sim &lt;- 100 # perform simulation sim times
for(i in seq(1,sim)) {
  Q &lt;- rnorm(sam,sd=15000) # draw random normal variates
  std[i] &lt;- sd(Q) # compute standard deviation
  lmr &lt;- lmoms(Q) # compute the L-moments
  std.by.lmom[i] &lt;- lmr$lambdas[2] # save the L-scale value
}
# convert L-scale values to equivalent standard deviations
std.by.lmom      &lt;- sqrt(pi)*std.by.lmom

# compute the two biases and then output
# see how the standard deviation estimated through L-scale
# has a smaller bias than the usual (product moment) standard
# deviation. The unbiasness of L-moments is demonstrated.
std.bias         &lt;- true.std - mean(std)
std.by.lmom.bias &lt;- true.std - mean(std.by.lmom)
cat(c(std.bias,std.by.lmom.bias,"\n"))
</code></pre>

<hr>
<h2 id='parpdq3'>Estimate the Parameters of the Polynomial Density-Quantile3 Distribution</h2><span id='topic+parpdq3'></span>

<h3>Description</h3>

<p>This function estimates the parameters of the Polynomial Density-Quantile3 distribution given the L-moments of the data in an L-moment object such as that returned by <code><a href="#topic+lmoms">lmoms</a></code>. The relations between the distribution parameters and L-moments are seen under <code><a href="#topic+lmompdq3">lmompdq3</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>parpdq3(lmom, checklmom=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="parpdq3_+3A_lmom">lmom</code></td>
<td>
<p>An L-moment object created by <code><a href="#topic+lmoms">lmoms</a></code> or <code><a href="#topic+vec2lmom">vec2lmom</a></code>.</p>
</td></tr>
<tr><td><code id="parpdq3_+3A_checklmom">checklmom</code></td>
<td>
<p>Should the <code>lmom</code> be checked for validity using the <code><a href="#topic+are.lmom.valid">are.lmom.valid</a></code> function. Normally this should be left as the default and it is unlikely that the L-moments will not be viable. However, for some circumstances or large simulation exercises then one might want to bypass this check.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> is returned.
</p>
<table>
<tr><td><code>type</code></td>
<td>
<p>The type of distribution: <code>pdq3</code>.</p>
</td></tr>
<tr><td><code>para</code></td>
<td>
<p>The parameters of the distribution.</p>
</td></tr>
<tr><td><code>ifail</code></td>
<td>
<p>A numeric field connected to the <code>ifailtext</code>; a value of 0 indicates fully successful operation of the function.</p>
</td></tr>
<tr><td><code>ifailtext</code></td>
<td>
<p>A message, instead of a warning, about the internal operations or operational limits of the function.</p>
</td></tr>
<tr><td><code>source</code></td>
<td>
<p>The source of the parameters: &ldquo;parpdq3&rdquo;.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The following is a study of the performance of <code>parpdq3</code> as the upper limit of the shape parameter <code class="reqn">\kappa</code> is approached. The algorithms have the ability to estimate the <code class="reqn">\kappa</code> reliabily, it is the scale parameter <code class="reqn">\alpha</code> that breaks down and hence there is a hard-wired setting of <code class="reqn">|\kappa| &gt; 0.98</code> in which a warning is issue in <code>parpdq3</code> about <code class="reqn">\alpha</code> reliability:
</p>
<pre>
  A &lt;- 10
  K &lt;- seq(0.8, 1, by=0.0001)
  K &lt;- sort(c(-K, K))
  As &lt;- Ks &lt;- rep(NA, length(K))
  for(i in 1:length(K)) {
    para &lt;- list(para=c(0, A, K[i]), type="pdq3")
    As[i] &lt;- parpdq3( lmompdq3(para) )$para[2]
    Ks[i] &lt;- parpdq3( lmompdq3(para) )$para[3]
  }
  plot( K, (As-A)/A, type="l", col="red")
  abline(v=c(-0.98, +0.98)) # heuristically determined threshold
</pre>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Hosking, J.R.M., 2007, Distributions with maximum entropy subject to constraints on their L-moments or expected order statistics: Journal of Statistical Planning and Inference, v. 137, no. 9, pp. 2870&ndash;2891, <a href="https://doi.org/10.1016/j.jspi.2006.10.010">doi:10.1016/j.jspi.2006.10.010</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lmompdq3">lmompdq3</a></code>, <code><a href="#topic+cdfpdq3">cdfpdq3</a></code>, <code><a href="#topic+pdfpdq3">pdfpdq3</a></code>, <code><a href="#topic+quapdq3">quapdq3</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>para &lt;- list(para=c(0, 0.4332, -0.7029), type="pdq3")
parpdq3(lmompdq3(para))$para

para &lt;- list(para=c(0, 0.4332, 0.7029), type="pdq3")
parpdq3(lmompdq3(para))$para

para &lt;- list(para=c(0, 0.4332, 1-sqrt(.Machine$double.eps)), type="pdq3")
parpdq3(lmompdq3(para))$para

para &lt;- list(para=c(0, 0.4332, -1+sqrt(.Machine$double.eps)), type="pdq3")
parpdq3(lmompdq3(para))$para

para &lt;- list(para=c(0, 0.4332, +0.0001), type="pdq3")
parpdq3(lmompdq3(para))$para

para &lt;- list(para=c(0, 0.4332, -0.0001), type="pdq3")
parpdq3(lmompdq3(para))$para

para &lt;- list(para=c(0, 0.4332, 0), type="pdq3")
parpdq3(lmompdq3(para))$para
</code></pre>

<hr>
<h2 id='parpdq4'>Estimate the Parameters of the Polynomial Density-Quantile4 Distribution</h2><span id='topic+parpdq4'></span>

<h3>Description</h3>

<p>This function estimates the parameters of the Polynomial Density-Quantile4 distribution given the L-moments of the data in an L-moment object such as that returned by <code><a href="#topic+lmoms">lmoms</a></code>. The relations between the distribution parameters and L-moments are seen under <code><a href="#topic+lmompdq4">lmompdq4</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>parpdq4(lmom, checklmom=TRUE, snapt4uplimit=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="parpdq4_+3A_lmom">lmom</code></td>
<td>
<p>An L-moment object created by <code><a href="#topic+lmoms">lmoms</a></code> or <code><a href="#topic+vec2lmom">vec2lmom</a></code>.</p>
</td></tr>
<tr><td><code id="parpdq4_+3A_checklmom">checklmom</code></td>
<td>
<p>Should the <code>lmom</code> be checked for validity using the <code><a href="#topic+are.lmom.valid">are.lmom.valid</a></code> function. Normally this should be left as the default and it is unlikely that the L-moments will not be viable. However, for some circumstances or large simulation exercises then one might want to bypass this check.</p>
</td></tr>
<tr><td><code id="parpdq4_+3A_snapt4uplimit">snapt4uplimit</code></td>
<td>
<p>A logical controlling the behavior of the function for <code class="reqn">\tau_4</code> exceeding an operational upper margin and whether the incoming <code class="reqn">\tau_4</code> can be snapped down to this margin (see <b>Note</b>).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> is returned.
</p>
<table>
<tr><td><code>type</code></td>
<td>
<p>The type of distribution: <code>pdq4</code>.</p>
</td></tr>
<tr><td><code>para</code></td>
<td>
<p>The parameters of the distribution.</p>
</td></tr>
<tr><td><code>ifail</code></td>
<td>
<p>A numeric field connected to the <code>ifailtext</code>; a value of 0 indicates fully successful operation of the function.</p>
</td></tr>
<tr><td><code>ifailtext</code></td>
<td>
<p>A message, instead of a warning, about the internal operations or operational limits of the function.</p>
</td></tr>
<tr><td><code>source</code></td>
<td>
<p>The source of the parameters: &ldquo;parpdq4&rdquo;.</p>
</td></tr>
</table>


<h3>Note</h3>

<p><b>Upper Limit of the Shape Parameter</b>&mdash;The following is a study of the performance of <code>parpdq4</code> as the upper limit of the shape parameter <code class="reqn">\kappa</code> is approached. The algorithms have the ability to estimate the <code class="reqn">\kappa</code> reliabily, it is the scale parameter <code class="reqn">\alpha</code> that breaks down and hence there is a hard-wired setting of <code class="reqn">\kappa &gt; 0.99</code> in which a message is issued to <code>ifail</code> about <code class="reqn">\alpha</code> reliability:
</p>
<pre>
  A &lt;- 100
  K &lt;- seq(0.8, 1, by=0.0001)
  As &lt;- Ks &lt;- rep(NA, length(K))
  for(i in 1:length(K)) {
    para  &lt;- list(para=c(0, A, K[i]), type="pdq4")
    pdq4  &lt;- parpdq4(lmompdq4(para), snapt4uplimit=FALSE)
    As[i] &lt;- pdq4$para[2]
    Ks[i] &lt;- pdq4$para[3]
  }
  plot( K, (As-A)/A, type="l", col="red")
  abline(v=0.99) # heuristically determined threshold
</pre>
<p><b>Lower Limit of the Shape Parameter</b>&mdash;The lower limit of <code class="reqn">\kappa</code> does not really exist but as <code class="reqn">\kappa \rightarrow -\infty</code>, the qualty of the <code class="reqn">\alpha</code> operation will degrade. The approach in the code involves an <span class="rlang"><b>R</b></span> function <code>uniroot()</code> operation and the lower limit is not set to <code>-Inf</code> but is set within sources as the value <br /> <code>-.Machine$double.xmax^(1/64)</code>,<br /> which is not too small of a number, but the <code class="reqn">\tau_4</code> associated with this limit is -0.2499878576145593, which is extremely close to <code class="reqn">\tau_4 &gt; -1/4</code> lower limit. The implementation here will snap incoming <code class="reqn">\tau_4</code> to a threshold towards zero as
</p>
<pre>
  TAU4 &lt;- "users tau4"
  smallTAU4 &lt;- -0.2499878576145593
  if(TAU4 &lt; smallTAU4) TAU4 &lt;- smallTAU4 + sqrt(.Machine$double.eps)
  print(TAU4, 16) # -0.2499878427133981
</pre>
<p>and this snapping produces an operational lower bounds of <code class="reqn">\kappa</code> of -65455.6715146775. This topic can be explored by operations such as
</p>
<pre>
  # Have tau4 but with internals to protect quality of the
  # alpha estimation and speed root-solving the kappa, there
  # is an operational lower bounds of tau4. Here lower limit
  # tau4 = -0.25 and the operations below return -0.2499878.
  lmompdq4(parpdq4(vec2lmom(c(0, 100, 0, -1/4))))$ratios[4]
</pre>
<p><b>Upper Operational Limit of L-kurtosis</b>&mdash;The script below explores the operational limit of <code class="reqn">\tau_4</code> within the algorithms themselves. It is seen in the computations that breakdown in the reverse computation of the <code class="reqn">\tau_4</code> from the parameters begins at <code class="reqn">\tau_4 &gt;= 0.867</code>. As a result, the argument <code>snapt4upmargin</code> by default and convenience could trigger snapping the solution to this upper limit (see section <b>Even Lower Maximum Operational Limit of L-kurtosis</b>).
</p>
<pre>
  T4s &lt;- seq(0.8, 0.9, by=0.001) # sweeping through very high Tau4
  unit_std &lt;- 1/sqrt(pi)
  FF &lt;- pnorm(seq(-6, 6, by=0.01))
  plot(0,0, type="n", xlim=range(qnorm(FF)), ylim=c(-6, 6),
            xlab="Standard Normal Variate", ylab="Quantile")
  for(i in 1:length(T4s)) {
    lmr  &lt;- vec2lmom(c(0, unit_std, 0, T4s[i]))
    pdq4 &lt;- parpdq4(lmr, snapt4uplimit=FALSE)
    lmr4 &lt;- lmompdq4(pdq4)
    lines(qnorm(FF), quapdq4(FF, pdq4))
    err1 &lt;- theoLmoms(pdq4)$lambdas[2] - unit_std
    err2 &lt;-            lmr4$lambdas[2] - unit_std
    vals &lt;- c(T4s[i], pdq4$para[3], err1, err2)
    names(vals) &lt;- c("Tau4", "Kappa", "Err1(theoLmoms)", "Err2(lmompdq4)")
    print(vals) # both methods of Lambda2 estimation
  } # working and degenerates at Tau4 &gt;= 0.867, so use 0.866 as a margin
</pre>
<p>The problem geometrically is, as the <code class="reqn">\tau_4</code> becomes very &ldquo;large&rdquo;, that the distribution is become so peaked that its variation will be degenerating to zero, which is not compatible with the infinite limits of the distribution. Presumably beyond <code class="reqn">\tau_4 &gt;= 0.867</code>, the TL-moments could be used with further algorithmic development. There are other difficulties though in the next example as <code class="reqn">\tau_4</code> gets large.
</p>
<p><b>Even Lower Maximum Operational Limit of L-kurtosis</b>&mdash;Further study of the limits of maximum operational limit of <code class="reqn">\tau_4</code> can be made for reliable use of the basic internal functions of <span class="rlang"><b>R</b></span>. Consider the following code:
</p>
<pre>
  T4s &lt;- seq(0.4, 0.9, by=0.002)
  errs &lt;- vector(mode="numeric", length(T4s))
  for(i in 1:length(T4s)) {
    lmra &lt;- vec2lmom(c(0, 1, 0, T4s[i]))
    para &lt;- parpdq4(lmra, snapt4uplimit=FALSE)
    lmrb &lt;- lmompdq4(para)
    errs[i] &lt;- abs(lmra$lambdas[4] - lmrb$lambdas[4])/lmra$lambdas[4]
    print(c(T4s[i], errs[i], para$para[3]))
  }
  plot(T4s, errs, ylab="abs(Lambda4 - EstLambda4)/Lambda4", col="red")
  abline(v=0.845) # so use 0.845 as a lower margin
</pre>
<p>The <code class="reqn">\tau_4 &gt;= 0.845</code> is therefore a more defensive upper limit for operational purposes of the <span class="pkg">lmomco</span> package.
</p>
<p><b>Lower Limit Performance of L-kurtosis</b>&mdash;The lower limit of <code class="reqn">\tau_4 = -1/4</code> for the distribution is a statement of pure bimodality (two sides of a coin, as a matter of speaking). Visualization of the quantile function at the lower limit of <code class="reqn">\tau_4</code> in the recipe that follows shows this fact with two flat-line segments of solid red lines with the change over at right angles at standard normal variate of zero. Then the <code class="reqn">\tau_4</code> is nudged away from the lower limit just a little and replotted as the dashed line. Two other lines, but still for <code class="reqn">\tau_4 &lt; 0</code>, are shown in red and dark green. Finally, the demonstration ends with a magenta line for <code class="reqn">\tau_4 = 0</code>.
</p>
<pre>
  FF &lt;- pnorm(seq(-6, 6, by=0.01))
  plot(0,0, type="n", xlim=range(qnorm(FF)), ylim=c(-6, 6),
            xlab="Standard Normal Variate", ylab="Quantile")
  pdq4 &lt;- parpdq4(vec2lmom(c(0, 1/sqrt(pi), 0, -1/4     )))
  lines(qnorm(FF), quapdq4(FF, pdq4), col="red"   )
  pdq4 &lt;- parpdq4(vec2lmom(c(0, 1/sqrt(pi), 0, -1/4+0.03)))
  lines(qnorm(FF), quapdq4(FF, pdq4), col="red", lty=2) # dashed
  pdq4 &lt;- parpdq4(vec2lmom(c(0, 1/sqrt(pi), 0, -1/8     )))
  lines(qnorm(FF), quapdq4(FF, pdq4), col="darkgreen")
  pdq4 &lt;- parpdq4(vec2lmom(c(0, 1/sqrt(pi), 0, -1/16    )))
  lines(qnorm(FF), quapdq4(FF, pdq4), col="blue"   )
  pdq4 &lt;- parpdq4(vec2lmom(c(0, 1/sqrt(pi), 0, 0        )))
  lines(qnorm(FF), quapdq4(FF, pdq4), col="magenta")
</pre>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Hosking, J.R.M., 2007, Distributions with maximum entropy subject to constraints on their L-moments or expected order statistics: Journal of Statistical Planning and Inference, v. 137, no. 9, pp. 2870&ndash;2891, <a href="https://doi.org/10.1016/j.jspi.2006.10.010">doi:10.1016/j.jspi.2006.10.010</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lmompdq4">lmompdq4</a></code>, <code><a href="#topic+cdfpdq4">cdfpdq4</a></code>, <code><a href="#topic+pdfpdq4">pdfpdq4</a></code>, <code><a href="#topic+quapdq4">quapdq4</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Normal, Hosking (2007, p.2883)
para &lt;- list(para=c(0, 0.4332, -0.7029), type="pdq4")
parpdq4(lmompdq4(para))$para
# parameter reversion shown

para &lt;- list(para=c(0, 0.4332,  0.7029), type="pdq4")
parpdq4(lmompdq4(para))$para
# parameter reversion shown with sign change kappa

## Not run: 
  # other looks disabled for check --timings
  para &lt;- list(para=c(0, 0.4332, 0.97), type="pdq4")
  parpdq4(lmompdq4(para))$para
  # see now that alpha changing in fourth decimal as kappa
  # approaches the 0.98 threshold (see Note)

  # make two quick checks near zero and then zero
  para &lt;- list(para=c(0, 0.4332, +0.0001), type="pdq4")
  parpdq4(lmompdq4(para))$para
  para &lt;- list(para=c(0, 0.4332, -0.0001), type="pdq4")
  parpdq4(lmompdq4(para))$para
  para &lt;- list(para=c(0, 0.4332, 0), type="pdq4")
  parpdq4(lmompdq4(para))$para # 
## End(Not run)
</code></pre>

<hr>
<h2 id='parpe3'>Estimate the Parameters of the Pearson Type III Distribution</h2><span id='topic+parpe3'></span>

<h3>Description</h3>

<p>This function estimates the parameters of the Pearson Type III distribution given the L-moments of the data in an L-moment object such as that returned by <code><a href="#topic+lmoms">lmoms</a></code>. The L-moments in terms of the parameters are complicated and solved numerically. For the implementation in <span class="pkg">lmomco</span>, the three parameters are <code class="reqn">\mu</code>, <code class="reqn">\sigma</code>, and <code class="reqn">\gamma</code> for the mean, standard deviation, and skew, respectively.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>parpe3(lmom, checklmom=TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="parpe3_+3A_lmom">lmom</code></td>
<td>
<p>An L-moment object created by <code><a href="#topic+lmoms">lmoms</a></code> or <code><a href="#topic+vec2lmom">vec2lmom</a></code>.</p>
</td></tr>
<tr><td><code id="parpe3_+3A_checklmom">checklmom</code></td>
<td>
<p>Should the <code>lmom</code> be checked for validity using the <code><a href="#topic+are.lmom.valid">are.lmom.valid</a></code> function. Normally this should be left as the default and it is very unlikely that the L-moments will not be viable (particularly in the <code class="reqn">\tau_4</code> and <code class="reqn">\tau_3</code> inequality). However, for some circumstances or large simulation exercises then one might want to bypass this check.</p>
</td></tr>
<tr><td><code id="parpe3_+3A_...">...</code></td>
<td>
<p>Other arguments to pass.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> is returned.
</p>
<table>
<tr><td><code>type</code></td>
<td>
<p>The type of distribution: <code>pe3</code>.</p>
</td></tr>
<tr><td><code>para</code></td>
<td>
<p>The parameters of the distribution.</p>
</td></tr>
<tr><td><code>source</code></td>
<td>
<p>The source of the parameters: &ldquo;parpe3&rdquo;.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Hosking, J.R.M., 1990, L-moments&mdash;Analysis and estimation of distributions using linear combinations of order statistics: Journal of the Royal Statistical Society, Series B, v. 52, pp. 105&ndash;124.
</p>
<p>Hosking, J.R.M., 1996, FORTRAN routines for use with the method of L-moments: Version 3, IBM Research Report RC20525, T.J. Watson Research Center, Yorktown Heights, New York.
</p>
<p>Hosking, J.R.M., and Wallis, J.R., 1997, Regional frequency analysis&mdash;An approach based on L-moments: Cambridge University Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lmompe3">lmompe3</a></code>, <code><a href="#topic+cdfpe3">cdfpe3</a></code>, <code><a href="#topic+pdfpe3">pdfpe3</a></code>, <code><a href="#topic+quape3">quape3</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>lmr &lt;- lmoms(rnorm(20))
parpe3(lmr)
</code></pre>

<hr>
<h2 id='parray'>Estimate the Parameters of the Rayleigh Distribution</h2><span id='topic+parray'></span>

<h3>Description</h3>

<p>This function estimates the parameters of the Rayleigh distribution given the L-moments of the data in an L-moment object such as that returned by <code><a href="#topic+lmoms">lmoms</a></code>. The relations between distribution parameters and L-moments are
</p>
<p style="text-align: center;"><code class="reqn">\alpha = \frac{2\lambda_2\sqrt{\pi}}{\sqrt{2} - 1}\mbox{,}</code>
</p>

<p>and
</p>
<p style="text-align: center;"><code class="reqn">\xi = \lambda_1 - \alpha\sqrt{\pi/2}\mbox{.}</code>
</p>



<h3>Usage</h3>

<pre><code class='language-R'>parray(lmom, xi=NULL, checklmom=TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="parray_+3A_lmom">lmom</code></td>
<td>
<p>An L-moment object created by <code><a href="#topic+lmoms">lmoms</a></code> or <code><a href="#topic+vec2lmom">vec2lmom</a></code>.</p>
</td></tr>
<tr><td><code id="parray_+3A_xi">xi</code></td>
<td>
<p>The lower limit of the distribution. If <code class="reqn">\xi</code> is known then alternative algorithms are triggered and only the first L-moment is required for fitting.</p>
</td></tr>
<tr><td><code id="parray_+3A_checklmom">checklmom</code></td>
<td>
<p>Should the <code>lmom</code> be checked for validity using the <code><a href="#topic+are.lmom.valid">are.lmom.valid</a>
</code> function. Normally this should be left as the default and it is very unlikely that the L-moments will not be viable (particularly in the <code class="reqn">\tau_4</code> and <code class="reqn">\tau_3</code> inequality). However, for some circumstances or large simulation exercises then one might want to bypass this check.</p>
</td></tr>
<tr><td><code id="parray_+3A_...">...</code></td>
<td>
<p>Other arguments to pass.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> is returned.
</p>
<table>
<tr><td><code>type</code></td>
<td>
<p>The type of distribution: <code>ray</code>.</p>
</td></tr>
<tr><td><code>para</code></td>
<td>
<p>The parameters of the distribution.</p>
</td></tr>
<tr><td><code>source</code></td>
<td>
<p>The source of the parameters: &ldquo;parray&rdquo;.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Hosking, J.R.M., 1986, The theory of probability weighted moments: Research Report RC12210, IBM Research Division, Yorkton Heights, N.Y.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lmomray">lmomray</a></code>,
<code><a href="#topic+cdfray">cdfray</a></code>, <code><a href="#topic+pdfray">pdfray</a></code>, <code><a href="#topic+quaray">quaray</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>lmr &lt;- lmoms(rnorm(20))
parray(lmr)
</code></pre>

<hr>
<h2 id='parrevgum'>Estimate the Parameters of the Reverse Gumbel Distribution</h2><span id='topic+parrevgum'></span>

<h3>Description</h3>

<p>This function estimates the parameters of the Reverse Gumbel distribution given the type-B L-moments of the data in an L-moment object such as that returned by
<code><a href="#topic+pwmRC">pwmRC</a></code> using <code><a href="#topic+pwm2lmom">pwm2lmom</a></code>. This distribution is important in the analysis of censored data. It is the distribution of a logarithmically transformed 2-parameter Weibull distribution. The relations between distribution parameters and L-moments are
</p>
<p style="text-align: center;"><code class="reqn">\alpha = \lambda^B_2/\lbrace\log(2) + \mathrm{Ei}(-2\log(1-\zeta)) - \mathrm{Ei}(-\log(1-\zeta))\rbrace</code>
</p>

<p>and
</p>
<p style="text-align: center;"><code class="reqn">\xi = \lambda^B_1 + \alpha\lbrace\mathrm{Ei}(-\log(1-\zeta))\rbrace\mbox{,}</code>
</p>

<p>where <code class="reqn">\zeta</code> is the compliment of the right-tail censoring fraction of the sample or the nonexceedance probability of the right-tail censoring threshold, and <code class="reqn">\mathrm{Ei}(x)</code> is the exponential integral defined as
</p>
<p style="text-align: center;"><code class="reqn"> \mathrm{Ei}(X) = \int_X^{\infty} x^{-1}e^{-x}\mathrm{d}x \mbox{,}</code>
</p>

<p>where <code class="reqn">\mathrm{Ei}(-\log(1-\zeta)) \rightarrow 0</code> as <code class="reqn">\zeta \rightarrow 1</code> and <code class="reqn">\mathrm{Ei}(-\log(1-\zeta))</code> can not be evaluated as <code class="reqn">\zeta \rightarrow 0</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>parrevgum(lmom, zeta=1, checklmom=TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="parrevgum_+3A_lmom">lmom</code></td>
<td>
<p>An L-moment object created by <code><a href="#topic+lmoms">lmoms</a></code> through <code><a href="#topic+pwmRC">pwmRC</a></code> or other L-moment type object. The user intervention of the <code>zeta</code> differentiates this distribution (and this function) from similar parameter estimation functions in the <span class="pkg">lmomco</span> package.</p>
</td></tr>
<tr><td><code id="parrevgum_+3A_zeta">zeta</code></td>
<td>
<p>The compliment of the right censoring fraction. Number of samples observed (noncensored) divided by the total number of samples.</p>
</td></tr>
<tr><td><code id="parrevgum_+3A_checklmom">checklmom</code></td>
<td>
<p>Should the <code>lmom</code> be checked for validity using the <code><a href="#topic+are.lmom.valid">are.lmom.valid</a></code> function. Normally this should be left as the default and it is very unlikely that the L-moments will not be viable (particularly in the <code class="reqn">\tau_4</code> and <code class="reqn">\tau_3</code> inequality). However, for some circumstances or large simulation exercises then one might want to bypass this check.</p>
</td></tr>
<tr><td><code id="parrevgum_+3A_...">...</code></td>
<td>
<p>Other arguments to pass.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> is returned.
</p>
<table>
<tr><td><code>type</code></td>
<td>
<p>The type of distribution: <code>revgum</code>.</p>
</td></tr>
<tr><td><code>para</code></td>
<td>
<p>The parameters of the distribution.</p>
</td></tr>
<tr><td><code>zeta</code></td>
<td>
<p>The compliment of the right censoring fraction. Number of samples observed (noncensored) divided by the total number of samples.</p>
</td></tr>
<tr><td><code>source</code></td>
<td>
<p>The source of the parameters: &ldquo;parrevgum&rdquo;.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Hosking, J.R.M., 1995, The use of L-moments in the analysis of censored data, in Recent Advances in Life-Testing and Reliability, edited by N. Balakrishnan, chapter 29, CRC Press, Boca Raton, Fla., pp. 546&ndash;560.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lmomrevgum">lmomrevgum</a></code>,
<code><a href="#topic+cdfrevgum">cdfrevgum</a></code>, <code><a href="#topic+pdfrevgum">pdfrevgum</a></code>, <code><a href="#topic+quarevgum">quarevgum</a></code>, <code><a href="#topic+pwm2lmom">pwm2lmom</a></code>, <code><a href="#topic+pwmRC">pwmRC</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># See p. 553 of Hosking (1995)
# Data listed in Hosking (1995, table 29.3, p. 553)
D &lt;- c(-2.982, -2.849, -2.546, -2.350, -1.983, -1.492, -1.443,
       -1.394, -1.386, -1.269, -1.195, -1.174, -0.854, -0.620,
       -0.576, -0.548, -0.247, -0.195, -0.056, -0.013,  0.006,
        0.033,  0.037,  0.046,  0.084,  0.221,  0.245,  0.296)
D &lt;- c(D,rep(.2960001,40-28)) # 28 values, but Hosking mentions
                              # 40 values in total
z &lt;-  pwmRC(D,threshold=.2960001)
str(z)
# Hosking reports B-type L-moments for this sample are
# lamB1 = -.516 and lamB2 = 0.523
btypelmoms &lt;- pwm2lmom(z$Bbetas)
# My version of R reports lamB1 = -0.5162 and lamB2 = 0.5218
str(btypelmoms)
rg.pars &lt;- parrevgum(btypelmoms,z$zeta)
str(rg.pars)
# Hosking reports xi = 0.1636 and alpha = 0.9252 for the sample
# My version of R reports xi = 0.1635 and alpha = 0.9254
</code></pre>

<hr>
<h2 id='parrice'>Estimate the Parameters of the Rice Distribution</h2><span id='topic+parrice'></span>

<h3>Description</h3>

<p>This function estimates the parameters (<code class="reqn">\nu</code> and <code class="reqn">\alpha</code>) of the Rice distribution given the L-moments of the data in an L-moment object such as that returned by <code><a href="#topic+lmoms">lmoms</a></code>. The relations between distribution parameters and L-moments are complex and tabular lookup is made using a relation between <code class="reqn">\tau</code> and a form of signal-to-noise ratio <code class="reqn">\mathrm{SNR}</code> defined as <code class="reqn">\nu/\alpha</code> and a relation between <code class="reqn">\tau</code> and precomputed Laguerre polynomial (<code><a href="#topic+LaguerreHalf">LaguerreHalf</a></code>).
</p>
<p>The <code class="reqn">\lambda_1</code> (mean) is most straightforward
</p>
<p style="text-align: center;"><code class="reqn">
\lambda_1 = \alpha \times \sqrt{\pi/2} \times L_{1/2}(-\nu^2/[2\alpha^2])\mbox{,}
</code>
</p>

<p>for which the terms to the right of the multiplication symbol are uniquely a function of <code class="reqn">\tau</code> and precomputed for tabular lookup and interpolation from &lsquo;<span class="file">sysdata.rdb</span>&rsquo; (<span class="env">.lmomcohash$RiceTable</span>). Parameter estimation also relies directly on tabular lookup and interpolation to convert <code class="reqn">\tau</code> to <code class="reqn">\mathrm{SNR}</code>. The file &lsquo;<span class="file">SysDataBuilder01.R</span>&rsquo; provides additional technical details.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>parrice(lmom, checklmom=TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="parrice_+3A_lmom">lmom</code></td>
<td>
<p>An L-moment object created by <code><a href="#topic+lmoms">lmoms</a></code> or <code><a href="#topic+vec2lmom">vec2lmom</a></code>.</p>
</td></tr>
<tr><td><code id="parrice_+3A_checklmom">checklmom</code></td>
<td>
<p>Should the <code>lmom</code> be checked for validity using the <code><a href="#topic+are.lmom.valid">are.lmom.valid</a></code> function. Normally this should be left as the default and it is very unlikely that the L-moments will not be viable (particularly in the <code class="reqn">\tau_4</code> and <code class="reqn">\tau_3</code> inequality). However, for some circumstances or large simulation exercises then one might want to bypass this check. However, the end point of the Rice distribution for high <code class="reqn">\nu/\alpha</code> is not determined here, so it is recommended to leave <code>checklmom</code> turned on.</p>
</td></tr>
<tr><td><code id="parrice_+3A_...">...</code></td>
<td>
<p>Other arguments to pass.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> is returned.
</p>
<table>
<tr><td><code>type</code></td>
<td>
<p>The type of distribution: <code>rice</code>.</p>
</td></tr>
<tr><td><code>para</code></td>
<td>
<p>The parameters of the distribution.</p>
</td></tr>
<tr><td><code>source</code></td>
<td>
<p>The source of the parameters: &ldquo;parrice&rdquo;.</p>
</td></tr>
<tr><td><code>ifail</code></td>
<td>
<p>A numeric failure mode.</p>
</td></tr>
<tr><td><code>ifailtext</code></td>
<td>
<p>A helpful message on the failure.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Asquith, W.H., 2011, Distributional analysis with L-moment statistics using the R environment for statistical computing: Createspace Independent Publishing Platform, ISBN 978&ndash;146350841&ndash;8.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lmomrice">lmomrice</a></code>, <code><a href="#topic+cdfrice">cdfrice</a></code>, <code><a href="#topic+pdfrice">pdfrice</a></code>, <code><a href="#topic+quarice">quarice</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
  parrice(lmomrice(vec2par(c(10,50),   type="rice"))) # Within Rician limits
  parrice(lmomrice(vec2par(c(100,0.1), type="rice"))) # Beyond Rician limits

plotlmrdia(lmrdia(), xlim=c(0,0.2), ylim=c(-0.1,0.22),
           autolegend=TRUE, xleg=0.05, yleg=0.05)
lines(.lmomcohash$RiceTable$TAU3, .lmomcohash$RiceTable$TAU4, lwd=5, col=8)
legend(0.1,0, "RICE DISTRIBUTION", lwd=5, col=8, bty="n")
text(0.14, -0.04,  "Normal distribution limit on left end point"   )
text(0.14, -0.055, "Rayleigh distribution limit on right end point")

# check parrice against a Maximum Likelihood method in VGAM
set.seed(1)
library(VGAM) # now example from riceff() of VGAM
vee &lt;- exp(2); sigma &lt;- exp(1); y &lt;- rrice(n &lt;- 1000, vee, sigma)
fit &lt;- vglm(y ~ 1, riceff, trace=TRUE, crit="c")
Coef(fit)
# NOW THE MOMENT OF TRUTH, USING L-MOMENTS
parrice(lmoms(y))
# VGAM package 0.8-1 reports
#     vee    sigma
# 7.344560 2.805877
# lmomco 1.2.2 reports
#      nu    alpha
# 7.348784 2.797651
## End(Not run)
</code></pre>

<hr>
<h2 id='pars2x'>Estimate Quantiles from an Ensemble of Parameters</h2><span id='topic+pars2x'></span>

<h3>Description</h3>

<p>This function acts as a frontend to estimate quantiles from an ensemble of parameters from the methods of L-moments (<code><a href="#topic+lmr2par">lmr2par</a></code>), maximum likelihood (MLE, <code><a href="#topic+mle2par">mle2par</a></code>), and maximum product of spacings (MPS, <code><a href="#topic+mps2par">mps2par</a></code>) for nonexceedance probabilities. The mean, standard deviation, and number of unique quantiles for each nonexceedance probability are computed too. The unique quantiles are used because the MLE and MPS methods could fall back to L-moments or other and thus it should be considered that one of the methods might have failed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pars2x(f, paras, na.rm=FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pars2x_+3A_f">f</code></td>
<td>
<p>Nonexceedance probability (<code class="reqn">0 \le F \le 1</code>).</p>
</td></tr>
<tr><td><code id="pars2x_+3A_paras">paras</code></td>
<td>
<p>An ensemble of parameters from <code><a href="#topic+x2pars">x2pars</a></code>.</p>
</td></tr>
<tr><td><code id="pars2x_+3A_na.rm">na.rm</code></td>
<td>
<p>A logical to pass to the mean and standard deviation computations.</p>
</td></tr>
<tr><td><code id="pars2x_+3A_...">...</code></td>
<td>
<p>The additional arguments, if ever used.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code>data.frame</code> having, if at least one of the parameter estimation methods is not <code>NULL</code>, the following columns in addition to attributes that are demonstrated in the <b>Examples</b> section:
</p>
<table>
<tr><td><code>lmr</code></td>
<td>
<p>Quantiles based on parameters from method of L-moments.</p>
</td></tr>
<tr><td><code>mle</code></td>
<td>
<p>Quantiles based on parameters from MLE.</p>
</td></tr>
<tr><td><code>mps</code></td>
<td>
<p>Quantiles based on parameters from MPS.</p>
</td></tr>
<tr><td><code>f</code></td>
<td>
<p>The nonexceedance probabilities.</p>
</td></tr>
<tr><td><code>mean</code></td>
<td>
<p>The mean of the unique quantiles (usually three) seen for each probability. Results can be affected by <code>na.rm</code>.</p>
</td></tr>
<tr><td><code>sd</code></td>
<td>
<p>The standard deviation of the unique quantiles (usually three) seen for each probability. Results can be affected by <code>na.rm</code>.</p>
</td></tr>
<tr><td><code>n</code></td>
<td>
<p>The number of unique quantiles (usually three) seen for each probability and quantiles computed as <code>NA</code> are not counted.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>See Also</h3>

<p><code><a href="#topic+x2pars">x2pars</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Simulate from GLO and refit it. Occasionally, the simulated data
# will result in MLE or MPS failing to converge, just a note to users.
# This example also shows the use of the attributes of the Results.
set.seed(3237)
x &lt;- rlmomco(32, vec2par(c(2.5, 0.7, -0.39), type="glo"))
three.para.est &lt;- x2pars(x, type="glo")
FF &lt;- nonexceeds() # a range in nonexceedance probabilities
# In the event of MLE or MPS failure, one will see NA's in the Results.
Results &lt;- pars2x(FF, three.para.est, na.rm=FALSE)
sum &lt;- attr(Results, "all.summary")
plot(pp(x), sort(x), type="n", ylim=range(sum), log="y")
polygon(attr(Results, "f.poly"), attr(Results, "x.poly"), col=8, lty=0)
points(pp(x), sort(x), col=3)
lines(Results$f, Results$lmr,  col=1) # black line
lines(Results$f, Results$mle,  col=2) # red   line
lines(Results$f, Results$mps,  col=4) # blue  line
lines(Results$f, Results$mean, col=6, lty=2, lwd=2) # purple mean # 
## End(Not run)
</code></pre>

<hr>
<h2 id='parsla'>Estimate the Parameters of the Slash Distribution</h2><span id='topic+parsla'></span>

<h3>Description</h3>

<p>This function estimates the parameters of the Slash distribution from the trimmed L-moments (TL-moments) having trim level 1. The relations between distribution parameters and TL-moments are shown under <code><a href="#topic+lmomsla">lmomsla</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>parsla(lmom, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="parsla_+3A_lmom">lmom</code></td>
<td>
<p>A TL-moment object from <code><a href="#topic+TLmoms">TLmoms</a></code> with <code>trim=1</code>.</p>
</td></tr>
<tr><td><code id="parsla_+3A_...">...</code></td>
<td>
<p>Other arguments to pass.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> is returned.
</p>
<table>
<tr><td><code>type</code></td>
<td>
<p>The type of distribution: <code>sla</code>.</p>
</td></tr>
<tr><td><code>para</code></td>
<td>
<p>The parameters of the distribution.</p>
</td></tr>
<tr><td><code>source</code></td>
<td>
<p>The source of the parameters: &ldquo;parsla&rdquo;.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Rogers, W.H., and Tukey, J.W., 1972, Understanding some long-tailed symmetrical distributions: Statistica Neerlandica, v. 26, no. 3, pp. 211&ndash;226.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+TLmoms">TLmoms</a></code>, <code><a href="#topic+lmomsla">lmomsla</a></code>, <code><a href="#topic+cdfsla">cdfsla</a></code>, <code><a href="#topic+pdfsla">pdfsla</a></code>, <code><a href="#topic+quasla">quasla</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
par1 &lt;- vec2par(c(-100, 30), type="sla")
X   &lt;- rlmomco(500, par1)
lmr &lt;- TLmoms(X, trim=1)
par2 &lt;- parsla(lmr)
F &lt;- seq(0.001,.999, by=0.001)
plot(qnorm(pp(X)), sort(X), pch=21, col=8,
     xlab="STANDARD NORMAL VARIATE",
     ylab="QUANTILE")
lines(qnorm(F), quasla(F, par1), lwd=3)
lines(qnorm(F), quasla(F, par2), col=2)

## End(Not run)
</code></pre>

<hr>
<h2 id='parsmd'>Estimate the Parameters of the Singh&ndash;Maddala Distribution</h2><span id='topic+parsmd'></span>

<h3>Description</h3>

<p>This function estimates the parameters of the Singh&ndash;Maddala (Burr Type XII) distribution given the L-moments of the data in an L-moment object such as that returned by <code><a href="#topic+lmoms">lmoms</a></code>. The L-moments in terms of the parameters are complicated and solved numerically. Extensive study of the computational limits of the <span class="rlang"><b>R</b></span> implementation are incorporated within the source code of the function. The file <code>lmomco/inst/doc/domain_of_smd.R</code> contains the algorithmic sweep used to compute the L-skew and L-kurtosis attainable domain of the distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>parsmd(lmom, checklmom=TRUE, checkbounds=TRUE, snap.tau4=TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="parsmd_+3A_lmom">lmom</code></td>
<td>
<p>An L-moment object created by <code><a href="#topic+lmoms">lmoms</a></code> or <code><a href="#topic+vec2lmom">vec2lmom</a></code>.</p>
</td></tr>
<tr><td><code id="parsmd_+3A_checklmom">checklmom</code></td>
<td>
<p>Should the <code>lmom</code> be checked for validity using the <code><a href="#topic+are.lmom.valid">are.lmom.valid</a></code> function. Normally this should be left as the default and it is very unlikely that the L-moments will not be viable (particularly in the <code class="reqn">\tau_3</code> and <code class="reqn">\tau_4</code> inequality, <br /> <code><a href="#topic+are.lmom.valid">are.lmom.valid</a></code>). However, for some circumstances or large simulation exercises then one might want to bypass this check.</p>
</td></tr>
<tr><td><code id="parsmd_+3A_checkbounds">checkbounds</code></td>
<td>
<p>Should the lower bounds of <code class="reqn">\tau_4</code> be verified and if sample <code class="reqn">\hat\tau_3</code> and <code class="reqn">\hat\tau_4</code> are outside of these bounds, then <code>NA</code> are returned for the solutions.</p>
</td></tr>
<tr><td><code id="parsmd_+3A_snap.tau4">snap.tau4</code></td>
<td>
<p>A logical to trigger the application of the empirical limits of the distribution in terms of <code class="reqn">\tau_3</code> and <code class="reqn">\tau_4</code> wherein parameter estimation appears numerically possible and such parameters return the given values of these L-moment ratios. The lower and upper limits of <code class="reqn">\tau_4</code> are defined by separate polynomials as functions of <code class="reqn">\tau_3</code>. If the logical is true, then <code class="reqn">\tau_4</code> in excess of the upper bounds are assigned to the upper bounds and <code class="reqn">\tau_4</code> in deficit of the lower bounds are assigned to the lower bounds. Messages within the returned parameter object are provided if the snapping occurs.</p>
</td></tr>
<tr><td><code id="parsmd_+3A_...">...</code></td>
<td>
<p>Other arguments to pass.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> is returned.
</p>
<table>
<tr><td><code>type</code></td>
<td>
<p>The type of distribution: <code>smd</code>.</p>
</td></tr>
<tr><td><code>para</code></td>
<td>
<p>The parameters of the distribution.</p>
</td></tr>
<tr><td><code>last_para</code></td>
<td>
<p>The last or final iteration of the parameters that are the same as <code>para</code> if <code>ifail</code> is zero. This provides a way to preserve where the parameter left off or gave up.</p>
</td></tr>
<tr><td><code>source</code></td>
<td>
<p>The source of the parameters: &ldquo;parsmd&rdquo;.</p>
</td></tr>
<tr><td><code>iter</code></td>
<td>
<p>The number of iteration attempts looping on the <code>optim()</code> call.</p>
</td></tr>
<tr><td><code>rt</code></td>
<td>
<p>The output of the <code>optim()</code> call.</p>
</td></tr>
<tr><td><code>message</code></td>
<td>
<p>A message from <code>parsmd</code>, which generally involves <code>checkbounds=TRUE</code> and <br /><code>snap.tau4=TRUE</code> on the resetting or snapping of the <code class="reqn">\tau_3</code> and <code class="reqn">\tau_4</code> to the computational bounds for the distribution.</p>
</td></tr>
<tr><td><code>ifail</code></td>
<td>
<p>A interger flag to status of the operations: -1 means that the L-moments are invalid (if they are checked), 0 means that the parameter estimation appears successful, and 1 means that the parameter estimation appears to have failed.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Shahzad, M.N., and Zahid, A., 2013, Parameter estimation of Singh Maddala distribution by moments: International Journal of Advanced Statistics and Probability, v. 1, no. 3, pp. 121&ndash;131, <a href="https://doi.org/10.14419/ijasp.v1i3.1206">doi:10.14419/ijasp.v1i3.1206</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lmomsmd">lmomsmd</a></code>, <code><a href="#topic+cdfsmd">cdfsmd</a></code>, <code><a href="#topic+pdfsmd">pdfsmd</a></code>, <code><a href="#topic+quasmd">quasmd</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>lmr &lt;- lmoms(rnorm(20))
parsmd(lmr, snap.tau4=TRUE)
</code></pre>

<hr>
<h2 id='parst3'>Estimate the Parameters of the 3-Parameter Student t Distribution</h2><span id='topic+parst3'></span>

<h3>Description</h3>

<p>This function estimates the parameters of the 3-parameter Student t distribution given the L-moments of the data in an L-moment object such as that returned by <code><a href="#topic+lmoms">lmoms</a></code>. The relations between distribution parameters and L-moments are seen under <code><a href="#topic+lmomst3">lmomst3</a></code>. The largest value of <code class="reqn">\nu</code> recognized is <code class="reqn">10^5.5</code>, which is the near the Normal distribution and the smallest value recognized is <code class="reqn">1.001</code>, which is near the Cauchy. As <code class="reqn">\nu \rightarrow 1</code> the distribution limits to the Cauchy, but the implementation here does not switch over to the Cauchy. Therefore in <span class="pkg">lmomco</span> <code class="reqn">1.001 \le \nu \le 10^5.5</code>. The <code class="reqn">\nu</code> is the &ldquo;degrees of freedom&rdquo; parameter that is well-known with the 1-parameter Student t distribution. The <code class="reqn">nu</code> limits are studied in the <code>inst/doc/t4t6/studyST3.R</code> script and the <code><a href="#topic+theoTLmoms">theoTLmoms</a></code> function and its performance on the quantile function of the distribution provide the guidance including range of numerically computable <code class="reqn">\tau_6</code>. The <code class="reqn">\tau_4</code> value can be set as low as <code class="reqn">0.1226</code> as short-hand for the true lower L-kurtosis limit, which is that of the Normal (<code class="reqn">30/\pi \times \mathrm{atan}(\sqrt{2}) - 9 = 0.1226017</code> and additional decimals). Internally, the given <code class="reqn">0.1226 \le \tau_4 \le 0.1226017</code> is snapped to that of the Normal with an internal small positive nudge up. The <code class="reqn">\tau_4 &gt; 0.998</code> are set to <code class="reqn">\tau_4 = 0.998</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>parst3(lmom, checklmom=TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="parst3_+3A_lmom">lmom</code></td>
<td>
<p>An L-moment object created by <code><a href="#topic+lmoms">lmoms</a></code> or <code><a href="#topic+vec2lmom">vec2lmom</a></code>.</p>
</td></tr>
<tr><td><code id="parst3_+3A_checklmom">checklmom</code></td>
<td>
<p>Should the <code>lmom</code> be checked for validity using the <code><a href="#topic+are.lmom.valid">are.lmom.valid</a></code> function. Normally this should be left as the default and it is very unlikely that the L-moments will not be viable (particularly in the <code class="reqn">\tau_4</code> and <code class="reqn">\tau_3</code> inequality). However, for some circumstances or large simulation exercises then one might want to bypass this check.</p>
</td></tr>
<tr><td><code id="parst3_+3A_...">...</code></td>
<td>
<p>Other arguments to pass.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> is returned.
</p>
<table>
<tr><td><code>type</code></td>
<td>
<p>The type of distribution: <code>st3</code>.</p>
</td></tr>
<tr><td><code>para</code></td>
<td>
<p>The parameters of the distribution.</p>
</td></tr>
<tr><td><code>rt</code></td>
<td>
<p>The returned list of the <code>uniroot()</code> call to estimate <code class="reqn">\nu</code>.</p>
</td></tr>
<tr><td><code>source</code></td>
<td>
<p>The source of the parameters: &ldquo;parst3&rdquo;.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Asquith, W.H., 2011, Distributional analysis with L-moment statistics using the R environment for statistical computing: Createspace Independent Publishing Platform, ISBN 978&ndash;146350841&ndash;8.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lmomst3">lmomst3</a></code>, <code><a href="#topic+cdfst3">cdfst3</a></code>, <code><a href="#topic+pdfst3">pdfst3</a></code>, <code><a href="#topic+quast3">quast3</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  parst3(vec2lmom(c(10, 2, 0, 0.1226)))$para
  parst3(vec2lmom(c(10, 2, 0, 0.14  )))$para
  parst3(vec2lmom(c(10, 2, 0, 0.4   )))$para
  parst3(vec2lmom(c(10, 2, 0, 0.9   )))$para
  parst3(vec2lmom(c(10, 2, 0, 0.998 )))$para
</code></pre>

<hr>
<h2 id='partexp'>Estimate the Parameters of the Truncated Exponential Distribution</h2><span id='topic+partexp'></span>

<h3>Description</h3>

<p>This function estimates the parameters of the Truncated Exponential distribution given
the L-moments of the data in an L-moment object such as that returned by <code><a href="#topic+lmoms">lmoms</a></code>. The parameter <code class="reqn">\psi</code> is the right truncation of the distribution, and <code class="reqn">\alpha</code> is a scale parameter, letting <code class="reqn">\beta = 1/\alpha</code> to match nomenclature of Vogel and others (2008), and recalling the L-moments in terms of the parameters and letting <code class="reqn">\eta = \exp(-\beta\psi)</code> are
</p>
<p style="text-align: center;"><code class="reqn">\lambda_1 = \frac{1 - \eta + \eta\log(\eta)}{\beta(1-\eta)}\mbox{,}</code>
</p>

<p style="text-align: center;"><code class="reqn">\lambda_2 = \frac{1 + 2\eta\log(\eta) - \eta^2}{2\beta(1-\eta)^2}\mbox{, and}</code>
</p>

<p style="text-align: center;"><code class="reqn">\tau_2 = \frac{\lambda_2}{\lambda_1} = \frac{1 + 2\eta\log(\eta) - \eta^2}{2(1-\eta)[1-\eta+\eta\log(\eta)]}\mbox{,}</code>
</p>

<p>and <code class="reqn">\tau_2</code> is a monotonic function of <code class="reqn">\eta</code> is decreasing from <code class="reqn">\tau_2 = 1/2</code> at <code class="reqn">\eta = 0</code> to <code class="reqn">\tau_2 = 1/3</code> at <code class="reqn">\eta = 1</code> the parameters are readily solved given <code class="reqn">\tau_2 = [1/3, 1/2]</code>, the <span class="rlang"><b>R</b></span> function <code>uniroot</code>  can be used to solve for <code class="reqn">\eta</code> with a starting interval of <code class="reqn">(0, 1)</code>, then the parameters in terms of the parameters are
</p>
<p style="text-align: center;"><code class="reqn">\alpha = \frac{1 - \eta + \eta\log(\eta)}{(1 - \eta)\lambda_1}\mbox{, and}</code>
</p>

<p style="text-align: center;"><code class="reqn">\psi = -\log(\eta)/\alpha\mbox{.}</code>
</p>

<p>If the <code class="reqn">\eta</code> is rooted as equaling zero, then it is assumed that <code class="reqn">\hat\tau_2 \equiv \tau_2</code> and the exponential distribution triggered, or if the <code class="reqn">\eta</code> is rooted as equaling unity, then it is assumed that <code class="reqn">\hat\tau_2 \equiv \tau_2</code> and the uniform distribution triggered (see below).
</p>
<p>The distribution is restricted to a narrow range of L-CV (<code class="reqn">\tau_2 = \lambda_2/\lambda_1</code>). If <code class="reqn">\tau_2 = 1/3</code>, the process represented is a stationary Poisson for which the probability density function is simply the uniform distribution and <code class="reqn">f(x) = 1/\psi</code>. If <code class="reqn">\tau_2 = 1/2</code>, then the distribution is represented as the usual exponential distribution with a location parameter of zero and a scale parameter <code class="reqn">1/\beta</code>. Both of these limiting conditions are supported.
</p>
<p>If the distribution shows to be uniform (<code class="reqn">\tau_2 = 1/3</code>), then the third element in the returned parameter vector is used as the <code class="reqn">\psi</code> parameter for the uniform distribution, and the first and second elements are <code>NA</code> of the returned parameter vector.
</p>
<p>If the distribution shows to be exponential (<code class="reqn">\tau_2 = 1/2</code>), then the second element in the returned parameter vector is the inverse of the rate parameter for the exponential distribution, and the first element is <code>NA</code> and the third element is <code>0</code> (a numeric <code>FALSE</code>) of the returned parameter vector.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>partexp(lmom, checklmom=TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="partexp_+3A_lmom">lmom</code></td>
<td>
<p>An L-moment object created by <code><a href="#topic+lmoms">lmoms</a></code> or
<code><a href="#topic+vec2lmom">vec2lmom</a></code>.</p>
</td></tr>
<tr><td><code id="partexp_+3A_checklmom">checklmom</code></td>
<td>
<p>Should the <code>lmom</code> be checked for validity using the <code><a href="#topic+are.lmom.valid">are.lmom.valid</a></code> function. Normally this should be left as the default and it is very unlikely that the L-moments will not be viable (particularly in the <code class="reqn">\tau_4</code> and <code class="reqn">\tau_3</code> inequality). However, for some circumstances or large simulation exercises then one might want to bypass this check.</p>
</td></tr>
<tr><td><code id="partexp_+3A_...">...</code></td>
<td>
<p>Other arguments to pass.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> is returned.
</p>
<table>
<tr><td><code>type</code></td>
<td>
<p>The type of distribution: <code>texp</code>.</p>
</td></tr>
<tr><td><code>para</code></td>
<td>
<p>The parameters of the distribution.</p>
</td></tr>
<tr><td><code>ifail</code></td>
<td>
<p>A logical value expressed in numeric form indicating the failure or success state of the parameter estimation. A value of two indicates that the <code class="reqn">\tau_2 &lt; 1/3</code> whereas a value of three indicates that the <code class="reqn">\tau_2 &gt; 1/2</code>; for each of these inequalities a fuzzy tolerance of one part in one million is used. Successful parameter estimation, which includes the uniform and exponential boundaries, is indicated by a value of zero.</p>
</td></tr>
<tr><td><code>ifail.message</code></td>
<td>
<p>Various messages for successful and failed parameter estimations are reported. In particular, there are two conditions for which each distributional boundary (uniform or exponential) can be obtained. First, for the uniform distribution, one message would indicate if the <code class="reqn">\tau_2 = 1/3</code> is assumed within a one part in one million will be identified or if <code class="reqn">\eta</code> is rooted to 1. Second, for the exponential distribution, one message would indicate if the <code class="reqn">\tau_2 = 1/2</code> is assumed within a one part in one million will be identified or if <code class="reqn">\eta</code> is rooted to 0.</p>
</td></tr>
<tr><td><code>eta</code></td>
<td>
<p>The value for <code class="reqn">\eta</code>. The value is set to either unity or zero if the <code class="reqn">\tau_2</code> fuzzy tests as being equal to 1/3 or 1/2, respectively. The value is set to the rooted value of <code class="reqn">\eta</code> for all other valid solutions. The value is set to <code>NA</code> if <code class="reqn">\tau_2</code> tests as being outside the 1/3 and 1/2 limits.</p>
</td></tr>
<tr><td><code>source</code></td>
<td>
<p>The source of the parameters: &ldquo;partexp&rdquo;.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Vogel, R.M., Hosking, J.R.M., Elphick, C.S., Roberts, D.L., and Reed, J.M., 2008, Goodness of fit of probability distributions for sightings as species approach extinction: Bulletin of Mathematical Biology, DOI 10.1007/s11538-008-9377-3, 19 p.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lmomtexp">lmomtexp</a></code>, <code><a href="#topic+cdftexp">cdftexp</a></code>, <code><a href="#topic+pdftexp">pdftexp</a></code>, <code><a href="#topic+quatexp">quatexp</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># truncated exponential is a nonstationary poisson process
A  &lt;- partexp(vec2lmom(c(100, 1/2),   lscale=FALSE)) # pure exponential
B  &lt;- partexp(vec2lmom(c(100, 0.499), lscale=FALSE)) # almost exponential
BB &lt;- partexp(vec2lmom(c(100, 0.45),  lscale=FALSE)) # truncated exponential
C  &lt;- partexp(vec2lmom(c(100, 1/3),   lscale=FALSE)) # stationary poisson process
D  &lt;- partexp(vec2lmom(c(100, 40))) # truncated exponential
</code></pre>

<hr>
<h2 id='parTLgld'>Estimate the Parameters of the Generalized Lambda Distribution using Trimmed L-moments (t=1)</h2><span id='topic+parTLgld'></span>

<h3>Description</h3>

<p>This function estimates the parameters of the Generalized Lambda distribution given the trimmed L-moments (TL-moments) for <code class="reqn">t=1</code> of the data in a TL-moment object with a trim level of unity (<code>trim=1</code>). The relations between distribution parameters and TL-moments are seen under <code><a href="#topic+lmomTLgld">lmomTLgld</a></code>. There are no simple expressions for the parameters in terms of the L-moments. Consider that multiple parameter solutions are possible with the Generalized Lambda distribution so some expertise with this distribution and other aspects is advised.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>parTLgld(lmom, verbose=FALSE, initkh=NULL, eps=1e-3,
         aux=c("tau5", "tau6"), checklmom=TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="parTLgld_+3A_lmom">lmom</code></td>
<td>
<p>A TL-moment object created by <code><a href="#topic+TLmoms">TLmoms</a></code>.</p>
</td></tr>
<tr><td><code id="parTLgld_+3A_verbose">verbose</code></td>
<td>
<p>A logical switch on the verbosity of output.  Default is <code>verbose=FALSE</code>.</p>
</td></tr>
<tr><td><code id="parTLgld_+3A_initkh">initkh</code></td>
<td>
<p>A vector of the initial guess of the <code class="reqn">\kappa</code> and <code class="reqn">h</code> parameters. No other regions of parameter space are consulted.</p>
</td></tr>
<tr><td><code id="parTLgld_+3A_eps">eps</code></td>
<td>
<p>A small term or threshold for which the square root of the sum of square errors in <code class="reqn">\tau_3</code> and <code class="reqn">\tau_4</code> is compared to to judge &ldquo;good enough&rdquo; for the alogrithm to order solutions based on smallest error as explained in next argument.</p>
</td></tr>
<tr><td><code id="parTLgld_+3A_aux">aux</code></td>
<td>
<p>Control the algorithm to order solutions based on smallest error in trimmed <code class="reqn">\Delta \tau_5</code> or <code class="reqn">\Delta \tau_6</code>.</p>
</td></tr>
<tr><td><code id="parTLgld_+3A_checklmom">checklmom</code></td>
<td>
<p>Should the <code>lmom</code> be checked for validity using the <code><a href="#topic+are.lmom.valid">are.lmom.valid</a></code> function. Normally this should be left as the default and it is very unlikely that the L-moments will not be viable (particularly in the <code class="reqn">\tau_4</code> and <code class="reqn">\tau_3</code> inequality). However, for some circumstances or large simulation exercises then one might want to bypass this check.</p>
</td></tr>
<tr><td><code id="parTLgld_+3A_...">...</code></td>
<td>
<p>Other arguments to pass.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Karian and Dudewicz (2000) summarize six regions of the <code class="reqn">\kappa</code> and <code class="reqn">h</code> space in which the Generalized Lambda distribution is valid for suitably choosen <code class="reqn">\alpha</code>. Numerical experimentation suggestions that the L-moments are not valid in Regions 1 and 2. However, initial guesses of the parameters within each region are used with numerous separate <code>optim</code> (the <span class="rlang"><b>R</b></span> function) efforts to perform a least sum-of-square errors on the following objective function.
</p>
<p style="text-align: center;"><code class="reqn">(\hat{\tau}^{(1)}_3 - \tilde{\tau}^{(1)}_3)^2 + (\hat{\tau}^{(1)}_4 - \tilde{\tau}^{(1)}_4)^2 \mbox{, }</code>
</p>

<p>where <code class="reqn">\tilde{\tau}^{(1)}_r</code> is the L-moment ratio of the data, <code class="reqn">\hat{\tau}^{(1)}_r</code> is the estimated value of the TL-moment ratio for the current pairing of <code class="reqn">\kappa</code> and <code class="reqn">h</code> and <code class="reqn">\tau^{(1)}_r</code> is the actual value of the L-moment ratio.
</p>
<p>For each optimization a check on the validity of the parameters so produced is made&ndash;are the parameters consistent with the Generalized Lambda distribution and a second check is made on the validity of <code class="reqn">\tau^{(1)}_3</code> and <code class="reqn">\tau^{(1)}_4</code>. If both validity checks return <code>TRUE</code> then the optimization is retained if its sum-of-square error is less than the previous optimum value. It is possible for a given solution to be found outside the starting region of the initial guesses. The surface generated by the <code class="reqn">\tau^{(1)}_3</code> and <code class="reqn">\tau^{(1)}_4</code> equations seen in <code><a href="#topic+lmomTLgld">lmomTLgld</a></code> is complex; different initial guesses within a given region can yield what appear to be radically different <code class="reqn">\kappa</code> and <code class="reqn">h</code>. Users are encouraged to &ldquo;play&rdquo; with alternative solutions (see the <code>verbose</code> argument). A quick double check on the L-moments (not TL-moments) from the solved parameters using <code><a href="#topic+lmomTLgld">lmomTLgld</a></code> is encouraged as well.
</p>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> is returned if <code>result='best'</code>.
</p>
<table>
<tr><td><code>type</code></td>
<td>
<p>The type of distribution: <code>gld</code>.</p>
</td></tr>
<tr><td><code>para</code></td>
<td>
<p>The parameters of the distribution.</p>
</td></tr>
<tr><td><code>delTau5</code></td>
<td>
<p>Difference between <code class="reqn">\tilde{\tau}^{(1)}_5</code> of the fitted distribution and true <code class="reqn">\hat{\tau}^{(1)}_5</code>.</p>
</td></tr>
<tr><td><code>error</code></td>
<td>
<p>Smallest sum of square error found.</p>
</td></tr>
<tr><td><code>source</code></td>
<td>
<p>The source of the parameters: &ldquo;parTLgld&rdquo;.</p>
</td></tr>
<tr><td><code>rest</code></td>
<td>
<p>An <span class="rlang"><b>R</b></span> <code>data.frame</code> of other solutions if found.</p>
</td></tr>
</table>
<p>The rest of the solutions have the following:
</p>
<table>
<tr><td><code>xi</code></td>
<td>
<p>The location parameter of the distribution.</p>
</td></tr>
<tr><td><code>alpha</code></td>
<td>
<p>The scale parameter of the distribution.</p>
</td></tr>
<tr><td><code>kappa</code></td>
<td>
<p>The 1st shape parameter of the distribution.</p>
</td></tr>
<tr><td><code>h</code></td>
<td>
<p>The 2nd shape parameter of the distribution.</p>
</td></tr>
<tr><td><code>attempt</code></td>
<td>
<p>The attempt number that found valid TL-moments and parameters of GLD.</p>
</td></tr>
<tr><td><code>delTau5</code></td>
<td>
<p>The absolute difference between <code class="reqn">\hat{\tau}^{(1)}_5</code> of data to <code class="reqn">\tilde{\tau}^{(1)}_5</code> of the fitted distribution.</p>
</td></tr>
<tr><td><code>error</code></td>
<td>
<p>The sum of square error found.</p>
</td></tr>
<tr><td><code>initial_k</code></td>
<td>
<p>The starting point of the <code class="reqn">\kappa</code> parameter.</p>
</td></tr>
<tr><td><code>initial_h</code></td>
<td>
<p>The starting point of the <code class="reqn">h</code> parameter.</p>
</td></tr>
<tr><td><code>valid.gld</code></td>
<td>
<p>Logical on validity of the GLD&mdash;<code>TRUE</code> by this point.</p>
</td></tr>
<tr><td><code>valid.lmr</code></td>
<td>
<p>Logical on validity of the L-moments&mdash;<code>TRUE</code> by this point.</p>
</td></tr>
<tr><td><code>lowerror</code></td>
<td>
<p>Logical on whether error was less than <code>eps</code>&mdash;<code>TRUE</code> by this point.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>This function is a cumbersome method of parameter solution, but years of testing suggest that with supervision and the available options regarding the optimization that reliable parameter estimations result.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>Source</h3>

<p>W.H. Asquith in Feb. 2006 with a copy of Karian and Dudewicz (2000) and again Feb. 2011.
</p>


<h3>References</h3>

<p>Asquith, W.H., 2007, L-moments and TL-moments of the generalized lambda distribution: Computational Statistics and Data Analysis, v. 51, no. 9, pp. 4484&ndash;4496.
</p>
<p>Karian, Z.A., and Dudewicz, E.J., 2000, Fitting statistical distributions&mdash;The generalized lambda distribution and generalized bootstrap methods: CRC Press, Boca Raton, FL, 438 p.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+TLmoms">TLmoms</a></code>, <code><a href="#topic+lmomTLgld">lmomTLgld</a></code>, <code><a href="#topic+cdfgld">cdfgld</a></code>, <code><a href="#topic+pdfgld">pdfgld</a></code>, <code><a href="#topic+quagld">quagld</a></code>,
<code><a href="#topic+pargld">pargld</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># As of version 1.6.2, it is felt that in spirit of CRAN CPU
# reduction that the intensive operations of parTLgld() should
# be kept a bay.

## Not run: 
X &lt;- rgamma(202,2) # simulate a skewed distribution
lmr &lt;- TLmoms(X, trim=1) # compute trimmed L-moments
PARgldTL &lt;- parTLgld(lmr) # fit the GLD

F &lt;- pp(X) # plotting positions for graphing
plot(F,sort(X), col=8, cex=0.25)
lines(F, qlmomco(F,PARgldTL)) # show the best estimate
if(! is.null(PARgldTL$rest)) { 
  n &lt;- length(PARgldTL$rest$xi)
  other &lt;- unlist(PARgldTL$rest[n,1:4]) # show alternative
  lines(F, qlmomco(F,vec2par(other, type="gld")), col=2)
}
# Note in the extraction of other solutions that no testing for whether
# additional solutions were found is made. Also, it is quite possible
# that the other solutions "[n,1:4]" is effectively another numerical
# convergence on the primary solution. Some users of this example thus
# might not see two separate lines. Users are encouraged to inspect the
# rest of the solutions: print(PARgld$rest)

# For one run of the above example, the GLD results follow
#print(PARgldTL)
#$type
#[1] "gld"
#$para
#         xi       alpha       kappa           h
# 1.02333964 -3.86037875 -0.06696388 -0.22100601
#$delTau5
#[1] -0.02299319
#$error
#[1] 7.048409e-08
#$source
#[1] "pargld"
#$rest
#         xi     alpha       kappa          h attempt     delTau5        error
#1  1.020725 -3.897500 -0.06606563 -0.2195527       6 -0.02302222 1.333402e-08
#2  1.021203 -3.895334 -0.06616654 -0.2196020       4 -0.02304333 8.663930e-11
#3  1.020684 -3.904782 -0.06596204 -0.2192197       5 -0.02306065 3.908918e-09
#4  1.019795 -3.917609 -0.06565792 -0.2187232       2 -0.02307092 2.968498e-08
#5  1.023654 -3.883944 -0.06668986 -0.2198679       7 -0.02315035 2.991811e-07
#6 -4.707935 -5.044057  5.89280906 -0.3261837      13  0.04168800 2.229672e-10

## End(Not run)

## Not run: 
F &lt;- seq(.01,.99,.01)
plot(F,qlmomco(F, vec2par(c( 1.02333964, -3.86037875,
                            -0.06696388, -0.22100601), type="gld")),
     type="l")
lines(F,qlmomco(F, vec2par(c(-4.707935, -5.044057,
                              5.89280906, -0.3261837), type="gld")))

## End(Not run)
</code></pre>

<hr>
<h2 id='parTLgpa'>Estimate the Parameters of the Generalized Pareto Distribution using Trimmed L-moments</h2><span id='topic+parTLgpa'></span>

<h3>Description</h3>

<p>This function estimates the parameters of the Generalized Pareto distribution given
the the trimmed L-moments (TL-moments) for <code class="reqn">t=1</code> of the data in TL-moment object with a trim level of unity (<code>trim=1</code>). The parameters are computed as
</p>
<p style="text-align: center;"><code class="reqn">\kappa = \frac{10-45\tau^{(1)}_3}{9\tau^{(1)}_3+10} \mbox{,}</code>
</p>

<p style="text-align: center;"><code class="reqn">\alpha = \frac{1}{6}\lambda^{(1)}_2(\kappa+2)(\kappa+3)(\kappa+4) \mbox{, and}</code>
</p>

<p style="text-align: center;"><code class="reqn">\xi = \lambda^{(1)}_1 - \frac{\alpha(\kappa+5)}{(\kappa+2)(\kappa+3)} \mbox{.}</code>
</p>



<h3>Usage</h3>

<pre><code class='language-R'>parTLgpa(lmom, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="parTLgpa_+3A_lmom">lmom</code></td>
<td>
<p>A TL-moment object created by <code><a href="#topic+TLmoms">TLmoms</a></code>.</p>
</td></tr>
<tr><td><code id="parTLgpa_+3A_...">...</code></td>
<td>
<p>Other arguments to pass.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> is returned.
</p>
<table>
<tr><td><code>type</code></td>
<td>
<p>The type of distribution: <code>gpa</code>.</p>
</td></tr>
<tr><td><code>para</code></td>
<td>
<p>The parameters of the distribution.</p>
</td></tr>
<tr><td><code>source</code></td>
<td>
<p>The source of the parameters: &ldquo;parTLgpa&rdquo;.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Elamir, E.A.H., and Seheult, A.H., 2003, Trimmed L-moments: Computational Statistics and Data Analysis, v. 43, pp. 299&ndash;314.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+TLmoms">TLmoms</a></code>, <code><a href="#topic+lmomTLgpa">lmomTLgpa</a></code>,
<code><a href="#topic+cdfgpa">cdfgpa</a></code>, <code><a href="#topic+pdfgpa">pdfgpa</a></code>, <code><a href="#topic+quagpa">quagpa</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>TL &lt;- TLmoms(rnorm(20),trim=1)
parTLgpa(TL)
</code></pre>

<hr>
<h2 id='partri'>Estimate the Parameters of the Asymmetric Triangular Distribution</h2><span id='topic+partri'></span>

<h3>Description</h3>

<p>This function estimates the parameters of the Asymmetric Triangular distribution given the L-moments of the data in an L-moment object such as that returned by <code><a href="#topic+lmoms">lmoms</a></code>. The relations between distribution parameters and L-moments are seen under <code><a href="#topic+lmomtri">lmomtri</a></code>.
</p>
<p>The estimtion by the <code>partri</code> function is built around simultaneous numerical optimization of an objective function defined as
</p>
<p style="text-align: center;"><code class="reqn">\epsilon = \biggl(\frac{\lambda_1 - \hat\lambda_1}{\hat\lambda_1}\biggr)^2 + \biggl(\frac{\lambda_2 - \hat\lambda_2}{\hat\lambda_2}\biggr)^2 + \biggl(\frac{\tau_3 - \hat\tau_3}{1}\biggr)^2</code>
</p>

<p>for estimation of the three parameters (<code class="reqn">\nu</code>, minimum; <code class="reqn">\omega</code>, mode; and <code class="reqn">\psi</code>, maximum) from the sample L-moments (<code class="reqn">\hat\lambda_1</code>, <code class="reqn">\hat\lambda_2</code>, <code class="reqn">\hat\tau_3</code>). The divisions shown in the objective function are used for scale removal to help make each L-moment order somewhat similar in its relative contribution to the solution. The coefficient of L-variation is not used because the distribution implementation by the <span class="pkg">lmomco</span> package supports entire real number line and the loss of definition of <code class="reqn">\tau_2</code> at <code class="reqn">x = 0</code>, in particular, causes untidiness in coding.
</p>
<p>The function is designed to support both left- or right-hand right triangular shapes because of (1) <code>paracheck</code> argument availability in <code><a href="#topic+lmomtri">lmomtri</a></code>, (2) the sorting of the numerical estimates if the mode is no compatable with either of the limits, and (3) the snapping of <code class="reqn">\nu = \omega \equiv (\nu^\star + \omega^\star)/2</code> when <code class="reqn">\hat\tau_3 &gt; 0.142857</code> or <code class="reqn">\psi = \omega \equiv (\psi^\star + \omega^\star)/2</code> when <code class="reqn">\hat\tau_3 &lt; 0.142857</code> where the <code class="reqn">\star</code> versions are the optimized values if the <code class="reqn">\tau_3</code> is very near to its numerical bounds.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>partri(lmom, checklmom=TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="partri_+3A_lmom">lmom</code></td>
<td>
<p>An L-moment object created by <code><a href="#topic+lmoms">lmoms</a></code> or <code><a href="#topic+vec2lmom">vec2lmom</a></code>.</p>
</td></tr>
<tr><td><code id="partri_+3A_checklmom">checklmom</code></td>
<td>
<p>Should the <code>lmom</code> be checked for validity using the <code><a href="#topic+are.lmom.valid">are.lmom.valid</a></code> function. Normally this should be left as the default and it is very unlikely that the L-moments will not be viable (particularly in the <code class="reqn">\tau_4</code> and <code class="reqn">\tau_3</code> inequality). However, for some circumstances or large simulation exercises then one might want to bypass this check.</p>
</td></tr>
<tr><td><code id="partri_+3A_...">...</code></td>
<td>
<p>Other arguments to pass.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> is returned.
</p>
<table>
<tr><td><code>type</code></td>
<td>
<p>The type of distribution: <code>tri</code>.</p>
</td></tr>
<tr><td><code>para</code></td>
<td>
<p>The parameters of the distribution.</p>
</td></tr>
<tr><td><code>obj.val</code></td>
<td>
<p>The value of the objective function, which is the error of the optimization.</p>
</td></tr>
<tr><td><code>source</code></td>
<td>
<p>The source of the parameters: &ldquo;partri&rdquo;.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>See Also</h3>

<p><code><a href="#topic+lmomtri">lmomtri</a></code>,
<code><a href="#topic+cdftri">cdftri</a></code>, <code><a href="#topic+pdftri">pdftri</a></code>, <code><a href="#topic+quatri">quatri</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>lmr &lt;- lmomtri(vec2par(c(10,90,100), type="tri"))
partri(lmr)

partri(lmomtri(vec2par(c(-11, 67,67), type="tri")))$para
partri(lmomtri(vec2par(c(-11,-11,67), type="tri")))$para
</code></pre>

<hr>
<h2 id='parwak'>Estimate the Parameters of the Wakeby Distribution</h2><span id='topic+parwak'></span>

<h3>Description</h3>

<p>This function estimates the parameters of the Wakeby distribution given the L-moments of the data in an L-moment object such as that returned by <code><a href="#topic+lmoms">lmoms</a></code>. The relations between distribution parameters and L-moments are seen under <code><a href="#topic+lmomwak">lmomwak</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>parwak(lmom, checklmom=TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="parwak_+3A_lmom">lmom</code></td>
<td>
<p>An L-moment object created by <code><a href="#topic+lmoms">lmoms</a></code>
or <code><a href="#topic+vec2lmom">vec2lmom</a></code>.</p>
</td></tr>
<tr><td><code id="parwak_+3A_checklmom">checklmom</code></td>
<td>
<p>Should the <code>lmom</code> be checked for validity using the <code><a href="#topic+are.lmom.valid">are.lmom.valid</a></code> function. Normally this should be left as the default and it is very unlikely that the L-moments will not be viable (particularly in the <code class="reqn">\tau_4</code> and <code class="reqn">\tau_3</code> inequality). However, for some circumstances or large simulation exercises then one might want to bypass this check.</p>
</td></tr>
<tr><td><code id="parwak_+3A_...">...</code></td>
<td>
<p>Other arguments to pass.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> is returned.
</p>
<table>
<tr><td><code>type</code></td>
<td>
<p>The type of distribution: <code>wak</code>.</p>
</td></tr>
<tr><td><code>para</code></td>
<td>
<p>The parameters of the distribution.</p>
</td></tr>
<tr><td><code>source</code></td>
<td>
<p>The source of the parameters: &ldquo;parwak&rdquo;.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Hosking, J.R.M., 1990, L-moments&mdash;Analysis and estimation of distributions using linear combinations of order statistics: Journal of the Royal Statistical Society, Series B, v. 52, pp. 105&ndash;124.
</p>
<p>Hosking, J.R.M., 1996, FORTRAN routines for use with the method of L-moments: Version 3, IBM Research Report RC20525, T.J. Watson Research Center,
Yorktown Heights, New York.
</p>
<p>Hosking, J.R.M., and Wallis, J.R., 1997, Regional frequency analysis&mdash;An approach based on L-moments: Cambridge University Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lmomwak">lmomwak</a></code>,
<code><a href="#topic+cdfwak">cdfwak</a></code>, <code><a href="#topic+pdfwak">pdfwak</a></code>, <code><a href="#topic+quawak">quawak</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>lmr &lt;- lmoms(rnorm(20))
parwak(lmr)
</code></pre>

<hr>
<h2 id='parwei'>Estimate the Parameters of the Weibull Distribution</h2><span id='topic+parwei'></span>

<h3>Description</h3>

<p>This function estimates the parameters of the Weibull distribution given the L-moments of the data in an L-moment object such as that returned by <code><a href="#topic+lmoms">lmoms</a></code>. The Weibull distribution is a reverse Generalized Extreme Value distribution.  As result, the Generalized Extreme Value algorithms are used for implementation of the Weibull in this package. The relations between the Generalized Extreme Value parameters (<code class="reqn">\xi</code>, <code class="reqn">\alpha</code>, and <code class="reqn">\kappa</code>) and the Weibull parameters are
</p>
<p style="text-align: center;"><code class="reqn">\kappa = 1/\delta \mbox{,}</code>
</p>

<p style="text-align: center;"><code class="reqn">\alpha = \beta/\delta \mbox{, and}</code>
</p>

<p style="text-align: center;"><code class="reqn">\xi = \zeta - \beta \mbox{.}</code>
</p>

<p>These relations are taken from Hosking and Wallis (1997). The relations between the distribution parameters and L-moments are seen under <code><a href="#topic+lmomgev">lmomgev</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>parwei(lmom,checklmom=TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="parwei_+3A_lmom">lmom</code></td>
<td>
<p>An L-moment object created by <code><a href="#topic+lmoms">lmoms</a></code> or <code><a href="#topic+vec2lmom">vec2lmom</a></code>.</p>
</td></tr>
<tr><td><code id="parwei_+3A_checklmom">checklmom</code></td>
<td>
<p>Should the <code>lmom</code> be checked for validity using the <code><a href="#topic+are.lmom.valid">are.lmom.valid</a></code> function. Normally this should be left as the default and it is very unlikely that the L-moments will not be viable (particularly in the <code class="reqn">\tau_4</code> and <code class="reqn">\tau_3</code> inequality). However, for some circumstances or large simulation exercises then one might want to bypass this check.</p>
</td></tr>
<tr><td><code id="parwei_+3A_...">...</code></td>
<td>
<p>Other arguments to pass.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> is returned.
</p>
<table>
<tr><td><code>type</code></td>
<td>
<p>The type of distribution: <code>wei</code>.</p>
</td></tr>
<tr><td><code>para</code></td>
<td>
<p>The parameters of the distribution.</p>
</td></tr>
<tr><td><code>source</code></td>
<td>
<p>The source of the parameters: &ldquo;parwei&rdquo;.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Hosking, J.R.M., and Wallis, J.R., 1997, Regional frequency analysis&mdash;An approach based on L-moments: Cambridge University Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lmomwei">lmomwei</a></code>,
<code><a href="#topic+cdfwei">cdfwei</a></code>, <code><a href="#topic+pdfwei">pdfwei</a></code>, <code><a href="#topic+quawei">quawei</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>parwei(lmoms(rnorm(20)))
## Not run: 
str(parwei(lmoms(rweibull(3000,1.3, scale=340)-1200))) #
## End(Not run)
</code></pre>

<hr>
<h2 id='pdfaep4'>Probability Density Function of the 4-Parameter Asymmetric Exponential Power Distribution</h2><span id='topic+pdfaep4'></span>

<h3>Description</h3>

<p>This function computes the probability density of the 4-parameter Asymmetric Exponential Power distribution given parameters (<code class="reqn">\xi</code>,
<code class="reqn">\alpha</code>, <code class="reqn">\kappa</code>, and <code class="reqn">h</code>)  computed by <code><a href="#topic+paraep4">paraep4</a></code>. The probability density function is
</p>
<p style="text-align: center;"><code class="reqn">f(x) = \frac{\kappa\,h}{\alpha(1+\kappa^2)\,\Gamma(1/h)}\,
    \mathrm{exp}\left( -\left[\kappa^{ \mathrm{sign}(x-\xi)}\left(\frac{|x-\xi|}{\alpha}\right)\,\right]^h \right)  </code>
</p>

<p>where <code class="reqn">f(x)</code> is the probability density for quantile <code class="reqn">x</code>,
<code class="reqn">\xi</code> is a location parameter, <code class="reqn">\alpha</code> is a scale parameter,
<code class="reqn">\kappa</code> is a shape parameter, and <code class="reqn">h</code> is another shape parameter. The range  is <code class="reqn">-\infty &lt; x &lt; \infty</code>. If the <code class="reqn">\tau_3</code> of the distribution is zero (symmetrical), then the distribution is known as the Exponential Power (see <code><a href="#topic+lmrdia46">lmrdia46</a></code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pdfaep4(x, para, paracheck=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pdfaep4_+3A_x">x</code></td>
<td>
<p>A real value vector.</p>
</td></tr>
<tr><td><code id="pdfaep4_+3A_para">para</code></td>
<td>
<p>The parameters from <code><a href="#topic+paraep4">paraep4</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
<tr><td><code id="pdfaep4_+3A_paracheck">paracheck</code></td>
<td>
<p>A logical controlling whether the parameters and checked for validity.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Probability density (<code class="reqn">f</code>) for <code class="reqn">x</code>.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Asquith, W.H., 2014, Parameter estimation for the 4-parameter asymmetric exponential power distribution by the method of L-moments using R: Computational Statistics and Data Analysis, v. 71, pp. 955&ndash;970.
</p>
<p>Delicado, P., and Goria, M.N., 2008, A small sample comparison of maximum likelihood,
moments and L-moments methods for the asymmetric exponential power distribution:
Computational Statistics and Data Analysis, v. 52, no. 3, pp. 1661&ndash;1673.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cdfaep4">cdfaep4</a></code>, <code><a href="#topic+quaaep4">quaaep4</a></code>, <code><a href="#topic+lmomaep4">lmomaep4</a></code>, <code><a href="#topic+paraep4">paraep4</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>aep4 &lt;- vec2par(c(1000,15000,0.5,0.4), type='aep4');
F &lt;- nonexceeds();
x &lt;- quaaep4(F,aep4);
check.pdf(pdfaep4,aep4,plot=TRUE);
## Not run: 
delx &lt;- .01;
x &lt;- seq(-10,10, by=delx);
K &lt;- 3;
PAR &lt;- list(para=c(0,1, K, 0.5), type="aep4");
plot(x,pdfaep4(x, PAR), type="n",
     ylab="PROBABILITY DENSITY",
     ylim=c(0,0.6), xlim=range(x));
lines(x,pdfaep4(x,PAR), lwd=2);

PAR &lt;- list(para=c(0,1, K, 1), type="aep4");
lines(x,pdfaep4(x, PAR), lty=2, lwd=2);

PAR &lt;- list(para=c(0,1, K, 2), type="aep4");
lines(x,pdfaep4(x, PAR), lty=3, lwd=2);

PAR &lt;- list(para=c(0,1, K, 4), type="aep4");
lines(x,pdfaep4(x, PAR), lty=4, lwd=2);

## End(Not run)
</code></pre>

<hr>
<h2 id='pdfcau'>Probability Density Function of the Cauchy Distribution</h2><span id='topic+pdfcau'></span>

<h3>Description</h3>

<p>This function computes the probability density
of the Cauchy distribution given parameters (<code class="reqn">\xi</code> and <code class="reqn">\alpha</code>)  provided by <code><a href="#topic+parcau">parcau</a></code>.  The probability density function is
</p>
<p style="text-align: center;"><code class="reqn">f(x) = \left(\pi \alpha \left[1 + \left({\frac{x-\xi}{\alpha}}\right)^2\right] \right)^{-1}\mbox{,}</code>
</p>

<p>where <code class="reqn">f(x)</code> is the probability density for quantile <code class="reqn">x</code>,
<code class="reqn">\xi</code> is a location parameter, and <code class="reqn">\alpha</code> is a scale parameter.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pdfcau(x, para)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pdfcau_+3A_x">x</code></td>
<td>
<p>A real value vector.</p>
</td></tr>
<tr><td><code id="pdfcau_+3A_para">para</code></td>
<td>
<p>The parameters from <code><a href="#topic+parcau">parcau</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Probability density (<code class="reqn">f</code>) for <code class="reqn">x</code>.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Elamir, E.A.H., and Seheult, A.H., 2003, Trimmed L-moments: Computational Statistics
and Data Analysis, vol. 43, pp. 299&ndash;314.
</p>
<p>Evans, Merran, Hastings, Nicholas, Peacock, J.B., 2000, Statistical distributions: 3rd ed., Wiley, New York.
</p>
<p>Gilchrist, W.G., 2000, Statistical modeling with quantile functions:
Chapman and Hall/CRC, Boca Raton, FL.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cdfcau">cdfcau</a></code>, <code><a href="#topic+quacau">quacau</a></code>, <code><a href="#topic+lmomcau">lmomcau</a></code>, <code><a href="#topic+parcau">parcau</a></code>, <code><a href="#topic+vec2par">vec2par</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>  cau &lt;- vec2par(c(12,12),type='cau')
  x &lt;- quacau(0.5,cau)
  pdfcau(x,cau)
</code></pre>

<hr>
<h2 id='pdfemu'>Probability Density Function of the Eta-Mu Distribution</h2><span id='topic+pdfemu'></span>

<h3>Description</h3>

<p>This function computes the probability density of the Eta-Mu (<code class="reqn">\eta:\mu</code>) distribution given parameters (<code class="reqn">\eta</code> and <code class="reqn">\mu</code>)  computed by <code><a href="#topic+paremu">paremu</a></code>. The probability density function is
</p>
<p style="text-align: center;"><code class="reqn">
f(x) = \frac{4\sqrt{\pi}\mu^{\mu - 1/2}h^\mu}{\gamma(\mu)H^{\mu - 1/2}}\,x^{2\mu}\,\exp(-2\mu h x^2)\,I_{\mu-1/2}(2\mu H x^2)\mbox{,}
</code>
</p>

<p>where <code class="reqn">f(x)</code> is the nonexceedance probability for quantile <code class="reqn">x</code>, and the modified Bessel function of the first kind is <code class="reqn">I_k(x)</code>, and the <code class="reqn">h</code> and <code class="reqn">H</code> are
</p>
<p style="text-align: center;"><code class="reqn">
h = \frac{1}{1-\eta^2}\mbox{,}
</code>
</p>

<p>and
</p>
<p style="text-align: center;"><code class="reqn">
H = \frac{\eta}{1-\eta^2}\mbox{,}
</code>
</p>

<p>for &ldquo;Format 2&rdquo;  as described by Yacoub (2007). This format is exclusively used in the algorithms of the <span class="pkg">lmomco</span> package.
</p>
<p>If <code class="reqn">\mu=1</code>, then the Rice distribution results, although <code><a href="#topic+pdfrice">pdfrice</a></code> is not used. If <code class="reqn">\kappa \rightarrow 0</code>, then the exact Nakagami-m density function results with a close relation to the Rayleigh distribution.
</p>
<p>Define <code class="reqn">m</code> as
</p>
<p style="text-align: center;"><code class="reqn">m = 2\mu\biggl[1 + {\biggr(\frac{H}{h}\biggl)}^2 \biggr]\mbox{,}</code>
</p>

<p>where for a given <code class="reqn">m</code>, the parameter <code class="reqn">\mu</code> must lie in the range
</p>
<p style="text-align: center;"><code class="reqn">m/2 \le \mu \le m\mbox{.}</code>
</p>

<p>The <code class="reqn">I_k(x)</code> for real <code class="reqn">x &gt; 0</code> and noninteger <code class="reqn">k</code> is
</p>
<p style="text-align: center;"><code class="reqn">I_k(x) = \frac{1}{\pi} \int_0^\pi \exp(x\cos(\theta)) \cos(k \theta)\; \mathrm{d}\theta - \frac{\sin(k\pi)}{\pi}\int_0^\infty \exp(-x \mathrm{cosh}(t) - kt)\; \mathrm{d}t\mbox{.}</code>
</p>



<h3>Usage</h3>

<pre><code class='language-R'>pdfemu(x, para, paracheck=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pdfemu_+3A_x">x</code></td>
<td>
<p>A real value vector.</p>
</td></tr>
<tr><td><code id="pdfemu_+3A_para">para</code></td>
<td>
<p>The parameters from <code><a href="#topic+paremu">paremu</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
<tr><td><code id="pdfemu_+3A_paracheck">paracheck</code></td>
<td>
<p>A logical controlling whether the parameters and checked for validity.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Probability density (<code class="reqn">f</code>) for <code class="reqn">x</code>.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Yacoub, M.D., 2007, The kappa-mu distribution and the eta-mu distribution: IEEE Antennas and Propagation Magazine, v. 49, no. 1, pp. 68&ndash;81
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cdfemu">cdfemu</a></code>, <code><a href="#topic+quaemu">quaemu</a></code>, <code><a href="#topic+lmomemu">lmomemu</a></code>, <code><a href="#topic+paremu">paremu</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
x &lt;- seq(0,4, by=.1)
para &lt;- vec2par(c(.5, 1.4), type="emu")
F &lt;- cdfemu(x, para);         X &lt;- quaemu(F, para)
plot(F, X, type="l", lwd=8);  lines(F, x, col=2)

delx &lt;- 0.005
x &lt;- seq(0,3, by=delx)
plot(c(0,3), c(0,1), xaxs="i", yaxs="i",
     xlab="RHO", ylab="pdfemu(RHO)", type="n")
mu &lt;- 0.6
# Note that in order to produce the figure correctly using the etas
# shown in the figure that it must be recognized that these are the etas
# for format1, but all of the algorithms in lmomco are built around
# format2
etas.format1 &lt;- c(0, 0.02, 0.05, 0.1, 0.2, 0.3, 0.5, 1)
etas.format2 &lt;- (1 - etas.format1)/(1+etas.format1)
H &lt;- etas.format2 / (1 - etas.format2^2)
h &lt;-            1 / (1 - etas.format2^2)
for(eta in etas.format2) {
   lines(x, pdfemu(x, vec2par(c(eta, mu), type="emu")),
         col=rgb(eta^2,0,0))
}
mtext("Yacoub (2007, figure 5)")

plot(c(0,3), c(0,2), xaxs="i", yaxs="i",
     xlab="RHO", ylab="pdfemu(RHO)", type="n")
eta.format1 &lt;- 0.5
eta.format2 &lt;- (1 - eta.format1)/(1 + eta.format1)
mus &lt;- c(0.25, 0.3, 0.5, 0.75, 1, 1.5, 2, 3)
for(mu in mus) {
   lines(x, pdfemu(x, vec2par(c(eta, mu), type="emu")))
}
mtext("Yacoub (2007, figure 6)")

plot(c(0,3), c(0,1), xaxs="i", yaxs="i",
     xlab="RHO", ylab="pdfemu(RHO)", type="n")
m &lt;- 0.75
mus &lt;- c(0.7425, 0.75, 0.7125, 0.675, 0.45, 0.5, 0.6)
for(mu in mus) {
   eta &lt;- sqrt((m / (2*mu))^-1 - 1)
   print(eta)
   lines(x, pdfemu(x, vec2par(c(eta, mu), type="emu")))
}
mtext("Yacoub (2007, figure 7)") #
## End(Not run)
</code></pre>

<hr>
<h2 id='pdfexp'>Probability Density Function of the Exponential Distribution</h2><span id='topic+pdfexp'></span>

<h3>Description</h3>

<p>This function computes the probability density
of the Exponential distribution given parameters (<code class="reqn">\xi</code> and <code class="reqn">\alpha</code>)  computed by <code><a href="#topic+parexp">parexp</a></code>. The probability density function  is
</p>
<p style="text-align: center;"><code class="reqn">f(x) = \alpha^{-1}\exp(Y)\mbox{,}</code>
</p>

<p>where <code class="reqn">Y</code> is
</p>
<p style="text-align: center;"><code class="reqn">Y = \left(\frac{-(x - \xi)}{\alpha}\right)\mbox{,}</code>
</p>

<p>where <code class="reqn">f(x)</code> is the probability density for the quantile <code class="reqn">x</code>,
<code class="reqn">\xi</code> is a location parameter, and <code class="reqn">\alpha</code> is a scale parameter.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pdfexp(x, para)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pdfexp_+3A_x">x</code></td>
<td>
<p>A real value vector.</p>
</td></tr>
<tr><td><code id="pdfexp_+3A_para">para</code></td>
<td>
<p>The parameters from <code><a href="#topic+parexp">parexp</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Probability density (<code class="reqn">f</code>) for <code class="reqn">x</code>.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Hosking, J.R.M., 1990, L-moments&mdash;Analysis and estimation of
distributions using linear combinations of order statistics: Journal
of the Royal Statistical Society, Series B, v. 52, pp. 105&ndash;124.
</p>
<p>Hosking, J.R.M., 1996, FORTRAN routines for use with the method of L-moments:
Version 3, IBM Research Report RC20525, T.J. Watson Research Center,
Yorktown Heights, New York.
</p>
<p>Hosking, J.R.M. and Wallis, J.R., 1997, Regional frequency analysis&mdash;An
approach based on L-moments: Cambridge University Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cdfexp">cdfexp</a></code>, <code><a href="#topic+quaexp">quaexp</a></code>, <code><a href="#topic+lmomexp">lmomexp</a></code>, <code><a href="#topic+parexp">parexp</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>  lmr &lt;- lmoms(c(123,34,4,654,37,78))
  expp &lt;- parexp(lmr)
  x &lt;- quaexp(.5,expp)
  pdfexp(x,expp)
</code></pre>

<hr>
<h2 id='pdfgam'>Probability Density Function of the Gamma Distribution</h2><span id='topic+pdfgam'></span>

<h3>Description</h3>

<p>This function computes the probability density function
of the Gamma distribution given parameters (<code class="reqn">\alpha</code>, shape, and <code class="reqn">\beta</code>, scale)  computed by <code><a href="#topic+pargam">pargam</a></code>.  The probability density function has no explicit form, but is expressed as an integral
</p>
<p style="text-align: center;"><code class="reqn">f(x|\alpha, \beta)^{\mathrm{lmomco}} = \frac{1}{\beta^\alpha\,\Gamma(\alpha)}\, x^{\alpha - 1}\, \mathrm{exp}(-x/\beta) \mbox{,}</code>
</p>

<p>where <code class="reqn">f(x)</code> is the probability density for the quantile <code class="reqn">x</code>, <code class="reqn">\alpha</code> is a shape parameter, and <code class="reqn">\beta</code> is a scale parameter.
</p>
<p>Alternatively, a three-parameter version is available for this package following the parameterization of the Generalized Gamma distribution used in the <span class="pkg">gamlss.dist</span> package and is
</p>
<p style="text-align: center;"><code class="reqn">f(x|\mu,\sigma,\nu)_{\mathrm{gamlss.dist}}^{\mathrm{lmomco}}=\frac{\theta^\theta\, |\nu|}{\Gamma(\theta)}\,\frac{z^\theta}{x}\,\mathrm{exp}(-z\theta)\mbox{,}</code>
</p>

<p>where <code class="reqn">z =(x/\mu)^\nu</code>, <code class="reqn">\theta = 1/(\sigma^2\,|\nu|^2)</code> for <code class="reqn">x &gt; 0</code>, location parameter <code class="reqn">\mu &gt; 0</code>, scale parameter <code class="reqn">\sigma &gt; 0</code>, and shape parameter <code class="reqn">-\infty &lt; \nu &lt; \infty</code>. Note that for <code class="reqn">\nu = 0</code> the distribution is log-Normal. The three parameter version is automatically triggered if the length of the <code>para</code> element is three and not two.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pdfgam(x, para)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pdfgam_+3A_x">x</code></td>
<td>
<p>A real value vector.</p>
</td></tr>
<tr><td><code id="pdfgam_+3A_para">para</code></td>
<td>
<p>The parameters from <code><a href="#topic+pargam">pargam</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Probability density (<code class="reqn">f</code>) for <code class="reqn">x</code>.
</p>


<h3>Note</h3>

<p><b>Two Parameter <code class="reqn">\equiv</code> Three Parameter</b><br />
For <code class="reqn">\nu = 1</code>, the parameter conversion between the two gamma forms is <code class="reqn">\alpha = \sigma^{-2}</code> and <code class="reqn">\beta = \mu\sigma^2</code> and this can be readily verified:
</p>
<pre>
  mu &lt;- 5; sig &lt;- 0.7; nu &lt;- 0
  x &lt;- exp(seq(-3,3,by=.1))
  para2 &lt;- vec2par(c(1/sig^2, (mu*sig^2)  ), type="gam")
  para3 &lt;- vec2par(c(      mu,    sig,   1), type="gam")
  plot(x, pdfgam(x, para2), ylab="Gamma Density"); lines(x, pdfgam(x, para3))
</pre>
<p><b>Package flexsurv Generalized Gamma</b><br />
The <span class="pkg">flexsurv</span> package provides an &ldquo;original&rdquo; (<code>GenGamma.orig</code>) and &ldquo;preferred&rdquo; parameterization (<code>GenGamma</code>) of the Generalized Gamma distribution and discusses parameter conversion between the two. Here the parameterization of the preferred form is compared to that in <span class="pkg">lmomco</span>. The probability density function of <code>dgengamma()</code> from <span class="pkg">flexsurv</span> is
</p>
<p style="text-align: center;"><code class="reqn">f(x|\mu_2, \sigma_2, Q)_{\mathrm{flexsurv}} = \frac{\eta^\eta|Q|}{\sigma_2\Gamma(\eta)}\frac{1}{x}\, \mathrm{exp}\bigr\{\eta\times[wQ - \mathrm{exp}(wQ)]\bigr\}\mbox{,}</code>
</p>

<p>where <code class="reqn">\eta = Q^{-2}</code>, <code class="reqn">w = \log(g/\eta)/Q</code> for <code class="reqn">g \sim \mathrm{Gamma}(\eta, 1)</code> where <code class="reqn">\mathrm{Gamma}</code> is the cumulative distribution function (presumably, need to verify this) of the Gamma distribution, and
</p>
<p style="text-align: center;"><code class="reqn">x \sim \mathrm{exp}(\mu_2 + w\sigma_2)\mbox{,}</code>
</p>

<p>where <code class="reqn">\mu_2 &gt; 0</code>, <code class="reqn">\sigma_2 &gt; 0</code>, and <code class="reqn">-\infty &lt; Q &lt; \infty</code>, and the log-Normal distribution results for <code class="reqn">Q=0</code>.  These definitions for <span class="pkg">flexsurv</span> seem incomplete to this author and further auditing is needed.
</p>
<p><b>Additional Generalized Gamma Comparison</b><br />
The default <span class="pkg">gamlss.dist</span> package version uses so-called <em>log.links</em> for <code class="reqn">\mu</code> and <code class="reqn">\sigma</code>, and so-called <em>identity.link</em> for <code class="reqn">\nu</code> and these links are implicit for <span class="pkg">lmomco</span>. The parameters can be converted to <span class="pkg">flexsurv</span> package equivalents by <code class="reqn">\mu_2 = \log(\mu)</code>, <code class="reqn">\sigma_2 = \sigma</code>, and <code class="reqn">Q = \sigma\nu</code>, which is readily verified by
</p>
<pre>
  mu &lt;- 2; sig &lt;- 0.8; nu &lt;- 0.2; x &lt;- exp(seq(-3,1,by=0.1))
  para &lt;- vec2par(c(mu,sig,nu), type="gam")
  dGG &lt;- gamlss.dist::dGG(x, mu=mu, sigma=sig, nu=nu)
  plot( x, dGG, ylab="density", lwd=0.8, cex=2)
  lines(x, flexsurv::dgengamma(x, log(mu), sig, Q=sig*nu), col=8, lwd=5)
  lines(x, pdfgam(x, para), col=2)
</pre>
<p>What complicates the discussion further is that seemingly only the <em>log.link</em> concept is manifested in the use of <code class="reqn">\log(mu)</code> to provide the <code class="reqn">\mu_2</code> for <code>flexsurv::</code><code>dgengamma</code>.
</p>
<p><b>On the Log-Normal via Generalized Gamma</b><br />
The <span class="pkg">gamlss.dist</span> package uses an <code class="reqn">|\nu| &lt; 1\mathrm{e{-}6}</code> trigger for the log-Normal calls. Further testing and the initial independent origin of <span class="pkg">lmomco</span> code suggests that a primary trigger though can be based on the finiteness of the <code>lgamma(theta)</code> for <code class="reqn">\theta</code>. This is used in <code>pdfgam</code> as well as <code><a href="#topic+cdfgam">cdfgam</a></code> and <code><a href="#topic+quagam">quagam</a></code>.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Hosking, J.R.M., 1990, L-moments&mdash;Analysis and estimation of
distributions using linear combinations of order statistics: Journal
of the Royal Statistical Society, Series B, v. 52, pp. 105&ndash;124.
</p>
<p>Hosking, J.R.M. and Wallis, J.R., 1997, Regional frequency analysis&mdash;An
approach based on L-moments: Cambridge University Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cdfgam">cdfgam</a></code>, <code><a href="#topic+quagam">quagam</a></code>, <code><a href="#topic+lmomgam">lmomgam</a></code>, <code><a href="#topic+pargam">pargam</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>  lmr &lt;- lmoms(c(123,34,4,654,37,78))
  gam &lt;- pargam(lmr)
  x &lt;- quagam(0.5,gam)
  pdfgam(x,gam)

## Not run: 
# 3-p Generalized Gamma Distribution and gamlss.dist package parameterization
gg &lt;- vec2par(c(7.4, 0.2, 14), type="gam"); X &lt;- seq(0.04,9, by=.01)
GGa &lt;- gamlss.dist::dGG(X, mu=7.4, sigma=0.2, nu=14)
GGb &lt;- pdfgam(X, gg) # We now compare the two densities.
plot( X, GGa, type="l", xlab="X", ylab="PROBABILITY DENSITY", col=3, lwd=6)
lines(X, GGb, col=2, lwd=2) #
## End(Not run)

## Not run: 
# 3-p Generalized Gamma Distribution and gamlss.dist package parameterization
gg &lt;- vec2par(c(1.7, 3, -4), type="gam"); X &lt;- seq(0.04,9, by=.01)
GGa &lt;- gamlss.dist::dGG(X, mu=1.7, sigma=3, nu=-4)
GGb &lt;- pdfgam(X, gg) # We now compare the two densities.
plot( X, GGa, type="l", xlab="X", ylab="PROBABILITY DENSITY", col=3, lwd=6)
lines(X, GGb, col=2, lwd=2) #
## End(Not run)
</code></pre>

<hr>
<h2 id='pdfgep'>Probability Density Function of the Generalized Exponential Poisson Distribution</h2><span id='topic+pdfgep'></span>

<h3>Description</h3>

<p>This function computes the probability density of the Generalized Exponential Poisson distribution given parameters (<code class="reqn">\beta</code>, <code class="reqn">\kappa</code>, and <code class="reqn">h</code>)  computed by <code><a href="#topic+pargep">pargep</a></code>. The probability density function is
</p>
<p style="text-align: center;"><code class="reqn">f(x) = \frac{\kappa h \eta}{[1 - \exp(-h)]^\kappa}{1 - \exp[-h + h\exp(-\eta x)}\times\exp[-h - \eta x + h\exp(-\eta x)]\mbox{,}</code>
</p>

<p>where <code class="reqn">F(x)</code> is the nonexceedance probability for quantile <code class="reqn">x &gt; 0</code>, <code class="reqn">\eta = 1/\beta</code>, <code class="reqn">\beta &gt; 0</code> is a scale parameter, <code class="reqn">\kappa &gt; 0</code> is a shape parameter, and <code class="reqn">h &gt; 0</code> is another shape parameter.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pdfgep(x, para)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pdfgep_+3A_x">x</code></td>
<td>
<p>A real value vector.</p>
</td></tr>
<tr><td><code id="pdfgep_+3A_para">para</code></td>
<td>
<p>The parameters from <code><a href="#topic+pargep">pargep</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Probability density (<code class="reqn">f</code>) for <code class="reqn">x</code>.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Barreto-Souza, W., and Cribari-Neto, F., 2009, A generalization of the exponential-Poisson distribution: Statistics and Probability, 79, pp. 2493&ndash;2500.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pdfgep">pdfgep</a></code>, <code><a href="#topic+quagep">quagep</a></code>, <code><a href="#topic+lmomgep">lmomgep</a></code>, <code><a href="#topic+pargep">pargep</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>pdfgep(0.5, vec2par(c(10,2.9,1.5), type="gep"))
## Not run: 
x &lt;- seq(0,3, by=0.01); ylim &lt;- c(0,1.5)
plot(NA,NA, xlim=range(x), ylim=ylim, xlab="x", ylab="f(x)")
mtext("Barreto-Souza and Cribari-Neto (2009, fig. 1)")
K &lt;- c(0.1, 1, 5, 10)
for(i in 1:length(K)) {
   gep &lt;- vec2par(c(2,K[i],1), type="gep"); lines(x, pdfgep(x, gep), lty=i)
}

## End(Not run)
</code></pre>

<hr>
<h2 id='pdfgev'>Probability Density Function of the Generalized Extreme Value Distribution</h2><span id='topic+pdfgev'></span>

<h3>Description</h3>

<p>This function computes the probability density
of the Generalized Extreme Value distribution given parameters (<code class="reqn">\xi</code>, <code class="reqn">\alpha</code>, and <code class="reqn">\kappa</code>)  computed by <code><a href="#topic+pargev">pargev</a></code>. The probability density function is
</p>
<p style="text-align: center;"><code class="reqn">f(x) = \alpha^{-1} \exp[-(1-\kappa)Y - \exp(-Y)] \mbox{,}</code>
</p>

<p>where <code class="reqn">Y</code> is
</p>
<p style="text-align: center;"><code class="reqn">Y = -\kappa^{-1} \log\!\left(1 - \frac{\kappa(x-\xi)}{\alpha}\right)\mbox{,}</code>
</p>

<p>for <code class="reqn">\kappa \ne 0</code>, and
</p>
<p style="text-align: center;"><code class="reqn">Y = (x-\xi)/\alpha\mbox{,}</code>
</p>

<p>for <code class="reqn">\kappa = 0</code>, where <code class="reqn">f(x)</code> is the probability density for quantile <code class="reqn">x</code>, <code class="reqn">\xi</code> is a location parameter, <code class="reqn">\alpha</code> is a scale parameter, and <code class="reqn">\kappa</code> is a shape parameter. The range of <code class="reqn">x</code> is <code class="reqn">-\infty &lt; x \le \xi + \alpha/\kappa</code> if <code class="reqn">k &gt; 0</code>; <code class="reqn">\xi + \alpha/\kappa \le x &lt; \infty</code> if <code class="reqn">\kappa \le 0</code>. Note that the shape parameter <code class="reqn">\kappa</code> parameterization of the distribution herein follows that in tradition by the greater L-moment community and others use a sign reversal on <code class="reqn">\kappa</code>. (The <span class="pkg">evd</span> package is one example.)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pdfgev(x, para, paracheck=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pdfgev_+3A_x">x</code></td>
<td>
<p>A real value vector.</p>
</td></tr>
<tr><td><code id="pdfgev_+3A_para">para</code></td>
<td>
<p>The parameters from <code><a href="#topic+pargev">pargev</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
<tr><td><code id="pdfgev_+3A_paracheck">paracheck</code></td>
<td>
<p>A logical switch as to whether the validity of the parameters should be checked.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Probability density (<code class="reqn">f</code>) for <code class="reqn">x</code>.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Hosking, J.R.M., 1990, L-moments&mdash;Analysis and estimation of distributions using linear combinations of order statistics: Journal of the Royal Statistical Society, Series B, v. 52, pp. 105&ndash;124, <a href="https://doi.org/10.1111/j.2517-6161.1990.tb01775.x">doi:10.1111/j.2517-6161.1990.tb01775.x</a>.
</p>
<p>Hosking, J.R.M., 1996, FORTRAN routines for use with the method of L-moments: Version 3, IBM Research Report RC20525, T.J. Watson Research Center, Yorktown Heights, New York.
</p>
<p>Hosking, J.R.M. and Wallis, J.R., 1997, Regional frequency analysis&mdash;An approach based on L-moments: Cambridge University Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cdfgev">cdfgev</a></code>, <code><a href="#topic+quagev">quagev</a></code>, <code><a href="#topic+lmomgev">lmomgev</a></code>, <code><a href="#topic+pargev">pargev</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>  lmr &lt;- lmoms(c(123, 34, 4, 654, 37, 78))
  gev &lt;- pargev(lmr)
  x &lt;- quagev(0.5, gev)
       pdfgev(  x, gev)

## Not run: 
  # We explore using maximum likelihood for GEV estimation on its density function.
  # We check the convergence and check on parameters back estimating the mean.
  small &lt;- .Machine$double.eps
  for(k in c(-2, -1/2, -small, 0, +small, 1/2, 2)) {
    names(k) &lt;- "myKappa"
    gev &lt;- vec2par(c(2, 2, k), type="gev")
    x &lt;- rlmomco(1000, gev)
    mu1 &lt;- mean(x); names(mu1) &lt;- "mean"
    cv1 &lt;-      NA; names(cv1) &lt;- "converge"
    mle &lt;- mle2par(x, type="gev", init.para=pargev(lmoms(x)),
             ptransf=function(t) { c(t[1], log(t[2]), t[3]) },
           pretransf=function(t) { c(t[1], exp(t[2]), t[3]) },
                      null.on.not.converge=FALSE)
    mu2 &lt;- lmomgev(mle)$lambdas[1]; names(mu2) &lt;- "backMean"
    cv2 &lt;- mle$optim$convergence;   names(cv2) &lt;- "converge"
    print(round(c(k, cv1, mu1, gev$para), digits=5))
    print(round(c(k, cv2, mu2, mle$para), digits=5))
  } # 
## End(Not run)
</code></pre>

<hr>
<h2 id='pdfgld'>Probability Density Function of the Generalized Lambda Distribution</h2><span id='topic+pdfgld'></span>

<h3>Description</h3>

<p>This function computes the probability density function of the Generalized Lambda distribution given parameters (<code class="reqn">\xi</code>, <code class="reqn">\alpha</code>, <code class="reqn">\kappa</code>, and <code class="reqn">h</code>)  computed by <code><a href="#topic+pargld">pargld</a></code> or similar. The probability density function is
</p>
<p style="text-align: center;"><code class="reqn">f(x) = {[(\kappa[F(x)^{\kappa-1}] + h[1-F(x)])^{h-1})\times\alpha]}^{-1} \mbox{,}</code>
</p>

<p>where <code class="reqn">f(x)</code> is the probability density function at <code class="reqn">x</code>, <code class="reqn">F(x)</code> is the cumulative distribution function at <code class="reqn">x</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pdfgld(x, para, paracheck)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pdfgld_+3A_x">x</code></td>
<td>
<p>A real value vector.</p>
</td></tr>
<tr><td><code id="pdfgld_+3A_para">para</code></td>
<td>
<p>The parameters from <code><a href="#topic+pargld">pargld</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
<tr><td><code id="pdfgld_+3A_paracheck">paracheck</code></td>
<td>
<p>A logical switch as to whether the validity of the parameters should be checked. Default is <code>paracheck=TRUE</code>. This switch is made so that the root solution needed for <code><a href="#topic+cdfgld">cdfgld</a></code> exhibits an extreme speed increase because of the repeated calls to <code><a href="#topic+quagld">quagld</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Probability density (<code class="reqn">f</code>) for <code class="reqn">x</code>.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Asquith, W.H., 2007, L-moments and TL-moments of the generalized lambda distribution: Computational Statistics and Data Analysis, v. 51, no. 9, pp. 4484&ndash;4496.
</p>
<p>Karian, Z.A., and Dudewicz, E.J., 2000, Fitting statistical distributions&mdash;The generalized lambda distribution and generalized bootstrap methods: CRC Press, Boca Raton, FL, 438 p.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cdfgld">cdfgld</a></code>, <code><a href="#topic+quagld">quagld</a></code>, <code><a href="#topic+lmomgld">lmomgld</a></code>, <code><a href="#topic+pargld">pargld</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Using Karian and Dudewicz, 2000, p. 10
gld &lt;- vec2par(c(0.0305,1/1.3673,0.004581,0.01020),type='gld')
quagld(0.25,gld) # which equals about 0.028013 as reported by K&amp;D
pdfgld(0.028013,gld) # which equals about 43.04 as reported by K&amp;D
F &lt;- seq(.001,.999,by=.001)
x &lt;- quagld(F,gld)
plot(x, pdfgld(x,gld), type='l', xlim=c(0,.1))

## End(Not run)
</code></pre>

<hr>
<h2 id='pdfglo'>Probability Density Function of the Generalized Logistic Distribution</h2><span id='topic+pdfglo'></span>

<h3>Description</h3>

<p>This function computes the probability density of the Generalized Logistic distribution given parameters (<code class="reqn">\xi</code>, <code class="reqn">\alpha</code>, and <code class="reqn">\kappa</code>)  computed by <code><a href="#topic+parglo">parglo</a></code>. The probability density function is
</p>
<p style="text-align: center;"><code class="reqn">f(x) = \frac{\alpha^{-1} \exp(-(1-\kappa)Y)}{[1+\exp(-Y)]^2} \mbox{,}</code>
</p>

<p>where <code class="reqn">Y</code> is
</p>
<p style="text-align: center;"><code class="reqn">Y = -\kappa^{-1} \log\left(1 - \frac{\kappa(x-\xi)}{\alpha}\right)
\mbox{,}</code>
</p>

<p>for <code class="reqn">\kappa \ne 0</code>, and
</p>
<p style="text-align: center;"><code class="reqn">Y = (x-\xi)/\alpha\mbox{,}</code>
</p>

<p>for <code class="reqn">\kappa = 0</code>, and where <code class="reqn">f(x)</code> is the probability density for quantile <code class="reqn">x</code>, <code class="reqn">\xi</code> is a location parameter, <code class="reqn">\alpha</code> is a scale parameter, and <code class="reqn">\kappa</code> is a shape parameter.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pdfglo(x, para)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pdfglo_+3A_x">x</code></td>
<td>
<p>A real value vector.</p>
</td></tr>
<tr><td><code id="pdfglo_+3A_para">para</code></td>
<td>
<p>The parameters from <code><a href="#topic+parglo">parglo</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Probability density (<code class="reqn">f</code>) for <code class="reqn">x</code>.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Hosking, J.R.M., 1990, L-moments&mdash;Analysis and estimation of
distributions using linear combinations of order statistics: Journal
of the Royal Statistical Society, Series B, v. 52, pp. 105&ndash;124.
</p>
<p>Hosking, J.R.M., 1996, FORTRAN routines for use with the method of L-moments:
Version 3, IBM Research Report RC20525, T.J. Watson Research Center,
Yorktown Heights, New York.
</p>
<p>Hosking, J.R.M. and Wallis, J.R., 1997, Regional frequency analysis&mdash;An
approach based on L-moments: Cambridge University Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cdfglo">cdfglo</a></code>, <code><a href="#topic+quaglo">quaglo</a></code>, <code><a href="#topic+lmomglo">lmomglo</a></code>, <code><a href="#topic+parglo">parglo</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>  lmr &lt;- lmoms(c(123,34,4,654,37,78))
  glo &lt;- parglo(lmr)
  x &lt;- quaglo(0.5,glo)
  pdfglo(x,glo)
</code></pre>

<hr>
<h2 id='pdfgno'>Probability Density Function of the Generalized Normal Distribution</h2><span id='topic+pdfgno'></span>

<h3>Description</h3>

<p>This function computes the probability density of the Generalized Normal distribution given parameters (<code class="reqn">\xi</code>, <code class="reqn">\alpha</code>, and <code class="reqn">\kappa</code>)  computed by <code><a href="#topic+pargno">pargno</a></code>. The probability density function function is
</p>
<p style="text-align: center;"><code class="reqn">f(x) = \frac{\exp(\kappa Y - Y^2/2)}{\alpha \sqrt{2\pi}} \mbox{,} </code>
</p>

<p>where <code class="reqn">Y</code> is
</p>
<p style="text-align: center;"><code class="reqn">Y = -\kappa^{-1} \log\left(1 - \frac{\kappa(x-\xi)}{\alpha}\right)\mbox{,}</code>
</p>

<p>for <code class="reqn">\kappa \ne 0</code>, and
</p>
<p style="text-align: center;"><code class="reqn">Y = (x-\xi)/\alpha\mbox{,}</code>
</p>

<p>for <code class="reqn">\kappa = 0</code>, where <code class="reqn">f(x)</code> is the probability density for quantile <code class="reqn">x</code>, <code class="reqn">\xi</code> is a location parameter, <code class="reqn">\alpha</code> is a scale parameter, and <code class="reqn">\kappa</code> is a shape parameter.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pdfgno(x, para)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pdfgno_+3A_x">x</code></td>
<td>
<p>A real value vector.</p>
</td></tr>
<tr><td><code id="pdfgno_+3A_para">para</code></td>
<td>
<p>The parameters from <code><a href="#topic+pargno">pargno</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Probability density (<code class="reqn">f</code>) for <code class="reqn">x</code>.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Hosking, J.R.M., 1990, L-moments&mdash;Analysis and estimation of
distributions using linear combinations of order statistics: Journal
of the Royal Statistical Society, Series B, v. 52, pp. 105&ndash;124.
</p>
<p>Hosking, J.R.M., 1996, FORTRAN routines for use with the method of L-moments:
Version 3, IBM Research Report RC20525, T.J. Watson Research Center,
Yorktown Heights, New York.
</p>
<p>Hosking, J.R.M. and Wallis, J.R., 1997, Regional frequency analysis&mdash;An
approach based on L-moments: Cambridge University Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cdfgno">cdfgno</a></code>, <code><a href="#topic+quagno">quagno</a></code>, <code><a href="#topic+lmomgno">lmomgno</a></code>, <code><a href="#topic+pargno">pargno</a></code>, <code><a href="#topic+pdfln3">pdfln3</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  lmr &lt;- lmoms(c(123,34,4,654,37,78))
  gno &lt;- pargno(lmr)
  x &lt;- quagno(0.5,gno)
  pdfgno(x,gno)
</code></pre>

<hr>
<h2 id='pdfgov'>Probability Density Function of the Govindarajulu Distribution</h2><span id='topic+pdfgov'></span>

<h3>Description</h3>

<p>This function computes the probability density of the Govindarajulu distribution given parameters (<code class="reqn">\xi</code>, <code class="reqn">\alpha</code>, and <code class="reqn">\beta</code>)  computed by <code><a href="#topic+pargov">pargov</a></code>. The probability density function is
</p>
<p style="text-align: center;"><code class="reqn">f(x) = [\alpha\beta(\beta+1)]^{-1} [F(x)]^{1-\beta} [1 - F(x)]^{-1} \mbox{,}</code>
</p>

<p>where <code class="reqn">f(x)</code> is the probability density for quantile <code class="reqn">x</code>, <code class="reqn">F(x)</code> the cumulative distribution function  or nonexceedance probability at <code class="reqn">x</code>, <code class="reqn">\xi</code> is a location parameter, <code class="reqn">\alpha</code> is a scale parameter, and <code class="reqn">\beta</code> is a shape parameter.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pdfgov(x, para)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pdfgov_+3A_x">x</code></td>
<td>
<p>A real value vector.</p>
</td></tr>
<tr><td><code id="pdfgov_+3A_para">para</code></td>
<td>
<p>The parameters from <code><a href="#topic+pargov">pargov</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Probability density (<code class="reqn">f</code>) for <code class="reqn">x</code>.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Gilchrist, W.G., 2000, Statistical modelling with quantile functions: Chapman and Hall/CRC, Boca Raton.
</p>
<p>Nair, N.U., Sankaran, P.G., Balakrishnan, N., 2013, Quantile-based reliability analysis: Springer, New York.
</p>
<p>Nair, N.U., Sankaran, P.G., and Vineshkumar, B., 2012, The Govindarajulu distribution&mdash;Some Properties and applications: Communications in Statistics, Theory and Methods, v. 41, no. 24, pp. 4391&ndash;4406.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cdfgov">cdfgov</a></code>, <code><a href="#topic+quagov">quagov</a></code>, <code><a href="#topic+lmomgov">lmomgov</a></code>, <code><a href="#topic+pargov">pargov</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>  lmr &lt;- lmoms(c(123,34,4,654,37,78))
  gov &lt;- pargov(lmr)
  x &lt;- quagov(0.5,gov)
  pdfgov(x,gov)
</code></pre>

<hr>
<h2 id='pdfgpa'>Probability Density Function of the Generalized Pareto Distribution</h2><span id='topic+pdfgpa'></span>

<h3>Description</h3>

<p>This function computes the probability density of the Generalized Pareto distribution given parameters (<code class="reqn">\xi</code>, <code class="reqn">\alpha</code>, and <code class="reqn">\kappa</code>) computed by <code><a href="#topic+pargpa">pargpa</a></code>. The probability density function is
</p>
<p style="text-align: center;"><code class="reqn">f(x) = \alpha^{-1} \exp(-(1-\kappa)Y) \mbox{,}</code>
</p>

<p>where <code class="reqn">Y</code> is
</p>
<p style="text-align: center;"><code class="reqn">Y = -\kappa^{-1} \log\left(1 - \frac{\kappa(x - \xi)}{\alpha}\right)\mbox{,}</code>
</p>

<p>for <code class="reqn">\kappa \ne 0</code>, and
</p>
<p style="text-align: center;"><code class="reqn">Y = (x - \xi)/\alpha\mbox{,}</code>
</p>

<p>for <code class="reqn">\kappa = 0</code>, where <code class="reqn">f(x)</code> is the probability density for quantile <code class="reqn">x</code>, <code class="reqn">\xi</code> is a location parameter, <code class="reqn">\alpha</code> is a scale parameter, and <code class="reqn">\kappa</code> is a shape parameter. The range of <code class="reqn">x</code> is <code class="reqn">\xi \le x \le \xi + \alpha/\kappa</code> if <code class="reqn">k &gt; 0</code>; <code class="reqn">\xi \le x &lt; \infty</code> if <code class="reqn">\kappa \le 0</code>. Note that the shape parameter <code class="reqn">\kappa</code> parameterization of the distribution herein follows that in tradition by the greater L-moment community and others use a sign reversal on <code class="reqn">\kappa</code>. (The <span class="pkg">evd</span> package is one example.)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pdfgpa(x, para, paracheck=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pdfgpa_+3A_x">x</code></td>
<td>
<p>A real value vector.</p>
</td></tr>
<tr><td><code id="pdfgpa_+3A_para">para</code></td>
<td>
<p>The parameters from <code><a href="#topic+pargpa">pargpa</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
<tr><td><code id="pdfgpa_+3A_paracheck">paracheck</code></td>
<td>
<p>A logical switch as to whether the validity of the parameters should be checked.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Probability density (<code class="reqn">f</code>) for <code class="reqn">x</code>.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Hosking, J.R.M., 1990, L-moments&mdash;Analysis and estimation of distributions using linear combinations of order statistics: Journal of the Royal Statistical Society, Series B, v. 52, pp. 105&ndash;124, <a href="https://doi.org/10.1111/j.2517-6161.1990.tb01775.x">doi:10.1111/j.2517-6161.1990.tb01775.x</a>.
</p>
<p>Hosking, J.R.M., 1996, FORTRAN routines for use with the method of L-moments: Version 3, IBM Research Report RC20525, T.J. Watson Research Center, Yorktown Heights, New York.
</p>
<p>Hosking, J.R.M. and Wallis, J.R., 1997, Regional frequency analysis&mdash;An approach based on L-moments: Cambridge University Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cdfgpa">cdfgpa</a></code>, <code><a href="#topic+quagpa">quagpa</a></code>, <code><a href="#topic+lmomgpa">lmomgpa</a></code>, <code><a href="#topic+pargpa">pargpa</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>  lmr &lt;- lmoms(c(123, 34, 4, 654, 37, 78))
  gpa &lt;- pargpa(lmr)
  x   &lt;- quagpa(0.5, gpa)
         pdfgpa(  x, gpa)

## Not run: 
  # We explore using maximum likelihood for GPA estimation on its density function
  # with stress testing near the K &gt; -1 lower limit, K near zero, and then large K
  # producing extreme densities. We check the convergence and check on parameters
  # back estimating the mean. The experiment is designed that with repeated
  # operations that convergence "failures" in stats::optim()
  #   1  'indicates that the iteration limit maxit had been reached'
  #   10 'indicates degeneracy of the Nelder-Mead simplex.'
  # With the 10 being a bit more common and 1 but still for many runs convergence
  # at K = 8 is still attainable. Also, note the care in the construction of the
  # ptransf and pretransf for the honoring the GPA parameter space.
  small &lt;- .Machine$double.eps; n &lt;- 1000 # samples
  for(k in c(-1+small, -0.99, -1/2, -small, 0, 1/2, 8)) {
    names(k) &lt;- "myKappa"
    gpa &lt;- vec2par(c(2, 2, k), type="gpa")
    x &lt;- rlmomco(n, gpa)
    mu1 &lt;- mean(x); names(mu1) &lt;- "mean"
    cv1 &lt;-      NA; names(cv1) &lt;- "converge"
    mle &lt;- mle2par(x, type="gpa", init.para=pargpa(lmoms(x)),
             ptransf=function(t) { c(t[1], log(t[2]), log(t[3] +1)) },
           pretransf=function(t) { c(t[1], exp(t[2]), exp(t[3])-1)  },
                      null.on.not.converge=FALSE)
    mu2 &lt;- lmomgpa(mle)$lambdas[1]; names(mu2) &lt;- "backMean"
    cv2 &lt;- mle$optim$convergence;   names(cv2) &lt;- "converge"
    print(round(c(k, cv1, mu1, gpa$para), digits=5))
    print(round(c(k, cv2, mu2, mle$para), digits=5))
  } # 
## End(Not run)
</code></pre>

<hr>
<h2 id='pdfgum'>Probability Density Function of the Gumbel Distribution</h2><span id='topic+pdfgum'></span>

<h3>Description</h3>

<p>This function computes the probability density
of the Gumbel distribution given parameters (<code class="reqn">\xi</code> and <code class="reqn">\alpha</code>)  computed by <code><a href="#topic+pargum">pargum</a></code>. The probability density function is
</p>
<p style="text-align: center;"><code class="reqn">f(x) = \alpha^{-1} \exp(Y)\,\exp[-\exp(Y)]\mbox{,}</code>
</p>

<p>where
</p>
<p style="text-align: center;"><code class="reqn">Y = -\frac{x - \xi}{\alpha} \mbox{,}</code>
</p>

<p>where <code class="reqn">f(x)</code> is the nonexceedance probability for quantile <code class="reqn">x</code>,
<code class="reqn">\xi</code> is a location parameter, and <code class="reqn">\alpha</code> is a scale parameter.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pdfgum(x, para)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pdfgum_+3A_x">x</code></td>
<td>
<p>A real value vector.</p>
</td></tr>
<tr><td><code id="pdfgum_+3A_para">para</code></td>
<td>
<p>The parameters from <code><a href="#topic+pargum">pargum</a></code> or <code>vec2par</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Probability density (<code class="reqn">f</code>) for <code class="reqn">x</code>.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Hosking, J.R.M., 1990, L-moments&mdash;Analysis and estimation of
distributions using linear combinations of order statistics: Journal
of the Royal Statistical Society, Series B, v. 52, pp. 105&ndash;124.
</p>
<p>Hosking, J.R.M., 1996, FORTRAN routines for use with the method of L-moments:
Version 3, IBM Research Report RC20525, T.J. Watson Research Center,
Yorktown Heights, New York.
</p>
<p>Hosking, J.R.M. and Wallis, J.R., 1997, Regional frequency analysis&mdash;An
approach based on L-moments: Cambridge University Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cdfgum">cdfgum</a></code>, <code><a href="#topic+quagum">quagum</a></code>, <code><a href="#topic+lmomgum">lmomgum</a></code>, <code><a href="#topic+pargum">pargum</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>  lmr &lt;- lmoms(c(123,34,4,654,37,78))
  gum &lt;- pargum(lmr)
  x &lt;- quagum(0.5,gum)
  pdfgum(x,gum)
</code></pre>

<hr>
<h2 id='pdfkap'>Probability Density Function of the Kappa Distribution</h2><span id='topic+pdfkap'></span>

<h3>Description</h3>

<p>This function computes the probability density of the Kappa distribution given parameters (<code class="reqn">\xi</code>, <code class="reqn">\alpha</code>, <code class="reqn">\kappa</code>, and <code class="reqn">h</code>)  computed by <code><a href="#topic+parkap">parkap</a></code>. The probability density function is
</p>
<p style="text-align: center;"><code class="reqn">f(x) = \alpha^{-1} [1-\kappa(x - \xi)/\alpha]^{1/k-1} \times [F(x)]^{1-h}</code>
</p>

<p>where <code class="reqn">f(x)</code> is the probability density for quantile <code class="reqn">x</code>, <code class="reqn">F(x)</code> is the cumulative distribution function  or nonexceedance probability at <code class="reqn">x</code>, <code class="reqn">\xi</code> is a location parameter, <code class="reqn">\alpha</code> is a scale parameter, and <code class="reqn">\kappa</code> is a shape parameter.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pdfkap(x, para)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pdfkap_+3A_x">x</code></td>
<td>
<p>A real value vector.</p>
</td></tr>
<tr><td><code id="pdfkap_+3A_para">para</code></td>
<td>
<p>The parameters from <code><a href="#topic+parkap">parkap</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Probability density (<code class="reqn">f</code>) for <code class="reqn">x</code>.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Hosking, J.R.M. and Wallis, J.R., 1997, Regional frequency analysis&mdash;An
approach based on L-moments: Cambridge University Press.
</p>
<p>Sourced from written communication with Dr. Hosking in October 2007.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cdfkap">cdfkap</a></code>, <code><a href="#topic+quakap">quakap</a></code>, <code><a href="#topic+lmomkap">lmomkap</a></code>, <code><a href="#topic+parkap">parkap</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>kap &lt;- vec2par(c(1000,15000,0.5,-0.4),type='kap')
F &lt;- nonexceeds()
x &lt;- quakap(F,kap)
check.pdf(pdfkap,kap,plot=TRUE)
</code></pre>

<hr>
<h2 id='pdfkmu'>Probability Density Function of the Kappa-Mu Distribution</h2><span id='topic+pdfkmu'></span>

<h3>Description</h3>

<p>This function computes the probability density
of the Kappa-Mu (<code class="reqn">\kappa:\mu</code>) distribution given parameters (<code class="reqn">\kappa</code> and <code class="reqn">\mu</code>)  computed by <code><a href="#topic+parkmu">parkmu</a></code>. The probability density function  is
</p>
<p style="text-align: center;"><code class="reqn">
f(x) = \frac{2\mu(1+\kappa)^{(\mu + 1)/2}}{\kappa^{(\mu-1)/2}\mathrm{exp}(\mu\kappa)}\,x^\mu\,\exp(-\mu(1+\kappa)x^2)\,I_{\mu - 1}(2\mu\sqrt{\kappa(1+\kappa)}x)\mbox{,}
</code>
</p>

<p>where <code class="reqn">f(x)</code> is the nonexceedance probability for quantile <code class="reqn">x</code>, and the modified Bessel function of the first kind is <code class="reqn">I_k(x)</code>, and define <code class="reqn">m</code> as
</p>
<p style="text-align: center;"><code class="reqn">m = \frac{\mu(1+\kappa)^2}{1+2\kappa}\mbox{.}</code>
</p>

<p>and for a given <code class="reqn">m</code>, the new parameter <code class="reqn">\mu</code> must lie in the range
</p>
<p style="text-align: center;"><code class="reqn">0 \le \mu \le m\mbox{.}</code>
</p>

<p>The definition of <code class="reqn">I_k(x)</code> is seen under <code><a href="#topic+pdfemu">pdfemu</a></code>. Lastly, if <code class="reqn">\kappa = \infty</code>, then there is a Dirca Delta function of probability at <code class="reqn">x=0</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pdfkmu(x, para, paracheck=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pdfkmu_+3A_x">x</code></td>
<td>
<p>A real value vector.</p>
</td></tr>
<tr><td><code id="pdfkmu_+3A_para">para</code></td>
<td>
<p>The parameters from <code><a href="#topic+parkmu">parkmu</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
<tr><td><code id="pdfkmu_+3A_paracheck">paracheck</code></td>
<td>
<p>A logical controlling whether the parameters and checked for validity.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Probability density (<code class="reqn">f</code>) for <code class="reqn">x</code>.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Yacoub, M.D., 2007, The kappa-mu distribution and the eta-mu distribution: IEEE Antennas and Propagation Magazine, v. 49, no. 1, pp. 68&ndash;81
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cdfkmu">cdfkmu</a></code>, <code><a href="#topic+quakmu">quakmu</a></code>, <code><a href="#topic+lmomkmu">lmomkmu</a></code>, <code><a href="#topic+parkmu">parkmu</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
x &lt;- seq(0,4, by=.1)
para &lt;- vec2par(c(.5, 1.4), type="kmu")
F &lt;- cdfkmu(x, para)
X &lt;- quakmu(F, para, quahi=pi)
plot(F, X, type="l", lwd=8)
lines(F, x, col=2)

## End(Not run)
## Not run: 
# Note that in this example very delicate steps are taken to show
# how one interacts with the Dirac Delta function (x=0) when the m
# is known but mu == 0. For x=0, the fraction of total probability
# is recorded, but when one is doing numerical summation to evaluate
# whether the total probability under the PDF is unity some algebraic
# manipulations are needed as shown for the conditional when kappa
# is infinity.

delx &lt;- 0.001
x &lt;- seq(0,3, by=delx)

plot(c(0,3), c(0,1), xlab="RHO", ylab="pdfkmu(RHO)", type="n")
m &lt;- 1.25
mus &lt;- c(0.25, 0.50, 0.75, 1, 1.25, 0)
for(mu in mus) {
   kappa &lt;- m/mu - 1 + sqrt((m/mu)*((m/mu)-1))
   para &lt;- vec2par(c(kappa, mu), type="kmu")
   if(! is.finite(kappa)) {
      para &lt;- vec2par(c(Inf,m), type="kmu")
      density &lt;- pdfkmu(x, para)
      lines(x, density, col=2, lwd=3)
      dirac &lt;- 1/delx - sum(density[x != 0])
      cumulant &lt;- (sum(density) + density[1]*(1/delx - 1))*delx
      density[x == 0] &lt;- rep(dirac, length(density[x == 0]))
      message("Total integrated probability is ", cumulant, "\n")
   }
   lines(x, pdfkmu(x, para))
}
mtext("Yacoub (2007, figure 3)")

## End(Not run)
</code></pre>

<hr>
<h2 id='pdfkur'>Probability Density Function of the Kumaraswamy Distribution</h2><span id='topic+pdfkur'></span>

<h3>Description</h3>

<p>This function computes the probability density
of the Kumaraswamy distribution given parameters (<code class="reqn">\alpha</code> and <code class="reqn">\beta</code>)  computed by <code><a href="#topic+parkur">parkur</a></code>. The probability density function is
</p>
<p style="text-align: center;"><code class="reqn">f(x) = \alpha\beta x^{\alpha - 1}(1-x^\alpha)^{\beta-1} \mbox{,}</code>
</p>

<p>where <code class="reqn">f(x)</code> is the nonexceedance probability for quantile <code class="reqn">x</code>,
<code class="reqn">\alpha</code> is a shape parameter, and <code class="reqn">\beta</code> is a shape parameter.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pdfkur(x, para)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pdfkur_+3A_x">x</code></td>
<td>
<p>A real value vector.</p>
</td></tr>
<tr><td><code id="pdfkur_+3A_para">para</code></td>
<td>
<p>The parameters from <code><a href="#topic+parkur">parkur</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Probability density (<code class="reqn">f</code>) for <code class="reqn">x</code>.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Jones, M.C., 2009, Kumaraswamy's distribution&mdash;A beta-type distribution with
some tractability advantages: Statistical Methodology, v. 6, pp. 70&ndash;81.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cdfkur">cdfkur</a></code>, <code><a href="#topic+quakur">quakur</a></code>, <code><a href="#topic+lmomkur">lmomkur</a></code>, <code><a href="#topic+parkur">parkur</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>  lmr &lt;- lmoms(c(0.25, 0.4, 0.6, 0.65, 0.67, 0.9))
  kur &lt;- parkur(lmr)
  x &lt;- quakur(0.5,kur)
  pdfkur(x,kur)
</code></pre>

<hr>
<h2 id='pdflap'>Probability Density Function of the Laplace Distribution</h2><span id='topic+pdflap'></span>

<h3>Description</h3>

<p>This function computes the probability density of the Laplace distribution given parameters (<code class="reqn">\xi</code> and <code class="reqn">\alpha</code>)  computed by <code><a href="#topic+parlap">parlap</a></code>. The probability density function is
</p>
<p style="text-align: center;"><code class="reqn">f(x) = (2\alpha)^{-1} \exp(Y)\mbox{,}</code>
</p>

<p>where <code class="reqn">Y</code> is
</p>
<p style="text-align: center;"><code class="reqn">Y = \left(\frac{-|x - \xi|}{\alpha}\right)\mbox{.}</code>
</p>



<h3>Usage</h3>

<pre><code class='language-R'>pdflap(x, para)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pdflap_+3A_x">x</code></td>
<td>
<p>A real value vector.</p>
</td></tr>
<tr><td><code id="pdflap_+3A_para">para</code></td>
<td>
<p>The parameters from <code><a href="#topic+parlap">parlap</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Probability density (<code class="reqn">f</code>) for <code class="reqn">x</code>.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Hosking, J.R.M., 1986, The theory of probability weighted moments: IBM Research Report RC12210, T.J. Watson Research Center, Yorktown Heights, New York.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cdflap">cdflap</a></code>, <code><a href="#topic+qualap">qualap</a></code>, <code><a href="#topic+lmomlap">lmomlap</a></code>, <code><a href="#topic+parlap">parlap</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>  lmr &lt;- lmoms(c(123,34,4,654,37,78))
  lap &lt;- parlap(lmr)
  x &lt;- qualap(0.5,lap)
  pdflap(x,lap)
</code></pre>

<hr>
<h2 id='pdflmrq'>Probability Density Function of the Linear Mean Residual Quantile Function Distribution
</h2><span id='topic+pdflmrq'></span>

<h3>Description</h3>

<p>This function computes the probability density function of the Linear Mean Residual Quantile Function distribution given parameters  computed by <code><a href="#topic+parlmrq">parlmrq</a></code>.  The probability density function is
</p>
<p style="text-align: center;"><code class="reqn">f(x) = \frac{1 - F(x)}{2\alpha\,F(x) + (\mu - \alpha)}\mbox{,}</code>
</p>

<p>where <code class="reqn">f(x)</code> is the nonexceedance probability for quantile <code class="reqn">x</code>, <code class="reqn">F(x)</code> is the cumulative distribution function or nonexceedance probability at <code class="reqn">x</code>, <code class="reqn">\mu</code> is a location parameter, and <code class="reqn">\alpha</code> is a scale parameter.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pdflmrq(x, para)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pdflmrq_+3A_x">x</code></td>
<td>
<p>A real value vector.</p>
</td></tr>
<tr><td><code id="pdflmrq_+3A_para">para</code></td>
<td>
<p>The parameters from <code><a href="#topic+parlmrq">parlmrq</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Probability density (<code class="reqn">f</code>) for <code class="reqn">x</code>.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Midhu, N.N., Sankaran, P.G., and Nair, N.U., 2013, A class of distributions with linear mean residual quantile function and it's generalizations: Statistical Methodology, v. 15, pp. 1&ndash;24.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cdflmrq">cdflmrq</a></code>, <code><a href="#topic+qualmrq">qualmrq</a></code>, <code><a href="#topic+lmomlmrq">lmomlmrq</a></code>, <code><a href="#topic+parlmrq">parlmrq</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>lmr &lt;- lmoms(c(3, 0.05, 1.6, 1.37, 0.57, 0.36, 2.2))
pdflmrq(3,parlmrq(lmr))
## Not run: 
para.lmrq &lt;- list(para=c(2.1043, 0.4679), type="lmrq")
para.wei  &lt;- vec2par(c(0,2,0.9), type="wei") # note switch from Midhu et al. ordering.
F &lt;- seq(0.01,0.99,by=.01); x &lt;- qualmrq(F, para.lmrq)
plot(x, pdflmrq(x, para.lmrq), type="l", ylab="", lwd=2, lty=2, col=2,
     xlab="The p.d.f. of Weibull and p.d.f. of LMRQD", xaxs="i", yaxs="i",
     xlim=c(0,9), ylim=c(0,0.8))
lines(x, pdfwei(x, para.wei))
mtext("Midhu et al. (2013, Statis. Meth.)")

## End(Not run)
</code></pre>

<hr>
<h2 id='pdfln3'>Probability Density Function of the 3-Parameter Log-Normal Distribution</h2><span id='topic+pdfln3'></span>

<h3>Description</h3>

<p>This function computes the probability density
of the Log-Normal3 distribution given parameters (<code class="reqn">\zeta</code>, lower bounds; <code class="reqn">\mu_{\mathrm{log}}</code>, location; and <code class="reqn">\sigma_{\mathrm{log}}</code>, scale)  computed by <code><a href="#topic+parln3">parln3</a></code>. The probability density function function (same as Generalized Normal distribution, <code><a href="#topic+pdfgno">pdfgno</a></code>) is
</p>
<p style="text-align: center;"><code class="reqn">f(x) = \frac{\exp(\kappa Y - Y^2/2)}{\alpha \sqrt{2\pi}} \mbox{,} </code>
</p>

<p>where <code class="reqn">Y</code> is
</p>
<p style="text-align: center;"><code class="reqn">
Y = \frac{\log(x - \zeta) - \mu_{\mathrm{log}}}{\sigma_{\mathrm{log}}}\mbox{,}
</code>
</p>

<p>where <code class="reqn">\zeta</code> is the lower bounds (real space) for which <code class="reqn">\zeta &lt; \lambda_1 - \lambda_2</code> (checked in <code><a href="#topic+are.parln3.valid">are.parln3.valid</a></code>), <code class="reqn">\mu_{\mathrm{log}}</code> be the mean in natural logarithmic space, and <code class="reqn">\sigma_{\mathrm{log}}</code> be the standard deviation in natural logarithm space for which <code class="reqn">\sigma_{\mathrm{log}} &gt; 0</code> (checked in <code><a href="#topic+are.parln3.valid">are.parln3.valid</a></code>) is obvious because this parameter has an analogy to the second product moment. Letting <code class="reqn">\eta = \exp(\mu_{\mathrm{log}})</code>, the parameters of the Generalized Normal are <code class="reqn">\zeta + \eta</code>, <code class="reqn">\alpha = \eta\sigma_{\mathrm{log}}</code>, and <code class="reqn">\kappa = -\sigma_{\mathrm{log}}</code>. At this point, the algorithms (<code><a href="#topic+pdfgno">pdfgno</a></code>) for the Generalized Normal provide the functional core.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pdfln3(x, para)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pdfln3_+3A_x">x</code></td>
<td>
<p>A real value vector.</p>
</td></tr>
<tr><td><code id="pdfln3_+3A_para">para</code></td>
<td>
<p>The parameters from <code><a href="#topic+parln3">parln3</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Probability density (<code class="reqn">f</code>) for <code class="reqn">x</code>.
</p>


<h3>Note</h3>

<p>The parameterization of the Log-Normal3 results in ready support for either a known or unknown lower bounds. Details regarding the parameter fitting and control of the <code class="reqn">\zeta</code> parameter can be seen under the Details section in <code><a href="#topic+parln3">parln3</a></code>.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Asquith, W.H., 2011, Distributional analysis with L-moment statistics using the R environment for statistical computing: Createspace Independent Publishing Platform, ISBN 978&ndash;146350841&ndash;8.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cdfln3">cdfln3</a></code>, <code><a href="#topic+qualn3">qualn3</a></code>, <code><a href="#topic+lmomln3">lmomln3</a></code>, <code><a href="#topic+parln3">parln3</a></code>, <code><a href="#topic+pdfgno">pdfgno</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>  lmr &lt;- lmoms(c(123,34,4,654,37,78))
  ln3 &lt;- parln3(lmr); gno &lt;- pargno(lmr)
  x &lt;- qualn3(0.5,ln3)
  pdfln3(x,ln3) # 0.008053616
  pdfgno(x,gno) # 0.008053616 (the distributions are the same, but see Note)
</code></pre>

<hr>
<h2 id='pdfnor'>Probability Density Function of the Normal Distribution</h2><span id='topic+pdfnor'></span>

<h3>Description</h3>

<p>This function computes the probability density function
of the Normal distribution given parameters  computed
by <code><a href="#topic+parnor">parnor</a></code>.  The probability density function is
</p>
<p style="text-align: center;"><code class="reqn">f(x) = \frac{1}{\sigma \sqrt{2\pi}} \exp\!\left(\frac{-(x-\mu)^2}{2\sigma^2}\right) \mbox{,}</code>
</p>

<p>where <code class="reqn">f(x)</code> is the probability density for quantile <code class="reqn">x</code>, <code class="reqn">\mu</code> is the arithmetic mean, and <code class="reqn">\sigma</code> is the standard deviation. The <span class="rlang"><b>R</b></span> function <code>pnorm</code> is used.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pdfnor(x, para)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pdfnor_+3A_x">x</code></td>
<td>
<p>A real value.</p>
</td></tr>
<tr><td><code id="pdfnor_+3A_para">para</code></td>
<td>
<p>The parameters from <code><a href="#topic+parnor">parnor</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Probability density (<code class="reqn">f</code>) for <code class="reqn">x</code>.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Hosking, J.R.M., 1990, L-moments&mdash;Analysis and estimation of
distributions using linear combinations of order statistics: Journal
of the Royal Statistical Society, Series B, v. 52, pp. 105&ndash;124.
</p>
<p>Hosking, J.R.M., 1996, FORTRAN routines for use with the method of L-moments:
Version 3, IBM Research Report RC20525, T.J. Watson Research Center,
Yorktown Heights, New York.
</p>
<p>Hosking, J.R.M., and Wallis, J.R., 1997, Regional frequency analysis&mdash;An
approach based on L-moments: Cambridge University Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cdfnor">cdfnor</a></code>, <code><a href="#topic+quanor">quanor</a></code>, <code><a href="#topic+lmomnor">lmomnor</a></code>, <code><a href="#topic+parnor">parnor</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>  lmr &lt;- lmoms(c(123,34,4,654,37,78))
  pdfnor(50,parnor(lmr))
</code></pre>

<hr>
<h2 id='pdfpdq3'>Probability Density Function of the Polynomial Density-Quantile3 Distribution</h2><span id='topic+pdfpdq3'></span>

<h3>Description</h3>

<p>This function computes the probability density of the Polynomial Density-Quantile3 distribution given parameters (<code class="reqn">\alpha</code> and <code class="reqn">\beta</code>)  computed by <code><a href="#topic+parpdq3">parpdq3</a></code>. The probability density function has not explicit form. The implementation here simply uses a <em>five-point stencil</em> to approciate the derivative of the cumulative distribution function <code><a href="#topic+cdfpdq3">cdfpdq3</a></code> and hence an <code>eps</code> term is used and multipled to the scale parameter (<code class="reqn">\alpha</code>) of the distribution. The distribution's canonical definition is in terms of the quantile function (<code><a href="#topic+quapdq3">quapdq3</a></code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pdfpdq3(x, para, paracheck=TRUE, h=NA, hfactor=0.2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pdfpdq3_+3A_x">x</code></td>
<td>
<p>A real value vector.</p>
</td></tr>
<tr><td><code id="pdfpdq3_+3A_para">para</code></td>
<td>
<p>The parameters from <code><a href="#topic+parpdq4">parpdq4</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
<tr><td><code id="pdfpdq3_+3A_paracheck">paracheck</code></td>
<td>
<p>A logical switch as to whether the validity of the parameters should be checked. Default is <code>paracheck=TRUE</code>. This switch is made so that the root solution needed for <code><a href="#topic+cdfpdq3">cdfpdq3</a></code> shows an extreme speed increase because of the repeated calls to <code>quapdq3</code>.</p>
</td></tr>
<tr><td><code id="pdfpdq3_+3A_h">h</code></td>
<td>
<p>The differential element of the stencil, if provided, otherwise <code>hfactor</code> used.</p>
</td></tr>
<tr><td><code id="pdfpdq3_+3A_hfactor">hfactor</code></td>
<td>
<p>A term multiplied to the <code class="reqn">\alpha</code> parameter to set the <code class="reqn">h</code> in the numerical derivative. Not optimal, but seems to work for a variety of chosen parameters for plotting the density function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Probability density (<code class="reqn">f</code>) for <code class="reqn">x</code>.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Hosking, J.R.M., 2007, Distributions with maximum entropy subject to
constraints on their L-moments or expected order statistics: Journal of
Statistical Planning and Inference, v. 137, no. 9, pp. 2870&ndash;2891, <a href="https://doi.org/10.1016/j.jspi.2006.10.010">doi:10.1016/j.jspi.2006.10.010</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cdfpdq3">cdfpdq3</a></code>, <code><a href="#topic+quapdq3">quapdq3</a></code>, <code><a href="#topic+lmompdq3">lmompdq3</a></code>, <code><a href="#topic+parpdq3">parpdq3</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
  para &lt;- list(para=c(0.6933, 1.5495, 0.5488), type="pdq3")
  X &lt;- seq(-5, +12, by=(12 - -5) / 1000)
  plot( X, pdfpdq3(X, para), type="l", col=grey(0.8), lwd=4, ylim=c(0, 0.3))
  lines(X, c(NA, diff(pf(exp(X), df1=7, df2=1))/((12 - -5) / 1000)), lty=2)
  legend("topleft", c("log F(7,1) distribution with same L-moments",
                      "PDQ3 distribution with same L-moments as the log F(7,1)"),
                    lwd=c(1, 4), lty=c(2, 1), col=c(1, grey(0.8)), cex=0.8)
  mtext("Mimic Hosking (2007, fig. 2 [left])")
  check.pdf(pdfpdq3, para) # 
## End(Not run)

## Not run: 
  para &lt;- list(para=c(100, 43.32, -0.7029), type="pdq3")
  minX &lt;- quapdq3(0.0001, para)
  maxX &lt;- quapdq3(0.9999, para)
  X &lt;- seq(minX, maxX, by=(maxX - minX) / 1000)
  plot( X, pdfpdq3(X, para), type="l", col=grey(0.8), lwd=4)
  check.pdf(pdfpdq3, para) # 
## End(Not run)

## Not run: 
  para &lt;- vec2par(c(0.4729820, 3.0242067, 0.9880701), type="pdq3")
  print(lmom2par(par2lmom(para), type="pdq3"))
  # "|kappa| &gt; 0.98, alpha (yes alpha) results could be unreliable"
  # So, we are entering into a problem for which the kappa parameter is
  # very large and instabilities in the algorithm will result, but
  # vec2par() has not mechanism for determining this type of situation.
  # Ultimately, things will manifest with a check.pdf() that fails.
  sup &lt;- lmomco::supdist(para)$support
  xx &lt;- seq(sup[1], sup[2], by=diff(range(sup)) / 2000)
  plot(xx, pdfpdq3(xx, para), type="l", col=grey(0.8))
  plot(xx, pdfpdq3(xx, para), type="l", col=grey(0.8), xlim=c(-1,10))
  # See hints of instability in the density shape in the second plot
  check.pdf(pdfpdq3, para) # non-finite function value 
## End(Not run)
</code></pre>

<hr>
<h2 id='pdfpdq4'>Probability Density Function of the Polynomial Density-Quantile4 Distribution</h2><span id='topic+pdfpdq4'></span>

<h3>Description</h3>

<p>This function computes the probability density of the Polynomial Density-Quantile4 distribution given parameters (<code class="reqn">\alpha</code> and <code class="reqn">\beta</code>) computed by <code><a href="#topic+parpdq4">parpdq4</a></code>. The probability density function has not explicit form. The implementation here simply uses a <em>five-point stencil</em> to approciate the derivative of the cumulative distribution function <code><a href="#topic+cdfpdq4">cdfpdq4</a></code> and hence an <code>eps</code> term is used and multipled to the scale parameter (<code class="reqn">\alpha</code>) of the distribution. The distribution's canonical definition is in terms of the quantile function (<code><a href="#topic+quapdq4">quapdq4</a></code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pdfpdq4(x, para, paracheck=TRUE, h=NA, hfactor=0.2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pdfpdq4_+3A_x">x</code></td>
<td>
<p>A real value vector.</p>
</td></tr>
<tr><td><code id="pdfpdq4_+3A_para">para</code></td>
<td>
<p>The parameters from <code><a href="#topic+parpdq4">parpdq4</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
<tr><td><code id="pdfpdq4_+3A_paracheck">paracheck</code></td>
<td>
<p>A logical switch as to whether the validity of the parameters should be checked. Default is <code>paracheck=TRUE</code>. This switch is made so that the root solution needed for <code><a href="#topic+cdfpdq4">cdfpdq4</a></code> shows an extreme speed increase because of the repeated calls to <code>quapdq4</code>.</p>
</td></tr>
<tr><td><code id="pdfpdq4_+3A_h">h</code></td>
<td>
<p>The differential element of the stencil, if provided, otherwise <code>hfactor</code> used.</p>
</td></tr>
<tr><td><code id="pdfpdq4_+3A_hfactor">hfactor</code></td>
<td>
<p>A term multiplied to the <code class="reqn">\alpha</code> parameter to set the <code class="reqn">h</code> in the numerical derivative. Not optimal, but seems to work for a variety of chosen parameters for plotting the density function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Probability density (<code class="reqn">f</code>) for <code class="reqn">x</code>.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Hosking, J.R.M., 2007, Distributions with maximum entropy subject to constraints on their L-moments or expected order statistics: Journal of Statistical Planning and Inference, v. 137, no. 9, pp. 2870&ndash;2891, <a href="https://doi.org/10.1016/j.jspi.2006.10.010">doi:10.1016/j.jspi.2006.10.010</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cdfpdq4">cdfpdq4</a></code>, <code><a href="#topic+quapdq4">quapdq4</a></code>, <code><a href="#topic+lmompdq4">lmompdq4</a></code>, <code><a href="#topic+parpdq4">parpdq4</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
  para &lt;- list(para=c(0, 0.4332, -0.7029), type="pdq4")
  X &lt;- seq(-4, +4, by=(4 - -4) / 1000)
  plot( X, pdfpdq4(X, para), type="l", col=grey(0.8), lwd=4, ylim=c(0, 0.5))
  lines(X, dnorm(  X, sd=1), lty=2)
  legend("topleft", c("Standard normal distribution",
                      "PDQ4 distribution with same L-moments as the standard normal"),
                    lwd=c(1, 4), lty=c(2, 1), col=c(1, grey(0.8)), cex=0.8)
  mtext("Mimic Hosking (2007, fig. 3 [left])")
  check.pdf(pdfpdq4, para, hfactor=0.3) 
## End(Not run)

## Not run: 
  para &lt;- list(para=c(100, 43.32, -0.7029), type="pdq4")
  minX &lt;- quapdq4(0.0001, para)
  maxX &lt;- quapdq4(0.9999, para)
  X &lt;- seq(minX, maxX, by=(maxX - minX) / 1000)
  plot( X, pdfpdq4(X, para), type="l", col=grey(0.8), lwd=4)

  check.pdf(pdfpdq4, para, hfactor=0.3) 
## End(Not run)
</code></pre>

<hr>
<h2 id='pdfpe3'>Probability Density Function of the Pearson Type III Distribution</h2><span id='topic+pdfpe3'></span>

<h3>Description</h3>

<p>This function computes the probability density of the Pearson Type III distribution given parameters (<code class="reqn">\mu</code>, <code class="reqn">\sigma</code>, and <code class="reqn">\gamma</code>)  computed by <code><a href="#topic+parpe3">parpe3</a></code>. These parameters are equal to the product moments (<code><a href="#topic+pmoms">pmoms</a></code>): mean, standard deviation, and skew. The probability density function for <code class="reqn">\gamma \ne 0</code> is
</p>
<p style="text-align: center;"><code class="reqn">f(x) = \frac{Y^{\alpha -1} \exp({-Y/\beta})}
                  {\beta^\alpha\, \Gamma(\alpha)} \mbox{,}</code>
</p>

<p>where <code class="reqn">f(x)</code> is the probability density for quantile <code class="reqn">x</code>, <code class="reqn">\Gamma</code> is the complete gamma function in <span class="rlang"><b>R</b></span> as <code>gamma</code>,
<code class="reqn">\xi</code> is a location parameter, <code class="reqn">\beta</code> is a scale parameter,
<code class="reqn">\alpha</code> is a shape parameter, and <code class="reqn">Y = x - \xi</code> for <code class="reqn">\gamma &gt; 0</code> and <code class="reqn">Y = \xi - x</code> for <code class="reqn">\gamma &lt; 0</code>. These three &ldquo;new&rdquo; parameters are related to the product moments (<code class="reqn">\mu</code>, mean; <code class="reqn">\sigma</code>, standard deviation; <code class="reqn">\gamma</code>, skew) by
</p>
<p style="text-align: center;"><code class="reqn">\alpha = 4/\gamma^2 \mbox{,}</code>
</p>

<p style="text-align: center;"><code class="reqn">\beta  = \frac{1}{2}\sigma |\gamma| \mbox{,\ and}</code>
</p>

<p style="text-align: center;"><code class="reqn">\xi = \mu - 2\sigma/\gamma \mbox{.}</code>
</p>

<p>If <code class="reqn">\gamma = 0</code>, the distribution is symmetrical and simply is the probability density Normal distribution with mean and standard deviation of <code class="reqn">\mu</code> and <code class="reqn">\sigma</code>, respectively. Internally, the <code class="reqn">\gamma = 0</code> condition is implemented by <span class="rlang"><b>R</b></span> function <code>dnorm</code>. The <span class="pkg">PearsonDS</span> package supports the Pearson distribution system including the Type III (see <b>Examples</b>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pdfpe3(x, para)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pdfpe3_+3A_x">x</code></td>
<td>
<p>A real value vector.</p>
</td></tr>
<tr><td><code id="pdfpe3_+3A_para">para</code></td>
<td>
<p>The parameters from <code><a href="#topic+parpe3">parpe3</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Probability density (<code class="reqn">f</code>) for <code class="reqn">x</code>.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Hosking, J.R.M., 1990, L-moments&mdash;Analysis and estimation of
distributions using linear combinations of order statistics: Journal
of the Royal Statistical Society, Series B, v. 52, pp. 105&ndash;124.
</p>
<p>Hosking, J.R.M., and Wallis, J.R., 1997, Regional frequency analysis&mdash;An
approach based on L-moments: Cambridge University Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cdfpe3">cdfpe3</a></code>, <code><a href="#topic+quape3">quape3</a></code>, <code><a href="#topic+lmompe3">lmompe3</a></code>, <code><a href="#topic+parpe3">parpe3</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>  lmr &lt;- lmoms(c(123,34,4,654,37,78))
  pe3 &lt;- parpe3(lmr)
  x &lt;- quape3(0.5,pe3)
  pdfpe3(x,pe3)
## Not run: 
# Demonstrate Pearson Type III between lmomco and PearsonDS
qlmomco.pearsonIII &lt;- function(f, para) {
   MU    &lt;- para$para[1] # product moment mean
   SIGMA &lt;- para$para[2] # product moment standard deviation
   GAMMA &lt;- para$para[3] # product moment skew
   L &lt;- para$para[1] - 2*SIGMA/GAMMA # location
   S &lt;- (1/2)*SIGMA*abs(GAMMA)       # scale
   A &lt;- 4/GAMMA^2                    # shape
   return(PearsonDS::qpearsonIII(f, A, L, S)) # shape comes first!
}
FF &lt;- nonexceeds(); para &lt;- vec2par(c(6,.4,.7), type="pe3")
plot( FF, qlmomco(FF, para), xlab="Probability", ylab="Quantile", cex=3)
lines(FF, qlmomco.pearsonIII(FF, para), col=2, lwd=3) # 
## End(Not run)

## Not run: 
# Demonstrate forced Pearson Type III parameter estimation via PearsonDS package
para &lt;- vec2par(c(3, 0.4, 0.6), type="pe3"); X &lt;- rlmomco(105, para)
lmrpar &lt;- lmom2par(lmoms(X), type="pe3")
mpspar &lt;- mps2par(X, type="pe3"); mlepar &lt;- mle2par(X, type="pe3")
PDS &lt;- PearsonDS:::pearsonIIIfitML(X) # force function exporting
if(PDS$convergence != 0) {
  warning("convergence failed"); PDS &lt;- NULL # if null, rerun simulation [new data]
} else {
  # This is a list() mimic of PearsonDS::pearsonFitML()
  PDS   &lt;- list(type=3, shape=PDS$par[1], location=PDS$par[2], scale=PDS$par[3])
  skew  &lt;- sign(PDS$shape) * sqrt(4/PDS$shape)
  stdev &lt;-    2*PDS$scale  / abs(skew); mu &lt;- PDS$location + 2*stdev/skew
  PDS &lt;- vec2par(c(mu,stdev,skew), type="pe3") # lmomco form of parameters
}
print(lmrpar$para); print(mpspar$para); print(mlepar$para); print(PDS$para)
#        mu     sigma     gamma
# 2.9653380 0.3667651 0.5178592 # L-moments (by lmomco, of course)
# 2.9678021 0.3858198 0.4238529 # MPS by lmomco
# 2.9653357 0.3698575 0.4403525 # MLE by lmomco
# 2.9653379 0.3698609 0.4405195 # MLE by PearsonDS
# So we can see for this simulation that the two MLE approaches are similar.
## End(Not run)
</code></pre>

<hr>
<h2 id='pdfray'>Probability Density Function of the Rayleigh Distribution</h2><span id='topic+pdfray'></span>

<h3>Description</h3>

<p>This function computes the probability density of the Rayleigh distribution given parameters (<code class="reqn">\xi</code> and <code class="reqn">\alpha</code>)  computed by <code><a href="#topic+parray">parray</a></code>. The probability density function is
</p>
<p style="text-align: center;"><code class="reqn">f(x) =  \frac{x - \xi}{\alpha^2}\,\exp\!\left(\frac{-(x - \xi)^2}{2\alpha^2}\right)\mbox{,}</code>
</p>

<p>where <code class="reqn">f(x)</code> is the nonexceedance probability for quantile <code class="reqn">x</code>,
<code class="reqn">\xi</code> is a location parameter, and <code class="reqn">\alpha</code> is a scale parameter.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pdfray(x, para)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pdfray_+3A_x">x</code></td>
<td>
<p>A real value vector.</p>
</td></tr>
<tr><td><code id="pdfray_+3A_para">para</code></td>
<td>
<p>The parameters from <code><a href="#topic+parray">parray</a></code> or similar.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Probability density (<code class="reqn">f</code>) for <code class="reqn">x</code>.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Hosking, J.R.M., 1986, The theory of probability weighted moments:
Research Report RC12210, IBM Research Division, Yorkton Heights, N.Y.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cdfray">cdfray</a></code>, <code><a href="#topic+quaray">quaray</a></code>, <code><a href="#topic+lmomray">lmomray</a></code>, <code><a href="#topic+parray">parray</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>  lmr &lt;- lmoms(c(123,34,4,654,37,78))
  ray &lt;- parray(lmr)
  x &lt;- quaray(0.5,ray)
  pdfray(x,ray)
</code></pre>

<hr>
<h2 id='pdfrevgum'>Probability Density Function of the Reverse Gumbel Distribution</h2><span id='topic+pdfrevgum'></span>

<h3>Description</h3>

<p>This function computes the probability density
of the Reverse Gumbel distribution given parameters (<code class="reqn">\xi</code> and <code class="reqn">\alpha</code>)  computed by <code><a href="#topic+parrevgum">parrevgum</a></code>. The probability density function is
</p>
<p style="text-align: center;"><code class="reqn">f(x) = \alpha^{-1} \exp(Y) [\exp(\exp[-\exp(Y)])] \mbox{,}</code>
</p>

<p>where
</p>
<p style="text-align: center;"><code class="reqn">Y = \frac{x - \xi}{\alpha} \mbox{,}</code>
</p>

<p>where <code class="reqn">f(x)</code> is the probability density for quantile <code class="reqn">x</code>,
<code class="reqn">\xi</code> is a location parameter, and <code class="reqn">\alpha</code> is a scale parameter.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pdfrevgum(x, para)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pdfrevgum_+3A_x">x</code></td>
<td>
<p>A real value vector.</p>
</td></tr>
<tr><td><code id="pdfrevgum_+3A_para">para</code></td>
<td>
<p>The parameters from <code><a href="#topic+parrevgum">parrevgum</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Probability density (<code class="reqn">f</code>) for <code class="reqn">x</code>.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Hosking, J.R.M., 1990, L-moments&mdash;Analysis and estimation of
distributions using linear combinations of order statistics: Journal
of the Royal Statistical Society, Series B, v. 52, pp. 105&ndash;124.
</p>
<p>Hosking, J.R.M., 1995, The use of L-moments in the analysis of censored data,
in Recent Advances in Life-Testing and Reliability, edited by N. Balakrishnan, chapter 29, CRC Press, Boca Raton, Fla., pp. 546&ndash;560.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cdfrevgum">cdfrevgum</a></code>, <code><a href="#topic+quarevgum">quarevgum</a></code>, <code><a href="#topic+lmomrevgum">lmomrevgum</a></code>, <code><a href="#topic+parrevgum">parrevgum</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'># See p. 553 of Hosking (1995)
# Data listed in Hosking (1995, table 29.3, p. 553)
D &lt;- c(-2.982, -2.849, -2.546, -2.350, -1.983, -1.492, -1.443,
       -1.394, -1.386, -1.269, -1.195, -1.174, -0.854, -0.620,
       -0.576, -0.548, -0.247, -0.195, -0.056, -0.013,  0.006,
        0.033,  0.037,  0.046,  0.084,  0.221,  0.245,  0.296)
D &lt;- c(D,rep(.2960001,40-28)) # 28 values, but Hosking mentions
                              # 40 values in total
z &lt;-  pwmRC(D,threshold=.2960001)
str(z)
# Hosking reports B-type L-moments for this sample are
# lamB1 = -0.516 and lamB2 = 0.523
btypelmoms &lt;- pwm2lmom(z$Bbetas)
# My version of R reports lamB1 = -0.5162 and lamB2 = 0.5218
str(btypelmoms)
rg.pars &lt;- parrevgum(btypelmoms,z$zeta)
str(rg.pars)
# Hosking reports xi=0.1636 and alpha=0.9252 for the sample
# My version of R reports xi = 0.1635 and alpha = 0.9254
# Now one can continue one with a plotting example.
## Not run: 
F  &lt;- nonexceeds()
PP &lt;- pp(D) # plotting positions of the data
D  &lt;- sort(D)
plot(D,PP)
lines(D,cdfrevgum(D,rg.pars))
# Now finally do the PDF
F &lt;- seq(0.01,0.99,by=.01)
x &lt;- quarevgum(F,rg.pars)
plot(x,pdfrevgum(x,rg.pars),type='l')

## End(Not run)
</code></pre>

<hr>
<h2 id='pdfrice'>Probability Density Function of the Rice Distribution</h2><span id='topic+pdfrice'></span>

<h3>Description</h3>

<p>This function computes the probability density
of the Rice distribution given parameters  (<code class="reqn">\nu</code> and <code class="reqn">\mathrm{SNR}</code>)  computed by <code><a href="#topic+parrice">parrice</a></code>. The probability density function is
</p>
<p style="text-align: center;"><code class="reqn">
f(x) = \frac{x}{\alpha^2}\,\exp\!\left(\frac{-(x^2+\nu^2)}{2\alpha^2}\right)\,I_0(x\nu/\alpha^2)\mbox{,}
</code>
</p>

<p>where <code class="reqn">f(x)</code> is the nonexceedance probability for quantile <code class="reqn">x</code>,
<code class="reqn">\nu</code> is a parameter, and <code class="reqn">\nu/\alpha</code> is a form of signal-to-noise ratio <code class="reqn">\mathrm{SNR}</code>, and <code class="reqn">I_k(x)</code> is the modified Bessel function of the first kind, which for integer <code class="reqn">k=0</code> is seen under <code><a href="#topic+LaguerreHalf">LaguerreHalf</a></code>. If <code class="reqn">\nu=0</code>, then the Rayleigh distribution results and <code><a href="#topic+pdfray">pdfray</a></code> is used. If <code class="reqn">24 &lt; \mathrm{SNR} &lt; 52</code> is used, then the Normal distribution functions are used with appropriate parameter estimation for <code class="reqn">\mu</code> and <code class="reqn">\sigma</code> that include the Laguerre polynomial <code><a href="#topic+LaguerreHalf">LaguerreHalf</a></code>. If <code class="reqn">\mathrm{SNR} &gt; 52</code>, then the Normal distribution functions continue to be used with <code class="reqn">\mu=\alpha\times\mathrm{SNR}</code> and <code class="reqn">\sigma = A</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pdfrice(x, para)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pdfrice_+3A_x">x</code></td>
<td>
<p>A real value vector.</p>
</td></tr>
<tr><td><code id="pdfrice_+3A_para">para</code></td>
<td>
<p>The parameters from <code><a href="#topic+parrice">parrice</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Probability density (<code class="reqn">f</code>) for <code class="reqn">x</code>.
</p>


<h3>Note</h3>

<p>The <span class="pkg">VGAM</span> package provides a pdf of the Rice for reference:
</p>
<pre>
"drice" &lt;- function(x, vee, sigma, log = FALSE) { # From the VGAM package
    if(!is.logical(log.arg &lt;- log)) stop("bad input for argument 'log'")
    rm(log)
    N = max(length(x), length(vee), length(sigma))
    x = rep(x, len=N); vee = rep(vee, len=N); sigma = rep(sigma, len=N)
    logdensity = rep(log(0), len=N)
    xok = (x &gt; 0)
    x.abs = abs(x[xok]*vee[xok]/sigma[xok]^2)
    logdensity[xok] = log(x[xok]) - 2 * log(sigma[xok]) +
                      (-(x[xok]^2+vee[xok]^2)/(2*sigma[xok]^2)) +
                      log(besselI(x.abs, nu=0, expon.scaled = TRUE)) + x.abs
    logdensity[sigma &lt;= 0] &lt;- NaN; logdensity[vee &lt; 0] &lt;- NaN
    if(log.arg) logdensity else exp(logdensity)
}
</pre>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Asquith, W.H., 2011, Distributional analysis with L-moment statistics using the R environment for statistical computing: Createspace Independent Publishing Platform, ISBN 978&ndash;146350841&ndash;8.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cdfrice">cdfrice</a></code>, <code><a href="#topic+quarice">quarice</a></code>, <code><a href="#topic+lmomrice">lmomrice</a></code>, <code><a href="#topic+parrice">parrice</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>lmr &lt;- lmoms(c(10, 43, 27, 26, 49, 26, 62, 39, 51, 14))
rice &lt;- parrice(lmr)
x &lt;- quarice(nonexceeds(),rice)
plot(x,pdfrice(x,rice), type="b")


# For SNR=v/a &gt; 24 or 240.001/10 &gt; 24, the Normal distribution is
# used by the Rice as implemented here.
rice1 &lt;- vec2par(c(239.9999,10), type="rice")
rice2 &lt;- vec2par(c(240.0001,10), type="rice")
x &lt;- 200:280
plot( x, pdfrice(x, rice1), type="l", lwd=5, lty=3) # still RICIAN code
lines(x, dnorm(  x, mean=240.0001, sd=10), lwd=3, col=2) # NORMAL obviously
lines(x, pdfrice(x, rice2), lwd=1, col=3) # NORMAL distribution code is triggered

# For SNR=v/a &gt; 52 or 521/10 &gt; 52, the Normal distribution
# used by the Rice as implemented here with simple parameter estimation
# because this high of SNR is beyond limits of Bessel function in Laguerre
# polynomial
rice1 &lt;- vec2par(c(520,10), type="rice")
rice2 &lt;- vec2par(c(521,10), type="rice")
x &lt;- 10^(log10(520) - 0.05):10^(log10(520) + 0.05)
plot( x, pdfrice(x, rice1), type="l", lwd=5, lty=3)
lines(x, pdfrice(x, rice2), lwd=1, col=3) # NORMAL code triggered
</code></pre>

<hr>
<h2 id='pdfsla'>Probability Density Function of the Slash Distribution</h2><span id='topic+pdfsla'></span>

<h3>Description</h3>

<p>This function computes the probability density of the Slash distribution given parameters (<code class="reqn">\xi</code> and <code class="reqn">\alpha</code>)  provided by <code><a href="#topic+parsla">parsla</a></code>.  The probability density function is
</p>
<p style="text-align: center;"><code class="reqn">f(x) = \frac{\phi(0) - \phi(y)}{y^2} \mbox{,}</code>
</p>

<p>where <code class="reqn">f(x)</code> is the probability density for quantile <code class="reqn">x</code>, <code class="reqn">y = (x - \xi)/\alpha</code>, <code class="reqn">\xi</code> is a location parameter, and <code class="reqn">\alpha</code> is a scale parameter. The function <code class="reqn">\phi(y)</code> is the probability density function of the Standard Normal distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pdfsla(x, para)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pdfsla_+3A_x">x</code></td>
<td>
<p>A real value vector.</p>
</td></tr>
<tr><td><code id="pdfsla_+3A_para">para</code></td>
<td>
<p>The parameters from <code><a href="#topic+parsla">parsla</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Probability density (<code class="reqn">f</code>) for <code class="reqn">x</code>.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Rogers, W.H., and Tukey, J.W., 1972, Understanding some long-tailed symmetrical distributions: Statistica Neerlandica, v. 26, no. 3, pp. 211&ndash;226.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cdfsla">cdfsla</a></code>, <code><a href="#topic+quasla">quasla</a></code>, <code><a href="#topic+lmomsla">lmomsla</a></code>, <code><a href="#topic+parsla">parsla</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>  sla &lt;- vec2par(c(12, 1.2), type="sla")
  x &lt;- quasla(0.5, sla)
  pdfsla(x, sla)
</code></pre>

<hr>
<h2 id='pdfsmd'>Probability Density Function of the Singh&ndash;Maddala Distribution</h2><span id='topic+pdfsmd'></span>

<h3>Description</h3>

<p>This function computes the probability density of the Singh&ndash;Maddala (Burr Type XII) distribution given parameters (<code class="reqn">a</code>, <code class="reqn">b</code>, and <code class="reqn">q</code>)  computed by <code><a href="#topic+parsmd">parsmd</a></code>. The probability density function is
</p>
<p style="text-align: center;"><code class="reqn">f(x) = \frac{b \cdot q \cdot x^{b-1}}{a^b \biggl(1 + \bigl[(x-\xi)/a\bigr]^b \biggr)^{q+1}}\mbox{,}</code>
</p>

<p>where <code class="reqn">f(x)</code> is the probability density for quantile <code class="reqn">x</code> with <code class="reqn">0 \le x \le \infty</code>, <code class="reqn">\xi</code> is a location parameter, <code class="reqn">a</code> is a scale parameter (<code class="reqn">a &gt; 0</code>), <code class="reqn">b</code> is a shape parameter (<code class="reqn">b &gt; 0</code>), and <code class="reqn">q</code> is another shape parameter (<code class="reqn">q &gt; 0</code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pdfsmd(x, para)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pdfsmd_+3A_x">x</code></td>
<td>
<p>A real value vector.</p>
</td></tr>
<tr><td><code id="pdfsmd_+3A_para">para</code></td>
<td>
<p>The parameters from <code><a href="#topic+parsmd">parsmd</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Probability density (<code class="reqn">f</code>) for <code class="reqn">x</code>.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Kumar, D., 2017, The Singh&ndash;Maddala distribution&mdash;Properties and estimation: International Journal of System Assurance Engineering and Management, v. 8, no. S2, 15 p., <a href="https://doi.org/10.1007/s13198-017-0600-1">doi:10.1007/s13198-017-0600-1</a>.
</p>
<p>Shahzad, M.N., and Zahid, A., 2013, Parameter estimation of Singh Maddala distribution by moments: International Journal of Advanced Statistics and Probability, v. 1, no. 3, pp. 121&ndash;131, <a href="https://doi.org/10.14419/ijasp.v1i3.1206">doi:10.14419/ijasp.v1i3.1206</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cdfsmd">cdfsmd</a></code>, <code><a href="#topic+quasmd">quasmd</a></code>, <code><a href="#topic+lmomsmd">lmomsmd</a></code>, <code><a href="#topic+parsmd">parsmd</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'># The SMD approximating the normal and use x=0
tau4_of_normal &lt;- 30 * pi^-1 * atan(sqrt(2)) - 9 # from theory
pdfsmd(0, parsmd( vec2lmom( c( -pi, pi, 0, tau4_of_normal ) ) ) ) # 0.061953
dnorm( 0, mean=-pi, sd=pi*sqrt(pi))                               # 0.06110337

## Not run: 
LMlo &lt;- vec2lmom(c(10000, 1500, 0.3, 0.1))
LMhi &lt;- vec2lmom(c(10000, 1500, 0.3, 0.6))
SMDlo &lt;- parsmd(LMlo, snap.tau4=TRUE) # Tau4 snapped to 0.15077
SMDhi &lt;- parsmd(LMhi, snap.tau4=TRUE) # Tau4 snapped to 0.25360
FF &lt;- pnorm(seq(-6, 3, by=.01))
x &lt;- sort(c(quasmd(FF, SMDlo), quasmd(FF, SMDhi)))
plot( x, pdfsmd(x, SMDlo), col="red", xlim=range(x), type="l")
lines(x, pdfsmd(x, SMDhi), col="blue") #
## End(Not run)
</code></pre>

<hr>
<h2 id='pdfst3'>Probability Density Function of the 3-Parameter Student t Distribution</h2><span id='topic+pdfst3'></span>

<h3>Description</h3>

<p>This function computes the probability density of the 3-parameter Student t distribution given parameters (<code class="reqn">\xi</code>, <code class="reqn">\alpha</code>, <code class="reqn">\nu</code>)  computed by <code><a href="#topic+parst3">parst3</a></code>. The probability density function is
</p>
<p style="text-align: center;"><code class="reqn">
f(x) = \frac{\Gamma(\frac{1}{2} + \frac{1}{2}\nu)}{\alpha\nu^{1/2}\,\Gamma(\frac{1}{2})\Gamma(\frac{1}{2}\nu)}(1+t^2/\nu)^{-(\nu+1)/2}\mbox{,}
</code>
</p>

<p>where <code class="reqn">f(x)</code> is the probability density for quantile <code class="reqn">x</code>, <code class="reqn">t</code> is defined as <code class="reqn">t = (x - \xi)/\alpha</code>, <code class="reqn">\xi</code> is a location parameter, <code class="reqn">\alpha</code> is a scale parameter, and <code class="reqn">\nu</code> is a shape parameter in terms of the degrees of freedom as for the more familiar Student t distribution in <span class="rlang"><b>R</b></span>.
</p>
<p>For value <code>X</code>, the built-in <span class="rlang"><b>R</b></span> functions can be used. For <code>U</code> = <code class="reqn">\xi</code> and <code>A</code>=<code class="reqn">\alpha</code> for <code class="reqn">1.001 \le \nu \le 10^5.5</code>, one can use <code>dt((X-U)/A, N)/A</code> for <code>N</code>=<code class="reqn">\nu</code>. The <span class="rlang"><b>R</b></span> function <code>dt</code> is used for the 1-parameter Student t density. The limits for <code class="reqn">\nu</code> stem from study of ability for theoretical integration of the quantile function to produce viable <code class="reqn">\tau_4</code> and <code class="reqn">\tau_6</code> (see <code>inst/doc/t4t6/studyST3.R</code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pdfst3(x, para, paracheck=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pdfst3_+3A_x">x</code></td>
<td>
<p>A real value vector.</p>
</td></tr>
<tr><td><code id="pdfst3_+3A_para">para</code></td>
<td>
<p>The parameters from <code><a href="#topic+parst3">parst3</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
<tr><td><code id="pdfst3_+3A_paracheck">paracheck</code></td>
<td>
<p>A logical on whether the parameter should be check for validity.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Probability density (<code class="reqn">f</code>) for <code class="reqn">x</code>.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Asquith, W.H., 2011, Distributional analysis with L-moment statistics using the R environment for statistical computing: Createspace Independent Publishing Platform, ISBN 978&ndash;146350841&ndash;8.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cdfst3">cdfst3</a></code>, <code><a href="#topic+quast3">quast3</a></code>, <code><a href="#topic+lmomst3">lmomst3</a></code>,  <code><a href="#topic+parst3">parst3</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
xs &lt;- -200:200
  para &lt;- vec2par(c(37, 25,  114), type="st3")
plot(xs, pdfst3(xs, para), type="l")
  para &lt;- vec2par(c(11, 36, 1000), type="st3")
lines(xs, pdfst3(xs, para), lty=2)
  para &lt;- vec2par(c(-7, 60,   40), type="st3")
lines(xs, pdfst3(xs, para), lty=3)

## End(Not run)
</code></pre>

<hr>
<h2 id='pdftexp'>Probability Density Function of the Truncated Exponential Distribution</h2><span id='topic+pdftexp'></span>

<h3>Description</h3>

<p>This function computes the probability density of the Truncated Exponential distribution given parameters (<code class="reqn">\psi</code> and <code class="reqn">\alpha</code>)  computed by <code><a href="#topic+partexp">partexp</a></code>. The parameter <code class="reqn">\psi</code> is the right truncation, and <code class="reqn">\alpha</code> is a scale parameter. The probability density function, letting <code class="reqn">\beta = 1/\alpha</code> to match nomenclature of Vogel and others (2008), is
</p>
<p style="text-align: center;"><code class="reqn">f(x) = \frac{\beta\,\exp(-\beta{t})}{1 - \mathrm{exp}(-\beta\psi)}\mbox{,}</code>
</p>

<p>where <code class="reqn">x(x)</code> is the probability density for the quantile <code class="reqn">0 \le x \le \psi</code> and <code class="reqn">\psi &gt; 0</code> and <code class="reqn">\alpha &gt; 0</code>. This distribution represents a nonstationary Poisson process.
</p>
<p>The distribution is restricted to a narrow range of L-CV (<code class="reqn">\tau_2 = \lambda_2/\lambda_1</code>). If <code class="reqn">\tau_2 = 1/3</code>, the process represented is a stationary Poisson for which the probability density function is simply the uniform distribution and <code class="reqn">f(x) = 1/\psi</code>. If <code class="reqn">\tau_2 = 1/2</code>, then the distribution is represented as the usual exponential distribution with a location parameter of zero and a scale parameter <code class="reqn">1/\beta</code>. Both of these limiting conditions are supported.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pdftexp(x, para)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pdftexp_+3A_x">x</code></td>
<td>
<p>A real value vector.</p>
</td></tr>
<tr><td><code id="pdftexp_+3A_para">para</code></td>
<td>
<p>The parameters from <code><a href="#topic+partexp">partexp</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Probability density (<code class="reqn">F</code>) for <code class="reqn">x</code>.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Vogel, R.M., Hosking, J.R.M., Elphick, C.S., Roberts, D.L., and Reed, J.M., 2008, Goodness of fit of probability distributions for sightings as species approach extinction: Bulletin of Mathematical Biology, DOI 10.1007/s11538-008-9377-3, 19 p.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cdftexp">cdftexp</a></code>, <code><a href="#topic+quatexp">quatexp</a></code>, <code><a href="#topic+lmomtexp">lmomtexp</a></code>, <code><a href="#topic+partexp">partexp</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>lmr &lt;- vec2lmom(c(40,0.38), lscale=FALSE)
pdftexp(0.5,partexp(lmr))
## Not run: 
F &lt;- seq(0,1,by=0.001)
A &lt;- partexp(vec2lmom(c(100, 1/2), lscale=FALSE))
x &lt;- quatexp(F, A)
plot(x, pdftexp(x, A), pch=16, type='l')
by &lt;- 0.01; lcvs &lt;- c(1/3, seq(1/3+by, 1/2-by, by=by), 1/2)
reds &lt;- (lcvs - 1/3)/max(lcvs - 1/3)
for(lcv in lcvs) {
    A &lt;- partexp(vec2lmom(c(100, lcv), lscale=FALSE))
    x &lt;- quatexp(F, A)
    lines(x, pdftexp(x, A),
          pch=16, col=rgb(reds[lcvs == lcv],0,0))
}

## End(Not run)
</code></pre>

<hr>
<h2 id='pdftri'>Probability Density Function of the Asymmetric Triangular Distribution</h2><span id='topic+pdftri'></span>

<h3>Description</h3>

<p>This function computes the probability density of the Asymmetric Triangular distribution given parameters (<code class="reqn">\nu</code>, <code class="reqn">\omega</code>, and <code class="reqn">\psi</code>)  computed by <code><a href="#topic+partri">partri</a></code>. The probability density function is
</p>
<p style="text-align: center;"><code class="reqn">f(x) = \frac{2(x-\nu)}{(\omega - \nu)(\psi - \nu)}\mbox{,}</code>
</p>

<p>for <code class="reqn">x &lt; \omega</code>,
</p>
<p style="text-align: center;"><code class="reqn">f(x) = \frac{2(\psi-x)}{(\psi - \omega)(\psi - \nu)}\mbox{,}</code>
</p>

<p>for <code class="reqn">x &gt;  \omega</code>, and
</p>
<p style="text-align: center;"><code class="reqn">f(x) = \frac{2}{(\psi - \nu)}\mbox{,}</code>
</p>

<p>for <code class="reqn">x = \omega</code>
where <code class="reqn">x(F)</code> is the quantile for nonexceedance probability <code class="reqn">F</code>, <code class="reqn">\nu</code> is the minimum, <code class="reqn">\psi</code> is the maximum, and <code class="reqn">\omega</code> is the mode of the distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pdftri(x, para)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pdftri_+3A_x">x</code></td>
<td>
<p>A real value vector.</p>
</td></tr>
<tr><td><code id="pdftri_+3A_para">para</code></td>
<td>
<p>The parameters from <code><a href="#topic+partri">partri</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Probability density (<code class="reqn">f</code>) for <code class="reqn">x</code>.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>See Also</h3>

<p><code><a href="#topic+pdftri">pdftri</a></code>, <code><a href="#topic+quatri">quatri</a></code>, <code><a href="#topic+lmomtri">lmomtri</a></code>, <code><a href="#topic+partri">partri</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>  tri &lt;- vec2par(c(-120, 102, 320), type="tri")
  x &lt;- quatri(nonexceeds(),tri)
  pdftri(x,tri)
</code></pre>

<hr>
<h2 id='pdfwak'>Probability Density Function of the Wakeby Distribution</h2><span id='topic+pdfwak'></span>

<h3>Description</h3>

<p>This function computes the probability density
of the Wakeby distribution given parameters (<code class="reqn">\xi</code>, <code class="reqn">\alpha</code>, <code class="reqn">\beta</code>, <code class="reqn">\gamma</code>, and <code class="reqn">\delta</code>)  computed by <code><a href="#topic+parwak">parwak</a></code>. The probability density function is
</p>
<p style="text-align: center;"><code class="reqn">f(x) = (\alpha[1-F(x)]^{\beta - 1} + \gamma[1-F(x)]^{-\delta - 1})^{-1}\mbox{,}</code>
</p>

<p>where <code class="reqn">f(x)</code> is the probability density for quantile <code class="reqn">x</code>, <code class="reqn">F(x)</code> is the cumulative distribution function or nonexceedance probability at <code class="reqn">x</code>, <code class="reqn">\xi</code> is a location parameter, <code class="reqn">\alpha</code> and <code class="reqn">\beta</code> are scale parameters, and <code class="reqn">\gamma</code>, and <code class="reqn">\delta</code> are shape parameters. The five returned parameters from <code><a href="#topic+parwak">parwak</a></code> in order are <code class="reqn">\xi</code>, <code class="reqn">\alpha</code>, <code class="reqn">\beta</code>, <code class="reqn">\gamma</code>, and <code class="reqn">\delta</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pdfwak(x, para)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pdfwak_+3A_x">x</code></td>
<td>
<p>A real value vector.</p>
</td></tr>
<tr><td><code id="pdfwak_+3A_para">para</code></td>
<td>
<p>The parameters from <code><a href="#topic+parwak">parwak</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Probability density (<code class="reqn">f</code>) for <code class="reqn">x</code>.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Hosking, J.R.M. and Wallis, J.R., 1997, Regional frequency analysis&mdash;An
approach based on L-moments: Cambridge University Press.
</p>
<p>Sourced from written communication with Dr. Hosking in October 2007.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cdfwak">cdfwak</a></code>, <code><a href="#topic+quawak">quawak</a></code>, <code><a href="#topic+lmomwak">lmomwak</a></code>, <code><a href="#topic+parwak">parwak</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
lmr &lt;- vec2lmom(c(1,0.5,.4,.3,.15))
wak &lt;- parwak(lmr)
F &lt;- nonexceeds()
x &lt;- quawak(F,wak)
check.pdf(pdfwak,wak,plot=TRUE)

## End(Not run)
</code></pre>

<hr>
<h2 id='pdfwei'>Probability Density Function of the Weibull Distribution</h2><span id='topic+pdfwei'></span>

<h3>Description</h3>

<p>This function computes the probability density of the Weibull distribution given parameters (<code class="reqn">\zeta</code>, <code class="reqn">\beta</code>, and <code class="reqn">\delta</code>)  computed by <code><a href="#topic+parwei">parwei</a></code>. The probability density function is
</p>
<p style="text-align: center;"><code class="reqn">f(x) = \delta Y^{\delta-1} \exp(-Y^\delta)/\beta </code>
</p>

<p>where <code class="reqn">f(x)</code> is the probability density, <code class="reqn">Y = (x-\zeta)/\beta</code>, quantile <code class="reqn">x</code>,
<code class="reqn">\zeta</code> is a location parameter, <code class="reqn">\beta</code> is a scale parameter, and
<code class="reqn">\delta</code> is a shape parameter.
</p>
<p>The Weibull distribution is a reverse Generalized Extreme Value distribution.  As result, the Generalized Extreme Value algorithms are used for implementation of the Weibull in <span class="pkg">lmomco</span>. The relations between the Generalized Extreme Value parameters (<code class="reqn">\xi</code>, <code class="reqn">\alpha</code>, and <code class="reqn">\kappa</code>) are <code class="reqn">\kappa = 1/\delta</code>, <code class="reqn">\alpha = \beta/\delta</code>, and <code class="reqn">\xi = \zeta - \beta</code>. These relations are available in Hosking and Wallis (1997).
</p>
<p>In <span class="rlang"><b>R</b></span>, the probability distribution function of the Weibull distribution is <code>pweibull</code>. Given a Weibull parameter object <code>para</code>, the <span class="rlang"><b>R</b></span> syntax is <code>pweibull(x+para$para[1],</code> <code>para$para[3],</code>
<br /> <code>scale=para$para[2])</code>. For the <span class="pkg">lmomco</span> implmentation, the reversed Generalized Extreme Value distribution <code><a href="#topic+pdfgev">pdfgev</a></code> is used and again in <span class="rlang"><b>R</b></span> syntax is <code>pdfgev(-x,para)</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pdfwei(x, para)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pdfwei_+3A_x">x</code></td>
<td>
<p>A real value vector.</p>
</td></tr>
<tr><td><code id="pdfwei_+3A_para">para</code></td>
<td>
<p>The parameters from <code><a href="#topic+parwei">parwei</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Probability density (<code class="reqn">f</code>) for <code class="reqn">x</code>.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Hosking, J.R.M. and Wallis, J.R., 1997, Regional frequency analysis&mdash;An
approach based on L-moments: Cambridge University Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cdfwei">cdfwei</a></code>, <code><a href="#topic+quawei">quawei</a></code>, <code><a href="#topic+lmomwei">lmomwei</a></code>, <code><a href="#topic+parwei">parwei</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>  # Evaluate Weibull deployed here and built-in function (pweibull)
  lmr &lt;- lmoms(c(123,34,4,654,37,78))
  WEI &lt;- parwei(lmr)
  F1  &lt;- cdfwei(50,WEI)
  F2  &lt;- pweibull(50+WEI$para[1],shape=WEI$para[3],scale=WEI$para[2])
  if(F1 == F2) EQUAL &lt;- TRUE
## Not run: 
  # The Weibull is a reversed generalized extreme value
  Q &lt;- sort(rlmomco(34,WEI)) # generate Weibull sample
  lm1 &lt;- lmoms( Q)   # regular L-moments
  lm2 &lt;- lmoms(-Q)   # L-moment of negated (reversed) data
  WEI &lt;- parwei(lm1) # parameters of Weibull
  GEV &lt;- pargev(lm2) # parameters of GEV
  F &lt;- nonexceeds()  # Get a vector of nonexceedance probabilities
  plot(pp(Q),Q)
  lines(cdfwei(Q,WEI),Q,lwd=5,col=8)
  lines(1-cdfgev(-Q,GEV),Q,col=2) # line overlaps previous distribution

## End(Not run)
</code></pre>

<hr>
<h2 id='pfactor.bernstein'>Estimation of Optimal p-factor of Distributional Support Estimation for Smoothed Quantiles from the Bernstein or Kantorovich Polynomials </h2><span id='topic+pfactor.bernstein'></span>

<h3>Description</h3>

<p>Compute the optimal p-factor through numerical integration of the smoothed empirical quantile function to estimate the L-moments of the distribution. This function attempts to report an optimal &ldquo;p-factor&rdquo;  (author's term) for the given parent distribution in <code>para</code> based on estimating the crossing of the origin of an error between the given L-moment ratio <code class="reqn">\tau_r</code> for 3, 4, and 5 that will come from either the distribution parameter object or given as an argument in <code>lmr.dist</code>.  The estimated support of the distribution is that shown by  Turnbull and Ghosh (2014) and is computed as follows
</p>
<p style="text-align: center;"><code class="reqn">\biggl(x_{0:n},\: x_{n+1:n}\biggr) = \biggl(x_{1:n} - \frac{(x_{2:n} - x_{1:n})}{(1 - p)^{-2} - 1},\: x_{n:n} + \frac{(x_{n:n} - x_{n-1:n})}{(1 - p)^{-2} - 1}\biggr)\mbox{,}</code>
</p>

<p>where <code class="reqn">p</code> is the p-factor. The support will honor natural bounds if given by either <code>fix.lower</code> or <code>fix.upper</code>. The polynomial type for smooth is provided in <code>poly.type</code>. These three arguments are the same as those for <code><a href="#topic+dat2bernqua">dat2bernqua</a></code> and <code><a href="#topic+lmoms.bernstein">lmoms.bernstein</a></code>. The statistic type used to measure central tendency of the errors for the <code>nsim</code> simulations per <code class="reqn">p</code>. The function has its own hardwired p-factors to compute but these can be superseded by the <code>pfactors</code> argument. The <code>p.lo</code> and <code>p.hi</code> are the lower and upper bounds to truncate on immediately after the p-factors to use are assembled. These are made for three purposes: (1) protection against numerical problems for mathematical upper limits (unity), (2) to potentially provide for much faster execution if the user already knows the approximate optimal value for the p-factor, and (3) to potentially use this function in a direct optimization framework using the <span class="rlang"><b>R</b></span> functions <code>optim</code> or <code>uniroot</code>. It is strongly suggested to keep <code>plot.em</code> set so the user can inspect the computations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pfactor.bernstein(para, x=NULL, n=NULL,
                        bern.control=NULL,
                        poly.type=c("Bernstein", "Kantorovich"),
                        stat.type=c("Mean", "Median"),
                        fix.lower=NULL, fix.upper=NULL,
                        lmr.dist=NULL, lmr.n=c("3", "4", "5"),
                        nsim=500, plot.em=TRUE, pfactors=NULL,
                        p.lo=.Machine$double.eps, p.hi=1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pfactor.bernstein_+3A_para">para</code></td>
<td>
<p>A mandatory &ldquo;parent&rdquo; distribution defined by a usual <span class="pkg">lmomco</span> distribution parameter object for a distribution. The simulations are based on this distribution, although optimization for <code class="reqn">p</code> can be set to a different L-moment value by <code>lmr.dist</code>.</p>
</td></tr>
<tr><td><code id="pfactor.bernstein_+3A_x">x</code></td>
<td>
<p>An optional vector of data values.</p>
</td></tr>
<tr><td><code id="pfactor.bernstein_+3A_n">n</code></td>
<td>
<p>An optional sample size to run the simulations on. This value is computed by <code>length(x)</code> if <code>x</code> is provided. If set by argument, then that size supersedes the length of the optional observed sample.</p>
</td></tr>
<tr><td><code id="pfactor.bernstein_+3A_bern.control">bern.control</code></td>
<td>
<p>A <code>list</code> that holds <code>poly.type</code>, <code>stat.type</code>, <code>fix.lower</code>, and <code>fix.upper</code>. And this list will supersede the respective
values provided as separate arguments. There is an implicit <code>bound.type</code> of <code>"Carv"</code>.</p>
</td></tr>
<tr><td><code id="pfactor.bernstein_+3A_poly.type">poly.type</code></td>
<td>
<p>Same argument as for <code><a href="#topic+dat2bernqua">dat2bernqua</a></code>.</p>
</td></tr>
<tr><td><code id="pfactor.bernstein_+3A_stat.type">stat.type</code></td>
<td>
<p>The central estimation statistic for each p-factor evaluated.</p>
</td></tr>
<tr><td><code id="pfactor.bernstein_+3A_fix.lower">fix.lower</code></td>
<td>
<p>Same argument as for <code><a href="#topic+dat2bernqua">dat2bernqua</a></code>.</p>
</td></tr>
<tr><td><code id="pfactor.bernstein_+3A_fix.upper">fix.upper</code></td>
<td>
<p>Same argument as for <code><a href="#topic+dat2bernqua">dat2bernqua</a></code>.</p>
</td></tr>
<tr><td><code id="pfactor.bernstein_+3A_lmr.dist">lmr.dist</code></td>
<td>
<p>This is the value for the <code>lmr.n</code> of the distribution in <code>para</code> unless explicitly set through <code>lmr.dist</code>.</p>
</td></tr>
<tr><td><code id="pfactor.bernstein_+3A_lmr.n">lmr.n</code></td>
<td>
<p>The L-moment ratio number for p-factor optimization.</p>
</td></tr>
<tr><td><code id="pfactor.bernstein_+3A_nsim">nsim</code></td>
<td>
<p>The number of simulations to run. Experiments suggest the default is adequate for reasonably small sample sizes&mdash;the simulation count can be reduced as <code>n</code> becomes large.</p>
</td></tr>
<tr><td><code id="pfactor.bernstein_+3A_plot.em">plot.em</code></td>
<td>
<p>A logical to trigger the diagnostic plot of the simulated errors and a smooth line through these errors.</p>
</td></tr>
<tr><td><code id="pfactor.bernstein_+3A_pfactors">pfactors</code></td>
<td>
<p>An optional vector of p-factors to loop through for the simulations. The vector computing internall is this is set to <code>NULL</code> seems to be more than adequate.</p>
</td></tr>
<tr><td><code id="pfactor.bernstein_+3A_p.lo">p.lo</code></td>
<td>
<p>An computational lower boundary for which the <code>pfactors</code> by argument or default are truncated to. The default for <code>lo</code> is to be quite small and does no truncate the default <code>pfactors</code>.</p>
</td></tr>
<tr><td><code id="pfactor.bernstein_+3A_p.hi">p.hi</code></td>
<td>
<p>An computational upper boundary for which the <code>pfactors</code> by argument or default are truncated to. The default for <code>hi</code> is unity, which is the true upper limit that results in a 0 slope between the <code class="reqn">x_{0:n}</code> to <code class="reqn">x_{1:n}</code> or <code class="reqn">x_{n:n}</code> to <code class="reqn">x_{n+1:n}</code> order statistics.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> or <code>real</code> is returned.  If <code>pfactors</code> is a single value, then the single value for the error statistic is returned, otherwise the list described will be. If the returned <code>pfactor</code> is <code>NA</code>, then likely the smooth line did not cross zero and the reason the user should keep <code>plot.em=TRUE</code> and inspect the plot. Perhaps revisions to the arguments will become evident. The contents of the list are
</p>
<table>
<tr><td><code>pfactor</code></td>
<td>
<p>The estimated value of <code class="reqn">p</code> smoothed by <code>lowess</code> that has an error of zero, see <code>err.stat</code> as a function of <code>ps</code>.</p>
</td></tr>
<tr><td><code>bounds.type</code></td>
<td>
<p><code>Carv</code>, which is the same bound type as needed by <code><a href="#topic+dat2bernqua">dat2bernqua</a></code> and <br /> <code><a href="#topic+lmoms.bernstein">lmoms.bernstein</a></code>.</p>
</td></tr>
<tr><td><code>poly.type</code></td>
<td>
<p>The given <code>poly.type</code>.</p>
</td></tr>
<tr><td><code>stat.type</code></td>
<td>
<p>The given <code>stat.type</code>. The &ldquo;Mean&rdquo; seems to be preferable.</p>
</td></tr>
<tr><td><code>lmom.type</code></td>
<td>
<p>A string of the L-moment type: &ldquo;Tau3&rdquo;, &ldquo;Tau4&rdquo;, &ldquo;Tau5&rdquo;.</p>
</td></tr>
<tr><td><code>fix.lower</code></td>
<td>
<p>The given fixed lower boundary, which could stay <code>NULL</code>.</p>
</td></tr>
<tr><td><code>fix.upper</code></td>
<td>
<p>The given fixed upper boundary, which could stay <code>NULL</code>.</p>
</td></tr>
<tr><td><code>source</code></td>
<td>
<p>An attribute identifying the computational source of the L-moments: &ldquo;pfactor.bernstein&rdquo;.</p>
</td></tr>
<tr><td><code>ps</code></td>
<td>
<p>The p-factors actually evaluated.</p>
</td></tr>
<tr><td><code>err.stat</code></td>
<td>
<p>The error statistic computed by <code>stat.type</code> of the simulated <code class="reqn">\hat{\tau_r}</code> by integration provided by <code><a href="#topic+lmoms.bernstein">lmoms.bernstein</a></code> minus the &ldquo;true&rdquo; value <code class="reqn">\tau_r</code> provided by either <code>para</code> or given by <code>lmr.dist</code> where <code class="reqn">r</code> is <code>lmr.n</code>.</p>
</td></tr>
<tr><td><code>err.smooth</code></td>
<td>
<p>The <code>lowess</code>-smoothed values for <code>err.stat</code> and the <code>pfactor</code> comes from a linear interpolation of this smooth for the error being zero.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Repeated application of this function for various <code>n</code> would result in the analyst having a vector of <code class="reqn">n</code> and <code class="reqn">p</code> (<code>pfactor</code>). The analyst could then fit a regression equation and refine the estimated <code class="reqn">p(n)</code>. For example, a dual-logarithmic regression is suggested <code>lm(log(p)~log(n))</code>.
</p>
<p>Also, symmetrical data likely see little benefit from optimizing on the symmetry-measuring L-moments Tau3 and Tau5; the analyst might prefer to optimize on peakedness measured by Tau4.
</p>


<h3>Note</h3>

<p>This function is highly experimental and subject to extreme overhaul. Please contact the author if you are an interested party in Bernstein and Kantorovich polynomials.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Turnbull, B.C., and Ghosh, S.K., 2014, Unimodal density estimation using Bernstein polynomials. Computational Statistics and Data Analysis, v. 72, pp. 13&ndash;29.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lmoms.bernstein">lmoms.bernstein</a></code>, <code><a href="#topic+dat2bernqua">dat2bernqua</a></code>, <code><a href="#topic+lmoms">lmoms</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
pdf("pfactor_exampleB.pdf")
X &lt;- exp(rnorm(200)); para &lt;- parexp(lmoms(X))
# nsim is too small, but makes the following three not take too long
pfactor.bernstein(para, n=20, lmr.n="3", nsim=100, p.lo=.06, p.hi=.3)
pfactor.bernstein(para, n=20, lmr.n="4", nsim=100, p.lo=.06, p.hi=.3)
pfactor.bernstein(para, n=20, lmr.n="5", nsim=100, p.lo=.06, p.hi=.3)
dev.off()

## End(Not run)
## Not run: 
# Try intra-sample p-factor optimization from two perspectives. The 3-parameter
# GEV "over fits" the data and provides the parent.  Then use Tau3 of the fitted
# GEV for peakedness restraint and then use Tau3 of the data. Then repeat but use
# the apparent "exact" value of Tau3 for the true exponential parent.
pdf("pfactor_exampleB.pdf")
lmr &lt;- vec2lmom(c(60,20)); paraA &lt;- parexp(lmr); n &lt;- 40
tr &lt;- lmorph(par2lmom(paraA))$ratios[3]
X &lt;- rlmomco(n, paraA); para &lt;- pargev(lmoms(X))
F &lt;- seq(0.001,0.999, by=0.001)
plot(qnorm(pp(X, a=0.40)), sort(X), type="n", log="y",
      xlab="Standard normal variate", ylab="Quantile",
      xlim=qnorm(range(F)), ylim=range(qlmomco(F,paraA)))
lines(qnorm(F), qlmomco(F, paraA), col=8, lwd=2)
lines(qnorm(F), qlmomco(F, para), lty=2)
points(qnorm(pp(X, a=0.40)), sort(X))

# Make sure to fill in the p-factor when needed!
bc &lt;- list(poly.type = "Bernstein", bound.type="Carv",
           stat.type="Mean", fix.lower=0, fix.upper=NULL, p=NULL)
kc &lt;- list(poly.type = "Kantorovich", bound.type="Carv",
           stat.type="Mean", fix.lower=0, fix.upper=NULL, p=NULL)

# Bernstein
A &lt;- pfactor.bernstein(para,      n=n, nsim=100,              bern.control=bc)
B &lt;- pfactor.bernstein(para, x=X, n=n, nsim=100,              bern.control=bc)
C &lt;- pfactor.bernstein(para,      n=n, nsim=100, lmr.dist=tr, bern.control=bc)
D &lt;- pfactor.bernstein(para, x=X, n=n, nsim=100, lmr.dist=tr, bern.control=bc)
plot(qnorm(pp(X, a=0.40)), sort(X), type="n", log="y",
      xlab="Standard normal variate", ylab="Quantile",
      xlim=qnorm(range(F)), ylim=range(qlmomco(F,paraA)))
lines(qnorm(F), qlmomco(F, paraA), col=8, lwd=2)
lines(qnorm(F), qlmomco(F, para), lty=2)
points(qnorm(pp(X, a=0.40)), sort(X))
      bc$p &lt;- A$pfactor
lines(qnorm(F), dat2bernqua(F,X, bern.control=bc), col=2)
      bc$p &lt;- B$pfactor
lines(qnorm(F), dat2bernqua(F,X, bern.control=bc), col=3)
      bc$p &lt;- C$pfactor
lines(qnorm(F), dat2bernqua(F,X, bern.control=bc), col=2, lty=2)
      bc$p &lt;- D$pfactor
lines(qnorm(F), dat2bernqua(F,X, bern.control=bc), col=3, lty=2)
# Kantorovich
A &lt;- pfactor.bernstein(para,      n=n, nsim=100,              bern.control=kc)
B &lt;- pfactor.bernstein(para, x=X, n=n, nsim=100,              bern.control=kc)
C &lt;- pfactor.bernstein(para,      n=n, nsim=100, lmr.dist=tr, bern.control=kc)
D &lt;- pfactor.bernstein(para, x=X, n=n, nsim=100, lmr.dist=tr, bern.control=kc)
plot(qnorm(pp(X, a=0.40)), sort(X), type="n", log="y",
      xlab="Standard normal variate", ylab="Quantile",
      xlim=qnorm(range(F)), ylim=range(qlmomco(F,paraA)))
lines(qnorm(F), qlmomco(F, paraA), col=8, lwd=2)
lines(qnorm(F), qlmomco(F, para), lty=2)
points(qnorm(pp(X, a=0.40)), sort(X))
      kc$p &lt;- A$pfactor
lines(qnorm(F), dat2bernqua(F,X, bern.control=kc), col=2)
      kc$p &lt;- B$pfactor
lines(qnorm(F), dat2bernqua(F,X, bern.control=kc), col=3)
      kc$p &lt;- C$pfactor
lines(qnorm(F), dat2bernqua(F,X, bern.control=kc), col=2, lty=2)
      kc$p &lt;- D$pfactor
lines(qnorm(F), dat2bernqua(F,X, bern.control=kc), col=3, lty=2)
dev.off()

## End(Not run)
## Not run: 
X &lt;- exp(rnorm(200)); para &lt;- parexp(lmoms(X))
"pfactor.root" &lt;- function(para, p.lo, p.hi, ...) {
    afunc &lt;- function(p, para=NULL, x=NULL, ...) {
      return(pfactor.bernstein(para=para, x=x, pfactors=p, ...)) }
    rt &lt;- uniroot(afunc, c(p.lo, p.hi),
                  tol=0.001, maxiter=30, nsim=500, para=para, ...)
    return(rt)
}
pfactor.root(para, 0.05, 0.15, n=10, lmr.n="4")
pfactor.bernstein(para, n=10, lmr.n="4", nsim=200, p.lo=.05, p.hi=.15)

## End(Not run)
</code></pre>

<hr>
<h2 id='plmomco'>Cumulative Distribution Function of the Distributions</h2><span id='topic+plmomco'></span>

<h3>Description</h3>

<p>This function acts as an alternative front end to <code><a href="#topic+par2cdf">par2cdf</a></code>. The nomenclature of the <code><a href="#topic+plmomco">plmomco</a></code> function is to mimic that of built-in <span class="rlang"><b>R</b></span> functions that interface with distributions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plmomco(x, para)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plmomco_+3A_x">x</code></td>
<td>
<p>A real value.</p>
</td></tr>
<tr><td><code id="plmomco_+3A_para">para</code></td>
<td>
<p>The parameters from <code><a href="#topic+lmom2par">lmom2par</a></code> or similar.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Nonexceedance probability (<code class="reqn">0 \le F \le 1</code>) for <code>x</code>.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>See Also</h3>

<p><code><a href="#topic+dlmomco">dlmomco</a></code>, <code><a href="#topic+qlmomco">qlmomco</a></code>, <code><a href="#topic+rlmomco">rlmomco</a></code>,  <code><a href="#topic+slmomco">slmomco</a></code>, <code><a href="#topic+add.lmomco.axis">add.lmomco.axis</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>para &lt;- vec2par(c(0,1),type='nor') # Standard Normal parameters
nonexceed &lt;- plmomco(1,para) # percentile of one standard deviation
</code></pre>

<hr>
<h2 id='plotlmrdia'>Plot L-moment Ratio Diagram (Tau3 and Tau4)</h2><span id='topic+plotlmrdia'></span>

<h3>Description</h3>

<p>Plot the Tau3-Tau4 L-moment ratio diagram of L-skew and L-kurtosis from a Tau3-Tau4 L-moment ratio diagram object returned by <code><a href="#topic+lmrdia">lmrdia</a></code>. This diagram is useful for selecting a distribution to model the data. The application of L-moment diagrams is well documented in the literature. This function is intended to function as a demonstration of L-moment ratio diagram plotting with enough user settings for many practical applications.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotlmrdia(lmr=NULL, nopoints=FALSE, nolines=FALSE, nolimits=FALSE,
           noaep4=FALSE, nogev=FALSE, noglo=FALSE,  nogno=FALSE, nogov=FALSE,
           nogpa=FALSE,  nope3=FALSE, nopdq3=FALSE, nowei=TRUE,
           nocau=TRUE,   noexp=FALSE, nonor=FALSE,  nogum=FALSE,
           noray=FALSE, nosla=TRUE, nouni=FALSE,
           xlab="L-skew (Tau3), dimensionless",
           ylab="L-kurtosis (Tau4), dimensionless", add=FALSE, empty=FALSE,
           autolegend=FALSE, xleg=NULL, yleg=NULL, legendcex=0.9,
           ncol=1, text.width=NULL, lwd.cex=1, expand.names=FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plotlmrdia_+3A_lmr">lmr</code></td>
<td>
<p>L-moment diagram object from <code><a href="#topic+lmrdia">lmrdia</a></code>, if <code>NULL</code>, then <code>empty</code> is internally set to <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="plotlmrdia_+3A_nopoints">nopoints</code></td>
<td>
<p>If <code>TRUE</code> then point distributions are not drawn.</p>
</td></tr>
<tr><td><code id="plotlmrdia_+3A_nolines">nolines</code></td>
<td>
<p>If <code>TRUE</code> then line distributions are not drawn.</p>
</td></tr>
<tr><td><code id="plotlmrdia_+3A_nolimits">nolimits</code></td>
<td>
<p>If <code>TRUE</code> then theoretical limits of L-moments are not drawn.</p>
</td></tr>
<tr><td><code id="plotlmrdia_+3A_noaep4">noaep4</code></td>
<td>
<p>If <code>TRUE</code> then the lower bounds line of Asymmetric Exponential Power distribution is not drawn.</p>
</td></tr>
<tr><td><code id="plotlmrdia_+3A_nogev">nogev</code></td>
<td>
<p>If <code>TRUE</code> then line of Generalized Extreme Value distribution is not drawn.</p>
</td></tr>
<tr><td><code id="plotlmrdia_+3A_noglo">noglo</code></td>
<td>
<p>If <code>TRUE</code> then line of Generalized Logistic distribution is not drawn.</p>
</td></tr>
<tr><td><code id="plotlmrdia_+3A_nogno">nogno</code></td>
<td>
<p>If <code>TRUE</code> then line of Generalized Normal (Log-Normal3) distribution is not drawn.</p>
</td></tr>
<tr><td><code id="plotlmrdia_+3A_nogov">nogov</code></td>
<td>
<p>If <code>TRUE</code> then line of Govindarajulu distribution is not drawn.</p>
</td></tr>
<tr><td><code id="plotlmrdia_+3A_nogpa">nogpa</code></td>
<td>
<p>If <code>TRUE</code> then line of Generalized Pareto distribution is not drawn.</p>
</td></tr>
<tr><td><code id="plotlmrdia_+3A_nope3">nope3</code></td>
<td>
<p>If <code>TRUE</code> then line of Pearson Type III distribution is not drawn.</p>
</td></tr>
<tr><td><code id="plotlmrdia_+3A_nopdq3">nopdq3</code></td>
<td>
<p>If <code>TRUE</code> then line of Polynomial Density-Quantile3 distribution is not drawn.</p>
</td></tr>
<tr><td><code id="plotlmrdia_+3A_nowei">nowei</code></td>
<td>
<p>If <code>TRUE</code> then line of the Weibull distribution is not drawn. The Weibull is a reverse of the Generalized Extreme Value. Traditionally in the literature, the Tau3-Tau4 L-moment ratio diagram have usually included the Weibull distribution and therefore the default setting of this argument is to not plot the Weibull.</p>
</td></tr>
<tr><td><code id="plotlmrdia_+3A_nocau">nocau</code></td>
<td>
<p>If <code>TRUE</code> then point (TL-moment [trim=1]) of the Cauchy distribution is not drawn.</p>
</td></tr>
<tr><td><code id="plotlmrdia_+3A_noexp">noexp</code></td>
<td>
<p>If <code>TRUE</code> then point of Exponential distribution is not drawn.</p>
</td></tr>
<tr><td><code id="plotlmrdia_+3A_nonor">nonor</code></td>
<td>
<p>If <code>TRUE</code> then point of Normal distribution is not drawn.</p>
</td></tr>
<tr><td><code id="plotlmrdia_+3A_nogum">nogum</code></td>
<td>
<p>If <code>TRUE</code> then point of Gumbel distribution is not drawn.</p>
</td></tr>
<tr><td><code id="plotlmrdia_+3A_noray">noray</code></td>
<td>
<p>If <code>TRUE</code> then point of Rayleigh distribution is not drawn.</p>
</td></tr>
<tr><td><code id="plotlmrdia_+3A_nouni">nouni</code></td>
<td>
<p>If <code>TRUE</code> then point of Uniform distribution is not drawn.</p>
</td></tr>
<tr><td><code id="plotlmrdia_+3A_nosla">nosla</code></td>
<td>
<p>If <code>TRUE</code> then point (TL-moment [trim=1]) of the Slash distribution is not drawn.</p>
</td></tr>
<tr><td><code id="plotlmrdia_+3A_xlab">xlab</code></td>
<td>
<p>Horizonal axis label passed to <code>xlab</code> of the <code>plot</code> function.</p>
</td></tr>
<tr><td><code id="plotlmrdia_+3A_ylab">ylab</code></td>
<td>
<p>Vertical axis label passed to <code>ylab</code> of the <code>plot</code> function.</p>
</td></tr>
<tr><td><code id="plotlmrdia_+3A_add">add</code></td>
<td>
<p>A logical to toggle a call to <code>plot</code> to start a new plot, otherwise, just the trajectories are otherwise plotted.</p>
</td></tr>
<tr><td><code id="plotlmrdia_+3A_empty">empty</code></td>
<td>
<p>A logical to return before any trajectories are plotted but after the condition of the <code>add</code> has been evaluated.</p>
</td></tr>
<tr><td><code id="plotlmrdia_+3A_autolegend">autolegend</code></td>
<td>
<p>Generate the legend by built-in algorithm.</p>
</td></tr>
<tr><td><code id="plotlmrdia_+3A_xleg">xleg</code></td>
<td>
<p>X-coordinate of the legend. This argument is checked for being a character versus a numeric. If it is a character, then <code>yleg</code> is not needed and <code>xleg</code> and take on &ldquo;location may also be specified by setting x to a single keyword&rdquo; as per the functionality of <code>graphics::legend()</code> itself.</p>
</td></tr>
<tr><td><code id="plotlmrdia_+3A_yleg">yleg</code></td>
<td>
<p>Y-coordinate of the legend.</p>
</td></tr>
<tr><td><code id="plotlmrdia_+3A_legendcex">legendcex</code></td>
<td>
<p>The <code>cex</code> to pass to <code>graphics::legend()</code>.</p>
</td></tr>
<tr><td><code id="plotlmrdia_+3A_ncol">ncol</code></td>
<td>
<p>The number of columns in which to set the legend items (default is 1, which differs from <code>legend()</code> default of 1).</p>
</td></tr>
<tr><td><code id="plotlmrdia_+3A_text.width">text.width</code></td>
<td>
<p>Argument of the same name for <code>legend</code>. Setting to 0.1 for <code>ncol</code> set to 2 seems to work pretty well when two columns are desired.</p>
</td></tr>
<tr><td><code id="plotlmrdia_+3A_lwd.cex">lwd.cex</code></td>
<td>
<p>Expansion factor on the line widths.</p>
</td></tr>
<tr><td><code id="plotlmrdia_+3A_expand.names">expand.names</code></td>
<td>
<p>Expand the distribution names in the legend.</p>
</td></tr>
<tr><td><code id="plotlmrdia_+3A_...">...</code></td>
<td>
<p>Additional arguments passed into <code>plot()</code> and <code>legend()</code> functions..</p>
</td></tr>
</table>


<h3>Note</h3>

<p>This function provides hardwired calls to <code>lines</code> and <code>points</code> to produce the diagram. The plot symbology for the shown distributions is summarized here. The Asymmetric Exponential Power and Kappa (four parameter) and Wakeby (five parameter) distributions are not well represented on the diagram as each constitute an area (Kappa) or hyperplane (Wakeby) and not a line (3-parameter distributions) or a point (2-parameter distributions). However, the Kappa demarks the area bounded by the Generalized Logistic (<code>glo</code>) on the top and the
theoretical L-moment limits on the bottom. The Asymmetric Exponential Power demarks its own unique lower boundary and extends up in the <code class="reqn">\tau_4</code> direction to <code class="reqn">\tau_4 = 1</code>. However, parameter estimation with L-moments has lost considerable accuracy for <code class="reqn">\tau_4</code> that large (see Asquith, 2014).
</p>

<table>
<tr>
 <td style="text-align: center;">
  <b>GRAPHIC TYPE</b> </td><td style="text-align: left;"> <b>GRAPHIC NATURE</b> </td>
</tr>
<tr>
 <td style="text-align: center;">
  L-moment Limits </td><td style="text-align: left;"> line width 2 and color a medium-dark grey </td>
</tr>
<tr>
 <td style="text-align: center;">
  Asymmetric Exponential Power (4-p) </td><td style="text-align: left;"> line width 1, line type 4 (dot), and color red </td>
</tr>
<tr>
 <td style="text-align: center;">
  Generalized Extreme Value (GEV) </td><td style="text-align: left;"> line width 1, line type 1 (solid), and color darkred </td>
</tr>
<tr>
 <td style="text-align: center;">
  Generalized Logistic </td><td style="text-align: left;"> line width 1 and color green </td>
</tr>
<tr>
 <td style="text-align: center;">
  Generalized Normal </td><td style="text-align: left;"> line width 1, line type 2 (dash), and color blue </td>
</tr>
<tr>
 <td style="text-align: center;">
  Govindarajulu </td><td style="text-align: left;"> line width 1, line type 2 (dash), and color 6 (magenta) </td>
</tr>
<tr>
 <td style="text-align: center;">
  Generalized Pareto </td><td style="text-align: left;"> line width 1, line type 1 (solid), and color blue </td>
</tr>
<tr>
 <td style="text-align: center;">
  Pearson Type III </td><td style="text-align: left;"> line width 1, line type 1 (solid), and color 6 (purple) </td>
</tr>
<tr>
 <td style="text-align: center;">
  Polynomial Density-Quantile3 </td><td style="text-align: left;"> line width 1.3, line type 2 (dash), and color darkgreen </td>
</tr>
<tr>
 <td style="text-align: center;">
  Weibull (reversed GEV) </td><td style="text-align: left;"> line width 1, line type 1 (solid), and color darkorange </td>
</tr>
<tr>
 <td style="text-align: center;">
  Exponential </td><td style="text-align: left;"> symbol 16 (filled circle) and color red </td>
</tr>
<tr>
 <td style="text-align: center;">
  Normal </td><td style="text-align: left;"> symbol 15 (filled square) and color red </td>
</tr>
<tr>
 <td style="text-align: center;">
  Gumbel </td><td style="text-align: left;"> symbol 17 (filled triangle) and color red) </td>
</tr>
<tr>
 <td style="text-align: center;">
  Rayleigh </td><td style="text-align: left;"> symbol 18 (filled diamond) and color red </td>
</tr>
<tr>
 <td style="text-align: center;">
  Uniform </td><td style="text-align: left;"> symbol 12 (square and a plus sign) and color red </td>
</tr>
<tr>
 <td style="text-align: center;">
  Cauchy </td><td style="text-align: left;"> symbol 13 (circle with over lapping <code class="reqn">\times</code>) and color turquoise4 </td>
</tr>
<tr>
 <td style="text-align: center;">
  Slash  </td><td style="text-align: left;"> symbol 10 (cicle containing <code class="reqn">+</code>) and color turquoise4 </td>
</tr>
<tr>
 <td style="text-align: center;">
</td>
</tr>

</table>



<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Asquith, W.H., 2011, Distributional analysis with L-moment statistics using the R environment for statistical computing: Createspace Independent Publishing Platform, ISBN 978&ndash;146350841&ndash;8.
</p>
<p>Asquith, W.H., 2014, Parameter estimation for the 4-parameter asymmetric exponential power distribution by the method of L-moments using R: Computational Statistics and Data Analysis, v. 71, pp. 955&ndash;970.
</p>
<p>Hosking, J.R.M., 1986, The theory of probability weighted moments: Research Report RC12210, IBM Research Division, Yorkton Heights, N.Y.
</p>
<p>Hosking, J.R.M., 1990, L-moments&mdash;Analysis and estimation of distributions using linear combinations of order statistics: Journal of the Royal Statistical Society, Series B, v. 52, pp. 105&ndash;124.
</p>
<p>Hosking, J.R.M., and Wallis, J.R., 1997, Regional frequency analysis&ndash;An approach based on L-moments: Cambridge University Press.
</p>
<p>Vogel, R.M., and Fennessey, N.M., 1993, L moment diagrams should replace product moment diagrams: Water Resources Research, v. 29, no. 6, pp. 1745&ndash;1752.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lmrdia">lmrdia</a></code>, <code><a href="#topic+plotlmrdia46">plotlmrdia46</a></code>, <code><a href="#topic+plotradarlmr">plotradarlmr</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>plotlmrdia(lmrdia()) # simplest of all uses

## Not run: 
# A more complex example follows: for a given mean, L-scale, L-skew, and L-kurtosis,
# use sample size of 30, use 500 simulations, set L-moments, fit the Kappa distribution
T3 &lt;- 0.34; T4 &lt;- 0.21; n &lt;- 30; nsim &lt;- 500
lmr &lt;- vec2lmom(c(10000, 7500, T3, T4)); kap &lt;- parkap(lmr)

# create vectors for storing simulated L-skew (t3) and L-kurtosis (t4)
t3 &lt;- t4 &lt;- vector(mode="numeric")

# perform nsim simulations by randomly drawing from the Kappa distribution
# and compute the L-moments in sim.lmr and store the t3 and t4 of each sample
for(i in 1:nsim) {
  sim.lmr &lt;- lmoms(rlmomco(n, kap))
  t3[i] &lt;- sim.lmr$ratios[3]; t4[i] &lt;- sim.lmr$ratios[4]
}

# plot the diagram and "zoom" by manually setting the axis limits
plotlmrdia(xlim=c(-0.1, 0.5), ylim=c(-0.1, 0.4), las=1, empty=TRUE)

# Follow up by plotting the {t3, t4} values and the mean of the values
points(t3, t4, pch=21, bg="white", lwd=0.8) # plot each simulation

# plot crossing dashed lines at true values of L-skew and L-kurtosis
abline(v=T3, col="salmon4", lty=2, lwd=3) # Theoretical values for the
abline(h=T4, col="salmon4", lty=2, lwd=3) # distribution as fit

points(mean(t3), mean(t4), pch=16, cex=3) # mean of simulations and
# should plot reasonably close to the salmon4-colored crossing lines

# plot the trajectories of the distributions
plotlmrdia(lmrdia(), add=TRUE, nopoints=TRUE, inset=0.01,
           autolegend=TRUE, xleg="topleft", lwd.cex=1.5) # 
## End(Not run)
</code></pre>

<hr>
<h2 id='plotlmrdia46'>Plot L-moment Ratio Diagram (Tau4 and Tau6)</h2><span id='topic+plotlmrdia46'></span>

<h3>Description</h3>

<p>Plot the Tau4-Tau6 L-moment ratio diagram showing trajectories of <code class="reqn">\tau_4</code> and <code class="reqn">\tau_6</code> for strictly symmetrical distributions from a Tau4-Tau6 L-moment ratio diagram object returned by <code><a href="#topic+lmrdia46">lmrdia46</a></code>. This diagram is useful for selecting among symmetrical distributions to model the data. This function is intended to function as a demonstration of Tau4-Tau6 L-moment ratio diagram plotting with enough user settings for many practical applications.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotlmrdia46(lmr=NULL, nopoints=FALSE, nolines=FALSE,
             noaep4=FALSE, nogld_byt5opt=TRUE,
             nopdq4=FALSE, nost3=FALSE, nosymstable=FALSE, notukey=FALSE,
             nocau=TRUE,   nonor=FALSE, nosla=TRUE, trucate.tau4.to.gtzero=TRUE,
             xlab="L-kurtosis (Tau4), dimensionless",
             ylab="Sixth L-moment ratio (Tau6), dimensionless",
             add=FALSE, empty=FALSE,
             autolegend=FALSE, xleg=NULL, yleg=NULL, legendcex=0.9,
             ncol=1, text.width=NULL, lwd.cex=1, expand.names=FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plotlmrdia46_+3A_lmr">lmr</code></td>
<td>
<p>L-moment diagram object from <code><a href="#topic+lmrdia46">lmrdia46</a></code>, if <code>NULL</code>, then <code>empty</code> is internally set to <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="plotlmrdia46_+3A_nopoints">nopoints</code></td>
<td>
<p>If <code>TRUE</code> then point distributions are not drawn.</p>
</td></tr>
<tr><td><code id="plotlmrdia46_+3A_nolines">nolines</code></td>
<td>
<p>If <code>TRUE</code> then line distributions are not drawn.</p>
</td></tr>
<tr><td><code id="plotlmrdia46_+3A_noaep4">noaep4</code></td>
<td>
<p>If <code>TRUE</code> then the Symmetric Exponential Power distribution is not drawn.</p>
</td></tr>
<tr><td><code id="plotlmrdia46_+3A_nogld_byt5opt">nogld_byt5opt</code></td>
<td>
<p>If <code>TRUE</code> then line of Generalized Lambda distribution through it solution optimization on <code class="reqn">\tau_5 = 0</code> is not drawn.</p>
</td></tr>
<tr><td><code id="plotlmrdia46_+3A_nopdq4">nopdq4</code></td>
<td>
<p>If <code>TRUE</code> then line of Polynomial Density-Quantile4 distribution is not drawn.</p>
</td></tr>
<tr><td><code id="plotlmrdia46_+3A_nost3">nost3</code></td>
<td>
<p>If <code>TRUE</code> then line of Student 3t distribution is not drawn.</p>
</td></tr>
<tr><td><code id="plotlmrdia46_+3A_nosymstable">nosymstable</code></td>
<td>
<p>If <code>TRUE</code> then line of Symmetric Stable distribution is not drawn.</p>
</td></tr>
<tr><td><code id="plotlmrdia46_+3A_notukey">notukey</code></td>
<td>
<p>If <code>TRUE</code> then line of Tukey Lambda distribution is not drawn.</p>
</td></tr>
<tr><td><code id="plotlmrdia46_+3A_nocau">nocau</code></td>
<td>
<p>If <code>TRUE</code> then point of Cauchy distribution (trim=1 L-moments) is not drawn.</p>
</td></tr>
<tr><td><code id="plotlmrdia46_+3A_nonor">nonor</code></td>
<td>
<p>If <code>TRUE</code> then point of Normal distribution is not drawn.</p>
</td></tr>
<tr><td><code id="plotlmrdia46_+3A_nosla">nosla</code></td>
<td>
<p>If <code>TRUE</code> then point of Slash distribution (trim=1 L-moments) is not drawn.</p>
</td></tr>
<tr><td><code id="plotlmrdia46_+3A_trucate.tau4.to.gtzero">trucate.tau4.to.gtzero</code></td>
<td>
<p>Truncate the distributions that can extend to negative <code class="reqn">\tau_4</code> to zero. This is a reasonable default and prevents line drawing to the left into a clipping region for easier handling of post processing of a graphic in vector editing software.</p>
</td></tr>
<tr><td><code id="plotlmrdia46_+3A_xlab">xlab</code></td>
<td>
<p>Horizonal axis label passed to <code>xlab</code> of the <code>plot</code> function.</p>
</td></tr>
<tr><td><code id="plotlmrdia46_+3A_ylab">ylab</code></td>
<td>
<p>Vertical axis label passed to <code>ylab</code> of the <code>plot</code> function.</p>
</td></tr>
<tr><td><code id="plotlmrdia46_+3A_add">add</code></td>
<td>
<p>A logical to toggle a call to <code>plot</code> to start a new plot, otherwise, just the trajectories are otherwise plotted.</p>
</td></tr>
<tr><td><code id="plotlmrdia46_+3A_empty">empty</code></td>
<td>
<p>A logical to return before any trajectories are plotted but after the condition of the <code>add</code> has been evaluated.</p>
</td></tr>
<tr><td><code id="plotlmrdia46_+3A_autolegend">autolegend</code></td>
<td>
<p>Generate the legend by built-in algorithm.</p>
</td></tr>
<tr><td><code id="plotlmrdia46_+3A_xleg">xleg</code></td>
<td>
<p>X-coordinate of the legend. This argument is checked for being a character versus a numeric. If it is a character, then <code>yleg</code> is not needed and <code>xleg</code> and take on &ldquo;location may also be specified by setting x to a single keyword&rdquo; as per the functionality of <code>graphics::legend()</code> itself.</p>
</td></tr>
<tr><td><code id="plotlmrdia46_+3A_yleg">yleg</code></td>
<td>
<p>Y-coordinate of the legend.</p>
</td></tr>
<tr><td><code id="plotlmrdia46_+3A_legendcex">legendcex</code></td>
<td>
<p>The <code>cex</code> to pass to <code>graphics::legend()</code>.</p>
</td></tr>
<tr><td><code id="plotlmrdia46_+3A_ncol">ncol</code></td>
<td>
<p>The number of columns in which to set the legend items (default is 1, which differs from <code>legend()</code> default of 1).</p>
</td></tr>
<tr><td><code id="plotlmrdia46_+3A_text.width">text.width</code></td>
<td>
<p>Argument of the same name for <code>legend</code>. Setting to 0.1 for <code>ncol</code> set to 2 seems to work pretty well when two columns are desired.</p>
</td></tr>
<tr><td><code id="plotlmrdia46_+3A_lwd.cex">lwd.cex</code></td>
<td>
<p>Expansion factor on the line widths.</p>
</td></tr>
<tr><td><code id="plotlmrdia46_+3A_expand.names">expand.names</code></td>
<td>
<p>Expand the distribution names in the legend.</p>
</td></tr>
<tr><td><code id="plotlmrdia46_+3A_...">...</code></td>
<td>
<p>Additional arguments passed into the <code>plot()</code> and <code>legend()</code> functions.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>This function provides hardwired calls to <code>lines</code> and <code>points</code> to produce the diagram. The plot symbology for the shown distributions is summarized here.
</p>

<table>
<tr>
 <td style="text-align: center;">
  <b>GRAPHIC TYPE</b> </td><td style="text-align: left;"> <b>GRAPHIC NATURE</b> </td>
</tr>
<tr>
 <td style="text-align: center;">
  Symmetric Exponential Power </td><td style="text-align: left;"> line width 1, line type 4 (dot), and color red </td>
</tr>
<tr>
 <td style="text-align: center;">
  Generalized Lambda </td><td style="text-align: left;"> line width 1, line type 1 (solid), and color purple </td>
</tr>
<tr>
 <td style="text-align: center;">
  Polynomial Density-Quantile4 </td><td style="text-align: left;"> line width 1, line type 1 (solid), and color darkgreen </td>
</tr>
<tr>
 <td style="text-align: center;">
  Student t </td><td style="text-align: left;"> line width 1, line type 1 (solid), and color blue</td>
</tr>
<tr>
 <td style="text-align: center;">
  Symmetric Stable </td><td style="text-align: left;"> line width 2, line type 1 (solid), and color a medium-dark grey</td>
</tr>
<tr>
 <td style="text-align: center;">
  Tukey Lambda (1-p) </td><td style="text-align: left;"> line width 1, line type 2 (dash), and color purple</td>
</tr>
<tr>
 <td style="text-align: center;">
  Normal </td><td style="text-align: left;"> symbol 15 (filled square) and color red </td>
</tr>
<tr>
 <td style="text-align: center;">
  Cauchy </td><td style="text-align: left;"> symbol 13 (circle with over lapping <code class="reqn">\times</code>) and color turquoise4 </td>
</tr>
<tr>
 <td style="text-align: center;">
  Slash  </td><td style="text-align: left;"> symbol 10 (cicle containing <code class="reqn">+</code>) and color turquoise4 </td>
</tr>
<tr>
 <td style="text-align: center;">

</td>
</tr>

</table>



<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Asquith, W.H., 2014, Parameter estimation for the 4-parameter asymmetric exponential power distribution by the method of L-moments using R: Computational Statistics and Data Analysis, v. 71, pp. 955&ndash;970.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lmrdia46">lmrdia46</a></code>, <code><a href="#topic+plotlmrdia">plotlmrdia</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>plotlmrdia46(lmrdia46(), nogld_byt5opt=FALSE, autolegend=TRUE,
             xleg="topleft")


## Not run: 
# A more complex example follows: for a given mean, L-scale, L-skew = 0 (symmetry), and
# L-kurtosis, use sample size of 30, use 500 simulations, set L-moments,
# fit the Asymmetric Exponential Power4 distribution, which is symmetrical when the
# L-skew is zero and thus the distribution is the Exponential Power.
T3  &lt;- 0; T4 &lt;- 0.21; n &lt;- 30; nsim &lt;- 500
lmr &lt;- vec2lmom(c(10000, 7500, T3, T4, 0)); aep4 &lt;- paraep4(lmr)
T6  &lt;- theoLmoms(aep4, nmom=6)$ratios[6]

# create vectors for storing simulated L-kurtosis (t4) and Tau6 (t6)
t4 &lt;- t6 &lt;- vector(mode="numeric")

# perform nsim simulations by randomly drawing from the AEP4 distribution
# and compute the L-moments in sim.lmr and store the t4 and t6 of each sample
for(i in 1:nsim) {
  sim.lmr &lt;- lmoms(rlmomco(n, aep4), nmom=6)
  t4[i] &lt;- sim.lmr$ratios[4]; t6[i] &lt;- sim.lmr$ratios[6]
}

# plot the diagram and "zoom" by manually setting the axis limits
plotlmrdia46(xlim=c(-0.05, 0.5), ylim=c(-0.1, 0.35), las=1, empty=TRUE)

# follow up by plotting the {t3, t4} values and the mean of the values
points(t4, t6, cex=0.8, pch=21, bg="white", lwd=0.8) # plot each simulation

# plot crossing dashed lines at true values of L-skew and L-kurtosis
abline(v=T4, col="salmon4", lty=2, lwd=3) # Theoretical values for the
abline(h=T6, col="salmon4", lty=2, lwd=3) # distribution as fit

points(mean(t4), mean(t6), pch=16, cex=3) # mean of simulations and
# should plot reasonably close to the salmon4-colored crossing lines

# plot the trajectories of the distributions
plotlmrdia46(lmrdia46(), add=TRUE, nopoints=TRUE, inset=0.01,
             autolegend=TRUE, xleg="topleft", lwd.cex=1.5) # 
## End(Not run)
</code></pre>

<hr>
<h2 id='plotradarlmr'>Plot L-moment Radar Plot (Chart) Graphic</h2><span id='topic+plotradarlmr'></span>

<h3>Description</h3>

<p>Plot a L-moment radar plots (charts).  This graphic is somewhat experimental and of unknown application benefit as no known precedent seems available. L-moment ratio diagrams (<code><a href="#topic+plotlmrdia">plotlmrdia</a></code>) are incredibly useful but have generally been restricted to the 2-D domain. The graphic supported here attempts to provide a visualization of <code class="reqn">\tau_r</code> for an arbitrary <code class="reqn">(r-2) &gt; 3</code> number of axes in the form of a radar plot. The angle of the axes is uninformative but the order of the axes is for <code class="reqn">\tau_r</code> for <code class="reqn">r = 3, 4, \cdots</code>. The radar plot is essentially a line graph but mapped to a circular space at the expense of more <em>ink</em> being used. The radar plot is primarily intended to be a mechansim in <span class="pkg">lmomco</span> for which similarity between other radar plots or presence of outlier combinations of <code class="reqn">\tau_r</code> can be judged when seen amongst various samples.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotradarlmr(lmom, num.axis=4, plot=TRUE, points=FALSE, poly=TRUE, tag=NA,
             title="L-moment Ratio Radar Plot", make.zero.axis=FALSE,
             minrat=NULL, maxrat=NULL, theomins=TRUE, rot=0,
             labadj=1.2, lengthadj=1.75, offsetadj=0.25, scaleadj=2.2,
     axis.control  = list(col=1, lty=2, lwd=0.5, axis.cex=0.75, lab.cex=0.95),
     point.control = list(col=8, lwd=0.5, pch=16),
     poly.control  = list(col=rgb(0,0,0,.1), border=1, lty=1, lwd=1), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plotradarlmr_+3A_lmom">lmom</code></td>
<td>
<p>L-moment object such as from <code><a href="#topic+lmoms">lmoms</a></code>.</p>
</td></tr>
<tr><td><code id="plotradarlmr_+3A_num.axis">num.axis</code></td>
<td>
<p>The number of axes. Some error trapping in axis count relative to the length of the <code class="reqn">\tau_r</code> in <code>lmom</code> is made.</p>
</td></tr>
<tr><td><code id="plotradarlmr_+3A_plot">plot</code></td>
<td>
<p>A logical controlling whether <span class="rlang"><b>R</b></span> function <code>plot</code> will be called.</p>
</td></tr>
<tr><td><code id="plotradarlmr_+3A_points">points</code></td>
<td>
<p>A logical controlling whether the points of defined by the <code class="reqn">\tau_r</code> in <code>lmom</code>.</p>
</td></tr>
<tr><td><code id="plotradarlmr_+3A_poly">poly</code></td>
<td>
<p>A logical controlling whether the polygon of defined by the <code class="reqn">\tau_r</code> in <code>lmom</code>.</p>
</td></tr>
<tr><td><code id="plotradarlmr_+3A_tag">tag</code></td>
<td>
<p>A text tag plotted at the center of the plot. An <code>NA</code> will result in nothing being plotted.</p>
</td></tr>
<tr><td><code id="plotradarlmr_+3A_title">title</code></td>
<td>
<p>The title of the plot. An <code>NA</code> will result in nothing being plotted.</p>
</td></tr>
<tr><td><code id="plotradarlmr_+3A_make.zero.axis">make.zero.axis</code></td>
<td>
<p>A logical controlling whether polygon will be &ldquo;faked in&rdquo; like as if <code class="reqn">\tau_r</code> having all zeros are provided. This feature is to act as a mechanism to overlay only the zero axis such as might be needed when a lot of other material has been already been drawn on the plot.</p>
</td></tr>
<tr><td><code id="plotradarlmr_+3A_minrat">minrat</code></td>
<td>
<p>A vector of the minimum values for the <code class="reqn">\tau_r</code> axes in case the user desired to have some zoomability. The default is all <code class="reqn">-1</code> values, and a scalar for <code>minrat</code> will be repeated for the <code>num.axis</code>.</p>
</td></tr>
<tr><td><code id="plotradarlmr_+3A_maxrat">maxrat</code></td>
<td>
<p>A vector of the maximum values for the <code class="reqn">\tau_r</code> axes in case the user desired to have some zoomability. The default is all <code class="reqn">+1</code> values, and a scalar for <code>maxrat</code> will be repeated for the <code>num.axis</code>.</p>
</td></tr>
<tr><td><code id="plotradarlmr_+3A_theomins">theomins</code></td>
<td>
<p>The are some basic and fundamental lower limits other than -1 that if used provide for a better relative scaling of the axes on the plot. If <code>TRUE</code>, then some select overwritting of potential user-provided <code>minrat</code> is provided.</p>
</td></tr>
<tr><td><code id="plotradarlmr_+3A_rot">rot</code></td>
<td>
<p>The basic rotational offset for the angle of the first (<code class="reqn">\tau_3</code>) axis.</p>
</td></tr>
<tr><td><code id="plotradarlmr_+3A_labadj">labadj</code></td>
<td>
<p>An adjustment multiplier to help positions of the axis titles.</p>
</td></tr>
<tr><td><code id="plotradarlmr_+3A_lengthadj">lengthadj</code></td>
<td>
<p>An adjustment multiplier characterize axis length.</p>
</td></tr>
<tr><td><code id="plotradarlmr_+3A_offsetadj">offsetadj</code></td>
<td>
<p>An adjustment to help set the empty space in the middle of the plot for the <code>tag</code>.</p>
</td></tr>
<tr><td><code id="plotradarlmr_+3A_scaleadj">scaleadj</code></td>
<td>
<p>An adjustment multiplier to help set the parent domain of the underlying (but hidden) x-y plot called by the <span class="rlang"><b>R</b></span> function <code>plot</code>.</p>
</td></tr>
<tr><td><code id="plotradarlmr_+3A_axis.control">axis.control</code></td>
<td>
<p>A specially built and not error trapped <span class="rlang"><b>R</b></span> <code>list</code> to hold the control elements of the axes.</p>
</td></tr>
<tr><td><code id="plotradarlmr_+3A_point.control">point.control</code></td>
<td>
<p>A specially built and not error trapped <span class="rlang"><b>R</b></span> <code>list</code> to hold the control elements for plotting of the points if <code>points=TRUE</code>.</p>
</td></tr>
<tr><td><code id="plotradarlmr_+3A_poly.control">poly.control</code></td>
<td>
<p>A specially built and not error trapped <span class="rlang"><b>R</b></span> <code>list</code> to hold the control elements for plotting of the polygon if <code>poly=TRUE</code>.</p>
</td></tr>
<tr><td><code id="plotradarlmr_+3A_...">...</code></td>
<td>
<p>Additional arguments passed on to the <span class="rlang"><b>R</b></span> function <code>text</code> function for the <code>title</code> and <code>tag</code>. This argument is largely not intended for general use, unlike most idioms of <code>...</code> in <span class="rlang"><b>R</b></span>, but is provided at the release of this function to help developers and avoid future backwards compatibility problems.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>This function has many implicit flexible features. The example below attempts to be reasonably comprehensive. Note that in the example that it is required to continue &ldquo;knowing&rdquo; what <code>minrat</code> and <code>maxrat</code> where used with <code>plot=TRUE</code>.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>See Also</h3>

<p><code><a href="#topic+plotlmrdia">plotlmrdia</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
plotradarlmr(NULL, minrat=-0.6, maxrat=0.6, tag="2 GEVs") # create the plot base
gev  &lt;- vec2par(c(1230,123,-.24), type="gev") # set first parent distribution
poly &lt;- list(col=NA, border=rgb(0,0,1,.1))    # set up polygon handling (blue)
for(i in 1:100) { # perform 100 simulations of the GEV with a sample of size 36
   plotradarlmr(lmoms(rlmomco(36,gev), nmom=6), plot=FALSE,
                poly.control=poly, minrat=-0.6, maxrat=0.6)
}
poly &lt;- list(col=NA, border=4, lwd=3) # set up parent polygon
plotradarlmr(theoLmoms(gev, nmom=6), plot=FALSE,
             poly.control=poly, minrat=-0.6, maxrat=0.6) # draw the parent
 gev &lt;- vec2par(c(450,1323,.5), type="gev") # set second parent distribution
poly &lt;- list(col=NA, border=rgb(0,1,0,.1))  # set up polygon handling (green)
for(i in 1:100) { # perform 100 simulations of the GEV with a sample of size 36
   plotradarlmr(lmoms(rlmomco(36,gev), nmom=6), plot=FALSE,
                poly.control=poly, minrat=-0.6, maxrat=0.6) # draw the parent
}
poly &lt;- list(col=NA, border=3, lwd=3) # set up parent polygon
plotradarlmr(theoLmoms(gev, nmom=6), plot=FALSE,
             poly.control=poly, minrat=-0.6, maxrat=0.6)
poly &lt;- list(col=NA, border=6, lty=1, lwd=2) # make the zeros purple to standout.
plotradarlmr(NULL, make.zero.axis=TRUE, plot=FALSE,
             poly.control=poly, minrat=-0.6, maxrat=0.6) # 
## End(Not run)
</code></pre>

<hr>
<h2 id='pmoms'>The Sample Product Moments: Mean, Standard Deviation, Skew, and Excess Kurtosis</h2><span id='topic+pmoms'></span>

<h3>Description</h3>

<p>Compute the first four sample product moments. Both classical (theoretical and biased) versions and unbiased (nearly) versions are produced. Readers are directed to the References and the source code for implementation details.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pmoms(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pmoms_+3A_x">x</code></td>
<td>
<p>A real value vector.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> is returned.
</p>
<table>
<tr><td><code>moments</code></td>
<td>
<p>Vector of the product moments: first element is the mean (<code>mean</code> in <span class="rlang"><b>R</b></span>), second is standard deviation, and the higher values typically are not used as these are not unbiased moments, but the ratios[3] and ratios[4] are nearly unbiased.</p>
</td></tr>
<tr><td><code>ratios</code></td>
<td>
<p>Vector of the product moment ratios. Second element is the coefficient of variation, ratios[3] is skew, and ratios[4] is kurtosis.</p>
</td></tr>
<tr><td><code>sd</code></td>
<td>
<p>Nearly unbiased standard deviation [well at least unbiased variance <br /> (<code>unbiased.sd^2</code>)] computed by <span class="rlang"><b>R</b></span> function <code>sd</code>. </p>
</td></tr>
<tr><td><code>umvu.sd</code></td>
<td>
<p>Uniformly-minimum variance unbiased estimator of standard deviation.</p>
</td></tr>
<tr><td><code>skew</code></td>
<td>
<p>Nearly unbiased skew, same as ratios[3].</p>
</td></tr>
<tr><td><code>kurt</code></td>
<td>
<p>Nearly unbiased kurtosis, same as ratios[4].</p>
</td></tr>
<tr><td><code>excesskurt</code></td>
<td>
<p>Excess kurtosis from the Normal distribution: <code>kurt - 3</code>.</p>
</td></tr>
<tr><td><code>classic.sd</code></td>
<td>
<p>Classical (theoretical) definition of standard deviation.</p>
</td></tr>
<tr><td><code>classic.skew</code></td>
<td>
<p>Classical (theoretical) definition of skew.</p>
</td></tr>
<tr><td><code>classic.kurt</code></td>
<td>
<p>Classical (theoretical) definition of kurtosis</p>
</td></tr>
<tr><td><code>classic.excesskurt</code></td>
<td>
<p>Excess classical (theoretical) kurtosis from <br /> Normal distribution: <code>classic.kurt - 3</code>.</p>
</td></tr>
<tr><td><code>message</code></td>
<td>
<p>The product moments are confusing in terms of definition because they are not naturally unbiased.  This characteristic is different from the L-moments. The author thinks that it is informative to show the biased versions within the &ldquo;classic&rdquo; designations. Therefore, this <code>message</code> includes several clarifications of the output.</p>
</td></tr>
<tr><td><code>source</code></td>
<td>
<p>An attribute identifying the computational source (the function name) of the product moments: &ldquo;pmoms&rdquo;.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>This function is primarily available for gamesmanship with the Pearson Type III distribution as its parameterization in <span class="pkg">lmomco</span> returns the product moments as the very parameters of that distribution. This of course is like the Normal distribution in which the first two parameters are the first two product moments; the Pearson Type III just adds skew.  See the example below. Another reason for having this function in <span class="pkg">lmomco</span> is that it demonstrates application of unbiased product moments and permits comparisons to the L-moments (see Asquith, 2011; figs. 12.13&ndash;12.16).
</p>
<p>The <code>umvu.sd</code> is computed by
</p>
<p style="text-align: center;"><code class="reqn">\hat\sigma' = \frac{\Gamma[(n-1)/2]}{\Gamma(n/2)\sqrt{2}}\sqrt{\sum_{i=1}^{n} (x_i - \hat\mu)^2}\mbox{,}</code>
</p>

<p>where <code class="reqn">\hat\sigma'</code> is the estimate of standard deviation for the sample <code class="reqn">x</code> of size <code class="reqn">n</code>, <code class="reqn">\Gamma(\cdots)</code> is the complete gamma function, and <code class="reqn">\hat\mu</code> is the arthimetic mean.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Asquith, W.H., 2011, Distributional analysis with L-moment statistics using the R environment for statistical computing: Createspace Independent Publishing Platform, ISBN 978&ndash;146350841&ndash;8.
</p>
<p>Hosking, J.R.M., and Wallis, J.R., 1997, Regional frequency analysis&mdash;An approach based on L-moments: Cambridge University Press.
</p>
<p>Joanes, D.N., Gill, C.A., 1998, Comparing measures of sample skewness and kurtosis: The Statistician, v. 47, no. 1, pp. 183&ndash;189.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lmoms">lmoms</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'># A simple example
PM &lt;- pmoms(rnorm(1000)) # n standard normal values as a fake data set.
cat(c(PM$moments[1],PM$moments[2],PM$ratios[3],PM$ratios[4],"\n"))
# As sample size gets very large the four values returned should be
# 0,1,0,0 by definition of the standard normal distribution.

# A more complex example
para &lt;- vec2par(c(100,500,3),type='pe3') # mean=100, sd=500, skew=3
# The Pearson type III distribution is implemented here such that
# the "parameters" are equal to the mean, standard deviation, and skew.
simDATA &lt;- rlmomco(100,para) # simulate 100 observations
PM &lt;- pmoms(simDATA) # compute the product moments

p.tmp &lt;- c(PM$moments[1],PM$moments[2],PM$ratios[3])
cat(c("Sample P-moments:",p.tmp,"\n"))
# This distribution has considerable variation and large skew. Stability
# of the sample product moments requires LARGE sample sizes (too large
# for a builtin example)

# Continue the example through the L-moments
lmr &lt;- lmoms(simDATA) # compute the L-moments
epara &lt;- parpe3(lmr) # estimate the Pearson III parameters. This is a
# hack to back into comparative estimates of the product moments. This
# can only be done because we know that the parent distribution is a
# Pearson Type III

l.tmp &lt;- c(epara$para[1],epara$para[2],epara$para[3])
cat(c("PearsonIII by L-moments:",l.tmp,"\n"))
# The first values are the means and will be identical and close to 100.
# The second values are the standard deviations and the L-moment to
#   PearsonIII will be closer to 500 than the product moment (this
#   shows the raw power of L-moment based analysis---they work).
# The third values are the skew. Almost certainly the L-moment estimate
#   of skew will be closer to 3 than the product moment.
</code></pre>

<hr>
<h2 id='pp'>Plotting-Position Formula</h2><span id='topic+pp'></span>

<h3>Description</h3>

<p>The plotting positions of a data vector (<code>x</code>) are returned in ascending order. The plotting-position formula is
</p>
<p style="text-align: center;"><code class="reqn">pp_i = \frac{i-a}{n+1-2a} \mbox{,}</code>
</p>

<p>where <code class="reqn">pp_i</code> is the nonexceedance probability <code class="reqn">F</code> of the <code class="reqn">i</code>th ascending data value. The parameter <code class="reqn">a</code> specifies the plotting-position type, and <code class="reqn">n</code> is the sample size (<code>length(x)</code>). Alternatively, the plotting positions can be computed by
</p>
<p style="text-align: center;"><code class="reqn">pp_i = \frac{i+A}{n+B} \mbox{,}</code>
</p>

<p>where <code class="reqn">A</code> and <code class="reqn">B</code> can obviously be expressed in terms of <code class="reqn">a</code> for <code class="reqn">B &gt; A &gt; -1</code> (Hosking and Wallis, 1997, sec. 2.8).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pp(x, A=NULL, B=NULL, a=0, sort=TRUE, ties.method="first", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pp_+3A_x">x</code></td>
<td>
<p>A vector of data values. The vector is used to get sample size through <code>length</code>.</p>
</td></tr>
<tr><td><code id="pp_+3A_a">A</code></td>
<td>
<p>A value for the plotting-position coefficient <code class="reqn">A</code>.</p>
</td></tr>
<tr><td><code id="pp_+3A_b">B</code></td>
<td>
<p>A value for the plotting-position coefficient <code class="reqn">B</code>.</p>
</td></tr>
<tr><td><code id="pp_+3A_a">a</code></td>
<td>
<p>A value for the plotting-position formula from which <code class="reqn">A</code> and <code class="reqn">B</code> are computed, default is <code>a=0</code>, which returns the Weibull plotting positions.</p>
</td></tr>
<tr><td><code id="pp_+3A_sort">sort</code></td>
<td>
<p>A logical whether the ranks of the data are sorted prior to <code class="reqn">F</code> computation. It was a design mistake years ago to default this function to a sort, but it is now far too late to risk changing the logic now. The function originally lacked the <code>sort</code> argument for many years.</p>
</td></tr>
<tr><td><code id="pp_+3A_ties.method">ties.method</code></td>
<td>
<p>This is the argument of the same name passed to <code>rank</code>.</p>
</td></tr>
<tr><td><code id="pp_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>vector</code> is returned.
</p>


<h3>Note</h3>

<p>Various plotting positions have been suggested in the literature. Stedinger and others (1992, p.18.25) comment that &ldquo;all plotting positions give crude estimates of the unknown [non]exceedance probabilities associated with the largest (and smallest) events.&rdquo; The various plotting positions are summarized in the follow table.
</p>

<dl>
<dt>Weibull</dt><dd><p><code class="reqn">a=0</code>, Unbiased exceedance probability for all distributions (see discussion in <code><a href="#topic+pp.f">pp.f</a></code>).</p>
</dd>
<dt>Median</dt><dd><p><code class="reqn">a=0.3175</code>, Median exceedance probabilities for all distributions (if so, see <code><a href="#topic+pp.median">pp.median</a></code>).</p>
</dd>
<dt>APL</dt><dd><p><code class="reqn">\approx 0.35</code>, Often used with probability-weighted moments.</p>
</dd>
<dt>Blom</dt><dd><p><code class="reqn">a=0.375</code>, Nearly unbiased quantiles for normal distribution.</p>
</dd>
<dt>Cunnane</dt><dd><p><code class="reqn">a=0.40</code>, Approximately quantile unbiased.</p>
</dd>
<dt>Gringorten</dt><dd><p><code class="reqn">a=0.44</code>, Optimized for Gumbel distribution.</p>
</dd>
<dt>Hazen</dt><dd><p><code class="reqn">a=0.50</code>, A traditional choice.</p>
</dd>
</dl>

<p>The function uses the <span class="rlang"><b>R</b></span> <code>rank</code> function, which has specific settings to handle tied data. For implementation here, the <code>ties.method="first"</code> method to <code>rank</code> is used. The user has flexibility in changing this to their own custom purposes.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Hosking, J.R.M., and Wallis, J.R., 1997, Regional frequency analysis&mdash;An
approach based on L-moments: Cambridge University Press.
</p>
<p>Stedinger, J.R., Vogel, R.M., and Foufoula-Georgiou, E., 1992, Frequency analysis of extreme events, in Handbook of Hydrology, chapter 18, editor-in-chief D. A. Maidment: McGraw-Hill, New York.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+nonexceeds">nonexceeds</a></code>, <code><a href="#topic+pwm.pp">pwm.pp</a></code>, <code><a href="#topic+pp.f">pp.f</a></code>, <code><a href="#topic+pp.median">pp.median</a></code>, <code><a href="#topic+headrick.sheng.lalpha">headrick.sheng.lalpha</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>Q  &lt;- rnorm(20)
PP &lt;- pp(Q)
plot(PP, sort(Q))

Q &lt;- rweibull(30, 1.4, scale=400)
WEI &lt;- parwei(lmoms(Q))
PP &lt;- pp(Q)
plot( PP, sort(Q))
lines(PP, quawei(PP, WEI))

# This plot looks similar, but when connecting lines are added
# the nature of the sorting is obvious.
plot( pp(Q, sort=FALSE), Q)
lines(pp(Q, sort=FALSE), Q, col=2)
</code></pre>

<hr>
<h2 id='pp.f'>Quantile Function of the Ranks of Plotting Positions </h2><span id='topic+pp.f'></span>

<h3>Description</h3>

<p>There are two major forms (outside of the general plotting-position formula <code><a href="#topic+pp">pp</a></code>) for estimation of the <code class="reqn">p_r</code>th probability of the <code class="reqn">r</code>th order statistic for a sample of size <code class="reqn">n</code>: the mean is <code class="reqn">pp'_r = r/(n+1)</code> (Weibull plotting position) and the Beta quantile function is <code class="reqn">pp_r(F) = IIB(F, r, n+1-r)</code>, where <code class="reqn">F</code> represents the nonexceedance probability of the plotting position.  <code class="reqn">IIB</code> is the &ldquo;inverse of the incomplete beta function&rdquo; or the quantile function of the Beta distribution as provided in <span class="rlang"><b>R</b></span> by <code>qbeta(f, a, b)</code>.  If <code class="reqn">F=0.5</code>, then the median is returned but that is conveniently implemented in <code><a href="#topic+pp.median">pp.median</a></code>.   Readers might consult Gilchrist (2011, chapter 12) and Karian and Dudewicz (2011, p. 510).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pp.f(f, x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pp.f_+3A_f">f</code></td>
<td>
<p>A nonexceedance probability.</p>
</td></tr>
<tr><td><code id="pp.f_+3A_x">x</code></td>
<td>
<p>A vector of data. The ranks and the length of the vector are computed within the function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>vector</code> is returned.
</p>


<h3>Note</h3>

<p>The function uses the <span class="rlang"><b>R</b></span> function <code>rank</code>, which has specific settings to handle tied data. For implementation here, the <code>ties.method="first"</code> method to <code>rank</code> is used.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Gilchrist, W.G., 2000, Statistical modelling with quantile functions: Chapman and Hall/CRC, Boca Raton.
</p>
<p>Karian, Z.A., and Dudewicz, E.J., 2011, Handbook of fitting statistical distributions with R: Boca Raton, FL, CRC Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pp">pp</a></code>, <code><a href="#topic+pp.median">pp.median</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>X &lt;- sort(rexp(10))
PPlo &lt;- pp.f(0.25, X)
PPhi &lt;- pp.f(0.75, X)
plot(c(PPlo,NA,PPhi), c(X,NA,X))
points(pp(X), X) # Weibull i/(n+1)
</code></pre>

<hr>
<h2 id='pp.median'>Quantile Function of the Ranks of Plotting Positions</h2><span id='topic+pp.median'></span>

<h3>Description</h3>

<p>The median of a plotting position. The median is <code class="reqn">pp^\star_r = IIB(0.5, r, n+1-r)</code>.  <code class="reqn">IIB</code> is the &ldquo;inverse of the incomplete beta function&rdquo; or the quantile function of the Beta distribution as provided in <span class="rlang"><b>R</b></span> by <code>qbeta(f, a, b)</code>. Readers might consult Gilchrist (2011, chapter 12) and Karian and Dudewicz (2011, p. 510). The <code class="reqn">pp'_r</code> are known in some fields as &ldquo;mean rankit&rdquo; and <code class="reqn">pp^\star_r</code> as &ldquo;median rankit.&rdquo;
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pp.median(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pp.median_+3A_x">x</code></td>
<td>
<p>A real value vector. The ranks and the length of the vector are computed within the function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>vector</code> is returned.
</p>


<h3>Note</h3>

<p>The function internally calls <code><a href="#topic+pp.f">pp.f</a></code> (see <b>Note</b> in for that function).
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Gilchrist, W.G., 2000, Statistical modelling with quantile functions: Chapman and Hall/CRC, Boca Raton.
</p>
<p>Karian, Z.A., and Dudewicz, E.J., 2011, Handbook of fitting statistical distributions with R: Boca Raton, FL, CRC Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pp">pp</a></code>, <code><a href="#topic+pp.f">pp.f</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
X &lt;- rexp(10)*rexp(10)
means  &lt;- pp(X, sort=FALSE)
median &lt;- pp.median(X)
supposed.median &lt;- pp(X, a=0.3175, sort=FALSE)
lmr &lt;- lmoms(X)
par &lt;- parwak(lmr)
FF  &lt;- nonexceeds()
plot(FF, qlmomco(FF, par), type="l", log="y")
points(means,  X)
points(median, X, col=2)
points(supposed.median, X, pch=16, col=2, cex=0.5)
# The plot shows that the median and supposed.median by the plotting-position
# formula are effectively equivalent. Thus, the partial application it seems
# that a=0.3175 would be good enough in lieu of the complexity of the
# quantile function of the Beta distribution.

## End(Not run)
</code></pre>

<hr>
<h2 id='prettydist'>A Pretty List of Distribution Names</h2><span id='topic+prettydist'></span>

<h3>Description</h3>

<p>Return a full name of one or more distributions from the abbreviation for the distribution. The official list of abbreviations for the <span class="pkg">lmomco</span> package is available under <code><a href="#topic+dist.list">dist.list</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>prettydist(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="prettydist_+3A_x">x</code></td>
<td>
<p>A vector of <span class="pkg">lmomco</span> distribution abbreviations.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of distribution identifiers.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>See Also</h3>

<p><code><a href="#topic+dist.list">dist.list</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>the.lst &lt;- dist.list() # the authoritative list of abbreviations
prettydist(the.lst)
</code></pre>

<hr>
<h2 id='prob2grv'>Convert a Vector of Annual Nonexceedance Probabilities to Gumbel Reduced Variates</h2><span id='topic+prob2grv'></span>

<h3>Description</h3>

<p>This function converts a vector of annual nonexceedance probabilities <code class="reqn">F</code> to Gumbel reduced variates (GRV, <code class="reqn">grv</code>; Hosking and Wallis [1997, p. 92]) 
</p>
<p style="text-align: center;"><code class="reqn">grv = -\log(-\log(F))\mbox{,}</code>
</p>

<p>where <code class="reqn">0 \le F \le 1</code>. The Gumbel distribution (<code><a href="#topic+quagum">quagum</a></code>), which is a special case of the Generalized Extreme Value (<code><a href="#topic+quagev">quagev</a></code>), will plot as a straightline when the horizontal axis is GRV transformed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>prob2grv(f)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="prob2grv_+3A_f">f</code></td>
<td>
<p>A vector of annual nonexceedance probabilities.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of Gumbel reduced variates.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Hosking, J.R.M., and Wallis, J.R., 1997, Regional frequency analysis&mdash;An approach based on L-moments: Cambridge University Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+grv2prob">grv2prob</a></code>, <code><a href="#topic+prob2T">prob2T</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>F &lt;- nonexceeds()
grv &lt;- prob2grv(F)
</code></pre>

<hr>
<h2 id='prob2lrv'>Convert a Vector of Annual Nonexceedance Probabilities to Logistic Reduced Variates</h2><span id='topic+prob2lrv'></span>

<h3>Description</h3>

<p>This function converts a vector of annual nonexceedance probabilities <code class="reqn">F</code> to logistic reduced variates (LRV, <code class="reqn">lrv</code>) 
</p>
<p style="text-align: center;"><code class="reqn">lrv = 1/(\exp(-lrv) + 1)\mbox{,}</code>
</p>

<p>where <code class="reqn">0 \le F \le 1</code>. The logistic distribution, which is generalized by the Generalized Logistic (<code><a href="#topic+quaglo">quaglo</a></code>) with <code class="reqn">\kappa = 0</code>, will plot as a straightline when the horizontal axis is LRV transformed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>prob2lrv(f)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="prob2lrv_+3A_f">f</code></td>
<td>
<p>A vector of annual nonexceedance probabilities.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of logistic reduced variates.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Bradford, R.B., 2002, Volume-duration growth curves for flood estimation in permeable catchments: Hydrology and Earth System Sciences, v. 6, no. 5, pp. 939&ndash;947.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lrv2prob">lrv2prob</a></code>, <code><a href="#topic+prob2T">prob2T</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>F &lt;- nonexceeds()
lrv &lt;- prob2lrv(F)
## Not run: 
X &lt;- rlmomco(10040, vec2par(c(0,1,0), type="glo"))
plot(prob2lrv(pp(X, a=0.4)), sort(X)); abline(0,1)

## End(Not run)
</code></pre>

<hr>
<h2 id='prob2T'>Convert a Vector of Annual Nonexceedance Probabilities to T-year Return Periods</h2><span id='topic+prob2T'></span>

<h3>Description</h3>

<p>This function converts a vector of annual nonexceedance probabilities <code class="reqn">F</code> to <code class="reqn">T</code>-year return periods
</p>
<p style="text-align: center;"><code class="reqn">T = \frac{1}{1 - F}\mbox{,}</code>
</p>

<p>where <code class="reqn">0 \le F \le 1</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>prob2T(f)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="prob2T_+3A_f">f</code></td>
<td>
<p>A vector of annual nonexceedance probabilities.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of <code class="reqn">T</code>-year return periods.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>See Also</h3>

<p><code><a href="#topic+T2prob">T2prob</a></code>, <code><a href="#topic+nonexceeds">nonexceeds</a></code>, <code><a href="#topic+add.lmomco.axis">add.lmomco.axis</a></code>, <code><a href="#topic+prob2grv">prob2grv</a></code>, <code><a href="#topic+prob2lrv">prob2lrv</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>F &lt;- nonexceeds()
T &lt;- prob2T(F)
</code></pre>

<hr>
<h2 id='pwm'>Unbiased Sample Probability-Weighted Moments </h2><span id='topic+pwm'></span>

<h3>Description</h3>

<p>Unbiased sample probability-weighted moments (PWMs) are computed from a sample. The <code class="reqn">\beta_r</code>'s are computed using
</p>
<p style="text-align: center;"><code class="reqn">\beta_r = n^{-1}\sum^n_{j=1} {j-1 \choose r} x_{j:n}\mbox{.}</code>
</p>



<h3>Usage</h3>

<pre><code class='language-R'>pwm(x, nmom=5, sort=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pwm_+3A_x">x</code></td>
<td>
<p>A vector of data values.</p>
</td></tr>
<tr><td><code id="pwm_+3A_nmom">nmom</code></td>
<td>
<p>Number of PWMs to return (<code class="reqn">r = </code> <code>nmom - 1</code>).</p>
</td></tr>
<tr><td><code id="pwm_+3A_sort">sort</code></td>
<td>
<p>Do the data need sorting? The computations require sorted data. This option is provided to optimize processing speed if presorted data already exists.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> is returned.
</p>
<table>
<tr><td><code>betas</code></td>
<td>
<p>The PWMs. Note that convention is the have a <code class="reqn">\beta_0</code>, but this is placed in the first index <code>i=1</code> of the <code>betas</code> vector.</p>
</td></tr>
<tr><td><code>source</code></td>
<td>
<p>Source of the PWMs: &ldquo;pwm&rdquo;.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Greenwood, J.A., Landwehr, J.M., Matalas, N.C., and Wallis, J.R., 1979, Probability weighted moments&mdash;Definition and relation to parameters of several distributions expressable in inverse form: Water Resources Research, v. 15, pp. 1,049&ndash;1,054.
</p>
<p>Hosking, J.R.M., 1990, L-moments&mdash;Analysis and estimation of
distributions using linear combinations of order statistics: Journal
of the Royal Statistical Society, Series B, v. 52, pp. 105&ndash;124.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lmoms">lmoms</a></code>, <code><a href="#topic+pwm2lmom">pwm2lmom</a></code>, <code><a href="#topic+pwm">pwm</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'># Data listed in Hosking (1995, table 29.2, p. 551)
H &lt;- c(3,4,5,6,6,7,8,8,9,9,9,10,10,11,11,11,13,13,13,13,13,
       17,19,19,25,29,33,42,42,51.9999,52,52,52)
# 51.9999 was really 52, but a real non censored data point.
z &lt;-  pwmRC(H,52,checkbetas=TRUE)
str(z)
# Hosking(1995) reports that A-type L-moments for this sample are
# lamA1=15.7 and lamAL-CV=.389, and lamAL-skew=.393
pwm2lmom(z$Abetas)
# WHA gets 15.666, 0.3959, and 0.4030

# See p. 553 of Hosking (1995)
# Data listed in Hosking (1995, table 29.3, p. 553)
D &lt;- c(-2.982, -2.849, -2.546, -2.350, -1.983, -1.492, -1.443,
       -1.394, -1.386, -1.269, -1.195, -1.174, -0.854, -0.620,
       -0.576, -0.548, -0.247, -0.195, -0.056, -0.013,  0.006,
        0.033,  0.037,  0.046,  0.084,  0.221, 0.245, 0.296)
D &lt;- c(D,rep(.2960001,40-28)) # 28 values, but Hosking mentions
                              # 40 values in total
z &lt;-  pwmRC(D,.2960001)
# Hosking reports B-type L-moments for this sample are
# lamB1 = -.516 and lamB2 = 0.523
pwm2lmom(z$Bbetas)
# WHA gets -.5162 and 0.5218
</code></pre>

<hr>
<h2 id='pwm.beta2alpha'>Conversion of Beta to Alpha Probability-Weighted Moments (PWMs) or Alpha to Beta PWMs </h2><span id='topic+pwm.beta2alpha'></span><span id='topic+pwm.alpha2beta'></span>

<h3>Description</h3>

<p>Conversion of &ldquo;beta&rdquo; (the well known ones) to &ldquo;alpha&rdquo; probability-weighted moments (PWMs) by <code><a href="#topic+pwm.beta2alpha">pwm.beta2alpha</a></code> or alpha to beta PWMs by <code><a href="#topic+pwm.alpha2beta">pwm.alpha2beta</a></code>. The relations between the <code class="reqn">\alpha</code> and <code class="reqn">\beta</code> PWMs are
</p>
<p style="text-align: center;"><code class="reqn">\alpha_r = \sum^r_{k=0} (-1)^k {r \choose k} \beta_k\mbox{,}</code>
</p>

<p>and
</p>
<p style="text-align: center;"><code class="reqn">\beta_r = \sum^r_{k=0} (-1)^k {r \choose k} \alpha_k\mbox{.}</code>
</p>

<p>Lastly, note that the <code class="reqn">\beta</code> are almost exclusively used in the literature. Because each is a linear combination of the other, they are equivalent in meaning but not numerically.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pwm.beta2alpha(pwm)

pwm.alpha2beta(pwm)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pwm.beta2alpha_+3A_pwm">pwm</code></td>
<td>
<p>A vector of alpha or beta probability-weighted moments depending on which related function is called.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>If <code class="reqn">\beta_r \rightarrow \alpha_r</code> (<code><a href="#topic+pwm.beta2alpha">pwm.beta2alpha</a></code>), a vector of the <code class="reqn">\alpha_r</code>. Note that convention is the have a <code class="reqn">\alpha_0</code>, but this is placed in the first index <code>i=1</code> vector. Alternatively, if <code class="reqn">\alpha_r \rightarrow \beta_r</code> (<code><a href="#topic+pwm.alpha2beta">pwm.alpha2beta</a></code>), a vector of the <code class="reqn">\beta_r</code>.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p># NEED
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pwm">pwm</a></code>, <code><a href="#topic+pwm2lmom">pwm2lmom</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>X &lt;- rnorm(100)
pwm(X)$betas
pwm.beta2alpha(pwm(X)$betas)
pwm.alpha2beta(pwm.beta2alpha(pwm(X)$betas))
</code></pre>

<hr>
<h2 id='pwm.gev'>Generalized Extreme Value Plotting-Position Probability-Weighted Moments </h2><span id='topic+pwm.gev'></span>

<h3>Description</h3>

<p>Generalized Extreme Value plotting-position probability-weighted moments (PWMs) are computed from a sample.  The first five <code class="reqn">\beta_r</code>'s are computed by default. The plotting-position formula for the Generalized Extreme Value distribution is
</p>
<p style="text-align: center;"><code class="reqn">pp_i = \frac{i-0.35}{n} \mbox{,}</code>
</p>

<p>where <code class="reqn">pp_i</code> is the nonexceedance probability <code class="reqn">F</code> of the <code class="reqn">i</code>th ascending values of the sample of size <code class="reqn">n</code>. The PWMs are computed by
</p>
<p style="text-align: center;"><code class="reqn">\beta_r = n^{-1}\sum_{i=1}^{n}pp_i^r \times x_{j:n} \mbox{,}</code>
</p>

<p>where <code class="reqn">x_{j:n}</code> is the <code class="reqn">j</code>th order statistic
<code class="reqn">x_{1:n} \le x_{2:n} \le x_{j:n} \dots \le x_{n:n}</code> of random variable X, and <code class="reqn">r</code> is <code class="reqn">0, 1, 2, \dots</code>. Finally, <code><a href="#topic+pwm.gev">pwm.gev</a></code> dispatches to <code>pwm.pp(data,A=-0.35,B=0)</code> and does not have its own logic.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pwm.gev(x, nmom=5, sort=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pwm.gev_+3A_x">x</code></td>
<td>
<p>A vector of data values.</p>
</td></tr>
<tr><td><code id="pwm.gev_+3A_nmom">nmom</code></td>
<td>
<p>Number of PWMs to return.</p>
</td></tr>
<tr><td><code id="pwm.gev_+3A_sort">sort</code></td>
<td>
<p>Do the data need sorting? The computations require sorted data. This option is provided to optimize processing speed if presorted data already exists.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> is returned.
</p>
<table>
<tr><td><code>betas</code></td>
<td>
<p>The PWMs. Note that convention is the have a <code class="reqn">\beta_0</code>, but this is placed in the first index <code>i=1</code> of the <code>betas</code> vector.</p>
</td></tr>
<tr><td><code>source</code></td>
<td>
<p>Source of the PWMs: &ldquo;pwm.gev&rdquo;.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Greenwood, J.A., Landwehr, J.M., Matalas, N.C., and Wallis, J.R., 1979, Probability weighted moments&mdash;Definition and relation to parameters of several distributions expressable in inverse form: Water Resources Research, v. 15, pp. 1,049&ndash;1,054.
</p>
<p>Hosking, J.R.M., 1990, L-moments&mdash;Analysis and estimation of
distributions using linear combinations of order statistics: Journal
of the Royal Statistical Society, Series B, v. 52, pp. 105&ndash;124.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pwm.ub">pwm.ub</a></code>, <code><a href="#topic+pwm.pp">pwm.pp</a></code>, <code><a href="#topic+pwm2lmom">pwm2lmom</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>pwm &lt;- pwm.gev(rnorm(20))
</code></pre>

<hr>
<h2 id='pwm.pp'>Plotting-Position Sample Probability-Weighted Moments </h2><span id='topic+pwm.pp'></span>

<h3>Description</h3>

<p>The sample probability-weighted moments (PWMs) are computed from the plotting positions of the data. The first five <code class="reqn">\beta_r</code>'s are computed by default. The plotting-position formula for a sample size of <code class="reqn">n</code> is
</p>
<p style="text-align: center;"><code class="reqn">pp_i = \frac{i+A}{n+B} \mbox{,}</code>
</p>

<p>where <code class="reqn">pp_i</code> is the nonexceedance probability <code class="reqn">F</code> of the <code class="reqn">i</code>th ascending data values. An alternative form of the plotting position equation is
</p>
<p style="text-align: center;"><code class="reqn">pp_i = \frac{i + a}{n + 1 - 2a}\mbox{,}</code>
</p>

<p>where <code class="reqn">a</code> is a single plotting position coefficient. Having <code class="reqn">a</code> provides <code class="reqn">A</code> and <code class="reqn">B</code>, therefore the parameters <code class="reqn">A</code> and <code class="reqn">B</code> together specify the plotting-position type. The PWMs are computed by
</p>
<p style="text-align: center;"><code class="reqn">\beta_r = n^{-1}\sum_{i=1}^{n}pp_i^r \times x_{j:n} \mbox{,}</code>
</p>

<p>where <code class="reqn">x_{j:n}</code> is the <code class="reqn">j</code>th order statistic <code class="reqn">x_{1:n} \le x_{2:n} \le x_{j:n} \dots \le x_{n:n}</code> of random variable X, and <code class="reqn">r</code> is <code class="reqn">0, 1, 2, \dots</code> for the PWM order.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pwm.pp(x, pp=NULL, A=NULL, B=NULL, a=0, nmom=5, sort=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pwm.pp_+3A_x">x</code></td>
<td>
<p>A vector of data values.</p>
</td></tr>
<tr><td><code id="pwm.pp_+3A_pp">pp</code></td>
<td>
<p>An optional vector of nonexceedance probabilities. If present then <code>A</code> and <code>B</code> or <code>a</code> are ignored.</p>
</td></tr>
<tr><td><code id="pwm.pp_+3A_a">A</code></td>
<td>
<p>A value for the plotting-position formula. If <code>A</code> and <code>B</code> are both zero then the unbiased PWMs are computed through <code><a href="#topic+pwm.ub">pwm.ub</a></code>.</p>
</td></tr>
<tr><td><code id="pwm.pp_+3A_b">B</code></td>
<td>
<p>Another value for the plotting-position formula. If <code>A</code> and <code>B</code> are both zero then the unbiased PWMs are computed through <code><a href="#topic+pwm.ub">pwm.ub</a></code>.</p>
</td></tr>
<tr><td><code id="pwm.pp_+3A_a">a</code></td>
<td>
<p>A single plotting position coefficient from which, if not <code>NULL</code>, <code class="reqn">A</code> and <code class="reqn">B</code> will be internally computed;</p>
</td></tr>
<tr><td><code id="pwm.pp_+3A_nmom">nmom</code></td>
<td>
<p>Number of PWMs to return.</p>
</td></tr>
<tr><td><code id="pwm.pp_+3A_sort">sort</code></td>
<td>
<p>Do the data need sorting? The computations require sorted data. This option is provided to optimize processing speed if presorted data already exists.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> is returned.
</p>
<table>
<tr><td><code>betas</code></td>
<td>
<p>The PWMs. Note that convention is the have a <code class="reqn">\beta_0</code>, but this is placed in the first index <code>i=1</code> of the <code>betas</code> vector.</p>
</td></tr>
<tr><td><code>source</code></td>
<td>
<p>Source of the PWMs: &ldquo;pwm.pp&rdquo;.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Greenwood, J.A., Landwehr, J.M., Matalas, N.C., and Wallis, J.R., 1979, Probability weighted moments&mdash;Definition and relation to parameters of several distributions expressable in inverse form: Water Resources Research, v. 15, pp. 1,049&ndash;1,054.
</p>
<p>Hosking, J.R.M., 1990, L-moments&mdash;Analysis and estimation of
distributions using linear combinations of order statistics: Journal
of the Royal Statistical Society, Series B, v. 52, pp. 105&ndash;124.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pwm.ub">pwm.ub</a></code>, <code><a href="#topic+pwm.gev">pwm.gev</a></code>, <code><a href="#topic+pwm2lmom">pwm2lmom</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>pwm &lt;- pwm.pp(rnorm(20), A=-0.35, B=0)

X &lt;- rnorm(20)
pwm &lt;- pwm.pp(X, pp=pp(X)) # weibull plotting positions
</code></pre>

<hr>
<h2 id='pwm.ub'>Unbiased Sample Probability-Weighted Moments </h2><span id='topic+pwm.ub'></span>

<h3>Description</h3>

<p>Unbiased sample probability-weighted moments (PWMs) are computed from a sample. The <code class="reqn">\beta_r</code>'s are computed using
</p>
<p style="text-align: center;"><code class="reqn">\beta_r = n^{-1} {n-1 \choose r}^{-1} \sum^n_{j=1} {j-1 \choose r} x_{j:n}\mbox{.}</code>
</p>



<h3>Usage</h3>

<pre><code class='language-R'>pwm.ub(x, nmom=5, sort=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pwm.ub_+3A_x">x</code></td>
<td>
<p>A vector of data values.</p>
</td></tr>
<tr><td><code id="pwm.ub_+3A_nmom">nmom</code></td>
<td>
<p>Number of PWMs to return (<code class="reqn">r =</code> <code>nmom - 1</code>).</p>
</td></tr>
<tr><td><code id="pwm.ub_+3A_sort">sort</code></td>
<td>
<p>Do the data need sorting? The computations require sorted data. This option is provided to optimize processing speed if presorted data already exists.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> is returned.
</p>
<table>
<tr><td><code>betas</code></td>
<td>
<p>The PWMs. Note that convention is the have a <code class="reqn">\beta_0</code>, but this is placed in the first index <code>i=1</code> of the <code>betas</code> vector.</p>
</td></tr>
<tr><td><code>source</code></td>
<td>
<p>Source of the PWMs: &ldquo;pwm.ub&rdquo;.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Through a user inquiry, it came to the author's attention in May 2014 that some unrelated studies using PWMs in the earth-system sciences have published erroneous sample PWMs formula. Because <span class="pkg">lmomco</span> is intended to be an authoritative source, here are some computations to further prove correctness with provenance: 
</p>
<pre>
"pwm.handbookhydrology" &lt;- function(x, nmom=5) {
   x &lt;- sort(x, decreasing = TRUE); n &lt;- length(x); betas &lt;- rep(NA, nmom)
   for(r in 0:(nmom-1)) {
      tmp &lt;- sum(sapply(1:(n-r),
          function(j) { choose(n - j, r) * x[j] / choose(n - 1, r) }))
      betas[(r+1)] &lt;- tmp/n
   }
   return(betas)
}
</pre>
<p>and a demonstration with alternative algebra in Stedinger and others (1993)
</p>
<pre>
set.seed(1)
glo &lt;- vec2par(c(123,1123,-.5), type="glo"); X &lt;- rlmomco(100, glo)
lmom2pwm(lmoms(X, nmom=5))$betas # unbiased L-moments flipped to PWMs
[1]  998.7932 1134.0658 1046.4906  955.8872  879.3349
pwm.ub(X, nmom=5)$betas  # Hosking and Wallis (1997) and Asquith (2011)
[1]  998.7932 1134.0658 1046.4906  955.8872  879.3349
pwm.handbookhydrology(X) # ** alert reverse sort, opposite usually seen**
[1]  998.7932 1134.0658 1046.4906  955.8872  879.3349
</pre>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Asquith, W.H., 2011, Distributional analysis with L-moment statistics using the R environment for statistical computing: Createspace Independent Publishing Platform, ISBN 978&ndash;146350841&ndash;8.
</p>
<p>Greenwood, J.A., Landwehr, J.M., Matalas, N.C., and Wallis, J.R., 1979, Probability weighted moments&mdash;Definition and relation to parameters of several distributions expressable in inverse form: Water Resources Research, v. 15, pp. 1,049&ndash;1,054.
</p>
<p>Stedinger, J.R., Vogel, R.M., Foufoula-Georgiou, E., 1993, Frequency analysis of extreme events: <em>in</em> Handbook of Hydrology, ed. Maidment, D.R., McGraw-Hill, Section 18.6 Partial duration series, mixtures, and censored data, pp. 18.37&ndash;18.39.
</p>
<p>Hosking, J.R.M., 1990, L-moments&mdash;Analysis and estimation of distributions using linear combinations of order statistics: Journal of the Royal Statistical Society, Series B, v. 52, pp. 105&ndash;124.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pwm.pp">pwm.pp</a></code>, <code><a href="#topic+pwm.gev">pwm.gev</a></code>, <code><a href="#topic+pwm2lmom">pwm2lmom</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>pwm &lt;- pwm.ub(rnorm(20))
</code></pre>

<hr>
<h2 id='pwm2lmom'>Probability-Weighted Moments to L-moments</h2><span id='topic+pwm2lmom'></span>

<h3>Description</h3>

<p>Converts the probability-weighted moments (PWM) to the L-moments. The conversion is linear so procedures based on PWMs are identical to those based on L-moments through a system of linear equations
</p>
<p style="text-align: center;"><code class="reqn">\lambda_1 = \beta_0 \mbox{,}</code>
</p>

<p style="text-align: center;"><code class="reqn">\lambda_2 = 2\beta_1 - \beta_0 \mbox{,}</code>
</p>

<p style="text-align: center;"><code class="reqn">\lambda_3 = 6\beta_2 - 6\beta_1 + \beta_0 \mbox{,}</code>
</p>

<p style="text-align: center;"><code class="reqn">\lambda_4 = 20\beta_3 - 30\beta_2 + 12\beta_1 - \beta_0 \mbox{,}</code>
</p>

<p style="text-align: center;"><code class="reqn">\lambda_5 = 70\beta_4 - 140\beta_3 + 90\beta_2 - 20\beta_1 + \beta_0 \mbox{,}</code>
</p>

<p style="text-align: center;"><code class="reqn">\tau = \lambda_2/\lambda_1 \mbox{,}</code>
</p>

<p style="text-align: center;"><code class="reqn">\tau_3 = \lambda_3/\lambda_2 \mbox{,}</code>
</p>

<p style="text-align: center;"><code class="reqn">\tau_4 = \lambda_4/\lambda_2 \mbox{, and}</code>
</p>

<p style="text-align: center;"><code class="reqn">\tau_5 = \lambda_5/\lambda_2 \mbox{.}</code>
</p>

<p>The general expression and the expression used for computation if the argument is a vector of PWMs is
</p>
<p style="text-align: center;"><code class="reqn">\lambda_{r+1} = \sum^r_{k=0} (-1)^{r-k}{r \choose k}{r+k \choose k} \beta_{k+1}\mbox{.}</code>
</p>



<h3>Usage</h3>

<pre><code class='language-R'>pwm2lmom(pwm)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pwm2lmom_+3A_pwm">pwm</code></td>
<td>
<p> A PWM object created by <code><a href="#topic+pwm.ub">pwm.ub</a></code> or similar. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The probability-weighted moments (PWMs) are linear combinations of the L-moments and therefore contain the same statistical information of the data as the L-moments. However, the PWMs are harder to interpret as measures of probability distributions. The linearity between L-moments and PWMs means that procedures base on one are equivalent to the other.
</p>
<p>The function can take a variety of PWM argument types in <code><a href="#topic+pwm">pwm</a></code>. The function checks whether the argument is an <span class="rlang"><b>R</b></span> <code>list</code> and if so attempts to extract the <code class="reqn">\beta_r</code>'s from <code>list</code> names such as <code>BETA0</code>, <code>BETA1</code>, and so on. If the extraction is successful, then a list of L-moments similar to <code><a href="#topic+lmom.ub">lmom.ub</a></code> is returned. If the extraction was not successful, then an <span class="rlang"><b>R</b></span> <code>list</code> name <code>betas</code> is checked; if <code>betas</code> is found, then this vector of PWMs is used to compute the L-moments. If <code>pwm</code> is a <code>list</code> but can not be routed in the function, a <code>warning</code> is made and <code>NULL</code> is returned. If the <code>pwm</code> argument is a <code>vector</code>, then this vector of PWMs is used. to compute the L-moments are returned.
</p>


<h3>Value</h3>

<p>One of two <span class="rlang"><b>R</b></span> <code>list</code>s are returned. Version I is
</p>
<table>
<tr><td><code>L1</code></td>
<td>
<p>Arithmetic mean.</p>
</td></tr>
<tr><td><code>L2</code></td>
<td>
<p>L-scale&mdash;analogous to standard deviation.</p>
</td></tr>
<tr><td><code>LCV</code></td>
<td>
<p>coefficient of L-variation&mdash;analogous to coe. of variation.</p>
</td></tr>
<tr><td><code>TAU3</code></td>
<td>
<p>The third L-moment ratio or L-skew&mdash;analogous to skew.</p>
</td></tr>
<tr><td><code>TAU4</code></td>
<td>
<p>The fourth L-moment ratio or L-kurtosis&mdash;analogous to kurtosis.</p>
</td></tr>
<tr><td><code>TAU5</code></td>
<td>
<p>The fifth L-moment ratio.</p>
</td></tr>
<tr><td><code>L3</code></td>
<td>
<p>The third L-moment.</p>
</td></tr>
<tr><td><code>L4</code></td>
<td>
<p>The fourth L-moment.</p>
</td></tr>
<tr><td><code>L5</code></td>
<td>
<p>The fifth L-moment.</p>
</td></tr>
</table>
<p>Version II is 
</p>
<table>
<tr><td><code>lambdas</code></td>
<td>
<p>The L-moments.</p>
</td></tr>
<tr><td><code>ratios</code></td>
<td>
<p>The L-moment ratios.</p>
</td></tr>
<tr><td><code>source</code></td>
<td>
<p>Source of the L-moments &ldquo;pwm2lmom&rdquo;.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Greenwood, J.A., Landwehr, J.M., Matalas, N.C., and Wallis, J.R., 1979, Probability weighted moments&mdash;Definition and relation to parameters of several distributions expressable in inverse form: Water Resources Research, v. 15, pp. 1,049&ndash;1,054.
</p>
<p>Hosking, J.R.M., 1990, L-moments&ndash;Analysis and estimation of distributions using linear combinations of order statistics: Journal of the Royal Statistical Society, Series B, v. 52, pp. 105&ndash;124.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lmom.ub">lmom.ub</a></code>, <code><a href="#topic+pwm.ub">pwm.ub</a></code>, <code><a href="#topic+pwm">pwm</a></code>, <code><a href="#topic+lmom2pwm">lmom2pwm</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>D &lt;- c(123,34,4,654,37,78)
pwm2lmom(pwm.ub(D))
pwm2lmom(pwm(D))
pwm2lmom(pwm(rnorm(100)))
</code></pre>

<hr>
<h2 id='pwm2vec'>Convert Probability-Weighted Moment object to a Vector</h2><span id='topic+pwm2vec'></span>

<h3>Description</h3>

<p>This function converts a probability-weighted moment object in the structure used by <span class="pkg">lmomco</span> into a simple vector of <code class="reqn">\beta_0</code>, <code class="reqn">\beta_1</code>, <code class="reqn">\beta_2</code>, <code class="reqn">\beta_3</code>, <code class="reqn">\beta_4</code>, ..., <code class="reqn">\beta_{r-1}</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pwm2vec(pwm, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pwm2vec_+3A_pwm">pwm</code></td>
<td>
<p>Probability-weighted moment object such as from <code><a href="#topic+pwm">pwm</a></code> and <code><a href="#topic+vec2pwm">vec2pwm</a></code>.</p>
</td></tr>
<tr><td><code id="pwm2vec_+3A_...">...</code></td>
<td>
<p>Not presently used.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of the first five probability-weighted moments if available. The <code>$betas</code> field of the <code>pwm</code> argument is simply returned by this function.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>See Also</h3>

<p><code><a href="#topic+pwm">pwm</a></code>, <code><a href="#topic+vec2pwm">vec2pwm</a></code>, <code><a href="#topic+lmom2vec">lmom2vec</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  pmr &lt;- pwm(rnorm(40));             pwm2vec(pmr)
  pmr &lt;- vec2pwm(c(140,150,45,21));  pwm2vec(pmr)
</code></pre>

<hr>
<h2 id='pwmLC'>Sample Probability-Weighted Moments for Left-Tail Censoring </h2><span id='topic+pwmLC'></span>

<h3>Description</h3>

<p>Compute the sample probability-weighted moments (PWMs) for left-tail censored data set&mdash;that is a data set censored from below. The censoring threshold is denoted as <code class="reqn">T</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pwmLC(x, threshold=NULL, nmom=5, sort=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pwmLC_+3A_x">x</code></td>
<td>
<p>A vector of data values.</p>
</td></tr>
<tr><td><code id="pwmLC_+3A_threshold">threshold</code></td>
<td>
<p>The left-tail censoring (lower) threshold.</p>
</td></tr>
<tr><td><code id="pwmLC_+3A_nmom">nmom</code></td>
<td>
<p>Number of PWMs to return.</p>
</td></tr>
<tr><td><code id="pwmLC_+3A_sort">sort</code></td>
<td>
<p>Do the data need sorting? Note that convention is the have a <code class="reqn">\beta'_0</code>, but this is placed in the first index <code>i=1</code> of the <code>betas</code> vector.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>There is some ambiguity if the threshold also numerically equals valid data in the data set. In the data for the examples below, which are taken from elsewhere, there are real observations at the censoring level. One can see how a hack is made to marginally decrease or increase the data or the threshold for the computations. This is needed because the code uses
</p>
<pre>
sapply(x, function(v) { if(v &gt;= T) return(T); return(v) } )
</pre>
<p>to reset the data vector <code>x</code>. By operating on the data in this fashion one can toy with various levels of the threshold for experimental purposes; this seemed a more natural way for general implementation. The code sets <code class="reqn">n</code> = <code>length(x)</code> and <code class="reqn">m</code> = <code>n - length(x[x == T])</code>, which also seems natural. The <code class="reqn">\beta^A_r</code> are computed by dispatching to <code><a href="#topic+pwm">pwm</a></code>.
</p>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> is returned.
</p>
<table>
<tr><td><code>Aprimebetas</code></td>
<td>
<p>The A'-type PWMs. These should be same as <code>pwm()</code> returns if there is no censoring. Note that convention is the have a <code class="reqn">\beta_0</code>, but this is placed in the first index <code>i=1</code> of the <code>betas</code> vector.</p>
</td></tr>
<tr><td><code>Bprimebetas</code></td>
<td>
<p>The B'-type PWMs. These should be <code>NA</code> if there is no censoring. Note that convention is the have a <code class="reqn">\beta_0</code>, but this is placed in the first index <code>i = 1</code> of the <code>betas</code> vector.</p>
</td></tr>
<tr><td><code>source</code></td>
<td>
<p>Source of the PWMs: &ldquo;pwmLC&rdquo;.</p>
</td></tr>
<tr><td><code>threshold</code></td>
<td>
<p>The upper censoring threshold.</p>
</td></tr>
<tr><td><code>zeta</code></td>
<td>
<p>The left censoring fraction: <code>numbelowthreshold/samplesize</code>.</p>
</td></tr>
<tr><td><code>numbelowthreshold</code></td>
<td>
<p>Number of data points equal to or above the threshold.</p>
</td></tr>
<tr><td><code>observedsize</code></td>
<td>
<p>Number of real data points in the sample (above the threshold).</p>
</td></tr>
<tr><td><code>samplesize</code></td>
<td>
<p>Number of actual sample values.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Zafirakou-Koulouris, A., Vogel, R.M., Craig, S.M., and Habermeier, J., 1998, L-moment diagrams for censored observations: Water Resources Research, v. 34, no. 5, pp. 1241&ndash;1249.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lmoms">lmoms</a></code>, <code><a href="#topic+pwm2lmom">pwm2lmom</a></code>, <code><a href="#topic+pwm">pwm</a></code>, <code><a href="#topic+pwmRC">pwmRC</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>#
</code></pre>

<hr>
<h2 id='pwmRC'>Sample Probability-Weighted Moments for Right-Tail Censoring </h2><span id='topic+pwmRC'></span>

<h3>Description</h3>

<p>Compute the sample Probability-Weighted Moments (PWMs) for right-tail censored data set&mdash;that is a data set censored from above. The censoring threshold is denoted as <code class="reqn">T</code>. The data possess <code class="reqn">m</code> values that are observed (noncensored, <code class="reqn">&lt; T</code>) out of a total of <code class="reqn">n</code> samples. The ratio of <code class="reqn">m</code> to <code class="reqn">n</code> is defined as <code class="reqn">\zeta = m/n</code>, which will play an important role in parameter estimation. The <code class="reqn">\zeta</code> is interpreted as the probability <code class="reqn">\mathrm{Pr}\lbrace \rbrace</code> that <code class="reqn">x</code> is less than the quantile at <code class="reqn">\zeta</code> nonexceedance probability: (<code class="reqn">\mathrm{Pr}\lbrace x &lt; X(\zeta) \rbrace</code>). Two types of PWMs are computed for right-tail censored situations. The &ldquo;A&rdquo;-type PWMs and &ldquo;B&rdquo;-type PWMs. The A-type PWMs are defined by
</p>
<p style="text-align: center;"><code class="reqn">\beta^A_r = m^{-1}\sum^m_{j=1} {j-1 \choose r} x_{[j:n]}\mbox{,}</code>
</p>

<p>which are the PWMs of the uncensored sample of <code class="reqn">m</code> observed values. The B-type PWMs are computed from the &ldquo;complete&rdquo; sample, in which the <code class="reqn">n-m</code> censored values are replaced by the censoring threshold <code class="reqn">T</code>. The B-type PWMs are defined by
</p>
<p style="text-align: center;"><code class="reqn">\beta^B_r = n^{-1} \biggl( \sum^m_{j=1} {j-1 \choose r} x_{[j:n]} +
                                \sum^n_{j=m+1} {j-1 \choose r} T \biggr) \mbox{.}</code>
</p>

<p>The two previous expressions are used in the function. These PWMs are readily converted to L-moments by the usual methods (<code><a href="#topic+pwm2lmom">pwm2lmom</a></code>). When there are more than a few censored values, the PWMs are readily computed by computing <code class="reqn">\beta^A_r</code> and using the expression
</p>
<p style="text-align: center;"><code class="reqn">\beta^B_r = Z\beta^A_r + \frac{1-Z}{r+1}T\mbox{,}</code>
</p>

<p>where
</p>
<p style="text-align: center;"><code class="reqn">Z = \frac{m}{n}\frac{{m-1 \choose r}}{{n-1 \choose r}}\mbox{.}</code>
</p>

<p>The two expressions above are consulted when the <code>checkbetas=TRUE</code> argument is present. Both sequences of B-type are <code>cat</code>ed to the terminal. This provides a check on the implementation of the algorithm. The functions <code><a href="#topic+Apwm2BpwmRC">Apwm2BpwmRC</a></code> and <code><a href="#topic+Bpwm2ApwmRC">Bpwm2ApwmRC</a></code> can be used to switch back and forth between the two PWM types given fitted parameters for a distribution in the <span class="pkg">lmomco</span> package that supports right-tail censoring. Finally, the <code>RC</code> in the function name is to denote <code>R</code>ight-tail <code>C</code>ensoring.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pwmRC(x, threshold=NULL, nmom=5, sort=TRUE, checkbetas=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pwmRC_+3A_x">x</code></td>
<td>
<p>A vector of data values.</p>
</td></tr>
<tr><td><code id="pwmRC_+3A_threshold">threshold</code></td>
<td>
<p>The right-tail censoring (upper) threshold.</p>
</td></tr>
<tr><td><code id="pwmRC_+3A_nmom">nmom</code></td>
<td>
<p>Number of PWMs to return.</p>
</td></tr>
<tr><td><code id="pwmRC_+3A_sort">sort</code></td>
<td>
<p>Do the data need sorting? Note that convention is the have a <code class="reqn">\beta_0</code>, but this is placed in the first index <code>i=1</code> of the <code>betas</code> vector.</p>
</td></tr>
<tr><td><code id="pwmRC_+3A_checkbetas">checkbetas</code></td>
<td>
<p>A cross relation between <code class="reqn">\beta^A_r</code> and <code class="reqn">\beta^B_r</code> exists&mdash;display the results of the secondary computation of the <code class="reqn">\beta^B_r</code>. The two displayed vectors should be numerically equal.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>There is some ambiguity if the threshold also numerically equals valid data in the data set. In the data for the examples below, which are taken from elsewhere, there are real observations at the censoring level. One can see how a hack is made to marginally decrease or increase the data or the threshold for the computations. This is needed because the code uses
</p>
<pre>
sapply(x, function(v) { if(v &gt;= T) return(T); return(v) } )
</pre>
<p>to reset the data vector <code>x</code>. By operating on the data in this fashion one can toy with various levels of the threshold for experimental purposes; this seemed a more natural way for general implementation. The code sets <code class="reqn">n</code> = <code>length(x)</code> and <code class="reqn">m</code> = <code>n - length(x[x == T])</code>, which also seems natural. The <code class="reqn">\beta^A_r</code> are computed by dispatching to <code><a href="#topic+pwm">pwm</a></code>.
</p>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> is returned.
</p>
<table>
<tr><td><code>Abetas</code></td>
<td>
<p>The A-type PWMs. These should be same as <code>pwm()</code> returns if there is no censoring. Note that convention is the have a <code class="reqn">\beta_0</code>, but this is placed in the first index <code>i=1</code> of the <code>betas</code> vector.</p>
</td></tr>
<tr><td><code>Bbetas</code></td>
<td>
<p>The B-type PWMs. These should be <code>NA</code> if there is no censoring. Note that convention is the have a <code class="reqn">\beta_0</code>, but this is placed in the first index <code>i=1</code> of the <code>betas</code> vector.</p>
</td></tr>
<tr><td><code>source</code></td>
<td>
<p>Source of the PWMs: &ldquo;pwmRC&rdquo;.</p>
</td></tr>
<tr><td><code>threshold</code></td>
<td>
<p>The upper censoring threshold.</p>
</td></tr>
<tr><td><code>zeta</code></td>
<td>
<p>The right censoring fraction: <code>numabovethreshold/samplesize</code>.</p>
</td></tr>
<tr><td><code>numabovethreshold</code></td>
<td>
<p>Number of data points equal to or above the threshold.</p>
</td></tr>
<tr><td><code>observedsize</code></td>
<td>
<p>Number of real data points in the sample (below the threshold).</p>
</td></tr>
<tr><td><code>samplesize</code></td>
<td>
<p>Number of actual sample values.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Greenwood, J.A., Landwehr, J.M., Matalas, N.C., and Wallis, J.R., 1979, Probability weighted moments&mdash;Definition and relation to parameters of several distributions expressable in inverse form: Water Resources Research, v. 15, pp. 1,049&ndash;1,054.
</p>
<p>Hosking, J.R.M., 1990, L-moments&mdash;Analysis and estimation of distributions using linear combinations of order statistics: Journal of the Royal Statistical Society, Series B, v. 52, pp. 105&ndash;124.
</p>
<p>Hosking, J.R.M., 1995, The use of L-moments in the analysis of censored data, in Recent Advances in Life-Testing and Reliability, edited by N. Balakrishnan, chapter 29, CRC Press, Boca Raton, Fla., pp. 546&ndash;560.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lmoms">lmoms</a></code>, <code><a href="#topic+pwm2lmom">pwm2lmom</a></code>, <code><a href="#topic+pwm">pwm</a></code>, <code><a href="#topic+pwmLC">pwmLC</a></code>  </p>


<h3>Examples</h3>

<pre><code class='language-R'># Data listed in Hosking (1995, table 29.2, p. 551)
H &lt;- c(3,4,5,6,6,7,8,8,9,9,9,10,10,11,11,11,13,13,13,13,13,
       17,19,19,25,29,33,42,42,51.9999,52,52,52)
# 51.9999 was really 52, a real (noncensored) data point.
z &lt;-  pwmRC(H,threshold=52,checkbetas=TRUE)
str(z)
# Hosking(1995) reports that A-type L-moments for this sample are
# lamA1=15.7 and lamAL-CV=.389, and lamAL-skew=.393
pwm2lmom(z$Abetas)
# My version of R reports 15.666, 0.3959, and 0.4030


# See p. 553 of Hosking (1995)
# Data listed in Hosking (1995, table 29.3, p. 553)
D &lt;- c(-2.982, -2.849, -2.546, -2.350, -1.983, -1.492, -1.443,
       -1.394, -1.386, -1.269, -1.195, -1.174, -0.854, -0.620,
       -0.576, -0.548, -0.247, -0.195, -0.056, -0.013,  0.006,
        0.033,  0.037,  0.046,  0.084,  0.221,  0.245,  0.296)
D &lt;- c(D,rep(.2960001,40-28)) # 28 values, but Hosking mentions
                              # 40 values in total
z &lt;-  pwmRC(D,.2960001)
# Hosking reports B-type L-moments for this sample are
# lamB1 = -.516 and lamB2 = 0.523
pwm2lmom(z$Bbetas)
# My version of R reports -.5162 and 0.5218
</code></pre>

<hr>
<h2 id='qlmomco'>Quantile Function of the Distributions</h2><span id='topic+qlmomco'></span>

<h3>Description</h3>

<p>This function acts as an alternative front end to <code><a href="#topic+par2qua">par2qua</a></code>. The nomenclature of the <code><a href="#topic+qlmomco">qlmomco</a></code> function is to mimic that of built-in <span class="rlang"><b>R</b></span> functions that interface with distributions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>qlmomco(f, para)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="qlmomco_+3A_f">f</code></td>
<td>
<p>Nonexceedance probability (<code class="reqn">0 \le F \le 1</code>).</p>
</td></tr>
<tr><td><code id="qlmomco_+3A_para">para</code></td>
<td>
<p>The parameters from <code><a href="#topic+lmom2par">lmom2par</a></code> or similar.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Quantile value for <code class="reqn">F</code> for the specified parameters.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>See Also</h3>

<p><code><a href="#topic+dlmomco">dlmomco</a></code>, <code><a href="#topic+plmomco">plmomco</a></code>, <code><a href="#topic+rlmomco">rlmomco</a></code>, <code><a href="#topic+slmomco">slmomco</a></code>, <code><a href="#topic+add.lmomco.axis">add.lmomco.axis</a></code>, <code><a href="#topic+supdist">supdist</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>para &lt;- vec2par(c(0,1),type='nor') # standard normal parameters
p75  &lt;- qlmomco(.75,para) # 75th percentile of one standard deviation
</code></pre>

<hr>
<h2 id='qua.ostat'>Compute the Quantiles of the Distribution of an Order Statistic</h2><span id='topic+qua.ostat'></span>

<h3>Description</h3>

<p>This function computes a specified quantile by nonexceedance probability <code class="reqn">F</code> for the <code class="reqn">j</code>th-order statistic of a sample of size <code class="reqn">n</code> for a given distribution. Let the quantile function (inverse distribution) of the Beta distribution be
</p>
<p style="text-align: center;"><code class="reqn"> \mathrm{B}^{(-1)}(F,j,n-j+1) \mbox{,} </code>
</p>

<p>and let <code class="reqn">x(F,\Theta)</code> represent the quantile function of the given distribution and <code class="reqn">\Theta</code> represents a vector of distribution parameters. The quantile function of the distribution of the <code class="reqn">j</code>th-order statistic is
</p>
<p style="text-align: center;"><code class="reqn"> x\bigl(\mathrm{B}^{(-1)}(F,j,n-j+1),\Theta\bigr) \mbox{.} </code>
</p>



<h3>Usage</h3>

<pre><code class='language-R'>qua.ostat(f, j, n, para=NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="qua.ostat_+3A_f">f</code></td>
<td>
<p>The nonexceedance probability <code class="reqn">F</code> for the quantile.</p>
</td></tr>
<tr><td><code id="qua.ostat_+3A_j">j</code></td>
<td>
<p>The <code class="reqn">j</code>th-order statistic <code class="reqn">x_{1:n} \le x_{2:n} \le \ldots \le x_{j:n} \le x_{n:n}.</code></p>
</td></tr>
<tr><td><code id="qua.ostat_+3A_n">n</code></td>
<td>
<p>The sample size.</p>
</td></tr>
<tr><td><code id="qua.ostat_+3A_para">para</code></td>
<td>
<p>A distribution parameter list from a function such as <code><a href="#topic+lmom2par">lmom2par</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The quantile of the distribution of the <code class="reqn">j</code>th-order statistic is returned.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Gilchrist, W.G., 2000, Statistical modelling with quantile functions: Chapman and Hall/CRC, Boca Raton, Fla.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lmom2par">lmom2par</a></code>, <code><a href="#topic+vec2par">vec2par</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>gpa &lt;- vec2par(c(100, 500, 0.5), type="gpa")
n &lt;- 20   # the sample size
j &lt;- 15   # the 15th order statistic
F &lt;- 0.99 # the 99th percentile
theoOstat &lt;- qua.ostat(F, j, n, gpa)

## Not run: 
# Let us test this value against a brute force estimate.
Jth &lt;- vector(mode="numeric")
for(i in seq_len(50000)) {
  Q &lt;- sort( rlmomco(n, gpa) )
  Jth[i] &lt;- Q[j]
}
bruteOstat &lt;- quantile(Jth, F) # estimate by built-in function
theoOstat  &lt;- signif( theoOstat, digits=5)
bruteOstat &lt;- signif(bruteOstat, digits=5)
cat(c("Theoretical=", theoOstat, "  Simulated=", bruteOstat, "\n")) # 
## End(Not run)
</code></pre>

<hr>
<h2 id='qua2ci.cov'>Estimate a Confidence Interval for Quantiles of a Parent Distribution using Sample Variance-Covariances of L-moments</h2><span id='topic+qua2ci.cov'></span>

<h3>Description</h3>

<p>This function estimates the lower and upper limits of a specified confidence interval for aribitrary quantile values for a sample <code class="reqn">x</code> and a specified distribution form. The estimation is based on the sample variance-covariance structure of the L-moments (<code><a href="#topic+lmoms.cov">lmoms.cov</a></code>) through a Monte Carlo approach. The quantile values, actually the nonexceedance probabilities (<code class="reqn">F</code> for <code class="reqn">0 \le F \le 1</code>), are specified by the user. The user provides type of parent distribution distribution and this form which will be fitted internal to the function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>qua2ci.cov(x,f, type=NULL, nsim=1000,
                interval=c("confidence", "none"), level=0.90, tol=1E-6,
                asnorm=FALSE, altlmoms=NULL, flip=NULL, dimless=TRUE,
                usefastlcov=TRUE, nmom=5, getsimlmom=FALSE, verbose=FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="qua2ci.cov_+3A_x">x</code></td>
<td>
<p>A real value vector.</p>
</td></tr>
<tr><td><code id="qua2ci.cov_+3A_f">f</code></td>
<td>
<p>Nonexceedance probabilities (<code class="reqn">0 \le F \le 1</code>) of the quantiles for which the confidence interval is needed.</p>
</td></tr>
<tr><td><code id="qua2ci.cov_+3A_type">type</code></td>
<td>
<p>Three character distribution type (for example, type='gev').</p>
</td></tr>
<tr><td><code id="qua2ci.cov_+3A_nsim">nsim</code></td>
<td>
<p>The number of simulations to perform. Large numbers produce more refined confidence limit estimates at the cost of CPU time. The default is anticipated to be large enough to semi-quantitatively interpret results without too much computational delay. Larger simulation numbers are recommended.</p>
</td></tr>
<tr><td><code id="qua2ci.cov_+3A_interval">interval</code></td>
<td>
<p>The type of interval to compute. If <code>"none"</code>, then the simulated quantiles are returned at which point <em>only</em> the first value in <code class="reqn">f</code> or <code>f[1]</code> will be considered but a warning will be issued to remind the user. This option is nice for making boxplots of the quantile distribution.</p>
</td></tr>
<tr><td><code id="qua2ci.cov_+3A_level">level</code></td>
<td>
<p>The confidence interval (<code class="reqn">0 \le </code> <code>level</code> <code class="reqn"> &lt; 1</code>). The interval is specified as the size of the interval for which the default is 0.90 or the 90th percentile. The function will return the 5th [<code class="reqn">(1-0.90)/2</code>] and 95th [<code class="reqn">(1-(1-0.90)/2)</code>] percentile cumulative probability of the simulated quantile distribution as specified by the nonexceedance probability argument.</p>
</td></tr>
<tr><td><code id="qua2ci.cov_+3A_tol">tol</code></td>
<td>
<p>The tolerance argument of same name and default to feed to <code>MASS::mvrnorm()</code> and try increasing this tolerance if the error &ldquo;'Sigma' is not positive definite&rdquo; occurs (see <b>Note</b> for more discussion).</p>
</td></tr>
<tr><td><code id="qua2ci.cov_+3A_asnorm">asnorm</code></td>
<td>
<p>Use the mean and standard deviation of the simulated quantiles as parameters of the Normal distribution to estimate the confidence interval. Otherwise, a Bernstein polynomial approximation (<code><a href="#topic+dat2bernqua">dat2bernqua</a></code>) to the empirical distribution of the simulated quantile distribution is used.</p>
</td></tr>
<tr><td><code id="qua2ci.cov_+3A_altlmoms">altlmoms</code></td>
<td>
<p>Alternative L-moments to rescale the simulated L-moments from the variance-covariance structure of the sample L-moments in <code>x</code>. These L-moments need to be an <span class="pkg">lmomco</span> package L-moment object (e.g. <code><a href="#topic+lmoms">lmoms</a></code>). The presence of alternative L-moments will result in <code>dimless=TRUE</code>.</p>
</td></tr>
<tr><td><code id="qua2ci.cov_+3A_flip">flip</code></td>
<td>
<p>A flipping or reflection value denoted as <code class="reqn">\eta</code>. The values in <code>x</code> are flipped by this value (<code class="reqn">y = \eta - x</code>) and analysis proceeds with flipped information, and then results are flipped back just prior to returning values with the exception that if <code>getsimlmom=TRUE</code> then the simultated L-moments are in &ldquo;flipped space.&rdquo;</p>
</td></tr>
<tr><td><code id="qua2ci.cov_+3A_dimless">dimless</code></td>
<td>
<p>Perform the simulations in dimensionless space meaning that values in <code>x</code> are converted by <code class="reqn">y = (x-\lambda_1)/\lambda_2</code> and simulation based on <code class="reqn">y</code> and scale is returned on output according to the L-moments of <code>x</code> or the alternative L-moments in <code>altlmoms</code>. Scale is returned to the simulated L-moments, if returned by <code>getsimlmom=TRUE</code>, which is not fully parallel with the returned behavior when flipping is involved.</p>
</td></tr>
<tr><td><code id="qua2ci.cov_+3A_usefastlcov">usefastlcov</code></td>
<td>
<p>A logical to use the function <code>Lmomcov()</code> from the <span class="pkg">Lmoments</span> package to compute the sample variance-covariance matrices and not the much slower function <code><a href="#topic+lmoms.cov">lmoms.cov</a></code> in the <span class="pkg">lmomco</span> package.</p>
</td></tr>
<tr><td><code id="qua2ci.cov_+3A_nmom">nmom</code></td>
<td>
<p>The number of L-moments involved. This argument needs to be high enough to permit parameterization of the distribution in <code>type</code> but computational effort increases as <code>nmom</code> gets large.  This option is provided in conjunction with <code>getsimlmom=TRUE</code> to be able to get a &ldquo;wider set&rdquo; of simulated L-moments returned than precisely required by the distribution. Also, some distributions might as part of their specific fitting algorithms, require inspection of higher L-moments than seemingly required than their numer of parameters suggests.</p>
</td></tr>
<tr><td><code id="qua2ci.cov_+3A_getsimlmom">getsimlmom</code></td>
<td>
<p>A logical controlling whether the simulated L-moment matrix having <code>nsim</code> rows and <code>nmom</code> columns is returned instead of confidence limits.</p>
</td></tr>
<tr><td><code id="qua2ci.cov_+3A_verbose">verbose</code></td>
<td>
<p>The verbosity of the operation of the function.</p>
</td></tr>
<tr><td><code id="qua2ci.cov_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass such as to <code><a href="#topic+lmom2par">lmom2par</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>data.frame</code> is returned.
</p>
<table>
<tr><td><code>lwr</code></td>
<td>
<p>The lower value of the confidence interval having nonexceedance probability equal to <code class="reqn">(1-</code><code>level</code><code class="reqn">)/2</code>.</p>
</td></tr>
<tr><td><code>fit</code></td>
<td>
<p>The fit of the quantile based on the L-moments of <code>x</code> and possibly by reflection controlled by <code>flip</code> or based on the alternative L-moments in <code>altlmoms</code> and again by the reflection controlled by <code>flip</code>.</p>
</td></tr>
<tr><td><code>upr</code></td>
<td>
<p>The upper  value of the confidence interval having nonexceedance probability equal to <code class="reqn">1-(1-</code><code>level</code><code class="reqn">)/2</code>.</p>
</td></tr>
<tr><td><code>qua_med</code></td>
<td>
<p>The median of the simulated quantiles.</p>
</td></tr>
<tr><td><code>qua_mean</code></td>
<td>
<p>The mean of the simulated quantiles for which the median and mean should be very close if the simulation size is large enough and the quantile distribution is symmetrical.</p>
</td></tr>
<tr><td><code>qua_var</code></td>
<td>
<p>The variance (<code class="reqn">\sigma^2(F)</code>) of the simulated quantiles.</p>
</td></tr>
<tr><td><code>qua_lam2</code></td>
<td>
<p>The L-scale (<code class="reqn">\lambda_2(F)</code>) of the simulated quantiles for which <code class="reqn">\sigma^2(F) \approx \pi\times\lambda^2_2(F)</code>.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>These particular data set needs further evaluation as these particular sample can produce non-positive definite matrix being fed to <code>MASS:mvrnorm()</code>. It is noted that there are no ties in this data set.
</p>
<pre>
  test_dat &lt;- c(0.048151736, 0.036753258, 0.034895847, 0.082792447, 0.096984927,
                0.213977450, 0.020264292, 0.269585438, 0.304746113, 0.066339093,
                0.015651114, 0.025122412, 0.184095698, 0.047167958, 0.049824752,
                0.043390768, 0.055228680, 0.009325696, 0.042145010, 0.008113992,
                0.118901521, 0.050399301, 0.049646181, 0.032299402, 0.015229284,
                0.013684668, 0.049371734, 0.068426211, 0.207159600, 0.087228473,
                0.306276783, 0.024870356, 0.016946801, 0.051553444, 0.017654117)
  qua2ci.cov(test_dat, 0.5, type="pe3", tol=1E-6, nmom=5) # fails

  lams &lt;- lmoms(    test_dat)$lambdas
  lamc &lt;- lmoms.cov(test_dat)
  n &lt;- 100
  set.seed(1)
  MV1 &lt;- mvtnorm::rmvnorm(n, mean=lams, sigma=lamc, method="eigen")
  MV1 &lt;- mvtnorm::rmvnorm(n, mean=lams, sigma=lamc, method="chol")
  MV1 &lt;- mvtnorm::rmvnorm(n, mean=lams, sigma=lamc, method="svd")
  colnames(MV1) &lt;- paste0(rep("lam",5),1:5)
  set.seed(1)
  MV2 &lt;- MASS::mvrnorm(n, lams, lamc, tol=5E-2)
  set.seed(1)
  MV3 &lt;- MASS::mvrnorm(n, lams, lamc, tol=Inf)

  summary(MV2-MV3)
  summary(MV1)
  summary(MV2)
  plotlmrdia(lmrdia(), xlim=c(0.3,0.7), ylim=c(0,.6))
  points(MV1[,3]/MV1[,2], MV1[,4]/MV1[,2], col="red",  cex=0.5)
  points(MV2[,3]/MV2[,2], MV2[,4]/MV2[,2], col="blue", cex=0.5)
</pre>
<p>Next we, try focusing on the upper left corner of the matrix, after all we do not need beyond the 3rd moment because the Pearson III is being used.
</p>
<pre>
  qua2ci.cov(test_dat, 0.5, type="pe3", tol=1E-6, nmom=3) # fails
</pre>
<p>Now try increasing the tolerance setting on the matrix postive definite test in the <code>MASS::mvrnorm()</code> function.
</p>
<pre>
  qua2ci.cov(test_dat, 0.5, type="pe3", tol=1E-4, nmom=5) # fails
</pre>
<p>Now try again just focusing on the upper left corner that we really need.
</p>
<pre>
  set.seed(1)
  qua2ci.cov(test_dat, 0.5, type="pe3", tol=1E-4, nmom=3) # IT WORKS
  # nonexceed     lwr      fit      upr  qua_med qua_mean   qua_var qua_lam2
  #       0.5 0.02762 0.044426 0.061189 0.044322 0.044319 0.0001019 0.005672
</pre>
<p>Let us now try a hack of smoothing the data through the Bernstein polynomial. Perhaps subtle issues in the data can be &ldquo;fixed&rdquo; by this and the seed has been set to have the <code>MASS::mvrnorm()</code> see the same seed although the variance-covariance matrix is slightly changing. Notice that the tolerance now returns to the default and that we are requesting up through the 5th L-moment.
</p>
<pre>
  set.seed(1)
  n &lt;- length(test_dat)
  smth_dat &lt;- dat2bernqua((1:n)/(n+1), test_dat)
  qua2ci.cov(smth_dat, 0.5, type="pe3", tol=1E-6, nmom=5) # IT WORKS
  # nonexceed     lwr      fit     upr  qua_med qua_mean   qua_var  qua_lam2
  #       0.5 0.02864 0.048288 0.06778 0.048406 0.048201 0.0001405 0.0066678
</pre>
<p>A quick look at the smoothing. The author is not advocating for this but this trick might be useful in data-mining scale work where for some samples, we need something back. The user might then consider using the differences <code>upr</code><code class="reqn">-</code><code>fit</code> and <code>fit</code><code class="reqn">-</code><code>lwr</code> to reconstruct the interval from a fit based on the original sample.
</p>
<pre>
  plot( (1:n)/(n+1), sort(test_dat))
  lines((1:n)/(n+1), smth_dat, col=2)
</pre>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>See Also</h3>

<p><code><a href="#topic+lmoms">lmoms</a></code>, <code><a href="#topic+lmoms.cov">lmoms.cov</a></code>, <code><a href="#topic+qua2ci.simple">qua2ci.simple</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
samsize &lt;- 128; nsim &lt;- 2000; f &lt;- 0.999
wei &lt;- parwei(vec2lmom(c(100,75,-.3)))
set.seed(1734); X &lt;- rlmomco(samsize, wei); set.seed(1734)
tmp &lt;- qua2ci.cov(X, f, type="wei", nsim=nsim)
print(tmp) # show results of one 2000 replicated Monte Carlo
# nonexceed     lwr    fit    upr  qua_med  qua_mean  qua_var  qua_lam2
#     0.999   310.4  333.2  360.2    333.6     334.3    227.3    8.4988
set.seed(1734)
qf &lt;- qua2ci.cov(X, f, type="wei", nsim=nsim, interval="none") # another
boxplot(qf)
message(" quantile variance: ", round(tmp$qua_var,  digits=2),
        " compared to ", round(var(qf, na.rm=TRUE), digits=2))
set.seed(1734)
genci.simple(wei, n=samsize, f=f)
# nonexceed     lwr    fit    upr  qua_med  qua_mean  qua_var  qua_lam2
#     0.999   289.7  312.0  337.7    313.5     313.6    213.5    8.2330

#----------------------------------------
# Using X from above example, demonstrate that using dimensionless
# simulation that the results are the same.
set.seed(145); qua2ci.cov(X, 0.1, type="wei") # both outputs same
set.seed(145); qua2ci.cov(X, 0.1, type="wei", dimless=TRUE)
# nonexceed     lwr    fit    upr  qua_med  qua_mean  qua_var  qua_lam2
#       0.1  -78.62 -46.01 -11.39   -43.58    -44.38   416.04     11.54

#----------------------------------------
# Using X again, demonstration application of the flip and notice that just
# simple reversal is occurring and that the Weibull is a reversed GEV.
eta &lt;- 0
set.seed(145); qua2ci.cov(X, 0.9, type="wei", nsim=nsim)
# nonexceed     lwr    fit    upr  qua_med  qua_mean  qua_var  qua_lam2
#       0.9   232.2  244.2  255.9    244.3     244.1    51.91    4.0635
set.seed(145); qua2ci.cov(X, 0.9, type="gev", nsim=nsim, flip=eta)
# nonexceed     lwr    fit    upr  qua_med  qua_mean  qua_var  qua_lam2
#       0.9   232.2  244.2  256.2    244.2     244.3    53.02    4.1088
# The values are slightly different, which likely represents a combination
# of numerics of the variance-covariance matrix because the Monte Carlo
# is seeded the same.

#----------------------------------------
# Using X again, removed dimension and have the function add it back.
lmr &lt;- lmoms(X); Y &lt;- (X - lmr$lambdas[1])/lmr$lambdas[2]
set.seed(145); qua2ci.cov(Y, 0.9, type="wei", altlmoms=lmr, nsim=nsim)
# nonexceed     lwr    fit    upr  qua_med  qua_mean  qua_var  qua_lam2
#       0.9   232.2  244.2  255.9    244.3     244.1    51.91   4.0635
## End(Not run)
</code></pre>

<hr>
<h2 id='qua2ci.simple'>Estimate a Confidence Interval for a Single Quantile of a Parent Distribution by a Simple Algorithm</h2><span id='topic+qua2ci'></span><span id='topic+qua2ci.simple'></span>

<h3>Description</h3>

<p>This function estimates the lower and upper limits of a specified confidence interval for an aribitrary quantile value of a specified parent distribution [quantile function <code class="reqn">Q(F,\theta)</code> with parameters <code class="reqn">\theta</code>] using Monte Carlo simulation. The quantile value, actually the nonexceedance probability (<code class="reqn">F</code> for <code class="reqn">0 \le F \le 1</code>) of the value, is specified by the user. The user also provides the parameters of the parent distribution (see <code><a href="#topic+lmom2par">lmom2par</a></code>). This function does consider an estimate of the variance-covariance structure of the sample data (for that see <code><a href="#topic+qua2ci.cov">qua2ci.cov</a></code>).  The <code>qua2ci.simple</code> is the original implementation and dates close to the initial releases of <span class="pkg">lmomco</span> and was originally named <code>qua2ci</code>. That name is now deprecated but retained as an alias, which will be removed at some later release.
</p>
<p>For <code>nsim</code> simulation runs (ideally a large number), samples of size <code class="reqn">n</code> are drawn from <code class="reqn">Q(F,\theta)</code>. The L-moments of each simulated sample are computed using <code><a href="#topic+lmoms">lmoms</a></code> and a distribution of the same type is fit. The <code class="reqn">F</code>-quantile of the just-fitted distribution is computed and placed into a vector. The process of simulating the sample, computing the L-moments, computing the parameters, and solving for the <code class="reqn">F</code>-quantile is repeated for the specified number of simulation runs.
</p>
<p>To estimate the confidence interval, the L-moments of the vector simulated quantiles are computed. Subsequently, the parameters of a user-specified distribution &ldquo;error&rdquo; distribution (<code>edist</code>) are computed. The two quantiles of this error distribution for the specified confidence interval are computed. These two quantiles represent the estimated lower and upper limits for the confidence interval of the parent distribution for samples of size <code class="reqn">n</code>. The error distribution defaults to the Generalized Normal (see <code><a href="#topic+pargno">pargno</a></code>) because this distribution has the Normal as a special case but extends the fit to the 3rd L-moment (<code class="reqn">\tau_3</code>) for exotic situations in which some asymmetry in the quantile distribution might exist.
</p>
<p>Finally, it is often useful to have vectors of lower and upper limits for confidence intervals for a vector of <code class="reqn">F</code> values. The function <code><a href="#topic+genci.simple">genci.simple</a></code> does just that and uses <code><a href="#topic+qua2ci.simple">qua2ci.simple</a></code> as the computational underpinning.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>qua2ci.simple(f,para,n, level=0.90, edist="gno", nsim=1000, showpar=FALSE,
                        empdist=TRUE, verbose=FALSE, maxlogdiff=6, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="qua2ci.simple_+3A_f">f</code></td>
<td>
<p>Nonexceedance probability (<code class="reqn">0 \le F \le 1</code>) of the quantile for which the confidence interval is needed. This function is not vectorized and therefore only the first value will be used. This is in contrast to the vectorization of <code class="reqn">F</code> in the conceptually similar function <code><a href="#topic+qua2ci.cov">qua2ci.cov</a></code>.</p>
</td></tr>
<tr><td><code id="qua2ci.simple_+3A_para">para</code></td>
<td>
<p>The parameters from <code><a href="#topic+lmom2par">lmom2par</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>&mdash;these parameters represent the &ldquo;true&rdquo; parent.</p>
</td></tr>
<tr><td><code id="qua2ci.simple_+3A_n">n</code></td>
<td>
<p>The sample size for each Monte Carlo simulation will use.</p>
</td></tr>
<tr><td><code id="qua2ci.simple_+3A_level">level</code></td>
<td>
<p>The confidence interval (<code class="reqn">0 \le </code> <code>level</code> <code class="reqn"> &lt; 1</code>). The interval is specified as the size of the interval. The default is 0.90 or the 90th percentile. The function will return the 5th [<code class="reqn">(1-0.90)/2</code>] and 95th [<code class="reqn">(1-(1-0.90)/2)</code>] percentile cumulative probability of the simulated quantile distribution as specified by the nonexceedance probability argument. The arguments <code>level</code> and <code>f</code> therefore are separate features.</p>
</td></tr>
<tr><td><code id="qua2ci.simple_+3A_edist">edist</code></td>
<td>
<p>The model for the error distribution. Although the Normal (the default) commonly is  assumed in error analyses, it need not be, as support for other distributions supported by <span class="pkg">lmomco</span> is available. The default is the Generalized Normal so the not only is the Normal possible but asymmetry is also accomodated (<code><a href="#topic+lmomgno">lmomgno</a></code>).  For example, if the L-skew  (<code class="reqn">\tau_4</code>) or L-kurtosis (<code class="reqn">\tau_4</code>) values depart considerably from those of the Normal (<code class="reqn">\tau_3 = 0</code> and <code class="reqn">\tau_4 = 0.122602</code>), then the Generalized Normal or some alternative distribution would likely provide more reliable confidence interval estimation.</p>
</td></tr>
<tr><td><code id="qua2ci.simple_+3A_nsim">nsim</code></td>
<td>
<p>The number of simulations (replications) for the sample size <code>n</code> to perform. Large numbers produce more refined confidence limit estimates at the cost of CPU time. The default is anticipated to be large enough for evaluative-useage without too much computational delay. Larger simulation numbers are recommended.</p>
</td></tr>
<tr><td><code id="qua2ci.simple_+3A_showpar">showpar</code></td>
<td>
<p>The parameters of the <code>edist</code> for each simulation are printed.</p>
</td></tr>
<tr><td><code id="qua2ci.simple_+3A_empdist">empdist</code></td>
<td>
<p>If <code>TRUE</code>, then an <span class="rlang"><b>R</b></span> <code>environment</code> is appended onto the element <code>empdist</code> in the returned list, otherwise <code>empdist</code> is <code>NA</code>.</p>
</td></tr>
<tr><td><code id="qua2ci.simple_+3A_verbose">verbose</code></td>
<td>
<p>The verbosity of the operation of the function.</p>
</td></tr>
<tr><td><code id="qua2ci.simple_+3A_maxlogdiff">maxlogdiff</code></td>
<td>
<p>The maximum permitted difference in log10 space between a simulated quantile and the true value. It is possible that a well fit simulated sample to the parent distribution type provides crazy quantile estimates in the far reaches of either tail.  The default value of 6 was chosen based on experience with the Kappa distribution fit to a typical heavy-right tail flood magnitude data set. The concern motivating this feature is that as the number of parameters increases, it seems progressively there is more chance for a distribution tail to swing wildy into regions for which an analyst would not be comfortable with given discipline-specific knowledge. The choice of 6-log cycles is <em>ad hoc</em> at best, and users are encouraged to do their own exploration. If <code>verbose=TRUE</code> then a message will be printed when the <code>maxlogdiff</code> condition is tripped.</p>
</td></tr>
<tr><td><code id="qua2ci.simple_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass such as to <code><a href="#topic+lmom2par">lmom2par</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> is returned. The <code>lwr</code> and <code>upr</code> match the nomenclature of <code><a href="#topic+qua2ci.cov">qua2ci.cov</a></code> but because <code>qua2ci.simple</code> is provided the parent, the <code>true</code> value is returned, whereas <code><a href="#topic+qua2ci.cov">qua2ci.cov</a></code> returns the <code>fit</code>.
</p>
<table>
<tr><td><code>lwr</code></td>
<td>
<p>The lower value of the confidence interval having nonexceedance probability equal to <code class="reqn">(1-</code><code>level</code><code class="reqn">)/2</code>.</p>
</td></tr>
<tr><td><code>true</code></td>
<td>
<p>The value returned by <code>par2qua(f,para)</code>.</p>
</td></tr>
<tr><td><code>upr</code></td>
<td>
<p>The upper  value of the confidence interval having nonexceedance probability equal to <code class="reqn">1-(1-</code><code>level</code><code class="reqn">)/2</code>.</p>
</td></tr>
<tr><td><code>elmoms</code></td>
<td>
<p>The L-moments from <code><a href="#topic+lmoms">lmoms</a></code> of the distribution of simulated of quantiles.</p>
</td></tr>
<tr><td><code>epara</code></td>
<td>
<p>The parameters of the error distribution fit using the <code>elmoms</code>.</p>
</td></tr>
<tr><td><code>empdist</code></td>
<td>
<p>An <span class="rlang"><b>R</b></span> <code>environment</code> (see below).</p>
</td></tr>
<tr><td><code>ifail</code></td>
<td>
<p>A diagnostic value. A value of zero means that successful exit was made.</p>
</td></tr>
<tr><td><code>ifailtext</code></td>
<td>
<p>A descriptive message related to the <code>ifail</code> value.</p>
</td></tr>
<tr><td><code>nsim</code></td>
<td>
<p>An echoing of the <code>nsim</code> argument for the function.</p>
</td></tr>
<tr><td><code>sim.attempts</code></td>
<td>
<p>The number of executions of the <code>while</code> loop (see Note below).</p>
</td></tr>
</table>
<p>The <code>empdist</code> element in the returned <code>list</code> is an <span class="rlang"><b>R</b></span> <code>environment</code> that contains:
</p>
<table>
<tr><td><code>simquas</code></td>
<td>
<p>A <code>nsim</code>-long vector of the simulated quantiles for <code>f</code>.</p>
</td></tr>
<tr><td><code>empir.dist.lwr</code></td>
<td>
<p>The <em>lower</em> limit derived from the <span class="rlang"><b>R</b></span> <code>quantile</code> function for <code>type=6</code>, which uses <code class="reqn">i/(n+1)</code>.</p>
</td></tr>
<tr><td><code>empir.dist.upr</code></td>
<td>
<p>The <em>upper</em> limit derived from the <span class="rlang"><b>R</b></span> <code>quantile</code> function for <code>type=6</code>, which uses <code class="reqn">i/(n+1)</code>.</p>
</td></tr>
<tr><td><code>bern.smooth.lwr</code></td>
<td>
<p>The <em>lower</em> limit estimated by the Bernstein smoother in <code><a href="#topic+dat2bernqua">dat2bernqua</a></code> for <br /> <code>poly.type = "Bernstein"</code> and <code>bound.type = "none"</code>.</p>
</td></tr>
<tr><td><code>bern.smooth.upr</code></td>
<td>
<p>The <em>upper</em> limit estimated by the Bernstein smoother in <code><a href="#topic+dat2bernqua">dat2bernqua</a></code> for <br /> <code>poly.type = "Bernstein"</code> and <code>bound.type = "none"</code>.</p>
</td></tr>
<tr><td><code>epmoms</code></td>
<td>
<p>The product moments of the simulated quantiles from <code><a href="#topic+pmoms">pmoms</a></code>.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>This function relies on a <code>while</code> loop that runs until <code>nsim</code> have successfully completed. Some reasons for an early <code>next</code> in the loop include invalid L-moments by <code><a href="#topic+are.lmom.valid">are.lmom.valid</a></code> of the simluated data or invalid fitted parameters by <code><a href="#topic+are.par.valid">are.par.valid</a></code> to simulated L-moments.  See the source code for more details.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>See Also</h3>

<p><code><a href="#topic+lmoms">lmoms</a></code>, <code><a href="#topic+pmoms">pmoms</a></code>, <code><a href="#topic+par2qua">par2qua</a></code>, <code><a href="#topic+genci.simple">genci.simple</a></code>, <code><a href="#topic+qua2ci.cov">qua2ci.cov</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# It is well known that standard deviation (sigma) of the
# sample mean is equal to sigma/sample_size. Let is look at the
# quantile distribution of the median (f=0.5)
mean   &lt;- 0; sigma &lt;- 100
parent &lt;- vec2par(c(mean,sigma), type='nor')
CI     &lt;- qua2ci.simple(0.5, parent, n=10, nsim=20)
# Theoretrical sample mean sigma = 100/10 = 10
# L-moment theory: L-scale * sqrt(pi) = sigma
# Thus, it follows that the quantity
CI$elmoms$lambdas[2]/sqrt(pi)
# approaches 10 as nsim --&gt; Inf.
## End(Not run)

# Another example.
D   &lt;- c(123, 34, 4, 654, 37, 78, 93, 95, 120) # fake sample
lmr &lt;- lmoms(D)    # compute the L-moments of the data
WEI &lt;- parwei(lmr) # estimate Weibull distribution parameters
CI  &lt;- qua2ci.simple(0.75,WEI,20, nsim=20, level=0.95)
# CI contains the estimate 95-percent confidence interval for the
# 75th-percentile of the parent Weibull distribution for 20 sample size 20.
## Not run: 
pdf("Substantial_qua2ci_example.pdf")
level &lt;- 0.90; cilo &lt;- (1-level)/2; cihi &lt;- 1 - cilo
para &lt;- lmom2par(vec2lmom(c(180,50,0.75)), type="gev")
A &lt;- qua2ci.simple(0.98, para, 30, edist="gno", level=level, nsim=3000)
Apara &lt;- A$epara; Aenv &lt;- A$empdist
Bpara &lt;- lmom2par(A$elmoms, type="aep4")

lo &lt;- log10(A$lwr); hi &lt;- log10(A$upr)
xs &lt;- 10^(seq(lo-0.2, hi+0.2, by=0.005))
lo &lt;- A$lwr; hi &lt;- A$upr; xm &lt;- A$true; sbar &lt;- mean(Aenv$simquas)
dd &lt;- density(Aenv$simquas, adjust=0.5)
pk &lt;- max(dd$y, dlmomco(xs, Apara), dlmomco(xs, Bpara))
dx &lt;- dd$x[dd$x &gt;= Aenv$empir.dist.lower &amp; dd$x &lt;= Aenv$empir.dist.upper]
dy &lt;- dd$y[dd$x &gt;= Aenv$empir.dist.lower &amp; dd$x &lt;= Aenv$empir.dist.upper]
dx &lt;- c(dx[1], dx, dx[length(dx)]); dy &lt;- c(0, dy, 0)

plot(c(0), c(0), type="n", xlim=range(xs), ylim=c(0,pk),
                 xlab="X VALUE", ylab="PROBABILITY DENSITY")
polygon(dx, dy, col=8)
lines(xs, dlmomco(xs, Apara)); lines(xs, dlmomco(xs, Bpara), col=2, lwd=2)
lines(dd, lty=2, lwd=2, col=8)
lines(xs, dlmomco(xs, para), col=6); lines(c(xm,xm), c(0,pk), lty=4, lwd=3)
lines(c(lo,lo,NA,hi,hi), c(0,pk,NA,0,pk), lty=2)

xlo &lt;- qlmomco(cilo, Apara); xhi &lt;- qlmomco(cihi, Apara)
points(c(xlo, xhi), c(dlmomco(xlo, Apara), dlmomco(xhi, Apara)), pch=16)
xlo &lt;- qlmomco(cilo, Bpara); xhi &lt;- qlmomco(cihi, Bpara)
points(c(xlo, xhi), c(dlmomco(xlo, Bpara), dlmomco(xhi, Bpara)), pch=16, col=2)
lines(rep(Aenv$empir.dist.lwr, 2), c(0,pk), lty=3, lwd=2, col=3)
lines(rep(Aenv$empir.dist.upr, 2), c(0,pk), lty=3, lwd=2, col=3)
lines(rep(Aenv$bern.smooth.lwr,2), c(0,pk), lty=3, lwd=2, col=4)
lines(rep(Aenv$bern.smooth.upr,2), c(0,pk), lty=3, lwd=2, col=4)
cat(c(  "F(true) = ",             round(plmomco(xm,   Apara), digits=2),
      "; F(mean(sim), edist) = ", round(plmomco(sbar, Apara), digits=2), "\n"), sep="")
dev.off()
## End(Not run)
## Not run: 
ty &lt;- "nor" # try running with "glo" (to get the L-skew "fit", see below)
para &lt;- lmom2par(vec2lmom(c(-180,70,-.5)), type=ty)
f &lt;- 0.99; n &lt;- 41; ns &lt;- 1000; Qtrue &lt;- qlmomco(f, para)
Qsim1 &lt;- replicate(ns, qlmomco(f, lmom2par(lmoms(rlmomco(n, para)), type=ty)))
Qsim2 &lt;- qua2ci.simple(f, para, n, nsim=ns, edist="gno")
Qbar1 &lt;- mean(Qsim1); Qbar2 &lt;- mean(Qsim2$empdist$simquas)
epara &lt;- Qsim2$epara; FT &lt;- plmomco(Qtrue, epara)
F1 &lt;- plmomco(Qbar1, epara); F2 &lt;- plmomco(Qbar2, epara)
cat(c(  "F(true) = ",      round(FT, digits=2),
      "; F(via sim.) = ",  round(F1, digits=2),
      "; F(via edist) = ", round(F2, digits=2), "\n"), sep="")
# The given L-moments are highly skewed, but a Normal distribution is fit so
# L-skew is ignored. The game is deep tail (f=0.99) estimation. The true value of the
# quantile has a percentile on the error distribution 0.48 that is almost exactly 0.5
# (median = mean = symmetrical error distribution).  A test run shows nice behavior:
# F(true) =  0.48; F(via sim.) =  0.49; F(via edist) =  0.5
# But another run with ty &lt;- "glo" (see how 0.36 &lt;&lt; [0.52, 0.54]) has
# F(true) =  0.36; F(via sim.) =  0.54; F(via edist) =  0.52
# So as the asymmetry becomes extreme, the error distribution becomes asymmetrical too.
## End(Not run)
</code></pre>

<hr>
<h2 id='quaaep4'>Quantile Function of the 4-Parameter Asymmetric Exponential Power Distribution</h2><span id='topic+quaaep4'></span>

<h3>Description</h3>

<p>This function computes the quantiles of the 4-parameter Asymmetric Exponential Power distribution given parameters (<code class="reqn">\xi</code>, <code class="reqn">\alpha</code>, <code class="reqn">\kappa</code>, and <code class="reqn">h</code>) of the distribution computed by <code><a href="#topic+paraep4">paraep4</a></code>. The quantile function of the distribution given the cumulative distribution function <code class="reqn">F(x)</code> for <code class="reqn">F &lt; F(\xi)</code> is
</p>
<p style="text-align: center;"><code class="reqn">x(F) = \xi - \alpha\kappa\biggl[\gamma^{(-1)}\bigl((1+\kappa^2)F/\kappa^2,\; 1/h\bigr)\biggr]^{1/h}\mbox{,}</code>
</p>

<p>and for <code class="reqn">F \ge F(\xi)</code> is
</p>
<p style="text-align: center;"><code class="reqn">x(F) = \xi + \frac{\alpha}{\kappa}\biggl[\gamma^{(-1)}\bigl((1+\kappa^2)(1-F),\; 1/h\bigr)\biggr]^{1/h} \mbox{,}</code>
</p>

<p>where <code class="reqn">x(F)</code> is the quantile <code class="reqn">x</code> for nonexceedance probability <code class="reqn">F</code>,
<code class="reqn">\xi</code> is a location parameter, <code class="reqn">\alpha</code> is a scale parameter,
<code class="reqn">\kappa</code> is a shape parameter, <code class="reqn">h</code> is another shape parameter, <code class="reqn">\gamma^{(-1)}(Z, shape)</code> is the inverse of the upper tail of the incomplete gamma function. The range of the distribution is <code class="reqn">-\infty &lt; x &lt; \infty</code>. The inverse upper tail of the incomplete gamma function is <code>qgamma(Z, shape, lower.tail=FALSE)</code> in <span class="rlang"><b>R</b></span>. The mathematical definition of the upper tail of the incomplete gamma function shown in documentation for <code><a href="#topic+cdfaep4">cdfaep4</a></code>. If the <code class="reqn">\tau_3</code> of the distribution is zero (symmetrical), then the distribution is known as the Exponential Power (see <code><a href="#topic+lmrdia46">lmrdia46</a></code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>quaaep4(f, para, paracheck=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="quaaep4_+3A_f">f</code></td>
<td>
<p>Nonexceedance probability (<code class="reqn">0 \le F \le 1</code>).</p>
</td></tr>
<tr><td><code id="quaaep4_+3A_para">para</code></td>
<td>
<p>The parameters from <code><a href="#topic+paraep4">paraep4</a></code> or similar.</p>
</td></tr>
<tr><td><code id="quaaep4_+3A_paracheck">paracheck</code></td>
<td>
<p>A logical controlling whether the parameters are checked for validity. Overriding of this check might be extremely important and needed for use of the quantile function in the context of TL-moments with nonzero trimming.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Quantile value for nonexceedance probability <code class="reqn">F</code>.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Asquith, W.H., 2014, Parameter estimation for the 4-parameter asymmetric exponential power distribution by the method of L-moments using R: Computational Statistics and Data Analysis, v. 71, pp. 955&ndash;970.
</p>
<p>Delicado, P., and Goria, M.N., 2008, A small sample comparison of maximum likelihood,
moments and L-moments methods for the asymmetric exponential power distribution:
Computational Statistics and Data Analysis, v. 52, no. 3, pp. 1661&ndash;1673.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cdfaep4">cdfaep4</a></code>, <code><a href="#topic+pdfaep4">pdfaep4</a></code>, <code><a href="#topic+lmomaep4">lmomaep4</a></code>, <code><a href="#topic+paraep4">paraep4</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>para &lt;- vec2par(c(0,1, 0.5, 2), type="aep4");
IQR &lt;- quaaep4(0.75,para) - quaaep4(0.25,para);
cat("Interquartile Range=",IQR,"\n")

## Not run: 
F &lt;- c(0.00001, 0.0001, 0.001, seq(0.01, 0.99, by=0.01),
       0.999, 0.9999, 0.99999);
delx &lt;- 0.1;
x &lt;- seq(-10,10, by=delx);
K &lt;- .67

PAR &lt;- list(para=c(0,1, K, 0.5), type="aep4");
plot(x,cdfaep4(x, PAR), type="n",
     ylab="NONEXCEEDANCE PROBABILITY",
     ylim=c(0,1), xlim=c(-20,20));
lines(x,cdfaep4(x,PAR), lwd=3);
lines(quaaep4(F, PAR), F, col=4);

PAR &lt;- list(para=c(0,1, K, 1), type="aep4");
lines(x,cdfaep4(x, PAR), lty=2, lwd=3);
lines(quaaep4(F, PAR), F, col=4, lty=2);

PAR &lt;- list(para=c(0,1, K, 2), type="aep4");
lines(x,cdfaep4(x, PAR), lty=3, lwd=3);
lines(quaaep4(F, PAR), F, col=4, lty=3);

PAR &lt;- list(para=c(0,1, K, 4), type="aep4");
lines(x,cdfaep4(x, PAR), lty=4, lwd=3);
lines(quaaep4(F, PAR), F, col=4, lty=4);

## End(Not run)
</code></pre>

<hr>
<h2 id='quaaep4kapmix'>Quantile Function Mixture Between the 4-Parameter Asymmetric Exponential Power and Kappa Distributions</h2><span id='topic+quaaep4kapmix'></span>

<h3>Description</h3>

<p>This function computes the quantiles of a mixture as needed between the 4-parameter Asymmetric Exponential Power (AEP4) and Kappa distributions given L-moments (<code><a href="#topic+lmoms">lmoms</a></code>). The quantile function of a two-distribution mixture is supported by <code><a href="#topic+par2qua2">par2qua2</a></code> and is
</p>
<p style="text-align: center;"><code class="reqn">x(F) = (1-w) \times A(F) + w \times K(F)\mbox{,} </code>
</p>

<p>where <code class="reqn">x(F)</code> is the mixture for nonexceedance probability <code class="reqn">F</code>, <code class="reqn">A(F)</code> is the AEP4 quantile function (<code><a href="#topic+quaaep4">quaaep4</a></code>), <code class="reqn">K(F)</code> is the Kappa quantile function (<code><a href="#topic+quakap">quakap</a></code>), and <code class="reqn">w</code> is a weight factor.
</p>
<p>Now, the above mixture is only applied if the <code class="reqn">\tau_4</code> for the given <code class="reqn">\tau_3</code> is within the overlapping region of the AEP4 and Kappa distributions. For this condition, the <code class="reqn">w</code> is computed by proration between the upper Kappa distribution bound (same as the <code class="reqn">\tau_3</code> and <code class="reqn">\tau_4</code> of the Generalized Logistic distribution, see <code><a href="#topic+lmrdia">lmrdia</a></code>) and the lower bounds of the AEP4. For <code class="reqn">\tau_4</code> above the Kappa, then the AEP4 is exclusive and conversely, for <code class="reqn">\tau_4</code> below the AEP4, then the Kappa is exclusive.
</p>
<p>The <code class="reqn">w</code> therefore is the proration
</p>
<p style="text-align: center;"><code class="reqn">w = [\tau^{K}_4(\hat\tau_3) - \hat\tau_4] / [\tau^{K}_4(\hat\tau_3) - \tau^{A}_4(\hat\tau_3)]\mbox{,}</code>
</p>

<p>where <code class="reqn">\hat\tau_4</code> is the sample L-kurtosis, <code class="reqn">\tau^{K}_4</code> is the upper bounds of the Kappa and <code class="reqn">\tau^{A}_4</code> is the lower bounds of the AEP4 for the sample L-skew (<code class="reqn">\hat\tau_3</code>).
</p>
<p>The parameter estimation for the AEP4 by <code><a href="#topic+paraep4">paraep4</a></code> can fall back to pure Kappa if argument <code>kapapproved=TRUE</code> is set. Such a fall back is unrelated to the mixture described here.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>quaaep4kapmix(f, lmom, checklmom=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="quaaep4kapmix_+3A_f">f</code></td>
<td>
<p>Nonexceedance probability (<code class="reqn">0 \le F \le 1</code>).</p>
</td></tr>
<tr><td><code id="quaaep4kapmix_+3A_lmom">lmom</code></td>
<td>
<p>A L-moment object created by <code><a href="#topic+lmoms">lmoms</a></code> or similar.</p>
</td></tr>
<tr><td><code id="quaaep4kapmix_+3A_checklmom">checklmom</code></td>
<td>
<p>Should the <code>lmom</code> be checked for validity using the <code><a href="#topic+are.lmom.valid">are.lmom.valid</a></code> function. Normally this should be left as the default and it is very unlikely that the L-moments will not be viable (particularly in the <code class="reqn">\tau_4</code> and <code class="reqn">\tau_3</code> inequality). However, for some circumstances or large simulation exercises then one might want to bypass this check.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Quantile value for nonexceedance probability <code class="reqn">F</code>.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Asquith, W.H., 2014, Parameter estimation for the 4-parameter asymmetric exponential power distribution by the method of L-moments using R: Computational Statistics and Data Analysis, v. 71, pp. 955&ndash;970.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+par2qua2">par2qua2</a></code>, <code><a href="#topic+quaaep4">quaaep4</a></code>, <code><a href="#topic+quakap">quakap</a></code>, <code><a href="#topic+paraep4">paraep4</a></code>, <code><a href="#topic+parkap">parkap</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
FF &lt;- c(0.0001, 0.0005, 0.001, seq(0.01,0.99, by=0.01), 0.999,
       0.9995, 0.9999); Z &lt;- qnorm(FF)
t3s &lt;- seq(0, 0.5, by=0.1); T4step &lt;- 0.02
pdf("mixture_test.pdf")
for(t3 in t3s) {
   T4low &lt;- (5*t3^2 - 1)/4; T4kapup &lt;- (5*t3^2 + 1)/6
   t4s &lt;- seq(T4low+T4step, T4kapup+2*T4step, by=T4step)
   for(t4 in t4s) {
      lmr &lt;- vec2lmom(c(0,1,t3,t4)) # make L-moments for lmomco
      if(! are.lmom.valid(lmr)) next # for general protection
      kap  &lt;- parkap(lmr)
      if(kap$ifail == 5) next # avoid further work if numeric problems
      aep4 &lt;- paraep4(lmr, method="A")
      X &lt;- quaaep4kapmix(FF, lmr)
      if(is.null(X)) next # one last protection
      plot(Z, X, type="l", lwd=5, col=1, ylim=c(-15,15),
           xlab="STANDARD NORMAL VARIATE",
           ylab="VARIABLE VALUE")
      mtext(paste("L-skew =",lmr$ratios[3],
                  "  L-kurtosis = ",lmr$ratios[4]))
      # Now add two more quantile functions for reference and review
      # of the mixture. These of course would not be done in practice
      # only quaaep4kapmix() would suffice.
      if(! as.logical(aep4$ifail)) {
         lines(Z, qlmomco(F,aep4), lwd=2, col=2)
      }
      if(! as.logical(kap$ifail)) {
         lines(Z, qlmomco(F,kap),  lwd=2, col=3)
      }
      message("t3=",t3,"  t4=",t4) # stout for a log file
  }
}
dev.off()

## End(Not run)
</code></pre>

<hr>
<h2 id='quacau'>Quantile Function of the Cauchy Distribution</h2><span id='topic+quacau'></span>

<h3>Description</h3>

<p>This function computes the quantiles of the Cauchy distribution given parameters (<code class="reqn">\xi</code> and <code class="reqn">\alpha</code>) of the distribution provided by <code><a href="#topic+parcau">parcau</a></code>. The quantile function of the distribution is
</p>
<p style="text-align: center;"><code class="reqn">x(F) = \xi + \alpha \times \tan\bigl(\pi(F-0.5)\bigr) \mbox{,}</code>
</p>

<p>where <code class="reqn">x(F)</code> is the quantile for nonexceedance probability <code class="reqn">F</code>, <code class="reqn">\xi</code> is a location parameter and <code class="reqn">\alpha</code> is a scale parameter. The quantile function of the Cauchy distribution is supported by <span class="rlang"><b>R</b></span> function <code>qcauchy</code>. This function does not use <code>qcauchy</code> because <code>qcauchy</code> does not return <code>Inf</code> for <code class="reqn">F = 1</code> although it
returns <code>-Inf</code> for <code class="reqn">F = 0</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>quacau(f, para, paracheck=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="quacau_+3A_f">f</code></td>
<td>
<p>Nonexceedance probability (<code class="reqn">0 \le F \le 1</code>).</p>
</td></tr>
<tr><td><code id="quacau_+3A_para">para</code></td>
<td>
<p>The parameters from <code><a href="#topic+parcau">parcau</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
<tr><td><code id="quacau_+3A_paracheck">paracheck</code></td>
<td>
<p>A logical controlling whether the parameters are checked for validity. Overriding of this check might be extremely important and needed for use of the distribution quantile function in the context of TL-moments with nonzero trimming.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Quantile value for for nonexceedance probability <code class="reqn">F</code>.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Elamir, E.A.H., and Seheult, A.H., 2003, Trimmed L-moments: Computational Statistics
and Data Analysis, v. 43, pp. 299&ndash;314.
</p>
<p>Gilchirst, W.G., 2000, Statistical modeling with quantile functions:
Chapman and Hall/CRC, Boca Raton, FL.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cdfcau">cdfcau</a></code>, <code><a href="#topic+pdfcau">pdfcau</a></code>, <code><a href="#topic+lmomcau">lmomcau</a></code>, <code><a href="#topic+parcau">parcau</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  para &lt;- c(12,12)
  quacau(.5,vec2par(para,type='cau'))
</code></pre>

<hr>
<h2 id='quaemu'>Quantile Function of the Eta-Mu Distribution</h2><span id='topic+quaemu'></span>

<h3>Description</h3>

<p>This function computes the quantiles of the Eta-Mu (<code class="reqn">\eta:\mu</code>) distribution given <code class="reqn">\eta</code> and <code class="reqn">\mu</code>) computed by <code><a href="#topic+paremu">paremu</a></code>. The quantile function is complex and numerical rooting of the cumulative distribution function (<code><a href="#topic+cdfemu">cdfemu</a></code>) is used.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>quaemu(f, para, paracheck=TRUE, yacoubsintegral=TRUE, eps=1e-7)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="quaemu_+3A_f">f</code></td>
<td>
<p>Nonexceedance probability (<code class="reqn">0 \le F \le 1</code>).</p>
</td></tr>
<tr><td><code id="quaemu_+3A_para">para</code></td>
<td>
<p>The parameters from <code><a href="#topic+paremu">paremu</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
<tr><td><code id="quaemu_+3A_paracheck">paracheck</code></td>
<td>
<p>A logical controlling whether the parameters are checked for validity. Overriding of this check might be extremely important and needed for use of the quantile function in the context of TL-moments with nonzero trimming.</p>
</td></tr>
<tr><td><code id="quaemu_+3A_yacoubsintegral">yacoubsintegral</code></td>
<td>
<p>A logical controlling whether the integral by Yacoub (2007) is used for the cumulative distribution function instead of numerical integration of <code><a href="#topic+pdfemu">pdfemu</a></code>.</p>
</td></tr>
<tr><td><code id="quaemu_+3A_eps">eps</code></td>
<td>
<p>A close-enough error term for the recursion process.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Quantile value for nonexceedance probability <code class="reqn">F</code>.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Yacoub, M.D., 2007, The kappa-mu distribution and the eta-mu distribution: IEEE Antennas and Propagation Magazine, v. 49, no. 1, pp. 68&ndash;81
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cdfemu">cdfemu</a></code>, <code><a href="#topic+pdfemu">pdfemu</a></code>, <code><a href="#topic+lmomemu">lmomemu</a></code>,  <code><a href="#topic+paremu">paremu</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
quaemu(0.75,vec2par(c(0.9, 1.5), type="emu")) #
## End(Not run)
</code></pre>

<hr>
<h2 id='quaexp'>Quantile Function of the Exponential Distribution</h2><span id='topic+quaexp'></span>

<h3>Description</h3>

<p>This function computes the quantiles of the Exponential distribution given parameters (<code class="reqn">\xi</code> and <code class="reqn">\alpha</code>) computed by <code><a href="#topic+parexp">parexp</a></code>. The quantile function is
</p>
<p style="text-align: center;"><code class="reqn">x(F) = \xi - \alpha \log(1-F) \mbox{,}</code>
</p>

<p>where <code class="reqn">x(F)</code> is the quantile for nonexceedance probability <code class="reqn">F</code>, <code class="reqn">\xi</code> is a location parameter, and <code class="reqn">\alpha</code> is a scale parameter.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>quaexp(f, para, paracheck=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="quaexp_+3A_f">f</code></td>
<td>
<p>Nonexceedance probability (<code class="reqn">0 \le F \le 1</code>).</p>
</td></tr>
<tr><td><code id="quaexp_+3A_para">para</code></td>
<td>
<p>The parameters from <code><a href="#topic+parexp">parexp</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
<tr><td><code id="quaexp_+3A_paracheck">paracheck</code></td>
<td>
<p>A logical controlling whether the parameters are checked for validity. Overriding of this check might be extremely important and needed for use of the quantile function in the context of TL-moments with nonzero trimming.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Quantile value for nonexceedance probability <code class="reqn">F</code>.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Hosking, J.R.M., 1990, L-moments&mdash;Analysis and estimation of
distributions using linear combinations of order statistics: Journal
of the Royal Statistical Society, Series B, v. 52, pp. 105&ndash;124.
</p>
<p>Hosking, J.R.M., 1996, FORTRAN routines for use with the method of L-moments:
Version 3, IBM Research Report RC20525, T.J. Watson Research Center,
Yorktown Heights, New York.
</p>
<p>Hosking, J.R.M., and Wallis, J.R., 1997, Regional frequency analysis&mdash;An
approach based on L-moments: Cambridge University Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cdfexp">cdfexp</a></code>, <code><a href="#topic+pdfexp">pdfexp</a></code>, <code><a href="#topic+lmomexp">lmomexp</a></code>, <code><a href="#topic+parexp">parexp</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>  lmr &lt;- lmoms(c(123,34,4,654,37,78))
  quaexp(0.5,parexp(lmr))
</code></pre>

<hr>
<h2 id='quagam'>Quantile Function of the Gamma Distribution</h2><span id='topic+quagam'></span>

<h3>Description</h3>

<p>This function computes the quantiles of the Gamma distribution given
parameters (<code class="reqn">\alpha</code> and <code class="reqn">\beta</code>) computed by <code><a href="#topic+pargam">pargam</a></code>.  The quantile function has no explicit form. See the <code>qgamma</code> function of <span class="rlang"><b>R</b></span> and <code><a href="#topic+cdfgam">cdfgam</a></code>. The parameters have the following interpretations: <code class="reqn">\alpha</code> is a shape parameter and <code class="reqn">\beta</code> is a scale parameter in the <span class="rlang"><b>R</b></span> syntax of the <code>qgamma()</code> function.
</p>
<p>Alternatively, a three-parameter version is available following the parameterization of the Generalized Gamma distribution used in the <span class="pkg">gamlss.dist</span> package and for <span class="pkg">lmomco</span> is documented under <code><a href="#topic+pdfgam">pdfgam</a></code>. The three parameter version is automatically triggered if the length of the <code>para</code> element is three and not two.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>quagam(f, para, paracheck=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="quagam_+3A_f">f</code></td>
<td>
<p>Nonexceedance probability (<code class="reqn">0 \le F \le 1</code>).</p>
</td></tr>
<tr><td><code id="quagam_+3A_para">para</code></td>
<td>
<p>The parameters from <code><a href="#topic+pargam">pargam</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
<tr><td><code id="quagam_+3A_paracheck">paracheck</code></td>
<td>
<p>A logical controlling whether the parameters are checked for validity. Overriding of this check might be extremely important and needed for use of the quantile function in the context of TL-moments with nonzero trimming.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Quantile value for nonexceedance probability <code class="reqn">F</code>.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Hosking, J.R.M., 1990, L-moments&mdash;Analysis and estimation of
distributions using linear combinations of order statistics: Journal
of the Royal Statistical Society, Series B, v. 52, pp. 105&ndash;124.
</p>
<p>Hosking, J.R.M., and Wallis, J.R., 1997, Regional frequency analysis&mdash;An
approach based on L-moments: Cambridge University Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cdfgam">cdfgam</a></code>, <code><a href="#topic+pdfgam">pdfgam</a></code>, <code><a href="#topic+lmomgam">lmomgam</a></code>, <code><a href="#topic+pargam">pargam</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>  lmr &lt;- lmoms(c(123,34,4,654,37,78))
  g &lt;- pargam(lmr)
  quagam(0.5,g)
## Not run: 
  # generate 50 random samples from this fitted parent
  Qsim &lt;- rlmomco(5000,g)
  # compute the apparent gamma parameter for this parent
  gsim &lt;- pargam(lmoms(Qsim))

## End(Not run)

## Not run: 
# 3-p Generalized Gamma Distribution and gamlss.dist package parameterization
gg &lt;- vec2par(c(2, 4, 3), type="gam")
X &lt;- gamlss.dist::rGG(1000, mu=2, sigma=4, nu=3); FF &lt;- nonexceeds(sig6=TRUE)
plot(qnorm(lmomco::pp(X)), sort(X), pch=16, col=8) # lets compare the two quantiles
lines(qnorm(FF), gamlss.dist::qGG(FF, mu=2, sigma=4, nu=3), lwd=6, col=3)
lines(qnorm(FF), quagam(FF, gg), col=2, lwd=2) # 
## End(Not run)

## Not run: 
# 3-p Generalized Gamma Distribution and gamlss.dist package parameterization
gg &lt;- vec2par(c(7.4, 0.2, -3), type="gam")
X &lt;- gamlss.dist::rGG(1000, mu=7.4, sigma=0.2, nu=-3); FF &lt;- nonexceeds(sig6=TRUE)
plot(qnorm(lmomco::pp(X)), sort(X), pch=16, col=8) # lets compare the two quantiles
lines(qnorm(FF), gamlss.dist::qGG(FF, mu=7.4, sigma=0.2, nu=-3), lwd=6, col=3)
lines(qnorm(FF), quagam(FF, gg), col=2, lwd=2) # 
## End(Not run)
</code></pre>

<hr>
<h2 id='quagep'>Quantile Function of the Generalized Exponential Poisson Distribution</h2><span id='topic+quagep'></span>

<h3>Description</h3>

<p>This function computes the quantiles of the Generalized Exponential Poisson distribution given parameters (<code class="reqn">\beta</code>, <code class="reqn">\kappa</code>, and <code class="reqn">h</code>) of the distribution computed by <code><a href="#topic+pargep">pargep</a></code>. The quantile function of the distribution is
</p>
<p style="text-align: center;"><code class="reqn">x(F) = \eta^{-1} \log[1 + h^{-1}\log(1 - F^{1/\kappa}[1 - \exp(-h)])]\mbox{,}</code>
</p>

<p>where <code class="reqn">F(x)</code> is the nonexceedance probability for quantile <code class="reqn">x &gt; 0</code>, <code class="reqn">\eta = 1/\beta</code>, <code class="reqn">\beta &gt; 0</code> is a scale parameter, <code class="reqn">\kappa &gt; 0</code> is a shape parameter, and <code class="reqn">h &gt; 0</code> is another shape parameter.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>quagep(f, para, paracheck=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="quagep_+3A_f">f</code></td>
<td>
<p>Nonexceedance probability (<code class="reqn">0 \le F \le 1</code>).</p>
</td></tr>
<tr><td><code id="quagep_+3A_para">para</code></td>
<td>
<p>The parameters from <code><a href="#topic+pargep">pargep</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
<tr><td><code id="quagep_+3A_paracheck">paracheck</code></td>
<td>
<p>A logical controlling whether the parameters are checked for validity. Overriding of this check might be extremely important and needed for use of the quantile function in the context of TL-moments with nonzero trimming.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If <code>f = 1</code> or is so close to unity that <code>NaN</code> in the computations of the quantile function, then the function enters into an infinite loop for which an &ldquo;order of magnitude decrement&rdquo; on the value of <br /> <code>.Machine$double.eps</code> is made until a numeric hit is encountered.  Let <code class="reqn">\eta</code> be this machine value, then <code class="reqn">F = 1 - \eta^{1/j}</code> where <code class="reqn">j</code> is the iteration in the infinite loop. Eventually <code class="reqn">F</code> becomes small enough that a finite value will result. This result is an estimate of the maximum numerical value the function can produce on the current running platform.  This feature assists in the numerical integration of the quantile function for L-moment estimation (see <code><a href="#topic+expect.max.ostat">expect.max.ostat</a></code>).  The <code><a href="#topic+expect.max.ostat">expect.max.ostat</a></code> was zealous on reporting errors related to lack of finite integration. However with the &ldquo;order magnitude decrementing,&rdquo; then the errors in <code><a href="#topic+expect.max.ostat">expect.max.ostat</a></code> become fewer and are either
</p>
<pre>
Error in integrate(fnb, lower, upper, subdivisions = 200L) : 
  extremely bad integrand behaviour
</pre>
<p>or
</p>
<pre>
Error in integrate(fnb, lower, upper, subdivisions = 200L) : 
  maximum number of subdivisions reached
</pre>
<p>and are shown here to aid in research into Generalized Exponential Power implementation.
</p>


<h3>Value</h3>

<p>Quantile value for nonexceedance probability <code class="reqn">F</code>.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Barreto-Souza, W., and Cribari-Neto, F., 2009, A generalization of the exponential-Poisson distribution: Statistics and Probability, 79, pp. 2493&ndash;2500.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cdfgep">cdfgep</a></code>, <code><a href="#topic+pdfgep">pdfgep</a></code>, <code><a href="#topic+lmomgep">lmomgep</a></code>, <code><a href="#topic+pargep">pargep</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>gep &lt;- list(para=c(2, 1.5, 3), type="gep")
quagep(0.5, gep)
## Not run: 
  pdf("gep.pdf")
  F &lt;- nonexceeds(f01=TRUE)
  K &lt;- seq(-1,2,by=.2); H &lt;- seq(-1,2,by=.2)
  K &lt;- 10^(K); H &lt;- 10^(H)
  for(i in 1:length(K)) {
    for(j in 1:length(H)) {
      gep &lt;- vec2par(c(2,K[i],H[j]), type="gep")
      message("(K,H): ",K[i]," ",H[j])
      plot(F, quagep(F, gep), lty=i, col=j, type="l", ylim=c(0,4),
           xlab="NONEXCEEDANCE PROBABILITY", ylab="X(F)")
      mtext(paste("(K,H): ",K[i]," ",H[j]))
    }
  }
  dev.off()

## End(Not run)
</code></pre>

<hr>
<h2 id='quagev'>Quantile Function of the Generalized Extreme Value Distribution</h2><span id='topic+quagev'></span>

<h3>Description</h3>

<p>This function computes the quantiles of the Generalized Extreme Value distribution given parameters (<code class="reqn">\xi</code>, <code class="reqn">\alpha</code>, and <code class="reqn">\kappa</code>) of the distribution computed by <code><a href="#topic+pargev">pargev</a></code>. The quantile function of the distribution is
</p>
<p style="text-align: center;"><code class="reqn">x(F) = \xi + \frac{\alpha}{\kappa} \left( 1-(-\log(F))^\kappa \right)\mbox{,}</code>
</p>

<p>for <code class="reqn">\kappa \ne 0</code>, and
</p>
<p style="text-align: center;"><code class="reqn">x(F) = \xi - \alpha \log(-\log(F))\mbox{,}</code>
</p>

<p>for <code class="reqn">\kappa = 0</code>,  where <code class="reqn">x(F)</code> is the quantile for nonexceedance probability <code class="reqn">F</code>, <code class="reqn">\xi</code> is a location parameter, <code class="reqn">\alpha</code> is a scale parameter, and <code class="reqn">\kappa</code> is a shape parameter. The range of <code class="reqn">x</code> is <code class="reqn">-\infty &lt; x \le \xi + \alpha/\kappa</code> if <code class="reqn">k &gt; 0</code>; <code class="reqn">\xi + \alpha/\kappa \le x &lt; \infty</code> if <code class="reqn">\kappa \le 0</code>. Note that the shape parameter <code class="reqn">\kappa</code> parameterization of the distribution herein follows that in tradition by the greater L-moment community and others use a sign reversal on <code class="reqn">\kappa</code>. (The <span class="pkg">evd</span> package is one example.)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>quagev(f, para, paracheck=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="quagev_+3A_f">f</code></td>
<td>
<p>Nonexceedance probability (<code class="reqn">0 \le F \le 1</code>).</p>
</td></tr>
<tr><td><code id="quagev_+3A_para">para</code></td>
<td>
<p>The parameters from <code><a href="#topic+pargev">pargev</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
<tr><td><code id="quagev_+3A_paracheck">paracheck</code></td>
<td>
<p>A logical controlling whether the parameters are checked for validity. Overriding of this check might be extremely important and needed for use of the quantile function in the context of TL-moments with nonzero trimming.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Quantile value for nonexceedance probability <code class="reqn">F</code>.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Hosking, J.R.M., 1990, L-moments&mdash;Analysis and estimation of distributions using linear combinations of order statistics: Journal of the Royal Statistical Society, Series B, v. 52, pp. 105&ndash;124, <a href="https://doi.org/10.1111/j.2517-6161.1990.tb01775.x">doi:10.1111/j.2517-6161.1990.tb01775.x</a>.
</p>
<p>Hosking, J.R.M., 1996, FORTRAN routines for use with the method of L-moments: Version 3, IBM Research Report RC20525, T.J. Watson Research Center, Yorktown Heights, New York.
</p>
<p>Hosking, J.R.M., and Wallis, J.R., 1997, Regional frequency analysis&mdash;An approach based on L-moments: Cambridge University Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cdfgev">cdfgev</a></code>, <code><a href="#topic+pdfgev">pdfgev</a></code>, <code><a href="#topic+lmomgev">lmomgev</a></code>, <code><a href="#topic+pargev">pargev</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>  lmr &lt;- lmoms(c(123, 34, 4, 654, 37, 78))
  quagev(0.5, pargev(lmr))
</code></pre>

<hr>
<h2 id='quagld'>Quantile Function of the Generalized Lambda Distribution</h2><span id='topic+quagld'></span>

<h3>Description</h3>

<p>This function computes the quantiles of the Generalized Lambda distribution given parameters (<code class="reqn">\xi</code>, <code class="reqn">\alpha</code>, <code class="reqn">\kappa</code>, and <code class="reqn">h</code>) of the distribution computed by <code><a href="#topic+pargld">pargld</a></code>. The quantile function is
</p>
<p style="text-align: center;"><code class="reqn">x(F) = \xi + \alpha(F^{\kappa} - (1-F)^{h}) \mbox{,}</code>
</p>

<p>where <code class="reqn">x(F)</code> is the quantile for nonexceedance probability <code class="reqn">F</code>,
<code class="reqn">\xi</code> is a location parameter, <code class="reqn">\alpha</code> is a scale
parameter, and <code class="reqn">\kappa</code>, and <code class="reqn">h</code> are shape parameters. Note that in this parameterization, the scale term is shown in the numerator and not the denominator. This is done for <span class="pkg">lmomco</span> as part of the parallel nature between distributions whose various scale parameters are shown having the same units as the location parameter.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>quagld(f, para, paracheck=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="quagld_+3A_f">f</code></td>
<td>
<p>Nonexceedance probability (<code class="reqn">0 \le F \le 1</code>).</p>
</td></tr>
<tr><td><code id="quagld_+3A_para">para</code></td>
<td>
<p>The parameters from <code><a href="#topic+pargld">pargld</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
<tr><td><code id="quagld_+3A_paracheck">paracheck</code></td>
<td>
<p>A logical controlling whether the parameters are checked for validity. Overriding of this check might be extremely important and needed for use quantile function in the context of TL-moments with nonzero trimming.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Quantile value for nonexceedance probability <code class="reqn">F</code>.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Asquith, W.H., 2007, L-moments and TL-moments of the generalized lambda distribution: Computational Statistics and Data Analysis, v. 51, no. 9, pp. 4484&ndash;4496.
</p>
<p>Karian, Z.A., and Dudewicz, E.J., 2000, Fitting statistical distributions&mdash;The generalized lambda distribution and generalized bootstrap methods:
CRC Press, Boca Raton, FL, 438 p.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cdfgld">cdfgld</a></code>, <code><a href="#topic+pargld">pargld</a></code>, <code><a href="#topic+lmomgld">lmomgld</a></code>, <code><a href="#topic+lmomTLgld">lmomTLgld</a></code>, <code><a href="#topic+pargld">pargld</a></code>, <code><a href="#topic+parTLgld">parTLgld</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
  para &lt;- vec2par(c(123,34,4,3),type="gld")
  quagld(0.5,para, paracheck=FALSE)

## End(Not run)

</code></pre>

<hr>
<h2 id='quaglo'>Quantile Function of the Generalized Logistic Distribution</h2><span id='topic+quaglo'></span>

<h3>Description</h3>

<p>This function computes the quantiles of the Generalized Logistic distribution given parameters (<code class="reqn">\xi</code>, <code class="reqn">\alpha</code>, and <code class="reqn">\kappa</code>) computed by
<code><a href="#topic+parglo">parglo</a></code>. The quantile function is
</p>
<p style="text-align: center;"><code class="reqn">x(F) = \xi + \frac{\alpha}{\kappa}\left(1-\left(\frac{1-F}{F}\right)^\kappa\right)\mbox{,}</code>
</p>

<p>for  <code class="reqn">\kappa \ne 0</code>, and
</p>
<p style="text-align: center;"><code class="reqn">x(F) = \xi - \alpha\log{\left(\frac{1-F}{F}\right)}\mbox{,}</code>
</p>

<p>for  <code class="reqn">\kappa = 0</code>, where <code class="reqn">x(F)</code> is the quantile for nonexceedance probability <code class="reqn">F</code>, <code class="reqn">\xi</code> is a location parameter, <code class="reqn">\alpha</code> is a scale parameter, and <code class="reqn">\kappa</code> is a shape parameter.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>quaglo(f, para, paracheck=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="quaglo_+3A_f">f</code></td>
<td>
<p>Nonexceedance probability (<code class="reqn">0 \le F \le 1</code>).</p>
</td></tr>
<tr><td><code id="quaglo_+3A_para">para</code></td>
<td>
<p>The parameters from <code><a href="#topic+parglo">parglo</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
<tr><td><code id="quaglo_+3A_paracheck">paracheck</code></td>
<td>
<p>A logical controlling whether the parameters are checked for validity. Overriding of this check might be extremely important and needed for use of the quantile function in the context of TL-moments with nonzero trimming.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Quantile value for for nonexceedance probability <code class="reqn">F</code>.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Hosking, J.R.M., 1990, L-moments&mdash;Analysis and estimation of
distributions using linear combinations of order statistics: Journal
of the Royal Statistical Society, Series B, v. 52, pp. 105&ndash;124.
</p>
<p>Hosking, J.R.M., 1996, FORTRAN routines for use with the method of L-moments:
Version 3, IBM Research Report RC20525, T.J. Watson Research Center,
Yorktown Heights, New York.
</p>
<p>Hosking, J.R.M., and Wallis, J.R., 1997, Regional frequency analysis&mdash;An
approach based on L-moments: Cambridge University Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cdfglo">cdfglo</a></code>, <code><a href="#topic+pdfglo">pdfglo</a></code>, <code><a href="#topic+lmomglo">lmomglo</a></code>, <code><a href="#topic+parglo">parglo</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>  lmr &lt;- lmoms(c(123,34,4,654,37,78))
  quaglo(0.5,parglo(lmr))
</code></pre>

<hr>
<h2 id='quagno'>Quantile Function of the Generalized Normal Distribution</h2><span id='topic+quagno'></span>

<h3>Description</h3>

<p>This function computes the quantiles of the Generalized Normal (Log-Normal3) distribution given parameters (<code class="reqn">\xi</code>, <code class="reqn">\alpha</code>, and <code class="reqn">\kappa</code>) computed by <code><a href="#topic+pargno">pargno</a></code>.  The quantile function has no explicit form. The parameters have the following interpretations: <code class="reqn">\xi</code> is a location parameter, <code class="reqn">\alpha</code> is a scale parameter, and <code class="reqn">\kappa</code> is a shape parameter.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>quagno(f, para, paracheck=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="quagno_+3A_f">f</code></td>
<td>
<p>Nonexceedance probability (<code class="reqn">0 \le F \le 1</code>).</p>
</td></tr>
<tr><td><code id="quagno_+3A_para">para</code></td>
<td>
<p>The parameters from <code><a href="#topic+pargno">pargno</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
<tr><td><code id="quagno_+3A_paracheck">paracheck</code></td>
<td>
<p>A logical controlling whether the parameters are checked for validity. Overriding of this check might be extremely important and needed for use of the quantile function in the context of TL-moments with nonzero trimming.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Quantile value for nonexceedance probability <code class="reqn">F</code>.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Hosking, J.R.M., 1990, L-moments&mdash;Analysis and estimation of
distributions using linear combinations of order statistics: Journal
of the Royal Statistical Society, Series B, v. 52, pp. 105&ndash;124.
</p>
<p>Hosking, J.R.M., 1996, FORTRAN routines for use with the method of L-moments:
Version 3, IBM Research Report RC20525, T.J. Watson Research Center,
Yorktown Heights, New York.
</p>
<p>Hosking, J.R.M., and Wallis, J.R., 1997, Regional frequency analysis&mdash;An
approach based on L-moments: Cambridge University Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cdfgno">cdfgno</a></code>, <code><a href="#topic+pdfgno">pdfgno</a></code>, <code><a href="#topic+lmomgno">lmomgno</a></code>, <code><a href="#topic+pargno">pargno</a></code>, <code><a href="#topic+qualn3">qualn3</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  lmr &lt;- lmoms(c(123,34,4,654,37,78))
  quagno(0.5,pargno(lmr))
</code></pre>

<hr>
<h2 id='quagov'>Quantile Function of the Govindarajulu Distribution</h2><span id='topic+quagov'></span>

<h3>Description</h3>

<p>This function computes the quantiles of the Govindarajulu distribution given parameters (<code class="reqn">\xi</code>, <code class="reqn">\alpha</code>, and <code class="reqn">\beta</code>)  computed by
<code><a href="#topic+pargov">pargov</a></code>. The quantile function is
</p>
<p style="text-align: center;"><code class="reqn">x(F) = \xi + \alpha[(\beta+1)F^\beta - \beta F^{\beta+1}] \mbox{,}</code>
</p>

<p>where <code class="reqn">x(F)</code> is the quantile for nonexceedance probability <code class="reqn">F</code>, <code class="reqn">\xi</code> is location parameter, <code class="reqn">\alpha</code> is a scale parameter, and <code class="reqn">\beta</code> is a shape parameter.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>quagov(f, para, paracheck=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="quagov_+3A_f">f</code></td>
<td>
<p>Nonexceedance probability (<code class="reqn">0 \le F \le 1</code>).</p>
</td></tr>
<tr><td><code id="quagov_+3A_para">para</code></td>
<td>
<p>The parameters from <code><a href="#topic+pargov">pargov</a></code> or similar.</p>
</td></tr>
<tr><td><code id="quagov_+3A_paracheck">paracheck</code></td>
<td>
<p>A logical controlling whether the parameters are checked for validity. Overriding of this check might be extremely important and needed for use of the quantile function in the context of TL-moments with nonzero trimming.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Quantile value for for nonexceedance probability <code class="reqn">F</code>.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Gilchrist, W.G., 2000, Statistical modelling with quantile functions: Chapman and Hall/CRC, Boca Raton.
</p>
<p>Nair, N.U., Sankaran, P.G., Balakrishnan, N., 2013, Quantile-based reliability analysis: Springer, New York.
</p>
<p>Nair, N.U., Sankaran, P.G., and Vineshkumar, B., 2012, The Govindarajulu distribution&mdash;Some Properties and applications: Communications in Statistics, Theory and Methods, 41(24), 4391&ndash;4406.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cdfgov">cdfgov</a></code>, <code><a href="#topic+pdfgov">pdfgov</a></code>, <code><a href="#topic+lmomgov">lmomgov</a></code>, <code><a href="#topic+pargov">pargov</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>lmr &lt;- lmoms(c(123,34,4,654,37,78))
quagov(0.5,pargov(lmr))
## Not run: 
lmr &lt;- lmoms(c(3, 0.05, 1.6, 1.37, 0.57, 0.36, 2.2));
par &lt;- pargov(lmr)# LMRQ said to have a linear mean residual quantile function.
# Let us have a look.
F &lt;- c(0,nonexceeds(),1)
plot(F, qlmomco(F,par), type="l", lwd=3, xlab="NONEXCEEDANCE PROBABILITY",
     ylab="LIFE TIME, RESIDUAL LIFE, OR REVERSED RESIDUAL LIFE")
lines(F, rmlmomco(F,par),  col=2, lwd=4)  # heavy red line (residual life)
lines(F, rrmlmomco(F,par), col=2, lty=2)  # dashed red (reversed res. life)
lines(F, cmlmomco(F,par),  col=4)         # conditional mean (blue)
# Notice how the conditional mean attaches to the parent at F=1, but it does not
# attached at F=0 because of the none zero origin.
cmlmomco(0,par)           # 1.307143 # expected life given birth only
lmomgov(par)$lambdas[1]   # 1.307143 # expected life of the parent distribution
rmlmomco(0, par)          # 1.288989 # residual life given birth only
qlmomco(0, par)           # 0.018153 # instantaneous life given birth
# Note: qlmomco(0,par) + rmlmomco(0,par) is the E[lifetime], but rmlmomco()
# is the RESIDUAL MEAN LIFE.

## End(Not run)
</code></pre>

<hr>
<h2 id='quagpa'>Quantile Function of the Generalized Pareto Distribution</h2><span id='topic+quagpa'></span>

<h3>Description</h3>

<p>This function computes the quantiles of the Generalized Pareto distribution given parameters (<code class="reqn">\xi</code>, <code class="reqn">\alpha</code>, and <code class="reqn">\kappa</code>) computed by <code><a href="#topic+pargpa">pargpa</a></code>. The quantile function is
</p>
<p style="text-align: center;"><code class="reqn">x(F) = \xi + \frac{\alpha}{\kappa} \left( 1-(1-F)^\kappa \right)\mbox{,}</code>
</p>

<p>for <code class="reqn">\kappa \ne 0</code>, and
</p>
<p style="text-align: center;"><code class="reqn">x(F) = \xi - \alpha\log(1-F)\mbox{,}</code>
</p>

<p>for <code class="reqn">\kappa = 0</code>, where <code class="reqn">x(F)</code> is the quantile for nonexceedance probability <code class="reqn">F</code>, <code class="reqn">\xi</code> is a location parameter, <code class="reqn">\alpha</code> is a scale parameter, and
<code class="reqn">\kappa</code> is a shape parameter. The range of <code class="reqn">x</code> is <code class="reqn">\xi \le x \le \xi + \alpha/\kappa</code> if <code class="reqn">k &gt; 0</code>; <code class="reqn">\xi \le x &lt; \infty</code> if <code class="reqn">\kappa \le 0</code>. Note that the shape parameter <code class="reqn">\kappa</code> parameterization of the distribution herein follows that in tradition by the greater L-moment community and others use a sign reversal on <code class="reqn">\kappa</code>. (The <span class="pkg">evd</span> package is one example.)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>quagpa(f, para, paracheck=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="quagpa_+3A_f">f</code></td>
<td>
<p>Nonexceedance probability (<code class="reqn">0 \le F \le 1</code>).</p>
</td></tr>
<tr><td><code id="quagpa_+3A_para">para</code></td>
<td>
<p>The parameters from <code><a href="#topic+pargpa">pargpa</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
<tr><td><code id="quagpa_+3A_paracheck">paracheck</code></td>
<td>
<p>A logical controlling whether the parameters are checked for validity. Overriding of this check might be extremely important and needed for use of the quantile function in the context of TL-moments with nonzero trimming.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Quantile value for nonexceedance probability <code class="reqn">F</code>.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Hosking, J.R.M., 1990, L-moments&mdash;Analysis and estimation of distributions using linear combinations of order statistics: Journal of the Royal Statistical Society, Series B, v. 52, pp. 105&ndash;124, <a href="https://doi.org/10.1111/j.2517-6161.1990.tb01775.x">doi:10.1111/j.2517-6161.1990.tb01775.x</a>.
</p>
<p>Hosking, J.R.M., 1996, FORTRAN routines for use with the method of L-moments: Version 3, IBM Research Report RC20525, T.J. Watson Research Center, Yorktown Heights, New York.
</p>
<p>Hosking, J.R.M., and Wallis, J.R., 1997, Regional frequency analysis&mdash;An approach based on L-moments: Cambridge University Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cdfgpa">cdfgpa</a></code>, <code><a href="#topic+pdfgpa">pdfgpa</a></code>, <code><a href="#topic+lmomgpa">lmomgpa</a></code>, <code><a href="#topic+pargpa">pargpa</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>  lmr &lt;- lmoms(c(123, 34, 4, 654, 37, 78))
  quagpa(0.5,pargpa(lmr))

## Not run: 
  # Let us compare L-moments, parameters, and 90th percentile for a simulated
  # GPA distibution of sample size 100 having the following parameters between
  # lmomco and lmom packages in R. The answers are the same.
  gpa.par &lt;- lmomco::vec2par(c(1.02787, 4.54603, 0.07234), type="gpa")
  X &lt;- lmomco::rlmomco(100, gpa.par)
   lmom::samlmu(X)
  lmomco::lmoms(X)
    lmom::pelgpa( lmom::samlmu(X))
  lmomco::pargpa(lmomco::lmoms(X))
    lmom::quagpa(0.90,   lmom::pelgpa(  lmom::samlmu(X)))
  lmomco::quagpa(0.90, lmomco::pargpa(lmomco::lmoms( X))) # 
## End(Not run)
</code></pre>

<hr>
<h2 id='quagum'>Quantile Function of the Gumbel Distribution</h2><span id='topic+quagum'></span>

<h3>Description</h3>

<p>This function computes the quantiles of the Gumbel distribution given parameters (<code class="reqn">\xi</code> and <code class="reqn">\alpha</code>)  computed by <code><a href="#topic+pargum">pargum</a></code>. The quantile function  is
</p>
<p style="text-align: center;"><code class="reqn">x(F) = \xi - \alpha\log(-\log(F)) \mbox{,}</code>
</p>

<p>where <code class="reqn">x(F)</code> is the quantile for nonexceedance probability <code class="reqn">F</code>, <code class="reqn">\xi</code> is a location parameter, and <code class="reqn">\alpha</code> is a scale parameter.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>quagum(f, para, paracheck=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="quagum_+3A_f">f</code></td>
<td>
<p>Nonexceedance probability (<code class="reqn">0 \le F \le 1</code>).</p>
</td></tr>
<tr><td><code id="quagum_+3A_para">para</code></td>
<td>
<p>The parameters from <code><a href="#topic+pargum">pargum</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
<tr><td><code id="quagum_+3A_paracheck">paracheck</code></td>
<td>
<p>A logical controlling whether the parameters are checked for validity. Overriding of this check might be extremely important and needed for use of the quantile function in the context of TL-moments with nonzero trimming.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Quantile value for nonexceedance probability <code class="reqn">F</code>.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Hosking, J.R.M., 1990, L-moments&mdash;Analysis and estimation of
distributions using linear combinations of order statistics: Journal
of the Royal Statistical Society, Series B, v. 52, p. 105&ndash;124.
</p>
<p>Hosking, J.R.M., 1996, FORTRAN routines for use with the method of L-moments:
Version 3, IBM Research Report RC20525, T.J. Watson Research Center,
Yorktown Heights, New York.
</p>
<p>Hosking, J.R.M., and Wallis, J.R., 1997, Regional frequency analysis&mdash;An
approach based on L-moments: Cambridge University Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cdfgum">cdfgum</a></code>, <code><a href="#topic+pdfgum">pdfgum</a></code>, <code><a href="#topic+lmomgum">lmomgum</a></code>, <code><a href="#topic+pargum">pargum</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>  lmr &lt;- lmoms(c(123,34,4,654,37,78))
  quagum(0.5,pargum(lmr))
</code></pre>

<hr>
<h2 id='quakap'>Quantile Function of the Kappa Distribution</h2><span id='topic+quakap'></span>

<h3>Description</h3>

<p>This function computes the quantiles of the Kappa distribution given parameters (<code class="reqn">\xi</code>, <code class="reqn">\alpha</code>, <code class="reqn">\kappa</code>, and <code class="reqn">h</code>)  computed by <code><a href="#topic+parkap">parkap</a></code>. The quantile function  is
</p>
<p style="text-align: center;"><code class="reqn">x(F) = \xi + \frac{\alpha}{\kappa}\left(1-{\left(\frac{1-F^h}{h}\right)}^\kappa\right) \mbox{,}</code>
</p>

<p>where <code class="reqn">x(F)</code> is the quantile for nonexceedance probability <code class="reqn">F</code>, <code class="reqn">\xi</code> is a location parameter, <code class="reqn">\alpha</code> is a scale parameter, <code class="reqn">\kappa</code> is a shape parameter, and <code class="reqn">h</code> is another shape parameter.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>quakap(f, para, paracheck=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="quakap_+3A_f">f</code></td>
<td>
<p>Nonexceedance probability (<code class="reqn">0 \le F \le 1</code>).</p>
</td></tr>
<tr><td><code id="quakap_+3A_para">para</code></td>
<td>
<p>The parameters from <code><a href="#topic+parkap">parkap</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
<tr><td><code id="quakap_+3A_paracheck">paracheck</code></td>
<td>
<p>A logical controlling whether the parameters are checked for validity. Overriding of this check might be extremely important and needed for use of the  quantile function in the context of TL-moments with nonzero trimming.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Quantile value for nonexceedance probability <code class="reqn">F</code>.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Hosking, J.R.M., 1994, The four-parameter kappa distribution: IBM Journal of Reserach and Development, v. 38, no. 3, pp. 251&ndash;258.
</p>
<p>Hosking, J.R.M., and Wallis, J.R., 1997, Regional frequency analysis&mdash;An approach based on L-moments: Cambridge University Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cdfkap">cdfkap</a></code>, <code><a href="#topic+pdfkap">pdfkap</a></code>, <code><a href="#topic+lmomkap">lmomkap</a></code>, <code><a href="#topic+parkap">parkap</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>  lmr &lt;- lmoms(c(123,34,4,654,37,78,21,32,231,23))
  quakap(0.5,parkap(lmr))
</code></pre>

<hr>
<h2 id='quakmu'>Quantile Function of the Kappa-Mu Distribution</h2><span id='topic+quakmu'></span>

<h3>Description</h3>

<p>This function computes the quantiles of the Kappa-Mu (<code class="reqn">\kappa:\mu</code>) distribution given parameters (<code class="reqn">\kappa</code> and <code class="reqn">\alpha</code>)  computed by <code><a href="#topic+parkmu">parkmu</a></code>. The quantile function is complex and numerical rooting of the cumulative distribution function (<code><a href="#topic+cdfkmu">cdfkmu</a></code>) is used.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>quakmu(f, para, paracheck=TRUE, getmed=FALSE, qualo=NA, quahi=NA, verbose=FALSE,
                marcumQ=TRUE, marcumQmethod=c("chisq", "delta", "integral"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="quakmu_+3A_f">f</code></td>
<td>
<p>Nonexceedance probability (<code class="reqn">0 \le F \le 1</code>).</p>
</td></tr>
<tr><td><code id="quakmu_+3A_para">para</code></td>
<td>
<p>The parameters from <code><a href="#topic+parkmu">parkmu</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
<tr><td><code id="quakmu_+3A_paracheck">paracheck</code></td>
<td>
<p>A logical controlling whether the parameters are checked for validity. Overriding of this check might be extremely important and needed for use of the quantile function in the context of TL-moments with nonzero trimming.</p>
</td></tr>
<tr><td><code id="quakmu_+3A_getmed">getmed</code></td>
<td>
<p>Same argument for <code><a href="#topic+cdfkmu">cdfkmu</a></code>. Because of nesting a <code>quakmu</code> call in <code><a href="#topic+cdfkmu">cdfkmu</a></code>, this argument and the next two are shown here are to avoid confusion in use of <code>...</code> instead. This argument should not overrided by the user.</p>
</td></tr>
<tr><td><code id="quakmu_+3A_qualo">qualo</code></td>
<td>
<p>A lower limit of the range of <code class="reqn">x</code> to look for a <code>uniroot</code> of <code class="reqn">F(x)</code>.</p>
</td></tr>
<tr><td><code id="quakmu_+3A_quahi">quahi</code></td>
<td>
<p>An upper limit of the range of <code class="reqn">x</code> to look for a <code>uniroot</code> of <code class="reqn">F(x)</code>.</p>
</td></tr>
<tr><td><code id="quakmu_+3A_verbose">verbose</code></td>
<td>
<p>Should alert messages be shown by <code>message()</code>?</p>
</td></tr>
<tr><td><code id="quakmu_+3A_marcumq">marcumQ</code></td>
<td>
<p>Same argument for <code><a href="#topic+cdfkmu">cdfkmu</a></code>, which the user can set change.</p>
</td></tr>
<tr><td><code id="quakmu_+3A_marcumqmethod">marcumQmethod</code></td>
<td>
<p>Same argument for <code><a href="#topic+cdfkmu">cdfkmu</a></code>, which the user can set change.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Quantile value for nonexceedance probability <code class="reqn">F</code>.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Yacoub, M.D., 2007, The kappa-mu distribution and the eta-mu distribution: IEEE Antennas and Propagation Magazine, v. 49, no. 1, pp. 68&ndash;81
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cdfkmu">cdfkmu</a></code>, <code><a href="#topic+pdfkmu">pdfkmu</a></code>, <code><a href="#topic+lmomkmu">lmomkmu</a></code>, <code><a href="#topic+parkmu">parkmu</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>quakmu(0.75,vec2par(c(0.9, 1.5), type="kmu"))
</code></pre>

<hr>
<h2 id='quakur'>Quantile Function of the Kumaraswamy Distribution</h2><span id='topic+quakur'></span>

<h3>Description</h3>

<p>This function computes the quantiles <code class="reqn">0 &lt; x &lt; 1</code> of the Kumaraswamy distribution given parameters (<code class="reqn">\alpha</code> and <code class="reqn">\beta</code>)  computed by <code><a href="#topic+parkur">parkur</a></code>. The quantile function  is
</p>
<p style="text-align: center;"><code class="reqn">x(F) = (1 - (1-F)^{1/\beta})^{1/\alpha} \mbox{,}</code>
</p>

<p>where <code class="reqn">x(F)</code> is the quantile for nonexceedance probability <code class="reqn">F</code>,
<code class="reqn">\alpha</code> is a shape parameter, and <code class="reqn">\beta</code> is a shape parameter.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>quakur(f, para, paracheck=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="quakur_+3A_f">f</code></td>
<td>
<p>Nonexceedance probability (<code class="reqn">0 \le F \le 1</code>).</p>
</td></tr>
<tr><td><code id="quakur_+3A_para">para</code></td>
<td>
<p>The parameters from <code><a href="#topic+parkur">parkur</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
<tr><td><code id="quakur_+3A_paracheck">paracheck</code></td>
<td>
<p>A logical controlling whether the parameters are checked for validity. Overriding of this check might be extremely important and needed for use of the quantile function in the context of TL-moments with nonzero trimming.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Quantile value for nonexceedance probability <code class="reqn">F</code>.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Jones, M.C., 2009, Kumaraswamy's distribution&mdash;A beta-type distribution with
some tractability advantages: Statistical Methodology, v. 6, pp. 70&ndash;81.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cdfkur">cdfkur</a></code>, <code><a href="#topic+pdfkur">pdfkur</a></code>, <code><a href="#topic+lmomkur">lmomkur</a></code>, <code><a href="#topic+parkur">parkur</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>  lmr &lt;- lmoms(c(0.25, 0.4, 0.6, 0.65, 0.67, 0.9))
  quakur(0.5,parkur(lmr))
</code></pre>

<hr>
<h2 id='qualap'>Quantile Function of the Laplace Distribution</h2><span id='topic+qualap'></span>

<h3>Description</h3>

<p>This function computes the quantiles of the Laplace distribution given parameters (<code class="reqn">\xi</code> and <code class="reqn">\alpha</code>)  computed by <code><a href="#topic+parlap">parlap</a></code>. The quantile function  is
</p>
<p style="text-align: center;"><code class="reqn">x(F) = \xi + \alpha\times\log(2F)\mbox{,}</code>
</p>

<p>for <code class="reqn">F \le 0.5</code>, and
</p>
<p style="text-align: center;"><code class="reqn">x(F) = \xi - \alpha\times\log(2(1-F))\mbox{,}</code>
</p>

<p>for <code class="reqn">F &gt; 0.5</code>, where <code class="reqn">x(F)</code> is the quantile for nonexceedance probability <code class="reqn">F</code>, <code class="reqn">\xi</code> is a location parameter, and <code class="reqn">\alpha</code> is a scale parameter.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>qualap(f, para, paracheck=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="qualap_+3A_f">f</code></td>
<td>
<p>Nonexceedance probability (<code class="reqn">0 \le F \le 1</code>).</p>
</td></tr>
<tr><td><code id="qualap_+3A_para">para</code></td>
<td>
<p>The parameters from <code><a href="#topic+parlap">parlap</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
<tr><td><code id="qualap_+3A_paracheck">paracheck</code></td>
<td>
<p>A logical controlling whether the parameters are checked for validity. Overriding of this check might be extremely important and needed for use of the quantile function in the context of TL-moments with nonzero trimming.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Quantile value for for nonexceedance probability <code class="reqn">F</code>.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Hosking, J.R.M., 1986, The theory of probability weighted moments: IBM Research Report RC12210, T.J. Watson Research Center, Yorktown Heights, New York.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cdflap">cdflap</a></code>, <code><a href="#topic+pdflap">pdflap</a></code>, <code><a href="#topic+lmomlap">lmomlap</a></code>, <code><a href="#topic+parlap">parlap</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>  lmr &lt;- lmoms(c(123,34,4,654,37,78))
  qualap(0.5,parlap(lmr))
</code></pre>

<hr>
<h2 id='qualmrq'>Quantile Function of the Linear Mean Residual Quantile Function Distribution
</h2><span id='topic+qualmrq'></span>

<h3>Description</h3>

<p>This function computes the quantiles of the Linear Mean Residual Quantile Function distribution given parameters (<code class="reqn">\mu</code> and <code class="reqn">\alpha</code>)  computed by <code><a href="#topic+parlmrq">parlmrq</a></code>. The quantile function  is
</p>
<p style="text-align: center;"><code class="reqn">x(F) = -(\alpha + \mu)\times\log(1-F) - 2\alpha\times F\mbox{,}</code>
</p>

<p>where <code class="reqn">x(F)</code> is the quantile for nonexceedance probability <code class="reqn">F</code>, <code class="reqn">\mu</code> is a location parameter, and <code class="reqn">\alpha</code> is a scale parameter.  The parameters must satisfy <code class="reqn">\mu &gt; 0</code> and <code class="reqn">-\mu \le \alpha &lt; \mu</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>qualmrq(f, para, paracheck=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="qualmrq_+3A_f">f</code></td>
<td>
<p>Nonexceedance probability (<code class="reqn">0 \le F \le 1</code>).</p>
</td></tr>
<tr><td><code id="qualmrq_+3A_para">para</code></td>
<td>
<p>The parameters from <code><a href="#topic+parlmrq">parlmrq</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
<tr><td><code id="qualmrq_+3A_paracheck">paracheck</code></td>
<td>
<p>A logical controlling whether the parameters are checked for validity. Overriding of this check might be extremely important and needed for use of the quantile function in the context of TL-moments with nonzero trimming.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Quantile value for nonexceedance probability <code class="reqn">F</code>.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Midhu, N.N., Sankaran, P.G., and Nair, N.U., 2013, A class of distributions with linear mean residual quantile function and it's generalizations: Statistical Methodology, v. 15, pp. 1&ndash;24.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cdflmrq">cdflmrq</a></code>, <code><a href="#topic+pdflmrq">pdflmrq</a></code>, <code><a href="#topic+lmomlmrq">lmomlmrq</a></code>, <code><a href="#topic+parlmrq">parlmrq</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>lmr &lt;- lmoms(c(3, 0.05, 1.6, 1.37, 0.57, 0.36, 2.2));
par &lt;- parlmrq(lmr)
qualmrq(0.75,par)  
## Not run: 
# The distribution is said to have a linear mean residual quantile function.
# Let us have a look.
F &lt;- nonexceeds(); par &lt;- vec2par(c(101,21), type="lmrq")
plot(F, qlmomco(F,par), type="l", lwd=3, xlab="NONEXCEEDANCE PROBABILITY",
     ylab="LIFE TIME, RESIDUAL LIFE, OR REVERSED RESIDUAL LIFE")
lines(F, rmlmomco(F,par),  col=2, lwd=4) # heavy red line (residual life)
lines(F, rrmlmomco(F,par), col=2, lty=2) # dashed red (reversed res. life)
lines(F, cmlmomco(F,par),  col=4)        # conditional mean (blue)
# Notice that the rmlmomco() is a straight line as the name of the parent
# distribution: Linear Mean Residual Quantile Distribution suggests.
# Curiously, the reversed mean residual is not linear.

## End(Not run)
</code></pre>

<hr>
<h2 id='qualn3'>Quantile Function of the 3-Parameter Log-Normal Distribution</h2><span id='topic+qualn3'></span>

<h3>Description</h3>

<p>This function computes the quantiles of the Log-Normal3 distribution given parameters (<code class="reqn">\zeta</code>, lower bounds; <code class="reqn">\mu_{\mathrm{log}}</code>, location; and <code class="reqn">\sigma_{\mathrm{log}}</code>, scale) of the distribution computed by <code><a href="#topic+parln3">parln3</a></code>.  The quantile function (same as Generalized Normal distribution, <code><a href="#topic+quagno">quagno</a></code>) is
</p>
<p style="text-align: center;"><code class="reqn">x = \Phi^{(-1)}(Y) \mbox{,} </code>
</p>

<p>where <code class="reqn">\Phi^{(-1)}</code> is the quantile function of the Standard Normal distribution and <code class="reqn">Y</code> is
</p>
<p style="text-align: center;"><code class="reqn">
Y = \frac{\log(x - \zeta) - \mu_{\mathrm{log}}}{\sigma_{\mathrm{log}}}\mbox{,}
</code>
</p>

<p>where  <code class="reqn">\zeta</code> is the lower bounds (real space) for which <code class="reqn">\zeta &lt; \lambda_1 - \lambda_2</code> (checked in <code><a href="#topic+are.parln3.valid">are.parln3.valid</a></code>), <code class="reqn">\mu_{\mathrm{log}}</code> be the mean in natural logarithmic space, and <code class="reqn">\sigma_{\mathrm{log}}</code> be the standard deviation in natural logarithm space for which <code class="reqn">\sigma_{\mathrm{log}} &gt; 0</code> (checked in <code><a href="#topic+are.parln3.valid">are.parln3.valid</a></code>) is obvious because this parameter has an analogy to the second product moment. Letting <code class="reqn">\eta = \exp(\mu_{\mathrm{log}})</code>, the parameters of the Generalized Normal are <code class="reqn">\zeta + \eta</code>, <code class="reqn">\alpha = \eta\sigma_{\mathrm{log}}</code>, and <code class="reqn">\kappa = -\sigma_{\mathrm{log}}</code>. At this point, the algorithms (<code><a href="#topic+quagno">quagno</a></code>) for the Generalized Normal provide the functional core.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>qualn3(f, para, paracheck=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="qualn3_+3A_f">f</code></td>
<td>
<p>Nonexceedance probability (<code class="reqn">0 \le F \le 1</code>).</p>
</td></tr>
<tr><td><code id="qualn3_+3A_para">para</code></td>
<td>
<p>The parameters from <code><a href="#topic+parln3">parln3</a></code> or  <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
<tr><td><code id="qualn3_+3A_paracheck">paracheck</code></td>
<td>
<p>A logical controlling whether the parameters are checked for validity. Overriding of this check might be extremely important and needed for use of the distribution quantile function in the context of TL-moments with nonzero trimming.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Quantile value for nonexceedance probability <code class="reqn">F</code>.
</p>


<h3>Note</h3>

<p>The parameterization of the Log-Normal3 results in ready support for either a known or unknown lower bounds. More information regarding the parameter fitting and control of the <code class="reqn">\zeta</code> parameter can be seen in the Details section under <code><a href="#topic+parln3">parln3</a></code>.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Asquith, W.H., 2011, Distributional analysis with L-moment statistics using the R environment for statistical computing: Createspace Independent Publishing Platform, ISBN 978&ndash;146350841&ndash;8.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cdfln3">cdfln3</a></code>, <code><a href="#topic+pdfln3">pdfln3</a></code>, <code><a href="#topic+lmomln3">lmomln3</a></code>, <code><a href="#topic+parln3">parln3</a></code>, <code><a href="#topic+quagno">quagno</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>  lmr &lt;- lmoms(c(123,34,4,654,37,78))
  qualn3(0.5,parln3(lmr))
</code></pre>

<hr>
<h2 id='quanor'>Quantile Function of the Normal Distribution</h2><span id='topic+quanor'></span>

<h3>Description</h3>

<p>This function computes the quantiles of the Normal distribution given parameters (<code class="reqn">\mu</code> and <code class="reqn">\sigma</code>)  computed by <code><a href="#topic+parnor">parnor</a></code>. The quantile function  has no explicit form (see <code>cdfnor</code> and <code>qnorm</code>). The parameters have the following interpretations: <code class="reqn">\mu</code> is the arithmetic mean and <code class="reqn">\sigma</code> is the standard deviation. The <span class="rlang"><b>R</b></span> function <code>qnorm</code> is used.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>quanor(f, para, paracheck=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="quanor_+3A_f">f</code></td>
<td>
<p>Nonexceedance probability (<code class="reqn">0 \le F \le 1</code>).</p>
</td></tr>
<tr><td><code id="quanor_+3A_para">para</code></td>
<td>
<p>The parameters from <code><a href="#topic+parnor">parnor</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
<tr><td><code id="quanor_+3A_paracheck">paracheck</code></td>
<td>
<p>A logical controlling whether the parameters are checked for validity. Overriding of this check might be extremely important and needed for use of the  quantile function in the context of TL-moments with nonzero trimming.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Quantile value for nonexceedance probability <code class="reqn">F</code>.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Hosking, J.R.M., 1990, L-moments&mdash;Analysis and estimation of distributions using linear combinations of order statistics: Journal of the Royal Statistical Society, Series B, v. 52, pp. 105&ndash;124.
</p>
<p>Hosking, J.R.M., 1996, FORTRAN routines for use with the method of L-moments: Version 3, IBM Research Report RC20525, T.J. Watson Research Center, Yorktown Heights, New York.
</p>
<p>Hosking, J.R.M., and Wallis, J.R., 1997, Regional frequency analysis&mdash;An approach based on L-moments: Cambridge University Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cdfnor">cdfnor</a></code>, <code><a href="#topic+pdfnor">pdfnor</a></code>, <code><a href="#topic+lmomnor">lmomnor</a></code>, <code><a href="#topic+parnor">parnor</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>  lmr &lt;- lmoms(c(123,34,4,654,37,78))
  quanor(0.5,parnor(lmr))
</code></pre>

<hr>
<h2 id='quapdq3'>Quantile Function of the Polynomial Density-Quantile3 Distribution</h2><span id='topic+quapdq3'></span>

<h3>Description</h3>

<p>This function computes the quantiles of the Polynomial Density-Quantile3 distribution (PDQ3) given parameters (<code class="reqn">\xi</code>, <code class="reqn">\alpha</code>, and <code class="reqn">\kappa</code>) computed by <code><a href="#topic+parpdq3">parpdq3</a></code>. The quantile function is
</p>
<p style="text-align: center;"><code class="reqn">x(F) = \xi + \alpha \biggl[\log\biggl(\frac{F}{1-F}\biggr) + \kappa \log\bigg(\frac{[1-\kappa(2F-1)]^2}{4F(1-F)}\biggr)\biggr]\mbox{,}</code>
</p>

<p>where <code class="reqn">x(F)</code> is the quantile for nonexceedance probability <code class="reqn">F</code>,
<code class="reqn">\xi</code> is a location parameter, <code class="reqn">\alpha</code> is a scale parameter,
and <code class="reqn">\kappa</code> is a shape parameter. The range of the distribution is <code class="reqn">-\infty &lt; x &lt; \infty</code>. This formulation of logistic distribution generalization is unique in the literature.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>quapdq3(f, para, paracheck=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="quapdq3_+3A_f">f</code></td>
<td>
<p>Nonexceedance probability (<code class="reqn">0 \le F \le 1</code>).</p>
</td></tr>
<tr><td><code id="quapdq3_+3A_para">para</code></td>
<td>
<p>The parameters from <code><a href="#topic+parpdq3">parpdq3</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
<tr><td><code id="quapdq3_+3A_paracheck">paracheck</code></td>
<td>
<p>A logical controlling whether the parameters are checked for validity. Overriding of this check might be extremely important and needed for use of the quantile function in the context of TL-moments with nonzero trimming.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The PDQ3 was proposed by Hosking (2007) with the core justification of maximizing entropy and that &ldquo;maximizing entropy subject to a set of constraints can be regarded as deriving a distribution that is consistent with the information specified in the constraints while making minimal assumptions about the form of the distribution other than those embodied in the constraints.&rdquo; The PDQ3 is that family constrained to the <code class="reqn">\lambda_1</code>, <code class="reqn">\lambda_2</code>, and <code class="reqn">\tau_3</code> values of the L-moments. (See also the Polynomial Density-Quantile4 function for constraint on <code class="reqn">\lambda_1</code>, <code class="reqn">\lambda_2</code>, and <code class="reqn">\tau_4</code> values of the L-moments, <code><a href="#topic+quapdq4">quapdq4</a></code>.)
</p>
<p>The PDQ3 has maximum entropy conditional on having specified values for the L-moments of <code class="reqn">\lambda_1</code>, <code class="reqn">\lambda_2</code>, and <code class="reqn">\lambda_3 = \tau_3\lambda_2</code>.  The tails of the PDQ3 are exponentially decreasing and the distribution could be useful in distributional analysis with data showing similar tail characteristics. The attainable L-kurtosis range is <code class="reqn">\tau_4 = (5\tau_3/\kappa) - 1</code>.
</p>


<h3>Value</h3>

<p>Quantile value for nonexceedance probability <code class="reqn">F</code>.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Hosking, J.R.M., 2007, Distributions with maximum entropy subject to constraints on their L-moments or expected order statistics: Journal of Statistical Planning and Inference, v. 137, no. 9, pp. 2870&ndash;2891, <a href="https://doi.org/10.1016/j.jspi.2006.10.010">doi:10.1016/j.jspi.2006.10.010</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cdfpdq3">cdfpdq3</a></code>, <code><a href="#topic+pdfpdq3">pdfpdq3</a></code>, <code><a href="#topic+lmompdq3">lmompdq3</a></code>, <code><a href="#topic+parpdq3">parpdq3</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>lmr &lt;- lmoms(c(123, 34, 4, 654, 37, 78))
quapdq3(0.5, parpdq3(lmr)) # [1] 51.22802

## Not run: 
  FF &lt;- seq(0.002475, 1 - 0.002475, by=0.001)
  para &lt;- list(para=c(0.6933, 1.5495, 0.5488), type="pdq3")
  plot(log(FF/(1-FF)), quapdq3(FF, para), type="l", col=grey(0.8), lwd=4,
       xlab="Logistic variate, log(f/(1-f))", ylab="Quantile, Q(f)")
  lines(log(FF/(1-FF)), log(qf(FF, df1=7, df2=1)), lty=2)
  legend("topleft", c("log F(7,1) distribution with same L-moments",
                      "PDQ3 distribution with same L-moments as the log F(7,1)"),
         lwd=c(1, 4), lty=c(2, 1), col=c(1, grey(0.8)), cex=0.8)
  mtext("Mimic Hosking (2007, fig. 2 [right])") # 
## End(Not run)
</code></pre>

<hr>
<h2 id='quapdq4'>Quantile Function of the Polynomial Density-Quantile4 Distribution</h2><span id='topic+quapdq4'></span>

<h3>Description</h3>

<p>This function computes the quantiles of the Polynomial Density-Quantile4
distribution (PDQ4) given parameters (<code class="reqn">\xi</code>, <code class="reqn">\alpha</code>, and
<code class="reqn">\kappa</code>) computed by <code><a href="#topic+parpdq4">parpdq4</a></code>. The quantile function
for <code class="reqn">0 &lt; \kappa &lt; 1</code> is
</p>
<p style="text-align: center;"><code class="reqn">x(F) = \xi + \alpha \biggl[\log\biggl(\frac{F}{1-F}\biggr) -
  2\kappa\;\mathrm{atanh}(\kappa[2F-1])\biggr] \mbox{\ and}</code>
</p>

<p>for <code class="reqn">-\infty &lt; \kappa &lt; 0</code> is
</p>
<p style="text-align: center;"><code class="reqn">x(F) = \xi + \alpha \biggl[\log\biggl(\frac{F}{1-F}\biggr) + 2\kappa\;\mathrm{atan}(\kappa[2F-1])\biggr] \mbox{,}</code>
</p>

<p>where <code class="reqn">x(F)</code> is the quantile for nonexceedance probability <code class="reqn">F</code>,
<code class="reqn">\xi</code> is a location parameter, <code class="reqn">\alpha</code> is a scale parameter,
and <code class="reqn">\kappa</code> is a shape parameter. The range of the distribution is <code class="reqn">-\infty &lt; x &lt; \infty</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>quapdq4(f, para, paracheck=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="quapdq4_+3A_f">f</code></td>
<td>
<p>Nonexceedance probability (<code class="reqn">0 \le F \le 1</code>).</p>
</td></tr>
<tr><td><code id="quapdq4_+3A_para">para</code></td>
<td>
<p>The parameters from <code><a href="#topic+parpdq4">parpdq4</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
<tr><td><code id="quapdq4_+3A_paracheck">paracheck</code></td>
<td>
<p>A logical controlling whether the parameters are checked for validity. Overriding of this check might be extremely important and needed for use of the quantile function in the context of TL-moments with nonzero trimming.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The PDQ4 was proposed by Hosking (2007) with the core justification of maximizing entropy and that &ldquo;maximizing entropy subject to a set of constraints can be regarded as deriving a distribution that is consistent with the information specified in the constraints while making minimal assumptions about the form of the distribution other than those embodied in the constraints.&rdquo; The PDQ4 is that family constrained to the <code class="reqn">\lambda_1</code>, <code class="reqn">\lambda_2</code>, and <code class="reqn">\tau_4</code> values of the L-moments. (See also the Polynomial Density-Quantile3 function for constraint on <code class="reqn">\lambda_1</code>, <code class="reqn">\lambda_2</code>, and <code class="reqn">\tau_3</code> values of the L-moments, <code><a href="#topic+quapdq3">quapdq3</a></code>.)
</p>
<p>The PDQ4 is a symmetrical distribution (<code class="reqn">\tau_3 = 0</code> everywhere) that has maximum entropy conditional on having specified values for the L-moments of <code class="reqn">\lambda_1</code>, <code class="reqn">\lambda_2</code>, and <code class="reqn">\lambda_4 = \tau_4\lambda_2</code> with <code class="reqn">\lambda_3 = \tau_3 = 0</code>.  The tails of the PDQ4 are exponentially decreasing and the distribution could be useful in distributional analysis with data showing similar tail characteristics. The attainable L-kurtosis range is <code class="reqn">-1/4 &lt; \tau_4 &lt; 1</code> with the sign change from negative to positive of <code class="reqn">\kappa</code> occurring at <code class="reqn">\tau_4 = 1/6</code>. Finally, PDQ4 generalizes the logistic distribution, which is the special case <code class="reqn">\kappa \rightarrow 0</code>, and contains distributions both lighter-tailed (<code class="reqn">\kappa &lt; 0</code>) and heavier-tailed (<code class="reqn">\kappa &gt; 0</code>) than the logistic.
</p>


<h3>Value</h3>

<p>Quantile value for nonexceedance probability <code class="reqn">F</code>.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Hosking, J.R.M., 2007, Distributions with maximum entropy subject to constraints on their L-moments or expected order statistics: Journal of Statistical Planning and Inference, v. 137, no. 9, pp. 2,870&ndash;2891, <a href="https://doi.org/10.1016/j.jspi.2006.10.010">doi:10.1016/j.jspi.2006.10.010</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cdfpdq4">cdfpdq4</a></code>, <code><a href="#topic+pdfpdq4">pdfpdq4</a></code>, <code><a href="#topic+lmompdq4">lmompdq4</a></code>, <code><a href="#topic+parpdq4">parpdq4</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>  lmr &lt;- lmoms(c(123, 34, 4, 654, 37, 78))
  quapdq4(0.5, parpdq4(lmr)) # [1] 155

## Not run: 
  FF &lt;- seq(0.0001, 0.9999, by=0.001)
  para &lt;- list(para=c(0, 0.4332, -0.7029), type="pdq4")
  plot( qnorm(FF, sd=1), quapdq4(FF, para), type="l", col=grey(0.8), lwd=4,
       xlab="Standard normal variate", ylab="Quantiles, Q(f)")
  lines(qnorm(FF, sd=1),   qnorm(FF, sd=1), lty=2)
  legend("topleft", c("Standard normal distribution",
                      "PDQ4 distribution with same L-moments as the standard normal"),
        lwd=c(1, 4), lty=c(2, 1), col=c(1, grey(0.8)), cex=0.8)
  mtext("Mimic Hosking (2007, fig. 3 [right])") # 
## End(Not run)

## Not run: 
  # A quick recipe to look at the shapes of quantile functions.
  FF &lt;- seq(0.001, 0.999, by=0.001)
  plot(qnorm(FF), qnorm(FF), type="n", ylim=c(-7, 7),
       xlab="Standard normal variate", ylab="PDQ4 variate")
  abline(h=0, lty=2, lwd=0.9); abline(v=0, lty=2, lwd=0.9)

  lscale   &lt;- 1 / sqrt(pi)
  tau4s    &lt;- seq(-1/4, 0.7, by=.05)
  tau4s[1] &lt;- tau4s[1] + 0.001
  for(i in 1:length(tau4s)) {
    lmr &lt;- vec2lmom(c(0, lscale, 0, tau4s[i]))
    if(! are.lmom.valid(lmr)) next
    pdq4 &lt;- parpdq4(lmr, snapt4uplimit=FALSE)
    lines(qnorm(FF), qlmomco(FF, pdq4), col=rgb(abs(tau4s[i]), 0, 1))
  }
  abline(0,1, col="darkgreen", lwd=3)
  txt &lt;- "Standard normal distribution (Tau4=0.122602)"
  txt &lt;- c(txt, paste0("PDQ4 distribution for varying Tau4 values",
                       " (color varies for accenting)"))
  legend("topleft", txt, col=c("darkgreen", rgb(0.2, 0, 1)),
                         cex=0.9, bty="n", lwd=c(3,1)) # 
## End(Not run)
</code></pre>

<hr>
<h2 id='quape3'>Quantile Function of the Pearson Type III Distribution</h2><span id='topic+quape3'></span>

<h3>Description</h3>

<p>This function computes the quantiles of the Pearson Type III distribution given parameters (<code class="reqn">\mu</code>, <code class="reqn">\sigma</code>, and <code class="reqn">\gamma</code>)  computed by <code><a href="#topic+parpe3">parpe3</a></code>. The quantile function  has no explicit form (see <code><a href="#topic+cdfpe3">cdfpe3</a></code>).
</p>
<p>For the implementation in the <span class="pkg">lmomco</span> package, the three parameters are <code class="reqn">\mu</code>, <code class="reqn">\sigma</code>, and <code class="reqn">\gamma</code> for the mean, standard deviation, and skew, respectively. Therefore, the Pearson Type III distribution is of considerable theoretical interest to this package because the parameters, which are estimated via the L-moments, are in fact the product moments, although, the values fitted by the method of L-moments will not be numerically equal to the sample product moments. Further details are provided in the Examples section under <code><a href="#topic+pmoms">pmoms</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>quape3(f, para, paracheck=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="quape3_+3A_f">f</code></td>
<td>
<p>Nonexceedance probability (<code class="reqn">0 \le F \le 1</code>).</p>
</td></tr>
<tr><td><code id="quape3_+3A_para">para</code></td>
<td>
<p>The parameters from <code><a href="#topic+parpe3">parpe3</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
<tr><td><code id="quape3_+3A_paracheck">paracheck</code></td>
<td>
<p>A logical controlling whether the parameters are checked for validity. Overriding of this check might be extremely important and needed for use of the quantile function in the context of TL-moments with nonzero trimming.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Quantile value for nonexceedance probability <code class="reqn">F</code>.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Hosking, J.R.M., 1990, L-moments&mdash;Analysis and estimation of
distributions using linear combinations of order statistics: Journal
of the Royal Statistical Society, Series B, v. 52, pp. 105&ndash;124.
</p>
<p>Hosking, J.R.M., 1996, FORTRAN routines for use with the method of L-moments:
Version 3, IBM Research Report RC20525, T.J. Watson Research Center,
Yorktown Heights, New York.
</p>
<p>Hosking, J.R.M., and Wallis, J.R., 1997, Regional frequency analysis&mdash;An
approach based on L-moments: Cambridge University Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cdfpe3">cdfpe3</a></code>, <code><a href="#topic+pdfpe3">pdfpe3</a></code>, <code><a href="#topic+lmompe3">lmompe3</a></code>, <code><a href="#topic+parpe3">parpe3</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>  lmr &lt;- lmoms(c(123,34,4,654,37,78))
  quape3(0.5,parpe3(lmr))

## Not run: 
  # Let us run an experiment on the reflection symmetric PE3.
  # Pick some parameters suitable for hydrologic applications in log.
  para_neg &lt;- vec2par(c(3,.3,-1), type="pe3") # Notice only the
  para_pos &lt;- vec2par(c(3,.3,+1), type="pe3") # sign change of skew.

  nsim &lt;- 1000 # Number of simulations
  nsam &lt;- 70   # Reasonable sample size in hydrology
  neg &lt;- pos &lt;- rep(NA, nsim)
  for(i in 1:nsim) {
    ff &lt;- runif(nsam) # Ensure that each qlmomco()--&gt;quape3() has same probs.
    neg[i] &lt;- lmoms.cov(qlmomco(ff, para_neg), nmom=3, se="lmrse")[3]
    pos[i] &lt;- lmoms.cov(qlmomco(ff, para_pos), nmom=3, se="lmrse")[3]
    # We have extracted the sample standard error of L-skew from the sample
    # This is not the same as the standard error of so computed PE3 
    # parameters, but for the illustration here, it does not matter much.
  }
  zz &lt;- data.frame(setau3=c(neg,pos), # preserve to make grouping boxplot
                   sign=c(rep("negskew", nsim), rep("posskew", nsim)))
  boxplot(zz$setau3~zz$sign, xlab="Sign of a '1' PE3 skew",
                             ylab="Standard error of L-skew")
  mtext("Standard Errors of 1,000 PE3 Parents (3,0.3,+/-1) (n=70)")
  # Notice that the distribution of the standard errors of L-skew are 
  # basically the same whether or no the sign of the skew is reversed.
  # Finally, we make a scatter plot as a check that for any given sample
  # derived from same probabilities that the standard errors are indeed,
  # that is, remain sample specific.
  plot(neg, pos, xlab="Standard error of -1 skew simulation",
                 ylab="Standard error of +1 skew simulation")
  mtext("Standard Errors of 1,000 PE3 Parents (3,0.3,+/-1) (n=70)") # 
## End(Not run)
</code></pre>

<hr>
<h2 id='quaray'>Quantile Function of the Rayleigh Distribution</h2><span id='topic+quaray'></span>

<h3>Description</h3>

<p>This function computes the quantiles of the Rayleigh distribution given parameters (<code class="reqn">\xi</code> and <code class="reqn">\alpha</code>)  computed by <code><a href="#topic+parray">parray</a></code>. The quantile function  is
</p>
<p style="text-align: center;"><code class="reqn">x(F) = \xi + \sqrt{-2\alpha^2\log(1-F)} \mbox{,}</code>
</p>

<p>where <code class="reqn">x(F)</code> is the quantile for nonexceedance probability <code class="reqn">F</code>, <code class="reqn">\xi</code> is a location parameter, and <code class="reqn">\alpha</code> is a scale parameter.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>quaray(f, para, paracheck=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="quaray_+3A_f">f</code></td>
<td>
<p>Nonexceedance probability (<code class="reqn">0 \le F \le 1</code>).</p>
</td></tr>
<tr><td><code id="quaray_+3A_para">para</code></td>
<td>
<p>The parameters from <code><a href="#topic+parray">parray</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
<tr><td><code id="quaray_+3A_paracheck">paracheck</code></td>
<td>
<p>A logical controlling whether the parameters are checked for validity. Overriding of this check might be extremely important and needed for use of the quantile function in the context of TL-moments with nonzero trimming.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Quantile value for nonexceedance probability <code class="reqn">F</code>.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Hosking, J.R.M., 1986, The theory of probability weighted moments:
Research Report RC12210, IBM Research Division, Yorkton Heights, N.Y.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cdfray">cdfray</a></code>, <code><a href="#topic+pdfray">pdfray</a></code>, <code><a href="#topic+lmomray">lmomray</a></code>, <code><a href="#topic+parray">parray</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>  lmr &lt;- lmoms(c(123,34,4,654,37,78))
  quaray(0.5,parray(lmr))
</code></pre>

<hr>
<h2 id='quarevgum'>Quantile Function of the Reverse Gumbel Distribution</h2><span id='topic+quarevgum'></span>

<h3>Description</h3>

<p>This function computes the quantiles of the Reverse Gumbel distribution given parameters (<code class="reqn">\xi</code> and <code class="reqn">\alpha</code>) computed by <code><a href="#topic+parrevgum">parrevgum</a></code>. The quantile function  is
</p>
<p style="text-align: center;"><code class="reqn">x(F) = \xi + \alpha\log(-\log(1-F)) \mbox{,}</code>
</p>

<p>where <code class="reqn">x(F)</code> is the quantile for nonexceedance probability <code class="reqn">F</code>, <code class="reqn">\xi</code> is a location parameter, and <code class="reqn">\alpha</code> is a scale parameter.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>quarevgum(f, para, paracheck=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="quarevgum_+3A_f">f</code></td>
<td>
<p>Nonexceedance probability (<code class="reqn">0 \le F \le 1</code>).</p>
</td></tr>
<tr><td><code id="quarevgum_+3A_para">para</code></td>
<td>
<p>The parameters from <code><a href="#topic+parrevgum">parrevgum</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
<tr><td><code id="quarevgum_+3A_paracheck">paracheck</code></td>
<td>
<p>A logical controlling whether the parameters are checked for validity. Overriding of this check might be extremely important and needed for use of the quantile function in the context of TL-moments with nonzero trimming.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Quantile value for nonexceedance probability <code class="reqn">F</code>.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Hosking, J.R.M., 1995, The use of L-moments in the analysis of censored data,
in Recent Advances in Life-Testing and Reliability, edited by N. Balakrishnan,
chapter 29, CRC Press, Boca Raton, Fla., pp. 546&ndash;560.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cdfrevgum">cdfrevgum</a></code>, <code><a href="#topic+pdfrevgum">pdfrevgum</a></code>, <code><a href="#topic+lmomrevgum">lmomrevgum</a></code>, <code><a href="#topic+parrevgum">parrevgum</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'># See p. 553 of Hosking (1995)
# Data listed in Hosking (1995, table 29.3, p. 553)
D &lt;- c(-2.982, -2.849, -2.546, -2.350, -1.983, -1.492, -1.443,
       -1.394, -1.386, -1.269, -1.195, -1.174, -0.854, -0.620,
       -0.576, -0.548, -0.247, -0.195, -0.056, -0.013,  0.006,
        0.033,  0.037,  0.046,  0.084,  0.221,  0.245,  0.296)
D &lt;- c(D,rep(.2960001,40-28)) # 28 values, but Hosking mentions
                              # 40 values in total
z &lt;-  pwmRC(D,threshold=.2960001)
str(z)
# Hosking reports B-type L-moments for this sample are
# lamB1 = -.516 and lamB2 = 0.523
btypelmoms &lt;- pwm2lmom(z$Bbetas)
# My version of R reports lamB1 = -0.5162 and lamB2 = 0.5218
str(btypelmoms)
rg.pars &lt;- parrevgum(btypelmoms,z$zeta)
str(rg.pars)
# Hosking reports xi = 0.1636 and alpha = 0.9252 for the sample
# My version of R reports xi = 0.1635 and alpha = 0.9254
F  &lt;- nonexceeds()
PP &lt;- pp(D) # plotting positions of the data
plot(PP,sort(D),ylim=range(quarevgum(F,rg.pars)))
lines(F,quarevgum(F,rg.pars))
# In the plot notice how the data flat lines at the censoring level,
# but the distribution continues on.  Neat.
</code></pre>

<hr>
<h2 id='quarice'>Quantile Function of the Rice Distribution</h2><span id='topic+quarice'></span>

<h3>Description</h3>

<p>This function computes the quantiles of the Rice distribution given parameters (<code class="reqn">\nu</code> and <code class="reqn">\alpha</code>)  computed by <code><a href="#topic+parrice">parrice</a></code>. The quantile function  is complex and numerical rooting of the cumulative distribution function <code><a href="#topic+cdfrice">cdfrice</a></code> is used.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>quarice(f, para, xmax=NULL, paracheck=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="quarice_+3A_f">f</code></td>
<td>
<p>Nonexceedance probability (<code class="reqn">0 \le F \le 1</code>).</p>
</td></tr>
<tr><td><code id="quarice_+3A_para">para</code></td>
<td>
<p>The parameters from <code><a href="#topic+parrice">parrice</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
<tr><td><code id="quarice_+3A_xmax">xmax</code></td>
<td>
<p>The maximum x value used for integeration.</p>
</td></tr>
<tr><td><code id="quarice_+3A_paracheck">paracheck</code></td>
<td>
<p>A logical controlling whether the parameters are checked for validity. Overriding of this check might be extremely important and needed for use of the quantile function in the context of TL-moments with nonzero trimming.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Quantile value for nonexceedance probability <code class="reqn">F</code>.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Asquith, W.H., 2011, Distributional analysis with L-moment statistics using the R environment for statistical computing: Createspace Independent Publishing Platform, ISBN 978&ndash;146350841&ndash;8.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cdfrice">cdfrice</a></code>, <code><a href="#topic+pdfrice">pdfrice</a></code>, <code><a href="#topic+lmomrice">lmomrice</a></code>, <code><a href="#topic+parrice">parrice</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>lmr &lt;- vec2lmom(c(125,0.20), lscale=FALSE)
quarice(0.75,parrice(lmr))
# The quantile function of the Rice as implemented in lmomco
# is slow because of rooting the CDF, which is created by
# integration of the PDF. Rician random variates are easily created.
# Thus, in speed applications the rlmomco() with a Rice parameter
# object could be bypassed by the following function, rrice().
## Not run: 
"rrice" = function(n, nu, alpha) { # from the VGAM package
    theta = 1 # any number
    X = rnorm(n, mean=nu * cos(theta), sd=alpha)
    Y = rnorm(n, mean=nu * sin(theta), sd=alpha)
    return(sqrt(X^2 + Y^2))
}
n &lt;- 5000; # suggest making it about 10,000
nu &lt;- 100; alpha &lt;- 10
set.seed(501); lmoms(rrice(n, nu, alpha))
set.seed(501); lmoms(rlmomco(n, vec2par(c(nu,alpha), type='rice')))
# There are slight numerical differences between the two?

## End(Not run)
</code></pre>

<hr>
<h2 id='quasla'>Quantile Function of the Slash Distribution</h2><span id='topic+quasla'></span>

<h3>Description</h3>

<p>This function computes the quantiles of the Slash distribution given
parameters (<code class="reqn">\xi</code> and <code class="reqn">\alpha</code>)  provided by
<code><a href="#topic+parsla">parsla</a></code>. The quantile function  <code class="reqn">x(F; \xi, \alpha)</code> for nonexceedance probability <code class="reqn">F</code> and where <code class="reqn">\xi</code> is a location parameter and <code class="reqn">\alpha</code> is a scale parameter is complex and requires numerical optimization of the cumulative distribution function (<code><a href="#topic+cdfsla">cdfsla</a></code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>quasla(f, para, paracheck=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="quasla_+3A_f">f</code></td>
<td>
<p>Nonexceedance probability (<code class="reqn">0 \le F \le 1</code>).</p>
</td></tr>
<tr><td><code id="quasla_+3A_para">para</code></td>
<td>
<p>The parameters from <code><a href="#topic+parsla">parsla</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
<tr><td><code id="quasla_+3A_paracheck">paracheck</code></td>
<td>
<p>A logical controlling whether the parameters are checked for validity. Overriding of this check might be extremely important and needed for use of the quantile function in the context of TL-moments with nonzero trimming.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Quantile value for for nonexceedance probability <code class="reqn">F</code>.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Rogers, W.H., and Tukey, J.W., 1972, Understanding some long-tailed symmetrical distributions: Statistica Neerlandica, v. 26, no. 3, pp. 211&ndash;226.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cdfsla">cdfsla</a></code>, <code><a href="#topic+pdfsla">pdfsla</a></code>, <code><a href="#topic+lmomsla">lmomsla</a></code>, <code><a href="#topic+parsla">parsla</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>para &lt;- c(12,1.2)
quasla(0.55,vec2par(para,type='sla'))
</code></pre>

<hr>
<h2 id='quasmd'>Quantile Function of the Singh&ndash;Maddala Distribution</h2><span id='topic+quasmd'></span>

<h3>Description</h3>

<p>This function computes the quantiles of the Singh&ndash;Maddala (Burr Type XII) distribution given parameters (<code class="reqn">\xi</code>, <code class="reqn">a</code>, <code class="reqn">b</code>, and <code class="reqn">q</code>) computed by <code><a href="#topic+parsmd">parsmd</a></code>. The quantile function  is
</p>
<p style="text-align: center;"><code class="reqn">x(F) = \xi + a\biggl((1-F)^{-1/q} - 1 \biggr)^{1/b}\mbox{,}</code>
</p>

<p>where <code class="reqn">x(F)</code> with <code class="reqn">0 \le x \le \infty</code> is the quantile for nonexceedance probability <code class="reqn">F</code>, <code class="reqn">\xi</code> is a location parameter, <code class="reqn">a</code> is a scale parameter (<code class="reqn">a &gt; 0</code>), <code class="reqn">b</code> is a shape parameter (<code class="reqn">b &gt; 0</code>), and <code class="reqn">q</code> is another shape parameter (<code class="reqn">q &gt; 0</code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>quasmd(f, para, paracheck=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="quasmd_+3A_f">f</code></td>
<td>
<p>Nonexceedance probability (<code class="reqn">0 \le F \le 1</code>).</p>
</td></tr>
<tr><td><code id="quasmd_+3A_para">para</code></td>
<td>
<p>The parameters from <code><a href="#topic+parsmd">parsmd</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
<tr><td><code id="quasmd_+3A_paracheck">paracheck</code></td>
<td>
<p>A logical controlling whether the parameters are checked for validity. Overriding of this check might be extremely important and needed for use of the quantile function in the context of TL-moments with nonzero trimming.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Quantile value for nonexceedance probability <code class="reqn">F</code>.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Kumar, D., 2017, The Singh&ndash;Maddala distribution&mdash;Properties and estimation: International Journal of System Assurance Engineering and Management, v. 8, no. S2, 15 p., <a href="https://doi.org/10.1007/s13198-017-0600-1">doi:10.1007/s13198-017-0600-1</a>.
</p>
<p>Shahzad, M.N., and Zahid, A., 2013, Parameter estimation of Singh Maddala distribution by moments: International Journal of Advanced Statistics and Probability, v. 1, no. 3, pp. 121&ndash;131, <a href="https://doi.org/10.14419/ijasp.v1i3.1206">doi:10.14419/ijasp.v1i3.1206</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cdfsmd">cdfsmd</a></code>, <code><a href="#topic+pdfsmd">pdfsmd</a></code>, <code><a href="#topic+lmomsmd">lmomsmd</a></code>, <code><a href="#topic+parsmd">parsmd</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>quasmd(0.99, parsmd(vec2lmom(c(155, 118.6, 0.6, 0.45)))) # 1547.337 99th percentile
</code></pre>

<hr>
<h2 id='quast3'>Quantile Function of the 3-Parameter Student t Distribution</h2><span id='topic+quast3'></span>

<h3>Description</h3>

<p>This function computes the quantiles of the 3-parameter Student t distribution given parameters (<code class="reqn">\xi</code>, <code class="reqn">\alpha</code>, <code class="reqn">\nu</code>) computed by <code><a href="#topic+parst3">parst3</a></code>. There is no explicit solution for the quantile function for nonexceedance probability <code>F</code> but built-in <span class="rlang"><b>R</b></span> functions can be used. The implementation is <code>U</code> = <code class="reqn">\xi</code> and <code>A</code> = <code class="reqn">\alpha</code> for <code class="reqn">1.001 \le \nu \le 10^5.5</code>, one can use <code>U + A*qt(F, N)</code> where <code>qt</code> is the 1-parameter Student t quantile function. The numerically accessible range of implementation here and consistency to the <code class="reqn">\tau_4</code> and <code class="reqn">\tau_6</code> is <code class="reqn">10.001 \le \nu \le 10^5.5</code>. The limits for <code class="reqn">\nu</code> stem from study of ability for theoretical integration of the quantile function to produce viable <code class="reqn">\tau_4</code> and <code class="reqn">\tau_6</code> (see <code>inst/doc/t4t6/studyST3.R</code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>quast3(f, para, paracheck=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="quast3_+3A_f">f</code></td>
<td>
<p>Nonexceedance probability (<code class="reqn">0 \le F \le 1</code>).</p>
</td></tr>
<tr><td><code id="quast3_+3A_para">para</code></td>
<td>
<p>The parameters from <code><a href="#topic+parst3">parst3</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
<tr><td><code id="quast3_+3A_paracheck">paracheck</code></td>
<td>
<p>A logical on whether the parameters are checked for validity. Overriding of this check might be extremely important and needed for use of the quantile function in the context of TL-moments with nonzero trimming.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Quantile value for nonexceedance probability <code class="reqn">F</code>.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Asquith, W.H., 2011, Distributional analysis with L-moment statistics using the R environment for statistical computing: Createspace Independent Publishing Platform, ISBN 978&ndash;146350841&ndash;8.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cdfst3">cdfst3</a></code>, <code><a href="#topic+pdfst3">pdfst3</a></code>, <code><a href="#topic+lmomst3">lmomst3</a></code>, <code><a href="#topic+parst3">parst3</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>lmr &lt;- lmoms(c(123, 34, 4, 654, 37, 78))
quast3(0.75, parst3(lmr))
</code></pre>

<hr>
<h2 id='quatexp'>Quantile Function of the Truncated Exponential Distribution</h2><span id='topic+quatexp'></span>

<h3>Description</h3>

<p>This function computes the quantiles of the Truncated Exponential distribution given parameters (<code class="reqn">\psi</code> and <code class="reqn">\alpha</code>)  computed by <code><a href="#topic+partexp">partexp</a></code>. The parameter <code class="reqn">\psi</code> is the right truncation, and <code class="reqn">\alpha</code> is a scale parameter. The quantile function, letting <code class="reqn">\beta = 1/\alpha</code> to match nomenclature of Vogel and others (2008), is
</p>
<p style="text-align: center;"><code class="reqn">x(F) = -\frac{1}{\beta}\log(1-F[1-\mathrm{exp}(-\beta\psi)])\mbox{,}</code>
</p>

<p>where <code class="reqn">x(F)</code> is the quantile <code class="reqn">0 \le x \le \psi</code> for nonexceedance probability <code class="reqn">F</code> and <code class="reqn">\psi &gt; 0</code> and <code class="reqn">\alpha &gt; 0</code>. This distribution represents a nonstationary Poisson process.
</p>
<p>The distribution is restricted to a narrow range of L-CV (<code class="reqn">\tau_2 = \lambda_2/\lambda_1</code>). If <code class="reqn">\tau_2 = 1/3</code>, the process represented is a stationary Poisson for which the quantile function is simply the uniform distribution and <code class="reqn">x(F) = \psi\,F</code>. If <code class="reqn">\tau_2 = 1/2</code>, then the distribution is represented as the usual exponential distribution with a location parameter of zero and a scale parameter <code class="reqn">1/\beta</code>. Both of these limiting conditions are supported.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>quatexp(f, para, paracheck=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="quatexp_+3A_f">f</code></td>
<td>
<p>Nonexceedance probability (<code class="reqn">0 \le F \le 1</code>).</p>
</td></tr>
<tr><td><code id="quatexp_+3A_para">para</code></td>
<td>
<p>The parameters from <code><a href="#topic+partexp">partexp</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
<tr><td><code id="quatexp_+3A_paracheck">paracheck</code></td>
<td>
<p>A logical controlling whether the parameters are checked for validity. Overriding of this check might be extremely important and needed for use of the quantile function in the context of TL-moments with nonzero trimming.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Quantile value for nonexceedance probability <code class="reqn">F</code>.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Vogel, R.M., Hosking, J.R.M., Elphick, C.S., Roberts, D.L., and Reed, J.M., 2008, Goodness of fit of probability distributions for sightings as species approach extinction: Bulletin of Mathematical Biology, DOI 10.1007/s11538-008-9377-3, 19 p.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cdftexp">cdftexp</a></code>, <code><a href="#topic+pdftexp">pdftexp</a></code>, <code><a href="#topic+lmomtexp">lmomtexp</a></code>, <code><a href="#topic+partexp">partexp</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>lmr &lt;- vec2lmom(c(40,0.38), lscale=FALSE)
quatexp(0.5,partexp(lmr))
## Not run: 
F &lt;- seq(0,1,by=0.001)
A &lt;- partexp(vec2lmom(c(100, 1/2), lscale=FALSE))
plot(qnorm(F), quatexp(F, A), pch=16, type='l')
by &lt;- 0.01; lcvs &lt;- c(1/3, seq(1/3+by, 1/2-by, by=by), 1/2)
reds &lt;- (lcvs - 1/3)/max(lcvs - 1/3)
for(lcv in lcvs) {
    A &lt;- partexp(vec2lmom(c(100, lcv), lscale=FALSE))
    lines(qnorm(F), quatexp(F, A), col=rgb(reds[lcvs == lcv],0,0))
}

## End(Not run)
</code></pre>

<hr>
<h2 id='quatri'>Quantile Function of the Asymmetric Triangular Distribution</h2><span id='topic+quatri'></span>

<h3>Description</h3>

<p>This function computes the quantiles of the Asymmetric Triangular distribution given parameters (<code class="reqn">\nu</code>, <code class="reqn">\omega</code>, and <code class="reqn">\psi</code>) of the distribution computed by <code><a href="#topic+partri">partri</a></code>. The quantile function of the distribution is
</p>
<p style="text-align: center;"><code class="reqn">x(F) = \nu + \sqrt{(\psi - \nu)(\omega - \nu)F}\mbox{,}</code>
</p>

<p>for <code class="reqn">F &lt; P</code>,
</p>
<p style="text-align: center;"><code class="reqn">x(F) = \psi - \sqrt{(\psi - \nu)(\psi - \omega)(1-F)}\mbox{,}</code>
</p>

<p>for <code class="reqn">F &gt; P</code>, and
</p>
<p style="text-align: center;"><code class="reqn">x(F) = \omega\mbox{,}</code>
</p>

<p>for <code class="reqn">F = P</code>
where <code class="reqn">x(F)</code> is the quantile for nonexceedance probability <code class="reqn">F</code>, <code class="reqn">\nu</code> is the minimum, <code class="reqn">\psi</code> is the maximum, and <code class="reqn">\omega</code> is the mode of the distribution and
</p>
<p style="text-align: center;"><code class="reqn">P = \frac{(\omega - \nu)}{(\psi - \nu)}\mbox{.}</code>
</p>



<h3>Usage</h3>

<pre><code class='language-R'>quatri(f, para, paracheck=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="quatri_+3A_f">f</code></td>
<td>
<p>Nonexceedance probability (<code class="reqn">0 \le F \le 1</code>).</p>
</td></tr>
<tr><td><code id="quatri_+3A_para">para</code></td>
<td>
<p>The parameters from <code><a href="#topic+partri">partri</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
<tr><td><code id="quatri_+3A_paracheck">paracheck</code></td>
<td>
<p>A logical controlling whether the parameters are checked for validity. Overriding of this check might be extremely important and needed for use of the quantile function in the context of TL-moments with nonzero trimming.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Quantile value for nonexceedance probability <code class="reqn">F</code>.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>See Also</h3>

<p><code><a href="#topic+cdftri">cdftri</a></code>, <code><a href="#topic+pdftri">pdftri</a></code>, <code><a href="#topic+lmomtri">lmomtri</a></code>, <code><a href="#topic+partri">partri</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>  lmr &lt;- lmoms(c(46, 70, 59, 36, 71, 48, 46, 63, 35, 52))
  quatri(0.5,partri(lmr))
</code></pre>

<hr>
<h2 id='quawak'>Quantile Function of the Wakeby Distribution</h2><span id='topic+quawak'></span>

<h3>Description</h3>

<p>This function computes the quantiles of the Wakeby distribution given
parameters (<code class="reqn">\xi</code>, <code class="reqn">\alpha</code>, <code class="reqn">\beta</code>, <code class="reqn">\gamma</code>, and <code class="reqn">\delta</code>) computed by <code><a href="#topic+parwak">parwak</a></code>. The quantile function  is
</p>
<p style="text-align: center;"><code class="reqn">x(F) = \xi+\frac{\alpha}{\beta}(1-(1-F)^\beta)-
                 \frac{\gamma}{\delta}(1-(1-F))^{-\delta} \mbox{,}</code>
</p>

<p>where <code class="reqn">x(F)</code> is the quantile for nonexceedance probability <code class="reqn">F</code>, <code class="reqn">\xi</code> is a location parameter, <code class="reqn">\alpha</code> and <code class="reqn">\beta</code> are scale parameters, and <code class="reqn">\gamma</code> and <code class="reqn">\delta</code> are shape parameters. The five returned parameters from <code>parwak</code> in order are <code class="reqn">\xi</code>, <code class="reqn">\alpha</code>, <code class="reqn">\beta</code>, <code class="reqn">\gamma</code>, and <code class="reqn">\delta</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>quawak(f, wakpara, paracheck=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="quawak_+3A_f">f</code></td>
<td>
<p>Nonexceedance probability (<code class="reqn">0 \le F \le 1</code>).</p>
</td></tr>
<tr><td><code id="quawak_+3A_wakpara">wakpara</code></td>
<td>
<p>The parameters from <code><a href="#topic+parwak">parwak</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
<tr><td><code id="quawak_+3A_paracheck">paracheck</code></td>
<td>
<p>A logical controlling whether the parameters are checked for validity. Overriding of this check might be extremely important and needed for use of the quantile function in the context of TL-moments with nonzero trimming.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Quantile value for nonexceedance probability <code class="reqn">F</code>.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Hosking, J.R.M., 1990, L-moments&mdash;Analysis and estimation of
distributions using linear combinations of order statistics: Journal
of the Royal Statistical Society, Series B, v. 52, pp. 105&ndash;124.
</p>
<p>Hosking, J.R.M., 1996, FORTRAN routines for use with the method of L-moments:
Version 3, IBM Research Report RC20525, T.J. Watson Research Center,
Yorktown Heights, New York.
</p>
<p>Hosking, J.R.M., and Wallis, J.R., 1997, Regional frequency analysis&mdash;An
approach based on L-moments: Cambridge University Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cdfwak">cdfwak</a></code>, <code><a href="#topic+pdfwak">pdfwak</a></code>, <code><a href="#topic+lmomwak">lmomwak</a></code>, <code><a href="#topic+parwak">parwak</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>  lmr &lt;- lmoms(c(123,34,4,654,37,78))
  quawak(0.5,parwak(lmr))
</code></pre>

<hr>
<h2 id='quawei'>Quantile Function of the Weibull Distribution</h2><span id='topic+quawei'></span>

<h3>Description</h3>

<p>This function computes the quantiles of the Weibull distribution given parameters (<code class="reqn">\zeta</code>, <code class="reqn">\beta</code>, and <code class="reqn">\delta</code>) computed by <code><a href="#topic+parwei">parwei</a></code>. The quantile function  is
</p>
<p style="text-align: center;"><code class="reqn">x(F) = \beta[- \log(1-F)]^{1/\delta} - \zeta \mbox{,}</code>
</p>

<p>where <code class="reqn">x(F)</code> is the quantile for nonexceedance probability <code class="reqn">F</code>,
<code class="reqn">\zeta</code> is a location parameter, <code class="reqn">\beta</code> is a scale parameter, and <code class="reqn">\delta</code> is a shape parameter.
</p>
<p>The Weibull distribution is a reverse Generalized Extreme Value distribution.  As result, the Generalized Extreme Value algorithms are used for implementation of the Weibull in <span class="pkg">lmomco</span>. The relations between the Generalized Extreme Value distribution parameters (<code class="reqn">\xi</code>, <code class="reqn">\alpha</code>, <code class="reqn">\kappa</code>) are
<code class="reqn">\kappa</code>) is <code class="reqn">\kappa = 1/\delta</code>, 
<code class="reqn">\alpha = \beta/\delta</code>, and
<code class="reqn">\xi = \zeta - \beta</code>.
These relations are taken from Hosking and Wallis (1997).
</p>
<p>In <span class="rlang"><b>R</b></span>, the quantile function of the Weibull distribution is <code>qweibull</code>. Given a Weibull parameter object <code>p</code>, the <span class="rlang"><b>R</b></span> syntax is <code>qweibull(f, p$para[3], scale=p$para[2]) - p$para[1]</code>. For the current implementation for this package, the reversed Generalized Extreme Value distribution <code><a href="#topic+quagev">quagev</a></code> is used and the implementation is <code>-quagev((1-f),para)</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>quawei(f, para, paracheck=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="quawei_+3A_f">f</code></td>
<td>
<p>Nonexceedance probability (<code class="reqn">0 \le F \le 1</code>).</p>
</td></tr>
<tr><td><code id="quawei_+3A_para">para</code></td>
<td>
<p>The parameters from <code><a href="#topic+parwei">parwei</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
<tr><td><code id="quawei_+3A_paracheck">paracheck</code></td>
<td>
<p>A logical controlling whether the parameters are checked for validity. Overriding of this check might be extremely important and needed for use of the quantile function in the context of TL-moments with nonzero trimming.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Quantile value for nonexceedance probability <code class="reqn">F</code>.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Hosking, J.R.M., and Wallis, J.R., 1997, Regional frequency analysis&mdash;An
approach based on L-moments: Cambridge University Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cdfwei">cdfwei</a></code>, <code><a href="#topic+pdfwei">pdfwei</a></code>, <code><a href="#topic+lmomwei">lmomwei</a></code>, <code><a href="#topic+parwei">parwei</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>  # Evaluate Weibull deployed here and within R (qweibull)
  lmr &lt;- lmoms(c(123,34,4,654,37,78))
  WEI &lt;- parwei(lmr)
  Q1  &lt;- quawei(0.5,WEI)
  Q2  &lt;- qweibull(0.5,shape=WEI$para[3],scale=WEI$para[2])-WEI$para[1]
  if(Q1 == Q2) EQUAL &lt;- TRUE

  # The Weibull is a reversed generalized extreme value
  Q &lt;- sort(rlmomco(34,WEI)) # generate Weibull sample
  lm1 &lt;- lmoms(Q)    # regular L-moments
  lm2 &lt;- lmoms(-Q)   # L-moment of negated (reversed) data
  WEI &lt;- parwei(lm1) # parameters of Weibull
  GEV &lt;- pargev(lm2) # parameters of GEV
  F &lt;- nonexceeds()  # Get a vector of nonexceedance probs
  plot(pp(Q),Q)
  lines(F,quawei(F,WEI))
  lines(F,-quagev(1-F,GEV),col=2) # line over laps previous
</code></pre>

<hr>
<h2 id='ralmomco'>Alpha-Percentile Residual Quantile Function of the Distributions</h2><span id='topic+ralmomco'></span>

<h3>Description</h3>

<p>This function computes the <code class="reqn">\alpha</code>-Percentile Residual Quantile Function for quantile function <code class="reqn">x(F)</code> (<code><a href="#topic+par2qua">par2qua</a></code>, <code><a href="#topic+qlmomco">qlmomco</a></code>). The function is defined by Nair and Vineshkumar (2011, p. 85) and Nair et al. (2013, p. 56) as
</p>
<p style="text-align: center;"><code class="reqn">P_\alpha(u) = x(1 - [1-\alpha][1-u]) - x(u)\mbox{,}</code>
</p>

<p>where <code class="reqn">P_\alpha(u)</code> is the  <code class="reqn">\alpha</code>-percentile residual quantile for nonexceedance probability <code class="reqn">u</code> and percentile <code class="reqn">\alpha</code> and <code class="reqn">x(u)</code> is a constant for <code class="reqn">x(F = u)</code>. The reversed <code class="reqn">\alpha</code>-percentile residual quantile is available under <code><a href="#topic+rralmomco">rralmomco</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ralmomco(f, para, alpha=0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ralmomco_+3A_f">f</code></td>
<td>
<p>Nonexceedance probability (<code class="reqn">0 \le F \le 1</code>).</p>
</td></tr>
<tr><td><code id="ralmomco_+3A_para">para</code></td>
<td>
<p>The parameters from <code><a href="#topic+lmom2par">lmom2par</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
<tr><td><code id="ralmomco_+3A_alpha">alpha</code></td>
<td>
<p>The <code class="reqn">\alpha</code> percentile, which is divided by <code class="reqn">100</code> inside the function ahead of calling the quantile function of the distribution.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code class="reqn">\alpha</code>-percentile residual quantile value for <code class="reqn">F</code>.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Nair, N.U., and Vineshkumar, B., 2011, Reversed percentile residual life and related concepts: Journal of the Korean Statistical Society, v. 40, no. 1, pp. 85&ndash;92.
</p>
<p>Nair, N.U., Sankaran, P.G., and Balakrishnan, N., 2013, Quantile-based reliability analysis: Springer, New York.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+qlmomco">qlmomco</a></code>, <code><a href="#topic+rmlmomco">rmlmomco</a></code>, <code><a href="#topic+rralmomco">rralmomco</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># It is easiest to think about residual life as starting at the origin, units in days.
A &lt;- vec2par(c(0.0, 2649, 2.11), type="gov") # so set lower bounds = 0.0
maximum.lifetime &lt;- quagov(1,A) # 2649 days
ralmomco(0,A,alpha=0)   #    0 days
ralmomco(0,A,alpha=100) # 2649 days
ralmomco(1,A,alpha=0)   #    0 days (death certain)
ralmomco(1,A,alpha=100) #    0 days (death certain)
## Not run: 
F &lt;- nonexceeds(f01=TRUE)
plot(F, qlmomco(F,A), type="l",
     xlab="NONEXCEEDANCE PROBABILITY", ylab="LIFETIME, IN DAYS")
lines(F, rmlmomco(F, A), col=4, lwd=4) # thick blue, residual mean life
lines(F, ralmomco(F, A, alpha=50), col=2) # solid red, median residual life
lines(F, ralmomco(F, A, alpha=10), col=2, lty=2) # lower dashed line,
                                              # the 10th percentile of residual life
lines(F, ralmomco(F, A, alpha=90), col=2, lty=2) # upper dashed line,
                                              # 10th percentile of residual life
## End(Not run)
</code></pre>

<hr>
<h2 id='reslife.lmoms'>L-moments of Residual Life</h2><span id='topic+reslife.lmoms'></span>

<h3>Description</h3>

<p>This function computes the L-moments of residual life for a quantile function <code class="reqn">x(F)</code> for an exceedance threshold in probabiliy of <code class="reqn">u</code>. The L-moments of residual life are thoroughly described by Nair et al. (2013, p. 202).  These L-moments are define as
</p>
<p style="text-align: center;"><code class="reqn">\lambda(u)_r = \sum_{k=0}^{r-1} (-1)^k {r-1 \choose k}^2 \int_u^1 \left(\frac{p-u}{1-u}\right)^{r-k-1} \left(\frac{1-p}{1-u}\right)^k \frac{x(p)}{1-u}\,\mathrm{d}p \mbox{,}</code>
</p>

<p>where <code class="reqn">\lambda(u)_r</code> is the <code class="reqn">r</code>th L-moment at residual life probability <code class="reqn">u</code>.  The L-moment ratios <code class="reqn">\tau(u)_r</code> have the usual definitions. The implementation here exclusively uses the quantile function of the distribution. If <code class="reqn">u=0</code>, then the usual L-moments of the quantile function are returned because the integration domain is the entire potential lifetime range.  If <code class="reqn">u=1</code>, then <code class="reqn">\lambda(1)_1 = x(1)</code> is returned, which is the maximum lifetime of the distribution (the value for the upper support of the distribution), and the remaining <code class="reqn">\lambda(1)_r</code> for <code class="reqn">r \ge 2</code> are set to <code>NA</code>. Lastly, the notation <code class="reqn">(u)</code> is neither super or subscripted to avoid confusion with L-moment order <code class="reqn">r</code> or the TL-moments that indicate trimming level as a superscript (see <code><a href="#topic+TLmoms">TLmoms</a></code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>reslife.lmoms(f, para, nmom=5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="reslife.lmoms_+3A_f">f</code></td>
<td>
<p>Nonexceedance probability (<code class="reqn">0 \le F \le 1</code>).</p>
</td></tr>
<tr><td><code id="reslife.lmoms_+3A_para">para</code></td>
<td>
<p>The parameters from <code><a href="#topic+lmom2par">lmom2par</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
<tr><td><code id="reslife.lmoms_+3A_nmom">nmom</code></td>
<td>
<p>The number of moments to compute. Default is 5.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> is returned.
</p>
<table>
<tr><td><code>lambdas</code></td>
<td>
<p>Vector of the L-moments. First element is
<code class="reqn">\lambda_1</code>, second element is <code class="reqn">\lambda_2</code>, and so on.</p>
</td></tr>
<tr><td><code>ratios</code></td>
<td>
<p>Vector of the L-moment ratios. Second element is
<code class="reqn">\tau</code>, third element is <code class="reqn">\tau_3</code> and so on.</p>
</td></tr>
<tr><td><code>life.exceeds</code></td>
<td>
<p>The value for <code class="reqn">x(F)</code> for <code class="reqn">F=</code> <code>f</code>.</p>
</td></tr>
<tr><td><code>life.percentile</code></td>
<td>
<p>The value <code class="reqn">100\times</code><code>f</code>.</p>
</td></tr>
<tr><td><code>trim</code></td>
<td>
<p>Level of symmetrical trimming used in the computation, which is <code>NULL</code> because no trimming theory for L-moments of residual life have been developed or researched.</p>
</td></tr>
<tr><td><code>leftrim</code></td>
<td>
<p>Level of left-tail trimming used in the computation, which is <code>NULL</code> because no trimming theory for L-moments of residual life have been developed or researched.</p>
</td></tr>
<tr><td><code>rightrim</code></td>
<td>
<p>Level of right-tail trimming used in the computation, which is <code>NULL</code> because no trimming theory for L-moments of residual life have been developed or researched.</p>
</td></tr>
<tr><td><code>source</code></td>
<td>
<p>An attribute identifying the computational source of the L-moments: <br /> &ldquo;reslife.lmoms&rdquo;.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Nair, N.U., Sankaran, P.G., and Balakrishnan, N., 2013, Quantile-based reliability analysis: Springer, New York.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rmlmomco">rmlmomco</a></code>, <code><a href="#topic+rreslife.lmoms">rreslife.lmoms</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>A &lt;- vec2par(c(230, 2649, 3), type="gov") # Set lower bounds = 230 hours
F &lt;- nonexceeds(f01=TRUE)
plot(F, rmlmomco(F,A), type="l", ylim=c(0,3000), # mean residual life [black]
     xlab="NONEXCEEDANCE PROBABILITY",
     ylab="LIFE, RESIDUAL LIFE (RL), RL_L-SCALE, RL_L-skew (rescaled)")
L1 &lt;- L2 &lt;- T3 &lt;- vector(mode="numeric", length=length(F))
for(i in 1:length(F)) {
  lmr &lt;- reslife.lmoms(F[i], A, nmom=3)
  L1[i] &lt;- lmr$lambdas[1]; L2[i] &lt;- lmr$lambdas[2]; T3[i] &lt;- lmr$ratios[3]
}
lines(c(0,1), c(1500,1500),  lty=2) # Origin line (to highlight T3 crossing "zero")
lines(F, L1,          col=2, lwd=3) # Mean life (not residual, that is M(u)) [red]
lines(F, L2,          col=3, lwd=3) # L-scale of residual life [green]
lines(F, 5E3*T3+1500, col=4, lwd=3) # L-skew of residual life (re-scaled) [blue]
## Not run: 
# Nair et al. (2013, p. 203), test shows L2(u=0.37) = 771.2815
A &lt;- vec2par(c(230, 2649, 0.3), type="gpa"); F &lt;- 0.37
"afunc" &lt;- function(p) { return((1-p)*rmlmomco(p,A)) }
L2u1 &lt;- (1-F)^(-2)*integrate(afunc,F,1)$value
L2u2 &lt;- reslife.lmoms(F,A)$lambdas[2]

## End(Not run)
</code></pre>

<hr>
<h2 id='riglmomco'>Income Gap Ratio Quantile Function for the Distributions</h2><span id='topic+riglmomco'></span>

<h3>Description</h3>

<p>This function computes the Income Gap Ratio for quantile function <code class="reqn">x(F)</code> (<code><a href="#topic+par2qua">par2qua</a></code>, <code><a href="#topic+qlmomco">qlmomco</a></code>). The function is defined by Nair et al. (2013, p. 230) as
</p>
<p style="text-align: center;"><code class="reqn">G(u) = 1 - \frac{{}_\mathrm{r}\lambda_1(u)}{x(u)}\mbox{,}</code>
</p>

<p>where <code class="reqn">G(u)</code> is the  income gap quantile for nonexceedance probability <code class="reqn">u</code>, <code class="reqn">x(u)</code> is a constant for <code class="reqn">x(F = u)</code> is the quantile for <code class="reqn">u</code>, and <code class="reqn">{}_\mathrm{r}\lambda_1(u)</code> is the 1st reversed residual life L-moment (<code><a href="#topic+rreslife.lmoms">rreslife.lmoms</a></code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>riglmomco(f, para)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="riglmomco_+3A_f">f</code></td>
<td>
<p>Nonexceedance probability (<code class="reqn">0 \le F \le 1</code>).</p>
</td></tr>
<tr><td><code id="riglmomco_+3A_para">para</code></td>
<td>
<p>The parameters from <code><a href="#topic+lmom2par">lmom2par</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Income gap ratio quantile value for <code class="reqn">F</code>.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Nair, N.U., Sankaran, P.G., and Balakrishnan, N., 2013, Quantile-based reliability analysis: Springer, New York.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+qlmomco">qlmomco</a></code>, <code><a href="#topic+rreslife.lmoms">rreslife.lmoms</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Let us parametize some "income" distribution.
A &lt;- vec2par(c(123, 264, 2.11), type="gov")
riglmomco(0.5, A)
## Not run: 
F &lt;- nonexceeds(f01=TRUE)
plot(F, riglmomco(F,A), type="l",
     xlab="NONEXCEEDANCE PROBABILITY", ylab="INCOME GAP RATIO")
## End(Not run)
</code></pre>

<hr>
<h2 id='rlmomco'>Random Variates of a Distribution</h2><span id='topic+rlmomco'></span>

<h3>Description</h3>

<p>This function generates random variates for the specified distribution in the parameter object argument. See documentation about the parameter object is seen in <code><a href="#topic+lmom2par">lmom2par</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>. The prepended <code>r</code> in the function name is to parallel the built-in distribution syntax of <span class="rlang"><b>R</b></span> but of course reflects the <span class="pkg">lmomco</span> name in the function. An assumption is made that the user knows that they are providing appropirate (that is valid) distribution parameters. This is evident by the </p>
<pre>paracheck = FALSE</pre><p> argument passed to the <code><a href="#topic+par2qua">par2qua</a></code> function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rlmomco(n, para)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rlmomco_+3A_n">n</code></td>
<td>
<p>Number of samples to generate</p>
</td></tr>
<tr><td><code id="rlmomco_+3A_para">para</code></td>
<td>
<p>The parameters from <code><a href="#topic+lmom2par">lmom2par</a></code> or similar.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Vector of quantile values.
</p>


<h3>Note</h3>

<p>The action of this function in <span class="rlang"><b>R</b></span> idiom is <code>par2qua(runif(n), para)</code> for the distribution parameters <code>para</code>, the <span class="rlang"><b>R</b></span> function <code>runif</code> is the Uniform distribution, and <code>n</code> being the simulation size. 
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>See Also</h3>

<p><code><a href="#topic+dlmomco">dlmomco</a></code>, <code><a href="#topic+plmomco">plmomco</a></code>, <code><a href="#topic+qlmomco">qlmomco</a></code>, <code><a href="#topic+slmomco">slmomco</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>lmr      &lt;- lmoms(rnorm(20)) # generate 20 standard normal variates
para     &lt;- parnor(lmr) # estimate parameters of the normal
simulate &lt;- rlmomco(20,para) # simulate 20 samples using lmomco package

lmr  &lt;- vec2lmom(c(1000,500,.3)) # first three lmoments are known
para &lt;- lmom2par(lmr,type="gev") # est. parameters of GEV distribution
Q    &lt;- rlmomco(45,para) # simulate 45 samples
PP   &lt;- pp(Q)            # compute the plotting positions
plot(PP,sort(Q))         # plot the data up
</code></pre>

<hr>
<h2 id='rmlmomco'>Mean Residual Quantile Function of the Distributions</h2><span id='topic+rmlmomco'></span>

<h3>Description</h3>

<p>This function computes the Mean Residual Quantile Function for quantile function <code class="reqn">x(F)</code> (<code><a href="#topic+par2qua">par2qua</a></code>, <code><a href="#topic+qlmomco">qlmomco</a></code>). The function is defined by Nair et al. (2013, p. 51) as
</p>
<p style="text-align: center;"><code class="reqn">M(u) = \frac{1}{1-u}\int_u^1 [x(p) - x(u)]\; \mathrm{d}p\mbox{,}</code>
</p>

<p>where <code class="reqn">M(u)</code> is the mean residual quantile for nonexceedance probability <code class="reqn">u</code> and <code class="reqn">x(u)</code> is a constant for <code class="reqn">x(F = u)</code>. The variance of <code class="reqn">M(u)</code> is provided in <code><a href="#topic+rmvarlmomco">rmvarlmomco</a></code>.
</p>
<p>The integration instead of from <code class="reqn">0 \rightarrow 1</code> for the usual quantile function is <code class="reqn">u \rightarrow 1</code>. Note that <code class="reqn">x(u)</code> is a constant, so
</p>
<p style="text-align: center;"><code class="reqn">M(u) = \frac{1}{1-u}\int_u^1 x(p)\; \mathrm{d}p - x(u)\mbox{,}</code>
</p>

<p>is equivalent and the basis for the implementation in <code><a href="#topic+rmlmomco">rmlmomco</a></code>. Assuming that <code class="reqn">x(F)</code> is a life distribution, the <code class="reqn">M(u)</code> is interpreted (see Nair et al. [2013, p. 51]) as the average remaining life beyond the <code class="reqn">100(1-F)\%</code> of the distribution. Alternatively, <code class="reqn">M(u)</code> is the mean residual life conditioned that survival to lifetime <code class="reqn">x(F)</code> has occurred.
</p>
<p>If <code class="reqn">u = 0</code>, then <code class="reqn">M(0)</code> is the expectation of the life distribution or in otherwords <code class="reqn">M(0) = \lambda_1</code> of the parent quantile function.  If <code class="reqn">u = 1</code>, then <code class="reqn">M(u) = 0</code> (death has occurred)&mdash;there is zero residual life remaining. The implementation intercepts an intermediate <code class="reqn">\infty</code> and returns 0 for <code class="reqn">u = 1</code>.
</p>
<p>The <code class="reqn">M(u)</code> is referred to as a quantile function but this quantity is not to be interpreted as a type of probability distribution. The second example produces a <code class="reqn">M(u)</code> that is not monotonic increasing with <code class="reqn">u</code> and therefore it is immediately apparent that <code class="reqn">M(u)</code> is not the quantile function of some probability distribution by itself. Nair et al. (2013) provide extensive details on quantile-based reliability analysis.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rmlmomco(f, para)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rmlmomco_+3A_f">f</code></td>
<td>
<p>Nonexceedance probability (<code class="reqn">0 \le F \le 1</code>).</p>
</td></tr>
<tr><td><code id="rmlmomco_+3A_para">para</code></td>
<td>
<p>The parameters from <code><a href="#topic+lmom2par">lmom2par</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Mean residual value for <code class="reqn">F</code>.
</p>


<h3>Note</h3>

<p>The Mean Residual Quantile Function is the first of many other functions and &ldquo;curves&rdquo; associated with lifetime/reliability analysis operations that at their root use the quantile function (QF, <code class="reqn">x(F)</code>) of a distribution. Nair et al. (2013) (NSB) is the authoritative text on which the following functions in <span class="pkg">lmomco</span> were based
</p>

<table>
<tr>
 <td style="text-align: left;">
</td>
</tr>
<tr>
 <td style="text-align: left;">
Residual mean QF </td><td style="text-align: center;"> <code class="reqn">M(u)</code> </td><td style="text-align: left;"> <code><a href="#topic+rmlmomco">rmlmomco</a></code> </td><td style="text-align: right;"> NSB[p.51] </td>
</tr>
<tr>
 <td style="text-align: left;">
Variance residual QF   </td><td style="text-align: center;"> <code class="reqn">V(u)</code> </td><td style="text-align: left;"> <code><a href="#topic+rmvarlmomco">rmvarlmomco</a></code> </td><td style="text-align: right;"> NSB[p.54] </td>
</tr>
<tr>
 <td style="text-align: left;">
<code class="reqn">\alpha</code>-percentile residual QF   </td><td style="text-align: center;"> <code class="reqn">P_\alpha(u)</code> </td><td style="text-align: left;"> <code><a href="#topic+ralmomco">ralmomco</a></code> </td><td style="text-align: right;"> NSB[p.56] </td>
</tr>
<tr>
 <td style="text-align: left;">
Reversed <code class="reqn">\alpha</code>-percentile residual QF   </td><td style="text-align: center;"> <code class="reqn">R_\alpha(u)</code> </td><td style="text-align: left;"> <code><a href="#topic+rralmomco">rralmomco</a></code> </td><td style="text-align: right;"> NSB[p.69--70] </td>
</tr>
<tr>
 <td style="text-align: left;">
Reversed residual mean QF </td><td style="text-align: center;">  <code class="reqn">R(u)</code> </td><td style="text-align: left;"> <code><a href="#topic+rrmlmomco">rrmlmomco</a></code> </td><td style="text-align: right;"> NSB[p.57] </td>
</tr>
<tr>
 <td style="text-align: left;">
Reversed variance residual  QF </td><td style="text-align: center;">  <code class="reqn">D(u)</code> </td><td style="text-align: left;"> <code><a href="#topic+rrmvarlmomco">rrmvarlmomco</a></code> </td><td style="text-align: right;"> NSB[p.58] </td>
</tr>
<tr>
 <td style="text-align: left;">
Conditional mean QF </td><td style="text-align: center;"> <code class="reqn">\mu(u)</code> </td><td style="text-align: left;"> <code><a href="#topic+cmlmomco">cmlmomco</a></code>  </td><td style="text-align: right;"> NSB[p.68] </td>
</tr>
<tr>
 <td style="text-align: left;">
Vitality function (see conditional mean)</td>
</tr>
<tr>
 <td style="text-align: left;">
Total time on test transform QF </td><td style="text-align: center;">  <code class="reqn">T(u)</code> </td><td style="text-align: left;"> <code><a href="#topic+tttlmomco">tttlmomco</a></code> </td><td style="text-align: right;"> NSB[p.171--172, 176] </td>
</tr>
<tr>
 <td style="text-align: left;">
Scaled total time on test transform QF </td><td style="text-align: center;">  <code class="reqn">\phi(u)</code> </td><td style="text-align: left;"> <code><a href="#topic+stttlmomco">stttlmomco</a></code> </td><td style="text-align: right;"> NSB[p.173] </td>
</tr>
<tr>
 <td style="text-align: left;">
Lorenz curve </td><td style="text-align: center;">  <code class="reqn">L(u)</code> </td><td style="text-align: left;"> <code><a href="#topic+lrzlmomco">lrzlmomco</a></code> </td><td style="text-align: right;"> NSB[p.174] </td>
</tr>
<tr>
 <td style="text-align: left;">
Bonferroni curve </td><td style="text-align: center;">  <code class="reqn">B(u)</code> </td><td style="text-align: left;"> <code><a href="#topic+bfrlmomco">bfrlmomco</a></code> </td><td style="text-align: right;"> NSB[p.179] </td>
</tr>
<tr>
 <td style="text-align: left;">
Leimkuhler curve </td><td style="text-align: center;">  <code class="reqn">K(u)</code> </td><td style="text-align: left;"> <code><a href="#topic+lkhlmomco">lkhlmomco</a></code> </td><td style="text-align: right;"> NSB[p.181] </td>
</tr>
<tr>
 <td style="text-align: left;">
Income gap ratio curve  </td><td style="text-align: center;">  <code class="reqn">G(u)</code> </td><td style="text-align: left;"> <code><a href="#topic+riglmomco">riglmomco</a></code> </td><td style="text-align: right;"> NSB[p.230] </td>
</tr>
<tr>
 <td style="text-align: left;">
Mean life: <code class="reqn">\mu \equiv \mu(0) \equiv \lambda_1(u=0)  \equiv \lambda_1</code></td>
</tr>
<tr>
 <td style="text-align: left;">
L-moments of residual life </td><td style="text-align: center;"> <code class="reqn">\lambda_r(u)</code> </td><td style="text-align: left;"> <code><a href="#topic+reslife.lmoms">reslife.lmoms</a></code> </td><td style="text-align: right;"> NSB[p.202]</td>
</tr>
<tr>
 <td style="text-align: left;">
L-moments of reversed residual life </td><td style="text-align: center;"> <code class="reqn">{}_\mathrm{r}\lambda_r(u)</code> </td><td style="text-align: left;"> <code><a href="#topic+rreslife.lmoms">rreslife.lmoms</a></code> </td><td style="text-align: right;"> NSB[p.211]</td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>



<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Kupka, J., and Loo, S., 1989, The hazard and vitality measures of ageing: Journal of Applied Probability, v. 26, pp. 532&ndash;542.
</p>
<p>Nair, N.U., Sankaran, P.G., and Balakrishnan, N., 2013, Quantile-based reliability analysis: Springer, New York.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+qlmomco">qlmomco</a></code>, <code><a href="#topic+cmlmomco">cmlmomco</a></code>, <code><a href="#topic+rmvarlmomco">rmvarlmomco</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># It is easiest to think about residual life as starting at the origin, units in days.
A &lt;- vec2par(c(0.0, 2649, 2.11), type="gov") # so set lower bounds = 0.0
qlmomco(0.5, A)  # The median lifetime = 1261 days
rmlmomco(0.5, A) # The average remaining life given survival to the median = 861 days

# 2nd example with discussion points
F &lt;- nonexceeds(f01=TRUE)
plot(F, qlmomco(F, A), type="l", # usual quantile plot as seen throughout lmomco
     xlab="NONEXCEEDANCE PROBABILITY", ylab="LIFETIME, IN DAYS")
lines(F, rmlmomco(F, A), col=2, lwd=3)           # mean residual life
L1 &lt;- lmomgov(A)$lambdas[1]                      # mean lifetime at start/birth
lines(c(0,1), c(L1,L1), lty=2)                   # line "ML" (mean life)
# Notice how ML intersects M(F|F=0) and again later in "time" (about F = 1/4)  showing
# that this Govindarajulu has a peak mean residual life that is **greater** than the
# expected lifetime at start. The M(F) then tapers off to zero at infinity time (F=1).
# M(F) is non-monotonic for this example---not a proper probability distribution.
</code></pre>

<hr>
<h2 id='rmvarlmomco'>Variance Residual Quantile Function of the Distributions</h2><span id='topic+rmvarlmomco'></span>

<h3>Description</h3>

<p>This function computes the Variance Residual Quantile Function for a quantile function <code class="reqn">x(F)</code> (<code><a href="#topic+par2qua">par2qua</a></code>, <code><a href="#topic+qlmomco">qlmomco</a></code>).  The variance is defined by Nair et al. (2013, p. 55) as
</p>
<p style="text-align: center;"><code class="reqn">V(u) = \frac{1}{1-u} \int_u^1 M(u)^2\; \mathrm{d}p\mbox{,}</code>
</p>

<p>where <code class="reqn">V(u)</code> is the variance of <code class="reqn">M(u)</code> (the residual mean quantile function, <code><a href="#topic+rmlmomco">rmlmomco</a></code>) for nonexceedance probability <code class="reqn">u</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rmvarlmomco(f, para)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rmvarlmomco_+3A_f">f</code></td>
<td>
<p>Nonexceedance probability (<code class="reqn">0 \le F \le 1</code>).</p>
</td></tr>
<tr><td><code id="rmvarlmomco_+3A_para">para</code></td>
<td>
<p>The parameters from <code><a href="#topic+lmom2par">lmom2par</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Residual variance value for <code class="reqn">F</code>.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Nair, N.U., Sankaran, P.G., and Balakrishnan, N., 2013, Quantile-based reliability analysis: Springer, New York.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+qlmomco">qlmomco</a></code>, <code><a href="#topic+rmlmomco">rmlmomco</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># It is easiest to think about residual life as starting at the origin, units in days.
A &lt;- vec2par(c(0.0, 2649, 2.11), type="gov") # so set lower bounds = 0.0
qlmomco(0.5, A)  # The median lifetime = 1261 days
rmlmomco(0.5, A) # The average remaining life given survival to the median = 861 days
rmvarlmomco(0.5, A) # and the variance of that value.
## Not run: 
A &lt;- lmom2par(vec2lmom(c(2000, 450, 0.14, 0.1)), type="kap")
F &lt;- nonexceeds(f01=TRUE)
plot(F, qlmomco(F,A), type="l", ylim=c(100,6000),
     xlab="NONEXCEEDANCE PROBABILITY", ylab="LIFETIME OR SQRT(VAR LIFE), IN DAYS")
lines(F, sqrt( rmvarlmomco(F, A)), col=4, lwd=4) # thick blue, residual mean life
lines(F, sqrt(rrmvarlmomco(F, A)), col=2, lwd=4) # thick red, reversed resid. mean life
lines(F,   rmlmomco(F,A), col=4, lty=2); lines(F, rrmlmomco(F,A), col=2, lty=2)
lines(F,  tttlmomco(F,A), col=3, lty=2); lines(F,  cmlmomco(F,A), col=3)

## End(Not run)
</code></pre>

<hr>
<h2 id='rralmomco'>Reversed Alpha-Percentile Residual Quantile Function of the Distributions</h2><span id='topic+rralmomco'></span>

<h3>Description</h3>

<p>This function computes the Reversed <code class="reqn">\alpha</code>-Percentile Residual Quantile Function for quantile function <code class="reqn">x(F)</code> (<code><a href="#topic+par2qua">par2qua</a></code>, <code><a href="#topic+qlmomco">qlmomco</a></code>). The function is defined by Nair and Vineshkumar (2011, p. 87) and Midhu et al. (2013, p. 13) as
</p>
<p style="text-align: center;"><code class="reqn">R_\alpha(u) = x(u) - x(u[1-\alpha])\mbox{,}</code>
</p>

<p>where <code class="reqn">R_\alpha(u)</code> is the reversed <code class="reqn">\alpha</code>-percentile residual quantile for nonexceedance probability <code class="reqn">u</code> and percentile <code class="reqn">\alpha</code> and <code class="reqn">x(u[1-\alpha])</code> is a constant for <code class="reqn">x(F = u[1-\alpha])</code>. The nonreversed <code class="reqn">\alpha</code>-percentile residual quantile is available under <code><a href="#topic+ralmomco">ralmomco</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rralmomco(f, para, alpha=0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rralmomco_+3A_f">f</code></td>
<td>
<p>Nonexceedance probability (<code class="reqn">0 \le F \le 1</code>).</p>
</td></tr>
<tr><td><code id="rralmomco_+3A_para">para</code></td>
<td>
<p>The parameters from <code><a href="#topic+lmom2par">lmom2par</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
<tr><td><code id="rralmomco_+3A_alpha">alpha</code></td>
<td>
<p>The <code class="reqn">\alpha</code> percentile, which is divided by <code class="reqn">100</code> inside the function ahead of calling the quantile function of the distribution.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Reversed <code class="reqn">\alpha</code>-percentile residual quantile value for <code class="reqn">F</code>.
</p>


<h3>Note</h3>

<p>Technically it seems that Nair et al. (2013) do not explictly define the reversed <code class="reqn">\alpha</code>-percentile residual quantile but their index points to pp. 69&ndash;70 for a derivation involving the Generalized Lambda distribution (GLD) but that derivation (top of p. 70) has incorrect algebra.  A possibilty is that Nair et al. (2013) forgot to include <code class="reqn">R_\alpha(u)</code> as an explicit definition in juxtaposition to <code class="reqn">P_\alpha(u)</code> (<code><a href="#topic+ralmomco">ralmomco</a></code>) and then apparently made an easy-to-see algebra error in trying to collect terms for the GLD.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Nair, N.U., and Vineshkumar, B., 2011, Reversed percentile residual life and related concepts: Journal of the Korean Statistical Society, v. 40, no. 1, pp. 85&ndash;92.
</p>
<p>Midhu, N.N., Sankaran, P.G., and Nair, N.U., 2013, A class of distributions with linear mean residual quantile function and it's generalizations: Statistical Methodology, v. 15, pp. 1&ndash;24.
</p>
<p>Nair, N.U., Sankaran, P.G., and Balakrishnan, N., 2013, Quantile-based reliability analysis: Springer, New York.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+qlmomco">qlmomco</a></code>, <code><a href="#topic+ralmomco">ralmomco</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># It is easiest to think about residual life as starting at the origin, units in days.
A &lt;- vec2par(c(145, 2649, 2.11), type="gov") # so set lower bounds = 0.0
rralmomco(0.78, A, alpha=50)
## Not run: 
F &lt;- nonexceeds(f01=TRUE); r &lt;- range(rralmomco(F,A, alpha=50), ralmomco(F,A, alpha=50))
plot(F, rralmomco(F,A, alpha=50), type="l", xlab="NONEXCEEDANCE PROBABILITY",
                  ylim=r, ylab="MEDIAN RESIDUAL OR REVERSED LIFETIME, IN DAYS")
lines(F, ralmomco(F, A, alpha=50), col=2) # notice the lack of symmetry

## End(Not run)
</code></pre>

<hr>
<h2 id='rreslife.lmoms'>L-moments of Reversed Residual Life</h2><span id='topic+rreslife.lmoms'></span>

<h3>Description</h3>

<p>This function computes the L-moments of reversed residual life for a quantile function <code class="reqn">x(F)</code> for an exceedance threshold in probabiliy of <code class="reqn">u</code>. The L-moments of residual life are thoroughly described by Nair et al. (2013, p. 211).  These L-moments are define as
</p>
<p style="text-align: center;"><code class="reqn">{}_\mathrm{r}\lambda(u)_r = \sum_{k=0}^{r-1} (-1)^k {r-1 \choose k}^2 \int_0^u \left(\frac{p}{u}\right)^{r-k-1} \left(1 - \frac{p}{u}\right)^k \frac{x(p)}{u}\,\mathrm{d}p \mbox{,}</code>
</p>

<p>where <code class="reqn">{}_\mathrm{r}\lambda(u)_r</code> is the <code class="reqn">r</code>th L-moment at residual life probability <code class="reqn">u</code>.  The L-moment ratios <code class="reqn">{}_\mathrm{r}\tau(u)_r</code> have the usual definitions. The implementation here exclusively uses the quantile function of the distribution. If <code class="reqn">u=0</code>, then the usual L-moments of the quantile function are returned because the integration domain is the entire potential lifetime range.  If <code class="reqn">u=0</code>, then <code class="reqn">{}_\mathrm{r}\lambda(1)_1 = x(0)</code> is returned, which is the minimum lifetime of the distribution (the value for the lower support of the distribution), and the remaining <code class="reqn">{}_\mathrm{r}\lambda(1)_r</code> for <code class="reqn">r \ge 2</code> are set to <code>NA</code>. The reversal aspect is denoted by the prepended romanscript <code class="reqn">\mathrm{r}</code> to the <code class="reqn">\lambda</code>'s and <code class="reqn">\tau</code>'s. Lastly, the notation <code class="reqn">(u)</code> is neither super or subscripted to avoid confusion with L-moment order <code class="reqn">r</code> or the TL-moments that indicate trimming level as a superscript (see <code><a href="#topic+TLmoms">TLmoms</a></code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rreslife.lmoms(f, para, nmom=5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rreslife.lmoms_+3A_f">f</code></td>
<td>
<p>Nonexceedance probability (<code class="reqn">0 \le F \le 1</code>).</p>
</td></tr>
<tr><td><code id="rreslife.lmoms_+3A_para">para</code></td>
<td>
<p>The parameters from <code><a href="#topic+lmom2par">lmom2par</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
<tr><td><code id="rreslife.lmoms_+3A_nmom">nmom</code></td>
<td>
<p>The number of moments to compute. Default is 5.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> is returned.
</p>
<table>
<tr><td><code>lambdas</code></td>
<td>
<p>Vector of the L-moments. First element is
<code class="reqn">{}_\mathrm{r}\lambda_1</code>, second element is <code class="reqn">{}_\mathrm{r}\lambda_2</code>, and so on.</p>
</td></tr>
<tr><td><code>ratios</code></td>
<td>
<p>Vector of the L-moment ratios. Second element is
<code class="reqn">{}_\mathrm{r}\tau</code>, third element is <code class="reqn">{}_\mathrm{r}\tau_3</code> and so on.</p>
</td></tr>
<tr><td><code>life.notexceeds</code></td>
<td>
<p>The value for <code class="reqn">x(F)</code> for <code class="reqn">F=</code> <code>f</code>.</p>
</td></tr>
<tr><td><code>life.percentile</code></td>
<td>
<p>The value <code class="reqn">100\times</code><code>f</code>.</p>
</td></tr>
<tr><td><code>trim</code></td>
<td>
<p>Level of symmetrical trimming used in the computation, which is <code>NULL</code> because no trimming theory for L-moments of residual life have been developed or researched.</p>
</td></tr>
<tr><td><code>leftrim</code></td>
<td>
<p>Level of left-tail trimming used in the computation, which is <code>NULL</code> because no trimming theory for L-moments of residual life have been developed or researched.</p>
</td></tr>
<tr><td><code>rightrim</code></td>
<td>
<p>Level of right-tail trimming used in the computation, which is <code>NULL</code> because no trimming theory for L-moments of residual life have been developed or researched.</p>
</td></tr>
<tr><td><code>source</code></td>
<td>
<p>An attribute identifying the computational source of the L-moments: &ldquo;rreslife.lmoms&rdquo;.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Nair, N.U., Sankaran, P.G., and Balakrishnan, N., 2013, Quantile-based reliability analysis: Springer, New York.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rmlmomco">rmlmomco</a></code>, <code><a href="#topic+reslife.lmoms">reslife.lmoms</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># It is easiest to think about residual life as starting at the origin, units in days.
A &lt;- vec2par(c(0.0, 2649, 2.11), type="gov") # so set lower bounds = 0.0
"afunc" &lt;- function(p)        { return(par2qua(p,A,paracheck=FALSE)) }
"bfunc" &lt;- function(p,u=NULL) { return((2*p - u)*par2qua(p,A,paracheck=FALSE)) }
f &lt;- 0.35
rL1a &lt;- integrate(afunc, lower=0, upper=f)$value      / f   # Nair et al. (2013, eq. 6.18)
rL2a &lt;- integrate(bfunc, lower=0, upper=f, u=f)$value / f^2 # Nair et al. (2013, eq. 6.19)
rL &lt;- rreslife.lmoms(f, A, nmom=2) # The data.frame shows equality of the two approaches.
rL1b &lt;- rL$lambdas[1]; rL2b &lt;- rL$lambdas[2]
print(data.frame(rL1a=rL1a, rL1b=rL1b, rL2b=rL2b, rL2b=rL2b))
## Not run: 
# 2nd Example, let us look at Tau3, each of the L-skews are the same.
T3    &lt;- par2lmom(A)$ratios[3]
T3.0  &lt;-  reslife.lmoms(0, A)$ratios[3]
rT3.1 &lt;- rreslife.lmoms(1, A)$ratios[3]

## End(Not run)
## Not run: 
# Nair et al. (2013, p. 212), test shows rL2(u=0.77) = 12.6034
A &lt;- vec2par(c(230, 269, 3.3), type="gpa"); F &lt;- 0.77
"afunc" &lt;- function(p) { return(p*rrmlmomco(p,A)) }
rL2u1 &lt;- (F)^(-2)*integrate(afunc,0,F)$value
rL2u2 &lt;- rreslife.lmoms(F,A)$lambdas[2]

## End(Not run)
</code></pre>

<hr>
<h2 id='rrmlmomco'>Reversed Mean Residual Quantile Function of the Distributions</h2><span id='topic+rrmlmomco'></span>

<h3>Description</h3>

<p>This function computes the Reversed Mean Residual Quantile Function for quantile function <code class="reqn">x(F)</code> (<code><a href="#topic+par2qua">par2qua</a></code>, <code><a href="#topic+qlmomco">qlmomco</a></code>). The function is defined by Nair et al. (2013, p.57) as
</p>
<p style="text-align: center;"><code class="reqn">R(u) = x(u) - \frac{1}{u}\int_0^u x(p)\; \mathrm{d}p\mbox{,}</code>
</p>

<p>where <code class="reqn">R(u)</code> is the reversed mean residual for nonexceedance probability <code class="reqn">u</code> and <code class="reqn">x(u)</code> is a constant for <code class="reqn">x(F = u)</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rrmlmomco(f, para)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rrmlmomco_+3A_f">f</code></td>
<td>
<p>Nonexceedance probability (<code class="reqn">0 \le F \le 1</code>).</p>
</td></tr>
<tr><td><code id="rrmlmomco_+3A_para">para</code></td>
<td>
<p>The parameters from <code><a href="#topic+lmom2par">lmom2par</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Reversed mean residual value for <code class="reqn">F</code>.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Nair, N.U., Sankaran, P.G., and Balakrishnan, N., 2013, Quantile-based reliability analysis: Springer, New York.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+qlmomco">qlmomco</a></code>, <code><a href="#topic+rrmvarlmomco">rrmvarlmomco</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># It is easiest to think about residual life as starting at the origin, units in days.
A &lt;- vec2par(c(0.0, 2649, 2.6), type="gov") # so set lower bounds = 0.0
qlmomco(0.5, A)  # The median lifetime = 1005 days
rrmlmomco(0.5, A) # The reversed mean remaining life given median survival = 691 days

## Not run: 
F &lt;- nonexceeds(f01=TRUE)
plot(F, qlmomco(F,A), type="l", # life
     xlab="NONEXCEEDANCE PROBABILITY", ylab="LIFETIME, IN DAYS")
lines(F,  rmlmomco(F, A), col=4, lwd=4) # thick blue, mean residual life
lines(F, rrmlmomco(F, A), col=2, lwd=4) # thick red, reversed mean residual life

## End(Not run)
</code></pre>

<hr>
<h2 id='rrmvarlmomco'>Reversed Variance Residual Quantile Function of the Distributions</h2><span id='topic+rrmvarlmomco'></span>

<h3>Description</h3>

<p>This function computes the Reversed Variance Residual Quantile Function for a quantile function <code class="reqn">x{F}</code> (<code><a href="#topic+par2qua">par2qua</a></code>, <code><a href="#topic+qlmomco">qlmomco</a></code>). The variance is defined by Nair et al. (2013, p. 58) as
</p>
<p style="text-align: center;"><code class="reqn">D(u) = \frac{1}{u} \int_0^u R(u)^2\; \mathrm{d}p\mbox{,}</code>
</p>

<p>where <code class="reqn">D(u)</code> is the variance of <code class="reqn">R(u)</code>  (the reversed mean residual quantile function, <code><a href="#topic+rrmlmomco">rrmlmomco</a></code>) for nonexceedance probability <code class="reqn">u</code>.  The variance of <code class="reqn">M(u)</code> is provided in <code><a href="#topic+rmvarlmomco">rmvarlmomco</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rrmvarlmomco(f, para)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rrmvarlmomco_+3A_f">f</code></td>
<td>
<p>Nonexceedance probability (<code class="reqn">0 \le F \le 1</code>).</p>
</td></tr>
<tr><td><code id="rrmvarlmomco_+3A_para">para</code></td>
<td>
<p>The parameters from <code><a href="#topic+lmom2par">lmom2par</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Reversed residual variance value for <code class="reqn">F</code>.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Nair, N.U., Sankaran, P.G., and Balakrishnan, N., 2013, Quantile-based reliability analysis: Springer, New York.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+qlmomco">qlmomco</a></code>, <code><a href="#topic+rrmlmomco">rrmlmomco</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># It is easiest to think about residual life as starting at the origin, units in days.
A &lt;- vec2par(c(0.0, 264, 1.6), type="gov") # so set lower bounds = 0.0
rrmvarlmomco(0.5, A) # variance at the median reversed mean residual life
## Not run: 
A &lt;- vec2par(c(-100, 264, 1.6), type="gov")
F &lt;- nonexceeds(f01=TRUE)
plot(F, rmvarlmomco(F,A), type="l")
lines(F, rrmvarlmomco(F,A), col=2)

## End(Not run)
</code></pre>

<hr>
<h2 id='sen.mean'>Sen Weighted Mean Statistic</h2><span id='topic+sen.mean'></span>

<h3>Description</h3>

<p>The Sen weighted mean statistic <code class="reqn">\mathcal{S}_{n,k}</code> is a robust estimator of the mean of a distribution
</p>
<p style="text-align: center;"><code class="reqn">\mathcal{S}_{n,k} = {n \choose 2k+1}^{-1} \sum_{i=1}^n {i - 1 \choose k} {n - i \choose k } x_{i:n}\mbox{,}</code>
</p>

<p>where <code class="reqn">x_{i:n}</code> are the sample order statistics and <code class="reqn">k</code> is a weighting or trimming parameter. If <code class="reqn">k = 2</code>, then the <code class="reqn">\mathcal{S}_{n,2}</code> is the first symmetrical TL-moment (trim = 1). Note that <code class="reqn">\mathcal{S}_{n,0} = \mu = \overline{X}_n</code> or the arithmetic <code>mean</code> and <code class="reqn">\mathcal{S}_{n,k}</code> is the sample <code>median</code> if either <code class="reqn">n</code> is even and <code class="reqn">k = (n/2) - 1</code> or <code class="reqn">n</code> is odd and <code class="reqn">k = (n-1)/2</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sen.mean(x, k=0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sen.mean_+3A_x">x</code></td>
<td>
<p>A vector of data values that will be reduced to non-missing values.</p>
</td></tr>
<tr><td><code id="sen.mean_+3A_k">k</code></td>
<td>
<p>A weighting or trimming parameter <code class="reqn">0 &lt; k &lt; (n-1)/2</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> is returned.
</p>
<table>
<tr><td><code>sen</code></td>
<td>
<p>The sen mean <code class="reqn">\mathcal{S}_{n,k}</code>.</p>
</td></tr>
<tr><td><code>source</code></td>
<td>
<p>An attribute identifying the computational source: &ldquo;sen.mean&rdquo;.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Jurečková, J., and Picek, J., 2006, Robust statistical methods with R: Boca Raton, Fla., Chapman and Hall/CRC, ISBN 1&ndash;58488&ndash;454&ndash;1, 197 p.
</p>
<p>Sen, P.K., 1964, On some properties of the rank-weighted means: Journal Indian Society of Agricultural Statistics: v. 16, pp. 51&ndash;61.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+TLmoms">TLmoms</a></code>, <code><a href="#topic+gini.mean.diff">gini.mean.diff</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>fake.dat &lt;- c(123, 34, 4, 654, 37, 78)
sen.mean(fake.dat); mean(fake.dat) # These should be the same values

sen.mean(fake.dat, k=(length(fake.dat)/2) - 1); median(fake.dat)
# Again, same values

# Finally, the sen.mean() is like a symmetrically trimmed TL-moment
# Let us demonstrate by computed a two sample trimming for each side
# for a Normal distribution having a mean of 100.
fake.dat &lt;- rnorm(20, mean=100)
lmr &lt;- TLmoms(fake.dat, trim=2)
sen &lt;- sen.mean(fake.dat, k=2)

print(abs(lmr$lambdas[1] - sen$sen)) # zero is returned
</code></pre>

<hr>
<h2 id='sentiv.curve'>Compute the Sensitivity Curve for a Single Quantile</h2><span id='topic+sentiv.curve'></span>

<h3>Description</h3>

<p>The <em>sensitivity curve</em> (<code class="reqn">SC</code>) is a means to assess how sensitive a particular statistic <code class="reqn">T_{n+1}</code> for a sample of size <code class="reqn">n</code> is to an additional sample <code class="reqn">x</code> to be included. For the implementation by this function, the statistic <code class="reqn">T</code> is a specific quantile <code class="reqn">x(F)</code> of interest set by a nonexceedance probability <code class="reqn">F</code>.  The <code class="reqn">SC</code> is
</p>
<p style="text-align: center;"><code class="reqn">SC_{n+1}(x,\,| F) = (n+1)(T_{n+1} - T_n)\mbox{,}</code>
</p>

<p>where <code class="reqn">T_n</code> represent the statistic for the sample of size <code class="reqn">n</code>. The notation here follows that of Hampel (1974, p. 384) concerning <code class="reqn">n</code> and <code class="reqn">n+1</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sentiv.curve(f, x, method=c("bootstrap", "polynomial", "none"),
                   data=NULL, para=NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sentiv.curve_+3A_f">f</code></td>
<td>
<p>The nonexceedance probability <code class="reqn">F</code> of the quantile for which the sensitivity of its estimation is needed. Only the first value if a vector is given is used and a warning issued.</p>
</td></tr>
<tr><td><code id="sentiv.curve_+3A_x">x</code></td>
<td>
<p>The <code class="reqn">x</code> values representing the potential <em>one more value</em> to be added to the original data.</p>
</td></tr>
<tr><td><code id="sentiv.curve_+3A_data">data</code></td>
<td>
<p>A vector of mandatory sample data values. These will either be converted to (1) order statistic expectations exact analytical expressions or simulation (backup plan), (2) Bernstein (or similar) polynomials, or (3) the provided values treated as if they are the order statistic expectations.</p>
</td></tr>
<tr><td><code id="sentiv.curve_+3A_method">method</code></td>
<td>
<p>A character variable determining how the statistics <code class="reqn">T</code> are computed (see Details).</p>
</td></tr>
<tr><td><code id="sentiv.curve_+3A_para">para</code></td>
<td>
<p>A distribution parameter list from a function such as <code><a href="#topic+vec2par">vec2par</a></code> or <code><a href="#topic+lmom2par">lmom2par</a></code>.</p>
</td></tr>
<tr><td><code id="sentiv.curve_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass either to the <code><a href="#topic+lmoms.bootbarvar">lmoms.bootbarvar</a></code> or to the <br /> <code><a href="#topic+dat2bernqua">dat2bernqua</a></code> function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The main features of this function involve how the statistics are computed and are controlled by the <code>method</code> argument. Three different approaches are provided.
</p>
<p><b>Bootstrap:</b> Arguments <code>data</code> and <code>para</code> are <em>mandatory</em>. If <code>boostrap</code> is requested, then the distribution type set by the <code>type</code> attribute in <code>para</code> is used along with the method of L-moments for <code class="reqn">T(F)</code> estimation. The <code class="reqn">T_n(F)</code> is directly computed from the distribution in <code>para</code>. And for each <code>x</code>, the <code class="reqn">T_{n+1}(F)</code> is computed by <code><a href="#topic+lmoms">lmoms</a></code>, <code><a href="#topic+lmom2par">lmom2par</a></code>, and the distribution type. The sample so fed to <code><a href="#topic+lmoms">lmoms</a></code> is denoted as <code>c(EX, x)</code>.
</p>
<p><b>Polynomial:</b> Argument <code>data</code> is <em>mandatory</em> and <code>para</code> is <em>not</em> used. If <code>polynomial</code> is requested, then the Bernstein polynomial (likely) from the <code><a href="#topic+dat2bernqua">dat2bernqua</a></code> is used. The <code class="reqn">T_n(F)</code> is computed by the <code>data</code> sample. And for each <code>x</code>, the <code class="reqn">T_{n+1}(F)</code> also is computed by <code><a href="#topic+dat2bernqua">dat2bernqua</a></code>, but the sample so fed to <code><a href="#topic+dat2bernqua">dat2bernqua</a></code> is denoted as <code>c(EX, x)</code>.
</p>
<p><b>None:</b> Arguments <code>data</code> and <code>para</code> are <em>mandatory</em>. If <code>none</code> is requested, then the distribution type set by the <code>type</code> attribute in <code>para</code> is used along with the method of L-moments. The <code class="reqn">T_n(F)</code> is directly computed from the distribution in <code>para</code>. And for each <code>x</code>, the <code class="reqn">T_{n+1}(F)</code> is computed by <code><a href="#topic+lmoms">lmoms</a></code>, <code><a href="#topic+lmom2par">lmom2par</a></code>, and the distribution type. The sample so fed to <code><a href="#topic+lmoms">lmoms</a></code> is denoted as <code>c(EX, x)</code>.
</p>
<p>The internal variable <code>EX</code> now requires discussion. If <code>method=none</code>, then the <code>data</code> are sorted and set into the internal variable <code>EX</code>. Conversely, if <code>method=</code><code>bootstrap</code> or <code>method=</code><code>polynomial</code>, then <code>EX</code> will contain the expectations of the order statistics from <code><a href="#topic+lmoms.bootbarvar">lmoms.bootbarvar</a></code>.
</p>
<p>Lastly, the Weibull plotting positions are used for the probability values for the data as provided by the <code><a href="#topic+pp">pp</a></code> function. Evidently, if <code>method</code> is either <code>parent</code> or <code>polynomial</code> then a &ldquo;stylized sensitivity curve&rdquo; would created (David, 1981, p. 165) because the expectations of the sample order statistics and not the sample order statistics (the sorted sample) are used.
</p>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> is returned.
</p>
<table>
<tr><td><code>curve</code></td>
<td>
<p>The value for <code class="reqn">SC(x) = (n+1)(T_{n+1} - T_n)</code>.</p>
</td></tr>
<tr><td><code>curve.perchg</code></td>
<td>
<p>The percent change sensitivity curve by <code class="reqn">SC^{(\%)}(x) = 100\times (T_{n+1} - T_n)/T_n</code>.</p>
</td></tr>
<tr><td><code>Tnp1</code></td>
<td>
<p>The values for <code class="reqn">T_{n+1} = T_n + SC(x)/(n+1)</code>.</p>
</td></tr>
<tr><td><code>Tn</code></td>
<td>
<p>The value (singular) for <code class="reqn">T_n</code> which was estimated according to <code>method</code>.</p>
</td></tr>
<tr><td><code>color</code></td>
<td>
<p>The curve potentially passes through a zero depending on the values for <code class="reqn">x</code>. The <code>color</code> is set to distinquish between negatives and positives so that the user could use the absolute value of <code>curve</code> on logarithmic scales and use the color to distinquish the original negatives.</p>
</td></tr>
<tr><td><code>EX</code></td>
<td>
<p>The values for the internal variable <code>EX</code>.</p>
</td></tr>
<tr><td><code>source</code></td>
<td>
<p>An attribute identifying the computational source of the sensitivity curve: &ldquo;sentiv.curve&rdquo;.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>David, H.A., 1981, Order statistics: John Wiley, New York.
</p>
<p>Hampel, F.R., 1974, The influence curve and its role in robust estimation: Journal of the American Statistical Association, v. 69, no. 346, pp. 383&ndash;393.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+expect.max.ostat">expect.max.ostat</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
set.seed(50)
mean &lt;- 12530; lscale &lt;- 5033; lskew &lt;- 0.4
n &lt;- 46; type &lt;- "gev"; lmr &lt;- vec2lmom(c(mean,lscale,lskew))
F &lt;- 0.90 # going to explore sensitivity on the 90th percentile
par.p &lt;- lmom2par(lmr, type=type) # Parent distribution
TRUE.Q &lt;- par2qua(F, par.p)
X &lt;- sort(rlmomco(n, par.p)) # Simulate a small sample
par.s &lt;- lmom2par(lmoms(X), type=type) # Now fit the distribution
SIM.Q &lt;- par2qua(F, par.s); SIM.BAR &lt;- par2lmom(par.s)$lambdas[1]
D &lt;- log10(mean) - log10(lscale)
R &lt;- as.integer(log10(mean)) + c(-D, D) # need some x-values to explore
Xs &lt;- 10^(seq(R[1], R[2], by=.01)) # x-values to explore
# Sample estimate are the "parent" only to mimic a more real-world setting.
# where one "knows" the form of the parent but perhaps not the parameters.
SC1 &lt;- sentiv.curve(F, Xs, data=X, para=par.s, method="bootstrap")
SC2 &lt;- sentiv.curve(F, Xs, data=X, para=par.s, method="polynomial",
                              bound.type="Carv")
SC3 &lt;- sentiv.curve(F, Xs, data=X, para=par.s, method="none")
xlim &lt;- range(c(Xs,SC1$Tnp1,SC2$Tnp1,SC3$Tnp1))
ylim &lt;- range(c(SC1$curve.perchg, SC2$curve.perchg, SC3$curve.perchg))
plot(xlim, c(0,0), type="l", lty=2, ylim=ylim, xaxs="i", yaxs="i",
     xlab=paste("Magnitude of next value added to sample of size",n),
     ylab=paste("Percent change fitted",F,"probability quantile"))
mtext(paste("Distribution",par.s$type,"with parameters",
      paste(round(par.s$para, digits=3), collapse=", ")))
lines(rep(TRUE.Q,  2), c(-10,10), lty=4, lwd=3)
lines(rep(SIM.BAR, 2), c(-10,10), lty=3, lwd=2)
lines(rep(SIM.Q,   2), c(-10,10), lty=2)
lines(Xs, SC1$curve.perchg, lwd=3, col=1)
lines(Xs, SC2$curve.perchg, lwd=2, col=2)
lines(Xs, SC3$curve.perchg, lwd=1, col=4)
rug(SC1$Tnp1, col=rgb(0,0,0,0.3))
rug(SC2$Tnp1, col=rgb(1,0,0,0.3))
rug(SC3$Tnp1, col=rgb(0,0,1,0.3), tcl=-.75) #
## End(Not run)
</code></pre>

<hr>
<h2 id='slmomco'>Reversed Cumulative Distribution Function (Survival Function) of the Distributions</h2><span id='topic+slmomco'></span>

<h3>Description</h3>

<p>This function acts as an alternative front end to <code><a href="#topic+par2cdf">par2cdf</a></code> but reverses the probability to form the survival function. Conceptually, <code class="reqn">S(F) = 1 - F(x)</code> where <code class="reqn">F(x)</code> is <code><a href="#topic+plmomco">plmomco</a></code> (implemented by <code><a href="#topic+par2cdf">par2cdf</a></code>). The nomenclature of the <code><a href="#topic+slmomco">slmomco</a></code> function is to mimic that of built-in <span class="rlang"><b>R</b></span> functions that interface with distributions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>slmomco(x, para)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="slmomco_+3A_x">x</code></td>
<td>
<p>A real value.</p>
</td></tr>
<tr><td><code id="slmomco_+3A_para">para</code></td>
<td>
<p>The parameters from <code><a href="#topic+lmom2par">lmom2par</a></code> or similar.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Exceedance probability (<code class="reqn">0 \le S \le 1</code>) for <code>x</code>.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>See Also</h3>

<p><code><a href="#topic+dlmomco">dlmomco</a></code>, <code><a href="#topic+plmomco">plmomco</a></code>, <code><a href="#topic+qlmomco">qlmomco</a></code>, <code><a href="#topic+rlmomco">rlmomco</a></code>, <code><a href="#topic+add.lmomco.axis">add.lmomco.axis</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>para &lt;- vec2par(c(0,1),type='nor') # Standard Normal parameters
exceed &lt;- slmomco(1, para) # percentile of one standard deviation
</code></pre>

<hr>
<h2 id='stttlmomco'>Scaled Total Time on Test Transform of Distributions</h2><span id='topic+stttlmomco'></span>

<h3>Description</h3>

<p>This function computes the Scaled Total Time on Test Transform Quantile Function for a quantile function <code class="reqn">x(F)</code> (<code><a href="#topic+par2qua">par2qua</a></code>, <code><a href="#topic+qlmomco">qlmomco</a></code>).  The TTT is defined by Nair et al. (2013, p. 173) as
</p>
<p style="text-align: center;"><code class="reqn">\phi(u) = \frac{1}{\mu}\left[(1-u)x(u) + \int_0^u x(p)\; \mathrm{d}p \right]\mbox{,}</code>
</p>

<p>where <code class="reqn">\phi(u)</code> is the scaled  total time on test for nonexceedance probability <code class="reqn">u</code>, and <code class="reqn">x(u)</code> is a constant  for <code class="reqn">x(F = u)</code>. The <code class="reqn">\phi(u)</code> is also expressible in terms of total time on test transform quantile function (<code class="reqn">T(u)</code>, <code><a href="#topic+tttlmomco">tttlmomco</a></code>) as
</p>
<p style="text-align: center;"><code class="reqn">\phi(u) = \frac{T(u)}{\mu}\mbox{,}</code>
</p>

<p>where <code class="reqn">\mu</code> is the conditional mean (<code><a href="#topic+cmlmomco">cmlmomco</a></code>) at <code class="reqn">u = 0</code> and the later definition is the basis for implementation in <span class="pkg">lmomco</span>. The integral in the first definition is closely related to the structure of the reversed residual mean quantile function (<code class="reqn">R(u)</code>, <code><a href="#topic+rrmlmomco">rrmlmomco</a></code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>stttlmomco(f, para)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="stttlmomco_+3A_f">f</code></td>
<td>
<p>Nonexceedance probability (<code class="reqn">0 \le F \le 1</code>).</p>
</td></tr>
<tr><td><code id="stttlmomco_+3A_para">para</code></td>
<td>
<p>The parameters from <code><a href="#topic+lmom2par">lmom2par</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Scaled total time on test value for <code class="reqn">F</code>.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Nair, N.U., Sankaran, P.G., and Balakrishnan, N., 2013, Quantile-based reliability analysis: Springer, New York.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+qlmomco">qlmomco</a></code>, <code><a href="#topic+tttlmomco">tttlmomco</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># It is easiest to think about residual life as starting at the origin,
# but for this example, let us set the lower limit at 100 days.
A &lt;- vec2par(c(100, 2649, 2.11), type="gov")
f &lt;- 0.47  # Both computations of Phi show 0.6455061
"afunc" &lt;- function(p) { return(par2qua(p,A,paracheck=FALSE)) }
tmpa &lt;- 1/cmlmomco(f=0, A); tmpb &lt;- (1-f)*par2qua(f,A,paracheck=FALSE)
Phiu1 &lt;- tmpa * ( tmpb + integrate(afunc,0,f)$value )
Phiu2 &lt;- stttlmomco(f, A)
## Not run: 
# The TTT-plot (see Nair et al. (2013, p. 173))
n &lt;- 30; X &lt;- sort(rlmomco(n, A)); lmr &lt;- lmoms(X)  # simulated lives and their L-moments
# recognize here that the "fit" is to the lifetime data themselves and not to special
# curves or projections of the data to other scales
"Phir" &lt;- function(r, X, sort=TRUE) {
   n &lt;- length(X); if(sort) X &lt;- sort(X)
   if(r == 0) return(0) # can use 2:r as X_{0:n} is zero
   Tau.rOFn &lt;- sapply(1:r, function(j) { Xlo &lt;- ifelse((j-1) == 0, 0, X[(j-1)]);
                                         return((n-j+1)*(X[j] - Xlo)) })
   return(sum(Tau.rOFn))
}
Xbar &lt;- mean(X); rOFn &lt;- (1:n)/n # Nair et al. (2013) are clear r/n used in the Phi(u)
Phi &lt;- sapply(1:n, function(r) { return(Phir(r,X, sort=FALSE)) }) / (n*Xbar)
layout(matrix(1:3, ncol=1))
plot(rOFn, Phi, type="b",
     xlab="NONEXCEEDANCE PROBABILITY", ylab="SCALED TOTAL TIME ON TEST")
lines(rOFn, stttlmomco(rOFn, A), lwd=2, col=8) # solid grey, the parent distribution
par1 &lt;- pargov(lmr); par2 &lt;- pargov(lmr, xi=min(X)) # notice attempt to "fit at minimum"
lines(pp(X), stttlmomco(rOFn, par1)) # now Weibull (i/(n+1)) being used for F via pp()
lines(pp(X), stttlmomco(rOFn, par2), lty=2) # perhaps better, but could miss short lives
F &lt;- nonexceeds(f01=TRUE)
plot(pp(X), sort(X), xlab="NONEXCEEDANCE PROBABILITY", ylab="TOTAL TIME ON TEST (DAYS)")
lines(F, qlmomco(F, A), lwd=2, col=8) # the parent again
lines(F, qlmomco(F, par1), lty=1); lines(F, qlmomco(F, par2), lty=2) # two estimated fits
plot(F,  lrzlmomco(F, par2), col=2, type="l")  # Lorenz curve from L-moment fit (red)
lines(F, bfrlmomco(F, par2), col=3, lty=2) # Bonferroni curve from L-moment fit (green)
lines(F, lkhlmomco(F, par2), col=4, lty=4) # Leimkuhler curve from L-moment fit (blue)
lines(rOFn, Phi) # Scaled Total Time on Test

## End(Not run)
</code></pre>

<hr>
<h2 id='supdist'>The Support of a Distribution based on the Parameters </h2><span id='topic+supdist'></span>

<h3>Description</h3>

<p>This function takes a parameter object, such as that returned by <code><a href="#topic+lmom2par">lmom2par</a></code>, and computes the support (the lower and upper bounds, <code class="reqn">\{L, U\}</code>) of the distribution given by the parameters. The computation is based on two calls to <code><a href="#topic+par2qua">par2qua</a></code> for the parameters in argument <code>para</code> (<code class="reqn">\Theta</code>) and nonexceedance probabilities <code class="reqn">F \in \{0, 1\}</code>:
</p>
<pre>lower &lt;- par2qua(0, para)
upper &lt;- par2qua(1, para)</pre>
<p>The quality of <code class="reqn">\{L, U\}</code> is dependent of the handling of <code class="reqn">F \in \{0,1\}</code> internal to each quantile function. Across the suite of distributions supported by <span class="pkg">lmomco</span>, potential applications, and parameter combinations, it difficult to ensure numerical results for the respective <code class="reqn">\{L, U\}</code> are either very small, are large, or are (or should be) infinite. The distinction is sometimes difficult depending how fast the tail(s) of a distribution is (are) either approaching a limit as <code class="reqn">F</code> respectively approaches <code class="reqn">0^{+}</code> or <code class="reqn">1^{-}</code>.
</p>
<p>The intent of this function is to provide a unified portal for <code class="reqn">\{L, U\}</code> estimation. Most of the time <span class="rlang"><b>R</b></span> (and <span class="pkg">lmomco</span>) do the right thing anyway and the further overhead within the parameter estimation suite of functions in <span class="pkg">lmomco</span> is not implemented.
</p>
<p>The support returned by this function might be useful in extended application development involving probability density functions <code>pdfCCC</code> (<code class="reqn">f(x,\Theta)</code>, see <code><a href="#topic+dlmomco">dlmomco</a></code>) and cumulative distribution functions <code>cdfCCC</code> (<code class="reqn">F(x,\Theta)</code>, see <code><a href="#topic+plmomco">plmomco</a></code>) functions&mdash;both of these functions use as their primary argument a value <code class="reqn">x</code> that exists along the real number line.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>supdist(para, trapNaN=FALSE, delexp=0.5, paracheck=TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="supdist_+3A_para">para</code></td>
<td>
<p>The parameters of the distribution.</p>
</td></tr>
<tr><td><code id="supdist_+3A_trapnan">trapNaN</code></td>
<td>
<p>A logical influencing how <code>NaN</code> are handled (see Note).</p>
</td></tr>
<tr><td><code id="supdist_+3A_delexp">delexp</code></td>
<td>
<p>The magnitude of the decrementing of the exponent to search down and up from.  A very long-tailed but highly peaked distribution might require this to be smaller than default.</p>
</td></tr>
<tr><td><code id="supdist_+3A_paracheck">paracheck</code></td>
<td>
<p>A logical controlling whether the parameters are checked for validity.</p>
</td></tr>
<tr><td><code id="supdist_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> is returned.
</p>
<table>
<tr><td><code>type</code></td>
<td>
<p>Three character (minimum) distribution type (for example, <code>type="gev"</code>);</p>
</td></tr>
<tr><td><code>support</code></td>
<td>
<p>The support (or range) of the fitted distribution;</p>
</td></tr>
<tr><td><code>nonexceeds</code></td>
<td>
<p>The nonexceedance probabilities at the computed support.</p>
</td></tr>
<tr><td><code>fexpons</code></td>
<td>
<p>A vector indicating how the respective lower and upper boundaries were arrived at (see Note); and</p>
</td></tr>
<tr><td><code>finite</code></td>
<td>
<p>A logical on each entry of the <code>support</code> with a preemptive call by the <code>is.finite</code> function in <span class="rlang"><b>R</b></span>.</p>
</td></tr>
<tr><td><code>source</code></td>
<td>
<p>An attribute identifying the computational source
of the distribution support: &ldquo;supdist&rdquo;.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Concerning <code>fexpons</code>, for the returned vectors of length 2, index 1 is for <code class="reqn">\{L\}</code> and index 2 is for <code class="reqn">\{U\}</code>. If an entry in <code>fexpons</code> is <code>NA</code>, then <code class="reqn">F = 0</code> or <code class="reqn">F = 1</code> for the respective bound was possible. And even if <code>trapNaN</code> is <code>TRUE</code>, no further refinement on the bounds was attempted.
</p>
<p>On the otherhand, if <code>trapNaN</code> is <code>TRUE</code> and if the bounds <code class="reqn">\{L\}</code> and (or) <code class="reqn">\{U\}</code> is not <code>NA</code>, then an attempt was made to move away from <code class="reqn">F \in \{0,1\}</code> in incremental integer exponent from <code class="reqn">0^{+}</code> or <code class="reqn">1^{-}</code> until a <code>NaN</code> was not encountered. The integer exponents are <code class="reqn">i \in [-(\phi), -(\phi - 1), \ldots, -4]</code>, where <code class="reqn">\phi</code> <code>= .Machine$sizeof.longdouble</code> and <code class="reqn">-4</code> is a hardwired limit (1 part in 10,000). In the last example in the Examples section, the <code class="reqn">\{U\}</code> for <code class="reqn">F=1</code> quantile is <code>NaN</code> but <code class="reqn">1 - 10^i</code> for which <code class="reqn">i = -16</code>, which also is the <code>.Machine$sizeof.longdouble</code> on the author's development platform.
</p>
<p>At first release, it seems there was justification in triggering this to <code>TRUE</code> if a quantile function returns a <code>NA</code> when asked for <code class="reqn">F = 0</code> or <code class="reqn">F = 1</code>&mdash;some quantile functions partially trapped <code>NaN</code>s themselves. So even if <code>trapNaN == FALSE</code>, it is triggered to <code>TRUE</code> if a <code>NA</code> is discovered as described. <em>Users are encouraged to discuss adaptions or changes to the implementation of <code>supdist</code> with the author.</em>
</p>
<p>Thus it should be considered a feature of <code>supdist</code> that should a quantile function already trap errors at either <code class="reqn">F = 0</code> or <code class="reqn">F = 1</code> and return <code>NA</code>, then <code>trapNaN</code> is internally set to <code>TRUE</code> regardless of being originally <code>FALSE</code> and the preliminary limit is reset to <code>NaN</code>. The Rice distribution <code><a href="#topic+quarice">quarice</a></code> is one such example that internally already traps an <code class="reqn">F = 1</code> by returning <code class="reqn">x(F{=}1) = </code><code>NA</code>.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>See Also</h3>

<p><code><a href="#topic+lmom2par">lmom2par</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>lmr &lt;- lmoms(c(33, 37, 41, 54, 78, 91, 100, 120, 124))
supdist(lmom2par(lmr, type="gov" )) # Lower = 27.41782, Upper = 133.01470
supdist(lmom2par(lmr, type="gev" )) # Lower = -Inf,     Upper = 264.4127

supdist(lmom2par(lmr, type="wak" ))               # Lower = 16.43722, Upper = NaN
supdist(lmom2par(lmr, type="wak" ), trapNaN=TRUE) # Lower = 16.43722, Upper = 152.75126
#$support  16.43722  152.75126
#$fexpons        NA  -16
#$finite       TRUE  TRUE
## Not run: 
para &lt;- vec2par(c(0.69, 0.625), type="kmu") # very flat tails and narrow peak!
supdist(para, delexp=1   )$support # [1] 0        NaN
supdist(para, delexp=0.5 )$support # [1] 0.000000 3.030334
supdist(para, delexp=0.05)$support # [1] 0.000000 3.155655
# This distribution appears to have a limit at PI and the delexp=0.5

## End(Not run)
</code></pre>

<hr>
<h2 id='T2prob'>Convert a Vector of T-year Return Periods to Annual Nonexceedance Probabilities</h2><span id='topic+T2prob'></span>

<h3>Description</h3>

<p>This function converts a vector of <code class="reqn">T</code>-year return periods to annual nonexceedance probabilities <code class="reqn">F</code>
</p>
<p style="text-align: center;"><code class="reqn">F = 1 - \frac{1}{T}\mbox{,}</code>
</p>

<p>where <code class="reqn">0 \le F \le 1</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>T2prob(T)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="T2prob_+3A_t">T</code></td>
<td>
<p>A vector of <code class="reqn">T</code>-year return periods.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of annual nonexceedance probabilities.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>See Also</h3>

<p><code><a href="#topic+prob2T">prob2T</a></code>, <code><a href="#topic+nonexceeds">nonexceeds</a></code>, <code><a href="#topic+add.lmomco.axis">add.lmomco.axis</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>T &lt;- c(1, 2, 5, 10, 25, 50, 100, 250, 500)
F &lt;- T2prob(T)
</code></pre>

<hr>
<h2 id='tau34sq.normtest'>The Tau34-squared Test: A Normality Test based on L-skew and L-kurtosis and an Elliptical Rejection Region on an L-moment Ratio Diagram</h2><span id='topic+tau34sq.normtest'></span>

<h3>Description</h3>

<p>This function performs highly intriguing test for normality using L-skew (<code class="reqn">\tau_3</code>) and L-kurtosis (<code class="reqn">\tau_4</code>) computed from an input vector of data. The test is simultaneously focused on L-skew and L-kurtosis. Harri and Coble (2011) presented two types of normality tests based on these two L-moment ratios. Their first test is dubbed the <code class="reqn">\tau_3\tau_4</code> test. Those authors however conclude that a second test dubbed the <code class="reqn">\tau^2_{3,4}</code> test &ldquo;in particular shows consistently high power against [sic] symmetric distributions and also against [sic] skewed distributions and is a powerful test that can be applied against a variety of distributions.&rdquo;
</p>
<p>A sample-size transformed quantity of the sample L-skew (<code class="reqn">\hat\tau_3</code>) is
</p>
<p style="text-align: center;"><code class="reqn">Z(\tau_3) = \hat\tau_3 \times \frac{1}{\sqrt{0.1866/n + 0.8/n^2}}\mathrm{,}</code>
</p>

<p>which has an approximate Standard Normal distribution. A sample-sized transformation of the sample L-kurtosis (<code class="reqn">\hat\tau_4</code>) is
</p>
<p style="text-align: center;"><code class="reqn">Z(\tau_4)' = \hat\tau_4 \times \frac{1}{\sqrt{0.0883/n}}\mathrm{,}</code>
</p>

<p>which also has an approximate Standard Normal distribution. A superior approximation for the variate of the Standard Normal distribution however is
</p>
<p style="text-align: center;"><code class="reqn">Z(\tau_4) = \hat\tau_4 \times \frac{1}{\sqrt{0.0883/n + 0.68/n^2 + 4.9/n^3}}\mathrm{,}</code>
</p>

<p>and is highly preferred for the algorithms in <code><a href="#topic+tau34sq.normtest">tau34sq.normtest</a></code>.
</p>
<p>The <code class="reqn">\tau_3\tau_4</code> test (not implemented in <code><a href="#topic+tau34sq.normtest">tau34sq.normtest</a></code>) by Harri and Coble (2011) can be constructed from the <code class="reqn">Z(\tau_3)</code> and <code class="reqn">Z(\tau_4)</code> statistics as shown, and a square rejection region constructed on an L-moment ratio diagram of L-skew versus L-kurtosis. However, the preferred method is the &ldquo;Tau34-squared&rdquo; test <code class="reqn">\tau^2_{3,4}</code> that can be developed by expressing an ellipse on the L-moment ratio diagram of L-skew versus L-kurtosis. The <code class="reqn">\tau^2_{3,4}</code> test statistic is defined as
</p>
<p style="text-align: center;"><code class="reqn">\tau^2_{3,4} = Z(\tau_3)^2 + Z(\tau_4)^2\mathrm{,}</code>
</p>

<p>which is approximately distributed as a <code class="reqn">\chi^2</code> distribution with two degrees of freedom. The <code class="reqn">\tau^2_{3,4}</code> also is the expression of the ellipical region on the L-moment ratio diagram of L-skew versus L-kurtosis.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tau34sq.normtest(x, alpha=0.05, pvalue.only=FALSE, getlist=TRUE,
                    useHoskingZt4=TRUE, verbose=FALSE, digits=4)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tau34sq.normtest_+3A_x">x</code></td>
<td>
<p>A vector of values.</p>
</td></tr>
<tr><td><code id="tau34sq.normtest_+3A_alpha">alpha</code></td>
<td>
<p>The <code class="reqn">\alpha</code> significance level.</p>
</td></tr>
<tr><td><code id="tau34sq.normtest_+3A_pvalue.only">pvalue.only</code></td>
<td>
<p>Only return the p-value of the test and superceeds the <code>getlist</code> argument.</p>
</td></tr>
<tr><td><code id="tau34sq.normtest_+3A_getlist">getlist</code></td>
<td>
<p>Return a list of salient parts of the computations.</p>
</td></tr>
<tr><td><code id="tau34sq.normtest_+3A_usehoskingzt4">useHoskingZt4</code></td>
<td>
<p>J.R.M. Hosking provided a better approximation <code class="reqn">Z(\tau_4)</code> in personal correspondance to Harri and Coble (2011) than the one <code class="reqn">Z(\tau_4)'</code> they first presented in their paper. This argument is a logical on whether this approximation should be used. It is highly recommended that <code>useHoskingZt4</code> be left at the default setting.</p>
</td></tr>
<tr><td><code id="tau34sq.normtest_+3A_verbose">verbose</code></td>
<td>
<p>Print a nice summary of the test.</p>
</td></tr>
<tr><td><code id="tau34sq.normtest_+3A_digits">digits</code></td>
<td>
<p>How many digits to report in the summary.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> is returned if <code>getlist</code> argument is true. The list contents are
</p>
<table>
<tr><td><code>SampleTau3</code></td>
<td>
<p>The sample L-skew.</p>
</td></tr>
<tr><td><code>SampleTau4</code></td>
<td>
<p>The sample L-kurtosis.</p>
</td></tr>
<tr><td><code>Ztau3</code></td>
<td>
<p>The Z-value of <code class="reqn">\tau_3</code>.</p>
</td></tr>
<tr><td><code>Ztau4</code></td>
<td>
<p>The Z-value of <code class="reqn">\tau_4</code>.</p>
</td></tr>
<tr><td><code>Tau34sq</code></td>
<td>
<p>The <code class="reqn">\tau^2_{3,4}</code> value.</p>
</td></tr>
<tr><td><code>ChiSq.2df</code></td>
<td>
<p>The Chi-squared distribution nonexceedance probability.</p>
</td></tr>
<tr><td><code>pvalue</code></td>
<td>
<p>The p-value of the test (original notation for package).</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>The p-value of the test (updated to align with many other hypothesis test styles).</p>
</td></tr>
<tr><td><code>isSig</code></td>
<td>
<p>A logical on whether the p-value is &ldquo;statistically significant&rdquo; based on the <code class="reqn">\alpha</code> value.</p>
</td></tr>
<tr><td><code>source</code></td>
<td>
<p>The source of the parameters: &ldquo;tau34sq.normtest&rdquo;.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Harri, A., and Coble, K.H., 2011, Normality testing&mdash;Two new tests using L-moments: Journal of Applied Statistics, v. 38, no. 7, pp. 1369&ndash;1379.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pdfnor">pdfnor</a></code>, <code><a href="#topic+plotlmrdia">plotlmrdia</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>HarriCoble &lt;- tau34sq.normtest(rnorm(20), verbose=TRUE)
## Not run: 
# If this basic algorithm is run repeatedly with different arguments,
# then the first three rows of table 1 in Harri and Coble (2011) can
# basically be repeated. Testing by WHA indicates that even better
# empirical alphas will be computed compared to those reported in that table 1.
# R --vanilla --silent --args n 20 s 100 &lt; t34.R
# Below is file t34.R
library(batch) # for command line argument parsing
a &lt;- 0.05; n &lt;- 50; s &lt;- 5E5 # defaults
parseCommandArgs() # it will echo out those arguments on command line
sims &lt;- sapply(1:s, function(i) {
          return(tau34sq.normtest(rnorm(n),
                 pvalue.only=TRUE)) })
p &lt;- length(sims[sims &lt;= a])
print("RESULTS(Alpha, SampleSize, EmpiricalAlpha)")
print(c(a, n, p/s))

## End(Not run)
</code></pre>

<hr>
<h2 id='theoLmoms'>The Theoretical L-moments and L-moment Ratios using Integration of the Quantile Function</h2><span id='topic+theoLmoms'></span>

<h3>Description</h3>

<p>Compute the theoretrical L-moments for a vector. A theoretrical L-moment in integral form is
</p>
<p style="text-align: center;"><code class="reqn"> \lambda_r = \frac{1}{r}
                               \sum^{r-1}_{k=0}{(-1)^k {r-1 \choose k}
        \frac{r!\:I_r}{(r-k-1)!\,k!}
       } \mbox{,}</code>
</p>

<p>in which
</p>
<p style="text-align: center;"><code class="reqn"> I_r = \int^1_0 x(F) \times F^{r-k-1}(1-F)^{k}\,\mathrm{d}F \mbox{,}</code>
</p>

<p>where <code class="reqn">x(F)</code> is the quantile function of the random variable <code class="reqn">X</code> for nonexceedance probability <code class="reqn">F</code>, and <code class="reqn">r</code> represents the order of the L-moments. This function actually dispatches to <code><a href="#topic+theoTLmoms">theoTLmoms</a></code> with <code>trim=0</code> argument.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>theoLmoms(para, nmom=5, minF=0, maxF=1, quafunc=NULL,
                nsim=50000, fold=5,
                silent=TRUE, verbose=FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="theoLmoms_+3A_para">para</code></td>
<td>
<p>A distribution parameter object such as from <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
<tr><td><code id="theoLmoms_+3A_nmom">nmom</code></td>
<td>
<p>The number of moments to compute. Default is 5.</p>
</td></tr>
<tr><td><code id="theoLmoms_+3A_minf">minF</code></td>
<td>
<p>The end point of nonexceedance probability in which to perform the integration. Try setting to non-zero (but very small)  if the integral is divergent.</p>
</td></tr>
<tr><td><code id="theoLmoms_+3A_maxf">maxF</code></td>
<td>
<p>The end point of nonexceedance probability in which to perform the integration. Try setting to non-unity (but still very close [perhaps <code>1 - minF</code>]) if the integral is divergent.</p>
</td></tr>
<tr><td><code id="theoLmoms_+3A_quafunc">quafunc</code></td>
<td>
<p>An optional and arbitrary quantile function that simply needs to except a nonexceedance probability and the parameter object in <code>para</code>. This is a feature that permits computation of the L-moments of a quantile function that does not have to be implemented in the greater overhead hassles of the <span class="pkg">lmomco</span> style. This feature might be useful for estimation of quantile function mixtures or those distributions not otherwise implemented in this package.</p>
</td></tr>
<tr><td><code id="theoLmoms_+3A_nsim">nsim</code></td>
<td>
<p>Simulation size for Monte Carlo integration is such is internally deemed necessary (see <code>silent</code> argument).</p>
</td></tr>
<tr><td><code id="theoLmoms_+3A_fold">fold</code></td>
<td>
<p>The number of fractions or number of folds of <code>nsim</code>, which in other words, means that <code>nsim</code> is divided by <code>folds</code> and a loop creating <code>folds</code> integrations of <code>nsim/folds</code> is used from which the mean and mean absolute error of the integrand are computed. This is to try to recover similar output as <code>integrate()</code>.</p>
</td></tr>
<tr><td><code id="theoLmoms_+3A_silent">silent</code></td>
<td>
<p>The argument of <code>silent</code> for the <code>try()</code> operation wrapped on <code>integrate()</code>. If set true and the integral is probability divergent, Monte Carlo integration is triggered using <code>nsim</code> and <code>folds</code>. The user would have to set <code>verbose=TRUE</code> to then acquire the returned table in <code>integration_table</code> of the integration passes including those are or are not Monte Carlo.</p>
</td></tr>
<tr><td><code id="theoLmoms_+3A_verbose">verbose</code></td>
<td>
<p>Toggle verbose output. Because the <span class="rlang"><b>R</b></span> function <code>integrate</code> is used to perform the numerical integration, it might be useful to see selected messages regarding the numerical integration.</p>
</td></tr>
<tr><td><code id="theoLmoms_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> is returned.
</p>
<table>
<tr><td><code>lambdas</code></td>
<td>
<p>Vector of the TL-moments. First element is <code class="reqn">\lambda_1</code>, second element is <code class="reqn">\lambda_2</code>, and so on.</p>
</td></tr>
<tr><td><code>ratios</code></td>
<td>
<p>Vector of the L-moment ratios. Second element is <code class="reqn">\tau_2</code>, third element is <code class="reqn">\tau_3</code> and so on.</p>
</td></tr>
<tr><td><code>trim</code></td>
<td>
<p>Level of symmetrical trimming used in the computation, which will equal zero (the ordinary L-moments) because this function dispatches to <code><a href="#topic+theoTLmoms">theoTLmoms</a></code>.</p>
</td></tr>
<tr><td><code>source</code></td>
<td>
<p>An attribute identifying the computational source of the L-moments: &ldquo;theoLmoms&rdquo;.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Hosking, J.R.M., 1990, L-moments&mdash;Analysis and estimation of distributions using linear combinations of order statistics: Journal of the Royal Statistical Society, Series B, v. 52, pp. 105&ndash;124.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+theoTLmoms">theoTLmoms</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>para &lt;- vec2par(c(0,1), type='nor') # standard normal
TL00 &lt;- theoLmoms(para) # compute ordinary L-moments
</code></pre>

<hr>
<h2 id='theoLmoms.max.ostat'>Compute the Theoretical L-moments of a Distribution Distribution based on System of Maximum Order Statistic Expectations</h2><span id='topic+theoLmoms.max.ostat'></span><span id='topic+theoLmoms.min.ostat'></span>

<h3>Description</h3>

<p>This function computes the theoretical L-moments of a distribution by the following
</p>
<p style="text-align: center;"><code class="reqn">
\lambda_r = (-1)^{r-1} \sum_{k=1}^r (-1)^{r-k}k^{-1}{r-1 \choose k-1}{r+k-2 \choose k-1}\mathrm{E}[X_{1:k}]
</code>
</p>

<p>for the minima  (<code><a href="#topic+theoLmoms.min.ostat">theoLmoms.min.ostat</a></code>, theoretical L-moments from the minima of order statistics) or
</p>
<p style="text-align: center;"><code class="reqn">
\lambda_r = \sum_{k=1}^r (-1)^{r-k}k^{-1}{r-1 \choose k-1}{r+k-2 \choose k-1}\mathrm{E}[X_{k:k}]
</code>
</p>

<p>for the maxima (<code><a href="#topic+theoLmoms.max.ostat">theoLmoms.max.ostat</a></code>, theoretical L-moments from the maxima of order statistics). The functions <code><a href="#topic+expect.min.ostat">expect.min.ostat</a></code> and <code><a href="#topic+expect.max.ostat">expect.max.ostat</a></code> compute the minima (<code class="reqn">\mathrm{E}[X_{1:k}]</code>) and maxima (<code class="reqn">\mathrm{E}[X_{k:k}]</code>), respectively.
</p>
<p>If <code>qua != NULL</code>, then the first expectation equation shown under <code><a href="#topic+expect.max.ostat">expect.max.ostat</a></code> is used for the order statistic expectations and any function set in <code>cdf</code> and <code>pdf</code> is ignored.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>theoLmoms.max.ostat(para=NULL, cdf=NULL, pdf=NULL, qua=NULL,
                    nmom=4, switch2minostat=FALSE, showterms=FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="theoLmoms.max.ostat_+3A_para">para</code></td>
<td>
<p>A distribution parameter list from a function such as <code>lmom2par</code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
<tr><td><code id="theoLmoms.max.ostat_+3A_cdf">cdf</code></td>
<td>
<p>CDF of the distribution for the parameters.</p>
</td></tr>
<tr><td><code id="theoLmoms.max.ostat_+3A_pdf">pdf</code></td>
<td>
<p>PDF of the distribution for the parameters.</p>
</td></tr>
<tr><td><code id="theoLmoms.max.ostat_+3A_qua">qua</code></td>
<td>
<p>Quantile function for the parameters.</p>
</td></tr>
<tr><td><code id="theoLmoms.max.ostat_+3A_nmom">nmom</code></td>
<td>
<p>The number of L-moments to compute.</p>
</td></tr>
<tr><td><code id="theoLmoms.max.ostat_+3A_switch2minostat">switch2minostat</code></td>
<td>
<p>A logical in which a switch to the expectations of minimum order statistics will be used and <code><a href="#topic+expect.min.ostat">expect.min.ostat</a></code> instead of <code><a href="#topic+expect.max.ostat">expect.max.ostat</a></code> will be used with expected small change in overall numerics. The function <br /> <code><a href="#topic+theoLmoms.min.ostat">theoLmoms.min.ostat</a></code> provides a direct interface for L-moment computation by minimum order statistics.</p>
</td></tr>
<tr><td><code id="theoLmoms.max.ostat_+3A_showterms">showterms</code></td>
<td>
<p>A logical controlling just a reference message that will show the multipliers on each of the order statistic minima or maxima that comprise the terms within the summations in the above formulae (see Asquith, 2011, p. 95).</p>
</td></tr>
<tr><td><code id="theoLmoms.max.ostat_+3A_...">...</code></td>
<td>
<p>Optional, but likely, arguments to pass to <code><a href="#topic+expect.min.ostat">expect.min.ostat</a></code> or <br /><code><a href="#topic+expect.max.ostat">expect.max.ostat</a></code>. Such arguments will likely tailor the integration limits that can be specific for the distribution in question. Further these arguments might be needed for the cumulative distribution function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> is returned.
</p>
<table>
<tr><td><code>lambdas</code></td>
<td>
<p>Vector of the L-moments: first element is
<code class="reqn">\lambda_1</code>, second element is <code class="reqn">\lambda_2</code>, and so on.</p>
</td></tr>
<tr><td><code>ratios</code></td>
<td>
<p>Vector of the L-moment ratios. Second element is
<code class="reqn">\tau</code>, third element is <code class="reqn">\tau_3</code> and so on.</p>
</td></tr>
<tr><td><code>trim</code></td>
<td>
<p>Level of symmetrical trimming used in the computation, which will equal <code>NULL</code> until trimming support is made.</p>
</td></tr>
<tr><td><code>leftrim</code></td>
<td>
<p>Level of left-tail trimming used in the computation, which will equal <code>NULL</code> until trimming support is made.</p>
</td></tr>
<tr><td><code>rightrim</code></td>
<td>
<p>Level of right-tail trimming used in the computation, which will equal <code>NULL</code> until trimming support is made.</p>
</td></tr>
<tr><td><code>source</code></td>
<td>
<p>An attribute identifying the computational source of the L-moments: &ldquo;theoLmoms.max.ostat&rdquo;.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Perhaps one of the neater capabilities that the <code>theoLmoms.max.ostat</code> and <code>theoLmoms.min.ostat</code> functions provide is for computing L-moments that are not analytically available from other authors or have no analytical solution.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Asquith, W.H., 2011, Distributional analysis with L-moment statistics using the R environment for statistical computing: Createspace Independent Publishing Platform, ISBN 978&ndash;146350841&ndash;8.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+theoLmoms">theoLmoms</a></code>, <code><a href="#topic+expect.min.ostat">expect.min.ostat</a></code>, <code><a href="#topic+expect.max.ostat">expect.max.ostat</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
para &lt;- vec2par(c(40,20), type='nor')
A1 &lt;- theoLmoms.max.ostat(para=para, cdf=cdfnor, pdf=pdfnor, switch2minostat=FALSE)
A2 &lt;- theoLmoms.max.ostat(para=para, cdf=cdfnor, pdf=pdfnor, switch2minostat=TRUE)
B1 &lt;- theoLmoms.max.ostat(para=para, qua=quanor, switch2minostat=FALSE)
B2 &lt;- theoLmoms.max.ostat(para=para, qua=quanor, switch2minostat=TRUE)
print(A1$ratios[4]) # reports 0.1226017
print(A2$ratios[4]) # reports 0.1226017
print(B1$ratios[4]) # reports 0.1226012
print(B2$ratios[4]) # reports 0.1226012
# Theoretical value = 0.122601719540891.
# Confirm operational with native R-code being used inside lmomco functions
# Symmetrically correct on whether minima or maxima are used, but some
# Slight change when qnorm() used instead of dnorm() and pnorm().

para &lt;- vec2par(c(40,20), type='exp')
A1 &lt;- theoLmoms.max.ostat(para=para, cdf=cdfexp, pdf=pdfexp, switch2minostat=FALSE)
A2 &lt;- theoLmoms.max.ostat(para=para, cdf=cdfexp, pdf=pdfexp, switch2minostat=TRUE)
B1 &lt;- theoLmoms.max.ostat(para=para, qua=quaexp, switch2minostat=FALSE)
B2 &lt;- theoLmoms.max.ostat(para=para, qua=quaexp, switch2minostat=TRUE)
print(A1$ratios[4]) # 0.1666089
print(A2$ratios[4]) # 0.1666209
print(B1$ratios[4]) # 0.1666667
print(B2$ratios[4]) # 0.1666646
# Theoretical value = 0.1666667

para &lt;- vec2par(c(40,20), type='ray')
A1 &lt;- theoLmoms.max.ostat(para=para, cdf=cdfray, pdf=pdfray, switch2minostat=FALSE)
A2 &lt;- theoLmoms.max.ostat(para=para, cdf=cdfray, pdf=pdfray, switch2minostat=TRUE)
B1 &lt;- theoLmoms.max.ostat(para=para, qua=quaray, switch2minostat=FALSE)
B2 &lt;- theoLmoms.max.ostat(para=para, qua=quaray, switch2minostat=TRUE)
print(A1$ratios[4]) # 0.1053695
print(A2$ratios[4]) # 0.1053695
print(B1$ratios[4]) # 0.1053636
print(B2$ratios[4]) # 0.1053743
# Theoretical value = 0.1053695

## End(Not run)
## Not run: 
# The Rice distribution is complex and tailoring of the integration
# limits is needed to effectively trap errors, the limits for the
# Normal distribution above are infinite so no granular control is needed.
para &lt;- vec2par(c(30,10), type="rice")
theoLmoms.max.ostat(para=para, cdf=cdfrice, pdf=pdfrice,
                    lower=0, upper=.Machine$double.max)

## End(Not run)
## Not run: 
para &lt;- vec2par(c(0.6, 1.5), type="emu")
theoLmoms.min.ostat(para, cdf=cdfemu, pdf=pdfemu,
                    lower=0, upper=.Machine$double.max)
theoLmoms.min.ostat(para, cdf=cdfemu, pdf=pdfemu, yacoubsintegral = FALSE,
                    lower=0, upper=.Machine$double.max)

para &lt;- vec2par(c(0.6, 1.5), type="kmu")
theoLmoms.min.ostat(para, cdf=cdfkmu, pdf=pdfkmu,
                    lower=0, upper=.Machine$double.max)
theoLmoms.min.ostat(para, cdf=cdfkmu, pdf=pdfkmu, marcumQ = FALSE,
                    lower=0, upper=.Machine$double.max)

## End(Not run)
## Not run: 
# The Normal distribution is used on the fly for the Rice for high to
# noise ratios (SNR=nu/alpha &gt; some threshold). This example will error out.
nu &lt;- 30; alpha &lt;- 0.5
para &lt;- vec2par(c(nu,alpha), type="rice")
theoLmoms.max.ostat(para=para, cdf=cdfrice, pdf=pdfrice,
                    lower=0, upper=.Machine$double.max)

## End(Not run)
</code></pre>

<hr>
<h2 id='theopwms'>The Theoretical Probability-Weighted Moments using Integration of the Quantile Function </h2><span id='topic+theopwms'></span>

<h3>Description</h3>

<p>Compute the theoretical probability-weighted moments (PWMs) for a distribution. A theoretical PWM in integral form is
</p>
<p style="text-align: center;"><code class="reqn"> \beta_r = \int^1_0 x(F)\,F^r\,\mathrm{d}F \mbox{,}</code>
</p>

<p>where <code class="reqn">x(F)</code> is the quantile function of the random variable <code class="reqn">X</code> for nonexceedance probability <code class="reqn">F</code> and <code class="reqn">r</code> represents the order of the PWM. This function loops across the above equation for each <code>nmom</code> set in the argument list. The function <code class="reqn">x(F)</code> is computed through the <code><a href="#topic+par2qua">par2qua</a></code> function. The distribution type is determined using the <code>type</code> attribute of the <code>para</code> argument, which is a parameter object of <span class="pkg">lmomco</span> (see <code><a href="#topic+vec2par">vec2par</a></code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>theopwms(para, nmom=5, minF=0, maxF=1, quafunc=NULL,
               nsim=50000, fold=5,
               silent=TRUE, verbose=FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="theopwms_+3A_para">para</code></td>
<td>
<p>A distribution parameter object such as that by <code><a href="#topic+lmom2par">lmom2par</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
<tr><td><code id="theopwms_+3A_nmom">nmom</code></td>
<td>
<p>The number of moments to compute. Default is 5.</p>
</td></tr>
<tr><td><code id="theopwms_+3A_minf">minF</code></td>
<td>
<p>The end point of nonexceedance probability in which to perform the integration. Try setting to non-zero (but small) if you have a divergent integral.</p>
</td></tr>
<tr><td><code id="theopwms_+3A_maxf">maxF</code></td>
<td>
<p>The end point of nonexceedance probability in which to perform the integration. Try setting to non-unity (but close) if you have a divergent integral.</p>
</td></tr>
<tr><td><code id="theopwms_+3A_quafunc">quafunc</code></td>
<td>
<p>An optional and arbitrary quantile function that simply needs to except a nonexceedance probability and the parameter object in <code>para</code>. This is a feature that permits computation of the PWMs of a quantile function that does not have to be implemented in the greater overhead hassles of the <span class="pkg">lmomco</span> style. This feature might be useful for estimation of quantile function mixtures or those distributions not otherwise implemented in this package.</p>
</td></tr>
<tr><td><code id="theopwms_+3A_nsim">nsim</code></td>
<td>
<p>Simulation size for Monte Carlo integration is such is internally deemed necessary (see <code>silent</code> argument).</p>
</td></tr>
<tr><td><code id="theopwms_+3A_fold">fold</code></td>
<td>
<p>The number of fractions or number of folds of <code>nsim</code>, which in other words, means that <code>nsim</code> is divided by <code>folds</code> and a loop creating <code>folds</code> integrations of <code>nsim/folds</code> is used from which the mean and mean absolute error of the integrand are computed. This is to try to recover similar output as <code>integrate()</code>.</p>
</td></tr>
<tr><td><code id="theopwms_+3A_silent">silent</code></td>
<td>
<p>The argument of <code>silent</code> for the <code>try()</code> operation wrapped on <code>integrate()</code>. If set true and the integral is probability divergent, Monte Carlo integration is triggered using <code>nsim</code> and <code>folds</code>. The user would have to set <code>verbose=TRUE</code> to then acquire the returned table in <code>integrations</code> of the integration passes including those are or are not Monte Carlo.</p>
</td></tr>
<tr><td><code id="theopwms_+3A_verbose">verbose</code></td>
<td>
<p>Toggle verbose output. Because the <span class="rlang"><b>R</b></span> function <code>integrate</code> is used to perform the numerical integration, it might be useful to see selected messages regarding the numerical integration.</p>
</td></tr>
<tr><td><code id="theopwms_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> is returned.
</p>
<table>
<tr><td><code>betas</code></td>
<td>
<p>The PWMs. Note that convention is the have a <code class="reqn">\beta_0</code>, but this is placed in the first index <code>i=1</code> of the <code>betas</code> vector.</p>
</td></tr>
<tr><td><code>nsim</code></td>
<td>
<p>Echo of the <code>nsim</code> argument if and only if at least one Monte Carlo integration was required, otherwise this is set to &ldquo;not needed&rdquo; on the return.</p>
</td></tr>
<tr><td><code>folds</code></td>
<td>
<p>Echo of the <code>folds</code> argument if and only if at least one Monte Carlo integration was required, otherwise this is set to &ldquo;not needed&rdquo; on the return.</p>
</td></tr>
<tr><td><code>monte_carlo</code></td>
<td>
<p>A logical vector of whether one or more Monte Carlo integrations was needed for the <code>r</code>-th index of the vector during the integrations for the <code class="reqn">r</code>-th PWM (beta).</p>
</td></tr>
<tr><td><code>source</code></td>
<td>
<p>An attribute identifying the computational source of the probability-weighted moments: &ldquo;theopwms&rdquo;.</p>
</td></tr>
<tr><td><code>integrations</code></td>
<td>
<p>If <code>verbose=TRUE</code>, then the results of the integrations are a data frame stored here. Otherwise, <code>integrations</code> is not present in the list.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Hosking, J.R.M., 1990, L-moments&ndash;Analysis and estimation of distributions using linear combinations of order statistics: Journal of the Royal Statistical Society, Series B, v. 52, p. 105&ndash;124.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+theoLmoms">theoLmoms</a></code>, <code><a href="#topic+pwm">pwm</a></code>, <code><a href="#topic+pwm2lmom">pwm2lmom</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>para     &lt;- vec2par(c(0,1),type='nor') # standard normal
the.pwms &lt;- theopwms(para) # compute PWMs
str(the.pwms)

## Not run: 
  # This example has a divergent integral triggered on the beta0. Monte Carlo (MC)
  # integration is thus triggered. The verbose=TRUE saves numerical or MC
  # integration result table to the return.
  para &lt;- vec2par(c(2,2, 1.8673636098392308, -0.1447286792099476), type="kap")
  pwmkap &lt;- lmom2pwm( lmomkap(para) )
  print(pwmkap$betas) # 0.1155903 1.2153105 0.9304619 0.7282926 0.5938137
  pwmthe &lt;- theopwms(para, nmom=5, verbose=TRUE)
  print(pwmthe$betas) # 0.1235817 1.2153104 0.9304619 0.7282926 0.5938137

  para &lt;- vec2par(c(2,2, 0.9898362024687231, -0.5140894097276032), type="kap")
  pwmkap &lt;- lmom2pwm( lmomkap(para) )
  print(pwmkap$betas) # -0.06452787  1.33177963  1.06818379  0.85911124  0.71308145
  pwmthe &lt;- theopwms(para, nmom=5, verbose=TRUE)
  print(pwmthe$betas) # -0.06901669  1.33177952  1.06818379  0.85911123  0.71308144 
## End(Not run)
</code></pre>

<hr>
<h2 id='theoTLmoms'>The Theoretical Trimmed L-moments and TL-moment Ratios using Integration of the Quantile Function</h2><span id='topic+theoTLmoms'></span>

<h3>Description</h3>

<p>Compute the theoretrical trimmed L-moments (TL-moments) for a vector. The level of symmetrical or asymmetrical trimming is
specified. A theoretrical TL-moment in integral form is
</p>
<p style="text-align: center;"><code class="reqn"> \lambda^{(t_1,t_2)}_r = \underbrace{\frac{1}{r}}_{\stackrel{\mbox{average}}{\mbox{of terms}}}
                               \sum^{r-1}_{k=0} \overbrace{(-1)^k}^{\mbox{differences}}
          \underbrace{ r-1 \choose k }_{\mbox{combinations}}
        \frac{\overbrace{(r+t_1+t_2)!}^{\mbox{sample size}}\: I^{(t_1,t_2)}_r}
     {\underbrace{(r+t_1-k-1)!}_{\mbox{left tail}}
      \underbrace{(t_2+k)!}_{\mbox{right tail}}} \mbox{, in which }</code>
</p>

<p style="text-align: center;"><code class="reqn"> I^{(t_1,t_2)}_r = \int^1_0
                              \underbrace{x(F)}_{\stackrel{\mbox{quantile}}{\mbox{function}}} \times
                              \overbrace{F^{r+t_1-k-1}}^{\mbox{left tail}}
      \overbrace{(1-F)^{t_2+k}}^{\mbox{right tail}} \,\mathrm{d}F \mbox{,}</code>
</p>

<p>where <code class="reqn">x(F)</code> is the quantile function of the random variable <code class="reqn">X</code> for nonexceedance probability <code class="reqn">F</code>, <code class="reqn">t_1</code> represents the trimming level of the <code class="reqn">t_1</code>-smallest, <code class="reqn">t_2</code> represents the trimming level of the <code class="reqn">t_2</code>-largest values, <code class="reqn">r</code> represents the order of the L-moments. This function loops across the above equation for each <code>nmom</code> set in the argument list. The function <code class="reqn">x(F)</code> is computed through the <code><a href="#topic+par2qua">par2qua</a></code> function. The distribution type is determined using the <code>type</code> attribute of the <code>para</code> argument&mdash;the parameter object.
</p>
<p>As of version 1.5.2 of <span class="pkg">lmomco</span>, there exists enhanced error trapping on integration failures in <br />
<code><a href="#topic+theoTLmoms">theoTLmoms</a></code>. The function now abandons operations should any of the integrations for the <code class="reqn">r</code>th L-moment fail for reasons such as divergent integral or round off problems. The function returns NAs for all L-moments in <code>lambdas</code> and <code>ratios</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>theoTLmoms(para, nmom=5, trim=NULL, leftrim=NULL, rightrim=NULL,
                 minF=0, maxF=1, quafunc=NULL,
                 nsim=50000, fold=5,
                 silent=TRUE, verbose=FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="theoTLmoms_+3A_para">para</code></td>
<td>
<p>A distribution parameter object of this package such as by <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
<tr><td><code id="theoTLmoms_+3A_nmom">nmom</code></td>
<td>
<p>The number of moments to compute. Default is 5.</p>
</td></tr>
<tr><td><code id="theoTLmoms_+3A_trim">trim</code></td>
<td>
<p>Level of symmetrical trimming to use in the computations.
Although <code>NULL</code> in the argument list, the default is 0&mdash;the usual L-moment is returned.</p>
</td></tr>
<tr><td><code id="theoTLmoms_+3A_leftrim">leftrim</code></td>
<td>
<p>Level of trimming of the left-tail of the sample.</p>
</td></tr>
<tr><td><code id="theoTLmoms_+3A_rightrim">rightrim</code></td>
<td>
<p>Level of trimming of the right-tail of the sample.</p>
</td></tr>
<tr><td><code id="theoTLmoms_+3A_minf">minF</code></td>
<td>
<p>The end point of nonexceedance probability in which to perform the integration. Try setting to non-zero (but small) if you have a divergent integral.</p>
</td></tr>
<tr><td><code id="theoTLmoms_+3A_maxf">maxF</code></td>
<td>
<p>The end point of nonexceedance probability in which to perform the integration. Try setting to non-unity (but close) if you have a divergent integral.</p>
</td></tr>
<tr><td><code id="theoTLmoms_+3A_quafunc">quafunc</code></td>
<td>
<p>An optional and arbitrary quantile function that simply needs to except a nonexceedance probability and the parameter object in <code>para</code>. This is a feature that permits computation of the L-moments of a quantile function that does not have to be implemented in the greater overhead hassles of the <span class="pkg">lmomco</span> style. This feature might be useful for estimation of quantile function mixtures or those distributions not otherwise implemented in this package.</p>
</td></tr>
<tr><td><code id="theoTLmoms_+3A_nsim">nsim</code></td>
<td>
<p>Simulation size for Monte Carlo integration is such is internally deemed necessary (see <code>silent</code> argument).</p>
</td></tr>
<tr><td><code id="theoTLmoms_+3A_fold">fold</code></td>
<td>
<p>The number of fractions or number of folds of <code>nsim</code>, which in other words, means that <code>nsim</code> is divided by <code>folds</code> and a loop creating <code>folds</code> integrations of <code>nsim/folds</code> is used from which the mean and mean absolute error of the integrand are computed. This is to try to recover similar output as <code>integrate()</code>.</p>
</td></tr>
<tr><td><code id="theoTLmoms_+3A_silent">silent</code></td>
<td>
<p>The argument of <code>silent</code> for the <code>try()</code> operation wrapped on <code>integrate()</code>. If set true and the integral is probability divergent, Monte Carlo integration is triggered using <code>nsim</code> and <code>folds</code>. The user would have to set <code>verbose=TRUE</code> to then acquire the returned table in <code>integrations</code> of the integration passes including those are or are not Monte Carlo.</p>
</td></tr>
<tr><td><code id="theoTLmoms_+3A_verbose">verbose</code></td>
<td>
<p>Toggle verbose output. Because the <span class="rlang"><b>R</b></span> function <code>integrate</code> is used to perform the numerical integration, it might be useful to see selected messages regarding the numerical integration.</p>
</td></tr>
<tr><td><code id="theoTLmoms_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> is returned.
</p>
<table>
<tr><td><code>lambdas</code></td>
<td>
<p>Vector of the TL-moments. First element is
<code class="reqn">\lambda^{(t_1,t_2)}_1</code>, second element is <code class="reqn">\lambda^{(t_1,t_2)}_2</code>, and so on.</p>
</td></tr>
<tr><td><code>ratios</code></td>
<td>
<p>Vector of the L-moment ratios. Second element is
<code class="reqn">\tau^{(t_1,t_2)}</code>, third element is <code class="reqn">\tau^{(t_1,t_2)}_3</code> and so on.</p>
</td></tr>
<tr><td><code>trim</code></td>
<td>
<p>Level of symmetrical trimming used in the computation, which will equal <code>NULL</code> if asymmetrical trimming was used.</p>
</td></tr>
<tr><td><code>leftrim</code></td>
<td>
<p>Level of left-tail trimming used in the computation.</p>
</td></tr>
<tr><td><code>rightrim</code></td>
<td>
<p>Level of right-tail trimming used in the computation.</p>
</td></tr>
<tr><td><code>nsim</code></td>
<td>
<p>Echo of the <code>nsim</code> argument if and only if at least one Monte Carlo integration was required, otherwise this is set to &ldquo;not needed&rdquo; on the return.</p>
</td></tr>
<tr><td><code>folds</code></td>
<td>
<p>Echo of the <code>folds</code> argument if and only if at least one Monte Carlo integration was required, otherwise this is set to &ldquo;not needed&rdquo; on the return.</p>
</td></tr>
<tr><td><code>monte_carlo</code></td>
<td>
<p>A logical vector of whether one or more Monte Carlo integrations was needed for the <code>r</code>-th index of the vector during the integrations for the <code class="reqn">r</code>-th L-moment.</p>
</td></tr>
<tr><td><code>source</code></td>
<td>
<p>An attribute identifying the computational source of the L-moments: &ldquo;theoTLmoms&rdquo; or switched to &ldquo;theoLmoms&rdquo; if this function was dispatched from <code><a href="#topic+theoLmoms">theoLmoms</a></code>.</p>
</td></tr>
<tr><td><code>integrations</code></td>
<td>
<p>If <code>verbose=TRUE</code>, then the results of the integrations are a data frame stored here. Otherwise, <code>integrations</code> is not present in the list.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>An extended example of a <em>unique application</em> of the TL-moments is useful to demonstrate capabilities of the <span class="pkg">lmomco</span> package API.  Consider the following example in which the analyst has 21 years of data for a given spatial location. Based on regional analysis, the highest value (the <code>outlier</code> = 21.12) is known to be exotically high but also documentable as not representing say a transcription error in the source database. The regional analysis also shows that the Generalized Extreme Value (GEV) distribution is appropriate.
</p>
<p>The analyst is using a complex L-moment computational framework (say a software package called <b>BigStudy.R</b>) in which only the input data are under the control of the analyst or it is too risky to modify <b>BigStudy.R</b>. Yet, it is desired to somehow acquire robust estimation. The <code>outlier</code> value can be accommodated by estimating a pseudo-value and then simply make a substitution in the input data file for <b>BigStudy.R</b>.
</p>
<p>The following code initiates pseudo-value estimation by storing the original 20 years of data in variable <code>data.org</code> and then extending these data with the <code>outlier</code>. The usual sample L-moments are computed in <code>first.lmr</code> and will only be used for qualitative comparison. A 3-dimensional optimizer will be used for the GEV so the starting point is stored in <code>first.par</code>.
</p>
<pre>
  data.org  &lt;- c(5.19, 2.58, 7.59, 3.22, 7.50, 4.05, 2.54, 9.00, 3.93, 5.15,
                 6.80, 2.10, 8.44, 6.11, 3.30, 5.75, 3.52, 3.48, 6.32, 4.07)
  outlier   &lt;- 21.12;            the.data  &lt;- c(data.org, outlier)
  first.lmr &lt;- lmoms(the.data);  first.par &lt;- pargev(first.lmr)
</pre>
<p>Robustness is acquired by computing the sample TL-moments such that the <code>outlier</code> is quantitatively removed by single trimming from the right side as the follow code shows:
</p>
<pre>
  trimmed.lmr &lt;- TLmoms(the.data, rightrim=1, leftrim=0)
</pre>
<p>The objective now is to fit a GEV to the sample TL-moments in <code>trimmed.lmr</code>. However, the right-trimmed only (<code class="reqn">t_1 = 0</code> and <code class="reqn">t_2 = 1</code>) version of the TL-moments is being used and analytical solutions to the GEV for <code class="reqn">t = (0,1)</code> are lacking or perhaps they are too much trouble to derive. The <code>theoTLmoms</code> function provides the avenue for progress because of its numerical integration basis for acquistion of the TL-moments. An objective function for the <code class="reqn">t_2 = 1</code> TL-moments of the GEV is defined and based on the sum of square errors of the first three TL-moments:
</p>
<pre>
  "afunc" &lt;- function(par, tarlmr=NULL, p=3) {
              the.par  &lt;- vec2par(par, type="gev", paracheck=FALSE)
              fit.tlmr &lt;- theoTLmoms(the.par, rightrim=1, leftrim=0)
              return(sum((tarlmr$lambdas[1:p] - fit.tlmr$lambdas[1:p])^2))
  }
</pre>
<p>and then optimize on this function and make a qualitative comparison between the original sample L-moments (untrimmed) to the equivalent L-moments (untrimmed) of the GEV having TL-moments equaling those in <code>trimmed.lmr</code>:
</p>
<pre>
  rt &lt;- optim(first.par$para, afunc, tarlmr=trimmed.lmr)
  last.lmr &lt;- lmomgev(vec2par(rt$par, type="gev"))

  message("# Original sample    L-moment lambdas: ",
           paste(round(first.lmr$lambdas[1:3], digits=4), collapse=" "))
  message("# Targeting back-fit L-moment lambdas: ",
           paste(round(last.lmr$lambdas[ 1:3], digits=4), collapse=" "))
  # Original sample    L-moment lambdas: 5.7981 1.8565 0.7287
  # Targeting back-fit L-moment lambdas: 5.5916 1.6501 0.5223
</pre>
<p>The primary result on comparison of the <code class="reqn">\lambda_r</code> shows that the L-scale drops substantially as does L-skew: (<code class="reqn">\tau_3 = 0.7287 / 1.8565 = 0.3925 \rightarrow \lambda_3^{(t_2{=}1)} = 0.5223 / 1.6501 = 0.3165</code>).
</p>
<p>Now that the target L-moments (not TL-moments) are known (<code>last.lmr</code>), it is possible to optimize again on the value for the <code>outlier</code> that would provide the <code>last.lmr</code> within the greater computational framework in use by the analyst.
</p>
<pre>
  "bfunc" &lt;- function(x, tarlmr=NULL, p=3) {
              sam.lmr &lt;- lmoms(c(data.org, x))
              return(sum((tarlmr$lambdas[1:p] - sam.lmr$lambdas[1:p])^2))
  }
  suppressWarnings(outlier.rt &lt;- optim(outlier, bfunc, tarlmr=last.lmr))
  # silence warning about 1D optimization with optim(), well behaved here

  pseudo.outlier &lt;- round(outlier.rt$par, digits=2)
  final.lmr &lt;- lmoms(c(data.org, pseudo.outlier))

  message("# Resulting new L-moment lambdas: ",
          paste(round(final.lmr$lambdas[1:3], digits=4), collapse=" "))
  # Resulting new L-moment lambdas: 5.5914 1.6499 0.5221

  message("# Pseudo-value for highest value: ", round(outlier.rt$par, digits=2))
  # Pseudo-value for highest value: 16.78
</pre>
<p>Where the second optimization shows that if the largest value for the 21 years of data is given a value of <code class="reqn">16.78</code> instead of its original value of <code class="reqn">21.12</code> that the sample L-moments (untrimmed) will be consistent as if the TL-moments <code class="reqn">t = (0,1)</code> has been somehow used without resorting to a risky re-coding of the greater computational framework.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Elamir, E.A.H., and Seheult, A.H., 2003, Trimmed L-moments: Computational Statistics and Data Analysis, v. 43, pp. 299&ndash;314.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+theoLmoms">theoLmoms</a></code>, <code><a href="#topic+TLmoms">TLmoms</a></code>, <code><a href="#topic+tlmr2par">tlmr2par</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>para &lt;- vec2par(c(0, 1), type='nor') # standard normal
TL00 &lt;- theoTLmoms(para) # compute ordinary L-moments
TL30 &lt;- theoTLmoms(para, leftrim=3, rightrim=0) # trim 3 smallest samples

# Let us look at the difference from simulation to theoretrical using
# L-kurtosis and asymmetrical trimming for generalized Lambda dist.
n     &lt;- 100 # really a much larger sample should be used---for speed
P     &lt;- vec2par(c(10000, 10000, 6, 0.4),type='gld')
Lkurt &lt;- TLmoms(quagld(runif(n),P), rightrim=3, leftrim=0)$ratios[4]
theoLkurt &lt;- theoTLmoms(P, rightrim=3, leftrim=0)$ratios[4]
Lkurt - theoLkurt # as the number for runif goes up, this
                  # difference goes to zero

# Example using the Generalized Pareto Distribution
# to verify computations from theoretical and sample stand point.
n      &lt;- 100 # really a much larger sample should be used---for speed
P      &lt;- vec2par(c(12, 34, 4),type='gpa')
theoTL &lt;- theoTLmoms(P, rightrim=2, leftrim=4)
samTL  &lt;- TLmoms(quagpa(runif(n),P), rightrim=2, leftrim=4)
del    &lt;- samTL$ratios[3] - theoTL$ratios[3] # if n is large difference
                                             # is small
str(del)

## Not run: 
  "cusquaf" &lt;- function(f, para, ...) { # Gumbel-Normal product
     g &lt;- vec2par(c(para[1:2]), type="gum")
     n &lt;- vec2par(c(para[3:4]), type="nor")
     return(par2qua(f,g)*par2qua(f,n))
  }
  para &lt;- c(5.6, .45, 3, .3)
  theoTLmoms(para, quafunc=cusquaf) # L-skew = 0.13038711
## End(Not run)

## Not run: 
  # This example has a divergent integral triggered on the last of the inner
  # loop of the 4th L-moment call. Monte Carlo (MC) integration is thus triggered.
  # The verbose=TRUE saves numerical or MC integration result table to the return.
  para   &lt;-  vec2par(c(2.00,  2.00, -0.20, -0.55), type="kap")
  lmrbck &lt;- lmomkap(   para, nmom=5)
  # print(lmrbck$lambdas) 3.1189568 1.9562688 0.4700229 0.4078741 0.1974055
  lmrthe &lt;- theoTLmoms2(para, nmom=5, verbose=TRUE)              # seed dependent
  # print(lmrthe$lambdas) 3.1189569 1.9562686 0.4700227 0.4068539 0.1974049
  parkap(lmrbck)$para # 2.00       2.00     -0.20      -0.55
  parkap(lmrthe)$para # 2.018883  1.986761  -0.202422  -0.570451 # seed dependent
## End(Not run)
</code></pre>

<hr>
<h2 id='TLmom'>A Sample Trimmed L-moment </h2><span id='topic+TLmom'></span>

<h3>Description</h3>

<p>A sample trimmed L-moment (TL-moment) is computed for a vector. The <code class="reqn">r \ge 1</code> order of the L-moment is specified as well as the level of symmetrical trimming.  A trimmed TL-moment
<code class="reqn">\hat{\lambda}^{(t_1,t_2)}_r</code> is
</p>
<p style="text-align: center;"><code class="reqn"> \hat{\lambda}^{(t_1,t_2)}_r = \frac{1}{r}\sum^{n-t_2}_{i=t_1+1}
           \left[ \frac{\sum\limits^{r-1}_{k=0}{ (-1)^k {r-1 \choose k}
                                                 {i-1 \choose r+t_1-1-k}
                                                 {n-i \choose t_2+k}
                                         }}{{n \choose r+t_1+t_2}}
           \right] x_{i:n} \mbox{,}</code>
</p>

<p>where <code class="reqn">t_a</code> represents the trimming level of the <code class="reqn">t_2</code>-largest or <code class="reqn">t_1</code>-smallest values, <code class="reqn">r</code> represents the order of the L-moment, <code class="reqn">n</code> represents the sample size, and <code class="reqn">x_{i:n}</code> represents the <code class="reqn">i</code>th sample order statistic (<code class="reqn">x_{1:n} \le x_{2:n} \le \dots \le x_{n:n}</code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>TLmom(x, order, trim=NULL, leftrim=NULL, rightrim=NULL, sortdata=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="TLmom_+3A_x">x</code></td>
<td>
<p>A vector of data values.</p>
</td></tr>
<tr><td><code id="TLmom_+3A_order">order</code></td>
<td>
<p>L-moment order to use in the computations.
Default is 1 (the mean).</p>
</td></tr>
<tr><td><code id="TLmom_+3A_trim">trim</code></td>
<td>
<p>Level of symmetrical trimming to use in the computations. Although <code>NULL</code> is in the argument list, the default is 0&mdash;the usual L-moment is returned.</p>
</td></tr>
<tr><td><code id="TLmom_+3A_leftrim">leftrim</code></td>
<td>
<p>Level of trimming of the left-tail of the sample, which should be left to <code>NULL</code> if no or symmetrical trimming is used.</p>
</td></tr>
<tr><td><code id="TLmom_+3A_rightrim">rightrim</code></td>
<td>
<p>Level of trimming of the right-tail of the sample, which should be left to <code>NULL</code> if no or symmetrical trimming is used.</p>
</td></tr>
<tr><td><code id="TLmom_+3A_sortdata">sortdata</code></td>
<td>
<p>A logical switch on whether the data should be sorted. The default is TRUE.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> is returned.
</p>
<table>
<tr><td><code>lambda</code></td>
<td>
<p>The TL-moment of order=<code>order</code>, <code class="reqn">\hat{\lambda}^{(t_1,t_2)}_r</code> where <code class="reqn">r</code> is the moment order, <code class="reqn">t_1</code> is left-tail trimming, and <code class="reqn">t_2</code> is right-tail trimming.</p>
</td></tr>
<tr><td><code>order</code></td>
<td>
<p>L-moment order computed. Default is 1 (the mean).</p>
</td></tr>
<tr><td><code>trim</code></td>
<td>
<p>Level of symmetrical trimming used in the computation.</p>
</td></tr>
<tr><td><code>leftrim</code></td>
<td>
<p>Level of left-tail trimming used in the computation, which will equal <code>trim</code> if symmetrical trimming was used.</p>
</td></tr>
<tr><td><code>rightrim</code></td>
<td>
<p>Level of right-tail trimming used in the computation, which will equal <code>trim</code> if symmetrical trimming was used.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The presence of the <code>sortdata</code> switch can be dangerous. L-moment computation requires that the data be sorted into the &ldquo;order statistics&rdquo;. Thus the default behavior of <code>sortdata=TRUE</code> is required when the function is called on its own. In practice, this function would almost certainly not be used on its own because multiple trimmed L-moments would be needed. Multiple trimmed L-moments are best computed by <code><a href="#topic+TLmoms">TLmoms</a></code>, which calls <code><a href="#topic+TLmom">TLmom</a></code> multiple times. The function <code><a href="#topic+TLmoms">TLmoms</a></code> takes over the sort operation on the data and passes <code>sortdata=FALSE</code> to <code><a href="#topic+TLmom">TLmom</a></code> for efficiency. (The point of this discussion is that CPU time is not wasted sorting the data more than once.)
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Elamir, E.A.H., and Seheult, A.H., 2003, Trimmed L-moments: Computational Statistics and Data Analysis, v. 43, pp. 299&ndash;314.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+TLmoms">TLmoms</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>X1 &lt;- rcauchy(30)
TL &lt;- TLmom(X1,order=2,trim=1)
</code></pre>

<hr>
<h2 id='TLmoms'>The Sample Trimmed L-moments and L-moment Ratios </h2><span id='topic+TLmoms'></span>

<h3>Description</h3>

<p>Compute the sample trimmed L-moments (TL-moments) for a vector. The level of symmetrical trimming is specified. The mathematical expression for a TL-moment is seen under <code><a href="#topic+TLmom">TLmom</a></code>.  The <code><a href="#topic+TLmoms">TLmoms</a></code> function loops across that expression and the <code><a href="#topic+TLmom">TLmom</a></code> function for each <code>nmom</code>=<code class="reqn">r</code> set in the argument list.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>TLmoms(x, nmom, trim=NULL, leftrim=NULL, rightrim=NULL, vecit=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="TLmoms_+3A_x">x</code></td>
<td>
<p>A vector of data values.</p>
</td></tr>
<tr><td><code id="TLmoms_+3A_nmom">nmom</code></td>
<td>
<p>The number of moments to compute. Default is 5.</p>
</td></tr>
<tr><td><code id="TLmoms_+3A_trim">trim</code></td>
<td>
<p>Level of symmetrical trimming to use in the computations. Although <code>NULL</code> is in the argument list, the default is 0&mdash;the usual L-moment is returned.</p>
</td></tr>
<tr><td><code id="TLmoms_+3A_leftrim">leftrim</code></td>
<td>
<p>Level of trimming of the left-tail of the sample, which should be left to <code>NULL</code> if no or symmetrical trimming is used.</p>
</td></tr>
<tr><td><code id="TLmoms_+3A_rightrim">rightrim</code></td>
<td>
<p>Level of trimming of the right-tail of the sample, which should be left to <code>NULL</code> if no or symmetrical trimming is used.</p>
</td></tr>
<tr><td><code id="TLmoms_+3A_vecit">vecit</code></td>
<td>
<p>A logical to return the first two <code class="reqn">\lambda_i \in 1,2</code> and then the <code class="reqn">\tau_i \in 3,\cdots</code> where the length of the returned vector is controlled by the <code>nmom</code> argument. This argument will store the trims in the attributes of the returned vector, but caution is advised if <code><a href="#topic+vec2par">vec2par</a></code> were to be used on the vector because that function does not consult the trimming.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> is returned.
</p>
<table>
<tr><td><code>lambdas</code></td>
<td>
<p>Vector of the TL-moments. First element is
<code class="reqn">\hat{\lambda}^{(t_1,t_2)}_1</code>, second element is <code class="reqn">\hat{\lambda}^{(t_1,t_2)}_2</code>, and so on.</p>
</td></tr>
<tr><td><code>ratios</code></td>
<td>
<p>Vector of the L-moment ratios. Second element is
<code class="reqn">\hat{\tau}^{(t_1,t_2)}</code>, third element is <code class="reqn">\hat{\tau}^{(t_1,t_2)}_3</code> and so on.</p>
</td></tr>
<tr><td><code>trim</code></td>
<td>
<p>Level of symmetrical trimming used in the computation.</p>
</td></tr>
<tr><td><code>leftrim</code></td>
<td>
<p>Level of left-tail trimming used in the computation, which will equal <code>trim</code> if symmetrical trimming was used.</p>
</td></tr>
<tr><td><code>rightrim</code></td>
<td>
<p>Level of right-tail trimming used in the computation, which will equal <code>trim</code> if symmetrical trimming was used.</p>
</td></tr>
<tr><td><code>source</code></td>
<td>
<p>An attribute identifying the computational source of the L-moments: &ldquo;TLmoms&rdquo;.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Elamir, E.A.H., and Seheult, A.H., 2003, Trimmed L-moments: Computational Statistics and Data Analysis, v. 43, pp. 299&ndash;314.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+TLmom">TLmom</a></code>, <code><a href="#topic+lmoms">lmoms</a></code>, and <code><a href="#topic+lmorph">lmorph</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>X1 &lt;- rcauchy(30)
TL &lt;- TLmoms(X1,nmom=6,trim=1)

# This trimming with remove the 1 and the two 4s. All values passed on to the TLmom()
# function then are equal and number of L-moments is too big as well. TLmom() returns
# NaN but these are intercepted and systematically changed to NAs.
TLmoms(c(1,2,2,2,4,4), leftrim=1, rightrim=2, nmom=6)$lambdas
# [1]  2  0  0 NA NA NA

# Example of zero skewness (Berry Boessenkool)
TLmoms(c(3.2, 4.4, 4.8, 2.6, 3.6))
</code></pre>

<hr>
<h2 id='tlmr2par'>Sample Trimmed L-moments to Fitted Distribution</h2><span id='topic+tlmr2par'></span>

<h3>Description</h3>

<p>Parameter estimation of a distribution given initial estimate of the parameters of the distribution to the sample trimmed L-moment (TL-moment) using numerical optimization. Thought the TL-moments can be used with substantial depth into either tail and need not be symmetrically trimmed, the TL-moments do not appear as useful when substantial tail trimming is needed, say for mix population mitigation. Then censored or truncation methods might be preferred. The <code><a href="#topic+x2xlo">x2xlo</a></code> family of operations can be used for conditional left-tail truncation, which is not uncommon in frequency analyses of rail-tail interest water resources phenomena.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tlmr2par(x, type, init.para=NULL, trim=NULL, leftrim=NULL, rightrim=NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tlmr2par_+3A_x">x</code></td>
<td>
<p>A vector of data values.</p>
</td></tr>
<tr><td><code id="tlmr2par_+3A_type">type</code></td>
<td>
<p>Three character (minimum) distribution type (for example, <code>type="gev"</code>, see <code><a href="#topic+dist.list">dist.list</a></code>.</p>
</td></tr>
<tr><td><code id="tlmr2par_+3A_init.para">init.para</code></td>
<td>
<p>Initial parameters as a vector <code class="reqn">\Theta</code> or as an <span class="pkg">lmomco</span> parameter &ldquo;object&rdquo; from say <code><a href="#topic+vec2par">vec2par</a></code>. If a vector is given, then internally <code><a href="#topic+vec2par">vec2par</a></code> is called with distribution equal to <code>type</code>.</p>
</td></tr>
<tr><td><code id="tlmr2par_+3A_trim">trim</code></td>
<td>
<p>Level of symmetrical trimming to use in the computations. Although <code>NULL</code> is in the argument list, the default is 0&mdash;the usual L-moment is returned.</p>
</td></tr>
<tr><td><code id="tlmr2par_+3A_leftrim">leftrim</code></td>
<td>
<p>Level of trimming of the left-tail of the sample, which should be left to <code>NULL</code> if no or symmetrical trimming is used.</p>
</td></tr>
<tr><td><code id="tlmr2par_+3A_rightrim">rightrim</code></td>
<td>
<p>Level of trimming of the right-tail of the sample, which should be left to <code>NULL</code> if no or symmetrical trimming is used.</p>
</td></tr>
<tr><td><code id="tlmr2par_+3A_...">...</code></td>
<td>
<p>Other arguments to pass to the <code>optim()</code> function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> is returned.  This list should contain at least the following items, but some distributions such as the <code>revgum</code> have extra.
</p>
<table>
<tr><td><code>type</code></td>
<td>
<p>The type of distribution in three character (minimum) format.</p>
</td></tr>
<tr><td><code>para</code></td>
<td>
<p>The parameters of the distribution.</p>
</td></tr>
<tr><td><code>text</code></td>
<td>
<p>Optional material. If the solution fails but the optimization appears to converge, then this element is inserted into the list and the <code>para</code> will be all <code>NA</code>.</p>
</td></tr>
<tr><td><code>source</code></td>
<td>
<p>Attribute specifying source of the parameters.</p>
</td></tr>
<tr><td><code>rt</code></td>
<td>
<p>The list from the <code>optim()</code> function.</p>
</td></tr>
<tr><td><code>init.para</code></td>
<td>
<p>A copy of the initial parameters given.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Elamir, E.A.H., and Seheult, A.H., 2003, Trimmed L-moments: Computational Statistics and Data Analysis, v. 43, pp. 299&ndash;314.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+theoTLmoms">theoTLmoms</a></code>, <code><a href="#topic+TLmoms">TLmoms</a></code>, <code><a href="#topic+lmr2par">lmr2par</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>
# (1) An example to check that trim(0,0) should recover whole sample
the.data &lt;- rlmomco(140, vec2par(c(3, 0.4, -0.1), type="pe3"))
wild.guess &lt;- vec2par(c(mean(the.data), 1, 0),    type="pe3")
pe3whole &lt;- lmom2par(lmoms(the.data),             type="pe3")
pe3trimA  &lt;- tlmr2par(the.data, "pe3", init.para=wild.guess, leftrim=0,  rightrim=0)
pe3trimB  &lt;- tlmr2par(the.data, "pe3", init.para=wild.guess, leftrim=10, rightrim=3)
message("PE3 parent       = ", paste0(pe3whole$para, sep=" "))
message("PE3 whole sample = ", paste0(pe3whole$para, sep=" "))
message("PE3 trim( 0, 0)  = ", paste0(pe3trimA$para, sep=" "))
message("PE3 trim(10, 3)  = ", paste0(pe3trimB$para, sep=" ")) #


# (2) An example with "real" outliers
FF &lt;- lmomco::nonexceeds(); qFF &lt;- qnorm(FF); type &lt;- "gev"
the.data &lt;- c(3.064458, 3.139879, 3.167317, 3.225309, 3.324282, 3.330414,
             3.3304140, 3.340444, 3.357935, 3.376577, 3.378398, 3.392697,
             3.4149730, 3.421604, 3.424882, 3.434569, 3.448706, 3.451786,
             3.4517860, 3.462398, 3.465383, 3.469822, 3.491362, 3.501059,
             3.5224440, 3.523746, 3.527630, 3.527630, 3.531479, 3.546543,
             3.5932860, 3.597695, 3.600973, 3.614897, 3.620136, 3.660865,
             3.6848450, 3.820858, 4.708421)
the.data &lt;- sort(the.data) # though already sorted, backup for plotting needs

# visually, looks like 4 outliers to the left and one outlier to the right
# perhaps the practical situation is that we do not wan the left tail to
# mess up the right when fitting a distribution because maybe the practical
# aspects are the that right tail is of engineering interest, but then we
# have some idea that the one very large event is of questionable suitability
t1 &lt;- 4; t2 &lt;- 1 # see left and right trimming and then estimation parameters
whole.para &lt;- lmom2par(lmoms(the.data), type=type)
trim.para  &lt;- tlmr2par(the.data, type, init.para=whole.para, leftrim=t1, rightrim=t2)

n &lt;- length(the.data)
cols &lt;- rep(grey(0.5), n)
pchs &lt;- rep(1, n)
if(t1 != 0) {
  cols[      1 :t1] &lt;- "red"
  cols[(n-t2+1):n ] &lt;- "purple"
}
if(t2 != 0) {
  pchs[      1 :t1] &lt;- 16
  pchs[(n-t2+1):n ] &lt;- 16
}
plot( qFF, qlmomco(FF, whole.para), type="l", lwd=2, ylim=c(3.1,4.8),
           xlab="Standard normal variate",
           ylab="Some phenomena, log10(cfs)")
lines(qFF, qlmomco(FF, trim.para), col=4, lwd=3)
points(qnorm(pp(the.data)), sort(the.data), pch=pchs, col=cols)
legend("topleft", c("L-moments",
                   paste0("TL-moments(", t1, ",", t2,")")), bty="n",
                  lty=c(1,1), lwd=c(2,3), col=c(1,4))
# see the massive change from the whole sample to the trim(t1,t2) curve
</code></pre>

<hr>
<h2 id='tlmrcau'>Compute Select TL-moment ratios of the Cauchy Distribution </h2><span id='topic+tlmrcau'></span>

<h3>Description</h3>

<p>This function computes select TL-moment ratios of the Cauchy distribution for defaults of <code class="reqn">\xi = 0</code> and <code class="reqn">\alpha = 1</code>. This function can be useful for plotting the trajectory of the distribution on TL-moment ratio diagrams of <code class="reqn">\tau^{(t_1,t_2)}_2</code>, <code class="reqn">\tau^{(t_1,t_2)}_3</code>, <code class="reqn">\tau^{(t_1,t_2)}_4</code>, <code class="reqn">\tau^{(t_1,t_2)}_5</code>, and <code class="reqn">\tau^{(t_1,t_2)}_6</code>. In reality, <code class="reqn">\tau^{(t_1,t_2)}_2</code> is dependent on the values for <code class="reqn">\xi</code> and <code class="reqn">\alpha</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tlmrcau(trim=NULL, leftrim=NULL, rightrim=NULL, xi=0, alpha=1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tlmrcau_+3A_trim">trim</code></td>
<td>
<p>Level of symmetrical trimming to use in the computations.
Although <code>NULL</code> in the argument list, the default is 0&mdash;the usual L-moment ratios are returned.</p>
</td></tr>
<tr><td><code id="tlmrcau_+3A_leftrim">leftrim</code></td>
<td>
<p>Level of trimming of the left-tail of the sample.</p>
</td></tr>
<tr><td><code id="tlmrcau_+3A_rightrim">rightrim</code></td>
<td>
<p>Level of trimming of the right-tail of the sample.</p>
</td></tr>
<tr><td><code id="tlmrcau_+3A_xi">xi</code></td>
<td>
<p>Location parameter of the distribution.</p>
</td></tr>
<tr><td><code id="tlmrcau_+3A_alpha">alpha</code></td>
<td>
<p>Scale parameter of the distribution.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> is returned.
</p>
<table>
<tr><td><code>tau2</code></td>
<td>
<p>A vector of the <code class="reqn">\tau^{(t_1,t_2)}_2</code> values.</p>
</td></tr>
<tr><td><code>tau3</code></td>
<td>
<p>A vector of the <code class="reqn">\tau^{(t_1,t_2)}_3</code> values.</p>
</td></tr>
<tr><td><code>tau4</code></td>
<td>
<p>A vector of the <code class="reqn">\tau^{(t_1,t_2)}_4</code> values.</p>
</td></tr>
<tr><td><code>tau5</code></td>
<td>
<p>A vector of the <code class="reqn">\tau^{(t_1,t_2)}_5</code> values.</p>
</td></tr>
<tr><td><code>tau6</code></td>
<td>
<p>A vector of the <code class="reqn">\tau^{(t_1,t_2)}_6</code> values.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The function uses numerical integration of the quantile function of the distribution through the <code><a href="#topic+theoTLmoms">theoTLmoms</a></code> function.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith </p>


<h3>See Also</h3>

<p><code><a href="#topic+quacau">quacau</a></code>, <code><a href="#topic+theoTLmoms">theoTLmoms</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
tlmrcau(trim=2)
tlmrcau(trim=2, xi=2) # another slow example

## End(Not run)
</code></pre>

<hr>
<h2 id='tlmrexp'>Compute Select TL-moment ratios of the Exponential Distribution </h2><span id='topic+tlmrexp'></span>

<h3>Description</h3>

<p>This function computes select TL-moment ratios of the Exponential distribution for defaults of <code class="reqn">\xi = 0</code> and <code class="reqn">\alpha = 1</code>. This function can be useful for plotting the trajectory of the distribution on TL-moment ratio diagrams of <code class="reqn">\tau^{(t_1,t_2)}_2</code>, <code class="reqn">\tau^{(t_1,t_2)}_3</code>, <code class="reqn">\tau^{(t_1,t_2)}_4</code>, <code class="reqn">\tau^{(t_1,t_2)}_5</code>, and <code class="reqn">\tau^{(t_1,t_2)}_6</code>. In reality, <code class="reqn">\tau^{(t_1,t_2)}_2</code> is  dependent on the values for <code class="reqn">\xi</code> and <code class="reqn">\alpha</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tlmrexp(trim=NULL, leftrim=NULL, rightrim=NULL, xi=0, alpha=1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tlmrexp_+3A_trim">trim</code></td>
<td>
<p>Level of symmetrical trimming to use in the computations.
Although <code>NULL</code> in the argument list, the default is 0&mdash;the usual L-moment ratios are returned.</p>
</td></tr>
<tr><td><code id="tlmrexp_+3A_leftrim">leftrim</code></td>
<td>
<p>Level of trimming of the left-tail of the sample.</p>
</td></tr>
<tr><td><code id="tlmrexp_+3A_rightrim">rightrim</code></td>
<td>
<p>Level of trimming of the right-tail of the sample.</p>
</td></tr>
<tr><td><code id="tlmrexp_+3A_xi">xi</code></td>
<td>
<p>Location parameter of the distribution.</p>
</td></tr>
<tr><td><code id="tlmrexp_+3A_alpha">alpha</code></td>
<td>
<p>Scale parameter of the distribution.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> is returned.
</p>
<table>
<tr><td><code>tau2</code></td>
<td>
<p>A vector of the <code class="reqn">\tau^{(t_1,t_2)}_2</code> values.</p>
</td></tr>
<tr><td><code>tau3</code></td>
<td>
<p>A vector of the <code class="reqn">\tau^{(t_1,t_2)}_3</code> values.</p>
</td></tr>
<tr><td><code>tau4</code></td>
<td>
<p>A vector of the <code class="reqn">\tau^{(t_1,t_2)}_4</code> values.</p>
</td></tr>
<tr><td><code>tau5</code></td>
<td>
<p>A vector of the <code class="reqn">\tau^{(t_1,t_2)}_5</code> values.</p>
</td></tr>
<tr><td><code>tau6</code></td>
<td>
<p>A vector of the <code class="reqn">\tau^{(t_1,t_2)}_6</code> values.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The function uses numerical integration of the quantile function of the distribution through the <code><a href="#topic+theoTLmoms">theoTLmoms</a></code> function.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith </p>


<h3>See Also</h3>

<p><code><a href="#topic+quaexp">quaexp</a></code>, <code><a href="#topic+theoTLmoms">theoTLmoms</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
tlmrexp(trim=2)
tlmrexp(trim=2, xi=2) # another slow example

## End(Not run)
</code></pre>

<hr>
<h2 id='tlmrgev'>Compute Select TL-moment ratios of the Generalized Extreme Value Distribution </h2><span id='topic+tlmrgev'></span>

<h3>Description</h3>

<p>This function computes select TL-moment ratios of the Generalized Extreme Value distribution for defaults of <code class="reqn">\xi = 0</code> and <code class="reqn">\alpha = 1</code>. This function can be useful for plotting the trajectory of the distribution on TL-moment ratio diagrams of <code class="reqn">\tau^{(t_1,t_2)}_2</code>, <code class="reqn">\tau^{(t_1,t_2)}_3</code>, <code class="reqn">\tau^{(t_1,t_2)}_4</code>, <code class="reqn">\tau^{(t_1,t_2)}_5</code>, and <code class="reqn">\tau^{(t_1,t_2)}_6</code>. In reality, <code class="reqn">\tau^{(t_1,t_2)}_2</code> is dependent on the values for <code class="reqn">\xi</code> and <code class="reqn">\alpha</code>. If the message </p>
<pre>Error in integrate(XofF, 0, 1) : the integral is probably divergent</pre><p> occurs then careful adjustment of the shape parameter <code class="reqn">\kappa</code> parameter range is very likely required. Remember that TL-moments with nonzero trimming permit computation of TL-moments into parameter ranges beyond those recognized for the usual (untrimmed) L-moments.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tlmrgev(trim=NULL, leftrim=NULL, rightrim=NULL,
        xi=0, alpha=1, kbeg=-.99, kend=10, by=.1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tlmrgev_+3A_trim">trim</code></td>
<td>
<p>Level of symmetrical trimming to use in the computations.
Although <code>NULL</code> in the argument list, the default is 0&mdash;the usual L-moment ratios are returned.</p>
</td></tr>
<tr><td><code id="tlmrgev_+3A_leftrim">leftrim</code></td>
<td>
<p>Level of trimming of the left-tail of the sample.</p>
</td></tr>
<tr><td><code id="tlmrgev_+3A_rightrim">rightrim</code></td>
<td>
<p>Level of trimming of the right-tail of the sample.</p>
</td></tr>
<tr><td><code id="tlmrgev_+3A_xi">xi</code></td>
<td>
<p>Location parameter of the distribution.</p>
</td></tr>
<tr><td><code id="tlmrgev_+3A_alpha">alpha</code></td>
<td>
<p>Scale parameter of the distribution.</p>
</td></tr>
<tr><td><code id="tlmrgev_+3A_kbeg">kbeg</code></td>
<td>
<p>The beginning <code class="reqn">\kappa</code> value of the distribution.</p>
</td></tr>
<tr><td><code id="tlmrgev_+3A_kend">kend</code></td>
<td>
<p>The ending <code class="reqn">\kappa</code> value of the distribution.</p>
</td></tr>
<tr><td><code id="tlmrgev_+3A_by">by</code></td>
<td>
<p>The increment for the <code>seq()</code> between <code>kbeg</code> and <code>kend</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> is returned.
</p>
<table>
<tr><td><code>tau2</code></td>
<td>
<p>A vector of the <code class="reqn">\tau^{(t_1,t_2)}_2</code> values.</p>
</td></tr>
<tr><td><code>tau3</code></td>
<td>
<p>A vector of the <code class="reqn">\tau^{(t_1,t_2)}_3</code> values.</p>
</td></tr>
<tr><td><code>tau4</code></td>
<td>
<p>A vector of the <code class="reqn">\tau^{(t_1,t_2)}_4</code> values.</p>
</td></tr>
<tr><td><code>tau5</code></td>
<td>
<p>A vector of the <code class="reqn">\tau^{(t_1,t_2)}_5</code> values.</p>
</td></tr>
<tr><td><code>tau6</code></td>
<td>
<p>A vector of the <code class="reqn">\tau^{(t_1,t_2)}_6</code> values.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The function uses numerical integration of the quantile function of the distribution through the <code><a href="#topic+theoTLmoms">theoTLmoms</a></code> function.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith </p>


<h3>See Also</h3>

<p><code><a href="#topic+quagev">quagev</a></code>, <code><a href="#topic+theoTLmoms">theoTLmoms</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
tlmrgev(leftrim=12, rightrim=1, xi=0,   alpha=2 )
tlmrgev(leftrim=12, rightrim=1, xi=100, alpha=20) # another slow example

## End(Not run)
## Not run: 
  # Plot and L-moment ratio diagram of Tau3 and Tau4
  # with exclusive focus on the GEV distribution.
  plotlmrdia(lmrdia(), autolegend=TRUE, xleg=-.1, yleg=.6,
             xlim=c(-.8, .7), ylim=c(-.1, .8),
             nolimits=TRUE, noglo=TRUE, nogpa=TRUE, nope3=TRUE,
             nogno=TRUE, nocau=TRUE, noexp=TRUE, nonor=TRUE,
             nogum=TRUE, noray=TRUE, nouni=TRUE)

  # Compute the TL-moment ratios for trimming of one
  # value on the left and four on the right. Notice the
  # expansion of the kappa parameter space from &gt; -1 to
  # something near -5.
  J &lt;- tlmrgev(kbeg=-4.99, leftrim=1, rightrim=4)
  lines(J$tau3, J$tau4, lwd=2, col=3) # BLUE CURVE

  # Compute the TL-moment ratios for trimming of four
  # values on the left and one on the right.
  J &lt;- tlmrgev(kbeg=-1.99, leftrim=4, rightrim=1)
  lines(J$tau3, J$tau4, lwd=2, col=4) # GREEN CURVE

  # The kbeg and kend can be manually changed to see how
  # the resultant curve expands or contracts on the
  # extent of the L-moment ratio diagram.

## End(Not run)
## Not run: 
  # Following up, let us plot the two quantile functions
  LM  &lt;- vec2par(c(0,1,-0.99), type='gev', paracheck=FALSE)
  TLM &lt;- vec2par(c(0,1,-4.99), type='gev', paracheck=FALSE)
  F &lt;- nonexceeds()
  plot(qnorm(F),  quagev(F, LM), type="l")
  lines(qnorm(F), quagev(F, TLM, paracheck=FALSE), col=2)
  # Notice how the TLM parameterization runs off towards
  # infinity much much earlier than the conventional
  # near limits of the GEV.

## End(Not run)
</code></pre>

<hr>
<h2 id='tlmrglo'>Compute Select TL-moment ratios of the Generalized Logistic Distribution </h2><span id='topic+tlmrglo'></span>

<h3>Description</h3>

<p>This function computes select TL-moment ratios of the Generalized Logistic distribution for defaults of <code class="reqn">\xi = 0</code> and <code class="reqn">\alpha = 1</code>. This function can be useful for plotting the trajectory of the distribution on TL-moment ratio diagrams of <code class="reqn">\tau^{(t_1,t_2)}_2</code>, <code class="reqn">\tau^{(t_1,t_2)}_3</code>, <code class="reqn">\tau^{(t_1,t_2)}_4</code>, <code class="reqn">\tau^{(t_1,t_2)}_5</code>, and <code class="reqn">\tau^{(t_1,t_2)}_6</code>. In reality, <code class="reqn">\tau^{(t_1,t_2)}_2</code> is dependent on the values for <code class="reqn">\xi</code> and <code class="reqn">\alpha</code>. If the message </p>
<pre>Error in integrate(XofF, 0, 1) : the integral is probably divergent</pre><p> occurs then careful adjustment of the shape parameter <code class="reqn">\kappa</code> parameter range is very likely required. Remember that TL-moments with nonzero trimming permit computation of TL-moments into parameter ranges beyond those recognized for the usual (untrimmed) L-moments.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tlmrglo(trim=NULL, leftrim=NULL, rightrim=NULL,
        xi=0, alpha=1, kbeg=-.99, kend=0.99, by=.1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tlmrglo_+3A_trim">trim</code></td>
<td>
<p>Level of symmetrical trimming to use in the computations.
Although <code>NULL</code> in the argument list, the default is 0&mdash;the usual L-moment ratios are returned.</p>
</td></tr>
<tr><td><code id="tlmrglo_+3A_leftrim">leftrim</code></td>
<td>
<p>Level of trimming of the left-tail of the sample.</p>
</td></tr>
<tr><td><code id="tlmrglo_+3A_rightrim">rightrim</code></td>
<td>
<p>Level of trimming of the right-tail of the sample.</p>
</td></tr>
<tr><td><code id="tlmrglo_+3A_xi">xi</code></td>
<td>
<p>Location parameter of the distribution.</p>
</td></tr>
<tr><td><code id="tlmrglo_+3A_alpha">alpha</code></td>
<td>
<p>Scale parameter of the distribution.</p>
</td></tr>
<tr><td><code id="tlmrglo_+3A_kbeg">kbeg</code></td>
<td>
<p>The beginning <code class="reqn">\kappa</code> value of the distribution.</p>
</td></tr>
<tr><td><code id="tlmrglo_+3A_kend">kend</code></td>
<td>
<p>The ending <code class="reqn">\kappa</code> value of the distribution.</p>
</td></tr>
<tr><td><code id="tlmrglo_+3A_by">by</code></td>
<td>
<p>The increment for the <code>seq()</code> between <code>kbeg</code> and <code>kend</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> is returned.
</p>
<table>
<tr><td><code>tau2</code></td>
<td>
<p>A vector of the <code class="reqn">\tau^{(t_1,t_2)}_2</code> values.</p>
</td></tr>
<tr><td><code>tau3</code></td>
<td>
<p>A vector of the <code class="reqn">\tau^{(t_1,t_2)}_3</code> values.</p>
</td></tr>
<tr><td><code>tau4</code></td>
<td>
<p>A vector of the <code class="reqn">\tau^{(t_1,t_2)}_4</code> values.</p>
</td></tr>
<tr><td><code>tau5</code></td>
<td>
<p>A vector of the <code class="reqn">\tau^{(t_1,t_2)}_5</code> values.</p>
</td></tr>
<tr><td><code>tau6</code></td>
<td>
<p>A vector of the <code class="reqn">\tau^{(t_1,t_2)}_6</code> values.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The function uses numerical integration of the quantile function of the distribution through the <code><a href="#topic+theoTLmoms">theoTLmoms</a></code> function.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith </p>


<h3>See Also</h3>

<p><code><a href="#topic+quaglo">quaglo</a></code>, <code><a href="#topic+theoTLmoms">theoTLmoms</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
tlmrglo(leftrim=1, rightrim=3, xi=0, alpha=4)
tlmrglo(leftrim=1, rightrim=3, xi=32, alpha=83) # another slow example

## End(Not run)
## Not run: 
  # Plot and L-moment ratio diagram of Tau3 and Tau4
  # with exclusive focus on the GLO distribution.
  plotlmrdia(lmrdia(), autolegend=TRUE, xleg=-.1, yleg=.6,
             xlim=c(-.8, .7), ylim=c(-.1, .8),
             nolimits=TRUE, nogev=TRUE, nogpa=TRUE, nope3=TRUE,
             nogno=TRUE, nocau=TRUE, noexp=TRUE, nonor=TRUE,
             nogum=TRUE, noray=TRUE, nouni=TRUE)

  # Compute the TL-moment ratios for trimming of one
  # value on the left and four on the right. Notice the
  # expansion of the kappa parameter space from
  # -1 &lt; k &lt; -1 to something larger based on manual
  # adjustments until blue curve encompassed the plot.
  J &lt;- tlmrglo(kbeg=-2.5, kend=1.9, leftrim=1, rightrim=4)
  lines(J$tau3, J$tau4, lwd=2, col=2) # RED CURVE

  # Compute the TL-moment ratios for trimming of four
  # values on the left and one on the right.
  J &lt;- tlmrglo(kbeg=-1.65, kend=3, leftrim=4, rightrim=1)
  lines(J$tau3, J$tau4, lwd=2, col=4) # BLUE CURVE

  # The kbeg and kend can be manually changed to see how
  # the resultant curve expands or contracts on the
  # extent of the L-moment ratio diagram.

## End(Not run)
## Not run: 
  # Following up, let us plot the two quantile functions
  LM  &lt;- vec2par(c(0,1,0.99), type='glo', paracheck=FALSE)
  TLM &lt;- vec2par(c(0,1,3.00), type='glo', paracheck=FALSE)
  F &lt;- nonexceeds()
  plot(qnorm(F),  quaglo(F, LM), type="l")
  lines(qnorm(F), quaglo(F, TLM, paracheck=FALSE), col=2)
  # Notice how the TLM parameterization runs off towards
  # infinity much much earlier than the conventional
  # near limits of the GLO.

## End(Not run)
</code></pre>

<hr>
<h2 id='tlmrgno'>Compute Select TL-moment ratios of the Generalized Normal Distribution </h2><span id='topic+tlmrgno'></span>

<h3>Description</h3>

<p>This function computes select TL-moment ratios of the Generalized Normal distribution for defaults of <code class="reqn">\xi = 0</code> and <code class="reqn">\alpha = 1</code>. This function can be useful for plotting the trajectory of the distribution on TL-moment ratio diagrams of <code class="reqn">\tau^{(t_1,t_2)}_2</code>, <code class="reqn">\tau^{(t_1,t_2)}_3</code>, <code class="reqn">\tau^{(t_1,t_2)}_4</code>, <code class="reqn">\tau^{(t_1,t_2)}_5</code>, and <code class="reqn">\tau^{(t_1,t_2)}_6</code>. In reality, <code class="reqn">\tau^{(t_1,t_2)}_2</code> is dependent on the values for <code class="reqn">\xi</code> and <code class="reqn">\alpha</code>. If the message </p>
<pre>Error in integrate(XofF, 0, 1) : the integral is probably divergent</pre><p> occurs then careful adjustment of the shape parameter <code class="reqn">\kappa</code> parameter range is very likely required. Remember that TL-moments with nonzero trimming permit computation of TL-moments into parameter ranges beyond those recognized for the usual (untrimmed) L-moments.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tlmrgno(trim=NULL, leftrim=NULL, rightrim=NULL,
        xi=0, alpha=1, kbeg=-3, kend=3, by=.1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tlmrgno_+3A_trim">trim</code></td>
<td>
<p>Level of symmetrical trimming to use in the computations.
Although <code>NULL</code> in the argument list, the default is 0&mdash;the usual L-moment ratios are returned.</p>
</td></tr>
<tr><td><code id="tlmrgno_+3A_leftrim">leftrim</code></td>
<td>
<p>Level of trimming of the left-tail of the sample.</p>
</td></tr>
<tr><td><code id="tlmrgno_+3A_rightrim">rightrim</code></td>
<td>
<p>Level of trimming of the right-tail of the sample.</p>
</td></tr>
<tr><td><code id="tlmrgno_+3A_xi">xi</code></td>
<td>
<p>Location parameter of the distribution.</p>
</td></tr>
<tr><td><code id="tlmrgno_+3A_alpha">alpha</code></td>
<td>
<p>Scale parameter of the distribution.</p>
</td></tr>
<tr><td><code id="tlmrgno_+3A_kbeg">kbeg</code></td>
<td>
<p>The beginning <code class="reqn">\kappa</code> value of the distribution.</p>
</td></tr>
<tr><td><code id="tlmrgno_+3A_kend">kend</code></td>
<td>
<p>The ending <code class="reqn">\kappa</code> value of the distribution.</p>
</td></tr>
<tr><td><code id="tlmrgno_+3A_by">by</code></td>
<td>
<p>The increment for the <code>seq()</code> between <code>kbeg</code> and <code>kend</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> is returned.
</p>
<table>
<tr><td><code>tau2</code></td>
<td>
<p>A vector of the <code class="reqn">\tau^{(t_1,t_2)}_2</code> values.</p>
</td></tr>
<tr><td><code>tau3</code></td>
<td>
<p>A vector of the <code class="reqn">\tau^{(t_1,t_2)}_3</code> values.</p>
</td></tr>
<tr><td><code>tau4</code></td>
<td>
<p>A vector of the <code class="reqn">\tau^{(t_1,t_2)}_4</code> values.</p>
</td></tr>
<tr><td><code>tau5</code></td>
<td>
<p>A vector of the <code class="reqn">\tau^{(t_1,t_2)}_5</code> values.</p>
</td></tr>
<tr><td><code>tau6</code></td>
<td>
<p>A vector of the <code class="reqn">\tau^{(t_1,t_2)}_6</code> values.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The function uses numerical integration of the quantile function of the distribution through the <code><a href="#topic+theoTLmoms">theoTLmoms</a></code> function.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith </p>


<h3>See Also</h3>

<p><code><a href="#topic+quagno">quagno</a></code>, <code><a href="#topic+theoTLmoms">theoTLmoms</a></code>, <code><a href="#topic+tlmrln3">tlmrln3</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
tlmrgno(leftrim=3, rightrim=2, xi=0, alpha=2)
tlmrgno(leftrim=3, rightrim=2, xi=120, alpha=55) # another slow example

## End(Not run)
## Not run: 
  # Plot and L-moment ratio diagram of Tau3 and Tau4
  # with exclusive focus on the GNO distribution.
  plotlmrdia(lmrdia(), autolegend=TRUE, xleg=-.1, yleg=.6,
             xlim=c(-.8, .7), ylim=c(-.1, .8),
             nolimits=TRUE, nogev=TRUE, nogpa=TRUE, nope3=TRUE,
             noglo=TRUE, nocau=TRUE, noexp=TRUE, nonor=TRUE,
             nogum=TRUE, noray=TRUE, nouni=TRUE)

  # Compute the TL-moment ratios for trimming of one
  # value on the left and four on the right.
  J &lt;- tlmrgno(kbeg=-3.5, kend=3.9, leftrim=1, rightrim=4)
  lines(J$tau3, J$tau4, lwd=2, col=2) # RED CURVE

  # Compute the TL-moment ratios for trimming of four
  # values on the left and one on the right.
  J &lt;- tlmrgno(kbeg=-4, kend=4, leftrim=4, rightrim=1)
  lines(J$tau3, J$tau4, lwd=2, col=4) # BLUE CURVE

  # The kbeg and kend can be manually changed to see how
  # the resultant curve expands or contracts on the
  # extent of the L-moment ratio diagram.

## End(Not run)
## Not run: 
  # Following up, let us plot the two quantile functions
  LM  &lt;- vec2par(c(0,1,0.99), type='gno', paracheck=FALSE)
  TLM &lt;- vec2par(c(0,1,3.00), type='gno', paracheck=FALSE)
  F &lt;- nonexceeds()
  plot(qnorm(F),  quagno(F, LM), type="l")
  lines(qnorm(F), quagno(F, TLM, paracheck=FALSE), col=2)
  # Notice how the TLM parameterization runs off towards
  # infinity much much earlier than the conventional
  # near limits of the GNO.

## End(Not run)
</code></pre>

<hr>
<h2 id='tlmrgpa'>Compute Select TL-moment ratios of the Generalized Pareto </h2><span id='topic+tlmrgpa'></span>

<h3>Description</h3>

<p>This function computes select TL-moment ratios of the Generalized Pareto distribution for defaults of <code class="reqn">\xi = 0</code> and <code class="reqn">\alpha = 1</code>. This function can be useful for plotting the trajectory of the distribution on TL-moment ratio diagrams of <code class="reqn">\tau^{(t_1,t_2)}_2</code>, <code class="reqn">\tau^{(t_1,t_2)}_3</code>, <code class="reqn">\tau^{(t_1,t_2)}_4</code>, <code class="reqn">\tau^{(t_1,t_2)}_5</code>, and <code class="reqn">\tau^{(t_1,t_2)}_6</code>. In reality, <code class="reqn">\tau^{(t_1,t_2)}_2</code> is dependent on the values for <code class="reqn">\xi</code> and <code class="reqn">\alpha</code>. If the message </p>
<pre>Error in integrate(XofF, 0, 1) : the integral is probably divergent</pre><p> occurs then careful adjustment of the shape parameter <code class="reqn">\kappa</code> parameter range is very likely required. Remember that TL-moments with nonzero trimming permit computation of TL-moments into parameter ranges beyond those recognized for the usual (untrimmed) L-moments.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tlmrgpa(trim=NULL, leftrim=NULL, rightrim=NULL,
        xi=0, alpha=1, kbeg=-.99, kend=10, by=.1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tlmrgpa_+3A_trim">trim</code></td>
<td>
<p>Level of symmetrical trimming to use in the computations.
Although <code>NULL</code> in the argument list, the default is 0&mdash;the usual L-moment ratios are returned.</p>
</td></tr>
<tr><td><code id="tlmrgpa_+3A_leftrim">leftrim</code></td>
<td>
<p>Level of trimming of the left-tail of the sample.</p>
</td></tr>
<tr><td><code id="tlmrgpa_+3A_rightrim">rightrim</code></td>
<td>
<p>Level of trimming of the right-tail of the sample.</p>
</td></tr>
<tr><td><code id="tlmrgpa_+3A_xi">xi</code></td>
<td>
<p>Location parameter of the distribution.</p>
</td></tr>
<tr><td><code id="tlmrgpa_+3A_alpha">alpha</code></td>
<td>
<p>Scale parameter of the distribution.</p>
</td></tr>
<tr><td><code id="tlmrgpa_+3A_kbeg">kbeg</code></td>
<td>
<p>The beginning <code class="reqn">\kappa</code> value of the distribution.</p>
</td></tr>
<tr><td><code id="tlmrgpa_+3A_kend">kend</code></td>
<td>
<p>The ending <code class="reqn">\kappa</code> value of the distribution.</p>
</td></tr>
<tr><td><code id="tlmrgpa_+3A_by">by</code></td>
<td>
<p>The increment for the <code>seq()</code> between <code>kbeg</code> and <code>kend</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> is returned.
</p>
<table>
<tr><td><code>tau2</code></td>
<td>
<p>A vector of the <code class="reqn">\tau^{(t_1,t_2)}_2</code> values.</p>
</td></tr>
<tr><td><code>tau3</code></td>
<td>
<p>A vector of the <code class="reqn">\tau^{(t_1,t_2)}_3</code> values.</p>
</td></tr>
<tr><td><code>tau4</code></td>
<td>
<p>A vector of the <code class="reqn">\tau^{(t_1,t_2)}_4</code> values.</p>
</td></tr>
<tr><td><code>tau5</code></td>
<td>
<p>A vector of the <code class="reqn">\tau^{(t_1,t_2)}_5</code> values.</p>
</td></tr>
<tr><td><code>tau6</code></td>
<td>
<p>A vector of the <code class="reqn">\tau^{(t_1,t_2)}_6</code> values.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The function uses numerical integration of the quantile function of the distribution through the <code><a href="#topic+theoTLmoms">theoTLmoms</a></code> function.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith </p>


<h3>See Also</h3>

<p><code><a href="#topic+quagpa">quagpa</a></code>, <code><a href="#topic+theoTLmoms">theoTLmoms</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
tlmrgpa(leftrim=7, rightrim=2, xi=0, alpha=31)
tlmrgpa(leftrim=7, rightrim=2, xi=143, alpha=98) # another slow example

## End(Not run)
## Not run: 
  # Plot and L-moment ratio diagram of Tau3 and Tau4
  # with exclusive focus on the GPA distribution.
  plotlmrdia(lmrdia(), autolegend=TRUE, xleg=-.1, yleg=.6,
             xlim=c(-.8, .7), ylim=c(-.1, .8),
             nolimits=TRUE, nogev=TRUE, noglo=TRUE, nope3=TRUE,
             nogno=TRUE, nocau=TRUE, noexp=TRUE, nonor=TRUE,
             nogum=TRUE, noray=TRUE, nouni=TRUE)

  # Compute the TL-moment ratios for trimming of one
  # value on the left and four on the right. Notice the
  # expansion of the kappa parameter space from k &gt; -1.
  J &lt;- tlmrgpa(kbeg=-3.2, kend=50, by=.05, leftrim=1, rightrim=4)
  lines(J$tau3, J$tau4, lwd=2, col=2) # RED CURVE
  # Notice the gap in the curve near tau3 = 0.1

  # Compute the TL-moment ratios for trimming of four
  # values on the left and one on the right.
  J &lt;- tlmrgpa(kbeg=-1.6, kend=8, leftrim=4, rightrim=1)
  lines(J$tau3, J$tau4, lwd=2, col=3) # GREEN CURVE

  # The kbeg and kend can be manually changed to see how
  # the resultant curve expands or contracts on the
  # extent of the L-moment ratio diagram.

## End(Not run)
## Not run: 
  # Following up, let us plot the two quantile functions
  LM  &lt;- vec2par(c(0,1,0.99), type='gpa', paracheck=FALSE)
  TLM &lt;- vec2par(c(0,1,3.00), type='gpa', paracheck=FALSE)
  F &lt;- nonexceeds()
  plot(qnorm(F),  quagpa(F, LM), type="l")
  lines(qnorm(F), quagpa(F, TLM, paracheck=FALSE), col=2)
  # Notice how the TLM parameterization runs off towards
  # infinity much much earlier than the conventional
  # near limits of the GPA.

## End(Not run)
</code></pre>

<hr>
<h2 id='tlmrgum'>Compute Select TL-moment ratios of the Gumbel Distribution </h2><span id='topic+tlmrgum'></span>

<h3>Description</h3>

<p>This function computes select TL-moment ratios of the Gumbel distribution for defaults of <code class="reqn">\xi = 0</code> and <code class="reqn">\alpha = 1</code>. This function can be useful for plotting the trajectory of the distribution on TL-moment ratio diagrams of <code class="reqn">\tau^{(t_1,t_2)}_2</code>, <code class="reqn">\tau^{(t_1,t_2)}_3</code>, <code class="reqn">\tau^{(t_1,t_2)}_4</code>, <code class="reqn">\tau^{(t_1,t_2)}_5</code>, and <code class="reqn">\tau^{(t_1,t_2)}_6</code>. In reality, <code class="reqn">\tau^{(t_1,t_2)}_2</code> is  dependent on the values for <code class="reqn">\xi</code> and <code class="reqn">\alpha</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tlmrgum(trim=NULL, leftrim=NULL, rightrim=NULL, xi=0, alpha=1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tlmrgum_+3A_trim">trim</code></td>
<td>
<p>Level of symmetrical trimming to use in the computations.
Although <code>NULL</code> in the argument list, the default is 0&mdash;the usual L-moment ratios are returned.</p>
</td></tr>
<tr><td><code id="tlmrgum_+3A_leftrim">leftrim</code></td>
<td>
<p>Level of trimming of the left-tail of the sample.</p>
</td></tr>
<tr><td><code id="tlmrgum_+3A_rightrim">rightrim</code></td>
<td>
<p>Level of trimming of the right-tail of the sample.</p>
</td></tr>
<tr><td><code id="tlmrgum_+3A_xi">xi</code></td>
<td>
<p>Location parameter of the distribution.</p>
</td></tr>
<tr><td><code id="tlmrgum_+3A_alpha">alpha</code></td>
<td>
<p>Scale parameter of the distribution.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> is returned.
</p>
<table>
<tr><td><code>tau2</code></td>
<td>
<p>A vector of the <code class="reqn">\tau^{(t_1,t_2)}_2</code> values.</p>
</td></tr>
<tr><td><code>tau3</code></td>
<td>
<p>A vector of the <code class="reqn">\tau^{(t_1,t_2)}_3</code> values.</p>
</td></tr>
<tr><td><code>tau4</code></td>
<td>
<p>A vector of the <code class="reqn">\tau^{(t_1,t_2)}_4</code> values.</p>
</td></tr>
<tr><td><code>tau5</code></td>
<td>
<p>A vector of the <code class="reqn">\tau^{(t_1,t_2)}_5</code> values.</p>
</td></tr>
<tr><td><code>tau6</code></td>
<td>
<p>A vector of the <code class="reqn">\tau^{(t_1,t_2)}_6</code> values.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The function uses numerical integration of the quantile function of the distribution through the <code><a href="#topic+theoTLmoms">theoTLmoms</a></code> function.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith </p>


<h3>See Also</h3>

<p><code><a href="#topic+quagum">quagum</a></code>, <code><a href="#topic+theoTLmoms">theoTLmoms</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
tlmrgum(trim=2)
tlmrgum(trim=2, xi=2) # another slow example

## End(Not run)
</code></pre>

<hr>
<h2 id='tlmrln3'>Compute Select TL-moment ratios of the 3-Parameter Log-Normal Distribution </h2><span id='topic+tlmrln3'></span>

<h3>Description</h3>

<p>This function computes select TL-moment ratios of the Log-Normal3 distribution for defaults of <code class="reqn">\zeta = 0</code> and <code class="reqn">\mu_\mathrm{log} = 0</code>. This function can be useful for plotting the trajectory of the distribution on TL-moment ratio diagrams of <code class="reqn">\tau^{(t_1,t_2)}_2</code>, <code class="reqn">\tau^{(t_1,t_2)}_3</code>, <code class="reqn">\tau^{(t_1,t_2)}_4</code>, <code class="reqn">\tau^{(t_1,t_2)}_5</code>, and <code class="reqn">\tau^{(t_1,t_2)}_6</code>. In reality, <code class="reqn">\tau^{(t_1,t_2)}_2</code> is dependent on the values for <code class="reqn">\zeta</code> and <code class="reqn">\mu_\mathrm{log}</code>. If the message </p>
<pre>Error in integrate(XofF, 0, 1) : the integral is probably divergent</pre><p> occurs then careful adjustment of the shape parameter <code class="reqn">\sigma_\mathrm{log}</code> parameter range is very likely required. Remember that TL-moments with nonzero trimming permit computation of TL-moments into parameter ranges beyond those recognized for the usual (untrimmed) L-moments.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tlmrln3(trim=NULL, leftrim=NULL, rightrim=NULL,
        zeta=0, mulog=0, sbeg=0.01, send=3.5, by=.1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tlmrln3_+3A_trim">trim</code></td>
<td>
<p>Level of symmetrical trimming to use in the computations.
Although <code>NULL</code> in the argument list, the default is 0&mdash;the usual L-moment ratios are returned.</p>
</td></tr>
<tr><td><code id="tlmrln3_+3A_leftrim">leftrim</code></td>
<td>
<p>Level of trimming of the left-tail of the sample.</p>
</td></tr>
<tr><td><code id="tlmrln3_+3A_rightrim">rightrim</code></td>
<td>
<p>Level of trimming of the right-tail of the sample.</p>
</td></tr>
<tr><td><code id="tlmrln3_+3A_zeta">zeta</code></td>
<td>
<p>Location parameter of the distribution.</p>
</td></tr>
<tr><td><code id="tlmrln3_+3A_mulog">mulog</code></td>
<td>
<p>Mean of the logarithms of the distribution.</p>
</td></tr>
<tr><td><code id="tlmrln3_+3A_sbeg">sbeg</code></td>
<td>
<p>The beginning <code class="reqn">\sigma_\mathrm{log}</code> value of the distribution.</p>
</td></tr>
<tr><td><code id="tlmrln3_+3A_send">send</code></td>
<td>
<p>The ending <code class="reqn">\sigma_\mathrm{log}</code> value of the distribution.</p>
</td></tr>
<tr><td><code id="tlmrln3_+3A_by">by</code></td>
<td>
<p>The increment for the <code>seq()</code> between <code>sbeg</code> and <code>send</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> is returned.
</p>
<table>
<tr><td><code>tau2</code></td>
<td>
<p>A vector of the <code class="reqn">\tau^{(t_1,t_2)}_2</code> values.</p>
</td></tr>
<tr><td><code>tau3</code></td>
<td>
<p>A vector of the <code class="reqn">\tau^{(t_1,t_2)}_3</code> values.</p>
</td></tr>
<tr><td><code>tau4</code></td>
<td>
<p>A vector of the <code class="reqn">\tau^{(t_1,t_2)}_4</code> values.</p>
</td></tr>
<tr><td><code>tau5</code></td>
<td>
<p>A vector of the <code class="reqn">\tau^{(t_1,t_2)}_5</code> values.</p>
</td></tr>
<tr><td><code>tau6</code></td>
<td>
<p>A vector of the <code class="reqn">\tau^{(t_1,t_2)}_6</code> values.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The function uses numerical integration of the quantile function of the distribution through the <code><a href="#topic+theoTLmoms">theoTLmoms</a></code> function.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith </p>


<h3>See Also</h3>

<p><code><a href="#topic+qualn3">qualn3</a></code>, <code><a href="#topic+theoTLmoms">theoTLmoms</a></code>, <code><a href="#topic+tlmrgno">tlmrgno</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
  # Recalling that generalized Normal and log-Normal3 are
  # the same with the GNO being the more general.

  # Plot and L-moment ratio diagram of Tau3 and Tau4
  # with exclusive focus on the GNO distribution.
  plotlmrdia(lmrdia(), autolegend=TRUE, xleg=-.1, yleg=.6,
             xlim=c(-.8, .7), ylim=c(-.1, .8),
             nolimits=TRUE, noglo=TRUE, nogpa=TRUE, nope3=TRUE,
             nogev=TRUE, nocau=TRUE, noexp=TRUE, nonor=TRUE,
             nogum=TRUE, noray=TRUE, nouni=TRUE)

  LN3 &lt;- tlmrln3(sbeg=.001, mulog=-1)
  lines(LN3$tau3, LN3$tau4) # See how it overplots the GNO
  # for right skewness. So only part of the GNO is covered.

  # Compute the TL-moment ratios for trimming of one
  # value on the left and four on the right.
  J &lt;- tlmrgno(kbeg=-3.5, kend=3.9, leftrim=1, rightrim=4)
  lines(J$tau3, J$tau4, lwd=2, col=2) # RED CURVE

  LN3 &lt;- tlmrln3(, leftrim=1, rightrim=4, sbeg=.001)
  lines(LN3$tau3, LN3$tau4) # See how it again over plots
  # only part of the GNO

## End(Not run)
</code></pre>

<hr>
<h2 id='tlmrnor'>Compute Select TL-moment ratios of the Normal Distribution </h2><span id='topic+tlmrnor'></span>

<h3>Description</h3>

<p>This function computes select TL-moment ratios of the Normal distribution for defaults of <code class="reqn">\mu = 0</code> and <code class="reqn">\sigma = 1</code>. This function can be useful for plotting the trajectory of the distribution on TL-moment ratio diagrams of <code class="reqn">\tau^{(t_1,t_2)}_2</code>, <code class="reqn">\tau^{(t_1,t_2)}_3</code>, <code class="reqn">\tau^{(t_1,t_2)}_4</code>, <code class="reqn">\tau^{(t_1,t_2)}_5</code>, and <code class="reqn">\tau^{(t_1,t_2)}_6</code>. In reality, <code class="reqn">\tau^{(t_1,t_2)}_2</code> is  dependent on the values for <code class="reqn">\mu</code> and <code class="reqn">\sigma</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tlmrnor(trim=NULL, leftrim=NULL, rightrim=NULL, mu=0, sigma=1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tlmrnor_+3A_trim">trim</code></td>
<td>
<p>Level of symmetrical trimming to use in the computations.
Although <code>NULL</code> in the argument list, the default is 0&mdash;the usual L-moment ratios are returned.</p>
</td></tr>
<tr><td><code id="tlmrnor_+3A_leftrim">leftrim</code></td>
<td>
<p>Level of trimming of the left-tail of the sample.</p>
</td></tr>
<tr><td><code id="tlmrnor_+3A_rightrim">rightrim</code></td>
<td>
<p>Level of trimming of the right-tail of the sample.</p>
</td></tr>
<tr><td><code id="tlmrnor_+3A_mu">mu</code></td>
<td>
<p>Location parameter (mean) of the distribution.</p>
</td></tr>
<tr><td><code id="tlmrnor_+3A_sigma">sigma</code></td>
<td>
<p>Scale parameter (standard deviation) of the distribution.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> is returned.
</p>
<table>
<tr><td><code>tau2</code></td>
<td>
<p>A vector of the <code class="reqn">\tau^{(t_1,t_2)}_2</code> values.</p>
</td></tr>
<tr><td><code>tau3</code></td>
<td>
<p>A vector of the <code class="reqn">\tau^{(t_1,t_2)}_3</code> values.</p>
</td></tr>
<tr><td><code>tau4</code></td>
<td>
<p>A vector of the <code class="reqn">\tau^{(t_1,t_2)}_4</code> values.</p>
</td></tr>
<tr><td><code>tau5</code></td>
<td>
<p>A vector of the <code class="reqn">\tau^{(t_1,t_2)}_5</code> values.</p>
</td></tr>
<tr><td><code>tau6</code></td>
<td>
<p>A vector of the <code class="reqn">\tau^{(t_1,t_2)}_6</code> values.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The function uses numerical integration of the quantile function of the distribution through the <code><a href="#topic+theoTLmoms">theoTLmoms</a></code> function.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith </p>


<h3>See Also</h3>

<p><code><a href="#topic+quanor">quanor</a></code>, <code><a href="#topic+theoTLmoms">theoTLmoms</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
tlmrnor(leftrim=2, rightrim=1)
tlmrnor(leftrim=2, rightrim=1, mu=100, sigma=1000) # another slow example

## End(Not run)
</code></pre>

<hr>
<h2 id='tlmrpe3'>Compute Select TL-moment ratios of the Pearson Type III </h2><span id='topic+tlmrpe3'></span>

<h3>Description</h3>

<p>This function computes select TL-moment ratios of the Pearson Type III distribution for defaults of <code class="reqn">\xi = 0</code> and <code class="reqn">\beta = 1</code>. This function can be useful for plotting the trajectory of the distribution on TL-moment ratio diagrams of <code class="reqn">\tau^{(t_1,t_2)}_2</code>, <code class="reqn">\tau^{(t_1,t_2)}_3</code>, <code class="reqn">\tau^{(t_1,t_2)}_4</code>, <code class="reqn">\tau^{(t_1,t_2)}_5</code>, and <code class="reqn">\tau^{(t_1,t_2)}_6</code>. In reality, <code class="reqn">\tau^{(t_1,t_2)}_2</code> is  dependent on the values for <code class="reqn">\xi</code> and <code class="reqn">\alpha</code>. If the message </p>
<pre>Error in integrate(XofF, 0, 1) : the integral is probably divergent</pre><p> occurs then careful adjustment of the shape parameter <code class="reqn">\beta</code> parameter range is very likely required. Remember that TL-moments with nonzero trimming permit computation of TL-moments into parameter ranges beyond those recognized for the usual (untrimmed) L-moments. The function uses numerical integration of the quantile function of the distribution through the <code><a href="#topic+theoTLmoms">theoTLmoms</a></code> function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tlmrpe3(trim=NULL, leftrim=NULL, rightrim=NULL,
        xi=0, beta=1, abeg=-.99, aend=0.99, by=.1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tlmrpe3_+3A_trim">trim</code></td>
<td>
<p>Level of symmetrical trimming to use in the computations.
Although <code>NULL</code> in the argument list, the default is 0&mdash;the usual L-moment ratios are returned.</p>
</td></tr>
<tr><td><code id="tlmrpe3_+3A_leftrim">leftrim</code></td>
<td>
<p>Level of trimming of the left-tail of the sample.</p>
</td></tr>
<tr><td><code id="tlmrpe3_+3A_rightrim">rightrim</code></td>
<td>
<p>Level of trimming of the right-tail of the sample.</p>
</td></tr>
<tr><td><code id="tlmrpe3_+3A_xi">xi</code></td>
<td>
<p>Location parameter of the distribution.</p>
</td></tr>
<tr><td><code id="tlmrpe3_+3A_beta">beta</code></td>
<td>
<p>Scale parameter of the distribution.</p>
</td></tr>
<tr><td><code id="tlmrpe3_+3A_abeg">abeg</code></td>
<td>
<p>The beginning <code class="reqn">\alpha</code> value of the distribution.</p>
</td></tr>
<tr><td><code id="tlmrpe3_+3A_aend">aend</code></td>
<td>
<p>The ending <code class="reqn">\alpha</code> value of the distribution.</p>
</td></tr>
<tr><td><code id="tlmrpe3_+3A_by">by</code></td>
<td>
<p>The increment for the <code>seq()</code> between <code>abeg</code> and <code>aend</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> is returned.
</p>
<table>
<tr><td><code>tau2</code></td>
<td>
<p>A vector of the <code class="reqn">\tau^{(t_1,t_2)}_2</code> values.</p>
</td></tr>
<tr><td><code>tau3</code></td>
<td>
<p>A vector of the <code class="reqn">\tau^{(t_1,t_2)}_3</code> values.</p>
</td></tr>
<tr><td><code>tau4</code></td>
<td>
<p>A vector of the <code class="reqn">\tau^{(t_1,t_2)}_4</code> values.</p>
</td></tr>
<tr><td><code>tau5</code></td>
<td>
<p>A vector of the <code class="reqn">\tau^{(t_1,t_2)}_5</code> values.</p>
</td></tr>
<tr><td><code>tau6</code></td>
<td>
<p>A vector of the <code class="reqn">\tau^{(t_1,t_2)}_6</code> values.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The function uses numerical integration of the quantile function of the distribution through the <code><a href="#topic+theoTLmoms">theoTLmoms</a></code> function.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith </p>


<h3>See Also</h3>

<p><code><a href="#topic+quape3">quape3</a></code>, <code><a href="#topic+theoTLmoms">theoTLmoms</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
tlmrpe3(leftrim=2, rightrim=4, xi=0, beta=2)
tlmrpe3(leftrim=2, rightrim=4, xi=100, beta=20) # another slow example
  # Plot and L-moment ratio diagram of Tau3 and Tau4
  # with exclusive focus on the PE3 distribution.
  plotlmrdia(lmrdia(), autolegend=TRUE, xleg=-.1, yleg=.6,
             xlim=c(-.8, .7), ylim=c(-.1, .8),
             nolimits=TRUE, nogev=TRUE, nogpa=TRUE, noglo=TRUE,
             nogno=TRUE, nocau=TRUE, noexp=TRUE, nonor=TRUE,
             nogum=TRUE, noray=TRUE, nouni=TRUE)

  # Compute the TL-moment ratios for trimming of one
  # value on the left and four on the right. Notice the
  # expansion of the alpha parameter space from
  # -1 &lt; a &lt; -1 to something larger based on manual
  # adjustments until blue curve encompassed the plot.
  J &lt;- tlmrpe3(abeg=-15, aend=6, leftrim=1, rightrim=4)
  lines(J$tau3, J$tau4, lwd=2, col=2) # RED CURVE

  # Compute the TL-moment ratios for trimming of four
  # values on the left and one on the right.
  J &lt;- tlmrpe3(abeg=-6, aend=10, leftrim=4, rightrim=1)
  lines(J$tau3, J$tau4, lwd=2, col=4) # BLUE CURVE

  # The abeg and aend can be manually changed to see how
  # the resultant curve expands or contracts on the
  # extent of the L-moment ratio diagram.

## End(Not run)
## Not run: 
  # Following up, let us plot the two quantile functions
  LM  &lt;- vec2par(c(0,1,0.99), type='pe3', paracheck=FALSE)
  TLM &lt;- vec2par(c(0,1,3.00), type='pe3', paracheck=FALSE)
  F &lt;- nonexceeds()
  plot(qnorm(F),  quape3(F, LM), type="l")
  lines(qnorm(F), quape3(F, TLM, paracheck=FALSE), col=2)
  # Notice how the TLM parameterization runs off towards
  # infinity much much earlier than the conventional
  # near limits of the PE3.

## End(Not run)
</code></pre>

<hr>
<h2 id='tlmrray'>Compute Select TL-moment ratios of the Rayleigh Distribution </h2><span id='topic+tlmrray'></span>

<h3>Description</h3>

<p>This function computes select TL-moment ratios of the Rayleigh distribution for defaults of <code class="reqn">\xi = 0</code> and <code class="reqn">\alpha = 1</code>. This function can be useful for plotting the trajectory of the distribution on TL-moment ratio diagrams of <code class="reqn">\tau^{(t_1,t_2)}_2</code>, <code class="reqn">\tau^{(t_1,t_2)}_3</code>, <code class="reqn">\tau^{(t_1,t_2)}_4</code>, <code class="reqn">\tau^{(t_1,t_2)}_5</code>, and <code class="reqn">\tau^{(t_1,t_2)}_6</code>.  In reality, <code class="reqn">\tau^{(t_1,t_2)}_2</code> is  dependent on the values for <code class="reqn">\xi</code> and <code class="reqn">\alpha</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tlmrray(trim=NULL, leftrim=NULL, rightrim=NULL, xi=0, alpha=1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tlmrray_+3A_trim">trim</code></td>
<td>
<p>Level of symmetrical trimming to use in the computations.
Although <code>NULL</code> in the argument list, the default is 0&mdash;the usual L-moment ratios are returned.</p>
</td></tr>
<tr><td><code id="tlmrray_+3A_leftrim">leftrim</code></td>
<td>
<p>Level of trimming of the left-tail of the sample.</p>
</td></tr>
<tr><td><code id="tlmrray_+3A_rightrim">rightrim</code></td>
<td>
<p>Level of trimming of the right-tail of the sample.</p>
</td></tr>
<tr><td><code id="tlmrray_+3A_xi">xi</code></td>
<td>
<p>Location parameter of the distribution.</p>
</td></tr>
<tr><td><code id="tlmrray_+3A_alpha">alpha</code></td>
<td>
<p>Scale parameter of the distribution.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> is returned.
</p>
<table>
<tr><td><code>tau2</code></td>
<td>
<p>A vector of the <code class="reqn">\tau^{(t_1,t_2)}_2</code> values.</p>
</td></tr>
<tr><td><code>tau3</code></td>
<td>
<p>A vector of the <code class="reqn">\tau^{(t_1,t_2)}_3</code> values.</p>
</td></tr>
<tr><td><code>tau4</code></td>
<td>
<p>A vector of the <code class="reqn">\tau^{(t_1,t_2)}_4</code> values.</p>
</td></tr>
<tr><td><code>tau5</code></td>
<td>
<p>A vector of the <code class="reqn">\tau^{(t_1,t_2)}_5</code> values.</p>
</td></tr>
<tr><td><code>tau6</code></td>
<td>
<p>A vector of the <code class="reqn">\tau^{(t_1,t_2)}_6</code> values.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The function uses numerical integration of the quantile function of the distribution through the <code><a href="#topic+theoTLmoms">theoTLmoms</a></code> function.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith </p>


<h3>See Also</h3>

<p><code><a href="#topic+quaray">quaray</a></code>, <code><a href="#topic+theoTLmoms">theoTLmoms</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
tlmrray(leftrim=2, rightrim=1, xi=0, alpha=2)
tlmrray(leftrim=2, rightrim=1, xi=10, alpha=2) # another slow example

## End(Not run)
</code></pre>

<hr>
<h2 id='tttlmomco'>Total Time on Test Transform of Distributions</h2><span id='topic+tttlmomco'></span>

<h3>Description</h3>

<p>This function computes the Total Time on Test Transform Quantile Function for a quantile function <code class="reqn">x(F)</code> (<code><a href="#topic+par2qua">par2qua</a></code>, <code><a href="#topic+qlmomco">qlmomco</a></code>).  The TTT is defined by Nair et al. (2013, p. 171&ndash;172, 176) has several expressions
</p>
<p style="text-align: center;"><code class="reqn">T(u) = \mu - (1 - u) M(u)\mbox{,}</code>
</p>

<p style="text-align: center;"><code class="reqn">T(u) = x(u) - u R(u)\mbox{,}</code>
</p>

<p style="text-align: center;"><code class="reqn">T(u) = (1-u) x(u) + \mu L(u)\mbox{,}</code>
</p>

<p>where <code class="reqn">T(u)</code> is the total time on test for nonexceedance probability <code class="reqn">u</code>,  <code class="reqn">M(u)</code> is the residual mean quantile function (<code><a href="#topic+rmlmomco">rmlmomco</a></code>), <code class="reqn">x(u)</code> is a constant for <code class="reqn">x(F = u)</code>, <code class="reqn">R(u)</code> is the reversed mean residual quantile function (<code><a href="#topic+rrmlmomco">rrmlmomco</a></code>), <code class="reqn">L(u)</code> is the Lorenz curve (<code><a href="#topic+lrzlmomco">lrzlmomco</a></code>), and <code class="reqn">\mu</code> as the following definitions
</p>
<p style="text-align: center;"><code class="reqn">\mu \equiv \lambda_1(u=0)\mbox{\ first L-moment of residual life for\ }u=0\mbox{,}</code>
</p>

<p style="text-align: center;"><code class="reqn">\mu \equiv \lambda_1(x(F))\mbox{\ first L-moment of the quantile function}\mbox{,}</code>
</p>

<p style="text-align: center;"><code class="reqn">\mu \equiv \mu(0)\mbox{\ conditional mean for\ }u=0\mbox{.}</code>
</p>

<p>The definitions imply that within numerical tolerances that <code class="reqn">\mu(0)</code> (<code><a href="#topic+cmlmomco">cmlmomco</a></code>) should be equal to <code class="reqn">T(1)</code>, which means that the conditional mean that the 0th percentile in life has been reached equals that total time on test for the 100th percentile. The later can be interpreted as meaning that each of realization of the lifetime distribution for the respective sample size lived to its expected ordered lifetimes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tttlmomco(f, para)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tttlmomco_+3A_f">f</code></td>
<td>
<p>Nonexceedance probability (<code class="reqn">0 \le F \le 1</code>).</p>
</td></tr>
<tr><td><code id="tttlmomco_+3A_para">para</code></td>
<td>
<p>The parameters from <code><a href="#topic+lmom2par">lmom2par</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Total time on test value for <code class="reqn">F</code>.
</p>


<h3>Note</h3>

<p>The second definition for <code class="reqn">\mu</code> is used and in <span class="pkg">lmomco</span> code the implementation for nonexceedance probability <code>f</code> and parameter object <code>para</code> is
</p>
<pre>
Tu &lt;- par2qua(f, para) - f*rrmlmomco(f, para) # 2nd def.
</pre>
<p>but other possible implementations for the first and third definitions respectively are
</p>
<pre>
Tu &lt;- cmlmomco(f=0, para) - (1-f)*rmlmomco(f, para) # 1st def.
Tu &lt;- (1-f)*par2qua(f, para) + cmlmomco(f=0, para)*lrzlmomco(f, para) # 3rd def.
</pre>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Nair, N.U., Sankaran, P.G., and Balakrishnan, N., 2013, Quantile-based reliability analysis: Springer, New York.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+qlmomco">qlmomco</a></code>, <code><a href="#topic+rmlmomco">rmlmomco</a></code>, <code><a href="#topic+rrmlmomco">rrmlmomco</a></code>, <code><a href="#topic+lrzlmomco">lrzlmomco</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># It is easiest to think about residual life as starting at the origin, units in days.
A &lt;- vec2par(c(0.0, 2649, 2.11), type="gov") # so set lower bounds = 0.0
tttlmomco(0.5, A)  # The median lifetime = 859 days

f &lt;- c(0.25,0.75) # All three computations report: 306.2951 and 1217.1360 days.
Tu1 &lt;- cmlmomco(f=0, A) - (1-f)* rmlmomco(f, A)
Tu2 &lt;-    par2qua(f, A) -    f * rrmlmomco(f, A)
Tu3 &lt;- (1-f)*par2qua(f, A) + cmlmomco(f=0, A)*lrzlmomco(f, A)

if(abs(cmlmomco(0,A) - tttlmomco(1,A)) &lt; 1E-4) {
   print("These two quantities should be nearly identical.\n")
}
</code></pre>

<hr>
<h2 id='tulia6Eprecip'>Annual Maximum Precipitation Data for Tulia 6E, Texas</h2><span id='topic+tulia6Eprecip'></span>

<h3>Description</h3>

<p>Annual maximum precipitation data for Tulia 6E, Texas
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(tulia6Eprecip)
</code></pre>


<h3>Format</h3>

<p>An <span class="rlang"><b>R</b></span> <code>data.frame</code> with
</p>

<dl>
<dt>YEAR</dt><dd><p>The calendar year of the annual maxima.</p>
</dd>
<dt>DEPTH</dt><dd><p>The depth of 7-day annual maxima rainfall in inches.</p>
</dd>
</dl>



<h3>References</h3>

<p>Asquith, W.H., 1998, Depth-duration frequency of precipitation for
Texas: U.S. Geological Survey Water-Resources Investigations Report
98&ndash;4044, 107 p.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(tulia6Eprecip)
summary(tulia6Eprecip)
</code></pre>

<hr>
<h2 id='tuliaprecip'>Annual Maximum Precipitation Data for Tulia, Texas</h2><span id='topic+tuliaprecip'></span>

<h3>Description</h3>

<p>Annual maximum precipitation data for Tulia, Texas
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(tuliaprecip)
</code></pre>


<h3>Format</h3>

<p>An <span class="rlang"><b>R</b></span> <code>data.frame</code> with
</p>

<dl>
<dt>YEAR</dt><dd><p>The calendar year of the annual maxima.</p>
</dd>
<dt>DEPTH</dt><dd><p>The depth of 7-day annual maxima rainfall in inches.</p>
</dd>
</dl>



<h3>References</h3>

<p>Asquith, W.H., 1998, Depth-duration frequency of precipitation for
Texas: U.S. Geological Survey Water-Resources Investigations Report
98&ndash;4044, 107 p.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(tuliaprecip)
summary(tuliaprecip)
</code></pre>

<hr>
<h2 id='TX38lgtrmFlow'>First six L-moments of logarithms of annual mean streamflow and variances for 35 selected long-term U.S. Geological Survey streamflow-gaging stations in Texas</h2><span id='topic+TX38lgtrmFlow'></span>

<h3>Description</h3>

<p>L-moments of annual mean streamflow for 35 long-term U.S. Geological Survey (USGS) streamflow-gaging stations (streamgages) with at least 49 years of natural and unregulated record through water year 2012 (Asquith and Barbie, 2014). Logarithmic transformations of annual mean streamflow at each of the 35 streamgages were done. For example, logarithmic transformation of strictly positive hydrologic data is done to avoid conditional probability adjustment for the zero values; values equal to zero must be offset to avoid using a logarithm of zero. A mathematical benefit of using logarithmic transformation is that probability distributions with infinite lower and upper limits become applicable. An arbitrary value of 10 cubic feet per second was added to the streamflows for each of the 35 streamgages prior to logarithmic transformation to accommodate mean annual streamflows equal to zero (no flow). These data should be referred to as the offset-annual mean streamflow. The offsetting along the real-number line permits direct use of logarithmic transformations without the added complexity of conditional probability adjustment for zero values in magnitude and frequency analyses.
</p>
<p>The first six sample L-moments of the base-10 logarithms of the offset-annual mean streamflow were computed using the <code>lmoms(..., nmom=6)</code>. The sampling variances of each corresponding L-moment are used to compute regional or study-area values for the L-moments through weighted-mean computation.  The available years of record for each of 35 stations is so large as to produce severe numerical problems in matrices needed for sampling variances using the recently developed the exact-analytical bootstrap for L-moments method (Wang and Hutson, 2013) (<code><a href="#topic+lmoms.bootbarvar">lmoms.bootbarvar</a></code>). In order to compute sampling variances for each of the sample L-moments for each streamgage, replacement-bootstrap simulation using the <code>sample(..., replace=TRUE)</code> function with 10,000 replications with replacement.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(TX38lgtrmFlow)
</code></pre>


<h3>Format</h3>

<p>An <span class="rlang"><b>R</b></span> <code>data.frame</code> with
</p>

<dl>
<dt>STATION</dt><dd><p>The USGS streamgage number.</p>
</dd>
<dt>YEARS</dt><dd><p>The number of years of data record.</p>
</dd>
<dt>Mean</dt><dd><p>The arthimetic mean (<code class="reqn">\lambda_1</code>) of <code class="reqn">\log_{10}(x + 10)</code>, where <code class="reqn">x</code> is the vector of data.</p>
</dd>
<dt>Lscale</dt><dd><p>The L-scale (<code class="reqn">\lambda_2</code>) of the log10-offset data.</p>
</dd>
<dt>LCV</dt><dd><p>The coefficient of L-variation (<code class="reqn">\tau_2</code>) of the log10-offset data.</p>
</dd>
<dt>Lskew</dt><dd><p>The L-skew (<code class="reqn">\tau_3</code>) of the log10-offset data.</p>
</dd>
<dt>Lkurtosis</dt><dd><p>The L-kurtosis (<code class="reqn">\tau_4</code>) of the log10-offset data.</p>
</dd>
<dt>Tau5</dt><dd><p>The <code class="reqn">\tau_5</code> of the log10-offset data.</p>
</dd>
<dt>Tau6</dt><dd><p>The <code class="reqn">\tau_6</code> of the log10-offset data.</p>
</dd>
<dt>VarMean</dt><dd><p>The estimated sampling variance for <code class="reqn">\lambda_1</code> multiplied by 1000.</p>
</dd>
<dt>VarLscale</dt><dd><p>The estimated sampling variance for <code class="reqn">\lambda_2</code> multiplied by 1000.</p>
</dd>
<dt>VarLCV</dt><dd><p>The estimated sampling variance for <code class="reqn">\tau_2</code> multiplied by 1000.</p>
</dd>
<dt>VarLskew</dt><dd><p>The estimated sampling variance for <code class="reqn">\tau_3</code> multiplied by 1000.</p>
</dd>
<dt>VarLkurtosis</dt><dd><p>The estimated sampling variance for <code class="reqn">\tau_4</code> multiplied by 1000.</p>
</dd>
<dt>VarTau5</dt><dd><p>The estimated sampling variance for <code class="reqn">\tau_5</code> multiplied by 1000.</p>
</dd>
<dt>VarTau6</dt><dd><p>The estimated sampling variance for <code class="reqn">\tau_6</code> multiplied by 1000.</p>
</dd>
</dl>



<h3>Note</h3>

<p>The title of this dataset indicates 35 stations, and 35 stations is the length of the data. The name of the dataset <code>TX38lgtrmFlow</code> and the source of the data (Asquith and Barbie, 2014) reflects 38 stations. It was decided to not show the data for 3 of the stations because a trend was detected but the dataset had already been named. The inconsistency will have to stand.
</p>


<h3>References</h3>

<p>Asquith, W.H., and Barbie, D.L., 2014, Trend analysis and selected summary statistics of annual mean streamflow for 38 selected long-term U.S. Geological Survey streamflow-gaging stations in Texas, water years 1916&ndash;2012: U.S. Geological Survey Scientific Investigations Report 2013&ndash;5230, 16 p.
</p>
<p>Wang, D., and Hutson, A.D., 2013, Joint confidence region estimation of L-moments with an extension to right censored data: Journal of Applied Statistics, v. 40, no. 2, pp. 368&ndash;379.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(TX38lgtrmFlow)
summary(TX38lgtrmFlow)
## Not run: 
# Need to load libraries in this order
library(lmomco); library(lmomRFA)
data(TX38lgtrmFlow)
TxDat &lt;- TX38lgtrmFlow
TxDat &lt;- TxDat[,-c(4)]; TxDat &lt;- TxDat[,-c(8:15)]
summary(regtst(TxDat))
TxDat2 &lt;- TxDat[-c(11, 28),] # Remove 08082700 Millers Creek near Munday
                             # Remove 08190500 West Nueces River at Brackettville
# No explanation for why Millers Creek is so radically discordant with the other
# streamgages with the possible exception that its data record does not span the
# drought of the 1950s like many of the other streamgages.
# The West Nueces is a highly different river from even nearby streamgages. It
# is a problem in flood frequency analysis too. So not surprizing to see this
# streamgage come up as discordant.
summary(regtst(TxDat2))
S &lt;- summary(regtst(TxDat2))
# The results suggest that none of the 3-parameter distributions are suitable.
# The bail out solution using the Wakeby distribution is accepted. Our example
# will continue on by consideration of the two 4-parameter distributions
# available. A graphical comparison between three frequency curves will be made.
kap &lt;- S$rpara
rmom &lt;- S$rmom
lmr &lt;- vec2lmom(rmom, lscale=FALSE)
aep &lt;- paraep4(lmr)
F &lt;- as.numeric(unlist(attributes(S$quant)$dimnames[2]))
plot(qnorm(F), S$quant[6,], type="l", lwd=3, lty=2,
     xlab="Nonexceedance probability (as standard normal variate)",
     ylab="Frequency factor (dimensionless)")
lines(qnorm(F), quakap(F, kap), col=4, lwd=2)
lines(qnorm(F), quaaep4(F, aep), col=2)
legend(-1, 0.8, c("Wakeby distribution (5 parameters)",
                  "Kappa distribution (4 parameters)",
                  "Asymmetrical Exponential Power distribution (4 parameters)"),
       bty = "n", cex=0.75, lwd=c(3,2,1), lty=c(2,1,1), col=c(1,4,2)
      )
# Based on general left tail behavior the Wakeby distribution is not acceptable.
# Based on general right tail behavior the AEP is preferred.
#
# It is recognized that the regional analysis provided by regtst() indicates
# substantial heterogeneity by all three definitions of that statistic. Further
# analysis to somehow compensate for climatological and general physiographic
# differences between the watersheds might be able to compensate for the
# heterogeneity. Such an effort is outside scope of this example.
#
# Suppose that the following data set is available for particular stream site from
# a short record streamgage, let us apply the dimensionless frequency curve as
# defined by the asymmetric exponential power distribution. Lettuce also use the
# 50-year drought as an example. This recurrence interval has a nonexceedance
# probability of 0.02. Lastly, there is the potential with this particular process
# to compute a negative annual mean streamflow, when this happens truncate to zero.
data &lt;- c(11.9, 42.8, 36, 20.4, 43.8, 30.7, 91.1, 54.7, 43.7, 17, 28.7, 20.5, 81.2)
xbar &lt;- mean(log10(data + 10)) # shift, log, and mean
# Note the application of the "the index method" within the exponentiation.
tmp.quantile &lt;- 10^(xbar*quaaep4(0.02, aep)) - 10 # detrans, offset
Q50yeardrought &lt;- ifelse(tmp.quantile &lt; 0, 0, tmp.quantile)
# The value is 2.53 cubic feet per second average streamflow.

## End(Not run)
</code></pre>

<hr>
<h2 id='USGSsta01515000peaks'>Annual Peak Streamflow Data for U.S. Geological Survey Streamflow-Gaging Station 01515000</h2><span id='topic+USGSsta01515000peaks'></span>

<h3>Description</h3>

<p>Annual peak streamflow data for U.S. Geological Survey streamflow-gaging station 01515000. The peak streamflow-qualification codes <code>Flag</code> are:
</p>

<dl>
<dt>1</dt><dd><p>Discharge is a Maximum Daily Average</p>
</dd>
<dt>2</dt><dd><p>Discharge is an Estimate</p>
</dd>
<dt>3</dt><dd><p>Discharge affected by Dam Failure</p>
</dd>
<dt>4</dt><dd><p>Discharge less than indicated value, which is Minimum Recordable Discharge at this site</p>
</dd>
<dt>5</dt><dd><p>Discharge affected to unknown degree by Regulation or Diversion</p>
</dd>
<dt>6</dt><dd><p>Discharge affected by Regulation or Diversion</p>
</dd>
<dt>7</dt><dd><p>Discharge is an Historic Peak</p>
</dd>
<dt>8</dt><dd><p>Discharge actually greater than indicated value</p>
</dd>
<dt>9</dt><dd><p>Discharge due to Snowmelt, Hurricane, Ice-Jam or Debris Dam breakup</p>
</dd>
<dt>A</dt><dd><p>Year of occurrence is unknown or not exact</p>
</dd>
<dt>B</dt><dd><p>Month or Day of occurrence is unknown or not exact</p>
</dd>
<dt>C</dt><dd><p>All or part of the record affected by Urbanization, Mining, Agricultural changes, Channelization, or other</p>
</dd>
<dt>D</dt><dd><p>Base Discharge changed during this year</p>
</dd>
<dt>E</dt><dd><p>Only Annual Maximum Peak available for this year</p>
</dd>
</dl>

<p>The gage height qualification codes <code>Flag.1</code> are:
</p>

<dl>
<dt>1</dt><dd><p>Gage height affected by backwater</p>
</dd>
<dt>2</dt><dd><p>Gage height not the maximum for the year</p>
</dd>
<dt>3</dt><dd><p>Gage height at different site and(or) datum</p>
</dd>
<dt>4</dt><dd><p>Gage height below minimum recordable elevation</p>
</dd>
<dt>5</dt><dd><p>Gage height is an estimate</p>
</dd>
<dt>6</dt><dd><p>Gage datum changed during this year</p>
</dd>
</dl>



<h3>Usage</h3>

<pre><code class='language-R'>data(USGSsta01515000peaks)
</code></pre>


<h3>Format</h3>

<p>An <span class="rlang"><b>R</b></span> <code>data.frame</code> with
</p>

<dl>
<dt>Date</dt><dd><p>The date of the annual peak streamflow.</p>
</dd>
<dt>Streamflow</dt><dd><p>Annual peak streamflow data in cubic feet per second.</p>
</dd>
<dt>Flags</dt><dd><p>Qualification flags on the streamflow data.</p>
</dd>
<dt>Stage</dt><dd><p>Annual peak stage (gage height, river height) in feet.</p>
</dd>
<dt>Flags.1</dt><dd><p>Qualification flags on the gage height data.</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>data(USGSsta01515000peaks)
## Not run: plot(USGSsta01515000peaks)
</code></pre>

<hr>
<h2 id='USGSsta02366500peaks'>Annual Peak Streamflow Data for U.S. Geological Survey Streamflow-Gaging Station 02366500</h2><span id='topic+USGSsta02366500peaks'></span>

<h3>Description</h3>

<p>Annual peak streamflow data for U.S. Geological Survey streamflow-gaging station 02366500. The peak streamflow-qualification codes <code>Flag</code> are:
</p>

<dl>
<dt>1</dt><dd><p>Discharge is a Maximum Daily Average</p>
</dd>
<dt>2</dt><dd><p>Discharge is an Estimate</p>
</dd>
<dt>3</dt><dd><p>Discharge affected by Dam Failure</p>
</dd>
<dt>4</dt><dd><p>Discharge less than indicated value, which is Minimum Recordable Discharge at this site</p>
</dd>
<dt>5</dt><dd><p>Discharge affected to unknown degree by Regulation or Diversion</p>
</dd>
<dt>6</dt><dd><p>Discharge affected by Regulation or Diversion</p>
</dd>
<dt>7</dt><dd><p>Discharge is an Historic Peak</p>
</dd>
<dt>8</dt><dd><p>Discharge actually greater than indicated value</p>
</dd>
<dt>9</dt><dd><p>Discharge due to Snowmelt, Hurricane, Ice-Jam or Debris Dam breakup</p>
</dd>
<dt>A</dt><dd><p>Year of occurrence is unknown or not exact</p>
</dd>
<dt>B</dt><dd><p>Month or Day of occurrence is unknown or not exact</p>
</dd>
<dt>C</dt><dd><p>All or part of the record affected by Urbanization, Mining, Agricultural changes, Channelization, or other</p>
</dd>
<dt>D</dt><dd><p>Base Discharge changed during this year</p>
</dd>
<dt>E</dt><dd><p>Only Annual Maximum Peak available for this year</p>
</dd>
</dl>

<p>The gage height qualification codes <code>Flag.1</code> are:
</p>

<dl>
<dt>1</dt><dd><p>Gage height affected by backwater</p>
</dd>
<dt>2</dt><dd><p>Gage height not the maximum for the year</p>
</dd>
<dt>3</dt><dd><p>Gage height at different site and(or) datum</p>
</dd>
<dt>4</dt><dd><p>Gage height below minimum recordable elevation</p>
</dd>
<dt>5</dt><dd><p>Gage height is an estimate</p>
</dd>
<dt>6</dt><dd><p>Gage datum changed during this year</p>
</dd>
</dl>



<h3>Usage</h3>

<pre><code class='language-R'>data(USGSsta02366500peaks)
</code></pre>


<h3>Format</h3>

<p>An <span class="rlang"><b>R</b></span> <code>data.frame</code> with
</p>

<dl>
<dt>Date</dt><dd><p>The date of the annual peak streamflow.</p>
</dd>
<dt>Streamflow</dt><dd><p>Annual peak streamflow data in cubic feet per second.</p>
</dd>
<dt>Flags</dt><dd><p>Qualification flags on the streamflow data.</p>
</dd>
<dt>Stage</dt><dd><p>Annual peak stage (gage height, river height) in feet.</p>
</dd>
<dt>Flags.1</dt><dd><p>Qualification flags on the gage height data.</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>data(USGSsta02366500peaks)
## Not run: plot(USGSsta02366500peaks)
</code></pre>

<hr>
<h2 id='USGSsta05405000peaks'>Annual Peak Streamflow Data for U.S. Geological Survey Streamflow-Gaging Station 05405000</h2><span id='topic+USGSsta05405000peaks'></span>

<h3>Description</h3>

<p>Annual peak streamflow data for U.S. Geological Survey streamflow-gaging station 05405000. The peak streamflow-qualification codes <code>Flag</code> are:
</p>

<dl>
<dt>1</dt><dd><p>Discharge is a Maximum Daily Average</p>
</dd>
<dt>2</dt><dd><p>Discharge is an Estimate</p>
</dd>
<dt>3</dt><dd><p>Discharge affected by Dam Failure</p>
</dd>
<dt>4</dt><dd><p>Discharge less than indicated value, which is Minimum Recordable Discharge at this site</p>
</dd>
<dt>5</dt><dd><p>Discharge affected to unknown degree by Regulation or Diversion</p>
</dd>
<dt>6</dt><dd><p>Discharge affected by Regulation or Diversion</p>
</dd>
<dt>7</dt><dd><p>Discharge is an Historic Peak</p>
</dd>
<dt>8</dt><dd><p>Discharge actually greater than indicated value</p>
</dd>
<dt>9</dt><dd><p>Discharge due to Snowmelt, Hurricane, Ice-Jam or Debris Dam breakup</p>
</dd>
<dt>A</dt><dd><p>Year of occurrence is unknown or not exact</p>
</dd>
<dt>B</dt><dd><p>Month or Day of occurrence is unknown or not exact</p>
</dd>
<dt>C</dt><dd><p>All or part of the record affected by Urbanization, Mining, Agricultural changes, Channelization, or other</p>
</dd>
<dt>D</dt><dd><p>Base Discharge changed during this year</p>
</dd>
<dt>E</dt><dd><p>Only Annual Maximum Peak available for this year</p>
</dd>
</dl>

<p>The gage height qualification codes <code>Flag.1</code> are:
</p>

<dl>
<dt>1</dt><dd><p>Gage height affected by backwater</p>
</dd>
<dt>2</dt><dd><p>Gage height not the maximum for the year</p>
</dd>
<dt>3</dt><dd><p>Gage height at different site and(or) datum</p>
</dd>
<dt>4</dt><dd><p>Gage height below minimum recordable elevation</p>
</dd>
<dt>5</dt><dd><p>Gage height is an estimate</p>
</dd>
<dt>6</dt><dd><p>Gage datum changed during this year</p>
</dd>
</dl>



<h3>Usage</h3>

<pre><code class='language-R'>data(USGSsta05405000peaks)
</code></pre>


<h3>Format</h3>

<p>An <span class="rlang"><b>R</b></span> <code>data.frame</code> with
</p>

<dl>
<dt>agency_cd</dt><dd><p>Agency code.</p>
</dd>
<dt>site_no</dt><dd><p>Agency station number.</p>
</dd>
<dt>peak_dt</dt><dd><p>The date of the annual peak streamflow.</p>
</dd>
<dt>peak_tm</dt><dd><p>Time of the peak streamflow.</p>
</dd>
<dt>peak_va</dt><dd><p>Annual peak streamflow data in cubic feet per second.</p>
</dd>
<dt>peak_cd</dt><dd><p>Qualification flags on the streamflow data.</p>
</dd>
<dt>gage_ht</dt><dd><p>Annual peak stage (gage height, river height) in feet.</p>
</dd>
<dt>gage_ht_cd</dt><dd><p>Qualification flags on the gage height data.</p>
</dd>
<dt>year_last_pk</dt><dd><p>Peak streamflow reported is the highest since this year.</p>
</dd>
<dt>ag_dt</dt><dd><p>Date of maximum gage-height for water year (if not concurrent with peak).</p>
</dd>
<dt>ag_tm</dt><dd><p>Time of maximum gage-height for water year (if not concurrent with peak).</p>
</dd>
<dt>ag_gage_ht</dt><dd><p>Maximum gage height for water year in feet (if not concurrent with peak).</p>
</dd>
<dt>ag_gage_ht_cd</dt><dd><p>Maximum gage height code.</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>data(USGSsta05405000peaks)
## Not run: plot(USGSsta05405000peaks)
</code></pre>

<hr>
<h2 id='USGSsta06766000dvs'>Daily Mean Streamflow Data for U.S. Geological Survey Streamflow-Gaging Station 06766000</h2><span id='topic+USGSsta06766000dvs'></span>

<h3>Description</h3>

<p>Daily mean streamflow data for U.S. Geological Survey streamflow-gaging station 06766000 PLATTE RIVER AT BRADY, NE. The qualification code <code>X01_00060_00003_cd</code> values are:
</p>

<dl>
<dt>A</dt><dd><p>Approved for publication &mdash; Processing and review completed.</p>
</dd>
<dt>1</dt><dd><p>Daily value is write protected without any remark code to be printed.</p>
</dd>
</dl>



<h3>Usage</h3>

<pre><code class='language-R'>data(USGSsta06766000dvs)
</code></pre>


<h3>Format</h3>

<p>An <span class="rlang"><b>R</b></span> <code>data.frame</code> with
</p>

<dl>
<dt>agency_cd</dt><dd><p>The agency code <code>USGS</code>.</p>
</dd>
<dt>site_no</dt><dd><p>The station identification number.</p>
</dd>
<dt>datetime</dt><dd><p>The date and time of the data.</p>
</dd>
<dt>X01_00060_00003</dt><dd><p>The daily mean streamflow data in cubic feet per second.</p>
</dd>
<dt>X01_00060_00003_cd</dt><dd><p>A code on the data value.</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>data(USGSsta06766000dvs)
## Not run: plot(USGSsta06766000dvs)
</code></pre>

<hr>
<h2 id='USGSsta08151500peaks'>Annual Peak Streamflow Data for U.S. Geological Survey Streamflow-Gaging Station 08151500</h2><span id='topic+USGSsta08151500peaks'></span>

<h3>Description</h3>

<p>Annual peak streamflow data for U.S. Geological Survey streamflow-gaging station 08151500. The peak streamflow-qualification codes <code>Flag</code> are:
</p>

<dl>
<dt>1</dt><dd><p>Discharge is a Maximum Daily Average</p>
</dd>
<dt>2</dt><dd><p>Discharge is an Estimate</p>
</dd>
<dt>3</dt><dd><p>Discharge affected by Dam Failure</p>
</dd>
<dt>4</dt><dd><p>Discharge less than indicated value, which is Minimum Recordable Discharge at this site</p>
</dd>
<dt>5</dt><dd><p>Discharge affected to unknown degree by Regulation or Diversion</p>
</dd>
<dt>6</dt><dd><p>Discharge affected by Regulation or Diversion</p>
</dd>
<dt>7</dt><dd><p>Discharge is an Historic Peak</p>
</dd>
<dt>8</dt><dd><p>Discharge actually greater than indicated value</p>
</dd>
<dt>9</dt><dd><p>Discharge due to Snowmelt, Hurricane, Ice-Jam or Debris Dam breakup</p>
</dd>
<dt>A</dt><dd><p>Year of occurrence is unknown or not exact</p>
</dd>
<dt>B</dt><dd><p>Month or Day of occurrence is unknown or not exact</p>
</dd>
<dt>C</dt><dd><p>All or part of the record affected by Urbanization, Mining, Agricultural changes, Channelization, or other</p>
</dd>
<dt>D</dt><dd><p>Base Discharge changed during this year</p>
</dd>
<dt>E</dt><dd><p>Only Annual Maximum Peak available for this year</p>
</dd>
</dl>

<p>The gage height qualification codes <code>Flag.1</code> are:
</p>

<dl>
<dt>1</dt><dd><p>Gage height affected by backwater</p>
</dd>
<dt>2</dt><dd><p>Gage height not the maximum for the year</p>
</dd>
<dt>3</dt><dd><p>Gage height at different site and(or) datum</p>
</dd>
<dt>4</dt><dd><p>Gage height below minimum recordable elevation</p>
</dd>
<dt>5</dt><dd><p>Gage height is an estimate</p>
</dd>
<dt>6</dt><dd><p>Gage datum changed during this year</p>
</dd>
</dl>



<h3>Usage</h3>

<pre><code class='language-R'>data(USGSsta08151500peaks)
</code></pre>


<h3>Format</h3>

<p>An <span class="rlang"><b>R</b></span> <code>data.frame</code> with
</p>

<dl>
<dt>Date</dt><dd><p>The date of the annual peak streamflow.</p>
</dd>
<dt>Streamflow</dt><dd><p>Annual peak streamflow data in cubic feet per second.</p>
</dd>
<dt>Flags</dt><dd><p>Qualification flags on the streamflow data.</p>
</dd>
<dt>Stage</dt><dd><p>Annual peak stage (gage height, river height) in feet.</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>data(USGSsta08151500peaks)
## Not run: plot(USGSsta08151500peaks)
</code></pre>

<hr>
<h2 id='USGSsta08167000peaks'>Annual Peak Streamflow Data for U.S. Geological Survey Streamflow-Gaging Station 08167000</h2><span id='topic+USGSsta08167000peaks'></span>

<h3>Description</h3>

<p>Annual peak streamflow data for U.S. Geological Survey streamflow-gaging station 08167000. The peak streamflow-qualification codes <code>Flag</code> are:
</p>

<dl>
<dt>1</dt><dd><p>Discharge is a Maximum Daily Average</p>
</dd>
<dt>2</dt><dd><p>Discharge is an Estimate</p>
</dd>
<dt>3</dt><dd><p>Discharge affected by Dam Failure</p>
</dd>
<dt>4</dt><dd><p>Discharge less than indicated value, which is Minimum Recordable Discharge at this site</p>
</dd>
<dt>5</dt><dd><p>Discharge affected to unknown degree by Regulation or Diversion</p>
</dd>
<dt>6</dt><dd><p>Discharge affected by Regulation or Diversion</p>
</dd>
<dt>7</dt><dd><p>Discharge is an Historic Peak</p>
</dd>
<dt>8</dt><dd><p>Discharge actually greater than indicated value</p>
</dd>
<dt>9</dt><dd><p>Discharge due to Snowmelt, Hurricane, Ice-Jam or Debris Dam breakup</p>
</dd>
<dt>A</dt><dd><p>Year of occurrence is unknown or not exact</p>
</dd>
<dt>B</dt><dd><p>Month or Day of occurrence is unknown or not exact</p>
</dd>
<dt>C</dt><dd><p>All or part of the record affected by Urbanization, Mining, Agricultural changes, Channelization, or other</p>
</dd>
<dt>D</dt><dd><p>Base Discharge changed during this year</p>
</dd>
<dt>E</dt><dd><p>Only Annual Maximum Peak available for this year</p>
</dd>
</dl>

<p>The gage height qualification codes <code>Flag.1</code> are:
</p>

<dl>
<dt>1</dt><dd><p>Gage height affected by backwater</p>
</dd>
<dt>2</dt><dd><p>Gage height not the maximum for the year</p>
</dd>
<dt>3</dt><dd><p>Gage height at different site and(or) datum</p>
</dd>
<dt>4</dt><dd><p>Gage height below minimum recordable elevation</p>
</dd>
<dt>5</dt><dd><p>Gage height is an estimate</p>
</dd>
<dt>6</dt><dd><p>Gage datum changed during this year</p>
</dd>
</dl>



<h3>Usage</h3>

<pre><code class='language-R'>data(USGSsta08167000peaks)
</code></pre>


<h3>Format</h3>

<p>An <span class="rlang"><b>R</b></span> <code>data.frame</code> with
</p>

<dl>
<dt>agency_cd</dt><dd><p>Agency code.</p>
</dd>
<dt>site_no</dt><dd><p>Agency station number.</p>
</dd>
<dt>peak_dt</dt><dd><p>The date of the annual peak streamflow.</p>
</dd>
<dt>peak_tm</dt><dd><p>Time of the peak streamflow.</p>
</dd>
<dt>peak_va</dt><dd><p>Annual peak streamflow data in cubic feet per second.</p>
</dd>
<dt>peak_cd</dt><dd><p>Qualification flags on the streamflow data.</p>
</dd>
<dt>gage_ht</dt><dd><p>Annual peak stage (gage height, river height) in feet.</p>
</dd>
<dt>gage_ht_cd</dt><dd><p>Qualification flags on the gage height data.</p>
</dd>
<dt>year_last_pk</dt><dd><p>Peak streamflow reported is the highest since this year.</p>
</dd>
<dt>ag_dt</dt><dd><p>Date of maximum gage-height for water year (if not concurrent with peak).</p>
</dd>
<dt>ag_tm</dt><dd><p>Time of maximum gage-height for water year (if not concurrent with peak).</p>
</dd>
<dt>ag_gage_ht</dt><dd><p>Maximum gage height for water year in feet (if not concurrent with peak).</p>
</dd>
<dt>ag_gage_ht_cd</dt><dd><p>Maximum gage height code.</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>data(USGSsta08167000peaks)
## Not run: plot(USGSsta08167000peaks)
</code></pre>

<hr>
<h2 id='USGSsta08190000peaks'>Annual Peak Streamflow Data for U.S. Geological Survey Streamflow-Gaging Station 08190000</h2><span id='topic+USGSsta08190000peaks'></span>

<h3>Description</h3>

<p>Annual peak streamflow data for U.S. Geological Survey streamflow-gaging station 08190000. The peak streamflow-qualification codes <code>Flag</code> are:
</p>

<dl>
<dt>1</dt><dd><p>Discharge is a Maximum Daily Average</p>
</dd>
<dt>2</dt><dd><p>Discharge is an Estimate</p>
</dd>
<dt>3</dt><dd><p>Discharge affected by Dam Failure</p>
</dd>
<dt>4</dt><dd><p>Discharge less than indicated value, which is Minimum Recordable Discharge at this site</p>
</dd>
<dt>5</dt><dd><p>Discharge affected to unknown degree by Regulation or Diversion</p>
</dd>
<dt>6</dt><dd><p>Discharge affected by Regulation or Diversion</p>
</dd>
<dt>7</dt><dd><p>Discharge is an Historic Peak</p>
</dd>
<dt>8</dt><dd><p>Discharge actually greater than indicated value</p>
</dd>
<dt>9</dt><dd><p>Discharge due to Snowmelt, Hurricane, Ice-Jam or Debris Dam breakup</p>
</dd>
<dt>A</dt><dd><p>Year of occurrence is unknown or not exact</p>
</dd>
<dt>B</dt><dd><p>Month or Day of occurrence is unknown or not exact</p>
</dd>
<dt>C</dt><dd><p>All or part of the record affected by Urbanization, Mining, Agricultural changes, Channelization, or other</p>
</dd>
<dt>D</dt><dd><p>Base Discharge changed during this year</p>
</dd>
<dt>E</dt><dd><p>Only Annual Maximum Peak available for this year</p>
</dd>
</dl>

<p>The gage height qualification codes <code>Flag.1</code> are:
</p>

<dl>
<dt>1</dt><dd><p>Gage height affected by backwater</p>
</dd>
<dt>2</dt><dd><p>Gage height not the maximum for the year</p>
</dd>
<dt>3</dt><dd><p>Gage height at different site and(or) datum</p>
</dd>
<dt>4</dt><dd><p>Gage height below minimum recordable elevation</p>
</dd>
<dt>5</dt><dd><p>Gage height is an estimate</p>
</dd>
<dt>6</dt><dd><p>Gage datum changed during this year</p>
</dd>
</dl>



<h3>Usage</h3>

<pre><code class='language-R'>data(USGSsta08190000peaks)
</code></pre>


<h3>Format</h3>

<p>An <span class="rlang"><b>R</b></span> <code>data.frame</code> with
</p>

<dl>
<dt>agency_cd</dt><dd><p>Agency code.</p>
</dd>
<dt>site_no</dt><dd><p>Agency station number.</p>
</dd>
<dt>peak_dt</dt><dd><p>The date of the annual peak streamflow.</p>
</dd>
<dt>peak_tm</dt><dd><p>Time of the peak streamflow.</p>
</dd>
<dt>peak_va</dt><dd><p>Annual peak streamflow data in cubic feet per second.</p>
</dd>
<dt>peak_cd</dt><dd><p>Qualification flags on the streamflow data.</p>
</dd>
<dt>gage_ht</dt><dd><p>Annual peak stage (gage height, river height) in feet.</p>
</dd>
<dt>gage_ht_cd</dt><dd><p>Qualification flags on the gage height data.</p>
</dd>
<dt>year_last_pk</dt><dd><p>Peak streamflow reported is the highest since this year.</p>
</dd>
<dt>ag_dt</dt><dd><p>Date of maximum gage-height for water year (if not concurrent with peak).</p>
</dd>
<dt>ag_tm</dt><dd><p>Time of maximum gage-height for water year (if not concurrent with peak).</p>
</dd>
<dt>ag_gage_ht</dt><dd><p>Maximum gage height for water year in feet (if not concurrent with peak).</p>
</dd>
<dt>ag_gage_ht_cd</dt><dd><p>Maximum gage height code.</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>data(USGSsta08190000peaks)
## Not run: plot(USGSsta08190000peaks)
</code></pre>

<hr>
<h2 id='USGSsta09442000peaks'>Annual Peak Streamflow Data for U.S. Geological Survey Streamflow-Gaging Station 09442000</h2><span id='topic+USGSsta09442000peaks'></span>

<h3>Description</h3>

<p>Annual peak streamflow data for U.S. Geological Survey streamflow-gaging station 09442000.  The peak streamflow-qualification codes <code>Flag</code> are:
</p>

<dl>
<dt>1</dt><dd><p>Discharge is a Maximum Daily Average</p>
</dd>
<dt>2</dt><dd><p>Discharge is an Estimate</p>
</dd>
<dt>3</dt><dd><p>Discharge affected by Dam Failure</p>
</dd>
<dt>4</dt><dd><p>Discharge less than indicated value, which is Minimum Recordable Discharge at this site</p>
</dd>
<dt>5</dt><dd><p>Discharge affected to unknown degree by Regulation or Diversion</p>
</dd>
<dt>6</dt><dd><p>Discharge affected by Regulation or Diversion</p>
</dd>
<dt>7</dt><dd><p>Discharge is an Historic Peak</p>
</dd>
<dt>8</dt><dd><p>Discharge actually greater than indicated value</p>
</dd>
<dt>9</dt><dd><p>Discharge due to Snowmelt, Hurricane, Ice-Jam or Debris Dam breakup</p>
</dd>
<dt>A</dt><dd><p>Year of occurrence is unknown or not exact</p>
</dd>
<dt>B</dt><dd><p>Month or Day of occurrence is unknown or not exact</p>
</dd>
<dt>C</dt><dd><p>All or part of the record affected by Urbanization, Mining, Agricultural changes, Channelization, or other</p>
</dd>
<dt>D</dt><dd><p>Base Discharge changed during this year</p>
</dd>
<dt>E</dt><dd><p>Only Annual Maximum Peak available for this year</p>
</dd>
</dl>

<p>The gage height qualification codes <code>Flag.1</code> are:
</p>

<dl>
<dt>1</dt><dd><p>Gage height affected by backwater</p>
</dd>
<dt>2</dt><dd><p>Gage height not the maximum for the year</p>
</dd>
<dt>3</dt><dd><p>Gage height at different site and(or) datum</p>
</dd>
<dt>4</dt><dd><p>Gage height below minimum recordable elevation</p>
</dd>
<dt>5</dt><dd><p>Gage height is an estimate</p>
</dd>
<dt>6</dt><dd><p>Gage datum changed during this year</p>
</dd>
</dl>



<h3>Usage</h3>

<pre><code class='language-R'>data(USGSsta09442000peaks)
</code></pre>


<h3>Format</h3>

<p>An <span class="rlang"><b>R</b></span> <code>data.frame</code> with
</p>

<dl>
<dt>Date</dt><dd><p>The date of the annual peak streamflow.</p>
</dd>
<dt>Streamflow</dt><dd><p>Annual peak streamflow data in cubic feet per second.</p>
</dd>
<dt>Flags</dt><dd><p>Qualification flags on the streamflow data.</p>
</dd>
<dt>Stage</dt><dd><p>Annual peak stage (gage height, river height) in feet.</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>data(USGSsta09442000peaks)
## Not run: plot(USGSsta09442000peaks)
</code></pre>

<hr>
<h2 id='USGSsta14321000peaks'>Annual Peak Streamflow Data for U.S. Geological Survey Streamflow-Gaging Station 14321000</h2><span id='topic+USGSsta14321000peaks'></span>

<h3>Description</h3>

<p>Annual peak streamflow data for U.S. Geological Survey streamflow-gaging station 14321000. The peak streamflow-qualification codes <code>Flag</code> are:
</p>

<dl>
<dt>1</dt><dd><p>Discharge is a Maximum Daily Average</p>
</dd>
<dt>2</dt><dd><p>Discharge is an Estimate</p>
</dd>
<dt>3</dt><dd><p>Discharge affected by Dam Failure</p>
</dd>
<dt>4</dt><dd><p>Discharge less than indicated value, which is Minimum Recordable Discharge at this site</p>
</dd>
<dt>5</dt><dd><p>Discharge affected to unknown degree by Regulation or Diversion</p>
</dd>
<dt>6</dt><dd><p>Discharge affected by Regulation or Diversion</p>
</dd>
<dt>7</dt><dd><p>Discharge is an Historic Peak</p>
</dd>
<dt>8</dt><dd><p>Discharge actually greater than indicated value</p>
</dd>
<dt>9</dt><dd><p>Discharge due to Snowmelt, Hurricane, Ice-Jam or Debris Dam breakup</p>
</dd>
<dt>A</dt><dd><p>Year of occurrence is unknown or not exact</p>
</dd>
<dt>B</dt><dd><p>Month or Day of occurrence is unknown or not exact</p>
</dd>
<dt>C</dt><dd><p>All or part of the record affected by Urbanization, Mining, Agricultural changes, Channelization, or other</p>
</dd>
<dt>D</dt><dd><p>Base Discharge changed during this year</p>
</dd>
<dt>E</dt><dd><p>Only Annual Maximum Peak available for this year</p>
</dd>
</dl>

<p>The gage height qualification codes <code>Flag.1</code> are:
</p>

<dl>
<dt>1</dt><dd><p>Gage height affected by backwater</p>
</dd>
<dt>2</dt><dd><p>Gage height not the maximum for the year</p>
</dd>
<dt>3</dt><dd><p>Gage height at different site and(or) datum</p>
</dd>
<dt>4</dt><dd><p>Gage height below minimum recordable elevation</p>
</dd>
<dt>5</dt><dd><p>Gage height is an estimate</p>
</dd>
<dt>6</dt><dd><p>Gage datum changed during this year</p>
</dd>
</dl>



<h3>Usage</h3>

<pre><code class='language-R'>data(USGSsta14321000peaks)
</code></pre>


<h3>Format</h3>

<p>An <span class="rlang"><b>R</b></span> <code>data.frame</code> with
</p>

<dl>
<dt>Date</dt><dd><p>The date of the annual peak streamflow.</p>
</dd>
<dt>Streamflow</dt><dd><p>Annual peak streamflow data in cubic feet per second.</p>
</dd>
<dt>Flags</dt><dd><p>Qualification flags on the streamflow data.</p>
</dd>
<dt>Stage</dt><dd><p>Annual peak stage (gage height, river height) in feet.</p>
</dd>
<dt>Flags.1</dt><dd><p>Qualification flags on the gage height data.</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>data(USGSsta14321000peaks)
## Not run: plot(USGSsta14321000peaks)
</code></pre>

<hr>
<h2 id='vec2lmom'>Convert a Vector of L-moments to a L-moment Object</h2><span id='topic+vec2lmom'></span>

<h3>Description</h3>

<p>This function converts a vector of L-moments to a L-moment object of <span class="pkg">lmomco</span>. The object is an <span class="rlang"><b>R</b></span> <code>list</code>. This function is intended to facilitate the use of L-moments (and TL-moments) that the user might have from other sources. L-moments and L-moment ratios of arbitrary length are supported.
</p>
<p>Because in typical practice, the <code class="reqn">k \ge 3</code> order L-moments are dimensionless ratios (<code class="reqn">\tau_3</code>, <code class="reqn">\tau_4</code>, and <code class="reqn">\tau_5</code>), this function computes <code class="reqn">\lambda_3</code>, <code class="reqn">\lambda_4</code>, <code class="reqn">\lambda_5</code> from <code class="reqn">\lambda_2</code> from the ratios. However, typical practice is not set on the use of <code class="reqn">\lambda_2</code> or <code class="reqn">\tau</code> as measure of dispersion. Therefore, this function takes an <code>lscale</code> optional logical (<code>TRUE|FALSE</code>) argument&mdash;if <code class="reqn">\lambda_2</code> is provided and <code>lscale=TRUE</code>, then <code class="reqn">\tau</code> is computed by the function and if <code class="reqn">\tau</code> is provided, then <code class="reqn">\lambda_2</code> is computed by the function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>vec2lmom(vec, lscale=TRUE,
         trim=NULL, leftrim=NULL, rightrim=NULL, checklmom=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="vec2lmom_+3A_vec">vec</code></td>
<td>
<p>A vector of L-moment values in <code class="reqn">\lambda_1</code>, <code class="reqn">\lambda_2</code> or <code class="reqn">\tau</code>, <code class="reqn">\tau_3</code>, <code class="reqn">\tau_4</code>, and <code class="reqn">\tau_5</code> order.</p>
</td></tr>
<tr><td><code id="vec2lmom_+3A_lscale">lscale</code></td>
<td>
<p>A logical switch on the type of the second value of first argument.
L-scale (<code class="reqn">\lambda_2</code>) or LCV (<code class="reqn">\tau</code>). Default is <code>TRUE</code>,
the second value in the first argument is <code class="reqn">\lambda_2</code>.</p>
</td></tr>
<tr><td><code id="vec2lmom_+3A_trim">trim</code></td>
<td>
<p>Level of symmetrical trimming, which should equal <code>NULL</code> if asymmetrical trimming is used.</p>
</td></tr>
<tr><td><code id="vec2lmom_+3A_leftrim">leftrim</code></td>
<td>
<p>Level of trimming of the left-tail of the sample, which will equal <code>NULL</code> even if <code>trim = 1</code> if the trimming is symmetrical.</p>
</td></tr>
<tr><td><code id="vec2lmom_+3A_rightrim">rightrim</code></td>
<td>
<p>Level of trimming of the right-tail of the sample, which will equal <code>NULL</code> even if <code>trim = 1</code> if the trimming is symmetrical.</p>
</td></tr>
<tr><td><code id="vec2lmom_+3A_checklmom">checklmom</code></td>
<td>
<p>Should the <code>lmom</code> be checked for validity using the <code><a href="#topic+are.lmom.valid">are.lmom.valid</a></code> function. Normally this should be left as the default unless TL-moments are being constructed in lieu of using <code><a href="#topic+vec2TLmom">vec2TLmom</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> is returned.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>See Also</h3>

<p><code><a href="#topic+lmoms">lmoms</a></code>, <code><a href="#topic+vec2pwm">vec2pwm</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>lmr &lt;- vec2lmom(c(12,0.6,0.34,0.20,0.05),lscale=FALSE)
</code></pre>

<hr>
<h2 id='vec2par'>Convert a Vector of Parameters to a Parameter Object of a Distribution</h2><span id='topic+vec2par'></span>

<h3>Description</h3>

<p>This function converts a vector of parameters to a parameter object of a distribution. The type of distribution is specified in the
argument list:
<code>aep4</code>, <code>cau</code>, <code>exp</code>, <code>gam</code>, <code>gep</code>, <code>gev</code>,
<code>glo</code>, <code>gno</code>, <code>gpa</code>, <code>gum</code>, <code>kap</code>,
<code>kur</code>, <code>lap</code>, <code>lmrq</code>, <code>ln3</code>, <code>nor</code>,
<code>pe3</code>, <code>ray</code>, <code>revgum</code>, <code>rice</code>, <code>st3</code>,
<code>texp</code>, <code>wak</code>, and <code>wei</code>. These abbreviations and only these are used in routing logic within <span class="pkg">lmomco</span>. There is no provision for fuzzy matching. However, if the distribution type is not identified, then the function issues a warning, but goes ahead and creates the parameter list and of course can not check for the validity of the parameters. If one has a need to determine on-the-fly the number of parameters in a distribution as supported in <span class="pkg">lmomco</span>, then see the <code><a href="#topic+dist.list">dist.list</a></code> function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>vec2par(vec, type, nowarn=FALSE, paracheck=TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="vec2par_+3A_vec">vec</code></td>
<td>
<p>A vector of parameter values for the distribution specified by type.</p>
</td></tr>
<tr><td><code id="vec2par_+3A_type">type</code></td>
<td>
<p>Three character distribution type (for example, <code>type='gev'</code>).</p>
</td></tr>
<tr><td><code id="vec2par_+3A_nowarn">nowarn</code></td>
<td>
<p>A logical switch on warning suppression. If <code>TRUE</code> then <code>options(warn=-1)</code> is made and restored on return. This switch is to permit calls in which warnings are not desired as the user knows how to handle the returned value&mdash;say in an optimization algorithm.</p>
</td></tr>
<tr><td><code id="vec2par_+3A_paracheck">paracheck</code></td>
<td>
<p>A logical controlling whether the parameters and checked for validity. Overriding of this check might be extremely important and needed for use of the distribution quantile function in the context of TL-moments with nonzero trimming.</p>
</td></tr>
<tr><td><code id="vec2par_+3A_...">...</code></td>
<td>
<p>Additional arguments for the <code><a href="#topic+are.par.valid">are.par.valid</a></code> call that is made internally.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If the distribution is a Reverse Gumbel (<code>type=revgum</code>) or Generalized Pareto (<code>type=gpa</code>), which are 2-parameter or 3-parameter distributions, the third or fourth value in the vector is the <code class="reqn">\zeta</code> of the distribution. <code class="reqn">\zeta</code> represents the fraction of the sample that is noncensored, or number of observed (noncensored) values divided by the sample size. The <code class="reqn">\zeta</code> represents censoring on the right, that is there are unknown observations above a threshold or the largest observed sample. Consultation of <code><a href="#topic+parrevgum">parrevgum</a></code> or <code><a href="#topic+pargpaRC">pargpaRC</a></code> should elucidate the censoring discussion.
</p>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> is returned. This list should contain at least the following items, but some distributions such as the <code>revgum</code> have extra.
</p>
<table>
<tr><td><code>type</code></td>
<td>
<p>The type of distribution in three character format.</p>
</td></tr>
<tr><td><code>para</code></td>
<td>
<p>The parameters of the distribution.</p>
</td></tr>
<tr><td><code>source</code></td>
<td>
<p>Attribute specifying source of the parameters&mdash;&ldquo;vec2par&rdquo;.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>If the <code>type</code> is not amongst the official list given above, then the <code>type</code> given is loaded into the <code>type</code> element of the returned list and an other element <code>isuser = TRUE</code> is also added. There is no <code>isuser</code> created if the distribution is supported by <span class="pkg">lmomco</span>. This is an attempt to given some level of flexibility so that others can create their own distributions or conduct research on derivative code from <span class="pkg">lmomco</span>.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>See Also</h3>

<p><code><a href="#topic+lmom2par">lmom2par</a></code>, <code><a href="#topic+par2vec">par2vec</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>para &lt;- vec2par(c(12,123,0.5),'gev')
Q &lt;- quagev(0.5,para)

my.custom &lt;- vec2par(c(2,2), type='myowndist') # Think about making your own
</code></pre>

<hr>
<h2 id='vec2pwm'>Convert a Vector of Probability-Weighted Moments to a Probability-Weighted Moments Object</h2><span id='topic+vec2pwm'></span>

<h3>Description</h3>

<p>This function converts a vector of probability-weighted moments (PWM) to a PWM
object of <span class="pkg">lmomco</span>. The object is an <span class="rlang"><b>R</b></span> <code>list</code>. This function is intended
to facilitate the use of PWM that the user might have from other sources. The
first five PWMs are supported (<code class="reqn">\beta_0</code>, <code class="reqn">\beta_1</code>, <code class="reqn">\beta_2</code>,
<code class="reqn">\beta_3</code>, <code class="reqn">\beta_4</code>) if <code>as.list=FALSE</code> otherwise the <code class="reqn">\beta_r</code> are unlimited.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>vec2pwm(vec, as.list=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="vec2pwm_+3A_vec">vec</code></td>
<td>
<p>A vector of PWM values in (<code class="reqn">\beta_0</code>, <code class="reqn">\beta_1</code>, <code class="reqn">\beta_2</code>, <code class="reqn">\beta_3</code>, <code class="reqn">\beta_4</code>) order.</p>
</td></tr>
<tr><td><code id="vec2pwm_+3A_as.list">as.list</code></td>
<td>
<p>A logical controlling the returned data structure.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> is returned if <code>as.list=TRUE</code>.
</p>
<table>
<tr><td><code>BETA0</code></td>
<td>
<p>The first PWM, which is equal to the arithmetic mean.</p>
</td></tr>
<tr><td><code>BETA1</code></td>
<td>
<p>The second PWM.</p>
</td></tr>
<tr><td><code>BETA2</code></td>
<td>
<p>The third PWM.</p>
</td></tr>
<tr><td><code>BETA3</code></td>
<td>
<p>The fourth PWM.</p>
</td></tr>
<tr><td><code>BETA4</code></td>
<td>
<p>The fifth PWM.</p>
</td></tr>
<tr><td><code>source</code></td>
<td>
<p>Source of the PWMs: &ldquo;vec2pwm&rdquo;.</p>
</td></tr>
</table>
<p>Another <span class="rlang"><b>R</b></span> <code>list</code> is returned if <code>as.list=FALSE</code>.
</p>
<table>
<tr><td><code>betas</code></td>
<td>
<p>The PWMs.</p>
</td></tr>
<tr><td><code>source</code></td>
<td>
<p>Source of the PWMs: &ldquo;vec2pwm&rdquo;.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>See Also</h3>

<p><code><a href="#topic+vec2lmom">vec2lmom</a></code>, <code><a href="#topic+lmom2pwm">lmom2pwm</a></code>, <code><a href="#topic+pwm2lmom">pwm2lmom</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>pwm &lt;- vec2pwm(c(12,123,12,12,54))
</code></pre>

<hr>
<h2 id='vec2TLmom'>Convert a Vector of TL-moments to a TL-moment Object</h2><span id='topic+vec2TLmom'></span>

<h3>Description</h3>

<p>This function converts a vector of trimmed L-moments (TL-moments) to a TL-moment object of <span class="pkg">lmomco</span> by dispatch to <code><a href="#topic+vec2lmom">vec2lmom</a></code>. The object is an <span class="rlang"><b>R</b></span> <code>list</code>. This function is intended to facilitate the use of TL-moments that the user might have from other sources. The trimming on the left-tail is denoted by <code class="reqn">t</code> and the trimming on the right-tail is denoted as <code class="reqn">s</code>. The first five TL-moments are <code class="reqn">\lambda^{(t,s)}_1</code>, <code class="reqn">\lambda^{(t,s)}_2</code>, <code class="reqn">\lambda^{(t,s)}_3</code>, <code class="reqn">\lambda^{(t,s)}_4</code>, <code class="reqn">\lambda^{(t,s)}_5</code>, <code class="reqn">\tau^{(t,s)}</code>, <code class="reqn">\tau^{(t,s)}_3</code>, <code class="reqn">\tau^{(t,s)}_4</code>, and <code class="reqn">\tau^{(t,s)}_5</code>. The function supports TL-moments and TL-moment ratios of arbitrary length. Because in typical practice the <code class="reqn">k \ge 3</code> order L-moments are dimensionless ratios (<code class="reqn">\tau^{(t,s)}_3</code>, <code class="reqn">\tau^{(t,s)}_4</code>, and <code class="reqn">\tau^{(t,s)}_5</code>), this function computes <code class="reqn">\lambda^{(t,s)}_3</code>, <code class="reqn">\lambda^{(t,s)}_4</code>, <code class="reqn">\lambda^{(t,s)}_5</code> from <code class="reqn">\lambda^{(t,s)}_2</code> and the ratios. However, typical practice is not set on the use of <code class="reqn">\lambda^{(t,s)}_2</code> or <code class="reqn">\tau^{(t,s)}</code> as measure of dispersion. Therefore, this function takes an <code>lscale</code> optional logical argument&mdash;if <code class="reqn">\lambda^{(t,s)}_2</code> is provided and <code>lscale=TRUE</code>, then <code class="reqn">\tau</code> is computed by the function and if <code class="reqn">\tau</code> is provided, then <code class="reqn">\lambda^{(t,s)}_2</code> is computed by the function. The trim level of the TL-moment is required. Lastly, it might be common for <code class="reqn">t=s</code> and hence symmetrical trimming is used.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>vec2TLmom(vec, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="vec2TLmom_+3A_vec">vec</code></td>
<td>
<p>A vector of L-moment values in <code class="reqn">\lambda^{(t,s)}_1</code>, <code class="reqn">\lambda^{(t,s)}_2</code> or <code class="reqn">\tau^{(t,s)}</code>, <code class="reqn">\tau^{(t,s)}_3</code>, <code class="reqn">\tau^{(t,s)}_4</code>, and <code class="reqn">\tau^{(t,s)}_5</code> order.</p>
</td></tr>
<tr><td><code id="vec2TLmom_+3A_...">...</code></td>
<td>
<p>The arguments used by <code><a href="#topic+vec2lmom">vec2lmom</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> is returned where <code class="reqn">t</code> represents the <code>trim</code> level.
</p>
<table>
<tr><td><code>lambdas</code></td>
<td>
<p>Vector of the TL-moments. First element is <code class="reqn">\lambda^{(t,s)}_1</code>, second element is <code class="reqn">\lambda^{(t,s)}_2</code>, and so on.</p>
</td></tr>
<tr><td><code>ratios</code></td>
<td>
<p>Vector of the L-moment ratios. Second element is <code class="reqn">\tau^{(t,s)}</code>, third element is <code class="reqn">\tau^{(t,s)}_3</code> and so on.</p>
</td></tr>
<tr><td><code>trim</code></td>
<td>
<p>Level of symmetrical trimming, which should equal <code>NULL</code> if asymmetrical trimming is used.</p>
</td></tr>
<tr><td><code>leftrim</code></td>
<td>
<p>Level of trimming of the left-tail of the sample.</p>
</td></tr>
<tr><td><code>rightrim</code></td>
<td>
<p>Level of trimming of the right-tail of the sample.</p>
</td></tr>
<tr><td><code>source</code></td>
<td>
<p>An attribute identifying the computational source of the L-moments: &ldquo;TLmoms&rdquo;.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The motiviation for this function that arrange trivial arguments for <code><a href="#topic+vec2lmom">vec2lmom</a></code> is that it is uncertain how TL-moments will grow in the research community and there might someday be a needed for alternative support without having to touch <code><a href="#topic+vec2lmom">vec2lmom</a></code>. Plus there is nice function name parallelism in having a dedicated function for the TL-moments as there is for L-moments and probability-weighted moments.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>See Also</h3>

<p><code><a href="#topic+TLmoms">TLmoms</a></code>, <code><a href="#topic+vec2lmom">vec2lmom</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>TL &lt;- vec2TLmom(c(12,0.6,0.34,0.20,0.05),lscale=FALSE,trim=1)
</code></pre>

<hr>
<h2 id='vegaprecip'>Annual Maximum Precipitation Data for Vega, Texas</h2><span id='topic+vegaprecip'></span>

<h3>Description</h3>

<p>Annual maximum precipitation data for Vega, Texas
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(vegaprecip)
</code></pre>


<h3>Format</h3>

<p>An <span class="rlang"><b>R</b></span> <code>data.frame</code> with
</p>

<dl>
<dt>YEAR</dt><dd><p>The calendar year of the annual maxima.</p>
</dd>
<dt>DEPTH</dt><dd><p>The depth of 7-day annual maxima rainfall in inches.</p>
</dd>
</dl>



<h3>References</h3>

<p>Asquith, W.H., 1998, Depth-duration frequency of precipitation for
Texas: U.S. Geological Survey Water-Resources Investigations Report
98&ndash;4044, 107 p.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(vegaprecip)
summary(vegaprecip)
</code></pre>

<hr>
<h2 id='x2pars'>Estimate an Ensemble of Parameters from Three Different Methods</h2><span id='topic+x2pars'></span>

<h3>Description</h3>

<p>This function acts as a frontend to estimate an ensemble of parameters from the methods of L-moments (<code><a href="#topic+lmr2par">lmr2par</a></code>), maximum likelihood (MLE, <code><a href="#topic+mle2par">mle2par</a></code>), and maximum product of spacings (MPS, <code><a href="#topic+mps2par">mps2par</a></code>). The parameters estimated by the L-moments are used as the initial parameter guesses for the subsequent calls to MLE and MPS.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>x2pars(x, verbose=TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="x2pars_+3A_x">x</code></td>
<td>
<p>A vector of data values.</p>
</td></tr>
<tr><td><code id="x2pars_+3A_verbose">verbose</code></td>
<td>
<p>A logical to control a sequential message ahead of each method.</p>
</td></tr>
<tr><td><code id="x2pars_+3A_...">...</code></td>
<td>
<p>The additional arguments, if ever used.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code>list</code> having
</p>
<table>
<tr><td><code>lmr</code></td>
<td>
<p>Parameters from method of L-moments. This is expected to be <code>NULL</code> if the method fails, and the <code>NULL</code> is tested for in <code><a href="#topic+pars2x">pars2x</a></code>.</p>
</td></tr>
<tr><td><code>mle</code></td>
<td>
<p>Parameters from MLE. This is expected to be <code>NULL</code> if the method fails, and the <code>NULL</code> is tested for in <code><a href="#topic+pars2x">pars2x</a></code>.</p>
</td></tr>
<tr><td><code>mps</code></td>
<td>
<p>Parameters from MPS. This is expected to be <code>NULL</code> if the method fails, and the <code>NULL</code> is tested for in <code><a href="#topic+pars2x">pars2x</a></code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>See Also</h3>

<p><code><a href="#topic+pars2x">pars2x</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Simulate from GLO and refit it. Occasionally, the simulated data
# will result in MLE or MPS failing to converge, just a note to users.
set.seed(3237)
x &lt;- rlmomco(126, vec2par(c(2.5, 0.7, 0.3), type="glo"))
three.para.est &lt;- x2pars(x, type="glo")
print(three.para.est$lmr$para) # 2.5598083 0.6282518 0.1819538
print(three.para.est$mle$para) # 2.5887340 0.6340132 0.2424734
print(three.para.est$mps$para) # 2.5843058 0.6501916 0.2364034
## End(Not run)
</code></pre>

<hr>
<h2 id='x2xlo'>Conversion of a Vector through a Left-Hand Threshold to Setup Conditional Probability Computations</h2><span id='topic+x2xlo'></span>

<h3>Description</h3>

<p>This function takes a vector of numerical values and subselects the values above and those equal to or less than the <code>leftout</code> argument and assigns plotting positions based on the <code>a</code> argument (passed into the <code><a href="#topic+pp">pp</a></code> function) and returns a list providing helpful as well as necessary results needed for conditional probability adjustment to support for general magnitude and frequency analysis as often is needed in hydrologic applications. This function only performs very simple vector operations. The real features for conditional probability application are found in the <code><a href="#topic+f2flo">f2flo</a></code> and <code><a href="#topic+f2flo">f2flo</a></code> functions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>x2xlo(x, leftout=0, a=0, ghost=NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="x2xlo_+3A_x">x</code></td>
<td>
<p>A vector of values.</p>
</td></tr>
<tr><td><code id="x2xlo_+3A_leftout">leftout</code></td>
<td>
<p>The lower threshold for which to leave out. The default of zero sets up for conditional probability adjustments for values equal (or less than) zero. This argument is called &ldquo;left out&rdquo; so as to reinforce the idea that it is a lower threshold hold on which to &ldquo;leave out&rdquo; data.</p>
</td></tr>
<tr><td><code id="x2xlo_+3A_a">a</code></td>
<td>
<p>The plotting position coefficient passed to <code><a href="#topic+pp">pp</a></code>.</p>
</td></tr>
<tr><td><code id="x2xlo_+3A_ghost">ghost</code></td>
<td>
<p>A ghosting or shadowing variable to be dragged along and then split up according to the lower threshold. If not <code>NULL</code>, then the output also contains <code>ghostin</code> and <code>ghostout</code>. This is a useful feature say if the year of data collection is associated with <code>x</code> and the user wants a convenient way to keep the proper association with the year. This feature is only for the convenience of the user and does not represent some special adjustment to the underlying concepts. A warning is issued if the lengths of <code>x</code> and <code>ghost</code> are not the same, but the function continues proceeding.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> <code>list</code> is returned.
</p>
<table>
<tr><td><code>xin</code></td>
<td>
<p>The subselection of values greater than the <code>leftout</code> threshold.</p>
</td></tr>
<tr><td><code>ppin</code></td>
<td>
<p>The plotting positions of the subselected values greater than the <code>leftout</code> threshold. These plotting positions correspond to those data values in <code>xin</code>.</p>
</td></tr>
<tr><td><code>xout</code></td>
<td>
<p>The subselection of values less than or equal to the <code>leftout</code> threshold.</p>
</td></tr>
<tr><td><code>ppout</code></td>
<td>
<p>The plotting positions of the subselected values  less than or equal to the <code>leftout</code> threshold. These plotting positions correspond to those data values in <code>xout</code>.</p>
</td></tr>
<tr><td><code>pp</code></td>
<td>
<p>The plotting position of the largest value left out of <code>xin</code>.</p>
</td></tr>
<tr><td><code>thres</code></td>
<td>
<p>The threshold value provided by the argument <code>leftout</code>.</p>
</td></tr>
<tr><td><code>nin</code></td>
<td>
<p>Number of values greater than the threshold.</p>
</td></tr>
<tr><td><code>nlo</code></td>
<td>
<p>Number of values less than or equal to the threshold.</p>
</td></tr>
<tr><td><code>n</code></td>
<td>
<p>Total number of values: <code>nin</code> + <code>nlo</code>.</p>
</td></tr>
<tr><td><code>source</code></td>
<td>
<p>The source of the parameters: &ldquo;x2xlo&rdquo;.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>See Also</h3>

<p><code><a href="#topic+f2flo">f2flo</a></code>, <code><a href="#topic+flo2f">flo2f</a></code>, <code><a href="#topic+f2f">f2f</a></code>, <code><a href="#topic+xlo2qua">xlo2qua</a></code>, <code><a href="#topic+par2qua2lo">par2qua2lo</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
set.seed(62)
Fs &lt;- nonexceeds()
type &lt;- "exp"; parent &lt;- vec2par(c(0,13.4), type=type)
X &lt;- rlmomco(100, parent); a &lt;- 0; PP &lt;- pp(X, a=a); Xs &lt;- sort(X)
par &lt;- lmom2par(lmoms(X), type=type)
plot(PP, Xs, type="n", xlim=c(0,1), ylim=c(.1,100), log="y",
     xlab="NONEXCEEDANCE PROBABILITY", ylab="RANDOM VARIATE")
points(PP, Xs, col=3, cex=2, pch=0, lwd=2)
X[X &lt; 2.1] &lt;- X[X &lt; 2.1]/2 # create some low outliers
Xlo &lt;- x2xlo(X, leftout=2.1, a=a)
parlo &lt;- lmom2par(lmoms(Xlo$xin), type=type)
points(Xlo$ppout, Xlo$xout, pch=4, col=1)
points(Xlo$ppin, Xlo$xin,   col=4, cex=.7)
lines(Fs, qlmomco(Fs, parent), lty=2, lwd=2)
lines(Fs, qlmomco(Fs, par),    col=2, lwd=4)
lines(sort(c(Xlo$ppin,.999)),
      qlmomco(f2flo(sort(c(Xlo$ppin,.999)), pp=Xlo$pp), parlo), col=4, lwd=3)
# Notice how in the last line plotted that the proper plotting positions of the data
# greater than the threshold are passed into the f2flo() function that has the effect
# of mapping conventional nonexceedance probabilities into the conditional probability
# space. These mapped probabilities are then passed into the quantile function.
legend(.3,1, c("Simulated random variates",
                "Values to 'leave' (condition) out because x/2 (low outliers)",
                "Values to 'leave' in", "Exponential parent",
                "Exponential fitted to whole data set",
                "Exponential fitted to left-in values"), bty="n", cex=.75,
                pch   =c(0,4,1,NA,NA,NA), col=c(3,1,4,1,2,4), pt.lwd=c(2,1,1,1),
                pt.cex=c(2,1,0.7,1),      lwd=c(0,0,0,2,2,3),    lty=c(0,0,0,2,1,1))

## End(Not run)
</code></pre>

<hr>
<h2 id='xlo2qua'>Conversion of a Vector through a Left-Hand Threshold to Setup Conditional Probability Computations</h2><span id='topic+xlo2qua'></span>

<h3>Description</h3>

<p>This function takes a vector of nonexceedance probabilities, a parameter object, and the object of the conditional probabability structure and computes the quantiles. This function only performs very simple vector operations. The real features for conditional probability application are found in the <code><a href="#topic+x2xlo">x2xlo</a></code> and <code><a href="#topic+f2flo">f2flo</a></code> functions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>xlo2qua(f, para=NULL, xlo=NULL, augasNA=FALSE, sort=FALSE, fillthres=TRUE,
           retrans=function(x) x, paracheck=TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="xlo2qua_+3A_f">f</code></td>
<td>
<p>Nonexceedance probability (<code class="reqn">0 \le F \le 1</code>). Be aware, these are sorted internally.</p>
</td></tr>
<tr><td><code id="xlo2qua_+3A_para">para</code></td>
<td>
<p>Parameters from <code><a href="#topic+parpe3">parpe3</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
<tr><td><code id="xlo2qua_+3A_xlo">xlo</code></td>
<td>
<p>Mandatory result from <code><a href="#topic+x2xlo">x2xlo</a></code> containing the content needed for internal call to <code><a href="#topic+f2flo">f2flo</a></code> and then vector augmentation with the threshold within the <code>xlo</code>. If this is left as <code>NULL</code>, then the function simply calls the quantile function for the parameters in <code>para</code>.</p>
</td></tr>
<tr><td><code id="xlo2qua_+3A_augasna">augasNA</code></td>
<td>
<p>A logical to switch out the threshold of <code>xlo</code> for <code>NA</code>.</p>
</td></tr>
<tr><td><code id="xlo2qua_+3A_sort">sort</code></td>
<td>
<p>A logical whose default adheres to long-term assembly of <span class="pkg">lmomco</span> behavior with working with conditional trunction. Setting this to true, triggers hand assembly of the the unsorted returned quantiles with support for <code>NA</code> and more flexibility than <code><a href="#topic+x2xlo">x2xlo</a></code> as originally designed. If sort is true, then the <code>f</code> is permitted to contain <code>NA</code> values.</p>
</td></tr>
<tr><td><code id="xlo2qua_+3A_fillthres">fillthres</code></td>
<td>
<p>A logical to trigger <code>qua[qua &lt;= xlo$thres] &lt;- xlo$thres</code> or replacement of computed values less than the threshold with the threshold. The argument <code>augasNA</code> is consulted after <code>fillthres</code>.</p>
</td></tr>
<tr><td><code id="xlo2qua_+3A_retrans">retrans</code></td>
<td>
<p>A retransformation function for the quantiles after they are computed according to the <code>para</code>.</p>
</td></tr>
<tr><td><code id="xlo2qua_+3A_paracheck">paracheck</code></td>
<td>
<p>A logical controlling whether the parameters are checked for validity.</p>
</td></tr>
<tr><td><code id="xlo2qua_+3A_...">...</code></td>
<td>
<p>Additional arguments, if needed, dispatched to <code><a href="#topic+par2qua">par2qua</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of quantiles (sorted) for the nonexceedance probabilities and padding as needed to the threshold within the <code>xlo</code> object.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>See Also</h3>

<p><code><a href="#topic+f2flo">f2flo</a></code>, <code><a href="#topic+flo2f">flo2f</a></code>, <code><a href="#topic+f2f">f2f</a></code>, <code><a href="#topic+x2xlo">x2xlo</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'># This seed produces a quantile below the threshold for the FF nonexceedances and
# triggers the qua[qua &lt;= xlo$thres] &lt;- xlo$thres inside xlo2qua().

set.seed(2)
FF  &lt;- nonexceeds();  LOT &lt;- 0 # low-outlier threshold

XX  &lt;- 10^rlmomco(20, vec2par(c(3, 0.7, 0.3), type="pe3"))
XX  &lt;- c(rep(LOT, 5), XX)
# Pack the LOT values to the simulation, note that in most practical applications
# involving logarithms, that zeros rather than LOTs would be more apt, but this
# demonstration is useful because of the qua[qua &lt;= xlo$thres] (see sources).
# Now, make the xlo object using the LOT as the threshold---the out of sample flag.

xlo &lt;- x2xlo(XX, leftout=LOT)
pe3 &lt;- parpe3( lmoms( log10(xlo$xin) ) )
# Fit the PE3 to the log10 of those values remaining in the sample.

QQ  &lt;- xlo2qua(FF, para=pe3, xlo=xlo, retrans=function(x) 10^x)
# This line does all the work. Saves about four lines of code and streamlines
# logic when making frequency curves from the parameters and the xlo.

# Demonstrate this frequency curve to the observational sample.
plot(FF, QQ, log="y", type="l", col=grey(0.8))
points(pp(XX), sort(XX), col="red")

# Notice that with logic here and different seeds that XX could originally have
# values less than the threshold, so one would not have the lower tail all
# plotting along the threshold and a user might want to make other decisions.
QZ  &lt;- xlo2qua(FF, para=pe3, xlo=xlo, augasNA=TRUE, retrans=function(x) 10^x)
lines(FF, QZ, col="blue")
# See how the QZ does not plot until about FF=0.2 because of the augmentation
# as NA (augasNA) being set true.

## Not run: 
# Needs library(copBasic); library(MGBT) # too
Asite &lt;- "08148500"; Bsite &lt;- "08150000"; dtype &lt;- "gev"
AB    &lt;- MGBT::jointPeaks(Asite, Bsite) # tables of the peaks and pairwise peaks
A     &lt;- AB$Asite_no[AB$Asite_no$appearsSystematic == TRUE, ] # only record when
B     &lt;- AB$Bsite_no[AB$Bsite_no$appearsSystematic == TRUE, ] # monitoring occurring
QA    &lt;- A$peak_va; Alot &lt;- 0 # cfs (just protection from zeros, more sophisticated)
QB    &lt;- B$peak_va; Blot &lt;- 0 # cfs (work might be needed for better thresholds)
Alo   &lt;- x2xlo(QA, leftout=Alot) # A xlo object
Blo   &lt;- x2xlo(QB, leftout=Blot) # B xlo object
Apara &lt;- lmr2par(log10(Alo$xin), type=dtype) # note log10
Bpara &lt;- lmr2par(log10(Blo$xin), type=dtype) # note log10
Aupr  &lt;- 10^supdist(Apara)$support[2]
Bupr  &lt;- 10^supdist(Bpara)$support[2]
UVsS  &lt;- AB$AB[, c("U", "V")] # isolate paired empirical probabilities
rhoS  &lt;- copBasic::rhoCOP(as.sample=TRUE,     para=UVsS) # Spearman rho
infS  &lt;- copBasic::LzCOPpermsym(cop=EMPIRcop, para=UVsS, as.vec=TRUE)
# a vector of permutation (variable exchangability) distances

tparf &lt;- function(par) { c(log(par[1] -1), log(par[2]),  # transform for optimization
                   qnorm(punif(par[3],  min=-1, max=1))) }
rparf &lt;- function(par) { c(exp(par[1])+1,  exp(par[2]),  # re-transformation to copula
                   qunif(pnorm(par[3]), min=-1, max=1)) }

ofunc &lt;- function(par) { # objective function
  mypara &lt;- rparf(par)   # re-transform to copula space
  mypara &lt;- list(cop=GHcop, para=mypara[1:2], breve=mypara[3]) # asymmetry by breveCOP()
  rhoT   &lt;- copBasic::rhoCOP(cop=breveCOP, para=mypara) # Spearman rho
  infT   &lt;- copBasic::LzCOPpermsym(cop=breveCOP, para=mypara, as.vec=TRUE)
  err    &lt;- mean( (infT - infS)^2 ) + (rhoT - rhoS)^2 # sum of square-like errors
  return(err)
}
init.par &lt;- tparf(c(2, 1, 0)); rt &lt;- NULL # init parameters and root
try( rt &lt;- optim(init.par, ofunc) )
cpara &lt;- rparf(rt$par) # re-transformation
cpara &lt;- list(cop=GHcop, para=cpara[1:2], breve=cpara[3]) # copula parameters for
# an double-parameter Gumbel copula with permutation asymmetry via the breve.

ns &lt;- 1000 # years of bivariate simulation
UVsim &lt;- copBasic::rCOP(ns, cop=breveCOP, para=cpara, resamv01=TRUE) # simulation
AS &lt;- xlo2qua(UVsim[,1], para=Apara, xlo=Alo, sort=FALSE,  # **** see xlo2qua() use
                         retrans=function(x) 10^x, paracheck=FALSE)
BS &lt;- xlo2qua(UVsim[,2], para=Bpara, xlo=Blo, sort=FALSE,  # **** see xlo2qua() use
                         retrans=function(x) 10^x, paracheck=FALSE)

FF  &lt;- seq(0.001, 0.999, by=0.001); qFF &lt;- qnorm(FF) # probabilities for marginal curve
AF &lt;- xlo2qua(FF, para=Apara, xlo=Alo, sort=FALSE,         # **** see xlo2qua() use
                  retrans=function(x) 10^(x), paracheck=FALSE)
BF &lt;- xlo2qua(FF, para=Bpara, xlo=Blo, sort=FALSE,         # **** see xlo2qua() use
                  retrans=function(x) 10^(x), paracheck=FALSE)
# There might be a small region in the lower-left corner that is not attainable by the
# use of the thresholding. Let us add the complexity to the example by working out
# about the minimum points on the curves w/o more sophisticated computation.
mx &lt;- min(c(AS, AF), na.rm=TRUE); my &lt;- min(c(BS, BF), na.rm=TRUE)
# The use of the mx and my help us with a polygon to come, but also help us to set
# some axis limits that are especially suitable to see the entire situation of the
# simulation canvasing [0,1]^2 but the quantiles through the univariate margins might
# have truncation because of handling of the lower-tail by the threshold.

# finally plot the bivariate relation
plot(AB$AB$Apeak_va, AB$AB$Bpeak_va, log="xy", type="n",
     xlim=range(c(mx, QA, AS, ifelse(is.finite(Aupr), Aupr, NA)), na.rm=TRUE),
     ylim=range(c(my, QB, BS, ifelse(is.finite(Bupr), Bupr, NA)), na.rm=TRUE),
     xlab=paste0("Paired water-year peak streamflow for streamgage ", Asite),
     ylab=paste0("Paired water-year peak streamflow for streamgage ", Bsite))
cr &lt;- 10^par()$usr[c(1, 3)]             # finish forming the region in the lower-left
px &lt;- c(cr[1], mx, mx, cr[1], cr[1])    # corner that is truncated away; we do this
py &lt;- c(cr[2], cr[2], my, my, cr[2])    # this because log10() used and in practical
polygon(px, py, col="wheat", border=NA) # applications at best zeros might be data
abline(v=mx, lty=2, lwd=0.8); abline(h=my, lty=2, lwd=0.8) # further demarcation
if( is.finite(Aupr) ) abline(v=Aupr, lty=2, lwd=1.5, col="purple") # upper limit
if( is.finite(Bupr) ) abline(h=Bupr, lty=2, lwd=1.5, col="purple") # upper limit
points(AS, BS, pch=21, col="red", bg="white") # now plot the simulations
points(AB$AB$Apeak_va, AB$AB$Bpeak_va, cex=AB$AB$cex, # now plot the observed data that
       col="black", bg=grey(AB$AB$cex/2), pch=21) # defined the parameter estimation of
legend("bottomright",                             # the copula then draw a legend.
     c("Paired streamflow (fill lightens/size increases as days apart increases)",
       paste0(ns, " years simulated by copula and GEV margins")), bty="o", cex=0.8,
       pch=c(21,21), col=c("black","red"), pt.cex=c(1.3,1), pt.bg=c(grey(0.7),"white"))

ST &lt;- round(1/(1-kfuncCOP(0.99, cop=breveCOP, para=cpara)), digits=0)
message("Super-critical return period for ",
               "primary return period of 100 years is ", ST, " years.")

#  move on to showing the univariate margins by parametric fit with left-truncation
plot(qnorm(pp(QA)), sort(QA), log="y", pch=21, bg="white", main=Asite,
     ylim=range(c(QA, AF, Aupr), na.rm=TRUE),
     xlab="Standard normal variate", ylab="Peak streamflow, in cfs")
abline(h=Aupr, lty=2, lwd=1.5, col="purple")
lines(qFF, AF, lwd=3, col="seagreen")
legend("bottomright",
     c(paste0("Marginal distribution by ", toupper(dtype)),
       "Upper bounds of fitted distribution",
       "Systematic peaks by Weibull plotting position"), bty="o", seg.len=3,
       pch=c(NA,NA,21), col=c("seagreen","purple","black"), bg="white", cex=0.8,
       lty=c(1, 2, NA), lwd=c(3, 1.5, NA), pt.bg=c(NA, NA, "white"))

plot(qnorm(pp(QB)), sort(QB), log="y", pch=21, bg="white", main=Bsite,
     ylim=range(c(QB, BF, Bupr), na.rm=TRUE),
     xlab="Standard normal variate", ylab="Peak streamflow, in cfs")
abline(h=Bupr, lty=2, lwd=1.5, col="purple")
lines(qFF, BF, lwd=3, col="seagreen")
legend("bottomright",
     c(paste0("Marginal distribution by ", toupper(dtype)),
       "Upper bounds of fitted distribution",
       "Systematic peaks by Weibull plotting position"), bty="o", seg.len=3,
       pch=c(NA,NA,21), col=c("seagreen","purple","black"), bg="white", cex=0.8,
       lty=c(1, 2, NA), lwd=c(3, 1.5, NA), pt.bg=c(NA, NA, "white")) # 
## End(Not run)
</code></pre>

<hr>
<h2 id='z.par2cdf'>Blipping Cumulative Distribution Functions</h2><span id='topic+z.par2cdf'></span>

<h3>Description</h3>

<p>This function acts as a front end or dispatcher to the distribution-specific cumulative distribution functions but also provides for blipping according to
</p>
<p style="text-align: center;"><code class="reqn">F(x) = 0</code>
</p>

<p>for <code class="reqn">x \le z</code> and
</p>
<p style="text-align: center;"><code class="reqn">F(x) = p + (1-p)G(x)</code>
</p>

<p>for <code class="reqn">x &gt; z</code> where <code class="reqn">z</code> is a threshold value. The <code class="reqn">z</code> is not tracked as part of the parameter object. This might arguably be a design flaw, but the function will do its best to test whether the <code class="reqn">z</code> given is compatable (but not necessarily equal to <code class="reqn">\hat{x} = x(0)</code>) with the quantile function <code class="reqn">x(F)</code> (<code><a href="#topic+z.par2qua">z.par2qua</a></code>). Lastly, please refer to the finiteness check in the Examples to see how one might accommodate <code class="reqn">-\infty</code> for <code class="reqn">F = 0</code> on a standard normal variate plot.
</p>
<p>A recommended practice when working with this function is the insertion of the <code class="reqn">x</code> value at <code class="reqn">F=p</code>. Analogous practice is suggested for <code><a href="#topic+z.par2qua">z.par2qua</a></code> (see that documentation).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>z.par2cdf(x, p, para, z=0, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="z.par2cdf_+3A_x">x</code></td>
<td>
<p>A real value vector.</p>
</td></tr>
<tr><td><code id="z.par2cdf_+3A_p">p</code></td>
<td>
<p>Nonexceedance probability of the <code>z</code> value. This probability could simply be the portion of record having zero values if <code>z=0</code>.</p>
</td></tr>
<tr><td><code id="z.par2cdf_+3A_para">para</code></td>
<td>
<p>The parameters from <code><a href="#topic+lmom2par">lmom2par</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
<tr><td><code id="z.par2cdf_+3A_z">z</code></td>
<td>
<p>Threshold value.</p>
</td></tr>
<tr><td><code id="z.par2cdf_+3A_...">...</code></td>
<td>
<p>The additional arguments are passed to the cumulative distribution function such as <code>paracheck=FALSE</code> for the Generalized Lambda distribution (<code><a href="#topic+cdfgld">cdfgld</a></code>).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Nonexceedance probability (<code class="reqn">0 \le F \le 1</code>) for <code>x</code>.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Asquith, W.H., 2011, Distributional analysis with L-moment statistics using the R environment for statistical computing: Createspace Independent Publishing Platform, ISBN 978&ndash;146350841&ndash;8.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+z.par2qua">z.par2qua</a></code>, <code><a href="#topic+par2cdf">par2cdf</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(21)
the.gpa   &lt;- vec2par(c(100,1000,0.1),type='gpa')
fake.data &lt;- rlmomco(30,the.gpa) # simulate some data
fake.data &lt;- sort(c(fake.data,rep(0,10))) # add some zero observations
# going to tick to the inside and title right axis as well, so change some
# plotting parameters
par(mgp=c(3,0.5,0), mar=c(5,4,4,3))
# next compute the parameters for the positive data
gpa.all &lt;- pargpa(lmoms(fake.data))
gpa.nzo &lt;- pargpa(lmoms(fake.data[fake.data &gt; 0]))
n   &lt;- length(fake.data) # sample size
p   &lt;- length(fake.data[fake.data == 0])/n # est. prob of zero value
F   &lt;- nonexceeds(sig6=TRUE); F &lt;- sort(c(F,p)); qF &lt;- qnorm(F)
# The following x vector obviously contains zero, so no need to insert it.
x   &lt;- seq(-100, max(fake.data)) # absurd for x&lt;0, but testing implementation
PP  &lt;- pp(fake.data) # compute plotting positions of sim. sample
plot(fake.data, qnorm(PP), xlim=c(0,4000), yaxt="n", ylab="") # plot the sample
add.lmomco.axis(las=2, tcl=0.5, side=2, twoside=FALSE,
                                        side.type="NPP", otherside.type="SNV")
lines(quagpa(F,gpa.all), qF) # the parent (without zeros)
cdf &lt;- qnorm(z.par2cdf(x,p,gpa.nzo))
cdf[! is.finite(cdf)] &lt;- min(fake.data,qnorm(PP)) # See above documentation
lines(x, cdf,lwd=3) # fitted model with zero conditional
# now repeat the above code over and over again and watch the results
par(mgp=c(3,1,0), mar=c(5,4,4,2)+0.1) # restore defaults
</code></pre>

<hr>
<h2 id='z.par2qua'>Blipping Quantile Functions</h2><span id='topic+z.par2qua'></span>

<h3>Description</h3>

<p>This function acts as a front end or dispatcher to the distribution-specific quantile functions but also provides for blipping for zero (or other) threshold according to
</p>
<p style="text-align: center;"><code class="reqn">x(F) = 0</code>
</p>

<p>for <code class="reqn">0 \le F \le p</code> and
</p>
<p style="text-align: center;"><code class="reqn">x_G\left(\frac{F-p}{1-p}\right)</code>
</p>

<p>for <code class="reqn">F &gt; p</code>. This function is generalized for <code class="reqn">z \ne 0</code>. The <code class="reqn">z</code> is not tracked as part of the parameter object. This might arguably be a design flaw, but the function will do its best to test whether the <code class="reqn">z</code> given is compatable (but not necessarily equal to <code class="reqn">\hat{x} = x(0)</code>) with the quantile function <code class="reqn">x(F)</code>.
</p>
<p>A recommended practice when working with this function when <code class="reqn">F</code> values are generated for various purposes, such as for graphics, then the value of <code class="reqn">p</code> should be inserted into the vector, and the vector obviously sorted (see the line using the <code><a href="#topic+nonexceeds">nonexceeds</a></code> function). This should be considered as well when <code><a href="#topic+z.par2cdf">z.par2cdf</a></code> is used but with the insertion of the <code class="reqn">x</code> value at <code class="reqn">F=p</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>z.par2qua(f, p, para, z=0, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="z.par2qua_+3A_f">f</code></td>
<td>
<p>Nonexceedance probabilities (<code class="reqn">0 \le F \le 1</code>).</p>
</td></tr>
<tr><td><code id="z.par2qua_+3A_p">p</code></td>
<td>
<p>Nonexceedance probability of <code>z</code> value.</p>
</td></tr>
<tr><td><code id="z.par2qua_+3A_para">para</code></td>
<td>
<p>The parameters from <code><a href="#topic+lmom2par">lmom2par</a></code> or <code><a href="#topic+vec2par">vec2par</a></code>.</p>
</td></tr>
<tr><td><code id="z.par2qua_+3A_z">z</code></td>
<td>
<p>Threshold value.</p>
</td></tr>
<tr><td><code id="z.par2qua_+3A_...">...</code></td>
<td>
<p>The additional arguments are passed to the quantile function such as <br />  <code>paracheck = FALSE</code> for the Generalized Lambda distribution (<code><a href="#topic+quagld">quagld</a></code>).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Quantile value for <code class="reqn">f</code>.
</p>


<h3>Author(s)</h3>

<p>W.H. Asquith</p>


<h3>References</h3>

<p>Asquith, W.H., 2011, Distributional analysis with L-moment statistics using the R environment for statistical computing: Createspace Independent Publishing Platform, ISBN 978&ndash;146350841&ndash;8.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+z.par2cdf">z.par2cdf</a></code>, <code><a href="#topic+par2qua">par2qua</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'># define the real parent (or close)
the.gpa   &lt;- vec2par(c(100,1000,0.1),type='gpa')
fake.data &lt;- rlmomco(30,the.gpa) # simulate some data
fake.data &lt;- sort(c(fake.data, rep(0,10))) # add some zero observations

par(mgp=c(3,0.5,0)) # going to tick to the inside, change some parameters
# next compute the parameters for the positive data
gpa.all &lt;- pargpa(lmoms(fake.data))
gpa.nzo &lt;- pargpa(lmoms(fake.data[fake.data &gt; 0]))
n   &lt;- length(fake.data) # sample size
p   &lt;- length(fake.data[fake.data == 0])/n # est. prob of zero value
F   &lt;- nonexceeds(sig6=TRUE); F &lt;- sort(c(F,p)); qF &lt;- qnorm(F)
PP  &lt;- pp(fake.data) # compute plotting positions of sim. sample
plot(qnorm(PP), fake.data, ylim=c(0,4000), xaxt="n", xlab="") # plot the sample
add.lmomco.axis(las=2, tcl=0.5, twoside=TRUE, side.type="SNV", otherside.type="NA")
lines(qF,quagpa(F,gpa.all)) # the parent (without zeros)
lines(qF,z.par2qua(F,p,gpa.nzo),lwd=3) # fitted model with zero conditional
par(mgp=c(3,1,0)) # restore defaults
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
