<!DOCTYPE html><html><head><title>Help for package samplesizelogisticcasecontrol</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {samplesizelogisticcasecontrol}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#samplesizelogisticcasecontrol-package'>
<p>Sample size and power calculations for case-control studies</p></a></li>
<li><a href='#file.list'>
<p>List to describe the covariate and exposure data</p></a></li>
<li><a href='#power_binary'><p>Power for a binary exposure</p></a></li>
<li><a href='#power_continuous'><p>Power for a continuous exposure</p></a></li>
<li><a href='#power_data'><p>Power using pilot data</p></a></li>
<li><a href='#power_ordinal'><p>Power for an ordinal exposure</p></a></li>
<li><a href='#sampleSize_binary'><p>Sample size for a binary exposure</p></a></li>
<li><a href='#sampleSize_continuous'><p>Sample size for a continuous exposure</p></a></li>
<li><a href='#sampleSize_data'><p>Sample size using pilot data</p></a></li>
<li><a href='#sampleSize_ordinal'><p>Sample size for an ordinal exposure</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Title:</td>
<td>Sample Size and Power Calculations for Case-Control Studies</td>
</tr>
<tr>
<td>Version:</td>
<td>2.0.2</td>
</tr>
<tr>
<td>Date:</td>
<td>2023-08-21</td>
</tr>
<tr>
<td>Author:</td>
<td>Mitchell H. Gail</td>
</tr>
<tr>
<td>Description:</td>
<td>To determine sample size or power for case-control studies to be analyzed using logistic regression.</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>William Wheeler &lt;WheelerB@imsweb.com&gt;</td>
</tr>
<tr>
<td>Depends:</td>
<td>mvtnorm</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-08-21 14:43:02 UTC; wheelerwi</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-08-21 15:20:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='samplesizelogisticcasecontrol-package'>
Sample size and power calculations for case-control studies
</h2><span id='topic+samplesizelogisticcasecontrol'></span><span id='topic+samplesizelogisticcasecontrol-package'></span>

<h3>Description</h3>

<p>This package can be used to calculate the required sample size needed for 
case-control studies to have sufficient power, or calculate the power of a
case-control study for a given sample size. 
To calculate the sample size, one needs to
specify the significance level <code class="reqn">\alpha</code>, power <code class="reqn">\gamma</code>, and the 
hypothesized non-null <code class="reqn">\theta</code>. Here <code class="reqn">\theta</code> is a log odds ratio
for an exposure main effect or <code class="reqn">\theta</code> is an interaction effect on the 
logistic scale.
Choosing <code class="reqn">\theta</code> requires subject matter knowledge to understand how
strong the association needs to be to have practical importance.   
Sample size varies inversely with
<code class="reqn">\theta^{2}</code> and is thus highly dependent on <code class="reqn">\theta</code>. 
</p>


<h3>Details</h3>

<p>The main functions in the package are for different types of exposure variables, where the
exposure variable is the variable of interest in a hypothesis test. 
The functions <code><a href="#topic+sampleSize_binary">sampleSize_binary</a></code> and <code><a href="#topic+power_binary">power_binary</a></code>
can be used for a binary exposure variable (X = 0 or 1), 
while the functions <code><a href="#topic+sampleSize_ordinal">sampleSize_ordinal</a></code> and <code><a href="#topic+power_ordinal">power_ordinal</a></code> 
is a more general function that can be used for 
an ordinal exposure variable (X takes the values 0, 1, ..., k). 
<code><a href="#topic+sampleSize_continuous">sampleSize_continuous</a></code> and <code><a href="#topic+power_continuous">power_continuous</a></code> are useful for a continuous exposure variable and
<code><a href="#topic+sampleSize_data">sampleSize_data</a></code> and <code><a href="#topic+power_data">power_data</a></code> can be used when pilot data is available that defines
the distribution of the exposure and other confounding variables. Each function will return the
sample sizes or power for a Wald-type test and a score test. When there are no adjustments for confounders, the user can 
specify a general distribution for the exposure variable. With confounders, either pilot data or a function to 
generate random samples from the multivariate distribution of the confounders and exposure variable must
be given. 
</p>
<p>If the parameter of interest, <code class="reqn">\theta</code>,
is one dimensional, then the test statistic is often asymptotically equivalent
to a test of the form 
<code class="reqn">T &gt; Z_{1-\alpha}\sigma_{0}n^{-\frac{1}{2}}</code> or
<code class="reqn">T &gt; Z_{1-\alpha}\sigma_{\theta}n^{-\frac{1}{2}}</code>, where
<code class="reqn">Z_{1-\alpha}</code> is the <code class="reqn">1-\alpha</code> quantile of a standard
normal distribution, <code class="reqn">n</code> is the total sample size (cases plus controls), 
and <code class="reqn">n^{\frac{1}{2}}T</code> is 
normally distributed with mean 0 and null variance <code class="reqn">\sigma_{0}^{2}</code>.
Depending on which critical value
<code class="reqn">Z_{1-\alpha}\sigma_{0}n^{-\frac{1}{2}}</code> or
<code class="reqn">Z_{1-\alpha}\sigma_{\theta}n^{-\frac{1}{2}}</code> 
of the test was used, the formulas for sample size are obtained by inverting the
equations for power:
</p>
<p><code class="reqn">n_{1} = (Z_{\gamma}\sigma_{\theta} + Z_{1-\alpha}\sigma_{0})^{2}/\theta^{2}</code>
or
<code class="reqn">n_{2} = (Z_{\gamma} + Z_{1-\alpha})^{2}\sigma_{\theta}^{2}/\theta^{2}</code>. 
</p>


<h3>Author(s)</h3>

<p>Mitchell H. Gail &lt;gailm@mail.nih.gov&gt;</p>


<h3>References</h3>

<p>Gail, M.H. and Haneuse, S. Power and sample size for case-control studies.  
In Handbook of Statistical Methods for Case-Control Studies.  
Editors:  Ornulf Borgan, Norman Breslow, Nilanjan Chatterjee, Mitchell Gail, Alastair Scott, Christopher Wild.  
Chapman and Hall/CRC, Taylor and Francis Group, New York, 2018, pages 163-187.
</p>
<p>Gail, M. H and Haneuse, S. Power and sample size for multivariate logistic modeling of unmatched case-control studies. 
Statistical Methods in Medical Research. 2019;28(3):822-834, <br />
https://doi.org/10.1177/0962280217737157
</p>

<hr>
<h2 id='file.list'>
List to describe the covariate and exposure data 
</h2><span id='topic+file.list'></span>

<h3>Description</h3>

<p>The list to describe the covariate and exposure data for the <code>data</code> option.
</p>


<h3>Format</h3>

<p>The format is:
List of 7
</p>

<dl>
<dt>file</dt><dd><p> Data file containing the confounders and exposure variables.
No default.</p>
</dd>
<dt>exposure</dt><dd><p> Name or column number in <code>file</code> for the exposure variable. 
This can also be a vector giving the columns to form an interaction
variable (see details).
No default. </p>
</dd>
<dt>covars</dt><dd><p>Character vector of variables names or numeric vector of column numbers
in <code>file</code> that will be confounders. These variables must be numeric.
The length and order of the <code>logOR</code> argument must match the length and 
order of c(<code>covars</code>, <code>exposure</code>).
The default is NULL.</p>
</dd>
<dt>header</dt><dd><p> 0 or 1 if <code>file</code> has the first row as variable names. 
The default is determined from the first line of the <code>file</code>.</p>
</dd>
<dt>delimiter</dt><dd><p> The delimiter in <code>file</code>.
The default is determined from the first two lines of the <code>file</code>.</p>
</dd>
<dt>in.miss</dt><dd><p> Vector of character strings to define the missing values. This option
corresponds to the option <code>na.strings</code> in <code>read.table()</code>.
The default is &quot;NA&quot;.</p>
</dd>
<dt>subsetData</dt><dd><p> List of sublists to subset the data. 
Each sublist should contain the names &quot;var&quot;, &quot;operator&quot; and &quot;value&quot; corresponding
to a variable name, operator and values of the variable.
Multiple sublists are logically connected by the AND operator. For example, <br />
subsetData=list(list(var=&quot;GENDER&quot;, operator=&quot;==&quot;, value=&quot;MALE&quot;)) <br />
will only include subjects with the string &quot;MALE&quot; for the GENDER variable. <br />
subsetData=list(list(var=&quot;AGE&quot;, operator=&quot;&gt;&quot;, value=50), <br />
list(var=&quot;STUDY&quot;, operator=&quot;%in%&quot;, value=c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;))) <br />
will include subjects with AGE &gt; 50 AND in STUDY A, B or C.  
The default is NULL.</p>
</dd>
</dl>



<h3>Details</h3>

<p> In this list, <code>file</code> and <code>exposure</code> must be specified. If <code>exposure</code> is a vector
of column names or column numbers, then an exposure variable will be created by multipling the columns
defined in the vector to form the interaction variable. Thus, the columns must be numeric variables. 
In this case, the length and order of <code>logOR</code> must match the length and order of
c(<code>covars</code>, &lt;new interaction variable&gt;).
</p>

<hr>
<h2 id='power_binary'>Power for a binary exposure</h2><span id='topic+power_binary'></span>

<h3>Description</h3>

<p>Calculates the power of as case-control study with a binary exposure variable
</p>


<h3>Usage</h3>

<pre><code class='language-R'>power_binary(prev, logOR, probXeq1=NULL, distF=NULL, data=NULL, 
      size.2sided=0.05, sampleSize=1000, cc.ratio=0.5, interval=c(-100, 100), tol=0.0001) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="power_binary_+3A_prev">prev</code></td>
<td>
<p>Number between 0 and 1 giving the prevalence of disease. No default.</p>
</td></tr>
<tr><td><code id="power_binary_+3A_logor">logOR</code></td>
<td>
<p>Vector of ordered log-odds ratios for the confounders and exposure.
The last log-odds ratio in the vector is for the exposure. If the 
option <code>data</code> (below) is specified, then the order must match the 
order of <code>data</code>.  
No default.</p>
</td></tr>
<tr><td><code id="power_binary_+3A_probxeq1">probXeq1</code></td>
<td>
<p>NULL or a number between 0 and 1 giving the probability that the exposure
variable is 1. If set to NULL, the the <code>data</code> option must be specified so 
that <code>probXeq1</code> can be estimated. The default is NULL.</p>
</td></tr>
<tr><td><code id="power_binary_+3A_distf">distF</code></td>
<td>
<p>NULL, a function or a character string giving the function to generate random
vectors from the distribution of the confounders and exposure. The order of the returned
vector must match the order of <code>logOR</code>.
User defined functions are also allowed, provided the user-defined function has only
one integer valued argument that inputs the number of random vectors to generate. 
For instance the header of a user-defined function called &quot;userF&quot; would be 
userF &lt;- function(n). 
The default depends on other options (see details).</p>
</td></tr>
<tr><td><code id="power_binary_+3A_data">data</code></td>
<td>
<p>NULL, matrix, data frame or a list of type <code><a href="#topic+file.list">file.list</a></code> that gives
a sample from the distribution of the confounders and exposure.
If a matrix or data frame, then the last column consists of random values for the exposure, 
while the other columns are for the confounders. The order of the columns must match the order of 
the vector <code>logOR</code>.
The default is NULL.</p>
</td></tr>
<tr><td><code id="power_binary_+3A_size.2sided">size.2sided</code></td>
<td>
<p>Number between 0 and 1 giving the size of the 2-sided hypothesis test. The default is 0.05.</p>
</td></tr>
<tr><td><code id="power_binary_+3A_samplesize">sampleSize</code></td>
<td>
<p>Sample size of the study. The default is 1000.</p>
</td></tr>
<tr><td><code id="power_binary_+3A_cc.ratio">cc.ratio</code></td>
<td>
<p>Number between 0 and 1 for the proportion of cases in the case-control sample. The default is 0.5.</p>
</td></tr>
<tr><td><code id="power_binary_+3A_interval">interval</code></td>
<td>
<p>Two element vector giving the interval to search for the estimated intercept parameter. 
The default is c(-100, 100).</p>
</td></tr>
<tr><td><code id="power_binary_+3A_tol">tol</code></td>
<td>
<p>Positive value giving the stopping tolerance for the root finding method to estimate
the intercept parameter.
The default is 0.0001.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If there are no confounders (length(logOR) = 1), then either <code>probXeq1</code> or <code>data</code> must
be specified, where <code>probXeq1</code> takes precedance. If there are confounders (length(logOR) &gt; 1), then
either <code>data</code> or <code>distF</code> must be specified, where <code>data</code> takes precedance.
</p>


<h3>Value</h3>

<p>A list containing four powers, where two of them are for a Wald test and two for a score test.
The two powers for each test correspond to the equations for 
<code class="reqn">n_{1}</code> and <code class="reqn">n_{2}</code>.
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+power_continuous">power_continuous</a></code>, <code><a href="#topic+power_ordinal">power_ordinal</a></code>, <code><a href="#topic+power_data">power_data</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>  prev  &lt;- 0.01
  logOR &lt;- 0.3

  # No confounders, Prob(X=1)=0.2
  power_binary(prev, logOR, probXeq1=0.2) 

  # Generate data for a N(0,1) confounder and binary exposure
  data &lt;- cbind(rnorm(1000), rbinom(1000, 1, 0.4))
  beta &lt;- c(0.1, 0.2)
  power_binary(prev, beta, data=data) 

  # Define a function to generate random vectors for two confounders and the binary exposure
  f &lt;- function(n) {cbind(rnorm(n), rbinom(n, 3, 0.5), rbinom(n, 1, 0.3))}
  logOR &lt;- c(0.2, 0.3, 0.25)
  power_binary(prev, logOR, distF=f) 

</code></pre>

<hr>
<h2 id='power_continuous'>Power for a continuous exposure</h2><span id='topic+power_continuous'></span>

<h3>Description</h3>

<p>Calculates the power of as case-control study with a continuous exposure variable
</p>


<h3>Usage</h3>

<pre><code class='language-R'>power_continuous(prev, logOR, distF=NULL, distF.support=c(-Inf, Inf), 
      data=NULL, size.2sided=0.05, sampleSize=1000, cc.ratio=0.5, interval=c(-100, 100), 
      tol=0.0001, distF.var=NULL) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="power_continuous_+3A_prev">prev</code></td>
<td>
<p>Number between 0 and 1 giving the prevalence of disease. No default.</p>
</td></tr>
<tr><td><code id="power_continuous_+3A_logor">logOR</code></td>
<td>
<p>Vector of ordered log-odds ratios for the confounders and exposure.
The last log-odds ratio in the vector is for the exposure. If the 
option <code>data</code> (below) is specified, then the order must match the 
order of <code>data</code>.  
No default.</p>
</td></tr>
<tr><td><code id="power_continuous_+3A_distf">distF</code></td>
<td>
<p>NULL, a function or a character string giving the pdf of the exposure variable for the case 
of no confounders, or giving the function to generate random vectors from the
distribution formed by the confounders and exposure.
For the case of no confounders, examples are <code><a href="stats.html#topic+dnorm">dnorm</a></code>, 
&quot;dnorm(x, mean=0.5, sd=2.1)&quot;, &quot;dbeta(?, shape1=0.3, shape2=3)&quot;, &quot;dchisq(whatever, df=1)&quot;.
Notice that when <code>distF</code> is a character string, the first argument can be anything but
must be given to serve as a place holder. 
For the case of two confounders, an example might be a random vector generator from a 
multivariate normal distribution &quot;rmvnorm(x, c(0,0,0))&quot;. 
User defined functions are also allowed, provided the user-defined function has only
one input argument. The input argument would be a vector of quantiles if the user-defined 
function is a pdf, or the input argument would be an integer specifiying the number
of random vectors to generate if the user-defined function is a function to generate
random vectors from the distribution of the confounders and exposure.
An example pdf is the function H, where 
H &lt;- function(x) { dunif(x, min=2, max=7) }. 
The default depends on other options (see details).</p>
</td></tr>
<tr><td><code id="power_continuous_+3A_distf.support">distF.support</code></td>
<td>
<p>Two element vector giving the domain of <code>distF</code>. This option is only used
when <code>distF</code> is a pdf.
The default is c(-Inf, Inf).</p>
</td></tr>
<tr><td><code id="power_continuous_+3A_data">data</code></td>
<td>
<p>NULL, matrix, data frame or a list of type <code><a href="#topic+file.list">file.list</a></code> 
that gives a sample from the distribution of the confounders and exposure.
If a matrix or data frame, then the last column consists of random values for the exposure, 
while the other columns are for the confounders. The order of the columns must match the order of 
the vector <code>logOR</code>.
The default is NULL.</p>
</td></tr>
<tr><td><code id="power_continuous_+3A_size.2sided">size.2sided</code></td>
<td>
<p>Number between 0 and 1 giving the size of the 2-sided hypothesis test. The default is 0.05.</p>
</td></tr>
<tr><td><code id="power_continuous_+3A_samplesize">sampleSize</code></td>
<td>
<p>Sample size of the study. The default is 1000.</p>
</td></tr>
<tr><td><code id="power_continuous_+3A_cc.ratio">cc.ratio</code></td>
<td>
<p>Number between 0 and 1 for the proportion of cases in the case-control sample. The default is 0.5.</p>
</td></tr>
<tr><td><code id="power_continuous_+3A_interval">interval</code></td>
<td>
<p>Two element vector giving the interval to search for the estimated intercept parameter. 
The default is c(-100, 100).</p>
</td></tr>
<tr><td><code id="power_continuous_+3A_tol">tol</code></td>
<td>
<p>Positive value giving the stopping tolerance for the root finding method to estimate
the intercept parameter.
The default is 0.0001.</p>
</td></tr>
<tr><td><code id="power_continuous_+3A_distf.var">distF.var</code></td>
<td>
<p>The variance of the exposure variable for the case of no confounders. This option is 
for efficiency purposes. If not specified, the variance will be estimated by either
the empirical variance of a random sample from the distribution of the exposure or
by numerical integration.
The default is NULL.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>data</code> option takes precedance over the other options. If <code>data</code> is not specified,
then the distribution of the exposure will be N(0,1) or MVN(0, 1) depending on whether there
are confounders. 
</p>


<h3>Value</h3>

<p>A list containing four powers, where two of them are for a Wald test and two for a score test.
The two powers for each test correspond to the equations for 
<code class="reqn">n_{1}</code> and <code class="reqn">n_{2}</code>.
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+power_binary">power_binary</a></code>, <code><a href="#topic+power_ordinal">power_ordinal</a></code>, <code><a href="#topic+power_data">power_data</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>  prev  &lt;- 0.01
  logOR &lt;- 0.3

  # No confounders, exposure assumed to be N(0,1)
  power_continuous(prev, logOR) 

  # Two confounders and exposure assumed to be MVN(0,1)
  beta &lt;- c(0.1, 0.1, logOR)
  power_continuous(prev, beta) 

  # No confounders, exposure is beta(0.3, 3)
  power_continuous(prev, logOR, distF="dbeta(m, shape1=0.3, shape2=3)",
                        distF.support=c(0, 1)) 
</code></pre>

<hr>
<h2 id='power_data'>Power using pilot data</h2><span id='topic+power_data'></span>

<h3>Description</h3>

<p>Calculates the power of a case-control study with pilot data
</p>


<h3>Usage</h3>

<pre><code class='language-R'>power_data(prev, logOR, data, size.2sided=0.05, sampleSize=1000, cc.ratio=0.5,
        interval=c(-100, 100), tol=0.0001) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="power_data_+3A_prev">prev</code></td>
<td>
<p>Number between 0 and 1 giving the prevalence of disease. No default.</p>
</td></tr>
<tr><td><code id="power_data_+3A_logor">logOR</code></td>
<td>
<p>Vector of ordered log-odds ratios for the confounders and exposure.
The last log-odds ratio in the vector is for the exposure. If the 
option <code>data</code> (below) is specified, then the order must match the 
order of <code>data</code>.  
No default.</p>
</td></tr>
<tr><td><code id="power_data_+3A_data">data</code></td>
<td>
<p>Matrix, data frame or a list of type <code><a href="#topic+file.list">file.list</a></code> 
that gives a sample from the distribution of the confounders and exposure (see details).
If a matrix or data frame, then the last column consists of random values for the exposure, 
while the other columns are for the confounders. The order of the columns must match the order of 
the vector <code>logOR</code>.
The default is NULL.</p>
</td></tr>
<tr><td><code id="power_data_+3A_size.2sided">size.2sided</code></td>
<td>
<p>Number between 0 and 1 giving the size of the 2-sided hypothesis test. The default is 0.05.</p>
</td></tr>
<tr><td><code id="power_data_+3A_samplesize">sampleSize</code></td>
<td>
<p>Sample size of the study (see details). The default is 1000.</p>
</td></tr>
<tr><td><code id="power_data_+3A_cc.ratio">cc.ratio</code></td>
<td>
<p>Number between 0 and 1 for the proportion of cases in the case-control sample.
The default is 0.5.</p>
</td></tr>
<tr><td><code id="power_data_+3A_interval">interval</code></td>
<td>
<p>Two element vector giving the interval to search for the estimated intercept parameter. 
The default is c(-100, 100).</p>
</td></tr>
<tr><td><code id="power_data_+3A_tol">tol</code></td>
<td>
<p>Positive value giving the stopping tolerance for the root finding method to estimate
the intercept parameter.
The default is 0.0001.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The option <code>sampleSize</code> is not necessarily <code>nrow(data)</code>. The input <code>data</code> can be a
small sample of pilot data that would be representative of the actual study data. 
</p>


<h3>Value</h3>

<p>A list containing four powers, where two of them are for a Wald test and two for a score test.
The two powers for each test correspond to the equations for 
<code class="reqn">n_{1}</code> and <code class="reqn">n_{2}</code>.
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+power_binary">power_binary</a></code>, <code><a href="#topic+power_ordinal">power_ordinal</a></code>, <code><a href="#topic+power_continuous">power_continuous</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>  prev  &lt;- 0.01
  logOR &lt;- 0.3
  data  &lt;- matrix(rnorm(100, mean=1.5), ncol=1)

  # Assuming exposuure is N(1.5, 1)
  power_data(prev, logOR, data) 

</code></pre>

<hr>
<h2 id='power_ordinal'>Power for an ordinal exposure</h2><span id='topic+power_ordinal'></span>

<h3>Description</h3>

<p>Calculates the power of as case-control study with an ordinal exposure variable
</p>


<h3>Usage</h3>

<pre><code class='language-R'>power_ordinal(prev, logOR, probX=NULL, distF=NULL, data=NULL, 
      size.2sided=0.05, sampleSize=1000, cc.ratio=0.5, interval=c(-100, 100), tol=0.0001) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="power_ordinal_+3A_prev">prev</code></td>
<td>
<p>Number between 0 and 1 giving the prevalence of disease. No default.</p>
</td></tr>
<tr><td><code id="power_ordinal_+3A_logor">logOR</code></td>
<td>
<p>Vector of ordered log-odds ratios per category increase for the confounders and exposure.
The last log-odds ratio in the vector is for the exposure. 
If the exposures are coded 0, 1, ..., k (k+1 categories), then the <code>logOR</code>
corresponds to a one category increase.
If the option <code>data</code> (below) is specified, then the order must match the 
order of <code>data</code>.  
No default.</p>
</td></tr>
<tr><td><code id="power_ordinal_+3A_probx">probX</code></td>
<td>
<p>NULL or a vector that sums to 1 giving the probability that the exposure
variable is equal to i, i = 0, 1, ..., k. 
If set to NULL, the the <code>data</code> option must be specified so 
that <code>probX</code> can be estimated. The default is NULL.</p>
</td></tr>
<tr><td><code id="power_ordinal_+3A_distf">distF</code></td>
<td>
<p>NULL, a function or a character string giving the function to generate random
vectors from the distribution of the confounders and exposure. The order of the returned
vector must match the order of <code>logOR</code>.
The default depends on other options (see details).</p>
</td></tr>
<tr><td><code id="power_ordinal_+3A_data">data</code></td>
<td>
<p>NULL, matrix, data frame or a list of type <code><a href="#topic+file.list">file.list</a></code> 
that gives a sample from the distribution of the confounders and exposure.
If a matrix or data frame, then the last column consists of random values for the exposure, 
while the other columns are for the confounders. The order of the columns must match the order of 
the vector <code>logOR</code>.
The default is NULL.</p>
</td></tr>
<tr><td><code id="power_ordinal_+3A_size.2sided">size.2sided</code></td>
<td>
<p>Number between 0 and 1 giving the size of the 2-sided hypothesis test. The default is 0.05.</p>
</td></tr>
<tr><td><code id="power_ordinal_+3A_samplesize">sampleSize</code></td>
<td>
<p>Sample size of the study. The default is 1000.</p>
</td></tr>
<tr><td><code id="power_ordinal_+3A_cc.ratio">cc.ratio</code></td>
<td>
<p>Number between 0 and 1 for the proportion of cases in the case-control sample. The default is 0.5.</p>
</td></tr>
<tr><td><code id="power_ordinal_+3A_interval">interval</code></td>
<td>
<p>Two element vector giving the interval to search for the estimated intercept parameter. 
The default is c(-100, 100).</p>
</td></tr>
<tr><td><code id="power_ordinal_+3A_tol">tol</code></td>
<td>
<p>Positive value giving the stopping tolerance for the root finding method to estimate
the intercept parameter.
The default is 0.0001.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If there are no confounders (length(logOR) = 1), then either <code>probX</code> or <code>data</code> must
be specified, where <code>probX</code> takes precedance. If there are confounders (length(logOR) &gt; 1), then
either <code>data</code> or <code>distF</code> must be specified, where <code>data</code> takes precedance.
</p>


<h3>Value</h3>

<p>A list containing four powers, where two of them are for a Wald test and two for a score test.
The two powers for each test correspond to the equations for 
<code class="reqn">n_{1}</code> and <code class="reqn">n_{2}</code>.
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+power_continuous">power_continuous</a></code>, <code><a href="#topic+power_binary">power_binary</a></code>, <code><a href="#topic+power_data">power_data</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>  prev  &lt;- 0.01
  logOR &lt;- 0.3

  # No confounders, Prob(X=1)=0.2
  power_ordinal(prev, logOR, probX=c(0.8, 0.2)) 

  # Generate data for a N(0,1) confounder and ordinal exposure with 3 levels
  data &lt;- cbind(rnorm(1000), rbinom(1000, 2, 0.5))
  beta &lt;- c(0.1, 0.2)
  power_ordinal(prev, beta, data=data) 

  # Define a function to generate random vectors for two confounders and an ordinal
  #   exposure with 5 levels
  f &lt;- function(n) {cbind(rnorm(n), rbinom(n, 1, 0.5), rbinom(n, 4, 0.5))}
  beta &lt;- c(0.2, 0.3, 0.25)
  power_ordinal(prev, beta, distF=f) 

</code></pre>

<hr>
<h2 id='sampleSize_binary'>Sample size for a binary exposure</h2><span id='topic+sampleSize_binary'></span>

<h3>Description</h3>

<p>Calculates the required sample size of as case-control study with a binary exposure variable
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sampleSize_binary(prev, logOR, probXeq1=NULL, distF=NULL, data=NULL, 
      size.2sided=0.05, power=0.9, cc.ratio=0.5, interval=c(-100, 100), tol=0.0001,
      n.samples=10000) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sampleSize_binary_+3A_prev">prev</code></td>
<td>
<p>Number between 0 and 1 giving the prevalence of disease. No default.</p>
</td></tr>
<tr><td><code id="sampleSize_binary_+3A_logor">logOR</code></td>
<td>
<p>Vector of ordered log-odds ratios for the confounders and exposure.
The last log-odds ratio in the vector is for the exposure. If the 
option <code>data</code> (below) is specified, then the order must match the 
order of <code>data</code>.  
No default.</p>
</td></tr>
<tr><td><code id="sampleSize_binary_+3A_probxeq1">probXeq1</code></td>
<td>
<p>NULL or a number between 0 and 1 giving the probability that the exposure
variable is 1. If set to NULL, the the <code>data</code> option must be specified so 
that <code>probXeq1</code> can be estimated. The default is NULL.</p>
</td></tr>
<tr><td><code id="sampleSize_binary_+3A_distf">distF</code></td>
<td>
<p>NULL, a function or a character string giving the function to generate random
vectors from the distribution of the confounders and exposure. The order of the returned
vector must match the order of <code>logOR</code>.
User defined functions are also allowed, provided the user-defined function has only
one integer valued argument that inputs the number of random vectors to generate. 
For instance the header of a user-defined function called &quot;userF&quot; would be 
userF &lt;- function(n). 
The default depends on other options (see details).</p>
</td></tr>
<tr><td><code id="sampleSize_binary_+3A_data">data</code></td>
<td>
<p>NULL, matrix, data frame or a list of type <code><a href="#topic+file.list">file.list</a></code> that gives
a sample from the distribution of the confounders and exposure.
If a matrix or data frame, then the last column consists of random values for the exposure, 
while the other columns are for the confounders. The order of the columns must match the order of 
the vector <code>logOR</code>.
The default is NULL.</p>
</td></tr>
<tr><td><code id="sampleSize_binary_+3A_size.2sided">size.2sided</code></td>
<td>
<p>Number between 0 and 1 giving the size of the 2-sided hypothesis test. The default is 0.05.</p>
</td></tr>
<tr><td><code id="sampleSize_binary_+3A_power">power</code></td>
<td>
<p>Number between 0 and 1 for the desired power of the test. The default is 0.9.</p>
</td></tr>
<tr><td><code id="sampleSize_binary_+3A_cc.ratio">cc.ratio</code></td>
<td>
<p>Number between 0 and 1 for the proportion of cases in the case-control sample. The default is 0.5.</p>
</td></tr>
<tr><td><code id="sampleSize_binary_+3A_interval">interval</code></td>
<td>
<p>Two element vector giving the interval to search for the estimated intercept parameter. 
The default is c(-100, 100).</p>
</td></tr>
<tr><td><code id="sampleSize_binary_+3A_tol">tol</code></td>
<td>
<p>Positive value giving the stopping tolerance for the root finding method to estimate
the intercept parameter.
The default is 0.0001.</p>
</td></tr>
<tr><td><code id="sampleSize_binary_+3A_n.samples">n.samples</code></td>
<td>
<p>Integer giving the number of random vectors to generate when the option <code>distF</code>
is specified.
The default is 10000.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If there are no confounders (length(logOR) = 1), then either <code>probXeq1</code> or <code>data</code> must
be specified, where <code>probXeq1</code> takes precedance. If there are confounders (length(logOR) &gt; 1), then
either <code>data</code> or <code>distF</code> must be specified, where <code>data</code> takes precedance.
</p>


<h3>Value</h3>

<p>A list containing four sample sizes, where two of them are for a Wald test and two for a score test.
The two sample sizes for each test correspond to the equations for 
<code class="reqn">n_{1}</code> and <code class="reqn">n_{2}</code>.
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+sampleSize_continuous">sampleSize_continuous</a></code>, <code><a href="#topic+sampleSize_ordinal">sampleSize_ordinal</a></code>, <code><a href="#topic+sampleSize_data">sampleSize_data</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>  prev  &lt;- 0.01
  logOR &lt;- 0.3

  # No confounders, Prob(X=1)=0.2
  sampleSize_binary(prev, logOR, probXeq1=0.2) 

  # Generate data for a N(0,1) confounder and binary exposure
  data &lt;- cbind(rnorm(1000), rbinom(1000, 1, 0.4))
  beta &lt;- c(0.1, 0.2)
  sampleSize_binary(prev, beta, data=data) 

  # Define a function to generate random vectors for two confounders and the binary exposure
  f &lt;- function(n) {cbind(rnorm(n), rbinom(n, 3, 0.5), rbinom(n, 1, 0.3))}
  logOR &lt;- c(0.2, 0.3, 0.25)
  sampleSize_binary(prev, logOR, distF=f) 

</code></pre>

<hr>
<h2 id='sampleSize_continuous'>Sample size for a continuous exposure</h2><span id='topic+sampleSize_continuous'></span>

<h3>Description</h3>

<p>Calculates the required sample size of as case-control study with a continuous exposure variable
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sampleSize_continuous(prev, logOR, distF=NULL, distF.support=c(-Inf, Inf), 
      data=NULL, size.2sided=0.05, power=0.9, cc.ratio=0.5, interval=c(-100, 100), 
      tol=0.0001, n.samples=10000, distF.var=NULL) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sampleSize_continuous_+3A_prev">prev</code></td>
<td>
<p>Number between 0 and 1 giving the prevalence of disease. No default.</p>
</td></tr>
<tr><td><code id="sampleSize_continuous_+3A_logor">logOR</code></td>
<td>
<p>Vector of ordered log-odds ratios for the confounders and exposure.
The last log-odds ratio in the vector is for the exposure. If the 
option <code>data</code> (below) is specified, then the order must match the 
order of <code>data</code>.  
No default.</p>
</td></tr>
<tr><td><code id="sampleSize_continuous_+3A_distf">distF</code></td>
<td>
<p>NULL, a function or a character string giving the pdf of the exposure variable for the case 
of no confounders, or giving the function to generate random vectors from the
distribution formed by the confounders and exposure.
For the case of no confounders, examples are <code><a href="stats.html#topic+dnorm">dnorm</a></code>, 
&quot;dnorm(x, mean=0.5, sd=2.1)&quot;, &quot;dbeta(?, shape1=0.3, shape2=3)&quot;, &quot;dchisq(whatever, df=1)&quot;.
Notice that when <code>distF</code> is a character string, the first argument can be anything but
must be given to serve as a place holder. 
For the case of two confounders, an example might be a random vector generator from a 
multivariate normal distribution &quot;rmvnorm(x, c(0,0,0))&quot;. 
User defined functions are also allowed, provided the user-defined function has only
one input argument. The input argument would be a vector of quantiles if the user-defined 
function is a pdf, or the input argument would be an integer specifiying the number
of random vectors to generate if the user-defined function is a function to generate
random vectors from the distribution of the confounders and exposure.
An example pdf is the function H, where 
H &lt;- function(x) { dunif(x, min=2, max=7) }. 
The default depends on other options (see details).</p>
</td></tr>
<tr><td><code id="sampleSize_continuous_+3A_distf.support">distF.support</code></td>
<td>
<p>Two element vector giving the domain of <code>distF</code>. This option is only used
when <code>distF</code> is a pdf.
The default is c(-Inf, Inf).</p>
</td></tr>
<tr><td><code id="sampleSize_continuous_+3A_data">data</code></td>
<td>
<p>NULL, matrix, data frame or a list of type <code><a href="#topic+file.list">file.list</a></code> 
that gives a sample from the distribution of the confounders and exposure.
If a matrix or data frame, then the last column consists of random values for the exposure, 
while the other columns are for the confounders. The order of the columns must match the order of 
the vector <code>logOR</code>.
The default is NULL.</p>
</td></tr>
<tr><td><code id="sampleSize_continuous_+3A_size.2sided">size.2sided</code></td>
<td>
<p>Number between 0 and 1 giving the size of the 2-sided hypothesis test. The default is 0.05.</p>
</td></tr>
<tr><td><code id="sampleSize_continuous_+3A_power">power</code></td>
<td>
<p>Number between 0 and 1 for the desired power of the test. The default is 0.9.</p>
</td></tr>
<tr><td><code id="sampleSize_continuous_+3A_cc.ratio">cc.ratio</code></td>
<td>
<p>Number between 0 and 1 for the proportion of cases in the case-control sample. The default is 0.5.</p>
</td></tr>
<tr><td><code id="sampleSize_continuous_+3A_interval">interval</code></td>
<td>
<p>Two element vector giving the interval to search for the estimated intercept parameter. 
The default is c(-100, 100).</p>
</td></tr>
<tr><td><code id="sampleSize_continuous_+3A_tol">tol</code></td>
<td>
<p>Positive value giving the stopping tolerance for the root finding method to estimate
the intercept parameter.
The default is 0.0001.</p>
</td></tr>
<tr><td><code id="sampleSize_continuous_+3A_n.samples">n.samples</code></td>
<td>
<p>Integer giving the number of random vectors to generate when the option <code>distF</code>
is specified and is a random vector generation function.
The default is 10000.</p>
</td></tr>
<tr><td><code id="sampleSize_continuous_+3A_distf.var">distF.var</code></td>
<td>
<p>The variance of the exposure variable for the case of no confounders. This option is 
for efficiency purposes. If not specified, the variance will be estimated by either
the empirical variance of a random sample from the distribution of the exposure or
by numerical integration.
The default is NULL.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>data</code> option takes precedance over the other options. If <code>data</code> is not specified,
then the distribution of the exposure will be N(0,1) or MVN(0, 1) depending on whether there
are confounders. 
</p>


<h3>Value</h3>

<p>A list containing four sample sizes, where two of them are for a Wald test and two for a score test.
The two sample sizes for each test correspond to the equations for 
<code class="reqn">n_{1}</code> and <code class="reqn">n_{2}</code>.
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+sampleSize_binary">sampleSize_binary</a></code>, <code><a href="#topic+sampleSize_ordinal">sampleSize_ordinal</a></code>, <code><a href="#topic+sampleSize_data">sampleSize_data</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>  prev  &lt;- 0.01
  logOR &lt;- 0.3

  # No confounders, exposure assumed to be N(0,1)
  sampleSize_continuous(prev, logOR) 

  # Two confounders and exposure assumed to be MVN(0,1)
  beta &lt;- c(0.1, 0.1, logOR)
  sampleSize_continuous(prev, beta) 

  # No confounders, exposure is beta(0.3, 3)
  sampleSize_continuous(prev, logOR, distF="dbeta(m, shape1=0.3, shape2=3)",
                        distF.support=c(0, 1)) 
</code></pre>

<hr>
<h2 id='sampleSize_data'>Sample size using pilot data</h2><span id='topic+sampleSize_data'></span>

<h3>Description</h3>

<p>Calculates the required sample size of a case-control study with pilot data
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sampleSize_data(prev, logOR, data, size.2sided=0.05, power=0.9, cc.ratio=0.5,
        interval=c(-100, 100), tol=0.0001) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sampleSize_data_+3A_prev">prev</code></td>
<td>
<p>Number between 0 and 1 giving the prevalence of disease. No default.</p>
</td></tr>
<tr><td><code id="sampleSize_data_+3A_logor">logOR</code></td>
<td>
<p>Vector of ordered log-odds ratios for the confounders and exposure.
The last log-odds ratio in the vector is for the exposure. If the 
option <code>data</code> (below) is specified, then the order must match the 
order of <code>data</code>.  
No default.</p>
</td></tr>
<tr><td><code id="sampleSize_data_+3A_data">data</code></td>
<td>
<p>Matrix, data frame or a list of type <code><a href="#topic+file.list">file.list</a></code> 
that gives a sample from the distribution of the confounders and exposure.
If a matrix or data frame, then the last column consists of random values for the exposure, 
while the other columns are for the confounders. The order of the columns must match the order of 
the vector <code>logOR</code>.
The default is NULL.</p>
</td></tr>
<tr><td><code id="sampleSize_data_+3A_size.2sided">size.2sided</code></td>
<td>
<p>Number between 0 and 1 giving the size of the 2-sided hypothesis test. The default is 0.05.</p>
</td></tr>
<tr><td><code id="sampleSize_data_+3A_power">power</code></td>
<td>
<p>Number between 0 and 1 for the desired power of the test. The default is 0.9.</p>
</td></tr>
<tr><td><code id="sampleSize_data_+3A_cc.ratio">cc.ratio</code></td>
<td>
<p>Number between 0 and 1 for the proportion of cases in the case-control sample.
The default is 0.5.</p>
</td></tr>
<tr><td><code id="sampleSize_data_+3A_interval">interval</code></td>
<td>
<p>Two element vector giving the interval to search for the estimated intercept parameter. 
The default is c(-100, 100).</p>
</td></tr>
<tr><td><code id="sampleSize_data_+3A_tol">tol</code></td>
<td>
<p>Positive value giving the stopping tolerance for the root finding method to estimate
the intercept parameter.
The default is 0.0001.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing four sample sizes, where two of them are for a Wald test and two for a score test.
The two sample sizes for each test correspond to the equations for 
<code class="reqn">n_{1}</code> and <code class="reqn">n_{2}</code>.
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+sampleSize_binary">sampleSize_binary</a></code>, <code><a href="#topic+sampleSize_ordinal">sampleSize_ordinal</a></code>, <code><a href="#topic+sampleSize_continuous">sampleSize_continuous</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>  prev  &lt;- 0.01
  logOR &lt;- 0.3
  data  &lt;- matrix(rnorm(100, mean=1.5), ncol=1)

  # Assuming exposuure is N(1.5, 1)
  sampleSize_data(prev, logOR, data) 

</code></pre>

<hr>
<h2 id='sampleSize_ordinal'>Sample size for an ordinal exposure</h2><span id='topic+sampleSize_ordinal'></span>

<h3>Description</h3>

<p>Calculates the required sample size of as case-control study with an ordinal exposure variable
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sampleSize_ordinal(prev, logOR, probX=NULL, distF=NULL, data=NULL, 
      size.2sided=0.05, power=0.9, cc.ratio=0.5, interval=c(-100, 100), tol=0.0001,
      n.samples=10000) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sampleSize_ordinal_+3A_prev">prev</code></td>
<td>
<p>Number between 0 and 1 giving the prevalence of disease. No default.</p>
</td></tr>
<tr><td><code id="sampleSize_ordinal_+3A_logor">logOR</code></td>
<td>
<p>Vector of ordered log-odds ratios per category increase for the confounders and exposure.
The last log-odds ratio in the vector is for the exposure. 
If the exposures are coded 0, 1, ..., k (k+1 categories), then the <code>logOR</code>
corresponds to a one category increase.
If the option <code>data</code> (below) is specified, then the order must match the 
order of <code>data</code>.  
No default.</p>
</td></tr>
<tr><td><code id="sampleSize_ordinal_+3A_probx">probX</code></td>
<td>
<p>NULL or a vector that sums to 1 giving the probability that the exposure
variable is equal to i, i = 0, 1, ..., k. 
If set to NULL, the the <code>data</code> option must be specified so 
that <code>probX</code> can be estimated. The default is NULL.</p>
</td></tr>
<tr><td><code id="sampleSize_ordinal_+3A_distf">distF</code></td>
<td>
<p>NULL, a function or a character string giving the function to generate random
vectors from the distribution of the confounders and exposure. The order of the returned
vector must match the order of <code>logOR</code>.
The default depends on other options (see details).</p>
</td></tr>
<tr><td><code id="sampleSize_ordinal_+3A_data">data</code></td>
<td>
<p>NULL, matrix, data frame or a list of type <code><a href="#topic+file.list">file.list</a></code> 
that gives a sample from the distribution of the confounders and exposure.
If a matrix or data frame, then the last column consists of random values for the exposure, 
while the other columns are for the confounders. The order of the columns must match the order of 
the vector <code>logOR</code>.
The default is NULL.</p>
</td></tr>
<tr><td><code id="sampleSize_ordinal_+3A_size.2sided">size.2sided</code></td>
<td>
<p>Number between 0 and 1 giving the size of the 2-sided hypothesis test. The default is 0.05.</p>
</td></tr>
<tr><td><code id="sampleSize_ordinal_+3A_power">power</code></td>
<td>
<p>Number between 0 and 1 for the desired power of the test. The default is 0.9.</p>
</td></tr>
<tr><td><code id="sampleSize_ordinal_+3A_cc.ratio">cc.ratio</code></td>
<td>
<p>Number between 0 and 1 for the proportion of cases in the case-control sample. The default is 0.5.</p>
</td></tr>
<tr><td><code id="sampleSize_ordinal_+3A_interval">interval</code></td>
<td>
<p>Two element vector giving the interval to search for the estimated intercept parameter. 
The default is c(-100, 100).</p>
</td></tr>
<tr><td><code id="sampleSize_ordinal_+3A_tol">tol</code></td>
<td>
<p>Positive value giving the stopping tolerance for the root finding method to estimate
the intercept parameter.
The default is 0.0001.</p>
</td></tr>
<tr><td><code id="sampleSize_ordinal_+3A_n.samples">n.samples</code></td>
<td>
<p>Integer giving the number of random vectors to generate when the option <code>distF</code>
is specified and is a random vector generation function.
The default is 10000.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If there are no confounders (length(logOR) = 1), then either <code>probX</code> or <code>data</code> must
be specified, where <code>probX</code> takes precedance. If there are confounders (length(logOR) &gt; 1), then
either <code>data</code> or <code>distF</code> must be specified, where <code>data</code> takes precedance.
</p>


<h3>Value</h3>

<p>A list containing four sample sizes, where two of them are for a Wald test and two for a score test.
The two sample sizes for each test correspond to the equations for 
<code class="reqn">n_{1}</code> and <code class="reqn">n_{2}</code>.
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+sampleSize_continuous">sampleSize_continuous</a></code>, <code><a href="#topic+sampleSize_binary">sampleSize_binary</a></code>, <code><a href="#topic+sampleSize_data">sampleSize_data</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>  prev  &lt;- 0.01
  logOR &lt;- 0.3

  # No confounders, Prob(X=1)=0.2
  sampleSize_ordinal(prev, logOR, probX=c(0.8, 0.2)) 

  # Generate data for a N(0,1) confounder and ordinal exposure with 3 levels
  data &lt;- cbind(rnorm(1000), rbinom(1000, 2, 0.5))
  beta &lt;- c(0.1, 0.2)
  sampleSize_ordinal(prev, beta, data=data) 

  # Define a function to generate random vectors for two confounders and an ordinal
  #   exposure with 5 levels
  f &lt;- function(n) {cbind(rnorm(n), rbinom(n, 1, 0.5), rbinom(n, 4, 0.5))}
  beta &lt;- c(0.2, 0.3, 0.25)
  sampleSize_ordinal(prev, beta, distF=f) 

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
