<!DOCTYPE html><html><head><title>Help for package SKFCPD</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {SKFCPD}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#compute_log_lik'>
<p>Natural logarithm of profile likelihood by the fast computing algorithm</p></a></li>
<li><a href='#Construct_G_exp_fastGP'>
<p>The coefficient matrix in the dynamic linear model when kernel is the exponential covariance</p></a></li>
<li><a href='#Construct_G_matern_5_2_fastGP'>
<p>The coefficient matrix in the dynamic linear model when kernel is the Matern covariance with roughness parameter 2.5.</p></a></li>
<li><a href='#Construct_G_matern_5_2_one_dim'>
<p>The coefficient matrix in the dynamic linear model when kernel is the Matern covariance with roughness parameter 2.5.</p></a></li>
<li><a href='#Construct_G_W_W0_V'>
<p>Generating coefficient and conditional matrics</p></a></li>
<li><a href='#Construct_W_exp_fastGP'>
<p>The conditional covariance matrix of the state in the dynamic linear model when kernel is the exponential covariance</p></a></li>
<li><a href='#Construct_W_matern_5_2_fastGP'>
<p>The conditional covariance matrix for  matern covariance with roughness parameter 2.5</p></a></li>
<li><a href='#Construct_W_matern_5_2_one_dim'>
<p>The conditional covariance matrix for  matern covariance with roughness parameter 2.5</p></a></li>
<li><a href='#Construct_W0_exp_one_dim'>
<p>covariance of the stationary distribution of the state when kernel is the exponential covariance.</p></a></li>
<li><a href='#Construct_W0_matern_5_2_one_dim'>
<p>covariance of the stationary distribution of the state when kernel is the Matern covariance with roughness parameter 2.5.</p></a></li>
<li><a href='#CPD_DLM'><p> Setting up the CPD_DLM model</p></a></li>
<li><a href='#Estimate_GP_params'><p>Estimate parameters from fast computation of GaSP model</p></a></li>
<li><a href='#Estimated_GP_params-class'><p>Estimated GaSP parameters class</p></a></li>
<li><a href='#GaSP_CPD_pred_dist_objective_prior_direct_online'><p> Computing the predictive distribution directly in the online fashion</p></a></li>
<li><a href='#GaSP_CPD_pred_dist_objective_prior_KF_online'><p> Computing the predictive distribution in the online fashion</p></a></li>
<li><a href='#Get_log_det_S2_one_dim'>
<p>the natural logarithm of the determinant of the correlation matrix and the estimated sum of squares in the exponent of the profile likelihood</p></a></li>
<li><a href='#get_LY_online'><p> Updating Kalman filter parameters</p></a></li>
<li><a href='#get_mu_sigma_hat'>
<p>Caculate the mean and variance parameter through fast computation</p></a></li>
<li><a href='#get_predictive_dist_direct_objective_prior'><p> Updating the predictive distribution</p></a></li>
<li><a href='#get_predictive_dist_KF_objective_prior'><p> Updating the predictive distribution</p></a></li>
<li><a href='#Get_Q_K'>
<p>matrices and vectors for the inverse covariance in the predictive distribution</p></a></li>
<li><a href='#KF_ini'><p> Getting inital Kalman filter parameters</p></a></li>
<li><a href='#KF_ini_for_profile_like'><p> Getting inital Kalman filter parameters for different observation sequences</p></a></li>
<li><a href='#KF_param_update_for_profile_like'><p> Updating Kalman filter parameters</p></a></li>
<li><a href='#plot_SKFCPD'>
<p>Plot for SKFCPD model</p></a></li>
<li><a href='#productPowerMinusHalf'>
<p>Square root of product for every elements in a vector</p></a></li>
<li><a href='#SKFCPD'><p> Getting the results of the SKFCPD model</p></a></li>
<li><a href='#SKFCPD-class'><p>Class <code>"SKFCPD"</code></p></a></li>
<li><a href='#SKFCPD-package'>
<p>Dynamic Linear Model for Online Changepoint Detection</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Fast Online Changepoint Detection for Temporally Correlated Data</td>
</tr>
<tr>
<td>Version:</td>
<td>0.2.4</td>
</tr>
<tr>
<td>Date:</td>
<td>2024-02-15</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Hanmo Li &lt;hanmo@pstat.ucsb.edu&gt;</td>
</tr>
<tr>
<td>Author:</td>
<td>Hanmo Li [aut, cre],
  Yuedong Wang [aut],
  Mengyang Gu [aut]</td>
</tr>
<tr>
<td>Description:</td>
<td>Sequential Kalman filter for scalable online changepoint detection by temporally correlated data. It enables fast single and multiple change points with missing values. See the reference: Hanmo Li, Yuedong Wang, Mengyang Gu (2023), &lt;<a href="https://arxiv.org/abs/2310.18611">arXiv:2310.18611</a>&gt;.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL (&ge; 3)</a></td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0), methods (&ge; 4.2.2), rlang (&ge; 1.0.6), ggplot2
(&ge; 3.4.0), ggpubr (&ge; 0.5.0), reshape2 (&ge; 1.4.4), FastGaSP
(&ge; 0.5.2)</td>
</tr>
<tr>
<td>Imports:</td>
<td>Rcpp (&ge; 1.0.9)</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp, RcppEigen</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-02-16 05:00:08 UTC; lihan</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-02-17 23:30:12 UTC</td>
</tr>
</table>
<hr>
<h2 id='compute_log_lik'> 
Natural logarithm of profile likelihood by the fast computing algorithm
</h2><span id='topic+compute_log_lik'></span>

<h3>Description</h3>

<p>This function computes the natural logarithm of the profile likelihood for the range and nugget parameter after plugging the closed form maximum likelihood estimator for the variance parameter. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>compute_log_lik(param, design, response, kernel_type)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="compute_log_lik_+3A_param">param</code></td>
<td>
<p>a vector of parameters. The first parameter is the natural logarithm of the inverse range parameter in the kernel function. If the data contain noise, the second parameter is the logarithm of the nugget-variance ratio parameter.</p>
</td></tr>
<tr><td><code id="compute_log_lik_+3A_design">design</code></td>
<td>
<p>A matrix with dimension n x p. The design of the experiment. </p>
</td></tr>
<tr><td><code id="compute_log_lik_+3A_response">response</code></td>
<td>
<p>A matrix with dimension n x q. The observations. </p>
</td></tr>
<tr><td><code id="compute_log_lik_+3A_kernel_type">kernel_type</code></td>
<td>
<p>A character specifying the type of kernels of the input. <code>matern_5_2</code> are <code>Matern correlation</code> with roughness parameter 5/2. <code>exp</code> is power exponential correlation with roughness parameter alpha=2. The default choice is <code>matern_5_2</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The numerical value of natural logarithm of the profile likelihood.
</p>


<h3>Author(s)</h3>

<p>Hanmo Li [aut, cre],
  Yuedong Wang [aut],
  Mengyang Gu [aut]
</p>
<p>Maintainer: Hanmo Li &lt;hanmo@pstat.ucsb.edu&gt;
</p>


<h3>References</h3>

<p>Hartikainen, J. and Sarkka, S. (2010). <em>Kalman filtering and smoothing solutions to temporal gaussian process regression models</em>,  <em>Machine Learning for Signal Processing (MLSP), 2010 IEEE International Workshop</em>,  379-384.
</p>
<p>M. Gu, Y. Xu (2017), <em>Nonseparable Gaussian stochastic process: a unified
view and computational strategy</em>, arXiv:1711.11501.
</p>
<p>M. Gu, X. Wang and J.O. Berger (2018), <em>Robust Gaussian Stochastic Process Emulation</em>, <em>Annals of Statistics</em>, <b>46</b>, 3038-3066.
</p>

<hr>
<h2 id='Construct_G_exp_fastGP'> 
The coefficient matrix in the dynamic linear model when kernel is the exponential covariance
</h2><span id='topic+Construct_G_exp_fastGP'></span>

<h3>Description</h3>

<p>The coefficient matrix in the dynamic linear model when kernel is the exponential covariance. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Construct_G_exp_fastGP(delta_x,lambda)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Construct_G_exp_fastGP_+3A_delta_x">delta_x</code></td>
<td>
<p>the distance between the sorted input.
</p>
</td></tr>
<tr><td><code id="Construct_G_exp_fastGP_+3A_lambda">lambda</code></td>
<td>
<p>the transformed range parameter. </p>
</td></tr>
</table>


<h3>Value</h3>

<p>GG matrix. 
</p>


<h3>Author(s)</h3>

<p>Hanmo Li [aut, cre],
  Yuedong Wang [aut],
  Mengyang Gu [aut]
</p>
<p>Maintainer: Hanmo Li &lt;hanmo@pstat.ucsb.edu&gt;
</p>


<h3>References</h3>

<p>Hartikainen, J. and Sarkka, S. (2010). <em>Kalman filtering and smoothing solutions to temporal gaussian process regression models</em>.  <em>Machine Learning for Signal Processing (MLSP), 2010 IEEE International Workshop</em>,  379-384.
</p>
<p>M. Gu, Y. Xu (2019), <em>fast nonseparable Gaussian stochastic process with application to methylation level interpolation</em>.  <em>Journal of Computational and Graphical Statistics</em>, In Press, arXiv:1711.11501.
</p>
<p>Campagnoli P, Petris G, Petrone S. (2009), <em>Dynamic linear model with R</em>. Springer-Verlag New York.
</p>

<hr>
<h2 id='Construct_G_matern_5_2_fastGP'> 
The coefficient matrix in the dynamic linear model when kernel is the Matern covariance with roughness parameter 2.5. 
</h2><span id='topic+Construct_G_matern_5_2_fastGP'></span>

<h3>Description</h3>

<p>The coefficient matrix in the dynamic linear model when kernel is the Matern covariance with roughness parameter 2.5. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Construct_G_matern_5_2_fastGP(delta_x,lambda)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Construct_G_matern_5_2_fastGP_+3A_delta_x">delta_x</code></td>
<td>
<p>A vector of the distance between the sorted input.
</p>
</td></tr>
<tr><td><code id="Construct_G_matern_5_2_fastGP_+3A_lambda">lambda</code></td>
<td>
<p>the transformed range parameter. </p>
</td></tr>
</table>


<h3>Value</h3>

<p>GG matrix. 
</p>


<h3>Author(s)</h3>

<p>Hanmo Li [aut, cre],
  Yuedong Wang [aut],
  Mengyang Gu [aut]
</p>
<p>Maintainer: Hanmo Li &lt;hanmo@pstat.ucsb.edu&gt;
</p>


<h3>References</h3>

<p>Hartikainen, J. and Sarkka, S. (2010). <em>Kalman filtering and smoothing solutions to temporal gaussian process regression models</em>.  <em>Machine Learning for Signal Processing (MLSP), 2010 IEEE International Workshop</em>,  379-384.
</p>
<p>M. Gu, Y. Xu (2019), <em>fast nonseparable Gaussian stochastic process with application to methylation level interpolation</em>.  <em>Journal of Computational and Graphical Statistics</em>, In Press, arXiv:1711.11501.
</p>
<p>Campagnoli P, Petris G, Petrone S. (2009), <em>Dynamic linear model with R</em>. Springer-Verlag New York.
</p>

<hr>
<h2 id='Construct_G_matern_5_2_one_dim'> 
The coefficient matrix in the dynamic linear model when kernel is the Matern covariance with roughness parameter 2.5. 
</h2><span id='topic+Construct_G_matern_5_2_one_dim'></span>

<h3>Description</h3>

<p>The coefficient matrix in the dynamic linear model when kernel is the Matern covariance with roughness parameter 2.5. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Construct_G_matern_5_2_one_dim(delta_x,lambda)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Construct_G_matern_5_2_one_dim_+3A_delta_x">delta_x</code></td>
<td>
<p>A value of the distance between the sorted input.
</p>
</td></tr>
<tr><td><code id="Construct_G_matern_5_2_one_dim_+3A_lambda">lambda</code></td>
<td>
<p>the transformed range parameter. </p>
</td></tr>
</table>


<h3>Value</h3>

<p>GG matrix. 
</p>


<h3>Author(s)</h3>

<p>Hanmo Li [aut, cre],
  Yuedong Wang [aut],
  Mengyang Gu [aut]
</p>
<p>Maintainer: Hanmo Li &lt;hanmo@pstat.ucsb.edu&gt;
</p>


<h3>References</h3>

<p>Hartikainen, J. and Sarkka, S. (2010). <em>Kalman filtering and smoothing solutions to temporal gaussian process regression models</em>.  <em>Machine Learning for Signal Processing (MLSP), 2010 IEEE International Workshop</em>,  379-384.
</p>
<p>M. Gu, Y. Xu (2019), <em>fast nonseparable Gaussian stochastic process with application to methylation level interpolation</em>.  <em>Journal of Computational and Graphical Statistics</em>, In Press, arXiv:1711.11501.
</p>
<p>Campagnoli P, Petris G, Petrone S. (2009), <em>Dynamic linear model with R</em>. Springer-Verlag New York.
</p>

<hr>
<h2 id='Construct_G_W_W0_V'> 
Generating coefficient and conditional matrics</h2><span id='topic+Construct_G_W_W0_V'></span>

<h3>Description</h3>

<p>Generating coefficient and conditional matrics for Gaussian Process(GP) model with Matern 2.5 or power exponential kernels.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Construct_G_W_W0_V(d, gamma, eta, kernel_type, is_initial)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Construct_G_W_W0_V_+3A_d">d</code></td>
<td>
<p>A value of the distance between the sorted input.</p>
</td></tr>
<tr><td><code id="Construct_G_W_W0_V_+3A_gamma">gamma</code></td>
<td>
<p>A value of the range parameter for the covariance matrix.</p>
</td></tr>
<tr><td><code id="Construct_G_W_W0_V_+3A_eta">eta</code></td>
<td>
<p>The noise-to-signal ratio. </p>
</td></tr>
<tr><td><code id="Construct_G_W_W0_V_+3A_kernel_type">kernel_type</code></td>
<td>
<p>A character specifying the type of kernels of the input. <code>matern_5_2</code> are <code>Matern correlation</code> with roughness parameter 5/2. <code>exp</code> is power exponential correlation with roughness parameter alpha=2. The default choice is <code>matern_5_2</code>.</p>
</td></tr>
<tr><td><code id="Construct_G_W_W0_V_+3A_is_initial">is_initial</code></td>
<td>
<p>A bolean variable. is_initial=TRUE means the matrics generated is for the inital state.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of GG, W, W0 and VV matrix. 
</p>


<h3>Author(s)</h3>

<p>Hanmo Li [aut, cre],
  Yuedong Wang [aut],
  Mengyang Gu [aut]
</p>
<p>Maintainer: Hanmo Li &lt;hanmo@pstat.ucsb.edu&gt;
</p>


<h3>References</h3>

<p>Hartikainen, J. and Sarkka, S. (2010). <em>Kalman filtering and smoothing solutions to temporal gaussian process regression models</em>.  <em>Machine Learning for Signal Processing (MLSP), 2010 IEEE International Workshop</em>,  379-384.
</p>
<p>M. Gu, Y. Xu (2019), <em>fast nonseparable Gaussian stochastic process with application to methylation level interpolation</em>.  <em>Journal of Computational and Graphical Statistics</em>, In Press, arXiv:1711.11501.
</p>
<p>Campagnoli P, Petris G, Petrone S. (2009), <em>Dynamic linear model with R</em>. Springer-Verlag New York.
</p>

<hr>
<h2 id='Construct_W_exp_fastGP'> 
The conditional covariance matrix of the state in the dynamic linear model when kernel is the exponential covariance
</h2><span id='topic+Construct_W_exp_fastGP'></span>

<h3>Description</h3>

<p>The conditional covariance matrix of the state in the dynamic linear model when kernel is the exponential covariance. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Construct_W_exp_fastGP(delta_x,lambda,W0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Construct_W_exp_fastGP_+3A_delta_x">delta_x</code></td>
<td>
<p>the distance between the sorted input.
</p>
</td></tr>
<tr><td><code id="Construct_W_exp_fastGP_+3A_lambda">lambda</code></td>
<td>
<p>the transformed range parameter. </p>
</td></tr>
<tr><td><code id="Construct_W_exp_fastGP_+3A_w0">W0</code></td>
<td>
<p>the covariance matrix of the stationary distribution of the state. </p>
</td></tr>
</table>


<h3>Value</h3>

<p>W matrix. 
</p>


<h3>Author(s)</h3>

<p>Hanmo Li [aut, cre],
  Yuedong Wang [aut],
  Mengyang Gu [aut]
</p>
<p>Maintainer: Hanmo Li &lt;hanmo@pstat.ucsb.edu&gt;
</p>


<h3>References</h3>

<p>Hartikainen, J. and Sarkka, S. (2010). <em>Kalman filtering and smoothing solutions to temporal gaussian process regression models</em>.  <em>Machine Learning for Signal Processing (MLSP), 2010 IEEE International Workshop</em>,  379-384.
</p>
<p>M. Gu, Y. Xu (2019), <em>fast nonseparable Gaussian stochastic process with application to methylation level interpolation</em>.  <em>Journal of Computational and Graphical Statistics</em>, In Press, arXiv:1711.11501.
</p>
<p>Campagnoli P, Petris G, Petrone S. (2009), <em>Dynamic linear model with R</em>. Springer-Verlag New York.
</p>

<hr>
<h2 id='Construct_W_matern_5_2_fastGP'> 
The conditional covariance matrix for  matern covariance with roughness parameter 2.5
</h2><span id='topic+Construct_W_matern_5_2_fastGP'></span>

<h3>Description</h3>

<p>The conditional covariance matrix of the state in the dynamic linear model when kernel is the matern covariance with roughness parameter 2.5.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Construct_W_matern_5_2_fastGP(delta_x,lambda, W0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Construct_W_matern_5_2_fastGP_+3A_delta_x">delta_x</code></td>
<td>
<p>a vector of the distance between the sorted input.
</p>
</td></tr>
<tr><td><code id="Construct_W_matern_5_2_fastGP_+3A_lambda">lambda</code></td>
<td>
<p>the transformed range parameter. </p>
</td></tr>
<tr><td><code id="Construct_W_matern_5_2_fastGP_+3A_w0">W0</code></td>
<td>
<p>the covariance matrix of the stationary distribution of the state. </p>
</td></tr>
</table>


<h3>Value</h3>

<p>W matrix. 
</p>


<h3>Author(s)</h3>

<p>Hanmo Li [aut, cre],
  Yuedong Wang [aut],
  Mengyang Gu [aut]
</p>
<p>Maintainer: Hanmo Li &lt;hanmo@pstat.ucsb.edu&gt;
</p>


<h3>References</h3>

<p>Hartikainen, J. and Sarkka, S. (2010). <em>Kalman filtering and smoothing solutions to temporal gaussian process regression models</em>.  <em>Machine Learning for Signal Processing (MLSP), 2010 IEEE International Workshop</em>,  379-384.
</p>
<p>M. Gu, Y. Xu (2019), <em>fast nonseparable Gaussian stochastic process with application to methylation level interpolation</em>.  <em>Journal of Computational and Graphical Statistics</em>, In Press, arXiv:1711.11501.
</p>
<p>Campagnoli P, Petris G, Petrone S. (2009), <em>Dynamic linear model with R</em>. Springer-Verlag New York.
</p>

<hr>
<h2 id='Construct_W_matern_5_2_one_dim'> 
The conditional covariance matrix for  matern covariance with roughness parameter 2.5
</h2><span id='topic+Construct_W_matern_5_2_one_dim'></span>

<h3>Description</h3>

<p>The conditional covariance matrix of the state in the dynamic linear model when kernel is the matern covariance with roughness parameter 2.5.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Construct_W_matern_5_2_one_dim(delta_x,lambda)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Construct_W_matern_5_2_one_dim_+3A_delta_x">delta_x</code></td>
<td>
<p>a value of the distance between the sorted input.
</p>
</td></tr>
<tr><td><code id="Construct_W_matern_5_2_one_dim_+3A_lambda">lambda</code></td>
<td>
<p>the transformed range parameter. </p>
</td></tr>
</table>


<h3>Value</h3>

<p>W matrix. 
</p>


<h3>Author(s)</h3>

<p>Hanmo Li [aut, cre],
  Yuedong Wang [aut],
  Mengyang Gu [aut]
</p>
<p>Maintainer: Hanmo Li &lt;hanmo@pstat.ucsb.edu&gt;
</p>


<h3>References</h3>

<p>Hartikainen, J. and Sarkka, S. (2010). <em>Kalman filtering and smoothing solutions to temporal gaussian process regression models</em>.  <em>Machine Learning for Signal Processing (MLSP), 2010 IEEE International Workshop</em>,  379-384.
</p>
<p>M. Gu, Y. Xu (2019), <em>fast nonseparable Gaussian stochastic process with application to methylation level interpolation</em>.  <em>Journal of Computational and Graphical Statistics</em>, In Press, arXiv:1711.11501.
</p>
<p>Campagnoli P, Petris G, Petrone S. (2009), <em>Dynamic linear model with R</em>. Springer-Verlag New York.
</p>

<hr>
<h2 id='Construct_W0_exp_one_dim'> 
covariance of the stationary distribution of the state when kernel is the exponential covariance.
</h2><span id='topic+Construct_W0_exp_one_dim'></span>

<h3>Description</h3>

<p>This function computes the covariance of the stationary distribution of the state when kernel is the exponential covariance.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Construct_W0_exp_one_dim(lambda)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Construct_W0_exp_one_dim_+3A_lambda">lambda</code></td>
<td>
<p>the transformed range parameter. </p>
</td></tr>
</table>


<h3>Value</h3>

<p>W0 matrix. 
</p>


<h3>Author(s)</h3>

<p>Hanmo Li [aut, cre],
  Yuedong Wang [aut],
  Mengyang Gu [aut]
</p>
<p>Maintainer: Hanmo Li &lt;hanmo@pstat.ucsb.edu&gt;
</p>


<h3>References</h3>

<p>Hartikainen, J. and Sarkka, S. (2010). <em>Kalman filtering and smoothing solutions to temporal gaussian process regression models</em>.  <em>Machine Learning for Signal Processing (MLSP), 2010 IEEE International Workshop</em>,  379-384.
</p>
<p>M. Gu, Y. Xu (2019), <em>fast nonseparable Gaussian stochastic process with application to methylation level interpolation</em>.  <em>Journal of Computational and Graphical Statistics</em>, In Press, arXiv:1711.11501.
</p>
<p>Campagnoli P, Petris G, Petrone S. (2009), <em>Dynamic linear model with R</em>. Springer-Verlag New York.
</p>

<hr>
<h2 id='Construct_W0_matern_5_2_one_dim'> 
covariance of the stationary distribution of the state when kernel is the Matern covariance with roughness parameter 2.5. 
</h2><span id='topic+Construct_W0_matern_5_2_one_dim'></span>

<h3>Description</h3>

<p>This function computes covariance of the stationary distribution of the state when kernel is the Matern covariance with roughness parameter 2.5. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Construct_W0_matern_5_2_one_dim(lambda)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Construct_W0_matern_5_2_one_dim_+3A_lambda">lambda</code></td>
<td>
<p>the transformed range parameter. </p>
</td></tr>
</table>


<h3>Value</h3>

<p>W0 matrix. 
</p>


<h3>Author(s)</h3>

<p>Hanmo Li [aut, cre],
  Yuedong Wang [aut],
  Mengyang Gu [aut]
</p>
<p>Maintainer: Hanmo Li &lt;hanmo@pstat.ucsb.edu&gt;
</p>


<h3>References</h3>

<p>Hartikainen, J. and Sarkka, S. (2010). <em>Kalman filtering and smoothing solutions to temporal gaussian process regression models</em>.  <em>Machine Learning for Signal Processing (MLSP), 2010 IEEE International Workshop</em>,  379-384.
</p>
<p>M. Gu, Y. Xu (2019), <em>fast nonseparable Gaussian stochastic process with application to methylation level interpolation</em>.  <em>Journal of Computational and Graphical Statistics</em>, In Press, arXiv:1711.11501.
</p>
<p>Campagnoli P, Petris G, Petrone S. (2009), <em>Dynamic linear model with R</em>. Springer-Verlag New York.
</p>

<hr>
<h2 id='CPD_DLM'> Setting up the CPD_DLM model
</h2><span id='topic+CPD_DLM'></span>

<h3>Description</h3>

<p>Implementing the robust GaSP model for estimating the changepoint locations. The range parameter and noise-to-signal ratio are estimated from the training samples by a Gaussian process model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  CPD_DLM(design, response, gamma,model_type, mu, sigma_2, eta,
         kernel_type, stop_at_first_cp, hazard_vec,
         truncate_at_prev_cp)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CPD_DLM_+3A_design">design</code></td>
<td>
<p>A matrix with dimension n x p. The design of the experiment. </p>
</td></tr>
<tr><td><code id="CPD_DLM_+3A_response">response</code></td>
<td>
<p>A matrix with dimension n x q. The observations. </p>
</td></tr>
<tr><td><code id="CPD_DLM_+3A_gamma">gamma</code></td>
<td>
<p>A numeric variable of the range parameter for the covariance matrix. The default value of gamma is 1.</p>
</td></tr>
<tr><td><code id="CPD_DLM_+3A_model_type">model_type</code></td>
<td>
<p>A numeric variable that can take values of 0, 1 and 2. Model_type=0 stands for a GP model with unknown mean and known variance. Model_type=1 stands for a GP model with known mean and unknown variance. Model_type=2 stands for a GP model with unknown mean and unknown variance. The default value of model_type is 2.</p>
</td></tr>
<tr><td><code id="CPD_DLM_+3A_mu">mu</code></td>
<td>
<p>A vector of the mean parameter at each coordinate. Ignored when model_type = 0 or 2.</p>
</td></tr>
<tr><td><code id="CPD_DLM_+3A_sigma_2">sigma_2</code></td>
<td>
<p>A vector of the variance parameter at each coordinate.</p>
</td></tr>
<tr><td><code id="CPD_DLM_+3A_eta">eta</code></td>
<td>
<p>A vector of the noise-to-signal ratio at each coordinate</p>
</td></tr>
<tr><td><code id="CPD_DLM_+3A_kernel_type">kernel_type</code></td>
<td>
<p>A character specifying the type of kernels of the input. <code>matern_5_2</code> are <code>Matern correlation</code> with roughness parameter 5/2. <code>exp</code> is power exponential correlation with roughness parameter alpha=2. The default choice is <code>matern_5_2</code>.</p>
</td></tr>
<tr><td><code id="CPD_DLM_+3A_stop_at_first_cp">stop_at_first_cp</code></td>
<td>
<p>A numeric variable that decides if the SKFCPD method stops when it detects the first changepoint. The default value of stop_at_first_cp is FALSE.</p>
</td></tr>
<tr><td><code id="CPD_DLM_+3A_hazard_vec">hazard_vec</code></td>
<td>
<p>The hazard vector in the SKFCPD method. 1/vector is the prior probability that a changepoint occur at a vector of time points.</p>
</td></tr>
<tr><td><code id="CPD_DLM_+3A_truncate_at_prev_cp">truncate_at_prev_cp</code></td>
<td>
<p>If TRUE, truncate the run length at the most recently detected changepoint. The default value of truncate_at_prev_cp is FALSE.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>SKFCPD</code> returns a S4 object of class <code>SKFCPD</code> (see <code>SKFCPD-class</code>).
</p>


<h3>Author(s)</h3>

<p>Hanmo Li [aut, cre],
  Yuedong Wang [aut],
  Mengyang Gu [aut]
</p>
<p>Maintainer: Hanmo Li &lt;hanmo@pstat.ucsb.edu&gt;
</p>


<h3>References</h3>

<p>Li, Hanmo, Yuedong Wang, and Mengyang Gu. <em>Sequential Kalman filter for fast online changepoint detection in longitudinal health records.</em> arXiv preprint arXiv:2310.18611 (2023).
</p>
<p>Fearnhead, Paul, and Zhen Liu. <em>On-line inference for multiple changepoint problems.</em> Journal of the Royal Statistical Society Series B: Statistical Methodology 69, no. 4 (2007): 589-605.
</p>
<p>Adams, Ryan Prescott, and David JC MacKay. <em>Bayesian online changepoint detection.</em> arXiv preprint arXiv:0710.3742 (2007).
</p>
<p>Hartikainen, Jouni, and Simo Sarkka. <em>Kalman filtering and smoothing solutions to temporal Gaussian process regression models.</em> In 2010 IEEE international workshop on machine learning for signal processing, pp. 379-384. IEEE, 2010.
</p>

<hr>
<h2 id='Estimate_GP_params'>Estimate parameters from fast computation of GaSP model
</h2><span id='topic+Estimate_GP_params'></span>

<h3>Description</h3>

<p>Getting the estimated parameters from fast computation of the Gaussian stochastic process (GaSP) model with the Matern kernel function with a noise.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  Estimate_GP_params(input, output, kernel_type='matern_5_2')
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Estimate_GP_params_+3A_input">input</code></td>
<td>
<p>a vector with dimension num_obs x 1 for the sorted input locations.</p>
</td></tr>
<tr><td><code id="Estimate_GP_params_+3A_output">output</code></td>
<td>
<p>a  vector with dimension n x 1 for the observations at the sorted input locations.</p>
</td></tr>
<tr><td><code id="Estimate_GP_params_+3A_kernel_type">kernel_type</code></td>
<td>
<p>a <code>character</code> to specify the type of kernel to use. The current version supports kernel_type to be &quot;matern_5_2&quot; or &quot;exp&quot;, meaning that the matern kernel with roughness parameter being 2.5 or 0.5 (power exponent kernel), respectively. 
</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>Estimate_GP_params</code> returns an S4 object of class <code>Estimated_GP_params</code> with estimated parameters including
</p>
<table>
<tr><td><code>beta</code></td>
<td>
<p>the inverse range parameter, i.e. beta=1/gamma</p>
</td></tr>
<tr><td><code>eta</code></td>
<td>
<p>the noise-to-signal ratio</p>
</td></tr>
<tr><td><code>sigma_2</code></td>
<td>
<p>the variance parameter</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Hanmo Li [aut, cre],
  Yuedong Wang [aut],
  Mengyang Gu [aut]
</p>
<p>Maintainer: Hanmo Li &lt;hanmo@pstat.ucsb.edu&gt;
</p>


<h3>References</h3>

<p>Hartikainen, Jouni, and Simo Sarkka. <em>Kalman filtering and smoothing solutions to temporal Gaussian process regression models.</em> In 2010 IEEE international workshop on machine learning for signal processing, pp. 379-384. IEEE, 2010.
</p>
<p>Gu, Mengyang, and Yanxun Xu. <em>Fast nonseparable Gaussian stochastic process with application to methylation level interpolation.</em> Journal of Computational and Graphical Statistics 29, no. 2 (2020): 250-260.
</p>
<p>Gu, Mengyang, and Weining Shen. <em>Generalized probabilistic principal component analysis of correlated data.</em> The Journal of Machine Learning Research 21, no. 1 (2020): 428-468.
</p>
<p>Gu, Mengyang, Xiaojing Wang, and James O. Berger. <em>Robust Gaussian stochastic process emulation.</em> The Annals of Statistics 46, no. 6A (2018): 3038-3066.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
  library(SKFCPD)

  #------------------------------------------------------------------------------
  # simple example with noise
  #------------------------------------------------------------------------------
  
  y_R&lt;-function(x){
    cos(2*pi*x)
  }
  ###let's test for 100 observations
  set.seed(1)
  num_obs=100
  input=runif(num_obs)
  output=y_R(input)+rnorm(num_obs,mean=0,sd=1)
  
  ## run Estimate_GP_params to get estimated parameters
  params_est = Estimate_GP_params(input, output)
  print(params_est@beta) ## inverse of range parameter
  print(params_est@eta) ## noise-to-signal ratio
  print(params_est@sigma_2) ## variance
</code></pre>

<hr>
<h2 id='Estimated_GP_params-class'>Estimated GaSP parameters class</h2><span id='topic+Estimated_GP_params-class'></span>

<h3>Description</h3>

<p>S4 class for fast parameter estimation of the Gaussian stochastic process (GaSP) model with the Matern kernel function with or without a noise.</p>


<h3>Objects from the Class</h3>

<p>Objects of this class are created with the function <code><a href="#topic+Estimate_GP_params">Estimate_GP_params</a></code> that computes the calculations needed for setting up the estimation and prediction.</p>


<h3>Slots</h3>


<dl>
<dt><code>beta</code>:</dt><dd><p>object of class <code>numeric</code> for the inverse of the range parameter, i.e. beta = 1/gamma.</p>
</dd>
<dt><code>eta</code>:</dt><dd><p>object of class <code>numeric</code> for the estimated noise-to-signal parameter.</p>
</dd>
<dt><code>sigma_2</code>:</dt><dd><p>object of class <code>numeric</code> for the estimated variance parameter.</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Hanmo Li [aut, cre],
  Yuedong Wang [aut],
  Mengyang Gu [aut]
</p>
<p>Maintainer: Hanmo Li &lt;hanmo@pstat.ucsb.edu&gt;
</p>


<h3>References</h3>

<p>Hartikainen, J. and Sarkka, S. (2010). <em>Kalman filtering and smoothing solutions to temporal gaussian process regression models</em>,  <em>Machine Learning for Signal Processing (MLSP), 2010 IEEE International Workshop</em>,  379-384.
</p>
<p>M. Gu, Y. Xu (2017), <em>Nonseparable Gaussian stochastic process: a unified
view and computational strategy</em>, arXiv:1711.11501.
</p>
<p>M. Gu, X. Wang and J.O. Berger (2018), <em>Robust Gaussian Stochastic Process Emulation</em>, <em>Annals of Statistics</em>, <b>46</b>, 3038-3066.
</p>

<hr>
<h2 id='GaSP_CPD_pred_dist_objective_prior_direct_online'> Computing the predictive distribution directly in the online fashion
</h2><span id='topic+GaSP_CPD_pred_dist_objective_prior_direct_online'></span>

<h3>Description</h3>

<p>This function computs directly the predictive distribution of the run length in the online fashion. The direct computation includes the inversion of covariance matrix, which is of computational complexity $O(n^3)$, with $n$ being the number of observations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  GaSP_CPD_pred_dist_objective_prior_direct_online(cur_seq, d, gamma, eta, mu, sigma_2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="GaSP_CPD_pred_dist_objective_prior_direct_online_+3A_cur_seq">cur_seq</code></td>
<td>
<p>A vector of sequence of observations.</p>
</td></tr>
<tr><td><code id="GaSP_CPD_pred_dist_objective_prior_direct_online_+3A_d">d</code></td>
<td>
<p>A value of the distance between the sorted input.</p>
</td></tr>
<tr><td><code id="GaSP_CPD_pred_dist_objective_prior_direct_online_+3A_gamma">gamma</code></td>
<td>
<p>A numeric variable of the range parameter for the covariance matrix. The default value of gamma is 1.</p>
</td></tr>
<tr><td><code id="GaSP_CPD_pred_dist_objective_prior_direct_online_+3A_eta">eta</code></td>
<td>
<p>A vector of the noise-to-signal ratio at each coordinate</p>
</td></tr>
<tr><td><code id="GaSP_CPD_pred_dist_objective_prior_direct_online_+3A_mu">mu</code></td>
<td>
<p>A vector of the mean parameter at each coordinate. Ignored when model_type = 0 or 2.</p>
</td></tr>
<tr><td><code id="GaSP_CPD_pred_dist_objective_prior_direct_online_+3A_sigma_2">sigma_2</code></td>
<td>
<p>A vector of the variance parameter at each coordinate.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>GaSP_CPD_pred_dist_objective_prior_direct_online</code> returns the log likelihood of observations that follows Gaussian Process with Exponential kernel.
</p>


<h3>Author(s)</h3>

<p>Hanmo Li [aut, cre],
  Yuedong Wang [aut],
  Mengyang Gu [aut]
</p>
<p>Maintainer: Hanmo Li &lt;hanmo@pstat.ucsb.edu&gt;
</p>


<h3>References</h3>

<p>Williams, C. K., &amp; Rasmussen, C. E. (2006). <em>Gaussian processes for machine learning (Vol. 2, No. 3, p. 4).</em> <em>Cambridge, MA: MIT press.</em>
</p>

<hr>
<h2 id='GaSP_CPD_pred_dist_objective_prior_KF_online'> Computing the predictive distribution in the online fashion
</h2><span id='topic+GaSP_CPD_pred_dist_objective_prior_KF_online'></span>

<h3>Description</h3>

<p>This function computs the predictive distribution of the run length in the online fashion.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  GaSP_CPD_pred_dist_objective_prior_KF_online(KF_params, prev_L_params, cur_point,
  d, gamma, model_type, mu, sigma_2, eta, kernel_type, G_W_W0_V_ini, G_W_W0_V)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="GaSP_CPD_pred_dist_objective_prior_KF_online_+3A_kf_params">KF_params</code></td>
<td>
<p>A list of current Kalman filter parameters.</p>
</td></tr>
<tr><td><code id="GaSP_CPD_pred_dist_objective_prior_KF_online_+3A_prev_l_params">prev_L_params</code></td>
<td>
<p>A list of previous Kalman filter parameters.</p>
</td></tr>
<tr><td><code id="GaSP_CPD_pred_dist_objective_prior_KF_online_+3A_cur_point">cur_point</code></td>
<td>
<p>A value of current observation.</p>
</td></tr>
<tr><td><code id="GaSP_CPD_pred_dist_objective_prior_KF_online_+3A_d">d</code></td>
<td>
<p>A value of the distance between the sorted input.</p>
</td></tr>
<tr><td><code id="GaSP_CPD_pred_dist_objective_prior_KF_online_+3A_gamma">gamma</code></td>
<td>
<p>A numeric variable of the range parameter for the covariance matrix. The default value of gamma is 1.</p>
</td></tr>
<tr><td><code id="GaSP_CPD_pred_dist_objective_prior_KF_online_+3A_model_type">model_type</code></td>
<td>
<p>A numeric variable that can take values of 0, 1 and 2. Model_type=0 stands for a GP model with unknown mean and known variance. Model_type=1 stands for a GP model with known mean and unknown variance. Model_type=2 stands for a GP model with unknown mean and unknown variance. The default value of model_type is 2.</p>
</td></tr>
<tr><td><code id="GaSP_CPD_pred_dist_objective_prior_KF_online_+3A_mu">mu</code></td>
<td>
<p>A vector of the mean parameter at each coordinate. Ignored when model_type = 0 or 2.</p>
</td></tr>
<tr><td><code id="GaSP_CPD_pred_dist_objective_prior_KF_online_+3A_sigma_2">sigma_2</code></td>
<td>
<p>A vector of the variance parameter at each coordinate.</p>
</td></tr>
<tr><td><code id="GaSP_CPD_pred_dist_objective_prior_KF_online_+3A_eta">eta</code></td>
<td>
<p>A vector of the noise-to-signal ratio at each coordinate</p>
</td></tr>
<tr><td><code id="GaSP_CPD_pred_dist_objective_prior_KF_online_+3A_kernel_type">kernel_type</code></td>
<td>
<p>A character specifying the type of kernels of the input. <code>matern_5_2</code> are <code>Matern correlation</code> with roughness parameter 5/2. <code>exp</code> is power exponential correlation with roughness parameter alpha=2. The default choice is <code>matern_5_2</code>.</p>
</td></tr>
<tr><td><code id="GaSP_CPD_pred_dist_objective_prior_KF_online_+3A_g_w_w0_v_ini">G_W_W0_V_ini</code></td>
<td>
<p>A list of the initial coefficient and conditional matrics for Gaussian Process(GP) model. It's the output from the function <code>Construct_G_W_W0_V</code> </p>
</td></tr>
<tr><td><code id="GaSP_CPD_pred_dist_objective_prior_KF_online_+3A_g_w_w0_v">G_W_W0_V</code></td>
<td>
<p>A list of the coefficient and conditional matrics for Gaussian Process(GP) model. It's the output from the function <code>Construct_G_W_W0_V</code> </p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>GaSP_CPD_pred_dist_objective_prior_KF_online</code> returns a list that contains 3 items: (1) the current Kalman filter parameters; (2) the previous Kalman filter parameters and (3) the vector of the logrithm for the current predictive distribution of different run lengths.
</p>


<h3>Author(s)</h3>

<p>Hanmo Li [aut, cre],
  Yuedong Wang [aut],
  Mengyang Gu [aut]
</p>
<p>Maintainer: Hanmo Li &lt;hanmo@pstat.ucsb.edu&gt;
</p>


<h3>References</h3>

<p>Fearnhead, P., &amp; Liu, Z. (2007). <em>On-line inference for multiple changepoint problem.</em> <em> Journal of the Royal Statistical Society: Series B (Statistical Methodology)</em>, 69(4), 589-605.
</p>
<p>Adams, R. P., &amp; MacKay, D. J. (2007). <em>Bayesian online changepoint detection.</em> <em>arXiv preprint</em> arXiv:0710.3742.
</p>
<p>Hartikainen, J. and Sarkka, S. (2010). <em>Kalman filtering and smoothing solutions to temporal gaussian process regression models</em>,  <em>Machine Learning for Signal Processing (MLSP), 2010 IEEE International Workshop</em>,  379-384.
</p>

<hr>
<h2 id='Get_log_det_S2_one_dim'> 
the natural logarithm of the determinant of the correlation matrix and the estimated sum of squares in the exponent of the profile likelihood
</h2><span id='topic+Get_log_det_S2_one_dim'></span>

<h3>Description</h3>

<p>This function computes the natural logarithm of the determinant of the correlation matrix and the estimated sum of squares for computing the profile likelihood. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Get_log_det_S2_one_dim(param,have_noise,delta_x,output,kernel_type)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Get_log_det_S2_one_dim_+3A_param">param</code></td>
<td>
<p>a vector of parameters. The first parameter is the natural logarithm of the inverse range parameter in the kernel function. If the data contain noise, the second parameter is the logarithm of the nugget-variance ratio parameter.
</p>
</td></tr>
<tr><td><code id="Get_log_det_S2_one_dim_+3A_have_noise">have_noise</code></td>
<td>
<p>a bool value. If it is true, it means the model contains a noise. </p>
</td></tr>
<tr><td><code id="Get_log_det_S2_one_dim_+3A_delta_x">delta_x</code></td>
<td>
<p>a vector with dimension (num_obs-1) x 1 for the differences between the sorted input locations.</p>
</td></tr>
<tr><td><code id="Get_log_det_S2_one_dim_+3A_output">output</code></td>
<td>
<p>a  vector with dimension num_obs x 1 for the observations at the sorted input locations.</p>
</td></tr>
<tr><td><code id="Get_log_det_S2_one_dim_+3A_kernel_type">kernel_type</code></td>
<td>
<p>A <code>character</code> specifying the type of kernel.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list where the first value is the natural logarithm of the determinant of the correlation matrix and the second value is the estimated sum of squares.
</p>


<h3>Author(s)</h3>

<p>Hanmo Li [aut, cre],
  Yuedong Wang [aut],
  Mengyang Gu [aut]
</p>
<p>Maintainer: Hanmo Li &lt;hanmo@pstat.ucsb.edu&gt;
</p>


<h3>References</h3>

<p>Hartikainen, J. and Sarkka, S. (2010). <em>Kalman filtering and smoothing solutions to temporal gaussian process regression models</em>,  <em>Machine Learning for Signal Processing (MLSP), 2010 IEEE International Workshop</em>,  379-384.
</p>
<p>M. Gu, Y. Xu (2017), <em>Nonseparable Gaussian stochastic process: a unified
view and computational strategy</em>, arXiv:1711.11501.
</p>
<p>M. Gu, X. Wang and J.O. Berger (2018), <em>Robust Gaussian Stochastic Process Emulation</em>, <em>Annals of Statistics</em>, <b>46</b>, 3038-3066.
</p>

<hr>
<h2 id='get_LY_online'> Updating Kalman filter parameters
</h2><span id='topic+get_LY_online'></span>

<h3>Description</h3>

<p>Updating the Kalman filter parameters for Gaussian Process model with Matern 2.5 or power exponential kernels.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  get_LY_online(cur_input, prev_param, eta, G_W_W0_V)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_LY_online_+3A_cur_input">cur_input</code></td>
<td>
<p>A value of current observation.</p>
</td></tr>
<tr><td><code id="get_LY_online_+3A_prev_param">prev_param</code></td>
<td>
<p>A list of previous Kalman filter parameters.</p>
</td></tr>
<tr><td><code id="get_LY_online_+3A_eta">eta</code></td>
<td>
<p>The noise-to-signal ratio.</p>
</td></tr>
<tr><td><code id="get_LY_online_+3A_g_w_w0_v">G_W_W0_V</code></td>
<td>
<p>A list of the coefficient and conditional matrics for Gaussian Process(GP) model. It's the output from the function <code>Construct_G_W_W0_V</code> </p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>get_LY_online</code> returns a list of updated kalman filter parameters.
</p>


<h3>Author(s)</h3>

<p>Hanmo Li [aut, cre],
  Yuedong Wang [aut],
  Mengyang Gu [aut]
</p>
<p>Maintainer: Hanmo Li &lt;hanmo@pstat.ucsb.edu&gt;
</p>


<h3>References</h3>

<p>Fearnhead, P., &amp; Liu, Z. (2007). <em>On-line inference for multiple changepoint problem.</em> <em> Journal of the Royal Statistical Society: Series B (Statistical Methodology)</em>, 69(4), 589-605.
</p>
<p>Adams, R. P., &amp; MacKay, D. J. (2007). <em>Bayesian online changepoint detection.</em> <em>arXiv preprint</em> arXiv:0710.3742.
</p>
<p>Hartikainen, J. and Sarkka, S. (2010). <em>Kalman filtering and smoothing solutions to temporal gaussian process regression models</em>,  <em>Machine Learning for Signal Processing (MLSP), 2010 IEEE International Workshop</em>,  379-384.
</p>

<hr>
<h2 id='get_mu_sigma_hat'> 
Caculate the mean and variance parameter through fast computation
</h2><span id='topic+get_mu_sigma_hat'></span>

<h3>Description</h3>

<p>This function computes the estimtation of the mean and variance parameter through Kalamn filters for fast computations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_mu_sigma_hat(param, design, response, kernel_type)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_mu_sigma_hat_+3A_param">param</code></td>
<td>
<p>a vector of parameters. The first parameter is the natural logarithm of the inverse range parameter in the kernel function. If the data contain noise, the second parameter is the logarithm of the nugget-variance ratio parameter.</p>
</td></tr>
<tr><td><code id="get_mu_sigma_hat_+3A_design">design</code></td>
<td>
<p>A matrix with dimension n x p. The design of the experiment. </p>
</td></tr>
<tr><td><code id="get_mu_sigma_hat_+3A_response">response</code></td>
<td>
<p>A matrix with dimension n x q. The observations. </p>
</td></tr>
<tr><td><code id="get_mu_sigma_hat_+3A_kernel_type">kernel_type</code></td>
<td>
<p>A character specifying the type of kernels of the input. <code>matern_5_2</code> are <code>Matern correlation</code> with roughness parameter 5/2. <code>exp</code> is power exponential correlation with roughness parameter alpha=2. The default choice is <code>matern_5_2</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with the estimtation of the mean and variance parameter.
</p>


<h3>Author(s)</h3>

<p>Hanmo Li [aut, cre],
  Yuedong Wang [aut],
  Mengyang Gu [aut]
</p>
<p>Maintainer: Hanmo Li &lt;hanmo@pstat.ucsb.edu&gt;
</p>


<h3>References</h3>

<p>Hartikainen, J. and Sarkka, S. (2010). <em>Kalman filtering and smoothing solutions to temporal gaussian process regression models</em>,  <em>Machine Learning for Signal Processing (MLSP), 2010 IEEE International Workshop</em>,  379-384.
</p>
<p>M. Gu, Y. Xu (2017), <em>Nonseparable Gaussian stochastic process: a unified
view and computational strategy</em>, arXiv:1711.11501.
</p>
<p>M. Gu, X. Wang and J.O. Berger (2018), <em>Robust Gaussian Stochastic Process Emulation</em>, <em>Annals of Statistics</em>, <b>46</b>, 3038-3066.
</p>

<hr>
<h2 id='get_predictive_dist_direct_objective_prior'> Updating the predictive distribution
</h2><span id='topic+get_predictive_dist_direct_objective_prior'></span>

<h3>Description</h3>

<p>Updating the predictive distribution of the run length under the objective prior directly.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  get_predictive_dist_direct_objective_prior(cur_input_seq, d, gamma, mu, sigma_2, eta)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_predictive_dist_direct_objective_prior_+3A_cur_input_seq">cur_input_seq</code></td>
<td>
<p>A vector of sequence of observations.</p>
</td></tr>
<tr><td><code id="get_predictive_dist_direct_objective_prior_+3A_d">d</code></td>
<td>
<p>A value of the distance between the sorted input.</p>
</td></tr>
<tr><td><code id="get_predictive_dist_direct_objective_prior_+3A_gamma">gamma</code></td>
<td>
<p>A numeric variable of the range parameter for the covariance matrix. The default value of gamma is 1.</p>
</td></tr>
<tr><td><code id="get_predictive_dist_direct_objective_prior_+3A_eta">eta</code></td>
<td>
<p>A vector of the noise-to-signal ratio at each coordinate</p>
</td></tr>
<tr><td><code id="get_predictive_dist_direct_objective_prior_+3A_mu">mu</code></td>
<td>
<p>A vector of the mean parameter at each coordinate. Ignored when model_type = 0 or 2.</p>
</td></tr>
<tr><td><code id="get_predictive_dist_direct_objective_prior_+3A_sigma_2">sigma_2</code></td>
<td>
<p>A vector of the variance parameter at each coordinate.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>get_predictive_dist_direct_objective_prior</code> returns the log likelihood of observations that follows Gaussian Process with Exponential kernel.
</p>


<h3>Author(s)</h3>

<p>Hanmo Li [aut, cre],
  Yuedong Wang [aut],
  Mengyang Gu [aut]
</p>
<p>Maintainer: Hanmo Li &lt;hanmo@pstat.ucsb.edu&gt;
</p>


<h3>References</h3>

<p>Williams, C. K., &amp; Rasmussen, C. E. (2006). <em>Gaussian processes for machine learning (Vol. 2, No. 3, p. 4).</em> <em>Cambridge, MA: MIT press.</em>
</p>

<hr>
<h2 id='get_predictive_dist_KF_objective_prior'> Updating the predictive distribution
</h2><span id='topic+get_predictive_dist_KF_objective_prior'></span>

<h3>Description</h3>

<p>Updating the predictive distribution of the run length under the objective prior.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  get_predictive_dist_KF_objective_prior(cur_input, cur_num_obs,
  params, prev_L, d, gamma, model_type, mu, sigma_2, eta, kernel_type)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_predictive_dist_KF_objective_prior_+3A_cur_input">cur_input</code></td>
<td>
<p>A value of current observation.</p>
</td></tr>
<tr><td><code id="get_predictive_dist_KF_objective_prior_+3A_cur_num_obs">cur_num_obs</code></td>
<td>
<p>A value of index for the current observation.</p>
</td></tr>
<tr><td><code id="get_predictive_dist_KF_objective_prior_+3A_params">params</code></td>
<td>
<p>A list of current Kalman filter parameters.</p>
</td></tr>
<tr><td><code id="get_predictive_dist_KF_objective_prior_+3A_prev_l">prev_L</code></td>
<td>
<p>A list of previous Kalman filter parameters.</p>
</td></tr>
<tr><td><code id="get_predictive_dist_KF_objective_prior_+3A_d">d</code></td>
<td>
<p>A value of the distance between the sorted input.</p>
</td></tr>
<tr><td><code id="get_predictive_dist_KF_objective_prior_+3A_gamma">gamma</code></td>
<td>
<p>A numeric variable of the range parameter for the covariance matrix.</p>
</td></tr>
<tr><td><code id="get_predictive_dist_KF_objective_prior_+3A_model_type">model_type</code></td>
<td>
<p>A numeric variable that can take values of 0, 1 and 2. Model_type=0 stands for a GP model with unknown mean and known variance. Model_type=1 stands for a GP model with known mean and unknown variance. Model_type=2 stands for a GP model with unknown mean and unknown variance.</p>
</td></tr>
<tr><td><code id="get_predictive_dist_KF_objective_prior_+3A_mu">mu</code></td>
<td>
<p>A vector of the mean parameter at each coordinate. Ignored when model_type = 0 or 2.</p>
</td></tr>
<tr><td><code id="get_predictive_dist_KF_objective_prior_+3A_sigma_2">sigma_2</code></td>
<td>
<p>A vector of the variance parameter at each coordinate.</p>
</td></tr>
<tr><td><code id="get_predictive_dist_KF_objective_prior_+3A_eta">eta</code></td>
<td>
<p>A vector of the noise-to-signal ratio at each coordinate</p>
</td></tr>
<tr><td><code id="get_predictive_dist_KF_objective_prior_+3A_kernel_type">kernel_type</code></td>
<td>
<p>A character specifying the type of kernels of the input. <code>matern_5_2</code> are <code>Matern correlation</code> with roughness parameter 5/2. <code>exp</code> is power exponential correlation with roughness parameter alpha=2.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>get_predictive_dist_KF_objective_prior</code> returns a list of updated predictive distribution of the run length under the objective prior.
</p>


<h3>Author(s)</h3>

<p>Hanmo Li [aut, cre],
  Yuedong Wang [aut],
  Mengyang Gu [aut]
</p>
<p>Maintainer: Hanmo Li &lt;hanmo@pstat.ucsb.edu&gt;
</p>


<h3>References</h3>

<p>Fearnhead, P., &amp; Liu, Z. (2007). <em>On-line inference for multiple changepoint problem.</em> <em> Journal of the Royal Statistical Society: Series B (Statistical Methodology)</em>, 69(4), 589-605.
</p>
<p>Adams, R. P., &amp; MacKay, D. J. (2007). <em>Bayesian online changepoint detection.</em> <em>arXiv preprint</em> arXiv:0710.3742.
</p>
<p>Hartikainen, J. and Sarkka, S. (2010). <em>Kalman filtering and smoothing solutions to temporal gaussian process regression models</em>,  <em>Machine Learning for Signal Processing (MLSP), 2010 IEEE International Workshop</em>,  379-384.
</p>

<hr>
<h2 id='Get_Q_K'> 
matrices and vectors for the inverse covariance in the predictive distribution
</h2><span id='topic+Get_Q_K'></span>

<h3>Description</h3>

<p>This function computes the required values for the inverse covariance matrix. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Get_Q_K(GG,W,C0,VV)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Get_Q_K_+3A_gg">GG</code></td>
<td>
<p>a list of matrices defined in the dynamic linear model.</p>
</td></tr>
<tr><td><code id="Get_Q_K_+3A_w">W</code></td>
<td>
<p>a list of matrices defined in the dynamic linear model.</p>
</td></tr>
<tr><td><code id="Get_Q_K_+3A_c0">C0</code></td>
<td>
<p>a matrix defined in the dynamic linear model.</p>
</td></tr>
<tr><td><code id="Get_Q_K_+3A_vv">VV</code></td>
<td>
<p>a numerical value for the nugget.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of 2 items for Q and K. 
</p>


<h3>Author(s)</h3>

<p>Hanmo Li [aut, cre],
  Yuedong Wang [aut],
  Mengyang Gu [aut]
</p>
<p>Maintainer: Hanmo Li &lt;hanmo@pstat.ucsb.edu&gt;
</p>


<h3>References</h3>

<p>Hartikainen, J. and Sarkka, S. (2010). <em>Kalman filtering and smoothing solutions to temporal gaussian process regression models</em>.  <em>Machine Learning for Signal Processing (MLSP), 2010 IEEE International Workshop</em>,  379-384.
</p>
<p>M. Gu, Y. Xu (2019), <em>fast nonseparable gaussian stochastic process with application to methylation level interpolation</em>.  <em>Journal of Computational and Graphical Statistics</em>, In Press, arXiv:1711.11501.
</p>
<p>Campagnoli P, Petris G, Petrone S. (2009), <em>Dynamic linear model with R</em>. Springer-Verlag New York.
</p>

<hr>
<h2 id='KF_ini'> Getting inital Kalman filter parameters
</h2><span id='topic+KF_ini'></span>

<h3>Description</h3>

<p>Initialize the Kalman filter parameters for Gaussian Process model with Matern 2.5 or power exponential kernels.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  KF_ini(cur_input, d, gamma, eta, kernel_type, G_W_W0_V)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="KF_ini_+3A_cur_input">cur_input</code></td>
<td>
<p>A value of current observation.</p>
</td></tr>
<tr><td><code id="KF_ini_+3A_d">d</code></td>
<td>
<p>A value of the distance between the sorted input.</p>
</td></tr>
<tr><td><code id="KF_ini_+3A_gamma">gamma</code></td>
<td>
<p>A value of the range parameter for the covariance matrix.</p>
</td></tr>
<tr><td><code id="KF_ini_+3A_eta">eta</code></td>
<td>
<p>The noise-to-signal ratio.</p>
</td></tr>
<tr><td><code id="KF_ini_+3A_kernel_type">kernel_type</code></td>
<td>
<p>A character specifying the type of kernels of the input. <code>matern_5_2</code> are <code>Matern correlation</code> with roughness parameter 5/2. <code>exp</code> is power exponential correlation with roughness parameter alpha=2.</p>
</td></tr>
<tr><td><code id="KF_ini_+3A_g_w_w0_v">G_W_W0_V</code></td>
<td>
<p>A list of the coefficient and conditional matrics for Gaussian Process(GP) model. It's the output from the function <code>Construct_G_W_W0_V</code> </p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>KF_ini</code> returns a list of kalman filter parameters.
</p>


<h3>Author(s)</h3>

<p>Hanmo Li [aut, cre],
  Yuedong Wang [aut],
  Mengyang Gu [aut]
</p>
<p>Maintainer: Hanmo Li &lt;hanmo@pstat.ucsb.edu&gt;
</p>


<h3>References</h3>

<p>Fearnhead, P., &amp; Liu, Z. (2007). <em>On-line inference for multiple changepoint problem.</em> <em> Journal of the Royal Statistical Society: Series B (Statistical Methodology)</em>, 69(4), 589-605.
</p>
<p>Adams, R. P., &amp; MacKay, D. J. (2007). <em>Bayesian online changepoint detection.</em> <em>arXiv preprint</em> arXiv:0710.3742.
</p>
<p>Hartikainen, J. and Sarkka, S. (2010). <em>Kalman filtering and smoothing solutions to temporal gaussian process regression models</em>,  <em>Machine Learning for Signal Processing (MLSP), 2010 IEEE International Workshop</em>,  379-384.
</p>

<hr>
<h2 id='KF_ini_for_profile_like'> Getting inital Kalman filter parameters for different observation sequences
</h2><span id='topic+KF_ini_for_profile_like'></span>

<h3>Description</h3>

<p>Initialize the Kalman filter parameters for Gaussian Process model with Matern 2.5 or power exponential kernels with different observation sequences.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  KF_ini_for_profile_like(cur_input, d, gamma, eta, kernel_type, G_W_W0_V)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="KF_ini_for_profile_like_+3A_cur_input">cur_input</code></td>
<td>
<p>A value of current observation.</p>
</td></tr>
<tr><td><code id="KF_ini_for_profile_like_+3A_d">d</code></td>
<td>
<p>A value of the distance between the sorted input.</p>
</td></tr>
<tr><td><code id="KF_ini_for_profile_like_+3A_gamma">gamma</code></td>
<td>
<p>A value of the range parameter for the covariance matrix.</p>
</td></tr>
<tr><td><code id="KF_ini_for_profile_like_+3A_eta">eta</code></td>
<td>
<p>The noise-to-signal ratio.</p>
</td></tr>
<tr><td><code id="KF_ini_for_profile_like_+3A_kernel_type">kernel_type</code></td>
<td>
<p>A character specifying the type of kernels of the input. <code>matern_5_2</code> are <code>Matern correlation</code> with roughness parameter 5/2. <code>exp</code> is power exponential correlation with roughness parameter alpha=2.</p>
</td></tr>
<tr><td><code id="KF_ini_for_profile_like_+3A_g_w_w0_v">G_W_W0_V</code></td>
<td>
<p>A list of the coefficient and conditional matrics for Gaussian Process(GP) model. It's the output from the function <code>Construct_G_W_W0_V</code> </p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>KF_ini_for_profile_like</code> returns a list of kalman filter parameters with different observation sequences.
</p>


<h3>Author(s)</h3>

<p>Hanmo Li [aut, cre],
  Yuedong Wang [aut],
  Mengyang Gu [aut]
</p>
<p>Maintainer: Hanmo Li &lt;hanmo@pstat.ucsb.edu&gt;
</p>


<h3>References</h3>

<p>Fearnhead, P., &amp; Liu, Z. (2007). <em>On-line inference for multiple changepoint problem.</em> <em> Journal of the Royal Statistical Society: Series B (Statistical Methodology)</em>, 69(4), 589-605.
</p>
<p>Adams, R. P., &amp; MacKay, D. J. (2007). <em>Bayesian online changepoint detection.</em> <em>arXiv preprint</em> arXiv:0710.3742.
</p>
<p>Hartikainen, J. and Sarkka, S. (2010). <em>Kalman filtering and smoothing solutions to temporal gaussian process regression models</em>,  <em>Machine Learning for Signal Processing (MLSP), 2010 IEEE International Workshop</em>,  379-384.
</p>

<hr>
<h2 id='KF_param_update_for_profile_like'> Updating Kalman filter parameters
</h2><span id='topic+KF_param_update_for_profile_like'></span>

<h3>Description</h3>

<p>Updating the Kalman filter parameters for Gaussian Process model with Matern 2.5 or power exponential kernels with different observation sequences.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  KF_param_update_for_profile_like(cur_input, cur_num_obs,
  prev_param, d, gamma, eta, kernel_type, G_W_W0_V)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="KF_param_update_for_profile_like_+3A_cur_input">cur_input</code></td>
<td>
<p>A value of current observation.</p>
</td></tr>
<tr><td><code id="KF_param_update_for_profile_like_+3A_cur_num_obs">cur_num_obs</code></td>
<td>
<p>A value of index for the current observation.</p>
</td></tr>
<tr><td><code id="KF_param_update_for_profile_like_+3A_prev_param">prev_param</code></td>
<td>
<p>A list of previous Kalman filter parameters.</p>
</td></tr>
<tr><td><code id="KF_param_update_for_profile_like_+3A_d">d</code></td>
<td>
<p>A value of the distance between the sorted input.</p>
</td></tr>
<tr><td><code id="KF_param_update_for_profile_like_+3A_gamma">gamma</code></td>
<td>
<p>A value of the range parameter for the covariance matrix.</p>
</td></tr>
<tr><td><code id="KF_param_update_for_profile_like_+3A_eta">eta</code></td>
<td>
<p>The noise-to-signal ratio.</p>
</td></tr>
<tr><td><code id="KF_param_update_for_profile_like_+3A_kernel_type">kernel_type</code></td>
<td>
<p>A character specifying the type of kernels of the input. <code>matern_5_2</code> are <code>Matern correlation</code> with roughness parameter 5/2. <code>exp</code> is power exponential correlation with roughness parameter alpha=2.</p>
</td></tr>
<tr><td><code id="KF_param_update_for_profile_like_+3A_g_w_w0_v">G_W_W0_V</code></td>
<td>
<p>A list of the coefficient and conditional matrics for Gaussian Process(GP) model. It's the output from the function <code>Construct_G_W_W0_V</code> </p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>KF_param_update_for_profile_like</code> returns a list of updated kalman filter parameters with different observation sequences.
</p>


<h3>Author(s)</h3>

<p>Hanmo Li [aut, cre],
  Yuedong Wang [aut],
  Mengyang Gu [aut]
</p>
<p>Maintainer: Hanmo Li &lt;hanmo@pstat.ucsb.edu&gt;
</p>


<h3>References</h3>

<p>Fearnhead, P., &amp; Liu, Z. (2007). <em>On-line inference for multiple changepoint problem.</em> <em> Journal of the Royal Statistical Society: Series B (Statistical Methodology)</em>, 69(4), 589-605.
</p>
<p>Adams, R. P., &amp; MacKay, D. J. (2007). <em>Bayesian online changepoint detection.</em> <em>arXiv preprint</em> arXiv:0710.3742.
</p>
<p>Hartikainen, J. and Sarkka, S. (2010). <em>Kalman filtering and smoothing solutions to temporal gaussian process regression models</em>,  <em>Machine Learning for Signal Processing (MLSP), 2010 IEEE International Workshop</em>,  379-384.
</p>

<hr>
<h2 id='plot_SKFCPD'>
Plot for SKFCPD model
</h2><span id='topic+plot_SKFCPD'></span>

<h3>Description</h3>

<p>Function to make plots on SKFCPD models after the SKFCPD model has been constructed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot_SKFCPD(x, type = "cp")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot_SKFCPD_+3A_x">x</code></td>
<td>
<p> an object of  class <code>SKFCPD</code>.</p>
</td></tr>
<tr><td><code id="plot_SKFCPD_+3A_type">type</code></td>
<td>
<p>A character specifying the type of plot. <code>cp</code> plots the data with estimated changepoints marked in red crossings. <code>run_length_posterior</code> plots the matrix of run length posterior distribution.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Two plots: (1) plot of data with the red dashed lines mark the estimated changepoint locations, and (2) plot of the run length posterior distribution matrix. For multidimensional data, only the first dimension is plotted.
</p>


<h3>Author(s)</h3>

<p>Hanmo Li [aut, cre],
  Yuedong Wang [aut],
  Mengyang Gu [aut]
</p>
<p>Maintainer: Hanmo Li &lt;hanmo@pstat.ucsb.edu&gt;
</p>


<h3>References</h3>

<p>Li, Hanmo, Yuedong Wang, and Mengyang Gu. <em>Sequential Kalman filter for fast online changepoint detection in longitudinal health records.</em> arXiv preprint arXiv:2310.18611 (2023).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  library(SKFCPD)
  
  #------------------------------------------------------------------------------
  # Example: fast online changepoint detection with DEPENDENT data.
  # 
  # Data generation: Data follows a multidimensional Gaussian process with Matern 2.5 kernel.
  #------------------------------------------------------------------------------
  # Data Generation
  set.seed(1)
  
  n_obs = 150
  n_dim = 2
  seg_len = c(70, 30, 20,30)
  mean_each_seg = c(0,1,-1,0)
  
  x_mat=matrix(1:n_obs)
  y_mat=matrix(NA, nrow=n_obs, ncol=n_dim)
  
  gamma = rep(5, n_dim) # range parameter of the covariance matrix
  
  # compute the matern 2.5 kernel
  construct_cor_matrix = function(input, gamma){
    n = length(input)
    R0=abs(outer(input,(input),'-'))
    matrix_one = matrix(1, n, n)
    const = sqrt(5) * R0 / gamma
    Sigma = (matrix_one + const + const^2/3) * (exp(-const))
    return(Sigma)
  }
  
  for(j in 1:n_dim){
    y_each_dim = c()
    for(i in 1:length(seg_len)){
      nobs_per_seg = seg_len[i]
      Sigma = construct_cor_matrix(1:nobs_per_seg, gamma[j])
      L=t(chol(Sigma))
      theta=rep(mean_each_seg[i],nobs_per_seg)+L%*%rnorm(nobs_per_seg)
      y_each_dim = c(y_each_dim, theta+0.1*rnorm(nobs_per_seg))
    }
    y_mat[,j] = y_each_dim
  }
  
  ## Detect changepoints by SKFCPD
  Online_CPD_1 = SKFCPD(design = x_mat,
                        response = y_mat,
                        train_prop = 1/3)
  
  ## visulize the results
  plot_SKFCPD(Online_CPD_1)
</code></pre>

<hr>
<h2 id='productPowerMinusHalf'> 
Square root of product for every elements in a vector
</h2><span id='topic+productPowerMinusHalf'></span>

<h3>Description</h3>

<p>This function computes Square root of product for every elements in a vector.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>productPowerMinusHalf(vec)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="productPowerMinusHalf_+3A_vec">vec</code></td>
<td>
<p>A input vector.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The square root of product for every elements in a vector
</p>


<h3>Author(s)</h3>

<p>Hanmo Li [aut, cre],
  Yuedong Wang [aut],
  Mengyang Gu [aut]
</p>
<p>Maintainer: Hanmo Li &lt;hanmo@pstat.ucsb.edu&gt;
</p>

<hr>
<h2 id='SKFCPD'> Getting the results of the SKFCPD model
</h2><span id='topic+SKFCPD'></span>

<h3>Description</h3>

<p>Estimating changepoint locations using the Dynamic Linear Model (DLM) within the Bayesian Online Changepoint Detection (BOCPD) framework. The efficient computation is achieved through implementation of the Kalman filter. The range parameter and noise-to-signal ratio are estimated from training samples via a Gaussian process model. This function is capable of handling multidimensional data with temporal correlations and random missing patterns.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  SKFCPD(design = NULL, response = NULL, FCPD = NULL, 
  init_params = list(gamma = 1, sigma_2 = 1, eta = 1), 
  train_prop = NULL, kernel_type = "matern_5_2", 
  hazard_vec=100, print_info = TRUE, truncate_at_prev_cp = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SKFCPD_+3A_design">design</code></td>
<td>
<p>A vector with the length of n. The design of the experiment. </p>
</td></tr>
<tr><td><code id="SKFCPD_+3A_response">response</code></td>
<td>
<p>A matrix with dimension n x q. The observations. </p>
</td></tr>
<tr><td><code id="SKFCPD_+3A_fcpd">FCPD</code></td>
<td>
<p>An object of the class <code>SKFCPD</code> computed in the previous run of the algorithm.</p>
</td></tr>
<tr><td><code id="SKFCPD_+3A_init_params">init_params</code></td>
<td>
<p>A list with estimated range parameter <code>gamma</code>, noise-to-signal parameter <code>eta</code> and variance parameter <code>sigma_2</code>. The default values are <code>gamma</code>=1, <code>eta</code>=1, and <code>sigma_2</code>=1.</p>
</td></tr>
<tr><td><code id="SKFCPD_+3A_train_prop">train_prop</code></td>
<td>
<p>A numerical value between 0 and 1. The propotation of training samples for parameter estimation. When <code>train_prop</code>=NULL, we skip the training process and specify the parameter values in the argument <code>init_params</code>.</p>
</td></tr>
<tr><td><code id="SKFCPD_+3A_kernel_type">kernel_type</code></td>
<td>
<p>A character specifying the type of kernels of the input. <code>matern_5_2</code> are Matern correlation with roughness parameter 5/2. <code>exp</code> is power exponential correlation with roughness parameter alpha=2. The default choice is <code>matern_5_2</code>.</p>
</td></tr>
<tr><td><code id="SKFCPD_+3A_hazard_vec">hazard_vec</code></td>
<td>
<p>Either a constant or a vector with the length of n. The hazard vector in the SKFCPD method. hazard_vec = 1/<code>hazard_const</code> is the prior probability that a changepoint occur at any time points. The default value of hazard_vec is 100. </p>
</td></tr>
<tr><td><code id="SKFCPD_+3A_print_info">print_info</code></td>
<td>
<p>This setting prints out updates on the progress of the algorithm if set to TRUE.</p>
</td></tr>
<tr><td><code id="SKFCPD_+3A_truncate_at_prev_cp">truncate_at_prev_cp</code></td>
<td>
<p>If TRUE, truncate the run length at the most recently detected changepoint. The default value of truncate_at_prev_cp is FALSE.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>SKFCPD</code> returns a S4 object of class <code>SKFCPD</code> (see <code>SKFCPD-class</code>).
</p>


<h3>Author(s)</h3>

<p>Hanmo Li [aut, cre],
  Yuedong Wang [aut],
  Mengyang Gu [aut]
</p>
<p>Maintainer: Hanmo Li &lt;hanmo@pstat.ucsb.edu&gt;
</p>


<h3>References</h3>

<p>Li, Hanmo, Yuedong Wang, and Mengyang Gu. <em>Sequential Kalman filter for fast online changepoint detection in longitudinal health records.</em> arXiv preprint arXiv:2310.18611 (2023).
</p>
<p>Fearnhead, Paul, and Zhen Liu. <em>On-line inference for multiple changepoint problems.</em> Journal of the Royal Statistical Society Series B: Statistical Methodology 69, no. 4 (2007): 589-605.
</p>
<p>Adams, Ryan Prescott, and David JC MacKay. <em>Bayesian online changepoint detection.</em> arXiv preprint arXiv:0710.3742 (2007).
</p>
<p>Hartikainen, Jouni, and Simo Sarkka. <em>Kalman filtering and smoothing solutions to temporal Gaussian process regression models.</em> In 2010 IEEE international workshop on machine learning for signal processing, pp. 379-384. IEEE, 2010.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  library(SKFCPD)
  
  #------------------------------------------------------------------------------
  # Example: fast online changepoint detection with DEPENDENT data.
  # 
  # Data generation: Data follows a multidimensional Gaussian process with Matern 2.5 kernel.
  #------------------------------------------------------------------------------
  # Data Generation
  set.seed(1)
  
  n_obs = 150
  n_dim = 2
  seg_len = c(70, 30, 20,30)
  mean_each_seg = c(0,1,-1,0)
  
  x_mat=matrix(1:n_obs)
  y_mat=matrix(NA, nrow=n_obs, ncol=n_dim)
  
  gamma = rep(5, n_dim) # range parameter of the covariance matrix
  
  # compute the matern 2.5 kernel
  construct_cor_matrix = function(input, gamma){
    n = length(input)
    R0=abs(outer(input,(input),'-'))
    matrix_one = matrix(1, n, n)
    const = sqrt(5) * R0 / gamma
    Sigma = (matrix_one + const + const^2/3) * (exp(-const))
    return(Sigma)
  }
  
  for(j in 1:n_dim){
    y_each_dim = c()
    for(i in 1:length(seg_len)){
      nobs_per_seg = seg_len[i]
      Sigma = construct_cor_matrix(1:nobs_per_seg, gamma[j])
      L=t(chol(Sigma))
      theta=rep(mean_each_seg[i],nobs_per_seg)+L%*%rnorm(nobs_per_seg)
      y_each_dim = c(y_each_dim, theta+0.1*rnorm(nobs_per_seg))
    }
    y_mat[,j] = y_each_dim
  }
  
  ## Detect changepoints by SKFCPD
  Online_CPD_1 = SKFCPD(design = x_mat,
                        response = y_mat,
                        train_prop = 1/3)
  
  ## visulize the results
  plot_SKFCPD(Online_CPD_1)
</code></pre>

<hr>
<h2 id='SKFCPD-class'>Class <code>"SKFCPD"</code></h2><span id='topic+SKFCPD-class'></span>

<h3>Description</h3>

<p>S4 class for SKFCPD where the range parameter and noise-to-signal parameters are estimated from the training samples.
</p>


<h3>Objects from the Class</h3>

<p>Objects of this class are created and initialized with the function <code><a href="#topic+SKFCPD">SKFCPD</a></code> that computes the calculations needed for setting up the analysis.
</p>


<h3>Slots</h3>


<dl>
<dt><code>design</code>:</dt><dd><p>Object of class <code>"matrix"</code> with dimension n x p. The design of the experiment. </p>
</dd>
<dt><code>response</code>:</dt><dd><p>Object of class <code>"matrix"</code> with dimension n x q. The observations. </p>
</dd>
<dt><code>test_start</code>:</dt><dd><p>Object of class <code>"numeric"</code>. The starting index of test period.</p>
</dd>
<dt><code>kernel_type</code>:</dt><dd><p>Object of class <code>"character"</code> to specify the type of kernel to use. </p>
</dd>
<dt><code>gamma</code>:</dt><dd><p>Object of class <code>"vector"</code> with dimension q x 1. The range parameters. </p>
</dd>
<dt><code>eta</code>:</dt><dd><p>Object of class <code>"vector"</code> with dimension q x 1. The noise-to-signal ratio. </p>
</dd>
<dt><code>sigma_2</code>:</dt><dd><p>Object of class <code>"vector"</code> with dimension q x 1. The variance parameters. </p>
</dd>
<dt><code>hazard_vec</code>:</dt><dd><p>Object of class <code>"numeric"</code>. The n x 1 hazard vector in the FastCPD method. </p>
</dd>
<dt><code>KF_params_list</code>:</dt><dd><p>Object of class <code>"list"</code>. The list of Kalman filter parameters from the previous run of the algorithm. </p>
</dd>
<dt><code>prev_L_params_list</code>:</dt><dd><p>Object of class <code>"list"</code>. The list of parameters for calculating the quadratic form of the inverse covariance matrix from the previous run of the algorithm. </p>
</dd>
<dt><code>run_length_posterior_mat</code>:</dt><dd><p>Object of class <code>"matrix"</code> with dimension n x n. The posterior distribution of the run length. </p>
</dd>
<dt><code>run_length_joint_mat</code>:</dt><dd><p>Object of class <code>"matrix"</code> with dimension n x n. The joint distribution of the run length and the observations. </p>
</dd>
<dt><code>log_pred_dist_mat</code>:</dt><dd><p>Object of class <code>"matrix"</code> with dimension n x n. The logrithm of the predictive distribution of observations. </p>
</dd>
<dt><code>cp</code>:</dt><dd><p>Object of class <code>"vector"</code> with length m. The location of estimated changepoints.</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Hanmo Li [aut, cre],
  Yuedong Wang [aut],
  Mengyang Gu [aut]
</p>
<p>Maintainer: Hanmo Li &lt;hanmo@pstat.ucsb.edu&gt;
</p>


<h3>References</h3>

<p>Li, Hanmo, Yuedong Wang, and Mengyang Gu. <em>Sequential Kalman filter for fast online changepoint detection in longitudinal health records.</em> arXiv preprint arXiv:2310.18611 (2023).
</p>
<p>Fearnhead, Paul, and Zhen Liu. <em>On-line inference for multiple changepoint problems.</em> Journal of the Royal Statistical Society Series B: Statistical Methodology 69, no. 4 (2007): 589-605.
</p>
<p>Adams, Ryan Prescott, and David JC MacKay. <em>Bayesian online changepoint detection.</em> arXiv preprint arXiv:0710.3742 (2007).
</p>
<p>Hartikainen, Jouni, and Simo Sarkka. <em>Kalman filtering and smoothing solutions to temporal Gaussian process regression models.</em> In 2010 IEEE international workshop on machine learning for signal processing, pp. 379-384. IEEE, 2010.
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+SKFCPD">SKFCPD</a></code> for more details about how to create a <code>SKFCPD</code> object.
</p>

<hr>
<h2 id='SKFCPD-package'>
Dynamic Linear Model for Online Changepoint Detection
</h2><span id='topic+SKFCPD-package'></span>

<h3>Description</h3>

<p>The 'SKFCPD' package provides estimation of changepoint locations using the Dynamic Linear Model (DLM) within the Bayesian Online Changepoint Detection (BOCPD) framework. The efficient computation is achieved through implementation of the Sequential Kalman filter. The range parameter and noise-to-signal ratio are estimated from training samples via a Gaussian process model. This package is capable of handling multidimensional data with temporal correlations and random missing patterns.
</p>


<h3>Details</h3>

<p>The DESCRIPTION file:
</p>

<table>
<tr>
 <td style="text-align: left;">
Package: </td><td style="text-align: left;"> SKFCPD</td>
</tr>
<tr>
 <td style="text-align: left;">
Type: </td><td style="text-align: left;"> Package</td>
</tr>
<tr>
 <td style="text-align: left;">
Title: </td><td style="text-align: left;"> Fast Online Changepoint Detection for Temporally Correlated Data</td>
</tr>
<tr>
 <td style="text-align: left;">
Version: </td><td style="text-align: left;"> 0.2.4</td>
</tr>
<tr>
 <td style="text-align: left;">
Date: </td><td style="text-align: left;"> 2024-02-15</td>
</tr>
<tr>
 <td style="text-align: left;">
Authors@R: </td><td style="text-align: left;"> c(person(given="Hanmo",family="Li",role=c("aut", "cre"),
    email="hanmo@pstat.ucsb.edu"), 
    person(given="Yuedong",family="Wang", role=c("aut"),
    email="yuedong@pstat.ucsb.edu"),
    person(given="Mengyang",family="Gu", role=c("aut"),
    email="mengyang@pstat.ucsb.edu"))</td>
</tr>
<tr>
 <td style="text-align: left;">
Maintainer: </td><td style="text-align: left;"> Hanmo Li &lt;hanmo@pstat.ucsb.edu&gt;</td>
</tr>
<tr>
 <td style="text-align: left;">
Author: </td><td style="text-align: left;"> Hanmo Li [aut, cre],
  Yuedong Wang [aut],
  Mengyang Gu [aut]</td>
</tr>
<tr>
 <td style="text-align: left;">
Description: </td><td style="text-align: left;"> Sequential Kalman filter for scalable online changepoint detection by temporally correlated data. It enables fast single and multiple change points with missing values. See the reference: Hanmo Li, Yuedong Wang, Mengyang Gu (2023), &lt;arXiv:2310.18611&gt;.</td>
</tr>
<tr>
 <td style="text-align: left;">
License: </td><td style="text-align: left;"> GPL (&gt;= 3)</td>
</tr>
<tr>
 <td style="text-align: left;">
Depends: </td><td style="text-align: left;"> R (&gt;= 3.5.0), methods (&gt;= 4.2.2), rlang (&gt;= 1.0.6), ggplot2
(&gt;= 3.4.0), ggpubr (&gt;= 0.5.0), reshape2 (&gt;= 1.4.4), FastGaSP
(&gt;= 0.5.2)</td>
</tr>
<tr>
 <td style="text-align: left;">
Imports: </td><td style="text-align: left;"> Rcpp (&gt;= 1.0.9)</td>
</tr>
<tr>
 <td style="text-align: left;">
LinkingTo: </td><td style="text-align: left;"> Rcpp, RcppEigen</td>
</tr>
<tr>
 <td style="text-align: left;">
NeedsCompilation: </td><td style="text-align: left;"> yes</td>
</tr>
<tr>
 <td style="text-align: left;">
Encoding: </td><td style="text-align: left;"> UTF-8</td>
</tr>
<tr>
 <td style="text-align: left;">
Packaged: </td><td style="text-align: left;"> 2024-02-15 11:15:56 UTC; lihan</td>
</tr>
<tr>
 <td style="text-align: left;">
Archs: </td><td style="text-align: left;"> x64</td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>


<p>Index of help topics:
</p>
<pre>
Estimate_GP_params      Estimate parameters from fast computation of
                        GaSP model
SKFCPD                  Getting the results of the SKFCPD model
SKFCPD-class            Class '"SKFCPD"'
SKFCPD-package          Dynamic Linear Model for Online Changepoint
                        Detection
plot_SKFCPD             Plot for SKFCPD model
</pre>
<p>Implements a fast online changepoint detection algorithm using dynamic linear model based on Sequential Kalman filter. It's for temporally correlated data and accepts multi-dimensional datasets with missing values.
</p>


<h3>Author(s)</h3>

<p>Hanmo Li [aut, cre],
  Yuedong Wang [aut],
  Mengyang Gu [aut]
</p>
<p>Maintainer: Hanmo Li &lt;hanmo@pstat.ucsb.edu&gt;
</p>


<h3>References</h3>

<p>Li, Hanmo, Yuedong Wang, and Mengyang Gu. <em>Sequential Kalman filter for fast online changepoint detection in longitudinal health records.</em> arXiv preprint arXiv:2310.18611 (2023).
</p>
<p>Fearnhead, Paul, and Zhen Liu. <em>On-line inference for multiple changepoint problems.</em> Journal of the Royal Statistical Society Series B: Statistical Methodology 69, no. 4 (2007): 589-605.
</p>
<p>Adams, Ryan Prescott, and David JC MacKay. <em>Bayesian online changepoint detection.</em> arXiv preprint arXiv:0710.3742 (2007).
</p>
<p>Hartikainen, Jouni, and Simo Sarkka. <em>Kalman filtering and smoothing solutions to temporal Gaussian process regression models.</em> In 2010 IEEE international workshop on machine learning for signal processing, pp. 379-384. IEEE, 2010.
</p>
<p>Gu, Mengyang, and Yanxun Xu. <em>Fast nonseparable Gaussian stochastic process with application to methylation level interpolation.</em> Journal of Computational and Graphical Statistics 29, no. 2 (2020): 250-260.
</p>
<p>Gu, Mengyang, and Weining Shen. <em>Generalized probabilistic principal component analysis of correlated data.</em> The Journal of Machine Learning Research 21, no. 1 (2020): 428-468.
</p>
<p>Gu, Mengyang, Xiaojing Wang, and James O. Berger. <em>Robust Gaussian stochastic process emulation.</em> The Annals of Statistics 46, no. 6A (2018): 3038-3066.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+SKFCPD">SKFCPD</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  library(SKFCPD)
  
  #------------------------------------------------------------------------------
  # Example: fast online changepoint detection with DEPENDENT data.
  # 
  # Data generation: Data follows a multidimensional Gaussian process with Matern 2.5 kernel.
  #------------------------------------------------------------------------------
  # Data Generation
  set.seed(1)
  
  n_obs = 150
  n_dim = 2
  seg_len = c(70, 30, 20,30)
  mean_each_seg = c(0,1,-1,0)
  
  x_mat=matrix(1:n_obs)
  y_mat=matrix(NA, nrow=n_obs, ncol=n_dim)
  
  gamma = rep(5, n_dim) # range parameter of the covariance matrix
  
  # compute the matern 2.5 kernel
  construct_cor_matrix = function(input, gamma){
    n = length(input)
    R0=abs(outer(input,(input),'-'))
    matrix_one = matrix(1, n, n)
    const = sqrt(5) * R0 / gamma
    Sigma = (matrix_one + const + const^2/3) * (exp(-const))
    return(Sigma)
  }
  
  for(j in 1:n_dim){
    y_each_dim = c()
    for(i in 1:length(seg_len)){
      nobs_per_seg = seg_len[i]
      Sigma = construct_cor_matrix(1:nobs_per_seg, gamma[j])
      L=t(chol(Sigma))
      theta=rep(mean_each_seg[i],nobs_per_seg)+L%*%rnorm(nobs_per_seg)
      y_each_dim = c(y_each_dim, theta+0.1*rnorm(nobs_per_seg))
    }
    y_mat[,j] = y_each_dim
  }
  
  ## Detect changepoints by SKFCPD
  Online_CPD_1 = SKFCPD(design = x_mat,
                        response = y_mat,
                        train_prop = 1/3)
  
  ## visulize the results
  plot_SKFCPD(Online_CPD_1)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
