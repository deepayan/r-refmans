<!DOCTYPE html><html><head><title>Help for package plfm</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {plfm}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#anger'><p>Situational determinants of anger-related behavior</p></a></li>
<li><a href='#anger2'><p>Situational determinants of anger-related behavior</p></a></li>
<li><a href='#bayesplfm'><p>Bayesian analysis of probabilistic latent feature models for two-way two-mode frequency data</p></a></li>
<li><a href='#car'><p>Ratings of associations between car models and car attributes</p></a></li>
<li><a href='#car2'><p>Judgements on associations between car models and car attributes</p></a></li>
<li><a href='#gendat'><p>Data generation</p></a></li>
<li><a href='#gendatLCplfm'><p>Data generation</p></a></li>
<li><a href='#hostility'><p>self-reported hostile behavior in frustrating situations</p></a></li>
<li><a href='#LCplfm'><p>Latent class probabilistic feature analysis of three-way three-mode binary data</p></a></li>
<li><a href='#plfm'><p>Probabilistic latent feature analysis of two-way two-mode frequency data</p></a></li>
<li><a href='#plfm-package'><p>Probabilistic Latent Feature Analysis</p></a></li>
<li><a href='#plot.LCplfm'><p>plot parameters in <code>LCplfm</code> object</p></a></li>
<li><a href='#plot.plfm'><p>plot parameters in <code>plfm</code> object</p></a></li>
<li><a href='#plot.stepLCplfm'><p>Plot fit of <code>stepLCplfm</code> objects</p></a></li>
<li><a href='#plot.stepplfm'><p>Plot fit of <code>stepplfm</code> objects</p></a></li>
<li><a href='#print.bayesplfm'><p>Printing  <code>bayesplfm</code> objects</p></a></li>
<li><a href='#print.LCplfm'><p>Printing LCplfm objects</p></a></li>
<li><a href='#print.plfm'><p>Printing plfm objects</p></a></li>
<li><a href='#print.stepLCplfm'><p>Printing <code>stepLCplfm</code> objects</p></a></li>
<li><a href='#print.stepplfm'><p>Printing <code>stepplfm</code> objects</p></a></li>
<li><a href='#print.summary.bayesplfm'><p>Printing summaries of Bayesian probabilistic latent feature analysis</p></a></li>
<li><a href='#print.summary.plfm'><p>Printing summaries of probabilistic latent feature analysis objects</p></a></li>
<li><a href='#print.summary.stepLCplfm'><p>Printing summaries of <code>stepLCplfm</code> objects</p></a></li>
<li><a href='#print.summary.stepplfm'><p>Printing summaries of <code>stepplfm</code> objects</p></a></li>
<li><a href='#stepLCplfm'><p>Latent class probabilistic latent feature analysis of three-way three-mode binary data</p></a></li>
<li><a href='#stepplfm'><p>Probabilistic latent feature analysis of two-way two-mode frequency data</p></a></li>
<li><a href='#summary.bayesplfm'>
<p>Summarizing Bayesian probabilistic latent feature analysis</p></a></li>
<li><a href='#summary.plfm'><p>Summarizing probabilistic latent feature analysis</p></a></li>
<li><a href='#summary.stepLCplfm'><p>Summary method for <code>stepLCplfm</code> objects</p></a></li>
<li><a href='#summary.stepplfm'><p>Summary method for <code>stepplfm</code> objects</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Probabilistic Latent Feature Analysis</td>
</tr>
<tr>
<td>Version:</td>
<td>2.2.6</td>
</tr>
<tr>
<td>Date:</td>
<td>2024-02-14</td>
</tr>
<tr>
<td>Author:</td>
<td>Michel Meulders [aut, cre],
  Philippe De Bruecker [ctb]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Michel Meulders &lt;michel.meulders@kuleuven.be&gt;</td>
</tr>
<tr>
<td>Depends:</td>
<td>sfsmisc, abind</td>
</tr>
<tr>
<td>Description:</td>
<td>Functions for estimating probabilistic latent feature models with a disjunctive, conjunctive or additive mapping rule on (aggregated) binary three-way data.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>LazyLoad:</td>
<td>yes</td>
</tr>
<tr>
<td>LazyData:</td>
<td>yes</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-02-14 19:54:37 UTC; u0010822</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-02-15 00:40:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='anger'>Situational determinants of anger-related behavior</h2><span id='topic+anger'></span>

<h3>Description</h3>

<p>The raw data consist of the binary judgments of 101 first-year psychology students who indicated whether or not they would display 
each of 8 anger-related behaviors when being angry at someone in each of 6 situations. 
The 8 behaviors consist of 4 pairs of reactions that reflect a particular strategy to deal with situations in which 
one is angry at someone, namely, (1) fighting (fly off the handle, quarrel), 
(2) fleeing (leave, avoid), (3) emotional sharing (pour out one's heart, tell one's story), 
and (4) making up (make up, clear up the matter). 
The six situations are constructed from two factors  with three levels: 
(1) the extent to which one likes the  instigator of anger (like, dislike, unfamiliar), 
and (2) the status of the instigator of anger (higher, lower, equal). 
Each situation is presented as one level of a factor, 
without specifying a level for the other factor.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(anger)</code></pre>


<h3>Format</h3>

<p>The data consist of a list of 5 objects:
</p>

<ol>
<li><p> freq1: A 6 X 8 matrix of frequencies. The frequency in cell <em>(j,k)</em> indicates how many of 101 respondents 
would display reaction  <em>k</em> in situation <em>j</em>.
</p>
</li>
<li><p> freqtot: A 6 X 8 matrix of frequencies. The frequency in cell <em>(j,k)</em> indicates the total number of respondents 
who judged the situation-response pair <em>(j,k)</em>.
</p>
</li>
<li><p> rowlabels: A vector of labels for the situations.
</p>
</li>
<li><p> columnlabels: A vector of labels for the anger-related reactions.
</p>
</li>
<li><p> data: A 101 X 6 X 8 array of binary (0/1) values. the value in cell <em>(i,j,k)</em> equals 1 if
person <em>i</em> would display behavior <em>k</em> in situation <em>j</em>, and 0 otherwise.
</p>
</li></ol>



<h3>Source</h3>

<p>Meulders, M., De Boeck, P., Kuppens, P., and Van Mechelen, I. (2002). Constrained latent
class analysis of three-way three-mode data. <em>Journal of Classification, 19</em>, 277-302.
</p>


<h3>References</h3>

<p>Kuppens, P., Van Mechelen, I., and Meulders, M. (2004). Every cloud has a silver lining: 
Interpersonal and individual differences determinants of anger-related behaviors. <em>Personality and Social Psychology Bulletin, 30</em>, 1550-1564. 
</p>
<p>Meulders, M. (2013). An R Package for Probabilistic Latent Feature Analysis of Two-Way Two-Mode Frequencies. <em>Journal of Statistical Software, 54(14)</em>, 1-29. 
URL http://www.jstatsoft.org/v54/i14/.
</p>
<p>Vermunt, J. K. (2007). A hierarchical mixture model for clustering three-way data
sets. <em>Computational Statistics and Data Analysis, 51</em>, 5368-5376.
</p>

<hr>
<h2 id='anger2'>Situational determinants of anger-related behavior</h2><span id='topic+anger2'></span>

<h3>Description</h3>

<p>The raw data consist of the binary judgments of 115 first-year psychology students who indicated whether or not they would display 
each of 14 anger-related behaviors when being angry at someone in each of 9 situations. 
The 14 behaviors consist of 7 pairs of reactions that reflect a particular strategy to deal with situations in which 
one is angry at someone:
</p>

<ol>
<li><p> Anger-out: (a) You flew off the handle, (b) You started a fight
</p>
</li>
<li><p> Avoidance: (a) You avoided a confrontation, (b) You went out of the other's way
</p>
</li>
<li><p> Social sharing (a) You unburdened your heart to others, (b) You told others what had happened 
</p>
</li>
<li><p> Assertive behavior: (a) You said what was bothering you in a direct and sober way, (b) You calmly explained what was bothering you 
</p>
</li>
<li><p> Indirect behavior (a) You showed something was bothering you without saying anything, (b) You started to sulk 
</p>
</li>
<li><p> Anger-in: (a) You suppressed your anger, (b) You bottled up your anger 
</p>
</li>
<li><p> Reconciliation (a) You reconciled, (b) You talked things out</p>
</li></ol>

<p>The six situations are constructed by crossing the levels of two factors  with three levels: 
(1) the extent to which one likes the  instigator of anger (like, unfamilar, dislike), 
and (2) the status of the instigator of anger (lower status, equal status, higher status)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(anger2)</code></pre>


<h3>Format</h3>

<p>The data consist of a list of 5 objects:
</p>

<ol>
<li><p> data: A 115 X 9 X 14 matrix of binary observations (0/1). The observation in cell <em>(i,j,k)</em> equals 1 if person <em>i</em> would display behavior
<em>k</em> in situation <em>j</em> and 0 otherwise.
</p>
</li>
<li><p> freq1: A 9 X 14 matrix of frequencies. The frequency in cell <em>(j,k)</em> indicates the number of respondents 
who indicate that they would display behavior <em>k</em> in situation <em>j</em>.
</p>
</li>
<li><p> freqtot: A 9 X 14 matrix of frequencies. The frequency in cell <em>(j,k)</em> indicates the total number of respondents 
who judged the situation-response pair <em>(j,k)</em>.
</p>
</li>
<li><p> rowlabels: A vector of labels for the situations.
</p>
</li>
<li><p> columnlabels: A vector of labels for the anger-related behaviors.
</p>
</li></ol>



<h3>Source</h3>

<p>Kuppens, P., Van Mechelen, I., and Meulders, M. (2004). Every cloud has a silver lining: 
Interpersonal and individual differences determinants of anger-related behaviors. <em>Personality and Social Psychology Bulletin, 30</em>, 1550-1564.</p>


<h3>References</h3>

<p>Meulders, M. and De Bruecker, P. (2018). Latent class probabilistic latent feature analysis of three-way three-mode binary data. 
<em>Journal of Statistical Software, 87(1), 1-45</em>, 1-29.
</p>

<hr>
<h2 id='bayesplfm'>Bayesian analysis of probabilistic latent feature models for two-way two-mode frequency data</h2><span id='topic+bayesplfm'></span>

<h3>Description</h3>

<p>Computation of a sample of the posterior distribution for disjunctive or conjunctive probabilistic latent feature models with <em>F</em> features.</p>


<h3>Usage</h3>

<pre><code class='language-R'>bayesplfm(data,object,attribute,rating,freq1,freqtot,F,
          Nchains=2,Nburnin=0,maxNiter=4000,
          Nstep=1000,Rhatcrit=1.2,maprule="disj",datatype="freq",
          start.bayes="best",fitted.plfm=NULL)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bayesplfm_+3A_data">data</code></td>
<td>
<p> A data frame that consists of three components: the variables 
<code>object</code>, <code>attribute</code> and <code>rating</code>. Each row of the data frame describes the outcome of a binary rater judgement
about the association between a certain object and a certain attribute.</p>
</td></tr> 
<tr><td><code id="bayesplfm_+3A_object">object</code></td>
<td>
<p>The name of the <code>object</code> component in the data frame <code>data</code>. The values of the vector <code>data$object</code> should be (non-missing) numeric or character values.</p>
</td></tr>
<tr><td><code id="bayesplfm_+3A_attribute">attribute</code></td>
<td>
<p>The name of the <code>attribute</code> component in the data frame <code>data</code>. The values of the vector <code>data$attribute</code> should be (non-missing) numeric or character values.</p>
</td></tr>
<tr><td><code id="bayesplfm_+3A_rating">rating</code></td>
<td>
<p>The name of the <code>rating</code> component in the data frame <code>data</code>. The elements of the vector <code>data$rating</code> should be the numeric values 0 (no association) or 1 (association), 
or should be specified as missing (NA).</p>
</td></tr>
<tr><td><code id="bayesplfm_+3A_freq1">freq1</code></td>
<td>
<p>A <em>J X K</em> matrix of observed association frequencies.</p>
</td></tr>
<tr><td><code id="bayesplfm_+3A_freqtot">freqtot</code></td>
<td>
<p>A <em>J X K</em> matrix with the total number of binary ratings in each cell <em>(j,k)</em>. If the total number of ratings is the same for all cells of the matrix 
it is sufficient to enter a single numeric value rather than a matrix. For instance, if <em>N</em> raters have judged <em>J X K</em> associations, one may specify <code>freqtot</code><em>=N</em></p>
</td></tr>
<tr><td><code id="bayesplfm_+3A_f">F</code></td>
<td>
<p>The number of latent features included in the model.</p>
</td></tr>  
<tr><td><code id="bayesplfm_+3A_nchains">Nchains</code></td>
<td>
<p>The number of Markov-chains that are simulated using a data-augmented Gibbs sampling algorithm.</p>
</td></tr>
<tr><td><code id="bayesplfm_+3A_nburnin">Nburnin</code></td>
<td>
<p>The number of burn-in iterations.</p>
</td></tr>
<tr><td><code id="bayesplfm_+3A_maxniter">maxNiter</code></td>
<td>
<p>The maximum number of iterations that will be computed for each chain.</p>
</td></tr>
<tr><td><code id="bayesplfm_+3A_nstep">Nstep</code></td>
<td>
<p>The convergence of the chains to the true posterior will be checked for each parameter after c*<code>Nstep</code> iterations with c=1,2,...
The convergence will only be checked when <code>Nchains</code>&gt;1.</p>
</td></tr>
<tr><td><code id="bayesplfm_+3A_rhatcrit">Rhatcrit</code></td>
<td>
<p>The estimation procedure will be stopped if the Rhat convergence diagnostic is smaller than <code>Rhatcrit</code> 
for each object- and attribute parameter. By default <code>Rhatcrit</code>=1.2.</p>
</td></tr>  
<tr><td><code id="bayesplfm_+3A_maprule">maprule</code></td>
<td>
<p>Disjunctive (<em>maprule=&quot;disj&quot;</em>) or conjunctive (<em>maprule=&quot;conj&quot;</em>) mapping rule of the probabilistic latent feature model.</p>
</td></tr>
<tr><td><code id="bayesplfm_+3A_datatype">datatype</code></td>
<td>
<p>The type of data used as input. When <code>datatype</code>=&quot;freq&quot; one should specify frequency data <code>freq1</code> and <code>freqtot</code>, and when <code>datatype</code>=&quot;dataframe&quot; one should 
specify the name of the data frame <code>data</code>, and its components, <code>object</code>, <code>attribute</code> and <code>rating</code>.</p>
</td></tr>
<tr><td><code id="bayesplfm_+3A_start.bayes">start.bayes</code></td>
<td>
<p>This argument can be used to define the type of starting point for the Bayesian analysis. If <code>start.bayes</code>=&quot;best&quot; the best solution of a <code><a href="#topic+plfm">plfm</a></code> analysis 
is used as the starting point for the Bayesian analysis, and if <code>start.bayes</code> = &quot;fitted.plfm&quot;, the
starting point is read from the (<code><a href="#topic+plfm">plfm</a></code>) object assigned to the argument 
<code>fitted.plfm</code>. If <code>start.bayes</code>=&quot;random&quot;, a random starting point is used for the Bayesian analysis.
</p>
</td></tr>
<tr><td><code id="bayesplfm_+3A_fitted.plfm">fitted.plfm</code></td>
<td>
<p>The name of the <code><a href="#topic+plfm">plfm</a></code> object that contains posterior mode estimates for the specified model.</p>
</td></tr> 
</table>


<h3>Details</h3>

<p>The function <code><a href="#topic+bayesplfm">bayesplfm</a></code> can be used to compute a sample of the posterior 
distribution of disjunctive or conjunctive probabilistic latent feature models with a particular number of features 
using a data-augmented Gibbs sampling algorithm 
(Meulders, De Boeck, Van Mechelen, Gelman, and Maris, 2001; Meulders, De Boeck, Van Mechelen, and Gelman, 2005; Meulders, 2013).
</p>
<p>By specifying the parameter <code>Nchains</code> the function can be used to compute one single chain, or multiple chains. 
When only one chain is computed, no convergence measure is reported. When more than one chain is computed, for each parameter, 
convergence to the true posterior distribution is assessed using the Rhat convergence diagnostic proposed by Gelman and Rubin (1992).
</p>
<p>When using <code><a href="#topic+bayesplfm">bayesplfm</a></code> for Bayesian analysis the same starting point will be used for each simulated chain. The reason for using the same
starting point for each of the chains is that the posterior distribution of probabilistic feature models with <em>F&gt;2</em> is always multimodal 
(local maxima may exist, and one may switch feature labels), so that the aim of the Bayesian analysis is to compute a sample in the neigbourhood 
of one specific posterior mode.  It is recommended to use the best posterior mode obtained
with the <code><a href="#topic+plfm">plfm</a></code> function as a starting point for the Bayesian analysis (use <code>start.bayes</code>=&quot;best&quot;, or specify <code>start.bayes</code>=&quot;fitted.plfm&quot; and 
<code>fitted.plfm</code>=object) with &quot;object&quot; being a <code><a href="#topic+plfm">plfm</a></code> object that contains posterior mode estimates for the specified model. As an alternative to using the <code>plfm()</code>, 
function one may use random  starting points for the Bayesian analysis (<code>start.bayes</code>=&quot;random&quot;) to explore the posterior distribution.
</p>
<p>The function <code>bayesplfm()</code> will converge well if the  distinct posterior modes are well-separated and if the different chains only visit the same mode during the estimation process. 
However, if the posterior distribution is multimodal, it may fail to converge  if the Gibbs sampler starts visiting different posterior modes within
one chain, or if different chains sample from distinct posterior modes. 
</p>


<h3>Value</h3>

<table>
<tr><td><code>call</code></td>
<td>
<p>Parameters used to call the function.</p>
</td></tr>
<tr><td><code>sample.objpar</code></td>
<td>
<p>A <em>J X F X Niter X Nchains</em> array with parameter values for the object parameters. 
The matrix <code>sample.objpar[,,i,c]</code> contains the draw of the object parameters 
in iteration <em>i</em> of chain <em>c</em>. Note: when <code>Nchains</code>=1 the chain length <em>Niter</em> equals <code>maxNiter</code>, 
and when <code>Nchains</code>&gt;1 the chain length <em>Niter</em> equals the number of iterations required to obtain convergence.</p>
</td></tr>
<tr><td><code>sample.attpar</code></td>
<td>
<p>A <em>K X F X Niter X Nchains</em> array with parameter values for the attribute parameters. 
The matrix <code>sample.attpar[,,i,c]</code> contains the draw of the attribute parameters 
in iteration <em>i</em> of chain <em>c</em>. Note: when <code>Nchains</code>=1 the chain length <em>Niter</em> equals <code>maxNiter</code>, 
and when <code>Nchains</code>&gt;1 the chain length <em>Niter</em> equals the number of iterations required to obtain convergence.</p>
</td></tr>
<tr><td><code>pmean.objpar</code></td>
<td>
<p>A <em>J X F</em> matrix with the posterior mean of the object parameters computed on all iterations and chains in the sample.</p>
</td></tr>
<tr><td><code>pmean.attpar</code></td>
<td>
<p>A <em>K X F</em> matrix with the posterior mean of the attribute parameters computed on all iterations and chains in the sample.</p>
</td></tr>
<tr><td><code>p95.objpar</code></td>
<td>
<p>A <em>3 X J X F</em> array which contains for each object parameter the percentiles 2.5, 50 and 97.5.</p>
</td></tr>
<tr><td><code>p95.attpar</code></td>
<td>
<p>A <em>3 X K X F</em> array which contains for each attribute parameter the percentiles 2.5, 50 and 97.5.</p>
</td></tr>
<tr><td><code>Rhat.objpar</code></td>
<td>
<p>A <em>J X F</em> matrix with Rhat convergence values for the object parameters.</p>
</td></tr>
<tr><td><code>Rhat.attpar</code></td>
<td>
<p>A <em>K X F</em> matrix with Rhat convergence values for the attribute parameters.</p>
</td></tr>
<tr><td><code>fitmeasures</code></td>
<td>
<p>A list with two measures of descriptive fit on the <em>J X K</em> table: (1) the correlation between observed and expected frequencies, 
and (2) the proportion of the variance in the observed frequencies accounted for by the model. 
The association probabilities and corresponding expected frequencies are computed using the posterior mean of the parameters.</p>
</td></tr>
<tr><td><code>convstat</code></td>
<td>
<p>The number of object-and attribute parameters that do not meet the convergence criterion.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michel Meulders
</p>


<h3>References</h3>

<p>Gelman, A., and Rubin, D. B. (1992). Inference from iterative simulation using multiple
sequences. <em>Statistical Science, 7</em> , 457-472.
</p>
<p>Meulders, M., De Boeck, P., Van Mechelen, I., Gelman, A., and Maris, E. (2001). Bayesian inference with probability matrix decomposition models. 
<em>Journal of Educational and Behavioral Statistics, 26</em>, 153-179.
</p>
<p>Meulders, M., De Boeck, P., Van Mechelen, I., and Gelman, A. (2005). Probabilistic feature analysis of facial perception of emotions. 
<em>Applied Statistics, 54</em>, 781-793.
</p>
<p>Meulders, M. and De Bruecker, P. (2018). Latent class probabilistic latent feature analysis of three-way three-mode binary data. 
<em>Journal of Statistical Software, 87(1)</em>, 1-45.
</p>
<p>Meulders, M. (2013). An R Package for Probabilistic Latent Feature Analysis of Two-Way Two-Mode Frequencies. <em>Journal of Statistical Software, 54(14)</em>, 1-29. 
URL http://www.jstatsoft.org/v54/i14/.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+plfm">plfm</a></code>, <code><a href="#topic+summary.bayesplfm">summary.bayesplfm</a></code>,<code><a href="#topic+print.summary.bayesplfm">print.summary.bayesplfm</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
## example 1: Bayesian analysis using data generated under the model

## define number of objects
J&lt;-10
## define number of attributes
K&lt;-10
## define number of features
F&lt;-2

## generate true parameters
set.seed(43565)
objectparameters&lt;-matrix(runif(J*F),nrow=J)
attributeparameters&lt;-matrix(runif(K*F),nrow=K)

## generate data for conjunctive model using N=100 replications
gdat&lt;-gendat(maprule="conj",N=100,
              objpar=objectparameters,attpar=attributeparameters)

## Use stepplfm to compute posterior mode(s) for 1 up to 3 features 

conj.lst&lt;-stepplfm(minF=1,maxF=3,maprule="conj",freq1=gdat$freq1,freqtot=100,M=5)


## Compute a sample of the posterior distribution 
## for the conjunctive model with two features
## use the posterior mode obtained with stepplfm as starting point
conjbayes2&lt;-bayesplfm(maprule="conj",freq1=gdat$freq1,freqtot=100,F=2,
                      maxNiter=3000,Nburnin=0,Nstep=1000,Nchains=2,
                      start.bayes="fitted.plfm",fitted.plfm=conj.lst[[2]])


## End(Not run)

## Not run: 
## example 2: Bayesian analysis of situational determinants of anger-related behavior

## load data
data(anger)

## Compute one chain of 500 iterations (including 250 burn-in iterations) 
## for the disjunctive model with two features
## use a random starting point

bayesangerdisj2a&lt;-bayesplfm(maprule="disj",freq1=anger$freq1,freqtot=anger$freqtot,F=2,
                      maxNiter=500,Nstep=500,Nburnin=250,Nchains=1,start.bayes="random")

##print a summary of the output 
summary(bayesangerdisj2a)


## Compute a sample of the posterior distribution 
## for the disjunctive model with two features
## compute starting points with plfm
## run 2 chains with a maximum length of 10000 iterations
## compute convergence after each 1000 iterations

bayesangerdisj2b&lt;-bayesplfm(maprule="disj",freq1=anger$freq1,freqtot=anger$freqtot,F=2,
                      maxNiter=10000,Nburnin=0,Nstep=1000,Nchains=2,start.bayes="best")


## print the output of the disjunctive 2-feature model for the anger data
print(bayesangerdisj2b)


## print a summary of the output of the disjunctive 2-feature model 
##for the anger data
summary(bayesangerdisj2b)

## End(Not run)


</code></pre>

<hr>
<h2 id='car'>Ratings of associations between car models and car attributes</h2><span id='topic+car'></span>

<h3>Description</h3>

<p> The data describe the ratings of 78 respondents about the association between each of 14 car models and each of 27 car attributes.</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(car)</code></pre>


<h3>Format</h3>

<p>The data consist of a list of 4 objects:
</p>

<ol>
<li><p> datalongformat: A data frame that consists of 6 components:  Each row of the data frame  describes the outcome of a binary rater judgement
about the association between a certain car and a certain attribute. The components <em>IDobject</em> and <em>objectlabel</em> contain an ID and 
label for the car models, the components <em>IDattribute</em> and <em>attributelabel</em> contain an ID and  label for the attributes, the component <em>IDrater</em> 
contains a rater ID, and the component <em>rating</em> contains the binary  ratings (1 if the car model has the attribute according to the rater, and 0 otherwise).
</p>
</li>
<li><p> data3w: A 78 X 14 X 27 array of binary judgements. The observation in cell <em>(i,j,k)</em> equals 1 if respondent <em>i</em> indicates that car <em>j</em> has 
attribute <em>k</em>, and 0 otherwise.   
</p>
</li>
<li><p> freq1: A 14 X 27 matrix of frequencies. The frequency in cell <em>(j,k)</em> indicates how many of 78 respondents 
indicate an association between car model <em>j</em> and attribute <em>k</em>.
</p>
</li>
<li><p> freqtot: A 14 X 27 matrix of frequencies. The frequency in cell <em>(j,k)</em> indicates the total number of respondents 
who judged the car-attribute pair <em>(j,k)</em>.
</p>
</li></ol>



<h3>Source</h3>

<p>Van Gysel, E. (2011). <em>Perceptuele analyse van automodellen met probabilistische feature modellen.</em> [translation from Dutch: Perceptual analysis of car models with probabilistic feature models] 
Master thesis. Hogeschool-Universiteit Brussel.</p>


<h3>References</h3>

<p>Meulders, M. (2013). An R Package for Probabilistic Latent Feature Analysis of Two-Way Two-Mode Frequencies. <em>Journal of Statistical Software, 54(14)</em>, 1-29. 
URL http://www.jstatsoft.org/v54/i14/.
</p>

<hr>
<h2 id='car2'>Judgements on associations between car models and car attributes</h2><span id='topic+car2'></span>

<h3>Description</h3>

<p> The data consist of the binary judgements of 147 respondents about the association between each of 12 car models and each of 23 car attributes.</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(car2)</code></pre>


<h3>Format</h3>

<p>The data consist of a list of 5 objects:
</p>

<ol>
<li><p> data3w: A 147 X 12 X 23 array of binary judgements. The observation in cell <em>(i,j,k)</em> equals 1 if respondent <em>i</em> indicates that car <em>j</em> has 
attribute <em>k</em>, and 0 otherwise.   
</p>
</li>
<li><p> freq1: A 12 X 23 matrix of frequencies. The frequency in cell <em>(j,k)</em> indicates how many of 147 respondents 
indicate an association between car model <em>j</em> and attribute <em>k</em>.
</p>
</li>
<li><p> freqtot: A 12 X 23 matrix of frequencies. The frequency in cell <em>(j,k)</em> indicates the total number of respondents 
who judged the car-attribute pair <em>(j,k)</em>.
</p>
</li></ol>



<h3>Source</h3>

<p>M\&quot;ahler, R. (2014). <em>Analyse van perceptie en preferentie van middelgrote wagens.</em> [translation from Dutch: Analysis of perception and preference for midsize cars.] 
Master thesis. KU Leuven.</p>


<h3>References</h3>

<p>Meulders, M. and De Bruecker, P. (2018). Latent class probabilistic latent feature analysis of three-way three-mode binary data. 
<em>Journal of Statistical Software, 87(1)</em>, 1-45.
</p>

<hr>
<h2 id='gendat'>Data generation</h2><span id='topic+gendat'></span>

<h3>Description</h3>

<p>Computation of association probabilities and data generation for disjunctive, conjunctive or additive probabilistic latent feature models.</p>


<h3>Usage</h3>

<pre><code class='language-R'>gendat(maprule="disj", N, objpar, attpar)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gendat_+3A_maprule">maprule</code></td>
<td>
<p>Disjunctive (<code>maprule="disj"</code>), conjunctive (<code>maprule="conj"</code>) or additive (<code>maprule="add"</code>) 
mapping rule of the probabilistic latent feature model.</p>
</td></tr>
<tr><td><code id="gendat_+3A_n">N</code></td>
<td>
<p>Number of replications for which binary associations are generated.</p>
</td></tr>
<tr><td><code id="gendat_+3A_objpar">objpar</code></td>
<td>
<p>True objectparameters. As object parameters are probabilities they should be between 0 and 1.</p>
</td></tr>
<tr><td><code id="gendat_+3A_attpar">attpar</code></td>
<td>
<p>True attributeparameters. As attribute parameters are probabilities they should be between 0 and 1.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function <code>gendat</code> computes for all pairs of <em>J</em> objects and <em>K</em> attributes association probabilities and it generates 
association frequencies (i.e. the number of replications <code>N</code> for which an object is associated to an attribute), 
according to a disjunctive, conjunctive or additive probabilistic latent feature model. In addition, the function computes a matrix with in each cell 
the total number of replications <code>N</code>. 
If the requested number of replications <code>N</code> equals 0, 
the function only computes association probabilities and does not generate new data. 
</p>
<p>To compute association probabilities the function <em>gendat</em> uses a <em>J X F</em> matrix of object parameters and a <em>K X F</em> matrix 
of attribute parameters as input. The <em>F</em> object parameters of object <em>j</em> represent, for each of <em>F</em> features, 
the probability that object <em>j</em> has feature <em>f</em>. 
Similarly, the <em>F</em> attribute parameters of attribute <em>k</em> reflect, for each of <em>F</em> features, 
the probability that attribute <em>k</em> is linked to feature <em>f</em>. 
</p>
<p>According to the <em>disjunctive</em> probabilistic latent feature model, object <em>j</em> is associated
to attribute <em>k</em> if the object and the attribute have at least one feature in common. 
More specifically, the association probability in cell <em>(j,k)</em> for the disjunctive model 
can be computed as: 
</p>
<p style="text-align: center;"><code class="reqn">p(j,k)=1-\prod_f(1-objpar[j,f]*attpar[k,f]).</code>
</p>

<p>According to the <em>conjunctive</em> probabilistic latent feature model, object <em>j</em> and attribute <em>k</em> 
are associated if object <em>j</em> has all the features that are linked to attribute <em>k</em>. 
For the conjunctive model the association probability in cell <em>(j,k)</em> is computed as:
</p>
<p style="text-align: center;"><code class="reqn">p(j,k)=\prod_f(1-(1-objpar[j,f])*attpar[k,f]).</code>
</p>

<p>The <em>additive</em> mapping rule states that an object and attribute are more likely to associated if they have more common features. More specifically, 
the association probability for the additive model is computed as:
</p>
<p style="text-align: center;"><code class="reqn">p(j,k)= \frac{1}{F}*\sum_f (objpar[j,f])*attpar[k,f]).</code>
</p>



<h3>Value</h3>

<table>
<tr><td><code>call</code></td>
<td>
<p>Parameters used to call the function.</p>
</td></tr>
<tr><td><code>prob1</code></td>
<td>
<p><em>J X K</em> matrix of association probabilities.</p>
</td></tr>
<tr><td><code>freq1</code></td>
<td>
<p><em>J X K</em> matrix of association frequencies.</p>
</td></tr>
<tr><td><code>freqtot</code></td>
<td>
<p><em>J X K</em> matrix with number of replications.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michel Meulders</p>


<h3>References</h3>

<p>Maris, E., De Boeck, P., and Van Mechelen, I. (1996). Probability matrix decomposition models. <em>Psychometrika, 61</em>, 7-29.
</p>
<p>Meulders, M., De Boeck, P., Van Mechelen, I., Gelman, A., and Maris, E. (2001). Bayesian inference with probability matrix decomposition models. 
<em>Journal of Educational and Behavioral Statistics, 26</em>, 153-179.
</p>
<p>Meulders, M., De Boeck, P., Van Mechelen, I., &amp; Gelman, A. (2005). Probabilistic feature analysis of facial perception of emotions. 
<em>Applied Statistics, 54</em>, 781-793.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+plfm">plfm</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## define constants
J&lt;-20
K&lt;-15
F&lt;-2

## generate true parameters
set.seed(43565)
objectparameters&lt;-matrix(runif(J*F),nrow=J)
attributeparameters&lt;-matrix(runif(K*F),nrow=K)

## compute association probabilities for a conjunctive model
probconj&lt;-gendat(maprule="conj",N=0,
             objpar=objectparameters,attpar=attributeparameters)

## generate data for a disjunctive model using N=200 replications
gdat&lt;-gendat(maprule="disj",N=200,
             objpar=objectparameters,attpar=attributeparameters)

## generate data for a additive model using N=200 replications
gdat&lt;-gendat(maprule="add",N=200,
             objpar=objectparameters,attpar=attributeparameters)
</code></pre>

<hr>
<h2 id='gendatLCplfm'>Data generation</h2><span id='topic+gendatLCplfm'></span>

<h3>Description</h3>

<p>Data generation for disjunctive, conjunctive and additive latent class probabilistic latent feature models.</p>


<h3>Usage</h3>

<pre><code class='language-R'>gendatLCplfm(N,objpar,attpar,sizepar,maprule="disj",model=1)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gendatLCplfm_+3A_n">N</code></td>
<td>
<p>Number of replications (e.g. persons) for which binary object-attribute associations are generated.</p>
</td></tr>
<tr><td><code id="gendatLCplfm_+3A_objpar">objpar</code></td>
<td>
<p>True objectparameters. If <code>model</code>=1, <code>model</code>=3, <code>model</code>=4, or <code>model</code>=6 <code>objpar</code> is a <em>J X F X T</em> array, 
if  <code>model</code>=2 or <code>model</code>=5 <code>objpar</code> is a <em>J X F</em> matrix. As object parameters are probabilities they should be between 0 and 1.</p>
</td></tr>
<tr><td><code id="gendatLCplfm_+3A_attpar">attpar</code></td>
<td>
<p>True attributeparameters. If <code>model</code>=2, <code>model</code>=3, <code>model</code>=5, or <code>model</code>=6 <code>attpar</code> is a <em>K X F X T</em> array, 
if  <code>model</code>=1 or <code>model</code>=4 <code>attpar</code> is a <em>K X F</em> matrix. As attribute parameters are probabilities they should be between 0 and 1.</p>
</td></tr>
<tr><td><code id="gendatLCplfm_+3A_sizepar">sizepar</code></td>
<td>
<p>A <em>T</em>-vector of true class size parameters.</p>
</td></tr>
<tr><td><code id="gendatLCplfm_+3A_maprule">maprule</code></td>
<td>
<p>Disjunctive (<code>maprule="disj"</code>), conjunctive (<code>maprule="conj"</code>) or additive  (<code>maprule="add"</code>) 
mapping rule of the latent class probabilistic latent feature model.</p>
</td></tr>
<tr><td><code id="gendatLCplfm_+3A_model">model</code></td>
<td>
<p>The type of dependency and heterogeneity assumption included in the model. <code>model</code>=1, <code>model</code>=2, <code>model</code>=3 represent models with a constant 
object-feature classification per person and with, respectively, class-specific object parameters, class-specific attribute parameters, 
and class-specific object- and attribute parameters. <code>model</code>=4, <code>model</code>=5, <code>model</code>=6 represent models with a constant 
attribute-feature classification per person and with, respectively, class-specific object parameters, class-specific attribute parameters, 
and class-specific object- and attribute parameters.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function <code>gendatLCplfm</code> generates binary object-attribute associations for <em>N</em> replications 
according to a disjunctive, conjunctive or additive latent class probabilistic latent feature model of a specific model type. 
In addition, the function computes the <em>J X K</em> matrix of marginal object-attribute association probabilities and
a  <em>J X K X T</em> array of class-specific object-attribute association probabilities.                      
To compute association probabilities the function <em>gendatLCplfm</em> uses a vector of class size parameters (<code>sizepar</code>) a matrix or array of 
object parameters (<code>objpar</code>) and a matrix or array of true  attribute parameters (<code>attpar</code>) as input. 
</p>
<p>According to the <em>disjunctive</em> probabilistic latent feature model, object <em>j</em> is associated
to attribute <em>k</em> if the object and the attribute have at least one feature in common. 
More specifically, for <code>model=1</code> the class-specific object-attribute association probability in cell <em>(j,k)</em> for the disjunctive model 
can be computed as: 
</p>
<p style="text-align: center;"><code class="reqn">p(j,k|t)=1-\prod_f(1-objpar[j,f,t]*attpar[k,f]).</code>
</p>

<p>According to the <em>conjunctive</em> probabilistic latent feature model, object <em>j</em> and attribute <em>k</em> 
are associated if object <em>j</em> has all the features that are linked to attribute <em>k</em>. 
</p>
<p>In particular, for <code>model=1</code>,the class-specific object-attribute association probability in cell <em>(j,k)</em> for the conjunctive model can be computed as:
</p>
<p style="text-align: center;"><code class="reqn">p(j,k|t)=\prod_f(1-(1-objpar[j,f,t])*attpar[k,f]).</code>
</p>

<p>According to the <em>additive</em> probabilistic latent feature model, an object and an attribute are more likely to be associated if they have more features in common. 
</p>
<p>In particular, for <code>model=1</code>,the class-specific object-attribute association probability in cell <em>(j,k)</em> for the additive model can be computed as:
</p>
<p style="text-align: center;"><code class="reqn">p(j,k|t)= \frac{1}{F} * \sum_f(objpar[j,f,t])*attpar[k,f]).</code>
</p>

<p>The marginal object-attribute association probability can be computed as follows:
</p>
<p style="text-align: center;"><code class="reqn">p(j,k)=\sum_t sizepar[t]*p(j,k|t).</code>
</p>



<h3>Value</h3>

<table>
<tr><td><code>call</code></td>
<td>
<p>Parameters used to call the function.</p>
</td></tr>
<tr><td><code>data</code></td>
<td>
<p><em>I X J X K</em> matrix of association probabilities.</p>
</td></tr>
<tr><td><code>class</code></td>
<td>
<p><em>I</em>-vector that contains latent class membership of each replication.</p>
</td></tr>
<tr><td><code>condprob.JKT</code></td>
<td>
<p><em>J X K X T</em> array of class-specific conditional object-attribute association probabilities.</p>
</td></tr>
<tr><td><code>margprob.JK</code></td>
<td>
<p><em>J X K</em> matrix  of marginal object-attribute association probabilities.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michel Meulders</p>


<h3>References</h3>

<p>Meulders, M., Tuerlinckx, F., and Vanpaemel, W. (2013). Constrained multilevel latent class models for the analysis of three-way three-mode binary data. 
<em>Journal of Classification, 30 (3)</em>, 306-337.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+LCplfm">LCplfm</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# define constants
I&lt;-500
J&lt;-10
K&lt;-8
F&lt;-2
T&lt;-2

# model 1

# generate true parameters
objpar&lt;-array(runif(J*F*T),c(J,F,T))
attpar&lt;-matrix(runif(K*F),c(K,F))
sizepar&lt;-rep(1/T,T)
# generate data
d&lt;-gendatLCplfm(N=I,objpar=objpar,attpar=attpar,sizepar=sizepar,maprule="conj",model=1)
# estimate parameters of true model
res&lt;-LCplfm(data=d$data,F=2,T=2,model=1,maprule="conj")


# model 2

# generate true parameters
objpar&lt;-matrix(runif(J*F),nrow=J)
attpar&lt;-array(runif(K*F*T),c(K,F,T))
sizepar&lt;-rep(1/T,T)
# generate data
d&lt;-gendatLCplfm(N=I,objpar=objpar,attpar=attpar,sizepar=sizepar,maprule="conj",model=2)
# estimate parameters of true model
res&lt;-LCplfm(data=d$data,F=2,T=2,model=2,maprule="conj")

# model 3

# generate true parameters
objpar&lt;-array(runif(J*F*T),c(J,F,T))
attpar&lt;-array(runif(K*F*T),c(K,F,T))
sizepar&lt;-rep(1/T,T)
# generate data
d&lt;-gendatLCplfm(N=I,objpar=objpar,attpar=attpar,sizepar=sizepar,maprule="conj",model=3)
# estimate parameters of true model
res&lt;-LCplfm(data=d$data,F=2,T=2,model=3,maprule="conj")

# model 4

# generate true parameters
objpar&lt;-array(runif(J*F*T),c(J,F,T))
attpar&lt;-matrix(runif(K*F),c(K,F))
sizepar&lt;-rep(1/T,T)
# generate data
d&lt;-gendatLCplfm(N=I,objpar=objpar,attpar=attpar,sizepar=sizepar,maprule="conj",model=4)
# estimate parameters of true model
res&lt;-LCplfm(data=d$data,F=2,T=2,model=4,maprule="conj")

# model 5

# generate true parameters
objpar&lt;-matrix(runif(J*F),nrow=J)
attpar&lt;-array(runif(K*F*T),c(K,F,T))
sizepar&lt;-rep(1/T,T)
# generate data
d&lt;-gendatLCplfm(N=I,objpar=objpar,attpar=attpar,sizepar=sizepar,maprule="conj",model=5)
# estimate parameters of true model
res&lt;-LCplfm(data=d$data,F=2,T=2,model=5,maprule="conj")


# model 6
# generate true parameters
objpar&lt;-array(runif(J*F*T),c(J,F,T))
attpar&lt;-array(runif(K*F*T),c(K,F,T))
sizepar&lt;-rep(1/T,T)
# generate data
d&lt;-gendatLCplfm(N=I,objpar=objpar,attpar=attpar,sizepar=sizepar,maprule="conj",model=6)
# estimate parameters of true model
res&lt;-LCplfm(data=d$data,F=2,T=2,model=6,maprule="conj")

## End(Not run)
</code></pre>

<hr>
<h2 id='hostility'>self-reported hostile behavior in frustrating situations</h2><span id='topic+hostility'></span>

<h3>Description</h3>

<p>The data consist of the judgments of 316 first-year psychology students who indicated on a three point scale the extent to which they would display 
each of 4 hostile behaviors in each of 14 frustrating situations (0= you do not display this response in this situation, 
1= you display this response to a limited extent in this situation, 2= you display this response to a strong extent in this situation). 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(hostility)</code></pre>


<h3>Format</h3>

<p>The data consist of a list of 6 objects:
</p>

<ol>
<li><p> data: A 316 X 14 X 4 array of dichotomized judgements (0 versus 1 or 2). The observation in cell <em>(i,j,k)</em> equals 1 if person <em>i</em> 
would display behavior <em>k</em> in situation <em>j</em> to a limited or strong extent and 0 if person <em>i</em> 
would not display behavior <em>k</em> in situation <em>j</em>.
</p>
</li>
<li><p> freq1: A 14 X 4 matrix of frequencies. The frequency in cell <em>(j,k)</em> indicates the number of respondents 
who indicate that they would display behavior <em>k</em> in situation <em>j</em>.
</p>
</li>
<li><p> freqtot: A 14 X 4 matrix of frequencies. The frequency in cell <em>(j,k)</em> indicates the total number of respondents 
who judged the situation-response pair <em>(j,k)</em>.
</p>
</li>
<li><p> situation: A vector with descriptions of the situations.
</p>
</li>
<li><p> rowlabels: A vector of labels for the situations.
</p>
</li>
<li><p> columnlabels: A vector of labels for the anger-related behaviors.
</p>
</li></ol>



<h3>Source</h3>

<p>Vansteelandt, K. (1999). A formal model for the competency-demand hypothesis. <em>European Journal of Personality, 13</em>, 429-442.
</p>


<h3>References</h3>

<p>Vansteelandt, K. and Van Mechelen, I. (1998). Individual differences in situation-behavior profiles: A triple typology model. 
<em>Journal of Personality and Social Psychology, 75</em>, 751-765. 
</p>

<hr>
<h2 id='LCplfm'>Latent class probabilistic feature analysis of three-way three-mode binary data</h2><span id='topic+LCplfm'></span>

<h3>Description</h3>

<p>Computation of parameter estimates, standard errors, criteria for model selection, and measures of descriptive fit for 
disjunctive, conjunctive and additive latent class probabilistic  feature models.</p>


<h3>Usage</h3>

<pre><code class='language-R'>  
LCplfm(data,F=2,T=2,M=5,maprule="disj",emcrit1=1e-3,emcrit2=1e-8,
       model=1,start.objectparameters=NULL,start.attributeparameters=NULL,
       start.sizeparameters=NULL,delta=0.0001,printrun=FALSE,
       update.objectparameters=NULL,update.attributeparameters=NULL,
       Nbootstrap=2000)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="LCplfm_+3A_data">data</code></td>
<td>
<p>A <em>I X J X K</em> data array of binary observations. Observation <em>(i,j,k)</em> <em>(i=1,..,I; j=1,..,J; k=1,..,K)</em>  indicates 
whether object <em>j</em> is associated to attribute <em>k</em> according to rater <em>i</em>.</p>
</td></tr> 
<tr><td><code id="LCplfm_+3A_f">F</code></td>
<td>
<p>The number of latent features included in the model.</p>
</td></tr>
<tr><td><code id="LCplfm_+3A_t">T</code></td>
<td>
<p>The number of latent classes included in the model.</p>
</td></tr>
<tr><td><code id="LCplfm_+3A_m">M</code></td>
<td>
<p>The number of times a particular model is estimated using random starting points.</p>
</td></tr>
<tr><td><code id="LCplfm_+3A_maprule">maprule</code></td>
<td>
<p>Disjunctive (<code>maprule</code>=&quot;disj&quot;), conjunctive (<code>maprule</code>=&quot;conj&quot;) or additive (<code>maprule</code>=&quot;add&quot;) mapping rule of the probabilistic latent feature model.</p>
</td></tr>
<tr><td><code id="LCplfm_+3A_emcrit1">emcrit1</code></td>
<td>
<p>Convergence criterion to be used for the estimation of candidate models.</p>
</td></tr>
<tr><td><code id="LCplfm_+3A_emcrit2">emcrit2</code></td>
<td>
<p>Convergence criterion to be used for the estimation of the best model.</p>
</td></tr>
<tr><td><code id="LCplfm_+3A_model">model</code></td>
<td>
<p>The type of dependency and heterogeneity assumption included in the model. <code>model</code>=1, <code>model</code>=2, <code>model</code>=3 represent models with a constant 
object-feature classification per person and with, respectively, class-specific object parameters, class-specific attribute parameters, 
and class-specific object- and attribute parameters. <code>model</code>=4, <code>model</code>=5, <code>model</code>=6 represent models with a constant 
attribute-feature classification per person and with, respectively, class-specific object parameters, class-specific attribute parameters, 
and class-specific object- and attribute parameters.</p>
</td></tr>
<tr><td><code id="LCplfm_+3A_start.objectparameters">start.objectparameters</code></td>
<td>
<p>An array of object parameters to be used as starting value for each run.
The size of the array equals <em>J x F x T x M</em>  when <code>model = 1,4,3,6</code> and 
<em>J x F x M</em> when <code>model = 2,5</code>.  
If <code>start.objectparameters=NULL</code> randomly generated object parameters 
are used as starting values.</p>
</td></tr>
<tr><td><code id="LCplfm_+3A_start.attributeparameters">start.attributeparameters</code></td>
<td>
<p>An  array of attribute parameters to be used as starting value for each run. 
The size of the array equals <em>K x F x T x M</em>  when <code>model = 2,5,3,6</code> 
and <em>K x F x M</em> when <code>model = 1,3</code>. 
If <code>start.attributeparameters=NULL</code> randomly generated attribute parameters 
are used as starting values.</p>
</td></tr>
<tr><td><code id="LCplfm_+3A_start.sizeparameters">start.sizeparameters</code></td>
<td>
<p>A <em>T x M</em> matrix of latent class size parameters to be used as starting value for each run. 
If <code>start.sizeparameters=NULL</code> randomly  generated class size parameters are used 
as starting values.</p>
</td></tr>
<tr><td><code id="LCplfm_+3A_delta">delta</code></td>
<td>
<p>The precision used to compute standard errors of the parameters with the method of finite differences.</p>
</td></tr>
<tr><td><code id="LCplfm_+3A_printrun">printrun</code></td>
<td>
<p><code>printrun</code>=TRUE prints the analysis type (disjunctive, conjunctive, additive), the number of features (<em>F</em>), the number of latent classes (<em>T</em>) 
and the number of the run to the output screen, whereas <code>printrun</code>=FALSE suppresses the printing.</p>
</td></tr>
<tr><td><code id="LCplfm_+3A_update.objectparameters">update.objectparameters</code></td>
<td>
<p>A binary valued array that indicates for each object parameter whether it has to be 	estimated 
from the data or constrained to the starting value. A value of 1 means that the corresponding object parameter is estimated and 
a value of 0 means that the corresponding object parameter is constrained to the starting value provided by the user.
The size of the array equals <em>J x F x T</em>  when <code>model = 1,4,3,6</code> and <em>J x F</em> when <code>model = 2,5</code>.  
If <code>update.objectparameters</code> <code>= NULL</code> all object parameters are estimated from the data.</p>
</td></tr>
<tr><td><code id="LCplfm_+3A_update.attributeparameters">update.attributeparameters</code></td>
<td>
<p>A binary valued array that indicates for each attribute parameter whether it has to be estimated 
from the data or constrained to the starting value. A value of 1 means that the corresponding attribute parameter is estimated and 
a value of 0 means that the corresponding attribute parameter is constrained to the starting value provided by the user.
The size of the array equals <em>K x F x T</em>  when <code>model = 2,5,3,6</code> and <em>K x F</em> when <code>model = 1,3</code>.  
If <code>update.attributeparameters</code> <code>= NULL</code> all attribute parameters are estimated from the data.</p>
</td></tr>
<tr><td><code id="LCplfm_+3A_nbootstrap">Nbootstrap</code></td>
<td>
<p>Number of bootstrap iterations to be used for simulating the reference distribution of odds-ratio dependency measures.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><em>Estimation</em>
The estimation algorithm includes two steps. In a first exploratory step an EM algorithm is used to conduct <code>M</code> runs using random starting points. Each exploratory run is 
terminated if the convergence criterium (i.e., the sum of absolute differences between parameter values in subsequent iterations) is smaller than <code>emcrit1</code>. In a second step, 
the best solution  among the <code>M</code> runs (i.e., with the highest posterior density) is used as the starting point of the EM algorithm for conducting a final analysis. The final 
analysis is terminated if the convergence criterion <code>emcrit2</code> is smaller than the convergence criterion. 
</p>
<p><em>Model selection criteria, goodness-of-fit and statistical dependency measures</em>
</p>
<p>To choose among models with different numbers of features, or with different mapping rules, 
one may use information criteria such as the Akaike Information Criterion (AIC, Akaike, 1973, 1974),
or the Schwarz Bayesian Information Criterion (BIC, Schwarz, 1978). AIC and BIC are computed as <em>-2*loglikelihood+k*Npar</em>.
For AIC <em>k</em> equals 2 and for BIC <em>k</em> equals <em>log(N)</em>, with <em>N</em> the observed number of replications (<em>I</em>) 
for which object-attribute associations are collected. <em>Npar</em> represents the number of model parameters.
Models with the lowest value for AIC or BIC should be selected.
</p>
<p>The descriptive goodness-of-fit of the model is assessed with the correlation between observed and expected frequencies in the <em>J X K</em> table, 
and the proportion of the variance in the observed frequencies accounted for by the model (VAF)
(i.e. the squared correlation between observed and expected frequencies).
</p>
<p>To assess to which extent the model can capture observed statistical dependencies between object-attribute pairs with a common object or attribute, a parametric 
bootstrap procedure is used to evaluate whether observed dependencies are within the simulated 95 or 99 percent confidence interval. Let <em>D(i,j,k)</em> be equal to 1 if rater i
indicates that object <em>j</em> is associated to attribute <em>k</em>. The statistical dependency between pairs <em>(j,k)</em> and <em>(j*,k*)</em> is measured with the odds ratio (OR) statistic: 
</p>
<p style="text-align: center;"><code class="reqn">OR(j,k,j^{*},k^{*})=\mbox{log}\left\lbrack\frac{N_{11}*N_{00}}{N_{10}*N_{01}}\right\rbrack</code>
</p>

<p>with 
</p>
<p style="text-align: center;"><code class="reqn">N_{11}=\sum_i D(i,j,k) D(i,j^{*},k^{*}) +0.5</code>
</p>

<p style="text-align: center;"><code class="reqn">N_{00}=\sum_i (1-D(i,j,k)) (1-D(i,j^{*},k^{*})) +0.5</code>
</p>
 
<p style="text-align: center;"><code class="reqn">N_{10}=\sum_i D(i,j,k) (1-D(i,j^{*},k^{*})) +0.5</code>
</p>

<p style="text-align: center;"><code class="reqn">N_{01}=\sum_i (1-D(i,j,k)) D(i,j^{*},k^{*}) +0.5</code>
</p>

<p>The model selection criteria AIC and BIC, the descriptive goodness-of-fit measures  (correlation observed and expected frequencies, and VAF) and a summary of the OR dependency measures 
(i.e., proportion of observed OR dependencies of a certain type that are in the simulated 95 or 99 percent confidence interval) are stored in the object <code>fitmeasures</code> of the output list
</p>


<h3>Value</h3>

<table>
<tr><td><code>call</code></td>
<td>
<p>Parameters used to call the function.</p>
</td></tr>
<tr><td><code>logpost.runs</code></td>
<td>
<p>A list with the logarithm of the posterior density for each of the <em>M</em> computed models.</p>
</td></tr>
<tr><td><code>best</code></td>
<td>
<p>An index which indicates the model with the highest posterior density among each of the <em>M</em> computed models.</p>
</td></tr>
<tr><td><code>objpar</code></td>
<td>
<p>Estimated object parameters for the best model.</p>
</td></tr>
<tr><td><code>attpar</code></td>
<td>
<p>Estimated attribute parameters for the best model.</p>
</td></tr>
<tr><td><code>sizepar</code></td>
<td>
<p>A vector of <code>T</code> class size parameters for the best model.</p>
</td></tr>
<tr><td><code>SE.objpar</code></td>
<td>
<p>Estimated standard errors for the object parameters of the best model.</p>
</td></tr>
<tr><td><code>SE.attpar</code></td>
<td>
<p>Estimated standard errors for the attribute parameters of the best model.</p>
</td></tr>
<tr><td><code>SE.sizepar</code></td>
<td>
<p>Estimated standard errors for the class size parameters  of the best model.</p>
</td></tr>
<tr><td><code>gradient.objpar</code></td>
<td>
<p>Gradient of the object parameters for the best model.</p>
</td></tr>
<tr><td><code>gradient.attpar</code></td>
<td>
<p>Gradient of the attribute parameters for the best model.</p>
</td></tr>
<tr><td><code>gradient.sizepar</code></td>
<td>
<p>Gradient of the class size parameters for the best model.</p>
</td></tr>
<tr><td><code>fitmeasures</code></td>
<td>
<p>A list of model selection criteria, goodness-of-fit measures and OR dependency measures for the model with the highest posterior density.</p>
</td></tr>
<tr><td><code>postprob</code></td>
<td>
<p>A <em>I X T</em> matrix of posterior probabilities for the best model.</p>
</td></tr>
<tr><td><code>margprob.JK</code></td>
<td>
<p>A <em>J X K</em> matrix of marginal object-attribute association probabilities.</p>
</td></tr>
<tr><td><code>condprob.JKT</code></td>
<td>
<p>A <em>J X K X T</em> array of conditional object-attribute association probabilities (i.e., probability of object-attribute association given latent class membership).</p>
</td></tr>
<tr><td><code>report.OR.attpair</code></td>
<td>
<p>A matrix that contains for all attribute pairs per object the observed OR dependency (OR.obs), the expected OR dependency (OR.mean) 
and the upper and lower bounds of the corresponding simulated 95 and 99 percent confidence interval (OR.p025, OR.p975, OR.p005, OR.p995).</p>
</td></tr>
<tr><td><code>report.OR.objpair</code></td>
<td>
<p>A matrix that contains for all object pairs per attribute the observed OR dependency (OR.obs), the expected OR dependency (OR.mean) 
and the upper and lower bounds of the corresponding simulated 95 and 99 percent confidence interval (OR.p025, OR.p975, OR.p005, OR.p995).</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michel Meulders and Philippe De Bruecker
</p>


<h3>References</h3>

<p>Akaike, H. (1973). Information theory and an extension of the maximum likelihood
principle. In B. N. Petrov and F. Csaki (Eds.), <em>Second international symposium on
information theory</em> (p. 271-283). Budapest: Academiai Kiado.
</p>
<p>Akaike, H. (1974). A new look at the statistical model identification. <em>IEEE Transactions
on Automatic Control, 19</em>, 716-723.
</p>
<p>Candel, M. J. J. M., and Maris, E. (1997). Perceptual analysis of two-way two-mode
frequency data: probability matrix decomposition and two alternatives.
<em>International Journal of Research in Marketing, 14</em>, 321-339.
</p>
<p>Louis, T. A. (1982). Finding observed information using the em algorithm. <em>Journal of the
Royal Statistical Society, Series B, 44</em>, 98-130.
</p>
<p>Maris, E. (1999). Estimating multiple classification latent class models. <em>Psychometrika, 64</em>, 187-212.
</p>
<p>Maris, E., De Boeck, P., and Van Mechelen, I. (1996). Probability matrix decomposition models. <em>Psychometrika, 61</em>, 7-29.
</p>
<p>Meulders, M., De Boeck, P., and Van Mechelen, I. (2001). Probability matrix decomposition
models and main-effects generalized linear models for the analysis of replicated
binary associations. <em>Computational Statistics and Data Analysis, 38</em>, 217-233.
</p>
<p>Meulders, M., De Boeck, P., Van Mechelen, I., Gelman, A., and Maris, E. (2001). Bayesian inference with probability matrix decomposition models. 
<em>Journal of Educational and Behavioral Statistics, 26</em>, 153-179.
</p>
<p>Meulders, M., De Boeck, P., Van Mechelen, I., and Gelman, A. (2005). Probabilistic feature analysis of facial perception of emotions. 
<em>Applied Statistics, 54</em>, 781-793.
</p>
<p>Meulders, M. and De Bruecker, P. (2018). Latent class probabilistic latent feature analysis of three-way three-mode binary data. 
<em>Journal of Statistical Software, 87(1)</em>, 1-45.
</p>
<p>Meulders, M. (2013). An R Package for Probabilistic Latent Feature Analysis of Two-Way Two-Mode Frequencies. <em>Journal of Statistical Software, 54(14)</em>, 1-29. 
URL http://www.jstatsoft.org/v54/i14/.
</p>
<p>Meulders, M., Tuerlinckx, F., and Vanpaemel, W. (2013). Constrained multilevel latent class models for the analysis of three-way three-mode binary data. 
<em>Journal of Classification, 30 (3)</em>, 306-337.
</p>
<p>Tanner, M. A. (1996). <em>Tools for statistical inference: Methods for the exploration of
posterior distributions and likelihood functions</em> (Third ed.). New York:
Springer-Verlag.
</p>
<p>Tatsuoka, K. (1984). <em>Analysis of errors in fraction addition and subtraction problems</em>. Final Report for NIE-G-81-0002, University of Illinois, Urbana-Champaign. 
</p>
<p>Schwarz, G. (1978). Estimating the dimensions of a model. <em>Annals of Statistics, 6</em>, 461-464.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+print.LCplfm">print.LCplfm</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 

# example 1: analysis on determinants of anger-related behavior

# load anger data
data(anger)

# estimate a disjunctive LCplfm model with F=2 and T=2 
# assume constant situation-feature classification
# and class-specific situation parameters (i.e. model 1)
# use 10 exploratory runs with random starting points 
anger.LCplfm.disj&lt;-LCplfm(data=anger$data,F=2, T=2, M=10)

# print the output of the model 
print (anger.LCplfm.disj)


# estimate an additive LCplfm model with F=2 and T=2 
# assume constant situation-feature classification
# and class-specific situation parameters (i.e. model 1)
# use 10 exploratory runs with random starting points 
anger.LCplfm.add&lt;-LCplfm(data=anger$data,F=2, T=2, M=10, maprule="add")

# print the output of the model 
print (anger.LCplfm.add)


# estimate a disjunctive LCplfm model with F=4 and T=2
# assume constant situation-feature classifications
# and class-specific situation parameters (i.e. model 1)
# use 20 exploratory runs with random starting points (M=20)
# constrain parameters of subsequent behavior pairs to "load"
# on only one feature

# specify which attribute parameters have to be estimated from the data
update.attribute&lt;-matrix(rep(0,8*4),ncol=4)
update.attribute[1:2,1]&lt;-c(1,1)
update.attribute[3:4,2]&lt;-c(1,1)
update.attribute[5:6,3]&lt;-c(1,1)
update.attribute[7:8,4]&lt;-c(1,1)

# specify starting values for attribute parameters in each of M=20 runs
# for parameters with update.attribute==0 starting values are constrained to 1e-6
# for parameters with update.attribute==1 starting values are sampled from a unif(0,1)
start.attribute&lt;-array(runif(8*4*20),c(8,4,20))
start.attribute[update.attribute%o%rep(1,20)==0]&lt;-1e-6 

# estimate the constrained model
anger.LCplfm.constr&lt;-LCplfm(data=anger$data,F=4, T=2, M=20, 
                     update.attributeparameters=update.attribute,
                     start.attributeparameters=start.attribute)

# estimate a disjunctive LCplfm model with F=4 and T=2
# assume constant situation-feature classifications
# class-specific situation and bahavior parameters (i.e. model 3)
# use 20 exploratory runs with random starting points (M=20)
# constrain parameters of subsequent behavior pairs to "load"
# on only one feature

# specify which attribute parameters have to be estimated from the data
 
update.attribute&lt;-matrix(rep(0,8*4),ncol=4)
update.attribute[1:2,1]&lt;-c(1,1)
update.attribute[3:4,2]&lt;-c(1,1)
update.attribute[5:6,3]&lt;-c(1,1)
update.attribute[7:8,4]&lt;-c(1,1)
update.attribute&lt;-update.attribute%o%rep(1,2)

# specify starting values for attribute parameters in each of M=20 runs
# for parameters with update.attribute==0 starting values are constrained to 1e-6
# for parameters with update.attribute==1 starting values are sampled from a unif(0,1)
start.attribute&lt;-array(runif(8*4*2*20),c(8,4,2,20))
start.attribute[update.attribute%o%rep(1,20)==0]&lt;-1e-6 

# estimate the constrained model
anger.LCplfm.m3.constr&lt;-LCplfm(data=anger$data,F=4, T=2, M=20, model=3, 
                     update.attributeparameters=update.attribute,
                     start.attributeparameters=start.attribute)


## End(Not run)

## Not run: 
# example 2: analysis of car perception data

# load car data
data(car)

# estimate a disjunctive LCplfm with F=3 and T=2
# assume constant attribute-feature classification
# and class-specific car parameters (i.e. model 4)
# use 10 exploratory runs with random starting points 
car.LCplfm.disj&lt;-LCplfm(data=car$data3w,F=3, T=2, M=10,model=4)

# print the output of the model 
print(car.LCplfm.disj)

# estimate an additive LCplfm with F=3 and T=2
# assume constant attribute-feature classification
# and class-specific car parameters (i.e. model 4)
# use 10 exploratory runs with random starting points 
car.LCplfm.add&lt;-LCplfm(data=car$data3w,F=3, T=2, M=10, model=4, maprule="add")

# print the output of the model 
print(car.LCplfm.add)


## End(Not run)

## Not run: 

# example 3: estimation of multiple classification latent class 
# model (Maris, 1999) for cognitive diagnosis


# load subtraction data
library(CDM)
data(fraction.subtraction.data)
data(fraction.subtraction.qmatrix)


# create three-way data as input for LCplfm
I&lt;-536
J&lt;-1
K&lt;-20
data3w&lt;-array(c(as.matrix(fraction.subtraction.data)),c(I,J,K))

# add item labels

itemlabel&lt;-c("5/3 - 3/4", 
"3/4 - 3/8", 
"5/6 - 1/9",
"3 1/2 - 2 3/2", 
"4 3/5 - 3 4/10", 
"6/7 - 4/7", 
"3 - 2 1/5", 
"2/3 - 2/3", 
"3 7/8 - 2", 
"4 4/12 - 2 7/12", 
"4 1/3 - 2 4/3", 
"1 1/8 - 1/8", 
"3 3/8 - 2 5/6", 
"3 4/5 - 3 2/5", 
"2 - 1/3", 
"4 5/7 - 1 4/7", 
"7 3/5 - 4/5", 
"4 1/10 - 2 8/10", 
"4 - 1 4/3", 
"4 1/3 - 1 5/3") 

dimnames(data3w)[[3]]&lt;-itemlabel

# estimate multiple classification latent class model (Maris, 1999)

set.seed(537982)
subtract.m1.lst&lt;-stepLCplfm(data3w,minF=3,maxF=5,minT=1,maxT=3,model=1,M=20,maprule="conj")


# print BIC values
sumar&lt;-summary(subtract.m1.lst)
as.matrix(sort(sumar[,5]))

# print output best model
subtract.m1.lst[[5,2]]

# correlation between extracted skills and qmatrix
round(cor(fraction.subtraction.qmatrix,subtract.m1.lst[[5,2]]$attpar),2)

## End(Not run)
</code></pre>

<hr>
<h2 id='plfm'>Probabilistic latent feature analysis of two-way two-mode frequency data</h2><span id='topic+plfm'></span>

<h3>Description</h3>

<p>Computation of parameter estimates, standard errors, criteria for model selection, and goodness-of-fit criteria for 
disjunctive, conjunctive or additive probabilistic latent feature models with <em>F</em> features.</p>


<h3>Usage</h3>

<pre><code class='language-R'>plfm(data,object,attribute,rating,freq1,freqtot,F,
     datatype="freq",maprule="disj",M=5,emcrit1=1e-2,
     emcrit2=1e-10,printrun=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plfm_+3A_data">data</code></td>
<td>
<p> A data frame that consists of three components: the variables 
<code>object</code>, <code>attribute</code> and <code>rating</code>. Each row of the data frame describes the outcome of a binary rater judgement
about the association between a certain object and a certain attribute.</p>
</td></tr> 
<tr><td><code id="plfm_+3A_object">object</code></td>
<td>
<p>The name of the <code>object</code> component in the data frame <code>data</code>. The values of the vector <code>data$object</code> should be (non-missing) numeric or character values.</p>
</td></tr>
<tr><td><code id="plfm_+3A_attribute">attribute</code></td>
<td>
<p>The name of the <code>attribute</code> component in the data frame <code>data</code>. The values of the vector <code>data$attribute</code> should be (non-missing) numeric or character values.</p>
</td></tr>
<tr><td><code id="plfm_+3A_rating">rating</code></td>
<td>
<p>The name of the <code>rating</code> component in the data frame <code>data</code>. The elements of the vector <code>data$rating</code> should be the numeric values 0 (no association) or 1 (association), 
or should be specified as missing (NA).</p>
</td></tr>
<tr><td><code id="plfm_+3A_freq1">freq1</code></td>
<td>
<p>A <em>J X K</em> matrix of observed association frequencies.</p>
</td></tr>
<tr><td><code id="plfm_+3A_freqtot">freqtot</code></td>
<td>
<p>A <em>J X K</em> matrix with the total number of binary ratings in each cell <em>(j,k)</em>. If the total number of ratings is the same for all cells of the matrix 
it is sufficient to enter a single numeric value rather than a matrix. For instance, if <em>N</em> raters have judged <em>J X K</em> associations, one may specify <code>freqtot</code><em>=N</em></p>
</td></tr>
<tr><td><code id="plfm_+3A_f">F</code></td>
<td>
<p>The number of latent features included in the model.</p>
</td></tr>
<tr><td><code id="plfm_+3A_datatype">datatype</code></td>
<td>
<p>The type of data used as input. When <code>datatype</code>=&quot;freq&quot; one should specify frequency data <code>freq1</code> and <code>freqtot</code>, and when <code>datatype</code>=&quot;dataframe&quot; one should 
specify the name of the data frame <code>data</code>, and its components, <code>object</code>, <code>attribute</code> and <code>rating</code>.</p>
</td></tr>
<tr><td><code id="plfm_+3A_maprule">maprule</code></td>
<td>
<p>Disjunctive (<code>maprule</code>=&quot;disj&quot;),  conjunctive (<code>maprule</code>=&quot;conj&quot;) or additive (<code>maprule</code>=&quot;add&quot;) mapping rule of the probabilistic latent feature model.</p>
</td></tr>
<tr><td><code id="plfm_+3A_m">M</code></td>
<td>
<p>The number of times a particular model is estimated using random starting points.</p>
</td></tr>
<tr><td><code id="plfm_+3A_emcrit1">emcrit1</code></td>
<td>
<p>Convergence criterion which indicates when the estimation algorithm should switch from Expectation-Maximization (EM) steps to EM+Newton-Rhapson steps.</p>
</td></tr>
<tr><td><code id="plfm_+3A_emcrit2">emcrit2</code></td>
<td>
<p>Convergence criterion which indicates final convergence to a local maximum.</p>
</td></tr>
<tr><td><code id="plfm_+3A_printrun">printrun</code></td>
<td>
<p><code>printrun</code>=TRUE prints the analysis type (disjunctive, conjunctive or additive), the number of features (<em>F</em>) and the number of the run to the output screen, whereas 
<code>printrun</code>=FALSE suppresses the printing.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><em>Estimation</em>
</p>
<p>The function <code><a href="#topic+plfm">plfm</a></code> uses an accelerated EM-algorithm to locate the posterior mode(s) of the probabilistic latent feature model. 
The algorithm starts with a series of Expectation-Maximization (EM) steps until the difference between subsequent values of the 
logarithm of the posterior density becomes smaller than the convergence criterion <code>emcrit1</code>, and then switches to an accelerated algorithm which 
consists of EM + Newton-Rhapson steps. The accelerated algorithm stops when  the difference between subsequent values of the 
logarithm of the posterior density becomes smaller than the convergence criterion <code>emcrit2</code>.  
Computational details about the implementation of the EM-steps for PLFMs are described in Maris, De Boeck, and Van Mechelen (1996). 
The general scheme of the accelerated algorithm is described in Louis (1982) and Tanner (1996). Computational details about implementing the accelerated algorithm 
for PLFMs are described in Meulders (2013).
</p>
<p>When using the function <code><a href="#topic+plfm">plfm</a></code> to estimate a particular PLFM (i.e. with a certain number of latent features and specific mapping rule), 
one may locate the distinct posterior mode(s) by running the algorithm <code>M</code> times using random starting points. The estimated object-and attribute parameters of 
each run are stored in the objects <code>objpar.runs</code> and <code>attpar.runs</code> of the output list. Next, a number of additional statistics 
(estimated object- and attribute parameters, asymptotic standard errors of object- and attribute parameters, model selecion criteria and goodness-of-fit measures) 
are computed for the best model (i.e. the model among <code>M</code> runs with the highest posterior density).
</p>
<p><em>Model selection criteria and goodness-of-fit measures</em>
</p>
<p>To choose among models with different numbers of features, or with different mapping rules, 
one may use information criteria such as the Akaike Information Criterion (AIC, Akaike, 1973, 1974),
or the Schwarz Bayesian Information Criterion (BIC, Schwarz, 1978). AIC and BIC are computed as <em>-2*loglikelihood+k*Npar</em>.
For AIC <em>k</em> equals 2 and for BIC <em>k</em> equals <em>log(N)</em>, with <em>N</em> the observed number of replications 
for which object-attribute associations are collected. <em>Npar</em> represents the number of model parameters; 
for probabilistic latent feature models this equals <em>(J+K)F</em>. Models with the lowest value for AIC or BIC should be selected.
</p>
<p>To assess the statistical fit of the probabilistic feature model one may use a Pearson chi-square measure 
on the <em>J X K</em> frequency table to evaluate whether predicted 
frequencies deviate significantly from observed frequencies (see Meulders et al., 2001). In addition, one may assess the descriptive fit of the model 
using the correlation between observed and expected frequencies in the <em>J X K</em> table, 
and the proportion of the variance in the observed frequencies accounted for by the model (VAF)
(i.e. the squared correlation between observed and expected frequencies).
</p>
<p>The model selection criteria AIC and BIC, the results of the Pearson goodness-of fit test, 
and the descriptive fit measures (correlation observed and expected frequencies, and VAF) are stored in the object <code>fitmeasures</code> of the output list
</p>


<h3>Value</h3>

<table>
<tr><td><code>call</code></td>
<td>
<p>Parameters used to call the function.</p>
</td></tr>
<tr><td><code>objpar</code></td>
<td>
<p>A <em>J X F</em> matrix of object parameters.</p>
</td></tr>
<tr><td><code>attpar</code></td>
<td>
<p>A <em>K X F</em> matrix of attribute parameters.</p>
</td></tr>
<tr><td><code>fitmeasures</code></td>
<td>
<p>A list of model selection criteria and goodness-of-fit criteria for the model with the highest posterior density.</p>
</td></tr>
<tr><td><code>logpost.runs</code></td>
<td>
<p>A list with the logarithm of the posterior density for each of the <em>M</em> computed models.</p>
</td></tr>
<tr><td><code>objpar.runs</code></td>
<td>
<p>A <em>M X J X F</em> array which contains the object parameters for each of the <em>M</em> computed models.</p>
</td></tr>
<tr><td><code>attpar.runs</code></td>
<td>
<p>A <em>M X K X F</em> array which contains the attribute parameters for each of the <em>M</em> computed models.</p>
</td></tr>
<tr><td><code>bestsolution</code></td>
<td>
<p>An index which indicates the model with the highest posterior density among each of the <em>M</em> computed models.</p>
</td></tr>
<tr><td><code>gradient.objpar</code></td>
<td>
<p>A <em>J X F</em> gradient matrix for the object parameters in the best solution.</p>
</td></tr>
<tr><td><code>gradient.attpar</code></td>
<td>
<p>A <em>K X F</em> gradient matrix for the attribute parameters in the best solution.</p>
</td></tr>
<tr><td><code>SE.objpar</code></td>
<td>
<p>A <em>J X F</em> matrix of asymptotic standard errors for the object parameters in the best solution.</p>
</td></tr>
<tr><td><code>SE.attpar</code></td>
<td>
<p>A <em>K X F</em> matrix of asymptotic standard errors for the attribute parameters in the best solution.</p>
</td></tr>
<tr><td><code>prob1</code></td>
<td>
<p>A <em>J X K</em> matrix of expected association probabilities for the best solution.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michel Meulders
</p>


<h3>References</h3>

<p>Akaike, H. (1973). Information theory and an extension of the maximum likelihood
principle. In B. N. Petrov and F. Csaki (Eds.), <em>Second international symposium on
information theory</em> (p. 271-283). Budapest: Academiai Kiado.
</p>
<p>Akaike, H. (1974). A new look at the statistical model identification. <em>IEEE Transactions
on Automatic Control, 19</em>, 716-723.
</p>
<p>Candel, M. J. J. M., and Maris, E. (1997). Perceptual analysis of two-way two-mode
frequency data: probability matrix decomposition and two alternatives.
<em>International Journal of Research in Marketing, 14</em>, 321-339.
</p>
<p>Louis, T. A. (1982). Finding observed information using the em algorithm. <em>Journal of the
Royal Statistical Society, Series B, 44</em>, 98-130.
</p>
<p>Maris, E., De Boeck, P., and Van Mechelen, I. (1996). Probability matrix decomposition models. <em>Psychometrika, 61</em>, 7-29.
</p>
<p>Meulders, M., De Boeck, P., and Van Mechelen, I. (2001). Probability matrix decomposition
models and main-effects generalized linear models for the analysis of replicated
binary associations. <em>Computational Statistics and Data Analysis, 38</em>, 217-233.
</p>
<p>Meulders, M., De Boeck, P., Van Mechelen, I., Gelman, A., and Maris, E. (2001). Bayesian inference with probability matrix decomposition models. 
<em>Journal of Educational and Behavioral Statistics, 26</em>, 153-179.
</p>
<p>Meulders, M., De Boeck, P., Van Mechelen, I., and Gelman, A. (2005). Probabilistic feature analysis of facial perception of emotions. 
<em>Applied Statistics, 54</em>, 781-793.
</p>
<p>Meulders, M. and De Bruecker, P. (2018). Latent class probabilistic latent feature analysis of three-way three-mode binary data. 
<em>Journal of Statistical Software, 87(1)</em>, 1-45.
</p>
<p>Meulders, M. (2013). An R Package for Probabilistic Latent Feature Analysis of Two-Way Two-Mode Frequencies. <em>Journal of Statistical Software, 54(14)</em>, 1-29. 
URL http://www.jstatsoft.org/v54/i14/.
</p>
<p>Tanner, M. A. (1996). <em>Tools for statistical inference: Methods for the exploration of
posterior distributions and likelihood functions</em> (Third ed.). New York:
Springer-Verlag.
</p>
<p>Schwarz, G. (1978). Estimating the dimensions of a model. <em>Annals of Statistics, 6</em>, 461-464.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gendat">gendat</a></code>, <code><a href="#topic+print.plfm">print.plfm</a></code>, 
<code><a href="#topic+summary.plfm">summary.plfm</a></code>, <code><a href="#topic+print.summary.plfm">print.summary.plfm</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
## example 1: Analysis of data generated under the model

# define constants
J&lt;-20
K&lt;-15
F&lt;-2

# generate true parameters
set.seed(43565)
objectparameters&lt;-matrix(runif(J*F),nrow=J)
attributeparameters&lt;-matrix(runif(K*F),nrow=K)

# generate data for disjunctive model using N=200 replications
gdat.disj&lt;-gendat(maprule="disj",N=200,
              objpar=objectparameters,attpar=attributeparameters)

# Estimate a disjunctive probabilistic latent feature model with 2 features
# suppress printing the type of analysis to the output screen
disj2&lt;-plfm(maprule="disj",freq1=gdat.disj$freq1,freqtot=200,F=2,M=1,printrun=FALSE)

# generate data for an additive model using N=200 replications
gdat.add&lt;-gendat(maprule="add",N=200,
              objpar=objectparameters,attpar=attributeparameters)

# Estimate an additive probabilistic latent feature model with 2 features
# suppress printing the type of analysis to the output screen
add2&lt;-plfm(maprule="add",freq1=gdat.add$freq1,freqtot=200,F=2,M=1,printrun=FALSE)

## End(Not run)


## Not run: 
# example 2:Perceptual analysis of associations between car models and car attributes

# load car data
data(car)

# compute 1 run of a disjunctive model with 4 features
# use components of a data frame as input
cardisj4&lt;-plfm(datatype="dataframe",data=car$datalongformat,object=objectlabel,
               attribute=attributelabel,rating=rating,maprule="disj",F=4,M=1)

# print the output of a disjunctive 4-feature model  
# for data on the perception of car models
print (cardisj4)


# print a summary of the output of a disjunctive 4-feature model  
# for data on the perception of car models
sumcardisj4&lt;-summary(cardisj4)
sumcardisj4

## End(Not run)

## Not run: 
# example 3: analysis on determinants of anger-related behavior

# load anger data
data(anger)

# compute 1 run of a disjunctive model with 2 features
# use frequency data as input
angerdisj2&lt;-plfm(maprule="disj",freq1=anger$freq1,freqtot=anger$freqtot,F=2,M=1)


# print the output of a disjunctive 2-feature model 
# for data on the situational determinants of anger-related behaviors
print (angerdisj2)


# print a summary of the output of a disjunctive 2-feature model 
# for data on the situational determinants of anger-related behaviors
sumangerdisj2&lt;-summary(angerdisj2)
sumangerdisj2

## End(Not run)


</code></pre>

<hr>
<h2 id='plfm-package'>Probabilistic Latent Feature Analysis</h2><span id='topic+plfm-package'></span>

<h3>Description</h3>

<p>Functions for estimating disjunctive, conjunctive or additive probabilistic latent feature models on (aggregated) binary three-way data
</p>


<h3>Details</h3>

<p>Probabilistic latent feature models can be used to model three-way three-mode binary observations (e.g. persons who indicate for each of a number of products and for each of 
a set of attributes whether a product has a certain attribute). A basic probabilistic feature model (referred to as <code><a href="#topic+plfm">plfm</a></code>) uses aggregated three-way three-mode binary 
data as input, namely the two-way two-mode frequency table that is obtained by summing the binary three-way three-mode data across persons. The basic probabilistic feature model 
(Maris, De Boeck and Van Mechelen, 1996) is based
on the assumption that observations are statistically independent and that model parameters are homogeneous across persons. The <code><a href="#topic+plfm">plfm</a></code> function can be used to locate 
the posterior mode(s) of basic probabilistic feature models, and to compute information criteria for model selection, and measures of statistical and descriptive model fit. 
The <code><a href="#topic+stepplfm">stepplfm</a></code> function can be used to fit a series of disjunctive, conjunctive or additive basic probabilistic feature models with different number of latent features. 
In addition, the <code><a href="#topic+bayesplfm">bayesplfm</a></code> function can be used to compute a sample of the posterior distribution of the basic probabilistic feature model 
in the neigbourhood of a specific posterior mode.
</p>
<p>Latent class extensions of the probabilistic feature model (referred to as <code><a href="#topic+LCplfm">LCplfm</a></code>) take binary three-way three-mode observations as input. In contrast to the basic probabilistic 
feature model, latent class probabilistic feature models allow to model dependencies between (subsets of) observations (Meulders, De Boeck and Van Mechelen, 2003) 
and/or to account for heterogeneity in model parameters across persons (Meulders, Tuerlinckx, and Vanpaemel, 2013).
The <code><a href="#topic+LCplfm">LCplfm</a></code> function can be used to compute posterior mode estimates (of different types of) latent class probabilistic 
feature models as well as to compute information criteria for model selection, and measures of descriptive model fit. The <code><a href="#topic+stepLCplfm">stepLCplfm</a></code> function can be used to compute a series of
latent class probabilistic feature models with different numbers of latent features and latent classes.
</p>
<p>To see the preferable citation of the package, type citation(&quot;plfm&quot;).
</p>


<h3>Author(s)</h3>

<p>Michel Meulders 
</p>
<p>Maintainer: &lt;michel.meulders@kuleuven.be&gt;
</p>


<h3>References</h3>

<p>Candel, M. J. J. M., and Maris, E. (1997). Perceptual analysis of two-way two-mode
frequency data: probability matrix decomposition and two alternatives.
<em>International Journal of Research in Marketing, 14</em>, 321-339.
</p>
<p>Gelman, A., Van Mechelen, I., Verbeke, G., Heitjan, D. F., and Meulders, M. (2005). 
Multiple imputation for model checking: Completed-data plots with missing and latent data. 
<em>Biometrics, 61</em>, 74-85. 
</p>
<p>Maris, E., De Boeck, P., and Van Mechelen, I. (1996). Probability matrix decomposition models. <em>Psychometrika, 61</em>, 7-29.
</p>
<p>Meulders, M. (2013). An R Package for Probabilistic Latent Feature Analysis of Two-Way Two-Mode Frequencies. <em>Journal of Statistical Software, 54(14)</em>, 1-29. 
URL http://www.jstatsoft.org/v54/i14/.
</p>
<p>Meulders, M., De Boeck, P., Kuppens, P., and Van Mechelen, I. (2002). Constrained latent
class analysis of three-way three-mode data. <em>Journal of Classification, 19</em>, 277-302.
</p>
<p>Meulders, M., De Boeck, P., and Van Mechelen, I. (2001). Probability matrix decomposition
models and main-effects generalized linear models for the analysis of replicated
binary associations. <em>Computational Statistics and Data Analysis, 38</em>, 217-233.
</p>
<p>Meulders, M., De Boeck, P., and Van Mechelen, I. (2003). A taxonomy of latent structure
assumptions for probability matrix decomposition models. <em>Psychometrika, 68</em>, 61-77.
</p>
<p>Meulders, M., De Boeck, P., Van Mechelen, I., and Gelman, A. (2005). Probabilistic feature analysis of facial perception of emotions. 
<em>Applied Statistics, 54</em>, 781-793.
</p>
<p>Meulders, M., De Boeck, P., Van Mechelen, I., Gelman, A., and Maris, E. (2001). Bayesian inference with probability matrix decomposition models. 
<em>Journal of Educational and Behavioral Statistics, 26</em>, 153-179.
</p>
<p>Meulders, M. and De Bruecker, P. (2018). Latent class probabilistic latent feature analysis of three-way three-mode binary data. 
<em>Journal of Statistical Software, 87(1)</em>, 1-45.
</p>
<p>Meulders, M., Gelman, A., Van Mechelen, I., and De Boeck P. (1998). Generalizing the probability matrix decomposition model: 
An example of Bayesian model checking and model expansion. 
In J. Hox, and E. De Leeuw (Eds.), <em>Assumptions, robustness, and estimation methods in multivariate modeling</em> (pp. 1-19). 
TT Publicaties: Amsterdam.
</p>
<p>Meulders, M., Tuerlinckx, F., and Vanpaemel, W. (2013). Constrained multilevel latent class models for the analysis of three-way three-mode binary data. 
<em>Journal of Classification, 30 (3)</em>, 306-337.
</p>

<hr>
<h2 id='plot.LCplfm'>plot parameters in <code><a href="#topic+LCplfm">LCplfm</a></code> object</h2><span id='topic+plot.LCplfm'></span>

<h3>Description</h3>

<p>Plot method to visualize the parameters  of latent class probabilistic feature models with different numbers of features/classes.</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'LCplfm'
plot(x, feature=1, class=0, element="object", cexsymb=1, cexlabel=1,
                      minpositionlabel = -1, positionlabel = -0.8, xlegend = "topright", 
                      ylegend=NULL, x.intersplegend=1, y.intersplegend=1, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.LCplfm_+3A_x">x</code></td>
<td>
<p>Latent class probabilistic feature model object returned by <code><a href="#topic+LCplfm">LCplfm</a></code>.</p>
</td></tr>
<tr><td><code id="plot.LCplfm_+3A_feature">feature</code></td>
<td>
<p>Latent feature for which parameters are visualized.</p>
</td></tr>
<tr><td><code id="plot.LCplfm_+3A_class">class</code></td>
<td>
<p>Latent class for which parameters are visualized. When the model contains class-specific object- or attribute parameters, <code>class=0</code> means that parameters of 
all classes are included in the plot.</p>
</td></tr>
<tr><td><code id="plot.LCplfm_+3A_element">element</code></td>
<td>
<p>Object parameters are plotted if <code>element</code>=&quot;object&quot; and attribute parameters are plotted if <code>element</code>=&quot;attribute&quot;.</p>
</td></tr>
<tr><td><code id="plot.LCplfm_+3A_cexsymb">cexsymb</code></td>
<td>
<p>Size of symbol used for plotting points.</p>
</td></tr>
<tr><td><code id="plot.LCplfm_+3A_cexlabel">cexlabel</code></td>
<td>
<p>Size of object- or attribute labels in plot.</p>
</td></tr>
<tr><td><code id="plot.LCplfm_+3A_minpositionlabel">minpositionlabel</code></td>
<td>
<p>Value smaller than 0 that defines space for plotting object- or attribute labels.</p>
</td></tr>
<tr><td><code id="plot.LCplfm_+3A_positionlabel">positionlabel</code></td>
<td>
<p>Value between <code>minpositionlabel</code> and 0 to align object- or attribute labels.</p>
</td></tr>
<tr><td><code id="plot.LCplfm_+3A_xlegend">xlegend</code>, <code id="plot.LCplfm_+3A_ylegend">ylegend</code></td>
<td>
<p>The x and y co-ordinates to be used to position the legend. They can be specified by keyword or in 
any way which is accepted by xy.coords: See &quot;Details&quot; of legend.</p>
</td></tr>
<tr><td><code id="plot.LCplfm_+3A_x.intersplegend">x.intersplegend</code></td>
<td>
<p>Character interspacing factor for horizontal (x) spacing in legend.</p>
</td></tr>
<tr><td><code id="plot.LCplfm_+3A_y.intersplegend">y.intersplegend</code></td>
<td>
<p>Character interspacing factor for vertical (y) line distances in legend.</p>
</td></tr>
<tr><td><code id="plot.LCplfm_+3A_...">...</code></td>
<td>
<p>Further arguments are ignored.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
# example 1: analysis on determinants of anger-related behavior

# load anger data
data(anger)

# compute 5 runs of disjunctive latent class probabilistic feature model
# with 4 features and 2 latent classes
# assume constant situation classification per person 
# and class-specific situation parameters (i.e. model=1) 

anger.m1&lt;-LCplfm(data=anger$data,F=4,T=2,maprule="disj",
                  M=5,emcrit1=1e-3,emcrit2=1e-8,model=1)

# visualize object and attribute parameters 
# of both classes per feature in one figure

par(mfrow=c(2,2),pty="s")
plot(anger.m1,element="attribute",feature=1, main="Feature 1", 
     minpositionlabel=-2, positionlabel=-1)
plot(anger.m1,element="attribute",feature=2, main="Feature 2", 
     minpositionlabel=-2, positionlabel=-1)
plot(anger.m1,element="attribute",feature=3, main="Feature 3", 
     minpositionlabel=-2, positionlabel=-1)
plot(anger.m1,element="attribute",feature=4, main="Feature 4", 
     minpositionlabel=-2, positionlabel=-1)

par(mfrow=c(2,2),pty="s")
plot(anger.m1,element="object",feature=1,main="Feature 1", 
     minpositionlabel=-1.5, positionlabel=-1, y.intersplegend=0.7)
plot(anger.m1,element="object",feature=2,main="Feature 2", 
     minpositionlabel=-1.5, positionlabel=-1, y.intersplegend=0.7)
plot(anger.m1,element="object",feature=3,main="Feature 3", 
     minpositionlabel=-1.5, positionlabel=-1, y.intersplegend=0.7)
plot(anger.m1,element="object",feature=4,main="Feature 4", 
     minpositionlabel=-1.5, positionlabel=-1, y.intersplegend=0.7)

# compute 5 runs of disjunctive latent class probabilistic feature model
# with 2 features and 2 latent classes
# assume constant situation classification per person 
# and class-specific situation and behavior parameters (i.e. model=3) 

anger.m3&lt;-LCplfm(data=anger$data,F=2,T=2,maprule="disj",
                  M=5,emcrit1=1e-3,emcrit2=1e-8,model=3)

# visualize object and attribute parameters of feature 1,2 
# for class 1
par(mfrow=c(2,2)) 
plot(anger.m3,element="attribute",feature=1, class=1,main="Feature 1, class 1", 
     minpositionlabel=-2, positionlabel=-1)
plot(anger.m3,element="attribute",feature=2, class=1,main="Feature 2, class 1", 
     minpositionlabel=-2, positionlabel=-1)
plot(anger.m3,element="object",feature=1, class=1,main="Feature 1, class 1", 
     minpositionlabel=-2, positionlabel=-1)
plot(anger.m3,element="object",feature=2, class=1,main="Feature 2, class 1", 
     minpositionlabel=-2, positionlabel=-1)


# visualize object and attribute parameters of feature 1,2 
# for class 2
par(mfrow=c(2,2))
plot(anger.m3,element="attribute",feature=1, class=2,main="Feature 1, class 2", 
     minpositionlabel=-1.7, positionlabel=-1, y.intersplegend=0.7)
plot(anger.m3,element="attribute",feature=2, class=2,main="Feature 2, class 2", 
     minpositionlabel=-1.7, positionlabel=-1, y.intersplegend=0.7)
plot(anger.m3,element="object",feature=1, class=2,main="Feature 1, class 2", 
     minpositionlabel=-1.7, positionlabel=-1, y.intersplegend=0.7)
plot(anger.m3,element="object",feature=2, class=2,main="Feature 2, class 2", 
     minpositionlabel=-1.7, positionlabel=-1, y.intersplegend=0.7)


## End(Not run)
</code></pre>

<hr>
<h2 id='plot.plfm'>plot parameters in <code><a href="#topic+plfm">plfm</a></code> object</h2><span id='topic+plot.plfm'></span>

<h3>Description</h3>

<p>Plot method to visualize the parameters  of probabilistic feature models.</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'plfm'
plot(x,feature=1,element="object",cexsymb=1,cexlabel=1,...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.plfm_+3A_x">x</code></td>
<td>
<p>Probabilistic feature model object returned by <code><a href="#topic+plfm">plfm</a></code>.</p>
</td></tr>
<tr><td><code id="plot.plfm_+3A_feature">feature</code></td>
<td>
<p>Latent feature for which parameters are visualized.</p>
</td></tr>
<tr><td><code id="plot.plfm_+3A_element">element</code></td>
<td>
<p>Object parameters are plotted if <code>element</code>=&quot;object&quot; and attribute parameters are plotted if <code>element</code>=&quot;attribute&quot;.</p>
</td></tr>
<tr><td><code id="plot.plfm_+3A_cexsymb">cexsymb</code></td>
<td>
<p>Size of symbol used for plotting points.</p>
</td></tr>
<tr><td><code id="plot.plfm_+3A_cexlabel">cexlabel</code></td>
<td>
<p>Size of object- or attribute labels in plot.</p>
</td></tr>
<tr><td><code id="plot.plfm_+3A_...">...</code></td>
<td>
<p>Further arguments are ignored.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>
# examples


## Not run: 
# example 1:Perceptual analysis of associations between car models and car attributes

# load car data
data(car)

# compute 1 run of a disjunctive model with 4 features
# use components of a data frame as input
cardisj4&lt;-plfm(datatype="dataframe",data=car$datalongformat,object=objectlabel,
               attribute=attributelabel,rating=rating,maprule="disj",F=4,M=1)

# plot car and attribute parameters per feature
par(mfrow=c(1,2))
plot(cardisj4,feature=1,element="object",main="Car parameters Feature 1")
plot(cardisj4,feature=1,element="attribute",main="Attribute parameters Feature 1")

par(mfrow=c(1,2))
plot(cardisj4,feature=2,element="object",main="Car parameters Feature 2")
plot(cardisj4,feature=2,element="attribute",main="Attribute parameters Feature 2")

par(mfrow=c(1,2))
plot(cardisj4,feature=3,element="object",main="Car parameters Feature 3")
plot(cardisj4,feature=3,element="attribute",main="Attribute parameters Feature 3")

par(mfrow=c(1,2))
plot(cardisj4,feature=4,element="object",main="Car parameters Feature 4")
plot(cardisj4,feature=4,element="attribute",main="Attribute parameters Feature 4")

## End(Not run)



par(mfrow=c(1,2))

# example 2: analysis on determinants of anger-related behavior

# load anger data
data(anger)

# compute 1 run of a disjunctive model with 4 features
# use frequency data as input
angerdisj2&lt;-plfm(maprule="disj",freq1=anger$freq1,freqtot=anger$freqtot,F=2,M=1)

# plot situation and behavior parameters
par(mfrow=c(2,2))
for (f in 1:2){
plot(angerdisj2,feature=f,element="object",main=paste("Situation parameters Feature",f,sep=" "))}
for (f in 1:2){
plot(angerdisj2,feature=f,element="attribute",main=paste("Behavior parameters Feature",f,sep=" "))}

</code></pre>

<hr>
<h2 id='plot.stepLCplfm'>Plot fit of <code><a href="#topic+stepLCplfm">stepLCplfm</a></code> objects</h2><span id='topic+plot.stepLCplfm'></span>

<h3>Description</h3>

<p>Plot method to visualize the fit of latent class probabilistic feature models with different numbers of features/classes.</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'stepLCplfm'
plot(x,which="BIC",...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.stepLCplfm_+3A_x">x</code></td>
<td>
<p>List of latent class probabilistic latent feature analysis objects returned by <code><a href="#topic+stepLCplfm">stepLCplfm</a></code>.</p>
</td></tr>
<tr><td><code id="plot.stepLCplfm_+3A_which">which</code></td>
<td>
<p>Fit criterion for which models with different numbers of features are compared. 
The argument <code>which</code> can take the following values: 
&quot;AIC&quot;, &quot;BIC&quot;, &quot;Deviance&quot;, &quot;Correlation&quot;, &quot;VAF&quot;</p>
</td></tr>
<tr><td><code id="plot.stepLCplfm_+3A_...">...</code></td>
<td>
<p>Further arguments are ignored.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
# example 1: analysis on determinants of anger-related behavior

# load anger data
data(anger)

# compute 5 runs of disjunctive latent class probabilistic feature models
# with 1 up to 3 features and with 1 up to 2 latent classes
# assume constant situation classification per person 
# and class-specific situation parameters (i.e. model=1) 

anger.lst&lt;-stepLCplfm(minF=1,maxF=3,minT=1,maxT=2,data=anger$data,
                      maprule="disj",M=5,emcrit1=1e-3,emcrit2=1e-8,model=1)


# visualize BIC of fitted models 

par(pty="s")
plot(anger.lst)

# print overview fit measures for all estimated models

anger.lst

# print model with 3 features and 1 latent class

anger.lst[[3,1]]

## End(Not run)

## Not run: 
# example 2:Perceptual analysis of associations between car models and car attributes

# load car data
data(car)


# compute 5 runs of disjunctive models with 4 features and 1 up to 3 latent classes
# assume constant attribute classification per respondent 
# and class-specific car parameters (i.e. model 4)

car.lst&lt;-stepLCplfm(minF=4,maxF=4,minT=1,maxT=3,data=car$data3w,
                      maprule="disj",M=5,emcrit1=1e-3,emcrit2=1e-8,model=4,printrun=TRUE)


# visualize BIC of fitted models
plot(car.lst)

# print overview of fitmeasures for all fitted models
car.lst

## End(Not run)
</code></pre>

<hr>
<h2 id='plot.stepplfm'>Plot fit of <code><a href="#topic+stepplfm">stepplfm</a></code> objects</h2><span id='topic+plot.stepplfm'></span>

<h3>Description</h3>

<p>Plot method to visualize the fit of probabilistic latent feature analysis objects with different numbers of features.</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'stepplfm'
plot(x,which="BIC",...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.stepplfm_+3A_x">x</code></td>
<td>
<p>List of probabilistic latent feature analysis objects returned by <code><a href="#topic+stepplfm">stepplfm</a></code>.</p>
</td></tr>
<tr><td><code id="plot.stepplfm_+3A_which">which</code></td>
<td>
<p>Fit criterion for which models with different numbers of features are compared. 
The argument <code>which</code> can take the following values: 
&quot;AIC&quot;, &quot;BIC&quot;, &quot;Deviance&quot;, &quot;Chisquare&quot;, &quot;Correlation&quot;, &quot;VAF&quot;</p>
</td></tr>
<tr><td><code id="plot.stepplfm_+3A_...">...</code></td>
<td>
<p>Further arguments are ignored.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
## example 1:Perceptual analysis of associations between car models and car attributes

##load car data
data(car)


## compute 5 runs of disjunctive and conjunctive models with 1 up to 4 features
car.lst&lt;-stepplfm(minF=1,maxF=4,maprule="disj/conj",freq1=car$freq1,
                  freqtot=car$freqtot,M=5)

## visualize the fit of models with different mapping rules 
## and a different number of features

par(pty="s")
par(mfrow=c(2,2))
plot(car.lst,which="BIC")
plot(car.lst,which="AIC")
plot(car.lst,which="VAF")


## End(Not run)

## Not run: 
## example 2: analysis on determinants of anger-related behavior

## load anger data
data(anger)

## compute 1 run of disjunctive and conjunctive models with 1 up to 3 features
anger.lst&lt;-stepplfm(minF=1,maxF=3,maprule="disj/conj",freq1=anger$freq1,
                    freqtot=anger$freqtot,M=1)

## visualize the fit of models with different mapping rules 
## and a different number of features

par(pty="s")
par(mfrow=c(2,2))
plot(anger.lst,which="BIC")
plot(anger.lst,which="AIC")
plot(anger.lst,which="VAF")

## End(Not run)

</code></pre>

<hr>
<h2 id='print.bayesplfm'>Printing  <code><a href="#topic+bayesplfm">bayesplfm</a></code> objects
</h2><span id='topic+print.bayesplfm'></span>

<h3>Description</h3>

<p>Printing method for objects generated by the <code><a href="#topic+bayesplfm">bayesplfm</a></code> function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'bayesplfm'
print(x,...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.bayesplfm_+3A_x">x</code></td>
<td>
<p>Object returned by <code><a href="#topic+bayesplfm">bayesplfm</a></code>.</p>
</td></tr>
<tr><td><code id="print.bayesplfm_+3A_...">...</code></td>
<td>
<p>Further arguments are ignored.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The printing method for Bayesian probabilistic latent feature analysis objects displays 
(1) the parameters used to call the <code><a href="#topic+bayesplfm">bayesplfm</a></code> function,
(2) the number of parameters that do not meet the convergence criterion   
(3) information on the descriptive fit of the model (i.e. correlation between observed and expected frequencies, 
and proportion of the variance in the observed frequencies accounted for by the model), 
and (4) the posterior mean of the object- and attribute parameters.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+bayesplfm">bayesplfm</a></code>,<code><a href="#topic+summary.bayesplfm">summary.bayesplfm</a></code>,<code><a href="#topic+print.summary.bayesplfm">print.summary.bayesplfm</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
##load car data
data(car)


## Compute a sample of the posterior distribution 
## for the disjunctive model with two features
## compute the starting point using plfm
carbayes2&lt;-bayesplfm(maprule="disj",freq1=car$freq1,freqtot=car$freqtot,F=2,
                      maxNiter=500,Nburnin=0,Nstep=100,Nchains=2,
                      start.bayes="best")


## print the object generated by bayesplfm
carbayes2

## End(Not run)

</code></pre>

<hr>
<h2 id='print.LCplfm'>Printing LCplfm objects</h2><span id='topic+print.LCplfm'></span>

<h3>Description</h3>

<p>Printing method for latent class probabilistic feature analysis objects.</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'LCplfm'
print(x,...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.LCplfm_+3A_x">x</code></td>
<td>
<p>Latent class probabilistic  feature analysis object returned by <code><a href="#topic+LCplfm">LCplfm</a></code>.</p>
</td></tr>
<tr><td><code id="print.LCplfm_+3A_...">...</code></td>
<td>
<p>Further arguments are ignored.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The printing method for latent class probabilistic  feature analysis objects displays 
(1) the parameters used to call the <code><a href="#topic+LCplfm">LCplfm</a></code> function, 
(2) the estimated object-, attribute- and class size parameters,
(3) the estimated standard errors of object-, attribute- and class size parameters,
(4) fit measures  
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# example 
print(LCplfm(data=anger$data,F=2, T=2, M=1))

## End(Not run)
</code></pre>

<hr>
<h2 id='print.plfm'>Printing plfm objects</h2><span id='topic+print.plfm'></span>

<h3>Description</h3>

<p>Printing method for probabilistic latent feature analysis objects.</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'plfm'
print(x,...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.plfm_+3A_x">x</code></td>
<td>
<p>Probabilistic latent feature analysis object returned by <code><a href="#topic+plfm">plfm</a></code>.</p>
</td></tr>
<tr><td><code id="print.plfm_+3A_...">...</code></td>
<td>
<p>Further arguments are ignored.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The printing method for probabilistic latent feature analysis objects displays 
(1) the parameters used to call the <code><a href="#topic+plfm">plfm</a></code> function, 
(2) information on the descriptive fit of the model (i.e. correlation between observed and expected frequencies, 
and proportion of the variance in the observed frequencies accounted for by the model), 
and (3) the estimated object- and attribute parameters.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## example print.plfm(plfm(...))
</code></pre>

<hr>
<h2 id='print.stepLCplfm'>Printing <code><a href="#topic+stepLCplfm">stepLCplfm</a></code> objects</h2><span id='topic+print.stepLCplfm'></span>

<h3>Description</h3>

<p>Printing method for a series of latent class probabilistic latent feature analysis objects.</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'stepLCplfm'
print(x,...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.stepLCplfm_+3A_x">x</code></td>
<td>
<p>Latent class probabilistic latent feature analysis object returned by <code><a href="#topic+stepLCplfm">stepLCplfm</a></code>.</p>
</td></tr>
<tr><td><code id="print.stepLCplfm_+3A_...">...</code></td>
<td>
<p>Further arguments are ignored.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The printing method for <code><a href="#topic+stepLCplfm">stepLCplfm</a></code> displays summary tables about the fit of models with different numbers of features and different numbers of latent classes. 
Two tables are printed which summarize the fit of models with different numbers of features/classes in terms of (1) information criteria (AIC, BIC,...), 
and (2) the descriptive fit of the model to the <em>JXK</em> 
frequency table (correlation between observed and expected frequencies, and variance accounted for by the model).
</p>


<h3>Examples</h3>

<pre><code class='language-R'># example print.stepLCplfm(stepLCplfm(...))
</code></pre>

<hr>
<h2 id='print.stepplfm'>Printing <code><a href="#topic+stepplfm">stepplfm</a></code> objects</h2><span id='topic+print.stepplfm'></span>

<h3>Description</h3>

<p>Printing method for a series of probabilistic latent feature analysis objects.</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'stepplfm'
print(x,...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.stepplfm_+3A_x">x</code></td>
<td>
<p>probabilistic latent feature analysis object returned by <code><a href="#topic+stepplfm">stepplfm</a></code>.</p>
</td></tr>
<tr><td><code id="print.stepplfm_+3A_...">...</code></td>
<td>
<p>Further arguments are ignored.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The printing method for <code><a href="#topic+stepplfm">stepplfm</a></code> displays summary tables about the fit of models with different numbers of features. 
For each mapping rule, three tables are printed which summarize the fit of models with different numbers of features in terms of (1) information criteria (AIC, BIC,...), 
(2) the statistical fit of the model to the <em>JXK</em> frequency table (Chi-square value, df and corresponding p-value), and (3) the descriptive fit of the model to the <em>JXK</em> 
frequency table (correlation between observed and expected frequencies, and variance accounted for by the model).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## example print.stepplfm(stepplfm(...))
</code></pre>

<hr>
<h2 id='print.summary.bayesplfm'>Printing summaries of Bayesian probabilistic latent feature analysis
</h2><span id='topic+print.summary.bayesplfm'></span>

<h3>Description</h3>

<p>Printing method for summaries of objects generated by <code><a href="#topic+summary.bayesplfm">summary.bayesplfm</a></code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'summary.bayesplfm'
print(x,...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.summary.bayesplfm_+3A_x">x</code></td>
<td>
<p>Summary of Bayesian probabilistic latent feature analysis returned 
by <code><a href="#topic+summary.bayesplfm">summary.bayesplfm</a></code></p>
</td></tr>
<tr><td><code id="print.summary.bayesplfm_+3A_...">...</code></td>
<td>
<p>Further arguments are ignored</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+summary.bayesplfm">summary.bayesplfm</a></code>, <code><a href="#topic+bayesplfm">bayesplfm</a></code>
</p>

<hr>
<h2 id='print.summary.plfm'>Printing summaries of probabilistic latent feature analysis objects</h2><span id='topic+print.summary.plfm'></span>

<h3>Description</h3>

<p>Printing method for summaries of probabilistic latent feature analysis objects.</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'summary.plfm'
print(x,...)</code></pre>


<h3>Arguments</h3>

<p>,
</p>
<table>
<tr><td><code id="print.summary.plfm_+3A_x">x</code></td>
<td>
<p>Summary of a probabilistic latent feature analysis object returned by <code><a href="#topic+summary.plfm">summary.plfm</a></code></p>
</td></tr>
<tr><td><code id="print.summary.plfm_+3A_...">...</code></td>
<td>
<p>Further arguments are ignored</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+plfm">plfm</a></code>, <code><a href="#topic+summary.plfm">summary.plfm</a></code>
</p>

<hr>
<h2 id='print.summary.stepLCplfm'>Printing summaries of <code><a href="#topic+stepLCplfm">stepLCplfm</a></code> objects</h2><span id='topic+print.summary.stepLCplfm'></span>

<h3>Description</h3>

<p>Printing method for summaries of <code><a href="#topic+stepLCplfm">stepLCplfm</a></code> objects.</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'summary.stepLCplfm'
print(x,digits=2,...)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.summary.stepLCplfm_+3A_x">x</code></td>
<td>
<p>Summary of a list of latent class probabilistic latent feature analysis objects returned by <code><a href="#topic+summary.stepLCplfm">summary.stepLCplfm</a></code>.</p>
</td></tr>
<tr><td><code id="print.summary.stepLCplfm_+3A_digits">digits</code></td>
<td>
<p>By default 2 significant digits are used for printing.</p>
</td></tr>
<tr><td><code id="print.summary.stepLCplfm_+3A_...">...</code></td>
<td>
<p>Further arguments are ignored.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+stepLCplfm">stepLCplfm</a></code>, <code><a href="#topic+summary.stepLCplfm">summary.stepLCplfm</a></code>
</p>

<hr>
<h2 id='print.summary.stepplfm'>Printing summaries of <code><a href="#topic+stepplfm">stepplfm</a></code> objects</h2><span id='topic+print.summary.stepplfm'></span>

<h3>Description</h3>

<p>Printing method for summaries of <code><a href="#topic+stepplfm">stepplfm</a></code> objects.</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'summary.stepplfm'
print(x,digits=2,...)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.summary.stepplfm_+3A_x">x</code></td>
<td>
<p>Summary of a list of probabilistic latent feature analysis object returned by <code><a href="#topic+summary.stepplfm">summary.stepplfm</a></code>.</p>
</td></tr>
<tr><td><code id="print.summary.stepplfm_+3A_digits">digits</code></td>
<td>
<p>By default 2 significant digits are used for printing.</p>
</td></tr>
<tr><td><code id="print.summary.stepplfm_+3A_...">...</code></td>
<td>
<p>Further arguments are ignored.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+stepplfm">stepplfm</a></code>, <code><a href="#topic+summary.stepplfm">summary.stepplfm</a></code>
</p>

<hr>
<h2 id='stepLCplfm'>Latent class probabilistic latent feature analysis of three-way three-mode binary data</h2><span id='topic+stepLCplfm'></span>

<h3>Description</h3>

<p>The function <code><a href="#topic+stepLCplfm">stepLCplfm</a></code> subsequently applies the <code><a href="#topic+LCplfm">LCplfm</a></code> function to fit disjunctive, conjunctive or additive models with <em>minF</em> up to <em>maxF</em> 
latent features and <em>minT</em> to <em>maxT</em> latent classes. The results of the estimated models are stored in a list with <em>F X T</em> components.</p>


<h3>Usage</h3>

<pre><code class='language-R'>	stepLCplfm(minF=1,maxF=3,minT=1,maxT=3,
                   data,maprule="disj",M=5,emcrit1=1e-3,emcrit2=1e-8,
                   model=1,delta=0.0001,printrun=FALSE,Nbootstrap=2000)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="stepLCplfm_+3A_minf">minF</code></td>
<td>
<p>Minimum number of latent features included in the model.</p>
</td></tr>
<tr><td><code id="stepLCplfm_+3A_maxf">maxF</code></td>
<td>
<p>Maximum number of latent features included in the model.</p>
</td></tr>
<tr><td><code id="stepLCplfm_+3A_mint">minT</code></td>
<td>
<p>Minimum number of latent classes included in the model.</p>
</td></tr>
<tr><td><code id="stepLCplfm_+3A_maxt">maxT</code></td>
<td>
<p>Maximum number of latent classes included in the model.</p>
</td></tr>
<tr><td><code id="stepLCplfm_+3A_data">data</code></td>
<td>
<p>A <em>I X J X K</em> data array of binary observations. Observation <em>(i,j,k)</em> <em>(i=1,..,I; j=1,..,J; k=1,..,K)</em>  indicates 
whether object <em>j</em> is associated to attribute <em>k</em> according to rater <em>i</em>.</p>
</td></tr> 
<tr><td><code id="stepLCplfm_+3A_maprule">maprule</code></td>
<td>
<p>Fit disjunctive models (<code>maprule</code>=&quot;disj&quot;), conjunctive models (<code>maprule</code>=&quot;conj&quot;) or additive models (<code>maprule</code>=&quot;add&quot;) .</p>
</td></tr>
<tr><td><code id="stepLCplfm_+3A_m">M</code></td>
<td>
<p>The number of exploratory runs of the EM algorithm using random starting points for each model.</p>
</td></tr>
<tr><td><code id="stepLCplfm_+3A_emcrit1">emcrit1</code></td>
<td>
<p>Convergence criterion to be used for the estimation of candidate models in the exploration step.</p>
</td></tr>
<tr><td><code id="stepLCplfm_+3A_emcrit2">emcrit2</code></td>
<td>
<p>Convergence criterion to be used for the estimation of the best model in the final analysis.</p>
</td></tr>
<tr><td><code id="stepLCplfm_+3A_model">model</code></td>
<td>
<p>The type of dependency and heterogeneity assumption included in the model. <code>model</code>=1, <code>model</code>=2, <code>model</code>=3 represent models with a constant 
object-feature classification per person and with, respectively, class-specific object parameters, class-specific attribute parameters, 
and class-specific object- and attribute parameters. <code>model</code>=4, <code>model</code>=5, <code>model</code>=6 represent models with a constant 
attribute-feature classification per person and with, respectively, class-specific object parameters, class-specific attribute parameters, 
and class-specific object- and attribute parameters.</p>
</td></tr>
<tr><td><code id="stepLCplfm_+3A_delta">delta</code></td>
<td>
<p>The precision used to compute standard errors of the model parameters with the method of finite differences.</p>
</td></tr>
<tr><td><code id="stepLCplfm_+3A_printrun">printrun</code></td>
<td>
<p><code>printrun</code>=TRUE prints the analysis type (disjunctive or conjunctive), the number of features (<em>F</em>), the number of latent classes (<em>T</em>) 
and the number of the run to the output screen, whereas <code>printrun</code>=FALSE suppresses the printing.</p>
</td></tr>
<tr><td><code id="stepLCplfm_+3A_nbootstrap">Nbootstrap</code></td>
<td>
<p>Number of bootstrap iterations to be used for simulating the reference distribution of odds-ratio dependency measures.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The results of subsequent <code><a href="#topic+LCplfm">LCplfm</a></code> analyses are stored in a matrix of lists with <code>(maxF-minF+1,maxT-minT+1)</code> components.</p>


<h3>Author(s)</h3>

<p>Michel Meulders
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
# example 1: analysis on determinants of anger-related behavior

# load anger data
data(anger)

# compute 5 runs of disjunctive latent class probabilistic feature models
# with 1 up to 3 features and with 1 up to 2 latent classes
# assume constant situation classification per person 
# and class-specific situation parameters (i.e. model=1) 

anger.lst&lt;-stepLCplfm(minF=1,maxF=3,minT=1,maxT=2,data=anger$data,
                      maprule="disj",M=5,emcrit1=1e-3,emcrit2=1e-8,model=1)


# visualize BIC of fitted models 

par(pty="s")
plot(anger.lst)

# print overview fit measures for all estimated models

anger.lst

# print model with 3 features and 1 latent class

anger.lst[[3,1]]

## End(Not run)

## Not run: 
# example 2:Perceptual analysis of associations between car models and car attributes

# load car data
data(car)


# compute 5 runs of disjunctive models with 4 features and 1 up to 3 latent classes
# assume constant attribute classification per respondent 
# and class-specific car parameters (i.e. model 4)

car.lst&lt;-stepLCplfm(minF=4,maxF=4,minT=1,maxT=3,data=car$data3w,
                      maprule="disj",M=5,emcrit1=1e-3,emcrit2=1e-8,model=4,printrun=TRUE)


# visualize BIC of fitted models
plot(car.lst)

# print overview of fitmeasures for all fitted models
car.lst

## End(Not run)
</code></pre>

<hr>
<h2 id='stepplfm'>Probabilistic latent feature analysis of two-way two-mode frequency data</h2><span id='topic+stepplfm'></span>

<h3>Description</h3>

<p>The function <code><a href="#topic+stepplfm">stepplfm</a></code> subsequently applies the <code><a href="#topic+plfm">plfm</a></code> function to fit disjunctive, conjunctive or additive models with <em>minF</em> up to <em>maxF</em> 
latent features. The results of the different models are stored in a list.</p>


<h3>Usage</h3>

<pre><code class='language-R'>	stepplfm(minF,maxF,data,object,attribute,
 	rating,freq1,freqtot,datatype="freq",
	maprule="disj",M=5,emcrit1=1e-2,emcrit2=1e-10,
        printrun=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="stepplfm_+3A_minf">minF</code></td>
<td>
<p>Minimum number of features to be fitted</p>
</td></tr>
<tr><td><code id="stepplfm_+3A_maxf">maxF</code></td>
<td>
<p>Maximum number of features to be fitted</p>
</td></tr>
<tr><td><code id="stepplfm_+3A_data">data</code></td>
<td>
<p> A data frame that consists of three components: the variables 
<code>object</code>, <code>attribute</code> and <code>rating</code>. Each row of the data frame describes the outcome of a binary rater judgement
about the association between a certain object and a certain attribute.</p>
</td></tr> 
<tr><td><code id="stepplfm_+3A_object">object</code></td>
<td>
<p>The name of the <code>object</code> component in the data frame <code>data</code>. The values of the vector <code>data$object</code> should be (non-missing) numeric or character values.</p>
</td></tr>
<tr><td><code id="stepplfm_+3A_attribute">attribute</code></td>
<td>
<p>The name of the <code>attribute</code> component in the data frame <code>data</code>. The values of the vector <code>data$attribute</code> should be (non-missing) numeric or character values.</p>
</td></tr>
<tr><td><code id="stepplfm_+3A_rating">rating</code></td>
<td>
<p>The name of the <code>rating</code> component in the data frame <code>data</code>. The elements of the vector <code>data$rating</code> should be the numeric values 0 (no association) or 1 (association), 
or should be specified as missing (NA).</p>
</td></tr>
<tr><td><code id="stepplfm_+3A_freq1">freq1</code></td>
<td>
<p><em>J X K</em> matrix of observed association frequencies.</p>
</td></tr>
<tr><td><code id="stepplfm_+3A_freqtot">freqtot</code></td>
<td>
<p>A <em>J X K</em> matrix with the total number of binary ratings in each cell <em>(j,k)</em>. If the total number of ratings is the same for all cells of the matrix 
it is sufficient to enter a single numeric value rather than a matrix. For instance, if <em>N</em> raters have judged <em>J X K</em> associations, 
one may specify <code>freqtot</code><em>=N</em>.</p>
</td></tr>
<tr><td><code id="stepplfm_+3A_datatype">datatype</code></td>
<td>
<p>The type of data used as input. When <code>datatype</code>=&quot;freq&quot; one should specify frequency data <code>freq1</code> and <code>freqtot</code>, and when <code>datatype</code>=&quot;dataframe&quot; one should 
specify the name of the data frame <code>data</code>, and its components, <code>object</code>, <code>attribute</code> and <code>rating</code>.</p>
</td></tr>
<tr><td><code id="stepplfm_+3A_maprule">maprule</code></td>
<td>
<p>Fit disjunctive models (<code>maprule</code>=&quot;disj&quot;), conjunctive models (<code>maprule</code>=&quot;conj&quot;), or additive models (<code>maprule</code>=&quot;add&quot;). Multiple mapping rules can 
be computed in one analysis. For instance, to compute both disjunctive and conjunctive models one my use <code>maprule</code>=&quot;disj/conj&quot;. 
Other combinations are <code>maprule</code>=&quot;disj/add&quot;, <code>maprule</code>=&quot;conj/add&quot; and <code>maprule</code>=&quot;disj/conj/add&quot;.</p>
</td></tr>
<tr><td><code id="stepplfm_+3A_m">M</code></td>
<td>
<p>The number of times a particular model is estimated using random starting points.</p>
</td></tr>
<tr><td><code id="stepplfm_+3A_emcrit1">emcrit1</code></td>
<td>
<p>Convergence criterion which indicates when the estimation algorithm should switch from Expectation-Maximization (EM) steps to EM+Newton-Rhapson steps.</p>
</td></tr>
<tr><td><code id="stepplfm_+3A_emcrit2">emcrit2</code></td>
<td>
<p>Convergence criterion which indicates final convergence to a local maximum.</p>
</td></tr>
<tr><td><code id="stepplfm_+3A_printrun">printrun</code></td>
<td>
<p><code>printrun</code>=TRUE prints the analysis type (disjunctive, conjunctive, additive), the number of features (<code>F</code>) and the number of the run to the output screen, whereas 
<code>printrun</code>=FALSE suppresses the printing.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>When only one type of mapping rule is requested (disjunctive, conjunctive, additive) (i.e., <code>maprule</code>=&quot;disj&quot;, <code>maprule</code>=&quot;conj&quot; or <code>maprule</code>=&quot;add&quot;) 
with <code>minF</code> to <code>maxF</code> features, the results of subsequent <code><a href="#topic+plfm">plfm</a></code> analyses are stored in a list with <code>maxF-minF+1</code> components. 
When analyses with multiple mapping rules are  requested (e.g. <code>maprule</code>=&quot;disj/conj&quot;), the results for each mapping rule 
are  stored in a list with <code>maxF-minF+1</code> components (e.g., two lists named &quot;disj&quot; and &quot;conj&quot;, respectively) . 
The final object generated by <code><a href="#topic+stepplfm">stepplfm</a></code> combines the lists &quot;disj&quot; and &quot;conj&quot; in a list with two components.
</p>


<h3>Author(s)</h3>

<p>Michel Meulders
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

## Not run: 
# example 1:Perceptual analysis of associations between car models and car attributes

# load car data
data(car)


# compute 5 runs of disjunctive and conjunctive models with 1 up to 4 features
car.lst&lt;-stepplfm(minF=1,maxF=4,maprule="disj/conj",freq1=car$freq1,
                  freqtot=car$freqtot,M=5,emcrit1=1e-6)

# print output of the conjunctive model with 4 features
car.lst$conj[[4]]

# print output of the stepplfm analysis on the car data
car.lst

# summarize and print output of stepplfm analysis on car data
sumcar&lt;-summary(car.lst)
sumcar

# visualize fit of models with different mapping rules and a different number of features
par(pty="s")
par(mfrow=c(2,2))
plot(car.lst,which="BIC")
plot(car.lst,which="AIC")
plot(car.lst,which="VAF")

## End(Not run)


## Not run: 
# example 2: analysis on determinants of anger-related behavior

# load anger data
data(anger)

# compute 1 run of disjunctive models with 1 up to 3 features
anger.lst&lt;-stepplfm(minF=1,maxF=3,maprule="disj",freq1=anger$freq1,freqtot=anger$freqtot,M=1)

# print output of disjunctive model with 2 features

anger.lst[[2]]

# print output of stepplfm analysis on anger data
anger.lst

# summarize and print output of stepplfm analysis on anger data
sumanger&lt;-summary(anger.lst)
sumanger

# visualize fit of models with different mapping rules and a different number of features

par(pty="s")
par(mfrow=c(2,2))
plot(anger.lst,which="BIC")
plot(anger.lst,which="AIC")
plot(anger.lst,which="VAF")

## End(Not run)
</code></pre>

<hr>
<h2 id='summary.bayesplfm'>
Summarizing Bayesian probabilistic latent feature analysis
</h2><span id='topic+summary.bayesplfm'></span>

<h3>Description</h3>

<p>The function <code><a href="#topic+summary.bayesplfm">summary.bayesplfm</a></code> summarizes the output of the object generated by the 
<code><a href="#topic+bayesplfm">bayesplfm</a></code> function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'bayesplfm'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.bayesplfm_+3A_object">object</code></td>
<td>
<p>Bayesian probabilistic latent feature analysis object returned by <code><a href="#topic+bayesplfm">bayesplfm</a></code></p>
</td></tr>
<tr><td><code id="summary.bayesplfm_+3A_...">...</code></td>
<td>
<p>Further arguments are ignored</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The summary of the Bayesian probabilistic latent feature analysis objects displays:
</p>
 
<ol>
<li><p> The parameters used to call the <code><a href="#topic+bayesplfm">bayesplfm</a></code> function.
</p>
</li>
<li><p> Information on the descriptive fit of the model (i.e. correlation between observed and expected frequencies,
and proportion of the variance in the observed frequencies accounted for by the model).
</p>
</li>
<li><p> The posterior mean of the object- and attribute parameters.
</p>
</li>
<li><p> 95 percent posterior intervals for the object- and attribute parameters.
</p>
</li>
<li><p> Rhat convergence values for object- and attribute parameters (if <code>Nchains</code>&gt;1).
</p>
</li></ol>



<h3>Value</h3>

<table>
<tr><td><code>call</code></td>
<td>
<p>Parameters used to call the function.</p>
</td></tr>
<tr><td><code>descriptivefit</code></td>
<td>
<p>A list with two measures of descriptive fit on the <em>J X K</em> table: (1) the correlation 
between observed and expected frequencies, and (2) the proportion of the variance 
in the observed frequencies accounted for by the model. </p>
</td></tr>
<tr><td><code>objpar</code></td>
<td>
<p>A <em>J X F</em> matrix with the posterior mean of the object parameters computed on all iterations and chains in the sample.</p>
</td></tr>
<tr><td><code>attpar</code></td>
<td>
<p>A <em>K X F</em> matrix with the posterior mean of the attribute parameters computed on all iterations and chains in the sample.</p>
</td></tr>
<tr><td><code>p95objpar</code></td>
<td>
<p>95 percent posterior intervals of object parameters.</p>
</td></tr>
<tr><td><code>p95attpar</code></td>
<td>
<p>95 percent posterior intervals of attribute parameters.</p>
</td></tr>
<tr><td><code>Rhatobjpar</code></td>
<td>
<p>Rhat convergence values for object parameters.</p>
</td></tr>
<tr><td><code>Rhatattpar</code></td>
<td>
<p>Rhat convergence values for attribute parameters.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+bayesplfm">bayesplfm</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

##load car data
data(car)

## compute 5 runs of disjunctive model with 2 features
carem2&lt;-plfm(maprule="disj",freq1=car$freq1,freqtot=car$freqtot,F=2,M=5)

## Compute a sample of the posterior distribution 
## for the disjunctive model with two features
## use the posterior mode obtained with the previous plfm analysis
carbayes2&lt;-bayesplfm(maprule="disj",freq1=car$freq1,freqtot=car$freqtot,F=2,
                      maxNiter=500,Nburnin=0,Nstep=100,Nchains=2,
                      start.bayes="fitted.plfm",fitted.plfm=carem2)


## compute a summary of the object generated by bayesplfm
summarycarbayes2&lt;-summary(carbayes2)

## End(Not run)
</code></pre>

<hr>
<h2 id='summary.plfm'>Summarizing probabilistic latent feature analysis</h2><span id='topic+summary.plfm'></span>

<h3>Description</h3>

<p>The function <code>summary.plfm</code> summarizes the main output of <code><a href="#topic+plfm">plfm</a></code> including estimates and standard errors for 
object- and attribute parameters, model selection criteria, and goodness-of-fit measures.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'plfm'
summary(object, ...)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.plfm_+3A_object">object</code></td>
<td>
<p>Probabilistic latent feature analysis object returned by <code><a href="#topic+plfm">plfm</a></code></p>
</td></tr>
<tr><td><code id="summary.plfm_+3A_...">...</code></td>
<td>
<p>Further arguments are ignored</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The summary of probabilistic latent feature analysis objects displays: 
</p>

<ol>
<li><p> The parameters used to call the <code><a href="#topic+plfm">plfm</a></code> function.
</p>
</li>
<li><p> The value of the loglikelihood, the deviance, the logarithm of the posterior density, the information criteria AIC and BIC.
</p>
</li>
<li><p> The result of a Pearson chi-square goodness-of-fit test on the <em>J X K</em> table.
</p>
</li>
<li><p> Information on the descriptive fit of the model (i.e. correlation between observed and expected frequencies.
and proportion of the variance in the observed frequencies accounted for by the model).
</p>
</li>
<li><p> The estimated object- and attribute parameters.
</p>
</li>
<li><p> Asymptotic standard errors of the object- and attribute parameters.
</p>
</li></ol>



<h3>Value</h3>

<table>
<tr><td><code>call</code></td>
<td>
<p>Parameters used to call the function.</p>
</td></tr>
<tr><td><code>informationcriteria</code></td>
<td>
<p>List of information criteria that can be used for model selection.</p>
</td></tr>
<tr><td><code>chisquaretest</code></td>
<td>
<p>Pearson Chi-square test to evaluate the statistical goodness-of-fit of the model on the <em>J X K</em> object by attribute table of association frequencies.</p>
</td></tr>
<tr><td><code>descriptivefit</code></td>
<td>
<p>A list of measures to evaluate the descriptive goodness-of-fit of the model on the <em>J X K</em> object by attribute table of association frequencies.</p>
</td></tr>
<tr><td><code>objpar</code></td>
<td>
<p>A <em>J X F</em> matrix of estimated object parameters.</p>
</td></tr>
<tr><td><code>SE.objpar</code></td>
<td>
<p>A <em>J X F</em> matrix of estimated standard errors of object parameters.</p>
</td></tr>
<tr><td><code>attpar</code></td>
<td>
<p>A <em>K X F</em> matrix of estimated attribute parameters.</p>
</td></tr>
<tr><td><code>SE.attpar</code></td>
<td>
<p>A <em>K X F</em> matrix of estimated standard errors of attribute parameters</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michel Meulders</p>


<h3>See Also</h3>

<p><code><a href="#topic+plfm">plfm</a></code>, <code><a href="#topic+print.plfm">print.plfm</a></code>, <code><a href="#topic+print.summary.plfm">print.summary.plfm</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Perceptual analysis of associations between car models and car attributes

##load car data
data(car)

##compute the disjunctive model with 4 features
carf4&lt;-plfm(maprule="disj",freq1=car$freq1,freqtot=car$freqtot,F=4,M=1)

## display a summary of the results
summary(carf4)
</code></pre>

<hr>
<h2 id='summary.stepLCplfm'>Summary method for <code><a href="#topic+stepLCplfm">stepLCplfm</a></code> objects</h2><span id='topic+summary.stepLCplfm'></span>

<h3>Description</h3>

<p>The function <code>summary.stepLCplfm</code> summarizes the fit measures of a series of <code><a href="#topic+LCplfm">LCplfm</a></code> objects. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'stepLCplfm'
summary(object, ...)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.stepLCplfm_+3A_object">object</code></td>
<td>
<p>Latent class probabilistic latent feature analysis object returned by <code><a href="#topic+stepLCplfm">stepLCplfm</a></code></p>
</td></tr>
<tr><td><code id="summary.stepLCplfm_+3A_...">...</code></td>
<td>
<p>Further arguments are ignored</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The summary of the <code><a href="#topic+stepLCplfm">stepLCplfm</a></code> generates a table of fit measures (information criteria, descriptive goodness-of-fit measures,
statistical dependency measures) for models with different numbers of latent class/features that are involved in the analysis.
</p>


<h3>Author(s)</h3>

<p>Michel Meulders</p>


<h3>See Also</h3>

<p><code><a href="#topic+stepLCplfm">stepLCplfm</a></code>, <code><a href="#topic+print.stepLCplfm">print.stepLCplfm</a></code>
</p>

<hr>
<h2 id='summary.stepplfm'>Summary method for <code><a href="#topic+stepplfm">stepplfm</a></code> objects</h2><span id='topic+summary.stepplfm'></span>

<h3>Description</h3>

<p>The function <code>summary.stepplfm</code> summarizes the fit measures of a series of <code><a href="#topic+plfm">plfm</a></code> objects. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'stepplfm'
summary(object, ...)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.stepplfm_+3A_object">object</code></td>
<td>
<p>Probabilistic latent feature analysis object returned by <code><a href="#topic+stepplfm">stepplfm</a></code></p>
</td></tr>
<tr><td><code id="summary.stepplfm_+3A_...">...</code></td>
<td>
<p>Further arguments are ignored</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The summary of the <code><a href="#topic+stepplfm">stepplfm</a></code> generates a table of fit measures (information criteria, Chi-square fit on the <em>J X K</em> table, and descriptive fit measures) 
for models with different numbers of features and/or mapping rules that are involved in the analysis.
</p>


<h3>Author(s)</h3>

<p>Michel Meulders</p>


<h3>See Also</h3>

<p><code><a href="#topic+stepplfm">stepplfm</a></code>, <code><a href="#topic+print.stepplfm">print.stepplfm</a></code>, <code><a href="#topic+print.summary.stepplfm">print.summary.stepplfm</a></code>
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
