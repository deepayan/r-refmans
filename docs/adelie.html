<!DOCTYPE html><html lang="en"><head><title>Help for package adelie</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {adelie}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#constraint.box'><p>Create a box constraint for a group.</p></a></li>
<li><a href='#cv.glintnet'><p>Cross-validation for glintnet</p></a></li>
<li><a href='#cv.grpnet'><p>Cross-validation for grpnet</p></a></li>
<li><a href='#gaussian_cov'><p>Solves group elastic net via covariance method.</p></a></li>
<li><a href='#glintnet'><p>fit a GLM interaction model with group lasso or group elastic-net regularization</p></a></li>
<li><a href='#glm.binomial'><p>Creates a Binomial GLM family object.</p></a></li>
<li><a href='#glm.cox'><p>Creates a Cox GLM family object.</p></a></li>
<li><a href='#glm.gaussian'><p>Creates a Gaussian GLM family object.</p></a></li>
<li><a href='#glm.multigaussian'><p>Creates a MultiGaussian GLM family object.</p></a></li>
<li><a href='#glm.multinomial'><p>Creates a Multinomial GLM family object.</p></a></li>
<li><a href='#glm.poisson'><p>Creates a Poisson GLM family object.</p></a></li>
<li><a href='#grpnet'><p>fit a GLM with group lasso or group elastic-net regularization</p></a></li>
<li><a href='#io.snp_phased_ancestry'><p>IO handler for SNP phased, ancestry matrix.</p></a></li>
<li><a href='#io.snp_unphased'><p>IO handler for SNP unphased matrix.</p></a></li>
<li><a href='#matrix.block_diag'><p>Creates a block-diagonal matrix.</p></a></li>
<li><a href='#matrix.concatenate'><p>Creates a concatenation of the matrices.</p></a></li>
<li><a href='#matrix.convex_relu'><p>Creates a feature matrix for the convex relu problem.</p></a></li>
<li><a href='#matrix.dense'><p>Creates a dense matrix object.</p></a></li>
<li><a href='#matrix.eager_cov'><p>Creates an eager covariance matrix.</p></a></li>
<li><a href='#matrix.interaction'><p>Creates a matrix with pairwise interactions.</p></a></li>
<li><a href='#matrix.kronecker_eye'><p>Creates a Kronecker product with an identity matrix.</p></a></li>
<li><a href='#matrix.lazy_cov'><p>Creates a lazy covariance matrix.</p></a></li>
<li><a href='#matrix.one_hot'><p>Creates a one-hot encoded matrix.</p></a></li>
<li><a href='#matrix.snp_phased_ancestry'><p>Creates a SNP phased, ancestry matrix.</p></a></li>
<li><a href='#matrix.snp_unphased'><p>Creates a SNP unphased matrix.</p></a></li>
<li><a href='#matrix.sparse'><p>Creates a sparse matrix object.</p></a></li>
<li><a href='#matrix.standardize'><p>Creates a standardized matrix.</p></a></li>
<li><a href='#matrix.subset'><p>Creates a subset of the matrix along an axis.</p></a></li>
<li><a href='#plot.cv.glintnet'><p>plot the cross-validation curve produced by cv.glintnet</p></a></li>
<li><a href='#plot.grpnet'><p>plot coefficients from a &quot;grpnet&quot; object</p></a></li>
<li><a href='#predict.cv.glintnet'><p>make predictions from a &quot;cv.glintnet&quot; object.</p></a></li>
<li><a href='#predict.cv.grpnet'><p>make predictions from a &quot;cv.grpnet&quot; object.</p></a></li>
<li><a href='#predict.glintnet'><p>make predictions from a &quot;glintnet&quot; object.</p></a></li>
<li><a href='#predict.grpnet'><p>make predictions from a &quot;grpnet&quot; object.</p></a></li>
<li><a href='#print.cv.grpnet'><p>print a cross-validated grpnet object</p></a></li>
<li><a href='#print.glintnet'><p>Print a summary of the glintnet path at each step along the path.</p></a></li>
<li><a href='#print.grpnet'><p>print a grpnet object</p></a></li>
<li><a href='#set_configs'><p>Set configuration settings.</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Title:</td>
<td>Group Lasso and Elastic Net Solver for Generalized Linear Models</td>
</tr>
<tr>
<td>Version:</td>
<td>1.0.7</td>
</tr>
<tr>
<td>Date:</td>
<td>2025-02-27</td>
</tr>
<tr>
<td>Description:</td>
<td>Extremely efficient procedures for fitting the entire group lasso and group elastic net regularization path for GLMs, multinomial, the Cox model and multi-task Gaussian models. Similar to the R package 'glmnet' in scope of models, and in computational speed.  This package provides  R bindings to the C++ code underlying the corresponding Python package 'adelie'. These bindings offer a general purpose group elastic net solver, 
    a wide range of matrix classes that can exploit special structure 
    to allow large-scale inputs, and an assortment of 
    generalized linear model classes for fitting various types of data. 
    The package is an implementation of Yang, J. and Hastie, T. (2024) &lt;<a href="https://doi.org/10.48550%2FarXiv.2405.08631">doi:10.48550/arXiv.2405.08631</a>&gt;.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.2</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp, RcppEigen</td>
</tr>
<tr>
<td>SystemRequirements:</td>
<td>C++17</td>
</tr>
<tr>
<td>Imports:</td>
<td>Matrix, r2r, Rcpp, methods, stringr, utils</td>
</tr>
<tr>
<td>Suggests:</td>
<td>ggplot2, gridExtra, testthat (&ge; 3.0.0), knitr, rmarkdown</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/JamesYang007/adelie-r">https://github.com/JamesYang007/adelie-r</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/JamesYang007/adelie-r/issues">https://github.com/JamesYang007/adelie-r/issues</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2025-02-27 15:23:01 UTC; hastie</td>
</tr>
<tr>
<td>Author:</td>
<td>James Yang [aut, cph],
  Trevor Hastie [aut, cph, cre],
  Balasubramanian Narasimhan [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Trevor Hastie &lt;hastie@stanford.edu&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2025-02-28 17:50:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='constraint.box'>Create a box constraint for a group.</h2><span id='topic+constraint.box'></span>

<h3>Description</h3>

<p>A box constraint sets upper and lower bounds for coefficients in a model.
This is done per group, and this function is used separately to set the bounds for each group in the model. The constraints are returned as a list, with number of elements the number of groups. List entries can be <code>NULL</code>, which means no constraints for that group. Currently works with single-response models (so <code>glm.multinomial</code> and <code>glm.multigaussian</code> are excluded). Note that for each group for which non-null constraints are provide, a separate call to <code>constraint.box()</code> must be made (i.e. the constraint object cannot be replicated). See the second example below.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>constraint.box(lower, upper, max_iters = 100, tol = 1e-09)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="constraint.box_+3A_lower">lower</code></td>
<td>
<p>lower bound for each coefficient in the group. If the group has <code>m</code> variables, this should be a vector of length <code>m</code>. Values can be <code>-Inf</code>.</p>
</td></tr>
<tr><td><code id="constraint.box_+3A_upper">upper</code></td>
<td>
<p>upper bound for each coefficient in the group. If the group has <code>m</code> variables, this should be a vector of length <code>m</code>. Values can be <code>Inf</code>.</p>
</td></tr>
<tr><td><code id="constraint.box_+3A_max_iters">max_iters</code></td>
<td>
<p>maximum number of proximal Newton iterations; default is 100.</p>
</td></tr>
<tr><td><code id="constraint.box_+3A_tol">tol</code></td>
<td>
<p>convergence tolerance for proximal Newton; default is 1e-9.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Box constraint object.
</p>


<h3>Author(s)</h3>

<p>Trevor Hastie and James Yang<br /> Maintainer: Trevor Hastie <a href="mailto:hastie@stanford.edu">hastie@stanford.edu</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Group of length 10, with positivity constraint on all the coefficients.
lower &lt;- rep(0,10)
upper &lt;- rep(Inf,10)
cont &lt;- constraint.box(lower = lower, upper = upper)

# 10 singleton groups, and non-negativity constraints on all parameters.
cont &lt;- lapply(1:10, function(i)constraint.box(lower = 0, upper = Inf))

# Same as above, but non-negativity constraints only on first 5 parameters.
cont &lt;- lapply(1:5, function(i)constraint.box(lower = 0, upper = Inf))
cont &lt;- c(cont, rep(list(NULL), 5)) # rep rule does not apply to NULL

</code></pre>

<hr>
<h2 id='cv.glintnet'>Cross-validation for glintnet</h2><span id='topic+cv.glintnet'></span>

<h3>Description</h3>

<p>Does k-fold cross-validation for glintnet
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cv.glintnet(
  X,
  glm,
  offsets = NULL,
  intr_keys = NULL,
  intr_values,
  levels = NULL,
  n_folds = 10,
  foldid = NULL,
  n_threads = 1,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cv.glintnet_+3A_x">X</code></td>
<td>
<p>Feature matrix. Either a regular R matrix, or else an
<code>adelie</code> custom matrix class, or a concatination of such.</p>
</td></tr>
<tr><td><code id="cv.glintnet_+3A_glm">glm</code></td>
<td>
<p>GLM family/response object. This is an expression that
represents the family, the reponse and other arguments such as
weights, if present. The choices are <code>glm.gaussian()</code>,
<code>glm.binomial()</code>, <code>glm.poisson()</code>,
<code>glm.multinomial()</code>, <code>glm.cox()</code>, <code>glm.multinomial()</code>,
and <code>glm.multigaussian()</code>. This is a required argument, and
there is no default. In the simple example below, we use <code>glm.gaussian(y)</code>.</p>
</td></tr>
<tr><td><code id="cv.glintnet_+3A_offsets">offsets</code></td>
<td>
<p>Offsets, default is <code>NULL</code>. If present, this is
a fixed vector or matrix corresponding to the shape of the natural
parameter, and is added to the fit.</p>
</td></tr>
<tr><td><code id="cv.glintnet_+3A_intr_keys">intr_keys</code></td>
<td>
<p>List of feature indices. This is a list of all features with which interactions can be
formed. Default is <code>1:p</code> where <code>p</code> is the number of columns in <code>X</code>.</p>
</td></tr>
<tr><td><code id="cv.glintnet_+3A_intr_values">intr_values</code></td>
<td>
<p>List of integer vectors of feature indices. For each of the <code>m &lt;= p</code> indices
listed in <code>intr_keys</code>, there is a vector of indices indicating which columns are candidates for
interaction with that feature. If a vector is <code>NULL</code>, that means all other features are candidates
for interactions.  The default is a list of length <code>m</code> where each element is <code>NULL</code>;
that is <code>rep(list(NULL), m</code>.</p>
</td></tr>
<tr><td><code id="cv.glintnet_+3A_levels">levels</code></td>
<td>
<p>Number of levels for each of the columns of <code>mat</code>, with <code>1</code> representing a
quantitative feature. A factor with <code>K</code> levels should be represented by the numbers <code>0,1,...,K-1</code>.</p>
</td></tr>
<tr><td><code id="cv.glintnet_+3A_n_folds">n_folds</code></td>
<td>
<p>(default 10). Although <code>n_folds</code> can be
as large as the sample size (leave-one-out CV), it is not recommended for
large datasets. Smallest value allowable is <code>n_folds=3</code>.</p>
</td></tr>
<tr><td><code id="cv.glintnet_+3A_foldid">foldid</code></td>
<td>
<p>An optional vector of values between 1 and <code>n_folds</code>
identifying what fold each observation is in. If supplied, <code>n_folds</code> can
be missing.</p>
</td></tr>
<tr><td><code id="cv.glintnet_+3A_n_threads">n_threads</code></td>
<td>
<p>Number of threads, default <code>1</code>.</p>
</td></tr>
<tr><td><code id="cv.glintnet_+3A_...">...</code></td>
<td>
<p>Additional named arguments to <code>grpnet</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function runs <code>glintnet</code> <code>n_folds</code>+1 times; the first to get the
<code>lambda</code> sequence, and then the remainder to compute the fit with each
of the folds omitted. The out-of-fold deviance is accumulated, and the average deviance and
standard deviation over the folds is computed.  Note that <code>cv.glintnet</code>
does NOT search for values for <code>alpha</code>. A specific value should be
supplied, else <code>alpha=1</code> is assumed by default. If users would like to
cross-validate <code>alpha</code> as well, they should call <code>cv.glintnet</code> with
a pre-computed vector <code>foldid</code>, and then use this same <code>foldid</code> vector in
separate calls to <code>cv.glintnet</code> with different values of <code>alpha</code>.
Note also that the results of <code>cv.glintnet</code> are random, since the folds
are selected at random. Users can reduce this randomness by running
<code>cv.glintnet</code> many times, and averaging the error curves.
</p>


<h3>Value</h3>

<p>A list of class <code>"glintnet"</code>, which inherits from class <code>"grpnet"</code>.
This has a a few additional components such as <code>pairs</code>, <code>groups</code> and <code>levels</code>.
Users typically use methods like <code>predict()</code>, <code>print()</code>, <code>plot()</code> etc to examine the object.
</p>


<h3>Author(s)</h3>

<p>James Yang, Trevor Hastie, and  Balasubramanian Narasimhan <br /> Maintainer: Trevor Hastie
<a href="mailto:hastie@stanford.edu">hastie@stanford.edu</a>
</p>


<h3>References</h3>

<p>Lim, Michael and Hastie, Trevor (2015) <em>Learning interactions via hierarchical group-lasso regularization</em>, JCGS
<a href="https://doi.org/10.1080/10618600.2014.938812">doi:10.1080/10618600.2014.938812</a><br />
Yang, James and Hastie, Trevor. (2024) A Fast and Scalable Pathwise-Solver for Group Lasso
and Elastic Net Penalized Regression via Block-Coordinate Descent. arXiv <a href="https://doi.org/10.48550/arXiv.2405.08631">doi:10.48550/arXiv.2405.08631</a>.<br />
Friedman, J., Hastie, T. and Tibshirani, R. (2008)
<em>Regularization Paths for Generalized Linear Models via Coordinate
Descent (2010), Journal of Statistical Software, Vol. 33(1), 1-22</em>,
<a href="https://doi.org/10.18637/jss.v033.i01">doi:10.18637/jss.v033.i01</a>.<br />
Simon, N., Friedman, J., Hastie, T. and Tibshirani, R. (2011)
<em>Regularization Paths for Cox's Proportional
Hazards Model via Coordinate Descent, Journal of Statistical Software, Vol.
39(5), 1-13</em>,
<a href="https://doi.org/10.18637/jss.v039.i05">doi:10.18637/jss.v039.i05</a>.<br />
Tibshirani,Robert, Bien, J., Friedman, J., Hastie, T.,Simon, N.,Taylor, J. and
Tibshirani, Ryan. (2012) <em>Strong Rules for Discarding Predictors in
Lasso-type Problems, JRSSB, Vol. 74(2), 245-266</em>,
<a href="https://arxiv.org/abs/1011.2234">https://arxiv.org/abs/1011.2234</a>.<br />
</p>


<h3>See Also</h3>

<p><code>cv.glintnet</code>, <code>predict.glintnet</code>, <code>plot.glintnet</code>, <code>print.glintnet</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(0)
n=500
d_cont = 5     # number of continuous features
d_disc = 5     # number of categorical features
Z_cont = matrix(rnorm(n*d_cont), n, d_cont)
levels = sample(2:5,d_disc, replace = TRUE)
Z_disc = matrix(0,n,d_disc)
for(i in seq(d_disc))Z_disc[,i] = sample(0:(levels[i]-1),n,replace=TRUE)
Z = cbind(Z_cont,Z_disc)
levels = c(rep(1,d_cont),levels)

xmat = model.matrix(~Z_cont[,1]*factor(Z_disc[,2]))
nc=ncol(xmat)
beta = rnorm(nc)
y = xmat%*%beta+rnorm(n)*1.5

cvfit &lt;- cv.glintnet(Z, glm.gaussian(y), levels=levels, intr_keys = 1)
plot(cvfit)
predict(cvfit, newx=Z[1:5,])

</code></pre>

<hr>
<h2 id='cv.grpnet'>Cross-validation for grpnet</h2><span id='topic+cv.grpnet'></span>

<h3>Description</h3>

<p>Does k-fold cross-validation for grpnet
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cv.grpnet(
  X,
  glm,
  n_folds = 10,
  foldid = NULL,
  min_ratio = 0.01,
  lmda_path_size = 100,
  offsets = NULL,
  progress_bar = FALSE,
  n_threads = 1,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cv.grpnet_+3A_x">X</code></td>
<td>
<p>Feature matrix. Either a regualr R matrix, or else an
<code>adelie</code> custom matrix class, or a concatination of such.</p>
</td></tr>
<tr><td><code id="cv.grpnet_+3A_glm">glm</code></td>
<td>
<p>GLM family/response object. This is an expression that
represents the family, the reponse and other arguments such as
weights, if present. The choices are <code>glm.gaussian()</code>,
<code>glm.binomial()</code>, <code>glm.poisson()</code>,
<code>glm.multinomial()</code>, <code>glm.cox()</code>, <code>glm.multinomial()</code>,
and <code>glm.multigaussian()</code>. This is a required argument, and
there is no default. In the simple example below, we use <code>glm.gaussian(y)</code>.</p>
</td></tr>
<tr><td><code id="cv.grpnet_+3A_n_folds">n_folds</code></td>
<td>
<p>(default 10). Although <code>n_folds</code> can be
as large as the sample size (leave-one-out CV), it is not recommended for
large datasets. Smallest value allowable is <code>n_folds=3</code>.</p>
</td></tr>
<tr><td><code id="cv.grpnet_+3A_foldid">foldid</code></td>
<td>
<p>An optional vector of values between 1 and <code>n_folds</code>
identifying what fold each observation is in. If supplied, <code>n_folds</code> can
be missing.</p>
</td></tr>
<tr><td><code id="cv.grpnet_+3A_min_ratio">min_ratio</code></td>
<td>
<p>Ratio between smallest and largest value of lambda. Default is 1e-2.</p>
</td></tr>
<tr><td><code id="cv.grpnet_+3A_lmda_path_size">lmda_path_size</code></td>
<td>
<p>Number of values for <code>lambda</code>, if generated automatically.
Default is 100.</p>
</td></tr>
<tr><td><code id="cv.grpnet_+3A_offsets">offsets</code></td>
<td>
<p>Offsets, default is <code>NULL</code>. If present, this is
a fixed vector or matrix corresponding to the shape of the natural
parameter, and is added to the fit.</p>
</td></tr>
<tr><td><code id="cv.grpnet_+3A_progress_bar">progress_bar</code></td>
<td>
<p>Progress bar. Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="cv.grpnet_+3A_n_threads">n_threads</code></td>
<td>
<p>Number of threads, default <code>1</code>.</p>
</td></tr>
<tr><td><code id="cv.grpnet_+3A_...">...</code></td>
<td>
<p>Other arguments that can be passed to <code>grpnet</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function runs <code>grpnet</code> <code>n_folds</code>+1 times; the first to get the
<code>lambda</code> sequence, and then the remainder to compute the fit with each
of the folds omitted. The out-of-fold deviance is accumulated, and the average deviance and
standard deviation over the folds is computed.  Note that <code>cv.grpnet</code>
does NOT search for values for <code>alpha</code>. A specific value should be
supplied, else <code>alpha = 1</code> is assumed by default. If users would like to
cross-validate <code>alpha</code> as well, they should call <code>cv.grpnet</code> with
a pre-computed vector <code>foldid</code>, and then use this same <code>foldid</code> vector in
separate calls to <code>cv.grpnet</code> with different values of <code>alpha</code>.
Note also that the results of <code>cv.grpnet</code> are random, since the folds
are selected at random (unless supplied via <code>foldid</code>).
Users can reduce this randomness by running
<code>cv.grpnet</code> many times, and averaging the error curves.
</p>


<h3>Value</h3>

<p>an object of class <code>"cv.grpnet"</code> is returned, which is a list
with the ingredients of the cross-validation fit.
</p>
<table role = "presentation">
<tr><td><code>lambda</code></td>
<td>
<p>the values of <code>lambda</code> used in the
fits.</p>
</td></tr>
<tr><td><code>cvm</code></td>
<td>
<p>The mean cross-validated deviance - a vector of length <code>length(lambda)</code>.</p>
</td></tr>
<tr><td><code>cvsd</code></td>
<td>
<p>estimate of standard error of <code>cvm</code>.</p>
</td></tr>
<tr><td><code>cvup</code></td>
<td>
<p>upper curve = <code>cvm+cvsd</code>.</p>
</td></tr>
<tr><td><code>cvlo</code></td>
<td>
<p>lower curve = <code>cvm-cvsd</code>.</p>
</td></tr>
<tr><td><code>nzero</code></td>
<td>
<p>number of non-zero coefficients at each <code>lambda</code>.</p>
</td></tr>
<tr><td><code>name</code></td>
<td>
<p>a text string indicating type of measure (for plotting purposes).
Currently this is <code>"deviance"</code></p>
</td></tr>
<tr><td><code>grpnet.fit</code></td>
<td>
<p>a fitted grpnet object for the
full data.</p>
</td></tr>
<tr><td><code>lambda.min</code></td>
<td>
<p>value of <code>lambda</code> that gives minimum <code>cvm</code>.</p>
</td></tr>
<tr><td><code>lambda.1se</code></td>
<td>
<p>largest value of <code>lambda</code> such that
mean deviance is within 1 standard error of the minimum.</p>
</td></tr>
<tr><td><code>index</code></td>
<td>
<p>a one column matrix with the indices of <code>lambda.min</code> and <code>lambda.1se</code> in the sequence of coefficients, fits etc.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>James Yang, Trevor Hastie, and  Balasubramanian Narasimhan <br /> Maintainer: Trevor Hastie
<a href="mailto:hastie@stanford.edu">hastie@stanford.edu</a>
</p>


<h3>References</h3>

<p>Yang, James and Hastie, Trevor. (2024) A Fast and Scalable Pathwise-Solver for Group Lasso
and Elastic Net Penalized Regression via Block-Coordinate Descent. arXiv <a href="https://doi.org/10.48550/arXiv.2405.08631">doi:10.48550/arXiv.2405.08631</a>.<br />
Friedman, J., Hastie, T. and Tibshirani, R. (2008)
<em>Regularization Paths for Generalized Linear Models via Coordinate
Descent (2010), Journal of Statistical Software, Vol. 33(1), 1-22</em>,
<a href="https://doi.org/10.18637/jss.v033.i01">doi:10.18637/jss.v033.i01</a>.<br />
Simon, N., Friedman, J., Hastie, T. and Tibshirani, R. (2011)
<em>Regularization Paths for Cox's Proportional
Hazards Model via Coordinate Descent, Journal of Statistical Software, Vol.
39(5), 1-13</em>,
<a href="https://doi.org/10.18637/jss.v039.i05">doi:10.18637/jss.v039.i05</a>.<br />
Tibshirani,Robert, Bien, J., Friedman, J., Hastie, T.,Simon, N.,Taylor, J. and
Tibshirani, Ryan. (2012) <em>Strong Rules for Discarding Predictors in
Lasso-type Problems, JRSSB, Vol. 74(2), 245-266</em>,
<a href="https://arxiv.org/abs/1011.2234">https://arxiv.org/abs/1011.2234</a>.<br />
</p>


<h3>See Also</h3>

<p><code>print.cv.grpnet</code>, <code>predict.cv.grpnet</code>, <code>coef.cv.grpnet</code>, <code>plot.cv.grpnet</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(0)
n &lt;- 100
p &lt;- 200
X &lt;- matrix(rnorm(n * p), n, p)
y &lt;- X[,1:25] %*% rnorm(25)/4 + rnorm(n)
groups &lt;- c(1, sample(2:199, 60, replace = FALSE))
groups &lt;- sort(groups)
cvfit &lt;- cv.grpnet(X, glm.gaussian(y), groups = groups)
print(cvfit)
plot(cvfit)
predict(cvfit, newx = X[1:5,])
predict(cvfit, type = "nonzero")

</code></pre>

<hr>
<h2 id='gaussian_cov'>Solves group elastic net via covariance method.</h2><span id='topic+gaussian_cov'></span>

<h3>Description</h3>

<p>Solves group elastic net via covariance method.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gaussian_cov(
  A,
  v,
  constraints = NULL,
  groups = NULL,
  alpha = 1,
  penalty = NULL,
  lmda_path = NULL,
  max_iters = as.integer(1e+05),
  tol = 1e-07,
  rdev_tol = 0.001,
  newton_tol = 1e-12,
  newton_max_iters = 1000,
  n_threads = 1,
  early_exit = TRUE,
  screen_rule = "pivot",
  min_ratio = 0.01,
  lmda_path_size = 100,
  max_screen_size = NULL,
  max_active_size = NULL,
  pivot_subset_ratio = 0.1,
  pivot_subset_min = 1,
  pivot_slack_ratio = 1.25,
  check_state = FALSE,
  progress_bar = FALSE,
  warm_start = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gaussian_cov_+3A_a">A</code></td>
<td>
<p>Positive semi-definite matrix.</p>
</td></tr>
<tr><td><code id="gaussian_cov_+3A_v">v</code></td>
<td>
<p>Linear term.</p>
</td></tr>
<tr><td><code id="gaussian_cov_+3A_constraints">constraints</code></td>
<td>
<p>Constraints.</p>
</td></tr>
<tr><td><code id="gaussian_cov_+3A_groups">groups</code></td>
<td>
<p>Groups.</p>
</td></tr>
<tr><td><code id="gaussian_cov_+3A_alpha">alpha</code></td>
<td>
<p>Elastic net parameter.</p>
</td></tr>
<tr><td><code id="gaussian_cov_+3A_penalty">penalty</code></td>
<td>
<p>Penalty factor.</p>
</td></tr>
<tr><td><code id="gaussian_cov_+3A_lmda_path">lmda_path</code></td>
<td>
<p>The regularization path.</p>
</td></tr>
<tr><td><code id="gaussian_cov_+3A_max_iters">max_iters</code></td>
<td>
<p>Maximum number of coordinate descents.</p>
</td></tr>
<tr><td><code id="gaussian_cov_+3A_tol">tol</code></td>
<td>
<p>Coordinate descent convergence tolerance.</p>
</td></tr>
<tr><td><code id="gaussian_cov_+3A_rdev_tol">rdev_tol</code></td>
<td>
<p>Relative percent deviance explained tolerance.</p>
</td></tr>
<tr><td><code id="gaussian_cov_+3A_newton_tol">newton_tol</code></td>
<td>
<p>Convergence tolerance for the BCD update.</p>
</td></tr>
<tr><td><code id="gaussian_cov_+3A_newton_max_iters">newton_max_iters</code></td>
<td>
<p>Maximum number of iterations for the BCD update.</p>
</td></tr>
<tr><td><code id="gaussian_cov_+3A_n_threads">n_threads</code></td>
<td>
<p>Number of threads.</p>
</td></tr>
<tr><td><code id="gaussian_cov_+3A_early_exit">early_exit</code></td>
<td>
<p><code>TRUE</code> if the function should exit early.</p>
</td></tr>
<tr><td><code id="gaussian_cov_+3A_screen_rule">screen_rule</code></td>
<td>
<p>Screen rule (currently the only value is the default <code>"pivot"</code>.</p>
</td></tr>
<tr><td><code id="gaussian_cov_+3A_min_ratio">min_ratio</code></td>
<td>
<p>Ratio between largest and smallest regularization parameter, default is <code>0.01</code>.</p>
</td></tr>
<tr><td><code id="gaussian_cov_+3A_lmda_path_size">lmda_path_size</code></td>
<td>
<p>Number of regularization steps in the path, default is <code>100</code>.</p>
</td></tr>
<tr><td><code id="gaussian_cov_+3A_max_screen_size">max_screen_size</code></td>
<td>
<p>Maximum number of screen groups, default is <code>NULL</code> for no maximum.</p>
</td></tr>
<tr><td><code id="gaussian_cov_+3A_max_active_size">max_active_size</code></td>
<td>
<p>Maximum number of active groups, default is <code>NULL</code> for no maximum.</p>
</td></tr>
<tr><td><code id="gaussian_cov_+3A_pivot_subset_ratio">pivot_subset_ratio</code></td>
<td>
<p>Subset ratio of pivot rule, default is <code>0.1</code>.</p>
</td></tr>
<tr><td><code id="gaussian_cov_+3A_pivot_subset_min">pivot_subset_min</code></td>
<td>
<p>Minimum subset of pivot rule, default is <code>1</code>.</p>
</td></tr>
<tr><td><code id="gaussian_cov_+3A_pivot_slack_ratio">pivot_slack_ratio</code></td>
<td>
<p>Slack ratio of pivot rule, default is <code>1.25</code>.</p>
</td></tr>
<tr><td><code id="gaussian_cov_+3A_check_state">check_state</code></td>
<td>
<p>Check state, default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="gaussian_cov_+3A_progress_bar">progress_bar</code></td>
<td>
<p>Progress bar, default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="gaussian_cov_+3A_warm_start">warm_start</code></td>
<td>
<p>Warm start, default is <code>NULL</code> (no warm start).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>State of the solver.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(0)
n &lt;- 100
p &lt;- 200
X &lt;- matrix(rnorm(n * p), n, p)
y &lt;- X[,1] * rnorm(1) + rnorm(n)
A &lt;- t(X) %*% X / n
v &lt;- t(X) %*% y / n
state &lt;- gaussian_cov(A, v)

</code></pre>

<hr>
<h2 id='glintnet'>fit a GLM interaction model with group lasso or group elastic-net regularization</h2><span id='topic+glintnet'></span>

<h3>Description</h3>

<p>This function is an implementation of the <code>glinternet</code> model of Lim and Hastie, for fitting interactions between pairs of variables in a model. The method creates <em>interaction matrices</em> and enforces hierarchy using the <em>overlap group lasso</em>. Once the augmented model matrix is set up,
<code>glintnet</code> uses <code>grpnet</code> to fit the overlap group lasso path. It hence inherits all the capabilities of
<code>grpnet</code>, and in particular can fit interaction models for  all the GLM families.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>glintnet(
  X,
  glm,
  offsets = NULL,
  intr_keys = NULL,
  intr_values,
  levels = NULL,
  n_threads = 1,
  save.X = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="glintnet_+3A_x">X</code></td>
<td>
<p>A dense matrix, which can include factors with levels coded as non-negative integers starting at 0.</p>
</td></tr>
<tr><td><code id="glintnet_+3A_glm">glm</code></td>
<td>
<p>GLM family/response object. This is an expression that
represents the family, the reponse and other arguments such as
weights, if present. The choices are <code>glm.gaussian()</code>,
<code>glm.binomial()</code>, <code>glm.poisson()</code>,
<code>glm.multinomial()</code>, <code>glm.cox()</code>, <code>glm.multinomial()</code>,
and <code>glm.multigaussian()</code>. This is a required argument, and
there is no default. In the simple example below, we use <code>glm.gaussian(y)</code>.</p>
</td></tr>
<tr><td><code id="glintnet_+3A_offsets">offsets</code></td>
<td>
<p>Offsets, default is <code>NULL</code>. If present, this is
a fixed vector or matrix corresponding to the shape of the natural
parameter, and is added to the fit.</p>
</td></tr>
<tr><td><code id="glintnet_+3A_intr_keys">intr_keys</code></td>
<td>
<p>List of feature indices. This is a list of all features with which interactions can be
formed. Default is <code>1:p</code> where <code>p</code> is the number of columns in <code>X</code>.</p>
</td></tr>
<tr><td><code id="glintnet_+3A_intr_values">intr_values</code></td>
<td>
<p>List of integer vectors of feature indices. For each of the <code>m &lt;= p</code> indices
listed in <code>intr_keys</code>, there is a vector of indices indicating which columns are candidates for
interaction with that feature. If a vector is <code>NULL</code>, that means all other features are candidates
for interactions.  The default is a list of length <code>m</code> where each element is <code>NULL</code>;
that is <code>rep(list(NULL), m</code>.</p>
</td></tr>
<tr><td><code id="glintnet_+3A_levels">levels</code></td>
<td>
<p>Number of levels for each of the columns of <code>mat</code>, with <code>1</code> representing a
quantitative feature. A factor with <code>K</code> levels should be represented by the numbers <code>0,1,...,K-1</code>.</p>
</td></tr>
<tr><td><code id="glintnet_+3A_n_threads">n_threads</code></td>
<td>
<p>Number of threads, default <code>1</code>.</p>
</td></tr>
<tr><td><code id="glintnet_+3A_save.x">save.X</code></td>
<td>
<p>Logical flag, default <code>FALSE</code>. If <code>TRUE</code>, the internally constructed X matrix is returned.</p>
</td></tr>
<tr><td><code id="glintnet_+3A_...">...</code></td>
<td>
<p>Additional named arguments to <code>grpnet</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The input matrix can be composed of quantitative variables or columns representing factors.
The argument <code>levels</code> indicates which are quantitative, and which are factors.
The later are represented by numbers starting at 0, up to one less than the number of levels (sorry!)
Each of the factors are converted to &quot;one-hot&quot; matrices, and hence a group of columns are created for each of these.
This is done using the matrix utility function <code>matrix.one_hot()</code>. In addition interaction matrices are created.
For each pair of variables for which an interaction is considered, a matrix is created consisting of the
cross-product of each of the constituent matrices, as described in the &quot;glinternet&quot; reference.
Once this much bigger matrix is established, the model is handed to <code>grpnet</code> to produce the fit.
</p>


<h3>Value</h3>

<p>A list of class <code>"glintnet"</code>, which inherits from class <code>"grpnet"</code>.
This has a a few additional components such as <code>pairs</code>, <code>groups</code> and <code>levels</code>.
Users typically use methods like <code>predict()</code>, <code>print()</code>, <code>plot()</code> etc to examine the object.
</p>


<h3>Author(s)</h3>

<p>James Yang, Trevor Hastie, and  Balasubramanian Narasimhan <br /> Maintainer: Trevor Hastie
<a href="mailto:hastie@stanford.edu">hastie@stanford.edu</a>
</p>


<h3>References</h3>

<p>Lim, Michael and Hastie, Trevor (2015) <em>Learning interactions via hierarchical group-lasso regularization</em>, JCGS
<a href="https://doi.org/10.1080/10618600.2014.938812">doi:10.1080/10618600.2014.938812</a><br />
Yang, James and Hastie, Trevor. (2024) A Fast and Scalable Pathwise-Solver for Group Lasso
and Elastic Net Penalized Regression via Block-Coordinate Descent. arXiv <a href="https://doi.org/10.48550/arXiv.2405.08631">doi:10.48550/arXiv.2405.08631</a>.<br />
Friedman, J., Hastie, T. and Tibshirani, R. (2008)
<em>Regularization Paths for Generalized Linear Models via Coordinate
Descent (2010), Journal of Statistical Software, Vol. 33(1), 1-22</em>,
<a href="https://doi.org/10.18637/jss.v033.i01">doi:10.18637/jss.v033.i01</a>.<br />
Simon, N., Friedman, J., Hastie, T. and Tibshirani, R. (2011)
<em>Regularization Paths for Cox's Proportional
Hazards Model via Coordinate Descent, Journal of Statistical Software, Vol.
39(5), 1-13</em>,
<a href="https://doi.org/10.18637/jss.v039.i05">doi:10.18637/jss.v039.i05</a>.<br />
Tibshirani,Robert, Bien, J., Friedman, J., Hastie, T.,Simon, N.,Taylor, J. and
Tibshirani, Ryan. (2012) <em>Strong Rules for Discarding Predictors in
Lasso-type Problems, JRSSB, Vol. 74(2), 245-266</em>,
<a href="https://arxiv.org/abs/1011.2234">https://arxiv.org/abs/1011.2234</a>.<br />
</p>


<h3>See Also</h3>

<p><code>cv.glintnet</code>, <code>predict.glintnet</code>, <code>plot.glintnet</code>, <code>print.glintnet</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(0)
n=500
d_cont = 5     # number of continuous features
d_disc = 5     # number of categorical features
Z_cont = matrix(rnorm(n*d_cont), n, d_cont)
levels = sample(2:5,d_disc, replace = TRUE)
Z_disc = matrix(0,n,d_disc)
for(i in seq(d_disc))Z_disc[,i] = sample(0:(levels[i]-1),n,replace=TRUE)
Z = cbind(Z_cont,Z_disc)
levels = c(rep(1,d_cont),levels)

xmat = model.matrix(~Z_cont[,1]*factor(Z_disc[,2]))
nc=ncol(xmat)
beta = rnorm(nc)
y = xmat%*%beta+rnorm(n)*1.5

fit &lt;- glintnet(Z, glm.gaussian(y), levels=levels, intr_keys = 1)
print(fit)

</code></pre>

<hr>
<h2 id='glm.binomial'>Creates a Binomial GLM family object.</h2><span id='topic+glm.binomial'></span>

<h3>Description</h3>

<p>A GLM family object specifies the type of model fit, provides the appropriate response object and makes sure it is represented in the right form for the model family, and allows for optional parameters such as a weight vector.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>glm.binomial(y, weights = NULL, link = "logit")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="glm.binomial_+3A_y">y</code></td>
<td>
<p>Binary response vector, with values 0 or 1, or a logical vector. Alternatively, if data are represented by a two-column matrix of proportions (with row-sums = 1), then one can provide one of the columns as the response. This is useful for grouped binomial data, where each observation represents the result of <code>m[i]</code> successes out of <code>n[i]</code> trials. Then the response is provided as <code>y[i] = m[i]/n[i]</code> and the corresponding element of the weight vector as <code>w[i]=n[i]</code>. Alternatively can use <code>glm.multinomial()</code> instead.</p>
</td></tr>
<tr><td><code id="glm.binomial_+3A_weights">weights</code></td>
<td>
<p>Observation weight vector, with default <code>NULL</code>, which results in weight <code>1/n</code> for each observation.</p>
</td></tr>
<tr><td><code id="glm.binomial_+3A_link">link</code></td>
<td>
<p>The link function type, with choice <code>"logit"</code> (default) or <code>"probit"</code>).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Binomial GLM object.
</p>


<h3>Author(s)</h3>

<p>Trevor Hastie and James Yang<br /> Maintainer: Trevor Hastie <a href="mailto:hastie@stanford.edu">hastie@stanford.edu</a>
</p>


<h3>See Also</h3>

<p><code>glm.gaussian</code>, <code>glm.binomial</code>, <code>glm.poisson</code>,  <code>glm.multinomial</code>, <code>glm.multigaussian</code>, <code>glm.cox</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 100
y &lt;- rbinom(n, 1, 0.5)
obj &lt;- glm.binomial(y)
</code></pre>

<hr>
<h2 id='glm.cox'>Creates a Cox GLM family object.</h2><span id='topic+glm.cox'></span>

<h3>Description</h3>

<p>A GLM family object specifies the type of model fit, provides the appropriate response object and makes sure it is represented in the right form for the model family, and allows for optional parameters such as a weight vector.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>glm.cox(
  stop,
  status,
  start = -Inf,
  strata = NULL,
  weights = NULL,
  tie_method = c("efron", "breslow")
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="glm.cox_+3A_stop">stop</code></td>
<td>
<p>Stop time vector.</p>
</td></tr>
<tr><td><code id="glm.cox_+3A_status">status</code></td>
<td>
<p>Binary status vector of same length as <code>stop</code>, with 1 a &quot;death&quot;, and 0 censored.</p>
</td></tr>
<tr><td><code id="glm.cox_+3A_start">start</code></td>
<td>
<p>Start time vector. Default is a vector of <code>-Inf</code> of same length as <code>stop</code>.</p>
</td></tr>
<tr><td><code id="glm.cox_+3A_strata">strata</code></td>
<td>
<p>Observations can belong in strata, labeled 1,2, .... If <code>strata = NULL</code> then all observations are in a single stratum.</p>
</td></tr>
<tr><td><code id="glm.cox_+3A_weights">weights</code></td>
<td>
<p>Observation weights, with default <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="glm.cox_+3A_tie_method">tie_method</code></td>
<td>
<p>The tie-breaking method - one of  <code>"efron"</code> (default) or <code>"breslow"</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Cox GLM object.
</p>


<h3>Author(s)</h3>

<p>James Yang, Trevor Hastie, and  Balasubramanian Narasimhan <br /> Maintainer: Trevor Hastie <a href="mailto:hastie@stanford.edu">hastie@stanford.edu</a>
</p>


<h3>See Also</h3>

<p><code>glm.gaussian</code>, <code>glm.binomial</code>, <code>glm.poisson</code>,  <code>glm.multinomial</code>, <code>glm.multigaussian</code>, <code>glm.cox</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 100
start &lt;- sample.int(20, size = n, replace = TRUE)
stop &lt;- start + 1 + sample.int(5, size = n, replace = TRUE)
status &lt;- rbinom(n, 1, 0.5)
strata &lt;- sample(c(1,2), n, replace = TRUE)
obj1 &lt;- glm.cox(stop, status)
obj2 &lt;- glm.cox(stop, status, start = start)
obj3 &lt;- glm.cox(stop, status, start = start, strata = strata)
</code></pre>

<hr>
<h2 id='glm.gaussian'>Creates a Gaussian GLM family object.</h2><span id='topic+glm.gaussian'></span>

<h3>Description</h3>

<p>A GLM family object specifies the type of model fit, provides the appropriate response object and makes sure it is represented in the right form for the model family, and allows for optional parameters such as a weight vector.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>glm.gaussian(y, weights = NULL, opt = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="glm.gaussian_+3A_y">y</code></td>
<td>
<p>Response vector.</p>
</td></tr>
<tr><td><code id="glm.gaussian_+3A_weights">weights</code></td>
<td>
<p>Observation weight vector, with default <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="glm.gaussian_+3A_opt">opt</code></td>
<td>
<p>If <code>TRUE</code> (default), an optimized routine is run.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Gaussian GLM
</p>


<h3>Author(s)</h3>

<p>James Yang, Trevor Hastie, and  Balasubramanian Narasimhan <br /> Maintainer: Trevor Hastie <a href="mailto:hastie@stanford.edu">hastie@stanford.edu</a>
</p>


<h3>See Also</h3>

<p><code>glm.gaussian</code>, <code>glm.binomial</code>, <code>glm.poisson</code>,  <code>glm.multinomial</code>, <code>glm.multigaussian</code>, <code>glm.cox</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 100
y &lt;- rnorm(n)
obj &lt;- glm.gaussian(y)
</code></pre>

<hr>
<h2 id='glm.multigaussian'>Creates a MultiGaussian GLM family object.</h2><span id='topic+glm.multigaussian'></span>

<h3>Description</h3>

<p>A GLM family object specifies the type of model fit, provides the appropriate response object and makes sure it is represented in the right form for the model family, and allows for optional parameters such as a weight vector.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>glm.multigaussian(y, weights = NULL, opt = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="glm.multigaussian_+3A_y">y</code></td>
<td>
<p>Response matrix, with two or more columns.</p>
</td></tr>
<tr><td><code id="glm.multigaussian_+3A_weights">weights</code></td>
<td>
<p>Observation weight vector, with default <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="glm.multigaussian_+3A_opt">opt</code></td>
<td>
<p>If <code>TRUE</code> (default), an optimized routine is run.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>MultiGaussian GLM object.
</p>


<h3>Author(s)</h3>

<p>James Yang, Trevor Hastie, and  Balasubramanian Narasimhan <br /> Maintainer: Trevor Hastie <a href="mailto:hastie@stanford.edu">hastie@stanford.edu</a>
</p>


<h3>See Also</h3>

<p><code>glm.gaussian</code>, <code>glm.binomial</code>, <code>glm.poisson</code>,  <code>glm.multinomial</code>, <code>glm.multigaussian</code>, <code>glm.cox</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 100
K &lt;- 5
y &lt;- matrix(rnorm(n*K), n, K)
obj &lt;- glm.multigaussian(y)
</code></pre>

<hr>
<h2 id='glm.multinomial'>Creates a Multinomial GLM family object.</h2><span id='topic+glm.multinomial'></span>

<h3>Description</h3>

<p>A GLM family object specifies the type of model fit, provides the appropriate response object and makes sure it is represented in the right form for the model family, and allows for optional parameters such as a weight vector.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>glm.multinomial(y, weights = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="glm.multinomial_+3A_y">y</code></td>
<td>
<p>Response matrix with <code>K&gt;1</code> columns, and row sums equal to 1. This can either be a &quot;one-hot&quot; encoded version of a K-category factor variable, or else a matrix of proportions. This is useful for grouped multinomial data, where column <code>y[i, k]</code> represents the proportion of outcomes in category k in <code>n[i]</code> trials. Then the corresponding element of the weight vector is <code>w[i]=n[i]</code>.</p>
</td></tr>
<tr><td><code id="glm.multinomial_+3A_weights">weights</code></td>
<td>
<p>Observation weights.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Multinomial GLM object.
</p>


<h3>Author(s)</h3>

<p>James Yang, Trevor Hastie, and  Balasubramanian Narasimhan <br /> Maintainer: Trevor Hastie <a href="mailto:hastie@stanford.edu">hastie@stanford.edu</a>
</p>


<h3>See Also</h3>

<p><code>glm.gaussian</code>, <code>glm.binomial</code>, <code>glm.poisson</code>,  <code>glm.multinomial</code>, <code>glm.multigaussian</code>, <code>glm.cox</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 100
K &lt;- 5
y &lt;- t(rmultinom(n, 1, rep(1/K, K)))
obj &lt;- glm.multinomial(y)
</code></pre>

<hr>
<h2 id='glm.poisson'>Creates a Poisson GLM family object.</h2><span id='topic+glm.poisson'></span>

<h3>Description</h3>

<p>A GLM family object specifies the type of model fit, provides the appropriate response object and makes sure it is represented in the right form for the model family, and allows for optional parameters such as a weight vector.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>glm.poisson(y, weights = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="glm.poisson_+3A_y">y</code></td>
<td>
<p>Response vector of non-negative counts.</p>
</td></tr>
<tr><td><code id="glm.poisson_+3A_weights">weights</code></td>
<td>
<p>Observation weight vector, with default <code>NULL</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Poisson GLM object.
</p>


<h3>Author(s)</h3>

<p>James Yang, Trevor Hastie, and  Balasubramanian Narasimhan <br /> Maintainer: Trevor Hastie <a href="mailto:hastie@stanford.edu">hastie@stanford.edu</a>
</p>


<h3>See Also</h3>

<p><code>glm.gaussian</code>, <code>glm.binomial</code>, <code>glm.poisson</code>,  <code>glm.multinomial</code>, <code>glm.multigaussian</code>, <code>glm.cox</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 100
y &lt;- rpois(n, 1)
obj &lt;- glm.poisson(y)
</code></pre>

<hr>
<h2 id='grpnet'>fit a GLM with group lasso or group elastic-net regularization</h2><span id='topic+grpnet'></span>

<h3>Description</h3>

<p>Computes a group elastic-net regularization path for a variety of
GLM and other families, including the Cox model. This function
extends the abilities of the <code>glmnet</code> package to allow for
grouped regularization. The code is very efficient (core routines
are written in C++), and allows for specialized matrix
classes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>grpnet(
  X,
  glm,
  constraints = NULL,
  groups = NULL,
  alpha = 1,
  penalty = NULL,
  offsets = NULL,
  lambda = NULL,
  standardize = TRUE,
  irls_max_iters = as.integer(10000),
  irls_tol = 1e-07,
  max_iters = as.integer(1e+05),
  tol = 1e-07,
  adev_tol = 0.9,
  ddev_tol = 0,
  newton_tol = 1e-12,
  newton_max_iters = 1000,
  n_threads = 1,
  early_exit = TRUE,
  intercept = TRUE,
  screen_rule = c("pivot", "strong"),
  min_ratio = 0.01,
  lmda_path_size = 100,
  max_screen_size = NULL,
  max_active_size = NULL,
  pivot_subset_ratio = 0.1,
  pivot_subset_min = 1,
  pivot_slack_ratio = 1.25,
  check_state = FALSE,
  progress_bar = FALSE,
  warm_start = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="grpnet_+3A_x">X</code></td>
<td>
<p>Feature matrix. Either a regular R matrix, or else an
<code>adelie</code> custom matrix class, or a concatination of such.</p>
</td></tr>
<tr><td><code id="grpnet_+3A_glm">glm</code></td>
<td>
<p>GLM family/response object. This is an expression that
represents the family, the reponse and other arguments such as
weights, if present. The choices are <code>glm.gaussian()</code>,
<code>glm.binomial()</code>, <code>glm.poisson()</code>,
<code>glm.multinomial()</code>, <code>glm.cox()</code>, <code>glm.multinomial()</code>,
and <code>glm.multigaussian()</code>. This is a required argument, and
there is no default. In the simple example below, we use <code>glm.gaussian(y)</code>.</p>
</td></tr>
<tr><td><code id="grpnet_+3A_constraints">constraints</code></td>
<td>
<p>Group-wise constraints on the parameters, supplied as a list with an element for each group. Default is <code>NULL</code>, which means no constraints. List elements can be <code>NULL</code> as well. Currently only 'box constraints' are supported, which means upper and lower limits. The function <code>constraint.box()</code> must be used to set the constraints for each group that has constraints. Details are given in the documentation for <code>constraint.box</code>.</p>
</td></tr>
<tr><td><code id="grpnet_+3A_groups">groups</code></td>
<td>
<p>This is an ordered vector of integers that represents the groupings,
with each entry indicating where a group begins.  The entries refer to column numbers
in the feature matrix, and hence the memebers of a group have to be contiguous.
If there are <code>p</code> features, the default is <code>1:p</code> (no groups; i.e. <code>p</code> groups each of of size 1). So the length of <code>groups</code> is the number of groups.
(Note that in the <code>state</code> output of <code>grpnet</code> this vector might be shifted to start from 0,
since internally <code>adelie</code> uses zero-based indexing.)</p>
</td></tr>
<tr><td><code id="grpnet_+3A_alpha">alpha</code></td>
<td>
<p>The elasticnet mixing parameter, with <code class="reqn">0\le\alpha\le 1</code>.
The penalty is defined as
</p>
<p style="text-align: center;"><code class="reqn">(1-\alpha)/2\sum_j||\beta_j||_2^2+\alpha\sum_j||\beta_j||_2,</code>
</p>
<p> where thte sum is over groups.
<code>alpha=1</code> is pure group
lasso penalty, and <code>alpha=0</code> the pure ridge penalty.</p>
</td></tr>
<tr><td><code id="grpnet_+3A_penalty">penalty</code></td>
<td>
<p>Separate penalty factors can be applied to each group of coefficients.
This is a number that multiplies <code>lambda</code> to allow
differential shrinkage for groups. Can be 0 for some groups, which implies no
shrinkage, and that group is always included in the model.
Default is square-root of group sizes for each group.</p>
</td></tr>
<tr><td><code id="grpnet_+3A_offsets">offsets</code></td>
<td>
<p>Offsets, default is <code>NULL</code>. If present, this is
a fixed vector or matrix corresponding to the shape of the natural
parameter, and is added to the fit.</p>
</td></tr>
<tr><td><code id="grpnet_+3A_lambda">lambda</code></td>
<td>
<p>A user supplied <code>lambda</code> sequence. Typical usage is to
have the program compute its own <code>lambda</code> sequence based on
<code>lmda_path_size</code> and <code>min_ratio</code>. This is returned with the fit.</p>
</td></tr>
<tr><td><code id="grpnet_+3A_standardize">standardize</code></td>
<td>
<p>If <code>TRUE</code> (the default), the columns of <code>X</code> are standardized before the
fit is computed. This is good practice if the features are on different scales, because it has an impact on
the penalty. The regularization path is computed using the standardized features, and the
standardization information is saved on the object for making future predictions. The different matrix classes have their own methods for standardization. For example, for a sparse matrix the standardization information will be computed, but not actually applied (eg centering would destroy the sparsity). Rather, the methods for matrix multiply will be aware, and incorporate the standardization information.</p>
</td></tr>
<tr><td><code id="grpnet_+3A_irls_max_iters">irls_max_iters</code></td>
<td>
<p>Maximum number of IRLS iterations, default is
<code>1e4</code>.</p>
</td></tr>
<tr><td><code id="grpnet_+3A_irls_tol">irls_tol</code></td>
<td>
<p>IRLS convergence tolerance, default is <code>1e-7</code>.</p>
</td></tr>
<tr><td><code id="grpnet_+3A_max_iters">max_iters</code></td>
<td>
<p>Maximum total number of coordinate descent
iterations, default is <code>1e5</code>.</p>
</td></tr>
<tr><td><code id="grpnet_+3A_tol">tol</code></td>
<td>
<p>Coordinate descent convergence tolerance, default <code>1e-7</code>.</p>
</td></tr>
<tr><td><code id="grpnet_+3A_adev_tol">adev_tol</code></td>
<td>
<p>Fraction deviance explained tolerance, default
<code>0.9</code>. This can be seen as a limit on overfitting the
training data.</p>
</td></tr>
<tr><td><code id="grpnet_+3A_ddev_tol">ddev_tol</code></td>
<td>
<p>Difference in fraction deviance explained
tolerance, default <code>0</code>. If a step in the path changes the
deviance by this amount or less, the algorithm truncates the
path.</p>
</td></tr>
<tr><td><code id="grpnet_+3A_newton_tol">newton_tol</code></td>
<td>
<p>Convergence tolerance for the BCD update, default
<code>1e-12</code>. This parameter controls the iterations in each
block-coordinate step to establish the block solution.</p>
</td></tr>
<tr><td><code id="grpnet_+3A_newton_max_iters">newton_max_iters</code></td>
<td>
<p>Maximum number of iterations for the BCD
update, default <code>1000</code>.</p>
</td></tr>
<tr><td><code id="grpnet_+3A_n_threads">n_threads</code></td>
<td>
<p>Number of threads, default <code>1</code>.</p>
</td></tr>
<tr><td><code id="grpnet_+3A_early_exit">early_exit</code></td>
<td>
<p><code>TRUE</code> if the function should be allowed to exit
early.</p>
</td></tr>
<tr><td><code id="grpnet_+3A_intercept">intercept</code></td>
<td>
<p>Default <code>TRUE</code> to include an unpenalized
intercept.</p>
</td></tr>
<tr><td><code id="grpnet_+3A_screen_rule">screen_rule</code></td>
<td>
<p>Screen rule, with default <code>"pivot"</code>. Other option is <code>"strong"</code>.
(an empirical improvement over <code>"strong"</code>, the other option.)</p>
</td></tr>
<tr><td><code id="grpnet_+3A_min_ratio">min_ratio</code></td>
<td>
<p>Ratio between smallest and largest value of lambda. Default is 1e-2.</p>
</td></tr>
<tr><td><code id="grpnet_+3A_lmda_path_size">lmda_path_size</code></td>
<td>
<p>Number of values for <code>lambda</code>, if generated automatically.
Default is 100.</p>
</td></tr>
<tr><td><code id="grpnet_+3A_max_screen_size">max_screen_size</code></td>
<td>
<p>Maximum number of screen groups. Default is <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="grpnet_+3A_max_active_size">max_active_size</code></td>
<td>
<p>Maximum number of active groups. Default is <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="grpnet_+3A_pivot_subset_ratio">pivot_subset_ratio</code></td>
<td>
<p>Subset ratio of pivot rule. Default is <code>0.1</code>. Users not expected to fiddle with this.</p>
</td></tr>
<tr><td><code id="grpnet_+3A_pivot_subset_min">pivot_subset_min</code></td>
<td>
<p>Minimum subset of pivot rule. Defaults is <code>1</code>. Users not expected to fiddle with this.</p>
</td></tr>
<tr><td><code id="grpnet_+3A_pivot_slack_ratio">pivot_slack_ratio</code></td>
<td>
<p>Slack ratio of pivot rule, default is <code>1.25</code>. Users not expected to fiddle with this.
See reference for details.</p>
</td></tr>
<tr><td><code id="grpnet_+3A_check_state">check_state</code></td>
<td>
<p>Check state. Internal parameter, with default <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="grpnet_+3A_progress_bar">progress_bar</code></td>
<td>
<p>Progress bar. Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="grpnet_+3A_warm_start">warm_start</code></td>
<td>
<p>Warm start (default is <code>NULL</code>). Internal parameter.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of class <code>"grpnet"</code>. This has a main component called <code>state</code> which
represents the fitted path, and a few extra
useful components such as the <code>call</code>, the <code>family</code> name, <code>groups</code> and <code>group_sizes</code>.
Users are encouraged to use methods like <code>predict()</code>, <code>coef()</code>, <code>print()</code>, <code>plot()</code> etc to examine the object.
</p>


<h3>Author(s)</h3>

<p>James Yang, Trevor Hastie, and  Balasubramanian Narasimhan <br /> Maintainer: Trevor Hastie
<a href="mailto:hastie@stanford.edu">hastie@stanford.edu</a>
</p>


<h3>References</h3>

<p>Yang, James and Hastie, Trevor. (2024) A Fast and Scalable Pathwise-Solver for Group Lasso
and Elastic Net Penalized Regression via Block-Coordinate Descent. arXiv <a href="https://doi.org/10.48550/arXiv.2405.08631">doi:10.48550/arXiv.2405.08631</a>.<br />
Friedman, J., Hastie, T. and Tibshirani, R. (2008)
<em>Regularization Paths for Generalized Linear Models via Coordinate
Descent (2010), Journal of Statistical Software, Vol. 33(1), 1-22</em>,
<a href="https://doi.org/10.18637/jss.v033.i01">doi:10.18637/jss.v033.i01</a>.<br />
Simon, N., Friedman, J., Hastie, T. and Tibshirani, R. (2011)
<em>Regularization Paths for Cox's Proportional
Hazards Model via Coordinate Descent, Journal of Statistical Software, Vol.
39(5), 1-13</em>,
<a href="https://doi.org/10.18637/jss.v039.i05">doi:10.18637/jss.v039.i05</a>.<br />
Tibshirani,Robert, Bien, J., Friedman, J., Hastie, T.,Simon, N., Taylor, J. and
Tibshirani, Ryan. (2012) <em>Strong Rules for Discarding Predictors in
Lasso-type Problems, JRSSB, Vol. 74(2), 245-266</em>,
<a href="https://arxiv.org/abs/1011.2234">https://arxiv.org/abs/1011.2234</a>.<br />
</p>


<h3>See Also</h3>

<p><code>cv.grpnet</code>, <code>predict.grpnet</code>, <code>coef.grpnet</code>, <code>plot.grpnet</code>, <code>print.grpnet</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(0)
n &lt;- 100
p &lt;- 200
X &lt;- matrix(rnorm(n * p), n, p)
y &lt;- X[,1] * rnorm(1) + rnorm(n)
## Here we create 60 groups randomly. Groups need to be contiguous, and the `groups` variable
## indicates the beginning position of each group.
groups &lt;- c(1, sample(2:199, 60, replace = FALSE))
groups &lt;- sort(groups)
print(groups)
fit &lt;- grpnet(X, glm.gaussian(y), groups = groups)
print(fit)
plot(fit)
coef(fit)
cvfit  &lt;- cv.grpnet(X, glm.gaussian(y), groups = groups)
print(cvfit)
plot(cvfit)
predict(cvfit,newx=X[1:5,], lambda="lambda.min")
</code></pre>

<hr>
<h2 id='io.snp_phased_ancestry'>IO handler for SNP phased, ancestry matrix.</h2><span id='topic+io.snp_phased_ancestry'></span>

<h3>Description</h3>

<p>IO handler for SNP phased, ancestry matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>io.snp_phased_ancestry(filename, read_mode = "file")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="io.snp_phased_ancestry_+3A_filename">filename</code></td>
<td>
<p>File name.</p>
</td></tr>
<tr><td><code id="io.snp_phased_ancestry_+3A_read_mode">read_mode</code></td>
<td>
<p>Reading mode.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>IO handler for SNP phased, ancestry data.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 123
s &lt;- 423
A &lt;- 8
filename &lt;- paste(tempdir(), "snp_phased_ancestry_dummy.snpdat", sep="/")
handle &lt;- io.snp_phased_ancestry(filename)
calldata &lt;- matrix(
    as.integer(sample.int(
        2, n * s * 2,
        replace=TRUE,
        prob=c(0.7, 0.3)
    ) - 1),
    n, s * 2
)
ancestries &lt;- matrix(
    as.integer(sample.int(
        A, n * s * 2,
        replace=TRUE,
        prob=rep_len(1/A, A)
    ) - 1),
    n, s * 2
)
handle$write(calldata, ancestries, A, 1)
handle$read()
file.remove(filename)
</code></pre>

<hr>
<h2 id='io.snp_unphased'>IO handler for SNP unphased matrix.</h2><span id='topic+io.snp_unphased'></span>

<h3>Description</h3>

<p>IO handler for SNP unphased matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>io.snp_unphased(filename, read_mode = "file")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="io.snp_unphased_+3A_filename">filename</code></td>
<td>
<p>File name.</p>
</td></tr>
<tr><td><code id="io.snp_unphased_+3A_read_mode">read_mode</code></td>
<td>
<p>Reading mode.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>IO handler for SNP unphased data.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 123
s &lt;- 423
filename &lt;- paste(tempdir(), "snp_unphased_dummy.snpdat", sep="/")
handle &lt;- io.snp_unphased(filename)
mat &lt;- matrix(
    as.integer(sample.int(
        3, n * s, 
        replace=TRUE, 
        prob=c(0.7, 0.2, 0.1)
    ) - 1),
    n, s
)
impute &lt;- double(s)
handle$write(mat, "mean", impute, 1)
handle$read()
file.remove(filename)
</code></pre>

<hr>
<h2 id='matrix.block_diag'>Creates a block-diagonal matrix.</h2><span id='topic+matrix.block_diag'></span>

<h3>Description</h3>

<p>Creates a block-diagonal matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>matrix.block_diag(mats, method = c("naive", "cov"), n_threads = 1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="matrix.block_diag_+3A_mats">mats</code></td>
<td>
<p>List of matrices.</p>
</td></tr>
<tr><td><code id="matrix.block_diag_+3A_method">method</code></td>
<td>
<p>Method type, with  default <code>method="naive"</code>.</p>
</td></tr>
<tr><td><code id="matrix.block_diag_+3A_n_threads">n_threads</code></td>
<td>
<p>Number of threads.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Block-diagonal matrix.
</p>


<h3>Author(s)</h3>

<p>Trevor Hastie and James Yang<br /> Maintainer: Trevor Hastie <a href="mailto:hastie@stanford.edu">hastie@stanford.edu</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 100
ps &lt;- c(10, 20, 30)
mats &lt;- lapply(ps, function(p) {
    X &lt;- matrix(rnorm(n * p), n, p)
    matrix.dense(t(X) %*% X, method="cov")
})
out &lt;- matrix.block_diag(mats, method="cov")
mats &lt;- lapply(ps, function(p) {
    X &lt;- matrix(rnorm(n * p), n, p)
    matrix.dense(X, method="naive")
})
out &lt;- matrix.block_diag(mats, method="naive")
</code></pre>

<hr>
<h2 id='matrix.concatenate'>Creates a concatenation of the matrices.</h2><span id='topic+matrix.concatenate'></span>

<h3>Description</h3>

<p>Creates a concatenation of the matrices.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>matrix.concatenate(mats, axis = 2, n_threads = 1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="matrix.concatenate_+3A_mats">mats</code></td>
<td>
<p>List of matrices.</p>
</td></tr>
<tr><td><code id="matrix.concatenate_+3A_axis">axis</code></td>
<td>
<p>The axis along which the matrices will be joined. With axis = 2 (default) this function is equivalent to <code>cbind()</code> and axis = 1 is equivalent to <code>rbind()</code>.</p>
</td></tr>
<tr><td><code id="matrix.concatenate_+3A_n_threads">n_threads</code></td>
<td>
<p>Number of threads.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Concatenation of matrices.
The object is an S4 class with methods for efficient computation in C++ by adelie. Note that for the object itself axis is represented with base 0 (so 1 less than the argument here).
</p>


<h3>Author(s)</h3>

<p>Trevor Hastie and James Yang<br /> Maintainer: Trevor Hastie <a href="mailto:hastie@stanford.edu">hastie@stanford.edu</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 100
ps &lt;- c(10, 20, 30)
n &lt;- 100
mats &lt;- lapply(ps, function(p) {
    matrix.dense(matrix(rnorm(n * p), n, p))
})
out &lt;- matrix.concatenate(mats, axis=2)
</code></pre>

<hr>
<h2 id='matrix.convex_relu'>Creates a feature matrix for the convex relu problem.</h2><span id='topic+matrix.convex_relu'></span>

<h3>Description</h3>

<p>Creates a feature matrix for the convex relu problem.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>matrix.convex_relu(mat, mask, gated = FALSE, n_threads = 1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="matrix.convex_relu_+3A_mat">mat</code></td>
<td>
<p>Base feature matrix. It is either a dense or sparse matrix.</p>
</td></tr>
<tr><td><code id="matrix.convex_relu_+3A_mask">mask</code></td>
<td>
<p>Boolean mask matrix.</p>
</td></tr>
<tr><td><code id="matrix.convex_relu_+3A_gated">gated</code></td>
<td>
<p>Flag to indicate whether to use the convex gated relu feature matrix.</p>
</td></tr>
<tr><td><code id="matrix.convex_relu_+3A_n_threads">n_threads</code></td>
<td>
<p>Number of threads.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Convex relu feature matrix.
The object is an S4 class with methods for efficient computation in C++ by adelie.
</p>


<h3>Author(s)</h3>

<p>Trevor Hastie and James Yang<br /> Maintainer: Trevor Hastie <a href="mailto:hastie@stanford.edu">hastie@stanford.edu</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 100
p &lt;- 20
m &lt;- 10
Z_dense &lt;- matrix(rnorm(n * p), n, p)
mask &lt;- matrix(rbinom(n * m, 1, 0.5), n, m)
out &lt;- matrix.convex_relu(Z_dense, mask)
Z_sparse &lt;- as(Z_dense, "dgCMatrix")
out &lt;- matrix.convex_relu(Z_sparse, mask)
</code></pre>

<hr>
<h2 id='matrix.dense'>Creates a dense matrix object.</h2><span id='topic+matrix.dense'></span>

<h3>Description</h3>

<p>Creates a dense matrix object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>matrix.dense(mat, method = c("naive", "cov", "constraint"), n_threads = 1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="matrix.dense_+3A_mat">mat</code></td>
<td>
<p>The dense matrix.</p>
</td></tr>
<tr><td><code id="matrix.dense_+3A_method">method</code></td>
<td>
<p>Method type, with  default <code>method="naive"</code>.
If <code>method="cov"</code>, the matrix is used with the solver <code>gaussian_cov()</code>.
Used for <code>glm.gaussian()</code> and <code>glm.multigaussian()</code> families. Generally &quot;naive&quot; is used for wide matrices, and &quot;cov&quot; for tall matrices.
If <code>method="constraint"</code>, the matrix is used as input to the constraint objects.</p>
</td></tr>
<tr><td><code id="matrix.dense_+3A_n_threads">n_threads</code></td>
<td>
<p>Number of threads.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Dense matrix.
The object is an S4 class with methods for efficient computation by adelie.
</p>


<h3>Author(s)</h3>

<p>Trevor Hastie and James Yang<br /> Maintainer: Trevor Hastie <a href="mailto:hastie@stanford.edu">hastie@stanford.edu</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 100
p &lt;- 20
X_dense &lt;- matrix(rnorm(n * p), n, p)
out &lt;- matrix.dense(X_dense, method="naive")
A_dense &lt;- t(X_dense) %*% X_dense
out &lt;- matrix.dense(A_dense, method="cov")
out &lt;- matrix.dense(X_dense, method="constraint")
</code></pre>

<hr>
<h2 id='matrix.eager_cov'>Creates an eager covariance matrix.</h2><span id='topic+matrix.eager_cov'></span>

<h3>Description</h3>

<p>Creates an eager covariance matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>matrix.eager_cov(mat, n_threads = 1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="matrix.eager_cov_+3A_mat">mat</code></td>
<td>
<p>A dense matrix to be used with the <code>gaussian_cov()</code> solver.</p>
</td></tr>
<tr><td><code id="matrix.eager_cov_+3A_n_threads">n_threads</code></td>
<td>
<p>Number of threads.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The dense covariance matrix. This matrix is exactly <code>t(mat)%*%mat</code>, computed with some efficiency.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 100
p &lt;- 20
mat &lt;- matrix(rnorm(n * p), n, p)
out &lt;- matrix.eager_cov(mat)
</code></pre>

<hr>
<h2 id='matrix.interaction'>Creates a matrix with pairwise interactions.</h2><span id='topic+matrix.interaction'></span>

<h3>Description</h3>

<p>Creates a matrix with pairwise interactions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>matrix.interaction(
  mat,
  intr_keys = NULL,
  intr_values,
  levels = NULL,
  n_threads = 1
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="matrix.interaction_+3A_mat">mat</code></td>
<td>
<p>The dense matrix, which can include factors with levels coded as non-negative integers.</p>
</td></tr>
<tr><td><code id="matrix.interaction_+3A_intr_keys">intr_keys</code></td>
<td>
<p>List of feature indices. This is a list of all features with which interactions can be formed. Default is <code>1:p</code> where <code>p</code> is the number of columns in <code>mat</code>.</p>
</td></tr>
<tr><td><code id="matrix.interaction_+3A_intr_values">intr_values</code></td>
<td>
<p>List of integer vectors of feature indices. For each of the <code>m &lt;= p</code> indices listed in <code>intr_keys</code>, there is a vector of indices indicating which columns are candidates for interaction with that feature. If a list is <code>list(NULL)</code>, that means all other features are candidates for interactions.  The default is a list of length <code>m</code> where each element is <code>list(NULL)</code>; that is <code>rep(list(NULL), m</code>.</p>
</td></tr>
<tr><td><code id="matrix.interaction_+3A_levels">levels</code></td>
<td>
<p>Number of levels for each of the columns of <code>mat</code>, with <code>1</code> representing a quantitative feature. A factor with <code>K</code> levels should be represented by the numbers <code>0,1,...,K-1</code>.</p>
</td></tr>
<tr><td><code id="matrix.interaction_+3A_n_threads">n_threads</code></td>
<td>
<p>Number of threads.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Pairwise interaction matrix. Logic is used to avoid repetitions. For each factor variable, the column is one-hot-encoded to form a basis for that feature.
The object is an S4 class with methods for efficient computation by adelie. Note that some of the arguments are transformed to C++ base 0 for internal use, and if the object is examined, it will reflect that.
</p>


<h3>Author(s)</h3>

<p>Trevor Hastie and James Yang<br /> Maintainer: Trevor Hastie <a href="mailto:hastie@stanford.edu">hastie@stanford.edu</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 10
p &lt;- 20
X_dense &lt;- matrix(rnorm(n * p), n, p)
X_dense[,1] &lt;- rbinom(n, 4, 0.5)
intr_keys &lt;- c(1, 2)
intr_values &lt;- list(NULL, c(1, 3))
levels &lt;- c(c(5), rep(1, p-1))
out &lt;- matrix.interaction(X_dense, intr_keys, intr_values, levels)
</code></pre>

<hr>
<h2 id='matrix.kronecker_eye'>Creates a Kronecker product with an identity matrix.</h2><span id='topic+matrix.kronecker_eye'></span>

<h3>Description</h3>

<p>Creates a Kronecker product with an identity matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>matrix.kronecker_eye(mat, K = 1, n_threads = 1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="matrix.kronecker_eye_+3A_mat">mat</code></td>
<td>
<p>The matrix to view as a Kronecker product.</p>
</td></tr>
<tr><td><code id="matrix.kronecker_eye_+3A_k">K</code></td>
<td>
<p>Dimension of the identity matrix (default is 1, which does essentially nothing).</p>
</td></tr>
<tr><td><code id="matrix.kronecker_eye_+3A_n_threads">n_threads</code></td>
<td>
<p>Number of threads.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Kronecker product with identity matrix. If <code>mat</code> is n x p, the the resulting matrix will be nK x np.
The object is an S4 class with methods for efficient computation by adelie.
</p>


<h3>Author(s)</h3>

<p>James Yang, Trevor Hastie, and  Balasubramanian Narasimhan <br /> Maintainer: Trevor Hastie <a href="mailto:hastie@stanford.edu">hastie@stanford.edu</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 100
p &lt;- 20
K &lt;- 2
mat &lt;- matrix(rnorm(n * p), n, p)
out &lt;- matrix.kronecker_eye(mat, K)
mat &lt;- matrix.dense(mat)
out &lt;- matrix.kronecker_eye(mat, K)
</code></pre>

<hr>
<h2 id='matrix.lazy_cov'>Creates a lazy covariance matrix.</h2><span id='topic+matrix.lazy_cov'></span>

<h3>Description</h3>

<p>Creates a lazy covariance matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>matrix.lazy_cov(mat, n_threads = 1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="matrix.lazy_cov_+3A_mat">mat</code></td>
<td>
<p>A dense  data matrix to be used with the <code>gaussian_cov()</code> solver.</p>
</td></tr>
<tr><td><code id="matrix.lazy_cov_+3A_n_threads">n_threads</code></td>
<td>
<p>Number of threads.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Lazy covariance matrix. This is essentially the same matrix, but with a setup to create covariance terms as needed on the fly.
The object is an S4 class with methods for efficient computation by adelie.
</p>


<h3>Author(s)</h3>

<p>James Yang, Trevor Hastie, and  Balasubramanian Narasimhan <br /> Maintainer: Trevor Hastie <a href="mailto:hastie@stanford.edu">hastie@stanford.edu</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 100
p &lt;- 20
mat &lt;- matrix(rnorm(n * p), n, p)
out &lt;- matrix.lazy_cov(mat)
</code></pre>

<hr>
<h2 id='matrix.one_hot'>Creates a one-hot encoded matrix.</h2><span id='topic+matrix.one_hot'></span>

<h3>Description</h3>

<p>Creates a one-hot encoded matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>matrix.one_hot(mat, levels = NULL, n_threads = 1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="matrix.one_hot_+3A_mat">mat</code></td>
<td>
<p>A dense matrix, which can include factors with levels coded as non-negative integers.</p>
</td></tr>
<tr><td><code id="matrix.one_hot_+3A_levels">levels</code></td>
<td>
<p>Number of levels for each of the columns of <code>mat</code>, with <code>1</code> representing a quantitative feature. A factor with <code>K</code> levels should be represented by the numbers <code>0,1,...,K-1</code>.</p>
</td></tr>
<tr><td><code id="matrix.one_hot_+3A_n_threads">n_threads</code></td>
<td>
<p>Number of threads.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>One-hot encoded matrix. All the factor columns, with levels&gt;1, are replaced by a collection of one-hot encoded versions (dummy matrices). The resulting matrix has <code>sum(levels)</code> columns.
The object is an S4 class with methods for efficient computation by adelie. Note that some of the arguments are transformed to C++ base 0 for internal use, and if the object is examined, it will reflect that.
</p>


<h3>Author(s)</h3>

<p>James Yang, Trevor Hastie, and  Balasubramanian Narasimhan <br /> Maintainer: Trevor Hastie <a href="mailto:hastie@stanford.edu">hastie@stanford.edu</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 100
p &lt;- 20
mat &lt;- matrix(rnorm(n * p), n, p)
fac &lt;- sample(0:5, n, replace = TRUE)
mat=cbind(fac,mat)
levels &lt;- c(6, rep(1,p))
out &lt;- matrix.one_hot(mat, levels = levels)
</code></pre>

<hr>
<h2 id='matrix.snp_phased_ancestry'>Creates a SNP phased, ancestry matrix.</h2><span id='topic+matrix.snp_phased_ancestry'></span>

<h3>Description</h3>

<p>Creates a SNP phased, ancestry matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>matrix.snp_phased_ancestry(io, n_threads = 1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="matrix.snp_phased_ancestry_+3A_io">io</code></td>
<td>
<p>IO handler.</p>
</td></tr>
<tr><td><code id="matrix.snp_phased_ancestry_+3A_n_threads">n_threads</code></td>
<td>
<p>Number of threads.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>SNP phased, ancestry matrix.
</p>


<h3>Author(s)</h3>

<p>James Yang, Trevor Hastie, and  Balasubramanian Narasimhan <br /> Maintainer: Trevor Hastie <a href="mailto:hastie@stanford.edu">hastie@stanford.edu</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 123
s &lt;- 423
A &lt;- 8
filename &lt;- paste(tempdir(), "snp_phased_ancestry_dummy.snpdat", sep="/")
handle &lt;- io.snp_phased_ancestry(filename)
calldata &lt;- matrix(
    as.integer(sample.int(
        2, n * s * 2,
        replace=TRUE,
        prob=c(0.7, 0.3)
    ) - 1),
    n, s * 2
)
ancestries &lt;- matrix(
    as.integer(sample.int(
        A, n * s * 2,
        replace=TRUE,
        prob=rep_len(1/A, A)
    ) - 1),
    n, s * 2
)
handle$write(calldata, ancestries, A, 1)
out &lt;- matrix.snp_phased_ancestry(handle)
file.remove(filename)
</code></pre>

<hr>
<h2 id='matrix.snp_unphased'>Creates a SNP unphased matrix.</h2><span id='topic+matrix.snp_unphased'></span>

<h3>Description</h3>

<p>Creates a SNP unphased matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>matrix.snp_unphased(io, n_threads = 1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="matrix.snp_unphased_+3A_io">io</code></td>
<td>
<p>IO handler.</p>
</td></tr>
<tr><td><code id="matrix.snp_unphased_+3A_n_threads">n_threads</code></td>
<td>
<p>Number of threads.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>SNP unphased matrix.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 123
s &lt;- 423
filename &lt;- paste(tempdir(), "snp_unphased_dummy.snpdat", sep="/")
handle &lt;- io.snp_unphased(filename)
mat &lt;- matrix(
    as.integer(sample.int(
        3, n * s,
        replace=TRUE,
        prob=c(0.7, 0.2, 0.1)
    ) - 1),
    n, s
)
impute &lt;- double(s)
handle$write(mat, "mean", impute, 1)
out &lt;- matrix.snp_unphased(handle)
file.remove(filename)
</code></pre>

<hr>
<h2 id='matrix.sparse'>Creates a sparse matrix object.</h2><span id='topic+matrix.sparse'></span>

<h3>Description</h3>

<p>Creates a sparse matrix object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>matrix.sparse(mat, method = c("naive", "cov", "constraint"), n_threads = 1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="matrix.sparse_+3A_mat">mat</code></td>
<td>
<p>A sparse matrix.</p>
</td></tr>
<tr><td><code id="matrix.sparse_+3A_method">method</code></td>
<td>
<p>Method type, with  default <code>method="naive"</code>.
If <code>method="cov"</code>, the matrix is used with the solver <code>gaussian_cov()</code>.
Used for <code>glm.gaussian()</code> and <code>glm.multigaussian()</code> families. Generally &quot;naive&quot; is used for wide matrices, and &quot;cov&quot; for tall matrices.
If <code>method="constraint"</code>, the matrix is used as input to the constraint objects.</p>
</td></tr>
<tr><td><code id="matrix.sparse_+3A_n_threads">n_threads</code></td>
<td>
<p>Number of threads.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Sparse matrix object.
The object is an S4 class with methods for efficient computation by adelie.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 100
p &lt;- 20
X_dense &lt;- matrix(rnorm(n * p), n, p)
X_sp &lt;- as(X_dense, "dgCMatrix")
out &lt;- matrix.sparse(X_sp, method="naive")
A_dense &lt;- t(X_dense) %*% X_dense
A_sp &lt;- as(A_dense, "dgCMatrix")
out &lt;- matrix.sparse(A_sp, method="cov")
out &lt;- matrix.sparse(X_sp, method="constraint")
</code></pre>

<hr>
<h2 id='matrix.standardize'>Creates a standardized matrix.</h2><span id='topic+matrix.standardize'></span>

<h3>Description</h3>

<p>Creates a standardized matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>matrix.standardize(
  mat,
  centers = NULL,
  scales = NULL,
  weights = NULL,
  ddof = 0,
  n_threads = 1
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="matrix.standardize_+3A_mat">mat</code></td>
<td>
<p>An <code>adelie</code> matrix.</p>
</td></tr>
<tr><td><code id="matrix.standardize_+3A_centers">centers</code></td>
<td>
<p>The center values. Default is to use the column means.</p>
</td></tr>
<tr><td><code id="matrix.standardize_+3A_scales">scales</code></td>
<td>
<p>The scale values. Default is to use the sample standard deviations.</p>
</td></tr>
<tr><td><code id="matrix.standardize_+3A_weights">weights</code></td>
<td>
<p>Observation weight vector, which defaults to 1/n per observation.</p>
</td></tr>
<tr><td><code id="matrix.standardize_+3A_ddof">ddof</code></td>
<td>
<p>Degrees of freedom for standard deviations, with default 0 (1/n). The alternative is 1 leading to 1/(n-1).</p>
</td></tr>
<tr><td><code id="matrix.standardize_+3A_n_threads">n_threads</code></td>
<td>
<p>Number of threads.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Standardized matrix.
The object is an S4 class with methods for efficient computation by adelie.
Conventions depend on the matrix class. For example, if a matrix is constructed using <code>matrix.onehot()</code>, only the quantitative variables are standardized.
</p>


<h3>Author(s)</h3>

<p>James Yang, Trevor Hastie, and  Balasubramanian Narasimhan <br /> Maintainer: Trevor Hastie <a href="mailto:hastie@stanford.edu">hastie@stanford.edu</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 100
p &lt;- 20
X &lt;- matrix(rnorm(n * p), n, p)
out &lt;- matrix.standardize(matrix.dense(X))
</code></pre>

<hr>
<h2 id='matrix.subset'>Creates a subset of the matrix along an axis.</h2><span id='topic+matrix.subset'></span>

<h3>Description</h3>

<p>Creates a subset of the matrix along an axis.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>matrix.subset(mat, indices, axis = 1, n_threads = 1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="matrix.subset_+3A_mat">mat</code></td>
<td>
<p>The <code>adelie</code> matrix to subset.</p>
</td></tr>
<tr><td><code id="matrix.subset_+3A_indices">indices</code></td>
<td>
<p>Vector of indices to subset the matrix.</p>
</td></tr>
<tr><td><code id="matrix.subset_+3A_axis">axis</code></td>
<td>
<p>The axis along which to subset (2 is columns, 1 is rows).</p>
</td></tr>
<tr><td><code id="matrix.subset_+3A_n_threads">n_threads</code></td>
<td>
<p>Number of threads.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Matrix subsetted along the appropriate axis.
The object is an S4 class with methods for efficient computation by adelie.
</p>


<h3>Author(s)</h3>

<p>James Yang, Trevor Hastie, and  Balasubramanian Narasimhan <br /> Maintainer: Trevor Hastie <a href="mailto:hastie@stanford.edu">hastie@stanford.edu</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 100
p &lt;- 20
X &lt;- matrix.dense(matrix(rnorm(n * p), n, p))
indices &lt;- c(1, 3, 10)
out &lt;- matrix.subset(X, indices, axis=1)
out &lt;- matrix.subset(X, indices, axis=2)
</code></pre>

<hr>
<h2 id='plot.cv.glintnet'>plot the cross-validation curve produced by cv.glintnet</h2><span id='topic+plot.cv.glintnet'></span><span id='topic+plot.cv.grpnet'></span>

<h3>Description</h3>

<p>Plots the cross-validation curve, and upper and lower standard deviation
curves, as a function of the <code>lambda</code> values used.
</p>
<p>Plots the cross-validation curve, and upper and lower standard deviation
curves, as a function of the <code>lambda</code> values used.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'cv.glintnet'
plot(x, sign.lambda = -1, ...)

## S3 method for class 'cv.grpnet'
plot(x, sign.lambda = -1, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot.cv.glintnet_+3A_x">x</code></td>
<td>
<p>fitted <code>"cv.grpnet"</code> object</p>
</td></tr>
<tr><td><code id="plot.cv.glintnet_+3A_sign.lambda">sign.lambda</code></td>
<td>
<p>Either plot against <code>log(lambda)</code> or its
negative (default) if <code>sign.lambda=-1</code></p>
</td></tr>
<tr><td><code id="plot.cv.glintnet_+3A_...">...</code></td>
<td>
<p>Other graphical parameters</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A plot is produced, and nothing is returned.
</p>
<p>A plot is produced, and nothing is returned.
</p>


<h3>Author(s)</h3>

<p>James Yang, Trevor Hastie, and  Balasubramanian Narasimhan <br /> Maintainer:
Trevor Hastie <a href="mailto:hastie@stanford.edu">hastie@stanford.edu</a>
</p>


<h3>References</h3>

<p>Yang, James and Hastie, Trevor. (2024) A Fast and Scalable Pathwise-Solver for Group Lasso
and Elastic Net Penalized Regression via Block-Coordinate Descent. arXiv <a href="https://doi.org/10.48550/arXiv.2405.08631">doi:10.48550/arXiv.2405.08631</a>.<br />
Adelie Python user guide  <a href="https://jamesyang007.github.io/adelie/">https://jamesyang007.github.io/adelie/</a>
</p>


<h3>See Also</h3>

<p><code>grpnet</code> and <code>cv.grpnet</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(0)
n=500
d_cont = 5     # number of continuous features
d_disc = 5     # number of categorical features
Z_cont = matrix(rnorm(n*d_cont), n, d_cont)
levels = sample(2:5,d_disc, replace = TRUE)
Z_disc = matrix(0,n,d_disc)
for(i in seq(d_disc))Z_disc[,i] = sample(0:(levels[i]-1),n,replace=TRUE)
Z = cbind(Z_cont,Z_disc)
levels = c(rep(1,d_cont),levels)

xmat = model.matrix(~Z_cont[,1]*factor(Z_disc[,2]))
nc=ncol(xmat)
beta = rnorm(nc)
y = xmat%*%beta+rnorm(n)*1.5

cvfit &lt;- cv.glintnet(Z, glm.gaussian(y), levels=levels, intr_keys = 1)
plot(cvfit)


set.seed(1010)
n = 1000
p = 100
nzc = trunc(p/10)
x = matrix(rnorm(n * p), n, p)
beta = rnorm(nzc)
fx = (x[, seq(nzc)] %*% beta)
eps = rnorm(n) * 5
y = drop(fx + eps)
px = exp(fx)
px = px/(1 + px)
ly = rbinom(n = length(px), prob = px, size = 1)
cvob1 = cv.grpnet(x, glm.gaussian(y))
plot(cvob1)
title("Gaussian Family", line = 2.5)
frame()
set.seed(1011)
cvob2 = cv.grpnet(x, glm.binomial(ly))
plot(cvob2)
title("Binomial Family", line = 2.5)

</code></pre>

<hr>
<h2 id='plot.grpnet'>plot coefficients from a &quot;grpnet&quot; object</h2><span id='topic+plot.grpnet'></span>

<h3>Description</h3>

<p>Produces a coefficient profile plot of the coefficient paths for a fitted
<code>"grpnet"</code> object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'grpnet'
plot(x, sign.lambda = -1, glm.name = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot.grpnet_+3A_x">x</code></td>
<td>
<p>fitted <code>"grpnet"</code> model</p>
</td></tr>
<tr><td><code id="plot.grpnet_+3A_sign.lambda">sign.lambda</code></td>
<td>
<p>This determines whether we plot against <code>log(lambda)</code> or its negative.
values are <code>-1</code>(default) or <code>1</code></p>
</td></tr>
<tr><td><code id="plot.grpnet_+3A_glm.name">glm.name</code></td>
<td>
<p>This is a logical (default <code>TRUE</code>), and causes the glm name of the model
to be included in the plot.</p>
</td></tr>
<tr><td><code id="plot.grpnet_+3A_...">...</code></td>
<td>
<p>Other graphical parameters to plot</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A coefficient profile plot is produced. If <code>x</code> is a multinomial or multigaussian model,
the 2norm of the vector of coefficients is plotted.
</p>


<h3>Author(s)</h3>

<p>James Yang, Trevor Hastie, and  Balasubramanian Narasimhan <br /> Maintainer: Trevor Hastie <a href="mailto:hastie@stanford.edu">hastie@stanford.edu</a>
</p>


<h3>References</h3>

<p>Yang, James and Hastie, Trevor. (2024) A Fast and Scalable Pathwise-Solver for Group Lasso
and Elastic Net Penalized Regression via Block-Coordinate Descent. arXiv <a href="https://doi.org/10.48550/arXiv.2405.08631">doi:10.48550/arXiv.2405.08631</a>.
</p>


<h3>See Also</h3>

<p><code>grpnet</code>, and <code>print</code>, and <code>coef</code> methods, and
<code>cv.grpnet</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x=matrix(rnorm(100*20),100,20)
y=rnorm(100)
fit1=grpnet(x,glm.gaussian(y))
plot(fit1)
g4=diag(4)[sample(1:4,100,replace=TRUE),]
fit2=grpnet(x,glm.multinomial(g4))
plot(fit2,lwd=3)
fit3=grpnet(x,glm.gaussian(y),groups=c(1,5,9,13,17))
plot(fit3)
</code></pre>

<hr>
<h2 id='predict.cv.glintnet'>make predictions from a &quot;cv.glintnet&quot; object.</h2><span id='topic+predict.cv.glintnet'></span><span id='topic+coef.cv.glintnet'></span>

<h3>Description</h3>

<p>This function makes predictions from a cross-validated <code>glintnet</code> model, using
the stored <code>"glintnet.fit"</code> object, and the optimal value chosen for
<code>lambda</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'cv.glintnet'
predict(object, newx, lambda = c("lambda.1se", "lambda.min"), ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict.cv.glintnet_+3A_object">object</code></td>
<td>
<p>Fitted <code>"cv.glintnet"</code>.</p>
</td></tr>
<tr><td><code id="predict.cv.glintnet_+3A_newx">newx</code></td>
<td>
<p>Matrix of new values for <code>x</code> at which predictions are to be
made. This matrix is of the same form as in the call to <code>glintnet</code>.</p>
</td></tr>
<tr><td><code id="predict.cv.glintnet_+3A_lambda">lambda</code></td>
<td>
<p>Value(s) of the penalty parameter <code>lambda</code> at which
predictions are required. Default is the entire sequence used to create the
model. If values of <code>lambda</code> are supplied, the function uses linear
interpolation to make predictions for values of <code>lambda</code> that do
not coincide with those used in the fitting algorithm. Note: if newx is a vector
(a single row which has lost its matrix dimensions), convert it to a 1-row matrix first, e.g. by supplying t(newx) instead.</p>
</td></tr>
<tr><td><code id="predict.cv.glintnet_+3A_...">...</code></td>
<td>
<p>Other arguments that can be passed to <code>predict.grpnet</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function makes it easier to use the results of cross-validation to make
a prediction.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(0)
n=500
d_cont = 5     # number of continuous features
d_disc = 5     # number of categorical features
Z_cont = matrix(rnorm(n*d_cont), n, d_cont)
levels = sample(2:5,d_disc, replace = TRUE)
Z_disc = matrix(0,n,d_disc)
for(i in seq(d_disc))Z_disc[,i] = sample(0:(levels[i]-1),n,replace=TRUE)
Z = cbind(Z_cont,Z_disc)
levels = c(rep(1,d_cont),levels)

xmat = model.matrix(~Z_cont[,1]*factor(Z_disc[,2]))
nc=ncol(xmat)
beta = rnorm(nc)
y = xmat%*%beta+rnorm(n)*1.5

cvfit &lt;- cv.glintnet(Z, glm.gaussian(y), levels=levels, intr_keys = 1)
plot(cvfit)
predict(cvfit, newx=Z[1:5,])

</code></pre>

<hr>
<h2 id='predict.cv.grpnet'>make predictions from a &quot;cv.grpnet&quot; object.</h2><span id='topic+predict.cv.grpnet'></span><span id='topic+coef.cv.grpnet'></span>

<h3>Description</h3>

<p>This function makes predictions from a cross-validated grpnet model, using
the stored <code>"grpnet.fit"</code> object, and the optimal value chosen for
<code>lambda</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'cv.grpnet'
predict(object, newx, lambda = c("lambda.1se", "lambda.min"), ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict.cv.grpnet_+3A_object">object</code></td>
<td>
<p>Fitted <code>"cv.grpnet"</code>.</p>
</td></tr>
<tr><td><code id="predict.cv.grpnet_+3A_newx">newx</code></td>
<td>
<p>Matrix of new values for <code>x</code> at which predictions are to be
made. Can be a matrix, a sparse matrix as in <code>Matrix</code> package,
or else any of the matrix forms allowable in the <code>adelie</code> package. This
argument is not used for <code>type="coefficients"</code>.</p>
</td></tr>
<tr><td><code id="predict.cv.grpnet_+3A_lambda">lambda</code></td>
<td>
<p>Value(s) of the penalty parameter <code>lambda</code> at which
predictions are required. Default is the value <code>lambda="lambda.1se"</code> stored
on the CV <code>object</code>. Alternatively <code>lambda="lambda.min"</code> can be used. If
<code>lambda</code> is numeric, it is taken as the value(s) of <code>lambda</code> to be
used.</p>
</td></tr>
<tr><td><code id="predict.cv.grpnet_+3A_...">...</code></td>
<td>
<p>Other arguments to <code>predict.grpnet</code>, such at <code>type</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function makes it easier to use the results of cross-validation to make
a prediction.
</p>


<h3>Value</h3>

<p>The object returned depends on the arguments.
</p>


<h3>Author(s)</h3>

<p>James Yang, Trevor Hastie, and  Balasubramanian Narasimhan <br /> Maintainer: Trevor Hastie <a href="mailto:hastie@stanford.edu">hastie@stanford.edu</a>
</p>


<h3>References</h3>

<p>Yang, James and Hastie, Trevor. (2024) A Fast and Scalable Pathwise-Solver for Group Lasso
and Elastic Net Penalized Regression via Block-Coordinate Descent. arXiv <a href="https://doi.org/10.48550/arXiv.2405.08631">doi:10.48550/arXiv.2405.08631</a>.
</p>


<h3>See Also</h3>

<p><code>grpnet</code>, and <code>print</code>, and <code>coef</code> methods, and
<code>cv.grpnet</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
x = matrix(rnorm(100 * 20), 100, 20)
y = rnorm(100)
cv.fit = cv.grpnet(x, glm.gaussian(y))
predict(cv.fit, newx = x[1:5, ])
coef(cv.fit)
coef(cv.fit, lambda = "lambda.min")
predict(cv.fit, newx = x[1:5, ], lambda = c(0.001, 0.002))

</code></pre>

<hr>
<h2 id='predict.glintnet'>make predictions from a &quot;glintnet&quot; object.</h2><span id='topic+predict.glintnet'></span><span id='topic+coef.glintnet'></span>

<h3>Description</h3>

<p>Similar to other predict methods, this functions predicts linear predictors,
coefficients and more from a fitted <code>"glintnet"</code> object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'glintnet'
predict(
  object,
  newx,
  lambda = NULL,
  type = c("link", "response", "coefficients", "nonzero"),
  newoffsets = NULL,
  n_threads = 1,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict.glintnet_+3A_object">object</code></td>
<td>
<p>Fitted <code>"glintnet"</code> model.</p>
</td></tr>
<tr><td><code id="predict.glintnet_+3A_newx">newx</code></td>
<td>
<p>Matrix of new values for <code>x</code> at which predictions are to be
made. This matrix is of the same form as in the call to <code>glintnet</code>.</p>
</td></tr>
<tr><td><code id="predict.glintnet_+3A_lambda">lambda</code></td>
<td>
<p>Value(s) of the penalty parameter <code>lambda</code> at which
predictions are required. Default is the entire sequence used to create the
model. If values of <code>lambda</code> are supplied, the function uses linear
interpolation to make predictions for values of <code>lambda</code> that do
not coincide with those used in the fitting algorithm. Note: if newx is a vector
(a single row which has lost its matrix dimensions), convert it to a 1-row matrix first, e.g. by supplying t(newx) instead.</p>
</td></tr>
<tr><td><code id="predict.glintnet_+3A_type">type</code></td>
<td>
<p>Type of prediction required. Type <code>"link"</code> is  the default, and gives the linear
predictors. Type <code>"response"</code> applies the inverse link to these predictions.
Type <code>"coefficients"</code> extracts the coefficients, intercepts and the active-set sizes.
Type <code>"nonzero"</code> returns a list of active groups along the path, indexed from 1 to number of groups.</p>
</td></tr>
<tr><td><code id="predict.glintnet_+3A_newoffsets">newoffsets</code></td>
<td>
<p>If an offset is used in the fit, then one must be supplied
for making predictions (except for <code>type="coefficients"</code>.</p>
</td></tr>
<tr><td><code id="predict.glintnet_+3A_n_threads">n_threads</code></td>
<td>
<p>Number of threads, default <code>1</code>.</p>
</td></tr>
<tr><td><code id="predict.glintnet_+3A_...">...</code></td>
<td>
<p>Other arguments that can be passed to <code>predict.grpnet</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>The object returned depends on type.
</p>


<h3>Author(s)</h3>

<p>James Yang, Trevor Hastie, and  Balasubramanian Narasimhan <br /> Maintainer: Trevor Hastie
<a href="mailto:hastie@stanford.edu">hastie@stanford.edu</a>
</p>


<h3>References</h3>

<p>Yang, James and Hastie, Trevor. (2024) A Fast and Scalable Pathwise-Solver for Group Lasso
and Elastic Net Penalized Regression via Block-Coordinate Descent. arXiv <a href="https://doi.org/10.48550/arXiv.2405.08631">doi:10.48550/arXiv.2405.08631</a>.<br />
Adelie Python user guide  <a href="https://jamesyang007.github.io/adelie/">https://jamesyang007.github.io/adelie/</a>
</p>


<h3>See Also</h3>

<p><code>grpnet</code>, and <code>print</code>, and <code>coef</code> methods, and
<code>cv.grpnet</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(0)
n=500
d_cont = 5     # number of continuous features
d_disc = 5     # number of categorical features
Z_cont = matrix(rnorm(n*d_cont), n, d_cont)
levels = sample(2:5,d_disc, replace = TRUE)
Z_disc = matrix(0,n,d_disc)
for(i in seq(d_disc))Z_disc[,i] = sample(0:(levels[i]-1),n,replace=TRUE)
Z = cbind(Z_cont,Z_disc)
levels = c(rep(1,d_cont),levels)

xmat = model.matrix(~Z_cont[,1]*factor(Z_disc[,2]))
nc=ncol(xmat)
beta = rnorm(nc)
y = xmat%*%beta+rnorm(n)*1.5

fit &lt;- glintnet(Z, glm.gaussian(y), levels=levels, intr_keys = 1)
predict(fit, lambda = c(.1,.01), newx = Z[1:4,])
predict(fit, lambda = c(0.1,0.01), type="nonzero")

</code></pre>

<hr>
<h2 id='predict.grpnet'>make predictions from a &quot;grpnet&quot; object.</h2><span id='topic+predict.grpnet'></span><span id='topic+coef.grpnet'></span>

<h3>Description</h3>

<p>Similar to other predict methods, this functions predicts linear predictors,
coefficients and more from a fitted <code>"grpnet"</code> object. Note that if the default <code>standardize=TRUEE</code> was used in fitting the <code>grpnet</code> object, the coefficients reported are for the standardized inputs.
However, the <code>predict</code> function will apply the stored standardization to <code>newx</code> and give the correct predictions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'grpnet'
predict(
  object,
  newx,
  lambda = NULL,
  type = c("link", "response", "coefficients", "nonzero"),
  newoffsets = NULL,
  n_threads = 1,
  ...
)

## S3 method for class 'grpnet'
coef(object, lambda = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict.grpnet_+3A_object">object</code></td>
<td>
<p>Fitted <code>"grpnet"</code> model.</p>
</td></tr>
<tr><td><code id="predict.grpnet_+3A_newx">newx</code></td>
<td>
<p>Matrix of new values for <code>x</code> at which predictions are to be
made. Can be a matrix, a sparse matrix as in <code>Matrix</code> package, or else any of the matrix forms
allowable in the <code>adelie</code> package. The number of columns must match that of the input matrix
used in fitting <code>object</code>. If the model object was fit with <code>standardize=TRUE</code>, the saved
centers and scaling will be applied to this matrix. This argument is not used for <code>type="coefficients"</code></p>
</td></tr>
<tr><td><code id="predict.grpnet_+3A_lambda">lambda</code></td>
<td>
<p>Value(s) of the penalty parameter <code>lambda</code> at which
predictions are required. Default is the entire sequence used to create the
model. If values of <code>lambda</code> are supplied, the function uses linear
interpolation to make predictions for values of <code>lambda</code> that do
not coincide with those used in the fitting algorithm. Note: if newx is a vector
(a single row which has lost its matrix dimensions), convert it to a 1-row matrix first, e.g. by supplying t(newx) instead.</p>
</td></tr>
<tr><td><code id="predict.grpnet_+3A_type">type</code></td>
<td>
<p>Type of prediction required. Type <code>"link"</code> is  the default, and gives the linear
predictors. Type <code>"response"</code> applies the inverse link to these predictions.
Type <code>"coefficients"</code> extracts the coefficients, intercepts and the active-set sizes.
Type <code>"nonzero"</code> returns a list of active groups along the path, indexed from 1 to number of groups.</p>
</td></tr>
<tr><td><code id="predict.grpnet_+3A_newoffsets">newoffsets</code></td>
<td>
<p>If an offset is used in the fit, then one must be supplied
for making predictions (except for <code>type="coefficients"</code>.</p>
</td></tr>
<tr><td><code id="predict.grpnet_+3A_n_threads">n_threads</code></td>
<td>
<p>Number of threads, default <code>1</code>.</p>
</td></tr>
<tr><td><code id="predict.grpnet_+3A_...">...</code></td>
<td>
<p>Currently ignored.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The shape of the objects returned are different for <code>"multinomial"</code> and <code>"multigaussian"</code>
objects.
<code>coef(...)</code> is equivalent to <code>predict(type="coefficients",...)</code>
</p>


<h3>Value</h3>

<p>The object returned depends on type.
</p>


<h3>Author(s)</h3>

<p>James Yang, Trevor Hastie, and  Balasubramanian Narasimhan <br /> Maintainer: Trevor Hastie
<a href="mailto:hastie@stanford.edu">hastie@stanford.edu</a>
</p>


<h3>References</h3>

<p>Yang, James and Hastie, Trevor. (2024) A Fast and Scalable Pathwise-Solver for Group Lasso
and Elastic Net Penalized Regression via Block-Coordinate Descent. arXiv <a href="https://doi.org/10.48550/arXiv.2405.08631">doi:10.48550/arXiv.2405.08631</a>.<br />
Adelie Python user guide  <a href="https://jamesyang007.github.io/adelie/">https://jamesyang007.github.io/adelie/</a>
</p>


<h3>See Also</h3>

<p><code>grpnet</code>, and <code>print</code>, and <code>coef</code> methods, and
<code>cv.grpnet</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(0)
n &lt;- 100
p &lt;- 200
X &lt;- matrix(rnorm(n * p), n, p)
y &lt;- X[,1] * rnorm(1) + rnorm(n)
groups &lt;- c(1, sample(2:199, 60, replace = FALSE))
groups &lt;- sort(groups)
fit &lt;- grpnet(X, glm.gaussian(y), groups = groups)
coef(fit)
predict(fit,newx = X[1:5,], lambda = c(0.1, 0.05))
predict(fit, type="nonzero", lambda = c(0.1, 0.05))
</code></pre>

<hr>
<h2 id='print.cv.grpnet'>print a cross-validated grpnet object</h2><span id='topic+print.cv.grpnet'></span>

<h3>Description</h3>

<p>Print a summary of the results of cross-validation for a grpnet model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'cv.grpnet'
print(x, digits = max(3, getOption("digits") - 3), ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="print.cv.grpnet_+3A_x">x</code></td>
<td>
<p>fitted 'cv.grpnet' object</p>
</td></tr>
<tr><td><code id="print.cv.grpnet_+3A_digits">digits</code></td>
<td>
<p>significant digits in printout</p>
</td></tr>
<tr><td><code id="print.cv.grpnet_+3A_...">...</code></td>
<td>
<p>additional print arguments</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>James Yang, Trevor Hastie, and  Balasubramanian Narasimhan<br /> Maintainer: Trevor Hastie <a href="mailto:hastie@stanford.edu">hastie@stanford.edu</a>
</p>


<h3>References</h3>

<p>Yang, James and Hastie, Trevor. (2024) A Fast and Scalable Pathwise-Solver for Group Lasso
and Elastic Net Penalized Regression via Block-Coordinate Descent. arXiv <a href="https://doi.org/10.48550/arXiv.2405.08631">doi:10.48550/arXiv.2405.08631</a>.
</p>


<h3>See Also</h3>

<p><code>grpnet</code>, <code>predict</code> and <code>coef</code> methods.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
x = matrix(rnorm(100 * 20), 100, 20)
y = rnorm(100)
fit1 = cv.grpnet(x, glm.gaussian(y))
print(fit1)
</code></pre>

<hr>
<h2 id='print.glintnet'>Print a summary of the glintnet path at each step along the path.</h2><span id='topic+print.glintnet'></span>

<h3>Description</h3>

<p>Print a summary of the grpnet path at each step along the path.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'glintnet'
print(x, digits = max(3, getOption("digits") - 3), ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="print.glintnet_+3A_x">x</code></td>
<td>
<p>fitted glintnet object</p>
</td></tr>
<tr><td><code id="print.glintnet_+3A_digits">digits</code></td>
<td>
<p>significant digits in printout</p>
</td></tr>
<tr><td><code id="print.glintnet_+3A_...">...</code></td>
<td>
<p>additional print arguments</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The call that produced the object <code>x</code> is printed, followed by a
five-column matrix with columns <code>N_main</code>,  <code>N_int</code>, <code>Df</code>, <code style="white-space: pre;">&#8288;%Dev&#8288;</code> and <code>Lambda</code>.
The <code>N_main</code> column is the number of main-effect terms in the solution, and <code>N_int</code> the number of interaction terms. Since an interaction term implies both main effects, the former is always at least as large as the latter.
The <code>Df</code> column is the number of nonzero coefficients (Df is a
reasonable name only for lasso fits). <code style="white-space: pre;">&#8288;%Dev&#8288;</code> is the percent deviance
explained (relative to the null deviance).
</p>


<h3>Value</h3>

<p>The matrix above is silently returned
</p>


<h3>References</h3>

<p>Yang, James and Hastie, Trevor. (2024) A Fast and Scalable Pathwise-Solver for Group Lasso
and Elastic Net Penalized Regression via Block-Coordinate Descent. arXiv <a href="https://doi.org/10.48550/arXiv.2405.08631">doi:10.48550/arXiv.2405.08631</a>.
</p>


<h3>See Also</h3>

<p><code>grpnet</code>, <code>predict</code>, <code>plot</code> and <code>coef</code> methods.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
x = matrix(rnorm(100 * 20), 100, 20)
y = rnorm(100)
fit1 = grpnet(x, glm.gaussian(y), groups = c(1:5,7,9))
print(fit1)
</code></pre>

<hr>
<h2 id='print.grpnet'>print a grpnet object</h2><span id='topic+print.grpnet'></span>

<h3>Description</h3>

<p>Print a summary of the grpnet path at each step along the path.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'grpnet'
print(x, digits = max(3, getOption("digits") - 3), ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="print.grpnet_+3A_x">x</code></td>
<td>
<p>fitted grpnet object</p>
</td></tr>
<tr><td><code id="print.grpnet_+3A_digits">digits</code></td>
<td>
<p>significant digits in printout</p>
</td></tr>
<tr><td><code id="print.grpnet_+3A_...">...</code></td>
<td>
<p>additional print arguments</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The call that produced the object <code>x</code> is printed, followed by a
four-column matrix with columns <code>Groups</code>, <code>Df</code>, <code style="white-space: pre;">&#8288;%Dev&#8288;</code> and <code>Lambda</code>.
The <code>Groups</code> column is the number of active groups in the solution.
The <code>Df</code> column is the number of nonzero coefficients (Df is a
reasonable name only for lasso fits). <code style="white-space: pre;">&#8288;%Dev&#8288;</code> is the percent deviance
explained (relative to the null deviance).
</p>


<h3>Value</h3>

<p>The matrix above is silently returned
</p>


<h3>References</h3>

<p>Yang, James and Hastie, Trevor. (2024) A Fast and Scalable Pathwise-Solver for Group Lasso
and Elastic Net Penalized Regression via Block-Coordinate Descent. arXiv <a href="https://doi.org/10.48550/arXiv.2405.08631">doi:10.48550/arXiv.2405.08631</a>.
</p>


<h3>See Also</h3>

<p><code>grpnet</code>, <code>predict</code>, <code>plot</code> and <code>coef</code> methods.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
x = matrix(rnorm(100 * 20), 100, 20)
y = rnorm(100)
fit1 = grpnet(x, glm.gaussian(y), groups = c(1:5,7,9))
print(fit1)
</code></pre>

<hr>
<h2 id='set_configs'>Set configuration settings.</h2><span id='topic+set_configs'></span>

<h3>Description</h3>

<p>Set configuration settings.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>set_configs(name, value = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="set_configs_+3A_name">name</code></td>
<td>
<p>Configuration variable name.</p>
</td></tr>
<tr><td><code id="set_configs_+3A_value">value</code></td>
<td>
<p>Value to assign to the configuration variable.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Assigned value.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set_configs("hessian_min", 1e-6)
set_configs("hessian_min")
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
