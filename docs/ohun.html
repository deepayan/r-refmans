<!DOCTYPE html><html><head><title>Help for package ohun</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {ohun}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#consensus_detection'><p>Remove ambiguous detections</p></a></li>
<li><a href='#diagnose_detection'><p>Evaluate the performance of a sound event detection procedure</p></a></li>
<li><a href='#energy_detector'><p>Detects the start and end of sound events</p></a></li>
<li><a href='#feature_acoustic_data'><p>alternative name for <code>summarize_acoustic_data</code></p></a></li>
<li><a href='#feature_reference'><p>alternative name for <code>summarize_reference</code></p></a></li>
<li><a href='#filter_detection'><p>alternative name for <code>consensus_detection</code></p></a></li>
<li><a href='#get_envelopes'><p>Extract absolute amplitude envelopes</p></a></li>
<li><a href='#get_templates'><p>Find templates representative of the structural variation of sound events</p></a></li>
<li><a href='#label_detection'><p>Label detections from a sound event detection procedure</p></a></li>
<li><a href='#label_spectro'><p>Plot a labeled spectrogram</p></a></li>
<li><a href='#lbh_reference'><p>Example data frame of a selection table including all sound events of interests.</p></a></li>
<li><a href='#lbh1'><p>Long-billed hermit recording</p></a></li>
<li><a href='#lbh2'><p>Long-billed hermit recording</p></a></li>
<li><a href='#merge_overlaps'><p>Merge overlapping selections</p></a></li>
<li><a href='#ohun'><p>ohun: Optimizing sound event detection</p></a></li>
<li><a href='#optimize_energy_detector'><p>Optimize energy-based sound event detection</p></a></li>
<li><a href='#optimize_template_detector'><p>Optimize acoustic template detection</p></a></li>
<li><a href='#plot_detection'><p>Plot detection and reference annotations</p></a></li>
<li><a href='#print.envelopes'><p>Class 'envelopes': list of absolute amplitude envelopes</p></a></li>
<li><a href='#print.template_correlations'><p>print method for class <code>template_correlations</code></p></a></li>
<li><a href='#split_acoustic_data'><p>Splits sound files and associated annotations</p></a></li>
<li><a href='#summarize_acoustic_data'><p>Summarize information about file format in an acoustic data set</p></a></li>
<li><a href='#summarize_diagnostic'><p>Summarize detection diagnostics</p></a></li>
<li><a href='#summarize_reference'><p>Summarize temporal and frequency dimensions of annotations and gaps</p></a></li>
<li><a href='#template_correlator'><p>Acoustic templates correlator using time-frequency cross-correlation</p></a></li>
<li><a href='#template_detector'><p>Acoustic template detection from time-frequency cross-correlations</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Title:</td>
<td>Optimizing Acoustic Signal Detection</td>
</tr>
<tr>
<td>Version:</td>
<td>1.0.1</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Marcelo Araya-Salas &lt;marcelo.araya@ucr.ac.cr&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Facilitates the automatic detection of acoustic signals, 
    providing functions to diagnose and optimize the performance of detection 
    routines. Detections from other software can also be explored and optimized.
    Araya-Salas et al. (2022) &lt;<a href="https://doi.org/10.1101%2F2022.12.13.520253">doi:10.1101/2022.12.13.520253</a>&gt;.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://docs.ropensci.org/ohun/">https://docs.ropensci.org/ohun/</a>, <a href="https://github.com/ropensci/ohun/">https://github.com/ropensci/ohun/</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/ropensci/ohun/issues/">https://github.com/ropensci/ohun/issues/</a></td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>Language:</td>
<td>en-US</td>
</tr>
<tr>
<td>Imports:</td>
<td>tuneR, warbleR (&ge; 1.1.29), cli, methods, stats, utils,
seewave (&ge; 2.0.1), fftw, rlang, sf, igraph, checkmate, ggplot2</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.2.1)</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, rmarkdown, testthat, viridis, Sim.DiffProc, vdiffr</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-11-15 14:17:41 UTC; m</td>
</tr>
<tr>
<td>Author:</td>
<td>Marcelo Araya-Salas
    <a href="https://orcid.org/0000-0003-3594-619X"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut, cre],
  Alec L. Robitaille
    <a href="https://orcid.org/0000-0002-4706-1762"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [rev],
  Sam Lapp <a href="https://orcid.org/0000-0003-1637-6822"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [rev]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-11-17 11:30:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='consensus_detection'>Remove ambiguous detections</h2><span id='topic+consensus_detection'></span>

<h3>Description</h3>

<p><code>consensus_detection</code> removes ambiguous detections
</p>


<h3>Usage</h3>

<pre><code class='language-R'>consensus_detection(detection, by = "overlap", filter = "max", cores = 1, pb = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="consensus_detection_+3A_detection">detection</code></td>
<td>
<p>Data frame or selection table (using the warbleR package's format, see <code><a href="warbleR.html#topic+selection_table">selection_table</a></code>) with the output of <code><a href="#topic+label_detection">label_detection</a></code> containing the start and end of the signals. Must contained at least the following columns: &quot;sound.files&quot;, &quot;selec&quot;, &quot;start&quot;, &quot;end&quot; and &quot;detection.class&quot; (the last one is generated by <code><a href="#topic+label_detection">label_detection</a></code>). It must also contained the column indicated in the 'by' argument (which is 'overlap' by default).</p>
</td></tr>
<tr><td><code id="consensus_detection_+3A_by">by</code></td>
<td>
<p>Character vector of length 1 indicating a column in 'detection' that will be used to filter detections. Must refer to a numeric column. Default is 'overlap', which is return by <code><a href="#topic+label_detection">label_detection</a></code>.</p>
</td></tr>
<tr><td><code id="consensus_detection_+3A_filter">filter</code></td>
<td>
<p>Character vector of length 1 indicating the criterium used to filter the column refer to by the 'by' argument. Current options are 'max' (maximum) and 'min' (minimum). Default is 'max'.</p>
</td></tr>
<tr><td><code id="consensus_detection_+3A_cores">cores</code></td>
<td>
<p>Numeric. Controls whether parallel computing is applied.
It specifies the number of cores to be used. Default is 1 (i.e. no parallel computing).</p>
</td></tr>
<tr><td><code id="consensus_detection_+3A_pb">pb</code></td>
<td>
<p>Logical argument to control progress bar. Default is <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function removes ambiguous detections keeping only the one that maximizes a criterium given by 'filter'. By default it keeps the detection with the highest overlap to the reference signal. It works on the output of <code><a href="#topic+label_detection">label_detection</a></code>. Useful when several detections match the same reference as in the case of template detection with multiple templates (see <code><a href="#topic+template_detector">template_detector</a></code>).
</p>


<h3>Value</h3>

<p>A data frame or selection table (if 'detection' was also a selection table, warbleR package's format, see <code><a href="warbleR.html#topic+selection_table">selection_table</a></code>) as in 'X' but removing ambiguous detections (split and merged positives).
</p>


<h3>Author(s)</h3>

<p>Marcelo Araya-Salas (<a href="mailto:marcelo.araya@ucr.ac.cr">marcelo.araya@ucr.ac.cr</a>).
</p>


<h3>References</h3>

<p>#' Araya-Salas, M., Smith-Vidaurre, G., Chaverri, G., Brenes, J. C., Chirino, F., Elizondo-Calvo, J., &amp; Rico-Guevara, A. 2022. ohun: an R package for diagnosing and optimizing automatic sound event detection. BioRxiv, 2022.12.13.520253. https://doi.org/10.1101/2022.12.13.520253
</p>


<h3>See Also</h3>

<p><code><a href="#topic+label_detection">label_detection</a></code>, <code><a href="#topic+template_detector">template_detector</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>{
  # load example data
  data("lbh1", "lbh_reference")

  # save sound files
  tuneR::writeWave(lbh1, file.path(tempdir(), "lbh2.wav"))

  # template for the first sound file in 'lbh_reference'
  templ1 &lt;- lbh_reference[1, ]

  # generate template correlations
  tc &lt;- template_correlator(
    templates = templ1, path = tempdir(),
    files = "lbh2.wav"
  )

  # template detection
  td &lt;- template_detector(template.correlations = tc, threshold = 0.12)

  # this detection generates 2 split positives
  diagnose_detection(
    reference = lbh_reference[lbh_reference == "lbh2.wav", ],
    detection = td
  )

  # label detection
  ltd &lt;- label_detection(
    reference = lbh_reference[lbh_reference == "lbh2.wav", ],
    detection = td
  )

  # now they can be filter to keep the detection with the highest score for each split
  ftd &lt;- consensus_detection(ltd, by = "scores")

  # splits must be 0
  diagnose_detection(
    reference = lbh_reference[lbh_reference == "lbh2.wav", ],
    detection = ftd
  )
}

</code></pre>

<hr>
<h2 id='diagnose_detection'>Evaluate the performance of a sound event detection procedure</h2><span id='topic+diagnose_detection'></span>

<h3>Description</h3>

<p><code>diagnose_detection</code> evaluates the performance of a sound event detection procedure comparing the output selection table to a reference selection table
</p>


<h3>Usage</h3>

<pre><code class='language-R'>diagnose_detection(reference, detection, by.sound.file = FALSE,
time.diagnostics = FALSE, cores = 1, pb = TRUE, path = NULL, by = NULL,
 macro.average = FALSE, min.overlap = 0.5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="diagnose_detection_+3A_reference">reference</code></td>
<td>
<p>Data frame or 'selection.table' (following the warbleR package format) with the reference selections (start and end of the sound events) that will be used to evaluate the performance of the detection, represented by those selections in 'detection'. Must contained at least the following columns: &quot;sound.files&quot;, &quot;selec&quot;, &quot;start&quot; and &quot;end&quot;. <strong>It must contain the reference selections that will be used for detection optimization</strong>.</p>
</td></tr>
<tr><td><code id="diagnose_detection_+3A_detection">detection</code></td>
<td>
<p>Data frame or 'selection.table' with the detections (start and end of the sound events) that will be compared against the 'reference' selections. Must contained at least the following columns: &quot;sound.files&quot;, &quot;selec&quot;, &quot;start&quot; and &quot;end&quot;. It can contain data for additional sound files not found in 'references'. In this case the routine assumes that no sound events are found in those files, so detection from those files are all false positives.</p>
</td></tr>
<tr><td><code id="diagnose_detection_+3A_by.sound.file">by.sound.file</code></td>
<td>
<p>Logical argument to control whether performance diagnostics are summarized across sound files (when <code>by.sound.file = FALSE</code>, when more than 1 sound file is included in 'reference') or shown separated by sound file. Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="diagnose_detection_+3A_time.diagnostics">time.diagnostics</code></td>
<td>
<p>Logical argument to control if diagnostics related to the duration of the sound events (&quot;mean.duration.true.positives&quot;, &quot;mean.duration.false.positives&quot;, &quot;mean.duration.false.negatives&quot; and &quot;proportional.duration.true.positives&quot;) are returned (if <code>TRUE</code>). Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="diagnose_detection_+3A_cores">cores</code></td>
<td>
<p>Numeric. Controls whether parallel computing is applied.
It specifies the number of cores to be used. Default is 1 (i.e. no parallel computing).</p>
</td></tr>
<tr><td><code id="diagnose_detection_+3A_pb">pb</code></td>
<td>
<p>Logical argument to control progress bar. Default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="diagnose_detection_+3A_path">path</code></td>
<td>
<p>Character string containing the directory path where the sound files are located. If supplied then duty cycle (fraction of a sound file in which sounds were detected)is also returned. This feature is more helpful for tuning an energy-based detection. Default is <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="diagnose_detection_+3A_by">by</code></td>
<td>
<p>Character vector with the name of a column in 'reference' for splitting diagnostics. Diagnostics will be returned separated for each level in 'by'. Default is <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="diagnose_detection_+3A_macro.average">macro.average</code></td>
<td>
<p>Logical argument to control if diagnostics are first calculated for each sound file and then averaged across sound files, which can minimize the effect of unbalanced sample sizes between sound files. If <code>FALSE</code> (default) diagnostics are based on aggregated statistics irrespective of sound files. The following indices can be estimated by macro-averaging: overlap, mean.duration.true.positives, mean.duration.false.positives, mean.duration.false.positives, mean.duration.false.negatives, proportional.duration.true.positives, recall and precision (f.score is always derived from recall and precision). Note that when applying macro-averaging, recall and precision are not derived from the true positive, false positive and false negative values returned by the function.</p>
</td></tr>
<tr><td><code id="diagnose_detection_+3A_min.overlap">min.overlap</code></td>
<td>
<p>Numeric. Controls the minimum amount of overlap required for a detection and a reference sound for it to be counted as true positive. Default is 0.5. Overlap is measured as intersection over union.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function evaluates the performance of a sound event detection procedure by comparing its output selection table to a reference selection table in which all sound events of interest have been selected. The function takes any overlap between detected sound events and target sound events as true positives. Note that all sound files located in the supplied 'path' will be analyzed even if not all of them are listed in 'reference'. When several possible matching pairs of sound event and detections are found, the optimal set of matching pairs is found through maximum bipartite matching (using the R package igraph). Priority for assigning a detection to a reference is given by the amount of time overlap. 'splits' and 'merge.positives' are also counted (i.e. counted twice) as 'true.positives'. Therefore &quot;true.positives + false.positives = detections&quot;.
</p>


<h3>Value</h3>

<p>A data frame including the following detection performance diagnostics:
</p>

<ul>
<li> <p><code>detections</code>: total number of detections
</p>
</li>
<li> <p><code>true.positives</code>: number of sound events in 'reference' that correspond to any detection. Matching is defined as some degree of overlap in time. In a perfect detection routine it should be equal to the number of rows in 'reference'.
</p>
</li>
<li> <p><code>false.positives</code>: number of detections that don't match (i.e. don't overlap with) any of the sound events in 'reference'. In a perfect detection routine it should be 0.
</p>
</li>
<li> <p><code>false.negatives</code>: number of sound events in 'reference' that were not detected (not found in 'detection'. In a perfect detection routine it should be 0.
</p>
</li>
<li> <p><code>splits</code>: number of detections overlapping reference sounds that also overlap with other detections. In a perfect detection routine it should be 0.
</p>
</li>
<li> <p><code>merges</code>: number of detections that overlap with two or more reference sounds. In a perfect detection routine it should be 0.
</p>
</li>
<li> <p><code>mean.duration.true.positives</code>: mean duration of true positives (in ms). Only included when <code>time.diagnostics = TRUE</code>.
</p>
</li>
<li> <p><code>mean.duration.false.positives</code>: mean duration of false positives (in ms). Only included when <code>time.diagnostics = TRUE</code>.
</p>
</li>
<li> <p><code>mean.duration.false.negatives</code>: mean duration of false negatives (in ms). Only included when <code>time.diagnostics = TRUE</code>.
</p>
</li>
<li> <p><code>overlap</code>: mean intersection over union overlap of true positives.
</p>
</li>
<li> <p><code>proportional.duration.true.positives</code>: ratio of duration of true positives to the duration of sound events in 'reference'. In a perfect detection routine it should be 1. Based only on true positives that were not split or merged.
</p>
</li>
<li> <p><code>duty.cycle</code>: proportion of a sound file in which sounds were detected. Only included when <code>time.diagnostics = TRUE</code> and <code>path</code> is supplied. Useful when conducting energy-based detection as a perfect detection can be obtained with a very low amplitude threshold, which will detect everything, but will produce a duty cycle close to 1.
</p>
</li>
<li> <p><code>recall</code>: Proportion of sound events in 'reference' that were detected. In a perfect detection routine it should be 1.
</p>
</li>
<li> <p><code>precision</code>: Proportion of detections that correspond to sound events in 'reference'. In a perfect detection routine it should be 1.
</p>
</li>
<li> <p><code>f.score</code>: Combines recall and precision as the harmonic mean of these two. Provides a single value for evaluating performance. In a perfect detection routine it should be 1.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Marcelo Araya-Salas <a href="mailto:marcelo.araya@ucr.ac.cr">marcelo.araya@ucr.ac.cr</a>)
</p>


<h3>References</h3>

<p>Araya-Salas, M., Smith-Vidaurre, G., Chaverri, G., Brenes, J. C., Chirino, F., Elizondo-Calvo, J., &amp; Rico-Guevara, A. 2022. ohun: an R package for diagnosing and optimizing automatic sound event detection. BioRxiv, 2022.12.13.520253. https://doi.org/10.1101/2022.12.13.520253
</p>


<h3>See Also</h3>

<p><code><a href="#topic+optimize_energy_detector">optimize_energy_detector</a></code>, <code><a href="#topic+optimize_template_detector">optimize_template_detector</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>{
  # load data
  data("lbh_reference")

  # perfect detection
  diagnose_detection(reference = lbh_reference, detection = lbh_reference)

  # missing one in detection
  diagnose_detection(reference = lbh_reference, detection = lbh_reference[-1, ])

  # an extra one in detection
  diagnose_detection(reference = lbh_reference[-1, ], detection = lbh_reference)

  # with time diagnostics
  diagnose_detection(
    reference = lbh_reference[-1, ],
    detection = lbh_reference, time.diagnostics = TRUE
  )

  # and extra sound file in reference
  diagnose_detection(
    reference = lbh_reference,
    detection =
      lbh_reference[lbh_reference$sound.files != "lbh1", ]
  )

  # and extra sound file in detection
  diagnose_detection(
    reference =
      lbh_reference[lbh_reference$sound.files != "lbh1", ],
    detection = lbh_reference
  )

  # and extra sound file in detection by sound file
  dd &lt;- diagnose_detection(
    reference =
      lbh_reference[lbh_reference$sound.files != "lbh1", ],
    detection = lbh_reference, time.diagnostics = TRUE, by.sound.file = TRUE
  )

  # get summary
  summarize_diagnostic(dd)
}
</code></pre>

<hr>
<h2 id='energy_detector'>Detects the start and end of sound events</h2><span id='topic+energy_detector'></span>

<h3>Description</h3>

<p><code>energy_detector</code> detects the start and end of sound events based on energy and time attributes
</p>


<h3>Usage</h3>

<pre><code class='language-R'>energy_detector(files = NULL, envelopes = NULL, path = ".", hop.size = 11.6, wl = NULL,
thinning = 1, bp = NULL, smooth = 5, threshold = 5, peak.amplitude = 0,
hold.time = 0, min.duration = 0, max.duration = Inf, cores = 1, pb = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="energy_detector_+3A_files">files</code></td>
<td>
<p>Character vector indicating the sound files that will be analyzed. Optional. If 'files' and 'envelopes' are not supplied then the function will work on all supported format sound files in the working directory. Supported file formats:'.wav', '.mp3', '.flac' and '.wac'. If not supplied the function will work on all sound files (in the supported format) in 'path'.</p>
</td></tr>
<tr><td><code id="energy_detector_+3A_envelopes">envelopes</code></td>
<td>
<p>An object of class 'envelopes' (generated by <code><a href="#topic+get_envelopes">get_envelopes</a></code>) containing the amplitude envelopes of the sound files to be analyzed. If 'files' and 'envelopes' are not supplied then the function will work on all supported format sound files in the working directory.</p>
</td></tr>
<tr><td><code id="energy_detector_+3A_path">path</code></td>
<td>
<p>Character string containing the directory path where the sound files are located.
The current working directory is used as default.</p>
</td></tr>
<tr><td><code id="energy_detector_+3A_hop.size">hop.size</code></td>
<td>
<p>A numeric vector of length 1 specifying the time window duration (in ms). Default is 11.6 ms, which is equivalent to 512 wl for a 44.1 kHz sampling rate. Ignored if 'wl' is supplied.</p>
</td></tr>
<tr><td><code id="energy_detector_+3A_wl">wl</code></td>
<td>
<p>A numeric vector of length 1 specifying the window length of the spectrogram. Default is <code>NULL</code>. If supplied, 'hop.size' is ignored. Used internally for bandpass filtering (so only applied when 'bp' is supplied).</p>
</td></tr>
<tr><td><code id="energy_detector_+3A_thinning">thinning</code></td>
<td>
<p>Numeric vector of length 1 in the range 0~1 indicating the proportional reduction of the number of
samples used to represent amplitude envelopes (i.e. the thinning of the envelopes). Usually amplitude envelopes have many more samples
than those needed to accurately represent amplitude variation in time, which affects the size of the
output (usually very large R objects / files). Default is <code>1</code> (no thinning). Higher sampling rates can afford higher size reduction (e.g. lower thinning values). Reduction is conducted by interpolation using <code><a href="stats.html#topic+approx">approx</a></code>. Note that thinning may decrease time precision, and the higher the thinning the less precise the time detection. This argument is used internally by <code><a href="#topic+get_envelopes">get_envelopes</a></code>. Not used if 'envelopes' are supplied.</p>
</td></tr>
<tr><td><code id="energy_detector_+3A_bp">bp</code></td>
<td>
<p>Numeric vector of length 2 giving the lower and upper limits of a frequency bandpass filter (in kHz). Default is <code>NULL</code>. This argument is used internally by <code><a href="#topic+get_envelopes">get_envelopes</a></code>. Not used if 'envelopes' are supplied. Bandpass is done using the function <code><a href="seewave.html#topic+ffilter">ffilter</a></code>, which applies a short-term Fourier transformation to first create a spectrogram in which the target frequencies are filtered and then is back transformed into a wave object using a reverse Fourier transformation.</p>
</td></tr>
<tr><td><code id="energy_detector_+3A_smooth">smooth</code></td>
<td>
<p>A numeric vector of length 1 to smooth the amplitude envelope  with a sum smooth function. It controls the time 'neighborhood' (in ms) in which amplitude samples are smoothed (i.e. averaged with neighboring samples). Default is 5. 0 means no smoothing is applied. Note that smoothing is applied before thinning (see 'thinning' argument). The function  <code><a href="warbleR.html#topic+envelope">envelope</a></code> is used internally which is analogous to sum smoothing in <code><a href="seewave.html#topic+env">env</a></code>. This argument is used internally by <code><a href="#topic+get_envelopes">get_envelopes</a></code>. Not used if 'envelopes' are supplied.</p>
</td></tr>
<tr><td><code id="energy_detector_+3A_threshold">threshold</code></td>
<td>
<p>Numeric vector of length 1 with a value between 0 and 100 specifying the amplitude threshold for detecting sound event occurrences. Amplitude is represented as a percentage so 0 and 100 represent the lowest amplitude and highest amplitude respectively. Default is 5.</p>
</td></tr>
<tr><td><code id="energy_detector_+3A_peak.amplitude">peak.amplitude</code></td>
<td>
<p>Numeric vector of length 1 with the minimum peak amplitude value. Detections below that value are excluded. Peak amplitude is the maximum sound pressure level (in decibels) across the sound event (see <code><a href="warbleR.html#topic+sound_pressure_level">sound_pressure_level</a></code>). This can be useful when expecting higher peak amplitude in the target sound events compared to non-target sound events or when keeping only the best examples of the target sound events. Default is 0.</p>
</td></tr>
<tr><td><code id="energy_detector_+3A_hold.time">hold.time</code></td>
<td>
<p>Numeric vector of length 1. Specifies the time range (in ms) at which selections will be merged (i.e. if 2 selections are separated by less than the specified 'hold.time' they will be merged in to a single selection). Default is <code>0</code> (no hold time applied).</p>
</td></tr>
<tr><td><code id="energy_detector_+3A_min.duration">min.duration</code></td>
<td>
<p>Numeric vector of length 1 giving the shortest duration (in ms) of the sound events to be detected. It removes sound events below that threshold. If 'hold.time' is supplied sound events are first merged and then filtered by duration. Default is 0 (i.e. no filtering based on minimum duration).</p>
</td></tr>
<tr><td><code id="energy_detector_+3A_max.duration">max.duration</code></td>
<td>
<p>Numeric vector of length 1 giving the longest duration (in
ms) of the sound events to be detected. It removes sound events above that
threshold. If 'hold.time' is supplied sound events are first merged and then filtered by duration.  Default is <code>Inf</code> (i.e. no filtering based on maximum duration).</p>
</td></tr>
<tr><td><code id="energy_detector_+3A_cores">cores</code></td>
<td>
<p>Numeric. Controls whether parallel computing is applied.
It specifies the number of cores to be used. Default is 1 (i.e. no parallel computing).</p>
</td></tr>
<tr><td><code id="energy_detector_+3A_pb">pb</code></td>
<td>
<p>Logical argument to control progress bar. Default is <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function detects the time position of target sound events based on energy and time thresholds. It first detect all sound above a given energy threshold (argument 'energy'). If 'hold.time' is supplied then detected sounds are merged if necessary. Then the sounds detected are filtered based on duration attributes ('min.duration' and 'max.duration'). If 'peak.amplitude' is higher than 0 then only those sound events with higher peak amplitude are kept. Band pass filtering ('bp'), thinning ('thinning') and envelope smoothing ('smooth') are applied (if supplied) before threshold detection.
</p>


<h3>Value</h3>

<p>The function returns a 'selection_table' (warbleR package's formats, see <code><a href="warbleR.html#topic+selection_table">selection_table</a></code>) or data frame (if sound files can't be found) containing the start and end of each sound event by
sound file. If no sound event was detected for a sound file it is not included in the output data frame.
</p>


<h3>Author(s)</h3>

<p>Marcelo Araya-Salas (<a href="mailto:marcelo.araya@ucr.ac.cr">marcelo.araya@ucr.ac.cr</a>)
</p>


<h3>References</h3>

<p>Araya-Salas, M., Smith-Vidaurre, G., Chaverri, G., Brenes, J. C., Chirino, F., Elizondo-Calvo, J., &amp; Rico-Guevara, A. 2022. ohun: an R package for diagnosing and optimizing automatic sound event detection. BioRxiv, 2022.12.13.520253. https://doi.org/10.1101/2022.12.13.520253
</p>


<h3>See Also</h3>

<p><code><a href="#topic+optimize_energy_detector">optimize_energy_detector</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Save example files into temporary working directory
data("lbh1", "lbh2", "lbh_reference")
tuneR::writeWave(lbh1, file.path(tempdir(), "lbh1.wav"))
tuneR::writeWave(lbh2, file.path(tempdir(), "lbh2.wav"))

# using smoothing and minimum duration
detec &lt;- energy_detector(files = c("lbh1.wav", "lbh2.wav"),
path = tempdir(), threshold = 6, smooth = 6.8,
bp = c(2, 9), hop.size = 3, min.duration = 0.05)

# diagnose detection
diagnose_detection(reference = lbh_reference,
detection = detec)

# without declaring 'files'
detec &lt;- energy_detector(path = tempdir(), threshold = 60, smooth = 6.8,
bp = c(2, 9), hop.size = 6.8, min.duration = 90)

# diagnose detection
diagnose_detection(reference = lbh_reference,
detection = detec)

# using hold time
detec &lt;- energy_detector(threshold = 10, hold.time = 150,
bp = c(2, 9), hop.size = 6.8, path = tempdir())

# diagnose detection
diagnose_detection(reference = lbh_reference, detection = detec)

# calculate envelopes first
envs &lt;- get_envelopes(bp = c(2, 9), hop.size = 6.8, path = tempdir())

# then run detection providing 'envelopes' (but no 'files')
detec &lt;- energy_detector(envelopes = envs, threshold = 10, hold.time = 150, min.duration = 50)

# diagnose detection
diagnose_detection(reference = lbh_reference, detection = detec, time.diagnostics = TRUE)

# USIN OTHER SOUND FILE FORMAT (flac program must be installed)
 # fisrt convert files to flac
 warbleR::wav_2_flac(path = tempdir())

 # change sound file extension to flac
 flac_reference &lt;- lbh_reference
 flac_reference$sound.files &lt;- gsub(".wav", ".flac", flac_reference$sound.files)

 # run detection
 detec &lt;- energy_detector(files = c("lbh1.flac", "lbh2.flac"), path = tempdir(), threshold = 60,
 smooth = 6.8, bp = c(2, 9), hop.size = 6.8, min.duration = 90)

 # diagnose detection
 diagnose_detection(reference = flac_reference, detection = detec)


</code></pre>

<hr>
<h2 id='feature_acoustic_data'>alternative name for <code><a href="#topic+summarize_acoustic_data">summarize_acoustic_data</a></code></h2><span id='topic+feature_acoustic_data'></span>

<h3>Description</h3>

<p>alternative name for <code><a href="#topic+summarize_acoustic_data">summarize_acoustic_data</a></code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>feature_acoustic_data(path = ".", digits = 2)
</code></pre>


<h3>Details</h3>

<p>see <code><a href="#topic+summarize_acoustic_data">summarize_acoustic_data</a></code> for documentation. <code><a href="#topic+feature_acoustic_data">feature_acoustic_data</a></code> will be deprecated in future versions.
</p>

<hr>
<h2 id='feature_reference'>alternative name for <code><a href="#topic+summarize_reference">summarize_reference</a></code></h2><span id='topic+feature_reference'></span>

<h3>Description</h3>

<p>alternative name for <code><a href="#topic+summarize_reference">summarize_reference</a></code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>feature_reference(
  reference,
  path = NULL,
  by.sound.file = FALSE,
  units = c("ms", "kHz"),
  digits = 2
)
</code></pre>


<h3>Details</h3>

<p>see <code><a href="#topic+summarize_reference">summarize_reference</a></code> for documentation. <code><a href="#topic+feature_reference">feature_reference</a></code> will be deprecated in future versions.
</p>

<hr>
<h2 id='filter_detection'>alternative name for <code><a href="#topic+consensus_detection">consensus_detection</a></code></h2><span id='topic+filter_detection'></span>

<h3>Description</h3>

<p>alternative name for <code><a href="#topic+consensus_detection">consensus_detection</a></code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>filter_detection(
  detection,
  by = "overlap",
  filter = "max",
  cores = 1,
  pb = TRUE
)
</code></pre>


<h3>Details</h3>

<p>see <code><a href="#topic+consensus_detection">consensus_detection</a></code> for documentation. <code><a href="#topic+filter_detection">filter_detection</a></code> will be deprecated in future versions.
</p>

<hr>
<h2 id='get_envelopes'>Extract absolute amplitude envelopes</h2><span id='topic+get_envelopes'></span>

<h3>Description</h3>

<p><code>get_envelopes</code> extracts absolute amplitude envelopes to speed up energy detection
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_envelopes(path = ".", files = NULL, bp = NULL, hop.size = 11.6, wl = NULL,
cores = 1, thinning = 1, pb = TRUE, smooth = 5, normalize = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_envelopes_+3A_path">path</code></td>
<td>
<p>Character string containing the directory path where the sound files are located.
The current working directory is used as default.</p>
</td></tr>
<tr><td><code id="get_envelopes_+3A_files">files</code></td>
<td>
<p>character vector or indicating the sound files that will be analyzed. Supported file formats:'.wav', '.mp3', '.flac' and '.wac'. If not supplied the function will work on all sound files (in the supported format) in 'path'.</p>
</td></tr>
<tr><td><code id="get_envelopes_+3A_bp">bp</code></td>
<td>
<p>Numeric vector of length 2 giving the lower and upper limits of a
frequency bandpass filter (in kHz). Default is <code>NULL</code>. Bandpass is done using the function <code><a href="seewave.html#topic+ffilter">ffilter</a></code>, which applies a short-term Fourier transformation to first create a spectrogram in which the target frequencies are filtered and then is back transformed into a wave object using a reverse Fourier transformation.</p>
</td></tr>
<tr><td><code id="get_envelopes_+3A_hop.size">hop.size</code></td>
<td>
<p>A numeric vector of length 1 specifying the time window duration (in ms). Default is 11.6 ms, which is equivalent to 512 wl for a 44.1 kHz sampling rate. Ignored if 'wl' is supplied.</p>
</td></tr>
<tr><td><code id="get_envelopes_+3A_wl">wl</code></td>
<td>
<p>A numeric vector of length 1 specifying the window length of the spectrogram. Default is <code>NULL</code>. If supplied, 'hop.size' is ignored. Used internally for bandpass filtering (so only applied when 'bp' is supplied).</p>
</td></tr>
<tr><td><code id="get_envelopes_+3A_cores">cores</code></td>
<td>
<p>Numeric. Controls whether parallel computing is applied.
It specifies the number of cores to be used. Default is 1 (i.e. no parallel computing).</p>
</td></tr>
<tr><td><code id="get_envelopes_+3A_thinning">thinning</code></td>
<td>
<p>Numeric vector of length 1 in the range 0~1 indicating the proportional reduction of the number of
samples used to represent amplitude envelopes (i.e. the thinning of the envelopes). Usually amplitude envelopes have many more samples
than those needed to accurately represent amplitude variation in time, which affects the size of the
output (usually very large R objects / files). Default is <code>1</code> (no thinning). Higher sampling rates can afford higher size reduction (e.g. lower thinning values). Reduction is conducted by linear interpolation using <code><a href="stats.html#topic+approx">approx</a></code>. Note that thinning may decrease time precision and that the higher the thinning the less precise the time detection. It's generally not advised if no smoothing ('smooth' argument) is applied.</p>
</td></tr>
<tr><td><code id="get_envelopes_+3A_pb">pb</code></td>
<td>
<p>Logical argument to control progress bar. Default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="get_envelopes_+3A_smooth">smooth</code></td>
<td>
<p>A numeric vector of length 1 to smooth the amplitude envelope
with a sum smooth function. It controls the time 'neighborhood' (in ms) in which amplitude samples are smoothed (i.e. averaged with neighboring samples). Default is 5. 0 means no smoothing is applied. Note that smoothing is applied before thinning (see 'thinning' argument). The function  <code><a href="warbleR.html#topic+envelope">envelope</a></code> is used internally which is analogous to sum smoothing in <code><a href="seewave.html#topic+env">env</a></code>. This argument is used internally by <code><a href="#topic+get_envelopes">get_envelopes</a></code>.</p>
</td></tr>
<tr><td><code id="get_envelopes_+3A_normalize">normalize</code></td>
<td>
<p>Logical argument to control if envelopes are normalized to a 0-1 range.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function extracts the absolute amplitude envelopes of sound files. Can be used to manipulate envelopes before running <code><a href="#topic+energy_detector">energy_detector</a></code>.
</p>


<h3>Value</h3>

<p>An object of class 'envelopes'.
</p>


<h3>Author(s)</h3>

<p>Marcelo Araya-Salas (<a href="mailto:marcelo.araya@ucr.ac.cr">marcelo.araya@ucr.ac.cr</a>).
</p>


<h3>References</h3>

<p>Araya-Salas, M., Smith-Vidaurre, G., Chaverri, G., Brenes, J. C., Chirino, F., Elizondo-Calvo, J., &amp; Rico-Guevara, A. 2022. ohun: an R package for diagnosing and optimizing automatic sound event detection. BioRxiv, 2022.12.13.520253. https://doi.org/10.1101/2022.12.13.520253
</p>


<h3>See Also</h3>

<p><code><a href="#topic+energy_detector">energy_detector</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>{
  # Save to temporary working directory
  data(list = c("lbh1", "lbh2"))
  tuneR::writeWave(lbh1, file.path(tempdir(), "lbh1.wav"))
  tuneR::writeWave(lbh2, file.path(tempdir(), "lbh2.wav"))

  # get raw absolute amplitude envelopes
  envs &lt;- get_envelopes(path = tempdir())

  # extract segment for the first sound event in the first sound file
  x &lt;- envs[[1]]$envelope

  # and plot it
  plot(x[(length(x) / 9):(length(x) / 4)], type = "l", xlab = "samples", ylab = "amplitude")

  # smoothing envelopes
  envs &lt;- get_envelopes(path = tempdir(), smooth = 6.8)
  x &lt;- envs[[1]]$envelope
  plot(x[(length(x) / 9):(length(x) / 4)], type = "l", xlab = "samples", ylab = "amplitude")

  # smoothing and thinning
  envs &lt;- get_envelopes(path = tempdir(), thinning = 1 / 10, smooth = 6.8)
  x &lt;- envs[[1]]$envelope
  plot(x[(length(x) / 9):(length(x) / 4)], type = "l", xlab = "samples", ylab = "amplitude")

  # no normalization
  envs &lt;- get_envelopes(path = tempdir(), thinning = 1 / 10, smooth = 6.8)
  x &lt;- envs[[1]]$envelope
  plot(x[(length(x) / 9):(length(x) / 4)],
    type = "l", xlab = "samples", ylab = "amplitude",
    normalize = FALSE
  )
}

</code></pre>

<hr>
<h2 id='get_templates'>Find templates representative of the structural variation of sound events</h2><span id='topic+get_templates'></span>

<h3>Description</h3>

<p><code>get_templates</code> find the sound events that are closer to the acoustic space centroid (i.e. close to the average acoustic structure) in a reference table.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_templates(reference, acoustic.space = NULL, path = ".",
n.sub.spaces = 1, plot = TRUE, color = "#21908C4D", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_templates_+3A_reference">reference</code></td>
<td>
<p>Selection table (using the warbleR package's format, see <code><a href="warbleR.html#topic+selection_table">selection_table</a></code>) or data frame with columns
for sound file name (sound.files), selection number (selec), and start and end time of sound event
(start and end).</p>
</td></tr>
<tr><td><code id="get_templates_+3A_acoustic.space">acoustic.space</code></td>
<td>
<p>Numeric matrix or data frame with the two dimensions of a custom acoustic space to be used for finding templates. if not supplied the acoustic space is calculated internally (default). Optional. Note that the function assumes that 'reference' and 'acoustic.space' refer to the same sound events and similarly ordered.</p>
</td></tr>
<tr><td><code id="get_templates_+3A_path">path</code></td>
<td>
<p>Character string containing the directory path where the sound files are located.
The current working directory is used as default.</p>
</td></tr>
<tr><td><code id="get_templates_+3A_n.sub.spaces">n.sub.spaces</code></td>
<td>
<p>Integer vector of length 1 with the number of sub-spaces to split the total acoustic space. If <code>n.sub.spaces = 1</code>, only the sound event closer to the centroid is returned. If <code>n.sub.spaces &gt; 1</code> the function returns additional sound events, corresponding to those closer to the centroids of the sub-spaces. To do this, the function defines sub-spaces as equal-size slices of a circle centered at the centroid of the acoustic space.</p>
</td></tr>
<tr><td><code id="get_templates_+3A_plot">plot</code></td>
<td>
<p>Logical to control if the plot is created. Default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="get_templates_+3A_color">color</code></td>
<td>
<p>Character string with the point color. Default is '#21908C4D'.</p>
</td></tr>
<tr><td><code id="get_templates_+3A_...">...</code></td>
<td>
<p>Additional arguments to be passed to <code><a href="warbleR.html#topic+spectro_analysis">spectro_analysis</a></code> for further customization when measuring parameters to calculate the acoustic space.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function finds sound events (from a reference table) that are representative of the acoustic structure variation of all sound events. This is done by finding the events closer to the centroid of the acoustic space. If the acoustic space is not supplied ('acoustic.space' argument) then the function will estimate it by measuring several acoustic features using the function <code><a href="warbleR.html#topic+spectro_analysis">spectro_analysis</a></code> (features related to energy distribution in the frequency and time domain as well as features of the dominant frequency contours, see <code><a href="warbleR.html#topic+spectro_analysis">spectro_analysis</a></code> for more details) and summarizing it with Principal Component Analysis (after z-transforming parameters) using the function <code><a href="stats.html#topic+prcomp">prcomp</a></code>. Acoustic features with missing values are removed before estimating Principal Component Analysis. The rationale is that a sound event close to the average structure is more likely to share structural features with most events across the acoustic space than a sound event in the periphery of the space.
If only 1 template is required the function returns the sound event closest to the acoustic space centroid. If more than 1 template is required additional sound events are returned that are representative of the acoustic space. To do this, the function defines sub-spaces as equal-size slices of a circle centered at the centroid of the acoustic space. A column 'template' is included in the output selection table that identifies each template. Custom acoustic spaces can be supplied with argument 'acoustic.space'. Notice that the function aims to partition spaces in which sounds are somehow homogeneously distributed. When clear clusters are found in the distribution of the acoustic space thus clusters might not match the sub-spaces defined by the function.
</p>


<h3>Value</h3>

<p>The function returns a 'selection_table' (warbleR package's formats, see <code><a href="warbleR.html#topic+selection_table">selection_table</a></code>) or data frame (if sound files can't be found) containing the start and end of each sound event by
sound file.
</p>


<h3>Author(s)</h3>

<p>Marcelo Araya-Salas (<a href="mailto:marcelo.araya@ucr.ac.cr">marcelo.araya@ucr.ac.cr</a>). Implements a
modified version of the timer function from seewave.
</p>


<h3>References</h3>

<p>Araya-Salas, M., Smith-Vidaurre, G., Chaverri, G., Brenes, J. C., Chirino, F., Elizondo-Calvo, J., &amp; Rico-Guevara, A. 2022. ohun: an R package for diagnosing and optimizing automatic sound event detection. BioRxiv, 2022.12.13.520253. https://doi.org/10.1101/2022.12.13.520253
</p>


<h3>See Also</h3>

<p><code><a href="#topic+template_detector">template_detector</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>{
  # Save example files into temporary working directory
  data("lbh1", "lbh2", "lbh_reference")
  tuneR::writeWave(lbh1, file.path(tempdir(), "lbh1.wav"))
  tuneR::writeWave(lbh2, file.path(tempdir(), "lbh2.wav"))

  # get a single mean template
  template &lt;- get_templates(reference = lbh_reference, path = tempdir())

  # get 3 templates
  template &lt;- get_templates(reference = lbh_reference, n.sub.spaces = 3, path = tempdir())
}

</code></pre>

<hr>
<h2 id='label_detection'>Label detections from a sound event detection procedure</h2><span id='topic+label_detection'></span>

<h3>Description</h3>

<p><code>label_detection</code> labels the performance of a sound event detection procedure comparing the output selection table to a reference selection table
</p>


<h3>Usage</h3>

<pre><code class='language-R'>label_detection(reference, detection, cores = 1, pb = TRUE, min.overlap = 0.5,
 by = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="label_detection_+3A_reference">reference</code></td>
<td>
<p>Data frame or 'selection.table' (following the warbleR package format) with the reference selections (start and end of the sound events) that will be used to evaluate the performance of the detection, represented by those selections in 'detection'. Must contained at least the following columns: &quot;sound.files&quot;, &quot;selec&quot;, &quot;start&quot; and &quot;end&quot;. <strong>It must contain the reference selections that will be used for detection optimization</strong>.</p>
</td></tr>
<tr><td><code id="label_detection_+3A_detection">detection</code></td>
<td>
<p>Data frame or 'selection.table' with the detections (start and end of the sound events) that will be compared against the 'reference' selections. Must contained at least the following columns: &quot;sound.files&quot;, &quot;selec&quot;, &quot;start&quot; and &quot;end&quot;. It can contain data for additional sound files not found in 'references'. In this case the routine assumes that no sound events are found in those files, so detection from those files are all false positives.</p>
</td></tr>
<tr><td><code id="label_detection_+3A_cores">cores</code></td>
<td>
<p>Numeric. Controls whether parallel computing is applied.
It specifies the number of cores to be used. Default is 1 (i.e. no parallel computing).</p>
</td></tr>
<tr><td><code id="label_detection_+3A_pb">pb</code></td>
<td>
<p>Logical argument to control progress bar. Default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="label_detection_+3A_min.overlap">min.overlap</code></td>
<td>
<p>Numeric. Controls the minimum amount of overlap required for a detection and a reference sound for it to be counted as true positive. Default is 0.5. Overlap is measured as intersection over union.</p>
</td></tr>
<tr><td><code id="label_detection_+3A_by">by</code></td>
<td>
<p>Character vector with the name of a categorical column in 'reference' for running a stratified. Labels will be returned separated for each level in 'by'. Default is <code>NULL</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function identifies the rows in the output of a detection routine as true or false positives. This is achieved by comparing the data frame to a reference selection table in which all sound events of interest have been selected.
</p>


<h3>Value</h3>

<p>A data frame or selection table (if 'detection' was also a selection table, warbleR package's format, see <code><a href="warbleR.html#topic+selection_table">selection_table</a></code>) including three additional columns, 'detection.class', which indicates the class of each detection, 'reference' which identifies the event in the 'reference' table that was detected  and 'overlap' which refers to the amount overlap to the reference sound. See <code><a href="#topic+diagnose_detection">diagnose_detection</a></code> for a description of the labels used in 'detection.class'. The output data frame also contains an additional data frame with the overlap for each pair of overlapping detection/reference.  Overlap is measured as intersection over union.
</p>


<h3>Author(s)</h3>

<p>Marcelo Araya-Salas <a href="mailto:marcelo.araya@ucr.ac.cr">marcelo.araya@ucr.ac.cr</a>)
</p>


<h3>References</h3>

<p>Araya-Salas, M., Smith-Vidaurre, G., Chaverri, G., Brenes, J. C., Chirino, F., Elizondo-Calvo, J., &amp; Rico-Guevara, A. 2022. ohun: an R package for diagnosing and optimizing automatic sound event detection. BioRxiv, 2022.12.13.520253. https://doi.org/10.1101/2022.12.13.520253
</p>


<h3>See Also</h3>

<p><code><a href="#topic+diagnose_detection">diagnose_detection</a></code>, <code><a href="#topic+summarize_diagnostic">summarize_diagnostic</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>{
  # load data
  data("lbh_reference")

  # an extra one in detection (1 false positive)
  label_detection(reference = lbh_reference[-1, ], detection = lbh_reference)

  # missing one in detection (all true positives)
  label_detection(reference = lbh_reference, detection = lbh_reference[-1, ])

  # perfect detection (all true positives)
  label_detection(reference = lbh_reference, detection = lbh_reference)

  # and extra sound file in reference (all true positives)
  label_detection(
    reference = lbh_reference, detection =
      lbh_reference[lbh_reference$sound.files != "lbh1.wav", ]
  )

  # and extra sound file in detection (some false positives)
  label_detection(
    reference =
      lbh_reference[lbh_reference$sound.files != "lbh1.wav", ],
    detection = lbh_reference
  )

  # duplicate 1 detection row (to get 2 splits)
  detec &lt;- lbh_reference[c(1, seq_len(nrow(lbh_reference))), ]
  detec$selec[1] &lt;- 1.2
  label_detection(
    reference = lbh_reference,
    detection = detec
  )

  # merge 2 detections (to get split and merge)
  Y &lt;- lbh_reference
  Y$end[1] &lt;- 1.2
  label_detection(reference = lbh_reference, detection = Y)

  # remove split to get only merge
  Y &lt;- Y[-2, ]
  label_detection(reference = lbh_reference, detection = Y)
}
</code></pre>

<hr>
<h2 id='label_spectro'>Plot a labeled spectrogram</h2><span id='topic+label_spectro'></span>

<h3>Description</h3>

<p><code>label_spectro</code> plot a spectrogram along with amplitude envelopes or cross-correlation scores
</p>


<h3>Usage</h3>

<pre><code class='language-R'>label_spectro(wave, reference = NULL, detection = NULL,
 envelope = FALSE, threshold = NULL, smooth = 5, collevels = seq(-100, 0, 5),
 palette = viridis::viridis, template.correlation = NULL,
 line.x.position = 2, hop.size = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="label_spectro_+3A_wave">wave</code></td>
<td>
<p>A 'wave' class object.</p>
</td></tr>
<tr><td><code id="label_spectro_+3A_reference">reference</code></td>
<td>
<p>Data frame or 'selection.table' (following the warbleR package format) with the reference selections (start and end of the sound events). Must contained at least the following columns: &quot;sound.files&quot;, &quot;selec&quot;, &quot;start&quot; and &quot;end&quot;.</p>
</td></tr>
<tr><td><code id="label_spectro_+3A_detection">detection</code></td>
<td>
<p>Data frame or 'selection.table' with the detection (start and end of the sound events) Must contained at least the following columns: &quot;sound.files&quot;, &quot;selec&quot;, &quot;start&quot; and &quot;end&quot;.</p>
</td></tr>
<tr><td><code id="label_spectro_+3A_envelope">envelope</code></td>
<td>
<p>Logical to control whether the amplitude envelope is plotted. Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="label_spectro_+3A_threshold">threshold</code></td>
<td>
<p>A numeric vector on length 1 indicated the amplitude or correlation threshold to plot on the envelope or correlation scores respectively. Default is <code>NULL</code>. Note that for amplitude the range of valid values is 0-1, while for correlations the range is 0-100.</p>
</td></tr>
<tr><td><code id="label_spectro_+3A_smooth">smooth</code></td>
<td>
<p>A numeric vector of length 1 to smooth the amplitude envelope
with a sum smooth function. It controls the time range (in ms) in which amplitude samples are smoothed (i.e. averaged with neighboring samples). Default is 5. 0 means no smoothing is applied.</p>
</td></tr>
<tr><td><code id="label_spectro_+3A_collevels">collevels</code></td>
<td>
<p>Numeric sequence of negative numbers to control color partitioning and amplitude values that are shown (as in <code><a href="seewave.html#topic+spectro">spectro</a></code>).</p>
</td></tr>
<tr><td><code id="label_spectro_+3A_palette">palette</code></td>
<td>
<p>Function with the color palette to be used on the spectrogram (as in <code><a href="seewave.html#topic+spectro">spectro</a></code>)</p>
</td></tr>
<tr><td><code id="label_spectro_+3A_template.correlation">template.correlation</code></td>
<td>
<p>List extracted from the output of <code><a href="#topic+template_correlator">template_correlator</a></code> containing the correlation scores and metadata for an specific sound file/template dyad. For instance 'correlations[[1]]' where 'correlations' is the output of a <code><a href="#topic+template_correlator">template_correlator</a></code> call. If supplied the correlation is also plotted. Default is <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="label_spectro_+3A_line.x.position">line.x.position</code></td>
<td>
<p>Numeric vector of length 1 with the position in the frequency axis (so in kHz) of the lines highlighting sound events. Default is 2.</p>
</td></tr>
<tr><td><code id="label_spectro_+3A_hop.size">hop.size</code></td>
<td>
<p>A numeric vector of length 1 specifying the time window duration (in ms). Default is 11.6 ms, which is equivalent to 512 'wl' for a 44.1 kHz sampling rate.</p>
</td></tr>
<tr><td><code id="label_spectro_+3A_...">...</code></td>
<td>
<p>Additional arguments to be passed to  <code><a href="seewave.html#topic+spectro">spectro</a></code> for further spectrogram customization.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function plots spectrograms annotated with the position of sound events. <strong>Created for graphs included in the vignette, and probably only useful for that or for very short recordings</strong>. Only works on a single 'wave' object at the time.
</p>


<h3>Value</h3>

<p>A spectrogram along with lines highlighting the position of sound events in 'reference' and/or 'detection'. If supplied it will also plot the amplitude envelope or corelation scores below the spectrogram.
</p>


<h3>Author(s)</h3>

<p>Marcelo Araya-Salas (<a href="mailto:marcelo.araya@ucr.ac.cr">marcelo.araya@ucr.ac.cr</a>).
</p>


<h3>References</h3>

<p>#' Araya-Salas, M., Smith-Vidaurre, G., Chaverri, G., Brenes, J. C., Chirino, F., Elizondo-Calvo, J., &amp; Rico-Guevara, A. 2022. ohun: an R package for diagnosing and optimizing automatic sound event detection. BioRxiv, 2022.12.13.520253. https://doi.org/10.1101/2022.12.13.520253
</p>


<h3>See Also</h3>

<p><code><a href="#topic+energy_detector">energy_detector</a></code>, <code><a href="#topic+template_correlator">template_correlator</a></code>, <code><a href="#topic+template_detector">template_detector</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>{
  # load example data
  data(list = "lbh1", "lbh_reference")

  # adding labels
  label_spectro(
    wave = lbh1,
    reference = lbh_reference[lbh_reference$sound.files == "lbh1.wav", ],
    wl = 200, ovlp = 50, flim = c(1, 10)
  )

  # adding envelope
  label_spectro(
    wave = lbh1,
    detection = lbh_reference[lbh_reference$sound.files == "lbh1.wav", ],
    wl = 200, ovlp = 50, flim = c(1, 10)
  )

  # see the package vignette for more examples
}

</code></pre>

<hr>
<h2 id='lbh_reference'>Example data frame of a selection table including all sound events of interests.</h2><span id='topic+lbh_reference'></span>

<h3>Description</h3>

<p><code>lbh_reference</code> is a data frame containing the start, end, bottom and top frequency of all songs in 'lbh_1.wav' and 'lbh_2.wav' recordings. #'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(lbh_reference)
</code></pre>


<h3>Format</h3>

<p>A data frame with 19 rows and 6 variables: </p>

<dl>
<dt>sound.files</dt><dd><p>recording names</p>
</dd>
<dt>selec</dt><dd><p>selection numbers within recording</p>
</dd>
<dt>start</dt><dd><p>start times of selected sound event</p>
</dd>
<dt>end</dt><dd><p>end times of selected sound event</p>
</dd>
<dt>bottom.freq</dt><dd><p>lower limit of frequency range</p>
</dd>
<dt>top.freq</dt><dd><p>upper limit of frequency range</p>
</dd>
</dl>



<h3>Details</h3>

<p>A data frame containing the start, end, low and high frequency of
<em>Phaethornis longirostris</em> (Long-billed Hermit) songs from the 2
example sound files included in this package ('lbh_1' and 'lbh_2'). These two files are clips extracted from the xeno-canto's '154138' and '154129' recordings respectively.
</p>


<h3>Source</h3>

<p>Marcelo Araya-Salas, ohun
</p>

<hr>
<h2 id='lbh1'>Long-billed hermit recording</h2><span id='topic+lbh1'></span>

<h3>Description</h3>

<p><code>lbh1</code> a wave object with long-billed hermit (<em>Phaethornis longirostris</em>) songs extracted from xeno-canto's '154138' recording.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(lbh1)
</code></pre>


<h3>Format</h3>

<p>An object of class <code>Wave</code> of length 110250.
</p>


<h3>Source</h3>

<p>Marcelo Araya-Salas
</p>

<hr>
<h2 id='lbh2'>Long-billed hermit recording</h2><span id='topic+lbh2'></span>

<h3>Description</h3>

<p><code>lbh2</code>  a wave object with long-billed hermit (<em>Phaethornis longirostris</em>) songs extracted from xeno-canto's '154129' recording.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(lbh2)
</code></pre>


<h3>Format</h3>

<p>An object of class <code>Wave</code> of length 110250.
</p>


<h3>Source</h3>

<p>Marcelo Araya-Salas
</p>

<hr>
<h2 id='merge_overlaps'>Merge overlapping selections</h2><span id='topic+merge_overlaps'></span>

<h3>Description</h3>

<p><code>merge_overlaps</code> merges several overlapping selections into a single selection
</p>


<h3>Usage</h3>

<pre><code class='language-R'>merge_overlaps(X, pb = TRUE, cores = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="merge_overlaps_+3A_x">X</code></td>
<td>
<p>Data frame or 'selection.table' (following the warbleR package format) with selections (start and end of the sound events). Must contained at least the following columns: &quot;sound.files&quot;, &quot;selec&quot;, &quot;start&quot; and &quot;end&quot;.</p>
</td></tr>
<tr><td><code id="merge_overlaps_+3A_pb">pb</code></td>
<td>
<p>Logical argument to control progress bar. Default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="merge_overlaps_+3A_cores">cores</code></td>
<td>
<p>Numeric. Controls whether parallel computing is applied.
It specifies the number of cores to be used. Default is 1 (i.e. no parallel computing).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function finds time-overlapping selection in reference tables and collapses them into a single selection. It can be useful to prepare reference tables to be used in an energy detection routine. In such cases overlapping selections are expected to be detected as a single sound. Therefore, merging them can be useful to prepare references in a format representing a more realistic expectation of how a perfect energy detection routine would look like.
</p>


<h3>Value</h3>

<p>If any time-overlapping selection is found it returns a data frame in which overlapping selections are collapse into a single selection.
</p>


<h3>Author(s)</h3>

<p>Marcelo Araya-Salas <a href="mailto:marcelo.araya@ucr.ac.cr">marcelo.araya@ucr.ac.cr</a>)
</p>


<h3>References</h3>

<p>Araya-Salas, M., Smith-Vidaurre, G., Chaverri, G., Brenes, J. C., Chirino, F., Elizondo-Calvo, J., &amp; Rico-Guevara, A. 2022. ohun: an R package for diagnosing and optimizing automatic sound event detection. BioRxiv, 2022.12.13.520253. https://doi.org/10.1101/2022.12.13.520253
</p>


<h3>See Also</h3>

<p><code><a href="#topic+summarize_diagnostic">summarize_diagnostic</a></code>, <code><a href="#topic+label_detection">label_detection</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>{
  # load data
  data("lbh_reference")

  # nothing to merge
  merge_overlaps(lbh_reference)

  # create artificial overlapping selections
  lbh_ref2 &lt;- rbind(as.data.frame(lbh_reference[c(3, 10), ]), lbh_reference[c(3, 10), ])

  lbh_ref2$selec &lt;- seq_len(nrow(lbh_ref2))

  merge_overlaps(lbh_ref2)
}
</code></pre>

<hr>
<h2 id='ohun'>ohun: Optimizing sound event detection</h2><span id='topic+ohun'></span><span id='topic+ohun-package'></span>

<h3>Description</h3>

<p>ohun is intended to facilitate the automated detection of sound events, providing functions to diagnose and optimize detection routines. Detections from other software can also be explored and optimized.
</p>


<h3>Details</h3>

<p>The main features of the package are:
</p>

<ul>
<li><p> The use of reference annotations for detection optimization and diagnostic
</p>
</li>
<li><p> The use of signal detection theory diagnostic parameters to evaluate detection performance
</p>
</li>
<li><p> The batch processing of sound files for improve computational performance
</p>
</li></ul>

<p>The package offers functions for:
</p>

<ul>
<li><p> Energy-based detection
</p>
</li>
<li><p> Template-based detection
</p>
</li>
<li><p> Diagnose detection precision
</p>
</li>
<li><p> Improve detection by adjusting parameters to optimize accuracy
</p>
</li></ul>

<p>All functions allow the parallelization of tasks, which distributes the tasks among several processors to improve computational efficiency. The package works on sound files in '.wav', '.mp3', '.flac' and '.wac' format.
</p>
<p>License: GPL (&gt;= 2)
</p>


<h3>Author(s)</h3>

<p>Marcelo Araya-Salas
</p>
<p>Maintainer: Marcelo Araya-Salas (<a href="mailto:marcelo.araya@ucr.ac.cr">marcelo.araya@ucr.ac.cr</a>)
</p>


<h3>See Also</h3>

<p>Useful links:
</p>

<ul>
<li> <p><a href="https://docs.ropensci.org/ohun/">https://docs.ropensci.org/ohun/</a>
</p>
</li>
<li> <p><a href="https://github.com/ropensci/ohun/">https://github.com/ropensci/ohun/</a>
</p>
</li>
<li><p> Report bugs at <a href="https://github.com/ropensci/ohun/issues/">https://github.com/ropensci/ohun/issues/</a>
</p>
</li></ul>


<hr>
<h2 id='optimize_energy_detector'>Optimize energy-based sound event detection</h2><span id='topic+optimize_energy_detector'></span>

<h3>Description</h3>

<p>Optimize energy-based sound event detection under different correlation threshold values
</p>


<h3>Usage</h3>

<pre><code class='language-R'>optimize_energy_detector(reference, files = NULL, threshold = 5,
peak.amplitude = 0, hop.size = 11.6, wl = NULL, smooth = 5, hold.time = 0,
min.duration = NULL, max.duration = NULL, thinning = 1, cores = 1, pb = TRUE,
 by.sound.file = FALSE, bp = NULL, path = ".", previous.output = NULL, envelopes = NULL,
 macro.average = FALSE, min.overlap = 0.5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="optimize_energy_detector_+3A_reference">reference</code></td>
<td>
<p>Selection table (using the warbleR package's format, see <code><a href="warbleR.html#topic+selection_table">selection_table</a></code>) or data frame with columns
for sound file name (sound.files), selection number (selec), and start and end time of sound event
(start and end). <strong>It must contain the reference selections that will be used for detection optimization</strong>.</p>
</td></tr>
<tr><td><code id="optimize_energy_detector_+3A_files">files</code></td>
<td>
<p>Character vector indicating the sound files that will be analyzed. Optional. If  not supplied the function will work on the sound files in 'reference'. It can be used to include sound files with no target sound events. Supported file formats:'.wav', '.mp3', '.flac' and '.wac'. If not supplied the function will work on all sound files (in the supported format) in 'path'.</p>
</td></tr>
<tr><td><code id="optimize_energy_detector_+3A_threshold">threshold</code></td>
<td>
<p>A numeric vector specifying the amplitude threshold for detecting
sound events (in %). Default is 5. <strong>Several values can be supplied for optimization</strong>.</p>
</td></tr>
<tr><td><code id="optimize_energy_detector_+3A_peak.amplitude">peak.amplitude</code></td>
<td>
<p>Numeric vector of length 1 with the minimum peak amplitude value. A detection below that value would be excluded. Peak amplitude is the maximum sound pressure level (in decibels) across the sound event (see <code><a href="warbleR.html#topic+sound_pressure_level">sound_pressure_level</a></code>). This can be useful when expecting higher peak amplitude in the target sound events compared to non-target sound events or when keeping only the best examples of the target sound events (i.e. high precision and low recall). Default is 0. <strong>Several values can be supplied for optimization</strong>.</p>
</td></tr>
<tr><td><code id="optimize_energy_detector_+3A_hop.size">hop.size</code></td>
<td>
<p>A numeric vector of length 1 specifying the time window duration (in ms). Default is 11.6 ms, which is equivalent to 512 wl for a 44.1 kHz sampling rate. Ignored if 'wl' is supplied.</p>
</td></tr>
<tr><td><code id="optimize_energy_detector_+3A_wl">wl</code></td>
<td>
<p>A numeric vector of length 1 specifying the window length of the spectrogram. Default is <code>NULL</code>. If supplied, 'hop.size' is ignored. Used internally for bandpass filtering (so only applied when 'bp' is supplied).</p>
</td></tr>
<tr><td><code id="optimize_energy_detector_+3A_smooth">smooth</code></td>
<td>
<p>A numeric vector of length 1 to smooth the amplitude envelope
with a sum smooth function. It controls the time 'neighborhood' (in ms) in which amplitude samples are smoothed (i.e. averaged with neighboring samples). Default is 5. 0 means no smoothing is applied. Note that smoothing is applied before thinning (see 'thinning' argument). The function  <code><a href="warbleR.html#topic+envelope">envelope</a></code> is used internally which is analogous to sum smoothing in <code><a href="seewave.html#topic+env">env</a></code>. This argument is used internally by <code><a href="#topic+get_envelopes">get_envelopes</a></code>. <strong>Several values can be supplied for optimization</strong>.</p>
</td></tr>
<tr><td><code id="optimize_energy_detector_+3A_hold.time">hold.time</code></td>
<td>
<p>Numeric vector of length 1. Specifies the time range (in ms) at which selections will be merged (i.e. if 2 selections are separated by less than the specified 'hold.time' they will be merged in to a single selection). Default is <code>0</code> (no hold time applied). <strong>Several values can be supplied for optimization</strong>.</p>
</td></tr>
<tr><td><code id="optimize_energy_detector_+3A_min.duration">min.duration</code></td>
<td>
<p>Numeric vector giving the shortest duration (in
ms) of the sound events to be detected. It removes sound events below that
threshold. <strong>Several values can be supplied for optimization</strong>.</p>
</td></tr>
<tr><td><code id="optimize_energy_detector_+3A_max.duration">max.duration</code></td>
<td>
<p>Numeric vector giving the longest duration (in
ms) of the sound events to be detected. It removes sound events above that
threshold. <strong>Several values can be supplied for optimization</strong>.</p>
</td></tr>
<tr><td><code id="optimize_energy_detector_+3A_thinning">thinning</code></td>
<td>
<p>Numeric vector in the range 0~1 indicating the proportional reduction of the number of
samples used to represent amplitude envelopes (i.e. the thinning of the envelopes). Usually amplitude envelopes have many more samples
than those needed to accurately represent amplitude variation in time, which affects the size of the
output (usually very large R objects / files). Default is  <code>1</code> (no thinning). Higher sampling rates may afford higher size reduction (e.g. lower thinning values). Reduction is conducted by interpolation using <code><a href="stats.html#topic+approx">approx</a></code>. Note that thinning may decrease time precision, and the higher the thinning the less precise the time detection. <strong>Several values can be supplied for optimization</strong>.</p>
</td></tr>
<tr><td><code id="optimize_energy_detector_+3A_cores">cores</code></td>
<td>
<p>Numeric. Controls whether parallel computing is applied.
It specifies the number of cores to be used. Default is 1 (i.e. no parallel computing).</p>
</td></tr>
<tr><td><code id="optimize_energy_detector_+3A_pb">pb</code></td>
<td>
<p>Logical argument to control progress bar and messages. Default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="optimize_energy_detector_+3A_by.sound.file">by.sound.file</code></td>
<td>
<p>Logical argument to control whether performance diagnostics are summarized across sound files (when <code>by.sound.file = FALSE</code> and more than 1 sound file is included in 'reference') or shown separated by sound file. Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="optimize_energy_detector_+3A_bp">bp</code></td>
<td>
<p>Numeric vector of length 2 giving the lower and upper limits of a
frequency bandpass filter (in kHz). Default is <code>NULL</code>.  This argument is used internally by <code><a href="#topic+get_envelopes">get_envelopes</a></code>. Not used if 'envelopes' are supplied. Bandpass is done using the function <code><a href="seewave.html#topic+ffilter">ffilter</a></code>, which applies a short-term Fourier transformation to first create a spectrogram in which the target frequencies are filtered and then is back transformed into a wave object using a reverse Fourier transformation.</p>
</td></tr>
<tr><td><code id="optimize_energy_detector_+3A_path">path</code></td>
<td>
<p>Character string containing the directory path where the sound files are located.
The current working directory is used as default.</p>
</td></tr>
<tr><td><code id="optimize_energy_detector_+3A_previous.output">previous.output</code></td>
<td>
<p>Data frame with the output of a previous run of this function. This will be used to include previous results in the new output and avoid recalculating detection performance for parameter combinations previously evaluated.</p>
</td></tr>
<tr><td><code id="optimize_energy_detector_+3A_envelopes">envelopes</code></td>
<td>
<p>An object of class 'envelopes' (generated by <code><a href="#topic+get_envelopes">get_envelopes</a></code>) containing the amplitude envelopes of the sound files to be analyzed. If 'files' and 'envelopes' are not supplied then the function will work on all supported format sound files in the working directory.</p>
</td></tr>
<tr><td><code id="optimize_energy_detector_+3A_macro.average">macro.average</code></td>
<td>
<p>Logical argument to control if diagnostics are first calculated for each sound file and then averaged across sound files, which can minimize the effect of unbalanced sample sizes between sound files. If <code>FALSE</code> (default) diagnostics are based on aggregated statistics irrespective of sound files. The following indices can be estimated by macro-averaging: overlap, mean.duration.true.positives, mean.duration.false.positives, mean.duration.false.positives, mean.duration.false.negatives, proportional.duration.true.positives, recall and precision (f.score is always derived from recall and precision). Note that when applying macro-averaging, recall and precision are not derived from the true positive, false positive and false negative values returned by the function.</p>
</td></tr>
<tr><td><code id="optimize_energy_detector_+3A_min.overlap">min.overlap</code></td>
<td>
<p>Numeric. Controls the minimum amount of overlap required for a detection and a reference sound for it to be counted as true positive. Default is 0.5. Overlap is measured as intersection over union.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function takes a selections data frame or 'selection_table' ('reference') estimates the detection performance of a energy detector under different detection parameter combinations. This is done by comparing the position in time of the detection to those of the reference selections in 'reference'. The function returns several diagnostic metrics to allow user to determine which parameter values provide a detection that more closely matches the selections in 'reference'. Those parameters can be later used for performing a more efficient detection using <code><a href="#topic+energy_detector">energy_detector</a></code>.
</p>


<h3>Value</h3>

<p>A data frame in which each row shows the result of a detection job with a particular combination of tuning parameters (including in the data frame). It also includes the following diagnostic metrics:
</p>

<ul>
<li> <p><code>true.positives</code>: number of sound events in 'reference' that correspond to any detection. Matching is defined as some degree of overlap in time. In a perfect detection routine it should be equal to the number of rows in 'reference'.
</p>
</li>
<li> <p><code>false.positives</code>: number of detections that don't match any of the sound events in 'reference'. In a perfect detection routine it should be 0.
</p>
</li>
<li> <p><code>false.negatives</code>: number of sound events in 'reference' that were not detected (not found in 'detection'. In a perfect detection routine it should be 0.
</p>
</li>
<li> <p><code>splits</code>: number of detections overlapping reference sounds that also overlap with other detections. In a perfect detection routine it should be 0.
</p>
</li>
<li> <p><code>merges</code>: number of detections that overlap with two or more reference sounds. In a perfect detection routine it should be 0.
</p>
</li>
<li> <p><code>mean.duration.true.positives</code>: mean duration of true positives (in ms). Only included when <code>time.diagnostics = TRUE</code>.
</p>
</li>
<li> <p><code>mean.duration.false.positives</code>: mean duration of false positives (in ms). Only included when <code>time.diagnostics = TRUE</code>.
</p>
</li>
<li> <p><code>mean.duration.false.negatives</code>: mean duration of false negatives (in ms). Only included when <code>time.diagnostics = TRUE</code>.
</p>
</li>
<li> <p><code>overlap</code>: mean intersection over union overlap of true positives.
</p>
</li>
<li> <p><code>proportional.duration.true.positives</code>: ratio of duration of true positives to th duration of sound events in 'reference'. In a perfect detection routine it should be 1. Based only on true positives that were not split or merged. Only included when <code>time.diagnostics = TRUE</code>.
</p>
</li>
<li> <p><code>duty.cycle</code>: proportion of a sound file in which sounds were detected. Only included when <code>time.diagnostics = TRUE</code> and <code>path</code> is supplied.
</p>
</li>
<li> <p><code>recall</code>: Proportion of sound events in 'reference' that were detected. In a perfect detection routine it should be 1.
</p>
</li>
<li> <p><code>precision</code>: Proportion of detections that correspond to sound events in 'reference'. In a perfect detection routine it should be 1.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Marcelo Araya-Salas (<a href="mailto:marcelo.araya@ucr.ac.cr">marcelo.araya@ucr.ac.cr</a>).
</p>


<h3>References</h3>

<p>Araya-Salas, M., Smith-Vidaurre, G., Chaverri, G., Brenes, J. C., Chirino, F., Elizondo-Calvo, J., &amp; Rico-Guevara, A. 2022. ohun: an R package for diagnosing and optimizing automatic sound event detection. BioRxiv, 2022.12.13.520253. https://doi.org/10.1101/2022.12.13.520253
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Save example files into temporary working directory
data("lbh1", "lbh2", "lbh_reference")
tuneR::writeWave(lbh1, file.path(tempdir(), "lbh1.wav"))
tuneR::writeWave(lbh2, file.path(tempdir(), "lbh2.wav"))

# using smoothing and minimum duration
optimize_energy_detector(
  reference = lbh_reference, path = tempdir(),
  threshold = c(6, 10), smooth = 6.8, bp = c(2, 9), hop.size = 6.8,
  min.duration = 90
)

# with thinning and smoothing
optimize_energy_detector(
  reference = lbh_reference, path = tempdir(),
  threshold = c(6, 10, 15), smooth = c(7, 10), thinning = c(0.1, 0.01),
  bp = c(2, 9), hop.size = 6.8, min.duration = 90
)

# by sound file
(opt_ed &lt;- optimize_energy_detector(
  reference = lbh_reference,
  path = tempdir(), threshold = c(6, 10, 15), smooth = 6.8, bp = c(2, 9),
  hop.size = 6.8, min.duration = 90, by.sound.file = TRUE
))

# summarize
summarize_diagnostic(opt_ed)

# using hold time
(op_ed &lt;- optimize_energy_detector(
  reference = lbh_reference,
  threshold = 10, hold.time = c(100, 150), bp = c(2, 9), hop.size = 6.8,
  path = tempdir()
))

# including previous output in new call
optimize_energy_detector(
  reference = lbh_reference, threshold = 10,
  hold.time = c(50, 200), previous.output = op_ed, smooth = 6.8,
  bp = c(2, 9), hop.size = 7, path = tempdir()
)

# having and extra file in files (simulating a file that should have no detetions)
sub_reference &lt;- lbh_reference[lbh_reference$sound.files != "lbh1.wav", ]

optimize_energy_detector(
  reference = sub_reference, files = unique(lbh_reference$sound.files),
  threshold = 10, hold.time = c(1, 150), bp = c(2, 9), smooth = 6.8,
  hop.size = 7, path = tempdir()
)


</code></pre>

<hr>
<h2 id='optimize_template_detector'>Optimize acoustic template detection</h2><span id='topic+optimize_template_detector'></span>

<h3>Description</h3>

<p><code><a href="#topic+optimize_template_detector">optimize_template_detector</a></code> optimizes acoustic template detection
</p>


<h3>Usage</h3>

<pre><code class='language-R'>optimize_template_detector(template.correlations, reference, threshold,
cores = 1, pb = TRUE, by.sound.file = FALSE, previous.output = NULL,
macro.average = FALSE, min.overlap = 0.5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="optimize_template_detector_+3A_template.correlations">template.correlations</code></td>
<td>
<p>An object of class 'template_correlations' (generated by <code><a href="#topic+template_correlator">template_correlator</a></code>) in which to optimize detections. Must contain data for all sound files as in 'reference'. It can also contain data for additional sound files. In this case the routine assumes that no sound events are found in those files, so detection from those files are all false positives.</p>
</td></tr>
<tr><td><code id="optimize_template_detector_+3A_reference">reference</code></td>
<td>
<p>Data frame or 'selection.table' (following the warbleR package format) with the reference selections (start and end of the sound events) that will be used to evaluate the performance of the detection, represented by those selections in 'detection'. Must contained at least the following columns: &quot;sound.files&quot;, &quot;selec&quot;, &quot;start&quot; and &quot;end&quot;. <strong>It must contain the reference selections that will be used for detection optimization</strong>.</p>
</td></tr>
<tr><td><code id="optimize_template_detector_+3A_threshold">threshold</code></td>
<td>
<p>Numeric vector of length &gt; 1 with values between 0 and 1 specifying the correlation threshold for detecting sound event occurrences (i.e. correlation peaks). Must be supplied. <strong>Several values should be supplied for optimization</strong>.</p>
</td></tr>
<tr><td><code id="optimize_template_detector_+3A_cores">cores</code></td>
<td>
<p>Numeric. Controls whether parallel computing is applied.
It specifies the number of cores to be used. Default is 1 (i.e. no parallel computing).</p>
</td></tr>
<tr><td><code id="optimize_template_detector_+3A_pb">pb</code></td>
<td>
<p>Logical argument to control progress bar and messages. Default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="optimize_template_detector_+3A_by.sound.file">by.sound.file</code></td>
<td>
<p>Logical to control if diagnostics are calculated for each sound file independently (<code>TRUE</code>) or for all sound files combined (<code>FALSE</code>, default).</p>
</td></tr>
<tr><td><code id="optimize_template_detector_+3A_previous.output">previous.output</code></td>
<td>
<p>Data frame with the output of a previous run of this function. This will be used to include previous results in the new output and avoid recalculating detection performance for parameter combinations previously evaluated.</p>
</td></tr>
<tr><td><code id="optimize_template_detector_+3A_macro.average">macro.average</code></td>
<td>
<p>Logical argument to control if diagnostics are first calculated for each sound file and then averaged across sound files, which can minimize the effect of unbalanced sample sizes between sound files. If <code>FALSE</code> (default) diagnostics are based on aggregated statistics irrespective of sound files. The following indices can be estimated by macro-averaging: overlap, mean.duration.true.positives, mean.duration.false.positives, mean.duration.false.positives, mean.duration.false.negatives, proportional.duration.true.positives, recall and precision (f.score is always derived from recall and precision). Note that when applying macro-averaging, recall and precision are not derived from the true positive, false positive and false negative values returned by the function.</p>
</td></tr>
<tr><td><code id="optimize_template_detector_+3A_min.overlap">min.overlap</code></td>
<td>
<p>Numeric. Controls the minimum amount of overlap required for a detection and a reference sound for it to be counted as true positive. Default is 0.5. Overlap is measured as intersection over union.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function takes a a reference data frame or 'selection_table' ('X') and the output of <code><a href="#topic+template_correlator">template_correlator</a></code> and estimates the detection performance for different detection parameter combinations. This is done by comparing the position in time of the detection to those of the reference selections. The function returns several diagnostic metrics to allow user to determine which parameter values provide a detection that more closely matches the selections in 'reference'. Those parameters can be later used for performing a more efficient detection using <code><a href="#topic+template_detector">template_detector</a></code>. Supported file formats:'.wav', '.mp3', '.flac' and '.wac'.
</p>


<h3>Value</h3>

<p>A data frame in which each row shows the result of a detection job for each cutoff value, including the following diagnostic metrics:
</p>

<ul>
<li> <p><code>true.positives</code>: number of sound events in 'reference' that correspond to any detection. Matching is defined as some degree of overlap in time. In a perfect detection routine it should be equal to the number of rows in 'reference'.
</p>
</li>
<li> <p><code>false.positives</code>: number of detections that don't match any of the sound events in 'reference'. In a perfect detection routine it should be 0.
</p>
</li>
<li> <p><code>false.negatives</code>: number of sound events in 'reference' that were not detected (not found in 'detection'. In a perfect detection routine it should be 0.
</p>
</li>
<li> <p><code>splits</code>: number of detections overlapping reference sounds that also overlap with other detections. In a perfect detection routine it should be 0.
</p>
</li>
<li> <p><code>merges</code>: number of sound events in 'detection' that overlap with more than one sound event in 'reference'. In a perfect detection routine it should be 0.
</p>
</li>
<li> <p><code>recall</code>: Proportion of sound events in 'reference' that were detected. In a perfect detection routine it should be 1.
</p>
</li>
<li> <p><code>precision</code>: Proportion of detections that correspond to sound events in 'reference' that were detected. In a perfect detection routine it should be 1.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Marcelo Araya-Salas (<a href="mailto:marcelo.araya@ucr.ac.cr">marcelo.araya@ucr.ac.cr</a>).
</p>


<h3>References</h3>

<p>Araya-Salas, M., Smith-Vidaurre, G., Chaverri, G., Brenes, J. C., Chirino, F., Elizondo-Calvo, J., &amp; Rico-Guevara, A. 2022. ohun: an R package for diagnosing and optimizing automatic sound event detection. BioRxiv, 2022.12.13.520253. https://doi.org/10.1101/2022.12.13.520253
</p>


<h3>See Also</h3>

<p><code><a href="#topic+optimize_energy_detector">optimize_energy_detector</a></code>, <code><a href="#topic+template_correlator">template_correlator</a></code>, <code><a href="#topic+template_detector">template_detector</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>{
# Save sound files to temporary working directory
data("lbh1", "lbh2", "lbh_reference")
tuneR::writeWave(lbh1, file.path(tempdir(), "lbh1.wav"))
tuneR::writeWave(lbh2, file.path(tempdir(), "lbh2.wav"))

# template for the second sound file in 'lbh_reference'
templ &lt;- lbh_reference[11, ]

# generate template correlations
tc &lt;- template_correlator(templates = templ, path = tempdir(),
files = "lbh2.wav")

# using 2 threshold
optimize_template_detector(template.correlations = tc, reference =
lbh_reference[lbh_reference$sound.files == "lbh2.wav", ],
threshold = c(0.2, 0.5))

# using several thresholds
optimize_template_detector(template.correlations = tc,
reference = lbh_reference[lbh_reference$sound.files == "lbh2.wav", ],
 threshold = seq(0.5, 0.9, by = 0.05))

 # template for the first and second sound file in 'lbh_reference'
 templ &lt;- lbh_reference[c(1, 11), ]

 # generate template correlations
 tc &lt;- template_correlator(templates = templ, path = tempdir(),
 files = c("lbh1.wav", "lbh2.wav"))

optimize_template_detector(template.correlations = tc, reference =
  lbh_reference, threshold = seq(0.5, 0.7, by = 0.1))

 # showing diagnostics by sound file
 optimize_template_detector(template.correlations = tc, reference =
 lbh_reference,
 threshold = seq(0.5, 0.7, by = 0.1), by.sound.file = TRUE)
}

</code></pre>

<hr>
<h2 id='plot_detection'>Plot detection and reference annotations</h2><span id='topic+plot_detection'></span>

<h3>Description</h3>

<p><code>plot_detection</code> evaluates the performance of a sound event detection procedure comparing the output selection table to a reference selection table
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot_detection(reference, detection, mid.point = FALSE, size = 20, positions = c(1, 2))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot_detection_+3A_reference">reference</code></td>
<td>
<p>Data frame or 'selection.table' (following the warbleR package format) with the reference selections (start and end of the sound events) that will be used to evaluate the performance of the detection, represented by those selections in 'detection'. Must contained at least the following columns: &quot;sound.files&quot;, &quot;selec&quot;, &quot;start&quot; and &quot;end&quot;. <strong>It must contain the reference selections that will be used for detection optimization</strong>.</p>
</td></tr>
<tr><td><code id="plot_detection_+3A_detection">detection</code></td>
<td>
<p>Data frame or 'selection.table' with the detections (start and end of the sound events) that will be compared against the 'reference' selections. Must contained at least the following columns: &quot;sound.files&quot;, &quot;selec&quot;, &quot;start&quot; and &quot;end&quot;. It can contain data for additional sound files not found in 'references'. In this case the routine assumes that no sound events are found in those files, so detection from those files are all false positives.</p>
</td></tr>
<tr><td><code id="plot_detection_+3A_mid.point">mid.point</code></td>
<td>
<p>Logical argument to control if each annotations is shown as a rectangle with fix width center at the mid point of the time position (if <code>TRUE</code>) or the true time range of the annotations is used (if <code>FALSE</code>,  default). 'mid.point' can be useful to make visible annotations in very long sound files that would otherwise look to thin.</p>
</td></tr>
<tr><td><code id="plot_detection_+3A_size">size</code></td>
<td>
<p>Numeric. Controls the size of the rectangles if <code>mid.point = TRUE</code>. Default is 20.</p>
</td></tr>
<tr><td><code id="plot_detection_+3A_positions">positions</code></td>
<td>
<p>Numeric. Controls the vertical position of the rectangles representing anotations. Default is c(1, 2). This can be used to get reference and detection annotations closer in the vertical axis. Note that the height of rectangles is 0.5.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function helps to visualize the match between reference and detection annotations by plotting them next to each other as rectangles along the time axis. If the annotations contain data for several sound files each sound file will be plotted in its own panel. The plot can be further modify by users using regular ggplot syntax.
</p>


<h3>Value</h3>

<p>A ggplot graph (i.e. an object of class &quot;ggplot&quot;).
</p>


<h3>Author(s)</h3>

<p>Marcelo Araya-Salas <a href="mailto:marcelo.araya@ucr.ac.cr">marcelo.araya@ucr.ac.cr</a>)
</p>


<h3>References</h3>

<p>Araya-Salas, M., Smith-Vidaurre, G., Chaverri, G., Brenes, J. C., Chirino, F., Elizondo-Calvo, J., &amp; Rico-Guevara, A. 2022. ohun: an R package for diagnosing and optimizing automatic sound event detection. BioRxiv, 2022.12.13.520253. https://doi.org/10.1101/2022.12.13.520253
</p>


<h3>See Also</h3>

<p><code><a href="#topic+label_spectro">label_spectro</a></code>, <code><a href="#topic+diagnose_detection">diagnose_detection</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>{
  # load data
  data("lbh_reference")

  # mid point and regular size
  plot_detection(
    reference = lbh_reference[-14, ],
    detection = lbh_reference[-1, ], mid.point = TRUE
  )

  # mid point and larger size
  plot_detection(
    reference = lbh_reference[-14, ],
    detection = lbh_reference[-1, ], mid.point = TRUE, size = 25
  )

  # true time rectangles
  plot_detection(
    reference = lbh_reference[-14, ],
    detection = lbh_reference[-1, ]
  )

  # use position to make reference and anotations overlap vertically
  plot_detection(
    reference = lbh_reference[-14, ],
    detection = lbh_reference[-1, ], positions = c(1, 1.4)
  )

  # modified using ggplot
  gg_pd &lt;- plot_detection(
    reference = lbh_reference[-14, ],
    detection = lbh_reference[-1, ], positions = c(1, 1.4)
  )

  gg_pd + ggplot2::theme_classic(base_size = 25)
}
</code></pre>

<hr>
<h2 id='print.envelopes'>Class 'envelopes': list of absolute amplitude envelopes</h2><span id='topic+print.envelopes'></span>

<h3>Description</h3>

<p>Class for absolute amplitude envelopes
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'envelopes'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.envelopes_+3A_x">x</code></td>
<td>
<p>Object of class <code>envelopes</code>, generated by <code><a href="#topic+get_envelopes">get_envelopes</a></code>.</p>
</td></tr>
<tr><td><code id="print.envelopes_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods. Ignored when printing envelopes.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>An object of class <code>envelopes</code> created by <code><a href="#topic+get_envelopes">get_envelopes</a></code> is a list with sound files absolute amplitude envelopes and metadata
</p>


<h3>Value</h3>

<p>Prints a summary of an object of class 'envelopes'.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+get_envelopes">get_envelopes</a></code>
print method for class <code>envelopes</code>
</p>

<hr>
<h2 id='print.template_correlations'>print method for class <code>template_correlations</code></h2><span id='topic+print.template_correlations'></span>

<h3>Description</h3>

<p>print method for class <code>template_correlations</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'template_correlations'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.template_correlations_+3A_x">x</code></td>
<td>
<p>Object of class <code>template_correlations</code>, generated by <code><a href="#topic+template_correlator">template_correlator</a></code>.</p>
</td></tr>
<tr><td><code id="print.template_correlations_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods. Ignored when printing 'template_correlations' class objects.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Prints a summary of an object of class 'template_correlations'.
</p>

<hr>
<h2 id='split_acoustic_data'>Splits sound files and associated annotations</h2><span id='topic+split_acoustic_data'></span>

<h3>Description</h3>

<p><code>split_acoustic_data</code> splits sound files (and corresponding selection tables) in shorter segments
</p>


<h3>Usage</h3>

<pre><code class='language-R'>split_acoustic_data(path = ".", sgmt.dur = 10, sgmts = NULL, files = NULL,
 cores = 1, pb = TRUE, only.sels = FALSE, X = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="split_acoustic_data_+3A_path">path</code></td>
<td>
<p>Directory path where sound files are found.
The current working directory is used as default.</p>
</td></tr>
<tr><td><code id="split_acoustic_data_+3A_sgmt.dur">sgmt.dur</code></td>
<td>
<p>Numeric. Duration (in s) of segments in which sound files would be split. Sound files shorter than 'sgmt.dur' won't be split. Ignored if 'sgmts' is supplied.</p>
</td></tr>
<tr><td><code id="split_acoustic_data_+3A_sgmts">sgmts</code></td>
<td>
<p>Numeric. Number of segments in which to split each sound file. If supplied 'sgmt.dur' is ignored.</p>
</td></tr>
<tr><td><code id="split_acoustic_data_+3A_files">files</code></td>
<td>
<p>Character vector indicating the subset of files that will be split. Supported file formats:'.wav', '.mp3', '.flac' and '.wac'. If not supplied the function will work on all sound files (in the supported format) in 'path'.</p>
</td></tr>
<tr><td><code id="split_acoustic_data_+3A_cores">cores</code></td>
<td>
<p>Numeric. Controls whether parallel computing is applied.
It specifies the number of cores to be used. Default is 1 (i.e. no parallel computing).</p>
</td></tr>
<tr><td><code id="split_acoustic_data_+3A_pb">pb</code></td>
<td>
<p>Logical argument to control progress bar. Default is <code>TRUE</code>. Only used when</p>
</td></tr>
<tr><td><code id="split_acoustic_data_+3A_only.sels">only.sels</code></td>
<td>
<p>Logical argument to control if only the data frame is returned (no wave files are saved). Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="split_acoustic_data_+3A_x">X</code></td>
<td>
<p>'selection_table' object or a data frame with columns
for sound file name (sound.files), selection number (selec), and start and end time of signal
(start and end). If supplied the data frame/selection table is modified to reflect the position of the selections in the new sound files. Note that some selections could split between 2 segments. To deal with this, a 'split.sels' column is added to the data frame in which those selection are labeled as 'split'. Default is <code>NULL</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function aims to reduce the size of sound files in order to simplify some processes that are limited by sound file size (big files can be manipulated, e.g. <code><a href="#topic+energy_detector">energy_detector</a></code>).
</p>


<h3>Value</h3>

<p>Wave files for each segment in the working directory (if <code>only.sels = FALSE</code>, named as 'sound.file.name-#.wav') and a data frame in the R environment containing the name of the original sound files (original.sound.files), the name of the clips (sound.files) and the start and end of clips in the original files. Clips are saved in .wav format. If 'X' is supplied then a data frame with the position of the selections in the newly created clips is returned instead. In this case the output data frame contains an additional column, 'split.sels', that inform users whether selections have been split into multiple clips ('split') or not (<code>NA</code>).
</p>


<h3>Author(s)</h3>

<p>Marcelo Araya-Salas (<a href="mailto:marcelo.araya@ucr.ac.cr">marcelo.araya@ucr.ac.cr</a>)
</p>


<h3>References</h3>

<p>Araya-Salas, M., Smith-Vidaurre, G., Chaverri, G., Brenes, J. C., Chirino, F., Elizondo-Calvo, J., &amp; Rico-Guevara, A. 2022. ohun: an R package for diagnosing and optimizing automatic sound event detection. BioRxiv, 2022.12.13.520253. https://doi.org/10.1101/2022.12.13.520253
</p>


<h3>See Also</h3>

<p><code><a href="warbleR.html#topic+cut_sels">cut_sels</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>{
  # load data and save to temporary working directory
  data("lbh1", "lbh2")
  tuneR::writeWave(lbh1, file.path(tempdir(), "lbh1.wav"))
  tuneR::writeWave(lbh2, file.path(tempdir(), "lbh2.wav"))

  # split files in 1 s files
  split_acoustic_data(sgmt.dur = 1, path = tempdir())

  # Check this folder
  tempdir()
}

</code></pre>

<hr>
<h2 id='summarize_acoustic_data'>Summarize information about file format in an acoustic data set</h2><span id='topic+summarize_acoustic_data'></span>

<h3>Description</h3>

<p><code>summarize_acoustic_data</code> summarizes information about file format in an acoustic data set
</p>


<h3>Usage</h3>

<pre><code class='language-R'>summarize_acoustic_data(path = ".", digits = 2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summarize_acoustic_data_+3A_path">path</code></td>
<td>
<p>Character string containing the directory path where the sound files are located. Default is <code>"."</code> (current working directory).</p>
</td></tr>
<tr><td><code id="summarize_acoustic_data_+3A_digits">digits</code></td>
<td>
<p>Numeric vector of length 1 with the number of decimals to include. Default is 2.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function summarizes information about file format in an acoustic data set. It provides information about the number of files, file formats, sampling rates, bit depts, channels, duration and file size (in MB). For file format, sampling rate, bit depth and number of channels the function includes information about the number of files for each format (e.g. '44.1 kHz (2)' means 2 files with a sampling rate of 44.1 kHz).
</p>


<h3>Value</h3>

<p>The function prints a summary of the format of the files in an acoustic data set.
</p>


<h3>Author(s)</h3>

<p>Marcelo Araya-Salas <a href="mailto:marcelo.araya@ucr.ac.cr">marcelo.araya@ucr.ac.cr</a>)
</p>


<h3>References</h3>

<p>Araya-Salas, M., Smith-Vidaurre, G., Chaverri, G., Brenes, J. C., Chirino, F., Elizondo-Calvo, J., &amp; Rico-Guevara, A. 2022. ohun: an R package for diagnosing and optimizing automatic sound event detection. BioRxiv, 2022.12.13.520253. https://doi.org/10.1101/2022.12.13.520253
</p>


<h3>See Also</h3>

<p><code><a href="#topic+summarize_reference">summarize_reference</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>{
  # load data and save example files into temporary working directory
  data("lbh1", "lbh2", "lbh_reference")
  tuneR::writeWave(lbh1, file.path(tempdir(), "lbh1.wav"))
  tuneR::writeWave(lbh2, file.path(tempdir(), "lbh2.wav"))

  # summary across sound files
  summarize_acoustic_data(path = tempdir())
}
</code></pre>

<hr>
<h2 id='summarize_diagnostic'>Summarize detection diagnostics</h2><span id='topic+summarize_diagnostic'></span>

<h3>Description</h3>

<p><code>summarize_diagnostic</code> summarizes detection diagnostics
</p>


<h3>Usage</h3>

<pre><code class='language-R'>summarize_diagnostic(diagnostic, time.diagnostics = FALSE, macro.average = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summarize_diagnostic_+3A_diagnostic">diagnostic</code></td>
<td>
<p>A data frame with the output of a detection optimization function (<code><a href="#topic+diagnose_detection">diagnose_detection</a></code>, <code><a href="#topic+optimize_energy_detector">optimize_energy_detector</a></code> or <code><a href="#topic+optimize_template_detector">optimize_template_detector</a></code>)</p>
</td></tr>
<tr><td><code id="summarize_diagnostic_+3A_time.diagnostics">time.diagnostics</code></td>
<td>
<p>Logical argument to control if diagnostics related to the duration of the sound events (&quot;mean.duration.true.positives&quot;, &quot;mean.duration.false.positives&quot;, &quot;mean.duration.false.negatives&quot; and &quot;proportional.duration.true.positives&quot;) are returned (if <code>TRUE</code>). Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="summarize_diagnostic_+3A_macro.average">macro.average</code></td>
<td>
<p>Logical argument to control if diagnostics are first calculated for each sound file and then averaged across sound files, which can minimize the effect of unbalanced sample sizes between sound files. If <code>FALSE</code> (default) diagnostics are based on aggregated statistics irrespective of sound files. The following indices can be estimated by macro-averaging: overlap, mean.duration.true.positives, mean.duration.false.positives, mean.duration.false.positives, mean.duration.false.negatives, proportional.duration.true.positives, recall and precision (f.score is always derived from recall and precision). Note that when applying macro-averaging, recall and precision are not derived from the true positive, false positive and false negative values returned by the function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function summarizes a detection diagnostic data frame in which diagnostic parameters are shown split by (typically) a categorical column, usually sound files. This function is used internally by <code><a href="#topic+diagnose_detection">diagnose_detection</a></code>. 'splits' and 'merge.positives' are also counted (i.e. counted twice) as 'true.positives'. Therefore &quot;true.positives + false.positives = detections&quot;.
</p>


<h3>Value</h3>

<p>A data frame, similar to the output of a detection optimization function (<code><a href="#topic+diagnose_detection">diagnose_detection</a></code>, <code><a href="#topic+optimize_energy_detector">optimize_energy_detector</a></code>, <code><a href="#topic+optimize_template_detector">optimize_template_detector</a></code>) including the following detection performance diagnostics:
</p>

<ul>
<li> <p><code>detections</code>: total number of detections
</p>
</li>
<li> <p><code>true.positives</code>: number of sound events in 'reference' that correspond to any detection. Matching is defined as some degree of overlap in time. In a perfect detection routine it should be equal to the number of rows in 'reference'.
</p>
</li>
<li> <p><code>false.positives</code>: number of detections that don't match (i.e. don't overlap with) any of the sound events in 'reference'. In a perfect detection routine it should be 0.
</p>
</li>
<li> <p><code>false.negatives</code>: number of sound events in 'reference' that were not detected (not found in 'detection'. In a perfect detection routine it should be 0.
</p>
</li>
<li> <p><code>splits</code>: number of detections overlapping reference sounds that also overlap with other detections. In a perfect detection routine it should be 0.
</p>
</li>
<li> <p><code>merges</code>: number of detections that overlap with two or more reference sounds. In a perfect detection routine it should be 0.
</p>
</li>
<li> <p><code>mean.duration.true.positives</code>: mean duration of true positives (in s). Only included when <code>time.diagnostics = TRUE</code>.
</p>
</li>
<li> <p><code>mean.duration.false.positives</code>: mean duration of false positives (in ms). Only included when <code>time.diagnostics = TRUE</code>.
</p>
</li>
<li> <p><code>mean.duration.false.negatives</code>: mean duration of false negatives (in ms). Only included when <code>time.diagnostics = TRUE</code>.
</p>
</li>
<li> <p><code>overlap</code>: mean intersection over union overlap of true positives.
</p>
</li>
<li> <p><code>proportional.duration.true.positives</code>: ratio of duration of true positives to the duration of sound events in 'reference'. In a perfect detection routine it should be 1. Based only on true positives that were not split or merged.
</p>
</li>
<li> <p><code>duty.cycle</code>: proportion of a sound file in which sounds were detected. Only included when <code>time.diagnostics = TRUE</code> and <code>path</code> is supplied. Useful when conducting energy-based detection as a perfect detection can be obtained with a very low amplitude threshold, which will detect everything, but will produce a duty cycle close to 1.
</p>
</li>
<li> <p><code>recall</code>: Proportion of sound events in 'reference' that were detected. In a perfect detection routine it should be 1.
</p>
</li>
<li> <p><code>precision</code>: Proportion of detections that correspond to sound events in 'reference'. In a perfect detection routine it should be 1.
</p>
</li>
<li> <p><code>f.score</code>: Combines recall and precision as the harmonic mean of these two. Provides a single value for evaluating performance. In a perfect detection routine it should be 1.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Marcelo Araya-Salas <a href="mailto:marcelo.araya@ucr.ac.cr">marcelo.araya@ucr.ac.cr</a>)
</p>


<h3>References</h3>

<p>Araya-Salas, M., Smith-Vidaurre, G., Chaverri, G., Brenes, J. C., Chirino, F., Elizondo-Calvo, J., &amp; Rico-Guevara, A. 2022. ohun: an R package for diagnosing and optimizing automatic sound event detection. BioRxiv, 2022.12.13.520253.
Mesaros, A., Heittola, T., &amp; Virtanen, T. (2016). Metrics for polyphonic sound event detection. Applied Sciences, 6(6), 162.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+diagnose_detection">diagnose_detection</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>{
  # load example selection tables

  data("lbh_reference")

  # run diagnose_detection() by sound file
  diag &lt;- diagnose_detection(
    reference = lbh_reference,
    detection = lbh_reference[-1, ], by.sound.file = TRUE
  )

  # summarize
  summarize_diagnostic(diagnostic = diag)

  # should be the same as this:
  diagnose_detection(
    reference = lbh_reference,
    detection = lbh_reference[-1, ], by.sound.file = FALSE
  )
}
</code></pre>

<hr>
<h2 id='summarize_reference'>Summarize temporal and frequency dimensions of annotations and gaps</h2><span id='topic+summarize_reference'></span>

<h3>Description</h3>

<p><code>summarize_reference</code> summarizes temporal and frequency dimensions of annotations and gaps
</p>


<h3>Usage</h3>

<pre><code class='language-R'>summarize_reference(reference, path = NULL, by.sound.file = FALSE,
units = c("ms", "kHz"), digits = 2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summarize_reference_+3A_reference">reference</code></td>
<td>
<p>Data frame or 'selection.table' (following the warbleR package format) with the reference selections (start and end of the sound events) that will be used to evaluate the performance of the detection, represented by those selections in 'detection'. Must contained at least the following columns: &quot;sound.files&quot;, &quot;selec&quot;, &quot;start&quot; and &quot;end&quot;. If frequency range columns are included (&quot;bottom.freq&quot; and &quot;top.freq&quot;) these are also used to characterize reference selections.</p>
</td></tr>
<tr><td><code id="summarize_reference_+3A_path">path</code></td>
<td>
<p>Character string containing the directory path where the sound files are located. If supplied then duty cycle and peak frequency features are returned. These features are more helpful for tuning a energy-based detection. Default is <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="summarize_reference_+3A_by.sound.file">by.sound.file</code></td>
<td>
<p>Logical argument to control whether features are summarized across sound files (when <code>by.sound.file = FALSE</code>, and more than 1 sound file is included in 'reference') or shown separated by sound file. Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="summarize_reference_+3A_units">units</code></td>
<td>
<p>A character vector of length 2 with the units to be used for time and frequency parameters, in that order. Default is <code>c("ms", "kHz")</code>. It can also take 's' and 'Hz'.</p>
</td></tr>
<tr><td><code id="summarize_reference_+3A_digits">digits</code></td>
<td>
<p>Numeric vector of length 1 with the number of decimals to include. Default is 2.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function extracts quantitative features from reference tables that can inform the range of values to be used in a energy-based detection optimization routine. Features related to selection duration can be used to set the 'max.duration' and 'min.duration' values, frequency related features can inform bandpass values, gap related features inform hold time values and duty cycle can be used to evaluate performance.
</p>


<h3>Value</h3>

<p>The function returns the mean, minimum and maximum duration of selections and gaps (time intervals between selections) and of the number of annotations by sound file. If frequency range columns are included in the reference table (i.e. &quot;bottom.freq&quot; and &quot;top.freq&quot;) the minimum bottom frequency ('min.bottom.freq') and the maximum top frequency ('max.top.freq') are also estimated. Finally, if the path to the sound files in 'reference' is supplied the duty cycle (fraction of a sound file corresponding to target sound events) and peak amplitude (highest amplitude in a detection) are also returned. If &lsquo;by.sound.file = FALSE' a matrix with features in rows is returned. Otherwise a data frame is returned in which each row correspond to a sound file. By default, time features are returned in &rsquo;ms' while frequency features in 'kHz' (but see 'units' argument).
</p>


<h3>Author(s)</h3>

<p>Marcelo Araya-Salas <a href="mailto:marcelo.araya@ucr.ac.cr">marcelo.araya@ucr.ac.cr</a>)
</p>


<h3>References</h3>

<p>Araya-Salas, M., Smith-Vidaurre, G., Chaverri, G., Brenes, J. C., Chirino, F., Elizondo-Calvo, J., &amp; Rico-Guevara, A. 2022. ohun: an R package for diagnosing and optimizing automatic sound event detection. BioRxiv, 2022.12.13.520253. https://doi.org/10.1101/2022.12.13.520253
</p>


<h3>See Also</h3>

<p><code><a href="#topic+optimize_energy_detector">optimize_energy_detector</a></code>, <code><a href="#topic+optimize_template_detector">optimize_template_detector</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>{
  # load data and save example files into temporary working directory
  data("lbh1", "lbh2", "lbh_reference")
  tuneR::writeWave(lbh1, file.path(tempdir(), "lbh1.wav"))
  tuneR::writeWave(lbh2, file.path(tempdir(), "lbh2.wav"))

  # summary across sound files
  summarize_reference(reference = lbh_reference, path = tempdir())

  # summary across sound files
  summarize_reference(reference = lbh_reference, by.sound.file = TRUE, path = tempdir())
}
</code></pre>

<hr>
<h2 id='template_correlator'>Acoustic templates correlator using time-frequency cross-correlation</h2><span id='topic+template_correlator'></span>

<h3>Description</h3>

<p><code>template_correlator</code> estimates templates cross-correlation across multiple sound files.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>template_correlator(templates, files = NULL, hop.size = 11.6, wl = NULL, ovlp = 0,
wn ='hanning', cor.method = "pearson", cores = 1, path = ".",
pb = TRUE, type = "fourier", fbtype = "mel", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="template_correlator_+3A_templates">templates</code></td>
<td>
<p>'selection_table', 'extended_selection_table' (warbleR package's formats, see <code><a href="warbleR.html#topic+selection_table">selection_table</a></code>) or data frame with time and frequency information of the sound event(s) to be used as templates (1 template per row). The object must contain columns for sound files (sound.files),
selection number (selec), and start and end time of sound event (start and end). If frequency range columns are included ('bottom.freq' and 'top.freq', in kHz) the correlation will be run on those frequency ranges. All templates must have the same sampling rate and both templates and 'files' (in which to find templates) must also have the same sampling rate.</p>
</td></tr>
<tr><td><code id="template_correlator_+3A_files">files</code></td>
<td>
<p>Character vector with name of the files in which to run the cross-correlation with the supplied template(s). Supported file formats:'.wav', '.mp3', '.flac' and '.wac'. If not supplied the function will work on all sound files (in the supported formats) in 'path'.</p>
</td></tr>
<tr><td><code id="template_correlator_+3A_hop.size">hop.size</code></td>
<td>
<p>A numeric vector of length 1 specifying the time window duration (in ms). Default is 11.6 ms, which is equivalent to 512 wl for a 44.1 kHz sampling rate. Ignored if 'wl' is supplied.</p>
</td></tr>
<tr><td><code id="template_correlator_+3A_wl">wl</code></td>
<td>
<p>A numeric vector of length 1 specifying the window length of the spectrogram. Default is <code>NULL</code>. If supplied, 'hop.size' is ignored.</p>
</td></tr>
<tr><td><code id="template_correlator_+3A_ovlp">ovlp</code></td>
<td>
<p>Numeric vector of length 1 specifying % of overlap between two
consecutive windows, as in <code><a href="seewave.html#topic+spectro">spectro</a></code>. Default is 0. High values of ovlp
slow down the function but may produce more accurate results.</p>
</td></tr>
<tr><td><code id="template_correlator_+3A_wn">wn</code></td>
<td>
<p>A character vector of length 1 specifying the window name as in <code><a href="seewave.html#topic+ftwindow">ftwindow</a></code>.</p>
</td></tr>
<tr><td><code id="template_correlator_+3A_cor.method">cor.method</code></td>
<td>
<p>A character vector of length 1 specifying the correlation method as in <code><a href="stats.html#topic+cor">cor</a></code>.</p>
</td></tr>
<tr><td><code id="template_correlator_+3A_cores">cores</code></td>
<td>
<p>Numeric. Controls whether parallel computing is applied.
It specifies the number of cores to be used. Default is 1 (i.e. no parallel computing).</p>
</td></tr>
<tr><td><code id="template_correlator_+3A_path">path</code></td>
<td>
<p>Character string containing the directory path where the sound files are located.
The current working directory is used as default.</p>
</td></tr>
<tr><td><code id="template_correlator_+3A_pb">pb</code></td>
<td>
<p>Logical argument to control progress bar. Default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="template_correlator_+3A_type">type</code></td>
<td>
<p>A character vector of length 1 specifying the type of cross-correlation: &quot;fourier&quot; (i.e. spectrographic cross-correlation using Fourier transform; internally using <code><a href="seewave.html#topic+spectro">spectro</a></code>; default), &quot;mfcc&quot; (auditory scale coefficient matrix cross-correlation; internally using <code><a href="tuneR.html#topic+melfcc">melfcc</a></code>) or &quot;mel-auditory&quot; (cross-correlation of auditory spectrum, i.e. spectrum after transformation to an auditory scale; internally using <code><a href="tuneR.html#topic+melfcc">melfcc</a></code>). The argument 'fbtype' controls the auditory scale to be used. Note that the last 2 methods have not been widely used in this context so can be regarded as experimental.</p>
</td></tr>
<tr><td><code id="template_correlator_+3A_fbtype">fbtype</code></td>
<td>
<p>Character vector indicating the auditory frequency scale to use: &quot;mel&quot;, &quot;bark&quot;, &quot;htkmel&quot;, &quot;fcmel&quot;.</p>
</td></tr>
<tr><td><code id="template_correlator_+3A_...">...</code></td>
<td>
<p>Additional arguments to be passed to <code><a href="tuneR.html#topic+melfcc">melfcc</a></code> for further customization when using auditory scales.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function calculates the similarity of acoustic templates across sound files by means of time-frequency cross-correlation. Fourier spectrograms or time-frequency representations from auditory scales (including cepstral coefficients) can be used. Several templates can be run over several sound files. Note that template-based detection is divided in two steps: template correlation (using this function) and template detection (or peak detection as it infers detection based on peak correlation scores, using the function <code><a href="#topic+template_detector">template_detector</a></code>). So the output of this function (and object of 'template_correlations') must be input into <code><a href="#topic+template_detector">template_detector</a></code> for inferring sound event occurrences. <code><a href="#topic+optimize_template_detector">optimize_template_detector</a></code> can be used to optimize template detection.
</p>


<h3>Value</h3>

<p>The function returns an object of class 'template_correlations' which is a list with the correlation scores for each combination of templates and files. 'template_correlations' objects must be used to infer sound event occurrences using <code><a href="#topic+template_detector">template_detector</a></code> or to graphically explore template correlations across sound files using <code><a href="warbleR.html#topic+full_spectrograms">full_spectrograms</a></code>.
</p>


<h3>Author(s)</h3>

<p>Marcelo Araya-Salas <a href="mailto:marcelo.araya@ucr.ac.cr">marcelo.araya@ucr.ac.cr</a>)
</p>


<h3>References</h3>

<p>Araya-Salas, M., Smith-Vidaurre, G., Chaverri, G., Brenes, J. C., Chirino, F., Elizondo-Calvo, J., &amp; Rico-Guevara, A. 2022. ohun: an R package for diagnosing and optimizing automatic sound event detection. BioRxiv, 2022.12.13.520253. https://doi.org/10.1101/2022.12.13.520253
</p>
<p>Khanna H., Gaunt S.L.L.  &amp; McCallum D.A. (1997). Digital spectrographic cross-correlation: tests of recall. Bioacoustics 7(3): 209-234.
</p>
<p>Lyon, R. H., &amp; Ordubadi, A. (1982). Use of cepstra in acoustical signal analysis. Journal of Mechanical Design, 104(2), 303-306.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+energy_detector">energy_detector</a></code>, <code><a href="#topic+template_detector">template_detector</a></code>, <code><a href="#topic+optimize_template_detector">optimize_template_detector</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>{
  # load example data
  data("lbh1", "lbh2", "lbh_reference")

  # save sound files
  tuneR::writeWave(lbh1, file.path(tempdir(), "lbh1.wav"))
  tuneR::writeWave(lbh2, file.path(tempdir(), "lbh2.wav"))

  # create template
  templ &lt;- lbh_reference[4, ]
  templ2 &lt;- warbleR::selection_table(templ,
    extended = TRUE, confirm.extended = FALSE,
    path = tempdir()
  )

  # fourier spectrogram
  (tc_fr &lt;- template_correlator(templates = templ, path = tempdir(), type = "fourier"))

  # mel auditory spectrograms
  (tc_ma &lt;- template_correlator(templates = templ, path = tempdir(), type = "mel-auditory"))

  # mfcc spectrograms
  (tc_mfcc &lt;- template_correlator(templates = templ, path = tempdir(), type = "mfcc"))

  # similar results (but no exactly the same) are found with the 3 methods
  # these are the correlation of the correlation vectors
  # fourier vs mel-auditory
  cor(
    tc_fr$`lbh2.wav-4/lbh2.wav`$correlation.scores,
    tc_ma$`lbh2.wav-4/lbh2.wav`$correlation.scores
  )

  # fourier vs mfcc
  cor(
    tc_fr$`lbh2.wav-4/lbh2.wav`$correlation.scores,
    tc_mfcc$`lbh2.wav-4/lbh2.wav`$correlation.scores
  )

  # mel-auditory vs mfcc
  cor(
    tc_ma$`lbh2.wav-4/lbh2.wav`$correlation.scores,
    tc_mfcc$`lbh2.wav-4/lbh2.wav`$correlation.scores
  )

  # using an extended selection table
  templ_est &lt;- warbleR::selection_table(templ,
    extended = TRUE, confirm.extended = FALSE,
    path = tempdir()
  )

  tc_fr_est &lt;- template_correlator(templates = templ_est, path = tempdir(), type = "fourier")

  # produces the same result as templates in a regular data frame
  cor(
    tc_fr$`lbh2.wav-4/lbh2.wav`$correlation.scores,
    tc_fr_est$`lbh2.wav_4-1/lbh2.wav`$correlation.scores
  )
}
</code></pre>

<hr>
<h2 id='template_detector'>Acoustic template detection from time-frequency cross-correlations</h2><span id='topic+template_detector'></span>

<h3>Description</h3>

<p><code>template_detector</code> find sound event occurrences in cross-correlation vectors from <code><a href="#topic+template_correlator">template_correlator</a></code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>template_detector(template.correlations, cores = 1, threshold, pb = TRUE,
 verbose = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="template_detector_+3A_template.correlations">template.correlations</code></td>
<td>
<p>object of class 'template_correlations' generated by <code><a href="#topic+template_correlator">template_correlator</a></code> containing the correlation score vectors.</p>
</td></tr>
<tr><td><code id="template_detector_+3A_cores">cores</code></td>
<td>
<p>Numeric. Controls whether parallel computing is applied.
It specifies the number of cores to be used. Default is 1 (i.e. no parallel computing).</p>
</td></tr>
<tr><td><code id="template_detector_+3A_threshold">threshold</code></td>
<td>
<p>Numeric vector of length 1 with a value between 0 and 1 specifying the correlation threshold for detecting sound event occurrences (i.e. correlation peaks). Must be supplied. Correlation scores are forced to between 0 and 1 (by converting negative scores to 0). 0 and 1 represent the lowest and highest similarity to the template respectively.</p>
</td></tr>
<tr><td><code id="template_detector_+3A_pb">pb</code></td>
<td>
<p>Logical argument to control progress bar. Default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="template_detector_+3A_verbose">verbose</code></td>
<td>
<p>Logical argument to control if some summary messages are printed to the console.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function infers sound events occurrences from cross-correlation scores along sound files. Correlation scores must be generated first using <code><a href="#topic+template_correlator">template_correlator</a></code>. The output is a data frame (or selection table if sound files are still found in the original path supplied to <code><a href="#topic+template_correlator">template_correlator</a></code>, using the warbleR package's format, see <code><a href="warbleR.html#topic+selection_table">selection_table</a></code>) containing the start and end of the detected sound events as well as the cross-correlation score ('scores' column) for each detection. <strong>Note that the detected sounds are assumed to have the same duration as the template, so their start and end correspond to the correlation peak position +/- half the template duration</strong>.
</p>


<h3>Value</h3>

<p>The function returns a 'selection_table' (warbleR package's formats, see <code><a href="warbleR.html#topic+selection_table">selection_table</a></code>) or data frame (if sound files can't be found) with the start and end and correlation score for the
detected sound events.
</p>


<h3>Author(s)</h3>

<p>Marcelo Araya-Salas <a href="mailto:marcelo.araya@ucr.ac.cr">marcelo.araya@ucr.ac.cr</a>)
</p>


<h3>References</h3>

<p>Araya-Salas, M., Smith-Vidaurre, G., Chaverri, G., Brenes, J. C., Chirino, F., Elizondo-Calvo, J., &amp; Rico-Guevara, A. 2022. ohun: an R package for diagnosing and optimizing automatic sound event detection. BioRxiv, 2022.12.13.520253. https://doi.org/10.1101/2022.12.13.520253
</p>


<h3>See Also</h3>

<p><code><a href="#topic+energy_detector">energy_detector</a></code>, <code><a href="#topic+template_correlator">template_correlator</a></code>, <code><a href="#topic+optimize_template_detector">optimize_template_detector</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>{
  # load example data
  data("lbh1", "lbh2", "lbh_reference")

  # save sound files
  tuneR::writeWave(lbh1, file.path(tempdir(), "lbh1.wav"))
  tuneR::writeWave(lbh2, file.path(tempdir(), "lbh2.wav"))

  # template for the first sound file in 'lbh_reference'
  templ1 &lt;- lbh_reference[1, ]

  # generate template correlations
  tc &lt;- template_correlator(templates = templ1, path = tempdir(), files = "lbh1.wav")

  # template detection
  td &lt;- template_detector(template.correlations = tc, threshold = 0.4)

  # diagnose detection
  diagnose_detection(
    reference =
      lbh_reference[lbh_reference$sound.files == "lbh1.wav", ],
    detection = td
  )

  # template for the second and third sound file in 'lbh_reference'
  # which have similar song types
  templ2 &lt;- lbh_reference[4, ]

  # generate template correlations
  tc &lt;- template_correlator(
    templates = templ2, path = tempdir(),
    files = c("lbh1.wav", "lbh2.wav")
  )

  # template detection
  td &lt;- template_detector(template.correlations = tc, threshold = 0.3)

  # diagnose detection
  diagnose_detection(reference = lbh_reference, detection = td)
}
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
