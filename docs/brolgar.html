<!DOCTYPE html><html><head><title>Help for package brolgar</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {brolgar}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#brolgar-package'><p>brolgar: Browse Over Longitudinal Data Graphically and Analytically in R</p></a></li>
<li><a href='#+25+26gt+3B+25'><p>Pipe operator</p></a></li>
<li><a href='#add_n_obs'><p>Add the number of observations for each key in a <code>tsibble</code></p></a></li>
<li><a href='#b_min'><p>Brolgar summaries (b_summaries)</p></a></li>
<li><a href='#brolgar-features'><p>Calculate features of a <code>tsibble</code> object in conjunction with <code>features()</code></p></a></li>
<li><a href='#facet_sample'><p>Facet data into groups to facilitate exploration</p></a></li>
<li><a href='#facet_strata'><p>Facet data into groups to facilitate exploration</p></a></li>
<li><a href='#heights'><p>World Height Data</p></a></li>
<li><a href='#index_summary'><p>Index summaries</p></a></li>
<li><a href='#key_slope'><p>Fit linear model for each key</p></a></li>
<li><a href='#keys_near'><p>Return keys nearest to a given statistics or summary.</p></a></li>
<li><a href='#keys_near.data.frame'><p>Return keys nearest to a given statistics or summary.</p></a></li>
<li><a href='#keys_near.tbl_ts'><p>Return keys nearest to a given statistics or summary.</p></a></li>
<li><a href='#l_funs'><p>A named list of the five number summary</p></a></li>
<li><a href='#monotonic'><p>Are values monotonic? Always increasing, decreasing, or unvarying?</p></a></li>
<li><a href='#n_obs'><p>Return the number of observations</p></a></li>
<li><a href='#near_between'><p>Return x percent to y percent of values</p></a></li>
<li><a href='#near_middle'><p>Return the middle x percent of values</p></a></li>
<li><a href='#near_quantile'><p>Which values are nearest to any given quantiles</p></a></li>
<li><a href='#nearests'><p>Is x nearest to y?</p></a></li>
<li><a href='#pisa'><p>Student data from 2000-2018 PISA OECD data</p></a></li>
<li><a href='#reexports'><p>Objects exported from other packages</p></a></li>
<li><a href='#sample-n-frac-keys'><p>Sample a number or fraction of keys to explore</p></a></li>
<li><a href='#stratify_keys'><p>Stratify the keys into groups to facilitate exploration</p></a></li>
<li><a href='#wages'><p>Wages data from National Longitudinal Survey of Youth (NLSY)</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Title:</td>
<td>Browse Over Longitudinal Data Graphically and Analytically in R</td>
</tr>
<tr>
<td>Version:</td>
<td>1.0.1</td>
</tr>
<tr>
<td>Description:</td>
<td>Provides a framework of tools to summarise, visualise, and explore 
  longitudinal data. It builds upon the tidy time series data frames used in the
  'tsibble' package, and is designed to integrate within the 'tidyverse', and
  'tidyverts' (for time series) ecosystems. The methods implemented include 
  calculating features for understanding longitudinal data, including 
  calculating summary statistics such as quantiles, medians, and numeric ranges,
  sampling individual series, identifying individual series representative of a 
  group, and extending the facet system  in 'ggplot2' to facilitate exploration of samples of data. These methods are
  fully described in the paper "brolgar: An R package to Browse Over 
  Longitudinal Data Graphically and Analytically in R", Nicholas Tierney, 
  Dianne Cook, Tania Prvan (2020) &lt;<a href="https://doi.org/10.32614%2FRJ-2022-023">doi:10.32614/RJ-2022-023</a>&gt;.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/njtierney/brolgar">https://github.com/njtierney/brolgar</a>,
<a href="https://brolgar.njtierney.com/">https://brolgar.njtierney.com/</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/njtierney/brolgar/issues">https://github.com/njtierney/brolgar/issues</a></td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>dplyr (&ge; 0.8.3), fabletools, ggplot2 (&ge; 3.2.0), glue (&ge;
1.3.1), magrittr (&ge; 1.5), purrr (&ge; 0.3.2), rlang (&ge; 0.4.0),
stats, tibble (&ge; 2.1.3), tidyr (&ge; 0.8.3), tsibble (&ge; 0.8.2),
vctrs</td>
</tr>
<tr>
<td>Suggests:</td>
<td>gapminder, gghighlight (&ge; 0.1.0), knitr (&ge; 1.23), Matrix
(&ge; 1.6-5), lme4, modelr, rmarkdown (&ge; 1.14), spelling (&ge;
2.1), testthat (&ge; 3.0.0), tsibbledata, vdiffr (&ge; 0.3.1)</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Language:</td>
<td>en-US</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.1</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-05-10 07:57:20 UTC; nick</td>
</tr>
<tr>
<td>Author:</td>
<td>Nicholas Tierney <a href="https://orcid.org/0000-0003-1460-8722"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cre],
  Di Cook <a href="https://orcid.org/0000-0002-3813-7155"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut],
  Tania Prvan [aut],
  Stuart Lee [ctb],
  Earo Wang [ctb]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Nicholas Tierney &lt;nicholas.tierney@gmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-05-10 14:50:34 UTC</td>
</tr>
</table>
<hr>
<h2 id='brolgar-package'>brolgar: Browse Over Longitudinal Data Graphically and Analytically in R</h2><span id='topic+brolgar'></span><span id='topic+brolgar-package'></span>

<h3>Description</h3>

<p>Provides a framework of tools to summarise, visualise, and explore longitudinal data. It builds upon the tidy time series data frames used in the 'tsibble' package, and is designed to integrate within the 'tidyverse', and 'tidyverts' (for time series) ecosystems. The methods implemented include calculating features for understanding longitudinal data, including calculating summary statistics such as quantiles, medians, and numeric ranges, sampling individual series, identifying individual series representative of a group, and extending the facet system in 'ggplot2' to facilitate exploration of samples of data. These methods are fully described in the paper &quot;brolgar: An R package to Browse Over Longitudinal Data Graphically and Analytically in R&quot;, Nicholas Tierney, Dianne Cook, Tania Prvan (2020) <a href="https://arxiv.org/abs/2012.01619">arXiv:2012.01619</a>.
</p>


<h3>Details</h3>

<p><code>brolgar</code> stands for: <strong>BR</strong>owse over <strong>L</strong>ongitudinal data <strong>G</strong>raphically
and <strong>A</strong>nalytically in <strong>R</strong>.
</p>


<h3>Author(s)</h3>

<p><strong>Maintainer</strong>: Nicholas Tierney <a href="mailto:nicholas.tierney@gmail.com">nicholas.tierney@gmail.com</a> (<a href="https://orcid.org/0000-0003-1460-8722">ORCID</a>)
</p>
<p>Authors:
</p>

<ul>
<li><p> Di Cook <a href="mailto:dicook@monash.edu">dicook@monash.edu</a> (<a href="https://orcid.org/0000-0002-3813-7155">ORCID</a>)
</p>
</li>
<li><p> Tania Prvan <a href="mailto:tania.prvan@mq.edu.au">tania.prvan@mq.edu.au</a>
</p>
</li></ul>

<p>Other contributors:
</p>

<ul>
<li><p> Stuart Lee [contributor]
</p>
</li>
<li><p> Earo Wang [contributor]
</p>
</li></ul>



<h3>See Also</h3>

<p>Useful links:
</p>

<ul>
<li> <p><a href="https://github.com/njtierney/brolgar">https://github.com/njtierney/brolgar</a>
</p>
</li>
<li> <p><a href="https://brolgar.njtierney.com/">https://brolgar.njtierney.com/</a>
</p>
</li>
<li><p> Report bugs at <a href="https://github.com/njtierney/brolgar/issues">https://github.com/njtierney/brolgar/issues</a>
</p>
</li></ul>


<hr>
<h2 id='+25+26gt+3B+25'>Pipe operator</h2><span id='topic++25+3E+25'></span>

<h3>Description</h3>

<p>See <code>magrittr::<a href="magrittr.html#topic++25+3E+25">%&gt;%</a></code> for details.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lhs %&gt;% rhs
</code></pre>

<hr>
<h2 id='add_n_obs'>Add the number of observations for each key in a <code>tsibble</code></h2><span id='topic+add_n_obs'></span>

<h3>Description</h3>

<p>Here, we are not counting the number of rows in the dataset, but rather
we are counting the number observations for each keys in the data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>add_n_obs(.data, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="add_n_obs_+3A_.data">.data</code></td>
<td>
<p>tsibble</p>
</td></tr>
<tr><td><code id="add_n_obs_+3A_...">...</code></td>
<td>
<p>extra arguments</p>
</td></tr>
</table>


<h3>Value</h3>

<p>tsibble with <code>n_obs</code>, the number of observations per key added.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(dplyr)
# you can explore the data to see those cases that have exactly two 
 # observations:
heights %&gt;% 
  add_n_obs() %&gt;% 
  filter(n_obs == 2)
</code></pre>

<hr>
<h2 id='b_min'>Brolgar summaries (b_summaries)</h2><span id='topic+b_min'></span><span id='topic+b_summaries'></span><span id='topic+b_max'></span><span id='topic+b_median'></span><span id='topic+b_mean'></span><span id='topic+b_q25'></span><span id='topic+b_q75'></span><span id='topic+b_range'></span><span id='topic+b_range_diff'></span><span id='topic+b_sd'></span><span id='topic+b_var'></span><span id='topic+b_mad'></span><span id='topic+b_iqr'></span><span id='topic+b_diff_var'></span><span id='topic+b_diff_sd'></span><span id='topic+b_diff_mean'></span><span id='topic+b_diff_median'></span><span id='topic+b_diff_q25'></span><span id='topic+b_diff_q75'></span><span id='topic+b_diff_max'></span><span id='topic+b_diff_min'></span><span id='topic+b_diff_iqr'></span>

<h3>Description</h3>

<p>Customised summaries of vectors with appropriate defaults for longitudinal
data. The functions are prefixed with <code>b_</code> to assist with autocomplete.
It uses <code>na.rm = TRUE</code> for all, and for calculations
involving quantiles, <code>type = 8</code> and <code>names = FALSE</code>. Summaries include:
* b_min: The minimum
* b_max: The maximum
* b_median: The median
* b_mean: The mean
* b_q25: The 25th quantile
* b_q75: The 75th quantile
* b_range: The range
* b_range_diff: difference in range (max - min)
* b_sd: The standard deviation
* b_var: The variance
* b_mad: The mean absolute deviation
* b_iqr: The Inter-quartile range
* b_diff_var: The variance diff()
* b_diff_sd: The standard deviation of diff()
* b_diff_mean: The mean of diff()
* b_diff_median: The median of diff()
* b_diff_q25: The q25 of diff()
* b_diff_q75: The q75 of diff()
</p>


<h3>Usage</h3>

<pre><code class='language-R'>b_min(x, ...)

b_max(x, ...)

b_median(x, ...)

b_mean(x, ...)

b_q25(x, ...)

b_q75(x, ...)

b_range(x, ...)

b_range_diff(x, ...)

b_sd(x, ...)

b_var(x, ...)

b_mad(x, ...)

b_iqr(x, ...)

b_diff_var(x, ...)

b_diff_sd(x, ...)

b_diff_mean(x, ...)

b_diff_median(x, ...)

b_diff_q25(x, ...)

b_diff_q75(x, ...)

b_diff_max(x, ...)

b_diff_min(x, ...)

b_diff_iqr(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="b_min_+3A_x">x</code></td>
<td>
<p>a vector</p>
</td></tr>
<tr><td><code id="b_min_+3A_...">...</code></td>
<td>
<p>other arguments to pass</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>
x &lt;- c(1:5, NA, 5:1)
min(x)
b_min(x)
max(x)
b_max(x)
median(x)
b_median(x)
mean(x)
b_mean(x)
range(x)
b_range(x)
var(x)
b_var(x)
sd(x)
b_sd(x)

</code></pre>

<hr>
<h2 id='brolgar-features'>Calculate features of a <code>tsibble</code> object in conjunction with <code><a href="#topic+features">features()</a></code></h2><span id='topic+brolgar-features'></span><span id='topic+feat_three_num'></span><span id='topic+feat_five_num'></span><span id='topic+feat_ranges'></span><span id='topic+feat_spread'></span><span id='topic+feat_monotonic'></span><span id='topic+feat_brolgar'></span><span id='topic+feat_diff_summary'></span>

<h3>Description</h3>

<p>You can calculate a series of summary statistics (features) of a given
variable for a dataset. For example, a three number summary, the minimum,
median, and maximum, can be calculated for a given variable. This is
designed to work with the <code><a href="#topic+features">features()</a></code> function shown in the examples.
Other available features in <code>brolgar</code> include:
</p>

<ul>
<li> <p><code><a href="#topic+feat_three_num">feat_three_num()</a></code> - minimum, median, maximum
</p>
</li>
<li> <p><code><a href="#topic+feat_five_num">feat_five_num()</a></code> - minimum, q25, median, q75, maximum.
</p>
</li>
<li> <p><code><a href="#topic+feat_ranges">feat_ranges()</a></code> - min, max, range difference, interquartile range.
</p>
</li>
<li> <p><code><a href="#topic+feat_spread">feat_spread()</a></code>  - variance, standard deviation, median absolute distance,
and interquartile range
</p>
</li>
<li> <p><code><a href="#topic+feat_monotonic">feat_monotonic()</a></code> - is it always increasing, decreasing, or unvarying?
</p>
</li>
<li> <p><code><a href="#topic+feat_diff_summary">feat_diff_summary()</a></code> - the summary statistics of the differences
amongst a value, including the five number summary, as well as the
standard deviation and variance. Returns NA if there is only one
observation, as we can't take the difference of one observation, and a
difference of 0 in these cases would be misleading.
</p>
</li>
<li> <p><code><a href="#topic+feat_brolgar">feat_brolgar()</a></code>  all features in brolgar.
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>feat_three_num(x, ...)

feat_five_num(x, ...)

feat_ranges(x, ...)

feat_spread(x, ...)

feat_monotonic(x, ...)

feat_brolgar(x, ...)

feat_diff_summary(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="brolgar-features_+3A_x">x</code></td>
<td>
<p>A vector to extract features from.</p>
</td></tr>
<tr><td><code id="brolgar-features_+3A_...">...</code></td>
<td>
<p>Further arguments passed to other functions.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>
# You can use any of the features `feat_*` in conjunction with `features` 
# like so:
heights %&gt;%
  features(height_cm, # variable you want to explore
           feat_three_num) # the feature summarisation you want to perform
</code></pre>

<hr>
<h2 id='facet_sample'>Facet data into groups to facilitate exploration</h2><span id='topic+facet_sample'></span>

<h3>Description</h3>

<p>This function requires a <code>tbl_ts</code> object, which can be created with
<code>tsibble::as_tsibble()</code>. Under the hood, <code>facet_strata</code> is powered by
<code><a href="#topic+stratify_keys">stratify_keys()</a></code> and <code><a href="#topic+sample_n_keys">sample_n_keys()</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>facet_sample(
  n_per_facet = 3,
  n_facets = 12,
  nrow = NULL,
  ncol = NULL,
  scales = "fixed",
  shrink = TRUE,
  strip.position = "top"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="facet_sample_+3A_n_per_facet">n_per_facet</code></td>
<td>
<p>Number of keys per facet you want to plot. Default is 3.</p>
</td></tr>
<tr><td><code id="facet_sample_+3A_n_facets">n_facets</code></td>
<td>
<p>Number of facets to create. Default is 12</p>
</td></tr>
<tr><td><code id="facet_sample_+3A_nrow">nrow</code>, <code id="facet_sample_+3A_ncol">ncol</code></td>
<td>
<p>Number of rows and columns.</p>
</td></tr>
<tr><td><code id="facet_sample_+3A_scales">scales</code></td>
<td>
<p>Should scales be fixed (<code>"fixed"</code>, the default),
free (<code>"free"</code>), or free in one dimension (<code>"free_x"</code>,
<code>"free_y"</code>)?</p>
</td></tr>
<tr><td><code id="facet_sample_+3A_shrink">shrink</code></td>
<td>
<p>If <code>TRUE</code>, will shrink scales to fit output of
statistics, not raw data. If <code>FALSE</code>, will be range of raw data
before statistical summary.</p>
</td></tr>
<tr><td><code id="facet_sample_+3A_strip.position">strip.position</code></td>
<td>
<p>By default, the labels are displayed on the top of
the plot. Using <code>strip.position</code> it is possible to place the labels on
either of the four sides by setting <code>strip.position = c("top",
  "bottom", "left", "right")</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>a ggplot object
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(ggplot2)
ggplot(heights,
aes(x = year,
    y = height_cm,
    group = country)) +
  geom_line() +
  facet_sample()

ggplot(heights,
       aes(x = year,
           y = height_cm,
           group = country)) +
  geom_line() +
  facet_sample(n_per_facet = 1,
               n_facets = 12)
</code></pre>

<hr>
<h2 id='facet_strata'>Facet data into groups to facilitate exploration</h2><span id='topic+facet_strata'></span>

<h3>Description</h3>

<p>This function requires a <code>tbl_ts</code> object, which can be created with
<code>tsibble::as_tsibble()</code>. Under the hood, <code>facet_strata</code> is powered by
<code><a href="#topic+stratify_keys">stratify_keys()</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>facet_strata(
  n_strata = 12,
  along = NULL,
  fun = mean,
  nrow = NULL,
  ncol = NULL,
  scales = "fixed",
  shrink = TRUE,
  strip.position = "top"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="facet_strata_+3A_n_strata">n_strata</code></td>
<td>
<p>number of groups to create</p>
</td></tr>
<tr><td><code id="facet_strata_+3A_along">along</code></td>
<td>
<p>variable to stratify along. This groups by each <code>key</code> and then
takes a summary statistic (by default, the mean). It then arranges by the
mean value for each <code>key</code> and assigns the <code>n_strata</code> groups.</p>
</td></tr>
<tr><td><code id="facet_strata_+3A_fun">fun</code></td>
<td>
<p>summary function. Default is mean.</p>
</td></tr>
<tr><td><code id="facet_strata_+3A_nrow">nrow</code>, <code id="facet_strata_+3A_ncol">ncol</code></td>
<td>
<p>Number of rows and columns.</p>
</td></tr>
<tr><td><code id="facet_strata_+3A_scales">scales</code></td>
<td>
<p>Should scales be fixed (<code>"fixed"</code>, the default),
free (<code>"free"</code>), or free in one dimension (<code>"free_x"</code>,
<code>"free_y"</code>)?</p>
</td></tr>
<tr><td><code id="facet_strata_+3A_shrink">shrink</code></td>
<td>
<p>If <code>TRUE</code>, will shrink scales to fit output of
statistics, not raw data. If <code>FALSE</code>, will be range of raw data
before statistical summary.</p>
</td></tr>
<tr><td><code id="facet_strata_+3A_strip.position">strip.position</code></td>
<td>
<p>By default, the labels are displayed on the top of
the plot. Using <code>strip.position</code> it is possible to place the labels on
either of the four sides by setting <code>strip.position = c("top",
  "bottom", "left", "right")</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>a ggplot object
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(ggplot2)
ggplot(heights,
       aes(x = year,
           y = height_cm,
           group = country)) +
  geom_line() +
  facet_strata()
  

ggplot(heights,
       aes(x = year,
           y = height_cm,
           group = country)) +
  geom_line() +
  facet_wrap(~continent)

ggplot(heights,
       aes(x = year,
           y = height_cm,
           group = country)) +
  geom_line() +
  facet_strata(along = year)


library(dplyr)
heights %&gt;%
  key_slope(height_cm ~ year) %&gt;%
  right_join(heights, ., by = "country") %&gt;%
  ggplot(aes(x = year,
             y = height_cm)) +
  geom_line(aes(group = country)) +
  geom_smooth(method = "lm") + 
  facet_strata(along = .slope_year)

</code></pre>

<hr>
<h2 id='heights'>World Height Data</h2><span id='topic+heights'></span>

<h3>Description</h3>

<p>Average male heights in 144 countries from 1810-1989, with a
smaller number of countries from 1500-1800. Data has been filtered to
only include countries with more than one observation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>heights
</code></pre>


<h3>Format</h3>

<p>An object of class <code>tbl_ts</code> (inherits from <code>tbl_df</code>, <code>tbl</code>, <code>data.frame</code>) with 1490 rows and 4 columns.
</p>


<h3>Details</h3>

<p><code>heights</code> is stored as a time series <code>tsibble</code> object. It contains
the variables:
</p>

<ul>
<li><p> country: The Country. This forms the identifying <code>key</code>.
</p>
</li>
<li><p> year: Year. This forms the time <code>index</code>.
</p>
</li>
<li><p> height_cm: Average male height in centimeters.
</p>
</li>
<li><p> continent: continent extracted from country name using <code>countrycode</code>
package (https://joss.theoj.org/papers/10.21105/joss.00848).
</p>
</li></ul>

<p>For more information, see the article: &quot;Why are you tall while others are
short? Agricultural production and other proximate determinants of global
heights&quot;,  Joerg Baten and Matthias Blum, European Review of Economic
History 18 (2014), 144–165. Data available from
<a href="https://datasets.iisg.amsterdam/dataset.xhtml?persistentId=hdl:10622/IAEKLA">https://datasets.iisg.amsterdam/dataset.xhtml?persistentId=hdl:10622/IAEKLA</a>, accessed via the Clio Infra website.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># show the data
heights

# show the spaghetti plot (ugh!)
library(ggplot2)
ggplot(heights, 
       aes(x = year, 
           y = height_cm, 
           group = country)) + 
    geom_line()
    
# Explore all samples with `facet_strata()`
ggplot(heights,
       aes(x = year,
           y = height_cm,
           group = country)) +
  geom_line() +
  facet_strata()

# Explore the heights over each continent
ggplot(heights,
       aes(x = year,
           y = height_cm,
           group = country)) +
  geom_line() +
  facet_wrap(~continent)
  
# explore the five number summary of height_cm with `features`
heights %&gt;% 
  features(height_cm, feat_five_num)
</code></pre>

<hr>
<h2 id='index_summary'>Index summaries</h2><span id='topic+index_summary'></span><span id='topic+index_regular'></span><span id='topic+index_regular.tbl_ts'></span><span id='topic+index_regular.data.frame'></span><span id='topic+index_summary.tbl_ts'></span><span id='topic+index_summary.data.frame'></span>

<h3>Description</h3>

<p>These functions check if the index is regular (<code>index_regular()</code>), and
summarise the index variable (<code>index_summary()</code>). This can be useful
to check your index variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>index_regular(.data, ...)

## S3 method for class 'tbl_ts'
index_regular(.data, ...)

## S3 method for class 'data.frame'
index_regular(.data, index, ...)

index_summary(.data, ...)

## S3 method for class 'tbl_ts'
index_summary(.data, ...)

## S3 method for class 'data.frame'
index_summary(.data, index, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="index_summary_+3A_.data">.data</code></td>
<td>
<p>data.frame or tsibble</p>
</td></tr>
<tr><td><code id="index_summary_+3A_...">...</code></td>
<td>
<p>extra arguments</p>
</td></tr>
<tr><td><code id="index_summary_+3A_index">index</code></td>
<td>
<p>the proposed index variable</p>
</td></tr>
</table>


<h3>Value</h3>

<p>logical  TRUE means it is regular, FALSE means not
</p>


<h3>Examples</h3>

<pre><code class='language-R'># a tsibble
index_regular(heights)

# some data frames
index_regular(pisa, year)
index_regular(airquality, Month)

# a tsibble
index_summary(heights)
# some data frames
index_summary(pisa, year)
index_summary(airquality, Month)
index_summary(airquality, Day)
</code></pre>

<hr>
<h2 id='key_slope'>Fit linear model for each key</h2><span id='topic+key_slope'></span><span id='topic+add_key_slope'></span><span id='topic+add_key_slope.default'></span>

<h3>Description</h3>

<p>Using <code>key_slope</code> you can fit a linear model to each key in the <code>tsibble</code>.
<code>add_key_slope</code> adds this slope information back to the data, and returns
the full dimension <code>tsibble</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>key_slope(.data, formula, ...)

add_key_slope(.data, formula)

add_key_slope.default(.data, formula)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="key_slope_+3A_.data">.data</code></td>
<td>
<p>tsibble</p>
</td></tr>
<tr><td><code id="key_slope_+3A_formula">formula</code></td>
<td>
<p>formula</p>
</td></tr>
<tr><td><code id="key_slope_+3A_...">...</code></td>
<td>
<p>extra arguments</p>
</td></tr>
</table>


<h3>Value</h3>

<p>tibble with coefficient information
</p>


<h3>Examples</h3>

<pre><code class='language-R'>key_slope(heights, height_cm ~ year)

</code></pre>

<hr>
<h2 id='keys_near'>Return keys nearest to a given statistics or summary.</h2><span id='topic+keys_near'></span><span id='topic+keys_near.default'></span>

<h3>Description</h3>

<p>Return keys nearest to a given statistics or summary.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>keys_near(.data, ...)

## Default S3 method:
keys_near(.data, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="keys_near_+3A_.data">.data</code></td>
<td>
<p>tsibble</p>
</td></tr>
<tr><td><code id="keys_near_+3A_...">...</code></td>
<td>
<p>extra arguments to pass to <code>mutate_at</code> when performing the summary
as given by <code>funs</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>data.frame containing keys closest to a given statistic.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>keys_near(heights, height_cm)

</code></pre>

<hr>
<h2 id='keys_near.data.frame'>Return keys nearest to a given statistics or summary.</h2><span id='topic+keys_near.data.frame'></span>

<h3>Description</h3>

<p>Return keys nearest to a given statistics or summary.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'data.frame'
keys_near(.data, key, var, top_n = 1, funs = l_five_num, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="keys_near.data.frame_+3A_.data">.data</code></td>
<td>
<p>data.frame</p>
</td></tr>
<tr><td><code id="keys_near.data.frame_+3A_key">key</code></td>
<td>
<p>key, which identifies unique observations.</p>
</td></tr>
<tr><td><code id="keys_near.data.frame_+3A_var">var</code></td>
<td>
<p>variable to summarise</p>
</td></tr>
<tr><td><code id="keys_near.data.frame_+3A_top_n">top_n</code></td>
<td>
<p>top number of closest observations to return - default is 1, which will also return ties.</p>
</td></tr>
<tr><td><code id="keys_near.data.frame_+3A_funs">funs</code></td>
<td>
<p>named list of functions to summarise by. Default is a given
list of the five number summary, <code>l_five_num</code>.</p>
</td></tr>
<tr><td><code id="keys_near.data.frame_+3A_...">...</code></td>
<td>
<p>extra arguments to pass to <code>mutate_at</code> when performing the summary
as given by <code>funs</code>.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>heights %&gt;%
  key_slope(height_cm ~ year) %&gt;%
  keys_near(key = country,
            var = .slope_year)
# Specify your own list of summaries
l_ranges &lt;- list(min = b_min,
                 range_diff = b_range_diff,
                 max = b_max,
                 iqr = b_iqr)

heights %&gt;%
  key_slope(formula = height_cm ~ year) %&gt;%
  keys_near(key = country,
              var = .slope_year,
              funs = l_ranges)
</code></pre>

<hr>
<h2 id='keys_near.tbl_ts'>Return keys nearest to a given statistics or summary.</h2><span id='topic+keys_near.tbl_ts'></span>

<h3>Description</h3>

<p>Return keys nearest to a given statistics or summary.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'tbl_ts'
keys_near(.data, var, top_n = 1, funs = l_five_num, stat_as_factor = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="keys_near.tbl_ts_+3A_.data">.data</code></td>
<td>
<p>tsibble</p>
</td></tr>
<tr><td><code id="keys_near.tbl_ts_+3A_var">var</code></td>
<td>
<p>variable to summarise</p>
</td></tr>
<tr><td><code id="keys_near.tbl_ts_+3A_top_n">top_n</code></td>
<td>
<p>top number of closest observations to return - default is 1, which will also return ties.</p>
</td></tr>
<tr><td><code id="keys_near.tbl_ts_+3A_funs">funs</code></td>
<td>
<p>named list of functions to summarise by. Default is a given
list of the five number summary, <code>l_five_num</code>.</p>
</td></tr>
<tr><td><code id="keys_near.tbl_ts_+3A_stat_as_factor">stat_as_factor</code></td>
<td>
<p>coerce <code>stat</code> variable into a factor? Default is TRUE.</p>
</td></tr>
<tr><td><code id="keys_near.tbl_ts_+3A_...">...</code></td>
<td>
<p>extra arguments to pass to <code>mutate_at</code> when performing the summary
as given by <code>funs</code>.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>               
# Return observations closest to the five number summary of height_cm
heights %&gt;%
  keys_near(var = height_cm)
               
</code></pre>

<hr>
<h2 id='l_funs'>A named list of the five number summary</h2><span id='topic+l_funs'></span><span id='topic+l_five_num'></span><span id='topic+l_three_num'></span>

<h3>Description</h3>

<p>Designed for use with the <code><a href="#topic+keys_near">keys_near()</a></code> function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>l_five_num

l_three_num
</code></pre>


<h3>Format</h3>

<p>An object of class <code>list</code> of length 5.
</p>
<p>An object of class <code>list</code> of length 3.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Specify your own list of summaries
l_ranges &lt;- list(min = b_min,
                 range_diff = b_range_diff,
                 max = b_max,
                 iqr = b_iqr)

heights %&gt;%
  key_slope(formula = height_cm ~ year) %&gt;%
  keys_near(key = country,
              var = .slope_year,
              funs = l_ranges)
</code></pre>

<hr>
<h2 id='monotonic'>Are values monotonic? Always increasing, decreasing, or unvarying?</h2><span id='topic+monotonic'></span><span id='topic+increasing'></span><span id='topic+decreasing'></span><span id='topic+unvarying'></span>

<h3>Description</h3>

<p>These provides three families of functions to tell you if values are always
increasing, decreasing, or unvarying, with the functions, <code>increasing()</code>,
<code>decreasing()</code>, or <code>unvarying()</code>. Under the hood it uses <code>diff</code> to find
differences, so if you like you can pass extra arguments to <code>diff</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>increasing(x, ...)

decreasing(x, ...)

unvarying(x, ...)

monotonic(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="monotonic_+3A_x">x</code></td>
<td>
<p>numeric or integer</p>
</td></tr>
<tr><td><code id="monotonic_+3A_...">...</code></td>
<td>
<p>extra arguments to pass to diff</p>
</td></tr>
</table>


<h3>Value</h3>

<p>logical TRUE or FALSE
</p>


<h3>Examples</h3>

<pre><code class='language-R'>vec_inc &lt;- c(1:10)
vec_dec&lt;- c(10:1)
vec_ran &lt;- c(sample(1:10))
vec_flat &lt;- rep.int(1,10)

increasing(vec_inc)
increasing(vec_dec)
increasing(vec_ran)
increasing(vec_flat)

decreasing(vec_inc)
decreasing(vec_dec)
decreasing(vec_ran)
decreasing(vec_flat)

unvarying(vec_inc)
unvarying(vec_dec)
unvarying(vec_ran)
unvarying(vec_flat)

library(ggplot2)
library(gghighlight)
library(dplyr)

heights_mono &lt;- heights %&gt;%
  features(height_cm, feat_monotonic) %&gt;%
  left_join(heights, by = "country")
  
  ggplot(heights_mono,
         aes(x = year,
             y = height_cm,
             group = country)) +
  geom_line() + 
  gghighlight(increase)

 ggplot(heights_mono,
        aes(x = year,
            y = height_cm,
             group = country)) +
  geom_line() + 
  gghighlight(decrease)

heights_mono %&gt;%
filter(monotonic) %&gt;%
  ggplot(aes(x = year,
             y = height_cm,
             group = country)) + 
  geom_line()
  
heights_mono %&gt;%
  filter(increase) %&gt;%
  ggplot(aes(x = year,
             y = height_cm,
             group = country)) + 
  geom_line()
  
</code></pre>

<hr>
<h2 id='n_obs'>Return the number of observations</h2><span id='topic+n_obs'></span>

<h3>Description</h3>

<p>Returns the number of observations of a vector or data.frame. It uses
<code>vctrs::vec_size()</code> under the hood.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>n_obs(x, names = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="n_obs_+3A_x">x</code></td>
<td>
<p>vector or data.frame</p>
</td></tr>
<tr><td><code id="n_obs_+3A_names">names</code></td>
<td>
<p>logical; If TRUE the result is a named vector named &quot;n_obs&quot;, else
it is just the number of observations.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>number of observations
</p>


<h3>Note</h3>

<p>You cannot use <code>n_obs</code> with <code>features</code> counting the key variable like
so - <code>features(heights, country, n_obs)</code>. Instead, use any other variable.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n_obs(iris)
n_obs(1:10)
add_n_obs(heights)
heights %&gt;%
  features(height_cm, n_obs) # can be any variable except id, the key.
</code></pre>

<hr>
<h2 id='near_between'>Return x percent to y percent of values</h2><span id='topic+near_between'></span>

<h3>Description</h3>

<p>Return x percent to y percent of values
</p>


<h3>Usage</h3>

<pre><code class='language-R'>near_between(x, from, to)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="near_between_+3A_x">x</code></td>
<td>
<p>numeric vector</p>
</td></tr>
<tr><td><code id="near_between_+3A_from">from</code></td>
<td>
<p>the lower bound of percentage</p>
</td></tr>
<tr><td><code id="near_between_+3A_to">to</code></td>
<td>
<p>the upper bound of percentage</p>
</td></tr>
</table>


<h3>Value</h3>

<p>logical vector
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- runif(20)

near_middle(x = x,
            middle = 0.5,
            within = 0.2)

library(dplyr)
heights %&gt;% features(height_cm, list(min = min)) %&gt;%
  filter(near_between(min, 0.1, 0.9))

near_quantile(x = x,
              probs = 0.5, 
              tol = 0.01)

near_quantile(x, c(0.25, 0.5, 0.75), 0.05)

heights %&gt;%
  features(height_cm, l_five_num) %&gt;%
  mutate_at(vars(min:max),
            .funs = near_quantile,
            0.5, 
            0.01) %&gt;%
  filter(min)

heights %&gt;%
  features(height_cm, list(min = min)) %&gt;%
  mutate(min_near_q3 = near_quantile(min, c(0.25, 0.5, 0.75), 0.01)) %&gt;%
  filter(min_near_q3)

heights %&gt;%
  features(height_cm, list(min = min)) %&gt;%
  filter(near_between(min, 0.1, 0.9))

heights %&gt;%
  features(height_cm, list(min = min)) %&gt;%
  filter(near_middle(min, 0.5, 0.1))
</code></pre>

<hr>
<h2 id='near_middle'>Return the middle x percent of values</h2><span id='topic+near_middle'></span>

<h3>Description</h3>

<p>Return the middle x percent of values
</p>


<h3>Usage</h3>

<pre><code class='language-R'>near_middle(x, middle, within)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="near_middle_+3A_x">x</code></td>
<td>
<p>numeric vector</p>
</td></tr>
<tr><td><code id="near_middle_+3A_middle">middle</code></td>
<td>
<p>percentage you want to center around</p>
</td></tr>
<tr><td><code id="near_middle_+3A_within">within</code></td>
<td>
<p>percentage around center</p>
</td></tr>
</table>


<h3>Value</h3>

<p>logical vector
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- runif(20)
near_middle(x = x,
            middle = 0.5,
            within = 0.2)
            
library(dplyr)
heights %&gt;% features(height_cm, list(min = min)) %&gt;%
  filter(near_middle(min, 0.5, 0.1))
            
</code></pre>

<hr>
<h2 id='near_quantile'>Which values are nearest to any given quantiles</h2><span id='topic+near_quantile'></span>

<h3>Description</h3>

<p>Which values are nearest to any given quantiles
</p>


<h3>Usage</h3>

<pre><code class='language-R'>near_quantile(x, probs, tol = 0.01)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="near_quantile_+3A_x">x</code></td>
<td>
<p>vector</p>
</td></tr>
<tr><td><code id="near_quantile_+3A_probs">probs</code></td>
<td>
<p>quantiles to calculate</p>
</td></tr>
<tr><td><code id="near_quantile_+3A_tol">tol</code></td>
<td>
<p>tolerance in terms of x that you will accept near to the
quantile. Default is 0.01.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>logical vector of TRUE/FALSE if number is close to a quantile
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- runif(20)
near_quantile(x, 0.5, 0.05)
near_quantile(x, c(0.25, 0.5, 0.75), 0.05)

library(dplyr)
heights %&gt;% 
  features(height_cm, list(min = min)) %&gt;% 
  mutate(min_near_median = near_quantile(min, 0.5, 0.01)) %&gt;%
  filter(min_near_median)
heights %&gt;% 
  features(height_cm, list(min = min)) %&gt;% 
  mutate(min_near_q3 = near_quantile(min, c(0.25, 0.5, 0.75), 0.01)) %&gt;%
  filter(min_near_q3)
</code></pre>

<hr>
<h2 id='nearests'>Is x nearest to y?</h2><span id='topic+nearests'></span><span id='topic+nearest_lgl'></span><span id='topic+nearest_qt_lgl'></span>

<h3>Description</h3>

<p>Returns TRUE if x is nearest to y.
There are two implementations. <code>nearest_lgl()</code> returns a logical vector
when an element of the first argument is nearest to an element of the
second argument. <code>nearest_qt_lgl()</code> is similar to <code>nearest_lgl()</code>, but
instead determines if an element of the first argument is nearest to
some value of the given quantile probabilities. See example for more
detail.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nearest_lgl(x, y)

nearest_qt_lgl(y, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="nearests_+3A_x">x</code></td>
<td>
<p>a numeric vector</p>
</td></tr>
<tr><td><code id="nearests_+3A_y">y</code></td>
<td>
<p>a numeric vector</p>
</td></tr>
<tr><td><code id="nearests_+3A_...">...</code></td>
<td>
<p>(if used) arguments to pass to <code>quantile()</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>logical vector of <code>length(y)</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
x &lt;- 1:10
y &lt;- 5:14
z &lt;- 16:25
a &lt;- -1:-5
b &lt;- -1

nearest_lgl(x, y)
nearest_lgl(y, x)

nearest_lgl(x, z)
nearest_lgl(z, x)

nearest_lgl(x, a)
nearest_lgl(a, x)

nearest_lgl(x, b)
nearest_lgl(b, x)

library(dplyr)
heights_near_min &lt;- heights %&gt;%
  filter(nearest_lgl(min(height_cm), height_cm))
  
heights_near_fivenum &lt;- heights %&gt;%
  filter(nearest_lgl(fivenum(height_cm), height_cm))
  
heights_near_qt_1 &lt;- heights %&gt;%
  filter(nearest_qt_lgl(height_cm, c(0.5)))
  
heights_near_qt_3 &lt;- heights %&gt;%
  filter(nearest_qt_lgl(height_cm, c(0.1, 0.5, 0.9)))

</code></pre>

<hr>
<h2 id='pisa'>Student data from 2000-2018 PISA OECD data</h2><span id='topic+pisa'></span>

<h3>Description</h3>

<p>A subset of PISA data, containing scores and other information
from the triennial testing of 15 year olds around
the globe. Original data available from
<a href="https://www.oecd.org/pisa/data/">https://www.oecd.org/pisa/data/</a>. Data derived from
<a href="https://github.com/kevinwang09/learningtower">https://github.com/kevinwang09/learningtower</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pisa
</code></pre>


<h3>Format</h3>

<p>A tibble of the following variables
</p>

<ul>
<li><p> year the year of measurement
</p>
</li>
<li><p> country the three letter country code. This data contains Australia,
New Zealand, and Indonesia. The full data from learningtower contains
99 countries.
</p>
</li>
<li><p> school_id The unique school identification number
</p>
</li>
<li><p> student_id The student identification number
</p>
</li>
<li><p> gender recorded gender - 1 female or 2 male or missing
</p>
</li>
<li><p> math Simulated score in mathematics
</p>
</li>
<li><p> read Simulated score in reading
</p>
</li>
<li><p> science Simulated score in science
</p>
</li>
<li><p> stu_wgt The final survey weight score for the student score
</p>
</li></ul>

<p>Understanding a bit more about the PISA data, the <code>school_id</code> and
<code>student_id</code> are not unique across time. This means the longitudinal element
is the country within a given year.
</p>
<p>We can cast <code>pisa</code> as a <code>tsibble</code>, but we need to aggregate the data to each
year and country. In doing so, it is important that we provide some summary
statistics of each of the scores - we want to include the mean, and minimum
and maximum of the math, reading, and science scores, so that we do not lose
the information of the individuals.
</p>
<p>The example code below does this, first grouping by year and country, then
calculating the weighted mean for math, reading, and science. This can be
done using the student weight variable <code>stu_wgt</code>, to get the survey weighted
mean. The minimum and maximum are then calculated.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>pisa

library(dplyr)
# Let's identify

#1.  The **key**, the individual, who would have repeated measurements. 
#2.  The **index**, the time component.
#3.  The **regularity** of the time interval (index). 

# Here it looks like the key is the student_id, which is nested within
# school_id #' and country,

# And the index is year, so we would write the following

as_tsibble(pisa, 
           key = country,
           index = year)

# We can assess the regularity of the year like so:

index_regular(pisa, year)
index_summary(pisa, year)

# We can now convert this into a `tsibble`:

pisa_ts &lt;- as_tsibble(pisa,
           key = country,
           index = year,
           regular = TRUE)

pisa_ts
pisa_ts_au_nz &lt;- pisa_ts %&gt;% filter(country %in% c("AUS", "NZL", "QAT"))

library(ggplot2)
ggplot(pisa_ts_au_nz, 
       aes(x = year, 
           y = math_mean,
           group = country,
           colour = country)) +
  geom_ribbon(aes(ymin = math_min, 
                  ymax = math_max), 
              fill = "grey70") +
  geom_line(size = 1) +
  lims(y = c(0, 1000)) +
  labs(y = "math") +
facet_wrap(~country)
</code></pre>

<hr>
<h2 id='reexports'>Objects exported from other packages</h2><span id='topic+reexports'></span><span id='topic+features'></span><span id='topic+features_at'></span><span id='topic+features_if'></span><span id='topic+features_all'></span><span id='topic+as_tsibble'></span><span id='topic+n_keys'></span>

<h3>Description</h3>

<p>These objects are imported from other packages. Follow the links
below to see their documentation.
</p>

<dl>
<dt>fabletools</dt><dd><p><code><a href="fabletools.html#topic+features">features</a></code>, <code><a href="fabletools.html#topic+features">features_all</a></code>, <code><a href="fabletools.html#topic+features">features_at</a></code>, <code><a href="fabletools.html#topic+features">features_if</a></code></p>
</dd>
<dt>tsibble</dt><dd><p><code><a href="tsibble.html#topic+as-tsibble">as_tsibble</a></code>, <code><a href="tsibble.html#topic+key-data">n_keys</a></code></p>
</dd>
</dl>

<hr>
<h2 id='sample-n-frac-keys'>Sample a number or fraction of keys to explore</h2><span id='topic+sample-n-frac-keys'></span><span id='topic+sample_n_keys'></span><span id='topic+sample_frac_keys'></span>

<h3>Description</h3>

<p>Sample a number or fraction of keys to explore
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sample_n_keys(.data, size)

sample_frac_keys(.data, size)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sample-n-frac-keys_+3A_.data">.data</code></td>
<td>
<p>tsibble object</p>
</td></tr>
<tr><td><code id="sample-n-frac-keys_+3A_size">size</code></td>
<td>
<p>The number or fraction of observations, depending on the
function used. In <code>sample_n_keys</code>, it is a number &gt; 0, and in
<code>sample_frac_keys</code> it is a fraction, between 0 and 1.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>tsibble with fewer observations of key
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(ggplot2)
sample_n_keys(heights,
             size = 10) %&gt;%
  ggplot(aes(x = year,
             y = height_cm,
             group = country)) + 
  geom_line()
library(ggplot2)
sample_frac_keys(wages,
                0.1) %&gt;%
  ggplot(aes(x = xp,
             y = unemploy_rate,
             group = id)) + 
  geom_line()
</code></pre>

<hr>
<h2 id='stratify_keys'>Stratify the keys into groups to facilitate exploration</h2><span id='topic+stratify_keys'></span>

<h3>Description</h3>

<p>To look at as much of the raw data as possible, it can be helpful to
stratify the data into groups for plotting. You can <code>stratify</code> the
<code>keys</code> using the <code>stratify_keys()</code> function, which adds the column,
<code>.strata</code>. This allows the user to create facetted plots showing a more
of the raw data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>stratify_keys(.data, n_strata, along = NULL, fun = mean, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="stratify_keys_+3A_.data">.data</code></td>
<td>
<p>data.frame to explore</p>
</td></tr>
<tr><td><code id="stratify_keys_+3A_n_strata">n_strata</code></td>
<td>
<p>number of groups to create</p>
</td></tr>
<tr><td><code id="stratify_keys_+3A_along">along</code></td>
<td>
<p>variable to stratify along. This groups by each <code>key</code> and then
takes a summary statistic (by default, the mean). It then arranges by the
mean value for each <code>key</code> and assigns the <code>n_strata</code> groups.</p>
</td></tr>
<tr><td><code id="stratify_keys_+3A_fun">fun</code></td>
<td>
<p>summary function. Default is mean.</p>
</td></tr>
<tr><td><code id="stratify_keys_+3A_...">...</code></td>
<td>
<p>extra arguments</p>
</td></tr>
</table>


<h3>Value</h3>

<p>data.frame with column, <code>.strata</code> containing <code>n_strata</code> groups
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(ggplot2)
library(brolgar)

heights %&gt;%
  sample_frac_keys(size = 0.1) %&gt;%
  stratify_keys(10) %&gt;%
 ggplot(aes(x = height_cm,
            y = year,
            group = country)) + 
 geom_line() + 
 facet_wrap(~.strata)
 
 # now facet along some feature
library(dplyr)
 heights %&gt;%
key_slope(height_cm ~ year) %&gt;%
  right_join(heights, ., by = "country") %&gt;%
  stratify_keys(n_strata = 12,
                along = .slope_year,
                fun = median) %&gt;%
  ggplot(aes(x = year,
             y = height_cm,
             group = country)) + 
  geom_line() + 
  facet_wrap(~.strata)


heights %&gt;%
  stratify_keys(n_strata = 12,
                along = height_cm) %&gt;%
  ggplot(aes(x = year,
             y = height_cm,
             group = country)) + 
  geom_line() + 
  facet_wrap(~.strata)
</code></pre>

<hr>
<h2 id='wages'>Wages data from National Longitudinal Survey of Youth (NLSY)</h2><span id='topic+wages'></span>

<h3>Description</h3>

<p>This data contains measurements on hourly wages by years in
the workforce, with education and race as covariates. The population
measured was male high-school dropouts, aged between 14 and 17 years
when first measured. <code>wages</code> is a time series <code>tsibble</code>.
It comes from J. D. Singer and J. B. Willett.
Applied Longitudinal Data Analysis.
Oxford University Press, Oxford, UK, 2003.
https://stats.idre.ucla.edu/stat/r/examples/alda/data/wages_pp.txt
</p>


<h3>Usage</h3>

<pre><code class='language-R'>wages
</code></pre>


<h3>Format</h3>

<p>A <code>tsibble</code> data frame with 6402 rows and 8 variables:
</p>

<dl>
<dt>id</dt><dd><p>1–888, for each subject. This forms the <code>key</code> of the data</p>
</dd>
<dt>ln_wages</dt><dd><p>natural log of wages, adjusted for inflation,
to 1990 dollars.</p>
</dd>
<dt>xp</dt><dd><p>Experience - the length of time in the workforce (in years).
This is treated as the time variable, with t0 for each subject starting
on their first day at work. The number of time points and values of time
points for each subject can differ. This forms the <code>index</code> of the data</p>
</dd>
<dt>ged</dt><dd><p>when/if a graduate equivalency diploma is obtained.</p>
</dd>
<dt>xp_since_ged</dt><dd><p>change in experience since getting a ged (if they get one)</p>
</dd>
<dt>black</dt><dd><p>categorical indicator of race = black.</p>
</dd>
<dt>hispanic</dt><dd><p>categorical indicator of race = hispanic.</p>
</dd>
<dt>high_grade</dt><dd><p>highest grade completed</p>
</dd>
<dt>unemploy_rate</dt><dd><p>unemployment rates in the local geographic region
at each measurement time</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'># show the data
wages
library(ggplot2)
# set seed so that the plots stay the same
set.seed(2019-7-15-1300)
# explore a sample of five individuals
wages %&gt;%
  sample_n_keys(size = 5) %&gt;%
  ggplot(aes(x = xp,
             y = ln_wages,
             group = id)) + 
  geom_line()

# Explore many samples with `facet_sample()`
  ggplot(wages, 
         aes(x = xp,
             y = ln_wages,
             group = id)) + 
  geom_line() + 
  facet_sample()

# explore the five number summary of ln_wages with `features`
wages %&gt;% 
  features(ln_wages, feat_five_num)
  
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
