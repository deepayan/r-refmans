<!DOCTYPE html><html lang="en"><head><title>Help for package grpreg</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {grpreg}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#grpreg-package'><p>grpreg: Regularization Paths for Regression Models with Grouped Covariates</p></a></li>
<li><a href='#AUC.cv.grpsurv'><p>Calculates AUC for cv.grpsurv objects</p></a></li>
<li><a href='#Birthwt'><p>Risk Factors Associated with Low Infant Birth Weight</p></a></li>
<li><a href='#birthwt.grpreg'><p>Risk Factors Associated with Low Infant Birth Weight</p></a></li>
<li><a href='#cv.grpreg'><p>Cross-validation for grpreg/grpsurv</p></a></li>
<li><a href='#expand_spline'><p>Expand feature matrix using basis splines</p></a></li>
<li><a href='#gBridge'><p>Fit a group bridge regression path</p></a></li>
<li><a href='#gen_nonlinear_data'><p>Generate nonlinear example data</p></a></li>
<li><a href='#grpreg'><p>Fit a group penalized regression path</p></a></li>
<li><a href='#grpsurv'><p>Fit an group penalized survival model</p></a></li>
<li><a href='#logLik.grpreg'><p>logLik method for grpreg</p></a></li>
<li><a href='#Lung'><p>VA lung cancer data set</p></a></li>
<li><a href='#plot_spline'><p>Plot spline curve for a fitted additive model</p></a></li>
<li><a href='#plot.cv.grpreg'><p>Plots the cross-validation curve from a <code>cv.grpreg</code> object</p></a></li>
<li><a href='#plot.grpreg'><p>Plot coefficients from a &quot;grpreg&quot; object</p></a></li>
<li><a href='#plot.grpsurv.func'><p>Plot survival curve for grpsurv model</p></a></li>
<li><a href='#predict.cv.grpreg'><p>Model predictions based on a fitted <code>grpreg</code> object</p></a></li>
<li><a href='#predict.grpsurv'><p>Model predictions for grpsurv objects</p></a></li>
<li><a href='#residuals.grpreg'><p>Extract residuals from a grpreg or grpsurv fit</p></a></li>
<li><a href='#select'><p>Select an value of lambda along a grpreg path</p></a></li>
<li><a href='#summary.cv.grpreg'><p>Summarizing inferences based on cross-validation</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Title:</td>
<td>Regularization Paths for Regression Models with Grouped
Covariates</td>
</tr>
<tr>
<td>Version:</td>
<td>3.5.0</td>
</tr>
<tr>
<td>Date:</td>
<td>2024-09-03</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.1.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>Matrix</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, rmarkdown, splines, survival, tinytest</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>Description:</td>
<td>Efficient algorithms for fitting the regularization path of linear
  regression, GLM, and Cox regression models with grouped penalties.  This
  includes group selection methods such as group lasso, group MCP, and
  group SCAD as well as bi-level selection methods such as the group
  exponential lasso, the composite MCP, and the group bridge.  For more
  information, see Breheny and Huang (2009) &lt;<a href="https://doi.org/10.4310%2Fsii.2009.v2.n3.a10">doi:10.4310/sii.2009.v2.n3.a10</a>&gt;,
  Huang, Breheny, and Ma (2012) &lt;<a href="https://doi.org/10.1214%2F12-sts392">doi:10.1214/12-sts392</a>&gt;, Breheny and Huang
  (2015) &lt;<a href="https://doi.org/10.1007%2Fs11222-013-9424-2">doi:10.1007/s11222-013-9424-2</a>&gt;, and Breheny (2015)
  &lt;<a href="https://doi.org/10.1111%2Fbiom.12300">doi:10.1111/biom.12300</a>&gt;, or visit the package homepage
  <a href="https://pbreheny.github.io/grpreg/">https://pbreheny.github.io/grpreg/</a>.</td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/pbreheny/grpreg/issues">https://github.com/pbreheny/grpreg/issues</a></td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://pbreheny.github.io/grpreg/">https://pbreheny.github.io/grpreg/</a>,
<a href="https://github.com/pbreheny/grpreg">https://github.com/pbreheny/grpreg</a></td>
</tr>
<tr>
<td>LazyData:</td>
<td>TRUE</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.2</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-09-03 15:37:26 UTC; pbreheny</td>
</tr>
<tr>
<td>Author:</td>
<td>Patrick Breheny <a href="https://orcid.org/0000-0002-0650-1119"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cre],
  Yaohui Zeng [ctb],
  Ryan Kurth [ctb]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Patrick Breheny &lt;patrick-breheny@uiowa.edu&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-09-03 17:00:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='grpreg-package'>grpreg: Regularization Paths for Regression Models with Grouped Covariates</h2><span id='topic+grpreg-package'></span>

<h3>Description</h3>

<p>Efficient algorithms for fitting the regularization path of linear regression, GLM, and Cox regression models with grouped penalties. This includes group selection methods such as group lasso, group MCP, and group SCAD as well as bi-level selection methods such as the group exponential lasso, the composite MCP, and the group bridge. For more information, see Breheny and Huang (2009) <a href="https://doi.org/10.4310/sii.2009.v2.n3.a10">doi:10.4310/sii.2009.v2.n3.a10</a>, Huang, Breheny, and Ma (2012) <a href="https://doi.org/10.1214/12-sts392">doi:10.1214/12-sts392</a>, Breheny and Huang (2015) <a href="https://doi.org/10.1007/s11222-013-9424-2">doi:10.1007/s11222-013-9424-2</a>, and Breheny (2015) <a href="https://doi.org/10.1111/biom.12300">doi:10.1111/biom.12300</a>, or visit the package homepage <a href="https://pbreheny.github.io/grpreg/">https://pbreheny.github.io/grpreg/</a>.
</p>


<h3>Author(s)</h3>

<p>Patrick Breheny
</p>


<h3>References</h3>


<ul>
<li><p> Yuan M and Lin Y. (2006) Model selection and estimation in regression
with grouped variables. <em>Journal of the Royal Statistical Society Series B</em>,
<strong>68</strong>: 49-67. <a href="https://doi.org/10.1111/j.1467-9868.2005.00532.x">doi:10.1111/j.1467-9868.2005.00532.x</a>
</p>
</li>
<li><p> Huang J, Ma S, Xie H, and Zhang C. (2009) A group bridge approach for
variable selection. <em>Biometrika</em>, <strong>96</strong>: 339-355. <a href="https://doi.org/10.1093/biomet/asp020">doi:10.1093/biomet/asp020</a>
</p>
</li>
<li><p> Breheny P and Huang J. (2009) Penalized methods for bi-level variable
selection. <em>Statistics and its interface</em>, <strong>2</strong>: 369-380.
<a href="https://doi.org/10.4310/sii.2009.v2.n3.a10">doi:10.4310/sii.2009.v2.n3.a10</a>
</p>
</li>
<li><p> Huang J, Breheny P, and Ma S. (2012). A selective review of group
selection in high dimensional models. <em>Statistical Science</em>, <strong>27</strong>: 481-499.
<a href="https://doi.org/10.1214/12-sts392">doi:10.1214/12-sts392</a>
</p>
</li>
<li><p> Breheny P and Huang J. (2015) Group descent algorithms for nonconvex
penalized linear and logistic regression models with grouped predictors.
<em>Statistics and Computing</em>, <strong>25</strong>: 173-187. <a href="https://doi.org/10.1007/s11222-013-9424-2">doi:10.1007/s11222-013-9424-2</a>
</p>
</li>
<li><p> Breheny P. (2015) The group exponential lasso for bi-level variable
selection. <em>Biometrics</em>, <strong>71</strong>: 731-740. <a href="https://doi.org/10.1111/biom.12300">doi:10.1111/biom.12300</a>
</p>
</li></ul>



<h3>See Also</h3>

<p>Useful links:
</p>

<ul>
<li> <p><a href="https://pbreheny.github.io/grpreg/">https://pbreheny.github.io/grpreg/</a>
</p>
</li>
<li> <p><a href="https://github.com/pbreheny/grpreg">https://github.com/pbreheny/grpreg</a>
</p>
</li>
<li><p> Report bugs at <a href="https://github.com/pbreheny/grpreg/issues">https://github.com/pbreheny/grpreg/issues</a>
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>vignette("getting-started", package="grpreg")
</code></pre>

<hr>
<h2 id='AUC.cv.grpsurv'>Calculates AUC for cv.grpsurv objects</h2><span id='topic+AUC.cv.grpsurv'></span><span id='topic+AUC'></span>

<h3>Description</h3>

<p>Calculates the cross-validated AUC (concordance) from a &quot;cv.grpsurv&quot; object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'cv.grpsurv'
AUC(obj, ...)

AUC(obj, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="AUC.cv.grpsurv_+3A_obj">obj</code></td>
<td>
<p>A <code>cv.grpsurv</code> object. You must run <code>cv.grpsurv()</code> with the option <code>returnY=TRUE</code> in order for <code>AUC</code> to work.</p>
</td></tr>
<tr><td><code id="AUC.cv.grpsurv_+3A_...">...</code></td>
<td>
<p>For S3 method compatibility.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The area under the curve (AUC), or equivalently, the concordance statistic
(C), is calculated according to the procedure described in van Houwelingen
and Putter (2011). The function calls <code>survival::concordancefit()</code>, except
cross-validated linear predictors are used to guard against overfitting.
Thus, the values returned by <code>AUC.cv.grpsurv()</code> will be lower than those you
would obtain with <code>concordancefit()</code> if you fit the full (unpenalized) model.
</p>


<h3>References</h3>

<p>van Houwelingen H, Putter H (2011). <em>Dynamic Prediction in Clinical Survival Analysis</em>. CRC Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cv.grpsurv">cv.grpsurv()</a></code>, <code><a href="survival.html#topic+survival-deprecated">survival::survConcordance()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(Lung)
X &lt;- Lung$X
y &lt;- Lung$y
group &lt;- Lung$group

cvfit &lt;- cv.grpsurv(X, y, group, returnY=TRUE)
head(AUC(cvfit))
ll &lt;- log(cvfit$fit$lambda)
plot(ll, AUC(cvfit), xlim=rev(range(ll)), lwd=3, type='l',
     xlab=expression(log(lambda)), ylab='AUC', las=1)
</code></pre>

<hr>
<h2 id='Birthwt'>Risk Factors Associated with Low Infant Birth Weight</h2><span id='topic+Birthwt'></span>

<h3>Description</h3>

<p>The <code>Birthwt</code> data contains 189 observations, 16 predictors, and an
outcome, birthweight, available both as a continuous measure and a binary
indicator for low birth weight.The data were collected at Baystate Medical
Center, Springfield, Mass during 1986. This data frame is a
reparameterization of the <code>birthwt</code> data frame from the <strong>MASS</strong> package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Birthwt
</code></pre>


<h3>Format</h3>

<p>The <code>Birthwt</code> object is a list containing four elements (<code>X</code>, <code>bwt</code>, <code>low</code>, and <code>group</code>):
</p>

<dl>
<dt>bwt</dt><dd><p>Birth weight in kilograms</p>
</dd>
<dt>low</dt><dd><p>Indicator of birth weight less than 2.5kg</p>
</dd>
<dt>group</dt><dd><p>Vector describing how the columns of X are grouped</p>
</dd>
<dt>X</dt><dd><p>A matrix with 189 observations (rows) and 16 predictor variables (columns).</p>
</dd>
</dl>

<p>The matrix <code>X</code> contains the following columns:
</p>

<dl>
<dt>age1,age2,age3</dt><dd><p>Orthogonal polynomials of first, second, and third degree representing mother's age in years</p>
</dd>
<dt>lwt1,lwt2,lwt3</dt><dd><p>Orthogonal polynomials of first, second, and third degree representing mother's weight in pounds at last menstrual period</p>
</dd>
<dt>white,black</dt><dd><p>Indicator functions for mother's race; &quot;other&quot; is reference group</p>
</dd>
<dt>smoke</dt><dd><p>Smoking status during pregnancy</p>
</dd>
<dt>ptl1,ptl2m</dt><dd><p>Indicator functions for one or for two or more previous premature labors, respectively. No previous premature labors is the reference category.</p>
</dd>
<dt>ht</dt><dd><p>History of hypertension</p>
</dd>
<dt>ui</dt><dd><p>Presence of uterine irritability</p>
</dd>
<dt>ftv1,ftv2,ftv3m</dt><dd><p>Indicator functions for one, for two, or for three or more physician visits during the first trimester, respectively. No visits is the reference category.</p>
</dd>
</dl>



<h3>Source</h3>

<p><a href="https://cran.r-project.org/package=MASS">https://cran.r-project.org/package=MASS</a>
</p>


<h3>References</h3>


<ul>
<li><p> Venables, W. N. and Ripley, B. D. (2002). <em>Modern Applied Statistics with S.</em> Fourth edition. Springer.
</p>
</li>
<li><p> Hosmer, D.W. and Lemeshow, S. (1989) <em>Applied Logistic Regression.</em> New York: Wiley
</p>
</li></ul>



<h3>See Also</h3>

<p><a href="MASS.html#topic+birthwt">MASS::birthwt</a>, <code><a href="#topic+grpreg">grpreg()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(Birthwt)
hist(Birthwt$bwt, xlab="Child's birth weight", main="")
table(Birthwt$low)
## See examples in ?birthwt (MASS package)
##   for more about the data set
## See examples in ?grpreg for use of this data set
##   with group penalized regression models
</code></pre>

<hr>
<h2 id='birthwt.grpreg'>Risk Factors Associated with Low Infant Birth Weight</h2><span id='topic+birthwt.grpreg'></span>

<h3>Description</h3>

<p>This version of the data set has been deprecated and will not be supported
in future versions.  Please use <code><a href="#topic+Birthwt">Birthwt</a></code> instead.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>birthwt.grpreg
</code></pre>


<h3>Format</h3>

<p>This data frame contains the following columns:
</p>

<ul>
<li><p><code>low</code> Indicator of birth weight less than 2.5kg </p>
</li>
<li><p><code>bwt</code>
Birth weight in kilograms </p>
</li>
<li><p><code>age1,age2,age3</code> Orthogonal polynomials
of first, second, and third degree representing mother's age in years
</p>
</li>
<li><p><code>lwt1,lwt2,lwt3</code> Orthogonal polynomials of first, second, and
third degree representing mother's weight in pounds at last menstrual period
</p>
</li>
<li><p><code>white,black</code> Indicator functions for mother's race; &quot;other&quot; is
reference group </p>
</li>
<li><p><code>smoke</code> smoking status during pregnancy
</p>
</li>
<li><p><code>ptl1,ptl2m</code> Indicator functions for one or for two or more
previous premature labors, respectively.  No previous premature labors is
the reference category.  </p>
</li>
<li><p><code>ht</code> History of hypertension
</p>
</li>
<li><p><code>ui</code> Presence of uterine irritability </p>
</li>
<li><p><code>ftv1,ftv2,ftv3m</code>
Indicator functions for one, for two, or for three or more physician visits
during the first trimester, respectively.  No visits is the reference
category.
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+Birthwt">Birthwt</a></code>
</p>

<hr>
<h2 id='cv.grpreg'>Cross-validation for grpreg/grpsurv</h2><span id='topic+cv.grpreg'></span><span id='topic+cv.grpsurv'></span>

<h3>Description</h3>

<p>Performs k-fold cross validation for penalized regression models with
grouped covariates over a grid of values for the regularization parameter
lambda.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cv.grpreg(
  X,
  y,
  group = 1:ncol(X),
  ...,
  nfolds = 10,
  seed,
  fold,
  returnY = FALSE,
  trace = FALSE
)

cv.grpsurv(
  X,
  y,
  group = 1:ncol(X),
  ...,
  nfolds = 10,
  seed,
  fold,
  se = c("quick", "bootstrap"),
  returnY = FALSE,
  trace = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cv.grpreg_+3A_x">X</code></td>
<td>
<p>The design matrix, as in <code><a href="#topic+grpreg">grpreg()</a></code>/<code><a href="#topic+grpsurv">grpsurv()</a></code>.</p>
</td></tr>
<tr><td><code id="cv.grpreg_+3A_y">y</code></td>
<td>
<p>The response vector (or matrix), as in <code><a href="#topic+grpreg">grpreg()</a></code>/<code><a href="#topic+grpsurv">grpsurv()</a></code>.</p>
</td></tr>
<tr><td><code id="cv.grpreg_+3A_group">group</code></td>
<td>
<p>The grouping vector, as in <code><a href="#topic+grpreg">grpreg()</a></code>/<code><a href="#topic+grpsurv">grpsurv()</a></code>.</p>
</td></tr>
<tr><td><code id="cv.grpreg_+3A_...">...</code></td>
<td>
<p>Additional arguments to <code><a href="#topic+grpreg">grpreg()</a></code>/<code><a href="#topic+grpsurv">grpsurv()</a></code>.</p>
</td></tr>
<tr><td><code id="cv.grpreg_+3A_nfolds">nfolds</code></td>
<td>
<p>The number of cross-validation folds.  Default is 10.</p>
</td></tr>
<tr><td><code id="cv.grpreg_+3A_seed">seed</code></td>
<td>
<p>You may set the seed of the random number generator in order to
obtain reproducible results.</p>
</td></tr>
<tr><td><code id="cv.grpreg_+3A_fold">fold</code></td>
<td>
<p>Which fold each observation belongs to.  By default the
observations are randomly assigned.</p>
</td></tr>
<tr><td><code id="cv.grpreg_+3A_returny">returnY</code></td>
<td>
<p>Should cv.grpreg()/cv.grpsurv() return the fitted
values from the cross-validation folds?  Default is FALSE; if TRUE, this
will return a matrix in which the element for row i, column j is the fitted
value for observation i from the fold in which observation i was excluded
from the fit, at the jth value of lambda.  NOTE: For <code>cv.grpsurv()</code>, the
rows of <code>Y</code> are ordered by time on study, and therefore will not
correspond to the original order of observations pased to <code>cv.grpsurv</code>.</p>
</td></tr>
<tr><td><code id="cv.grpreg_+3A_trace">trace</code></td>
<td>
<p>If set to TRUE, cv.grpreg will inform the user of its progress
by announcing the beginning of each CV fold.  Default is FALSE.</p>
</td></tr>
<tr><td><code id="cv.grpreg_+3A_se">se</code></td>
<td>
<p>For <code>cv.grpsurv()</code>, the method by which the cross-valiation
standard error (CVSE) is calculated.  The 'quick' approach is based on a
rough approximation, but can be calculated more or less instantly.  The
'bootstrap' approach is more accurate, but requires additional computing
time.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function calls <code><a href="#topic+grpreg">grpreg()</a></code> or <code><a href="#topic+grpsurv">grpsurv()</a></code> <code>nfolds</code> times, each
time leaving out 1/<code>nfolds</code> of the data.  The cross-validation error is
based on the deviance;
<a href="https://pbreheny.github.io/grpreg/articles/models.html">see here for more details</a>.
</p>
<p>For Gaussian and Poisson responses, the folds are chosen according to simple
random sampling.  For binomial responses, the numbers for each outcome class
are balanced across the folds; i.e., the number of outcomes in which
<code>y</code> is equal to 1 is the same for each fold, or possibly off by 1 if
the numbers do not divide evenly.  This approach is used for Cox regression
as well to balance the amount of censoring cross each fold.
</p>
<p>For Cox models, <code>cv.grpsurv</code> uses the approach of calculating the full
Cox partial likelihood using the cross-validated set of linear predictors.
Other approaches to cross-validation for the Cox regression model have been
proposed in the literature; the strengths and weaknesses of the various
methods for penalized regression in the Cox model are the subject of current
research.  A simple approximation to the standard error is provided,
although an option to bootstrap the standard error (<code>se='bootstrap'</code>)
is also available.
</p>
<p>As in <code><a href="#topic+grpreg">grpreg()</a></code>, seemingly unrelated regressions/multitask learning can
be carried out by setting <code>y</code> to be a matrix, in which case groups are
set up automatically (see <code><a href="#topic+grpreg">grpreg()</a></code> for details), and
cross-validation is carried out with respect to rows of <code>y</code>.  As
mentioned in the details there, it is recommended to standardize the
responses prior to fitting.
</p>


<h3>Value</h3>

<p>An object with S3 class <code>"cv.grpreg"</code> containing:
</p>
<table role = "presentation">
<tr><td><code>cve</code></td>
<td>
<p>The error for each value of <code>lambda</code>, averaged across the
cross-validation folds.</p>
</td></tr> <tr><td><code>cvse</code></td>
<td>
<p>The estimated standard error associated
with each value of for <code>cve</code>.</p>
</td></tr> <tr><td><code>lambda</code></td>
<td>
<p>The sequence of
regularization parameter values along which the cross-validation error was
calculated.</p>
</td></tr> <tr><td><code>fit</code></td>
<td>
<p>The fitted <code>grpreg</code> object for the whole data.</p>
</td></tr>
<tr><td><code>fold</code></td>
<td>
<p>The fold assignments for cross-validation for each observation;
note that for <code>cv.grpsurv</code>, these are in terms of the ordered
observations, not the original observations.</p>
</td></tr> <tr><td><code>min</code></td>
<td>
<p>The index of
<code>lambda</code> corresponding to <code>lambda.min</code>.</p>
</td></tr> <tr><td><code>lambda.min</code></td>
<td>
<p>The
value of <code>lambda</code> with the minimum cross-validation error.</p>
</td></tr>
<tr><td><code>null.dev</code></td>
<td>
<p>The deviance for the intercept-only model.</p>
</td></tr>
<tr><td><code>pe</code></td>
<td>
<p>If <code>family="binomial"</code>, the cross-validation prediction error for
each value of <code>lambda</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Patrick Breheny
</p>


<h3>See Also</h3>

<p><code><a href="#topic+grpreg">grpreg()</a></code>, <code><a href="#topic+plot.cv.grpreg">plot.cv.grpreg()</a></code>, <code><a href="#topic+summary.cv.grpreg">summary.cv.grpreg()</a></code>,
<code><a href="#topic+predict.cv.grpreg">predict.cv.grpreg()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(Birthwt)
X &lt;- Birthwt$X
y &lt;- Birthwt$bwt
group &lt;- Birthwt$group

cvfit &lt;- cv.grpreg(X, y, group)
plot(cvfit)
summary(cvfit)
coef(cvfit) ## Beta at minimum CVE

cvfit &lt;- cv.grpreg(X, y, group, penalty="gel")
plot(cvfit)
summary(cvfit)

</code></pre>

<hr>
<h2 id='expand_spline'>Expand feature matrix using basis splines</h2><span id='topic+expand_spline'></span>

<h3>Description</h3>

<p>Performs a basis expansion for many features at once, returning output that is compatible
for use with the <code>grpreg()</code> function. Returns an expanded matrix along with a vector
that describes its grouping.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>expand_spline(x, df = 3, degree = 3, type = c("ns", "bs"))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="expand_spline_+3A_x">x</code></td>
<td>
<p>Features to be expanded (numeric matrix).</p>
</td></tr>
<tr><td><code id="expand_spline_+3A_df">df</code></td>
<td>
<p>Degrees of freedom (numeric; default = 3).</p>
</td></tr>
<tr><td><code id="expand_spline_+3A_degree">degree</code></td>
<td>
<p>Degree of the piecewise polynomial (integer; default = 3 (cubic splines)).</p>
</td></tr>
<tr><td><code id="expand_spline_+3A_type">type</code></td>
<td>
<p>Type of spline, either B-spline (<code>"bs"</code>) or natural cubic spline (<code>"ns"</code>; default).</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>expand_spline()</code> uses the function <code><a href="splines.html#topic+bs">splines::bs()</a></code> or <code><a href="splines.html#topic+ns">splines::ns()</a></code> to generate a basis
matrix for each column of <code>x</code>. These matrices represent the spline basis for piecewise
polynomials with specified degree evaluated separately for each original column of <code>x</code>.
These matrices are then column-bound to form a single grouped matrix of derived features. A vector
that describes the grouping present in the resulting matrix is also generated. The resulting
object can be passed to <code><a href="#topic+grpreg">grpreg()</a></code>.
</p>
<p>This methodology was originally proposed by Ravikumar et al. (2009), who named it SPAM (SParse Additive Modeling).
</p>


<h3>Value</h3>

<p>An object of class <code>expandedMatrix</code> consisting of:
</p>

<ul>
<li> <p><code>X</code>: A matrix of dimension <code>nrow(x)</code> by <code>df*ncol(x)</code>
</p>
</li>
<li> <p><code>group</code>: A vector of length <code>df*ncol(x)</code> that describes the grouping structure
</p>
</li>
<li><p> Additional metadata on the splines, such as knot locations, required in order to evaluate spline at new feature values (e.g., for prediction)
</p>
</li></ul>



<h3>References</h3>


<ul>
<li><p> Ravikumar P, Lafferty J, Liu H and Wasserman L (2009). Sparse additive models. <em>Journal of the Royal Statistical Society Series B</em>, <strong>71</strong>: 1009-1030.
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+plot_spline">plot_spline()</a></code> to visualize the resulting nonlinear fits
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
Data &lt;- gen_nonlinear_data(n=1000)
X &lt;- expand_spline(Data$X)
fit &lt;- grpreg(X, Data$y)
plot_spline(fit, "V02", lambda = 0.03)
</code></pre>

<hr>
<h2 id='gBridge'>Fit a group bridge regression path</h2><span id='topic+gBridge'></span>

<h3>Description</h3>

<p>Fit regularization paths for linear and logistic group bridge-penalized
regression models over a grid of values for the regularization parameter
lambda.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gBridge(
  X,
  y,
  group = 1:ncol(X),
  family = c("gaussian", "binomial", "poisson"),
  nlambda = 100,
  lambda,
  lambda.min = {
     if (nrow(X) &gt; ncol(X)) 
         0.001
     else 0.05
 },
  lambda.max,
  alpha = 1,
  eps = 0.001,
  delta = 1e-07,
  max.iter = 10000,
  gamma = 0.5,
  group.multiplier,
  warn = TRUE,
  returnX = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gBridge_+3A_x">X</code></td>
<td>
<p>The design matrix, as in <code>grpreg</code>.</p>
</td></tr>
<tr><td><code id="gBridge_+3A_y">y</code></td>
<td>
<p>The response vector (or matrix), as in <code>grpreg</code>.</p>
</td></tr>
<tr><td><code id="gBridge_+3A_group">group</code></td>
<td>
<p>The grouping vector, as in <code>grpreg</code>.</p>
</td></tr>
<tr><td><code id="gBridge_+3A_family">family</code></td>
<td>
<p>Either &quot;gaussian&quot; or &quot;binomial&quot;, depending on the response.</p>
</td></tr>
<tr><td><code id="gBridge_+3A_nlambda">nlambda</code></td>
<td>
<p>The number of <code>lambda</code> values, as in <code>grpreg</code>.</p>
</td></tr>
<tr><td><code id="gBridge_+3A_lambda">lambda</code></td>
<td>
<p>A user supplied sequence of <code style="white-space: pre;">&#8288;lambda values, as in &#8288;</code>grpreg()'.</p>
</td></tr>
<tr><td><code id="gBridge_+3A_lambda.min">lambda.min</code></td>
<td>
<p>The smallest value for <code>lambda</code>, as in <code>grpreg</code>.</p>
</td></tr>
<tr><td><code id="gBridge_+3A_lambda.max">lambda.max</code></td>
<td>
<p>The maximum value for <code>lambda</code>.  Unlike the penalties
in <code>grpreg</code>, it is not possible to solve for <code>lambda.max</code> directly
with group bridge models.  Thus, it must be specified by the user.  If it is
not specified, <code>gBridge</code> will attempt to guess <code>lambda.max</code>, but
this is not particularly accurate.</p>
</td></tr>
<tr><td><code id="gBridge_+3A_alpha">alpha</code></td>
<td>
<p>Tuning parameter for the balance between the group penalty and
the L2 penalty, as in <code>grpreg</code>.</p>
</td></tr>
<tr><td><code id="gBridge_+3A_eps">eps</code></td>
<td>
<p>Convergence threshhold, as in <code>grpreg</code>.</p>
</td></tr>
<tr><td><code id="gBridge_+3A_delta">delta</code></td>
<td>
<p>The group bridge penalty is not differentiable at zero, and
requires a small number <code>delta</code> to bound it away from zero.  There is
typically no need to change this value.</p>
</td></tr>
<tr><td><code id="gBridge_+3A_max.iter">max.iter</code></td>
<td>
<p>Maximum number of iterations, as in <code>grpreg</code>.</p>
</td></tr>
<tr><td><code id="gBridge_+3A_gamma">gamma</code></td>
<td>
<p>Tuning parameter of the group bridge penalty (the exponent to
which the L1 norm of the coefficients in the group are raised).  Default is
0.5, the square root.</p>
</td></tr>
<tr><td><code id="gBridge_+3A_group.multiplier">group.multiplier</code></td>
<td>
<p>The multiplicative factor by which each group's
penalty is to be multiplied, as in <code>grpreg</code>.</p>
</td></tr>
<tr><td><code id="gBridge_+3A_warn">warn</code></td>
<td>
<p>Should the function give a warning if it fails to converge?  As
in <code>grpreg</code>.</p>
</td></tr>
<tr><td><code id="gBridge_+3A_returnx">returnX</code></td>
<td>
<p>Return the standardized design matrix (and associated group
structure information)?  Default is FALSE.</p>
</td></tr>
<tr><td><code id="gBridge_+3A_...">...</code></td>
<td>
<p>Not used.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This method fits the group bridge method of Huang et al. (2009).  Unlike the
penalties in <code>grpreg</code>, the group bridge is not differentiable at zero;
because of this, a number of changes must be made to the algorithm, which is
why it has its own function.  Most notably, the method is unable to start at
<code>lambda.max</code>; it must start at <code>lambda.min</code> and proceed in the
opposite direction.
</p>
<p>In other respects, the usage and behavior of the function is similar to the
rest of the <code>grpreg</code> package.
</p>


<h3>Value</h3>

<p>An object with S3 class <code>"grpreg"</code>, as in <code>grpreg</code>.
</p>


<h3>References</h3>


<ul>
<li><p> Huang J, Ma S, Xie H, and Zhang C. (2009) A group bridge approach for
variable selection. <em>Biometrika</em>, <strong>96</strong>: 339-355. <a href="https://doi.org/10.1093/biomet/asp020">doi:10.1093/biomet/asp020</a>
</p>
</li>
<li><p> Breheny P and Huang J. (2009) Penalized methods for bi-level variable
selection. <em>Statistics and its interface</em>, <strong>2</strong>: 369-380.
<a href="https://doi.org/10.4310/sii.2009.v2.n3.a10">doi:10.4310/sii.2009.v2.n3.a10</a>
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+grpreg">grpreg()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(Birthwt)
X &lt;- Birthwt$X
group &lt;- Birthwt$group

## Linear regression
y &lt;- Birthwt$bwt
fit &lt;- gBridge(X, y, group, lambda.max=0.08)
plot(fit)
select(fit)$beta

## Logistic regression
y &lt;- Birthwt$low
fit &lt;- gBridge(X, y, group, family="binomial", lambda.max=0.17)
plot(fit)
select(fit)$beta
</code></pre>

<hr>
<h2 id='gen_nonlinear_data'>Generate nonlinear example data</h2><span id='topic+gen_nonlinear_data'></span>

<h3>Description</h3>

<p>Mainly intended to demonstrate the use of basis expansion models for sparse additive modeling; intended for use with <code><a href="#topic+expand_spline">expand_spline()</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gen_nonlinear_data(n = 100, p = 16, seed)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gen_nonlinear_data_+3A_n">n</code></td>
<td>
<p>Sample size (numeric; default = 100).</p>
</td></tr>
<tr><td><code id="gen_nonlinear_data_+3A_p">p</code></td>
<td>
<p>Number of features (numeric; default = 16).</p>
</td></tr>
<tr><td><code id="gen_nonlinear_data_+3A_seed">seed</code></td>
<td>
<p>Set to get different random data sets, passed to <code><a href="base.html#topic+set.seed">set.seed()</a></code></p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>Data &lt;- gen_nonlinear_data()
</code></pre>

<hr>
<h2 id='grpreg'>Fit a group penalized regression path</h2><span id='topic+grpreg'></span>

<h3>Description</h3>

<p>Fit regularization paths for models with grouped penalties over a grid of
values for the regularization parameter lambda. Fits linear and logistic
regression models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>grpreg(
  X,
  y,
  group = 1:ncol(X),
  penalty = c("grLasso", "grMCP", "grSCAD", "gel", "cMCP"),
  family = c("gaussian", "binomial", "poisson"),
  nlambda = 100,
  lambda,
  lambda.min = {
     if (nrow(X) &gt; ncol(X)) 
         1e-04
     else 0.05
 },
  log.lambda = TRUE,
  alpha = 1,
  eps = 1e-04,
  max.iter = 10000,
  dfmax = p,
  gmax = length(unique(group)),
  gamma = ifelse(penalty == "grSCAD", 4, 3),
  tau = 1/3,
  group.multiplier,
  warn = TRUE,
  returnX = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="grpreg_+3A_x">X</code></td>
<td>
<p>The design matrix, without an intercept.  <code>grpreg</code>
standardizes the data and includes an intercept by default.</p>
</td></tr>
<tr><td><code id="grpreg_+3A_y">y</code></td>
<td>
<p>The response vector, or a matrix in the case of multitask learning
(see details).</p>
</td></tr>
<tr><td><code id="grpreg_+3A_group">group</code></td>
<td>
<p>A vector describing the grouping of the coefficients.  For
greatest efficiency and least ambiguity (see details), it is best if
<code>group</code> is a factor or vector of consecutive integers, although
unordered groups and character vectors are also allowed.  If there are
coefficients to be included in the model without being penalized, assign
them to group 0 (or <code>"0"</code>).</p>
</td></tr>
<tr><td><code id="grpreg_+3A_penalty">penalty</code></td>
<td>
<p>The penalty to be applied to the model.  For group selection,
one of <code>grLasso</code>, <code>grMCP</code>, or <code>grSCAD</code>.  For bi-level
selection, one of <code>gel</code> or <code>cMCP</code>.  See below for details.</p>
</td></tr>
<tr><td><code id="grpreg_+3A_family">family</code></td>
<td>
<p>Either &quot;gaussian&quot; or &quot;binomial&quot;, depending on the response.</p>
</td></tr>
<tr><td><code id="grpreg_+3A_nlambda">nlambda</code></td>
<td>
<p>The number of <code>lambda</code> values.  Default is 100.</p>
</td></tr>
<tr><td><code id="grpreg_+3A_lambda">lambda</code></td>
<td>
<p>A user supplied sequence of <code>lambda</code> values.  Typically,
this is left unspecified, and the function automatically computes a grid of
lambda values that ranges uniformly on the log scale over the relevant range
of lambda values.</p>
</td></tr>
<tr><td><code id="grpreg_+3A_lambda.min">lambda.min</code></td>
<td>
<p>The smallest value for <code>lambda</code>, as a fraction of
<code>lambda.max</code>.  Default is .0001 if the number of observations is larger
than the number of covariates and .05 otherwise.</p>
</td></tr>
<tr><td><code id="grpreg_+3A_log.lambda">log.lambda</code></td>
<td>
<p>Whether compute the grid values of lambda on log scale
(default) or linear scale.</p>
</td></tr>
<tr><td><code id="grpreg_+3A_alpha">alpha</code></td>
<td>
<p><code>grpreg</code> allows for both a group penalty and an L2 (ridge)
penalty; <code>alpha</code> controls the proportional weight of the regularization
parameters of these two penalties.  The group penalties' regularization
parameter is <code>lambda*alpha</code>, while the regularization parameter of the
ridge penalty is <code>lambda*(1-alpha)</code>.  Default is 1: no ridge penalty.</p>
</td></tr>
<tr><td><code id="grpreg_+3A_eps">eps</code></td>
<td>
<p>Convergence threshhold.  The algorithm iterates until the RMSD
for the change in linear predictors for each coefficient is less than
<code>eps</code>.  Default is <code>1e-4</code>.  See details.</p>
</td></tr>
<tr><td><code id="grpreg_+3A_max.iter">max.iter</code></td>
<td>
<p>Maximum number of iterations (total across entire path).
Default is 10000.  See details.</p>
</td></tr>
<tr><td><code id="grpreg_+3A_dfmax">dfmax</code></td>
<td>
<p>Limit on the number of parameters allowed to be nonzero.  If
this limit is exceeded, the algorithm will exit early from the
regularization path.</p>
</td></tr>
<tr><td><code id="grpreg_+3A_gmax">gmax</code></td>
<td>
<p>Limit on the number of groups allowed to have nonzero elements.
If this limit is exceeded, the algorithm will exit early from the
regularization path.</p>
</td></tr>
<tr><td><code id="grpreg_+3A_gamma">gamma</code></td>
<td>
<p>Tuning parameter of the group or composite MCP/SCAD penalty
(see details).  Default is 3 for MCP and 4 for SCAD.</p>
</td></tr>
<tr><td><code id="grpreg_+3A_tau">tau</code></td>
<td>
<p>Tuning parameter for the group exponential lasso; defaults to
1/3.</p>
</td></tr>
<tr><td><code id="grpreg_+3A_group.multiplier">group.multiplier</code></td>
<td>
<p>A vector of values representing multiplicative
factors by which each group's penalty is to be multiplied.  Often, this is a
function (such as the square root) of the number of predictors in each
group.  The default is to use the square root of group size for the group
selection methods, and a vector of 1's (i.e., no adjustment for group size)
for bi-level selection.</p>
</td></tr>
<tr><td><code id="grpreg_+3A_warn">warn</code></td>
<td>
<p>Should the function give a warning if it fails to converge?
Default is TRUE.  See details.</p>
</td></tr>
<tr><td><code id="grpreg_+3A_returnx">returnX</code></td>
<td>
<p>Return the standardized design matrix (and associated group
structure information)?  Default is FALSE.</p>
</td></tr>
<tr><td><code id="grpreg_+3A_...">...</code></td>
<td>
<p>Arguments passed to other functions (such as gBridge).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>There are two general classes of methods involving grouped penalties: those
that carry out bi-level selection and those that carry out group selection.
Bi-level means carrying out variable selection at the group level as well as
the level of individual covariates (i.e., selecting important groups as well
as important members of those groups).  Group selection selects important
groups, and not members within the group &ndash; i.e., within a group,
coefficients will either all be zero or all nonzero.  The <code>grLasso</code>,
<code>grMCP</code>, and <code>grSCAD</code> penalties carry out group selection, while
the <code>gel</code> and <code>cMCP</code> penalties carry out bi-level selection.  For
bi-level selection, see also the <code><a href="#topic+gBridge">gBridge()</a></code> function.  For
historical reasons and backwards compatibility, some of these penalties have
aliases; e.g., <code>gLasso</code> will do the same thing as <code>grLasso</code>, but
users are encouraged to use <code>grLasso</code>.
</p>
<p>Please note the distinction between <code>grMCP</code> and <code>cMCP</code>.  The
former involves an MCP penalty being applied to an L2-norm of each group.
The latter involves a hierarchical penalty which places an outer MCP penalty
on a sum of inner MCP penalties for each group, as proposed in Breheny &amp;
Huang, 2009.  Either penalty may be referred to as the &quot;group MCP&quot;,
depending on the publication.  To resolve this confusion, Huang et al.
(2012) proposed the name &quot;composite MCP&quot; for the <code>cMCP</code> penalty.
</p>
<p>For more information about the penalties and their properties, please
consult the references below, many of which contain discussion, case
studies, and simulation studies comparing the methods.  If you use
<code>grpreg</code> for an analysis, please cite the appropriate reference.
</p>
<p>In keeping with the notation from the original MCP paper, the tuning
parameter of the MCP penalty is denoted 'gamma'.  Note, however, that in
Breheny and Huang (2009), <code>gamma</code> is denoted 'a'.
</p>
<p>The objective function for <code>grpreg</code> optimization is defined to be
</p>
<p style="text-align: center;"><code class="reqn">Q(\beta|X, y) = \frac{1}{n} L(\beta|X, y) + </code>
</p>
<p style="text-align: center;"><code class="reqn"> P_\lambda(\beta)</code>
</p>
<p> where the loss function L is
the negative log-likelihood (half the deviance) for the specified outcome
distribution (gaussian/binomial/poisson). For more details, refer to the
following:
</p>

<ul>
<li> <p><a href="https://pbreheny.github.io/grpreg/articles/models.html">Models and loss functions</a>
</p>
</li>
<li> <p><a href="https://pbreheny.github.io/grpreg/articles/penalties.html">Penalties</a>
</p>
</li></ul>

<p>For the bi-level selection methods, a locally approximated coordinate
descent algorithm is employed.  For the group selection methods, group
descent algorithms are employed.
</p>
<p>The algorithms employed by <code>grpreg</code> are stable and generally converge
quite rapidly to values close to the solution.  However, especially when p
is large compared with n, <code>grpreg</code> may fail to converge at low values
of <code>lambda</code>, where models are nonidentifiable or nearly singular.
Often, this is not the region of the coefficient path that is most
interesting.  The default behavior warning the user when convergence
criteria are not met may be distracting in these cases, and can be modified
with <code>warn</code> (convergence can always be checked later by inspecting the
value of <code>iter</code>).
</p>
<p>If models are not converging, increasing <code>max.iter</code> may not be the most
efficient way to correct this problem.  Consider increasing <code>n.lambda</code>
or <code>lambda.min</code> in addition to increasing <code>max.iter</code>.
</p>
<p>Although <code>grpreg</code> allows groups to be unordered and given arbitary
names, it is recommended that you specify groups as consecutive integers.
The first reason is efficiency: if groups are out of order, <code>X</code> must be
reordered prior to fitting, then this process reversed to return
coefficients according to the original order of <code>X</code>.  This is
inefficient if <code>X</code> is very large.  The second reason is ambiguity with
respect to other arguments such as <code>group.multiplier</code>.  With
consecutive integers, <code>group=3</code> unambiguously denotes the third element
of <code>group.multiplier</code>.
</p>
<p>Seemingly unrelated regressions/multitask learning can be carried out using
<code>grpreg</code> by passing a matrix to <code>y</code>.  In this case, <code>X</code> will
be used in separate regressions for each column of <code>y</code>, with the
coefficients grouped across the responses.  In other words, each column of
<code>X</code> will form a group with m members, where m is the number of columns
of <code>y</code>.  For multiple Gaussian responses, it is recommended to
standardize the columns of <code>y</code> prior to fitting, in order to apply the
penalization equally across columns.
</p>
<p><code>grpreg</code> requires groups to be non-overlapping.
</p>


<h3>Value</h3>

<p>An object with S3 class <code>"grpreg"</code> containing:
</p>

<dl>
<dt>beta</dt><dd><p>The fitted matrix of coefficients.  The number of rows is equal
to the number of coefficients, and the number of columns is equal to
<code>nlambda</code>.</p>
</dd>
<dt>family</dt><dd><p>Same as above.</p>
</dd>
<dt>group</dt><dd><p>Same as above.</p>
</dd>
<dt>lambda</dt><dd><p>The sequence of <code>lambda</code> values in the path.</p>
</dd>
<dt>alpha</dt><dd><p>Same as above.</p>
</dd>
<dt>deviance</dt><dd><p>A vector containing the deviance of the fitted model at each
value of <code>lambda</code>.</p>
</dd>
<dt>n</dt><dd><p>Number of observations.</p>
</dd>
<dt>penalty</dt><dd><p>Same as above.</p>
</dd>
<dt>df</dt><dd><p>A vector of length <code>nlambda</code> containing estimates of effective number of model parameters all the points along the regularization path.  For details on how this is calculated, see Breheny and Huang (2009).</p>
</dd>
<dt>iter</dt><dd><p>A vector of length <code>nlambda</code> containing the number of iterations until convergence at each value of <code>lambda</code>.</p>
</dd>
<dt>group.multiplier</dt><dd><p>A named vector containing the multiplicative constant applied to each group's penalty.</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Patrick Breheny
</p>


<h3>References</h3>


<ul>
<li><p> Breheny P and Huang J. (2009) Penalized methods for bi-level variable
selection. <em>Statistics and its interface</em>, <strong>2</strong>: 369-380.
<a href="https://doi.org/10.4310/sii.2009.v2.n3.a10">doi:10.4310/sii.2009.v2.n3.a10</a>
</p>
</li>
<li><p> Huang J, Breheny P, and Ma S. (2012). A selective review of group
selection in high dimensional models. <em>Statistical Science</em>, <strong>27</strong>: 481-499.
<a href="https://doi.org/10.1214/12-sts392">doi:10.1214/12-sts392</a>
</p>
</li>
<li><p> Breheny P and Huang J. (2015) Group descent algorithms for nonconvex
penalized linear and logistic regression models with grouped predictors.
<em>Statistics and Computing</em>, <strong>25</strong>: 173-187. <a href="https://doi.org/10.1007/s11222-013-9424-2">doi:10.1007/s11222-013-9424-2</a>
</p>
</li>
<li><p> Breheny P. (2015) The group exponential lasso for bi-level variable
selection. <em>Biometrics</em>, <strong>71</strong>: 731-740. <a href="https://doi.org/10.1111/biom.12300">doi:10.1111/biom.12300</a>
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+cv.grpreg">cv.grpreg()</a></code>, as well as <code><a href="#topic+plot.grpreg">plot.grpreg()</a></code> and <code><a href="#topic+select.grpreg">select.grpreg()</a></code> methods.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Birthweight data
data(Birthwt)
X &lt;- Birthwt$X
group &lt;- Birthwt$group

# Linear regression
y &lt;- Birthwt$bwt
fit &lt;- grpreg(X, y, group, penalty="grLasso")
plot(fit)
fit &lt;- grpreg(X, y, group, penalty="grMCP")
plot(fit)
fit &lt;- grpreg(X, y, group, penalty="grSCAD")
plot(fit)
fit &lt;- grpreg(X, y, group, penalty="gel")
plot(fit)
fit &lt;- grpreg(X, y, group, penalty="cMCP")
plot(fit)
select(fit, "AIC")

# Logistic regression
y &lt;- Birthwt$low
fit &lt;- grpreg(X, y, group, penalty="grLasso", family="binomial")
plot(fit)
fit &lt;- grpreg(X, y, group, penalty="grMCP", family="binomial")
plot(fit)
fit &lt;- grpreg(X, y, group, penalty="grSCAD", family="binomial")
plot(fit)
fit &lt;- grpreg(X, y, group, penalty="gel", family="binomial")
plot(fit)
fit &lt;- grpreg(X, y, group, penalty="cMCP", family="binomial")
plot(fit)
select(fit, "BIC")

# Multitask learning (simulated example)
set.seed(1)
n &lt;- 50
p &lt;- 10
k &lt;- 5
X &lt;- matrix(runif(n*p), n, p)
y &lt;- matrix(rnorm(n*k, X[,1] + X[,2]), n, k)
fit &lt;- grpreg(X, y)
# Note that group is set up automatically
fit$group
plot(fit)
</code></pre>

<hr>
<h2 id='grpsurv'>Fit an group penalized survival model</h2><span id='topic+grpsurv'></span>

<h3>Description</h3>

<p>Fit regularization paths for Cox models with grouped penalties over a grid
of values for the regularization parameter lambda.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>grpsurv(
  X,
  y,
  group = 1:ncol(X),
  penalty = c("grLasso", "grMCP", "grSCAD", "gel", "cMCP"),
  gamma = ifelse(penalty == "grSCAD", 4, 3),
  alpha = 1,
  nlambda = 100,
  lambda,
  lambda.min = {
     if (nrow(X) &gt; ncol(X)) 
         0.001
     else 0.05
 },
  eps = 0.001,
  max.iter = 10000,
  dfmax = p,
  gmax = length(unique(group)),
  tau = 1/3,
  group.multiplier,
  warn = TRUE,
  returnX = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="grpsurv_+3A_x">X</code></td>
<td>
<p>The design matrix.</p>
</td></tr>
<tr><td><code id="grpsurv_+3A_y">y</code></td>
<td>
<p>The time-to-event outcome, as a two-column matrix or
<code><a href="survival.html#topic+Surv">Surv</a></code> object.  The first column should be time on
study (follow up time); the second column should be a binary variable with 1
indicating that the event has occurred and 0 indicating (right) censoring.</p>
</td></tr>
<tr><td><code id="grpsurv_+3A_group">group</code></td>
<td>
<p>A vector describing the grouping of the coefficients.  For
greatest efficiency and least ambiguity (see details), it is best if
<code>group</code> is a factor or vector of consecutive integers, although
unordered groups and character vectors are also allowed.  If there are
coefficients to be included in the model without being penalized, assign
them to group 0 (or <code>"0"</code>).</p>
</td></tr>
<tr><td><code id="grpsurv_+3A_penalty">penalty</code></td>
<td>
<p>The penalty to be applied to the model.  For group selection,
one of <code>grLasso</code>, <code>grMCP</code>, or <code>grSCAD</code>.  For bi-level
selection, one of <code>gel</code> or <code>cMCP</code>.  See below for details.</p>
</td></tr>
<tr><td><code id="grpsurv_+3A_gamma">gamma</code></td>
<td>
<p>Tuning parameter of the group or composite MCP/SCAD penalty
(see details).  Default is 3 for MCP and 4 for SCAD.</p>
</td></tr>
<tr><td><code id="grpsurv_+3A_alpha">alpha</code></td>
<td>
<p><code>grpsurv</code> allows for both a group penalty and an L2
(ridge) penalty; <code>alpha</code> controls the proportional weight of the
regularization parameters of these two penalties.  The group penalties'
regularization parameter is <code>lambda*alpha</code>, while the regularization
parameter of the ridge penalty is <code>lambda*(1-alpha)</code>.  Default is 1: no
ridge penalty.</p>
</td></tr>
<tr><td><code id="grpsurv_+3A_nlambda">nlambda</code></td>
<td>
<p>The number of lambda values.  Default is 100.</p>
</td></tr>
<tr><td><code id="grpsurv_+3A_lambda">lambda</code></td>
<td>
<p>A user-specified sequence of lambda values.  By default, a
sequence of values of length <code>nlambda</code> is computed automatically,
equally spaced on the log scale.</p>
</td></tr>
<tr><td><code id="grpsurv_+3A_lambda.min">lambda.min</code></td>
<td>
<p>The smallest value for lambda, as a fraction of
lambda.max.  Default is .001 if the number of observations is larger than
the number of covariates and .05 otherwise.</p>
</td></tr>
<tr><td><code id="grpsurv_+3A_eps">eps</code></td>
<td>
<p>Convergence threshhold.  The algorithm iterates until the RMSD
for the change in linear predictors for each coefficient is less than
<code>eps</code>.  Default is <code>0.001</code>.</p>
</td></tr>
<tr><td><code id="grpsurv_+3A_max.iter">max.iter</code></td>
<td>
<p>Maximum number of iterations (total across entire path).
Default is 10000.</p>
</td></tr>
<tr><td><code id="grpsurv_+3A_dfmax">dfmax</code></td>
<td>
<p>Limit on the number of parameters allowed to be nonzero.  If
this limit is exceeded, the algorithm will exit early from the
regularization path.</p>
</td></tr>
<tr><td><code id="grpsurv_+3A_gmax">gmax</code></td>
<td>
<p>Limit on the number of groups allowed to have nonzero elements.
If this limit is exceeded, the algorithm will exit early from the
regularization path.</p>
</td></tr>
<tr><td><code id="grpsurv_+3A_tau">tau</code></td>
<td>
<p>Tuning parameter for the group exponential lasso; defaults to
1/3.</p>
</td></tr>
<tr><td><code id="grpsurv_+3A_group.multiplier">group.multiplier</code></td>
<td>
<p>A vector of values representing multiplicative
factors by which each group's penalty is to be multiplied.  Often, this is a
function (such as the square root) of the number of predictors in each
group.  The default is to use the square root of group size for the group
selection methods, and a vector of 1's (i.e., no adjustment for group size)
for bi-level selection.</p>
</td></tr>
<tr><td><code id="grpsurv_+3A_warn">warn</code></td>
<td>
<p>Return warning messages for failures to converge and model
saturation?  Default is TRUE.</p>
</td></tr>
<tr><td><code id="grpsurv_+3A_returnx">returnX</code></td>
<td>
<p>Return the standardized design matrix?  Default is FALSE.</p>
</td></tr>
<tr><td><code id="grpsurv_+3A_...">...</code></td>
<td>
<p>Not used.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The sequence of models indexed by the regularization parameter <code>lambda</code>
is fit using a coordinate descent algorithm.  In order to accomplish this,
the second derivative (Hessian) of the Cox partial log-likelihood is
diagonalized (see references for details).  The objective function is
defined to be </p>
<p style="text-align: center;"><code class="reqn">Q(\beta|X, y) = \frac{1}{n} L(\beta|X, y) + </code>
</p>
<p style="text-align: center;"><code class="reqn">
P_\lambda(\beta)</code>
</p>

<p>where the loss function L is the negative partial log-likelihood (half the
deviance) from the Cox regression model.
<a href="https://pbreheny.github.io/grpreg/articles/models.html">See here for more details</a>.
</p>
<p>Presently, ties are not handled by <code>grpsurv</code> in a particularly
sophisticated manner.  This will be improved upon in a future release of
<code>grpreg</code>.
</p>


<h3>Value</h3>

<p>An object with S3 class <code>"grpsurv"</code> containing:
</p>
<table role = "presentation">
<tr><td><code>beta</code></td>
<td>
<p>The fitted matrix of coefficients. The number of rows is equal to
the number of coefficients, and the number of columns is equal to <code>nlambda</code>.</p>
</td></tr>
<tr><td><code>group</code></td>
<td>
<p>Same as above.</p>
</td></tr>
<tr><td><code>lambda</code></td>
<td>
<p>The sequence of <code>lambda</code> values in the path.</p>
</td></tr>
<tr><td><code>penalty</code></td>
<td>
<p>Same as above.</p>
</td></tr>
<tr><td><code>gamma</code></td>
<td>
<p>Same as above.</p>
</td></tr>
<tr><td><code>alpha</code></td>
<td>
<p>Same as above.</p>
</td></tr>
<tr><td><code>deviance</code></td>
<td>
<p>The deviance of the fitted model at each value of <code>lambda</code>.</p>
</td></tr>
<tr><td><code>n</code></td>
<td>
<p>The number of observations.</p>
</td></tr>
<tr><td><code>df</code></td>
<td>
<p>A vector of length <code>nlambda</code> containing estimates of effective
number of model parameters all the points along the regularization path. For
details on how this is calculated, see Breheny and Huang (2009).</p>
</td></tr>
<tr><td><code>iter</code></td>
<td>
<p>A vector of length <code>nlambda</code> containing the number of iterations
until convergence at each value of <code>lambda</code>.</p>
</td></tr>
<tr><td><code>group.multiplier</code></td>
<td>
<p>A named vector containing the multiplicative constant
applied to each group's penalty.</p>
</td></tr>
</table>
<p>For Cox models, the following objects are also returned (and are necessary
to estimate baseline survival conditional on the estimated regression
coefficients), all of which are ordered by time on study (i.e., the ith row
of <code>W</code> does not correspond to the ith row of <code>X</code>):
</p>
<table role = "presentation">
<tr><td><code>W</code></td>
<td>
<p>Matrix of <code>exp(beta)</code> values for each subject over all <code>lambda</code>
values.</p>
</td></tr>
<tr><td><code>time</code></td>
<td>
<p>Times on study.</p>
</td></tr>
<tr><td><code>fail</code></td>
<td>
<p>Failure event indicator.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Patrick Breheny
</p>


<h3>References</h3>


<ul>
<li><p> Breheny P and Huang J. (2009) Penalized methods for bi-level variable
selection. <em>Statistics and its interface</em>, <strong>2</strong>: 369-380.
<a href="https://doi.org/10.4310/sii.2009.v2.n3.a10">doi:10.4310/sii.2009.v2.n3.a10</a>
</p>
</li>
<li><p> Huang J, Breheny P, and Ma S. (2012). A selective review of group
selection in high dimensional models. <em>Statistical Science</em>, <strong>27</strong>: 481-499.
<a href="https://doi.org/10.1214/12-sts392">doi:10.1214/12-sts392</a>
</p>
</li>
<li><p> Breheny P and Huang J. (2015) Group descent algorithms for nonconvex
penalized linear and logistic regression models with grouped predictors.
<em>Statistics and Computing</em>, <strong>25</strong>: 173-187. <a href="https://doi.org/10.1007/s11222-013-9424-2">doi:10.1007/s11222-013-9424-2</a>
</p>
</li>
<li><p> Breheny P. (2015) The group exponential lasso for bi-level variable
selection. <em>Biometrics</em>, <strong>71</strong>: 731-740. <a href="https://doi.org/10.1111/biom.12300">doi:10.1111/biom.12300</a>
</p>
</li>
<li><p> Simon N, Friedman JH, Hastie T, and Tibshirani R. (2011)
Regularization Paths for Cox's Proportional Hazards Model via Coordinate
Descent. <em>Journal of Statistical Software</em>, <strong>39</strong>: 1-13.
<a href="https://doi.org/10.18637/jss.v039.i05">doi:10.18637/jss.v039.i05</a>
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+plot.grpreg">plot.grpreg()</a></code>, <code><a href="#topic+predict.grpsurv">predict.grpsurv()</a></code>, <code><a href="#topic+cv.grpsurv">cv.grpsurv()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(Lung)
X &lt;- Lung$X
y &lt;- Lung$y
group &lt;- Lung$group

fit &lt;- grpsurv(X, y, group)
plot(fit)

S &lt;- predict(fit, X, type='survival', lambda=0.05)
plot(S, xlim=c(0,200))
</code></pre>

<hr>
<h2 id='logLik.grpreg'>logLik method for grpreg</h2><span id='topic+logLik.grpreg'></span><span id='topic+logLik'></span><span id='topic+logLik.grpsurv'></span>

<h3>Description</h3>

<p>Calculates the log likelihood and degrees of freedom for a fitted grpreg
object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'grpreg'
logLik(object, df.method = c("default", "active"), REML = FALSE, ...)

## S3 method for class 'grpsurv'
logLik(object, df.method = c("default", "active"), ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="logLik.grpreg_+3A_object">object</code></td>
<td>
<p>A fitted <code>grpreg</code> or <code>grpsurv</code> object, as obtained from
<code><a href="#topic+grpreg">grpreg()</a></code> or <code><a href="#topic+grpsurv">grpsurv()</a></code></p>
</td></tr>
<tr><td><code id="logLik.grpreg_+3A_df.method">df.method</code></td>
<td>
<p>How should effective model parameters be calculated? One
of: <code>"active"</code>, which counts the number of nonzero coefficients; or
<code>"default"</code>, which uses the calculated <code>df</code> returned by
<code>grpreg</code>. Default is <code>"default"</code>.</p>
</td></tr>
<tr><td><code id="logLik.grpreg_+3A_reml">REML</code></td>
<td>
<p>Use restricted MLE for estimation of the scale parameter in a
gaussian model?  Default is FALSE.</p>
</td></tr>
<tr><td><code id="logLik.grpreg_+3A_...">...</code></td>
<td>
<p>For S3 method compatibility.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Exists mainly for use with <code><a href="stats.html#topic+AIC">stats::AIC()</a></code> and <code><a href="stats.html#topic+AIC">stats::BIC()</a></code>.
</p>


<h3>Value</h3>

<p>Returns an object of class 'logLik', in this case consisting of a
number (or vector of numbers) with two attributes: 'df' (the estimated
degrees of freedom in the model) and 'nobs' (number of observations).
</p>
<p>The 'print' method for 'logLik' objects is not intended to handle vectors;
consequently, the value of the function does not necessarily display
correctly.  However, it works with 'AIC' and 'BIC' without any glitches and
returns the expected vectorized output.
</p>


<h3>Author(s)</h3>

<p>Patrick Breheny
</p>


<h3>See Also</h3>

<p><code><a href="#topic+grpreg">grpreg()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(Birthwt)
X &lt;- Birthwt$X
y &lt;- Birthwt$bwt
group &lt;- Birthwt$group
fit &lt;- grpreg(X,y,group,penalty="cMCP")
logLik(fit) ## Display is glitchy for vectors
AIC(fit)
BIC(fit)
</code></pre>

<hr>
<h2 id='Lung'>VA lung cancer data set</h2><span id='topic+Lung'></span>

<h3>Description</h3>

<p>Data from a randomised trial of two treatment regimens for lung cancer. This
is a standard survival analysis data set from the classic textbook by
Kalbfleisch and Prentice.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Lung
</code></pre>


<h3>Format</h3>

<p>A list of two objects: <code>y</code> and <code>X</code>
</p>

<dl>
<dt>y</dt><dd><p>A two column matrix (<code>Surv</code> object) containing the follow-up
time (in days) and an indicator variable for whether the patient died
while on the study or not.</p>
</dd>
<dt>X</dt><dd><p>A matrix with 137 observations (rows) and 9 predictor variables
(columns). The remainder of this list describes the columns of <code>X</code></p>
</dd>
<dt>trt</dt><dd><p>Treatment indicator (1=control group, 2=treatment group)</p>
</dd>
<dt>karno</dt><dd><p>Karnofsky performance score (0=bad, 100=good)</p>
</dd>
<dt>diagtime</dt><dd><p>Time from diagnosis to randomization (months)</p>
</dd>
<dt>age</dt><dd><p>Age (years, at baseline)</p>
</dd>
<dt>prior</dt><dd><p>Prior therapy (0=no, 1=yes)</p>
</dd>
<dt>squamous</dt><dd><p>Indicator for whether the cancer type is squamous cell
carcinoma (0=no, 1=yes)</p>
</dd>
<dt>small</dt><dd><p>Indicator for whether the cancer type is small cell lung
cancer (0=no, 1=yes)</p>
</dd>
<dt>adeno</dt><dd><p>Indicator for whether the cancer type is adenocarcinoma
(0=no, 1=yes)</p>
</dd>
<dt>large</dt><dd><p>Indicator for whether the cancer type is large cell carcinoma
(0=no, 1=yes)</p>
</dd>
</dl>



<h3>Source</h3>

<p><a href="https://cran.r-project.org/package=survival">https://cran.r-project.org/package=survival</a>
</p>


<h3>References</h3>


<ul>
<li><p> Kalbfleisch D and Prentice RL (1980), <em>The Statistical Analysis of
Failure Time Data</em>. Wiley, New York.
</p>
</li></ul>



<h3>See Also</h3>

<p><code>grpsurv()</code>
</p>

<hr>
<h2 id='plot_spline'>Plot spline curve for a fitted additive model</h2><span id='topic+plot_spline'></span>

<h3>Description</h3>

<p>Plots a spline curve for a single variable using a <code>grpreg</code> or <code>cv.grpreg</code> object for which an additive model was fit.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot_spline(
  fit,
  variable,
  lambda,
  which = NULL,
  partial = FALSE,
  type = "contrast",
  warnings = TRUE,
  points.par = NULL,
  add = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot_spline_+3A_fit">fit</code></td>
<td>
<p>A <code>grpreg</code> object. The model must have been fit using a <code>expand_spline</code> object.</p>
</td></tr>
<tr><td><code id="plot_spline_+3A_variable">variable</code></td>
<td>
<p>The name of the variable which will be plotted (character).</p>
</td></tr>
<tr><td><code id="plot_spline_+3A_lambda">lambda</code></td>
<td>
<p>Values of the regularization parameter <code>lambda</code> which will be used for the plot. If a vector is passed, a curve will be drawn for each value of lambda (numeric vector; if a <code>cv.grpreg</code> object is passed, the <code>lambda</code> value minimizing cross-validation error will be used as a default; otherwise, there is no default value)</p>
</td></tr>
<tr><td><code id="plot_spline_+3A_which">which</code></td>
<td>
<p>Index of penalty parameter <code>lambda</code> which will be used for the plot. If both <code>lambda</code> and <code>which</code> are specified, <code>lambda</code> takes precedence (integer vector).</p>
</td></tr>
<tr><td><code id="plot_spline_+3A_partial">partial</code></td>
<td>
<p>If <code>TRUE</code>, a scatter plot of the partial residuals is superimposed on the curve (logical; default = <code>FALSE</code>). If multiple lambdas are specified, the largest value is used to calculate the residuals.</p>
</td></tr>
<tr><td><code id="plot_spline_+3A_type">type</code></td>
<td>
<p>Type of plot to be produced (default = <code>"contrast"</code>). The following options are supported:
</p>

<ul>
<li><p> If <code>"conditional"</code>, the plot returned shows the value of the variable on the x-axis and the change in linear predictor on the y-axis, holding all other variables constant at their mean value.
</p>
</li>
<li><p> If <code>"contrast"</code>, the plot returned shows the effect on the linear predictor by moving the x variable away from its mean.
</p>
</li></ul>
</td></tr>
<tr><td><code id="plot_spline_+3A_warnings">warnings</code></td>
<td>
<p>If <code>FALSE</code>, warnings will be suppressed (default = <code>TRUE</code>).</p>
</td></tr>
<tr><td><code id="plot_spline_+3A_points.par">points.par</code></td>
<td>
<p>List of parameters (see <code><a href="graphics.html#topic+par">par()</a></code> to pass to <code><a href="graphics.html#topic+points">points()</a></code> when <code>partial=TRUE</code>.</p>
</td></tr>
<tr><td><code id="plot_spline_+3A_add">add</code></td>
<td>
<p>Add spline to existing plot? (default: FALSE)</p>
</td></tr>
<tr><td><code id="plot_spline_+3A_...">...</code></td>
<td>
<p>Further arguments to be passed to <code>plot()</code>. Note that these arguments also control the appearance of the lines.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>plot_spline()</code> takes a model fit using both the <code><a href="#topic+grpreg">grpreg()</a></code> and <code><a href="#topic+expand_spline">expand_spline()</a></code> functions and plots a spline curve for a given variable.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
Data &lt;- gen_nonlinear_data(n=1000)
X &lt;- expand_spline(Data$X)
fit &lt;- grpreg(X, Data$y)
plot_spline(fit, "V02", lambda = 0.03)
plot_spline(fit, "V02", which = c(10, 90))
plot_spline(fit, "V02", lambda = 0.03, partial=TRUE)
plot_spline(fit, "V02", lambda = 0.03, partial=TRUE, type='conditional')
plot_spline(fit, "V02", lambda = 0.03, partial=TRUE, lwd=6, col='yellow',
            points.par=list(pch=9, col='blue'))

op &lt;- par(mfrow=c(3,2), mar=c(4.5, 4.5, 0.25, 0.25))
for (i in 1:6) plot_spline(fit, sprintf("V%02d", i), lambda = 0.03, partial=TRUE)
par(op)

cvfit &lt;- cv.grpreg(X, Data$y)
plot_spline(cvfit, "V02")
plot_spline(cvfit, "V02", partial=TRUE)
</code></pre>

<hr>
<h2 id='plot.cv.grpreg'>Plots the cross-validation curve from a <code>cv.grpreg</code> object</h2><span id='topic+plot.cv.grpreg'></span>

<h3>Description</h3>

<p>Plots the cross-validation curve from a <code>cv.grpreg</code> object, along with
standard error bars.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'cv.grpreg'
plot(
  x,
  log.l = TRUE,
  type = c("cve", "rsq", "scale", "snr", "pred", "all"),
  selected = TRUE,
  vertical.line = TRUE,
  col = "red",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot.cv.grpreg_+3A_x">x</code></td>
<td>
<p>A <code>cv.grpreg</code> object.</p>
</td></tr>
<tr><td><code id="plot.cv.grpreg_+3A_log.l">log.l</code></td>
<td>
<p>Should horizontal axis be on the log scale?  Default is TRUE.</p>
</td></tr>
<tr><td><code id="plot.cv.grpreg_+3A_type">type</code></td>
<td>
<p>What to plot on the vertical axis.  <code>cve</code> plots the
cross-validation error (deviance); <code>rsq</code> plots an estimate of the
fraction of the deviance explained by the model (R-squared); <code>snr</code>
plots an estimate of the signal-to-noise ratio; <code>scale</code> plots, for
<code>family="gaussian"</code>, an estimate of the scale parameter (standard
deviation); <code>pred</code> plots, for <code>family="binomial"</code>, the estimated
prediction error; <code>all</code> produces all of the above.</p>
</td></tr>
<tr><td><code id="plot.cv.grpreg_+3A_selected">selected</code></td>
<td>
<p>If <code>TRUE</code> (the default), places an axis on top of the
plot denoting the number of groups in the model (i.e., that contain a
nonzero regression coefficient) at that value of <code>lambda</code>.</p>
</td></tr>
<tr><td><code id="plot.cv.grpreg_+3A_vertical.line">vertical.line</code></td>
<td>
<p>If <code>TRUE</code> (the default), draws a vertical line at
the value where cross-validaton error is minimized.</p>
</td></tr>
<tr><td><code id="plot.cv.grpreg_+3A_col">col</code></td>
<td>
<p>Controls the color of the dots (CV estimates).</p>
</td></tr>
<tr><td><code id="plot.cv.grpreg_+3A_...">...</code></td>
<td>
<p>Other graphical parameters to <code>plot</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>Error bars representing approximate +/- 1 SE (68\
plotted along with the estimates at value of <code>lambda</code>.  For <code>rsq</code>
and <code>snr</code>, these confidence intervals are quite crude, especially near
zero, and will hopefully be improved upon in later versions of
<code>grpreg</code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+grpreg">grpreg()</a></code>, <code><a href="#topic+cv.grpreg">cv.grpreg()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Birthweight data
data(Birthwt)
X &lt;- Birthwt$X
group &lt;- Birthwt$group

# Linear regression
y &lt;- Birthwt$bwt
cvfit &lt;- cv.grpreg(X, y, group)
plot(cvfit)
op &lt;- par(mfrow=c(2,2))
plot(cvfit, type="all")

## Logistic regression
y &lt;- Birthwt$low
cvfit &lt;- cv.grpreg(X, y, group, family="binomial")
par(op)
plot(cvfit)
par(mfrow=c(2,2))
plot(cvfit, type="all")
</code></pre>

<hr>
<h2 id='plot.grpreg'>Plot coefficients from a &quot;grpreg&quot; object</h2><span id='topic+plot.grpreg'></span>

<h3>Description</h3>

<p>Produces a plot of the coefficient paths for a fitted <code>grpreg</code> object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'grpreg'
plot(x, alpha = 1, legend.loc, label = FALSE, log.l = FALSE, norm = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot.grpreg_+3A_x">x</code></td>
<td>
<p>Fitted <code>"grpreg"</code> model.</p>
</td></tr>
<tr><td><code id="plot.grpreg_+3A_alpha">alpha</code></td>
<td>
<p>Controls alpha-blending.  Default is alpha=1.</p>
</td></tr>
<tr><td><code id="plot.grpreg_+3A_legend.loc">legend.loc</code></td>
<td>
<p>Where should the legend go?  If left unspecified, no
legend is drawn.  See <code><a href="graphics.html#topic+legend">legend</a></code> for details.</p>
</td></tr>
<tr><td><code id="plot.grpreg_+3A_label">label</code></td>
<td>
<p>If TRUE, annotates the plot with text labels in the right
margin describing which variable/group the corresponding line belongs to.</p>
</td></tr>
<tr><td><code id="plot.grpreg_+3A_log.l">log.l</code></td>
<td>
<p>Should horizontal axis be on the log scale?  Default is FALSE.</p>
</td></tr>
<tr><td><code id="plot.grpreg_+3A_norm">norm</code></td>
<td>
<p>If <code>TRUE</code>, plot the norm of each group, rather than the
individual coefficients.</p>
</td></tr>
<tr><td><code id="plot.grpreg_+3A_...">...</code></td>
<td>
<p>Other graphical parameters to <code>plot</code>, <code>matlines</code>, or
<code>legend</code></p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+grpreg">grpreg()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Fit model to birthweight data
data(Birthwt)
X &lt;- Birthwt$X
y &lt;- Birthwt$bwt
group &lt;- Birthwt$group
fit &lt;- grpreg(X, y, group, penalty="grLasso")

# Plot (basic)
plot(fit)

# Plot group norms, with labels in right margin
plot(fit, norm=TRUE, label=TRUE)

# Plot (miscellaneous options)
myColors &lt;- c("black", "red", "green", "blue", "yellow", "purple",
"orange", "brown")
plot(fit, legend.loc="topleft", col=myColors)
labs &lt;- c("Mother's Age", "# Phys. visits", "Hypertension", "Mother's weight",
          "# Premature", "Race", "Smoking", "Uterine irritability")
plot(fit, legend.loc="topleft", lwd=6, alpha=0.5, legend=labs)
plot(fit, norm=TRUE, legend.loc="topleft", lwd=6, alpha=0.5, legend=labs)
</code></pre>

<hr>
<h2 id='plot.grpsurv.func'>Plot survival curve for grpsurv model</h2><span id='topic+plot.grpsurv.func'></span>

<h3>Description</h3>

<p>Plot survival curve for a model that has been fit using <code>grpsurv</code>
followed by a prediction of the survival function using
<code>predict.grpsurv</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'grpsurv.func'
plot(x, alpha = 1, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot.grpsurv.func_+3A_x">x</code></td>
<td>
<p>A <code>'grpsurv.func'</code> object, which is returned by
<code>predict.grpsurv</code> if <code>type='survival'</code> is specified.  See
examples.</p>
</td></tr>
<tr><td><code id="plot.grpsurv.func_+3A_alpha">alpha</code></td>
<td>
<p>Controls alpha-blending (i.e., transparency).  Useful if many
overlapping lines are present.</p>
</td></tr>
<tr><td><code id="plot.grpsurv.func_+3A_...">...</code></td>
<td>
<p>Other graphical parameters to pass to <code>plot</code></p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Patrick Breheny
</p>


<h3>See Also</h3>

<p><code><a href="#topic+grpsurv">grpsurv</a></code>, <code><a href="#topic+predict.grpsurv">predict.grpsurv</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(Lung)
X &lt;- Lung$X
y &lt;- Lung$y
group &lt;- Lung$group
fit &lt;- grpsurv(X, y, group)

# A single survival curve
S &lt;- predict(fit, X[1,], type='survival', lambda=.05)
plot(S, xlim=c(0,200))

# Lots of survival curves
S &lt;- predict(fit, X, type='survival', lambda=.05)
plot(S, xlim=c(0,200), alpha=0.3)
</code></pre>

<hr>
<h2 id='predict.cv.grpreg'>Model predictions based on a fitted <code>grpreg</code> object</h2><span id='topic+predict.cv.grpreg'></span><span id='topic+coef.cv.grpreg'></span><span id='topic+predict.grpreg'></span><span id='topic+coef.grpreg'></span>

<h3>Description</h3>

<p>Similar to other predict methods, this function returns predictions from a
fitted <code>"grpreg"</code> object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'cv.grpreg'
predict(
  object,
  X,
  lambda = object$lambda.min,
  which = object$min,
  type = c("link", "response", "class", "coefficients", "vars", "groups", "nvars",
    "ngroups", "norm"),
  ...
)

## S3 method for class 'cv.grpreg'
coef(object, lambda = object$lambda.min, which = object$min, ...)

## S3 method for class 'grpreg'
predict(
  object,
  X,
  type = c("link", "response", "class", "coefficients", "vars", "groups", "nvars",
    "ngroups", "norm"),
  lambda,
  which = 1:length(object$lambda),
  ...
)

## S3 method for class 'grpreg'
coef(object, lambda, which = 1:length(object$lambda), drop = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict.cv.grpreg_+3A_object">object</code></td>
<td>
<p>Fitted <code>"grpreg"</code> or <code>"cv.grpreg"</code> model object.</p>
</td></tr>
<tr><td><code id="predict.cv.grpreg_+3A_x">X</code></td>
<td>
<p>Matrix of values at which predictions are to be made.  Not used for
<code>type="coefficients"</code></p>
</td></tr>
<tr><td><code id="predict.cv.grpreg_+3A_lambda">lambda</code></td>
<td>
<p>Values of the regularization parameter <code>lambda</code> at which
predictions are requested.  For values of <code>lambda</code> not in the sequence
of fitted models, linear interpolation is used.</p>
</td></tr>
<tr><td><code id="predict.cv.grpreg_+3A_which">which</code></td>
<td>
<p>Indices of the penalty parameter <code>lambda</code> at which
predictions are required.  By default, all indices are returned.  If
<code>lambda</code> is specified, this will override <code>which</code>.</p>
</td></tr>
<tr><td><code id="predict.cv.grpreg_+3A_type">type</code></td>
<td>
<p>Type of prediction: <code>"link"</code> returns the linear predictors;
<code>"response"</code> gives the fitted values; <code>"class"</code> returns the
binomial outcome with the highest probability; <code>"coefficients"</code> returns
the coefficients; <code>"vars"</code> returns the indices for the nonzero
coefficients; <code>"groups"</code> returns the indices for the groups with at
least one nonzero coefficient; <code>"nvars"</code> returns the number of nonzero
coefficients; <code>"ngroups"</code> returns the number of groups with at least
one nonzero coefficient; <code>"norm"</code> returns the L2 norm of the
coefficients in each group.</p>
</td></tr>
<tr><td><code id="predict.cv.grpreg_+3A_...">...</code></td>
<td>
<p>Not used.</p>
</td></tr>
<tr><td><code id="predict.cv.grpreg_+3A_drop">drop</code></td>
<td>
<p>By default, if a single value of <code>lambda</code> is supplied, a
vector of coefficients is returned.  Set <code>drop=FALSE</code> if you wish to
have <code>coef</code> always return a matrix (see <code><a href="base.html#topic+drop">drop</a></code>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>coef</code> and <code>predict</code> methods are provided for <code>"cv.grpreg"</code>
options as a convenience.  They simply call <code>coef.grpreg</code> and
<code>predict.grpreg</code> with <code>lambda</code> set to the value that minimizes the
cross-validation error.
</p>


<h3>Value</h3>

<p>The object returned depends on type.
</p>


<h3>Author(s)</h3>

<p>Patrick Breheny
</p>


<h3>See Also</h3>

<p><code>grpreg</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Fit penalized logistic regression model to birthweight data
data(Birthwt)
X &lt;- Birthwt$X
y &lt;- Birthwt$low
group &lt;- Birthwt$group
fit &lt;- grpreg(X, y, group, penalty="grLasso", family="binomial")

# Coef and predict methods
coef(fit, lambda=.001)
predict(fit, X, type="link", lambda=.07)[1:10]
predict(fit, X, type="response", lambda=.07)[1:10]
predict(fit, X, type="class", lambda=.01)[1:15]
predict(fit, type="vars", lambda=.07)
predict(fit, type="groups", lambda=.07)
predict(fit, type="norm", lambda=.07)

# Coef and predict methods for cross-validation
cvfit &lt;- cv.grpreg(X, y, group, family="binomial", penalty="grMCP")
coef(cvfit)
predict(cvfit, X)[1:10]
predict(cvfit, X, type="response")[1:10]
predict(cvfit, type="groups")
</code></pre>

<hr>
<h2 id='predict.grpsurv'>Model predictions for grpsurv objects</h2><span id='topic+predict.grpsurv'></span>

<h3>Description</h3>

<p>Similar to other predict methods, this function returns predictions from a fitted <code>grpsurv</code> object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'grpsurv'
predict(
  object,
  X,
  type = c("link", "response", "survival", "hazard", "median", "norm", "coefficients",
    "vars", "nvars", "groups", "ngroups"),
  lambda,
  which = 1:length(object$lambda),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict.grpsurv_+3A_object">object</code></td>
<td>
<p>Fitted <code>grpsurv</code> model object.</p>
</td></tr>
<tr><td><code id="predict.grpsurv_+3A_x">X</code></td>
<td>
<p>Matrix of values at which predictions are to be made. Not required for some <code>type</code> values.</p>
</td></tr>
<tr><td><code id="predict.grpsurv_+3A_type">type</code></td>
<td>
<p>Type of prediction:
</p>

<ul>
<li> <p><code>link</code>: linear predictors
</p>
</li>
<li> <p><code>response</code>: risk (i.e., <code>exp(link)</code>)
</p>
</li>
<li> <p><code>survival</code>: the estimated survival function
</p>
</li>
<li> <p><code>hazard</code>: the estimated cumulative hazard function
</p>
</li>
<li> <p><code>median</code>: median survival time
</p>
</li>
<li><p> The other options are all identical to their <code><a href="#topic+grpreg">grpreg()</a></code> counterparts
</p>
</li></ul>
</td></tr>
<tr><td><code id="predict.grpsurv_+3A_lambda">lambda</code></td>
<td>
<p>Regularization parameter at which predictions are requested. For values of <code>lambda</code> not in the sequence of fitted models, linear interpolation is used.</p>
</td></tr>
<tr><td><code id="predict.grpsurv_+3A_which">which</code></td>
<td>
<p>Indices of the penalty parameter <code>lambda</code> at which predictions are required. Default: all indices. If <code>lambda</code> is specified, this will override <code>which</code>.</p>
</td></tr>
<tr><td><code id="predict.grpsurv_+3A_...">...</code></td>
<td>
<p>Not used.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Estimation of baseline survival function conditional on the estimated values of <code>beta</code> is carried out according to the method described in Chapter 4.3 of Kalbfleisch and Prentice.
</p>


<h3>Value</h3>

<p>The object returned depends on type.
</p>


<h3>Author(s)</h3>

<p>Patrick Breheny
</p>


<h3>References</h3>


<ul>
<li><p> Kalbfleish JD and Prentice RL (2002). The Statistical Analysis of Failure Time Data, 2nd edition. Wiley.
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+grpsurv">grpsurv()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(Lung)
X &lt;- Lung$X

y &lt;- Lung$y
group &lt;- Lung$group
 
fit &lt;- grpsurv(X, y, group)
coef(fit, lambda=0.05)
head(predict(fit, X, type="link", lambda=0.05))
head(predict(fit, X, type="response", lambda=0.05))
 
# Survival function
S &lt;- predict(fit, X[1,], type="survival", lambda=0.05)
S(100)
S &lt;- predict(fit, X, type="survival", lambda=0.05)
plot(S, xlim=c(0,200))
 
# Medians
predict(fit, X[1,], type="median", lambda=0.05)
M &lt;- predict(fit, X, type="median")
M[1:10, 1:10]
 
# Nonzero coefficients
predict(fit, type="vars", lambda=c(0.1, 0.01))
predict(fit, type="nvars", lambda=c(0.1, 0.01))
</code></pre>

<hr>
<h2 id='residuals.grpreg'>Extract residuals from a grpreg or grpsurv fit</h2><span id='topic+residuals.grpreg'></span>

<h3>Description</h3>

<p>Currently, only deviance residuals are supported.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'grpreg'
residuals(object, lambda, which = 1:length(object$lambda), drop = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="residuals.grpreg_+3A_object">object</code></td>
<td>
<p>Object of class <code>grpreg</code> or <code>grpsurv</code>.</p>
</td></tr>
<tr><td><code id="residuals.grpreg_+3A_lambda">lambda</code></td>
<td>
<p>Values of the regularization parameter at which residuals are requested (numeric vector). For values of lambda not in the sequence of fitted models, linear interpolation is used.</p>
</td></tr>
<tr><td><code id="residuals.grpreg_+3A_which">which</code></td>
<td>
<p>Index of the penalty parameter at which residuals are requested (default = all indices). If <code>lambda</code> is specified, this take precedence over <code>which</code>.</p>
</td></tr>
<tr><td><code id="residuals.grpreg_+3A_drop">drop</code></td>
<td>
<p>By default, if a single value of lambda is supplied, a vector of residuals is returned (logical; default=<code>TRUE</code>). Set <code>drop=FALSE</code> if you wish to have the function always return a matrix (see <code><a href="base.html#topic+drop">drop()</a></code>).</p>
</td></tr>
<tr><td><code id="residuals.grpreg_+3A_...">...</code></td>
<td>
<p>Not used.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>data(Birthwt)
X &lt;- Birthwt$X
y &lt;- Birthwt$bwt
group &lt;- Birthwt$group
fit &lt;- grpreg(X, y, group, returnX=TRUE)
residuals(fit)[1:5, 1:5]
head(residuals(fit, lambda=0.1))
</code></pre>

<hr>
<h2 id='select'>Select an value of lambda along a grpreg path</h2><span id='topic+select'></span><span id='topic+select.grpreg'></span>

<h3>Description</h3>

<p>Selects a point along the regularization path of a fitted grpreg object
according to the AIC, BIC, or GCV criteria.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>select(obj, ...)

## S3 method for class 'grpreg'
select(
  obj,
  criterion = c("BIC", "AIC", "GCV", "AICc", "EBIC"),
  df.method = c("default", "active"),
  smooth = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="select_+3A_obj">obj</code></td>
<td>
<p>A fitted grpreg object.</p>
</td></tr>
<tr><td><code id="select_+3A_...">...</code></td>
<td>
<p>For S3 method compatibility.</p>
</td></tr>
<tr><td><code id="select_+3A_criterion">criterion</code></td>
<td>
<p>The criterion by which to select the regularization
parameter.  One of <code>"AIC"</code>, <code>"BIC"</code>, <code>"GCV"</code>, <code>"AICc"</code>,
or <code>"EBIC"</code>; default is <code>"BIC"</code>.</p>
</td></tr>
<tr><td><code id="select_+3A_df.method">df.method</code></td>
<td>
<p>How should effective model parameters be calculated?  One
of: <code>"active"</code>, which counts the number of nonzero coefficients; or
<code>"default"</code>, which uses the calculated <code>df</code> returned by
<code>grpreg</code>.  Default is <code>"default"</code>.</p>
</td></tr>
<tr><td><code id="select_+3A_smooth">smooth</code></td>
<td>
<p>Applies a smoother to the information criteria before
selecting the optimal value.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The criteria are defined as follows, where <code class="reqn">L</code> is the deviance (i.e,
-2 times the log-likelihood), <code class="reqn">\nu</code> is the degrees of freedom, and
<code class="reqn">n</code> is the sample size:
</p>
<p style="text-align: center;"><code class="reqn">AIC = L + 2\nu</code>
</p>
 <p style="text-align: center;"><code class="reqn">BIC = L + \log(n)\nu</code>
</p>
 <p style="text-align: center;"><code class="reqn">GCV = \frac{L}{(1-\nu/n)^2}</code>
</p>

<p style="text-align: center;"><code class="reqn">AICc = AIC + 2\frac{\nu(\nu+1)}{n-\nu-1}</code>
</p>
 <p style="text-align: center;"><code class="reqn">EBIC = BIC + 2 \log{p \choose \nu}</code>
</p>



<h3>Value</h3>

<p>A list containing:
</p>

<dl>
<dt>lambda</dt><dd><p>The selected value of the regularization parameter, <code>lambda</code>.</p>
</dd>
<dt>beta</dt><dd><p>The vector of coefficients at the chosen value of <code>lambda</code>.</p>
</dd>
<dt>df</dt><dd><p>The effective number of model parameters at the chosen value of <code>lambda</code>.</p>
</dd>
<dt>IC</dt><dd><p>A vector of the calculated model selection criteria for each point on the regularization path.</p>
</dd>
</dl>



<h3>See Also</h3>

<p><code><a href="#topic+grpreg">grpreg()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(Birthwt)
X &lt;- Birthwt$X
y &lt;- Birthwt$bwt
group &lt;- Birthwt$group
fit &lt;- grpreg(X, y, group, penalty="grLasso")
select(fit)
select(fit,crit="AIC",df="active")
plot(fit)
abline(v=select(fit)$lambda)
par(mfrow=c(1,3))
l &lt;- fit$lambda
xlim &lt;- rev(range(l))
plot(l, select(fit)$IC, xlim=xlim, pch=19, type="o", ylab="BIC")
plot(l, select(fit,"AIC")$IC, xlim=xlim, pch=19, type="o",ylab="AIC")
plot(l, select(fit,"GCV")$IC, xlim=xlim, pch=19, type="o",ylab="GCV")
</code></pre>

<hr>
<h2 id='summary.cv.grpreg'>Summarizing inferences based on cross-validation</h2><span id='topic+summary.cv.grpreg'></span><span id='topic+print.summary.cv.grpreg'></span>

<h3>Description</h3>

<p>Summary method for <code>cv.grpreg</code> or <code>cv.grpsurv</code> objects
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'cv.grpreg'
summary(object, ...)

## S3 method for class 'summary.cv.grpreg'
print(x, digits, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="summary.cv.grpreg_+3A_object">object</code></td>
<td>
<p>A <code>"cv.grpreg"</code> object.</p>
</td></tr>
<tr><td><code id="summary.cv.grpreg_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods.</p>
</td></tr>
<tr><td><code id="summary.cv.grpreg_+3A_x">x</code></td>
<td>
<p>A <code>"summary.cv.grpreg"</code> object.</p>
</td></tr>
<tr><td><code id="summary.cv.grpreg_+3A_digits">digits</code></td>
<td>
<p>Number of digits past the decimal point to print out.  Can be
a vector specifying different display digits for each of the five
non-integer printed values.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>summary(cvfit)</code> produces an object with S3 class
<code>"summary.cv.grpreg"</code>.  The class has its own print method and contains
the following list elements: </p>
<table role = "presentation">
<tr><td><code>penalty</code></td>
<td>
<p>The penalty used by
<code>grpreg</code>/<code>grpsurv</code>.</p>
</td></tr> <tr><td><code>model</code></td>
<td>
<p>The type of model:
<code>"linear"</code>, <code>"logistic"</code>, <code>"Poisson"</code>, <code>"Cox"</code>, etc.</p>
</td></tr>
<tr><td><code>n</code></td>
<td>
<p>Number of observations</p>
</td></tr> <tr><td><code>p</code></td>
<td>
<p>Number of regression coefficients
(not including the intercept).</p>
</td></tr> <tr><td><code>min</code></td>
<td>
<p>The index of <code>lambda</code> with
the smallest cross-validation error.</p>
</td></tr> <tr><td><code>lambda</code></td>
<td>
<p>The sequence of
<code>lambda</code> values used by <code>cv.grpreg</code>/<code>cv.grpsurv</code>.</p>
</td></tr>
<tr><td><code>cve</code></td>
<td>
<p>Cross-validation error (deviance).</p>
</td></tr> <tr><td><code>r.squared</code></td>
<td>
<p>Proportion
of variance explained by the model, as estimated by cross-validation.</p>
</td></tr>
<tr><td><code>snr</code></td>
<td>
<p>Signal to noise ratio, as estimated by cross-validation.</p>
</td></tr>
<tr><td><code>sigma</code></td>
<td>
<p>For linear regression models, the scale parameter estimate.</p>
</td></tr>
<tr><td><code>pe</code></td>
<td>
<p>For logistic regression models, the prediction error
(misclassification error).</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Patrick Breheny
</p>


<h3>See Also</h3>

<p><code><a href="#topic+grpreg">grpreg</a></code>, <code><a href="#topic+cv.grpreg">cv.grpreg</a></code>,
<code><a href="#topic+cv.grpsurv">cv.grpsurv</a></code>, <code><a href="#topic+plot.cv.grpreg">plot.cv.grpreg</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Birthweight data
data(Birthwt)
X &lt;- Birthwt$X
group &lt;- Birthwt$group

# Linear regression
y &lt;- Birthwt$bwt
cvfit &lt;- cv.grpreg(X, y, group)
summary(cvfit)

# Logistic regression
y &lt;- Birthwt$low
cvfit &lt;- cv.grpreg(X, y, group, family="binomial")
summary(cvfit)

# Cox regression
data(Lung)
cvfit &lt;- with(Lung, cv.grpsurv(X, y, group))
summary(cvfit)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
