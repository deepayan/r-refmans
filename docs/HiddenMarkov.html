<!DOCTYPE html><html><head><title>Help for package HiddenMarkov</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {HiddenMarkov}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#HiddenMarkov-package'><p>Overview of Package HiddenMarkov</p></a></li>
<li><a href='#BaumWelch'><p>Estimation Using Baum-Welch Algorithm</p></a></li>
<li><a href='#bwcontrol'><p>Control Parameters for Baum Welch Algorithm</p></a></li>
<li><a href='#Change+20Log'><p>Changes Made to Package HiddenMarkov</p></a></li>
<li><a href='#compdelta'><p>Marginal Distribution of Stationary Markov Chain</p></a></li>
<li><a href='#Demonstration'><p>Demonstration Examples</p></a></li>
<li><a href='#dthmm'><p>Discrete Time HMM Object (DTHMM)</p></a></li>
<li><a href='#Estep'><p>E-Step of EM Algorithm for DTHMM</p></a></li>
<li><a href='#forwardback'><p>Forward and Backward Probabilities of DTHMM</p></a></li>
<li><a href='#HiddenMarkov-defunct'><p>Defunct Functions in Package HiddenMarkov</p></a></li>
<li><a href='#HiddenMarkov-dthmm-deprecated'><p>Discrete Time HMM - Deprecated Functions</p></a></li>
<li><a href='#HiddenMarkov-internal'><p>Internally Used Functions</p></a></li>
<li><a href='#HiddenMarkov-mmpp-deprecated'><p>Markov Modulated Poisson Process - Deprecated Functions</p></a></li>
<li><a href='#logLik'><p>Log Likelihood of Hidden Markov Model</p></a></li>
<li><a href='#mchain'><p>Markov Chain Object</p></a></li>
<li><a href='#mmglm'><p>Markov Modulated GLM Object</p></a></li>
<li><a href='#mmglm-2nd-level-functions'><p>Markov Modulated Generalised Linear Model - 2nd Level Functions</p></a></li>
<li><a href='#mmpp'><p>Markov Modulated Poisson Process Object</p></a></li>
<li><a href='#mmpp-2nd-level-functions'><p>Markov Modulated Poisson Process - 2nd Level Functions</p></a></li>
<li><a href='#Mstep'><p>M-Step of EM Algorithm for DTHMM</p></a></li>
<li><a href='#neglogLik'><p>Negative Log-Likelihood</p></a></li>
<li><a href='#probhmm'><p>Conditional Distribution Function of DTHMM</p></a></li>
<li><a href='#residuals'><p>Residuals of Hidden Markov Model</p></a></li>
<li><a href='#simulate'><p>Simulate Hidden Markov Process</p></a></li>
<li><a href='#summary'><p>Summary of Hidden Markov Model</p></a></li>
<li><a href='#Transform-Parameters'><p>Transform Transition or Rate Matrices to Vector</p></a></li>
<li><a href='#Viterbi'><p>Viterbi Algorithm for Hidden Markov Model</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Title:</td>
<td>Hidden Markov Models</td>
</tr>
<tr>
<td>Version:</td>
<td>1.8-13</td>
</tr>
<tr>
<td>Date:</td>
<td>2021-04-27</td>
</tr>
<tr>
<td>Author:</td>
<td>David Harte</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>David Harte &lt;d.s.harte@gmail.com&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Contains functions for the analysis of Discrete Time Hidden Markov Models, Markov Modulated GLMs and the Markov Modulated Poisson Process. It includes functions for simulation, parameter estimation, and the Viterbi algorithm. See the topic "HiddenMarkov" for an introduction to the package, and "Change Log" for a list of recent changes. The algorithms are based of those of Walter Zucchini.</td>
</tr>
<tr>
<td>Suggests:</td>
<td>parallel</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://www.statsresearch.co.nz/dsh/sslib/">https://www.statsresearch.co.nz/dsh/sslib/</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2021-04-26 21:27:50 UTC; david</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2021-04-27 13:30:06 UTC</td>
</tr>
</table>
<hr>
<h2 id='HiddenMarkov-package'>Overview of Package HiddenMarkov</h2><span id='topic+HiddenMarkov-package'></span><span id='topic+HiddenMarkov'></span>

<h3>Description</h3>

<p>In this topic we give an overview of the package.
</p>


<h3>Classes of Hidden Markov Models Analysed</h3>

<p>The classes of models currently fitted by the package are listed below. Each are defined within an object that contains the data, current parameter values, and other model characteristics.
</p>

<dl>
<dt>Discrete Time Hidden Markov Model:</dt><dd>
<p>is described under the topic <code><a href="#topic+dthmm">dthmm</a></code>. This model can be simulated or fitted to data by defining the required model structure within an object of class <code>"<a href="#topic+dthmm">dthmm</a>"</code>.</p>
</dd>
<dt>Markov Modulated Generalised Linear Model:</dt><dd>
<p>is described under the topic <code><a href="#topic+mmglm1">mmglm1</a></code>.</p>
</dd>
<dt>Markov Modulated Generalised Linear Longitudinal Model:</dt><dd>
<p>is described under the topic <code><a href="#topic+mmglmlong1">mmglmlong1</a></code>.</p>
</dd>
<dt>Markov Modulated Poisson Process:</dt><dd>
<p>is described under the topic <code><a href="#topic+mmpp">mmpp</a></code>. This model can be simulated or fitted to data by defining the required model structure within an object of class <code>"<a href="#topic+mmpp">mmpp</a>"</code>.</p>
</dd>
</dl>



<h3>Main Tasks Performed by the Package</h3>

<p>The main tasks performed by the package are listed below. These can be achieved by calling the appropriate generic function.
</p>

<dl>
<dt>Simulation of HMMs:</dt><dd><p>can be performed by the function <code><a href="#topic+simulate">simulate</a></code>.</p>
</dd>
<dt>Parameter Estimation:</dt><dd><p>can be performed by the functions <code><a href="#topic+BaumWelch">BaumWelch</a></code> (EM algorithm), or <code><a href="#topic+neglogLik">neglogLik</a></code> together with <code><a href="stats.html#topic+nlm">nlm</a></code> or <code><a href="stats.html#topic+optim">optim</a></code> (Newton type methods or grid searches).</p>
</dd>
<dt>Model Residuals:</dt><dd><p>can be extracted with the function <code><a href="#topic+residuals">residuals</a></code>.</p>
</dd>
<dt>Model Summary:</dt><dd><p>can be extracted with the function <code><a href="#topic+summary">summary</a></code>.</p>
</dd>
<dt>Log-Likelihood:</dt><dd><p>can be calculated with the function <code><a href="#topic+logLik">logLik</a></code>.</p>
</dd>
<dt>Prediction of the Markov States:</dt><dd><p>can be performed by the function <code><a href="#topic+Viterbi">Viterbi</a></code>.</p>
</dd>
</dl>

<p>All other functions in the package are called from within the above generic functions, and only need to be used if their output is specifically required. We have referred to some of these other functions as &ldquo;2nd level&rdquo; functions, for example see the topic <code><a href="#topic+mmpp-2nd-level-functions">mmpp-2nd-level-functions</a></code>.
</p>


<h3>Organisation of Topics in the Package</h3>


<dl>
<dt>Cited References:</dt><dd><p>anywhere in the manual are only listed within this topic.</p>
</dd>
<dt>General Documentation:</dt><dd><p>topics summarising general structure are indexed under the keyword &ldquo;documentation&rdquo; in the Index.</p>
</dd>
</dl>



<h3>Acknowledgement</h3>

<p>Many of the functions contained in the package are based on those of Walter Zucchini (2005).
</p>


<h3>References</h3>

<p>Baum, L.E.; Petrie, T.; Soules, G. &amp; Weiss, N. (1970). A maximization technique occurring in the statistical analysis of probabilistic functions of Markov chains. <em>Annals of Mathematical Statistics</em> <b>41(1)</b>, 164&ndash;171. doi: <a href="https://doi.org/10.1214/aoms/1177697196">10.1214/aoms/1177697196</a>
</p>
<p>Charnes, A.; Frome, E.L. &amp; Yu, P.L. (1976). The equivalence of generalized least squares and maximum likelihood estimates in the exponential family. <em>J. American Statist. Assoc.</em> <b>71(353)</b>, 169&ndash;171. doi: <a href="https://doi.org/10.2307/2285762">10.2307/2285762</a>
</p>
<p>Dempster, A.P.; Laird, N.M. &amp; Rubin, D.B. (1977). Maximum likelihood from incomplete data via the EM algorithm (with discussion). <em>J. Royal Statist. Society B</em> <b>39(1)</b>, 1&ndash;38. URL: <a href="https://www.jstor.org/stable/2984875">https://www.jstor.org/stable/2984875</a>
</p>
<p>Elliott, R.J.; Aggoun, L. &amp; Moore, J.B. (1994). <em>Hidden Markov Models: Estimation and Control.</em> Springer-Verlag, New York. doi: <a href="https://doi.org/10.1007/978-0-387-84854-9">10.1007/978-0-387-84854-9</a>
</p>
<p>Harte, D. (2019). <em>Mathematical Background Notes for Package &ldquo;HiddenMarkov&rdquo;.</em> Statistics Research Associates, Wellington. URL: <a href="https://www.statsresearch.co.nz/dsh/sslib/manuals/notes.pdf">https://www.statsresearch.co.nz/dsh/sslib/manuals/notes.pdf</a>
</p>
<p>Hartley, H.O. (1958). Maximum likelihood estimation from incomplete data. <em>Biometrics</em> <b>14(2)</b>, 174&ndash;194. doi: <a href="https://doi.org/10.2307/2527783">10.2307/2527783</a>
</p>
<p>Klemm, A.; Lindemann, C. &amp; Lohmann, M. (2003). Modeling IP traffic using the batch Markovian arrival process. <em>Performance Evaluation</em> <b>54(2)</b>, 149&ndash;173. doi: <a href="https://doi.org/10.1016/S0166-5316(03)00067-1">10.1016/S0166-5316(03)00067-1</a>
</p>
<p>MacDonald, I.L. &amp; Zucchini, W. (1997). <em>Hidden Markov and Other Models for Discrete-valued Time Series.</em> Chapman and Hall/CRC, Boca Raton.
</p>
<p>McCullagh, P. &amp; Nelder, J.A. (1989). <em>Generalized Linear Models (2nd Edition).</em> Chapman and Hall, London.
</p>
<p>Rabiner, L.R. (1989). A tutorial on hidden Markov models and selected applications in speech recognition. <em>Proceedings of the IEEE</em> <b>77(2)</b>, 257&ndash;286. doi: <a href="https://doi.org/10.1109/5.18626">10.1109/5.18626</a>
</p>
<p>Roberts, W.J.J.; Ephraim, Y. &amp; Dieguez, E. (2006). On Ryden's EM algorithm for estimating MMPPs. <em>IEEE Signal Processing Letters</em> <b>13(6)</b>, 373&ndash;376. doi: <a href="https://doi.org/10.1109/LSP.2006.871709">10.1109/LSP.2006.871709</a>
</p>
<p>Ryden, T. (1994). Parameter estimation for Markov modulated Poisson processes. <em>Stochastic Models</em> <b>10(4)</b>, 795&ndash;829. doi: <a href="https://doi.org/10.1080/15326349408807323">10.1080/15326349408807323</a>
</p>
<p>Ryden, T. (1996). An EM algorithm for estimation in Markov-modulated Poisson processes. <em>Computational Statistics &amp; Data Analysis</em> <b>21(4)</b>, 431&ndash;447. doi: <a href="https://doi.org/10.1016/0167-9473(95)00025-9">10.1016/0167-9473(95)00025-9</a>
</p>
<p>Zucchini, W. (2005). <em>Hidden Markov Models Short Course, 3&ndash;4 April 2005.</em> Macquarie University, Sydney.
</p>

<hr>
<h2 id='BaumWelch'>Estimation Using Baum-Welch Algorithm</h2><span id='topic+BaumWelch'></span><span id='topic+BaumWelch.dthmm'></span><span id='topic+BaumWelch.mmglm0'></span><span id='topic+BaumWelch.mmglm1'></span><span id='topic+BaumWelch.mmglmlong1'></span><span id='topic+BaumWelch.mmpp'></span>

<h3>Description</h3>

<p>Estimates the parameters of a hidden Markov model. The Baum-Welch algorithm (Baum et al, 1970) referred to in the HMM literature is a version of the EM algorithm (Dempster et al, 1977). See Hartley (1958) for an earlier application of the EM methodology, though not referred to as such.</p>


<h3>Usage</h3>

<pre><code class='language-R'>BaumWelch(object, control, ...)
## S3 method for class 'dthmm'
BaumWelch(object, control = bwcontrol(), ...)
## S3 method for class 'mmglm0'
BaumWelch(object, control = bwcontrol(), ...)
## S3 method for class 'mmglm1'
BaumWelch(object, control = bwcontrol(), ...)
## S3 method for class 'mmglmlong1'
BaumWelch(object, control = bwcontrol(), PSOCKcluster=NULL,
          tmpfile=NULL, ...)
## S3 method for class 'mmpp'
BaumWelch(object, control = bwcontrol(), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="BaumWelch_+3A_object">object</code></td>
<td>
<p>an object of class <code>"<a href="#topic+dthmm">dthmm</a>"</code>, <code>"<a href="#topic+mmglm0">mmglm0</a>"</code>, <code>"<a href="#topic+mmglm1">mmglm1</a>"</code>, <code>"<a href="#topic+mmglmlong1">mmglmlong1</a>"</code>, or <code>"<a href="#topic+mmpp">mmpp</a>"</code>.</p>
</td></tr>
<tr><td><code id="BaumWelch_+3A_control">control</code></td>
<td>
<p>a list of control settings for the iterative process. These can be changed by using the function <code><a href="#topic+bwcontrol">bwcontrol</a></code>.</p>
</td></tr>
<tr><td><code id="BaumWelch_+3A_psockcluster">PSOCKcluster</code></td>
<td>
<p>see section below called &ldquo;Parallel Processing&rdquo;.</p>
</td></tr>
<tr><td><code id="BaumWelch_+3A_tmpfile">tmpfile</code></td>
<td>
<p>name of a file (.Rda) into which estimates are written at each 10th iteration. The model object is called <code>object</code>. If <code>NULL</code> (default), no file is created.</p>
</td></tr>
<tr><td><code id="BaumWelch_+3A_...">...</code></td>
<td>
<p>other arguments.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The initial parameter values used by the EM algorithm are those that are contained within the input <code>object</code>.
</p>
<p>The code for the methods <code>"<a href="#topic+dthmm">dthmm</a>"</code>, <code>"<a href="#topic+mmglm0">mmglm0</a>"</code>, <code>"<a href="#topic+mmglm1">mmglm1</a>"</code>,<code>"<a href="#topic+mmglmlong1">mmglmlong1</a>"</code> and <code>"<a href="#topic+mmpp">mmpp</a>"</code> can be viewed by appending <code>BaumWelch.dthmm</code>, <code>BaumWelch.mmglm0</code>, <code>BaumWelch.mmglm1</code>, <code>BaumWelch.mmglmlong1</code>  or <code>BaumWelch.mmpp</code>, respectively, to <code>HiddenMarkov:::</code>, on the <span class="rlang"><b>R</b></span> command line; e.g. <code>HiddenMarkov:::dthmm</code>. The three colons are needed because these method functions are not in the exported NAMESPACE.
</p>


<h3>Value</h3>

<p>The output object (a <code><a href="base.html#topic+list">list</a></code>) with have the same class as the input, and will have the same components. The parameter values will be replaced by those estimated by this function. The object will also contain additional components. 
</p>
<p>An object of class <code>"<a href="#topic+dthmm">dthmm</a>"</code> will also contain
</p>
<table>
<tr><td><code>u</code></td>
<td>
<p>an <code class="reqn">n \times m</code> matrix containing estimates of the conditional expectations. See &ldquo;Details&rdquo; in <code><a href="#topic+Estep">Estep</a></code>.</p>
</td></tr>
<tr><td><code>v</code></td>
<td>
<p>an <code class="reqn">n \times m \times m</code> array containing estimates of the conditional expectations. See &ldquo;Details&rdquo; in <code><a href="#topic+Estep">Estep</a></code>.</p>
</td></tr>
<tr><td><code>LL</code></td>
<td>
<p>value of log-likelihood at the end.</p>
</td></tr>
<tr><td><code>iter</code></td>
<td>
<p>number of iterations performed.</p>
</td></tr>
<tr><td><code>diff</code></td>
<td>
<p>difference between final and previous log-likelihood.</p>
</td></tr>
</table>


<h3>Parallel Processing</h3>

<p>In longitudinal models, the forward and backward equations need to be calculated for each individual subject. These can be done independently, the results being concatenated to be used in the E-step. If the argument <code>PSOCKcluster</code> is set, subjects are divided equally between each node in the cluster for the calculation of the forward and backward equations. This division is very basic, and assumes that all nodes run at a roughly comparable speed.
</p>
<p>If the communication between nodes is slow and the dataset is small, then the time taken to allocate the work to the various nodes may in fact take more time than simply using one processor to perform all of the calculations.
</p>
<p>The required steps in initiating parallel processing are as follows.
</p>
<pre>
#   load the "parallel" package
library(parallel)

#   define the SNOW cluster object, e.g. a SOCK cluster
#   where each node has the same R installation.
cl &lt;- makePSOCKcluster(c("localhost", "horoeka.localdomain", 
                         "horoeka.localdomain", "localhost"))

#   A more general setup: Totara is Fedora, Rimu is Debian:
#   Use 2 processors on Totara, 1 on Rimu:
totara  &lt;- list(host="localhost",
                rscript="/usr/lib/R/bin/Rscript",
                snowlib="/usr/lib/R/library")
rimu    &lt;- list(host="rimu.localdomain",
                rscript="/usr/lib/R/bin/Rscript",
                snowlib="/usr/local/lib/R/site-library")
cl &lt;- makeCluster(list(totara, totara, rimu), type="SOCK")

#   then define the required model object
#   say the model object is called x
BaumWelch(x, PSOCKcluster=cl)

#   stop the R jobs on the slave machines
stopCluster(cl)
</pre>
<p>Note that the communication method does not need to be <code>SOCKS</code>; see the <span class="pkg">parallel</span> package documentation, topic <code><a href="parallel.html#topic+makeCluster">makeCluster</a></code>, for other options. Further, if some nodes are on other machines, the firewalls may need to be tweaked. The master machine initiates the <span class="rlang"><b>R</b></span> jobs on the slave machines by communicating through port 22 (use of security keys are needed rather than passwords), and subsequent communications through port 10187. Again, these details can be tweaked in the options settings within the <span class="pkg">parallel</span> package.
</p>


<h3>References</h3>

<p>Cited references are listed on the <a href="#topic+HiddenMarkov">HiddenMarkov</a> manual page.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+logLik">logLik</a></code>, <code><a href="#topic+residuals">residuals</a></code>, <code><a href="#topic+simulate">simulate</a></code>, <code><a href="#topic+summary">summary</a></code>, <code><a href="#topic+neglogLik">neglogLik</a></code></p>

<hr>
<h2 id='bwcontrol'>Control Parameters for Baum Welch Algorithm</h2><span id='topic+bwcontrol'></span>

<h3>Description</h3>

<p>Creates a list of parameters that control the operation of <code><a href="#topic+BaumWelch">BaumWelch</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bwcontrol(maxiter = 500, tol = 1e-05, prt = TRUE, posdiff = TRUE,
          converge = expression(diff &lt; tol))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bwcontrol_+3A_maxiter">maxiter</code></td>
<td>
<p>is the maximum number of iterations, default is 500.</p>
</td></tr>
<tr><td><code id="bwcontrol_+3A_tol">tol</code></td>
<td>
<p>is the convergence criterion, default is 0.00001.</p>
</td></tr>
<tr><td><code id="bwcontrol_+3A_prt">prt</code></td>
<td>
<p>is logical, and determines whether information is printed at each iteration; default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="bwcontrol_+3A_posdiff">posdiff</code></td>
<td>
<p>is logical, and determines whether the iterative process stops if a negative log-likelihood difference occurs, default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="bwcontrol_+3A_converge">converge</code></td>
<td>
<p>is an expression giving the convergence criterion. The default is the difference between successive values of the log-likelihood.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>#    Increase the maximum number of iterations to 1000.
#    All other components will retain their default values.
a &lt;- bwcontrol(maxiter=1000)
print(a)
</code></pre>

<hr>
<h2 id='Change+20Log'>Changes Made to Package HiddenMarkov</h2><span id='topic+Changes'></span>

<h3>Description</h3>

<p>This page contains a listing of recent changes made to the package.
</p>


<h3>Details</h3>


<ol>
<li><p> Since we have included different classes of HMMs (see <code><a href="#topic+dthmm">dthmm</a></code>, <code><a href="#topic+mmglm0">mmglm0</a></code> and <code><a href="#topic+mmpp">mmpp</a></code>), it is much tidier to use an object orientated approach. This ensures that the functions across all models follow a more consistent naming convention, and also the argument list for the different model functions are more simple and consistent (see <code><a href="#topic+HiddenMarkov">HiddenMarkov</a></code>). (14 Sep 2007)
</p>
</li>
<li><p> The main tasks (model fitting, residuals, simulation, Viterbi, etc) can now be called by generic functions (see topic <code><a href="#topic+HiddenMarkov">HiddenMarkov</a></code>). The package documentation has been rearranged so that these generic functions contain the documentation for all model types (e.g. see <code><a href="#topic+BaumWelch">BaumWelch</a></code>). (14 Sep 2007)
</p>
</li>
<li><p> There are a number of functions, still contained in the package, that are obsolete. This is either because they do not easily fit into the current naming convention used to implement the more object orientated approach, or their argument list is slightly complicated. These functions have been grouped in the topics <code>dthmm.obsolete</code> and <code>mmpp.obsolete</code>. (14 Sep 2007)
</p>
</li>
<li><p> There are various <em>second level</em> functions. For example, the model fitting is achieved by the generic <code><a href="#topic+BaumWelch">BaumWelch</a></code> function. However, this will call functions to do the E-step, M-step, forward and backward probabilities, and so on. At the moment, these <em>second level</em> functions have not been modified into an object orientated approach. It is not clear at this point whether this would be advantageous. If one went down this route, then one would probably group all of the E-step functions (for all models) under the same topic. If not, then it may be best to group all second level functions for each model under the same topic (e.g. <code><a href="#topic+forwardback">forwardback</a></code>, <code><a href="#topic+probhmm">probhmm</a></code> and <code><a href="#topic+Estep">Estep</a></code> would be grouped together, being the second level functions for the <code><a href="#topic+dthmm">dthmm</a></code> model). (14 Sep 2007)
</p>
</li>
<li><p> The original function called <code>Viterbi</code> has been renamed to <code><a href="#topic+Viterbihmm">Viterbihmm</a></code>, and <code><a href="#topic+Viterbi">Viterbi</a></code> is now a generic function. (14 Sep 2007)
</p>
</li>
<li><p> Programming code that uses old versions of the functions should still work with this revised version of the package. However, you will get warning messages stating that certain functions are deprecated, and suggesting a possible alternative. To get a quick overview of the programming style, have a look at the examples in topic <code><a href="#topic+dthmm">dthmm</a></code>. (09 Nov 2007)
</p>
</li>
<li> <p><code><a href="#topic+forwardback">forwardback</a></code>: <code>for</code> loops replaced by Fortran code; much faster. The corresponding R code is still contained within the function in case the Fortran has incompatibility issues. (23 Nov 2007)
</p>
</li>
<li> <p><code><a href="#topic+forwardback.mmpp">forwardback.mmpp</a></code>: <code>for</code> loops replaced by Fortran code. The corresponding R code is still contained within the function in case the Fortran has incompatibility issues. (24 Nov 2007)
</p>
</li>
<li> <p><code><a href="#topic+Estep.mmpp">Estep.mmpp</a></code>: <code>for</code> loops replaced by Fortran code. Cuts time considerably. These loops in R used far more time than the forward and backward equations. The corresponding R code is still contained within the function in case the Fortran has incompatibility issues. (27 Nov 2007)
</p>
</li>
<li> <p><code><a href="#topic+forwardback.mmpp">forwardback.mmpp</a></code>, <code><a href="#topic+forwardback">forwardback</a></code> and <code><a href="#topic+Estep.mmpp">Estep.mmpp</a></code>: argument <code>fortran</code> added. (3 Dec 2007)
</p>
</li>
<li> <p><code><a href="#topic+forwardback">forwardback</a></code>, <code><a href="#topic+forwardback.mmpp">forwardback.mmpp</a></code> and <code><a href="#topic+Estep.mmpp">Estep.mmpp</a></code>: inclusion of all variable sized arrays in the Fortran subroutine call to be compatible with non gfortran compilers (3 Dec 2007); more added for calls to Fortran subroutines <code>multi1</code> and <code>multi2</code>. (6 Dec 2007)
</p>
</li>
<li> <p><code><a href="#topic+Estep.mmpp">Estep.mmpp</a></code>: error in Fortran code of loop 6; <code>j1=0</code> to <code>j1=1</code>. (5 Dec 2007)
</p>
</li>
<li> <p><code><a href="#topic+BaumWelch.mmpp">BaumWelch.mmpp</a></code>: <code>if (diff &lt; 0) stop ...</code> to <code>if (diff &lt; 0 &amp; control$posdiff) stop ...</code>, consistent with <code><a href="#topic+BaumWelch.dthmm">BaumWelch.dthmm</a></code>. (11 Dec 2007)
</p>
</li>
<li> <p><code><a href="#topic+logLik.dthmm">logLik.dthmm</a></code>, <code><a href="#topic+logLik.mmglm0">logLik.mmglm0</a></code>, <code><a href="#topic+logLik.mmpp">logLik.mmpp</a></code>: <code>for</code> loop replaced by Fortran code. (15 Feb 2008)
</p>
</li>
<li> <p><code><a href="#topic+dthmm">dthmm</a></code>: argument <code>discrete</code> set automatically for known distributions, stops if not set for unknown distributions. (15 Feb 2008)
</p>
</li>
<li> <p><code><a href="#topic+neglogLik">neglogLik</a></code>, <code><a href="#topic+Pi2vector">Pi2vector</a></code>, <code><a href="#topic+vector2Pi">vector2Pi</a></code>, <code><a href="#topic+Q2vector">Q2vector</a></code>, <code><a href="#topic+vector2Q">vector2Q</a></code>: new functions providing an alternative means of calculating maximum likelihood parameter estimates. (18 Feb 2008)
</p>
</li>
<li> <p><code><a href="#topic+dthmm">dthmm</a></code>: argument <code>nonstat</code> was not set correctly. (21 Jun 2008)
</p>
</li>
<li><p> Hyperlinks on package vignettes page. (22 Jun 2008)
</p>
</li>
<li> <p><code><a href="#topic+mmpp">mmpp</a></code>: argument <code>nonstat</code> was not set correctly. (23 Jun 2008)
</p>
</li>
<li><p> The manual pages <code><a href="#topic+HiddenMarkov-dthmm-deprecated">HiddenMarkov-dthmm-deprecated</a></code> and <code><a href="#topic+HiddenMarkov-mmpp-deprecated">HiddenMarkov-mmpp-deprecated</a></code> have been given a keyword of &ldquo;internal&rdquo;. This hides them from the listing of package functions. (3 Jul 2008)
</p>
</li>
<li><p> All cited references are now only listed in the topic <code><a href="#topic+HiddenMarkov">HiddenMarkov</a></code>. (3 Jul 2008)
</p>
</li>
<li> <p><code><a href="#topic+neglogLik">neglogLik</a></code>: argument <code>updatep</code> has been renamed to <code>pmap</code>. (9 Jul 2008)
</p>
</li>
<li> <p><code><a href="#topic+neglogLik">neglogLik</a></code>: format of this function changed to be consistent with that in package <span class="pkg">PtProcess</span>. Argument <code>p</code> renamed as <code>params</code>. (07 Aug 2008)
</p>
</li>
<li> <p><code><a href="#topic+mmglm0">mmglm0</a></code>: remove some LaTeX specific formatting to be compatible with <span class="rlang"><b>R</b></span> 2.9.0. (26 Jan 2009)
</p>
</li>
<li> <p><code><a href="#topic+Viterbi">Viterbi</a></code>: Correct hyperlink to base function <code>which.max</code>. (10 Oct 2009)
</p>
</li>
<li><p> Tidied HTML representation of equations in manual pages. (15 Dec 2009)
</p>
</li>
<li> <p><code>mmglm</code>: Renamed to <code><a href="#topic+mmglm0">mmglm0</a></code>, new version <code><a href="#topic+mmglm1">mmglm1</a></code>. See manual page for more details. (5 Jan 2010)
</p>
</li>
<li> <p><code><a href="#topic+mmglmlong1">mmglmlong1</a></code>: new function for longitudinal data. (18 Jan 2010)
</p>
</li>
<li> <p><code><a href="#topic+dthmm">dthmm</a></code>: clarify argument <code>distn</code> on manual page, and nature of parameter estimates when the Markov chain is stationary. (04 Feb 2010)
</p>
</li>
<li> <p><code><a href="#topic+BaumWelch.mmglmlong1">BaumWelch.mmglmlong1</a></code>: new argument <code>tmpfile</code> added. (13 Feb 2010)
</p>
</li>
<li> <p><code><a href="#topic+Viterbi">Viterbi</a></code>: Methods added for objects of class <code>"<a href="#topic+mmglm1">mmglm1</a>"</code> and <code>"<a href="#topic+mmglmlong1">mmglmlong1</a>"</code>. (29 Jul 2010)
</p>
</li>
<li> <p><code><a href="#topic+logLik">logLik</a></code>: Method added for object of class <code>"<a href="#topic+mmglmlong1">mmglmlong1</a>"</code>. (30 Jul 2010)
</p>
</li>
<li> <p><code><a href="#topic+forwardback.dthmm">forwardback.dthmm</a></code>, <code><a href="#topic+forwardback.mmpp">forwardback.mmpp</a></code>: New argument <code>"fwd.only"</code>. (30 Jul 2010)
</p>
</li>
<li> <p><code><a href="#topic+logLik.dthmm">logLik.dthmm</a></code>: Calls <code><a href="#topic+forwardback.dthmm">forwardback.dthmm</a></code> to perform calculations. (30 Jul 2010)
</p>
</li>
<li> <p><code><a href="#topic+logLik.mmpp">logLik.mmpp</a></code>: Calls <code><a href="#topic+forwardback.mmpp">forwardback.mmpp</a></code> to perform calculations. (30 Jul 2010)
</p>
</li>
<li> <p><code><a href="#topic+Viterbi">Viterbi</a></code>: Now generates an error message when applied to objects of class <code>"<a href="#topic+mmpp">mmpp</a>"</code>. Method not currently available. (03 Aug 2010)
</p>
</li>
<li> <p><code>"<a href="#topic+Viterbi.mmglm1">Viterbi.mmglm1</a>"</code>: Fixed bug with number of Bernoulli trials specification when using a binomial family. (05 Aug 2010)
</p>
</li>
<li> <p><code><a href="#topic+residuals.dthmm">residuals.dthmm</a></code>, <code><a href="#topic+probhmm">probhmm</a></code>: Modify for greater efficiency and generality to accommodate more general models. Arguments of <code><a href="#topic+probhmm">probhmm</a></code> have also been changed. (05 Aug 2010)
</p>
</li>
<li> <p><code>residualshmm</code>: Made defunct, incompatible with revised <code><a href="#topic+probhmm">probhmm</a></code>. (05 Aug 2010)
</p>
</li>
<li> <p><code><a href="#topic+residuals">residuals</a></code>: Methods added for objects of class <code>"<a href="#topic+mmglm1">mmglm1</a>"</code> and <code>"<a href="#topic+mmglmlong1">mmglmlong1</a>"</code>. Generates an error message when applied to objects of class <code>"<a href="#topic+mmpp">mmpp</a>"</code>, currently no method available. (05 Aug 2010)
</p>
</li>
<li><p> Add CITATION file. (24 Sep 2010)
</p>
</li>
<li> <p><code><a href="#topic+makedistn">makedistn</a></code>: Change <code>eval(parse(text=paste(x, " list(log=log)))", sep="")))</code> to <br /> <code>eval(parse(text=paste(x, " list(log.p=log)))", sep="")))</code>. (19 Dec 2010)
</p>
</li>
<li> <p><code><a href="#topic+pglm">pglm</a></code>, <code><a href="#topic+pmmglm">pmmglm</a></code>: Change all <code>log</code> arguments to <code>log.p</code>. (19 Dec 2010)
</p>
</li>
<li><p> Revise examples in <code>/tests</code> directory. (02 May 2011)
</p>
</li>
<li><p> Implement very basic NAMESPACE and remove file <code>/R/zzz.R</code>. (5 Nov 2011)
</p>
</li>
<li><p> List functions explicitly in NAMESPACE. (19 Dec 2011)
</p>
</li>
<li> <p><code><a href="#topic+mmglm">mmglm</a></code> and <code><a href="#topic+neglogLik">neglogLik</a></code>: Restrict the number of iterations in examples on manual pages to minimise time during package checks. (19 Dec 2011)
</p>
</li>
<li> <p><code>modify.func</code>: New function to allow the user to modify package functions in the NAMESPACE set-up. This function violates the CRAN policy as users are not supposed to change the NAMESPACE on such packages. Some examples where it is required to modify package functions will not work, for example, the second example in <code><a href="#topic+Mstep">Mstep</a></code>. (7 Mar 2012)
</p>
</li>
<li> <p><code>modify.func</code>: Function removed. See the second example in <code><a href="#topic+Mstep">Mstep</a></code> for a work-around when package functions need to be modified. (14 Apr 2012)
</p>
</li>
<li> <p><code><a href="#topic+Mstep">Mstep</a></code>: Revised documentation about distribution requirements and ways to include other distributions into the software framework. (14 Apr 2012)
</p>
</li>
<li><p> The package <span class="pkg">snow</span> has been superseded by <span class="pkg">parallel</span>, changed where needed. In <code><a href="#topic+BaumWelch.mmglmlong1">BaumWelch.mmglmlong1</a></code> arguments <code>makeSOCKcluster</code> and <code>SNOWcluster</code> renamed to <code>makePSOCKcluster</code> and <code>PSOCKcluster</code>, respectively. Functions <code>dmmglm</code> and <code>pmmglm</code> added to exported namespace (required for parallel processing). (13 Aug 2014)
</p>
</li>
<li> <p><code><a href="#topic+BaumWelch.mmglmlong1">BaumWelch.mmglmlong1</a></code>: Call to <code>clusterApply</code> and <code>clusterExport</code> changed to <code>parallel::clusterApply</code> and <code>parallel::clusterExport</code>, respectively. (25 Sep 2014)
</p>
</li>
<li><p> Fix error in <code>inst/CITATION</code> file. (21 Jan 2015)
</p>
</li>
<li><p> Added to NAMESPACE: functions imported from <span class="pkg">stats</span>. (06 Jul 2015)
</p>
</li>
<li> <p><code><a href="#topic+HiddenMarkov">HiddenMarkov</a></code>: Add DOI to some references, rename topic to appear first in table of contents. (16 Oct 2015)
</p>
</li>
<li><p> Fortran warning: in file <code>src/extract.f</code>, <code>integer</code> definitions should precede <code>double precision</code> definitions. (29 Aug 2016)
</p>
</li>
<li><p> Fix NOTES in <code>R CMD check --as-cran</code>: <code>Found no calls to: 'R_registerRoutines',</code> <code>'R_useDynamicSymbols'</code> (17 Jun 2017)
</p>
</li>
<li> <p><code><a href="#topic+simulate.mchain">simulate.mchain</a></code>: Change <code>if (sum(object$delta)!=1)</code> to <code>if (!isTRUE(all.equal(sum(object$delta), 1)))</code>. (21 Oct 2017)
</p>
</li>
<li> <p><code><a href="#topic+simulate.mmpp">simulate.mmpp</a></code>: Change <code>if (sum(object$delta)!=1)</code> to <code>if (!isTRUE(all.equal(sum(object$delta), 1)))</code>. (27 Oct 2017)
</p>
</li>
<li><p> Clarify various points in documentation. (27 Oct 2017)
</p>
</li>
<li> <p><code><a href="#topic+HiddenMarkov">HiddenMarkov</a></code>: Hyperlink update to Harte (2019); others updated to https where possible. (27 Apr 2021)
</p>
</li></ol>


<h3>Future Development</h3>


<ol>
<li><p> The functions <code><a href="#topic+Viterbi">Viterbi</a></code> and <code><a href="#topic+residuals">residuals</a></code> need methods for objects of class <code><a href="#topic+mmpp">mmpp</a></code>.
</p>
</li>
<li><p> A number of the original functions have names that are too general. For example <code><a href="#topic+forwardback">forwardback</a></code> calculates the forward-backward probabilities, but only for the model <code><a href="#topic+dthmm">dthmm</a></code>. The corresponding function for the <code><a href="#topic+mmpp">mmpp</a></code> model is <code><a href="#topic+forwardback.mmpp">forwardback.mmpp</a></code>. It would be more consistent to attach to these original functions a <code>dthmm</code> suffix.
</p>
</li>
<li><p> The demonstration examples are all for <code><a href="#topic+dthmm">dthmm</a></code>. Also need some for <code><a href="#topic+mmglm1">mmglm1</a></code>, <code><a href="#topic+mmglmlong1">mmglmlong1</a></code> and <code><a href="#topic+mmpp">mmpp</a></code>.
</p>
</li></ol>

<hr>
<h2 id='compdelta'>Marginal Distribution of Stationary Markov Chain</h2><span id='topic+compdelta'></span>

<h3>Description</h3>

<p>Computes the marginal distribution of a <em>stationary</em> Markov chain with transition probability matrix <code class="reqn">\Pi</code>. The <code class="reqn">m</code> discrete states of the Markov chain are denoted by <code class="reqn">1, \cdots, m</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>compdelta(Pi)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="compdelta_+3A_pi">Pi</code></td>
<td>
<p>is the <code class="reqn">m \times m</code> transition probability matrix of the Markov chain.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If the Markov chain is stationary, then the marginal distribution <code class="reqn">\delta</code> satisfies
</p>
<p style="text-align: center;"><code class="reqn">
\delta = \delta \Pi \,.
</code>
</p>

<p>Obviously,
</p>
<p style="text-align: center;"><code class="reqn">
\sum_j^m \delta_j = 1.
</code>
</p>



<h3>Value</h3>

<p>A numeric vector of length <code class="reqn">m</code> containing the marginal probabilities.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>Pi &lt;- matrix(c(1/2, 1/2,   0,   0,   0,
               1/3, 1/3, 1/3,   0,   0,
                 0, 1/3, 1/3, 1/3,   0,
                 0,   0, 1/3, 1/3, 1/3,
                 0,   0,   0, 1/2, 1/2),
             byrow=TRUE, nrow=5)

print(compdelta(Pi))
</code></pre>

<hr>
<h2 id='Demonstration'>Demonstration Examples</h2><span id='topic+Demonstration'></span>

<h3>Description</h3>

<p>Demonstration examples can be run by executing the code below.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#   Model with class "dthmm" with the Beta distribution
demo("beta", package="HiddenMarkov")

#   Model with class "dthmm" with the Gamma distribution
demo("gamma", package="HiddenMarkov")
 
#   Model with class "dthmm" with the Log Normal distribution
demo("lnorm", package="HiddenMarkov")
 
#   Model with class "dthmm" with the Logistic distribution
demo("logis", package="HiddenMarkov")

#   Model with class "dthmm" with the Gaussian distribution
demo("norm", package="HiddenMarkov")
</code></pre>

<hr>
<h2 id='dthmm'>Discrete Time HMM Object (DTHMM)</h2><span id='topic+dthmm'></span>

<h3>Description</h3>

<p>Creates a discrete time hidden Markov model object with class <code>"dthmm"</code>. The observed process is univariate.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dthmm(x, Pi, delta, distn, pm, pn = NULL, discrete = NULL,
      nonstat = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dthmm_+3A_x">x</code></td>
<td>
<p>is a vector of length <code class="reqn">n</code> containing the univariate observed process. Alternatively, <code>x</code> could be specified as <code>NULL</code>, meaning that the data will be added later (e.g. simulated).</p>
</td></tr>
<tr><td><code id="dthmm_+3A_pi">Pi</code></td>
<td>
<p>is the <code class="reqn">m \times m</code> transition probability matrix of the homogeneous hidden Markov chain.</p>
</td></tr>
<tr><td><code id="dthmm_+3A_delta">delta</code></td>
<td>
<p>is the marginal probability distribution of the <code class="reqn">m</code> hidden states at the first time point.</p>
</td></tr>
<tr><td><code id="dthmm_+3A_distn">distn</code></td>
<td>
<p>is a character string with the abbreviated distribution name. Distributions provided by the package are <code><a href="stats.html#topic+Beta">Beta</a></code> (<code>"beta"</code>), <code><a href="stats.html#topic+Binomial">Binomial</a></code> (<code>"binom"</code>), <code><a href="stats.html#topic+Exponential">Exponential</a></code> (<code>"exp"</code>), <code><a href="stats.html#topic+GammaDist">GammaDist</a></code> (<code>"gamma"</code>), <code><a href="stats.html#topic+Lognormal">Lognormal</a></code> (<code>"lnorm"</code>), <code><a href="stats.html#topic+Logistic">Logistic</a></code> (<code>"logis"</code>), <code><a href="stats.html#topic+Normal">Normal</a></code> (<code>"norm"</code>), and <code><a href="stats.html#topic+Poisson">Poisson</a></code> (<code>"pois"</code>). See topic <code><a href="#topic+Mstep">Mstep</a></code>, Section &ldquo;Modifications and Extensions&rdquo;, to extend to other distributions.</p>
</td></tr>
<tr><td><code id="dthmm_+3A_pm">pm</code></td>
<td>
<p>is a list object containing the (Markov dependent) parameter values associated with the distribution of the observed process (see below).</p>
</td></tr>
<tr><td><code id="dthmm_+3A_pn">pn</code></td>
<td>
<p>is a list object containing the observation dependent parameter values associated with the distribution of the observed process (see below).</p>
</td></tr>
<tr><td><code id="dthmm_+3A_discrete">discrete</code></td>
<td>
<p>is logical, and is <code>TRUE</code> if <code>distn</code> is a discrete distribution. Set automatically for distributions already contained in the package.</p>
</td></tr>
<tr><td><code id="dthmm_+3A_nonstat">nonstat</code></td>
<td>
<p>is logical, <code>TRUE</code> if the homogeneous Markov chain is assumed to be non-stationary, default. See section &ldquo;Stationarity&rdquo; below.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code><a href="base.html#topic+list">list</a></code> object with class <code>"dthmm"</code>, containing the above arguments as named components.
</p>


<h3>Notation</h3>


<ol>
<li><p> MacDonald &amp; Zucchini (1997) use <code class="reqn">t</code> to denote the <em>time</em>, where <code class="reqn">t = 1, \cdots, T</code>. To avoid confusion with other uses of <code><a href="base.html#topic+t">t</a></code> and <code><a href="base.html#topic+logical">T</a></code> in <span class="rlang"><b>R</b></span>, we use <code class="reqn">i = 1, \cdots, n</code>.
</p>
</li>
<li><p> We denote the observed sequence as <code class="reqn">\{X_i\},\ i = 1, \cdots, n</code>; and the hidden Markov chain as <code class="reqn">\{C_i\},\ i = 1, \cdots, n</code>.
</p>
</li>
<li><p> The history of the observed process up to time <code class="reqn">i</code> is denoted by <code class="reqn">X^{(i)}</code>, i.e.
</p>
<p style="text-align: center;"><code class="reqn">
X^{(i)} = (X_1, \cdots, X_i)
</code>
</p>

<p>where <code class="reqn">i = 1, \cdots, n</code>. Similarly for <code class="reqn">C^{(i)}</code>.
</p>
</li>
<li><p> The hidden Markov chain has <code class="reqn">m</code> states denoted by <code class="reqn">1, \cdots, m</code>.
</p>
</li>
<li><p> The Markov chain transition probability matrix is denoted by <code class="reqn">\Pi</code>, where the <code class="reqn">(j, k)</code>th element is
</p>
<p style="text-align: center;"><code class="reqn">
\pi_{jk} = \Pr\{ C_{i+1}=k \, | \, C_i=j \}
</code>
</p>

<p>for all <code class="reqn">i</code> (i.e. all time points), and <code class="reqn">j,k = 1, \cdots, m</code>.
</p>
</li>
<li><p> The Markov chain is assumed to be <em>homogeneous</em>, i.e. for each <code class="reqn">j</code> and <code class="reqn">k</code>, <code class="reqn">\pi_{jk}</code> is constant over time.
</p>
</li>
<li><p> The Markov chain is said to be <em>stationary</em> if the marginal distribution is the same over time, i.e. for each <code class="reqn">j</code>, <code class="reqn">\delta_j = \Pr\{ C_i = j \}</code> is constant for all <code class="reqn">i</code>. The marginal distribution is denoted by <code class="reqn">\delta = (\delta_1, \cdots, \delta_m)</code>.
</p>
</li></ol>


<h3>List Object pm</h3>

<p>The list object <code>pm</code> contains parameter values for the probability distribution of the observed process that are dependent on the hidden Markov state. These parameters are generally required to be estimated. See &ldquo;Modifications&rdquo; in topic <code><a href="#topic+Mstep">Mstep</a></code> when some do not require estimation.
</p>
<p>Assume that the hidden Markov chain has <code class="reqn">m</code> states, and that there are <code class="reqn">\ell</code> parameters that are dependent on the hidden Markov state. Then the list object <code>pm</code> should contain <code class="reqn">\ell</code> <em>named</em> vector components each of length <code class="reqn">m</code>. The names are determined by the required probability distribution.
</p>
<p>For example, if <code>distn == "norm"</code>, the arguments names must coincide with those used by the functions <code><a href="stats.html#topic+dnorm">dnorm</a></code> or <code><a href="stats.html#topic+rnorm">rnorm</a></code>, which are <code>mean</code> and <code>sd</code>. Each must be specified in either <code>pm</code> or <code>pn</code>. If they both vary according to the hidden Markov state then <code>pm</code> should have the <em>named</em> components <code>mean</code> and <code>sd</code>. These are both vectors of length <code class="reqn">m</code> containing the means and standard deviations of the observed process when the hidden Markov chain is in each of the <code class="reqn">m</code> states. If, for example, <code>sd</code> was &ldquo;time&rdquo; dependent, then <code>sd</code> would be contained in <code>pn</code> (see below).
</p>
<p>If <code>distn == "pois"</code>, then <code>pm</code> should have one component named <code>lambda</code>, being the parameter name in the function <code><a href="stats.html#topic+dpois">dpois</a></code>. Even if there is only one parameter, the vector component should still be within a list and named.
</p>


<h3>List Object pn</h3>

<p>The list object <code>pn</code> contains parameter values of the probability distribution for the observed process that are dependent on the observation number or &ldquo;time&rdquo;. These parameters are assumed to be <em>known</em>.
</p>
<p>Assume that the observed process is of length <code class="reqn">n</code>, and that there are <code class="reqn">\ell</code> parameters that are dependent on the observation number or time. Then the list object <code>pn</code> should contain <code class="reqn">\ell</code> <em>named</em> vector components each of length <code class="reqn">n</code>. The names, as in <code>pm</code>, are determined by the required probability distribution.
</p>
<p>For example, in the observed process we may count the number of successes in a <em>known</em> number of Bernoulli trials, i.e. the number of Bernoulli trials is known at each time point, but the probability of success varies according to a hidden Markov state. The <code>prob</code> parameter of <code><a href="stats.html#topic+rbinom">rbinom</a></code> (or <code><a href="stats.html#topic+dbinom">dbinom</a></code>) would be specified in <code>pm</code> and the <code>size</code> parameter would specified in <code>pn</code>.
</p>
<p>One could also have a situation where the observed process was Gaussian, with the means varying according to the hidden Markov state, but the variances varying non-randomly according to the observation number (or vice versa). Here <code>mean</code> would be specified within <code>pm</code> and <code>sd</code> within <code>pn</code>. Note that a given parameter can only occur within <em>one</em> of <code>pm</code> or <code>pn</code>.
</p>


<h3>Complete Data Likelihood</h3>

<p>The &ldquo;complete data likelihood&rdquo;, <code class="reqn">L_c</code>, is
</p>
<p style="text-align: center;"><code class="reqn">
L_c = \Pr\{ X_1=x_1, \cdots, X_n=x_n, C_1=c_1, \cdots, C_n=c_n \}\,.
</code>
</p>

<p>This can be shown to be
</p>
<p style="text-align: center;"><code class="reqn">
\Pr\{ X_1=x_1 \,|\, C_1=c_1 \} \Pr\{ C_1=c_1 \} \prod_{i=2}^n \Pr\{ X_i=x_i \,|\, C_i=c_i \} \Pr\{ C_i=c_i \,|\, C_{i-1}=c_{i-1} \}\,,
</code>
</p>

<p>and hence, substituting model parameters, we get
</p>
<p style="text-align: center;"><code class="reqn">
L_c = \delta_{c_1} \pi_{c_1c_2} \pi_{c_2c_3} \cdots \pi_{c_{n-1}c_n} \prod_{i=1}^n \Pr\{ X_i=x_i \,|\, C_i=c_i \}\,,
</code>
</p>

<p>and so
</p>
<p style="text-align: center;"><code class="reqn">
\log L_c = \log \delta_{c_1} +  \sum_{i=2}^n \log \pi_{c_{i-1}c_i} + \sum_{i=1}^n \log \Pr\{ X_i=x_i \,|\, C_i=c_i \}\,.
</code>
</p>

<p>Hence the &ldquo;complete data likelihood&rdquo; is split into three terms: the first relates to parameters of the marginal distribution (Markov chain), the second to the transition probabilities, and the third to the distribution parameters of the observed random variable. When the Markov chain is non-stationary, each term can be maximised separately.
</p>


<h3>Stationarity</h3>

<p>When the hidden Markov chain is assumed to be non-stationary, the complete data likelihood has a neat structure, in that <code class="reqn">\delta</code> only occurs in the first term, <code class="reqn">\Pi</code> only occurs in the second term, and the parameters associated with the observed probabilities only occur in the third term. Hence, the likelihood can easily be maximised by maximising each term individually. In this situation, the estimated parameters using <code><a href="#topic+BaumWelch">BaumWelch</a></code> will be the &ldquo;exact&rdquo; maximum likelihood estimates.
</p>
<p>When the hidden Markov chain is assumed to be stationary, <code class="reqn">\delta = \Pi^\prime \delta</code> (see topic <code><a href="#topic+compdelta">compdelta</a></code>), and then the first two terms of the complete data likelihood determine the transition probabilities <code class="reqn">\Pi</code>. This raises more complicated numerical problems, as the first term is effectively a constraint. In our implementation of the EM algorithm, we deal with this in a slightly ad-hoc manner by effectively disregarding the first term, which is assumed to be relatively small. In the M-step, the transition matrix is determined by the second term, then <code class="reqn">\delta</code> is estimated using the relation <code class="reqn">\delta = \delta \Pi</code>. Hence, using the <code><a href="#topic+BaumWelch">BaumWelch</a></code> function will only provide approximate maximum likelihood estimates. Exact solutions can be calculated by directly maximising the likelihood function, see first example in <code><a href="#topic+neglogLik">neglogLik</a></code>.
</p>


<h3>References</h3>

<p>Cited references are listed on the <a href="#topic+HiddenMarkov">HiddenMarkov</a> manual page.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#-----  Test Gaussian Distribution -----

Pi &lt;- matrix(c(1/2, 1/2,   0,
               1/3, 1/3, 1/3,
                 0, 1/2, 1/2),
             byrow=TRUE, nrow=3)

delta &lt;- c(0, 1, 0)

x &lt;- dthmm(NULL, Pi, delta, "norm",
           list(mean=c(1, 6, 3), sd=c(0.5, 1, 0.5)))

x &lt;- simulate(x, nsim=1000)

#    use above parameter values as initial values
y &lt;- BaumWelch(x)

print(summary(y))
print(logLik(y))
hist(residuals(y))

#   check parameter estimates
print(sum(y$delta))
print(y$Pi %*% rep(1, ncol(y$Pi)))


#-----  Test Poisson Distribution  -----

Pi &lt;- matrix(c(0.8, 0.2,
               0.3, 0.7),
             byrow=TRUE, nrow=2)

delta &lt;- c(0, 1)

x &lt;- dthmm(NULL, Pi, delta, "pois", list(lambda=c(4, 0.1)),
           discrete = TRUE)

x &lt;- simulate(x, nsim=1000)

#    use above parameter values as initial values
y &lt;- BaumWelch(x)

print(summary(y))
print(logLik(y))
hist(residuals(y))

#   check parameter estimates
print(sum(y$delta))
print(y$Pi %*% rep(1, ncol(y$Pi)))


#-----  Test Exponential Distribution  -----

Pi &lt;- matrix(c(0.8, 0.2,
               0.3, 0.7),
             byrow=TRUE, nrow=2)

delta &lt;- c(0, 1)

x &lt;- dthmm(NULL, Pi, delta, "exp", list(rate=c(2, 0.1)))

x &lt;- simulate(x, nsim=1000)

#    use above parameter values as initial values
y &lt;- BaumWelch(x)

print(summary(y))
print(logLik(y))
hist(residuals(y))

#   check parameter estimates
print(sum(y$delta))
print(y$Pi %*% rep(1, ncol(y$Pi)))


#-----  Test Beta Distribution  -----

Pi &lt;- matrix(c(0.8, 0.2,
               0.3, 0.7),
             byrow=TRUE, nrow=2)

delta &lt;- c(0, 1)

x &lt;- dthmm(NULL, Pi, delta, "beta", list(shape1=c(2, 6), shape2=c(6, 2)))

x &lt;- simulate(x, nsim=1000)

#    use above parameter values as initial values
y &lt;- BaumWelch(x)

print(summary(y))
print(logLik(y))
hist(residuals(y))

#   check parameter estimates
print(sum(y$delta))
print(y$Pi %*% rep(1, ncol(y$Pi)))


#-----  Test Binomial Distribution  -----

Pi &lt;- matrix(c(0.8, 0.2,
               0.3, 0.7),
             byrow=TRUE, nrow=2)

delta &lt;- c(0, 1)

#   vector of "fixed &amp; known" number of Bernoulli trials
pn &lt;- list(size=rpois(1000, 10)+1)

x &lt;- dthmm(NULL, Pi, delta, "binom", list(prob=c(0.2, 0.8)), pn,
           discrete=TRUE)

x &lt;- simulate(x, nsim=1000)

#    use above parameter values as initial values
y &lt;- BaumWelch(x)

print(summary(y))
print(logLik(y))
hist(residuals(y))

#   check parameter estimates
print(sum(y$delta))
print(y$Pi %*% rep(1, ncol(y$Pi)))


#-----  Test Gamma Distribution  -----

Pi &lt;- matrix(c(0.8, 0.2,
               0.3, 0.7),
             byrow=TRUE, nrow=2)

delta &lt;- c(0, 1)

pm &lt;- list(rate=c(4, 0.5), shape=c(3, 3))

x &lt;- seq(0.01, 10, 0.01)
plot(x, dgamma(x, rate=pm$rate[1], shape=pm$shape[1]),
     type="l", col="blue", ylab="Density")
points(x, dgamma(x, rate=pm$rate[2], shape=pm$shape[2]),
       type="l", col="red")

x &lt;- dthmm(NULL, Pi, delta, "gamma", pm)

x &lt;- simulate(x, nsim=1000)

#    use above parameter values as initial values
y &lt;- BaumWelch(x)

print(summary(y))
print(logLik(y))
hist(residuals(y))

#   check parameter estimates
print(sum(y$delta))
print(y$Pi %*% rep(1, ncol(y$Pi)))
</code></pre>

<hr>
<h2 id='Estep'>E-Step of EM Algorithm for DTHMM</h2><span id='topic+Estep'></span>

<h3>Description</h3>

<p>Performs the <em>expectation</em> step of the EM algorithm for a <code><a href="#topic+dthmm">dthmm</a></code> process. This function is called by the <code><a href="#topic+BaumWelch">BaumWelch</a></code> function. The Baum-Welch algorithm referred to in the HMM literature is a version of the EM algorithm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Estep(x, Pi, delta, distn, pm, pn = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Estep_+3A_x">x</code></td>
<td>
<p>is a vector of length <code class="reqn">n</code> containing the observed process.</p>
</td></tr>
<tr><td><code id="Estep_+3A_pi">Pi</code></td>
<td>
<p>is the current estimate of the <code class="reqn">m \times m</code> transition probability matrix of the hidden Markov chain.</p>
</td></tr>
<tr><td><code id="Estep_+3A_distn">distn</code></td>
<td>
<p>is a character string with the distribution name, e.g. <code>"norm"</code> or <code>"pois"</code>. If the distribution is specified as <code>"wxyz"</code> then a probability (or density) function called <code>"dwxyz"</code> should be available, in the standard <span class="rlang"><b>R</b></span> format (e.g. <code><a href="stats.html#topic+dnorm">dnorm</a></code> or <code><a href="stats.html#topic+dpois">dpois</a></code>).</p>
</td></tr>
<tr><td><code id="Estep_+3A_pm">pm</code></td>
<td>
<p>is a list object containing the current (Markov dependent) parameter estimates associated with the distribution of the observed process (see <code><a href="#topic+dthmm">dthmm</a></code>).</p>
</td></tr>
<tr><td><code id="Estep_+3A_pn">pn</code></td>
<td>
<p>is a list object containing the observation dependent parameter values associated with the distribution of the observed process (see <code><a href="#topic+dthmm">dthmm</a></code>).</p>
</td></tr>
<tr><td><code id="Estep_+3A_delta">delta</code></td>
<td>
<p>is the current estimate of the marginal probability distribution of the <code class="reqn">m</code> hidden states.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Let <code class="reqn">u_{ij}</code> be one if <code class="reqn">C_i=j</code> and zero otherwise. Further, let <code class="reqn">v_{ijk}</code> be one if <code class="reqn">C_{i-1}=j</code> and <code class="reqn">C_i=k</code>, and zero otherwise. Let <code class="reqn">X^{(n)}</code> contain the complete observed process. Then, given the current model parameter estimates, the returned value <code>u[i,j]</code> is
</p>
<p style="text-align: center;"><code class="reqn">
\widehat{u}_{ij} = \mbox{E}[u_{ij} \, | \, X^{(n)}] = \Pr\{C_i=j \, | \, X^{(n)} = x^{(n)} \} \,,
</code>
</p>

<p>and <code>v[i,j,k]</code> is
</p>
<p style="text-align: center;"><code class="reqn">
\widehat{v}_{ijk} = \mbox{E}[v_{ijk} \, | \, X^{(n)}] = \Pr\{C_{i-1}=j, C_i=k \, | \, X^{(n)} = x^{(n)} \}\,,
</code>
</p>

<p>where <code class="reqn">j,k = 1, \cdots, m</code> and <code class="reqn">i = 1, \cdots, n</code>.
</p>


<h3>Value</h3>

<p>A <code>list</code> object is returned with the following components.
</p>
<table>
<tr><td><code>u</code></td>
<td>
<p>an <code class="reqn">n \times m</code> matrix containing estimates of the conditional expectations. See &ldquo;Details&rdquo;.</p>
</td></tr>
<tr><td><code>v</code></td>
<td>
<p>an <code class="reqn">n \times m \times m</code> array containing estimates of the conditional expectations. See &ldquo;Details&rdquo;.</p>
</td></tr>
<tr><td><code>LL</code></td>
<td>
<p>the current value of the log-likelihood.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>The algorithm has been taken from Zucchini (2005).</p>


<h3>References</h3>

<p>Cited references are listed on the <a href="#topic+HiddenMarkov">HiddenMarkov</a> manual page.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+BaumWelch">BaumWelch</a></code>, <code><a href="#topic+Mstep">Mstep</a></code>
</p>

<hr>
<h2 id='forwardback'>Forward and Backward Probabilities of DTHMM</h2><span id='topic+forwardback'></span><span id='topic+forward'></span><span id='topic+backward'></span><span id='topic+forwardback.dthmm'></span>

<h3>Description</h3>

<p>These functions calculate the forward and backward probabilities for a <code><a href="#topic+dthmm">dthmm</a></code> process, as defined in MacDonald &amp; Zucchini (1997, Page 60).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>backward(x, Pi, distn, pm, pn = NULL)
forward(x, Pi, delta, distn, pm, pn = NULL)
forwardback(x, Pi, delta, distn, pm, pn = NULL, fortran = TRUE)
forwardback.dthmm(Pi, delta, prob, fortran = TRUE, fwd.only = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="forwardback_+3A_x">x</code></td>
<td>
<p>is a vector of length <code class="reqn">n</code> containing the observed process.</p>
</td></tr>
<tr><td><code id="forwardback_+3A_pi">Pi</code></td>
<td>
<p>is the <code class="reqn">m \times m</code> transition probability matrix of the hidden Markov chain.</p>
</td></tr>
<tr><td><code id="forwardback_+3A_delta">delta</code></td>
<td>
<p>is the marginal probability distribution of the <code class="reqn">m</code> hidden states.</p>
</td></tr>
<tr><td><code id="forwardback_+3A_distn">distn</code></td>
<td>
<p>is a character string with the distribution name, e.g. <code>"norm"</code> or <code>"pois"</code>. If the distribution is specified as <code>"wxyz"</code> then a probability (or density) function called <code>"dwxyz"</code> should be available, in the standard <span class="rlang"><b>R</b></span> format (e.g. <code><a href="stats.html#topic+dnorm">dnorm</a></code> or <code><a href="stats.html#topic+dpois">dpois</a></code>).</p>
</td></tr>
<tr><td><code id="forwardback_+3A_pm">pm</code></td>
<td>
<p>is a list object containing the current (Markov dependent) parameter estimates associated with the distribution of the observed process (see <code><a href="#topic+dthmm">dthmm</a></code>).</p>
</td></tr>
<tr><td><code id="forwardback_+3A_pn">pn</code></td>
<td>
<p>is a list object containing the observation dependent parameter values associated with the distribution of the observed process (see <code><a href="#topic+dthmm">dthmm</a></code>).</p>
</td></tr>
<tr><td><code id="forwardback_+3A_prob">prob</code></td>
<td>
<p>an <code class="reqn">n \times m</code> matrix containing the observation probabilities or densities (rows) by Markov state (columns).</p>
</td></tr>
<tr><td><code id="forwardback_+3A_fortran">fortran</code></td>
<td>
<p>logical, if <code>TRUE</code> (default) use the Fortran code, else use the <span class="rlang"><b>R</b></span> code.</p>
</td></tr>
<tr><td><code id="forwardback_+3A_fwd.only">fwd.only</code></td>
<td>
<p>logical, if <code>FALSE</code> (default) calculate both forward and backward probabilities; else calculate and return only forward probabilities and log-likelihood.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Denote the <code class="reqn">n \times m</code> matrices containing the forward and backward probabilities as <code class="reqn">A</code> and <code class="reqn">B</code>, respectively. Then the <code class="reqn">(i,j)</code>th elements are
</p>
<p style="text-align: center;"><code class="reqn">
\alpha_{ij} = \Pr\{ X_1 = x_1, \cdots, X_i = x_i, C_i = j \}
</code>
</p>

<p>and
</p>
<p style="text-align: center;"><code class="reqn">
\beta_{ij} = \Pr\{ X_{i+1} = x_{i+1}, \cdots, X_n = x_n \,|\, C_i = j \} \,.
</code>
</p>

<p>Further, the diagonal elements of the product matrix <code class="reqn">A B^\prime</code> are all the same, taking the value of the log-likelihood.
</p>


<h3>Value</h3>

<p>The function <code>forwardback</code> returns a list with two matrices containing the forward and backward (log) probabilities, <code>logalpha</code> and <code>logbeta</code>, respectively, and the log-likelihood (<code>LL</code>).
</p>
<p>The functions <code>backward</code> and <code>forward</code> return a matrix containing the forward and backward (log) probabilities, <code>logalpha</code> and <code>logbeta</code>, respectively.
</p>


<h3>Author(s)</h3>

<p>The algorithm has been taken from Zucchini (2005).</p>


<h3>References</h3>

<p>Cited references are listed on the <a href="#topic+HiddenMarkov">HiddenMarkov</a> manual page.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+logLik">logLik</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#    Set Parameter Values

Pi &lt;- matrix(c(1/2, 1/2,   0,   0,   0,
               1/3, 1/3, 1/3,   0,   0,
                 0, 1/3, 1/3, 1/3,   0,
                 0,   0, 1/3, 1/3, 1/3,
                 0,   0,   0, 1/2, 1/2),
             byrow=TRUE, nrow=5)

p &lt;- c(1, 4, 2, 5, 3)
delta &lt;- c(0, 1, 0, 0, 0)

#------   Poisson HMM   ------

x &lt;- dthmm(NULL, Pi, delta, "pois", list(lambda=p), discrete=TRUE)

x &lt;- simulate(x, nsim=10)

y &lt;- forwardback(x$x, Pi, delta, "pois", list(lambda=p))

# below should be same as LL for all time points
print(log(diag(exp(y$logalpha) %*% t(exp(y$logbeta)))))
print(y$LL)

#------   Gaussian HMM   ------

x &lt;- dthmm(NULL, Pi, delta, "norm", list(mean=p, sd=p/3))

x &lt;- simulate(x, nsim=10)

y &lt;- forwardback(x$x, Pi, delta, "norm", list(mean=p, sd=p/3))

# below should be same as LL for all time points
print(log(diag(exp(y$logalpha) %*% t(exp(y$logbeta)))))
print(y$LL)
</code></pre>

<hr>
<h2 id='HiddenMarkov-defunct'>Defunct Functions in Package HiddenMarkov</h2><span id='topic+HiddenMarkov-defunct'></span><span id='topic+residualshmm'></span>

<h3>Description</h3>

<p>These functions are now defunct and are no longer in the package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>residualshmm(x, Pi, delta, distn, pm, pn = NULL, discrete = FALSE)
</code></pre>

<hr>
<h2 id='HiddenMarkov-dthmm-deprecated'>Discrete Time HMM - Deprecated Functions</h2><span id='topic+HiddenMarkov-dthmm-deprecated'></span><span id='topic+Baum.Welch'></span><span id='topic+sim.hmm'></span><span id='topic+sim.hmm1'></span><span id='topic+sim.markov'></span><span id='topic+Viterbihmm'></span>

<h3>Description</h3>

<p>These functions are deprecated and will ultimately be removed from the package. Please change to the object orientated versions: <code><a href="#topic+BaumWelch">BaumWelch</a></code>, <code><a href="#topic+residuals">residuals</a></code>, <code><a href="#topic+simulate">simulate</a></code> or <code><a href="#topic+Viterbi">Viterbi</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Baum.Welch(x, Pi, delta, distn, pm, pn = NULL, nonstat = TRUE,
           maxiter = 500, tol = 1e-05, prt = TRUE,
           posdiff = (distn[1]!="glm"))
residualshmm(x, Pi, delta, distn, pm, pn = NULL, discrete = FALSE)
sim.hmm(n, initial, Pi, distn, pm, pn = NULL)
sim.hmm1(n, initial, Pi, distn, pm)
sim.markov(n, initial, Pi)
Viterbihmm(x, Pi, delta, distn, pm, pn = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="HiddenMarkov-dthmm-deprecated_+3A_x">x</code></td>
<td>
<p>is a vector of length <code class="reqn">n</code> containing the observed process.</p>
</td></tr>
<tr><td><code id="HiddenMarkov-dthmm-deprecated_+3A_n">n</code></td>
<td>
<p>length of process.</p>
</td></tr>
<tr><td><code id="HiddenMarkov-dthmm-deprecated_+3A_initial">initial</code></td>
<td>
<p>integer, being the initial hidden Markov state <code class="reqn">(1, \cdots, m)</code>.</p>
</td></tr>
<tr><td><code id="HiddenMarkov-dthmm-deprecated_+3A_pi">Pi</code></td>
<td>
<p>is the <code class="reqn">m \times m</code> transition probability matrix of the hidden Markov chain.</p>
</td></tr>
<tr><td><code id="HiddenMarkov-dthmm-deprecated_+3A_delta">delta</code></td>
<td>
<p>is the marginal probability distribution of the <code class="reqn">m</code> hidden states at the first time point.</p>
</td></tr>
<tr><td><code id="HiddenMarkov-dthmm-deprecated_+3A_distn">distn</code></td>
<td>
<p>is a character string with the distribution name, e.g. <code>"norm"</code> or <code>"pois"</code>. If the distribution is specified as <code>"wxyz"</code> then a distribution function called <code>"pwxyz"</code> should be available, in the standard <span class="rlang"><b>R</b></span> format (e.g. <code><a href="stats.html#topic+pnorm">pnorm</a></code> or <code><a href="stats.html#topic+ppois">ppois</a></code>).</p>
</td></tr>
<tr><td><code id="HiddenMarkov-dthmm-deprecated_+3A_pm">pm</code></td>
<td>
<p>is a list object containing the (Markov dependent) parameter values associated with the distribution of the observed process (see <code><a href="#topic+dthmm">dthmm</a></code>).</p>
</td></tr>
<tr><td><code id="HiddenMarkov-dthmm-deprecated_+3A_pn">pn</code></td>
<td>
<p>is a list object containing the observation dependent parameter values associated with the distribution of the observed process (see <code><a href="#topic+dthmm">dthmm</a></code>).</p>
</td></tr>
<tr><td><code id="HiddenMarkov-dthmm-deprecated_+3A_discrete">discrete</code></td>
<td>
<p>is logical, and is <code>TRUE</code> if <code>distn</code> is a discrete distribution.</p>
</td></tr>
<tr><td><code id="HiddenMarkov-dthmm-deprecated_+3A_nonstat">nonstat</code></td>
<td>
<p>is logical, <code>TRUE</code> if the homogeneous Markov chain is assumed to be non-stationary, default. See &ldquo;Details&rdquo; below.</p>
</td></tr>
<tr><td><code id="HiddenMarkov-dthmm-deprecated_+3A_maxiter">maxiter</code></td>
<td>
<p>is the maximum number of iterations, default is 500.</p>
</td></tr>
<tr><td><code id="HiddenMarkov-dthmm-deprecated_+3A_tol">tol</code></td>
<td>
<p>is the convergence criterion, being the difference between successive values of the log-likelihood; default is 0.00001.</p>
</td></tr>
<tr><td><code id="HiddenMarkov-dthmm-deprecated_+3A_prt">prt</code></td>
<td>
<p>is logical, and determines whether information is printed at each iteration; default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="HiddenMarkov-dthmm-deprecated_+3A_posdiff">posdiff</code></td>
<td>
<p>is logical, and determines whether the iterative process stops if a negative log-likelihood difference occurs.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function <code>sim.hmm1</code> will run faster for cases where the argument <code>pn</code> is <code>NULL</code>.
</p>

<hr>
<h2 id='HiddenMarkov-internal'>Internally Used Functions</h2><span id='topic+residuals.mmpp'></span><span id='topic+Viterbi.mmpp'></span><span id='topic+as.dthmm'></span><span id='topic+as.mmglm0'></span><span id='topic+makedensity'></span><span id='topic+makedensity1'></span><span id='topic+makedistn'></span><span id='topic+getj'></span><span id='topic+dglm'></span><span id='topic+pglm'></span><span id='topic+dmmglm'></span><span id='topic+pmmglm'></span><span id='topic+mmglm'></span>

<h3>Description</h3>

<p>This page lists internally used functions. They should not be required by most users.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>as.dthmm(object)
as.mmglm0(object)

makedensity(distn)
makedensity1(distn)
makedistn(distn)

getj(x, j)

dglm(x, x1, beta0, beta1, sigma, family, link, size = NA,
     log = FALSE)
pglm(q, x1, beta0, beta1, sigma, family, link, size = NA,
     log.p = FALSE)
dmmglm(x, beta, sigma, glmfamily, Xdesign, size=NA, log=FALSE)
pmmglm(x, beta, sigma, glmfamily, Xdesign, size=NA, log.p=FALSE)

mmglm(...)
</code></pre>


<h3>Details</h3>

<p>The function <code>makedensity</code> is used to reparameterise various <span class="rlang"><b>R</b></span> probability (or density) functions (e.g. <code><a href="stats.html#topic+dnorm">dnorm</a></code> and <code><a href="stats.html#topic+dpois">dpois</a></code>) into a format with a standard argument list. Similarly, <code>makedistn</code> reparameterises a distribution function.
</p>
<p>The function <code>getj</code> is used to extract the <code class="reqn">j</code>th element from each vector component in a list object.
</p>
<p>The function <code>as.dthmm</code> coerces an object with class <code>"<a href="#topic+mmglm0">mmglm0</a>"</code> to an object with class <code>"<a href="#topic+dthmm">dthmm</a>"</code>. Similarly, the function <code>as.mmglm0</code> coerces an object with class <code>"<a href="#topic+dthmm">dthmm</a>"</code> to an object with class <code>"<a href="#topic+mmglm0">mmglm0</a>"</code> (if possible).
</p>
<p>The functions <code>dglm</code> and <code>pglm</code> calculate the density and probability, respectively, for an observation given a generalised linear model.
</p>
<p>The functions <code>dmmglm</code> and <code>pmmglm</code> calculate the density and probability, respectively, for an observation given a generalised linear model.
</p>

<hr>
<h2 id='HiddenMarkov-mmpp-deprecated'>Markov Modulated Poisson Process - Deprecated Functions</h2><span id='topic+HiddenMarkov-mmpp-deprecated'></span><span id='topic+backward0.mmpp'></span><span id='topic+forward0.mmpp'></span><span id='topic+logLikmmpp'></span><span id='topic+Estep0.mmpp'></span><span id='topic+Baum.Welch.mmpp'></span><span id='topic+Baum.Welch0.mmpp'></span><span id='topic+sim.mmpp'></span>

<h3>Description</h3>

<p>These functions are deprecated and will ultimately be removed from the package. Please change to the revised versions: <code><a href="#topic+BaumWelch">BaumWelch</a></code>, <code><a href="#topic+Estep.mmpp">Estep.mmpp</a></code>, <code><a href="#topic+forwardback.mmpp">forwardback.mmpp</a></code>, <code><a href="#topic+simulate">simulate</a></code> or <code><a href="#topic+logLik">logLik</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>backward0.mmpp(tau, Q, lambda)
forward0.mmpp(tau, Q, delta, lambda)

logLikmmpp(tau, Q, delta, lambda)

Estep0.mmpp(tau, Q, delta, lambda)

Baum.Welch.mmpp(tau, Q, delta, lambda, nonstat = TRUE,
                maxiter = 500, tol = 1e-05, prt = TRUE,
                converge = expression(diff &lt; tol))
Baum.Welch0.mmpp(tau, Q, delta, lambda, nonstat = TRUE,
                 maxiter = 500, tol = 1e-05, prt = TRUE,
                 converge = expression(diff &lt; tol))

sim.mmpp(n, initial, Q, lambda)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="HiddenMarkov-mmpp-deprecated_+3A_tau">tau</code></td>
<td>
<p>vector containing the interevent times. Note that the first event is at time zero.</p>
</td></tr>
<tr><td><code id="HiddenMarkov-mmpp-deprecated_+3A_q">Q</code></td>
<td>
<p>the infinitesimal generator matrix of the Markov process.</p>
</td></tr>
<tr><td><code id="HiddenMarkov-mmpp-deprecated_+3A_lambda">lambda</code></td>
<td>
<p>a vector containing the Poisson rates.</p>
</td></tr>
<tr><td><code id="HiddenMarkov-mmpp-deprecated_+3A_delta">delta</code></td>
<td>
<p>is the marginal probability distribution of the <code class="reqn">m</code> hidden states at time zero.</p>
</td></tr>
<tr><td><code id="HiddenMarkov-mmpp-deprecated_+3A_n">n</code></td>
<td>
<p>number of Poisson events to be simulated.</p>
</td></tr>
<tr><td><code id="HiddenMarkov-mmpp-deprecated_+3A_initial">initial</code></td>
<td>
<p>integer, being the initial hidden Markov state <code class="reqn">(1, \cdots, m)</code>.</p>
</td></tr>
<tr><td><code id="HiddenMarkov-mmpp-deprecated_+3A_nonstat">nonstat</code></td>
<td>
<p>is logical, <code>TRUE</code> if the homogeneous Markov chain is assumed to be non-stationary, default.</p>
</td></tr>
<tr><td><code id="HiddenMarkov-mmpp-deprecated_+3A_maxiter">maxiter</code></td>
<td>
<p>is the maximum number of iterations, default is 500.</p>
</td></tr>
<tr><td><code id="HiddenMarkov-mmpp-deprecated_+3A_tol">tol</code></td>
<td>
<p>is the convergence criterion, being the difference between successive values of the log-likelihood; default is 0.00001.</p>
</td></tr>
<tr><td><code id="HiddenMarkov-mmpp-deprecated_+3A_prt">prt</code></td>
<td>
<p>is logical, and determines whether information is printed at each iteration; default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="HiddenMarkov-mmpp-deprecated_+3A_converge">converge</code></td>
<td>
<p>is an expression giving the convergence criterion.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The functions with a suffix of zero are non-scaled, and hence will have numerical problems for series containing larger numbers of events; and are <em>much</em> slower.
</p>
<p>These functions use the algorithm given by Ryden (1996) based on eigenvalue decompositions.
</p>

<hr>
<h2 id='logLik'>Log Likelihood of Hidden Markov Model</h2><span id='topic+logLik'></span><span id='topic+logLik.dthmm'></span><span id='topic+logLik.mmglm0'></span><span id='topic+logLik.mmglm1'></span><span id='topic+logLik.mmglmlong1'></span><span id='topic+logLik.mmpp'></span>

<h3>Description</h3>

<p>Provides methods for the generic function <code><a href="stats.html#topic+logLik">logLik</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'dthmm'
logLik(object, fortran=TRUE, ...)
## S3 method for class 'mmglm0'
logLik(object, fortran=TRUE, ...)
## S3 method for class 'mmglm1'
logLik(object, fortran=TRUE, ...)
## S3 method for class 'mmglmlong1'
logLik(object, fortran=TRUE, ...)
## S3 method for class 'mmpp'
logLik(object, fortran=TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="logLik_+3A_object">object</code></td>
<td>
<p>an object with class <code>"<a href="#topic+dthmm">dthmm</a>"</code>, <code>"<a href="#topic+mmglm0">mmglm0</a>"</code>, <code>"<a href="#topic+mmglm1">mmglm1</a>"</code>, <code>"<a href="#topic+mmglmlong1">mmglmlong1</a>"</code> or <code>"<a href="#topic+mmpp">mmpp</a>"</code>.</p>
</td></tr>
<tr><td><code id="logLik_+3A_fortran">fortran</code></td>
<td>
<p>logical, if <code>TRUE</code> (default) use the Fortran code, else use the <span class="rlang"><b>R</b></span> code.</p>
</td></tr>
<tr><td><code id="logLik_+3A_...">...</code></td>
<td>
<p>other arguments.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The methods provided here will always recalculate the log-likelihood even if it is already contained within the <code>object</code>. This enables the user to change parameter or data values within the <code>object</code> and recalculate the log-likelihood for the revised configuration.
</p>
<p>The code for the methods <code>"<a href="#topic+dthmm">dthmm</a>"</code>, <code>"<a href="#topic+mmglm0">mmglm0</a>"</code>, <code>"<a href="#topic+mmglm1">mmglm1</a>"</code>,<code>"<a href="#topic+mmglmlong1">mmglmlong1</a>"</code> and <code>"<a href="#topic+mmpp">mmpp</a>"</code> can be viewed by appending <code>logLik.dthmm</code>, <code>logLik.mmglm0</code>, <code>logLik.mmglm1</code>, <code>logLik.mmglmlong1</code>  or <code>logLik.mmpp</code>, respectively, to <code>HiddenMarkov:::</code>, on the <span class="rlang"><b>R</b></span> command line; e.g. <code>HiddenMarkov:::dthmm</code>. The three colons are needed because these method functions are not in the exported NAMESPACE.
</p>


<h3>Value</h3>

<p>Returns the value of the log-likelihood.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>Pi &lt;- matrix(c(1/2, 1/2,   0,
               1/3, 1/3, 1/3,
                 0, 1/2, 1/2),
             byrow=TRUE, nrow=3)

x &lt;- dthmm(NULL, Pi, c(0,1,0), "norm",
           list(mean=c(1, 6, 3), sd=c(1, 0.5, 1)))

x &lt;- simulate(x, nsim=100)

print(logLik(x))
</code></pre>

<hr>
<h2 id='mchain'>Markov Chain Object</h2><span id='topic+mchain'></span>

<h3>Description</h3>

<p>Creates a Markov chain object with class <code>"mchain"</code>. It does not simulate data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mchain(x, Pi, delta, nonstat = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mchain_+3A_x">x</code></td>
<td>
<p>is a vector of length <code class="reqn">n</code> containing the observed process, else it is specified as <code>NULL</code>. This is used when there are no data and a process is to be simulated.</p>
</td></tr>
<tr><td><code id="mchain_+3A_pi">Pi</code></td>
<td>
<p>is the <code class="reqn">m \times m</code> transition probability matrix of the Markov chain.</p>
</td></tr>
<tr><td><code id="mchain_+3A_delta">delta</code></td>
<td>
<p>is the marginal probability distribution of the <code class="reqn">m</code> state Markov chain at the first time point.</p>
</td></tr>
<tr><td><code id="mchain_+3A_nonstat">nonstat</code></td>
<td>
<p>is logical, <code>TRUE</code> if the homogeneous Markov chain is assumed to be non-stationary, default. See &ldquo;Details&rdquo; below.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code><a href="base.html#topic+list">list</a></code> object with class <code>"mchain"</code>, containing the above arguments as named components.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>Pi &lt;- matrix(c(0.8, 0.2,
               0.3, 0.7),
             byrow=TRUE, nrow=2)

#    Create a Markov chain object with no data (NULL)
x &lt;- mchain(NULL, Pi, c(0,1))

#    Simulate some data
x &lt;- simulate(x, nsim=2000)

#   estimate transition probabilities
estPi &lt;- table(x$mc[-length(x$mc)], x$mc[-1])
rowtotal &lt;- estPi %*% matrix(1, nrow=nrow(Pi), ncol=1)
estPi &lt;- diag(as.vector(1/rowtotal)) %*% estPi
print(estPi)
</code></pre>

<hr>
<h2 id='mmglm'>Markov Modulated GLM Object</h2><span id='topic+mmglm0'></span><span id='topic+mmglm1'></span><span id='topic+mmglmlong1'></span>

<h3>Description</h3>

<p>These functions create Markov modulated generalised linear model objects. <em><b>These functions are in development and may change</b></em>, see &ldquo;Under Development&rdquo; below.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mmglm0(x, Pi, delta, family, link, beta, glmformula = formula(y~x1),
       sigma = NA, nonstat = TRUE, msg = TRUE)
mmglm1(y, Pi, delta, glmfamily, beta, Xdesign,
       sigma = NA, nonstat = TRUE, size = NA, msg = TRUE)
mmglmlong1(y, Pi, delta, glmfamily, beta, Xdesign, longitude, 
           sigma = NA, nonstat = TRUE, size = NA, msg = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mmglm_+3A_x">x</code></td>
<td>
<p>a dataframe containing the observed variable (i.e. the response variable in the generalised linear model) and the covariate. The function <code>mmglm0</code> requires that the response variable be named <code>y</code> and the covariate <code>x1</code>.  Alternatively, <code>x</code> could be specified as <code>NULL</code>, meaning that the data will be added later (e.g. simulated). See Details below for the binomial case. The functions <code>mmglm1</code> and <code>mmglmlong1</code> do not have these naming restrictions.</p>
</td></tr>
<tr><td><code id="mmglm_+3A_y">y</code></td>
<td>
<p>numeric vector, response variable. In the case of binomial, it is the number of successes (see argument <code>size</code>).</p>
</td></tr>
<tr><td><code id="mmglm_+3A_pi">Pi</code></td>
<td>
<p>is the <code class="reqn">m \times m</code> transition probability matrix of the hidden Markov chain.</p>
</td></tr>
<tr><td><code id="mmglm_+3A_delta">delta</code></td>
<td>
<p>is the marginal probability distribution of the <code class="reqn">m</code> hidden states at the first time point.</p>
</td></tr>
<tr><td><code id="mmglm_+3A_family">family</code></td>
<td>
<p>character string, the GLM family, one of <code>"gaussian"</code>, <code>"poisson"</code>, <code>"Gamma"</code> or <code>"binomial"</code>.</p>
</td></tr>
<tr><td><code id="mmglm_+3A_link">link</code></td>
<td>
<p>character string, the link function. If <code>family == "binomial"</code>, then one of <code>"logit"</code>, <code>"probit"</code> or <code>"cloglog"</code>; else one of <code>"identity"</code>, <code>"inverse"</code> or <code>"log"</code>.</p>
</td></tr>
<tr><td><code id="mmglm_+3A_glmfamily">glmfamily</code></td>
<td>
<p>a <code><a href="stats.html#topic+family">family</a></code> object defining the glm family and link function. It is currently restricted to Gaussian, Poisson, Binomial or Gamma models with the standard link functions provided by <code><a href="stats.html#topic+glm">glm</a></code>.</p>
</td></tr>
<tr><td><code id="mmglm_+3A_xdesign">Xdesign</code></td>
<td>
<p>a <code class="reqn">nN \times p</code> design matrix, where <code class="reqn">p</code> is the number of parameters in the linear predictor, <code class="reqn">N</code> is the number of subjects (<code class="reqn">N=1</code> in <code>mmglm1</code>), and <code class="reqn">n</code> is the number of observations for each subject (<em>assumed to be the same</em>).</p>
</td></tr>
<tr><td><code id="mmglm_+3A_beta">beta</code></td>
<td>
<p>a <code class="reqn">p \times m</code> matrix containing parameter values, used as initial values during estimation. In the case of the simple regression model of <code>mmglm0</code>, <code class="reqn">p=2</code>. In the case of <code>mmglm1</code> and <code>mmglmlong1</code>, <code class="reqn">p</code> is the number of columns of <code>Xdesign</code>.</p>
</td></tr>
<tr><td><code id="mmglm_+3A_glmformula">glmformula</code></td>
<td>
<p>the only model formula for <code>mmglm0</code> is <code>y~x1</code>. Note that the functions <code>mmglm1</code> and <code>mmglmlong1</code> do not have this restriction, however, in those cases, the model formula is currently implicitly defined through <code>Xdesign</code>.</p>
</td></tr>
<tr><td><code id="mmglm_+3A_sigma">sigma</code></td>
<td>
<p>if <code>family == "gaussian"</code>, then it is the variance; if <code>family == "Gamma"</code>, then it is <code>1/sqrt(shape)</code>. It is of length <code class="reqn">m</code> for each Markov state.</p>
</td></tr>
<tr><td><code id="mmglm_+3A_nonstat">nonstat</code></td>
<td>
<p>is logical, <code>TRUE</code> if the homogeneous Markov chain is assumed to be non-stationary, default.</p>
</td></tr>
<tr><td><code id="mmglm_+3A_longitude">longitude</code></td>
<td>
<p>a vector the same length as <code>y</code> identifying the subject for each observation. The observations must be grouped by subject, and ordered by &ldquo;time&rdquo; within subject.</p>
</td></tr>
<tr><td><code id="mmglm_+3A_size">size</code></td>
<td>
<p>is number of Bernoulli trials in each observation when the glm <code><a href="stats.html#topic+family">family</a></code> is binomial. It is the same length as <code>y</code>.</p>
</td></tr>
<tr><td><code id="mmglm_+3A_msg">msg</code></td>
<td>
<p>is logical, suppress messages about developmental status.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This family of models is similar in nature to those of the class <code><a href="#topic+dthmm">dthmm</a></code>, in that both classes have the distribution of the observed variable being &ldquo;modulated&rdquo; by the changing hidden Markov state. They differ slightly in the mechanism. This family assumes that the mean of the observation distribution can be expressed as a linear model of other known variables, but it is the parameters in the linear predictor that are being modulated by the hidden Markov process, thus causing the changes in the observed means. The linear model is assumed to be a generalised linear model as described by McCullagh &amp; Nelder (1989).
</p>
<p>The function <code>mmglm0</code> is a very simple trivial case where the linear predictor is of the form <code class="reqn">\beta_0 + \beta_1 x_1</code>. The version <code>mmglm1</code> does not have this limitation. The model formula for <code>mmglm1</code> is defined implicitly through the structure of the specified design matrix. The model <code>mmglmlong1</code> is similar to <code>mmglm1</code> but can be applied to longitudinal observations. Models of the form given by <code>mmglm1</code> are assumed to have one time series, and from a theoretical perspective, one would be interested in the asymptotic properties of the parameter estimates as the series length gets very large. In the longitudinal case (<code>mmglmlong1</code>), the series of observations per individual is probably very small (<code class="reqn">&lt;10</code>), and hence interest is in the asymptotic properties as the number of individuals becomes large. Note that in the longitudinal case, the number of observations per individual is assumed to be the same. The responses are assumed to be conditionally independent given the value of the Markov chain and the explanatory variables in the linear predictor.
</p>
<p>If <code>family == "binomial"</code> then the response variable <code>y</code> is interpreted as the number of successes. The dataframe <code>x</code> must also contain a variable called <code>size</code> being the number of Bernoulli trials. This is different to the format used by the function <code><a href="stats.html#topic+glm">glm</a></code> where <code>y</code> would be a matrix with two columns containing the number of successes and failures, respectively. The different format here allows one to specify the number of Bernoulli trials <em>only</em> so that the number of successes or failures can be simulated later.
</p>
<p>When the density function of the response variable is from the exponential family (Charnes et al, 1976, Eq. 2.1), the likelihood function (Charnes et al, 1976, Eq. 2.4) can be maximised by using iterative weighted least squares (Charnes et al, 1976, Eq. 1.1 and 1.2). This is the method used by the <span class="rlang"><b>R</b></span> function <code><a href="stats.html#topic+glm">glm</a></code>. In this Markov modulated version of the model, the third term of the complete data log-likelihood, as given in Harte (2006, Sec. 2.3), needs to be maximised. This is simply the sum of the individual log-likelihood contributions of the response variable weighted by the Markov state probabilities calculated in the E-step. This can also be maximised using iterative least squares by passing these additional weights (Markov state probabilities) into the <code><a href="stats.html#topic+glm">glm</a></code> function.
</p>


<h3>Value</h3>

<p>A <code><a href="base.html#topic+list">list</a></code> object with class <code>"mmglm0"</code>, containing the above arguments as named components.
</p>


<h3>Under Development</h3>

<p>These functions are still being developed. In previous releases of the package (<code class="reqn">&lt; 1.3</code>), there was only one function called <code>mmglm</code>. This has been renamed to <code>mmglm0</code>. The most recent version is <code>mmglm1</code> along with <code>mmglmlong1</code> which has flexibility to include longitudinal data. Further development versions will be numbered sequentially. The name <code>mmglm</code> has been reserved for the final stable version, at which point the numbered versions will become deprecated.
</p>


<h3>References</h3>

<p>Cited references are listed on the <a href="#topic+HiddenMarkov">HiddenMarkov</a> manual page.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#--------------------------------------------------------
#     Gaussian with identity link function
#         using mmglm0

delta &lt;- c(0,1)

Pi &lt;- matrix(c(0.8, 0.2,
               0.3, 0.7),
             byrow=TRUE, nrow=2)

beta &lt;- matrix(c(0.1, -0.1,
                 1.0,  5.0),
               byrow=TRUE, nrow=2)

x &lt;- mmglm0(NULL, Pi, delta, family="gaussian", link="identity",
            beta=beta, sigma=c(1, 2))

n &lt;- 1000
x &lt;- simulate(x, nsim=n, seed=10)

#   Increase maxiter below to achieve convergence
#   Has been restricted to minimise time of package checks
y &lt;- BaumWelch(x, bwcontrol(maxiter=2))

w &lt;- hist(residuals(y))
z &lt;- seq(-3, 3, 0.01)
points(z, dnorm(z)*n*(w$breaks[2]-w$breaks[1]), col="red", type="l")
box()

print(summary(y))
print(logLik(y))


#--------------------------------------------------------
#    Gaussian with log link function
#         using mmglm1

n &lt;- 1000

#   the range of x needs changing according to the glmfamily
x &lt;- seq(-0.9, 1.5, length.out=n)

colour &lt;- c("blue", "green", "red")
colnum &lt;- rep(1:3, n/3+1)[1:n] - 1

data &lt;- data.frame(x=x, colour=colour[colnum+1])

#   will simulate response variable, not required in formula
#   design matrix only depends on RHS of formula
glmformula &lt;- formula( ~ x + I(x^2) + colour)
glmfamily &lt;- gaussian(link="log")
Xdesign &lt;- model.matrix(glmformula, data=data)

# --- Parameter Values and Simulation ---

Pi &lt;- matrix(c(0.8, 0.2,
               0.3, 0.7),
             byrow=TRUE, nrow=2)

delta &lt;- c(1, 0)

sd &lt;- c(1.2, 1)

beta &lt;- matrix(c(-1, -1.2,
                 -2, -1.8,
                  3,  2.8,
                  1,  0.8, 
                  2,  2.2), 
               ncol=ncol(Pi), nrow=ncol(Xdesign), byrow=TRUE)

y &lt;- mmglm1(NULL, Pi, delta, glmfamily, beta, Xdesign, sigma=sd)

y &lt;- simulate(y, seed=5)

# --- Estimation ---

#   Increase maxiter below to achieve convergence
#   Has been restricted to minimise time of package checks
tmp &lt;- BaumWelch(y, bwcontrol(posdiff=FALSE, maxiter=2))
print(summary(tmp))


#-------------------------------------------------
#    Binomial with logit link function
#         using mmglm1

#   n = series length
n &lt;- 1000

#   the range of x need changing according to the glmfamily
x &lt;- seq(-1, 1.5, length.out=n)

colour &lt;- c("blue", "green", "red")
colnum &lt;- rep(1:3, n/3+1)[1:n] - 1

data &lt;- data.frame(x=x, colour=colour[colnum+1])

glmformula &lt;- formula( ~ x + I(x^2) + colour)
glmfamily &lt;- binomial(link="logit")
Xdesign &lt;- model.matrix(glmformula, data=data)

# --- Parameter Values and Simulation ---

Pi &lt;- matrix(c(0.8, 0.2,
               0.3, 0.7),
             byrow=TRUE, nrow=2)

delta &lt;- c(1, 0)

beta &lt;- matrix(c(-1, -1.2,
                 -2, -1.8,
                  3,  2.8,
                  1,  0.8, 
                  2,  2.2), 
               ncol=ncol(Pi), nrow=ncol(Xdesign), byrow=TRUE)

y &lt;- mmglm1(NULL, Pi, delta, glmfamily, beta, Xdesign, sigma=sd,
            size=rep(100, n))

#   each element of y$y is the number of successes in 100 Bernoulli trials
y &lt;- simulate(y, seed=5)


# --- Estimation ---

#   Increase maxiter below to achieve convergence
#   Has been restricted to minimise time of package checks
tmp &lt;- BaumWelch(y, bwcontrol(posdiff=FALSE, maxiter=2))
print(summary(tmp))


#-------------------------------------------------
#    Gaussian with log link function, longitudinal data
#         using mmglmlong1

#   n = series length for each subject
#   N = number of subjects
n &lt;- 5
N &lt;- 1000

#   the range of x need changing according to the glmfamily
x &lt;- seq(-0.9, 1.5, length.out=n)

colour &lt;- c("blue", "green", "red")
colnum &lt;- rep(1:3, n/3+1)[1:n] - 1

data &lt;- data.frame(x=x, colour=colour[colnum+1])

#   will simulate response variable, not required in formula
#   design matrix only depends on RHS of formula
glmformula &lt;- formula( ~ x + I(x^2) + colour)
glmfamily &lt;- gaussian(link="log")
Xdesign0 &lt;- model.matrix(glmformula, data=data)

#    multiple subjects
Xdesign &lt;- NULL
for (i in 1:N) Xdesign &lt;- rbind(Xdesign, Xdesign0)

# --- Parameter Values and Simulation ---

Pi &lt;- matrix(c(0.8, 0.2,
               0.3, 0.7),
             byrow=TRUE, nrow=2)

delta &lt;- c(0.5, 0.5)

sd &lt;- c(1.2, 1)

beta &lt;- matrix(c(-1, -1.2,
                 -2, -1.8,
                  3,  2.8,
                  1,  0.8, 
                  2,  2.2), 
               ncol=ncol(Pi), nrow=ncol(Xdesign), byrow=TRUE)

y &lt;- mmglmlong1(NULL, Pi, delta, glmfamily, beta, Xdesign, sigma=sd,
                longitude=rep(1:N, each=n))

y &lt;- simulate(y, seed=5)

# --- Estimation ---

#    Note: the "Not run" blocks below are not run during package checks
#    as the makePSOCKcluster definition is specific to my network,
#    modify accordingly if you want parallel processing.

cl &lt;- NULL
## Not run: 
if (require(parallel)){
    cl &lt;- makePSOCKcluster(c("localhost", "horoeka.localdomain", 
                             "horoeka.localdomain", "localhost"))
}
## End(Not run)

#   Increase maxiter below to achieve convergence
#   Has been restricted to minimise time of package checks
tmp &lt;- BaumWelch(y, bwcontrol(posdiff=FALSE, maxiter=2),
                 PSOCKcluster=cl)

## Not run: 
if (!is.null(cl)){
    stopCluster(cl)
    rm(cl)
}
## End(Not run)

print(summary(tmp))


#-------------------------------------------------
#    Binomial with logit link function, longitudinal data
#         using mmglmlong1

#   n = series length for each subject
#   N = number of subjects
n &lt;- 10
N &lt;- 100

#   the range of x need changing according to the glmfamily
x &lt;- seq(-1, 1.5, length.out=n)

colour &lt;- c("blue", "green", "red")
colnum &lt;- rep(1:3, n/3+1)[1:n] - 1

data &lt;- data.frame(x=x, colour=colour[colnum+1])

glmformula &lt;- formula( ~ x + I(x^2) + colour)
glmfamily &lt;- binomial(link="logit")
Xdesign0 &lt;- model.matrix(glmformula, data=data)

#    multiple subjects
Xdesign &lt;- NULL
for (i in 1:N) Xdesign &lt;- rbind(Xdesign, Xdesign0)

# --- Parameter Values and Simulation ---

Pi &lt;- matrix(c(0.8, 0.2,
               0.3, 0.7),
             byrow=TRUE, nrow=2)

delta &lt;- c(0.5, 0.5)

beta &lt;- matrix(c(-1, -1.2,
                 -2, -1.8,
                  3,  2.8,
                  1,  0.8, 
                  2,  2.2), 
               ncol=ncol(Pi), nrow=ncol(Xdesign), byrow=TRUE)

y &lt;- mmglmlong1(NULL, Pi, delta, glmfamily, beta, Xdesign, sigma=sd,
                longitude=rep(1:N, each=n), size=rep(200, N*n))

y &lt;- simulate(y, seed=5)

# --- Estimation ---

#   Increase maxiter below to achieve convergence
#   Has been restricted to minimise time of package checks
tmp &lt;- BaumWelch(y, bwcontrol(posdiff=FALSE, maxiter=1))
print(summary(tmp))
</code></pre>

<hr>
<h2 id='mmglm-2nd-level-functions'>Markov Modulated Generalised Linear Model - 2nd Level Functions</h2><span id='topic+mmglm-2nd-level-functions'></span><span id='topic+Estep.mmglm1'></span><span id='topic+Mstep.mmglm1'></span>

<h3>Description</h3>

<p>These functions will generally not be called directly by the user.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Estep.mmglm1(object, fortran=TRUE)
Mstep.mmglm1(object, u)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mmglm-2nd-level-functions_+3A_object">object</code></td>
<td>
<p>an object with class <code>"mmglm"</code> or <code>"mmglmlong"</code></p>
</td></tr>
<tr><td><code id="mmglm-2nd-level-functions_+3A_u">u</code></td>
<td>
<p>a matrix of weights by Markov state and observation used in fitting the generalised linear model.</p>
</td></tr>
<tr><td><code id="mmglm-2nd-level-functions_+3A_fortran">fortran</code></td>
<td>
<p>logical, if <code>TRUE</code> (default) use the Fortran code in the forward-backward equations, else use the <span class="rlang"><b>R</b></span> code.</p>
</td></tr>
</table>

<hr>
<h2 id='mmpp'>Markov Modulated Poisson Process Object</h2><span id='topic+mmpp'></span>

<h3>Description</h3>

<p>Creates a Markov modulated Poisson process model object with class <code>"mmpp"</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mmpp(tau, Q, delta, lambda, nonstat = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mmpp_+3A_tau">tau</code></td>
<td>
<p>vector containing the <em>event times</em>. Note that the first event is at time zero. Alternatively, <code>tau</code> could be specified as <code>NULL</code>, meaning that the data will be added later (e.g. simulated).</p>
</td></tr>
<tr><td><code id="mmpp_+3A_q">Q</code></td>
<td>
<p>the infinitesimal generator matrix of the Markov process.</p>
</td></tr>
<tr><td><code id="mmpp_+3A_delta">delta</code></td>
<td>
<p>is the marginal probability distribution of the <code class="reqn">m</code> hidden states at time zero.</p>
</td></tr>
<tr><td><code id="mmpp_+3A_lambda">lambda</code></td>
<td>
<p>a vector containing the Poisson rates.</p>
</td></tr>
<tr><td><code id="mmpp_+3A_nonstat">nonstat</code></td>
<td>
<p>is logical, <code>TRUE</code> if the homogeneous Markov process is assumed to be non-stationary, default.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Markov modulated Poisson process is based on a hidden Markov process in continuous time. The initial state probabilities (at time zero) are specified by <code>delta</code> and the transition rates by the <code>Q</code> matrix. The rate parameter of the Poisson process (<code>lambda</code>) is determined by the current state of the hidden Markov process. Within each state, the Poisson process is homogeneous (constant rate parameter). A Poisson event is assumed to occur at time zero and at the end of the observation period, however, state transitions of the Markov process do not necessarily coincide with Poisson events. For more details, see Ryden (1996).
</p>


<h3>Value</h3>

<p>A <code><a href="base.html#topic+list">list</a></code> object with class <code>"mmpp"</code>, containing the above arguments as named components.
</p>


<h3>References</h3>

<p>Cited references are listed on the <a href="#topic+HiddenMarkov">HiddenMarkov</a> manual page.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>Q &lt;- matrix(c(-2,  2,
               1, -1),
            byrow=TRUE, nrow=2)/10

#    NULL indicates that we have no data at this point
x &lt;- mmpp(NULL, Q, delta=c(0, 1), lambda=c(5, 1))

x &lt;- simulate(x, nsim=5000, seed=5)

y &lt;- BaumWelch(x)

print(summary(y))

#    log-likelihood using initial parameter values
print(logLik(x))

#    log-likelihood using estimated parameter values
print(logLik(y))
</code></pre>

<hr>
<h2 id='mmpp-2nd-level-functions'>Markov Modulated Poisson Process - 2nd Level Functions</h2><span id='topic+mmpp-2nd-level-functions'></span><span id='topic+forwardback.mmpp'></span><span id='topic+Estep.mmpp'></span>

<h3>Description</h3>

<p>These functions have not been put into a generic format, but are called by generic functions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>forwardback.mmpp(tau, Q, delta, lambda, fortran = TRUE, fwd.only = FALSE)
Estep.mmpp(tau, Q, delta, lambda, fortran = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mmpp-2nd-level-functions_+3A_tau">tau</code></td>
<td>
<p>vector containing the interevent times. Note that the first event is at time zero.</p>
</td></tr>
<tr><td><code id="mmpp-2nd-level-functions_+3A_q">Q</code></td>
<td>
<p>the infinitesimal generator matrix of the Markov process.</p>
</td></tr>
<tr><td><code id="mmpp-2nd-level-functions_+3A_lambda">lambda</code></td>
<td>
<p>a vector containing the Poisson rates.</p>
</td></tr>
<tr><td><code id="mmpp-2nd-level-functions_+3A_delta">delta</code></td>
<td>
<p>is the marginal probability distribution of the <code class="reqn">m</code> hidden states at time zero.</p>
</td></tr>
<tr><td><code id="mmpp-2nd-level-functions_+3A_fortran">fortran</code></td>
<td>
<p>logical, if <code>TRUE</code> (default) use the Fortran code, else use the <span class="rlang"><b>R</b></span> code.</p>
</td></tr>
<tr><td><code id="mmpp-2nd-level-functions_+3A_fwd.only">fwd.only</code></td>
<td>
<p>logical, if <code>FALSE</code> (default) calculate both forward and backward probabilities; else calculate and return only forward probabilities and log-likelihood.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>These functions use the algorithm given by Ryden (1996) based on eigenvalue decompositions.
</p>


<h3>References</h3>

<p>Cited references are listed on the <a href="#topic+HiddenMarkov">HiddenMarkov</a> manual page.
</p>

<hr>
<h2 id='Mstep'>M-Step of EM Algorithm for DTHMM</h2><span id='topic+Mstep'></span><span id='topic+Mstep.beta'></span><span id='topic+Mstep.binom'></span><span id='topic+Mstep.exp'></span><span id='topic+Mstep.gamma'></span><span id='topic+Mstep.glm'></span><span id='topic+Mstep.lnorm'></span><span id='topic+Mstep.logis'></span><span id='topic+Mstep.norm'></span><span id='topic+Mstep.pois'></span>

<h3>Description</h3>

<p>Performs the <em>maximisation</em> step of the EM algorithm for a <code><a href="#topic+dthmm">dthmm</a></code> process. This function is called by the <code><a href="#topic+BaumWelch">BaumWelch</a></code> function. The Baum-Welch algorithm used in the HMM literature is a version of the EM algorithm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Mstep.beta(x, cond, pm, pn, maxiter = 200)
Mstep.binom(x, cond, pm, pn)
Mstep.exp(x, cond, pm, pn)
Mstep.gamma(x, cond, pm, pn, maxiter = 200)
Mstep.glm(x, cond, pm, pn, family, link)
Mstep.lnorm(x, cond, pm, pn)
Mstep.logis(x, cond, pm, pn, maxiter = 200)
Mstep.norm(x, cond, pm, pn)
Mstep.pois(x, cond, pm, pn)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Mstep_+3A_x">x</code></td>
<td>
<p>is a vector of length <code class="reqn">n</code> containing the observed process.</p>
</td></tr>
<tr><td><code id="Mstep_+3A_cond">cond</code></td>
<td>
<p>is an object created by <code><a href="#topic+Estep">Estep</a></code>.</p>
</td></tr>
<tr><td><code id="Mstep_+3A_family">family</code></td>
<td>
<p>character string, the GLM family, one of <code>"gaussian"</code>, <code>"poisson"</code>, <code>"Gamma"</code> or <code>"binomial"</code>.</p>
</td></tr>
<tr><td><code id="Mstep_+3A_link">link</code></td>
<td>
<p>character string, the link function. If <code>family == "Binomial"</code>, then one of <code>"logit"</code>, <code>"probit"</code> or <code>"cloglog"</code>; else one of <code>"identity"</code>, <code>"inverse"</code> or <code>"log"</code>.</p>
</td></tr>
<tr><td><code id="Mstep_+3A_pm">pm</code></td>
<td>
<p>is a list object containing the current (Markov dependent) parameter estimates associated with the distribution of the observed process (see <code><a href="#topic+dthmm">dthmm</a></code>). These are only used as initial values if the algorithm within the <code>Mstep</code> is iterative.</p>
</td></tr>
<tr><td><code id="Mstep_+3A_pn">pn</code></td>
<td>
<p>is a list object containing the observation dependent parameter values associated with the distribution of the observed process (see <code><a href="#topic+dthmm">dthmm</a></code>).</p>
</td></tr>
<tr><td><code id="Mstep_+3A_maxiter">maxiter</code></td>
<td>
<p>maximum number of Newton-Raphson iterations.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The functions <code>Mstep.beta</code>, <code>Mstep.binom</code>, <code>Mstep.exp</code>, <code>Mstep.gamma</code>, <code>Mstep.lnorm</code>, <code>Mstep.logis</code>, <code>Mstep.norm</code> and <code>Mstep.pois</code> perform the maximisation step for the Beta, Binomial, Exponential, Gamma, Log Normal, Logistic, Normal and Poisson distributions, respectively. Each function has the same argument list, even if specific arguments are redundant, because the functions are called from within other functions in a generic like manner. Specific notes for some follow.
</p>

<dl>
<dt><code>Mstep.beta</code></dt><dd><p>The <span class="rlang"><b>R</b></span> functions for the <code><a href="stats.html#topic+Beta">Beta</a></code> Distribution have arguments <code>shape1</code>, <code>shape2</code> and <code>ncp</code>. We only use <code>shape1</code> and <code>shape2</code>, i.e. <code>ncp</code> is assumed to be zero. Different combinations of <code>"shape1"</code> and <code>"shape2"</code> can be &ldquo;time&rdquo; dependent (specified in <code>pn</code>) and Markov dependent (specified in <code>pm</code>). However, each should only be specified in one (see topic <code><a href="#topic+dthmm">dthmm</a></code>).
</p>
</dd>
<dt><code>Mstep.binom</code></dt><dd><p>The <span class="rlang"><b>R</b></span> functions for the <code><a href="stats.html#topic+Binomial">Binomial</a></code> Distribution have arguments <code>size</code> and <code>prob</code>. The <code>size</code> argument of the <code><a href="stats.html#topic+Binomial">Binomial</a></code> Distribution should always be specified in the <code>pn</code> argument (see topic <code><a href="#topic+dthmm">dthmm</a></code>).
</p>
</dd>
<dt><code>Mstep.gamma</code></dt><dd><p>The <span class="rlang"><b>R</b></span> functions for the <code><a href="stats.html#topic+GammaDist">GammaDist</a></code> have arguments <code>shape</code>, <code>rate</code> and <code>scale</code>. Since <code>scale</code> is redundant, we only use <code>shape</code> and <code>rate</code>. Different combinations of <code>"shape"</code> and <code>"rate"</code> can be &ldquo;time&rdquo; dependent (specified in <code>pn</code>) and Markov dependent (specified in <code>pm</code>). However, each should only be specified in one (see topic <code><a href="#topic+dthmm">dthmm</a></code>).
</p>
</dd>
<dt><code>Mstep.lnorm</code></dt><dd><p>The <span class="rlang"><b>R</b></span> functions for the <code><a href="stats.html#topic+Lognormal">Lognormal</a></code> Distribution have arguments <code>meanlog</code> and <code>sdlog</code>. Different combinations of <code>"meanlog"</code> and <code>"sdlog"</code> can be &ldquo;time&rdquo; dependent (specified in <code>pn</code>) and Markov dependent (specified in <code>pm</code>). However, each should only be specified in one (see topic <code><a href="#topic+dthmm">dthmm</a></code>).
</p>
</dd>
<dt><code>Mstep.logis</code></dt><dd><p>The <span class="rlang"><b>R</b></span> functions for the <code><a href="stats.html#topic+Logistic">Logistic</a></code> Distribution have arguments <code>location</code> and <code>scale</code>. Different combinations of <code>"location"</code> and <code>"scale"</code> can be &ldquo;time&rdquo; dependent (specified in <code>pn</code>) and Markov dependent (specified in <code>pm</code>). However, each should only be specified in one (see topic <code><a href="#topic+dthmm">dthmm</a></code>).
</p>
</dd>
<dt><code>Mstep.norm</code></dt><dd><p>The <span class="rlang"><b>R</b></span> functions for the <code><a href="stats.html#topic+Normal">Normal</a></code> Distribution have arguments <code>mean</code> and <code>sd</code>. Different combinations of <code>"mean"</code> and <code>"sd"</code> can be &ldquo;time&rdquo; dependent (specified in <code>pn</code>) and Markov dependent (specified in <code>pm</code>). However, each should only be specified in one (see topic <code><a href="#topic+dthmm">dthmm</a></code>).
</p>
</dd>
</dl>



<h3>Value</h3>

<p>A list object with the same structure as <code>pm</code> (see topic <code><a href="#topic+dthmm">dthmm</a></code>).
</p>


<h3>Modifications and Extensions</h3>

<p>The <span class="pkg">HiddenMarkov</span> package calls the associated functions belonging to the specified probability distribution in a generic way. For example, if the argument <code>distn</code> in <code><a href="#topic+dthmm">dthmm</a></code> is <code>"xyz"</code>, it will expect to find functions <code>pxyz</code>, <code>dxyz</code>, and <code>Mstep.xyz</code>. And if simulations are to be performed, it will require <code>rxyz</code>. In this section we describe the required format for the distribution related functions <code>pxyz</code>, <code>dxyz</code>, and <code>rxyz</code>; and for the function <code>Mstep.xyz</code> required for the M-step in the EM algorithm.
</p>
<p>Consider the examples below of distribution related functions and their arguments. Note that the probability functions all have a first argument of <code>q</code>, and the last two arguments are all the same, with the same default values. Similarly, the density functions have a first argument of <code>x</code>, and the last argument is the same, with the same defaults. The arguments in the middle are peculiar to the given distribution, <em>one argument for each distribution parameter</em>. Note that the observed process <code>x</code> is <em>univariate</em>.
</p>
<pre>
pnorm(q, mean = 0, sd = 1, lower.tail = TRUE, log.p = FALSE)
pbeta(q, shape1, shape2, ncp = 0, lower.tail = TRUE, log.p = FALSE)
ppois(q, lambda, lower.tail = TRUE, log.p = FALSE)
pbinom(q, size, prob, lower.tail = TRUE, log.p = FALSE)

dnorm(x, mean = 0, sd = 1, log = FALSE)
dbeta(x, shape1, shape2, ncp = 0, log = FALSE)
dpois(x, lambda, log = FALSE)
dbinom(x, size, prob, log = FALSE)

rnorm(n, mean = 0, sd = 1)
rbeta(n, shape1, shape2, ncp = 0)
rpois(n, lambda)
rbinom(n, size, prob)

</pre>
<p>The functions <code>pxyz</code> (distribution function), <code>dxyz</code> (density) and <code>rxyz</code> (random number generator) must be consistent with the conventions used in the above examples. The software will deduce the distribution argument names from what is specified in <code>pm</code> and <code>pn</code>, and it will call these functions assuming that their argument list is consistent with those described above. The functions <code>pxyz</code> and <code>dxyz</code> are used in the forward and backward equations.
<br />
</p>
<p>The functions <code>dxyz</code>, <code>pxyz</code> and <code>rxyz</code> <em>must</em> also behave in the same vectorised way as <code><a href="stats.html#topic+dnorm">dnorm</a></code>. For example, if <code>x</code> is a vector, and <code>mean</code> and <code>sd</code> are scalars, then <code><a href="stats.html#topic+dnorm">dnorm</a>(x, mean, sd)</code> calculates the density for each element in <code>x</code> using the scalar values of <code>mean</code> and <code>sd</code>; thus the returned value is the same length as <code>x</code>. Alternatively, if <code>x</code> is a scalar and <code>mean</code> and <code>sd</code> are vectors, both of the same length, then the returned value is the same length as <code>mean</code> and is the density of <code>x</code> evaluated at the corresponding pairs of values of <code>mean</code> and <code>sd</code>. The third possibility is that <code>x</code> and one of the distribution parameters, say <code>sd</code>, are vectors of the same length, and <code>mu</code> is a scalar. Then the returned vector will be of the same length as <code>x</code>, where the <code class="reqn">i</code>th value is the density at <code>x[i]</code> with mean <code>mean</code> and standard deviation <code>sd[i]</code>. Note that the functions for the <code><a href="stats.html#topic+Multinomial">Multinomial</a></code> distribution do not have this behaviour. Here the vector <code>x</code> contains the counts for <em>one</em> multinomial experiment, so the vector is used to characterise the multivariate character of the random variable rather than multiple univariate realisations. Further, the distribution parameters (i.e. category probabilities) are characterised as one vector rather than a sequence of separate function arguments.
<br />
</p>
<p>The other calculation, that is specific to the chosen distribution, is the maximisation in the M-step. If we have <code>distn="xyz"</code>, then there should be a function called <code>Mstep.xyz</code>. Further, it should have arguments <code>(x, cond, pm, pn)</code>; see for example <code>Mstep.norm</code>. The parameters that are estimated within this function are named in a consistent way with those that are defined within the <code><a href="#topic+dthmm">dthmm</a></code> arguments <code>pm</code> and <code>pn</code>. Notice that the estimates of <code>mean</code> and <code>sd</code> in <code>Mstep.norm</code> are weighted by <code>cond$u</code>. The calculations for <code>cond$u</code> are performed in the E-step, and utilise the distribution related functions <code>"dxyz"</code> and <code>"pxyz"</code>. The values of <code>cond$u</code> are essentially probabilities that the process belongs to the given Markov state, hence, when we calculate the distributional parameters (like <code>mu</code> and <code>sd</code> in <code>Mstep.norm</code>) we calculate weighted sums using the probabilities <code>cond$u</code>. This procedure can be shown to give the maximum likelihood estimates of <code>mu</code> and <code>sd</code>, and hence a similar weighting should be used for the distribution <code>"xyz"</code> (see Harte, 2006, for further mathematical detail). One needs to take a little more care when dealing with a distributions like the beta, where the cross derivatives of the log likelihood between the parameters, i.e. <code class="reqn">\partial^2 \log L /(\partial \alpha_1 \partial \alpha_2)</code> are non-zero. See <code>Mstep.beta</code> for further details.
<br />
</p>
<p>Now consider a situation where we want to modify the way in which a normal distribution is fitted. Say we know the Markov dependent means, and we only want to estimate the standard deviations. Since both parameters are Markov dependent, they both need to be specified in the <code>pm</code> argument of <code><a href="#topic+dthmm">dthmm</a></code>. The estimation of the distribution specific parameters takes place in the M-step, in this case <code><a href="#topic+Mstep.norm">Mstep.norm</a></code>. To achieve what we want, we need to modify this function. In this case it is relatively easy (see code in &ldquo;Examples&rdquo; below). From the function <code><a href="#topic+Mstep.norm">Mstep.norm</a></code>, take the code under the section <code>if (all(nms==c("mean", "sd")))</code>, i.e. both of the parameters are Markov dependent. However, replace the line where the mean is estimated to <code>mean &lt;- pm$mean</code>, i.e. leave it as was initially specified. Unfortunately, one cannot easily modify the functions in a package namespace. The simple work-around here is to define a new distribution, say <code>"xyz"</code>, then define a new function with the above changes called <code>Mstep.xyz</code>. However, the distribution related functions are just the same as those for the normal distribution, hence, define them as follows:
</p>
<pre>
rxyz &lt;- rnorm
dxyz &lt;- dnorm
pxyz &lt;- pnorm
qxyz &lt;- qnorm
</pre>
<p>See the 2nd example below for full details.
</p>


<h3>Note</h3>

<p>The Mstep functions can be used to estimate the maximum likelihood parameters from a simple sample. See the example below where this is done for the logistic distribution.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+BaumWelch">BaumWelch</a></code>, <code><a href="#topic+Estep">Estep</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#    Fit logistic distribution to a simple single sample

#    Simulate data
n &lt;- 20000
location &lt;- -2
scale &lt;- 1.5

x &lt;- rlogis(n, location, scale)

#    give each datum equal weight
cond &lt;- NULL
cond$u &lt;- matrix(rep(1/n, n), ncol=1)

#    calculate maximum likelihood parameter estimates
#    start iterations at values used to simulate
print(Mstep.logis(x, cond,
                  pm=list(location=location,
                          scale=scale)))

#-----------------------------------------------------
#   Example with Gaussian Observations
#   Assume that both mean and sd are Markov dependent, but the means
#   are known and sd requires estimation (See "Modifications" above).
#   One way is to define a new distribution called "xyz", say.

Mstep.xyz &lt;- function(x, cond, pm, pn){
    #   this function is a modified version of Mstep.norm
    #   here the mean is fixed to the values specified in pm$mean
    nms &lt;- sort(names(pm))
    n &lt;- length(x)
    m &lt;- ncol(cond$u)
    if (all(nms==c("mean", "sd"))){
        mean &lt;- pm$mean
        sd &lt;- sqrt(apply((matrix(x, nrow=n, ncol=m) - 
                   matrix(mean,
                   nrow=n, ncol=m, byrow=TRUE))^2 * cond$u, MARGIN=2,
                   FUN=sum)/apply(cond$u, MARGIN=2, FUN=sum))
        return(list(mean=mean, sd=sd))
    }
}

#   define the distribution related functions for "xyz"
#   they are the same as those for the Normal distribution
rxyz &lt;- rnorm
dxyz &lt;- dnorm
pxyz &lt;- pnorm
qxyz &lt;- qnorm

Pi &lt;- matrix(c(1/2, 1/2,   0,
               1/3, 1/3, 1/3,
                 0, 1/2, 1/2),
             byrow=TRUE, nrow=3)
p1 &lt;- c(1, 6, 3)
p2 &lt;- c(0.5, 1, 0.5)
n &lt;- 1000

pm &lt;- list(mean=p1, sd=p2)

x &lt;- dthmm(NULL, Pi, c(0, 1, 0), "xyz", pm, discrete=FALSE)

x &lt;- simulate(x, n, seed=5)

#    use above parameter values as initial values
y &lt;- BaumWelch(x)

print(y$delta)
print(y$pm)
print(y$Pi)
</code></pre>

<hr>
<h2 id='neglogLik'>Negative Log-Likelihood</h2><span id='topic+neglogLik'></span>

<h3>Description</h3>

<p>Calculates the log-likelihood multiplied by negative one. It is in a format that can be used with the functions <code><a href="stats.html#topic+nlm">nlm</a></code> and <code><a href="stats.html#topic+optim">optim</a></code>, providing an alternative to the <code><a href="#topic+BaumWelch">BaumWelch</a></code> algorithm for maximum likelihood parameter estimation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>neglogLik(params, object, pmap)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="neglogLik_+3A_params">params</code></td>
<td>
<p>a vector of revised parameter values.</p>
</td></tr>
<tr><td><code id="neglogLik_+3A_object">object</code></td>
<td>
<p>an object of class <code>"<a href="#topic+dthmm">dthmm</a>"</code>, <code>"<a href="#topic+mmglm0">mmglm0</a>"</code>, or <code>"<a href="#topic+mmpp">mmpp</a>"</code>.</p>
</td></tr>
<tr><td><code id="neglogLik_+3A_pmap">pmap</code></td>
<td>
<p>a user provided function mapping the revised (or restricted) parameter values <code>p</code> into the appropriate locations in <code>object</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is in a format that can be used with the two functions <code><a href="stats.html#topic+nlm">nlm</a></code> and <code><a href="stats.html#topic+optim">optim</a></code> (see Examples below). This provides alternative methods of estimating the maximum likelihood parameter values, to that of the EM algorithm provided by <code><a href="#topic+BaumWelch">BaumWelch</a></code>, including Newton type methods and grid searches. It can also be used to restrict estimation to a subset of parameters.
</p>
<p>The EM algorithm is relatively stable when starting from poor initial values but convergence is very slow in close proximity to the solution. Newton type methods are very sensitive to initial conditions but converge much more quickly in close proximity to the solution. This suggests initially using the EM algorithm and then switching to Newton type methods (see Examples below).
</p>
<p>The maximisation of the model likelihood function can be restricted to be over a subset of the model parameters. Other parameters will then be fixed at the values stored in the model <code>object</code>. Let <code class="reqn">\Theta</code> denote the model parameter space, and let <code class="reqn">\Psi</code> denote the parameter sub-space (<code class="reqn">\Psi \subseteq \Theta</code>) over which the likelihood function is to be maximised. The argument <code>params</code> contains values in <code class="reqn">\Psi</code>, and <code>pmap</code> is assigned a function that maps these values into the model parameter space <code class="reqn">\Theta</code>. See &ldquo;Examples&rdquo; below.
</p>
<p>The mapping function assigned to <code>pmap</code> can also be made to impose restrictions on the domain of the parameter space <code class="reqn">\Psi</code> so that the minimiser cannot jump to values such that <code class="reqn">\Psi \not\subseteq \Theta</code>. For example, if a particular parameter must be positive, one can work with a transformed parameter that can take any value on the real line, with the model parameter being the exponential of this transformed parameter. Similarly a modified logit like transform can be used to ensure that parameter values remain within a fixed interval with finite boundaries. Examples of these situations can be found in the  &ldquo;Examples&rdquo; below.
</p>
<p>Some functions are provided in the topic <code><a href="#topic+Transform-Parameters">Transform-Parameters</a></code> that may provide useful components within the user provided function assigned to <code>pmap</code>.
</p>


<h3>Value</h3>

<p>Value of the log-likelihood times negative one.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+nlm">nlm</a></code>, <code><a href="stats.html#topic+optim">optim</a></code>, <code><a href="#topic+Transform-Parameters">Transform-Parameters</a></code>, <code><a href="#topic+BaumWelch">BaumWelch</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>#   Example where the Markov chain is assumed to be stationary

Pi &lt;- matrix(c(0.8, 0.1, 0.1,
               0.1, 0.6, 0.3,
               0.2, 0.3, 0.5),
             byrow=TRUE, nrow=3)

#   start simulation in state 2
delta &lt;- c(0, 1, 0)

x &lt;- dthmm(NULL, Pi, delta, "exp", list(rate=c(5, 2, 0.2)), nonstat=FALSE)
x &lt;- simulate(x, nsim=5000, seed=5)

#   Approximate solution using BaumWelch
x1 &lt;- BaumWelch(x, control=bwcontrol(maxiter=10, tol=1e-5))


#   Exact solution using nlm

allmap &lt;- function(y, p){
    #    maps vector back to delta, Pi and rate
    m &lt;- sqrt(length(p))
    y$Pi &lt;- vector2Pi(p[1:(m*(m-1))])
    y$pm$rate &lt;- exp(p[(m^2-m+1):(m^2)])
    y$delta &lt;- compdelta(Pi)
    return(y)
}

p &lt;- c(Pi2vector(x$Pi), log(x$pm$rate))
#   Increase iterlim below to achieve convergence
#   Has been restricted to minimise time of package checks
z &lt;- nlm(neglogLik, p, object=x, pmap=allmap,
         print.level=2, gradtol=0.000001, iterlim=2)
x2 &lt;- allmap(x, z$estimate)


#   compare parameter estimates
print(summary(x))
print(summary(x1))
print(summary(x2))


#--------------------------------------------------------
#   Estimate only the off diagonal elements in the matrix Pi
#   Hold all others as in the simulation

#   This function maps the changeable parameters into the
#   dthmm object - done within the function neglogLik
#   The logit-like transform removes boundaries

Pi &lt;- matrix(c(0.8, 0.1, 0.1,
               0.1, 0.6, 0.3,
               0.2, 0.3, 0.5),
             byrow=TRUE, nrow=3)

delta &lt;- c(0, 1, 0)

x &lt;- dthmm(NULL, Pi, delta, "exp", list(rate=c(5, 3, 1)))
x &lt;- simulate(x, nsim=5000, seed=5)

offdiagmap &lt;- function(y, p){
    #   rows must sum to one
    invlogit &lt;- function(eta)
        exp(eta)/(1+exp(eta))
    y$Pi[1,2] &lt;- (1-y$Pi[1,1])*invlogit(p[1])
    y$Pi[1,3] &lt;- 1-y$Pi[1,1]-y$Pi[1,2]
    y$Pi[2,1] &lt;- (1-y$Pi[2,2])*invlogit(p[2])
    y$Pi[2,3] &lt;- 1-y$Pi[2,1]-y$Pi[2,2]
    y$Pi[3,1] &lt;- (1-y$Pi[3,3])*invlogit(p[3])
    y$Pi[3,2] &lt;- 1-y$Pi[3,1]-y$Pi[3,3]
    return(y)
}

z &lt;- nlm(neglogLik, c(0, 0, 0), object=x, pmap=offdiagmap,
         print.level=2, gradtol=0.000001)

#    x1 contains revised parameter estimates
x1 &lt;- offdiagmap(x, z$estimate)

#    print revised values of Pi
print(x1$Pi)

#    print log-likelihood using original and revised values
print(logLik(x))
print(logLik(x1))

#--------------------------------------------------------
#   Fully estimate both Q and lambda for an MMPP Process

Q &lt;- matrix(c(-8,  5,  3,
               1, -4,  3,
               2,  5, -7),
            byrow=TRUE, nrow=3)/25
lambda &lt;- c(5, 3, 1)
delta &lt;- c(0, 1, 0)

#    simulate some data
x &lt;- mmpp(NULL, Q, delta, lambda)
x &lt;- simulate(x, nsim=5000, seed=5)

allmap &lt;- function(y, p){
    #    maps vector back to Pi and rate
    m &lt;- sqrt(length(p))
    y$Q &lt;- vector2Q(p[1:(m*(m-1))])
    y$lambda &lt;- exp(p[(m^2-m+1):(m^2)])
    return(y)
}

#    Start by using the EM algorithm
x1 &lt;- BaumWelch(x, control=bwcontrol(maxiter=10, tol=0.01))

#    use above as initial values for the nlm function
#    map parameters to a single vector, fixed delta
p &lt;- c(Q2vector(x1$Q), log(x1$lambda))

#    Complete estimation using nlm
#    Increase iterlim below to achieve convergence
#    Has been restricted to minimise time of package checks
z &lt;- nlm(neglogLik, p, object=x, pmap=allmap,
         print.level=2, gradtol=0.000001, iterlim=5)

#    mmpp object with estimated parameter values from nlm
x2 &lt;- allmap(x, z$estimate)

#    compare log-likelihoods
print(logLik(x))
print(logLik(x1))
print(logLik(x2))

#   print final parameter estimates
print(summary(x2))
</code></pre>

<hr>
<h2 id='probhmm'>Conditional Distribution Function of DTHMM</h2><span id='topic+probhmm'></span>

<h3>Description</h3>

<p>Calculates the distribution function at each point for a <code><a href="#topic+dthmm">dthmm</a></code> process given the complete observed process except the given point.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>probhmm(logalpha, logbeta, Pi, delta, cumprob)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="probhmm_+3A_logalpha">logalpha</code></td>
<td>
<p>an <code class="reqn">n \times m</code> matrix containing the logarithm of the forward probabilities.</p>
</td></tr>
<tr><td><code id="probhmm_+3A_logbeta">logbeta</code></td>
<td>
<p>an <code class="reqn">n \times m</code> matrix containing the logarithm of the backward probabilities.</p>
</td></tr>
<tr><td><code id="probhmm_+3A_pi">Pi</code></td>
<td>
<p>is the <code class="reqn">m \times m</code> transition probability matrix of the hidden Markov chain.</p>
</td></tr>
<tr><td><code id="probhmm_+3A_delta">delta</code></td>
<td>
<p>is the marginal probability distribution of the <code class="reqn">m</code> hidden states at the first time point.</p>
</td></tr>
<tr><td><code id="probhmm_+3A_cumprob">cumprob</code></td>
<td>
<p>an <code class="reqn">n \times m</code> matrix where the <code class="reqn">(i,k)</code>th element is <code class="reqn">\Pr\{ X_i \le x_i \,|\, C_k = c_k\}</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Let <code class="reqn">X^{(-i)}</code> denote the entire process, except with the point <code class="reqn">X_i</code> removed. The distribution function at the point <code class="reqn">X_i</code> is
</p>
<p style="text-align: center;"><code class="reqn">
\Pr\{ X_i \le x_i \,|\, X^{(-i)} = x^{(-i)} \}\,.
</code>
</p>

<p>This <span class="rlang"><b>R</b></span> function calculates the distribution function for each point <code class="reqn">X_i</code> for <code class="reqn">i=1, \cdots, n</code>. This is done by using the forward and backward probabilities before and after the <code class="reqn">i</code>th point, respectively.
</p>
<p>In the programming code, note the subtraction of the mean. This is to stop underflow when the exponential is taken. Removal of the mean is automatically compensated for by the fact that the same factor is removed in both the numerator and denominator.
</p>


<h3>Value</h3>

<p>A vector containing the probability.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+residuals">residuals</a></code></p>

<hr>
<h2 id='residuals'>Residuals of Hidden Markov Model</h2><span id='topic+residuals'></span><span id='topic+residuals.dthmm'></span><span id='topic+residuals.mmglm0'></span><span id='topic+residuals.mmglm1'></span><span id='topic+residuals.mmglmlong1'></span>

<h3>Description</h3>

<p>Provides methods for the generic function <code><a href="stats.html#topic+residuals">residuals</a></code>. There is currently no method for objects of class <code>"<a href="#topic+mmpp">mmpp</a>"</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'dthmm'
residuals(object, ...)
## S3 method for class 'mmglm0'
residuals(object, ...)
## S3 method for class 'mmglm1'
residuals(object, ...)
## S3 method for class 'mmglmlong1'
residuals(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="residuals_+3A_object">object</code></td>
<td>
<p>an object with class <code><a href="#topic+dthmm">dthmm</a></code>, <code><a href="#topic+mmglm0">mmglm0</a></code>, <code><a href="#topic+mmglm1">mmglm1</a></code> or <code><a href="#topic+mmglmlong1">mmglmlong1</a></code>.</p>
</td></tr>
<tr><td><code id="residuals_+3A_...">...</code></td>
<td>
<p>other arguments.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The calculated residuals are <em>pseudo residuals</em>. Under satisfactory conditions they have an approximate standard normal distribution. Initially the function <code><a href="#topic+probhmm">probhmm</a></code> is called. If the model fits satisfactorily, the returned values should be approximately uniformly distributed. Hence by applying the function <code><a href="stats.html#topic+Normal">qnorm</a></code>, the resultant &ldquo;residuals&rdquo; should have an approximate standard normal distribution.
</p>
<p>A continuity adjustment is made when the observed distribution is discrete. In the case of count distributions (e.g. binomial and Poisson) where the observed count is close to or on the boundary of the domain (e.g. binomial or Poisson count is zero, or binomial count is &ldquo;n&rdquo;), the pseudo residuals will give a very poor indication of the models goodness of fit; see the Poisson example below.
</p>
<p>The code for the methods <code>"<a href="#topic+dthmm">dthmm</a>"</code>, <code>"<a href="#topic+mmglm0">mmglm0</a>"</code>, <code>"<a href="#topic+mmglm1">mmglm1</a>"</code> and <code>"<a href="#topic+mmglmlong1">mmglmlong1</a>"</code> can be viewed by appending <code>residuals.dthmm</code>, <code>residuals.mmglm0</code>, <code>residuals.mmglm1</code> or <code>residuals.mmglmlong1</code>, respectively, to <code>HiddenMarkov:::</code>, on the <span class="rlang"><b>R</b></span> command line; e.g. <code>HiddenMarkov:::dthmm</code>. The three colons are needed because these method functions are not in the exported NAMESPACE.
</p>


<h3>Value</h3>

<p>A vector containing the pseudo residuals.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#   Example Using Beta Distribution

Pi &lt;- matrix(c(0.8, 0.2,
               0.3, 0.7),
             byrow=TRUE, nrow=2)

n &lt;- 2000

x &lt;- dthmm(NULL, Pi, c(0,1), "beta",
           list(shape1=c(2, 6), shape2=c(6, 2)))

x &lt;- simulate(x, nsim=n, seed=5)

y &lt;- residuals(x) 

w &lt;- hist(y, main="Beta HMM: Pseudo Residuals")
z &lt;- seq(-3, 3, 0.01)
points(z, dnorm(z)*n*(w$breaks[2]-w$breaks[1]), col="red", type="l")
box()

qqnorm(y, main="Beta HMM: Q-Q Plot of Pseudo Residuals")
abline(a=0, b=1, lty=3)
abline(h=seq(-2, 2, 1), lty=3)
abline(v=seq(-2, 2, 1), lty=3)


#-----------------------------------------------
#   Example Using Gaussian Distribution

Pi &lt;- matrix(c(1/2, 1/2,   0,   0,   0,
               1/3, 1/3, 1/3,   0,   0,
                 0, 1/3, 1/3, 1/3,   0,
                 0,   0, 1/3, 1/3, 1/3,
                 0,   0,   0, 1/2, 1/2),
             byrow=TRUE, nrow=5)

x &lt;- dthmm(NULL, Pi, c(0, 1, 0, 0, 0), "norm",
           list(mean=c(1, 4, 2, 5, 3), sd=c(0.5, 1, 1, 0.5, 0.1)))

n &lt;- 2000
x &lt;- simulate(x, nsim=n, seed=5)

y &lt;- residuals(x) 

w &lt;- hist(y, main="Gaussian HMM: Pseudo Residuals")
z &lt;- seq(-3, 3, 0.01)
points(z, dnorm(z)*n*(w$breaks[2]-w$breaks[1]), col="red", type="l")
box()

qqnorm(y, main="Gaussian HMM: Q-Q Plot of Pseudo Residuals")
abline(a=0, b=1, lty=3)
abline(h=seq(-2, 2, 1), lty=3)
abline(v=seq(-2, 2, 1), lty=3)


#-----------------------------------------------
#   Example Using Poisson Distribution  

Pi &lt;- matrix(c(0.8, 0.2,
               0.3, 0.7),
             byrow=TRUE, nrow=2)

x &lt;- dthmm(NULL, Pi, c(0, 1), "pois",
           list(lambda=c(1, 5)), discrete=TRUE)

n &lt;- 2000
x &lt;- simulate(x, nsim=n, seed=5)

y &lt;- residuals(x) 

w &lt;- hist(y, main="Poisson HMM: Pseudo Residuals")
z &lt;- seq(-3, 3, 0.01)
points(z, dnorm(z)*n*(w$breaks[2]-w$breaks[1]), col="red", type="l")
box()

qqnorm(y, main="Poisson HMM: Q-Q Plot of Pseudo Residuals")
abline(a=0, b=1, lty=3)
abline(h=seq(-2, 2, 1), lty=3)
abline(v=seq(-2, 2, 1), lty=3)
</code></pre>

<hr>
<h2 id='simulate'>Simulate Hidden Markov Process</h2><span id='topic+simulate'></span><span id='topic+simulate.dthmm'></span><span id='topic+simulate.mchain'></span><span id='topic+simulate.mmglm0'></span><span id='topic+simulate.mmglm1'></span><span id='topic+simulate.mmglmlong1'></span><span id='topic+simulate.mmpp'></span>

<h3>Description</h3>

<p>These functions provide methods for the generic function <code><a href="stats.html#topic+simulate">simulate</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'dthmm'
simulate(object, nsim = 1, seed = NULL, ...)
## S3 method for class 'mchain'
simulate(object, nsim = 1, seed = NULL, ...)
## S3 method for class 'mmglm0'
simulate(object, nsim = 1, seed = NULL, ...)
## S3 method for class 'mmglm1'
simulate(object, nsim = 1, seed = NULL, ...)
## S3 method for class 'mmglmlong1'
simulate(object, nsim = 1, seed = NULL, ...)
## S3 method for class 'mmpp'
simulate(object, nsim = 1, seed = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="simulate_+3A_object">object</code></td>
<td>
<p>an object with class <code>"<a href="#topic+dthmm">dthmm</a>"</code>, <code>"<a href="#topic+mchain">mchain</a>"</code>, <code>"<a href="#topic+mmglm0">mmglm0</a>"</code>, <code>"<a href="#topic+mmglm1">mmglm1</a>"</code>, <code>"<a href="#topic+mmglmlong1">mmglmlong1</a>"</code> or <code>"<a href="#topic+mmpp">mmpp</a>"</code>.</p>
</td></tr>
<tr><td><code id="simulate_+3A_nsim">nsim</code></td>
<td>
<p>number of points to simulate.</p>
</td></tr>
<tr><td><code id="simulate_+3A_seed">seed</code></td>
<td>
<p>seed for the random number generator.</p>
</td></tr>
<tr><td><code id="simulate_+3A_...">...</code></td>
<td>
<p>other arguments.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Below details about particular methods are given where necessary.
</p>

<dl>
<dt><code>simulate.mmglm0</code></dt><dd><p>If the covariate <code>x1</code> is <code>NULL</code>, then uniform (0,1) variables are generated as the values for <code>x1</code>. When the <code>family</code> is <code>"binomial"</code> and <code>size</code> is <code>NULL</code> (i.e. the number of Bernoulli trials are not specified), then they are simulated as <code>100+<a href="stats.html#topic+rpois">rpois</a>(nsim, lambda=5)</code>.</p>
</dd>
</dl>

<p>The code for the methods <code>"<a href="#topic+dthmm">dthmm</a>"</code>, <code>"<a href="#topic+mchain">mchain</a>"</code>, <code>"<a href="#topic+mmglm0">mmglm0</a>"</code>, <code>"<a href="#topic+mmglm1">mmglm1</a>"</code>,<code>"<a href="#topic+mmglmlong1">mmglmlong1</a>"</code> and <code>"<a href="#topic+mmpp">mmpp</a>"</code> can be viewed by appending <code>simulate.dthmm</code>, <code>simulate.mchain</code>, <code>simulate.mmglm0</code>, <code>simulate.mmglm1</code>, <code>simulate.mmglmlong1</code>  or <code>simulate.mmpp</code>, respectively, to <code>HiddenMarkov:::</code>, on the <span class="rlang"><b>R</b></span> command line; e.g. <code>HiddenMarkov:::dthmm</code>. The three colons are needed because these method functions are not in the exported NAMESPACE.
</p>


<h3>Value</h3>

<p>The returned object has the same class as the input object and contains the components that were in the input object. Additional components depend on the class as below:
</p>
<p><code>"<a href="#topic+dthmm">dthmm</a>"</code>: it will also have a vector <code>x</code> containing the simulated values;
</p>
<p><code>"<a href="#topic+mmglm0">mmglm0</a>"</code>: it will also contain a dataframe <code>x</code> about the glm; and
</p>
<p><code>"<a href="#topic+mmpp">mmpp</a>"</code>: <code>tau</code> contains times of the simulated Poisson events (plus time 0), <code>ys</code> is a vector of states at the time of each event, <code>y</code> is the sequence of states visited, and <code>x</code> is the time spent in each state.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#    The hidden Markov chain has 5 states with transition matrix:

Pi &lt;- matrix(c(1/2, 1/2,   0,   0,   0,
               1/3, 1/3, 1/3,   0,   0,
                 0, 1/3, 1/3, 1/3,   0,
                 0,   0, 1/3, 1/3, 1/3,
                 0,   0,   0, 1/2, 1/2),
             byrow=TRUE, nrow=5)

#--------------------------------------------
#   simulate a Poisson HMM

x &lt;- dthmm(NULL, Pi, c(0, 1, 0, 0, 0), "pois",
           list(lambda=c(1, 4, 2, 5, 3)), discrete = TRUE)

x &lt;- simulate(x, nsim=2000)

#    check Poisson means
for (i in 1:5) print(mean(x$x[x$y==i]))

#--------------------------------------------
#   simulate a Gaussian HMM

x &lt;- dthmm(NULL, Pi, c(0, 1, 0, 0, 0), "norm",
           list(mean=c(1, 4, 2, 5, 3), sd=c(0.5, 1, 1, 0.5, 0.1)))

x &lt;- simulate(x, nsim=2000)

#    check means and standard deviations
for (i in 1:5) print(mean(x$x[x$y==i]))
for (i in 1:5) print(sd(x$x[x$y==i]))
</code></pre>

<hr>
<h2 id='summary'>Summary of Hidden Markov Model</h2><span id='topic+summary'></span><span id='topic+summary.dthmm'></span><span id='topic+summary.mmpp'></span><span id='topic+summary.mmglm0'></span><span id='topic+summary.mmglm1'></span><span id='topic+summary.mmglmlong1'></span>

<h3>Description</h3>

<p>Provides methods for the generic function <code><a href="base.html#topic+summary">summary</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'dthmm'
summary(object, ...)
## S3 method for class 'mmglm0'
summary(object, ...)
## S3 method for class 'mmglm1'
summary(object, ...)
## S3 method for class 'mmglmlong1'
summary(object, ...)
## S3 method for class 'mmpp'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary_+3A_object">object</code></td>
<td>
<p>an object with class <code>"<a href="#topic+dthmm">dthmm</a>"</code>, <code>"<a href="#topic+mmglm0">mmglm0</a>"</code>, <code>"<a href="#topic+mmglm1">mmglm1</a>"</code>, <code>"<a href="#topic+mmglmlong1">mmglmlong1</a>"</code> or <code>"<a href="#topic+mmpp">mmpp</a>"</code>.</p>
</td></tr>
<tr><td><code id="summary_+3A_...">...</code></td>
<td>
<p>other arguments.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The code for the methods <code>"<a href="#topic+dthmm">dthmm</a>"</code>, <code>"<a href="#topic+mmglm0">mmglm0</a>"</code>, <code>"<a href="#topic+mmglm1">mmglm1</a>"</code>,<code>"<a href="#topic+mmglmlong1">mmglmlong1</a>"</code> and <code>"<a href="#topic+mmpp">mmpp</a>"</code> can be viewed by appending <code>summary.dthmm</code>, <code>summary.mmglm0</code>, <code>summary.mmglm1</code>, <code>summary.mmglmlong1</code>  or <code>summary.mmpp</code>, respectively, to <code>HiddenMarkov:::</code>, on the <span class="rlang"><b>R</b></span> command line; e.g. <code>HiddenMarkov:::dthmm</code>. The three colons are needed because these method functions are not in the exported NAMESPACE.
</p>


<h3>Value</h3>

<p>A list object with a reduced number of components, mainly the parameter values.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>Pi &lt;- matrix(c(0.8, 0.2,
               0.3, 0.7),
             byrow=TRUE, nrow=2)

x &lt;- dthmm(NULL, Pi, c(0, 1), "beta",
           list(shape1=c(2, 6), shape2=c(6, 2)))

x &lt;- simulate(x, nsim=2000)

print(summary(x))
</code></pre>

<hr>
<h2 id='Transform-Parameters'>Transform Transition or Rate Matrices to Vector</h2><span id='topic+Transform-Parameters'></span><span id='topic+Pi2vector'></span><span id='topic+vector2Pi'></span><span id='topic+Q2vector'></span><span id='topic+vector2Q'></span>

<h3>Description</h3>

<p>These functions transform <code class="reqn">m \times m</code> transition probability matrices or <code class="reqn">Q</code> matrices to a vector of length <code class="reqn">m(m-1)</code>, and back. See Details.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Pi2vector(Pi)
vector2Pi(p)

Q2vector(Q)
vector2Q(p)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Transform-Parameters_+3A_pi">Pi</code></td>
<td>
<p>an <code class="reqn">m</code> by <code class="reqn">m</code> transition probability matrix.</p>
</td></tr>
<tr><td><code id="Transform-Parameters_+3A_q">Q</code></td>
<td>
<p>an <code class="reqn">m</code> by <code class="reqn">m</code> rate matrix.</p>
</td></tr>
<tr><td><code id="Transform-Parameters_+3A_p">p</code></td>
<td>
<p>a vector of length <code class="reqn">m(m-1)</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function <code>Pi2vector</code> maps the <code class="reqn">m</code> by <code class="reqn">m</code> transition probability matrix of a discrete time HMM to a vector of length <code class="reqn">m(m-1)</code>, and <code>vector2Pi</code> has the reverse effect. They use a logit like transformation so that the parameter space is on the whole real line thus avoiding hard boundaries which cause problems for many optimisation procedures (see <code><a href="#topic+neglogLik">neglogLik</a></code>).
</p>
<p>Similarly, the function <code>Q2vector</code> maps the <code class="reqn">m</code> by <code class="reqn">m</code> rate matrix <code class="reqn">Q</code> of an MMPP process to a vector of length <code class="reqn">m(m-1)</code>, and <code>vector2Q</code> has the reverse effect. They use a log transformation so that the parameter space is on the whole real line thus avoiding hard boundaries which cause problems for many optimisation procedures (see <code><a href="#topic+neglogLik">neglogLik</a></code>).
</p>


<h3>Value</h3>

<p>The functions <code>Pi2vector</code> and <code>Q2vector</code> return a vector of length <code class="reqn">m(m-1)</code>, the function <code>vector2Pi</code> returns an <code class="reqn">m</code> by <code class="reqn">m</code> transition probability matrix, and <code>vector2Q</code> returns an <code class="reqn">m \times m</code> rate matrix <code class="reqn">Q</code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+neglogLik">neglogLik</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>Pi &lt;- matrix(c(0.8, 0.1, 0.1,
               0.1, 0.6, 0.3,
               0.2, 0.3, 0.5),
             byrow=TRUE, nrow=3)

print(vector2Pi(Pi2vector(Pi)))

#------------------------------------------------

Q &lt;- matrix(c(-8,  5,  3,
               1, -4,  3,
               2,  5, -7),
            byrow=TRUE, nrow=3)

print(vector2Q(Q2vector(Q)))
</code></pre>

<hr>
<h2 id='Viterbi'>Viterbi Algorithm for Hidden Markov Model</h2><span id='topic+Viterbi'></span><span id='topic+Viterbi.dthmm'></span><span id='topic+Viterbi.mmglm0'></span><span id='topic+Viterbi.mmglm1'></span><span id='topic+Viterbi.mmglmlong1'></span>

<h3>Description</h3>

<p>Provides methods for the generic function <code><a href="#topic+Viterbi">Viterbi</a></code>. This predicts the most likely sequence of Markov states given the observed dataset. There is currently no method for objects of class <code>"<a href="#topic+mmpp">mmpp</a>"</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'dthmm'
Viterbi(object, ...)
## S3 method for class 'mmglm0'
Viterbi(object, ...)
## S3 method for class 'mmglm1'
Viterbi(object, ...)
## S3 method for class 'mmglmlong1'
Viterbi(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Viterbi_+3A_object">object</code></td>
<td>
<p>an object with class <code>"<a href="#topic+dthmm">dthmm</a>"</code>, <code>"<a href="#topic+mmglm0">mmglm0</a>"</code>, <code>"<a href="#topic+mmglm1">mmglm1</a>"</code> or <code>"<a href="#topic+mmglmlong1">mmglmlong1</a>"</code>.</p>
</td></tr>
<tr><td><code id="Viterbi_+3A_...">...</code></td>
<td>
<p>other arguments.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The purpose of the Viterbi algorithm is to <em>globally decode</em> the underlying hidden Markov state at each time point. It does this by determining the sequence of states <code class="reqn">(k_1^*, \cdots, k_n^*)</code> which maximises the joint distribution of the hidden states given the entire observed process, i.e.
</p>
<p style="text-align: center;"><code class="reqn">
(k_1^*, \cdots, k_n^*) = _{\stackrel{\mbox{argmax}}{{k_1, \cdots, k_n \in \{1, 2, \cdots, m\}}}} \Pr\{ C_1=k_1, \cdots, C_n=k_n \,|\, X^{(n)}=x^{(n)} \}\,.
</code>
</p>

<p>The algorithm has been taken from Zucchini (2005), however, we calculate sums of the logarithms of probabilities rather than products of probabilities. This lessens the chance of numerical underflow. Given that the logarithmic function is monotonically increasing, the <em>argmax</em> will still be the same. Note that <em>argmax</em> can be evaluated with the <span class="rlang"><b>R</b></span> function <code><a href="base.html#topic+which.min">which.max</a></code>.
</p>
<p>Determining the <em>a posteriori</em> most probable state at time <code class="reqn">i</code> is referred to as <em>local decoding</em>, i.e.
</p>
<p style="text-align: center;"><code class="reqn">
k_i^* = _{\stackrel{\mbox{argmax}}{k \in \{1, 2, \cdots, m\}}} \Pr\{ C_i=k \,|\, X^{(n)}=x^{(n)} \}\,.
</code>
</p>

<p>Note that the above probabilities are calculated by the function <code><a href="#topic+Estep">Estep</a></code>, and are contained in <code>u[i,j]</code> (output from <code>Estep</code>), i.e. <code class="reqn">k_i^*</code> is simply <code>which.max(u[i,])</code>.
</p>
<p>The code for the methods <code>"<a href="#topic+dthmm">dthmm</a>"</code>, <code>"<a href="#topic+mmglm0">mmglm0</a>"</code>, <code>"<a href="#topic+mmglm1">mmglm1</a>"</code> and <code>"<a href="#topic+mmglmlong1">mmglmlong1</a>"</code> can be viewed by appending <code>Viterbi.dthmm</code>, <code>Viterbi.mmglm0</code>, <code>Viterbi.mmglm1</code> or <code>Viterbi.mmglmlong1</code>, respectively, to <code>HiddenMarkov:::</code>, on the <span class="rlang"><b>R</b></span> command line; e.g. <code>HiddenMarkov:::dthmm</code>. The three colons are needed because these method functions are not in the exported NAMESPACE.
</p>


<h3>Value</h3>

<p>A vector of length <code class="reqn">n</code> containing integers (<code class="reqn">1, \cdots, m</code>) representing the hidden Markov states for each node of the chain.
</p>


<h3>References</h3>

<p>Cited references are listed on the <a href="#topic+HiddenMarkov">HiddenMarkov</a> manual page.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>Pi &lt;- matrix(c(1/2, 1/2,   0,   0,   0,
               1/3, 1/3, 1/3,   0,   0,
                 0, 1/3, 1/3, 1/3,   0,
                 0,   0, 1/3, 1/3, 1/3,
                 0,   0,   0, 1/2, 1/2),
             byrow=TRUE, nrow=5)
delta &lt;- c(0, 1, 0, 0, 0)
lambda &lt;- c(1, 4, 2, 5, 3)
m &lt;- nrow(Pi)

x &lt;- dthmm(NULL, Pi, delta, "pois", list(lambda=lambda), discrete=TRUE)
x &lt;- simulate(x, nsim=2000)

#------  Global Decoding  ------

states &lt;- Viterbi(x)
states &lt;- factor(states, levels=1:m)

#  Compare predicted states with true states
#  p[j,k] = Pr{Viterbi predicts state k | true state is j}
p &lt;- matrix(NA, nrow=m, ncol=m)
for (j in 1:m){
    a &lt;- (x$y==j)
    p[j,] &lt;- table(states[a])/sum(a)
}
print(p)

#------  Local Decoding  ------

#   locally decode at i=100

print(which.max(Estep(x$x, Pi, delta, "pois", list(lambda=lambda))$u[100,]))

#---------------------------------------------------
#   simulate a beta HMM

Pi &lt;- matrix(c(0.8, 0.2,
               0.3, 0.7),
             byrow=TRUE, nrow=2)
delta &lt;- c(0, 1)

y &lt;- seq(0.01, 0.99, 0.01)
plot(y, dbeta(y, 2, 6), type="l", ylab="Density", col="blue")
points(y, dbeta(y, 6, 2), type="l", col="red")

n &lt;- 100
x &lt;- dthmm(NULL, Pi, delta, "beta",
           list(shape1=c(2, 6), shape2=c(6, 2)))
x &lt;- simulate(x, nsim=n)

#   colour denotes actual hidden Markov state
plot(1:n, x$x, type="l", xlab="Time", ylab="Observed Process")
points((1:n)[x$y==1], x$x[x$y==1], col="blue", pch=15)
points((1:n)[x$y==2], x$x[x$y==2], col="red", pch=15)

states &lt;- Viterbi(x)
#   mark the wrongly predicted states
wrong &lt;- (states != x$y)
points((1:n)[wrong], x$x[wrong], pch=1, cex=2.5, lwd=2)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
