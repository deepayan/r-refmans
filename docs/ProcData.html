<!DOCTYPE html><html lang="en"><head><title>Help for package ProcData</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {ProcData}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#ProcData-package'><p>ProcData: A package for process data analysis</p></a></li>
<li><a href='#action_seqs_summary'><p>Summarize action sequences</p></a></li>
<li><a href='#aseq2feature_seq2seq'><p>Feature Extraction by action sequence autoencoder</p></a></li>
<li><a href='#atseq2feature_seq2seq'><p>Feature Extraction by action and time sequence autoencoder</p></a></li>
<li><a href='#calculate_dist_cpp'><p>Calculate &quot;oss_action&quot; dissimilarity matrix through Rcpp</p></a></li>
<li><a href='#cc_data'><p>Data of item CP025Q01 (climate control item 1) in PISA 2012</p></a></li>
<li><a href='#chooseK_mds'><p>Choose the number of multidimensional scaling features</p></a></li>
<li><a href='#chooseK_seq2seq'><p>Choose the number of autoencoder features</p></a></li>
<li><a href='#combine_actions'><p>Combine consecutive actions into a single action</p></a></li>
<li><a href='#count_actions'><p>Count action appearances</p></a></li>
<li><a href='#predict.seqm'><p>Predict method for sequence models</p></a></li>
<li><a href='#print.proc'><p>Print method for class <code>"proc"</code></p></a></li>
<li><a href='#print.summary.proc'><p>Print method for class <code>"summary.proc"</code></p></a></li>
<li><a href='#proc'><p>Class <code>"proc"</code> constructor</p></a></li>
<li><a href='#read.seqs'><p>Reading response processes from csv files</p></a></li>
<li><a href='#remove_action'><p>Remove actions from response processes</p></a></li>
<li><a href='#remove_repeat'><p>Remove repeated actions</p></a></li>
<li><a href='#replace_action'><p>Replace actions in response processes</p></a></li>
<li><a href='#seq_gen'><p>Action sequence generator</p></a></li>
<li><a href='#seq_gen2'><p>Markov action sequence generator</p></a></li>
<li><a href='#seq_gen3'><p>RNN action sequence generator</p></a></li>
<li><a href='#seq2feature_mds'><p>Feature extraction via multidimensional scaling</p></a></li>
<li><a href='#seq2feature_mds_large'><p>Feature Extraction by MDS for Large Dataset</p></a></li>
<li><a href='#seq2feature_mds_stochastic'><p>Feature extraction by stochastic mds</p></a></li>
<li><a href='#seq2feature_ngram'><p>ngram feature extraction</p></a></li>
<li><a href='#seq2feature_seq2seq'><p>Feature Extraction by autoencoder</p></a></li>
<li><a href='#seqm'><p>Fitting sequence models</p></a></li>
<li><a href='#sub_seqs'><p>Subset response processes</p></a></li>
<li><a href='#summary.proc'><p>Summary method for class <code>"proc"</code></p></a></li>
<li><a href='#time_seqs_summary'><p>Summarize timestamp sequences</p></a></li>
<li><a href='#tseq2feature_seq2seq'><p>Feature Extraction by time sequence autoencoder</p></a></li>
<li><a href='#tseq2interval'><p>Transform a timestamp sequence into a inter-arrival time sequence</p></a></li>
<li><a href='#write.seqs'><p>Write process data to csv files</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Process Data Analysis</td>
</tr>
<tr>
<td>Version:</td>
<td>0.3.2</td>
</tr>
<tr>
<td>Date:</td>
<td>2021-03-24</td>
</tr>
<tr>
<td>Description:</td>
<td>Provides tools for exploratory process data analysis. Process data refers to the data describing
    participants' problem-solving processes in computer-based assessments. It is often recorded in computer
    log files. This package provides functions to read, process, and write process data. It also implements
    two feature extraction methods to compress the information stored in process data into standard 
    numerical vectors. This package also provides recurrent neural network based models that relate response processes 
    with other binary or scale variables of interest. The functions that involve training and evaluating neural networks 
    are wrappers of functions in 'keras'.</td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/xytangtang/ProcData/issues">https://github.com/xytangtang/ProcData/issues</a></td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5)</td>
</tr>
<tr>
<td>Imports:</td>
<td>Rcpp (&ge; 0.12.16), keras (&ge; 2.2.4)</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp</td>
</tr>
<tr>
<td>SystemRequirements:</td>
<td>Python (&gt;= 2.7), Keras (&gt;= 2.0), TensorFlow (&gt;=
1.13)</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.0</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2021-03-25 05:31:36 UTC; xueyingtang</td>
</tr>
<tr>
<td>Author:</td>
<td>Xueying Tang [aut, cre],
  Susu Zhang [aut],
  Zhi Wang [aut],
  Jingchen Liu [aut],
  Zhiliang Ying [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Xueying Tang &lt;xueyingtang1989@gmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2021-04-01 12:50:09 UTC</td>
</tr>
</table>
<hr>
<h2 id='ProcData-package'>ProcData: A package for process data analysis</h2><span id='topic+ProcData'></span><span id='topic+ProcData-package'></span>

<h3>Description</h3>

<p>General tools for exploratory process data analysis. Process data refers to
the data describing participants' problem solving processes in computer-based
assessments. It is often recorded in computer log files. This package a process 
dataset and functions for reading processes from a csv file, process manipulation,
action sequence generators. It also implements two automatic feature
extraction methods that compress the information stored in process data,
which often has a nonstandard format, into standard numerical vectors. This
package also provides recurrent neural network based models that relate
response processes with other binary or scale variables of interest. The
functions that involve training and evaluating neural networks are based on
functions in keras.
</p>


<h3>Data structure</h3>

<p><code>ProcData</code> organizes response processes as an object of class <code><a href="#topic+proc">proc</a></code>.
Some functions are provided for summarizing and manipulating <code>proc</code> objects.
</p>

<ul>
<li> <p><code><a href="#topic+summary.proc">summary.proc</a></code> calculates summary statistics of a <code>proc</code> object.
</p>
</li>
<li> <p><code><a href="#topic+remove_action">remove_action</a></code> removes actions and the corresponding timestamps
</p>
</li>
<li> <p><code><a href="#topic+replace_action">replace_action</a></code> replaces an action by another action
</p>
</li>
<li> <p><code><a href="#topic+combine_actions">combine_actions</a></code> combines consecutive action into one action.
</p>
</li></ul>



<h3>Read sequences</h3>


<ul>
<li> <p><code><a href="#topic+read.seqs">read.seqs</a></code> reads response processes from a csv file.
</p>
</li></ul>



<h3>Sequence generators</h3>


<ul>
<li> <p><code><a href="#topic+seq_gen">seq_gen</a></code> generates action sequences of an imaginery simulation-based item.
</p>
</li>
<li> <p><code><a href="#topic+seq_gen2">seq_gen2</a></code> generates action sequences according to a given probability
transition matrix.
</p>
</li>
<li> <p><code><a href="#topic+seq_gen3">seq_gen3</a></code> generates action sequences according to a recurrent neural network.
</p>
</li></ul>



<h3>Feature extraction methods</h3>


<ul>
<li> <p><code><a href="#topic+seq2feature_mds">seq2feature_mds</a></code> extracts features from response processes by
multidimensional scaling.
</p>
</li>
<li> <p><code><a href="#topic+seq2feature_seq2seq">seq2feature_seq2seq</a></code> extracts features from response processes by
autoencoder.
</p>
</li>
<li> <p><code><a href="#topic+seq2feature_ngram">seq2feature_ngram</a></code> extracts ngram features from response processes.
</p>
</li></ul>



<h3>Sequence models</h3>


<ul>
<li> <p><code><a href="#topic+seqm">seqm</a></code> fits a neural network model that relates response processes 
with a response variable.
</p>
</li>
<li> <p><code><a href="#topic+predict.seqm">predict.seqm</a></code> makes predictions from the models fitted by <code>seqm</code>.
</p>
</li></ul>



<h3>Author(s)</h3>

<p><strong>Maintainer</strong>: Xueying Tang <a href="mailto:xueyingtang1989@gmail.com">xueyingtang1989@gmail.com</a>
</p>
<p>Authors:
</p>

<ul>
<li><p> Susu Zhang <a href="mailto:susu.zhang1992@gmail.com">susu.zhang1992@gmail.com</a>
</p>
</li>
<li><p> Zhi Wang <a href="mailto:zhiwpku@gmail.com">zhiwpku@gmail.com</a>
</p>
</li>
<li><p> Jingchen Liu <a href="mailto:jcliu@stat.columbia.edu">jcliu@stat.columbia.edu</a>
</p>
</li>
<li><p> Zhiliang Ying <a href="mailto:zying@stat.columbia.edu">zying@stat.columbia.edu</a>
</p>
</li></ul>



<h3>See Also</h3>

<p>Useful links:
</p>

<ul>
<li><p> Report bugs at <a href="https://github.com/xytangtang/ProcData/issues">https://github.com/xytangtang/ProcData/issues</a>
</p>
</li></ul>


<hr>
<h2 id='action_seqs_summary'>Summarize action sequences</h2><span id='topic+action_seqs_summary'></span>

<h3>Description</h3>

<p>Summarize action sequences
</p>


<h3>Usage</h3>

<pre><code class='language-R'>action_seqs_summary(action_seqs)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="action_seqs_summary_+3A_action_seqs">action_seqs</code></td>
<td>
<p>a list of action sequences.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list containing the following objects:
</p>
<table role = "presentation">
<tr><td><code>n_seq</code></td>
<td>
<p>the number of action sequences</p>
</td></tr>
<tr><td><code>n_action</code></td>
<td>
<p>the number of distinct actions</p>
</td></tr>
<tr><td><code>action</code></td>
<td>
<p>the action set</p>
</td></tr>
<tr><td><code>seq_length</code></td>
<td>
<p>sequence lengths</p>
</td></tr>
<tr><td><code>action_freq</code></td>
<td>
<p>action counts</p>
</td></tr>
<tr><td><code>action_seqfreq</code></td>
<td>
<p>the number of sequences that each action appears</p>
</td></tr>
<tr><td><code>trans_count</code></td>
<td>
<p>a <code>length(action)</code> by <code>length(action)</code> matrix whose
element in the i-th row and j-th column is the counts of transition from 
<code>action[i]</code> to <code>action[j]</code>.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+time_seqs_summary">time_seqs_summary</a></code> for summarizing timestamp sequences.
</p>

<hr>
<h2 id='aseq2feature_seq2seq'>Feature Extraction by action sequence autoencoder</h2><span id='topic+aseq2feature_seq2seq'></span>

<h3>Description</h3>

<p><code>aseq2feature_seq2seq</code> extract features from action sequences by action
sequence autoencoder.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>aseq2feature_seq2seq(aseqs, K, rnn_type = "lstm", n_epoch = 50,
  method = "last", step_size = 1e-04, optimizer_name = "adam",
  samples_train, samples_valid, samples_test = NULL, pca = TRUE,
  verbose = TRUE, return_theta = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="aseq2feature_seq2seq_+3A_aseqs">aseqs</code></td>
<td>
<p>a list of <code>n</code> action sequences. Each element is an action
sequence in the form of a vector of actions.</p>
</td></tr>
<tr><td><code id="aseq2feature_seq2seq_+3A_k">K</code></td>
<td>
<p>the number of features to be extracted.</p>
</td></tr>
<tr><td><code id="aseq2feature_seq2seq_+3A_rnn_type">rnn_type</code></td>
<td>
<p>the type of recurrent unit to be used for modeling
response processes. <code>"lstm"</code> for the long-short term memory unit. 
<code>"gru"</code> for the gated recurrent unit.</p>
</td></tr>
<tr><td><code id="aseq2feature_seq2seq_+3A_n_epoch">n_epoch</code></td>
<td>
<p>the number of training epochs for the autoencoder.</p>
</td></tr>
<tr><td><code id="aseq2feature_seq2seq_+3A_method">method</code></td>
<td>
<p>the method for computing features from the output of an
recurrent neural network in the encoder. Available options are 
<code>"last"</code> and <code>"avg"</code>.</p>
</td></tr>
<tr><td><code id="aseq2feature_seq2seq_+3A_step_size">step_size</code></td>
<td>
<p>the learning rate of optimizer.</p>
</td></tr>
<tr><td><code id="aseq2feature_seq2seq_+3A_optimizer_name">optimizer_name</code></td>
<td>
<p>a character string specifying the optimizer to be used
for training. Availabel options are <code>"sgd"</code>, <code>"rmsprop"</code>, 
<code>"adadelta"</code>, and <code>"adam"</code>.</p>
</td></tr>
<tr><td><code id="aseq2feature_seq2seq_+3A_samples_train">samples_train</code></td>
<td>
<p>vectors of indices specifying the
training, validation and test sets for training autoencoder.</p>
</td></tr>
<tr><td><code id="aseq2feature_seq2seq_+3A_samples_valid">samples_valid</code></td>
<td>
<p>vectors of indices specifying the
training, validation and test sets for training autoencoder.</p>
</td></tr>
<tr><td><code id="aseq2feature_seq2seq_+3A_samples_test">samples_test</code></td>
<td>
<p>vectors of indices specifying the
training, validation and test sets for training autoencoder.</p>
</td></tr>
<tr><td><code id="aseq2feature_seq2seq_+3A_pca">pca</code></td>
<td>
<p>logical. If TRUE, the principal components of features are
returned. Default is TRUE.</p>
</td></tr>
<tr><td><code id="aseq2feature_seq2seq_+3A_verbose">verbose</code></td>
<td>
<p>logical. If TRUE, training progress is printed.</p>
</td></tr>
<tr><td><code id="aseq2feature_seq2seq_+3A_return_theta">return_theta</code></td>
<td>
<p>logical. If TRUE, extracted features are returned.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function trains a sequence-to-sequence autoencoder using keras. The encoder
of the autoencoder consists of an embedding layer and a recurrent neural network.
The decoder consists of another recurrent neural network and a fully connect layer
with softmax activation. The outputs of the encoder are the extracted features.
</p>
<p>The output of the encoder is a function of the encoder recurrent neural network.
It is the last output of the encoder recurrent neural network if <code>method="last"</code>
and the average of the encoder recurrent nenural network if <code>method="avg"</code>.
</p>


<h3>Value</h3>

<p><code>aseq2feature_seq2seq</code> returns a list containing
</p>
<table role = "presentation">
<tr><td><code>theta</code></td>
<td>
<p>a matrix containing <code>K</code> features or principal features. Each column is a feature.</p>
</td></tr>
<tr><td><code>train_loss</code></td>
<td>
<p>a vector of length <code>n_epoch</code> recording the trace of training losses.</p>
</td></tr>
<tr><td><code>valid_loss</code></td>
<td>
<p>a vector of length <code>n_epoch</code> recording the trace of validation losses.</p>
</td></tr>
<tr><td><code>test_loss</code></td>
<td>
<p>a vector of length <code>n_epoch</code> recording the trace of test losses. Exists only if <code>samples_test</code> is not <code>NULL</code>.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+chooseK_seq2seq">chooseK_seq2seq</a></code> for choosing <code>K</code> through cross-validation.
</p>
<p>Other feature extraction methods: <code><a href="#topic+atseq2feature_seq2seq">atseq2feature_seq2seq</a></code>,
<code><a href="#topic+seq2feature_mds_large">seq2feature_mds_large</a></code>,
<code><a href="#topic+seq2feature_mds">seq2feature_mds</a></code>,
<code><a href="#topic+seq2feature_ngram">seq2feature_ngram</a></code>,
<code><a href="#topic+seq2feature_seq2seq">seq2feature_seq2seq</a></code>,
<code><a href="#topic+tseq2feature_seq2seq">tseq2feature_seq2seq</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
if (!system("python -c 'import tensorflow as tf'", ignore.stdout = TRUE, ignore.stderr= TRUE)) {
  n &lt;- 50
  seqs &lt;- seq_gen(n)
  seq2seq_res &lt;- aseq2feature_seq2seq(seqs$action_seqs, 5, rnn_type="lstm", n_epoch=5, 
                                   samples_train=1:40, samples_valid=41:50)
  features &lt;- seq2seq_res$theta
  plot(seq2seq_res$train_loss, col="blue", type="l")
  lines(seq2seq_res$valid_loss, col="red")
}


</code></pre>

<hr>
<h2 id='atseq2feature_seq2seq'>Feature Extraction by action and time sequence autoencoder</h2><span id='topic+atseq2feature_seq2seq'></span>

<h3>Description</h3>

<p><code>atseq2feature_seq2seq</code> extract features from action and timestamp sequences by a 
sequence autoencoder.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>atseq2feature_seq2seq(atseqs, K, weights = c(1, 0.5),
  cumulative = FALSE, log = TRUE, rnn_type = "lstm", n_epoch = 50,
  method = "last", step_size = 1e-04, optimizer_name = "rmsprop",
  samples_train, samples_valid, samples_test = NULL, pca = TRUE,
  verbose = TRUE, return_theta = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="atseq2feature_seq2seq_+3A_atseqs">atseqs</code></td>
<td>
<p>a list of two elements, first element is the list of <code>n</code> action sequences, Each element 
is an action sequence in the form of a vector of actions. The second element is the list of <code>n</code> 
timestamp sequences corresponding to the action sequences. Each element is a numeric sequence in the form 
of a vector of timestamps associated with actions, with the timestamp of the first event (e.g., &quot;start&quot;) of 0.</p>
</td></tr>
<tr><td><code id="atseq2feature_seq2seq_+3A_k">K</code></td>
<td>
<p>the number of features to be extracted.</p>
</td></tr>
<tr><td><code id="atseq2feature_seq2seq_+3A_weights">weights</code></td>
<td>
<p>a vector of 2 elements for the weight of the loss of action sequences
(categorical_crossentropy) and time sequences (mean squared error), respectively. 
The total loss is calculated as the weighted sum of the two losses.</p>
</td></tr>
<tr><td><code id="atseq2feature_seq2seq_+3A_cumulative">cumulative</code></td>
<td>
<p>logical. If TRUE, the sequence of cumulative time up to each event is
used as input to the neural network. If FALSE, the sequence of inter-arrival time (gap 
time between an event and the previous event) will be used as input to the neural network.
Default is FALSE.</p>
</td></tr>
<tr><td><code id="atseq2feature_seq2seq_+3A_log">log</code></td>
<td>
<p>logical. If TRUE, for the timestamp sequences, input of the neural net is
the base-10 log of the original sequence of times plus 1 (i.e., log10(t+1)). If FALSE,
the original sequence of times is used.</p>
</td></tr>
<tr><td><code id="atseq2feature_seq2seq_+3A_rnn_type">rnn_type</code></td>
<td>
<p>the type of recurrent unit to be used for modeling
response processes. <code>"lstm"</code> for the long-short term memory unit. 
<code>"gru"</code> for the gated recurrent unit.</p>
</td></tr>
<tr><td><code id="atseq2feature_seq2seq_+3A_n_epoch">n_epoch</code></td>
<td>
<p>the number of training epochs for the autoencoder.</p>
</td></tr>
<tr><td><code id="atseq2feature_seq2seq_+3A_method">method</code></td>
<td>
<p>the method for computing features from the output of an
recurrent neural network in the encoder. Available options are 
<code>"last"</code> and <code>"avg"</code>.</p>
</td></tr>
<tr><td><code id="atseq2feature_seq2seq_+3A_step_size">step_size</code></td>
<td>
<p>the learning rate of optimizer.</p>
</td></tr>
<tr><td><code id="atseq2feature_seq2seq_+3A_optimizer_name">optimizer_name</code></td>
<td>
<p>a character string specifying the optimizer to be used
for training. Availabel options are <code>"sgd"</code>, <code>"rmsprop"</code>, 
<code>"adadelta"</code>, and <code>"adam"</code>.</p>
</td></tr>
<tr><td><code id="atseq2feature_seq2seq_+3A_samples_train">samples_train</code></td>
<td>
<p>vectors of indices specifying the
training, validation and test sets for training autoencoder.</p>
</td></tr>
<tr><td><code id="atseq2feature_seq2seq_+3A_samples_valid">samples_valid</code></td>
<td>
<p>vectors of indices specifying the
training, validation and test sets for training autoencoder.</p>
</td></tr>
<tr><td><code id="atseq2feature_seq2seq_+3A_samples_test">samples_test</code></td>
<td>
<p>vectors of indices specifying the
training, validation and test sets for training autoencoder.</p>
</td></tr>
<tr><td><code id="atseq2feature_seq2seq_+3A_pca">pca</code></td>
<td>
<p>logical. If TRUE, the principal components of features are
returned. Default is TRUE.</p>
</td></tr>
<tr><td><code id="atseq2feature_seq2seq_+3A_verbose">verbose</code></td>
<td>
<p>logical. If TRUE, training progress is printed.</p>
</td></tr>
<tr><td><code id="atseq2feature_seq2seq_+3A_return_theta">return_theta</code></td>
<td>
<p>logical. If TRUE, extracted features are returned.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function trains a sequence-to-sequence autoencoder using keras. The encoder
of the autoencoder consists of a recurrent neural network.
The decoder consists of another recurrent neural network followed by a fully connected layer
with softmax activation for actions and another fully connected layer with ReLU activation 
for times. The outputs of the encoder are the extracted features.
</p>
<p>The output of the encoder is a function of the encoder recurrent neural network.
It is the last latent state of the encoder recurrent neural network if <code>method="last"</code>
and the average of the encoder recurrent neural network latent states if <code>method="avg"</code>.
</p>


<h3>Value</h3>

<p><code>tseq2feature_seq2seq</code> returns a list containing
</p>
<table role = "presentation">
<tr><td><code>theta</code></td>
<td>
<p>a matrix containing <code>K</code> features or principal features. Each column is a feature.</p>
</td></tr>
<tr><td><code>train_loss</code></td>
<td>
<p>a vector of length <code>n_epoch</code> recording the trace of training losses.</p>
</td></tr>
<tr><td><code>valid_loss</code></td>
<td>
<p>a vector of length <code>n_epoch</code> recording the trace of validation losses.</p>
</td></tr>
<tr><td><code>test_loss</code></td>
<td>
<p>a vector of length <code>n_epoch</code> recording the trace of test losses. Exists only if <code>samples_test</code> is not <code>NULL</code>.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+chooseK_seq2seq">chooseK_seq2seq</a></code> for choosing <code>K</code> through cross-validation.
</p>
<p>Other feature extraction methods: <code><a href="#topic+aseq2feature_seq2seq">aseq2feature_seq2seq</a></code>,
<code><a href="#topic+seq2feature_mds_large">seq2feature_mds_large</a></code>,
<code><a href="#topic+seq2feature_mds">seq2feature_mds</a></code>,
<code><a href="#topic+seq2feature_ngram">seq2feature_ngram</a></code>,
<code><a href="#topic+seq2feature_seq2seq">seq2feature_seq2seq</a></code>,
<code><a href="#topic+tseq2feature_seq2seq">tseq2feature_seq2seq</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
if (!system("python -c 'import tensorflow as tf'", ignore.stdout = TRUE, ignore.stderr= TRUE)) {
  n &lt;- 50
  data(cc_data)
  samples &lt;- sample(1:length(cc_data$seqs$time_seqs), n)
  atseqs &lt;- sub_seqs(cc_data$seqs, samples)
  action_and_time_seq2seq_res &lt;- atseq2feature_seq2seq(atseqs, 5, rnn_type="lstm", n_epoch=5, 
                                   samples_train=1:40, samples_valid=41:50)
  features &lt;- action_and_time_seq2seq_res$theta
  plot(action_and_time_seq2seq_res$train_loss, col="blue", type="l",
       ylim = range(c(action_and_time_seq2seq_res$train_loss, 
                      action_and_time_seq2seq_res$valid_loss)))
  lines(action_and_time_seq2seq_res$valid_loss, col="red", type = 'l')
}

</code></pre>

<hr>
<h2 id='calculate_dist_cpp'>Calculate &quot;oss_action&quot; dissimilarity matrix through Rcpp</h2><span id='topic+calculate_dist_cpp'></span>

<h3>Description</h3>

<p>Calculate &quot;oss_action&quot; dissimilarity matrix through Rcpp
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calculate_dist_cpp(seqs)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="calculate_dist_cpp_+3A_seqs">seqs</code></td>
<td>
<p>a list of action sequences</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>calculate_dist_cpp</code> returns the &quot;oss_action&quot; dissimilarity matrix of 
the action sequences in <code>seqs</code>.
</p>

<hr>
<h2 id='cc_data'>Data of item CP025Q01 (climate control item 1) in PISA 2012</h2><span id='topic+cc_data'></span>

<h3>Description</h3>

<p>A dataset containing the response processes and binary response outcomes of 16763 respondents.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cc_data
</code></pre>


<h3>Format</h3>

<p>A list with two elements. 
</p>

<dl>
<dt>seqs</dt><dd><p>An object of class <code>"<a href="#topic+proc">proc</a>"</code> containing the action sequences and 
the time sequences of the respondents.</p>
</dd>
<dt>responses</dt><dd><p>Binary responses of 16763 respondents. The order of the respondents
matches that in <code>seqs</code>.</p>
</dd>
</dl>


<h3>Source</h3>

<p>item interface: <a href="http://www.oecd.org/pisa/test-2012/testquestions/question3/">http://www.oecd.org/pisa/test-2012/testquestions/question3/</a>
</p>

<hr>
<h2 id='chooseK_mds'>Choose the number of multidimensional scaling features</h2><span id='topic+chooseK_mds'></span>

<h3>Description</h3>

<p><code>chooseK_mds</code> choose the number of multidimensional scaling features
to be extracted by cross-validation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>chooseK_mds(seqs = NULL, K_cand, dist_type = "oss_action",
  n_fold = 5, max_epoch = 100, step_size = 0.01, tot = 1e-06,
  return_dist = FALSE, L_set = 1:3)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="chooseK_mds_+3A_seqs">seqs</code></td>
<td>
<p>a <code>"<a href="#topic+proc">proc</a>"</code> object or a square matrix. If a squared matrix is 
provided, it is treated as the dissimilary matrix of a group of response processes.</p>
</td></tr>
<tr><td><code id="chooseK_mds_+3A_k_cand">K_cand</code></td>
<td>
<p>the candidates of the number of features.</p>
</td></tr>
<tr><td><code id="chooseK_mds_+3A_dist_type">dist_type</code></td>
<td>
<p>a character string specifies the dissimilarity measure for two
response processes. See 'Details'.</p>
</td></tr>
<tr><td><code id="chooseK_mds_+3A_n_fold">n_fold</code></td>
<td>
<p>the number of folds for cross-validation.</p>
</td></tr>
<tr><td><code id="chooseK_mds_+3A_max_epoch">max_epoch</code></td>
<td>
<p>the maximum number of epochs for stochastic gradient
descent.</p>
</td></tr>
<tr><td><code id="chooseK_mds_+3A_step_size">step_size</code></td>
<td>
<p>the step size of stochastic gradient descent.</p>
</td></tr>
<tr><td><code id="chooseK_mds_+3A_tot">tot</code></td>
<td>
<p>the accuracy tolerance for determining convergence.</p>
</td></tr>
<tr><td><code id="chooseK_mds_+3A_return_dist">return_dist</code></td>
<td>
<p>logical. If <code>TRUE</code>, the dissimilarity matrix will be
returned. Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="chooseK_mds_+3A_l_set">L_set</code></td>
<td>
<p>length of ngrams considered</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>chooseK_mds</code> returns a list containing
</p>
<table role = "presentation">
<tr><td><code>K</code></td>
<td>
<p>the value in <code>K_cand</code> producing the smallest cross-validation loss.</p>
</td></tr>
<tr><td><code>K_cand</code></td>
<td>
<p>the candidates of the number of features.</p>
</td></tr>
<tr><td><code>cv_loss</code></td>
<td>
<p>the cross-validation loss for each candidate in <code>K_cand</code>.</p>
</td></tr>
<tr><td><code>dist_mat</code></td>
<td>
<p>the dissimilary matrix. This element exists only if <code>return_dist=TRUE</code>.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Gomez-Alonso, C. and Valls, A. (2008). A similarity measure for sequences of
categorical data based on the ordering of common elements. In V. Torra &amp; Y. Narukawa (Eds.) 
<em>Modeling Decisions for Artificial Intelligence</em>, (pp. 134-145). Springer Berlin Heidelberg.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+seq2feature_mds">seq2feature_mds</a></code> for feature extraction after choosing
the number of features.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 50
set.seed(12345)
seqs &lt;- seq_gen(n)
K_res &lt;- chooseK_mds(seqs, 5:10, return_dist=TRUE)
theta &lt;- seq2feature_mds(K_res$dist_mat, K_res$K)$theta

</code></pre>

<hr>
<h2 id='chooseK_seq2seq'>Choose the number of autoencoder features</h2><span id='topic+chooseK_seq2seq'></span>

<h3>Description</h3>

<p><code>chooseK_seq2seq</code> chooses the number of features to be extracted
by cross-validation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>chooseK_seq2seq(seqs, ae_type, K_cand, rnn_type = "lstm", n_epoch = 50,
  method = "last", step_size = 1e-04, optimizer_name = "adam",
  n_fold = 5, cumulative = FALSE, log = TRUE, weights = c(1, 0.5),
  valid_prop = 0.1, verbose = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="chooseK_seq2seq_+3A_seqs">seqs</code></td>
<td>
<p>an object of class <code>"<a href="#topic+proc">proc</a>"</code>.</p>
</td></tr>
<tr><td><code id="chooseK_seq2seq_+3A_ae_type">ae_type</code></td>
<td>
<p>a string specifies the type of autoencoder. The autoencoder can be an
action sequence autoencoder (&quot;action&quot;), a time sequence autoencoder (&quot;time&quot;), or an 
action-time sequence autoencoder (&quot;both&quot;).</p>
</td></tr>
<tr><td><code id="chooseK_seq2seq_+3A_k_cand">K_cand</code></td>
<td>
<p>the candidates of the number of features.</p>
</td></tr>
<tr><td><code id="chooseK_seq2seq_+3A_rnn_type">rnn_type</code></td>
<td>
<p>the type of recurrent unit to be used for modeling
response processes. <code>"lstm"</code> for the long-short term memory unit. 
<code>"gru"</code> for the gated recurrent unit.</p>
</td></tr>
<tr><td><code id="chooseK_seq2seq_+3A_n_epoch">n_epoch</code></td>
<td>
<p>the number of training epochs for the autoencoder.</p>
</td></tr>
<tr><td><code id="chooseK_seq2seq_+3A_method">method</code></td>
<td>
<p>the method for computing features from the output of an
recurrent neural network in the encoder. Available options are 
<code>"last"</code> and <code>"avg"</code>.</p>
</td></tr>
<tr><td><code id="chooseK_seq2seq_+3A_step_size">step_size</code></td>
<td>
<p>the learning rate of optimizer.</p>
</td></tr>
<tr><td><code id="chooseK_seq2seq_+3A_optimizer_name">optimizer_name</code></td>
<td>
<p>a character string specifying the optimizer to be used
for training. Availabel options are <code>"sgd"</code>, <code>"rmsprop"</code>, 
<code>"adadelta"</code>, and <code>"adam"</code>.</p>
</td></tr>
<tr><td><code id="chooseK_seq2seq_+3A_n_fold">n_fold</code></td>
<td>
<p>the number of folds for cross-validation.</p>
</td></tr>
<tr><td><code id="chooseK_seq2seq_+3A_cumulative">cumulative</code></td>
<td>
<p>logical. If TRUE, the sequence of cumulative time up to each event is
used as input to the neural network. If FALSE, the sequence of inter-arrival time (gap 
time between an event and the previous event) will be used as input to the neural network.
Default is FALSE.</p>
</td></tr>
<tr><td><code id="chooseK_seq2seq_+3A_log">log</code></td>
<td>
<p>logical. If TRUE, for the timestamp sequences, input of the neural net is
the base-10 log of the original sequence of times plus 1 (i.e., log10(t+1)). If FALSE,
the original sequence of times is used.</p>
</td></tr>
<tr><td><code id="chooseK_seq2seq_+3A_weights">weights</code></td>
<td>
<p>a vector of 2 elements for the weight of the loss of action sequences
(categorical_crossentropy) and time sequences (mean squared error), respectively. 
The total loss is calculated as the weighted sum of the two losses.</p>
</td></tr>
<tr><td><code id="chooseK_seq2seq_+3A_valid_prop">valid_prop</code></td>
<td>
<p>the proportion of validation samples in each fold.</p>
</td></tr>
<tr><td><code id="chooseK_seq2seq_+3A_verbose">verbose</code></td>
<td>
<p>logical. If TRUE, training progress is printed.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>chooseK_seq2seq</code> returns a list containing
</p>
<table role = "presentation">
<tr><td><code>K</code></td>
<td>
<p>the candidate in <code>K_cand</code> producing the smallest cross-validation loss.</p>
</td></tr>
<tr><td><code>K_cand</code></td>
<td>
<p>the candidates of number of features.</p>
</td></tr>
<tr><td><code>cv_loss</code></td>
<td>
<p>the cross-validation loss for each candidate in <code>K_cand</code>.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+seq2feature_seq2seq">seq2feature_seq2seq</a></code> for feature extraction given the number of features.
</p>

<hr>
<h2 id='combine_actions'>Combine consecutive actions into a single action</h2><span id='topic+combine_actions'></span>

<h3>Description</h3>

<p>Combine the action pattern described in <code>old_actions</code> into a single action 
<code>new_action</code>. The timestamp of the combined action can be the timestamp of the
first action in the action pattern, the timestamp of the last action in the action
pattern, or the average of the two timestamps.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>combine_actions(seqs, old_actions, new_action, timestamp = "first")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="combine_actions_+3A_seqs">seqs</code></td>
<td>
<p>an object of class <code>"<a href="#topic+proc">proc</a>"</code></p>
</td></tr>
<tr><td><code id="combine_actions_+3A_old_actions">old_actions</code></td>
<td>
<p>a character vector giving consecutive actions to be replaced.</p>
</td></tr>
<tr><td><code id="combine_actions_+3A_new_action">new_action</code></td>
<td>
<p>a string giving the combined action</p>
</td></tr>
<tr><td><code id="combine_actions_+3A_timestamp">timestamp</code></td>
<td>
<p>&quot;first&quot;, &quot;last&quot;, or &quot;avg&quot;, specifying how the timestamp of the combined
action should be derived.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>an object of class <code>"<a href="#topic+proc">proc</a>"</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>seqs &lt;- seq_gen(100)
new_seqs &lt;- combine_actions(seqs, 
                            old_actions=c("OPT1_3", "OPT2_2", "RUN"), 
                            new_action="KEY_ACTION")
</code></pre>

<hr>
<h2 id='count_actions'>Count action appearances</h2><span id='topic+count_actions'></span>

<h3>Description</h3>

<p>This function counts the appearances of each action in <code>actions</code> in 
action sequence <code>x</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>count_actions(x, actions)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="count_actions_+3A_x">x</code></td>
<td>
<p>an action sequence.</p>
</td></tr>
<tr><td><code id="count_actions_+3A_actions">actions</code></td>
<td>
<p>a set of actions whose number of appearances will be count.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>an integer vector of counts.
</p>

<hr>
<h2 id='predict.seqm'>Predict method for sequence models</h2><span id='topic+predict.seqm'></span>

<h3>Description</h3>

<p>Obtains predictions from a fitted sequence model object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'seqm'
predict(object, new_seqs, new_covariates = NULL,
  type = "response", ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict.seqm_+3A_object">object</code></td>
<td>
<p>a fitted object of class <code>"seqm"</code> from <code>seqm</code>.</p>
</td></tr>
<tr><td><code id="predict.seqm_+3A_new_seqs">new_seqs</code></td>
<td>
<p>an object of class <code>"<a href="#topic+proc">proc</a>"</code> with which to predict.</p>
</td></tr>
<tr><td><code id="predict.seqm_+3A_new_covariates">new_covariates</code></td>
<td>
<p>a new covariate matrix with which to predict.</p>
</td></tr>
<tr><td><code id="predict.seqm_+3A_type">type</code></td>
<td>
<p>a string specifying whether to predict responses (<code>"response"</code>) 
or features (<code>"feature"</code>) or both (<code>"both"</code>).</p>
</td></tr>
<tr><td><code id="predict.seqm_+3A_...">...</code></td>
<td>
<p>further arguments to be passed to <code>predict.keras.engine.training.Model</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>It unserialize <code>object$model_fit</code> to obtain a keras model of class 
<code>"keras.engin.training.Model"</code> and then calls <code>predict</code>
to obtain predictions.
</p>


<h3>Value</h3>

<p>If <code>type="response"</code>, a vector of predictions. The vector gives the 
probabilities of the response variable being one if <code>response_type="binary"</code>.
If <code>type="feature"</code>, a matrix of rnn outputs. If <code>type="both"</code>, a list 
containing both the vector of response variable prediction and the rnn output matrix.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+seqm">seqm</a></code> for fitting sequence models.
</p>

<hr>
<h2 id='print.proc'>Print method for class <code>"proc"</code></h2><span id='topic+print.proc'></span>

<h3>Description</h3>

<p>Print method for class <code>"proc"</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'proc'
print(x, n = 5, index = NULL, quote = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="print.proc_+3A_x">x</code></td>
<td>
<p>an object of class <code>"<a href="#topic+proc">proc</a>"</code></p>
</td></tr>
<tr><td><code id="print.proc_+3A_n">n</code></td>
<td>
<p>number of processes to be printed.</p>
</td></tr>
<tr><td><code id="print.proc_+3A_index">index</code></td>
<td>
<p>indice of processes to be printed.</p>
</td></tr>
<tr><td><code id="print.proc_+3A_quote">quote</code></td>
<td>
<p>logical, indicating whether or not strings should be printed with surrounding quotes.</p>
</td></tr>
<tr><td><code id="print.proc_+3A_...">...</code></td>
<td>
<p>not used.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>print.proc</code> invisibly returns the <code>"proc"</code> object it prints.
</p>

<hr>
<h2 id='print.summary.proc'>Print method for class <code>"summary.proc"</code></h2><span id='topic+print.summary.proc'></span>

<h3>Description</h3>

<p>Print method for class <code>"summary.proc"</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'summary.proc'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="print.summary.proc_+3A_x">x</code></td>
<td>
<p>an object of class <code>"<a href="#topic+proc">proc</a>"</code></p>
</td></tr>
<tr><td><code id="print.summary.proc_+3A_...">...</code></td>
<td>
<p>not used.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>No return value.
</p>

<hr>
<h2 id='proc'>Class <code>"proc"</code> constructor</h2><span id='topic+proc'></span>

<h3>Description</h3>

<p>Create a <code>"proc"</code> object from given action sequences and timestamp sequences
</p>


<h3>Usage</h3>

<pre><code class='language-R'>proc(action_seqs, time_seqs, ids = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="proc_+3A_action_seqs">action_seqs</code></td>
<td>
<p>a list of action sequences.</p>
</td></tr>
<tr><td><code id="proc_+3A_time_seqs">time_seqs</code></td>
<td>
<p>a list of timestamp sequences.</p>
</td></tr>
<tr><td><code id="proc_+3A_ids">ids</code></td>
<td>
<p>ids identifiers of response processes.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>An object of 
class <code>"proc"</code> is a list containing the following components:
</p>

<ul>
<li><p>action_seqsa list of action sequences.
</p>
</li>
<li><p>time_seqsa list of timestamp sequences.
</p>
</li></ul>

<p>The names of the elements in <code>seqs$action_seqs</code> and <code>seqs$time_seqs</code> are 
process identifiers.
</p>


<h3>Value</h3>

<p>an object of class <code>"<a href="#topic+proc">proc</a>"</code> containing the provided action and
timestamp sequences.
</p>

<hr>
<h2 id='read.seqs'>Reading response processes from csv files</h2><span id='topic+read.seqs'></span>

<h3>Description</h3>

<p>Reads a csv file and creates response process data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>read.seqs(file, style, id_var = NULL, action_var = NULL,
  time_var = NULL, step_sep = ",", ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="read.seqs_+3A_file">file</code></td>
<td>
<p>the name of the csv file from which the response processes are to be read.</p>
</td></tr>
<tr><td><code id="read.seqs_+3A_style">style</code></td>
<td>
<p>the style that the response processes are stored. See 'Details'.</p>
</td></tr>
<tr><td><code id="read.seqs_+3A_id_var">id_var</code></td>
<td>
<p>a string giving the name of the variable storing the process identifier.</p>
</td></tr>
<tr><td><code id="read.seqs_+3A_action_var">action_var</code></td>
<td>
<p>a string giving the name of the variable storing action sequences.</p>
</td></tr>
<tr><td><code id="read.seqs_+3A_time_var">time_var</code></td>
<td>
<p>a string giving the name of the variable storing timestamp sequences.</p>
</td></tr>
<tr><td><code id="read.seqs_+3A_step_sep">step_sep</code></td>
<td>
<p>the step separator characters. It is only used if <code>style="single"</code>.</p>
</td></tr>
<tr><td><code id="read.seqs_+3A_...">...</code></td>
<td>
<p>further arguments to be passed to <code>read.csv</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>read.seqs</code> calls <code>read.csv</code> to read process data stored in a csv file into <code>R</code>.
The csv file to be read should at least include an identifier of distinct response processes, 
and action sequences. It can also include timestamp sequences.
</p>
<p>The response processes (action sequences and timestamp sequences) stored in csv files can 
be in one of the two styles, <code>"single"</code> and <code>"multiple"</code>. In <code>"single"</code> style,
each response process occupies a single line. Actions and timestamps at different steps 
are separated by <code>step_sep</code>. In <code>"multiple"</code> style, each response process occupies 
multiple lines with each step taking up one line.
</p>


<h3>Value</h3>

<p><code>read.seqs</code> returns an object of class <code>"<a href="#topic+proc">proc</a>"</code>.
</p>

<hr>
<h2 id='remove_action'>Remove actions from response processes</h2><span id='topic+remove_action'></span>

<h3>Description</h3>

<p>Remove actions in <code>actions</code> and the corresponding timestamps
in response processes <code>seqs</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>remove_action(seqs, actions)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="remove_action_+3A_seqs">seqs</code></td>
<td>
<p>an object of class <code>"<a href="#topic+proc">proc</a>"</code></p>
</td></tr>
<tr><td><code id="remove_action_+3A_actions">actions</code></td>
<td>
<p>a character vector. Each element is an action to be removed.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>an object of class <code>"<a href="#topic+proc">proc</a>"</code> with actions in <code>actions</code>
and the corresponding timestamps removed.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  seqs &lt;- seq_gen(10)
  new_seqs &lt;- remove_action(seqs, c("RUN", "Start"))
</code></pre>

<hr>
<h2 id='remove_repeat'>Remove repeated actions</h2><span id='topic+remove_repeat'></span>

<h3>Description</h3>

<p>Remove repeated actions
</p>


<h3>Usage</h3>

<pre><code class='language-R'>remove_repeat(seqs, ignore = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="remove_repeat_+3A_seqs">seqs</code></td>
<td>
<p>an object of class <code>"<a href="#topic+proc">proc</a>"</code></p>
</td></tr>
<tr><td><code id="remove_repeat_+3A_ignore">ignore</code></td>
<td>
<p>repeated actions in ignore will not be deleted.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>an object of class <code>"<a href="#topic+proc">proc</a>"</code>
</p>

<hr>
<h2 id='replace_action'>Replace actions in response processes</h2><span id='topic+replace_action'></span>

<h3>Description</h3>

<p>Replace <code>old_action</code> with <code>new_action</code> in <code>seqs</code>. Timestamp
sequences are not affected.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>replace_action(seqs, old_action, new_action)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="replace_action_+3A_seqs">seqs</code></td>
<td>
<p>an object of class <code>"<a href="#topic+proc">proc</a>"</code></p>
</td></tr>
<tr><td><code id="replace_action_+3A_old_action">old_action</code></td>
<td>
<p>a string giving the action to be replaced.</p>
</td></tr>
<tr><td><code id="replace_action_+3A_new_action">new_action</code></td>
<td>
<p>a string giving the action replacing <code>old_action</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>an object of class <code>"<a href="#topic+proc">proc</a>"</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>seqs &lt;- seq_gen(10)
new_seqs &lt;- replace_action(seqs, "Start", "Begin")
</code></pre>

<hr>
<h2 id='seq_gen'>Action sequence generator</h2><span id='topic+seq_gen'></span>

<h3>Description</h3>

<p><code>seq_gen</code> generates action sequences of an imaginary simulation-based item.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>seq_gen(n, action_set1 = c("OPT1_1", "OPT1_2", "OPT1_3"),
  action_set2 = c("OPT2_1", "OPT2_2"), answer_set = c("CHECK_A",
  "CHECK_B", "CHECK_C", "CHECK_D"), p1 = rep(1, length(action_set1)),
  p2 = rep(1, length(action_set2)), p_answer = rep(1,
  length(answer_set)), p_continue = 0.5, p_choose = 0.5,
  include_time = FALSE, time_intv_dist = list("exp", 1))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="seq_gen_+3A_n">n</code></td>
<td>
<p>An integer. The number of action sequences to be generated.</p>
</td></tr>
<tr><td><code id="seq_gen_+3A_action_set1">action_set1</code>, <code id="seq_gen_+3A_action_set2">action_set2</code></td>
<td>
<p>Character vectors giving the choices for 
the first and the second conditions.</p>
</td></tr>
<tr><td><code id="seq_gen_+3A_answer_set">answer_set</code></td>
<td>
<p>A character vector giving the choices for the answer.</p>
</td></tr>
<tr><td><code id="seq_gen_+3A_p1">p1</code>, <code id="seq_gen_+3A_p2">p2</code></td>
<td>
<p>Nonnegative numeric vectors. They are the weights for sampling 
from <code>action_set1</code> and <code>action_set2</code>.</p>
</td></tr>
<tr><td><code id="seq_gen_+3A_p_answer">p_answer</code></td>
<td>
<p>A nonnegative numeric vector giving the weights for sampling
from <code>answer_set</code>.</p>
</td></tr>
<tr><td><code id="seq_gen_+3A_p_continue">p_continue</code></td>
<td>
<p>Probability of running an/another experiment.</p>
</td></tr>
<tr><td><code id="seq_gen_+3A_p_choose">p_choose</code></td>
<td>
<p>Probability of choosing an answer.</p>
</td></tr>
<tr><td><code id="seq_gen_+3A_include_time">include_time</code></td>
<td>
<p>logical. Indicate if timestamp sequences should be generated. Default is
FALSE.</p>
</td></tr>
<tr><td><code id="seq_gen_+3A_time_intv_dist">time_intv_dist</code></td>
<td>
<p>A list specifying the distribution of the inter-arrival time.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The format of the generated sequences resembles that of the response processes of 
simulation-based items. In these items, participants are asked to answer
a question by running simulated experiments in which two conditions can 
be controlled. A simulated experiment can be run by setting the two conditions
at one of the given choices and click &quot;Run&quot; button.
</p>
<p>The possible actions are &quot;Start&quot;, &quot;End&quot;, &quot;Run&quot;, and the elements in <code>action_set1</code>, 
<code>action_set2</code>, and <code>answer_set</code>. The generated sequences begin with &quot;Start&quot;
and continue with groups of three actions. Each group of three actions, representing 
one experiment, consists of an action chosen from <code>action_set1</code> according to 
<code>p1</code>, an action chosen from <code>action_set2</code> according to <code>p2</code>, and &quot;Run&quot;.
The probability of performing an experiment after &quot;Start&quot; or one experiment is 
<code>p_continue</code>. After the experiment process, with probability <code>p_choose</code>, an 
answer will be chosen. The chosen answer is randomly sampled from <code>answer_set</code> 
according to <code>p_answer</code>. All generated sequences end with &quot;End&quot;.
</p>


<h3>Value</h3>

<p>An object of class <code>"<a href="#topic+proc">proc</a>"</code> with <code>time_seqs = NULL</code>.
</p>


<h3>See Also</h3>

<p>Other sequence generators: <code><a href="#topic+seq_gen2">seq_gen2</a></code>,
<code><a href="#topic+seq_gen3">seq_gen3</a></code>
</p>

<hr>
<h2 id='seq_gen2'>Markov action sequence generator</h2><span id='topic+seq_gen2'></span>

<h3>Description</h3>

<p><code>seq_gen2</code> generates action sequences according to a given probability
transition matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>seq_gen2(n, Pmat = NULL, events = letters, start_index = 1,
  end_index = length(events), max_len = 200, include_time = FALSE,
  time_intv_dist = list("exp", 1))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="seq_gen2_+3A_n">n</code></td>
<td>
<p>An integer. The number of action sequences to be generated.</p>
</td></tr>
<tr><td><code id="seq_gen2_+3A_pmat">Pmat</code></td>
<td>
<p>An <code>N</code> by <code>N</code> probability transition matrix.</p>
</td></tr>
<tr><td><code id="seq_gen2_+3A_events">events</code></td>
<td>
<p>A character vector specifying the set of <code>N</code> possible
actions. Default is <code>letters</code>.</p>
</td></tr>
<tr><td><code id="seq_gen2_+3A_start_index">start_index</code></td>
<td>
<p>Index of the action indicating the start of an item in
<code>events</code>.</p>
</td></tr>
<tr><td><code id="seq_gen2_+3A_end_index">end_index</code></td>
<td>
<p>Index of the action indicating the end of an item in
<code>events</code>.</p>
</td></tr>
<tr><td><code id="seq_gen2_+3A_max_len">max_len</code></td>
<td>
<p>Maximum length of generated sequences.</p>
</td></tr>
<tr><td><code id="seq_gen2_+3A_include_time">include_time</code></td>
<td>
<p>logical. Indicate if timestamp sequences should be generated. Default is
FALSE.</p>
</td></tr>
<tr><td><code id="seq_gen2_+3A_time_intv_dist">time_intv_dist</code></td>
<td>
<p>A list specifying the distribution of the inter-arrival time.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function generates <code>n</code> action sequences according <code>Pmat</code>. The
set of possible actions is <code>events</code>. All generated sequences start with
<code>events[start_index]</code> and end with <code>events[end_index]</code>. If
<code>Pmat</code> is not supplied, actions is uniformly drawn from
<code>events[-start_index]</code> until <code>events[end_index]</code> appears.
</p>


<h3>Value</h3>

<p>An object of class <code>"<a href="#topic+proc">proc</a>"</code> with <code>time_seqs = NULL</code>.
</p>


<h3>See Also</h3>

<p>Other sequence generators: <code><a href="#topic+seq_gen3">seq_gen3</a></code>,
<code><a href="#topic+seq_gen">seq_gen</a></code>
</p>

<hr>
<h2 id='seq_gen3'>RNN action sequence generator</h2><span id='topic+seq_gen3'></span>

<h3>Description</h3>

<p><code>seq_gen3</code> generates action sequences according to a recurrent neural network
</p>


<h3>Usage</h3>

<pre><code class='language-R'>seq_gen3(n, events = letters, rnn_type = "lstm", K = 10,
  weights = NULL, max_len = 100, initial_state = NULL,
  start_index = 1, end_index = length(events), include_time = FALSE,
  time_intv_dist = list("exp", 1))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="seq_gen3_+3A_n">n</code></td>
<td>
<p>An integer. The number of action sequences to be generated.</p>
</td></tr>
<tr><td><code id="seq_gen3_+3A_events">events</code></td>
<td>
<p>A character vector specifying the set of <code>N</code> possible
actions. Default is <code>letters</code>.</p>
</td></tr>
<tr><td><code id="seq_gen3_+3A_rnn_type">rnn_type</code></td>
<td>
<p>the type of recurrent unit to be used for generating sequences. 
<code>"lstm"</code> for the long-short term memory unit. <code>"gru"</code> for the gated
recurrent unit.</p>
</td></tr>
<tr><td><code id="seq_gen3_+3A_k">K</code></td>
<td>
<p>the latent dimension of the recurrent unit.</p>
</td></tr>
<tr><td><code id="seq_gen3_+3A_weights">weights</code></td>
<td>
<p>a list containing the weights in the embedding layer, the recurrent 
unit, the fully connected layer. If not (properly) specified, randomly generated 
weights are used.</p>
</td></tr>
<tr><td><code id="seq_gen3_+3A_max_len">max_len</code></td>
<td>
<p>Maximum length of generated sequences.</p>
</td></tr>
<tr><td><code id="seq_gen3_+3A_initial_state">initial_state</code></td>
<td>
<p>a list containing the initial state of the recurrent neural 
network. If <code>rnn_type="lstm"</code>, it contains two 1 by <code>K</code> matrices. If
<code>rnn_type="gru"</code>, it contains one 1 by <code>K</code> matrix. If not specified, 
all the elements are set to zero.</p>
</td></tr>
<tr><td><code id="seq_gen3_+3A_start_index">start_index</code></td>
<td>
<p>Index of the action indicating the start of an item in
<code>events</code>.</p>
</td></tr>
<tr><td><code id="seq_gen3_+3A_end_index">end_index</code></td>
<td>
<p>Index of the action indicating the end of an item in
<code>events</code>.</p>
</td></tr>
<tr><td><code id="seq_gen3_+3A_include_time">include_time</code></td>
<td>
<p>logical. Indicate if timestamp sequences should be generated. Default is
FALSE.</p>
</td></tr>
<tr><td><code id="seq_gen3_+3A_time_intv_dist">time_intv_dist</code></td>
<td>
<p>A list specifying the distribution of the inter-arrival time.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing the following elements
</p>
<table role = "presentation">
<tr><td><code>seqs</code></td>
<td>
<p>an object of class <code>"<a href="#topic+proc">proc</a>"</code> with <code>time_seqs=NULL</code>.</p>
</td></tr>
<tr><td><code>weights</code></td>
<td>
<p>a list containing the weights used for generating sequences.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>Other sequence generators: <code><a href="#topic+seq_gen2">seq_gen2</a></code>,
<code><a href="#topic+seq_gen">seq_gen</a></code>
</p>

<hr>
<h2 id='seq2feature_mds'>Feature extraction via multidimensional scaling</h2><span id='topic+seq2feature_mds'></span>

<h3>Description</h3>

<p><code>seq2feature_mds</code> extracts <code>K</code> features from response processes by
multidimensional scaling.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>seq2feature_mds(seqs = NULL, K = 2, method = "auto",
  dist_type = "oss_action", pca = TRUE, subset_size = 100,
  subset_method = "random", n_cand = 10, return_dist = FALSE,
  L_set = 1:3)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="seq2feature_mds_+3A_seqs">seqs</code></td>
<td>
<p>a <code>"<a href="#topic+proc">proc</a>"</code> object or a square matrix. If a squared matrix is 
provided, it is treated as the dissimilary matrix of a group of response processes.</p>
</td></tr>
<tr><td><code id="seq2feature_mds_+3A_k">K</code></td>
<td>
<p>the number of features to be extracted.</p>
</td></tr>
<tr><td><code id="seq2feature_mds_+3A_method">method</code></td>
<td>
<p>a character string specifies the algorithm used for performing MDS. See
'Details'.</p>
</td></tr>
<tr><td><code id="seq2feature_mds_+3A_dist_type">dist_type</code></td>
<td>
<p>a character string specifies the dissimilarity measure for two
response processes. See 'Details'.</p>
</td></tr>
<tr><td><code id="seq2feature_mds_+3A_pca">pca</code></td>
<td>
<p>logical. If <code>TRUE</code> (default), the principal components of the
extracted features are returned.</p>
</td></tr>
<tr><td><code id="seq2feature_mds_+3A_subset_size">subset_size</code>, <code id="seq2feature_mds_+3A_n_cand">n_cand</code></td>
<td>
<p>two parameters used in the large data algorithm. See 'Details'
and <code><a href="#topic+seq2feature_mds_large">seq2feature_mds_large</a></code>.</p>
</td></tr>
<tr><td><code id="seq2feature_mds_+3A_subset_method">subset_method</code></td>
<td>
<p>a character string specifying the method for choosing the subset 
in the large data algorithm. See 'Details' and <code><a href="#topic+seq2feature_mds_large">seq2feature_mds_large</a></code>.</p>
</td></tr>
<tr><td><code id="seq2feature_mds_+3A_return_dist">return_dist</code></td>
<td>
<p>logical. If <code>TRUE</code>, the dissimilarity matrix will be
returned. Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="seq2feature_mds_+3A_l_set">L_set</code></td>
<td>
<p>length of ngrams considered</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Since the classical MDS has a computational complexity of order <code class="reqn">n^3</code> where 
<code class="reqn">n</code> is the number of response processes, it is computational expensive to 
perform classical MDS when a large number of response processes is considered. 
In addition, storing an <code class="reqn">n \times n</code> dissimilarity matrix when <code class="reqn">n</code> is large
require a large amount of memory. In <code>seq2feature_mds</code>, the algorithm proposed
in Paradis (2018) is implemented to obtain MDS for large datasets. <code>method</code> 
specifies the algorithm to be used for obtaining MDS features. If <code>method = "small"</code>,
classical MDS is used by calling <code><a href="stats.html#topic+cmdscale">cmdscale</a></code>. If <code>method = "large"</code>,
the algorithm for large datasets will be used. If <code>method = "auto"</code> (default), 
<code>seq2feature_mds</code> selects the algorithm automatically based on the sample size.
</p>
<p><code>dist_type</code> specifies the dissimilarity to be used for measuring the discrepancy
between two response processes. If <code>dist_type = "oss_action"</code>, the order-based 
sequence similarity (oss) proposed in Gomez-Alonso and Valls (2008) is used 
for action sequences. If <code>dist_type = "oss_both"</code>, both action sequences and
timestamp sequences are used to compute a time-weighted oss. 
</p>
<p>The number of features to be extracted <code>K</code> can be selected by cross-validation 
using <code><a href="#topic+chooseK_mds">chooseK_mds</a></code>.
</p>


<h3>Value</h3>

<p><code>seq2feature_mds</code> returns a list containing 
</p>
<table role = "presentation">
<tr><td><code>theta</code></td>
<td>
<p>a numeric matrix giving the <code>K</code> extracted features or principal
features. Each column is a feature.</p>
</td></tr> 
<tr><td><code>dist_mat</code></td>
<td>
<p>the dissimilary matrix. This element exists only if 
<code>return_dist=TRUE</code>.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Gomez-Alonso, C. and Valls, A. (2008). A similarity measure for sequences of
categorical data based on the ordering of common elements. In V. Torra &amp; Y. Narukawa (Eds.) 
<em>Modeling Decisions for Artificial Intelligence</em>, (pp. 134-145). Springer Berlin Heidelberg.
</p>
<p>Paradis, E. (2018). Multidimensional scaling with very large datasets. <em>
Journal of Computational and Graphical Statistics</em>, 27(4), 935-939.
</p>
<p>Tang, X., Wang, Z., He, Q., Liu, J., and Ying, Z. (2020) Latent Feature Extraction for 
Process Data via Multidimensional Scaling. <em>Psychometrika</em>, 85, 378-397.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+chooseK_mds">chooseK_mds</a></code> for choosing <code>K</code>.
</p>
<p>Other feature extraction methods: <code><a href="#topic+aseq2feature_seq2seq">aseq2feature_seq2seq</a></code>,
<code><a href="#topic+atseq2feature_seq2seq">atseq2feature_seq2seq</a></code>,
<code><a href="#topic+seq2feature_mds_large">seq2feature_mds_large</a></code>,
<code><a href="#topic+seq2feature_ngram">seq2feature_ngram</a></code>,
<code><a href="#topic+seq2feature_seq2seq">seq2feature_seq2seq</a></code>,
<code><a href="#topic+tseq2feature_seq2seq">tseq2feature_seq2seq</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 50
set.seed(12345)
seqs &lt;- seq_gen(n)
theta &lt;- seq2feature_mds(seqs, 5)$theta
</code></pre>

<hr>
<h2 id='seq2feature_mds_large'>Feature Extraction by MDS for Large Dataset</h2><span id='topic+seq2feature_mds_large'></span>

<h3>Description</h3>

<p><code>seq2feature_mds_large</code> extracts MDS features from a large number of 
response processes. The algorithm proposed in Paradis (2018) is implemented with minor 
variations to perform MDS. The algorithm first selects a relatively small subset of 
response processes to perform the classical MDS. Then the coordinate of each of the 
other response processes are obtained by minimizing the loss function related to the target
response processes and the those in the subset through BFGS.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>seq2feature_mds_large(seqs, K, dist_type = "oss_action", subset_size,
  subset_method = "random", n_cand = 10, pca = TRUE, L_set = 1:3)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="seq2feature_mds_large_+3A_seqs">seqs</code></td>
<td>
<p>an object of class <code>"<a href="#topic+proc">proc</a>"</code></p>
</td></tr>
<tr><td><code id="seq2feature_mds_large_+3A_k">K</code></td>
<td>
<p>the number of features to be extracted.</p>
</td></tr>
<tr><td><code id="seq2feature_mds_large_+3A_dist_type">dist_type</code></td>
<td>
<p>a character string specifies the dissimilarity measure for two
response processes. See 'Details'.</p>
</td></tr>
<tr><td><code id="seq2feature_mds_large_+3A_subset_size">subset_size</code></td>
<td>
<p>the size of the subset on which classical MDS is performed.</p>
</td></tr>
<tr><td><code id="seq2feature_mds_large_+3A_subset_method">subset_method</code></td>
<td>
<p>a character string specifying the method for choosing the subset.
It must be one of <code>"random"</code>, <code>"sample_avgmax"</code>,
<code>"sample_minmax"</code>, <code>"full_avgmax"</code>, and <code>"full_minmax"</code>.</p>
</td></tr>
<tr><td><code id="seq2feature_mds_large_+3A_n_cand">n_cand</code></td>
<td>
<p>The size of the candidate set when selecting the subset. It is only used when 
<code>subset_method</code> is <code>"sample_avgmax"</code> or <code>"sample_minmax"</code>.</p>
</td></tr>
<tr><td><code id="seq2feature_mds_large_+3A_pca">pca</code></td>
<td>
<p>logical. If <code>TRUE</code> (default), the principal components of the
extracted features are returned.</p>
</td></tr>
<tr><td><code id="seq2feature_mds_large_+3A_l_set">L_set</code></td>
<td>
<p>length of ngrams considered</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>seq2feature_mds_large</code> returns an <code class="reqn">n \times K</code> matrix of extracted 
features.
</p>


<h3>References</h3>

<p>Paradis, E. (2018). Multidimensional Scaling with Very Large Datasets. 
<em>Journal of Computational and Graphical Statistics</em>, 27, 935&ndash;939.
</p>


<h3>See Also</h3>

<p>Other feature extraction methods: <code><a href="#topic+aseq2feature_seq2seq">aseq2feature_seq2seq</a></code>,
<code><a href="#topic+atseq2feature_seq2seq">atseq2feature_seq2seq</a></code>,
<code><a href="#topic+seq2feature_mds">seq2feature_mds</a></code>,
<code><a href="#topic+seq2feature_ngram">seq2feature_ngram</a></code>,
<code><a href="#topic+seq2feature_seq2seq">seq2feature_seq2seq</a></code>,
<code><a href="#topic+tseq2feature_seq2seq">tseq2feature_seq2seq</a></code>
</p>

<hr>
<h2 id='seq2feature_mds_stochastic'>Feature extraction by stochastic mds</h2><span id='topic+seq2feature_mds_stochastic'></span>

<h3>Description</h3>

<p>Feature extraction by stochastic mds
</p>


<h3>Usage</h3>

<pre><code class='language-R'>seq2feature_mds_stochastic(seqs = NULL, K = 2,
  dist_type = "oss_action", max_epoch = 100, step_size = 0.01,
  pca = TRUE, tot = 1e-06, return_dist = FALSE, L_set = 1:3)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="seq2feature_mds_stochastic_+3A_seqs">seqs</code></td>
<td>
<p>a <code>"<a href="#topic+proc">proc</a>"</code> object or a square matrix. If a squared matrix is 
provided, it is treated as the dissimilary matrix of a group of response processes.</p>
</td></tr>
<tr><td><code id="seq2feature_mds_stochastic_+3A_k">K</code></td>
<td>
<p>the number of features to be extracted.</p>
</td></tr>
<tr><td><code id="seq2feature_mds_stochastic_+3A_dist_type">dist_type</code></td>
<td>
<p>a character string specifies the dissimilarity measure for two
response processes. See 'Details'.</p>
</td></tr>
<tr><td><code id="seq2feature_mds_stochastic_+3A_max_epoch">max_epoch</code></td>
<td>
<p>the maximum number of epochs for stochastic gradient
descent.</p>
</td></tr>
<tr><td><code id="seq2feature_mds_stochastic_+3A_step_size">step_size</code></td>
<td>
<p>the step size of stochastic gradient descent.</p>
</td></tr>
<tr><td><code id="seq2feature_mds_stochastic_+3A_pca">pca</code></td>
<td>
<p>a logical scalar. If <code>TRUE</code>, the principal components of the
extracted features are returned.</p>
</td></tr>
<tr><td><code id="seq2feature_mds_stochastic_+3A_tot">tot</code></td>
<td>
<p>the accuracy tolerance for determining convergence.</p>
</td></tr>
<tr><td><code id="seq2feature_mds_stochastic_+3A_return_dist">return_dist</code></td>
<td>
<p>logical. If <code>TRUE</code>, the dissimilarity matrix will be
returned. Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="seq2feature_mds_stochastic_+3A_l_set">L_set</code></td>
<td>
<p>length of ngrams considered.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>seq2feature_mds_stochastic</code> returns a list containing 
</p>
<table role = "presentation">
<tr><td><code>theta</code></td>
<td>
<p>a numeric matrix giving the <code>K</code> extracted features or principal
features. Each column is a feature.</p>
</td></tr> 
<tr><td><code>loss</code></td>
<td>
<p>the value of the multidimensional scaling objective function.</p>
</td></tr>
<tr><td><code>dist_mat</code></td>
<td>
<p>the dissimilary matrix. This element exists only if <code>return_dist=TRUE</code>.</p>
</td></tr>
</table>

<hr>
<h2 id='seq2feature_ngram'>ngram feature extraction</h2><span id='topic+seq2feature_ngram'></span>

<h3>Description</h3>

<p><code>seq2feature_ngram</code> extracts ngram features from response processes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>seq2feature_ngram(seqs, level = 2, type = "binary", sep = "\t")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="seq2feature_ngram_+3A_seqs">seqs</code></td>
<td>
<p>an object of class <code>"<a href="#topic+proc">proc</a>"</code></p>
</td></tr>
<tr><td><code id="seq2feature_ngram_+3A_level">level</code></td>
<td>
<p>an integer specifying the max length of ngrams</p>
</td></tr>
<tr><td><code id="seq2feature_ngram_+3A_type">type</code></td>
<td>
<p>a character string (<code>"binary"</code>, <code>"freq"</code>, or <code>"weighted"</code>) 
specifying the type of ngram features.</p>
</td></tr>
<tr><td><code id="seq2feature_ngram_+3A_sep">sep</code></td>
<td>
<p>action seperator within ngram.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Three types of ngram features can be extracted. <code>type = "binary"</code> gives 
binary ngram features indicating whether an ngram appears in a response process. 
<code>type = "freq"</code> gives ngram frequency features. Each feature is the count of
the corresponding ngram in a response process. <code>type = "weighted"</code> gives the
weighted ngram features proposed in He and von Davier (2015).
</p>


<h3>Value</h3>

<p>a matrix of ngram features
</p>


<h3>References</h3>

<p>He Q., von Davier M. (2015). Identifying Feature Sequences from Process
Data in Problem-Solving Items with N-Grams. In: van der Ark L., Bolt D., Wang WC., 
Douglas J., Chow SM. (eds) <em>Quantitative Psychology Research</em>. Springer 
Proceedings in Mathematics &amp; Statistics, vol 140. Springer, Cham.
</p>


<h3>See Also</h3>

<p>Other feature extraction methods: <code><a href="#topic+aseq2feature_seq2seq">aseq2feature_seq2seq</a></code>,
<code><a href="#topic+atseq2feature_seq2seq">atseq2feature_seq2seq</a></code>,
<code><a href="#topic+seq2feature_mds_large">seq2feature_mds_large</a></code>,
<code><a href="#topic+seq2feature_mds">seq2feature_mds</a></code>,
<code><a href="#topic+seq2feature_seq2seq">seq2feature_seq2seq</a></code>,
<code><a href="#topic+tseq2feature_seq2seq">tseq2feature_seq2seq</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>seqs &lt;- seq_gen(100)
theta &lt;- seq2feature_ngram(seqs)
</code></pre>

<hr>
<h2 id='seq2feature_seq2seq'>Feature Extraction by autoencoder</h2><span id='topic+seq2feature_seq2seq'></span>

<h3>Description</h3>

<p><code>seq2feature_seq2seq</code> extract features from response processes by autoencoder.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>seq2feature_seq2seq(seqs, ae_type = "action", K, rnn_type = "lstm",
  n_epoch = 50, method = "last", step_size = 1e-04,
  optimizer_name = "adam", cumulative = FALSE, log = TRUE,
  weights = c(1, 0.5), samples_train, samples_valid,
  samples_test = NULL, pca = TRUE, verbose = TRUE,
  return_theta = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="seq2feature_seq2seq_+3A_seqs">seqs</code></td>
<td>
<p>an object of class <code>"<a href="#topic+proc">proc</a>"</code>.</p>
</td></tr>
<tr><td><code id="seq2feature_seq2seq_+3A_ae_type">ae_type</code></td>
<td>
<p>a string specifies the type of autoencoder. The autoencoder can be an
action sequence autoencoder (&quot;action&quot;), a time sequence autoencoder (&quot;time&quot;), or an 
action-time sequence autoencoder (&quot;both&quot;).</p>
</td></tr>
<tr><td><code id="seq2feature_seq2seq_+3A_k">K</code></td>
<td>
<p>the number of features to be extracted.</p>
</td></tr>
<tr><td><code id="seq2feature_seq2seq_+3A_rnn_type">rnn_type</code></td>
<td>
<p>the type of recurrent unit to be used for modeling
response processes. <code>"lstm"</code> for the long-short term memory unit. 
<code>"gru"</code> for the gated recurrent unit.</p>
</td></tr>
<tr><td><code id="seq2feature_seq2seq_+3A_n_epoch">n_epoch</code></td>
<td>
<p>the number of training epochs for the autoencoder.</p>
</td></tr>
<tr><td><code id="seq2feature_seq2seq_+3A_method">method</code></td>
<td>
<p>the method for computing features from the output of an
recurrent neural network in the encoder. Available options are 
<code>"last"</code> and <code>"avg"</code>.</p>
</td></tr>
<tr><td><code id="seq2feature_seq2seq_+3A_step_size">step_size</code></td>
<td>
<p>the learning rate of optimizer.</p>
</td></tr>
<tr><td><code id="seq2feature_seq2seq_+3A_optimizer_name">optimizer_name</code></td>
<td>
<p>a character string specifying the optimizer to be used
for training. Availabel options are <code>"sgd"</code>, <code>"rmsprop"</code>, 
<code>"adadelta"</code>, and <code>"adam"</code>.</p>
</td></tr>
<tr><td><code id="seq2feature_seq2seq_+3A_cumulative">cumulative</code></td>
<td>
<p>logical. If TRUE, the sequence of cumulative time up to each event is
used as input to the neural network. If FALSE, the sequence of inter-arrival time (gap 
time between an event and the previous event) will be used as input to the neural network.
Default is FALSE.</p>
</td></tr>
<tr><td><code id="seq2feature_seq2seq_+3A_log">log</code></td>
<td>
<p>logical. If TRUE, for the timestamp sequences, input of the neural net is
the base-10 log of the original sequence of times plus 1 (i.e., log10(t+1)). If FALSE,
the original sequence of times is used.</p>
</td></tr>
<tr><td><code id="seq2feature_seq2seq_+3A_weights">weights</code></td>
<td>
<p>a vector of 2 elements for the weight of the loss of action sequences
(categorical_crossentropy) and time sequences (mean squared error), respectively. 
The total loss is calculated as the weighted sum of the two losses.</p>
</td></tr>
<tr><td><code id="seq2feature_seq2seq_+3A_samples_train">samples_train</code>, <code id="seq2feature_seq2seq_+3A_samples_valid">samples_valid</code>, <code id="seq2feature_seq2seq_+3A_samples_test">samples_test</code></td>
<td>
<p>vectors of indices specifying the
training, validation and test sets for training autoencoder.</p>
</td></tr>
<tr><td><code id="seq2feature_seq2seq_+3A_pca">pca</code></td>
<td>
<p>logical. If TRUE, the principal components of features are
returned. Default is TRUE.</p>
</td></tr>
<tr><td><code id="seq2feature_seq2seq_+3A_verbose">verbose</code></td>
<td>
<p>logical. If TRUE, training progress is printed.</p>
</td></tr>
<tr><td><code id="seq2feature_seq2seq_+3A_return_theta">return_theta</code></td>
<td>
<p>logical. If TRUE, extracted features are returned.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function wraps <code><a href="#topic+aseq2feature_seq2seq">aseq2feature_seq2seq</a></code>, 
<code><a href="#topic+tseq2feature_seq2seq">tseq2feature_seq2seq</a></code>, and <code><a href="#topic+atseq2feature_seq2seq">atseq2feature_seq2seq</a></code>.
</p>


<h3>Value</h3>

<p><code>seq2feature_seq2seq</code> returns a list containing
</p>
<table role = "presentation">
<tr><td><code>theta</code></td>
<td>
<p>a matrix containing <code>K</code> features or principal features. Each column is a feature.</p>
</td></tr>
<tr><td><code>train_loss</code></td>
<td>
<p>a vector of length <code>n_epoch</code> recording the trace of training losses.</p>
</td></tr>
<tr><td><code>valid_loss</code></td>
<td>
<p>a vector of length <code>n_epoch</code> recording the trace of validation losses.</p>
</td></tr>
<tr><td><code>test_loss</code></td>
<td>
<p>a vector of length <code>n_epoch</code> recording the trace of test losses. Exists only if <code>samples_test</code> is not <code>NULL</code>.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Tang, X., Wang, Z., Liu, J., and Ying, Z. (2020) An exploratory analysis of the latent 
structure of process data via action sequence autoencoders. <em>British Journal of 
Mathematical and Statistical Psychology</em>. 74(1), 1-33.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+chooseK_seq2seq">chooseK_seq2seq</a></code> for choosing <code>K</code> through cross-validation.
</p>
<p>Other feature extraction methods: <code><a href="#topic+aseq2feature_seq2seq">aseq2feature_seq2seq</a></code>,
<code><a href="#topic+atseq2feature_seq2seq">atseq2feature_seq2seq</a></code>,
<code><a href="#topic+seq2feature_mds_large">seq2feature_mds_large</a></code>,
<code><a href="#topic+seq2feature_mds">seq2feature_mds</a></code>,
<code><a href="#topic+seq2feature_ngram">seq2feature_ngram</a></code>,
<code><a href="#topic+tseq2feature_seq2seq">tseq2feature_seq2seq</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'> 
if (!system("python -c 'import tensorflow as tf'", ignore.stdout = TRUE, ignore.stderr= TRUE)) {
  n &lt;- 50
  data(cc_data)
  samples &lt;- sample(1:length(cc_data$seqs$time_seqs), n)
  seqs &lt;- sub_seqs(cc_data$seqs, samples)

  # action sequence autoencoder
  K_res &lt;- chooseK_seq2seq(seqs=seqs, ae_type="action", K_cand=c(5, 10), 
                           n_epoch=5, n_fold=2, valid_prop=0.2)
  seq2seq_res &lt;- seq2feature_seq2seq(seqs=seqs, ae_type="action", K=K_res$K, 
                         n_epoch=5, samples_train=1:40, samples_valid=41:50)
  theta &lt;- seq2seq_res$theta

  # time sequence autoencoder
  K_res &lt;- chooseK_seq2seq(seqs=seqs, ae_type="time", K_cand=c(5, 10), 
                           n_epoch=5, n_fold=2, valid_prop=0.2)
  seq2seq_res &lt;- seq2feature_seq2seq(seqs=seqs, ae_type="time", K=K_res$K, 
                         n_epoch=5, samples_train=1:40, samples_valid=41:50)
  theta &lt;- seq2seq_res$theta

  # action and time sequence autoencoder
  K_res &lt;- chooseK_seq2seq(seqs=seqs, ae_type="both", K_cand=c(5, 10), 
                           n_epoch=5, n_fold=2, valid_prop=0.2)
  seq2seq_res &lt;- seq2feature_seq2seq(seqs=seqs, ae_type="both", K=K_res$K, 
                         n_epoch=5, samples_train=1:40, samples_valid=41:50)
  theta &lt;- seq2seq_res$theta
  plot(seq2seq_res$train_loss, col="blue", type="l")
  lines(seq2seq_res$valid_loss, col="red")
}

</code></pre>

<hr>
<h2 id='seqm'>Fitting sequence models</h2><span id='topic+seqm'></span>

<h3>Description</h3>

<p><code>seqm</code> is used to fit a neural network model relating a response process
with a variable.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>seqm(seqs, response, covariates = NULL, response_type,
  actions = unique(unlist(seqs$action_seqs)), rnn_type = "lstm",
  include_time = FALSE, time_interval = TRUE, log_time = TRUE,
  K_emb = 20, K_rnn = 20, n_hidden = 0, K_hidden = NULL,
  index_valid = 0.2, verbose = FALSE, max_len = NULL, n_epoch = 20,
  batch_size = 16, optimizer_name = "rmsprop", step_size = 0.001)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="seqm_+3A_seqs">seqs</code></td>
<td>
<p>an object of class <code>"<a href="#topic+proc">proc</a>"</code>.</p>
</td></tr>
<tr><td><code id="seqm_+3A_response">response</code></td>
<td>
<p>response variable.</p>
</td></tr>
<tr><td><code id="seqm_+3A_covariates">covariates</code></td>
<td>
<p>covariate matrix.</p>
</td></tr>
<tr><td><code id="seqm_+3A_response_type">response_type</code></td>
<td>
<p>&quot;binary&quot; or &quot;scale&quot;.</p>
</td></tr>
<tr><td><code id="seqm_+3A_actions">actions</code></td>
<td>
<p>a character vector gives all possible actions. It is will be
expanded to include all actions appear in <code>seqs</code> if necessary.</p>
</td></tr>
<tr><td><code id="seqm_+3A_rnn_type">rnn_type</code></td>
<td>
<p>the type of recurrent unit to be used for modeling
response processes. <code>"lstm"</code> for the long-short term memory unit. 
<code>"gru"</code> for the gated recurrent unit.</p>
</td></tr>
<tr><td><code id="seqm_+3A_include_time">include_time</code></td>
<td>
<p>logical. If the timestamp sequence should be included in the model.</p>
</td></tr>
<tr><td><code id="seqm_+3A_time_interval">time_interval</code></td>
<td>
<p>logical. If the timestamp sequence is included as a sequence of 
inter-arrival time.</p>
</td></tr>
<tr><td><code id="seqm_+3A_log_time">log_time</code></td>
<td>
<p>logical. If take the logarithm of the time sequence.</p>
</td></tr>
<tr><td><code id="seqm_+3A_k_emb">K_emb</code></td>
<td>
<p>the latent dimension of the embedding layer.</p>
</td></tr>
<tr><td><code id="seqm_+3A_k_rnn">K_rnn</code></td>
<td>
<p>the latent dimension of the recurrent neural network.</p>
</td></tr>
<tr><td><code id="seqm_+3A_n_hidden">n_hidden</code></td>
<td>
<p>the number of hidden fully-connected layers.</p>
</td></tr>
<tr><td><code id="seqm_+3A_k_hidden">K_hidden</code></td>
<td>
<p>a vector of length <code>n_hidden</code> specifying the number of
nodes in each hidden layer.</p>
</td></tr>
<tr><td><code id="seqm_+3A_index_valid">index_valid</code></td>
<td>
<p>proportion of sequences used as the validation set or a vector 
of indices specifying the validation set.</p>
</td></tr>
<tr><td><code id="seqm_+3A_verbose">verbose</code></td>
<td>
<p>logical. If TRUE, training progress is printed.</p>
</td></tr>
<tr><td><code id="seqm_+3A_max_len">max_len</code></td>
<td>
<p>the maximum length of response processes.</p>
</td></tr>
<tr><td><code id="seqm_+3A_n_epoch">n_epoch</code></td>
<td>
<p>the number of training epochs.</p>
</td></tr>
<tr><td><code id="seqm_+3A_batch_size">batch_size</code></td>
<td>
<p>the batch size used in training.</p>
</td></tr>
<tr><td><code id="seqm_+3A_optimizer_name">optimizer_name</code></td>
<td>
<p>a character string specifying the optimizer to be used
for training. Availabel options are <code>"sgd"</code>, <code>"rmsprop"</code>, 
<code>"adadelta"</code>, and <code>"adam"</code>.</p>
</td></tr>
<tr><td><code id="seqm_+3A_step_size">step_size</code></td>
<td>
<p>the learning rate of optimizer.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The model consists of an embedding layer, a recurrent layer and one or more
fully connected layers. The embedding layer takes an action sequence and
output a sequences of <code>K</code> dimensional numeric vectors to the recurrent
layer. If <code>include_time = TRUE</code>, the embedding sequence is combined with
the timestamp sequence in the response process as the input the recurrent
layer. The last output of the recurrent layer and the covariates specified in 
<code>covariates</code> are used as the input of the subsequent fully connected layer.
If <code>response_type="binary"</code>, the last layer uses the sigmoid activation
to produce the probability of the response being one. If
<code>response_type="scale"</code>, the last layer uses the linear activation. The
dimension of the output of other fully connected layers (if any) is specified
by <code>K_hidden</code>.
</p>
<p>The action sequences are re-coded into integer sequences and are padded with
zeros to length <code>max_len</code> before feeding into the model. If the provided
<code>max_len</code> is smaller than the length of the longest sequence in
<code>seqs</code>, it will be overridden.
</p>


<h3>Value</h3>

<p><code>seqm</code> returns an object of class <code>"seqm"</code>, which is a list containing
</p>
<table role = "presentation">
<tr><td><code>structure</code></td>
<td>
<p>a string describing the neural network structure.</p>
</td></tr>
<tr><td><code>coefficients</code></td>
<td>
<p>a list of fitted coefficients. The length of the list is 
6 + 2 * <code>n_hidden</code>. The first element gives the action embedding. 
Elements 2-4 are parameters in the recurrent unit. The rest of the elements are 
for the fully connected layers. Elements 4 + (2 * i - 1) and 4 + 2 * i give the parameters
for the i-th fully connected layer.</p>
</td></tr>
<tr><td><code>model_fit</code></td>
<td>
<p>a vector of class <code>"raw"</code>. It is the serialized version of 
the trained keras model.</p>
</td></tr> 
<tr><td><code>feature_model</code></td>
<td>
<p>a vector of class <code>"raw"</code>. It is the serialized version of the
keras model for obtaining the rnn outputs.</p>
</td></tr>
<tr><td><code>include_time</code></td>
<td>
<p>if the timestamp sequence is included in the model.</p>
</td></tr>
<tr><td><code>time_interval</code></td>
<td>
<p>if inter-arrival time is used.</p>
</td></tr>
<tr><td><code>log_time</code></td>
<td>
<p>if the logarithm time is used.</p>
</td></tr>
<tr><td><code>actions</code></td>
<td>
<p>all possible actions.</p>
</td></tr>
<tr><td><code>max_len</code></td>
<td>
<p>the maximum length of action sequences.</p>
</td></tr>
<tr><td><code>history</code></td>
<td>
<p>a <code>n_epoch</code> by 2 matrix giving the training and
validation losses at the end of each epoch.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+predict.seqm">predict.seqm</a></code> for the <code>predict</code> method for <code>seqm</code> objects.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
if (!system("python -c 'import tensorflow as tf'", ignore.stdout = TRUE, ignore.stderr= TRUE)) {
  n &lt;- 100
  data(cc_data)
  samples &lt;- sample(1:length(cc_data$responses), n)
  seqs &lt;- sub_seqs(cc_data$seqs, samples)

  y &lt;- cc_data$responses[samples]
  x &lt;- matrix(rnorm(n*2), ncol=2)

  index_test &lt;- 91:100
  index_train &lt;- 1:90
  seqs_train &lt;- sub_seqs(seqs, index_train)
  seqs_test &lt;- sub_seqs(seqs, index_test)

  actions &lt;- unique(unlist(seqs$action_seqs))

  ## no covariate is used
  res1 &lt;- seqm(seqs = seqs_train, response = y[index_train], 
               response_type = "binary", actions=actions, K_emb = 5, K_rnn = 5, 
               n_epoch = 5)
  pred_res1 &lt;- predict(res1, new_seqs = seqs_test)

  mean(as.numeric(pred_res1 &gt; 0.5) == y[index_test])

  ## add more fully connected layers after the recurrent layer.
  res2 &lt;- seqm(seqs = seqs_train, response = y[index_train],
               response_type = "binary", actions=actions, K_emb = 5, K_rnn = 5, 
               n_hidden=2, K_hidden=c(10,5), n_epoch = 5)
  pred_res2 &lt;- predict(res2, new_seqs = seqs_test)
  mean(as.numeric(pred_res2 &gt; 0.5) == y[index_test])

  ## add covariates
  res3 &lt;- seqm(seqs = seqs_train, response = y[index_train], 
               covariates = x[index_train, ],
               response_type = "binary", actions=actions, 
               K_emb = 5, K_rnn = 5, n_epoch = 5)
  pred_res3 &lt;- predict(res3, new_seqs = seqs_test, 
                       new_covariates=x[index_test, ])
                     
  ## include time sequences
  res4 &lt;- seqm(seqs = seqs_train, response = y[index_train], 
               response_type = "binary", actions=actions,
               include_time=TRUE, K_emb=5, K_rnn=5, n_epoch=5)
  pred_res4 &lt;- predict(res4, new_seqs = seqs_test)
}

</code></pre>

<hr>
<h2 id='sub_seqs'>Subset response processes</h2><span id='topic+sub_seqs'></span>

<h3>Description</h3>

<p>Subset response processes
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sub_seqs(seqs, ids)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="sub_seqs_+3A_seqs">seqs</code></td>
<td>
<p>an object of class <code>"<a href="#topic+proc">proc</a>"</code></p>
</td></tr>
<tr><td><code id="sub_seqs_+3A_ids">ids</code></td>
<td>
<p>a vector of indices</p>
</td></tr>
</table>


<h3>Value</h3>

<p>an object of class <code>"<a href="#topic+proc">proc</a>"</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(cc_data)
seqs &lt;- sub_seqs(cc_data$seqs, 1:10)
</code></pre>

<hr>
<h2 id='summary.proc'>Summary method for class <code>"proc"</code></h2><span id='topic+summary.proc'></span>

<h3>Description</h3>

<p>The summary of a &quot;proc&quot; object combines the summary of the action sequences and the summary
of the timestamp sequences.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'proc'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="summary.proc_+3A_object">object</code></td>
<td>
<p>an object of class <code>"<a href="#topic+proc">proc</a>"</code>.</p>
</td></tr>
<tr><td><code id="summary.proc_+3A_...">...</code></td>
<td>
<p>not used.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list. Its components are the components returned by <a href="#topic+action_seqs_summary">action_seqs_summary</a> and
<a href="#topic+time_seqs_summary">time_seqs_summary</a>.
</p>


<h3>See Also</h3>

<p><a href="#topic+action_seqs_summary">action_seqs_summary</a> and <a href="#topic+time_seqs_summary">time_seqs_summary</a>
</p>

<hr>
<h2 id='time_seqs_summary'>Summarize timestamp sequences</h2><span id='topic+time_seqs_summary'></span>

<h3>Description</h3>

<p>Summarize timestamp sequences
</p>


<h3>Usage</h3>

<pre><code class='language-R'>time_seqs_summary(time_seqs)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="time_seqs_summary_+3A_time_seqs">time_seqs</code></td>
<td>
<p>a list of timestamp sequences</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list containing the following objects
</p>
<table role = "presentation">
<tr><td><code>total_time</code></td>
<td>
<p>total response time of <code>n_seq</code> response processes</p>
</td></tr>
<tr><td><code>mean_react_time</code></td>
<td>
<p>mean reaction time of <code>n_seq</code> response processes</p>
</td></tr>
</table>

<hr>
<h2 id='tseq2feature_seq2seq'>Feature Extraction by time sequence autoencoder</h2><span id='topic+tseq2feature_seq2seq'></span>

<h3>Description</h3>

<p><code>tseq2feature_seq2seq</code> extract features from timestamps of action sequences by a 
sequence autoencoder.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tseq2feature_seq2seq(tseqs, K, cumulative = FALSE, log = TRUE,
  rnn_type = "lstm", n_epoch = 50, method = "last",
  step_size = 1e-04, optimizer_name = "rmsprop", samples_train,
  samples_valid, samples_test = NULL, pca = TRUE, verbose = TRUE,
  return_theta = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="tseq2feature_seq2seq_+3A_tseqs">tseqs</code></td>
<td>
<p>a list of <code>n</code> timestamp sequences. Each element is a numeric
sequence in the form of a vector of timestamps associated with actions, with
the timestamp of the first event (e.g., &quot;start&quot;) of 0.</p>
</td></tr>
<tr><td><code id="tseq2feature_seq2seq_+3A_k">K</code></td>
<td>
<p>the number of features to be extracted.</p>
</td></tr>
<tr><td><code id="tseq2feature_seq2seq_+3A_cumulative">cumulative</code></td>
<td>
<p>logical. If TRUE, the sequence of cumulative time up to each event is
used as input to the neural network. If FALSE, the sequence of inter-arrival time (gap 
time between an event and the previous event) will be used as input to the neural network.
Default is FALSE.</p>
</td></tr>
<tr><td><code id="tseq2feature_seq2seq_+3A_log">log</code></td>
<td>
<p>logical. If TRUE, for the timestamp sequences, input of the neural net is
the base-10 log of the original sequence of times plus 1 (i.e., log10(t+1)). If FALSE,
the original sequence of times is used.</p>
</td></tr>
<tr><td><code id="tseq2feature_seq2seq_+3A_rnn_type">rnn_type</code></td>
<td>
<p>the type of recurrent unit to be used for modeling
response processes. <code>"lstm"</code> for the long-short term memory unit. 
<code>"gru"</code> for the gated recurrent unit.</p>
</td></tr>
<tr><td><code id="tseq2feature_seq2seq_+3A_n_epoch">n_epoch</code></td>
<td>
<p>the number of training epochs for the autoencoder.</p>
</td></tr>
<tr><td><code id="tseq2feature_seq2seq_+3A_method">method</code></td>
<td>
<p>the method for computing features from the output of an
recurrent neural network in the encoder. Available options are 
<code>"last"</code> and <code>"avg"</code>.</p>
</td></tr>
<tr><td><code id="tseq2feature_seq2seq_+3A_step_size">step_size</code></td>
<td>
<p>the learning rate of optimizer.</p>
</td></tr>
<tr><td><code id="tseq2feature_seq2seq_+3A_optimizer_name">optimizer_name</code></td>
<td>
<p>a character string specifying the optimizer to be used
for training. Availabel options are <code>"sgd"</code>, <code>"rmsprop"</code>, 
<code>"adadelta"</code>, and <code>"adam"</code>.</p>
</td></tr>
<tr><td><code id="tseq2feature_seq2seq_+3A_samples_train">samples_train</code></td>
<td>
<p>vectors of indices specifying the
training, validation and test sets for training autoencoder.</p>
</td></tr>
<tr><td><code id="tseq2feature_seq2seq_+3A_samples_valid">samples_valid</code></td>
<td>
<p>vectors of indices specifying the
training, validation and test sets for training autoencoder.</p>
</td></tr>
<tr><td><code id="tseq2feature_seq2seq_+3A_samples_test">samples_test</code></td>
<td>
<p>vectors of indices specifying the
training, validation and test sets for training autoencoder.</p>
</td></tr>
<tr><td><code id="tseq2feature_seq2seq_+3A_pca">pca</code></td>
<td>
<p>logical. If TRUE, the principal components of features are
returned. Default is TRUE.</p>
</td></tr>
<tr><td><code id="tseq2feature_seq2seq_+3A_verbose">verbose</code></td>
<td>
<p>logical. If TRUE, training progress is printed.</p>
</td></tr>
<tr><td><code id="tseq2feature_seq2seq_+3A_return_theta">return_theta</code></td>
<td>
<p>logical. If TRUE, extracted features are returned.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function trains a sequence-to-sequence autoencoder using keras. The encoder
of the autoencoder consists of a recurrent neural network.
The decoder consists of another recurrent neural network and a fully connected layer
with ReLU activation. The outputs of the encoder are the extracted features.
</p>
<p>The output of the encoder is a function of the encoder recurrent neural network.
It is the last latent state of the encoder recurrent neural network if <code>method="last"</code>
and the average of the encoder recurrent neural network latent states if <code>method="avg"</code>.
</p>


<h3>Value</h3>

<p><code>tseq2feature_seq2seq</code> returns a list containing
</p>
<table role = "presentation">
<tr><td><code>theta</code></td>
<td>
<p>a matrix containing <code>K</code> features or principal features. Each column is a feature.</p>
</td></tr>
<tr><td><code>train_loss</code></td>
<td>
<p>a vector of length <code>n_epoch</code> recording the trace of training losses.</p>
</td></tr>
<tr><td><code>valid_loss</code></td>
<td>
<p>a vector of length <code>n_epoch</code> recording the trace of validation losses.</p>
</td></tr>
<tr><td><code>test_loss</code></td>
<td>
<p>a vector of length <code>n_epoch</code> recording the trace of test losses. Exists only if <code>samples_test</code> is not <code>NULL</code>.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+chooseK_seq2seq">chooseK_seq2seq</a></code> for choosing <code>K</code> through cross-validation.
</p>
<p>Other feature extraction methods: <code><a href="#topic+aseq2feature_seq2seq">aseq2feature_seq2seq</a></code>,
<code><a href="#topic+atseq2feature_seq2seq">atseq2feature_seq2seq</a></code>,
<code><a href="#topic+seq2feature_mds_large">seq2feature_mds_large</a></code>,
<code><a href="#topic+seq2feature_mds">seq2feature_mds</a></code>,
<code><a href="#topic+seq2feature_ngram">seq2feature_ngram</a></code>,
<code><a href="#topic+seq2feature_seq2seq">seq2feature_seq2seq</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
if (!system("python -c 'import tensorflow as tf'", ignore.stdout = TRUE, ignore.stderr= TRUE)) {
  n &lt;- 50
  data(cc_data)
  samples &lt;- sample(1:length(cc_data$seqs$time_seqs), n)
  tseqs &lt;- cc_data$seqs$time_seqs[samples]
  time_seq2seq_res &lt;- tseq2feature_seq2seq(tseqs, 5, rnn_type="lstm", n_epoch=5, 
                                   samples_train=1:40, samples_valid=41:50)
  features &lt;- time_seq2seq_res$theta
  plot(time_seq2seq_res$train_loss, col="blue", type="l",
     ylim = range(c(time_seq2seq_res$train_loss, time_seq2seq_res$valid_loss)))
  lines(time_seq2seq_res$valid_loss, col="red", type = 'l')
}


</code></pre>

<hr>
<h2 id='tseq2interval'>Transform a timestamp sequence into a inter-arrival time sequence</h2><span id='topic+tseq2interval'></span>

<h3>Description</h3>

<p>Transform a timestamp sequence into a inter-arrival time sequence
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tseq2interval(x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="tseq2interval_+3A_x">x</code></td>
<td>
<p>a timestamp sequence</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a numeric vector of the same length as <code>x</code>. The first element in 
the returned vector is 0. The t-th returned element is <code>x[t] - x[t-1]</code>.
</p>

<hr>
<h2 id='write.seqs'>Write process data to csv files</h2><span id='topic+write.seqs'></span>

<h3>Description</h3>

<p>Write process data to csv files
</p>


<h3>Usage</h3>

<pre><code class='language-R'>write.seqs(seqs, file, style, id_var = "ID", action_var = "Event",
  time_var = "Time", step_sep = ",", ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="write.seqs_+3A_seqs">seqs</code></td>
<td>
<p>an object of class <code>"<a href="#topic+proc">proc</a>"</code> to written in the csv file.</p>
</td></tr>
<tr><td><code id="write.seqs_+3A_file">file</code></td>
<td>
<p>the name of the csv file from which the response processes are to be read.</p>
</td></tr>
<tr><td><code id="write.seqs_+3A_style">style</code></td>
<td>
<p>the style that the response processes are stored. See 'Details'.</p>
</td></tr>
<tr><td><code id="write.seqs_+3A_id_var">id_var</code></td>
<td>
<p>a string giving the name of the variable storing the process identifier.</p>
</td></tr>
<tr><td><code id="write.seqs_+3A_action_var">action_var</code></td>
<td>
<p>a string giving the name of the variable storing action sequences.</p>
</td></tr>
<tr><td><code id="write.seqs_+3A_time_var">time_var</code></td>
<td>
<p>a string giving the name of the variable storing timestamp sequences.</p>
</td></tr>
<tr><td><code id="write.seqs_+3A_step_sep">step_sep</code></td>
<td>
<p>the step separator characters. It is only used if <code>style="single"</code>.</p>
</td></tr>
<tr><td><code id="write.seqs_+3A_...">...</code></td>
<td>
<p>further arguments to be passed to <code>write.csv</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>No return value.
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
