<!DOCTYPE html><html><head><title>Help for package oem</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {oem}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#big.oem'><p>Orthogonalizing EM for big.matrix objects</p></a></li>
<li><a href='#cv.oem'><p>Cross validation for Orthogonalizing EM</p></a></li>
<li><a href='#logLik.oem'><p>log likelihood function for fitted oem objects</p></a></li>
<li><a href='#oem'><p>Orthogonalizing EM</p></a></li>
<li><a href='#oem.xtx'><p>Orthogonalizing EM with precomputed XtX</p></a></li>
<li><a href='#oemfit'><p>Deprecated functions</p></a></li>
<li><a href='#plot.oem'><p>Plot method for Orthogonalizing EM fitted objects</p></a></li>
<li><a href='#predict.cv.oem'><p>Prediction function for fitted cross validation oem objects</p></a></li>
<li><a href='#predict.oem'><p>Prediction method for Orthogonalizing EM fitted objects</p></a></li>
<li><a href='#predict.xval.oem'><p>Prediction function for fitted cross validation oem objects</p></a></li>
<li><a href='#print.summary.cv.oem'><p>print method for <code>summary.cv.oem</code> objects</p></a></li>
<li><a href='#summary.cv.oem'><p>summary method for cross validation Orthogonalizing EM fitted objects</p></a></li>
<li><a href='#xval.oem'><p>Fast cross validation for Orthogonalizing EM</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Orthogonalizing EM: Penalized Regression for Big Tall Data</td>
</tr>
<tr>
<td>Version:</td>
<td>2.0.11</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Jared Huling &lt;jaredhuling@gmail.com&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Solves penalized least squares problems for big tall data
    using the orthogonalizing EM algorithm of Xiong et al. (2016) 
    &lt;<a href="https://doi.org/10.1080%2F00401706.2015.1054436">doi:10.1080/00401706.2015.1054436</a>&gt;. The main fitting function is oem() and the
    functions cv.oem() and xval.oem() are for cross validation, the latter being an
    accelerated cross validation function for linear models. The big.oem() function
    allows for out of memory fitting. A description of the underlying methods and 
    code interface is described in Huling and Chien (2022) &lt;<a href="https://doi.org/10.18637%2Fjss.v104.i06">doi:10.18637/jss.v104.i06</a>&gt;.</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://arxiv.org/abs/1801.09661">https://arxiv.org/abs/1801.09661</a>,
<a href="https://github.com/jaredhuling/oem">https://github.com/jaredhuling/oem</a>,
<a href="https://jaredhuling.org/oem/">https://jaredhuling.org/oem/</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/jaredhuling/oem/issues">https://github.com/jaredhuling/oem/issues</a></td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.2.0), bigmemory</td>
</tr>
<tr>
<td>Imports:</td>
<td>Rcpp (&ge; 0.11.0), Matrix, foreach, methods</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp, RcppEigen, BH, bigmemory, RcppArmadillo</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.0</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, rmarkdown</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2022-10-12 14:11:31 UTC; huling</td>
</tr>
<tr>
<td>Author:</td>
<td>Bin Dai [aut],
  Jared Huling <a href="https://orcid.org/0000-0003-0670-4845"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cre],
  Yixuan Qiu [ctb],
  Gael Guennebaud [cph],
  Jitse Niesen [cph]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2022-10-13 08:20:08 UTC</td>
</tr>
</table>
<hr>
<h2 id='big.oem'>Orthogonalizing EM for big.matrix objects</h2><span id='topic+big.oem'></span>

<h3>Description</h3>

<p>Orthogonalizing EM for big.matrix objects
</p>


<h3>Usage</h3>

<pre><code class='language-R'>big.oem(
  x,
  y,
  family = c("gaussian", "binomial"),
  penalty = c("elastic.net", "lasso", "ols", "mcp", "scad", "mcp.net", "scad.net",
    "grp.lasso", "grp.lasso.net", "grp.mcp", "grp.scad", "grp.mcp.net", "grp.scad.net",
    "sparse.grp.lasso"),
  weights = numeric(0),
  lambda = numeric(0),
  nlambda = 100L,
  lambda.min.ratio = NULL,
  alpha = 1,
  gamma = 3,
  tau = 0.5,
  groups = numeric(0),
  penalty.factor = NULL,
  group.weights = NULL,
  standardize = TRUE,
  intercept = TRUE,
  maxit = 500L,
  tol = 1e-07,
  irls.maxit = 100L,
  irls.tol = 0.001,
  compute.loss = FALSE,
  gigs = 4,
  hessian.type = c("full", "upper.bound")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="big.oem_+3A_x">x</code></td>
<td>
<p>input big.matrix object pointing to design matrix 
Each row is an observation, each column corresponds to a covariate</p>
</td></tr>
<tr><td><code id="big.oem_+3A_y">y</code></td>
<td>
<p>numeric response vector of length nobs.</p>
</td></tr>
<tr><td><code id="big.oem_+3A_family">family</code></td>
<td>
<p><code>"gaussian"</code> for least squares problems, <code>"binomial"</code> for binary response. 
<code>"binomial"</code> currently not available.</p>
</td></tr>
<tr><td><code id="big.oem_+3A_penalty">penalty</code></td>
<td>
<p>Specification of penalty type. Choices include:
</p>

<ul>
<li><p><code>"elastic.net"</code> - elastic net penalty, extra parameters: <code>"alpha"</code>
</p>
</li>
<li><p><code>"lasso"</code> - lasso penalty
</p>
</li>
<li><p><code>"ols"</code> - ordinary least squares
</p>
</li>
<li><p><code>"mcp"</code> - minimax concave penalty, extra parameters: <code>"gamma"</code>
</p>
</li>
<li><p><code>"scad"</code> - smoothly clipped absolute deviation, extra parameters: <code>"gamma"</code>
</p>
</li>
<li><p><code>"mcp.net"</code> - minimax concave penalty + l2 penalty, extra parameters: 
<code>"gamma"</code>, <code>"alpha"</code>
</p>
</li>
<li><p><code>"scad.net"</code> - smoothly clipped absolute deviation + l2 penalty, extra parameters: 
<code>"gamma"</code>, <code>"alpha"</code>
</p>
</li>
<li><p><code>"grp.lasso"</code> - group lasso penalty
</p>
</li>
<li><p><code>"grp.lasso.net"</code> - group lasso penalty + l2 penalty, extra parameters: <code>"alpha"</code>
</p>
</li>
<li><p><code>"grp.mcp"</code> - group minimax concave penalty, extra parameters: <code>"gamma"</code>
</p>
</li>
<li><p><code>"grp.scad"</code> - group smoothly clipped absolute deviation, extra parameters: <code>"gamma"</code>
</p>
</li>
<li><p><code>"grp.mcp.net"</code> - group minimax concave penalty + l2 penalty, extra parameters: <code>"gamma"</code>, <code>"alpha"</code>
</p>
</li>
<li><p><code>"grp.scad.net"</code> - group smoothly clipped absolute deviation + l2 penalty, extra parameters: <code>"gamma"</code>, <code>"alpha"</code>
</p>
</li>
<li><p><code>"sparse.grp.lasso"</code> - sparse group lasso penalty (group lasso + lasso), extra parameters: <code>"tau"</code>
</p>
</li></ul>

<p>Careful consideration is required for the group lasso, group MCP, and group SCAD penalties. Groups as specified by the <code>groups</code> argument 
should be chosen in a sensible manner.</p>
</td></tr>
<tr><td><code id="big.oem_+3A_weights">weights</code></td>
<td>
<p>observation weights. Not implemented yet. Defaults to 1 for each observation (setting weight vector to 
length 0 will default all weights to 1)</p>
</td></tr>
<tr><td><code id="big.oem_+3A_lambda">lambda</code></td>
<td>
<p>A user supplied lambda sequence. By default, the program computes
its own lambda sequence based on <code>nlambda</code> and <code>lambda.min.ratio</code>. Supplying
a value of lambda overrides this.</p>
</td></tr>
<tr><td><code id="big.oem_+3A_nlambda">nlambda</code></td>
<td>
<p>The number of lambda values - default is 100.</p>
</td></tr>
<tr><td><code id="big.oem_+3A_lambda.min.ratio">lambda.min.ratio</code></td>
<td>
<p>Smallest value for lambda, as a fraction of <code>lambda.max</code>, the (data derived) entry
value (i.e. the smallest value for which all coefficients are zero). The default
depends on the sample size nobs relative to the number of variables nvars. If
<code>nobs &gt; nvars</code>, the default is 0.0001, close to zero. If <code>nobs &lt; nvars</code>, the default
is 0.01. A very small value of <code>lambda.min.ratio</code> will lead to a saturated fit
when <code>nobs &lt; nvars</code>.</p>
</td></tr>
<tr><td><code id="big.oem_+3A_alpha">alpha</code></td>
<td>
<p>mixing value for <code>elastic.net</code>, <code>mcp.net</code>, <code>scad.net</code>, <code>grp.mcp.net</code>, <code>grp.scad.net</code>. 
penalty applied is (1 - alpha) * (ridge penalty) + alpha * (lasso/mcp/mcp/grp.lasso penalty)</p>
</td></tr>
<tr><td><code id="big.oem_+3A_gamma">gamma</code></td>
<td>
<p>tuning parameter for SCAD and MCP penalties. must be &gt;= 1</p>
</td></tr>
<tr><td><code id="big.oem_+3A_tau">tau</code></td>
<td>
<p>mixing value for <code>sparse.grp.lasso</code>. penalty applied is (1 - tau) * (group lasso penalty) + tau * (lasso penalty)</p>
</td></tr>
<tr><td><code id="big.oem_+3A_groups">groups</code></td>
<td>
<p>A vector of describing the grouping of the coefficients. See the example below. All unpenalized variables
should be put in group 0</p>
</td></tr>
<tr><td><code id="big.oem_+3A_penalty.factor">penalty.factor</code></td>
<td>
<p>Separate penalty factors can be applied to each coefficient. 
This is a number that multiplies lambda to allow differential shrinkage. Can be 0 for some variables, 
which implies no shrinkage, and that variable is always included in the model. Default is 1 for all 
variables.</p>
</td></tr>
<tr><td><code id="big.oem_+3A_group.weights">group.weights</code></td>
<td>
<p>penalty factors applied to each group for the group lasso. Similar to <code>penalty.factor</code>, 
this is a number that multiplies lambda to allow differential shrinkage. Can be 0 for some groups, 
which implies no shrinkage, and that group is always included in the model. Default is sqrt(group size) for all
groups.</p>
</td></tr>
<tr><td><code id="big.oem_+3A_standardize">standardize</code></td>
<td>
<p>Logical flag for x variable standardization, prior to fitting the models. 
The coefficients are always returned on the original scale. Default is <code>standardize = TRUE</code>. If 
variables are in the same units already, you might not wish to standardize. Keep in mind that 
standardization is done differently for sparse matrices, so results (when standardized) may be
slightly different for a sparse matrix object and a dense matrix object</p>
</td></tr>
<tr><td><code id="big.oem_+3A_intercept">intercept</code></td>
<td>
<p>Should intercept(s) be fitted (<code>default = TRUE</code>) or set to zero (<code>FALSE</code>)</p>
</td></tr>
<tr><td><code id="big.oem_+3A_maxit">maxit</code></td>
<td>
<p>integer. Maximum number of OEM iterations</p>
</td></tr>
<tr><td><code id="big.oem_+3A_tol">tol</code></td>
<td>
<p>convergence tolerance for OEM iterations</p>
</td></tr>
<tr><td><code id="big.oem_+3A_irls.maxit">irls.maxit</code></td>
<td>
<p>integer. Maximum number of IRLS iterations</p>
</td></tr>
<tr><td><code id="big.oem_+3A_irls.tol">irls.tol</code></td>
<td>
<p>convergence tolerance for IRLS iterations. Only used if <code>family != "gaussian"</code></p>
</td></tr>
<tr><td><code id="big.oem_+3A_compute.loss">compute.loss</code></td>
<td>
<p>should the loss be computed for each estimated tuning parameter? Defaults to <code>FALSE</code>. Setting
to <code>TRUE</code> will dramatically increase computational time</p>
</td></tr>
<tr><td><code id="big.oem_+3A_gigs">gigs</code></td>
<td>
<p>maximum number of gigs of memory available. Used to figure out how to break up calculations
involving the design matrix x</p>
</td></tr>
<tr><td><code id="big.oem_+3A_hessian.type">hessian.type</code></td>
<td>
<p>only for logistic regression. if <code>hessian.type = "full"</code>, then the full hessian is used. If
<code>hessian.type = "upper.bound"</code>, then an upper bound of the hessian is used. The upper bound can be dramatically
faster in certain situations, ie when n &gt;&gt; p</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object with S3 class &quot;oem&quot;
</p>


<h3>References</h3>

<p>Huling. J.D. and Chien, P. (2022), Fast Penalized Regression and Cross Validation for Tall Data with the oem Package.
Journal of Statistical Software 104(6), 1-24. doi:10.18637/jss.v104.i06
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
set.seed(123)
nrows &lt;- 50000
ncols &lt;- 100
bkFile &lt;- "bigmat.bk"
descFile &lt;- "bigmatk.desc"
bigmat &lt;- filebacked.big.matrix(nrow=nrows, ncol=ncols, type="double",
                                backingfile=bkFile, backingpath=".",
                                descriptorfile=descFile,
                                dimnames=c(NULL,NULL))

# Each column value with be the column number multiplied by
# samples from a standard normal distribution.
set.seed(123)
for (i in 1:ncols) bigmat[,i] = rnorm(nrows)*i

y &lt;- rnorm(nrows) + bigmat[,1] - bigmat[,2]

fit &lt;- big.oem(x = bigmat, y = y, 
               penalty = c("lasso", "elastic.net", 
                           "ols", 
                           "mcp",       "scad", 
                           "mcp.net",   "scad.net",
                           "grp.lasso", "grp.lasso.net",
                           "grp.mcp",   "grp.scad",
                           "sparse.grp.lasso"), 
               groups = rep(1:20, each = 5))
               
fit2 &lt;- oem(x = bigmat[,], y = y, 
            penalty = c("lasso", "grp.lasso"), 
            groups = rep(1:20, each = 5))   
           
max(abs(fit$beta[[1]] - fit2$beta[[1]]))            

layout(matrix(1:2, ncol = 2))
plot(fit)
plot(fit, which.model = 2)

## End(Not run)

</code></pre>

<hr>
<h2 id='cv.oem'>Cross validation for Orthogonalizing EM</h2><span id='topic+cv.oem'></span>

<h3>Description</h3>

<p>Cross validation for Orthogonalizing EM
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cv.oem(
  x,
  y,
  penalty = c("elastic.net", "lasso", "ols", "mcp", "scad", "mcp.net", "scad.net",
    "grp.lasso", "grp.lasso.net", "grp.mcp", "grp.scad", "grp.mcp.net", "grp.scad.net",
    "sparse.grp.lasso"),
  weights = numeric(0),
  lambda = NULL,
  type.measure = c("mse", "deviance", "class", "auc", "mae"),
  nfolds = 10,
  foldid = NULL,
  grouped = TRUE,
  keep = FALSE,
  parallel = FALSE,
  ncores = -1,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cv.oem_+3A_x">x</code></td>
<td>
<p>input matrix of dimension n x p or <code>CsparseMatrix</code> objects of the <span class="pkg">Matrix</span> (sparse not yet implemented. 
Each row is an observation, each column corresponds to a covariate. The cv.oem() function
is optimized for n &gt;&gt; p settings and may be very slow when p &gt; n, so please use other packages
such as <code>glmnet</code>, <code>ncvreg</code>, <code>grpreg</code>, or <code>gglasso</code> when p &gt; n or p approx n.</p>
</td></tr>
<tr><td><code id="cv.oem_+3A_y">y</code></td>
<td>
<p>numeric response vector of length nobs.</p>
</td></tr>
<tr><td><code id="cv.oem_+3A_penalty">penalty</code></td>
<td>
<p>Specification of penalty type in lowercase letters. Choices include <code>"lasso"</code>, 
<code>"ols"</code> (Ordinary least squares, no penaly), <code>"elastic.net"</code>, <code>"scad"</code>, <code>"mcp"</code>, <code>"grp.lasso"</code></p>
</td></tr>
<tr><td><code id="cv.oem_+3A_weights">weights</code></td>
<td>
<p>observation weights. defaults to 1 for each observation (setting weight vector to 
length 0 will default all weights to 1)</p>
</td></tr>
<tr><td><code id="cv.oem_+3A_lambda">lambda</code></td>
<td>
<p>A user supplied lambda sequence. By default, the program computes
its own lambda sequence based on nlambda and lambda.min.ratio. Supplying
a value of lambda overrides this.</p>
</td></tr>
<tr><td><code id="cv.oem_+3A_type.measure">type.measure</code></td>
<td>
<p>measure to evaluate for cross-validation. The default is <code>type.measure = "deviance"</code>, 
which uses squared-error for gaussian models (a.k.a <code>type.measure = "mse"</code> there), deviance for logistic
regression. <code>type.measure = "class"</code> applies to binomial only. <code>type.measure = "auc"</code> is for two-class logistic 
regression only. <code>type.measure = "mse"</code> or <code>type.measure = "mae"</code> (mean absolute error) can be used by all models;
they measure the deviation from the fitted mean to the response.</p>
</td></tr>
<tr><td><code id="cv.oem_+3A_nfolds">nfolds</code></td>
<td>
<p>number of folds for cross-validation. default is 10. 3 is smallest value allowed.</p>
</td></tr>
<tr><td><code id="cv.oem_+3A_foldid">foldid</code></td>
<td>
<p>an optional vector of values between 1 and nfold specifying which fold each observation belongs to.</p>
</td></tr>
<tr><td><code id="cv.oem_+3A_grouped">grouped</code></td>
<td>
<p>Like in <span class="pkg">glmnet</span>, this is an experimental argument, with default <code>TRUE</code>, and can be ignored by most users. 
For all models, this refers to computing nfolds separate statistics, and then using their mean and estimated standard 
error to describe the CV curve. If <code>grouped = FALSE</code>, an error matrix is built up at the observation level from the 
predictions from the <code>nfold</code> fits, and then summarized (does not apply to <code>type.measure = "auc"</code>).</p>
</td></tr>
<tr><td><code id="cv.oem_+3A_keep">keep</code></td>
<td>
<p>If <code>keep = TRUE</code>, a prevalidated list of arrasy is returned containing fitted values for each observation 
and each value of lambda for each model. This means these fits are computed with this observation and the rest of its
fold omitted. The folid vector is also returned. Default is <code>keep = FALSE</code></p>
</td></tr>
<tr><td><code id="cv.oem_+3A_parallel">parallel</code></td>
<td>
<p>If TRUE, use parallel foreach to fit each fold. Must register parallel before hand, such as <span class="pkg">doMC</span>.</p>
</td></tr>
<tr><td><code id="cv.oem_+3A_ncores">ncores</code></td>
<td>
<p>Number of cores to use. If <code>parallel = TRUE</code>, then ncores will be automatically set to 1 to prevent conflicts</p>
</td></tr>
<tr><td><code id="cv.oem_+3A_...">...</code></td>
<td>
<p>other parameters to be passed to <code>"oem"</code> function</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object with S3 class <code>"cv.oem"</code>
</p>


<h3>References</h3>

<p>Huling. J.D. and Chien, P. (2022), Fast Penalized Regression and Cross Validation for Tall Data with the oem Package.
Journal of Statistical Software 104(6), 1-24. doi:10.18637/jss.v104.i06
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(123)
n.obs &lt;- 1e4
n.vars &lt;- 100

true.beta &lt;- c(runif(15, -0.25, 0.25), rep(0, n.vars - 15))

x &lt;- matrix(rnorm(n.obs * n.vars), n.obs, n.vars)
y &lt;- rnorm(n.obs, sd = 3) + x %*% true.beta

fit &lt;- cv.oem(x = x, y = y, 
              penalty = c("lasso", "grp.lasso"), 
              groups = rep(1:20, each = 5))

layout(matrix(1:2, ncol = 2))
plot(fit)
plot(fit, which.model = 2)
</code></pre>

<hr>
<h2 id='logLik.oem'>log likelihood function for fitted oem objects</h2><span id='topic+logLik.oem'></span><span id='topic+logLik.cv.oem'></span><span id='topic+logLik.xval.oem'></span>

<h3>Description</h3>

<p>log likelihood function for fitted oem objects
</p>
<p>log likelihood function for fitted cross validation <code>oem</code> objects
</p>
<p>log likelihood function for fitted cross validation <code>oem</code> objects
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'oem'
logLik(object, which.model = 1, ...)

## S3 method for class 'cv.oem'
logLik(object, which.model = 1, ...)

## S3 method for class 'xval.oem'
logLik(object, which.model = 1, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="logLik.oem_+3A_object">object</code></td>
<td>
<p>fitted &quot;oem&quot; model object.</p>
</td></tr>
<tr><td><code id="logLik.oem_+3A_which.model">which.model</code></td>
<td>
<p>If multiple penalties are fit and returned in the same <code>oem</code> object, the <code>which.model</code> argument is used to 
specify which model to plot. For example, if the oem object <code>"oemobj"</code> was fit with argument 
<code>penalty = c("lasso", "grp.lasso")</code>, then <code>which.model = 2</code> provides a plot for the group lasso model.</p>
</td></tr>
<tr><td><code id="logLik.oem_+3A_...">...</code></td>
<td>
<p>not used</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(123)
n.obs &lt;- 2000
n.vars &lt;- 50

true.beta &lt;- c(runif(15, -0.25, 0.25), rep(0, n.vars - 15))
x &lt;- matrix(rnorm(n.obs * n.vars), n.obs, n.vars)
y &lt;- rnorm(n.obs, sd = 3) + x %*% true.beta

fit &lt;- oem(x = x, y = y, penalty = c("lasso", "mcp"), compute.loss = TRUE)

logLik(fit)

logLik(fit, which.model = "mcp")


fit &lt;- cv.oem(x = x, y = y, penalty = c("lasso", "mcp"), compute.loss = TRUE,
              nlambda = 25)

logLik(fit)

logLik(fit, which.model = "mcp")


fit &lt;- xval.oem(x = x, y = y, penalty = c("lasso", "mcp"), compute.loss = TRUE, 
                nlambda = 25)

logLik(fit)

logLik(fit, which.model = "mcp")

</code></pre>

<hr>
<h2 id='oem'>Orthogonalizing EM</h2><span id='topic+oem'></span>

<h3>Description</h3>

<p>Orthogonalizing EM
</p>


<h3>Usage</h3>

<pre><code class='language-R'>oem(
  x,
  y,
  family = c("gaussian", "binomial"),
  penalty = c("elastic.net", "lasso", "ols", "mcp", "scad", "mcp.net", "scad.net",
    "grp.lasso", "grp.lasso.net", "grp.mcp", "grp.scad", "grp.mcp.net", "grp.scad.net",
    "sparse.grp.lasso"),
  weights = numeric(0),
  lambda = numeric(0),
  nlambda = 100L,
  lambda.min.ratio = NULL,
  alpha = 1,
  gamma = 3,
  tau = 0.5,
  groups = numeric(0),
  penalty.factor = NULL,
  group.weights = NULL,
  standardize = TRUE,
  intercept = TRUE,
  maxit = 500L,
  tol = 1e-07,
  irls.maxit = 100L,
  irls.tol = 0.001,
  accelerate = FALSE,
  ncores = -1,
  compute.loss = FALSE,
  hessian.type = c("upper.bound", "full")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="oem_+3A_x">x</code></td>
<td>
<p>input matrix of dimension n x p or <code>CsparseMatrix</code> object of the <span class="pkg">Matrix</span> package. 
Each row is an observation, each column corresponds to a covariate. The oem() function
is optimized for n &gt;&gt; p settings and may be very slow when p &gt; n, so please use other packages
such as <code>glmnet</code>, <code>ncvreg</code>, <code>grpreg</code>, or <code>gglasso</code> when p &gt; n or p approx n.</p>
</td></tr>
<tr><td><code id="oem_+3A_y">y</code></td>
<td>
<p>numeric response vector of length <code>nobs</code>.</p>
</td></tr>
<tr><td><code id="oem_+3A_family">family</code></td>
<td>
<p><code>"gaussian"</code> for least squares problems, <code>"binomial"</code> for binary response.</p>
</td></tr>
<tr><td><code id="oem_+3A_penalty">penalty</code></td>
<td>
<p>Specification of penalty type. Choices include:
</p>

<ul>
<li><p><code>"elastic.net"</code> - elastic net penalty, extra parameters: <code>"alpha"</code>
</p>
</li>
<li><p><code>"lasso"</code> - lasso penalty
</p>
</li>
<li><p><code>"ols"</code> - ordinary least squares
</p>
</li>
<li><p><code>"mcp"</code> - minimax concave penalty, extra parameters: <code>"gamma"</code>
</p>
</li>
<li><p><code>"scad"</code> - smoothly clipped absolute deviation, extra parameters: <code>"gamma"</code>
</p>
</li>
<li><p><code>"mcp.net"</code> - minimax concave penalty + l2 penalty, extra parameters: 
<code>"gamma"</code>, <code>"alpha"</code>
</p>
</li>
<li><p><code>"scad.net"</code> - smoothly clipped absolute deviation + l2 penalty, extra parameters: 
<code>"gamma"</code>, <code>"alpha"</code>
</p>
</li>
<li><p><code>"grp.lasso"</code> - group lasso penalty
</p>
</li>
<li><p><code>"grp.lasso.net"</code> - group lasso penalty + l2 penalty, extra parameters: <code>"alpha"</code>
</p>
</li>
<li><p><code>"grp.mcp"</code> - group minimax concave penalty, extra parameters: <code>"gamma"</code>
</p>
</li>
<li><p><code>"grp.scad"</code> - group smoothly clipped absolute deviation, extra parameters: <code>"gamma"</code>
</p>
</li>
<li><p><code>"grp.mcp.net"</code> - group minimax concave penalty + l2 penalty, extra parameters: <code>"gamma"</code>, <code>"alpha"</code>
</p>
</li>
<li><p><code>"grp.scad.net"</code> - group smoothly clipped absolute deviation + l2 penalty, extra parameters: <code>"gamma"</code>, <code>"alpha"</code>
</p>
</li>
<li><p><code>"sparse.grp.lasso"</code> - sparse group lasso penalty (group lasso + lasso), extra parameters: <code>"tau"</code>
</p>
</li></ul>

<p>Careful consideration is required for the group lasso, group MCP, and group SCAD penalties. Groups as specified by the <code>groups</code> argument 
should be chosen in a sensible manner.</p>
</td></tr>
<tr><td><code id="oem_+3A_weights">weights</code></td>
<td>
<p>observation weights. Not implemented yet. Defaults to 1 for each observation (setting weight vector to 
length 0 will default all weights to 1)</p>
</td></tr>
<tr><td><code id="oem_+3A_lambda">lambda</code></td>
<td>
<p>A user supplied lambda sequence. By default, the program computes
its own lambda sequence based on <code>nlambda</code> and <code>lambda.min.ratio</code>. Supplying
a value of lambda overrides this.</p>
</td></tr>
<tr><td><code id="oem_+3A_nlambda">nlambda</code></td>
<td>
<p>The number of lambda values. The default is 100.</p>
</td></tr>
<tr><td><code id="oem_+3A_lambda.min.ratio">lambda.min.ratio</code></td>
<td>
<p>Smallest value for lambda, as a fraction of <code>lambda.max</code>, the (data derived) entry
value (i.e. the smallest value for which all coefficients are zero). The default
depends on the sample size nobs relative to the number of variables nvars. If
<code>nobs &gt; nvars</code>, the default is 0.0001, close to zero. If <code>nobs &lt; nvars</code>, the default
is 0.01. A very small value of <code>lambda.min.ratio</code> will lead to a saturated fit
when <code>nobs &lt; nvars</code>.</p>
</td></tr>
<tr><td><code id="oem_+3A_alpha">alpha</code></td>
<td>
<p>mixing value for <code>elastic.net</code>, <code>mcp.net</code>, <code>scad.net</code>, <code>grp.mcp.net</code>, <code>grp.scad.net</code>. 
penalty applied is (1 - alpha) * (ridge penalty) + alpha * (lasso/mcp/mcp/grp.lasso penalty)</p>
</td></tr>
<tr><td><code id="oem_+3A_gamma">gamma</code></td>
<td>
<p>tuning parameter for SCAD and MCP penalties. must be &gt;= 1</p>
</td></tr>
<tr><td><code id="oem_+3A_tau">tau</code></td>
<td>
<p>mixing value for <code>sparse.grp.lasso</code>. penalty applied is (1 - tau) * (group lasso penalty) + tau * (lasso penalty)</p>
</td></tr>
<tr><td><code id="oem_+3A_groups">groups</code></td>
<td>
<p>A vector of describing the grouping of the coefficients. See the example below. All unpenalized variables
should be put in group 0</p>
</td></tr>
<tr><td><code id="oem_+3A_penalty.factor">penalty.factor</code></td>
<td>
<p>Separate penalty factors can be applied to each coefficient. 
This is a number that multiplies lambda to allow differential shrinkage. Can be 0 for some variables, 
which implies no shrinkage, and that variable is always included in the model. Default is 1 for all 
variables.</p>
</td></tr>
<tr><td><code id="oem_+3A_group.weights">group.weights</code></td>
<td>
<p>penalty factors applied to each group for the group lasso. Similar to <code>penalty.factor</code>, 
this is a number that multiplies lambda to allow differential shrinkage. Can be 0 for some groups, 
which implies no shrinkage, and that group is always included in the model. Default is sqrt(group size) for all
groups.</p>
</td></tr>
<tr><td><code id="oem_+3A_standardize">standardize</code></td>
<td>
<p>Logical flag for x variable standardization, prior to fitting the models. 
The coefficients are always returned on the original scale. Default is <code>standardize = TRUE</code>. If 
variables are in the same units already, you might not wish to standardize. Keep in mind that 
standardization is done differently for sparse matrices, so results (when standardized) may be
slightly different for a sparse matrix object and a dense matrix object</p>
</td></tr>
<tr><td><code id="oem_+3A_intercept">intercept</code></td>
<td>
<p>Should intercept(s) be fitted (<code>default = TRUE</code>) or set to zero (<code>FALSE</code>)</p>
</td></tr>
<tr><td><code id="oem_+3A_maxit">maxit</code></td>
<td>
<p>integer. Maximum number of OEM iterations</p>
</td></tr>
<tr><td><code id="oem_+3A_tol">tol</code></td>
<td>
<p>convergence tolerance for OEM iterations</p>
</td></tr>
<tr><td><code id="oem_+3A_irls.maxit">irls.maxit</code></td>
<td>
<p>integer. Maximum number of IRLS iterations</p>
</td></tr>
<tr><td><code id="oem_+3A_irls.tol">irls.tol</code></td>
<td>
<p>convergence tolerance for IRLS iterations. Only used if <code>family != "gaussian"</code></p>
</td></tr>
<tr><td><code id="oem_+3A_accelerate">accelerate</code></td>
<td>
<p>boolean argument. Whether or not to use Nesterov acceleration with adaptive restarting</p>
</td></tr>
<tr><td><code id="oem_+3A_ncores">ncores</code></td>
<td>
<p>Integer scalar that specifies the number of threads to be used</p>
</td></tr>
<tr><td><code id="oem_+3A_compute.loss">compute.loss</code></td>
<td>
<p>should the loss be computed for each estimated tuning parameter? Defaults to <code>FALSE</code>. Setting
to <code>TRUE</code> will dramatically increase computational time</p>
</td></tr>
<tr><td><code id="oem_+3A_hessian.type">hessian.type</code></td>
<td>
<p>only for logistic regression. if <code>hessian.type = "full"</code>, then the full hessian is used. If
<code>hessian.type = "upper.bound"</code>, then an upper bound of the hessian is used. The upper bound can be dramatically
faster in certain situations, ie when n &gt;&gt; p</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object with S3 class &quot;oem&quot;
</p>


<h3>References</h3>

<p>Shifeng Xiong, Bin Dai, Jared Huling, and Peter Z. G. Qian. Orthogonalizing
EM: A design-based least squares algorithm. Technometrics, 58(3):285-293, 2016. <a href="https://amstat.tandfonline.com/doi/abs/10.1080/00401706.2015.1054436">https://amstat.tandfonline.com/doi/abs/10.1080/00401706.2015.1054436</a>
</p>
<p>Huling. J.D. and Chien, P. (2022), Fast Penalized Regression and Cross Validation for Tall Data with the oem Package.
Journal of Statistical Software 104(6), 1-24. doi:10.18637/jss.v104.i06
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(123)
n.obs &lt;- 1e4
n.vars &lt;- 50

true.beta &lt;- c(runif(15, -0.25, 0.25), rep(0, n.vars - 15))

x &lt;- matrix(rnorm(n.obs * n.vars), n.obs, n.vars)
y &lt;- rnorm(n.obs, sd = 3) + x %*% true.beta

fit &lt;- oem(x = x, y = y, 
           penalty = c("lasso", "grp.lasso", "sparse.grp.lasso"), 
           groups = rep(1:10, each = 5))

layout(matrix(1:3, ncol = 3))
plot(fit)
plot(fit, which.model = 2)
plot(fit, which.model = "sparse.grp.lasso")

# the oem package has support for
# sparse design matrices

library(Matrix)

xs &lt;- rsparsematrix(n.obs * 25, n.vars * 2, density = 0.01)
ys &lt;- rnorm(n.obs * 25, sd = 3) + as.vector(xs %*% c(true.beta, rep(0, n.vars)) )
x.dense &lt;- as.matrix(xs)

system.time(fit &lt;- oem(x = x.dense, y = ys, 
                       penalty = c("lasso", "grp.lasso"), 
                       groups = rep(1:20, each = 5), intercept = FALSE,
                       standardize = FALSE))

system.time(fits &lt;- oem(x = xs, y = ys, 
                        penalty = c("lasso", "grp.lasso"), 
                        groups = rep(1:20, each = 5), intercept = FALSE, 
                        standardize = FALSE, lambda = fit$lambda))
                        
max(abs(fit$beta[[1]] - fits$beta[[1]]))
max(abs(fit$beta[[2]] - fits$beta[[2]]))

# logistic
y &lt;- rbinom(n.obs, 1, prob = 1 / (1 + exp(-x %*% true.beta)))

system.time(res &lt;- oem(x, y, intercept = FALSE, 
                       penalty = c("lasso", "sparse.grp.lasso", "mcp"), 
                       family = "binomial", 
                       groups = rep(1:10, each = 5),
                       nlambda = 10,
                       irls.tol = 1e-3, tol = 1e-8))

layout(matrix(1:3, ncol = 3))
plot(res)
plot(res, which.model = 2)
plot(res, which.model = "mcp")


# sparse design matrix
xs &lt;- rsparsematrix(n.obs * 2, n.vars, density = 0.01)
x.dense &lt;- as.matrix(xs)
ys &lt;- rbinom(n.obs * 2, 1, prob = 1 / (1 + exp(-x %*% true.beta)))

system.time(res.gr &lt;- oem(x.dense, ys, intercept = FALSE, 
                          penalty = "grp.lasso", 
                          family = "binomial", 
                          nlambda = 10,
                          groups = rep(1:5, each = 10), 
                          irls.tol = 1e-3, tol = 1e-8))
                          
system.time(res.gr.s &lt;- oem(xs, ys, intercept = FALSE, 
                            penalty = "grp.lasso", 
                            family = "binomial", 
                            nlambda = 10,
                            groups = rep(1:5, each = 10), 
                            irls.tol = 1e-3, tol = 1e-8))
                            
max(abs(res.gr$beta[[1]] - res.gr.s$beta[[1]]))

</code></pre>

<hr>
<h2 id='oem.xtx'>Orthogonalizing EM with precomputed XtX</h2><span id='topic+oem.xtx'></span>

<h3>Description</h3>

<p>Orthogonalizing EM with precomputed XtX
</p>


<h3>Usage</h3>

<pre><code class='language-R'>oem.xtx(
  xtx,
  xty,
  family = c("gaussian", "binomial"),
  penalty = c("elastic.net", "lasso", "ols", "mcp", "scad", "mcp.net", "scad.net",
    "grp.lasso", "grp.lasso.net", "grp.mcp", "grp.scad", "grp.mcp.net", "grp.scad.net",
    "sparse.grp.lasso"),
  lambda = numeric(0),
  nlambda = 100L,
  lambda.min.ratio = NULL,
  alpha = 1,
  gamma = 3,
  tau = 0.5,
  groups = numeric(0),
  scale.factor = numeric(0),
  penalty.factor = NULL,
  group.weights = NULL,
  maxit = 500L,
  tol = 1e-07,
  irls.maxit = 100L,
  irls.tol = 0.001
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="oem.xtx_+3A_xtx">xtx</code></td>
<td>
<p>input matrix equal to <code>crossprod(x) / nrow(x)</code>. 
where <code>x</code> is the design matrix.
It is highly recommended to scale by the number of rows in <code>x</code>.
If <code>xtx</code> is scaled, <code>xty</code> must also be scaled or else results may be meaningless!</p>
</td></tr>
<tr><td><code id="oem.xtx_+3A_xty">xty</code></td>
<td>
<p>numeric vector of length <code>nvars</code>. Equal to <code>crosprod(x, y) / nobs</code>. 
It is highly recommended to scale by the number of rows in <code>x</code>.</p>
</td></tr>
<tr><td><code id="oem.xtx_+3A_family">family</code></td>
<td>
<p><code>"gaussian"</code> for least squares problems, <code>"binomial"</code> for binary response. 
(only <code>gaussian</code> implemented currently)</p>
</td></tr>
<tr><td><code id="oem.xtx_+3A_penalty">penalty</code></td>
<td>
<p>Specification of penalty type. Choices include:
</p>

<ul>
<li><p><code>"elastic.net"</code> - elastic net penalty, extra parameters: <code>"alpha"</code>
</p>
</li>
<li><p><code>"lasso"</code> - lasso penalty
</p>
</li>
<li><p><code>"ols"</code> - ordinary least squares
</p>
</li>
<li><p><code>"mcp"</code> - minimax concave penalty, extra parameters: <code>"gamma"</code>
</p>
</li>
<li><p><code>"scad"</code> - smoothly clipped absolute deviation, extra parameters: <code>"gamma"</code>
</p>
</li>
<li><p><code>"mcp.net"</code> - minimax concave penalty + l2 penalty, extra parameters: 
<code>"gamma"</code>, <code>"alpha"</code>
</p>
</li>
<li><p><code>"scad.net"</code> - smoothly clipped absolute deviation + l2 penalty, extra parameters: 
<code>"gamma"</code>, <code>"alpha"</code>
</p>
</li>
<li><p><code>"grp.lasso"</code> - group lasso penalty
</p>
</li>
<li><p><code>"grp.lasso.net"</code> - group lasso penalty + l2 penalty, extra parameters: <code>"alpha"</code>
</p>
</li>
<li><p><code>"grp.mcp"</code> - group minimax concave penalty, extra parameters: <code>"gamma"</code>
</p>
</li>
<li><p><code>"grp.scad"</code> - group smoothly clipped absolute deviation, extra parameters: <code>"gamma"</code>
</p>
</li>
<li><p><code>"grp.mcp.net"</code> - group minimax concave penalty + l2 penalty, extra parameters: <code>"gamma"</code>, <code>"alpha"</code>
</p>
</li>
<li><p><code>"grp.scad.net"</code> - group smoothly clipped absolute deviation + l2 penalty, extra parameters: <code>"gamma"</code>, <code>"alpha"</code>
</p>
</li>
<li><p><code>"sparse.grp.lasso"</code> - sparse group lasso penalty (group lasso + lasso), extra parameters: <code>"tau"</code>
</p>
</li></ul>

<p>Careful consideration is required for the group lasso, group MCP, and group SCAD penalties. Groups as specified by the <code>groups</code> argument 
should be chosen in a sensible manner.</p>
</td></tr>
<tr><td><code id="oem.xtx_+3A_lambda">lambda</code></td>
<td>
<p>A user supplied lambda sequence. By default, the program computes
its own lambda sequence based on <code>nlambda</code> and <code>lambda.min.ratio</code>. Supplying
a value of lambda overrides this.</p>
</td></tr>
<tr><td><code id="oem.xtx_+3A_nlambda">nlambda</code></td>
<td>
<p>The number of lambda values - default is 100.</p>
</td></tr>
<tr><td><code id="oem.xtx_+3A_lambda.min.ratio">lambda.min.ratio</code></td>
<td>
<p>Smallest value for lambda, as a fraction of <code>lambda.max</code>, the (data derived) entry
value (i.e. the smallest value for which all coefficients are zero). The default
depends on the sample size nobs relative to the number of variables nvars. The default is 0.0001</p>
</td></tr>
<tr><td><code id="oem.xtx_+3A_alpha">alpha</code></td>
<td>
<p>mixing value for <code>elastic.net</code>, <code>mcp.net</code>, <code>scad.net</code>, <code>grp.mcp.net</code>, <code>grp.scad.net</code>. 
penalty applied is (1 - alpha) * (ridge penalty) + alpha * (lasso/mcp/mcp/grp.lasso penalty)</p>
</td></tr>
<tr><td><code id="oem.xtx_+3A_gamma">gamma</code></td>
<td>
<p>tuning parameter for SCAD and MCP penalties. must be &gt;= 1</p>
</td></tr>
<tr><td><code id="oem.xtx_+3A_tau">tau</code></td>
<td>
<p>mixing value for <code>sparse.grp.lasso</code>. penalty applied is (1 - tau) * (group lasso penalty) + tau * (lasso penalty)</p>
</td></tr>
<tr><td><code id="oem.xtx_+3A_groups">groups</code></td>
<td>
<p>A vector of describing the grouping of the coefficients. See the example below. All unpenalized variables
should be put in group 0</p>
</td></tr>
<tr><td><code id="oem.xtx_+3A_scale.factor">scale.factor</code></td>
<td>
<p>of length <code>nvars === ncol(xtx) == length(xty)</code> for scaling columns of <code>x</code>. The standard deviation
for each column of <code>x</code> is a common choice for <code>scale.factor</code>. Coefficients will be returned on original scale. Default is 
no scaling.</p>
</td></tr>
<tr><td><code id="oem.xtx_+3A_penalty.factor">penalty.factor</code></td>
<td>
<p>Separate penalty factors can be applied to each coefficient. 
This is a number that multiplies lambda to allow differential shrinkage. Can be 0 for some variables, 
which implies no shrinkage, and that variable is always included in the model. Default is 1 for all 
variables.</p>
</td></tr>
<tr><td><code id="oem.xtx_+3A_group.weights">group.weights</code></td>
<td>
<p>penalty factors applied to each group for the group lasso. Similar to <code>penalty.factor</code>, 
this is a number that multiplies lambda to allow differential shrinkage. Can be 0 for some groups, 
which implies no shrinkage, and that group is always included in the model. Default is sqrt(group size) for all
groups.</p>
</td></tr>
<tr><td><code id="oem.xtx_+3A_maxit">maxit</code></td>
<td>
<p>integer. Maximum number of OEM iterations</p>
</td></tr>
<tr><td><code id="oem.xtx_+3A_tol">tol</code></td>
<td>
<p>convergence tolerance for OEM iterations</p>
</td></tr>
<tr><td><code id="oem.xtx_+3A_irls.maxit">irls.maxit</code></td>
<td>
<p>integer. Maximum number of IRLS iterations</p>
</td></tr>
<tr><td><code id="oem.xtx_+3A_irls.tol">irls.tol</code></td>
<td>
<p>convergence tolerance for IRLS iterations. Only used if <code>family != "gaussian"</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object with S3 class <code>"oem"</code>
</p>


<h3>References</h3>

<p>Huling. J.D. and Chien, P. (2022), Fast Penalized Regression and Cross Validation for Tall Data with the oem Package.
Journal of Statistical Software 104(6), 1-24. doi:10.18637/jss.v104.i06
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(123)
n.obs &lt;- 1e4
n.vars &lt;- 100

true.beta &lt;- c(runif(15, -0.25, 0.25), rep(0, n.vars - 15))

x &lt;- matrix(rnorm(n.obs * n.vars), n.obs, n.vars)
y &lt;- rnorm(n.obs, sd = 3) + x %*% true.beta

fit &lt;- oem(x = x, y = y, 
           penalty = c("lasso", "elastic.net", 
                        "ols", 
                        "mcp",       "scad", 
                        "mcp.net",   "scad.net",
                        "grp.lasso", "grp.lasso.net",
                        "grp.mcp",   "grp.scad",
                        "sparse.grp.lasso"), 
           standardize = FALSE, intercept = FALSE,
           groups = rep(1:20, each = 5))
           
xtx &lt;- crossprod(x) / n.obs
xty &lt;- crossprod(x, y) / n.obs

fit.xtx &lt;- oem.xtx(xtx = xtx, xty = xty, 
                   penalty = c("lasso", "elastic.net", 
                               "ols", 
                               "mcp",       "scad", 
                               "mcp.net",   "scad.net",
                               "grp.lasso", "grp.lasso.net",
                               "grp.mcp",   "grp.scad",
                               "sparse.grp.lasso"), 
                   groups = rep(1:20, each = 5))    
                   
max(abs(fit$beta[[1]][-1,] - fit.xtx$beta[[1]]))
max(abs(fit$beta[[2]][-1,] - fit.xtx$beta[[2]]))       

layout(matrix(1:2, ncol = 2))
plot(fit.xtx)
plot(fit.xtx, which.model = 2)

</code></pre>

<hr>
<h2 id='oemfit'>Deprecated functions</h2><span id='topic+oemfit'></span><span id='topic+oem-deprecated'></span><span id='topic+cv.oemfit'></span><span id='topic+plot.oemfit'></span><span id='topic+predict.oemfit'></span><span id='topic+print.oemfit'></span>

<h3>Description</h3>

<p>These functions have been renamed and deprecated in <span class="pkg">oem</span>:
<code>oemfit()</code> (use <code><a href="#topic+oem">oem</a>()</code>), <code>cv.oemfit()</code>
(use <code><a href="#topic+cv.oem">cv.oem</a>()</code>), <code>print.oemfit()</code>, 
<code>plot.oemfit()</code>, <code>predict.oemfit()</code>, and 
<code>coef.oemfit()</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>oemfit(
  formula,
  data = list(),
  lambda = NULL,
  nlambda = 100,
  lambda.min.ratio = NULL,
  tolerance = 0.001,
  maxIter = 1000,
  standardized = TRUE,
  numGroup = 1,
  penalty = c("lasso", "scad", "ols", "elastic.net", "ngarrote", "mcp"),
  alpha = 3,
  evaluate = 0,
  condition = -1
)

cv.oemfit(
  formula,
  data = list(),
  lambda = NULL,
  type.measure = c("mse", "mae"),
  ...,
  nfolds = 10,
  foldid,
  penalty = c("lasso", "scad", "elastic.net", "ngarrote", "mcp")
)

## S3 method for class 'oemfit'
plot(
  x,
  xvar = c("norm", "lambda", "loglambda", "dev"),
  xlab = iname,
  ylab = "Coefficients",
  ...
)

## S3 method for class 'oemfit'
predict(
  object,
  newx,
  s = NULL,
  type = c("response", "coefficients", "nonzero"),
  ...
)

## S3 method for class 'oemfit'
print(x, digits = max(3, getOption("digits") - 3), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="oemfit_+3A_formula">formula</code></td>
<td>
<p>an object of 'formula' (or one that can be coerced to
that class): a symbolic description of the model to be fitted. The
details of model specification are given under 'Details'</p>
</td></tr>
<tr><td><code id="oemfit_+3A_data">data</code></td>
<td>
<p>an optional data frame, list or environment (or object
coercible by 'as.data.frame' to a data frame) containing the
variables in the model.  If not found in 'data', the
variables are taken from 'environment(formula)', typically
the environment from which 'oemfit' is called.</p>
</td></tr>
<tr><td><code id="oemfit_+3A_lambda">lambda</code></td>
<td>
<p>A user supplied <code>lambda</code> sequence. Typical usage is
to have the program compute its own <code>lambda</code> sequence based on
<code>nlambda</code> and <code>lambda.min.ratio</code>. Supplying a value of
<code>lambda</code> overrides this. WARNING: use with care. Do not supply a
single value for <code>lambda</code> (for predictions after CV use <code>predict()</code> 
instead).  Supply instead a decreasing sequence of <code>lambda</code>
values. <code>oemfit</code> relies on its warms starts for speed, and its
often faster to fit a whole path than compute a single fit.</p>
</td></tr>
<tr><td><code id="oemfit_+3A_nlambda">nlambda</code></td>
<td>
<p>The number of <code>lambda</code> values - default is 100.</p>
</td></tr>
<tr><td><code id="oemfit_+3A_lambda.min.ratio">lambda.min.ratio</code></td>
<td>
<p>Smallest value for <code>lambda</code>, as a fraction of
<code>lambda.max</code>, the (data derived) entry value (i.e. the smallest
value for which all coefficients are zero). The default depends on the
sample size <code>nobs</code> relative to the number of variables
<code>nvars</code>. If <code>nobs &gt; nvars</code>, the default is <code>0.0001</code>,
close to zero.  If <code>nobs &lt; nvars</code>, the default is <code>0.01</code>.
A very small value of
<code>lambda.min.ratio</code> will lead to a saturated fit in the <code>nobs &lt;
nvars</code> case.</p>
</td></tr>
<tr><td><code id="oemfit_+3A_tolerance">tolerance</code></td>
<td>
<p>Convergence tolerance for OEM. Each inner
OEM loop continues until the maximum change in the
objective after any coefficient update is less than <code>tolerance</code>.
Defaults value is <code>1E-3</code>.</p>
</td></tr>
<tr><td><code id="oemfit_+3A_maxiter">maxIter</code></td>
<td>
<p>Maximum number of passes over the data for all lambda
values; default is 1000.</p>
</td></tr>
<tr><td><code id="oemfit_+3A_standardized">standardized</code></td>
<td>
<p>Logical flag for x variable standardization, prior to
fitting the model sequence. The coefficients are always returned on
the original scale. Default is <code>standardize=TRUE</code>.
If variables are in the same units already, you might not wish to
standardize.</p>
</td></tr>
<tr><td><code id="oemfit_+3A_numgroup">numGroup</code></td>
<td>
<p>Integer value for the number of groups to use for OEM
fitting. Default is 1.</p>
</td></tr>
<tr><td><code id="oemfit_+3A_penalty">penalty</code></td>
<td>
<p>type in lower letters. Different types include
'lasso', 'scad', 'ols' (ordinary least square), 'elastic-net',
'ngarrote' (non-negative garrote) and 'mcp'.</p>
</td></tr>
<tr><td><code id="oemfit_+3A_alpha">alpha</code></td>
<td>
<p>alpha value for scad and mcp.</p>
</td></tr>
<tr><td><code id="oemfit_+3A_evaluate">evaluate</code></td>
<td>
<p>debugging argument</p>
</td></tr>
<tr><td><code id="oemfit_+3A_condition">condition</code></td>
<td>
<p>Debugging for different ways of calculating OEM.</p>
</td></tr>
<tr><td><code id="oemfit_+3A_type.measure">type.measure</code></td>
<td>
<p>type.measure measure to evaluate for cross-validation. 
<code>type.measure = "mse"</code> (mean squared error) or 
<code>type.measure = "mae"</code> (mean absolute error)</p>
</td></tr>
<tr><td><code id="oemfit_+3A_...">...</code></td>
<td>
<p>arguments to be passed to <code>oemfit()</code></p>
</td></tr>
<tr><td><code id="oemfit_+3A_nfolds">nfolds</code></td>
<td>
<p>number of folds for cross-validation. default is 10.</p>
</td></tr>
<tr><td><code id="oemfit_+3A_foldid">foldid</code></td>
<td>
<p>an optional vector of values between 1 and nfold specifying which fold each observation belongs to.</p>
</td></tr>
<tr><td><code id="oemfit_+3A_x">x</code></td>
<td>
<p>fitted <code>oemfit</code> object</p>
</td></tr>
<tr><td><code id="oemfit_+3A_xvar">xvar</code></td>
<td>
<p>what is on the X-axis. &quot;norm&quot; plots against the L1-norm of the coefficients,
&quot;lambda&quot; against the log-lambda sequence, and &quot;dev&quot; against the percent deviance
explained.</p>
</td></tr>
<tr><td><code id="oemfit_+3A_xlab">xlab</code></td>
<td>
<p>x-axis label</p>
</td></tr>
<tr><td><code id="oemfit_+3A_ylab">ylab</code></td>
<td>
<p>y-axis label</p>
</td></tr>
<tr><td><code id="oemfit_+3A_object">object</code></td>
<td>
<p>fitted <code>oemfit</code> object</p>
</td></tr>
<tr><td><code id="oemfit_+3A_newx">newx</code></td>
<td>
<p>matrix of new values for x at which predictions are to be
made. Must be a matrix.</p>
</td></tr>
<tr><td><code id="oemfit_+3A_s">s</code></td>
<td>
<p>Value(s) of the penalty parameter lambda at which predictions
are required. Default is the entire sequence used to create the model.</p>
</td></tr>
<tr><td><code id="oemfit_+3A_type">type</code></td>
<td>
<p>not used.</p>
</td></tr>
<tr><td><code id="oemfit_+3A_digits">digits</code></td>
<td>
<p>significant digits in print out.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The sequence of models implied by 'lambda' is fit by OEM algorithm.
</p>


<h3>Author(s)</h3>

<p>Bin Dai
</p>

<hr>
<h2 id='plot.oem'>Plot method for Orthogonalizing EM fitted objects</h2><span id='topic+plot.oem'></span><span id='topic+plot.cv.oem'></span><span id='topic+plot.xval.oem'></span>

<h3>Description</h3>

<p>Plot method for Orthogonalizing EM fitted objects
</p>
<p>Plot method for Orthogonalizing EM fitted objects
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'oem'
plot(
  x,
  which.model = 1,
  xvar = c("norm", "lambda", "loglambda", "dev"),
  labsize = 0.6,
  xlab = iname,
  ylab = NULL,
  main = x$penalty[which.model],
  ...
)

## S3 method for class 'cv.oem'
plot(x, which.model = 1, sign.lambda = 1, ...)

## S3 method for class 'xval.oem'
plot(
  x,
  which.model = 1,
  type = c("cv", "coefficients"),
  xvar = c("norm", "lambda", "loglambda", "dev"),
  labsize = 0.6,
  xlab = iname,
  ylab = NULL,
  main = x$penalty[which.model],
  sign.lambda = 1,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.oem_+3A_x">x</code></td>
<td>
<p>fitted &quot;oem&quot; model object</p>
</td></tr>
<tr><td><code id="plot.oem_+3A_which.model">which.model</code></td>
<td>
<p>If multiple penalties are fit and returned in the same oem object, the which.model argument is used to 
specify which model to plot. For example, if the oem object <code>"oemobj"</code> was fit with argument 
<code>penalty = c("lasso", "grp.lasso")</code>, then <code>which.model = 2</code> provides a plot for the group lasso model.</p>
</td></tr>
<tr><td><code id="plot.oem_+3A_xvar">xvar</code></td>
<td>
<p>What is on the X-axis. <code>"norm"</code> plots against the L1-norm of the coefficients, <code>"lambda"</code> against the log-lambda sequence, and <code>"dev"</code>
against the percent deviance explained.</p>
</td></tr>
<tr><td><code id="plot.oem_+3A_labsize">labsize</code></td>
<td>
<p>size of labels for variable names. If labsize = 0, then no variable names will be plotted</p>
</td></tr>
<tr><td><code id="plot.oem_+3A_xlab">xlab</code></td>
<td>
<p>label for x-axis</p>
</td></tr>
<tr><td><code id="plot.oem_+3A_ylab">ylab</code></td>
<td>
<p>label for y-axis</p>
</td></tr>
<tr><td><code id="plot.oem_+3A_main">main</code></td>
<td>
<p>main title for plot</p>
</td></tr>
<tr><td><code id="plot.oem_+3A_...">...</code></td>
<td>
<p>other graphical parameters for the plot</p>
</td></tr>
<tr><td><code id="plot.oem_+3A_sign.lambda">sign.lambda</code></td>
<td>
<p>Either plot against log(lambda) (default) or its negative if <code>sign.lambda = -1</code>.</p>
</td></tr>
<tr><td><code id="plot.oem_+3A_type">type</code></td>
<td>
<p>one of <code>"cv"</code> or <code>"coefficients"</code>. <code>type = "cv"</code> will produce a plot of cross validation results like plot.cv.oem. 
<code>type = "coefficients"</code> will produce a coefficient path plot like <code>plot.oem()</code></p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(123)
n.obs &lt;- 1e4
n.vars &lt;- 100
n.obs.test &lt;- 1e3

true.beta &lt;- c(runif(15, -0.5, 0.5), rep(0, n.vars - 15))

x &lt;- matrix(rnorm(n.obs * n.vars), n.obs, n.vars)
y &lt;- rnorm(n.obs, sd = 3) + x %*% true.beta

fit &lt;- oem(x = x, y = y, penalty = c("lasso", "grp.lasso"), groups = rep(1:10, each = 10))

layout(matrix(1:2, ncol = 2))
plot(fit, which.model = 1)
plot(fit, which.model = 2)

set.seed(123)
n.obs &lt;- 1e4
n.vars &lt;- 100
n.obs.test &lt;- 1e3

true.beta &lt;- c(runif(15, -0.5, 0.5), rep(0, n.vars - 15))

x &lt;- matrix(rnorm(n.obs * n.vars), n.obs, n.vars)
y &lt;- rnorm(n.obs, sd = 3) + x %*% true.beta

fit &lt;- cv.oem(x = x, y = y, penalty = c("lasso", "grp.lasso"), groups = rep(1:10, each = 10))

layout(matrix(1:2, ncol = 2))
plot(fit, which.model = 1)
plot(fit, which.model = "grp.lasso")

set.seed(123)
n.obs &lt;- 1e4
n.vars &lt;- 100
n.obs.test &lt;- 1e3

true.beta &lt;- c(runif(15, -0.5, 0.5), rep(0, n.vars - 15))

x &lt;- matrix(rnorm(n.obs * n.vars), n.obs, n.vars)
y &lt;- rnorm(n.obs, sd = 3) + x %*% true.beta

fit &lt;- xval.oem(x = x, y = y, penalty = c("lasso", "grp.lasso"), groups = rep(1:10, each = 10))

layout(matrix(1:4, ncol = 2))
plot(fit, which.model = 1)
plot(fit, which.model = 2)

plot(fit, which.model = 1, type = "coef")
plot(fit, which.model = 2, type = "coef")

</code></pre>

<hr>
<h2 id='predict.cv.oem'>Prediction function for fitted cross validation oem objects</h2><span id='topic+predict.cv.oem'></span>

<h3>Description</h3>

<p>Prediction function for fitted cross validation oem objects
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'cv.oem'
predict(
  object,
  newx,
  which.model = "best.model",
  s = c("lambda.min", "lambda.1se"),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.cv.oem_+3A_object">object</code></td>
<td>
<p>fitted <code>"cv.oem"</code> model object</p>
</td></tr>
<tr><td><code id="predict.cv.oem_+3A_newx">newx</code></td>
<td>
<p>Matrix of new values for <code>x</code> at which predictions are to be made. Must be a matrix; can be sparse as in the 
<code>CsparseMatrix</code> objects of the <span class="pkg">Matrix</span> package
This argument is not used for <code>type = c("coefficients","nonzero")</code></p>
</td></tr>
<tr><td><code id="predict.cv.oem_+3A_which.model">which.model</code></td>
<td>
<p>If multiple penalties are fit and returned in the same <code>oem</code> object, the <code>which.model</code> argument is used to 
specify which model to make predictions for. For example, if the oem object <code>"oemobj"</code> was fit with argument 
<code>penalty = c("lasso", "grp.lasso")</code>, then <code>which.model = 2</code> provides predictions for the group lasso model. For 
<code>predict.cv.oem()</code>, can specify
<code>"best.model"</code> to use the best model as estimated by cross-validation</p>
</td></tr>
<tr><td><code id="predict.cv.oem_+3A_s">s</code></td>
<td>
<p>Value(s) of the penalty parameter lambda at which predictions are required. Default is the entire sequence used to create 
the model. For <code>predict.cv.oem()</code>, can also specify <code>"lambda.1se"</code> or <code>"lambda.min"</code> for best lambdas estimated by cross validation</p>
</td></tr>
<tr><td><code id="predict.cv.oem_+3A_...">...</code></td>
<td>
<p>used to pass the other arguments for predict.oem</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object depending on the type argument
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(123)
n.obs &lt;- 1e4
n.vars &lt;- 100
n.obs.test &lt;- 1e3

true.beta &lt;- c(runif(15, -0.5, 0.5), rep(0, n.vars - 15))

x &lt;- matrix(rnorm(n.obs * n.vars), n.obs, n.vars)
y &lt;- rnorm(n.obs, sd = 3) + x %*% true.beta
x.test &lt;- matrix(rnorm(n.obs.test * n.vars), n.obs.test, n.vars)
y.test &lt;- rnorm(n.obs.test, sd = 3) + x.test %*% true.beta

fit &lt;- cv.oem(x = x, y = y, 
              penalty = c("lasso", "grp.lasso"), 
              groups = rep(1:10, each = 10), 
              nlambda = 10)

preds.best &lt;- predict(fit, newx = x.test, type = "response", which.model = "best.model")

apply(preds.best, 2, function(x) mean((y.test - x) ^ 2))

preds.gl &lt;- predict(fit, newx = x.test, type = "response", which.model = "grp.lasso")

apply(preds.gl, 2, function(x) mean((y.test - x) ^ 2))

preds.l &lt;- predict(fit, newx = x.test, type = "response", which.model = 1)

apply(preds.l, 2, function(x) mean((y.test - x) ^ 2))
</code></pre>

<hr>
<h2 id='predict.oem'>Prediction method for Orthogonalizing EM fitted objects</h2><span id='topic+predict.oem'></span>

<h3>Description</h3>

<p>Prediction method for Orthogonalizing EM fitted objects
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'oem'
predict(
  object,
  newx,
  s = NULL,
  which.model = 1,
  type = c("link", "response", "coefficients", "nonzero", "class"),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.oem_+3A_object">object</code></td>
<td>
<p>fitted &quot;oem&quot; model object</p>
</td></tr>
<tr><td><code id="predict.oem_+3A_newx">newx</code></td>
<td>
<p>Matrix of new values for <code>x</code> at which predictions are to be made. Must be a matrix; can be sparse as in the 
<code>CsparseMatrix</code> objects of the <span class="pkg">Matrix</span> package. 
This argument is not used for <code>type=c("coefficients","nonzero")</code></p>
</td></tr>
<tr><td><code id="predict.oem_+3A_s">s</code></td>
<td>
<p>Value(s) of the penalty parameter lambda at which predictions are required. Default is the entire sequence used to create 
the model.</p>
</td></tr>
<tr><td><code id="predict.oem_+3A_which.model">which.model</code></td>
<td>
<p>If multiple penalties are fit and returned in the same oem object, the <code>which.model</code> argument is used to 
specify which model to make predictions for. For example, if the oem object <code>oemobj</code> was fit with argument 
<code>penalty = c("lasso", "grp.lasso")</code>, then which.model = 2 provides predictions for the group lasso model.</p>
</td></tr>
<tr><td><code id="predict.oem_+3A_type">type</code></td>
<td>
<p>Type of prediction required. <code>type = "link"</code> gives the linear predictors for the <code>"binomial"</code> model; for <code>"gaussian"</code> models it gives the fitted values. 
<code>type = "response"</code> gives the fitted probabilities for <code>"binomial"</code>. <code>type = "coefficients"</code> computes the coefficients at the requested values for <code>s</code>.
<code>type = "class"</code> applies only to <code>"binomial"</code> and produces the class label corresponding to the maximum probability.</p>
</td></tr>
<tr><td><code id="predict.oem_+3A_...">...</code></td>
<td>
<p>not used</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object depending on the type argument
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(123)
n.obs &lt;- 1e4
n.vars &lt;- 100
n.obs.test &lt;- 1e3

true.beta &lt;- c(runif(15, -0.5, 0.5), rep(0, n.vars - 15))

x &lt;- matrix(rnorm(n.obs * n.vars), n.obs, n.vars)
y &lt;- rnorm(n.obs, sd = 3) + x %*% true.beta
x.test &lt;- matrix(rnorm(n.obs.test * n.vars), n.obs.test, n.vars)
y.test &lt;- rnorm(n.obs.test, sd = 3) + x.test %*% true.beta

fit &lt;- oem(x = x, y = y, 
           penalty = c("lasso", "grp.lasso"), 
           groups = rep(1:10, each = 10), 
           nlambda = 10)

preds.lasso &lt;- predict(fit, newx = x.test, type = "response", which.model = 1)
preds.grp.lasso &lt;- predict(fit, newx = x.test, type = "response", which.model = 2)

apply(preds.lasso,     2, function(x) mean((y.test - x) ^ 2))
apply(preds.grp.lasso, 2, function(x) mean((y.test - x) ^ 2))

</code></pre>

<hr>
<h2 id='predict.xval.oem'>Prediction function for fitted cross validation oem objects</h2><span id='topic+predict.xval.oem'></span>

<h3>Description</h3>

<p>Prediction function for fitted cross validation oem objects
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'xval.oem'
predict(
  object,
  newx,
  which.model = "best.model",
  s = c("lambda.min", "lambda.1se"),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.xval.oem_+3A_object">object</code></td>
<td>
<p>fitted &quot;cv.oem&quot; model object</p>
</td></tr>
<tr><td><code id="predict.xval.oem_+3A_newx">newx</code></td>
<td>
<p>Matrix of new values for x at which predictions are to be made. Must be a matrix; can be sparse as in the 
<code>CsparseMatrix</code> objects of the <span class="pkg">Matrix</span> package
This argument is not used for type=c(&quot;coefficients&quot;,&quot;nonzero&quot;)</p>
</td></tr>
<tr><td><code id="predict.xval.oem_+3A_which.model">which.model</code></td>
<td>
<p>If multiple penalties are fit and returned in the same <code>oem</code> object, the <code>which.model</code> argument is used to 
specify which model to make predictions for. For example, if the oem object &quot;oemobj&quot; was fit with argument 
<code>penalty = c("lasso", "grp.lasso")</code>, then <code>which.model = 2</code> provides predictions for the group lasso model. For 
<code>predict.cv.oem()</code>, can specify
<code>"best.model"</code> to use the best model as estimated by cross-validation</p>
</td></tr>
<tr><td><code id="predict.xval.oem_+3A_s">s</code></td>
<td>
<p>Value(s) of the penalty parameter <code>lambda</code> at which predictions are required. Default is the entire sequence used to create 
the model. For predict.cv.oem, can also specify <code>"lambda.1se"</code> or <code>"lambda.min"</code> for best lambdas estimated by cross validation</p>
</td></tr>
<tr><td><code id="predict.xval.oem_+3A_...">...</code></td>
<td>
<p>used to pass the other arguments for <code>predict.oem()</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object depending on the type argument
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(123)
n.obs &lt;- 1e4
n.vars &lt;- 100
n.obs.test &lt;- 1e3

true.beta &lt;- c(runif(15, -0.5, 0.5), rep(0, n.vars - 15))

x &lt;- matrix(rnorm(n.obs * n.vars), n.obs, n.vars)
y &lt;- rnorm(n.obs, sd = 3) + x %*% true.beta
x.test &lt;- matrix(rnorm(n.obs.test * n.vars), n.obs.test, n.vars)
y.test &lt;- rnorm(n.obs.test, sd = 3) + x.test %*% true.beta

fit &lt;- xval.oem(x = x, y = y, 
                penalty = c("lasso", "grp.lasso"), 
                groups = rep(1:10, each = 10), 
                nlambda = 10)

preds.best &lt;- predict(fit, newx = x.test, type = "response", which.model = "best.model")

apply(preds.best, 2, function(x) mean((y.test - x) ^ 2))

preds.gl &lt;- predict(fit, newx = x.test, type = "response", which.model = "grp.lasso")

apply(preds.gl, 2, function(x) mean((y.test - x) ^ 2))

preds.l &lt;- predict(fit, newx = x.test, type = "response", which.model = 1)

apply(preds.l, 2, function(x) mean((y.test - x) ^ 2))
</code></pre>

<hr>
<h2 id='print.summary.cv.oem'>print method for <code>summary.cv.oem</code> objects</h2><span id='topic+print.summary.cv.oem'></span>

<h3>Description</h3>

<p>print method for <code>summary.cv.oem</code> objects
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'summary.cv.oem'
print(x, digits, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.summary.cv.oem_+3A_x">x</code></td>
<td>
<p>a &quot;summary.cv.oem&quot; object</p>
</td></tr>
<tr><td><code id="print.summary.cv.oem_+3A_digits">digits</code></td>
<td>
<p>digits to display</p>
</td></tr>
<tr><td><code id="print.summary.cv.oem_+3A_...">...</code></td>
<td>
<p>not used</p>
</td></tr>
</table>

<hr>
<h2 id='summary.cv.oem'>summary method for cross validation Orthogonalizing EM fitted objects</h2><span id='topic+summary.cv.oem'></span><span id='topic+summary.xval.oem'></span>

<h3>Description</h3>

<p>summary method for cross validation Orthogonalizing EM fitted objects
</p>
<p>summary method for cross validation Orthogonalizing EM fitted objects
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'cv.oem'
summary(object, ...)

## S3 method for class 'xval.oem'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.cv.oem_+3A_object">object</code></td>
<td>
<p>fitted <code>"cv.oem"</code> object</p>
</td></tr>
<tr><td><code id="summary.cv.oem_+3A_...">...</code></td>
<td>
<p>not used</p>
</td></tr>
</table>

<hr>
<h2 id='xval.oem'>Fast cross validation for Orthogonalizing EM</h2><span id='topic+xval.oem'></span>

<h3>Description</h3>

<p>Fast cross validation for Orthogonalizing EM
</p>


<h3>Usage</h3>

<pre><code class='language-R'>xval.oem(
  x,
  y,
  nfolds = 10L,
  foldid = NULL,
  type.measure = c("mse", "deviance", "class", "auc", "mae"),
  ncores = -1,
  family = c("gaussian", "binomial"),
  penalty = c("elastic.net", "lasso", "ols", "mcp", "scad", "mcp.net", "scad.net",
    "grp.lasso", "grp.lasso.net", "grp.mcp", "grp.scad", "grp.mcp.net", "grp.scad.net",
    "sparse.grp.lasso"),
  weights = numeric(0),
  lambda = numeric(0),
  nlambda = 100L,
  lambda.min.ratio = NULL,
  alpha = 1,
  gamma = 3,
  tau = 0.5,
  groups = numeric(0),
  penalty.factor = NULL,
  group.weights = NULL,
  standardize = TRUE,
  intercept = TRUE,
  maxit = 500L,
  tol = 1e-07,
  irls.maxit = 100L,
  irls.tol = 0.001,
  compute.loss = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="xval.oem_+3A_x">x</code></td>
<td>
<p>input matrix of dimension n x p (sparse matrices not yet implemented). 
Each row is an observation, each column corresponds to a covariate. The xval.oem() function
is optimized for n &gt;&gt; p settings and may be very slow when p &gt; n, so please use other packages
such as <code>glmnet</code>, <code>ncvreg</code>, <code>grpreg</code>, or <code>gglasso</code> when p &gt; n or p approx n.</p>
</td></tr>
<tr><td><code id="xval.oem_+3A_y">y</code></td>
<td>
<p>numeric response vector of length <code>nobs = nrow(x)</code>.</p>
</td></tr>
<tr><td><code id="xval.oem_+3A_nfolds">nfolds</code></td>
<td>
<p>integer number of cross validation folds. 3 is the minimum number allowed. defaults to 10</p>
</td></tr>
<tr><td><code id="xval.oem_+3A_foldid">foldid</code></td>
<td>
<p>an optional vector of values between 1 and <code>nfold</code> specifying which fold each observation belongs to.</p>
</td></tr>
<tr><td><code id="xval.oem_+3A_type.measure">type.measure</code></td>
<td>
<p>measure to evaluate for cross-validation. The default is <code>type.measure = "deviance"</code>, 
which uses squared-error for gaussian models (a.k.a <code>type.measure = "mse"</code> there), deviance for logistic
regression. <code>type.measure = "class"</code> applies to <code>binomial</code> only. <code>type.measure = "auc"</code> is for two-class logistic 
regression only. <code>type.measure="mse"</code> or <code>type.measure="mae"</code> (mean absolute error) can be used by all models;
they measure the deviation from the fitted mean to the response.</p>
</td></tr>
<tr><td><code id="xval.oem_+3A_ncores">ncores</code></td>
<td>
<p>Integer scalar that specifies the number of threads to be used</p>
</td></tr>
<tr><td><code id="xval.oem_+3A_family">family</code></td>
<td>
<p><code>"gaussian"</code> for least squares problems, <code>"binomial"</code> for binary response (not implemented yet).</p>
</td></tr>
<tr><td><code id="xval.oem_+3A_penalty">penalty</code></td>
<td>
<p>Specification of penalty type. Choices include:
</p>

<ul>
<li><p><code>"elastic.net"</code> - elastic net penalty, extra parameters: <code>"alpha"</code>
</p>
</li>
<li><p><code>"lasso"</code> - lasso penalty
</p>
</li>
<li><p><code>"ols"</code> - ordinary least squares
</p>
</li>
<li><p><code>"mcp"</code> - minimax concave penalty, extra parameters: <code>"gamma"</code>
</p>
</li>
<li><p><code>"scad"</code> - smoothly clipped absolute deviation, extra parameters: <code>"gamma"</code>
</p>
</li>
<li><p><code>"mcp.net"</code> - minimax concave penalty + l2 penalty, extra parameters: 
<code>"gamma"</code>, <code>"alpha"</code>
</p>
</li>
<li><p><code>"scad.net"</code> - smoothly clipped absolute deviation + l2 penalty, extra parameters: 
<code>"gamma"</code>, <code>"alpha"</code>
</p>
</li>
<li><p><code>"grp.lasso"</code> - group lasso penalty
</p>
</li>
<li><p><code>"grp.lasso.net"</code> - group lasso penalty + l2 penalty, extra parameters: <code>"alpha"</code>
</p>
</li>
<li><p><code>"grp.mcp"</code> - group minimax concave penalty, extra parameters: <code>"gamma"</code>
</p>
</li>
<li><p><code>"grp.scad"</code> - group smoothly clipped absolute deviation, extra parameters: <code>"gamma"</code>
</p>
</li>
<li><p><code>"grp.mcp.net"</code> - group minimax concave penalty + l2 penalty, extra parameters: <code>"gamma"</code>, <code>"alpha"</code>
</p>
</li>
<li><p><code>"grp.scad.net"</code> - group smoothly clipped absolute deviation + l2 penalty, extra parameters: <code>"gamma"</code>, <code>"alpha"</code>
</p>
</li>
<li><p><code>"sparse.grp.lasso"</code> - sparse group lasso penalty (group lasso + lasso), extra parameters: <code>"tau"</code>
</p>
</li></ul>

<p>Careful consideration is required for the group lasso, group MCP, and group SCAD penalties. Groups as specified by the <code>groups</code> argument 
should be chosen in a sensible manner.</p>
</td></tr>
<tr><td><code id="xval.oem_+3A_weights">weights</code></td>
<td>
<p>observation weights. defaults to 1 for each observation (setting weight vector to 
length 0 will default all weights to 1)</p>
</td></tr>
<tr><td><code id="xval.oem_+3A_lambda">lambda</code></td>
<td>
<p>A user supplied lambda sequence. By default, the program computes
its own lambda sequence based on <code>nlambda</code> and <code>lambda.min.ratio</code>. Supplying
a value of lambda overrides this.</p>
</td></tr>
<tr><td><code id="xval.oem_+3A_nlambda">nlambda</code></td>
<td>
<p>The number of lambda values - default is 100.</p>
</td></tr>
<tr><td><code id="xval.oem_+3A_lambda.min.ratio">lambda.min.ratio</code></td>
<td>
<p>Smallest value for lambda, as a fraction of <code>lambda.max</code>, the (data derived) entry
value (i.e. the smallest value for which all coefficients are zero). The default
depends on the sample size nobs relative to the number of variables nvars. If
<code>nobs &gt; nvars</code>, the default is 0.0001, close to zero.</p>
</td></tr>
<tr><td><code id="xval.oem_+3A_alpha">alpha</code></td>
<td>
<p>mixing value for <code>elastic.net</code>, <code>mcp.net</code>, <code>scad.net</code>, <code>grp.mcp.net</code>, <code>grp.scad.net</code>. 
penalty applied is (1 - alpha) * (ridge penalty) + alpha * (lasso/mcp/mcp/grp.lasso penalty)</p>
</td></tr>
<tr><td><code id="xval.oem_+3A_gamma">gamma</code></td>
<td>
<p>tuning parameter for SCAD and MCP penalties. must be &gt;= 1</p>
</td></tr>
<tr><td><code id="xval.oem_+3A_tau">tau</code></td>
<td>
<p>mixing value for <code>sparse.grp.lasso</code>. penalty applied is (1 - tau) * (group lasso penalty) + tau * (lasso penalty)</p>
</td></tr>
<tr><td><code id="xval.oem_+3A_groups">groups</code></td>
<td>
<p>A vector of describing the grouping of the coefficients. See the example below. All unpenalized variables
should be put in group 0</p>
</td></tr>
<tr><td><code id="xval.oem_+3A_penalty.factor">penalty.factor</code></td>
<td>
<p>Separate penalty factors can be applied to each coefficient. 
This is a number that multiplies lambda to allow differential shrinkage. Can be 0 for some variables, 
which implies no shrinkage, and that variable is always included in the model. Default is 1 for all 
variables.</p>
</td></tr>
<tr><td><code id="xval.oem_+3A_group.weights">group.weights</code></td>
<td>
<p>penalty factors applied to each group for the group lasso. Similar to <code>penalty.factor</code>, 
this is a number that multiplies lambda to allow differential shrinkage. Can be 0 for some groups, 
which implies no shrinkage, and that group is always included in the model. Default is sqrt(group size) for all
groups.</p>
</td></tr>
<tr><td><code id="xval.oem_+3A_standardize">standardize</code></td>
<td>
<p>Logical flag for <code>x</code> variable standardization, prior to fitting the models. 
The coefficients are always returned on the original scale. Default is <code>standardize = TRUE</code>. If 
variables are in the same units already, you might not wish to standardize.</p>
</td></tr>
<tr><td><code id="xval.oem_+3A_intercept">intercept</code></td>
<td>
<p>Should intercept(s) be fitted (<code>default = TRUE</code>) or set to zero (<code>FALSE</code>)</p>
</td></tr>
<tr><td><code id="xval.oem_+3A_maxit">maxit</code></td>
<td>
<p>integer. Maximum number of OEM iterations</p>
</td></tr>
<tr><td><code id="xval.oem_+3A_tol">tol</code></td>
<td>
<p>convergence tolerance for OEM iterations</p>
</td></tr>
<tr><td><code id="xval.oem_+3A_irls.maxit">irls.maxit</code></td>
<td>
<p>integer. Maximum number of IRLS iterations</p>
</td></tr>
<tr><td><code id="xval.oem_+3A_irls.tol">irls.tol</code></td>
<td>
<p>convergence tolerance for IRLS iterations. Only used if <code>family != "gaussian"</code></p>
</td></tr>
<tr><td><code id="xval.oem_+3A_compute.loss">compute.loss</code></td>
<td>
<p>should the loss be computed for each estimated tuning parameter? Defaults to <code>FALSE</code>. Setting
to <code>TRUE</code> will dramatically increase computational time</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object with S3 class <code>"xval.oem"</code>
</p>


<h3>References</h3>

<p>Huling. J.D. and Chien, P. (2022), Fast Penalized Regression and Cross Validation for Tall Data with the oem Package.
Journal of Statistical Software 104(6), 1-24. doi:10.18637/jss.v104.i06
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(123)
n.obs &lt;- 1e4
n.vars &lt;- 100

true.beta &lt;- c(runif(15, -0.25, 0.25), rep(0, n.vars - 15))

x &lt;- matrix(rnorm(n.obs * n.vars), n.obs, n.vars)
y &lt;- rnorm(n.obs, sd = 3) + x %*% true.beta

system.time(fit &lt;- oem(x = x, y = y, 
                       penalty = c("lasso", "grp.lasso"), 
                       groups = rep(1:20, each = 5)))
                       
system.time(xfit &lt;- xval.oem(x = x, y = y, 
                             penalty = c("lasso", "grp.lasso"), 
                             groups = rep(1:20, each = 5)))
                             
system.time(xfit2 &lt;- xval.oem(x = x, y = y, 
                              penalty = c("lasso", "grp.lasso",
                                          "mcp",       "scad", 
                                          "mcp.net",   "scad.net",
                                          "grp.lasso", "grp.lasso.net",
                                          "grp.mcp",   "grp.scad",
                                          "sparse.grp.lasso"), 
                              groups = rep(1:20, each = 5)))

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
