<!DOCTYPE html><html><head><title>Help for package arulesCBA</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {arulesCBA}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#arulesCBA-package'><p>arulesCBA: Classification Based on Association Rules</p></a></li>
<li><a href='#CBA'><p>Classification Based on Association Rules Algorithm (CBA)</p></a></li>
<li><a href='#CBA_helpers'><p>Helper Functions For Dealing with Classes</p></a></li>
<li><a href='#CBA_ruleset'><p>Constructor for Objects for Classifiers Based on Association Rules</p></a></li>
<li><a href='#discretizeDF.supervised'><p>Supervised Methods to Convert Continuous Variables into Categorical</p>
Variables</a></li>
<li><a href='#FOIL'><p>Use FOIL to learn a rule set for classification</p></a></li>
<li><a href='#LUCS_KDD_CBA'><p>Interface to the LUCS-KDD Implementations of CMAR, PRM and CPAR</p></a></li>
<li><a href='#Lymphography'><p>The Lymphography Domain Data Set (UCI)</p></a></li>
<li><a href='#mineCARs'><p>Mine Class Association Rules</p></a></li>
<li><a href='#Mushroom'><p>The Mushroom Data Set (UCI)</p></a></li>
<li><a href='#predict.CBA'><p>Model Prediction for Classifiers Based on Association Rules</p></a></li>
<li><a href='#prepareTransactions'><p>Prepare Data for Associative Classification</p></a></li>
<li><a href='#RCAR'><p>Regularized Class Association Rules for Multi-class Problems (RCAR+)</p></a></li>
<li><a href='#RWeka_CBA'><p>CBA classifiers based on rule-based classifiers in RWeka</p></a></li>
<li><a href='#transactions2DF'><p>Convert Transactions to a Data.Frame</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Version:</td>
<td>1.2.5</td>
</tr>
<tr>
<td>Date:</td>
<td>2022-08-19</td>
</tr>
<tr>
<td>Title:</td>
<td>Classification Based on Association Rules</td>
</tr>
<tr>
<td>Description:</td>
<td>Provides the infrastructure for association rule-based classification including the algorithms 
  CBA, CMAR, CPAR, C4.5, FOIL, PART, PRM, RCAR, and RIPPER to build associative classifiers. 
  Hahsler et al (2019) &lt;<a href="https://doi.org/10.32614%2FRJ-2019-048">doi:10.32614/RJ-2019-048</a>&gt;.</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Michael Hahsler &lt;mhahsler@lyle.smu.edu&gt;</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 4.0.0), Matrix (&ge; 1.4-0), arules (&ge; 1.7-4)</td>
</tr>
<tr>
<td>Imports:</td>
<td>methods, discretization (&ge; 1.0-1), glmnet (&ge; 3.0-0)</td>
</tr>
<tr>
<td>Suggests:</td>
<td>testthat, mlbench, rJava, RWeka</td>
</tr>
<tr>
<td>SystemRequirements:</td>
<td>Java (&gt;= 8)</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/mhahsler/arulesCBA">https://github.com/mhahsler/arulesCBA</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/mhahsler/arulesCBA">https://github.com/mhahsler/arulesCBA</a></td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.1</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2022-08-19 21:29:03 UTC; hahsler</td>
</tr>
<tr>
<td>Author:</td>
<td>Michael Hahsler <a href="https://orcid.org/0000-0003-2716-1405"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cre, cph],
  Ian Johnson [aut, cph],
  Tyler Giallanza [ctb]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2022-08-19 22:10:06 UTC</td>
</tr>
</table>
<hr>
<h2 id='arulesCBA-package'>arulesCBA: Classification Based on Association Rules</h2><span id='topic+arulesCBA-package'></span>

<h3>Description</h3>

<p>Provides the infrastructure for association rule-based classification including the algorithms
CBA, CMAR, CPAR, C4.5, FOIL, PART, PRM, RCAR, and RIPPER to build associative classifiers.
Hahsler et al (2019) <a href="doi:10.32614/RJ-2019-048">doi:10.32614/RJ-2019-048</a>.
</p>


<h3>Author(s)</h3>

<p>Michael Hahsler
</p>

<hr>
<h2 id='CBA'>Classification Based on Association Rules Algorithm (CBA)</h2><span id='topic+CBA'></span><span id='topic+pruneCBA_M1'></span><span id='topic+pruneCBA_M2'></span>

<h3>Description</h3>

<p>Build a classifier based on association rules using the ranking, pruning and
classification strategy of the CBA algorithm by Liu, et al. (1998).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CBA(
  formula,
  data,
  pruning = "M1",
  parameter = NULL,
  control = NULL,
  balanceSupport = FALSE,
  disc.method = "mdlp",
  verbose = FALSE,
  ...
)

pruneCBA_M1(formula, rules, transactions, verbose = FALSE)

pruneCBA_M2(formula, rules, transactions, verbose = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CBA_+3A_formula">formula</code></td>
<td>
<p>A symbolic description of the model to be fitted. Has to be
of form <code>class ~ .</code> or <code>class ~ predictor1 + predictor2</code>.</p>
</td></tr>
<tr><td><code id="CBA_+3A_data">data</code></td>
<td>
<p><a href="arules.html#topic+transactions-class">arules::transactions</a> containing the training data or a data.frame which.
is automatically discretized and converted to transactions with <code><a href="#topic+prepareTransactions">prepareTransactions()</a></code>.</p>
</td></tr>
<tr><td><code id="CBA_+3A_pruning">pruning</code></td>
<td>
<p>Pruning strategy used: &quot;M1&quot; or &quot;M2&quot;.</p>
</td></tr>
<tr><td><code id="CBA_+3A_parameter">parameter</code>, <code id="CBA_+3A_control">control</code></td>
<td>
<p>Optional parameter and control lists for apriori.</p>
</td></tr>
<tr><td><code id="CBA_+3A_balancesupport">balanceSupport</code></td>
<td>
<p>balanceSupport parameter passed to <code><a href="#topic+mineCARs">mineCARs()</a></code> function.</p>
</td></tr>
<tr><td><code id="CBA_+3A_disc.method">disc.method</code></td>
<td>
<p>Discretization method used to discretize continuous
variables if data is a data.frame (default: <code>"mdlp"</code>). See
<code><a href="#topic+discretizeDF.supervised">discretizeDF.supervised()</a></code> for more supervised discretization
methods.</p>
</td></tr>
<tr><td><code id="CBA_+3A_verbose">verbose</code></td>
<td>
<p>Show progress?</p>
</td></tr>
<tr><td><code id="CBA_+3A_...">...</code></td>
<td>
<p>For convenience, additional parameters are used to create the
<code>parameter</code> control list for apriori (e.g., to specify the support and
confidence thresholds).</p>
</td></tr>
<tr><td><code id="CBA_+3A_rules">rules</code>, <code id="CBA_+3A_transactions">transactions</code></td>
<td>
<p>prune a set of rules using a transaction set.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Implementation the CBA algorithm with the M1 or M2 pruning strategy
introduced by Liu, et al. (1998).
</p>
<p>Candidate classification association rules (CARs) are mined with the
APRIORI algorithm but minimum support is only checked for the LHS (rule coverage)
and not the whole rule. Rules are ranked by confidence, support and
size. Then either the M1 or M2 algorithm are used to perform database
coverage pruning and default rule pruning.
</p>


<h3>Value</h3>

<p>Returns an object of class <a href="#topic+CBA">CBA</a> representing the trained classifier.
</p>


<h3>Author(s)</h3>

<p>Ian Johnson and Michael Hahsler
</p>


<h3>References</h3>

<p>Liu, B. Hsu, W. and Ma, Y (1998). Integrating Classification and
Association Rule Mining. <strong>KDD'98 Proceedings of the Fourth
International Conference on Knowledge Discovery and Data Mining,</strong> New York,
27-31 August. AAAI. pp. 80-86.
<a href="https://dl.acm.org/doi/10.5555/3000292.3000305">https://dl.acm.org/doi/10.5555/3000292.3000305</a>
</p>


<h3>See Also</h3>

<p><a href="#topic+CBA">CBA</a>, <code><a href="#topic+mineCARs">mineCARs()</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("iris")

# 1. Learn a classifier using automatic default discretization
classifier &lt;- CBA(Species ~ ., data = iris, supp = 0.05, conf = 0.9)
classifier

# inspect the rule base
inspect(classifier$rules)

# make predictions
predict(classifier, head(iris))
table(pred = predict(classifier, iris), true = iris$Species)


# 2. Learn classifier from transactions (and use verbose)
iris_trans &lt;- prepareTransactions(Species ~ ., iris, disc.method = "mdlp")
iris_trans
classifier &lt;- CBA(Species ~ ., data = iris_trans, supp = 0.05, conf = 0.9, verbose = TRUE)
classifier

# make predictions. Note: response extracts class information from transactions.
predict(classifier, head(iris_trans))
table(pred = predict(classifier, iris_trans), true = response(Species ~ ., iris_trans))
</code></pre>

<hr>
<h2 id='CBA_helpers'>Helper Functions For Dealing with Classes</h2><span id='topic+CBA_helpers'></span><span id='topic+classes'></span><span id='topic+response'></span><span id='topic+classFrequency'></span><span id='topic+majorityClass'></span><span id='topic+transactionCoverage'></span><span id='topic+uncoveredClassExamples'></span><span id='topic+uncoveredMajorityClass'></span>

<h3>Description</h3>

<p>Helper functions to extract the response from transactions or rules, determine the
class frequency, majority class, transaction coverage and the
uncovered examples per class.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>classes(formula, x)

response(formula, x)

classFrequency(formula, x, type = "relative")

majorityClass(formula, transactions)

transactionCoverage(transactions, rules)

uncoveredClassExamples(formula, transactions, rules)

uncoveredMajorityClass(formula, transactions, rules)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CBA_helpers_+3A_formula">formula</code></td>
<td>
<p>A symbolic description of the model to be fitted.</p>
</td></tr>
<tr><td><code id="CBA_helpers_+3A_x">x</code>, <code id="CBA_helpers_+3A_transactions">transactions</code></td>
<td>
<p>An object of class <a href="arules.html#topic+transactions-class">arules::transactions</a>
or <a href="arules.html#topic+rules">rules</a>.</p>
</td></tr>
<tr><td><code id="CBA_helpers_+3A_type">type</code></td>
<td>
<p><code style="white-space: pre;">&#8288;"relative" or &#8288;</code>&quot;absolute&quot;' to return proportions or
absolute counts.</p>
</td></tr>
<tr><td><code id="CBA_helpers_+3A_rules">rules</code></td>
<td>
<p>A set of <a href="arules.html#topic+rules">rules</a>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>response</code> returns the response label as a factor.
</p>
<p><code>classFrequency</code> returns the item frequency for each class label as a
vector.
</p>
<p><code>majorityClass</code> returns the most frequent class label in the
transactions.
</p>


<h3>Author(s)</h3>

<p>Michael Hahsler
</p>


<h3>See Also</h3>

<p><code><a href="arules.html#topic+itemFrequency">itemFrequency()</a></code>, <a href="arules.html#topic+rules">rules</a>, <a href="arules.html#topic+transactions-class">arules::transactions</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("iris")

iris.disc &lt;- discretizeDF.supervised(Species ~ ., iris)
iris.trans &lt;- as(iris.disc, "transactions")
inspect(head(iris.trans, n = 3))

# convert the class items back to a class label
response(Species ~ ., head(iris.trans, n = 3))

# Class labels
classes(Species ~ ., iris.trans)

# Class distribution. The iris dataset is perfectly balanced.
classFrequency(Species ~ ., iris.trans)

# Majority class
# (Note: since all class frequencies for iris are the same, the first one is returned)
majorityClass(Species ~ ., iris.trans)

# Use for CARs
cars &lt;- mineCARs(Species ~ ., iris.trans, parameter = list(support = 0.3))

#' # Class labels
classes(Species ~ ., cars)

# Number of rules for each class
classFrequency(Species ~ ., cars, type = "absolute")

# conclusion (item in the RHS) of the rule as a class label
response(Species ~ ., cars)

# How many rules (using the first three rules) cover each transactions?
transactionCoverage(iris.trans, cars[1:3])

# Number of transactions per class not covered by the first three rules
uncoveredClassExamples(Species ~ ., iris.trans, cars[1:3])

# Majority class of the uncovered examples
uncoveredMajorityClass(Species ~ ., iris.trans, cars[1:3])
</code></pre>

<hr>
<h2 id='CBA_ruleset'>Constructor for Objects for Classifiers Based on Association Rules</h2><span id='topic+CBA_ruleset'></span>

<h3>Description</h3>

<p>Objects for classifiers based on association rules have class <code>CBA</code>.
A creator function <code>CBA_ruleset()</code> and several methods are provided.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CBA_ruleset(
  formula,
  rules,
  default,
  method = "first",
  weights = NULL,
  bias = NULL,
  model = NULL,
  discretization = NULL,
  description = "Custom rule set",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CBA_ruleset_+3A_formula">formula</code></td>
<td>
<p>A symbolic description of the model to be fitted. Has to be
of form <code>class ~ .</code>. The class is the variable name (part of the item
label before <code>=</code>).</p>
</td></tr>
<tr><td><code id="CBA_ruleset_+3A_rules">rules</code></td>
<td>
<p>A set of class association rules mined with <code><a href="#topic+mineCARs">mineCARs()</a></code> or
<code><a href="arules.html#topic+apriori">apriori()</a></code> (from <span class="pkg">arules</span>).</p>
</td></tr>
<tr><td><code id="CBA_ruleset_+3A_default">default</code></td>
<td>
<p>Default class. If not specified then objects that are
not matched by rules are classified as <code>NA</code>.</p>
</td></tr>
<tr><td><code id="CBA_ruleset_+3A_method">method</code></td>
<td>
<p>Classification method <code>"first"</code> found rule or <code>"majority"</code>.</p>
</td></tr>
<tr><td><code id="CBA_ruleset_+3A_weights">weights</code></td>
<td>
<p>Rule weights for the majority voting method. Either a quality measure
available in the classification rule set or a numeric vector of the same length are
the classification rule set can be specified. If missing, then equal weights are used</p>
</td></tr>
<tr><td><code id="CBA_ruleset_+3A_bias">bias</code></td>
<td>
<p>Class bias vector.</p>
</td></tr>
<tr><td><code id="CBA_ruleset_+3A_model">model</code></td>
<td>
<p>An optional list with model information (e.g., parameters).</p>
</td></tr>
<tr><td><code id="CBA_ruleset_+3A_discretization">discretization</code></td>
<td>
<p>A list with discretization information used by <code><a href="#topic+predict">predict()</a></code> to discretize data
supplied as a <code>data.frame</code>.</p>
</td></tr>
<tr><td><code id="CBA_ruleset_+3A_description">description</code></td>
<td>
<p>Description field used when the classifier is printed.</p>
</td></tr>
<tr><td><code id="CBA_ruleset_+3A_...">...</code></td>
<td>
<p>Additional arguments added as list elements to the CBA object.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>CBA_ruleset()</code> creates a new object of class <code>CBA</code> using the
provides rules as the rule base.  For method <code>"first"</code>, the user needs
to make sure that the rules are predictive and sorted from most to least
predictive.
</p>


<h3>Value</h3>

<p>A object of class <code>CBA</code> representing the trained classifier with fields:
</p>
<table>
<tr><td><code>formula</code></td>
<td>
<p>used formula.</p>
</td></tr>
<tr><td><code>rules</code></td>
<td>
<p>the classifier rule base.</p>
</td></tr>
<tr><td><code>default</code></td>
<td>
<p>default class label (uses partial matching against the class labels).</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>classification method.</p>
</td></tr>
<tr><td><code>weights</code></td>
<td>
<p>rule weights.</p>
</td></tr>
<tr><td><code>bias</code></td>
<td>
<p>class bias vector if available.</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>list with model description.</p>
</td></tr>
<tr><td><code>discretization</code></td>
<td>
<p>discretization information.</p>
</td></tr>
<tr><td><code>description</code></td>
<td>
<p>description in human readable form.</p>
</td></tr>
</table>
<p><code>rules</code> returns the rule base.
</p>


<h3>Author(s)</h3>

<p>Michael Hahsler
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mineCARs">mineCARs()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Example 1: create a first-matching-rule classifier with non-redundant rules
##  sorted by confidence.
data("iris")

# discretize and create transactions
iris.disc &lt;- discretizeDF.supervised(Species ~., iris)
trans &lt;- as(iris.disc, "transactions")

# create rule base with CARs
cars &lt;- mineCARs(Species ~ ., trans, parameter = list(support = .01, confidence = .8))

cars &lt;- cars[!is.redundant(cars)]
cars &lt;- sort(cars, by = "conf")

# create classifier and use the majority class as the default if no rule matches.
cl &lt;- CBA_ruleset(Species ~ .,
  rules = cars,
  default = uncoveredMajorityClass(Species ~ ., trans, cars),
  method = "first")
cl

# look at the rule base
inspect(cl$rules)

# make predictions
prediction &lt;- predict(cl, trans)
table(prediction, response(Species ~ ., trans))
accuracy(prediction, response(Species ~ ., trans))

# Example 2: use weighted majority voting.
cl &lt;- CBA_ruleset(Species ~ .,
  rules = cars,
  default = uncoveredMajorityClass(Species ~ ., trans, cars),
  method = "majority", weights = "lift")
cl

prediction &lt;- predict(cl, trans)
table(prediction, response(Species ~ ., trans))
accuracy(prediction, response(Species ~ ., trans))

## Example 3: Create a classifier with no rules that always predicts
##  the majority class. Note, we need cars for the structure and subset it
##  to leave no rules.
cl &lt;- CBA_ruleset(Species ~ .,
  rules = cars[NULL],
  default = majorityClass(Species ~ ., trans))
cl

prediction &lt;- predict(cl, trans)
table(prediction, response(Species ~ ., trans))
accuracy(prediction, response(Species ~ ., trans))
</code></pre>

<hr>
<h2 id='discretizeDF.supervised'>Supervised Methods to Convert Continuous Variables into Categorical
Variables</h2><span id='topic+discretizeDF.supervised'></span><span id='topic+discretize'></span>

<h3>Description</h3>

<p>This function implements several supervised methods to convert continuous
variables into a categorical variables (factor) suitable for association
rule mining and building associative classifiers. A whole data.frame is
discretized (i.e., all numeric columns are discretized).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>discretizeDF.supervised(formula, data, method = "mdlp", dig.lab = 3, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="discretizeDF.supervised_+3A_formula">formula</code></td>
<td>
<p>a formula object to specify the class variable for supervised
discretization and the predictors to be discretized in the form
<code>class ~ .</code> or <code>class ~ predictor1 + predictor2</code>.</p>
</td></tr>
<tr><td><code id="discretizeDF.supervised_+3A_data">data</code></td>
<td>
<p>a data.frame containing continuous variables to be discretized</p>
</td></tr>
<tr><td><code id="discretizeDF.supervised_+3A_method">method</code></td>
<td>
<p>discretization method. Available are: &ldquo;&quot;mdlp&quot;<code style="white-space: pre;">&#8288;, &#8288;</code>&quot;caim&quot;', '&quot;cacc&quot;', '&quot;ameva&quot;', '&quot;chi2&quot;',
'&quot;chimerge&quot;', '&quot;extendedchi2&quot;', and '&quot;modchi2&quot;'.</p>
</td></tr>
<tr><td><code id="discretizeDF.supervised_+3A_dig.lab">dig.lab</code></td>
<td>
<p>integer; number of digits used to create labels.</p>
</td></tr>
<tr><td><code id="discretizeDF.supervised_+3A_...">...</code></td>
<td>
<p>Additional parameters are passed on to the implementation of
the chosen discretization method.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>discretizeDF.supervised()</code> only implements supervised discretization.
See <code><a href="arules.html#topic+discretizeDF">discretizeDF()</a></code> in package <span class="pkg">arules</span> for unsupervised
discretization.
</p>


<h3>Value</h3>

<p><code>discretizeDF()</code> returns a discretized data.frame. Discretized
columns have an attribute <code>"discretized:breaks"</code> indicating the used
breaks or and <code>"discretized:method"</code> giving the used method.
</p>


<h3>Author(s)</h3>

<p>Michael Hahsler
</p>


<h3>See Also</h3>

<p>Unsupervised discretization from <span class="pkg">arules</span>:
<code><a href="#topic+discretize">discretize()</a></code>, <code><a href="arules.html#topic+discretizeDF">discretizeDF()</a></code>.
</p>
<p>Details about the available supervised discretization methods from
<span class="pkg">discretization</span>:
<a href="discretization.html#topic+mdlp">discretization::mdlp</a>,
<a href="discretization.html#topic+caim">discretization::caim</a>,
<a href="discretization.html#topic+cacc">discretization::cacc</a>,
<a href="discretization.html#topic+ameva">discretization::ameva</a>,
<a href="discretization.html#topic+chi2">discretization::chi2</a>,
<a href="discretization.html#topic+chiM">discretization::chiM</a>,
<a href="discretization.html#topic+extendChi2">discretization::extendChi2</a>,
<a href="discretization.html#topic+modChi2">discretization::modChi2</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("iris")
summary(iris)

# supervised discretization using Species
iris.disc &lt;- discretizeDF.supervised(Species ~ ., iris)
summary(iris.disc)

attributes(iris.disc$Sepal.Length)

# discretize the first few instances of iris using the same breaks as iris.disc
discretizeDF(head(iris), methods = iris.disc)

# only discretize predictors Sepal.Length and Petal.Length
iris.disc2 &lt;- discretizeDF.supervised(Species ~ Sepal.Length + Petal.Length, iris)
head(iris.disc2)
</code></pre>

<hr>
<h2 id='FOIL'>Use FOIL to learn a rule set for classification</h2><span id='topic+FOIL'></span><span id='topic+foil'></span>

<h3>Description</h3>

<p>Build a classifier rule base using FOIL (First Order Inductive Learner), a
greedy algorithm that learns rules to distinguish positive from negative
examples.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>FOIL(
  formula,
  data,
  max_len = 3,
  min_gain = 0.7,
  best_k = 5,
  disc.method = "mdlp"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="FOIL_+3A_formula">formula</code></td>
<td>
<p>A symbolic description of the model to be fitted. Has to be
of form <code>class ~ .</code> or <code>class ~ predictor1 + predictor2</code>.</p>
</td></tr>
<tr><td><code id="FOIL_+3A_data">data</code></td>
<td>
<p>A data.frame or <a href="arules.html#topic+transactions-class">arules::transactions</a> containing the training data.
Data frames are automatically discretized and converted to transactions with
<code><a href="#topic+prepareTransactions">prepareTransactions()</a></code>.</p>
</td></tr>
<tr><td><code id="FOIL_+3A_max_len">max_len</code></td>
<td>
<p>maximal length of the LHS of the created rules.</p>
</td></tr>
<tr><td><code id="FOIL_+3A_min_gain">min_gain</code></td>
<td>
<p>minimal gain required to expand a rule.</p>
</td></tr>
<tr><td><code id="FOIL_+3A_best_k">best_k</code></td>
<td>
<p>use the average expected accuracy (laplace) of the best k
rules per class for prediction.</p>
</td></tr>
<tr><td><code id="FOIL_+3A_disc.method">disc.method</code></td>
<td>
<p>Discretization method used to discretize continuous
variables if data is a data.frame (default: <code>"mdlp"</code>). See
<code><a href="#topic+discretizeDF.supervised">discretizeDF.supervised()</a></code> for more supervised discretization methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Implements FOIL (Quinlan and Cameron-Jones, 1995) to learn rules and then
use them as a classifier following Xiaoxin and Han (2003).
</p>
<p>For each class, we find the positive and negative examples and learn the
rules using FOIL. Then the rules for all classes are combined and sorted by
Laplace accuracy on the training data.
</p>
<p>Following Xiaoxin and Han (2003), we classify new examples by
</p>

<ol>
<li><p> select all the rules whose bodies are satisfied by the example;
</p>
</li>
<li>
<p>from the rules select the best k rules per class (highest expected Laplace
accuracy);
</p>
</li>
<li><p> average the expected Laplace accuracy per class and choose
the class with the highest average.
</p>
</li></ol>



<h3>Value</h3>

<p>Returns an object of class <a href="#topic+CBA">CBA</a> representing the
trained classifier.
</p>


<h3>Author(s)</h3>

<p>Michael Hahsler
</p>


<h3>References</h3>

<p>Quinlan, J.R., Cameron-Jones, R.M. Induction of logic programs:
FOIL and related systems. NGCO 13, 287-312 (1995).
<a href="https://doi.org/10.1007/BF03037228">doi:10.1007/BF03037228</a>
</p>
<p>Yin, Xiaoxin and Jiawei Han. CPAR: Classification based on Predictive
Association Rules, SDM, 2003.
<a href="https://doi.org/10.1137/1.9781611972733.40">doi:10.1137/1.9781611972733.40</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("iris")

# learn a classifier using automatic default discretization
classifier &lt;- FOIL(Species ~ ., data = iris)
classifier

# inspect the rule base
inspect(classifier$rules)

# make predictions for the first few instances of iris
predict(classifier, head(iris))
</code></pre>

<hr>
<h2 id='LUCS_KDD_CBA'>Interface to the LUCS-KDD Implementations of CMAR, PRM and CPAR</h2><span id='topic+LUCS_KDD_CBA'></span><span id='topic+FOIL2'></span><span id='topic+CPAR'></span><span id='topic+PRM'></span><span id='topic+CMAR'></span>

<h3>Description</h3>

<p>Interface for the LUCS-KDD Software Library Java implementations of CMAR
(Li, Han and Pei, 2001), PRM, and CPAR (Yin and Han, 2003). <strong>Note:</strong> The
Java implementations is not part of <span class="pkg">arulesCBA</span> and
is only free for <strong>non-commercial use</strong>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>FOIL2(formula, data, best_k = 5, disc.method = "mdlp", verbose = FALSE)

CPAR(formula, data, best_k = 5, disc.method = "mdlp", verbose = FALSE)

PRM(formula, data, best_k = 5, disc.method = "mdlp", verbose = FALSE)

CMAR(
  formula,
  data,
  support = 0.1,
  confidence = 0.5,
  disc.method = "mdlp",
  verbose = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="LUCS_KDD_CBA_+3A_formula">formula</code></td>
<td>
<p>a symbolic description of the model to be fitted. Has to be
of form <code>class ~ .</code> or <code>class ~ predictor1 + predictor2</code>.</p>
</td></tr>
<tr><td><code id="LUCS_KDD_CBA_+3A_data">data</code></td>
<td>
<p>A data.frame or <a href="arules.html#topic+transactions-class">arules::transactions</a> containing the training data.
Data frames are automatically discretized and converted to transactions with
<code><a href="#topic+prepareTransactions">prepareTransactions()</a></code>.</p>
</td></tr>
<tr><td><code id="LUCS_KDD_CBA_+3A_best_k">best_k</code></td>
<td>
<p>use average expected accuracy of the best k rules
per class for prediction.</p>
</td></tr>
<tr><td><code id="LUCS_KDD_CBA_+3A_disc.method">disc.method</code></td>
<td>
<p>Discretization method used to discretize continuous
variables if data is a data.frame (default: <code>"mdlp"</code>). See
<code><a href="#topic+discretizeDF.supervised">discretizeDF.supervised()</a></code> for more supervised discretization
methods.</p>
</td></tr>
<tr><td><code id="LUCS_KDD_CBA_+3A_verbose">verbose</code></td>
<td>
<p>Show verbose output?</p>
</td></tr>
<tr><td><code id="LUCS_KDD_CBA_+3A_support">support</code>, <code id="LUCS_KDD_CBA_+3A_confidence">confidence</code></td>
<td>
<p>minimum support and minimum confidence thresholds
for CMAR (range <code class="reqn">[0, 1]</code>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p><strong>Requirement:</strong> The code needs a
<strong>JDK (Java Software Development Kit) Version 1.8 (or higher)</strong>
installation.
On some systems (Windows),
you may need to set the <code>JAVA_HOME</code> environment variable so the system
finds the compiler.
</p>
<p><strong>Memory:</strong> The memory for Java can be increased via R options. For
example: <code>options(java.parameters = "-Xmx1024m")</code>
</p>
<p><strong>Note:</strong> The implementation does not expose the min. gain parameter for
CPAR, PRM and FOIL2. It is fixed at 0.7 (the value used by Yin and Han,
2001). FOIL2 is an alternative Java implementation to the native
implementation of FOIL already provided in the <span class="pkg">arulesCBA</span>.
<a href="#topic+FOIL">FOIL</a> exposes min. gain.
</p>


<h3>Value</h3>

<p>Returns an object of class <a href="#topic+CBA">CBA</a> representing the
trained classifier.
</p>


<h3>References</h3>

<p>Li W., Han, J. and Pei, J. CMAR: Accurate and Efficient
Classification Based on Multiple Class-Association Rules, ICDM, 2001, pp.
369-376.
</p>
<p>Yin, Xiaoxin and Jiawei Han. CPAR: Classification based on Predictive
Association Rules, SDM, 2003.
<a href="https://doi.org/10.1137/1.9781611972733.40">doi:10.1137/1.9781611972733.40</a>
</p>
<p>Frans Coenen et al. The LUCS-KDD Software Library,
<a href="https://cgi.csc.liv.ac.uk/~frans/KDD/Software/">https://cgi.csc.liv.ac.uk/~frans/KDD/Software/</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># make sure you have a Java SDK Version 1.4.0+ and not a headless installation.
system("java -version")

data("iris")

# build a classifier, inspect rules and make predictions
cl &lt;- CMAR(Species ~ ., iris, support = .2, confidence = .8, verbose = TRUE)
cl

inspect(cl$rules)
predict(cl, head(iris))

cl &lt;- CPAR(Species ~ ., iris)
cl

cl &lt;- PRM(Species ~ ., iris)
cl

cl &lt;- FOIL2(Species ~ ., iris)
cl
</code></pre>

<hr>
<h2 id='Lymphography'>The Lymphography Domain Data Set (UCI)</h2><span id='topic+Lymphography'></span>

<h3>Description</h3>

<p>This is lymphography domain obtained from the University Medical Centre,
Institute of Oncology, Ljubljana, Yugoslavia. It was repeatedly used in the
machine learning literature.
</p>


<h3>Format</h3>

<p>A data frame with 147 observations on the following 19 variables.
</p>

<dl>
<dt><code>class</code></dt><dd><p>a factor with levels <code>normalfind</code> <code>metastases</code> <code>malignlymph</code> <code>fibrosis</code></p>
</dd>
<dt><code>lymphatics</code></dt><dd><p>a factor with levels <code>normal</code> <code>arched</code> <code>deformed</code> <code>displaced</code></p>
</dd>
<dt><code>blockofaffere</code></dt><dd><p>a factor with levels <code>no</code> <code>yes</code></p>
</dd>
<dt><code>bloflymphc</code></dt><dd><p>a factor with levels <code>no</code> <code>yes</code></p>
</dd>
<dt><code>bloflymphs</code></dt><dd><p>a factor with levels <code>no</code> <code>yes</code></p>
</dd>
<dt><code>bypass</code></dt><dd><p>a factor with levels <code>no</code> <code>yes</code></p>
</dd>
<dt><code>extravasates</code></dt><dd><p>a factor with levels <code>no</code> <code>yes</code></p>
</dd>
<dt><code>regenerationof</code></dt><dd><p>a factor with levels <code>no</code> <code>yes</code></p>
</dd>
<dt><code>earlyuptakein</code></dt><dd><p>a factor with levels <code>no</code> <code>yes</code></p>
</dd>
<dt><code>lymnodesdimin</code></dt><dd><p>a factor with levels <code>0</code> <code>1</code> <code>2</code> <code>3</code></p>
</dd>
<dt><code>lymnodesenlar</code></dt><dd><p>a factor with levels <code>1</code> <code>2</code> <code>3</code> <code>4</code></p>
</dd>
<dt><code>changesinlym</code></dt><dd><p>a factor with levels <code>bean</code> <code>oval</code> <code>round</code></p>
</dd>
<dt><code>defectinnode</code></dt><dd><p>a factor with levels <code>no</code> <code>lacunar</code> <code>lacmarginal</code> <code>laccentral</code></p>
</dd>
<dt><code>changesinnode</code></dt><dd><p>a factor with levels <code>no</code> <code>lacunar</code> <code>lacmargin</code> <code>laccentral</code></p>
</dd>
<dt><code>changesinstru</code></dt><dd><p>a factor with levels <code>no</code> <code>grainy</code> <code>droplike</code> <code>coarse</code> <code>diluted</code> <code>reticular</code> <code>stripped</code> <code>faint</code></p>
</dd>
<dt><code>specialforms</code></dt><dd><p>a factor with levels <code>no</code> <code>chalices</code> <code>vesicles</code></p>
</dd>
<dt><code>dislocationof</code></dt><dd><p>a factor with levels <code>no</code> <code>yes</code></p>
</dd>
<dt><code>exclusionofno</code></dt><dd><p>a factor with levels <code>no</code> <code>yes</code></p>
</dd>
<dt><code>noofnodesin</code></dt><dd><p>a factor with levels <code>0-9</code> <code>10-19</code> <code>20-29</code> <code>30-39</code> <code>40-49</code> <code>50-59</code> <code>60-69</code> <code>&gt;=70</code></p>
</dd>
</dl>



<h3>Source</h3>

<p>The data set was obtained from the UCI Machine Learning Repository
at <a href="http://archive.ics.uci.edu/ml/datasets/Lymphography">http://archive.ics.uci.edu/ml/datasets/Lymphography</a>.
</p>


<h3>References</h3>

<p>This lymphography domain was obtained from the University
Medical Centre, Institute of Oncology, Ljubljana, Yugoslavia. Thanks go to
M. Zwitter and M. Soklic for providing the data. Please include this
citation if you plan to use this database.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data("Lymphography")

summary(Lymphography)

</code></pre>

<hr>
<h2 id='mineCARs'>Mine Class Association Rules</h2><span id='topic+mineCARs'></span>

<h3>Description</h3>

<p>Class Association Rules (CARs) are association rules that have only items
with class values in the RHS as introduced for the CBA algorithm by Liu et
al., 1998.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mineCARs(
  formula,
  transactions,
  parameter = NULL,
  control = NULL,
  balanceSupport = FALSE,
  verbose = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mineCARs_+3A_formula">formula</code></td>
<td>
<p>A symbolic description of the model to be fitted.</p>
</td></tr>
<tr><td><code id="mineCARs_+3A_transactions">transactions</code></td>
<td>
<p>An object of class <a href="arules.html#topic+transactions-class">arules::transactions</a>
containing the training data.</p>
</td></tr>
<tr><td><code id="mineCARs_+3A_parameter">parameter</code>, <code id="mineCARs_+3A_control">control</code></td>
<td>
<p>Optional parameter and control lists for
<code><a href="arules.html#topic+apriori">apriori()</a></code>.</p>
</td></tr>
<tr><td><code id="mineCARs_+3A_balancesupport">balanceSupport</code></td>
<td>
<p>logical; if <code>TRUE</code>, class imbalance is
counteracted by using class specific minimum support values. Alternatively,
a support value for each class can be specified (see Details section).</p>
</td></tr>
<tr><td><code id="mineCARs_+3A_verbose">verbose</code></td>
<td>
<p>logical; report progress?</p>
</td></tr>
<tr><td><code id="mineCARs_+3A_...">...</code></td>
<td>
<p>For convenience, the mining parameters for <code><a href="arules.html#topic+apriori">apriori()</a></code> can be
specified as .... Examples are the <code>support</code> and <code>confidence</code>
thresholds, and the <code>maxlen</code> of rules.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Class association rules (CARs) are of the form
</p>
<p style="text-align: center;"><code class="reqn">P \Rightarrow c_i,</code>
</p>

<p>where the LHS <code class="reqn">P</code> is a pattern (i.e., an itemset) and <code class="reqn">c_i</code> is a
single items representing the class label.
</p>
<p><strong>Mining parameters.</strong>
Mining parameters for
<code><a href="arules.html#topic+apriori">apriori()</a></code> can be either specified as a list (or object
of <a href="arules.html#topic+ASparameter-classes">arules::APparameter</a>) as argument <code>parameter</code> or, for
convenience, as arguments in <code>...</code>.
<em>Note:</em> <code><a href="#topic+mineCARs">mineCARs()</a></code> uses
by default a minimum support of 0.1 (for the LHS of the rules via parameter
<code>originalSupport = FALSE</code>),
a minimum confidence of 0.5 and a <code>maxlen</code> (rule
length including items in the LHS and RHS) of 5.
</p>
<p><strong>Balancing minimum support.</strong>
Using a single minimum support threshold
for a highly class imbalanced dataset will lead to the problem, that
minority classes will only be presented in very few rules. To address this
issue, <code>balanceSupport = TRUE</code> can be used to adjust minimum support
for each class dependent on the prevalence of the class (i.e., the frequency
of the <code class="reqn">c_i</code> in the transactions) similar to the minimum class support
suggested for CBA by Liu et al (2000) we use
</p>
<p style="text-align: center;"><code class="reqn">minsupp_i = minsupp_t
  \frac{supp(c_i)}{max(supp(C))},</code>
</p>

<p>where <code class="reqn">max(supp(C))</code> is the support of the majority class. Therefore,
the defined minimum support is used for the majority class and then minimum
support is scaled down for classes which are less prevalent, giving them a
chance to also produce a reasonable amount of rules. In addition, a named
numerical vector with a support values for each class can be specified.
</p>


<h3>Value</h3>

<p>Returns an object of class <a href="arules.html#topic+rules">rules</a>.
</p>


<h3>Author(s)</h3>

<p>Michael Hahsler
</p>


<h3>References</h3>

<p>Liu, B. Hsu, W. and Ma, Y (1998). Integrating Classification and
Association Rule Mining. <em>KDD'98 Proceedings of the Fourth
International Conference on Knowledge Discovery and Data Mining,</em> New York,
27-31 August. AAAI. pp. 80-86.
</p>
<p>Liu B., Ma Y., Wong C.K. (2000) Improving an Association Rule Based
Classifier. In: Zighed D.A., Komorowski J., Zytkow J. (eds) <em>Principles
of Data Mining and Knowledge Discovery. PKDD 2000. Lecture Notes in Computer
Science</em>, vol 1910. Springer, Berlin, Heidelberg.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("iris")

# discretize and convert to transactions
iris.trans &lt;- prepareTransactions(Species ~ ., iris)

# mine CARs with items for "Species" in the RHS.
# Note: mineCars uses a default a minimum coverage (lhs support) of 0.1, a
#       minimum confidence of .5 and maxlen of 5
cars &lt;- mineCARs(Species ~ ., iris.trans)
inspect(head(cars))

# specify minimum support and confidence
cars &lt;- mineCARs(Species ~ ., iris.trans,
  parameter = list(support = 0.3, confidence = 0.9, maxlen = 3))
inspect(head(cars))

# for convenience this can also be written without a list for parameter using ...
cars &lt;- mineCARs(Species ~ ., iris.trans, support = 0.3, confidence = 0.9, maxlen = 3)

# restrict the predictors to items starting with "Sepal"
cars &lt;- mineCARs(Species ~ Sepal.Length + Sepal.Width, iris.trans)
inspect(cars)

# using different support for each class
cars &lt;- mineCARs(Species ~ ., iris.trans, balanceSupport = c(
  "Species=setosa" = 0.1,
  "Species=versicolor" = 0.5,
  "Species=virginica" = 0.01), confidence = 0.9)
cars

# balance support for class imbalance
data("Lymphography")
Lymphography_trans &lt;- as(Lymphography, "transactions")

classFrequency(class ~ ., Lymphography_trans)

# mining does not produce CARs for the minority classes
cars &lt;- mineCARs(class ~ ., Lymphography_trans, support = .3, maxlen = 3)
classFrequency(class ~ ., cars, type = "absolute")

# Balance support by reducing the minimum support for minority classes
cars &lt;- mineCARs(class ~ ., Lymphography_trans, support = .3, maxlen = 3,
  balanceSupport = TRUE)
classFrequency(class ~ ., cars, type = "absolute")

# Mine CARs from regular transactions (a negative class item is automatically added)
data(Groceries)
cars &lt;- mineCARs(`whole milk` ~ ., Groceries,
  balanceSupport = TRUE, support = 0.01, confidence = 0.8)
inspect(sort(cars, by = "lift"))
</code></pre>

<hr>
<h2 id='Mushroom'>The Mushroom Data Set (UCI)</h2><span id='topic+Mushroom'></span>

<h3>Description</h3>

<p>The <code>Mushroom</code> data set includes descriptions of hypothetical samples
corresponding to 23 species of gilled mushrooms in the Agaricus and Lepiota
Family.  It contains information about 8123 mushrooms.  4208 (51.8\
edible and 3916 (48.2\
features plus the class attribute (edible or not).
</p>


<h3>Format</h3>

<p>A data frame with 8123 observations on the following 23 variables.
</p>

<dl>
<dt><code>Class</code></dt><dd><p>a factor with levels <code>edible</code> <code>poisonous</code></p>
</dd>
<dt><code>CapShape</code></dt><dd><p>a factor with levels <code>bell</code> <code>conical</code> <code>flat</code> <code>knobbed</code> <code>sunken</code> <code>convex</code></p>
</dd>
<dt><code>CapSurf</code></dt><dd><p>a factor with levels <code>fibrous</code> <code>grooves</code> <code>smooth</code> <code>scaly</code></p>
</dd>
<dt><code>CapColor</code></dt><dd><p>a factor with levels <code>buff</code> <code>cinnamon</code> <code>red</code> <code>gray</code> <code>brown</code> <code>pink</code> <code>green</code> <code>purple</code> <code>white</code> <code>yellow</code></p>
</dd>
<dt><code>Bruises</code></dt><dd><p>a factor with levels <code>no</code> <code>bruises</code></p>
</dd>
<dt><code>Odor</code></dt><dd><p>a factor with levels <code>almond</code> <code>creosote</code> <code>foul</code> <code>anise</code> <code>musty</code> <code>none</code> <code>pungent</code> <code>spicy</code> <code>fishy</code></p>
</dd>
<dt><code>GillAttached</code></dt><dd><p>a factor with levels <code>attached</code> <code>free</code></p>
</dd>
<dt><code>GillSpace</code></dt><dd><p>a factor with levels <code>close</code> <code>crowded</code></p>
</dd>
<dt><code>GillSize</code></dt><dd><p>a factor with levels <code>broad</code> <code>narrow</code></p>
</dd>
<dt><code>GillColor</code></dt><dd><p>a factor with levels <code>buff</code> <code>red</code> <code>gray</code> <code>chocolate</code> <code>black</code> <code>brown</code> <code>orange</code> <code>pink</code> <code>green</code> <code>purple</code> <code>white</code> <code>yellow</code></p>
</dd>
<dt><code>StalkShape</code></dt><dd><p>a factor with levels <code>enlarging</code> <code>tapering</code></p>
</dd>
<dt><code>StalkRoot</code></dt><dd><p>a factor with levels <code>bulbous</code> <code>club</code> <code>equal</code> <code>rooted</code></p>
</dd>
<dt><code>SurfaceAboveRing</code></dt><dd><p>a factor with levels <code>fibrous</code> <code>silky</code> <code>smooth</code> <code>scaly</code></p>
</dd>
<dt><code>SurfaceBelowRing</code></dt><dd><p>a factor with levels <code>fibrous</code> <code>silky</code> <code>smooth</code> <code>scaly</code></p>
</dd>
<dt><code>ColorAboveRing</code></dt><dd><p>a factor with levels <code>buff</code> <code>cinnamon</code> <code>red</code> <code>gray</code> <code>brown</code> <code>orange</code> <code>pink</code> <code>white</code> <code>yellow</code></p>
</dd>
<dt><code>ColorBelowRing</code></dt><dd><p>a factor with levels <code>buff</code> <code>cinnamon</code> <code>red</code> <code>gray</code> <code>brown</code> <code>orange</code> <code>pink</code> <code>white</code> <code>yellow</code></p>
</dd>
<dt><code>VeilType</code></dt><dd><p>a factor with levels <code>partial</code></p>
</dd>
<dt><code>VeilColor</code></dt><dd><p>a factor with levels <code>brown</code> <code>orange</code> <code>white</code> <code>yellow</code></p>
</dd>
<dt><code>RingNumber</code></dt><dd><p>a factor with levels <code>none</code> <code>one</code> <code>two</code></p>
</dd>
<dt><code>RingType</code></dt><dd><p>a factor with levels <code>evanescent</code> <code>flaring</code> <code>large</code> <code>none</code> <code>pendant</code></p>
</dd>
<dt><code>Spore</code></dt><dd><p>a factor with levels <code>buff</code> <code>chocolate</code> <code>black</code> <code>brown</code> <code>orange</code> <code>green</code> <code>purple</code> <code>white</code> <code>yellow</code></p>
</dd>
<dt><code>Population</code></dt><dd><p>a factor with levels <code>brown</code> <code>yellow</code></p>
</dd>
<dt><code>Habitat</code></dt><dd><p>a factor with levels <code>woods</code> <code>grasses</code> <code>leaves</code> <code>meadows</code> <code>paths</code> <code>urban</code> <code>waste</code></p>
</dd>
</dl>



<h3>Source</h3>

<p>The data set was obtained from the UCI Machine Learning Repository
at <a href="http://archive.ics.uci.edu/ml/datasets/Mushroom">http://archive.ics.uci.edu/ml/datasets/Mushroom</a>.
</p>


<h3>References</h3>

<p>Alfred A. Knopf (1981). Mushroom records drawn from The Audubon
Society Field Guide to North American Mushrooms. G. H. Lincoff (Pres.), New
York.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(Mushroom)

summary(Mushroom)

</code></pre>

<hr>
<h2 id='predict.CBA'>Model Prediction for Classifiers Based on Association Rules</h2><span id='topic+predict.CBA'></span><span id='topic+predict'></span><span id='topic+accuracy'></span>

<h3>Description</h3>

<p>Predicts classes for new data using a CBA classifier.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'CBA'
predict(object, newdata, type = c("class", "score"), ...)

accuracy(pred, true)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.CBA_+3A_object">object</code></td>
<td>
<p>An object of class <a href="#topic+CBA">CBA</a>.</p>
</td></tr>
<tr><td><code id="predict.CBA_+3A_newdata">newdata</code></td>
<td>
<p>A data.frame or <a href="arules.html#topic+transactions-class">arules::transactions</a> containing rows of new entries
to be classified.</p>
</td></tr>
<tr><td><code id="predict.CBA_+3A_type">type</code></td>
<td>
<p>Predict <code>"class"</code> labels. Some classifiers can also return
<code>"scores"</code>.</p>
</td></tr>
<tr><td><code id="predict.CBA_+3A_...">...</code></td>
<td>
<p>Additional arguments are ignored.</p>
</td></tr>
<tr><td><code id="predict.CBA_+3A_pred">pred</code>, <code id="predict.CBA_+3A_true">true</code></td>
<td>
<p>two factors with the same level representing the predictions and the ground truth (e.g., obtrained with <code><a href="#topic+response">response()</a></code>).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A factor vector with the classification result.
</p>


<h3>Author(s)</h3>

<p>Michael Hahsler
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("iris")

train_id &lt;- sample(seq_len(nrow(iris)), 130)
iris_train &lt;- iris[train_id, ]
iris_test &lt;- iris[-train_id, ]

cl &lt;- CBA(Species ~., iris_train)
pr &lt;- predict(cl, iris_test)
pr

accuracy(pr, response(Species ~., iris_test))
</code></pre>

<hr>
<h2 id='prepareTransactions'>Prepare Data for Associative Classification</h2><span id='topic+prepareTransactions'></span>

<h3>Description</h3>

<p>Converts data.frame into transactions suitable for classification based on association rules.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>prepareTransactions(formula, data, disc.method = "mdlp", match = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="prepareTransactions_+3A_formula">formula</code></td>
<td>
<p>the formula.</p>
</td></tr>
<tr><td><code id="prepareTransactions_+3A_data">data</code></td>
<td>
<p>a data.frame with the data.</p>
</td></tr>
<tr><td><code id="prepareTransactions_+3A_disc.method">disc.method</code></td>
<td>
<p>Discretization method used to discretize continuous
variables if data is a data.frame (default: <code>"mdlp"</code>). See
<code><a href="#topic+discretizeDF.supervised">discretizeDF.supervised()</a></code> for more supervised discretization
methods.</p>
</td></tr>
<tr><td><code id="prepareTransactions_+3A_match">match</code></td>
<td>
<p>typically <code>NULL</code>. Only used internally if data is a
already a set of transactions.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>To convert a data.frame into items in a transaction dataset for classification,
the following steps are performed:
</p>

<ol>
<li><p> All continuous features are discretized using class-based
discretization (default is MDLP) and each range is represented as an item.
</p>
</li>
<li><p> Factors are converted into items, one item for each level.
</p>
</li>
<li><p> Each logical is converted into an item.
</p>
</li>
<li><p> If the class variable is a logical, then a negative class item is added.
</p>
</li></ol>

<p>Steps 1-3 are skipped if <code>data</code> is already as <a href="arules.html#topic+transactions-class">arules::transactions</a> object.
</p>


<h3>Value</h3>

<p>An object of class <a href="arules.html#topic+transactions-class">arules::transactions</a> from
<span class="pkg">arules</span> with an attribute called <code>"disc_info"</code> that contains
information on the used discretization for each column.
</p>


<h3>Author(s)</h3>

<p>Michael Hahsler
</p>


<h3>See Also</h3>

<p><a href="arules.html#topic+transactions-class">arules::transactions</a>, <code>transactions2DF()</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Perform discretization and convert to transactions
data("iris")
iris_trans &lt;- prepareTransactions(Species ~ ., iris)
inspect(head(iris_trans))

# A negative class item is added for regular transaction data (here "!canned beer")
# Note: backticks are needed in formulas with item labels that contain a space or special
# character.
data("Groceries")
g2 &lt;- prepareTransactions(`canned beer` ~ ., Groceries)
inspect(head(g2))
</code></pre>

<hr>
<h2 id='RCAR'>Regularized Class Association Rules for Multi-class Problems (RCAR+)</h2><span id='topic+RCAR'></span><span id='topic+rcar'></span>

<h3>Description</h3>

<p>Build a classifier based on association rules mined for an input dataset and
weighted with LASSO regularized logistic regression following RCAR (Azmi, et
al., 2019). RCAR+ extends RCAR from a binary classifier to a multi-class
classifier and can use support-balanced CARs.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RCAR(
  formula,
  data,
  lambda = NULL,
  alpha = 1,
  glmnet.args = NULL,
  cv.glmnet.args = NULL,
  parameter = NULL,
  control = NULL,
  balanceSupport = FALSE,
  disc.method = "mdlp",
  verbose = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="RCAR_+3A_formula">formula</code></td>
<td>
<p>A symbolic description of the model to be fitted. Has to be
of form <code>class ~ .</code> or <code>class ~ predictor1 + predictor2</code>.</p>
</td></tr>
<tr><td><code id="RCAR_+3A_data">data</code></td>
<td>
<p>A data.frame or <a href="arules.html#topic+transactions-class">arules::transactions</a> containing the training data.
Data frames are automatically discretized and converted to transactions with
<code><a href="#topic+prepareTransactions">prepareTransactions()</a></code>.</p>
</td></tr>
<tr><td><code id="RCAR_+3A_lambda">lambda</code></td>
<td>
<p>The amount of weight given to regularization during the
logistic regression learning process. If not specified (<code>NULL</code>) then
cross-validation is used to determine the best value (see Details section).</p>
</td></tr>
<tr><td><code id="RCAR_+3A_alpha">alpha</code></td>
<td>
<p>The elastic net mixing parameter. <code>alpha = 1</code> is the lasso
penalty (default RCAR), and <code>alpha = 0</code> the ridge penalty.</p>
</td></tr>
<tr><td><code id="RCAR_+3A_cv.glmnet.args">cv.glmnet.args</code>, <code id="RCAR_+3A_glmnet.args">glmnet.args</code></td>
<td>
<p>A list of arguments passed on to
<code><a href="glmnet.html#topic+cv.glmnet">cv.glmnet()</a></code> and <code><a href="glmnet.html#topic+glmnet">glmnet()</a></code>, respectively. See Example section.</p>
</td></tr>
<tr><td><code id="RCAR_+3A_parameter">parameter</code>, <code id="RCAR_+3A_control">control</code></td>
<td>
<p>Optional parameter and control lists for <code><a href="arules.html#topic+apriori">apriori()</a></code>.</p>
</td></tr>
<tr><td><code id="RCAR_+3A_balancesupport">balanceSupport</code></td>
<td>
<p>balanceSupport parameter passed to <code><a href="#topic+mineCARs">mineCARs()</a></code>.</p>
</td></tr>
<tr><td><code id="RCAR_+3A_disc.method">disc.method</code></td>
<td>
<p>Discretization method for factorizing numeric input
(default: <code>"mdlp"</code>). See <code><a href="#topic+discretizeDF.supervised">discretizeDF.supervised()</a></code> for more
supervised discretization methods.</p>
</td></tr>
<tr><td><code id="RCAR_+3A_verbose">verbose</code></td>
<td>
<p>Report progress?</p>
</td></tr>
<tr><td><code id="RCAR_+3A_...">...</code></td>
<td>
<p>For convenience, additional parameters are used to create the
<code>parameter</code> control list for <code><a href="arules.html#topic+apriori">apriori()</a></code> (e.g., to specify the support and
confidence thresholds).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>RCAR+ extends RCAR from a binary classifier to a multi-class classifier
using regularized multinomial logistic regression via <span class="pkg">glmnet</span>.
</p>
<p>If lambda is not specified (<code>NULL</code>) then cross-validation with the
largest value of lambda such that error is within 1 standard error of the
minimum is used to determine the best value (see <code><a href="glmnet.html#topic+cv.glmnet">cv.glmnet()</a></code> also for how to
perform cross-validation in parallel).
</p>


<h3>Value</h3>

<p>Returns an object of class <a href="#topic+CBA">CBA</a> representing the trained
classifier with the additional field <code>model</code> containing a list with the
following elements:
</p>
<table>
<tr><td><code>all_rules</code></td>
<td>
<p>all rules used to build the classifier, including the rules
with a weight of zero.</p>
</td></tr>
<tr><td><code>reg_model</code></td>
<td>
<p>them multinomial logistic
regression model as an object of class <code><a href="glmnet.html#topic+glmnet">glmnet()</a></code>.</p>
</td></tr>
<tr><td><code>cv</code></td>
<td>
<p>contains the results for the cross-validation used determine
lambda.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Tyler Giallanza and Michael Hahsler
</p>


<h3>References</h3>

<p>M. Azmi, G.C. Runger, and A. Berrado (2019). Interpretable
regularized class association rules algorithm for classification in a
categorical data space. <em>Information Sciences,</em> Volume 483, May 2019.
Pages 313-331.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("iris")

classifier &lt;- RCAR(Species~., iris)
classifier

# inspect the rule base sorted by the larges class weight
inspect(sort(classifier$rules, by = "weight"))

# make predictions for the first few instances of iris
predict(classifier, head(iris))

# inspecting the regression model, plot the regularization path, and
# plot the cross-validation results to determine lambda
str(classifier$model$reg_model)
plot(classifier$model$reg_model)
plot(classifier$model$cv)

# show progress report and use 5 instead of the default 10 cross-validation folds.
classifier &lt;- RCAR(Species~., iris, cv.glmnet.args = list(nfolds = 5), verbose = TRUE)
</code></pre>

<hr>
<h2 id='RWeka_CBA'>CBA classifiers based on rule-based classifiers in RWeka</h2><span id='topic+RWeka_CBA'></span><span id='topic+RIPPER_CBA'></span><span id='topic+PART_CBA'></span><span id='topic+C4.5_CBA'></span>

<h3>Description</h3>

<p>Provides CBA-type classifiers based on RIPPER (Cohen, 1995), C4.5 (Quinlan,
1993) and PART (Frank and Witten, 1998) using the implementation in Weka via
RWeka (Hornik et al, 2009).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RIPPER_CBA(formula, data, control = NULL, disc.method = "mdlp")

PART_CBA(formula, data, control = NULL, disc.method = "mdlp")

C4.5_CBA(formula, data, control = NULL, disc.method = "mdlp")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="RWeka_CBA_+3A_formula">formula</code></td>
<td>
<p>A symbolic description of the model to be fitted. Has to be
of form <code>class ~ .</code> or <code>class ~ predictor1 + predictor2</code>.</p>
</td></tr>
<tr><td><code id="RWeka_CBA_+3A_data">data</code></td>
<td>
<p>A data.frame or <a href="arules.html#topic+transactions-class">arules::transactions</a> containing the training data.
Data frames are automatically discretized and converted to transactions with
<code><a href="#topic+prepareTransactions">prepareTransactions()</a></code>.</p>
</td></tr>
<tr><td><code id="RWeka_CBA_+3A_control">control</code></td>
<td>
<p>algorithmic control options for R/Weka Rule learners (see
Details Section).</p>
</td></tr>
<tr><td><code id="RWeka_CBA_+3A_disc.method">disc.method</code></td>
<td>
<p>Discretization method used to discretize continuous
variables if data is a data.frame (default: <code>"mdlp"</code>). See
<code><a href="#topic+discretizeDF.supervised">discretizeDF.supervised()</a></code> for more supervised discretization
methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>You need to install package <span class="pkg">RWeka</span> to use these classifiers.
</p>
<p>See R/Weka functions
<code><a href="RWeka.html#topic+Weka_classifier_rules">RWeka::JRip()</a></code> (RIPPER),
<code><a href="RWeka.html#topic+Weka_classifier_trees">RWeka::J48()</a></code> (C4.5 rules),
<code><a href="RWeka.html#topic+Weka_classifier_rules">RWeka::PART()</a></code>
for algorithm details and how control options can be passed on via
<code>control</code>. An example is given in the Examples Section below.
</p>
<p>Memory for <span class="pkg">RWeka</span> can be increased using the R options (e.g.,
<code>options(java.parameters = "-Xmx1024m")</code>) before <span class="pkg">RWeka</span> or
<span class="pkg">rJava</span> is loaded or any RWeka-based classigier in this package is used.
</p>


<h3>Value</h3>

<p>Returns an object of class <a href="#topic+CBA">CBA</a> representing the
trained classifier.
</p>


<h3>Author(s)</h3>

<p>Michael Hahsler
</p>


<h3>References</h3>

<p>W. W. Cohen (1995). Fast effective rule induction. In A.
Prieditis and S. Russell (eds.), Proceedings of the 12th International
Conference on Machine Learning, pages 115-123. Morgan Kaufmann. ISBN
1-55860-377-8.
</p>
<p>E. Frank and I. H. Witten (1998). Generating accurate rule sets without
global optimization. In J. Shavlik (ed.), Machine Learning: Proceedings of
the Fifteenth International Conference. Morgan Kaufmann Publishers: San
Francisco, CA.
</p>
<p>R. Quinlan (1993). C4.5: Programs for Machine Learning. Morgan Kaufmann
Publishers, San Mateo, CA.
</p>
<p>Hornik K, Buchta C, Zeileis A (2009). &quot;Open-Source Machine Learning: R Meets
Weka.&quot; <em>Computational Statistics,</em> 24(2), 225-232.
<a href="https://doi.org/10.1007/s00180-008-0119-7">doi:10.1007/s00180-008-0119-7</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># rJava and RWeka need to be installed

## Not run: 
data("iris")

# learn a classifier using automatic default discretization
classifier &lt;- RIPPER_CBA(Species ~ ., data = iris)
classifier

# inspect the rule base
inspect(classifier$rules)

# make predictions for the first few instances of iris
predict(classifier, head(iris))

table(predict(classifier, iris), iris$Species)

# C4.5
classifier &lt;- C4.5_CBA(Species ~ ., iris)
inspect(classifier$rules)

# To use algorithmic options (here for PART), you need to load RWeka
library(RWeka)

# control options can be found using the Weka Option Wizard (WOW)
WOW(PART)

# build PART with control option U (Generate unpruned decision list) set to TRUE
classifier &lt;- PART_CBA(Species ~ ., data = iris, control = RWeka::Weka_control(U = TRUE))
classifier
inspect(classifier$rules)
predict(classifier, head(iris))

## End(Not run)

</code></pre>

<hr>
<h2 id='transactions2DF'>Convert Transactions to a Data.Frame</h2><span id='topic+transactions2DF'></span>

<h3>Description</h3>

<p>Convert transactions back into data.frames by combining the
items for the same variable into a single column.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>transactions2DF(transactions, itemLabels = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="transactions2DF_+3A_transactions">transactions</code></td>
<td>
<p>an object of class <a href="arules.html#topic+transactions">transactions</a>.</p>
</td></tr>
<tr><td><code id="transactions2DF_+3A_itemlabels">itemLabels</code></td>
<td>
<p>logical; use the complete item labels (variable=level) as the
levels in the data.frame? By default, only the levels are used.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a data.frame.
</p>


<h3>Author(s)</h3>

<p>Michael Hahsler
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("iris")
iris_trans &lt;- prepareTransactions(Species ~ ., iris)
iris_trans

# standard conversion
iris_df &lt;- transactions2DF(iris_trans)
head(iris_df)

# use item labels in the data.frame
iris_df2 &lt;- transactions2DF(iris_trans, itemLabels = TRUE)
head(iris_df2)

# Conversion of transactions without variables in itemInfo
data("Groceries")
head(transactions2DF(Groceries), 2)

# Conversion of transactions prepared for classification
g2 &lt;- prepareTransactions(`shopping bags` ~ ., Groceries)
head(transactions2DF(g2), 2)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
