<!DOCTYPE html><html lang="en"><head><title>Help for package mcstatsim</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {mcstatsim}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#calc_bias'><p>Calculate Bias and Bias Monte Carlo Standard Error</p></a></li>
<li><a href='#calc_coverage'><p>Calculate Coverage Probability and its Monte Carlo Standard Error</p></a></li>
<li><a href='#calc_mse'><p>Calculate Mean Squared Error and its Monte Carlo Standard Error</p></a></li>
<li><a href='#calc_rejection_rate'><p>Calculate Rejection Rate and its Monte Carlo Standard Error</p></a></li>
<li><a href='#calc_relative_bias'><p>Calculate Relative Bias and its Monte Carlo Standard Error</p></a></li>
<li><a href='#calc_relative_mse'><p>Calculate Relative Mean Squared Error and its Monte Carlo Standard Error</p></a></li>
<li><a href='#calc_relative_rmse'><p>Calculate Relative Root Mean Squared Error and its Monte Carlo Standard Error</p></a></li>
<li><a href='#calc_rmse'><p>Calculate Root Mean Squared Error and its Monte Carlo Standard Error</p></a></li>
<li><a href='#calc_variance'><p>Calculate Variance and its Monte Carlo Standard Error</p></a></li>
<li><a href='#calc_width'><p>Calculate Average Width of Confidence Intervals and its Monte Carlo Standard Error</p></a></li>
<li><a href='#combine_df'><p>Combine Dataframes in a Nested List</p></a></li>
<li><a href='#mcpmap'><p>Parallel Map Function using pbapply::pbmapply</p></a></li>
<li><a href='#runsim'><p>Run Monte Carlo Simulations in Parallel</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Monte Carlo Statistical Simulation Tools Using a Functional
Approach</td>
</tr>
<tr>
<td>Version:</td>
<td>0.5.0</td>
</tr>
<tr>
<td>Description:</td>
<td>
    A lightweight package designed to facilitate statistical 
    simulations through functional programming. It centralizes the simulation process into a single 
    higher-order function, enhancing manageability and usability without adding overhead from external 
    dependencies. The package includes ready-to-use functions for common simulation targets. A detailed example can be found on <a href="https://github.com/ielbadisy/mcstatsim">https://github.com/ielbadisy/mcstatsim</a>.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/AGPL-3">AGPL (&ge; 3)</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.1</td>
</tr>
<tr>
<td>Imports:</td>
<td>pbapply</td>
</tr>
<tr>
<td>Suggests:</td>
<td>testthat (&ge; 3.0.0)</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/ielbadisy/mcstatsim">https://github.com/ielbadisy/mcstatsim</a></td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-07-29 12:07:17 UTC; elbadisy</td>
</tr>
<tr>
<td>Author:</td>
<td>Imad EL BADISY [aut, cre, cph]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Imad EL BADISY &lt;elbadisyimad@gmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-07-29 12:30:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='calc_bias'>Calculate Bias and Bias Monte Carlo Standard Error</h2><span id='topic+calc_bias'></span>

<h3>Description</h3>

<p>This function computes the bias and the Monte Carlo Standard Error (MCSE) of the bias
for a set of estimates relative to a true parameter value. The bias is the difference
between the mean of the estimates and the true parameter. The MCSE of the bias is calculated
as the square root of the variance of the estimates divided by the number of estimates,
providing a measure of the precision of the bias estimate.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calc_bias(estimates, true_param)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="calc_bias_+3A_estimates">estimates</code></td>
<td>
<p>A numeric vector of estimates from the simulation or sampling process.</p>
</td></tr>
<tr><td><code id="calc_bias_+3A_true_param">true_param</code></td>
<td>
<p>The true parameter value that the estimates are intended to approximate.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with two components: 'bias', the calculated bias of the estimates, and 'bias_mcse',
the Monte Carlo Standard Error of the bias, indicating the uncertainty associated with the bias estimate.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>estimates &lt;- rnorm(100, mean = 50, sd = 10)
true_param &lt;- 50
bias_info &lt;- calc_bias(estimates, true_param)
print(bias_info)
</code></pre>

<hr>
<h2 id='calc_coverage'>Calculate Coverage Probability and its Monte Carlo Standard Error</h2><span id='topic+calc_coverage'></span>

<h3>Description</h3>

<p>Computes the coverage probability of a confidence interval, defined as the proportion
of times the true parameter value falls within the calculated lower and upper bounds
across a set of simulations. Additionally, calculates the Monte Carlo Standard Error (MCSE)
of the coverage probability to assess the uncertainty associated with this coverage estimate.
This function is useful for evaluating the accuracy and reliability of confidence intervals
generated by statistical models or estimation procedures.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calc_coverage(lower_bound, upper_bound, true_param)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="calc_coverage_+3A_lower_bound">lower_bound</code></td>
<td>
<p>A numeric vector of lower bounds of confidence intervals.</p>
</td></tr>
<tr><td><code id="calc_coverage_+3A_upper_bound">upper_bound</code></td>
<td>
<p>A numeric vector of upper bounds of confidence intervals, corresponding to 'lower_bound'.</p>
</td></tr>
<tr><td><code id="calc_coverage_+3A_true_param">true_param</code></td>
<td>
<p>The true parameter value that the confidence intervals are intended to estimate.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with two components: 'coverage', the calculated coverage probability of the confidence intervals,
and 'coverage_mcse', the Monte Carlo Standard Error of the coverage. This MCSE provides a measure of the precision
of the coverage probability estimate.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(123) # For reproducibility
estimates &lt;- rnorm(100, mean = 50, sd = 10)
ci_lower &lt;- estimates - 1.96 * 10
ci_upper &lt;- estimates + 1.96 * 10
true_param &lt;- 50
coverage_info &lt;- calc_coverage(ci_lower, ci_upper, true_param)
print(coverage_info)
</code></pre>

<hr>
<h2 id='calc_mse'>Calculate Mean Squared Error and its Monte Carlo Standard Error</h2><span id='topic+calc_mse'></span>

<h3>Description</h3>

<p>Computes the Mean Squared Error (MSE) of a set of estimates relative to a true parameter value,
along with the Monte Carlo Standard Error (MCSE) for the MSE. The MCSE takes into account the
variance, skewness, and kurtosis of the estimates to provide a more accurate measure of uncertainty.
This function is useful for assessing the accuracy of simulation or estimation methods by comparing
the squared deviations of estimated values from a known parameter.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calc_mse(estimates, true_param)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="calc_mse_+3A_estimates">estimates</code></td>
<td>
<p>A numeric vector of estimates from a simulation or sampling process.</p>
</td></tr>
<tr><td><code id="calc_mse_+3A_true_param">true_param</code></td>
<td>
<p>The true parameter value that the estimates are intended to approximate.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with two components: 'mse', the calculated Mean Squared Error of the estimates,
and 'mse_mcse', the Monte Carlo Standard Error of the MSE, offering insight into the reliability
of the MSE calculation.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>estimates &lt;- rnorm(100, mean = 50, sd = 10)
true_param &lt;- 50
mse_info &lt;- calc_mse(estimates, true_param)
print(mse_info)
</code></pre>

<hr>
<h2 id='calc_rejection_rate'>Calculate Rejection Rate and its Monte Carlo Standard Error</h2><span id='topic+calc_rejection_rate'></span>

<h3>Description</h3>

<p>Computes the rejection rate of hypotheses tests based on a vector of p-values and a specified
significance level (alpha). The rejection rate is the proportion of p-values that are lower than
alpha, indicating significant results. Additionally, the function calculates the Monte Carlo
Standard Error (MCSE) for the rejection rate, which quantifies the uncertainty associated with
the estimated rejection rate. This function is useful for assessing the overall type I error rate
or the power of a statistical test across multiple simulations or experimental replications.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calc_rejection_rate(p_values, alpha = 0.05)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="calc_rejection_rate_+3A_p_values">p_values</code></td>
<td>
<p>A numeric vector of p-values from multiple hypothesis tests.</p>
</td></tr>
<tr><td><code id="calc_rejection_rate_+3A_alpha">alpha</code></td>
<td>
<p>The significance level used to determine if a p-value indicates a significant result.
Default is 0.05.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with two components: 'rejection_rate', the proportion of tests that resulted in
rejection of the null hypothesis, and 'rejection_rate_mcse', the Monte Carlo Standard Error of the
rejection rate, providing an estimate of its variability.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(123) # For reproducibility
p_values &lt;- runif(100, min = 0, max = 1) # Simulated p-values
rejection_info &lt;- calc_rejection_rate(p_values)
print(rejection_info)
</code></pre>

<hr>
<h2 id='calc_relative_bias'>Calculate Relative Bias and its Monte Carlo Standard Error</h2><span id='topic+calc_relative_bias'></span>

<h3>Description</h3>

<p>Computes the relative bias of a set of estimates with respect to a true parameter value,
along with the Monte Carlo Standard Error (MCSE) of the relative bias. Relative bias is
the ratio of the mean of the estimates to the true parameter, providing a scale-independent
measure of bias. This function is particularly useful for evaluating the accuracy of estimates
in situations where the magnitude of the true parameter is crucial to the interpretation of bias.
The function gracefully handles cases where the true parameter is zero by returning 'NA' for
both relative bias and its MCSE, avoiding division by zero errors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calc_relative_bias(estimates, true_param)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="calc_relative_bias_+3A_estimates">estimates</code></td>
<td>
<p>A numeric vector of estimates from a simulation or sampling process.</p>
</td></tr>
<tr><td><code id="calc_relative_bias_+3A_true_param">true_param</code></td>
<td>
<p>The true parameter value that the estimates are intended to approximate.
Note that 'true_param' must not be zero, as relative bias calculation involves division by
the true parameter value.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with two components: 'rel_bias', the calculated relative bias of the estimates, and
'rel_bias_mcse', the Monte Carlo Standard Error of the relative bias. If 'true_param' is zero,
both 'rel_bias' and 'rel_bias_mcse' will be 'NA'.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>estimates &lt;- rnorm(100, mean = 50, sd = 10)
true_param &lt;- 50 # Non-zero true parameter
relative_bias_info &lt;- calc_relative_bias(estimates, true_param)
print(relative_bias_info)
</code></pre>

<hr>
<h2 id='calc_relative_mse'>Calculate Relative Mean Squared Error and its Monte Carlo Standard Error</h2><span id='topic+calc_relative_mse'></span>

<h3>Description</h3>

<p>Computes the Relative Mean Squared Error (Relative MSE) of a set of estimates with respect to a true
parameter value, along with the Monte Carlo Standard Error (MCSE) of the Relative MSE. The Relative
MSE is a normalized measure of error that scales the Mean Squared Error (MSE) by the square of the
true parameter value, making it particularly useful for comparing the accuracy of estimates across
different scales. The function also calculates the MCSE for the Relative MSE, taking into account the
variance, skewness, and kurtosis of the estimates to provide a measure of uncertainty. The function
returns 'NA' for both Relative MSE and its MCSE if the true parameter is zero, to avoid division by zero.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calc_relative_mse(estimates, true_param)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="calc_relative_mse_+3A_estimates">estimates</code></td>
<td>
<p>A numeric vector of estimates from a simulation or sampling process.</p>
</td></tr>
<tr><td><code id="calc_relative_mse_+3A_true_param">true_param</code></td>
<td>
<p>The true parameter value that the estimates are intended to approximate.
Note that 'true_param' must not be zero, as the calculation involves division by the true parameter value.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with two components: 'rel_mse', the calculated Relative Mean Squared Error of the estimates,
and 'rel_mse_mcse', the Monte Carlo Standard Error of the Relative MSE. If 'true_param' is zero,
both 'rel_mse' and 'rel_mse_mcse' will be 'NA'.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>estimates &lt;- rnorm(100, mean = 50, sd = 10)
true_param &lt;- 50 # Non-zero true parameter
relative_mse_info &lt;- calc_relative_mse(estimates, true_param)
print(relative_mse_info)
</code></pre>

<hr>
<h2 id='calc_relative_rmse'>Calculate Relative Root Mean Squared Error and its Monte Carlo Standard Error</h2><span id='topic+calc_relative_rmse'></span>

<h3>Description</h3>

<p>Computes the Relative Root Mean Squared Error (Relative RMSE) of a set of estimates with respect
to a true parameter value. The Relative RMSE is derived from the Relative Mean Squared Error (MSE),
providing a scale-independent measure of error that facilitates comparisons across different scales
of the true parameter. This function is especially useful for evaluating the accuracy of estimates
when the magnitude of the true parameter varies significantly across different scenarios. The function
gracefully handles cases where the true parameter is zero by returning 'NA' for both Relative RMSE
and its MCSE, to avoid division by zero. The MCSE for the Relative RMSE is not directly computed
in this function and is marked as a placeholder for future implementation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calc_relative_rmse(estimates, true_param)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="calc_relative_rmse_+3A_estimates">estimates</code></td>
<td>
<p>A numeric vector of estimates from a simulation or sampling process.</p>
</td></tr>
<tr><td><code id="calc_relative_rmse_+3A_true_param">true_param</code></td>
<td>
<p>The true parameter value that the estimates are intended to approximate.
Note that 'true_param' must not be zero, as the calculation involves division by the true parameter value.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with two components: 'rel_rmse', the calculated Relative Root Mean Squared Error of the
estimates, and 'rel_rmse_mcse', the Monte Carlo Standard Error of the Relative RMSE. The MCSE is
currently not calculated and returned as 'NA'. This is a placeholder for future implementation.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>estimates &lt;- rnorm(100, mean = 50, sd = 10)
true_param &lt;- 50 # Non-zero true parameter
relative_rmse_info &lt;- calc_relative_rmse(estimates, true_param)
print(relative_rmse_info)
</code></pre>

<hr>
<h2 id='calc_rmse'>Calculate Root Mean Squared Error and its Monte Carlo Standard Error</h2><span id='topic+calc_rmse'></span>

<h3>Description</h3>

<p>Computes the Root Mean Squared Error (RMSE) of a set of estimates relative to a true parameter value,
along with the Monte Carlo Standard Error (MCSE) for the RMSE. The RMSE is a measure of the accuracy
of the estimates, representing the square root of the average squared differences between the estimated
values and the true parameter. The MCSE for the RMSE is calculated using jackknife estimates, providing
an assessment of the uncertainty associated with the RMSE value.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calc_rmse(estimates, true_param)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="calc_rmse_+3A_estimates">estimates</code></td>
<td>
<p>A numeric vector of estimates from a simulation or sampling process.</p>
</td></tr>
<tr><td><code id="calc_rmse_+3A_true_param">true_param</code></td>
<td>
<p>The true parameter value that the estimates are intended to approximate.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with two components: 'rmse', the calculated Root Mean Squared Error of the estimates,
and 'rmse_mcse', the Monte Carlo Standard Error of the RMSE. This MCSE is derived from jackknife
estimates, offering insight into the reliability of the RMSE calculation.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>estimates &lt;- rnorm(100, mean = 50, sd = 10)
true_param &lt;- 50
rmse_info &lt;- calc_rmse(estimates, true_param)
print(rmse_info)
</code></pre>

<hr>
<h2 id='calc_variance'>Calculate Variance and its Monte Carlo Standard Error</h2><span id='topic+calc_variance'></span>

<h3>Description</h3>

<p>Computes the sample variance of a set of estimates and the Monte Carlo Standard Error (MCSE)
for the variance. The MCSE is adjusted by the sample kurtosis to account for the shape
of the distribution of the estimates. This function is particularly useful in simulation studies
where understanding the variability of an estimator and the precision of this variability estimate
is crucial.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calc_variance(estimates)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="calc_variance_+3A_estimates">estimates</code></td>
<td>
<p>A numeric vector of estimates from a simulation or sampling process.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing two elements: 'variance', the calculated sample variance of the estimates,
and 'variance_mcse', the Monte Carlo Standard Error of the variance. The MCSE provides a measure of
the uncertainty associated with the variance estimate, adjusted for kurtosis.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>estimates &lt;- rnorm(100, mean = 50, sd = 10)
variance_info &lt;- calc_variance(estimates)
print(variance_info)
</code></pre>

<hr>
<h2 id='calc_width'>Calculate Average Width of Confidence Intervals and its Monte Carlo Standard Error</h2><span id='topic+calc_width'></span>

<h3>Description</h3>

<p>This function computes the average width of a set of confidence intervals, represented by their
lower and upper bounds, along with the Monte Carlo Standard Error (MCSE) of this average width.
The average width provides insight into the precision of the estimation process, with narrower
intervals typically indicating more precise estimates. The MCSE of the width offers a measure of
the uncertainty associated with the average width calculation, useful for assessing the variability
of interval estimates across simulations or bootstrap samples.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calc_width(lower_bound, upper_bound)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="calc_width_+3A_lower_bound">lower_bound</code></td>
<td>
<p>A numeric vector of lower bounds of confidence intervals.</p>
</td></tr>
<tr><td><code id="calc_width_+3A_upper_bound">upper_bound</code></td>
<td>
<p>A numeric vector of upper bounds of confidence intervals, corresponding to 'lower_bound'.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with two components: 'width', the average width of the confidence intervals, and
'width_mcse', the Monte Carlo Standard Error of the average width. This MCSE provides a quantification
of the uncertainty in the average width estimate.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(123) # For reproducibility
estimates &lt;- rnorm(100, mean = 50, sd = 10)
ci_lower &lt;- estimates - 1.96 * 10
ci_upper &lt;- estimates + 1.96 * 10
width_info &lt;- calc_width(ci_lower, ci_upper)
print(width_info)
</code></pre>

<hr>
<h2 id='combine_df'>Combine Dataframes in a Nested List</h2><span id='topic+combine_df'></span>

<h3>Description</h3>

<p>This function combines dataframes that are nested within a list of lists into a single dataframe.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>combine_df(nested_list)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="combine_df_+3A_nested_list">nested_list</code></td>
<td>
<p>A list of lists, where each sublist contains dataframes to be combined.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function first checks if the input is a non-empty list of lists containing dataframes.
It then iterates through each sublist, combining the dataframes and adding an ID column to indicate their source.
Finally, all combined dataframes are row-bound into a single dataframe.
</p>


<h3>Value</h3>

<p>A combined dataframe where each original dataframe is augmented with an ID column indicating its source list.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>df1 &lt;- data.frame(a = 1:3, b = 4:6)
df2 &lt;- data.frame(a = 7:9, b = 10:12)
nested_list &lt;- list(list(df1, df2), list(df1, df2))
combine_df(nested_list)
</code></pre>

<hr>
<h2 id='mcpmap'>Parallel Map Function using pbapply::pbmapply</h2><span id='topic+mcpmap'></span>

<h3>Description</h3>

<p>This function applies a given function over a list of parameters in parallel using multiple cores.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mcpmap(
  lists,
  func,
  num_cores = parallel::detectCores() - 1,
  show_progress = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mcpmap_+3A_lists">lists</code></td>
<td>
<p>A list of lists containing the parameters for the function.</p>
</td></tr>
<tr><td><code id="mcpmap_+3A_func">func</code></td>
<td>
<p>The function to be applied.</p>
</td></tr>
<tr><td><code id="mcpmap_+3A_num_cores">num_cores</code></td>
<td>
<p>The number of cores to use for parallel execution. Default is one less than the total number of available cores.</p>
</td></tr>
<tr><td><code id="mcpmap_+3A_show_progress">show_progress</code></td>
<td>
<p>Logical indicating whether to display the progress bar. Default is TRUE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function ensures that all elements in the list have the same length and uses 'pbapply::pbmapply' for parallel processing.
It sets the number of cores based on the operating system and then applies the function in parallel.
</p>


<h3>Value</h3>

<p>A list of results from applying the function over the parameters.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>params &lt;- list(a = 1:3, b = 4:6)
mcpmap(params, function(a, b) a + b, num_cores = 2)
</code></pre>

<hr>
<h2 id='runsim'>Run Monte Carlo Simulations in Parallel</h2><span id='topic+runsim'></span>

<h3>Description</h3>

<p>This function executes a series of Monte Carlo simulations in parallel, providing detailed progress updates.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>runsim(
  n,
  grid_params,
  sim_func,
  show_progress = TRUE,
  num_cores = parallel::detectCores() - 1
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="runsim_+3A_n">n</code></td>
<td>
<p>The number of times the simulation function should be executed for each set of parameters. Must be a positive integer.</p>
</td></tr>
<tr><td><code id="runsim_+3A_grid_params">grid_params</code></td>
<td>
<p>A dataframe where each row corresponds to a unique combination of parameters for the simulation. Typically generated using 'expand.grid'.</p>
</td></tr>
<tr><td><code id="runsim_+3A_sim_func">sim_func</code></td>
<td>
<p>The simulation function to be applied. This function should accept parameters corresponding to a row in 'grid_params' and return a dataframe or a list that can be row-bound.</p>
</td></tr>
<tr><td><code id="runsim_+3A_show_progress">show_progress</code></td>
<td>
<p>Logical indicating whether to display progress messages during the execution of the simulations.</p>
</td></tr>
<tr><td><code id="runsim_+3A_num_cores">num_cores</code></td>
<td>
<p>The number of cores to use for parallel execution. The default is one less than the total number of cores available on the system.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function first validates the input parameters. It then uses parallel processing to apply 'sim_func' to each combination of parameters specified in 'grid_params', repeating each simulation 'n' times.
The results are combined into a single dataframe.
</p>


<h3>Value</h3>

<p>A combined dataframe of all simulation results.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(mcstatsim)

# Define a simple simulation function
sim_function &lt;- function(a, b) {
  Sys.sleep(0.1)  # Simulate a time-consuming process
  return(data.frame(result = a + b))
}

# Generate a grid of parameters
params &lt;- expand.grid(a = 1:3, b = 4:6)

# Run simulations
results &lt;- runsim(n = 1, grid_params = params, sim_func = sim_function)
print(results)

## End(Not run)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
