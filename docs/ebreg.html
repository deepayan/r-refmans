<!DOCTYPE html><html><head><title>Help for package ebreg</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {ebreg}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#ebreg'><p>Implements the empirical Bayes method in high-dimensional linear model setting for inference and prediction</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Implementation of the Empirical Bayes Method</td>
</tr>
<tr>
<td>Version:</td>
<td>0.1.3</td>
</tr>
<tr>
<td>Author:</td>
<td>Yiqi Tang, Ryan Martin</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Yiqi Tang &lt;ytang22@ncsu.edu&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Implements a Bayesian-like approach to the high-dimensional sparse linear regression problem based on an empirical or data-dependent prior distribution, which can be used for estimation/inference on the model parameters, variable selection, and prediction of a future response. The method was first presented in Martin, Ryan and Mess, Raymond and Walker, Stephen G (2017) &lt;<a href="https://doi.org/10.3150%2F15-BEJ797">doi:10.3150/15-BEJ797</a>&gt;. More details focused on the prediction problem are given in Martin, Ryan and Tang, Yiqi (2019) &lt;<a href="https://doi.org/10.48550/arXiv.1903.00961">doi:10.48550/arXiv.1903.00961</a>&gt;.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Depends:</td>
<td>lars, stats</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.1</td>
</tr>
<tr>
<td>Imports:</td>
<td>Rdpack</td>
</tr>
<tr>
<td>RdMacros:</td>
<td>Rdpack</td>
</tr>
<tr>
<td>Suggests:</td>
<td>testthat, roxygen2</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2021-05-25 22:58:36 UTC; yiqitang</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2021-05-26 13:10:06 UTC</td>
</tr>
</table>
<hr>
<h2 id='ebreg'>Implements the empirical Bayes method in high-dimensional linear model setting for inference and prediction</h2><span id='topic+ebreg'></span>

<h3>Description</h3>

<p>The function ebreg implements the method first presented in Martin, Mess, and Walker (2017) for
Bayesian inference and variable selection in the high-dimensional sparse linear regression problem.  The
chief novelty is the manner in which the prior distribution for the regression coefficients depends on data;
more details, with a focus on the prediction problem, are given in Martin and Tang (2019).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ebreg(
  y,
  X,
  XX,
  standardized = TRUE,
  alpha = 0.99,
  gam = 0.005,
  sig2,
  prior = TRUE,
  igpar = c(0.01, 4),
  log.f,
  M,
  sample.beta = FALSE,
  pred = FALSE,
  conf.level = 0.95
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ebreg_+3A_y">y</code></td>
<td>
<p>vector of response variables for regression</p>
</td></tr>
<tr><td><code id="ebreg_+3A_x">X</code></td>
<td>
<p>matrix of predictor variables</p>
</td></tr>
<tr><td><code id="ebreg_+3A_xx">XX</code></td>
<td>
<p>vector to predict outcome variable, if pred=TRUE</p>
</td></tr>
<tr><td><code id="ebreg_+3A_standardized">standardized</code></td>
<td>
<p>logical. If TRUE, the data provided has already been standardized</p>
</td></tr>
<tr><td><code id="ebreg_+3A_alpha">alpha</code></td>
<td>
<p>numeric value between 0 and 1, likelihood fraction. Default is 0.99</p>
</td></tr>
<tr><td><code id="ebreg_+3A_gam">gam</code></td>
<td>
<p>numeric value between 0 and 1, conditional prior precision parameter. Default is 0.005</p>
</td></tr>
<tr><td><code id="ebreg_+3A_sig2">sig2</code></td>
<td>
<p>numeric value for error variance. If NULL (default), variance is estimated from data</p>
</td></tr>
<tr><td><code id="ebreg_+3A_prior">prior</code></td>
<td>
<p>logical. If TRUE, a prior is used for the error variance</p>
</td></tr>
<tr><td><code id="ebreg_+3A_igpar">igpar</code></td>
<td>
<p>the parameters for the inverse gamma prior on the error variance. Default is (0.01,4)</p>
</td></tr>
<tr><td><code id="ebreg_+3A_log.f">log.f</code></td>
<td>
<p>log of the prior for the model size</p>
</td></tr>
<tr><td><code id="ebreg_+3A_m">M</code></td>
<td>
<p>integer value to indicate the Monte Carlo sample size (burn-in of size 0.2 * M automatically added)</p>
</td></tr>
<tr><td><code id="ebreg_+3A_sample.beta">sample.beta</code></td>
<td>
<p>logical. If TRUE, samples of beta are obtained</p>
</td></tr>
<tr><td><code id="ebreg_+3A_pred">pred</code></td>
<td>
<p>logical. If TRUE, predictions are obtained</p>
</td></tr>
<tr><td><code id="ebreg_+3A_conf.level">conf.level</code></td>
<td>
<p>numeric value between 0 and 1, confidence level for the marginal credible interval if sample.beta=TRUE, and for the prediction interval if pred=TRUE</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Consider the classical regression problem
</p>
<p style="text-align: center;"><code class="reqn">y = X\beta + \sigma \epsilon,</code>
</p>

<p>where <code class="reqn">y</code> is a <code class="reqn">n</code>-vector of responses, <code class="reqn">X</code> is a <code class="reqn">n \times p</code> matrix of predictor variables,
<code class="reqn">\beta</code> is a <code class="reqn">p</code>-vector of regression coefficients, <code class="reqn">\sigma &gt; 0</code> is a scale parameter, and
<code class="reqn">\epsilon</code> is a <code class="reqn">n</code>-vector of independent and identically distributed standard normal random errors.
Here we allow <code class="reqn">p \ge n</code> (or even <code class="reqn">p \gg n</code>) and accommodate the high dimensionality by assuming
<code class="reqn">\beta</code> is sparse in the sense that most of its components are zero.  The approach described in
Martin, Mess, and Walker (2017) and in Martin and Tang (2019) starts by decomposing the full <code class="reqn">\beta</code>
vector as a pair <code class="reqn">(S, \beta_S)</code> where <code class="reqn">S</code> is a subset of indices <code class="reqn">1,2,\ldots,p</code> that represents the
location of active variables and <code class="reqn">\beta_S</code> is the <code class="reqn">|S|</code>-vector of non-zero coefficients.  The approach
proceeds by specifying a prior distribution for <code class="reqn">S</code> and then a conditional prior distribution for
<code class="reqn">\beta_S</code>, given <code class="reqn">S</code>.  This latter prior distribution here is taken to depend on data, hence &quot;empirical&quot;.
A prior distribution for <code class="reqn">\sigma^2</code> can also be introduced, and this option is included in the function.
</p>


<h3>Value</h3>

<p>A list with components
</p>

<ul>
<li><p> beta - matrix with rows containing sampled beta, if sample.beta=TRUE, otherwise NULL
</p>
</li>
<li><p> beta.mean - vector containing the posterior mean of beta, if sample.beta=TRUE, otherwise NULL
</p>
</li>
<li><p> ynew - matrix containing predicted responses, if pred=TRUE, otherwise NULL
</p>
</li>
<li><p> ynew.mean - vector containing the predictions for the predictor values tested, XX, if pred=TRUE, otherwise NULL
</p>
</li>
<li><p> S - matrix with rows containing the sampled models
</p>
</li>
<li><p> incl.prob - vector containing inclusion probabilities of the predictors
</p>
</li>
<li><p> sig2 - estimated error variance, if prior=FALSE, otherwise NULL
</p>
</li>
<li><p> PI - prediction interval, confidence level specified by the user, if pred=TRUE, otherwise NULL
</p>
</li>
<li><p> CI - matrix containing marginal credible intervals, confidence level specified by the user, if sample.beta=TRUE, otherwise NULL
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Yiqi Tang
</p>
<p>Ryan Martin
</p>


<h3>References</h3>

<p>Martin R, Mess R, Walker SG (2017).
&ldquo;Empirical Bayes posterior concentration in sparse high-dimensional linear models.&rdquo;
<em>Bernoulli</em>, <b>23</b>(3), 1822&ndash;1847.
ISSN 1350-7265.
</p>
<p>Martin R, Tang Y (2019).
&ldquo;Empirical priors for prediction in sparse high-dimensional linear regression.&rdquo;
<em>arXiv preprint arXiv:1903.00961</em>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 70
p &lt;- 100
beta &lt;- rep(1, 5)
s0 &lt;- length(beta)
sig2 &lt;- 1
d &lt;- 1
log.f &lt;- function(x) -x * (log(1) + 0.05 * log(p)) + log(x &lt;= n)
X &lt;- matrix(rnorm(n * p), nrow=n, ncol=p)
X.new &lt;- matrix(rnorm(p), nrow=1, ncol=p)
y &lt;- as.numeric(X[, 1:s0] %*% beta[1:s0]) + sqrt(sig2) * rnorm(n)

o&lt;-ebreg(y, X, X.new, TRUE, .99, .005, NULL, FALSE, igpar=c(0.01, 4),
log.f, M=5000, TRUE, FALSE, .95)

incl.pr &lt;- o$incl.prob
plot(incl.pr, xlab="Variable Index", ylab="Inclusion Probability", type="h", ylim=c(0,1))

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
