<!DOCTYPE html><html><head><title>Help for package smoots</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {smoots}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#bootCast'><p>Forecasting Function for ARMA Models via Bootstrap</p></a></li>
<li><a href='#confBounds'><p>Asymptotically Unbiased Confidence Bounds</p></a></li>
<li><a href='#critMatrix'><p>ARMA Order Selection Matrix</p></a></li>
<li><a href='#dax'><p>German Stock Market Index (DAX) Financial Time Series Data</p></a></li>
<li><a href='#dsmooth'><p>Data-driven Local Polynomial for the Trend's Derivatives in Equidistant Time</p>
Series</a></li>
<li><a href='#fitted.smoots'><p>Extract Model Fitted Values</p></a></li>
<li><a href='#gdpUS'><p>Quarterly US GDP, Q1 1947 to Q2 2019</p></a></li>
<li><a href='#gsmooth'><p>Estimation of Trends and their Derivatives via Local Polynomial Regression</p></a></li>
<li><a href='#knsmooth'><p>Estimation of Nonparametric Trend Functions via Kernel Regression</p></a></li>
<li><a href='#modelCast'><p>Forecasting Function for Trend-Stationary Time Series</p></a></li>
<li><a href='#msmooth'><p>Data-driven Nonparametric Regression for the Trend in Equidistant Time</p>
Series</a></li>
<li><a href='#normCast'><p>Forecasting Function for ARMA Models under Normally Distributed Innovations</p></a></li>
<li><a href='#optOrd'><p>Optimal Order Selection</p></a></li>
<li><a href='#plot.smoots'><p>Plot Method for the Package 'smoots'</p></a></li>
<li><a href='#print.smoots'><p>Print Method for the Package 'smoots'</p></a></li>
<li><a href='#rescale'><p>Rescaling Derivative Estimates</p></a></li>
<li><a href='#residuals.smoots'><p>Extract Model Residuals</p></a></li>
<li><a href='#rollCast'><p>Backtesting Semi-ARMA Models with Rolling Forecasts</p></a></li>
<li><a href='#smoots'><p>smoots: A package for data-driven nonparametric estimation of the trend and</p>
its derivatives in equidistant time series.</a></li>
<li><a href='#tempNH'><p>Mean Monthly Northern Hemisphere Temperature Changes</p></a></li>
<li><a href='#trendCast'><p>Forecasting Function for Nonparametric Trend Functions</p></a></li>
<li><a href='#tsmooth'><p>Advanced Data-driven Nonparametric Regression for the Trend in Equidistant</p>
Time Series</a></li>
<li><a href='#vix'><p>CBOE Volatility Index (VIX) Financial Time Series Data</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Nonparametric Estimation of the Trend and Its Derivatives in TS</td>
</tr>
<tr>
<td>Version:</td>
<td>1.1.4</td>
</tr>
<tr>
<td>Description:</td>
<td>The nonparametric trend and its derivatives in equidistant time 
    series (TS) with short-memory stationary errors can be estimated. The 
    estimation is conducted via local polynomial regression using an 
    automatically selected bandwidth obtained by a built-in iterative plug-in 
    algorithm or a bandwidth fixed by the user. A Nadaraya-Watson kernel 
    smoother is also built-in as a comparison. With version 1.1.0, a linearity 
    test for the trend function, forecasting methods and backtesting 
    approaches are implemented as well.
    The smoothing methods of the package are described in Feng, Y., Gries, T., 
    and Fritz, M. (2020) &lt;<a href="https://doi.org/10.1080%2F10485252.2020.1759598">doi:10.1080/10485252.2020.1759598</a>&gt;.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>Imports:</td>
<td>stats, utils, graphics, grDevices, Rcpp (&ge; 1.0.7), future (&ge;
1.22.1), future.apply (&ge; 1.8.1), progressr (&ge; 0.8.0),
progress (&ge; 1.2.2)</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, rmarkdown, fGarch, RcppArmadillo (&ge; 0.10.6.0.0),
testthat (&ge; 3.0.0)</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp, RcppArmadillo</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 2.10)</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://wiwi.uni-paderborn.de/en/dep4/feng/">https://wiwi.uni-paderborn.de/en/dep4/feng/</a>
<a href="https://wiwi.uni-paderborn.de/dep4/gries/">https://wiwi.uni-paderborn.de/dep4/gries/</a></td>
</tr>
<tr>
<td>Acknowledgments:</td>
<td>This work was supported by the German DFG project
GZ-FE-1500-2-1.</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-09-11 08:10:03 UTC; Dominik Schulz</td>
</tr>
<tr>
<td>Author:</td>
<td>Yuanhua Feng [aut] (Paderborn University, Germany),
  Sebastian Letmathe [aut] (Paderborn University, Germany),
  Dominik Schulz [aut, cre] (Paderborn University, Germany),
  Thomas Gries [ctb] (Paderborn University, Germany),
  Marlon Fritz [ctb] (Paderborn University, Germany)</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Dominik Schulz &lt;schulzd@mail.uni-paderborn.de&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-09-11 08:50:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='bootCast'>Forecasting Function for ARMA Models via Bootstrap</h2><span id='topic+bootCast'></span>

<h3>Description</h3>

<p>Point forecasts and the respective forecasting intervals for
autoregressive-moving-average (ARMA) models can be calculated, the latter
via bootstrap, by means of this function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bootCast(
  X,
  p = NULL,
  q = NULL,
  include.mean = FALSE,
  n.start = 1000,
  h = 1,
  it = 10000,
  pb = TRUE,
  cores = future::availableCores(),
  alpha = 0.95,
  export.error = FALSE,
  plot = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bootCast_+3A_x">X</code></td>
<td>
<p>a numeric vector that contains the time series that is assumed to
follow an ARMA model ordered from past to present.</p>
</td></tr>
<tr><td><code id="bootCast_+3A_p">p</code></td>
<td>
<p>an integer value <code class="reqn">\geq 0</code> that defines the AR order
<code class="reqn">p</code> of the underlying ARMA(<code class="reqn">p,q</code>) model within <code>X</code>; is set to
<code>NULL</code> by default; if no value is passed to <code>p</code> but one is passed
to <code>q</code>, <code>p</code> is set to <code>0</code>; if both <code>p</code> and <code>q</code> are
<code>NULL</code>, optimal orders following the BIC for
<code class="reqn">0 \leq p,q \leq 5</code> are chosen; is set to <code>NULL</code> by
default; decimal numbers will be rounded off to integers.</p>
</td></tr>
<tr><td><code id="bootCast_+3A_q">q</code></td>
<td>
<p>an integer value <code class="reqn">\geq 0</code> that defines the MA order
<code class="reqn">q</code> of the underlying ARMA(<code class="reqn">p,q</code>) model within <code>X</code>; is set to
<code>NULL</code> by default; if no value is passed to <code>q</code> but one is passed
to <code>p</code>, <code>q</code> is set to <code>0</code>; if both <code>p</code> and <code>q</code> are
<code>NULL</code>, optimal orders following the BIC for
<code class="reqn">0 \leq p,q \leq 5</code> are chosen; is set to <code>NULL</code> by
default; decimal numbers will be rounded off to integers.</p>
</td></tr>
<tr><td><code id="bootCast_+3A_include.mean">include.mean</code></td>
<td>
<p>a logical value; if set to <code>TRUE</code>, the mean of the
series is also also estimated; if set to <code>FALSE</code>, <code class="reqn">E(X_t) = 0</code> is
assumed; is set to <code>FALSE</code> by default.</p>
</td></tr>
<tr><td><code id="bootCast_+3A_n.start">n.start</code></td>
<td>
<p>an integer that defines the 'burn-in' number
of observations for the simulated ARMA series via bootstrap; is set to
<code>1000</code> by default; decimal numbers will be rounded off to integers.</p>
</td></tr>
<tr><td><code id="bootCast_+3A_h">h</code></td>
<td>
<p>an integer that represents the forecasting horizon; if <code class="reqn">n</code> is
the number of observations, point forecasts and forecasting intervals will be
obtained for the time points <code class="reqn">n + 1</code> to <code class="reqn">n + h</code>; is set to
<code>h = 1</code> by default; decimal numbers will be rounded off to integers.</p>
</td></tr>
<tr><td><code id="bootCast_+3A_it">it</code></td>
<td>
<p>an integer that represents the total number of iterations, i.e.,
the number of simulated series; is set to <code>10000</code> by default; decimal
numbers will be rounded off to integers.</p>
</td></tr>
<tr><td><code id="bootCast_+3A_pb">pb</code></td>
<td>
<p>a logical value; for <code>pb = TRUE</code>, a progress bar will be shown
in the console.</p>
</td></tr>
<tr><td><code id="bootCast_+3A_cores">cores</code></td>
<td>
<p>an integer value &gt;0 that states the number of (logical) cores to
use in the bootstrap (or <code>NULL</code>); the default is the maximum number of
available cores
(via <code><a href="future.html#topic+availableCores">future::availableCores</a></code>); for
<code>cores = NULL</code>, parallel computation is disabled.</p>
</td></tr>
<tr><td><code id="bootCast_+3A_alpha">alpha</code></td>
<td>
<p>a numeric vector of length 1 with <code class="reqn">0 &lt; </code> <code>alpha</code>
<code class="reqn"> &lt; 1</code>; the forecasting intervals will be obtained based on the
confidence level (<code class="reqn">100</code><code>alpha</code>)-percent; is set to
<code>alpha = 0.95</code> by default, i.e., a <code class="reqn">95</code>-percent confidence level.</p>
</td></tr>
<tr><td><code id="bootCast_+3A_export.error">export.error</code></td>
<td>
<p>a single logical value; if the argument is set to
<code>TRUE</code>, a list is returned instead of a matrix (<code>FALSE</code>); the
first element of the list is the usual forecasting matrix, whereas the second
element is a matrix with <code>h</code> columns, where each column represents
the calculated forecasting errors for the respective future time point
<code class="reqn">n + 1, n + 2, ..., n + h</code>; is set to <code>FALSE</code> by default.</p>
</td></tr>
<tr><td><code id="bootCast_+3A_plot">plot</code></td>
<td>
<p>a logical value that controls the graphical output; for
<code>plot = TRUE</code>, the original series with the obtained point forecasts
as well as the forecasting intervals will be plotted; for the default
<code>plot = FALSE</code>, no plot will be created.</p>
</td></tr>
<tr><td><code id="bootCast_+3A_...">...</code></td>
<td>
<p>additional arguments for the standard plot function, e.g.,
<code>xlim</code>, <code>type</code>, ... ; arguments with respect to plotted graphs,
e.g., the argument <code>col</code>, only affect the original series <code>X</code>;
please note that in accordance with the argument <code>x</code> (lower case) of the
standard plot function, an additional numeric vector with time points can be
implemented via the argument <code>x</code> (lower case). <code>x</code> should be
valid for the sample observations only, i.e.
<code>length(x) == length(X)</code> should be <code>TRUE</code>, as future time
points will be calculated automatically.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is part of the <code>smoots</code> package and was implemented under
version 1.1.0. For a given time series <code class="reqn">X_t</code>, <code class="reqn">t = 1, 2, ..., n</code>,
the point forecasts and the respective forecasting intervals will be
calculated. It is assumed that the series follows an ARMA(<code class="reqn">p,q</code>) model
</p>
<p style="text-align: center;"><code class="reqn">X_t - \mu = \epsilon_t + \beta_1 (X_{t-1} - \mu) + ... + \beta_p
(X_{t-p} - \mu) + \alpha_1 \epsilon_{t-1} + ... + \alpha_{q}
\epsilon_{t-q},</code>
</p>

<p>where <code class="reqn">\alpha_j</code> and <code class="reqn">\beta_i</code> are real
numbers (for <code class="reqn">i = 1, 2, .., p</code> and <code class="reqn">j = 1, 2, ..., q</code>) and
<code class="reqn">\epsilon_t</code> are i.i.d. (identically and independently
distributed) random variables with zero mean and constant variance.
<code class="reqn">\mu</code> is equal to <code class="reqn">E(X_t)</code>.
</p>
<p>The point forecasts and forecasting intervals for the future periods
<code class="reqn">n + 1, n + 2, ..., n + h</code> will be obtained. With respect to the point
forecasts <code class="reqn">\hat{X}_{n + k}</code>, where <code class="reqn">k = 1, 2, ..., h</code>,
</p>
<p style="text-align: center;"><code class="reqn">\hat{X}_{n + k} = \hat{\mu} + \sum_{i = 1}^{p} \hat{\beta}_{i}
(X_{n + k - i} - \hat{\mu}) + \sum_{j = 1}^{q} \hat{\alpha}_{j}
\hat{\epsilon}_{n + k - j}</code>
</p>

<p>with <code class="reqn">X_{n+k-i} = \hat{X}_{n+k-i}</code> for
<code class="reqn">n+k-i &gt; n</code> and
<code class="reqn">\hat{\epsilon}_{n+k-j} = E(\epsilon_t) = 0</code> for <code class="reqn">n+k-j &gt; n</code> will be applied.
</p>
<p>The forecasting intervals on the other hand are obtained by a forward
bootstrap method that was introduced by Pan and Politis (2016) for
autoregressive models and extended by Lu and Wang (2020) for applications to
autoregressive-moving-average models.
For this purpose, let <code class="reqn">l</code> be the number of the current bootstrap
iteration. Based on the demeaned residuals of the initial ARMA estimation,
different innovation series <code class="reqn">\epsilon_{l,t}^{s}</code> will
be sampled.  The initial coefficient estimates and the sampled innovation
series are then used to simulate a variety of series
<code class="reqn">X_{l,t}^{s}</code>, from which again coefficient estimates will
be obtained. With these newly obtained estimates, proxy residual series
<code class="reqn">\hat{\epsilon}_{l,t}^{s}</code> are calculated for
the original series <code class="reqn">X_t</code>. Subsequently, point forecasts for the
time points <code class="reqn">n + 1</code> to <code class="reqn">n + h</code> are obtained for each iteration
<code class="reqn">l</code> based on the original series <code class="reqn">X_t</code>, the newly obtained
coefficient forecasts and the proxy residual series
<code class="reqn">\epsilon_{l,t}^{s}</code>.
Simultaneously, &quot;true&quot; forecasts, i.e., true future observations, are
simulated. Within each iteration, the difference between the simulated true
forecast and the bootstrapped point forecast is calculated and saved for each
future time point <code class="reqn">n + 1</code> to <code class="reqn">n + h</code>. The result for these time
points are simulated empirical values of the forecasting error. Denote by
<code class="reqn">q_k(.)</code> the quantile of the empirical distribution for the
future time point <code class="reqn">n + k</code>. Given a predefined confidence level
<code>alpha</code>, define <code class="reqn">\alpha_s = (1 -</code> <code>alpha</code><code class="reqn">)/2</code>. The
bootstrapped forecasting interval is then
</p>
<p style="text-align: center;"><code class="reqn">[\hat{X}_{n + k} + q_k(\alpha_s), \hat{X}_{n + k} + q_k(1 -
\alpha_s)],</code>
</p>

<p>i.e., the forecasting intervals are given by the sum of the respective point
forecasts and quantiles of the respective bootstrapped forecasting error
distributions.
</p>
<p>The function <code>bootCast</code> allows for different adjustments to
the forecasting progress. At first, a vector with the values of the observed
time series ordered from past to present has to be passed to the argument
<code>X</code>. Orders <code class="reqn">p</code> and <code class="reqn">q</code> of the underlying ARMA process can be
defined via the arguments <code>p</code> and <code>q</code>. If only one of these orders
is inserted by the user, the other order is automatically set to <code>0</code>. If
none of these arguments are defined, the function will choose orders based on
the Bayesian Information Criterion (BIC) for
<code class="reqn">0 \leq p,q \leq 5</code>. Via the logical argument
<code>include.mean</code> the user can decide, whether to consider the mean of the
series within the estimation process. By means of <code>n.start</code>, the number
of &quot;burn-in&quot; observations for the simulated ARMA processes can be regulated.
These observations are usually used for the processes to build up and then
omitted. Furthermore, the argument <code>h</code> allows for the definition of the
maximum future time point <code class="reqn">n + h</code>. Point forecasts and forecasting
intervals will be returned for the time points <code class="reqn">n + 1</code> to <code class="reqn">n + h</code>.
<code>it</code> corresponds to the number of bootstrap iterations. We recommend a
sufficiently high number of repetitions for maximum accuracy of the results.
Another argument is <code>alpha</code>, which is the equivalent of the confidence
level considered within the calculation of the forecasting intervals, i.e.,
the quantiles <code class="reqn">(1 - </code> <code>alpha</code><code class="reqn">)/2</code> and <code class="reqn">1 - (1 - </code>
<code>alpha</code><code class="reqn">)/2</code> of the bootstrapped forecasting error distribution
will be obtained.
</p>
<p>Since this bootstrap approach needs a lot of computation time, especially for
series with high numbers of observations and when fitting models with many
parameters, parallel computation of the bootstrap iterations is enabled.
With <code>cores</code>, the number of cores can be defined with an integer.
Nonetheless, for <code>cores = NULL</code>, no cluster is created and therefore
the parallel computation is disabled. Note that the bootstrapped results are
fully reproducible for all cluster sizes. The progress of the bootstrap can
be observed in the R console, where a progress bar and the estimated
remaining time are displayed for <code>pb = TRUE</code>.
</p>
<p>If the argument <code>export.error</code> is set to <code>TRUE</code>, the output of
the function is a list instead of a matrix with additional information on
the simulated forecasting errors. For more information see the section
<em>Value</em>.
</p>
<p>For simplicity, the function also incorporates the possibility to directly
create a plot of the output, if the argument <code>plot</code> is set to
<code>TRUE</code>. By the additional and optional arguments <code>...</code>, further
arguments of the standard plot function can be implemented to shape the
returned plot.
</p>
<p>NOTE:
</p>
<p>Within this function, the <code><a href="stats.html#topic+arima">arima</a></code> function of the
<code>stats</code> package with its method <code>"CSS-ML"</code> is used throughout
for the estimation of ARMA models. Furthermore, to increase the performance,
C++ code via the <code><a href="Rcpp.html#topic+Rcpp-package">Rcpp</a></code> and
<code><a href="RcppArmadillo.html#topic+RcppArmadillo-package">RcppArmadillo</a></code> packages was
implemented. Also, the <code><a href="future.html#topic+multisession">future</a></code> and
<code><a href="future.apply.html#topic+future.apply-package">future.apply</a></code> packages are
considered for parallel computation of bootstrap iterations. The progress
of the bootstrap is shown via the
<code><a href="progressr.html#topic+progressr-package">progressr</a></code> package.
</p>


<h3>Value</h3>

<p>The function returns a <code class="reqn">3</code> by <code class="reqn">h</code> matrix with its columns
representing the future time points and the point forecasts, the lower
bounds of the forecasting intervals and the upper bounds of the
forecasting intervals as the rows. If the argument <code>plot</code> is set to
<code>TRUE</code>, a plot of the forecasting results is created.
</p>
<p>If <code>export.error = TRUE</code> is selected, a list with the following
elements is returned instead.
</p>

<dl>
<dt>fcast</dt><dd><p>the <code class="reqn">3</code> by <code class="reqn">h</code> matrix forecasting matrix with point
forecasts and bounds of the forecasting intervals.</p>
</dd>
<dt>error</dt><dd><p>a <code>it</code> by <code class="reqn">h</code> matrix, where each column represents a
future time point <code class="reqn">n + 1, n + 2, ..., n + h</code>; in each column the
respective <code>it</code> simulated forecasting errors are saved.</p>
</dd>
</dl>



<h3>Author(s)</h3>


<ul>
<li><p> Dominik Schulz (Research Assistant) (Department of Economics, Paderborn
University), <br />
Package Creator and Maintainer
</p>
</li></ul>



<h3>References</h3>

<p>Feng, Y., Gries, T. and Fritz, M. (2020). Data-driven
local polynomial for the trend and its derivatives in economic time
series. Journal of Nonparametric Statistics, 32:2, 510-533.
</p>
<p>Feng, Y., Gries, T., Letmathe, S. and Schulz, D. (2019). The smoots package
in R for semiparametric modeling of trend stationary time series. Discussion
Paper. Paderborn University. Unpublished.
</p>
<p>Feng, Y., Gries, T., Fritz, M., Letmathe, S. and Schulz, D. (2020).
Diagnosing the trend and bootstrapping the forecasting intervals using a
semiparametric ARMA. Discussion Paper. Paderborn University. Unpublished.
</p>
<p>Lu, X., and Wang, L. (2020). Bootstrap prediction interval for ARMA models
with unknown orders. REVSTAT–Statistical Journal, 18:3, 375-396.
</p>
<p>Pan, L. and Politis, D. N. (2016). Bootstrap prediction intervals for linear,
nonlinear and nonparametric autoregressions. In: Journal of Statistical
Planning and Inference 177, pp. 1-27.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>### Example 1: Simulated ARMA process ###

# Function for drawing from a demeaned chi-squared distribution
rchisq0 &lt;- function(n, df, npc = 0) {
 rchisq(n, df, npc) - df
}

# Simulation of the underlying process
n &lt;- 2000
n.start = 1000
set.seed(23)
X &lt;- arima.sim(model = list(ar = c(1.2, -0.7), ma = 0.63), n = n,
 rand.gen = rchisq0, n.start = n.start, df = 3) + 13.1

# Quick application with low number of iterations
# (not recommended in practice)
result &lt;- bootCast(X = X, p = 2, q = 1, include.mean = TRUE,
 n.start = n.start, h = 5, it = 10, cores = 2, plot = TRUE,
 lty = 3, col = "forestgreen", xlim = c(1950, 2005), type = "b",
 main = "Exemplary title", pch = "*")
result

### Example 2: Application with more iterations ###
## Not run: 
result2 &lt;- bootCast(X = X, p = 2, q = 1, include.mean = TRUE,
 n.start = n.start, h = 5, it = 10000, cores = 2, plot = TRUE,
 lty = 3, col = "forestgreen", xlim = c(1950, 2005),
 main = "Exemplary title")
result2


## End(Not run)
</code></pre>

<hr>
<h2 id='confBounds'>Asymptotically Unbiased Confidence Bounds</h2><span id='topic+confBounds'></span>

<h3>Description</h3>

<p>Asymptotically Unbiased Confidence Bounds
</p>


<h3>Usage</h3>

<pre><code class='language-R'>confBounds(
  obj,
  alpha = 0.95,
  p = c(0, 1, 2, 3),
  plot = TRUE,
  showPar = TRUE,
  rescale = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="confBounds_+3A_obj">obj</code></td>
<td>
<p>an object returned by either <code><a href="#topic+msmooth">msmooth</a></code>,
<code><a href="#topic+tsmooth">tsmooth</a></code> or <code><a href="#topic+dsmooth">dsmooth</a></code>.</p>
</td></tr>
<tr><td><code id="confBounds_+3A_alpha">alpha</code></td>
<td>
<p>the confidence level; a single numeric value between <code>0</code>
and <code>1</code>; <code>0.95</code> is the default.</p>
</td></tr>
<tr><td><code id="confBounds_+3A_p">p</code></td>
<td>
<p>the order of polynomial used for the parametric polynomial
regression that is conducted as a benchmark for the trend function;
must satisfy <code class="reqn">0 \leq</code> <code>p</code> <code class="reqn">\leq 3</code>; set to
<code>1</code> by default; is irrelevant, if a derivative of the trend of order
greater than zero is being analyzed.</p>
</td></tr>
<tr><td><code id="confBounds_+3A_plot">plot</code></td>
<td>
<p>a logical value; for <code>plot = TRUE</code>, the default, a plot is
created.</p>
</td></tr>
<tr><td><code id="confBounds_+3A_showpar">showPar</code></td>
<td>
<p>set to <code>TRUE</code>, if the parametric fitted values are to be
shown against the unbiased estimates and the confidence bounds for
<code>plot = TRUE</code>; the default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="confBounds_+3A_rescale">rescale</code></td>
<td>
<p>a single logical value; is set to <code>TRUE</code> by default;
if the output of a derivative estimation process is passed to <code>obj</code> and
if <code>rescale = TRUE</code>, the estimates and confidence bounds will be
rescaled according to <code>x</code> for the plot (see also the details on the
parameter <em>...</em>); the numerical output stays unchanged.</p>
</td></tr>
<tr><td><code id="confBounds_+3A_...">...</code></td>
<td>
<p>further arguments that can be passed to the <code>plot</code> function;
if an argument <code>x</code> with time points is not given by the user,
<code>x = 1:length(obj$ye)</code> is used per default for the observation time
points.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is part of the <code>smoots</code> package and was implemented under
version 1.1.0. The underlying theory is based on the additive nonparametric
regression function
</p>
<p style="text-align: center;"><code class="reqn">y_t = m(x_t) + \epsilon_t,</code>
</p>

<p>where <code class="reqn">y_t</code> is the observed time series, <code class="reqn">x_t</code> is the rescaled time
on the interval <code class="reqn">[0, 1]</code>, <code class="reqn">m(x_t)</code> is a smooth trend function and
<code class="reqn">\epsilon_t</code> are stationary errors with <code class="reqn">E(\epsilon_t) = 0</code> and
short-range dependence.
</p>
<p>The purpose of this function is the estimation of reasonable confidence
intervals for the nonparametric trend function and its derivatives. The
optimal bandwidth minimizes the Asymptotic Mean Integrated Squared Error
(AMISE) criterion, however, local polynomial estimates are (usually) biased.
The bias is then (approximately)
</p>
<p style="text-align: center;"><code class="reqn">\frac{h^{k - v} m^{(k)}(x) \beta_{(\nu, k)}}{k!},</code>
</p>

<p>where <code class="reqn">p</code> is the order of the local polynomials, <code class="reqn">k = p + 1</code> is the
order of the asymptotically equivalent kernel, <code class="reqn">\nu</code> is the order of the
of the trend function's derivative, <code class="reqn">m^(v)</code> is the <code class="reqn">\nu</code>-th order
derivative of the trend function and <code class="reqn">\beta_{(\nu, k)} = \int_{-1}^{1}
u^k K_{(\nu, k)}(u) du</code>.
<code class="reqn">K_{(\nu, k)}(u)</code> is the <code class="reqn">k</code>-th order asymptotically
equivalent kernel function for estimating <code class="reqn">m^{(\nu)}</code>.
A renewed estimation with an adjusted bandwidth
<code class="reqn">h_{ub} = o(n^{-1 / (2k + 1)})</code>, i.e., a
bandwidth with a smaller order than the optimal bandwidth, is conducted.
<code class="reqn">h = h_{A}^{(2k + 1) / (2k)}</code>, where
<code class="reqn">h_{A}</code> is the optimal bandwidth, is implemented.
</p>
<p>Following this idea, we have that
</p>
<p style="text-align: center;"><code class="reqn">\sqrt{nh}[m^{(\nu)}(x) - \hat{m}^{(\nu)}(x)]</code>
</p>

<p>converges to
</p>
<p style="text-align: center;"><code class="reqn">N(0,2\pi c_f R(x))</code>
</p>

<p>in distribution, where <code class="reqn">2\pi c_f</code> is the sum of autocovariances.
Consequently, the trend (or derivative) estimates are asymptotically unbiased
and normally distributed.
</p>
<p>To make use of this function, an object of class <code>smoots</code> can be given
as input that was created by either <code><a href="#topic+msmooth">msmooth</a></code>,
<code><a href="#topic+tsmooth">tsmooth</a></code> or <code><a href="#topic+dsmooth">dsmooth</a></code>. Based on the optimal
bandwidth saved within <code>obj</code>, an adjustment to the bandwidth is made so
that the estimates following the adjusted bandwidth are (relatively)
unbiased.
</p>
<p>Based on the input argument <code>alpha</code>, the level of confidence between
<code>0</code> and <code>1</code>, the respective confidence bounds are calculated for
each observation point.
</p>
<p>From the input argument <code>obj</code>, the order of derivative is automatically
obtained. By means of the argument <code>p</code>, an order of polynomial is
selected for a parametric regression of the trend function. This is only
meaningful, if the trend (and not its derivatives) is analyzed. Otherwise,
the argument is automatically dropped by the function. Furthermore, if
<code>plot = TRUE</code>, a plot of the unbiased trend (or derivative) estimates
alongside the confidence bounds is created. If also <code>showPar = TRUE</code>,
the estimated parametric trend (or parametric constant value for the
derivatives) is added to the confidence bound plot for comparison.
</p>
<p>NOTE:
</p>
<p>The values that are returned by the function are obtained with respect to
the rescaled time points on the interval <code class="reqn">[0, 1]</code>. While the plot can be
adjusted and rescaled by means of a given vector with the actual time points,
the numeric output is not rescaled. For this purpose we refer the user to
the <code><a href="#topic+rescale">rescale</a></code> function of the <code>smoots</code> package.
</p>
<p>This function implements C++ code by means of the
<code><a href="Rcpp.html#topic+Rcpp-package">Rcpp</a></code> and
<code><a href="RcppArmadillo.html#topic+RcppArmadillo-package">RcppArmadillo</a></code> packages for
better performance.
</p>


<h3>Value</h3>

<p>A plot is created in the plot window and a list with different components
is returned.
</p>

<dl>
<dt>alpha</dt><dd><p>a numeric vector of length 1; the level of confidence; input
argument.</p>
</dd>
<dt>b.ub</dt><dd><p>a numeric vector with one element that represents the adjusted
bandwidth for the unbiased trend estimation.</p>
</dd>
<dt>p.estim</dt><dd><p>a numeric vector with the estimates following the parametric
regression defined by <code>p</code> that is conducted as a benchmark for the trend
function; for the trend's derivatives or for <code>p = 0</code>, a constant value
is the benchmark; the values are obtained with respect to the rescaled time
points on the interval <code class="reqn">[0, 1]</code>.</p>
</dd>
<dt>n</dt><dd><p>the number of observations.</p>
</dd>
<dt>np.estim</dt><dd><p>a data frame with the three (numeric) columns <strong>ye.ub</strong>,
<strong>lower</strong> and <strong>upper</strong>; in <strong>ye.ub</strong> the unbiased trend
estimates, in <strong>lower</strong> the lower confidence bound and in <strong>upper</strong>
the upper confidence bound can be found; the values are obtained with respect
to the rescaled time points on the interval <code class="reqn">[0, 1]</code>.</p>
</dd>
<dt>v</dt><dd><p>the order of the trend's derivative considered for the test.</p>
</dd>
</dl>



<h3>Author(s)</h3>


<ul>
<li><p> Yuanhua Feng (Department of Economics, Paderborn University), <br />
Author of the Algorithms <br />
Website: <a href="https://wiwi.uni-paderborn.de/en/dep4/feng/">https://wiwi.uni-paderborn.de/en/dep4/feng/</a>
</p>
</li>
<li><p> Dominik Schulz (Research Assistant) (Department of Economics, Paderborn
University), <br />
Package Creator and Maintainer
</p>
</li></ul>



<h3>References</h3>

<p>Beran, J. and Feng, Y. (2002). Local polynomial fitting with long-memory,
short-memory and antipersistent errors. Annals of the Institute of
Statistical Mathematics, 54(2), 291-311.
</p>
<p>Feng, Y., Gries, T. and Fritz, M. (2020). Data-driven
local polynomial for the trend and its derivatives in economic time
series. Journal of Nonparametric Statistics, 32:2, 510-533.
</p>
<p>Feng, Y., Gries, T., Letmathe, S. and Schulz, D. (2019). The smoots package
in R for semiparametric modeling of trend stationary time series. Discussion
Paper. Paderborn University. Unpublished.
</p>
<p>Feng, Y., Gries, T., Fritz, M., Letmathe, S. and Schulz, D. (2020).
Diagnosing the trend and bootstrapping the forecasting intervals using a
semiparametric ARMA. Discussion Paper. Paderborn University. Unpublished.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>log_gdp &lt;- log(smoots::gdpUS$GDP)
est &lt;- msmooth(log_gdp)
confBounds(est)

</code></pre>

<hr>
<h2 id='critMatrix'>ARMA Order Selection Matrix</h2><span id='topic+critMatrix'></span>

<h3>Description</h3>

<p>An information criterion is calculated for different orders of an
autoregressive-moving-average (ARMA) model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>critMatrix(
  X,
  p.max = 5,
  q.max = 5,
  criterion = c("bic", "aic"),
  include.mean = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="critMatrix_+3A_x">X</code></td>
<td>
<p>a numeric vector that contains the observed time series ordered
from past to present; the series is assumed to follow an ARMA process.</p>
</td></tr>
<tr><td><code id="critMatrix_+3A_p.max">p.max</code></td>
<td>
<p>an integer value <code class="reqn">&gt;= 0</code> that defines the maximum
autoregressive order to calculate the criterion for; is set to <code>5</code>
by default; decimal numbers will be rounded off to integers.</p>
</td></tr>
<tr><td><code id="critMatrix_+3A_q.max">q.max</code></td>
<td>
<p>an integer value <code class="reqn">&gt;= 0</code> that defines the maximum
moving-average order to to calculate the criterion for; is set to <code>5</code>
by default; decimal numbers will be rounded off to integers.</p>
</td></tr>
<tr><td><code id="critMatrix_+3A_criterion">criterion</code></td>
<td>
<p>a character value that defines the information criterion
that will be calculated; the Bayesian Information Criterion (<code>"bic"</code>)
and Akaike Information Criterion (<code>"aic"</code>) are the supported choices;
is set to <code>"bic"</code> by default.</p>
</td></tr>
<tr><td><code id="critMatrix_+3A_include.mean">include.mean</code></td>
<td>
<p>a logical value; this argument regulates whether to
estimate the mean of the series (<code>TRUE</code>) or not (<code>FALSE</code>); is set
to <code>TRUE</code> by default.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is part of the <code>smoots</code> package and was implemented under
version 1.1.0. The series passed to <code>X</code> is assumed to follow an
ARMA(<code class="reqn">p,q</code>) model. A <code>p.max + 1</code> by <code>q.max + 1</code> matrix is
calculated for this series. More precisely, the criterion chosen via the
argument <code>criterion</code> is calculated for all combinations of orders
<code class="reqn">p = 0, 1, ..., p_{max}</code> and
<code class="reqn">q = 0, 1, ..., q_{max}</code>.
</p>
<p>Within the function, two information criteria are supported: the Bayesian
Information Criterion (BIC) and Akaike's Information Criterion (AIC). The AIC
is given by
</p>
<p style="text-align: center;"><code class="reqn">AIC_{p,q} := \ln(\hat{\sigma}_{p,q}^{2}) + \frac{2(p+q)}{n},</code>
</p>

<p>where <code class="reqn">\hat{sigma}_{p,q}^{2}</code> is the estimated
innovation variance, <code class="reqn">p</code> and <code class="reqn">q</code> are the ARMA orders and <code class="reqn">n</code> is
the number of observations.
</p>
<p>The BIC, on the other hand, is defined by
</p>
<p style="text-align: center;"><code class="reqn">BIC_{p,q} := k \ln(n) - 2\ln(\hat{L})</code>
</p>

<p>with <code class="reqn">k</code> being the number of estimated parameters and
<code class="reqn">\hat{L}</code> being the estimated Log-Likelihood. Since the parameter
<code class="reqn">k</code> only differs with respect to the orders <code class="reqn">p</code> and <code class="reqn">q</code> for all
estimated models, the term <code class="reqn">k \ln(n)</code> is reduced to
<code class="reqn">(p + q) \ln(n)</code> within the function. Exemplarily,
if the mean of the series is estimated as well, it is usually considered
within the parameter <code class="reqn">k</code> when calculating the BIC.
However, since the mean is estimated for all models, not considering this
estimated parameter within the calculation of the BIC will reduce all BIC
values by the same amount of <code class="reqn">\ln(n)</code>. Therefore, the selection
via this simplified criterion is still valid, if the number of the estimated
parameters only differs with respect to <code class="reqn">p</code> and <code class="reqn">q</code> between the
models that the BIC is obtained for.
</p>
<p>The optimal orders are considered to be the ones which minimize either the
BIC or the AIC. The use of the BIC is however recommended, because the BIC
is consistent, whereas the AIC is not.
</p>
<p>NOTE:
</p>
<p>Within this function, the <code><a href="stats.html#topic+arima">arima</a></code> function of the
<code>stats</code> package with its method <code>"CSS-ML"</code> is used throughout for
the estimation of ARMA models.
</p>


<h3>Value</h3>

<p>The function returns a <code>p.max + 1</code> by <code>q.max + 1</code> matrix, where the
rows represent the AR orders from <code class="reqn">p = 0</code> to <code class="reqn">p = p_{max}</code>
and the columns represent the MA orders from <code class="reqn">q = 0</code> to
<code class="reqn">q = q_{max}</code>. The values within the matrix are the values of
the previously selected information criterion for the different combinations
of <code class="reqn">p</code> and <code class="reqn">q</code>.
</p>


<h3>Author(s)</h3>


<ul>
<li><p> Dominik Schulz (Research Assistant) (Department of Economics, Paderborn
University), <br />
Package Creator and Maintainer
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Simulate an ARMA(2,1) process
set.seed(23)
X.sim &lt;- stats::arima.sim(model = list(ar = c(1.2, -0.71), ma = 0.46),
 n = 1000) + 13.1
# Application of the function
critMatrix(X.sim)
# Result: Via the BIC, the orders p.opt = 2 and q.opt = 1 are selected.

## End(Not run)
</code></pre>

<hr>
<h2 id='dax'>German Stock Market Index (DAX) Financial Time Series Data</h2><span id='topic+dax'></span>

<h3>Description</h3>

<p>A dataset that contains the daily financial data of the DAX from
1990 to July 2019 (currency in EUR).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dax
</code></pre>


<h3>Format</h3>

<p>A data frame with 7475 rows and 9 variables:
</p>

<dl>
<dt>Year</dt><dd><p>the observation year</p>
</dd>
<dt>Month</dt><dd><p>the observation month</p>
</dd>
<dt>Day</dt><dd><p>the observation day</p>
</dd>
<dt>Open</dt><dd><p>the opening price of the day</p>
</dd>
<dt>High</dt><dd><p>the highest price of the day</p>
</dd>
<dt>Low</dt><dd><p>the lowest price of the day</p>
</dd>
<dt>Close</dt><dd><p>the closing price of the day</p>
</dd>
<dt>AdjClose</dt><dd><p>the adjusted closing price of the day</p>
</dd>
<dt>Volume</dt><dd><p>the traded volume</p>
</dd>
</dl>



<h3>Source</h3>

<p>The data was obtained from Yahoo Finance (accessed: 2019-08-22).
</p>
<p><a href="https://query1.finance.yahoo.com/v7/finance/download/%5EGDAXI?period1=631148400&amp;period2=1564524000&amp;interval=1d&amp;events=history&amp;crumb=Iaq1EPZAQRb">https://query1.finance.yahoo.com/v7/finance/download/^GDAXI?period1=631148400&amp;period2=1564524000&amp;interval=1d&amp;events=history&amp;crumb=Iaq1EPZAQRb</a>
</p>

<hr>
<h2 id='dsmooth'>Data-driven Local Polynomial for the Trend's Derivatives in Equidistant Time
Series</h2><span id='topic+dsmooth'></span>

<h3>Description</h3>

<p>This function runs through an iterative process in order to find the
optimal bandwidth for the nonparametric estimation of the first or second
derivative of the trend in an equidistant time series (with short-memory
errors) and subsequently employs the obtained bandwidth via local
polynomial regression.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dsmooth(
  y,
  d = c(1, 2),
  mu = c(0, 1, 2, 3),
  pp = c(1, 3),
  bStart.p = 0.15,
  bStart = 0.15
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dsmooth_+3A_y">y</code></td>
<td>
<p>a numeric vector that contains the time series ordered from past to
present.</p>
</td></tr>
<tr><td><code id="dsmooth_+3A_d">d</code></td>
<td>
<p>an integer <code>1</code> or <code>2</code> that defines the order of
derivative; the default is <code>d = 1</code>.</p>
</td></tr>
<tr><td><code id="dsmooth_+3A_mu">mu</code></td>
<td>
<p>an integer <code>0</code>, ..., <code>3</code> that represents the smoothness
parameter of the kernel weighting function and thus defines the kernel
function that will be used within the local polynomial regression; is set to
<code>1</code> by default.
</p>

<table>
<tr>
 <td style="text-align: center;">
<strong>Number</strong> </td><td style="text-align: left;"> <strong>Kernel</strong></td>
</tr>
<tr>
 <td style="text-align: center;">
<code>0</code> </td><td style="text-align: left;"> Uniform Kernel</td>
</tr>
<tr>
 <td style="text-align: center;">
<code>1</code> </td><td style="text-align: left;"> Epanechnikov Kernel</td>
</tr>
<tr>
 <td style="text-align: center;">
<code>2</code> </td><td style="text-align: left;"> Bisquare Kernel</td>
</tr>
<tr>
 <td style="text-align: center;">
<code>3</code> </td><td style="text-align: left;"> Triweight Kernel
</td>
</tr>

</table>
</td></tr>
<tr><td><code id="dsmooth_+3A_pp">pp</code></td>
<td>
<p>an integer <code>1</code> (local linear regression) or <code>3</code> (local
cubic regression) that indicates the order of polynomial upon which
<code class="reqn">c_f</code>, i.e. the variance factor, will be calculated by
<code><a href="#topic+msmooth">msmooth</a></code>; the default is <code>pp = 1</code>.</p>
</td></tr>
<tr><td><code id="dsmooth_+3A_bstart.p">bStart.p</code></td>
<td>
<p>a numeric object that indicates the starting value of the
bandwidth for the iterative process for the calculation of <code class="reqn">c_f</code>; should
be <code class="reqn">&gt; 0</code>; is set to <code>0.15</code> by default.</p>
</td></tr>
<tr><td><code id="dsmooth_+3A_bstart">bStart</code></td>
<td>
<p>a numeric object that indicates the starting value of the
bandwidth for the iterative process; should be <code class="reqn">&gt; 0</code>; is set to
<code>0.15</code> by default.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The trend's derivative is estimated based on the additive
nonparametric regression model for an equidistant time series
</p>
<p style="text-align: center;"><code class="reqn">y_t = m(x_t) + \epsilon_t,</code>
</p>

<p>where <code class="reqn">y_t</code> is the observed time series, <code class="reqn">x_t</code> is the rescaled time
on the interval <code class="reqn">[0, 1]</code>, <code class="reqn">m(x_t)</code> is a smooth and deterministic
trend function and <code class="reqn">\epsilon_t</code> are stationary errors with
<code class="reqn">E(\epsilon_t) = 0</code> and short-range dependence (see also Beran and Feng,
2002). With this function, the first or second derivative of <code class="reqn">m(x_t)</code>
can be estimated without a parametric model assumption for the error series.
</p>
<p>The iterative-plug-in (IPI) algorithm, which numerically minimizes the
Asymptotic Mean Squared Error (AMISE), was proposed by Feng, Gries and
Fritz (2020).
</p>
<p>Define <code class="reqn">I[m^{(k)}] = \int_{c_b}^{d_b} [m^{(k)}(x)]^2 dx</code>, <code class="reqn">\beta_{(\nu, k)} = \int_{-1}^{1} u^k
K_{(\nu, k)}(u) du</code>
and <code class="reqn">R(K) = \int_{-1}^{1} K_{(\nu, k)}^{2}(u) du</code>, where <code class="reqn">p</code> is the order of the polynomial,
<code class="reqn">k = p + 1</code> is the order of the asymptotically equivalent kernel,
<code class="reqn">\nu</code> is the order of the trend function's derivative, <code class="reqn">0 \leq c_{b}
&lt; d_{b} \leq 1</code>, <code class="reqn">c_f</code> is the variance factor and
<code class="reqn">K_{(\nu, k)}(u)</code> the <code class="reqn">k</code>-th order equivalent kernel
obtained for the estimation of <code class="reqn">m^{(\nu)}</code> in the interior.
<code class="reqn">m^{(\nu)}</code> is the <code class="reqn">\nu</code>-th order derivative (<code class="reqn">\nu = 0,
1, 2, ...</code>) of the nonparametric trend.
</p>
<p>Furthermore, we define
</p>
<p style="text-align: center;"><code class="reqn">C_{1} = \frac{I[m^{(k)}] \beta_{(\nu, k)}^2}{(k!)^2}</code>
</p>

<p>and
</p>
<p style="text-align: center;"><code class="reqn">C_{2} = \frac{2 \pi c_{f} (d_b - c_b) R(K)}{nh^{2 \nu + 1}}</code>
</p>

<p>with <code class="reqn">h</code> being the bandwidth and <code class="reqn">n</code> being the number of
observations. The AMISE is then
</p>
<p style="text-align: center;"><code class="reqn">AMISE(h) = h^{2(k-\nu)}C_{1} + C_{2}.</code>
</p>

<p>The variance factor <code class="reqn">c_f</code> is first obtained from a pilot-estimation of
the time series' nonparametric trend (<code class="reqn">\nu = 0</code>) with polynomial order
<code class="reqn">p_p</code>. The estimate is then plugged into the iterative procedure for
estimating the first or second derivative (<code class="reqn">\nu = 1</code> or <code class="reqn">\nu = 2</code>).
For further details on the asymptotic theory or the algorithm, we refer the
user to Feng, Fritz and Gries (2020) and Feng et al. (2019).
</p>
<p>The function itself is applicable in the following way: Based on a data input
<code>y</code>, an order of polynomial <code>pp</code> for the variance factor estimation
procedure, a starting value for the relative bandwidth <code>bStart.p</code> in the
variance factor estimation procedure, a kernel function defined by the
smoothness parameter <code>mu</code> and a starting value for the relative
bandwidth <code>bStart</code> in the bandwidth estimation procedure, an optimal
bandwidth is numerically calculated for the trend's derivative of order
<code>d</code>. In fact, aside from the input vector <code>y</code>, every argument has a
default setting that can be adjusted for the individual case. However, it is
recommended to initially use the default values for the estimation of the
first derivative and adjust the argument <code>d</code> to <code>d = 2</code> for the
estimation of the second derivative. Following Feng, Gries and Fritz (2020),
the initial bandwidth does not affect the resulting optimal bandwidth in
theory. However in practice, local minima of the AMISE can influence the
results. Therefore, the default starting bandwidth is set to <code>0.15</code>, the
suggested starting bandwidth by Feng, Gries and Fritz (2020) for the
data-driven  estimation of the first derivative. The recommended initial
bandwidth for the second derivative, however, is <code>0.2</code> and not
<code>0.15</code>. Thus, if the algorithm does not give suitable results
(especially for <code>d = 2</code>), the adjustment of the initial bandwidth might
be a good starting point. Analogously, the default starting bandwidth for the
trend estimation for the variance factor is <code>bStart.p = 0.15</code>, although
according to Feng, Gries and Fritz (2020), <code>bStart.p = 0.1</code> is suggested
for <code>pp = 1</code> and <code>bStart.p = 0.2</code> for <code>pp = 3</code>. The default is
therefore a compromise between the two suggested values. For more specific
information on the input arguments consult the section <em>Arguments</em>.
</p>
<p>After the bandwidth estimation, the nonparametric derivative of the series
is calculated with respect to the obtained optimal bandwidth by means of a
local polynomial regression. The output object is then a list that contains,
among other components, the original time series, the estimates of the
derivative and the estimated optimal bandwidth.
</p>
<p>The default print method for this function delivers key numbers such as
the iteration steps and the generated optimal bandwidth rounded to the fourth
decimal. The exact numbers and results such as the estimated nonparametric
trend series are saved within the output object and can be addressed via the
<code>$</code> sign.
</p>
<p>NOTE:
</p>
<p>The estimates are obtained for the rescaled time points on the interval
<code class="reqn">[0, 1]</code>. Therefore, the estimated derivatives might not reflect the
derivatives for the actual time points. To rescale them, we refer the
user to the <code><a href="#topic+rescale">rescale</a></code> function of the <code>smoots</code> package.
</p>
<p>With package version 1.1.0, this function implements C++ code by means
of the <code><a href="Rcpp.html#topic+Rcpp-package">Rcpp</a></code> and
<code><a href="RcppArmadillo.html#topic+RcppArmadillo-package">RcppArmadillo</a></code> packages for
better performance.
</p>


<h3>Value</h3>

<p>The function returns a list with different components:
</p>

<dl>
<dt>b0</dt><dd><p>the optimal bandwidth chosen by the IPI-algorithm.</p>
</dd>
<dt>bStart</dt><dd><p>the starting bandwidth for the local polynomial
regression based derivative estimation procedure; input argument.</p>
</dd>
<dt>bStart.p</dt><dd><p>the starting bandwidth for the nonparametric trend estimation
that leads to the variance factor estimate; input argument.</p>
</dd>
<dt>bvc</dt><dd><p>indicates whether an enlarged bandwidth was used for the variance
factor estimation or not; it is always set to <code>"Y"</code> (yes) for this
function.</p>
</dd>
<dt>cf0</dt><dd><p>the estimated variance factor; in contrast to the definitions
given in the <em>Details</em> section, this object actually contains an
estimated value of <code class="reqn">2\pi c_f</code>, i.e. it corresponds to the estimated sum
of autocovariances.</p>
</dd>
<dt>InfR</dt><dd><p>the inflation rate setting.</p>
</dd>
<dt>iterations</dt><dd><p>the bandwidths of the single iterations steps</p>
</dd>
<dt>Mcf</dt><dd><p>the estimation method for the variance factor estimation; it is
always estimated nonparametrically (<code>"NP"</code>) within this function.</p>
</dd>
<dt>mu</dt><dd><p>the smoothness parameter of the second order kernel; input
argument.</p>
</dd>
<dt>n</dt><dd><p>the number of observations.</p>
</dd>
<dt>niterations</dt><dd><p>the total number of iterations until convergence.</p>
</dd>
<dt>orig</dt><dd><p>the original input series; input argument.</p>
</dd>
<dt>p</dt><dd><p>the order of polynomial for the local polynomial
regression used within derivative estimation procedure.</p>
</dd>
<dt>pp</dt><dd><p>the order of polynomial for the local polynomial
regression used in the variance factor estimation; input argument.</p>
</dd>
<dt>v</dt><dd><p>the considered order of the trend's derivative; input argument
<code>d</code>.</p>
</dd>
<dt>ws</dt><dd><p>the weighting system matrix used within the local polynomial
regression; this matrix is a condensed version of a complete weighting system
matrix; in each row of <code>ws</code>, the weights for conducting the smoothing
procedure at a specific observation time point can be found; the first
<code class="reqn">[nb + 0.5]</code> rows, where <code class="reqn">n</code> corresponds to the number of
observations, <code class="reqn">b</code> is the bandwidth considered for smoothing and
<code class="reqn">[.]</code> denotes the integer part, contain the weights at the
<code class="reqn">[nb + 0.5]</code> left-hand boundary points; the weights in row
<code class="reqn">[nb + 0.5] + 1</code> are representative for the estimation at all
interior points and the remaining rows contain the weights for the right-hand
boundary points; each row has exactly <code class="reqn">2[nb + 0.5] + 1</code> elements,
more specifically the weights for observations of the nearest
<code class="reqn">2[nb + 0.5] + 1</code> time points; moreover, the weights are normalized,
i.e. the weights are obtained under consideration of the time points
<code class="reqn">x_t = t/n</code>, where <code class="reqn">t = 1, 2, ..., n</code>.</p>
</dd>
<dt>ye</dt><dd><p>the nonparametric estimates of the derivative for the rescaled
time points on the interval <code class="reqn">[0, 1]</code>.</p>
</dd>
</dl>



<h3>Author(s)</h3>


<ul>
<li><p> Yuanhua Feng (Department of Economics, Paderborn University), <br />
Author of the Algorithms <br />
Website: <a href="https://wiwi.uni-paderborn.de/en/dep4/feng/">https://wiwi.uni-paderborn.de/en/dep4/feng/</a>
</p>
</li>
<li><p> Dominik Schulz (Research Assistant) (Department of Economics, Paderborn
University), <br />
Package Creator and Maintainer
</p>
</li></ul>



<h3>References</h3>

<p>Feng, Y., Gries, T. and Fritz, M. (2020). Data-driven
local polynomial for the trend and its derivatives in economic time
series. Journal of Nonparametric Statistics, 32:2, 510-533.
</p>
<p>Feng, Y., Gries, T., Letmathe, S. and Schulz, D. (2019). The smoots package
in R for semiparametric modeling of trend stationary time series. Discussion
Paper. Paderborn University. Unpublished.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Logarithm of test data
test_data &lt;- gdpUS
y &lt;- log(test_data$GDP)
t &lt;- seq(from = 1947, to = 2019.25, by = 0.25)

# Applied dsmooth function for the trend's first derivative
result_d &lt;- dsmooth(y, d = 1, mu = 1, pp = 1, bStart.p = 0.1, bStart = 0.15)
estim &lt;- result_d$ye

# Plot of the results
plot(t, estim, xlab = "Year", ylab = "First derivative", type = "l",
 main = paste0("Estimated first derivative of the trend for log-quarterly ",
 "US-GDP, Q1 1947 - Q2 2019"), cex.axis = 0.8, cex.main = 0.8,
 cex.lab = 0.8, bty = "n")

# Print result
result_d
</code></pre>

<hr>
<h2 id='fitted.smoots'>Extract Model Fitted Values</h2><span id='topic+fitted.smoots'></span>

<h3>Description</h3>

<p>Generic function which extracts fitted values from a <code>smoots</code> class
object. Both <code>fitted</code> and <code>fitted.values</code> can be called.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'smoots'
fitted(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fitted.smoots_+3A_object">object</code></td>
<td>
<p>an object from the <code>smoots</code> class.</p>
</td></tr>
<tr><td><code id="fitted.smoots_+3A_...">...</code></td>
<td>
<p>included for consistency with the generic function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Fitted values extracted from a <code>smoots</code> class object.
</p>


<h3>Author(s)</h3>


<ul>
<li><p> Sebastian Letmathe (Scientific Employee) (Department of Economics,
Paderborn University), <br />
</p>
</li></ul>


<hr>
<h2 id='gdpUS'>Quarterly US GDP, Q1 1947 to Q2 2019</h2><span id='topic+gdpUS'></span>

<h3>Description</h3>

<p>A dataset that contains the (seasonally adjusted) Gross
Domestic Product of the US from the first quarter of 1947 to the second
quarter of 2019
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gdpUS
</code></pre>


<h3>Format</h3>

<p>A data frame with 290 rows and 3 variables:
</p>

<dl>
<dt>Year</dt><dd><p>the observation year</p>
</dd>
<dt>Quarter</dt><dd><p>the observation quarter in the given year</p>
</dd>
<dt>GDP</dt><dd><p>the Gross Domestic Product of the US in billions of chained
2012 US Dollars (annual rate)</p>
</dd>
</dl>



<h3>Source</h3>

<p>The data was obtained from the Federal Reserve Bank of St. Louis
(accessed: 2019-09-01).
</p>
<p><a href="https://fred.stlouisfed.org/series/GDPC1">https://fred.stlouisfed.org/series/GDPC1</a>
</p>

<hr>
<h2 id='gsmooth'>Estimation of Trends and their Derivatives via Local Polynomial Regression</h2><span id='topic+gsmooth'></span>

<h3>Description</h3>

<p>This function is an R function for estimating the trend function
and its derivatives in an equidistant time series with local polynomial
regression and a fixed bandwidth given beforehand.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gsmooth(y, v = 0, p = v + 1, mu = 1, b = 0.15, bb = c(0, 1))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gsmooth_+3A_y">y</code></td>
<td>
<p>a numeric vector that contains the time series data ordered from
past to present.</p>
</td></tr>
<tr><td><code id="gsmooth_+3A_v">v</code></td>
<td>
<p>an integer <code>0</code>, <code>1</code>, ... that represents the order of
derivative that will be estimated; is set to <code>v = 0</code> by default.
</p>

<table>
<tr>
 <td style="text-align: center;">
<strong>Number (<code>v</code>)</strong> </td><td style="text-align: left;"> <strong>Degree of derivative</strong></td>
</tr>
<tr>
 <td style="text-align: center;">
<code>0</code> </td><td style="text-align: left;"> The function <em>f(x)</em> itself</td>
</tr>
<tr>
 <td style="text-align: center;">
<code>1</code> </td><td style="text-align: left;"> The first derivative <em>f'(x)</em></td>
</tr>
<tr>
 <td style="text-align: center;">
<code>2</code> </td><td style="text-align: left;"> The second derivative <em>f&rdquo;(x)</em></td>
</tr>
<tr>
 <td style="text-align: center;">
<code>...</code> </td><td style="text-align: left;"> ...
</td>
</tr>

</table>
</td></tr>
<tr><td><code id="gsmooth_+3A_p">p</code></td>
<td>
<p>an integer <code class="reqn">&gt;= (</code> <code>v</code> <code class="reqn">+ 1)</code> that represents the order
of polynomial; <code>p - v</code> must be an odd number; is set to <code>v + 1</code>
by default.
</p>
<p>Exemplary for <code>v = 0</code>:
</p>

<table>
<tr>
 <td style="text-align: center;">
<strong>Number (<code>p</code>)</strong> </td><td style="text-align: left;"> <strong>Polynomial</strong> </td><td style="text-align: center;">
<strong><code>p - v</code></strong> </td><td style="text-align: left;"> <strong><code>p - v</code> odd?</strong> </td><td style="text-align: left;">
<strong><code>p</code> usable?</strong></td>
</tr>
<tr>
 <td style="text-align: center;">
<code>1</code> </td><td style="text-align: left;"> Linear </td><td style="text-align: center;"> 1 </td><td style="text-align: left;"> Yes
</td><td style="text-align: left;"> Yes</td>
</tr>
<tr>
 <td style="text-align: center;">
<code>2</code> </td><td style="text-align: left;"> Quadratic </td><td style="text-align: center;"> 2 </td><td style="text-align: left;"> No
</td><td style="text-align: left;"> No</td>
</tr>
<tr>
 <td style="text-align: center;">
<code>3</code> </td><td style="text-align: left;"> Cubic </td><td style="text-align: center;"> 3 </td><td style="text-align: left;"> Yes
</td><td style="text-align: left;"> Yes</td>
</tr>
<tr>
 <td style="text-align: center;">
<code>...</code> </td><td style="text-align: left;"> ... </td><td style="text-align: center;"> ... </td><td style="text-align: left;"> ...
</td><td style="text-align: left;"> ...
</td>
</tr>

</table>
</td></tr>
<tr><td><code id="gsmooth_+3A_mu">mu</code></td>
<td>
<p>an integer <code>0</code>, <code>1</code>, <code>2</code>, ... that represents the
smoothness parameter of the kernel weighting function that will be used; is
set to <code>1</code> by default.
</p>

<table>
<tr>
 <td style="text-align: center;">
<strong>Number (<code>mu</code>)</strong> </td><td style="text-align: left;"> <strong>Kernel</strong></td>
</tr>
<tr>
 <td style="text-align: center;">
<code>0</code> </td><td style="text-align: left;"> Uniform Kernel</td>
</tr>
<tr>
 <td style="text-align: center;">
<code>1</code> </td><td style="text-align: left;"> Epanechnikov Kernel</td>
</tr>
<tr>
 <td style="text-align: center;">
<code>2</code> </td><td style="text-align: left;"> Bisquare Kernel</td>
</tr>
<tr>
 <td style="text-align: center;">
<code>3</code> </td><td style="text-align: left;"> Triweight Kernel</td>
</tr>
<tr>
 <td style="text-align: center;">
<code>...</code> </td><td style="text-align: left;"> ...
</td>
</tr>

</table>
</td></tr>
<tr><td><code id="gsmooth_+3A_b">b</code></td>
<td>
<p>a real number <code class="reqn">0 &lt;</code> <code>b</code> <code class="reqn">&lt; 0.5</code>; represents the
relative bandwidth that will be used for the smoothing process; is set to
<code>0.15</code> by default.</p>
</td></tr>
<tr><td><code id="gsmooth_+3A_bb">bb</code></td>
<td>
<p>can be set to <code>0</code> or <code>1</code>; the parameter controlling the
bandwidth used at the boundary; is set to <code>1</code> by default.
</p>

<table>
<tr>
 <td style="text-align: center;">
<strong>Number (<code>bb</code>)</strong> </td><td style="text-align: left;"> <strong>Estimation procedure at boundary
points</strong></td>
</tr>
<tr>
 <td style="text-align: center;">
<code>0</code> </td><td style="text-align: left;"> Fixed bandwidth on one side with possible large
bandwidth on the other side at the boundary</td>
</tr>
<tr>
 <td style="text-align: center;">
<code>1</code> </td><td style="text-align: left;"> The k-nearest neighbor method will be used
</td>
</tr>

</table>
</td></tr>
</table>


<h3>Details</h3>

<p>The trend or its derivatives are estimated based on the additive
nonparametric regression model for an equidistant time series
</p>
<p style="text-align: center;"><code class="reqn">y_t = m(x_t) + \epsilon_t,</code>
</p>

<p>where <code class="reqn">y_t</code> is the observed time series, <code class="reqn">x_t</code> is the rescaled time
on the interval <code class="reqn">[0, 1]</code>, <code class="reqn">m(x_t)</code> is a smooth and deterministic
trend function and <code class="reqn">\epsilon_t</code> are stationary errors with
<code class="reqn">E(\epsilon_t) = 0</code> (see also Beran and Feng, 2002).
</p>
<p>This function is part of the package <code>smoots</code> and is used in
the field of analyzing equidistant time series data. It applies the local
polynomial regression method to the input data with an arbitrarily
selectable bandwidth. By these means, the trend as well as its derivatives
can be estimated nonparametrically, even though the result will strongly
depend on the bandwidth given beforehand as an input.
</p>
<p>NOTE:
</p>
<p>The estimates are obtained with regard to the rescaled time points on the
interval <code class="reqn">[0, 1]</code>. Thus, if <code class="reqn">\nu &gt; 0</code>, the estimates might not
reflect the values for the actual time points. To rescale the estimates, we
refer the user to the <code><a href="#topic+rescale">rescale</a></code> function of the <code>smoots</code>
package.
</p>
<p>With package version 1.1.0, this function implements C++ code by means
of the <code><a href="Rcpp.html#topic+Rcpp-package">Rcpp</a></code> and
<code><a href="RcppArmadillo.html#topic+RcppArmadillo-package">RcppArmadillo</a></code> packages for
better performance.
</p>


<h3>Value</h3>

<p>The output object is a list with different components:
</p>

<dl>
<dt>b</dt><dd><p>the chosen (relative) bandwidth; input argument.</p>
</dd>
<dt>bb</dt><dd><p>the chosen bandwidth option at the boundaries; input argument.</p>
</dd>
<dt>mu</dt><dd><p>the chosen smoothness parameter for the second order kernel; input
argument.</p>
</dd>
<dt>n</dt><dd><p>the number of observations.</p>
</dd>
<dt>orig</dt><dd><p>the original input series; input argument.</p>
</dd>
<dt>p</dt><dd><p>the chosen order of polynomial; input argument.</p>
</dd>
<dt>res</dt><dd><p>a vector with the estimated residual series; is set to <code>NULL</code>
for <code>v &gt; 0</code>.</p>
</dd>
<dt>v</dt><dd><p>the order of derivative; input argument.</p>
</dd>
<dt>ws</dt><dd><p>the weighting system matrix used within the local polynomial
regression; this matrix is a condensed version of a complete weighting system
matrix; in each row of <code>ws</code>, the weights for conducting the smoothing
procedure at a specific observation time point can be found; the first
<code class="reqn">[nb + 0.5]</code> rows, where <code class="reqn">n</code> corresponds to the number of
observations, <code class="reqn">b</code> is the bandwidth considered for smoothing and
<code class="reqn">[.]</code> denotes the integer part, contain the weights at the
<code class="reqn">[nb + 0.5]</code> left-hand boundary points; the weights in row
<code class="reqn">[nb + 0.5] + 1</code> are representative for the estimation at all
interior points and the remaining rows contain the weights for the right-hand
boundary points; each row has exactly <code class="reqn">2[nb + 0.5] + 1</code> elements,
more specifically the weights for observations of the nearest
<code class="reqn">2[nb + 0.5] + 1</code> time points; moreover, the weights are normalized,
i.e. the weights are obtained under consideration of the time points
<code class="reqn">x_t = t/n</code>, where <code class="reqn">t = 1, 2, ..., n</code>.</p>
</dd>
<dt>ye</dt><dd><p>a vector with the estimates of the selected nonparametric order of
derivative on the rescaled time interval <code class="reqn">[0, 1]</code>.</p>
</dd>
</dl>



<h3>Author(s)</h3>


<ul>
<li><p> Yuanhua Feng (Department of Economics, Paderborn University), <br />
Author of the Algorithms <br />
Website: <a href="https://wiwi.uni-paderborn.de/en/dep4/feng/">https://wiwi.uni-paderborn.de/en/dep4/feng/</a>
</p>
</li>
<li><p> Dominik Schulz (Research Assistant) (Department of Economics, Paderborn
University), <br />
Package Creator and Maintainer
</p>
</li></ul>



<h3>References</h3>

<p>Beran, J. and Feng, Y. (2002). Local polynomial fitting with long-memory,
short-memory and antipersistent errors. Annals of the Institute of
Statistical Mathematics, 54(2), 291-311.
</p>
<p>Feng, Y., Gries, T. and Fritz, M. (2020). Data-driven
local polynomial for the trend and its derivatives in economic time
series. Journal of Nonparametric Statistics, 32:2, 510-533.
</p>
<p>Feng, Y., Gries, T., Letmathe, S. and Schulz, D. (2019). The smoots package
in R for semiparametric modeling of trend stationary time series. Discussion
Paper. Paderborn University. Unpublished.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Logarithm of test data
test_data &lt;- gdpUS
y &lt;- log(test_data$GDP)

# Applied gsmooth function for the trend with two different bandwidths
results1 &lt;- gsmooth(y, v = 0, p = 1, mu = 1, b = 0.28, bb = 1)
results2 &lt;- gsmooth(y, v = 0, p = 1, mu = 1, b = 0.11, bb = 1)
trend1 &lt;- results1$ye
trend2 &lt;- results2$ye

# Plot of the results
t &lt;- seq(from = 1947, to = 2019.25, by = 0.25)
plot(t, y, type = "l", xlab = "Year", ylab = "log(US-GDP)", bty = "n",
 lwd = 2,
 main = "Estimated trend for log-quarterly US-GDP, Q1 1947 - Q2 2019")
points(t, trend1, type = "l", col = "red", lwd = 1)
points(t, trend2, type = "l", col = "blue", lwd = 1)
legend("bottomright", legend = c("Trend (b = 0.28)", "Trend (b = 0.11)"),
 fill = c("red", "blue"), cex = 0.6)
title(sub = expression(italic("Figure 1")), col.sub = "gray47",
 cex.sub = 0.6, adj = 0)


</code></pre>

<hr>
<h2 id='knsmooth'>Estimation of Nonparametric Trend Functions via Kernel Regression</h2><span id='topic+knsmooth'></span>

<h3>Description</h3>

<p>This function estimates the nonparametric trend function in an equidistant
time series with Nadaraya-Watson kernel regression.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>knsmooth(y, mu = 1, b = 0.15, bb = c(0, 1))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="knsmooth_+3A_y">y</code></td>
<td>
<p>a numeric vector that contains the time series data ordered from
past to present.</p>
</td></tr>
<tr><td><code id="knsmooth_+3A_mu">mu</code></td>
<td>
<p>an integer <code>0</code>, <code>1</code>, <code>2</code>, ... that represents the
smoothness parameter of the second order kernel function that will be used;
is set to <code>1</code> by default.
</p>

<table>
<tr>
 <td style="text-align: center;">
<strong>Number (<code>mu</code>)</strong> </td><td style="text-align: left;"> <strong>Kernel</strong></td>
</tr>
<tr>
 <td style="text-align: center;">
<code>0</code> </td><td style="text-align: left;"> Uniform Kernel</td>
</tr>
<tr>
 <td style="text-align: center;">
<code>1</code> </td><td style="text-align: left;"> Epanechnikov Kernel</td>
</tr>
<tr>
 <td style="text-align: center;">
<code>2</code> </td><td style="text-align: left;"> Bisquare Kernel</td>
</tr>
<tr>
 <td style="text-align: center;">
<code>3</code> </td><td style="text-align: left;"> Triweight Kernel</td>
</tr>
<tr>
 <td style="text-align: center;">
<code>...</code> </td><td style="text-align: left;"> ...
</td>
</tr>

</table>
</td></tr>
<tr><td><code id="knsmooth_+3A_b">b</code></td>
<td>
<p>a real number <code class="reqn">0 &lt;</code> <code>b</code> <code class="reqn">&lt; 0.5</code>; represents the
relative bandwidth that will be used for the smoothing process; is set to
<code>0.15</code> by default.</p>
</td></tr>
<tr><td><code id="knsmooth_+3A_bb">bb</code></td>
<td>
<p>can be set to <code>0</code> or <code>1</code>; the parameter controlling the
bandwidth used at the boundary; is set to <code>0</code> by default.
</p>

<table>
<tr>
 <td style="text-align: center;">
<strong>Number (<code>bb</code>)</strong> </td><td style="text-align: left;"> <strong>Estimation procedure at boundary
points</strong></td>
</tr>
<tr>
 <td style="text-align: center;">
<code>0</code> </td><td style="text-align: left;"> Fixed bandwidth on one side with possible large
bandwidth on the other side at the boundary</td>
</tr>
<tr>
 <td style="text-align: center;">
<code>1</code> </td><td style="text-align: left;"> The k-nearest neighbor method will be used
</td>
</tr>

</table>
</td></tr>
</table>


<h3>Details</h3>

<p>The trend is estimated based on the additive
nonparametric regression model for an equidistant time series
</p>
<p style="text-align: center;"><code class="reqn">y_t = m(x_t) + \epsilon_t,</code>
</p>

<p>where <code class="reqn">y_t</code> is the observed time series, <code class="reqn">x_t</code> is the rescaled time
on the interval <code class="reqn">[0, 1]</code>, <code class="reqn">m(x_t)</code> is a smooth and deterministic
trend function and <code class="reqn">\epsilon_t</code> are stationary errors with
<code class="reqn">E(\epsilon_t) = 0</code>.
</p>
<p>This function is part of the package <code>smoots</code> and is used for
the estimation of trends in equidistant time series. The applied method
is a kernel regression with arbitrarily selectable second order
kernel, relative bandwidth and boundary method. Especially the chosen
bandwidth has a strong impact on the final result and has thus to be
selected carefully. This approach is not recommended by the authors of this
package.
</p>


<h3>Value</h3>

<p>The output object is a list with different components:
</p>

<dl>
<dt>b</dt><dd><p>the chosen (relative) bandwidth; input argument.</p>
</dd>
<dt>bb</dt><dd><p>the chosen bandwidth option at the boundaries; input argument.</p>
</dd>
<dt>mu</dt><dd><p>the chosen smoothness parameter for the second order kernel; input
argument.</p>
</dd>
<dt>n</dt><dd><p>the number of observations.</p>
</dd>
<dt>orig</dt><dd><p>the original input series; input argument.</p>
</dd>
<dt>res</dt><dd><p>a vector with the estimated residual series.</p>
</dd>
<dt>ye</dt><dd><p>a vector with the estimates of the nonparametric trend.</p>
</dd>
</dl>



<h3>Author(s)</h3>


<ul>
<li><p> Yuanhua Feng (Department of Economics, Paderborn University), <br />
Author of the Algorithms <br />
Website: <a href="https://wiwi.uni-paderborn.de/en/dep4/feng/">https://wiwi.uni-paderborn.de/en/dep4/feng/</a>
</p>
</li>
<li><p> Dominik Schulz (Research Assistant) (Department of Economics, Paderborn
University), <br />
Package Creator and Maintainer
</p>
</li></ul>



<h3>References</h3>

<p>Feng, Y. (2009). Kernel and Locally Weighted Regression. Verlag für
Wissenschaft und Forschung, Berlin.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Logarithm of test data
test_data &lt;- gdpUS
y &lt;- log(test_data$GDP)

#Applied knmooth function for the trend with two different bandwidths
trend1 &lt;- knsmooth(y, mu = 1, b = 0.28, bb = 1)$ye
trend2 &lt;- knsmooth(y, mu = 1, b = 0.05, bb = 1)$ye

# Plot of the results
t &lt;- seq(from = 1947, to = 2019.25, by = 0.25)
plot(t, y, type = "l", xlab = "Year", ylab = "log(US-GDP)", bty = "n",
 lwd = 2,
 main = "Estimated trend for log-quarterly US-GDP, Q1 1947 - Q2 2019")
points(t, trend1, type = "l", col = "red", lwd = 1)
points(t, trend2, type = "l", col = "blue", lwd = 1)
legend("bottomright", legend = c("Trend (b = 0.28)", "Trend (b = 0.05)"),
 fill = c("red", "blue"), cex = 0.6)
title(sub = expression(italic("Figure 1")), col.sub = "gray47",
 cex.sub = 0.6, adj = 0)


</code></pre>

<hr>
<h2 id='modelCast'>Forecasting Function for Trend-Stationary Time Series</h2><span id='topic+modelCast'></span>

<h3>Description</h3>

<p>Point forecasts and the respective forecasting intervals for
trend-stationary time series are calculated.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>modelCast(
  obj,
  p = NULL,
  q = NULL,
  h = 1,
  method = c("norm", "boot"),
  alpha = 0.95,
  it = 10000,
  n.start = 1000,
  pb = TRUE,
  cores = future::availableCores(),
  np.fcast = c("lin", "const"),
  export.error = FALSE,
  plot = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="modelCast_+3A_obj">obj</code></td>
<td>
<p>an object of class <code>smoots</code>; must be the output of a trend
estimation process and not of a first or second derivative estimation
process.</p>
</td></tr>
<tr><td><code id="modelCast_+3A_p">p</code></td>
<td>
<p>an integer value <code class="reqn">&gt;= 0</code> that defines the AR order <code class="reqn">p</code> of the
underlying ARMA(<code class="reqn">p,q</code>) model within the rest term (see the section
<em>Details</em> for more information); is set to <code>NULL</code> by default; if no
value is passed to <code>p</code> but one is passed to <code>q</code>, <code>p</code> is set to
<code>0</code>; if both <code>p</code> and <code>q</code> are <code>NULL</code>, optimal orders
following the BIC for <code class="reqn">0 \leq p,q \leq 5</code> are chosen; is
set to <code>NULL</code> by default; decimal numbers will be rounded off to
integers.</p>
</td></tr>
<tr><td><code id="modelCast_+3A_q">q</code></td>
<td>
<p>an integer value <code class="reqn">\geq 0</code> that defines the MA order
<code class="reqn">q</code> of the underlying ARMA(<code class="reqn">p,q</code>) model within <code>X</code>; is set to
<code>NULL</code> by default; if no value is passed to <code>q</code> but one is passed
to <code>p</code>, <code>q</code> is set to <code>0</code>; if both <code>p</code> and <code>q</code> are
<code>NULL</code>, optimal orders following the BIC for
<code class="reqn">0 \leq p,q \leq 5</code> are chosen; is set to <code>NULL</code> by
default; decimal numbers will be rounded off to integers.</p>
</td></tr>
<tr><td><code id="modelCast_+3A_h">h</code></td>
<td>
<p>an integer that represents the forecasting horizon; if <code class="reqn">n</code> is
the number of observations, point forecasts and forecasting intervals will be
obtained for the time points <code class="reqn">n + 1</code> to <code class="reqn">n + h</code>; is set to
<code>h = 1</code> by default; decimal numbers will be rounded off to integers.</p>
</td></tr>
<tr><td><code id="modelCast_+3A_method">method</code></td>
<td>
<p>a character object; defines the method used for the calculation
of the forecasting intervals; with <code>"norm"</code> the intervals are obtained
under the assumption of normally distributed innovations; with <code>"boot"</code>
the intervals are obtained via a bootstrap; is set to <code>"norm"</code> by
default.</p>
</td></tr>
<tr><td><code id="modelCast_+3A_alpha">alpha</code></td>
<td>
<p>a numeric vector of length 1 with <code class="reqn">0 &lt; </code> <code>alpha</code>
<code class="reqn"> &lt; 1</code>; the forecasting intervals will be obtained based on the
confidence level (<code class="reqn">100</code><code>alpha</code>)-percent; is set to
<code>alpha = 0.95</code> by default, i.e., a <code class="reqn">95</code>-percent confidence level.</p>
</td></tr>
<tr><td><code id="modelCast_+3A_it">it</code></td>
<td>
<p>an integer that represents the total number of iterations, i.e.,
the number of simulated series; is set to <code>10000</code> by default; only
necessary, if <code>method = "boot"</code>; decimal
numbers will be rounded off to integers.</p>
</td></tr>
<tr><td><code id="modelCast_+3A_n.start">n.start</code></td>
<td>
<p>an integer that defines the 'burn-in' number
of observations for the simulated ARMA series via bootstrap; is set to
<code>1000</code> by default; only necessary, if <code>method = "boot"</code>;decimal
numbers will be rounded off to integers.</p>
</td></tr>
<tr><td><code id="modelCast_+3A_pb">pb</code></td>
<td>
<p>a logical value; for <code>pb = TRUE</code>, a progress bar will be shown
in the console, if <code>method = "boot"</code>.</p>
</td></tr>
<tr><td><code id="modelCast_+3A_cores">cores</code></td>
<td>
<p>an integer value &gt;0 that states the number of (logical) cores to
use in the bootstrap (or <code>NULL</code>); the default is the maximum number of
available cores
(via <code><a href="future.html#topic+availableCores">future::availableCores</a></code>); for
<code>cores = NULL</code>, parallel computation is disabled.</p>
</td></tr>
<tr><td><code id="modelCast_+3A_np.fcast">np.fcast</code></td>
<td>
<p>a character object; defines the forecasting method used
for the nonparametric trend; for <code>np.fcast = "lin"</code> the trend is
is extrapolated linearly based on the last two trend estimates; for
<code>np.fcast = "const"</code>, the last trend estimate is used as a constant
estimate for future values; is set to <em>&quot;lin&quot;</em> by default.</p>
</td></tr>
<tr><td><code id="modelCast_+3A_export.error">export.error</code></td>
<td>
<p>a single logical value; if the argument is set to
<code>TRUE</code> and if also <code>method = "boot"</code>, a list is returned instead
of a matrix (<code>FALSE</code>); the first element of the list is the usual
forecasting matrix whereas the second element is a matrix with <code>h</code>
columns, where each column represents the calculated forecasting errors for
the respective future time point <code class="reqn">n + 1, n + 2, ..., n + h</code>; is set to
<code>FALSE</code> by default.</p>
</td></tr>
<tr><td><code id="modelCast_+3A_plot">plot</code></td>
<td>
<p>a logical value that controls the graphical output; for
<code>plot = TRUE</code>, the original series with the obtained point forecasts
as well as the forecasting intervals will be plotted; for the default
<code>plot = FALSE</code>, no plot will be created.</p>
</td></tr>
<tr><td><code id="modelCast_+3A_...">...</code></td>
<td>
<p>additional arguments for the standard plot function, e.g.,
<code>xlim</code>, <code>type</code>, ... ; arguments with respect to plotted graphs,
e.g., the argument <code>col</code>, only affect the original series <code>X</code>;
please note that in accordance with the argument <code>x</code> (lower case) of the
standard plot function, an additional numeric vector with time points can be
implemented via the argument <code>x</code> (lower case). <code>x</code> should be
valid for the sample observations only, i.e.
<code>length(x) == length(obj$orig)</code> should be <code>TRUE</code>, as future time
points will be calculated automatically.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is part of the <em>smoots</em> package and was implemented under
version 1.1.0. The point forecasts and forecasting intervals are obtained
based on the additive nonparametric regression model
</p>
<p style="text-align: center;"><code class="reqn">y_t = m(x_t) + \epsilon_t,</code>
</p>

<p>where <code class="reqn">y_t</code> is the observed time series with equidistant design,
<code class="reqn">x_t</code> is the rescaled time on the interval <code class="reqn">[0, 1]</code>,
<code class="reqn">m(x_t)</code> is a smooth trend function and
<code class="reqn">\epsilon_t</code> are stationary errors with
<code class="reqn">E(\epsilon_t) = 0</code> and
short-range dependence (see also Beran and Feng, 2002). Thus, we assume
<code class="reqn">y_t</code> to be a trend-stationary time series. Furthermore, we assume
that the rest term <code class="reqn">\epsilon_t</code> follows an ARMA(<code class="reqn">p,q</code>)
model
</p>
<p style="text-align: center;"><code class="reqn">\epsilon_t = \zeta_t + \beta_1 \epsilon_{t-1} + ... + \beta_p
\epsilon_{t-p} + \alpha_1 \zeta_{t-1} + ... +
\alpha_q \zeta_{t-q},</code>
</p>

<p>where <code class="reqn">\alpha_j</code>, <code class="reqn">j = 1, 2, ..., q</code>, and
<code class="reqn">\beta_i</code>, <code class="reqn">i = 1, 2, ..., p</code>, are real numbers and
the random variables <code class="reqn">\zeta_t</code> are
i.i.d. (identically and independently distributed) with
zero mean and constant variance.
</p>
<p>The point forecasts and forecasting intervals for the future periods
<code class="reqn">n + 1, n + 2, ..., n + h</code> will be obtained. With respect to the point
forecasts of <code class="reqn">\epsilon_t</code>, i.e.,
<code class="reqn">\hat{\epsilon}_{n+k}</code>, where
<code class="reqn">k = 1, 2, ..., h</code>,
</p>
<p style="text-align: center;"><code class="reqn">\hat{\epsilon}_{n+k} = \sum_{i=1}^{p} \hat{\beta}_i \epsilon_{n+k-i} +
\sum_{j=1}^{q} \hat{\alpha}_j \hat{\zeta}_{n+k-j}</code>
</p>

<p>with <code class="reqn">\epsilon_{n+k-i} = \hat{\epsilon}_{n+k-i}</code> for <code class="reqn">n+k-i &gt; n</code> and
<code class="reqn">\hat{\zeta}_{n+k-j} = E(\zeta_t) = 0</code> for <code class="reqn">n+k-j &gt; n</code> will be applied. In practice, this procedure will
not be applied directly to <code class="reqn">\epsilon_t</code> but to
<code class="reqn">y_t - \hat{m}(x_t)</code>.
</p>
<p>The point forecasts of the nonparametric trend are simply obtained following
the proposal by Fritz et al. (forthcoming) by
</p>
<p style="text-align: center;"><code class="reqn">\hat{m}(x_{n+k}) = \hat{m}(x_n) + Dk(\hat{m}(x_n) -
\hat{m}(x_{n-1})),</code>
</p>

<p>where <code class="reqn">D</code> is a dummy variable that is either equal to the constant value
<code class="reqn">1</code> or <code class="reqn">0</code>. Consequently, if <code class="reqn">D = 0</code>,
<code class="reqn">\hat{m}(x_{n})</code>, i.e., the last trend estimate, is
used as a constant estimate for the future. However, if <code class="reqn">D = 1</code>, the
trend is extrapolated linearly. The point forecast for the whole component
model is then given by
</p>
<p style="text-align: center;"><code class="reqn">\hat{y}_{n+k} = \hat{m}(x_{n+k}) + \hat{\epsilon}_{n+k},</code>
</p>

<p>i.e., it is equal to the sum of the point forecasts of the individual
components.
</p>
<p>Equivalently to the point forecasts, the forecasting intervals are the sum
of the forecasting intervals of the individual components. To simplify the
process, the forecasting error in <code class="reqn">\hat{m}(x_{n+k})</code>,
which is of order <code class="reqn">O(-2/5)</code>, is not considered (see Fritz et al.
(forthcoming)), i.e., only the forecasting intervals with respect to the
rest term <code class="reqn">\epsilon_t</code> will be calculated.
</p>
<p>If the distribution of the innovations is non-normal or generally not further
specified, bootstrapping the forecasting intervals is recommended. If they
are however normally distributed or if it is at least assumed that they are,
the forecasting errors are also approximately normally distributed with a
quickly obtainable variance. For further details on the bootstrapping
method, we refer the readers to <code><a href="#topic+bootCast">bootCast</a></code>, whereas more
information on the calculation under normality can be found at
<code><a href="#topic+normCast">normCast</a></code>.
</p>
<p>In order to apply the function, a <code>smoots</code> object that was generated as
the result of a trend estimation process needs to be passed to the argument
<code>obj</code>. The arguments <code>p</code> and <code>q</code> represent the orders of the
of the ARMA(<code class="reqn">p,q</code>) model that the error term
<code class="reqn">\epsilon_t</code> is assumed to follow. If both arguments are
set to <code>NULL</code>, which is the default setting, orders will be selected
according to the Bayesian Information Criterion (BIC) for all possible
combinations of <code class="reqn">p,q = 0, 1, ..., 5</code>. Furthermore, the forecasting
horizon can be adjusted by means of the argument <code>h</code>, so that point
forecasts and forecasting intervals will be obtained for all time points
<code class="reqn">n + 1, n + 2, ..., n + h</code>.
</p>
<p>The function also allows for two calculation approaches for the forecasting
intervals. Via the argument <code>method</code>, intervals
can be obtained under the assumption that the ARMA innovations are normally
distributed (<code>method = "norm"</code>). Alternatively, bootstrapped intervals
can be obtained for unknown innovation distributions that are clearly
non-Gaussian (<code>method = "boot"</code>).
</p>
<p>Another argument is <code>alpha</code>. By passing a value
to this argument, the (<code class="reqn">100</code><code>alpha</code>)-percent confidence level for
the forecasting intervals can be defined. If <code>method = "boot"</code> is
selected, the additional arguments <code>it</code> and <code>n.start</code> can be
adjusted. More specifically, <code>it</code> regulates the number of iterations of
the bootstrap, whereas <code>n.start</code> sets the number of 'burn-in'
observations in the simulated ARMA processes within the bootstrap that are
omitted.
</p>
<p>Since this bootstrap approach for <code>method = "boot"</code> generally needs a
lot of computation time, especially for
series with high numbers of observations and when fitting models with many
parameters, parallel computation of the bootstrap iterations is enabled.
With <code>cores</code>, the number of cores can be defined with an integer.
Nonetheless, for <code>cores = NULL</code>, no cluster is created and therefore
the parallel computation is disabled. Note that the bootstrapped results are
fully reproducible for all cluster sizes. The progress of the bootstrap can
be observed in the R console, where a progress bar and the estimated
remaining time are displayed for <code>pb = TRUE</code>.
</p>
<p>Moreover, the argument <code>np.fcast</code> allows to set the forecasting method
for the nonparametric trend function. As previously discussed, the two
options are a linear extrapolation of the trend (<code>np.fcast = "lin"</code>) and
a constant continuation of the last estimated value of the trend
(<code>np.fcast = "const"</code>).
</p>
<p>The function also implements the option to automatically create a plot of
the forecasting results for <code>plot = TRUE</code>. This includes the feature
to pass additional arguments of the standard plot function to
<code>modelCast</code> (see also the section 'Examples').
</p>
<p>NOTE:
</p>
<p>Within this function, the <code><a href="stats.html#topic+arima">arima</a></code> function of the
<code>stats</code> package with its method <code>"CSS-ML"</code> is used throughout
for the estimation of ARMA models. Furthermore, to increase the performance,
C++ code via the <code><a href="Rcpp.html#topic+Rcpp-package">Rcpp</a></code> and
<code><a href="RcppArmadillo.html#topic+RcppArmadillo-package">RcppArmadillo</a></code> packages was
implemented. Also, the <code><a href="future.html#topic+multisession">future</a></code> and
<code><a href="future.apply.html#topic+future.apply-package">future.apply</a></code> packages are
considered for parallel computation of bootstrap iterations. The progress
of the bootstrap is shown via the
<code><a href="progressr.html#topic+progressr-package">progressr</a></code> package.
</p>


<h3>Value</h3>

<p>The function returns a <code class="reqn">3</code> by <code class="reqn">h</code> matrix with its columns
representing the future time points and the point forecasts, the lower
bounds of the forecasting intervals and the upper bounds of the
forecasting intervals as the rows. If the argument <code>plot</code> is set to
<code>TRUE</code>, a plot of the forecasting results is created.
</p>
<p>#'If <code>export.error = TRUE</code> is selected, a list with the following
elements is returned instead.
</p>

<dl>
<dt>fcast</dt><dd><p>the <code class="reqn">3</code> by <code class="reqn">h</code> forecasting matrix with point forecasts
and bounds of the forecasting intervals.</p>
</dd>
<dt>error</dt><dd><p>an <code>it</code> by <code class="reqn">h</code> matrix, where each column
represents a future time point <code class="reqn">n + 1, n + 2, ..., n + h</code>; in each column
the respective <code>it</code> simulated forecasting errors are saved.</p>
</dd>
</dl>



<h3>Author(s)</h3>


<ul>
<li><p> Yuanhua Feng (Department of Economics, Paderborn University), <br />
Author of the Algorithms <br />
Website: <a href="https://wiwi.uni-paderborn.de/en/dep4/feng/">https://wiwi.uni-paderborn.de/en/dep4/feng/</a>
</p>
</li>
<li><p> Dominik Schulz (Research Assistant) (Department of Economics, Paderborn
University), <br />
Package Creator and Maintainer
</p>
</li></ul>



<h3>References</h3>

<p>Beran, J. and Feng, Y. (2002). Local polynomial fitting with long-memory,
short-memory and antipersistent errors. Annals of the Institute of
Statistical Mathematics, 54(2), 291-311.
</p>
<p>Feng, Y., Gries, T. and Fritz, M. (2020). Data-driven
local polynomial for the trend and its derivatives in economic time
series. Journal of Nonparametric Statistics, 32:2, 510-533.
</p>
<p>Feng, Y., Gries, T., Letmathe, S. and Schulz, D. (2019). The smoots package
in R for semiparametric modeling of trend stationary time series. Discussion
Paper. Paderborn University. Unpublished.
</p>
<p>Feng, Y., Gries, T., Fritz, M., Letmathe, S. and Schulz, D. (2020).
Diagnosing the trend and bootstrapping the forecasting intervals using a
semiparametric ARMA. Discussion Paper. Paderborn University. Unpublished.
</p>
<p>Fritz, M., Forstinger, S., Feng, Y., and Gries, T. (forthcoming).
Forecasting economic growth processes for developing economies.
Unpublished.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
X &lt;- log(smoots::gdpUS$GDP)
NPest &lt;- smoots::msmooth(X)
modelCast(NPest, h = 5, plot = TRUE, xlim = c(261, 295), type = "b",
 col = "deepskyblue4", lty = 3, pch = 20, main = "Exemplary title")


</code></pre>

<hr>
<h2 id='msmooth'>Data-driven Nonparametric Regression for the Trend in Equidistant Time
Series</h2><span id='topic+msmooth'></span>

<h3>Description</h3>

<p>This function runs an iterative plug-in algorithm to find the optimal
bandwidth for the estimation of the nonparametric trend in equidistant
time series (with short memory errors) and then employs the resulting
bandwidth via either local polynomial or kernel regression.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>msmooth(
  y,
  p = c(1, 3),
  mu = c(0, 1, 2, 3),
  bStart = 0.15,
  alg = c("A", "B", "N", "NA", "NAM", "NM", "O", "OA", "OAM", "OM"),
  method = c("lpr", "kr")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="msmooth_+3A_y">y</code></td>
<td>
<p>a numeric vector that contains the input time series ordered from
past to present.</p>
</td></tr>
<tr><td><code id="msmooth_+3A_p">p</code></td>
<td>
<p>an integer <code>1</code> (local linear regression) or <code>3</code> (local
cubic regression); represents the order of polynomial within the local
polynomial regression (see also the 'Details' section); is set to <code>1</code>
by default; is automatically set to <code>1</code> if <code>method = "kr"</code>.</p>
</td></tr>
<tr><td><code id="msmooth_+3A_mu">mu</code></td>
<td>
<p>an integer <code>0</code>, ..., <code>3</code> that represents the smoothness
parameter of the kernel weighting function and thus defines the kernel
function that will be used within the local polynomial regression; is set
to <code>1</code> by default.
</p>

<table>
<tr>
 <td style="text-align: center;">
<strong>Number</strong> </td><td style="text-align: left;"> <strong>Kernel</strong></td>
</tr>
<tr>
 <td style="text-align: center;">
<code>0</code> </td><td style="text-align: left;"> Uniform Kernel</td>
</tr>
<tr>
 <td style="text-align: center;">
<code>1</code> </td><td style="text-align: left;"> Epanechnikov Kernel</td>
</tr>
<tr>
 <td style="text-align: center;">
<code>2</code> </td><td style="text-align: left;"> Bisquare Kernel</td>
</tr>
<tr>
 <td style="text-align: center;">
<code>3</code> </td><td style="text-align: left;"> Triweight Kernel
</td>
</tr>

</table>
</td></tr>
<tr><td><code id="msmooth_+3A_bstart">bStart</code></td>
<td>
<p>a numeric object that indicates the starting value of the
bandwidth for the iterative process; should be <code class="reqn">&gt; 0</code>; is set to
<code>0.15</code> by default.</p>
</td></tr>
<tr><td><code id="msmooth_+3A_alg">alg</code></td>
<td>
<p>a control parameter (as character) that indicates the
corresponding algorithm used (set to <code>"A"</code> by default for <code>p = 1</code>
and to <code>"B"</code> for <code>p = 3</code>).
</p>

<table>
<tr>
 <td style="text-align: center;">
<strong>Algorithm</strong> </td><td style="text-align: left;"> <strong>Description</strong></td>
</tr>
<tr>
 <td style="text-align: center;">
<code>"A"</code> </td><td style="text-align: left;"> Nonparametric estimation of the variance factor with an
enlarged bandwidth, optimal inflation rate</td>
</tr>
<tr>
 <td style="text-align: center;">
<code>"B"</code> </td><td style="text-align: left;"> Nonparametric estimation of the variance factor with an
enlarged bandwidth, naive inflation rate </td>
</tr>
<tr>
 <td style="text-align: center;">
<code>"O"</code> </td><td style="text-align: left;"> Nonparametric estimation of the variance factor, optimal
inflation rate</td>
</tr>
<tr>
 <td style="text-align: center;">
<code>"N"</code> </td><td style="text-align: left;"> Nonparametric estimation of the variance factor, naive
inflation rate</td>
</tr>
<tr>
 <td style="text-align: center;">
<code>"OAM"</code> </td><td style="text-align: left;"> Estimation of the variance factor with
ARMA(<code class="reqn">p,q</code>)-models, optimal inflation rate</td>
</tr>
<tr>
 <td style="text-align: center;">
<code>"NAM"</code> </td><td style="text-align: left;"> Estimation of the variance factor with
ARMA(<code class="reqn">p,q</code>)-models, naive inflation rate</td>
</tr>
<tr>
 <td style="text-align: center;">
<code>"OA"</code> </td><td style="text-align: left;"> Estimation of the variance factor with
AR(<code class="reqn">p</code>)-models, optimal inflation rate</td>
</tr>
<tr>
 <td style="text-align: center;">
<code>"NA"</code> </td><td style="text-align: left;"> Estimation of the variance factor with
AR(<code class="reqn">p</code>)-models, naive inflation rate</td>
</tr>
<tr>
 <td style="text-align: center;">
<code>"OM"</code> </td><td style="text-align: left;"> Estimation of the variance factor with
MA(<code class="reqn">q</code>)-models, optimal inflation rate</td>
</tr>
<tr>
 <td style="text-align: center;">
<code>"NM"</code> </td><td style="text-align: left;"> Estimation of the variance factor with
MA(<code class="reqn">q</code>)-models, naive inflation rate
</td>
</tr>

</table>

<p>It is proposed to use <code>alg = "A"</code> in combination with <code>p = 1</code>.
If the user finds that the chosen bandwidth by algorithm <code>"A"</code> is too
small, <code>alg = "B"</code> with preferably <code>p = 3</code> is suggested. For more
information on the components of the different algorithms, please consult
<code><a href="#topic+tsmooth">tsmooth</a></code>.</p>
</td></tr>
<tr><td><code id="msmooth_+3A_method">method</code></td>
<td>
<p>the smoothing approach; <code>"lpr"</code> represents the local
polynomial regression, whereas <code>"kr"</code> implements a kernel regression;
is set to <code>"lpr"</code> by default.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The trend is estimated based on the additive
nonparametric regression model for an equidistant time series
</p>
<p style="text-align: center;"><code class="reqn">y_t = m(x_t) + \epsilon_t,</code>
</p>

<p>where <code class="reqn">y_t</code> is the observed time series, <code class="reqn">x_t</code> is the rescaled time
on the interval <code class="reqn">[0, 1]</code>, <code class="reqn">m(x_t)</code> is a smooth and deterministic
trend function and <code class="reqn">\epsilon_t</code> are stationary errors with
<code class="reqn">E(\epsilon_t) = 0</code> and short-range dependence (see also Beran and Feng,
2002). With this function <code class="reqn">m(x_t)</code> can be estimated without a parametric
model assumption for the error series. Thus, after estimating and removing
the trend, any suitable parametric model, e.g. an ARMA(<code class="reqn">p,q</code>) model, can
be fitted to the residuals (see <code><a href="stats.html#topic+arima">arima</a></code>).
</p>
<p>The iterative-plug-in (IPI) algorithm, which numerically minimizes the
Asymptotic Mean Squared Error (AMISE), was proposed by Feng, Gries
and Fritz (2020).
</p>
<p>Define <code class="reqn">I[m^{(k)}] = \int_{c_b}^{d_b} [m^{(k)}(x)]^2 dx</code>, <code class="reqn">\beta_{(\nu, k)} = \int_{-1}^{1} u^k
K_{(\nu, k)}(u) du</code>
and <code class="reqn">R(K) = \int_{-1}^{1} K_{(\nu, k)}^{2}(u) du</code>, where <code class="reqn">p</code> is the order of the polynomial,
<code class="reqn">k = p + 1</code> is the order of the asymptotically equivalent kernel,
<code class="reqn">\nu</code> is the order of the trend function's derivative, <code class="reqn">0 \leq c_{b}
&lt; d_{b} \leq 1</code>, <code class="reqn">c_f</code> is the variance factor and
<code class="reqn">K_{(\nu, k)}(u)</code> the <code class="reqn">k</code>-th order equivalent kernel
obtained for the estimation of <code class="reqn">m^{(\nu)}</code> in the interior.
<code class="reqn">m^{(\nu)}</code> is the <code class="reqn">\nu</code>-th order derivative (<code class="reqn">\nu = 0,
1, 2, ...</code>) of the nonparametric trend.
</p>
<p>Furthermore, we define
</p>
<p style="text-align: center;"><code class="reqn">C_{1} = \frac{I[m^{(k)}] \beta_{(\nu, k)}^2}{(k!)^2}</code>
</p>

<p>and
</p>
<p style="text-align: center;"><code class="reqn">C_{2} = \frac{2 \pi c_{f} (d_b - c_b) R(K)}{nh^{2 \nu + 1}}</code>
</p>

<p>with <code class="reqn">h</code> being the bandwidth and <code class="reqn">n</code> being the number of
observations. The AMISE is then
</p>
<p style="text-align: center;"><code class="reqn">AMISE(h) = h^{2(k-\nu)}C_{1} + C_{2}.</code>
</p>

<p>The function calculates suitable estimates for <code class="reqn">c_f</code>, the variance
factor, and <code class="reqn">I[m^{(k)}]</code> over different iterations. In each
iteration, a bandwidth is obtained in accordance with the AMISE that once
more serves as an input for the following iteration. The process repeats
until either convergence or the 40th iteration is reached. For further
details on the asymptotic theory or the algorithm, please consult Feng,
Gries and Fritz (2020) or Feng et al. (2019).
</p>
<p>To apply the function, only few arguments are needed: a data input <code>y</code>,
an order of polynomial <code>p</code>, a kernel function defined by the smoothness
parameter <code>mu</code>, a starting value for the relative bandwidth
<code>bStart</code> and a final smoothing method <code>method</code>.
In fact, aside from the input vector <code>y</code>, every argument has a default
setting that can be adjusted for the individual case. It is recommended to
initially use the default values for <code>p</code>, <code>alg</code> and
<code>bStart</code> and adjust them in the rare case of the resulting optimal
bandwidth being either too small or too large. Theoretically, the
initial bandwidth does not affect the selected optimal bandwidth. However, in
practice local minima of the AMISE might exist and influence the selected
bandwidth. Therefore, the default setting is <code>bStart = 0.15</code>, which is a
compromise between the starting values <code>bStart = 0.1</code> for <code>p = 1</code>
and <code>bStart = 0.2</code> for <code>p = 3</code> that were proposed by Feng, Gries
and Fritz (2020). In the rare case of a clearly unsuitable optimal bandwidth,
a starting bandwidth that differs from the default value is a first
possible approach to obtain a better result. Other argument adjustments can
be tried as well. For more specific information on the input arguments
consult the section <em>Arguments</em>.
</p>
<p>When applying the function, an optimal bandwidth is obtained based on the
IPI algorithm proposed by Feng, Gries and Fritz (2020). In a second step,
the nonparametric trend of the series is calculated with respect
to the chosen bandwidth and the selected regression method (<code>lpf</code> or
<code>kr</code>). It is notable that <code>p</code> is automatically set to 1 for
<code>method = "kr"</code>. The output object is then a list that contains, among
other components, the original time series, the estimated trend values and
the series without the trend.
</p>
<p>The default print method for this function delivers key numbers such as
the iteration steps and the generated optimal bandwidth rounded to the fourth
decimal. The exact numbers and results such as the estimated nonparametric
trend series are saved within the output object and can be addressed via the
<code>$</code> sign.
</p>
<p>NOTE:
</p>
<p>With package version 1.1.0, this function implements C++ code by means
of the <code><a href="Rcpp.html#topic+Rcpp-package">Rcpp</a></code> and
<code><a href="RcppArmadillo.html#topic+RcppArmadillo-package">RcppArmadillo</a></code> packages for
better performance.
</p>


<h3>Value</h3>

<p>The function returns a list with different components:
</p>

<dl>
<dt>AR.BIC</dt><dd><p>the Bayesian Information Criterion of the optimal AR(<code class="reqn">p</code>)
model when estimating the variance factor via autoregressive models
(if calculated; calculated for <code>alg = "OA"</code> and <code>alg = "NA"</code>).</p>
</dd>
<dt>ARMA.BIC</dt><dd><p>the Bayesian Information Criterion of the optimal
ARMA(<code class="reqn">p,q</code>) model when estimating the variance factor via
autoregressive-moving-average models (if calculated; calculated for
<code>alg = "OAM"</code> and <code>alg = "NAM"</code>).</p>
</dd>
<dt>cb</dt><dd><p>the percentage of omitted observations on each side of the
observation period; always equal to 0.05.</p>
</dd>
<dt>b0</dt><dd><p>the optimal bandwidth chosen by the IPI-algorithm.</p>
</dd>
<dt>bb</dt><dd><p>the boundary bandwidth method used within the IPI; always equal to
1.</p>
</dd>
<dt>bStart</dt><dd><p>the starting value of the (relative) bandwidth; input
argument.</p>
</dd>
<dt>bvc</dt><dd><p>indicates whether an enlarged bandwidth was used for the variance
factor estimation or not; depends on the chosen algorithm.</p>
</dd>
<dt>cf0</dt><dd><p>the estimated variance factor; in contrast to the definitions
given in the <em>Details</em> section, this object actually contains an
estimated value of <code class="reqn">2\pi c_f</code>, i.e. it corresponds to the estimated sum
of autocovariances.</p>
</dd>
<dt>cf0.AR</dt><dd><p>the estimated variance factor obtained by estimation of
autoregressive models (if calculated; <code>alg = "OA"</code> or <code>"NA"</code>).</p>
</dd>
<dt>cf0.ARMA</dt><dd><p>the estimated variance factor obtained by estimation of
autoregressive-moving-average models (if calculated; calculated for
<code>alg = "OAM"</code> and <code>alg = "NAM"</code>).</p>
</dd>
<dt>cf0.LW</dt><dd><p>the estimated variance factor obtained by Lag-Window Spectral
Density Estimation following Bühlmann (1996) (if calculated; calculated for
algorithms <code>"A"</code>, <code>"B"</code>, <code>"O"</code> and <code>"N"</code>).</p>
</dd>
<dt>cf0.MA</dt><dd><p>the estimated variance factor obtained by estimation of
moving-average models (if calculated; calculated for <code>alg = "OM"</code> and
<code>alg = "NM"</code>).</p>
</dd>
<dt>I2</dt><dd><p>the estimated value of <code class="reqn">I[m^{(k)}]</code>.</p>
</dd>
<dt>InfR</dt><dd><p>the setting for the inflation rate according to the chosen
algorithm.</p>
</dd>
<dt>iterations</dt><dd><p>the bandwidths of the single iterations steps</p>
</dd>
<dt>L0.opt</dt><dd><p>the optimal bandwidth for the lag-window spectral density
estimation (if calculated; calculated for algorithms <code>"A"</code>, <code>"B"</code>,
<code>"O"</code> and <code>"N"</code>).</p>
</dd>
<dt>MA.BIC</dt><dd><p>the Bayesian Information Criterion of the optimal MA(<code class="reqn">q</code>)
model when estimating the variance factor via moving-average models (if
calculated; calculated for <code>alg = "OM"</code> and <code>alg = "NM"</code>).</p>
</dd>
<dt>Mcf</dt><dd><p>the estimation method for the variance factor estimation; depends
on the chosen algorithm.</p>
</dd>
<dt>mu</dt><dd><p>the smoothness parameter of the second order kernel; input
argument.</p>
</dd>
<dt>n</dt><dd><p>the number of observations.</p>
</dd>
<dt>niterations</dt><dd><p>the total number of iterations until convergence.</p>
</dd>
<dt>orig</dt><dd><p>the original input series; input argument.</p>
</dd>
<dt>p.BIC</dt><dd><p>the order p of the optimal AR(<code class="reqn">p</code>) or ARMA(<code class="reqn">p,q</code>) model
when estimating the variance factor via autoregressive or
autoregressive-moving average models (if calculated; calculated for
<code>alg = "OA"</code>, <code>alg = "NA"</code>, <code>alg = "OAM"</code> and
<code>alg = "NAM"</code>).</p>
</dd>
<dt>p</dt><dd><p>the order of polynomial used in the IPI-algorithm; also used for the
final smoothing, if <code>method = "lpr"</code>; input argument.</p>
</dd>
<dt>q.BIC</dt><dd><p>the order <code class="reqn">q</code> of the optimal MA(<code class="reqn">q</code>) or ARMA(<code class="reqn">p,q</code>)
model when estimating the variance factor via moving-average or
autoregressive-moving average models (if calculated; calculated for
<code>alg = "OM"</code>,
<code>alg = "NM"</code>, <code>alg = "OAM"</code> and <code>alg = "NAM"</code>).</p>
</dd>
<dt>res</dt><dd><p>the estimated residual series.</p>
</dd>
<dt>v</dt><dd><p>the considered order of derivative of the trend; is always zero for
this function.</p>
</dd>
<dt>ws</dt><dd><p>the weighting system matrix used within the local polynomial
regression; this matrix is a condensed version of a complete weighting system
matrix; in each row of <code>ws</code>, the weights for conducting the smoothing
procedure at a specific observation time point can be found; the first
<code class="reqn">[nb + 0.5]</code> rows, where <code class="reqn">n</code> corresponds to the number of
observations, <code class="reqn">b</code> is the bandwidth considered for smoothing and
<code class="reqn">[.]</code> denotes the integer part, contain the weights at the
<code class="reqn">[nb + 0.5]</code> left-hand boundary points; the weights in row
<code class="reqn">[nb + 0.5] + 1</code> are representative for the estimation at all
interior points and the remaining rows contain the weights for the right-hand
boundary points; each row has exactly <code class="reqn">2[nb + 0.5] + 1</code> elements,
more specifically the weights for observations of the nearest
<code class="reqn">2[nb + 0.5] + 1</code> time points; moreover, the weights are normalized,
i.e. the weights are obtained under consideration of the time points
<code class="reqn">x_t = t/n</code>, where <code class="reqn">t = 1, 2, ..., n</code>.</p>
</dd>
<dt>ye</dt><dd><p>the nonparametric estimates of the trend.</p>
</dd>
</dl>



<h3>Author(s)</h3>


<ul>
<li><p> Yuanhua Feng (Department of Economics, Paderborn University), <br />
Author of the Algorithms <br />
Website: <a href="https://wiwi.uni-paderborn.de/en/dep4/feng/">https://wiwi.uni-paderborn.de/en/dep4/feng/</a>
</p>
</li>
<li><p> Dominik Schulz (Research Assistant) (Department of Economics, Paderborn
University), <br />
Package Creator and Maintainer
</p>
</li></ul>



<h3>References</h3>

<p>Beran, J. and Feng, Y. (2002). Local polynomial fitting with long-memory,
short-memory and antipersistent errors. Annals of the Institute of
Statistical Mathematics, 54(2), 291-311.
</p>
<p>Bühlmann, P. (1996). Locally adaptive lag-window spectral estimation.
Journal of Time Series Analysis, 17(3), 247-270.
</p>
<p>Feng, Y., Gries, T. and Fritz, M. (2020). Data-driven
local polynomial for the trend and its derivatives in economic time
series. Journal of Nonparametric Statistics, 32:2, 510-533.
</p>
<p>Feng, Y., Gries, T., Letmathe, S. and Schulz, D. (2019). The smoots package
in R for semiparametric modeling of trend stationary time series. Discussion
Paper. Paderborn University. Unpublished.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>### Example 1: US-GDP ###

# Logarithm of test data
# -&gt; the logarithm of the data is assumed to follow the additive model
test_data &lt;- gdpUS
y &lt;- log(test_data$GDP)

# Applied msmooth function for the trend
results &lt;- msmooth(y, p = 1, mu = 1, bStart = 0.1, alg = "A", method = "lpr")
res &lt;- results$res
ye &lt;- results$ye

# Plot of the results
t &lt;- seq(from = 1947, to = 2019.25, by = 0.25)
matplot(t, cbind(y, ye), type = "ll", lty = c(3, 1), col = c(1, "red"),
 xlab = "Years", ylab = "Log-Quartlery US-GDP",
 main = "Log-Quarterly US-GDP vs. Trend, Q1 1947 - Q2 2019")
legend("bottomright", legend = c("Original series", "Estimated trend"),
 fill = c(1, "red"), cex = 0.7)
results

## Not run: 
### Example 2: German Stock Index ###

# The following procedure can be considered, if (log-)returns are assumed
# to follow a model from the general class of semiparametric GARCH-type
# models (including Semi-GARCH, Semi-Log-GARCH and Semi-APARCH models among
# others) with a slowly changing variance over time due to a deterministic,
# nonparametric scale function.

# Obtain the logarithm of the squared returns
returns &lt;- diff(log(dax$Close))   # (log-)returns
rt &lt;- returns - mean(returns)     # demeaned (log-)returns
yt &lt;- log(rt^2)                   # logarithm of the squared returns

# Apply 'smoots' function to the log-data, because the logarithm of
# the squared returns follows an additive model with a nonparametric trend
# function, if the returns are assumed to follow a semiparametric GARCH-type
# model.

# In this case, the setting 'alg = "A"' is used in combination with p = 3, as
# the resulting estimates appear to be more suitable than for 'alg = "B"'.
est &lt;- msmooth(yt, p = 3, alg = "A")
m_xt &lt;- est$ye                    # estimated trend values

# Obtain the standardized returns 'eps' and the scale function 'scale.f'
res &lt;- est$res                    # the detrended log-data
C &lt;- -log(mean(exp(res)))         # an estimate of a constant value needed
                                  # for the retransformation
scale.f &lt;- exp((m_xt - C) / 2)    # estimated values of the scale function in
                                  # the returns
eps &lt;- rt / scale.f               # the estimated standardized returns

# -&gt; 'eps' can now be analyzed by any suitable GARCH-type model.
#    The total volatilities are then the product of the conditional
#    volatilities obtained from 'eps' and the scale function 'scale.f'.

## End(Not run)
</code></pre>

<hr>
<h2 id='normCast'>Forecasting Function for ARMA Models under Normally Distributed Innovations</h2><span id='topic+normCast'></span>

<h3>Description</h3>

<p>Point forecasts and the respective forecasting intervals for autoregressive-
moving-average (ARMA) models can be calculated, the latter under the
assumption of normally distributed innovations, by means of this function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>normCast(
  X,
  p = NULL,
  q = NULL,
  include.mean = FALSE,
  h = 1,
  alpha = 0.95,
  plot = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="normCast_+3A_x">X</code></td>
<td>
<p>a numeric vector that contains the time series that is assumed to
follow an ARMA model ordered from past to present.</p>
</td></tr>
<tr><td><code id="normCast_+3A_p">p</code></td>
<td>
<p>an integer value <code class="reqn">&gt;= 0</code> that defines the AR order <code class="reqn">p</code> of the
underlying ARMA(<code class="reqn">p,q</code>) model within <code>X</code>; is set to <code>NULL</code> by
default; if no value is passed to <code>p</code> but one is passed to <code>q</code>,
<code>p</code> is set to <code>0</code>; if both <code>p</code> and <code>q</code> are <code>NULL</code>,
optimal orders following the BIC for <code class="reqn">0 \leq p,q \leq 5</code>
are chosen; is set to <code>NULL</code> by default; decimal numbers will be rounded
off to integers.</p>
</td></tr>
<tr><td><code id="normCast_+3A_q">q</code></td>
<td>
<p>an integer value <code class="reqn">&gt;= 0</code> that defines the MA order <code class="reqn">q</code> of the
underlying ARMA(<code class="reqn">p,q</code>) model within <code>X</code>; is set to <code>NULL</code> by
default; if no value is passed to <code>q</code> but one is passed to <code>p</code>,
<code>q</code> is set to <code>0</code>; if both <code>p</code> and <code>q</code> are <code>NULL</code>,
optimal orders following the BIC for <code class="reqn">0 \leq p,q \leq 5</code>
are chosen; is set to <code>NULL</code> by default; decimal numbers will be rounded
off to integers.</p>
</td></tr>
<tr><td><code id="normCast_+3A_include.mean">include.mean</code></td>
<td>
<p>a logical value; if set to <code>TRUE</code>, the mean of the
series is also estimated; if set to <code>FALSE</code>,
<code class="reqn">E(X_t) = 0</code> is assumed; is set to <code>FALSE</code> by default.</p>
</td></tr>
<tr><td><code id="normCast_+3A_h">h</code></td>
<td>
<p>an integer that represents the forecasting horizon; if <code class="reqn">n</code> is
the number of observations, point forecasts and forecasting intervals will be
obtained for the time points <code class="reqn">n + 1</code> to <code class="reqn">n + h</code>; is set to <code>1</code>
by default; decimal numbers will be rounded off to integers.</p>
</td></tr>
<tr><td><code id="normCast_+3A_alpha">alpha</code></td>
<td>
<p>a numeric vector of length 1 with <code class="reqn">0 &lt;</code> <code>alpha</code>
<code class="reqn">&lt; 1</code>; the forecasting intervals will be obtained based on the confidence
level (<code class="reqn">100</code><code>alpha</code>)-percent; is set to <em>alpha = 0.95</em> by
default, i.e., a <code class="reqn">95</code>-percent confidence level.</p>
</td></tr>
<tr><td><code id="normCast_+3A_plot">plot</code></td>
<td>
<p>a logical value that controls the graphical output; for
<code>plot = TRUE</code>, the original series with the obtained point forecasts
as well as the forecasting intervals will be plotted; for the default
<code>plot = FALSE</code>, no plot will be created.</p>
</td></tr>
<tr><td><code id="normCast_+3A_...">...</code></td>
<td>
<p>additional arguments for the standard plot function, e.g.,
<code>xlim</code>, <code>type</code>, ... ; arguments with respect to plotted graphs,
e.g., the argument <code>col</code>, only affect the original series <code>X</code>;
please note that in accordance with the argument <code>x</code> (lower case) of the
standard plot function, an additional numeric vector with time points can be
implemented via the argument <code>x</code> (lower case). <code>x</code> should be
valid for the sample observations only, i.e.
<code>length(x) == length(X)</code> should be <code>TRUE</code>, as future time
points will be calculated automatically.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is part of the <code>smoots</code> package and was implemented under
version 1.1.0. For a given time series <code class="reqn">X_[t]</code>, <code class="reqn">t = 1, 2, ..., n</code>,
the point forecasts and the respective forecasting intervals will be
calculated.
It is assumed that the series follows an ARMA(<code class="reqn">p,q</code>) model
</p>
<p style="text-align: center;"><code class="reqn">X_t - \mu = \epsilon_t + \beta_1 (X_{t-1} - \mu) + ... + \beta_p
(X_{t-p} - \mu) + \alpha_1 \epsilon_{t-1} + ... + \alpha_{q}
\epsilon_{t-q},</code>
</p>

<p>where <code class="reqn">\alpha_j</code> and <code class="reqn">\beta_i</code> are real
numbers (for <code class="reqn">i = 1, 2, .., p</code> and <code class="reqn">j = 1, 2, ..., q</code>) and
<code class="reqn">\epsilon_t</code> are i.i.d. (identically and independently
distributed) random variables with zero mean and constant variance.
<code class="reqn">\mu</code> is equal to <code class="reqn">E(X_t)</code>.
</p>
<p>The point forecasts and forecasting intervals for the future periods
<code class="reqn">n + 1, n + 2, ..., n + h</code> will be obtained. With respect to the point
forecasts <code class="reqn">\hat{X}_{n + k}</code>, where <code class="reqn">k = 1, 2, ..., h</code>,
</p>
<p style="text-align: center;"><code class="reqn">\hat{X}_{n + k} = \hat{\mu} + \sum_{i = 1}^{p} \hat{\beta}_{i}
(X_{n + k - i} - \hat{\mu}) + \sum_{j = 1}^{q} \hat{\alpha}_{j}
\hat{\epsilon}_{n + k - j}</code>
</p>

<p>with <code class="reqn">X_{n+k-i} = \hat{X}_{n+k-i}</code> for
<code class="reqn">n+k-i &gt; n</code> and
<code class="reqn">\hat{\epsilon}_{n+k-j} = E(\epsilon_t) = 0</code> for <code class="reqn">n+k-j &gt; n</code> will be applied.
</p>
<p>The forecasting intervals on the other hand are obtained under the assumption
of normally distributed innovations. Let <code class="reqn">q(c)</code> be the <code class="reqn">100c</code>-percent
quantile of the standard normal distribution. The <code class="reqn">100a</code>-percent
forecasting interval at a point <code class="reqn">n + k</code>, where <code class="reqn">k = 1, 2, ..., h</code>,
is given by
</p>
<p style="text-align: center;"><code class="reqn">[\hat{X}_{n+k} - q(a_r)s_k, \hat{X}_{n+k} + q(a_r)s_k]</code>
</p>

<p>with <code class="reqn">s_k</code> being the standard deviation of the forecasting error
at the time point <code class="reqn">n + k</code> and with
<code class="reqn">a_r = 1 - (1 - a)/2</code>. For ARMA models with normal
innovations, the variance of the forecasting error can be derived from the
MA(<code class="reqn">\infty</code>) representation of  the model. It is
</p>
<p style="text-align: center;"><code class="reqn">\sigma_{\epsilon}^{2} \sum_{i=0}^{k - 1} d_{i}^{2},</code>
</p>

<p>where <code class="reqn">d_i</code> are the coefficients of the MA(<code class="reqn">\infty</code>)
representation and <code class="reqn">\sigma_{\epsilon}^{2}</code> is the
innovation variance.
</p>
<p>The function <code>normCast</code> allows for different adjustments to
the forecasting progress. At first, a vector with the values of the observed
time series ordered from past to present has to be passed to the argument
<code>X</code>. Orders <code class="reqn">p</code> and <code class="reqn">q</code> of the underlying ARMA process can be
defined via the arguments <code>p</code> and <code>q</code>. If only one of these orders
is inserted by the user, the other order is automatically set to <code>0</code>. If
none of these arguments are defined, the function will choose orders based on
the Bayesian Information Criterion (BIC) for <code class="reqn">0 \leq p,q \leq 5</code>. Via the logical argument <code>include.mean</code> the user can decide,
whether to consider the mean of the series within the estimation process.
Furthermore, the argument <code>h</code> allows for the definition of the maximum
future time point <code class="reqn">n + h</code>. Point forecasts and forecasting intervals will
be returned for the time points <code class="reqn">n + 1</code> to <code class="reqn">n + h</code>. Another argument
is <code>alpha</code>, which is the equivalent of the confidence level considered
within the calculation of the forecasting intervals, i.e., the quantiles
<code class="reqn">(1 -</code> <code>alpha</code><code class="reqn">)/2</code> and
<code class="reqn">1 - (1 -</code> <code>alpha</code><code class="reqn">)/2</code> of the
forecasting intervals will be obtained.
</p>
<p>For simplicity, the function also incorporates the possibility to directly
create a plot of the output, if the argument <code>plot</code> is set to
<code>TRUE</code>. By the additional and optional arguments <code>...</code>, further
arguments of the standard plot function can be implemented to shape the
returned plot.
</p>
<p>NOTE:
Within this function, the <code><a href="stats.html#topic+arima">arima</a></code> function of the
<code>stats</code> package with its method <code>"CSS-ML"</code> is used throughout
for the estimation of ARMA models.
</p>


<h3>Value</h3>

<p>The function returns a <code class="reqn">3</code> by <code class="reqn">h</code> matrix with its columns
representing the future time points and the point forecasts, the lower
bounds of the forecasting intervals and the upper bounds of the
forecasting intervals as the rows. If the argument <code>plot</code> is set to
<code>TRUE</code>, a plot of the forecasting results is created.
</p>


<h3>Author(s)</h3>


<ul>
<li><p> Dominik Schulz (Research Assistant) (Department of Economics, Paderborn
University), <br />
Package Creator and Maintainer
</p>
</li></ul>



<h3>References</h3>

<p>Feng, Y., Gries, T. and Fritz, M. (2020). Data-driven
local polynomial for the trend and its derivatives in economic time
series. Journal of Nonparametric Statistics, 32:2, 510-533.
</p>
<p>Feng, Y., Gries, T., Letmathe, S. and Schulz, D. (2019). The smoots package
in R for semiparametric modeling of trend stationary time series. Discussion
Paper. Paderborn University. Unpublished.
</p>
<p>Feng, Y., Gries, T., Fritz, M., Letmathe, S. and Schulz, D. (2020).
Diagnosing the trend and bootstrapping the forecasting intervals using a
semiparametric ARMA. Discussion Paper. Paderborn University. Unpublished.
</p>
<p>Fritz, M., Forstinger, S., Feng, Y., and Gries, T. (2020). Forecasting
economic growth processes for developing economies. Unpublished.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>### Example 1: Simulated ARMA process ###

# Simulation of the underlying process
n &lt;- 2000
n.start = 1000
set.seed(21)
X &lt;- arima.sim(model = list(ar = c(1.2, -0.7), ma = 0.63), n = n,
 rand.gen = rnorm, n.start = n.start) + 7.7

# Application of normCast()
result &lt;- normCast(X = X, p = 2, q = 1, include.mean = TRUE, h = 5,
 plot = TRUE, xlim = c(1971, 2005), col = "deepskyblue4",
 type = "b", lty = 3, pch = 16, main = "Exemplary title")
result
</code></pre>

<hr>
<h2 id='optOrd'>Optimal Order Selection</h2><span id='topic+optOrd'></span>

<h3>Description</h3>

<p>From a matrix with values of an information criterion for different orders
<code class="reqn">p</code> and <code class="reqn">q</code> of an autoregressive-moving-average (ARMA) model, the
optimal orders are selected.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>optOrd(mat, restr = NULL, sFUN = min)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="optOrd_+3A_mat">mat</code></td>
<td>
<p>a numeric matrix, whose rows represent the AR orders
<code class="reqn">p = 0, 1, ..., p_{max}</code> and whose columns
represent the MA orders <code class="reqn">q = 0, 1, q_{max}</code>; the
elements of the matrix are then the values of an information criterion
calculated for ARMA models with the different order combinations; a matrix
returned by the function <code><a href="#topic+critMatrix">critMatrix</a></code> of the <code>smoots</code>
package shares these characteristics.</p>
</td></tr>
<tr><td><code id="optOrd_+3A_restr">restr</code></td>
<td>
<p>a single expression (not a character object) that defines
further restrictions; the standard logical operators, e.g. <code>&gt;=</code>,
<code>&amp;</code> or <code>==</code>, can be used; refer to the rows with <code>p</code> and to
the columns with <code>q</code>; is set to <code>NULL</code> by default, i.e. no
restrictions are imposed.</p>
</td></tr>
<tr><td><code id="optOrd_+3A_sfun">sFUN</code></td>
<td>
<p>the selection function; is set to <code>min</code>, i.e. the minimal
value that meets the restrictions <code>restr</code> is selected and the
corresponding orders <code class="reqn">p</code> and <code class="reqn">q</code> are returned.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Given a matrix <code>mat</code> filled with the values of an information criterion
for different estimated ARMA(<code class="reqn">p,q</code>) models, where the rows represent
different orders <code class="reqn">p = 0, 1, ..., p_{max}</code> and where
the columns represent the orders <code class="reqn">q = 0, 1, ..., q_{max}</code>, the function returns a vector with the optimal orders
<code class="reqn">p</code> and <code class="reqn">q</code>. Further selection restrictions can be passed to the
argument <code>restr</code> as an expression. To implement a restriction, the rows
and columns are addressed via <code>p</code> and <code>q</code>, respectively. Moreover,
standard boolean operators such as <code>==</code>, <code>&gt;=</code> or <code>&amp;</code> can be
used. See the Section <em>Examples</em> for examples of different restrictions.
In many cases, the minimum value of a criterion is considered to indicate
the best model. However, in some other cases a different selection approach
might be appropriate. Therefore, a selection function can be considered by
means of the argument <code>sFUN</code>. The default is <code>sFUN = min</code>, i.e. the
function <code><a href="base.html#topic+Extremes">min</a></code> is applied to select the optimal
orders.
</p>


<h3>Value</h3>

<p>The function returns a vector with two elements. The first element is the
optimal order <code class="reqn">p</code>, whereas the second element is the selected optimal
order <code class="reqn">q</code>.
</p>


<h3>Author(s)</h3>


<ul>
<li><p> Sebastian Letmathe (Scientific Employee) (Department of Economics,
Paderborn University), <br />
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
set.seed(21)
Xt &lt;- arima.sim(model = list(ar = c(1.2, -0.5), ma = 0.7), n = 1000) + 7
mat &lt;- smoots::critMatrix(Xt)
optOrd(mat)  # without restrictions
optOrd(mat, p &lt;= q)  # with one restriction
optOrd(mat, p &gt;= 1 &amp; q &gt;= 4)  # with two restrictions

## End(Not run)

</code></pre>

<hr>
<h2 id='plot.smoots'>Plot Method for the Package 'smoots'</h2><span id='topic+plot.smoots'></span>

<h3>Description</h3>

<p>This function regulates how objects created by the package <code>smoots</code> are
plotted.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'smoots'
plot(x, t = NULL, rescale = TRUE, which = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.smoots_+3A_x">x</code></td>
<td>
<p>an input object of class <code>smoots</code>.</p>
</td></tr>
<tr><td><code id="plot.smoots_+3A_t">t</code></td>
<td>
<p>an optional vector with time points that will be considered for
the x-axis within the plot; is set to NULL by default and uses a vector
<code>1:length(x$ye)</code> for time points.</p>
</td></tr>
<tr><td><code id="plot.smoots_+3A_rescale">rescale</code></td>
<td>
<p>a single logical value; is set to <code>TRUE</code> by default;
if the output of a derivative estimation process is passed to <code>x</code> and if
<code>rescale = TRUE</code>, the estimates will be rescaled according to <code>t</code>.</p>
</td></tr>
<tr><td><code id="plot.smoots_+3A_which">which</code></td>
<td>
<p>a selector for the plot type so that the interactive prompt is
avoided; for the default, <code>which = NULL</code>, the user will be asked
interactively via the console which plot to show; to avoid this behavior,
set <code>which</code> to the corresponding number of the plot you would like
to create (1: original series, 2: trend series, 3: residual series,
4: original series with trend series for trend estimation objects,
1: original series, 2: derivative series for trend derivative estimation
object).</p>
</td></tr>
<tr><td><code id="plot.smoots_+3A_...">...</code></td>
<td>
<p>additional arguments of the standard plot method.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>


<h3>Author(s)</h3>


<ul>
<li><p> Dominik Schulz (Research Assistant) (Department of Economics, Paderborn
University), <br />
Package Creator and Maintainer
</p>
</li></ul>


<hr>
<h2 id='print.smoots'>Print Method for the Package 'smoots'</h2><span id='topic+print.smoots'></span>

<h3>Description</h3>

<p>This function regulates how objects created by the package <code>smoots</code> are
printed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'smoots'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.smoots_+3A_x">x</code></td>
<td>
<p>an input object of class <code>smoots</code>.</p>
</td></tr>
<tr><td><code id="print.smoots_+3A_...">...</code></td>
<td>
<p>included for compatibility; additional arguments will however
not affect the output.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>


<h3>Author(s)</h3>


<ul>
<li><p> Dominik Schulz (Research Assistant) (Department of Economics, Paderborn
University), <br />
Package Creator and Maintainer
</p>
</li></ul>


<hr>
<h2 id='rescale'>Rescaling Derivative Estimates</h2><span id='topic+rescale'></span>

<h3>Description</h3>

<p>The estimation functions of the <code>smoots</code> package estimate the
nonparametric trend function or its derivatives on the rescaled
time interval <code class="reqn">[0, 1]</code>. With this function the derivative estimates can
be rescaled in accordance with a given vector with time points.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rescale(y, x = seq_along(y), v = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rescale_+3A_y">y</code></td>
<td>
<p>a numeric vector or matrix with the derivative estimates obtained
for time points on the interval <code class="reqn">[0, 1]</code>; pass the list element <code>ye</code>
of the output of the functions <code><a href="#topic+dsmooth">dsmooth</a></code> or <code><a href="#topic+gsmooth">gsmooth</a></code>
(if the argument <code>v</code> <code class="reqn">&gt; 0</code>) to this argument.</p>
</td></tr>
<tr><td><code id="rescale_+3A_x">x</code></td>
<td>
<p>a numeric vector of length <code>length(y)</code> with the actual
(equidistant) time points ordered from past to present; the default is
<code>seq_along(y)</code>.</p>
</td></tr>
<tr><td><code id="rescale_+3A_v">v</code></td>
<td>
<p>the order of derivative that is implemented for <code>y</code>; the
default is <code>1</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The derivative estimation process is based on the additive time series model
</p>
<p style="text-align: center;"><code class="reqn">y_t = m(x_t) + \epsilon_t,</code>
</p>

<p>where <code class="reqn">y_t</code> is the observed time series with equidistant design,
<code class="reqn">x_t</code> is the rescaled time on <code class="reqn">[0, 1]</code>, <code class="reqn">m(x_t)</code> is a smooth and
deterministic trend function and <code class="reqn">\epsilon_t</code> are stationary errors
with E(eps_[t]) = 0 (see also Beran and Feng, 2002). Since the estimates of
the main smoothing functions in <code>smoots</code> are obtained with regard to the
rescaled time points <code class="reqn">x_t</code>, the derivative estimates returned by these
functions are valid for <code class="reqn">x_t</code> only. Thus, by passing the returned
estimates to the argument <code>y</code>, a vector with the actual time points to
the argument <code>x</code> and the order of derivative of <code>y</code> to the argument
<code>v</code>, a rescaled estimate series is calculated and returned. The function
can also be combined with the numeric output of <code><a href="#topic+confBounds">confBounds</a></code>.
</p>
<p>Note that the trend estimates, even though they are also obtained for the
rescaled time points <code class="reqn">x_t</code>, are still valid for the actual time points.
</p>


<h3>Value</h3>

<p>A numeric vector with the rescaled derivative estimates is returned.
</p>


<h3>Author(s)</h3>


<ul>
<li><p> Dominik Schulz (Research Assistant) (Department of Economics, Paderborn
University), <br />
Package Creator and Maintainer
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>data &lt;- smoots::gdpUS
Xt &lt;- log(data$GDP)
time &lt;- seq(from = 1947.25, to = 2019.5, by = 0.25)
d_est &lt;- smoots::dsmooth(Xt)
ye_rescale &lt;- smoots::rescale(d_est$ye, x = time, v = 1)
plot(time, ye_rescale, type = "l", main = "", ylab = "", xlab = "Year")

</code></pre>

<hr>
<h2 id='residuals.smoots'>Extract Model Residuals</h2><span id='topic+residuals.smoots'></span>

<h3>Description</h3>

<p>Generic function which extracts model residuals from a <code>smoots</code> class
object. Both <code>residuals</code> and its abbreviated form <code>resid</code> can be called.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'smoots'
residuals(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="residuals.smoots_+3A_object">object</code></td>
<td>
<p>an object from the <code>smoots</code> class.</p>
</td></tr>
<tr><td><code id="residuals.smoots_+3A_...">...</code></td>
<td>
<p>included for consistency with the generic function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Residuals extracted from a <code>smoots</code> class object.
</p>


<h3>Author(s)</h3>


<ul>
<li><p> Sebastian Letmathe (Scientific Employee) (Department of Economics,
Paderborn University), <br />
</p>
</li></ul>


<hr>
<h2 id='rollCast'>Backtesting Semi-ARMA Models with Rolling Forecasts</h2><span id='topic+rollCast'></span>

<h3>Description</h3>

<p>A simple backtest of Semi-ARMA models via rolling forecasts can be
implemented.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rollCast(
  y,
  p = NULL,
  q = NULL,
  K = 5,
  method = c("norm", "boot"),
  alpha = 0.95,
  np.fcast = c("lin", "const"),
  it = 10000,
  n.start = 1000,
  pb = TRUE,
  cores = future::availableCores(),
  argsSmoots = list(),
  plot = TRUE,
  argsPlot = list()
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rollCast_+3A_y">y</code></td>
<td>
<p>a numeric vector that represents the equidistant time series assumed
to follow a Semi-ARMA model; must be ordered from past to present.</p>
</td></tr>
<tr><td><code id="rollCast_+3A_p">p</code></td>
<td>
<p>an integer value <code class="reqn">\geq 0</code> that defines the AR order
<code class="reqn">p</code> of the underlying ARMA(<code class="reqn">p,q</code>) model within <code>X</code>; is set to
<code>NULL</code> by default; if no value is passed to <code>p</code> but one is passed
to <code>q</code>, <code>p</code> is set to <code>0</code>; if both <code>p</code> and <code>q</code> are
<code>NULL</code>, optimal orders following the BIC for
<code class="reqn">0 \leq p,q \leq 5</code> are chosen; is set to <code>NULL</code> by
default; decimal numbers will be rounded off to integers.</p>
</td></tr>
<tr><td><code id="rollCast_+3A_q">q</code></td>
<td>
<p>an integer value <code class="reqn">\geq 0</code> that defines the MA order
<code class="reqn">q</code> of the underlying ARMA(<code class="reqn">p,q</code>) model within <code>X</code>; is set to
<code>NULL</code> by default; if no value is passed to <code>q</code> but one is passed
to <code>p</code>, <code>q</code> is set to <code>0</code>; if both <code>p</code> and <code>q</code> are
<code>NULL</code>, optimal orders following the BIC for
<code class="reqn">0 \leq p,q \leq 5</code> are chosen; is set to <code>NULL</code> by
default; decimal numbers will be rounded off to integers.</p>
</td></tr>
<tr><td><code id="rollCast_+3A_k">K</code></td>
<td>
<p>a single, positive integer value that defines the number of
out-of-sample observations; the last <code>K</code> observations in <code>y</code> are
treated as the out-of-sample observations, whereas the rest of the
observations in <code>y</code> are the in-sample values.</p>
</td></tr>
<tr><td><code id="rollCast_+3A_method">method</code></td>
<td>
<p>a character object; defines the method used for the calculation
of the forecasting intervals; with <code>"norm"</code> the intervals are obtained
under the assumption of normally distributed innovations; with <code>"boot"</code>
the intervals are obtained via a bootstrap; is set to <code>"norm"</code> by
default.</p>
</td></tr>
<tr><td><code id="rollCast_+3A_alpha">alpha</code></td>
<td>
<p>a numeric vector of length 1 with <code class="reqn">0 &lt; </code> <code>alpha</code>
<code class="reqn"> &lt; 1</code>; the forecasting intervals will be obtained based on the
confidence level (<code class="reqn">100</code><code>alpha</code>)-percent; is set to
<code>alpha = 0.95</code> by default, i.e., a <code class="reqn">95</code>-percent confidence level.</p>
</td></tr>
<tr><td><code id="rollCast_+3A_np.fcast">np.fcast</code></td>
<td>
<p>a character object; defines the forecasting method used
for the nonparametric trend; for <code>np.fcast = "lin"</code> the trend is
is extrapolated linearly based on the last two trend estimates; for
<code>np.fcast = "const"</code>, the last trend estimate is used as a constant
estimate for future values; is set to <em>&quot;lin&quot;</em> by default.</p>
</td></tr>
<tr><td><code id="rollCast_+3A_it">it</code></td>
<td>
<p>an integer that represents the total number of iterations, i.e.,
the number of simulated series; is set to <code>10000</code> by default; only
necessary, if <code>method = "boot"</code>; decimal
numbers will be rounded off to integers.</p>
</td></tr>
<tr><td><code id="rollCast_+3A_n.start">n.start</code></td>
<td>
<p>an integer that defines the 'burn-in' number
of observations for the simulated ARMA series via bootstrap; is set to
<code>1000</code> by default; only necessary, if <code>method = "boot"</code>;decimal
numbers will be rounded off to integers.</p>
</td></tr>
<tr><td><code id="rollCast_+3A_pb">pb</code></td>
<td>
<p>a logical value; for <code>pb = TRUE</code>, a progress bar will be shown
in the console, if <code>method = "boot"</code>.</p>
</td></tr>
<tr><td><code id="rollCast_+3A_cores">cores</code></td>
<td>
<p>an integer value &gt;0 that states the number of (logical) cores to
use in the bootstrap (or <code>NULL</code>); the default is the maximum number of
available cores
(via <code><a href="future.html#topic+availableCores">future::availableCores</a></code>); for
<code>cores = NULL</code>, parallel computation is disabled.</p>
</td></tr>
<tr><td><code id="rollCast_+3A_argssmoots">argsSmoots</code></td>
<td>
<p>a list that contains arguments that will be passed to
<code><a href="#topic+msmooth">msmooth</a></code> for the estimation of the nonparametric trend
function; by default, the default values of <code>msmooth</code> are used.</p>
</td></tr>
<tr><td><code id="rollCast_+3A_plot">plot</code></td>
<td>
<p>a logical value that controls the graphical output; for the
default (<code>plot = TRUE</code>), the original series with the obtained point
forecasts as well as the forecasting intervals will be plotted; for
<code>plot = FALSE</code>, no plot will be created.</p>
</td></tr>
<tr><td><code id="rollCast_+3A_argsplot">argsPlot</code></td>
<td>
<p>a list; additional arguments for the standard plot function,
e.g., <code>xlim</code>, <code>type</code>, ..., can be passed to it; arguments with
respect to plotted graphs, e.g., the argument <code>col</code>, only affect the
original series <code>y</code>; please note that in accordance with the argument
<code>x</code> (lower case) of the standard plot function, an additional numeric
vector with time points can be implemented via the argument <code>x</code> (lower
case).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Define that an observed, equidistant time series <code class="reqn">y_t</code>, with
<code class="reqn">t = 1, 2, ..., n</code>, follows
</p>
<p style="text-align: center;"><code class="reqn">y_t = m(x_t) + \epsilon_t,</code>
</p>

<p>where <code class="reqn">x_t = t/n</code> is the rescaled time on the closed
interval <code class="reqn">[0,1]</code> and <code class="reqn">m(x_t)</code> is a nonparametric and
deterministic trend function (see Beran and Feng, 2002, and Feng, Gries and
Fritz, 2020).
<code class="reqn">\epsilon_t</code>, on the other hand, is a stationary process
with <code class="reqn">E(\epsilon_t) = 0</code> and short-range dependence.
For the purpose of this function, <code class="reqn">\epsilon_t</code> is assumed
to follow an autoregressive-moving-average (ARMA) model with
</p>
<p style="text-align: center;"><code class="reqn">\epsilon_t = \zeta_t + \beta_1 \epsilon_{t-1} + ... + \beta_p
\epsilon_{t-p} + \alpha_1 \zeta_{t-1} + ... +
\alpha_q \zeta_{t-q}.</code>
</p>

<p>Here, the random variables <code class="reqn">\zeta_t</code> are identically and
independently distributed (i.i.d.) with zero-mean and a constant variance
and the coefficients <code class="reqn">\alpha_j</code> and <code class="reqn">\beta_i</code>,
<code class="reqn">i = 1, 2, ..., p</code> and <code class="reqn">j = 1, 2, ..., q</code>, are real numbers.
The combination of both previous formulas will be called a semiparametric
ARMA (Semi-ARMA) model.
</p>
<p>An explicit forecasting method of Semi-ARMA models is described in
<code><a href="#topic+modelCast">modelCast</a></code>. To backtest a selected model, a slightly adjusted
procedure is used. The data is divided into in-sample and an
out-of-sample values (usually the last <code class="reqn">K = 5</code> observations in the data
are reserved for the out-of-sample observations). A model is fitted to the
in-sample data, whereas one-step rolling point forecasts and forecasting
intervals are obtained for the out-of-sample time points. The proposed
forecasts of the trend are either a linear or a constant extrapolation of
the trend with negligible forecasting intervals, whereas the point forecasts
of the stationary rest term are obtained via the selected ARMA(<code class="reqn">p,q</code>)
model (see Fritz et al., 2020). The corresponding forecasting intervals
are calculated under the assumption that the innovations
<code class="reqn">\zeta_t</code> are either normally distributed (see e.g. pp.
93-94 in Brockwell and Davis, 2016) or via a forward bootstrap (see Lu and
Wang, 2020). For a one-step forecast for time point <code class="reqn">t</code>, all observations
until time point <code class="reqn">t-1</code> are assumed to be known.
</p>
<p>The function calculates three important values for backtesting: the number
of breaches, i.e. the number of true observations that lie outside of the
forecasting intervals, the mean absolute scaled error (MASE, see Hyndman
and Koehler, 2006) and the root mean squared scaled error (RMSSE, see
Hyndman and Koehler, 2006) are obtained. For the MASE, a value <code class="reqn">&lt; 1</code>
indicates a better average forecasting potential than a naive forecasting
approach.
Furthermore, it is independent from the scale of the data and can thus be
used to compare forecasts of different datasets. Closely related is the
RMSSE, however here, the mean of the squared forecasting errors is computed
and scaled by the mean of the squared naive forecasting approach. Then the
root of that value is the RMSSE. Due to the close relation, the
interpretation of the RMSSE is similarly but not identically to the
interpretation of the MASE. Of course, a value close to zero is preferred
in both cases.
</p>
<p>To make use of the function, a numeric vector with the values of a time
series that is assumed to follow a Semi-ARMA model needs to be passed to
the argument <code>y</code>. Moreover, the arguments <code>p</code> and <code>q</code>
represent the AR and MA orders, respectively, of the underlying ARMA
process in the parametric part of the model. If both values are set to
<code>NULL</code>, an optimal order in accordance with the Bayesian Information
Criterion (BIC) will be selected. If only one of the values is <code>NULL</code>,
it will be changed to zero instead. <code>K</code> defines the number of the
out-of-sample observations; these will be cut off the end of <code>y</code>, while
the remaining observations are treated as the in-sample observations. For the
<code class="reqn">K</code> out-of-sample time points, rolling forecasts will be obtained.
<code>method</code> describes the method to use for the computation of the
prediction intervals. Under the normality assumption for the innovations
<code class="reqn">\zeta_t</code>, intervals can be obtained via
<em>method</em> = &quot;norm&quot;. However, if the assumption does not hold, a
bootstrap can be implemented as well (<em>method = &quot;boot&quot;</em>). Both
approaches are explained in more detail in <code><a href="#topic+normCast">normCast</a></code> and
<code><a href="#topic+bootCast">bootCast</a></code>, respectively. With <code>alpha</code>, the confidence
level of the forecasting intervals can be adjusted, as the
(<code class="reqn">100</code><code>alpha</code>)-percent forecasting intervals will be computed. By
means of the argument <code>np.fcast</code>, the forecasting method for the
nonparametric trend function can be defined. Selectable are a linear
(<code>np.fcast = "lin"</code>) and a constant (<code>np.fcast = "const"</code>)
extrapolation. For more information on these methods, we refer the reader to
<code><a href="#topic+trendCast">trendCast</a></code>.
</p>
<p><code>it</code>, <code>n.start</code>, <code>pb</code> and <code>cores</code> are only
relevant for <code>method = "boot"</code>. With <code>it</code> the total number of
bootstrap iterations is defined, whereas <code>n.start</code> regulates, how
many 'burn-in' observations are generated for each simulated ARMA process
in the bootstrap. Since a bootstrap may take a longer computation time,
with the argument <code>cores</code> the number of cores for parallel computation
of the bootstrap iterations can be defined. Nonetheless, for
<code>cores = NULL</code>, no cluster is created and therefore
the parallel computation is disabled. Note that the bootstrapped results are
fully reproducible for all cluster sizes. Moreover, for <code>pb = TRUE</code>,
the progress of the bootstrap approach can be observed in the R console via
a progress bar. Additional information on these four function arguments can
be found in <code><a href="#topic+bootCast">bootCast</a></code>.
</p>
<p>The argument <code>argsSmoots</code> is a list. In this list, different arguments
of the function <code><a href="#topic+msmooth">msmooth</a></code> can be implemented to adjust the
estimation of the nonparametric part of the complete model. The arguments
of the smoothing function are described in <code><a href="#topic+msmooth">msmooth</a></code>.
</p>
<p><code>rollCast</code> allows for a quick plot of the results. If the logical
argument <code>plot</code> is set to <code>TRUE</code>, a graphic with default
settings is created. Nevertheless, users are allowed to implement further
arguments of the standard plot function in the list <code>argsPlot</code>. For
example, the limits of the plot can be adjusted by <code>xlim</code> and
<code>ylim</code>. Furthermore, an argument <code>x</code> can be included in
<code>argsPlot</code> with the actual equidistant time points of the whole series
(in-sample &amp; out-of-sample observations). Otherwise, simply <code>1:n</code> is
used as the in-sample time points by default.
</p>
<p>NOTE:
</p>
<p>Within this function, the <code><a href="stats.html#topic+arima">arima</a></code> function of the
<code>stats</code> package with its method <code>"CSS-ML"</code> is used throughout for
the estimation of ARMA models. Furthermore, to increase the performance,
C++ code via the <code><a href="Rcpp.html#topic+Rcpp-package">Rcpp</a></code> and
<code><a href="RcppArmadillo.html#topic+RcppArmadillo-package">RcppArmadillo</a></code> packages
was implemented. Also, the <code><a href="future.html#topic+multisession">future</a></code> and
<code><a href="future.apply.html#topic+future.apply-package">future.apply</a></code> packages are
considered for parallel computation of bootstrap iterations. The progress
of the bootstrap is shown via the
<code><a href="progressr.html#topic+progressr-package">progressr</a></code> package.
</p>


<h3>Value</h3>

<p>A list with different elements is returned. The elements are as follows.
</p>

<dl>
<dt>alpha</dt><dd><p>a single numeric value; it describes, what confidence level
(<code class="reqn">100</code><code>alpha</code>)-percent has been considered for the forecasting
intervals.</p>
</dd>
<dt>breach</dt><dd><p>a logical vector that states whether the <code class="reqn">K</code> true
out-of-sample observations lie outside of the forecasting intervals,
respectively; a breach is denoted by <code>TRUE</code>.</p>
</dd>
<dt>breach.val</dt><dd><p>a numeric vector that contains the margin of the breaches
(in absolute terms) for the <code class="reqn">K</code> out-of-sample time points; if a breach
did not occur, the respective element is set to zero.</p>
</dd>
<dt>error</dt><dd><p>a numeric vector that contains the simulated empirical
values of the forecasting error for <code>method = "boot"</code>; otherwise,
it is set to <code>NULL</code>.</p>
</dd>
<dt>fcast.rest</dt><dd><p>a numeric vector that contains the <code class="reqn">K</code> point forecasts
of the parametric part of the model.</p>
</dd>
<dt>fcast.roll</dt><dd><p>a numeric matrix that contains the <code class="reqn">K</code> rolling point
forecasts as well as the values of the bounds of the respective forecasting
intervals for the complete model;
the first row contains the point forecasts, the lower bounds of the
forecasting intervals are in the second row and the upper bounds
can be found in the third row.</p>
</dd>
<dt>fcast.trend</dt><dd><p>a numeric vector that contains the <code class="reqn">K</code> obtained trend
forecasts.</p>
</dd>
<dt>K</dt><dd><p>a positive integer; states the number of out-of-sample observations
as well as the number of forecasts for the out-of-sample time points.</p>
</dd>
<dt>MASE</dt><dd><p>the obtained value of the mean average scaled error for the
selected model.</p>
</dd>
<dt>method</dt><dd><p>a character object that states, whether the forecasting
intervals were obtained via a bootstrap (<code>method = "boot"</code>) or under
the normality assumption for the innovations (<code>method = "norm"</code>).</p>
</dd>
<dt>model.nonpar</dt><dd><p>the output (usually a list) of the nonparametric
trend estimation via <code><a href="#topic+msmooth">msmooth</a></code>.</p>
</dd>
<dt>model.par</dt><dd><p>the output (usually a list) of the parametric ARMA
estimation of the detrended series via <code><a href="stats.html#topic+arima">arima</a></code>.</p>
</dd>
<dt>n</dt><dd><p>the number of observations (in-sample &amp; out-of-sample
observations).</p>
</dd>
<dt>n.in</dt><dd><p>the number of in-sample observations (<code>n - n.out</code>).</p>
</dd>
<dt>n.out</dt><dd><p>the number of out-of-sample observations (equals <code>K</code>).</p>
</dd>
<dt>np.fcast</dt><dd><p>a character object that states the applied forecasting
method for the nonparametric trend function; either a linear (
<code>np.fcast = "lin"</code>) or a constant <code>np.fcast = "const"</code> are
possible.</p>
</dd>
<dt>quants</dt><dd><p>a numeric vector of length 2 with the
<code class="reqn">[100(1 -</code> <code>alpha</code><code class="reqn">)/2]</code>-percent and
{<code class="reqn">100</code><code class="reqn">[1 - (1 -</code> <code>alpha</code><code class="reqn">)/2]</code>}-percent quantiles of
the forecasting error distribution.</p>
</dd>
<dt>RMSSE</dt><dd><p>the obtained value of the root mean squared scaled error for
the selected model.</p>
</dd>
<dt>y</dt><dd><p>a numeric vector that contains all true observations (in-sample &amp;
out-of-sample observations).</p>
</dd>
<dt>y.in</dt><dd><p>a numeric vector that contains all in-sample observations.</p>
</dd>
<dt>y.out</dt><dd><p>a numeric vector that contains the <code class="reqn">K</code> out-of-sample
observations.</p>
</dd>
</dl>



<h3>Author(s)</h3>


<ul>
<li><p> Yuanhua Feng (Department of Economics, Paderborn University), <br />
Author of the Algorithms <br />
Website: <a href="https://wiwi.uni-paderborn.de/en/dep4/feng/">https://wiwi.uni-paderborn.de/en/dep4/feng/</a>
</p>
</li>
<li><p> Dominik Schulz (Research Assistant) (Department of Economics, Paderborn
University), <br />
Package Creator and Maintainer
</p>
</li></ul>



<h3>References</h3>

<p>Beran, J., and Feng, Y. (2002). Local polynomial fitting with long-memory,
short-memory and antipersistent errors. Annals of the Institute of
Statistical Mathematics, 54, 291-311.
</p>
<p>Brockwell, P. J., and Davis, R. A. (2016). Introduction to time series
and forecasting, 3rd edition. Springer.
</p>
<p>Fritz, M., Forstinger, S., Feng, Y., and Gries, T. (2020). Forecasting
economic growth processes for developing economies. Unpublished.
</p>
<p>Feng, Y., Gries, T. and Fritz, M. (2020). Data-driven
local polynomial for the trend and its derivatives in economic time
series. Journal of Nonparametric Statistics, 32:2, 510-533.
</p>
<p>Hyndman, R. J., and Koehler, A. B. (2006). Another look at measures of
forecast accuracy. International Journal of Forecasting, 22:4, 679-688.
</p>
<p>Lu, X., and Wang, L. (2020). Bootstrap prediction interval for ARMA models
with unknown orders. REVSTAT–Statistical Journal, 18:3, 375-396.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>lgdp &lt;- log(smoots::gdpUS$GDP)
time &lt;- seq(from = 1947.25, to = 2019.5, by = 0.25)
backtest &lt;- rollCast(lgdp, K = 5,
 argsPlot = list(x = time, xlim = c(2012, 2019.5), col = "forestgreen",
 type = "b", pch = 20, lty = 2, main = "Example"))
backtest

</code></pre>

<hr>
<h2 id='smoots'>smoots: A package for data-driven nonparametric estimation of the trend and
its derivatives in equidistant time series.</h2><span id='topic+smoots'></span><span id='topic+smoots-package'></span>

<h3>Description</h3>

<p>The <code>smoots</code> package provides different applicable functions for the
estimation of the trend or its derivatives in equidistant time series.
The main functions include an automated bandwidth selection method for time
series with short-memory errors. With package version 1.1.0 several
functions for forecasting as well as linearity tests were added.
</p>


<h3>Functions (version 1.0.0)</h3>

<p>The <code>smoots</code> functions are either meant for calculating nonparametric
estimates of the trend of a time series or its derivatives.
</p>
<p><code>msmooth</code> is the central function of the package. It allows
the user to conduct a local polynomial regression of the trend based on
an optimal bandwidth that is obtained by an iterative plug-in algorithm.
There are also different algorithms implemented concerning the inflation rate
and other factors that can be chosen from (see also: <code><a href="#topic+msmooth">msmooth</a></code>).
</p>
<p><code>dsmooth</code> is a function that calculates the derivatives of the
trend after obtaining the optimal bandwidth by an iterative plug-in
algorithm. The estimates are obtained for rescaled time points on the
interval <code class="reqn">[0, 1]</code> (see also: <code><a href="#topic+dsmooth">dsmooth</a></code>).
</p>
<p><code>tsmooth</code> is similar to <code>msmooth</code> as it also calculates the trend
of the series. Instead of using the name of a predefined algorithm that
settles the inflation rate (and other factors), these factors can be manually
and individually adjusted as arguments in the function (see also:
<code><a href="#topic+tsmooth">tsmooth</a></code>).
</p>
<p><code>gsmooth</code> is a standard smoothing function that applies the local
polynomial regression method. A bandwidth can be chosen freely. The estimates
are obtained for rescaled time points on the interval <code class="reqn">[0, 1]</code>
(see also: <code><a href="#topic+gsmooth">gsmooth</a></code>).
</p>
<p><code>knsmooth</code> is a standard smoothing function that applies the kernel
regression method. A bandwidth can be chosen freely
(see also: <code><a href="#topic+knsmooth">knsmooth</a></code>).
</p>


<h3>Added Functions (version 1.1.0)</h3>

<p>With the publication of the package version 1.1.0, new functions were added.
These include functions for forecasting and functions for testing linearity
of the deterministic trend.
</p>
<p><code>rescale</code> helps rescaling the estimates of the derivatives of the
nonparametric trend function, because the estimates are obtained for rescaled
time points on the interval <code class="reqn">[0, 1]</code> and not for the actual time points
(see also: <code><a href="#topic+rescale">rescale</a></code>).
</p>
<p><code>critMatrix</code> is a quick tool for the calculation of information criteria
for ARMA(<code class="reqn">p,q</code>) models with different order combinations <code class="reqn">p</code> and
<code class="reqn">q</code>. The function returns a matrix with the obtained values of the
selected criterion for the different combinations of <code class="reqn">p</code> and <code class="reqn">q</code>
(see also: <code><a href="#topic+critMatrix">critMatrix</a></code>).
</p>
<p><code>optOrd</code> is useful in combination with <code>critMatrix</code>. It
reads a matrix equal in structure to the ones returned by <code>critMatrix</code>
and returns the optimal orders p and q. Furthermore, additional restrictions
for the selection can be imposed (see also: <code><a href="#topic+optOrd">optOrd</a></code>).
</p>
<p><code>normCast</code> provides means to obtain point forecasts as well as
forecasting intervals for a given series under the assumption that it follows
an ARMA(<code class="reqn">p,q</code>) model and that its innovations are normally distributed
(see also: <code><a href="#topic+normCast">normCast</a></code>).
</p>
<p><code>bootCast</code> can also be used to calculate point forecasts and forecasting
intervals, if the series of interest follows an ARMA(<code class="reqn">p,q</code>) model.
However, the main difference is that this function should be applied, if the
distribution of the innovations is unknown or explicitly non-Gaussian,
because the underlying bootstrap process does not need a distribution
assumption. In spite of this advantage, it also needs significantly more
computation time. Therefore, with version 1.1.1, the bootstrap can now be
conducted in parallel for an improved performance (see also:
<code><a href="#topic+bootCast">bootCast</a></code>).
</p>
<p><code>trendCast</code> uses a <code>smoots</code> object that is the output of a trend
estimation and calculates point forecasts of the trend. Forecasting intervals
are omitted for reasons that are explained within the function's
documentation (see also: <code><a href="#topic+trendCast">trendCast</a></code>).
</p>
<p><code>modelCast</code> calculates the point forecasts and forecasting intervals of
a trend-stationary series. Based on a <code>smoots</code> object that is the output
of a trend estimation, <code>trendCast</code> is applied to the estimated trend,
whereas either <code>normCast</code> or <code>bootCast</code> is applied to the
residuals (see also: <code><a href="#topic+modelCast">modelCast</a></code>).
</p>
<p><code>rollCast</code> is a backtesting function for Semi-ARMA models. A given
series is divided into in-sample and out-of-sample observations, where the
in-sample is used to fit a Semi-ARMA model. One-step rolling forecasts and
the corresponding forecasting intervals are then obtained for the
out-of-sample observations. The quality of the model is then assessed via
a comparison of the true out-of-sample observations with the point forecasts
and forecasting intervals. Different quality criteria are calculated and
returned (see also: <code><a href="#topic+modelCast">modelCast</a></code>).
</p>
<p><code>confBounds</code> calculates the confidence bounds of the estimated trend
or of the estimated derivative of the trend at a predefined confidence
level. A graphic of the confidence bounds alongside a previously chosen
constant or parametric illustration of the estimated series is created. With
this plot it can be tested graphically if the deterministic trend is constant
or if it follows a parametric polynomial model. Furthermore, it can also be
tested, if the derivatives of the trend are constant (see also:
<code><a href="#topic+confBounds">confBounds</a></code>).
</p>


<h3>Datasets</h3>

<p>The package includes four datasets: <code>gdpUS</code> (see also:
<code><a href="#topic+gdpUS">gdpUS</a></code>) that has data concerning the quarterly US GDP between
Q1 1947-01 and Q2 2019, <code>tempNH</code> (see also: <code><a href="#topic+tempNH">tempNH</a></code>) with
mean monthly Northern Hemisphere temperature changes from 1880 to 2018,
<code>dax</code> (see also: <code><a href="#topic+dax">dax</a></code>) with daily financial time series
data of the German stock index (DAX) from 1990 to July 2019 and <code>vix</code>
(see also: <code><a href="#topic+vix">vix</a></code>) with daily financial time series data of the
CBOE Volatility Index (VIX) from 1990 to July 2019.
</p>


<h3>License</h3>

<p>The package is distributed under the General Public License v3
([GPL-3](https://tldrlegal.com/license/gnu-general-public-license-v3-(gpl-3))).
</p>


<h3>Author(s)</h3>


<ul>
<li><p> Yuanhua Feng (Department of Economics, Paderborn University), <br />
Author of the Algorithms <br />
Website: <a href="https://wiwi.uni-paderborn.de/en/dep4/feng/">https://wiwi.uni-paderborn.de/en/dep4/feng/</a>
</p>
</li>
<li><p> Dominik Schulz (Research Assistant) (Department of Economics, Paderborn
University), <br />
Package Creator and Maintainer
</p>
</li></ul>



<h3>References</h3>

<p>Feng, Y., Gries, T. and Fritz, M. (2020). Data-driven
local polynomial for the trend and its derivatives in economic time
series. Journal of Nonparametric Statistics, 32:2, 510-533.
</p>
<p>Feng, Y., Gries, T., Letmathe, S. and Schulz, D. (2019). The smoots package
in R for semiparametric modeling of trend stationary time series. Discussion
Paper. Paderborn University. Unpublished.
</p>

<hr>
<h2 id='tempNH'>Mean Monthly Northern Hemisphere Temperature Changes</h2><span id='topic+tempNH'></span>

<h3>Description</h3>

<p>A dataset that contains mean monthly Northern Hemisphere temperature
changes from 1880 to 2018. The base period is 1951 to 1980.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tempNH
</code></pre>


<h3>Format</h3>

<p>A data frame with 1668 rows and 3 variables:
</p>

<dl>
<dt>Year</dt><dd><p>the observation year</p>
</dd>
<dt>Month</dt><dd><p>the observation month</p>
</dd>
<dt>Change</dt><dd><p>the observed mean monthly temperature changes in degrees
Celsius</p>
</dd>
</dl>



<h3>Source</h3>

<p>The data was obtained from the Goddard Institute for Space Studies
(part of the National Aeronautics and Space Administration [NASA])
(accessed: 2019-09-25).
</p>
<p><a href="https://data.giss.nasa.gov/gistemp/tabledata_v4/NH.Ts+dSST.txt">https://data.giss.nasa.gov/gistemp/tabledata_v4/NH.Ts+dSST.txt</a>
</p>

<hr>
<h2 id='trendCast'>Forecasting Function for Nonparametric Trend Functions</h2><span id='topic+trendCast'></span>

<h3>Description</h3>

<p>Forecasting Function for Nonparametric Trend Functions
</p>


<h3>Usage</h3>

<pre><code class='language-R'>trendCast(object, h = 1, np.fcast = c("lin", "const"), plot = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="trendCast_+3A_object">object</code></td>
<td>
<p>an object returned by either <code><a href="#topic+msmooth">msmooth</a></code>,
<code><a href="#topic+tsmooth">tsmooth</a></code>, <code><a href="#topic+gsmooth">gsmooth</a></code> (with <code>v = 0</code>) or
<code><a href="#topic+knsmooth">knsmooth</a></code>.</p>
</td></tr>
<tr><td><code id="trendCast_+3A_h">h</code></td>
<td>
<p>the forecasting horizon; the values <code class="reqn">m(n + 1)</code> to <code class="reqn">m(n + h)</code>
will be predicted; is set to <code>h = 1</code> by default; decimal numbers will be
rounded off to integers.</p>
</td></tr>
<tr><td><code id="trendCast_+3A_np.fcast">np.fcast</code></td>
<td>
<p>the forecasting method; <code>np.fcast = "lin"</code> uses a linear
extrapolation, whereas <code>np.fcast = "const"</code> uses the last fitted value
of <code class="reqn">m(x_t)</code> as a forecast; is set to <code>"lin"</code> by default.</p>
</td></tr>
<tr><td><code id="trendCast_+3A_plot">plot</code></td>
<td>
<p>a logical value; if set to <code>TRUE</code>, a simple plot of the
original time series, the local polynomial trend estimates as well as the
predicted values is generated.</p>
</td></tr>
<tr><td><code id="trendCast_+3A_...">...</code></td>
<td>
<p>additional arguments for the standard plot function, e.g.,
<code>xlim</code>, <code>type</code>, ... ; arguments with respect to plotted graphs,
e.g., the argument <code>col</code>, only affect the original series <code>X</code>;
please note that in accordance with the argument <code>x</code> (lower case) of the
standard plot function, an additional numeric vector with time points can be
implemented via the argument <code>x</code> (lower case). <code>x</code> should be
valid for the sample observations only, i.e.
<code>length(x) == length(obj$orig)</code> should be <code>TRUE</code>, as future time
points will be calculated automatically.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is part of the <code>smoots</code> package and was implemented under
version 1.1.0. The underlying theory is based on the additive nonparametric
regression function
</p>
<p style="text-align: center;"><code class="reqn">y_t = m(x_t) + \epsilon_t,</code>
</p>

<p>where <code class="reqn">y_t</code> is the observed time series with equidistant design,
<code class="reqn">x_t</code> is the rescaled time on the interval <code class="reqn">[0, 1]</code>, <code class="reqn">m(x_t)</code>
is a smooth and deterministic trend function and <code class="reqn">\epsilon_t</code> are
stationary errors with <code class="reqn">E(\epsilon_t) = 0</code>.
</p>
<p>The purpose of this function is the forecasting of future values based on
a nonparametric regression model. Following the proposition in Fritz
et al. (2020), point predictions can be conducted
separately for the nonparametric trend function <code class="reqn">m(x_t)</code> and the
stationary part <code class="reqn">\epsilon_t</code>. The sum of both forecasts is then the
forecast of <code class="reqn">y_t</code>. With this function, only the forecast with respect to
<code class="reqn">m(x_t)</code> is computable.
Now assume that the variance of the error in the local polynomial
forecasts is negligible when calculating the forecasting intervals. We
define the forecast for time point <code class="reqn">n + k</code>, <code class="reqn">k = 1, 2, ..., h</code>, by
</p>
<p style="text-align: center;"><code class="reqn">\hat{m}(x_{n + k}) = \hat{m}(x_n) + D k \delta_m,</code>
</p>

<p>where <code class="reqn">\delta_m</code> is equal to <code class="reqn">\hat{m}(x_n) -
\hat{m}(x_{n - 1})</code> and <code class="reqn">D</code> is a
dummy  variable. If <code class="reqn">D = 1</code>, a linear extrapolation is applied. For
<code class="reqn">D = 0</code>, <code class="reqn">\hat{m}(x_n)</code> is the predicted value.
</p>
<p>To make use of this function, an object of class <code>smoots</code> can be given
as input. However, since the discussed approach is only valid for the
estimated trend function, only objects created by <code><a href="#topic+msmooth">msmooth</a></code>,
<code><a href="#topic+tsmooth">tsmooth</a></code>, <code><a href="#topic+knsmooth">knsmooth</a></code> and <code>link{gsmooth}</code>, if
the trend was estimated, will be appropriate input objects.
</p>
<p>With the input argument <code>h</code>, a positive integer can be given to the
function that represents the forecasting horizon, i.e. how many future values
are to be estimated. Via the argument <code>np.fcast</code> the value of the dummy
variable D can be specified and thus the forecasting method. For
<code>np.fcast = "lin"</code>, <code class="reqn">D = 1</code> is applied, whereas for
<code>np.fcast = "const"</code>, <code class="reqn">D</code> is set to <code class="reqn">0</code>.
</p>
<p>By means of the argument <code>plot</code> that can be either set to the logical
values <code>TRUE</code> or <code>FALSE</code>, a simple plot of the original series
alongside the local polynomial estimates as well as the forecasted values can
be either generated or suppressed.
</p>
<p>The function always returns a vector of forecasted values ordered from
<code class="reqn">n + 1</code> to <code class="reqn">n + h</code>. Depending on the setting of the argument
<code>plot</code>, a generic plot of the results may be generated. Furthermore,
additional arguments of the standard plot function can be passed to this
function as well to adjust the generated plot.
</p>


<h3>Value</h3>

<p>A numeric vector is always returned with the forecasted values. Depending
on the setting for the argument <em>plot</em>, a generic plot might be created.
</p>


<h3>Author(s)</h3>


<ul>
<li><p> Yuanhua Feng (Department of Economics, Paderborn University), <br />
Author of the Algorithms <br />
Website: <a href="https://wiwi.uni-paderborn.de/en/dep4/feng/">https://wiwi.uni-paderborn.de/en/dep4/feng/</a>
</p>
</li>
<li><p> Dominik Schulz (Research Assistant) (Department of Economics, Paderborn
University), <br />
Package Creator and Maintainer
</p>
</li></ul>



<h3>References</h3>

<p>Feng, Y., Gries, T. and Fritz, M. (2020). Data-driven
local polynomial for the trend and its derivatives in economic time
series. Journal of Nonparametric Statistics, 32:2, 510-533.
</p>
<p>Feng, Y., Gries, T., Letmathe, S. and Schulz, D. (2019). The smoots package
in R for semiparametric modeling of trend stationary time series. Discussion
Paper. Paderborn University. Unpublished.
</p>
<p>Feng, Y., Gries, T., Fritz, M., Letmathe, S. and Schulz, D. (2020).
Diagnosing the trend and bootstrapping the forecasting intervals using a
semiparametric ARMA. Discussion Paper. Paderborn University. Unpublished.
</p>
<p>Fritz, M., Forstinger, S., Feng, Y., and Gries, T. (2020). Forecasting
economic growth processes for developing economies. Unpublished.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>log_gdp &lt;- log(smoots::gdpUS$GDP)
est &lt;- msmooth(log_gdp)
forecasts &lt;- trendCast(est, h = 5, plot = TRUE)
forecasts

</code></pre>

<hr>
<h2 id='tsmooth'>Advanced Data-driven Nonparametric Regression for the Trend in Equidistant
Time Series</h2><span id='topic+tsmooth'></span>

<h3>Description</h3>

<p>This function runs an iterative plug-in algorithm to find the optimal
bandwidth for the estimation of the nonparametric trend in equidistant
time series (with short-memory errors) and then employs the resulting
bandwidth via either local polynomial or kernel regression. This function
allows for more flexibility in its arguments than <em>msmooth</em>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tsmooth(
  y,
  p = c(1, 3),
  mu = c(0, 1, 2, 3),
  Mcf = c("NP", "ARMA", "AR", "MA"),
  InfR = c("Opt", "Nai", "Var"),
  bStart = 0.15,
  bvc = c("Y", "N"),
  bb = c(0, 1),
  cb = 0.05,
  method = c("lpr", "kr")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tsmooth_+3A_y">y</code></td>
<td>
<p>a numeric vector that contains the time series ordered from past to
present.</p>
</td></tr>
<tr><td><code id="tsmooth_+3A_p">p</code></td>
<td>
<p>an integer <code>1</code> (local linear regression) or <code>3</code> (local
cubic regression); represents the order of polynomial within the local
polynomial regression (see also the 'Details' section); is set to <code>1</code> by
default; is automatically set to <code>1</code> if <code>method = "kr"</code>.</p>
</td></tr>
<tr><td><code id="tsmooth_+3A_mu">mu</code></td>
<td>
<p>an integer <code>0</code>, ..., <code>3</code> that represents the smoothness
parameter of the kernel weighting function and thus defines the kernel
function that will be used within the local polynomial regression; is set to
<code>1</code> by default.
</p>

<table>
<tr>
 <td style="text-align: center;">
<strong>Number</strong> </td><td style="text-align: left;"> <strong>Kernel</strong></td>
</tr>
<tr>
 <td style="text-align: center;">
<code>0</code> </td><td style="text-align: left;"> Uniform Kernel</td>
</tr>
<tr>
 <td style="text-align: center;">
<code>1</code> </td><td style="text-align: left;"> Epanechnikov Kernel</td>
</tr>
<tr>
 <td style="text-align: center;">
<code>2</code> </td><td style="text-align: left;"> Bisquare Kernel</td>
</tr>
<tr>
 <td style="text-align: center;">
<code>3</code> </td><td style="text-align: left;"> Triweight Kernel
</td>
</tr>

</table>
</td></tr>
<tr><td><code id="tsmooth_+3A_mcf">Mcf</code></td>
<td>
<p>method for estimating the variance factor <code class="reqn">c_f</code> by the IPI
(see also the 'Details' section); is set to <code>NP</code> by default. <br />
</p>

<table>
<tr>
 <td style="text-align: center;">
<strong>Method</strong> </td><td style="text-align: left;"> <strong>Explanation</strong></td>
</tr>
<tr>
 <td style="text-align: center;">
<code>"NP"</code> </td><td style="text-align: left;"> Nonparametric estimation using the Bartlett window </td>
</tr>
<tr>
 <td style="text-align: center;">
<code>"ARMA"</code> </td><td style="text-align: left;"> Estimation on the assumption that the residuals follow an
ARMA model</td>
</tr>
<tr>
 <td style="text-align: center;">
<code>"AR"</code> </td><td style="text-align: left;"> Estimation on the assumption that the residuals follow an
AR model</td>
</tr>
<tr>
 <td style="text-align: center;">
<code>"MA"</code> </td><td style="text-align: left;"> Estimation on the assumption that the residuals follow an
MA model
</td>
</tr>

</table>
</td></tr>
<tr><td><code id="tsmooth_+3A_infr">InfR</code></td>
<td>
<p>a character object that represents the inflation
rate in the form <code class="reqn">h_d = h^a</code> for the bandwidth in the estimation of
<code class="reqn">I[m^{(k)}]</code> (see also the 'Details' section); is set to
<code>"Opt"</code> by default.
</p>

<table>
<tr>
 <td style="text-align: center;">
<strong>Inflation rate</strong> </td><td style="text-align: left;"> <strong>Description</strong></td>
</tr>
<tr>
 <td style="text-align: center;">
<code>"Opt"</code> </td><td style="text-align: left;"> Optimal inflation rate <code class="reqn">a_{p,O}</code> (<code class="reqn">5/7</code>
for <code>p = 1</code>; <code class="reqn">9/11</code> for <code>p = 3</code>)</td>
</tr>
<tr>
 <td style="text-align: center;">
<code>"Nai"</code> </td><td style="text-align: left;"> Naive inflation rate <code class="reqn">a_{p,N}</code> (<code class="reqn">5/9</code> for
<code>p = 1</code>; <code class="reqn">9/13</code> for <code>p = 3</code>)</td>
</tr>
<tr>
 <td style="text-align: center;">
<code>"Var"</code> </td><td style="text-align: left;"> Stable inflation rate <code class="reqn">a_{p,S}</code> (<code class="reqn">1/2</code> for
<code>p = 1</code> and <code>p = 3</code>)
</td>
</tr>

</table>
</td></tr>
<tr><td><code id="tsmooth_+3A_bstart">bStart</code></td>
<td>
<p>a numeric object that indicates the starting value of the
bandwidth for the iterative process; should be <code class="reqn">&gt; 0</code>; is set to
<code>0.15</code> by default.</p>
</td></tr>
<tr><td><code id="tsmooth_+3A_bvc">bvc</code></td>
<td>
<p>a character object that indicates whether an enlarged bandwidth is
being used for the estimation of the variance factor <code class="reqn">c_f</code> (see also the
'Details' section) or not; is set to <code>"Y"</code> by default.
</p>

<table>
<tr>
 <td style="text-align: center;">
<strong>Bandwidth</strong> </td><td style="text-align: left;"> <strong>Description</strong></td>
</tr>
<tr>
 <td style="text-align: center;">
<em>&quot;Y&quot;</em> </td><td style="text-align: left;"> Using an enlarged bandwidth</td>
</tr>
<tr>
 <td style="text-align: center;">
<em>&quot;N&quot;</em> </td><td style="text-align: left;"> Using a bandwidth without enlargement
</td>
</tr>

</table>
</td></tr>
<tr><td><code id="tsmooth_+3A_bb">bb</code></td>
<td>
<p>can be set to <code>0</code> or <code>1</code>; the parameter controlling the
bandwidth used at the boundary; is set to <code>1</code> by default.
</p>

<table>
<tr>
 <td style="text-align: center;">
<strong>Number (<code>bb</code>)</strong> </td><td style="text-align: left;"> <strong>Estimation procedure at boundary
points</strong></td>
</tr>
<tr>
 <td style="text-align: center;">
<code>0</code> </td><td style="text-align: left;"> Fixed bandwidth on one side with possible large
bandwidth on the other side at the boundary</td>
</tr>
<tr>
 <td style="text-align: center;">
<code>1</code> </td><td style="text-align: left;"> The <code class="reqn">k</code>-nearest neighbor method will be used
</td>
</tr>

</table>
</td></tr>
<tr><td><code id="tsmooth_+3A_cb">cb</code></td>
<td>
<p>a numeric value that indicates the percentage of omitted
observations on each side of the observation period for the automated
bandwidth selection; is set to <code>0.05</code> by default.</p>
</td></tr>
<tr><td><code id="tsmooth_+3A_method">method</code></td>
<td>
<p>the final smoothing approach; <code>"lpr"</code> represents the local
polynomial regression, whereas <code>"kr"</code> implements a kernel regression;
is set to <code>"lpr"</code> by default.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The trend is estimated based on the additive
nonparametric regression model for an equidistant time series
</p>
<p style="text-align: center;"><code class="reqn">y_t = m(x_t) + \epsilon_t,</code>
</p>

<p>where <code class="reqn">y_t</code> is the observed time series, <code class="reqn">x_t</code> is the rescaled time
on the interval <code class="reqn">[0, 1]</code>, <code class="reqn">m(x_t)</code> is a smooth and deterministic
trend function and <code class="reqn">\epsilon_t</code> are stationary errors with
<code class="reqn">E(\epsilon_t) = 0</code> and short-range dependence (see also Beran and Feng,
2002). With this function <code class="reqn">m(x_t)</code> can be estimated without a parametric
model assumption for the error series. Thus, after estimating and removing
the trend, any suitable parametric model, e.g. an ARMA(<code class="reqn">p,q</code>) model, can
be fitted to the residuals (see <code><a href="stats.html#topic+arima">arima</a></code>).
</p>
<p>The iterative-plug-in (IPI) algorithm, which numerically minimizes the
Asymptotic Mean Squared Error (AMISE), was proposed by Feng, Gries
and Fritz (2020).
</p>
<p>Define <code class="reqn">I[m^{(k)}] = \int_{c_b}^{d_b} [m^{(k)}(x)]^2 dx</code>, <code class="reqn">\beta_{(\nu, k)} = \int_{-1}^{1} u^k
K_{(\nu, k)}(u) du</code>
and <code class="reqn">R(K) = \int_{-1}^{1} K_{(\nu, k)}^{2}(u) du</code>, where <code class="reqn">p</code> is the order of the polynomial,
<code class="reqn">k = p + 1</code> is the order of the asymptotically equivalent kernel,
<code class="reqn">\nu</code> is the order of the trend function's derivative, <code class="reqn">0 \leq c_{b}
&lt; d_{b} \leq 1</code>, <code class="reqn">c_f</code> is the variance factor and
<code class="reqn">K_{(\nu, k)}(u)</code> the <code class="reqn">k</code>-th order equivalent kernel
obtained for the estimation of <code class="reqn">m^{(\nu)}</code> in the interior.
<code class="reqn">m^{(\nu)}</code> is the <code class="reqn">\nu</code>-th order derivative (<code class="reqn">\nu = 0,
1, 2, ...</code>) of the nonparametric trend.
</p>
<p>Furthermore, we define
</p>
<p style="text-align: center;"><code class="reqn">C_{1} = \frac{I[m^{(k)}] \beta_{(\nu, k)}^2}{(k!)^2}</code>
</p>

<p>and
</p>
<p style="text-align: center;"><code class="reqn">C_{2} = \frac{2 \pi c_{f} (d_b - c_b) R(K)}{nh^{2 \nu + 1}}</code>
</p>

<p>with <code class="reqn">h</code> being the bandwidth and <code class="reqn">n</code> being the number of
observations. The AMISE is then
</p>
<p style="text-align: center;"><code class="reqn">AMISE(h) = h^{2(k-\nu)}C_{1} + C_{2}.</code>
</p>

<p>The function calculates suitable estimates for <code class="reqn">c_f</code>, the variance
factor, and <code class="reqn">I[m^{(k)}]</code> over different iterations. In each
iteration, a bandwidth is obtained in accordance with the AMISE that once
more serves as an input for the following iteration. The process repeats
until either convergence or the 40th iteration is reached. For further
details on the asymptotic theory or the algorithm, please consult Feng, Gries
and Fritz (2020) or Feng et al. (2019).
</p>
<p>To apply the function, more arguments are needed compared to the similar
function <code><a href="#topic+msmooth">msmooth</a></code>: a data input <code>y</code>, an order of polynomial
<code>p</code>, a kernel weighting function defined by the smoothness parameter
<code>mu</code>, a variance factor estimation method <code>Mcf</code>, an inflation rate
setting <code>InfR</code> (see also Beran and Feng, 2002), a starting value for the
relative bandwidth <code>bStart</code>, an inflation setting for the variance
factor estimation <code>bvc</code>, a boundary method <code>bb</code>, a boundary cut-off
percentage <code>cb</code> and a final smoothing method <code>method</code>.
In fact, aside from the input vector <code>y</code>, every argument has a default
setting that can be adjusted for the individual case. Theoretically, the
initial bandwidth does not affect the selected optimal bandwidth. However, in
practice local minima of the AMISE might exist and influence the selected
bandwidth. Therefore, the default setting is <code>bStart = 0.15</code>, which is a
compromise between the starting values <code>bStart = 0.1</code> for <code>p = 1</code>
and <code>bStart = 0.2</code> for <code>p = 3</code> that were proposed by Feng, Gries
and Fritz (2020). In the rare case of a clearly unsuitable optimal bandwidth,
a starting bandwidth that differs from the default value is a first
possible approach to obtain a better result. Other argument adjustments can
be tried as well. For more specific information on the input arguments
consult the section <em>Arguments</em>.
</p>
<p>When applying the function, an optimal bandwidth is obtained based on the
IPI algorithm proposed by Feng, Gries and Fritz (2020). In a second step,
the nonparametric trend of the series is calculated with respect
to the chosen bandwidth and the selected regression method (<code>lpf</code> or
<code>kr</code>). Please note that <code>method = "lpf"</code> is strongly recommended by
the authors. Moreover, it is notable that <code>p</code> is automatically set to
<code>1</code> for <code>method = "kr"</code>. The output object is then a list that
contains, among other components, the original time series, the estimated
trend values and the series without the trend.
</p>
<p>The default print method for this function delivers only key numbers such as
the iteration steps and the generated optimal bandwidth rounded to the fourth
decimal. The exact numbers and results such as the estimated nonparametric
trend series are saved within the output object and can be addressed via the
<code>$</code> sign.
</p>
<p>NOTE:
</p>
<p>With package version 1.1.0, this function implements C++ code by means
of the <code><a href="Rcpp.html#topic+Rcpp-package">Rcpp</a></code> and
<code><a href="RcppArmadillo.html#topic+RcppArmadillo-package">RcppArmadillo</a></code> packages for
better performance.
</p>


<h3>Value</h3>

<p>The function returns a list with different components:
</p>

<dl>
<dt>AR.BIC</dt><dd><p>the Bayesian Information Criterion of the optimal AR(<code class="reqn">p</code>)
model when estimating the variance factor via autoregressive models
(if calculated; calculated for <code>alg = "OA"</code> and <code>alg = "NA"</code>).</p>
</dd>
<dt>ARMA.BIC</dt><dd><p>the Bayesian Information Criterion of the optimal
ARMA(<code class="reqn">p,q</code>) model when estimating the variance factor via
autoregressive-moving-average models (if calculated; calculated for
<code>alg = "OAM"</code> and <code>alg = "NAM"</code>).</p>
</dd>
<dt>cb</dt><dd><p>the percentage of omitted observations on each side of the
observation period.</p>
</dd>
<dt>b0</dt><dd><p>the optimal bandwidth chosen by the IPI-algorithm.</p>
</dd>
<dt>bb</dt><dd><p>the boundary bandwidth method used within the IPI; always equal to
1.</p>
</dd>
<dt>bStart</dt><dd><p>the starting value of the (relative) bandwidth; input
argument.</p>
</dd>
<dt>bvc</dt><dd><p>indicates whether an enlarged bandwidth was used for the variance
factor estimation or not; depends on the chosen algorithm.</p>
</dd>
<dt>cf0</dt><dd><p>the estimated variance factor; in contrast to the definitions
given in the <em>Details</em> section, this object actually contains an
estimated value of <code class="reqn">2\pi c_f</code>, i.e. it corresponds to the estimated sum
of autocovariances.</p>
</dd>
<dt>cf0.AR</dt><dd><p>the estimated variance factor obtained by estimation of
autoregressive models (if calculated; <code>alg = "OA"</code> or <code>"NA"</code>).</p>
</dd>
<dt>cf0.ARMA</dt><dd><p>the estimated variance factor obtained by estimation of
autoregressive-moving-average models (if calculated; calculated for
<code>alg = "OAM"</code> and <code>alg = "NAM"</code>).</p>
</dd>
<dt>cf0.LW</dt><dd><p>the estimated variance factor obtained by Lag-Window Spectral
Density Estimation following Bühlmann (1996) (if calculated; calculated for
algorithms <code>"A"</code>, <code>"B"</code>, <code>"O"</code> and <code>"N"</code>).</p>
</dd>
<dt>cf0.MA</dt><dd><p>the estimated variance factor obtained by estimation of
moving-average models (if calculated; calculated for <code>alg = "OM"</code> and
<code>alg = "NM"</code>).</p>
</dd>
<dt>I2</dt><dd><p>the estimated value of <code class="reqn">I[m^{(k)}]</code>.</p>
</dd>
<dt>InfR</dt><dd><p>the setting for the inflation rate according to the chosen
algorithm.</p>
</dd>
<dt>iterations</dt><dd><p>the bandwidths of the single iterations steps</p>
</dd>
<dt>L0.opt</dt><dd><p>the optimal bandwidth for the lag-window spectral density
estimation (if calculated; calculated for algorithms <code>"A"</code>, <code>"B"</code>,
<code>"O"</code> and <code>"N"</code>).</p>
</dd>
<dt>MA.BIC</dt><dd><p>the Bayesian Information Criterion of the optimal MA(<code class="reqn">q</code>)
model when estimating the variance factor via moving-average models (if
calculated; calculated for <code>alg = "OM"</code> and <code>alg = "NM"</code>).</p>
</dd>
<dt>Mcf</dt><dd><p>the estimation method for the variance factor estimation; depends
on the chosen algorithm.</p>
</dd>
<dt>mu</dt><dd><p>the smoothness parameter of the second order kernel; input
argument.</p>
</dd>
<dt>n</dt><dd><p>the number of observations.</p>
</dd>
<dt>niterations</dt><dd><p>the total number of iterations until convergence.</p>
</dd>
<dt>orig</dt><dd><p>the original input series; input argument.</p>
</dd>
<dt>p.BIC</dt><dd><p>the order p of the optimal AR(<code class="reqn">p</code>) or ARMA(<code class="reqn">p,q</code>) model
when estimating the variance factor via autoregressive or
autoregressive-moving average models (if calculated; calculated for
<code>alg = "OA"</code>, <code>alg = "NA"</code>, <code>alg = "OAM"</code> and
<code>alg = "NAM"</code>).</p>
</dd>
<dt>p</dt><dd><p>the order of polynomial used in the IPI-algorithm; also used for the
final smoothing, if <code>method = "lpr"</code>; input argument.</p>
</dd>
<dt>q.BIC</dt><dd><p>the order <code class="reqn">q</code> of the optimal MA(<code class="reqn">q</code>) or ARMA(<code class="reqn">p,q</code>)
model when estimating the variance factor via moving-average or
autoregressive-moving average models (if calculated; calculated for
<code>alg = "OM"</code>,
<code>alg = "NM"</code>, <code>alg = "OAM"</code> and <code>alg = "NAM"</code>).</p>
</dd>
<dt>res</dt><dd><p>the estimated residual series.</p>
</dd>
<dt>v</dt><dd><p>the considered order of derivative of the trend; is always zero for
this function.</p>
</dd>
<dt>ws</dt><dd><p>the weighting system matrix used within the local polynomial
regression; this matrix is a condensed version of a complete weighting system
matrix; in each row of <code>ws</code>, the weights for conducting the smoothing
procedure at a specific observation time point can be found; the first
<code class="reqn">[nb + 0.5]</code> rows, where <code class="reqn">n</code> corresponds to the number of
observations, <code class="reqn">b</code> is the bandwidth considered for smoothing and
<code class="reqn">[.]</code> denotes the integer part, contain the weights at the
<code class="reqn">[nb + 0.5]</code> left-hand boundary points; the weights in row
<code class="reqn">[nb + 0.5] + 1</code> are representative for the estimation at all
interior points and the remaining rows contain the weights for the right-hand
boundary points; each row has exactly <code class="reqn">2[nb + 0.5] + 1</code> elements,
more specifically the weights for observations of the nearest
<code class="reqn">2[nb + 0.5] + 1</code> time points; moreover, the weights are normalized,
i.e. the weights are obtained under consideration of the time points
<code class="reqn">x_t = t/n</code>, where <code class="reqn">t = 1, 2, ..., n</code>.</p>
</dd>
<dt>ye</dt><dd><p>the nonparametric estimates of the trend.</p>
</dd>
</dl>



<h3>Author(s)</h3>


<ul>
<li><p> Yuanhua Feng (Department of Economics, Paderborn University), <br />
Author of the Algorithms <br />
Website: <a href="https://wiwi.uni-paderborn.de/en/dep4/feng/">https://wiwi.uni-paderborn.de/en/dep4/feng/</a>
</p>
</li>
<li><p> Dominik Schulz (Research Assistant) (Department of Economics, Paderborn
University), <br />
Package Creator and Maintainer
</p>
</li></ul>



<h3>References</h3>

<p>Beran, J. and Feng, Y. (2002). Local polynomial fitting with long-memory,
short-memory and antipersistent errors. Annals of the Institute of
Statistical Mathematics, 54(2), 291-311.
</p>
<p>Bühlmann, P. (1996). Locally adaptive lag-window spectral estimation.
Journal of Time Series Analysis, 17(3), 247-270.
</p>
<p>Feng, Y., Gries, T. and Fritz, M. (2020). Data-driven
local polynomial for the trend and its derivatives in economic time
series. Journal of Nonparametric Statistics, 32:2, 510-533.
</p>
<p>Feng, Y., Gries, T., Letmathe, S. and Schulz, D. (2019). The smoots package
in R for semiparametric modeling of trend stationary time series. Discussion
Paper. Paderborn University. Unpublished.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>### Example 1: US-GDP ###

# Logarithm of test data
# -&gt; the logarithm of the data is assumed to follow the additive model
test_data &lt;- gdpUS
y &lt;- log(test_data$GDP)

# Applied tsmooth function for the trend
result &lt;- tsmooth(y, p = 1, mu = 1, Mcf = "NP", InfR = "Opt",
 bStart = 0.1, bvc = "Y")
trend1 &lt;- result$ye

# Plot of the results
t &lt;- seq(from = 1947, to = 2019.25, by = 0.25)
plot(t, y, type = "l", xlab = "Year", ylab = "log(US-GDP)", bty = "n",
 lwd = 1, lty = 3,
 main = "Estimated trend for log-quarterly US-GDP, Q1 1947 - Q2 2019")
points(t, trend1, type = "l", col = "red", lwd = 1)
title(sub = expression(italic("Figure 1")), col.sub = "gray47",
 cex.sub = 0.6, adj = 0)
result

## Not run: 
### Example 2: German Stock Index ###

# The following procedure can be considered, if (log-)returns are assumed
# to follow a model from the general class of semiparametric GARCH-type
# models (including Semi-GARCH, Semi-Log-GARCH and Semi-APARCH models among
# others) with a slowly changing variance over time due to a deterministic,
# nonparametric scale function.

# Obtain the logarithm of the squared returns
returns &lt;- diff(log(dax$Close))   # (log-)returns
rt &lt;- returns - mean(returns)     # demeaned (log-)returns
yt &lt;- log(rt^2)                   # logarithm of the squared returns

# Apply 'smoots' function to the log-data, because the logarithm of
# the squared returns follows an additive model with a nonparametric trend
# function, if the returns are assumed to follow a semiparametric GARCH-type
# model.

# In this case, the optimal inflation rate is used for p = 3.
est &lt;- tsmooth(yt, p = 3, InfR = "Opt")
m_xt &lt;- est$ye                    # estimated trend values

# Obtain the standardized returns 'eps' and the scale function 'scale.f'
res &lt;- est$res                    # the detrended log-data
C &lt;- -log(mean(exp(res)))         # an estimate of a constant value needed
                                  # for the retransformation
scale.f &lt;- exp((m_xt - C) / 2)    # estimated values of the scale function in
                                  # the returns
eps &lt;- rt / scale.f               # the estimated standardized returns

# -&gt; 'eps' can now be analyzed by any suitable GARCH-type model.
#    The total volatilities are then the product of the conditional
#    volatilities obtained from 'eps' and the scale function 'scale.f'.

## End(Not run)
</code></pre>

<hr>
<h2 id='vix'>CBOE Volatility Index (VIX) Financial Time Series Data</h2><span id='topic+vix'></span>

<h3>Description</h3>

<p>A dataset that contains the daily financial data of the VIX from
1990 to July 2019 (currency in USD).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>vix
</code></pre>


<h3>Format</h3>

<p>A data frame with 7452 rows and 9 variables:
</p>

<dl>
<dt>Year</dt><dd><p>the observation year</p>
</dd>
<dt>Month</dt><dd><p>the observation month</p>
</dd>
<dt>Day</dt><dd><p>the observation day</p>
</dd>
<dt>Open</dt><dd><p>the opening price of the day</p>
</dd>
<dt>High</dt><dd><p>the highest price of the day</p>
</dd>
<dt>Low</dt><dd><p>the lowest price of the day</p>
</dd>
<dt>Close</dt><dd><p>the closing price of the day</p>
</dd>
<dt>AdjClose</dt><dd><p>the adjusted closing price of the day</p>
</dd>
<dt>Volume</dt><dd><p>the traded volume</p>
</dd>
</dl>



<h3>Source</h3>

<p>The data was obtained from Yahoo Finance (accessed: 2019-08-22).
</p>
<p><a href="https://query1.finance.yahoo.com/v7/finance/download/%5EVIX?period1=631148400&amp;period2=1564524000&amp;interval=1d&amp;events=history&amp;crumb=Iaq1EPZAQRb">https://query1.finance.yahoo.com/v7/finance/download/^VIX?period1=631148400&amp;period2=1564524000&amp;interval=1d&amp;events=history&amp;crumb=Iaq1EPZAQRb</a>
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
