<!DOCTYPE html><html><head><title>Help for package MASS</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {MASS}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#abbey'>
<p>Determinations of Nickel Content</p></a></li>
<li><a href='#accdeaths'>
<p>Accidental Deaths in the US 1973-1978</p></a></li>
<li><a href='#addterm'>
<p>Try All One-Term Additions to a Model</p></a></li>
<li><a href='#Aids2'>
<p>Australian AIDS Survival Data</p></a></li>
<li><a href='#Animals'>
<p>Brain and Body Weights for 28 Species</p></a></li>
<li><a href='#anorexia'>
<p>Anorexia Data on Weight Change</p></a></li>
<li><a href='#anova.negbin'>
<p>Likelihood Ratio Tests for Negative Binomial GLMs</p></a></li>
<li><a href='#area'>
<p>Adaptive Numerical Integration</p></a></li>
<li><a href='#bacteria'>
<p>Presence of Bacteria after Drug Treatments</p></a></li>
<li><a href='#bandwidth.nrd'>
<p>Bandwidth for density() via Normal Reference Distribution</p></a></li>
<li><a href='#bcv'>
<p>Biased Cross-Validation for Bandwidth Selection</p></a></li>
<li><a href='#beav1'>
<p>Body Temperature Series of Beaver 1</p></a></li>
<li><a href='#beav2'>
<p>Body Temperature Series of Beaver 2</p></a></li>
<li><a href='#Belgian-phones'>
<p>Belgium Phone Calls 1950-1973</p></a></li>
<li><a href='#biopsy'>
<p>Biopsy Data on Breast Cancer Patients</p></a></li>
<li><a href='#birthwt'>
<p>Risk Factors Associated with Low Infant Birth Weight</p></a></li>
<li><a href='#Boston'>
<p>Housing Values in Suburbs of Boston</p></a></li>
<li><a href='#boxcox'>
<p>Box-Cox Transformations for Linear Models</p></a></li>
<li><a href='#cabbages'>
<p>Data from a cabbage field trial</p></a></li>
<li><a href='#caith'>
<p>Colours of Eyes and Hair of People in Caithness</p></a></li>
<li><a href='#Cars93'>
<p>Data from 93 Cars on Sale in the USA in 1993</p></a></li>
<li><a href='#cats'>
<p>Anatomical Data from Domestic Cats</p></a></li>
<li><a href='#cement'>
<p>Heat Evolved by Setting Cements</p></a></li>
<li><a href='#chem'>
<p>Copper in Wholemeal Flour</p></a></li>
<li><a href='#con2tr'>
<p>Convert Lists to Data Frames for use by lattice</p></a></li>
<li><a href='#confint-MASS'>
<p>Confidence Intervals for Model Parameters</p></a></li>
<li><a href='#contr.sdif'>
<p>Successive Differences Contrast Coding</p></a></li>
<li><a href='#coop'>
<p>Co-operative Trial in Analytical Chemistry</p></a></li>
<li><a href='#corresp'>
<p>Simple Correspondence Analysis</p></a></li>
<li><a href='#cov.rob'>
<p>Resistant Estimation of Multivariate Location and Scatter</p></a></li>
<li><a href='#cov.trob'>
<p>Covariance Estimation for Multivariate t Distribution</p></a></li>
<li><a href='#cpus'>
<p>Performance of Computer CPUs</p></a></li>
<li><a href='#crabs'>
<p>Morphological Measurements on Leptograpsus Crabs</p></a></li>
<li><a href='#Cushings'>
<p>Diagnostic Tests on Patients with Cushing's Syndrome</p></a></li>
<li><a href='#DDT'>
<p>DDT in Kale</p></a></li>
<li><a href='#deaths'>
<p>Monthly Deaths from Lung Diseases in the UK</p></a></li>
<li><a href='#denumerate'>
<p>Transform an Allowable Formula for 'loglm' into one for 'terms'</p></a></li>
<li><a href='#dose.p'>
<p>Predict Doses for Binomial Assay model</p></a></li>
<li><a href='#drivers'>
<p>Deaths of Car Drivers in Great Britain 1969-84</p></a></li>
<li><a href='#dropterm'>
<p>Try All One-Term Deletions from a Model</p></a></li>
<li><a href='#eagles'>
<p>Foraging Ecology of Bald Eagles</p></a></li>
<li><a href='#epil'>
<p>Seizure Counts for Epileptics</p></a></li>
<li><a href='#eqscplot'>
<p>Plots with Geometrically Equal Scales</p></a></li>
<li><a href='#farms'>
<p>Ecological Factors in Farm Management</p></a></li>
<li><a href='#fgl'>
<p>Measurements of Forensic Glass Fragments</p></a></li>
<li><a href='#fitdistr'>
<p>Maximum-likelihood Fitting of Univariate Distributions</p></a></li>
<li><a href='#forbes'>
<p>Forbes' Data on Boiling Points in the Alps</p></a></li>
<li><a href='#fractions'>
<p>Rational Approximation</p></a></li>
<li><a href='#GAGurine'>
<p>Level of GAG in Urine of Children</p></a></li>
<li><a href='#galaxies'>
<p>Velocities for 82 Galaxies</p></a></li>
<li><a href='#gamma.dispersion'>
<p>Calculate the MLE of the Gamma Dispersion Parameter in a GLM Fit</p></a></li>
<li><a href='#gamma.shape'>
<p>Estimate the Shape Parameter of the Gamma Distribution in a GLM Fit</p></a></li>
<li><a href='#gehan'>
<p>Remission Times of Leukaemia Patients</p></a></li>
<li><a href='#genotype'>
<p>Rat Genotype Data</p></a></li>
<li><a href='#geyser'><p>Old Faithful Geyser Data</p></a></li>
<li><a href='#gilgais'>
<p>Line Transect of Soil in Gilgai Territory</p></a></li>
<li><a href='#ginv'>
<p>Generalized Inverse of a Matrix</p></a></li>
<li><a href='#glm.convert'>
<p>Change a Negative Binomial fit to a GLM fit</p></a></li>
<li><a href='#glm.nb'>
<p>Fit a Negative Binomial Generalized Linear Model</p></a></li>
<li><a href='#glmmPQL'>
<p>Fit Generalized Linear Mixed Models via PQL</p></a></li>
<li><a href='#hills'>
<p>Record Times in Scottish Hill Races</p></a></li>
<li><a href='#hist.scott'>
<p>Plot a Histogram with Automatic Bin Width Selection</p></a></li>
<li><a href='#housing'>
<p>Frequency Table from a Copenhagen Housing Conditions Survey</p></a></li>
<li><a href='#huber'>
<p>Huber M-estimator of Location with MAD Scale</p></a></li>
<li><a href='#hubers'>
<p>Huber Proposal 2 Robust Estimator of Location and/or Scale</p></a></li>
<li><a href='#immer'>
<p>Yields from a Barley Field Trial</p></a></li>
<li><a href='#Insurance'>
<p>Numbers of Car Insurance claims</p></a></li>
<li><a href='#isoMDS'>
<p>Kruskal's Non-metric Multidimensional Scaling</p></a></li>
<li><a href='#kde2d'>
<p>Two-Dimensional Kernel Density Estimation</p></a></li>
<li><a href='#lda'>
<p>Linear Discriminant Analysis</p></a></li>
<li><a href='#ldahist'>
<p>Histograms or Density Plots of Multiple Groups</p></a></li>
<li><a href='#leuk'>
<p>Survival Times and White Blood Counts for Leukaemia Patients</p></a></li>
<li><a href='#lm.gls'>
<p>Fit Linear Models by Generalized Least Squares</p></a></li>
<li><a href='#lm.ridge'>
<p>Ridge Regression</p></a></li>
<li><a href='#loglm'>
<p>Fit Log-Linear Models by Iterative Proportional Scaling</p></a></li>
<li><a href='#loglm1'>
<p>Fit Log-Linear Models by Iterative Proportional Scaling &ndash; Internal function</p></a></li>
<li><a href='#logtrans'>
<p>Estimate log Transformation Parameter</p></a></li>
<li><a href='#lqs'>
<p>Resistant Regression</p></a></li>
<li><a href='#mammals'>
<p>Brain and Body Weights for 62 Species of Land Mammals</p></a></li>
<li><a href='#MASS-internal'><p>Internal MASS functions</p></a></li>
<li><a href='#mca'>
<p>Multiple Correspondence Analysis</p></a></li>
<li><a href='#mcycle'>
<p>Data from a Simulated Motorcycle Accident</p></a></li>
<li><a href='#Melanoma'>
<p>Survival from Malignant Melanoma</p></a></li>
<li><a href='#menarche'>
<p>Age of Menarche in Warsaw</p></a></li>
<li><a href='#michelson'>
<p>Michelson's Speed of Light Data</p></a></li>
<li><a href='#minn38'>
<p>Minnesota High School Graduates of 1938</p></a></li>
<li><a href='#motors'>
<p>Accelerated Life Testing of Motorettes</p></a></li>
<li><a href='#muscle'>
<p>Effect of Calcium Chloride on Muscle Contraction in Rat Hearts</p></a></li>
<li><a href='#mvrnorm'><p>Simulate from a Multivariate Normal Distribution</p></a></li>
<li><a href='#negative.binomial'>
<p>Family function for Negative Binomial GLMs</p></a></li>
<li><a href='#newcomb'>
<p>Newcomb's Measurements of the Passage Time of Light</p></a></li>
<li><a href='#nlschools'>
<p>Eighth-Grade Pupils in the Netherlands</p></a></li>
<li><a href='#npk'>
<p>Classical N, P, K Factorial Experiment</p></a></li>
<li><a href='#npr1'>
<p>US Naval Petroleum Reserve No. 1 data</p></a></li>
<li><a href='#Null'>
<p>Null Spaces of Matrices</p></a></li>
<li><a href='#oats'>
<p>Data from an Oats Field Trial</p></a></li>
<li><a href='#OME'>
<p>Tests of Auditory Perception in Children with OME</p></a></li>
<li><a href='#painters'>
<p>The Painter's Data of de Piles</p></a></li>
<li><a href='#pairs.lda'>
<p>Produce Pairwise Scatterplots from an 'lda' Fit</p></a></li>
<li><a href='#parcoord'>
<p>Parallel Coordinates Plot</p></a></li>
<li><a href='#petrol'>
<p>N. L. Prater's Petrol Refinery Data</p></a></li>
<li><a href='#Pima.tr'>
<p>Diabetes in Pima Indian Women</p></a></li>
<li><a href='#plot.lda'>
<p>Plot Method for Class 'lda'</p></a></li>
<li><a href='#plot.mca'>
<p>Plot Method for Objects of Class 'mca'</p></a></li>
<li><a href='#polr'>
<p>Ordered Logistic or Probit Regression</p></a></li>
<li><a href='#predict.glmmPQL'><p>Predict Method for glmmPQL Fits</p></a></li>
<li><a href='#predict.lda'>
<p>Classify Multivariate Observations by Linear Discrimination</p></a></li>
<li><a href='#predict.lqs'>
<p>Predict from an lqs Fit</p></a></li>
<li><a href='#predict.mca'>
<p>Predict Method for Class 'mca'</p></a></li>
<li><a href='#predict.qda'>
<p>Classify from Quadratic Discriminant Analysis</p></a></li>
<li><a href='#profile.glm'><p>Method for Profiling glm Objects</p></a></li>
<li><a href='#qda'>
<p>Quadratic Discriminant Analysis</p></a></li>
<li><a href='#quine'>
<p>Absenteeism from School in Rural New South Wales</p></a></li>
<li><a href='#Rabbit'>
<p>Blood Pressure in Rabbits</p></a></li>
<li><a href='#rational'>
<p>Rational Approximation</p></a></li>
<li><a href='#renumerate'>
<p>Convert a Formula Transformed by 'denumerate'</p></a></li>
<li><a href='#rlm'>
<p>Robust Fitting of Linear Models</p></a></li>
<li><a href='#rms.curv'>
<p>Relative Curvature Measures for Non-Linear Regression</p></a></li>
<li><a href='#rnegbin'>
<p>Simulate Negative Binomial Variates</p></a></li>
<li><a href='#road'>
<p>Road Accident Deaths in US States</p></a></li>
<li><a href='#rotifer'>
<p>Numbers of Rotifers by Fluid Density</p></a></li>
<li><a href='#Rubber'>
<p>Accelerated Testing of Tyre Rubber</p></a></li>
<li><a href='#sammon'>
<p>Sammon's Non-Linear Mapping</p></a></li>
<li><a href='#ships'>
<p>Ships Damage Data</p></a></li>
<li><a href='#shoes'>
<p>Shoe wear data of Box, Hunter and Hunter</p></a></li>
<li><a href='#shrimp'>
<p>Percentage of Shrimp in Shrimp Cocktail</p></a></li>
<li><a href='#shuttle'>
<p>Space Shuttle Autolander Problem</p></a></li>
<li><a href='#Sitka'>
<p>Growth Curves for Sitka Spruce Trees in 1988</p></a></li>
<li><a href='#Sitka89'>
<p>Growth Curves for Sitka Spruce Trees in 1989</p></a></li>
<li><a href='#Skye'>
<p>AFM Compositions of Aphyric Skye Lavas</p></a></li>
<li><a href='#snails'>
<p>Snail Mortality Data</p></a></li>
<li><a href='#SP500'>
<p>Returns of the Standard and Poors 500</p></a></li>
<li><a href='#stdres'>
<p>Extract Standardized Residuals from a Linear Model</p></a></li>
<li><a href='#steam'>
<p>The Saturated Steam Pressure Data</p></a></li>
<li><a href='#stepAIC'>
<p>Choose a model by AIC in a Stepwise Algorithm</p></a></li>
<li><a href='#stormer'>
<p>The Stormer Viscometer Data</p></a></li>
<li><a href='#studres'>
<p>Extract Studentized Residuals from a Linear Model</p></a></li>
<li><a href='#summary.loglm'>
<p>Summary Method Function for Objects of Class 'loglm'</p></a></li>
<li><a href='#summary.negbin'>
<p>Summary Method Function for Objects of Class 'negbin'</p></a></li>
<li><a href='#summary.rlm'>
<p>Summary Method for Robust Linear Models</p></a></li>
<li><a href='#survey'>
<p>Student Survey Data</p></a></li>
<li><a href='#synth.tr'>
<p>Synthetic Classification Problem</p></a></li>
<li><a href='#theta.md'>
<p>Estimate theta of the Negative Binomial</p></a></li>
<li><a href='#topo'>
<p>Spatial Topographic Data</p></a></li>
<li><a href='#Traffic'>
<p>Effect of Swedish Speed Limits on Accidents</p></a></li>
<li><a href='#truehist'>
<p>Plot a Histogram</p></a></li>
<li><a href='#ucv'>
<p>Unbiased Cross-Validation for Bandwidth Selection</p></a></li>
<li><a href='#UScereal'>
<p>Nutritional and Marketing Information on US Cereals</p></a></li>
<li><a href='#UScrime'>
<p>The Effect of Punishment Regimes on Crime Rates</p></a></li>
<li><a href='#VA'>
<p>Veteran's Administration Lung Cancer Trial</p></a></li>
<li><a href='#waders'>
<p>Counts of Waders at 15 Sites in South Africa</p></a></li>
<li><a href='#whiteside'>
<p>House Insulation: Whiteside's Data</p></a></li>
<li><a href='#width.SJ'>
<p>Bandwidth Selection by Pilot Estimation of Derivatives</p></a></li>
<li><a href='#write.matrix'>
<p>Write a Matrix or Data Frame</p></a></li>
<li><a href='#wtloss'>
<p>Weight Loss Data from an Obese Patient</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Priority:</td>
<td>recommended</td>
</tr>
<tr>
<td>Version:</td>
<td>7.3-60.2</td>
</tr>
<tr>
<td>Date:</td>
<td>2024-01-12</td>
</tr>
<tr>
<td>Revision:</td>
<td>$Rev: 3641 $</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 4.4.0), grDevices, graphics, stats, utils</td>
</tr>
<tr>
<td>Imports:</td>
<td>methods</td>
</tr>
<tr>
<td>Suggests:</td>
<td>lattice, nlme, nnet, survival</td>
</tr>
<tr>
<td>Description:</td>
<td>Functions and datasets to support Venables and Ripley,
  "Modern Applied Statistics with S" (4th edition, 2002).</td>
</tr>
<tr>
<td>Title:</td>
<td>Support Functions and Datasets for Venables and Ripley's MASS</td>
</tr>
<tr>
<td>LazyData:</td>
<td>yes</td>
</tr>
<tr>
<td>ByteCompile:</td>
<td>yes</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>URL:</td>
<td><a href="http://www.stats.ox.ac.uk/pub/MASS4/">http://www.stats.ox.ac.uk/pub/MASS4/</a></td>
</tr>
<tr>
<td>Contact:</td>
<td>&lt;MASS@stats.ox.ac.uk&gt;</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-01-12 08:51:36 UTC; ripley</td>
</tr>
<tr>
<td>Author:</td>
<td>Brian Ripley [aut, cre, cph],
  Bill Venables [ctb],
  Douglas M. Bates [ctb],
  Kurt Hornik [trl] (partial port ca 1998),
  Albrecht Gebhardt [trl] (partial port ca 1998),
  David Firth [ctb]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Brian Ripley &lt;ripley@stats.ox.ac.uk&gt;</td>
</tr>
<tr>
<td>Built:</td>
<td>R 4.4.0; x86_64-pc-linux-gnu; 2024-03-26 07:22:49 UTC; unix</td>
</tr>
</table>
<hr>
<h2 id='abbey'>
Determinations of Nickel Content
</h2><span id='topic+abbey'></span>

<h3>Description</h3>

<p>A numeric vector of 31 determinations of nickel content (ppm) in
a Canadian syenite rock.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>abbey
</code></pre>


<h3>Source</h3>

<p>S. Abbey (1988) <em>Geostandards Newsletter</em> <b>12</b>, 241.
</p>


<h3>References</h3>

<p>Venables, W. N. and Ripley, B. D. (2002)
<em>Modern Applied Statistics with S.</em> Fourth edition.  Springer.
</p>

<hr>
<h2 id='accdeaths'>
Accidental Deaths in the US 1973-1978
</h2><span id='topic+accdeaths'></span>

<h3>Description</h3>

<p>A regular time series giving the monthly totals of accidental
deaths in the USA. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>accdeaths
</code></pre>


<h3>Details</h3>

<p>The values for first six months of 1979 (p. 326) were
<code>7798 7406 8363 8460 9217 9316</code>.
</p>


<h3>Source</h3>

<p>P. J. Brockwell and R. A. Davis (1991)
<em>Time Series: Theory and Methods.</em>
Springer, New York.
</p>


<h3>References</h3>

<p>Venables, W. N. and Ripley, B. D. (2002)
<em>Modern Applied Statistics with S-PLUS.</em> Fourth Edition. Springer.
</p>

<hr>
<h2 id='addterm'>
Try All One-Term Additions to a Model
</h2><span id='topic+addterm'></span><span id='topic+addterm.default'></span><span id='topic+addterm.glm'></span><span id='topic+addterm.lm'></span>

<h3>Description</h3>

<p>Try fitting all models that differ from the current model by adding a
single term from those supplied, maintaining marginality.
</p>
<p>This function is generic; there exist methods for classes <code>lm</code> and
<code>glm</code> and the default method will work for many other classes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>addterm(object, ...)

## Default S3 method:
addterm(object, scope, scale = 0, test = c("none", "Chisq"),
        k = 2, sorted = FALSE, trace = FALSE, ...)
## S3 method for class 'lm'
addterm(object, scope, scale = 0, test = c("none", "Chisq", "F"),
        k = 2, sorted = FALSE, ...)
## S3 method for class 'glm'
addterm(object, scope, scale = 0, test = c("none", "Chisq", "F"),
        k = 2, sorted = FALSE, trace = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="addterm_+3A_object">object</code></td>
<td>

<p>An object fitted by some model-fitting function.
</p>
</td></tr>
<tr><td><code id="addterm_+3A_scope">scope</code></td>
<td>

<p>a formula specifying a maximal model which should include the current
one. All additional terms in the maximal model with all marginal terms
in the original model are tried.
</p>
</td></tr>
<tr><td><code id="addterm_+3A_scale">scale</code></td>
<td>

<p>used in the definition of the AIC statistic for selecting the models,
currently only for <code>lm</code>, <code>aov</code> and <code>glm</code> models. Specifying <code>scale</code>
asserts that the residual standard error or dispersion is known.
</p>
</td></tr>
<tr><td><code id="addterm_+3A_test">test</code></td>
<td>

<p>should the results include a test statistic relative to the original
model?  The F test is only appropriate for <code>lm</code> and <code>aov</code> models,
and perhaps for some over-dispersed <code>glm</code> models. The
Chisq test can be an exact test (<code>lm</code> models with known scale) or a
likelihood-ratio test depending on the method.
</p>
</td></tr>
<tr><td><code id="addterm_+3A_k">k</code></td>
<td>

<p>the multiple of the number of degrees of freedom used for the penalty.
Only <code>k=2</code> gives the genuine AIC: <code>k = log(n)</code> is sometimes referred
to as BIC or SBC.
</p>
</td></tr>
<tr><td><code id="addterm_+3A_sorted">sorted</code></td>
<td>

<p>should the results be sorted on the value of AIC?
</p>
</td></tr>
<tr><td><code id="addterm_+3A_trace">trace</code></td>
<td>

<p>if <code>TRUE</code> additional information may be given on the fits as they are tried.
</p>
</td></tr>
<tr><td><code id="addterm_+3A_...">...</code></td>
<td>

<p>arguments passed to or from other methods.
</p>
</td></tr></table>


<h3>Details</h3>

<p>The definition of AIC is only up to an additive constant: when
appropriate (<code>lm</code> models with specified scale) the constant is taken
to be that used in Mallows' Cp statistic and the results are labelled
accordingly.
</p>


<h3>Value</h3>

<p>A table of class <code>"anova"</code> containing at least columns for the change
in degrees of freedom and AIC (or Cp) for the models. Some methods
will give further information, for example sums of squares, deviances,
log-likelihoods and test statistics.
</p>


<h3>References</h3>

<p>Venables, W. N. and Ripley, B. D. (2002)
<em>Modern Applied Statistics with S.</em> Fourth edition.  Springer.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+dropterm">dropterm</a></code>, <code><a href="#topic+stepAIC">stepAIC</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>quine.hi &lt;- aov(log(Days + 2.5) ~ .^4, quine)
quine.lo &lt;- aov(log(Days+2.5) ~ 1, quine)
addterm(quine.lo, quine.hi, test="F")

house.glm0 &lt;- glm(Freq ~ Infl*Type*Cont + Sat, family=poisson,
                   data=housing)
addterm(house.glm0, ~. + Sat:(Infl+Type+Cont), test="Chisq")
house.glm1 &lt;- update(house.glm0, . ~ . + Sat*(Infl+Type+Cont))
addterm(house.glm1, ~. + Sat:(Infl+Type+Cont)^2, test = "Chisq")
</code></pre>

<hr>
<h2 id='Aids2'>
Australian AIDS Survival Data
</h2><span id='topic+Aids2'></span>

<h3>Description</h3>

<p>Data on patients diagnosed with AIDS in Australia before 1 July 1991.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Aids2
</code></pre>


<h3>Format</h3>

<p>This data frame contains 2843 rows and the following columns:
</p>

<dl>
<dt><code>state</code></dt><dd>
<p>Grouped state of origin: <code>"NSW "</code>includes ACT and
<code>"other"</code> is WA, SA, NT and TAS.
</p>
</dd>
<dt><code>sex</code></dt><dd>
<p>Sex of patient.
</p>
</dd>
<dt><code>diag</code></dt><dd><p>(Julian) date of diagnosis.</p>
</dd>
<dt><code>death</code></dt><dd>
<p>(Julian) date of death or end of observation.
</p>
</dd>
<dt><code>status</code></dt><dd>
<p><code>"A"</code> (alive) or <code>"D"</code> (dead) at end of observation.
</p>
</dd>
<dt><code>T.categ</code></dt><dd>
<p>Reported transmission category.
</p>
</dd>
<dt><code>age</code></dt><dd>
<p>Age (years) at diagnosis.
</p>
</dd>
</dl>



<h3>Note</h3>

<p>This data set has been slightly jittered as a
condition of its release, to ensure patient confidentiality.
</p>


<h3>Source</h3>

<p>Dr P. J. Solomon and the Australian National Centre in HIV Epidemiology
and Clinical Research.
</p>


<h3>References</h3>

<p>Venables, W. N. and Ripley, B. D. (2002)
<em>Modern Applied Statistics with S.</em> Fourth edition.  Springer.
</p>

<hr>
<h2 id='Animals'>
Brain and Body Weights for 28 Species
</h2><span id='topic+Animals'></span>

<h3>Description</h3>

<p>Average brain and body weights for 28 species of land animals.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Animals
</code></pre>


<h3>Format</h3>


<dl>
<dt><code>body</code></dt><dd>
<p>body weight in kg.
</p>
</dd>
<dt><code>brain</code></dt><dd>
<p>brain weight in g.
</p>
</dd>
</dl>



<h3>Note</h3>

<p>The name <code>Animals</code> avoided conflicts with a system dataset
<code>animals</code> in S-PLUS 4.5 and later.
</p>


<h3>Source</h3>

<p>P. J. Rousseeuw  and A. M. Leroy (1987)
<em>Robust Regression and Outlier Detection.</em>
Wiley, p. 57.
</p>


<h3>References</h3>

<p>Venables, W. N. and Ripley, B. D. (2002)
<em>Modern Applied Statistics with S-PLUS.</em> Fourth Edition. Springer.
</p>

<hr>
<h2 id='anorexia'>
Anorexia Data on Weight Change
</h2><span id='topic+anorexia'></span>

<h3>Description</h3>

<p>The <code>anorexia</code> data frame has 72 rows and 3 columns.
Weight change data for young female anorexia patients.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>anorexia
</code></pre>


<h3>Format</h3>

<p>This data frame contains the following columns:
</p>

<dl>
<dt><code>Treat</code></dt><dd>
<p>Factor of three levels: <code>"Cont"</code> (control), <code>"CBT"</code>
(Cognitive Behavioural treatment) and  <code>"FT"</code> (family
treatment).
</p>
</dd>
<dt><code>Prewt</code></dt><dd>
<p>Weight of patient before study period, in lbs.
</p>
</dd>
<dt><code>Postwt</code></dt><dd>
<p>Weight of patient after study period, in lbs.
</p>
</dd>
</dl>



<h3>Source</h3>

<p>Hand, D. J., Daly, F., McConway, K., Lunn, D. and Ostrowski, E. eds (1993)
<em>A Handbook of Small Data Sets.</em>
Chapman &amp; Hall, Data set 285 (p. 229)
</p>
<p>(Note that the original source mistakenly says that weights are in kg.)
</p>


<h3>References</h3>

<p>Venables, W. N. and Ripley, B. D. (2002)
<em>Modern Applied Statistics with S.</em> Fourth edition.  Springer.
</p>

<hr>
<h2 id='anova.negbin'>
Likelihood Ratio Tests for Negative Binomial GLMs
</h2><span id='topic+anova.negbin'></span>

<h3>Description</h3>

<p>Method function to perform sequential likelihood ratio tests for Negative
Binomial generalized linear models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'negbin'
anova(object, ..., test = "Chisq")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="anova.negbin_+3A_object">object</code></td>
<td>

<p>Fitted model object of class <code>"negbin"</code>, inheriting from
classes <code>"glm"</code> and <code>"lm"</code>, specifying a Negative Binomial
fitted GLM.  Typically the output of <code><a href="#topic+glm.nb">glm.nb</a>()</code>.
</p>
</td></tr>
<tr><td><code id="anova.negbin_+3A_...">...</code></td>
<td>

<p>Zero or more additional fitted model objects of class <code>"negbin"</code>.  They
should form a nested sequence of models, but need not be specified in any
particular order.
</p>
</td></tr>
<tr><td><code id="anova.negbin_+3A_test">test</code></td>
<td>

<p>Argument to match the <code>test</code> argument of <code><a href="stats.html#topic+anova.glm">anova.glm</a></code>.
Ignored (with a warning if changed) if a sequence of two or more
Negative Binomial fitted model objects is specified, but possibly
used if only one object is specified.
</p>
</td></tr></table>


<h3>Details</h3>

<p>This function is a method for the generic function
<code>anova()</code> for class <code>"negbin"</code>.
It can be invoked by calling <code>anova(x)</code> for an
object <code>x</code> of the appropriate class, or directly by
calling <code>anova.negbin(x)</code> regardless of the
class of the object.
</p>


<h3>Note</h3>

<p>If only one fitted model object is specified, a sequential analysis of
deviance table is given for the fitted model.  The <code>theta</code> parameter is kept
fixed.  If more than one fitted model object is specified they must all be
of class <code>"negbin"</code> and likelihood ratio tests are done of each model within
the next.  In this case <code>theta</code> is assumed to have been re-estimated for each
model.
</p>


<h3>References</h3>

<p>Venables, W. N. and Ripley, B. D. (2002)
<em>Modern Applied Statistics with S.</em> Fourth edition.  Springer.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+glm.nb">glm.nb</a></code>, <code><a href="#topic+negative.binomial">negative.binomial</a></code>, <code><a href="#topic+summary.negbin">summary.negbin</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>m1 &lt;- glm.nb(Days ~ Eth*Age*Lrn*Sex, quine, link = log)
m2 &lt;- update(m1, . ~ . - Eth:Age:Lrn:Sex)
anova(m2, m1)
anova(m2)
</code></pre>

<hr>
<h2 id='area'>
Adaptive Numerical Integration
</h2><span id='topic+area'></span>

<h3>Description</h3>

<p>Integrate a function of one variable over a finite range using a
recursive adaptive method.  This function is mainly for
demonstration purposes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>area(f, a, b, ..., fa = f(a, ...), fb = f(b, ...),
     limit = 10, eps = 1e-05)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="area_+3A_f">f</code></td>
<td>

<p>The integrand as an <code>S</code> function object.  The variable of integration must be
the first argument.
</p>
</td></tr>
<tr><td><code id="area_+3A_a">a</code></td>
<td>

<p>Lower limit of integration.
</p>
</td></tr>
<tr><td><code id="area_+3A_b">b</code></td>
<td>

<p>Upper limit of integration.
</p>
</td></tr>
<tr><td><code id="area_+3A_...">...</code></td>
<td>

<p>Additional arguments needed by the integrand.
</p>
</td></tr>
<tr><td><code id="area_+3A_fa">fa</code></td>
<td>

<p>Function value at the lower limit.
</p>
</td></tr>
<tr><td><code id="area_+3A_fb">fb</code></td>
<td>

<p>Function value at the upper limit.
</p>
</td></tr>
<tr><td><code id="area_+3A_limit">limit</code></td>
<td>

<p>Limit on the depth to which recursion is allowed to go.
</p>
</td></tr>
<tr><td><code id="area_+3A_eps">eps</code></td>
<td>

<p>Error tolerance to control the process.
</p>
</td></tr></table>


<h3>Details</h3>

<p>The method divides the interval in two and compares the values given by
Simpson's rule and the trapezium rule.  If these are within eps of each
other the Simpson's rule result is given, otherwise the process is applied
separately to each half of the interval and the results added together.
</p>


<h3>Value</h3>

<p>The integral from <code>a</code> to <code>b</code> of <code>f(x)</code>.
</p>


<h3>References</h3>

<p>Venables, W. N. and Ripley, B. D. (1994)
<em>Modern Applied Statistics with S-Plus.</em> Springer.
pp. 105&ndash;110.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>area(sin, 0, pi)  # integrate the sin function from 0 to pi.
</code></pre>

<hr>
<h2 id='bacteria'>
Presence of Bacteria after Drug Treatments
</h2><span id='topic+bacteria'></span>

<h3>Description</h3>

<p>Tests of the presence of the bacteria <em>H. influenzae</em>
in children with otitis media in the Northern Territory of Australia.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bacteria
</code></pre>


<h3>Format</h3>

<p>This data frame has 220 rows and the following columns:
</p>

<dl>
<dt>y</dt><dd><p>presence or absence: a factor with levels
<code>n</code> and <code>y</code>.</p>
</dd>
<dt>ap</dt><dd><p>active/placebo: a factor with levels <code>a</code> and <code>p</code>.</p>
</dd>
<dt>hilo</dt><dd><p>hi/low compliance: a factor with levels <code>hi</code> amd
<code>lo</code>.</p>
</dd>
<dt>week</dt><dd><p>numeric: week of test.</p>
</dd>
<dt>ID</dt><dd><p>subject ID: a factor.</p>
</dd>
<dt>trt</dt><dd><p>a factor with levels <code>placebo</code>, <code>drug</code> and
<code>drug+</code>, a re-coding of <code>ap</code> and <code>hilo</code>.</p>
</dd>
</dl>



<h3>Details</h3>

<p>Dr A. Leach tested the effects of a drug on 50 children with a history of
otitis media in the Northern Territory of Australia.  The children
were randomized to the drug or the a placebo, and also to receive
active encouragement to comply with taking the drug.
</p>
<p>The presence of <em>H. influenzae</em> was checked at weeks 0, 2, 4, 6
and 11: 30 of the checks were missing and are not included in this
data frame.
</p>


<h3>Source</h3>

<p>Dr Amanda Leach <em>via</em> Mr James McBroom.
</p>


<h3>References</h3>

<p>Menzies School of Health Research 1999&ndash;2000 Annual Report. p.20.
<a href="https://www.menzies.edu.au/icms_docs/172302_2000_Annual_report.pdf">https://www.menzies.edu.au/icms_docs/172302_2000_Annual_report.pdf</a>.
</p>
<p>Venables, W. N. and Ripley, B. D. (2002)
<em>Modern Applied Statistics with S.</em> Fourth edition.  Springer.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>contrasts(bacteria$trt) &lt;- structure(contr.sdif(3),
     dimnames = list(NULL, c("drug", "encourage")))
## fixed effects analyses
## IGNORE_RDIFF_BEGIN
summary(glm(y ~ trt * week, binomial, data = bacteria))
summary(glm(y ~ trt + week, binomial, data = bacteria))
summary(glm(y ~ trt + I(week &gt; 2), binomial, data = bacteria))
## IGNORE_RDIFF_END

# conditional random-effects analysis
library(survival)
bacteria$Time &lt;- rep(1, nrow(bacteria))
coxph(Surv(Time, unclass(y)) ~ week + strata(ID),
      data = bacteria, method = "exact")
coxph(Surv(Time, unclass(y)) ~ factor(week) + strata(ID),
      data = bacteria, method = "exact")
coxph(Surv(Time, unclass(y)) ~ I(week &gt; 2) + strata(ID),
      data = bacteria, method = "exact")

# PQL glmm analysis
library(nlme)
## IGNORE_RDIFF_BEGIN
summary(glmmPQL(y ~ trt + I(week &gt; 2), random = ~ 1 | ID,
                family = binomial, data = bacteria))
## IGNORE_RDIFF_END
</code></pre>

<hr>
<h2 id='bandwidth.nrd'>
Bandwidth for density() via Normal Reference Distribution
</h2><span id='topic+bandwidth.nrd'></span>

<h3>Description</h3>

<p>A well-supported rule-of-thumb for choosing the bandwidth of a Gaussian
kernel density estimator.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bandwidth.nrd(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bandwidth.nrd_+3A_x">x</code></td>
<td>

<p>A data vector.
</p>
</td></tr></table>


<h3>Value</h3>

<p>A bandwidth on a scale suitable for the <code>width</code> argument of
<code>density</code>.
</p>


<h3>References</h3>

<p>Venables, W. N. and Ripley, B. D. (2002)
<em>Modern Applied Statistics with S.</em>
Springer, equation (5.5) on page 130.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># The function is currently defined as
function(x)
{
    r &lt;- quantile(x, c(0.25, 0.75))
    h &lt;- (r[2] - r[1])/1.34
    4 * 1.06 * min(sqrt(var(x)), h) * length(x)^(-1/5)
}
</code></pre>

<hr>
<h2 id='bcv'>
Biased Cross-Validation for Bandwidth Selection
</h2><span id='topic+bcv'></span>

<h3>Description</h3>

<p>Uses biased cross-validation to select the bandwidth of a  Gaussian
kernel density estimator.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bcv(x, nb = 1000, lower, upper)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bcv_+3A_x">x</code></td>
<td>

<p>a numeric vector
</p>
</td></tr>
<tr><td><code id="bcv_+3A_nb">nb</code></td>
<td>

<p>number of bins to use.
</p>
</td></tr>
<tr><td><code id="bcv_+3A_lower">lower</code>, <code id="bcv_+3A_upper">upper</code></td>
<td>

<p>Range over which to minimize.  The default is almost always satisfactory.
</p>
</td></tr></table>


<h3>Value</h3>

<p>a bandwidth
</p>


<h3>References</h3>

<p>Scott, D. W. (1992)
<em>Multivariate Density Estimation: Theory, Practice, and Visualization.</em>
Wiley.
</p>
<p>Venables, W. N. and Ripley, B. D. (2002)
<em>Modern Applied Statistics with S.</em> Fourth edition.  Springer.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ucv">ucv</a></code>, <code><a href="#topic+width.SJ">width.SJ</a></code>, <code><a href="stats.html#topic+density">density</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>bcv(geyser$duration)
</code></pre>

<hr>
<h2 id='beav1'>
Body Temperature Series of Beaver 1
</h2><span id='topic+beav1'></span>

<h3>Description</h3>

<p>Reynolds (1994) describes a small part of a study of the long-term
temperature dynamics of beaver <em>Castor canadensis</em> in
north-central Wisconsin.  Body temperature was measured by telemetry
every 10 minutes for four females, but data from a one period of less
than a day for each of two animals is used there.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>beav1
</code></pre>


<h3>Format</h3>

<p>The <code>beav1</code> data frame has 114 rows and 4 columns.
This data frame contains the following columns:
</p>

<dl>
<dt><code>day</code></dt><dd>
<p>Day of observation (in days since the beginning of 1990),
December 12&ndash;13.
</p>
</dd>
<dt><code>time</code></dt><dd>
<p>Time of observation, in the form <code>0330</code> for 3.30am.
</p>
</dd>
<dt><code>temp</code></dt><dd>
<p>Measured body temperature in degrees Celsius.
</p>
</dd>
<dt><code>activ</code></dt><dd>
<p>Indicator of activity outside the retreat.
</p>
</dd>
</dl>



<h3>Note</h3>

<p>The observation at 22:20 is missing.
</p>


<h3>Source</h3>

<p>P. S. Reynolds (1994) Time-series analyses of beaver body temperatures.
Chapter 11 of
Lange, N., Ryan, L., Billard, L., Brillinger, D., Conquest, L.
and Greenhouse, J. eds (1994) <em>Case Studies in Biometry.</em> New
York: John Wiley and Sons.
</p>


<h3>References</h3>

<p>Venables, W. N. and Ripley, B. D. (2002)
<em>Modern Applied Statistics with S.</em> Fourth edition.  Springer.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+beav2">beav2</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>beav1 &lt;- within(beav1,
               hours &lt;- 24*(day-346) + trunc(time/100) + (time%%100)/60)
plot(beav1$hours, beav1$temp, type="l", xlab="time",
   ylab="temperature", main="Beaver 1")
usr &lt;- par("usr"); usr[3:4] &lt;- c(-0.2, 8); par(usr=usr)
lines(beav1$hours, beav1$activ, type="s", lty=2)
temp &lt;- ts(c(beav1$temp[1:82], NA, beav1$temp[83:114]),
           start = 9.5, frequency = 6)
activ &lt;- ts(c(beav1$activ[1:82], NA, beav1$activ[83:114]),
            start = 9.5, frequency = 6)

acf(temp[1:53])
acf(temp[1:53], type = "partial")
ar(temp[1:53])
act &lt;- c(rep(0, 10), activ)
X &lt;- cbind(1, act = act[11:125], act1 = act[10:124],
          act2 = act[9:123], act3 = act[8:122])
alpha &lt;- 0.80
stemp &lt;- as.vector(temp - alpha*lag(temp, -1))
sX &lt;- X[-1, ] - alpha * X[-115,]
beav1.ls &lt;- lm(stemp ~ -1 + sX, na.action = na.omit)
summary(beav1.ls, correlation = FALSE)
rm(temp, activ)
</code></pre>

<hr>
<h2 id='beav2'>
Body Temperature Series of Beaver 2
</h2><span id='topic+beav2'></span>

<h3>Description</h3>

<p>Reynolds (1994) describes a small part of a study of the long-term
temperature dynamics of beaver <em>Castor canadensis</em> in
north-central Wisconsin.  Body temperature was measured by telemetry
every 10 minutes for four females, but data from a one period of less
than a day for each of two animals is used there.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>beav2
</code></pre>


<h3>Format</h3>

<p>The <code>beav2</code> data frame has 100 rows and 4 columns.
This data frame contains the following columns:
</p>

<dl>
<dt><code>day</code></dt><dd>
<p>Day of observation (in days since the beginning of 1990),
November 3&ndash;4.
</p>
</dd>
<dt><code>time</code></dt><dd>
<p>Time of observation, in the form <code>0330</code> for 3.30am.
</p>
</dd>
<dt><code>temp</code></dt><dd>
<p>Measured body temperature in degrees Celsius.
</p>
</dd>
<dt><code>activ</code></dt><dd>
<p>Indicator of activity outside the retreat.
</p>
</dd>
</dl>



<h3>Source</h3>

<p>P. S. Reynolds (1994) Time-series analyses of beaver body temperatures.
Chapter 11 of
Lange, N., Ryan, L., Billard, L., Brillinger, D., Conquest, L.
and Greenhouse, J. eds (1994)
<em>Case Studies in Biometry.</em> New York: John Wiley and Sons.
</p>


<h3>References</h3>

<p>Venables, W. N. and Ripley, B. D. (2002)
<em>Modern Applied Statistics with S.</em> Fourth edition.  Springer.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+beav1">beav1</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>attach(beav2)
beav2$hours &lt;- 24*(day-307) + trunc(time/100) + (time%%100)/60
plot(beav2$hours, beav2$temp, type = "l", xlab = "time",
   ylab = "temperature", main = "Beaver 2")
usr &lt;- par("usr"); usr[3:4] &lt;- c(-0.2, 8); par(usr = usr)
lines(beav2$hours, beav2$activ, type = "s", lty = 2)

temp &lt;- ts(temp, start = 8+2/3, frequency = 6)
activ &lt;- ts(activ, start = 8+2/3, frequency = 6)
acf(temp[activ == 0]); acf(temp[activ == 1]) # also look at PACFs
ar(temp[activ == 0]); ar(temp[activ == 1])

arima(temp, order = c(1,0,0), xreg = activ)
dreg &lt;- cbind(sin = sin(2*pi*beav2$hours/24), cos = cos(2*pi*beav2$hours/24))
arima(temp, order = c(1,0,0), xreg = cbind(active=activ, dreg))

## IGNORE_RDIFF_BEGIN
library(nlme) # for gls and corAR1
beav2.gls &lt;- gls(temp ~ activ, data = beav2, correlation = corAR1(0.8),
                 method = "ML")
summary(beav2.gls)
summary(update(beav2.gls, subset = 6:100))
detach("beav2"); rm(temp, activ)
## IGNORE_RDIFF_END
</code></pre>

<hr>
<h2 id='Belgian-phones'>
Belgium Phone Calls 1950-1973
</h2><span id='topic+phones'></span>

<h3>Description</h3>

<p>A list object with the annual numbers of telephone calls, in
Belgium.  The components are:
</p>

<dl>
<dt><code>year</code></dt><dd>
<p>last two digits of the year.
</p>
</dd>
<dt><code>calls</code></dt><dd>
<p>number of telephone calls made (in millions of calls).
</p>
</dd>
</dl>



<h3>Usage</h3>

<pre><code class='language-R'>phones
</code></pre>


<h3>Source</h3>

<p>P. J. Rousseeuw and A. M. Leroy (1987)
<em>Robust Regression &amp; Outlier Detection.</em> Wiley.
</p>


<h3>References</h3>

<p>Venables, W. N. and Ripley, B. D. (2002)
<em>Modern Applied Statistics with S.</em> Fourth edition.  Springer.
</p>

<hr>
<h2 id='biopsy'>
Biopsy Data on Breast Cancer Patients
</h2><span id='topic+biopsy'></span>

<h3>Description</h3>

<p>This breast cancer database was obtained from the University of Wisconsin
Hospitals, Madison from Dr. William H. Wolberg. He assessed biopsies
of breast tumours for 699 patients up to 15 July 1992; each of nine
attributes has been scored on a scale of 1 to 10, and the outcome is
also known. There are 699 rows and 11 columns.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>biopsy
</code></pre>


<h3>Format</h3>

<p>This data frame contains the following columns:
</p>

<dl>
<dt><code>ID</code></dt><dd><p>sample code number (not unique).</p>
</dd>
<dt><code>V1</code></dt><dd><p>clump thickness.</p>
</dd>
<dt><code>V2</code></dt><dd><p>uniformity of cell size.</p>
</dd>
<dt><code>V3</code></dt><dd><p>uniformity of cell shape.</p>
</dd>
<dt><code>V4</code></dt><dd><p>marginal adhesion.</p>
</dd>
<dt><code>V5</code></dt><dd><p>single epithelial cell size.</p>
</dd>
<dt><code>V6</code></dt><dd><p>bare nuclei (16 values are missing).</p>
</dd>
<dt><code>V7</code></dt><dd><p>bland chromatin.</p>
</dd>
<dt><code>V8</code></dt><dd><p>normal nucleoli.</p>
</dd>
<dt><code>V9</code></dt><dd><p>mitoses.</p>
</dd>
<dt><code>class</code></dt><dd><p><code>"benign"</code> or <code>"malignant"</code>.</p>
</dd>
</dl>



<h3>Source</h3>

<p>P. M. Murphy and D. W. Aha  (1992). UCI Repository of machine
learning databases. [Machine-readable data repository]. Irvine, CA:
University of California, Department of Information and Computer Science.
</p>
<p>O. L. Mangasarian and W. H. Wolberg (1990)
Cancer diagnosis via linear programming.
<em>SIAM News</em> <b>23</b>, pp 1 &amp; 18.
</p>
<p>William H. Wolberg and O.L. Mangasarian (1990)
Multisurface method of pattern separation for medical diagnosis
applied to breast cytology.
<em>Proceedings of the National Academy of Sciences, U.S.A.</em>
<b>87</b>, pp. 9193&ndash;9196.
</p>
<p>O. L. Mangasarian, R. Setiono and W.H. Wolberg (1990)
Pattern recognition via linear programming: Theory and application
to medical diagnosis. In
<em>Large-scale Numerical Optimization</em>
eds Thomas F. Coleman and Yuying Li, SIAM Publications, Philadelphia,
pp 22&ndash;30.
</p>
<p>K. P. Bennett and O. L. Mangasarian (1992)
Robust linear programming discrimination of two linearly inseparable sets.
<em>Optimization Methods and Software</em>
<b>1</b>, pp. 23&ndash;34 (Gordon &amp; Breach Science Publishers).
</p>


<h3>References</h3>

<p>Venables, W. N. and Ripley, B. D. (2002)
<em>Modern Applied Statistics with S-PLUS.</em> Fourth Edition. Springer.
</p>

<hr>
<h2 id='birthwt'>
Risk Factors Associated with Low Infant Birth Weight
</h2><span id='topic+birthwt'></span>

<h3>Description</h3>

<p>The <code>birthwt</code> data frame has 189 rows and 10 columns.
The data were collected at Baystate Medical Center, Springfield, Mass
during 1986.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>birthwt
</code></pre>


<h3>Format</h3>

<p>This data frame contains the following columns:
</p>

<dl>
<dt><code>low</code></dt><dd><p>indicator of birth weight less than 2.5 kg.</p>
</dd>
<dt><code>age</code></dt><dd><p>mother's age in years.</p>
</dd>
<dt><code>lwt</code></dt><dd><p>mother's weight in pounds at last menstrual period.</p>
</dd>
<dt><code>race</code></dt><dd><p>mother's race (<code>1</code> = white, <code>2</code> = black,
<code>3</code> = other).</p>
</dd>
<dt><code>smoke</code></dt><dd><p>smoking status during pregnancy.</p>
</dd>
<dt><code>ptl</code></dt><dd><p>number of previous premature labours.</p>
</dd>
<dt><code>ht</code></dt><dd><p>history of hypertension.</p>
</dd>
<dt><code>ui</code></dt><dd><p>presence of uterine irritability.</p>
</dd>
<dt><code>ftv</code></dt><dd><p>number of physician visits during the first trimester.</p>
</dd>
<dt><code>bwt</code></dt><dd><p>birth weight in grams.</p>
</dd>
</dl>



<h3>Source</h3>

<p>Hosmer, D.W. and Lemeshow, S. (1989)
<em>Applied Logistic Regression.</em> New York: Wiley
</p>


<h3>References</h3>

<p>Venables, W. N. and Ripley, B. D. (2002)
<em>Modern Applied Statistics with S.</em> Fourth edition.  Springer.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>bwt &lt;- with(birthwt, {
race &lt;- factor(race, labels = c("white", "black", "other"))
ptd &lt;- factor(ptl &gt; 0)
ftv &lt;- factor(ftv)
levels(ftv)[-(1:2)] &lt;- "2+"
data.frame(low = factor(low), age, lwt, race, smoke = (smoke &gt; 0),
           ptd, ht = (ht &gt; 0), ui = (ui &gt; 0), ftv)
})
options(contrasts = c("contr.treatment", "contr.poly"))
glm(low ~ ., binomial, bwt)
</code></pre>

<hr>
<h2 id='Boston'>
Housing Values in Suburbs of Boston
</h2><span id='topic+Boston'></span>

<h3>Description</h3>

<p>The <code>Boston</code> data frame has 506 rows and 14 columns.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Boston
</code></pre>


<h3>Format</h3>

<p>This data frame contains the following columns:
</p>

<dl>
<dt><code>crim</code></dt><dd>
<p>per capita crime rate by town.
</p>
</dd>
<dt><code>zn</code></dt><dd>
<p>proportion of residential land zoned for lots over 25,000 sq.ft.
</p>
</dd>
<dt><code>indus</code></dt><dd>
<p>proportion of non-retail business acres per town.
</p>
</dd>
<dt><code>chas</code></dt><dd>
<p>Charles River dummy variable (= 1 if tract bounds river; 0 otherwise).
</p>
</dd>
<dt><code>nox</code></dt><dd>
<p>nitrogen oxides concentration (parts per 10 million).
</p>
</dd>
<dt><code>rm</code></dt><dd>
<p>average number of rooms per dwelling.
</p>
</dd>
<dt><code>age</code></dt><dd>
<p>proportion of owner-occupied units built prior to 1940.
</p>
</dd>
<dt><code>dis</code></dt><dd>
<p>weighted mean of distances to five Boston employment centres.
</p>
</dd>
<dt><code>rad</code></dt><dd>
<p>index of accessibility to radial highways.
</p>
</dd>
<dt><code>tax</code></dt><dd>
<p>full-value property-tax rate per $10,000.
</p>
</dd>
<dt><code>ptratio</code></dt><dd>
<p>pupil-teacher ratio by town.
</p>
</dd>
<dt><code>black</code></dt><dd>
<p><code class="reqn">1000(Bk - 0.63)^2</code> where <code class="reqn">Bk</code> is the proportion of blacks
by town.
</p>
</dd>
<dt><code>lstat</code></dt><dd>
<p>lower status of the population (percent).
</p>
</dd>
<dt><code>medv</code></dt><dd>
<p>median value of owner-occupied homes in $1000s.
</p>
</dd>
</dl>



<h3>Source</h3>

<p>Harrison, D. and Rubinfeld, D.L. (1978)
Hedonic prices and the demand for clean air.
<em>J. Environ. Economics and Management</em>
<b>5</b>, 81&ndash;102.
</p>
<p>Belsley D.A., Kuh, E.  and Welsch, R.E. (1980)
<em>Regression Diagnostics. Identifying Influential Data and Sources
of Collinearity.</em>
New York: Wiley.
</p>

<hr>
<h2 id='boxcox'>
Box-Cox Transformations for Linear Models
</h2><span id='topic+boxcox'></span><span id='topic+boxcox.default'></span><span id='topic+boxcox.formula'></span><span id='topic+boxcox.lm'></span>

<h3>Description</h3>

<p>Computes and optionally plots profile log-likelihoods for the
parameter of the Box-Cox power transformation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>boxcox(object, ...)

## Default S3 method:
boxcox(object, lambda = seq(-2, 2, 1/10), plotit = TRUE,
       interp, eps = 1/50, xlab = expression(lambda),
       ylab = "log-Likelihood", ...)

## S3 method for class 'formula'
boxcox(object, lambda = seq(-2, 2, 1/10), plotit = TRUE,
       interp, eps = 1/50, xlab = expression(lambda),
       ylab = "log-Likelihood", ...)

## S3 method for class 'lm'
boxcox(object, lambda = seq(-2, 2, 1/10), plotit = TRUE,
       interp, eps = 1/50, xlab = expression(lambda),
       ylab = "log-Likelihood", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="boxcox_+3A_object">object</code></td>
<td>
<p>a formula or fitted model object.  Currently only <code>lm</code> and
<code>aov</code> objects are handled.</p>
</td></tr>
<tr><td><code id="boxcox_+3A_lambda">lambda</code></td>
<td>
<p>vector of values of <code>lambda</code>
&ndash; default <code class="reqn">(-2, 2)</code> in steps of 0.1.</p>
</td></tr>
<tr><td><code id="boxcox_+3A_plotit">plotit</code></td>
<td>
<p>logical which controls whether the result should be plotted.</p>
</td></tr>
<tr><td><code id="boxcox_+3A_interp">interp</code></td>
<td>
<p>logical which controls whether spline interpolation is
used. Default to <code>TRUE</code> if plotting with <code>lambda</code> of
length less than 100.</p>
</td></tr>
<tr><td><code id="boxcox_+3A_eps">eps</code></td>
<td>
<p>Tolerance for <code>lambda = 0</code>; defaults to 0.02.</p>
</td></tr>
<tr><td><code id="boxcox_+3A_xlab">xlab</code></td>
<td>
<p>defaults to <code>"lambda"</code>.</p>
</td></tr>
<tr><td><code id="boxcox_+3A_ylab">ylab</code></td>
<td>
<p>defaults to <code>"log-Likelihood"</code>.</p>
</td></tr>
<tr><td><code id="boxcox_+3A_...">...</code></td>
<td>
<p>additional parameters to be used in the model fitting.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of the <code>lambda</code> vector and the computed profile
log-likelihood vector, invisibly if the result is plotted.
</p>


<h3>Side Effects</h3>

<p>If <code>plotit = TRUE</code> plots log-likelihood <em>vs</em> <code>lambda</code> and
indicates a 95% confidence interval about the maximum observed value
of <code>lambda</code>. If <code>interp = TRUE</code>, spline interpolation is
used to give a smoother plot.
</p>


<h3>References</h3>

<p>Box, G. E. P. and Cox, D. R. (1964)
An analysis of transformations (with discussion).
<em>Journal of the Royal Statistical Society B</em>, <b>26</b>, 211&ndash;252.
</p>
<p>Venables, W. N. and Ripley, B. D. (2002)
<em>Modern Applied Statistics with S.</em> Fourth edition.  Springer.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>boxcox(Volume ~ log(Height) + log(Girth), data = trees,
       lambda = seq(-0.25, 0.25, length.out = 10))

boxcox(Days+1 ~ Eth*Sex*Age*Lrn, data = quine,
       lambda = seq(-0.05, 0.45, length.out = 20))
</code></pre>

<hr>
<h2 id='cabbages'>
Data from a cabbage field trial
</h2><span id='topic+cabbages'></span>

<h3>Description</h3>

<p>The <code>cabbages</code> data set has 60 observations and 4 variables
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cabbages
</code></pre>


<h3>Format</h3>

<p>This data frame contains the following columns:
</p>

<dl>
<dt><code>Cult</code></dt><dd>
<p>Factor giving the cultivar of the cabbage, two levels: <code>c39</code>
and <code>c52</code>.
</p>
</dd>
<dt><code>Date</code></dt><dd>
<p>Factor specifying one of three planting dates: <code>d16</code>,
<code>d20</code> or <code>d21</code>.
</p>
</dd>
<dt><code>HeadWt</code></dt><dd>
<p>Weight of the cabbage head, presumably in kg.
</p>
</dd>
<dt><code>VitC</code></dt><dd>
<p>Ascorbic acid content, in undefined units.
</p>
</dd>
</dl>



<h3>Source</h3>

<p>Rawlings, J. O. (1988)
<em>Applied Regression Analysis: A Research Tool.</em>
Wadsworth and Brooks/Cole.  Example 8.4, page 219.
(Rawlings cites the original source as the files of the late
Dr Gertrude M Cox.)
</p>


<h3>References</h3>

<p>Venables, W. N. and Ripley, B. D. (2002)
<em>Modern Applied Statistics with S-PLUS.</em> Fourth Edition. Springer.
</p>

<hr>
<h2 id='caith'>
Colours of Eyes and Hair of People in Caithness
</h2><span id='topic+caith'></span>

<h3>Description</h3>

<p>Data on the cross-classification of people in Caithness, Scotland, by
eye and hair colour. The region of the UK is particularly interesting
as there is a mixture of people of Nordic, Celtic and Anglo-Saxon origin.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>caith
</code></pre>


<h3>Format</h3>

<p>A 4 by 5 table with rows the eye colours (blue, light, medium, dark) and
columns the hair colours (fair, red, medium, dark, black).
</p>


<h3>Source</h3>

<p>Fisher, R.A. (1940) The precision of discriminant functions.
<em>Annals of Eugenics (London)</em> <b>10</b>, 422&ndash;429.
</p>


<h3>References</h3>

<p>Venables, W. N. and Ripley, B. D. (2002)
<em>Modern Applied Statistics with S.</em> Fourth edition.  Springer.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## IGNORE_RDIFF_BEGIN
## The signs can vary by platform
corresp(caith)
## IGNORE_RDIFF_END
dimnames(caith)[[2]] &lt;- c("F", "R", "M", "D", "B")
par(mfcol=c(1,3))
plot(corresp(caith, nf=2)); title("symmetric")
plot(corresp(caith, nf=2), type="rows"); title("rows")
plot(corresp(caith, nf=2), type="col"); title("columns")
par(mfrow=c(1,1))
</code></pre>

<hr>
<h2 id='Cars93'>
Data from 93 Cars on Sale in the USA in 1993
</h2><span id='topic+Cars93'></span>

<h3>Description</h3>

<p>The <code>Cars93</code> data frame has 93 rows and 27 columns.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Cars93
</code></pre>


<h3>Format</h3>

<p>This data frame contains the following columns:
</p>

<dl>
<dt><code>Manufacturer</code></dt><dd>
<p>Manufacturer.
</p>
</dd>
<dt><code>Model</code></dt><dd>
<p>Model.
</p>
</dd>
<dt><code>Type</code></dt><dd>
<p>Type: a factor with levels <code>"Small"</code>, <code>"Sporty"</code>,
<code>"Compact"</code>, <code>"Midsize"</code>, <code>"Large"</code> and <code>"Van"</code>.
</p>
</dd>
<dt><code>Min.Price</code></dt><dd>
<p>Minimum Price (in $1,000): price for a basic version.
</p>
</dd>
<dt><code>Price</code></dt><dd>
<p>Midrange Price (in $1,000): average of <code>Min.Price</code> and
<code>Max.Price</code>.
</p>
</dd>
<dt><code>Max.Price</code></dt><dd>
<p>Maximum Price (in $1,000): price for &ldquo;a premium version&rdquo;.
</p>
</dd>
<dt><code>MPG.city</code></dt><dd>
<p>City MPG (miles per US gallon by EPA rating).
</p>
</dd>
<dt><code>MPG.highway</code></dt><dd>
<p>Highway MPG.
</p>
</dd>
<dt><code>AirBags</code></dt><dd>
<p>Air Bags standard. Factor: none, driver only, or driver &amp; passenger.
</p>
</dd>
<dt><code>DriveTrain</code></dt><dd>
<p>Drive train type: rear wheel, front wheel or 4WD; (factor).
</p>
</dd>
<dt><code>Cylinders</code></dt><dd>
<p>Number of cylinders (missing for Mazda RX-7, which has a rotary engine).
</p>
</dd>
<dt><code>EngineSize</code></dt><dd>
<p>Engine size (litres).
</p>
</dd>
<dt><code>Horsepower</code></dt><dd>
<p>Horsepower (maximum).
</p>
</dd>
<dt><code>RPM</code></dt><dd>
<p>RPM (revs per minute at maximum horsepower).
</p>
</dd>
<dt><code>Rev.per.mile</code></dt><dd>
<p>Engine revolutions per mile (in highest gear).
</p>
</dd>
<dt><code>Man.trans.avail</code></dt><dd>
<p>Is a manual transmission version available? (yes or no, Factor).
</p>
</dd>
<dt><code>Fuel.tank.capacity</code></dt><dd>
<p>Fuel tank capacity (US gallons).
</p>
</dd>
<dt><code>Passengers</code></dt><dd>
<p>Passenger capacity (persons)
</p>
</dd>
<dt><code>Length</code></dt><dd>
<p>Length (inches).
</p>
</dd>
<dt><code>Wheelbase</code></dt><dd>
<p>Wheelbase (inches).
</p>
</dd>
<dt><code>Width</code></dt><dd>
<p>Width (inches).
</p>
</dd>
<dt><code>Turn.circle</code></dt><dd>
<p>U-turn space (feet).
</p>
</dd>
<dt><code>Rear.seat.room</code></dt><dd>
<p>Rear seat room (inches) (missing for 2-seater vehicles).
</p>
</dd>
<dt><code>Luggage.room</code></dt><dd>
<p>Luggage capacity (cubic feet) (missing for vans).
</p>
</dd>
<dt><code>Weight</code></dt><dd>
<p>Weight (pounds).
</p>
</dd>
<dt><code>Origin</code></dt><dd>
<p>Of non-USA or USA company origins? (factor).
</p>
</dd>
<dt><code>Make</code></dt><dd>
<p>Combination of Manufacturer and Model (character).
</p>
</dd>
</dl>



<h3>Details</h3>

<p>Cars were selected at random from among 1993 passenger car models that
were listed in both the <em>Consumer Reports</em> issue and the
<em>PACE Buying Guide</em>.  Pickup trucks and Sport/Utility vehicles were
eliminated due to incomplete information in the <em>Consumer Reports</em>
source.  Duplicate models (e.g., Dodge Shadow and Plymouth Sundance)
were listed at most once.
</p>
<p>Further description can be found in Lock (1993).
</p>


<h3>Source</h3>

<p>Lock, R. H. (1993)
1993 New Car Data.
<em>Journal of Statistics Education</em>
<b>1</b>(1).
<a href="https://doi.org/10.1080/10691898.1993.11910459">doi:10.1080/10691898.1993.11910459</a>

</p>


<h3>References</h3>

<p>Venables, W. N. and Ripley, B. D. (2002)
<em>Modern Applied Statistics with S-PLUS.</em> Fourth Edition. Springer.
</p>

<hr>
<h2 id='cats'>
Anatomical Data from Domestic Cats
</h2><span id='topic+cats'></span>

<h3>Description</h3>

<p>The heart and body weights of samples of male and female cats used for
<em>digitalis</em> experiments.  The cats were all adult, over 2 kg body weight.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cats
</code></pre>


<h3>Format</h3>

<p>This data frame contains the following columns:
</p>

<dl>
<dt><code>Sex</code></dt><dd>
<p>sex: Factor with levels <code>"F"</code> and <code>"M"</code>.
</p>
</dd>
<dt><code>Bwt</code></dt><dd>
<p>body weight in kg.
</p>
</dd>
<dt><code>Hwt</code></dt><dd>
<p>heart weight in g.
</p>
</dd>
</dl>



<h3>Source</h3>

<p>R. A. Fisher (1947) The analysis of covariance method for the relation
between a part and the whole, <em>Biometrics</em> <b>3</b>, 65&ndash;68.
</p>


<h3>References</h3>

<p>Venables, W. N. and Ripley, B. D. (2002)
<em>Modern Applied Statistics with S.</em> Fourth edition.  Springer.
</p>

<hr>
<h2 id='cement'>
Heat Evolved by Setting Cements
</h2><span id='topic+cement'></span>

<h3>Description</h3>

<p>Experiment on the heat evolved in the setting of each of 13 cements.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cement
</code></pre>


<h3>Format</h3>


<dl>
<dt><code>x1, x2, x3, x4</code></dt><dd>
<p>Proportions (%) of active ingredients.
</p>
</dd>
<dt><code>y</code></dt><dd>
<p>heat evolved in cals/gm.
</p>
</dd>
</dl>



<h3>Details</h3>

<p>Thirteen samples of Portland cement were set. For each sample, the
percentages of the four main chemical ingredients was accurately
measured.  While the cement was setting the amount of heat evolved was
also measured.
</p>


<h3>Source</h3>

<p>Woods, H., Steinour, H.H. and Starke, H.R. (1932) Effect of composition of 
Portland cement on heat evolved during hardening. 
<em>Industrial Engineering and Chemistry</em>, <b>24</b>, 1207&ndash;1214.
</p>


<h3>References</h3>

<p>Hald, A. (1957) <em>Statistical Theory with Engineering
Applications.</em> Wiley, New York.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>lm(y ~ x1 + x2 + x3 + x4, cement)
</code></pre>

<hr>
<h2 id='chem'>
Copper in Wholemeal Flour
</h2><span id='topic+chem'></span>

<h3>Description</h3>

<p>A numeric vector of 24 determinations of copper in wholemeal
flour, in parts per million.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>chem
</code></pre>


<h3>Source</h3>

<p>Analytical Methods Committee (1989) Robust statistics &ndash; how not to
reject outliers. <em>The Analyst</em> <b>114</b>, 1693&ndash;1702.
</p>


<h3>References</h3>

<p>Venables, W. N. and Ripley, B. D. (2002)
<em>Modern Applied Statistics with S.</em> Fourth edition.  Springer.
</p>

<hr>
<h2 id='con2tr'>
Convert Lists to Data Frames for use by lattice
</h2><span id='topic+con2tr'></span>

<h3>Description</h3>

<p>Convert lists to data frames for use by lattice.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>con2tr(obj)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="con2tr_+3A_obj">obj</code></td>
<td>

<p>A list of components <code>x</code>, <code>y</code> and <code>z</code> as passed to
<code>contour</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>con2tr</code> repeats the <code>x</code> and <code>y</code> components suitably to
match the vector <code>z</code>.
</p>


<h3>Value</h3>

<p>A data frame suitable for passing to lattice (formerly trellis) functions.
</p>


<h3>References</h3>

<p>Venables, W. N. and Ripley, B. D. (2002)
<em>Modern Applied Statistics with S.</em> Fourth edition.  Springer.
</p>

<hr>
<h2 id='confint-MASS'>
Confidence Intervals for Model Parameters
</h2><span id='topic+confint.glm'></span><span id='topic+confint.nls'></span><span id='topic+confint.profile.glm'></span><span id='topic+confint.profile.nls'></span>

<h3>Description</h3>

<p>Computes confidence intervals for one or more parameters in a fitted
model.  Package <span class="pkg">MASS</span> added methods for <code>glm</code> and <code>nls</code>
fits.  As fron <span class="rlang"><b>R</b></span> 4.4.0 these have been migrated to package
<span class="pkg">stats</span>.
</p>
<p>It also adds a method for <code><a href="#topic+polr">polr</a></code> fits.
</p>

<hr>
<h2 id='contr.sdif'>
Successive Differences Contrast Coding
</h2><span id='topic+contr.sdif'></span>

<h3>Description</h3>

<p>A coding for factors based on successive differences.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>contr.sdif(n, contrasts = TRUE, sparse = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="contr.sdif_+3A_n">n</code></td>
<td>

<p>The number of levels required.
</p>
</td></tr>
<tr><td><code id="contr.sdif_+3A_contrasts">contrasts</code></td>
<td>

<p>logical: Should there be <code>n - 1</code> columns orthogonal to the mean
(the default) or <code>n</code> columns spanning the space?
</p>
</td></tr>
<tr><td><code id="contr.sdif_+3A_sparse">sparse</code></td>
<td>

<p>logical.  If true and the result would be sparse (only
true for <code>contrasts = FALSE</code>), return a sparse matrix.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The contrast coefficients are chosen so that the coded coefficients
in a one-way layout are the differences between the means of the
second and first levels, the third and second levels, and so on.  This
makes most sense for ordered factors, but does not assume that the
levels are equally spaced.
</p>


<h3>Value</h3>

<p>If <code>contrasts</code> is <code>TRUE</code>, a matrix with <code>n</code> rows and
<code>n - 1</code> columns, and the <code>n</code> by <code>n</code> identity matrix if
<code>contrasts</code> is <code>FALSE</code>.
</p>


<h3>References</h3>

<p>Venables, W. N. and Ripley, B. D. (2002)
<em>Modern Applied Statistics with S.</em>
Fourth Edition, Springer.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+contr.treatment">contr.treatment</a></code>, <code><a href="stats.html#topic+contr.sum">contr.sum</a></code>,
<code><a href="stats.html#topic+contr.helmert">contr.helmert</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>(A &lt;- contr.sdif(6))
zapsmall(ginv(A))
</code></pre>

<hr>
<h2 id='coop'>
Co-operative Trial in Analytical Chemistry
</h2><span id='topic+coop'></span>

<h3>Description</h3>

<p>Seven specimens were sent to 6 laboratories in 3 separate batches and
each analysed for Analyte.  Each analysis was duplicated.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>coop
</code></pre>


<h3>Format</h3>

<p>This data frame contains the following columns:
</p>

<dl>
<dt><code>Lab</code></dt><dd>
<p>Laboratory, <code>L1</code>, <code>L2</code>, ..., <code>L6</code>.
</p>
</dd>
<dt><code>Spc</code></dt><dd>
<p>Specimen, <code>S1</code>, <code>S2</code>, ..., <code>S7</code>.
</p>
</dd>
<dt><code>Bat</code></dt><dd>
<p>Batch, <code>B1</code>, <code>B2</code>, <code>B3</code> (nested within <code>Spc/Lab</code>),
</p>
</dd>
<dt><code>Conc</code></dt><dd>
<p>Concentration of Analyte in <code class="reqn">g/kg</code>.
</p>
</dd>
</dl>



<h3>Source</h3>

<p>Analytical Methods Committee (1987)
Recommendations for the conduct and
interpretation of co-operative trials,
<em>The Analyst</em> <b>112</b>, 679&ndash;686.
</p>


<h3>References</h3>

<p>Venables, W. N. and Ripley, B. D. (2002)
<em>Modern Applied Statistics with S.</em> Fourth edition.  Springer.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+chem">chem</a></code>, <code><a href="#topic+abbey">abbey</a></code>.
</p>

<hr>
<h2 id='corresp'>
Simple Correspondence Analysis
</h2><span id='topic+corresp'></span><span id='topic+corresp.xtabs'></span><span id='topic+corresp.data.frame'></span><span id='topic+corresp.default'></span><span id='topic+corresp.factor'></span><span id='topic+corresp.formula'></span><span id='topic+corresp.matrix'></span>

<h3>Description</h3>

<p>Find the principal canonical correlation and corresponding row- and
column-scores from a correspondence analysis of a two-way contingency
table.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>corresp(x, ...)

## S3 method for class 'matrix'
corresp(x, nf = 1, ...)

## S3 method for class 'factor'
corresp(x, y, ...)

## S3 method for class 'data.frame'
corresp(x, ...)

## S3 method for class 'xtabs'
corresp(x, ...)

## S3 method for class 'formula'
corresp(formula, data, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="corresp_+3A_x">x</code>, <code id="corresp_+3A_formula">formula</code></td>
<td>

<p>The function is generic, accepting various forms of the principal
argument for specifying a two-way frequency table.  Currently accepted
forms are matrices, data frames (coerced to frequency tables), objects
of class <code>"<a href="stats.html#topic+xtabs">xtabs</a>"</code> and formulae of the form <code>~ F1 + F2</code>,
where <code>F1</code> and <code>F2</code> are factors.
</p>
</td></tr>
<tr><td><code id="corresp_+3A_nf">nf</code></td>
<td>

<p>The number of factors to be computed. Note that although 1 is the most
usual, one school of thought takes the first two singular vectors for
a sort of biplot.
</p>
</td></tr>
<tr><td><code id="corresp_+3A_y">y</code></td>
<td>
<p>a second factor for a cross-classification.</p>
</td></tr>
<tr><td><code id="corresp_+3A_data">data</code></td>
<td>
<p>an optional data frame, list or environment against which
to preferentially resolve variables in the formula.</p>
</td></tr>
<tr><td><code id="corresp_+3A_...">...</code></td>
<td>

<p>If the principal argument is a formula, a data frame may be specified
as well from which variables in the formula are preferentially
satisfied.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See Venables &amp; Ripley (2002).  The <code>plot</code> method produces a graphical
representation of the table if <code>nf=1</code>, with the <em>areas</em> of circles
representing the numbers of points.  If <code>nf</code> is two or more the
<code>biplot</code> method is called, which plots the second and third columns of
the matrices <code>A = Dr^(-1/2) U L</code> and <code>B = Dc^(-1/2) V L</code> where the
singular value decomposition is <code>U L V</code>.  Thus the x-axis is the
canonical correlation times the row and column scores.  Although this
is called a biplot, it does <em>not</em> have any useful inner product
relationship between the row and column scores.  Think of this as an
equally-scaled plot with two unrelated sets of labels.  The origin is
marked on the plot with a cross.  (For other versions of this plot see
the book.)
</p>


<h3>Value</h3>

<p>An list object of class <code>"correspondence"</code> for which
<code>print</code>, <code>plot</code> and <code>biplot</code> methods are supplied.
The main components are the canonical correlation(s) and the row
and column scores.
</p>


<h3>References</h3>

<p>Venables, W. N. and Ripley, B. D. (2002)
<em>Modern Applied Statistics with S.</em> Fourth edition.  Springer.
</p>
<p>Gower, J. C. and Hand, D. J. (1996)
<em>Biplots.</em>  Chapman &amp; Hall.
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+svd">svd</a></code>, <code><a href="stats.html#topic+princomp">princomp</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## IGNORE_RDIFF_BEGIN
## The signs can vary by platform
(ct &lt;- corresp(~ Age + Eth, data = quine))
plot(ct)

corresp(caith)
biplot(corresp(caith, nf = 2))
## IGNORE_RDIFF_END
</code></pre>

<hr>
<h2 id='cov.rob'>
Resistant Estimation of Multivariate Location and Scatter
</h2><span id='topic+cov.rob'></span><span id='topic+cov.mve'></span><span id='topic+cov.mcd'></span>

<h3>Description</h3>

<p>Compute a multivariate location and scale estimate with a high
breakdown point &ndash; this can be thought of as estimating the mean and
covariance of the <code>good</code> part of the data. <code>cov.mve</code> and
<code>cov.mcd</code> are compatibility wrappers.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cov.rob(x, cor = FALSE, quantile.used = floor((n + p + 1)/2),
        method = c("mve", "mcd", "classical"),
        nsamp = "best", seed)

cov.mve(...)
cov.mcd(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cov.rob_+3A_x">x</code></td>
<td>

<p>a matrix or data frame.
</p>
</td></tr>
<tr><td><code id="cov.rob_+3A_cor">cor</code></td>
<td>

<p>should the returned result include a correlation matrix?
</p>
</td></tr>
<tr><td><code id="cov.rob_+3A_quantile.used">quantile.used</code></td>
<td>

<p>the minimum number of the data points regarded as <code>good</code> points.
</p>
</td></tr>
<tr><td><code id="cov.rob_+3A_method">method</code></td>
<td>

<p>the method to be used &ndash; minimum volume ellipsoid, minimum
covariance determinant or classical product-moment. Using
<code>cov.mve</code> or <code>cov.mcd</code> forces <code>mve</code> or <code>mcd</code>
respectively.
</p>
</td></tr>
<tr><td><code id="cov.rob_+3A_nsamp">nsamp</code></td>
<td>

<p>the number of samples or <code>"best"</code> or <code>"exact"</code> or
<code>"sample"</code>.  The limit
If <code>"sample"</code> the number chosen is <code>min(5*p, 3000)</code>, taken
from Rousseeuw and Hubert (1997). If <code>"best"</code> exhaustive
enumeration is done up to 5000 samples: if <code>"exact"</code>
exhaustive enumeration will be attempted.
</p>
</td></tr>
<tr><td><code id="cov.rob_+3A_seed">seed</code></td>
<td>

<p>the seed to be used for random sampling: see <code><a href="base.html#topic+RNGkind">RNGkind</a></code>. The
current value of <code>.Random.seed</code> will be preserved if it is set.
</p>
</td></tr>
<tr><td><code id="cov.rob_+3A_...">...</code></td>
<td>
<p>arguments to <code>cov.rob</code> other than <code>method</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For method <code>"mve"</code>, an approximate search is made of a subset of
size <code>quantile.used</code> with an enclosing ellipsoid of smallest volume; in
method <code>"mcd"</code> it is the volume of the Gaussian confidence
ellipsoid, equivalently the determinant of the classical covariance
matrix, that is minimized. The mean of the subset provides a first
estimate of the location, and the rescaled covariance matrix a first
estimate of scatter. The Mahalanobis distances of all the points from
the location estimate for this covariance matrix are calculated, and
those points within the 97.5% point under Gaussian assumptions are
declared to be <code>good</code>. The final estimates are the mean and rescaled
covariance of the <code>good</code> points.
</p>
<p>The rescaling is by the appropriate percentile under Gaussian data; in
addition the first covariance matrix has an <em>ad hoc</em> finite-sample
correction given by Marazzi.
</p>
<p>For method <code>"mve"</code> the search is made over ellipsoids determined
by the covariance matrix of <code>p</code> of the data points. For method
<code>"mcd"</code> an additional improvement step suggested by Rousseeuw and
van Driessen (1999) is used, in which once a subset of size
<code>quantile.used</code> is selected, an ellipsoid based on its covariance
is tested (as this will have no larger a determinant, and may be smaller).
</p>
<p>There is a hard limit on the allowed number of samples, <code class="reqn">2^{31} -
  1</code>.  However, practical limits are likely to be much lower
and one might check the number of samples used for exhaustive
enumeration, <code>combn(NROW(x), NCOL(x) + 1)</code>, before attempting it.
</p>


<h3>Value</h3>

<p>A list with components
</p>
<table>
<tr><td><code>center</code></td>
<td>

<p>the final estimate of location.
</p>
</td></tr>
<tr><td><code>cov</code></td>
<td>

<p>the final estimate of scatter.
</p>
</td></tr>
<tr><td><code>cor</code></td>
<td>

<p>(only is <code>cor = TRUE</code>) the estimate of the correlation
matrix.
</p>
</td></tr>
<tr><td><code>sing</code></td>
<td>

<p>message giving number of singular samples out of total
</p>
</td></tr>
<tr><td><code>crit</code></td>
<td>

<p>the value of the criterion on log scale. For MCD this is
the determinant, and for MVE it is proportional to the volume.
</p>
</td></tr>
<tr><td><code>best</code></td>
<td>

<p>the subset used. For MVE the best sample, for MCD the best
set of size <code>quantile.used</code>.
</p>
</td></tr>
<tr><td><code>n.obs</code></td>
<td>

<p>total number of observations.
</p>
</td></tr></table>


<h3>References</h3>

<p>P. J. Rousseeuw and A. M. Leroy (1987) 
<em>Robust Regression and Outlier Detection.</em>
Wiley.
</p>
<p>A. Marazzi (1993) 
<em>Algorithms, Routines and S Functions for Robust Statistics.</em>
Wadsworth and Brooks/Cole. 
</p>
<p>P. J. Rousseeuw and B. C. van Zomeren (1990) Unmasking
multivariate outliers and leverage points, 
<em>Journal of the American Statistical Association</em>, <b>85</b>, 633&ndash;639.
</p>
<p>P. J. Rousseeuw and K. van Driessen (1999) A fast algorithm for the
minimum covariance determinant estimator. <em>Technometrics</em>
<b>41</b>, 212&ndash;223.
</p>
<p>P. Rousseeuw and M. Hubert (1997) Recent developments in PROGRESS. In
<em>L1-Statistical Procedures and Related Topics </em>
ed Y. Dodge, IMS Lecture Notes volume <b>31</b>, pp. 201&ndash;214.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lqs">lqs</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(123)
cov.rob(stackloss)
cov.rob(stack.x, method = "mcd", nsamp = "exact")
</code></pre>

<hr>
<h2 id='cov.trob'>
Covariance Estimation for Multivariate t Distribution
</h2><span id='topic+cov.trob'></span>

<h3>Description</h3>

<p>Estimates a covariance or correlation matrix assuming the data came
from a multivariate t distribution: this provides some degree of
robustness to outlier without giving a high breakdown point.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cov.trob(x, wt = rep(1, n), cor = FALSE, center = TRUE, nu = 5,
         maxit = 25, tol = 0.01)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cov.trob_+3A_x">x</code></td>
<td>

<p>data  matrix. Missing values (NAs) are not allowed.
</p>
</td></tr>
<tr><td><code id="cov.trob_+3A_wt">wt</code></td>
<td>

<p>A vector of weights for each case: these are treated as if the case <code>i</code>
actually occurred <code>wt[i]</code> times.
</p>
</td></tr>
<tr><td><code id="cov.trob_+3A_cor">cor</code></td>
<td>

<p>Flag to choose between returning the correlation (<code>cor = TRUE</code>) or
covariance (<code>cor = FALSE</code>) matrix.
</p>
</td></tr>
<tr><td><code id="cov.trob_+3A_center">center</code></td>
<td>

<p>a logical value or a numeric vector providing the location about which
the covariance is to be taken. If <code>center = FALSE</code>, no centering
is done; if <code>center = TRUE</code> the MLE of the location vector is used.
</p>
</td></tr>
<tr><td><code id="cov.trob_+3A_nu">nu</code></td>
<td>

<p>&lsquo;degrees of freedom&rsquo; for the multivariate t distribution. Must exceed
2 (so that the covariance matrix is finite).
</p>
</td></tr>
<tr><td><code id="cov.trob_+3A_maxit">maxit</code></td>
<td>

<p>Maximum number of iterations in fitting.
</p>
</td></tr>
<tr><td><code id="cov.trob_+3A_tol">tol</code></td>
<td>

<p>Convergence tolerance for fitting.
</p>
</td></tr></table>


<h3>Value</h3>

<p>A list with the following components
</p>
<table>
<tr><td><code>cov</code></td>
<td>

<p>the fitted covariance matrix.
</p>
</td></tr>
<tr><td><code>center</code></td>
<td>

<p>the estimated or specified location vector.
</p>
</td></tr>
<tr><td><code>wt</code></td>
<td>

<p>the specified weights: only returned if the <code>wt</code> argument was given.
</p>
</td></tr>
<tr><td><code>n.obs</code></td>
<td>

<p>the number of cases used in the fitting.
</p>
</td></tr>
<tr><td><code>cor</code></td>
<td>

<p>the fitted correlation matrix: only returned if <code>cor = TRUE</code>.
</p>
</td></tr>
<tr><td><code>call</code></td>
<td>

<p>The matched call.
</p>
</td></tr>
<tr><td><code>iter</code></td>
<td>

<p>The number of iterations used.
</p>
</td></tr></table>


<h3>References</h3>

<p>J. T. Kent, D. E. Tyler and Y. Vardi (1994)
A curious likelihood identity for the multivariate t-distribution.
<em>Communications in Statistics&mdash;Simulation and Computation</em>
<b>23</b>, 441&ndash;453.
</p>
<p>Venables, W. N. and Ripley, B. D. (2002)
<em>Modern Applied Statistics with S-PLUS.</em> Fourth Edition. Springer.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+cov">cov</a></code>, <code><a href="stats.html#topic+cov.wt">cov.wt</a></code>, <code><a href="#topic+cov.mve">cov.mve</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>cov.trob(stackloss)
</code></pre>

<hr>
<h2 id='cpus'>
Performance of Computer CPUs
</h2><span id='topic+cpus'></span>

<h3>Description</h3>

<p>A relative performance measure and characteristics of 209 CPUs.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cpus
</code></pre>


<h3>Format</h3>

<p>The components are:
</p>

<dl>
<dt><code>name</code></dt><dd>
<p>manufacturer and model.
</p>
</dd>
<dt><code>syct</code></dt><dd>
<p>cycle time in nanoseconds.
</p>
</dd>
<dt><code>mmin</code></dt><dd>
<p>minimum main memory in kilobytes.
</p>
</dd>
<dt><code>mmax</code></dt><dd>
<p>maximum main memory in kilobytes.
</p>
</dd>
<dt><code>cach</code></dt><dd>
<p>cache size in kilobytes.
</p>
</dd>
<dt><code>chmin</code></dt><dd>
<p>minimum number of channels.
</p>
</dd>
<dt><code>chmax</code></dt><dd>
<p>maximum number of channels.
</p>
</dd>
<dt><code>perf</code></dt><dd>
<p>published performance on a benchmark mix relative to an IBM 370/158-3.
</p>
</dd>
<dt><code>estperf</code></dt><dd>
<p>estimated performance (by Ein-Dor &amp; Feldmesser).
</p>
</dd>
</dl>



<h3>Source</h3>

<p>P. Ein-Dor and J. Feldmesser (1987)
Attributes of the performance of central processing units: a relative
performance prediction model.
<em>Comm. ACM.</em> <b>30</b>, 308&ndash;317.
</p>


<h3>References</h3>

<p>Venables, W. N. and Ripley, B. D. (2002)
<em>Modern Applied Statistics with S.</em> Fourth edition.  Springer.
</p>

<hr>
<h2 id='crabs'>
Morphological Measurements on Leptograpsus Crabs
</h2><span id='topic+crabs'></span>

<h3>Description</h3>

<p>The <code>crabs</code> data frame has 200 rows and 8 columns, describing 5
morphological measurements on 50 crabs each of two colour forms and
both sexes, of the species <em>Leptograpsus variegatus</em> collected at
Fremantle, W. Australia.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>crabs
</code></pre>


<h3>Format</h3>

<p>This data frame contains the following columns:
</p>

<dl>
<dt><code>sp</code></dt><dd>
<p><code>species</code> - <code>"B"</code> or <code>"O"</code> for blue or orange.
</p>
</dd>
<dt><code>sex</code></dt><dd>
<p>as it says.
</p>
</dd>
<dt><code>index</code></dt><dd>
<p>index <code>1:50</code> within each of the four groups.
</p>
</dd>
<dt><code>FL</code></dt><dd>
<p>frontal lobe size (mm).
</p>
</dd>
<dt><code>RW</code></dt><dd>
<p>rear width (mm).
</p>
</dd>
<dt><code>CL</code></dt><dd>
<p>carapace length (mm).
</p>
</dd>
<dt><code>CW</code></dt><dd>
<p>carapace width (mm).
</p>
</dd>
<dt><code>BD</code></dt><dd>
<p>body depth (mm).
</p>
</dd>
</dl>



<h3>Source</h3>

<p>Campbell, N.A. and Mahon, R.J. (1974) A multivariate
study of variation in two species of rock crab of genus
<em>Leptograpsus.</em>
<em>Australian Journal of  Zoology</em> <b>22</b>, 417&ndash;425.
</p>


<h3>References</h3>

<p>Venables, W. N. and Ripley, B. D. (2002)
<em>Modern Applied Statistics with S.</em> Fourth edition.  Springer.
</p>

<hr>
<h2 id='Cushings'>
Diagnostic Tests on Patients with Cushing's Syndrome
</h2><span id='topic+Cushings'></span>

<h3>Description</h3>

<p>Cushing's syndrome is a hypertensive disorder associated with
over-secretion of cortisol by the adrenal gland. The observations
are urinary excretion rates of two steroid metabolites.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Cushings
</code></pre>


<h3>Format</h3>

<p>The <code>Cushings</code> data frame has 27 rows and 3 columns:
</p>

<dl>
<dt><code>Tetrahydrocortisone</code></dt><dd>
<p>urinary excretion rate (mg/24hr) of Tetrahydrocortisone.
</p>
</dd>
<dt><code>Pregnanetriol</code></dt><dd>
<p>urinary excretion rate (mg/24hr) of Pregnanetriol.
</p>
</dd>
<dt><code>Type</code></dt><dd>
<p>underlying type of syndrome, coded <code>a</code> (adenoma) , <code>b</code>
(bilateral hyperplasia), <code>c</code> (carcinoma) or <code>u</code> for unknown.
</p>
</dd>
</dl>



<h3>Source</h3>

<p>J. Aitchison and I. R. Dunsmore (1975)
<em>Statistical Prediction Analysis.</em>
Cambridge University Press, Tables 11.1&ndash;3.
</p>


<h3>References</h3>

<p>Venables, W. N. and Ripley, B. D. (2002)
<em>Modern Applied Statistics with S.</em> Fourth edition.  Springer.
</p>

<hr>
<h2 id='DDT'>
DDT in Kale
</h2><span id='topic+DDT'></span>

<h3>Description</h3>

<p>A numeric vector of 15 measurements by different laboratories of the
pesticide DDT in kale, in ppm (parts per million) using the multiple
pesticide residue measurement.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DDT
</code></pre>


<h3>Source</h3>

<p>C. E. Finsterwalder (1976)
Collaborative study of an extension of the Mills <em>et al</em>
method for the determination of pesticide residues in food.
<em>J. Off. Anal. Chem.</em> <b>59</b>, 169&ndash;171
</p>
<p>R. G. Staudte and S. J. Sheather (1990)
<em>Robust Estimation and Testing.</em>
Wiley
</p>

<hr>
<h2 id='deaths'>
Monthly Deaths from Lung Diseases in the UK
</h2><span id='topic+deaths'></span>

<h3>Description</h3>

<p>A time series giving the monthly deaths from bronchitis,
emphysema and asthma in the UK, 1974-1979, both sexes (<code>deaths</code>),
</p>


<h3>Usage</h3>

<pre><code class='language-R'>deaths
</code></pre>


<h3>Source</h3>

<p>P. J. Diggle (1990)
<em>Time Series: A Biostatistical Introduction.</em>
Oxford, table A.3
</p>


<h3>References</h3>

<p>Venables, W. N. and Ripley, B. D. (2002)
<em>Modern Applied Statistics with S.</em> Fourth edition.  Springer.
</p>


<h3>See Also</h3>

<p>This the same as dataset <code><a href="datasets.html#topic+ldeaths">ldeaths</a></code> in <span class="rlang"><b>R</b></span>'s <span class="pkg">datasets</span> package.
</p>

<hr>
<h2 id='denumerate'>
Transform an Allowable Formula for 'loglm' into one for 'terms'
</h2><span id='topic+denumerate'></span><span id='topic+denumerate.formula'></span>

<h3>Description</h3>

<p><code><a href="#topic+loglm">loglm</a></code> allows dimension numbers to be used in place of names in
the formula.  <code>denumerate</code> modifies such a formula into one that
<code><a href="stats.html#topic+terms">terms</a></code> can process.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>denumerate(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="denumerate_+3A_x">x</code></td>
<td>

<p>A formula conforming to the conventions of <code><a href="#topic+loglm">loglm</a></code>, that is, it
may allow dimension numbers to stand in for names when specifying
a log-linear model.
</p>
</td></tr></table>


<h3>Details</h3>

<p>The model fitting function <code><a href="#topic+loglm">loglm</a></code> fits log-linear models to
frequency data using iterative proportional scaling.  To specify
the model the user must nominate the margins in the data that
remain fixed under the log-linear model.  It is convenient to
allow the user to use dimension numbers, 1, 2, 3, ... for the
first, second, third, ..., margins in a similar way to variable
names.  As the model formula has to be parsed by <code><a href="stats.html#topic+terms">terms</a></code>, which
treats <code>1</code> in a special way and requires parseable variable names,
these formulae have to be modified by giving genuine names for
these margin, or dimension numbers.  <code>denumerate</code> replaces these
numbers with names of a special form, namely <code>n</code> is replaced by
<code>.vn</code>.  This allows <code>terms</code> to parse the formula in the usual way.
</p>


<h3>Value</h3>

<p>A linear model formula like that presented, except that where
dimension numbers, say <code>n</code>, have been used to specify fixed
margins these are replaced by names of the form <code>.vn</code> which may
be processed by <code>terms</code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+renumerate">renumerate</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>denumerate(~(1+2+3)^3 + a/b)
## which gives ~ (.v1 + .v2 + .v3)^3 + a/b
</code></pre>

<hr>
<h2 id='dose.p'>
Predict Doses for Binomial Assay model
</h2><span id='topic+dose.p'></span><span id='topic+print.glm.dose'></span>

<h3>Description</h3>

<p>Calibrate binomial assays, generalizing the calculation of LD50.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dose.p(obj, cf = 1:2, p = 0.5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dose.p_+3A_obj">obj</code></td>
<td>

<p>A fitted model object of class inheriting from <code>"glm"</code>.
</p>
</td></tr>
<tr><td><code id="dose.p_+3A_cf">cf</code></td>
<td>

<p>The terms in the coefficient vector giving the intercept and
coefficient of (log-)dose
</p>
</td></tr>
<tr><td><code id="dose.p_+3A_p">p</code></td>
<td>

<p>Probabilities at which to predict the dose needed.
</p>
</td></tr></table>


<h3>Value</h3>

<p>An object of class <code>"glm.dose"</code> giving the prediction (attribute
<code>"p"</code> and standard error (attribute <code>"SE"</code>) at each response
probability.
</p>


<h3>References</h3>

<p>Venables, W. N. and Ripley, B. D. (2002)
<em>Modern Applied Statistics with S.</em>
Springer.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>ldose &lt;- rep(0:5, 2)
numdead &lt;- c(1, 4, 9, 13, 18, 20, 0, 2, 6, 10, 12, 16)
sex &lt;- factor(rep(c("M", "F"), c(6, 6)))
SF &lt;- cbind(numdead, numalive = 20 - numdead)
budworm.lg0 &lt;- glm(SF ~ sex + ldose - 1, family = binomial)

dose.p(budworm.lg0, cf = c(1,3), p = 1:3/4)
dose.p(update(budworm.lg0, family = binomial(link=probit)),
       cf = c(1,3), p = 1:3/4)
</code></pre>

<hr>
<h2 id='drivers'>
Deaths of Car Drivers in Great Britain 1969-84
</h2><span id='topic+drivers'></span>

<h3>Description</h3>

<p>A regular time series giving the monthly totals of car drivers in
Great Britain killed or seriously injured Jan 1969 to Dec
1984.  Compulsory wearing of seat belts was introduced on 31 Jan 1983
</p>


<h3>Usage</h3>

<pre><code class='language-R'>drivers
</code></pre>


<h3>Source</h3>

<p>Harvey, A.C. (1989)
<em>Forecasting, Structural Time Series Models and the Kalman Filter.</em>
Cambridge University Press, pp. 519&ndash;523.
</p>


<h3>References</h3>

<p>Venables, W. N. and Ripley, B. D. (2002)
<em>Modern Applied Statistics with S-PLUS.</em> Fourth Edition. Springer.
</p>

<hr>
<h2 id='dropterm'>
Try All One-Term Deletions from a Model
</h2><span id='topic+dropterm'></span><span id='topic+dropterm.default'></span><span id='topic+dropterm.glm'></span><span id='topic+dropterm.lm'></span>

<h3>Description</h3>

<p>Try fitting all models that differ from the current model by dropping a
single term, maintaining marginality.
</p>
<p>This function is generic; there exist methods for classes <code>lm</code> and
<code>glm</code> and the default method will work for many other classes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dropterm (object, ...)

## Default S3 method:
dropterm(object, scope, scale = 0, test = c("none", "Chisq"),
         k = 2, sorted = FALSE, trace = FALSE, ...)

## S3 method for class 'lm'
dropterm(object, scope, scale = 0, test = c("none", "Chisq", "F"),
         k = 2, sorted = FALSE, ...)

## S3 method for class 'glm'
dropterm(object, scope, scale = 0, test = c("none", "Chisq", "F"),
         k = 2, sorted = FALSE, trace = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dropterm_+3A_object">object</code></td>
<td>

<p>A object fitted by some model-fitting function.
</p>
</td></tr>
<tr><td><code id="dropterm_+3A_scope">scope</code></td>
<td>

<p>a formula giving terms which might be dropped. By default, the
model formula. Only terms that can be dropped and maintain marginality
are actually tried.
</p>
</td></tr>
<tr><td><code id="dropterm_+3A_scale">scale</code></td>
<td>

<p>used in the definition of the AIC statistic for selecting the models,
currently only for <code>lm</code>, <code>aov</code> and <code>glm</code> models. Specifying <code>scale</code>
asserts that the residual standard error or dispersion is known.
</p>
</td></tr>
<tr><td><code id="dropterm_+3A_test">test</code></td>
<td>

<p>should the results include a test statistic relative to the original
model?  The F test is only appropriate for <code>lm</code> and <code>aov</code> models,
and perhaps for some over-dispersed <code>glm</code> models. The
Chisq test can be an exact test (<code>lm</code> models with known scale) or a
likelihood-ratio test depending on the method.
</p>
</td></tr>
<tr><td><code id="dropterm_+3A_k">k</code></td>
<td>

<p>the multiple of the number of degrees of freedom used for the penalty.
Only <code>k = 2</code> gives the genuine AIC: <code>k = log(n)</code> is sometimes
referred to as BIC or SBC.
</p>
</td></tr>
<tr><td><code id="dropterm_+3A_sorted">sorted</code></td>
<td>

<p>should the results be sorted on the value of AIC?
</p>
</td></tr>
<tr><td><code id="dropterm_+3A_trace">trace</code></td>
<td>

<p>if <code>TRUE</code> additional information may be given on the fits as they are tried.
</p>
</td></tr>
<tr><td><code id="dropterm_+3A_...">...</code></td>
<td>

<p>arguments passed to or from other methods.
</p>
</td></tr></table>


<h3>Details</h3>

<p>The definition of AIC is only up to an additive constant: when
appropriate (<code>lm</code> models with specified scale) the constant is taken
to be that used in Mallows' Cp statistic and the results are labelled
accordingly.
</p>


<h3>Value</h3>

<p>A table of class <code>"anova"</code> containing at least columns for the change
in degrees of freedom and AIC (or Cp) for the models. Some methods
will give further information, for example sums of squares, deviances,
log-likelihoods and test statistics.
</p>


<h3>References</h3>

<p>Venables, W. N. and Ripley, B. D. (2002)
<em>Modern Applied Statistics with S.</em> Fourth edition.  Springer.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+addterm">addterm</a></code>, <code><a href="#topic+stepAIC">stepAIC</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>quine.hi &lt;- aov(log(Days + 2.5) ~ .^4, quine)
quine.nxt &lt;- update(quine.hi, . ~ . - Eth:Sex:Age:Lrn)
dropterm(quine.nxt, test=  "F")
quine.stp &lt;- stepAIC(quine.nxt,
    scope = list(upper = ~Eth*Sex*Age*Lrn, lower = ~1),
    trace = FALSE)
dropterm(quine.stp, test = "F")
quine.3 &lt;- update(quine.stp, . ~ . - Eth:Age:Lrn)
dropterm(quine.3, test = "F")
quine.4 &lt;- update(quine.3, . ~ . - Eth:Age)
dropterm(quine.4, test = "F")
quine.5 &lt;- update(quine.4, . ~ . - Age:Lrn)
dropterm(quine.5, test = "F")

house.glm0 &lt;- glm(Freq ~ Infl*Type*Cont + Sat, family=poisson,
                   data = housing)
house.glm1 &lt;- update(house.glm0, . ~ . + Sat*(Infl+Type+Cont))
dropterm(house.glm1, test = "Chisq")
</code></pre>

<hr>
<h2 id='eagles'>
Foraging Ecology of Bald Eagles
</h2><span id='topic+eagles'></span>

<h3>Description</h3>

<p>Knight and Skagen collected during a field study on the foraging
behaviour of wintering Bald Eagles in Washington State, USA data
concerning 160 attempts by one (pirating) Bald Eagle to steal a chum
salmon from another (feeding) Bald Eagle.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>eagles
</code></pre>


<h3>Format</h3>

<p>The <code>eagles</code> data frame has 8 rows and 5 columns.
</p>

<dl>
<dt><code>y</code></dt><dd>
<p>Number of successful attempts.
</p>
</dd>
<dt><code>n</code></dt><dd>
<p>Total number of attempts.
</p>
</dd>
<dt><code>P</code></dt><dd>
<p>Size of pirating eagle (<code>L</code> = large, <code>S</code> = small).
</p>
</dd>
<dt><code>A</code></dt><dd>
<p>Age of pirating eagle (<code>I</code> = immature, <code>A</code> = adult).
</p>
</dd>
<dt><code>V</code></dt><dd>
<p>Size of victim eagle (<code>L</code> = large, <code>S</code> = small).
</p>
</dd>
</dl>



<h3>Source</h3>

<p>Knight, R. L. and Skagen, S. K. (1988)
Agonistic asymmetries and the foraging ecology of Bald Eagles.
<em>Ecology</em> <b>69</b>, 1188&ndash;1194.
</p>


<h3>References</h3>

<p>Venables, W. N. and Ripley, B. D. (2002)
<em>Modern Applied Statistics with S-PLUS.</em> Fourth Edition. Springer.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>eagles.glm &lt;- glm(cbind(y, n - y) ~ P*A + V, data = eagles,
                  family = binomial)
dropterm(eagles.glm)
prof &lt;- profile(eagles.glm)
plot(prof)
pairs(prof)
</code></pre>

<hr>
<h2 id='epil'>
Seizure Counts for Epileptics
</h2><span id='topic+epil'></span>

<h3>Description</h3>

<p>Thall and Vail (1990) give a data set on two-week seizure counts for
59 epileptics.  The number of seizures was recorded for a baseline
period of 8 weeks, and then patients were randomly assigned to a
treatment group or a control group.  Counts were then recorded for
four successive two-week periods. The subject's age is the only
covariate.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>epil
</code></pre>


<h3>Format</h3>

<p>This data frame has 236 rows and the following 9 columns:
</p>

<dl>
<dt><code>y</code></dt><dd>
<p>the count for the 2-week period.
</p>
</dd>
<dt><code>trt</code></dt><dd>
<p>treatment, <code>"placebo"</code> or <code>"progabide"</code>.
</p>
</dd>
<dt><code>base</code></dt><dd>
<p>the counts in the baseline 8-week period.
</p>
</dd>
<dt><code>age</code></dt><dd>
<p>subject's age, in years.
</p>
</dd>
<dt><code>V4</code></dt><dd>
<p><code>0/1</code> indicator variable of period 4.
</p>
</dd>
<dt><code>subject</code></dt><dd>
<p>subject number, 1 to 59.
</p>
</dd>
<dt><code>period</code></dt><dd>
<p>period, 1 to 4.
</p>
</dd>
<dt><code>lbase</code></dt><dd>
<p>log-counts for the baseline period, centred to have zero mean.
</p>
</dd>
<dt><code>lage</code></dt><dd>
<p>log-ages, centred to have zero mean.
</p>
</dd>
</dl>



<h3>Source</h3>

<p>Thall, P. F. and Vail, S. C. (1990)
Some covariance models for longitudinal count data with over-dispersion.
<em>Biometrics</em> <b>46</b>, 657&ndash;671.
</p>


<h3>References</h3>

<p>Venables, W. N. and Ripley, B. D. (2002)
<em>Modern Applied Statistics with S.</em> Fourth Edition. Springer.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## IGNORE_RDIFF_BEGIN
summary(glm(y ~ lbase*trt + lage + V4, family = poisson,
            data = epil), correlation = FALSE)
## IGNORE_RDIFF_END
epil2 &lt;- epil[epil$period == 1, ]
epil2["period"] &lt;- rep(0, 59); epil2["y"] &lt;- epil2["base"]
epil["time"] &lt;- 1; epil2["time"] &lt;- 4
epil2 &lt;- rbind(epil, epil2)
epil2$pred &lt;- unclass(epil2$trt) * (epil2$period &gt; 0)
epil2$subject &lt;- factor(epil2$subject)
epil3 &lt;- aggregate(epil2, list(epil2$subject, epil2$period &gt; 0),
   function(x) if(is.numeric(x)) sum(x) else x[1])
epil3$pred &lt;- factor(epil3$pred,
   labels = c("base", "placebo", "drug"))

contrasts(epil3$pred) &lt;- structure(contr.sdif(3),
    dimnames = list(NULL, c("placebo-base", "drug-placebo")))
## IGNORE_RDIFF_BEGIN
summary(glm(y ~ pred + factor(subject) + offset(log(time)),
            family = poisson, data = epil3), correlation = FALSE)
## IGNORE_RDIFF_END

summary(glmmPQL(y ~ lbase*trt + lage + V4,
                random = ~ 1 | subject,
                family = poisson, data = epil))
summary(glmmPQL(y ~ pred, random = ~1 | subject,
                family = poisson, data = epil3))
</code></pre>

<hr>
<h2 id='eqscplot'>
Plots with Geometrically Equal Scales
</h2><span id='topic+eqscplot'></span>

<h3>Description</h3>

<p>Version of a scatterplot with scales chosen to be equal on both axes, that
is 1cm represents the same units on each
</p>


<h3>Usage</h3>

<pre><code class='language-R'>eqscplot(x, y, ratio = 1, tol = 0.04, uin, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="eqscplot_+3A_x">x</code></td>
<td>

<p>vector of x values, or a 2-column matrix, or a list with components
<code>x</code> and <code>y</code>
</p>
</td></tr>
<tr><td><code id="eqscplot_+3A_y">y</code></td>
<td>

<p>vector of y values
</p>
</td></tr>
<tr><td><code id="eqscplot_+3A_ratio">ratio</code></td>
<td>

<p>desired ratio of units on the axes.  Units on the y axis are drawn at
<code>ratio</code> times the size of units on the x axis.  Ignored if <code>uin</code> is
specified and of length 2.
</p>
</td></tr>
<tr><td><code id="eqscplot_+3A_tol">tol</code></td>
<td>

<p>proportion of white space at the margins of plot
</p>
</td></tr>
<tr><td><code id="eqscplot_+3A_uin">uin</code></td>
<td>

<p>desired values for the units-per-inch parameter. If of length 1, the
desired units per inch on the x axis.
</p>
</td></tr>
<tr><td><code id="eqscplot_+3A_...">...</code></td>
<td>

<p>further arguments for <code>plot</code> and graphical parameters.  Note that
<code>par(xaxs="i", yaxs="i")</code> is enforced, and <code>xlim</code> and
<code>ylim</code> will be adjusted accordingly.
</p>
</td></tr></table>


<h3>Details</h3>

<p>Limits for the x and y axes are chosen so that they include the
data.  One of the sets of limits is then stretched from the midpoint to
make the units in the ratio given by <code>ratio</code>. Finally both are
stretched by <code>1 + tol</code> to move points away from the axes, and the
points plotted.
</p>


<h3>Value</h3>

<p>invisibly, the values of <code>uin</code> used for the plot.
</p>


<h3>Side Effects</h3>

<p>performs the plot.
</p>


<h3>Note</h3>

<p>Arguments <code>ratio</code> and <code>uin</code> were suggested by Bill Dunlap.
</p>


<h3>References</h3>

<p>Venables, W. N. and Ripley, B. D. (2002)
<em>Modern Applied Statistics with S.</em> Fourth edition.  Springer.
</p>


<h3>See Also</h3>

<p><code><a href="graphics.html#topic+plot">plot</a></code>, <code><a href="graphics.html#topic+par">par</a></code>
</p>

<hr>
<h2 id='farms'>
Ecological Factors in Farm Management
</h2><span id='topic+farms'></span>

<h3>Description</h3>

<p>The <code>farms</code> data frame has 20 rows and 4 columns. The rows are farms
on the Dutch island of Terschelling and the columns are factors
describing the management of grassland.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>farms
</code></pre>


<h3>Format</h3>

<p>This data frame contains the following columns:
</p>

<dl>
<dt><code>Mois</code></dt><dd>
<p>Five levels of soil moisture &ndash; level 3 does not occur at these 20 farms.
</p>
</dd>
<dt><code>Manag</code></dt><dd>
<p>Grassland management type (<code>SF</code> = standard,
<code>BF</code> = biological, <code>HF</code> = hobby farming,
<code>NM</code> = nature conservation).
</p>
</dd>
<dt><code>Use</code></dt><dd>
<p>Grassland use (<code>U1</code> = hay production, <code>U2</code> =
intermediate, <code>U3</code> = grazing).
</p>
</dd>
<dt><code>Manure</code></dt><dd>
<p>Manure usage &ndash; classes <code>C0</code> to <code>C4</code>.
</p>
</dd>
</dl>



<h3>Source</h3>

<p>J.C. Gower and D.J. Hand (1996) <em>Biplots</em>. Chapman &amp; Hall, Table 4.6.
</p>
<p>Quoted as from:<br />
R.H.G. Jongman, C.J.F. ter Braak and O.F.R. van Tongeren (1987)
<em>Data Analysis in Community and Landscape Ecology.</em>
PUDOC, Wageningen.
</p>


<h3>References</h3>

<p>Venables, W. N. and Ripley, B. D. (2002)
<em>Modern Applied Statistics with S.</em> Fourth edition.  Springer.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>farms.mca &lt;- mca(farms, abbrev = TRUE)  # Use levels as names
eqscplot(farms.mca$cs, type = "n")
text(farms.mca$rs, cex = 0.7)
text(farms.mca$cs, labels = dimnames(farms.mca$cs)[[1]], cex = 0.7)
</code></pre>

<hr>
<h2 id='fgl'>
Measurements of Forensic Glass Fragments
</h2><span id='topic+fgl'></span>

<h3>Description</h3>

<p>The <code>fgl</code> data frame has 214 rows and 10 columns.
It was collected by B. German on fragments of glass
collected in forensic work.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fgl
</code></pre>


<h3>Format</h3>

<p>This data frame contains the following columns:
</p>

<dl>
<dt><code>RI</code></dt><dd>
<p>refractive index; more precisely the refractive index is 1.518xxxx.
</p>
<p>The next 8 measurements are percentages by weight of oxides.
</p>
</dd>
<dt><code>Na</code></dt><dd><p>sodium.</p>
</dd>
<dt><code>Mg</code></dt><dd><p>manganese.</p>
</dd>
<dt><code>Al</code></dt><dd><p>aluminium.</p>
</dd>
<dt><code>Si</code></dt><dd><p>silicon.</p>
</dd>
<dt><code>K</code></dt><dd><p>potassium.</p>
</dd>
<dt><code>Ca</code></dt><dd><p>calcium.</p>
</dd>
<dt><code>Ba</code></dt><dd><p>barium.</p>
</dd>
<dt><code>Fe</code></dt><dd><p>iron.</p>
</dd>
<dt><code>type</code></dt><dd>
<p>The fragments were originally classed into seven types, one of which
was absent in this dataset.  The categories which occur are
window float glass (<code>WinF</code>: 70),
window non-float glass (<code>WinNF</code>: 76),
vehicle window glass (<code>Veh</code>: 17),
containers (<code>Con</code>: 13),
tableware (<code>Tabl</code>: 9) and
vehicle headlamps (<code>Head</code>: 29).
</p>
</dd>
</dl>



<h3>References</h3>

<p>Venables, W. N. and Ripley, B. D. (2002)
<em>Modern Applied Statistics with S.</em> Fourth edition.  Springer.
</p>

<hr>
<h2 id='fitdistr'>
Maximum-likelihood Fitting of Univariate Distributions
</h2><span id='topic+fitdistr'></span>

<h3>Description</h3>

<p>Maximum-likelihood fitting of univariate distributions, allowing
parameters to be held fixed if desired.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fitdistr(x, densfun, start, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fitdistr_+3A_x">x</code></td>
<td>

<p>A numeric vector of length at least one containing only <a href="base.html#topic+finite">finite</a> values.
</p>
</td></tr>
<tr><td><code id="fitdistr_+3A_densfun">densfun</code></td>
<td>

<p>Either a character string or a function returning a density evaluated
at its first argument.
</p>
<p>Distributions <code>"beta"</code>, <code>"cauchy"</code>, <code>"chi-squared"</code>,
<code>"exponential"</code>, <code>"gamma"</code>, <code>"geometric"</code>,
<code>"log-normal"</code>, <code>"lognormal"</code>, <code>"logistic"</code>,
<code>"negative binomial"</code>, <code>"normal"</code>, <code>"Poisson"</code>,
<code>"t"</code> and <code>"weibull"</code> are recognised, case being ignored.
</p>
</td></tr>
<tr><td><code id="fitdistr_+3A_start">start</code></td>
<td>

<p>A named list giving the parameters to be optimized with initial
values.  This can be omitted for some of the named distributions and
must be for others (see Details).
</p>
</td></tr>
<tr><td><code id="fitdistr_+3A_...">...</code></td>
<td>

<p>Additional parameters, either for <code>densfun</code> or for <code>optim</code>.
In particular, it can be used to specify bounds via <code>lower</code> or
<code>upper</code> or both.  If arguments of <code>densfun</code> (or the density
function corresponding to a character-string specification) are included
they will be held fixed.
</p>
</td></tr></table>


<h3>Details</h3>

<p>For the Normal, log-Normal, geometric, exponential and Poisson
distributions the closed-form MLEs (and exact standard errors) are
used, and <code>start</code> should not be supplied.
</p>
<p>For all other distributions, direct optimization of the log-likelihood
is performed using <code><a href="stats.html#topic+optim">optim</a></code>.  The estimated standard
errors are taken from the observed information matrix, calculated by a
numerical approximation.  For one-dimensional problems the Nelder-Mead
method is used and for multi-dimensional problems the BFGS method,
unless arguments named <code>lower</code> or <code>upper</code> are supplied (when
<code>L-BFGS-B</code> is used) or <code>method</code> is supplied explicitly.
</p>
<p>For the <code>"t"</code> named distribution the density is taken to be the
location-scale family with location <code>m</code> and scale <code>s</code>.
</p>
<p>For the following named distributions, reasonable starting values will
be computed if <code>start</code> is omitted or only partially specified:
<code>"cauchy"</code>, <code>"gamma"</code>, <code>"logistic"</code>,
<code>"negative binomial"</code> (parametrized by <code>mu</code> and
<code>size</code>), <code>"t"</code> and <code>"weibull"</code>.  Note that these
starting values may not be good enough if the fit is poor: in
particular they are not resistant to outliers unless the fitted
distribution is long-tailed.
</p>
<p>There are <code><a href="base.html#topic+print">print</a></code>, <code><a href="stats.html#topic+coef">coef</a></code>, <code><a href="stats.html#topic+vcov">vcov</a></code>
and <code><a href="stats.html#topic+logLik">logLik</a></code> methods for class <code>"fitdistr"</code>.
</p>


<h3>Value</h3>

<p>An object of class <code>"fitdistr"</code>, a list with four components,
</p>
<table>
<tr><td><code>estimate</code></td>
<td>
<p>the parameter estimates,</p>
</td></tr>
<tr><td><code>sd</code></td>
<td>
<p>the estimated standard errors,</p>
</td></tr>
<tr><td><code>vcov</code></td>
<td>
<p>the estimated variance-covariance matrix, and</p>
</td></tr>
<tr><td><code>loglik</code></td>
<td>
<p>the log-likelihood.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Numerical optimization cannot work miracles: please note the comments
in <code><a href="stats.html#topic+optim">optim</a></code> on scaling data.  If the fitted parameters are
far away from one, consider re-fitting specifying the control
parameter <code>parscale</code>.
</p>


<h3>References</h3>

<p>Venables, W. N. and Ripley, B. D. (2002)
<em>Modern Applied Statistics with S.</em> Fourth edition.  Springer.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## avoid spurious accuracy
op &lt;- options(digits = 3)
set.seed(123)
x &lt;- rgamma(100, shape = 5, rate = 0.1)
fitdistr(x, "gamma")
## now do this directly with more control.
fitdistr(x, dgamma, list(shape = 1, rate = 0.1), lower = 0.001)

set.seed(123)
x2 &lt;- rt(250, df = 9)
fitdistr(x2, "t", df = 9)
## allow df to vary: not a very good idea!
fitdistr(x2, "t")
## now do fixed-df fit directly with more control.
mydt &lt;- function(x, m, s, df) dt((x-m)/s, df)/s
fitdistr(x2, mydt, list(m = 0, s = 1), df = 9, lower = c(-Inf, 0))

set.seed(123)
x3 &lt;- rweibull(100, shape = 4, scale = 100)
fitdistr(x3, "weibull")

set.seed(123)
x4 &lt;- rnegbin(500, mu = 5, theta = 4)
fitdistr(x4, "Negative Binomial")
options(op)
</code></pre>

<hr>
<h2 id='forbes'>
Forbes' Data on Boiling Points in the Alps
</h2><span id='topic+forbes'></span>

<h3>Description</h3>

<p>A data frame with 17 observations on boiling point
of water and barometric pressure in inches of mercury.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>forbes
</code></pre>


<h3>Format</h3>


<dl>
<dt><code>bp</code></dt><dd>
<p>boiling point (degrees Farenheit).
</p>
</dd>
<dt><code>pres</code></dt><dd>
<p>barometric pressure in inches of mercury.
</p>
</dd>
</dl>



<h3>Source</h3>

<p>A. C. Atkinson (1985) <em>Plots, Transformations and Regression.</em> Oxford.
</p>
<p>S. Weisberg (1980) <em>Applied Linear Regression.</em> Wiley.
</p>

<hr>
<h2 id='fractions'>
Rational Approximation
</h2><span id='topic+fractions'></span><span id='topic+Math.fractions'></span><span id='topic+Ops.fractions'></span><span id='topic+Summary.fractions'></span><span id='topic++5B.fractions'></span><span id='topic++5B+3C-.fractions'></span><span id='topic+as.character.fractions'></span><span id='topic+as.fractions'></span><span id='topic+is.fractions'></span><span id='topic+print.fractions'></span><span id='topic+t.fractions'></span>

<h3>Description</h3>

<p>Find rational approximations to the components of a real numeric
object using a standard continued fraction method.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fractions(x, cycles = 10, max.denominator = 2000, ...)

as.fractions(x)

is.fractions(f)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fractions_+3A_x">x</code></td>
<td>

<p>Any object of mode numeric. Missing values are now allowed.
</p>
</td></tr>
<tr><td><code id="fractions_+3A_cycles">cycles</code></td>
<td>

<p>The maximum number of steps to be used in the continued fraction
approximation process.
</p>
</td></tr>
<tr><td><code id="fractions_+3A_max.denominator">max.denominator</code></td>
<td>

<p>An early termination criterion.  If any partial denominator
exceeds <code>max.denominator</code> the continued fraction stops at that point.
</p>
</td></tr>
<tr><td><code id="fractions_+3A_...">...</code></td>
<td>

<p>arguments passed to or from other methods.
</p>
</td></tr>
<tr><td><code id="fractions_+3A_f">f</code></td>
<td>

<p>an <span class="rlang"><b>R</b></span>  object.
</p>
</td></tr></table>


<h3>Details</h3>

<p>Each component is first expanded in a continued fraction of the
form
</p>
<p><code>x = floor(x) + 1/(p1 + 1/(p2 + ...)))</code>
</p>
<p>where <code>p1</code>, <code>p2</code>, ... are positive integers, terminating either
at <code>cycles</code> terms or when a <code>pj &gt; max.denominator</code>.  The
continued fraction is then re-arranged to retrieve the numerator
and denominator as integers.
</p>
<p>The numerators and denominators are then combined into a
character vector that becomes the <code>"fracs"</code> attribute and used in
printed representations.
</p>
<p>Arithmetic operations on <code>"fractions"</code> objects have full floating
point accuracy, but the character representation printed out may
not.
</p>


<h3>Value</h3>

<p>An object of class <code>"fractions"</code>.  A structure with <code>.Data</code> component
the same as the input numeric <code>x</code>, but with the rational
approximations held as a character vector attribute, <code>"fracs"</code>.
Arithmetic operations on <code>"fractions"</code> objects are possible.
</p>


<h3>References</h3>

<p>Venables, W. N. and Ripley, B. D. (2002)
<em>Modern Applied Statistics with S.</em> Fourth Edition. Springer.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rational">rational</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>X &lt;- matrix(runif(25), 5, 5)
zapsmall(solve(X, X/5)) # print near-zeroes as zero
fractions(solve(X, X/5))
fractions(solve(X, X/5)) + 1
</code></pre>

<hr>
<h2 id='GAGurine'>
Level of GAG in Urine of Children
</h2><span id='topic+GAGurine'></span>

<h3>Description</h3>

<p>Data were collected on the concentration of a chemical GAG in the
urine of 314 children aged from zero to seventeen years.  The aim of
the study was to produce a chart to help a paediatrican to assess if a
child's GAG concentration is &lsquo;normal&rsquo;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>GAGurine
</code></pre>


<h3>Format</h3>

<p>This data frame contains the following columns:
</p>

<dl>
<dt><code>Age</code></dt><dd>
<p>age of child in years.
</p>
</dd>
<dt><code>GAG</code></dt><dd>
<p>concentration of GAG (the units have been lost).
</p>
</dd>
</dl>



<h3>Source</h3>

<p>Mrs Susan Prosser, Paediatrics Department, University of Oxford,
via Department of Statistics Consulting Service.
</p>


<h3>References</h3>

<p>Venables, W. N. and Ripley, B. D. (2002)
<em>Modern Applied Statistics with S.</em> Fourth edition.  Springer.
</p>

<hr>
<h2 id='galaxies'>
Velocities for 82 Galaxies
</h2><span id='topic+galaxies'></span>

<h3>Description</h3>

<p>A numeric vector of velocities in km/sec of 82 galaxies from 6
well-separated conic sections of an <code>unfilled</code> survey of the Corona
Borealis region.  Multimodality in such surveys is evidence for voids
and superclusters in the far universe.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>galaxies
</code></pre>


<h3>Note</h3>

<p>There is an 83rd measurement of 5607 km/sec in the Postman
<em>et al.</em> paper which is omitted in Roeder (1990) and from the
dataset here.
</p>
<p>There is also a typo: this dataset has 78th observation 26690 which
should be 26960.
</p>


<h3>Source</h3>

<p>Roeder, K. (1990) Density estimation with confidence sets exemplified
by superclusters and voids in galaxies.
<em>Journal of the American Statistical Association</em> <b>85</b>, 617&ndash;624.
</p>
<p>Postman, M., Huchra, J. P. and Geller, M. J. (1986)
Probes of large-scale structures in the Corona Borealis region.
<em>Astronomical Journal</em> <b>92</b>, 1238&ndash;1247.
</p>


<h3>References</h3>

<p>Venables, W. N. and Ripley, B. D. (2002)
<em>Modern Applied Statistics with S.</em> Fourth edition.  Springer.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>gal &lt;- galaxies/1000
c(width.SJ(gal, method = "dpi"), width.SJ(gal))
plot(x = c(0, 40), y = c(0, 0.3), type = "n", bty = "l",
     xlab = "velocity of galaxy (1000km/s)", ylab = "density")
rug(gal)
lines(density(gal, width = 3.25, n = 200), lty = 1)
lines(density(gal, width = 2.56, n = 200), lty = 3)
</code></pre>

<hr>
<h2 id='gamma.dispersion'>
Calculate the MLE of the Gamma Dispersion Parameter in a GLM Fit
</h2><span id='topic+gamma.dispersion'></span>

<h3>Description</h3>

<p>A front end to <code>gamma.shape</code> for convenience.  Finds the
reciprocal of the estimate of the shape parameter only.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gamma.dispersion(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gamma.dispersion_+3A_object">object</code></td>
<td>

<p>Fitted model object giving the gamma fit.
</p>
</td></tr>
<tr><td><code id="gamma.dispersion_+3A_...">...</code></td>
<td>

<p>Additional arguments passed on to <code>gamma.shape</code>.
</p>
</td></tr></table>


<h3>Value</h3>

<p>The MLE of the dispersion parameter of the gamma distribution.
</p>


<h3>References</h3>

<p>Venables, W. N. and Ripley, B. D. (2002)
<em>Modern Applied Statistics with S.</em> Fourth edition.  Springer.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gamma.shape.glm">gamma.shape.glm</a></code>, including the example on its help page.
</p>

<hr>
<h2 id='gamma.shape'>
Estimate the Shape Parameter of the Gamma Distribution in a GLM Fit
</h2><span id='topic+gamma.shape'></span><span id='topic+gamma.shape.glm'></span><span id='topic+print.gamma.shape'></span>

<h3>Description</h3>

<p>Find the maximum likelihood estimate of the shape parameter of
the gamma distribution after fitting a <code>Gamma</code> generalized
linear model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gamma.shape(object, ...)

## S3 method for class 'glm'
gamma.shape(object, it.lim = 10,
            eps.max = .Machine$double.eps^0.25, verbose = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gamma.shape_+3A_object">object</code></td>
<td>

<p>Fitted model object from a <code>Gamma</code> family or <code>quasi</code> family with
<code>variance = "mu^2"</code>.
</p>
</td></tr>
<tr><td><code id="gamma.shape_+3A_it.lim">it.lim</code></td>
<td>

<p>Upper limit on the number of iterations.
</p>
</td></tr>
<tr><td><code id="gamma.shape_+3A_eps.max">eps.max</code></td>
<td>

<p>Maximum discrepancy between approximations for the iteration
process to continue.
</p>
</td></tr>
<tr><td><code id="gamma.shape_+3A_verbose">verbose</code></td>
<td>

<p>If <code>TRUE</code>, causes successive iterations to be printed out.  The
initial estimate is taken from the deviance.
</p>
</td></tr>
<tr><td><code id="gamma.shape_+3A_...">...</code></td>
<td>

<p>further arguments passed to or from other methods.
</p>
</td></tr></table>


<h3>Details</h3>

<p>A glm fit for a Gamma family correctly calculates the maximum
likelihood estimate of the mean parameters but provides only a
crude estimate of the dispersion parameter.  This function takes
the results of the glm fit and solves the maximum likelihood
equation for the reciprocal of the dispersion parameter, which is
usually called the shape (or exponent) parameter.
</p>


<h3>Value</h3>

<p>List of two components
</p>
<table>
<tr><td><code>alpha</code></td>
<td>

<p>the maximum likelihood estimate
</p>
</td></tr>
<tr><td><code>SE</code></td>
<td>

<p>the approximate standard error, the square-root of the reciprocal of
the observed information.
</p>
</td></tr></table>


<h3>References</h3>

<p>Venables, W. N. and Ripley, B. D. (2002)
<em>Modern Applied Statistics with S.</em> Fourth edition.  Springer.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gamma.dispersion">gamma.dispersion</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>clotting &lt;- data.frame(
    u = c(5,10,15,20,30,40,60,80,100),
    lot1 = c(118,58,42,35,27,25,21,19,18),
    lot2 = c(69,35,26,21,18,16,13,12,12))
clot1 &lt;- glm(lot1 ~ log(u), data = clotting, family = Gamma)
gamma.shape(clot1)

gm &lt;- glm(Days + 0.1 ~ Age*Eth*Sex*Lrn,
          quasi(link=log, variance="mu^2"), quine,
          start = c(3, rep(0,31)))
gamma.shape(gm, verbose = TRUE)
## IGNORE_RDIFF_BEGIN
summary(gm, dispersion = gamma.dispersion(gm))  # better summary
## IGNORE_RDIFF_END
</code></pre>

<hr>
<h2 id='gehan'>
Remission Times of Leukaemia Patients
</h2><span id='topic+gehan'></span>

<h3>Description</h3>

<p>A data frame from a trial of 42 leukaemia patients. Some were
treated with the drug <em>6-mercaptopurine</em>
and the rest are controls.  The trial was designed as matched pairs,
both withdrawn from the trial when either came out of remission.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gehan
</code></pre>


<h3>Format</h3>

<p>This data frame contains the following columns:
</p>

<dl>
<dt><code>pair</code></dt><dd>
<p>label for pair.
</p>
</dd>
<dt><code>time</code></dt><dd>
<p>remission time in weeks.
</p>
</dd>
<dt><code>cens</code></dt><dd>
<p>censoring, 0/1.
</p>
</dd>
<dt><code>treat</code></dt><dd>
<p>treatment, control or 6-MP.
</p>
</dd>
</dl>



<h3>Source</h3>

<p>Cox, D. R. and Oakes, D. (1984) <em>Analysis of Survival Data.</em>
Chapman &amp; Hall, p. 7. Taken from
</p>
<p>Gehan, E.A. (1965) A generalized Wilcoxon test for comparing
arbitrarily single-censored samples.
<em>Biometrika</em> <b>52</b>, 203&ndash;233.
</p>


<h3>References</h3>

<p>Venables, W. N. and Ripley, B. D. (2002)
<em>Modern Applied Statistics with S.</em> Fourth edition.  Springer.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(survival)
gehan.surv &lt;- survfit(Surv(time, cens) ~ treat, data = gehan,
     conf.type = "log-log")
summary(gehan.surv)
survreg(Surv(time, cens) ~ factor(pair) + treat, gehan, dist = "exponential")
summary(survreg(Surv(time, cens) ~ treat, gehan, dist = "exponential"))
summary(survreg(Surv(time, cens) ~ treat, gehan))
gehan.cox &lt;- coxph(Surv(time, cens) ~ treat, gehan)
summary(gehan.cox)
</code></pre>

<hr>
<h2 id='genotype'>
Rat Genotype Data
</h2><span id='topic+genotype'></span>

<h3>Description</h3>

<p>Data from a foster feeding experiment with rat mothers and litters of
four different genotypes: <code>A</code>, <code>B</code>, <code>I</code> and <code>J</code>.
Rat litters were separated from their natural mothers at birth and
given to foster mothers to rear.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>genotype
</code></pre>


<h3>Format</h3>

<p>The data frame has the following components:
</p>

<dl>
<dt><code>Litter</code></dt><dd>
<p>genotype of the litter.
</p>
</dd>
<dt><code>Mother</code></dt><dd>
<p>genotype of the foster mother.
</p>
</dd>
<dt><code>Wt</code></dt><dd>
<p>Litter average weight gain of the litter, in grams at age 28 days.
(The source states that the within-litter variability is negligible.)
</p>
</dd>
</dl>



<h3>Source</h3>

<p>Scheffe, H. (1959) <em>The Analysis of Variance</em> Wiley p. 140.
</p>
<p>Bailey, D. W. (1953)
<em>The Inheritance of Maternal Influences on the Growth of the Rat.</em>
Unpublished Ph.D. thesis, University of California. Table B of the Appendix.
</p>


<h3>References</h3>

<p>Venables, W. N. and Ripley, B. D. (2002)
<em>Modern Applied Statistics with S-PLUS.</em> Fourth Edition. Springer.
</p>

<hr>
<h2 id='geyser'>Old Faithful Geyser Data</h2><span id='topic+geyser'></span>

<h3>Description</h3>

<p>A version of the eruptions data from the &lsquo;Old Faithful&rsquo; geyser
in Yellowstone National  Park,  Wyoming. This version comes from
Azzalini and Bowman (1990) and is of continuous measurement from August
1 to August 15, 1985.
</p>
<p>Some nocturnal duration measurements were coded as 2, 3 or 4 minutes,
having originally been described as &lsquo;short&rsquo;, &lsquo;medium&rsquo;
or &lsquo;long&rsquo;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>geyser
</code></pre>


<h3>Format</h3>

<p>A data frame with 299 observations on 2 variables.
</p>

<table>
<tr>
 <td style="text-align: left;">
    <code>duration</code>  </td><td style="text-align: left;"> numeric  </td><td style="text-align: left;"> Eruption time in mins </td>
</tr>
<tr>
 <td style="text-align: left;">
    <code>waiting</code>   </td><td style="text-align: left;"> numeric  </td><td style="text-align: left;"> Waiting time for this eruption </td>
</tr>
<tr>
 <td style="text-align: left;">
  </td>
</tr>

</table>



<h3>Note</h3>

<p>The <code>waiting</code> time was incorrectly described as the time to the
next eruption in the original files, and corrected for <span class="pkg">MASS</span>
version 7.3-30.
</p>


<h3>References</h3>

<p>Azzalini, A. and Bowman, A. W. (1990) A look at some
data on the Old Faithful geyser.  <em>Applied Statistics</em>
<b>39</b>, 357&ndash;365.
</p>
<p>Venables, W. N. and Ripley, B. D. (2002)
<em>Modern Applied Statistics with S.</em> Fourth edition.  Springer.
</p>


<h3>See Also</h3>

<p><code><a href="datasets.html#topic+faithful">faithful</a></code>.
</p>
<p>CRAN package <span class="pkg">sm</span>.
</p>

<hr>
<h2 id='gilgais'>
Line Transect of Soil in Gilgai Territory
</h2><span id='topic+gilgais'></span>

<h3>Description</h3>

<p>This dataset was collected on a line transect survey in gilgai
territory in New South Wales, Australia.  Gilgais are natural gentle
depressions in otherwise flat land, and sometimes seem to be regularly
distributed. The data collection was stimulated by the question: are
these patterns reflected in soil properties?  At each of 365 sampling
locations on a linear grid of 4 meters spacing, samples were taken at
depths 0-10 cm, 30-40 cm and 80-90 cm below the surface. pH, electrical
conductivity and chloride content were measured on a 1:5 soil:water
extract from each sample.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gilgais
</code></pre>


<h3>Format</h3>

<p>This data frame contains the following columns:
</p>

<dl>
<dt><code>pH00</code></dt><dd>
<p>pH at depth 0&ndash;10 cm.
</p>
</dd>
<dt><code>pH30</code></dt><dd>
<p>pH at depth 30&ndash;40 cm.
</p>
</dd>
<dt><code>pH80</code></dt><dd>
<p>pH at depth 80&ndash;90 cm.
</p>
</dd>
<dt><code>e00</code></dt><dd>
<p>electrical conductivity in mS/cm  (0&ndash;10 cm).
</p>
</dd>
<dt><code>e30</code></dt><dd>
<p>electrical conductivity in mS/cm (30&ndash;40 cm).
</p>
</dd>
<dt><code>e80</code></dt><dd>
<p>electrical conductivity in mS/cm (80&ndash;90 cm).
</p>
</dd>
<dt><code>c00</code></dt><dd>
<p>chloride content in ppm  (0&ndash;10 cm).
</p>
</dd>
<dt><code>c30</code></dt><dd>
<p>chloride content in ppm (30&ndash;40 cm).
</p>
</dd>
<dt><code>c80</code></dt><dd>
<p>chloride content in ppm (80&ndash;90 cm).
</p>
</dd>
</dl>



<h3>Source</h3>

<p>Webster, R. (1977) Spectral analysis of gilgai soil.
<em>Australian Journal of Soil Research</em> <b>15</b>, 191&ndash;204.
</p>
<p>Laslett, G. M. (1989)
Kriging and splines: An empirical comparison of their
predictive performance in some applications (with discussion).
<em>Journal of the American Statistical Association</em> <b>89</b>, 319&ndash;409
</p>


<h3>References</h3>

<p>Venables, W. N. and Ripley, B. D. (2002)
<em>Modern Applied Statistics with S.</em> Fourth edition.  Springer.
</p>

<hr>
<h2 id='ginv'>
Generalized Inverse of a Matrix
</h2><span id='topic+ginv'></span>

<h3>Description</h3>

<p>Calculates the Moore-Penrose generalized inverse of a matrix
<code>X</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ginv(X, tol = sqrt(.Machine$double.eps))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ginv_+3A_x">X</code></td>
<td>

<p>Matrix for which the Moore-Penrose inverse is required.
</p>
</td></tr>
<tr><td><code id="ginv_+3A_tol">tol</code></td>
<td>

<p>A relative tolerance to detect zero singular values.
</p>
</td></tr></table>


<h3>Value</h3>

<p>A MP generalized inverse matrix for <code>X</code>.
</p>


<h3>References</h3>

<p>Venables, W. N. and Ripley, B. D. (2002)
<em>Modern Applied Statistics with S-PLUS.</em> Fourth Edition. Springer.
</p>


<h3>See Also</h3>

<p><code><a href="Matrix.html#topic+solve">solve</a></code>, <code><a href="base.html#topic+svd">svd</a></code>, <code><a href="base.html#topic+eigen">eigen</a></code>
</p>

<hr>
<h2 id='glm.convert'>
Change a Negative Binomial fit to a GLM fit
</h2><span id='topic+glm.convert'></span>

<h3>Description</h3>

<p>This function modifies an output object from <code>glm.nb()</code> to one
that looks like the output from <code>glm()</code> with a negative binomial
family.  This allows it to be updated keeping the theta parameter
fixed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>glm.convert(object)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="glm.convert_+3A_object">object</code></td>
<td>

<p>An object of class <code>"negbin"</code>, typically the output from
<code><a href="#topic+glm.nb">glm.nb</a>()</code>.
</p>
</td></tr></table>


<h3>Details</h3>

<p>Convenience function needed to effect some low level changes to the
structure of the fitted model object.
</p>


<h3>Value</h3>

<p>An object of class <code>"glm"</code> with negative binomial family.  The theta
parameter is then fixed at its present estimate.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+glm.nb">glm.nb</a></code>, <code><a href="#topic+negative.binomial">negative.binomial</a></code>, <code><a href="stats.html#topic+glm">glm</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>quine.nb1 &lt;- glm.nb(Days ~ Sex/(Age + Eth*Lrn), data = quine)
quine.nbA &lt;- glm.convert(quine.nb1)
quine.nbB &lt;- update(quine.nb1, . ~ . + Sex:Age:Lrn)
anova(quine.nbA, quine.nbB)
</code></pre>

<hr>
<h2 id='glm.nb'>
Fit a Negative Binomial Generalized Linear Model
</h2><span id='topic+glm.nb'></span><span id='topic+family.negbin'></span><span id='topic+logLik.negbin'></span>

<h3>Description</h3>

<p>A modification of the system function <code><a href="stats.html#topic+glm">glm</a>()</code> to include
estimation of the additional parameter, <code>theta</code>, for a
Negative Binomial generalized linear model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>glm.nb(formula, data, weights, subset, na.action,
       start = NULL, etastart, mustart,
       control = glm.control(...), method = "glm.fit",
       model = TRUE, x = FALSE, y = TRUE, contrasts = NULL, ...,
       init.theta, link = log)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="glm.nb_+3A_formula">formula</code>, <code id="glm.nb_+3A_data">data</code>, <code id="glm.nb_+3A_weights">weights</code>, <code id="glm.nb_+3A_subset">subset</code>, <code id="glm.nb_+3A_na.action">na.action</code>, <code id="glm.nb_+3A_start">start</code>, <code id="glm.nb_+3A_etastart">etastart</code>, <code id="glm.nb_+3A_mustart">mustart</code>, <code id="glm.nb_+3A_control">control</code>, <code id="glm.nb_+3A_method">method</code>, <code id="glm.nb_+3A_model">model</code>, <code id="glm.nb_+3A_x">x</code>, <code id="glm.nb_+3A_y">y</code>, <code id="glm.nb_+3A_contrasts">contrasts</code>, <code id="glm.nb_+3A_...">...</code></td>
<td>

<p>arguments for the <code><a href="stats.html#topic+glm">glm</a>()</code> function.
Note that these exclude <code>family</code> and <code>offset</code>
(but <code><a href="stats.html#topic+offset">offset</a>()</code> can be used).
</p>
</td></tr>
<tr><td><code id="glm.nb_+3A_init.theta">init.theta</code></td>
<td>

<p>Optional initial value for the theta parameter.  If omitted a moment
estimator after an initial fit using a Poisson GLM is used.
</p>
</td></tr>
<tr><td><code id="glm.nb_+3A_link">link</code></td>
<td>

<p>The link function.  Currently must be one of <code>log</code>, <code>sqrt</code>
or <code>identity</code>.
</p>
</td></tr></table>


<h3>Details</h3>

<p>An alternating iteration process is used.  For given <code>theta</code> the GLM
is fitted using the same process as used by <code>glm()</code>.  For fixed means
the <code>theta</code> parameter is estimated using score and information
iterations.  The two are alternated until convergence of both. (The
number of alternations and the number of iterations when estimating
<code>theta</code> are controlled by the <code>maxit</code> parameter of
<code>glm.control</code>.)
</p>
<p>Setting <code>trace &gt; 0</code> traces the alternating iteration
process. Setting <code>trace &gt; 1</code> traces the <code>glm</code> fit, and
setting <code>trace &gt; 2</code> traces the estimation of <code>theta</code>.
</p>


<h3>Value</h3>

<p>A fitted model object of class <code>negbin</code> inheriting from <code>glm</code>
and <code>lm</code>.  The object is like the output of <code>glm</code> but contains
three additional components, namely <code>theta</code> for the ML estimate of
theta, <code>SE.theta</code> for its approximate standard error (using
observed rather than expected information), and <code>twologlik</code> for
twice the log-likelihood function.
</p>


<h3>References</h3>

<p>Venables, W. N. and Ripley, B. D. (2002)
<em>Modern Applied Statistics with S.</em> Fourth edition.  Springer.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+glm">glm</a></code>, <code><a href="#topic+negative.binomial">negative.binomial</a></code>,
<code><a href="#topic+anova.negbin">anova.negbin</a></code>, <code><a href="#topic+summary.negbin">summary.negbin</a></code>,
<code><a href="#topic+theta.md">theta.md</a></code>
</p>
<p>There is a <code><a href="stats.html#topic+simulate">simulate</a></code> method.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>quine.nb1 &lt;- glm.nb(Days ~ Sex/(Age + Eth*Lrn), data = quine)
quine.nb2 &lt;- update(quine.nb1, . ~ . + Sex:Age:Lrn)
quine.nb3 &lt;- update(quine.nb2, Days ~ .^4)
anova(quine.nb1, quine.nb2, quine.nb3)
</code></pre>

<hr>
<h2 id='glmmPQL'>
Fit Generalized Linear Mixed Models via PQL
</h2><span id='topic+glmmPQL'></span>

<h3>Description</h3>

<p>Fit a GLMM model with multivariate normal random effects, using
Penalized Quasi-Likelihood.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>glmmPQL(fixed, random, family, data, correlation, weights,
        control, niter = 10, verbose = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="glmmPQL_+3A_fixed">fixed</code></td>
<td>

<p>a two-sided linear formula giving fixed-effects part of the model.
</p>
</td></tr>
<tr><td><code id="glmmPQL_+3A_random">random</code></td>
<td>

<p>a formula or list of formulae describing the random effects.
</p>
</td></tr>
<tr><td><code id="glmmPQL_+3A_family">family</code></td>
<td>

<p>a GLM family.
</p>
</td></tr>
<tr><td><code id="glmmPQL_+3A_data">data</code></td>
<td>

<p>an optional data frame, list or environment used as the first place to find
variables in the formulae, <code>weights</code> and if present in
<code>...</code>, <code>subset</code>.
</p>
</td></tr>
<tr><td><code id="glmmPQL_+3A_correlation">correlation</code></td>
<td>

<p>an optional correlation structure.
</p>
</td></tr>
<tr><td><code id="glmmPQL_+3A_weights">weights</code></td>
<td>

<p>optional case weights as in <code>glm</code>.
</p>
</td></tr>
<tr><td><code id="glmmPQL_+3A_control">control</code></td>
<td>

<p>an optional argument to be passed to <code>lme</code>.
</p>
</td></tr>
<tr><td><code id="glmmPQL_+3A_niter">niter</code></td>
<td>

<p>maximum number of iterations.
</p>
</td></tr>
<tr><td><code id="glmmPQL_+3A_verbose">verbose</code></td>
<td>

<p>logical: print out record of iterations?
</p>
</td></tr>
<tr><td><code id="glmmPQL_+3A_...">...</code></td>
<td>

<p>Further arguments for <code>lme</code>.
</p>
</td></tr></table>


<h3>Details</h3>

<p><code>glmmPQL</code> works by repeated calls to <code><a href="nlme.html#topic+lme">lme</a></code>, so
namespace <a href="https://CRAN.R-project.org/package=nlme"><span class="pkg">nlme</span></a> will be loaded at first use.  (Before 2015 it
used to attach <code>nlme</code> but nowadays only loads the namespace.)
</p>
<p>Unlike <code>lme</code>, <code><a href="stats.html#topic+offset">offset</a></code> terms are allowed in
<code>fixed</code> &ndash; this is done by pre- and post-processing the calls to
<code>lme</code>.
</p>
<p>Note that the returned object inherits from class <code>"lme"</code> and
that most generics will use the method for that class.  As from
version 3.1-158, the fitted values have any offset included, as do
the results of calling <code><a href="stats.html#topic+predict">predict</a></code>.
</p>


<h3>Value</h3>

<p>A object of class <code>c("glmmPQL", "lme")</code>: see <code><a href="nlme.html#topic+lmeObject">lmeObject</a></code>.
</p>


<h3>References</h3>

<p>Schall, R. (1991) Estimation in generalized linear models with
random effects.
<em>Biometrika</em>
<b>78</b>, 719&ndash;727.
</p>
<p>Breslow, N. E. and Clayton, D. G. (1993) Approximate inference in
generalized linear mixed models.
<em>Journal of the American Statistical Association</em>
<b>88</b>, 9&ndash;25.
</p>
<p>Wolfinger, R. and O'Connell, M. (1993) Generalized linear mixed models: a
pseudo-likelihood approach.
<em>Journal of Statistical Computation and Simulation</em>
<b>48</b>, 233&ndash;243.
</p>
<p>Venables, W. N. and Ripley, B. D. (2002)
<em>Modern Applied Statistics with S.</em> Fourth edition.  Springer.
</p>


<h3>See Also</h3>

<p><code><a href="nlme.html#topic+lme">lme</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>summary(glmmPQL(y ~ trt + I(week &gt; 2), random = ~ 1 | ID,
                family = binomial, data = bacteria))

## an example of an offset: the coefficient of 'week' changes by one.
summary(glmmPQL(y ~ trt + week, random = ~ 1 | ID,
               family = binomial, data = bacteria))
summary(glmmPQL(y ~ trt + week + offset(week), random = ~ 1 | ID,
                family = binomial, data = bacteria))
</code></pre>

<hr>
<h2 id='hills'>
Record Times in Scottish Hill Races
</h2><span id='topic+hills'></span>

<h3>Description</h3>

<p>The record times in 1984 for 35 Scottish hill races.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hills
</code></pre>


<h3>Format</h3>

<p>The components are:
</p>

<dl>
<dt><code>dist</code></dt><dd>
<p>distance in miles (on the map).
</p>
</dd>
<dt><code>climb</code></dt><dd>
<p>total height gained during the route, in feet.
</p>
</dd>
<dt><code>time</code></dt><dd>
<p>record time in minutes.
</p>
</dd>
</dl>



<h3>Source</h3>

<p>A.C. Atkinson (1986) Comment: Aspects of diagnostic regression analysis.
<em>Statistical Science</em> <b>1</b>, 397&ndash;402.
</p>
<p>[A.C. Atkinson (1988) Transformations unmasked. <em>Technometrics</em>
<b>30</b>, 311&ndash;318 &ldquo;corrects&rdquo; the time for Knock Hill from 78.65
to 18.65. It is unclear if this based on the original records.]
</p>


<h3>References</h3>

<p>Venables, W. N. and Ripley, B. D. (2002)
<em>Modern Applied Statistics with S.</em> Fourth edition.  Springer.
</p>

<hr>
<h2 id='hist.scott'>
Plot a Histogram with Automatic Bin Width Selection
</h2><span id='topic+hist.scott'></span><span id='topic+hist.FD'></span>

<h3>Description</h3>

<p>Plot a histogram with automatic bin width selection, using the Scott
or Freedman&ndash;Diaconis formulae.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hist.scott(x, prob = TRUE, xlab = deparse(substitute(x)), ...)
hist.FD(x, prob = TRUE, xlab = deparse(substitute(x)), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="hist.scott_+3A_x">x</code></td>
<td>
<p>A data vector</p>
</td></tr>
<tr><td><code id="hist.scott_+3A_prob">prob</code></td>
<td>
<p>Should the plot have unit area, so be a density estimate?</p>
</td></tr>
<tr><td><code id="hist.scott_+3A_xlab">xlab</code>, <code id="hist.scott_+3A_...">...</code></td>
<td>
<p>Further arguments to <code>hist</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>For the <code>nclass.*</code> functions, the suggested number of classes.
</p>


<h3>Side Effects</h3>

<p>Plot a histogram.
</p>


<h3>References</h3>

<p>Venables, W. N. and Ripley, B. D. (2002)
<em>Modern Applied Statistics with S.</em>
Springer.
</p>


<h3>See Also</h3>

<p><code><a href="graphics.html#topic+hist">hist</a></code>
</p>

<hr>
<h2 id='housing'>
Frequency Table from a Copenhagen Housing Conditions Survey
</h2><span id='topic+housing'></span>

<h3>Description</h3>

<p>The <code>housing</code> data frame has 72 rows and 5 variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>housing
</code></pre>


<h3>Format</h3>


<dl>
<dt><code>Sat</code></dt><dd>
<p>Satisfaction of householders with their present housing
circumstances, (High, Medium or Low, ordered factor).
</p>
</dd>
<dt><code>Infl</code></dt><dd>
<p>Perceived degree of influence householders have on the
management of the property (High, Medium, Low).
</p>
</dd>
<dt><code>Type</code></dt><dd>
<p>Type of rental accommodation, (Tower, Atrium, Apartment, Terrace).
</p>
</dd>
<dt><code>Cont</code></dt><dd>
<p>Contact residents are afforded with other residents, (Low, High).
</p>
</dd>
<dt><code>Freq</code></dt><dd>
<p>Frequencies: the numbers of residents in each class.
</p>
</dd>
</dl>



<h3>Source</h3>

<p>Madsen, M. (1976)
Statistical analysis of multiple contingency tables. Two examples.
<em>Scand. J. Statist.</em> <b>3</b>, 97&ndash;106.
</p>
<p>Cox, D. R. and Snell, E. J. (1984)
<em>Applied Statistics, Principles and Examples</em>.
Chapman &amp; Hall.
</p>


<h3>References</h3>

<p>Venables, W. N. and Ripley, B. D. (2002)
<em>Modern Applied Statistics with S.</em> Fourth edition.  Springer.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>options(contrasts = c("contr.treatment", "contr.poly"))

# Surrogate Poisson models
house.glm0 &lt;- glm(Freq ~ Infl*Type*Cont + Sat, family = poisson,
                  data = housing)
## IGNORE_RDIFF_BEGIN
summary(house.glm0, correlation = FALSE)
## IGNORE_RDIFF_END

addterm(house.glm0, ~. + Sat:(Infl+Type+Cont), test = "Chisq")

house.glm1 &lt;- update(house.glm0, . ~ . + Sat*(Infl+Type+Cont))
## IGNORE_RDIFF_BEGIN
summary(house.glm1, correlation = FALSE)
## IGNORE_RDIFF_END

1 - pchisq(deviance(house.glm1), house.glm1$df.residual)

dropterm(house.glm1, test = "Chisq")

addterm(house.glm1, ~. + Sat:(Infl+Type+Cont)^2, test  =  "Chisq")

hnames &lt;- lapply(housing[, -5], levels) # omit Freq
newData &lt;- expand.grid(hnames)
newData$Sat &lt;- ordered(newData$Sat)
house.pm &lt;- predict(house.glm1, newData,
                    type = "response")  # poisson means
house.pm &lt;- matrix(house.pm, ncol = 3, byrow = TRUE,
                   dimnames = list(NULL, hnames[[1]]))
house.pr &lt;- house.pm/drop(house.pm %*% rep(1, 3))
cbind(expand.grid(hnames[-1]), round(house.pr, 2))

# Iterative proportional scaling
loglm(Freq ~ Infl*Type*Cont + Sat*(Infl+Type+Cont), data = housing)


# multinomial model
library(nnet)
(house.mult&lt;- multinom(Sat ~ Infl + Type + Cont, weights = Freq,
                       data = housing))
house.mult2 &lt;- multinom(Sat ~ Infl*Type*Cont, weights = Freq,
                        data = housing)
anova(house.mult, house.mult2)

house.pm &lt;- predict(house.mult, expand.grid(hnames[-1]), type = "probs")
cbind(expand.grid(hnames[-1]), round(house.pm, 2))

# proportional odds model
house.cpr &lt;- apply(house.pr, 1, cumsum)
logit &lt;- function(x) log(x/(1-x))
house.ld &lt;- logit(house.cpr[2, ]) - logit(house.cpr[1, ])
(ratio &lt;- sort(drop(house.ld)))
mean(ratio)

(house.plr &lt;- polr(Sat ~ Infl + Type + Cont,
                   data = housing, weights = Freq))

house.pr1 &lt;- predict(house.plr, expand.grid(hnames[-1]), type = "probs")
cbind(expand.grid(hnames[-1]), round(house.pr1, 2))

Fr &lt;- matrix(housing$Freq, ncol  =  3, byrow = TRUE)
2*sum(Fr*log(house.pr/house.pr1))

house.plr2 &lt;- stepAIC(house.plr, ~.^2)
house.plr2$anova
</code></pre>

<hr>
<h2 id='huber'>
Huber M-estimator of Location with MAD Scale
</h2><span id='topic+huber'></span>

<h3>Description</h3>

<p>Finds the Huber M-estimator of location with MAD scale.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>huber(y, k = 1.5, tol = 1e-06)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="huber_+3A_y">y</code></td>
<td>

<p>vector of data values
</p>
</td></tr>
<tr><td><code id="huber_+3A_k">k</code></td>
<td>

<p>Winsorizes at <code>k</code> standard deviations
</p>
</td></tr>
<tr><td><code id="huber_+3A_tol">tol</code></td>
<td>

<p>convergence tolerance
</p>
</td></tr></table>


<h3>Value</h3>

<p>list of location and scale parameters
</p>
<table>
<tr><td><code>mu</code></td>
<td>

<p>location estimate
</p>
</td></tr>
<tr><td><code>s</code></td>
<td>

<p>MAD scale estimate
</p>
</td></tr></table>


<h3>References</h3>

<p>Huber, P. J. (1981)
<em>Robust Statistics.</em>
Wiley.
</p>
<p>Venables, W. N. and Ripley, B. D. (2002)
<em>Modern Applied Statistics with S.</em> Fourth edition.  Springer.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+hubers">hubers</a></code>, <code><a href="stats.html#topic+mad">mad</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>huber(chem)
</code></pre>

<hr>
<h2 id='hubers'>
Huber Proposal 2 Robust Estimator of Location and/or Scale
</h2><span id='topic+hubers'></span>

<h3>Description</h3>

<p>Finds the Huber M-estimator for location with scale specified, scale
with location specified, or both if neither is specified.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hubers(y, k = 1.5, mu, s, initmu = median(y), tol = 1e-06)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="hubers_+3A_y">y</code></td>
<td>

<p>vector y of data values
</p>
</td></tr>
<tr><td><code id="hubers_+3A_k">k</code></td>
<td>

<p>Winsorizes at <code>k</code> standard deviations
</p>
</td></tr>
<tr><td><code id="hubers_+3A_mu">mu</code></td>
<td>

<p>specified location
</p>
</td></tr>
<tr><td><code id="hubers_+3A_s">s</code></td>
<td>

<p>specified scale
</p>
</td></tr>
<tr><td><code id="hubers_+3A_initmu">initmu</code></td>
<td>

<p>initial value of <code>mu</code>
</p>
</td></tr>
<tr><td><code id="hubers_+3A_tol">tol</code></td>
<td>

<p>convergence tolerance
</p>
</td></tr></table>


<h3>Value</h3>

<p>list of location and scale estimates
</p>
<table>
<tr><td><code>mu</code></td>
<td>

<p>location estimate
</p>
</td></tr>
<tr><td><code>s</code></td>
<td>

<p>scale estimate
</p>
</td></tr></table>


<h3>References</h3>

<p>Huber, P. J. (1981)
<em>Robust Statistics.</em>
Wiley.
</p>
<p>Venables, W. N. and Ripley, B. D. (2002)
<em>Modern Applied Statistics with S.</em> Fourth edition.  Springer.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+huber">huber</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>hubers(chem)
hubers(chem, mu=3.68)
</code></pre>

<hr>
<h2 id='immer'>
Yields from a Barley Field Trial
</h2><span id='topic+immer'></span>

<h3>Description</h3>

<p>The <code>immer</code> data frame has 30 rows and 4 columns.  Five varieties of
barley were grown in six locations in each of 1931 and 1932.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>immer
</code></pre>


<h3>Format</h3>

<p>This data frame contains the following columns:
</p>

<dl>
<dt><code>Loc</code></dt><dd>
<p>The location.
</p>
</dd>
<dt><code>Var</code></dt><dd>
<p>The variety of barley (<code>"manchuria"</code>, <code>"svansota"</code>,
<code>"velvet"</code>, <code>"trebi"</code> and <code>"peatland"</code>).
</p>
</dd>
<dt><code>Y1</code></dt><dd>
<p>Yield in 1931.
</p>
</dd>
<dt><code>Y2</code></dt><dd>
<p>Yield in 1932.
</p>
</dd>
</dl>



<h3>Source</h3>

<p>Immer, F.R., Hayes, H.D. and LeRoy Powers (1934)
Statistical determination of barley varietal adaptation.
<em>Journal of the American Society for Agronomy</em>
<b>26</b>, 403&ndash;419.
</p>
<p>Fisher, R.A. (1947)
<em>The Design of Experiments.</em> 4th edition. Edinburgh: Oliver and Boyd.
</p>


<h3>References</h3>

<p>Venables, W. N. and Ripley, B. D. (2002)
<em>Modern Applied Statistics with S-PLUS.</em> Fourth Edition. Springer.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>immer.aov &lt;- aov(cbind(Y1,Y2) ~ Loc + Var, data = immer)
summary(immer.aov)

immer.aov &lt;- aov((Y1+Y2)/2 ~ Var + Loc, data = immer)
summary(immer.aov)
model.tables(immer.aov, type = "means", se = TRUE, cterms = "Var")
</code></pre>

<hr>
<h2 id='Insurance'>
Numbers of Car Insurance claims
</h2><span id='topic+Insurance'></span>

<h3>Description</h3>

<p>The data given in data frame <code>Insurance</code> consist of the
numbers of policyholders of an insurance company who were
exposed to risk, and the numbers of car insurance claims made by
those policyholders in the third quarter of 1973.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Insurance
</code></pre>


<h3>Format</h3>

<p>This data frame contains the following columns:
</p>

<dl>
<dt><code>District</code></dt><dd>
<p>factor: district of residence of policyholder (1 to 4): 4 is major cities.
</p>
</dd>
<dt><code>Group</code></dt><dd>
<p>an ordered factor: group of car with levels  &lt;1 litre, 1&ndash;1.5 litre,
1.5&ndash;2 litre, &gt;2 litre.
</p>
</dd>
<dt><code>Age</code></dt><dd>
<p>an ordered factor: the age of the insured in 4 groups labelled
&lt;25, 25&ndash;29, 30&ndash;35, &gt;35.
</p>
</dd>
<dt><code>Holders</code></dt><dd>
<p>numbers of policyholders.
</p>
</dd>
<dt><code>Claims</code></dt><dd>
<p>numbers of claims
</p>
</dd>
</dl>



<h3>Source</h3>

<p>L. A. Baxter, S. M. Coutts and G. A. F. Ross (1980) Applications of
linear models in motor insurance.
<em>Proceedings of the 21st International Congress of Actuaries, Zurich</em>
pp. 11&ndash;29.
</p>
<p>M. Aitkin, D. Anderson, B. Francis and J. Hinde (1989)
<em>Statistical Modelling in GLIM.</em>
Oxford University Press.
</p>


<h3>References</h3>

<p>Venables, W. N. and Ripley, B. D. (2002)
<em>Modern Applied Statistics with S-PLUS.</em> Fourth Edition. Springer.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## main-effects fit as Poisson GLM with offset
glm(Claims ~ District + Group + Age + offset(log(Holders)),
    data = Insurance, family = poisson)

# same via loglm
loglm(Claims ~ District + Group + Age + offset(log(Holders)),
      data = Insurance)
</code></pre>

<hr>
<h2 id='isoMDS'>
Kruskal's Non-metric Multidimensional Scaling
</h2><span id='topic+isoMDS'></span><span id='topic+Shepard'></span>

<h3>Description</h3>

<p>One form of non-metric multidimensional scaling
</p>


<h3>Usage</h3>

<pre><code class='language-R'>isoMDS(d, y = cmdscale(d, k), k = 2, maxit = 50, trace = TRUE,
       tol = 1e-3, p = 2)

Shepard(d, x, p = 2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="isoMDS_+3A_d">d</code></td>
<td>

<p>distance structure of the form returned by <code>dist</code>, or a full,
symmetric matrix.  Data are assumed to be dissimilarities or relative
distances, but must be positive except for self-distance.  Both
missing and infinite values are allowed.
</p>
</td></tr>
<tr><td><code id="isoMDS_+3A_y">y</code></td>
<td>

<p>An initial configuration. If none is supplied, <code>cmdscale</code> is used
to provide the classical solution, unless there are missing or
infinite dissimilarities.
</p>
</td></tr>
<tr><td><code id="isoMDS_+3A_k">k</code></td>
<td>

<p>The desired dimension for the solution, passed to <code>cmdscale</code>.
</p>
</td></tr>
<tr><td><code id="isoMDS_+3A_maxit">maxit</code></td>
<td>

<p>The maximum number of iterations.
</p>
</td></tr>
<tr><td><code id="isoMDS_+3A_trace">trace</code></td>
<td>

<p>Logical for tracing optimization. Default <code>TRUE</code>.
</p>
</td></tr>
<tr><td><code id="isoMDS_+3A_tol">tol</code></td>
<td>

<p>convergence tolerance.
</p>
</td></tr>
<tr><td><code id="isoMDS_+3A_p">p</code></td>
<td>
<p>Power for Minkowski distance in the configuration space.</p>
</td></tr>
<tr><td><code id="isoMDS_+3A_x">x</code></td>
<td>
<p>A final configuration.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This chooses a k-dimensional (default k = 2) configuration to minimize
the stress, the square root of the ratio of the sum of squared
differences between the input distances and those of the configuration
to the sum of configuration distances squared.  However, the input
distances are allowed a monotonic transformation.
</p>
<p>An iterative algorithm is used, which will usually converge in around
10 iterations.  As this is necessarily an <code class="reqn">O(n^2)</code> calculation,
it is slow for large datasets.  Further, since for the default <code class="reqn">p = 2</code>
the configuration is only determined up to rotations and reflections
(by convention the centroid is at the origin), the result can vary
considerably from machine to machine.
</p>


<h3>Value</h3>

<p>Two components:
</p>
<table>
<tr><td><code>points</code></td>
<td>

<p>A k-column vector of the fitted configuration.
</p>
</td></tr>
<tr><td><code>stress</code></td>
<td>

<p>The final stress achieved (in percent).
</p>
</td></tr></table>


<h3>Side Effects</h3>

<p>If <code>trace</code> is true, the initial stress and the current stress
are printed out every 5 iterations.
</p>


<h3>References</h3>

<p>T. F. Cox and M. A. A. Cox (1994, 2001)
<em>Multidimensional Scaling</em>. Chapman &amp; Hall.
</p>
<p>Ripley, B. D. (1996)
<em>Pattern Recognition and Neural Networks</em>. Cambridge University Press.
</p>
<p>Venables, W. N. and Ripley, B. D. (2002)
<em>Modern Applied Statistics with S.</em> Fourth edition.  Springer.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+cmdscale">cmdscale</a></code>, <code><a href="#topic+sammon">sammon</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>swiss.x &lt;- as.matrix(swiss[, -1])
swiss.dist &lt;- dist(swiss.x)
swiss.mds &lt;- isoMDS(swiss.dist)
plot(swiss.mds$points, type = "n")
text(swiss.mds$points, labels = as.character(1:nrow(swiss.x)))
swiss.sh &lt;- Shepard(swiss.dist, swiss.mds$points)
plot(swiss.sh, pch = ".")
lines(swiss.sh$x, swiss.sh$yf, type = "S")
</code></pre>

<hr>
<h2 id='kde2d'>
Two-Dimensional Kernel Density Estimation
</h2><span id='topic+kde2d'></span>

<h3>Description</h3>

<p>Two-dimensional kernel density estimation with an axis-aligned
bivariate normal kernel, evaluated on a square grid.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>kde2d(x, y, h, n = 25, lims = c(range(x), range(y)))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="kde2d_+3A_x">x</code></td>
<td>

<p>x coordinate of data
</p>
</td></tr>
<tr><td><code id="kde2d_+3A_y">y</code></td>
<td>

<p>y coordinate of data
</p>
</td></tr>
<tr><td><code id="kde2d_+3A_h">h</code></td>
<td>

<p>vector of bandwidths for x and y directions.  Defaults to
normal reference bandwidth (see <code><a href="#topic+bandwidth.nrd">bandwidth.nrd</a></code>). A scalar
value will be taken to apply to both directions.
</p>
</td></tr>
<tr><td><code id="kde2d_+3A_n">n</code></td>
<td>

<p>Number of grid points in each direction.  Can be scalar or a length-2
integer vector.
</p>
</td></tr>
<tr><td><code id="kde2d_+3A_lims">lims</code></td>
<td>

<p>The limits of the rectangle covered by the grid as <code>c(xl, xu, yl, yu)</code>.
</p>
</td></tr></table>


<h3>Value</h3>

<p>A list of three components.
</p>
<table>
<tr><td><code>x</code>, <code>y</code></td>
<td>

<p>The x and y coordinates of the grid points, vectors of length <code>n</code>.
</p>
</td></tr>
<tr><td><code>z</code></td>
<td>

<p>An <code>n[1]</code> by <code>n[2]</code> matrix of the estimated density: rows
correspond to the value of <code>x</code>, columns to the value of <code>y</code>. 
</p>
</td></tr></table>


<h3>References</h3>

<p>Venables, W. N. and Ripley, B. D. (2002)
<em>Modern Applied Statistics with S.</em> Fourth edition.  Springer.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>attach(geyser)
plot(duration, waiting, xlim = c(0.5,6), ylim = c(40,100))
f1 &lt;- kde2d(duration, waiting, n = 50, lims = c(0.5, 6, 40, 100))
image(f1, zlim = c(0, 0.05))
f2 &lt;- kde2d(duration, waiting, n = 50, lims = c(0.5, 6, 40, 100),
            h = c(width.SJ(duration), width.SJ(waiting)) )
image(f2, zlim = c(0, 0.05))
persp(f2, phi = 30, theta = 20, d = 5)

plot(duration[-272], duration[-1], xlim = c(0.5, 6),
     ylim = c(1, 6),xlab = "previous duration", ylab = "duration")
f1 &lt;- kde2d(duration[-272], duration[-1],
            h = rep(1.5, 2), n = 50, lims = c(0.5, 6, 0.5, 6))
contour(f1, xlab = "previous duration",
        ylab = "duration", levels  =  c(0.05, 0.1, 0.2, 0.4) )
f1 &lt;- kde2d(duration[-272], duration[-1],
            h = rep(0.6, 2), n = 50, lims = c(0.5, 6, 0.5, 6))
contour(f1, xlab = "previous duration",
        ylab = "duration", levels  =  c(0.05, 0.1, 0.2, 0.4) )
f1 &lt;- kde2d(duration[-272], duration[-1],
            h = rep(0.4, 2), n = 50, lims = c(0.5, 6, 0.5, 6))
contour(f1, xlab = "previous duration",
        ylab = "duration", levels  =  c(0.05, 0.1, 0.2, 0.4) )
detach("geyser")
</code></pre>

<hr>
<h2 id='lda'>
Linear Discriminant Analysis
</h2><span id='topic+lda'></span><span id='topic+lda.default'></span><span id='topic+lda.data.frame'></span><span id='topic+lda.formula'></span><span id='topic+lda.matrix'></span><span id='topic+model.frame.lda'></span><span id='topic+print.lda'></span><span id='topic+coef.lda'></span>

<h3>Description</h3>

<p>Linear discriminant analysis.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lda(x, ...)

## S3 method for class 'formula'
lda(formula, data, ..., subset, na.action)

## Default S3 method:
lda(x, grouping, prior = proportions, tol = 1.0e-4,
    method, CV = FALSE, nu, ...)

## S3 method for class 'data.frame'
lda(x, ...)

## S3 method for class 'matrix'
lda(x, grouping, ..., subset, na.action)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lda_+3A_formula">formula</code></td>
<td>

<p>A formula of the form <code>groups ~ x1 + x2 + ...</code>  That is, the
response is the grouping factor and the right hand side specifies
the (non-factor) discriminators.
</p>
</td></tr>
<tr><td><code id="lda_+3A_data">data</code></td>
<td>

<p>An optional data frame, list or environment from which variables
specified in <code>formula</code> are preferentially to be taken.
</p>
</td></tr>
<tr><td><code id="lda_+3A_x">x</code></td>
<td>

<p>(required if no formula is given as the principal argument.)
a matrix or data frame or Matrix containing the explanatory variables.
</p>
</td></tr>
<tr><td><code id="lda_+3A_grouping">grouping</code></td>
<td>

<p>(required if no formula principal argument is given.)
a factor specifying the class for each observation.
</p>
</td></tr>
<tr><td><code id="lda_+3A_prior">prior</code></td>
<td>

<p>the prior probabilities of class membership.  If unspecified, the
class proportions for the training set are used.  If present, the
probabilities should be specified in the order of the factor
levels.
</p>
</td></tr>
<tr><td><code id="lda_+3A_tol">tol</code></td>
<td>

<p>A tolerance to decide if a matrix is singular; it will reject variables
and linear combinations of unit-variance variables whose variance is
less than <code>tol^2</code>.
</p>
</td></tr>
<tr><td><code id="lda_+3A_subset">subset</code></td>
<td>

<p>An index vector specifying the cases to be used in the training
sample.  (NOTE: If given, this argument must be named.)
</p>
</td></tr>
<tr><td><code id="lda_+3A_na.action">na.action</code></td>
<td>

<p>A function to specify the action to be taken if <code>NA</code>s are found.
The default action is for the procedure to fail.  An alternative is
<code>na.omit</code>, which leads to rejection of cases with missing values on
any required variable.  (NOTE: If given, this argument must be named.)
</p>
</td></tr>
<tr><td><code id="lda_+3A_method">method</code></td>
<td>

<p><code>"moment"</code> for standard estimators of the mean and variance,
<code>"mle"</code> for MLEs, <code>"mve"</code> to use <code><a href="#topic+cov.mve">cov.mve</a></code>, or
<code>"t"</code> for robust estimates based on a <code class="reqn">t</code> distribution.
</p>
</td></tr>
<tr><td><code id="lda_+3A_cv">CV</code></td>
<td>

<p>If true, returns results (classes and posterior probabilities) for
leave-one-out cross-validation. Note that if the prior is estimated,
the proportions in the whole dataset are used.
</p>
</td></tr>
<tr><td><code id="lda_+3A_nu">nu</code></td>
<td>

<p>degrees of freedom for <code>method = "t"</code>.
</p>
</td></tr>
<tr><td><code id="lda_+3A_...">...</code></td>
<td>

<p>arguments passed to or from other methods.
</p>
</td></tr></table>


<h3>Details</h3>

<p>The function
tries hard to detect if the within-class covariance matrix is
singular. If any variable has within-group variance less than
<code>tol^2</code> it will stop and report the variable as constant.  This
could result from poor scaling of the problem, but is more
likely to result from constant variables.
</p>
<p>Specifying the <code>prior</code> will affect the classification unless
over-ridden in <code>predict.lda</code>.  Unlike in most statistical packages, it
will also affect the rotation of the linear discriminants within their
space, as a weighted between-groups covariance matrix is used. Thus
the first few linear discriminants emphasize the differences between
groups with the weights given by the prior, which may differ from
their prevalence in the dataset.
</p>
<p>If one or more groups is missing in the supplied data, they are dropped
with a warning, but the classifications produced are with respect to the
original set of levels.
</p>


<h3>Value</h3>

<p>If <code>CV = TRUE</code> the return value is a list with components
<code>class</code>, the MAP classification (a factor), and <code>posterior</code>,
posterior probabilities for the classes.
</p>
<p>Otherwise it is an object of class <code>"lda"</code> containing the
following components:
</p>
<table>
<tr><td><code>prior</code></td>
<td>

<p>the prior probabilities used.
</p>
</td></tr>
<tr><td><code>means</code></td>
<td>

<p>the group means.
</p>
</td></tr>
<tr><td><code>scaling</code></td>
<td>

<p>a matrix which transforms observations to discriminant functions,
normalized so that within groups covariance matrix is spherical.
</p>
</td></tr>
<tr><td><code>svd</code></td>
<td>

<p>the singular values, which give the ratio of the between- and
within-group standard deviations on the linear discriminant
variables.  Their squares are the canonical F-statistics.
</p>
</td></tr>
<tr><td><code>N</code></td>
<td>

<p>The number of observations used.
</p>
</td></tr>
<tr><td><code>call</code></td>
<td>

<p>The (matched) function call.
</p>
</td></tr>
</table>


<h3>Note</h3>

<p>This function may be called giving either a formula and
optional data frame, or a matrix and grouping factor as the first
two arguments.  All other arguments are optional, but <code>subset=</code> and
<code>na.action=</code>, if required, must be fully named.
</p>
<p>If a formula is given as the principal argument the object may be
modified using <code>update()</code> in the usual way.
</p>


<h3>References</h3>

<p>Venables, W. N. and Ripley, B. D. (2002)
<em>Modern Applied Statistics with S.</em> Fourth edition.  Springer.
</p>
<p>Ripley, B. D. (1996)
<em>Pattern Recognition and Neural Networks</em>. Cambridge University Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+predict.lda">predict.lda</a></code>, <code><a href="#topic+qda">qda</a></code>, <code><a href="#topic+predict.qda">predict.qda</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>Iris &lt;- data.frame(rbind(iris3[,,1], iris3[,,2], iris3[,,3]),
                   Sp = rep(c("s","c","v"), rep(50,3)))
train &lt;- sample(1:150, 75)
table(Iris$Sp[train])
## your answer may differ
##  c  s  v
## 22 23 30
z &lt;- lda(Sp ~ ., Iris, prior = c(1,1,1)/3, subset = train)
predict(z, Iris[-train, ])$class
##  [1] s s s s s s s s s s s s s s s s s s s s s s s s s s s c c c
## [31] c c c c c c c v c c c c v c c c c c c c c c c c c v v v v v
## [61] v v v v v v v v v v v v v v v
(z1 &lt;- update(z, . ~ . - Petal.W.))
</code></pre>

<hr>
<h2 id='ldahist'>
Histograms or Density Plots of Multiple Groups
</h2><span id='topic+ldahist'></span>

<h3>Description</h3>

<p>Plot histograms or density plots of data on a single Fisher linear
discriminant.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ldahist(data, g, nbins = 25, h, x0 = - h/1000, breaks,
        xlim = range(breaks), ymax = 0, width,
        type = c("histogram", "density", "both"),
        sep = (type != "density"),
        col = 5, xlab = deparse(substitute(data)), bty = "n", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ldahist_+3A_data">data</code></td>
<td>

<p>vector of data. Missing values (<code>NA</code>s) are allowed and omitted.
</p>
</td></tr>
<tr><td><code id="ldahist_+3A_g">g</code></td>
<td>

<p>factor or vector giving groups, of the same length as <code>data</code>.
</p>
</td></tr>
<tr><td><code id="ldahist_+3A_nbins">nbins</code></td>
<td>

<p>Suggested number of bins to cover the whole range of the data.
</p>
</td></tr>
<tr><td><code id="ldahist_+3A_h">h</code></td>
<td>

<p>The bin width (takes precedence over <code>nbins</code>).
</p>
</td></tr>
<tr><td><code id="ldahist_+3A_x0">x0</code></td>
<td>

<p>Shift for the bins - the breaks are at <code>x0 + h * (..., -1, 0, 1, ...)</code>
</p>
</td></tr>
<tr><td><code id="ldahist_+3A_breaks">breaks</code></td>
<td>

<p>The set of breakpoints to be used. (Usually omitted, takes precedence
over <code>h</code> and <code>nbins</code>).
</p>
</td></tr>
<tr><td><code id="ldahist_+3A_xlim">xlim</code></td>
<td>

<p>The limits for the x-axis.
</p>
</td></tr>
<tr><td><code id="ldahist_+3A_ymax">ymax</code></td>
<td>

<p>The upper limit for the y-axis.
</p>
</td></tr>
<tr><td><code id="ldahist_+3A_width">width</code></td>
<td>

<p>Bandwidth for density estimates. If missing, the Sheather-Jones
selector is used for each group separately.
</p>
</td></tr>
<tr><td><code id="ldahist_+3A_type">type</code></td>
<td>

<p>Type of plot.
</p>
</td></tr>
<tr><td><code id="ldahist_+3A_sep">sep</code></td>
<td>

<p>Whether there is a separate plot for each group, or one combined plot.
</p>
</td></tr>
<tr><td><code id="ldahist_+3A_col">col</code></td>
<td>

<p>The colour number for the bar fill.
</p>
</td></tr>
<tr><td><code id="ldahist_+3A_xlab">xlab</code></td>
<td>

<p>label for the plot x-axis. By default, this will be the name of <code>data</code>.
</p>
</td></tr>
<tr><td><code id="ldahist_+3A_bty">bty</code></td>
<td>

<p>The box type for the plot - defaults to none.
</p>
</td></tr>
<tr><td><code id="ldahist_+3A_...">...</code></td>
<td>

<p>additional arguments to <code>polygon</code>.
</p>
</td></tr></table>


<h3>Side Effects</h3>

<p>Histogram and/or density plots are plotted on the current device.
</p>


<h3>References</h3>

<p>Venables, W. N. and Ripley, B. D. (2002)
<em>Modern Applied Statistics with S.</em> Fourth edition.  Springer.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+plot.lda">plot.lda</a></code>.
</p>

<hr>
<h2 id='leuk'>
Survival Times and White Blood Counts for Leukaemia Patients
</h2><span id='topic+leuk'></span>

<h3>Description</h3>

<p>A data frame of data from 33 leukaemia patients.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>leuk
</code></pre>


<h3>Format</h3>

<p>A data frame with columns:
</p>

<dl>
<dt><code>wbc</code></dt><dd>
<p>white blood count.
</p>
</dd>
<dt><code>ag</code></dt><dd>
<p>a test result, <code>"present"</code> or <code>"absent"</code>.
</p>
</dd>
<dt><code>time</code></dt><dd>
<p>survival time in weeks.
</p>
</dd>
</dl>



<h3>Details</h3>

<p>Survival times are given for 33 patients who died from acute
myelogenous leukaemia.  Also measured was the patient's white blood cell
count at the time of diagnosis.  The patients were also factored into 2
groups according to the presence or absence of a morphologic
characteristic of white blood cells. Patients termed AG positive were
identified by the presence of Auer rods and/or significant granulation
of the leukaemic cells in the bone marrow at the time of diagnosis.
</p>


<h3>Source</h3>

<p>Cox, D. R. and Oakes, D. (1984) <em>Analysis of Survival Data</em>.
Chapman &amp; Hall, p. 9.
</p>
<p>Taken from
</p>
<p>Feigl, P. &amp; Zelen, M. (1965) Estimation of exponential survival
probabilities with concomitant information.
<em>Biometrics</em> <b>21</b>, 826&ndash;838.
</p>


<h3>References</h3>

<p>Venables, W. N. and Ripley, B. D. (2002)
<em>Modern Applied Statistics with S.</em> Fourth edition.  Springer.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(survival)
plot(survfit(Surv(time) ~ ag, data = leuk), lty = 2:3, col = 2:3)

# now Cox models
leuk.cox &lt;- coxph(Surv(time) ~ ag + log(wbc), leuk)
summary(leuk.cox)
</code></pre>

<hr>
<h2 id='lm.gls'>
Fit Linear Models by Generalized Least Squares
</h2><span id='topic+lm.gls'></span>

<h3>Description</h3>

<p>Fit linear models by Generalized Least Squares
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lm.gls(formula, data, W, subset, na.action, inverse = FALSE,
       method = "qr", model = FALSE, x = FALSE, y = FALSE,
       contrasts = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lm.gls_+3A_formula">formula</code></td>
<td>

<p>a formula expression as for regression models, of the form
<code>response ~ predictors</code>.
See the documentation of <code>formula</code> for other details.
</p>
</td></tr>
<tr><td><code id="lm.gls_+3A_data">data</code></td>
<td>

<p>an optional data frame, list or environment in which to interpret the
variables occurring in <code>formula</code>.
</p>
</td></tr>
<tr><td><code id="lm.gls_+3A_w">W</code></td>
<td>

<p>a weight matrix.
</p>
</td></tr>
<tr><td><code id="lm.gls_+3A_subset">subset</code></td>
<td>

<p>expression saying which subset of the rows of the data should  be used
in the fit. All observations are included by default.
</p>
</td></tr>
<tr><td><code id="lm.gls_+3A_na.action">na.action</code></td>
<td>

<p>a function to filter missing data.
</p>
</td></tr>
<tr><td><code id="lm.gls_+3A_inverse">inverse</code></td>
<td>

<p>logical: if true <code>W</code> specifies the inverse of the weight matrix: this
is appropriate if a variance matrix is used.
</p>
</td></tr>
<tr><td><code id="lm.gls_+3A_method">method</code></td>
<td>

<p>method to be used by <code>lm.fit</code>.
</p>
</td></tr>
<tr><td><code id="lm.gls_+3A_model">model</code></td>
<td>

<p>should the model frame be returned?
</p>
</td></tr>
<tr><td><code id="lm.gls_+3A_x">x</code></td>
<td>

<p>should the design matrix be returned?
</p>
</td></tr>
<tr><td><code id="lm.gls_+3A_y">y</code></td>
<td>

<p>should the response be returned?
</p>
</td></tr>
<tr><td><code id="lm.gls_+3A_contrasts">contrasts</code></td>
<td>

<p>a list of contrasts to be used for some or all of
</p>
</td></tr>
<tr><td><code id="lm.gls_+3A_...">...</code></td>
<td>

<p>additional arguments to <code><a href="stats.html#topic+lm.fit">lm.fit</a></code>.
</p>
</td></tr></table>


<h3>Details</h3>

<p>The problem is transformed to uncorrelated form and passed to
<code><a href="stats.html#topic+lm.fit">lm.fit</a></code>.
</p>


<h3>Value</h3>

<p>An object of class <code>"lm.gls"</code>, which is similar to an <code>"lm"</code>
object.  There is no <code>"weights"</code> component, and only a few <code>"lm"</code>
methods will work correctly.  As from version 7.1-22 the residuals and
fitted values refer to the untransformed problem.
</p>


<h3>See Also</h3>

<p><code><a href="nlme.html#topic+gls">gls</a></code>, <code><a href="stats.html#topic+lm">lm</a></code>, <code><a href="#topic+lm.ridge">lm.ridge</a></code>
</p>

<hr>
<h2 id='lm.ridge'>
Ridge Regression
</h2><span id='topic+lm.ridge'></span><span id='topic+plot.ridgelm'></span><span id='topic+print.ridgelm'></span><span id='topic+select'></span><span id='topic+select.ridgelm'></span>

<h3>Description</h3>

<p>Fit a linear model by ridge regression.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lm.ridge(formula, data, subset, na.action, lambda = 0, model = FALSE,
         x = FALSE, y = FALSE, contrasts = NULL, ...)
select(obj)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lm.ridge_+3A_formula">formula</code></td>
<td>

<p>a formula expression as for regression models, of the form
<code>response ~ predictors</code>. See the documentation of <code>formula</code>
for other details. <code><a href="stats.html#topic+offset">offset</a></code> terms are allowed.
</p>
</td></tr>
<tr><td><code id="lm.ridge_+3A_data">data</code></td>
<td>

<p>an optional data frame, list or environment in which to interpret the
variables occurring in <code>formula</code>.
</p>
</td></tr>
<tr><td><code id="lm.ridge_+3A_subset">subset</code></td>
<td>

<p>expression saying which subset of the rows of the data should  be used
in the fit.  All observations are included by default.
</p>
</td></tr>
<tr><td><code id="lm.ridge_+3A_na.action">na.action</code></td>
<td>

<p>a function to filter missing data.
</p>
</td></tr>
<tr><td><code id="lm.ridge_+3A_lambda">lambda</code></td>
<td>

<p>A scalar or vector of ridge constants.
</p>
</td></tr>
<tr><td><code id="lm.ridge_+3A_model">model</code></td>
<td>

<p>should the model frame be returned?  Not implemented.
</p>
</td></tr>
<tr><td><code id="lm.ridge_+3A_x">x</code></td>
<td>

<p>should the design matrix be returned?  Not implemented.
</p>
</td></tr>
<tr><td><code id="lm.ridge_+3A_y">y</code></td>
<td>

<p>should the response be returned?  Not implemented.
</p>
</td></tr>
<tr><td><code id="lm.ridge_+3A_contrasts">contrasts</code></td>
<td>

<p>a list of contrasts to be used for some or all of factor terms in the
formula. See the <code>contrasts.arg</code> of <code><a href="stats.html#topic+model.matrix.default">model.matrix.default</a></code>.
</p>
</td></tr>
<tr><td><code id="lm.ridge_+3A_...">...</code></td>
<td>

<p>additional arguments to <code><a href="stats.html#topic+lm.fit">lm.fit</a></code>.
</p>
</td></tr>
<tr><td><code id="lm.ridge_+3A_obj">obj</code></td>
<td>

<p>an <span class="rlang"><b>R</b></span> object, such as an <code>"lm.ridge"</code> fit.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If an intercept is present in the model, its coefficient is not
penalized.  (If you want to penalize an intercept, put in your own
constant term and remove the intercept.)
</p>


<h3>Value</h3>

<p>A list with components
</p>
<table>
<tr><td><code>coef</code></td>
<td>

<p>matrix of coefficients, one row for each value of <code>lambda</code>.
Note that these are not on the original scale and are for use by the
<code><a href="stats.html#topic+coef">coef</a></code> method.
</p>
</td></tr>
<tr><td><code>scales</code></td>
<td>

<p>scalings used on the X matrix.
</p>
</td></tr>
<tr><td><code>Inter</code></td>
<td>

<p>was intercept included?
</p>
</td></tr>
<tr><td><code>lambda</code></td>
<td>

<p>vector of lambda values
</p>
</td></tr>
<tr><td><code>ym</code></td>
<td>

<p>mean of <code>y</code>
</p>
</td></tr>
<tr><td><code>xm</code></td>
<td>

<p>column means of <code>x</code> matrix
</p>
</td></tr>
<tr><td><code>GCV</code></td>
<td>

<p>vector of GCV values
</p>
</td></tr>
<tr><td><code>kHKB</code></td>
<td>

<p>HKB estimate of the ridge constant.
</p>
</td></tr>
<tr><td><code>kLW</code></td>
<td>

<p>L-W estimate of the ridge constant.
</p>
</td></tr></table>


<h3>References</h3>

<p>Brown, P. J. (1994)
<em>Measurement, Regression and Calibration</em>
Oxford.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+lm">lm</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>longley # not the same as the S-PLUS dataset
names(longley)[1] &lt;- "y"
lm.ridge(y ~ ., longley)
plot(lm.ridge(y ~ ., longley,
              lambda = seq(0,0.1,0.001)))
select(lm.ridge(y ~ ., longley,
               lambda = seq(0,0.1,0.0001)))
</code></pre>

<hr>
<h2 id='loglm'>
Fit Log-Linear Models by Iterative Proportional Scaling
</h2><span id='topic+loglm'></span>

<h3>Description</h3>

<p>This function provides a front-end to the standard function,
<code>loglin</code>, to allow log-linear models to be specified and fitted
in a manner similar to that of other fitting functions, such as
<code>glm</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>loglm(formula, data, subset, na.action, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="loglm_+3A_formula">formula</code></td>
<td>

<p>A linear model formula specifying the log-linear model.
</p>
<p>If the left-hand side is empty, the <code>data</code> argument is required
and must be a (complete) array of frequencies.  In this case the
variables on the right-hand side may be the names of the
<code>dimnames</code> attribute of the frequency array, or may be the
positive integers: 1, 2, 3, ... used as alternative names for the
1st, 2nd, 3rd, ... dimension (classifying factor).
If the left-hand side is not empty it specifies a vector of
frequencies.  In this case the data argument, if present, must be
a data frame from which the left-hand side vector and the
classifying factors on the right-hand side are (preferentially)
obtained.  The usual abbreviation of a <code>.</code> to stand for &lsquo;all
other variables in the data frame&rsquo; is allowed.  Any non-factors
on the right-hand side of the formula are coerced to factor.
</p>
</td></tr>
<tr><td><code id="loglm_+3A_data">data</code></td>
<td>

<p>Numeric array or data frame (or list or environment).
In the first case it specifies the
array of frequencies; in the second it provides the data frame
from which the variables occurring in the formula are
preferentially obtained in the usual way.
</p>
<p>This argument may be the result of a call to <code><a href="stats.html#topic+xtabs">xtabs</a></code>.
</p>
</td></tr>
<tr><td><code id="loglm_+3A_subset">subset</code></td>
<td>

<p>Specifies a subset of the rows in the data frame to be used.  The
default is to take all rows.
</p>
</td></tr>
<tr><td><code id="loglm_+3A_na.action">na.action</code></td>
<td>

<p>Specifies a method for handling missing observations.  The
default is to fail if missing values are present.
</p>
</td></tr>
<tr><td><code id="loglm_+3A_...">...</code></td>
<td>

<p>May supply other arguments to the function <code><a href="#topic+loglm1">loglm1</a></code>.
</p>
</td></tr></table>


<h3>Details</h3>

<p>If the left-hand side of the formula is empty the <code>data</code> argument
supplies the frequency array and the right-hand side of the
formula is used to construct the list of fixed faces as required
by <code>loglin</code>.  Structural zeros may be specified by giving a
<code>start</code> argument with those entries set to zero, as described in
the help information for <code>loglin</code>.
</p>
<p>If the left-hand side is not empty, all variables on the
right-hand side are regarded as classifying factors and an array
of frequencies is constructed.  If some cells in the complete
array are not specified they are treated as structural zeros.
The right-hand side of the formula is again used to construct the
list of faces on which the observed and fitted totals must agree,
as required by <code>loglin</code>.  Hence terms such as
<code>a:b</code>, <code>a*b</code> and <code>a/b</code> are all equivalent.
</p>


<h3>Value</h3>

<p>An object of class <code>"loglm"</code> conveying the results of the fitted
log-linear model.  Methods exist for the generic functions <code>print</code>,
<code>summary</code>, <code>deviance</code>, <code>fitted</code>, <code>coef</code>,
<code>resid</code>, <code>anova</code> and <code>update</code>, which perform the expected
tasks.  Only log-likelihood ratio tests are allowed using <code>anova</code>.
</p>
<p>The deviance is simply an alternative name for the log-likelihood
ratio statistic for testing the current model within a saturated
model, in accordance with standard usage in generalized linear
models.
</p>


<h3>Warning</h3>

<p>If structural zeros are present, the calculation of degrees of
freedom may not be correct.  <code>loglin</code> itself takes no action to
allow for structural zeros.  <code>loglm</code> deducts one degree of
freedom for each structural zero, but cannot make allowance for
gains in error degrees of freedom due to loss of dimension in the
model space.  (This would require checking the rank of the
model matrix, but since iterative proportional scaling methods
are developed largely to avoid constructing the model matrix
explicitly, the computation is at least difficult.)
</p>
<p>When structural zeros (or zero fitted values) are present the
estimated coefficients will not be available due to infinite
estimates.  The deviances will normally continue to be correct, though.
</p>


<h3>References</h3>

<p>Venables, W. N. and Ripley, B. D. (2002)
<em>Modern Applied Statistics with S.</em> Fourth edition.  Springer.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+loglm1">loglm1</a></code>, <code><a href="stats.html#topic+loglin">loglin</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># The data frames  Cars93, minn38 and quine are available
# in the MASS package.

# Case 1: frequencies specified as an array.
sapply(minn38, function(x) length(levels(x)))
## hs phs fol sex f
##  3   4   7   2 0
##minn38a &lt;- array(0, c(3,4,7,2), lapply(minn38[, -5], levels))
##minn38a[data.matrix(minn38[,-5])] &lt;- minn38$f

## or more simply
minn38a &lt;- xtabs(f ~ ., minn38)

fm &lt;- loglm(~ 1 + 2 + 3 + 4, minn38a)  # numerals as names.
deviance(fm)
## [1] 3711.9
fm1 &lt;- update(fm, .~.^2)
fm2 &lt;- update(fm, .~.^3, print = TRUE)
## 5 iterations: deviation 0.075
anova(fm, fm1, fm2)

# Case 1. An array generated with xtabs.

loglm(~ Type + Origin, xtabs(~ Type + Origin, Cars93))

# Case 2.  Frequencies given as a vector in a data frame
names(quine)
## [1] "Eth"  "Sex"  "Age"  "Lrn"  "Days"
fm &lt;- loglm(Days ~ .^2, quine)
gm &lt;- glm(Days ~ .^2, poisson, quine)  # check glm.
c(deviance(fm), deviance(gm))          # deviances agree
## [1] 1368.7 1368.7
c(fm$df, gm$df)                        # resid df do not!
c(fm$df, gm$df.residual)               # resid df do not!
## [1] 127 128
# The loglm residual degrees of freedom is wrong because of
# a non-detectable redundancy in the model matrix.
</code></pre>

<hr>
<h2 id='loglm1'>
Fit Log-Linear Models by Iterative Proportional Scaling &ndash; Internal function
</h2><span id='topic+loglm1'></span><span id='topic+loglm1.xtabs'></span><span id='topic+loglm1.data.frame'></span><span id='topic+loglm1.default'></span>

<h3>Description</h3>

<p><code>loglm1</code> is an internal function used by <code><a href="#topic+loglm">loglm</a></code>.
It is a generic function dispatching on the <code>data</code> argument.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>loglm1(formula, data, ...)

## S3 method for class 'xtabs'
loglm1(formula, data, ...)

## S3 method for class 'data.frame'
loglm1(formula, data, ...)

## Default S3 method:
loglm1(formula, data, start = rep(1, length(data)), fitted = FALSE,
       keep.frequencies = fitted, param = TRUE, eps = 1/10,
       iter = 40, print = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="loglm1_+3A_formula">formula</code></td>
<td>

<p>A linear model formula specifying the log-linear model.
See <code><a href="#topic+loglm">loglm</a></code> for its interpretation.</p>
</td></tr>
<tr><td><code id="loglm1_+3A_data">data</code></td>
<td>

<p>Numeric array or data frame (or list or environment).
In the first case it specifies the
array of frequencies; in then second it provides the data frame
from which the variables occurring in the formula are
preferentially obtained in the usual way.
</p>
<p>This argument may also be the result of a call to <code><a href="stats.html#topic+xtabs">xtabs</a></code>.
</p>
</td></tr>
<tr><td><code id="loglm1_+3A_start">start</code>, <code id="loglm1_+3A_param">param</code>, <code id="loglm1_+3A_eps">eps</code>, <code id="loglm1_+3A_iter">iter</code>, <code id="loglm1_+3A_print">print</code></td>
<td>
<p>Arguments passed to
<code><a href="stats.html#topic+loglin">loglin</a></code>.</p>
</td></tr>
<tr><td><code id="loglm1_+3A_fitted">fitted</code></td>
<td>
<p>logical: should the fitted values be returned?</p>
</td></tr>
<tr><td><code id="loglm1_+3A_keep.frequencies">keep.frequencies</code></td>
<td>

<p>If <code>TRUE</code> specifies that the (possibly constructed) array of
frequencies is to be retained as part of the fitted model object.  The
default action is to use the same value as that used for <code>fitted</code>.
</p>
</td></tr>
<tr><td><code id="loglm1_+3A_...">...</code></td>
<td>
<p>arguments passed to the default method.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code>"loglm"</code>. 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+loglm">loglm</a></code>, <code><a href="stats.html#topic+loglin">loglin</a></code>
</p>

<hr>
<h2 id='logtrans'>
Estimate log Transformation Parameter
</h2><span id='topic+logtrans'></span><span id='topic+logtrans.formula'></span><span id='topic+logtrans.lm'></span><span id='topic+logtrans.default'></span>

<h3>Description</h3>

<p>Find and optionally plot the marginal (profile) likelihood for alpha
for a transformation model of the form <code>log(y + alpha) ~ x1 + x2 + ...</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>logtrans(object, ...)

## Default S3 method:
logtrans(object, ..., alpha = seq(0.5, 6, by = 0.25) - min(y),
         plotit = TRUE, interp =, xlab = "alpha",
         ylab = "log Likelihood")

## S3 method for class 'formula'
logtrans(object, data, ...)

## S3 method for class 'lm'
logtrans(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="logtrans_+3A_object">object</code></td>
<td>

<p>Fitted linear model object, or formula defining the untransformed
model that is <code>y ~ x1 + x2 + ...</code>.  The function is generic.
</p>
</td></tr>
<tr><td><code id="logtrans_+3A_...">...</code></td>
<td>

<p>If <code>object</code> is a formula, this argument may specify a data frame
as for <code>lm</code>.
</p>
</td></tr>
<tr><td><code id="logtrans_+3A_alpha">alpha</code></td>
<td>

<p>Set of values for the transformation parameter, alpha.
</p>
</td></tr>
<tr><td><code id="logtrans_+3A_plotit">plotit</code></td>
<td>

<p>Should plotting be done?
</p>
</td></tr>
<tr><td><code id="logtrans_+3A_interp">interp</code></td>
<td>

<p>Should the marginal log-likelihood be interpolated with a spline
approximation?   (Default is <code>TRUE</code> if plotting is to be done and
the number of real points is less than 100.)
</p>
</td></tr>
<tr><td><code id="logtrans_+3A_xlab">xlab</code></td>
<td>

<p>as for <code>plot</code>.
</p>
</td></tr>
<tr><td><code id="logtrans_+3A_ylab">ylab</code></td>
<td>

<p>as for <code>plot</code>.
</p>
</td></tr>
<tr><td><code id="logtrans_+3A_data">data</code></td>
<td>

<p>optional <code>data</code> argument for <code>lm</code> fit.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>List with components <code>x</code> (for alpha) and <code>y</code> (for the marginal
log-likelihood values).
</p>


<h3>Side Effects</h3>

<p>A plot of the marginal log-likelihood is produced, if requested,
together with an approximate mle and 95% confidence interval.
</p>


<h3>References</h3>

<p>Venables, W. N. and Ripley, B. D. (2002)
<em>Modern Applied Statistics with S.</em> Fourth edition.  Springer.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+boxcox">boxcox</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>logtrans(Days ~ Age*Sex*Eth*Lrn, data = quine,
         alpha = seq(0.75, 6.5, length.out = 20))
</code></pre>

<hr>
<h2 id='lqs'>
Resistant Regression
</h2><span id='topic+lqs'></span><span id='topic+lqs.formula'></span><span id='topic+lqs.default'></span><span id='topic+lmsreg'></span><span id='topic+ltsreg'></span>

<h3>Description</h3>

<p>Fit a regression to the <em>good</em> points in the dataset, thereby
achieving a regression estimator with a high breakdown point.
<code>lmsreg</code> and <code>ltsreg</code> are compatibility wrappers.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lqs(x, ...)

## S3 method for class 'formula'
lqs(formula, data, ...,
    method = c("lts", "lqs", "lms", "S", "model.frame"),
    subset, na.action, model = TRUE,
    x.ret = FALSE, y.ret = FALSE, contrasts = NULL)

## Default S3 method:
lqs(x, y, intercept = TRUE, method = c("lts", "lqs", "lms", "S"),
    quantile, control = lqs.control(...), k0 = 1.548, seed, ...)

lmsreg(...)
ltsreg(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lqs_+3A_formula">formula</code></td>
<td>
<p>a formula of the form <code>y ~ x1 + x2 + ...</code>.</p>
</td></tr>
<tr><td><code id="lqs_+3A_data">data</code></td>
<td>
<p>an optional data frame, list or environemnt from which
variables specified in <code>formula</code> are preferentially to be taken.</p>
</td></tr>
<tr><td><code id="lqs_+3A_subset">subset</code></td>
<td>
<p>an index vector specifying the cases to be used in
fitting. (NOTE: If given, this argument must be named exactly.)</p>
</td></tr>
<tr><td><code id="lqs_+3A_na.action">na.action</code></td>
<td>
<p>function to specify the action to be taken if
<code>NA</code>s are found.  The default action is for the procedure to
fail.  Alternatives include <code><a href="stats.html#topic+na.omit">na.omit</a></code> and
<code><a href="stats.html#topic+na.exclude">na.exclude</a></code>, which lead to omission of
cases with missing values on any required variable.  (NOTE: If
given, this argument must be named exactly.)
</p>
</td></tr>
<tr><td><code id="lqs_+3A_model">model</code>, <code id="lqs_+3A_x.ret">x.ret</code>, <code id="lqs_+3A_y.ret">y.ret</code></td>
<td>
<p>logical. If <code>TRUE</code> the model frame,
the model matrix and the response are returned, respectively.</p>
</td></tr>
<tr><td><code id="lqs_+3A_contrasts">contrasts</code></td>
<td>
<p>an optional list.  See the <code>contrasts.arg</code>
of <code><a href="stats.html#topic+model.matrix.default">model.matrix.default</a></code>.</p>
</td></tr>
<tr><td><code id="lqs_+3A_x">x</code></td>
<td>
<p>a matrix or data frame containing the explanatory variables.</p>
</td></tr>
<tr><td><code id="lqs_+3A_y">y</code></td>
<td>
<p>the response: a vector of length the number of rows of <code>x</code>.</p>
</td></tr>
<tr><td><code id="lqs_+3A_intercept">intercept</code></td>
<td>
<p>should the model include an intercept?</p>
</td></tr>
<tr><td><code id="lqs_+3A_method">method</code></td>
<td>

<p>the method to be used. <code>model.frame</code> returns the model frame: for the
others see the <code>Details</code> section. Using <code>lmsreg</code> or
<code>ltsreg</code> forces <code>"lms"</code> and <code>"lts"</code> respectively.
</p>
</td></tr>
<tr><td><code id="lqs_+3A_quantile">quantile</code></td>
<td>

<p>the quantile to be used: see <code>Details</code>. This is over-ridden if
<code>method = "lms"</code>.
</p>
</td></tr>
<tr><td><code id="lqs_+3A_control">control</code></td>
<td>
<p>additional control items: see <code>Details</code>.</p>
</td></tr>
<tr><td><code id="lqs_+3A_k0">k0</code></td>
<td>
<p>the cutoff / tuning constant used for <code class="reqn">\chi()</code>
and <code class="reqn">\psi()</code> functions when <code>method = "S"</code>, currently
corresponding to Tukey's &lsquo;biweight&rsquo;.</p>
</td></tr>
<tr><td><code id="lqs_+3A_seed">seed</code></td>
<td>

<p>the seed to be used for random sampling: see <code>.Random.seed</code>. The
current value of <code>.Random.seed</code> will be preserved if it is set..
</p>
</td></tr>
<tr><td><code id="lqs_+3A_...">...</code></td>
<td>
<p>arguments to be passed to <code>lqs.default</code> or
<code>lqs.control</code>, see <code>control</code> above and <code>Details</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Suppose there are <code>n</code> data points and <code>p</code> regressors,
including any intercept.
</p>
<p>The first three methods minimize some function of the sorted squared
residuals. For methods <code>"lqs"</code> and <code>"lms"</code> is the
<code>quantile</code> squared residual, and for <code>"lts"</code> it is the sum
of the <code>quantile</code> smallest squared residuals. <code>"lqs"</code> and
<code>"lms"</code> differ in the defaults for <code>quantile</code>, which are
<code>floor((n+p+1)/2)</code> and <code>floor((n+1)/2)</code> respectively.
For <code>"lts"</code> the default is <code>floor(n/2) + floor((p+1)/2)</code>.
</p>
<p>The <code>"S"</code> estimation method solves for the scale <code>s</code>
such that the average of a function chi of the residuals divided
by <code>s</code> is equal to a given constant.
</p>
<p>The <code>control</code> argument is a list with components
</p>

<dl>
<dt><code>psamp</code>:</dt><dd><p>the size of each sample. Defaults to <code>p</code>.</p>
</dd>
<dt><code>nsamp</code>:</dt><dd><p>the number of samples or <code>"best"</code> (the
default) or <code>"exact"</code> or <code>"sample"</code>.
If <code>"sample"</code> the number chosen is <code>min(5*p, 3000)</code>,
taken from Rousseeuw and Hubert (1997).
If <code>"best"</code> exhaustive enumeration is done up to 5000 samples;
if <code>"exact"</code> exhaustive enumeration will be attempted however
many samples are needed.</p>
</dd>
<dt><code>adjust</code>:</dt><dd><p>should the intercept be optimized for each
sample?  Defaults to <code>TRUE</code>.</p>
</dd>
</dl>



<h3>Value</h3>

<p>An object of class <code>"lqs"</code>.  This is a list with components
</p>
<table>
<tr><td><code>crit</code></td>
<td>
<p>the value of the criterion for the best solution found, in
the case of <code>method == "S"</code> before IWLS refinement.</p>
</td></tr>
<tr><td><code>sing</code></td>
<td>
<p>character. A message about the number of samples which
resulted in singular fits.</p>
</td></tr>
<tr><td><code>coefficients</code></td>
<td>
<p>of the fitted linear model</p>
</td></tr>
<tr><td><code>bestone</code></td>
<td>
<p>the indices of those points fitted by the best sample
found (prior to adjustment of the intercept, if requested).</p>
</td></tr>
<tr><td><code>fitted.values</code></td>
<td>
<p>the fitted values.</p>
</td></tr>
<tr><td><code>residuals</code></td>
<td>
<p>the residuals.</p>
</td></tr>
<tr><td><code>scale</code></td>
<td>
<p>estimate(s) of the scale of the error. The first is based
on the fit criterion.  The second (not present for <code>method ==
      "S"</code>) is based on the variance of those residuals whose absolute
value is less than 2.5 times the initial estimate.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>There seems no reason other than historical to use the <code>lms</code> and
<code>lqs</code> options.  LMS estimation is of low efficiency (converging
at rate <code class="reqn">n^{-1/3}</code>) whereas LTS has the same asymptotic efficiency
as an M estimator with trimming at the quartiles (Marazzi, 1993, p.201).
LQS and LTS have the same maximal breakdown value of
<code>(floor((n-p)/2) + 1)/n</code> attained if
<code>floor((n+p)/2) &lt;= quantile &lt;= floor((n+p+1)/2)</code>.
The only drawback mentioned of LTS is greater computation, as a sort
was thought to be required (Marazzi, 1993, p.201) but this is not
true as a partial sort can be used (and is used in this implementation).
</p>
<p>Adjusting the intercept for each trial fit does need the residuals to
be sorted, and may be significant extra computation if <code>n</code> is large
and <code>p</code> small.
</p>
<p>Opinions differ over the choice of <code>psamp</code>.  Rousseeuw and Hubert
(1997) only consider p; Marazzi (1993) recommends p+1 and suggests
that more samples are better than adjustment for a given computational
limit.
</p>
<p>The computations are exact for a model with just an intercept and
adjustment, and for LQS for a model with an intercept plus one
regressor and exhaustive search with adjustment. For all other cases
the minimization is only known to be approximate.
</p>


<h3>References</h3>

<p>P. J. Rousseeuw and A. M. Leroy (1987)
<em>Robust Regression and Outlier Detection.</em> Wiley.
</p>
<p>A. Marazzi (1993)
<em>Algorithms, Routines and S Functions for Robust Statistics.</em>
Wadsworth and Brooks/Cole.
</p>
<p>P. Rousseeuw and M. Hubert (1997) Recent developments in PROGRESS. In
<em>L1-Statistical Procedures and Related Topics</em>,
ed Y. Dodge, IMS Lecture Notes volume <b>31</b>, pp. 201&ndash;214.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+predict.lqs">predict.lqs</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## IGNORE_RDIFF_BEGIN
set.seed(123) # make reproducible
lqs(stack.loss ~ ., data = stackloss)
lqs(stack.loss ~ ., data = stackloss, method = "S", nsamp = "exact")
## IGNORE_RDIFF_END
</code></pre>

<hr>
<h2 id='mammals'>
Brain and Body Weights for 62 Species of Land Mammals
</h2><span id='topic+mammals'></span>

<h3>Description</h3>

<p>A data frame with average brain and body weights for 62 species
of land mammals.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mammals
</code></pre>


<h3>Format</h3>


<dl>
<dt><code>body</code></dt><dd>
<p>body weight in kg.
</p>
</dd>
<dt><code>brain</code></dt><dd>
<p>brain weight in g.
</p>
</dd>
<dt><code>name</code></dt><dd>
<p>Common name of species.
(Rock hyrax-a = <em>Heterohyrax brucci</em>,
Rock hyrax-b = <em>Procavia habessinic.</em>.)
</p>
</dd>
</dl>



<h3>Source</h3>

<p>Weisberg, S. (1985)
<em>Applied Linear Regression.</em> 2nd edition. Wiley, pp. 144&ndash;5.
</p>
<p>Selected from:
Allison, T. and Cicchetti, D. V. (1976)
Sleep in mammals: ecological and constitutional correlates.
<em>Science</em> <b>194</b>, 732&ndash;734.
</p>


<h3>References</h3>

<p>Venables, W. N. and Ripley, B. D. (2002)
<em>Modern Applied Statistics with S-PLUS.</em> Fourth Edition. Springer.
</p>

<hr>
<h2 id='MASS-internal'>Internal MASS functions</h2><span id='topic+enlist'></span><span id='topic+fbeta'></span><span id='topic+frequency.polygon'></span><span id='topic+nclass.freq'></span><span id='topic+neg.bin'></span><span id='topic+negexp.SSival'></span>

<h3>Description</h3>

<p>Internal MASS functions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>enlist(vec)
fbeta(x, alpha, beta)
frequency.polygon(x, nclass = nclass.freq(x), xlab="", ylab="", ...)
nclass.freq(x)
neg.bin(theta = stop("'theta' must be given"))
negexp.SSival(mCall, data, LHS)



</code></pre>


<h3>Details</h3>

<p>These are not intended to be called by the user.
Some are for compatibility
with earlier versions of MASS (the book).
</p>

<hr>
<h2 id='mca'>
Multiple Correspondence Analysis
</h2><span id='topic+mca'></span><span id='topic+print.mca'></span>

<h3>Description</h3>

<p>Computes a multiple correspondence analysis of a set of factors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mca(df, nf = 2, abbrev = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mca_+3A_df">df</code></td>
<td>

<p>A data frame containing only factors
</p>
</td></tr>
<tr><td><code id="mca_+3A_nf">nf</code></td>
<td>

<p>The number of dimensions for the MCA. Rarely 3 might be useful.
</p>
</td></tr>
<tr><td><code id="mca_+3A_abbrev">abbrev</code></td>
<td>

<p>Should the vertex names be abbreviated?  By default these are of the
form &lsquo;factor.level&rsquo; but if <code>abbrev = TRUE</code> they are just
&lsquo;level&rsquo; which will suffice if the factors have distinct levels.
</p>
</td></tr></table>


<h3>Value</h3>

<p>An object of class <code>"mca"</code>, with components
</p>
<table>
<tr><td><code>rs</code></td>
<td>

<p>The coordinates of the rows, in <code>nf</code> dimensions.
</p>
</td></tr>
<tr><td><code>cs</code></td>
<td>

<p>The coordinates of the column vertices, one for each level of each factor.
</p>
</td></tr>
<tr><td><code>fs</code></td>
<td>

<p>Weights for each row, used to interpolate additional factors in <code>predict.mca</code>.
</p>
</td></tr>
<tr><td><code>p</code></td>
<td>

<p>The number of factors
</p>
</td></tr>
<tr><td><code>d</code></td>
<td>

<p>The singular values for the <code>nf</code> dimensions.
</p>
</td></tr>
<tr><td><code>call</code></td>
<td>

<p>The matched call.
</p>
</td></tr></table>


<h3>References</h3>

<p>Venables, W. N. and Ripley, B. D. (2002)
<em>Modern Applied Statistics with S.</em> Fourth edition.  Springer.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+predict.mca">predict.mca</a></code>, <code><a href="#topic+plot.mca">plot.mca</a></code>, <code><a href="#topic+corresp">corresp</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>farms.mca &lt;- mca(farms, abbrev=TRUE)
farms.mca
plot(farms.mca)
</code></pre>

<hr>
<h2 id='mcycle'>
Data from a Simulated Motorcycle Accident
</h2><span id='topic+mcycle'></span>

<h3>Description</h3>

<p>A data frame giving a series of measurements of head acceleration
in a simulated motorcycle accident, used to test crash helmets.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mcycle
</code></pre>


<h3>Format</h3>


<dl>
<dt><code>times</code></dt><dd>
<p>in milliseconds after impact.
</p>
</dd>
<dt><code>accel</code></dt><dd>
<p>in g.
</p>
</dd>
</dl>



<h3>Source</h3>

<p>Silverman, B. W. (1985) Some aspects of the spline smoothing approach to
non-parametric curve fitting.
<em>Journal of the Royal Statistical Society series B</em> <b>47</b>, 1&ndash;52.
</p>


<h3>References</h3>

<p>Venables, W. N. and Ripley, B. D. (2002)
<em>Modern Applied Statistics with S-PLUS.</em> Fourth Edition. Springer.
</p>

<hr>
<h2 id='Melanoma'>
Survival from Malignant Melanoma
</h2><span id='topic+Melanoma'></span>

<h3>Description</h3>

<p>The <code>Melanoma</code> data frame has data on 205 patients in Denmark
with malignant melanoma.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Melanoma
</code></pre>


<h3>Format</h3>

<p>This data frame contains the following columns:
</p>

<dl>
<dt><code>time</code></dt><dd>
<p>survival time in days, possibly censored.
</p>
</dd>
<dt><code>status</code></dt><dd>
<p><code>1</code> died from melanoma, <code>2</code> alive, <code>3</code> dead from
other causes.
</p>
</dd>
<dt><code>sex</code></dt><dd>
<p><code>1</code> = male, <code>0</code> = female.
</p>
</dd>
<dt><code>age</code></dt><dd>
<p>age in years.
</p>
</dd>
<dt><code>year</code></dt><dd>
<p>of operation.
</p>
</dd>
<dt><code>thickness</code></dt><dd>
<p>tumour thickness in mm.
</p>
</dd>
<dt><code>ulcer</code></dt><dd>
<p><code>1</code> = presence, <code>0</code> = absence.
</p>
</dd>
</dl>



<h3>Source</h3>

<p>P. K. Andersen, O. Borgan, R. D. Gill and N. Keiding (1993)
<em>Statistical Models based on Counting Processes.</em>
Springer.
</p>

<hr>
<h2 id='menarche'>
Age of Menarche in Warsaw
</h2><span id='topic+menarche'></span>

<h3>Description</h3>

<p>Proportions of female children at various ages during adolescence
who have reached menarche.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>menarche
</code></pre>


<h3>Format</h3>

<p>This data frame contains the following columns:
</p>

<dl>
<dt><code>Age</code></dt><dd>
<p>Average age of the group.  (The groups are reasonably age homogeneous.)
</p>
</dd>
<dt><code>Total</code></dt><dd>
<p>Total number of children in the group.
</p>
</dd>
<dt><code>Menarche</code></dt><dd>
<p>Number who have reached menarche.
</p>
</dd>
</dl>



<h3>Source</h3>

<p>Milicer, H. and Szczotka, F. (1966) Age at Menarche in Warsaw girls in
1965.
<em>Human Biology</em> <b>38</b>, 199&ndash;203.
</p>
<p>The data are also given in<br />
Aranda-Ordaz, F.J. (1981)
On two families of transformations to additivity for binary response data.
<em>Biometrika</em> <b>68</b>, 357&ndash;363.
</p>


<h3>References</h3>

<p>Venables, W. N. and Ripley, B. D. (2002)
<em>Modern Applied Statistics with S.</em> Fourth edition.  Springer.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>mprob &lt;- glm(cbind(Menarche, Total - Menarche) ~ Age,
             binomial(link = probit), data = menarche)
</code></pre>

<hr>
<h2 id='michelson'>
Michelson's Speed of Light Data
</h2><span id='topic+michelson'></span>

<h3>Description</h3>

<p>Measurements of the speed of light in air, made between 5th June
and 2nd July, 1879.  The data consists of five experiments, each
consisting of 20 consecutive runs.  The response is the speed
of light in km/s, less 299000.  The currently accepted value, on
this scale of measurement, is 734.5.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>michelson
</code></pre>


<h3>Format</h3>

<p>The data frame contains the following components:
</p>

<dl>
<dt><code>Expt</code></dt><dd>
<p>The experiment number, from 1 to 5.
</p>
</dd>
<dt><code>Run</code></dt><dd>
<p>The run number within each experiment.
</p>
</dd>
<dt><code>Speed</code></dt><dd>
<p>Speed-of-light measurement.
</p>
</dd>
</dl>



<h3>Source</h3>

<p>A.J. Weekes (1986) <em>A Genstat Primer.</em> Edward Arnold.
</p>
<p>S. M. Stigler (1977) Do robust estimators work with real data?
<em>Annals of Statistics</em> <b>5</b>, 1055&ndash;1098.
</p>


<h3>References</h3>

<p>Venables, W. N. and Ripley, B. D. (2002)
<em>Modern Applied Statistics with S.</em> Fourth edition.  Springer.
</p>

<hr>
<h2 id='minn38'>
Minnesota High School Graduates of 1938
</h2><span id='topic+minn38'></span>

<h3>Description</h3>

<p>The Minnesota high school graduates of 1938 were classified according to
four factors, described below.  The <code>minn38</code> data frame has 168
rows and 5 columns.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>minn38
</code></pre>


<h3>Format</h3>

<p>This data frame contains the following columns:
</p>

<dl>
<dt><code>hs</code></dt><dd>
<p>high school rank: <code>"L"</code>, <code>"M"</code> and <code>"U"</code> for lower,
middle and upper third.
</p>
</dd>
<dt><code>phs</code></dt><dd>
<p>post high school status: Enrolled in college, (<code>"C"</code>), enrolled in
non-collegiate school, (<code>"N"</code>), employed full-time, (<code>"E"</code>)
and other, (<code>"O"</code>).
</p>
</dd>
<dt><code>fol</code></dt><dd>
<p>father's occupational level, (seven levels, <code>"F1"</code>, <code>"F2"</code>,
..., <code>"F7"</code>).
</p>
</dd>
<dt><code>sex</code></dt><dd>
<p>sex: factor with levels<code>"F"</code> or <code>"M"</code>.
</p>
</dd>
<dt><code>f</code></dt><dd>
<p>frequency.
</p>
</dd>
</dl>



<h3>Source</h3>

<p>From R. L. Plackett, (1974) <em>The Analysis of Categorical
Data.</em> London: Griffin
</p>
<p>who quotes the data from
</p>
<p>Hoyt, C. J., Krishnaiah, P. R. and Torrance, E. P. (1959) Analysis of
complex contingency tables, <em>J. Exp. Ed.</em> <b>27</b>, 187&ndash;194.
</p>

<hr>
<h2 id='motors'>
Accelerated Life Testing of Motorettes
</h2><span id='topic+motors'></span>

<h3>Description</h3>

<p>The <code>motors</code> data frame has 40 rows and 3 columns.  It describes an
accelerated life test at each of four temperatures of 10 motorettes,
and has rather discrete times.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>motors
</code></pre>


<h3>Format</h3>

<p>This data frame contains the following columns:
</p>

<dl>
<dt><code>temp</code></dt><dd>
<p>the temperature (degrees C) of the test.
</p>
</dd>
<dt><code>time</code></dt><dd>
<p>the time in hours to failure or censoring at 8064 hours (= 336 days).
</p>
</dd>
<dt><code>cens</code></dt><dd>
<p>an indicator variable for death.
</p>
</dd>
</dl>



<h3>Source</h3>

<p>Kalbfleisch, J. D. and Prentice, R. L. (1980)
<em>The Statistical Analysis of Failure Time Data.</em>
New York: Wiley.
</p>
<p>taken from
</p>
<p>Nelson, W. D. and Hahn, G. J. (1972)
Linear regression of a regression relationship from censored data.
Part 1 &ndash; simple methods and their application.
<em>Technometrics</em>, <b>14</b>, 247&ndash;276.
</p>


<h3>References</h3>

<p>Venables, W. N. and Ripley, B. D. (2002)
<em>Modern Applied Statistics with S.</em> Fourth edition.  Springer.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(survival)
plot(survfit(Surv(time, cens) ~ factor(temp), motors), conf.int = FALSE)
# fit Weibull model
motor.wei &lt;- survreg(Surv(time, cens) ~ temp, motors)
summary(motor.wei)
# and predict at 130C
unlist(predict(motor.wei, data.frame(temp=130), se.fit = TRUE))

motor.cox &lt;- coxph(Surv(time, cens) ~ temp, motors)
summary(motor.cox)
# predict at temperature 200
plot(survfit(motor.cox, newdata = data.frame(temp=200),
     conf.type = "log-log"))
summary( survfit(motor.cox, newdata = data.frame(temp=130)) )
</code></pre>

<hr>
<h2 id='muscle'>
Effect of Calcium Chloride on Muscle Contraction in Rat Hearts
</h2><span id='topic+muscle'></span>

<h3>Description</h3>

<p>The purpose of this experiment was to assess the influence of
calcium in solution on the contraction of heart muscle in rats.
The left auricle of 21 rat hearts was isolated and on several
occasions a constant-length strip of tissue was electrically
stimulated and dipped into various concentrations of calcium
chloride solution, after which the shortening of the strip was
accurately measured as the response.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>muscle
</code></pre>


<h3>Format</h3>

<p>This data frame contains the following columns:
</p>

<dl>
<dt><code>Strip</code></dt><dd>
<p>which heart muscle strip was used?
</p>
</dd>
<dt><code>Conc</code></dt><dd>
<p>concentration of calcium chloride solution, in multiples of 2.2 mM.
</p>
</dd>
<dt><code>Length</code></dt><dd>
<p>the change in length (shortening) of the strip, (allegedly) in mm.
</p>
</dd>
</dl>



<h3>Source</h3>

<p>Linder, A., Chakravarti, I. M. and Vuagnat, P. (1964)
Fitting asymptotic regression curves with different asymptotes.  In
<em>Contributions to Statistics. Presented to Professor P. C. Mahalanobis
on the occasion of his 70th birthday</em>,
ed. C. R. Rao, pp. 221&ndash;228. Oxford: Pergamon Press.
</p>


<h3>References</h3>

<p>Venables, W. N. and Ripley, B. D. (2002)
<em>Modern Applied Statistics with S.</em> Fourth Edition. Springer.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## IGNORE_RDIFF_BEGIN
A &lt;- model.matrix(~ Strip - 1, data=muscle)
rats.nls1 &lt;- nls(log(Length) ~ cbind(A, rho^Conc),
   data = muscle, start = c(rho=0.1), algorithm="plinear")
(B &lt;- coef(rats.nls1))

st &lt;- list(alpha = B[2:22], beta = B[23], rho = B[1])
(rats.nls2 &lt;- nls(log(Length) ~ alpha[Strip] + beta*rho^Conc,
                  data = muscle, start = st))
## IGNORE_RDIFF_END

Muscle &lt;- with(muscle, {
Muscle &lt;- expand.grid(Conc = sort(unique(Conc)), Strip = levels(Strip))
Muscle$Yhat &lt;- predict(rats.nls2, Muscle)
Muscle &lt;- cbind(Muscle, logLength = rep(as.numeric(NA), 126))
ind &lt;- match(paste(Strip, Conc),
            paste(Muscle$Strip, Muscle$Conc))
Muscle$logLength[ind] &lt;- log(Length)
Muscle})

lattice::xyplot(Yhat ~ Conc | Strip, Muscle, as.table = TRUE,
   ylim = range(c(Muscle$Yhat, Muscle$logLength), na.rm = TRUE),
   subscripts = TRUE, xlab = "Calcium Chloride concentration (mM)",
   ylab = "log(Length in mm)", panel =
   function(x, y, subscripts, ...) {
      panel.xyplot(x, Muscle$logLength[subscripts], ...)
      llines(spline(x, y))
   })
</code></pre>

<hr>
<h2 id='mvrnorm'>Simulate from a Multivariate Normal Distribution</h2><span id='topic+mvrnorm'></span>

<h3>Description</h3>

<p>Produces one or more samples from the specified
multivariate normal distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mvrnorm(n = 1, mu, Sigma, tol = 1e-6, empirical = FALSE, EISPACK = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mvrnorm_+3A_n">n</code></td>
<td>
<p>the number of samples required.</p>
</td></tr>
<tr><td><code id="mvrnorm_+3A_mu">mu</code></td>
<td>
<p>a vector giving the means of the variables.</p>
</td></tr>
<tr><td><code id="mvrnorm_+3A_sigma">Sigma</code></td>
<td>
<p>a positive-definite symmetric matrix specifying the
covariance matrix of the variables.</p>
</td></tr>
<tr><td><code id="mvrnorm_+3A_tol">tol</code></td>
<td>
<p>tolerance (relative to largest variance) for numerical lack
of positive-definiteness in <code>Sigma</code>.</p>
</td></tr>
<tr><td><code id="mvrnorm_+3A_empirical">empirical</code></td>
<td>
<p>logical. If true, mu and Sigma specify the empirical
not population mean and covariance matrix.</p>
</td></tr>
<tr><td><code id="mvrnorm_+3A_eispack">EISPACK</code></td>
<td>
<p>logical: values other than <code>FALSE</code> are an error.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The matrix decomposition is done via <code>eigen</code>; although a Choleski
decomposition might be faster, the eigendecomposition is
stabler.
</p>


<h3>Value</h3>

<p>If <code>n = 1</code> a vector of the same length as <code>mu</code>, otherwise an
<code>n</code> by <code>length(mu)</code> matrix with one sample in each row.
</p>


<h3>Side Effects</h3>

<p>Causes creation of the dataset <code>.Random.seed</code> if it does
not already exist, otherwise its value is updated.
</p>


<h3>References</h3>

<p>B. D. Ripley (1987) <em>Stochastic Simulation.</em> Wiley. Page 98.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+rnorm">rnorm</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>Sigma &lt;- matrix(c(10,3,3,2),2,2)
Sigma
var(mvrnorm(n = 1000, rep(0, 2), Sigma))
var(mvrnorm(n = 1000, rep(0, 2), Sigma, empirical = TRUE))
</code></pre>

<hr>
<h2 id='negative.binomial'>
Family function for Negative Binomial GLMs
</h2><span id='topic+negative.binomial'></span>

<h3>Description</h3>

<p>Specifies the information required to fit a Negative Binomial generalized
linear model, with known <code>theta</code> parameter, using <code>glm()</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>negative.binomial(theta = stop("'theta' must be specified"), link = "log")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="negative.binomial_+3A_theta">theta</code></td>
<td>

<p>The known value of the additional parameter, <code>theta</code>.
</p>
</td></tr>
<tr><td><code id="negative.binomial_+3A_link">link</code></td>
<td>

<p>The link function, as a character string, name or one-element
character vector specifying one of <code>log</code>, <code>sqrt</code>
or <code>identity</code>, or an object of class
<code>"<a href="stats.html#topic+family">link-glm</a>"</code>.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code>"family"</code>, a list of functions and
expressions needed by <code>glm()</code> to fit a Negative Binomial
generalized linear model.
</p>


<h3>References</h3>

<p>Venables, W. N. and Ripley, B. D. (2002)
<em>Modern Applied Statistics with S-PLUS.</em> Fourth Edition. Springer.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+glm.nb">glm.nb</a></code>, <code><a href="#topic+anova.negbin">anova.negbin</a></code>,
<code><a href="#topic+summary.negbin">summary.negbin</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Fitting a Negative Binomial model to the quine data
#   with theta = 2 assumed known.
#
glm(Days ~ .^4, family = negative.binomial(2), data = quine)
</code></pre>

<hr>
<h2 id='newcomb'>
Newcomb's Measurements of the Passage Time of Light
</h2><span id='topic+newcomb'></span>

<h3>Description</h3>

<p>A numeric vector giving the &lsquo;Third Series&rsquo; of measurements of the
passage time of light recorded by Newcomb in 1882.  The given values
divided by 1000 plus 24.8 give the time in millionths of a second for
light to traverse a known distance. The &lsquo;true&rsquo; value is now
considered to be 33.02.
</p>
<p>The dataset is given in the order in Staudte and Sheather.  Stigler
(1977, Table 5) gives the dataset as
</p>
<pre>
    28 26 33 24 34 -44 27 16 40 -2 29 22 24 21 25 30 23 29 31 19
    24 20 36 32 36 28 25 21 28 29 37 25 28 26 30 32 36 26 30 22
    36 23 27 27 28 27 31 27 26 33 26 32 32 24 39 28 24 25 32 25
    29 27 28 29 16 23
</pre>
<p>However, order is not relevant to its use as an example of robust
estimation.  (Thanks to Anthony Unwin for bringing this difference to our
attention.)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>newcomb
</code></pre>


<h3>Source</h3>

<p>S. M. Stigler (1973)
Simon Newcomb, Percy Daniell, and the history of robust estimation
1885&ndash;1920.
<em>Journal of the American Statistical Association</em> <b>68</b>, 872&ndash;879.
</p>
<p>S. M. Stigler (1977)
Do robust estimators work with <em>real</em> data?
<em>Annals of Statistics</em>, <b>5</b>, 1055&ndash;1098.
</p>
<p>R. G. Staudte and S. J. Sheather (1990)
<em>Robust Estimation and Testing.</em> Wiley.
</p>

<hr>
<h2 id='nlschools'>
Eighth-Grade Pupils in the Netherlands
</h2><span id='topic+nlschools'></span>

<h3>Description</h3>

<p>Snijders and Bosker (1999) use as a running example a study of 2287
eighth-grade pupils (aged about 11) in 132 classes in 131 schools in
the Netherlands.  Only the variables used in our examples are supplied.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nlschools
</code></pre>


<h3>Format</h3>

<p>This data frame contains 2287 rows and the following columns:
</p>

<dl>
<dt><code>lang</code></dt><dd>
<p>language test score.
</p>
</dd>
<dt><code>IQ</code></dt><dd>
<p>verbal IQ.
</p>
</dd>
<dt><code>class</code></dt><dd>
<p>class ID.
</p>
</dd>
<dt><code>GS</code></dt><dd>
<p>class size: number of eighth-grade pupils recorded in the class (there
may be others: see <code>COMB</code>, and some may have been omitted
with missing values).
</p>
</dd>
<dt><code>SES</code></dt><dd>
<p>social-economic status of pupil's family.
</p>
</dd>
<dt><code>COMB</code></dt><dd>
<p>were the pupils taught in a multi-grade class (<code>0/1</code>)?  Classes which
contained pupils from grades 7 and 8 are coded <code>1</code>, but only
eighth-graders were tested.
</p>
</dd>
</dl>



<h3>Source</h3>

<p>Snijders, T. A. B. and Bosker, R. J. (1999)
<em>Multilevel Analysis. An Introduction to Basic and Advanced
Multilevel Modelling.</em> London: Sage.
</p>


<h3>References</h3>

<p>Venables, W. N. and Ripley, B. D. (2002)
<em>Modern Applied Statistics with S.</em> Fourth edition.  Springer.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
nl1 &lt;- within(nlschools, {
IQave &lt;- tapply(IQ, class, mean)[as.character(class)]
IQ &lt;- IQ - IQave
})
cen &lt;- c("IQ", "IQave", "SES")
nl1[cen] &lt;- scale(nl1[cen], center = TRUE, scale = FALSE)

nl.lme &lt;- nlme::lme(lang ~ IQ*COMB + IQave + SES,
                    random = ~ IQ | class, data = nl1)
## IGNORE_RDIFF_BEGIN
summary(nl.lme)
## IGNORE_RDIFF_END

</code></pre>

<hr>
<h2 id='npk'>
Classical N, P, K Factorial Experiment
</h2><span id='topic+npk'></span>

<h3>Description</h3>

<p>A classical N, P, K (nitrogen, phosphate, potassium) factorial
experiment on the growth of peas conducted on 6 blocks. Each half of a
fractional factorial design confounding the NPK interaction was used
on 3 of the plots.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>npk
</code></pre>


<h3>Format</h3>

<p>The <code>npk</code> data frame has 24 rows and 5 columns:
</p>

<dl>
<dt><code>block</code></dt><dd>
<p>which block (label 1 to 6).
</p>
</dd>
<dt><code>N</code></dt><dd>
<p>indicator (0/1) for the application of nitrogen.
</p>
</dd>
<dt><code>P</code></dt><dd>
<p>indicator (0/1) for the application of phosphate.
</p>
</dd>
<dt><code>K</code></dt><dd>
<p>indicator (0/1) for the application of potassium.
</p>
</dd>
<dt><code>yield</code></dt><dd>
<p>Yield of peas, in pounds/plot (the plots were (1/70) acre).
</p>
</dd>
</dl>



<h3>Note</h3>

<p>This dataset is also contained in <span class="rlang"><b>R</b></span> 3.0.2 and later.
</p>


<h3>Source</h3>

<p>Imperial College, London, M.Sc. exercise sheet.
</p>


<h3>References</h3>

<p>Venables, W. N. and Ripley, B. D. (2002)
<em>Modern Applied Statistics with S.</em> Fourth edition.  Springer.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>options(contrasts = c("contr.sum", "contr.poly"))
npk.aov &lt;- aov(yield ~ block + N*P*K, npk)
## IGNORE_RDIFF_BEGIN
npk.aov
summary(npk.aov)
alias(npk.aov)
coef(npk.aov)
options(contrasts = c("contr.treatment", "contr.poly"))
npk.aov1 &lt;- aov(yield ~ block + N + K, data = npk)
summary.lm(npk.aov1)
se.contrast(npk.aov1, list(N=="0", N=="1"), data = npk)
model.tables(npk.aov1, type = "means", se = TRUE)
## IGNORE_RDIFF_END</code></pre>

<hr>
<h2 id='npr1'>
US Naval Petroleum Reserve No. 1 data
</h2><span id='topic+npr1'></span>

<h3>Description</h3>

<p>Data on the locations, porosity and permeability (a measure of oil flow)
on 104 oil wells in the US Naval Petroleum Reserve No. 1 in California.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>npr1
</code></pre>


<h3>Format</h3>

<p>This data frame contains the following columns:
</p>

<dl>
<dt><code>x</code></dt><dd>
<p>x coordinates, in miles (origin unspecified)..
</p>
</dd>
<dt><code>y</code></dt><dd>
<p>y coordinates, in miles.
</p>
</dd>
<dt><code>perm</code></dt><dd>
<p>permeability in milli-Darcies.
</p>
</dd>
<dt><code>por</code></dt><dd>
<p>porosity (%).
</p>
</dd>
</dl>



<h3>Source</h3>

<p>Maher, J.C., Carter, R.D. and Lantz, R.J. (1975)
Petroleum geology of Naval Petroleum Reserve No. 1, Elk Hills,
Kern County, California.
<em>USGS Professional Paper</em> <b>912</b>.
</p>


<h3>References</h3>

<p>Venables, W. N. and Ripley, B. D. (2002)
<em>Modern Applied Statistics with S.</em> Fourth edition.  Springer.
</p>

<hr>
<h2 id='Null'>
Null Spaces of Matrices
</h2><span id='topic+Null'></span>

<h3>Description</h3>

<p>Given a matrix, <code>M</code>, find a matrix <code>N</code> giving a basis for the
(left) null space.  That is <code>crossprod(N, M) = t(N) %*% M</code>
is an all-zero matrix and <code>N</code> has the maximum number of linearly
independent columns.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Null(M)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Null_+3A_m">M</code></td>
<td>

<p>Input matrix.  A vector is coerced to a 1-column matrix.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For a basis for the (right) null space
<code class="reqn">\{x : Mx = 0\}</code>,
use <code>Null(t(M))</code>.
</p>


<h3>Value</h3>

<p>The matrix <code>N</code> with the basis for the (left) null space, or a
matrix with zero columns if the matrix <code>M</code> is square and of
maximal rank.
</p>


<h3>References</h3>

<p>Venables, W. N. and Ripley, B. D. (2002)
<em>Modern Applied Statistics with S.</em> Fourth edition.  Springer.
</p>


<h3>See Also</h3>


<p><code><a href="base.html#topic+qr">qr</a></code>, <code><a href="base.html#topic+qr.Q">qr.Q</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># The function is currently defined as
function(M)
{
    tmp &lt;- qr(M)
    set &lt;- if(tmp$rank == 0L) seq_len(ncol(M)) else  -seq_len(tmp$rank)
    qr.Q(tmp, complete = TRUE)[, set, drop = FALSE]
}
</code></pre>

<hr>
<h2 id='oats'>
Data from an Oats Field Trial
</h2><span id='topic+oats'></span>

<h3>Description</h3>

<p>The yield of oats from a split-plot field trial using three varieties and
four levels of manurial treatment.  The experiment was laid out in 6 blocks
of 3 main plots, each split into 4 sub-plots.  The varieties were applied
to the main plots and the manurial treatments to the sub-plots.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>oats
</code></pre>


<h3>Format</h3>

<p>This data frame contains the following columns:
</p>

<dl>
<dt><code>B</code></dt><dd>
<p>Blocks, levels I, II, III, IV, V and VI.
</p>
</dd>
<dt><code>V</code></dt><dd>
<p>Varieties, 3 levels.
</p>
</dd>
<dt><code>N</code></dt><dd>
<p>Nitrogen (manurial) treatment, levels  0.0cwt, 0.2cwt, 0.4cwt and 0.6cwt,
showing the application in cwt/acre.
</p>
</dd>
<dt><code>Y</code></dt><dd>
<p>Yields in 1/4lbs per sub-plot, each of area 1/80 acre.
</p>
</dd>
</dl>



<h3>Source</h3>

<p>Yates, F. (1935) Complex experiments,
<em>Journal of the Royal Statistical Society Suppl.</em>
<b>2</b>, 181&ndash;247.
</p>
<p>Also given in
Yates, F. (1970)
<em>Experimental design: Selected papers of Frank Yates, C.B.E, F.R.S.</em>
London: Griffin.
</p>


<h3>References</h3>

<p>Venables, W. N. and Ripley, B. D. (2002)
<em>Modern Applied Statistics with S.</em> Fourth edition.  Springer.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>oats$Nf &lt;- ordered(oats$N, levels = sort(levels(oats$N)))
oats.aov &lt;- aov(Y ~ Nf*V + Error(B/V), data = oats, qr = TRUE)
## IGNORE_RDIFF_BEGIN
summary(oats.aov)
summary(oats.aov, split = list(Nf=list(L=1, Dev=2:3)))
## IGNORE_RDIFF_END
par(mfrow = c(1,2), pty = "s")
plot(fitted(oats.aov[[4]]), studres(oats.aov[[4]]))
abline(h = 0, lty = 2)
oats.pr &lt;- proj(oats.aov)
qqnorm(oats.pr[[4]][,"Residuals"], ylab = "Stratum 4 residuals")
qqline(oats.pr[[4]][,"Residuals"])

par(mfrow = c(1,1), pty = "m")
oats.aov2 &lt;- aov(Y ~ N + V + Error(B/V), data = oats, qr = TRUE)
model.tables(oats.aov2, type = "means", se = TRUE)
</code></pre>

<hr>
<h2 id='OME'>
Tests of Auditory Perception in Children with OME
</h2><span id='topic+OME'></span>

<h3>Description</h3>

<p>Experiments were performed on children on their ability to
differentiate a signal in broad-band noise. The noise was played from
a pair of speakers and a signal was added to just one channel; the
subject had to turn his/her head to the channel with the added signal.
The signal was either coherent (the amplitude of the noise was
increased for a period) or incoherent (independent noise was added for
the same period to form the same increase in power).
</p>
<p>The threshold used in the original analysis was the stimulus loudness
needs to get 75% correct responses. Some of the children had
suffered from otitis media with effusion (OME).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>OME
</code></pre>


<h3>Format</h3>

<p>The <code>OME</code> data frame has 1129 rows and 7 columns:
</p>

<dl>
<dt><code>ID</code></dt><dd>
<p>Subject ID (1 to 99, with some IDs missing). A few subjects were
measured at different ages.
</p>
</dd>
<dt><code>OME</code></dt><dd>
<p><code>"low"</code> or <code>"high"</code> or <code>"N/A"</code> (at ages other than
30 and 60 months). 
</p>
</dd>
<dt><code>Age</code></dt><dd>
<p>Age of the subject (months).
</p>
</dd>
<dt><code>Loud</code></dt><dd>
<p>Loudness of stimulus, in decibels.
</p>
</dd>
<dt><code>Noise</code></dt><dd>
<p>Whether the signal in the stimulus was <code>"coherent"</code> or
<code>"incoherent"</code>.
</p>
</dd>
<dt><code>Correct</code></dt><dd>
<p>Number of correct responses from <code>Trials</code> trials.
</p>
</dd>
<dt><code>Trials</code></dt><dd>
<p>Number of trials performed.
</p>
</dd>
</dl>



<h3>Background</h3>

<p>The experiment was to study otitis media with effusion (OME), a very
common childhood condition where the middle ear space, which is
normally air-filled, becomes congested by a fluid.  There is a
concomitant fluctuating, conductive hearing loss which can result in
various language, cognitive and social deficits.  The term &lsquo;binaural
hearing&rsquo; is used to describe the listening conditions in which the
brain is processing information from both ears at the same time.  The
brain computes differences in the intensity and/or timing of signals
arriving at each ear which contributes to sound localisation and also
to our ability to hear in background noise.
</p>
<p>Some years ago, it was found that children of 7&ndash;8 years with a history
of significant OME had significantly worse binaural hearing than
children without such a history, despite having equivalent
sensitivity.  The question remained as to whether it was the timing,
the duration, or the degree of severity of the otitis media episodes
during critical periods, which affected later binaural hearing.  In an
attempt to begin to answer this question, 95 children were monitored for
the presence of effusion every month since birth.  On the basis of OME
experience in their first two years, the test population was split
into one group of high OME prevalence and one of low prevalence.
</p>


<h3>Source</h3>

<p>Sarah Hogan, Dept of Physiology, University of Oxford, via
Dept of Statistics Consulting Service
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Fit logistic curve from p = 0.5 to p = 1.0
fp1 &lt;- deriv(~ 0.5 + 0.5/(1 + exp(-(x-L75)/scal)),
             c("L75", "scal"),
             function(x,L75,scal)NULL)
nls(Correct/Trials ~ fp1(Loud, L75, scal), data = OME,
    start = c(L75=45, scal=3))
nls(Correct/Trials ~ fp1(Loud, L75, scal),
    data = OME[OME$Noise == "coherent",],
    start=c(L75=45, scal=3))
nls(Correct/Trials ~ fp1(Loud, L75, scal),
    data = OME[OME$Noise == "incoherent",],
    start = c(L75=45, scal=3))

# individual fits for each experiment

aa &lt;- factor(OME$Age)
ab &lt;- 10*OME$ID + unclass(aa)
ac &lt;- unclass(factor(ab))
OME$UID &lt;- as.vector(ac)
OME$UIDn &lt;- OME$UID + 0.1*(OME$Noise == "incoherent")
rm(aa, ab, ac)
OMEi &lt;- OME

library(nlme)
fp2 &lt;- deriv(~ 0.5 + 0.5/(1 + exp(-(x-L75)/2)),
            "L75", function(x,L75) NULL)
dec &lt;- getOption("OutDec")
options(show.error.messages = FALSE, OutDec=".")
OMEi.nls &lt;- nlsList(Correct/Trials ~ fp2(Loud, L75) | UIDn,
   data = OMEi, start = list(L75=45), control = list(maxiter=100))
options(show.error.messages = TRUE, OutDec=dec)
tmp &lt;- sapply(OMEi.nls, function(X)
              {if(is.null(X)) NA else as.vector(coef(X))})
OMEif &lt;- data.frame(UID = round(as.numeric((names(tmp)))),
         Noise = rep(c("coherent", "incoherent"), 110),
         L75 = as.vector(tmp), stringsAsFactors = TRUE)
OMEif$Age &lt;- OME$Age[match(OMEif$UID, OME$UID)]
OMEif$OME &lt;- OME$OME[match(OMEif$UID, OME$UID)]
OMEif &lt;- OMEif[OMEif$L75 &gt; 30,]
summary(lm(L75 ~ Noise/Age, data = OMEif, na.action = na.omit))
summary(lm(L75 ~ Noise/(Age + OME), data = OMEif,
           subset = (Age &gt;= 30 &amp; Age &lt;= 60),
           na.action = na.omit), correlation = FALSE)

# Or fit by weighted least squares
fpl75 &lt;- deriv(~ sqrt(n)*(r/n - 0.5 - 0.5/(1 + exp(-(x-L75)/scal))),
               c("L75", "scal"),
               function(r,n,x,L75,scal) NULL)
nls(0 ~ fpl75(Correct, Trials, Loud, L75, scal),
    data = OME[OME$Noise == "coherent",],
    start = c(L75=45, scal=3))
nls(0 ~ fpl75(Correct, Trials, Loud, L75, scal),
    data = OME[OME$Noise == "incoherent",],
    start = c(L75=45, scal=3))

# Test to see if the curves shift with age
fpl75age &lt;- deriv(~sqrt(n)*(r/n -  0.5 - 0.5/(1 +
                  exp(-(x-L75-slope*age)/scal))),
                  c("L75", "slope", "scal"),
                  function(r,n,x,age,L75,slope,scal) NULL)
OME.nls1 &lt;-
nls(0 ~ fpl75age(Correct, Trials, Loud, Age, L75, slope, scal),
    data = OME[OME$Noise == "coherent",],
    start = c(L75=45, slope=0, scal=2))
sqrt(diag(vcov(OME.nls1)))

OME.nls2 &lt;-
nls(0 ~ fpl75age(Correct, Trials, Loud, Age, L75, slope, scal),
    data = OME[OME$Noise == "incoherent",],
    start = c(L75=45, slope=0, scal=2))
sqrt(diag(vcov(OME.nls2)))

# Now allow random effects by using NLME
OMEf &lt;- OME[rep(1:nrow(OME), OME$Trials),]
OMEf$Resp &lt;- with(OME, rep(rep(c(1,0), length(Trials)),
                          t(cbind(Correct, Trials-Correct))))
OMEf &lt;- OMEf[, -match(c("Correct", "Trials"), names(OMEf))]

## Not run: ## these fail in R on most platforms
fp2 &lt;- deriv(~ 0.5 + 0.5/(1 + exp(-(x-L75)/exp(lsc))),
             c("L75", "lsc"),
             function(x, L75, lsc) NULL)
try(summary(nlme(Resp ~ fp2(Loud, L75, lsc),
     fixed = list(L75 ~ Age, lsc ~ 1),
     random = L75 + lsc ~ 1 | UID,
     data = OMEf[OMEf$Noise == "coherent",], method = "ML",
     start = list(fixed=c(L75=c(48.7, -0.03), lsc=0.24)), verbose = TRUE)))

try(summary(nlme(Resp ~ fp2(Loud, L75, lsc),
     fixed = list(L75 ~ Age, lsc ~ 1),
     random = L75 + lsc ~ 1 | UID,
     data = OMEf[OMEf$Noise == "incoherent",], method = "ML",
     start = list(fixed=c(L75=c(41.5, -0.1), lsc=0)), verbose = TRUE)))

## End(Not run)</code></pre>

<hr>
<h2 id='painters'>
The Painter's Data of de Piles
</h2><span id='topic+painters'></span>

<h3>Description</h3>

<p>The subjective assessment, on a 0 to 20 integer scale, of 54
classical painters.  The painters were assessed on four characteristics:
composition, drawing, colour and expression.  The data is due to the
Eighteenth century art critic, de Piles.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>painters
</code></pre>


<h3>Format</h3>

<p>The row names of the data frame are the painters. The components are:
</p>

<dl>
<dt><code>Composition</code></dt><dd>
<p>Composition score.
</p>
</dd>
<dt><code>Drawing</code></dt><dd>
<p>Drawing score.
</p>
</dd>
<dt><code>Colour</code></dt><dd>
<p>Colour score.
</p>
</dd>
<dt><code>Expression</code></dt><dd>
<p>Expression score.
</p>
</dd>
<dt><code>School</code></dt><dd>
<p>The school to which a painter belongs, as indicated by a factor level
code as follows:
<code>"A"</code>: Renaissance;
<code>"B"</code>: Mannerist;
<code>"C"</code>: Seicento;
<code>"D"</code>: Venetian;
<code>"E"</code>: Lombard;
<code>"F"</code>: Sixteenth Century;
<code>"G"</code>: Seventeenth Century;
<code>"H"</code>: French.
</p>
</dd>
</dl>



<h3>Source</h3>

<p>A. J. Weekes (1986)
<em>A Genstat Primer.</em> Edward Arnold.
</p>
<p>M. Davenport and G. Studdert-Kennedy (1972) The statistical
analysis of aesthetic judgement: an exploration.
<em>Applied Statistics</em> <b>21</b>,  324&ndash;333.
</p>
<p>I. T. Jolliffe (1986)
<em>Principal Component Analysis.</em> Springer.
</p>


<h3>References</h3>

<p>Venables, W. N. and Ripley, B. D. (2002)
<em>Modern Applied Statistics with S.</em> Fourth edition.  Springer.
</p>

<hr>
<h2 id='pairs.lda'>
Produce Pairwise Scatterplots from an 'lda' Fit
</h2><span id='topic+pairs.lda'></span>

<h3>Description</h3>

<p>Pairwise scatterplot of the data on the linear discriminants.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'lda'
pairs(x, labels = colnames(x), panel = panel.lda,
     dimen, abbrev = FALSE, ..., cex=0.7, type = c("std", "trellis"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pairs.lda_+3A_x">x</code></td>
<td>

<p>Object of class <code>"lda"</code>.
</p>
</td></tr>
<tr><td><code id="pairs.lda_+3A_labels">labels</code></td>
<td>

<p>vector of character strings for labelling the variables.
</p>
</td></tr>
<tr><td><code id="pairs.lda_+3A_panel">panel</code></td>
<td>

<p>panel function to plot the data in each panel.
</p>
</td></tr>
<tr><td><code id="pairs.lda_+3A_dimen">dimen</code></td>
<td>

<p>The number of linear discriminants to be used for the plot; if this
exceeds the number determined by <code>x</code> the smaller value is used.
</p>
</td></tr>
<tr><td><code id="pairs.lda_+3A_abbrev">abbrev</code></td>
<td>

<p>whether the group labels are abbreviated on the plots. If <code>abbrev &gt; 0</code>
this gives <code>minlength</code> in the call to <code>abbreviate</code>.
</p>
</td></tr>
<tr><td><code id="pairs.lda_+3A_...">...</code></td>
<td>

<p>additional arguments for <code>pairs.default</code>.
</p>
</td></tr>
<tr><td><code id="pairs.lda_+3A_cex">cex</code></td>
<td>

<p>graphics parameter <code>cex</code> for labels on plots.
</p>
</td></tr>
<tr><td><code id="pairs.lda_+3A_type">type</code></td>
<td>

<p>type of plot. The default is in the style of <code><a href="graphics.html#topic+pairs.default">pairs.default</a></code>; the
style <code>"trellis"</code> uses the Trellis function <code><a href="lattice.html#topic+splom">splom</a></code>.
</p>
</td></tr></table>


<h3>Details</h3>

<p>This function is a method for the generic function
<code>pairs()</code> for class <code>"lda"</code>.
It can be invoked by calling <code>pairs(x)</code> for an
object <code>x</code> of the appropriate class, or directly by
calling <code>pairs.lda(x)</code> regardless of the
class of the object.
</p>


<h3>References</h3>

<p>Venables, W. N. and Ripley, B. D. (2002)
<em>Modern Applied Statistics with S.</em> Fourth edition.  Springer.
</p>


<h3>See Also</h3>

<p><code><a href="graphics.html#topic+pairs">pairs</a></code>
</p>

<hr>
<h2 id='parcoord'>
Parallel Coordinates Plot
</h2><span id='topic+parcoord'></span>

<h3>Description</h3>

<p>Parallel coordinates plot
</p>


<h3>Usage</h3>

<pre><code class='language-R'>parcoord(x, col = 1, lty = 1, var.label = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="parcoord_+3A_x">x</code></td>
<td>

<p>a matrix or data frame who columns represent variables.  Missing values
are allowed.
</p>
</td></tr>
<tr><td><code id="parcoord_+3A_col">col</code></td>
<td>

<p>A vector of colours, recycled as necessary for each observation.
</p>
</td></tr>
<tr><td><code id="parcoord_+3A_lty">lty</code></td>
<td>

<p>A vector of line types, recycled as necessary for each observation.
</p>
</td></tr>
<tr><td><code id="parcoord_+3A_var.label">var.label</code></td>
<td>

<p>If <code>TRUE</code>, each variable's axis is labelled with maximum and
minimum values.
</p>
</td></tr>
<tr><td><code id="parcoord_+3A_...">...</code></td>
<td>

<p>Further graphics parameters which are passed to <code>matplot</code>.
</p>
</td></tr></table>


<h3>Side Effects</h3>

<p>a parallel coordinates plots is drawn.
</p>


<h3>Author(s)</h3>

<p>B. D. Ripley.  Enhancements based on ideas and code by Fabian Scheipl.
</p>


<h3>References</h3>

<p>Wegman, E. J. (1990) Hyperdimensional data analysis using parallel
coordinates.
<em>Journal of the American Statistical Association</em>
<b>85</b>, 664&ndash;675.
</p>
<p>Venables, W. N. and Ripley, B. D. (2002)
<em>Modern Applied Statistics with S.</em> Fourth edition.  Springer.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>parcoord(state.x77[, c(7, 4, 6, 2, 5, 3)])

ir &lt;- rbind(iris3[,,1], iris3[,,2], iris3[,,3])
parcoord(log(ir)[, c(3, 4, 2, 1)], col = 1 + (0:149)%/%50)
</code></pre>

<hr>
<h2 id='petrol'>
N. L. Prater's Petrol Refinery Data
</h2><span id='topic+petrol'></span>

<h3>Description</h3>

<p>The yield of a petroleum refining process with four covariates.
The crude oil appears to come from only 10 distinct samples.
</p>
<p>These data were originally used by Prater (1956) to
build an estimation equation for the yield of the refining
process of crude oil to gasoline.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>petrol
</code></pre>


<h3>Format</h3>

<p>The variables are as follows
</p>

<dl>
<dt><code>No</code></dt><dd>
<p>crude oil sample identification label. (Factor.)
</p>
</dd>
<dt><code>SG</code></dt><dd>
<p>specific gravity, degrees API.  (Constant within sample.)
</p>
</dd>
<dt><code>VP</code></dt><dd>
<p>vapour pressure in pounds per square inch. (Constant within sample.)
</p>
</dd>
<dt><code>V10</code></dt><dd>
<p>volatility of crude; ASTM 10% point. (Constant within sample.)
</p>
</dd>
<dt><code>EP</code></dt><dd>
<p>desired volatility of gasoline. (The end point.  Varies within sample.)
</p>
</dd>
<dt><code>Y</code></dt><dd>
<p>yield as a percentage of crude.
</p>
</dd>
</dl>



<h3>Source</h3>

<p>N. H. Prater (1956) Estimate gasoline yields from
crudes. <em>Petroleum Refiner</em> <b>35</b>, 236&ndash;238.
</p>
<p>This dataset is also given in
D. J. Hand, F. Daly, K. McConway, D. Lunn and E. Ostrowski (eds) (1994)
<em>A Handbook of Small Data Sets.</em> Chapman &amp; Hall.
</p>


<h3>References</h3>

<p>Venables, W. N. and Ripley, B. D. (2002)
<em>Modern Applied Statistics with S.</em> Fourth edition.  Springer.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(nlme)
Petrol &lt;- petrol
Petrol[, 2:5] &lt;- scale(as.matrix(Petrol[, 2:5]), scale = FALSE)
pet3.lme &lt;- lme(Y ~ SG + VP + V10 + EP,
                random = ~ 1 | No, data = Petrol)
pet3.lme &lt;- update(pet3.lme, method = "ML")
pet4.lme &lt;- update(pet3.lme, fixed. = Y ~ V10 + EP)
anova(pet4.lme, pet3.lme)
</code></pre>

<hr>
<h2 id='Pima.tr'>
Diabetes in Pima Indian Women
</h2><span id='topic+Pima.tr'></span><span id='topic+Pima.tr2'></span><span id='topic+Pima.te'></span>

<h3>Description</h3>

<p>A population of women who were at least 21 years old, of Pima Indian heritage
and living near Phoenix, Arizona, was tested for diabetes
according to World Health Organization criteria.  The data
were collected by the US National Institute of Diabetes and Digestive and
Kidney Diseases.  We used the 532 complete records after dropping the
(mainly missing) data on serum insulin.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Pima.tr
Pima.tr2
Pima.te
</code></pre>


<h3>Format</h3>

<p>These data frames contains the following columns:
</p>

<dl>
<dt><code>npreg</code></dt><dd>
<p>number of pregnancies.
</p>
</dd>
<dt><code>glu</code></dt><dd>
<p>plasma glucose concentration in an oral glucose tolerance test.
</p>
</dd>
<dt><code>bp</code></dt><dd>
<p>diastolic blood pressure (mm Hg).
</p>
</dd>
<dt><code>skin</code></dt><dd>
<p>triceps skin fold thickness (mm).
</p>
</dd>
<dt><code>bmi</code></dt><dd>
<p>body mass index (weight in kg/(height in m)<code class="reqn">^2</code>).
</p>
</dd>
<dt><code>ped</code></dt><dd>
<p>diabetes pedigree function.
</p>
</dd>
<dt><code>age</code></dt><dd>
<p>age in years.
</p>
</dd>
<dt><code>type</code></dt><dd>
<p><code>Yes</code> or <code>No</code>, for diabetic according to WHO criteria.
</p>
</dd>
</dl>



<h3>Details</h3>

<p>The training set <code>Pima.tr</code> contains a randomly selected set of 200
subjects, and <code>Pima.te</code> contains the remaining 332 subjects.
<code>Pima.tr2</code> contains <code>Pima.tr</code> plus 100 subjects with
missing values in the explanatory variables.
</p>


<h3>Source</h3>

<p>Smith, J. W., Everhart, J. E., Dickson, W. C., Knowler, W. C.
and Johannes, R. S. (1988)
Using the ADAP learning algorithm to forecast the onset of
<em>diabetes mellitus</em>.
In <em>Proceedings of the Symposium on Computer Applications in
Medical Care (Washington, 1988),</em> ed. R. A. Greenes,
pp. 261&ndash;265. Los Alamitos, CA: IEEE Computer Society Press.
</p>
<p>Ripley, B.D. (1996)
<em>Pattern Recognition and Neural Networks.</em>
Cambridge: Cambridge University Press.
</p>

<hr>
<h2 id='plot.lda'>
Plot Method for Class 'lda'
</h2><span id='topic+plot.lda'></span>

<h3>Description</h3>

<p>Plots a set of data on one, two or more linear discriminants.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'lda'
plot(x, panel = panel.lda, ..., cex = 0.7, dimen,
     abbrev = FALSE, xlab = "LD1", ylab = "LD2")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.lda_+3A_x">x</code></td>
<td>

<p>An object of class <code>"lda"</code>.
</p>
</td></tr>
<tr><td><code id="plot.lda_+3A_panel">panel</code></td>
<td>

<p>the panel function used to plot the data.
</p>
</td></tr>
<tr><td><code id="plot.lda_+3A_...">...</code></td>
<td>

<p>additional arguments to <code>pairs</code>, <code>ldahist</code> or <code>eqscplot</code>.
</p>
</td></tr>
<tr><td><code id="plot.lda_+3A_cex">cex</code></td>
<td>

<p>graphics parameter <code>cex</code> for labels on plots.
</p>
</td></tr>
<tr><td><code id="plot.lda_+3A_dimen">dimen</code></td>
<td>

<p>The number of linear discriminants to be used for the plot; if this
exceeds the number determined by <code>x</code> the smaller value is used.
</p>
</td></tr>
<tr><td><code id="plot.lda_+3A_abbrev">abbrev</code></td>
<td>

<p>whether the group labels are abbreviated on the plots. If <code>abbrev &gt; 0</code>
this gives <code>minlength</code> in the call to <code>abbreviate</code>.
</p>
</td></tr>
<tr><td><code id="plot.lda_+3A_xlab">xlab</code></td>
<td>

<p>label for the x axis
</p>
</td></tr>
<tr><td><code id="plot.lda_+3A_ylab">ylab</code></td>
<td>

<p>label for the y axis
</p>
</td></tr></table>


<h3>Details</h3>

<p>This function is a method for the generic function
<code>plot()</code> for class <code>"lda"</code>.
It can be invoked by calling <code>plot(x)</code> for an
object <code>x</code> of the appropriate class, or directly by
calling <code>plot.lda(x)</code> regardless of the
class of the object.
</p>
<p>The behaviour is determined by the value of <code>dimen</code>. For
<code>dimen &gt; 2</code>, a <code>pairs</code> plot is used. For <code>dimen = 2</code>, an
equiscaled scatter plot is drawn. For <code>dimen = 1</code>, a set of
histograms or density plots are drawn.  Use argument <code>type</code> to
match <code>"histogram"</code> or <code>"density"</code> or <code>"both"</code>.
</p>


<h3>References</h3>

<p>Venables, W. N. and Ripley, B. D. (2002)
<em>Modern Applied Statistics with S.</em> Fourth edition.  Springer.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pairs.lda">pairs.lda</a></code>, <code><a href="#topic+ldahist">ldahist</a></code>, <code><a href="#topic+lda">lda</a></code>, <code><a href="#topic+predict.lda">predict.lda</a></code>
</p>

<hr>
<h2 id='plot.mca'>
Plot Method for Objects of Class 'mca'
</h2><span id='topic+plot.mca'></span>

<h3>Description</h3>

<p>Plot a multiple correspondence analysis.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'mca'
plot(x, rows = TRUE, col, cex = par("cex"), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.mca_+3A_x">x</code></td>
<td>

<p>An object of class <code>"mca"</code>.
</p>
</td></tr>
<tr><td><code id="plot.mca_+3A_rows">rows</code></td>
<td>

<p>Should the coordinates for the rows be plotted, or just the vertices
for the levels?
</p>
</td></tr>
<tr><td><code id="plot.mca_+3A_col">col</code>, <code id="plot.mca_+3A_cex">cex</code></td>
<td>

<p>The colours and <code>cex</code> to be used for the row points and level vertices
respectively.
</p>
</td></tr>
<tr><td><code id="plot.mca_+3A_...">...</code></td>
<td>

<p>Additional parameters to <code>plot</code>.
</p>
</td></tr></table>


<h3>References</h3>

<p>Venables, W. N. and Ripley, B. D. (2002)
<em>Modern Applied Statistics with S.</em> Fourth edition.  Springer.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mca">mca</a></code>, <code><a href="#topic+predict.mca">predict.mca</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>plot(mca(farms, abbrev = TRUE))
</code></pre>

<hr>
<h2 id='polr'>
Ordered Logistic or Probit Regression
</h2><span id='topic+polr'></span>

<h3>Description</h3>

<p>Fits a logistic or probit regression model to an ordered factor
response.  The default logistic case is <em>proportional odds
logistic regression</em>, after which the function is named.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>polr(formula, data, weights, start, ..., subset, na.action,
     contrasts = NULL, Hess = FALSE, model = TRUE,
     method = c("logistic", "probit", "loglog", "cloglog", "cauchit"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="polr_+3A_formula">formula</code></td>
<td>

<p>a formula expression as for regression models, of the form
<code>response ~ predictors</code>. The response should be a factor
(preferably an ordered factor), which will be interpreted as an
ordinal response, with levels ordered as in the factor.  
The model must have an intercept: attempts to remove one will
lead to a warning and be ignored.  An offset may be used.  See the
documentation of <code><a href="stats.html#topic+formula">formula</a></code> for other details.
</p>
</td></tr>
<tr><td><code id="polr_+3A_data">data</code></td>
<td>

<p>an optional data frame, list or environment in which to interpret
the variables occurring in <code>formula</code>.
</p>
</td></tr>
<tr><td><code id="polr_+3A_weights">weights</code></td>
<td>

<p>optional case weights in fitting.  Default to 1.
</p>
</td></tr>
<tr><td><code id="polr_+3A_start">start</code></td>
<td>

<p>initial values for the parameters.  This is in the format
<code>c(coefficients, zeta)</code>: see the Values section.
</p>
</td></tr>
<tr><td><code id="polr_+3A_...">...</code></td>
<td>

<p>additional arguments to be passed to <code><a href="stats.html#topic+optim">optim</a></code>, most often a
<code>control</code> argument.
</p>
</td></tr>
<tr><td><code id="polr_+3A_subset">subset</code></td>
<td>

<p>expression saying which subset of the rows of the data should  be used
in the fit.  All observations are included by default.
</p>
</td></tr>
<tr><td><code id="polr_+3A_na.action">na.action</code></td>
<td>

<p>a function to filter missing data.
</p>
</td></tr>
<tr><td><code id="polr_+3A_contrasts">contrasts</code></td>
<td>

<p>a list of contrasts to be used for some or all of
the factors appearing as variables in the model formula.
</p>
</td></tr>
<tr><td><code id="polr_+3A_hess">Hess</code></td>
<td>

<p>logical for whether the Hessian (the observed information matrix)
should be returned.  Use this if you intend to call <code>summary</code> or
<code>vcov</code> on the fit.
</p>
</td></tr>
<tr><td><code id="polr_+3A_model">model</code></td>
<td>

<p>logical for whether the model matrix should be returned.
</p>
</td></tr>
<tr><td><code id="polr_+3A_method">method</code></td>
<td>

<p>logistic or probit or (complementary) log-log or cauchit
(corresponding to a Cauchy latent variable). 
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This model is what Agresti (2002) calls a <em>cumulative link</em>
model.  The basic interpretation is as a <em>coarsened</em> version of a
latent variable <code class="reqn">Y_i</code> which has a logistic or normal or
extreme-value or Cauchy distribution with scale parameter one and a
linear model for the mean.  The ordered factor which is observed is
which bin <code class="reqn">Y_i</code> falls into with breakpoints
</p>
<p style="text-align: center;"><code class="reqn">\zeta_0 = -\infty &lt; \zeta_1 &lt; \cdots &lt; \zeta_K = \infty</code>
</p>

<p>This leads to the model
</p>
<p style="text-align: center;"><code class="reqn">\mbox{logit} P(Y \le k | x) = \zeta_k - \eta</code>
</p>

<p>with <em>logit</em> replaced by <em>probit</em> for a normal latent
variable, and <code class="reqn">\eta</code> being the linear predictor, a linear
function of the explanatory variables (with no intercept).  Note
that it is quite common for other software to use the opposite sign
for <code class="reqn">\eta</code> (and hence the coefficients <code>beta</code>).
</p>
<p>In the logistic case, the left-hand side of the last display is the
log odds of category <code class="reqn">k</code> or less, and since these are log odds
which differ only by a constant for different <code class="reqn">k</code>, the odds are
proportional.  Hence the term <em>proportional odds logistic
regression</em>.
</p>
<p>The log-log and complementary log-log links are the increasing functions
<code class="reqn">F^{-1}(p) = -log(-log(p))</code> and
<code class="reqn">F^{-1}(p) = log(-log(1-p))</code>;
some call the first the &lsquo;negative log-log&rsquo; link.  These
correspond to a latent variable with the extreme-value distribution for
the maximum and minimum respectively.
</p>
<p>A <em>proportional hazards</em> model for grouped survival times can be
obtained by using the complementary log-log link with grouping ordered
by increasing times.
</p>
<p><code><a href="stats.html#topic+predict">predict</a></code>, <code><a href="base.html#topic+summary">summary</a></code>, <code><a href="stats.html#topic+vcov">vcov</a></code>,
<code><a href="stats.html#topic+anova">anova</a></code>, <code><a href="stats.html#topic+model.frame">model.frame</a></code> and an
<code>extractAIC</code> method for use with <code><a href="#topic+stepAIC">stepAIC</a></code> (and
<code><a href="stats.html#topic+step">step</a></code>).  There are also <code><a href="stats.html#topic+profile">profile</a></code> and
<code><a href="stats.html#topic+confint">confint</a></code> methods.
</p>


<h3>Value</h3>

<p>A object of class <code>"polr"</code>.  This has components
</p>
<table>
<tr><td><code>coefficients</code></td>
<td>
<p>the coefficients of the linear predictor, which has no
intercept.</p>
</td></tr>
<tr><td><code>zeta</code></td>
<td>
<p>the intercepts for the class boundaries.</p>
</td></tr>
<tr><td><code>deviance</code></td>
<td>
<p>the residual deviance.</p>
</td></tr>
<tr><td><code>fitted.values</code></td>
<td>
<p>a matrix, with a column for each level of the response.</p>
</td></tr>
<tr><td><code>lev</code></td>
<td>
<p>the names of the response levels.</p>
</td></tr>
<tr><td><code>terms</code></td>
<td>
<p>the <code>terms</code> structure describing the model.</p>
</td></tr>
<tr><td><code>df.residual</code></td>
<td>
<p>the number of residual degrees of freedoms,
calculated using the weights.</p>
</td></tr>
<tr><td><code>edf</code></td>
<td>
<p>the (effective) number of degrees of freedom used by the model</p>
</td></tr>
<tr><td><code>n</code>, <code>nobs</code></td>
<td>
<p>the (effective) number of observations, calculated using the
weights. (<code>nobs</code> is for use by <code><a href="#topic+stepAIC">stepAIC</a></code>.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the matched call.</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>the matched method used.</p>
</td></tr>
<tr><td><code>convergence</code></td>
<td>
<p>the convergence code returned by <code>optim</code>.</p>
</td></tr>
<tr><td><code>niter</code></td>
<td>
<p>the number of function and gradient evaluations used by
<code>optim</code>.</p>
</td></tr>
<tr><td><code>lp</code></td>
<td>
<p>the linear predictor (including any offset).</p>
</td></tr>
<tr><td><code>Hessian</code></td>
<td>
<p>(if <code>Hess</code> is true).  Note that this is a
numerical approximation derived from the optimization proces.</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>(if <code>model</code> is true).</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The <code><a href="stats.html#topic+vcov">vcov</a></code> method uses the approximate Hessian: for
reliable results the model matrix should be sensibly scaled with all
columns having range the order of one.
</p>
<p>Prior to version 7.3-32, <code>method = "cloglog"</code> confusingly gave
the log-log link, implicitly assuming the first response level was the
&lsquo;best&rsquo;.
</p>


<h3>References</h3>

<p>Agresti, A. (2002) <em>Categorical Data.</em> Second edition.  Wiley.
</p>
<p>Venables, W. N. and Ripley, B. D. (2002)
<em>Modern Applied Statistics with S.</em> Fourth edition.  Springer.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+optim">optim</a></code>, <code><a href="stats.html#topic+glm">glm</a></code>, <code><a href="nnet.html#topic+multinom">multinom</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>options(contrasts = c("contr.treatment", "contr.poly"))
house.plr &lt;- polr(Sat ~ Infl + Type + Cont, weights = Freq, data = housing)
house.plr
summary(house.plr, digits = 3)
## slightly worse fit from
summary(update(house.plr, method = "probit", Hess = TRUE), digits = 3)
## although it is not really appropriate, can fit
summary(update(house.plr, method = "loglog", Hess = TRUE), digits = 3)
summary(update(house.plr, method = "cloglog", Hess = TRUE), digits = 3)

predict(house.plr, housing, type = "p")
addterm(house.plr, ~.^2, test = "Chisq")
house.plr2 &lt;- stepAIC(house.plr, ~.^2)
house.plr2$anova
anova(house.plr, house.plr2)

house.plr &lt;- update(house.plr, Hess=TRUE)
pr &lt;- profile(house.plr)
confint(pr)
plot(pr)
pairs(pr)
</code></pre>

<hr>
<h2 id='predict.glmmPQL'>Predict Method for glmmPQL Fits</h2><span id='topic+predict.glmmPQL'></span>

<h3>Description</h3>

<p>Obtains predictions from a fitted generalized linear model
with random effects.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'glmmPQL'
predict(object, newdata = NULL, type = c("link", "response"),
       level, na.action = na.pass, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.glmmPQL_+3A_object">object</code></td>
<td>
<p>a fitted object of class inheriting from <code>"glmmPQL"</code>.</p>
</td></tr>
<tr><td><code id="predict.glmmPQL_+3A_newdata">newdata</code></td>
<td>
<p>optionally, a data frame in which to look for variables with
which to predict.</p>
</td></tr>
<tr><td><code id="predict.glmmPQL_+3A_type">type</code></td>
<td>
<p>the type of prediction required.  The default is on the
scale of the linear predictors; the alternative <code>"response"</code>
is on the scale of the response variable.  Thus for a default
binomial model the default predictions are of log-odds (probabilities
on logit scale) and <code>type = "response"</code> gives the predicted
probabilities.</p>
</td></tr>
<tr><td><code id="predict.glmmPQL_+3A_level">level</code></td>
<td>
<p>an optional integer vector giving the level(s) of grouping
to be used in obtaining the predictions. Level values increase from
outermost to innermost grouping, with level zero corresponding to the
population predictions. Defaults to the highest or innermost level of
grouping.</p>
</td></tr>  
<tr><td><code id="predict.glmmPQL_+3A_na.action">na.action</code></td>
<td>
<p>function determining what should be done with missing
values in <code>newdata</code>.  The default is to predict <code>NA</code>.</p>
</td></tr>
<tr><td><code id="predict.glmmPQL_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>If <code>level</code> is a single integer, a vector otherwise a data frame.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+glmmPQL">glmmPQL</a></code>, <code><a href="nlme.html#topic+predict.lme">predict.lme</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>fit &lt;- glmmPQL(y ~ trt + I(week &gt; 2), random = ~1 |  ID,
               family = binomial, data = bacteria)
predict(fit, bacteria, level = 0, type="response")
predict(fit, bacteria, level = 1, type="response")
</code></pre>

<hr>
<h2 id='predict.lda'>
Classify Multivariate Observations by Linear Discrimination
</h2><span id='topic+predict.lda'></span>

<h3>Description</h3>

<p>Classify multivariate observations in conjunction with <code>lda</code>, and also
project data onto the linear discriminants.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'lda'
predict(object, newdata, prior = object$prior, dimen,
        method = c("plug-in", "predictive", "debiased"), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.lda_+3A_object">object</code></td>
<td>

<p>object  of class <code>"lda"</code>
</p>
</td></tr>
<tr><td><code id="predict.lda_+3A_newdata">newdata</code></td>
<td>

<p>data frame of cases to be classified or, if <code>object</code>
has a formula, a data frame with columns of the same names as the
variables used.  A vector will be interpreted
as a row vector.  If newdata is missing, an attempt will be
made to retrieve the data used to fit the <code>lda</code> object.
</p>
</td></tr>
<tr><td><code id="predict.lda_+3A_prior">prior</code></td>
<td>

<p>The prior probabilities of the classes, by default the proportions in the
training set or what was set in the call to <code>lda</code>.
</p>
</td></tr>
<tr><td><code id="predict.lda_+3A_dimen">dimen</code></td>
<td>

<p>the dimension of the space to be used. If this is less than <code>min(p, ng-1)</code>,
only the first <code>dimen</code> discriminant components are used (except for
<code>method="predictive"</code>), and only those dimensions are returned in <code>x</code>.
</p>
</td></tr>
<tr><td><code id="predict.lda_+3A_method">method</code></td>
<td>

<p>This determines how the parameter estimation is handled. With <code>"plug-in"</code>
(the default) the usual unbiased parameter estimates are used and
assumed to be correct. With <code>"debiased"</code> an unbiased estimator of
the log posterior probabilities is used, and with <code>"predictive"</code> the
parameter estimates are integrated out using a vague prior.
</p>
</td></tr>
<tr><td><code id="predict.lda_+3A_...">...</code></td>
<td>

<p>arguments based from or to other methods
</p>
</td></tr></table>


<h3>Details</h3>

<p>This function is a method for the generic function <code>predict()</code> for
class <code>"lda"</code>.  It can be invoked by calling <code>predict(x)</code> for
an object <code>x</code> of the appropriate class, or directly by calling
<code>predict.lda(x)</code> regardless of the class of the object.
</p>
<p>Missing values in <code>newdata</code> are handled by returning <code>NA</code> if the
linear discriminants cannot be evaluated. If <code>newdata</code> is omitted and
the <code>na.action</code> of the fit omitted cases, these will be omitted on the
prediction.
</p>
<p>This version centres the linear discriminants so that the
weighted mean (weighted by <code>prior</code>) of the group centroids is at
the origin.
</p>


<h3>Value</h3>

<p>a list with components
</p>
<table>
<tr><td><code>class</code></td>
<td>

<p>The MAP classification (a factor)
</p>
</td></tr>
<tr><td><code>posterior</code></td>
<td>

<p>posterior probabilities for the classes
</p>
</td></tr>
<tr><td><code>x</code></td>
<td>

<p>the scores of test cases on up to <code>dimen</code> discriminant variables
</p>
</td></tr></table>


<h3>References</h3>

<p>Venables, W. N. and Ripley, B. D. (2002)
<em>Modern Applied Statistics with S.</em> Fourth edition.  Springer.
</p>
<p>Ripley, B. D. (1996)
<em>Pattern Recognition and Neural Networks</em>. Cambridge University Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lda">lda</a></code>, <code><a href="#topic+qda">qda</a></code>, <code><a href="#topic+predict.qda">predict.qda</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>tr &lt;- sample(1:50, 25)
train &lt;- rbind(iris3[tr,,1], iris3[tr,,2], iris3[tr,,3])
test &lt;- rbind(iris3[-tr,,1], iris3[-tr,,2], iris3[-tr,,3])
cl &lt;- factor(c(rep("s",25), rep("c",25), rep("v",25)))
z &lt;- lda(train, cl)
predict(z, test)$class
</code></pre>

<hr>
<h2 id='predict.lqs'>
Predict from an lqs Fit
</h2><span id='topic+predict.lqs'></span>

<h3>Description</h3>

<p>Predict from an resistant regression fitted by <code>lqs</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'lqs'
predict(object, newdata, na.action = na.pass, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.lqs_+3A_object">object</code></td>
<td>

<p>object inheriting from class <code>"lqs"</code>
</p>
</td></tr>
<tr><td><code id="predict.lqs_+3A_newdata">newdata</code></td>
<td>

<p>matrix or data frame of cases to be predicted or, if <code>object</code>
has a formula, a data frame with columns of the same names as the
variables used.  A vector will be interpreted
as a row vector.  If <code>newdata</code> is missing, an attempt will be
made to retrieve the data used to fit the <code>lqs</code> object.
</p>
</td></tr>
<tr><td><code id="predict.lqs_+3A_na.action">na.action</code></td>
<td>
<p>function determining what should be done with missing
values in <code>newdata</code>.  The default is to predict <code>NA</code>.</p>
</td></tr>
<tr><td><code id="predict.lqs_+3A_...">...</code></td>
<td>
<p>arguments to be passed from or to other methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is a method for the generic function
<code>predict()</code> for class <code>lqs</code>.
It can be invoked by calling <code>predict(x)</code> for an
object <code>x</code> of the appropriate class, or directly by
calling <code>predict.lqs(x)</code> regardless of the
class of the object.
</p>
<p>Missing values in <code>newdata</code> are handled by returning <code>NA</code> if the
linear fit cannot be evaluated. If <code>newdata</code> is omitted and
the <code>na.action</code> of the fit omitted cases, these will be omitted on the
prediction.
</p>


<h3>Value</h3>

<p>A vector of predictions.
</p>


<h3>Author(s)</h3>

<p>B.D. Ripley</p>


<h3>See Also</h3>

<p><code><a href="#topic+lqs">lqs</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(123)
fm &lt;- lqs(stack.loss ~ ., data = stackloss, method = "S", nsamp = "exact")
predict(fm, stackloss)
</code></pre>

<hr>
<h2 id='predict.mca'>
Predict Method for Class 'mca'
</h2><span id='topic+predict.mca'></span>

<h3>Description</h3>

<p>Used to compute coordinates for additional rows or additional factors
in a multiple correspondence analysis.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'mca'
predict(object, newdata, type = c("row", "factor"), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.mca_+3A_object">object</code></td>
<td>

<p>An object of class <code>"mca"</code>, usually the result of a call to <code>mca</code>.
</p>
</td></tr>
<tr><td><code id="predict.mca_+3A_newdata">newdata</code></td>
<td>

<p>A data frame containing <em>either</em> additional rows of the factors used to
fit <code>object</code> <em>or</em> additional factors for the cases used in the
original fit.
</p>
</td></tr>
<tr><td><code id="predict.mca_+3A_type">type</code></td>
<td>

<p>Are predictions required for further rows or for new factors?
</p>
</td></tr>
<tr><td><code id="predict.mca_+3A_...">...</code></td>
<td>

<p>Additional arguments from <code>predict</code>: unused.
</p>
</td></tr></table>


<h3>Value</h3>

<p>If <code>type = "row"</code>, the coordinates for the additional rows.
</p>
<p>If <code>type = "factor"</code>, the coordinates of the column vertices for the
levels of the new factors.
</p>


<h3>References</h3>

<p>Venables, W. N. and Ripley, B. D. (2002)
<em>Modern Applied Statistics with S.</em> Fourth edition.  Springer.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mca">mca</a></code>, <code><a href="#topic+plot.mca">plot.mca</a></code>
</p>

<hr>
<h2 id='predict.qda'>
Classify from Quadratic Discriminant Analysis
</h2><span id='topic+predict.qda'></span>

<h3>Description</h3>

<p>Classify multivariate observations in conjunction with <code>qda</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'qda'
predict(object, newdata, prior = object$prior,
        method = c("plug-in", "predictive", "debiased", "looCV"), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.qda_+3A_object">object</code></td>
<td>

<p>object of class <code>"qda"</code>
</p>
</td></tr>
<tr><td><code id="predict.qda_+3A_newdata">newdata</code></td>
<td>

<p>data frame of cases to be classified or, if <code>object</code>
has a formula, a data frame with columns of the same names as the
variables used.  A vector will be interpreted
as a row vector.  If newdata is missing, an attempt will be
made to retrieve the data used to fit the <code>qda</code> object.
</p>
</td></tr>
<tr><td><code id="predict.qda_+3A_prior">prior</code></td>
<td>

<p>The prior probabilities of the classes, by default the proportions in the
training set or what was set in the call to <code>qda</code>.
</p>
</td></tr>
<tr><td><code id="predict.qda_+3A_method">method</code></td>
<td>

<p>This determines how the parameter estimation is handled. With <code>"plug-in"</code>
(the default) the usual unbiased parameter estimates are used and
assumed to be correct. With <code>"debiased"</code> an unbiased estimator of
the log posterior probabilities is used, and with <code>"predictive"</code> the
parameter estimates are integrated out using a vague prior.  With
<code>"looCV"</code> the leave-one-out cross-validation fits to the original
dataset are computed and returned.
</p>
</td></tr>
<tr><td><code id="predict.qda_+3A_...">...</code></td>
<td>

<p>arguments based from or to other methods
</p>
</td></tr></table>


<h3>Details</h3>

<p>This function is a method for the generic function
<code>predict()</code> for class <code>"qda"</code>.
It can be invoked by calling <code>predict(x)</code> for an
object <code>x</code> of the appropriate class, or directly by
calling <code>predict.qda(x)</code> regardless of the
class of the object.
</p>
<p>Missing values in <code>newdata</code> are handled by returning <code>NA</code> if the
quadratic discriminants cannot be evaluated. If <code>newdata</code> is omitted and
the <code>na.action</code> of the fit omitted cases, these will be omitted on the
prediction.
</p>


<h3>Value</h3>

<p>a list with components
</p>
<table>
<tr><td><code>class</code></td>
<td>

<p>The MAP classification (a factor)
</p>
</td></tr>
<tr><td><code>posterior</code></td>
<td>

<p>posterior probabilities for the classes
</p>
</td></tr></table>


<h3>References</h3>

<p>Venables, W. N. and Ripley, B. D. (2002)
<em>Modern Applied Statistics with S.</em> Fourth edition.  Springer.
</p>
<p>Ripley, B. D. (1996)
<em>Pattern Recognition and Neural Networks</em>. Cambridge University Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+qda">qda</a></code>, <code><a href="#topic+lda">lda</a></code>, <code><a href="#topic+predict.lda">predict.lda</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>tr &lt;- sample(1:50, 25)
train &lt;- rbind(iris3[tr,,1], iris3[tr,,2], iris3[tr,,3])
test &lt;- rbind(iris3[-tr,,1], iris3[-tr,,2], iris3[-tr,,3])
cl &lt;- factor(c(rep("s",25), rep("c",25), rep("v",25)))
zq &lt;- qda(train, cl)
predict(zq, test)$class
</code></pre>

<hr>
<h2 id='profile.glm'>Method for Profiling glm Objects</h2><span id='topic+profile.glm'></span>

<h3>Description</h3>

<p>Investigates the profile log-likelihood function for a fitted model of
class <code>"glm"</code>.
</p>
<p>As from <span class="rlang"><b>R</b></span> 4.4.0 was migrated to package <span class="pkg">stats</span> with additional
functionality.
</p>

<hr>
<h2 id='qda'>
Quadratic Discriminant Analysis
</h2><span id='topic+qda'></span><span id='topic+qda.data.frame'></span><span id='topic+qda.default'></span><span id='topic+qda.formula'></span><span id='topic+qda.matrix'></span><span id='topic+model.frame.qda'></span><span id='topic+print.qda'></span>

<h3>Description</h3>

<p>Quadratic discriminant analysis.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>qda(x, ...)

## S3 method for class 'formula'
qda(formula, data, ..., subset, na.action)

## Default S3 method:
qda(x, grouping, prior = proportions,
    method, CV = FALSE, nu, ...)

## S3 method for class 'data.frame'
qda(x, ...)

## S3 method for class 'matrix'
qda(x, grouping, ..., subset, na.action)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="qda_+3A_formula">formula</code></td>
<td>

<p>A formula of the form <code>groups ~ x1 + x2 + ...</code>  That is, the
response is the grouping factor and the right hand side specifies
the (non-factor) discriminators.
</p>
</td></tr>
<tr><td><code id="qda_+3A_data">data</code></td>
<td>

<p>An optional data frame, list or environment from which variables
specified in <code>formula</code> are preferentially to be taken.
</p>
</td></tr>
<tr><td><code id="qda_+3A_x">x</code></td>
<td>

<p>(required if no formula is given as the principal argument.)
a matrix or data frame or Matrix containing the explanatory variables.
</p>
</td></tr>
<tr><td><code id="qda_+3A_grouping">grouping</code></td>
<td>

<p>(required if no formula principal argument is given.)
a factor specifying the class for each observation.
</p>
</td></tr>
<tr><td><code id="qda_+3A_prior">prior</code></td>
<td>

<p>the prior probabilities of class membership.  If unspecified, the class
proportions for the training set are used.  If specified, the
probabilities should be specified in the order of the factor levels.
</p>
</td></tr>
<tr><td><code id="qda_+3A_subset">subset</code></td>
<td>

<p>An index vector specifying the cases to be used in the training
sample.  (NOTE: If given, this argument must be named.)
</p>
</td></tr>
<tr><td><code id="qda_+3A_na.action">na.action</code></td>
<td>

<p>A function to specify the action to be taken if <code>NA</code>s are found.
The default action is for the procedure to fail.  An alternative is
na.omit, which leads to rejection of cases with missing values on
any required variable.  (NOTE: If given, this argument must be named.)
</p>
</td></tr>
<tr><td><code id="qda_+3A_method">method</code></td>
<td>

<p><code>"moment"</code> for standard estimators of the mean and variance,
<code>"mle"</code> for MLEs, <code>"mve"</code> to use <code>cov.mve</code>, or <code>"t"</code> for robust
estimates based on a t distribution.
</p>
</td></tr>
<tr><td><code id="qda_+3A_cv">CV</code></td>
<td>

<p>If true, returns results (classes and posterior probabilities) for
leave-out-out cross-validation. Note that if the prior is estimated,
the proportions in the whole dataset are used.
</p>
</td></tr>
<tr><td><code id="qda_+3A_nu">nu</code></td>
<td>

<p>degrees of freedom for <code>method = "t"</code>.
</p>
</td></tr>
<tr><td><code id="qda_+3A_...">...</code></td>
<td>

<p>arguments passed to or from other methods.
</p>
</td></tr></table>


<h3>Details</h3>

<p>Uses a QR decomposition which will give an error message if the
within-group variance is singular for any group.
</p>


<h3>Value</h3>

<p>an object of class <code>"qda"</code> containing the following components:
</p>
<table>
<tr><td><code>prior</code></td>
<td>

<p>the prior probabilities used.
</p>
</td></tr>
<tr><td><code>means</code></td>
<td>

<p>the group means.
</p>
</td></tr>
<tr><td><code>scaling</code></td>
<td>

<p>for each group <code>i</code>, <code>scaling[,,i]</code> is an array which transforms observations
so that within-groups covariance matrix is spherical.
</p>
</td></tr>
<tr><td><code>ldet</code></td>
<td>

<p>a vector of half log determinants of the dispersion matrix.
</p>
</td></tr>
<tr><td><code>lev</code></td>
<td>

<p>the levels of the grouping factor.
</p>
</td></tr>
<tr><td><code>terms</code></td>
<td>

<p>(if formula is a formula)
an object of mode expression and class term summarizing
the  formula.
</p>
</td></tr>
<tr><td><code>call</code></td>
<td>

<p>the (matched) function call.
</p>
</td></tr>
</table>
<p>unless <code>CV=TRUE</code>, when the return value is a list with components:
</p>
<table>
<tr><td><code>class</code></td>
<td>

<p>The MAP classification (a factor)
</p>
</td></tr>
<tr><td><code>posterior</code></td>
<td>

<p>posterior probabilities for the classes
</p>
</td></tr></table>


<h3>References</h3>

<p>Venables, W. N. and Ripley, B. D. (2002)
<em>Modern Applied Statistics with S.</em> Fourth edition.  Springer.
</p>
<p>Ripley, B. D. (1996)
<em>Pattern Recognition and Neural Networks</em>. Cambridge University Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+predict.qda">predict.qda</a></code>, <code><a href="#topic+lda">lda</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>tr &lt;- sample(1:50, 25)
train &lt;- rbind(iris3[tr,,1], iris3[tr,,2], iris3[tr,,3])
test &lt;- rbind(iris3[-tr,,1], iris3[-tr,,2], iris3[-tr,,3])
cl &lt;- factor(c(rep("s",25), rep("c",25), rep("v",25)))
z &lt;- qda(train, cl)
predict(z,test)$class
</code></pre>

<hr>
<h2 id='quine'>
Absenteeism from School in Rural New South Wales
</h2><span id='topic+quine'></span>

<h3>Description</h3>

<p>The <code>quine</code> data frame has 146 rows and 5 columns.
Children from Walgett, New South Wales, Australia, were classified by
Culture, Age, Sex and Learner status and the number of days absent from
school in a particular school year was recorded.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>quine
</code></pre>


<h3>Format</h3>

<p>This data frame contains the following columns:
</p>

<dl>
<dt><code>Eth</code></dt><dd>
<p>ethnic background: Aboriginal or Not, (<code>"A"</code> or <code>"N"</code>).
</p>
</dd>
<dt><code>Sex</code></dt><dd>
<p>sex: factor with levels (<code>"F"</code> or <code>"M"</code>).
</p>
</dd>
<dt><code>Age</code></dt><dd>
<p>age group: Primary (<code>"F0"</code>), or forms <code>"F1,"</code>
<code>"F2"</code> or <code>"F3"</code>.
</p>
</dd>
<dt><code>Lrn</code></dt><dd>
<p>learner status: factor with levels Average or Slow learner, (<code>"AL"</code> or
<code>"SL"</code>).
</p>
</dd>
<dt><code>Days</code></dt><dd>
<p>days absent from school in the year.
</p>
</dd>
</dl>



<h3>Source</h3>

<p>S. Quine, quoted in Aitkin, M. (1978) The analysis of unbalanced cross
classifications (with discussion).
<em>Journal of the Royal Statistical Society series A</em> <b>141</b>, 195&ndash;223.
</p>


<h3>References</h3>

<p>Venables, W. N. and Ripley, B. D. (2002)
<em>Modern Applied Statistics with S.</em> Fourth edition.  Springer.
</p>

<hr>
<h2 id='Rabbit'>
Blood Pressure in Rabbits
</h2><span id='topic+Rabbit'></span>

<h3>Description</h3>

<p>Five rabbits were studied on two occasions, after treatment with
saline (control) and after treatment with the <code class="reqn">5-HT_3</code> antagonist MDL
72222.  After each treatment ascending doses of phenylbiguanide were
injected intravenously at 10 minute intervals and the responses of
mean blood pressure measured.  The goal was to test whether the
cardiogenic chemoreflex elicited by phenylbiguanide depends on the
activation of <code class="reqn">5-HT_3</code> receptors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Rabbit
</code></pre>


<h3>Format</h3>

<p>This data frame contains 60 rows and the following variables:
</p>

<dl>
<dt><code>BPchange</code></dt><dd>
<p>change in blood pressure relative to the start of the experiment.
</p>
</dd>
<dt><code>Dose</code></dt><dd>
<p>dose of Phenylbiguanide in micrograms.
</p>
</dd>
<dt><code>Run</code></dt><dd>
<p>label of run (<code>"C1"</code> to <code>"C5"</code>, then <code>"M1"</code> to <code>"M5"</code>).
</p>
</dd>
<dt><code>Treatment</code></dt><dd>
<p>placebo or the <code class="reqn">5-HT_3</code> antagonist MDL 72222.
</p>
</dd>
<dt><code>Animal</code></dt><dd>
<p>label of animal used (<code>"R1"</code> to <code>"R5"</code>).
</p>
</dd>
</dl>



<h3>Source</h3>

<p>J. Ludbrook (1994)
Repeated measurements and multiple comparisons in cardiovascular research.
<em>Cardiovascular Research</em>
<b>28</b>, 303&ndash;311.<br />
[The numerical data are not in the paper but were supplied by
Professor Ludbrook]
</p>


<h3>References</h3>

<p>Venables, W. N. and Ripley, B. D. (2002)
<em>Modern Applied Statistics with S.</em> Fourth edition.  Springer.
</p>

<hr>
<h2 id='rational'>
Rational Approximation
</h2><span id='topic+rational'></span><span id='topic+.rat'></span>

<h3>Description</h3>

<p>Find rational approximations to the components of a real numeric
object using a standard continued fraction method.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rational(x, cycles = 10, max.denominator = 2000, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rational_+3A_x">x</code></td>
<td>

<p>Any object of mode numeric. Missing values are now allowed.
</p>
</td></tr>
<tr><td><code id="rational_+3A_cycles">cycles</code></td>
<td>

<p>The maximum number of steps to be used in the continued fraction
approximation process.
</p>
</td></tr>
<tr><td><code id="rational_+3A_max.denominator">max.denominator</code></td>
<td>

<p>An early termination criterion.  If any partial denominator
exceeds <code>max.denominator</code> the continued fraction stops at that point.
</p>
</td></tr>
<tr><td><code id="rational_+3A_...">...</code></td>
<td>

<p>arguments passed to or from other methods.
</p>
</td></tr></table>


<h3>Details</h3>

<p>Each component is first expanded in a continued fraction of the
form
</p>
<p><code>x = floor(x) + 1/(p1 + 1/(p2 + ...)))</code>
</p>
<p>where <code>p1</code>, <code>p2</code>, ... are positive integers, terminating either
at <code>cycles</code> terms or when a <code>pj &gt; max.denominator</code>.  The
continued fraction is then re-arranged to retrieve the numerator
and denominator as integers and the ratio returned as the value.
</p>


<h3>Value</h3>

<p>A numeric object with the same attributes as <code>x</code> but with entries
rational approximations to the values.  This effectively rounds
relative to the size of the object and replaces very small
entries by zero.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+fractions">fractions</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>X &lt;- matrix(runif(25), 5, 5)
zapsmall(solve(X, X/5)) # print near-zeroes as zero
rational(solve(X, X/5))
</code></pre>

<hr>
<h2 id='renumerate'>
Convert a Formula Transformed by 'denumerate'
</h2><span id='topic+renumerate'></span><span id='topic+renumerate.formula'></span>

<h3>Description</h3>

<p><code><a href="#topic+denumerate">denumerate</a></code> converts a formula written using the conventions of
<code><a href="#topic+loglm">loglm</a></code> into one that <code><a href="stats.html#topic+terms">terms</a></code> is able to process.  <code>renumerate</code>
converts it back again to a form like the original.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>renumerate(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="renumerate_+3A_x">x</code></td>
<td>

<p>A formula, normally as modified by <code><a href="#topic+denumerate">denumerate</a></code>.
</p>
</td></tr></table>


<h3>Details</h3>

<p>This is an inverse function to <code><a href="#topic+denumerate">denumerate</a></code>.  It is only needed
since <code><a href="stats.html#topic+terms">terms</a></code> returns an expanded form of the original formula
where the non-marginal terms are exposed.  This expanded form is
mapped back into a form corresponding to the one that the user
originally supplied.
</p>


<h3>Value</h3>

<p>A formula where all variables with names of the form <code>.vn</code>, where
<code>n</code> is an integer, converted to numbers, <code>n</code>, as allowed by the
formula conventions of <code><a href="#topic+loglm">loglm</a></code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+denumerate">denumerate</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>denumerate(~(1+2+3)^3 + a/b)
## ~ (.v1 + .v2 + .v3)^3 + a/b
renumerate(.Last.value)
## ~ (1 + 2 + 3)^3 + a/b
</code></pre>

<hr>
<h2 id='rlm'>
Robust Fitting of Linear Models
</h2><span id='topic+rlm'></span><span id='topic+rlm.default'></span><span id='topic+rlm.formula'></span><span id='topic+print.rlm'></span><span id='topic+predict.rlm'></span><span id='topic+psi.bisquare'></span><span id='topic+psi.hampel'></span><span id='topic+psi.huber'></span>

<h3>Description</h3>

<p>Fit a linear model by robust regression using an M estimator.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rlm(x, ...)

## S3 method for class 'formula'
rlm(formula, data, weights, ..., subset, na.action,
    method = c("M", "MM", "model.frame"),
    wt.method = c("inv.var", "case"),
    model = TRUE, x.ret = TRUE, y.ret = FALSE, contrasts = NULL)

## Default S3 method:
rlm(x, y, weights, ..., w = rep(1, nrow(x)),
    init = "ls", psi = psi.huber,
    scale.est = c("MAD", "Huber", "proposal 2"), k2 = 1.345,
    method = c("M", "MM"), wt.method = c("inv.var", "case"),
    maxit = 20, acc = 1e-4, test.vec = "resid", lqs.control = NULL)

psi.huber(u, k = 1.345, deriv = 0)
psi.hampel(u, a = 2, b = 4, c = 8, deriv = 0)
psi.bisquare(u, c = 4.685, deriv = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rlm_+3A_formula">formula</code></td>
<td>

<p>a formula of the form <code>y ~ x1 + x2 + ...</code>.
</p>
</td></tr>
<tr><td><code id="rlm_+3A_data">data</code></td>
<td>

<p>an optional data frame, list or environment from which variables
specified in <code>formula</code> are preferentially to be taken.
</p>
</td></tr>
<tr><td><code id="rlm_+3A_weights">weights</code></td>
<td>

<p>a vector of prior weights for each case.
</p>
</td></tr>
<tr><td><code id="rlm_+3A_subset">subset</code></td>
<td>

<p>An index vector specifying the cases to be used in fitting.
</p>
</td></tr>
<tr><td><code id="rlm_+3A_na.action">na.action</code></td>
<td>

<p>A function to specify the action to be taken if <code>NA</code>s are found.
The &lsquo;factory-fresh&rsquo; default action in <span class="rlang"><b>R</b></span> is
<code><a href="stats.html#topic+na.omit">na.omit</a></code>, and can be changed by
<code><a href="base.html#topic+options">options</a>(na.action=)</code>.
</p>
</td></tr>
<tr><td><code id="rlm_+3A_x">x</code></td>
<td>

<p>a matrix or data frame containing the explanatory variables.
</p>
</td></tr>
<tr><td><code id="rlm_+3A_y">y</code></td>
<td>

<p>the response: a vector of length the number of rows of <code>x</code>.
</p>
</td></tr>
<tr><td><code id="rlm_+3A_method">method</code></td>
<td>

<p>currently either M-estimation or MM-estimation or (for the
<code>formula</code> method only) find the model frame.  MM-estimation
is M-estimation with Tukey's biweight initialized by a specific
S-estimator.  See the &lsquo;Details&rsquo; section.
</p>
</td></tr>
<tr><td><code id="rlm_+3A_wt.method">wt.method</code></td>
<td>

<p>are the weights case weights (giving the relative importance of case,
so a weight of 2 means there are two of these) or the inverse of the
variances, so a weight of two means this error is half as variable?
</p>
</td></tr>
<tr><td><code id="rlm_+3A_model">model</code></td>
<td>

<p>should the model frame be returned in the object?
</p>
</td></tr>
<tr><td><code id="rlm_+3A_x.ret">x.ret</code></td>
<td>

<p>should the model matrix be returned in the object?
</p>
</td></tr>
<tr><td><code id="rlm_+3A_y.ret">y.ret</code></td>
<td>

<p>should the response be returned in the object?
</p>
</td></tr>
<tr><td><code id="rlm_+3A_contrasts">contrasts</code></td>
<td>

<p>optional contrast specifications: see <code><a href="stats.html#topic+lm">lm</a></code>.
</p>
</td></tr>
<tr><td><code id="rlm_+3A_w">w</code></td>
<td>

<p>(optional) initial down-weighting for each case.
</p>
</td></tr>
<tr><td><code id="rlm_+3A_init">init</code></td>
<td>

<p>(optional) initial values for the coefficients OR a method to find
initial values OR the result of a fit with a <code>coef</code> component.  Known
methods are <code>"ls"</code> (the default) for an initial least-squares fit
using weights <code>w*weights</code>, and <code>"lts"</code> for an unweighted
least-trimmed squares fit with 200 samples.
</p>
</td></tr>
<tr><td><code id="rlm_+3A_psi">psi</code></td>
<td>

<p>the psi function is specified by this argument.  It must give
(possibly by name) a function <code>g(x, ..., deriv)</code> that for
<code>deriv=0</code> returns psi(x)/x and for <code>deriv=1</code> returns
psi'(x).  Tuning constants will be passed in via <code>...</code>.
</p>
</td></tr>
<tr><td><code id="rlm_+3A_scale.est">scale.est</code></td>
<td>

<p>method of scale estimation: re-scaled MAD of the residuals (default)
or Huber's proposal 2 (which can be selected by either <code>"Huber"</code>
or <code>"proposal 2"</code>).
</p>
</td></tr>
<tr><td><code id="rlm_+3A_k2">k2</code></td>
<td>

<p>tuning constant used for Huber proposal 2 scale estimation.
</p>
</td></tr>
<tr><td><code id="rlm_+3A_maxit">maxit</code></td>
<td>

<p>the limit on the number of IWLS iterations.
</p>
</td></tr>
<tr><td><code id="rlm_+3A_acc">acc</code></td>
<td>

<p>the accuracy for the stopping criterion.
</p>
</td></tr>
<tr><td><code id="rlm_+3A_test.vec">test.vec</code></td>
<td>

<p>the stopping criterion is based on changes in this vector.
</p>
</td></tr>
<tr><td><code id="rlm_+3A_...">...</code></td>
<td>

<p>additional arguments to be passed to <code>rlm.default</code> or to the <code>psi</code>
function.
</p>
</td></tr>
<tr><td><code id="rlm_+3A_lqs.control">lqs.control</code></td>
<td>

<p>An optional list of control values for <code><a href="#topic+lqs">lqs</a></code>.
</p>
</td></tr>
<tr><td><code id="rlm_+3A_u">u</code></td>
<td>

<p>numeric vector of evaluation points.
</p>
</td></tr>
<tr><td><code id="rlm_+3A_k">k</code>, <code id="rlm_+3A_a">a</code>, <code id="rlm_+3A_b">b</code>, <code id="rlm_+3A_c">c</code></td>
<td>

<p>tuning constants.
</p>
</td></tr>
<tr><td><code id="rlm_+3A_deriv">deriv</code></td>
<td>

<p><code>0</code> or <code>1</code>: compute values of the psi function or of its
first derivative.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Fitting is done by iterated re-weighted least squares (IWLS).
</p>
<p>Psi functions are supplied for the Huber, Hampel and Tukey bisquare
proposals as <code>psi.huber</code>, <code>psi.hampel</code> and
<code>psi.bisquare</code>. Huber's corresponds to a convex optimization
problem and gives a unique solution (up to collinearity). The other
two will have multiple local minima, and a good starting point is
desirable.
</p>
<p>Selecting <code>method = "MM"</code> selects a specific set of options which
ensures that the estimator has a high breakdown point. The initial set
of coefficients and the final scale are selected by an S-estimator
with <code>k0 = 1.548</code>; this gives (for <code class="reqn">n \gg p</code>)
breakdown point 0.5.
The final estimator is an M-estimator with Tukey's biweight and fixed
scale that will inherit this breakdown point provided <code>c &gt; k0</code>;
this is true for the default value of <code>c</code> that corresponds to
95% relative efficiency at the normal.  Case weights are not
supported for <code>method = "MM"</code>.
</p>


<h3>Value</h3>

<p>An object of class <code>"rlm"</code> inheriting from <code>"lm"</code>.
Note that the <code>df.residual</code> component is deliberately set to
<code>NA</code> to avoid inappropriate estimation of the residual scale from
the residual mean square by <code>"lm"</code> methods.
</p>
<p>The additional components not in an <code>lm</code> object are
</p>
<table>
<tr><td><code>s</code></td>
<td>

<p>the robust scale estimate used
</p>
</td></tr>
<tr><td><code>w</code></td>
<td>

<p>the weights used in the IWLS process
</p>
</td></tr>
<tr><td><code>psi</code></td>
<td>

<p>the psi function with parameters substituted
</p>
</td></tr>
<tr><td><code>conv</code></td>
<td>

<p>the convergence criteria at each iteration
</p>
</td></tr>
<tr><td><code>converged</code></td>
<td>

<p>did the IWLS converge?
</p>
</td></tr>
<tr><td><code>wresid</code></td>
<td>

<p>a working residual, weighted for <code>"inv.var"</code> weights only.
</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Prior to version <code>7.3-52</code>, offset terms in <code>formula</code>
were omitted from fitted and predicted values.
</p>


<h3>References</h3>

<p>P. J. Huber (1981)
<em>Robust Statistics</em>.
Wiley.
</p>
<p>F. R. Hampel, E. M. Ronchetti, P. J. Rousseeuw and W. A. Stahel (1986)
<em>Robust Statistics: The Approach based on Influence Functions</em>.
Wiley.
</p>
<p>A. Marazzi (1993)
<em>Algorithms, Routines and S Functions for Robust Statistics</em>.
Wadsworth &amp; Brooks/Cole.
</p>
<p>Venables, W. N. and Ripley, B. D. (2002)
<em>Modern Applied Statistics with S.</em>  Fourth edition.  Springer.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+lm">lm</a></code>, <code><a href="#topic+lqs">lqs</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>summary(rlm(stack.loss ~ ., stackloss))
rlm(stack.loss ~ ., stackloss, psi = psi.hampel, init = "lts")
rlm(stack.loss ~ ., stackloss, psi = psi.bisquare)
</code></pre>

<hr>
<h2 id='rms.curv'>
Relative Curvature Measures for Non-Linear Regression
</h2><span id='topic+rms.curv'></span><span id='topic+print.rms.curv'></span>

<h3>Description</h3>

<p>Calculates the root mean square parameter effects and intrinsic relative
curvatures, <code class="reqn">c^\theta</code> and <code class="reqn">c^\iota</code>, for a
fitted nonlinear regression, as defined in Bates &amp; Watts, section 7.3,
p. 253ff
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rms.curv(obj)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rms.curv_+3A_obj">obj</code></td>
<td>

<p>Fitted model object of class <code>"nls"</code>.  The model must be fitted using the
default algorithm.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The method of section 7.3.1 of Bates &amp; Watts is implemented.  The
function <code>deriv3</code> should be used generate a model function with first
derivative (gradient) matrix and second derivative (Hessian) array
attributes.  This function should then be used to fit the nonlinear
regression model.
</p>
<p>A print method, <code>print.rms.curv</code>, prints the <code>pc</code> and
<code>ic</code> components only, suitably annotated.
</p>
<p>If either <code>pc</code> or <code>ic</code> exceeds some threshold (0.3 has been
suggested) the curvature is unacceptably high for the planar assumption.
</p>


<h3>Value</h3>

<p>A list of class <code>rms.curv</code> with components <code>pc</code> and <code>ic</code>
for parameter effects and intrinsic relative curvatures multiplied by
sqrt(F), <code>ct</code> and <code>ci</code> for <code class="reqn">c^\theta</code> and <code class="reqn">c^\iota</code> (unmultiplied),
and <code>C</code> the C-array as used in section 7.3.1 of Bates &amp; Watts.
</p>


<h3>References</h3>

<p>Bates, D. M, and Watts, D. G. (1988)
<em>Nonlinear Regression Analysis and its Applications.</em>
Wiley, New York.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+deriv3">deriv3</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># The treated sample from the Puromycin data
mmcurve &lt;- deriv3(~ Vm * conc/(K + conc), c("Vm", "K"),
                  function(Vm, K, conc) NULL)
Treated &lt;- Puromycin[Puromycin$state == "treated", ]
(Purfit1 &lt;- nls(rate ~ mmcurve(Vm, K, conc), data = Treated,
                start = list(Vm=200, K=0.1)))
rms.curv(Purfit1)
##Parameter effects: c^theta x sqrt(F) = 0.2121
##        Intrinsic: c^iota  x sqrt(F) = 0.092
</code></pre>

<hr>
<h2 id='rnegbin'>
Simulate Negative Binomial Variates
</h2><span id='topic+rnegbin'></span>

<h3>Description</h3>

<p>Function to generate random outcomes from a Negative Binomial distribution,
with mean <code>mu</code> and variance <code>mu + mu^2/theta</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rnegbin(n, mu = n, theta = stop("'theta' must be specified"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rnegbin_+3A_n">n</code></td>
<td>

<p>If a scalar, the number of sample values required.  If a vector,
<code>length(n)</code> is the number required and <code>n</code> is used as the mean vector if
<code>mu</code> is not specified.
</p>
</td></tr>
<tr><td><code id="rnegbin_+3A_mu">mu</code></td>
<td>

<p>The vector of means.  Short vectors are recycled.
</p>
</td></tr>
<tr><td><code id="rnegbin_+3A_theta">theta</code></td>
<td>

<p>Vector of values of the <code>theta</code> parameter.  Short vectors are recycled.
</p>
</td></tr></table>


<h3>Details</h3>

<p>The function uses the representation of the Negative Binomial distribution
as a continuous mixture of Poisson distributions with Gamma distributed means.
Unlike <code>rnbinom</code> the index can be arbitrary.
</p>


<h3>Value</h3>

<p>Vector of random Negative Binomial variate values.
</p>


<h3>Side Effects</h3>

<p>Changes <code>.Random.seed</code> in the usual way.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Negative Binomials with means fitted(fm) and theta = 4.5
fm &lt;- glm.nb(Days ~ ., data = quine)
dummy &lt;- rnegbin(fitted(fm), theta = 4.5)
</code></pre>

<hr>
<h2 id='road'>
Road Accident Deaths in US States
</h2><span id='topic+road'></span>

<h3>Description</h3>

<p>A data frame with the annual deaths in road accidents for half
the US states.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>road
</code></pre>


<h3>Format</h3>

<p>Columns are:
</p>

<dl>
<dt><code>state</code></dt><dd>
<p>name.
</p>
</dd>
<dt><code>deaths</code></dt><dd>
<p>number of deaths.
</p>
</dd>
<dt><code>drivers</code></dt><dd>
<p>number of drivers (in 10,000s).
</p>
</dd>
<dt><code>popden</code></dt><dd>
<p>population density in people per square mile.
</p>
</dd>
<dt><code>rural</code></dt><dd>
<p>length of rural roads, in 1000s of miles.
</p>
</dd>
<dt><code>temp</code></dt><dd>
<p>average daily maximum temperature in January.
</p>
</dd>
<dt><code>fuel</code></dt><dd>
<p>fuel consumption in 10,000,000 US gallons per year.
</p>
</dd>
</dl>



<h3>Source</h3>

<p>Imperial College, London M.Sc. exercise
</p>

<hr>
<h2 id='rotifer'>
Numbers of Rotifers by Fluid Density
</h2><span id='topic+rotifer'></span>

<h3>Description</h3>

<p>The data give the numbers of rotifers falling out of suspension for
different fluid densities. There are two species, <code>pm</code>
<em>Polyartha major</em> and <code>kc</code>, <em>Keratella cochlearis</em> and
for each species the number falling out and the total number are
given.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rotifer
</code></pre>


<h3>Format</h3>


<dl>
<dt><code>density</code></dt><dd>
<p>specific density of fluid.
</p>
</dd>
<dt><code>pm.y</code></dt><dd>
<p>number falling out for <em>P. major</em>.
</p>
</dd>
<dt><code>pm.total</code></dt><dd>
<p>total number of <em>P. major</em>.
</p>
</dd>
<dt><code>kc.y</code></dt><dd>
<p>number falling out for <em>K. cochlearis</em>.
</p>
</dd>
<dt><code>kc.tot</code></dt><dd>
<p>total number of <em>K. cochlearis</em>.
</p>
</dd>
</dl>



<h3>Source</h3>

<p>D. Collett (1991) <em>Modelling Binary Data.</em> Chapman &amp; Hall. p. 217
</p>

<hr>
<h2 id='Rubber'>
Accelerated Testing of Tyre Rubber
</h2><span id='topic+Rubber'></span>

<h3>Description</h3>

<p>Data frame from accelerated testing of tyre rubber.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Rubber
</code></pre>


<h3>Format</h3>


<dl>
<dt><code>loss</code></dt><dd>
<p>the abrasion loss in gm/hr.
</p>
</dd>
<dt><code>hard</code></dt><dd>
<p>the hardness in Shore units.
</p>
</dd>
<dt><code>tens</code></dt><dd>
<p>tensile strength in kg/sq m.
</p>
</dd>
</dl>



<h3>Source</h3>

<p>O.L. Davies (1947)
<em>Statistical Methods in Research and Production.</em>
Oliver and Boyd, Table 6.1 p. 119.
</p>
<p>O.L. Davies and P.L. Goldsmith (1972)
<em>Statistical Methods in Research and Production.</em>
4th edition, Longmans, Table 8.1 p. 239.
</p>


<h3>References</h3>

<p>Venables, W. N. and Ripley, B. D. (2002)
<em>Modern Applied Statistics with S-PLUS.</em> Fourth Edition. Springer.
</p>

<hr>
<h2 id='sammon'>
Sammon's Non-Linear Mapping
</h2><span id='topic+sammon'></span>

<h3>Description</h3>

<p>One form of non-metric multidimensional scaling.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sammon(d, y = cmdscale(d, k), k = 2, niter = 100, trace = TRUE,
       magic = 0.2, tol = 1e-4)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sammon_+3A_d">d</code></td>
<td>

<p>distance structure of the form returned by <code>dist</code>, or a full, symmetric
matrix.  Data are assumed to be dissimilarities or relative distances,
but must be positive except for self-distance.  This can contain missing
values.
</p>
</td></tr>
<tr><td><code id="sammon_+3A_y">y</code></td>
<td>

<p>An initial configuration. If none is supplied, <code>cmdscale</code>
is used to provide the classical solution.  (If there are missing
values in <code>d</code>, an initial configuration must be provided.)  This
must not have duplicates.
</p>
</td></tr>
<tr><td><code id="sammon_+3A_k">k</code></td>
<td>

<p>The dimension of the configuration.
</p>
</td></tr>
<tr><td><code id="sammon_+3A_niter">niter</code></td>
<td>

<p>The maximum number of iterations.
</p>
</td></tr>
<tr><td><code id="sammon_+3A_trace">trace</code></td>
<td>

<p>Logical for tracing optimization. Default <code>TRUE</code>.
</p>
</td></tr>
<tr><td><code id="sammon_+3A_magic">magic</code></td>
<td>

<p>initial value of the step size constant in diagonal Newton method.
</p>
</td></tr>
<tr><td><code id="sammon_+3A_tol">tol</code></td>
<td>

<p>Tolerance for stopping, in units of stress.
</p>
</td></tr></table>


<h3>Details</h3>

<p>This chooses a two-dimensional configuration to minimize the stress,
the sum of squared differences between the input distances and those
of the configuration, weighted by the distances, the whole sum being
divided by the sum of input distances to make the stress scale-free.
</p>
<p>An iterative algorithm is used, which will usually converge in around
50 iterations.  As this is necessarily an <code class="reqn">O(n^2)</code> calculation, it is slow
for large datasets.  Further, since the configuration is only determined
up to rotations and reflections (by convention the centroid is at the
origin), the result can vary considerably from machine to machine.
In this release the algorithm has been modified by adding a step-length
search (<code>magic</code>) to ensure that it always goes downhill.
</p>


<h3>Value</h3>

<p>Two components:
</p>
<table>
<tr><td><code>points</code></td>
<td>

<p>A two-column vector of the fitted configuration.
</p>
</td></tr>
<tr><td><code>stress</code></td>
<td>

<p>The final stress achieved.
</p>
</td></tr></table>


<h3>Side Effects</h3>

<p>If trace is true, the initial stress and the current stress are printed
out every 10 iterations.
</p>


<h3>References</h3>

<p>Sammon, J. W. (1969)
A non-linear mapping for data structure analysis.
<em>IEEE Trans. Comput.</em>, <b>C-18</b> 401&ndash;409.
</p>
<p>Ripley, B. D. (1996)
<em>Pattern Recognition and Neural Networks</em>. Cambridge University Press.
</p>
<p>Venables, W. N. and Ripley, B. D. (2002)
<em>Modern Applied Statistics with S.</em> Fourth edition.  Springer.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+cmdscale">cmdscale</a></code>, <code><a href="#topic+isoMDS">isoMDS</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>swiss.x &lt;- as.matrix(swiss[, -1])
swiss.sam &lt;- sammon(dist(swiss.x))
plot(swiss.sam$points, type = "n")
text(swiss.sam$points, labels = as.character(1:nrow(swiss.x)))
</code></pre>

<hr>
<h2 id='ships'>
Ships Damage Data
</h2><span id='topic+ships'></span>

<h3>Description</h3>

<p>Data frame giving the number of damage incidents and aggregate
months of service by ship type, year of construction, and period of operation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ships
</code></pre>


<h3>Format</h3>


<dl>
<dt><code>type</code></dt><dd>
<p>type: <code>"A"</code> to <code>"E"</code>.
</p>
</dd>
<dt><code>year</code></dt><dd>
<p>year of construction: 1960&ndash;64, 65&ndash;69, 70&ndash;74, 75&ndash;79
(coded as <code>"60"</code>, <code>"65"</code>, <code>"70"</code>, <code>"75"</code>).
</p>
</dd>
<dt><code>period</code></dt><dd>
<p>period of operation : 1960&ndash;74, 75&ndash;79.
</p>
</dd>
<dt><code>service</code></dt><dd>
<p>aggregate months of service.
</p>
</dd>
<dt><code>incidents</code></dt><dd>
<p>number of damage incidents.
</p>
</dd>
</dl>



<h3>Source</h3>

<p>P. McCullagh and J. A. Nelder, (1983),
<em>Generalized Linear Models.</em> Chapman &amp; Hall, section 6.3.2, page 137
</p>

<hr>
<h2 id='shoes'>
Shoe wear data of Box, Hunter and Hunter
</h2><span id='topic+shoes'></span>

<h3>Description</h3>

<p>A list of two vectors, giving the wear of shoes of materials A and B
for one foot each of ten boys.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>shoes
</code></pre>


<h3>Source</h3>

<p>G. E. P. Box, W. G. Hunter and J. S. Hunter (1978)
<em>Statistics for Experimenters.</em> Wiley, p. 100
</p>


<h3>References</h3>

<p>Venables, W. N. and Ripley, B. D. (2002)
<em>Modern Applied Statistics with S.</em> Fourth edition.  Springer.
</p>

<hr>
<h2 id='shrimp'>
Percentage of Shrimp in Shrimp Cocktail
</h2><span id='topic+shrimp'></span>

<h3>Description</h3>

<p>A numeric vector with 18 determinations by different laboratories
of the amount (percentage of the declared total weight) of shrimp
in shrimp cocktail.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>shrimp
</code></pre>


<h3>Source</h3>

<p>F. J. King and J. J. Ryan (1976)
Collaborative study of the determination of the amount of shrimp in
shrimp cocktail. <em>J. Off. Anal. Chem.</em> <b>59</b>, 644&ndash;649.
</p>
<p>R. G. Staudte and S. J. Sheather (1990)
<em>Robust Estimation and Testing.</em> Wiley.
</p>

<hr>
<h2 id='shuttle'>
Space Shuttle Autolander Problem
</h2><span id='topic+shuttle'></span>

<h3>Description</h3>

<p>The <code>shuttle</code> data frame has 256 rows and 7 columns.
The first six columns are categorical variables giving example
conditions; the seventh is the decision.  The first 253 rows are the
training set, the last 3 the test conditions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>shuttle
</code></pre>


<h3>Format</h3>

<p>This data frame contains the following factor columns:
</p>

<dl>
<dt><code>stability</code></dt><dd>
<p>stable positioning or not (<code>stab</code> / <code>xstab</code>).
</p>
</dd>
<dt><code>error</code></dt><dd>
<p>size of error (<code>MM</code> / <code>SS</code> / <code>LX</code> / <code>XL</code>).
</p>
</dd>
<dt><code>sign</code></dt><dd>
<p>sign of error, positive or negative (<code>pp</code> / <code>nn</code>).
</p>
</dd>
<dt><code>wind</code></dt><dd>
<p>wind sign (<code>head</code> / <code>tail</code>).
</p>
</dd>
<dt><code>magn</code></dt><dd>
<p>wind strength (<code>Light</code> / <code>Medium</code> / <code>Strong</code> /
<code>Out of Range</code>).
</p>
</dd>
<dt><code>vis</code></dt><dd>
<p>visibility (<code>yes</code> / <code>no</code>).
</p>
</dd>
<dt><code>use</code></dt><dd>
<p>use the autolander or not. (<code>auto</code> / <code>noauto</code>.)
</p>
</dd>
</dl>



<h3>Source</h3>

<p>D. Michie (1989)
Problems of computer-aided concept formation. In
<em>Applications of Expert Systems 2</em>,
ed. J. R. Quinlan, Turing Institute Press / Addison-Wesley, pp. 310&ndash;333.
</p>


<h3>References</h3>

<p>Venables, W. N. and Ripley, B. D. (2002)
<em>Modern Applied Statistics with S.</em> Fourth edition.  Springer.
</p>

<hr>
<h2 id='Sitka'>
Growth Curves for Sitka Spruce Trees in 1988
</h2><span id='topic+Sitka'></span>

<h3>Description</h3>

<p>The <code>Sitka</code> data frame has 395 rows and 4 columns.  It gives repeated
measurements on the log-size of 79 Sitka spruce trees, 54 of which
were grown in ozone-enriched chambers and 25 were controls.  The size
was measured five times in 1988, at roughly monthly intervals.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Sitka
</code></pre>


<h3>Format</h3>

<p>This data frame contains the following columns:
</p>

<dl>
<dt><code>size</code></dt><dd><p>measured size (height times diameter squared) of
tree, on log scale.</p>
</dd>
<dt><code>Time</code></dt><dd><p>time of measurement in  days since 1 January 1988.</p>
</dd>
<dt><code>tree</code></dt><dd><p>number of tree.</p>
</dd>
<dt><code>treat</code></dt><dd><p>either <code>"ozone"</code> for an ozone-enriched
chamber or <code>"control"</code>.</p>
</dd>
</dl>



<h3>Source</h3>

<p>P. J. Diggle, K.-Y. Liang and S. L. Zeger (1994)
<em>Analysis of Longitudinal Data.</em>
Clarendon Press, Oxford
</p>


<h3>References</h3>

<p>Venables, W. N. and Ripley, B. D. (2002)
<em>Modern Applied Statistics with S.</em> Fourth edition.  Springer.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Sitka89">Sitka89</a></code>.
</p>

<hr>
<h2 id='Sitka89'>
Growth Curves for Sitka Spruce Trees in 1989
</h2><span id='topic+Sitka89'></span>

<h3>Description</h3>

<p>The <code>Sitka89</code> data frame has 632 rows and 4 columns.  It gives repeated
measurements on the log-size of 79 Sitka spruce trees, 54 of which
were grown in ozone-enriched chambers and 25 were controls.  The size
was measured eight times in 1989, at roughly monthly intervals.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Sitka89
</code></pre>


<h3>Format</h3>

<p>This data frame contains the following columns:
</p>

<dl>
<dt><code>size</code></dt><dd><p>measured size (height times diameter squared) of
tree, on log scale.</p>
</dd>
<dt><code>Time</code></dt><dd><p>time of measurement in  days since 1 January 1988.</p>
</dd>
<dt><code>tree</code></dt><dd><p>number of tree.</p>
</dd>
<dt><code>treat</code></dt><dd><p>either <code>"ozone"</code> for an ozone-enriched
chamber or <code>"control"</code>.</p>
</dd>
</dl>



<h3>Source</h3>

<p>P. J. Diggle, K.-Y. Liang and S. L. Zeger (1994)
<em>Analysis of Longitudinal Data.</em>
Clarendon Press, Oxford
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Sitka">Sitka</a></code>
</p>

<hr>
<h2 id='Skye'>
AFM Compositions of Aphyric Skye Lavas
</h2><span id='topic+Skye'></span>

<h3>Description</h3>

<p>The <code>Skye</code> data frame has 23 rows and 3 columns.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Skye
</code></pre>


<h3>Format</h3>

<p>This data frame contains the following columns:
</p>

<dl>
<dt><code>A</code></dt><dd>
<p>Percentage of sodium and potassium oxides.
</p>
</dd>
<dt><code>F</code></dt><dd>
<p>Percentage of iron oxide.
</p>
</dd>
<dt><code>M</code></dt><dd>
<p>Percentage of magnesium oxide.
</p>
</dd>
</dl>



<h3>Source</h3>

<p>R. N. Thompson, J. Esson and A. C. Duncan (1972)
Major element chemical variation in the Eocene lavas of the Isle of
Skye. <em>J. Petrology</em>, <b>13</b>, 219&ndash;253.
</p>


<h3>References</h3>

<p>J. Aitchison (1986)
<em>The Statistical Analysis of Compositional Data.</em>
Chapman and Hall, p.360.
</p>
<p>Venables, W. N. and Ripley, B. D. (2002)
<em>Modern Applied Statistics with S.</em> Fourth edition.  Springer.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># ternary() is from the on-line answers.
ternary &lt;- function(X, pch = par("pch"), lcex = 1,
                    add = FALSE, ord = 1:3, ...)
{
  X &lt;- as.matrix(X)
  if(any(X &lt; 0)) stop("X must be non-negative")
  s &lt;- drop(X %*% rep(1, ncol(X)))
  if(any(s&lt;=0)) stop("each row of X must have a positive sum")
  if(max(abs(s-1)) &gt; 1e-6) {
    warning("row(s) of X will be rescaled")
    X &lt;- X / s
  }
  X &lt;- X[, ord]
  s3 &lt;- sqrt(1/3)
  if(!add)
  {
    oldpty &lt;- par("pty")
    on.exit(par(pty=oldpty))
    par(pty="s")
    plot(c(-s3, s3), c(0.5-s3, 0.5+s3), type="n", axes=FALSE,
         xlab="", ylab="")
    polygon(c(0, -s3, s3), c(1, 0, 0), density=0)
    lab &lt;- NULL
    if(!is.null(dn &lt;- dimnames(X))) lab &lt;- dn[[2]]
    if(length(lab) &lt; 3) lab &lt;- as.character(1:3)
    eps &lt;- 0.05 * lcex
    text(c(0, s3+eps*0.7, -s3-eps*0.7),
         c(1+eps, -0.1*eps, -0.1*eps), lab, cex=lcex)
  }
  points((X[,2] - X[,3])*s3, X[,1], ...)
}

ternary(Skye/100, ord=c(1,3,2))
</code></pre>

<hr>
<h2 id='snails'>
Snail Mortality Data
</h2><span id='topic+snails'></span>

<h3>Description</h3>

<p>Groups of 20 snails were held for periods of 1, 2, 3 or 4 weeks
in carefully controlled conditions of temperature and relative
humidity.  There were two species of snail, A and B, and the
experiment was designed as a 4 by 3 by 4 by 2 completely randomized
design.  At the end of the exposure time the snails were tested to see if
they had survived; the process itself is fatal for the animals.  The
object of the exercise was to model the probability of survival in terms of
the stimulus variables, and in particular to test for differences between
species.
</p>
<p>The data are unusual in that in most cases fatalities during the experiment
were fairly small.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>snails
</code></pre>


<h3>Format</h3>

<p>The data frame contains the following components:
</p>

<dl>
<dt><code>Species</code></dt><dd>
<p>snail species A (<code>1</code>) or B (<code>2</code>).
</p>
</dd>
<dt><code>Exposure</code></dt><dd>
<p>exposure in weeks.
</p>
</dd>
<dt><code>Rel.Hum</code></dt><dd>
<p>relative humidity (4 levels).
</p>
</dd>
<dt><code>Temp</code></dt><dd>
<p>temperature, in degrees Celsius (3 levels).
</p>
</dd>
<dt><code>Deaths</code></dt><dd>
<p>number of deaths.
</p>
</dd>
<dt><code>N</code></dt><dd>
<p>number of snails exposed.
</p>
</dd>
</dl>



<h3>Source</h3>

<p>Zoology Department, The University of Adelaide.
</p>


<h3>References</h3>

<p>Venables, W. N. and Ripley, B. D. (2002)
<em>Modern Applied Statistics with S-PLUS.</em> Fourth Edition. Springer.
</p>

<hr>
<h2 id='SP500'>
Returns of the Standard and Poors 500
</h2><span id='topic+SP500'></span>

<h3>Description</h3>

<p>Returns of the Standard and Poors 500 Index in the 1990's
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SP500
</code></pre>


<h3>Format</h3>

<p>A vector of returns of the Standard and Poors 500 index for all
the trading days in 1990, 1991, ..., 1999.
</p>


<h3>References</h3>

<p>Venables, W. N. and Ripley, B. D. (2002)
<em>Modern Applied Statistics with S.</em> Fourth edition.  Springer.
</p>

<hr>
<h2 id='stdres'>
Extract Standardized Residuals from a Linear Model
</h2><span id='topic+stdres'></span>

<h3>Description</h3>

<p>The standardized residuals.  These are normalized to unit
variance, fitted including the current data point.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>stdres(object)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="stdres_+3A_object">object</code></td>
<td>

<p>any object representing a linear model.
</p>
</td></tr></table>


<h3>Value</h3>

<p>The vector of appropriately transformed residuals.
</p>


<h3>References</h3>

<p>Venables, W. N. and Ripley, B. D. (2002)
<em>Modern Applied Statistics with S.</em> Fourth edition.  Springer.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+residuals">residuals</a></code>, <code><a href="#topic+studres">studres</a></code>
</p>

<hr>
<h2 id='steam'>
The Saturated Steam Pressure Data
</h2><span id='topic+steam'></span>

<h3>Description</h3>

<p>Temperature and pressure in a saturated steam driven experimental device.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>steam
</code></pre>


<h3>Format</h3>

<p>The data frame contains the following components:
</p>

<dl>
<dt><code>Temp</code></dt><dd>
<p>temperature, in degrees Celsius.
</p>
</dd>
<dt><code>Press</code></dt><dd>
<p>pressure, in Pascals.
</p>
</dd>
</dl>



<h3>Source</h3>

<p>N.R. Draper  and H. Smith (1981)
<em>Applied Regression Analysis.</em> Wiley, pp. 518&ndash;9.
</p>


<h3>References</h3>

<p>Venables, W. N. and Ripley, B. D. (2002)
<em>Modern Applied Statistics with S-PLUS.</em> Fourth Edition. Springer.
</p>

<hr>
<h2 id='stepAIC'>
Choose a model by AIC in a Stepwise Algorithm
</h2><span id='topic+stepAIC'></span><span id='topic+extractAIC.gls'></span><span id='topic+terms.gls'></span><span id='topic+extractAIC.lme'></span><span id='topic+terms.lme'></span>

<h3>Description</h3>

<p>Performs stepwise model selection by AIC.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>stepAIC(object, scope, scale = 0,
        direction = c("both", "backward", "forward"),
        trace = 1, keep = NULL, steps = 1000, use.start = FALSE,
        k = 2, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="stepAIC_+3A_object">object</code></td>
<td>

<p>an object representing a model of an appropriate class.
This is used as the initial model in the stepwise search.
</p>
</td></tr>
<tr><td><code id="stepAIC_+3A_scope">scope</code></td>
<td>

<p>defines the range of models examined in the stepwise search.
This should be either a single formula, or a list containing
components <code>upper</code> and <code>lower</code>, both formulae.  See the
details for how to specify the formulae and how they are used.
</p>
</td></tr>
<tr><td><code id="stepAIC_+3A_scale">scale</code></td>
<td>

<p>used in the definition of the AIC statistic for selecting the models,
currently only for <code><a href="stats.html#topic+lm">lm</a></code> and <code><a href="stats.html#topic+aov">aov</a></code> models
(see <code><a href="stats.html#topic+extractAIC">extractAIC</a></code> for details).
</p>
</td></tr>
<tr><td><code id="stepAIC_+3A_direction">direction</code></td>
<td>

<p>the mode of stepwise search, can be one of <code>"both"</code>,
<code>"backward"</code>, or <code>"forward"</code>, with a default of <code>"both"</code>.
If the <code>scope</code> argument is missing the default for
<code>direction</code> is <code>"backward"</code>.
</p>
</td></tr>
<tr><td><code id="stepAIC_+3A_trace">trace</code></td>
<td>

<p>if positive, information is printed during the running of
<code>stepAIC</code>.
Larger values may give more information on the fitting process.
</p>
</td></tr>
<tr><td><code id="stepAIC_+3A_keep">keep</code></td>
<td>

<p>a filter function whose input is a fitted model object and the
associated <code>AIC</code> statistic, and whose output is arbitrary.
Typically <code>keep</code> will select a subset of the components of
the object and return them. The default is not to keep anything.
</p>
</td></tr>
<tr><td><code id="stepAIC_+3A_steps">steps</code></td>
<td>

<p>the maximum number of steps to be considered.  The default is 1000
(essentially as many as required).  It is typically used to stop the
process early.
</p>
</td></tr>
<tr><td><code id="stepAIC_+3A_use.start">use.start</code></td>
<td>

<p>if true the updated fits are done starting at the linear predictor for
the currently selected model. This may speed up the iterative
calculations for <code>glm</code> (and other fits), but it can also slow them
down. <b>Not used</b> in <span class="rlang"><b>R</b></span>.
</p>
</td></tr>
<tr><td><code id="stepAIC_+3A_k">k</code></td>
<td>

<p>the multiple of the number of degrees of freedom used for the penalty.
Only <code>k = 2</code> gives the genuine AIC: <code>k = log(n)</code> is
sometimes referred to as BIC or SBC.
</p>
</td></tr>
<tr><td><code id="stepAIC_+3A_...">...</code></td>
<td>

<p>any additional arguments to <code>extractAIC</code>. (None are currently used.)
</p>
</td></tr></table>


<h3>Details</h3>

<p>The set of models searched is determined by the <code>scope</code> argument.
The right-hand-side of its <code>lower</code> component is always included
in the model, and right-hand-side of the model is included in the
<code>upper</code> component.  If <code>scope</code> is a single formula, it
specifies the <code>upper</code> component, and the <code>lower</code> model is
empty.  If <code>scope</code> is missing, the initial model is used as the
<code>upper</code> model.
</p>
<p>Models specified by <code>scope</code> can be templates to update
<code>object</code> as used by <code><a href="stats.html#topic+update.formula">update.formula</a></code>.
</p>
<p>There is a potential problem in using <code><a href="stats.html#topic+glm">glm</a></code> fits with a
variable <code>scale</code>, as in that case the deviance is not simply
related to the maximized log-likelihood. The <code>glm</code> method for
<code><a href="stats.html#topic+extractAIC">extractAIC</a></code> makes the
appropriate adjustment for a <code>gaussian</code> family, but may need to be
amended for other cases. (The <code>binomial</code> and <code>poisson</code>
families have fixed <code>scale</code> by default and do not correspond
to a particular maximum-likelihood problem for variable <code>scale</code>.)
</p>
<p>Where a conventional deviance exists (e.g. for <code>lm</code>, <code>aov</code>
and <code>glm</code> fits) this is quoted in the analysis of variance table:
it is the <em>unscaled</em> deviance.
</p>


<h3>Value</h3>

<p>the stepwise-selected model is returned, with up to two additional
components.  There is an <code>"anova"</code> component corresponding to the
steps taken in the search, as well as a <code>"keep"</code> component if the
<code>keep=</code> argument was supplied in the call. The
<code>"Resid. Dev"</code> column of the analysis of deviance table refers
to a constant minus twice the maximized log likelihood: it will be a
deviance only in cases where a saturated model is well-defined
(thus excluding <code>lm</code>, <code>aov</code> and <code>survreg</code> fits,
for example).
</p>


<h3>Note</h3>

<p>The model fitting must apply the models to the same dataset.  This may
be a problem if there are missing values and an <code>na.action</code> other than
<code>na.fail</code> is used (as is the default in <span class="rlang"><b>R</b></span>).
We suggest you remove the missing values first.
</p>


<h3>References</h3>

<p>Venables, W. N. and Ripley, B. D. (2002)
<em>Modern Applied Statistics with S.</em> Fourth edition.  Springer.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+addterm">addterm</a></code>, <code><a href="#topic+dropterm">dropterm</a></code>, <code><a href="stats.html#topic+step">step</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>quine.hi &lt;- aov(log(Days + 2.5) ~ .^4, quine)
quine.nxt &lt;- update(quine.hi, . ~ . - Eth:Sex:Age:Lrn)
quine.stp &lt;- stepAIC(quine.nxt,
    scope = list(upper = ~Eth*Sex*Age*Lrn, lower = ~1),
    trace = FALSE)
quine.stp$anova

cpus1 &lt;- cpus
for(v in names(cpus)[2:7])
  cpus1[[v]] &lt;- cut(cpus[[v]], unique(quantile(cpus[[v]])),
                    include.lowest = TRUE)
cpus0 &lt;- cpus1[, 2:8]  # excludes names, authors' predictions
cpus.samp &lt;- sample(1:209, 100)
cpus.lm &lt;- lm(log10(perf) ~ ., data = cpus1[cpus.samp,2:8])
cpus.lm2 &lt;- stepAIC(cpus.lm, trace = FALSE)
cpus.lm2$anova

example(birthwt)
birthwt.glm &lt;- glm(low ~ ., family = binomial, data = bwt)
birthwt.step &lt;- stepAIC(birthwt.glm, trace = FALSE)
birthwt.step$anova
birthwt.step2 &lt;- stepAIC(birthwt.glm, ~ .^2 + I(scale(age)^2)
    + I(scale(lwt)^2), trace = FALSE)
birthwt.step2$anova

quine.nb &lt;- glm.nb(Days ~ .^4, data = quine)
quine.nb2 &lt;- stepAIC(quine.nb)
quine.nb2$anova
</code></pre>

<hr>
<h2 id='stormer'>
The Stormer Viscometer Data
</h2><span id='topic+stormer'></span>

<h3>Description</h3>

<p>The stormer viscometer measures the viscosity of a fluid by measuring the
time taken for an inner cylinder in the mechanism to perform a fixed number
of revolutions in response to an actuating weight.  The viscometer is
calibrated by measuring the time taken with varying weights while the
mechanism is suspended in fluids of accurately known viscosity.  The data
comes from such a calibration, and theoretical considerations suggest a
nonlinear relationship between time, weight and viscosity, of the form
<code>Time = (B1*Viscosity)/(Weight - B2) + E</code>
where <code>B1</code> and <code>B2</code>
are unknown parameters to be estimated, and <code>E</code> is error.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>stormer
</code></pre>


<h3>Format</h3>

<p>The data frame contains the following components:
</p>

<dl>
<dt><code>Viscosity</code></dt><dd>
<p>viscosity of fluid.
</p>
</dd>
<dt><code>Wt</code></dt><dd>
<p>actuating weight.
</p>
</dd>
<dt><code>Time</code></dt><dd>
<p>time taken.
</p>
</dd>
</dl>



<h3>Source</h3>

<p>E. J. Williams (1959) <em>Regression Analysis.</em> Wiley.
</p>


<h3>References</h3>

<p>Venables, W. N. and Ripley, B. D. (2002)
<em>Modern Applied Statistics with S.</em> Fourth edition.  Springer.
</p>

<hr>
<h2 id='studres'>
Extract Studentized Residuals from a Linear Model
</h2><span id='topic+studres'></span>

<h3>Description</h3>

<p>The Studentized residuals.  Like standardized residuals, these are
normalized to unit variance, but the Studentized version is fitted
ignoring the current data point. (They are sometimes called jackknifed
residuals).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>studres(object)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="studres_+3A_object">object</code></td>
<td>

<p>any object representing a linear model.
</p>
</td></tr></table>


<h3>Value</h3>

<p>The vector of appropriately transformed residuals.
</p>


<h3>References</h3>

<p>Venables, W. N. and Ripley, B. D. (2002)
<em>Modern Applied Statistics with S.</em> Fourth edition.  Springer.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+residuals">residuals</a></code>, <code><a href="#topic+stdres">stdres</a></code>
</p>

<hr>
<h2 id='summary.loglm'>
Summary Method Function for Objects of Class 'loglm'
</h2><span id='topic+summary.loglm'></span><span id='topic+print.summary.loglm'></span>

<h3>Description</h3>

<p>Returns a summary list for log-linear models fitted by
iterative proportional scaling using <code>loglm</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'loglm'
summary(object, fitted = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.loglm_+3A_object">object</code></td>
<td>

<p>a fitted loglm model object.
</p>
</td></tr>
<tr><td><code id="summary.loglm_+3A_fitted">fitted</code></td>
<td>

<p>if <code>TRUE</code> return observed and expected frequencies in the result.
Using <code>fitted = TRUE</code> may necessitate re-fitting the object.
</p>
</td></tr>
<tr><td><code id="summary.loglm_+3A_...">...</code></td>
<td>

<p>arguments to be passed to or from other methods.
</p>
</td></tr></table>


<h3>Details</h3>

<p>This function is a method for the generic function
<code>summary()</code> for class <code>"loglm"</code>.
It can be invoked by calling <code>summary(x)</code> for an
object <code>x</code> of the appropriate class, or directly by
calling <code>summary.loglm(x)</code> regardless of the
class of the object.
</p>


<h3>Value</h3>

<p>a list is returned for use by <code>print.summary.loglm</code>.
This has components
</p>
<table>
<tr><td><code>formula</code></td>
<td>

<p>the formula used to produce <code>object</code>
</p>
</td></tr>
<tr><td><code>tests</code></td>
<td>

<p>the table of test statistics (likelihood ratio, Pearson) for the fit.
</p>
</td></tr>
<tr><td><code>oe</code></td>
<td>

<p>if <code>fitted = TRUE</code>, an array of the observed and expected frequencies,
otherwise <code>NULL</code>.
</p>
</td></tr></table>


<h3>References</h3>

<p>Venables, W. N. and Ripley, B. D. (2002)
<em>Modern Applied Statistics with S.</em> Fourth edition.  Springer.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+loglm">loglm</a></code>, <code><a href="base.html#topic+summary">summary</a></code>
</p>

<hr>
<h2 id='summary.negbin'>
Summary Method Function for Objects of Class 'negbin'
</h2><span id='topic+summary.negbin'></span><span id='topic+print.summary.negbin'></span>

<h3>Description</h3>

<p>Identical to <code>summary.glm</code>, but with three lines of additional output: the
ML estimate of theta, its standard error, and twice the log-likelihood
function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'negbin'
summary(object, dispersion = 1, correlation = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.negbin_+3A_object">object</code></td>
<td>

<p>fitted model object of class <code>negbin</code> inheriting from <code>glm</code> and <code>lm</code>.
Typically the output of <code>glm.nb</code>.
</p>
</td></tr>
<tr><td><code id="summary.negbin_+3A_dispersion">dispersion</code></td>
<td>

<p>as for <code>summary.glm</code>, with a default of 1.
</p>
</td></tr>
<tr><td><code id="summary.negbin_+3A_correlation">correlation</code></td>
<td>

<p>as for <code>summary.glm</code>.
</p>
</td></tr>
<tr><td><code id="summary.negbin_+3A_...">...</code></td>
<td>

<p>arguments passed to or from other methods.
</p>
</td></tr></table>


<h3>Details</h3>

<p><code>summary.glm</code> is used to produce the majority of the output and supply the
result.
This function is a method for the generic function
<code>summary()</code> for class <code>"negbin"</code>.
It can be invoked by calling <code>summary(x)</code> for an
object <code>x</code> of the appropriate class, or directly by
calling <code>summary.negbin(x)</code> regardless of the
class of the object.
</p>


<h3>Value</h3>

<p>As for <code>summary.glm</code>; the additional lines of output are not included in
the resultant object.
</p>


<h3>Side Effects</h3>

<p>A summary table is produced as for <code>summary.glm</code>, with the additional
information described above.
</p>


<h3>References</h3>

<p>Venables, W. N. and Ripley, B. D. (2002)
<em>Modern Applied Statistics with S.</em> Fourth edition.  Springer.
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+summary">summary</a></code>, <code><a href="#topic+glm.nb">glm.nb</a></code>, <code><a href="#topic+negative.binomial">negative.binomial</a></code>, <code><a href="#topic+anova.negbin">anova.negbin</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## IGNORE_RDIFF_BEGIN
summary(glm.nb(Days ~ Eth*Age*Lrn*Sex, quine, link = log))
## IGNORE_RDIFF_END
</code></pre>

<hr>
<h2 id='summary.rlm'>
Summary Method for Robust Linear Models
</h2><span id='topic+summary.rlm'></span><span id='topic+print.summary.rlm'></span>

<h3>Description</h3>

<p><code>summary</code> method for objects of class <code>"rlm"</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'rlm'
summary(object, method = c("XtX", "XtWX"), correlation = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.rlm_+3A_object">object</code></td>
<td>

<p>the fitted model.
This is assumed to be the result of some fit that produces
an object inheriting from the class <code>rlm</code>, in the sense that
the components returned by the <code>rlm</code> function will be available.
</p>
</td></tr>
<tr><td><code id="summary.rlm_+3A_method">method</code></td>
<td>

<p>Should the weighted (by the IWLS weights) or unweighted cross-products
matrix be used?
</p>
</td></tr>
<tr><td><code id="summary.rlm_+3A_correlation">correlation</code></td>
<td>

<p>logical. Should correlations be computed (and printed)?
</p>
</td></tr>
<tr><td><code id="summary.rlm_+3A_...">...</code></td>
<td>

<p>arguments passed to or from other methods.
</p>
</td></tr></table>


<h3>Details</h3>

<p>This function is a method for the generic function
<code>summary()</code> for class <code>"rlm"</code>.
It can be invoked by calling <code>summary(x)</code> for an
object <code>x</code> of the appropriate class, or directly by
calling <code>summary.rlm(x)</code> regardless of the
class of the object.
</p>


<h3>Value</h3>

<p>If printing takes place, only a null value is returned.
Otherwise, a list is returned with the following components.
Printing always takes place if this function is invoked automatically
as a method for the <code>summary</code> function.
</p>
<table>
<tr><td><code>correlation</code></td>
<td>

<p>The computed correlation coefficient matrix for the coefficients in the model.
</p>
</td></tr>
<tr><td><code>cov.unscaled</code></td>
<td>

<p>The unscaled covariance matrix; i.e, a matrix such that multiplying it by
an estimate of the error variance produces an estimated covariance matrix
for the coefficients.
</p>
</td></tr>
<tr><td><code>sigma</code></td>
<td>

<p>The scale estimate.
</p>
</td></tr>
<tr><td><code>stddev</code></td>
<td>

<p>A scale estimate used for the standard errors.
</p>
</td></tr>
<tr><td><code>df</code></td>
<td>

<p>The number of degrees of freedom for the model and for residuals.
</p>
</td></tr>
<tr><td><code>coefficients</code></td>
<td>

<p>A matrix with three columns, containing the coefficients, their standard errors
and the corresponding t statistic.
</p>
</td></tr>
<tr><td><code>terms</code></td>
<td>

<p>The terms object used in fitting this model.
</p>
</td></tr></table>


<h3>References</h3>

<p>Venables, W. N. and Ripley, B. D. (2002)
<em>Modern Applied Statistics with S.</em> Fourth edition.  Springer.
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+summary">summary</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>summary(rlm(calls ~ year, data = phones, maxit = 50))
</code></pre>

<hr>
<h2 id='survey'>
Student Survey Data
</h2><span id='topic+survey'></span>

<h3>Description</h3>

<p>This data frame contains the responses of 237 Statistics I students at
the University of Adelaide to a number of questions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>survey
</code></pre>


<h3>Format</h3>

<p>The components of the data frame are:
</p>

<dl>
<dt><code>Sex</code></dt><dd>
<p>The sex of the student. (Factor with levels <code>"Male"</code> and <code>"Female"</code>.)
</p>
</dd>
<dt><code>Wr.Hnd</code></dt><dd>
<p>span (distance from tip of thumb to tip of little finger of spread
hand) of writing hand, in centimetres.
</p>
</dd>
<dt><code>NW.Hnd</code></dt><dd>
<p>span of non-writing hand.
</p>
</dd>
<dt><code>W.Hnd</code></dt><dd>
<p>writing hand of student. (Factor, with levels <code>"Left"</code> and <code>"Right"</code>.)
</p>
</dd>
<dt><code>Fold</code></dt><dd>
<p>&ldquo;Fold your arms! Which is on top&rdquo; (Factor, with levels
<code>"R on L"</code>, <code>"L on R"</code>, <code>"Neither"</code>.)
</p>
</dd>
<dt><code>Pulse</code></dt><dd>
<p>pulse rate of student (beats per minute).
</p>
</dd>
<dt><code>Clap</code></dt><dd>
<p>&lsquo;Clap your hands!  Which hand is on top?&rsquo; (Factor, with levels
<code>"Right"</code>, <code>"Left"</code>, <code>"Neither"</code>.)
</p>
</dd>
<dt><code>Exer</code></dt><dd>
<p>how often the student exercises. (Factor, with levels <code>"Freq"</code>
(frequently), <code>"Some"</code>, <code>"None"</code>.)
</p>
</dd>
<dt><code>Smoke</code></dt><dd>
<p>how much the student smokes. (Factor, levels <code>"Heavy"</code>,
<code>"Regul"</code> (regularly), <code>"Occas"</code> (occasionally),
<code>"Never"</code>.)
</p>
</dd>
<dt><code>Height</code></dt><dd>
<p>height of the student in centimetres.
</p>
</dd>
<dt><code>M.I</code></dt><dd>
<p>whether the student expressed height in imperial
(feet/inches) or metric (centimetres/metres) units. (Factor, levels
<code>"Metric"</code>, <code>"Imperial"</code>.)
</p>
</dd>
<dt><code>Age</code></dt><dd>
<p>age of the student in years.
</p>
</dd>
</dl>



<h3>References</h3>

<p>Venables, W. N. and Ripley, B. D. (2002)
<em>Modern Applied Statistics with S-PLUS.</em> Fourth Edition. Springer.
</p>

<hr>
<h2 id='synth.tr'>
Synthetic Classification Problem
</h2><span id='topic+synth.tr'></span><span id='topic+synth.te'></span>

<h3>Description</h3>

<p>The <code>synth.tr</code> data frame has 250 rows and 3 columns.
The <code>synth.te</code> data frame has 100 rows and 3 columns.
It is intended that <code>synth.tr</code> be used from training and
<code>synth.te</code> for testing.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>synth.tr
synth.te
</code></pre>


<h3>Format</h3>

<p>These data frames contains the following columns:
</p>

<dl>
<dt><code>xs</code></dt><dd>
<p>x-coordinate
</p>
</dd>
<dt><code>ys</code></dt><dd>
<p>y-coordinate
</p>
</dd>
<dt><code>yc</code></dt><dd>
<p>class, coded as 0 or 1.
</p>
</dd></dl>


<h3>Source</h3>

<p>Ripley, B.D. (1994)
Neural networks and related methods for
classification (with discussion).
<em>Journal of the Royal Statistical Society series B</em>
<b>56</b>, 409&ndash;456.
</p>
<p>Ripley, B.D. (1996)
<em>Pattern Recognition and Neural Networks.</em>
Cambridge: Cambridge University Press.
</p>

<hr>
<h2 id='theta.md'>
Estimate theta of the Negative Binomial
</h2><span id='topic+theta.md'></span><span id='topic+theta.ml'></span><span id='topic+theta.mm'></span>

<h3>Description</h3>

<p>Given the estimated mean vector, estimate <code>theta</code> of the
Negative Binomial Distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>theta.md(y, mu, dfr, weights, limit = 20, eps = .Machine$double.eps^0.25)

theta.ml(y, mu, n, weights, limit = 10, eps = .Machine$double.eps^0.25,
         trace = FALSE)

theta.mm(y, mu, dfr, weights, limit = 10, eps = .Machine$double.eps^0.25)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="theta.md_+3A_y">y</code></td>
<td>

<p>Vector of observed values from the Negative Binomial.
</p>
</td></tr>
<tr><td><code id="theta.md_+3A_mu">mu</code></td>
<td>

<p>Estimated mean vector.
</p>
</td></tr>
<tr><td><code id="theta.md_+3A_n">n</code></td>
<td>

<p>Number of data points (defaults to the sum of <code>weights</code>)
</p>
</td></tr>
<tr><td><code id="theta.md_+3A_dfr">dfr</code></td>
<td>

<p>Residual degrees of freedom (assuming <code>theta</code> known).  For
a weighted fit this is the sum of the weights minus the number of
fitted parameters.
</p>
</td></tr>
<tr><td><code id="theta.md_+3A_weights">weights</code></td>
<td>

<p>Case weights.  If missing, taken as 1.
</p>
</td></tr>
<tr><td><code id="theta.md_+3A_limit">limit</code></td>
<td>

<p>Limit on the number of iterations.
</p>
</td></tr>
<tr><td><code id="theta.md_+3A_eps">eps</code></td>
<td>

<p>Tolerance to determine convergence.
</p>
</td></tr>
<tr><td><code id="theta.md_+3A_trace">trace</code></td>
<td>

<p>logical: should iteration progress be printed?
</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>theta.md</code> estimates by equating the deviance to the residual
degrees of freedom, an analogue of a moment estimator.
</p>
<p><code>theta.ml</code> uses maximum likelihood.
</p>
<p><code>theta.mm</code> calculates the moment estimator of <code>theta</code> by
equating the Pearson chi-square
<code class="reqn">\sum (y-\mu)^2/(\mu+\mu^2/\theta)</code>
to the residual degrees of freedom.
</p>


<h3>Value</h3>

<p>The required estimate of <code>theta</code>, as a scalar.
For <code>theta.ml</code>, the standard error is given as attribute <code>"SE"</code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+glm.nb">glm.nb</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>quine.nb &lt;- glm.nb(Days ~ .^2, data = quine)
theta.md(quine$Days, fitted(quine.nb), dfr = df.residual(quine.nb))
theta.ml(quine$Days, fitted(quine.nb))
theta.mm(quine$Days, fitted(quine.nb), dfr = df.residual(quine.nb))

## weighted example
yeast &lt;- data.frame(cbind(numbers = 0:5, fr = c(213, 128, 37, 18, 3, 1)))
fit &lt;- glm.nb(numbers ~ 1, weights = fr, data = yeast)
## IGNORE_RDIFF_BEGIN
summary(fit)
## IGNORE_RDIFF_END
mu &lt;- fitted(fit)
theta.md(yeast$numbers, mu, dfr = 399, weights = yeast$fr)
theta.ml(yeast$numbers, mu, limit = 15, weights = yeast$fr)
theta.mm(yeast$numbers, mu, dfr = 399, weights = yeast$fr)
</code></pre>

<hr>
<h2 id='topo'>
Spatial Topographic Data
</h2><span id='topic+topo'></span>

<h3>Description</h3>

<p>The <code>topo</code> data frame has 52 rows and 3 columns, of
topographic heights within a 310 feet square.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>topo
</code></pre>


<h3>Format</h3>

<p>This data frame contains the following columns:
</p>

<dl>
<dt><code>x</code></dt><dd>
<p>x coordinates (units of 50 feet)
</p>
</dd>
<dt><code>y</code></dt><dd>
<p>y coordinates (units of 50 feet)
</p>
</dd>
<dt><code>z</code></dt><dd>
<p>heights (feet)
</p>
</dd></dl>


<h3>Source</h3>

<p>Davis, J.C. (1973)
<em>Statistics and Data Analysis in Geology.</em>
Wiley.
</p>


<h3>References</h3>

<p>Venables, W. N. and Ripley, B. D. (2002)
<em>Modern Applied Statistics with S.</em> Fourth edition.  Springer.
</p>

<hr>
<h2 id='Traffic'>
Effect of Swedish Speed Limits on Accidents
</h2><span id='topic+Traffic'></span>

<h3>Description</h3>

<p>An experiment was performed in Sweden in 1961&ndash;2 to assess the
effect of a speed limit on the motorway accident rate.  The
experiment was conducted on 92 days in each year, matched so that
day <code>j</code> in 1962 was comparable to day <code>j</code> in 1961.  On some days
the speed limit was in effect and enforced, while on other days
there was no speed limit and cars tended to be driven faster.
The speed limit days tended to be in contiguous blocks.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Traffic
</code></pre>


<h3>Format</h3>

<p>This data frame contains the following columns:
</p>

<dl>
<dt><code>year</code></dt><dd>
<p>1961 or 1962.
</p>
</dd>
<dt><code>day</code></dt><dd>
<p>of year.
</p>
</dd>
<dt><code>limit</code></dt><dd>
<p>was there a speed limit?
</p>
</dd>
<dt><code>y</code></dt><dd>
<p>traffic accident count for that day.
</p>
</dd>
</dl>



<h3>Source</h3>

<p>Svensson, A. (1981)
On the goodness-of-fit test for the multiplicative Poisson model.
<em>Annals of Statistics,</em> <b>9</b>, 697&ndash;704.
</p>


<h3>References</h3>

<p>Venables, W. N. and Ripley, B. D. (2002)
<em>Modern Applied Statistics with S-PLUS.</em> Fourth Edition. Springer.
</p>

<hr>
<h2 id='truehist'>
Plot a Histogram
</h2><span id='topic+truehist'></span>

<h3>Description</h3>

<p>Creates a histogram on the current graphics device.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>truehist(data, nbins = "Scott", h, x0 = -h/1000,
         breaks, prob = TRUE, xlim = range(breaks),
         ymax = max(est), col = "cyan",
         xlab = deparse(substitute(data)), bty = "n", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="truehist_+3A_data">data</code></td>
<td>

<p>numeric vector of data for histogram.  Missing values (<code>NA</code>s)
are allowed and omitted.
</p>
</td></tr>
<tr><td><code id="truehist_+3A_nbins">nbins</code></td>
<td>

<p>The suggested number of bins.  Either a positive integer, or a character string
naming a rule: <code>"Scott"</code> or <code>"Freedman-Diaconis"</code> or <code>"FD"</code>.  (Case is
ignored.)
</p>
</td></tr>
<tr><td><code id="truehist_+3A_h">h</code></td>
<td>

<p>The bin width, a strictly positive number (takes precedence over <code>nbins</code>).
</p>
</td></tr>
<tr><td><code id="truehist_+3A_x0">x0</code></td>
<td>

<p>Shift for the bins - the breaks are at <code>x0 + h * (..., -1, 0, 1, ...)</code>
</p>
</td></tr>
<tr><td><code id="truehist_+3A_breaks">breaks</code></td>
<td>

<p>The set of breakpoints to be used. (Usually omitted, takes precedence
over <code>h</code> and <code>nbins</code>).
</p>
</td></tr>
<tr><td><code id="truehist_+3A_prob">prob</code></td>
<td>

<p>If true (the default) plot a true histogram.
The vertical axis has a
<em>relative frequency density</em>
scale, so the product of the dimensions of any panel gives the
relative frequency.  Hence the total area under the histogram
is 1 and it is directly comparable with most other estimates
of the probability density function.
If false plot the counts in the bins.
</p>
</td></tr>
<tr><td><code id="truehist_+3A_xlim">xlim</code></td>
<td>

<p>The limits for the x-axis.
</p>
</td></tr>
<tr><td><code id="truehist_+3A_ymax">ymax</code></td>
<td>

<p>The upper limit for the y-axis.
</p>
</td></tr>
<tr><td><code id="truehist_+3A_col">col</code></td>
<td>

<p>The colour for the bar fill: the default is colour 5 in the default <span class="rlang"><b>R</b></span> palette.
</p>
</td></tr>
<tr><td><code id="truehist_+3A_xlab">xlab</code></td>
<td>

<p>label for the plot x-axis. By default, this will be the name of <code>data</code>.
</p>
</td></tr>
<tr><td><code id="truehist_+3A_bty">bty</code></td>
<td>

<p>The box type for the plot - defaults to none.
</p>
</td></tr>
<tr><td><code id="truehist_+3A_...">...</code></td>
<td>

<p>additional arguments to <code><a href="graphics.html#topic+rect">rect</a></code> or <code><a href="graphics.html#topic+plot">plot</a></code>.
</p>
</td></tr></table>


<h3>Details</h3>

<p>This plots a true histogram, a density estimate of total area 1.  If
<code>breaks</code> is specified, those breakpoints are used. Otherwise if
<code>h</code> is specified, a regular grid of bins is used with width
<code>h</code>.  If neither <code>breaks</code> nor <code>h</code> is specified,
<code>nbins</code> is used to select a suitable <code>h</code>.
</p>


<h3>Side Effects</h3>

<p>A histogram is plotted on the current device.
</p>


<h3>References</h3>

<p>Venables, W. N. and Ripley, B. D. (2002)
<em>Modern Applied Statistics with S.</em> Fourth edition.  Springer.
</p>


<h3>See Also</h3>

<p><code><a href="graphics.html#topic+hist">hist</a></code>
</p>

<hr>
<h2 id='ucv'>
Unbiased Cross-Validation for Bandwidth Selection
</h2><span id='topic+ucv'></span>

<h3>Description</h3>

<p>Uses unbiased cross-validation to select the bandwidth of a Gaussian
kernel density estimator.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ucv(x, nb = 1000, lower, upper)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ucv_+3A_x">x</code></td>
<td>

<p>a numeric vector
</p>
</td></tr>
<tr><td><code id="ucv_+3A_nb">nb</code></td>
<td>

<p>number of bins to use.
</p>
</td></tr>
<tr><td><code id="ucv_+3A_lower">lower</code>, <code id="ucv_+3A_upper">upper</code></td>
<td>

<p>Range over which to minimize.  The default is almost always satisfactory.
</p>
</td></tr></table>


<h3>Value</h3>

<p>a bandwidth.
</p>


<h3>References</h3>

<p>Scott, D. W. (1992)
<em>Multivariate Density Estimation: Theory, Practice, and  Visualization.</em>
Wiley.
</p>
<p>Venables, W. N. and Ripley, B. D. (2002)
<em>Modern Applied Statistics with S.</em> Fourth edition.  Springer.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+bcv">bcv</a></code>, <code><a href="#topic+width.SJ">width.SJ</a></code>, <code><a href="stats.html#topic+density">density</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>ucv(geyser$duration)
</code></pre>

<hr>
<h2 id='UScereal'>
Nutritional and Marketing Information on US Cereals
</h2><span id='topic+UScereal'></span>

<h3>Description</h3>

<p>The <code>UScereal</code> data frame has 65 rows and 11 columns.
The data come from the 1993 ASA Statistical Graphics Exposition,
and are taken from the mandatory  F&amp;DA food label. The data have been
normalized here to a portion of one American cup.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>UScereal
</code></pre>


<h3>Format</h3>

<p>This data frame contains the following columns:
</p>

<dl>
<dt><code>mfr</code></dt><dd>
<p>Manufacturer, represented by its first initial: G=General Mills,
K=Kelloggs, N=Nabisco, P=Post, Q=Quaker Oats, R=Ralston Purina.
</p>
</dd>
<dt><code>calories</code></dt><dd>
<p>number of calories in one portion.
</p>
</dd>
<dt><code>protein</code></dt><dd>
<p>grams of protein in one portion.
</p>
</dd>
<dt><code>fat</code></dt><dd>
<p>grams of fat in one portion.
</p>
</dd>
<dt><code>sodium</code></dt><dd>
<p>milligrams of sodium in one portion.
</p>
</dd>
<dt><code>fibre</code></dt><dd>
<p>grams of dietary fibre in one portion.
</p>
</dd>
<dt><code>carbo</code></dt><dd>
<p>grams of complex carbohydrates in one portion.
</p>
</dd>
<dt><code>sugars</code></dt><dd>
<p>grams of sugars in one portion.
</p>
</dd>
<dt><code>shelf</code></dt><dd>
<p>display shelf (1, 2, or 3, counting from the floor).
</p>
</dd>
<dt><code>potassium</code></dt><dd>
<p>grams of potassium.
</p>
</dd>
<dt><code>vitamins</code></dt><dd>
<p>vitamins and minerals (none, enriched, or 100%).
</p>
</dd>
</dl>



<h3>Source</h3>

<p>The original data are available at
<a href="http://lib.stat.cmu.edu/datasets/1993.expo/">http://lib.stat.cmu.edu/datasets/1993.expo/</a>.
</p>


<h3>References</h3>

<p>Venables, W. N. and Ripley, B. D. (2002)
<em>Modern Applied Statistics with S-PLUS.</em> Fourth Edition. Springer.
</p>

<hr>
<h2 id='UScrime'>
The Effect of Punishment Regimes on Crime Rates
</h2><span id='topic+UScrime'></span>

<h3>Description</h3>

<p>Criminologists are interested in the effect of punishment regimes on
crime rates.  This has been studied using aggregate data on 47 states
of the USA for 1960 given in this data frame.  The variables seem to
have been re-scaled to convenient numbers.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>UScrime
</code></pre>


<h3>Format</h3>

<p>This data frame contains the following columns:
</p>

<dl>
<dt><code>M</code></dt><dd>
<p>percentage of males aged 14&ndash;24.
</p>
</dd>
<dt><code>So</code></dt><dd>
<p>indicator variable for a Southern state.
</p>
</dd>
<dt><code>Ed</code></dt><dd>
<p>mean years of schooling.
</p>
</dd>
<dt><code>Po1</code></dt><dd>
<p>police expenditure in 1960.
</p>
</dd>
<dt><code>Po2</code></dt><dd>
<p>police expenditure in 1959.
</p>
</dd>
<dt><code>LF</code></dt><dd>
<p>labour force participation rate.
</p>
</dd>
<dt><code>M.F</code></dt><dd>
<p>number of males per 1000 females.
</p>
</dd>
<dt><code>Pop</code></dt><dd>
<p>state population.
</p>
</dd>
<dt><code>NW</code></dt><dd>
<p>number of non-whites per 1000 people.
</p>
</dd>
<dt><code>U1</code></dt><dd>
<p>unemployment rate of urban males 14&ndash;24.
</p>
</dd>
<dt><code>U2</code></dt><dd>
<p>unemployment rate of urban males 35&ndash;39.
</p>
</dd>
<dt><code>GDP</code></dt><dd>
<p>gross domestic product per head.
</p>
</dd>
<dt><code>Ineq</code></dt><dd>
<p>income inequality.
</p>
</dd>
<dt><code>Prob</code></dt><dd>
<p>probability of imprisonment.
</p>
</dd>
<dt><code>Time</code></dt><dd>
<p>average time served in state prisons.
</p>
</dd>
<dt><code>y</code></dt><dd>
<p>rate of crimes in a particular category per head of population.
</p>
</dd>
</dl>



<h3>Source</h3>

<p>Ehrlich, I. (1973) Participation in illegitimate activities: a
theoretical and empirical investigation.
<em>Journal of Political Economy</em>, <b>81</b>, 521&ndash;565.
</p>
<p>Vandaele, W. (1978) Participation in illegitimate activities: Ehrlich
revisited.  In <em>Deterrence and Incapacitation</em>,
eds A. Blumstein, J. Cohen and D. Nagin, pp. 270&ndash;335.
US National Academy of Sciences.
</p>


<h3>References</h3>

<p>Venables, W. N. and Ripley, B. D. (2002)
<em>Modern Applied Statistics with S-PLUS.</em> Fourth Edition. Springer.
</p>

<hr>
<h2 id='VA'>
Veteran's Administration Lung Cancer Trial
</h2><span id='topic+VA'></span>

<h3>Description</h3>

<p>Veteran's Administration lung cancer trial from Kalbfleisch &amp; Prentice.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>VA
</code></pre>


<h3>Format</h3>

<p>A data frame with columns:
</p>

<dl>
<dt><code>stime</code></dt><dd>
<p>survival or follow-up time in days.
</p>
</dd>
<dt><code>status</code></dt><dd>
<p>dead or censored.
</p>
</dd>
<dt><code>treat</code></dt><dd>
<p>treatment: standard or test.
</p>
</dd>
<dt><code>age</code></dt><dd>
<p>patient's age in years.
</p>
</dd>
<dt><code>Karn</code></dt><dd>
<p>Karnofsky score of patient's performance on a scale of 0 to 100.
</p>
</dd>
<dt><code>diag.time</code></dt><dd>
<p>times since diagnosis in months at entry to trial.
</p>
</dd>
<dt><code>cell</code></dt><dd>
<p>one of four cell types.
</p>
</dd>
<dt><code>prior</code></dt><dd>
<p>prior therapy?
</p>
</dd>
</dl>



<h3>Source</h3>

<p>Kalbfleisch, J.D. and Prentice R.L. (1980)
<em>The Statistical Analysis of Failure Time Data.</em>
Wiley.
</p>


<h3>References</h3>

<p>Venables, W. N. and Ripley, B. D. (2002)
<em>Modern Applied Statistics with S.</em> Fourth edition.  Springer.
</p>

<hr>
<h2 id='waders'>
Counts of Waders at 15 Sites in South Africa
</h2><span id='topic+waders'></span>

<h3>Description</h3>

<p>The <code>waders</code> data frame has 15 rows and 19 columns.
The entries are counts of waders in summer.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>waders
</code></pre>


<h3>Format</h3>

<p>This data frame contains the following columns (species)
</p>

<dl>
<dt><code>S1</code></dt><dd>
<p>Oystercatcher
</p>
</dd>
<dt><code>S2</code></dt><dd>
<p>White-fronted Plover
</p>
</dd>
<dt><code>S3</code></dt><dd>
<p>Kitt Lutz's Plover
</p>
</dd>
<dt><code>S4</code></dt><dd>
<p>Three-banded Plover
</p>
</dd>
<dt><code>S5</code></dt><dd>
<p>Grey Plover
</p>
</dd>
<dt><code>S6</code></dt><dd>
<p>Ringed Plover
</p>
</dd>
<dt><code>S7</code></dt><dd>
<p>Bar-tailed Godwit
</p>
</dd>
<dt><code>S8</code></dt><dd>
<p>Whimbrel
</p>
</dd>
<dt><code>S9</code></dt><dd>
<p>Marsh Sandpiper
</p>
</dd>
<dt><code>S10</code></dt><dd>
<p>Greenshank
</p>
</dd>
<dt><code>S11</code></dt><dd>
<p>Common Sandpiper
</p>
</dd>
<dt><code>S12</code></dt><dd>
<p>Turnstone
</p>
</dd>
<dt><code>S13</code></dt><dd>
<p>Knot
</p>
</dd>
<dt><code>S14</code></dt><dd>
<p>Sanderling
</p>
</dd>
<dt><code>S15</code></dt><dd>
<p>Little Stint
</p>
</dd>
<dt><code>S16</code></dt><dd>
<p>Curlew Sandpiper
</p>
</dd>
<dt><code>S17</code></dt><dd>
<p>Ruff
</p>
</dd>
<dt><code>S18</code></dt><dd>
<p>Avocet
</p>
</dd>
<dt><code>S19</code></dt><dd>
<p>Black-winged Stilt
</p>
</dd>
</dl>

<p>The rows are the sites:
</p>
<p>A = Namibia North coast<br />
B = Namibia North wetland<br />
C = Namibia South coast<br />
D = Namibia South wetland<br />
E = Cape North coast<br />
F = Cape North wetland<br />
G = Cape West coast<br />
H = Cape West wetland<br />
I = Cape South coast<br />
J= Cape South wetland<br />
K = Cape East coast<br />
L = Cape East wetland<br />
M = Transkei coast<br />
N = Natal coast<br />
O = Natal wetland
</p>


<h3>Source</h3>

<p>J.C. Gower and D.J. Hand (1996) <em>Biplots</em>
Chapman &amp; Hall Table 9.1. Quoted as from:
</p>
<p>R.W. Summers, L.G. Underhill, D.J. Pearson and D.A. Scott (1987)
Wader migration systems in south and eastern Africa and western Asia.
<em>Wader Study Group Bulletin</em> <b>49</b> Supplement, 15&ndash;34.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>plot(corresp(waders, nf=2))
</code></pre>

<hr>
<h2 id='whiteside'>
House Insulation: Whiteside's Data
</h2><span id='topic+whiteside'></span>

<h3>Description</h3>

<p>Mr Derek Whiteside of the UK Building Research Station recorded the
weekly gas consumption and average external temperature at his own
house in south-east England for two heating seasons, one of 26 weeks
before, and one of 30 weeks after cavity-wall insulation was
installed. The object of the exercise was to assess the effect of the
insulation on gas consumption.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>whiteside
</code></pre>


<h3>Format</h3>

<p>The <code>whiteside</code> data frame has 56 rows and 3 columns.:
</p>

<dl>
<dt><code>Insul</code></dt><dd>
<p>A factor, before or after insulation.
</p>
</dd>
<dt><code>Temp</code></dt><dd>
<p>Purportedly the average outside temperature in degrees Celsius. (These
values is far too low for any 56-week period in the 1960s in
South-East England. It might be the weekly average of daily minima.)
</p>
</dd>
<dt><code>Gas</code></dt><dd>
<p>The weekly gas consumption in 1000s of cubic feet.
</p>
</dd></dl>


<h3>Source</h3>

<p>A data set collected in the 1960s by Mr Derek Whiteside of the
UK Building Research Station. Reported by
</p>
<p>Hand, D. J., Daly, F., McConway, K., Lunn, D. and Ostrowski, E. eds (1993)
<em>A Handbook of Small Data Sets.</em>
Chapman &amp; Hall, p. 69.
</p>


<h3>References</h3>

<p>Venables, W. N. and Ripley, B. D. (2002)
<em>Modern Applied Statistics with S.</em> Fourth edition.  Springer.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require(lattice)
xyplot(Gas ~ Temp | Insul, whiteside, panel =
  function(x, y, ...) {
    panel.xyplot(x, y, ...)
    panel.lmline(x, y, ...)
  }, xlab = "Average external temperature (deg. C)",
  ylab = "Gas consumption  (1000 cubic feet)", aspect = "xy",
  strip = function(...) strip.default(..., style = 1))

gasB &lt;- lm(Gas ~ Temp, whiteside, subset = Insul=="Before")
gasA &lt;- update(gasB, subset = Insul=="After")
summary(gasB)
summary(gasA)
gasBA &lt;- lm(Gas ~ Insul/Temp - 1, whiteside)
summary(gasBA)

gasQ &lt;- lm(Gas ~ Insul/(Temp + I(Temp^2)) - 1, whiteside)
coef(summary(gasQ))

gasPR &lt;- lm(Gas ~ Insul + Temp, whiteside)
anova(gasPR, gasBA)
options(contrasts = c("contr.treatment", "contr.poly"))
gasBA1 &lt;- lm(Gas ~ Insul*Temp, whiteside)
coef(summary(gasBA1))
</code></pre>

<hr>
<h2 id='width.SJ'>
Bandwidth Selection by Pilot Estimation of Derivatives
</h2><span id='topic+width.SJ'></span>

<h3>Description</h3>

<p>Uses the method of Sheather &amp; Jones (1991) to select the bandwidth of
a Gaussian kernel density estimator.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>width.SJ(x, nb = 1000, lower, upper, method = c("ste", "dpi"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="width.SJ_+3A_x">x</code></td>
<td>

<p>a numeric vector
</p>
</td></tr>
<tr><td><code id="width.SJ_+3A_nb">nb</code></td>
<td>

<p>number of bins to use.
</p>
</td></tr>
<tr><td><code id="width.SJ_+3A_upper">upper</code>, <code id="width.SJ_+3A_lower">lower</code></td>
<td>

<p>range over which to search for solution if <code>method = "ste"</code>.
</p>
</td></tr>
<tr><td><code id="width.SJ_+3A_method">method</code></td>
<td>

<p>Either <code>"ste"</code> (&quot;solve-the-equation&quot;) or <code>"dpi"</code>
(&quot;direct plug-in&quot;).
</p>
</td></tr></table>


<h3>Value</h3>

<p>a bandwidth.
</p>


<h3>Note</h3>

<p>A faster version for large <code>n</code> (thousands) is available in <span class="rlang"><b>R</b></span>
<code class="reqn">\ge</code> 3.4.0 as part of <code><a href="stats.html#topic+bw.SJ">bw.SJ</a></code>: quadruple its
value for comparability with this version.
</p>


<h3>References</h3>

<p>Sheather, S. J. and Jones, M. C. (1991) A reliable data-based bandwidth
selection method for kernel density estimation.
<em>Journal of the Royal Statistical Society series B</em>
<b>53</b>, 683&ndash;690.
</p>
<p>Scott, D. W. (1992)
<em>Multivariate Density Estimation: Theory, Practice, and  Visualization.</em>
Wiley.
</p>
<p>Wand, M. P. and Jones, M. C. (1995)
<em>Kernel Smoothing.</em>
Chapman &amp; Hall.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ucv">ucv</a></code>, <code><a href="#topic+bcv">bcv</a></code>, <code><a href="stats.html#topic+density">density</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>width.SJ(geyser$duration, method = "dpi")
width.SJ(geyser$duration)

width.SJ(galaxies, method = "dpi")
width.SJ(galaxies)
</code></pre>

<hr>
<h2 id='write.matrix'>
Write a Matrix or Data Frame
</h2><span id='topic+write.matrix'></span>

<h3>Description</h3>

<p>Writes a matrix or data frame to a file or the console, using column
labels and a layout respecting columns.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>write.matrix(x, file = "", sep = " ", blocksize)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="write.matrix_+3A_x">x</code></td>
<td>

<p>matrix or data frame.
</p>
</td></tr>
<tr><td><code id="write.matrix_+3A_file">file</code></td>
<td>

<p>name of output file. The default (<code>""</code>) is the console.
</p>
</td></tr>
<tr><td><code id="write.matrix_+3A_sep">sep</code></td>
<td>

<p>The separator between columns.
</p>
</td></tr>
<tr><td><code id="write.matrix_+3A_blocksize">blocksize</code></td>
<td>

<p>If supplied and positive, the output is written in blocks of
<code>blocksize</code> rows.  Choose as large as possible consistent with
the amount of memory available.
</p>
</td></tr></table>


<h3>Details</h3>

<p>If <code>x</code> is a matrix, supplying <code>blocksize</code> is more
memory-efficient and enables larger matrices to be written, but each
block of rows might be formatted slightly differently.
</p>
<p>If <code>x</code> is a data frame, the conversion to a matrix may negate the
memory saving.
</p>


<h3>Side Effects</h3>

<p>A formatted file is produced, with column headings (if <code>x</code> has them)
and columns of data.
</p>


<h3>References</h3>

<p>Venables, W. N. and Ripley, B. D. (2002)
<em>Modern Applied Statistics with S.</em> Fourth edition.  Springer.
</p>


<h3>See Also</h3>

<p><code><a href="utils.html#topic+write.table">write.table</a></code>
</p>

<hr>
<h2 id='wtloss'>
Weight Loss Data from an Obese Patient
</h2><span id='topic+wtloss'></span>

<h3>Description</h3>

<p>The data frame gives the weight, in kilograms, of an obese patient at 52
time points over an 8 month period of a weight rehabilitation programme.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>wtloss
</code></pre>


<h3>Format</h3>

<p>This data frame contains the following columns:
</p>

<dl>
<dt><code>Days</code></dt><dd>
<p>time in days since the start of the programme.
</p>
</dd>
<dt><code>Weight</code></dt><dd>
<p>weight in kilograms of the patient.
</p>
</dd>
</dl>



<h3>Source</h3>

<p>Dr T. Davies, Adelaide.
</p>


<h3>References</h3>

<p>Venables, W. N. and Ripley, B. D. (2002)
<em>Modern Applied Statistics with S.</em> Fourth edition.  Springer.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## IGNORE_RDIFF_BEGIN
wtloss.fm &lt;- nls(Weight ~ b0 + b1*2^(-Days/th),
    data = wtloss, start = list(b0=90, b1=95, th=120))
wtloss.fm
## IGNORE_RDIFF_END
plot(wtloss)
with(wtloss, lines(Days, fitted(wtloss.fm)))
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
