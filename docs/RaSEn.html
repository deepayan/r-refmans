<!DOCTYPE html><html lang="en"><head><title>Help for package RaSEn</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {RaSEn}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#colon'><p>Colon data set.</p></a></li>
<li><a href='#predict.RaSE'><p>Predict the outcome of new observations based on the estimated RaSE classifier (Tian, Y. and Feng, Y., 2021).</p></a></li>
<li><a href='#predict.super_RaSE'><p>Predict the outcome of new observations based on the estimated super RaSE classifier (Zhu, J. and Feng, Y., 2021).</p></a></li>
<li><a href='#print.RaSE'><p>Print a fitted RaSE object.</p></a></li>
<li><a href='#print.super_RaSE'><p>Print a fitted super_RaSE object.</p></a></li>
<li><a href='#RaModel'><p>Generate data <code class="reqn">(x, y)</code> from various models in two papers.</p></a></li>
<li><a href='#RaPlot'><p>Visualize the feature ranking results of a fitted RaSE object.</p></a></li>
<li><a href='#RaRank'><p>Rank the features by selected percentages provided by the output from <code>RaScreen</code>.</p></a></li>
<li><a href='#RaScreen'><p>Variable screening via RaSE.</p></a></li>
<li><a href='#Rase'><p>Construct the random subspace ensemble classifier.</p></a></li>
<li><a href='#rat'><p>Affymetrix rat genome 230 2.0 array data set.</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Random Subspace Ensemble Classification and Variable Screening</td>
</tr>
<tr>
<td>Version:</td>
<td>3.0.0</td>
</tr>
<tr>
<td>Author:</td>
<td>Ye Tian [aut, cre] and Yang Feng [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Ye Tian &lt;ye.t@columbia.edu&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>We propose a general ensemble classification framework, RaSE algorithm, for the sparse classification problem. In RaSE algorithm, for each weak learner, some random subspaces are generated and the optimal one is chosen to train the model on the basis of some criterion. To be adapted to the problem, a novel criterion, ratio information criterion (RIC) is put up with based on Kullback-Leibler divergence. Besides minimizing RIC, multiple criteria can be applied, for instance, minimizing extended Bayesian information criterion (eBIC), minimizing training error, minimizing the validation error, minimizing the cross-validation error, minimizing leave-one-out error. There are various choices of base classifier, for instance, linear discriminant analysis, quadratic discriminant analysis, k-nearest neighbour, logistic regression, decision trees, random forest, support vector machines. RaSE algorithm can also be applied to do feature ranking, providing us the importance of each feature based on the selected percentage in multiple subspaces. RaSE framework can be extended to the general prediction framework, including both classification and regression. We can use the selected percentages of variables for variable screening. The latest version added the variable screening function for both regression and classification problems. </td>
</tr>
<tr>
<td>Imports:</td>
<td>MASS, caret, class, doParallel, e1071, foreach, nnet,
randomForest, rpart, stats, ggplot2, gridExtra, formatR, FNN,
ranger, KernelKnn, utils, ModelMetrics, glmnet</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>TRUE</td>
</tr>
<tr>
<td>LazyDataCompression:</td>
<td>bzip2</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.2</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, rmarkdown</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.1.0)</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2021-10-16 03:05:56 UTC; yetian</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2021-10-16 04:50:06 UTC</td>
</tr>
</table>
<hr>
<h2 id='colon'>Colon data set.</h2><span id='topic+colon'></span>

<h3>Description</h3>

<p>Alon et al.'s Colon cancer dataset containing information on 62 samples for 2000 genes. The samples belong to tumor and normal colon tissues.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>colon
</code></pre>


<h3>Format</h3>

<p>A list with the predictor matrix <code>x</code> and binary 0/1 response vector <code>y</code>.
</p>


<h3>Source</h3>

<p>The link to this data set: <a href="http://genomics-pubs.princeton.edu/oncology/">http://genomics-pubs.princeton.edu/oncology/</a>
</p>


<h3>References</h3>

<p>Alon, U., Barkai, N., Notterman, D.A., Gish, K., Ybarra, S., Mack, D. and Levine, A.J., 1999. <em>Broad patterns of gene expression revealed by clustering analysis of tumor and normal colon tissues probed by oligonucleotide arrays. Proceedings of the National Academy of Sciences, 96(12), pp.6745-6750.</em>
</p>
<p>Tian, Y. and Feng, Y., 2021. <em>RaSE: A Variable Screening Framework via Random Subspace Ensembles. arXiv preprint arXiv:2102.03892.</em>
</p>

<hr>
<h2 id='predict.RaSE'>Predict the outcome of new observations based on the estimated RaSE classifier (Tian, Y. and Feng, Y., 2021).</h2><span id='topic+predict.RaSE'></span>

<h3>Description</h3>

<p>Predict the outcome of new observations based on the estimated RaSE classifier (Tian, Y. and Feng, Y., 2021).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'RaSE'
predict(object, newx, type = c("vote", "prob", "raw-vote", "raw-prob"), ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict.RaSE_+3A_object">object</code></td>
<td>
<p>fitted <code>'RaSE'</code> object using <code>Rase</code>.</p>
</td></tr>
<tr><td><code id="predict.RaSE_+3A_newx">newx</code></td>
<td>
<p>a set of new observations. Each row of <code>newx</code> is a new observation.</p>
</td></tr>
<tr><td><code id="predict.RaSE_+3A_type">type</code></td>
<td>
<p>the type of prediction output. Can be 'vote', 'prob', 'raw-vote' or 'raw-prob'. Default = 'vote'.
</p>

<ul>
<li><p> vote: output the predicted class (by voting and cut-off) of new observations. Avalilable for all base learner types.
</p>
</li>
<li><p> prob: output the predicted probabilities (posterior probability of each observation to be class 1) of new observations. It is the average probability over all base learners. Avalilable only when base leaner is not equal to 'svm' and 'tree'.
</p>
</li>
<li><p> raw-vote: output the predicted class of new observations for all base learners. It is a <code>n</code> by <code>B1</code> matrix. <code>n</code> is the test sample size and <code>B1</code> is the number of base learners used in RaSE. Avalilable for all base learner types.
</p>
</li>
<li><p> raw-prob: output the predicted probabilities (posterior probability of each observation to be class 1) of new observations for all base learners. It is a <code>n</code> by <code>B1</code> matrix. Avalilable only when base leaner is not equal to 'svm' and 'tree'.
</p>
</li></ul>
</td></tr>
<tr><td><code id="predict.RaSE_+3A_...">...</code></td>
<td>
<p>additional arguments.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>depends on the parameter <code>type</code>. See the list above.
</p>


<h3>References</h3>

<p>Tian, Y. and Feng, Y., 2021. RaSE: Random subspace ensemble classification. Journal of Machine Learning Research, 22(45), pp.1-93.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Rase">Rase</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
set.seed(0, kind = "L'Ecuyer-CMRG")
train.data &lt;- RaModel("classification", 1, n = 100, p = 50)
test.data &lt;- RaModel("classification", 1, n = 100, p = 50)
xtrain &lt;- train.data$x
ytrain &lt;- train.data$y
xtest &lt;- test.data$x
ytest &lt;- test.data$y

model.fit &lt;- Rase(xtrain, ytrain, B1 = 100, B2 = 100, iteration = 0, base = 'lda',
cores = 2, criterion = 'ric', ranking = TRUE)
ypred &lt;- predict(model.fit, xtest)
mean(ypred != ytest)

## End(Not run)

</code></pre>

<hr>
<h2 id='predict.super_RaSE'>Predict the outcome of new observations based on the estimated super RaSE classifier (Zhu, J. and Feng, Y., 2021).</h2><span id='topic+predict.super_RaSE'></span>

<h3>Description</h3>

<p>Predict the outcome of new observations based on the estimated super RaSE classifier (Zhu, J. and Feng, Y., 2021).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'super_RaSE'
predict(object, newx, type = c("vote", "prob", "raw-vote", "raw-prob"), ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict.super_RaSE_+3A_object">object</code></td>
<td>
<p>fitted <code>'super_RaSE'</code> object using <code>Rase</code>.</p>
</td></tr>
<tr><td><code id="predict.super_RaSE_+3A_newx">newx</code></td>
<td>
<p>a set of new observations. Each row of <code>newx</code> is a new observation.</p>
</td></tr>
<tr><td><code id="predict.super_RaSE_+3A_type">type</code></td>
<td>
<p>the type of prediction output. Can be 'vote', 'prob', 'raw-vote' or 'raw-prob'. Default = 'vote'.
</p>

<ul>
<li><p> vote: output the predicted class (by voting and cut-off) of new observations. Avalilable for all base learner types.
</p>
</li>
<li><p> prob: output the predicted probabilities (posterior probability of each observation to be class 1) of new observations. It is the average probability over all base learners.
</p>
</li>
<li><p> raw-vote: output the predicted class of new observations for all base learners. It is a <code>n</code> by <code>B1</code> matrix. <code>n</code> is the test sample size and <code>B1</code> is the number of base learners used in RaSE. Avalilable for all base learner types.
</p>
</li>
<li><p> raw-prob: output the predicted probabilities (posterior probability of each observation to be class 1) of new observations for all base learners. It is a <code>n</code> by <code>B1</code> matrix.
</p>
</li></ul>
</td></tr>
<tr><td><code id="predict.super_RaSE_+3A_...">...</code></td>
<td>
<p>additional arguments.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>depends on the parameter <code>type</code>. See the list above.
</p>


<h3>References</h3>

<p>Zhu, J. and Feng, Y., 2021. Super RaSE: Super Random Subspace Ensemble Classification. https://www.preprints.org/manuscript/202110.0042
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Rase">Rase</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
set.seed(0, kind = "L'Ecuyer-CMRG")
train.data &lt;- RaModel("classification", 1, n = 100, p = 50)
test.data &lt;- RaModel("classification", 1, n = 100, p = 50)
xtrain &lt;- train.data$x
ytrain &lt;- train.data$y
xtest &lt;- test.data$x
ytest &lt;- test.data$y

# fit a super RaSE classifier by sampling base learner from kNN, LDA and
# logistic regression in equal probability
fit &lt;- Rase(xtrain = xtrain, ytrain = ytrain, B1 = 100, B2 = 100,
base = c("knn", "lda", "logistic"), super = list(type = "separate", base.update = T),
criterion = "cv", cv = 5, iteration = 1, cores = 2)
ypred &lt;- predict(fit, xtest)
mean(ypred != ytest)

## End(Not run)

</code></pre>

<hr>
<h2 id='print.RaSE'>Print a fitted RaSE object.</h2><span id='topic+print.RaSE'></span>

<h3>Description</h3>

<p>Similar to the usual print methods, this function summarizes results.
from a fitted <code>'RaSE'</code> object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'RaSE'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="print.RaSE_+3A_x">x</code></td>
<td>
<p>fitted <code>'RaSE'</code> model object.</p>
</td></tr>
<tr><td><code id="print.RaSE_+3A_...">...</code></td>
<td>
<p>additional arguments.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>No value is returned.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Rase">Rase</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(0, kind = "L'Ecuyer-CMRG")
train.data &lt;- RaModel("classification", 1, n = 100, p = 50)
xtrain &lt;- train.data$x
ytrain &lt;- train.data$y

# test RaSE classifier with LDA base classifier
fit &lt;- Rase(xtrain, ytrain, B1 = 50, B2 = 50, iteration = 0, cutoff = TRUE,
base = 'lda', cores = 2, criterion = 'ric', ranking = TRUE)

# print the summarized results
print(fit)
</code></pre>

<hr>
<h2 id='print.super_RaSE'>Print a fitted super_RaSE object.</h2><span id='topic+print.super_RaSE'></span>

<h3>Description</h3>

<p>Similar to the usual print methods, this function summarizes results.
from a fitted <code>'super_RaSE'</code> object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'super_RaSE'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="print.super_RaSE_+3A_x">x</code></td>
<td>
<p>fitted <code>'super_RaSE'</code> model object.</p>
</td></tr>
<tr><td><code id="print.super_RaSE_+3A_...">...</code></td>
<td>
<p>additional arguments.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>No value is returned.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Rase">Rase</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(0, kind = "L'Ecuyer-CMRG")
train.data &lt;- RaModel("classification", 1, n = 100, p = 50)
xtrain &lt;- train.data$x
ytrain &lt;- train.data$y

# test RaSE classifier with LDA base classifier
fit &lt;- Rase(xtrain, ytrain, B1 = 50, B2 = 50, iteration = 0, cutoff = TRUE,
base = 'lda', cores = 2, criterion = 'ric', ranking = TRUE)

# print the summarized results
print(fit)
</code></pre>

<hr>
<h2 id='RaModel'>Generate data <code class="reqn">(x, y)</code> from various models in two papers.</h2><span id='topic+RaModel'></span>

<h3>Description</h3>

<p><code>RaModel</code> generates data from 4 models described in Tian, Y. and Feng, Y., 2021(b) and 8 models described in Tian, Y. and Feng, Y., 2021(a).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RaModel(model.type, model.no, n, p, p0 = 1/2, sparse = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="RaModel_+3A_model.type">model.type</code></td>
<td>
<p>indicator of the paper covering the model, which can be 'classification' (Tian, Y. and Feng, Y., 2021(b)) or 'screening' (Tian, Y. and Feng, Y., 2021(a)).</p>
</td></tr>
<tr><td><code id="RaModel_+3A_model.no">model.no</code></td>
<td>
<p>model number. It can be 1-4 when <code>model.type</code> = 'classification' and 1-8 when <code>model.type</code> = 'screening', respectively.</p>
</td></tr>
<tr><td><code id="RaModel_+3A_n">n</code></td>
<td>
<p>sample size</p>
</td></tr>
<tr><td><code id="RaModel_+3A_p">p</code></td>
<td>
<p>data dimension</p>
</td></tr>
<tr><td><code id="RaModel_+3A_p0">p0</code></td>
<td>
<p>marginal probability of class 0. Default = 0.5. Only used when <code>model.type</code> = 'classification' and <code>model.no</code> = 1, 2, 3.</p>
</td></tr>
<tr><td><code id="RaModel_+3A_sparse">sparse</code></td>
<td>
<p>a logistic object indicating model sparsity. Default = TRUE. Only used when <code>model.type</code> = 'classification' and <code>model.no</code> = 1, 4.</p>
</td></tr>
</table>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>x</code></td>
<td>
<p>n * p matrix. n observations and p features.</p>
</td></tr>
<tr><td><code>y</code></td>
<td>
<p>n responses.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>When <code>model.type</code> = 'classification' and <code>sparse</code> = TRUE, models 1, 2, 4 require <code class="reqn">p \ge 5</code> and model 3 requires
<code class="reqn">p \ge 50</code>. When <code>model.type</code> = 'classification' and <code>sparse</code> = FALSE, models 1 and 4 require <code class="reqn">p \ge 50</code> and
<code class="reqn">p \ge 30</code>, respectively. When <code>model.type</code> = 'screening', models 1, 4, 5 and 7 require <code class="reqn">p \ge 4</code>. Models 2 and 8 require <code class="reqn">p \ge 5</code>. Model 3 requires <code class="reqn">p \ge 22</code>. Model 5 requires <code class="reqn">p \ge 2</code>.
</p>


<h3>References</h3>

<p>Tian, Y. and Feng, Y., 2021(a). RaSE: A variable screening framework via random subspace ensembles. Journal of the American Statistical Association, (just-accepted), pp.1-30.
</p>
<p>Tian, Y. and Feng, Y., 2021(b). RaSE: Random subspace ensemble classification. Journal of Machine Learning Research, 22(45), pp.1-93.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Rase">Rase</a></code>, <code><a href="#topic+RaScreen">RaScreen</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>train.data &lt;- RaModel("classification", 1, n = 100, p = 50)
xtrain &lt;- train.data$x
ytrain &lt;- train.data$y

## Not run: 
train.data &lt;- RaModel("screening", 2, n = 100, p = 50)
xtrain &lt;- train.data$x
ytrain &lt;- train.data$y

## End(Not run)
</code></pre>

<hr>
<h2 id='RaPlot'>Visualize the feature ranking results of a fitted RaSE object.</h2><span id='topic+RaPlot'></span>

<h3>Description</h3>

<p>This function plots the feature ranking results from a fitted <code>'RaSE'</code> object via <code>ggplot2</code>. In the figure, x-axis represents the feature number and y-axis represents the selected percentage of each feature in B1 subspaces.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RaPlot(
  object,
  main = NULL,
  xlab = "feature",
  ylab = "selected percentage",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="RaPlot_+3A_object">object</code></td>
<td>
<p>fitted <code>'RaSE'</code> model object.</p>
</td></tr>
<tr><td><code id="RaPlot_+3A_main">main</code></td>
<td>
<p>title of the plot. Default = <code>NULL</code>, which makes the title following the orm 'RaSE-base' with subscript i (rounds of iterations), where base represents the type of base classifier. i is omitted when it is zero.</p>
</td></tr>
<tr><td><code id="RaPlot_+3A_xlab">xlab</code></td>
<td>
<p>the label of x-axis. Default = 'feature'.</p>
</td></tr>
<tr><td><code id="RaPlot_+3A_ylab">ylab</code></td>
<td>
<p>the label of y-axis. Default = 'selected percentage'.</p>
</td></tr>
<tr><td><code id="RaPlot_+3A_...">...</code></td>
<td>
<p>additional arguments.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a <code>'ggplot'</code> object.
</p>


<h3>References</h3>

<p>Tian, Y. and Feng, Y., 2021. RaSE: Random subspace ensemble classification. Journal of Machine Learning Research, 22(45), pp.1-93.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Rase">Rase</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(0, kind = "L'Ecuyer-CMRG")
train.data &lt;- RaModel("classification", 1, n = 100, p = 50)
xtrain &lt;- train.data$x
ytrain &lt;- train.data$y

# fit RaSE classifier with QDA base classifier
fit &lt;- Rase(xtrain, ytrain, B1 = 50, B2 = 50, iteration = 1, base = 'qda',
cores = 2, criterion = 'ric')

# plot the selected percentage of each feature appearing in B1 subspaces
RaPlot(fit)

</code></pre>

<hr>
<h2 id='RaRank'>Rank the features by selected percentages provided by the output from <code>RaScreen</code>.</h2><span id='topic+RaRank'></span>

<h3>Description</h3>

<p>Rank the features by selected percentages provided by the output from <code>RaScreen</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RaRank(object, selected.num = "all positive", iteration = object$iteration)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="RaRank_+3A_object">object</code></td>
<td>
<p>output from <code>RaScreen</code>.</p>
</td></tr>
<tr><td><code id="RaRank_+3A_selected.num">selected.num</code></td>
<td>
<p>the number of selected variables. User can either choose from the following popular options or input an positive integer no larger than the dimension.
</p>

<ul>
<li><p> 'all positive': the number of variables with positive selected percentage.
</p>
</li>
<li><p> 'D': floor(D), where D is the maximum of ramdom subspace size.
</p>
</li>
<li><p> '1.5D': floor(1.5D).
</p>
</li>
<li><p> '2D': floor(2D).
</p>
</li>
<li><p> '3D': floor(3D).
</p>
</li>
<li><p> 'n/logn': floor(n/logn), where n is the sample size.
</p>
</li>
<li><p> '1.5n/logn': floor(1.5n/logn).
</p>
</li>
<li><p> '2n/logn': floor(2n/logn).
</p>
</li>
<li><p> '3n/logn': floor(3n/logn).
</p>
</li>
<li><p> 'n-1': the sample size n - 1.
</p>
</li>
<li><p> 'p': the dimension p.
</p>
</li></ul>
</td></tr>
<tr><td><code id="RaRank_+3A_iteration">iteration</code></td>
<td>
<p>indicates results from which iteration to use. It should be an positive integer. Default = the maximal interation round used by the output from <code>RaScreen</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Selected variables (indexes).
</p>


<h3>References</h3>

<p>Tian, Y. and Feng, Y., 2021(a). RaSE: A variable screening framework via random subspace ensembles. Journal of the American Statistical Association, (just-accepted), pp.1-30.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
set.seed(0, kind = "L'Ecuyer-CMRG")
train.data &lt;- RaModel("screening", 1, n = 100, p = 100)
xtrain &lt;- train.data$x
ytrain &lt;- train.data$y

# test RaSE screening with linear regression model and BIC
fit &lt;- RaScreen(xtrain, ytrain, B1 = 100, B2 = 50, iteration = 0, model = 'lm',
cores = 2, criterion = 'bic')

# Select floor(n/logn) variables
RaRank(fit, selected.num = "n/logn")

## End(Not run)
</code></pre>

<hr>
<h2 id='RaScreen'>Variable screening via RaSE.</h2><span id='topic+RaScreen'></span>

<h3>Description</h3>

<p><code>RaSE</code> is a general framework for variable screening. In RaSE screening, to select each of the B1 subspaces, B2 random subspaces are generated and the optimal one is chosen according to some criterion. Then the selected proportions (equivalently, percentages) of variables in the B1 subspaces are used as importance measure to rank these variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RaScreen(
  xtrain,
  ytrain,
  xval = NULL,
  yval = NULL,
  B1 = 200,
  B2 = NULL,
  D = NULL,
  dist = NULL,
  model = NULL,
  criterion = NULL,
  k = 5,
  cores = 1,
  seed = NULL,
  iteration = 0,
  cv = 5,
  scale = FALSE,
  C0 = 0.1,
  kl.k = NULL,
  classification = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="RaScreen_+3A_xtrain">xtrain</code></td>
<td>
<p>n * p observation matrix. n observations, p features.</p>
</td></tr>
<tr><td><code id="RaScreen_+3A_ytrain">ytrain</code></td>
<td>
<p>n 0/1 observatons.</p>
</td></tr>
<tr><td><code id="RaScreen_+3A_xval">xval</code></td>
<td>
<p>observation matrix for validation. Default = <code>NULL</code>. Useful only when <code>criterion</code> = 'validation'.</p>
</td></tr>
<tr><td><code id="RaScreen_+3A_yval">yval</code></td>
<td>
<p>0/1 observation for validation. Default = <code>NULL</code>. Useful only when <code>criterion</code> = 'validation'.</p>
</td></tr>
<tr><td><code id="RaScreen_+3A_b1">B1</code></td>
<td>
<p>the number of weak learners. Default = 200.</p>
</td></tr>
<tr><td><code id="RaScreen_+3A_b2">B2</code></td>
<td>
<p>the number of subspace candidates generated for each weak learner. Default = <code>NULL</code>, which will set B2 = <code class="reqn">20*floor(p/D)</code>.</p>
</td></tr>
<tr><td><code id="RaScreen_+3A_d">D</code></td>
<td>
<p>the maximal subspace size when generating random subspaces. Default = <code>NULL</code>. It means that <code>D</code> = <code class="reqn">min(\sqrt n0, \sqrt n1, p)</code> when <code>model</code> = 'qda', and <code>D</code> = <code class="reqn">min(\sqrt n, p)</code> otherwise.</p>
</td></tr>
<tr><td><code id="RaScreen_+3A_dist">dist</code></td>
<td>
<p>the distribution for features when generating random subspaces. Default = <code>NULL</code>, which represents the hierarchical uniform distribution. First generate an integer <code class="reqn">d</code> from <code class="reqn">1,...,D</code> uniformly, then uniformly generate a subset with cardinality <code class="reqn">d</code>.</p>
</td></tr>
<tr><td><code id="RaScreen_+3A_model">model</code></td>
<td>
<p>the model to use. Default = 'lda' when <code>classification</code> = TRUE and 'lm' when <code>classification</code> = FALSE.
</p>

<ul>
<li><p> lm: linear regression. Only available for regression.
</p>
</li>
<li><p> lda: linear discriminant analysis. <code><a href="MASS.html#topic+lda">lda</a></code> in <code>MASS</code> package. Only available for classification.
</p>
</li>
<li><p> qda: quadratic discriminant analysis. <code><a href="MASS.html#topic+qda">qda</a></code> in <code>MASS</code> package. Only available for classification.
</p>
</li>
<li><p> knn: k-nearest neighbor. <code><a href="class.html#topic+knn">knn</a></code>, <code><a href="class.html#topic+knn.cv">knn.cv</a></code> in <code>class</code> package, <code><a href="caret.html#topic+knn3">knn3</a></code> in <code>caret</code> package and <code><a href="caret.html#topic+knnreg">knnreg</a></code> in <code>caret</code> package.
</p>
</li>
<li><p> logistic: logistic regression. <code><a href="glmnet.html#topic+glmnet">glmnet</a></code> in <code>glmnet</code> package. Only available for classification.
</p>
</li>
<li><p> tree: decision tree. <code><a href="rpart.html#topic+rpart">rpart</a></code> in <code>rpart</code> package. Only available for classification.
</p>
</li>
<li><p> svm: support vector machine. If kernel is not identified by user, it will use RBF kernel. <code><a href="e1071.html#topic+svm">svm</a></code> in <code>e1071</code> package.
</p>
</li>
<li><p> randomforest: random forest. <code><a href="randomForest.html#topic+randomForest">randomForest</a></code> in <code>randomForest</code> package and <code><a href="ranger.html#topic+ranger">ranger</a></code> in <code>ranger</code> package.
</p>
</li>
<li><p> kernelknn: k-nearest neighbor with different kernels. It relies on function <code><a href="KernelKnn.html#topic+KernelKnn">KernelKnn</a></code> in <code>KernelKnn</code> package. Arguments <code>method</code> and <code>weights_function</code> are required. Different choices of multiple arguments are available. See documentation of function <code><a href="KernelKnn.html#topic+KernelKnn">KernelKnn</a></code> for details.
</p>
</li></ul>
</td></tr>
<tr><td><code id="RaScreen_+3A_criterion">criterion</code></td>
<td>
<p>the criterion to choose the best subspace. Default = 'ric' when <code>model</code> = 'lda', 'qda'; default = 'bic' when <code>model</code> = 'lm' or 'logistic'; default = 'loo' when <code>model</code> = 'knn'; default = 'cv' and set <code>cv</code> = 5 when <code>model</code> = 'tree', 'svm', 'randomforest'.
</p>

<ul>
<li><p> ric: minimizing ratio information criterion (RIC) with parametric estimation (Tian, Y. and Feng, Y., 2020). Available for binary classification and <code>model</code> = 'lda', 'qda', or 'logistic'.
</p>
</li>
<li><p> nric: minimizing ratio information criterion (RIC) with non-parametric estimation (Tian, Y. and Feng, Y., 2020; ). Available for binary classification and <code>model</code> = 'lda', 'qda', or 'logistic'.
</p>
</li>
<li><p> training: minimizing training error/MSE. Not available when <code>model</code> = 'knn'.
</p>
</li>
<li><p> loo: minimizing leave-one-out error/MSE. Only available when  <code>model</code> = 'knn'.
</p>
</li>
<li><p> validation: minimizing validation error/MSE based on the validation data.
</p>
</li>
<li><p> cv: minimizing k-fold cross-validation error/MSE. k equals to the value of <code>cv</code>. Default = 5.
</p>
</li>
<li><p> aic: minimizing Akaike information criterion (Akaike, H., 1973). Available when <code>base</code> = 'lm' or 'logistic'.
</p>
<p>AIC = -2 * log-likelihood + |S| * 2.
</p>
</li>
<li><p> bic: minimizing Bayesian information criterion (Schwarz, G., 1978). Available when <code>model</code> = 'lm' or 'logistic'.
</p>
<p>BIC = -2 * log-likelihood + |S| * log(n).
</p>
</li>
<li><p> ebic: minimizing extended Bayesian information criterion (Chen, J. and Chen, Z., 2008; 2012). <code>gam</code> value is needed. When <code>gam</code> = 0, it represents BIC. Available when <code>model</code> = 'lm' or 'logistic'.
</p>
<p>eBIC = -2 * log-likelihood + |S| * log(n) + 2 * |S| * gam * log(p).
</p>
</li></ul>
</td></tr>
<tr><td><code id="RaScreen_+3A_k">k</code></td>
<td>
<p>the number of nearest neightbors considered when <code>model</code> = 'knn' or 'kernel'. Only useful when <code>model</code> = 'knn' or 'kernel'. <code>k</code> is required to be a positive integer. Default = 5.</p>
</td></tr>
<tr><td><code id="RaScreen_+3A_cores">cores</code></td>
<td>
<p>the number of cores used for parallel computing. Default = 1.</p>
</td></tr>
<tr><td><code id="RaScreen_+3A_seed">seed</code></td>
<td>
<p>the random seed assigned at the start of the algorithm, which can be a real number or <code>NULL</code>. Default = <code>NULL</code>, in which case no random seed will be set.</p>
</td></tr>
<tr><td><code id="RaScreen_+3A_iteration">iteration</code></td>
<td>
<p>the number of iterations. Default = 0.</p>
</td></tr>
<tr><td><code id="RaScreen_+3A_cv">cv</code></td>
<td>
<p>the number of cross-validations used. Default = 5. Only useful when <code>criterion</code> = 'cv'.</p>
</td></tr>
<tr><td><code id="RaScreen_+3A_scale">scale</code></td>
<td>
<p>whether to normalize the data. Logistic, default = FALSE.</p>
</td></tr>
<tr><td><code id="RaScreen_+3A_c0">C0</code></td>
<td>
<p>a positive constant used when <code>iteration</code> &gt; 1. See Tian, Y. and Feng, Y., 2021 for details. Default = 0.1.</p>
</td></tr>
<tr><td><code id="RaScreen_+3A_kl.k">kl.k</code></td>
<td>
<p>the number of nearest neighbors used to estimate RIC in a non-parametric way. Default = <code>NULL</code>, which means that <code class="reqn">k0 = floor(\sqrt n0)</code> and <code class="reqn">k1 = floor(\sqrt n1)</code>. See Tian, Y. and Feng, Y., 2020 for details. Only available when <code>criterion</code> = 'nric'.</p>
</td></tr>
<tr><td><code id="RaScreen_+3A_classification">classification</code></td>
<td>
<p>the indicator of the problem type, which can be TRUE, FALSE or <code>NULL</code>. Default = <code>NULL</code>, which will automatically set <code>classification</code> = TRUE if the number of unique response value <code class="reqn">\le</code> 10. Otherwise, it will be set as FALSE.</p>
</td></tr>
<tr><td><code id="RaScreen_+3A_...">...</code></td>
<td>
<p>additional arguments.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list including the following items.
</p>
<table role = "presentation">
<tr><td><code>model</code></td>
<td>
<p>the model used in RaSE screening.</p>
</td></tr>
<tr><td><code>criterion</code></td>
<td>
<p>the criterion to choose the best subspace for each weak learner.</p>
</td></tr>
<tr><td><code>B1</code></td>
<td>
<p>the number of selected subspaces.</p>
</td></tr>
<tr><td><code>B2</code></td>
<td>
<p>the number of subspace candidates generated for each of B1 subspaces.</p>
</td></tr>
<tr><td><code>n</code></td>
<td>
<p>the sample size.</p>
</td></tr>
<tr><td><code>p</code></td>
<td>
<p>the dimension of data.</p>
</td></tr>
<tr><td><code>D</code></td>
<td>
<p>the maximal subspace size when generating random subspaces.</p>
</td></tr>
<tr><td><code>iteration</code></td>
<td>
<p>the number of iterations.</p>
</td></tr>
<tr><td><code>selected.perc</code></td>
<td>
<p>A list of length (<code>iteration</code>+1) recording the selected percentages of each feature in B1 subspaces. When it is of length 1, the result will be automatically transformed to a vector.</p>
</td></tr>
<tr><td><code>scale</code></td>
<td>
<p>a list of scaling parameters, including the scaling center and the scale parameter for each feature. Equals to <code>NULL</code> when the data is not scaled by <code>RaScreen</code>.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Tian, Y. and Feng, Y., 2021(a). RaSE: A variable screening framework via random subspace ensembles. Journal of the American Statistical Association, (just-accepted), pp.1-30.
</p>
<p>Tian, Y. and Feng, Y., 2021(b). RaSE: Random subspace ensemble classification. Journal of Machine Learning Research, 22(45), pp.1-93.
</p>
<p>Chen, J. and Chen, Z., 2008. Extended Bayesian information criteria for model selection with large model spaces. Biometrika, 95(3), pp.759-771.
</p>
<p>Chen, J. and Chen, Z., 2012. Extended BIC for small-n-large-P sparse GLM. Statistica Sinica, pp.555-574.
</p>
<p>Schwarz, G., 1978. Estimating the dimension of a model. The annals of statistics, 6(2), pp.461-464.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Rase">Rase</a></code>, <code><a href="#topic+RaRank">RaRank</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(0, kind = "L'Ecuyer-CMRG")
train.data &lt;- RaModel("screening", 1, n = 100, p = 100)
xtrain &lt;- train.data$x
ytrain &lt;- train.data$y

# test RaSE screening with linear regression model and BIC
fit &lt;- RaScreen(xtrain, ytrain, B1 = 100, B2 = 50, iteration = 0, model = 'lm',
cores = 2, criterion = 'bic')

# Select D variables
RaRank(fit, selected.num = "D")


## Not run: 
# test RaSE screening with knn model and 5-fold cross-validation MSE
fit &lt;- RaScreen(xtrain, ytrain, B1 = 100, B2 = 50, iteration = 0, model = 'knn',
cores = 2, criterion = 'cv', cv = 5)

# Select n/logn variables
RaRank(fit, selected.num = "n/logn")


# test RaSE screening with SVM and 5-fold cross-validation MSE
fit &lt;- RaScreen(xtrain, ytrain, B1 = 100, B2 = 50, iteration = 0, model = 'svm',
cores = 2, criterion = 'cv', cv = 5)

# Select n/logn variables
RaRank(fit, selected.num = "n/logn")


# test RaSE screening with logistic regression model and eBIC (gam = 0.5). Set iteration number = 1
train.data &lt;- RaModel("screening", 6, n = 100, p = 100)
xtrain &lt;- train.data$x
ytrain &lt;- train.data$y

fit &lt;- RaScreen(xtrain, ytrain, B1 = 100, B2 = 100, iteration = 1, model = 'logistic',
cores = 2, criterion = 'ebic', gam = 0.5)

# Select n/logn variables from the selected percentage after one iteration round
RaRank(fit, selected.num = "n/logn", iteration = 1)

## End(Not run)
</code></pre>

<hr>
<h2 id='Rase'>Construct the random subspace ensemble classifier.</h2><span id='topic+Rase'></span>

<h3>Description</h3>

<p><code>RaSE</code> is a general ensemble classification framework to solve the sparse classification problem. In RaSE algorithm, for each of the B1 weak learners, B2 random subspaces are generated and the optimal one is chosen to train the model on the basis of some criterion.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Rase(
  xtrain,
  ytrain,
  xval = NULL,
  yval = NULL,
  B1 = 200,
  B2 = 500,
  D = NULL,
  dist = NULL,
  base = NULL,
  super = list(type = c("separate"), base.update = TRUE),
  criterion = NULL,
  ranking = TRUE,
  k = c(3, 5, 7, 9, 11),
  cores = 1,
  seed = NULL,
  iteration = 0,
  cutoff = TRUE,
  cv = 5,
  scale = FALSE,
  C0 = 0.1,
  kl.k = NULL,
  lower.limits = NULL,
  upper.limits = NULL,
  weights = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Rase_+3A_xtrain">xtrain</code></td>
<td>
<p>n * p observation matrix. n observations, p features.</p>
</td></tr>
<tr><td><code id="Rase_+3A_ytrain">ytrain</code></td>
<td>
<p>n 0/1 observatons.</p>
</td></tr>
<tr><td><code id="Rase_+3A_xval">xval</code></td>
<td>
<p>observation matrix for validation. Default = <code>NULL</code>. Useful only when <code>criterion</code> = 'validation'.</p>
</td></tr>
<tr><td><code id="Rase_+3A_yval">yval</code></td>
<td>
<p>0/1 observation for validation. Default = <code>NULL</code>. Useful only when <code>criterion</code> = 'validation'.</p>
</td></tr>
<tr><td><code id="Rase_+3A_b1">B1</code></td>
<td>
<p>the number of weak learners. Default = 200.</p>
</td></tr>
<tr><td><code id="Rase_+3A_b2">B2</code></td>
<td>
<p>the number of subspace candidates generated for each weak learner. Default = 500.</p>
</td></tr>
<tr><td><code id="Rase_+3A_d">D</code></td>
<td>
<p>the maximal subspace size when generating random subspaces. Default = <code>NULL</code>, which is <code class="reqn">min(\sqrt n0, \sqrt n1, p)</code> when <code>base</code> = 'qda' and is <code class="reqn">min(\sqrt n, p)</code> otherwise. For classical RaSE with a single classifier type, <code>D</code> is a positive integer. For super RaSE with multiple classifier types, <code>D</code> is a vector indicating different D values used for each base classifier type (the corresponding classifier types should be noted in the names of the vector).</p>
</td></tr>
<tr><td><code id="Rase_+3A_dist">dist</code></td>
<td>
<p>the distribution for features when generating random subspaces. Default = <code>NULL</code>, which represents the uniform distribution. First generate an integer <code class="reqn">d</code> from <code class="reqn">1,...,D</code> uniformly, then uniformly generate a subset with cardinality <code class="reqn">d</code>.</p>
</td></tr>
<tr><td><code id="Rase_+3A_base">base</code></td>
<td>
<p>the type of base classifier. Default = 'lda'. Can be either a single string chosen from the following options or a string/probability vector. When it indicates a single type of base classifiers, the classical RaSE model (Tian, Y. and Feng, Y., 2021(b)) will be fitted. When it is a string vector which includes multiple base classifier types, a super RaSE model (Zhu, J. and Feng, Y., 2021) will be fitted, by samling base classifiers with equal probabilty. It can also be a probability vector with row names corresponding to the specific classifier type, in which case a super RaSE model will be trained by sampling base classifiers in the given sampling probability.
</p>

<ul>
<li><p> lda: linear discriminant analysis. <code><a href="MASS.html#topic+lda">lda</a></code> in <code>MASS</code> package.
</p>
</li>
<li><p> qda: quadratic discriminant analysis. <code><a href="MASS.html#topic+qda">qda</a></code> in <code>MASS</code> package.
</p>
</li>
<li><p> knn: k-nearest neighbor. <code><a href="class.html#topic+knn">knn</a></code>, <code><a href="class.html#topic+knn.cv">knn.cv</a></code> in <code>class</code> package and <code><a href="caret.html#topic+knn3">knn3</a></code> in <code>caret</code> package.
</p>
</li>
<li><p> logistic: logistic regression. <code><a href="stats.html#topic+glm">glm</a></code> in <code>stats</code> package and <code><a href="glmnet.html#topic+glmnet">glmnet</a></code> in <code>glmnet</code> package.
</p>
</li>
<li><p> tree: decision tree. <code><a href="rpart.html#topic+rpart">rpart</a></code> in <code>rpart</code> package.
</p>
</li>
<li><p> svm: support vector machine. <code><a href="e1071.html#topic+svm">svm</a></code> in <code>e1071</code> package.
</p>
</li>
<li><p> randomforest: random forest. <code><a href="randomForest.html#topic+randomForest">randomForest</a></code> in <code>randomForest</code> package.
</p>
</li>
<li><p> gamma: Bayesian classifier for multivariate gamma distribution with independent marginals.
</p>
</li></ul>
</td></tr>
<tr><td><code id="Rase_+3A_super">super</code></td>
<td>
<p>a list of control parameters for super RaSE (Zhu, J. and Feng, Y., 2021). Not used when base equals to a single string. Should be a list object with the following components:
</p>

<ul>
<li><p> type: the type of super RaSE. Currently the only option is 'separate', meaning that subspace distributions are different for each type of base classifiers.
</p>
</li>
<li><p> base.update: indicates whether the sampling probability of base classifiers should be updated during iterations or not. Logistic, default = TRUE.
</p>
</li></ul>
</td></tr>
<tr><td><code id="Rase_+3A_criterion">criterion</code></td>
<td>
<p>the criterion to choose the best subspace for each weak learner. For the classical RaSE (when <code>base</code> includes a single classifier type), default = 'ric' when <code>base</code> = 'lda', 'qda', 'gamma'; default = 'ebic' and set <code>gam</code> = 0 when <code>base</code> = 'logistic'; default = 'loo' when <code>base</code> = 'knn'; default = 'training' when <code>base</code> = 'tree', 'svm', 'randomforest'. For the super RaSE (when <code>base</code> indicates multiple classifiers or the sampling probability of multiple classifiers), default = 'cv' with the number of folds <code>cv</code> = 5, and it can only be 'cv', 'training' or 'auc'.
</p>

<ul>
<li><p> ric: minimizing ratio information criterion with parametric estimation (Tian, Y. and Feng, Y., 2021(b)). Available when <code>base</code> = 'lda', 'qda', 'gamma' or 'logistic'.
</p>
</li>
<li><p> nric: minimizing ratio information criterion with non-parametric estimation (Tian, Y. and Feng, Y., 2021(b)). Available when <code>base</code> = 'lda', 'qda', 'gamma' or 'logistic'.
</p>
</li>
<li><p> training: minimizing training error. Not available when <code>base</code> = 'knn'.
</p>
</li>
<li><p> loo: minimizing leave-one-out error. Only available when  <code>base</code> = 'knn'.
</p>
</li>
<li><p> validation: minimizing validation error based on the validation data. Available for all base classifiers.
</p>
</li>
<li><p> auc: minimizing negative area under the ROC curve (AUC). Currently it is estimated on training data via function <code><a href="ModelMetrics.html#topic+auc">auc</a></code> from package <code>ModelMetrics</code>. It is available for all classier choices.
</p>
</li>
<li><p> cv: minimizing k-fold cross-validation error. k equals to the value of <code>cv</code>. Default = 5. Not available when <code>base</code> = 'gamma'.
</p>
</li>
<li><p> aic: minimizing Akaike information criterion (Akaike, H., 1973). Available when <code>base</code> = 'lda' or 'logistic'.
</p>
<p>AIC = -2 * log-likelihood + |S| * 2.
</p>
</li>
<li><p> bic: minimizing Bayesian information criterion (Schwarz, G., 1978). Available when <code>base</code> = 'lda' or 'logistic'.
</p>
<p>BIC = -2 * log-likelihood + |S| * log(n).
</p>
</li>
<li><p> ebic: minimizing extended Bayesian information criterion (Chen, J. and Chen, Z., 2008; 2012). Need to assign value for <code>gam</code>. When <code>gam</code> = 0, it denotes the classical BIC. Available when <code>base</code> = 'lda' or 'logistic'.
</p>
<p>EBIC = -2 * log-likelihood + |S| * log(n) + 2 * |S| * gam * log(p).
</p>
</li></ul>
</td></tr>
<tr><td><code id="Rase_+3A_ranking">ranking</code></td>
<td>
<p>whether the function outputs the selected percentage of each feature in B1 subspaces. Logistic, default = TRUE.</p>
</td></tr>
<tr><td><code id="Rase_+3A_k">k</code></td>
<td>
<p>the number of nearest neightbors considered when <code>base</code> = 'knn'. Only useful when <code>base</code> = 'knn'. Default = (3, 5, 7, 9, 11).</p>
</td></tr>
<tr><td><code id="Rase_+3A_cores">cores</code></td>
<td>
<p>the number of cores used for parallel computing. Default = 1.</p>
</td></tr>
<tr><td><code id="Rase_+3A_seed">seed</code></td>
<td>
<p>the random seed assigned at the start of the algorithm, which can be a real number or <code>NULL</code>. Default = <code>NULL</code>, in which case no random seed will be set.</p>
</td></tr>
<tr><td><code id="Rase_+3A_iteration">iteration</code></td>
<td>
<p>the number of iterations. Default = 0.</p>
</td></tr>
<tr><td><code id="Rase_+3A_cutoff">cutoff</code></td>
<td>
<p>whether to use the empirically optimal threshold. Logistic, default = TRUE. If it is FALSE, the threshold will be set as 0.5.</p>
</td></tr>
<tr><td><code id="Rase_+3A_cv">cv</code></td>
<td>
<p>the number of cross-validations used. Default = 5. Only useful when <code>criterion</code> = 'cv'.</p>
</td></tr>
<tr><td><code id="Rase_+3A_scale">scale</code></td>
<td>
<p>whether to normalize the data. Logistic, default = FALSE.</p>
</td></tr>
<tr><td><code id="Rase_+3A_c0">C0</code></td>
<td>
<p>a positive constant used when <code>iteration</code> &gt; 1. Default = 0.1. See Tian, Y. and Feng, Y., 2021(b) for details.</p>
</td></tr>
<tr><td><code id="Rase_+3A_kl.k">kl.k</code></td>
<td>
<p>the number of nearest neighbors used to estimate RIC in a non-parametric way. Default = <code>NULL</code>, which means that <code class="reqn">k0 = floor(\sqrt n0)</code> and <code class="reqn">k1 = floor(\sqrt n1)</code>. See Tian, Y. and Feng, Y., 2021(b) for details. Only available when <code>criterion</code> = 'nric'.</p>
</td></tr>
<tr><td><code id="Rase_+3A_lower.limits">lower.limits</code></td>
<td>
<p>the vector of lower limits for each coefficient in logistic regression. Should be a vector of length equal to the number of variables (the column number of <code>xtrain</code>). Each of these must be non-positive. Default = <code>NULL</code>, meaning that lower limits are <code>-Inf</code> for all coefficients. Only available when <code>base</code> = 'logistic'. When it's activated, function <code><a href="glmnet.html#topic+glmnet">glmnet</a></code> will be used to fit logistic regression models, in which case the minimum subspace size is required to be larger than 1. The default subspace size distribution will be changed to uniform distribution on (2, ..., D).</p>
</td></tr>
<tr><td><code id="Rase_+3A_upper.limits">upper.limits</code></td>
<td>
<p>the vector of upper limits for each coefficient in logistic regression. Should be a vector of length equal to the number of variables (the column number of <code>xtrain</code>). Each of these must be non-negative. Default = <code>NULL</code>, meaning that upper limits are <code>Inf</code> for all coefficients. Only available when <code>base</code> = 'logistic'. When it's activated, function <code><a href="glmnet.html#topic+glmnet">glmnet</a></code> will be used to fit logistic regression models, in which case the minimum subspace size is required to be larger than 1. The default subspace size distribution will be changed to uniform distribution on (2, ..., D).</p>
</td></tr>
<tr><td><code id="Rase_+3A_weights">weights</code></td>
<td>
<p>observation weights. Should be a vector of length equal to training sample size (the length of <code>ytrain</code>). It will be normailized inside the algorithm. Each component of weights must be non-negative. Default is <code>NULL</code>, representing equal weight for each observation. Only available when <code>base</code> = 'logistic'. When it's activated, function <code><a href="glmnet.html#topic+glmnet">glmnet</a></code> will be used to fit logistic regression models, in which case the minimum subspace size is required to be larger than 1. The default subspace size distribution will be changed to uniform distribution on (2, ..., D).</p>
</td></tr>
<tr><td><code id="Rase_+3A_...">...</code></td>
<td>
<p>additional arguments.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object with S3 class <code>'RaSE'</code> if <code>base</code> indicates a single base classifier.
</p>
<table role = "presentation">
<tr><td><code>marginal</code></td>
<td>
<p>the marginal probability for each class.</p>
</td></tr>
<tr><td><code>base</code></td>
<td>
<p>the type of base classifier.</p>
</td></tr>
<tr><td><code>criterion</code></td>
<td>
<p>the criterion to choose the best subspace for each weak learner.</p>
</td></tr>
<tr><td><code>B1</code></td>
<td>
<p>the number of weak learners.</p>
</td></tr>
<tr><td><code>B2</code></td>
<td>
<p>the number of subspace candidates generated for each weak learner.</p>
</td></tr>
<tr><td><code>D</code></td>
<td>
<p>the maximal subspace size when generating random subspaces.</p>
</td></tr>
<tr><td><code>iteration</code></td>
<td>
<p>the number of iterations.</p>
</td></tr>
<tr><td><code>fit.list</code></td>
<td>
<p>sequence of B1 fitted base classifiers.</p>
</td></tr>
<tr><td><code>cutoff</code></td>
<td>
<p>the empirically optimal threshold.</p>
</td></tr>
<tr><td><code>subspace</code></td>
<td>
<p>sequence of subspaces correponding to B1 weak learners.</p>
</td></tr>
<tr><td><code>ranking</code></td>
<td>
<p>the selected percentage of each feature in B1 subspaces.</p>
</td></tr>
<tr><td><code>scale</code></td>
<td>
<p>a list of scaling parameters, including the scaling center and the scale parameter for each feature. Equals to <code>NULL</code> when the data is not scaled in <code>RaSE</code> model fitting.</p>
</td></tr>
</table>
<p>An object with S3 class <code>'super_RaSE'</code> if <code>base</code> includes multiple base classifiers or the sampling probability of multiple classifiers.
</p>
<table role = "presentation">
<tr><td><code>marginal</code></td>
<td>
<p>the marginal probability for each class.</p>
</td></tr>
<tr><td><code>base</code></td>
<td>
<p>the list of B1 base classifier types.</p>
</td></tr>
<tr><td><code>criterion</code></td>
<td>
<p>the criterion to choose the best subspace for each weak learner.</p>
</td></tr>
<tr><td><code>B1</code></td>
<td>
<p>the number of weak learners.</p>
</td></tr>
<tr><td><code>B2</code></td>
<td>
<p>the number of subspace candidates generated for each weak learner.</p>
</td></tr>
<tr><td><code>D</code></td>
<td>
<p>the maximal subspace size when generating random subspaces.</p>
</td></tr>
<tr><td><code>iteration</code></td>
<td>
<p>the number of iterations.</p>
</td></tr>
<tr><td><code>fit.list</code></td>
<td>
<p>sequence of B1 fitted base classifiers.</p>
</td></tr>
<tr><td><code>cutoff</code></td>
<td>
<p>the empirically optimal threshold.</p>
</td></tr>
<tr><td><code>subspace</code></td>
<td>
<p>sequence of subspaces correponding to B1 weak learners.</p>
</td></tr>
<tr><td><code>ranking.feature</code></td>
<td>
<p>the selected percentage of each feature corresponding to each type of classifier.</p>
</td></tr>
<tr><td><code>ranking.base</code></td>
<td>
<p>the selected percentage of each classifier type in the selected B1 learners.</p>
</td></tr>
<tr><td><code>scale</code></td>
<td>
<p>a list of scaling parameters, including the scaling center and the scale parameter for each feature. Equals to <code>NULL</code> when the data is not scaled in <code>RaSE</code> model fitting.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Ye Tian (maintainer, <a href="mailto:ye.t@columbia.edu">ye.t@columbia.edu</a>) and Yang Feng. The authors thank Yu Cao (Exeter Finance) and his team for many helpful suggestions and discussions.
</p>


<h3>References</h3>

<p>Tian, Y. and Feng, Y., 2021(a). RaSE: A variable screening framework via random subspace ensembles. Journal of the American Statistical Association, (just-accepted), pp.1-30.
</p>
<p>Tian, Y. and Feng, Y., 2021(b). RaSE: Random subspace ensemble classification. Journal of Machine Learning Research, 22(45), pp.1-93.
</p>
<p>Zhu, J. and Feng, Y., 2021. Super RaSE: Super Random Subspace Ensemble Classification. https://www.preprints.org/manuscript/202110.0042
</p>
<p>Chen, J. and Chen, Z., 2008. Extended Bayesian information criteria for model selection with large model spaces. Biometrika, 95(3), pp.759-771.
</p>
<p>Chen, J. and Chen, Z., 2012. Extended BIC for small-n-large-P sparse GLM. Statistica Sinica, pp.555-574.
</p>
<p>Akaike, H., 1973. Information theory and an extension of the maximum likelihood principle. In 2nd International Symposium on Information Theory, 1973 (pp. 267-281). Akademiai Kaido.
</p>
<p>Schwarz, G., 1978. Estimating the dimension of a model. The annals of statistics, 6(2), pp.461-464.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+predict.RaSE">predict.RaSE</a></code>, <code><a href="#topic+RaModel">RaModel</a></code>, <code><a href="#topic+print.RaSE">print.RaSE</a></code>, <code><a href="#topic+print.super_RaSE">print.super_RaSE</a></code>, <code><a href="#topic+RaPlot">RaPlot</a></code>, <code><a href="#topic+RaScreen">RaScreen</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(0, kind = "L'Ecuyer-CMRG")
train.data &lt;- RaModel("classification", 1, n = 100, p = 50)
test.data &lt;- RaModel("classification", 1, n = 100, p = 50)
xtrain &lt;- train.data$x
ytrain &lt;- train.data$y
xtest &lt;- test.data$x
ytest &lt;- test.data$y

# test RaSE classifier with LDA base classifier
fit &lt;- Rase(xtrain, ytrain, B1 = 100, B2 = 50, iteration = 0, base = 'lda',
cores = 2, criterion = 'ric')
mean(predict(fit, xtest) != ytest)

## Not run: 
# test RaSE classifier with LDA base classifier and 1 iteration round
fit &lt;- Rase(xtrain, ytrain, B1 = 100, B2 = 50, iteration = 1, base = 'lda',
cores = 2, criterion = 'ric')
mean(predict(fit, xtest) != ytest)

# test RaSE classifier with QDA base classifier and 1 iteration round
fit &lt;- Rase(xtrain, ytrain, B1 = 100, B2 = 50, iteration = 1, base = 'qda',
cores = 2, criterion = 'ric')
mean(predict(fit, xtest) != ytest)

# test RaSE classifier with kNN base classifier
fit &lt;- Rase(xtrain, ytrain, B1 = 100, B2 = 50, iteration = 0, base = 'knn',
cores = 2, criterion = 'loo')
mean(predict(fit, xtest) != ytest)

# test RaSE classifier with logistic regression base classifier
fit &lt;- Rase(xtrain, ytrain, B1 = 100, B2 = 50, iteration = 0, base = 'logistic',
cores = 2, criterion = 'bic')
mean(predict(fit, xtest) != ytest)

# test RaSE classifier with SVM base classifier
fit &lt;- Rase(xtrain, ytrain, B1 = 100, B2 = 50, iteration = 0, base = 'svm',
cores = 2, criterion = 'training')
mean(predict(fit, xtest) != ytest)

# test RaSE classifier with random forest base classifier
fit &lt;- Rase(xtrain, ytrain, B1 = 20, B2 = 10, iteration = 0, base = 'randomforest',
cores = 2, criterion = 'cv', cv = 3)
mean(predict(fit, xtest) != ytest)

# fit a super RaSE classifier by sampling base learner from kNN, LDA and logistic
# regression in equal probability
fit &lt;- Rase(xtrain = xtrain, ytrain = ytrain, B1 = 100, B2 = 100,
base = c("knn", "lda", "logistic"), super = list(type = "separate", base.update = T),
criterion = "cv", cv = 5, iteration = 1, cores = 2)
mean(predict(fit, xtest) != ytest)

# fit a super RaSE classifier by sampling base learner from random forest, LDA and
# SVM with probability 0.2, 0.5 and 0.3
fit &lt;- Rase(xtrain = xtrain, ytrain = ytrain, B1 = 100, B2 = 100,
base = c(randomforest = 0.2, lda = 0.5, svm = 0.3),
super = list(type = "separate", base.update = F),
criterion = "cv", cv = 5, iteration = 0, cores = 2)
mean(predict(fit, xtest) != ytest)

## End(Not run)
</code></pre>

<hr>
<h2 id='rat'>Affymetrix rat genome 230 2.0 array data set.</h2><span id='topic+rat'></span>

<h3>Description</h3>

<p>Affymetrix rat genome 230 2.0 array annotation data (chip rat2302). For this data set, 120 twelve-week old male rats were selected for tissue harvesting from the eyes and for microarray analysis. The expression of gene TRIM32 is set as the response and the 18975 probes that are expressed in the eye tissue are considered as the predictors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rat
</code></pre>


<h3>Format</h3>

<p>A list with the predictor matrix <code>x</code> and the response vector <code>y</code>.
</p>


<h3>Source</h3>

<p>The link to this data set: <a href="https://bioconductor.org/packages/release/data/annotation/html/rat2302.db.html">https://bioconductor.org/packages/release/data/annotation/html/rat2302.db.html</a>
</p>


<h3>References</h3>

<p>Scheetz, T.E., Kim, K.Y.A., Swiderski, R.E., Philp, A.R., Braun, T.A., Knudtson, K.L., Dorrance, A.M., DiBona, G.F., Huang, J., Casavant, T.L. and Sheffield, V.C., 2006. <em>Regulation of gene expression in the mammalian eye and its relevance to eye disease. Proceedings of the National Academy of Sciences, 103(39), pp.14429-14434.</em>
</p>
<p>Tian, Y. and Feng, Y., 2021. <em>RaSE: A Variable Screening Framework via Random Subspace Ensembles. arXiv preprint arXiv:2102.03892.</em>
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
