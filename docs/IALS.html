<!DOCTYPE html><html><head><title>Help for package IALS</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {IALS}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#Distance'>
<p>The distance between the spaces spanned by the column of two matrices.</p></a></li>
<li><a href='#IALS'>
<p>Iterative Alternating Least Square Estimation for Large-dimensional Matrix Factor Model</p></a></li>
<li><a href='#KIALS'>
<p>Estimating the Pair of Factor Numbers via Eigenvalue Ratios Corresponding to IALS</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Iterative Alternating Least Square Estimation for
Large-Dimensional Matrix Factor Model</td>
</tr>
<tr>
<td>Version:</td>
<td>0.1.3</td>
</tr>
<tr>
<td>Author:</td>
<td>Yong He [aut],
  Ran Zhao [aut, cre],
  Wen-Xin Zhou [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Ran Zhao &lt;Zhaoran@mail.sdu.edu.cn&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>The matrix factor model has drawn growing attention for its advantage in achieving two-directional dimension reduction simultaneously for matrix-structured observations. In contrast to the Principal Component Analysis (PCA)-based methods, we propose a simple Iterative Alternating Least Squares (IALS) algorithm for matrix factor model, see the details in He et al. (2023) &lt;<a href="https://arxiv.org/abs/2301.00360">arXiv:2301.00360</a>&gt;.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 4.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>RSpectra, pracma, HDMFA</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-02-16 11:31:24 UTC; 赵冉</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-02-16 11:50:07 UTC</td>
</tr>
</table>
<hr>
<h2 id='Distance'>
The distance between the spaces spanned by the column of two matrices.
</h2><span id='topic+Distance'></span>

<h3>Description</h3>

<p>Calculate the distance between spaces spanned by the column of two matrices. The distance is between 0 and 1. If the two spaces are the same, the distance is 0. if the two spaces are orthogonal, the distance is 1.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Distance(Z1, Z2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Distance_+3A_z1">Z1</code></td>
<td>

<p>Input a matrix with <code class="reqn">p \times q_1</code>.
</p>
</td></tr>
<tr><td><code id="Distance_+3A_z2">Z2</code></td>
<td>

<p>Input another matrix with <code class="reqn">p \times q_2</code>
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Define </p>
<p style="text-align: center;"><code class="reqn">\mathcal{D}(\bold{Q}_1,\bold{Q}_2)=\left(1-\frac{1}{\max{(q_1,q_2)}}\text{Tr}\left(\bold{Q}_1\bold{Q}_1^\top\bold{Q}_2\bold{Q}_2^\top\right)\right)^{1/2}.</code>
</p>

<p>By the definition of <code class="reqn">\mathcal{D}(\bold{Q}_1,\bold{Q}_2)</code>, we can easily see that <code class="reqn">0 \leq \mathcal{D}(\bold{Q}_1,\bold{Q}_2)\leq 1</code>, which measures the distance between the column spaces spanned by two orthogonal matrices <code class="reqn">\bold{Q}_1</code> and <code class="reqn">\bold{Q}_2</code>, i.e., <code class="reqn">\text{span}(\bold{Q}_1)</code> and <code class="reqn">\text{span}(\bold{Q}_2)</code>. In particular, <code class="reqn">\text{span}(\bold{Q}_1)</code> and <code class="reqn">\text{span}(\bold{Q}_2)</code> are the same when <code class="reqn">\mathcal{D}(\bold{Q}_1,\bold{Q}_2)=0</code>, while  <code class="reqn">\text{span}(\bold{Q}_1)</code> and <code class="reqn">\text{span}(\bold{Q}_2)</code> are orthogonal when <code class="reqn">\mathcal{D}(\bold{Q}_1,\bold{Q}_2)=1</code>. The Gram-Schmidt orthogonalization can be used to make <code class="reqn">\bold{Q}_1</code> and <code class="reqn">\bold{Q}_2</code> column-orthogonal matrices.
</p>


<h3>Value</h3>

<p>Output a number between 0 and 1.
</p>


<h3>Author(s)</h3>

<p>Yong He, Ran Zhao, Wen-Xin Zhou.
</p>


<h3>References</h3>

<p>He, Y., Zhao, R., &amp; Zhou, W. X. (2023). Iterative Least Squares Algorithm for Large-dimensional Matrix Factor Model by Random Projection. &lt;arXiv:2301.00360&gt;.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1111)
A=matrix(rnorm(10),5,2)
B=matrix(rnorm(15),5,3)
Distance(A,B)
</code></pre>

<hr>
<h2 id='IALS'>
Iterative Alternating Least Square Estimation for Large-dimensional Matrix Factor Model
</h2><span id='topic+IALS'></span>

<h3>Description</h3>

<p>This function is designed to fit the matrix factor model using the Iterative Least Squares (IALS) method, rather than Principal Component Analysis (PCA)-based methods. In detail, in the first step, we propose to estimate the latent factor matrices by projecting the matrix observations with two deterministic weight matrices, chosen to diversify away the idiosyncratic components. In the second step, we update the row/column loading matrices by minimizing the squared loss function under the identifiability condition. The estimators of the loading matrices are then treated as the new weight matrices, and the algorithm iteratively performs these two steps until a convergence criterion is reached.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>IALS(X, W1 = NULL, W2 = NULL, m1, m2, max_iter = 100, ep = 1e-06)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="IALS_+3A_x">X</code></td>
<td>

<p>Input an array with <code class="reqn">T \times p_1 \times p_2</code>, where <code class="reqn">T</code> is the sample size, <code class="reqn">p_1</code> is the the row dimension of each matrix observation and <code class="reqn">p_2</code> is the the column dimension of each matrix observation.
</p>
</td></tr>
<tr><td><code id="IALS_+3A_w1">W1</code></td>
<td>

<p>The initial value for the row factor loading matrix. The default is NULL, with an initial estimate chosen from <code class="reqn">\alpha</code>-PCA if not provided.
</p>
</td></tr>
<tr><td><code id="IALS_+3A_w2">W2</code></td>
<td>

<p>The initial value for the column factor loading matrix. The default is NULL, with an initial estimate chosen from <code class="reqn">\alpha</code>-PCA if not provided.
</p>
</td></tr>
<tr><td><code id="IALS_+3A_m1">m1</code></td>
<td>

<p>A positive integer indicating the row factor number.
</p>
</td></tr>
<tr><td><code id="IALS_+3A_m2">m2</code></td>
<td>

<p>A positive integer indicating the column factor number.
</p>
</td></tr>
<tr><td><code id="IALS_+3A_max_iter">max_iter</code></td>
<td>

<p>The maximum number of iterations for the algorithm, default is 100.
</p>
</td></tr>
<tr><td><code id="IALS_+3A_ep">ep</code></td>
<td>

<p>The stopping criterion in the iteration algorithm, default is <code class="reqn">10^{-6} \times Tp_1 p_2</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Assume we have two weight matrices <code class="reqn">\bold{W}_i</code> of dimension <code class="reqn">p_{i} \times m_{i}</code> for <code class="reqn">i=1,2</code>, as substitutes for <code class="reqn">\bold{R}</code> and <code class="reqn">\bold{C}</code> respectively. Then it is straightforward to estimate <code class="reqn">\bold{F}_t</code> simply by
</p>
<p style="text-align: center;"><code class="reqn">\hat{\bold{F}}_{t}=\frac{1}{p_{1}p_{2}}\bold{W}_1^\top\bold{X}_t\bold{W}_2.</code>
</p>

<p>Given <code class="reqn">\hat{\bold{F}}_t</code> and <code class="reqn">\bold{W}_1</code>, we can derive that 
</p>
<p style="text-align: center;"><code class="reqn">\hat{\bold{R}}=\sqrt{p_{1}}\left(\sum_{t=1}^{T}\bold{X}_t\bold{W}_2\hat{\bold{F}}_t^\top\right)\left[\left(\sum_{t=1}^{T}\hat{\bold{F}}_t\bold{W}_2^\top\bold{X}_t^\top\right)\left(\sum_{t=1}^{T}\bold{X}_t\bold{W}_2\hat{\bold{F}}_t^\top\right)\right]^{-1/2}.</code>
</p>

<p>Similarly, we get the following estimator of the column factor loading matrix
</p>
<p style="text-align: center;"><code class="reqn">\hat{\bold{C}}=\sqrt{p_{2}}\left(\sum_{t=1}^{T}\bold{X}_t^\top\hat{\bold{R}}\hat{\bold{F}}_t\right)\left[\left(\sum_{t=1}^{T}\hat{\bold{F}}_t^\top\hat{\bold{R}}^\top\bold{X}_t\right)\left(\sum_{t=1}^{T}\bold{X}_t^\top\hat{\bold{R}}\hat{\bold{F}}_t\right)\right]^{-1/2}.</code>
</p>

<p>Afterwards, we sequentially update <code class="reqn">\bold{F}</code>, <code class="reqn">\bold{R}</code> and <code class="reqn">\bold{C}</code>. In simulation, the iterative procedure is terminated either when a pre-specified maximum iteration number (<code class="reqn">\text{maxiter}=100</code>) is reached or  when </p>
<p style="text-align: center;"><code class="reqn">\sum_{t=1}^{T}\|\hat{\bold{S}}^{(s+1)}_t-\hat{\bold{S}}^{(s)}_t\|_{F} \leq \epsilon \cdot Tp_1p_2,</code>
</p>

<p>where <code class="reqn">\hat{\bold{S}}^{(s)}_t</code> is the common component estimated at the <code class="reqn">s</code>-th step, <code class="reqn">\epsilon</code> is a small constant (<code class="reqn">10^{-6}</code>) given in advance.
</p>


<h3>Value</h3>

<p>The return value is a list. In this list, it contains the following:
</p>
<table>
<tr><td><code>R</code></td>
<td>
<p>The estimated row loading matrix of dimension <code class="reqn">p_1\times m_1</code>, satisfying <code class="reqn">\bold{R}^\top\bold{R}=p_1\bold{I}_{m_1}</code>.</p>
</td></tr>
<tr><td><code>C</code></td>
<td>
<p>The estimated column loading matrix of dimension <code class="reqn">p_2\times m_2</code>, satisfying <code class="reqn">\bold{C}^\top\bold{C}=p_2\bold{I}_{m_2}</code>.</p>
</td></tr>
<tr><td><code>F</code></td>
<td>
<p>The estimated factor matrix of dimension <code class="reqn">T \times m_1\times m_2</code>.</p>
</td></tr>
<tr><td><code>iter</code></td>
<td>
<p>The number of iterations when the stopping criterion is met.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Yong He, Ran Zhao, Wen-Xin Zhou.
</p>


<h3>References</h3>

<p>He, Y., Zhao, R., &amp; Zhou, W. X. (2023). Iterative Alternating Least Square Estimation for Large-dimensional Matrix Factor Model. &lt;arXiv:2301.00360&gt;.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(11111)
T=20;p1=20;p2=20
k1=3;k2=3

R=matrix(runif(p1*k1,min=-1,max=1),p1,k1)
C=matrix(runif(p2*k2,min=-1,max=1),p2,k2)

X=E=array(0,c(T,p1,p2))
F=array(0,c(T,k1,k2))

for(t in 1:T){
  F[t,,]=matrix(rnorm(k1*k2),k1,k2)
  E[t,,]=matrix(rnorm(p1*p2),p1,p2)
}
for(t in 1:T){
X[t,,]=R%*%F[t,,]%*%t(C)+E[t,,]
}

#Estimating the matrix factor model using the default initial values
fit1 = IALS(X, W1 = NULL, W2 = NULL,k1, k2, max_iter = 100, ep = 1e-06) 
Distance(fit1$R,R);Distance(fit1$C,C)

#Estimating the matrix factor model using one-step iteration
fit2 = IALS(X, W1 = NULL , W2 = NULL, k1, k2, max_iter = 1, ep = 1e-06) 
Distance(fit2$R,R);Distance(fit2$C,C)
</code></pre>

<hr>
<h2 id='KIALS'>
Estimating the Pair of Factor Numbers via Eigenvalue Ratios Corresponding to IALS
</h2><span id='topic+KIALS'></span>

<h3>Description</h3>

<p>The function is to estimate the pair of factor numbers via eigenvalue ratios corresponding to IALS method. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>KIALS(X, W1 = NULL, W2 = NULL, kmax, max_iter = 100, ep = 1e-06)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="KIALS_+3A_x">X</code></td>
<td>

<p>Input an array with <code class="reqn">T \times p_1 \times p_2</code>, where <code class="reqn">T</code> is the sample size, <code class="reqn">p_1</code> is the the row dimension of each matrix observation and <code class="reqn">p_2</code> is the the column dimension of each matrix observation.
</p>
</td></tr>
<tr><td><code id="KIALS_+3A_w1">W1</code></td>
<td>

<p>The initial value for the row factor loading matrix. The default is NULL, with an initial estimate chosen from <code class="reqn">\alpha</code>-PCA if not provided.
</p>
</td></tr>
<tr><td><code id="KIALS_+3A_w2">W2</code></td>
<td>

<p>The initial value for the column factor loading matrix. The default is NULL, with an initial estimate chosen from <code class="reqn">\alpha</code>-PCA if not provided.
</p>
</td></tr>
<tr><td><code id="KIALS_+3A_kmax">kmax</code></td>
<td>

<p>The user-supplied maximum factor numbers. Here it means the upper bound of the number of row factors and column factors.
</p>
</td></tr>
<tr><td><code id="KIALS_+3A_max_iter">max_iter</code></td>
<td>

<p>The maximum number of iterations for the algorithm, default is 100. See in <code><a href="#topic+IALS">IALS</a></code>.
</p>
</td></tr>
<tr><td><code id="KIALS_+3A_ep">ep</code></td>
<td>

<p>The stopping criterion in the iteration algorithm, default is <code class="reqn">10^{-6} \times Tp_1 p_2</code>. See in <code><a href="#topic+IALS">IALS</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In detail, we first set <code class="reqn">k_{\max}</code> is a predetermined upper bound for <code class="reqn">k_1,k_2</code> and thus by <code><a href="#topic+IALS">IALS</a></code> method, we can obtain the estimate of <code class="reqn">\bold{F}_t</code>, denote as <code class="reqn">\hat{\bold{F}}_t</code>, which is of dimension <code class="reqn">k_{\max}\times k_{\max}</code>. Then the dimensions <code class="reqn">k_1</code> and <code class="reqn">k_2</code> are further determined as follows:
</p>
<p style="text-align: center;"><code class="reqn">\hat{k}_{1}=\arg\max_{j \leq k_{\max}}\frac{\lambda_{j}\left(\dfrac{1}{T}\sum_{t=1}^{T}\hat{\bold{F}}_t\hat{\bold{F}}_t^\top\right)}{\lambda_{j+1}\left(\frac{1}{T}\sum_{t=1}^{T}\hat{\bold{F}}_t\hat{\bold{F}}_t^\top\right)},</code>
</p>

<p style="text-align: center;"><code class="reqn">\hat{k}_{2}=\arg\max_{j \leq k_{\max}}\frac{\lambda_{j}\left(\dfrac{1}{T}\sum_{t=1}^{T}\hat{\bold{F}}_t^\top\hat{\bold{F}}_t\right)}{\lambda_{j+1}\left(\frac{1}{T}\sum_{t=1}^{T}\hat{\bold{F}}_t^\top\hat{\bold{F}}_t\right)}.</code>
</p>



<h3>Value</h3>

<table>
<tr><td><code>\eqn{k_1}</code></td>
<td>
<p>The estimated row factor number.</p>
</td></tr>
<tr><td><code>\eqn{k_2}</code></td>
<td>
<p>The estimated column factor number.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Yong He, Ran Zhao, Wen-Xin Zhou.
</p>


<h3>References</h3>

<p>He, Y., Zhao, R., &amp; Zhou, W. X. (2023). Iterative Alternating Least Square Estimation for Large-dimensional Matrix Factor Model. &lt;arXiv:2301.00360&gt;.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(11111)
T=20;p1=20;p2=20
k1=3;k2=3

R=matrix(runif(p1*k1,min=-1,max=1),p1,k1)
C=matrix(runif(p2*k2,min=-1,max=1),p2,k2)

X=E=array(0,c(T,p1,p2))
F=array(0,c(T,k1,k2))

for(t in 1:T){
  F[t,,]=matrix(rnorm(k1*k2),k1,k2)
  E[t,,]=matrix(rnorm(p1*p2),p1,p2)
}

for(t in 1:T){
X[t,,]=R%*%F[t,,]%*%t(C)+E[t,,]
}

kmax=8
K=KIALS(X, W1 = NULL, W2 = NULL, kmax, max_iter = 100, ep = 1e-06);K
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
