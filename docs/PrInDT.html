<!DOCTYPE html><html><head><title>Help for package PrInDT</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {PrInDT}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#data_land'><p>Landscape analysis</p></a></li>
<li><a href='#data_speaker'><p>Subject pronouns and a predictor with one very frequent level</p></a></li>
<li><a href='#data_vowel'><p>Vowel length</p></a></li>
<li><a href='#data_zero'><p>Subject pronouns</p></a></li>
<li><a href='#FindSubstr'><p>Check for forbidden split results in trees</p></a></li>
<li><a href='#NesPrInDT'><p>Nested <code>PrInDT</code> with additional undersampling of a factor with two unbalanced levels</p></a></li>
<li><a href='#PostPrInDT'><p>Posterior analysis of conditional inference trees: distribution of a specified variable in the terminal nodes.</p></a></li>
<li><a href='#PrInDT'><p>The basic undersampling loop for classification</p></a></li>
<li><a href='#PrInDTAll'><p>Conditional inference tree (ctree) based on all observations</p></a></li>
<li><a href='#PrInDTAllparts'><p>Conditional inference trees (ctrees) based on consecutive parts of the full sample</p></a></li>
<li><a href='#PrInDTMulab'><p>Multiple label classification based on resampling by <code>PrInDT</code></p></a></li>
<li><a href='#PrInDTMulabAll'><p>Multiple label classification based on all observations</p></a></li>
<li><a href='#PrInDTMulev'><p>PrInDT analysis for a classification problem with multiple classes.</p></a></li>
<li><a href='#PrInDTMulevAll'><p>Conditional inference tree (ctree) for multiple classes on all observations</p></a></li>
<li><a href='#PrInDTreg'><p>Regression tree resampling by the PrInDT method</p></a></li>
<li><a href='#PrInDTregAll'><p>Regression tree based on all observations</p></a></li>
<li><a href='#RePrInDT'><p>Repeated <code>PrInDT</code> for specified percentage combinations</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Prediction and Interpretation in Decision Trees for
Classification and Regression</td>
</tr>
<tr>
<td>Version:</td>
<td>1.0.1</td>
</tr>
<tr>
<td>Description:</td>
<td>Optimization of conditional inference trees from the package 'party'
    for classification and regression.
    For optimization, the model space is searched for the best tree on the full sample by 
    means of repeated subsampling. Restrictions are allowed so that only trees are accepted 
    which do not include pre-specified uninterpretable split results (cf. Weihs &amp; Buschfeld, 2021a).
    The function PrInDT() represents the basic resampling loop for 2-class classification (cf. Weihs 
    &amp; Buschfeld, 2021a). The function RePrInDT() (repeated PrInDT()) allows for repeated  
    applications of PrInDT() for different percentages of the observations of the large and the 
    small classes (cf. Weihs &amp; Buschfeld, 2021c). The function NesPrInDT() (nested PrInDT()) 
    allows for an extra layer of subsampling for a specific factor variable (cf. Weihs &amp; Buschfeld, 
    2021b). The functions PrInDTMulev() and PrInDTMulab() deal with multilevel and multilabel 
    classification. In addition to these PrInDT() variants for classification, the function 
    PrInDTreg() has been developed for regression problems. Finally, the function PostPrInDT() 
    allows for a posterior analysis of the distribution of a specified variable in the terminal 
    nodes of a given tree.
    References are:
    &ndash; Weihs, C., Buschfeld, S. (2021a) "Combining Prediction and Interpretation in 
    Decision Trees (PrInDT) - a Linguistic Example" &lt;<a href="https://doi.org/10.48550/arXiv.2103.02336">doi:10.48550/arXiv.2103.02336</a>&gt;;
    &ndash; Weihs, C., Buschfeld, S. (2021b) "NesPrInDT: Nested undersampling in PrInDT" 
    &lt;<a href="https://doi.org/10.48550/arXiv.2103.14931">doi:10.48550/arXiv.2103.14931</a>&gt;;
    &ndash; Weihs, C., Buschfeld, S. (2021c) "Repeated undersampling in PrInDT (RePrInDT): Variation 
    in undersampling and prediction, and ranking of predictors in ensembles" &lt;<a href="https://doi.org/10.48550/arXiv.2108.05129">doi:10.48550/arXiv.2108.05129</a>&gt;.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Imports:</td>
<td>graphics, MASS, party, splitstackshape, stats, stringr, utils</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 2.10)</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Claus Weihs &lt;claus.weihs@tu-dortmund.de&gt;</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-05-09 09:51:23 UTC; weihs</td>
</tr>
<tr>
<td>Author:</td>
<td>Claus Weihs [aut, cre],
  Sarah Buschfeld [aut],
  Niklas Nitsch [ctb]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-05-09 22:20:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='data_land'>Landscape analysis</h2><span id='topic+data_land'></span>

<h3>Description</h3>

<p>The use of language(s) on public signs and categorization criteria.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data_land
</code></pre>


<h3>Format</h3>

<p>A data frame with 149 observations and 28 columns
</p>

<dl>
<dt>coder</dt><dd><p>who coded the sign: Factor (3 levels &quot;C&quot;,&quot;E&quot;,&quot;S&quot;)  (anonymized)</p>
</dd>
<dt>researcher</dt><dd><p>who took a photograph of the sign: Factor (2 levels &quot;L&quot;,&quot;S&quot;)  (anonymized)</p>
</dd>
<dt>sign</dt><dd><p>where the sign was found: Factor (11 levels &quot;digi&quot;,&quot;door&quot;,&quot;graf&quot;,...)</p>
</dd>
<dt>type.of.sign</dt><dd><p>kind of sign: Factor (5 levels &quot;com&quot;,&quot;commem&quot;,&quot;infra&quot;,&quot;reg&quot;,&quot;trans&quot;)</p>
</dd>
<dt>permanent</dt><dd><p>was the sign permanent? Factor (2 levels &quot;no&quot;,&quot;yes&quot;)</p>
</dd>
<dt>proper.noun</dt><dd><p>kind of proper noun on the sign: Factor (9 levels &quot;bn&quot;,&quot;bn+&quot;,&quot;cn&quot;,...)</p>
</dd>
<dt>no.languages</dt><dd><p>number of languages on sign: Factor (4 levels &quot;1&quot;,&quot;2&quot;,&quot;3&quot;,&quot;4+&quot;)</p>
</dd>
<dt>French</dt><dd><p>French on sign? Factor (2 levels &quot;0&quot;,&quot;1&quot;)</p>
</dd>
<dt>Dutch</dt><dd><p>Dutch on sign? Factor (2 levels &quot;0&quot;,&quot;1&quot;)</p>
</dd>
<dt>English</dt><dd><p>English on sign? Factor (2 levels &quot;0&quot;,&quot;1&quot;)</p>
</dd>
<dt>Italian</dt><dd><p>Italian on sign? Factor (2 levels &quot;0&quot;,&quot;1&quot;)</p>
</dd>
<dt>Spanish</dt><dd><p>Spanish on sign? Factor (2 levels &quot;0&quot;,&quot;1&quot;)</p>
</dd>
<dt>German</dt><dd><p>German on sign? Factor (2 levels &quot;0&quot;,&quot;1&quot;)</p>
</dd>
<dt>Indian,Mandarin,Portuguese,Libanese,Japanese,Danish,Hebrew,Catalan</dt><dd><p>8 infrequent languages: Factor (2 levels &quot;0&quot;,&quot;1&quot;)</p>
</dd>
<dt>bn.unclear</dt><dd><p>brand name unclear: Factor (2 levels &quot;0&quot;,&quot;1&quot;)</p>
</dd>
<dt>multilingual.type</dt><dd><p>type of multilingualism on sign: Factor (6 levels &quot;0&quot;,&quot;1&quot;,&quot;2&quot;,&quot;3&quot;,&quot;4&quot;,&quot;uc&quot;)</p>
</dd>
<dt>location</dt><dd><p>location of sign: Factor (2 levels &quot;M&quot;,&quot;P&quot;)  (anonymized)</p>
</dd>
</dl>



<h3>Source</h3>

<p>Sarah Buschfeld, TU Dortmund
</p>

<hr>
<h2 id='data_speaker'>Subject pronouns and a predictor with one very frequent level</h2><span id='topic+data_speaker'></span>

<h3>Description</h3>

<p>Usage of subject pronouns and its predictors; speaker level &quot;adult&quot; very frequent.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data_speaker
</code></pre>


<h3>Format</h3>

<p>A data frame with 3370 observations and 6 columns
</p>

<dl>
<dt>class</dt><dd><p>subject pronoun realized? Factor (2 levels &quot;zero&quot;,&quot;realized&quot;)</p>
</dd>
<dt>AGE</dt><dd><p>age: Numerical (in months)</p>
</dd>
<dt>ETHN_GROUP</dt><dd><p>ethnic group: Factor (3 levels &quot;C&quot;,&quot;I&quot;,&quot;n_a&quot;) (anonymized)</p>
</dd>
<dt>MLU</dt><dd><p>mean length of utterance: Factor (5 levels &quot;1&quot;,&quot;2&quot;,&quot;3&quot;,&quot;adult&quot;,&quot;OL&quot;)</p>
</dd>
<dt>PRN_TYPE</dt><dd><p>pronoun type: Factor (5 levels &quot;dem&quot;,&quot;it_con&quot;,&quot;it_ex&quot;,&quot;it_ref&quot;,&quot;refer&quot;)</p>
</dd>
<dt>SPEAKER</dt><dd><p>speaker: Factor (2 levels &quot;adult&quot;,&quot;child&quot;)</p>
</dd>
</dl>



<h3>Source</h3>

<p>Sarah Buschfeld, TU Dortmund
</p>

<hr>
<h2 id='data_vowel'>Vowel length</h2><span id='topic+data_vowel'></span>

<h3>Description</h3>

<p>Vowel length and categorization criteria.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data_vowel
</code></pre>


<h3>Format</h3>

<p>A data frame with 82 observations and 22 columns
</p>

<dl>
<dt>Nickname</dt><dd><p>nickname: Factor (43 levels &quot;Nick1&quot;,&quot;Nick2&quot;,...,&quot;Nick43&quot;) (anonymized)</p>
</dd>
<dt>LiBa</dt><dd><p>linguistic background: Factor (2 levels &quot;mono&quot;,&quot;multi&quot;)</p>
</dd>
<dt>MLU</dt><dd><p>mean length of utterance: Factor (3 levels &quot;1&quot;,&quot;2&quot;,&quot;3&quot;)</p>
</dd>
<dt>phone_label</dt><dd><p>phone label: Factor (2 levels &quot;fleece&quot;,&quot;kit&quot;)</p>
</dd>
<dt>lexeme</dt><dd><p>lexeme: Factor (14 levels &quot;bee&quot;,&quot;cheek&quot;,&quot;cheese&quot;,&quot;chicken&quot;, ...)</p>
</dd>
<dt>phone_left_1_duration</dt><dd><p>duration of phone to the left of the vowel: Numerical (in msec)</p>
</dd>
<dt>phone_right_1_duration</dt><dd><p>duration of phone to the right of the vowel: Numerical (in msec)</p>
</dd>
<dt>word_duration</dt><dd><p>duration of word: Numerical (in msec)</p>
</dd>
<dt>vowel_minimum_pitch</dt><dd><p>minimum pitch of vowel: Numerical (in Hertz)</p>
</dd>
<dt>vowel_maximum_pitch</dt><dd><p>maximum pitch of vowel: Numerical (in Hertz)</p>
</dd>
<dt>vowel_intensity_mean</dt><dd><p>mean intensity of vowel: Numerical (in decibel)</p>
</dd>
<dt>f1_fifty</dt><dd><p>first formant F1 at midpoint of vowel (50%): Numerical (in Hertz)</p>
</dd>
<dt>f2_fifty</dt><dd><p>second formant F2 at midpoint of vowel (50%): numercial (in Hertz)</p>
</dd>
<dt>target</dt><dd><p>vowel length: Numerical (in msec)</p>
</dd>
<dt>cons_class_l</dt><dd><p>class of consonant to the left of the vowel: Factor (6 levels &quot;l&quot;,&quot;r&quot;,&quot;tsh&quot;,...)</p>
</dd>
<dt>cons_class_r</dt><dd><p>class of consonant to the right of the vowel: Factor (7 levels &quot;?&quot;(glottal stop),&quot;empty&quot;,&quot;nas&quot;,...)</p>
</dd>
<dt>ETH</dt><dd><p>ethnic group: Factor (6 levels &quot;C1a&quot;,&quot;C1b&quot;,&quot;C1c&quot;,&quot;C2a&quot;,&quot;C2b&quot;,&quot;C2c&quot;) (anonymized)</p>
</dd>
<dt>SEX</dt><dd><p>gender: Factor (2 levels &quot;female&quot;,&quot;male)</p>
</dd>
<dt>AGE</dt><dd><p>age: Numerical (in months)</p>
</dd>
<dt>syllables</dt><dd><p>number of syllables in lexeme: integer (1,2)</p>
</dd>
<dt>speed</dt><dd><p>speed of speech: Numerical (word duration / syllables; in msec)</p>
</dd>
<dt>country</dt><dd><p>country: Factor (2 levels &quot;E&quot;,&quot;S&quot;)  (anonymized)</p>
</dd>
</dl>



<h3>Source</h3>

<p>Sarah Buschfeld, TU Dortmund
</p>

<hr>
<h2 id='data_zero'>Subject pronouns</h2><span id='topic+data_zero'></span>

<h3>Description</h3>

<p>Usage of subject pronouns and its predictors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data_zero
</code></pre>


<h3>Format</h3>

<p>A data frame with 1024 observations and 7 columns
</p>

<dl>
<dt>real</dt><dd><p>subject pronoun realized? Factor (2 levels &quot;zero&quot;,&quot;realized&quot;)</p>
</dd>
<dt>AGE</dt><dd><p>age: Numerical (in months)</p>
</dd>
<dt>LiBa</dt><dd><p>linguistic background: Factor (3 levels &quot;mono&quot;,&quot;multi&quot;, NA)</p>
</dd>
<dt>ETH</dt><dd><p>ethnic group: Factor (6 levels &quot;C1a&quot;,&quot;C1b&quot;,&quot;C1c&quot;,&quot;C2a&quot;,&quot;C2b&quot;,&quot;C2c&quot;) (anonymized)</p>
</dd>
<dt>SEX</dt><dd><p>gender: Factor (2 levels &quot;female&quot;,&quot;male&quot;)</p>
</dd>
<dt>MLU</dt><dd><p>mean length of utterance: Factor (4 levels &quot;1&quot;,&quot;2&quot;,&quot;3&quot;,&quot;OL&quot;)</p>
</dd>
<dt>PRN</dt><dd><p>pronoun: Factor (7 levels &quot;I&quot;,&quot;you_s&quot;,&quot;he&quot;,&quot;she&quot;,&quot;it&quot;,&quot;we&quot;,&quot;they&quot;)</p>
</dd>
</dl>



<h3>Source</h3>

<p>Sarah Buschfeld, TU Dortmund
</p>

<hr>
<h2 id='FindSubstr'>Check for forbidden split results in trees</h2><span id='topic+FindSubstr'></span>

<h3>Description</h3>

<p>Check whether one of the character strings in the vector 'ctestv' appears as a split result in the conditional inference tree 'ct';
ctestv is a vector of character strings of forbidden split results.<br />
Example: ctestv &lt;- rbind('variable1 == {value1, value2}','variable2 &lt;= value3'), where
character strings specified in 'value1', 'value2' are not allowed as results of a splitting operation in 'variable 1' in a tree.
For restrictions of the type 'variable &lt;= xxx', all split results in a tree are excluded with 'variable &lt;= yyy' and yyy &lt;= xxx.<br />
Trees with split results specified in 'ctestv' are not accepted during optimization.<br />
A concrete example is: 'ctestv &lt;- rbind('ETH == {C2a, C1a}','AGE &lt;= 20')' for variables 'ETH' and 'AGE' and values 'C2a','C1a', and '20';<br />
For an application, please refer to, e.g., the functions <code><a href="#topic+PrInDT">PrInDT</a></code> and <code><a href="#topic+PrInDTreg">PrInDTreg</a></code>.<br />
If no restrictions exist, the default = NA is used.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>FindSubstr(ct, ctestv)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="FindSubstr_+3A_ct">ct</code></td>
<td>
<p>Tree to be checked</p>
</td></tr>
<tr><td><code id="FindSubstr_+3A_ctestv">ctestv</code></td>
<td>
<p>Vector with character strings of excluded split results</p>
</td></tr>
</table>


<h3>Value</h3>

 
<dl>
<dt>testt</dt><dd><p>TRUE if any of the split results in 'ctestv' appears in 'ct'; FALSE otherwise</p>
</dd>
</dl>


<hr>
<h2 id='NesPrInDT'>Nested <code><a href="#topic+PrInDT">PrInDT</a></code> with additional undersampling of a factor with two unbalanced levels</h2><span id='topic+NesPrInDT'></span>

<h3>Description</h3>

<p>Function for additional undersampling of the factor 'nesvar' with two unbalanced levels to avoid dominance of the level with higher frequency.
The factor 'nesvar' is allowed not be part of the input data frame 'datain'. The data of this factor is given in the vector 'nesunder'. 
The observations in 'nesunder' have to represent the same cases as in 'datain' in the same ordering.<br />
<code><a href="#topic+PrInDT">PrInDT</a></code> is called 'repin' times with subsamples of the original data so that the level with the larger frequency in the vector 'nesunder' has 
approximately the same number of values as the level with the smaller frequency.<br />
Only the arguments 'nesvar', 'nesunder', and 'repin' relate to the additional undersampling, all the other arguments relate to the standard 
<code><a href="#topic+PrInDT">PrInDT</a></code> procedure. <br /> As in <code><a href="#topic+PrInDT">PrInDT</a></code>, the aim is to optimally model the relationship between the two-class factor variable 'classname' and all other factor and  
numerical variables in the data frame 'datain' by means of 'N' repetitions of undersampling. The trees generated by <code><a href="#topic+PrInDT">PrInDT</a></code> can be
restricted by excluding unacceptable trees which include split results specified in the character strings of the vector 'ctestv'.<br />
The probability threshold 'thres' for the prediction of the smaller class may be specified (default = 0.5).<br />
Undersampling may be stratified in two ways by the feature 'strat'.<br />
The results are evaluated on the full sample and on the subsamples of 'nesunder'.
</p>
<p><strong>Reference</strong> <br /> Weihs, C., Buschfeld, S. 2021b. NesPrInDT: Nested undersampling in PrInDT. 
arXiv:2103.14931
</p>


<h3>Usage</h3>

<pre><code class='language-R'>NesPrInDT(datain, classname, ctestv=NA, N, plarge, psmall=1.0, conf.level=0.95,
       thres=0.5, stratvers=0, strat=NA, seedl=TRUE, nesvar, nesunder, repin)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="NesPrInDT_+3A_datain">datain</code></td>
<td>
<p>Input data frame with class factor variable 'classname' and the<br />
influential variables, which need to be factors or numericals (transform logicals and character variables to factors)</p>
</td></tr>
<tr><td><code id="NesPrInDT_+3A_classname">classname</code></td>
<td>
<p>Name of class variable (character)</p>
</td></tr>
<tr><td><code id="NesPrInDT_+3A_ctestv">ctestv</code></td>
<td>
<p>Vector of character strings of forbidden split results;<br />
see function <code><a href="#topic+PrInDT">PrInDT</a></code> for details.<br />
If no restrictions exist, the default = NA is used.</p>
</td></tr>
<tr><td><code id="NesPrInDT_+3A_n">N</code></td>
<td>
<p>Number of repetitions (integer &gt; 0)</p>
</td></tr>
<tr><td><code id="NesPrInDT_+3A_plarge">plarge</code></td>
<td>
<p>Undersampling percentage of larger class (numerical, &gt; 0 and &lt;= 1)</p>
</td></tr>
<tr><td><code id="NesPrInDT_+3A_psmall">psmall</code></td>
<td>
<p>Undersampling percentage of smaller class (numerical, &gt; 0 and &lt;= 1);<br />
default = 1</p>
</td></tr>
<tr><td><code id="NesPrInDT_+3A_conf.level">conf.level</code></td>
<td>
<p>(1 - significance level) in function <code>ctree</code> (numerical, &gt; 0 and &lt;= 1);<br />
default = 0.95</p>
</td></tr>
<tr><td><code id="NesPrInDT_+3A_thres">thres</code></td>
<td>
<p>Probability threshold for prediction of smaller class; default = 0.5</p>
</td></tr>
<tr><td><code id="NesPrInDT_+3A_stratvers">stratvers</code></td>
<td>
<p>Version of stratification;<br />
= 0: none (default),<br />
= 1: stratification according to the percentages of the values of the factor variable 'strat',<br />
&gt; 1: stratification with minimum number 'stratvers' of observations per value of 'strat'</p>
</td></tr>
<tr><td><code id="NesPrInDT_+3A_strat">strat</code></td>
<td>
<p>Name of one (!) stratification variable for undersampling (character);<br />
default = NA (no stratification)</p>
</td></tr>
<tr><td><code id="NesPrInDT_+3A_seedl">seedl</code></td>
<td>
<p>Should the seed for random numbers be set (TRUE / FALSE)?<br />
default = TRUE</p>
</td></tr>
<tr><td><code id="NesPrInDT_+3A_nesvar">nesvar</code></td>
<td>
<p>Name of factor to be undersampled (character)</p>
</td></tr>
<tr><td><code id="NesPrInDT_+3A_nesunder">nesunder</code></td>
<td>
<p>Data of factor to be undersampled (integer)</p>
</td></tr>
<tr><td><code id="NesPrInDT_+3A_repin">repin</code></td>
<td>
<p>Number of repetitions (integer) for undersampling of 'nesvar'</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Standard output can be produced by means of <code>print(name)</code> or just <code> name </code> as well as <code>plot(name)</code>  where 'name' is the output data 
frame of the function.<br />
The plot function will produce a series of more than one plot. If you use R, you might want to specify <code>windows(record=TRUE)</code> before 
<code>plot(name)</code> to save the whole series of plots. In R-Studio this functionality is provided automatically.
</p>


<h3>Value</h3>

  
<dl>
<dt>undba</dt><dd><p>balanced accuracies on undersamples</p>
</dd>
<dt>imax</dt><dd><p>indices of best trees on undersamples</p>
</dd>
<dt>undba3en</dt><dd><p>balanced accuracies of ensembles of 3 best trees on undersamples</p>
</dd>
<dt>accF</dt><dd><p>balanced accuracies on full sample</p>
</dd>
<dt>accE</dt><dd><p>balanced accuracy on full sample of best ensemble of 3 trees from undersampling</p>
</dd>
<dt>maxt</dt><dd><p>indices of best trees on full sample</p>
</dd>
<dt>treesb</dt><dd><p>3 best trees of all undersamples of 'nesunder'; refer to an individual tree as <code>treesb[[k]]</code>, k = 1, ..., 3*repin</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'># data input and preparation --&gt; data frame with 
#   class variable, factors, and numericals (no character variables)!!
data &lt;- PrInDT::data_speaker
data &lt;- na.omit(data)
nesvar &lt;- "SPEAKER"
N &lt;- 49  # no. of repetitions in inner loop
plarge &lt;- 0.06 # sampling percentage for larger class in nesunder-subsample
psmall &lt;- 1 # sampling percentage for smaller class in nesunder-subsample
nesunder &lt;- data$SPEAKER
data[,nesvar] &lt;- list(NULL)
outNes &lt;- NesPrInDT(data,"class",ctestv=NA,N,plarge,psmall,conf.level=0.95,nesvar=nesvar,
  nesunder=nesunder,repin=5)
outNes
plot(outNes)
hist(outNes$undba,main=" ",xlab = "balanced accuracies of 3 best trees of all undersamples")

</code></pre>

<hr>
<h2 id='PostPrInDT'>Posterior analysis of conditional inference trees: distribution of a specified variable in the terminal nodes.</h2><span id='topic+PostPrInDT'></span>

<h3>Description</h3>

<p>The conditional inference tree 'ct' is analyzed according to the distribution of a variable 'var' in its terminal nodes.<br />
In the case of a discrete variable 'var', the appearance of the different levels is considered for each terminal node. <br />
In the case of a continuous variable 'var', means and standard deviations of 'var' or the target variable are considered for each terminal node.<br />
In particular, this function can be used for the posterior analysis of a tree regarding the distribution of a variable not present in the tree.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PostPrInDT(datain, ct, target, var, vardata, vt)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PostPrInDT_+3A_datain">datain</code></td>
<td>
<p>input data frame with the observatios of all variables used in the model</p>
</td></tr>
<tr><td><code id="PostPrInDT_+3A_ct">ct</code></td>
<td>
<p>conditional inference tree to be analyzed</p>
</td></tr>
<tr><td><code id="PostPrInDT_+3A_target">target</code></td>
<td>
<p>name of target variable of 'ct' (character)</p>
</td></tr>
<tr><td><code id="PostPrInDT_+3A_var">var</code></td>
<td>
<p>name of variable of interest (character)</p>
</td></tr>
<tr><td><code id="PostPrInDT_+3A_vardata">vardata</code></td>
<td>
<p>observations of 'var'</p>
</td></tr>
<tr><td><code id="PostPrInDT_+3A_vt">vt</code></td>
<td>
<p>type of variables: 'dd' for discrete target (classification) and discrete variable 'var', 'dc' for discrete target (classification) and continuous 'var',
'cd' for continuous target (regression) and discrete 'var', and 'cc' for continuous target (regression) and continuous 'var'.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None: Relevant output is produced by the function.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data &lt;- PrInDT::data_zero
data &lt;- na.omit(data)
outAll &lt;- PrInDTAll(data,"real") 
PostPrInDT(data,outAll$treeAll,"real","ETH",data$ETH,vt="dd")
PostPrInDT(data,outAll$treeAll,"real","AGE",data$AGE,vt="dc")
datareg &lt;- PrInDT::data_vowel
outregAll &lt;- PrInDTregAll(datareg,"target") 
PostPrInDT(datareg,outregAll$treeAll,"target","Nickname",datareg$Nickname,vt="cd")
PostPrInDT(datareg,outregAll$treeAll,"target","AGE",datareg$AGE,vt="cc")

</code></pre>

<hr>
<h2 id='PrInDT'>The basic undersampling loop for classification</h2><span id='topic+PrInDT'></span>

<h3>Description</h3>

<p>The function PrInDT uses ctrees (conditional inference trees from the package &quot;party&quot;) for optimal modeling of
the relationship between the two-class factor variable 'classname' and all other factor and numerical variables
in the data frame 'datain' by means of 'N' repetitions of undersampling. The optimization citerion is the balanced accuracy 
on the full sample. The trees generated from undersampling can be restricted by not accepting trees 
including split results specified in the character strings of the vector 'ctestv'.<br />
The undersampling percentages are 'percl' for the larger class and 'percs' for the smaller class (default = 1).<br />
The probability threshold 'thres' for the prediction of the smaller class may be specified (default = 0.5).<br />
Undersampling may be stratified in two ways by the feature 'strat'.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PrInDT(datain, classname, ctestv=NA, N, percl, percs=1, conf.level=0.95, thres=0.5,
       stratvers=0, strat=NA, seedl=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PrInDT_+3A_datain">datain</code></td>
<td>
<p>Input data frame with class factor variable 'classname' and the<br />
influential variables, which need to be factors or numericals (transform logicals and character variables to factors)</p>
</td></tr>
<tr><td><code id="PrInDT_+3A_classname">classname</code></td>
<td>
<p>Name of class variable (character)</p>
</td></tr>
<tr><td><code id="PrInDT_+3A_ctestv">ctestv</code></td>
<td>
<p>Vector of character strings of forbidden split results;<br />
Example: ctestv &lt;- rbind('variable1 == {value1, value2}','variable2 &lt;= value3'), where
character strings specified in 'value1', 'value2' are not allowed as results of a splitting operation in variable 1 in a tree.<br />
For restrictions of the type 'variable &lt;= xxx', all split results in a tree are excluded with 'variable &lt;= yyy' and yyy &lt;= xxx.<br />
Trees with split results specified in 'ctestv' are not accepted during optimization.<br />
A concrete example is: 'ctestv &lt;- rbind('ETH == {C2a, C1a}','AGE &lt;= 20')' for variables 'ETH' and 'AGE' and values 'C2a','C1a', and '20';<br />
If no restrictions exist, the default = NA is used.</p>
</td></tr>
<tr><td><code id="PrInDT_+3A_n">N</code></td>
<td>
<p>Number (&gt; 2) of repetitions (integer)</p>
</td></tr>
<tr><td><code id="PrInDT_+3A_percl">percl</code></td>
<td>
<p>Undersampling percentage of larger class (numerical, &gt; 0 and &lt;= 1)</p>
</td></tr>
<tr><td><code id="PrInDT_+3A_percs">percs</code></td>
<td>
<p>Undersampling percentage of smaller class (numerical, &gt; 0 and &lt;= 1);<br />
default = 1</p>
</td></tr>
<tr><td><code id="PrInDT_+3A_conf.level">conf.level</code></td>
<td>
<p>(1 - significance level) in function <code>ctree</code> (numerical, &gt; 0 and &lt;= 1);<br />
default = 0.95</p>
</td></tr>
<tr><td><code id="PrInDT_+3A_thres">thres</code></td>
<td>
<p>Probability threshold for prediction of smaller class (numerical, &gt;= 0 and &lt; 1); default = 0.5</p>
</td></tr>
<tr><td><code id="PrInDT_+3A_stratvers">stratvers</code></td>
<td>
<p>Version of stratification;<br />
= 0: none (default),<br />
= 1: stratification according to the percentages of the values of the factor variable 'strat',<br />
&gt; 1: stratification with minimum number &quot;stratvers&quot; of observations per value of &quot;strat&quot;</p>
</td></tr>
<tr><td><code id="PrInDT_+3A_strat">strat</code></td>
<td>
<p>Name of one (!) stratification variable for undersampling (character);<br />
default = NA (no stratification)</p>
</td></tr>
<tr><td><code id="PrInDT_+3A_seedl">seedl</code></td>
<td>
<p>Should the seed for random numbers be set (TRUE / FALSE)?<br />
default = TRUE</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For the optimzation of the trees, we employ a method we call Sumping (Subsampling umbrella of 
model parameters), a variant of Bumping (Bootstrap umbrella of model parameters) (Tibshirani 
&amp; Knight, 1999) which use subsampling instead of bootstrapping. The aim of the 
optimization is to identify conditional inference trees with maximum predictive power
on the full sample under interpretability restrictions.
</p>
<p><strong>References</strong> <br />
&ndash; Tibshirani, R., Knight, K. 1999. Model Search and Inference By Bootstrap &quot;bumping&quot;.
Journal of Computational and Graphical Statistics, Vol. 8, No. 4 (Dec., 1999), pp. 671-686 <br />
&ndash; Weihs, C., Buschfeld, S. 2021a. Combining Prediction and Interpretation in  Decision Trees (PrInDT) - 
a Linguistic Example. arXiv:2103.02336
</p>
<p>Standard output can be produced by means of <code>print(name)</code> or just <code> name </code> as well as <code>plot(name)</code> where 'name' is the output data 
frame of the function.<br />
The plot function will produce a series of more than one plot. If you use R, you might want to specify <code>windows(record=TRUE)</code> before 
<code>plot(name)</code> to save the whole series of plots. In R-Studio this functionality is provided automatically.
</p>


<h3>Value</h3>


<dl>
<dt>tree1st</dt><dd><p>best tree on full sample</p>
</dd>
<dt>tree2nd</dt><dd><p>2nd-best tree on full sample</p>
</dd>
<dt>tree3rd</dt><dd><p>3rd-best tree on full sample</p>
</dd>
<dt>treet1st</dt><dd><p>best tree on test sample</p>
</dd>
<dt>treet2nd</dt><dd><p>2nd-best tree on test sample</p>
</dd>
<dt>treet3rd</dt><dd><p>3rd-best tree on test sample</p>
</dd>
<dt>ba1st</dt><dd><p>accuracies: largeClass, smallClass, balanced of 'tree1st', both for full and test sample</p>
</dd>
<dt>ba2nd</dt><dd><p>accuracies: largeClass, smallClass, balanced of 'tree2nd', both for full and test sample</p>
</dd>
<dt>ba3rd</dt><dd><p>accuracies: largeClass, smallClass, balanced of 'tree3rd', both for full and test sample</p>
</dd>
<dt>baen</dt><dd><p>accuracies: largeClass, smallClass, balanced of ensemble of all interpretable, 3 best acceptable, and all acceptable trees on full sample</p>
</dd>
<dt>bafull</dt><dd><p>vector of balanced accuracies of all trees from undersampling</p>
</dd>
<dt>batest</dt><dd><p>vector of test accuracies of all trees from undersampling</p>
</dd>
<dt>dataout</dt><dd><p>transformed data set 'datain' for further analyses</p>
</dd>
<dt>treeAll</dt><dd><p>tree based on all observations</p>
</dd>
<dt>baAll</dt><dd><p>balanced accuracy of 'treeAll'</p>
</dd>
<dt>interpAll</dt><dd><p>criterion of interpretability of 'treeall' (TRUE / FALSE)</p>
</dd>
<dt>confAll</dt><dd><p>confusion matrix of 'treeAll'</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>datastrat &lt;- PrInDT::data_zero
data &lt;- na.omit(datastrat) # cleaned full data: no NAs
# interpretation restrictions (split exclusions)
ctestv &lt;- rbind('ETH == {C2a, C1a}','MLU == {1, 3}') # split exclusions
N &lt;- 41  # no. of repetitions
conf.level &lt;- 0.99 # 1 - significance level (mincriterion) in ctree
percl &lt;- 0.08  # undersampling percentage of the larger class
percs &lt;- 0.95 # undersampling percentage of the smaller class
# calls of PrInDT
out &lt;- PrInDT(data,"real",ctestv,N,percl,percs,conf.level) # unstratified
out # print best model and ensembles as well as all observations
plot(out)
out &lt;- PrInDT(data,"real",ctestv,N,percl,percs,conf.level,stratvers=1,
              strat="SEX") # percentage stratification
out &lt;- PrInDT(data,"real",ctestv,N,percl,percs,conf.level,stratvers=50,
              strat="SEX") # stratification with minimum no. of tokens
out &lt;- PrInDT(data,"real",ctestv,N,percl,percs,conf.level,thres=0.4) # threshold = 0.4

</code></pre>

<hr>
<h2 id='PrInDTAll'>Conditional inference tree (ctree) based on all observations</h2><span id='topic+PrInDTAll'></span>

<h3>Description</h3>

<p>ctree based on all observations. Interpretability is checked (see 'ctestv'); probability threshold can be specified.
</p>
<p><strong>Reference</strong>: Weihs, C., Buschfeld, S. 2021a. Combining Prediction and Interpretation in  Decision Trees (PrInDT) - 
a Linguistic Example. arXiv:2103.02336
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PrInDTAll(datain, classname, ctestv=NA, conf.level=0.95, thres=0.5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PrInDTAll_+3A_datain">datain</code></td>
<td>
<p>Input data frame with class factor variable 'classname' and the<br />
influential variables, which need to be factors or numericals (transform logicals and character variables to factors)</p>
</td></tr>
<tr><td><code id="PrInDTAll_+3A_classname">classname</code></td>
<td>
<p>Name of class variable (character)</p>
</td></tr>
<tr><td><code id="PrInDTAll_+3A_ctestv">ctestv</code></td>
<td>
<p>Vector of character strings of forbidden split results;<br />
see function <code><a href="#topic+PrInDT">PrInDT</a></code> for details.<br />
If no restrictions exist, the default = NA is used.</p>
</td></tr>
<tr><td><code id="PrInDTAll_+3A_conf.level">conf.level</code></td>
<td>
<p>(1 - significance level) in function <code>ctree</code> (numerical, &gt; 0 and &lt;= 1); default = 0.95</p>
</td></tr>
<tr><td><code id="PrInDTAll_+3A_thres">thres</code></td>
<td>
<p>Probability threshold for prediction of smaller class (numerical, &gt;= 0 and &lt; 1); default = 0.5</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Standard output can be produced by means of <code>print(name)</code> or just <code> name </code> as well as <code>plot(name)</code> where 'name' is the output data 
frame of the function.<br />
</p>


<h3>Value</h3>


<dl>
<dt>treeall</dt><dd><p>ctree based on all observations</p>
</dd>
<dt>baAll</dt><dd><p>balanced accuracy of 'treeall'</p>
</dd>
<dt>interpAll</dt><dd><p>criterion of interpretability of 'treeall' (TRUE / FALSE)</p>
</dd>
<dt>confAll</dt><dd><p>confusion matrix of 'treeall'</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>datastrat &lt;- PrInDT::data_zero
data &lt;- na.omit(datastrat)
ctestv &lt;- rbind('ETH == {C2a,C1a}','MLU == {1, 3}')
conf.level &lt;- 0.99 # 1 - significance level (mincriterion) in ctree
outAll &lt;- PrInDTAll(data,"real",ctestv,conf.level) 
print(outAll) # print model based on all observations
plot(outAll) # plot model based on all observations

</code></pre>

<hr>
<h2 id='PrInDTAllparts'>Conditional inference trees (ctrees) based on consecutive parts of the full sample</h2><span id='topic+PrInDTAllparts'></span>

<h3>Description</h3>

<p>ctrees based on the full sample of the smaller class and consecutive parts of the larger class of the nesting variable 'nesvar'. 
The variable 'nesvar' has to be part of the data frame 'datain'.<br />   
Interpretability is checked (see 'ctestv'); probability threshold can be specified.
</p>
<p><strong>Reference</strong><br /> Weihs, C., Buschfeld, S. 2021b. NesPrInDT: Nested undersampling in PrInDT. 
arXiv:2103.14931
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PrInDTAllparts(datain, classname, ctestv=NA, conf.level=0.95, thres=0.5,
       nesvar, divt)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PrInDTAllparts_+3A_datain">datain</code></td>
<td>
<p>Input data frame with class factor variable 'classname' and the<br />
influential variables, which need to be factors or numericals (transform logicals and character variables to factors)</p>
</td></tr>
<tr><td><code id="PrInDTAllparts_+3A_classname">classname</code></td>
<td>
<p>Name of class variable (character)</p>
</td></tr>
<tr><td><code id="PrInDTAllparts_+3A_ctestv">ctestv</code></td>
<td>
<p>Vector of character strings of forbidden split results;<br />
see function <code><a href="#topic+PrInDT">PrInDT</a></code> for details.<br />
If no restrictions exist, the default = NA is used.</p>
</td></tr>
<tr><td><code id="PrInDTAllparts_+3A_conf.level">conf.level</code></td>
<td>
<p>(1 - significance level) in function <code>ctree</code> (numerical, &gt; 0 and &lt;= 1); default = 0.95</p>
</td></tr>
<tr><td><code id="PrInDTAllparts_+3A_thres">thres</code></td>
<td>
<p>Probability threshold for prediction of smaller class (numerical, &gt;= 0 and &lt; 1); default = 0.5</p>
</td></tr>
<tr><td><code id="PrInDTAllparts_+3A_nesvar">nesvar</code></td>
<td>
<p>Name of nesting variable (character)</p>
</td></tr>
<tr><td><code id="PrInDTAllparts_+3A_divt">divt</code></td>
<td>
<p>Number of parts of nesting variable nesvar for which models should be determined individually</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Standard output can be produced by means of <code>print(name)</code> or just <code> name </code> where 'name' is the output data 
frame of the function.
</p>


<h3>Value</h3>


<dl>
<dt>baAll</dt><dd><p>balanced accuracy of tree on full sample</p>
</dd>
<dt>nesvar</dt><dd><p>name of nesting variable</p>
</dd>
<dt>divt</dt><dd><p>number of consecutive parts of the sample</p>
</dd>
<dt>badiv</dt><dd><p>balanced accuracy of trees on 'divt' consecutive parts of the sample</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>data &lt;- PrInDT::data_speaker
data &lt;- na.omit(data)
nesvar &lt;- "SPEAKER"
outNesAll &lt;- PrInDTAllparts(data,"class",ctestv=NA,conf.level=0.95,thres=0.5,nesvar,divt=8)
outNesAll

</code></pre>

<hr>
<h2 id='PrInDTMulab'>Multiple label classification based on resampling by <code><a href="#topic+PrInDT">PrInDT</a></code></h2><span id='topic+PrInDTMulab'></span>

<h3>Description</h3>

<p>Multiple label classification based on resampling by <code><a href="#topic+PrInDT">PrInDT</a></code>. We consider two ways of modeling (Binary relevance modeling, 
dependent binary modeling) and three ways of model evaluation: single assessment, joint assessment, and true prediction  
(see the Value section for more information).<br />
Variables should be arranged in 'datain' according to indices specified in 'indind', 'indaddind', and 'inddep'.<br />
Undersampling is repeated 'N' times.<br />
Undersampling percentages 'percl' for the larger class and 'percs' for the smaller class can be 
specified, one each per dependent class variable.<br />
</p>
<p><strong>Reference</strong><br /> Probst, P., Au, Q., Casalicchio, G., Stachl, C., and Bischl, B. 2017. Multilabel Classification with 
R Package mlr. arXiv:1703.08991v2
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PrInDTMulab(datain, classnames, ctestv, conf.level=0.95, percl, percs=1,
       N, indind, indaddind, inddep)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PrInDTMulab_+3A_datain">datain</code></td>
<td>
<p>Input data frame with class factor variable 'classname' and the<br />
influential variables, which need to be factors or numericals (transform logicals and character variables to factors)</p>
</td></tr>
<tr><td><code id="PrInDTMulab_+3A_classnames">classnames</code></td>
<td>
<p>names of class variables (character vector)</p>
</td></tr>
<tr><td><code id="PrInDTMulab_+3A_ctestv">ctestv</code></td>
<td>
<p>Vector of character strings of forbidden split results;<br />
see function <code><a href="#topic+PrInDT">PrInDT</a></code> for details.<br />
If no restrictions exist, the default = NA is used.</p>
</td></tr>
<tr><td><code id="PrInDTMulab_+3A_conf.level">conf.level</code></td>
<td>
<p>(1 - significance level) in function <code>ctree</code> (numerical, &gt; 0 and &lt;= 1);<br />
default = 0.95</p>
</td></tr>
<tr><td><code id="PrInDTMulab_+3A_percl">percl</code></td>
<td>
<p>list of undersampling percentages of larger class (numerical, &gt; 0 and &lt;= 1): one per dependent class variable</p>
</td></tr>
<tr><td><code id="PrInDTMulab_+3A_percs">percs</code></td>
<td>
<p>list of undersampling percentage of smaller class (numerical, &gt; 0 and &lt;= 1); one per dependent class variable</p>
</td></tr>
<tr><td><code id="PrInDTMulab_+3A_n">N</code></td>
<td>
<p>no. of repetitions (integer &gt; 0)</p>
</td></tr>
<tr><td><code id="PrInDTMulab_+3A_indind">indind</code></td>
<td>
<p>indices of independent variables</p>
</td></tr>
<tr><td><code id="PrInDTMulab_+3A_indaddind">indaddind</code></td>
<td>
<p>indices of additional independent variables used in the case of dependent binary relevance modeling</p>
</td></tr>
<tr><td><code id="PrInDTMulab_+3A_inddep">inddep</code></td>
<td>
<p>indices of dependent variables</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Standard output can be produced by means of <code>print(name)</code> or just <code> name </code> as well as <code>plot(name)</code>  where 'name' is the output data 
frame of the function.<br />
The plot function will produce a series of more than one plot. If you use R, you might want to specify <code>windows(record=TRUE)</code> before 
<code>plot(name)</code> to save the whole series of plots. In R-Studio this functionality is provided automatically.
</p>


<h3>Value</h3>


<dl>
<dt>accbr</dt><dd><p>model errors for Binary Relevance (single assessment) - only independent predictors are used for modeling one label at a time,
the other labels are not used as predictors. As the performance measure for the resulting classification rules,
the balanced accuracy of the best model from PrInDT is employed for each individual label.</p>
</dd>
<dt>errbin</dt><dd><p>combined error for Binary Relevance (joint assessment) - the best prediction models for the different labels are combined  
to assess the combined prediction. The 01-accuracy counts a label combination as correct only if all labels are correctly predicted.
The hamming accuracy corresponds to the proportion of labels whose value is correctly predicted.</p>
</dd>
<dt>accdbr</dt><dd><p>model errors for Dependent Binary Relevance (Extended Model) (single assessment) - each label is trained by means of an extended model which 
not only includes the independent predictors but also the other labels. For these labels, the truly observed values are used for 
estimation and prediction. In the extended model, other labels, which are not treated as dependent variables, can also be used as additional predictors.</p>
</dd>
<dt>errext</dt><dd><p>combined errors for Dependent Binary Relevance (Extended Model) (joint assessment)</p>
</dd>
<dt>errtrue</dt><dd><p>combined errors for Dependent Binary Relevance (True Prediction) - in the prediction phase, the values 
of all modeled labels are first predicted by the independent predictors only and then the predicted labels are used in the estimated  
extended model in a 2nd step to 
ultimately predict the labels.</p>
</dd>
<dt>coldata</dt><dd><p>column names of input data</p>
</dd>
<dt>inddep</dt><dd><p>indices of dependent variables (labels to be modeled)</p>
</dd>
<dt>treebr</dt><dd><p>list of trees from Binary Relevance modeling, one tree for each label; refer to an individual tree as <code>treebr[[i]]</code>, 
i = 1, ..., no. of labels</p>
</dd>
<dt>treedbr</dt><dd><p>list of trees from Dependent Binary Relevance modeling, one for each label; refer to an individual tree as <code>treedbr[[i]]</code>, 
i = 1, ..., no. of labels</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>data &lt;- PrInDT::data_land # load data
dataclean &lt;- data[,c(1:7,23:24,11:13,22,8:10)]  # only relevant features
indind &lt;- c(1:9) # original predictors
indaddind &lt;- c(10:13) # additional predictors
inddep &lt;- c(14:16) # dependent variables
dataclean &lt;- na.omit(dataclean)
ctestv &lt;- NA
N &lt;- 21  # no. of repetitions
perc &lt;- c(0.45,0.05,0.25)   # percentages of observations of larger class, 
#                             1 per dependent class variable
perc2 &lt;- c(0.75,0.95,0.75)  # percentages of observations of smaller class, 
#                             1 per dependent class variable
##
# Call PrInDT: language by language
##
outmult &lt;- PrInDTMulab(dataclean,colnames(dataclean)[inddep],ctestv=NA,conf.level=0.95,
                  percl=perc,percs=perc2,N,indind,indaddind,inddep)
print(outmult)
plot(outmult)

</code></pre>

<hr>
<h2 id='PrInDTMulabAll'>Multiple label classification based on all observations</h2><span id='topic+PrInDTMulabAll'></span>

<h3>Description</h3>

<p>Multiple label classification based on all observations. We consider two ways of modeling (Binary relevance modeling, 
dependent binary modeling) and three ways of model evaluation: single 
assessment, joint assessment, and true prediction (see the Value section for more information).<br />
Interpretability is checked (see ctestv).<br />
Variables should be arranged in 'datain' according to indices specified in 'indind', 'indaddind', and 'inddep'.<br />
</p>
<p><strong>Reference</strong><br /> Probst, P., Au, Q., Casalicchio, G., Stachl, C., and Bischl, B. 2017. Multilabel Classification with 
R Package mlr. arXiv:1703.08991v2
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PrInDTMulabAll(datain, classnames, ctestv=NA, conf.level=0.95, indind, indaddind,
       inddep)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PrInDTMulabAll_+3A_datain">datain</code></td>
<td>
<p>Input data frame with class factor variable 'classname' and the<br />
influential variables, which need to be factors or numericals (transform logicals and character variables to factors)</p>
</td></tr>
<tr><td><code id="PrInDTMulabAll_+3A_classnames">classnames</code></td>
<td>
<p>names of class variables (character vector)</p>
</td></tr>
<tr><td><code id="PrInDTMulabAll_+3A_ctestv">ctestv</code></td>
<td>
<p>Vector of character strings of forbidden split results;<br />
see function <code><a href="#topic+PrInDT">PrInDT</a></code> for details.<br />
If no restrictions exist, the default = NA is used.</p>
</td></tr>
<tr><td><code id="PrInDTMulabAll_+3A_conf.level">conf.level</code></td>
<td>
<p>(1 - significance level) in function <code>ctree</code> (numerical, &gt; 0 and &lt;= 1);<br />
default = 0.95</p>
</td></tr>
<tr><td><code id="PrInDTMulabAll_+3A_indind">indind</code></td>
<td>
<p>indices of independent variables</p>
</td></tr>
<tr><td><code id="PrInDTMulabAll_+3A_indaddind">indaddind</code></td>
<td>
<p>indices of additional predictors used in the case of dependent binary relevance modeling</p>
</td></tr>
<tr><td><code id="PrInDTMulabAll_+3A_inddep">inddep</code></td>
<td>
<p>indices of dependent variables</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Standard output can be produced by means of <code>print(name)</code> or just <code> name </code> as well as <code>plot(name)</code>  where 'name' is the output data 
frame of the function.<br />
The plot function will produce a series of more than one plot. If you use R, you might want to specify <code>windows(record=TRUE)</code> before 
<code>plot(name)</code> to save the whole series of plots. In R-Studio this functionality is provided automatically.
</p>


<h3>Value</h3>

 
<dl>
<dt>accabr</dt><dd><p>model errors for Binary Relevance (single assessment) - only independent predictors are used for modeling one label at a time,  
the other labels are not used as predictors. The classification rules are trained on all observations. 
As the performance measure for the resulting classification rules, the balanced accuracy of the models for each individual label is employed.</p>
</dd>
<dt>errabin</dt><dd><p>combined error for Binary Relevance (joint assessment) - the best prediction models for the different labels are combined to assess the 
combined prediction. The 01-accuracy counts a label combination as correct only if all labels are correctly predicted. 
The hamming accuracy corresponds to the proportion of labels whose value is correctly predicted.</p>
</dd>
<dt>accadbr</dt><dd><p>model errors in Dependent Binary Relevance (Extended Model) (single assessment) - each label is trained by means of an extended model which 
not only includes the independent predictors but also the other labels. For these labels the truly observed values are used for estimation 
and prediction. In the extended model, further labels, which are not treated as dependent variables, can be used as additional predictors.</p>
</dd>
<dt>erraext</dt><dd><p>combined errors for Dependent Binary Relevance (Extended Model) (joint assessment) </p>
</dd>
<dt>erratrue</dt><dd><p>combined errors for Dependent Binary Relevance (True Prediction) - in the prediction phase, the values 
of all modeled labels are first predicted by the independent predictors only (see Binary Relevance) and then the predicted labels are used in  
the estimated extended model in a 2nd step to ultimately predict the labels.</p>
</dd>
<dt>coldata</dt><dd><p>column names of input data</p>
</dd>
<dt>inddep</dt><dd><p>indices of dependent variables (labels to be modeled)</p>
</dd>
<dt>treeabr</dt><dd><p>list of trees from Binary Relevance modeling, one tree for each label; refer to an individual tree as <code>treeabr[[i]]</code>, 
i = 1, ..., no. of labels</p>
</dd>
<dt>treeadbr</dt><dd><p>list of trees from Dependent Binary Relevance modeling, one for each label; refer to an individual tree as <code>treeadbr[[i]]</code>, 
i = 1, ..., no. of labels</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>data &lt;- PrInDT::data_land # load data
dataclean &lt;- data[,c(1:7,23:24,11:13,22,8:10)]  # only relevant features
indind &lt;- c(1:9) # original predictors
indaddind &lt;- c(10:13) # additional predictors
inddep &lt;- c(14:16) # dependent variables
dataclean &lt;- na.omit(dataclean)
ctestv &lt;- NA
##
# Call PrInDTAll: language by language
##
outmultAll &lt;- PrInDTMulabAll(dataclean,colnames(dataclean)[inddep],ctestv,conf.level=0.95,
                     indind,indaddind,inddep)
outmultAll
plot(outmultAll)

</code></pre>

<hr>
<h2 id='PrInDTMulev'>PrInDT analysis for a classification problem with multiple classes.</h2><span id='topic+PrInDTMulev'></span>

<h3>Description</h3>

<p>PrInDT analysis for a classification problem with more than 2 classes. For each combination of one class vs. 
the other classes a 2-class <code><a href="#topic+PrInDT">PrInDT</a></code> analysis is carried out.<br />
The percentages for undersampling of the larger class ('percl' in <code><a href="#topic+PrInDT">PrInDT</a></code>) are chosen so that the resulting sizes
are comparable with the size of the smaller classes for which all their observations are used in undersampling ('percs' = 1 in <code><a href="#topic+PrInDT">PrInDT</a></code>).<br />
The class with the highest probability in the K (= number of classes) analyses is chosen for prediction.<br />
Interpretability is checked (see 'ctestv').
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PrInDTMulev(datain, classname, ctestv=NA, N, conf.level=0.95)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PrInDTMulev_+3A_datain">datain</code></td>
<td>
<p>Input data frame with class factor variable 'classname' and the<br />
influential variables, which need to be factors or numericals (transform logicals and character variables to factors)</p>
</td></tr>
<tr><td><code id="PrInDTMulev_+3A_classname">classname</code></td>
<td>
<p>Name of class variable (character)</p>
</td></tr>
<tr><td><code id="PrInDTMulev_+3A_ctestv">ctestv</code></td>
<td>
<p>Vector of character strings of forbidden split results;<br />
see function <code><a href="#topic+PrInDT">PrInDT</a></code> for details.<br />
If no restrictions exist, the default = NA is used.</p>
</td></tr>
<tr><td><code id="PrInDTMulev_+3A_n">N</code></td>
<td>
<p>Number of repetitions (integer &gt; 0)</p>
</td></tr>
<tr><td><code id="PrInDTMulev_+3A_conf.level">conf.level</code></td>
<td>
<p>(1 - significance level) in function <code>ctree</code> (numerical, &gt; 0 and &lt;= 1)<br />
(default = 0.95)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Standard output can be produced by means of <code>print(name)</code> or just <code> name </code> as well as <code>plot(name)</code>  where 'name' is the output data 
frame of the function.<br />
The plot function will produce a series of more than one plot. If you use R, you might want to specify <code>windows(record=TRUE)</code> before 
<code>plot(name)</code> to save the whole series of plots. In R-Studio this functionality is provided automatically.
</p>


<h3>Value</h3>


<dl>
<dt>class</dt><dd><p>levels of class variable</p>
</dd> 
<dt>trees</dt><dd><p>trees for the levels of the class variable; refer to an individual tree as <code>trees[[k]]</code>, k = 1, ..., no. of levels</p>
</dd>
<dt>ba</dt><dd><p>balanced accuracy of combined predictions</p>
</dd> 
<dt>conf</dt><dd><p>confusion matrix of combined predictions</p>
</dd> 
<dt>ninterp</dt><dd><p>no. of non-interpretable trees</p>
</dd> 
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>datastrat &lt;- PrInDT::data_zero
data &lt;- na.omit(datastrat)
ctestv &lt;- NA
data$rel[data$ETH %in% c("C1a","C1b","C1c") &amp; data$real == "zero"] &lt;- "zero1"
data$rel[data$ETH %in% c("C2a","C2b","C2c") &amp; data$real == "zero"] &lt;- "zero2"
data$rel[data$real == "realized"] &lt;- "real"
data$rel &lt;- as.factor(data$rel) # rel is new class variable
data$real &lt;- NULL # remove old class variable
N &lt;- 51
conf.level &lt;- 0.99 # 1 - significance level (mincriterion) in ctree
out &lt;- PrInDTMulev(data,"rel",ctestv,N,conf.level) 
out # print best models based on subsamples
plot(out) # corresponding plots

</code></pre>

<hr>
<h2 id='PrInDTMulevAll'>Conditional inference tree (ctree) for multiple classes on all observations</h2><span id='topic+PrInDTMulevAll'></span>

<h3>Description</h3>

<p>ctree for more than 2 classes on all observations. Interpretability is checked (see 'ctestv').
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PrInDTMulevAll(datain, classname, ctestv=NA, conf.level=0.95)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PrInDTMulevAll_+3A_datain">datain</code></td>
<td>
<p>Input data frame with class factor variable 'classname' and the<br />
influential variables, which need to be factors or numericals (transform logicals and character variables to factors)</p>
</td></tr>
<tr><td><code id="PrInDTMulevAll_+3A_classname">classname</code></td>
<td>
<p>Name of class variable (character)</p>
</td></tr>
<tr><td><code id="PrInDTMulevAll_+3A_ctestv">ctestv</code></td>
<td>
<p>Vector of character strings of forbidden split results;<br />
see function <code><a href="#topic+PrInDT">PrInDT</a></code> for details.<br />
If no restrictions exist, the default = NA is used.</p>
</td></tr>
<tr><td><code id="PrInDTMulevAll_+3A_conf.level">conf.level</code></td>
<td>
<p>(1 - significance level) in function <code>ctree</code> (numerical, &gt; 0 and &lt;= 1)<br />
(default = 0.95)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Standard output can be produced by means of <code>print(name)</code> or just <code> name </code> as well as <code>plot(name)</code> where 'name' is the output data 
frame of the function.
</p>


<h3>Value</h3>


<dl>
<dt>treeall</dt><dd><p>ctree based on all observations</p>
</dd>
<dt>baAll</dt><dd><p>balanced accuracy of 'treeall'</p>
</dd>
<dt>interpAll</dt><dd><p>criterion of interpretability of 'treeall' (TRUE / FALSE)</p>
</dd>
<dt>confAll</dt><dd><p>confusion matrix of 'treeall'</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>datastrat &lt;- PrInDT::data_zero
data &lt;- na.omit(datastrat)
ctestv &lt;- rbind('ETH == {C2a,C1a}', 'MLU == {1, 3}')
data$rel[data$ETH %in% c("C1a","C1b","C1c") &amp; data$real == "zero"] &lt;- "zero1"
data$rel[data$ETH %in% c("C2a","C2b","C2c") &amp; data$real == "zero"] &lt;- "zero2"
data$rel[data$real == "realized"] &lt;- "real"
data$rel &lt;- as.factor(data$rel) # rel is new class variable
data$real &lt;- NULL # remove old class variable
conf.level &lt;- 0.99 # 1 - significance level (mincriterion) in ctree
outAll &lt;- PrInDTMulevAll(data,"rel",ctestv,conf.level) 
outAll # print model based on all observations
plot(outAll)

</code></pre>

<hr>
<h2 id='PrInDTreg'>Regression tree resampling by the PrInDT method</h2><span id='topic+PrInDTreg'></span>

<h3>Description</h3>

<p>Regression tree optimzation to identify the best interpretable tree; interpretability is checked (see 'ctestv').<br />
The relationship between the target variable 'regname' and all other factor and numerical variables
in the data frame 'datain' is optimally modeled by means of 'N' repetitions of subsampling.<br /> 
The optimization criterion is the R2 of the model on the full sample.<br />
Multiple subsampling percentages of observations and predictors can be specified (in 'pobs' and 'ppre', correspondingly).<br />
The trees generated from undersampling can be restricted by
rejecting unacceptable trees which include split results specified in the character strings of the vector 'ctestv'.<br />
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PrInDTreg(datain, regname, ctestv=NA, N, pobs, ppre, conf.level=0.95)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PrInDTreg_+3A_datain">datain</code></td>
<td>
<p>Input data frame with class factor variable 'classname' and the<br />
influential variables, which need to be factors or numericals (transform logicals and character variables to factors)</p>
</td></tr>
<tr><td><code id="PrInDTreg_+3A_regname">regname</code></td>
<td>
<p>name of regressand variable (character)</p>
</td></tr>
<tr><td><code id="PrInDTreg_+3A_ctestv">ctestv</code></td>
<td>
<p>Vector of character strings of forbidden split results;<br />
see function <code><a href="#topic+PrInDT">PrInDT</a></code> for details.<br />
If no restrictions exist, the default = NA is used.</p>
</td></tr>
<tr><td><code id="PrInDTreg_+3A_n">N</code></td>
<td>
<p>Number of repetitions (integer &gt; 0)</p>
</td></tr>
<tr><td><code id="PrInDTreg_+3A_pobs">pobs</code></td>
<td>
<p>Vector of resampling percentages of observations (numerical, &gt; 0 and &lt;= 1)</p>
</td></tr>
<tr><td><code id="PrInDTreg_+3A_ppre">ppre</code></td>
<td>
<p>Vector of resampling percentages of predictor variables (numerical, &gt; 0 and &lt;= 1)</p>
</td></tr>
<tr><td><code id="PrInDTreg_+3A_conf.level">conf.level</code></td>
<td>
<p>(1 - significance level) in function <code>ctree</code> (numerical, &gt; 0 and &lt;= 1);<br />
default = 0.95</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For the optimzation of the trees, we employ a method we call Sumping (Subsampling umbrella of 
model parameters), a variant of Bumping (Bootstrap umbrella of model parameters) (Tibshirani 
&amp; Knight, 1999) which use subsampling instead of bootstrapping. The aim of the 
optimization is to identify conditional inference trees with maximum predictive power
on the full sample under interpretability restrictions. 
</p>
<p><strong>Reference</strong><br /> Tibshirani, R., Knight, K. 1999. Model Search and Inference By Bootstrap &quot;bumping&quot;.
Journal of Computational and Graphical Statistics, Vol. 8, No. 4 (Dec., 1999), pp. 671-686 
</p>
<p>Standard output can be produced by means of <code>print(name)</code> or just <code> name </code> as well as <code>plot(name)</code> where 'name' is the output data 
frame of the function.<br />
The plot function will produce a series of more than one plot. If you use R, you might want to specify <code>windows(record=TRUE)</code> before 
<code>plot(name)</code> to save the whole series of plots. In R-Studio this functionality is provided automatically.
</p>


<h3>Value</h3>


<dl>
<dt>meanint</dt><dd><p>Mean number of interpretable trees over the combinations of individual percentages in 'pobs' and 'ppre'</p>
</dd>
<dt>R2mean</dt><dd><p>Mean R2 on test sets</p>
</dd>
<dt>ctmax</dt><dd><p>best resampled regression tree according to R2 on the full data set</p>
</dd>
<dt>percmax</dt><dd><p>Maximum R2 achieved for %observations</p>
</dd>
<dt>perfeamax</dt><dd><p>Maximum R2 achieved for %predictors</p>
</dd>
<dt>maxR2</dt><dd><p>best R2 on the full data set for resampled regression trees (for 'ctmax')</p>
</dd> 
<dt>interpmax</dt><dd><p>interpretability of best tree 'ctmax'</p>
</dd>
<dt>ctmax2</dt><dd><p>second best resampled regression tree according to R2 on the full data set</p>
</dd>
<dt>percmax2</dt><dd><p>second best R2 achieved for %observations</p>
</dd>
<dt>perfeamax2</dt><dd><p>second best R2 achieved for %features</p>
</dd>
<dt>max2R2</dt><dd><p>second best R2 on the full data set for resampled regression trees (for 'ctmax2')</p>
</dd>
<dt>interp2max</dt><dd><p>interpretability of second-best tree 'ctmax2'</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>data &lt;- PrInDT::data_vowel
data &lt;- na.omit(data)
ctestv &lt;- 'vowel_maximum_pitch &lt;= 320'
N &lt;- 30 # no. of repetitions
pobs &lt;- c(0.70,0.60) # percentages of observations
ppre &lt;- c(0.90,0.70) # percentages of predictors
outreg &lt;- PrInDTreg(data,"target",ctestv,N,pobs,ppre)
outreg
plot(outreg)

</code></pre>

<hr>
<h2 id='PrInDTregAll'>Regression tree based on all observations</h2><span id='topic+PrInDTregAll'></span>

<h3>Description</h3>

<p>Regression tree based on the full sample; interpretability is checked (see 'ctestv').<br />
The relationship between the target variable 'regname' and all other factor and numerical variables
in the data frame 'datain' is modeled based on all observations. <br />
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PrInDTregAll(datain, regname, ctestv=NA, conf.level=0.95)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PrInDTregAll_+3A_datain">datain</code></td>
<td>
<p>Input data frame with class factor variable 'classname' and the<br />
influential variables, which need to be factors or numericals (transform logicals and character variables to factors)</p>
</td></tr>
<tr><td><code id="PrInDTregAll_+3A_regname">regname</code></td>
<td>
<p>name of regressand variable (character)</p>
</td></tr>
<tr><td><code id="PrInDTregAll_+3A_ctestv">ctestv</code></td>
<td>
<p>Vector of character strings of forbidden split results;<br />
see function <code><a href="#topic+PrInDT">PrInDT</a></code> for details.<br />
If no restrictions exist, the default = NA is used.</p>
</td></tr>
<tr><td><code id="PrInDTregAll_+3A_conf.level">conf.level</code></td>
<td>
<p>(1 - significance level) in function <code>ctree</code> (numerical, &gt; 0 and &lt;= 1);<br />
default = 0.95</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Standard output can be produced by means of <code>print(name)</code> or just <code> name </code> as well as <code>plot(name)</code> where 'name' is the output data 
frame of the function.
</p>


<h3>Value</h3>


<dl>
<dt>treeall</dt><dd><p>tree based on all observations</p>
</dd>
<dt>R2All</dt><dd><p>goodness of fit of 'treeall' based on all observations</p>
</dd>
<dt>interpAll</dt><dd><p>criterion of interpretability of 'treeall' (TRUE / FALSE)</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>data &lt;- PrInDT::data_vowel
data &lt;- na.omit(data)
ctestv &lt;- 'vowel_maximum_pitch &lt;= 320'
outreg &lt;- PrInDTregAll(data,"target",ctestv)
outreg
plot(outreg)

</code></pre>

<hr>
<h2 id='RePrInDT'>Repeated <code><a href="#topic+PrInDT">PrInDT</a></code> for specified percentage combinations</h2><span id='topic+RePrInDT'></span>

<h3>Description</h3>

<p><code><a href="#topic+PrInDT">PrInDT</a></code> is called repeatedly according to the percentages specified in the vectors 'plarge' and 
'psmall'.<br />
The relationship between the two-class factor variable 'classname' and all other factor and numerical variables
in the data frame 'datain' is optimally modeled by means of 'N' repetitions of undersampling.<br /> 
The trees generated from undersampling can be restricted by rejecting 
unacceptable trees which include split results specified in the character strings of the vector 'ctestv'.<br />
The probability threshold 'thres' for the prediction of the smaller class may be specified (default = 0.5).<br />
Undersampling may be stratified in two ways by the feature 'strat'.
</p>
<p><strong>Reference</strong><br /> Weihs, C., Buschfeld, S. 2021c. Repeated undersampling in PrInDT (RePrInDT): Variation in undersampling and prediction, 
and ranking of predictors in ensembles. arXiv:2108.05129
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RePrInDT(datain, classname, ctestv=NA, N, plarge, psmall, conf.level=0.95,
       thres=0.5, stratvers=0, strat=NA, seedl=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="RePrInDT_+3A_datain">datain</code></td>
<td>
<p>Input data frame with class factor variable 'classname' and the<br />
influential variables, which need to be factors or numericals (transform logicals and character variables to factors)</p>
</td></tr>
<tr><td><code id="RePrInDT_+3A_classname">classname</code></td>
<td>
<p>Name of class variable (character)</p>
</td></tr>
<tr><td><code id="RePrInDT_+3A_ctestv">ctestv</code></td>
<td>
<p>Vector of character strings of forbidden split results;<br />
see function <code><a href="#topic+PrInDT">PrInDT</a></code> for details.<br />
If no restrictions exist, the default = NA is used.</p>
</td></tr>
<tr><td><code id="RePrInDT_+3A_n">N</code></td>
<td>
<p>Number of repetitions (integer &gt; 0)</p>
</td></tr>
<tr><td><code id="RePrInDT_+3A_plarge">plarge</code></td>
<td>
<p>Vector of undersampling percentages of larger class (numerical, &gt; 0 and &lt;= 1)</p>
</td></tr>
<tr><td><code id="RePrInDT_+3A_psmall">psmall</code></td>
<td>
<p>Vector of undersampling percentages of smaller class (numerical, &gt; 0 and &lt;= 1)</p>
</td></tr>
<tr><td><code id="RePrInDT_+3A_conf.level">conf.level</code></td>
<td>
<p>(1 - significance level) in function <code>ctree</code> (numerical, &gt; 0 and &lt;= 1);<br />
default = 0.95</p>
</td></tr>
<tr><td><code id="RePrInDT_+3A_thres">thres</code></td>
<td>
<p>Probability threshold for prediction of smaller class (numerical, &gt;= 0 and &lt; 1); default = 0.5</p>
</td></tr>
<tr><td><code id="RePrInDT_+3A_stratvers">stratvers</code></td>
<td>
<p>Version of stratification;<br />
= 0: none (default),<br />
= 1: stratification according to the percentages of the values of the factor variable 'strat',<br />
&gt; 1: stratification with minimum number 'stratvers' of observations per value of 'strat'</p>
</td></tr>
<tr><td><code id="RePrInDT_+3A_strat">strat</code></td>
<td>
<p>Name of one (!) stratification variable for undersampling (character);<br />
default = NA (no stratification)</p>
</td></tr>
<tr><td><code id="RePrInDT_+3A_seedl">seedl</code></td>
<td>
<p>Should the seed for random numbers be set (TRUE / FALSE)?<br />
default = TRUE</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Standard output can be produced by means of <code>print(name)</code> or just <code> name </code> as well as <code>plot(name)</code> where 'name' is the output data 
frame of the function.<br />
The plot function will produce a series of more than one plot. If you use R, you might want to specify <code>windows(record=TRUE)</code> before 
<code>plot(name)</code> to save the whole series of plots. In R-Studio this functionality is provided automatically.
</p>


<h3>Value</h3>


<dl>
<dt>treesb</dt><dd><p>best trees for the different percentage combinations; refer to an individual tree as <code>treesb[[k]]</code>, k = 1, ..., length(plarge)*length(psmall)</p>
</dd>
<dt>acc1st</dt><dd><p>accuracies of best trees on full sample</p>
</dd>
<dt>acc3en</dt><dd><p>accuracies of ensemble of 3 best trees on full sample</p>
</dd>
<dt>simp_m</dt><dd><p>mean of permutation losses for the predictors</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>datastrat &lt;- PrInDT::data_zero
data &lt;- na.omit(datastrat) # cleaned full data: no NAs
# interpretation restrictions (split exclusions)
ctestv &lt;- rbind('ETH == {C2a, C1a}', 'MLU == {1, 3}')
N &lt;- 51  # no. of repetitions
conf.level &lt;- 0.99 # 1 - significance level (mincriterion) in ctree
psmall &lt;- c(0.95,1)     # percentages of the small class
plarge &lt;- c(0.09,0.1)  # percentages of the large class
outRe &lt;- RePrInDT(data,"real",ctestv,N,plarge,psmall,conf.level) # might take 5 minutes
outRe
plot(outRe)

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
