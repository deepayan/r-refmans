<!DOCTYPE html><html lang="en"><head><title>Help for package denoiseR</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {denoiseR}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#denoiseR-package'>
<p>Regularized Low Rank Matrix Estimation</p></a></li>
<li><a href='#adashrink'><p>Adaptive Shrinkage</p></a></li>
<li><a href='#estim_delta'><p>Estimates delta for Iterated Stable Autoencoder</p></a></li>
<li><a href='#estim_sigma'><p>Estimate sigma</p></a></li>
<li><a href='#impactfactor'>
<p>Data set on metrics for scientific journals:</p></a></li>
<li><a href='#imputeada'><p>Adaptive Shrinkage with missing values - Imputation</p></a></li>
<li><a href='#imputecount'><p>Imputation of count data with the Iterated Stable Autoencoder</p></a></li>
<li><a href='#ISA'><p>Iterated Stable Autoencoder</p></a></li>
<li><a href='#LRsim'><p>Low Rank Simulation</p></a></li>
<li><a href='#optishrink'><p>Optimal Shrinkage</p></a></li>
<li><a href='#Presidents'>
<p>Contingency table with US Presidents speeches.</p></a></li>
<li><a href='#tumors'>
<p>Brain tumors data.</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Version:</td>
<td>1.0.2</td>
</tr>
<tr>
<td>Date:</td>
<td>2020-02-23</td>
</tr>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Regularized Low Rank Matrix Estimation</td>
</tr>
<tr>
<td>Author:</td>
<td>Julie Josse, Sylvain Sardy, Stefan Wager</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Julie Josse &lt;julie.josserennes@gmail.com&gt;</td>
</tr>
<tr>
<td>Imports:</td>
<td>irlba, Matrix, FactoMineR, stats</td>
</tr>
<tr>
<td>Suggests:</td>
<td>missMDA</td>
</tr>
<tr>
<td>Description:</td>
<td>Estimate a low rank matrix from noisy data using singular values
    thresholding and shrinking functions. Impute missing values with matrix completion. The method is described in &lt;<a href="https://doi.org/10.48550/arXiv.1602.01206">doi:10.48550/arXiv.1602.01206</a>&gt;.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>5.0.1</td>
</tr>
<tr>
<td>Depends:</td>
<td>R(&ge; 2.10)</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2020-02-26 06:34:43 UTC; josse</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2020-02-26 07:10:09 UTC</td>
</tr>
</table>
<hr>
<h2 id='denoiseR-package'>
Regularized Low Rank Matrix Estimation
</h2><span id='topic+denoiseR-package'></span><span id='topic+denoiseR'></span>

<h3>Description</h3>

<p>The methods implemented allow to recover a low-rank structure from noisy data. In addition, they may be used to estimate the underlying rank and to impute missing values.
</p>


<h3>Details</h3>


<table>
<tr>
 <td style="text-align: left;">
Package: </td><td style="text-align: left;"> denoiseR</td>
</tr>
<tr>
 <td style="text-align: left;">
Type: </td><td style="text-align: left;"> Package</td>
</tr>
<tr>
 <td style="text-align: left;">
Version: </td><td style="text-align: left;"> 1.0</td>
</tr>
<tr>
 <td style="text-align: left;">
Date: </td><td style="text-align: left;"> 2016-07-09</td>
</tr>
<tr>
 <td style="text-align: left;">
License: </td><td style="text-align: left;">  GPL (&gt;=2)</td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>



<h3>Author(s)</h3>

<p>Julie Josse, Sylvain Sardy, Stefan Wager <br />
Maintainer: Julie Josse &lt;julie.josserennes@gmail.com&gt;<br />
</p>


<h3>References</h3>

<p>Julie Josse, Sylvain Sardy, Stefan Wager. denoiseR a package for low rank matrix estimation.
</p>


<h3>See Also</h3>

<p>URL: http://juliejosse.com/<br />
http://web.stanford.edu/~swager/research.html<br />
http://www.unige.ch/math/folks/sardy<br />
</p>

<hr>
<h2 id='adashrink'>Adaptive Shrinkage</h2><span id='topic+adashrink'></span>

<h3>Description</h3>

<p>This function estimates a low-rank signal from Gaussian noisy data using the Adaptive Shrinker of the singular values. More precisely, the singular values are transformed using a function indexed by two parameters lambda and gamma as
dl  = dl * max(1-(lambda/dl)^gamma,0). This estimator is very flexible and adapts to the data whatever the noise regime.  The parameters lambda and gamma are estimated by minimizing a Stein unbiased risk estimate (SURE) when the variance sigma^2 of the noise is known or a generalized SURE (GSURE) otherwise.
A method using an universal threshold for lambda is also available. The estimator can be seen as a compromise between hard and soft thresholding.  Singular value soft thresholding is a particular case of the method when gamma is equal to 1. It is possible to enforce the method to use soft-thresholding by setting gamma to 1.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>adashrink(X, sigma = NA, method = c("GSURE", "QUT", "SURE"),
  gamma.seq = seq(1, 5, by = 0.1), nbsim = 500, method.optim = "BFGS",
  center = "TRUE", lambda0 = NA)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="adashrink_+3A_x">X</code></td>
<td>
<p>a data frame or a matrix with numeric entries</p>
</td></tr>
<tr><td><code id="adashrink_+3A_sigma">sigma</code></td>
<td>
<p>integer, standard deviation of the Gaussian noise. By default sigma is estimated using the estim_sigma function with the MAD option</p>
</td></tr>
<tr><td><code id="adashrink_+3A_method">method</code></td>
<td>
<p>to select the two tunning parameters lambda and gamma. By default by minimizing GSURE</p>
</td></tr>
<tr><td><code id="adashrink_+3A_gamma.seq">gamma.seq</code></td>
<td>
<p>a vector for the sequence of gamma. (not used when method is QUT). The values must be greater than 1. If gamma.seq is set to 1 then soft singular values soft thresholding is used.</p>
</td></tr>
<tr><td><code id="adashrink_+3A_nbsim">nbsim</code></td>
<td>
<p>integer, number of replications used to calculate the universal threshold lambda when method is QUT</p>
</td></tr>
<tr><td><code id="adashrink_+3A_method.optim">method.optim</code></td>
<td>
<p>the method used in the optim function. By default BFGS</p>
</td></tr>
<tr><td><code id="adashrink_+3A_center">center</code></td>
<td>
<p>boolean, to center the data. By default &quot;TRUE&quot;</p>
</td></tr>
<tr><td><code id="adashrink_+3A_lambda0">lambda0</code></td>
<td>
<p>integer, the initial value for lambda used to optimize SURE and GSURE. By default the median of the singular values (must be in log scale)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>When sigma is known, lambda and gamma can be estimated by minimizing SURE. To do this, a grid for gamma is defined in gamma.seq (gammas must be greater than 1) and the SURE function is optimized on lambda using the optim function of the package stats (?optim) with the optimization method by default sets to &quot;BFGS&quot;. The initial lambda can be modified in the argument lambda0. If gamma.seq is set to 1, then the SURE function is optimized in lambda only.
A value for sigma has to be provided. When sigma is not known, it can be estimated using the function estim_sigma. An alternative which does not require to know or estimate sigma is estimate the two tuning parameters by minimizing GSURE.
QUT consists in generating nbsim matrices of size n * p of Gaussian random variables with mean 0 and variance sigma^2 and computing the first singular value on each matrix. Then, the universal threshold lambda is calculated as the 1-alpha quantile of the null distribution (alpha is here sqrt(log(max(n,p)))). Then, gamma is estimated by minimizing a 1-dim SURE. This method is recommended when one is particularly interested in estimating the rank of the signal.        
The estimated low rank matrix is given in the output mu.hat. adashrink automatically estimates the rank of the signal. Its value is given in the output nb.eigen corresponding to the number of non-zero eigenvalues.
</p>


<h3>Value</h3>

<p>mu.hat the estimator of the signal
</p>
<p>nb.eigen the number of non-zero singular values
</p>
<p>gamma the optimal gamma selected by minimizing SURE or GSURE
</p>
<p>lambda the optimal lambda selected by minimizing SURE or GSURE
</p>
<p>singval the singular values of the estimator
</p>
<p>low.rank the results of the SVD of the estimator
</p>


<h3>References</h3>

<p>Josse, J. &amp; Sardy, S. (2015). Adaptive shrinkage of singular values. Statistics and Computing.
</p>
<p>Candes, E. J., Sing-Long C. A. and Trzasko, J. D (2012). Unbiased risk estimates for singular value thresholding and spectral estimators. IEEE Transactions on Signal Processing 61(19), 4643-4657.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+estim_sigma">estim_sigma</a></code>
</p>
<p><code><a href="#topic+LRsim">LRsim</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>Xsim &lt;- LRsim(200, 500, 100, 1)
## Not run: ada.gsure &lt;- adashrink(Xsim$X, method = "GSURE")
ada.gsure$nb.eigen
ada.gsure$singval
ada.gsure$lambda
ada.gsure$gamma

Xsim &lt;- LRsim(200, 500, 10, 4)
sig &lt;- estim_sigma(Xsim$X)
ada.sure &lt;- adashrink(Xsim$X, method = "SURE", sigma = sig)
soft.sure &lt;- adashrink(Xsim$X, gamma.seq  = 1, method = "SURE", sigma = sig)
## End(Not run)
</code></pre>

<hr>
<h2 id='estim_delta'>Estimates delta for Iterated Stable Autoencoder</h2><span id='topic+estim_delta'></span>

<h3>Description</h3>

<p>This function uses cross-validation to estimate delta for the Iterated Stable Autoencoder when considering Binomial noise. delta is the probability of deletion of each cell of
the data matrix
</p>


<h3>Usage</h3>

<pre><code class='language-R'>estim_delta(X, delta = seq(0.1, 0.9, length.out = 9), nbsim = 10,
  noise = "Binomial", transformation = c("None", "CA"), pNA = 0.1,
  maxiter = 1000, threshold = 1e-08)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="estim_delta_+3A_x">X</code></td>
<td>
<p>a data frame or a matrix with count</p>
</td></tr>
<tr><td><code id="estim_delta_+3A_delta">delta</code></td>
<td>
<p>vector, a sequence of values for the probability of deletion of each cell of
the data matrix</p>
</td></tr>
<tr><td><code id="estim_delta_+3A_nbsim">nbsim</code></td>
<td>
<p>number of times that pNA values are inserted and predicted in the data</p>
</td></tr>
<tr><td><code id="estim_delta_+3A_noise">noise</code></td>
<td>
<p>noise model assumed for the data. By default and only available &quot;Binomial&quot;</p>
</td></tr>
<tr><td><code id="estim_delta_+3A_transformation">transformation</code></td>
<td>
<p>estimates a transformation of the original matrix; currently,
only correspondence analysis CA is available</p>
</td></tr>
<tr><td><code id="estim_delta_+3A_pna">pNA</code></td>
<td>
<p>percentage of missing values added in the data set</p>
</td></tr>
<tr><td><code id="estim_delta_+3A_maxiter">maxiter</code></td>
<td>
<p>integer, maximum number of iterations of the iterative imputation algorithm</p>
</td></tr>
<tr><td><code id="estim_delta_+3A_threshold">threshold</code></td>
<td>
<p>for assessing convergence of the iterative imputation algorithm (difference between two successive iterations)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For each value delta, repeated learning cross-validation consists in inserting pNA percentage of missing values in the data set and predicting them with the Iterative Stable Autoencoder. More precisely, the prediction is obtained using the iterative imputation algorithm (imputecount) which alternates steps of imputation of the missing entries and estimation of the low-rank signal.   
This process is repeated nbsim times for all the deltas. The mean squared error of prediction is kept for each simulation and value of delta. The value of delta leading to the smallest MSEP on average over the simulations is given.
</p>


<h3>Value</h3>

<p>msep, matrix with the MSEP obtained for each simulation and each value of delta
</p>
<p>delta, value giving in average the smallest MSEP over the nbsim simulations
</p>


<h3>See Also</h3>

<p><code><a href="#topic+imputecount">imputecount</a></code>
</p>
<p><code><a href="#topic+ISA">ISA</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'> # A regularized Correspondence Analysis 
 ## Not run: library(FactoMineR)
 perfume &lt;-  read.table("http://factominer.free.fr/docs/perfume.txt",header=TRUE,
 sep="\t",row.names=1)
 rownames(perfume)[4] &lt;- "Cinema"
 
 isa.delt &lt;- estim_delta(perfume, nbsim = 10, transformation = "CA")
 
 isa.ca &lt;- ISA(perfume, delta = isa.delt$delta, noise = "Binomial", transformation = "CA")
 rownames(isa.ca$mu.hat) &lt;- rownames(perfume)
 colnames(isa.ca$mu.hat) &lt;- colnames(perfume)
 res.isa.ca &lt;- CA(isa.ca$mu.hat, graph = FALSE)
 plot(res.isa.ca, title = "Regularized CA", cex = 0.6, selectCol = "contrib 20")
## End(Not run)
</code></pre>

<hr>
<h2 id='estim_sigma'>Estimate sigma</h2><span id='topic+estim_sigma'></span>

<h3>Description</h3>

<p>This function estimates the standard deviation sigma of the noise of the model where the data are generated from a signal of rank k corrupted by homoscedastic Gaussian noise. 
Two estimators are implemented. The first one, named LN, is asymptotically unbiased for sigma in the asymptotic framework where both the number of rows and the number of columns are fixed while the noise variance tends to zero (Low Noise).
It is calculated by computing the residuals sum of squares (using the truncated SVD at order k as an estimator) divided by the number of data minus the number of estimated parameters. Thus, it requires as an input the rank k.
The second one, MAD (mean absolute deviation) is a robust estimator defined as the ratio of the median of the singular values of X over the square root of the median of the Marcenko-Pastur distribution. It can  be useful when the signal can be considered of low-rank (the rank is very small in comparison to the matrix size).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>estim_sigma(X, k = NA, method = c("LN", "MAD"), center = "TRUE")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="estim_sigma_+3A_x">X</code></td>
<td>
<p>a data frame or a matrix with numeric entries</p>
</td></tr>
<tr><td><code id="estim_sigma_+3A_k">k</code></td>
<td>
<p>integer specifying the rank of the signal only if method = &quot;LN&quot;. By default k is estimated using the estim_ncp function of the FactoMineR package</p>
</td></tr>
<tr><td><code id="estim_sigma_+3A_method">method</code></td>
<td>
<p>LN for the low noise asymptotic estimate (it requires to specify the rank k) or MAD for mean absolute deviation</p>
</td></tr>
<tr><td><code id="estim_sigma_+3A_center">center</code></td>
<td>
<p>boolean, to center the data. By default &quot;TRUE&quot;.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In the low noise (LN) asymptotic framework,  the estimator requires providing the rank k. Different methods are available in the litterature and if by default the user does not provide any value, we use of the function estim_ncp of the FactoMineR package with the option GCV (see ?estim_ncp).
</p>


<h3>Value</h3>

<p>sigma the estimated value
</p>


<h3>References</h3>

<p>Josse, J &amp; Husson, F. (2012). Selecting the number of components in principal component analysis using cross-validation approximations. Computational Statistics &amp; Data Analysis, 6 (56).
</p>
<p>Gavish, M &amp; Donoho, D. L. Optimal Shrinkage of Singular Values.
</p>
<p>Gavish, M &amp; Donoho, D. L. (2014). The Optimal Hard Threshold for Singular Values is 4/sqrt(3). IEEE Transactions on Information Theory, 60 (8), 5040-5053.
</p>
<p>Josse, J. &amp; Husson, F. (2011). Selecting the number of components in PCA using cross-validation approximations.Computational Statististics and Data Analysis. 56 (6), pp. 1869-1879.
</p>


<h3>See Also</h3>

<p><code>estim_ncp</code>
</p>
<p><code><a href="#topic+LRsim">LRsim</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>Xsim &lt;-  LRsim(100, 30, 2, 4)
res.sig &lt;- estim_sigma(Xsim$X, k = 2)
</code></pre>

<hr>
<h2 id='impactfactor'>
Data set on metrics for scientific journals: 
</h2><span id='topic+impactfactor'></span>

<h3>Description</h3>

<p>A subset of 443 journals of the sections Computer Science Software, Decision
Sciences Statistics, Probability and Uncertainty and Mathematics Statistics and Probability and their scores for 3 metrics recorded each year from 1999 to 2013: IPP impact per publication, SNIP source normalized impact per paper (tries to weight
by the number of citations per subject fieeld to adjust for different citation cultures) and the
SJR SCImago journal rank (tries to capture average prestige per publication). This data
contains 31 percent of missing values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(impactfactor)
</code></pre>


<h3>Format</h3>

<p>A data frame with 443 observations and  45 continuous variables
</p>


<h3>Source</h3>

<p>journalmetrics.com
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(impactfactor)
## Not run: ada.NA &lt;- imputeada(impactfactor, lambda = 4.46, gamma = 1.9)
impactfactorcomp &lt;- ada.NA$completeObs
## End(Not run)
</code></pre>

<hr>
<h2 id='imputeada'>Adaptive Shrinkage with missing values - Imputation</h2><span id='topic+imputeada'></span>

<h3>Description</h3>

<p>This function estimates a low-rank signal from a noisy Gaussian incomplete data using the iterative Adaptive Trace Norm (ATN) algorithm. It can be used to impute a data set.
dl  = dl * max(1-(lambda/dl)^gamma,0). If, the parameters lambda and gamma are not specified,  they are estimated by minimizing a Missing Stein unbiased risk estimate (SURE) when the variance sigma^2 of the noise is known or a generalized SURE (GSURE) otherwise.
These SURE and GSURE for missing values are implemented using finite differences.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>imputeada(X, lambda = NA, gamma = NA, sigma = NA, method = c("GSURE",
  "SURE"), gamma.seq = seq(1, 5, by = 0.1), method.optim = "BFGS",
  center = "TRUE", scale = "FALSE", threshold = 1e-08, nb.init = 1,
  maxiter = 1000, lambda0 = NA)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="imputeada_+3A_x">X</code></td>
<td>
<p>a data frame or a matrix with numeric entries</p>
</td></tr>
<tr><td><code id="imputeada_+3A_lambda">lambda</code></td>
<td>
<p>integer, value to be used in the iterative ATN algorithm</p>
</td></tr>
<tr><td><code id="imputeada_+3A_gamma">gamma</code></td>
<td>
<p>integer, value to be used in the iterative ATN algorithm</p>
</td></tr>
<tr><td><code id="imputeada_+3A_sigma">sigma</code></td>
<td>
<p>integer, standard deviation of the Gaussian noise.</p>
</td></tr>
<tr><td><code id="imputeada_+3A_method">method</code></td>
<td>
<p>to select the two tunning parameters lambda and gamma. By default by minimizing GSURE</p>
</td></tr>
<tr><td><code id="imputeada_+3A_gamma.seq">gamma.seq</code></td>
<td>
<p>a vector for the sequence of gamma. The values must be greater than 1</p>
</td></tr>
<tr><td><code id="imputeada_+3A_method.optim">method.optim</code></td>
<td>
<p>the method used in the optim function. By default BFGS</p>
</td></tr>
<tr><td><code id="imputeada_+3A_center">center</code></td>
<td>
<p>boolean, to center the data. By default &quot;TRUE&quot;</p>
</td></tr>
<tr><td><code id="imputeada_+3A_scale">scale</code></td>
<td>
<p>boolean, to scale the data. By default &quot;FALSE&quot;</p>
</td></tr>
<tr><td><code id="imputeada_+3A_threshold">threshold</code></td>
<td>
<p>for assessing convergence (difference between two successive iterations)</p>
</td></tr>
<tr><td><code id="imputeada_+3A_nb.init">nb.init</code></td>
<td>
<p>integer, to run the iterative ATN algorithm with nbinit different initialization. By default 1.</p>
</td></tr>
<tr><td><code id="imputeada_+3A_maxiter">maxiter</code></td>
<td>
<p>integer, maximum number of iterations of the iterative imputation algorithm</p>
</td></tr>
<tr><td><code id="imputeada_+3A_lambda0">lambda0</code></td>
<td>
<p>integer, the initial value for lambda used to optimize SURE and GSURE. By default the median of the singular values (must be in log scale)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The iterative ATN algorithm first consists in imputing missing values with initial values. 
Then, adashrink is performed on the completed dataset with its regularization parameter lambda and gamma. The missing entries are imputed with the estimated signal. These steps of estimation of the signal via adashrink and imputation of the missing values are iterated until convergence. At the end, both an estimation of the signal and a completed data set are provided. If lambda and gamma are not known, they can be estimated by minimizing SURE when sigma^2 is known. To do this, a grid for gamma is defined in gamma.seq (gammas must be greater than 1) and the Missing SURE function is optimized on lambda using the optim function of the package stats (?optim) with the optimization method by default sets to &quot;BFGS&quot;. The initial lambda can be modified in the argument lambda0.  
When sigma is not known, it is possible to estimate the two tuning parameters by minimizing Missing GSURE. Note that Missing SURE is defined using finite differences so it is computationally costly.
The estimated low rank matrix is given in the output mu.hat. imputeada automatically estimates the rank of the signal. Its value is given in the output nb.eigen corresponding to the number of non-zero eigenvalues.
</p>


<h3>Value</h3>

<p>mu.hat the estimator of the signal
</p>
<p>completeObs the completed data set. Observed values are the same but missing values are replaced by the estimated one in mu.hat
</p>
<p>nb.eigen the number of non-zero singular values
</p>
<p>gamma the given gamma or the optimal gamma selected by minimizing SURE or GSURE
</p>
<p>lambda the given lambda or the optimal lambda selected by minimizing SURE or GSURE
</p>
<p>singval the singular values of the estimator
</p>
<p>low.rank the results of the SVD of the estimator
</p>


<h3>See Also</h3>

<p><code><a href="#topic+adashrink">adashrink</a></code>
</p>
<p><code><a href="#topic+LRsim">LRsim</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>don.NA &lt;- LRsim(200, 500, 100, 4)$X
don.NA[sample(1:(200*500),20, replace = FALSE)] &lt;- NA
## Not run: adaNA &lt;- imputeada(don.NA, lambda = 0.022, gamma = 2.3)
esti &lt;- adaNA$mu.hat
comp &lt;- adaNA$completeObs
## End(Not run)
</code></pre>

<hr>
<h2 id='imputecount'>Imputation of count data with the Iterated Stable Autoencoder</h2><span id='topic+imputecount'></span>

<h3>Description</h3>

<p>This function estimates a low-rank signal from a noisy count incomplete data
using the Iterated Stable Autoencoder. It can be used to impute a data set.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>imputecount(X, threshold = 1e-08, maxiter = 1000, delta = 0.5,
  transformation = c("None", "CA"))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="imputecount_+3A_x">X</code></td>
<td>
<p>a data frame or a matrix with count data containing missing values</p>
</td></tr>
<tr><td><code id="imputecount_+3A_threshold">threshold</code></td>
<td>
<p>for assessing convergence (difference between two successive iterations)</p>
</td></tr>
<tr><td><code id="imputecount_+3A_maxiter">maxiter</code></td>
<td>
<p>integer, maximum number of iterations of the iterative imputation algorithm</p>
</td></tr>
<tr><td><code id="imputecount_+3A_delta">delta</code></td>
<td>
<p>numeric, probability of deletion of each cell of
the data matrix. By default delta = 0.5</p>
</td></tr>
<tr><td><code id="imputecount_+3A_transformation">transformation</code></td>
<td>
<p>estimate a transformation of the original matrix; currently,
only correspondence analysis CA is available</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Impute the missing entries of a count data set using the iterative ISA algorithm.
The iterative ISA algorithm first consists in imputing missing values with initial values. 
Then, ISA is performed on the completed dataset with its regularization parameter delta. The missing entries are imputed with the estimated signal. These steps of estimation of the signal via ISA and imputation of the missing values are iterated until convergence.
</p>


<h3>Value</h3>

<p>mu.hat the estimator of the signal
</p>
<p>completeObs the completed data set. The observed values are kept for the non-missing entries and the missing values are replaced by the predicted ones
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ISA">ISA</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#
</code></pre>

<hr>
<h2 id='ISA'>Iterated Stable Autoencoder</h2><span id='topic+ISA'></span>

<h3>Description</h3>

<p>This function estimates a low-rank signal from noisy data
using the Iterated Stable Autoencoder. More precisely, it transforms
a noise model into a regularization scheme using a parametric bootstrap. 
In the Gaussian noise model, the procedure is equivalent to shrinking the
singular values of the data matrix (a non linear transformation of the singular
values is applied) whereas it gives other estimators with rotated singular vectors outside the Gaussian framework.
Within the framework of a Binomial or Poisson noise model, it is also possible
to find the low-rank approximation of a transformed version of the data matrix
for instance such as the one used in Correspondence Analysis.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ISA(X, sigma = NA, delta = NA, noise = c("Gaussian", "Binomial"),
  transformation = c("None", "CA"), svd.cutoff = 0.001, maxiter = 1000,
  threshold = 1e-06, nu = min(nrow(X), ncol(X)), svdmethod = c("svd",
  "irlba"), center = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ISA_+3A_x">X</code></td>
<td>
<p>a data frame or a matrix with numeric entries</p>
</td></tr>
<tr><td><code id="ISA_+3A_sigma">sigma</code></td>
<td>
<p>numeric, standard deviation of the Gaussian noise. By default sigma is estimated using the estim_sigma function with the MAD option</p>
</td></tr>
<tr><td><code id="ISA_+3A_delta">delta</code></td>
<td>
<p>numeric, probability of deletion of each cell of
the data matrix when considering Binomial noise. By default delta = 0.5</p>
</td></tr>
<tr><td><code id="ISA_+3A_noise">noise</code></td>
<td>
<p>noise model assumed for the data. By default &quot;Gaussian&quot;</p>
</td></tr>
<tr><td><code id="ISA_+3A_transformation">transformation</code></td>
<td>
<p>estimate a transformation of the original matrix; currently,
only correspondence analysis is available</p>
</td></tr>
<tr><td><code id="ISA_+3A_svd.cutoff">svd.cutoff</code></td>
<td>
<p>singular values smaller than this are treated as numerical error</p>
</td></tr>
<tr><td><code id="ISA_+3A_maxiter">maxiter</code></td>
<td>
<p>integer, maximum number of iterations of ISA</p>
</td></tr>
<tr><td><code id="ISA_+3A_threshold">threshold</code></td>
<td>
<p>for assessing convergence (difference between two successive iterations)</p>
</td></tr>
<tr><td><code id="ISA_+3A_nu">nu</code></td>
<td>
<p>integer, number of singular values to be computed - may be useful for very large matrices</p>
</td></tr>
<tr><td><code id="ISA_+3A_svdmethod">svdmethod</code></td>
<td>
<p>svd by default. irlba can be specified to use a fast svd method.
It can be useful to deal with large matrix. In this case, nu may be specified</p>
</td></tr>
<tr><td><code id="ISA_+3A_center">center</code></td>
<td>
<p>boolean, to center the data for the Gaussian noise model. By default &quot;TRUE&quot;</p>
</td></tr>
</table>


<h3>Details</h3>

<p>When the data are continuous and assumed to be drawn from a Gaussian distribution
with expectation of low-rank and variance sigma^2, then ISA performs a regularized SVD by
corrupting the data with an homoscedastic Gaussian noise (default choice) with variance sigma^2.
A value for sigma has to be provided. When sigma is not known, it can be estimated using the
function estim_sigma.  
</p>
<p>For count data, the subsampling scheme used to draw X can be considered as Binomial or Poisson (equivalent to
Binomial, delta = 0.5). ISA regularizes the data by corrupting the data with Poisson noise or by drawing
from a Binomial distribution of parameters X_ij and 1-delta divided by 1-delta. Thus it is necessary to give a value
for delta. When, the data are transformed with Correspondence Analysis (transfo = &quot;CA&quot;), this latter
noising scheme is also applied but on the data transformed with the CA weights.
The estimated low rank matrix is given in the output mu.hat. ISA automatically estimates the rank of the signal.
Its value is given in the output nb.eigen corresponding to the number of non-zero eigenvalues.
</p>


<h3>Value</h3>

<p>mu.hat the estimator of the signal
</p>
<p>nb.eigen the number of non-zero singular values
</p>
<p>low.rank the results of the SVD of the estimator; for correspondence analysis, returns
the SVD of the CA transform
</p>
<p>nb.iter number of iterations taken by the ISA algorithm
</p>


<h3>References</h3>

<p>Josse, J. &amp; Wager, S. (2016). Bootstrap-Based Regularization for Low-Rank Matrix Estimation. Journal of Machine Learning Research.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+estim_sigma">estim_sigma</a></code>
</p>
<p><code><a href="#topic+LRsim">LRsim</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>Xsim &lt;- LRsim(200, 500, 10, 4)
isa.gauss &lt;- ISA(Xsim$X, sigma = 1/(4*sqrt(200*500)))
isa.gauss$nb.eigen

# isa.bin &lt;- ISA(X, delta = 0.7, noise = "Binomial")

# A regularized Correspondence Analysis 
## Not run: library(FactoMineR)
 perfume &lt;-  read.table("http://factominer.free.fr/docs/perfume.txt",
 header=TRUE,sep="\t",row.names=1)
 rownames(perfume)[4] &lt;- "Cinema"
 isa.ca &lt;- ISA(perfume, delta = 0.5, noise = "Binomial", transformation = "CA")
 rownames(isa.ca$mu.hat) &lt;- rownames(perfume)
 colnames(isa.ca$mu.hat) &lt;- colnames(perfume)
 res.isa.ca &lt;- CA(isa.ca$mu.hat, graph = FALSE)
 plot(res.isa.ca, title = "Regularized CA", cex = 0.6, selectCol = "contrib 20")
 res.ca &lt;- CA(perfume, graph = FALSE)
 plot(res.ca, title = "CA", cex = 0.6, selectCol = "contrib 20")
## End(Not run)
</code></pre>

<hr>
<h2 id='LRsim'>Low Rank Simulation</h2><span id='topic+LRsim'></span>

<h3>Description</h3>

<p>This function simulates a data set as a low-rank signal corrupted by Gaussian noise.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LRsim(n, p, k, SNR)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="LRsim_+3A_n">n</code></td>
<td>
<p>integer, number of rows</p>
</td></tr>
<tr><td><code id="LRsim_+3A_p">p</code></td>
<td>
<p>integer, number of columns</p>
</td></tr>
<tr><td><code id="LRsim_+3A_k">k</code></td>
<td>
<p>integer, rank of the signal</p>
</td></tr>
<tr><td><code id="LRsim_+3A_snr">SNR</code></td>
<td>
<p>numeric, signal to noise ratio</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A data set of size n*p and of rank k is simulated. More precisely, it is simulated as follows: A SVD is performed on a n*p matrix generated
from a standard multivariate normal distribution. Then, the signal is computed using the first k singular vectors and singular values U_q D_q V_q'.
The signal is scaled in such a way that the variance of each column is 1 and then a Gaussian noise with variance sigma^2 is added.
The SNR is calculated as 1/ sigma sqrt(np).
</p>


<h3>Value</h3>

<p>X the simulated data
</p>
<p>mu the true signal
</p>
<p>sigma the standard deviation of the noise added to the signal
</p>


<h3>Examples</h3>

<pre><code class='language-R'> 
Xsim &lt;- LRsim(100, 30, 2, 2)
</code></pre>

<hr>
<h2 id='optishrink'>Optimal Shrinkage</h2><span id='topic+optishrink'></span>

<h3>Description</h3>

<p>This function estimates a low-rank signal from Gaussian noisy data using the Optimal Shrinker of the singular values. 
More precisely, in an asymptotic framework, the estimator which applies a non-linear transformation of the singular values is the closest to the underlying signal in term of mean squared error. 
Two asymptotic frameworks are considered: one where both the number of rows and the number of columns are fixed while the noise variance tends to zero (Low Noise) and one where both the number of rows and of columns tend to infinity (ASYMPT) while the rank of the matrix stays fixed. In this latter, an optimal shrinker is given according to different norm losses (Frobenius, Operator, Nuclear).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>optishrink(X, sigma = NA, center = "TRUE", method = c("ASYMPT", "LN"),
  loss = c("Frobenius", "Operator", "Nuclear"), k = NA)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="optishrink_+3A_x">X</code></td>
<td>
<p>a data frame or a matrix with numeric entries</p>
</td></tr>
<tr><td><code id="optishrink_+3A_sigma">sigma</code></td>
<td>
<p>integer, standard deviation of the Gaussian noise. By default sigma is estimated using the estim_sigma function</p>
</td></tr>
<tr><td><code id="optishrink_+3A_center">center</code></td>
<td>
<p>boolean, to center the data. By default &quot;TRUE&quot;</p>
</td></tr>
<tr><td><code id="optishrink_+3A_method">method</code></td>
<td>
<p>asymptotic framework used either low noise LN or ASYMPT. By default ASYMPT</p>
</td></tr>
<tr><td><code id="optishrink_+3A_loss">loss</code></td>
<td>
<p>by default Frobenius only if method = &quot;ASYMPT&quot;</p>
</td></tr>
<tr><td><code id="optishrink_+3A_k">k</code></td>
<td>
<p>integer, specifying the rank of the signal only if method = &quot;LN&quot;. By default k is estimated using the estim_ncp function of the FactoMineR package</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In the low noise (LN) asymptotic framework, the estimator applies the following transformation on the first k singular values dl  = dl *(dl^2-sigma^2)/dl^2. Thus, it requires providing both the rank k and a value for sigma.  Concerning the rank k, different methods are available in the litterature and if by default the user does not provide any value, we use of the function estim_ncp of the FactoMineR package with the option GCV (see ?estim_ncp).
The other asymptotic framework (ASYMPT) only requires providing sigma. optishrink automatically estimates the rank of the signal. Its value is given in the output nb.eigen corresponding to the number of non-zero eigenvalues. 
The estimated low rank matrix is given in the output mu.hat.
</p>


<h3>Value</h3>

<p>mu.hat the estimator of the signal
</p>
<p>nb.eigen the number of non-zero singular values
</p>
<p>singval the singular values of the estimator
</p>
<p>low.rank the results of the SVD of the estimator
</p>


<h3>References</h3>

<p>Gavish, M &amp; Donoho, D. L. (2014). Optimal Shrinkage of Singular Values.
</p>
<p>Verbanck, M., Husson, F. &amp; Josse, J. (2015). Regularised PCA to denoise and visualise data. Statistics &amp; Computing. 25 (2), 471-486
</p>


<h3>See Also</h3>

<p><code><a href="#topic+estim_sigma">estim_sigma</a></code>
</p>
<p><code><a href="#topic+LRsim">LRsim</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>Xsim &lt;- LRsim(200, 500, 10, 2)
opti.ln &lt;- optishrink(Xsim$X, method = "LN", k = 10)
opti.asympt &lt;- optishrink(Xsim$X, method = "ASYMPT")

Xsim &lt;- LRsim(200, 500, 100, 1)
truesigma &lt;- 1/(1*sqrt(200*500))
opti.asympt &lt;- optishrink(Xsim$X, method = "ASYMPT", sigma = truesigma)
opti.asympt$nb.eigen
</code></pre>

<hr>
<h2 id='Presidents'>
Contingency table with US Presidents speeches. 
</h2><span id='topic+Presidents'></span>

<h3>Description</h3>

<p>A data set on US presidents inaugural speeches.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(Presidents)
</code></pre>


<h3>Format</h3>

<p>A data frame with 13 rows and  836 columns. Rows represents the  US presidents
(from 1940 to 2009) and columns words used during their inaugural addresses. This is a contingency table.
</p>


<h3>Source</h3>

<p>http://www.presidency.ucsb.edu and http://www.usa-presidents.info/union/
DtmVic software (Lebart 2015) http://www.dtmvic.com/
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(Presidents)
isa.ca &lt;- ISA(Presidents, delta = 0.1, transformation = "CA")
rownames(isa.ca$mu.hat) &lt;- rownames(Presidents)
colnames(isa.ca$mu.hat) &lt;- colnames(Presidents)
res.isa.ca &lt;- CA(as.data.frame(isa.ca$mu.hat), graph = FALSE)
plot(res.isa.ca, title = "Regularized CA", cex = 0.8, selectRow = "contrib 40")
plot(res.isa.ca, title = "Regularized CA", cex = 0.6, invisible = "row" )

## End(Not run)
</code></pre>

<hr>
<h2 id='tumors'>
Brain tumors data.
</h2><span id='topic+tumors'></span>

<h3>Description</h3>

<p>43 brain tumors and 356 continuous variables corresponding to the
expression data and 1 categorical variable corresponding to the type of tumors (4 types). 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(tumors)</code></pre>


<h3>Format</h3>

<p>A data frame with 43 rows and 357 columns. Rows represent the tumors,
columns represent the expression and the type of tumor.
</p>


<h3>Details</h3>

<p>A genetic data frame.
</p>


<h3>Source</h3>

<p>M. de Tayrac, S. Le, M. Aubry, J. Mosser, and F. Husson. Simultaneous analysis of distinct omics data sets with integration of biological knowledge: Multiple factor analysis approach. BMC Genomics, 10(1):32, 2009.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(tumors)
## Not run: 
res.ada &lt;- adashrink(tumors[, -ncol(tumors)], method = "SURE")
res.hcpc &lt;- HCPC(as.data.frame(res.ada$mu.hat), graph=F, consol = FALSE)
plot.HCPC(res.hcpc, choice = "map", draw.tree = "FALSE")

## End(Not run)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
