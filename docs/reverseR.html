<!DOCTYPE html><html lang="en"><head><title>Help for package reverseR</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {reverseR}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#bootLM'><p>Nonparametric/Parametric bootstrap linear model</p></a></li>
<li><a href='#Influence+20plots'><p>Two diagnostic plots for checking p-value influencers</p></a></li>
<li><a href='#jackLM'><p>Jackknife linear model</p></a></li>
<li><a href='#lmExact'><p>Create random values that deliver linear regressions with exact parameters</p></a></li>
<li><a href='#lmInfl'><p>Checks and analyzes leave-one-out (LOO) p-values and a variety of influence measures in linear regression</p></a></li>
<li><a href='#pcomp'><p>Calculates linear regression p-values from a variety of robust regression methods</p></a></li>
<li><a href='#PNAS2015'><p>Small dataset from a 2015 PNAS paper</p></a></li>
<li><a href='#regionInfl'><p>Identify regions of significance reversal and influence measure threshold</p></a></li>
<li><a href='#rpLM'><p>Calculates the 'replication probability of significance' of an 'lm' object</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>LazyLoad:</td>
<td>yes</td>
</tr>
<tr>
<td>LazyData:</td>
<td>yes</td>
</tr>
<tr>
<td>Title:</td>
<td>Linear Regression Stability to Significance Reversal</td>
</tr>
<tr>
<td>Version:</td>
<td>0.2</td>
</tr>
<tr>
<td>Date:</td>
<td>2024-09-24</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Andrej-Nikolai Spiess &lt;draspiess@gmail.com&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Tests linear regressions for significance reversal through leave-one(multiple)-out.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>methods, boot, boot.pval, L1pack, quantreg, isotree,
robustbase</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-09-04 16:19:47 UTC; User</td>
</tr>
<tr>
<td>Author:</td>
<td>Andrej-Nikolai Spiess [aut, cre],
  Michal Burdukiewicz [aut],
  Stefan Roediger [aut]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-09-04 16:40:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='bootLM'>Nonparametric/Parametric bootstrap linear model</h2><span id='topic+bootLM'></span>

<h3>Description</h3>

<p>Nonparametric and parametric bootstrap (sampling cases, residuals or distributions with replacement) method for parameter estimation and confidence interval of a linear model. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bootLM(model, type = c("cases", "residuals", "residuals2", "parametric"), 
       R = 10000, alpha = 0.05, ret.models = FALSE) 
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="bootLM_+3A_model">model</code></td>
<td>
<p>an <code><a href="stats.html#topic+lm">lm</a></code> model.</p>
</td></tr>
<tr><td><code id="bootLM_+3A_type">type</code></td>
<td>
<p>what to bootstrap. See &quot;Details&quot;.</p>
</td></tr>
<tr><td><code id="bootLM_+3A_r">R</code></td>
<td>
<p>number of bootstrap samples.</p>
</td></tr>
<tr><td><code id="bootLM_+3A_alpha">alpha</code></td>
<td>
<p>the <code class="reqn">\alpha</code>-level to use as the threshold border.</p>
</td></tr>
<tr><td><code id="bootLM_+3A_ret.models">ret.models</code></td>
<td>
<p>logical. If <code>TRUE</code>, the <code>R</code> models are returned as a list.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If <code>type = "cases"</code>, for all (<code class="reqn">x_i, y_i</code>) datapoints, linear models are created by sampling <code>R</code> times - with replacement - from <code class="reqn">n \in \{1 \ldots N\}</code> and building models <code class="reqn">Y_n = X_n\beta + \varepsilon</code>. This is also known as the .632-bootstrap, because the samples will, on average, contain <code class="reqn">1 - e^{-1} = 0.632</code> unique elements.
If <code>type = "residuals"</code>, for all residuals (<code class="reqn">r_i = y_i - \hat{y}_i</code>), linear models are created by sampling <code>R</code> times - with replacement - from <code class="reqn">n \in (1 \ldots N)</code> and building models <code class="reqn">\hat{Y}_i + r_n = X_i\beta + \varepsilon</code>. If <code>type = "residuals2"</code> is selected, scaled and centered residuals <code class="reqn">r_n = \frac{r_i}{\sqrt{1 - h_{ii}}} - \bar{r}</code> according to Davison &amp; Hinkley are used. In the <code>"parametric"</code> bootstrap, <code class="reqn">n</code> values drawn from a normal distribution <code class="reqn">j_n \in \mathcal{N}(0, \sigma)</code>, where <code class="reqn">\sigma = \sqrt{\frac{\sum(r_i)^2}{n - p}}</code>, are added to the fitted values, and linear models are created <code class="reqn">\hat{Y}_i + j_n = X_i\beta + \varepsilon</code>.
Parameter estimates are obtained from each sampling, from which the average <code class="reqn">\overline{P_{n}}</code> and standard error <code class="reqn">\hat{\sigma}</code> is calculated as well as a quantile based confidence interval. <em>p</em>-values are calculated through inversion of the confidence interval. 
</p>


<h3>Value</h3>

<p>A dataframe containing the estimated coefficients, their standard error, lower an upper confidence values and <em>p</em>-values. If <code>ret.models = TRUE</code> a list with all <code>R</code> models is returned.
</p>


<h3>Author(s)</h3>

<p>Andrej-Nikolai Spiess
</p>


<h3>References</h3>

<p>An Introduction to the Bootstrap.<br />
Efron B, Tibshirani R.<br />
Chapman &amp; Hall (1993).
</p>
<p>The Bootstrap and Edgeworth Expansion.<br />
Hall P.<br /> 
Springer, New York (1992).
</p>
<p>Modern Statistics with R.<br />
Thulin M.<br />
Eos Chasma Press, Uppsala (2021).
</p>
<p>Bootstrap methods and their application.<br />
Davison AC, Hinkley DV.<br />
Cambridge University Press (1997).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Example with single influencer (#18) and insignificant model (p = 0.115),
## using case bootstrap.
set.seed(123)
a &lt;- 1:20
b &lt;- 5 + 0.08 * a + rnorm(20, 0, 1)
LM &lt;- lm(b ~ a)
bootLM(LM, R = 100)

## using residuals bootstrap.
bootLM(LM, R = 100, type = "residuals")
</code></pre>

<hr>
<h2 id='Influence+20plots'>Two diagnostic plots for checking p-value influencers</h2><span id='topic+inflPlot'></span><span id='topic+pvalPlot'></span>

<h3>Description</h3>

<p>Two different plot types that visualize <em>p</em>-value influencers.<br />
</p>
<p>1. <code>inflPlot</code>: plots the linear regression, marks the reverser(s) in darkred and displays trend lines for the full and leave-reversers-out data set (black and darkred, respectively).<br />
2. <code>pvalPlot</code>: plots the <em>p</em>-values for each leave-one-out data point and displays the (log) <em>p</em>-values as an index plot with reverser points in darkred, together with the <code class="reqn">\alpha</code>-border as defined in <code><a href="#topic+lmInfl">lmInfl</a></code> and the original models' <em>p</em>-value.<br />
</p>


<h3>Usage</h3>

<pre><code class='language-R'>inflPlot(infl, measure, ...) 
pvalPlot(infl, ...) 
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Influence+2B20plots_+3A_infl">infl</code></td>
<td>
<p>an object obtained from <code><a href="#topic+lmInfl">lmInfl</a></code>.</p>
</td></tr>
<tr><td><code id="Influence+2B20plots_+3A_measure">measure</code></td>
<td>
<p>which influence measure to use, see 'Details'.</p>
</td></tr>
<tr><td><code id="Influence+2B20plots_+3A_...">...</code></td>
<td>
<p>other plotting parameters.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The influence <code>measure</code>'s to use are those listed in <code><a href="#topic+lmInfl">lmInfl</a></code>, with the following syntax:<br />
<code>"dfb.Slope", "dffit", "cov.r", "cook.d", "hat",  "sR", "hadi", "cdr", "Si"</code>.
</p>


<h3>Value</h3>

<p>The corresponding plot.
</p>


<h3>Author(s)</h3>

<p>Andrej-Nikolai Spiess
</p>


<h3>References</h3>

<p>Regression diagnostics: Identifying influential data and sources of collinearity.<br />
Belsley DA, Kuh E, Welsch RE.<br />
John Wiley, New York (2004).
</p>
<p>Applied Regression Analysis: A Research Tool.<br />
Rawlings JO, Pantula SG, Dickey DA.<br />
Springer; 2nd Corrected ed. 1998. Corr. 2nd printing 2001.
</p>
<p>Applied Regression Analysis and Generalized Linear Models.<br />
Fox J.<br />
SAGE Publishing, 3rd ed, 2016.
</p>
<p>Residuals and Influence in Regression.<br />
Cook RD &amp; Weisberg S.<br />
Chapman &amp; Hall, 1st ed, New York, USA (1982).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(123)
a &lt;- 1:20
b &lt;- 5 + 0.08 * a + rnorm(20, 0, 1)
LM1 &lt;- lm(b ~ a)
res1 &lt;- lmInfl(LM1) 
inflPlot(res1)
pvalPlot(res1)
</code></pre>

<hr>
<h2 id='jackLM'>Jackknife linear model</h2><span id='topic+jackLM'></span>

<h3>Description</h3>

<p>Jackknife (Leave-One-Out) method for parameter estimation and confidence interval of a linear model, according to Quenouille (1956). 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>jackLM(model, alpha = 0.05) 
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="jackLM_+3A_model">model</code></td>
<td>
<p>an <code><a href="stats.html#topic+lm">lm</a></code> model.</p>
</td></tr>
<tr><td><code id="jackLM_+3A_alpha">alpha</code></td>
<td>
<p>the <code class="reqn">\alpha</code>-level to use as the threshold border.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For all (<code class="reqn">x_i, y_i</code>) datapoints, a linear model is created by leaving out each entry successively, <code class="reqn">Y_{-i} = X_{-i}\beta + \varepsilon</code>. Pseudovalues from obtained and original coefficients are then created, <code class="reqn">P_{-i} = (N \cdot \beta) - ((N - 1) *  \beta_{-i})</code>, from which the average <code class="reqn">\overline{P_{-i}}</code> and standard error <code class="reqn">\frac{\sigma}{\sqrt N}</code> is calculated to obtain the classical confidence interval <code class="reqn">\overline{X}_n \pm t_{\alpha,\nu}\frac{S_n}{\sqrt{n}}</code>. 
</p>


<h3>Value</h3>

<p>A dataframe containg the estimated coefficients, their standard error, lower an upper confidence values and <em>p</em>-values.
</p>


<h3>Author(s)</h3>

<p>Andrej-Nikolai Spiess
</p>


<h3>References</h3>

<p>Notes on bias in estimation.<br />
Quenouille MH.<br />
<em>Biometrika</em>, <b>43</b>, 1956, 353-36l.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Example with single influencer (#18) and insignificant model (p = 0.115).
## Jackknife estimates are robust w.r.t. outlier #18.
set.seed(123)
a &lt;- 1:20
b &lt;- 5 + 0.08 * a + rnorm(20, 0, 1)
LM1 &lt;- lm(b ~ a)
jackLM(LM1)
</code></pre>

<hr>
<h2 id='lmExact'>Create random values that deliver linear regressions with exact parameters</h2><span id='topic+lmExact'></span>

<h3>Description</h3>

<p>Takes self-supplied x/y values or x/random values and transforms these as to deliver linear regressions <code class="reqn">y = \beta_0 + \beta_1x + \varepsilon</code> (with potential replicates) with either<br />
</p>
<p><b>1)</b> exact slope <code class="reqn">\beta_1</code> and intercept <code class="reqn">\beta_0</code>,<br />
<b>2)</b> exact <em>p</em>-value and intercept <code class="reqn">\beta_0</code>, or<br />
<b>3)</b> exact <code class="reqn">R^2</code> and intercept <code class="reqn">\beta_0</code>.<br />
</p>
<p>Intended for testing and education, not for cheating ! ;-)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lmExact(x = 1:20, y = NULL, ny = 1, intercept = 0, slope = 0.1, error = 0.1, 
        seed = NULL, pval = NULL, rsq = NULL, plot = TRUE, verbose = FALSE, ...) 
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="lmExact_+3A_x">x</code></td>
<td>
<p>the predictor values.</p>
</td></tr>
<tr><td><code id="lmExact_+3A_y">y</code></td>
<td>
<p><code>NULL</code>. A possible vector of <code class="reqn">y</code> values with <code>length(x)</code>.</p>
</td></tr>
<tr><td><code id="lmExact_+3A_ny">ny</code></td>
<td>
<p>the number of replicate response values per predictor value.</p>
</td></tr>
<tr><td><code id="lmExact_+3A_intercept">intercept</code></td>
<td>
<p>the desired intercept <code class="reqn">\beta_0</code>.</p>
</td></tr>
<tr><td><code id="lmExact_+3A_slope">slope</code></td>
<td>
<p>the desired slope <code class="reqn">\beta_1</code>.</p>
</td></tr>
<tr><td><code id="lmExact_+3A_error">error</code></td>
<td>
<p>if a single value, the standard deviation <code class="reqn">\sigma</code> for sampling from a normal distribution, or a user-supplied vector of length <code>x</code> with random deviates.</p>
</td></tr>
<tr><td><code id="lmExact_+3A_seed">seed</code></td>
<td>
<p>optional. The random generator seed for reproducibility.</p>
</td></tr>
<tr><td><code id="lmExact_+3A_pval">pval</code></td>
<td>
<p>the desired <em>p</em>-value of the slope.</p>
</td></tr>
<tr><td><code id="lmExact_+3A_rsq">rsq</code></td>
<td>
<p>the desired <code class="reqn">R^2</code>.</p>
</td></tr>
<tr><td><code id="lmExact_+3A_plot">plot</code></td>
<td>
<p>logical. If <code>TRUE</code>, the linear regression is plotted.</p>
</td></tr>
<tr><td><code id="lmExact_+3A_verbose">verbose</code></td>
<td>
<p>logical. If <code>TRUE</code>, a summary is printed to the console.</p>
</td></tr>
<tr><td><code id="lmExact_+3A_...">...</code></td>
<td>
<p>other arguments to <code><a href="stats.html#topic+lm">lm</a></code> or <code><a href="base.html#topic+plot">plot</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For case <b>1)</b>, the <code>error</code> values are added to the exact <code class="reqn">(x_i, \beta_0 + \beta_1 x_i)</code> values, the linear model <code class="reqn">y_i = \beta_0 + \beta_1 x_i + \varepsilon</code> is fit, and the residuals <code class="reqn">y_i - \hat{y_i}</code> are re-added to <code class="reqn">(x_i, \beta_0 + \beta_1 x_i)</code>.<br />
For case <b>2)</b>, the same as in <b>1)</b> is conducted, however the slope delivering the desired <em>p</em>-value is found by an optimizing algorithm.<br />
Finally, for case <b>3)</b>, a QR reconstruction, rescaling and refitting is conducted, using the code found under 'References'.<br />
</p>
<p>If <code>y</code> is supplied, changes in slope, intercept and <em>p</em>-value will deliver the sames residuals as the linear regression through <code>x</code> and <code>y</code>. A different <code class="reqn">R^2</code> will change the response value structure, however.
</p>


<h3>Value</h3>

<p>A list with the following items:<br />
</p>
<table role = "presentation">
<tr><td><code>lm</code></td>
<td>
<p>the linear model of class <code>lm</code>.</p>
</td></tr> 
<tr><td><code>x</code></td>
<td>
<p>the predictor values.</p>
</td></tr>
<tr><td><code>y</code></td>
<td>
<p>the (random) response values.</p>
</td></tr>
<tr><td><code>summary</code></td>
<td>
<p>the model summary for quick checking of obtained parameters.</p>
</td></tr>
</table>
<p>Using both <code>x</code> and <code>y</code> will give a linear regression with the desired parameter values when refitted.
</p>


<h3>Author(s)</h3>

<p>Andrej-Nikolai Spiess
</p>


<h3>References</h3>

<p>For method <b>3</b>):<br />
http://stats.stackexchange.com/questions/15011/generate-a-random-variable-with-a-defined-correlation-to-an-existing-variable.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## No replicates, intercept = 3, slope = 0.2, sigma = 2, n = 20.
res1 &lt;- lmExact(x = 1:20, ny = 1, intercept = 3, slope = 2, error = 2)

## Same as above, but with 3 replicates, sigma = 1,  n = 20.
res2 &lt;- lmExact(x = 1:20, ny = 3, intercept = 3, slope = 2, error = 1)

## No replicates, intercept = 2 and p-value = 0.025, sigma = 3, n = 50.
## =&gt; slope = 0.063
res3 &lt;- lmExact(x = 1:50, ny = 1, intercept = 2, pval = 0.025, error = 3)

## 5 replicates, intercept = 1, R-square = 0.85, sigma = 2, n = 10.
## =&gt; slope = 0.117
res4 &lt;- lmExact(x = 1:10, ny = 5, intercept = 1, rsq = 0.85, error = 2)

## Heteroscedastic (magnitude-dependent) noise.
error &lt;- sapply(1:20, function(x) rnorm(3, 0, x/10))
res5 &lt;- lmExact(x = 1:20, ny = 3, intercept = 1, slope = 0.2,
                error = error)
                
## Supply own x/y values, residuals are similar to an
## initial linear regression.
X &lt;- c(1.05, 3, 5.2, 7.5, 10.2, 11.7)
set.seed(123)
Y &lt;- 0.5 + 2 * X + rnorm(6, 0, 2)
res6 &lt;- lmExact(x = X, y = Y, intercept = 1, slope = 0.2)
all.equal(residuals(lm(Y ~ X)), residuals(res6$lm))
</code></pre>

<hr>
<h2 id='lmInfl'>Checks and analyzes leave-one-out (LOO) p-values and a variety of influence measures in linear regression</h2><span id='topic+lmInfl'></span>

<h3>Description</h3>

<p>This function calculates leave-one-out (LOO) <em>p</em>-values for all data points and identifies those resulting in &quot;significance reversal&quot;, i.e. in the <em>p</em>-value of the model's slope traversing the user-defined <code class="reqn">\alpha</code>-level. It also extends the classical influence measures from <code><a href="stats.html#topic+influence.measures">influence.measures</a></code> with a few newer ones (<em>e.g</em>, 'Hadi's measure', 'Coefficient of determination ratio' and 'Pena's Si') within an output format where each outlier is marked when exceeding the measure's specific threshold, as defined in the literature. Belsley, Kuh &amp; Welsch's <em>dfstat</em> criterion is also included. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lmInfl(model, alpha = 0.05, cutoff = c("BKW", "R"), verbose = TRUE, ...) 
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="lmInfl_+3A_model">model</code></td>
<td>
<p>the linear model of class <code><a href="stats.html#topic+lm">lm</a></code>.</p>
</td></tr>
<tr><td><code id="lmInfl_+3A_alpha">alpha</code></td>
<td>
<p>the <code class="reqn">\alpha</code>-level to use as the threshold border.</p>
</td></tr>
<tr><td><code id="lmInfl_+3A_cutoff">cutoff</code></td>
<td>
<p>use the cutoff-values from <code>B</code>elsley, <code>K</code>uh &amp; <code>W</code>elsch or the <code>R</code>-internal ones. See 'Details'.</p>
</td></tr>
<tr><td><code id="lmInfl_+3A_verbose">verbose</code></td>
<td>
<p>logical. If <code>TRUE</code>, results are displayed on the console.</p>
</td></tr>
<tr><td><code id="lmInfl_+3A_...">...</code></td>
<td>
<p>other arguments to <code><a href="stats.html#topic+lm">lm</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The algorithm<br />
1) calculates the <em>p</em>-value of the full model (all points),<br />
2) calculates a LOO-<em>p</em>-value for each point removed,<br />
3) checks for significance reversal in all data points and<br />
4) returns all models as well as classical <code><a href="stats.html#topic+influence.measures">influence.measures</a></code> with LOO-<em>p</em>-values, <code class="reqn">\Delta</code><em>p</em>-values, slopes and standard errors attached.<br />
</p>
<p>The idea of <em>p</em>-value influencers was first introduced by Belsley, Kuh &amp; Welsch, and described as an influence measure pertaining directly to the change in <em>t</em>-statistics, that will &quot;show whether the conclusions of hypothesis testing would be affected&quot;, termed <b>dfstat</b> in [1, 2, 3] or <b>dfstud</b> in [4]:
</p>
<p style="text-align: center;"><code class="reqn">\rm{dfstat}_{ij} \equiv \frac{\hat{\beta}_j}{s\sqrt{(X'X)^{-1}_{jj}}}-\frac{\hat{\beta}_{j(i)}}{s_{(i)}\sqrt{(X'_{(i)}X_{(i)})^{-1}_{jj}}}</code>
</p>

<p>where <code class="reqn">\hat{\beta}_j</code> is the <em>j</em>-th estimate, <em>s</em> is the residual standard error, <em>X</em> is the design matrix and (<em>i</em>) denotes the <em>i</em>-th observation deleted.<br />
<b>dfstat</b>, which for the regression's slope <code class="reqn">\beta_1</code> is the difference of <em>t</em>-statistics 
</p>
<p style="text-align: center;"><code class="reqn">\Delta t = t_{\beta1} - t_{\beta1(i)} = \frac{\beta_1}{\rm{s.e.(\beta_1)}} - \frac{\beta_1(i)}{\rm{s.e.(\beta_1(i)})}</code>
</p>

<p>is inextricably linked to the changes in <em>p</em>-value <code class="reqn">\Delta p</code>, calculated from
</p>
<p style="text-align: center;"><code class="reqn">\Delta p = p_{\beta1} - p_{\beta1(i)} = 2\left(1-P_t(t_{\beta1}, \nu)\right) - 2\left(1-P_t(t_{\beta1(i)} , \nu-1)\right)</code>
</p>

<p>where <code class="reqn">P_t</code> is the Student's <em>t</em> cumulative distribution function with <code class="reqn">\nu</code> degrees of freedom, and where significance reversal is attained when <code class="reqn">\alpha \in [p_{\beta1}, p_{\beta1(i)}]</code>.
Interestingly, the seemingly mandatory check of the influence of single data points on statistical inference is living in oblivion: apart from [1-4], there is, to the best of our knowledge, no reference to <b>dfstat</b> or <code class="reqn">\Delta p</code> in current literature on influence measures.
</p>
<p>Cut-off values for the different influence measures are per default (<code>cutoff = "BKW"</code>) those defined in Belsley, Kuh &amp; Welsch (1980) and additional literature.<br /><br />
<b>dfbeta slope</b>: <code class="reqn">| \Delta\beta1_i | &gt; 2/\sqrt{n}</code> (page 28)<br />
<b>dffits</b>: <code class="reqn">| \mathrm{dffits}_i | &gt; 2\sqrt{2/n}</code> (page 28)<br />
<b>covratio</b>: <code class="reqn">|\mathrm{covr}_i - 1| &gt; 3k/n</code> (page 23)<br />
<b>Cook's D</b>: <code class="reqn">D_i &gt; Q_F(0.5, k, n - k)</code> (Cook &amp; Weisberg, 1982)<br />
<b>leverage</b>: <code class="reqn">h_{ii} &gt; 2k/n</code> (page 17)<br />
<b>studentized residual</b>: <code class="reqn">t_i &gt; Q_t(0.975, n - k - 1)</code> (page 20)<br />
</p>
<p>If (<code>cutoff = "R"</code>), the criteria from <code><a href="stats.html#topic+influence.measures">influence.measures</a></code> are employed:<br /><br />
<b>dfbeta slope</b>: <code class="reqn">| \Delta\beta1_i | &gt; 1</code><br />
<b>dffits</b>: <code class="reqn">| \mathrm{dffits}_i | &gt; 3\sqrt{(k/(n - k))}</code><br />
<b>covratio</b>: <code class="reqn">|1 - \mathrm{covr}_i| &gt; 3k/(n - k)</code><br />
<b>Cook's D</b>: <code class="reqn">D_i &gt; Q_F(0.5, k, n - k)</code><br />
<b>leverage</b>: <code class="reqn">h_{ii} &gt; 3k/n</code><br /> 
</p>
<p>The influence output also includes the following more &quot;recent&quot; measures:<br />
<b>Hadi's measure</b> (column &quot;hadi&quot;):
</p>
<p style="text-align: center;"><code class="reqn">H_i^2 = \frac{h_{ii}}{1 - h_{ii}} + \frac{p}{1 - h_{ii}}\frac{d_i^2}{(1-d_i^2)}</code>
</p>

<p>where <code class="reqn">h_{ii}</code> are the diagonals of the hat matrix (leverages), <code class="reqn">p = 2</code> in univariate linear regression and <code class="reqn">d_i = e_i/\sqrt{\rm{SSE}}</code>, and threshold value <code class="reqn">\mathrm{Med}(H_i^2) + 2 \cdot \mathrm{MAD}(H_i^2)</code>.
</p>
<p><b>Coefficient of Determination Ratio</b> (column &quot;cdr&quot;):
</p>
<p style="text-align: center;"><code class="reqn">\mathrm{CDR}_i = \frac{R_{(i)}^2}{R^2}</code>
</p>

<p>with <code class="reqn">R_{(i)}^2</code> being the coefficient of determination without value <em>i</em>, and threshold 
</p>
<p style="text-align: center;"><code class="reqn">\frac{B_{\alpha,p/2,(n-p-2)/2}}{B_{\alpha,p/2,(n-p-1)/2}}</code>
</p>

<p><b>Pena's Si</b> (column &quot;Si&quot;):
</p>
<p style="text-align: center;"><code class="reqn">S_i = \frac{\mathbf{s}'_i\mathbf{s}_i}{p\widehat{\mathrm{var}}(\hat{y}_i)}</code>
</p>

<p>where <code class="reqn">\mathbf{s_i}</code> is the vector of each fitted value from the original model, <code class="reqn">\hat{y}_i</code>, subtracted with all fitted values after 1-deletion, <code class="reqn">\hat{y}_i - \hat{y}_{i(-1)}, \cdots, \hat{y}_i - \hat{y}_{i(-n)}</code>, <code class="reqn">p</code> = number of parameters, and <code class="reqn">\widehat{\mathrm{var}}(\hat{y}_i) = s^2h_{ii}</code>, <code class="reqn">s^2 = (\mathbf{e}'\mathbf{e})/(n - p)</code>, <code class="reqn">\mathbf{e}</code> being the residuals. In this package, a cutoff value of 0.9 is used, as the published criterion of <code class="reqn">|\mathbf{S_i} - \mathrm{Med}(\mathbf{S})| \ge 4.5\mathrm{MAD}(\mathbf{S})</code> seemed too conservative. Results from this function were verified by Prof. Daniel Pena through personal communication.
</p>


<h3>Value</h3>

<p>A list with the following items:<br />
</p>
<table role = "presentation">
<tr><td><code>origModel</code></td>
<td>
<p>the original model with all data points.</p>
</td></tr> 
<tr><td><code>finalModels</code></td>
<td>
<p>a list of final models with the influencer(s) removed.</p>
</td></tr>
<tr><td><code>infl</code></td>
<td>
<p>a matrix with the original data, classical <code><a href="stats.html#topic+influence.measures">influence.measures</a></code>, studentized residuals, leverages, dfstat, LOO-<em>p</em>-values, LOO-slopes/intercepts and their <code class="reqn">\Delta</code>'s, LOO-standard errors and <code class="reqn">R^2</code>s. Influence measures that exceed their specific threshold - see <code><a href="#topic+inflPlot">inflPlot</a></code> - will be marked with asterisks.</p>
</td></tr>
<tr><td><code>raw</code></td>
<td>
<p>same as <code>infl</code>, but with pure numeric data.</p>
</td></tr>
<tr><td><code>sel</code></td>
<td>
<p>a vector with the influencers' indices.</p>
</td></tr>
<tr><td><code>alpha</code></td>
<td>
<p>the selected <code class="reqn">\alpha</code>-level.</p>
</td></tr>
<tr><td><code>origP</code></td>
<td>
<p>the original model's <em>p</em>-value.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Andrej-Nikolai Spiess
</p>


<h3>References</h3>

<p><b>For dfstat / dfstud :</b><br />
Regression diagnostics: Identifying influential data and sources of collinearity.<br />
Belsley DA, Kuh E, Welsch RE.<br />
John Wiley, New York, USA (2004).
</p>
<p>Econometrics, 5ed.<br />
Baltagi B.<br />
Springer-Verlag Berlin, Germany (2011).
</p>
<p>Growth regressions and what the textbooks don't tell you.<br />
Temple J.<br />
<em>Bull Econom Res</em>, <b>52</b>, 2000, 181-205.
</p>
<p>Robust Regression and Outlier Detection.<br />
Rousseeuw PJ &amp; Leroy AM.<br />
John Wiley &amp; Sons, New York, NY (1987).<br />
</p>
<p><b>Hadi's measure:</b><br />
A new measure of overall potential influence in linear regression.<br />
Hadi AS.<br />
<em>Comp Stat &amp; Data Anal</em>, <b>14</b>, 1992, 1-27.<br />
</p>
<p><b>Coefficient of determination ratio:</b><br />
On the detection of influential outliers in linear regression analysis.<br />
Zakaria A, Howard NK, Nkansah BK.<br />
<em>Am J Theor Appl Stat</em>, <b>3</b>, 2014, 100-106.
</p>
<p>On the Coefficient of Determination Ratio for Detecting Influential Outliers in Linear Regression Analysis.<br />
Zakaria A, Gordor BK, Nkansah BK.<br />
<em>Am J Theor Appl Stat</em>, <b>11</b>, 2022, 27-35.<br />
</p>
<p><b>Pena's measure:</b><br />
A New Statistic for Influence in Linear Regression.<br />
Pena D.<br />
<em>Technometrics</em>, <b>47</b>, 2005, 1-12.<br />
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Example #1 with single influencer and significant model (p = 0.0089).
## Removal of #21 results in p = 0.115!
set.seed(123)
a &lt;- 1:20
b &lt;- 5 + 0.08 * a + rnorm(20, 0, 1)
a &lt;- c(a, 25); b &lt;- c(b, 10)
LM1 &lt;- lm(b ~ a)
lmInfl(LM1) 

## Example #2 with single influencer and insignificant model (p = 0.115).
## Removal of #18 results in p = 0.0227!
set.seed(123)
a &lt;- 1:20
b &lt;- 5 + 0.08 * a + rnorm(20, 0, 1)
LM2 &lt;- lm(b ~ a)
lmInfl(LM2) 

## Example #3 with multiple influencers and significant model (p = 0.0269).
## Removal of #2, #17, #18 or #20 results in crossing p = 0.05!
set.seed(125)
a &lt;- 1:20
b &lt;- 5 + 0.08 * a + rnorm(20, 0, 1)
LM3 &lt;- lm(b ~ a)
lmInfl(LM3) 

## Large Example #4 with top 10 influencers and significant model (p = 6.72E-8).
## Not possible to achieve a crossing of alpha with any point despite strong noise.
set.seed(123)
a &lt;- 1:100
b &lt;- 5 + 0.08 * a + rnorm(100, 0, 5)
LM4 &lt;- lm(b ~ a)
lmInfl(LM4) 
</code></pre>

<hr>
<h2 id='pcomp'>Calculates linear regression p-values from a variety of robust regression methods</h2><span id='topic+pcomp'></span>

<h3>Description</h3>

<p>This function calculates <em>p</em>-values from a variety of methods, specifically:<br />
1) standard linear model<br />
2) standard linear model with highest <em>p</em>-influencer removed<br />
3) robust regression with MM-estimators<br />
4) Theil-Sen regression<br />
5) least absolute deviations regression<br />
6) quantile regression<br />
7) weighted regression with isolation forest scores as inverse weights<br />
8) bootstrap linear model, see <code><a href="#topic+bootLM">bootLM</a></code><br />
9) jackknife linear model, see <code><a href="#topic+jackLM">jackLM</a></code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pcomp(x, y = NULL, R = 1000, alpha = 0.05, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="pcomp_+3A_x">x</code></td>
<td>
<p>either a linear model of class <code><a href="stats.html#topic+lm">lm</a></code> or the regressions <em>x</em>-values.</p>
</td></tr>
<tr><td><code id="pcomp_+3A_y">y</code></td>
<td>
<p>the optional <em>y</em>-values.</p>
</td></tr>
<tr><td><code id="pcomp_+3A_r">R</code></td>
<td>
<p>the number of bootstrap resamples, see <code><a href="#topic+bootLM">bootLM</a></code>.</p>
</td></tr>
<tr><td><code id="pcomp_+3A_alpha">alpha</code></td>
<td>
<p>the <code class="reqn">\alpha</code>-level for <code><a href="#topic+lmInfl">lmInfl</a></code>.</p>
</td></tr>
<tr><td><code id="pcomp_+3A_...">...</code></td>
<td>
<p>further arguments to be passed to downstream methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is meant to provide a swift overview on the sensitivity of the <em>p</em>-values to different (mostly robust) linear regression methods, which correlates to a large extent with the presence of influential / outlying data points, see 'Examples'.
</p>


<h3>Value</h3>

<p>A vector of <em>p</em>-values from the above mentioned ten methods, in that order.
</p>


<h3>Author(s)</h3>

<p>Andrej-Nikolai Spiess
</p>


<h3>References</h3>

<p>Robust Regression and Outlier Detection.<br />
Rousseeuw PJ &amp; Leroy AM.<br />
1ed (1987), Wiley (NJ, USA).
</p>
<p>A rank-invariant method of linear and polynomial regression analysis.<br />
Theil H.<br /> 
<em>I. Nederl. Akad. Wetensch. Proc</em>, <b>53</b>, 1950, 386-392.
</p>
<p>Estimates of the regression coefficient based on Kendall's tau.<br />
Sen PK.<br />
<em>J Am Stat Assoc</em>, <b>63</b>, 1968, 1379-1389.
</p>
<p>Least absolute deviations estimation via the EM algorithm.<br />
Phillips RF.<br />
<em>Statistics and Computing</em>, <b>12</b>, 2002, 281-285. 
</p>
<p>Quantile Regression.<br />
Koenker R.<br />
Cambridge University Press, Cambridge, New York (2005).
</p>
<p>Isolation-based anomaly detection.<br />
Liu FT, Ting KM, Zhou ZH.<br />
<em>ACM Transactions on Knowledge Discovery from Data</em>, <b>6.1</b>, 2012, 3.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Example with influencer
## =&gt; a few methods indicate significant 
## downward drop of the p-value
set.seed(123)
a &lt;- 1:20
b &lt;- 5 + 0.08 * a + rnorm(20, 0, 1)
pcomp(a, b) 
</code></pre>

<hr>
<h2 id='PNAS2015'>Small dataset from a 2015 PNAS paper</h2><span id='topic+PNAS2015'></span>

<h3>Description</h3>

<p>The data was acquired by digitization of a graph from a 2015 PNAS paper. Contains three datapoints that exert significance reversal.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(PNAS2015) 
</code></pre>


<h3>Author(s)</h3>

<p>Andrej-Nikolai Spiess
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## See examples in 'lmInfl' and 'lmThresh'.
LM &lt;- lm(y ~ x, data = PNAS2015)
lmInfl(LM)
</code></pre>

<hr>
<h2 id='regionInfl'>Identify regions of significance reversal and influence measure threshold</h2><span id='topic+regionInfl'></span>

<h3>Description</h3>

<p>Identifies regions of an (univariate) linear model in which a future data point would result in either<br />
a) significance reversal, or<br />
b) any selected influence measure as given in <code>crit</code> exceed its threshold value.<br />
This is intended mainly for visual/didactical purposes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>regionInfl(model, div.x = 20, div.y = 20, grid = TRUE, pred.int = TRUE,
       crit = c("P", "dfb.Slope", "dffit", "cov.r", "cook.d", "hat", "hadi",
       "sR", "cdr", "Si"), cex.grid = 0.5, alpha = 0.05, xlim = NULL, ylim = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="regionInfl_+3A_model">model</code></td>
<td>
<p>the linear model of class <code><a href="stats.html#topic+lm">lm</a></code>.</p>
</td></tr>
<tr><td><code id="regionInfl_+3A_div.x">div.x</code></td>
<td>
<p>the number of grid division for the <em>x</em>-axis.</p>
</td></tr>
<tr><td><code id="regionInfl_+3A_div.y">div.y</code></td>
<td>
<p>the number of grid division for the <em>y</em>-axis.</p>
</td></tr>
<tr><td><code id="regionInfl_+3A_grid">grid</code></td>
<td>
<p>logical. Show the grid lines on the plot or not.</p>
</td></tr>
<tr><td><code id="regionInfl_+3A_pred.int">pred.int</code></td>
<td>
<p>logical. Show the 95% prediction interval on the plot or not.</p>
</td></tr>
<tr><td><code id="regionInfl_+3A_crit">crit</code></td>
<td>
<p>the criterion to use. Either <code>"P"</code> for significance reversal or any of the influence measures given there.</p>
</td></tr>
<tr><td><code id="regionInfl_+3A_cex.grid">cex.grid</code></td>
<td>
<p>size of the grid points.</p>
</td></tr>
<tr><td><code id="regionInfl_+3A_alpha">alpha</code></td>
<td>
<p>the <code class="reqn">\alpha</code>-level to be set as threshold.</p>
</td></tr>
<tr><td><code id="regionInfl_+3A_xlim">xlim</code></td>
<td>
<p>similar to <code><a href="graphics.html#topic+xlim">xlim</a></code>, a 2-element vector for the <em>x</em>-axis limits, overrides <code>fac.x</code>.</p>
</td></tr>
<tr><td><code id="regionInfl_+3A_ylim">ylim</code></td>
<td>
<p>similar to <code><a href="graphics.html#topic+ylim">ylim</a></code>, a 2-element vector for the <em>y</em>-axis limits, overrides <code>fac.y</code>.</p>
</td></tr>
<tr><td><code id="regionInfl_+3A_...">...</code></td>
<td>
<p>other parameters to be supplied to <code><a href="base.html#topic+plot">plot</a></code> or <code><a href="#topic+lmInfl">lmInfl</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For a given linear model <code class="reqn">y_i = \beta_0 + \beta_1 x_i + \varepsilon</code>, each <code class="reqn">(a, b)</code> pair from a grid of values <code class="reqn">(a_1 \ldots a_j, b_1 \ldots b_k)</code> is added to the data, and an updated model <code class="reqn">(y_i, b_k) = \beta_0 + \beta_1 (x_i, a_j) + \varepsilon</code> is created. If the updated model's <code class="reqn">p \leq \alpha</code> or any of the influence measures does not exceed its published threshold, it is plotted in green, otherwise in orange. If <code>outlier = TRUE</code>, a possible reverser is eliminated prior to analysis but visualized in the plot.  
</p>


<h3>Value</h3>

<p>A plot with the regions marked in orange or green, and the grid matrix (<code>grid</code>) including the criterion outcome in 1 (green) or 0 (orange). 
</p>


<h3>Author(s)</h3>

<p>Andrej-Nikolai Spiess
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Model with p = 0.014 
set.seed(7)
N &lt;- 20
x &lt;- runif(N, 1, 100)
y &lt;- 0.05 * x + rnorm(N, 0, 2)
LM1 &lt;- lm(y ~ x)
summary(LM1)
regionInfl(LM1, crit = "P", div.x = 20, div.y = 20, cex.grid = 1, 
           xlim = c(-20, 120), ylim = c(-5, 10))
</code></pre>

<hr>
<h2 id='rpLM'>Calculates the 'replication probability of significance' of an 'lm' object</h2><span id='topic+rpLM'></span>

<h3>Description</h3>

<p>This function uses a bootstrap approach to calculate the <em>replication probability</em> of significance, which answers the question &quot;if we repeat this linear regression under identical conditions (similar sample size, similar residual variance), what is the probability of observing significance (or non-significance) similar to the original data?&quot;. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rpLM(model, alpha = 0.05, R = 10000, plot = TRUE, verbose = TRUE, ...) 
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rpLM_+3A_model">model</code></td>
<td>
<p>a linear model of class <code><a href="stats.html#topic+lm">lm</a></code>.</p>
</td></tr>
<tr><td><code id="rpLM_+3A_alpha">alpha</code></td>
<td>
<p>the <code class="reqn">\alpha</code>-level to use as the threshold border.</p>
</td></tr>
<tr><td><code id="rpLM_+3A_r">R</code></td>
<td>
<p>the number of bootstrap resamples, see <code><a href="#topic+bootLM">bootLM</a></code>.</p>
</td></tr>
<tr><td><code id="rpLM_+3A_plot">plot</code></td>
<td>
<p>logical. If <code>TRUE</code>, a stripchart of the bootstrap <em>P</em>-values, the original <em>P</em>-value and the <code class="reqn">\alpha</code>-level is displayed.</p>
</td></tr>
<tr><td><code id="rpLM_+3A_verbose">verbose</code></td>
<td>
<p>logical. If <code>TRUE</code>, the analysis steps are written to the console.</p>
</td></tr>
<tr><td><code id="rpLM_+3A_...">...</code></td>
<td>
<p>other parameters to be supplied to <code><a href="#topic+bootLM">bootLM</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The approach here is along the lines of Boos &amp; Stefanski (2011), which investigated the replication probability of the <em>P</em>-value, as opposed to the works of 
Goodman (1992), Shao &amp; Chow (2002) and Miller (2009), where the effect size is used. In our context, for a given linear model and using a bootstrap approach, the <em>replication probability</em> is the proportion of bootstrap <em>P</em>-values with <code class="reqn">\tilde{P} \leq \alpha</code> when the original model is significant, or  <code class="reqn">\tilde{P} &gt; \alpha</code> when not. Hence, we employ the bootstrap to assess the sampling variability of the <em>P</em>-value, not the sampling variability of the <em>P</em>-value under <code class="reqn">H_0</code>, as is common, thereby preserving the non-null property of the data.
</p>
<p>Bootstrap results are obtained from non-parametric cases bootstrapping (&quot;np.cases&quot;), non-parametric residuals bootstrapping (&quot;np.resid&quot;) and parametric residuals bootstrapping (&quot;p.resid&quot;), see <code><a href="#topic+bootLM">bootLM</a></code>.
</p>


<h3>Value</h3>

<p>A vector with the three different bootstrap results as described above. 
</p>


<h3>Author(s)</h3>

<p>Andrej-Nikolai Spiess
</p>


<h3>References</h3>

<p>Ecological Models and Data in R.<br />
Chapter 5: Stochastic simulation and power analysis.<br />
Benjamin M. Bolker.<br />
Princeton University Press (2008).
</p>
<p>P-Value Precision and Reproducibility.<br />
Boos DD &amp; Stefanski LA.<br />
<em>Am Stat</em>, <b>65</b>, 2011, 213-212.
</p>
<p>A comment on replication, p-values and evidence.<br />
Goodman SN.<br />
<em>Stat Med</em>, <b>11</b>, 1992, 875-879.
</p>
<p>Reproducibility probability in clinical trials.<br />
Shao J &amp; Chow SC.<br /> 
<em>Stat Med</em>, <b>21</b>, 2002, 1727-1742.
</p>
<p>What is the probability of replicating a statistically significant effect?<br />
Miller J.<br />
<em>Psych Bull &amp; Review</em>, <b>16</b>, 2009, 617-640.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(125)
a &lt;- 1:20
b &lt;- 5 + 0.08 * a + rnorm(length(a), 0, 1)
LM1 &lt;- lm(b ~ a)
summary(LM1)
rpLM(LM1, R = 100)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
