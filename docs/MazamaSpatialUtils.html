<!DOCTYPE html><html lang="en"><head><title>Help for package MazamaSpatialUtils</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {MazamaSpatialUtils}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#.removeSpatialDataDir'><p>Remove package data directory</p></a></li>
<li><a href='#+25+26gt+3B+25'><p>Pipe operator</p></a></li>
<li><a href='#codeToCountry'><p>Convert country codes to country names</p></a></li>
<li><a href='#codeToState'><p>Convert state codes to state nnames</p></a></li>
<li><a href='#CONUS'><p>CONUS state codes</p></a></li>
<li><a href='#convertEEZCountries'><p>Convert Exclusive Economic Zones countries shapefile</p></a></li>
<li><a href='#convertEPARegions'><p>Convert EPA Region shapefiles</p></a></li>
<li><a href='#convertGACC'><p>Convert Geographic Area Coordination Center shapefile</p></a></li>
<li><a href='#convertLayer'><p>Convert shapefile layer to simple features dataframe</p></a></li>
<li><a href='#convertNaturalEarthAdm1'><p>Convert Level 1 (state) borders shapefile</p></a></li>
<li><a href='#convertOSMTimezones'><p>Convert OSM timezone shapefile</p></a></li>
<li><a href='#convertTMWorldBorders'><p>Convert world borders shapefile</p></a></li>
<li><a href='#convertUSCensusCBSA'><p>Convert US Core Based Statistical Areas shapefile</p></a></li>
<li><a href='#convertUSCensusCongress'><p>Convert US congressional districts shapefile</p></a></li>
<li><a href='#convertUSCensusCounties'><p>Convert US county borders shapefile</p></a></li>
<li><a href='#convertUSCensusStates'><p>Convert US Census state shapefile</p></a></li>
<li><a href='#convertWBDHUC'><p>Convert USGS hydrologic unit geodatabase</p></a></li>
<li><a href='#convertWeatherZones'><p>Convert NWS Public Forecast Zones Shapefile.</p></a></li>
<li><a href='#convertWikipediaTimezoneTable'><p>Convert Wikipedia timezone table to dataframe</p></a></li>
<li><a href='#countryConversion'><p>Conversion functions for country names, codes and FIPS codes.</p></a></li>
<li><a href='#countryToCode'><p>Convert country names to country codes</p></a></li>
<li><a href='#dissolve'><p>Aggregate shapes in a simple features data frame</p></a></li>
<li><a href='#getCountry'><p>Return country names at specified locations</p></a></li>
<li><a href='#getCountryCode'><p>Return country ISO codes at specified locations</p></a></li>
<li><a href='#getCountryName'><p>Return country names at specified locations</p></a></li>
<li><a href='#getHUC'><p>Return HUCs at specified locations</p></a></li>
<li><a href='#getHUCName'><p>Return HUC names at specified locations</p></a></li>
<li><a href='#getPolygonID'><p>Get polygonID from SFDF of interest</p></a></li>
<li><a href='#getSpatialData'><p>Return spatial data associated with a set of locations</p></a></li>
<li><a href='#getSpatialDataDir'><p>Get package data directory</p></a></li>
<li><a href='#getState'><p>Return state names at specified locations</p></a></li>
<li><a href='#getStateCode'><p>Return state ISO codes at specified locations</p></a></li>
<li><a href='#getStateName'><p>Return state names at specified locations</p></a></li>
<li><a href='#getTimezone'><p>Return Olson timezones at specified locations</p></a></li>
<li><a href='#getUSCounty'><p>Return US county name at specified locations</p></a></li>
<li><a href='#getVariable'><p>Return SFDF variable at specified locations</p></a></li>
<li><a href='#installedSpatialData'><p>List locally installed spatial datasets</p></a></li>
<li><a href='#installSpatialData'><p>Install spatial datasets</p></a></li>
<li><a href='#iso2ToIso3'><p>Convert from ISO2 to ISO3 country codes</p></a></li>
<li><a href='#iso3ToIso2'><p>Convert from ISO3 to ISO2 country codes</p></a></li>
<li><a href='#loadSpatialData'><p>Load spatial datasets</p></a></li>
<li><a href='#MazamaSpatialUtils'><p>Mazama Science spatial data and utility functions.</p></a></li>
<li><a href='#setSpatialDataDir'><p>Set package data directory</p></a></li>
<li><a href='#SimpleCountries'><p>Simplified spatial dataset of country boundaries.</p></a></li>
<li><a href='#SimpleCountriesEEZ'><p>Simplified spatial dataset of EEZ/country combined boundaries.</p></a></li>
<li><a href='#SimpleTimezones'><p>Simplified spatial dataset of world timezones.</p></a></li>
<li><a href='#simplify'><p>Simplify simple features data frame</p></a></li>
<li><a href='#simplifyAndSave'><p>Save simplified versions of a spatial features dataframe</p></a></li>
<li><a href='#SpatialDataDir'><p>Directory for spatial data</p></a></li>
<li><a href='#stateToCode'><p>Convert state names to state codes</p></a></li>
<li><a href='#summarizeByPolygon'><p>Summarize values by polygon</p></a></li>
<li><a href='#US_52'><p>US state codes</p></a></li>
<li><a href='#US_countyCodes'><p>Dataframe of US county codes</p></a></li>
<li><a href='#US_countyConversion'><p>Conversion functions for US county names and FIPS codes.</p></a></li>
<li><a href='#US_stateCodes'><p>Dataframe of US state codes</p></a></li>
<li><a href='#US_stateConversion'><p>Conversion functions for US state names, codes and FIPS codes.</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Version:</td>
<td>0.8.7</td>
</tr>
<tr>
<td>Title:</td>
<td>Spatial Data Download and Utility Functions</td>
</tr>
<tr>
<td>Author:</td>
<td>Jonathan Callahan [aut, cre],
  Rachel Carroll [aut],
  Eli Grosman [aut],
  Roger Andre [aut],
  Tom Bergamaschi [aut],
  Tina Chen [aut],
  Ruby Fore [aut],
  Will Leahy [aut],
  Helen Miller [aut],
  Henry Nguyen [aut],
  Robin Winstanley [aut],
  Alice Yang [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Jonathan Callahan &lt;jonathan.s.callahan@gmail.com&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>A suite of conversion functions to create internally standardized
    spatial polygons data frames. Utility functions use these data sets to
    return values such as country, state, time zone, watershed, etc. associated
    with a set of longitude/latitude pairs. (They also make cool maps.)</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a></td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/MazamaScience/MazamaSpatialUtils">https://github.com/MazamaScience/MazamaSpatialUtils</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/MazamaScience/MazamaSpatialUtils/issues">https://github.com/MazamaScience/MazamaSpatialUtils/issues</a></td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 4.0.0), sf</td>
</tr>
<tr>
<td>Imports:</td>
<td>countrycode, dplyr, magrittr, MazamaCoreUtils (&ge; 0.4.5),
rlang, rmapshaper, stringr</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, markdown, readr, rmarkdown, testthat</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.1</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-11-01 21:04:37 UTC; jonathancallahan</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-11-03 05:30:26 UTC</td>
</tr>
</table>
<hr>
<h2 id='.removeSpatialDataDir'>Remove package data directory</h2><span id='topic+.removeSpatialDataDir'></span>

<h3>Description</h3>

<p>Resets the package data dir to NULL. Used for internal testing.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.removeSpatialDataDir()
</code></pre>


<h3>Value</h3>

<p>Silently returns previous value of data directory.
</p>


<h3>See Also</h3>

<p>SpatialDataDir
</p>
<p>getSpatialDataDir
</p>
<p>setSpatialDataDir
</p>

<hr>
<h2 id='+25+26gt+3B+25'>Pipe operator</h2><span id='topic++25+3E+25'></span>

<h3>Description</h3>

<p>See <code>magrittr::<a href="magrittr.html#topic+pipe">%&gt;%</a></code> for details.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lhs %&gt;% rhs
</code></pre>

<hr>
<h2 id='codeToCountry'>Convert country codes to country names</h2><span id='topic+codeToCountry'></span>

<h3>Description</h3>

<p>Converts a vector of ISO 3166-1 alpha-2 codes to the
corresponding English names.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>codeToCountry(countryCodes)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="codeToCountry_+3A_countrycodes">countryCodes</code></td>
<td>
<p>Vector of ISO 3166-1 alpha-2 country codes.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of English country names or NA.
</p>


<h3>Note</h3>

<p>This function is deprecated as of <strong>MazamaSpatialUtils 0.8.7</strong>.
Please use <a href="#topic+countryCodeToName">countryCodeToName</a> instead.
</p>

<hr>
<h2 id='codeToState'>Convert state codes to state nnames</h2><span id='topic+codeToState'></span>

<h3>Description</h3>

<p>Converts a vector of ISO 3166-2 alpha-2 state codes to the
corresponding English names.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>codeToState(stateCodes, countryCodes = NULL, dataset = "NaturalEarthAdm1")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="codeToState_+3A_statecodes">stateCodes</code></td>
<td>
<p>Vector of state codes.</p>
</td></tr>
<tr><td><code id="codeToState_+3A_countrycodes">countryCodes</code></td>
<td>
<p>Vector of ISO-3166-1 alpha-2 country codes the state might be found in.</p>
</td></tr>
<tr><td><code id="codeToState_+3A_dataset">dataset</code></td>
<td>
<p>Name of dataset containing state-level identifiers.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For this function to work, you must install and load the
&quot;NaturalEarthAdm1&quot; dataset.
</p>


<h3>Value</h3>

<p>A vector of English state names or NA.
</p>


<h3>See Also</h3>

<p>convertNaturalEarthAdm1
</p>

<hr>
<h2 id='CONUS'>CONUS state codes</h2><span id='topic+CONUS'></span>

<h3>Description</h3>

<p>State codes for the 48 contiguous states +DC that make up the CONtinental US.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CONUS
</code></pre>


<h3>Format</h3>

<p>A vector with 49 elements
</p>

<hr>
<h2 id='convertEEZCountries'>Convert Exclusive Economic Zones countries shapefile</h2><span id='topic+convertEEZCountries'></span>

<h3>Description</h3>

<p>Create a simple features dataframe for combined EEZ/country boundaries.
</p>
<p>The full resolution file will be named &quot;EEZCountries.rda&quot;. In addition,
&quot;_05&quot;, _02&quot; and &quot;_01&quot; versions of the file will be created that that are
simplified to 5%, 2% and 1%. Simplified versions will greatly improve the
speed of both searching and plotting.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>convertEEZCountries()
</code></pre>


<h3>Details</h3>

<p>A world EEZ/countries shapefile is converted to a simple features dataframe
with additional columns of data. To use this function, the file
&quot;EEZ_land_union_v3_202003.zip&quot; must be downloaded into the user's spatial
directory which is set with <code>setSpatialDataDir()</code>. The resulting file
will be created in this same spatial data directory.
</p>


<h3>Value</h3>

<p>Name of the datasetName being created.
</p>


<h3>Note</h3>

<p>For polygons with overlapping claims of sovereignty, we arbitrarily
assign the polygon to the country identified in the <code>ISO_SOV1</code> field.
</p>
<p>The source data is from Version 3 &ndash; 2020-03-17.
</p>
<p>From the source documentation:
</p>
<p>Geographic Information Systems have become indispensable tools in managing
and displaying marine data and information. However, a unique georeferenced
standard of marine place names and areas was not available, hampering several
marine geographic applications, for example the linking of these locations to
databases to integrate data. The purpose of Marine Regions is therefore to
create a standard, relational list of geographic names, coupled with information
and maps of the geographic location of these features. This will improve access
and clarity of the different geographic, marine names such as seas, sandbanks,
ridges and bays and display univocally the boundaries of marine biogeographic
or managerial marine areas.
</p>
<p>Marine Regions is an integration of the VLIMAR Gazetteer and the VLIZ Maritime
Boundaries Geodatabase. The VLIMAR Gazetteer is a database with geographic,
mainly marine names such as seas, sandbanks, seamounts, ridges, bays or even
standard sampling stations used in marine research. The geographic cover of
the VLIMAR gazetteer is global but initially focused on the Belgian Continental
Shelf and the Scheldt Estuary and the Southern Bight of the North Sea. Gradually
more regional and global geographic information was added to VLIMAR and combining
this information with the Maritime Boundaries database, representing the
Exclusive Economic Zone (EEZ) of the world, led to the creation of marineregions.org.
</p>
<p>Marine Regions is managed by the Flanders Marine Institute. Funding for the
creation of the VLIMAR gazetteer was provided initially through the EU Network
of Excellence MarBEF, but also other European initiatives such as Lifewatch
provide the necessary funding for the maintenance and management of Marine Regions.
</p>
<p>Marine Regions depends on data and knowledge sharing from global, European,
regional and national data providers and relevant experts. By setting up
Collaboration Agreements, data providers will benefit from belonging to the
Marine Regions partnership as they would get increased visibility, gain access
to a variety of data analysis services which will benefit from integration of
several distributed spatial datasetNames, as well as enjoying the benefit of the
creation of stable unique identifiers. An example template of a Collaboration
Agreement can be found here. Please contact info@marineregions.org if your
organisation is interested to explore this collaboration.
</p>
<p>Citation:
Flanders Marine Institute (2020). Union of the ESRI Country shapefile and the
Exclusive Economic Zones (version 3). Available online at
https://www.marineregions.org/. https://doi.org/10.14284/403
#'
</p>


<h3>References</h3>

<p><a href="https://www.marineregions.org/sources.php#unioneezcountry">https://www.marineregions.org/sources.php#unioneezcountry</a>
</p>


<h3>See Also</h3>

<p>setSpatialDataDir
</p>

<hr>
<h2 id='convertEPARegions'>Convert EPA Region shapefiles</h2><span id='topic+convertEPARegions'></span>

<h3>Description</h3>

<p>Returns a simple features data frame for EPA Regions
</p>
<p>The full resolution file will be named &quot;EPA_Regions.rda&quot;. In addition,
&quot;_05&quot;, _02&quot; and &quot;_01&quot; versions of the file will be created that that are
simplified to 5%, 2% and 1%. Simplified versions will greatly improve the
speed of both searching and plotting.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>convertEPARegions()
</code></pre>


<h3>Details</h3>

<p>An EPA region boundary shapefile is converted to a
simple features data frame with additional columns of data. The resulting file
will be created in the spatial data directory which is set with
<code>setSpatialDataDir()</code>.
</p>
<p>The source data is from 2022.
</p>


<h3>Value</h3>

<p>Name of the datasetName being created.
</p>


<h3>Note</h3>

<p>From the source documentation:
</p>
<p>This datasetName represents delineated EPA Region boundaries. EPA has ten
regional offices across the country, each of which is responsible for several
states and in some cases, territories or special environmental programs.
</p>
<p>This Shared Enterprise Geodata and Services (SEGS)datasetName was created by
U.S. EPA using 2011 TIGER/Line state boundaries from the U.S. Census Bureau.
The core mission of SEGS is to provide a single point of ownership for
geospatial datasetNames that are national in extent and of general use to all
EPA users and to make those datasetNames available through channels that best
meet user needs.
</p>


<h3>References</h3>

<p><a href="https://hub.arcgis.com/datasets/geoplatform::epa-regions">https://hub.arcgis.com/datasets/geoplatform::epa-regions</a>
</p>

<hr>
<h2 id='convertGACC'>Convert Geographic Area Coordination Center shapefile</h2><span id='topic+convertGACC'></span>

<h3>Description</h3>

<p>Create a simple features data frame for Geographic Area
Coordination Centers (GACCs). These are regions defined by the National
Interagency Fire Center (NIFC).
</p>
<p>The full resolution file will be named &quot;GACC.rda&quot;. In addition,
&quot;_05&quot;, _02&quot; and &quot;_01&quot; versions of the file will be created that that are
simplified to 5%, 2% and 1%. Simplified versions will greatly improve the
speed of both searching and plotting.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>convertGACC()
</code></pre>


<h3>Details</h3>

<p>A GACC shapefile is downloaded and converted to a
simple features data frame with additional columns of data. The resulting
file will be created in the spatial data directory which is set with
<code>setSpatialDataDir()</code>.
</p>
<p>The source data is from 2020.
</p>


<h3>Value</h3>

<p>Name of the datasetName being created.
</p>


<h3>Note</h3>

<p>From the source documentation:
</p>
<p>Although the primary mission of the GACC is logistical coordination, the
Center also has support programs in Predictive Services, Intelligence, and in
several Center's Fire Information. Predictive Services consists primarily of
professional meteorologists who monitor weather and fuel conditions, conduct
briefings, produce fire weather related products, liaison with the National
Weather Service, and oversee all aspects of the Remote Automated Weather
System (RAWS). The Intelligence Section is primarily responsible for
collecting and disseminating wildland fire and prescribed fire activity
information, monitoring the status of national firefighting resources,
maintaining year-to-date and historical fire occurrence data, and managing
the Sit Report and ICS-209 programs.
</p>
<p>In some GACCs, the Predictive Services and Intelligence sections work as one
unit called the Predictive Services Group. The Predictive Services and
Intelligence Sections, whether separated or combined, work collaboratively
producing Weekly, Monthly, and Seasonal Fire Weather/Fire Danger Outlooks.
Each Coordination Center provides additional support to their respective
geographic area's wildland fire community through training, workshops,
special projects, and other tasks. Except for dispatch of air tankers and
lead planes based outside the dispatch center responsibility the fire is
located in, the GACC does not have initial-attack dispatch responsibilities.
The United States and Alaska are divided into 11 Geographic Areas for the
purpose of incident management and mobilization of resources (people,
aircraft, ground equipment). Within each Area, an interagency Geographic Area
Coordinating Group (GACG), made up of Fire Directors from each of the Federal
and State land management agencies from within the Area, is established.
</p>
<p>Working collaboratively, the GACG's mission is to provide leadership and
support not only for wildland fire emergencies, but to other emergency
incidents (i.e. earthquakes, floods, hurricanes, tornadoes, etc), as
necessary. Authority for establishment of the GACG is through departmental
policy and interagency agreements. Additional agreements are established with
cooperators and other organizations in order to facilitate efficient fire
management activities within and adjacent to the Area. A cost-effective
sharing of resources among public agencies is a key component of the GACG
mission and is expected by the public, Congress, and States. All agencies and
geographic areas work together under the auspices and direction of the
National Interagency Fire Center (NIFC). The Geographic Area Coordination
Centers (GACC) is a result of an interagency agreement established by the
respective Geographic Area Coordinating Group. The primary mission of the
GACC is to serve Federal and State wildland fire agencies through logistical
coordination and mobilization of resources (people, aircraft, ground
equipment) throughout the geographical area, and with other geographic areas,
as necessary. This is generally done through coordinating the movement of
resources between the many Dispatch Centers within the geographic area and,
as necessary, with the National Interagency Coordination Center (NICC) when
resources are unavailable within the Area or when mobilization support is
needed in other geographic areas. As you survey each GACC website, it will
become obvious they are technical in design and are primarily for use by
local and geographic area wildland fire managers and firefighters. For the
general public, the GACC website may not meet your needs. If this is the case,
please check out the National Fire News website, provided by the National
Interagency Fire Center, and the InciWeb website, provided as a guide to
large fire incidents throughout the United States.
</p>
<p>The National Wildfire Coordinating Group (NWCG) makes no claims, promises, or
guarantees about the accuracy, completeness, or adequacy of the content; and
expressly disclaims liability for errors and omissions. No warranty of any
kind, implied, expressed or statutory is given with respect to the contents.
</p>


<h3>References</h3>

<p>https://hub.arcgis.com/datasets/nifc::national-gacc-boundaries
</p>


<h3>See Also</h3>

<p>setSpatialDataDir
</p>

<hr>
<h2 id='convertLayer'>Convert shapefile layer to simple features dataframe</h2><span id='topic+convertLayer'></span>

<h3>Description</h3>

<p>Raw shapefiles are read in using <code><a href="sf.html#topic+st_read">st_read</a></code>.
Spatial data are reprojected onto a standard projection
(<a href="https://epsg.io/4269">https://epsg.io/4269</a>) before being returned.
</p>
<p>If shapefiles have no projection information they are assumed to 'geographic'
coordinates
.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>convertLayer(dsn = NULL, layer)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="convertLayer_+3A_dsn">dsn</code></td>
<td>
<p>dsn argument to <code>sf::st_read()</code>.</p>
</td></tr>
<tr><td><code id="convertLayer_+3A_layer">layer</code></td>
<td>
<p>layer argument to <code>sf::st_read()</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code>sf</code>.
</p>

<hr>
<h2 id='convertNaturalEarthAdm1'>Convert Level 1 (state) borders shapefile</h2><span id='topic+convertNaturalEarthAdm1'></span>

<h3>Description</h3>

<p>Returns a simple features data frame for top level administrative divisions.
</p>
<p>The full resolution file will be named &quot;NaturalEarthAdm0.rda&quot;. In addition,
&quot;_05&quot;, _02&quot; and &quot;_01&quot; versions of the file will be created that that are
simplified to 5%, 2% and 1%. Simplified versions will greatly improve the
speed of both searching and plotting.
</p>
<p>Returns a simple features data frame for 1st level administrative divisions
</p>
<p>The full resolution file will be named &quot;NaturalEarthAdm1.rda&quot;. In addition,
&quot;_05&quot;, _02&quot; and &quot;_01&quot; versions of the file will be created that that are
simplified to 5%, 2% and 1%. Simplified versions will greatly improve the
speed of both searching and plotting.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>convertNaturalEarthAdm1()

convertNaturalEarthAdm1()
</code></pre>


<h3>Details</h3>

<p>A country border shapefile is downloaded and converted to a
simple features data frame with additional columns of data. The resulting file
will be created in the spatial data directory which is set with
<code>setSpatialDataDir()</code>. The resulting file
will be created in this same spatial data directory.
</p>
<p>A state border shapefile is downloaded and converted to a
simple features data frame with additional columns of data. The resulting file
will be created in the spatial data directory which is set with
<code>setSpatialDataDir()</code>. The resulting file
will be created in this same spatial data directory.
</p>
<p>Within the <span class="pkg">MazamaSpatialUtils</span> package the phrase 'state' refers to
administrative divisions beneath the level of the country or nation. This
makes sense in the United 'States'. In other countries this level is known as
'province', 'territory' or some other term.
</p>


<h3>References</h3>

<p>https://www.naturalearthdata.com
</p>
<p>https://www.naturalearthdata.com
</p>

<hr>
<h2 id='convertOSMTimezones'>Convert OSM timezone shapefile</h2><span id='topic+convertOSMTimezones'></span>

<h3>Description</h3>

<p>Create a simple features data frame for world timezones.
</p>
<p>The full resolution file will be named &quot;OSMTimezones.rda&quot;. In addition,
&quot;_05&quot;, _02&quot; and &quot;_01&quot; versions of the file will be created that that are
simplified to 5%, 2% and 1%. Simplified versions will greatly improve the
speed of both searching and plotting.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>convertOSMTimezones()
</code></pre>


<h3>Details</h3>

<p>A world timezone shapefile is downloaded and converted to a
simple features data frame with additional columns of data. The resulting file
will be created in the spatial data directory which is set with
<code>setSpatialDataDir()</code>.
</p>
<p>There are 2 timezones which have polygons but the associated rows in the dataframe have no data.
These timezones also have no <code>countryCode</code> assigned. We hope to rectify this in a future release.
These are the missing timezones:
</p>
<pre>
&gt; OSMTimezones$timezone[is.na(OSMTimezones$countryCode)]
 [1] "America/Nuuk"  "Asia/Qostanay"
</pre>


<h3>Value</h3>

<p>Name of the datasetName being created.
</p>


<h3>Note</h3>

<p>From the source documentation:
</p>
<p>This project aims to stay up-to-date with all of the currently valid
timezones that are defined in the timezone database. This project also will
attempt to provide the most accurate possible boundaries of timezones
according to community input.
</p>
<p>The underlying data is downloaded from OpenStreetMap via the overpass turbo
API. Various boundaries are assembled together to produce each zone with
various geographic operations. In numerous edge cases arbitrary boundaries
get created in various zones which are noted in the timezones.json file.
</p>
<p>To maintain consistency with the timezone database, this project will only
create a new release after the timezone database creates a new release. If
there are no new timezones created or deleted in a timezone database release,
then this project will only create a release if there have been changes
performed to the boundary definitions of an existing zone within this project.
</p>


<h3>References</h3>

<p><a href="https://github.com/evansiroky/timezone-boundary-builder">https://github.com/evansiroky/timezone-boundary-builder</a>
</p>

<hr>
<h2 id='convertTMWorldBorders'>Convert world borders shapefile</h2><span id='topic+convertTMWorldBorders'></span>

<h3>Description</h3>

<p>Returns a simple features data frame for world divisions
</p>
<p>The full resolution file will be named &quot;TMWorldBorders.rda&quot;. In addition,
&quot;_05&quot;, _02&quot; and &quot;_01&quot; versions of the file will be created that that are
simplified to 5%, 2% and 1%. Simplified versions will greatly improve the
speed of both searching and plotting.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>convertTMWorldBorders()
</code></pre>


<h3>Details</h3>

<p>A world borders shapefile is downloaded and converted to a
simple features data frame with additional columns of data. The resulting file is
created in the spatial data directory which is set with <code>setSpatialDataDir()</code>.
</p>


<h3>Value</h3>

<p>Name of the datasetName being created.
</p>


<h3>References</h3>

<p><a href="https://thematicmapping.org/">https://thematicmapping.org/</a>
</p>

<hr>
<h2 id='convertUSCensusCBSA'>Convert US Core Based Statistical Areas shapefile</h2><span id='topic+convertUSCensusCBSA'></span>

<h3>Description</h3>

<p>Returns a simple features data frame for US CBSAs
</p>
<p>The full resolution file will be named &quot;USCensusCBSA.rda&quot;. In addition,
&quot;_05&quot;, _02&quot; and &quot;_01&quot; versions of the file will be created that that are
simplified to 5%, 2% and 1%. Simplified versions will greatly improve the
speed of both searching and plotting.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>convertUSCensusCBSA()
</code></pre>


<h3>Details</h3>

<p>A US Core Based Statistical Areas (CBSA) shapefile is downloaded and converted to a
simple features data frame with additional columns of data. The resulting file
will be created in the spatial data directory which is set with
<code>setSpatialDataDir()</code>.
</p>


<h3>Value</h3>

<p>Name of the datasetName being created.
</p>


<h3>Note</h3>

<p>From the source documentation:
</p>
<p>Metropolitan and Micropolitan Statistical Areas are together termed Core Based
Statistical Areas (CBSAs) and are defined by the Office of Management and Budget
(OMB) and consist of the county or counties or equivalent entities associated
with at least one urban core (urbanized area or urban cluster) of at least 10,000
population, plus adjacent counties having a high degree of social and economic
integration with the core as measured through commuting ties with the counties
containing the core. Categories of CBSAs are: Metropolitan Statistical Areas,
based on urbanized areas of 50,000 or more population; and Micropolitan Statistical
Areas, based on urban clusters of at least 10,000 population but less than 50,000
population.
</p>
<p>The CBSA boundaries are those defined by OMB based on the 2010 Census,
published in 2013, and updated in 2020.
</p>


<h3>References</h3>

<p><a href="https://www2.census.gov/geo/tiger/TIGER2021/CBSA/">https://www2.census.gov/geo/tiger/TIGER2021/CBSA/</a>
</p>


<h3>See Also</h3>

<p>setSpatialDataDir
</p>
<p>getUSCounty
</p>

<hr>
<h2 id='convertUSCensusCongress'>Convert US congressional districts shapefile</h2><span id='topic+convertUSCensusCongress'></span>

<h3>Description</h3>

<p>Returns a simple features data frame for US Congressional Districts
for the 116th US House of Representatives.
</p>
<p>The full resolution file will be named &quot;USCensus116thCongress.rda&quot;. In addition,
&quot;_05&quot;, _02&quot; and &quot;_01&quot; versions of the file will be created that that are
simplified to 5%, 2% and 1%. Simplified versions will greatly improve the
speed of both searching and plotting.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>convertUSCensusCongress()
</code></pre>


<h3>Details</h3>

<p>A US congressional district shapefile is downloaded and converted to
a simple features data frame with additional columns of data. The resulting
file will be created in the spatial data directory which is set with
<code>setSpatialDataDir()</code>.
</p>
<p>#' The source data is from 2021.
</p>


<h3>Value</h3>

<p>Name of the datasetName being created.
</p>


<h3>Note</h3>

<p>From the source documentation:
</p>
<p>Congressional Districts are the 435 areas from which people are elected to the
U.S. House of Representatives. After the apportionment of congressional seats
among the states based on census population counts, each state is responsible
for establishing congressional districts for the purpose of electing representatives.
Each congressional district is to be as equal in population to all other
congressional districts in a state as practicable. The 116th Congress is seated
from January 2019 to 2021. The cartographic boundary files for the District of
Columbia, Puerto Rico, and the Island Areas (American Samoa, Guam, the Commonwealth
of the Northern Mariana Islands, and the U.S. Virgin Islands) each contain a
single record for the non-voting delegate district in these areas. The boundaries
of all other congressional districts are provided to the Census Bureau by the
states by May 1, 2018.
</p>
<p>You can join this file with table data downloaded from American FactFinder by
using the AFFGEOID field in the cartographic boundary file.
</p>


<h3>References</h3>

<p><a href="https://www2.census.gov/geo/tiger/GENZ2021/">https://www2.census.gov/geo/tiger/GENZ2021/</a>
</p>


<h3>See Also</h3>

<p>setSpatialDataDir
</p>

<hr>
<h2 id='convertUSCensusCounties'>Convert US county borders shapefile</h2><span id='topic+convertUSCensusCounties'></span>

<h3>Description</h3>

<p>Create a simple features data frame for US counties.
</p>
<p>The full resolution file will be named &quot;USCensusCounties.rda&quot;. In addition,
&quot;_05&quot;, _02&quot; and &quot;_01&quot; versions of the file will be created that that are
simplified to 5%, 2% and 1%. Simplified versions will greatly improve the
speed of both searching and plotting.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>convertUSCensusCounties()
</code></pre>


<h3>Details</h3>

<p>A US county borders shapefile is downloaded and converted to a
simple features data frame with additional columns of data. The resulting file
will be created in the spatial data directory which is set with
<a href="#topic+setSpatialDataDir">setSpatialDataDir</a>.
</p>
<p>The source data is from 2021.
</p>


<h3>Value</h3>

<p>Name of the datasetName being created.
</p>


<h3>Note</h3>

<p>From the source documentation:
</p>
<p>The primary legal divisions of most states are termed counties. In Louisiana,
these divisions are known as parishes. In Alaska, which has no counties, the
equivalent entities are the organized boroughs, city and boroughs,
municipalities, and for the unorganized area, census areas. The latter are
delineated cooperatively for statistical purposes by the State of Alaska and
the Census Bureau. In four states (Maryland, Missouri, Nevada, and Virginia),
there are one or more incorporated places that are independent of any county
organization and thus constitute primary divisions of their states. These
incorporated places are known as independent cities and are treated as
equivalent entities for purposes of data presentation. The District of
Columbia and Guam have no primary divisions, and each area is considered an
equivalent entity for purposes of data presentation. The Census Bureau treats
the following entities as equivalents of counties for purposes of data
presentation: Municipios in Puerto Rico, Districts and Islands in American
Samoa, Municipalities in the Commonwealth of the Northern Mariana Islands,
and Islands in the U.S. Virgin Islands. The entire area of the United States,
Puerto Rico, and the Island Areas is covered by counties or equivalent entities.
</p>
<p>You can join this file with table data downloaded from American FactFinder by
using the AFFGEOID field in the cartographic boundary file.
</p>


<h3>References</h3>

<p><a href="https://www2.census.gov/geo/tiger/GENZ2021/">https://www2.census.gov/geo/tiger/GENZ2021/</a>
</p>

<hr>
<h2 id='convertUSCensusStates'>Convert US Census state shapefile</h2><span id='topic+convertUSCensusStates'></span>

<h3>Description</h3>

<p>Create a simple features dataframe for US states
</p>
<p>The full resolution file will be named &quot;USCensusStates&quot;. In addition,
&quot;_05&quot;, _02&quot; and &quot;_01&quot; versions of the file will be created that that are
simplified to 5%, 2% and 1%. Simplified versions will greatly improve the
speed of both searching and plotting.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>convertUSCensusStates()
</code></pre>


<h3>Details</h3>

<p>A US state borders shapefile is downloaded and converted to a
simple features dataframe with additional columns of data. The resulting file
will be created in the spatial data directory which is set with
<a href="#topic+setSpatialDataDir">setSpatialDataDir</a>.
</p>
<p>The source data is from 2021.
</p>


<h3>Value</h3>

<p>Name of the datasetName being created.
</p>


<h3>Note</h3>

<p>From the source documentation:
</p>
<p><strong>Cartographic Boundary Files</strong>
</p>
<p>The cartographic boundary files are simplified representations of
selected geographic areas from the U.S. Census Bureau's Master Address File /
Topologically Integrated Geographic Encoding and Referencing (MAF/TIGER)
Database (MTDB). These boundary files are specifically designed for
small-scale thematic mapping. When possible, generalization is performed with
the intent to maintain the hierarchical relationships among geographies and
to maintain the alignment of geographies within a file set for a given year.
To improve the appearance of shapes, areas are represented with fewer vertices
than detailed TIGER/Line equivalents. Some small holes or discontiguous parts
of areas are not included in generalized files. Generalized boundary files
are clipped to a simplified version of the U.S. outline. As a result, some
offshore areas may be excluded from the generalized files.
</p>
<p><strong>Limitations</strong>
</p>
<p>Geographic areas may not align with the same areas from another year. Some
geographies are available as nation-based files while others are available
only as state-based files.
</p>
<p>States and equivalent entities are the primary governmental divisions of the
United States. In addition to the fifty states, the Census Bureau treats the
District of Columbia, Puerto Rico, and each of the Island Areas (American
Samoa, the Commonwealth of the Northern Mariana Islands, Guam, and the U.S.
Virgin Islands) as the statistical equivalents of states for the purpose of
data presentation.
</p>
<p><strong><em>&quot;Island Areas&quot; are removed in the MazamaSpatialUtils version.</em></strong>
</p>
<p>These files were specifically created to support small-scale thematic mapping.
To improve the appearance of shapes at small scales, areas are represented
with fewer vertices than detailed TIGER/Line Shapefiles. Cartographic boundary
files take up less disk space than their ungeneralized counterparts.
Cartographic boundary files take less time to render on screen than TIGER/Line
Shapefiles. You can join this file with table data downloaded from American
FactFinder by using the AFFGEOID field in the cartographic boundary file. If
detailed boundaries are required, please use the TIGER/Line Shapefiles instead
of the generalized cartographic boundary files.
</p>


<h3>References</h3>

<p><a href="https://www2.census.gov/geo/tiger/GENZ2021/">https://www2.census.gov/geo/tiger/GENZ2021/</a>
</p>

<hr>
<h2 id='convertWBDHUC'>Convert USGS hydrologic unit geodatabase</h2><span id='topic+convertWBDHUC'></span>

<h3>Description</h3>

<p>Create a simple features data frame for USGS watershed boundaries
</p>


<h3>Usage</h3>

<pre><code class='language-R'>convertWBDHUC(
  gdbDir = "~/Data/WBD/WBD_National_GDB.gdb",
  level = 2,
  simplify = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="convertWBDHUC_+3A_gdbdir">gdbDir</code></td>
<td>
<p>Directory containing the geodatabase.</p>
</td></tr>
<tr><td><code id="convertWBDHUC_+3A_level">level</code></td>
<td>
<p>Character or integer which must be 2, 4, 6, 8, 10, 12 or 14.</p>
</td></tr>
<tr><td><code id="convertWBDHUC_+3A_simplify">simplify</code></td>
<td>
<p>Logical specifying whether to perform simplification</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A USGS Watershed Boundary Dataset geodatabase is converted to a
simple features data frame with additional columns of data. To use this
function, the WBD geodatabase must be downloaded into a directory which is
identified with <code>gdbDir</code>. The resulting file will be created in the
spatial data directory which is set with <code>setSpatialDataDir()</code>.
</p>
<p>The full WBD datasetName can be downloaded from the USGS with the
following command:
</p>
<pre>
curl https://prd-tnm.s3.amazonaws.com/StagedProducts/Hydrography/WBD/National/GDB/WBD_National_GDB.zip -O
</pre>
<p>The source data was downloaded on 2023-03-23.
</p>


<h3>Value</h3>

<p>Name of the datasetName being created.
</p>


<h3>Note</h3>

<p>From the source documentation:
</p>
<p>The Watershed Boundary Dataset (WBD) is a comprehensive aggregated collection
of hydrologic unit data consistent with the national criteria for delineation
and resolution. It defines the areal extent of surface water drainage to a
point except in coastal or lake front areas where there could be multiple
outlets as stated by the &amp;quot;Federal Standards and Procedures for the
National Watershed Boundary Dataset (WBD)&amp;quot; &amp;quot;Standard&amp;quot;
(https://pubs.usgs.gov/tm/11/a3/). Watershed boundaries are determined solely
upon science-based hydrologic principles, not favoring any administrative
boundaries or special projects, nor particular program or agency. This dataset
represents the hydrologic unit boundaries to the 12-digit (6th level) for the
entire United States. Some areas may also include additional subdivisions
representing the 14- and 16-digit hydrologic unit (HU). At a minimum, the HUs
are delineated at 1:24,000-scale in the conterminous United States,
1:25,000-scale in Hawaii, Pacific basin and the Caribbean, and 1:63,360-scale
in Alaska, meeting the National Map Accuracy Standards (NMAS). Higher
resolution boundaries are being developed where partners and data exist and
will be incorporated back into the WBD. WBD data are delivered as a dataset
of polygons and corresponding lines that define the boundary of the polygon.
WBD polygon attributes include hydrologic unit codes (HUC), size (in the form
of acres and square kilometers), name, downstream hydrologic unit code, type
of watershed, non-contributing areas, and flow modifications. The HUC
describes where the unit is in the country and the level of the unit. WBD
line attributes contain the highest level of hydrologic unit for each boundary,
line source information and flow modifications.
</p>
<p>The intent of defining Hydrologic Units (HU) within the Watershed Boundary
Dataset is to establish a base-line drainage boundary framework, accounting
for all land and surface areas. Hydrologic units are intended to be used as
a tool for water-resource management and planning activities particularly
for site-specific and localized studies requiring a level of detail provided
by large-scale map information. The WBD complements the National Hydrography
Dataset (NHD) and supports numerous programmatic missions and activities
including: watershed management, rehabilitation and enhancement, aquatic
species conservation strategies, flood plain management and flood prevention,
water-quality initiatives and programs, dam safety programs, fire assessment
and management, resource inventory and assessment, water data analysis and
water census.
</p>


<h3>References</h3>

<p><a href="https://www.usgs.gov/national-hydrography/watershed-boundary-dataset">https://www.usgs.gov/national-hydrography/watershed-boundary-dataset</a>
</p>


<h3>See Also</h3>

<p>setSpatialDataDir
</p>

<hr>
<h2 id='convertWeatherZones'>Convert NWS Public Forecast Zones Shapefile.</h2><span id='topic+convertWeatherZones'></span>

<h3>Description</h3>

<p>Create a simple features data frame for NWS weather forecast zones.
</p>
<p>The full resolution file will be named &quot;WeatherZones.rda&quot;. In addition,
&quot;_05&quot;, _02&quot; and &quot;_01&quot; versions of the file will be created that that are
simplified to 5%, 2% and 1%. Simplified versions will greatly improve the
speed of both searching and plotting.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>convertWeatherZones()
</code></pre>


<h3>Details</h3>

<p>A weather forecast zone shapefile is downloaded and converted to a
simple features data frame with additional columns of data. The resulting file
will be created in the spatial data directory which is set with
<code>setSpatialDataDir()</code>.
</p>
<p>The source data is from 2022-09-13.
</p>


<h3>Value</h3>

<p>Name of the datasetName being created.
</p>


<h3>Note</h3>

<p>Records with a duplicated <code>zoneID</code> column (typically representing
coastal land and its watery inlets separately) are combined so that <code>zoneID</code>
becomes a unique identifier.
</p>
<p>From the source documentation:
</p>
<p>The NWS issues forecasts and some watches and warnings for public zones which
usually are the same as counties but in many cases are subsets of counties.
Counties are subset into zones to allow for more accurate forecasts because
of the differences in weather within a county due to such things as elevation
or proximity to large bodies of water.
</p>


<h3>References</h3>

<p><a href="https://www.weather.gov/gis/PublicZones">https://www.weather.gov/gis/PublicZones</a>
</p>

<hr>
<h2 id='convertWikipediaTimezoneTable'>Convert Wikipedia timezone table to dataframe</h2><span id='topic+convertWikipediaTimezoneTable'></span>

<h3>Description</h3>

<p>Returns a dataframe version of the Wikipedia timezone table with
the following columns:
</p>

<ul>
<li><p>timezone &ndash; Olson timezone
</p>
</li>
<li><p>UTC_offset &ndash; hours between local timezone and UTC
</p>
</li>
<li><p>UTC_DST_offset &ndash; hours between local timezone daylight savings and UTC
</p>
</li>
<li><p>countryCode &ndash; ISO 3166-2 country code
</p>
</li>
<li><p>longitude &ndash; longitude of the Olson timezone city
</p>
</li>
<li><p>latitude &ndash; latitude of the Olson timezone city
</p>
</li>
<li><p>status &ndash; either 'Canonical', 'Alias' or 'Deprecated'
</p>
</li>
<li><p>notes &ndash; typically specifying the target of an 'Alias'
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>convertWikipediaTimezoneTable()
</code></pre>


<h3>Details</h3>

<p>Older named timezones from the table which are linked to more modern
equivalents are not included in the returned dataframe.
</p>


<h3>Value</h3>

<p>Dataframe with 388 rows and 10 columns.
</p>


<h3>References</h3>

<p><a href="https://en.wikipedia.org/wiki/List_of_tz_database_time_zones">https://en.wikipedia.org/wiki/List_of_tz_database_time_zones</a>
</p>

<hr>
<h2 id='countryConversion'>Conversion functions for country names, codes and FIPS codes.</h2><span id='topic+countryConversion'></span><span id='topic+countryCodeToName'></span><span id='topic+countryCodeToFIPS'></span><span id='topic+countryFIPSToName'></span><span id='topic+countryFIPSToCode'></span><span id='topic+countryNameToCode'></span><span id='topic+countryNameToFIPS'></span>

<h3>Description</h3>

<p>Converts a vector of country names or codes from one system to
another returning <code>NA</code> where no match is found.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>countryCodeToName(countryCode = NULL)

countryCodeToFIPS(countryCode = NULL)

countryFIPSToName(countryFIPS = NULL)

countryFIPSToCode(countryFIPS = NULL)

countryNameToCode(countryName = NULL)

countryNameToFIPS(countryName = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="countryConversion_+3A_countrycode">countryCode</code></td>
<td>
<p>Vector of ISO 3166-1 alpha-2 codes.</p>
</td></tr>
<tr><td><code id="countryConversion_+3A_countryfips">countryFIPS</code></td>
<td>
<p>Vector of two-character FIPS codes.</p>
</td></tr>
<tr><td><code id="countryConversion_+3A_countryname">countryName</code></td>
<td>
<p>Vector of English language country names.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of country names or codes.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(MazamaSpatialUtils)

# FIPS codes are different!

countryNameToCode("Germany")
countryNameToFIPS("Germany")

countryCodeToName("CH")
countryFIPSToName("CH")

countryCodes &lt;- sample(SimpleCountries$countryCode, 30)

data.frame(
  name = countryCodeToName(countryCodes),
  code = countryCodes,
  FIPS = countryCodeToFIPS(countryCodes)
)

</code></pre>

<hr>
<h2 id='countryToCode'>Convert country names to country codes</h2><span id='topic+countryToCode'></span>

<h3>Description</h3>

<p>Converts a vector of English country names to the corresponding
ISO 3166-1 alpha-2 codes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>countryToCode(countryNames)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="countryToCode_+3A_countrynames">countryNames</code></td>
<td>
<p>Vector of English language country names.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of ISO 3166-1 alpha-2 codes or NA.
</p>


<h3>Note</h3>

<p>This function is deprecated as of <strong>MazamaSpatialUtils 0.8.7</strong>.
Please use <a href="#topic+countryNameToCode">countryNameToCode</a> instead.
</p>

<hr>
<h2 id='dissolve'>Aggregate shapes in a simple features data frame</h2><span id='topic+dissolve'></span>

<h3>Description</h3>

<p>Aggregate shapes in a simple features dataframe. This is a
convenience wrapper for <code><a href="rmapshaper.html#topic+ms_dissolve">ms_dissolve</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dissolve(SFDF, field = NULL, sum_fields = NULL, copy_fields = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="dissolve_+3A_sfdf">SFDF</code></td>
<td>
<p>Object of class simple features data frame.</p>
</td></tr>
<tr><td><code id="dissolve_+3A_field">field</code></td>
<td>
<p>Name of the field to dissolve on.</p>
</td></tr>
<tr><td><code id="dissolve_+3A_sum_fields">sum_fields</code></td>
<td>
<p>Names of fields to sum.</p>
</td></tr>
<tr><td><code id="dissolve_+3A_copy_fields">copy_fields</code></td>
<td>
<p>Names of fields to copy. The first instance of each field will be
copied to the aggregated feature</p>
</td></tr>
<tr><td><code id="dissolve_+3A_...">...</code></td>
<td>
<p>arguments passed to <code>rmapshaper::ms_dissolve()</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>A simple features dataframe with aggregated shapes.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
regions &lt;- dissolve(SimpleCountries, field = "UN_region", sum_fields = "area")
plot(regions)
dplyr::glimpse(regions)

</code></pre>

<hr>
<h2 id='getCountry'>Return country names at specified locations</h2><span id='topic+getCountry'></span>

<h3>Description</h3>

<p>Uses spatial comparison to determine which country polygons the
locations fall into and returns the country name for those polygons.
</p>
<p>Specification of <code>countryCodes</code> limits spatial searching to the
specified countries and greatly improves performance.
</p>
<p>If <code>allData = TRUE</code>, additional data is returned.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getCountry(
  longitude = NULL,
  latitude = NULL,
  datasetName = "SimpleCountriesEEZ",
  countryCodes = NULL,
  allData = FALSE,
  useBuffering = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="getCountry_+3A_longitude">longitude</code></td>
<td>
<p>Vector of longitudes in decimal degrees East.</p>
</td></tr>
<tr><td><code id="getCountry_+3A_latitude">latitude</code></td>
<td>
<p>Vector of latitudes in decimal degrees North.</p>
</td></tr>
<tr><td><code id="getCountry_+3A_datasetname">datasetName</code></td>
<td>
<p>Name of spatial dataset to use.</p>
</td></tr>
<tr><td><code id="getCountry_+3A_countrycodes">countryCodes</code></td>
<td>
<p>Vector of ISO 3166-1 alpha-2 country codes.</p>
</td></tr>
<tr><td><code id="getCountry_+3A_alldata">allData</code></td>
<td>
<p>Logical specifying whether a full dataframe should be returned.</p>
</td></tr>
<tr><td><code id="getCountry_+3A_usebuffering">useBuffering</code></td>
<td>
<p>Logical flag specifying the use of location buffering to
find the nearest polygon if no target polygon is found.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Vector of English language country names.
</p>


<h3>References</h3>

<p>http://www.naturalearthdata.com/downloads/10m-cultural-vectors/
</p>


<h3>See Also</h3>

<p>SimpleCountries
</p>
<p>getSpatialData
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(MazamaSpatialUtils)

longitude &lt;- seq(0, 50)
latitude &lt;- seq(0, 50)

getCountry(longitude, latitude)

</code></pre>

<hr>
<h2 id='getCountryCode'>Return country ISO codes at specified locations</h2><span id='topic+getCountryCode'></span>

<h3>Description</h3>

<p>Uses spatial comparison to determine which country polygons the
locations fall into and returns the country code strings for those polygons.
</p>
<p>Specification of <code>countryCodes</code> limits spatial searching to the
specified countries and greatly improves performance.
</p>
<p>If <code>allData = TRUE</code>, additional data is returned.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getCountryCode(
  longitude = NULL,
  latitude = NULL,
  datasetName = "SimpleCountriesEEZ",
  countryCodes = NULL,
  allData = FALSE,
  useBuffering = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="getCountryCode_+3A_longitude">longitude</code></td>
<td>
<p>Vector of longitudes in decimal degrees East.</p>
</td></tr>
<tr><td><code id="getCountryCode_+3A_latitude">latitude</code></td>
<td>
<p>Vector of latitudes in decimal degrees North.</p>
</td></tr>
<tr><td><code id="getCountryCode_+3A_datasetname">datasetName</code></td>
<td>
<p>Name of spatial dataset to use.</p>
</td></tr>
<tr><td><code id="getCountryCode_+3A_countrycodes">countryCodes</code></td>
<td>
<p>Vector of ISO 3166-1 alpha-2 country codes.</p>
</td></tr>
<tr><td><code id="getCountryCode_+3A_alldata">allData</code></td>
<td>
<p>Logical specifying whether a full dataframe should be returned.</p>
</td></tr>
<tr><td><code id="getCountryCode_+3A_usebuffering">useBuffering</code></td>
<td>
<p>Logical flag specifying the use of location buffering to
find the nearest polygon if no target polygon is found.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Vector of ISO-3166-1 alpha-2 country codes.
</p>


<h3>References</h3>

<p>http://www.naturalearthdata.com/downloads/10m-cultural-vectors/
</p>


<h3>See Also</h3>

<p>SimpleCountries
</p>
<p>getSpatialData
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(MazamaSpatialUtils)

longitude &lt;- seq(0, 50)
latitude &lt;- seq(0, 50)

getCountryCode(longitude, latitude)

</code></pre>

<hr>
<h2 id='getCountryName'>Return country names at specified locations</h2><span id='topic+getCountryName'></span>

<h3>Description</h3>

<p>Uses spatial comparison to determine which country polygons the
locations fall into and returns the country name for those polygons.
</p>
<p>Specification of <code>countryCodes</code> limits spatial searching to the
specified countries and greatly improves performance.
</p>
<p>If <code>allData = TRUE</code>, additional data is returned.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getCountryName(
  longitude = NULL,
  latitude = NULL,
  datasetName = "SimpleCountriesEEZ",
  countryCodes = NULL,
  allData = FALSE,
  useBuffering = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="getCountryName_+3A_longitude">longitude</code></td>
<td>
<p>Vector of longitudes in decimal degrees East.</p>
</td></tr>
<tr><td><code id="getCountryName_+3A_latitude">latitude</code></td>
<td>
<p>Vector of latitudes in decimal degrees North.</p>
</td></tr>
<tr><td><code id="getCountryName_+3A_datasetname">datasetName</code></td>
<td>
<p>Name of spatial dataset to use.</p>
</td></tr>
<tr><td><code id="getCountryName_+3A_countrycodes">countryCodes</code></td>
<td>
<p>Vector of ISO 3166-1 alpha-2 country codes.</p>
</td></tr>
<tr><td><code id="getCountryName_+3A_alldata">allData</code></td>
<td>
<p>Logical specifying whether a full dataframe should be returned.</p>
</td></tr>
<tr><td><code id="getCountryName_+3A_usebuffering">useBuffering</code></td>
<td>
<p>Logical flag specifying the use of location buffering to
find the nearest polygon if no target polygon is found.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Vector of English language country names.
</p>


<h3>See Also</h3>

<p>SimpleCountries
</p>
<p>getSpatialData
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(MazamaSpatialUtils)

longitude &lt;- seq(0, 50)
latitude &lt;- seq(0, 50)

getCountryName(longitude, latitude)

</code></pre>

<hr>
<h2 id='getHUC'>Return HUCs at specified locations</h2><span id='topic+getHUC'></span>

<h3>Description</h3>

<p>Uses spatial comparison to determine which HUC polygons the
locations fall into and returns the HUC identifier strings for those polygons.
</p>
<p>Specification of <code>HUCs</code> limits spatial searching to the
specified HUCs and greatly improves performance. For instance, if searching
for level 10 HUCs in the Upper Columbia basin, it would make sense to first
search WBDHU4_01 to learn that the level 4 HUC is <code>1702</code>. Then you
can greatly improve search times for higher level HUCs by specifying:
<code>HUCs = c("1702")</code>.
</p>
<p>If <code>allData = TRUE</code>, additional data is returned.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getHUC(
  longitude = NULL,
  latitude = NULL,
  dataset = NULL,
  HUCs = NULL,
  allData = FALSE,
  useBuffering = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="getHUC_+3A_longitude">longitude</code></td>
<td>
<p>Vector of longitudes in decimal degrees East.</p>
</td></tr>
<tr><td><code id="getHUC_+3A_latitude">latitude</code></td>
<td>
<p>Vector of latitudes in decimal degrees North.</p>
</td></tr>
<tr><td><code id="getHUC_+3A_dataset">dataset</code></td>
<td>
<p>Name of spatial dataset to use.</p>
</td></tr>
<tr><td><code id="getHUC_+3A_hucs">HUCs</code></td>
<td>
<p>Vector of Hydrologic Unit Codes used to limit searches.</p>
</td></tr>
<tr><td><code id="getHUC_+3A_alldata">allData</code></td>
<td>
<p>logical specifying whether a full dataframe should be returned</p>
</td></tr>
<tr><td><code id="getHUC_+3A_usebuffering">useBuffering</code></td>
<td>
<p>Logical flag specifying the use of location buffering to
find the nearest polygon if no target polygon is found.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Vector of HUC identifiers.
</p>


<h3>See Also</h3>

<p>getSpatialData
</p>

<hr>
<h2 id='getHUCName'>Return HUC names at specified locations</h2><span id='topic+getHUCName'></span>

<h3>Description</h3>

<p>Uses spatial comparison to determine which HUC polygons the
locations fall into and returns the HUC names for those polygons.
</p>
<p>Specification of <code>HUCs</code> limits spatial searching to the
specified HUCs and greatly improves performance. For instance, if searching
for level 10 HUCs in the Upper Columbia basin, it would make sense to first
search WBDHU4_01 to learn that the level 4 HUC is <code>1702</code>. Then you
can greatly improve search times for higher level HUCs by specifying:
<code>HUCs = c("1702")</code>.
</p>
<p>If <code>allData = TRUE</code>, additional data is returned.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getHUCName(
  longitude = NULL,
  latitude = NULL,
  dataset = NULL,
  HUCs = NULL,
  allData = FALSE,
  useBuffering = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="getHUCName_+3A_longitude">longitude</code></td>
<td>
<p>Vector of longitudes in decimal degrees East.</p>
</td></tr>
<tr><td><code id="getHUCName_+3A_latitude">latitude</code></td>
<td>
<p>Vector of latitudes in decimal degrees North.</p>
</td></tr>
<tr><td><code id="getHUCName_+3A_dataset">dataset</code></td>
<td>
<p>Name of spatial dataset to use.</p>
</td></tr>
<tr><td><code id="getHUCName_+3A_hucs">HUCs</code></td>
<td>
<p>Vector of Hydrologic Unit Codes used to limit searches.</p>
</td></tr>
<tr><td><code id="getHUCName_+3A_alldata">allData</code></td>
<td>
<p>Logical specifying whether a full dataframe should be returned</p>
</td></tr>
<tr><td><code id="getHUCName_+3A_usebuffering">useBuffering</code></td>
<td>
<p>Logical flag specifying the use of location buffering to
find the nearest polygon if no target polygon is found.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Vector of HUC names.
</p>


<h3>See Also</h3>

<p>getSpatialData
</p>

<hr>
<h2 id='getPolygonID'>Get polygonID from SFDF of interest</h2><span id='topic+getPolygonID'></span>

<h3>Description</h3>

<p>Extracts the the vector of unique polygon identifiers from
<code>SFDF</code>.
</p>
<p>This function is useful when writing code to aggregate data by polygon and
calculate per-polygon statistics. Each unique simple features data frame will
have a different set of data columns but each is guaranteed to have a column
named <code>polygonID</code> that uniquely identifies each polygon.
</p>
<p>This allows us to write code that aggregates by polygon without having to
know whether the polygons represent, countries, timezones or HUCs, etc.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getPolygonID(SFDF)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="getPolygonID_+3A_sfdf">SFDF</code></td>
<td>
<p>Spatial polygons dataset of interest.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Vector of polygon identifiers.
</p>

<hr>
<h2 id='getSpatialData'>Return spatial data associated with a set of locations</h2><span id='topic+getSpatialData'></span>

<h3>Description</h3>

<p>All locations are first converted to <code>SpatialPoints</code>
objects. The <code><a href="sf.html#topic+st_intersects">st_intersects</a></code> function is then used to determine which
polygon from <code>SFDF</code> each location falls in. The dataframe row associated
with each polygon is then associated with each location.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getSpatialData(
  longitude = NULL,
  latitude = NULL,
  SFDF = NULL,
  useBuffering = FALSE,
  verbose = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="getSpatialData_+3A_longitude">longitude</code></td>
<td>
<p>Vector of longitudes in decimal degrees East.</p>
</td></tr>
<tr><td><code id="getSpatialData_+3A_latitude">latitude</code></td>
<td>
<p>Vector of latitudes in decimal degrees North.</p>
</td></tr>
<tr><td><code id="getSpatialData_+3A_sfdf">SFDF</code></td>
<td>
<p>sf dataframe with MULTIPOLYGON geometry.</p>
</td></tr>
<tr><td><code id="getSpatialData_+3A_usebuffering">useBuffering</code></td>
<td>
<p>Logical flag specifying the use of location buffering to
find the nearest polygon if no target polygon is found.</p>
</td></tr>
<tr><td><code id="getSpatialData_+3A_verbose">verbose</code></td>
<td>
<p>Logical flag controlling detailed progress statements.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For coastal locations, locations may lie just outside the boundaries
of an individual polygon, especially if it is of low resolution.
To account for this any location that remains unassociated after the first
pass is checked to seee if it is with a specific distance of any polygon.
The set of distances is gradually increased until a polygon is reached or the
maximum distances is encountered. Distances include: 1km, 2km, 5km, 10km,
20km, 50km, 100km, 200km. If a location is more than 200km away from any
polygon, a data frame record with all <code>NA</code>s is returned for that
location.
</p>
<p>Missing or invalid values in the incoming <code>longitude</code> or <code>latitude</code>
vectors result in records with all <code>NA</code>s at those positions in the
returned data frame.
</p>


<h3>Value</h3>

<p>Dataframe of data.
</p>

<hr>
<h2 id='getSpatialDataDir'>Get package data directory</h2><span id='topic+getSpatialDataDir'></span>

<h3>Description</h3>

<p>Returns the package data directory where spatial data is located.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getSpatialDataDir()
</code></pre>


<h3>Value</h3>

<p>Absolute path string.
</p>


<h3>See Also</h3>

<p>dataDir
</p>
<p>setSpatialDataDir
</p>

<hr>
<h2 id='getState'>Return state names at specified locations</h2><span id='topic+getState'></span>

<h3>Description</h3>

<p>Uses spatial comparison to determine which 'state' polygons the
locations fall into and returns the ISO 3166-2 2-character state code
strings for those polygons.
</p>
<p>Specification of <code>countryCodes</code> limits spatial searching to the
specified countries and greatly improves performance.
</p>
<p>If <code>allData = TRUE</code>, additional data is returned.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getState(
  longitude = NULL,
  latitude = NULL,
  datasetName = "NaturalEarthAdm1",
  countryCodes = NULL,
  allData = FALSE,
  useBuffering = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="getState_+3A_longitude">longitude</code></td>
<td>
<p>Vector of longitudes in decimal degrees East.</p>
</td></tr>
<tr><td><code id="getState_+3A_latitude">latitude</code></td>
<td>
<p>Vector of latitudes in decimal degrees North.</p>
</td></tr>
<tr><td><code id="getState_+3A_datasetname">datasetName</code></td>
<td>
<p>Name of spatial dataset to use.</p>
</td></tr>
<tr><td><code id="getState_+3A_countrycodes">countryCodes</code></td>
<td>
<p>Vector of ISO 3166-1 alpha-2 country codes.</p>
</td></tr>
<tr><td><code id="getState_+3A_alldata">allData</code></td>
<td>
<p>Logical specifying whether a full dataframe should be returned.</p>
</td></tr>
<tr><td><code id="getState_+3A_usebuffering">useBuffering</code></td>
<td>
<p>Logical flag specifying the use of location buffering to
find the nearest polygon if no target polygon is found.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Vector of English language state names.
</p>


<h3>See Also</h3>

<p>getSpatialData
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(MazamaSpatialUtils)
setSpatialData("~/Data/Spatial_0.8")

loadSpatialData("NaturalEarthAdm1")

longitude &lt;- seq(-140, -90)
latitude &lt;- seq(20, 70)
getState(longitude, latitude)

## End(Not run)

</code></pre>

<hr>
<h2 id='getStateCode'>Return state ISO codes at specified locations</h2><span id='topic+getStateCode'></span>

<h3>Description</h3>

<p>Uses spatial comparison to determine which 'state' polygons the
locations fall into and returns the ISO 3166 2-character state code
strings for those polygons.
</p>
<p>Specification of <code>countryCodes</code> limits spatial searching to the
specified countries and greatly improves performance.
</p>
<p>If <code>allData = TRUE</code>, additional data is returned.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getStateCode(
  longitude = NULL,
  latitude = NULL,
  datasetName = "NaturalEarthAdm1",
  countryCodes = NULL,
  allData = FALSE,
  useBuffering = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="getStateCode_+3A_longitude">longitude</code></td>
<td>
<p>Vector of longitudes in decimal degrees East.</p>
</td></tr>
<tr><td><code id="getStateCode_+3A_latitude">latitude</code></td>
<td>
<p>Vector of latitudes in decimal degrees North.</p>
</td></tr>
<tr><td><code id="getStateCode_+3A_datasetname">datasetName</code></td>
<td>
<p>Name of spatial dataset to use.</p>
</td></tr>
<tr><td><code id="getStateCode_+3A_countrycodes">countryCodes</code></td>
<td>
<p>Vector of ISO 3166-1 alpha-2 country codes.</p>
</td></tr>
<tr><td><code id="getStateCode_+3A_alldata">allData</code></td>
<td>
<p>Logical specifying whether a full dataframe should be returned.</p>
</td></tr>
<tr><td><code id="getStateCode_+3A_usebuffering">useBuffering</code></td>
<td>
<p>Logical flag specifying the use of location buffering to
find the nearest polygon if no target polygon is found.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Vector of ISO-3166-2 alpha-2 state codes.
</p>


<h3>See Also</h3>

<p>getSpatialData
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(MazamaSpatialUtils)
setSpatialData("~/Data/Spatial_0.8")

loadSpatialData("NaturalEarthAdm1")

longitude &lt;- seq(-140, -90)
latitude &lt;- seq(20, 70)
getStateCode(longitude, latitude)

## End(Not run)
</code></pre>

<hr>
<h2 id='getStateName'>Return state names at specified locations</h2><span id='topic+getStateName'></span>

<h3>Description</h3>

<p>Uses spatial comparison to determine which 'state' polygons the
locations fall into and returns the ISO 3166-2 2-character state code
strings for those polygons.
</p>
<p>Specification of <code>countryCodes</code> limits spatial searching to the
specified countries and greatly improves performance.
</p>
<p>If <code>allData = TRUE</code>, additional data is returned.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getStateName(
  longitude = NULL,
  latitude = NULL,
  datasetName = "NaturalEarthAdm1",
  countryCodes = NULL,
  allData = FALSE,
  useBuffering = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="getStateName_+3A_longitude">longitude</code></td>
<td>
<p>Vector of longitudes in decimal degrees East.</p>
</td></tr>
<tr><td><code id="getStateName_+3A_latitude">latitude</code></td>
<td>
<p>Vector of latitudes in decimal degrees North.</p>
</td></tr>
<tr><td><code id="getStateName_+3A_datasetname">datasetName</code></td>
<td>
<p>Name of spatial dataset to use.</p>
</td></tr>
<tr><td><code id="getStateName_+3A_countrycodes">countryCodes</code></td>
<td>
<p>Vector of ISO 3166-1 alpha-2 country codes.</p>
</td></tr>
<tr><td><code id="getStateName_+3A_alldata">allData</code></td>
<td>
<p>Logical specifying whether a full dataframe should be returned.</p>
</td></tr>
<tr><td><code id="getStateName_+3A_usebuffering">useBuffering</code></td>
<td>
<p>Logical flag specifying the use of location buffering to
find the nearest polygon if no target polygon is found.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Vector of English language state names.
</p>


<h3>See Also</h3>

<p>getSpatialData
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(MazamaSpatialUtils)
setSpatialData("~/Data/Spatial_0.8")

loadSpatialData("NaturalEarthAdm1")

longitude &lt;- seq(-140, -90)
latitude &lt;- seq(20, 70)
getStateName(longitude, latitude)

## End(Not run)
</code></pre>

<hr>
<h2 id='getTimezone'>Return Olson timezones at specified locations</h2><span id='topic+getTimezone'></span>

<h3>Description</h3>

<p>Uses spatial comparison to determine which timezone polygons the
locations fall into and returns the Olson timezone strings for those polygons.
</p>
<p>Specification of <code>countryCodes</code> limits spatial searching to the
specified countries and greatly improves performance.
</p>
<p>If <code>allData=TRUE</code>, additional data is returned.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getTimezone(
  longitude = NULL,
  latitude = NULL,
  datasetName = "SimpleTimezones",
  countryCodes = NULL,
  allData = FALSE,
  useBuffering = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="getTimezone_+3A_longitude">longitude</code></td>
<td>
<p>Vector of longitudes in decimal degrees East.</p>
</td></tr>
<tr><td><code id="getTimezone_+3A_latitude">latitude</code></td>
<td>
<p>Vector of latitudes in decimal degrees North.</p>
</td></tr>
<tr><td><code id="getTimezone_+3A_datasetname">datasetName</code></td>
<td>
<p>Name of spatial dataset to use.</p>
</td></tr>
<tr><td><code id="getTimezone_+3A_countrycodes">countryCodes</code></td>
<td>
<p>Vector of ISO 3166-1 alpha-2 country codes.</p>
</td></tr>
<tr><td><code id="getTimezone_+3A_alldata">allData</code></td>
<td>
<p>Logical specifying whether a full dataframe should be returned.</p>
</td></tr>
<tr><td><code id="getTimezone_+3A_usebuffering">useBuffering</code></td>
<td>
<p>Logical flag specifying the use of location buffering to
find the nearest polygon if no target polygon is found.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Vector of Olson timezones.
</p>


<h3>References</h3>

<p><a href="https://github.com/evansiroky/timezone-boundary-builder">https://github.com/evansiroky/timezone-boundary-builder</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(MazamaSpatialUtils)

longitude &lt;- seq(-120, -60, 5)
latitude &lt;- seq(20, 80, 5)

getTimezone(longitude, latitude)

</code></pre>

<hr>
<h2 id='getUSCounty'>Return US county name at specified locations</h2><span id='topic+getUSCounty'></span>

<h3>Description</h3>

<p>Uses spatial comparison to determine which county polygons the
locations fall into and returns the county name strings for those polygons.
</p>
<p>Specification of <code>stateCodes</code> limits spatial searching to the specified
states and greatly improves performance.
</p>
<p>If <code>allData = TRUE</code>, additional data is returned.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getUSCounty(
  longitude = NULL,
  latitude = NULL,
  dataset = "USCensusCounties",
  stateCodes = NULL,
  allData = FALSE,
  useBuffering = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="getUSCounty_+3A_longitude">longitude</code></td>
<td>
<p>Vector of longitudes in decimal degrees East.</p>
</td></tr>
<tr><td><code id="getUSCounty_+3A_latitude">latitude</code></td>
<td>
<p>Vector of latitudes in decimal degrees North.</p>
</td></tr>
<tr><td><code id="getUSCounty_+3A_dataset">dataset</code></td>
<td>
<p>Name of spatial dataset to use.</p>
</td></tr>
<tr><td><code id="getUSCounty_+3A_statecodes">stateCodes</code></td>
<td>
<p>Vector of US state codes used to limit the search.</p>
</td></tr>
<tr><td><code id="getUSCounty_+3A_alldata">allData</code></td>
<td>
<p>Logical specifying whether a full dataframe should be returned.</p>
</td></tr>
<tr><td><code id="getUSCounty_+3A_usebuffering">useBuffering</code></td>
<td>
<p>Logical flag specifying the use of location buffering to
find the nearest polygon if no target polygon is found.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Vector of English language county names.
</p>


<h3>References</h3>

<p>http://www.naturalearthdata.com/downloads/10m-cultural-vectors/
</p>


<h3>See Also</h3>

<p>getSpatialData
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(MazamaSpatialUtils)
setSpatialDataDir("~/Data/Spatial_0.8")

loadSpatialData("USCensusCounties")

longitude &lt;- seq(-140, -90)
latitude &lt;- seq(20, 70)
getUSCounty(longitude, latitude)

## End(Not run)

</code></pre>

<hr>
<h2 id='getVariable'>Return SFDF variable at specified locations</h2><span id='topic+getVariable'></span>

<h3>Description</h3>

<p>Uses spatial comparison to determine which polygons the
locations fall into and returns the variable associated with those polygons.
</p>
<p>If <code>allData = TRUE</code>, the entire dataframe is returned.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getVariable(
  longitude = NULL,
  latitude = NULL,
  dataset = NULL,
  variable = NULL,
  countryCodes = NULL,
  allData = FALSE,
  useBuffering = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="getVariable_+3A_longitude">longitude</code></td>
<td>
<p>Vector of longitudes in decimal degrees East.</p>
</td></tr>
<tr><td><code id="getVariable_+3A_latitude">latitude</code></td>
<td>
<p>Vector of latitudes in decimal degrees North.</p>
</td></tr>
<tr><td><code id="getVariable_+3A_dataset">dataset</code></td>
<td>
<p>Name of spatial dataset to use.</p>
</td></tr>
<tr><td><code id="getVariable_+3A_variable">variable</code></td>
<td>
<p>Name of dataframe column to be returned.</p>
</td></tr>
<tr><td><code id="getVariable_+3A_countrycodes">countryCodes</code></td>
<td>
<p>Vector of ISO 3166-1 alpha-2 country codes.</p>
</td></tr>
<tr><td><code id="getVariable_+3A_alldata">allData</code></td>
<td>
<p>Logical specifying whether a full dataframe should be returned.</p>
</td></tr>
<tr><td><code id="getVariable_+3A_usebuffering">useBuffering</code></td>
<td>
<p>Logical flag specifying the use of location buffering to
find the nearest polygon if no target polygon is found.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Vector or dataframe.
</p>


<h3>See Also</h3>

<p>getSpatialData
</p>

<hr>
<h2 id='installedSpatialData'>List locally installed spatial datasets</h2><span id='topic+installedSpatialData'></span>

<h3>Description</h3>

<p>Searches the directory set with <code><a href="#topic+setSpatialDataDir">setSpatialDataDir</a></code>
for locally installed spatial data and returns a list of dataset names that
can be used with <code><a href="#topic+loadSpatialData">loadSpatialData</a></code>.
</p>
<p>If <code>verbose = TRUE</code>, a brief description is provided for each locally
installed dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>installedSpatialData(verbose = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="installedSpatialData_+3A_verbose">verbose</code></td>
<td>
<p>Logical specifying whether or not to print dataset descriptions.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Invisibly returns a vector of dataset names().
</p>

<hr>
<h2 id='installSpatialData'>Install spatial datasets</h2><span id='topic+installSpatialData'></span>

<h3>Description</h3>

<p>Install spatial datasets found  at <code>url</code> into the directory
previously set with <code>setSpatialDataDir()</code>.
</p>
<p>If <code>pattern = NULL</code> (default), available datasets will be displalyed..
</p>


<h3>Usage</h3>

<pre><code class='language-R'>installSpatialData(
  dataset = NULL,
  urlBase = "http://data.mazamascience.com/MazamaSpatialUtils/Spatial_0.8"
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="installSpatialData_+3A_dataset">dataset</code></td>
<td>
<p>Name of spatial dataset to install.</p>
</td></tr>
<tr><td><code id="installSpatialData_+3A_urlbase">urlBase</code></td>
<td>
<p>Location of spatial data files.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>If <code>pattern = NULL</code> a vector of dataset names.
</p>

<hr>
<h2 id='iso2ToIso3'>Convert from ISO2 to ISO3 country codes</h2><span id='topic+iso2ToIso3'></span>

<h3>Description</h3>

<p>Converts a vector of ISO 3166-1 alpha-2 codes to the
corresponding ISO 3166-1 alpha-3 codes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>iso2ToIso3(countryCodes)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="iso2ToIso3_+3A_countrycodes">countryCodes</code></td>
<td>
<p>Vector of ISO 3166-1 alpha-2 country codes.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of ISO3 country codes
</p>

<hr>
<h2 id='iso3ToIso2'>Convert from ISO3 to ISO2 country codes</h2><span id='topic+iso3ToIso2'></span>

<h3>Description</h3>

<p>Converts a vector of ISO 3166-1 alpha-3 codes to the
corresponding ISO 3166-1 alpha-2 codes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>iso3ToIso2(countryCodes)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="iso3ToIso2_+3A_countrycodes">countryCodes</code></td>
<td>
<p>Vector of ISO 3166-1 alpha-3 codes.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of ISO2 country codes
</p>

<hr>
<h2 id='loadSpatialData'>Load spatial datasets</h2><span id='topic+loadSpatialData'></span>

<h3>Description</h3>

<p>Load datasets found in the directory previously set with
<code>setSpatialDataDir()</code>.
Only files matching <code>pattern</code> will be loaded.
By default, all <code>.rda</code> files are matched.
</p>
<p>Core datastes available for the package include:
</p>

<ul>
<li><p><code>TMWorldBorders</code> &ndash; high resolution country polygons (higher
resolution than <code>SimpleCountries</code>)
</p>
</li>
<li><p><code>NaturalEarthAdm1</code> &ndash; state/province polygons throughout the world
</p>
</li>
<li><p><code>USCensusCounties</code> &ndash; county polygons in the United States
</p>
</li>
<li><p><code>WorldTimezones</code> &ndash; high resolution timezone polygons (higher
resolution than <code>SimpleTimezones</code>)
</p>
</li></ul>

<p>These can be installed with <code>installSpatialData()</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>loadSpatialData(pattern = "*\\.rda")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="loadSpatialData_+3A_pattern">pattern</code></td>
<td>
<p>Regular expression used to match file names.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Invisibly returns a vector of spatial dataset names loaded into the
global environment.
</p>


<h3>See Also</h3>

<p>setSpatialDataDir
</p>
<p>installSpatialData
</p>

<hr>
<h2 id='MazamaSpatialUtils'>Mazama Science spatial data and utility functions.</h2><span id='topic+MazamaSpatialUtils'></span>

<h3>Description</h3>

<p>This package contains code to convert various spatial datasets
into .rda files with uniformly named identifiers including:
</p>

<ul>
<li><p> countryCode &ndash; ISO 3166-1 alpha-2
</p>
</li>
<li><p> countryName &ndash; Country name
</p>
</li>
<li><p> stateCode &ndash; ISO 3166-2 alpha-2
</p>
</li>
<li><p> timezone &ndash; Olson timezone
</p>
</li>
<li><p> longitude &ndash; degrees East
</p>
</li>
<li><p> latitude &ndash; degrees North
</p>
</li>
<li><p> area &ndash; m^2
</p>
</li></ul>

<p>The only field guaranteed
to exist in every dataset is <code>countryCode</code>.
</p>
<p>The following additional standards are applied during the data conversion process:
</p>

<ul>
<li><p> all spatial data are converted to a purely geographic North American projection (<a href="https://epsg.io/4269">https://epsg.io/4269</a>) 
</p>
</li>
<li><p> no duplicated rows in the dataframe (conversion to <strong>multi-</strong>polygons) 
</p>
</li>
<li><p> lowerCamelCase, human readable names replace original parameter names 
</p>
</li>
<li><p> redundant, software-internal or otherwise unuseful data columns may be dropped 
</p>
</li>
<li><p> latitude and longitude of polygon centroids may be added 
</p>
</li></ul>

<p>Utility functions allow users to determine the country, state, county and timezones
associated with a set of locations, _e.g._ environmental monitoring sites.
</p>
<p>The uniformity of identifiers in the spatial datasets also makes it easy to generate maps
with data from any dataset that uses standard ISO codes for countries or states.
</p>

<hr>
<h2 id='setSpatialDataDir'>Set package data directory</h2><span id='topic+setSpatialDataDir'></span>

<h3>Description</h3>

<p>Sets the package data directory where spatial data is located.
If the directory does not exist, it will be created.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>setSpatialDataDir(dataDir)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="setSpatialDataDir_+3A_datadir">dataDir</code></td>
<td>
<p>Directory where spatial datasets are created.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Silently returns previous value of data directory.
</p>


<h3>See Also</h3>

<p>SpatialDataDir
</p>
<p>getSpatialDataDir
</p>

<hr>
<h2 id='SimpleCountries'>Simplified spatial dataset of country boundaries.</h2><span id='topic+SimpleCountries'></span>

<h3>Description</h3>

<p>SimpleCountries is a simplified world borders dataset suitable
for global maps and quick spatial searches. This dataset is distributed with
the package and is can be used with <code>getCountry()</code>,
<code>getCountryCode()</code> and <code>getCountryName()</code> when restricting searches
to land-based locations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SimpleCountries
</code></pre>


<h3>Format</h3>

<p>A simple features data frame with 246 records and 7 columns of data.
</p>


<h3>Details</h3>

<p>This dataset is equivalent to TMWorldBordersSimple but with fewer columns of data.
</p>


<h3>See Also</h3>

<p>convertTMWorldBordersSimple
</p>
<p>This dataset was generated on 2022-11-04 by running:
</p>
<pre>
library(MazamaSpatialUtils)
setSpatialDataDir("~/Data/Spatial_0.8")

convertTMWorldBorders()

loadSpatialData("NaturalEarthAdm0_05")

columnNames &lt;- c("countryCode", "countryName", "ISO3", "FIPS",
                 "UN_region", "polygonID")
SimpleCountries &lt;- NaturalEarthAdm0_05[, columnNames]
save(SimpleCountries, file = "data/SimpleCountries.rda")
</pre>

<hr>
<h2 id='SimpleCountriesEEZ'>Simplified spatial dataset of EEZ/country combined boundaries.</h2><span id='topic+SimpleCountriesEEZ'></span>

<h3>Description</h3>

<p>SimpleCountriesEEZ is a simplified world borders dataset with a
200 mile coastal buffer corresponding to Exclusive Economic Zones, suitable for
quick spatial searches. This dataset is distributed with the package and is
used by default in <code>getCountry()</code>, <code>getCountryCode()</code> and
<code>getCountryName()</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SimpleCountriesEEZ
</code></pre>


<h3>Format</h3>

<p>A simple features data frame with 319 records and 5 columns of data.
</p>


<h3>Details</h3>

<p>This dataset is equivalent to EEZCountries but with fewer columns of data.
</p>


<h3>See Also</h3>

<p>convertEEZCountries
</p>
<p>This dataset was generated on 2022-11-03 by running:
</p>
<pre>
library(MazamaSpatialUtils)
setSpatialDataDir("~/Data/Spatial_0.8")

convertEEZCountries()

loadSpatialData("EEZCountries_05")

SimpleCountriesEEZ &lt;- EEZCountries_05[,c("countryCode", "countryName", "polygonID")]
save(SimpleCountriesEEZ, file = "data/SimpleCountriesEEZ.rda")
</pre>

<hr>
<h2 id='SimpleTimezones'>Simplified spatial dataset of world timezones.</h2><span id='topic+SimpleTimezones'></span>

<h3>Description</h3>

<p>This dataset is used by default in the <code>getTimezones()</code>
function and contains the following columns of data:
</p>

<ul>
<li><p><code>timezone</code> &ndash; Olson timezone
</p>
</li>
<li><p><code>UTC_offset</code> &ndash; offset from UTC (hours)
</p>
</li>
<li><p><code>UTC_DST_offset</code> &ndash; offset from UTC during daylight savings (hours)
</p>
</li>
<li><p><code>countryCode</code> &ndash; ISO 3166-1 alpha-2 country code
</p>
</li>
<li><p><code>longitude</code> &ndash; longitude of the timezone polygon centroid
</p>
</li>
<li><p><code>latitude</code> &ndash; longitude of the timezone polygon centroid
</p>
</li>
<li><p><code>status</code> &ndash; one of 'Canonical', 'Alias' or 'Deprecated'
</p>
</li>
<li><p><code>notes</code> &ndash; typically specifying the target of an 'Alias'
</p>
</li>
<li><p><code>polygonID</code> &ndash; unique identifier (= <code>timezone</code>)
</p>
</li></ul>

<p>This dataset was generated on 2022-11-03 by running:
</p>
<pre>
library(MazamaSpatialUtils)
setSpatialDataDir("~/Data/Spatial_0.8")

convertOSMTimezones()

loadSpatialData("OSMTimezones_02")

SimpleTimezones &lt;- OSMTimezones_02
save(SimpleTimezones, file = "data/SimpleTimezones.rda")
</pre>


<h3>Usage</h3>

<pre><code class='language-R'>SimpleTimezones
</code></pre>


<h3>Format</h3>

<p>A simple features data frame with 423 records and 9 columns of data.
</p>

<hr>
<h2 id='simplify'>Simplify simple features data frame</h2><span id='topic+simplify'></span>

<h3>Description</h3>

<p>Simplify a simple features dataframe. This is a convenience
wrapper for <code><a href="rmapshaper.html#topic+ms_simplify">ms_simplify</a></code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simplify(SFDF, keep = 0.05, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="simplify_+3A_sfdf">SFDF</code></td>
<td>
<p>Object of class simple features data frame.</p>
</td></tr>
<tr><td><code id="simplify_+3A_keep">keep</code></td>
<td>
<p>Proportion of points to retain (0-1; default 0.05)</p>
</td></tr>
<tr><td><code id="simplify_+3A_...">...</code></td>
<td>
<p>Arguments passed to <code>rmapshaper::ms_simplify()</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>A simplified simple features dataframe.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(MazamaSpatialUtils)
FR &lt;-
  SimpleCountries %&gt;%
  dplyr::filter(countryCode == "FR")
par(mfrow = c(3, 3), mar = c(1, 1, 3, 1))
for (i in 9:1) {
  keep &lt;- 0.1 * i
  geom &lt;-
    FR %&gt;%
    simplify(keep) %&gt;%
    sf::st_geometry()
  plot(geom, main=paste0("keep = ", keep))
}
layout(1)
par(mar = c(5,4,4,2)+.1)

## End(Not run)
</code></pre>

<hr>
<h2 id='simplifyAndSave'>Save simplified versions of a spatial features dataframe</h2><span id='topic+simplifyAndSave'></span>

<h3>Description</h3>

<p>Creates and saves  &quot;_05&quot;, _02&quot; and &quot;_01&quot;
versions of <code>SFDF</code> that are simplified to 5%, 2% and 1%.
.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simplifyAndSave(
  SFDF = NULL,
  datasetName = NULL,
  uniqueIdentifier = NULL,
  dataDir = getSpatialDataDir()
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="simplifyAndSave_+3A_sfdf">SFDF</code></td>
<td>
<p>Simple features dataframe.</p>
</td></tr>
<tr><td><code id="simplifyAndSave_+3A_datasetname">datasetName</code></td>
<td>
<p>Base name used for <code>SFDF</code>.</p>
</td></tr>
<tr><td><code id="simplifyAndSave_+3A_uniqueidentifier">uniqueIdentifier</code></td>
<td>
<p>Name of column containing unique polygon identifiers.</p>
</td></tr>
<tr><td><code id="simplifyAndSave_+3A_datadir">dataDir</code></td>
<td>
<p>Spatial data directory set with <code>setSpatialDataDir()</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Writes data files to disk.
</p>

<hr>
<h2 id='SpatialDataDir'>Directory for spatial data</h2><span id='topic+SpatialDataDir'></span>

<h3>Description</h3>

<p>This package maintains an internal directory location which users can set
using <code><a href="#topic+setSpatialDataDir">setSpatialDataDir</a></code>. All package functions use this directory whenever datasets
are created or loaded.
</p>
<p>The default setting when the package is loaded is <code>getwd()</code>.
</p>


<h3>Format</h3>

<p>Absolute path string.
</p>


<h3>See Also</h3>

<p>getSpatialDataDir
</p>
<p>setSpatialDataDir
</p>

<hr>
<h2 id='stateToCode'>Convert state names to state codes</h2><span id='topic+stateToCode'></span>

<h3>Description</h3>

<p>Converts a vector of state names to an ISO 3166-2 two character
state codes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>stateToCode(stateNames, countryCodes = NULL, dataset = "NaturalEarthAdm1")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="stateToCode_+3A_statenames">stateNames</code></td>
<td>
<p>Vector of state names to be converted.</p>
</td></tr>
<tr><td><code id="stateToCode_+3A_countrycodes">countryCodes</code></td>
<td>
<p>Vector of ISO 3166-2 alpha-2 country codes the state might be found in.</p>
</td></tr>
<tr><td><code id="stateToCode_+3A_dataset">dataset</code></td>
<td>
<p>Name of dataset containing state-level identifiers.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For this function to work, you must install and load the
&quot;NaturalEarthAdm1&quot; dataset.
</p>


<h3>Value</h3>

<p>A vector of ISO 3166-2 codes or NA.
</p>


<h3>See Also</h3>

<p>convertNaturalEarthAdm1
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
stateToCode("Washington")
stateToCode("Barcelona")
stateToCode("Shandong")

## End(Not run)
</code></pre>

<hr>
<h2 id='summarizeByPolygon'>Summarize values by polygon</h2><span id='topic+summarizeByPolygon'></span>

<h3>Description</h3>

<p>Given vectors of longitudes, latitudes and values, this function
will summarize given values by spatial polygon using the <code>FUN</code> and return
a dataframe with polygon IDs and summary values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>summarizeByPolygon(
  longitude,
  latitude,
  value,
  SFDF,
  useBuffering = FALSE,
  FUN,
  varName = "summaryValue"
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="summarizeByPolygon_+3A_longitude">longitude</code></td>
<td>
<p>vector of longitudes</p>
</td></tr>
<tr><td><code id="summarizeByPolygon_+3A_latitude">latitude</code></td>
<td>
<p>vector of latitudes</p>
</td></tr>
<tr><td><code id="summarizeByPolygon_+3A_value">value</code></td>
<td>
<p>vector of values at the locations of interest</p>
</td></tr>
<tr><td><code id="summarizeByPolygon_+3A_sfdf">SFDF</code></td>
<td>
<p>simple features data frame with polygons used for aggregating</p>
</td></tr>
<tr><td><code id="summarizeByPolygon_+3A_usebuffering">useBuffering</code></td>
<td>
<p>passed to MazamaSpatialUtils::getSpatialData()</p>
</td></tr>
<tr><td><code id="summarizeByPolygon_+3A_fun">FUN</code></td>
<td>
<p>function to be applied while summarizing (e.g. mean, max, etc.)</p>
</td></tr>
<tr><td><code id="summarizeByPolygon_+3A_varname">varName</code></td>
<td>
<p>variable name assigned to the summary variable</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A dataframe with the same rows as 'SFDF' but containing only two
columns: 'polygonID' and the summary value.
</p>


<h3>Note</h3>

<p>This function has not been thoroughly tested and is included
in the package for experimental use only.
</p>

<hr>
<h2 id='US_52'>US state codes</h2><span id='topic+US_52'></span>

<h3>Description</h3>

<p>State codes for the 50 states +DC +PR (Puerto Rico).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>US_52
</code></pre>


<h3>Format</h3>

<p>A vector with 52 elements
</p>

<hr>
<h2 id='US_countyCodes'>Dataframe of US county codes</h2><span id='topic+US_countyCodes'></span>

<h3>Description</h3>

<p>US_countyCodes The following columns for US states and territories:
</p>

<ul>
<li><p><code>stateCode</code> &ndash; ISO 3166-2 alpha-2
</p>
</li>
<li><p><code>stateFIPS</code> &ndash; 2-digit FIPS code
</p>
</li>
<li><p><code>countyName</code> &ndash; English language county name
</p>
</li>
<li><p><code>countyFIPS</code> &ndash; five-digit FIPS code (2-digit state and 3-digit
county combined to create a unique identifier)
</p>
</li></ul>

<p>This dataset was generated on 2022-11-04 by running:
</p>
<pre>
library(MazamaSpatialUtils)
setSpatialDataDir("~/Data/Spatial_0.8")
loadSpatialData("USCensusCounties_02")

US_countyCodes &lt;-
  USCensusCounties_02 
  dplyr::select(stateCode, stateFIPS, countyName, countyFIPS)

US_countyCodes$geometry &lt;- NULL

save(US_countyCodes, file = "data/US_countyCodes.rda")
</pre>


<h3>Usage</h3>

<pre><code class='language-R'>US_countyCodes
</code></pre>


<h3>Format</h3>

<p>A dataframe with 3197 rows and 4 columns of data.
</p>

<hr>
<h2 id='US_countyConversion'>Conversion functions for US county names and FIPS codes.</h2><span id='topic+US_countyConversion'></span><span id='topic+US_countyFIPSToName'></span><span id='topic+US_countyNameToFIPS'></span>

<h3>Description</h3>

<p>Converts a vector of US county names or FIPS codes from one
system to another returning <code>NA</code> where no match is found.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>US_countyNameToFIPS(state = NULL, countyName = NULL)

US_countyFIPSToName(state = NULL, countyFIPS = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="US_countyConversion_+3A_state">state</code></td>
<td>
<p>Vector of state codes, names or FIPS codes. Values will be
evaluated to determine the type of input.</p>
</td></tr>
<tr><td><code id="US_countyConversion_+3A_countyname">countyName</code></td>
<td>
<p>Vector of English language county names.</p>
</td></tr>
<tr><td><code id="US_countyConversion_+3A_countyfips">countyFIPS</code></td>
<td>
<p>Vector of two-digit FIPS codes.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of US county names or FIPS codes.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(MazamaSpatialUtils)

US_countyNameToFIPS("Washington", "King")

# If a single state is provided, it will be recycled
US_countyNameToFIPS("Washington", c("King", "Okanogan"))

# Normally, equal length vectors are provided
US_countyNameToFIPS(c("WA", "WA"), c("King", "Okanogan"))

# You cannot mix codes!
US_countyNameToFIPS(c("WA", "Washington"), c("King", "Okanogan"))

# No 'Okanogan' county in Texas
US_countyNameToFIPS(c("WA", "TX"), c("King", "Okanogan"))

# But there is a 'King' county in Texas
US_countyNameToFIPS(c("TX", "WA"), c("King", "Okanogan"))
US_countyNameToFIPS(c("TX", "WA"), c("King", "King"))

# The US_countyFIPSToName() function is included for symmetry but a
# more typical usage of a 5-digit county FIPS would be to extract it from
# the US_countyCodes package dataset:

US_countyCodes %&gt;% dplyr::filter(countyFIPS == 53033)

</code></pre>

<hr>
<h2 id='US_stateCodes'>Dataframe of US state codes</h2><span id='topic+US_stateCodes'></span>

<h3>Description</h3>

<p>US_stateCodes the following columns for US states and territories:
</p>

<ul>
<li><p><code>stateName</code> &ndash; English language state name
</p>
</li>
<li><p><code>stateCode</code> &ndash; ISO 3166-2 alpha-2
</p>
</li>
<li><p><code>stateFIPS</code> &ndash; two-digit FIPS code
</p>
</li></ul>

<p>This dataset was generated on 2020-06-11 by running:
</p>



<h3>Usage</h3>

<pre><code class='language-R'>US_stateCodes
</code></pre>


<h3>Format</h3>

<p>A dataframe with 52 rows and 3 columns of data.
</p>

<hr>
<h2 id='US_stateConversion'>Conversion functions for US state names, codes and FIPS codes.</h2><span id='topic+US_stateConversion'></span><span id='topic+US_stateCodeToName'></span><span id='topic+US_stateCodeToFIPS'></span><span id='topic+US_stateFIPSToName'></span><span id='topic+US_stateFIPSToCode'></span><span id='topic+US_stateNameToCode'></span><span id='topic+US_stateNameToFIPS'></span>

<h3>Description</h3>

<p>Converts a vector of US state names or codes from one system to
another returning <code>NA</code> where no match is found.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>US_stateCodeToName(stateCode = NULL)

US_stateCodeToFIPS(stateCode = NULL)

US_stateFIPSToName(stateFIPS = NULL)

US_stateFIPSToCode(stateFIPS = NULL)

US_stateNameToCode(stateName = NULL)

US_stateNameToFIPS(stateName = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="US_stateConversion_+3A_statecode">stateCode</code></td>
<td>
<p>Vector of ISO 3166-2 alpha-2 codes.</p>
</td></tr>
<tr><td><code id="US_stateConversion_+3A_statefips">stateFIPS</code></td>
<td>
<p>Vector of two-digit FIPS codes.</p>
</td></tr>
<tr><td><code id="US_stateConversion_+3A_statename">stateName</code></td>
<td>
<p>Vector of English language state names.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of US state names or codes.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(MazamaSpatialUtils)

US_stateNameToCode("Washington")
US_stateNameToFIPS("Washington")

postalCodes &lt;- sample(US_stateCodes$stateCode, 30)

data.frame(
  name = US_stateCodeToName(postalCodes),
  code = postalCodes,
  FIPS = US_stateCodeToFIPS(postalCodes)
)

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
