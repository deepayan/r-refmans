<!DOCTYPE html><html><head><title>Help for package recalibratiNN</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {recalibratiNN}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#gg_CD_global'><p>Plots the cumulative distributions of PIT-values for global calibration diagnostics.</p></a></li>
<li><a href='#gg_CD_local'><p>Plots the cumulative distributions of PIT-values for local calibration diagnostics.</p></a></li>
<li><a href='#gg_PIT_global'><p>Plots Density Distributions of PIT-values for Global Calibration Diagnostics</p></a></li>
<li><a href='#gg_PIT_local'><p>Plots Density Distributions of PIT-values for Global Calibration Diagnostics</p></a></li>
<li><a href='#PIT_global'><p>Obtain the PIT-values of a Model</p></a></li>
<li><a href='#PIT_local'><p>Obtain local PIT-values from a model</p></a></li>
<li><a href='#recalibrate'><p>Generates Recalibrated Samples of the Predictive Distribution</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Title:</td>
<td>Quantile Recalibration for Regression Models</td>
</tr>
<tr>
<td>Version:</td>
<td>0.3.0</td>
</tr>
<tr>
<td>Description:</td>
<td>Enables the diagnostics and enhancement of regression model calibration.It offers both global and local visualization tools for calibration diagnostics and provides one recalibration method: Torres R, Nott DJ, Sisson SA, Rodrigues T, Reis JG, Rodrigues GS (2024) &lt;<a href="https://doi.org/10.48550%2FarXiv.2403.05756">doi:10.48550/arXiv.2403.05756</a>&gt;. The method leverages on Probabilistic Integral Transform (PIT) values to both evaluate and perform the calibration of statistical models. For a more detailed description of the package, please refer to the bachelor's thesis available bellow.  </td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.1</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://bdm.unb.br/handle/10483/38504">https://bdm.unb.br/handle/10483/38504</a>,
<a href="https://github.com/cmusso86/recalibratiNN">https://github.com/cmusso86/recalibratiNN</a>,
<a href="https://cmusso86.github.io/recalibratiNN/">https://cmusso86.github.io/recalibratiNN/</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/cmusso86/recalibratiNN/issues">https://github.com/cmusso86/recalibratiNN/issues</a></td>
</tr>
<tr>
<td>Imports:</td>
<td>stats(&ge; 3.0.0), dplyr(&ge; 1.0.0), ggplot2 (&ge; 3.0.0), purrr(&ge;
1.0.0), RANN(&ge; 2.0.0), tidyr(&ge; 1.0.0), tibble(&ge; 3.0.0), glue
(&ge; 1.0.0), magrittr(&ge; 2.0.0), Hmisc (&ge; 5.0.0), Rdpack</td>
</tr>
<tr>
<td>RdMacros:</td>
<td>Rdpack</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, rmarkdown, testthat (&ge; 3.0.0)</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-07-06 00:14:17 UTC; carolinamusso</td>
</tr>
<tr>
<td>Author:</td>
<td>Carolina Musso <a href="https://orcid.org/0000-0002-8107-6458"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cre, cph],
  Ricardo Torres <a href="https://orcid.org/0009-0000-9100-7125"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cph],
  Jo√£o Reis [aut, cph],
  Guilherme Rodrigues
    <a href="https://orcid.org/0000-0003-2009-4844"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut, ths,
    cph]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Carolina Musso &lt;cmusso86@gmail.com&gt;</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0)</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-07-06 02:10:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='gg_CD_global'>Plots the cumulative distributions of PIT-values for global calibration diagnostics.</h2><span id='topic+gg_CD_global'></span>

<h3>Description</h3>

<p>Visualizes the predicted vs. empirical cumulative distributions of PIT-values using ggplot.
</p>
<p>This function creates a ggplot graph that compares the cumulative distributions of
predicted and empirical Probability Integral Transform (PIT) values. It shows the calibration quality of a regression model by examining how well
the predicted values conform to the observed values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gg_CD_global(pit, ycal, yhat, mse)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gg_CD_global_+3A_pit">pit</code></td>
<td>
<p>Numeric vector of global PIT-values. It is recommended to calculate these using the <code>PIT_global()</code> function.</p>
</td></tr>
<tr><td><code id="gg_CD_global_+3A_ycal">ycal</code></td>
<td>
<p>Numeric vector representing the true observations (y-values) of the response variable from the calibration dataset.</p>
</td></tr>
<tr><td><code id="gg_CD_global_+3A_yhat">yhat</code></td>
<td>
<p>Numeric vector of predicted response (y-hat-values) on the calibration dataset.</p>
</td></tr>
<tr><td><code id="gg_CD_global_+3A_mse">mse</code></td>
<td>
<p>Mean Squared Error calculated from the calibration dataset.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code>ggplot</code> object displaying a point graph of the empirical versus predicted cumulative distributions of PIT-values.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
n &lt;- 10000
split &lt;- 0.8

# generating heterocedastic data
mu &lt;- function(x1){
10 + 5*x1^2
}

sigma_v &lt;- function(x1){
30*x1
}

x &lt;- runif(n, 1, 10)
y &lt;- rnorm(n, mu(x), sigma_v(x))

x_train &lt;- x[1:(n*split)]
y_train &lt;- y[1:(n*split)]

x_cal &lt;- x[(n*split+1):n]
y_cal &lt;- y[(n*split+1):n]

model &lt;- lm(y_train ~ x_train)

y_hat &lt;- predict(model, newdata=data.frame(x_train=x_cal))

MSE_cal &lt;- mean((y_hat - y_cal)^2)

pit &lt;- PIT_global( y_cal, y_hat,  MSE_cal)

gg_CD_global(pit,y_cal, y_hat, MSE_cal)


</code></pre>

<hr>
<h2 id='gg_CD_local'>Plots the cumulative distributions of PIT-values for local calibration diagnostics.</h2><span id='topic+gg_CD_local'></span>

<h3>Description</h3>

<p>This function generates a ggplot visual representation to compare the predicted versus empirical
cumulative distributions of Probability Integral Transform (PIT) values at a local level. It is
useful for diagnosing the calibration in different regions within the dataset, since miscalibration patterns may
differ across the covariate space. The function allows for customization of the plot layers to suit specific needs.
For advanced customization of the plot layers, refer to the ggplot2 User Guide.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gg_CD_local(
  pit_local,
  psz = 0.01,
  abline = "black",
  pal = "Set2",
  facet = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gg_CD_local_+3A_pit_local">pit_local</code></td>
<td>
<p>A data frame of local PIT-values, typically obtained from <code>PIT_local()</code>.</p>
</td></tr>
<tr><td><code id="gg_CD_local_+3A_psz">psz</code></td>
<td>
<p>Double indicating the size of the points on the plot. Default is 0.001.</p>
</td></tr>
<tr><td><code id="gg_CD_local_+3A_abline">abline</code></td>
<td>
<p>Color of the diagonal line. Default color is &quot;red&quot;.</p>
</td></tr>
<tr><td><code id="gg_CD_local_+3A_pal">pal</code></td>
<td>
<p>Palette name from RColorBrewer for coloring the plot. Default is &quot;Set2&quot;.</p>
</td></tr>
<tr><td><code id="gg_CD_local_+3A_facet">facet</code></td>
<td>
<p>Logical value indicating if a separate visualization for each subgroup is preferred. Default is FALSE.</p>
</td></tr>
<tr><td><code id="gg_CD_local_+3A_...">...</code></td>
<td>
<p>Additional parameters to customize the ggplot.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This funcion will work with the output of the <code>PIT_local()</code> function, which provides the PIT-values for each subgroup pf the covariate space in the appropriate format.
</p>


<h3>Value</h3>

<p>A <code>ggplot</code> object displaying the cumulative distributions of PIT-values that that can be customized as needed.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
n &lt;- 10000
split &lt;- 0.8

mu &lt;- function(x1){
10 + 5*x1^2
}

sigma_v &lt;- function(x1){
30*x1
}


x &lt;- runif(n, 1, 10)
y &lt;- rnorm(n, mu(x), sigma_v(x))

x_train &lt;- x[1:(n*split)]
y_train &lt;- y[1:(n*split)]

x_cal &lt;- x[(n*split+1):n]
y_cal &lt;- y[(n*split+1):n]

model &lt;- lm(y_train ~ x_train)

y_hat &lt;- predict(model, newdata=data.frame(x_train=x_cal))

MSE_cal &lt;- mean((y_hat - y_cal)^2)

pit_local &lt;- PIT_local(xcal = x_cal, ycal=y_cal, yhat=y_hat, mse=MSE_cal)

gg_CD_local(pit_local)
gg_CD_local(pit_local, facet=TRUE)

</code></pre>

<hr>
<h2 id='gg_PIT_global'>Plots Density Distributions of PIT-values for Global Calibration Diagnostics</h2><span id='topic+gg_PIT_global'></span>

<h3>Description</h3>

<p>This function generates a ggplot visual representation of the density of Probability Integral Transform (PIT) values globally.
For advanced customization of the plot layers, refer to the ggplot2 User Guide.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gg_PIT_global(
  pit,
  type = "density",
  fill = "steelblue4",
  alpha = 0.8,
  print_p = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gg_PIT_global_+3A_pit">pit</code></td>
<td>
<p>Vector of PIT values to be plotted.</p>
</td></tr>
<tr><td><code id="gg_PIT_global_+3A_type">type</code></td>
<td>
<p>Character string specifying the type of plot: either &quot;density&quot; or &quot;histogram&quot;.
This determines the representation style of the PIT values.</p>
</td></tr>
<tr><td><code id="gg_PIT_global_+3A_fill">fill</code></td>
<td>
<p>Character string defining the fill color of the plot. Default is 'steelblue4'.</p>
</td></tr>
<tr><td><code id="gg_PIT_global_+3A_alpha">alpha</code></td>
<td>
<p>Numeric value for the opacity of the plot fill, with 0 being fully transparent
and 1 being fully opaque. Default is 0.8.</p>
</td></tr>
<tr><td><code id="gg_PIT_global_+3A_print_p">print_p</code></td>
<td>
<p>Logical value indicating whether to print the p-value from the Kolmogorov-Smirnov test.
Useful for statistical diagnostics.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function also tests the PIT-values for uniformity using the Kolmogorov-Smirnov test (<code>ks.test</code>).
The p-value from the test is printed on the plot if <code>print_p</code> is set to <code>TRUE</code>.
</p>


<h3>Value</h3>

<p>A <code>ggplot</code> object depicting a density graph of PIT-values, which can be further customized.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
n &lt;- 10000
split &lt;- 0.8

# generating heterocedastic data
mu &lt;- function(x1){
10 + 5*x1^2
}

sigma_v &lt;- function(x1){
30*x1
}

x &lt;- runif(n, 1, 10)
y &lt;- rnorm(n, mu(x), sigma_v(x))

x_train &lt;- x[1:(n*split)]
y_train &lt;- y[1:(n*split)]

x_cal &lt;- x[(n*split+1):n]
y_cal &lt;- y[(n*split+1):n]

model &lt;- lm(y_train ~ x_train)

y_hat &lt;- predict(model, newdata=data.frame(x_train=x_cal))

MSE_cal &lt;- mean((y_hat - y_cal)^2)

pit &lt;- PIT_global(ycal=y_cal, yhat=y_hat, mse=MSE_cal)

gg_PIT_global(pit)




</code></pre>

<hr>
<h2 id='gg_PIT_local'>Plots Density Distributions of PIT-values for Global Calibration Diagnostics</h2><span id='topic+gg_PIT_local'></span>

<h3>Description</h3>

<p>A function based on ggplot2 to observe the density of PIT-values locally. It is recommended
to use PIT-values obtained via the <code>PIT_local</code> function from this package or an object of
equivalent format. For advanced customization of the plot layers, refer to the ggplot2 User Guide.This function also tests the PIT-values
for uniformity using the Kolmogorov-Smirnov test (<code>ks.test</code>). The p-value from the test is printed on the plot if <code>facet</code> is set to <code>TRUE</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gg_PIT_local(
  pit_local,
  alpha = 0.4,
  linewidth = 1,
  pal = "Set2",
  facet = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gg_PIT_local_+3A_pit_local">pit_local</code></td>
<td>
<p>A tibble with five columns: &quot;part&quot;, &quot;y_cal&quot;, &quot;y_hat&quot;, &quot;pit&quot;, and &quot;n&quot;,
representing the partitions, calibration data, predicted values, PIT-values,
and the count of observations, respectively.</p>
</td></tr>
<tr><td><code id="gg_PIT_local_+3A_alpha">alpha</code></td>
<td>
<p>Numeric value between 0 and 1 indicating the transparency of the plot fill.
Default is set to 0.4.</p>
</td></tr>
<tr><td><code id="gg_PIT_local_+3A_linewidth">linewidth</code></td>
<td>
<p>Integer specifying the linewidth of the density line. Default is set to 1.</p>
</td></tr>
<tr><td><code id="gg_PIT_local_+3A_pal">pal</code></td>
<td>
<p>A character string specifying the RColorBrewer palette to be used for coloring
the plot. Default is &quot;Set2&quot;.</p>
</td></tr>
<tr><td><code id="gg_PIT_local_+3A_facet">facet</code></td>
<td>
<p>Logical indicating whether to use <code>facet_wrap()</code> to separate different covariate regions
in the visualization. If TRUE, the p-value from the Kolmogorov-Smirnov test is printed on the plot.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code>ggplot</code> object representing the local density distributions of PIT-values,
which can be further customized through ggplot2 functions.
</p>


<h3>Examples</h3>

<pre><code class='language-R'> n &lt;- 10000
 mu &lt;- function(x1){
  10 + 5*x1^2
  }

sigma_v &lt;- function(x1){
 30*x1
}

x &lt;- runif(n, 2, 20)
y &lt;- rnorm(n, mu(x), sigma_v(x))

x_train &lt;- x[1:(n*0.8)]
y_train &lt;- y[1:(n*0.8)]

x_cal &lt;- x[(n*0.8+1):n]
y_cal &lt;- y[(n*0.8+1):n]

model &lt;- lm(y_train ~ x_train)

y_hat &lt;- predict(model, newdata=data.frame(x_train=x_cal))

MSE_cal &lt;- mean((y_hat - y_cal)^2)

pit_local &lt;- PIT_local(xcal = x_cal, ycal=y_cal, yhat=y_hat, mse=MSE_cal)

gg_PIT_local(pit_local)
gg_PIT_local(pit_local, facet=TRUE)
</code></pre>

<hr>
<h2 id='PIT_global'>Obtain the PIT-values of a Model</h2><span id='topic+PIT_global'></span>

<h3>Description</h3>

<p>A function to calculate the Probability Integral Transform (PIT) values for any fitted model
that assumes a normal distribution of the output.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PIT_global(ycal, yhat, mse)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PIT_global_+3A_ycal">ycal</code></td>
<td>
<p>Numeric vector representing the true observations (y-values) of the response variable from the calibration dataset.</p>
</td></tr>
<tr><td><code id="PIT_global_+3A_yhat">yhat</code></td>
<td>
<p>Numeric vector of predicted y-values on the calibration dataset.</p>
</td></tr>
<tr><td><code id="PIT_global_+3A_mse">mse</code></td>
<td>
<p>Mean Squared Error calculated from the calibration dataset.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is designed to work with models that is, even implicitly, assuming normal distribution of the response variable.
This includes, but is not limited to, linear models created using <code>lm()</code> or neural networks utilizing Mean Squared Error as the loss function.
The OLS method is used to minimized residuals in these models. This mathematical optimization will also yield a probabilistic optimization
when normal distribution of the response variable is assumed, since OLS and maximum likelihood estimation are equivalent under normality.
Therefore, in order to render a probabilistic interpretation of the predictions, the model is intrinsically assuming a normal distribution of the response variable.
</p>


<h3>Value</h3>

<p>Returns a numeric vector of PIT-values.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 10000
split &lt;- 0.8

# generating heterocedastic data
mu &lt;- function(x1){
10 + 5*x1^2
}

sigma_v &lt;- function(x1){
30*x1
}


x &lt;- runif(n, 1, 10)
y &lt;- rnorm(n, mu(x), sigma_v(x))

x_train &lt;- x[1:(n*split)]
y_train &lt;- y[1:(n*split)]

x_cal &lt;- x[(n*split+1):n]
y_cal &lt;- y[(n*split+1):n]

model &lt;- lm(y_train ~ x_train)

y_hat &lt;- predict(model, newdata=data.frame(x_train=x_cal))

MSE_cal &lt;- mean((y_hat - y_cal)^2)

PIT_global(ycal=y_cal, yhat=y_hat, mse=MSE_cal)

</code></pre>

<hr>
<h2 id='PIT_local'>Obtain local PIT-values from a model</h2><span id='topic+PIT_local'></span>

<h3>Description</h3>

<p>This function calculates local Probability Integral Transform (PIT) values using localized subregions of the covariate space from the calibration set.
The output will be used for visualization of calibration quality using the <code>gg_CD_local()</code> and <code>gg_PIT_local()</code>function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PIT_local(
  xcal,
  ycal,
  yhat,
  mse,
  clusters = 6,
  p_neighbours = 0.2,
  PIT = PIT_global
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PIT_local_+3A_xcal">xcal</code></td>
<td>
<p>Numeric matrix or data frame of features/covariates (x-values) from the calibration dataset.</p>
</td></tr>
<tr><td><code id="PIT_local_+3A_ycal">ycal</code></td>
<td>
<p>Numeric vector representing the true observations (y-values) of the response variable from the calibration dataset.</p>
</td></tr>
<tr><td><code id="PIT_local_+3A_yhat">yhat</code></td>
<td>
<p>Numeric vector of predicted response (y-hat-values) from the calibration dataset.</p>
</td></tr>
<tr><td><code id="PIT_local_+3A_mse">mse</code></td>
<td>
<p>Mean Squared Error calculated from the calibration dataset.</p>
</td></tr>
<tr><td><code id="PIT_local_+3A_clusters">clusters</code></td>
<td>
<p>Integer specifying the number of partitions to create for local calibration using the k-means method. Default is set to 6.</p>
</td></tr>
<tr><td><code id="PIT_local_+3A_p_neighbours">p_neighbours</code></td>
<td>
<p>Proportion of xcal used to localize neighbors in the KNN method. Default is 0.2.</p>
</td></tr>
<tr><td><code id="PIT_local_+3A_pit">PIT</code></td>
<td>
<p>Function used to calculate the PIT-values. Default is set to <code>PIT_global()</code> from this package, that assumes a Gaussian distribution.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>It calculates local Probability Integral Transform (PIT) values using localized subregions of the covariate space from the calibration set.
The centroids of such regions are derived from a k-means clustering method (from the <code>stats</code> package). The local areas around these centroids
are defined through an approximate k-nearest neighbors method from the <code>RANN</code> package.
Then, for this subregion, the PIT-values are calculated using the <code>PIT</code> function provided by the user. At the moment this function is tested to
work with the <code>PIT_global()</code> function from this package, which assumes a Gaussian distribution. Eventually, it can be used with other distributions.
</p>


<h3>Value</h3>

<p>A tibble with five columns containing unique names for each partition (&quot;part&quot;), &quot;y_cal&quot; (true observations),
&quot;y_hat&quot; (predicted values), &quot;pit&quot; (PIT-values), and &quot;n&quot; (number of neighbors) for each partition.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
n &lt;- 10000
split &lt;- 0.8

mu &lt;- function(x1){
10 + 5*x1^2
}

sigma_v &lt;- function(x1){
 30*x1
}

x &lt;- runif(n, 1, 10)
y &lt;- rnorm(n, mu(x), sigma_v(x))

x_train &lt;- x[1:(n*split)]
y_train &lt;- y[1:(n*split)]

x_cal &lt;- x[(n*split+1):n]
y_cal &lt;- y[(n*split+1):n]

model &lt;- lm(y_train ~ x_train)

y_hat &lt;- predict(model, newdata=data.frame(x_train=x_cal))

MSE_cal &lt;- mean((y_hat - y_cal)^2)

PIT_local(xcal = x_cal, ycal=y_cal, yhat=y_hat, mse=MSE_cal)

</code></pre>

<hr>
<h2 id='recalibrate'>Generates Recalibrated Samples of the Predictive Distribution</h2><span id='topic+recalibrate'></span>

<h3>Description</h3>

<p>This function offers recalibration techniques for regression models that assume Gaussian distributions by using the
Mean Squared Error (MSE) as the loss function. Based on the work by Torres R. et al. (2024), it supports
both local and global recalibration approaches to provide samples from a recalibrated predictive distribution. A detailed algorithm can also be found in Musso C. (2023).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>recalibrate(
  yhat_new,
  pit_values,
  mse,
  space_cal = NULL,
  space_new = NULL,
  type = c("local", "global"),
  p_neighbours = 0.1,
  epsilon = 0
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="recalibrate_+3A_yhat_new">yhat_new</code></td>
<td>
<p>Numeric vector with predicted response values for the new (or test) set.</p>
</td></tr>
<tr><td><code id="recalibrate_+3A_pit_values">pit_values</code></td>
<td>
<p>Numeric vector of Global Probability Integral Transform (PIT) values calculated on the calibration set. We recommend using the PIT_global function.</p>
</td></tr>
<tr><td><code id="recalibrate_+3A_mse">mse</code></td>
<td>
<p>Mean Squared Error calculated from the calibration/validation set.</p>
</td></tr>
<tr><td><code id="recalibrate_+3A_space_cal">space_cal</code></td>
<td>
<p>Numeric matrix or data frame representing the covariates/features of the calibration/validation set,
or any intermediate representation (like an intermediate layer of a neural network).</p>
</td></tr>
<tr><td><code id="recalibrate_+3A_space_new">space_new</code></td>
<td>
<p>Similar to space_cal, but for a new set of covariates/features, ensuring they are in the same
space as those in space_cal for effective local recalibration.</p>
</td></tr>
<tr><td><code id="recalibrate_+3A_type">type</code></td>
<td>
<p>Character string to choose between 'local' or 'global' calibration.</p>
</td></tr>
<tr><td><code id="recalibrate_+3A_p_neighbours">p_neighbours</code></td>
<td>
<p>Proportion (0,1] of the calibration dataset to be considered for determining the number of neighbors
in the KNN method. Default is set to 0.1. With p_neighbours=1, calibration is global but weighted by distance.</p>
</td></tr>
<tr><td><code id="recalibrate_+3A_epsilon">epsilon</code></td>
<td>
<p>Numeric value for approximation in the K-nearest neighbors (KNN) method. Default is 0, indicating exact distances.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The calibration technique implemented here draws inspiration from Approximate Bayesian Computation and Inverse Transform Theorem,
allowing for recalibration either locally or globally. The global method employs a uniform kernel, while the local method employs an Epanechnikov kernel.
</p>
<p>It's important to note that the least squares method will only yield a probabilistic interpretation if the output to be modeled
follows a normal distribution, and this assumption was used to implement this function.
</p>
<p>The local recalibration method is expected to improve the predictive performance of the model, especially when the model is not able to capture the heteroscedasticity of the data.
However, there is a trade off between refinement of localization and the Monte Carlo error, which can be controlled by the number of neighbors.
That is, when more localized, the recalibration will grasp local changes better, but the Monte Carlo error will increase, because of the reduced number of neighbors.
</p>
<p>When p_neighbours=1, recalibration is performed using the entire calibration dataset but with distance-weighted contributions.
</p>


<h3>Value</h3>

<p>A list containing the calibrated predicted mean and variance, along with samples from the recalibrated predictive distribution
and their respective weights calculated using an Epanechnikov kernel over the distances obtained from KNN.
</p>


<h3>References</h3>

<p>Torres R, Nott DJ, Sisson SA, Rodrigues T, Reis JG, Rodrigues GS (2024).
&ldquo;Model-Free Local Recalibration of Neural Networks.&rdquo;
<em>arXiv preprint arXiv:2403.05756</em>.
<a href="https://doi.org/10.48550/arXiv.2403.05756">doi:10.48550/arXiv.2403.05756</a>.
Musso C (2023).
&ldquo;Recalibration of Gaussian Neural Network Regression Models: The RecalibratiNN Package.&rdquo;
Undergraduate Thesis (Bachelor in Statistics), University of Bras√≠lia.
Available at: <a href="https://bdm.unb.br/handle/10483/38504">https://bdm.unb.br/handle/10483/38504</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
n &lt;- 1000
split &lt;- 0.8

# Auxiliary functions
mu &lt;- function(x1){
10 + 5*x1^2
}

sigma_v &lt;- function(x1){
30*x1
}

# Generating heteroscedastic data.
x &lt;- runif(n, 1, 10)
y &lt;- rnorm(n, mu(x), sigma_v(x))

# Train set
x_train &lt;- x[1:(n*split)]
y_train &lt;- y[1:(n*split)]

# Calibration/Validation set.
x_cal &lt;- x[(n*split+1):n]
y_cal &lt;- y[(n*split+1):n]

# New observations or the test set.
x_new &lt;- runif(n/5, 1, 10)

# Fitting a simple linear regression, which will not capture the heteroscedasticity
model &lt;- lm(y_train ~ x_train)

y_hat_cal &lt;- predict(model, newdata=data.frame(x_train=x_cal))
MSE_cal &lt;- mean((y_hat_cal - y_cal)^2)

y_hat_new &lt;- predict(model, newdata=data.frame(x_train=x_new))

pit &lt;- PIT_global(ycal=y_cal, yhat= y_hat_cal, mse=MSE_cal)

recalibrate(
  space_cal=x_cal,
  space_new=x_new,
  yhat_new=y_hat_new,
  pit_values=pit,
  mse= MSE_cal,
  type="local")

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
