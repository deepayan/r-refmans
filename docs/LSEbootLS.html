<!DOCTYPE html><html><head><title>Help for package LSEbootLS</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {LSEbootLS}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#LSEbootLS-package'><p>Bootstrap Methods for Regression Models with Locally Stationary Errors</p></a></li>
<li><a href='#application'><p>Calculate the bootstrap LSE for a long memory model</p></a></li>
<li><a href='#Coveragelongmemory'><p>Calculate the coverage of several long-memory models</p></a></li>
<li><a href='#Coverageshortmemory'><p>Calculate the coverage for several short-memory models</p></a></li>
<li><a href='#USinf'><p>US Monthly Inflation Data</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Date:</td>
<td>2024-06-28</td>
</tr>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Bootstrap Methods for Regression Models with Locally Stationary
Errors</td>
</tr>
<tr>
<td>Version:</td>
<td>0.1.0</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Nicolas Loyola &lt;nloyola2016@udec.cl&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Implements bootstrap methods for linear regression models with errors following a time-varying process, focusing on approximating the distribution of the least-squares estimator for regression models with locally stationary errors. It enables the construction of bootstrap and classical confidence intervals for regression coefficients, leveraging intensive simulation studies and real data analysis.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL (&ge; 3)</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>TRUE</td>
</tr>
<tr>
<td>Depends:</td>
<td>doParallel, R (&ge; 2.10)</td>
</tr>
<tr>
<td>Imports:</td>
<td>foreach, doRNG, stats, parallel, LSTS, tibble, iterators,
rlecuyer</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.1</td>
</tr>
<tr>
<td>Suggests:</td>
<td>testthat (&ge; 3.0.0)</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-06-29 04:35:05 UTC; nicol</td>
</tr>
<tr>
<td>Author:</td>
<td>Guillermo Ferreira [aut],
  Joel Muñoz [aut],
  Nicolas Loyola [aut, cre]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-07-01 10:10:03 UTC</td>
</tr>
</table>
<hr>
<h2 id='LSEbootLS-package'>Bootstrap Methods for Regression Models with Locally Stationary Errors</h2><span id='topic+LSEbootLS'></span><span id='topic+LSEbootLS-package'></span>

<h3>Description</h3>

<p>Implements bootstrap methods for linear regression models with errors following a time-varying process, focusing on approximating the distribution of the least-squares estimator for regression models with locally stationary errors. It enables the construction of bootstrap and classical confidence intervals for regression coefficients, leveraging intensive simulation studies and real data analysis. The methodology is based on the approach described in Ferreira et al. (2020), allowing errors to be locally approximated by stationary processes.
</p>


<h3>Author(s)</h3>

<p><strong>Maintainer</strong>: Nicolas Loyola <a href="mailto:nloyola2016@udec.cl">nloyola2016@udec.cl</a>
</p>
<p>Authors:
</p>

<ul>
<li><p> Guillermo Ferreira <a href="mailto:gferreri@udec.cl">gferreri@udec.cl</a>
</p>
</li>
<li><p> Joel Muñoz <a href="mailto:joelmuno@udec.cl">joelmuno@udec.cl</a>
</p>
</li></ul>


<hr>
<h2 id='application'>Calculate the bootstrap LSE for a long memory model</h2><span id='topic+application'></span>

<h3>Description</h3>

<p>Bootstrap procedure to approximate the sampling distribution of the LSE for
time series linear regression with errors following a Locally Stationary process.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>application(
  formula,
  data,
  start,
  d.order,
  s.order,
  N,
  S,
  B = 1,
  nr.cores = 1,
  seed = 123
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="application_+3A_formula">formula</code></td>
<td>
<p>(type: formula) an object of class &quot;formula&quot; (or one that can be coerced to that class): a symbolic description of the model to be fitted. The details of model specification are given under ‘Details’.</p>
</td></tr>
<tr><td><code id="application_+3A_data">data</code></td>
<td>
<p>(type: data.frame) data frame, list or environment (or object coercible by as.data.frame to a data frame) containing the variables in the model.</p>
</td></tr>
<tr><td><code id="application_+3A_start">start</code></td>
<td>
<p>(type: numeric) numeric vector, initial values for parameters to run the model.</p>
</td></tr>
<tr><td><code id="application_+3A_d.order">d.order</code></td>
<td>
<p>(type: numeric) polynomial order, where d is the ARFIMA parameter.</p>
</td></tr>
<tr><td><code id="application_+3A_s.order">s.order</code></td>
<td>
<p>(type: numeric) polynomial order noise scale factor.</p>
</td></tr>
<tr><td><code id="application_+3A_n">N</code></td>
<td>
<p>(type: numeric) sample size of each block.</p>
</td></tr>
<tr><td><code id="application_+3A_s">S</code></td>
<td>
<p>(type: numeric) shifting places from block to block. Observe that the number of blocks M is determined by the following formula <code class="reqn">M = \left\lfloor \frac{T-N}{S} + 1 \right\rfloor</code>, where <code class="reqn">\left\lfloor . \right\rfloor</code> takes a single numeric argument <code>x</code> and returns a numeric vector containing the integers formed by truncating the values in <code>x</code> toward <code>0</code>.</p>
</td></tr>
<tr><td><code id="application_+3A_b">B</code></td>
<td>
<p>(type: numeric) bootstrap replicates, 1 by default.</p>
</td></tr>
<tr><td><code id="application_+3A_nr.cores">nr.cores</code></td>
<td>
<p>(type: numeric) number of CPU cores to be used for parallel processing. 1 by default.</p>
</td></tr>
<tr><td><code id="application_+3A_seed">seed</code></td>
<td>
<p>(type: numeric) random number generator seed to generate the bootstrap samples.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function estimates the parameters in the linear regression model for <code class="reqn">t = 1, ..., T</code>,
</p>
<p style="text-align: center;"><code class="reqn">Y_{t,T} = X_{t,T} \beta + \epsilon_{t,T},</code>
</p>

<p>where the error term <code class="reqn">\epsilon_{t,T}</code> follows a Locally Stationary Autoregressive Fractionally Integrated Moving Average (LS-ARFIMA) structure, given by:
</p>
<p style="text-align: center;"><code class="reqn">\epsilon_{t,T} =(1 - B)^{-d(u)} \sigma(u)\eta_t,</code>
</p>

<p>where u=t/T in [0,1], <code class="reqn">d(u)</code> represents the long-memory parameter, <code class="reqn">\sigma(u)</code> is the noise scale factor, and <code class="reqn">\{\eta_t\}</code> is a white noise sequence with zero mean and unit variance.
</p>
<p>Particularly, we model <code class="reqn">d(u)</code> and <code class="reqn">\sigma(u)</code> as polynomials of order <code class="reqn">d.order</code> and <code class="reqn">s.order</code> respectively.
</p>
<p style="text-align: center;"><code class="reqn">d(u) = \sum_{i=0}^{d.order} \delta_i u^i,</code>
</p>

<p style="text-align: center;"><code class="reqn">\sigma(u) = \sum_{j=0}^{s.order} \alpha_j u^j,</code>
</p>

<p>For more details, see references.
</p>


<h3>Value</h3>

<p>A list with the following elements:
</p>

<ul>
<li> <p><code>coeff</code>: A tibble of estimated model coefficients, including intercepts, regression coefficients (<code class="reqn">\beta</code>), and coefficients of the <code class="reqn">\delta</code> and <code class="reqn">\alpha</code> polynomials. Contains columns for coefficient name, estimate, t-value and p-value.
</p>
</li>
<li> <p><code>estimation</code>: A matrix of bootstrap replicates for regression coefficients (<code class="reqn">\beta</code>).
</p>
</li>
<li> <p><code>delta</code>: A matrix of bootstrap replicates for the <code class="reqn">\delta</code> polynomial coefficients.
</p>
</li>
<li> <p><code>alpha</code>: A matrix of bootstrap replicates for the <code class="reqn">\alpha</code> polynomial coefficients.
</p>
</li></ul>



<h3>References</h3>

<p>Ferreira G., Mateu J., Vilar J.A., Muñoz J. (2020). Bootstrapping regression models with locally stationary disturbances. TEST, 30, 341-363.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n    &lt;- length(USinf)
shift&lt;-201
u1&lt;-c((1:shift)/shift,rep(0, n-shift))
u2&lt;-c(rep(0, shift),(1:(n-shift))/(n-shift))
u&lt;-(1:n)/n
switch &lt;- c(rep(1,shift), rep(0, n-shift))
x1&lt;-switch*u
x2&lt;-(1-switch)*u

test &lt;- data.frame(USinf, x1=x1, x2=x2)

application(formula=USinf~x1+x2,data=test,N=150,S=50,B=10,
start = c(0.16,2.0,-7,8,-3,0.25,-0.25,0.01),
d.order=4,s.order=2,nr.cores=1)

</code></pre>

<hr>
<h2 id='Coveragelongmemory'>Calculate the coverage of several long-memory models</h2><span id='topic+Coveragelongmemory'></span>

<h3>Description</h3>

<p>Generates coverage metrics for a parameter of interest using a specified long-memory model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Coveragelongmemory(
  n,
  R,
  N,
  S,
  mu = 0,
  dist,
  method,
  B = NULL,
  nr.cores = 1,
  seed = 123,
  alpha,
  beta,
  start,
  sign = 0.05
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Coveragelongmemory_+3A_n">n</code></td>
<td>
<p>(type: numeric) size of the simulated series.</p>
</td></tr>
<tr><td><code id="Coveragelongmemory_+3A_r">R</code></td>
<td>
<p>(type: numeric) number of realizations of the Monte Carlo experiments.</p>
</td></tr>
<tr><td><code id="Coveragelongmemory_+3A_n">N</code></td>
<td>
<p>(type: numeric) sample size of each block.</p>
</td></tr>
<tr><td><code id="Coveragelongmemory_+3A_s">S</code></td>
<td>
<p>(type: numeric) shifting places from block to block. Observe that the number of blocks M is determined by the following formula <code class="reqn">M=\left\lfloor \frac{T-N}{S} + 1 \right\rfloor</code>, where <code class="reqn">\left\lfloor . \right\rfloor</code> takes a single numeric argument <code>x</code> and returns a numeric vector containing the integers formed by truncating the values in <code>x</code> toward <code>0</code>.</p>
</td></tr>
<tr><td><code id="Coveragelongmemory_+3A_mu">mu</code></td>
<td>
<p>(type: numeric) trend coefficient of the regression model.</p>
</td></tr>
<tr><td><code id="Coveragelongmemory_+3A_dist">dist</code></td>
<td>
<p>(type: character) white noise distribution for calculating coverage, it includes the <code>"normal"</code>, <code>"exponential"</code> and <code>"uniform"</code> univariate distributions.</p>
</td></tr>
<tr><td><code id="Coveragelongmemory_+3A_method">method</code></td>
<td>
<p>(type: character) methods are asymptotic (<code>"asym"</code>), bootstrap percentile (<code>"boot"</code>) and bootstrap-t (<code>"boott"</code>).</p>
</td></tr>
<tr><td><code id="Coveragelongmemory_+3A_b">B</code></td>
<td>
<p>(type: numeric) the number of bootstrap replicates, NULL indicates the asymptotic method.</p>
</td></tr>
<tr><td><code id="Coveragelongmemory_+3A_nr.cores">nr.cores</code></td>
<td>
<p>(type: numeric) number of CPU cores to be used for parallel processing. 1 by default.</p>
</td></tr>
<tr><td><code id="Coveragelongmemory_+3A_seed">seed</code></td>
<td>
<p>(type: numeric) random number generator seed to generate the bootstrap samples.</p>
</td></tr>
<tr><td><code id="Coveragelongmemory_+3A_alpha">alpha</code></td>
<td>
<p>(type: numeric) numeric vector with values to simulate the time varying autoregressive parameters of model LSAR(1), <code class="reqn">\phi(u)</code>.</p>
</td></tr>
<tr><td><code id="Coveragelongmemory_+3A_beta">beta</code></td>
<td>
<p>(type: numeric) numeric vector with values to simulate the time varying scale factor parameters of model LSAR(1), <code class="reqn">\sigma(u)</code>.</p>
</td></tr>
<tr><td><code id="Coveragelongmemory_+3A_start">start</code></td>
<td>
<p>(type: numeric) numeric vector, initial values for parameters to run the model.</p>
</td></tr>
<tr><td><code id="Coveragelongmemory_+3A_sign">sign</code></td>
<td>
<p>nominal significance level</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function estimates the parameters in the linear regression model for <code class="reqn">t = 1, ..., T</code>,
</p>
<p style="text-align: center;"><code class="reqn">Y_{t,T} = X_{t,T} \beta + \epsilon_{t,T},</code>
</p>

<p>where a locally stationary fractional noise process (LSFN) is described by the equation:
</p>
<p style="text-align: center;"><code class="reqn">\epsilon_{t,T} = \sum_{j=0}^\infty \psi_j(u) \eta_{t-j}</code>
</p>

<p>for u=t/T in [0,1], where <code class="reqn">\psi_j(u) = \frac{\Gamma[j + d(u)]}{\Gamma[j+1] \Gamma[d(u)]}</code> and <code class="reqn">d(u)</code> is the
smoothly varying long-memory coefficient. This model is referred to as locally stationary fractional noise (LSFN).
</p>
<p>In this particular case, <code class="reqn">d(u)</code> is modeled as a linear polynomial, and <code class="reqn">\sigma(u)</code> as a quadratic polynomial.
</p>
<p>Resampling methods evaluated:
</p>

<ul>
<li><p> asym: Asymptotic method that uses the asymptotic variance of the estimator, based
on the Central Limit Theorem, to construct confidence intervals under the
assumption of normality in large samples.
</p>
</li>
<li><p> boot: Standard bootstrap that generates replicas of the estimator <code class="reqn">\hat{\beta}</code> by resampling
the adjusted residuals <code class="reqn">\hat{\epsilon}_t</code>. It approximates the distribution of the estimator by
the variability observed in the bootstrap replicas of <code class="reqn">\hat{\beta}</code>.
</p>
</li>
<li><p> boott: Adjusted bootstrap that scales the bootstrap replicas of the estimator
<code class="reqn">\hat{\beta}</code> by its standard error, aiming to refine the precision of the confidence interval
and adjust for the variability in the parameter estimation.
</p>
</li></ul>

<p>For more details, see references.
</p>


<h3>Value</h3>

<p>A data frame containing the following columns:
</p>

<ul>
<li> <p><code>n</code>: Size of each simulated series.
</p>
</li>
<li> <p><code>method</code>: Statistical method used for simulation.
</p>
</li>
<li> <p><code>coverage</code>: Proportion of true parameter values within the intervals.
</p>
</li>
<li> <p><code>avg_width</code>: Average width of the intervals.
</p>
</li>
<li> <p><code>sd_width</code>: Standard deviation of the interval widths.
</p>
</li></ul>



<h3>References</h3>

<p>Ferreira G., Mateu J., Vilar J.A., Muñoz J. (2020). Bootstrapping regression models with locally stationary disturbances. TEST, 30, 341-363.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>Coveragelongmemory(n=500,R=5,N=60,S=40,mu=0.5,dist="normal",method="asym",
beta=c(0.1,-2),alpha=c(0.15,0.25, 0.1),start = c(0.1,-2,0.15,0.2, 0.1))

</code></pre>

<hr>
<h2 id='Coverageshortmemory'>Calculate the coverage for several short-memory models</h2><span id='topic+Coverageshortmemory'></span>

<h3>Description</h3>

<p>Generates coverage metrics for a parameter of interest using a specified short-memory model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Coverageshortmemory(
  n,
  R,
  N,
  S,
  mu,
  dist,
  method,
  alpha,
  beta,
  start,
  Subdivisions = 100,
  m = 500,
  NN = 100,
  B,
  case,
  sign = 0.05
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Coverageshortmemory_+3A_n">n</code></td>
<td>
<p>(type: numeric) size of the simulated series.</p>
</td></tr>
<tr><td><code id="Coverageshortmemory_+3A_r">R</code></td>
<td>
<p>(type: numeric) number of realizations of the Monte Carlo experiments.</p>
</td></tr>
<tr><td><code id="Coverageshortmemory_+3A_n">N</code></td>
<td>
<p>(type: numeric) sample size of each block.</p>
</td></tr>
<tr><td><code id="Coverageshortmemory_+3A_s">S</code></td>
<td>
<p>(type: numeric) shifting places from block to block. Observe that the number of blocks M is determined by the following formula <code class="reqn">M = \left\lfloor \frac{T-N}{S} + 1 \right\rfloor</code>, where <code class="reqn">\left\lfloor . \right\rfloor</code> takes a single numeric argument <code>x</code> and returns a numeric vector containing the integers formed by truncating the values in <code>x</code> toward <code>0</code>.</p>
</td></tr>
<tr><td><code id="Coverageshortmemory_+3A_mu">mu</code></td>
<td>
<p>(type: numeric) trend coefficient of the regression model.</p>
</td></tr>
<tr><td><code id="Coverageshortmemory_+3A_dist">dist</code></td>
<td>
<p>(type: character) white noise distribution for calculating coverage, it includes the <code>"normal"</code>, <code>"exponential"</code> and <code>"uniform"</code> univariate distributions.</p>
</td></tr>
<tr><td><code id="Coverageshortmemory_+3A_method">method</code></td>
<td>
<p>(type: character) methods are asymptotic (<code>"asym"</code>), bootstrap percentile (<code>"boot"</code>), bootstrap-t (<code>"boott"</code>) and bootstrap-SP (<code>"bootSP"</code>).</p>
</td></tr>
<tr><td><code id="Coverageshortmemory_+3A_alpha">alpha</code></td>
<td>
<p>(type: numeric) numeric vector with values to simulate the time varying autoregressive parameters of model LSAR(1), <code class="reqn">\phi(u)</code>.</p>
</td></tr>
<tr><td><code id="Coverageshortmemory_+3A_beta">beta</code></td>
<td>
<p>(type: numeric) numeric vector with values to simulate the time varying scale factor parameters of model LSAR(1), <code class="reqn">\sigma(u)</code>.</p>
</td></tr>
<tr><td><code id="Coverageshortmemory_+3A_start">start</code></td>
<td>
<p>(type: numeric) numeric vector, initial values for parameters to run the model.</p>
</td></tr>
<tr><td><code id="Coverageshortmemory_+3A_subdivisions">Subdivisions</code></td>
<td>
<p>(type: numeric) the number of subintervals produced in the subdivision (integration) process; only required in the asymptotic method.</p>
</td></tr>
<tr><td><code id="Coverageshortmemory_+3A_m">m</code></td>
<td>
<p>(type: numeric) parameter that allows to remove the first m observations when simulating the LSAR process.</p>
</td></tr>
<tr><td><code id="Coverageshortmemory_+3A_nn">NN</code></td>
<td>
<p>(type: numeric) parameter that allows to remove the first NN observations of noise from the LSAR model.</p>
</td></tr>
<tr><td><code id="Coverageshortmemory_+3A_b">B</code></td>
<td>
<p>(type: numeric) the number of bootstrap replicates, NULL indicates the asymptotic method.</p>
</td></tr>
<tr><td><code id="Coverageshortmemory_+3A_case">case</code></td>
<td>
<p>(type: character) nonlinear (<code>"no-linear"</code>) and linear cases (<code>"linear"</code>).</p>
</td></tr>
<tr><td><code id="Coverageshortmemory_+3A_sign">sign</code></td>
<td>
<p>nominal significance level</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function estimates the parameters in the linear regression model for <code class="reqn">t = 1, ..., T</code>,
</p>
<p style="text-align: center;"><code class="reqn">Y_{t,T} = X_{t,T} \beta + \epsilon_{t,T},</code>
</p>

<p>where a locally stationary autoregressive process of order one (LSAR(1)) is described by the equation:
</p>
<p style="text-align: center;"><code class="reqn">\epsilon_{t,T} = \phi(u) \epsilon_{t-1,T} + \sigma(u) \eta_t</code>
</p>

<p>where u=t/T in [0,1], with
<code class="reqn">\phi(u)</code> is the autoregressive coefficient which is modeled as a linear polynomial,
<code class="reqn">\sigma(u)</code> is modeled as a quadratic polynomial, and <code class="reqn">\eta_t</code> is a white noise sequence
with zero mean and unit variance.
This setup is referred to as a locally stationary autoregressive model (LSAR(1)).
</p>
<p>Resampling methods evaluated:
</p>

<ul>
<li><p> asym: Asymptotic method that uses the asymptotic variance of the estimator, based
on the Central Limit Theorem, to construct confidence intervals under the
assumption of normality in large samples.
</p>
</li>
<li><p> boot: Standard bootstrap that generates replicas of the estimator <code class="reqn">\hat{\beta}</code> by resampling
the adjusted residuals <code class="reqn">\hat{\epsilon}_t</code>. It approximates the distribution of the estimator by
the variability observed in the bootstrap replicas of <code class="reqn">\hat{\beta}</code>.
</p>
</li>
<li><p> boott: Adjusted bootstrap that scales the bootstrap replicas of the estimator
<code class="reqn">\hat{\beta}</code> by its standard error, aiming to refine the precision of the confidence interval
and adjust for the variability in the parameter estimation.
</p>
</li>
<li><p> bootSP: Symmetrized Percentile-t method, a variation of the boot-t that symmetrizes the
bootstrap distribution around zero to handle skewed distributions or outliers more effectively.
This method enhances the accuracy of confidence intervals by adjusting for asymmetries in the
bootstrap replicas.
</p>
</li></ul>

<p>For more details, see references.
</p>


<h3>Value</h3>

<p>A data frame containing the following columns:
</p>

<ul>
<li> <p><code>n</code>: Size of each simulated series.
</p>
</li>
<li> <p><code>method</code>: Statistical method used for simulation.
</p>
</li>
<li> <p><code>coverage</code>: Proportion of true parameter values within the intervals.
</p>
</li>
<li> <p><code>avg_width</code>: Average width of the intervals.
</p>
</li>
<li> <p><code>sd_width</code>: Standard deviation of the interval widths.
</p>
</li></ul>



<h3>References</h3>

<p>Ferreira G., Mateu J., Vilar J.A., Muñoz J. (2020). Bootstrapping regression models with locally stationary disturbances. TEST, 30, 341-363.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>Coverageshortmemory(n=100,R=10,N=60,S=40,mu=0.5,dist="normal",method="asym",alpha=c(0.25,0.2),
beta=c(1,1,-0.5),start=c(0.15,0.15,1,1,-0.5),case="no-linear")

</code></pre>

<hr>
<h2 id='USinf'>US Monthly Inflation Data</h2><span id='topic+USinf'></span>

<h3>Description</h3>

<p>Monthly inflation rates for the United States.
The data covers the period from January 1965 to December 2011, totaling 564 observations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>USinf
</code></pre>


<h3>Format</h3>

<p>A time series object with 564 elements
</p>
<p>Monthly inflation rate, expressed as a percentage.
</p>


<h3>Source</h3>

<p>International Financial Statistics (IFS)
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
