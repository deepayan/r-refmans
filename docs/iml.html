<!DOCTYPE html><html><head><title>Help for package iml</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {iml}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#calculate.ale.cat'><p>Compute ALE for 1 categorical feature</p></a></li>
<li><a href='#calculate.ale.num'><p>Compute ALE for 1 numerical feature</p></a></li>
<li><a href='#calculate.ale.num.cat'><p>Compute ALE for 2 features, one numerical, one categorical</p></a></li>
<li><a href='#calculate.ale.num.num'><p>Compute ALE for 2 numerical features</p></a></li>
<li><a href='#extract.glmnet.effects'><p>Extract glmnet effects</p></a></li>
<li><a href='#FeatureEffect'><p>Effect of a feature on predictions</p></a></li>
<li><a href='#FeatureEffects'><p>Effect of a feature on predictions</p></a></li>
<li><a href='#FeatureImp'><p>Feature importance</p></a></li>
<li><a href='#has.predict'><p>returns TRUE if object has predict function</p></a></li>
<li><a href='#iml-package'><p>Make machine learning models and predictions interpretable</p></a></li>
<li><a href='#impute_cells'><p>Impute missing cells of grid</p></a></li>
<li><a href='#Interaction'><p>Feature interactions</p></a></li>
<li><a href='#InterpretationMethod'><p>Interpretation Method</p></a></li>
<li><a href='#LocalModel'><p>LocalModel</p></a></li>
<li><a href='#order_levels'><p>Order levels of a categorical features</p></a></li>
<li><a href='#Partial'><p>Effect of one or two feature(s) on the model predictions (deprecated)</p></a></li>
<li><a href='#plot.FeatureEffect'><p>Plot FeatureEffect</p></a></li>
<li><a href='#plot.FeatureEffects'><p>Plot FeatureEffect</p></a></li>
<li><a href='#plot.FeatureImp'><p>Plot Feature Importance</p></a></li>
<li><a href='#plot.Interaction'><p>Plot Interaction</p></a></li>
<li><a href='#plot.LocalModel'><p>Plot Local Model</p></a></li>
<li><a href='#plot.Shapley'><p>Plot Shapley</p></a></li>
<li><a href='#plot.TreeSurrogate'><p>Plot Tree Surrogate</p></a></li>
<li><a href='#predict.LocalModel'><p>Predict LocalModel</p></a></li>
<li><a href='#predict.TreeSurrogate'><p>Predict Tree Surrogate</p></a></li>
<li><a href='#Predictor'><p>Predictor object</p></a></li>
<li><a href='#probs.to.labels'><p>Turn class probabilities into class labels</p></a></li>
<li><a href='#Shapley'><p>Prediction explanations with game theory</p></a></li>
<li><a href='#TreeSurrogate'><p>Decision tree surrogate model</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Interpretable Machine Learning</td>
</tr>
<tr>
<td>Version:</td>
<td>0.11.2</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Giuseppe Casalicchio &lt;giuseppe.casalicchio@lmu.de&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Interpretability methods to analyze the behavior and
    predictions of any machine learning model.  Implemented methods are:
    Feature importance described by Fisher et al. (2018)
    &lt;<a href="https://arxiv.org/abs/1801.01489">arXiv:1801.01489</a>&gt;, accumulated local effects plots described by Apley
    (2018) &lt;<a href="https://arxiv.org/abs/1612.08468">arXiv:1612.08468</a>&gt;, partial dependence plots described by
    Friedman (2001) &lt;www.jstor.org/stable/2699986&gt;, individual conditional
    expectation ('ice') plots described by Goldstein et al.  (2013)
    &lt;<a href="https://doi.org/10.1080%2F10618600.2014.907095">doi:10.1080/10618600.2014.907095</a>&gt;, local models (variant of 'lime')
    described by Ribeiro et. al (2016) &lt;<a href="https://arxiv.org/abs/1602.04938">arXiv:1602.04938</a>&gt;, the Shapley
    Value described by Strumbelj et. al (2014)
    &lt;<a href="https://doi.org/10.1007%2Fs10115-013-0679-x">doi:10.1007/s10115-013-0679-x</a>&gt;, feature interactions described by
    Friedman et. al &lt;<a href="https://doi.org/10.1214%2F07-AOAS148">doi:10.1214/07-AOAS148</a>&gt; and tree surrogate models.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://christophm.github.io/iml/">https://christophm.github.io/iml/</a>,
<a href="https://github.com/christophM/iml/">https://github.com/christophM/iml/</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/christophM/iml/issues">https://github.com/christophM/iml/issues</a></td>
</tr>
<tr>
<td>Imports:</td>
<td>checkmate, data.table, Formula, future, future.apply, ggplot2,
Metrics, R6</td>
</tr>
<tr>
<td>Suggests:</td>
<td>ALEPlot, bench, bit64, caret, covr, e1071, future.callr,
glmnet, gower, h2o, keras (&ge; 2.2.5.0), knitr, MASS, mlr, mlr3,
party, partykit, patchwork, randomForest, ranger, rmarkdown,
rpart, testthat, yaImpute</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>Config/testthat/parallel:</td>
<td>true</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.1</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-03-28 20:47:00 UTC; GDaddy</td>
</tr>
<tr>
<td>Author:</td>
<td>Giuseppe Casalicchio [aut, cre],
  Christoph Molnar [aut],
  Patrick Schratz <a href="https://orcid.org/0000-0003-0748-6624"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-03-29 07:20:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='calculate.ale.cat'>Compute ALE for 1 categorical feature</h2><span id='topic+calculate.ale.cat'></span>

<h3>Description</h3>

<p>Compute ALE for 1 categorical feature
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calculate.ale.cat(dat, run.prediction, feature.name)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="calculate.ale.cat_+3A_dat">dat</code></td>
<td>
<p>the data.frame with same columns as training data</p>
</td></tr>
<tr><td><code id="calculate.ale.cat_+3A_run.prediction">run.prediction</code></td>
<td>
<p>Predict function of type: f(newdata)</p>
</td></tr>
<tr><td><code id="calculate.ale.cat_+3A_feature.name">feature.name</code></td>
<td>
<p>The column name of the feature for which to compute ALE</p>
</td></tr>
</table>

<hr>
<h2 id='calculate.ale.num'>Compute ALE for 1 numerical feature</h2><span id='topic+calculate.ale.num'></span>

<h3>Description</h3>

<p>Compute ALE for 1 numerical feature
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calculate.ale.num(dat, run.prediction, feature.name, grid.dt)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="calculate.ale.num_+3A_dat">dat</code></td>
<td>
<p>the data.frame with same columns as training data</p>
</td></tr>
<tr><td><code id="calculate.ale.num_+3A_run.prediction">run.prediction</code></td>
<td>
<p>Predict function of type: f(newdata)</p>
</td></tr>
<tr><td><code id="calculate.ale.num_+3A_feature.name">feature.name</code></td>
<td>
<p>The column name of the feature for which to compute ALE</p>
</td></tr>
<tr><td><code id="calculate.ale.num_+3A_grid.dt">grid.dt</code></td>
<td>
<p>data.table with single column with grid values for the numerical feature</p>
</td></tr>
</table>

<hr>
<h2 id='calculate.ale.num.cat'>Compute ALE for 2 features, one numerical, one categorical</h2><span id='topic+calculate.ale.num.cat'></span>

<h3>Description</h3>

<p>Compute ALE for 2 features, one numerical, one categorical
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calculate.ale.num.cat(dat, run.prediction, feature.name, grid.dt)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="calculate.ale.num.cat_+3A_dat">dat</code></td>
<td>
<p>the data.frame with same columns as training data</p>
</td></tr>
<tr><td><code id="calculate.ale.num.cat_+3A_run.prediction">run.prediction</code></td>
<td>
<p>Predict function of type: f(newdata)</p>
</td></tr>
<tr><td><code id="calculate.ale.num.cat_+3A_feature.name">feature.name</code></td>
<td>
<p>The column name of the features for which to compute ALE</p>
</td></tr>
<tr><td><code id="calculate.ale.num.cat_+3A_grid.dt">grid.dt</code></td>
<td>
<p>data.table with single column with grid values for the numerical feature</p>
</td></tr>
</table>

<hr>
<h2 id='calculate.ale.num.num'>Compute ALE for 2 numerical features</h2><span id='topic+calculate.ale.num.num'></span>

<h3>Description</h3>

<p>Compute ALE for 2 numerical features
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calculate.ale.num.num(dat, run.prediction, feature.name, grid.dt1, grid.dt2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="calculate.ale.num.num_+3A_dat">dat</code></td>
<td>
<p>the data.frame with same columns as training data</p>
</td></tr>
<tr><td><code id="calculate.ale.num.num_+3A_run.prediction">run.prediction</code></td>
<td>
<p>Predict function of type: f(newdata)</p>
</td></tr>
<tr><td><code id="calculate.ale.num.num_+3A_feature.name">feature.name</code></td>
<td>
<p>The column names of the feature for which to compute ALE</p>
</td></tr>
<tr><td><code id="calculate.ale.num.num_+3A_grid.dt1">grid.dt1</code></td>
<td>
<p>Data.table with single column with the grid value for feature 1</p>
</td></tr>
<tr><td><code id="calculate.ale.num.num_+3A_grid.dt2">grid.dt2</code></td>
<td>
<p>Data.table with single column with the grid value for feature 2</p>
</td></tr>
</table>

<hr>
<h2 id='extract.glmnet.effects'>Extract glmnet effects</h2><span id='topic+extract.glmnet.effects'></span>

<h3>Description</h3>

<p>Extract glmnet effects
</p>


<h3>Usage</h3>

<pre><code class='language-R'>extract.glmnet.effects(betas, best.index, x.recoded, x.original)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="extract.glmnet.effects_+3A_betas">betas</code></td>
<td>
<p>glmnet$beta</p>
</td></tr>
<tr><td><code id="extract.glmnet.effects_+3A_best.index">best.index</code></td>
<td>
<p>index k</p>
</td></tr>
<tr><td><code id="extract.glmnet.effects_+3A_x.recoded">x.recoded</code></td>
<td>
<p>the recoded version of x</p>
</td></tr>
<tr><td><code id="extract.glmnet.effects_+3A_x.original">x.original</code></td>
<td>
<p>the original x
Assuming that the first row is the x.interest</p>
</td></tr>
</table>

<hr>
<h2 id='FeatureEffect'>Effect of a feature on predictions</h2><span id='topic+FeatureEffect'></span>

<h3>Description</h3>

<p><code>FeatureEffect</code> computes and plots (individual) feature effects
of prediction models.
</p>


<h3>Details</h3>

<p>The <a href="#topic+FeatureEffect">FeatureEffect</a> class compute the effect a feature has on the prediction.
Different methods are implemented:
</p>

<ul>
<li><p> Accumulated Local Effect (ALE) plots
</p>
</li>
<li><p> Partial Dependence Plots (PDPs)
</p>
</li>
<li><p> Individual Conditional Expectation (ICE) curves
</p>
</li></ul>

<p>Accumulated local effects and partial dependence plots both show the average
model prediction over the feature. The difference is that ALE are computed as
accumulated differences over the conditional distribution and partial
dependence plots over the marginal distribution. ALE plots preferable to
PDPs, because they are faster and unbiased when features are correlated.
</p>
<p>ALE plots for categorical features are automatically ordered by the
similarity of the categories based on the distribution of the other features
for instances in a category. When the feature is an ordered factor, the ALE
plot leaves the order as is.
</p>
<p>Individual conditional expectation curves describe how, for a single
observation, the prediction changes when the feature changes and can be
combined with partial dependence plots.
</p>
<p>To learn more about accumulated local effects, read the <a href="https://christophm.github.io/interpretable-ml-book/ale.html">Interpretable Machine Learning book</a>.
</p>
<p>For the partial dependence plots:
<a href="https://christophm.github.io/interpretable-ml-book/pdp.html">https://christophm.github.io/interpretable-ml-book/pdp.html</a>
</p>
<p>For individual conditional expectation:
<a href="https://christophm.github.io/interpretable-ml-book/ice.html">https://christophm.github.io/interpretable-ml-book/ice.html</a>
</p>


<h3>Super class</h3>

<p><code><a href="#topic+InterpretationMethod">iml::InterpretationMethod</a></code> -&gt; <code>FeatureEffect</code>
</p>


<h3>Public fields</h3>

<div class="r6-fields">

<dl>
<dt><code>grid.size</code></dt><dd><p>(<code>numeric(1)</code> | <code>numeric(2)</code>)<br />
The size of the grid.</p>
</dd>
<dt><code>feature.name</code></dt><dd><p>(<code>character(1)</code> | <code>character(2)</code>)<br />
The names of the features for which the partial dependence was computed.</p>
</dd>
<dt><code>n.features</code></dt><dd><p>(<code>numeric(1)</code>)<br />
The number of features (either 1 or 2).</p>
</dd>
<dt><code>feature.type</code></dt><dd><p>(<code>character(1)</code> | <code>character(2)</code>)<br />
The detected types of the features, either &quot;categorical&quot; or &quot;numerical&quot;.</p>
</dd>
<dt><code>method</code></dt><dd><p>(<code>character(1)</code>)<br /></p>
</dd>
</dl>

</div>


<h3>Active bindings</h3>

<div class="r6-active-bindings">

<dl>
<dt><code>center.at</code></dt><dd><p><a href="base.html#topic+numeric">numeric</a><br />
Value at which the plot was centered. Ignored in the case of two
features.</p>
</dd>
</dl>

</div>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-FeatureEffect-new"><code>FeatureEffect$new()</code></a>
</p>
</li>
<li> <p><a href="#method-FeatureEffect-set.feature"><code>FeatureEffect$set.feature()</code></a>
</p>
</li>
<li> <p><a href="#method-FeatureEffect-center"><code>FeatureEffect$center()</code></a>
</p>
</li>
<li> <p><a href="#method-FeatureEffect-predict"><code>FeatureEffect$predict()</code></a>
</p>
</li>
<li> <p><a href="#method-FeatureEffect-clone"><code>FeatureEffect$clone()</code></a>
</p>
</li></ul>



<details open><summary>Inherited methods</summary>
<ul>
<li><span class="pkg-link" data-pkg="iml" data-topic="InterpretationMethod" data-id="plot"><a href='../../iml/html/InterpretationMethod.html#method-InterpretationMethod-plot'><code>iml::InterpretationMethod$plot()</code></a></span></li>
<li><span class="pkg-link" data-pkg="iml" data-topic="InterpretationMethod" data-id="print"><a href='../../iml/html/InterpretationMethod.html#method-InterpretationMethod-print'><code>iml::InterpretationMethod$print()</code></a></span></li>
</ul>
</details>

<hr>
<a id="method-FeatureEffect-new"></a>



<h4>Method <code>new()</code></h4>

<p>Create a FeatureEffect object
</p>


<h5>Usage</h5>

<div class="r"><pre>FeatureEffect$new(
  predictor,
  feature,
  method = "ale",
  center.at = NULL,
  grid.size = 20,
  grid.points = NULL
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>predictor</code></dt><dd><p><a href="#topic+Predictor">Predictor</a><br />
The object (created with <code>Predictor$new()</code>) holding the machine
learning model and the data.</p>
</dd>
<dt><code>feature</code></dt><dd><p>(<code>character(1)</code> | <code>character(2)</code> | <code>numeric(1)</code> |
<code>numeric(2)</code>)<br />
The feature name or index for which to compute the effects.</p>
</dd>
<dt><code>method</code></dt><dd><p>(<code>character(1)</code>)<br />
</p>

<ul>
<li><p> 'ale' for accumulated local effects,
</p>
</li>
<li><p> 'pdp' for partial dependence plot,
</p>
</li>
<li><p> 'ice' for individual conditional expectation curves,
</p>
</li>
<li><p> 'pdp + ice' for partial dependence plot and ice curves within the same
plot.
</p>
</li></ul>
</dd>
<dt><code>center.at</code></dt><dd><p>(<code>numeric(1)</code>)<br />
Value at which the plot should be centered. Ignored in the case of two
features.</p>
</dd>
<dt><code>grid.size</code></dt><dd><p>(<code>numeric(1)</code> | <code>numeric(2)</code>)<br />
The size of the grid for evaluating the predictions.</p>
</dd>
<dt><code>grid.points</code></dt><dd><p>(<code>numeric()</code> | <code style="white-space: pre;">&#8288;list(numeric()&#8288;</code>, <code>numeric()</code>)<br />
An optional grid along the feature. If grid.points are set, the grid.size
argument is ignored. Provide a list of two vectors with the same order as
in the 'feature' argument, if PDP/ALE for two features is to be computed
with a user-defined grid.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-FeatureEffect-set.feature"></a>



<h4>Method <code>set.feature()</code></h4>

<p>Get/set feature(s) (by index) for which to compute PDP.
</p>


<h5>Usage</h5>

<div class="r"><pre>FeatureEffect$set.feature(feature)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>feature</code></dt><dd><p>(<code>character(1)</code>)<br />
Feature name.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-FeatureEffect-center"></a>



<h4>Method <code>center()</code></h4>

<p>Set the value at which the ice computations are centered.
</p>


<h5>Usage</h5>

<div class="r"><pre>FeatureEffect$center(center.at)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>center.at</code></dt><dd><p>(<code>numeric(1)</code>)<br />
Value at which the plot should be centered. Ignored in the case of two
features.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-FeatureEffect-predict"></a>



<h4>Method <code>predict()</code></h4>

<p>Predict the marginal outcome given a feature.
</p>


<h5>Usage</h5>

<div class="r"><pre>FeatureEffect$predict(data, extrapolate = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>data</code></dt><dd><p><a href="base.html#topic+data.frame">data.frame</a><br />
Data.frame with the feature or a vector.</p>
</dd>
<dt><code>extrapolate</code></dt><dd><p>(<code>character(1)</code>)<br />
If TRUE, predict returns NA for x values outside of observed range.
If FALSE, predcit returns the closest PDP value for x values outside the range.
Ignored for categorical features</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>Values of the effect curves at the given values.
</p>


<hr>
<a id="method-FeatureEffect-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>FeatureEffect$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>




<h3>References</h3>

<p>Apley, D. W. 2016. &quot;Visualizing the Effects of Predictor Variables in Black
Box Supervised Learning Models.&quot; ArXiv Preprint.
</p>
<p>Friedman, J.H. 2001. &quot;Greedy Function Approximation: A Gradient Boosting
Machine.&quot; Annals of Statistics 29: 1189-1232.
</p>
<p>Goldstein, A., Kapelner, A., Bleich, J., and Pitkin, E. (2013). Peeking
Inside the Black Box: Visualizing Statistical Learning with Plots of
Individual Conditional Expectation, 1-22.
https://doi.org/10.1080/10618600.2014.907095
</p>


<h3>See Also</h3>

<p><a href="#topic+plot.FeatureEffect">plot.FeatureEffect</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># We train a random forest on the Boston dataset:
data("Boston", package = "MASS")
library("rpart")
rf &lt;- rpart(medv ~ ., data = Boston)
mod &lt;- Predictor$new(rf, data = Boston)

# Compute the accumulated local effects for the first feature
eff &lt;- FeatureEffect$new(mod, feature = "rm", grid.size = 30)
eff$plot()

# Again, but this time with a partial dependence plot and ice curves
eff &lt;- FeatureEffect$new(mod,
  feature = "rm", method = "pdp+ice",
  grid.size = 30
)
plot(eff)

# Since the result is a ggplot object, you can extend it:
library("ggplot2")
plot(eff) +
  # Adds a title
  ggtitle("Partial dependence") +
  # Adds original predictions
  geom_point(
    data = Boston, aes(y = mod$predict(Boston)[[1]], x = rm),
    color = "pink", size = 0.5
  )

# If you want to do your own thing, just extract the data:
eff.dat &lt;- eff$results
head(eff.dat)

# You can also use the object to "predict" the marginal values.
eff$predict(Boston[1:3, ])
# Instead of the entire data.frame, you can also use feature values:
eff$predict(c(5, 6, 7))

# You can reuse the pdp object for other features:
eff$set.feature("lstat")
plot(eff)

# Only plotting the aggregated partial dependence:
eff &lt;- FeatureEffect$new(mod, feature = "crim", method = "pdp")
eff$plot()

# Only plotting the individual conditional expectation:
eff &lt;- FeatureEffect$new(mod, feature = "crim", method = "ice")
eff$plot()

# Accumulated local effects and partial dependence plots support up to two
# features:
eff &lt;- FeatureEffect$new(mod, feature = c("crim", "lstat"))
plot(eff)

# FeatureEffect plots also works with multiclass classification
rf &lt;- rpart(Species ~ ., data = iris)
mod &lt;- Predictor$new(rf, data = iris, type = "prob")

# For some models we have to specify additional arguments for the predict
# function
plot(FeatureEffect$new(mod, feature = "Petal.Width"))

# FeatureEffect plots support up to two features:
eff &lt;- FeatureEffect$new(mod, feature = c("Sepal.Length", "Petal.Length"))
eff$plot()

# show where the actual data lies
eff$plot(show.data = TRUE)

# For multiclass classification models, you can choose to only show one class:
mod &lt;- Predictor$new(rf, data = iris, type = "prob", class = 1)
plot(FeatureEffect$new(mod, feature = "Sepal.Length"))
</code></pre>

<hr>
<h2 id='FeatureEffects'>Effect of a feature on predictions</h2><span id='topic+FeatureEffects'></span>

<h3>Description</h3>

<p><code>FeatureEffects</code> computes and plots feature effects
of multiple features at once.
</p>


<h3>Details</h3>

<p>FeatureEffects computes the effects for all given features on the model
prediction. <a href="#topic+FeatureEffects">FeatureEffects</a> is a convenience class that calls FeatureEffect
multiple times. See <code>?FeatureEffect</code> for details what's actually computed.
</p>
<p>Only first-order effects can be computed with the <a href="#topic+FeatureEffects">FeatureEffects</a> interface.
If you are interested in the visualization of interactions between two
features, directly use <a href="#topic+FeatureEffect">FeatureEffect</a>.
</p>


<h3>Parallelization</h3>

<p>Parallelization is supported via package <a href="https://CRAN.R-project.org/package=future"><span class="pkg">future</span></a>.
To initialize future-based parallelization, select an appropriate backend and
specify the amount of workers.
For example, to use a PSOCK based cluster backend do:
</p>
<div class="sourceCode r"><pre>future::plan(multisession, workers = 2)
&lt;iml function here&gt;
</pre></div>
<p>Consult the resources of the <a href="https://CRAN.R-project.org/package=future"><span class="pkg">future</span></a> package for more parallel
backend options.
</p>


<h3>Super class</h3>

<p><code><a href="#topic+InterpretationMethod">iml::InterpretationMethod</a></code> -&gt; <code>FeatureEffects</code>
</p>


<h3>Public fields</h3>

<div class="r6-fields">

<dl>
<dt><code>grid.size</code></dt><dd><p>(<code>numeric(1)</code> | <code>numeric(2)</code>)<br />
The size of the grid.</p>
</dd>
<dt><code>method</code></dt><dd><p>(<code>character(1)</code>)<br />
</p>

<ul>
<li><p> &quot;ale&quot; for accumulated local effects,
</p>
</li>
<li><p> &quot;pdp&quot; for partial dependence plot,
</p>
</li>
<li><p> &quot;ice&quot; for individual conditional expectation curves,
</p>
</li>
<li><p> &quot;pdp+ ice&quot; for partial dependence plot and ice curves within the same
plot.
</p>
</li></ul>
</dd>
<dt><code>effects</code></dt><dd><p>(<a href="base.html#topic+list">list</a>)<br />
Named list of FeatureEffects.</p>
</dd>
<dt><code>features</code></dt><dd><p>(<code>character()</code>)<br />
The names of the features for which the effects were computed.</p>
</dd>
<dt><code>center.at</code></dt><dd><p><a href="base.html#topic+numeric">numeric</a><br />
Value at which the plot was centered. Ignored in the case of two
features.</p>
</dd>
</dl>

</div>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-FeatureEffects-new"><code>FeatureEffects$new()</code></a>
</p>
</li>
<li> <p><a href="#method-FeatureEffects-clone"><code>FeatureEffects$clone()</code></a>
</p>
</li></ul>



<details open><summary>Inherited methods</summary>
<ul>
<li><span class="pkg-link" data-pkg="iml" data-topic="InterpretationMethod" data-id="plot"><a href='../../iml/html/InterpretationMethod.html#method-InterpretationMethod-plot'><code>iml::InterpretationMethod$plot()</code></a></span></li>
<li><span class="pkg-link" data-pkg="iml" data-topic="InterpretationMethod" data-id="print"><a href='../../iml/html/InterpretationMethod.html#method-InterpretationMethod-print'><code>iml::InterpretationMethod$print()</code></a></span></li>
</ul>
</details>

<hr>
<a id="method-FeatureEffects-new"></a>



<h4>Method <code>new()</code></h4>

<p>Create a FeatureEffects object
</p>


<h5>Usage</h5>

<div class="r"><pre>FeatureEffects$new(
  predictor,
  features = NULL,
  method = "ale",
  center.at = NULL,
  grid.size = 20
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>predictor</code></dt><dd><p><a href="#topic+Predictor">Predictor</a><br />
The object (created with <code>Predictor$new()</code>) holding the machine
learning model and the data.</p>
</dd>
<dt><code>features</code></dt><dd><p>(<code>character()</code>)<br />
The names of the features for which to compute the feature effects.</p>
</dd>
<dt><code>method</code></dt><dd><p>(<code>character(1)</code>)<br />
</p>

<ul>
<li><p> 'ale' for accumulated local effects,
</p>
</li>
<li><p> 'pdp' for partial dependence plot,
</p>
</li>
<li><p> 'ice' for individual conditional expectation curves,
</p>
</li>
<li><p> 'pdp+ice' for partial dependence plot and ice curves within the same
plot.
</p>
</li></ul>
</dd>
<dt><code>center.at</code></dt><dd><p>(<code>numeric(1)</code>)<br />
Value at which the plot should be centered. Ignored in the case of two
features.</p>
</dd>
<dt><code>grid.size</code></dt><dd><p>(<code>numeric(1)</code> | <code>numeric(2)</code>)<br />
The size of the grid for evaluating the predictions.</p>
</dd>
<dt><code>feature</code></dt><dd><p>(<code>character(1)</code> | <code>character(2)</code> | <code>numeric(1)</code> |
<code>numeric(2)</code>)<br />
The feature name or index for which to compute the effects.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-FeatureEffects-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>FeatureEffects$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>




<h3>References</h3>

<p>Apley, D. W. 2016. &quot;Visualizing the Effects of Predictor Variables in Black
Box Supervised Learning Models.&quot; ArXiv Preprint.
</p>
<p>Friedman, J.H. 2001. &quot;Greedy Function Approximation: A Gradient Boosting
Machine.&quot; Annals of Statistics 29: 1189-1232.
</p>
<p>Goldstein, A., Kapelner, A., Bleich, J., and Pitkin, E. (2013). Peeking
Inside the Black Box: Visualizing Statistical Learning with Plots of
Individual Conditional Expectation, 1-22.
https://doi.org/10.1080/10618600.2014.907095
</p>


<h3>See Also</h3>

<p><a href="#topic+plot.FeatureEffects">plot.FeatureEffects</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># We train a random forest on the Boston dataset:
library("rpart")
data("Boston", package = "MASS")
rf &lt;- rpart(medv ~ ., data = Boston)
mod &lt;- Predictor$new(rf, data = Boston)

# Compute the accumulated local effects for all features
eff &lt;- FeatureEffects$new(mod)
eff$plot()
## Not run: 
# Again, but this time with a partial dependence plot
eff &lt;- FeatureEffects$new(mod, method = "pdp")
eff$plot()

# Only a subset of features
eff &lt;- FeatureEffects$new(mod, features = c("nox", "crim"))
eff$plot()

# You can access each FeatureEffect individually

eff.nox &lt;- eff$effects[["nox"]]
eff.nox$plot()


# FeatureEffects also works with multiclass classification
rf &lt;- rpart(Species ~ ., data = iris)
mod &lt;- Predictor$new(rf, data = iris, type = "prob")

FeatureEffects$new(mod)$plot(ncol = 2)

## End(Not run)
</code></pre>

<hr>
<h2 id='FeatureImp'>Feature importance</h2><span id='topic+FeatureImp'></span>

<h3>Description</h3>

<p><code>FeatureImp</code> computes feature importance for prediction models. The
importance is measured as the factor by which the model's prediction error
increases when the feature is shuffled.
</p>


<h3>Details</h3>

<p>To compute the feature importance for a single feature, the model prediction
loss (error) is measured before and after shuffling the values of the
feature. By shuffling the feature values, the association between the outcome
and the feature is destroyed. The larger the increase in prediction error,
the more important the feature was. The shuffling is repeated to get more
accurate results, since the permutation feature importance tends to be quite
unstable.
Read the Interpretable Machine Learning book to learn about feature
importance in detail:
<a href="https://christophm.github.io/interpretable-ml-book/feature-importance.html">https://christophm.github.io/interpretable-ml-book/feature-importance.html</a>
</p>
<p>The loss function can be either specified via a string, or by handing a
function to <code>FeatureImp()</code>. If you want to use your own loss function it
should have this signature:
</p>
<div class="sourceCode"><pre>function(actual, predicted)
</pre></div>
<p>Using the string is
a shortcut to using loss functions from the <code>Metrics</code> package. Only use
functions that return a single performance value, not a vector. Allowed
losses are: <code>"ce"</code>, <code>"f1"</code>, <code>"logLoss"</code>, <code>"mae"</code>, <code>"mse"</code>, <code>"rmse"</code>, <code>"mape"</code>,
<code>"mdae"</code>, <code>"msle"</code>, <code>"percent_bias"</code>, <code>"rae"</code>, <code>"rmse"</code>, <code>"rmsle"</code>, <code>"rse"</code>,
<code>"rrse"</code> and <code>"smape"</code>.
</p>
<p>See <code>library(help = "Metrics")</code> to get a list of functions.
</p>


<h3>Parallelization</h3>

<p>Parallelization is supported via package <a href="https://CRAN.R-project.org/package=future"><span class="pkg">future</span></a>.
To initialize future-based parallelization, select an appropriate backend and
specify the amount of workers.
For example, to use a PSOCK based cluster backend do:
</p>
<div class="sourceCode r"><pre>future::plan(multisession, workers = 2)
&lt;iml function here&gt;
</pre></div>
<p>Consult the resources of the <a href="https://CRAN.R-project.org/package=future"><span class="pkg">future</span></a> package for more parallel
backend options.
</p>


<h3>Super class</h3>

<p><code><a href="#topic+InterpretationMethod">iml::InterpretationMethod</a></code> -&gt; <code>FeatureImp</code>
</p>


<h3>Public fields</h3>

<div class="r6-fields">

<dl>
<dt><code>loss</code></dt><dd><p>(<code>character(1)</code> | <a href="base.html#topic+function">function</a>)<br />
The loss function. Either the name of a loss (e.g. <code>"ce"</code> for
classification or <code>"mse"</code>) or a function.</p>
</dd>
<dt><code>original.error</code></dt><dd><p>(<code>numeric(1)</code>)<br />
The loss of the model before perturbing features.</p>
</dd>
<dt><code>n.repetitions</code></dt><dd><p><a href="base.html#topic+integer">integer</a><br />
Number of repetitions.</p>
</dd>
<dt><code>compare</code></dt><dd><p>(<code>character(1)</code>)<br /> Either <code>"ratio"</code> or <code>"difference"</code>,
depending on whether the importance was calculated as difference
between original model error and model error after permutation or as
ratio.</p>
</dd>
<dt><code>features</code></dt><dd><p>(<code>list</code>)<br /> Features for which importance scores are to
be calculated. The names are the feature/group names, while the contents
specify which feature(s) are to be permuted.</p>
</dd>
</dl>

</div>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-FeatureImp-new"><code>FeatureImp$new()</code></a>
</p>
</li>
<li> <p><a href="#method-FeatureImp-clone"><code>FeatureImp$clone()</code></a>
</p>
</li></ul>



<details open><summary>Inherited methods</summary>
<ul>
<li><span class="pkg-link" data-pkg="iml" data-topic="InterpretationMethod" data-id="plot"><a href='../../iml/html/InterpretationMethod.html#method-InterpretationMethod-plot'><code>iml::InterpretationMethod$plot()</code></a></span></li>
<li><span class="pkg-link" data-pkg="iml" data-topic="InterpretationMethod" data-id="print"><a href='../../iml/html/InterpretationMethod.html#method-InterpretationMethod-print'><code>iml::InterpretationMethod$print()</code></a></span></li>
</ul>
</details>

<hr>
<a id="method-FeatureImp-new"></a>



<h4>Method <code>new()</code></h4>

<p>Create a FeatureImp object
</p>


<h5>Usage</h5>

<div class="r"><pre>FeatureImp$new(
  predictor,
  loss,
  compare = "ratio",
  n.repetitions = 5,
  features = NULL
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>predictor</code></dt><dd><p><a href="#topic+Predictor">Predictor</a><br />
The object (created with <code>Predictor$new()</code>) holding the machine
learning model and the data.</p>
</dd>
<dt><code>loss</code></dt><dd><p>(<code>character(1)</code> | <a href="base.html#topic+function">function</a>)<br />
The loss function. Either the name of a loss (e.g. <code>"ce"</code> for
classification or <code>"mse"</code>) or a function. See Details for allowed
losses.</p>
</dd>
<dt><code>compare</code></dt><dd><p>(<code>character(1)</code>)<br />
Either <code>"ratio"</code> or <code>"difference"</code>.
Should importance be measured as the difference or as the ratio of
original model error and model error after permutation?
</p>

<ul>
<li><p> Ratio: error.permutation/error.orig
</p>
</li>
<li><p> Difference: error.permutation - error.orig
</p>
</li></ul>
</dd>
<dt><code>n.repetitions</code></dt><dd><p>(<code>numeric(1)</code>)<br />
How often should the shuffling of the feature be repeated?
The higher the number of repetitions the more stable and accurate the
results become.</p>
</dd>
<dt><code>features</code></dt><dd><p>(<code style="white-space: pre;">&#8288;character or list&#8288;</code>)<br />
For which features do you want importance scores calculated. The default
value of <code>NULL</code> implies all features. Use a named list of character vectors
to define groups of features for which joint importance will be calculated.
See examples.</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>(data.frame)<br />
data.frame with the results of the feature importance computation. One
row per feature with the following columns:
</p>

<ul>
<li><p> importance.05 (5% quantile of importance values from the repetitions)
</p>
</li>
<li><p> importance (median importance)
</p>
</li>
<li><p> importance.95 (95% quantile) and the permutation.error (median error
over all repetitions).
</p>
</li></ul>

<p>The distribution of the importance is also visualized as a bar in the
plots, the median importance over the repetitions as a point.
</p>


<hr>
<a id="method-FeatureImp-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>FeatureImp$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>




<h3>References</h3>

<p>Fisher, A., Rudin, C., and Dominici, F. (2018). Model Class Reliance:
Variable Importance Measures for any Machine Learning Model Class, from the
&quot;Rashomon&quot; Perspective. Retrieved from http://arxiv.org/abs/1801.01489
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library("rpart")
# We train a tree on the Boston dataset:
data("Boston", package = "MASS")
tree &lt;- rpart(medv ~ ., data = Boston)
y &lt;- Boston$medv
X &lt;- Boston[-which(names(Boston) == "medv")]
mod &lt;- Predictor$new(tree, data = X, y = y)


# Compute feature importances as the performance drop in mean absolute error
imp &lt;- FeatureImp$new(mod, loss = "mae")

# Plot the results directly
plot(imp)


# Since the result is a ggplot object, you can extend it:
library("ggplot2")
plot(imp) + theme_bw()
# If you want to do your own thing, just extract the data:
imp.dat &lt;- imp$results
head(imp.dat)
ggplot(imp.dat, aes(x = feature, y = importance)) +
  geom_point() +
  theme_bw()

# We can also look at the difference in model error instead of the ratio
imp &lt;- FeatureImp$new(mod, loss = "mae", compare = "difference")

# Plot the results directly
plot(imp)

# We can calculate feature importance for a subset of features 
imp &lt;- FeatureImp$new(mod, loss = "mae", features = c("crim", "zn", "indus"))
plot(imp)

# We can calculate joint importance of groups of features
groups = list(
 grp1 = c("crim", "zn", "indus", "chas"),
 grp2 = c("nox", "rm", "age", "dis"),
 grp3 = c("rad", "tax", "ptratio", "black", "lstat")
)
imp &lt;- FeatureImp$new(mod, loss = "mae", features = groups)
plot(imp)

# FeatureImp also works with multiclass classification.
# In this case, the importance measurement regards all classes
tree &lt;- rpart(Species ~ ., data = iris)
X &lt;- iris[-which(names(iris) == "Species")]
y &lt;- iris$Species
mod &lt;- Predictor$new(tree, data = X, y = y, type = "prob")

# For some models we have to specify additional arguments for the predict function
imp &lt;- FeatureImp$new(mod, loss = "ce")
plot(imp)

# For multiclass classification models, you can choose to only compute
# performance for one class.
# Make sure to adapt y
mod &lt;- Predictor$new(tree,
  data = X, y = y == "virginica",
  type = "prob", class = "virginica"
)
imp &lt;- FeatureImp$new(mod, loss = "ce")
plot(imp)
</code></pre>

<hr>
<h2 id='has.predict'>returns TRUE if object has predict function</h2><span id='topic+has.predict'></span>

<h3>Description</h3>

<p>returns TRUE if object has predict function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>has.predict(object)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="has.predict_+3A_object">object</code></td>
<td>
<p>The object to check.</p>
</td></tr>
</table>

<hr>
<h2 id='iml-package'>Make machine learning models and predictions interpretable</h2><span id='topic+iml'></span><span id='topic+iml-package'></span>

<h3>Description</h3>

<p>The iml package provides tools to analyze machine learning models and predictions.
</p>


<h3>Author(s)</h3>

<p><strong>Maintainer</strong>: Giuseppe Casalicchio <a href="mailto:giuseppe.casalicchio@lmu.de">giuseppe.casalicchio@lmu.de</a>
</p>
<p>Authors:
</p>

<ul>
<li><p> Christoph Molnar <a href="mailto:christoph.molnar@gmail.com">christoph.molnar@gmail.com</a>
</p>
</li>
<li><p> Patrick Schratz <a href="mailto:patrick.schratz@gmail.com">patrick.schratz@gmail.com</a> (<a href="https://orcid.org/0000-0003-0748-6624">ORCID</a>)
</p>
</li></ul>



<h3>See Also</h3>

<p><a href="https://christophm.github.io/interpretable-ml-book/agnostic">Book on Interpretable Machine Learning</a>
</p>

<hr>
<h2 id='impute_cells'>Impute missing cells of grid</h2><span id='topic+impute_cells'></span>

<h3>Description</h3>

<p>by default assumes first column of cell.dat is x1 and second is x2
leave grid1 NULL if feature x1 is a factor
the difference variable has to be named .yhat.diff
</p>


<h3>Usage</h3>

<pre><code class='language-R'>impute_cells(cell.dat, grid1 = NULL, grid2, x1.ind = 1, x2.ind = 2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="impute_cells_+3A_cell.dat">cell.dat</code></td>
<td>
<p>data.table with at least 4 columns: .yhat.diff and the two interval indices.
Make sure that empty cells are also included and cell.dat is not the sparse representation.</p>
</td></tr>
<tr><td><code id="impute_cells_+3A_grid1">grid1</code></td>
<td>
<p>data.frame where each row is the actual value for a given interval index for feature 1.
If empty impute_cells  assumes that the feature is categorical (factor).</p>
</td></tr>
<tr><td><code id="impute_cells_+3A_grid2">grid2</code></td>
<td>
<p>data.frame where each row is the actual value for a given interval index for feature 2</p>
</td></tr>
<tr><td><code id="impute_cells_+3A_x1.ind">x1.ind</code></td>
<td>
<p>column number or name of cell.dat for feature 1. If one feature is categorical, has to be x1</p>
</td></tr>
<tr><td><code id="impute_cells_+3A_x2.ind">x2.ind</code></td>
<td>
<p>column number or name of cell.dat for feature 2</p>
</td></tr>
</table>

<hr>
<h2 id='Interaction'>Feature interactions</h2><span id='topic+Interaction'></span>

<h3>Description</h3>

<p>Feature interactions
</p>
<p>Feature interactions
</p>


<h3>Details</h3>

<p><code>Interaction</code> estimates the feature interactions in a prediction model.
</p>
<p>Interactions between features are measured via the decomposition of the
prediction function: If a feature <code>j</code> has no interaction with any other
feature, the prediction function can be expressed as the sum of the partial
function that depends only on <code>j</code> and the partial function that only depends
on features other than <code>j</code>. If the variance of the full function is
completely explained by the sum of the partial functions, there is no
interaction between feature <code>j</code> and the other features. Any variance that is
not explained can be attributed to the interaction and is used as a measure
of interaction strength.
</p>
<p>The interaction strength between two features is the proportion of the
variance of the 2-dimensional partial dependence function that is not
explained by the sum of the two 1-dimensional partial dependence functions.
</p>
<p>The interaction is measured by Friedman's H-statistic (square root of the
H-squared test statistic) and takes on values between 0 (no interaction) to 1
(100% of standard deviation of f(x) du to interaction).
</p>
<p>To learn more about interaction effects, read the Interpretable Machine Learning book:
<a href="https://christophm.github.io/interpretable-ml-book/interaction.html">https://christophm.github.io/interpretable-ml-book/interaction.html</a>
</p>


<h3>Parallelization</h3>

<p>Parallelization is supported via package <a href="https://CRAN.R-project.org/package=future"><span class="pkg">future</span></a>.
To initialize future-based parallelization, select an appropriate backend and
specify the amount of workers.
For example, to use a PSOCK based cluster backend do:
</p>
<div class="sourceCode r"><pre>future::plan(multisession, workers = 2)
&lt;iml function here&gt;
</pre></div>
<p>Consult the resources of the <a href="https://CRAN.R-project.org/package=future"><span class="pkg">future</span></a> package for more parallel
backend options.
</p>


<h3>Super class</h3>

<p><code><a href="#topic+InterpretationMethod">iml::InterpretationMethod</a></code> -&gt; <code>Interaction</code>
</p>


<h3>Public fields</h3>

<div class="r6-fields">

<dl>
<dt><code>grid.size</code></dt><dd><p>(<code>logical(1)</code>)<br />
The number of values per feature that should be used to estimate the
interaction strength.</p>
</dd>
</dl>

</div>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-Interaction-new"><code>Interaction$new()</code></a>
</p>
</li>
<li> <p><a href="#method-Interaction-clone"><code>Interaction$clone()</code></a>
</p>
</li></ul>



<details open><summary>Inherited methods</summary>
<ul>
<li><span class="pkg-link" data-pkg="iml" data-topic="InterpretationMethod" data-id="plot"><a href='../../iml/html/InterpretationMethod.html#method-InterpretationMethod-plot'><code>iml::InterpretationMethod$plot()</code></a></span></li>
<li><span class="pkg-link" data-pkg="iml" data-topic="InterpretationMethod" data-id="print"><a href='../../iml/html/InterpretationMethod.html#method-InterpretationMethod-print'><code>iml::InterpretationMethod$print()</code></a></span></li>
</ul>
</details>

<hr>
<a id="method-Interaction-new"></a>



<h4>Method <code>new()</code></h4>

<p>Create an Interaction object
</p>


<h5>Usage</h5>

<div class="r"><pre>Interaction$new(predictor, feature = NULL, grid.size = 30)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>predictor</code></dt><dd><p><a href="#topic+Predictor">Predictor</a><br />
The object (created with <code>Predictor$new()</code>) holding the machine
learning model and the data.</p>
</dd>
<dt><code>feature</code></dt><dd><p>(<code>character(1)</code> | <code>character(2)</code> | <code>numeric(1)</code> |
<code>numeric(2)</code>)<br />
The feature name or index for which to compute the effects.</p>
</dd>
<dt><code>grid.size</code></dt><dd><p>(<code>numeric(1)</code> | <code>numeric(2)</code>)<br />
The size of the grid for evaluating the predictions.</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p><a href="base.html#topic+data.frame">data.frame</a> with the interaction strength (column <code>.interation</code>) per
feature calculated as Friedman's H-statistic and - in the case of a
multi-dimensional outcome - per class.
</p>


<hr>
<a id="method-Interaction-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>Interaction$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>




<h3>References</h3>

<p>Friedman, Jerome H., and Bogdan E. Popescu. &quot;Predictive learning
via rule ensembles.&quot; The Annals of Applied Statistics 2.3 (2008): 916-954.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library("rpart")
set.seed(42)
# Fit a CART on the Boston housing data set
data("Boston", package = "MASS")
rf &lt;- rpart(medv ~ ., data = Boston)
# Create a model object
mod &lt;- Predictor$new(rf, data = Boston[-which(names(Boston) == "medv")])

# Measure the interaction strength
ia &lt;- Interaction$new(mod)

# Plot the resulting leaf nodes
plot(ia)

# Extract the results
dat &lt;- ia$results
head(dat)

# Interaction also works with multiclass classification
rf &lt;- rpart(Species ~ ., data = iris)
mod &lt;- Predictor$new(rf, data = iris, type = "prob")

# For some models we have to specify additional arguments for the
# predict function
ia &lt;- Interaction$new(mod)

ia$plot()

# For multiclass classification models, you can choose to only show one class:
mod &lt;- Predictor$new(rf, data = iris, type = "prob", class = "virginica")
plot(Interaction$new(mod))

## End(Not run)

</code></pre>

<hr>
<h2 id='InterpretationMethod'>Interpretation Method</h2><span id='topic+InterpretationMethod'></span>

<h3>Description</h3>

<p>Superclass container for Interpretation Method objects
</p>


<h3>Public fields</h3>

<div class="r6-fields">

<dl>
<dt><code>results</code></dt><dd><p><a href="base.html#topic+data.frame">data.frame</a><br />
The aggregated results of the experiment</p>
</dd>
<dt><code>predictor</code></dt><dd><p>Predictor object.</p>
</dd>
</dl>

</div>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-InterpretationMethod-new"><code>InterpretationMethod$new()</code></a>
</p>
</li>
<li> <p><a href="#method-InterpretationMethod-plot"><code>InterpretationMethod$plot()</code></a>
</p>
</li>
<li> <p><a href="#method-InterpretationMethod-print"><code>InterpretationMethod$print()</code></a>
</p>
</li>
<li> <p><a href="#method-InterpretationMethod-clone"><code>InterpretationMethod$clone()</code></a>
</p>
</li></ul>


<hr>
<a id="method-InterpretationMethod-new"></a>



<h4>Method <code>new()</code></h4>

<p>Create an InterpretationMethod object
</p>


<h5>Usage</h5>

<div class="r"><pre>InterpretationMethod$new(predictor)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>predictor</code></dt><dd><p><a href="#topic+Predictor">Predictor</a><br />
The object (created with <code>Predictor$new()</code>) holding the machine
learning model and the data.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-InterpretationMethod-plot"></a>



<h4>Method <code>plot()</code></h4>

<p>Plot function. Calls <code>private$generatePlot()</code> of the
respective subclass.
</p>


<h5>Usage</h5>

<div class="r"><pre>InterpretationMethod$plot(...)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>...</code></dt><dd><p>Passed to <code>private$generatePlot()</code>.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-InterpretationMethod-print"></a>



<h4>Method <code>print()</code></h4>

<p>Printer for InterpretationMethod objects
</p>


<h5>Usage</h5>

<div class="r"><pre>InterpretationMethod$print()</pre></div>


<hr>
<a id="method-InterpretationMethod-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>InterpretationMethod$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>



<hr>
<h2 id='LocalModel'>LocalModel</h2><span id='topic+LocalModel'></span>

<h3>Description</h3>

<p><code>LocalModel</code> fits locally weighted linear regression models (logistic
regression for classification) to explain single predictions of a prediction
model.
</p>


<h3>Details</h3>

<p>A weighted glm is fitted with the machine learning model prediction as
target. Data points are weighted by their proximity to the instance to be
explained, using the gower proximity measure. L1-regularization is used to
make the results sparse.
</p>
<p>The resulting model can be seen as a surrogate for the machine learning
model, which is only valid for that one point. Categorical features are
binarized, depending on the category of the instance to be explained: 1 if
the category is the same, 0 otherwise.
</p>
<p>Please note that scaling continuous features in the machine learning method
might be advisable when using LIME as an interpretation technique. LIME uses
a distance measure to compute proximity weights for the weighted glm. Hence,
the original scale of the features may influence the distance measure and
therewith LIME results.
</p>
<p>To learn more about local models, read the Interpretable Machine Learning
book: <a href="https://christophm.github.io/interpretable-ml-book/lime.html">https://christophm.github.io/interpretable-ml-book/lime.html</a>
</p>
<p>The approach is similar to LIME, but has the following differences:
</p>

<ul>
<li> <p><strong>Distance measure</strong>: Uses as default the gower proximity (= 1 - gower
distance) instead of a kernel based on the Euclidean distance. Has the
advantage to have a meaningful neighborhood and no kernel width to tune.
When the distance is not <code>"gower"</code>, then the <code><a href="stats.html#topic+dist">stats::dist()</a></code> function with the
chosen method will be used, and turned into a similarity measure:
<code class="reqn">sqrt(exp(-(distance^2) / (kernel.width^2)))</code>.
</p>
</li>
<li> <p><strong>Sampling</strong>: Uses the original data instead of sampling from normal
distributions. Has the advantage to follow the original data distribution.
</p>
</li>
<li> <p><strong>Visualization</strong>: Plots effects instead of betas. Both are the same for binary
features, but ared different for numerical features. For numerical features,
plotting the betas makes no sense, because a negative beta might still
increase the prediction when the feature value is also negative.
</p>
</li></ul>

<p>To learn more about local surrogate models, read the Interpretable Machine
Learning book:
<a href="https://christophm.github.io/interpretable-ml-book/lime.html">https://christophm.github.io/interpretable-ml-book/lime.html</a>
</p>


<h3>Super class</h3>

<p><code><a href="#topic+InterpretationMethod">iml::InterpretationMethod</a></code> -&gt; <code>LocalModel</code>
</p>


<h3>Public fields</h3>

<div class="r6-fields">

<dl>
<dt><code>x.interest</code></dt><dd><p><a href="base.html#topic+data.frame">data.frame</a><br />
Single row with the instance to be explained.</p>
</dd>
<dt><code>k</code></dt><dd><p><code>numeric(1)</code><br />
The number of features as set by the user.</p>
</dd>
<dt><code>model</code></dt><dd><p><code>glmnet</code><br />
The fitted local model.</p>
</dd>
<dt><code>best.fit.index</code></dt><dd><p><code>numeric(1)</code><br />
The index of the best glmnet fit.</p>
</dd>
</dl>

</div>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-LocalModel-new"><code>LocalModel$new()</code></a>
</p>
</li>
<li> <p><a href="#method-LocalModel-predict"><code>LocalModel$predict()</code></a>
</p>
</li>
<li> <p><a href="#method-LocalModel-explain"><code>LocalModel$explain()</code></a>
</p>
</li>
<li> <p><a href="#method-LocalModel-clone"><code>LocalModel$clone()</code></a>
</p>
</li></ul>



<details open><summary>Inherited methods</summary>
<ul>
<li><span class="pkg-link" data-pkg="iml" data-topic="InterpretationMethod" data-id="plot"><a href='../../iml/html/InterpretationMethod.html#method-InterpretationMethod-plot'><code>iml::InterpretationMethod$plot()</code></a></span></li>
<li><span class="pkg-link" data-pkg="iml" data-topic="InterpretationMethod" data-id="print"><a href='../../iml/html/InterpretationMethod.html#method-InterpretationMethod-print'><code>iml::InterpretationMethod$print()</code></a></span></li>
</ul>
</details>

<hr>
<a id="method-LocalModel-new"></a>



<h4>Method <code>new()</code></h4>

<p>Create a Local Model object.
</p>


<h5>Usage</h5>

<div class="r"><pre>LocalModel$new(
  predictor,
  x.interest,
  dist.fun = "gower",
  gower.power = 1,
  kernel.width = NULL,
  k = 3
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>predictor</code></dt><dd><p><a href="#topic+Predictor">Predictor</a><br />
The object (created with <code>Predictor$new()</code>) holding the machine
learning model and the data.</p>
</dd>
<dt><code>x.interest</code></dt><dd><p><a href="base.html#topic+data.frame">data.frame</a><br />
Single row with the instance to be explained.</p>
</dd>
<dt><code>dist.fun</code></dt><dd><p><code>character(1)</code>)<br />
The name of the distance function for computing proximities (weights in
the linear model). Defaults to <code>"gower"</code>. Otherwise will be forwarded
to <a href="stats.html#topic+dist">stats::dist</a>.</p>
</dd>
<dt><code>gower.power</code></dt><dd><p>(<code>numeric(1)</code>)<br />
The calculated gower proximity will be raised to the power of this
value. Can be used to specify the size of the neighborhood for the
LocalModel (similar to kernel.width for the euclidean distance).</p>
</dd>
<dt><code>kernel.width</code></dt><dd><p>(<code>numeric(1)</code>)<br />
The width of the kernel for the proximity computation.
Only used if dist.fun is not <code>"gower"</code>.</p>
</dd>
<dt><code>k</code></dt><dd><p><code>numeric(1)</code><br />
The number of features.</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p><a href="base.html#topic+data.frame">data.frame</a><br />
Results with the feature names (<code>feature</code>) and contributions to the
prediction.
</p>


<hr>
<a id="method-LocalModel-predict"></a>



<h4>Method <code>predict()</code></h4>

<p>Method to predict new data with the local model See also
<a href="#topic+predict.LocalModel">predict.LocalModel</a>.
</p>


<h5>Usage</h5>

<div class="r"><pre>LocalModel$predict(newdata = NULL, ...)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>newdata</code></dt><dd><p><a href="base.html#topic+data.frame">data.frame</a><br />
Data to predict on.</p>
</dd>
<dt><code>...</code></dt><dd><p>Not used</p>
</dd>
</dl>

</div>


<hr>
<a id="method-LocalModel-explain"></a>



<h4>Method <code>explain()</code></h4>

<p>Set a new data point to explain.
</p>


<h5>Usage</h5>

<div class="r"><pre>LocalModel$explain(x.interest)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>x.interest</code></dt><dd><p><a href="base.html#topic+data.frame">data.frame</a><br />
Single row with the instance to be explained.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-LocalModel-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>LocalModel$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>




<h3>References</h3>

<p>Ribeiro, M. T., Singh, S., &amp; Guestrin, C. (2016). &quot;Why Should I Trust You?&quot;:
Explaining the Predictions of Any Classifier. Retrieved from
http://arxiv.org/abs/1602.04938
</p>
<p>Gower, J. C. (1971), &quot;A general coefficient of similarity and some of its
properties&quot;. Biometrics, 27, 623&ndash;637.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+plot.LocalModel">plot.LocalModel</a></code> and <code><a href="#topic+predict.LocalModel">predict.LocalModel</a></code>
</p>
<p><code><a href="#topic+Shapley">Shapley</a></code> can also be used to explain single predictions
</p>
<p>The package <code>lime</code> with the original implementation
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library("randomForest")
# First we fit a machine learning model on the Boston housing data
data("Boston", package = "MASS")
X &lt;- Boston[-which(names(Boston) == "medv")]
rf &lt;- randomForest(medv ~ ., data = Boston, ntree = 50)
mod &lt;- Predictor$new(rf, data = X)

# Explain the first instance of the dataset with the LocalModel method:
x.interest &lt;- X[1, ]
lemon &lt;- LocalModel$new(mod, x.interest = x.interest, k = 2)
lemon

# Look at the results in a table
lemon$results
# Or as a plot
plot(lemon)

# Reuse the object with a new instance to explain
lemon$x.interest
lemon$explain(X[2, ])
lemon$x.interest
plot(lemon)

# LocalModel also works with multiclass classification
rf &lt;- randomForest(Species ~ ., data = iris, ntree = 50)
X &lt;- iris[-which(names(iris) == "Species")]
mod &lt;- Predictor$new(rf, data = X, type = "prob", class = "setosa")

# Then we explain the first instance of the dataset with the LocalModel method:
lemon &lt;- LocalModel$new(mod, x.interest = X[1, ], k = 2)
lemon$results
plot(lemon)
</code></pre>

<hr>
<h2 id='order_levels'>Order levels of a categorical features</h2><span id='topic+order_levels'></span>

<h3>Description</h3>

<p>Orders the levels by their similarity in other features. Computes per feature
the distance, sums up all distances and does multi-dimensional scaling
</p>


<h3>Usage</h3>

<pre><code class='language-R'>order_levels(dat, feature.name)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="order_levels_+3A_dat">dat</code></td>
<td>
<p>data.frame with the training data</p>
</td></tr>
<tr><td><code id="order_levels_+3A_feature.name">feature.name</code></td>
<td>
<p>the name of the categorical feature</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Goal: Compute the distances between two categories.
Input: Instances from category 1 and 2
</p>

<ol>
<li><p> For all features, do (excluding the categorical feature for which we are computing the order):
</p>
</li></ol>


<ul>
<li><p> If the feature is numerical: Take instances from category 1, calculate the
empirical cumulative probability distribution function (ecdf) of the
feature. The ecdf is a function that tells us for a given feature value, how
many values are smaller. Do the same for category 2. The distance is the
absolute maximum point-wise distance of the two ecdf. Practically, this
value is high when the distribution from one category is strongly shifted
far away from the other. This measure is also known as the
Kolmogorov-Smirnov distance
(<a href="https://en.wikipedia.org/wiki/Kolmogorov%E2%80%93Smirnov_test">https://en.wikipedia.org/wiki/Kolmogorov%E2%80%93Smirnov_test</a>).
</p>
</li>
<li><p> If the feature is categorical: Take instances from category 1 and
calculate a table with the relative frequency of each category of the other
feature. Do the same for instances from category 2. The distance is the sum
of the absolute difference of both relative frequency tables.
</p>
</li></ul>


<ol>
<li><p> Sum up the distances over all features
</p>
</li></ol>

<p>This algorithm we run for all pairs of categories.
Then we have a k times k matrix, when k is the number of categories, where
each entry is the distance between two categories. Still not enough to have a
single order, because, a (dis)similarity tells you the pair-wise distances,
but does not give you a one-dimensional ordering of the classes. To kind of
force this thing into a single dimension, we have to use a dimension
reduction trick called multi-dimensional scaling. This can be solved using
multi-dimensional scaling, which takes in a distance matrix and returns a
distance matrix with reduced dimension. In our case, we only want 1 dimension
left, so that we have a single ordering of the categories and can compute the
accumulated local effects. After reducing it to a single ordering, we are
done and can use this ordering to compute ALE. This is not the Holy Grail how
to order the factors, but one possibility.
</p>


<h3>Value</h3>

<p>the order of the levels (not levels itself)
</p>

<hr>
<h2 id='Partial'>Effect of one or two feature(s) on the model predictions (deprecated)</h2><span id='topic+Partial'></span>

<h3>Description</h3>

<p>Effect of one or two feature(s) on the model predictions (deprecated)
</p>
<p>Effect of one or two feature(s) on the model predictions (deprecated)
</p>


<h3>Details</h3>

<p>Deprecated, please use <a href="#topic+FeatureEffect">FeatureEffect</a>.
</p>


<h3>Super classes</h3>

<p><code><a href="#topic+InterpretationMethod">iml::InterpretationMethod</a></code> -&gt; <code><a href="#topic+FeatureEffect">iml::FeatureEffect</a></code> -&gt; <code>Partial</code>
</p>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-Partial-new"><code>Partial$new()</code></a>
</p>
</li>
<li> <p><a href="#method-Partial-clone"><code>Partial$clone()</code></a>
</p>
</li></ul>



<details open><summary>Inherited methods</summary>
<ul>
<li><span class="pkg-link" data-pkg="iml" data-topic="InterpretationMethod" data-id="plot"><a href='../../iml/html/InterpretationMethod.html#method-InterpretationMethod-plot'><code>iml::InterpretationMethod$plot()</code></a></span></li>
<li><span class="pkg-link" data-pkg="iml" data-topic="InterpretationMethod" data-id="print"><a href='../../iml/html/InterpretationMethod.html#method-InterpretationMethod-print'><code>iml::InterpretationMethod$print()</code></a></span></li>
<li><span class="pkg-link" data-pkg="iml" data-topic="FeatureEffect" data-id="center"><a href='../../iml/html/FeatureEffect.html#method-FeatureEffect-center'><code>iml::FeatureEffect$center()</code></a></span></li>
<li><span class="pkg-link" data-pkg="iml" data-topic="FeatureEffect" data-id="predict"><a href='../../iml/html/FeatureEffect.html#method-FeatureEffect-predict'><code>iml::FeatureEffect$predict()</code></a></span></li>
<li><span class="pkg-link" data-pkg="iml" data-topic="FeatureEffect" data-id="set.feature"><a href='../../iml/html/FeatureEffect.html#method-FeatureEffect-set.feature'><code>iml::FeatureEffect$set.feature()</code></a></span></li>
</ul>
</details>

<hr>
<a id="method-Partial-new"></a>



<h4>Method <code>new()</code></h4>

<p>Effect of one or two feature(s) on the model predictions
</p>


<h5>Usage</h5>

<div class="r"><pre>Partial$new(
  predictor,
  feature,
  aggregation = "pdp",
  ice = TRUE,
  center.at = NULL,
  grid.size = 20
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>predictor</code></dt><dd><p><a href="#topic+Predictor">Predictor</a><br />
The object (created with <code>Predictor$new()</code>) holding the machine
learning model and the data.</p>
</dd>
<dt><code>feature</code></dt><dd><p>(<code>character(1)</code> | <code>character(2)</code> | <code>numeric(1)</code> |
<code>numeric(2)</code>)<br />
The feature name or index for which to compute the effects.</p>
</dd>
<dt><code>aggregation</code></dt><dd><p>(<code>character(1)</code>)<br />
The aggregation approach to use. Possible values are <code>"pdp"</code>,
<code>"ale"</code> or <code>"none"</code>.</p>
</dd>
<dt><code>ice</code></dt><dd><p><a href="base.html#topic+logical">logical</a><br />
Whether to compute ice plots.</p>
</dd>
<dt><code>center.at</code></dt><dd><p>(<code>numeric(1)</code>)<br />
Value at which the plot should be centered. Ignored in the case of two
features.</p>
</dd>
<dt><code>grid.size</code></dt><dd><p>(<code>numeric(1)</code> | <code>numeric(2)</code>)<br />
The size of the grid for evaluating the predictions.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-Partial-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>Partial$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>




<h3>See Also</h3>

<p><a href="#topic+FeatureEffect">FeatureEffect</a>
</p>

<hr>
<h2 id='plot.FeatureEffect'>Plot FeatureEffect</h2><span id='topic+plot.FeatureEffect'></span>

<h3>Description</h3>

<p><code>plot.FeatureEffect()</code> plots the results of a <a href="#topic+FeatureEffect">FeatureEffect</a> object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'FeatureEffect'
plot(x, rug = TRUE, show.data = FALSE, ylim = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.FeatureEffect_+3A_x">x</code></td>
<td>
<p>A <a href="#topic+FeatureEffect">FeatureEffect</a> object.</p>
</td></tr>
<tr><td><code id="plot.FeatureEffect_+3A_rug">rug</code></td>
<td>
<p><a href="base.html#topic+logical">logical</a><br />
Should a rug be plotted to indicate the feature distribution? The rug will
be jittered a bit, so the location may not be exact, but it avoids
overplotting.</p>
</td></tr>
<tr><td><code id="plot.FeatureEffect_+3A_show.data">show.data</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
Should the data points be shown? Only affects 2D plots, and ignored for 1D
plots, because rug has the same information.</p>
</td></tr>
<tr><td><code id="plot.FeatureEffect_+3A_ylim">ylim</code></td>
<td>
<p>(<code>numeric(2)</code>)<br /> Vector with two coordinates for the y-axis.
Only works when one feature is used in <a href="#topic+FeatureEffect">FeatureEffect</a>, ignored when two
are used.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>ggplot2 plot object
</p>


<h3>See Also</h3>

<p><a href="#topic+FeatureEffect">FeatureEffect</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># We train a random forest on the Boston dataset:
if (require("randomForest")) {
  data("Boston", package = "MASS")
  rf &lt;- randomForest(medv ~ ., data = Boston, ntree = 50)
  mod &lt;- Predictor$new(rf, data = Boston)

  # Compute the ALE for the first feature
  eff &lt;- FeatureEffect$new(mod, feature = "crim")

  # Plot the results directly
  plot(eff)
}
</code></pre>

<hr>
<h2 id='plot.FeatureEffects'>Plot FeatureEffect</h2><span id='topic+plot.FeatureEffects'></span>

<h3>Description</h3>

<p>plot.FeatureEffect() plots the results of a FeatureEffect object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'FeatureEffects'
plot(x, features = NULL, nrows = NULL, ncols = NULL, fixed_y = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.FeatureEffects_+3A_x">x</code></td>
<td>
<p>A <a href="#topic+FeatureEffect">FeatureEffect</a> object.</p>
</td></tr>
<tr><td><code id="plot.FeatureEffects_+3A_features">features</code></td>
<td>
<p><a href="base.html#topic+character">character</a> For which features should the effects be
plotted? Default is all features. You can also sort the order of the plots
with this argument.</p>
</td></tr>
<tr><td><code id="plot.FeatureEffects_+3A_nrows">nrows</code></td>
<td>
<p>The number of rows in the table of graphics</p>
</td></tr>
<tr><td><code id="plot.FeatureEffects_+3A_ncols">ncols</code></td>
<td>
<p>The number of columns in the table of graphics</p>
</td></tr>
<tr><td><code id="plot.FeatureEffects_+3A_fixed_y">fixed_y</code></td>
<td>
<p>Should the y-axis range be the same for all effects? Defaults
to TRUE.</p>
</td></tr>
<tr><td><code id="plot.FeatureEffects_+3A_...">...</code></td>
<td>
<p>Further arguments for <code>FeatureEffect$plot()</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>In contrast to other plot methods, for FeatureEffects the returned
plot is not a ggplot2 object, but a grid object, a collection of multiple
ggplot2 plots.
</p>


<h3>Value</h3>

<p>grid object
</p>


<h3>See Also</h3>

<p><a href="#topic+FeatureEffects">FeatureEffects</a> <a href="#topic+plot.FeatureEffect">plot.FeatureEffect</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># We train a random forest on the Boston dataset:
library("randomForest")
data("Boston", package = "MASS")
rf &lt;- randomForest(medv ~ ., data = Boston, ntree = 50)
mod &lt;- Predictor$new(rf, data = Boston)

# Compute the partial dependence for the first feature
eff &lt;- FeatureEffects$new(mod)

# Plot the results directly
eff$plot()

# For a subset of features
eff$plot(features = c("lstat", "crim"))

# With a different layout
eff$plot(nrows = 2)
</code></pre>

<hr>
<h2 id='plot.FeatureImp'>Plot Feature Importance</h2><span id='topic+plot.FeatureImp'></span>

<h3>Description</h3>

<p><code>plot.FeatureImp()</code> plots the feature importance results of a FeatureImp
object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'FeatureImp'
plot(x, sort = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.FeatureImp_+3A_x">x</code></td>
<td>
<p>A <a href="#topic+FeatureImp">FeatureImp</a> object</p>
</td></tr>
<tr><td><code id="plot.FeatureImp_+3A_sort">sort</code></td>
<td>
<p>logical. Should the features be sorted in descending order?
Defaults to TRUE.</p>
</td></tr>
<tr><td><code id="plot.FeatureImp_+3A_...">...</code></td>
<td>
<p>Further arguments for the objects plot function</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The plot shows the importance per feature.
</p>
<p>When <code>n.repetitions</code> in <code>FeatureImp$new</code> was larger than 1, then we get
multiple importance estimates per feature. The importance are aggregated and
the plot shows the median importance per feature (as dots) and also the
90%-quantile, which helps to understand how much variance the computation has
per feature.
</p>


<h3>Value</h3>

<p>ggplot2 plot object
</p>


<h3>See Also</h3>

<p><a href="#topic+FeatureImp">FeatureImp</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library("rpart")
# We train a tree on the Boston dataset:
data("Boston", package = "MASS")
tree &lt;- rpart(medv ~ ., data = Boston)
y &lt;- Boston$medv
X &lt;- Boston[-which(names(Boston) == "medv")]
mod &lt;- Predictor$new(tree, data = X, y = y)

# Compute feature importances as the performance drop in mean absolute error
imp &lt;- FeatureImp$new(mod, loss = "mae")

# Plot the results directly
plot(imp)
</code></pre>

<hr>
<h2 id='plot.Interaction'>Plot Interaction</h2><span id='topic+plot.Interaction'></span>

<h3>Description</h3>

<p><code>plot.Interaction()</code> plots the results of an Interaction object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'Interaction'
plot(x, sort = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.Interaction_+3A_x">x</code></td>
<td>
<p>An Interaction R6 object</p>
</td></tr>
<tr><td><code id="plot.Interaction_+3A_sort">sort</code></td>
<td>
<p>logical. Should the features be sorted in descending order?
Defaults to TRUE.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>ggplot2 plot object
</p>


<h3>See Also</h3>

<p><a href="#topic+Interaction">Interaction</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># We train a tree on the Boston dataset:
## Not run: 
library("rpart")
data("Boston", package = "MASS")
rf &lt;- rpart(medv ~ ., data = Boston)
mod &lt;- Predictor$new(rf, data = Boston)

# Compute the interactions
ia &lt;- Interaction$new(mod)

# Plot the results directly
plot(ia)

## End(Not run)
</code></pre>

<hr>
<h2 id='plot.LocalModel'>Plot Local Model</h2><span id='topic+plot.LocalModel'></span>

<h3>Description</h3>

<p><code>plot.LocalModel()</code> plots the feature effects of a LocalModel object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'LocalModel'
plot(object)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.LocalModel_+3A_object">object</code></td>
<td>
<p>A LocalModel R6 object</p>
</td></tr>
</table>


<h3>Value</h3>

<p>ggplot2 plot object
</p>


<h3>See Also</h3>

<p><a href="#topic+LocalModel">LocalModel</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library("randomForest")
# First we fit a machine learning model on the Boston housing data
data("Boston", package = "MASS")
X &lt;- Boston[-which(names(Boston) == "medv")]
rf &lt;- randomForest(medv ~ ., data = Boston, ntree = 50)
mod &lt;- Predictor$new(rf, data = X)

# Explain the first instance of the dataset with the LocalModel method:
x.interest &lt;- X[1, ]
lemon &lt;- LocalModel$new(mod, x.interest = x.interest, k = 2)
plot(lemon)
</code></pre>

<hr>
<h2 id='plot.Shapley'>Plot Shapley</h2><span id='topic+plot.Shapley'></span>

<h3>Description</h3>

<p>plot.Shapley() plots the Shapley values - the contributions of feature values
to the prediction.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'Shapley'
plot(object, sort = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.Shapley_+3A_object">object</code></td>
<td>
<p>A Shapley R6 object</p>
</td></tr>
<tr><td><code id="plot.Shapley_+3A_sort">sort</code></td>
<td>
<p><a href="base.html#topic+logical">logical</a><br />
Should the feature values be sorted by Shapley value? Ignored for
multi.class output.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>ggplot2 plot object
</p>


<h3>See Also</h3>

<p><a href="#topic+Shapley">Shapley</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library("rpart")
# First we fit a machine learning model on the Boston housing data
data("Boston", package = "MASS")
rf &lt;- rpart(medv ~ ., data = Boston)
X &lt;- Boston[-which(names(Boston) == "medv")]
mod &lt;- Predictor$new(rf, data = X)

# Then we explain the first instance of the dataset with the Shapley method:
x.interest &lt;- X[1, ]
shapley &lt;- Shapley$new(mod, x.interest = x.interest)
plot(shapley)

## End(Not run)
</code></pre>

<hr>
<h2 id='plot.TreeSurrogate'>Plot Tree Surrogate</h2><span id='topic+plot.TreeSurrogate'></span>

<h3>Description</h3>

<p>Plot the response for <code>newdata</code> of a <a href="#topic+TreeSurrogate">TreeSurrogate</a> object.
Each plot facet is one leaf node and visualizes the distribution of the
<code class="reqn">\hat{y}</code> from the machine learning model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'TreeSurrogate'
plot(object)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.TreeSurrogate_+3A_object">object</code></td>
<td>
<p>A <a href="#topic+TreeSurrogate">TreeSurrogate</a> object.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>ggplot2 plot object
</p>


<h3>See Also</h3>

<p><a href="#topic+TreeSurrogate">TreeSurrogate</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library("randomForest")
# Fit a Random Forest on the Boston housing data set
data("Boston", package = "MASS")
rf &lt;- randomForest(medv ~ ., data = Boston, ntree = 50)
# Create a model object
mod &lt;- Predictor$new(rf, data = Boston[-which(names(Boston) == "medv")])

# Fit a decision tree as a surrogate for the whole random forest
dt &lt;- TreeSurrogate$new(mod)

# Plot the resulting leaf nodes
plot(dt)
</code></pre>

<hr>
<h2 id='predict.LocalModel'>Predict LocalModel</h2><span id='topic+predict.LocalModel'></span>

<h3>Description</h3>

<p>Predict the response for newdata with the LocalModel model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'LocalModel'
predict(object, newdata = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.LocalModel_+3A_object">object</code></td>
<td>
<p>A LocalModel R6 object</p>
</td></tr>
<tr><td><code id="predict.LocalModel_+3A_newdata">newdata</code></td>
<td>
<p>A data.frame for which to predict</p>
</td></tr>
<tr><td><code id="predict.LocalModel_+3A_...">...</code></td>
<td>
<p>Further arguments for the objects predict function</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data.frame with the predicted outcome.
</p>


<h3>See Also</h3>

<p><a href="#topic+LocalModel">LocalModel</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library("randomForest")
# First we fit a machine learning model on the Boston housing data
data("Boston", package = "MASS")
X &lt;- Boston[-which(names(Boston) == "medv")]
rf &lt;- randomForest(medv ~ ., data = Boston, ntree = 50)
mod &lt;- Predictor$new(rf, data = X)

# Explain the first instance of the dataset with the LocalModel method:
x.interest &lt;- X[1, ]
lemon &lt;- LocalModel$new(mod, x.interest = x.interest, k = 2)
predict(lemon, newdata = x.interest)
</code></pre>

<hr>
<h2 id='predict.TreeSurrogate'>Predict Tree Surrogate</h2><span id='topic+predict.TreeSurrogate'></span>

<h3>Description</h3>

<p>Predict the response for newdata of a <a href="#topic+TreeSurrogate">TreeSurrogate</a> object.
</p>
<p>This function makes the <a href="#topic+TreeSurrogate">TreeSurrogate</a> object call
its internal <code style="white-space: pre;">&#8288;$predict()&#8288;</code> method.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'TreeSurrogate'
predict(object, newdata, type = "prob", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.TreeSurrogate_+3A_object">object</code></td>
<td>
<p>The surrogate tree. A <a href="#topic+TreeSurrogate">TreeSurrogate</a> object.</p>
</td></tr>
<tr><td><code id="predict.TreeSurrogate_+3A_newdata">newdata</code></td>
<td>
<p>A <a href="base.html#topic+data.frame">data.frame</a> for which to predict.</p>
</td></tr>
<tr><td><code id="predict.TreeSurrogate_+3A_type">type</code></td>
<td>
<p>Either &quot;prob&quot; or &quot;class&quot;. Ignored if the surrogate tree does
regression.</p>
</td></tr>
<tr><td><code id="predict.TreeSurrogate_+3A_...">...</code></td>
<td>
<p>Further arguments for <code>predict_party</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data.frame with the predicted outcome.
In case of regression it is the predicted <code class="reqn">\hat{y}</code>. In case of
classification it is either the class probabilities (for type &quot;prob&quot;) or the
class label (type &quot;class&quot;)
</p>


<h3>See Also</h3>

<p><a href="#topic+TreeSurrogate">TreeSurrogate</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library("randomForest")
# Fit a Random Forest on the Boston housing data set
data("Boston", package = "MASS")
rf &lt;- randomForest(medv ~ ., data = Boston, ntree = 50)
# Create a model object
mod &lt;- Predictor$new(rf, data = Boston[-which(names(Boston) == "medv")])

# Fit a decision tree as a surrogate for the whole random forest
dt &lt;- TreeSurrogate$new(mod)

# Plot the resulting leaf nodes
predict(dt, newdata = Boston)
</code></pre>

<hr>
<h2 id='Predictor'>Predictor object</h2><span id='topic+Predictor'></span>

<h3>Description</h3>

<p>A <code>Predictor</code> object holds any machine learning model (<code>mlr</code>, <code>caret</code>,
<code>randomForest</code>, ...) and the data to be used for analyzing the model. The
interpretation methods in the <code>iml</code> package need the machine learning model
to be wrapped in a <code>Predictor</code> object.
</p>


<h3>Details</h3>

<p>A Predictor object is a container for the prediction model and the data.
This ensures that the machine learning model can be analyzed in a robust way.
</p>
<p>Note: In case of classification, the model should return one column per class
with the class probability.
</p>


<h3>Public fields</h3>

<div class="r6-fields">

<dl>
<dt><code>data</code></dt><dd><p><a href="base.html#topic+data.frame">data.frame</a><br />
Data object with the data for the model interpretation.</p>
</dd>
<dt><code>model</code></dt><dd><p>(any)<br />
The machine learning model.</p>
</dd>
<dt><code>batch.size</code></dt><dd><p><code>numeric(1)</code><br />
The number of rows to be input the model for prediction at once.</p>
</dd>
<dt><code>class</code></dt><dd><p><code>character(1)</code><br />
The class column to be returned.</p>
</dd>
<dt><code>prediction.colnames</code></dt><dd><p><a href="base.html#topic+character">character</a><br />
The column names of the predictions.</p>
</dd>
<dt><code>prediction.function</code></dt><dd><p><a href="base.html#topic+function">function</a><br />
The function to predict newdata.</p>
</dd>
<dt><code>task</code></dt><dd><p><code>character(1)</code><br />
The inferred prediction task: <code>"classification"</code> or <code>"regression"</code>.</p>
</dd>
</dl>

</div>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-Predictor-new"><code>Predictor$new()</code></a>
</p>
</li>
<li> <p><a href="#method-Predictor-predict"><code>Predictor$predict()</code></a>
</p>
</li>
<li> <p><a href="#method-Predictor-print"><code>Predictor$print()</code></a>
</p>
</li>
<li> <p><a href="#method-Predictor-clone"><code>Predictor$clone()</code></a>
</p>
</li></ul>


<hr>
<a id="method-Predictor-new"></a>



<h4>Method <code>new()</code></h4>

<p>Create a Predictor object
</p>


<h5>Usage</h5>

<div class="r"><pre>Predictor$new(
  model = NULL,
  data = NULL,
  predict.function = NULL,
  y = NULL,
  class = NULL,
  type = NULL,
  batch.size = 1000
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>model</code></dt><dd><p>any<br />
The machine learning model. Recommended are models from <code>mlr</code> and
<code>caret</code>. Other machine learning with a S3 predict functions work as
well, but less robust (e.g. <code>randomForest</code>).</p>
</dd>
<dt><code>data</code></dt><dd><p><a href="base.html#topic+data.frame">data.frame</a><br />
The data to be used for analyzing the prediction model. Allowed column
classes are: <a href="base.html#topic+numeric">numeric</a>, <a href="base.html#topic+factor">factor</a>, <a href="base.html#topic+integer">integer</a>, <a href="base.html#topic+ordered">ordered</a> and <a href="base.html#topic+character">character</a>
For some models the data can be extracted automatically.
<code>Predictor$new()</code> throws an error when it can't extract the data
automatically.</p>
</dd>
<dt><code>predict.function</code></dt><dd><p><a href="base.html#topic+function">function</a><br />
The function to predict newdata. Only needed if <code>model</code> is not a model
from <code>mlr</code> or <code>caret</code> package. The first argument of <code>predict.fun</code> has to
be the model, the second the <code>newdata</code>:
</p>
<div class="sourceCode"><pre>function(model, newdata)
</pre></div></dd>
<dt><code>y</code></dt><dd><p><code>character(1)</code> | <a href="base.html#topic+numeric">numeric</a> | <a href="base.html#topic+factor">factor</a><br /> The target vector or
(preferably) the name of the target column in the <code>data</code> argument.
Predictor tries to infer the target automatically from the model.</p>
</dd>
<dt><code>class</code></dt><dd><p><code>character(1)</code>)<br />
The class column to be returned in case
of multiclass output. You can either use numbers, e.g. <code>class=2</code> would
take the 2nd column from the predictions, or the column name of the
predicted class, e.g. <code>class="dog"</code>.</p>
</dd>
<dt><code>type</code></dt><dd><p><code>character(1)</code>)<br />
This argument is passed to the prediction
function of the model. For regression models you usually don't have to
provide the type argument. The classic use case is to say <code>type="prob"</code>
for classification models. Consult the documentation of the machine
learning package you use to find which type options you have. If both
<code>predict.fun</code> and <code>type</code> are used, then type is passed as an argument
to <code>predict.fun</code>.</p>
</dd>
<dt><code>batch.size</code></dt><dd><p><code>numeric(1)</code><br />
The maximum number of rows to be input the model for prediction at once.
Currently only respected for <a href="#topic+FeatureImp">FeatureImp</a>, <a href="#topic+Partial">Partial</a> and <a href="#topic+Interaction">Interaction</a>.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-Predictor-predict"></a>



<h4>Method <code>predict()</code></h4>

<p>Predict new data with the machine learning model.
</p>


<h5>Usage</h5>

<div class="r"><pre>Predictor$predict(newdata)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>newdata</code></dt><dd><p><a href="base.html#topic+data.frame">data.frame</a><br />
Data to predict on.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-Predictor-print"></a>



<h4>Method <code>print()</code></h4>

<p>Print the Predictor object.
</p>


<h5>Usage</h5>

<div class="r"><pre>Predictor$print()</pre></div>


<hr>
<a id="method-Predictor-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>Predictor$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>




<h3>Examples</h3>

<pre><code class='language-R'>library("mlr")
task &lt;- makeClassifTask(data = iris, target = "Species")
learner &lt;- makeLearner("classif.rpart", minsplit = 7, predict.type = "prob")
mod.mlr &lt;- train(learner, task)
mod &lt;- Predictor$new(mod.mlr, data = iris)
mod$predict(iris[1:5, ])

mod &lt;- Predictor$new(mod.mlr, data = iris, class = "setosa")
mod$predict(iris[1:5, ])

library("randomForest")
rf &lt;- randomForest(Species ~ ., data = iris, ntree = 20)


mod &lt;- Predictor$new(rf, data = iris, type = "prob")
mod$predict(iris[50:55, ])

# Feature importance needs the target vector, which needs to be supplied:
mod &lt;- Predictor$new(rf, data = iris, y = "Species", type = "prob")
</code></pre>

<hr>
<h2 id='probs.to.labels'>Turn class probabilities into class labels</h2><span id='topic+probs.to.labels'></span>

<h3>Description</h3>

<p>Turn class probabilities into class labels
</p>


<h3>Usage</h3>

<pre><code class='language-R'>probs.to.labels(prediction)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="probs.to.labels_+3A_prediction">prediction</code></td>
<td>
<p>Prediction object.</p>
</td></tr>
</table>

<hr>
<h2 id='Shapley'>Prediction explanations with game theory</h2><span id='topic+Shapley'></span>

<h3>Description</h3>

<p><code>Shapley</code> computes feature contributions for single predictions with the
Shapley value, an approach from cooperative game theory. The features values
of an instance cooperate to achieve the prediction. The Shapley value fairly
distributes the difference of the instance's prediction and the datasets
average prediction among the features.
</p>


<h3>Details</h3>

<p>For more details on the algorithm see
<a href="https://christophm.github.io/interpretable-ml-book/shapley.html">https://christophm.github.io/interpretable-ml-book/shapley.html</a>
</p>


<h3>Super class</h3>

<p><code><a href="#topic+InterpretationMethod">iml::InterpretationMethod</a></code> -&gt; <code>Shapley</code>
</p>


<h3>Public fields</h3>

<div class="r6-fields">

<dl>
<dt><code>x.interest</code></dt><dd><p><a href="base.html#topic+data.frame">data.frame</a><br />
Single row with the instance to be explained.</p>
</dd>
<dt><code>y.hat.interest</code></dt><dd><p><a href="base.html#topic+numeric">numeric</a><br />
Predicted value for instance of interest.</p>
</dd>
<dt><code>y.hat.average</code></dt><dd><p><code>numeric(1)</code><br />
Average predicted value for data <code>X</code>.</p>
</dd>
<dt><code>sample.size</code></dt><dd><p><code>numeric(1)</code><br />
The number of times coalitions/marginals are
sampled from data X. The higher the more accurate the explanations
become.</p>
</dd>
</dl>

</div>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-Shapley-new"><code>Shapley$new()</code></a>
</p>
</li>
<li> <p><a href="#method-Shapley-explain"><code>Shapley$explain()</code></a>
</p>
</li>
<li> <p><a href="#method-Shapley-clone"><code>Shapley$clone()</code></a>
</p>
</li></ul>



<details open><summary>Inherited methods</summary>
<ul>
<li><span class="pkg-link" data-pkg="iml" data-topic="InterpretationMethod" data-id="plot"><a href='../../iml/html/InterpretationMethod.html#method-InterpretationMethod-plot'><code>iml::InterpretationMethod$plot()</code></a></span></li>
<li><span class="pkg-link" data-pkg="iml" data-topic="InterpretationMethod" data-id="print"><a href='../../iml/html/InterpretationMethod.html#method-InterpretationMethod-print'><code>iml::InterpretationMethod$print()</code></a></span></li>
</ul>
</details>

<hr>
<a id="method-Shapley-new"></a>



<h4>Method <code>new()</code></h4>

<p>Create a Shapley object
</p>


<h5>Usage</h5>

<div class="r"><pre>Shapley$new(predictor, x.interest = NULL, sample.size = 100)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>predictor</code></dt><dd><p><a href="#topic+Predictor">Predictor</a><br />
The object (created with <code>Predictor$new()</code>) holding the machine
learning model and the data.</p>
</dd>
<dt><code>x.interest</code></dt><dd><p><a href="base.html#topic+data.frame">data.frame</a><br />
Single row with the instance to be explained.</p>
</dd>
<dt><code>sample.size</code></dt><dd><p><code>numeric(1)</code><br />
The number of Monte Carlo samples for estimating the Shapley value.</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p><a href="base.html#topic+data.frame">data.frame</a><br />
<a href="base.html#topic+data.frame">data.frame</a> with the Shapley values (phi) per feature.
</p>


<hr>
<a id="method-Shapley-explain"></a>



<h4>Method <code>explain()</code></h4>

<p>Set a new data point which to explain.
</p>


<h5>Usage</h5>

<div class="r"><pre>Shapley$explain(x.interest)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>x.interest</code></dt><dd><p><a href="base.html#topic+data.frame">data.frame</a><br />
Single row with the instance to be explained.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-Shapley-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>Shapley$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>




<h3>References</h3>

<p>Strumbelj, E., Kononenko, I. (2014). Explaining prediction models and
individual predictions with feature contributions. Knowledge and Information
Systems, 41(3), 647-665. https://doi.org/10.1007/s10115-013-0679-x
</p>


<h3>See Also</h3>

<p><a href="#topic+Shapley">Shapley</a>
</p>
<p>A different way to explain predictions: <a href="#topic+LocalModel">LocalModel</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library("rpart")
# First we fit a machine learning model on the Boston housing data
data("Boston", package = "MASS")
rf &lt;- rpart(medv ~ ., data = Boston)
X &lt;- Boston[-which(names(Boston) == "medv")]
mod &lt;- Predictor$new(rf, data = X)

# Then we explain the first instance of the dataset with the Shapley method:
x.interest &lt;- X[1, ]
shapley &lt;- Shapley$new(mod, x.interest = x.interest)
shapley

# Look at the results in a table
shapley$results
# Or as a plot
plot(shapley)

# Explain another instance
shapley$explain(X[2, ])
plot(shapley)
## Not run: 
# Shapley() also works with multiclass classification
rf &lt;- rpart(Species ~ ., data = iris)
X &lt;- iris[-which(names(iris) == "Species")]
mod &lt;- Predictor$new(rf, data = X, type = "prob")

# Then we explain the first instance of the dataset with the Shapley() method:
shapley &lt;- Shapley$new(mod, x.interest = X[1, ])
shapley$results
plot(shapley)

# You can also focus on one class
mod &lt;- Predictor$new(rf, data = X, type = "prob", class = "setosa")
shapley &lt;- Shapley$new(mod, x.interest = X[1, ])
shapley$results
plot(shapley)

## End(Not run)
</code></pre>

<hr>
<h2 id='TreeSurrogate'>Decision tree surrogate model</h2><span id='topic+TreeSurrogate'></span>

<h3>Description</h3>

<p><code>TreeSurrogate</code> fits a decision tree on the predictions of a prediction model.
</p>


<h3>Details</h3>

<p>A conditional inference tree is fitted on the predicted <code class="reqn">\hat{y}</code> from
the machine learning model and the data. The <code>partykit</code> package and
function are used to fit the tree. By default a tree of maximum depth of 2 is
fitted to improve interpretability.
</p>
<p>To learn more about global surrogate models, read the Interpretable Machine
Learning book:
<a href="https://christophm.github.io/interpretable-ml-book/global.html">https://christophm.github.io/interpretable-ml-book/global.html</a>
</p>


<h3>Super class</h3>

<p><code><a href="#topic+InterpretationMethod">iml::InterpretationMethod</a></code> -&gt; <code>TreeSurrogate</code>
</p>


<h3>Public fields</h3>

<div class="r6-fields">

<dl>
<dt><code>tree</code></dt><dd><p><code>party</code><br />
The fitted tree. See also <a href="partykit.html#topic+ctree">partykit::ctree</a>.</p>
</dd>
<dt><code>maxdepth</code></dt><dd><p><code>numeric(1)</code><br />
The maximum tree depth.</p>
</dd>
<dt><code>r.squared</code></dt><dd><p><code>numeric(1|n.classes)</code><br />
R squared measures how well the decision tree approximates the
underlying model. It is calculated as 1 - (variance of prediction
differences / variance of black box model predictions). For the
multi-class case, r.squared contains one measure per class.</p>
</dd>
</dl>

</div>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-TreeSurrogate-new"><code>TreeSurrogate$new()</code></a>
</p>
</li>
<li> <p><a href="#method-TreeSurrogate-predict"><code>TreeSurrogate$predict()</code></a>
</p>
</li>
<li> <p><a href="#method-TreeSurrogate-clone"><code>TreeSurrogate$clone()</code></a>
</p>
</li></ul>



<details open><summary>Inherited methods</summary>
<ul>
<li><span class="pkg-link" data-pkg="iml" data-topic="InterpretationMethod" data-id="plot"><a href='../../iml/html/InterpretationMethod.html#method-InterpretationMethod-plot'><code>iml::InterpretationMethod$plot()</code></a></span></li>
<li><span class="pkg-link" data-pkg="iml" data-topic="InterpretationMethod" data-id="print"><a href='../../iml/html/InterpretationMethod.html#method-InterpretationMethod-print'><code>iml::InterpretationMethod$print()</code></a></span></li>
</ul>
</details>

<hr>
<a id="method-TreeSurrogate-new"></a>



<h4>Method <code>new()</code></h4>

<p>Create a TreeSurrogate object
</p>


<h5>Usage</h5>

<div class="r"><pre>TreeSurrogate$new(predictor, maxdepth = 2, tree.args = NULL)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>predictor</code></dt><dd><p><a href="#topic+Predictor">Predictor</a><br />
The object (created with <code>Predictor$new()</code>) holding the machine
learning model and the data.</p>
</dd>
<dt><code>maxdepth</code></dt><dd><p><code>numeric(1)</code><br />
The maximum depth of the tree. Default is 2.</p>
</dd>
<dt><code>tree.args</code></dt><dd><p>(named list)<br />
Further arguments for <code><a href="party.html#topic+ctree">party::ctree()</a></code>.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-TreeSurrogate-predict"></a>



<h4>Method <code>predict()</code></h4>

<p>Predict new data with the tree.
See also <a href="#topic+predict.TreeSurrogate">predict.TreeSurrogate</a>
</p>


<h5>Usage</h5>

<div class="r"><pre>TreeSurrogate$predict(newdata, type = "prob", ...)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>newdata</code></dt><dd><p><a href="base.html#topic+data.frame">data.frame</a><br />
Data to predict on.</p>
</dd>
<dt><code>type</code></dt><dd><p>Prediction type.</p>
</dd>
<dt><code>...</code></dt><dd><p>Further arguments passed to <code>predict()</code>.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-TreeSurrogate-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>TreeSurrogate$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>




<h3>References</h3>

<p>Craven, M., &amp; Shavlik, J. W. (1996). Extracting tree-structured
representations of trained networks. In Advances in neural information
processing systems (pp. 24-30).
</p>


<h3>See Also</h3>

<p><a href="#topic+predict.TreeSurrogate">predict.TreeSurrogate</a> <a href="#topic+plot.TreeSurrogate">plot.TreeSurrogate</a>
</p>
<p>For the tree implementation
<code><a href="partykit.html#topic+ctree">partykit::ctree()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library("randomForest")
# Fit a Random Forest on the Boston housing data set
data("Boston", package = "MASS")
rf &lt;- randomForest(medv ~ ., data = Boston, ntree = 50)
# Create a model object
mod &lt;- Predictor$new(rf, data = Boston[-which(names(Boston) == "medv")])

# Fit a decision tree as a surrogate for the whole random forest
dt &lt;- TreeSurrogate$new(mod)

# Plot the resulting leaf nodes
plot(dt)

# Use the tree to predict new data
predict(dt, Boston[1:10, ])

# Extract the results
dat &lt;- dt$results
head(dat)

# It also works for classification
rf &lt;- randomForest(Species ~ ., data = iris, ntree = 50)
X &lt;- iris[-which(names(iris) == "Species")]
mod &lt;- Predictor$new(rf, data = X, type = "prob")

# Fit a decision tree as a surrogate for the whole random forest
dt &lt;- TreeSurrogate$new(mod, maxdepth = 2)

# Plot the resulting leaf nodes
plot(dt)

# If you want to visualize the tree directly:
plot(dt$tree)

# Use the tree to predict new data
set.seed(42)
iris.sample &lt;- X[sample(1:nrow(X), 10), ]
predict(dt, iris.sample)
predict(dt, iris.sample, type = "class")

# Extract the dataset
dat &lt;- dt$results
head(dat)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
