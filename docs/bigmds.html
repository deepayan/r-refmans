<!DOCTYPE html><html><head><title>Help for package bigmds</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {bigmds}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#divide_conquer_mds'><p>Divide-and-conquer MDS</p></a></li>
<li><a href='#fast_mds'><p>Fast MDS</p></a></li>
<li><a href='#interpolation_mds'><p>Interpolation MDS</p></a></li>
<li><a href='#landmark_mds'><p>Landmark MDS</p></a></li>
<li><a href='#pivot_mds'><p>Pivot MDS</p></a></li>
<li><a href='#reduced_mds'><p>Reduced MDS</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Title:</td>
<td>Multidimensional Scaling for Big Data</td>
</tr>
<tr>
<td>Version:</td>
<td>3.0.0</td>
</tr>
<tr>
<td>Description:</td>
<td>MDS is a statistic tool for reduction of dimensionality, using as input a distance
    matrix of dimensions n × n. When n is large, classical algorithms suffer from
    computational problems and MDS configuration can not be obtained.
    With this package, we address these problems by means of six algorithms, being two of them 
    original proposals:
        - Landmark MDS proposed by De Silva V. and JB. Tenenbaum (2004).
        - Interpolation MDS proposed by Delicado P. and C. Pachón-García (2021)
        &lt;<a href="https://doi.org/10.48550/arXiv.2007.11919">doi:10.48550/arXiv.2007.11919</a>&gt; (original proposal).
        - Reduced MDS proposed by Paradis E (2018).
        - Pivot MDS proposed by Brandes U. and C. Pich (2007)
        - Divide-and-conquer MDS proposed by Delicado P. and C. Pachón-García (2021)
        &lt;<a href="https://doi.org/10.48550/arXiv.2007.11919">doi:10.48550/arXiv.2007.11919</a>&gt; (original proposal).
        - Fast MDS, proposed by Yang, T., J. Liu, L. McMillan and W. Wang (2006).</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.0.2)</td>
</tr>
<tr>
<td>Suggests:</td>
<td>testthat</td>
</tr>
<tr>
<td>Imports:</td>
<td>pracma, svd, corpcor, parallel, stats</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/pachoning/bigmds">https://github.com/pachoning/bigmds</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/pachoning/bigmds/issues">https://github.com/pachoning/bigmds/issues</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-01-09 14:14:51 UTC; cristianpachon</td>
</tr>
<tr>
<td>Author:</td>
<td>Cristian Pachón García
    <a href="https://orcid.org/0000-0001-9518-4874"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut, cre],
  Pedro Delicado <a href="https://orcid.org/0000-0003-3933-4852"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Cristian Pachón García &lt;cc.pachon@gmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-01-09 14:30:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='divide_conquer_mds'>Divide-and-conquer MDS</h2><span id='topic+divide_conquer_mds'></span>

<h3>Description</h3>

<p>Roughly speaking, a large data set, <code>x</code>, of size <code class="reqn">n</code>
is divided into parts, then classical MDS is performed over every part and,
finally, the partial configurations are combined so that all the points lie
on the same coordinate system with the aim to obtain a global MDS configuration.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>divide_conquer_mds(x, l, c_points, r, n_cores)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="divide_conquer_mds_+3A_x">x</code></td>
<td>
<p>A matrix with <code class="reqn">n</code> points (rows) and <code class="reqn">k</code> variables (columns).</p>
</td></tr>
<tr><td><code id="divide_conquer_mds_+3A_l">l</code></td>
<td>
<p>The size for which classical MDS can be computed efficiently
(using <code>cmdscale</code> function). It means that if <code class="reqn">\bar{l}</code> is the limit
size for which classical MDS is applicable, then <code>l</code><code class="reqn">\leq \bar{l}</code>.</p>
</td></tr>
<tr><td><code id="divide_conquer_mds_+3A_c_points">c_points</code></td>
<td>
<p>Number of points used to align the MDS solutions obtained by the
division of <code>x</code> into <code class="reqn">p</code> data subsets. Recommended value: <code>5·r</code>.</p>
</td></tr>
<tr><td><code id="divide_conquer_mds_+3A_r">r</code></td>
<td>
<p>Number of principal coordinates to be extracted.</p>
</td></tr>
<tr><td><code id="divide_conquer_mds_+3A_n_cores">n_cores</code></td>
<td>
<p>Number of cores wanted to use to run the algorithm.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The divide-and-conquer MDS starts dividing the <code class="reqn">n</code> points into
<code class="reqn">p</code> partitions: the first partition contains <code>l</code> points and the others
contain <code>l-c_points</code> points. Therefore, <code class="reqn">p = 1 + (n-</code><code>l)/(l-c_points)</code>.
The partitions are created at random.
</p>
<p>Once the partitions are created, <code>c_points</code> different random
points are taken from the first partition and concatenated to the other
partitions After that, classical MDS is applied to each partition,
with target low dimensional configuration <code>r</code>.
</p>
<p>Since all the partitions share <code>c_points</code>
points with the first one, Procrustes can be applied in order to align all
the configurations. Finally, all the configurations are
concatenated in order to obtain a global MDS configuration.
</p>


<h3>Value</h3>

<p>Returns a list containing the following elements:
</p>

<dl>
<dt>points</dt><dd><p>A matrix that consists of <code class="reqn">n</code> points (rows)
and <code>r</code> variables (columns) corresponding to the principal coordinates. Since
a dimensionality reduction is performed, <code>r</code><code class="reqn">&lt;&lt;k</code></p>
</dd>
<dt>eigen</dt><dd><p>The first <code>r</code> largest eigenvalues:
<code class="reqn">\bar{\lambda}_i, i \in  \{1, \dots, r\} </code>, where
<code class="reqn">\bar{\lambda}_i = 1/p \sum_{j=1}^{p}\lambda_i^j/n_j</code>,
being <code class="reqn">\lambda_i^j</code> the <code class="reqn">i-th</code> eigenvalue from partition <code class="reqn">j</code>
and <code class="reqn">n_j</code> the size of the partition <code class="reqn">j</code>.</p>
</dd>
</dl>



<h3>References</h3>

<p>Delicado P. and C. Pachón-García (2021). <em>Multidimensional Scaling for Big Data</em>.
<a href="https://arxiv.org/abs/2007.11919">https://arxiv.org/abs/2007.11919</a>.
</p>
<p>Borg, I. and P. Groenen (2005). <em>Modern Multidimensional Scaling: Theory and Applications</em>. Springer.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(42)
x &lt;- matrix(data = rnorm(4 * 10000), nrow = 10000) %*% diag(c(9, 4, 1, 1))
mds &lt;- divide_conquer_mds(x = x, l = 200, c_points = 5 * 2, r = 2, n_cores = 1)
head(mds$points)
mds$eigen

</code></pre>

<hr>
<h2 id='fast_mds'>Fast MDS</h2><span id='topic+fast_mds'></span>

<h3>Description</h3>

<p>Fast MDS uses recursive programming in combination with a divide
and conquer strategy in order to obtain an MDS configuration for a given
large data set <code>x</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fast_mds(x, l, s_points, r, n_cores)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fast_mds_+3A_x">x</code></td>
<td>
<p>A matrix with <code class="reqn">n</code> individuals (rows) and <code class="reqn">k</code> variables (columns).</p>
</td></tr>
<tr><td><code id="fast_mds_+3A_l">l</code></td>
<td>
<p>The size for which classical MDS can be computed efficiently
(using <code>cmdscale</code> function). It means that if <code class="reqn">\bar{l}</code> is the limit
size for which classical MDS is applicable, then <code>l</code><code class="reqn">\leq \bar{l}</code>.</p>
</td></tr>
<tr><td><code id="fast_mds_+3A_s_points">s_points</code></td>
<td>
<p>Number of points used to align the MDS solutions obtained by
the division of <code>x</code> into <code class="reqn">p</code> submatrices. Recommended value: <code>5·r</code>.</p>
</td></tr>
<tr><td><code id="fast_mds_+3A_r">r</code></td>
<td>
<p>Number of principal coordinates to be extracted.</p>
</td></tr>
<tr><td><code id="fast_mds_+3A_n_cores">n_cores</code></td>
<td>
<p>Number of cores wanted to use to run the algorithm.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Fast MDS randomly divides the whole sample data set, <code>x</code>, of size <code class="reqn">n</code>
into <code class="reqn">p=</code><code>l/s_points</code> data subsets, where <code>l</code> <code class="reqn">\leq \bar{l}</code> being <code class="reqn">\bar{l}</code>
the limit size for which classical MDS is applicable. Each one of the <code class="reqn">p</code> data subsets
has size <code class="reqn">\tilde{n} = n/p</code>. If <code class="reqn">\tilde{n} \leq \code{l}</code> then classical MDS is applied
to each data subset. Otherwise, fast MDS is recursively applied.
In either case, a final MDS configuration is obtained for each data subset.
</p>
<p>In order to align all the partial solutions, a small subset of size <code>s_points</code>
is randomly selected from each data subset. They are joined
to form an alignment set, over which classical MDS is performed giving rise to an
alignment configuration. Every data subset shares <code>s_points</code> points with the alignment
set. Therefore every MDS configuration can be aligned with the alignment configuration
using a Procrustes transformation.
</p>


<h3>Value</h3>

<p>Returns a list containing the following elements:
</p>

<dl>
<dt>points</dt><dd><p>A matrix that consists of <code class="reqn">n</code> individuals (rows)
and <code>r</code> variables (columns) corresponding to the principal coordinates. Since
we are performing a dimensionality reduction, <code>r</code><code class="reqn">&lt;&lt;k</code></p>
</dd>
<dt>eigen</dt><dd><p>The first <code>r</code> largest eigenvalues:
<code class="reqn">\bar{\lambda}_i, i \in  \{1, \dots, r\} </code>, where
<code class="reqn">\bar{\lambda}_i = 1/p \sum_{j=1}^{p}\lambda_i^j/n_j</code>,
being <code class="reqn">\lambda_i^j</code> the <code class="reqn">i-th</code> eigenvalue from partition <code class="reqn">j</code>
and <code class="reqn">n_j</code> the size of the partition <code class="reqn">j</code>.</p>
</dd>
</dl>



<h3>References</h3>

<p>Delicado P. and C. Pachón-García (2021). <em>Multidimensional Scaling for Big Data</em>.
<a href="https://arxiv.org/abs/2007.11919">https://arxiv.org/abs/2007.11919</a>.
</p>
<p>Yang, T., J. Liu, L. McMillan and W.Wang (2006). <em>A fast approximation to multidimensional scaling</em>.
In Proceedings of the ECCV Workshop on Computation Intensive Methods for Computer Vision (CIMCV).
</p>
<p>Borg, I. and P. Groenen (2005). <em>Modern Multidimensional Scaling: Theory and Applications</em>. Springer.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(42)
x &lt;- matrix(data = rnorm(4 * 10000), nrow = 10000) %*% diag(c(9, 4, 1, 1))
mds &lt;- fast_mds(x = x, l = 200, s_points = 5 * 2, r = 2, n_cores = 1)
head(mds$points)
mds$eigen

</code></pre>

<hr>
<h2 id='interpolation_mds'>Interpolation MDS</h2><span id='topic+interpolation_mds'></span>

<h3>Description</h3>

<p>Given that the size of the data set is too large, this algorithm
consists of taking a random sample from it of size
<code>l</code> <code class="reqn">\leq \bar{l}</code>, being <code class="reqn">\bar{l}</code> the limit size for which
classical MDS is applicable, to perform classical MDS to it, and to extend the
obtained results to the rest of the data set by using Gower's
interpolation formula, which allows to add a new set of points
to an existing MDS configuration.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>interpolation_mds(x, l, r, n_cores)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="interpolation_mds_+3A_x">x</code></td>
<td>
<p>A matrix with <code class="reqn">n</code> individuals (rows) and <code class="reqn">k</code> variables (columns).</p>
</td></tr>
<tr><td><code id="interpolation_mds_+3A_l">l</code></td>
<td>
<p>The size for which classical MDS can be computed efficiently
(using <code>cmdscale</code> function). It means that if <code class="reqn">\bar{l}</code> is the limit
size for which classical MDS is applicable, then <code>l</code><code class="reqn">\leq \bar{l}</code>.</p>
</td></tr>
<tr><td><code id="interpolation_mds_+3A_r">r</code></td>
<td>
<p>Number of principal coordinates to be extracted.</p>
</td></tr>
<tr><td><code id="interpolation_mds_+3A_n_cores">n_cores</code></td>
<td>
<p>Number of cores wanted to use to run the algorithm.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><em>Gower's interpolation formula</em> is the central piece of this algorithm
since it allows to add a new set of points to an existing MDS configuration
so that the new one has the same coordinate system.
</p>
<p>Given the matrix <code>x</code> with <code class="reqn">n</code> points (rows) and
and <code class="reqn">k</code> variables (columns), a first data subsets (based on a random sample)
of size <code>l</code> is taken and it is used to compute a MDS configuration.
</p>
<p>The remaining part of <code>x</code> is divided into <code class="reqn">p=({n}-</code><code>l</code>)<code>/l</code>
data subsets (randomly). For every data subset, it is obtained a MDS
configuration by means of <em>Gower's interpolation formula</em> and the first
MDS configuration obtained previously. Every MDS configuration is appended
to the existing one so that, at the end of the process, a global MDS
configuration for <code>x</code> is obtained.
</p>
<p>This method is similar to <code><a href="#topic+landmark_mds">landmark_mds()</a></code> and <code><a href="#topic+reduced_mds">reduced_mds()</a></code>.
</p>


<h3>Value</h3>

<p>Returns a list containing the following elements:
</p>

<dl>
<dt>points</dt><dd><p>A matrix that consists of <code class="reqn">n</code> individuals (rows)
and <code>r</code> variables (columns) corresponding to the principal coordinates. Since
we are performing a dimensionality reduction, <code>r</code><code class="reqn">&lt;&lt;k</code></p>
</dd>
<dt>eigen</dt><dd><p>The first <code>r</code> largest eigenvalues:
<code class="reqn">\lambda_i, i \in  \{1, \dots, r\} </code>, where each <code class="reqn">\lambda_i</code> is obtained
from applying classical MDS to the first data subset.</p>
</dd>
</dl>



<h3>References</h3>

<p>Delicado P. and C. Pachón-García (2021). <em>Multidimensional Scaling for Big Data</em>.
<a href="https://arxiv.org/abs/2007.11919">https://arxiv.org/abs/2007.11919</a>.
</p>
<p>Borg, I. and P. Groenen (2005). <em>Modern Multidimensional Scaling: Theory and Applications</em>. Springer.
</p>
<p>Gower JC. (1968). <em>Adding a point to vector diagrams in multivariate analysis</em>. Biometrika.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(42)
x &lt;- matrix(data = rnorm(4 * 10000), nrow = 10000) %*% diag(c(9, 4, 1, 1))
mds &lt;- interpolation_mds(x = x, l = 200, r = 2, n_cores = 1)
head(mds$points)
mds$eigen

</code></pre>

<hr>
<h2 id='landmark_mds'>Landmark MDS</h2><span id='topic+landmark_mds'></span>

<h3>Description</h3>

<p>Landmark MDS (LMDS) algorithm applies first classical MDS to a
subset of the data (<em>landmark points</em>) and then the remaining individuals are
projected onto the landmark low dimensional configuration using a
distance-based triangulation procedure.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>landmark_mds(x, num_landmarks, r)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="landmark_mds_+3A_x">x</code></td>
<td>
<p>A matrix with <code class="reqn">n</code> points (rows) and <code class="reqn">k</code> variables (columns).</p>
</td></tr>
<tr><td><code id="landmark_mds_+3A_num_landmarks">num_landmarks</code></td>
<td>
<p>Number of landmark points to obtain an initial MDS configuration. It is
equivalent to <code>l</code> parameter used in <code><a href="#topic+interpolation_mds">interpolation_mds()</a></code>, <code><a href="#topic+divide_conquer_mds">divide_conquer_mds()</a></code> and
<code><a href="#topic+fast_mds">fast_mds()</a></code>. Therefore, it is the size for which classical MDS can be computed efficiently
(using <code>cmdscale</code> function). It means that if <code class="reqn">\bar{l}</code> is the limit
size for which classical MDS is applicable, then <code>l</code><code class="reqn">\leq \bar{l}</code>.</p>
</td></tr>
<tr><td><code id="landmark_mds_+3A_r">r</code></td>
<td>
<p>Number of principal coordinates to be extracted.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>LMDS applies first classical MDS to a subset of the data (<em>landmark points</em>). Then,
it uses a distance-based triangulation procedure to project the non-landmark individuals. This
distance-based triangulation procedure coincides with  <em>Gower's interpolation formula</em>.
</p>
<p>This method is similar to <code><a href="#topic+interpolation_mds">interpolation_mds()</a></code> and <code><a href="#topic+reduced_mds">reduced_mds()</a></code>.
</p>


<h3>Value</h3>

<p>Returns a list containing the following elements:
</p>

<dl>
<dt>points</dt><dd><p>A matrix that consists of <code class="reqn">n</code> points (rows)
and <code>r</code> variables (columns) corresponding to the principal coordinates. Since
a dimensionality reduction is performed, <code>r</code><code class="reqn">&lt;&lt;k</code></p>
</dd>
<dt>eigen</dt><dd><p>The first <code>r</code> largest eigenvalues:
<code class="reqn">\lambda_i, i \in  \{1, \dots, r\} </code>, where each <code class="reqn">\lambda_i</code> is obtained
from applying classical MDS to the first data subset.</p>
</dd>
</dl>



<h3>References</h3>

<p>Delicado P. and C. Pachón-García (2021). <em>Multidimensional Scaling for Big Data</em>.
<a href="https://arxiv.org/abs/2007.11919">https://arxiv.org/abs/2007.11919</a>.
</p>
<p>Borg, I. and P. Groenen (2005). <em>Modern Multidimensional Scaling: Theory and Applications</em>. Springer.
</p>
<p>De Silva V. and JB. Tenenbaum (2004). <em>Sparse multidimensional scaling using landmark points</em>. Technical Report, Stanford University.
</p>
<p>Gower JC. (1968). <em>Adding a point to vector diagrams in multivariate analysis</em>. Biometrika.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(42)
x &lt;- matrix(data = rnorm(4 * 10000), nrow = 10000) %*% diag(c(9, 4, 1, 1))
mds &lt;- landmark_mds(x = x, num_landmarks = 200, r = 2)
head(mds$points)
mds$eigen

</code></pre>

<hr>
<h2 id='pivot_mds'>Pivot MDS</h2><span id='topic+pivot_mds'></span>

<h3>Description</h3>

<p>Pivot MDS, introduced in the literature of graph layout algorithms, is similar to
Landmark MDS (<code><a href="#topic+landmark_mds">landmark_mds()</a></code>) but it uses the distance information between landmark and non-landmark
points to improve the initial low dimensional configuration,
as more relations than just those between landmark points are taken into account.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pivot_mds(x, num_pivots, r)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pivot_mds_+3A_x">x</code></td>
<td>
<p>A matrix with <code class="reqn">n</code> individuals (rows) and <code class="reqn">k</code> variables (columns).</p>
</td></tr>
<tr><td><code id="pivot_mds_+3A_num_pivots">num_pivots</code></td>
<td>
<p>Number of pivot points to obtain an initial MDS configuration. It is
equivalent to <code>l</code> parameter used in <code><a href="#topic+interpolation_mds">interpolation_mds()</a></code>, <code><a href="#topic+divide_conquer_mds">divide_conquer_mds()</a></code> and
<code><a href="#topic+fast_mds">fast_mds()</a></code>. Therefore, it is the size for which classical MDS can be computed efficiently
(using <code>cmdscale</code> function). It means that if <code class="reqn">\bar{l}</code> is the limit
size for which classical MDS is applicable, then <code>l</code><code class="reqn">\leq \bar{l}</code>.</p>
</td></tr>
<tr><td><code id="pivot_mds_+3A_r">r</code></td>
<td>
<p>Number of principal coordinates to be extracted.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a list containing the following elements:
</p>

<dl>
<dt>points</dt><dd><p>A matrix that consists of <code class="reqn">n</code> individuals (rows)
and <code>r</code> variables (columns) corresponding to the principal coordinates. Since
we are performing a dimensionality reduction, <code>r</code><code class="reqn">&lt;&lt;k</code></p>
</dd>
<dt>eigen</dt><dd><p>The first <code>r</code> largest eigenvalues:
<code class="reqn">\lambda_i, i \in  \{1, \dots, r\} </code>, where each <code class="reqn">\lambda_i</code> is obtained
from applying classical MDS to the first data subset.</p>
</dd>
</dl>



<h3>References</h3>

<p>Delicado P. and C. Pachón-García (2021). <em>Multidimensional Scaling for Big Data</em>.
<a href="https://arxiv.org/abs/2007.11919">https://arxiv.org/abs/2007.11919</a>.
</p>
<p>Brandes U. and C. Pich (2007). <em>Eigensolver Methods for Progressive Multidimensional Scaling of Large Data</em>. Graph Drawing.
</p>
<p>Borg, I. and P. Groenen (2005). <em>Modern Multidimensional Scaling: Theory and Applications</em>. Springer.
</p>
<p>Gower JC. (1968). <em>Adding a point to vector diagrams in multivariate analysis</em>. Biometrika.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(42)
x &lt;- matrix(data = rnorm(4 * 10000), nrow = 10000) %*% diag(c(9, 4, 1, 1))
mds &lt;- pivot_mds(x = x, num_pivots = 200, r = 2)
head(mds$points)
mds$eigen

</code></pre>

<hr>
<h2 id='reduced_mds'>Reduced MDS</h2><span id='topic+reduced_mds'></span>

<h3>Description</h3>

<p>A data subset is selected and classical MDS is performed on it to obtain the
corresponding low dimensional configuration.Then the reaming points are projected
onto this initial configuration.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>reduced_mds(x, l, r, n_cores)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="reduced_mds_+3A_x">x</code></td>
<td>
<p>A matrix with <code class="reqn">n</code> individuals (rows) and <code class="reqn">k</code> variables (columns).</p>
</td></tr>
<tr><td><code id="reduced_mds_+3A_l">l</code></td>
<td>
<p>The size for which classical MDS can be computed efficiently
(using <code>cmdscale</code> function). It means that if <code class="reqn">\bar{l}</code> is the limit
size for which classical MDS is applicable, then <code>l</code><code class="reqn">\leq \bar{l}</code>.</p>
</td></tr>
<tr><td><code id="reduced_mds_+3A_r">r</code></td>
<td>
<p>Number of principal coordinates to be extracted.</p>
</td></tr>
<tr><td><code id="reduced_mds_+3A_n_cores">n_cores</code></td>
<td>
<p>Number of cores wanted to use to run the algorithm.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><em>Gower's interpolation formula</em> is the central piece of this algorithm
since it allows to add a new set of points to an existing MDS configuration
so that the new one has the same coordinate system.
</p>
<p>Given the matrix <code>x</code> with <code class="reqn">n</code> points (rows) and
and <code class="reqn">k</code> variables (columns), a first data subsets (based on a random sample)
of size <code>l</code> is taken and it is used to compute a MDS configuration.
</p>
<p>The remaining part of <code>x</code> is divided into <code class="reqn">p=({n}-</code><code>l</code>)<code>/l</code>
data subsets (randomly). For every data point, it is obtained a MDS
configuration by means of <em>Gower's interpolation formula</em> and the first
MDS configuration obtained previously. Every MDS configuration is appended
to the existing one so that, at the end of the process, a global MDS
configuration for <code>x</code> is obtained.
</p>
<p>#'This method is similar to <code><a href="#topic+landmark_mds">landmark_mds()</a></code> and <code><a href="#topic+interpolation_mds">interpolation_mds()</a></code>.
</p>


<h3>Value</h3>

<p>Returns a list containing the following elements:
</p>

<dl>
<dt>points</dt><dd><p>A matrix that consists of <code class="reqn">n</code> individuals (rows)
and <code>r</code> variables (columns) corresponding to the principal coordinates. Since
we are performing a dimensionality reduction, <code>r</code><code class="reqn">&lt;&lt;k</code></p>
</dd>
<dt>eigen</dt><dd><p>The first <code>r</code> largest eigenvalues:
<code class="reqn">\lambda_i, i \in  \{1, \dots, r\} </code>, where each <code class="reqn">\lambda_i</code> is obtained
from applying classical MDS to the first data subset.</p>
</dd>
</dl>



<h3>References</h3>

<p>Delicado P. and C. Pachón-García (2021). <em>Multidimensional Scaling for Big Data</em>.
<a href="https://arxiv.org/abs/2007.11919">https://arxiv.org/abs/2007.11919</a>.
</p>
<p>Paradis E. (2018). <em>Multidimensional Scaling With Very Large Datasets</em>. Journal of Computational and Graphical Statistics.
</p>
<p>Borg, I. and P. Groenen (2005). <em>Modern Multidimensional Scaling: Theory and Applications</em>. Springer.
</p>
<p>Gower JC. (1968). <em>Adding a point to vector diagrams in multivariate analysis</em>. Biometrika.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(42)
x &lt;- matrix(data = rnorm(4 * 10000), nrow = 10000) %*% diag(c(9, 4, 1, 1))
mds &lt;- reduced_mds(x = x, l = 200, r = 2, n_cores = 1)
head(mds$points)
mds$eigen

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
