<!DOCTYPE html><html><head><title>Help for package mbrdr</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {mbrdr}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#choose.fx'><p>choose fx for principal fitted response reduction and unstructured principal fitted response reduction</p></a></li>
<li><a href='#matpower'><p>compute the M^power where M is a symmetric matrix.</p></a></li>
<li><a href='#mbrdr'><p>Main function for model-based response dimension reduction regression</p></a></li>
<li><a href='#mbrdr.x'><p> Accessor functions for data in dr objects</p></a></li>
<li><a href='#mps'><p>Minneapolis School dataset</p></a></li>
<li><a href='#SIGMAS'><p>compute all required SIGMA matrices for <code>"pfrr"</code> and <code>"upfrr"</code></p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Model-Based Response Dimension Reduction</td>
</tr>
<tr>
<td>Version:</td>
<td>1.1.1</td>
</tr>
<tr>
<td>Date:</td>
<td>2022-01-24</td>
</tr>
<tr>
<td>Author:</td>
<td>Jae Keun Yoo</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Jae Keun Yoo &lt;peter.yoo@ewha.ac.kr&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Functions for model-based response dimension reduction. Usual dimension reduction methods in multivariate regression focus on the reduction of predictors, not responses.  The response dimension reduction is theoretically founded in Yoo and Cook (2008) &lt;<a href="https://doi.org/10.1016%2Fj.csda.2008.07.029">doi:10.1016/j.csda.2008.07.029</a>&gt;. Later, three model-based response dimension reduction approaches are proposed in Yoo (2016) &lt;<a href="https://doi.org/10.1080%2F02331888.2017.1410152">doi:10.1080/02331888.2017.1410152</a>&gt; and Yoo (2019) &lt;<a href="https://doi.org/10.1016%2Fj.jkss.2019.02.001">doi:10.1016/j.jkss.2019.02.001</a>&gt;. The method by Yoo and Cook (2008) is based on non-parametric ordinary least squares, but the model-based approaches are done through maximum likelihood estimation. For two model-based response dimension reduction methods called principal fitted response reduction and unstructured principal fitted response reduction, chi-squared tests are provided for determining the dimension of the response subspace.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2.0)]</td>
</tr>
<tr>
<td>Depends:</td>
<td>R(&ge; 3.5.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>stats</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>LazyData:</td>
<td>yes</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>6.0.1</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2022-01-24 08:12:29 UTC; yjkst</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2022-01-24 11:22:43 UTC</td>
</tr>
</table>
<hr>
<h2 id='choose.fx'>choose fx for principal fitted response reduction and unstructured principal fitted response reduction </h2><span id='topic+choose.fx'></span>

<h3>Description</h3>

<p>Returns a <code class="reqn">n \times q</code>  matrix used in  principal fitted response reduction and unstructured principal fitted response reduction.</p>


<h3>Usage</h3>

<pre><code class='language-R'>choose.fx(X, fx.choice=1, nclust = 5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="choose.fx_+3A_x">X</code></td>
<td>
  <p><code class="reqn">n \times p</code> predictor matrix </p>
</td></tr>
<tr><td><code id="choose.fx_+3A_fx.choice">fx.choice</code></td>
<td>
<p>four choices for fx; see below </p>
</td></tr>
<tr><td><code id="choose.fx_+3A_nclust">nclust</code></td>
<td>
<p>the number of clusters; see below </p>
</td></tr>
</table>


<h3>Details</h3>

<p>Both of principal fitted response reduction and unstructured principal fitted response reduction require
a choice of fx. The function will return one of four choices of fx, which are popular candidates among many.
</p>
<p><code>fx.choice=1</code>: This is default and returns the original predictor matrice X, centered at zero as fx.
</p>
<p><code>fx.choice=2</code>: This returns the original predictor matrice X, centered at zero and its squared values.
</p>
<p><code>fx.choice=3</code>: This returns the original predictor matrice X, centered at zero and its exponentiated values.
</p>
<p><code>fx.choice=4</code>: This clusters X with K-means algoritm with the number of clusters equal to the value in <code>nclust</code>.
Then, the cluster results are expanded to <code class="reqn">\code{nclust}-1</code> dummy variables, like factor used in <code>lm</code> function.
Finally, it returns <code>nclust-1</code> categorical basis. The option of <code>nclust</code> works only with <code>fx.choice=4</code>.
</p>


<h3>Value</h3>

<p>A <code class="reqn">n \times q</code>  matrix for fx.
</p>


<h3>Author(s)</h3>

<p>Jae Keun Yoo, peter.yoo@ewha.ac.kr</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(mps)
X &lt;- mps[,c(5:6,8:14)]
choose.fx(X)

choose.fx(X, fx.choice=2)

choose.fx(X, fx.choice=4, nclust=3)
</code></pre>

<hr>
<h2 id='matpower'>compute the M^power where M is a symmetric matrix.</h2><span id='topic+matpower'></span>

<h3>Description</h3>

<p>Returns M^power. </p>


<h3>Usage</h3>

<pre><code class='language-R'>matpower(M, pow)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="matpower_+3A_m">M</code></td>
<td>
<p> symmetric matrix</p>
</td></tr>
<tr><td><code id="matpower_+3A_pow">pow</code></td>
<td>
<p>power</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function computes M^power for a symmetric matrix M. </p>


<h3>Value</h3>

<p>Returns </p>


<h3>Author(s)</h3>

<p>Jae Keun Yoo, peter.yoo@ewha.ac.kr</p>


<h3>Examples</h3>

<pre><code class='language-R'>X &lt;- matrix(rnorm(100), c(20,5))
matpower(cov(X), -0.5) ## returns cov(X)^-0.5 %*% cov(X)^-0.5 = cov(X)^-1.
 </code></pre>

<hr>
<h2 id='mbrdr'>Main function for model-based response dimension reduction regression</h2><span id='topic+mbrdr'></span><span id='topic+mbrdr.compute'></span>

<h3>Description</h3>

<p>This is the main function in the mbrdr package.  It creates objects of class
mbrdr to estimate the response mean subspace and perform tests concerning
its dimension.  Several helper functions that require a mbrdr object can then
be applied to the output from this function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mbrdr (formula, data, subset, na.action = na.fail, weights, ...)

mbrdr.compute (y, x, weights, method = "upfrr", ...)
 </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mbrdr_+3A_formula">formula</code></td>
<td>
<p>a two-sided formula like <code>cbind(y1,y2,y3,y4)~x1+x2+x3</code>, where the left-side
variables are a matrix of the response variables, and the right-hand side
variables represent the predictors.  The left-hand side of the formula must be a matrix,
since the package reduces the dimension of the responses variables.
</p>
</td></tr>
<tr><td><code id="mbrdr_+3A_data">data</code></td>
<td>
<p> an optional data frame containing the variables in the model.
By default the variables are taken from the environment from
which &lsquo;mbrdr&rsquo; is called.</p>
</td></tr>
<tr><td><code id="mbrdr_+3A_subset">subset</code></td>
<td>
<p>an optional vector specifying a subset of observations to be
used in the fitting process.</p>
</td></tr>
<tr><td><code id="mbrdr_+3A_weights">weights</code></td>
<td>
<p>an optional vector of weights to be used where appropriate.  In the
context of dimension reduction methods, weights are used to obtain
elliptical symmetry, not constant variance.

</p>
</td></tr>
<tr><td><code id="mbrdr_+3A_na.action">na.action</code></td>
<td>
<p>a function which indicates what should happen when the data
contain &lsquo;NA&rsquo;s.  The default is &lsquo;na.fail,&rsquo; which will stop calculations.
The option 'na.omit' is also permitted, but it may not work correctly when
weights are used.</p>
</td></tr>
<tr><td><code id="mbrdr_+3A_x">x</code></td>
<td>
<p>The design matrix.  This will be computed from the formula by <code>dr</code> and then
passed to <code>dr.compute</code>, or you can create it yourself.</p>
</td></tr>
<tr><td><code id="mbrdr_+3A_y">y</code></td>
<td>
<p>The response vector or matrix</p>
</td></tr>
<tr><td><code id="mbrdr_+3A_method">method</code></td>
<td>
<p>This character string specifies the method of fitting.
The default is <code>"upfrr"</code>. The options include <code>"yc"</code>, <code>"prr"</code>, <code>"pfrr"</code>.
Each method may have its own additional arguments, or its  own defaults; see the details below for more information.</p>
</td></tr>
<tr><td><code id="mbrdr_+3A_...">...</code></td>
<td>
<p>For <code>mbrdr</code>, all additional arguments passed to <code>mbrdr.compute</code>.
For  <code>mbrdr.compute</code>, additional arguments may be required for particular dimension reduction method.
For  example,  <code>numdir</code> is the maximum number of directions to compute, with default equal to 4.
Other methods may have other defaults.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The general regression problem mainly focuses on studying <code class="reqn">E(y|x)</code>,
the conditional mean of a response <code class="reqn">y</code> given a set of predictors <code class="reqn">x</code>,
where y is <code class="reqn">r</code>-dimensional response variables with <code class="reqn">r geq 2</code> and
</p>
<p>This function provides methods for estimating the response dimension subspace of a general regression problem.
That is, we want to find a <code class="reqn">r \times d</code> matrix <code class="reqn">B</code> of minimal rank <code class="reqn">d</code> such that
</p>
<p style="text-align: center;"><code class="reqn">E(y|x)=E(P(B)y|x)</code>
</p>
<p>, where P(B) is an orthogonal projections onto the column space of B.
Both the dimension <code class="reqn">d</code> and the subspace <code class="reqn">P(B)</code> are unknown.
These methods make few assumptions.
</p>
<p>For the methods <code>"yc"</code>, <code>"prr"</code>, <code>"pfrr"</code> and
<code>"upfrr"</code>,  <code class="reqn">B</code> is estimated and returned.
And, only for <code>"pfrr"</code> and <code>"upfrr"</code>,
chi-squared test results for estimating <code class="reqn">d</code> is provided.
</p>
<p>Weights can be used, essentially to specify the relative
frequency of each case in the data.
</p>
<p>The option <code>fx.choice</code> is required to fit <code>"pfrr"</code> and <code>"upfrr"</code> and has the following four values.
</p>
<p><code>fx.choice=1</code>: This is default and returns the original predictor matrice X, centered at zero as fx.
</p>
<p><code>fx.choice=2</code>: This returns the original predictor matrice X, centered at zero and its squared values.
</p>
<p><code>fx.choice=3</code>: This returns the original predictor matrice X, centered at zero and its exponentiated values.
</p>
<p><code>fx.choice=4</code>: This clusters X with K-means algoritm with the number of clusters equal to the value in <code>nclust</code>.
Then, the cluster results are expanded to <code class="reqn">\code{nclust}-1</code> dummy variables, like factor used in <code>lm</code> function. Finally, it returns <code>nclust-1</code> categorical basis. The option of <code>nclust</code> works only with <code>fx.choice=4</code>.
</p>


<h3>Value</h3>

<p>mbrdr returns an object that inherits from mbrdr (the name of the type is the
value of the <code>method</code> argument), with attributes:
</p>
<table>
<tr><td><code>y</code></td>
<td>
<p>The response matrix</p>
</td></tr>
<tr><td><code>x</code></td>
<td>
<p>The design matrix</p>
</td></tr>
<tr><td><code>weights</code></td>
<td>
<p>The weights used, normalized to add to n.</p>
</td></tr>
<tr><td><code>cases</code></td>
<td>
<p>Number of cases used.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>The initial call to <code>mbrdr</code>.</p>
</td></tr>
<tr><td><code>evectors</code></td>
<td>
<p>The eigenvectors from kernel matrices to estimate <code class="reqn">B</code> computed from each response dimension reduction methods. It is the estimate of <code class="reqn">B</code>.</p>
</td></tr>
<tr><td><code>evalues</code></td>
<td>
<p>The eigenvalues corresponding to the eigenvectors.</p>
</td></tr>
<tr><td><code>stats</code></td>
<td>
<p>This is the dimension test statistics for <code class="reqn">pfrr</code> and <code>"upfrr"</code>. It is the cumulatative sum of the eigenvalues for <code>"yc"</code> and <code>"prr"</code></p>
</td></tr>
<tr><td><code>fx</code></td>
<td>
<p>This returns the user-selection of fx for <code>"pfrr"</code> and <code>"upfrr"</code>.</p>
</td></tr>
<tr><td><code>numdir</code></td>
<td>
<p>The maximum number of directions to be found.  The output
value of numdir may be smaller than the input value.</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>the dimension reduction method used.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jae Keun Yoo, &lt;peter.yoo@ewhat.ac.kr&gt;.</p>


<h3>References</h3>

<p>Yoo, JK. (2018). Response dimension reduction: model-based approach.
<em>Statistics : A Journal of Theoretical and Applied Statistic</em>, 52, 409-425. <code>"prr"</code> and <code>"pfrr"</code>
</p>
<p>Yoo, JK. (2019). Unstructured principal fitted response reduction in multivariate regression.
<em> Journal of the Korean Statistical Society</em>, 48, 561-567.  <code>"upfrr"</code>
</p>
<p>Yoo, JK. and Cook, R. D.  (2008), Response dimension reduction for the conditional mean in multivariate regression.
<em>Statistics and Probability Letters</em>, 47, 381-389.  <code>"yc"</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(mps)
# default fitting method is "upfrr"
s0 &lt;- mbrdr(cbind(A4, B4, A6, B6)~AFDC+Attend+B+Enrol+HS+Minority+Mobility+Poverty+PTR, data=mps)
summary(s0)

# Refit, using different choice of fx.
summary(s1 &lt;- update(s0, fx.choice=2))

# Refit again, using pfrr with fx.choice=2
summary(s2&lt;-update(s1, method="pfrr", fx.choice=1))

# Refit, using prr, which does not require the choice of fx.
summary(s3&lt;- update(s1,method="prr"))

# fit using Yoo-Cook method:
summary(s4 &lt;- update(s1,method="yc"))
</code></pre>

<hr>
<h2 id='mbrdr.x'> Accessor functions for data in dr objects </h2><span id='topic+mbrdr.x'></span><span id='topic+mbrdr.y'></span>

<h3>Description</h3>

<p>Accessor functions for dr objects.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mbrdr.x(object)
mbrdr.y(object)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mbrdr.x_+3A_object">object</code></td>
<td>
<p> An object that inherits from <code>mbrdr</code>. </p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a component of a dr object.  <code>mbrdr.x</code> returns the predictor
matrix reduced to full rank by dropping trailing columns; <code>mbrdr.y</code>
returns the response vector/matrix.
</p>


<h3>Author(s)</h3>

<p> Jae Keun Yoo, &lt;peter.yoo@ewha.ac.kr&gt; </p>


<h3>See Also</h3>

  <p><code><a href="#topic+mbrdr">mbrdr</a></code>. </p>

<hr>
<h2 id='mps'>Minneapolis School dataset</h2><span id='topic+mps'></span>

<h3>Description</h3>

<p>The Minneapolis school dataset was collected to evaluate the performance of student The percentages of students in 63 Minneapolis schools in 1972. And, The dataset was reported in Star-Tribune in 1973.</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(mps)
</code></pre>


<h3>Format</h3>

<p>A data frame of dimension is 63 x 15. Each row represents one elementary school. The first four columns correspond to  percentages of students in a school scoring above (A) and below (B) average on standardized fourth and sixth grade reading comprehension tests. Subtracting either pair of grade specific percentages from 100 gives the percentage of students scoring about average on the test. All the other variables are demographic informations for each school.
</p>


<h3>Details</h3>

<p>A4 = percentage of 4th graders scoring ABOVE average on a standard 4th grade vocabulary test in 1972.
</p>
<p>B4 = percentage of 4th graders scoring BELOW average on a standard 4th grade vocabulary test in 1972.
</p>
<p>A6 = percentage of 6th graders scoring BELOW average on a standard 6th grade comprehension test in 1972.
</p>
<p>B6 = percentage of 6th graders scoring BELOW average on a standard 6th grade comprehension test in 1972.
</p>
<p>AFDC = percentage of children receiving Aid to Families with Dependent Children
</p>
<p>Attend = average percentage of childern in attendance during the year
</p>
<p>B = percentage of children in the school not living with Both Parents
</p>
<p>BthPts = percentage of children in the school living with Both Parents
</p>
<p>Enrol = number of childeren enrolled in the school
</p>
<p>HS = percent of adults in the school area who have completed high school
</p>
<p>Minority = percent minority children in the area.
</p>
<p>Mobility = percentage of children who started in a school, but did not finish there
</p>
<p>Poverty = percentage of persons in the school area who are above the federal poverty levels
</p>
<p>PTR = pupil-teacher ratio
</p>
<p>School = names of school
</p>


<h3>References</h3>

<p>Cook, R. D. and Setodji, C. M. (2003) A model-free test for reduced rank in multivariate regression. Journal of the American Statistical Association, 98, pp. 340-351.
</p>
<p>JK. Yoo (2019) Unstructured principal fitted response reduction in multivariate regression. Journal of the Korean Statistical Society, 48, pp. 561-567.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(mps)
pairs(mps[,1:4])
</code></pre>

<hr>
<h2 id='SIGMAS'>compute all required SIGMA matrices for <code>"pfrr"</code> and <code>"upfrr"</code></h2><span id='topic+SIGMAS'></span>

<h3>Description</h3>

<p>Returns Sigmahat, Sigmahat_fit and Sigmahat_res  for principal fitted response reduction and unstructured principal fitted response reduction using the choice of fx.</p>


<h3>Usage</h3>

<pre><code class='language-R'>SIGMAS(Y, fx)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SIGMAS_+3A_y">Y</code></td>
<td>
  <p><code class="reqn">n \times r</code> response matrix </p>
</td></tr>
<tr><td><code id="SIGMAS_+3A_fx">fx</code></td>
<td>
<p>the chosen fx</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Both of principal fitted response reduction and unstructured principal fitted response reduction require
to compute many SIGMAs. The SIGMAs  are as follows:
Sigmahat =  (Y^T Y)/n;
Sigmahat_fit = (Y^T  P_fx  Y)/n;
Sigmahat_res = Sigmahat - Sigmahat_fit.
</p>


<h3>Value</h3>

<p>A list of Sigmahat, Sigmahat_fit and  Sigmahat_res.
</p>


<h3>Author(s)</h3>

<p>Jae Keun Yoo, peter.yoo@ewha.ac.kr</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(mps)
X &lt;- mps[,c(5:6,8:14)]
Y &lt;- mps[,c(1:4)]
fx1 &lt;- choose.fx(X)
fx2 &lt;- choose.fx(X, fx.choice=4, nclust=3)

SIGMAS(Y, fx1)
SIGMAS(Y, fx2)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
