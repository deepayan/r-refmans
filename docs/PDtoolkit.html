<!DOCTYPE html><html><head><title>Help for package PDtoolkit</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {PDtoolkit}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#auc.model'><p>Area under curve (AUC)</p></a></li>
<li><a href='#bivariate'><p>Bivariate analysis</p></a></li>
<li><a href='#boots.vld'><p>Bootstrap model validation</p></a></li>
<li><a href='#cat.bin'><p>Categorical risk factor binning</p></a></li>
<li><a href='#cat.slice'><p>Slice categorical variable</p></a></li>
<li><a href='#confusion.matrix'><p>Confusion matrix</p></a></li>
<li><a href='#constrained.logit'><p>Constrained logistic regression</p></a></li>
<li><a href='#create.partitions'><p>Create partitions (aka nested dummy variables)</p></a></li>
<li><a href='#cutoff.palette'><p>Palette of cutoff values that minimize and maximize metrics from the confusion matrix</p></a></li>
<li><a href='#decision.tree'><p>Custom decision tree algorithm</p></a></li>
<li><a href='#dp.testing'><p>Testing the discriminatory power of PD rating model</p></a></li>
<li><a href='#embedded.blocks'><p>Embedded blocks regression</p></a></li>
<li><a href='#encode.woe'><p>Encode WoE</p></a></li>
<li><a href='#ensemble.blocks'><p>Ensemble blocks regression</p></a></li>
<li><a href='#evrs'><p>Modelling the Economic Value of Credit Rating System</p></a></li>
<li><a href='#fairness.vld'><p>Model fairness validation</p></a></li>
<li><a href='#heterogeneity'><p>Testing heterogeneity of the PD rating model</p></a></li>
<li><a href='#hhi'><p>Herfindahl-Hirschman Index (HHI)</p></a></li>
<li><a href='#homogeneity'><p>Testing homogeneity of the PD rating model</p></a></li>
<li><a href='#imp.outliers'><p>Imputation methods for outliers</p></a></li>
<li><a href='#imp.sc'><p>Imputation methods for special cases</p></a></li>
<li><a href='#interaction.transformer'><p>Extract risk factors interaction from decision tree</p></a></li>
<li><a href='#kfold.idx'><p>Indices for K-fold validation</p></a></li>
<li><a href='#kfold.vld'><p>K-fold model cross-validation</p></a></li>
<li><a href='#loans'><p>German Credit Data</p></a></li>
<li><a href='#normal.test'><p>Multi-period predictive power test</p></a></li>
<li><a href='#num.slice'><p>Slice numeric variable</p></a></li>
<li><a href='#nzv'><p>Near-zero variance</p></a></li>
<li><a href='#power'><p>Power of statistical tests for predictive ability testing</p></a></li>
<li><a href='#pp.testing'><p>Testing the predictive power of PD rating model</p></a></li>
<li><a href='#predict.cdt'><p>Predict method for custom decision tree</p></a></li>
<li><a href='#psi'><p>Population Stability Index (PSI)</p></a></li>
<li><a href='#replace.woe'><p>Replace modalities of risk factor with weights of evidence (WoE) value</p></a></li>
<li><a href='#rf.clustering'><p>Risk factor clustering</p></a></li>
<li><a href='#rf.interaction.transformer'><p>Extract interactions from random forest</p></a></li>
<li><a href='#rs.calibration'><p>Calibration of the rating scale</p></a></li>
<li><a href='#scaled.score'><p>Scaling the probabilities</p></a></li>
<li><a href='#segment.vld'><p>Model segment validation</p></a></li>
<li><a href='#smote'><p>Synthetic Minority Oversampling Technique (SMOTE)</p></a></li>
<li><a href='#staged.blocks'><p>Staged blocks regression</p></a></li>
<li><a href='#stepFWD'><p>Customized stepwise regression with p-value and trend check</p></a></li>
<li><a href='#stepFWDr'><p>Customized stepwise regression with p-value and trend check on raw risk factors</p></a></li>
<li><a href='#stepMIV'><p>Stepwise logistic regression based on marginal information value (MIV)</p></a></li>
<li><a href='#stepRPC'><p>Stepwise logistic regression based on risk profile concept</p></a></li>
<li><a href='#stepRPCr'><p>Stepwise regression based on risk profile concept and raw risk factors</p></a></li>
<li><a href='#univariate'><p>Univariate analysis</p></a></li>
<li><a href='#ush.bin'><p>U-shape binning algorithm</p></a></li>
<li><a href='#ush.test'><p>Testing for U-shape relation</p></a></li>
<li><a href='#woe.tbl'><p>Weights of evidence (WoE) table</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Title:</td>
<td>Collection of Tools for PD Rating Model Development and
Validation</td>
</tr>
<tr>
<td>Version:</td>
<td>1.2.0</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Andrija Djurovic &lt;djandrija@gmail.com&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>The goal of this package is to cover the most common steps in probability of default (PD) rating model development and validation. 
	     The main procedures available are those that refer to univariate, bivariate, multivariate analysis, calibration and validation. 
	     Along with accompanied 'monobin' and 'monobinShiny' packages, 'PDtoolkit' provides functions which are suitable for different 
	     data transformation and modeling tasks such as: 
	     imputations, monotonic binning of numeric risk factors, binning of categorical risk factors, weights of evidence (WoE) and 
	     information value (IV) calculations, WoE coding (replacement of risk factors modalities with WoE values), risk factor clustering, 
	     area under curve (AUC) calculation and others. Additionally, package provides set of validation functions for testing homogeneity, 
	     heterogeneity, discriminatory and predictive power of the model.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL (&ge; 3)</a></td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/andrija-djurovic/PDtoolkit">https://github.com/andrija-djurovic/PDtoolkit</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.1</td>
</tr>
<tr>
<td>Depends:</td>
<td>monobin, R (&ge; 2.10)</td>
</tr>
<tr>
<td>Imports:</td>
<td>dplyr, rpart</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-09-20 05:00:49 UTC; adjurovic</td>
</tr>
<tr>
<td>Author:</td>
<td>Andrija Djurovic [aut, cre]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-09-20 05:20:05 UTC</td>
</tr>
</table>
<hr>
<h2 id='auc.model'>Area under curve (AUC)</h2><span id='topic+auc.model'></span>

<h3>Description</h3>

<p><code>auc.model</code> calculates area under curve (AUC) for a given predicted values and observed target variable.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>auc.model(predictions, observed)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="auc.model_+3A_predictions">predictions</code></td>
<td>
<p>Model predictions.</p>
</td></tr>
<tr><td><code id="auc.model_+3A_observed">observed</code></td>
<td>
<p>Observed values of target variable.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The command <code>auc.model</code> returns value of AUC.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+bivariate">bivariate</a></code> for automatic bivariate analysis.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>suppressMessages(library(PDtoolkit))
data(gcd)
#categorize numeric risk factor
gcd$maturity.bin &lt;- ndr.bin(x = gcd$maturity, y = gcd$qual, y.type = "bina")[[2]]
#estimate simple logistic regression model
lr &lt;- glm(qual ~ maturity.bin, family = "binomial", data = gcd)
#calculate auc
auc.model(predictions = predict(lr, type = "response", newdata = gcd),
    observed = gcd$qual)
</code></pre>

<hr>
<h2 id='bivariate'>Bivariate analysis</h2><span id='topic+bivariate'></span>

<h3>Description</h3>

<p><code>bivariate</code> returns the bivariate statistics for risk factors supplied in data frame <code>db</code>. <br />
Implemented procedure expects all risk factors to be categorical, thus numeric risk factors should be first
categorized. Additionally, maximum number of groups per risk factor is set to 10, so risk factors with more than
10 categories will not be processed automatically, but manual inspection can be still done using <code>woe.tbl</code>
and <code>auc.model</code> functions in order to produce the same statistics. Results of both checks (risk factor class and
number of categories), if identified, will be reported in second element of function output - <code>info</code> data frame. <br />
Bivariate report (first element of function output - <code>results</code> data frame) includes:
</p>

<ul>
<li><p> rf: Risk factor name.
</p>
</li>
<li><p> bin: Risk factor group (bin).
</p>
</li>
<li><p> no: Number of observations per bin.
</p>
</li>
<li><p> ng: Number of good cases (where target is equal to 0) per bin.
</p>
</li>
<li><p> nb: Number of bad cases (where target is equal to 1) per bin.
</p>
</li>
<li><p> pct.o: Percentage of observations per bin.
</p>
</li>
<li><p> pct.g: Percentage of good cases (where target is equal to 0) per bin.
</p>
</li>
<li><p> pct.b: Percentage of bad cases (where target is equal to 1) per bin.
</p>
</li>
<li><p> dr: Default rate per bin.
</p>
</li>
<li><p> so: Number of all observations.
</p>
</li>
<li><p> sg: Number of all good cases.
</p>
</li>
<li><p> sb: Number of all bad cases.
</p>
</li>
<li><p> dist.g: Distribution of good cases per bin.
</p>
</li>
<li><p> dist.b: Distribution of bad cases per bin.
</p>
</li>
<li><p> woe: WoE value.
</p>
</li>
<li><p> iv.b: Information value per bin.
</p>
</li>
<li><p> iv.s: Information value of risk factor (sum of individual bins' information values).
</p>
</li>
<li><p> auc: Area under curve of simple logistic regression model estimated as <code>y ~ x</code>,
where <code>y</code> is selected target variable and <code>x</code> is categorical risk factor.
</p>
</li></ul>

<p>Additional info report (second element of function output - <code>info</code> data frame), if produced, includes:
</p>

<ul>
<li><p> rf: Risk factor name.
</p>
</li>
<li><p> reason.code: Reason code takes value 1 if inappropriate class of risk factor is identified, while
for check of maximum number of categories it takes value 2.
</p>
</li>
<li><p> comment: Reason description.
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>bivariate(db, target)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bivariate_+3A_db">db</code></td>
<td>
<p>Data frame of risk factors and target variable supplied for bivariate analysis.</p>
</td></tr>
<tr><td><code id="bivariate_+3A_target">target</code></td>
<td>
<p>Name of target variable within <code>db</code> argument.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The command <code>bivariate</code> returns the list of two data frames. The first one contains bivariate metrics
while the second data frame reports results of above explained validations
(class of the risk factors and number of categories).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+woe.tbl">woe.tbl</a></code> and <code><a href="#topic+auc.model">auc.model</a></code> for manual bivariate analysis.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>suppressMessages(library(PDtoolkit))
data(gcd)
#categorize numeric risk factors
gcd$age.bin &lt;- ndr.bin(x = gcd$age, y = gcd$qual)[[2]]
gcd$age.bin.1 &lt;- cut(x = gcd$age, breaks = 20)
gcd$maturity.bin &lt;- ndr.bin(x = gcd$maturity, y = gcd$qual, y.type = "bina")[[2]]
gcd$amount.bin &lt;- ndr.bin(x = gcd$amount, y = gcd$qual)[[2]]
str(gcd)
#select target variable and categorized risk factors
gcd.bin &lt;- gcd[, c("qual", "age.bin", "maturity.bin", "amount.bin")]
#run bivariate analysis on data frame with only categorical risk factors
bivariate(db = gcd.bin, target = "qual")
#run bivariate analysis on data frame with mixed risk factors (categorical and numeric). 
#for this example info table is produced
bivariate(db = gcd, target = "qual")
#run woe table for risk factor with more than 10 modalities
woe.tbl(tbl = gcd, x = "age.bin.1", y = "qual")
#calculate auc for risk factor with more than 10 modalities
lr &lt;- glm(qual ~ age.bin.1, family = "binomial", data = gcd)
auc.model(predictions = predict(lr, type = "response", newdata = gcd),
    observed = gcd$qual)
</code></pre>

<hr>
<h2 id='boots.vld'>Bootstrap model validation</h2><span id='topic+boots.vld'></span>

<h3>Description</h3>

<p><code>boots.vld</code> performs bootstrap model validation.
The goal of this procedure is to generate main model performance metrics such as absolute mean
square error, root mean square error or area under curve (AUC) based on resampling method.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>boots.vld(model, B = 1000, seed = 1122)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="boots.vld_+3A_model">model</code></td>
<td>
<p>Model in use, an object of class inheriting from <code>"glm"</code>.</p>
</td></tr>
<tr><td><code id="boots.vld_+3A_b">B</code></td>
<td>
<p>Number of bootstrap samples. Default is set to 1000.</p>
</td></tr>
<tr><td><code id="boots.vld_+3A_seed">seed</code></td>
<td>
<p>Random seed needed for ensuring the result reproducibility. Default is 1122.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The command <code>boots.vld</code> returns a list of two objects.<br />
The first object (<code>iter</code>), returns iteration performance metrics.<br />
The second object (<code>summary</code>), is the data frame of iterations averages of performance metrics.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>suppressMessages(library(PDtoolkit))
data(loans)
#run stepFWD
res &lt;- stepFWD(start.model = Creditability ~ 1, 
                p.value = 0.05, 
	   coding = "WoE",
	   db = loans)
#check output elements
names(res)
#extract the final model
final.model &lt;- res$model
#print coefficients
summary(final.model)$coefficients
#print head of coded development data
head(res$dev.db)
#calculate AUC
auc.model(predictions = predict(final.model, type = "response", newdata = res$dev.db),
    observed = res$dev.db$Creditability)
boots.vld (model = final.model, B = 10, seed = 1122)
</code></pre>

<hr>
<h2 id='cat.bin'>Categorical risk factor binning</h2><span id='topic+cat.bin'></span>

<h3>Description</h3>

<p><code>cat.bin</code> implements three-stage binning procedure for categorical risk factors.
The first stage is possible correction for minimum percentage of observations.
The second stage is possible correction for target rate (default rate), while the third one is
possible correction for maximum number of bins. Last stage implements procedure known as
adjacent pooling algorithm (APA) which aims to minimize information loss while iterative merging of the bins.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cat.bin(
  x,
  y,
  sc = NA,
  sc.merge = "none",
  min.pct.obs = 0.05,
  min.avg.rate = 0.01,
  max.groups = NA,
  force.trend = "modalities"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cat.bin_+3A_x">x</code></td>
<td>
<p>Categorical risk factor.</p>
</td></tr>
<tr><td><code id="cat.bin_+3A_y">y</code></td>
<td>
<p>Numeric target vector (binary).</p>
</td></tr>
<tr><td><code id="cat.bin_+3A_sc">sc</code></td>
<td>
<p>Special case elements. Default value is <code>NA</code>.</p>
</td></tr>
<tr><td><code id="cat.bin_+3A_sc.merge">sc.merge</code></td>
<td>
<p>Define how special cases will be treated. Available options are: <br />
<code>"none", "first", "last", "closest"</code>. If <code>"none"</code> is selected, then the special cases
will be kept in separate bin. If <code>"first"</code> or <code>"last"</code> is selected, then the special cases
will be merged with first or last bin. Depending on sorting option <code>force.trend</code>, first or last
bin will be determined based on alphabetic order (if <code>force.trend</code> is selected as <code>"modalities"</code>) or
on minimum or maximum default rate (if <code>force.trend</code> is selected as <code>"dr"</code>).
If <code>"closest"</code> is selected, then the special case will be merged with the bin
that is closest based on default rate. Merging of the special cases with other bins is performed at the
beginning i.e. before running any of three-stage procedures.
Default value is <code>"none"</code>.</p>
</td></tr>
<tr><td><code id="cat.bin_+3A_min.pct.obs">min.pct.obs</code></td>
<td>
<p>Minimum percentage of observations per bin. Default is 0.05 or minimum 30 observations.</p>
</td></tr>
<tr><td><code id="cat.bin_+3A_min.avg.rate">min.avg.rate</code></td>
<td>
<p>Minimum default rate. Default is 0.01 or minimum 1 bad case for <code>y</code> 0/1.</p>
</td></tr>
<tr><td><code id="cat.bin_+3A_max.groups">max.groups</code></td>
<td>
<p>Maximum number of bins (groups) allowed for analyzed risk factor. If in the first two stages
number of bins is less or equal to selected <code>max.groups</code> or if <code>max.groups</code> is
default value (<code>NA</code>), no adjustment is performed. Otherwise, APA algorithm is applied
which minimize information loss in further iterative process of bin merging.</p>
</td></tr>
<tr><td><code id="cat.bin_+3A_force.trend">force.trend</code></td>
<td>
<p>Defines how initial summary table will be ordered. Possible options are:<br />
<code>"modalities"</code> and <code>"dr"</code>. If  <code>"modalities"</code> is selected, then merging will be
performed forward based on alphabetic order of risk factor modalities. On the other hand,
if <code>"dr"</code> is selected, then bins merging will be performed forward based on increasing order of
default rate per modality. This direction of merging is applied in the all three stages.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The command <code>cat.bin</code> generates a list of two objects. The first object, data frame <code>summary.tbl</code>
presents a summary table of final binning, while <code>x.trans</code> is a vector of new grouping values.
</p>


<h3>References</h3>

<p>Anderson, R. (2007). The credit scoring toolkit: theory and practice for
retail credit risk management and decision automation,
Oxford University Press
</p>


<h3>Examples</h3>

<pre><code class='language-R'>suppressMessages(library(PDtoolkit))
data(loans)
#prepare risk factor Purpose for the analysis
loans$Purpose &lt;- ifelse(nchar(loans$Purpose) == 2, loans$Purpose, paste0("0", loans$Purpose))
#artificially add missing values in order to show functions' features
loans$Purpose[1:6] &lt;- NA
#run binning procedure
res &lt;- cat.bin(x = loans$Purpose, 
	   y = loans$Creditability, 
	   sc = NA,
	   sc.merge = "none",
	   min.pct.obs = 0.05, 
	   min.avg.rate = 0.05,
	   max.groups = NA, 
	   force.trend = "modalities")
res[[1]]
#check new risk factor against the original 
table(loans$Purpose, res[[2]], useNA = "always")
#repeat the same process with setting max.groups to 4 and force.trend to dr
res &lt;- cat.bin(x = loans$Purpose, 
	   y = loans$Creditability, 
	   sc = NA,
	   sc.merge = "none",
	   min.pct.obs = 0.05, 
	   min.avg.rate = 0.05,
	   max.groups = 4, 
	   force.trend = "dr")
res[[1]]
#check new risk factor against the original 
table(loans$Purpose, res[[2]], useNA = "always")
#example of shrinking number of groups for numeric risk factor
#copy exisitng numeric risk factor to new called maturity
loans$maturity &lt;- loans$"Duration of Credit (month)"
#artificially add missing values in order to show functions' features
loans$maturity[1:10] &lt;- NA
#categorize maturity with MAPA algorithim from monobin package
loans$maturity.bin &lt;- cum.bin(x = loans$maturity, 
				y = loans$Creditability, g = 50)[[2]]
table(loans$maturity.bin)
#run binning procedure to decrease number of bins from the previous step
res &lt;- cat.bin(x = loans$maturity.bin, 
	   y = loans$Creditability, 
	   sc = "SC",
	   sc.merge = "closest",
	   min.pct.obs = 0.05, 
	   min.avg.rate = 0.01,
	   max.groups = 5, 
	   force.trend = "modalities")
res[[1]]
#check new risk factor against the original 
table(loans$maturity.bin, res[[2]], useNA = "always")
</code></pre>

<hr>
<h2 id='cat.slice'>Slice categorical variable</h2><span id='topic+cat.slice'></span>

<h3>Description</h3>

<p><code>cat.slice</code> implements manual re-coding of character vector values for a given mapping scheme.
This procedure is one of the helper functions which are handy for the model monitoring phase
(i.e. after model implementation).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cat.slice(x, mapping, sc = NA, sc.r = "SC")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cat.slice_+3A_x">x</code></td>
<td>
<p>Character vector to be re-coded.</p>
</td></tr>
<tr><td><code id="cat.slice_+3A_mapping">mapping</code></td>
<td>
<p>Data frame with compulsory columns: <code>x.orig</code> and <code>x.mapp</code> which represent the mapping
scheme. Column <code>x.orig</code> should contain unique values of original vector <code>x</code>, while <code>x.mapp</code>
should contain corresponding mapping values.</p>
</td></tr>
<tr><td><code id="cat.slice_+3A_sc">sc</code></td>
<td>
<p>Character vector with special case elements. Default value is <code>NA</code>.</p>
</td></tr>
<tr><td><code id="cat.slice_+3A_sc.r">sc.r</code></td>
<td>
<p>Character vector used for replacement of special cases. If supplied as one
element vector, it will be recycled to the length of <code>sc</code>. Default value is <code>"SC"</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The command <code>cat.slice</code> returns vector of re-coded values and special cases.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>suppressMessages(library(PDtoolkit))
data(gcd)
x &lt;- gcd$maturity
#artificially add some special values
x[1:5] &lt;- Inf
x[6:7] &lt;- NA
mbin &lt;- cum.bin(x = x, y = gcd$qual, sc.method = "together")
mbin[[1]]
gcd$x &lt;- mbin[[2]]
cb &lt;- cat.bin(x = gcd$x, 
	  y = gcd$qual, 
	  sc = "SC",
	  sc.merge = "none",
	  min.pct.obs = 0.05, 
	  min.avg.rate = 0.05)
x &lt;- gcd$x
mapping &lt;- data.frame(x.orig = x, x.mapp = cb[[2]])%&gt;%
       group_by(x.orig, x.mapp) %&gt;%
       summarise(n = n(), .groups = "drop")
mapping &lt;- data.frame(mapping[, -3])
sc &lt;- cat.slice(x = x, 
	     mapping = mapping, 
	     sc = NA, 
	     sc.r = "SC")
#compare automatic and manual re-coding
table(cb[[2]], useNA = "always")
table(sc, useNA = "always")
</code></pre>

<hr>
<h2 id='confusion.matrix'>Confusion matrix</h2><span id='topic+confusion.matrix'></span>

<h3>Description</h3>

<p><code>confusion.matrix</code> returns confusion matrix along with accompanied performance metrics.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>confusion.matrix(predictions, observed, cutoff)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="confusion.matrix_+3A_predictions">predictions</code></td>
<td>
<p>Model predictions.</p>
</td></tr>
<tr><td><code id="confusion.matrix_+3A_observed">observed</code></td>
<td>
<p>Observed values of target variable.</p>
</td></tr>
<tr><td><code id="confusion.matrix_+3A_cutoff">cutoff</code></td>
<td>
<p>Cutoff value. Single value numeric vector between 0 and 1.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The command <code>confusion.matrix</code> returns list of two objects. The first object is confusion matrix table,
while the second one is data frame with accompanied performance metrics.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>suppressMessages(library(PDtoolkit))
data(loans)
#identify numeric risk factors
num.rf &lt;- sapply(loans, is.numeric)
num.rf &lt;- names(num.rf)[!names(num.rf)%in%"Creditability" &amp; num.rf]
#discretized numeric risk factors using mdt.bin from monobin package
loans[, num.rf] &lt;- sapply(num.rf, function(x) 
			  mdt.bin(x = loans[, x], y = loans[, "Creditability"])[[2]])
str(loans)
res &lt;- stepFWD(start.model = Creditability ~ 1, 
   p.value = 0.05, 
   coding = "WoE",
   db = loans)
names(res)
summary(res$model)$coefficients
loans$model.pred &lt;- predict(res$model, type = "response")
#confusion matrix
confusion.matrix(predictions = predict(res$model, type = "response"), 
	     observed = loans$"Creditability",
	     cutoff = 0.5)
</code></pre>

<hr>
<h2 id='constrained.logit'>Constrained logistic regression</h2><span id='topic+constrained.logit'></span>

<h3>Description</h3>

<p><code>constrained.logit</code> performs estimation of logistic regression with constrains on values of the
estimated coefficient.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>constrained.logit(db, x, y, lower, upper)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="constrained.logit_+3A_db">db</code></td>
<td>
<p>Data set of risk factors and target variable.</p>
</td></tr>
<tr><td><code id="constrained.logit_+3A_x">x</code></td>
<td>
<p>Character vector of risk factors (independent variables) used in logistic regression.</p>
</td></tr>
<tr><td><code id="constrained.logit_+3A_y">y</code></td>
<td>
<p>Character vector of target (dependent variable) used in logistic regression.</p>
</td></tr>
<tr><td><code id="constrained.logit_+3A_lower">lower</code></td>
<td>
<p>Numeric vector of lower boundaries of the coefficients. This vector should contain value of the intercept,
therefore number of elements should be equal to number of elements of the argument <code>x</code> plus one.</p>
</td></tr>
<tr><td><code id="constrained.logit_+3A_upper">upper</code></td>
<td>
<p>Numeric vector of upper boundaries of the coefficients. This vector should contain value of the intercept,
therefore number of elements should be equal to number of elements of the argument <code>x</code> plus one.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The command <code>constrained.logit</code> returns list of two vectors. The first vector contains values of the
estimated coefficients, while the second vector contains predictions of the constrained logistic regression.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>suppressMessages(library(PDtoolkit))
data(loans)
#model 1
reg.1 &lt;- glm(Creditability ~ `Account Balance`, family = "binomial", data = loans)
summary(reg.1)$coefficient
loans$pred.1 &lt;-  unname(predict(reg.1, type = "response"))
#model 2
reg.2 &lt;- glm(Creditability ~ `Age (years)`, family = "binomial", data = loans)
summary(reg.2)$coefficient
loans$pred.2 &lt;-  unname(predict(reg.2, type = "response"))
#integration
fm &lt;- glm(Creditability ~ pred.1 + pred.2, family = "binomial", data = loans)
summary(fm)$coefficient
fm.pred &lt;- predict(fm, type = "response", newdata = loans)
auc.model(predictions = fm.pred, observed = loans$Creditability)
#constrained integration (regression)
cl.r &lt;- constrained.logit(db = loans, 
		  x = c("pred.1", "pred.2"), 
		  y = "Creditability",
		  lower = c(-Inf, -Inf, -Inf), 
		  upper = c(Inf, 4.5, Inf))
names(cl.r)
cl.r[["beta"]]
auc.model(predictions = cl.r[["prediction"]], observed = loans$Creditability)
</code></pre>

<hr>
<h2 id='create.partitions'>Create partitions (aka nested dummy variables)</h2><span id='topic+create.partitions'></span>

<h3>Description</h3>

<p><code>create.partitions</code> performs creation of partitions (aka nested dummy variables).
Using directly into logistic regression, partitions provide insight into difference of log-odds of adjacent risk factor bins (groups).
Adjacent bins are selected based on alphabetic order of analyzed risk factor modalities, therefore it is important
to ensure that modality labels are defined in line with expected monotonicity or any other criterion
that is considered while engineering the risk factors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>create.partitions(db)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="create.partitions_+3A_db">db</code></td>
<td>
<p>Data set of risk factors to be converted into partitions.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The command <code>create.partitions</code> returns a list of two objects (data frames).<br />
The first object (<code>partitions</code>), returns the data set with newly created nested dummy variables.<br />
The second object (<code>info</code>), is the data frame that returns info on partition process.
Set of quality checks are performed and reported if any of them observed. Two of them are of terminal nature
i.e. if observed, risk factor is not processed further (less then two non-missing groups and more than 10 modalities)
while the one provides only info (warning) as usually deviates from the main principles of risk factor processing
(less than 5% of observations per bin).
</p>


<h3>References</h3>

<p>Scallan, G. (2011). Class(ic) Scorecards: Selecting Characteristics and Attributes in Logistic Regression,
Edinburgh Credit Scoring Conference.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>suppressMessages(library(PDtoolkit))
data(loans)
#identify numeric risk factors
num.rf &lt;- sapply(loans, is.numeric)
num.rf &lt;- names(num.rf)[!names(num.rf)%in%"Creditability" &amp; num.rf]
#discretized numeric risk factors using ndr.bin from monobin package
loans[, num.rf] &lt;- sapply(num.rf, function(x) 
cum.bin(x = loans[, x], y = loans[, "Creditability"])[[2]])
str(loans)
loans.p &lt;- create.partitions(db = loans[, num.rf])
head(loans.p[["partitions"]])
loans.p[["info"]]
#bring target to partitions
db.p &lt;- cbind.data.frame(Creditability = loans$Creditability, loans.p[[1]])
#prepare risk factors for stepMIV 
db.p[, -1] &lt;- sapply(db.p[, -1], as.character)
#run stepMIV
res &lt;- stepMIV(start.model = Creditability ~ 1, 
   miv.threshold = 0.02, 
   m.ch.p.val = 0.05,
   coding = "dummy",
   db = db.p)
#check output elements
names(res)
#extract the final model
final.model &lt;- res$model
#print coefficients
summary(final.model)$coefficients
</code></pre>

<hr>
<h2 id='cutoff.palette'>Palette of cutoff values that minimize and maximize metrics from the confusion matrix</h2><span id='topic+cutoff.palette'></span>

<h3>Description</h3>

<p><code>cutoff.palette</code> returns confusion matrix along with accompanied performance metrics.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cutoff.palette(predictions, observed, min.pct.obs = 0.05, min.pct.def = 0.01)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cutoff.palette_+3A_predictions">predictions</code></td>
<td>
<p>Model predictions.</p>
</td></tr>
<tr><td><code id="cutoff.palette_+3A_observed">observed</code></td>
<td>
<p>Observed values of target variable.</p>
</td></tr>
<tr><td><code id="cutoff.palette_+3A_min.pct.obs">min.pct.obs</code></td>
<td>
<p>Minimum percentage of observations. Used to select boundaries of cutoff values. Default value is 0.05.</p>
</td></tr>
<tr><td><code id="cutoff.palette_+3A_min.pct.def">min.pct.def</code></td>
<td>
<p>Minimum percentage of default. Used to select boundaries of cutoff values. Default value is 0.01.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The command <code>cutoff.palette</code> returns data frame with minimum and maximum values of each confusion
matrix metric along with optimized cutoff itself.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>suppressMessages(library(PDtoolkit))
data(loans)
#identify numeric risk factors
num.rf &lt;- sapply(loans, is.numeric)
num.rf &lt;- names(num.rf)[!names(num.rf)%in%"Creditability" &amp; num.rf]
#discretized numeric risk factors using mdt.bin from monobin package
loans[, num.rf] &lt;- sapply(num.rf, function(x) 
			  mdt.bin(x = loans[, x], y = loans[, "Creditability"])[[2]])
str(loans)
res &lt;- stepFWD(start.model = Creditability ~ 1, 
   p.value = 0.05, 
   coding = "WoE",
   db = loans)
#run cutoff optimization
cop &lt;- cutoff.palette(predictions = predict(res$model, type = "response"), 
			observed = loans$"Creditability",
			min.pct.obs = 0.05, 
			min.pct.def = 0.01)
cop
confusion.matrix(predictions = predict(res$model, type = "response"), 
	     observed = loans$"Creditability",
	     cutoff = cop$cutoff.max[cop$metric%in%"f1.score"])
</code></pre>

<hr>
<h2 id='decision.tree'>Custom decision tree algorithm</h2><span id='topic+decision.tree'></span>

<h3>Description</h3>

<p><code>decision.tree</code> runs customized decision tree algorithm. Customization refers to minimum
percentage of observations and defaults in each node, maximum tree depth, monotonicity condition
at each splitting node and statistical test (test of two proportions) used for node splitting.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>decision.tree(
  db,
  rf,
  target,
  min.pct.obs = 0.05,
  min.avg.rate = 0.01,
  p.value = 0.5,
  max.depth = NA,
  monotonicity
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="decision.tree_+3A_db">db</code></td>
<td>
<p>Data frame of risk factors and target variable supplied for interaction extraction.</p>
</td></tr>
<tr><td><code id="decision.tree_+3A_rf">rf</code></td>
<td>
<p>Character vector of risk factor names on which decision tree is run.</p>
</td></tr>
<tr><td><code id="decision.tree_+3A_target">target</code></td>
<td>
<p>Name of target variable (default indicator 0/1) within db argument.</p>
</td></tr>
<tr><td><code id="decision.tree_+3A_min.pct.obs">min.pct.obs</code></td>
<td>
<p>Minimum percentage of observation in each leaf. Default is 0.05 or 30 observations.</p>
</td></tr>
<tr><td><code id="decision.tree_+3A_min.avg.rate">min.avg.rate</code></td>
<td>
<p>Minimum percentage of defaults in each leaf. Default is 0.01 or 1 default case.</p>
</td></tr>
<tr><td><code id="decision.tree_+3A_p.value">p.value</code></td>
<td>
<p>Significance level of test of two proportions for splitting criteria. Default is 0.05.</p>
</td></tr>
<tr><td><code id="decision.tree_+3A_max.depth">max.depth</code></td>
<td>
<p>Maximum tree depth.</p>
</td></tr>
<tr><td><code id="decision.tree_+3A_monotonicity">monotonicity</code></td>
<td>
<p>Logical indicator. If <code>TRUE</code>, observed trend between risk factor and target will be preserved
in splitting node.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The command <code>decision.tree</code> returns a object of class cdt. For details on output elements see the Examples.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+predict.cdt">predict.cdt</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>suppressMessages(library(PDtoolkit))
data(loans)
#modify risk factors in order to show how the function works with missing values
loans$"Account Balance"[1:10] &lt;- NA
loans$"Duration of Credit (month)"[c(13, 15)] &lt;- NA
tree.res &lt;- decision.tree(db = loans,
	rf = c("Account Balance", "Duration of Credit (month)"), 
	target = "Creditability",
	min.pct.obs = 0.05,
	min.avg.rate = 0.01,
	p.value = 0.05,
	max.depth = NA,
	monotonicity = TRUE)
str(tree.res)
</code></pre>

<hr>
<h2 id='dp.testing'>Testing the discriminatory power of PD rating model</h2><span id='topic+dp.testing'></span>

<h3>Description</h3>

<p><code>dp.testing</code> performs testing of discriminatory power of the model in use applied to application portfolio
in comparison to the discriminatory power from the moment of development. Testing is performed based on area
under curve (AUC) from the application portfolio and development sample under assumption that latter is a
deterministic (as given) and that test statistics follow the normal distribution.
Standard error of AUC for application portfolio is calculated as proposed by
Hanley and McNeil (see References).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dp.testing(app.port, def.ind, pdc, auc.test, alternative, alpha = 0.05)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dp.testing_+3A_app.port">app.port</code></td>
<td>
<p>Application portfolio (data frame) which contains default indicator (0/1) and
calibrated probabilities of default (PD) in use.</p>
</td></tr>
<tr><td><code id="dp.testing_+3A_def.ind">def.ind</code></td>
<td>
<p>Name of the column that represents observed default indicator (0/1).</p>
</td></tr>
<tr><td><code id="dp.testing_+3A_pdc">pdc</code></td>
<td>
<p>Name of the column that represent calibrated PD in use.</p>
</td></tr>
<tr><td><code id="dp.testing_+3A_auc.test">auc.test</code></td>
<td>
<p>Value of tested AUC (usually AUC from development sample).</p>
</td></tr>
<tr><td><code id="dp.testing_+3A_alternative">alternative</code></td>
<td>
<p>Alternative hypothesis. Available options are: <code>"less", "greater", "two.sided"</code>.</p>
</td></tr>
<tr><td><code id="dp.testing_+3A_alpha">alpha</code></td>
<td>
<p>Significance level of p-value for hypothesis testing. Default is 0.05.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Due to the fact that test of discriminatory power is usually implemented on the application portfolio,
certain prerequisites are needed to be fulfilled. In the first place model should be developed
and rating scale should be formed. In order to reflect appropriate role and right moment of
tests application, presented simplified example covers all steps before test implementation.
</p>


<h3>Value</h3>

<p>The command <code>dp.testing</code> returns a data frame with input parameters along with
hypothesis testing metrics such as estimated difference of observed (application portfolio) and testing AUC,
standard error of observed AUC, p-value of testing procedure and accepted hypothesis.
</p>


<h3>References</h3>

<p>Hanley J. and McNeil B. (1982). The meaning and use of the area under a receiver operating characteristic (ROC) curve.
Radiology (1982) 43 (1) pp. 29-36.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>suppressMessages(library(PDtoolkit))
data(loans)
#estimate some dummy model
mod.frm &lt;- `Creditability` ~ `Account Balance` + `Duration of Credit (month)` +
				`Age (years)`
lr.mod &lt;- glm(mod.frm, family = "binomial", data = loans)
summary(lr.mod)$coefficients
#model predictions
loans$pred &lt;-  unname(predict(lr.mod, type = "response", newdata = loans))
#scale probabilities
loans$score &lt;- scaled.score(probs = loans$pred, score = 600, odd = 50/1, pdo = 20)
#group scores into rating
loans$rating &lt;- sts.bin(x = round(loans$score), y = loans$Creditability, y.type = "bina")[[2]]
#create rating scale
rs &lt;- loans %&gt;%
group_by(rating) %&gt;%
summarise(no = n(),
	    nb = sum(Creditability),
	    ng = sum(1 - Creditability)) %&gt;%
mutate(dr = nb / no)
rs
#calcualte portfolio default rate
sum(rs$dr * rs$no / sum(rs$no))
#calibrate rating scale to central tendency of 27% with minimum PD of 5%
ct &lt;- 0.27
min.pd &lt;- 0.05
rs$pd &lt;- rs.calibration(rs = rs, 
			dr = "dr", 
			w = "no", 
			ct = ct, 
			min.pd = min.pd,
			method = "log.odds.ab")[[1]]
#check
rs
sum(rs$pd * rs$no / sum(rs$no))
#bring calibrated PDs to the development sample
loans &lt;- merge(loans, rs, by = "rating", all.x = TRUE)
#calculate development AUC
auc.dev &lt;- auc.model(predictions = loans$pd, observed = loans$Creditability)
auc.dev
#simulate some dummy application portfolio
set.seed(321)
app.port &lt;- loans[sample(1:nrow(loans), 400), ]
#calculate application portfolio AUC
auc.app &lt;- auc.model(predictions = app.port$pd, observed = app.port$Creditability)
auc.app
#test deterioration of descriminatory power measured by AUC
dp.testing(app.port = app.port, 
     def.ind = "Creditability", 
     pdc = "pd", auc.test = 0.7557,
     alternative = "less", 
     alpha = 0.05)
</code></pre>

<hr>
<h2 id='embedded.blocks'>Embedded blocks regression</h2><span id='topic+embedded.blocks'></span>

<h3>Description</h3>

<p><code>embedded.blocks</code> performs blockwise regression where the predictions of each blocks' model is used as an
risk factor for the model of the following block.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>embedded.blocks(
  method,
  target,
  db,
  coding = "WoE",
  blocks,
  p.value = 0.05,
  miv.threshold = 0.02,
  m.ch.p.val = 0.05
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="embedded.blocks_+3A_method">method</code></td>
<td>
<p>Regression method applied on each block.
Available methods: <code>"stepMIV"</code>, <code>"stepFWD"</code>, <code>"stepRPC"</code>, <code>"stepFWDr"</code>, and <code>"stepRPCr"</code>.</p>
</td></tr>
<tr><td><code id="embedded.blocks_+3A_target">target</code></td>
<td>
<p>Name of target variable within <code>db</code> argument.</p>
</td></tr>
<tr><td><code id="embedded.blocks_+3A_db">db</code></td>
<td>
<p>Modeling data with risk factors and target variable.</p>
</td></tr>
<tr><td><code id="embedded.blocks_+3A_coding">coding</code></td>
<td>
<p>Type of risk factor coding within the model. Available options are: <code>"WoE"</code> and
<code>"dummy"</code>. If <code>"WoE"</code> is selected, then modalities of the risk factors are replaced
by WoE values, while for <code>"dummy"</code> option dummies (0/1) will be created for <code>n-1</code>
modalities where <code>n</code> is total number of modalities of analyzed risk factor.</p>
</td></tr>
<tr><td><code id="embedded.blocks_+3A_blocks">blocks</code></td>
<td>
<p>Data frame with defined risk factor groups. It has to contain the following columns: <code>rf</code> and
<code>block</code>.</p>
</td></tr>
<tr><td><code id="embedded.blocks_+3A_p.value">p.value</code></td>
<td>
<p>Significance level of p-value for the estimated coefficient. For <code>WoE</code> coding this value is
is directly compared to p-value of the estimated coefficient, while for <code>dummy</code> coding
multiple Wald test is employed and its p-value is used for comparison with selected threshold (<code>p.value</code>).
This argument is applicable only for <code>"stepFWD"</code> and <code>"stepRPC"</code> selected methods.</p>
</td></tr>
<tr><td><code id="embedded.blocks_+3A_miv.threshold">miv.threshold</code></td>
<td>
<p>MIV (marginal information value) entrance threshold applicable only for code&quot;stepMIV&quot; method.
Only the risk factors with MIV higher than the threshold are candidate for the new model.
Additional criteria is that MIV value should significantly separate
good from bad cases measured by marginal chi-square test.</p>
</td></tr>
<tr><td><code id="embedded.blocks_+3A_m.ch.p.val">m.ch.p.val</code></td>
<td>
<p>Significance level of p-value for marginal chi-square test applicable only for code&quot;stepMIV&quot; method.
This test additionally supports MIV value of candidate risk factor for final decision.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The command <code>embedded.blocks</code> returns a list of three objects.<br />
The first object (<code>model</code>) is the list of the models of each block (an object of class inheriting from <code>"glm"</code>).<br />
The second object (<code>steps</code>), is the data frame with risk factors selected from the each block.<br />
The third object (<code>dev.db</code>), returns the list of block's model development databases.<br />
</p>


<h3>References</h3>

<p>Anderson, R.A. (2021). Credit Intelligence &amp; Modelling, Many Paths through the Forest of Credit Rating and Scoring,
OUP Oxford
</p>


<h3>See Also</h3>

<p><code><a href="#topic+staged.blocks">staged.blocks</a></code>, <code><a href="#topic+ensemble.blocks">ensemble.blocks</a></code>, <code><a href="#topic+stepMIV">stepMIV</a></code>, <code><a href="#topic+stepFWD">stepFWD</a></code>,
<code><a href="#topic+stepRPC">stepRPC</a></code>, <code><a href="#topic+stepFWDr">stepFWDr</a></code> and <code><a href="#topic+stepRPCr">stepRPCr</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>suppressMessages(library(PDtoolkit))
data(loans)
#create risk factor priority groups
rf.all &lt;- names(loans)[-1]
set.seed(22)
blocks &lt;- data.frame(rf = rf.all, block = sample(1:3, length(rf.all), rep = TRUE))
blocks &lt;- blocks[order(blocks$block), ]
blocks
#method: stepFWDr
res &lt;- embedded.blocks(method = "stepFWDr", 
		     target = "Creditability",
		     db = loans, 
		     blocks = blocks, 
		     p.value = 0.05)
names(res)
nb &lt;- length(res[["models"]])
res$models[[nb]]

auc.model(predictions = predict(res$models[[nb]], type = "response", 
				    newdata = res$dev.db[[nb]]),
      observed = res$dev.db[[nb]]$Creditability)
</code></pre>

<hr>
<h2 id='encode.woe'>Encode WoE</h2><span id='topic+encode.woe'></span>

<h3>Description</h3>

<p><code>encode.woe</code> implements replacement of character vector values with WoE values for a given mapping scheme.
This procedure is one of the helper functions which are handy for the model monitoring phase
(i.e. after model implementation).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>encode.woe(x, mapping)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="encode.woe_+3A_x">x</code></td>
<td>
<p>Character vector to be re-coded.</p>
</td></tr>
<tr><td><code id="encode.woe_+3A_mapping">mapping</code></td>
<td>
<p>Data frame with compulsory columns: <code>x.mod</code> and <code>x.woe</code> which represents the mapping
scheme. Column <code>x.mod</code> should contain unique values of original vector <code>x</code>, while <code>x.woe</code>
should contain corresponding mapping values.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The command <code>encode.woe</code> returns vector of re-coded WoE values.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>suppressMessages(library(PDtoolkit))
data(gcd)
mbin &lt;- cum.bin(x = gcd$maturity, y = gcd$qual, sc.method = "together")
mbin[[1]]
table(mbin[[2]], useNA = "always")
gcd$x.mod &lt;- mbin[[2]]
woe.rep &lt;- replace.woe(db = gcd[, c("qual", "x.mod")], target = "qual")
gcd$x.woe &lt;- woe.rep[[1]]$x
mapping &lt;- data.frame(x.mod = gcd$x.mod, x.woe = gcd$x.woe)%&gt;%
     group_by(x.mod, x.woe) %&gt;%
     summarise(n = n(), .groups = "drop")
mapping &lt;- data.frame(mapping[, -3])
ewoe &lt;- encode.woe(x = gcd$x.mod, mapping = mapping)
identical(ewoe, woe.rep[[1]]$x)
</code></pre>

<hr>
<h2 id='ensemble.blocks'>Ensemble blocks regression</h2><span id='topic+ensemble.blocks'></span>

<h3>Description</h3>

<p><code>ensemble.blocks</code> performs blockwise regression where the predictions of each blocks' model are
integrated into a final model. The final model is estimated in the form of logistic regression without
any check of the estimated coefficients (e.g. statistical significance or sign of the estimated coefficients).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ensemble.blocks(
  method,
  target,
  db,
  coding = "WoE",
  blocks,
  p.value = 0.05,
  miv.threshold = 0.02,
  m.ch.p.val = 0.05
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ensemble.blocks_+3A_method">method</code></td>
<td>
<p>Regression method applied on each block.
Available methods: <code>"stepMIV"</code>, <code>"stepFWD"</code>, <code>"stepRPC"</code>, <code>"stepFWDr"</code>, and <code>"stepRPCr"</code>.</p>
</td></tr>
<tr><td><code id="ensemble.blocks_+3A_target">target</code></td>
<td>
<p>Name of target variable within <code>db</code> argument.</p>
</td></tr>
<tr><td><code id="ensemble.blocks_+3A_db">db</code></td>
<td>
<p>Modeling data with risk factors and target variable.</p>
</td></tr>
<tr><td><code id="ensemble.blocks_+3A_coding">coding</code></td>
<td>
<p>Type of risk factor coding within the model. Available options are: <code>"WoE"</code> and
<code>"dummy"</code>. If <code>"WoE"</code> is selected, then modalities of the risk factors are replaced
by WoE values, while for <code>"dummy"</code> option dummies (0/1) will be created for <code>n-1</code>
modalities where <code>n</code> is total number of modalities of analyzed risk factor.</p>
</td></tr>
<tr><td><code id="ensemble.blocks_+3A_blocks">blocks</code></td>
<td>
<p>Data frame with defined risk factor groups. It has to contain the following columns: <code>rf</code> and
<code>block</code>.</p>
</td></tr>
<tr><td><code id="ensemble.blocks_+3A_p.value">p.value</code></td>
<td>
<p>Significance level of p-value for the estimated coefficient. For <code>WoE</code> coding this value is
is directly compared to p-value of the estimated coefficient, while for <code>dummy</code> coding
multiple Wald test is employed and its p-value is used for comparison with selected threshold (<code>p.value</code>).
This argument is applicable only for <code>"stepFWD"</code> and <code>"stepRPC"</code> selected methods.</p>
</td></tr>
<tr><td><code id="ensemble.blocks_+3A_miv.threshold">miv.threshold</code></td>
<td>
<p>MIV (marginal information value) entrance threshold applicable only for code&quot;stepMIV&quot; method.
Only the risk factors with MIV higher than the threshold are candidate for the new model.
Additional criteria is that MIV value should significantly separate
good from bad cases measured by marginal chi-square test.</p>
</td></tr>
<tr><td><code id="ensemble.blocks_+3A_m.ch.p.val">m.ch.p.val</code></td>
<td>
<p>Significance level of p-value for marginal chi-square test applicable only for code&quot;stepMIV&quot; method.
This test additionally supports MIV value of candidate risk factor for final decision.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The command <code>embeded.blocks</code> returns a list of three objects.<br />
The first object (<code>model</code>) is the list of the models of each block (an object of class inheriting from <code>"glm"</code>).<br />
The second object (<code>steps</code>), is the data frame with risk factors selected from the each block.<br />
The third object (<code>dev.db</code>), returns the list of block's model development databases.<br />
</p>


<h3>References</h3>

<p>Anderson, R.A. (2021). Credit Intelligence &amp; Modelling, Many Paths through the Forest of Credit Rating and Scoring,
OUP Oxford
</p>


<h3>See Also</h3>

<p><code><a href="#topic+staged.blocks">staged.blocks</a></code>, <code><a href="#topic+embedded.blocks">embedded.blocks</a></code>, <code><a href="#topic+stepMIV">stepMIV</a></code>, <code><a href="#topic+stepFWD">stepFWD</a></code>,
<code><a href="#topic+stepRPC">stepRPC</a></code>, <code><a href="#topic+stepFWDr">stepFWDr</a></code> and <code><a href="#topic+stepRPCr">stepRPCr</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>suppressMessages(library(PDtoolkit))
data(loans)
#create risk factor priority groups
rf.all &lt;- names(loans)[-1]
set.seed(22)
blocks &lt;- data.frame(rf = rf.all, block = sample(1:3, length(rf.all), rep = TRUE))
blocks &lt;- blocks[order(blocks$block), ]
blocks
#method: stepRPCr
res &lt;- ensemble.blocks(method = "stepRPCr", 
		      target = "Creditability",
		      db = loans,
		      blocks = blocks, 
		      p.value = 0.05)
names(res)
nb &lt;- length(res[["models"]])
res$models[[nb]]
auc.model(predictions = predict(res$models[[nb]], type = "response", 
				    newdata = res$dev.db[[nb]]),
      observed = res$dev.db[[nb]]$Creditability)
</code></pre>

<hr>
<h2 id='evrs'>Modelling the Economic Value of Credit Rating System</h2><span id='topic+evrs'></span>

<h3>Description</h3>

<p><code>evrs</code> calculates the economic benefits of improved PD model based on increase of portfolio return.
Implemented algorithm replicates the framework presented in the Reference under assumption that
bank adopts continuous PD rating scale. Despite this assumption, results are almost identical for scenarios
of base case portfolio from the Reference.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>evrs(
  db,
  pd,
  benchmark,
  lgd,
  target,
  sigma = NA,
  r,
  elasticity,
  prob.to.leave.threshold,
  sim.num = 500,
  seed = 991
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="evrs_+3A_db">db</code></td>
<td>
<p>Data frame with at least the following columns: default indicator (target), PDs of model in use,
PDs of benchmark model and LGD values.</p>
</td></tr>
<tr><td><code id="evrs_+3A_pd">pd</code></td>
<td>
<p>Name of PD of model in use within db argument.</p>
</td></tr>
<tr><td><code id="evrs_+3A_benchmark">benchmark</code></td>
<td>
<p>Name of PD of benchmark model within db argument.</p>
</td></tr>
<tr><td><code id="evrs_+3A_lgd">lgd</code></td>
<td>
<p>Name of LGD values within db argument.</p>
</td></tr>
<tr><td><code id="evrs_+3A_target">target</code></td>
<td>
<p>Name of target (default indicator 0/1) within db argument.</p>
</td></tr>
<tr><td><code id="evrs_+3A_sigma">sigma</code></td>
<td>
<p>Measurement error of model in use. If default value (<code>NA</code>) is passed, then measurement error
is calculated as standard deviation of PD difference of model in use and benchmark model.</p>
</td></tr>
<tr><td><code id="evrs_+3A_r">r</code></td>
<td>
<p>Risk-free rate.</p>
</td></tr>
<tr><td><code id="evrs_+3A_elasticity">elasticity</code></td>
<td>
<p>Elasticity parameter used to define customer churn in case of loan overpricing.</p>
</td></tr>
<tr><td><code id="evrs_+3A_prob.to.leave.threshold">prob.to.leave.threshold</code></td>
<td>
<p>Threshold for customers' probability to leave in case of loan overpricing.</p>
</td></tr>
<tr><td><code id="evrs_+3A_sim.num">sim.num</code></td>
<td>
<p>Number of simulations. Default is 500.</p>
</td></tr>
<tr><td><code id="evrs_+3A_seed">seed</code></td>
<td>
<p>Random seed to ensure reproducibility. Default is 991.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The command <code>evrs</code> returns a list of two elements. The first element is data frame
<code>summary.tbl</code> and it provides simulation summary: number of simulations, number of successful simulations,
population size (number of observations of supplied <code>db</code> data frame), measurement error,
average churn value (number of customers that left the portfolio due to the overpricing), average return of simulated
portfolios, return of benchmark portfolio and return difference (main result of the simulation). The second element is
numeric vector of return averages of simulated portfolios.
</p>


<h3>References</h3>

<p>Jankowitsch at al. (2007). Modelling the economic value of credit rating systems.
Journal of Banking &amp; Finance, Volume 31, Issue 1, .
</p>


<h3>Examples</h3>

<pre><code class='language-R'>suppressMessages(library(PDtoolkit))
data(loans)
#simulate model in use
miu.formula &lt;- Creditability ~ `Age (years)` + `Duration of Credit (month)` +
   			  `Value Savings/Stocks` + `Purpose`
miu &lt;- glm(miu.formula, family = "binomial", data = loans)
miu.pd &lt;- unname(predict(miu, type = "response", newdata = loans))
#simulate benchmark model with interaction.transformer support
bnm.pack &lt;- stepFWDr(start.model = Creditability ~ 1, 
                    p.value = 0.05, 
                    db = loans,
                    check.start.model = TRUE, 
                    offset.vals = NULL)
bnm &lt;- bnm.pack$model
bnm.pd &lt;- unname(predict(bnm, type = "response", newdata = bnm.pack$dev.db))
#prepare data for evrs function
db &lt;- data.frame("Creditability" = loans$Creditability, 	
   pd = miu.pd, 
   pd.benchmark = bnm.pd, 
   lgd = 0.75)
#calculate the difference in portfolio return between model in use the benchmark model
res &lt;- evrs(db = db, 
pd = "pd", 
benchmark = "pd.benchmark", 
lgd = "lgd",
target = "Creditability",
sigma = NA, 
r = 0.03, 
elasticity = 100, 
prob.to.leave.threshold = 0.5,
sim.num = 500, 
seed = 991)
names(res)
#print simulation summary table
res[["summary.tbl"]]
#portfolio return increase in case of using benchmark model
res[["summary.tbl"]][, "return.difference", drop = FALSE]
#summary of simulated returns
summary(res[["return.sim"]])
</code></pre>

<hr>
<h2 id='fairness.vld'>Model fairness validation</h2><span id='topic+fairness.vld'></span>

<h3>Description</h3>

<p><code>fairness.vld</code> performs fairness validation for a given sensitive attribute and selected outcome.
Sensitive attribute should be categorical variable with reasonable number of modalities, while
outcome can be categorical (e.g. reject/accept indicator or rating grade) or continuous (e.g. interest rate or amount).
Depending on model type outcome (see argument <code>mod.outcome.type</code>) Chi-square test or Wald test is applied.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fairness.vld(
  db,
  sensitive,
  obs.outcome,
  mod.outcome,
  conditional = NULL,
  mod.outcome.type,
  p.value
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fairness.vld_+3A_db">db</code></td>
<td>
<p>Data frame with sensitive attribute, observed outcome, model outcome and conditional attribute.</p>
</td></tr>
<tr><td><code id="fairness.vld_+3A_sensitive">sensitive</code></td>
<td>
<p>Name of sensitive attribute within <code>db</code>.</p>
</td></tr>
<tr><td><code id="fairness.vld_+3A_obs.outcome">obs.outcome</code></td>
<td>
<p>Name of observed outcome within <code>db</code>.</p>
</td></tr>
<tr><td><code id="fairness.vld_+3A_mod.outcome">mod.outcome</code></td>
<td>
<p>Name of model outcome within <code>db</code>.</p>
</td></tr>
<tr><td><code id="fairness.vld_+3A_conditional">conditional</code></td>
<td>
<p>Name of conditional attribute within <code>db</code>. It is used for calculation of conditional
statistical parity. Default value is <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="fairness.vld_+3A_mod.outcome.type">mod.outcome.type</code></td>
<td>
<p>Type of model outcome. Possible values are <code>disc</code> (discrete outcome)
and <code>cont</code> (continuous).</p>
</td></tr>
<tr><td><code id="fairness.vld_+3A_p.value">p.value</code></td>
<td>
<p>Significance level of applied statistical test (chi-square or Wald test).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The command <code>fairness.vld</code> returns a list of three data frames.<br />
The first object (<code>SP</code>), provides results of statistical parity testing.<br />
The second object (<code>CSP</code>), provides results of conditional statistical parity testing.
This object will be returned only if conditional attributed is supplied. <br />
The third object (<code>EO</code>), provides results of equal opportunity testing.<br />
</p>


<h3>References</h3>

<p>Hurlin, Christophe and Perignon, Christophe and Saurin, Sebastien (2022),
The Fairness of Credit Scoring Models. HEC Paris Research Paper No. FIN-2021-1411
</p>


<h3>Examples</h3>

<pre><code class='language-R'>suppressMessages(library(PDtoolkit))
#build hypothetical model
data(loans)
#numeric risk factors
#num.rf &lt;- sapply(loans, is.numeric)
#num.rf &lt;- names(num.rf)[!names(num.rf)%in%"Creditability" &amp; num.rf]
num.rf &lt;- c("Credit Amount", "Age (years)")
#discretized numeric risk factors using ndr.bin from monobin package
loans[, num.rf] &lt;- sapply(num.rf, function(x) 
ndr.bin(x = loans[, x], y = loans[, "Creditability"])[[2]])
str(loans)
#run stepMIV
rf &lt;- c("Account Balance", "Payment Status of Previous Credit", 
       "Purpose", "Value Savings/Stocks", "Credit Amount",
       "Age (years)", "Instalment per cent", "Foreign Worker")
res &lt;- stepMIV(start.model = Creditability ~ 1, 
   miv.threshold = 0.02, 
   m.ch.p.val = 0.05,
   coding = "WoE",
   coding.start.model = FALSE,
   db = loans[, c("Creditability", rf)])
#print coefficients
summary(res$model)$coefficients

#prepare data frame for fairness validation
db.fa &lt;- data.frame(Creditability = loans$Creditability, 
		  mpred = predict(res$model, type = "response", newdata = res$dev.db))
#add hypothetical reject/accept indicator 
db.fa$rai &lt;- ifelse(db.fa$mpred &gt; 0.5, 1, 0)
#add hypothetical rating
db.fa$rating &lt;- sts.bin(x = round(db.fa$mpred, 4), y = db.fa$Creditability)[[2]]
#add hypothetical interest rate
ir.r &lt;- seq(0.03, 0.10, length.out = 6)
names(ir.r) &lt;- sort(unique(db.fa$rating))
db.fa$ir &lt;- ir.r[db.fa$rating]
#add hypothetical sensitive attribute
db.fa$sensitive.1 &lt;- ifelse(loans$"Sex &amp; Marital Status"%in%2, 1, 0) #not in a model
db.fa$sensitive.2 &lt;- ifelse(loans$"Age (years)"%in%"03 [35,Inf)", 1, 0) #in a model
#add some attributes for calculation of conditional statistical parity
db.fa$"Credit Amount" &lt;- loans$"Credit Amount" 
head(db.fa)

#discrete model outcome - sensitive attribute not in a model
fairness.vld(db = db.fa, 
	 sensitive = "sensitive.1", 
	 obs.outcome = "Creditability", 
	 mod.outcome = "rai",
	 conditional = "Credit Amount", 
	 mod.outcome.type = "disc", 
	 p.value = 0.05)
##discrete model outcome - sensitive attribute in a model
#fairness.vld(db = db.fa, 
#		 sensitive = "sensitive.2", 
#		 obs.outcome = "Creditability", 
#		 mod.outcome = "rai",
#		 conditional = "Credit Amount", 
#		 mod.outcome.type = "disc", 
#		 p.value = 0.05)
##continuous outcome - sensitive attribute not in a model
#fairness.vld(db = db.fa, 
#		 sensitive = "sensitive.1", 
#		 obs.outcome = "Creditability", 
#		 mod.outcome = "ir",
#		 conditional = "Credit Amount", 
#		 mod.outcome.type = "cont", 
#		 p.value = 0.05)
#continuous outcome - sensitive attribute in a model
fairness.vld(db = db.fa, 
	 sensitive = "sensitive.2", 
	 obs.outcome = "Creditability", 
	 mod.outcome = "ir",
	 conditional = "Credit Amount", 
	 mod.outcome.type = "cont", 
	 p.value = 0.05)
</code></pre>

<hr>
<h2 id='heterogeneity'>Testing heterogeneity of the PD rating model</h2><span id='topic+heterogeneity'></span>

<h3>Description</h3>

<p><code>heterogeneity</code> performs heterogeneity testing of PD model based on the rating grades.
This test is usually applied on application portfolio, but it can be applied also on model development sample.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>heterogeneity(app.port, def.ind, rating, alpha = 0.05)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="heterogeneity_+3A_app.port">app.port</code></td>
<td>
<p>Application portfolio (data frame) which contains default indicator (0/1) and
ratings in use.</p>
</td></tr>
<tr><td><code id="heterogeneity_+3A_def.ind">def.ind</code></td>
<td>
<p>Name of the column that represents observed default indicator (0/1).</p>
</td></tr>
<tr><td><code id="heterogeneity_+3A_rating">rating</code></td>
<td>
<p>Name of the column that represent rating grades in use.</p>
</td></tr>
<tr><td><code id="heterogeneity_+3A_alpha">alpha</code></td>
<td>
<p>Significance level of p-value for two proportion test. Default is 0.05.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Testing procedure starts with summarizing the number of observations and defaults per rating grade.
After that, two proportion test is applied on adjacent rating grades. Testing hypothesis is that
default rate of grade <code>i</code> is less or greater than default rate of grade <code>i - 1</code>, where <code>i</code>
takes the values from 2 to the number of unique grades.
Direction of alternative hypothesis (less or greater) is determined automatically based on correlation direction
of observed default on rating grades.
Incomplete cases, identified based on default indicator (<code>def.ind</code>) and rating grade (<code>rating </code>)
columns are excluded from the summary table and testing procedure. If identified, warning will be returned.
</p>


<h3>Value</h3>

<p>The command <code>heterogeneity</code> returns a data frame with the following columns:
</p>

<ul>
<li><p> rating: Unique values of rating grades from application portfolio.
</p>
</li>
<li><p> no: Number of complete observations.
</p>
</li>
<li><p> nb: Number of defaults (bad cases) in complete observations.
</p>
</li>
<li><p> p.val: Test p-value (two proportion test of adjacent rating grades).
</p>
</li>
<li><p> alpha: Selected significance level.
</p>
</li>
<li><p> res: Accepted hypothesis.
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>suppressMessages(library(PDtoolkit))
data(loans)
#estimate some dummy model
mod.frm &lt;- `Creditability` ~ `Account Balance` + `Duration of Credit (month)` +
				`Age (years)` + `Value Savings/Stocks`
lr.mod &lt;- glm(mod.frm, family = "binomial", data = loans)
summary(lr.mod)$coefficients
#model predictions
loans$pred &lt;-  unname(predict(lr.mod, type = "response", newdata = loans))
#scale probabilities
loans$score &lt;- scaled.score(probs = loans$pred, score = 600, odd = 50/1, pdo = 20)
#group scores into ratings
loans$rating.1 &lt;- sts.bin(x = round(loans$score), y = loans$Creditability, y.type = "bina")[[2]]
#group probabilities into ratings
loans$rating.2 &lt;- sts.bin(x = round(loans$pred, 4), y = loans$Creditability, y.type = "bina")[[2]]
#simulate dummy application portfolio 
set.seed(1984)
app.port &lt;- loans[sample(1:nrow(loans), 400, rep = TRUE), ]
#run heterogeneity test on ratings based on the scaled score
#higher score lower default rate
heterogeneity(app.port = app.port, 
	   def.ind = "Creditability", 
	   rating = "rating.1", 
	   alpha = 0.05)
#run test on predicted default rate - direction of the test is changed
heterogeneity(app.port = app.port, 
	   def.ind = "Creditability", 
	   rating = "rating.2", 
	   alpha = 0.05)
</code></pre>

<hr>
<h2 id='hhi'>Herfindahl-Hirschman Index (HHI)</h2><span id='topic+hhi'></span>

<h3>Description</h3>

<p><code>hhi</code> performs calculation on Herfindahl-Hirschman Index.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hhi(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="hhi_+3A_x">x</code></td>
<td>
<p>Numeric vector of input values (e.g. number of observations or sum of exposure per rating grade).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The command <code>hhinormal.test</code> returns single element numeric vector of HHI value.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#simulate PD model and rating scale
suppressMessages(library(PDtoolkit))
data(loans)
res &lt;- stepFWDr(start.model = Creditability ~ 1, 
   p.value = 0.05, 
   db = loans)
mod.predictions &lt;- unname(predict(res$model, type = "response"))
rating.scale &lt;- sts.bin(y = loans$Creditability, x = mod.predictions)[[1]]
#calculate HHI 
hhi(x = rating.scale$no)
</code></pre>

<hr>
<h2 id='homogeneity'>Testing homogeneity of the PD rating model</h2><span id='topic+homogeneity'></span>

<h3>Description</h3>

<p><code>homogeneity</code> performs homogeneity testing of PD model based on the rating grades and selected segment.
This test is usually applied on application portfolio, but it can be applied also on model development sample.
Additionally, this method requires higher number of observations per segment modalities within each rating in order
to produce available results. For segments with less than 30 observations, test is not performed.
If as a segment user selects numeric variable from the application portfolio, variable will be grouped in selected number of
groups (argument <code>segment.num</code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>homogeneity(app.port, def.ind, rating, segment, segment.num, alpha = 0.05)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="homogeneity_+3A_app.port">app.port</code></td>
<td>
<p>Application portfolio (data frame) which contains default indicator (0/1),
ratings in use and variable used as a segment.</p>
</td></tr>
<tr><td><code id="homogeneity_+3A_def.ind">def.ind</code></td>
<td>
<p>Name of the column that represents observed default indicator (0/1).</p>
</td></tr>
<tr><td><code id="homogeneity_+3A_rating">rating</code></td>
<td>
<p>Name of the column that represent rating grades in use.</p>
</td></tr>
<tr><td><code id="homogeneity_+3A_segment">segment</code></td>
<td>
<p>Name of the column that represent testing segments. If it is of numeric type, than it is first grouped
into <code>segment.num</code> of groups otherwise is it used as supplied.</p>
</td></tr>
<tr><td><code id="homogeneity_+3A_segment.num">segment.num</code></td>
<td>
<p>Number of groups used for numeric variables supplied as a segment. Only applicable if <code>segment</code>
is of numeric type.</p>
</td></tr>
<tr><td><code id="homogeneity_+3A_alpha">alpha</code></td>
<td>
<p>Significance level of p-value for two proportion test. Default is 0.05.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Testing procedure is implemented for each rating separately comparing default rate from one segment modality to
the default rate from the rest of segment modalities.
</p>


<h3>Value</h3>

<p>The command <code>homogeneity</code> returns a data frame with the following columns:
</p>

<ul>
<li><p> segment.var: Variable used as a segment.
</p>
</li>
<li><p> rating: Unique values of rating grades from application portfolio..
</p>
</li>
<li><p> segment.mod: Tested segment modality. Default rate from this segment is compared with default rate from the
rest of the modalities within the each rating.
</p>
</li>
<li><p> no: Number of observations of the analyzed rating.
</p>
</li>
<li><p> nb: Number of defaults (bad cases) of the analyzed rating.
</p>
</li>
<li><p> no.segment: Number of observations of the analyzed segment modality.
</p>
</li>
<li><p> no.rest: Number of observations of the rest of the segment modalities.
</p>
</li>
<li><p> nb.segment: Number of defaults of the analyzed segment modality.
</p>
</li>
<li><p> nb.rest: Number of defaults of the rest of the segment modalities.
</p>
</li>
<li><p> p.val: Two proportion test (two sided) p-value.
</p>
</li>
<li><p> alpha: Selected significance level.
</p>
</li>
<li><p> res: Accepted hypothesis.
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>suppressMessages(library(PDtoolkit))
data(loans)
#estimate some dummy model
mod.frm &lt;- `Creditability` ~ `Account Balance` + `Duration of Credit (month)` +
				`Age (years)` + `Value Savings/Stocks` + 
				`Duration in Current address`
lr.mod &lt;- glm(mod.frm, family = "binomial", data = loans)
summary(lr.mod)$coefficients
#model predictions
loans$pred &lt;-  unname(predict(lr.mod, type = "response", newdata = loans))
#scale probabilities
loans$score &lt;- scaled.score(probs = loans$pred, score = 600, odd = 50/1, pdo = 20)
#group scores into ratings
loans$rating &lt;- ndr.bin(x = round(loans$score), y = loans$Creditability, y.type = "bina")[[2]]
#simulate dummy application portfolio (oversample loans data) 
set.seed(2211)
app.port &lt;- loans[sample(1:nrow(loans), 2500, rep = TRUE), ]
#run homogeneity test on ratings based on the Credit Amount segments
homogeneity(app.port = app.port, 
	def.ind = "Creditability", 
	rating = "rating", 
	segment = "Credit Amount",
	segment.num = 4, 
	alpha = 0.05)
</code></pre>

<hr>
<h2 id='imp.outliers'>Imputation methods for outliers</h2><span id='topic+imp.outliers'></span>

<h3>Description</h3>

<p><code>imp.outliers</code> replaces predefined quantum of the smallest and largest values by the less
extreme values. This procedure is applicable only to the numeric risk factors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>imp.outliers(
  db,
  sc = c(NA, NaN, Inf, -Inf),
  method = "iqr",
  range = 1.5,
  upper.pct = 0.95,
  lower.pct = 0.05
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="imp.outliers_+3A_db">db</code></td>
<td>
<p>Data frame of risk factors supplied for imputation.</p>
</td></tr>
<tr><td><code id="imp.outliers_+3A_sc">sc</code></td>
<td>
<p>Vector of all special case elements. Default values are <code>c(NA, NaN, Inf)</code>. Those values will be
excluded from calculation of imputed value and replacements.</p>
</td></tr>
<tr><td><code id="imp.outliers_+3A_method">method</code></td>
<td>
<p>Imputation method. Available options are: <code>"iqr"</code> and <code>"percentile"</code>. Method <code>iqr</code>
performs identification of outliers by the method applied in boxplot 5-figures, while for
<code>percentile</code> method user defines lower and upper limits for replacement.
Default value is <code>"iqr"</code>.</p>
</td></tr>
<tr><td><code id="imp.outliers_+3A_range">range</code></td>
<td>
<p>Determines how far the plot whiskers extend out from the box. If range is positive,
the whiskers extend to the most extreme data point which is no more than range times the
interquartile range from the box. A value of zero causes the whiskers to extend to
the data extremes. Default <code>range</code> is set to is 1.5.</p>
</td></tr>
<tr><td><code id="imp.outliers_+3A_upper.pct">upper.pct</code></td>
<td>
<p>Upper limit for percentile method. All values above this limit will be replaced by the value
identified at this percentile. Default value is set to <code class="reqn">95^{th}</code> percentile (0.95).
This parameter is used only if selected <code>method</code> is <code>percentile</code>.</p>
</td></tr>
<tr><td><code id="imp.outliers_+3A_lower.pct">lower.pct</code></td>
<td>
<p>Lower limit for percentile method. All values below this limit will be replaced by the value
identified at this percentile. Default value is set to <code class="reqn">5^{th}</code> percentile (0.05).
This parameter is used only if selected <code>method</code> is <code>percentile</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>This function returns list of two data frames. The first data frame contains analyzed risk factors with
imputed values for outliers, while the second data frame presents the imputation report. Using the imputation report,
for each risk factor, user can inspect imputed info (<code>info</code>), imputation method (<code>imputation.method</code>),
imputed value (<code>imputation.val.upper</code> and <code>imputation.val.lower</code>),
number of imputed observations (<code>imputation.num.upper</code> and <code>imputation.num.lower</code>).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>suppressMessages(library(PDtoolkit))
data(gcd)
gcd$age[1:20] &lt;- NA
gcd$age.bin &lt;- ndr.bin(x = gcd$age, y = gcd$qual, sc.method = "separately", y.type = "bina")[[2]]
gcd$dummy1 &lt;- NA
imput.res.1 &lt;- imp.outliers(db = gcd[, -1], 
		      method = "iqr",
		      range = 1.5)
#analyzed risk factors with imputed values
head(imput.res.1[[1]])
#imputation report
imput.res.1[[2]]
#percentile method
imput.res.2 &lt;- imp.outliers(db = gcd[, -1], 
		      method = "percentile",
		      upper.pct = 0.95,
		      lower.pct = 0.05)
#analyzed risk factors with imputed values
head(imput.res.2[[1]])
#imputation report
imput.res.2[[2]]
</code></pre>

<hr>
<h2 id='imp.sc'>Imputation methods for special cases</h2><span id='topic+imp.sc'></span>

<h3>Description</h3>

<p><code>imp.sc</code> imputes value for special cases.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>imp.sc(
  db,
  sc.all = c(NA, NaN, Inf, -Inf),
  sc.replace = c(NA, NaN, Inf, -Inf),
  method.num = "automatic",
  p.val = 0.05
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="imp.sc_+3A_db">db</code></td>
<td>
<p>Data frame of risk factors supplied for imputation.</p>
</td></tr>
<tr><td><code id="imp.sc_+3A_sc.all">sc.all</code></td>
<td>
<p>Vector of all special case elements. Default values are <code>c(NA, NaN, Inf)</code>.</p>
</td></tr>
<tr><td><code id="imp.sc_+3A_sc.replace">sc.replace</code></td>
<td>
<p>Vector of special case element to be replaced. Default values are <code>c(NA, NaN, Inf)</code>.</p>
</td></tr>
<tr><td><code id="imp.sc_+3A_method.num">method.num</code></td>
<td>
<p>Imputation method for numeric risk factors. Available options are: <br />
<code>"automatic", "mean", "median", "zero"</code>.</p>
</td></tr>
<tr><td><code id="imp.sc_+3A_p.val">p.val</code></td>
<td>
<p>Significance level of p-value for Pearson normality test. Applicable only if <code>method.num</code> is
<code>automatic</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>This function returns list of two data frames. The first data frame contains analyzed risk factors with
imputed values for special cases, while the second data frame presents the imputation report.
Using the imputation report, for each risk factor, user can inspect imputed info (<code>info</code>),
imputation method (<code>imputation.method</code>), imputed value (<code>imputed.value</code>),
number of imputed observations (<code>imputation.num</code>) and imputed mode
(<code>imputed.mode</code> - applicable only for categorical risk factors) for each risk factor.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>suppressMessages(library(PDtoolkit))
data(gcd)
gcd$age[1:20] &lt;- NA
gcd$age.bin &lt;- ndr.bin(x = gcd$age, y = gcd$qual, sc.method = "separately", y.type = "bina")[[2]]
gcd$dummy1 &lt;- NA
#select risk factors for which we want to impute missing values (NA)
db.imp &lt;- gcd[, c("age", "age.bin", "dummy1")]
colSums(is.na(db.imp))
imput.res &lt;- imp.sc(db = db.imp, 
	      method.num = "automatic",
	      p.val = 0.05)
#analyzed risk factors with imputed values
head(imput.res[[1]])
#imputation report
imput.res[[2]]
</code></pre>

<hr>
<h2 id='interaction.transformer'>Extract risk factors interaction from decision tree</h2><span id='topic+interaction.transformer'></span>

<h3>Description</h3>

<p><code>interaction.transformer</code> extracts the interaction between supplied risk factors from decision tree.
It implements customized decision tree algorithm that takes into account different conditions such as minimum
percentage of observations and defaults in each node, maximum tree depth and monotonicity condition
at each splitting node. Gini index is used as metric for node splitting .
</p>


<h3>Usage</h3>

<pre><code class='language-R'>interaction.transformer(
  db,
  rf,
  target,
  min.pct.obs,
  min.avg.rate,
  max.depth,
  monotonicity,
  create.interaction.rf
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="interaction.transformer_+3A_db">db</code></td>
<td>
<p>Data frame of risk factors and target variable supplied for interaction extraction.</p>
</td></tr>
<tr><td><code id="interaction.transformer_+3A_rf">rf</code></td>
<td>
<p>Character vector of risk factor names on which decision tree is run.</p>
</td></tr>
<tr><td><code id="interaction.transformer_+3A_target">target</code></td>
<td>
<p>Name of target variable (default indicator 0/1) within db argument.</p>
</td></tr>
<tr><td><code id="interaction.transformer_+3A_min.pct.obs">min.pct.obs</code></td>
<td>
<p>Minimum percentage of observation in each leaf.</p>
</td></tr>
<tr><td><code id="interaction.transformer_+3A_min.avg.rate">min.avg.rate</code></td>
<td>
<p>Minimum percentage of defaults in each leaf.</p>
</td></tr>
<tr><td><code id="interaction.transformer_+3A_max.depth">max.depth</code></td>
<td>
<p>Maximum number of splits.</p>
</td></tr>
<tr><td><code id="interaction.transformer_+3A_monotonicity">monotonicity</code></td>
<td>
<p>Logical indicator. If <code>TRUE</code>, observed trend between risk factor and target will be preserved
in splitting node.</p>
</td></tr>
<tr><td><code id="interaction.transformer_+3A_create.interaction.rf">create.interaction.rf</code></td>
<td>
<p>Logical indicator. If <code>TRUE</code>, second element of the output will be data frame with
interaction modalities.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The command <code>interaction.transformer</code> returns a list of two data frames. The first data frame provides
the tree summary. The second data frame is a new risk factor extracted from decision tree.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>suppressMessages(library(PDtoolkit))
data(loans)
#modify risk factors in order to show how the function works with missing values
loans$"Account Balance"[1:10] &lt;- NA
loans$"Duration of Credit (month)"[c(13, 15)] &lt;- NA
it &lt;- interaction.transformer(db = loans,
				 rf = c("Account Balance", "Duration of Credit (month)"), 
				 target = "Creditability",
				 min.pct.obs = 0.05,
				 min.avg.rate = 0.01,
				 max.depth = 2,
			 	 monotonicity = TRUE,
				 create.interaction.rf = TRUE)
names(it)
it[["tree.info"]]
tail(it[["interaction"]])
table(it[["interaction"]][, "rf.inter"], useNA = "always")
</code></pre>

<hr>
<h2 id='kfold.idx'>Indices for K-fold validation</h2><span id='topic+kfold.idx'></span>

<h3>Description</h3>

<p><code>kfold.idx</code> provides indices for K-fold validation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>kfold.idx(target, k = 10, type, seed = 2191)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="kfold.idx_+3A_target">target</code></td>
<td>
<p>Binary target variable.</p>
</td></tr>
<tr><td><code id="kfold.idx_+3A_k">k</code></td>
<td>
<p>Number of folds. If <code>k</code> is equal or greater than the number of observations of
target variable, then validation procedure is equivalent to leave one out cross-validation (LOOCV)
method. For stratified sampling, k is compared with frequencies of 0 and 1 from target.
Default is set to 10.</p>
</td></tr>
<tr><td><code id="kfold.idx_+3A_type">type</code></td>
<td>
<p>Sampling type. Possible options are <code>"random"</code> and <code>"stratified"</code>.</p>
</td></tr>
<tr><td><code id="kfold.idx_+3A_seed">seed</code></td>
<td>
<p>Random seed needed for ensuring the result reproducibility. Default is 2191.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The command <code>kfold.idx</code> returns a list of k folds estimation and validation indices.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>suppressMessages(library(PDtoolkit))
data(loans)
#good-bad ratio
prop.table(table(loans$Creditability))
#random k-folds
kf.r &lt;- kfold.idx(target = loans$Creditability, k = 5, type = "random", seed = 2191)
lapply(kf.r, function(x) prop.table(table(loans$Creditability[x[[2]]])))
#stratified k-folds
kf.s &lt;- kfold.idx(target = loans$Creditability, k = 5, type = "stratified", seed = 2191)
lapply(kf.s, function(x) prop.table(table(loans$Creditability[x[[2]]])))
</code></pre>

<hr>
<h2 id='kfold.vld'>K-fold model cross-validation</h2><span id='topic+kfold.vld'></span>

<h3>Description</h3>

<p><code>kfold.vld</code> performs k-fold model cross-validation.
The main goal of this procedure is to generate main model performance metrics such as absolute mean
square error, root mean square error or area under curve (AUC) based on resampling method.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>kfold.vld(model, k = 10, seed = 1984)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="kfold.vld_+3A_model">model</code></td>
<td>
<p>Model in use, an object of class inheriting from <code>"glm"</code></p>
</td></tr>
<tr><td><code id="kfold.vld_+3A_k">k</code></td>
<td>
<p>Number of folds. If <code>k</code> is equal or greater than the number of observations of
modeling data frame, then validation procedure is equivalent to leave one out cross-validation (LOOCV)
method. For LOOCV, AUC is not calculated. Default is set to 10.</p>
</td></tr>
<tr><td><code id="kfold.vld_+3A_seed">seed</code></td>
<td>
<p>Random seed needed for ensuring the result reproducibility. Default is 1984.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The command <code>kfold.vld</code> returns a list of two objects.<br />
The first object (<code>iter</code>), returns iteration performance metrics.<br />
The second object (<code>summary</code>), is the data frame of iterations averages of performance metrics.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>suppressMessages(library(PDtoolkit))
data(loans)
#run stepFWD
res &lt;- stepFWD(start.model = Creditability ~ 1, 
	   coding = "WoE",
	   db = loans)
#check output elements
names(res)
#extract the final model
final.model &lt;- res$model
#print coefficients
summary(final.model)$coefficients
#print head of coded development data
head(res$dev.db)
#calculate AUC
auc.model(predictions = predict(final.model, type = "response", newdata = res$dev.db),
    observed = res$dev.db$Creditability)
kfold.vld(model = final.model, k = 10, seed = 1984)
</code></pre>

<hr>
<h2 id='loans'>German Credit Data</h2><span id='topic+loans'></span>

<h3>Description</h3>

<p>The German Credit Data contains data on 20 variables and the classification whether
an applicant is considered a Good or a Bad credit risk for 1000 loan applicants.
Name of the columns are used as give in the source file.
Note that subset of those data is available also in 'monobin' package (gcd) and used for some examples in 'PDtoolkit' package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>loans
</code></pre>


<h3>Format</h3>

<p>An object of class <code>data.frame</code> with 1000 rows and 21 columns.
</p>


<h3>Source</h3>

<p><a href="https://online.stat.psu.edu/stat857/node/215/">https://online.stat.psu.edu/stat857/node/215/</a>
</p>

<hr>
<h2 id='normal.test'>Multi-period predictive power test</h2><span id='topic+normal.test'></span>

<h3>Description</h3>

<p><code>normal.test</code> performs multi-period testing of PD model predictive power. This procedure can be applied
on the level of the rating grade as well on the portfolio level.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>normal.test(pdc, odr, alpha = 0.05)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="normal.test_+3A_pdc">pdc</code></td>
<td>
<p>Numeric vector of calibrated probabilities of default (PD).</p>
</td></tr>
<tr><td><code id="normal.test_+3A_odr">odr</code></td>
<td>
<p>Numeric vector of observed default rates.</p>
</td></tr>
<tr><td><code id="normal.test_+3A_alpha">alpha</code></td>
<td>
<p>Significance level of p-value for implemented tests. Default is 0.05.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The command <code>normal.test</code> returns a data frame with estimated difference between <code>odr</code> and
<code>pdc</code>, test statistics, standard error of the test statistics, selected significance level,
p-value of test statistics and finally the test results.
</p>


<h3>References</h3>

<p>Basel Committee on Banking Supervision (2005). Studies on the Validation of Internal
Rating Systems, working paper no. 14.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(678)
normal.test(pdc = rep(0.02, 5), 
odr = runif(5, 0.02, 0.03)) 
</code></pre>

<hr>
<h2 id='num.slice'>Slice numeric variable</h2><span id='topic+num.slice'></span>

<h3>Description</h3>

<p><code>num.slice</code> implements manual discretization of numeric vector for a given boundaries. This procedure is one
of the helper functions which are handy for the model monitoring phase (i.e. after model implementation).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>num.slice(x, mapping, sc = c(NA, NaN, Inf, -Inf), sc.r = "SC")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="num.slice_+3A_x">x</code></td>
<td>
<p>Numeric vector to be discretized.</p>
</td></tr>
<tr><td><code id="num.slice_+3A_mapping">mapping</code></td>
<td>
<p>Data frame with compulsory columns: <code>x.min</code> and <code>x.max</code> which represent the discretized
boundaries.</p>
</td></tr>
<tr><td><code id="num.slice_+3A_sc">sc</code></td>
<td>
<p>Numeric vector with special case elements. Default values are <code>c(NA, NaN, Inf, -Inf)</code>.</p>
</td></tr>
<tr><td><code id="num.slice_+3A_sc.r">sc.r</code></td>
<td>
<p>Character vector used for replacement of special cases. If supplied as one
element vector, it will be recycled to the length of <code>sc</code>. Default value is <code>"SC"</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The command <code>num.slice</code> returns vector of discretized values and coded special cases.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>suppressMessages(library(PDtoolkit))
data(gcd)
x &lt;- gcd$maturity
#artificially add some special values
x[1:5] &lt;- Inf
x[6:7] &lt;- NA
#perform monotonic grouping in order to get bins' boundaries
mbin &lt;- sts.bin(x = x, y = gcd$qual, sc.method = "separately")
mbin[[1]]
#slice numeric variable
sn &lt;- num.slice(x = x, 
	      mapping = data.frame(x.min = mbin[[1]]$x.min[-c(1, 2)], 
					 x.max = mbin[[1]]$x.max[-c(1, 2)]), 
	      sc = c(NA, NaN, Inf, -Inf), 
	      sc.r = "SC")
#compare automatic and manual binning
table(mbin[[2]], useNA = "always")
table(sn, useNA = "always")
</code></pre>

<hr>
<h2 id='nzv'>Near-zero variance</h2><span id='topic+nzv'></span>

<h3>Description</h3>

<p><code>nzv</code> procedure aims to identify risk factors with low variability (almost constants). Usually these risk factors are
expertly investigated and decision is made if they should be excluded from further modeling process. <br />
<code>nzv</code> output report includes the following metrics:
</p>

<ul>
<li><p> rf: Risk factor name.
</p>
</li>
<li><p> rf.type: Risk factor class. This metric is always one of: <code>numeric</code> or <code>categorical</code>.
</p>
</li>
<li><p> sc.num: Number of special cases.
</p>
</li>
<li><p> sc.pct: Percentage of special cases in total number of observations.
</p>
</li>
<li><p> cc.num: Number of complete cases.
</p>
</li>
<li><p> cc.pct: Percentage of complete cases in total number of observations. Sum of this value and <code>sc.pct</code> is equal to 1.
</p>
</li>
<li><p> cc.unv: Number of unique values in complete cases.
</p>
</li>
<li><p> cc.unv.pct: Percentage of unique values in total number of complete cases.
</p>
</li>
<li><p> cc.lbl.1: The most frequent value in complete cases.
</p>
</li>
<li><p> cc.frq.1: Number of occurrence of the most frequent value in complete cases.
</p>
</li>
<li><p> cc.lbl.2: The second most frequent value in complete cases.
</p>
</li>
<li><p> cc.frq.2: Number of occurrence of the second most frequent value in complete cases.
</p>
</li>
<li><p> cc.fqr: Frequency ratio - the ratio between the occurrence of most frequent and the second most frequent value in
complete cases.
</p>
</li>
<li><p> ind: Indicator which takes value of <code>1</code> if the percentage of complete cases is less then 10% and frequency ratio
(<code>cc.fqr</code>) greater than 19. This values can be used for filtering risk factors that need further expert
investigation, but user are also encourage to derive its own indicators based on reported
metrics.
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>nzv(db, sc = c(NA, NaN, Inf, -Inf))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="nzv_+3A_db">db</code></td>
<td>
<p>Data frame of risk factors supplied for near-zero variance analysis.</p>
</td></tr>
<tr><td><code id="nzv_+3A_sc">sc</code></td>
<td>
<p>Numeric or character vector with special case elements. Default values are <code>c(NA, NaN, Inf, -Inf)</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The command <code>nzv</code> returns the data frame with different matrices needed for identification of near-zero variables.
For details see Description section.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>suppressMessages(library(PDtoolkit))
data(loans)
#artificially add some special values
loans$"Account Balance"[1:10] &lt;- NA
rf.s &lt;- nzv(db = loans, sc = c(NA, NaN, Inf, -Inf))
rf.s
</code></pre>

<hr>
<h2 id='power'>Power of statistical tests for predictive ability testing</h2><span id='topic+power'></span>

<h3>Description</h3>

<p><code>power</code> performs Monte Carlo simulation of power of statistical test used for testing the predictive
ability of the PD rating model. It covers fours tests: the binomial, Jeffreys, z-score and Hosmer-Lemeshow test.
This procedure is applied under assumption that the observed default rate is the true one and it is
used to check if calibrated PDs are underestimated for the binomial, Jeffreys, and z-score.
Therefore, for the cases where observed default rate is lower than the calibrated PD, the power calculation is not performed and will report the comment.
For the Hosmer-Lemeshow test is used to test if the calibrated PD is the true one regardless the difference between the observed and calibrated
portfolio default rate.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>power(rating.label, pdc, no, nb, alpha = 0.05, sim.num = 1000, seed = 2211)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="power_+3A_rating.label">rating.label</code></td>
<td>
<p>Vector of rating labels.</p>
</td></tr>
<tr><td><code id="power_+3A_pdc">pdc</code></td>
<td>
<p>Vector of calibrated probabilities of default (PD).</p>
</td></tr>
<tr><td><code id="power_+3A_no">no</code></td>
<td>
<p>Number of observations per rating grade.</p>
</td></tr>
<tr><td><code id="power_+3A_nb">nb</code></td>
<td>
<p>Number of defaults (bad cases) per rating grade.</p>
</td></tr>
<tr><td><code id="power_+3A_alpha">alpha</code></td>
<td>
<p>Significance level of p-value for implemented tests. Default is 0.05.</p>
</td></tr>
<tr><td><code id="power_+3A_sim.num">sim.num</code></td>
<td>
<p>Number of Monte Carlo simulations. Default is 1000.</p>
</td></tr>
<tr><td><code id="power_+3A_seed">seed</code></td>
<td>
<p>Random seed needed for ensuring the result reproducibility. Default is 2211.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Due to the fact that test of predictive power is usually implemented on the application portfolio,
certain prerequisites are needed to be fulfilled. In the first place model should be developed
and rating scale should be formed. In order to reflect appropriate role and right moment of
tests application, presented simplified example covers all steps before test implementation.
</p>


<h3>Value</h3>

<p>The command <code>power</code> returns a list with two objects. Both are the data frames and
while the first one presents power calculation of the tests applied usually on the
rating level (binomial, Jeffreys and z-score test), the second one presents results of
the Hosmer-Lemeshow test which is applied on the complete rating scale.
For both level of the implementation (rating or complete scale) if the observed default
rate is less than calibrated PD, function will return the comment and power simulation
will not be performed.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>suppressMessages(library(PDtoolkit))
data(loans)
#estimate some dummy model
mod.frm &lt;- `Creditability` ~ `Account Balance` + `Duration of Credit (month)` +
				`Age (years)`
lr.mod &lt;- glm(mod.frm, family = "binomial", data = loans)
summary(lr.mod)$coefficients
#model predictions
loans$pred &lt;-  unname(predict(lr.mod, type = "response", newdata = loans))
#scale probabilities
loans$score &lt;- scaled.score(probs = loans$pred, score = 600, odd = 50/1, pdo = 20)
#group scores into rating
loans$rating &lt;- sts.bin(x = round(loans$score), y = loans$Creditability, y.type = "bina")[[2]]
#create rating scale
rs &lt;- loans %&gt;%
group_by(rating) %&gt;%
summarise(no = n(),
	    nb = sum(Creditability),
	    ng = sum(1 - Creditability)) %&gt;%
mutate(dr = nb / no)
rs
#calcualte portfolio default rate
sum(rs$dr * rs$no / sum(rs$no))
#calibrate rating scale to central tendency of 27% with minimum PD of 5%
ct &lt;- 0.27
min.pd &lt;- 0.05
rs$pd &lt;- rs.calibration(rs = rs, 
			dr = "dr", 
			w = "no", 
			ct = ct, 
			min.pd = min.pd,
			method = "log.odds.ab")[[1]]
#check
rs
sum(rs$pd * rs$no / sum(rs$no))
#simulate some dummy application portfolio
set.seed(22)
app.port &lt;- loans[sample(1:nrow(loans), 400), ]
#summarise application portfolio on rating level
ap.summary &lt;- app.port %&gt;%
	  group_by(rating) %&gt;%
	  summarise(no = n(),
			nb = sum(Creditability),
			ng = sum(1 - Creditability)) %&gt;%
	  mutate(dr = nb / no)
#bring calibrated pd as a based for predictive power testing
ap.summary &lt;- merge(rs[, c("rating", "pd")], ap.summary, by = "rating", all.x = TRUE)
ap.summary
#perform predictive power testing
pp.res &lt;- pp.testing(rating.label = ap.summary$rating,
		     pdc = ap.summary$pd,
		     no = ap.summary$no,
		     nb = ap.summary$nb, 
		     alpha = 0.05)
pp.res
power(rating.label = ap.summary$rating,
  pdc = ap.summary$pd,
  no = ap.summary$no,
  nb = ap.summary$nb, 
  alpha = 0.05,
  sim.num = 1000,
  seed = 2211)
</code></pre>

<hr>
<h2 id='pp.testing'>Testing the predictive power of PD rating model</h2><span id='topic+pp.testing'></span>

<h3>Description</h3>

<p><code>pp.testing</code> performs testing of predictive power of the PD rating model. This procedure should be applied
on the level of the rating scale.
Four tests are implemented: the binomial, Jeffreys, z-score and Hosmer-Lemeshow test.
Only the Hosmer-Lemeshow test refers to complete rating scale, while the remaining three are implemented on the
rating grade level. The null hypothesis for the binomial, Jeffreys, and z-score tests is that the observed default rate
<code class="reqn">\frac{n_b}{n_o}</code> is less or equal to the calibrated PD (<code>pdc</code>) while for the Hosmer-Lemeshow test is that
the calibrated PD (<code>pdc</code>) is the true one.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pp.testing(rating.label, pdc, no, nb, alpha = 0.05)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pp.testing_+3A_rating.label">rating.label</code></td>
<td>
<p>Vector of rating labels.</p>
</td></tr>
<tr><td><code id="pp.testing_+3A_pdc">pdc</code></td>
<td>
<p>Vector of calibrated probabilities of default (PD).</p>
</td></tr>
<tr><td><code id="pp.testing_+3A_no">no</code></td>
<td>
<p>Number of observations per rating grade.</p>
</td></tr>
<tr><td><code id="pp.testing_+3A_nb">nb</code></td>
<td>
<p>Number of defaults (bad cases) per rating grade.</p>
</td></tr>
<tr><td><code id="pp.testing_+3A_alpha">alpha</code></td>
<td>
<p>Significance level of p-value for implemented tests. Default is 0.05.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Due to the fact that test of predictive power is usually implemented on the application portfolio,
certain prerequisites are needed to be fulfilled. In the first place model should be developed
and rating scale should be formed. In order to reflect appropriate role and right moment of
tests application, presented simplified example covers all steps before test implementation.
</p>


<h3>Value</h3>

<p>The command <code>pp.testing</code> returns a data frame with input parameters along with
p-value for each implemented test and the accepted hypothesis. Due to the fact that
Hosmer-Lemeshow test is applied to complete rating scale, returned p-values are all equal between
the rating grades as well as the test results.
</p>


<h3>References</h3>

<p>Tasche, D. (2008). Validation of internal rating systems and PD estimates,
The Analytics of Risk Model Validation, Quantitative Finance,
Elsevier B.V., .<br />
Oesterreichische Nationalbank (2004). Rating Models and Validation,
Oesterreichische Nationalbank (OeNB).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>suppressMessages(library(PDtoolkit))
data(loans)
#estimate some dummy model
mod.frm &lt;- `Creditability` ~ `Account Balance` + `Duration of Credit (month)` +
				`Age (years)`
lr.mod &lt;- glm(mod.frm, family = "binomial", data = loans)
summary(lr.mod)$coefficients
#model predictions
loans$pred &lt;-  unname(predict(lr.mod, type = "response", newdata = loans))
#scale probabilities
loans$score &lt;- scaled.score(probs = loans$pred, score = 600, odd = 50/1, pdo = 20)
#group scores into rating
loans$rating &lt;- sts.bin(x = round(loans$score), y = loans$Creditability, y.type = "bina")[[2]]
#create rating scale
rs &lt;- loans %&gt;%
group_by(rating) %&gt;%
summarise(no = n(),
	    nb = sum(Creditability),
	    ng = sum(1 - Creditability)) %&gt;%
mutate(dr = nb / no)
rs
#calcualte portfolio default rate
sum(rs$dr * rs$no / sum(rs$no))
#calibrate rating scale to central tendency of 27% with minimum PD of 5%
ct &lt;- 0.33
min.pd &lt;- 0.05
rs$pd &lt;- rs.calibration(rs = rs, 
			dr = "dr", 
			w = "no", 
			ct = ct, 
			min.pd = min.pd,
			method = "log.odds.ab")[[1]]
#checks
rs
sum(rs$pd * rs$no / sum(rs$no))
#simulate some dummy application portfolio
set.seed(11)
app.port &lt;- loans[sample(1:nrow(loans), 400), ]
#summarise application portfolio on rating level
ap.summary &lt;- app.port %&gt;%
	  group_by(rating) %&gt;%
	  summarise(no = n(),
			nb = sum(Creditability),
			ng = sum(1 - Creditability)) %&gt;%
	  mutate(dr = nb / no)
#bring calibrated pd as a based for predictive power testing
ap.summary &lt;- merge(rs[, c("rating", "pd")], ap.summary, by = "rating", all.x = TRUE)
ap.summary
#perform predictive power testing
pp.res &lt;- pp.testing(rating.label = ap.summary$rating,
		     pdc = ap.summary$pd,
		     no = ap.summary$no,
		     nb = ap.summary$nb, 
		     alpha = 0.05)
pp.res
</code></pre>

<hr>
<h2 id='predict.cdt'>Predict method for custom decision tree</h2><span id='topic+predict.cdt'></span>

<h3>Description</h3>

<p>Predict method for custom decision tree
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'cdt'
predict(object, newdata = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.cdt_+3A_object">object</code></td>
<td>
<p>Custom decision tree model (class cdt).</p>
</td></tr>
<tr><td><code id="predict.cdt_+3A_newdata">newdata</code></td>
<td>
<p>Optionally, a data frame in which to look for variables with which to predict.
If omitted, the fitted predictors are used.</p>
</td></tr>
<tr><td><code id="predict.cdt_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns average default rate per leaf.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#S3 method for class "cdt"
suppressMessages(library(PDtoolkit))
data(loans)
tree.res &lt;- decision.tree(db = loans,
	rf = c("Account Balance", "Duration of Credit (month)"), 
	target = "Creditability",
	min.pct.obs = 0.05,
	min.avg.rate = 0.01,
	p.value = 0.05,
	max.depth = NA,
	monotonicity = TRUE)
str(tree.res)
#predict method - development sample
pred.1 &lt;- predict(object = tree.res, newdata = NULL)
head(pred.1)
auc.model(predictions = pred.1$average, observed = loans$Creditability)
#predict method - new data
set.seed(321)
loans.m &lt;- loans[sample(1:nrow(loans), 500, replace = TRUE), ]
pred.2 &lt;- predict(object = tree.res, newdata = loans.m)
head(pred.2)
auc.model(predictions = pred.2$average, observed = loans.m$Creditability)
</code></pre>

<hr>
<h2 id='psi'>Population Stability Index (PSI)</h2><span id='topic+psi'></span>

<h3>Description</h3>

<p><code>psi</code> calculates Population Stability Index (PSI) for a given base and target vectors. Function can be used for
testing the stability of final model score, but also for testing a risk factor stability (aka Characteristic Stability Index).
Function also provides so-called critical values of z-score (based on normal distribution assumption) and chi-square
(based on Chi-square distribution) that can be used as alternatives for fixed &quot;rule of thumb&quot; thresholds
(10% and 25%). For details see the Reference.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>psi(base, target, bin = 10, alpha = 0.05)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="psi_+3A_base">base</code></td>
<td>
<p>Vector of value from base sample. Usually this is training (model development) sample.</p>
</td></tr>
<tr><td><code id="psi_+3A_target">target</code></td>
<td>
<p>Vector of value from target sample. Usually this is testing or portfolio application sample.</p>
</td></tr>
<tr><td><code id="psi_+3A_bin">bin</code></td>
<td>
<p>Number of bins. Applied only for numeric base and target and used for discretization of its values. Default is 10.</p>
</td></tr>
<tr><td><code id="psi_+3A_alpha">alpha</code></td>
<td>
<p>Significance level used for calculation of statistical critical values
(<code>cv.zscore</code> and <code>cv.chisq</code>). Default is 0.05, which refers to 0.95 confidence interval.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The command <code>psi</code> returns a list of two data frames. The first data frame contains values of
PSI along with statistical critical values for confidence level of <code>1 - alpha</code>, while second data frame
presents summary table used for the calculation of overall PSI. For numeric base and target vectors, summary
table is presented on the bin (bucket level), while for the categorical modalities of base and target vectors
are tabulated.
</p>


<h3>References</h3>

<p>Yurdakul, B. (2018). Statistical Properties of Population Stability Index . Dissertations. 3208.
downloaded from <a href="https://scholarworks.wmich.edu/dissertations/3208/">here</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>suppressMessages(library(PDtoolkit))
data(loans)
#split on training and testing data set
set.seed(1122)
tt.indx &lt;- sample(1:nrow(loans), 700, replace = FALSE)
training &lt;- loans[tt.indx, ]
testing &lt;- loans[-tt.indx, ]
#calculate psi for numeric risk factor
psi(base = training[, "Age (years)"], target = testing[, "Age (years)"], 
   bin = 10, alpha = 0.05)
#calculate psi for categorical risk factor
psi(base = training[, "Account Balance"], target = testing[, "Account Balance"], 
   bin = 10, alpha = 0.05)
</code></pre>

<hr>
<h2 id='replace.woe'>Replace modalities of risk factor with weights of evidence (WoE) value</h2><span id='topic+replace.woe'></span>

<h3>Description</h3>

<p><code>replace.woe</code> replaces modalities of risk factor with calculated WoE value. This function process only
categorical risk factors, thus it is assumed that numerical risk factors are previously categorized.
Additional info report (second element of function output - <code>info</code> data frame), if produced, includes:
</p>

<ul>
<li><p> rf: Risk factor name.
</p>
</li>
<li><p> reason.code: Reason code takes value 1 if inappropriate class of risk factor is identified.
It takes value 2 if maximum number of categories exceeds 10, while 3 if
there are any problem with weights of evidence (WoE) calculations
(usually if any bin contains only good or bad cases).
If validation 1 and 3 are observed, risk factor is not process for WoE replacement.
</p>
</li>
<li><p> comment: Reason description.
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>replace.woe(db, target)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="replace.woe_+3A_db">db</code></td>
<td>
<p>Data frame of categorical risk factors and target variable supplied for WoE coding.</p>
</td></tr>
<tr><td><code id="replace.woe_+3A_target">target</code></td>
<td>
<p>Name of target variable within <code>db</code> argument..</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The command <code>replace.woe</code> returns the list of two data frames. The first one contains WoE replacement
of analyzed risk factors' modalities, while the second data frame reports results of above
mentioned validations regarding class of the risk factors, number of modalities and WoE calculation.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>suppressMessages(library(PDtoolkit))
data(gcd)
#categorize numeric risk factor
gcd$maturity.bin &lt;- ndr.bin(x = gcd$maturity, y = gcd$qual, y.type = "bina")[[2]]
gcd$amount.bin &lt;- ndr.bin(x = gcd$amount, y = gcd$qual, y.type = "bina")[[2]]
gcd$age.bin &lt;- ndr.bin(x = gcd$age, y = gcd$qual, y.type = "bina")[[2]]
head(gcd)
#replace modalities with WoE values
woe.rep &lt;- replace.woe(db = gcd, target = "qual")
#results overview
head(woe.rep[[1]])
woe.rep[[2]]
</code></pre>

<hr>
<h2 id='rf.clustering'>Risk factor clustering</h2><span id='topic+rf.clustering'></span>

<h3>Description</h3>

<p><code>rf.clustering</code> implements correlation based clustering of risk factors.
Clustering procedure is base on <a href="stats.html#topic+hclust">hclust</a> from <code>stats</code> package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rf.clustering(db, metric, k = NA)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rf.clustering_+3A_db">db</code></td>
<td>
<p>Data frame of risk factors supplied for clustering analysis.</p>
</td></tr>
<tr><td><code id="rf.clustering_+3A_metric">metric</code></td>
<td>
<p>Correlation metric used for distance calculation. Available options are:
</p>

<ul>
<li> <p><code>"raw pearson"</code> - calculated distance <code>as.dist(1 - cor(db, method = "pearson"))</code>;
</p>
</li>
<li> <p><code>"raw spearman"</code> - calculated distance <code>as.dist(1 - cor(db, method = "spearman"))</code>;
</p>
</li>
<li> <p><code>"common pearson"</code> - calculated distance <code>as.dist((1 - cor(db, method = "pearson")) / 2)</code>;
</p>
</li>
<li> <p><code>"common spearman"</code> - calculated distance <code>as.dist((1 - cor(db, method = "spearman")) / 2)</code>;
</p>
</li>
<li> <p><code>"absolute pearson"</code> - calculated distance <code>as.dist(1 - abs(cor(db, method = "pearson")))</code>;
</p>
</li>
<li> <p><code>"absolute spearman"</code> - calculated distance <code>as.dist(1 - abs(cor(db, method = "spearman")))</code>;
</p>
</li>
<li> <p><code>"sqrt pearson"</code> - calculated distance <code>as.dist(sqrt(1 - cor(db, method = "pearson")))</code>;
</p>
</li>
<li> <p><code>"sqrt spearman"</code> - calculated distance <code>as.dist(sqrt(1 - cor(db, method = "spearman")))</code>;
</p>
</li>
<li> <p><code>"x2y"</code> - calculated distance <code>as.dist(1 - dx2y(d = db)[[2]]))</code>.
</p>
</li></ul>

<p><code>x2y</code> metric is proposed by Professor Rama Ramakrishnan and details can be found on this
<a href="https://rviews.rstudio.com/2021/04/15/an-alternative-to-the-correlation-coefficient-that-works-for-numeric-and-categorical-variables/">link</a>.
This metric is especially handy if analyst wants to perform clustering before any binning procedures and to decrease number of risk factors. Additionally,
<code>x2y</code> algorithm process numerical and categorical risk factors at once and it is able to identify
non-linear relationship between the pairs. Metric <code>x2y</code> is not symmetric with respect to inputs - <code>x, y</code>,
therefore arithmetic average of values between <code>xy</code> and <code>yx</code> is used to produce the final value for each pair.</p>
</td></tr>
<tr><td><code id="rf.clustering_+3A_k">k</code></td>
<td>
<p>Number of clusters. If default value (<code>NA</code>) is passed, then automatic elbow method
will be used to determine the optimal number of clusters, otherwise selected number of clusters will be used.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function <code>rf.clustering</code> returns a data frame with: risk factors, clusters assigned and
distance to centroid (ordered from smallest to largest).
The last column (distance to centroid) can be used for selection of one or more risk factors per
cluster.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>suppressMessages(library(PDtoolkit))
library(rpart)
data(loans)
#clustering using common spearman metric
#first we need to categorize numeric risk factors
num.rf &lt;- sapply(loans, is.numeric)
num.rf &lt;- names(num.rf)[!names(num.rf)%in%"Creditability" &amp; num.rf]
loans[, num.rf] &lt;- sapply(num.rf, function(x) 
			  sts.bin(x = loans[, x], y = loans[, "Creditability"])[[2]])
#replace woe in order to convert to all numeric factors 
loans.woe &lt;- replace.woe(db = loans, target = "Creditability")[[1]]
cr &lt;- rf.clustering(db = loans.woe[, -which(names(loans.woe)%in%"Creditability")], 
		  metric = "common spearman", 
		  k = NA)
cr
#select one risk factor per cluster with min distance to centorid
cr %&gt;% group_by(clusters) %&gt;% 
 slice(which.min(dist.to.centroid))
</code></pre>

<hr>
<h2 id='rf.interaction.transformer'>Extract interactions from random forest</h2><span id='topic+rf.interaction.transformer'></span>

<h3>Description</h3>

<p><code>rf.interaction.transformer</code> extracts the interactions from random forest.
It implements customized random forest algorithm that takes into account different conditions (for single decision tree) such as minimum
percentage of observations and defaults in each node, maximum tree depth and monotonicity condition
at each splitting node. Gini index is used as metric for node splitting .
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rf.interaction.transformer(
  db,
  rf,
  target,
  num.rf = NA,
  num.tree,
  min.pct.obs,
  min.avg.rate,
  max.depth,
  monotonicity,
  create.interaction.rf,
  seed = 991
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rf.interaction.transformer_+3A_db">db</code></td>
<td>
<p>Data frame of risk factors and target variable supplied for interaction extraction.</p>
</td></tr>
<tr><td><code id="rf.interaction.transformer_+3A_rf">rf</code></td>
<td>
<p>Character vector of risk factor names on which decision tree is run.</p>
</td></tr>
<tr><td><code id="rf.interaction.transformer_+3A_target">target</code></td>
<td>
<p>Name of target variable (default indicator 0/1) within db argument.</p>
</td></tr>
<tr><td><code id="rf.interaction.transformer_+3A_num.rf">num.rf</code></td>
<td>
<p>Number of risk factors randomly selected for each decision tree. If default value (<code>NA</code>) is supplied,
then number of risk factors will be calculated as <code>sqrt(number of all supplied risk factors)</code>.</p>
</td></tr>
<tr><td><code id="rf.interaction.transformer_+3A_num.tree">num.tree</code></td>
<td>
<p>Number of decision trees used for random forest.</p>
</td></tr>
<tr><td><code id="rf.interaction.transformer_+3A_min.pct.obs">min.pct.obs</code></td>
<td>
<p>Minimum percentage of observation in each leaf.</p>
</td></tr>
<tr><td><code id="rf.interaction.transformer_+3A_min.avg.rate">min.avg.rate</code></td>
<td>
<p>Minimum percentage of defaults in each leaf.</p>
</td></tr>
<tr><td><code id="rf.interaction.transformer_+3A_max.depth">max.depth</code></td>
<td>
<p>Maximum number of splits.</p>
</td></tr>
<tr><td><code id="rf.interaction.transformer_+3A_monotonicity">monotonicity</code></td>
<td>
<p>Logical indicator. If <code>TRUE</code>, observed trend between risk factor and target will be preserved
in splitting node.</p>
</td></tr>
<tr><td><code id="rf.interaction.transformer_+3A_create.interaction.rf">create.interaction.rf</code></td>
<td>
<p>Logical indicator. If <code>TRUE</code>, second element of the output will be data frame with
interaction modalities.</p>
</td></tr>
<tr><td><code id="rf.interaction.transformer_+3A_seed">seed</code></td>
<td>
<p>Random seed to ensure result reproducibility.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The command <code>rf.interaction.transformer</code> returns a list of two data frames. The first data frame provides
the trees summary. The second data frame is a new risk factor extracted from random forest.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#modify risk factors in order to show how the function works with missing values
loans$"Account Balance"[1:10] &lt;- NA
loans$"Duration of Credit (month)"[c(13, 15)] &lt;- NA
rf.it &lt;- rf.interaction.transformer(db = loans, 
			     rf = names(loans)[!names(loans)%in%"Creditability"], 
			     target = "Creditability",
			     num.rf = NA, 
			     num.tree = 3,
			     min.pct.obs = 0.05,
			     min.avg.rate = 0.01,
			     max.depth = 2,
			     monotonicity = TRUE,
			     create.interaction.rf = TRUE,
			     seed = 579)
names(rf.it)
rf.it[["tree.info"]]
tail(rf.it[["interaction"]])
table(rf.it[["interaction"]][, 1], useNA = "always")
</code></pre>

<hr>
<h2 id='rs.calibration'>Calibration of the rating scale</h2><span id='topic+rs.calibration'></span>

<h3>Description</h3>

<p><code>rs.calibration</code> performs calibration of the observed default rates for a given rating scale.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rs.calibration(rs, dr, w, ct, min.pd, method)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rs.calibration_+3A_rs">rs</code></td>
<td>
<p>Rating scale that contain observed default rate and weights used for optimization.</p>
</td></tr>
<tr><td><code id="rs.calibration_+3A_dr">dr</code></td>
<td>
<p>Observed default rate per rating.</p>
</td></tr>
<tr><td><code id="rs.calibration_+3A_w">w</code></td>
<td>
<p>Weights, usually number of observations (clients/accounts) per rating.</p>
</td></tr>
<tr><td><code id="rs.calibration_+3A_ct">ct</code></td>
<td>
<p>Value of central tendency to which calibration is performed.</p>
</td></tr>
<tr><td><code id="rs.calibration_+3A_min.pd">min.pd</code></td>
<td>
<p>Minimum probability of default (PD) per rating, as constrain for calibration process.</p>
</td></tr>
<tr><td><code id="rs.calibration_+3A_method">method</code></td>
<td>
<p>Calibration method. Available options are <code>"scaling", "log.odds.a", "log.odds.ab"</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Method <code>"scaling"</code> relies on linear rescaling of observed default rate. Rescaling factor is
calculated as a ratio between <code>ct</code> and observed portfolio default rate.
Method <code>"log.odds.a"</code> optimize intercept of logit transformation in a way that makes portfolio default
rate equal to selected central tendency (<code>ct</code>).
Method <code>"log.odds.ab"</code> optimize intercept and slope of logit transformation in a way that makes
portfolio default rate equal to selected central tendency (<code>ct</code>).
For respecting selected constrain of minimum PD (<code>min.pd</code>), two-stage iterative procedure is implemented.
Additional constrain of maximum PD (100%) is also implemented.
</p>


<h3>Value</h3>

<p>The command <code>rs.calibration</code> returns a list of two elements. The first element is
vector of calibrated PDs and the second one is dataframe of optimization parameters.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>suppressMessages(library(PDtoolkit))
data(loans)
#estimate some dummy model
mod.frm &lt;- `Creditability` ~ `Account Balance` + `Duration of Credit (month)` +
			`Age (years)`
lr.mod &lt;- glm(mod.frm, family = "binomial", data = loans)
summary(lr.mod)$coefficients
#model predictions
loans$pred &lt;-  unname(predict(lr.mod, type = "response", newdata = loans))
#scale probabilities
loans$score &lt;- scaled.score(probs = loans$pred, score = 600, odd = 50/1, pdo = 20)
#group scores into rating
loans$rating &lt;- sts.bin(x = round(loans$score), y = loans$Creditability, y.type = "bina")[[2]]
#create rating scale
rs &lt;- loans %&gt;%
group_by(rating) %&gt;%
summarise(no = n(),
    nb = sum(Creditability),
    ng = sum(1 - Creditability)) %&gt;%
mutate(dr = nb / no)
rs
#calcualte portfolio default rate
sum(rs$dr * rs$no / sum(rs$no))
#calibrate rating scale to central tendency of 27% with minimum PD of 5%
ct &lt;- 0.33
min.pd &lt;- 0.05
#scaling
pd.calib.s &lt;- rs.calibration(rs = rs, 
			     dr = "dr", 
			     w = "no", 
			     ct = ct, 
			     min.pd = min.pd,
			     method = "scaling")
rs$pd.scaling &lt;- pd.calib.s[[1]]
#log-odds a
pd.calib.a &lt;- rs.calibration(rs = rs, 
			     dr = "dr", 
		 	     w = "no", 
			     ct = ct, 
			     min.pd = min.pd,
			     method = "log.odds.a")
rs$pd.log.a &lt;- pd.calib.a[[1]]
#log-odds ab
pd.calib.ab &lt;- rs.calibration(rs = rs, 
			      dr = "dr", 
		 	      w = "no", 
			      ct = ct, 
			      min.pd = min.pd,
			      method = "log.odds.ab")
rs$pd.log.ab &lt;- pd.calib.ab[[1]]
#checks
rs
sum(rs$pd.scaling * rs$no / sum(rs$no))
sum(rs$pd.log.a * rs$no / sum(rs$no))
sum(rs$pd.log.ab * rs$no / sum(rs$no))
</code></pre>

<hr>
<h2 id='scaled.score'>Scaling the probabilities</h2><span id='topic+scaled.score'></span>

<h3>Description</h3>

<p><code>scaled.score</code> performs scaling of the probabilities for a certain set up. User has to select
three parameters (<code>score, odd, pdo</code>), while the probabilities (<code>probs</code>) are usually
predictions of the final model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>scaled.score(probs, score = 600, odd = 50/1, pdo = 20)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="scaled.score_+3A_probs">probs</code></td>
<td>
<p>Model predicted probabilities of default.</p>
</td></tr>
<tr><td><code id="scaled.score_+3A_score">score</code></td>
<td>
<p>Specific score for selected odd (for argument <code>odd</code>). Default is 600.</p>
</td></tr>
<tr><td><code id="scaled.score_+3A_odd">odd</code></td>
<td>
<p>Odd (good/bad) at specific score (for argument <code>score</code>). Default is 50/1.</p>
</td></tr>
<tr><td><code id="scaled.score_+3A_pdo">pdo</code></td>
<td>
<p>Points for double the odds. Default is 20.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The command <code>scaled.score</code> returns a vector of scaled scores.
</p>


<h3>References</h3>

<p>Siddiqi, N. (2012). Credit Risk Scorecards: Developing and Implementing Intelligent Credit Scoring,
John Wiley &amp; Sons, Inc.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>suppressMessages(library(PDtoolkit))
data(loans)
#run stepFWD
res &lt;- stepFWD(start.model = Creditability ~ 1, 
                p.value = 0.05, 
	   coding = "WoE",
	   db = loans)
final.model &lt;- res$model
summary(final.model)$coefficients
#overview of development data base
head(res$dev.db)
#predict probabilities using the final model
loans$probs &lt;- predict(final.model, type = "response", newdata = res$dev.db)
#scale probabilities to scores
loans$score &lt;- scaled.score(probs = loans$probs, score = 600, odd = 50/1, pdo = 20)
#check AUC of probabilities and score
auc.model(predictions = loans$probs, observed = loans$Creditability)
auc.model(predictions = loans$score, observed = ifelse(loans$Creditability == 0, 1, 0))
#note that higher score indicates lower probability of default
</code></pre>

<hr>
<h2 id='segment.vld'>Model segment validation</h2><span id='topic+segment.vld'></span>

<h3>Description</h3>

<p><code>segment.vld</code> performs model segment validation based on residuals.
The main goal of this procedure is to identify segments where model in use overestimates or
underestimates the observed default rate. The procedure consists of a few steps. The first step is to
calculate the model residuals (observed default indicator minus estimated probability).
Then, on obtained residuals, the regression tree is fitted for segment identification.
Finally, one proportion test is applied in order to test overestimation or underestimation
of the observed default rate within these segments. Results of this validation can indicate
omission of some important risk factor(s) or some specific sub-portfolio for which model performs
worse than for the rest of the portfolio.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>segment.vld(model, db, min.leaf = 0.03, alpha = 0.05)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="segment.vld_+3A_model">model</code></td>
<td>
<p>Model in use, an object of class inheriting from <code>"glm"</code></p>
</td></tr>
<tr><td><code id="segment.vld_+3A_db">db</code></td>
<td>
<p>Modeling data with risk factors and target variable. Risk factors used for <code>model</code> development
have to be of the same type (if WoE coding is used it has to be numeric with WoE values).
Additionally, the rest of the risk factors (these that are supplied in <code>db</code>, but not used
for <code>model</code> development) will be used for segment validation.</p>
</td></tr>
<tr><td><code id="segment.vld_+3A_min.leaf">min.leaf</code></td>
<td>
<p>Minimum percentage of observations per leaf. Default is 0.03.</p>
</td></tr>
<tr><td><code id="segment.vld_+3A_alpha">alpha</code></td>
<td>
<p>Significance level of p-value for one proportion test. Default is 0.05.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The command <code>segment.vld</code> returns a list of three objects.<br />
The first object (<code>segment.model</code>), returns regression tree results (<code>rpart</code> object).<br />
The second object (<code>segment.testing</code>), is the data frame with segment overview and testing results.<br />
The third object (<code>segment.rules</code>), is the data frame with average residual
rate and rules for segment identification. This elements is returned, only if the segments are
identified, otherwise it is<code>NULL</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>suppressMessages(library(PDtoolkit))
library(rpart)
data(loans)
#run stepMIV
res &lt;- stepFWD(start.model = Creditability ~ 1, 
              p.value = 0.05,
	   coding = "WoE",
	   db = loans)
#check output elements
names(res)
#extract the final model
final.model &lt;- res$model
#print coefficients
summary(final.model)$coefficients
#run segment validation procedure
seg.analysis &lt;- segment.vld(model = final.model, 
				db = res$dev.db,
				min.leaf = 0.03,
				alpha = 0.05)
#check output elements
names(seg.analysis)
#print segment model - regression tree
seg.analysis$segment.model
#print segment summary and statistical testing
seg.analysis$segment.testing
#print segment identification rules
seg.analysis$segment.rules
</code></pre>

<hr>
<h2 id='smote'>Synthetic Minority Oversampling Technique (SMOTE)</h2><span id='topic+smote'></span>

<h3>Description</h3>

<p><code>smote</code> performs type of data augmentation for the selected (usually minority). In order to process continuous and
categorical risk factors simultaneously, Heterogeneity Euclidean Overlapping Metric (HEOM) is used in nearest neighbors
algorithm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>smote(
  db,
  target,
  minority.class,
  osr,
  ordinal.rf = NULL,
  num.rf.const = NULL,
  k = 5,
  seed = 81000
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="smote_+3A_db">db</code></td>
<td>
<p>Data set of risk factors and target variable.</p>
</td></tr>
<tr><td><code id="smote_+3A_target">target</code></td>
<td>
<p>Name of target variable within <code>db</code> argument.</p>
</td></tr>
<tr><td><code id="smote_+3A_minority.class">minority.class</code></td>
<td>
<p>Value of minority class. It can be numeric or character value, but it has to exist in target variable.</p>
</td></tr>
<tr><td><code id="smote_+3A_osr">osr</code></td>
<td>
<p>Oversampling rate. It has to be numeric value greater than 0 (for example 0.2 for 20% oversampling).</p>
</td></tr>
<tr><td><code id="smote_+3A_ordinal.rf">ordinal.rf</code></td>
<td>
<p>Character vector of ordinal risk factors. Default value is <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="smote_+3A_num.rf.const">num.rf.const</code></td>
<td>
<p>Data frame with constrains for numeric risk factors. It has to contain the following columns:
<code>rf</code>(numeric risk factor names from <code>db</code>),
<code>lower</code> (lower bound of numeric risk factor),
<code>upper</code> (upper bound of numeric risk factor),
<code>type</code> (type of numeric risk factor - <code>"numeric"</code> or <code>"integer"</code>).
Constrains are used for correction of synthetic data for selected numeric risk factors.
Default value is <code>NULL</code> which means that no corrections are assumed.</p>
</td></tr>
<tr><td><code id="smote_+3A_k">k</code></td>
<td>
<p>Number of nearest neighbors. Default value is 5.</p>
</td></tr>
<tr><td><code id="smote_+3A_seed">seed</code></td>
<td>
<p>Random seed needed for ensuring the result reproducibility. Default is 81000.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The command <code>smote</code> returns a data frame with added synthetic observations for selected minority class.
The data frame contains all variables from <code>db</code> data frame plus additional variable (<code>smote</code>) that serves as
indicator for distinguishing between original and synthetic observations.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>suppressMessages(library(PDtoolkit))
data(loans)
#check numeric variables (note that one of variables is target not a risk factor)
names(loans)[sapply(loans, is.numeric)]
#define constains of numeric risk factors
num.rf.const &lt;- data.frame(rf = c("Duration of Credit (month)", "Credit Amount", "Age (years)"),
			   lower = c(4, 250, 19),
			   upper = c(72, 20000, 75),
			   type = c("integer", "numeric", "integer"))
num.rf.const

#loans$"Account Balance"[990:1000] &lt;- NA
#loans$"Credit Amount"[900:920] &lt;- NA

loans.s &lt;- smote(db = loans,
	     target = "Creditability",
	     minority.class = 1,  
	     osr = 0.05,
	     ordinal.rf = NULL, 
	     num.rf.const = num.rf.const, 
	     k = 5, 
	     seed = 81000)
str(loans.s)
table(loans.s$Creditability, loans.s$smote)
#select minority class
loans.mc &lt;- loans.s[loans.s$Creditability%in%1, ]
head(loans.mc)
</code></pre>

<hr>
<h2 id='staged.blocks'>Staged blocks regression</h2><span id='topic+staged.blocks'></span>

<h3>Description</h3>

<p><code>staged.blocks</code> performs blockwise regression where the predictions of each blocks' model is used as an
offset for the model of the following block.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>staged.blocks(
  method,
  target,
  db,
  coding = "WoE",
  blocks,
  p.value = 0.05,
  miv.threshold = 0.02,
  m.ch.p.val = 0.05
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="staged.blocks_+3A_method">method</code></td>
<td>
<p>Regression method applied on each block.
Available methods: <code>"stepMIV"</code>, <code>"stepFWD"</code>, <code>"stepRPC"</code>, <code>"stepFWDr"</code>, and <code>"stepRPCr"</code>.</p>
</td></tr>
<tr><td><code id="staged.blocks_+3A_target">target</code></td>
<td>
<p>Name of target variable within <code>db</code> argument.</p>
</td></tr>
<tr><td><code id="staged.blocks_+3A_db">db</code></td>
<td>
<p>Modeling data with risk factors and target variable.</p>
</td></tr>
<tr><td><code id="staged.blocks_+3A_coding">coding</code></td>
<td>
<p>Type of risk factor coding within the model. Available options are: <code>"WoE"</code> and
<code>"dummy"</code>. If <code>"WoE"</code> is selected, then modalities of the risk factors are replaced
by WoE values, while for <code>"dummy"</code> option dummies (0/1) will be created for <code>n-1</code>
modalities where <code>n</code> is total number of modalities of analyzed risk factor.</p>
</td></tr>
<tr><td><code id="staged.blocks_+3A_blocks">blocks</code></td>
<td>
<p>Data frame with defined risk factor groups. It has to contain the following columns: <code>rf</code> and
<code>block</code>.</p>
</td></tr>
<tr><td><code id="staged.blocks_+3A_p.value">p.value</code></td>
<td>
<p>Significance level of p-value for the estimated coefficient. For <code>WoE</code> coding this value is
is directly compared to p-value of the estimated coefficient, while for <code>dummy</code> coding
multiple Wald test is employed and its p-value is used for comparison with selected threshold (<code>p.value</code>).
This argument is applicable only for <code>"stepFWD"</code> and <code>"stepRPC"</code> selected methods.</p>
</td></tr>
<tr><td><code id="staged.blocks_+3A_miv.threshold">miv.threshold</code></td>
<td>
<p>MIV (marginal information value) entrance threshold applicable only for code&quot;stepMIV&quot; method.
Only the risk factors with MIV higher than the threshold are candidate for the new model.
Additional criteria is that MIV value should significantly separate
good from bad cases measured by marginal chi-square test.</p>
</td></tr>
<tr><td><code id="staged.blocks_+3A_m.ch.p.val">m.ch.p.val</code></td>
<td>
<p>Significance level of p-value for marginal chi-square test applicable only for code&quot;stepMIV&quot; method.
This test additionally supports MIV value of candidate risk factor for final decision.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The command <code>staged.blocks</code> returns a list of three objects.<br />
The first object (<code>model</code>) is the list of the models of each block (an object of class inheriting from <code>"glm"</code>).<br />
The second object (<code>steps</code>), is the data frame with risk factors selected from the each block.<br />
The third object (<code>dev.db</code>), returns the list of block's model development databases.<br />
</p>


<h3>References</h3>

<p>Anderson, R.A. (2021). Credit Intelligence &amp; Modelling, Many Paths through the Forest of Credit Rating and Scoring,
OUP Oxford
</p>


<h3>See Also</h3>

<p><code><a href="#topic+embedded.blocks">embedded.blocks</a></code>, <code><a href="#topic+ensemble.blocks">ensemble.blocks</a></code>, <code><a href="#topic+stepMIV">stepMIV</a></code>, <code><a href="#topic+stepFWD">stepFWD</a></code>,
<code><a href="#topic+stepRPC">stepRPC</a></code>, <code><a href="#topic+stepFWDr">stepFWDr</a></code> and <code><a href="#topic+stepRPCr">stepRPCr</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>suppressMessages(library(PDtoolkit))
data(loans)
#create risk factor priority groups
rf.all &lt;- names(loans)[-1]
set.seed(22)
blocks &lt;- data.frame(rf = rf.all, block = sample(1:3, length(rf.all), rep = TRUE))
blocks &lt;- blocks[order(blocks$block), ]
blocks
#method: stepFWDr
res &lt;- staged.blocks(method = "stepFWDr", 
		   target = "Creditability",
		   db = loans,  
		   blocks = blocks)
names(res)
nb &lt;- length(res[["models"]])
res$models[[nb]]
auc.model(predictions = predict(res$models[[nb]], type = "response", 
				  newdata = res$dev.db[[nb]]),
    observed = res$dev.db[[nb]]$Creditability)

identical(unname(predict(res$models[[1]], type = "link", newdata = res$dev.db[[1]])),
    res$dev.db[[2]]$offset.vals)
identical(unname(predict(res$models[[2]], type = "link", newdata = res$dev.db[[2]])),
    res$dev.db[[3]]$offset.vals)
</code></pre>

<hr>
<h2 id='stepFWD'>Customized stepwise regression with p-value and trend check</h2><span id='topic+stepFWD'></span>

<h3>Description</h3>

<p><code>stepFWD</code> customized stepwise regression with p-value and trend check. Trend check is performed
comparing observed trend between target and analyzed risk factor and trend of the estimated coefficients within the
logistic regression. Note that procedure checks the column names of supplied <code>db</code> data frame therefore some
renaming (replacement of special characters) is possible to happen. For details check help example.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>stepFWD(
  start.model,
  p.value = 0.05,
  coding = "WoE",
  coding.start.model = TRUE,
  check.start.model = TRUE,
  db,
  offset.vals = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="stepFWD_+3A_start.model">start.model</code></td>
<td>
<p>Formula class that represents starting model. It can include some risk factors, but it can be
defined only with intercept (<code>y ~ 1</code> where <code>y</code> is target variable).</p>
</td></tr>
<tr><td><code id="stepFWD_+3A_p.value">p.value</code></td>
<td>
<p>Significance level of p-value of the estimated coefficients. For <code>WoE</code> coding this value is
is directly compared to the p-value of the estimated coefficients, while for <code>dummy</code> coding
multiple Wald test is employed and its p-value is used for comparison with selected threshold (<code>p.value</code>).</p>
</td></tr>
<tr><td><code id="stepFWD_+3A_coding">coding</code></td>
<td>
<p>Type of risk factor coding within the model. Available options are: <code>"WoE"</code> (default) and
<code>"dummy"</code>. If <code>"WoE"</code> is selected, then modalities of the risk factors are replaced
by WoE values, while for <code>"dummy"</code> option dummies (0/1) will be created for <code>n-1</code>
modalities where <code>n</code> is total number of modalities of analyzed risk factor.</p>
</td></tr>
<tr><td><code id="stepFWD_+3A_coding.start.model">coding.start.model</code></td>
<td>
<p>Logical (<code>TRUE</code> or <code>FALSE</code>), if the risk factors from the starting model should be WoE coded.
It will have an impact only for WoE coding option. Default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="stepFWD_+3A_check.start.model">check.start.model</code></td>
<td>
<p>Logical (<code>TRUE</code> or <code>FALSE</code>), if risk factors from the starting model should be
checked for p-value and trend in stepwise process. Default is <code>TRUE</code>.
If <code>FALSE</code> is selected, then <code>coding.start.model</code> is forced to <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="stepFWD_+3A_db">db</code></td>
<td>
<p>Modeling data with risk factors and target variable. All risk factors (apart from the risk factors from the starting model)
should be categorized and as of character type.</p>
</td></tr>
<tr><td><code id="stepFWD_+3A_offset.vals">offset.vals</code></td>
<td>
<p>This can be used to specify an a priori known component to be included in the linear predictor during fitting.
This should be <code>NULL</code> or a numeric vector of length equal to the number of cases. Default is <code>NULL</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The command <code>stepFWD</code> returns a list of four objects.<br />
The first object (<code>model</code>), is the final model, an object of class inheriting from <code>"glm"</code>.<br />
The second object (<code>steps</code>), is the data frame with risk factors selected at each iteration.<br />
The third object (<code>warnings</code>), is the data frame with warnings if any observed.
The warnings refer to the following checks: if risk factor has more than 10 modalities,
if any of the bins (groups) has less than 5% of observations and
if there are problems with WoE calculations.<br />
The final, fourth, object <code>dev.db</code> returns the model development database.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>suppressMessages(library(PDtoolkit))
data(loans)
#identify numeric risk factors
num.rf &lt;- sapply(loans, is.numeric)
num.rf &lt;- names(num.rf)[!names(num.rf)%in%"Creditability" &amp; num.rf]
#discretized numeric risk factors using ndr.bin from monobin package
loans[, num.rf] &lt;- sapply(num.rf, function(x) 
ndr.bin(x = loans[, x], y = loans[, "Creditability"])[[2]])
str(loans)
res &lt;- stepFWD(start.model = Creditability ~ 1, 
	   p.value = 0.05, 
	   coding = "dummy",
	   db = loans)
summary(res$model)$coefficients
rf.check &lt;- tapply(res$dev.db$Creditability, 
		 res$dev.db$Instalment_per_cent, 
		 mean)
rf.check
diff(rf.check)
res$steps
head(res$dev.db)
</code></pre>

<hr>
<h2 id='stepFWDr'>Customized stepwise regression with p-value and trend check on raw risk factors</h2><span id='topic+stepFWDr'></span>

<h3>Description</h3>

<p><code>stepFWDr</code> customized stepwise regression with p-value and trend check on raw risk factors. Trend check is performed
comparing observed trend between target and analyzed risk factor and trend of the estimated coefficients within the
binomial logistic regression. Difference between <code>stepFWDr</code> and <code><a href="#topic+stepFWD">stepFWD</a></code> is that this function
run stepwise regression on mixed risk factor types (numerical and/or categorical), while  <code><a href="#topic+stepFWD">stepFWD</a></code> accepts only categorical risk factors.
Note that procedure checks the column names of supplied <code>db</code> data frame therefore some
renaming (replacement of special characters) is possible to happen. For details check help example.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>stepFWDr(
  start.model,
  p.value = 0.05,
  db,
  check.start.model = TRUE,
  offset.vals = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="stepFWDr_+3A_start.model">start.model</code></td>
<td>
<p>Formula class that represents starting model. It can include some risk factors, but it can be
defined only with intercept (<code>y ~ 1</code> where <code>y</code> is target variable).</p>
</td></tr>
<tr><td><code id="stepFWDr_+3A_p.value">p.value</code></td>
<td>
<p>Significance level of p-value of the estimated coefficients. For numerical risk factors this value is
is directly compared to the p-value of the estimated coefficients, while for categorical risk factors
multiple Wald test is employed and its p-value is used for comparison with selected threshold (<code>p.value</code>).</p>
</td></tr>
<tr><td><code id="stepFWDr_+3A_db">db</code></td>
<td>
<p>Modeling data with risk factors and target variable. Risk factors can be categorized or continuous.</p>
</td></tr>
<tr><td><code id="stepFWDr_+3A_check.start.model">check.start.model</code></td>
<td>
<p>Logical (<code>TRUE</code> or <code>FALSE</code>), if risk factors from the starting model should be
checked for p-value and trend in stepwise process. Default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="stepFWDr_+3A_offset.vals">offset.vals</code></td>
<td>
<p>This can be used to specify an a priori known component to be included in the linear predictor during fitting.
This should be <code>NULL</code> or a numeric vector of length equal to the number of cases. Default is <code>NULL</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The command <code>stepFWDr</code> returns a list of four objects.<br />
The first object (<code>model</code>), is the final model, an object of class inheriting from <code>"glm"</code>.<br />
The second object (<code>steps</code>), is the data frame with risk factors selected at each iteration.<br />
The third object (<code>warnings</code>), is the data frame with warnings if any observed.
The warnings refer to the following checks: if any categorical risk factor has more than 10 modalities or
if any of the bins (groups) has less than 5% of observations.<br />
The final, fourth, object <code>dev.db</code> returns the model development database.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>suppressMessages(library(PDtoolkit))
data(loans)
trf &lt;- c("Creditability", "Account Balance", "Duration of Credit (month)",
        "Age (years)", "Guarantors", "Concurrent Credits")
res &lt;- stepFWDr(start.model = Creditability ~ 1, 
               p.value = 0.05, 
            db = loans[, trf],
               check.start.model = TRUE, 
               offset.vals = NULL)
summary(res$model)$coefficients
rf.check &lt;- tapply(res$dev.db$Creditability, 
		 res$dev.db$Guarantors, 
		 mean)
rf.check
diff(rf.check)
res$steps
head(res$dev.db)
</code></pre>

<hr>
<h2 id='stepMIV'>Stepwise logistic regression based on marginal information value (MIV)</h2><span id='topic+stepMIV'></span>

<h3>Description</h3>

<p><code>stepMIV</code> performs stepwise logistic regression based on MIV.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>stepMIV(
  start.model,
  miv.threshold,
  m.ch.p.val,
  coding,
  coding.start.model = FALSE,
  db,
  offset.vals = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="stepMIV_+3A_start.model">start.model</code></td>
<td>
<p>Formula class that represent starting model. It can include some risk factors, but it can be
defined only with intercept (<code>y ~ 1</code> where <code>y</code> is target variable).</p>
</td></tr>
<tr><td><code id="stepMIV_+3A_miv.threshold">miv.threshold</code></td>
<td>
<p>MIV entrance threshold. Only the risk factors with MIV higher than the threshold are candidate
for the new model. Additional criteria is that MIV value should significantly separate
good from bad cases measured by marginal chi-square test.</p>
</td></tr>
<tr><td><code id="stepMIV_+3A_m.ch.p.val">m.ch.p.val</code></td>
<td>
<p>Significance level of p-value for marginal chi-square test. This test additionally supports MIV value of
candidate risk factor for final decision.</p>
</td></tr>
<tr><td><code id="stepMIV_+3A_coding">coding</code></td>
<td>
<p>Type of risk factor coding within the model. Available options are: <code>"WoE"</code> and
<code>"dummy"</code>. If <code>"WoE"</code> is selected, then modalities of the risk factors are replaced
by WoE values, while for <code>"dummy"</code> option dummies (0/1) will be created for <code>n-1</code>
modalities where <code>n</code> is total number of modalities of analyzed risk factor.</p>
</td></tr>
<tr><td><code id="stepMIV_+3A_coding.start.model">coding.start.model</code></td>
<td>
<p>Logical (<code>TRUE</code> or <code>FALSE</code>), if risk factors from the starting model should be WoE coded.
It will have an impact only for WoE coding option. Default value is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="stepMIV_+3A_db">db</code></td>
<td>
<p>Modeling data with risk factors and target variable. All risk factors should be categorized as of
character type.</p>
</td></tr>
<tr><td><code id="stepMIV_+3A_offset.vals">offset.vals</code></td>
<td>
<p>This can be used to specify an a priori known component to be included in the linear predictor during fitting.
This should be <code>NULL</code> or a numeric vector of length equal to the number of cases. Default is <code>NULL</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The command <code>stepMIV</code> returns a list of five objects.<br />
The first object (<code>model</code>), is the final model, an object of class inheriting from <code>"glm"</code>.<br />
The second object (<code>steps</code>), is the data frame with risk factors selected at each iteration.<br />
The third object (<code>miv.iter</code>), is the data frame with iteration details.<br />
The fourth object (<code>warnings</code>), is the data frame with warnings if any observed.
The warnings refer to the following checks: if risk factor has more than 10 modalities,
if any of the bins (groups) has less than 5% of observations and
if there are problems with WoE calculations.<br />
The final, fifth, object <code>dev.db</code> object <code>dev.db</code> returns the model development database.
</p>


<h3>References</h3>

<p>Scallan, G. (2011). Class(ic) Scorecards: Selecting Characteristics and Attributes in Logistic Regression,
Edinburgh Credit Scoring Conference.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>suppressMessages(library(PDtoolkit))
data(loans)
##identify numeric risk factors
#num.rf &lt;- sapply(loans, is.numeric)
#num.rf &lt;- names(num.rf)[!names(num.rf)%in%"Creditability" &amp; num.rf]
##discretized numeric risk factors using ndr.bin from monobin package
#loans[, num.rf] &lt;- sapply(num.rf, function(x) 
#	ndr.bin(x = loans[, x], y = loans[, "Creditability"])[[2]])
#str(loans)
#run stepMIV
rf &lt;- c("Account Balance", "Payment Status of Previous Credit", "Purpose",
       "Value Savings/Stocks", "Most valuable available asset", "Foreign Worker")
res &lt;- stepMIV(start.model = Creditability ~ 1, 
	   miv.threshold = 0.02, 
	   m.ch.p.val = 0.05,
	   coding = "WoE",
	   coding.start.model = FALSE,
	   db = loans[, c("Creditability", rf)])
#check output elements
names(res)
#print model warnings
res$warnings
#extract the final model
final.model &lt;- res$model
#print coefficients
summary(final.model)$coefficients
#print steps of stepwise
res$steps
#print head of all iteration details
head(res$miv.iter)
#print warnings
res$warnings
#print head of coded development data
head(res$dev.db)
#calculate AUC
auc.model(predictions = predict(final.model, type = "response", newdata = res$dev.db),
    observed = res$dev.db$Creditability)
</code></pre>

<hr>
<h2 id='stepRPC'>Stepwise logistic regression based on risk profile concept</h2><span id='topic+stepRPC'></span>

<h3>Description</h3>

<p><code>stepRPC</code> customized stepwise regression with p-value and trend check which additionally takes into account
the order of supplied risk factors per group when selects a candidate for the final regression model. Trend check is performed
comparing observed trend between target and analyzed risk factor and trend of the estimated coefficients within the
logistic regression. Note that procedure checks the column names of supplied <code>db</code> data frame therefore some
renaming (replacement of special characters) is possible to happen. For details, please, check the help example.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>stepRPC(
  start.model,
  risk.profile,
  p.value = 0.05,
  coding = "WoE",
  coding.start.model = TRUE,
  check.start.model = TRUE,
  db,
  offset.vals = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="stepRPC_+3A_start.model">start.model</code></td>
<td>
<p>Formula class that represents the starting model. It can include some risk factors, but it can be
defined only with intercept (<code>y ~ 1</code> where <code>y</code> is target variable).</p>
</td></tr>
<tr><td><code id="stepRPC_+3A_risk.profile">risk.profile</code></td>
<td>
<p>Data frame with defined risk profile. It has to contain the following columns: <code>rf</code> and
<code>group</code>. Column <code>group</code> defines order of groups that will be tested first as a candidate
for the regression model. Risk factors selected in each group are kept as a starting variables
for the next group testing. Column <code>rf</code> contains all candidate risk factors supplied for testing.</p>
</td></tr>
<tr><td><code id="stepRPC_+3A_p.value">p.value</code></td>
<td>
<p>Significance level of p-value of the estimated coefficients. For <code>WoE</code> coding this value is
is directly compared to the p-value of the estimated coefficients, while for <code>dummy</code> coding
multiple Wald test is employed and its value is used for comparison with selected threshold (<code>p.value</code>).</p>
</td></tr>
<tr><td><code id="stepRPC_+3A_coding">coding</code></td>
<td>
<p>Type of risk factor coding within the model. Available options are: <code>"WoE"</code> and
<code>"dummy"</code>. If <code>"WoE"</code> is selected, then modalities of the risk factors are replaced
by WoE values, while for <code>"dummy"</code> option dummies (0/1) will be created for <code>n-1</code>
modalities where <code>n</code> is total number of modalities of analyzed risk factor.</p>
</td></tr>
<tr><td><code id="stepRPC_+3A_coding.start.model">coding.start.model</code></td>
<td>
<p>Logical (<code>TRUE</code> or <code>FALSE</code>), if the risk factors from the starting model should be WoE coded.
It will have an impact only for WoE coding option.</p>
</td></tr>
<tr><td><code id="stepRPC_+3A_check.start.model">check.start.model</code></td>
<td>
<p>Logical (<code>TRUE</code> or <code>FALSE</code>), if risk factors from the starting model should
checked for p-value and trend in stepwise process.</p>
</td></tr>
<tr><td><code id="stepRPC_+3A_db">db</code></td>
<td>
<p>Modeling data with risk factors and target variable. All risk factors (apart from the risk factors from the starting model)
should be categorized and as of character type.</p>
</td></tr>
<tr><td><code id="stepRPC_+3A_offset.vals">offset.vals</code></td>
<td>
<p>This can be used to specify an a priori known component to be included in the linear predictor during fitting.
This should be <code>NULL</code> or a numeric vector of length equal to the number of cases. Default is <code>NULL</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The command <code>stepRPC</code> returns a list of four objects.<br />
The first object (<code>model</code>), is the final model, an object of class inheriting from <code>"glm"</code>.<br />
The second object (<code>steps</code>), is the data frame with risk factors selected at each iteration.<br />
The third object (<code>warnings</code>), is the data frame with warnings if any observed.
The warnings refer to the following checks: if risk factor has more than 10 modalities,
if any of the bins (groups) has less than 5% of observations and
if there are problems with WoE calculations.<br />
The final, fourth, object <code>dev.db</code> returns the model development database.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>suppressMessages(library(PDtoolkit))
data(loans)
#identify numeric risk factors
num.rf &lt;- sapply(loans, is.numeric)
num.rf &lt;- names(num.rf)[!names(num.rf)%in%"Creditability" &amp; num.rf]
#discretized numeric risk factors using ndr.bin from monobin package
loans[, num.rf] &lt;- sapply(num.rf, function(x) 
ndr.bin(x = loans[, x], y = loans[, "Creditability"])[[2]])
str(loans)
#create risk factor priority groups
rf.all &lt;- names(loans)[-1]
set.seed(591)
rf.pg &lt;- data.frame(rf = rf.all, group = sample(1:3, length(rf.all), rep = TRUE))
head(rf.pg)
#bring AUC for each risk factor in order to sort them within groups
bva &lt;- bivariate(db = loans, target = "Creditability")[[1]]
rf.auc &lt;- unique(bva[, c("rf", "auc")])
rf.pg &lt;- merge(rf.pg, rf.auc, by = "rf", all.x = TRUE)
#prioritized risk factors
rf.pg &lt;- rf.pg[order(rf.pg$group, rf.pg$auc), ]
rf.pg &lt;- rf.pg[order(rf.pg$group), ]
rf.pg
res &lt;- stepRPC(start.model = Creditability ~ 1, 
	   risk.profile = rf.pg, 
	   p.value = 0.05, 
	   coding = "WoE",
	   db = loans)
summary(res$model)$coefficients
res$steps
head(res$dev.db)
</code></pre>

<hr>
<h2 id='stepRPCr'>Stepwise regression based on risk profile concept and raw risk factors</h2><span id='topic+stepRPCr'></span>

<h3>Description</h3>

<p><code>stepRPCr</code> customized stepwise regression with p-value and trend check on raw risk factors which additionally takes into account
the order of supplied risk factors per group when selects a candidate for the final regression model. Trend check is performed
comparing observed trend between target and analyzed risk factor and trend of the estimated coefficients.
Note that procedure checks the column names of supplied <code>db</code> data frame therefore some
renaming (replacement of special characters) is possible to happen. For details, please, check the help example.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>stepRPCr(
  start.model,
  risk.profile,
  p.value = 0.05,
  db,
  check.start.model = TRUE,
  offset.vals = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="stepRPCr_+3A_start.model">start.model</code></td>
<td>
<p>Formula class that represents the starting model. It can include some risk factors, but it can be
defined only with intercept (<code>y ~ 1</code> where <code>y</code> is target variable).</p>
</td></tr>
<tr><td><code id="stepRPCr_+3A_risk.profile">risk.profile</code></td>
<td>
<p>Data frame with defined risk profile. It has to contain the following columns: <code>rf</code> and
<code>group</code>. Column <code>group</code> defines order of groups that will be tested first as a candidate
for the regression model. Risk factors selected in each group are kept as a starting variables
for the next group testing. Column <code>rf</code> contains all candidate risk factors supplied for testing.</p>
</td></tr>
<tr><td><code id="stepRPCr_+3A_p.value">p.value</code></td>
<td>
<p>Significance level of p-value of the estimated coefficients. For numerical risk factors this value is
is directly compared to the p-value of the estimated coefficients, while for categorical risk factors
multiple Wald test is employed and its value is used for comparison with selected threshold (<code>p.value</code>).</p>
</td></tr>
<tr><td><code id="stepRPCr_+3A_db">db</code></td>
<td>
<p>Modeling data with risk factors and target variable. All risk factors (apart from the risk factors from the starting model)
should be categorized and as of character type.</p>
</td></tr>
<tr><td><code id="stepRPCr_+3A_check.start.model">check.start.model</code></td>
<td>
<p>Logical (<code>TRUE</code> or <code>FALSE</code>), if risk factors from the starting model should
checked for p-value and trend in stepwise process.</p>
</td></tr>
<tr><td><code id="stepRPCr_+3A_offset.vals">offset.vals</code></td>
<td>
<p>This can be used to specify an a priori known component to be included in the linear predictor during fitting.
This should be <code>NULL</code> or a numeric vector of length equal to the number of cases. Default is <code>NULL</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The command <code>stepRPCr</code> returns a list of four objects.<br />
The first object (<code>model</code>), is the final model, an object of class inheriting from <code>"glm"</code>.<br />
The second object (<code>steps</code>), is the data frame with risk factors selected at each iteration.<br />
The third object (<code>warnings</code>), is the data frame with warnings if any observed.
The warnings refer to the following checks: if risk factor has more than 10 modalities or
if any of the bins (groups) has less than 5% of observations.<br />
The final, fourth, object <code>dev.db</code> returns the model development database.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>suppressMessages(library(PDtoolkit))
data(loans)
#create risk factor priority groups
rf.all &lt;- names(loans)[-1]
set.seed(6422)
rf.pg &lt;- data.frame(rf = rf.all, group = sample(1:3, length(rf.all), rep = TRUE))
rf.pg &lt;- rf.pg[order(rf.pg$group), ]
head(rf.pg)
res &lt;- stepRPCr(start.model = Creditability ~ 1, 
               risk.profile = rf.pg, 
               p.value = 0.05, 
               db = loans)
summary(res$model)$coefficients
res$steps
head(res$dev.db)
</code></pre>

<hr>
<h2 id='univariate'>Univariate analysis</h2><span id='topic+univariate'></span>

<h3>Description</h3>

<p><code>univariate</code> returns the univariate statistics for risk factors supplied in data frame <code>db</code>. <br />
For numeric risk factors univariate report includes:
</p>

<ul>
<li><p> rf: Risk factor name.
</p>
</li>
<li><p> rf.type: Risk factor class. This metric is always equal to <code>numeric</code>.
</p>
</li>
<li><p> bin.type: Bin type - special or complete cases.
</p>
</li>
<li><p> bin: Bin type. If a <code>sc.method</code> argument is equal to <code>"together"</code>, then
<code>bin</code> and <code>bin.type</code> have the same value. If the <code>sc.method</code> argument
is equal to <code>"separately"</code>, then the <code>bin</code> will contain all special cases that
exist for analyzed risk factor (e.g. <code>NA</code>, <code>NaN</code>, <code>Inf</code>).
</p>
</li>
<li><p> pct: Percentage of observations in each <code>bin</code>.
</p>
</li>
<li><p> cnt.unique: Number of unique values per <code>bin</code>.
</p>
</li>
<li><p> min: Minimum value.
</p>
</li>
<li><p> p1, p5, p25, p50, p75, p95, p99: Percentile values.
</p>
</li>
<li><p> avg: Mean value.
</p>
</li>
<li><p> avg.se: Standard error of the mean.
</p>
</li>
<li><p> max: Maximum value.
</p>
</li>
<li><p> neg: Number of negative values.
</p>
</li>
<li><p> pos: Number of positive values.
</p>
</li>
<li><p> cnt.outliers: Number of outliers. Records above or below
<code>Q75</code><code class="reqn">\pm</code><code>1.5 * IQR</code>, where <code>IQR = Q75 - Q25</code>.
</p>
</li>
<li><p> sc.ind: Special case indicator. It takes value 1 if share of special cases exceeds
<code>sc.threshold</code> otherwise 0.
</p>
</li></ul>

<p>For categorical risk factors univariate report includes:
</p>

<ul>
<li><p> rf: Risk factor name.
</p>
</li>
<li><p> rf.type: Risk factor class. This metric is equal to one of: <code>character</code>,
<code>factor</code> or <code>logical</code>.
</p>
</li>
<li><p> bin.type: Bin type - special or complete cases.
</p>
</li>
<li><p> bin: Bin type. If a <code>sc.method</code> argument is equal to <code>"together"</code>, then
<code>bin</code> and <code>bin.type</code> have the same value. If the <code>sc.method</code> argument
is equal to <code>"separately"</code>, then the <code>bin</code> will contain all special cases that
exist for analyzed risk factor (e.g. <code>NA</code>, <code>NaN</code>, <code>Inf</code>).
</p>
</li>
<li><p> pct: Percentage of observations in each <code>bin</code>.
</p>
</li>
<li><p> cnt.unique: Number of unique values per <code>bin</code>.
</p>
</li>
<li><p> sc.ind: Special case indicator. It takes value 1 if share of special cases exceeds
<code>sc.threshold</code> otherwise 0.
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>univariate(
  db,
  sc = c(NA, NaN, Inf, -Inf),
  sc.method = "together",
  sc.threshold = 0.2
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="univariate_+3A_db">db</code></td>
<td>
<p>Data frame of risk factors supplied for univariate analysis.</p>
</td></tr>
<tr><td><code id="univariate_+3A_sc">sc</code></td>
<td>
<p>Vector of special case elements. Default values are <code>c(NA, NaN, Inf)</code>.</p>
</td></tr>
<tr><td><code id="univariate_+3A_sc.method">sc.method</code></td>
<td>
<p>Define how special cases will be treated, all together or in separate bins.
Possible values are <code>"together"</code>, <code>"separately"</code>.</p>
</td></tr>
<tr><td><code id="univariate_+3A_sc.threshold">sc.threshold</code></td>
<td>
<p>Threshold for special cases expressed as percentage of total number of observations.
If <code>sc.method</code> is set to <code>"separately"</code>, then percentage for each special case
will be summed up.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The command <code>univariate</code> returns the data frame with explained univariate metrics for numeric,
character, factor and logical class of risk factors.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>suppressMessages(library(PDtoolkit))
data(gcd)
gcd$age[100:120] &lt;- NA
gcd$age.bin &lt;- ndr.bin(x = gcd$age, y = gcd$qual, y.type = "bina")[[2]]
gcd$age.bin &lt;- as.factor(gcd$age.bin)
gcd$maturity.bin &lt;- ndr.bin(x = gcd$maturity, y = gcd$qual, y.type = "bina")[[2]]
gcd$amount.bin &lt;- ndr.bin(x = gcd$amount, y = gcd$qual, y.type = "bina")[[2]]
gcd$all.miss1 &lt;- NaN
gcd$all.miss2 &lt;- NA
gcd$tf &lt;- sample(c(TRUE, FALSE), nrow(gcd), rep = TRUE)
#create date variable to confirm that it will not be processed by the function
gcd$dates &lt;- Sys.Date()
str(gcd)
univariate(db = gcd)
</code></pre>

<hr>
<h2 id='ush.bin'>U-shape binning algorithm</h2><span id='topic+ush.bin'></span>

<h3>Description</h3>

<p><code>ush.bin</code> performs U-shape binning. All algorithms from <a href="https://CRAN.R-project.org/package=monobin">monobin</a>
package are available. Due to specific nature of
binning algorithms it is possible that for some selected knots algorithm will not be able to find U-shape. Therefore,
users are encourage to inspect the results more into details and to try different binning algorithms.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ush.bin(
  x,
  y,
  knot,
  method,
  sc = c(NA, Inf, -Inf, NaN),
  sc.method = "together",
  g = 20,
  min.pct.obs = 0.05,
  min.avg.rate = 0.01,
  p.val = 0.05,
  woe.trend = TRUE,
  woe.gap = 0.1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ush.bin_+3A_x">x</code></td>
<td>
<p>Numeric vector to be binned.</p>
</td></tr>
<tr><td><code id="ush.bin_+3A_y">y</code></td>
<td>
<p>Numeric target vector (binary).</p>
</td></tr>
<tr><td><code id="ush.bin_+3A_knot">knot</code></td>
<td>
<p>Numeric value of selected knot. Usually the results of <code><a href="#topic+ush.test">ush.test</a></code> function.</p>
</td></tr>
<tr><td><code id="ush.bin_+3A_method">method</code></td>
<td>
<p>Binning method. Available options are all from monobin package:
<code>"cum.bin", "iso.bin", "ndr.bin", "pct.bin", "sts.bin", "woe.bin", "mdt.bin"</code>.</p>
</td></tr>
<tr><td><code id="ush.bin_+3A_sc">sc</code></td>
<td>
<p>Numeric vector with special case elements. Default values are <code>c(NA, NaN, Inf, -Inf)</code>.
Recommendation is to keep the default values always and add new ones if needed. Otherwise, if these values exist
in <code>x</code> and are not defined in the <code>sc</code> vector, function can report the error.</p>
</td></tr>
<tr><td><code id="ush.bin_+3A_sc.method">sc.method</code></td>
<td>
<p>Define how special cases will be treated, all together or separately.
Possible values are <code>"together", "separately"</code>.</p>
</td></tr>
<tr><td><code id="ush.bin_+3A_g">g</code></td>
<td>
<p>Number of starting groups. Only needed for <code>"cum.bin"</code>, <code>"pct.bin"</code> and <code>mdt.bin</code> methods. Default is 20.</p>
</td></tr>
<tr><td><code id="ush.bin_+3A_min.pct.obs">min.pct.obs</code></td>
<td>
<p>Minimum percentage of observations per bin. Default is 0.05 or 30 observations.</p>
</td></tr>
<tr><td><code id="ush.bin_+3A_min.avg.rate">min.avg.rate</code></td>
<td>
<p>Minimum <code>y</code> average rate. Default is 0.05 or 30 observations.</p>
</td></tr>
<tr><td><code id="ush.bin_+3A_p.val">p.val</code></td>
<td>
<p>Threshold for p-value. Only needed for <code>"sts.bin"</code> and <code>"ndr.bin"</code> methods.
Default is 0.05.</p>
</td></tr>
<tr><td><code id="ush.bin_+3A_woe.trend">woe.trend</code></td>
<td>
<p>Logical. Only needed for <code>"pct.bin"</code> method with default <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="ush.bin_+3A_woe.gap">woe.gap</code></td>
<td>
<p>Minimum WoE gap between bins. Only needed for <code>"woe.bin"</code> method with default of 0.1.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The command <code>ush.bin</code> generates a list of two objects. The first object, data frame <code>summary.tbl</code>
presents a summary table of final binning, while <code>x.trans</code> is a vector of discretized values.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>res &lt;- ush.bin(x = gcd$amount, y = gcd$qual, knot = 2992.579, method = "ndr.bin")
res[[1]]
plot(res[[1]]$dr, type = "l")
</code></pre>

<hr>
<h2 id='ush.test'>Testing for U-shape relation</h2><span id='topic+ush.test'></span>

<h3>Description</h3>

<p><code>ush.test</code> performs U-shape testing between the target and analyzed risk factor.
Testing is based on B-splines basis functions and change of the sign of the estimated coefficients.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ush.test(
  x,
  y,
  p.value = 0.05,
  min.pct.obs = 0.05,
  min.pct.def = 0.01,
  g = 20,
  sc = c(NA, Inf, -Inf, NaN)
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ush.test_+3A_x">x</code></td>
<td>
<p>Numeric vector to be tested for U-shape.</p>
</td></tr>
<tr><td><code id="ush.test_+3A_y">y</code></td>
<td>
<p>Numeric target vector (binary).</p>
</td></tr>
<tr><td><code id="ush.test_+3A_p.value">p.value</code></td>
<td>
<p>Threshold for p-value of statistical significance of the estimated coefficients
next to basis functions. Default is 0.05.</p>
</td></tr>
<tr><td><code id="ush.test_+3A_min.pct.obs">min.pct.obs</code></td>
<td>
<p>Minimum percentage of observations per bin. Default is 0.05.</p>
</td></tr>
<tr><td><code id="ush.test_+3A_min.pct.def">min.pct.def</code></td>
<td>
<p>Minimum <code>y</code> average rate. Default is 0.01 or minimum 1 bad case for y 0/1.</p>
</td></tr>
<tr><td><code id="ush.test_+3A_g">g</code></td>
<td>
<p>Number of knots used for testing the U-shape (integer). It should take values between 2 and 50 with
default value of 20.</p>
</td></tr>
<tr><td><code id="ush.test_+3A_sc">sc</code></td>
<td>
<p>Numeric vector with special case elements. Default values are <code>c(NA, NaN, Inf, -Inf)</code>.
Recommendation is to keep the default values always and add new ones if needed. Otherwise, if these values exist
in <code>x</code> and are not defined in the <code>sc</code> vector, function can report the error.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The command <code>ush.test</code> returns list of three objects. The first object (<code>candidates</code>)
is the data frame with summary of tested candidate knots. Using the reported results of this data frame
user can conclude if U-shape exists at all (column where <code>direction</code> is equal to <code>TRUE</code>) and
check its statistical significance (column <code>significance</code> - <code>TRUE, FALSE</code>).
The second object (<code>optimal</code>) reports optimal knot value (if exists).
It is selected as the knot with minimum deviance among all candidates for
which <code>direction</code> and <code>significance</code> are equal to <code>TRUE</code>.
The last, third, object (<code>basis.functions</code>) exports basis functions for optimal knot. Basis functions
will be exported only in case optimal knot is found. <br />
If optimal knot is not found, then users are encouraged to inspect closer the results of candidate testing.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(gcd)
res &lt;- ush.test(x = gcd$amount, y = gcd$qual)
res 
#optimal knot is not found so candidate can be defined as follows:
direction.t &lt;- res$candidate[res$candidate$direction, ]
optimal.k &lt;- direction.t$cp[direction.t$deviance%in%min(direction.t$deviance)]
optimal.k
</code></pre>

<hr>
<h2 id='woe.tbl'>Weights of evidence (WoE) table</h2><span id='topic+woe.tbl'></span>

<h3>Description</h3>

<p><code>woe.tbl</code> calculates WoE and information value for given target variable and risk factor along with
accompanied metrics needed for their calculation.
WoE table reports:
</p>

<ul>
<li><p> bin: Risk factor group (bin).
</p>
</li>
<li><p> no: Number of observations per bin.
</p>
</li>
<li><p> ng: Number of good cases (where target is equal to 0) per bin.
</p>
</li>
<li><p> nb: Number of bad cases (where target is equal to 1) per bin.
</p>
</li>
<li><p> pct.o: Percentage of observations per bin.
</p>
</li>
<li><p> pct.g: Percentage of good cases (where target is equal to 0) per bin.
</p>
</li>
<li><p> pct.b: Percentage of bad cases (where target is equal to 1) per bin.
</p>
</li>
<li><p> dr: Default rate per bin.
</p>
</li>
<li><p> so: Number of all observations.
</p>
</li>
<li><p> sg: Number of all good cases.
</p>
</li>
<li><p> sb: Number of all bad cases.
</p>
</li>
<li><p> dist.g: Distribution of good cases per bin.
</p>
</li>
<li><p> dist.b: Distribution of bad cases per bin.
</p>
</li>
<li><p> woe: WoE value.
</p>
</li>
<li><p> iv.b: Information value per bin.
</p>
</li>
<li><p> iv.s: Information value of risk factor (sum of individual bins' information values).
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>woe.tbl(tbl, x, y, y.check = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="woe.tbl_+3A_tbl">tbl</code></td>
<td>
<p>Data frame which contains target variable (<code>y</code>) and analyzed risk factor (<code>x</code>).</p>
</td></tr>
<tr><td><code id="woe.tbl_+3A_x">x</code></td>
<td>
<p>Selected risk factor.</p>
</td></tr>
<tr><td><code id="woe.tbl_+3A_y">y</code></td>
<td>
<p>Selected target variable.</p>
</td></tr>
<tr><td><code id="woe.tbl_+3A_y.check">y.check</code></td>
<td>
<p>Logical, if target variable (<code>y</code>) should be checked for 0/1 values.
Default value is <code>TRUE</code>.
Change of this parameter to <code>FALSE</code> can be handy for calculation of WoE based on model
predictions. Concretely, it is used only in calculation of marginal information value (MIV) in <code><a href="#topic+stepMIV">stepMIV</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The command <code>woe.tbl</code> returns the data frame with WoE and information value calculations along with accompanied metrics.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+bivariate">bivariate</a></code> for automatic bivariate analysis.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>suppressMessages(library(PDtoolkit))
data(gcd)
#categorize numeric risk factors
gcd$age.bin &lt;- woe.bin(x = gcd$age, y = gcd$qual, y.type = "bina")[[2]]
#generate woe table
woe.tbl(tbl = gcd, x = "age.bin", y = "qual")
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
