<!DOCTYPE html><html><head><title>Help for package NormData</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {NormData}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#Bootstrap.Stage.2.NormScore'><p>Bootstraps a confidence interval for a percentile rank</p></a></li>
<li><a href='#Bootstrap.Stage.2.NormTable'><p>Bootstraps confidence intervals for a normative table</p></a></li>
<li><a href='#Check.Assum'><p>Check assumptions for a fitted Stage 1 model</p></a></li>
<li><a href='#CheckFit'><p>Check the fit of the mean structure of a regression model</p></a></li>
<li><a href='#Coding'>
<p>Check the coding of a variable</p></a></li>
<li><a href='#Densities'><p>Plot densities</p></a></li>
<li><a href='#ExploreData'><p>Explore data</p></a></li>
<li><a href='#Fluency'><p>Verbal fluency data</p></a></li>
<li><a href='#Fract.Poly'><p>Fit fractional polynomials</p></a></li>
<li><a href='#GCSE'><p>GCSE exam score</p></a></li>
<li><a href='#GLT'><p>Conduct the General Linear Test (GLT) procedure</p></a></li>
<li><a href='#ICC'><p>Intra class correlation</p></a></li>
<li><a href='#Levels'><p>Explore data</p></a></li>
<li><a href='#Personality'><p>Data of the Openness scale of a personality test</p></a></li>
<li><a href='#plot+20Bootstrap.Stage.2.NormScore'><p>Plot the bootstrap distribution and the percentile bootstrap CI</p></a></li>
<li><a href='#plot+20CheckFit'><p>Evaluate the fit of the mean structure of a fitted Stage 1 model.</p></a></li>
<li><a href='#plot+20ExploreData'><p>Plot means and CIs for test scores.</p></a></li>
<li><a href='#plot+20ICC'><p>Graphical depiction of the ICC.</p></a></li>
<li><a href='#plot+20Stage.1'><p>Check the model assumptions for a fitted Stage 1 model graphically.</p></a></li>
<li><a href='#plot+20Stage.2.NormScore'><p>Plot the results for a <code>Stage.2.NormScore</code> object.</p></a></li>
<li><a href='#plot+20Tukey.HSD'><p>Plot the results of Tukey's Honest Significance Difference test.</p></a></li>
<li><a href='#Plot.Scatterplot.Matrix'><p>Explore data</p></a></li>
<li><a href='#PlotFittedPoly'><p>Explore data</p></a></li>
<li><a href='#Sandwich'>
<p>Sandwich estimators for standard errors</p></a></li>
<li><a href='#Stage.1'><p>Stage 1 of the regression-based normative analysis</p></a></li>
<li><a href='#Stage.2.AutoScore'><p>Make an automatic scoring sheet</p></a></li>
<li><a href='#Stage.2.NormScore'><p>Convert a raw score to a percentile rank</p></a></li>
<li><a href='#Stage.2.NormTable'><p>Derive a normative table</p></a></li>
<li><a href='#STAS'><p>State-Trait Anger Scale (STAS)</p></a></li>
<li><a href='#Substitution'><p>Substitution test data</p></a></li>
<li><a href='#summary'><p>Summary</p></a></li>
<li><a href='#TMAS'><p>TMAS data</p></a></li>
<li><a href='#Tukey.HSD'>
<p>Conducts Tukey's Honest Significance Difference test</p></a></li>
<li><a href='#VLT'><p>Verbal Learning Test data</p></a></li>
<li><a href='#WriteNormTable'>
<p>Write a normative table from R to a .txt/.csv/.xlsx file</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Derivation of Regression-Based Normative Data</td>
</tr>
<tr>
<td>Version:</td>
<td>1.1</td>
</tr>
<tr>
<td>Description:</td>
<td>Normative data are often used to estimate the relative position of a raw test score in the population. This package allows for deriving regression-based normative data. It includes functions that enable the fitting of regression models for the mean and residual (or variance) structures, test the model assumptions, derive the normative data in the form of normative tables or automatic scoring sheets, and estimate confidence intervals for the norms. This package accompanies the book Van der Elst, W. (2024). Regression-based normative data for psychological assessment. A hands-on approach using R. Springer Nature.  </td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>car, doBy, MASS, lmtest, dplyr, sandwich, openxlsx, methods</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-04-12 07:58:00 UTC; wim</td>
</tr>
<tr>
<td>Author:</td>
<td>Wim Van der Elst <a href="https://orcid.org/0000-0003-4315-7406"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Wim Van der Elst &lt;Wim.vanderelst@gmail.com&gt;</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-04-12 14:30:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='Bootstrap.Stage.2.NormScore'>Bootstraps a confidence interval for a percentile rank</h2><span id='topic+Bootstrap.Stage.2.NormScore'></span>

<h3>Description</h3>

<p>The function <code>Stage.2.NormScore()</code> can be used to convert a raw test score of a tested person <code class="reqn">Y_0</code> into a percentile rank <code class="reqn">\hat{\pi}_0</code> (taking into account specified values of the independent variables). The function <code>Bootstrap.Stage.2.NormScore()</code> can be used to obtain a confidence interval (CI) around the point estimate of the percentile rank <code class="reqn">\hat{\pi}_0</code>. A non-parametric bootstrap is used to compute a confidence interval (CI) around the estimated percentile rank (for details, see Chapter 8 in Van der Elst, 2023). 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Bootstrap.Stage.2.NormScore(Stage.2.NormScore, 
CI=.99, Number.Bootstraps=2000, Seed=123, 
Rounded=FALSE, Show.Fitted.Boot=FALSE, verbose=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Bootstrap.Stage.2.NormScore_+3A_stage.2.normscore">Stage.2.NormScore</code></td>
<td>
<p>A fitted object of class <code>Stage.2.NormScore</code>.</p>
</td></tr>
<tr><td><code id="Bootstrap.Stage.2.NormScore_+3A_ci">CI</code></td>
<td>
<p>The desired CI around the percentile rank for the raw test score at hand. Default <code>CI=.99</code>.</p>
</td></tr>
<tr><td><code id="Bootstrap.Stage.2.NormScore_+3A_number.bootstraps">Number.Bootstraps</code></td>
<td>
<p>The number of bootstrap samples that are taken. Default <code>Number.Bootstraps=2000</code>.</p>
</td></tr>
<tr><td><code id="Bootstrap.Stage.2.NormScore_+3A_seed">Seed</code></td>
<td>
<p>The seed to be used in the bootstrap (for repoducibility). Default <code>Seed = 123</code>.</p>
</td></tr>
<tr><td><code id="Bootstrap.Stage.2.NormScore_+3A_rounded">Rounded</code></td>
<td>
<p>Logical. Should the percentile rank be rounded to a whole number? Default <code>Rounded=FALSE</code>.</p>
</td></tr>
<tr><td><code id="Bootstrap.Stage.2.NormScore_+3A_show.fitted.boot">Show.Fitted.Boot</code></td>
<td>
<p>Logical. Should the fitted Stage 1 models for the bootstrap samples be printed? Default <code>Show.Fitted.Boot=FALSE</code>.</p>
</td></tr>
<tr><td><code id="Bootstrap.Stage.2.NormScore_+3A_verbose">verbose</code></td>
<td>
<p>A logical value indicating whether verbose output should be generated.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For details, see Chapter 8 in Van der Elst (2023).
</p>


<h3>Value</h3>

<p>An object of class <code>Stage.2.NormScore</code> with components,
</p>
<table>
<tr><td><code>CI.Percentile</code></td>
<td>
<p>The bootstrapped CI around the estimated percentile rank.</p>
</td></tr>
<tr><td><code>CI</code></td>
<td>
<p>The CI used.</p>
</td></tr>
<tr><td><code>All.Percentiles</code></td>
<td>
<p>All bootstrapped percentile ranks for the raw test score at hand.</p>
</td></tr>
<tr><td><code>Assume.Homoscedasticity</code></td>
<td>
<p>Logical. Was homoscedasticity assumed in the normative conversion? For details, see <code><a href="#topic+Stage.2.NormScore">Stage.2.NormScore</a></code>.</p>
</td></tr>
<tr><td><code>Assume.Normality</code></td>
<td>
<p>Logical. Was normality assumed in the normative conversion? For details, see <code><a href="#topic+Stage.2.NormScore">Stage.2.NormScore</a></code>.</p>
</td></tr>
<tr><td><code>Stage.2.NormScore</code></td>
<td>
<p>The fitted <code>Stage.2.NormScore</code> object used in the function call.</p>
</td></tr>
<tr><td><code>Percentile.Point.Estimate</code></td>
<td>
<p>The point estimate for the percentile rank (based on the original dataset).</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Wim Van der Elst
</p>


<h3>References</h3>

<p>Van der Elst, W. (2024). <em>Regression-based normative data for psychological assessment: A hands-on approach using R.</em> Springer Nature. 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Stage.2.NormScore">Stage.2.NormScore</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'> # Time-intensive part
# Replicate the bootstrap results that were obtained in 
# Case study 1 of Chapter 8 in Van der Elst (2023)
# -----------------------------------------------------
library(NormData) # load the NormData package
data(GCSE)        # load the GCSE dataset

# Fit the Stage 1 model
Model.1.GCSE &lt;- Stage.1(Dataset=GCSE, 
  Model=Science.Exam~Gender)

# Stage 2: Convert a science exam score = 30 obtained by a 
# female into a percentile rank (point estimate)
Normed_Score &lt;- Stage.2.NormScore(Stage.1.Model=Model.1.GCSE,
  Score=list(Science.Exam=30, Gender="F"), Rounded = FALSE)
summary(Normed_Score)

# Derive the 99pc CI around the point estimate 
# using a bootstrap procedure
Bootstrap_Normed_Score &lt;- Bootstrap.Stage.2.NormScore(
  Stage.2.NormScore=Normed_Score)

summary(Bootstrap_Normed_Score)

plot(Bootstrap_Normed_Score)


# Replicate the bootstrap results that were obtained in 
# Case study 2 of Chapter 8 in Van der Elst (2023)
# ------------------------------------------------
library(NormData)   # load the NormData package
data(Substitution)  # load the Substitution dataset

# Make the new variable Age.C (= Age centered) that is 
# needed to fit the final Stage 1 model, 
# and add it to the Substitution dataset
Substitution$Age.C &lt;- Substitution$Age - 50

# Fit the final Stage 1 model
Substitution.Model.9 &lt;- Stage.1(Dataset=Substitution, 
  Alpha=0.005, Model=LDST~Age.C+LE, Order.Poly.Var=1) 
summary(Substitution.Model.9)

# Convert an LDST score = 40 obtained by a 
# 20-year-old test participant with LE=Low 
# into a percentile rank (point estimate)
Normed_Score &lt;- Stage.2.NormScore(
   Stage.1.Model=Substitution.Model.9, 
   Score=list(LDST=40, Age.C=20-50, LE = "Low"), 
   Rounded = FALSE)

# Derive the 99pc CI around the point estimate 
# using a bootstrap
Bootstrap_Normed_Score &lt;- Bootstrap.Stage.2.NormScore(
   Stage.2.NormScore = Normed_Score)
summary(Bootstrap_Normed_Score)
plot(Bootstrap_Normed_Score)

</code></pre>

<hr>
<h2 id='Bootstrap.Stage.2.NormTable'>Bootstraps confidence intervals for a normative table</h2><span id='topic+Bootstrap.Stage.2.NormTable'></span>

<h3>Description</h3>

<p>The function <code>Stage.2.NormTable()</code> is used to derive a normative table that shows the percentile ranks <code class="reqn">\hat{\pi}_0</code> that correspond to a wide range of raw test scores <code class="reqn">Y_0</code>  (stratified by the relevant independent variables). The function <code>Bootstrap.Stage.2.NormTable()</code> can be used to obtain confidence intervals (CIs) around the point estimates of the percentile ranks <code class="reqn">\hat{\pi}_0</code> in the normative table. A non-parametric bootstrap is used to compute these CIs (for details, see Chapter 8 in Van der Elst, 2023). 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Bootstrap.Stage.2.NormTable(Stage.2.NormTable,
CI=.99, Number.Bootstraps=2000, Seed=123, 
Rounded=FALSE, Show.Fitted.Boot=FALSE, verbose=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Bootstrap.Stage.2.NormTable_+3A_stage.2.normtable">Stage.2.NormTable</code></td>
<td>
<p>A fitted object of class <code>Stage.2.NormTable</code>.</p>
</td></tr>
<tr><td><code id="Bootstrap.Stage.2.NormTable_+3A_ci">CI</code></td>
<td>
<p>The desired CI around the percentile ranks. Default <code>CI=.99</code>.</p>
</td></tr>
<tr><td><code id="Bootstrap.Stage.2.NormTable_+3A_number.bootstraps">Number.Bootstraps</code></td>
<td>
<p>The number of bootstrap samples that are taken. Default <code>Number.Bootstraps=2000</code>.</p>
</td></tr>
<tr><td><code id="Bootstrap.Stage.2.NormTable_+3A_seed">Seed</code></td>
<td>
<p>The seed to be used in the bootstrap (for repoducibility). Default <code>Seed = 123</code>.</p>
</td></tr>
<tr><td><code id="Bootstrap.Stage.2.NormTable_+3A_rounded">Rounded</code></td>
<td>
<p>Logical. Should the percentile ranks that are shown in the normative table be rounded to a whole number? Default <code>Rounded=FALSE</code>.</p>
</td></tr>
<tr><td><code id="Bootstrap.Stage.2.NormTable_+3A_show.fitted.boot">Show.Fitted.Boot</code></td>
<td>
<p>Logical. Should the fitted Stage 1 models for the bootstrap samples be printed? Default <code>Show.Fitted.Boot=FALSE</code>.</p>
</td></tr>
<tr><td><code id="Bootstrap.Stage.2.NormTable_+3A_verbose">verbose</code></td>
<td>
<p>A logical value indicating whether verbose output should be generated.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For details, see Chapter 8 in Van der Elst (2023).
</p>


<h3>Value</h3>

<p>An object of class <code>Stage.2.NormTable</code> with components,
</p>
<table>
<tr><td><code>NormTable.With.CI</code></td>
<td>
<p>The normative table with the bootstrapped CI.</p>
</td></tr>
<tr><td><code>CI</code></td>
<td>
<p>The CI used.</p>
</td></tr>
<tr><td><code>Assume.Homoscedasticity</code></td>
<td>
<p>Logical. Was homoscedasticity assumed in the normative conversion? For details, see <code><a href="#topic+Stage.2.NormTable">Stage.2.NormTable</a></code>.</p>
</td></tr>
<tr><td><code>Assume.Normality</code></td>
<td>
<p>Logical. Was normality assumed in the  in the normative conversion? For details, see <code><a href="#topic+Stage.2.NormTable">Stage.2.NormTable</a></code>.</p>
</td></tr>
<tr><td><code>NormTable.With.CI.Min</code></td>
<td>
<p>A table with the lower bounds of the CIs.</p>
</td></tr>
<tr><td><code>NormTable.With.CI.Max</code></td>
<td>
<p>A table with the upper bounds of the CIs.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Wim Van der Elst
</p>


<h3>References</h3>

<p>Van der Elst, W. (2024). <em>Regression-based normative data for psychological assessment: A hands-on approach using R.</em> Springer Nature. 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Stage.2.NormTable">Stage.2.NormTable</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'> # Time-intensive part
# Replicate the bootstrap results that were obtained in 
# Case study 1 of Chapter 8 in Van der Elst (2023)
# -----------------------------------------------------
library(NormData) # load the NormData package
data(GCSE)        # load the GCSE dataset

# Fit the Stage 1 model
Model.1.GCSE &lt;- Stage.1(Dataset=GCSE, 
  Model=Science.Exam~Gender)

# Normative table with CIs
NormTable.GCSE &lt;- Stage.2.NormTable(
  Stage.1.Model=Model.1.GCSE, 
  Test.Scores=seq(from=10, to=85, by=5),
  Grid.Norm.Table=data.frame(Gender=c("F", "M")), 
  Rounded = FALSE)
summary(NormTable.GCSE)

# Bootstrap the CIs
Bootstrap_NormTable.GCSE &lt;- Bootstrap.Stage.2.NormTable(
  Stage.2.NormTable = NormTable.GCSE)
summary(Bootstrap_NormTable.GCSE)


# Replicate the bootstrap results that were obtained in 
# Case study 2 of Chapter 8 in Van der Elst (2023)
# ------------------------------------------------
library(NormData)   # load the NormData package
data(Substitution)  # load the Substitution dataset

# Make the new variable Age.C (= Age centered) that is 
# needed to fit the final Stage 1 model, 
# and add it to the Substitution dataset
Substitution$Age.C &lt;- Substitution$Age - 50

# Fit the final Stage 1 model
Substitution.Model.9 &lt;- Stage.1(Dataset=Substitution, 
  Alpha=0.005, Model=LDST~Age.C+LE, Order.Poly.Var=1) 

summary(Substitution.Model.9)

# Make the normative table
NormTable.LDST &lt;- Stage.2.NormTable(
Stage.1.Model=Substitution.Model.9, 
  Test.Scores=seq(from=25, to=40, by=5),
  Grid.Norm.Table=expand.grid(
  Age.C=seq(from=-30, to=30, by = 1), 
  LE=c("Low", "Average", "High")), Rounded = FALSE)

# Bootstrap the CIs
Bootstrap_NormTable.LDST &lt;- Bootstrap.Stage.2.NormTable(
  Stage.2.NormTable = NormTable.LDST)

summary(Bootstrap_NormTable.LDST)

</code></pre>

<hr>
<h2 id='Check.Assum'>Check assumptions for a fitted Stage 1 model</h2><span id='topic+Check.Assum'></span>

<h3>Description</h3>

<p>Helper function to check the validity of the homoscedasticity and normality assumptions for a fitted Stage 1 model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Check.Assum(Stage.1.Model)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Check.Assum_+3A_stage.1.model">Stage.1.Model</code></td>
<td>
<p>The fitted <code>Stage.1</code> model.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For details, see Van der Elst (2023).
</p>


<h3>Value</h3>

<p>An object of class <code>Check.Assum</code> with component,
</p>
<table>
<tr><td><code>Assume.Homo.S2</code></td>
<td>
<p>Is the homoscedasticity assumption valid?</p>
</td></tr> 
<tr><td><code>Assume.Normality.S2</code></td>
<td>
<p>Is the normality assumption valid?</p>
</td></tr> 
</table>


<h3>Author(s)</h3>

<p>Wim Van der Elst
</p>


<h3>References</h3>

<p>Van der Elst, W. (2024). <em>Regression-based normative data for psychological assessment: A hands-on approach using R.</em> Springer Nature. 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Stage.1">Stage.1</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>data("Substitution")
# Fit a model with a linear mean prediction function
Fit &lt;- Stage.1(Dataset = Substitution, Model = LDST~Age)
Check.Assum(Fit)
   # Output shows that the homoscedasticity and normality
   # assumptions are both violated
</code></pre>

<hr>
<h2 id='CheckFit'>Check the fit of the mean structure of a regression model</h2><span id='topic+CheckFit'></span>

<h3>Description</h3>

<p>The function <code>CheckFit()</code> allows for evaluating the fit of the mean structure of a regression model by comparing sample means and model-predicted means. If the model fits the data well, there should be a good agreement between the sample means and the predicted mean test scores in the relevant subgroups. When the model only contains (binary and/or non-binary) qualitative independent variables, the subgroups correspond to all possible combinations of the different levels of the qualitative variables. When there are quantitative independent variables in the model, these have to be discretized first.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CheckFit(Stage.1.Model, Means, CI=.99, Digits=6)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CheckFit_+3A_stage.1.model">Stage.1.Model</code></td>
<td>
<p>The fitted <code>Stage.1</code> model.</p>
</td></tr>
<tr><td><code id="CheckFit_+3A_means">Means</code></td>
<td>
<p>A formula in the form of <code>Test.Score~Independent.Var1+Independent.Var2+...</code>. The mean, SD, and N will be provided for all combinations of the independent variable values levels. Note that all indpendent variables should be factors (i.e., non -quantitative).</p>
</td></tr>
<tr><td><code id="CheckFit_+3A_ci">CI</code></td>
<td>
<p>The required confidence limits. Default <code>CI=.99</code>, i.e. the 99 percent CI.</p>
</td></tr>
<tr><td><code id="CheckFit_+3A_digits">Digits</code></td>
<td>
<p>The number of digits used when showing the results. Default <code>Digits=6</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For details, see Van der Elst (2023).
</p>


<h3>Value</h3>

<p>An object of class <code>CheckFit</code> with component,
</p>
<table>
<tr><td><code>Results.Observed</code></td>
<td>
<p>A table with the means, SDs, and N for the observed test score, for each combination of independent variable levels.</p>
</td></tr> 
<tr><td><code>Results.Predicted</code></td>
<td>
<p>A table with the mean predicted test scores, for each combination of independent variable levels.</p>
</td></tr> 
<tr><td><code>Miss</code></td>
<td>
<p>The number of missing observations in the dataset.</p>
</td></tr>
<tr><td><code>Dataset</code></td>
<td>
<p>The dataset used in the analysis.</p>
</td></tr>
<tr><td><code>Model</code></td>
<td>
<p>The specified model for the mean.</p>
</td></tr>
<tr><td><code>CI</code></td>
<td>
<p>The requested CI around the mean.</p>
</td></tr>
<tr><td><code>N</code></td>
<td>
<p>The sample size of the specified dataset.</p>
</td></tr>
<tr><td><code>Stage.1.Model</code></td>
<td>
<p>The fitted <code>Stage.1.Model</code> used in the analysis.</p>
</td></tr>
<tr><td><code>Saturated</code></td>
<td>
<p>Is the fitted <code>Stage.1.Model</code> a saturated model?</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Wim Van der Elst
</p>


<h3>References</h3>

<p>Van der Elst, W. (2024). <em>Regression-based normative data for psychological assessment: A hands-on approach using R.</em> Springer Nature. 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Stage.1">Stage.1</a></code>, <code><a href="#topic+plot.CheckFit">plot.CheckFit</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'># Replicate the fit plot that was obtained in 
# Case study 1 of Chapter 7 in Van der Elst (2023)
# ------------------------------------------------
library(NormData)   # load the NormData package
data(Substitution)  # load the Substitution dataset
head(Substitution)  # have a look at the first datalines in
# the Substitution dataset

# Final Stage 1 model 
Substitution$Age.C &lt;- Substitution$Age - 50
  # Add Age_Group (that discretizes the quantitative variable Age 
  # into 6 groups with a span of 10 years in the dataset for use 
  # by the CheckFit() function later on)
Substitution$Age_Group &lt;- cut(Substitution$Age, 
   breaks=seq(from=20, to=80, by=10)) 
Substitution.Model.9 &lt;- Stage.1(Dataset=Substitution, 
   Alpha=0.005, Model=LDST~Age.C+LE, Order.Poly.Var=1) 

# Examine fit 
Fit.LDST &lt;- CheckFit(Stage.1.Model=Substitution.Model.9, 
  Means=LDST~Age_Group+LE)
summary(Fit.LDST) 
plot(Fit.LDST)


# Replicate the fit plot that was obtained in 
# Case study 2 of Chapter 7 in Van der Elst (2023)
# ------------------------------------------------
library(NormData)   # load the NormData package
data(VLT)           # load the VLT dataset
head(VLT)           # have a look at the first datalines in 
                    # the VLT dataset

# Fit the final Stage 1 model
VLT$Age.C &lt;- VLT$Age - 50
VLT$Age.C2 &lt;- (VLT$Age - 50)**2
  # Add Age_Group (that discretizes the quantitative variable Age 
  # into 6 groups with a span of 10 years in the dataset for use 
  # by the CheckFit() function later on)
VLT$Age_Group &lt;- cut(VLT$Age, breaks=seq(from=20, to=80, by=10)) 

VLT.Model.4 &lt;- Stage.1(Dataset = VLT, Alpha = .005, 
  Model = Total.Recall ~ Age.C+Age.C2+Gender+LE+Age.C:Gender)

# Examine fit using fit plots for the Age Group by 
# LE by Gender subgroups
Fit.Means.Total.Recall &lt;- CheckFit(Stage.1.Model=VLT.Model.4, 
  Means=Total.Recall~Age_Group+LE+Gender)

summary(Fit.Means.Total.Recall)
plot(Fit.Means.Total.Recall)
</code></pre>

<hr>
<h2 id='Coding'>
Check the coding of a variable
</h2><span id='topic+Coding'></span>

<h3>Description</h3>

<p>This function checks the coding of a variable, e.g., the dummy-coding scheme that will be used for binary or qualitative variables. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Coding(x, verbose=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Coding_+3A_x">x</code></td>
<td>
<p>The variable to be evaluated.</p>
</td></tr>
<tr><td><code id="Coding_+3A_verbose">verbose</code></td>
<td>
<p>A logical value indicating whether verbose output should be generated.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>No return value, called for side effects.</p>


<h3>Author(s)</h3>

<p>Wim Van der Elst
</p>


<h3>References</h3>

<p>Van der Elst, W. (2024). <em>Regression-based normative data for psychological assessment: A hands-on approach using R.</em> Springer Nature. 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(Substitution)
Coding(Substitution$LE)
</code></pre>

<hr>
<h2 id='Densities'>Plot densities</h2><span id='topic+Densities'></span>

<h3>Description</h3>

<p>Plot densities for an outcome for different subgroups.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Densities(Dataset, Test.Score, IV, Color=TRUE, 
Size.Legend=1, xlab="Test score", main, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Densities_+3A_dataset">Dataset</code></td>
<td>
<p>The name of the dataset.</p>
</td></tr>
<tr><td><code id="Densities_+3A_test.score">Test.Score</code></td>
<td>
<p>The name of the outcome variable (e.g., a raw test score).</p>
</td></tr>
<tr><td><code id="Densities_+3A_iv">IV</code></td>
<td>
<p>The name of the stratification variable, that defines for which subgroups density plots should be provided. If <code>IV</code> is not specified, a single density is shown (no subgroups).</p>
</td></tr>
<tr><td><code id="Densities_+3A_color">Color</code></td>
<td>
<p>Logical. Should densities for different subgroups be depicted in color? Default <code>Color=TRUE</code>.</p>
</td></tr>
<tr><td><code id="Densities_+3A_size.legend">Size.Legend</code></td>
<td>
<p>The size of the legend in the plot. Default <code>Size.Legend=1</code>.</p>
</td></tr>
<tr><td><code id="Densities_+3A_xlab">xlab</code></td>
<td>
<p>The label on the X-axis. Default <code>xlab="Test score"</code>.</p>
</td></tr>
<tr><td><code id="Densities_+3A_main">main</code></td>
<td>
<p>The title of the plot.</p>
</td></tr>
<tr><td><code id="Densities_+3A_...">...</code></td>
<td>
<p>Other arguments to be passed to the <code>plot(function)</code>, e.g. <code>xlim=c(0, 100)</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>No return value, called for side effects.</p>


<h3>Author(s)</h3>

<p>Wim Van der Elst
</p>


<h3>References</h3>

<p>Van der Elst, W. (2024). <em>Regression-based normative data for psychological assessment: A hands-on approach using R.</em> Springer Nature. 
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Plot Gender-specific densities of the raw science exam 
# scores in the GCSE dataset
data(GCSE)
Densities(Dataset = GCSE, Test.Score = Science.Exam, IV=Gender)

# Plot LE-specific densities of the residuals of a model
# where the Openness scale score is regressed on LE
data(Personality)
Fit &lt;- Stage.1(Dataset = Personality, Model = Openness~LE)
summary(Fit)
Data.With.Residuals &lt;- data.frame(Personality, 
  Fit$HomoNorm$Residuals)
Densities(Dataset = Data.With.Residuals, 
  Test.Score = Fit.HomoNorm.Residuals, IV = LE)

</code></pre>

<hr>
<h2 id='ExploreData'>Explore data</h2><span id='topic+ExploreData'></span>

<h3>Description</h3>

<p>This function provides summary statistics of a test score (i.e., the mean, SD, N, standard error of the mean, and CI of the mean), stratified by the independent variable(s) of interest. The independent variables should be factors (i.e., binary or non-binary qualitiative variables).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ExploreData(Dataset, Model, CI=.99, Digits=6)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ExploreData_+3A_dataset">Dataset</code></td>
<td>
<p>A dataset.</p>
</td></tr>
<tr><td><code id="ExploreData_+3A_model">Model</code></td>
<td>
<p>A formula in the form of <code>Test.Score~IV.1+IV.2+...</code>. Summary statistics (i.e., the mean, SD, N, standard error of the mean, and CI of the mean) are provided for all combinations of the levels of the IVs (independent variables). Note that all IVs should be factors (i.e., binary or non-binary qualitative variables).</p>
</td></tr>
<tr><td><code id="ExploreData_+3A_ci">CI</code></td>
<td>
<p>The CI for the mean. Default <code>CI=.99</code>, i.e. the 99 CI.</p>
</td></tr>
<tr><td><code id="ExploreData_+3A_digits">Digits</code></td>
<td>
<p>The number of digits used when showing the results. Default <code>Digits=6</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For details, see Van der Elst (2023).
</p>


<h3>Value</h3>

<p>An object of class <code>ExploreData</code> with component,
</p>
<table>
<tr><td><code>Results</code></td>
<td>
<p>A table with the summary statistics.</p>
</td></tr> 
<tr><td><code>Miss</code></td>
<td>
<p>The number of missing observations in the dataset.</p>
</td></tr>
<tr><td><code>Dataset</code></td>
<td>
<p>The dataset used in the analysis.</p>
</td></tr>
<tr><td><code>Model</code></td>
<td>
<p>The specified model.</p>
</td></tr>
<tr><td><code>CI</code></td>
<td>
<p>The requested CI around the mean.</p>
</td></tr>
<tr><td><code>N</code></td>
<td>
<p>The sample size of the specified dataset.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Wim Van der Elst
</p>


<h3>References</h3>

<p>Van der Elst, W. (2024). <em>Regression-based normative data for psychological assessment: A hands-on approach using R.</em> Springer Nature. 
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Replicate the exploratory analyses that were conducted  
# in Case study 1 of Chapter 5 in Van der Elst (2023)
# ------------------------------------------------------
library(NormData) # load the NormData package

data(Personality) # load the Personality dataset
Explore_Openness &lt;- ExploreData(Dataset=Personality, 
  Model=Openness~LE)
summary(Explore_Openness)
plot(Explore_Openness, 
  main="Mean Openness scale scores and 99pc CIs")


# Replicate the exploratory analyses that were conducted  
# in Case study 1 of Chapter 7 in Van der Elst (2023)
# ------------------------------------------------------
library(NormData)   # load the NormData package
data(Substitution)  # load the Substitution dataset
head(Substitution)  # have a look at the first datalines in
                    # the Substitution dataset

# First make a new variable Age_Group, that discretizes the
# quantitative variable Age into 6 groups with a span of 10 years
Substitution$Age_Group &lt;- cut(Substitution$Age, 
   breaks=seq(from=20, to=80, by=10)) 

# Compute descriptives of the LDST score for different Age Group
# by LE combinations
Explore.LDST.Age.LE &lt;- ExploreData(Dataset=Substitution,
   Model=LDST~Age_Group+LE) 
summary(Explore.LDST.Age.LE)

# Make a plot of the results. 
plot(Explore.LDST.Age.LE, 
   main="Mean (99pc CI) LDST scores by Age group and LE")

# Compute descriptives of the LDST score for different
# Age Group by Gender combinations
Explore.LDST.Age.Gender &lt;- ExploreData(Dataset=Substitution, 
  Model=LDST~Age_Group+Gender)

# Plot the results
plot(Explore.LDST.Age.Gender, 
  main="Mean (99pc CI) LDST scores by Age group and Gender")

# Compute descriptives of the LDST score for different
# LE by Gender combinations
Explore.LDST.LE.Gender &lt;-
  ExploreData(Dataset=Substitution, Model=LDST~LE+Gender)

# Plot the results
plot(Explore.LDST.LE.Gender,
  main="Mean (99pc CI) LDST scores by LE and Gender")

# Compute summary statistics of the LDST score in the
# Age Group by LE by Gender combinations
Explore.LDST &lt;- ExploreData(Dataset=Substitution,
   Model=LDST~Age_Group+LE+Gender)

# Plot the results
plot(Explore.LDST)
</code></pre>

<hr>
<h2 id='Fluency'>Verbal fluency data</h2><span id='topic+Fluency'></span>

<h3>Description</h3>

<p>This dataset contains the scores of the Fruits Verbal Fluency Test. The <code class="reqn">N = 1241</code> test participants were instructed to generate as many words as possible that belong to the category &lsquo;fruits&rsquo; (e.g., apple, orange, banana, etc.) within <code class="reqn">60</code> seconds. These are simulated data based on the results described in Rivera <em>et al.</em> (2019). </p>


<h3>Usage</h3>

<pre><code class='language-R'>data(Fluency)</code></pre>


<h3>Format</h3>

<p>A <code>data.frame</code> with <code class="reqn">1241</code> observations on <code class="reqn">3</code> variables.
</p>

<dl>
<dt><code>Id</code></dt><dd><p>The Id number of the test participant.</p>
</dd>
<dt><code>Country</code></dt><dd><p>The country where the test participant lives, coded as a factor.</p>
</dd>
<dt><code>Fruits</code></dt><dd><p>The number of correctly generated fruit names. Higher score is better.</p>
</dd>
</dl>


<h3>References</h3>

<p>Rivera <em>et al.</em> (2019). Normative Data For Verbal Fluency in Healthy Latin American Adults: Letter M, and Fruits and Occupations Categories. <em>Neuropsychology, 33,</em> 287-300.
</p>
<p>Van der Elst, W. (2024). <em>Regression-based normative data for psychological assessment: A hands-on approach using R.</em> Springer Nature. 
</p>

<hr>
<h2 id='Fract.Poly'>Fit fractional polynomials</h2><span id='topic+Fract.Poly'></span>

<h3>Description</h3>

<p>Fit a fractional polynomial model with <code class="reqn">m</code> terms of the form <code class="reqn">X^{p}</code>, where the exponents <code class="reqn">p</code> are selected from a small predefined set <code class="reqn">S</code> of both integer and non-integer values. This function can be useful to model the mean or variance prediction function in a more flexible way than by using linear, quadratic or cubic polynomials. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Fract.Poly(IV, Outcome, 
S=c(-3, -2.5, -2.0, -1.5, -1, -0.5, 0.5, 1, 1.5, 2, 2.5, 3), 
Max.M=3)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Fract.Poly_+3A_iv">IV</code></td>
<td>
<p>The Independent Variable to be considered in the model.</p>
</td></tr>
<tr><td><code id="Fract.Poly_+3A_outcome">Outcome</code></td>
<td>
<p>The outcome to be considered in the model.</p>
</td></tr>
<tr><td><code id="Fract.Poly_+3A_s">S</code></td>
<td>
<p>The set <code class="reqn">S</code> from which each power <code class="reqn">p^{m}</code> is selected. Default <code>S={-3, -2.5, -2.0, -1.5, -1, -0.5, 0.5, 1, 1.5, 2, 2.5, 3}</code>.</p>
</td></tr>
<tr><td><code id="Fract.Poly_+3A_max.m">Max.M</code></td>
<td>
<p>The maximum order <code class="reqn">M</code> to be considered for the fractional polynomial. This value can be <code class="reqn">5</code> at most. When <code class="reqn">M=5</code>, then fractional polynomials of order <code class="reqn">1</code> to <code class="reqn">5</code> are considered. Default <code>Max.M=3</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>All.Results</code></td>
<td>
<p>The results (powers and AIC values) of the fractional polynomials.</p>
</td></tr>
<tr><td><code>Lowest.AIC</code></td>
<td>
<p>Table with the fractional polynomial model that has the lowest AIC.</p>
</td></tr>
<tr><td><code>Best.Model</code></td>
<td>
<p>The best fitted model (<code>lm</code> object).</p>
</td></tr>
<tr><td><code>IV</code></td>
<td>
<p>The IV tha was considered in the model.</p>
</td></tr>
<tr><td><code>Outcome</code></td>
<td>
<p>The outcome that was considered in the model.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Wim Van der Elst
</p>


<h3>References</h3>

<p>Van der Elst, W. (2024). <em>Regression-based normative data for psychological assessment: A hands-on approach using R.</em> Springer Nature. 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(VLT)
# Fit fractional polynomials of orders 1 to 2
FP &lt;- Fract.Poly(IV = VLT$Age, Outcome = VLT$Total.Recall, 
  Max.M=2)
FP$Lowest.AIC
FP$Best.Model  
# Model with lowest AIC: 127.689 + (-190.731 * (Age**(-0.5))) +
#  (-7.586 * (Age**(0.5)))

# Make plot
plot(x=VLT$Age, y=VLT$Total.Recall, col="grey")
  # add best fitted fractional polynomial
Age.Vals.Plot &lt;- 20:80
Pred.Vals &lt;- 127.689 + (-190.731 * (Age.Vals.Plot**(-0.5))) +
   (-7.586 * (Age.Vals.Plot**(0.5)))
lines(x=Age.Vals.Plot, y=Pred.Vals, lwd=2, col="red", lty=2)
legend("topright", lwd=2, col="red", lty=2, 
  legend="Mean Prediction Function, Fractional Polynomial")
</code></pre>

<hr>
<h2 id='GCSE'>GCSE exam score</h2><span id='topic+GCSE'></span>

<h3>Description</h3>

<p>Thiis dataset contains the scores on a written science exam (General Certificate of Secondary Education; GCSE) that is taken by <code class="reqn">N = 1905</code> students in <code class="reqn">73</code> schools in England. The exam is taken at the end of compulsory schooling, when students are typically <code class="reqn">16</code> years old. The actual score maximum is <code class="reqn">160</code>, but here a rescaled score (with max value <code class="reqn">100</code>) is provided. The data originally come from the package <code>mlmRev</code>, dataset <code>Gcsemv</code>.</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(GCSE)</code></pre>


<h3>Format</h3>

<p>A <code>data.frame</code> with <code class="reqn">1905</code> observations on <code class="reqn">3</code> variables.
</p>

<dl>
<dt><code>Id</code></dt><dd><p>The Id number of the student.</p>
</dd>
<dt><code>Gender</code></dt><dd><p>The gender of the student, coded as M = male and F = female.</p>
</dd>
<dt><code>Science.Exam</code></dt><dd><p>The science exam score.</p>
</dd>
</dl>

<hr>
<h2 id='GLT'>Conduct the General Linear Test (GLT) procedure</h2><span id='topic+GLT'></span>

<h3>Description</h3>

<p>The function <code>GLT</code> fits two nested linear regression models (that are referred to as the unrestricted and the restricted models), and evaluates whether or not the fit of both models differs significantly. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>GLT(Dataset, Unrestricted.Model, Restricted.Model, Alpha=0.05, 
Alpha.Homosc=0.05, Assume.Homoscedasticity=NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="GLT_+3A_dataset">Dataset</code></td>
<td>
<p>A <code>data.frame</code> that should consist of one line per test participant. Each line should contain (at least) one test score and one independent variable.</p>
</td></tr>
<tr><td><code id="GLT_+3A_unrestricted.model">Unrestricted.Model</code></td>
<td>
<p>The unrestricted regression model to be fitted. A formula should be provided using the syntaxis of the <code>lm</code> function (for help, see <code>?lm</code>). For example, <code>Test.Score~ Gender</code> will fit a linear regression model in which <code>Gender</code> is regressed on <code>Test.Score</code>. <code>Test.Score~Gender+Age+Gender:Age</code> will regress <code>Test.Score</code> on <code>Gender</code>, <code>Age</code>, and their interaction.</p>
</td></tr>
<tr><td><code id="GLT_+3A_restricted.model">Restricted.Model</code></td>
<td>
<p>The restricted regression model to be fitted.</p>
</td></tr> 
<tr><td><code id="GLT_+3A_alpha">Alpha</code></td>
<td>
<p>The significance level that should be used in the GLT procedure. Default <code>Alpha= 0.05</code>.</p>
</td></tr>
<tr><td><code id="GLT_+3A_alpha.homosc">Alpha.Homosc</code></td>
<td>
<p>The significance level to conduct the homoscedasticity test. If the unrestricted model only contains qualitative independent variables, the Levene test is used. If the model contains at least one quantitative independent variables, the Breusch-Pagan test is used. If the homoscedasticity assumption is violated, a heteroscedasticity-robust <code>F*</code> test is provided. Default <code>Alpha.Homosc=0.05</code>.</p>
</td></tr>
<tr><td><code id="GLT_+3A_assume.homoscedasticity">Assume.Homoscedasticity</code></td>
<td>
<p>Logical. The <code>NormData</code> package &lsquo;decides&rsquo; whether the homoscedasticity assumption is valid based on the Levene (or Breusch-Pagan) test. <br /> The <code>Assume.Homoscedasticity= TRUE/FALSE</code> argument can be used to overrule this decision process and &lsquo;force&rsquo; the <code>NormData</code> package to assume or not assume homoscedasticity.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For details, see Van der Elst (2023).
</p>


<h3>Value</h3>

<p>An object of class <code>GLT</code> with components,
</p>
<table>
<tr><td><code>F.Test.Stat.Results</code></td>
<td>
<p>The result of the GLT procedure, i.e., the SSEs and DFs the fitted unrestricted and restricted models, and the <code class="reqn">F^*</code> test-statistic.</p>
</td></tr>
<tr><td><code>Fit.Unrestricted.Model</code></td>
<td>
<p>The fitted unrestricted model.</p>
</td></tr>
<tr><td><code>Fit.Restricted.Model</code></td>
<td>
<p>The fitted restricted model.</p>
</td></tr>
<tr><td><code>Alpha</code></td>
<td>
<p>The significance level that was used.</p>
</td></tr>
<tr><td><code>p.val.homoscedasticity</code></td>
<td>
<p>The p-value that was used in the homoscedasticity test for the unrestricted model.</p>
</td></tr>
<tr><td><code>F.Test.Hetero.Robust</code></td>
<td>
<p>The result of the heteroscedasticity-robust <code>F*</code> test. For details, see the <code>waldtest</code> function of the <code>lmtest package</code> (see <code>?waldtest</code>).</p>
</td></tr>
<tr><td><code>Alpha.Homoscedasticity</code></td>
<td>
<p>The significance level that was used to conduct the homoscedasticity test. Default <code>Alpha.Homoscedasticity=0.05</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Wim Van der Elst
</p>


<h3>References</h3>

<p>Van der Elst, W. (2024). <em>Regression-based normative data for psychological assessment: A hands-on approach using R.</em> Springer Nature. 
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Replicate the GLT results that were obtained in 
# Case study 1 of Chapter 5 in Van der Elst (2023)
# ------------------------------------------------
data(Personality)

GLT.Openness &lt;- GLT(Dataset=Personality,
     Unrestricted.Model=Openness~LE, Restricted.Model=Openness~1)
summary(GLT.Openness)

# Replicate the GLT results that were obtained in 
# Case study 2 of Chapter 5 in Van der Elst (2023)
# ------------------------------------------------
data(Fluency)

GLT.Fruits &lt;- GLT(Dataset=Fluency,
     Unrestricted.Model=Fruits~LE, Restricted.Model=Fruits~1)
summary(GLT.Fruits)
</code></pre>

<hr>
<h2 id='ICC'>Intra class correlation</h2><span id='topic+ICC'></span>

<h3>Description</h3>

<p>The function ICC computes the intra class correlation. The ICC corresponds to the proportion of the total variance in the residuals that is accounted for by the clustering variable at hand (Kutner <em>et al.</em>, 2005).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ICC(Cluster, Test.Score, Dataset, CI = 0.95)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ICC_+3A_cluster">Cluster</code></td>
<td>
<p>The name of the clustering variable in the dataset.</p>
</td></tr>
<tr><td><code id="ICC_+3A_test.score">Test.Score</code></td>
<td>
<p>The name of the outcome variable in the dataset (e.g., a test score).</p>
</td></tr>
<tr><td><code id="ICC_+3A_dataset">Dataset</code></td>
<td>
<p>A dataset.</p>
</td></tr>
<tr><td><code id="ICC_+3A_ci">CI</code></td>
<td>
<p>The required confidence limits around the ICC. Default <code>CI=.95</code>, i.e. the 95 CI.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is a modification of the <code>ICCest</code> function from the <code>ICC</code> package (v2.3.0), with minimal changes. For details of the original function, see https://cran.r-project.org/web/packages/ICC/ICC.pdf. The author of the original function is Matthew Wolak.</p>


<h3>Value</h3>

<p>An object of class <code>ICC</code> with component,
</p>
<table>
<tr><td><code>ICC</code></td>
<td>
<p>The intra class correlation coefficient.</p>
</td></tr> 
<tr><td><code>LowerCI</code></td>
<td>
<p>The lower bound of the CI around the ICC.</p>
</td></tr>
<tr><td><code>UpperCI</code></td>
<td>
<p>The upper bound of the CI around the ICC.</p>
</td></tr>
<tr><td><code>Num.Clusters</code></td>
<td>
<p>The number of clusters in the dataset.</p>
</td></tr>
<tr><td><code>Mean.Cluster.Size</code></td>
<td>
<p>The mean number of observations per cluster.</p>
</td></tr>
<tr><td><code>Data</code></td>
<td>
<p>The dataset used in the analysis (observations with missing values are excluded).</p>
</td></tr>
<tr><td><code>N.Dataset</code></td>
<td>
<p>The sample size of the full dataset.</p>
</td></tr>
<tr><td><code>N.Removed</code></td>
<td>
<p>The number of observations that are removed due to missingness.</p>
</td></tr>
<tr><td><code>alpha</code></td>
<td>
<p>The specified <code class="reqn">\alpha</code>-level for the CI, i.e., <code class="reqn">\alpha</code> = 1 - CI.</p>
</td></tr>
<tr><td><code>Labels.Cluster</code></td>
<td>
<p>The labels of the clustering variable.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Original function: Matthew Wolak (with some small modifications by Wim Van der Elst)
</p>


<h3>References</h3>

<p>https://cran.r-project.org/web/packages/ICC/ICC.pdf
</p>
<p>Kutner, M. H., Nachtsheim, C. J., Neter, J., and Li, W. (2005). <em>Applied linear statistical models</em> (5th edition). New York: McGraw Hill.
</p>
<p>Van der Elst, W. (2024). <em>Regression-based normative data for psychological assessment: A hands-on approach using R.</em> Springer Nature. 
</p>


<h3>See Also</h3>

<p><a href="#topic+plot.ICC">plot.ICC</a></p>


<h3>Examples</h3>

<pre><code class='language-R'># Compute ICC in Substitution dataset, using Test.Administrator as 
# clustering unit
data(Substitution)

# Add administrator to the dataset (just randomly allocate labels 
# as Test.Administrator, so ICC should be approx. 0)
Substitution$Test.Adminstrator &lt;- NA
Substitution$Test.Adminstrator &lt;- sample(LETTERS[1:10], 
  replace = TRUE, size = length(Substitution$Test.Adminstrator))
Substitution$Test.Adminstrator &lt;- 
  as.factor(Substitution$Test.Adminstrator)

ICC_LDST &lt;- ICC(Cluster = Test.Adminstrator, Test.Score = LDST, Data = Substitution)

# Explore results
summary(ICC_LDST)
plot(ICC_LDST)
</code></pre>

<hr>
<h2 id='Levels'>Explore data</h2><span id='topic+Levels'></span>

<h3>Description</h3>

<p>Gives the levels of a variable.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Levels(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Levels_+3A_x">x</code></td>
<td>
<p>A variable for which the different levels should be printed.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For details, see Van der Elst (2023).
</p>


<h3>Value</h3>

<p>No return value, called for side effects.</p>


<h3>Author(s)</h3>

<p>Wim Van der Elst
</p>


<h3>References</h3>

<p>Van der Elst, W. (2024). <em>Regression-based normative data for psychological assessment: A hands-on approach using R.</em> Springer Nature. 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(Substitution)
Levels(Substitution$Gender)
</code></pre>

<hr>
<h2 id='Personality'>Data of the Openness scale of a personality test</h2><span id='topic+Personality'></span>

<h3>Description</h3>

<p>These are the data of the Openness subscale of International Personality Item Pool (ipip.ori.org). This subscale consists of 5 items: 1 = <em>I am full of ideas</em>, 2 = <em>I avoid difficult reading material</em>, 3 = <em>I carry the conversation to a higher level</em>, 4 = <em>I spend time reflecting on things</em>, and 5 = <em>I will not probe deeply into a subject</em>. Each item is scored on a 6-point response scale with answer categories 1 = very inaccurate, 2 = moderately inaccurate, 3 = slightly inaccurate, 4 = slightly accurate, 5 = moderately accurate, and 6 = very accurate. The Openness scale score corresponds to the sum of the individual item scores, with items 2 and 5 being reverse scored. The raw Openness scale score ranges between 5 and 30. A higher score is indicative of higher levels of curiosity, intellectualism, imagination, and aesthetic interests (McCrae, 1994).
</p>
<p>The data were collected as part of the Synthetic Apeture Personality Assessment (SAPA http://sapa-project.org) web-based personality assessment project.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(Personality)</code></pre>


<h3>Format</h3>

<p>A <code>data.frame</code> with 2137 observations on 3 variables.
</p>

<dl>
<dt><code>Id</code></dt><dd><p>The Id number of the participant.</p>
</dd>
<dt><code>LE</code></dt><dd><p>The Level of Education (LE) of the participant, coded as 1 = less than high school, 2 = finished high school, 3 = some college but did not graduate, 4 = college graduate, and 5 = graduate degree.</p>
</dd>
<dt><code>Openness</code></dt><dd><p>Level of Openness.</p>
</dd></dl>



<h3>References</h3>

<p>McCrae, R. R. (1994). Openness to Experience: expanding the boundaries of factor V. <em>European Journal of Personality, 8,</em> 251-272.
</p>
<p>Van der Elst, W. (2024). <em>Regression-based normative data for psychological assessment: A hands-on approach using R.</em> Springer Nature. 
</p>

<hr>
<h2 id='plot+20Bootstrap.Stage.2.NormScore'>Plot the bootstrap distribution and the percentile bootstrap CI</h2><span id='topic+plot+20Bootstrap.Stage.2.NormScore'></span><span id='topic+plot.Bootstrap.Stage.2.NormScore'></span>

<h3>Description</h3>

<p>This function plots the bootstrap distribution and the percentile bootstrap CI for a test score based on a <code>Bootstrap.Stage.2.NormScore</code> object. A non-parametric bootstrap is used to compute a confidence interval (CI) around the estimated percentile rank (for details, see Chapter 8 in Van der Elst, 2023). 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'Bootstrap.Stage.2.NormScore'
plot(x, 
cex.axis=1, cex.main=1, cex.lab=1, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot+2B20Bootstrap.Stage.2.NormScore_+3A_x">x</code></td>
<td>
<p>A fitted object of class <code>Bootstrap.Stage.2.NormScore</code>.</p>
</td></tr>
<tr><td><code id="plot+2B20Bootstrap.Stage.2.NormScore_+3A_cex.axis">cex.axis</code></td>
<td>
<p>The magnification to be used for axis annotation.</p>
</td></tr>
<tr><td><code id="plot+2B20Bootstrap.Stage.2.NormScore_+3A_cex.main">cex.main</code></td>
<td>
<p>The magnification to be used for the main label.</p>
</td></tr>
<tr><td><code id="plot+2B20Bootstrap.Stage.2.NormScore_+3A_cex.lab">cex.lab</code></td>
<td>
<p>The magnification to be used for X and Y labels.</p>
</td></tr>
<tr><td><code id="plot+2B20Bootstrap.Stage.2.NormScore_+3A_...">...</code></td>
<td>
<p>Other arguments to be passed to the <code>plot()</code> function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>No return value, called for side effects.</p>


<h3>Author(s)</h3>

<p>Wim Van der Elst
</p>


<h3>References</h3>

<p>Van der Elst, W. (2024). <em>Regression-based normative data for psychological assessment: A hands-on approach using R.</em> Springer Nature. 
</p>


<h3>See Also</h3>

<p><a href="#topic+Bootstrap.Stage.2.NormScore">Bootstrap.Stage.2.NormScore</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  # Time-intensive part
# Replicate the bootstrap results that were obtained in 
# Case study 1 of Chapter 8 in Van der Elst (2023)
# -----------------------------------------------------
library(NormData) # load the NormData package
data(GCSE)        # load the GCSE dataset

# Fit the Stage 1 model
Model.1.GCSE &lt;- Stage.1(Dataset=GCSE, 
  Model=Science.Exam~Gender)

# Stage 2: Convert a science exam score = 30 obtained by a 
# female into a percentile rank (point estimate)
Normed_Score &lt;- Stage.2.NormScore(Stage.1.Model=Model.1.GCSE,
  Score=list(Science.Exam=30, Gender="F"), Rounded = FALSE)
summary(Normed_Score)

# Derive the 99pc CI around the point estimate 
# using a bootstrap procedure
Bootstrap_Normed_Score &lt;- Bootstrap.Stage.2.NormScore(
  Stage.2.NormScore=Normed_Score)

summary(Bootstrap_Normed_Score)

plot(Bootstrap_Normed_Score)


# Replicate the bootstrap results that were obtained in 
# Case study 2 of Chapter 8 in Van der Elst (2023)
# ------------------------------------------------
library(NormData)   # load the NormData package
data(Substitution)  # load the Substitution dataset

# Make the new variable Age.C (= Age centered) that is 
# needed to fit the final Stage 1 model, 
# and add it to the Substitution dataset
Substitution$Age.C &lt;- Substitution$Age - 50

# Fit the final Stage 1 model
Substitution.Model.9 &lt;- Stage.1(Dataset=Substitution, 
  Alpha=0.005, Model=LDST~Age.C+LE, Order.Poly.Var=1) 
summary(Substitution.Model.9)

# Convert an LDST score = 40 obtained by a 
# 20-year-old test participant with LE=Low 
# into a percentile rank (point estimate)
Normed_Score &lt;- Stage.2.NormScore(
   Stage.1.Model=Substitution.Model.9, 
   Score=list(LDST=40, Age.C=20-50, LE = "Low"), 
   Rounded = FALSE)

# Derive the 99pc CI around the point estimate 
# using a bootstrap
Bootstrap_Normed_Score &lt;- Bootstrap.Stage.2.NormScore(
   Stage.2.NormScore = Normed_Score)
summary(Bootstrap_Normed_Score)
plot(Bootstrap_Normed_Score)

</code></pre>

<hr>
<h2 id='plot+20CheckFit'>Evaluate the fit of the mean structure of a fitted Stage 1 model.</h2><span id='topic+plot+20CheckFit'></span><span id='topic+plot.CheckFit'></span>

<h3>Description</h3>

<p>The function <code>CheckFit()</code> allows for evaluating the fit of the mean structure of a regression model by comparing sample means and model-predicted means. This function plots the sample means (with CIs) and the means of the model-predicted values. If the model fits the data well, there should be a good agreement between the sample means and the predicted mean test scores in the relevant subgroups. When the model only contains (binary and/or non-binary) qualitative independent variables, the subgroups correspond to all possible combinations of the different levels of the qualitative variables. When there are quantitative independent variables in the model, these have to be discretized first.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'CheckFit'
plot(x, Color, pch, lty, 
Width.CI.Lines=.125, Size.symbol = 1, 
No.Overlap.X.Axis=TRUE, xlab, ylab="Test score", 
main = " ", Legend.text.size=1, Connect.Means, 
cex.axis=1, cex.main=1.5, cex.lab=1.5, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot+2B20CheckFit_+3A_x">x</code></td>
<td>
<p>A fitted object of class <code>CheckFit</code>.</p>
</td></tr>
<tr><td><code id="plot+2B20CheckFit_+3A_color">Color</code></td>
<td>
<p>The colors to be used for the means. If not specified, the default colors are used.</p>
</td></tr>
<tr><td><code id="plot+2B20CheckFit_+3A_pch">pch</code></td>
<td>
<p>The symbols to be used for the means. If not specified, dots are used.</p>
</td></tr>
<tr><td><code id="plot+2B20CheckFit_+3A_lty">lty</code></td>
<td>
<p>The line types to be used for the means. If not specified, solid lines are used.</p>
</td></tr>
<tr><td><code id="plot+2B20CheckFit_+3A_width.ci.lines">Width.CI.Lines</code></td>
<td>
<p>The width of the horizontal lines that are used to depict the CI around the mean. Default <code>Width.CI.Lines=0.125</code>.</p>
</td></tr>
<tr><td><code id="plot+2B20CheckFit_+3A_size.symbol">Size.symbol</code></td>
<td>
<p>The size of the symbol used to depict the mean test score. Default <code>Size.symbol=1</code>.</p>
</td></tr>
<tr><td><code id="plot+2B20CheckFit_+3A_no.overlap.x.axis">No.Overlap.X.Axis</code></td>
<td>
<p>Logical. When a plot is constructed using two IVs (i.e., 2 or more lines of the mean and CIs in the plot), it is possible that the plot is unclear because the different means and CIs can no longer be distinguished. To avoid this, the levels of IV1 (plotted on the X-axis) can be assigned slightly different values for each level of IV2. For example, the mean for the subcategory males in age range [20; 40] will be shown at value X=0.9 (rather than 1) and the mean for the subcategory females in age range [20; 40] will be shown at value X=1.1 (rather than 1). In this way, the different means and CIs can be more clearly distinguished. Default <code>No.Overlap.X.Axis=TRUE</code>.</p>
</td></tr>
<tr><td><code id="plot+2B20CheckFit_+3A_xlab">xlab</code></td>
<td>
<p>The label that should be added to the X-axis.</p>
</td></tr>
<tr><td><code id="plot+2B20CheckFit_+3A_ylab">ylab</code></td>
<td>
<p>The label that should be added to the Y-axis. Default <code>ylab="Test score"</code>.</p>
</td></tr>
<tr><td><code id="plot+2B20CheckFit_+3A_main">main</code></td>
<td>
<p>The title of the plot. Default <code>main=" "</code>.</p>
</td></tr>
<tr><td><code id="plot+2B20CheckFit_+3A_legend.text.size">Legend.text.size</code></td>
<td>
<p>The size of the text of the label for IV2. Default <code>Legend.text.size=1</code>.</p>
</td></tr>
<tr><td><code id="plot+2B20CheckFit_+3A_connect.means">Connect.Means</code></td>
<td>
<p>Logical. Should the symbols depicting the mean test scores be connected? If not specified, <code>Connect.Means = TRUE</code> is used if the model contains numeric independent variables and <code>Connect.Means = FALSE</code> otherwise.</p>
</td></tr>
<tr><td><code id="plot+2B20CheckFit_+3A_cex.axis">cex.axis</code></td>
<td>
<p>The size of the labels on the X- and Y-axis. Default <code>cex.axis=1</code>.</p>
</td></tr>  
<tr><td><code id="plot+2B20CheckFit_+3A_cex.main">cex.main</code></td>
<td>
<p>The magnification to be used for the main label.</p>
</td></tr>
<tr><td><code id="plot+2B20CheckFit_+3A_cex.lab">cex.lab</code></td>
<td>
<p>The magnification to be used for X and Y labels.</p>
</td></tr>
<tr><td><code id="plot+2B20CheckFit_+3A_...">...</code></td>
<td>
<p>Extra graphical parameters to be passed to <code>plot()</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>No return value, called for side effects.</p>


<h3>Author(s)</h3>

<p>Wim Van der Elst
</p>


<h3>References</h3>

<p>Van der Elst, W. (2024). <em>Regression-based normative data for psychological assessment: A hands-on approach using R.</em> Springer Nature. 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Stage.1">Stage.1</a></code>, <code><a href="#topic+plot.CheckFit">plot.CheckFit</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'># Replicate the fit plot that was obtained in 
# Case study 1 of Chapter 7 in Van der Elst (2023)
# ------------------------------------------------
library(NormData)   # load the NormData package
data(Substitution)  # load the Substitution dataset
head(Substitution)  # have a look at the first datalines in
# the Substitution dataset

# Final Stage 1 model 
Substitution$Age.C &lt;- Substitution$Age - 50
  # Add Age_Group (that discretizes the quantitative variable Age 
  # into 6 groups with a span of 10 years in the dataset for use 
  # by the CheckFit() function later on)
Substitution$Age_Group &lt;- cut(Substitution$Age, 
   breaks=seq(from=20, to=80, by=10)) 
Substitution.Model.9 &lt;- Stage.1(Dataset=Substitution, 
   Alpha=0.005, Model=LDST~Age.C+LE, Order.Poly.Var=1) 

# Examine fit 
Fit.LDST &lt;- CheckFit(Stage.1.Model=Substitution.Model.9, 
  Means=LDST~Age_Group+LE)
summary(Fit.LDST) 
plot(Fit.LDST)


# Replicate the fit plot that was obtained in 
# Case study 2 of Chapter 7 in Van der Elst (2023)
# ------------------------------------------------
library(NormData)   # load the NormData package
data(VLT)           # load the VLT dataset
head(VLT)           # have a look at the first datalines in 
                    # the VLT dataset

# Fit the final Stage 1 model
VLT$Age.C &lt;- VLT$Age - 50
VLT$Age.C2 &lt;- (VLT$Age - 50)**2
  # Add Age_Group (that discretizes the quantitative variable Age 
  # into 6 groups with a span of 10 years in the dataset for use 
  # by the CheckFit() function later on)
VLT$Age_Group &lt;- cut(VLT$Age, breaks=seq(from=20, to=80, by=10)) 

VLT.Model.4 &lt;- Stage.1(Dataset = VLT, Alpha = .005, 
  Model = Total.Recall ~ Age.C+Age.C2+Gender+LE+Age.C:Gender)

# Examine fit using fit plots for the Age Group by 
# LE by Gender subgroups
Fit.Means.Total.Recall &lt;- CheckFit(Stage.1.Model=VLT.Model.4, 
  Means=Total.Recall~Age_Group+LE+Gender)

summary(Fit.Means.Total.Recall)
plot(Fit.Means.Total.Recall)
</code></pre>

<hr>
<h2 id='plot+20ExploreData'>Plot means and CIs for test scores.</h2><span id='topic+plot+20ExploreData'></span><span id='topic+plot.ExploreData'></span>

<h3>Description</h3>

<p>Plot the means (and CIs) for the test scores, stratified by the independent variable(s) of interest. The independent variables should be factors (i.e., binary or non-binary qualitiative variables).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'ExploreData'
plot(x, Width.CI.Lines=.125, Size.symbol = 1,
No.Overlap.X.Axis=TRUE, xlab, ylab="Test score", main, 
Color, pch, lty, Black.white=FALSE, Legend.text.size=1, 
Connect.Means = TRUE, Error.Bars = "CI", 
cex.axis=1, cex.main=1, cex.lab=1, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot+2B20ExploreData_+3A_x">x</code></td>
<td>
<p>A fitted object of class <code>ExploreData</code>.</p>
</td></tr>
<tr><td><code id="plot+2B20ExploreData_+3A_width.ci.lines">Width.CI.Lines</code></td>
<td>
<p>The width of the horizontal lines that are used to depict the CI around the mean. Default <code>Width.CI.Lines=0.125</code>.</p>
</td></tr>
<tr><td><code id="plot+2B20ExploreData_+3A_size.symbol">Size.symbol</code></td>
<td>
<p>The size of the symbol used to depict the mean test score. Default <code>Size.symbol=1</code>.</p>
</td></tr>
<tr><td><code id="plot+2B20ExploreData_+3A_no.overlap.x.axis">No.Overlap.X.Axis</code></td>
<td>
<p>Logical. When a plot is constructed using multiple IVs (specified in the <code>Model=</code> argument of the <code>ExploreData()</code> function), it is possible that the plot becomes unclear because the different means (and CIs) largely overlap. To avoid this, the levels of IV1 (plotted on the X-axis) can be slightly shifted for each level of IV2. For example, if IV1=Age group and IX2=Gender, the mean for the subcategory males in age range [20; 40] will be shown at value 0.9 on the X-axis (rather than 1) and the mean for the subcategory females in age range [20; 40] will be shown at value 1.1 (rather than 1), and similarly for all levels of IV1. In this way, the different means and CIs can be more clearly distinguished. Default <code>No.Overlap.X.Axis=TRUE</code>.</p>
</td></tr>
<tr><td><code id="plot+2B20ExploreData_+3A_xlab">xlab</code></td>
<td>
<p>The label that should be added to the X-axis.</p>
</td></tr>
<tr><td><code id="plot+2B20ExploreData_+3A_ylab">ylab</code></td>
<td>
<p>The label that should be added to the Y-axis. Default <code>ylab="Test score"</code>.</p>
</td></tr>
<tr><td><code id="plot+2B20ExploreData_+3A_main">main</code></td>
<td>
<p>The title of the plot.</p>
</td></tr>
<tr><td><code id="plot+2B20ExploreData_+3A_color">Color</code></td>
<td>
<p>The colors that should be used for the means. If not specified, the default colors are used.</p>
</td></tr>
<tr><td><code id="plot+2B20ExploreData_+3A_pch">pch</code></td>
<td>
<p>The symbols to be used for the means. If not specified, dots are used.</p>
</td></tr>
<tr><td><code id="plot+2B20ExploreData_+3A_lty">lty</code></td>
<td>
<p>The line types to be used for the means. If not specified, solid lines are used (i.e., <code>lty=1</code>.</p>
</td></tr>
<tr><td><code id="plot+2B20ExploreData_+3A_black.white">Black.white</code></td>
<td>
<p>Logical. Should the plot be in black and white (rather than in color)? Default <code>Black.white=FALSE</code>.</p>
</td></tr>
<tr><td><code id="plot+2B20ExploreData_+3A_legend.text.size">Legend.text.size</code></td>
<td>
<p>The size of the text of the label for IV2. Default <code>Legend.text.size=1</code>.</p>
</td></tr>
<tr><td><code id="plot+2B20ExploreData_+3A_connect.means">Connect.Means</code></td>
<td>
<p>Logical. Should the symbols depicting the mean test scores be connected? Default <code>Connect.Means = TRUE</code>.</p>
</td></tr>
<tr><td><code id="plot+2B20ExploreData_+3A_error.bars">Error.Bars</code></td>
<td>
<p>The type of error bars around the means that should be added in the plot: confidence intervals (<code>Error.Bars = "CI"</code>), standard errors (<code>Error.Bars = "SE"</code>), standard deviations (<code>Error.Bars = "SD"</code>) or no error bars  (<code>Error.Bars = "None"</code>). Default <code>Error.Bars = "CI"</code>.</p>
</td></tr>
<tr><td><code id="plot+2B20ExploreData_+3A_cex.axis">cex.axis</code></td>
<td>
<p>The magnification to be used for axis annotation.</p>
</td></tr>
<tr><td><code id="plot+2B20ExploreData_+3A_cex.main">cex.main</code></td>
<td>
<p>The magnification to be used for the main label.</p>
</td></tr>
<tr><td><code id="plot+2B20ExploreData_+3A_cex.lab">cex.lab</code></td>
<td>
<p>The magnification to be used for X and Y labels.</p>
</td></tr>
<tr><td><code id="plot+2B20ExploreData_+3A_...">...</code></td>
<td>
<p>Extra graphical parameters to be passed to <code>plot()</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>No return value, called for side effects.</p>


<h3>Author(s)</h3>

<p>Wim Van der Elst
</p>


<h3>References</h3>

<p>Van der Elst, W. (2024). <em>Regression-based normative data for psychological assessment: A hands-on approach using R.</em> Springer Nature. 
</p>


<h3>See Also</h3>

<p><a href="#topic+ExploreData">ExploreData</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Replicate the exploratory analyses that were conducted  
# in Case study 1 of Chapter 5 in Van der Elst (2023)
# ------------------------------------------------------
library(NormData) # load the NormData package

data(Personality) # load the Personality dataset
Explore_Openness &lt;- ExploreData(Dataset=Personality, 
  Model=Openness~LE)
summary(Explore_Openness)
plot(Explore_Openness, 
  main="Mean Openness scale scores and 99pc CIs")


# Replicate the exploratory analyses that were conducted  
# in Case study 1 of Chapter 7 in Van der Elst (2023)
# ------------------------------------------------------
library(NormData)   # load the NormData package
data(Substitution)  # load the Substitution dataset
head(Substitution)  # have a look at the first datalines in
                    # the Substitution dataset

# First make a new variable Age_Group, that discretizes the
# quantitative variable Age into 6 groups with a span of 10 years
Substitution$Age_Group &lt;- cut(Substitution$Age, 
   breaks=seq(from=20, to=80, by=10)) 

# Compute descriptives of the LDST score for different Age Group
# by LE combinations
Explore.LDST.Age.LE &lt;- ExploreData(Dataset=Substitution,
   Model=LDST~Age_Group+LE) 
summary(Explore.LDST.Age.LE)

# Make a plot of the results. 
plot(Explore.LDST.Age.LE, 
   main="Mean (99pc CI) LDST scores by Age group and LE")

# Compute descriptives of the LDST score for different
# Age Group by Gender combinations
Explore.LDST.Age.Gender &lt;- ExploreData(Dataset=Substitution, 
  Model=LDST~Age_Group+Gender)

# Plot the results
plot(Explore.LDST.Age.Gender, 
  main="Mean (99pc CI) LDST scores by Age group and Gender")

# Compute descriptives of the LDST score for different
# LE by Gender combinations
Explore.LDST.LE.Gender &lt;-
  ExploreData(Dataset=Substitution, Model=LDST~LE+Gender)

# Plot the results
plot(Explore.LDST.LE.Gender,
  main="Mean (99pc CI) LDST scores by LE and Gender")

# Compute summary statistics of the LDST score in the
# Age Group by LE by Gender combinations
Explore.LDST &lt;- ExploreData(Dataset=Substitution,
   Model=LDST~Age_Group+LE+Gender)

# Plot the results
plot(Explore.LDST)
</code></pre>

<hr>
<h2 id='plot+20ICC'>Graphical depiction of the ICC.</h2><span id='topic+plot+20ICC'></span><span id='topic+plot.ICC'></span>

<h3>Description</h3>

<p>The ICC corresponds to the proportion of the total variance in the residuals that is accounted for by the clustering variable at hand (Kutner <em>et al.</em>, 2005). This function visualizes the extent ot which there is clustering in the dataset. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'ICC'
plot(x, X.Lab="Cluster", Y.Lab="Test score", 
Main="", Add.Jitter=0.2, Size.Points=1, Size.Labels=1, 
Add.Mean.Per.Cluster=TRUE, Col.Mean.Symbol="red", Seed=123, 
...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot+2B20ICC_+3A_x">x</code></td>
<td>
<p>A fitted object of class <code>ICC</code>.</p>
</td></tr>
<tr><td><code id="plot+2B20ICC_+3A_x.lab">X.Lab</code></td>
<td>
<p>The label that should be added to the X-axis. <code>X.Lab="Cluster"</code>.</p>
</td></tr>
<tr><td><code id="plot+2B20ICC_+3A_y.lab">Y.Lab</code></td>
<td>
<p>The label that should be added to the Y-axis. <code>Y.Lab="Test score"</code>.</p>
</td></tr>
<tr><td><code id="plot+2B20ICC_+3A_main">Main</code></td>
<td>
<p>The title of the plot. Default <code>Main=" "</code>, i.e., no title.</p>
</td></tr>
<tr><td><code id="plot+2B20ICC_+3A_add.jitter">Add.Jitter</code></td>
<td>
<p>The amount of jitter (random noise) that should be added in the horizontal direction (predicted scores, X-axis) of the plot. Adding a bit of jitter is useful to show the inidividual data points more clearly. The specified value <code>Add.Jitter=</code> in the function call determines the amount of jitter (range of values) that is added. For example, when <code>Add.Jitter=0.2</code>, a random value between -0.2 and 0.2 (sampled from a uniform) is added to the X-axis. Default <code>Add.Jitter=0.2</code>.</p>
</td></tr>
<tr><td><code id="plot+2B20ICC_+3A_size.points">Size.Points</code></td>
<td>
<p>The size of the points in the plot. Default <code>Size.Points=1</code>.</p>
</td></tr>
<tr><td><code id="plot+2B20ICC_+3A_size.labels">Size.Labels</code></td>
<td>
<p>The size of the Labels of the X-axis in the plot. Default <code>Size.Labels=1</code>.</p>
</td></tr>
<tr><td><code id="plot+2B20ICC_+3A_add.mean.per.cluster">Add.Mean.Per.Cluster</code></td>
<td>
<p>Logical. Should the means per cluster be shown? <br /> Default <code>Add.Mean.Per.Cluster=TRUE</code>.</p>
</td></tr>
<tr><td><code id="plot+2B20ICC_+3A_col.mean.symbol">Col.Mean.Symbol</code></td>
<td>
<p>The color of the symbol that is used to indicate the mean (for each of the clusters). Default <code>Col.Mean.Symbol="red"</code>.</p>
</td></tr>
<tr><td><code id="plot+2B20ICC_+3A_seed">Seed</code></td>
<td>
<p>The random seed that is used to add jitter. Default <code>Seed=123</code>.</p>
</td></tr>
<tr><td><code id="plot+2B20ICC_+3A_...">...</code></td>
<td>
<p>Other arguments to be passed to the plot function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>No return value, called for side effects.</p>


<h3>Author(s)</h3>

<p>Wim Van der Elst
</p>


<h3>References</h3>

<p>Kutner, M. H., Nachtsheim, C. J., Neter, J., and Li, W. (2005). <em>Applied linear statistical models</em> (5th edition). New York: McGraw Hill.
</p>
<p>Van der Elst, W. (2024). <em>Regression-based normative data for psychological assessment: A hands-on approach using R.</em> Springer Nature. 
</p>


<h3>See Also</h3>

<p><a href="#topic+ICC">ICC</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Compute ICC in Substitution dataset, using Test.Administrator as 
# clustering unit
data(Substitution)

# Add administrator to the dataset (just randomly allocate labels 
# as Test.Administrator, so ICC should be approx. 0)
Substitution$Test.Adminstrator &lt;- NA
Substitution$Test.Adminstrator &lt;- sample(LETTERS[1:10], 
  replace = TRUE, size = length(Substitution$Test.Adminstrator))
Substitution$Test.Adminstrator &lt;- 
  as.factor(Substitution$Test.Adminstrator)

ICC_LDST &lt;- ICC(Cluster = Test.Adminstrator, Test.Score = LDST, Data = Substitution)

# Explore results
summary(ICC_LDST)
plot(ICC_LDST)

# Make points in the plot a bit larger and reduce 
# the size of labels on the X-axis (initials test administrators)
plot(ICC_LDST, Size.Labels = .5, Size.Points=.5)
</code></pre>

<hr>
<h2 id='plot+20Stage.1'>Check the model assumptions for a fitted Stage 1 model graphically.</h2><span id='topic+plot+20Stage.1'></span><span id='topic+plot.Stage.1'></span>

<h3>Description</h3>

<p>This function provides several plots that are useful to evaluate model assumptions. When the <code>plot()</code> function is applied to a fitted <code>Stage.1</code> object, three panels are generated. These panels show plots that can be used (i) to evaluate the homoscedasticity assumption, (ii) to evaluate the normality assumption, and (iii) to evaluate the presence of outliers. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'Stage.1'
plot(x, Homoscedasticity=TRUE, Normality=TRUE, 
Outliers=TRUE, Assume.Homoscedasticity, Add.Jitter=0, Seed=123, 
Confidence.QQ.Normality=.99, Plots.Together=TRUE, 
Y.Lim.ResVarFunction, Group.Spec.Densities.Delta=FALSE, Main.Homosced.1,
Main.Homosced.2, Main.Norm.1, Main.Norm.2, Main.Norm.3, Main.Outliers, 
cex.axis.homo=1, cex.main.homo=1, cex.lab.homo=1,  
cex.axis.norm=1.6, cex.main.norm=1.5, cex.lab.norm=1.5,  
cex.axis.outl=1, cex.main.outl=1, cex.lab.outl=1,  
Color="red", Loess.Span=0.75, verbose=TRUE, ...)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot+2B20Stage.1_+3A_x">x</code></td>
<td>
<p>A fitted object of class <code>Stage.1</code>.</p>
</td></tr>
<tr><td><code id="plot+2B20Stage.1_+3A_homoscedasticity">Homoscedasticity</code></td>
<td>
<p>Logical. Should plots to evaluate homoscedasticity be shown? <br />  Default <code>Homoscedasticity=TRUE</code>.</p>
</td></tr>
<tr><td><code id="plot+2B20Stage.1_+3A_normality">Normality</code></td>
<td>
<p>Logical. Should plots to evaluate the normality assumption be shown? The normality plots are based on the standardized residuals in the normative dataset, which are computed as explained in the <code>Assume.Homoscedasticity=</code> argument documentation below. Default <code>Normality=TRUE</code>.</p>
</td></tr>
<tr><td><code id="plot+2B20Stage.1_+3A_outliers">Outliers</code></td>
<td>
<p>Logical. Should plots to evaluate outliers be shown? The outlier plot is based on the standardized residuals in the normative dataset, which are computed as explained in the <code>Assume.Homoscedasticity=</code> argument documentation below. Default <code>Outliers=TRUE</code>.</p>
</td></tr>
<tr><td><code id="plot+2B20Stage.1_+3A_assume.homoscedasticity">Assume.Homoscedasticity</code></td>
<td>

<p>By default, the standardized residuals <code class="reqn">\widehat{\delta}_i</code>  that are shown in the normality and outlier plots are computed based on the overall residual standard error when the homoscedasticity assumption is valid (i.e., as <code class="reqn">\widehat{\delta}_i = \frac{\widehat{\varepsilon}_i}{\widehat{\sigma}^2_{\varepsilon}}</code>, with  <code class="reqn">\widehat{\sigma}^2_{\varepsilon}</code> corresponding to the overall residual standard error), or based on prediction-specific residual standard errors when the homoscedasticity assumption is invalid (i.e., as <code class="reqn">\widehat{\delta}_i = \frac{\widehat{\varepsilon}_i}{\widehat{\sigma}^2_{\varepsilon_i}}</code>, with  <code class="reqn">\widehat{\sigma}^2_{\varepsilon_i}</code> corresponding to e.g., a cubic polynomial variance prediction function <code class="reqn">\widehat{\sigma}^2_{\varepsilon_i} = \widehat{\gamma}_0 + \widehat{\gamma}_1 \: \widehat{Y} + \widehat{\gamma}_2 \: \widehat{Y}^2 + {\gamma}_3 \: \widehat{Y}^3</code> when the mean structure of the model contains quantitiative independent variables). The default behaviour of the <code>plot()</code> function can be overruled using the <code>Assume.Homoscedasticity</code> argument. For example, when adding the argument <code>Assume.Homoscedasticity=TRUE</code> to the function call, the standardized residuals that are plotted will be computed based on the overall residual standard error (irrespective of the result of the Levene or Breusch-Pagan test).</p>
</td></tr>
<tr><td><code id="plot+2B20Stage.1_+3A_add.jitter">Add.Jitter</code></td>
<td>
<p>The amount of jitter (random noise) that should be added to the X-axis of the  homoscedasticity plots (which show the model-predicted mean values). Adding a bit of jitter is useful to show the data more clearly (especially when there are only a few unique predicted values, e.g., when a binary or non-binary qualitative independent variable is considered in the mean structure of the model), i.e., to avoid overlapping data points. The specified value <code>Add.Jitter=</code> in the function call determines the amount of jitter (range of values) that is added. For example, when <code>Add.Jitter=0.1</code>, a random value between -0.1 and 0.1 (sampled from a uniform) is added to the predicted values in the homoscedasticity plots (shown on the X-axis). Default <code>Add.Jitter=0</code>, i.e., no jitter added to the predicted values in the homoscedasticity plots.</p>
</td></tr>
<tr><td><code id="plot+2B20Stage.1_+3A_seed">Seed</code></td>
<td>
<p>The seed that is used when adding jitter. Default <code>Seed=123</code>.</p>
</td></tr>
<tr><td><code id="plot+2B20Stage.1_+3A_confidence.qq.normality">Confidence.QQ.Normality</code></td>
<td>
<p>Specifies the desired confidence-level for the confidence band arond the line of perfect agreement/normality in the QQ-plot that is used to evaluate normality. Default <code>Confidence.QQ.Normality=0.95</code>. Use <code>Confidence.QQ.Normality= FALSE</code> if no confidence band is needed.</p>
</td></tr>
<tr><td><code id="plot+2B20Stage.1_+3A_plots.together">Plots.Together</code></td>
<td>
<p>The different homoscedasticity and normality plots are grouped together in a panel by default. For example, the three normality plots are shown together in one panel. If it is preferred to have the different plots in separate panels (rather than grouped to- gether), the argument <code>Plots.Together=FALSE</code> can be used. Default <code>Plots.Together=TRUE</code>.</p>
</td></tr>
<tr><td><code id="plot+2B20Stage.1_+3A_y.lim.resvarfunction">Y.Lim.ResVarFunction</code></td>
<td>
<p>The min, max limits of the Y-axis that should be used for the variance function plot. By default, the limit of the Y-axis is set between <code class="reqn">0</code> and the maximum value of estimated variances multiplied by <code class="reqn">2</code>. This can be changed using the <code>Y.Lim.ResVarFunction</code> argument. For example, adding the argument <code>Y.Lim.ResVarFunction=c(0, 500)</code> sets the range of the Y-axis of the variance function plot from 0 to 500.</p>
</td></tr>
<tr><td><code id="plot+2B20Stage.1_+3A_group.spec.densities.delta">Group.Spec.Densities.Delta</code></td>
<td>
<p>Logical. Should a plot with the group-specific densities of the standardized residuals be shown? Default <code>Group.Spec.Densities.Delta=FALSE</code>.</p>
</td></tr>
<tr><td><code id="plot+2B20Stage.1_+3A_main.homosced.1">Main.Homosced.1</code></td>
<td>
<p>The title of the first panel of the homoscedasticity plot (i.e., the scatterplot of the residuals against the predicted scores).</p>
</td></tr>
<tr><td><code id="plot+2B20Stage.1_+3A_main.homosced.2">Main.Homosced.2</code></td>
<td>
<p>The title of second panel of the homoscedasticity plot (i.e., the variance function plot).</p>
</td></tr>
<tr><td><code id="plot+2B20Stage.1_+3A_main.norm.1">Main.Norm.1</code></td>
<td>
<p>The title of the first panel of the normality plot (i.e., the histogram of the standardized residuals).</p>
</td></tr>
<tr><td><code id="plot+2B20Stage.1_+3A_main.norm.2">Main.Norm.2</code></td>
<td>
<p>The title of the second panel of the normality plot (i.e., the density of the standardized residuals and standard normal distribution).</p>
</td></tr>
<tr><td><code id="plot+2B20Stage.1_+3A_main.norm.3">Main.Norm.3</code></td>
<td>
<p>The title of the third panel of the normality plot (i.e., the QQ-plot).</p>
</td></tr>
<tr><td><code id="plot+2B20Stage.1_+3A_main.outliers">Main.Outliers</code></td>
<td>
<p>The title of the outlier plot.</p>
</td></tr>
<tr><td><code id="plot+2B20Stage.1_+3A_cex.axis.homo">cex.axis.homo</code></td>
<td>
<p>The magnification to be used for axis annotation of the homoscedasticity plots.</p>
</td></tr>
<tr><td><code id="plot+2B20Stage.1_+3A_cex.main.homo">cex.main.homo</code></td>
<td>
<p>The magnification to be used for the main label of the homoscedasticity plots.</p>
</td></tr>
<tr><td><code id="plot+2B20Stage.1_+3A_cex.lab.homo">cex.lab.homo</code></td>
<td>
<p>The magnification to be used for the X- and Y-axis labels of the homoscedasticity plots.</p>
</td></tr>
<tr><td><code id="plot+2B20Stage.1_+3A_cex.axis.norm">cex.axis.norm</code></td>
<td>
<p>The magnification to be used for axis annotation of the normality plots.</p>
</td></tr>
<tr><td><code id="plot+2B20Stage.1_+3A_cex.main.norm">cex.main.norm</code></td>
<td>
<p>The magnification to be used for the main label of the normality plots.</p>
</td></tr>
<tr><td><code id="plot+2B20Stage.1_+3A_cex.lab.norm">cex.lab.norm</code></td>
<td>
<p>The magnification to be used for X and Y labels of the normality plots.</p>
</td></tr>
<tr><td><code id="plot+2B20Stage.1_+3A_cex.axis.outl">cex.axis.outl</code></td>
<td>
<p>The magnification to be used for axis annotation of the outlier plot.</p>
</td></tr>
<tr><td><code id="plot+2B20Stage.1_+3A_cex.main.outl">cex.main.outl</code></td>
<td>
<p>The magnification to be used for the main label of the outlier plot.</p>
</td></tr>
<tr><td><code id="plot+2B20Stage.1_+3A_cex.lab.outl">cex.lab.outl</code></td>
<td>
<p>The magnification to be used for X- and Y-axis labels of the outlier plot.</p>
</td></tr>
<tr><td><code id="plot+2B20Stage.1_+3A_color">Color</code></td>
<td>
<p>The color to be used for the Empirical Variance Function (EVF) and the standard normal distribution in the variance function plot and the normality plot that show the densities of the standardized residuals and the normal distribution, respectively. Default <code>Color="red"</code>.</p>
</td></tr>
<tr><td><code id="plot+2B20Stage.1_+3A_loess.span">Loess.Span</code></td>
<td>
<p>The parameter <code class="reqn">\alpha</code> that determines the degree of smoothing of the EVF that is shown in the variance function plot. Default <code>Loess.Span=0.75</code>.</p>
</td></tr>
<tr><td><code id="plot+2B20Stage.1_+3A_verbose">verbose</code></td>
<td>
<p>A logical value indicating whether verbose output should be generated.</p>
</td></tr>
<tr><td><code id="plot+2B20Stage.1_+3A_...">...</code></td>
<td>
<p>Other arguments to be passed.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>No return value, called for side effects.</p>


<h3>Author(s)</h3>

<p>Wim Van der Elst
</p>


<h3>References</h3>

<p>Van der Elst, W. (2024). <em>Regression-based normative data for psychological assessment: A hands-on approach using R.</em> Springer Nature. 
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Replicate the Stage 1 results that were obtained in 
# Case study 1 of Chapter 4 in Van der Elst (2023)
# ---------------------------------------------------
library(NormData)   # load the NormData package
data(GCSE)          # load the GCSE dataset

# Conduct the Stage 1 analysis
Model.1.GCSE &lt;- Stage.1(Dataset=GCSE, 
  Model=Science.Exam~Gender)

summary(Model.1.GCSE)
plot(Model.1.GCSE, Add.Jitter = .2)

# Use blue color for EVF and density normal distribution
plot(Model.1.GCSE, Add.Jitter = .2, Color="blue")

# Change the title of the variance function plot into
# "Variance function plot, residuals Science exam"
plot(Model.1.GCSE, Add.Jitter = .2, 
  Main.Homosced.2 = "Variance function plot, residuals Science exam")

# Use a 95 percent CI around the line of perfect agreement in the
# QQ plot of normality
plot(Model.1.GCSE, Add.Jitter = .2, 
     Confidence.QQ.Normality = .9)


# Replicate the Stage 1 results that were obtained in 
# Case study 1 of Chapter 7 in Van der Elst (2023)
# ---------------------------------------------------
library(NormData)   # load the NormData package
data(Substitution)  # load the Substitution dataset

# Add the variable Age.C (= Age centered) to the Substitution dataset
Substitution$Age.C &lt;- Substitution$Age - 50

# Fit the final Stage 1 model
Substitution.Model.9 &lt;- Stage.1(Dataset=Substitution, 
   Alpha=0.005, Model=LDST~Age.C+LE,
   Order.Poly.Var=1) # Order.Poly.Var=1 specifies a linear polynomial
                     # for the variance prediction function

# Final Stage 1 model
summary(Substitution.Model.9)
plot(Substitution.Model.9) 

# Request a variance function plot that assumes that 
# the homoscedasticity assumption is valid
plot(Substitution.Model.9, Assume.Homoscedasticity = TRUE) 
</code></pre>

<hr>
<h2 id='plot+20Stage.2.NormScore'>Plot the results for a <code>Stage.2.NormScore</code> object.</h2><span id='topic+plot+20Stage.2.NormScore'></span><span id='topic+plot.Stage.2.NormScore'></span>

<h3>Description</h3>

<p>The function <code>Stage.2.NormScore()</code> is used to convert the raw test score of a tested person <code class="reqn">Y_0</code> into a percentile rank <code class="reqn">\hat{\pi}_0</code> (taking into account specified values of the independent variables). This function plots the results graphically. In particular, the density of the standard normal distribution is shown (when the normality assumption is valid for the fitted Stage 1 model), or the density of the standardized residuals in the normative sample (when the noormality assumption is not shown). The AUC between <code class="reqn">- \infty</code> and the tested person's standarized test score <code class="reqn">\widehat{\delta}_i</code> is shaded in grey, which visualizes the percentile rank that corresponds to the raw test score.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'Stage.2.NormScore'
plot(x, Main=" ", Both.CDFs=FALSE, xlim, 
cex.axis=1, cex.main=1, cex.lab=1, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot+2B20Stage.2.NormScore_+3A_x">x</code></td>
<td>
<p>A fitted object of class <code>Stage.2.NormScore</code>.</p>
</td></tr>
<tr><td><code id="plot+2B20Stage.2.NormScore_+3A_main">Main</code></td>
<td>
<p>The title of the plot. Default <code>Main=" "</code>.</p>
</td></tr>
<tr><td><code id="plot+2B20Stage.2.NormScore_+3A_both.cdfs">Both.CDFs</code></td>
<td>
<p>Should both the densities of the standard normal distribution and of the standardized residuals <code class="reqn">\widehat{\delta}_i</code> in the normative sample be shown in one plot? Default <code>Both.CDFs=FALSE</code>.</p>
</td></tr>
<tr><td><code id="plot+2B20Stage.2.NormScore_+3A_xlim">xlim</code></td>
<td>
<p>The limits for the X-axis. Default <code>xlim=c(-4,4)</code>.</p>
</td></tr>
<tr><td><code id="plot+2B20Stage.2.NormScore_+3A_cex.axis">cex.axis</code></td>
<td>
<p>The magnification to be used for axis annotation.</p>
</td></tr>
<tr><td><code id="plot+2B20Stage.2.NormScore_+3A_cex.main">cex.main</code></td>
<td>
<p>The magnification to be used for the main label.</p>
</td></tr>
<tr><td><code id="plot+2B20Stage.2.NormScore_+3A_cex.lab">cex.lab</code></td>
<td>
<p>The magnification to be used for X and Y labels.</p>
</td></tr>
<tr><td><code id="plot+2B20Stage.2.NormScore_+3A_...">...</code></td>
<td>
<p>Extra graphical parameters to be passed to <code>plot()</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>No return value, called for side effects.</p>


<h3>Author(s)</h3>

<p>Wim Van der Elst
</p>


<h3>References</h3>

<p>Van der Elst, W. (2024). <em>Regression-based normative data for psychological assessment: A hands-on approach using R.</em> Springer Nature. 
</p>


<h3>See Also</h3>

<p><a href="#topic+Stage.2.NormScore">Stage.2.NormScore</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Replicate the normative conversion that was obtained in 
# Case study 1 of Chapter 3 in Van der Elst (2023)
# (science exam score = 30 obtained by a female)
# -------------------------------------------------------
library(NormData) # load the NormData package
data(GCSE)        # load the GCSE dataset

# Fit the Stage 1 model
Model.1.GCSE &lt;- Stage.1(Dataset=GCSE, 
  Model=Science.Exam~Gender)

# Stage 2: Convert a science exam score = 30 obtained by a 
# female into a percentile rank (point estimate)
Normed_Score &lt;- Stage.2.NormScore(Stage.1.Model=Model.1.GCSE,
  Score=list(Science.Exam=30, Gender="F"))

summary(Normed_Score)
plot(Normed_Score)


# Replicate the normative conversion that was obtained in 
# Case study 1 of Chapter 7 in Van der Elst (2023)
# (LDST score = 40 obtained by a 20-year-old 
# test participant with LE=Low)
# -------------------------------------------------------
library(NormData)   # load the NormData package
data(Substitution)  # load the Substitution dataset

# Make the new variable Age.C (= Age centered) that is 
# needed to fit the final Stage 1 model, 
# and add it to the Substitution dataset
Substitution$Age.C &lt;- Substitution$Age - 50

# Fit the final Stage 1 model
Substitution.Model.9 &lt;- Stage.1(Dataset=Substitution, 
  Alpha=0.005, Model=LDST~Age.C+LE, Order.Poly.Var=1) 
summary(Substitution.Model.9)

# Convert an LDST score = 40 obtained by a 
# 20-year-old test participant with LE=Low 
# into a percentile rank (point estimate)
Normed_Score &lt;- Stage.2.NormScore(
   Stage.1.Model=Substitution.Model.9, 
   Score=list(LDST=40, Age.C=20-50, LE = "Low"))

summary(Normed_Score)
plot(Normed_Score)
</code></pre>

<hr>
<h2 id='plot+20Tukey.HSD'>Plot the results of Tukey's Honest Significance Difference test.</h2><span id='topic+plot+20Tukey.HSD'></span><span id='topic+plot.Tukey.HSD'></span>

<h3>Description</h3>

<p>This function plots the results of Tukey's Honest Significance Difference (HSD; Tukey, 1949) test that allows for making post hoc comparisons of the group means. Tukey's HSD can only be conducted when the mean structure of the Stage 1 model only contains qualitative independent variables (i.e., when the fitted regression model is essentially an ANOVA).</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'Tukey.HSD'
plot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot+2B20Tukey.HSD_+3A_x">x</code></td>
<td>
<p>A fitted object of class <code>Tukey.HSD</code>.</p>
</td></tr>
<tr><td><code id="plot+2B20Tukey.HSD_+3A_...">...</code></td>
<td>
<p>Extra graphical parameters to be passed to <code>plot()</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>No return value, called for side effects.</p>


<h3>Author(s)</h3>

<p>Wim Van der Elst
</p>


<h3>References</h3>

<p>Tukey, J. (1949). Comparing individual means in the Analysis of Variance. <em>Biometrics, 5,</em> 99-114.
</p>
<p>Van der Elst, W. (2024). <em>Regression-based normative data for psychological assessment: A hands-on approach using R.</em> Springer Nature.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Tukey.HSD">Tukey.HSD</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>data(Personality)
Model.Openness &lt;- Stage.1(Dataset = Personality, Model = Openness ~ LE) 
# conduct post hoc comparisons for the levels of education
Tukey.Openness &lt;- Tukey.HSD(Model.Openness)
summary(Tukey.Openness)
plot(Tukey.Openness)

# conduct post hoc comparisons for the levels of education by education combinations
data(Substitution)
Model.Substitution &lt;- Stage.1(Dataset = Substitution, Model = LDST ~ LE*Gender)
Tukey.Substitution &lt;- Tukey.HSD(Model.Substitution)
summary(Tukey.Substitution)
plot(Tukey.Substitution)
</code></pre>

<hr>
<h2 id='Plot.Scatterplot.Matrix'>Explore data</h2><span id='topic+Plot.Scatterplot.Matrix'></span>

<h3>Description</h3>

<p>The function <code>Plot.Scatterplot.Matrix()</code> makes a scatterplot matrix of the specified variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Plot.Scatterplot.Matrix(Dataset, Variables, 
Add.Jitter=0.1, Seed=123, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Plot.Scatterplot.Matrix_+3A_dataset">Dataset</code></td>
<td>
<p>The name of the dataset.</p>
</td></tr>
<tr><td><code id="Plot.Scatterplot.Matrix_+3A_variables">Variables</code></td>
<td>
<p>The names of the variables that should be shown in the scatterplot matrix.</p>
</td></tr>
<tr><td><code id="Plot.Scatterplot.Matrix_+3A_add.jitter">Add.Jitter</code></td>
<td>
<p>The amount of jitter (random noise) that should be added to the variables in the scatterplot matrix. Adding a bit of jitter is useful to show the inidividual data points more clearly, especially if several qualitative variables are added in the plot. The specified value <code>Add.Jitter=</code> in the function call determines the amount of jitter (range of values) that is added. For example, when <code>Add.Jitter=0.1</code>, a random value between -0.1 and 0.1 (sampled from a uniform distribution) is added to the datapoints. Default <code>Add.Jitter=0.1</code>.</p>
</td></tr>
<tr><td><code id="Plot.Scatterplot.Matrix_+3A_seed">Seed</code></td>
<td>
<p>The seed that is used when adding jitter. Default <code>Seed=123</code>.</p>
</td></tr>
<tr><td><code id="Plot.Scatterplot.Matrix_+3A_...">...</code></td>
<td>
<p>Extra graphical parameters to be passed to <code>plot()</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For details, see Van der Elst (2023).
</p>


<h3>Value</h3>

<p>No return value, called for side effects.</p>


<h3>Author(s)</h3>

<p>Wim Van der Elst
</p>


<h3>References</h3>

<p>Van der Elst, W. (2024). <em>Regression-based normative data for psychological assessment: A hands-on approach using R.</em> Springer Nature. 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(Substitution)

# Make a scatterplot matrix with the variables LDST, 
# Age, Gender and LE in the Substitution dataset
Plot.Scatterplot.Matrix(Dataset = Substitution, 
Variables = c("LDST", "Age", "Gender", "LE"))
</code></pre>

<hr>
<h2 id='PlotFittedPoly'>Explore data</h2><span id='topic+PlotFittedPoly'></span>

<h3>Description</h3>

<p>The function PlotFittedPoly fits polynomials of a specified order to the data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PlotFittedPoly(Dataset, Test.Score, IV, Center.Value.IV=0,
Order.Polynomial=3, Confidence.Band.Poly=FALSE, Alpha=.01,
EMF = TRUE, Confidence.Band.EMF=TRUE,
xlab, ylab, Color = "red", Black.white=FALSE,
Legend.Location="topright", Legend.text.size=1,
Add.Jitter=0, Seed=123, cex.axis=1, cex.main=1, 
cex.lab=1, Loess.Span=0.75, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PlotFittedPoly_+3A_dataset">Dataset</code></td>
<td>
<p>The name of the dataset.</p>
</td></tr>
<tr><td><code id="PlotFittedPoly_+3A_test.score">Test.Score</code></td>
<td>
<p>The name of the test score.</p>
</td></tr>
<tr><td><code id="PlotFittedPoly_+3A_iv">IV</code></td>
<td>
<p>The name of the independent variable.</p>
</td></tr>
<tr><td><code id="PlotFittedPoly_+3A_center.value.iv">Center.Value.IV</code></td>
<td>
<p>The constant that is subtracted from the independent variable. <br /> Default <code>Center.Value.IV=0</code>.</p>
</td></tr>
<tr><td><code id="PlotFittedPoly_+3A_order.polynomial">Order.Polynomial</code></td>
<td>
<p>The order of the polynomials to be fitted. By default, <code>Order.Polynomial=3</code> and thus a cubic polynomial is fitted. If no polynomial has to be plotted, the argument  <code>Order.Polynomial="None"</code> can be used.</p>
</td></tr>
<tr><td><code id="PlotFittedPoly_+3A_confidence.band.poly">Confidence.Band.Poly</code></td>
<td>
<p>Logical. Should a confidence band around the prediction function of the polynomial model be added to the plot? Default <code>Confidence.Band.Poly=FALSE</code>.</p>
</td></tr>
<tr><td><code id="PlotFittedPoly_+3A_alpha">Alpha</code></td>
<td>
<p>The Alpha-level of the confidence band(s) for the polynomial and/or loess models. Default <code>Alpha=0.01</code> and thus a <code class="reqn">99\%</code> confidence band is fitted.</p>
</td></tr>
<tr><td><code id="PlotFittedPoly_+3A_emf">EMF</code></td>
<td>
<p>Logical. Should the EMF be added to the plot? Default <code>EMF=TRUE</code>.</p>
</td></tr>
<tr><td><code id="PlotFittedPoly_+3A_confidence.band.emf">Confidence.Band.EMF</code></td>
<td>
<p>Logical. Should a confidence band around the prediction function of the loess model be added to the plot? Default <code>Confidence.Band.EMF=TRUE</code>.</p>
</td></tr>
<tr><td><code id="PlotFittedPoly_+3A_xlab">xlab</code></td>
<td>
<p>The label that should be added to the X-axis. Default <code>xlab="IV"</code></p>
</td></tr>
<tr><td><code id="PlotFittedPoly_+3A_ylab">ylab</code></td>
<td>
<p>The label that should be added to the Y-axis. Default <code>ylab="Test score"</code>.</p>
</td></tr>
<tr><td><code id="PlotFittedPoly_+3A_color">Color</code></td>
<td>
<p>The color to be used for the fitted EMF. Default <code>Color = "red"</code>.</p>
</td></tr>
<tr><td><code id="PlotFittedPoly_+3A_black.white">Black.white</code></td>
<td>
<p>Logical. Should the plot be in black and white (rather than in color)? Default <code>Black.white=FALSE</code>.</p>
</td></tr>
<tr><td><code id="PlotFittedPoly_+3A_legend.location">Legend.Location</code></td>
<td>
<p>The location of the legend. Default <code>Legend.Location="topright"</code>. If no legend is needed, the argument <code>Legend.Location="None"</code> can be used.</p>
</td></tr>
<tr><td><code id="PlotFittedPoly_+3A_legend.text.size">Legend.text.size</code></td>
<td>
<p>The size of the text of the label for IV2. Default <code>Legend.text.size=1</code>.</p>
</td></tr>
<tr><td><code id="PlotFittedPoly_+3A_add.jitter">Add.Jitter</code></td>
<td>
<p>The amount of jitter (random noise) that should be added to the test score. Adding a bit of jitter is useful to show the data more clearly, i.e., to avoid overlapping data points. The specified value <code>Add.Jitter=</code> in the function call determines the amount of jitter (range of values) that is added. For example, when <code>Add.Jitter=0.1</code>, a random value between -0.1 and 0.1 (sampled from a uniform) is added to the test  scores. Default <code>Add.Jitter=0</code>, i.e., no jitter added to the predicted values in the homoscedasticity plot.</p>
</td></tr>
<tr><td><code id="PlotFittedPoly_+3A_seed">Seed</code></td>
<td>
<p>The seed that is used when adding jitter. Default <code>Seed=123</code>.</p>
</td></tr>
<tr><td><code id="PlotFittedPoly_+3A_cex.axis">cex.axis</code></td>
<td>
<p>The magnification to be used for axis annotation.</p>
</td></tr>
<tr><td><code id="PlotFittedPoly_+3A_cex.main">cex.main</code></td>
<td>
<p>The magnification to be used for the main label.</p>
</td></tr>
<tr><td><code id="PlotFittedPoly_+3A_cex.lab">cex.lab</code></td>
<td>
<p>The magnification to be used for X and Y labels.</p>
</td></tr>
<tr><td><code id="PlotFittedPoly_+3A_loess.span">Loess.Span</code></td>
<td>
<p>The parameter <code class="reqn">\alpha</code> that determines the degree of smoothing of the Empirical Variance Function. Default <code>Loess.Span=0.75</code>.</p>
</td></tr>
<tr><td><code id="PlotFittedPoly_+3A_...">...</code></td>
<td>
<p>Extra graphical parameters to be passed to <code>plot()</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For details, see Van der Elst (2023).
</p>


<h3>Value</h3>

<p>No return value, called for side effects.</p>


<h3>Author(s)</h3>

<p>Wim Van der Elst
</p>


<h3>References</h3>

<p>Van der Elst, W. (2024). <em>Regression-based normative data for psychological assessment: A hands-on approach using R.</em> Springer Nature. 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(Substitution)

# plot of linear, quadratic and cubic polynomials relating age
# to the LDST test score 
PlotFittedPoly(Dataset = Substitution, Test.Score = LDST, IV = Age, 
Order.Polynomial = 1, Center.Value.IV = 50)

PlotFittedPoly(Dataset = Substitution, Test.Score = LDST, IV = Age, 
Order.Polynomial = 2, Center.Value.IV = 50)

PlotFittedPoly(Dataset = Substitution, Test.Score = LDST, IV = Age, 
Order.Polynomial = 3, Center.Value.IV = 50)
</code></pre>

<hr>
<h2 id='Sandwich'>
Sandwich estimators for standard errors
</h2><span id='topic+Sandwich'></span>

<h3>Description</h3>

<p>The <code>Sandwich()</code> function can be used to obtain heteroscedasticity-consistent standard errors of the regression parameters of a fitted Stage 1 model. These are used to account for heteroscedasticity.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Sandwich(Stage.1.Model, Type="HC0")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Sandwich_+3A_stage.1.model">Stage.1.Model</code></td>
<td>
<p>The fitted stage 1 model for which heteroscedasticity-consistent standard errors (sandwich estimators) for the standard errors of the regression parameters has to be provided.</p>
</td></tr>
<tr><td><code id="Sandwich_+3A_type">Type</code></td>
<td>
<p>The type of the heteroscedasticity-consistent estimator that is used. By default, White's (White, 1980) estimator is used (i.e., <code>Type="HC0"</code>) but other estimators are available. For details, see the <code>vcovHC</code> function of the <code>sandwich</code> package. </p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>Sandwich</code></td>
<td>
<p>The fitted Stage 1 model with sandwich estimators.</p>
</td></tr>
<tr><td><code>Alpha</code></td>
<td>
<p>The significance level that is used for inference. Default <code>Alpha=0.05</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Wim Van der Elst
</p>


<h3>References</h3>

<p>Van der Elst, W. (2024). <em>Regression-based normative data for psychological assessment: A hands-on approach using R.</em> Springer Nature. 
</p>
<p>White, H. (1980). A heteroscedasticity-consistent covariance matrix and a direct test for heteroscedasticity. Econometrica, 48, 817-838.
</p>


<h3>See Also</h3>

<p><a href="#topic+Stage.1">Stage.1</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(GCSE)
Model.1.GCSE &lt;- Stage.1(Dataset = GCSE, Model = Science.Exam~Gender)
Sandwich(Stage.1.Model = Model.1.GCSE)
</code></pre>

<hr>
<h2 id='Stage.1'>Stage 1 of the regression-based normative analysis</h2><span id='topic+Stage.1'></span>

<h3>Description</h3>

<p>The function <code>Stage.1</code> fits a regression model with the specified mean and residual variance components, and conducts several model checks (homoscedasticity, normality, absence of outliers, and multicollinearity) that are useful in a setting where regression-based normative data have to be established.</p>


<h3>Usage</h3>

<pre><code class='language-R'>Stage.1(Dataset, Model, Order.Poly.Var=3, 
Alpha=0.05, Alpha.Homosc=0.05, Alpha.Norm = .05, 
Assume.Homoscedasticity=NULL,
Test.Assumptions=TRUE, Outlier.Cut.Off=4, 
Show.VIF=TRUE, GVIF.Threshold=10, Sandwich.Type="HC0", 
Alpha.CI.Group.Spec.SD.Resid=0.01)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Stage.1_+3A_dataset">Dataset</code></td>
<td>
<p>A <code>data.frame</code> that should consist of one line per test participant (the so-called &lsquo;wide&rsquo; data-format). Each line should contain (at least) one test score and one independent variable.</p>
</td></tr>
<tr><td><code id="Stage.1_+3A_model">Model</code></td>
<td>
<p>The regression model to be fitted (mean structure). A formula should be provided using the syntaxis of the  <code>lm</code> function (for help, see <code>?lm</code>). For example, <code>Test.Score~Gender</code> will fit a linear regression model in which <code>Gender</code> (the independent variable) is regressed on <code>Test.Score</code>. <code>Test.Score~Gender+Age+ Gender:Age</code> will regress <code>Test.Score</code> on <code>Gender</code>, <code>Age</code>, and the interaction term. <code>Test.Score~1</code> will fit an intercept-only model.</p>
</td></tr>
<tr><td><code id="Stage.1_+3A_order.poly.var">Order.Poly.Var</code></td>
<td>
<p>If the homoscedasticity assumption is violated and the mean structure of the fitted model contains at least one quantitative variable, a polynomial variance prediction function is fitted. The argument <code>Order.Poly.Var=</code> determines the order of the polynomial, e.g., <code>Order.Poly.Var=1</code>, <code>Order.Poly.Var=2</code>, <code>Order.Poly.Var=3</code> for linear, quadratic and cubic polynomials, respectively. By default, <code>Order.Poly.Var = 3</code>.</p>
</td></tr>
<tr><td><code id="Stage.1_+3A_alpha">Alpha</code></td>
<td>
<p>The significance level to be used when conducting inference for the mean structure of the model. Default <code>Alpha=0.05</code>.</p>
</td></tr>
<tr><td><code id="Stage.1_+3A_alpha.homosc">Alpha.Homosc</code></td>
<td>
<p>The significance level to be used to evaluate the homoscedasticity assumption based on the Levene test (when all independent variables in the model are qualitative) or the Breusch-Pagan test (when at least one of the independent variables is quantitative). Default <code>Alpha.Homosc=0.05</code>.</p>
</td></tr>
<tr><td><code id="Stage.1_+3A_alpha.norm">Alpha.Norm</code></td>
<td>
<p>The significance level to be used to test the normality assumption for the standardized errors using the Shapiro-Wilk test. The normality assumption is evaluated based on the standardized residuals in the normative dataset, which are computed as explained in the <code>Assume.Homoscedasticity=</code> argument documentation below. Default <code>Alpha.Shapiro=0.05</code>.</p>
</td></tr>
<tr><td><code id="Stage.1_+3A_assume.homoscedasticity">Assume.Homoscedasticity</code></td>
<td>
<p>Logical. The <code>NormData</code> package &lsquo;decides&rsquo; whether the homoscedasticity assumption is valid based on the Levene or Breusch-Pagan tests (for models that only include qualitative independent variables versus models that include at least one quantitative independent variable, respectively). The <code>Assume.Homoscedasticity= TRUE/FALSE</code> argument can be used to overrule this decision process and &lsquo;force&rsquo; the <code>NormData</code> package to assume or not assume homoscedasticity. When the argument <br />  <code>Assume.Homoscedasticity=TRUE</code> is used, the argument <code>Alpha.Homosc=0</code> is automatically used in the <code>Stage.1()</code> function call and thus the homoscedasticity assumption will never be rejected (because the <code class="reqn">p</code>-value of the Levene or Breusch-Pagan test-statistics will always be larger than the specified <code class="reqn">\alpha=0</code>). When <code>Assume.Homoscedasticity=FALSE</code> is used, the argument <code>Alpha.Homosc=1</code> is automatically used thus the homoscedasticity assumption will always be rejected (because the <code class="reqn">p</code>-value of the Levene or Breusch-Pagan test-statistics will always be smaller than the specified <code class="reqn">\alpha=1</code>).
</p>
<p>By default, the standardized residuals <code class="reqn">\widehat{\delta}_i</code> that are shown in the normality and outlier output sections of the results (and the plots, see <code><a href="#topic+plot+20Stage.1">plot Stage.1</a></code>) are computed based on the overall residual standard error when the homoscedasticity assumption is valid (i.e., as <code class="reqn">\widehat{\delta}_i = \frac{\widehat{\varepsilon}_i}{\widehat{\sigma}^2_{\varepsilon}}</code>, with  <code class="reqn">\widehat{\sigma}^2_{\varepsilon}</code> corresponding to the overall residual standard error), or based on prediction-specific residual standard errors when the homoscedasticity assumption is invalid (i.e., as <code class="reqn">\widehat{\delta}_i = \frac{\widehat{\varepsilon}_i}{\widehat{\sigma}^2_{\varepsilon_i}}</code>, with  <code class="reqn">\widehat{\sigma}^2_{\varepsilon_i}</code> corresponding to e.g., a cubic polynomial variance prediction function <code class="reqn">\widehat{\sigma}^2_{\varepsilon_i} = \widehat{\gamma}_0 + \widehat{\gamma}_1 \: \widehat{Y} + \widehat{\gamma}_2 \: \widehat{Y}^2 + {\gamma}_3 \: \widehat{Y}^3</code> when the mean structure of the model contains quantitiative independent variables).
</p>
</td></tr>
<tr><td><code id="Stage.1_+3A_test.assumptions">Test.Assumptions</code></td>
<td>
<p>Logical. Should the model assumptions be evaluated for the specified  model? Default <code>Test.Assumptions=TRUE</code>.</p>
</td></tr>
<tr><td><code id="Stage.1_+3A_outlier.cut.off">Outlier.Cut.Off</code></td>
<td>
<p>Outliers are evaluated based on the standardized residuals, which are computed as explained in the <code>Assume.Homoscedasticity=</code> argument documentation. The <code>Outlier.Cut.Off=</code> argument specifies the absolute value that is used as a threshold to detect outliers. Default <code>Outlier.Cut.Off=4</code>, so test scores with standardized residuals <code class="reqn">&lt; -4</code> or <code class="reqn">&gt; 4</code> are flagged as outliers.</p>
</td></tr>
<tr><td><code id="Stage.1_+3A_show.vif">Show.VIF</code></td>
<td>
<p>Logical. Should the generalized VIF (Fox and Monette, 1992) be shown when the function <code>summary()</code> is applied to the fitted object? Default <code>Show.VIF=TRUE</code>. If all  names of the independent variables in the fitted Stage 1 model contain the string &lsquo;Age&rsquo; (e.g., Age, Age.2 and Age.3), a higher-order polynomial model for the mean structure is being fitted. For such models, multicollinearity diagnostics are essentially irrelevant (see Van der Elst, 2023) and in such cases the generalized VIF is not printed in the summary output. The generalized VIF is also not shown whenn there is only one independent variable in the model (because multicollinearity relates to the linear association of two or more independent variables).</p>
</td></tr>
<tr><td><code id="Stage.1_+3A_gvif.threshold">GVIF.Threshold</code></td>
<td>
<p>The threshold value to be used to detect multicollinearity based on the generalized VIF. Default <code>GVIF.Threshold=10</code>.</p>
</td></tr>
<tr><td><code id="Stage.1_+3A_sandwich.type">Sandwich.Type</code></td>
<td>
<p>When the homoscedasticity assumption is violated, so-called sandwich estimators (or heteroscedasticity-consistent estimators) for the standard errors of the regression parameters are used. For example, the sandwich estimator for the standard error of <code class="reqn">\widehat{\beta}_1</code> in a simple linear regression model corresponds to <code class="reqn">\widehat{\sigma}_{{\beta}_1}=\sqrt{\frac{
\sum\limits_{i=1}^{N}\left(\left(X_i - \widehat{\mu}_{X_{i}}\right)^2 \: \widehat{\varepsilon}_i^2 \right)}{\left(\sum\limits_{i=1}^{N}(X_i - \widehat{\mu}_{X_{i}})^2\right)^2}}</code>. For multiple linear regression models, the sandwich estimators for the different independent variables  <code class="reqn">\widehat{\sigma}_{{\beta}_0}</code>, <code class="reqn">\widehat{\sigma}_{{\beta}_1}</code>, ...correspond to the square roots of the diagonal elements of <code class="reqn">\boldsymbol{\widehat{\Sigma}}_{\beta} = \\
\left(\boldsymbol{X}^{'}\boldsymbol{X}\right)^{-1}
\left(\boldsymbol{X}^{'} \left[\begin{array}{cccc}
\widehat{\varepsilon}^2_1 &amp; 0 &amp; \ldots &amp; 0\\
0 &amp; \widehat{\varepsilon}^2_2 &amp; \ldots &amp; 0\\
\vdots &amp; \vdots &amp; \ddots &amp; 0\\
0 &amp; 0 &amp; 0 &amp; \widehat{\varepsilon}^2_N
\end{array}\right] \boldsymbol{X}\right)
\left(\boldsymbol{X}^{'}\boldsymbol{X}\right)^{-1}.</code>
The sandwich-estimators that are shown in the above expressions are referred to as the Heteroscedasticity-Consistent 0 estimator (or HC0 estimator), which is the first sandwich-estimator that was proposed in the literature. The HC0 sandwich-estimator is justified based on asymptotic theory, and its application thus requires large sample sizes. For smaller sample sizes of <code class="reqn">N &lt; 250</code>, the use of the HC3 estimator is recommended because the HC0 sandwich-estimator tends to be negatively biased (Long and Erwin, 2000). By default, the HC0 estimator is used. The argument <code>Sandwich.Type=</code> can be used to request another type of the heteroscedasticity-consistent estimator. For details on these estimators, see the <code>vcovHC</code> function of the <code>sandwich</code> package. If <code class="reqn">N &lt; 250</code> and the homoscedasticity assumption is violated, a note will be given that the use of the HC3-estimator is recommended. To this end, the argument <code>Sandwich.Type="HC3"</code> can be added in the <code>Stage.1()</code> function call.</p>
</td></tr>
<tr><td><code id="Stage.1_+3A_alpha.ci.group.spec.sd.resid">Alpha.CI.Group.Spec.SD.Resid</code></td>
<td>
<p>The <code class="reqn">\alpha</code>-level to be used for the CIs around the prediction-specific residual standard errors (when the homoscedasticity assumption is invalid and the model only contains qualitative independent variable). These CIs are used in the variance function plot. Default <code>Alpha.CI.Group.Spec.SD.Resid=0.01</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For details, see Van der Elst (2023).
</p>


<h3>Value</h3>

<p>An object of class <code>Stage.1</code> with components,
</p>
<table>
<tr><td><code>HomoNorm</code></td>
<td>
<p>The fitted regression model assuming homoscedasticity and normality.</p>
</td></tr>
<tr><td><code>NoHomoNorm</code></td>
<td>
<p>The fitted regression model assuming no homoscedasticity and normality.</p>
</td></tr>
<tr><td><code>HomoNoNorm</code></td>
<td>
<p>The fitted regression model assuming homoscedasticity and no normality. </p>
</td></tr>
<tr><td><code>NoHomoNoNorm</code></td>
<td>
<p>The fitted regression model assuming no homoscedasticity and no normality. </p>
</td></tr>
<tr><td><code>Predicted</code></td>
<td>
<p>The predicted test scores based on the fitted model.</p>
</td></tr>
<tr><td><code>Sandwich.Type</code></td>
<td>
<p>The requested sandwich estimator.</p>
</td></tr>
<tr><td><code>Order.Poly.Var</code></td>
<td>
<p>The order of the polynomial variance prediction function.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Wim Van der Elst
</p>


<h3>References</h3>

<p>Fox, J. and Monette, G. (1992). Generalized collinearity diagnostics. <em>JASA, 87,</em> 178-183.
</p>
<p>Long, J. S. and Ervin, L. H. (2000). Using Heteroscedasticity Consistent Standard Errors in the Linear Regression Model. <em>The American Statistician, 54,</em> 217-224.
</p>
<p>Van der Elst, W. (2024). <em>Regression-based normative data for psychological assessment: A hands-on approach using R.</em> Springer Nature. 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+plot+20Stage.1">plot Stage.1</a></code>, <code><a href="#topic+Stage.2.AutoScore">Stage.2.AutoScore</a></code>, <code><a href="#topic+Stage.2.NormScore">Stage.2.NormScore</a></code>, <code><a href="#topic+Stage.2.NormTable">Stage.2.NormTable</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'># Replicate the Stage 1 results that were obtained in 
# Case study 1 of Chapter 4 in Van der Elst (2023)
# ---------------------------------------------------
library(NormData)   # load the NormData package
data(GCSE)          # load the GCSE dataset

# Conduct the Stage 1 analysis
Model.1.GCSE &lt;- Stage.1(Dataset=GCSE, 
    Model=Science.Exam~Gender)

summary(Model.1.GCSE)
plot(Model.1.GCSE)


# Replicate the Stage 1 results that were obtained in 
# Case study 1 of Chapter 7 in Van der Elst (2023)
# ---------------------------------------------------
library(NormData)   # load the NormData package
data(Substitution)  # load the Substitution dataset

# Add the variable Age.C (= Age centered) and its 
# quadratic and cubic terms to the Substitution dataset
Substitution$Age.C &lt;- Substitution$Age - 50
Substitution$Age.C2 &lt;- (Substitution$Age - 50)**2
Substitution$Age.C3 &lt;- (Substitution$Age - 50)**3

# Fit the full Stage 1 model
Substitution.Model.1 &lt;- Stage.1(Dataset=Substitution,
   Model=LDST~Age.C+Age.C2+Age.C3+Gender+LE+Age.C:LE+
   Gender:LE+Age.C:Gender, Alpha=0.005)
summary(Substitution.Model.1)

# Fit the model in which the non-significant Age.C:Gender
# interaction term is removed
Substitution.Model.2 &lt;- Stage.1(Dataset=Substitution, 
    Alpha=0.005,
    Model=LDST~Age.C+Age.C2+Age.C3+Gender+LE+
    Age.C:LE+Gender:LE)
summary(Substitution.Model.2)

# Evaluate the significance of the Gender:LE interaction term
# GLT is used because the interaction involves multiple regression
# parameters
GLT.1 &lt;- GLT(Dataset=Substitution, Alpha=0.005, 
   Unrestricted.Model=LDST~Age.C+Age.C2+Age.C3+
      Gender+LE+Age.C:LE+Gender:LE, 
   Restricted.Model=LDST~Age.C+Age.C2+Age.C3+
      Gender+LE+Age.C:LE)
summary(GLT.1)

# Fit the model in which the non-significant Gender:LE
# interaction term is removed
Substitution.Model.3 &lt;- Stage.1(Dataset=Substitution, 
    Alpha=0.005,
    Model=LDST~Age.C+Age.C2+Age.C3+Gender+LE+Age.C:LE)
summary(Substitution.Model.3)

# Evaluate the significance of the Age:LE interaction
# using the General Linear Test framework
GLT.2 &lt;- GLT(Dataset=Substitution,
    Unrestricted.Model=LDST~Age.C+Age.C2+Age.C3+Gender+LE+Age.C:LE,
    Restricted.Model=LDST~Age.C+Age.C2+Age.C3+Gender+LE, Alpha=0.005)
summary(GLT.2)

# Fit the model in which the non-significant Age_c:LE
# interaction term is removed
Substitution.Model.4 &lt;- Stage.1(Dataset=Substitution,
   Alpha=0.005, Model=LDST~Age.C+Age.C2+Age.C3+Gender+LE)
summary(Substitution.Model.4)

# Fit the model in which the non-significant Age.C3 term is removed
Substitution.Model.5 &lt;- Stage.1(Dataset=Substitution,
   Alpha=0.005, Model=LDST~Age.C+Age.C2+Gender+LE)
summary(Substitution.Model.5)

# Fit the model in which the non-significant Age.C2 term is removed
Substitution.Model.6 &lt;- Stage.1(Dataset=Substitution,
   Alpha=0.005, Model=LDST~Age.C+Gender+LE)
summary(Substitution.Model.6)

# Fit the model in which the non-significant main effect of Gender 
# is removed
Substitution.Model.7 &lt;- Stage.1(Dataset=Substitution, 
  Alpha=0.005, Model=LDST~Age.C+LE)
summary(Substitution.Model.7)
plot(Substitution.Model.7, Normality = FALSE, Outliers = FALSE)

# Check the significance of LE using the GLT framework
GLT.3 &lt;- GLT(Dataset=Substitution, Alpha=0.005,
    Unrestricted.Model=LDST~Age.C+LE, 
    Restricted.Model=LDST~Age.C)
summary(GLT.3)

# Residual variance function. Substitution.Model.7 uses
# a cubic polynomial variance prediction function. 
# Remove cubic Pred.Y term from Substitution.Model.7, so
# fit quadratic variance prediction function
Substitution.Model.8 &lt;- Stage.1(Dataset=Substitution, 
    Alpha=0.005, Model=LDST~Age.C+LE,
    Order.Poly.Var=2)  # Order.Poly.Var=2 specifies a quadratic polynomial
                       # for the variiance prediction function
summary(Substitution.Model.8)
plot(Substitution.Model.8, Normality = FALSE, Outliers = FALSE)

# Remove quadratic Pred.Y term, so fit linear variance 
# prediction function
Substitution.Model.9 &lt;- Stage.1(Dataset=Substitution, 
    Alpha=0.005, Model=LDST~Age.C+LE,
    Order.Poly.Var=1) # Order.Poly.Var=1 specifies a linear polynomial
                      # for the variiance prediction function

# Final Stage 1 model
summary(Substitution.Model.9)
plot(Substitution.Model.9) 
</code></pre>

<hr>
<h2 id='Stage.2.AutoScore'>Make an automatic scoring sheet</h2><span id='topic+Stage.2.AutoScore'></span>

<h3>Description</h3>

<p>This function is useful to construct an automatic scoring sheet that implements the Stage 2 normative conversion approach in a spreadsheet. In particular, a spreadsheet will be created with three tabs that should be copy-pasted to the different sections of the <code>Model details</code> tab of the template file. For details, see Van der Elst (2023). 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Stage.2.AutoScore(Stage.1.Model, Assume.Homoscedasticity, 
  Assume.Normality, Folder, NameFile="NormSheet.xlsx", 
  verbose=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Stage.2.AutoScore_+3A_stage.1.model">Stage.1.Model</code></td>
<td>
<p>A fitted object of class <code>Stage.1</code> that should be written to the Excel sheet (i.e., the final Stage 1 model).</p>
</td></tr>
<tr><td><code id="Stage.2.AutoScore_+3A_assume.homoscedasticity">Assume.Homoscedasticity</code></td>
<td>
<p>Logical. Should homoscedasticity be assumed? By default,  homoscedasticity is assumed when the <code class="reqn">p</code>-value of the Levene or Breusch-Pagan test for the fitted Stage 1 model is above the specified <code class="reqn">\alpha</code>-level in the <code>Stage.1()</code> function call. When homoscedasticity is assumed, an overall residual standard error is written to the spreadsheet. When homoscedasticity is not assumed, prediction-specific residual standard errors are written to the spreadsheet. The default decision procedure can be overruled by means of the arguments <br />  <code>Assume.Homoscedasticity=TRUE</code> or <code>Assume.Homoscedasticity=FALSE</code>.</p>
</td></tr>
<tr><td><code id="Stage.2.AutoScore_+3A_assume.normality">Assume.Normality</code></td>
<td>
<p>Logical. Should normality of the standardized errors be assumed? By default, normality is assumed when the <code class="reqn">p</code>-value of the Shapiro-Wilk test for the fitted Stage 1 model is above the specified <code class="reqn">\alpha</code>-level in the <code>Stage.1()</code> function call. When normality is assumed, the CDF of the standard normal distribution is written to the spreadsheet. When normality is not assumed, the CDF of the standardized residuals in the normative sample is written to the speeadsheet. The default decision procedure can be overruled by means of the arguments argument <code>Assume.Normality=TRUE</code> or <code>Assume.Normality=FALSE</code>.</p>
</td></tr>
<tr><td><code id="Stage.2.AutoScore_+3A_folder">Folder</code></td>
<td>
<p>The folder where the spreadsheet file should be saved.</p>
</td></tr>
<tr><td><code id="Stage.2.AutoScore_+3A_namefile">NameFile</code></td>
<td>
<p>The name of the file in which the normative tables should be saved. Default  <code>NameFile="NormTable.xlsx"</code></p>
</td></tr>  
<tr><td><code id="Stage.2.AutoScore_+3A_verbose">verbose</code></td>
<td>
<p>A logical value indicating whether verbose output should be generated.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For details, see Van der Elst (2023).
</p>


<h3>Value</h3>

<p>An object of class <code>Stage.2.AutoScore</code> with components,
</p>
<table>
<tr><td><code>Mean.Structure</code></td>
<td>
<p>The mean prediction function.</p>
</td></tr>
<tr><td><code>Residual.Structure</code></td>
<td>
<p>The variance prediction function.</p>
</td></tr>  
<tr><td><code>Percentiles.Delta</code></td>
<td>
<p>A table of the standardized residuals and their corresponding estimated percentile ranks (based on the CDF of the standard normal distribution or the CDF of the standardized residuals in the normative sample, see above).</p>
</td></tr> 
</table>


<h3>Author(s)</h3>

<p>Wim Van der Elst
</p>


<h3>References</h3>

<p>Van der Elst, W. (2024). <em>Regression-based normative data for psychological assessment: A hands-on approach using R.</em> Springer Nature. 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Stage.1">Stage.1</a></code>, <code><a href="#topic+Stage.2.NormTable">Stage.2.NormTable</a></code>, <code><a href="#topic+Stage.2.AutoScore">Stage.2.AutoScore</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Replicate the Stage 1 results that were obtained in 
# Case study 1 of Chapter 4 in Van der Elst (2023)
# ---------------------------------------------------
library(NormData)   # load the NormData package
data(GCSE)          # load the GCSE dataset

# Conduct the Stage 1 analysis
Model.1.GCSE &lt;- Stage.1(Dataset=GCSE, 
  Model=Science.Exam~Gender)

summary(Model.1.GCSE)
plot(Model.1.GCSE, Add.Jitter = .2)

# Write the results to a spreadsheet file
Stage.2.AutoScore(Stage.1.Model=Model.1.GCSE, 
  Folder=tempdir(),   # Replace tempdir() by the desired folder  
  NameFile="GCSE.Output.xlsx")

# Copy-paste the information in GCSE.Output.xlsx to the
# template file, as detailed in Van der Elst (2023)


# Replicate the Stage 1 results that were obtained in 
# Case study 1 of Chapter 7 in Van der Elst (2023)
# ---------------------------------------------------
library(NormData)   # load the NormData package
data(Substitution)  # load the Substitution dataset

# Add the variable Age.C (= Age centered) to the Substitution dataset
Substitution$Age.C &lt;- Substitution$Age - 50

# Fit the final Stage 1 model
Substitution.Model.9 &lt;- Stage.1(Dataset=Substitution, 
   Alpha=0.005, Model=LDST~Age.C+LE, Order.Poly.Var=1) 

# Final Stage 1 model
summary(Substitution.Model.9)
plot(Substitution.Model.9) 

# Write the results to a spreadsheet file
Stage.2.AutoScore(Stage.1.Model=Substitution.Model.9,
   Folder=tempdir(),  # Replace tempdir() by the desired folder
   NameFile="LDST.Output.xlsx")

# Copy-paste the information in LDST.Output.xlsx to the
# template file, as detailed in Van der Elst (2023)
</code></pre>

<hr>
<h2 id='Stage.2.NormScore'>Convert a raw score to a percentile rank</h2><span id='topic+Stage.2.NormScore'></span>

<h3>Description</h3>

<p>The function <code>Stage.2.NormScore()</code> can be used to convert the raw test score of a tested person <code class="reqn">Y_0</code> into a percentile rank <code class="reqn">\hat{\pi}_0</code> (taking into account specified values of the independent variables). 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Stage.2.NormScore(Stage.1.Model, Assume.Homoscedasticity, 
Assume.Normality, Score, Rounded=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Stage.2.NormScore_+3A_stage.1.model">Stage.1.Model</code></td>
<td>
<p>A fitted object of class <code>Stage.1</code> that should be used to conduct the normative conversions.</p>
</td></tr>
<tr><td><code id="Stage.2.NormScore_+3A_assume.homoscedasticity">Assume.Homoscedasticity</code></td>
<td>
<p>Logical. Should homoscedasticity be assumed in conducting the normative conversion? By default, homoscedasticity is assumed when the <code class="reqn">p</code>-value of the Levene or Breusch-Pagan test for the fitted Stage 1 model is above the specified <code class="reqn">\alpha</code>-level in the <code>Stage.1()</code> function call. When homoscedasticity is assumed, an overall residual standard error is used in the normative conversions. When homoscedasticity is not assumed, prediction-specific residual standard errors used. The default decision procedure can be overruled by means of the arguments argument <code>Assume.Homoscedasticity=TRUE</code> or <code>Assume.Homoscedasticity=FALSE</code>.</p>
</td></tr>
<tr><td><code id="Stage.2.NormScore_+3A_assume.normality">Assume.Normality</code></td>
<td>
<p>Logical. Should normality of the standardized errors be assumed in conducting the normative conversion? By default, normality is assumed when the <code class="reqn">p</code>-value of the Shapiro-Wilk test for the fitted Stage 1 model is above the specified <code class="reqn">\alpha</code>-level in the <code>Stage.1()</code> function call. When normality is assumed, the <code class="reqn">Y_0</code> to  <code class="reqn">\hat{\pi}_0</code> conversion is based on the CDF of the standard normal distribution. When normality is not assumed, this conversion is based on the CDF of the standardized residuals in the normative sample. The default decision procedure can be overruled by means of the arguments argument <code>Assume.Normality=TRUE</code> or <code>Assume.Normality=FALSE</code>.</p>
</td></tr>
<tr><td><code id="Stage.2.NormScore_+3A_score">Score</code></td>
<td>
<p>A <code>list</code> that contains the test score <code class="reqn">Y_0</code> to be converted into a percentile rank and the values for the relevant independent variable(s). For example, the argument <code>Score=list(Science.Exam=30, Gender="F")</code> specifies that a female student obtained a raw Science Exam score <code class="reqn">Y_0</code>. Observe that quotes are used to refer to a female student (i.e., &quot;F&quot;). This is done because the string <code>F</code> (without quotes) is shorthand notation for the logical indicator <code>FALSE</code> in R. If no quotes are used, an error will be generated that a logical indicator was provided where a factor level was expected. To avoid such issues, it is recommended to always use quotes to refer to the levels of a factor. In the <code>Score=...</code> argument, the test score should always be specified first followed by the independent variable. Notice that both the name of the independent variable and the coding scheme that is specified in the <code>Score=...</code> argument should correspond to the name of the independent variable and the original coding scheme that was used in the <code>Stage.1()</code> function call. For example, if the variable name <code>Gender</code> original coding scheme <code>F</code> and <code>M</code> was used in the <code>Stage.1()</code> function call, the same should be done in the <code>Stage.2.NormScore()</code> call. Thus <code>Score=list(Science.Exam=30, Gender="F")</code> should be used, and not e.g., <code>Score=list(Science.Exam=30, GenderM=0)</code>.</p>
</td></tr>
<tr><td><code id="Stage.2.NormScore_+3A_rounded">Rounded</code></td>
<td>
<p>Logical. Should the percentile rank be rounded to a whole number? Default <code>Rounded=TRUE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For details, see Van der Elst (2023). 
</p>


<h3>Value</h3>

<p>An object of class <code>Stage.2.NormScore</code> with components,
</p>
<table>
<tr><td><code>Fitted.Model</code></td>
<td>
<p>A fitted object of class <code>Stage.1()</code> that was used to convert the raw test score <code class="reqn">Y_0</code> into a percentile rank <code class="reqn">\hat{\pi}_0</code>.</p>
</td></tr>
<tr><td><code>Results</code></td>
<td>
<p>A data frame that contains the observed test score, residuals, percentile rank, ...</p>
</td></tr> 
<tr><td><code>Assume.Homoscedasticity</code></td>
<td>
<p>The homoscedasticity assumption that was made in the normative conversion.</p>
</td></tr>
<tr><td><code>Assume.Normality</code></td>
<td>
<p>The normality assumption that was made in the normative conversion.</p>
</td></tr>
<tr><td><code>Score</code></td>
<td>
<p>The test score and the value(s) of the independent variable(s) that were used in the computations.</p>
</td></tr>
<tr><td><code>Stage.1.Model</code></td>
<td>
<p>The <code>Stage.1.Model</code> model used in the analysis.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Wim Van der Elst
</p>


<h3>References</h3>

<p>Van der Elst, W. (2024). <em>Regression-based normative data for psychological assessment: A hands-on approach using R.</em> Springer Nature. 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Stage.2.NormTable">Stage.2.NormTable</a></code>, <code><a href="#topic+Stage.2.AutoScore">Stage.2.AutoScore</a></code>, <code><a href="#topic+Bootstrap.Stage.2.NormScore">Bootstrap.Stage.2.NormScore</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Replicate the normative conversion that was obtained in 
# Case study 1 of Chapter 3 in Van der Elst (2023)
# (science exam score = 30 obtained by a female)
# -------------------------------------------------------
library(NormData) # load the NormData package
data(GCSE)        # load the GCSE dataset

# Fit the Stage 1 model
Model.1.GCSE &lt;- Stage.1(Dataset=GCSE, 
  Model=Science.Exam~Gender)

# Stage 2: Convert a science exam score = 30 obtained by a 
# female into a percentile rank (point estimate)
Normed_Score &lt;- Stage.2.NormScore(Stage.1.Model=Model.1.GCSE,
  Score=list(Science.Exam=30, Gender="F"))

summary(Normed_Score)
plot(Normed_Score)


# Replicate the normative conversion that was obtained in 
# Case study 1 of Chapter 7 in Van der Elst (2023)
# (LDST score = 40 obtained by a 20-year-old 
# test participant with LE=Low)
# -------------------------------------------------------
library(NormData)   # load the NormData package
data(Substitution)  # load the Substitution dataset

# Make the new variable Age.C (= Age centered) that is 
# needed to fit the final Stage 1 model, 
# and add it to the Substitution dataset
Substitution$Age.C &lt;- Substitution$Age - 50

# Fit the final Stage 1 model
Substitution.Model.9 &lt;- Stage.1(Dataset=Substitution, 
  Alpha=0.005, Model=LDST~Age.C+LE, Order.Poly.Var=1) 
summary(Substitution.Model.9)

# Convert an LDST score = 40 obtained by a 
# 20-year-old test participant with LE=Low 
# into a percentile rank (point estimate)
Normed_Score &lt;- Stage.2.NormScore(
  Stage.1.Model=Substitution.Model.9, 
  Score=list(LDST=40, Age.C=20-50, LE = "Low"))

summary(Normed_Score)
plot(Normed_Score)
</code></pre>

<hr>
<h2 id='Stage.2.NormTable'>Derive a normative table</h2><span id='topic+Stage.2.NormTable'></span>

<h3>Description</h3>

<p>This function allows for deriving a normative table that shows percentile ranks <code class="reqn">\hat{\pi}_0</code> that correspond to a wide range of raw test scores <code class="reqn">Y_0</code> (stratified by the relevant independent variables). 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Stage.2.NormTable(Stage.1.Model, Assume.Homoscedasticity, 
Assume.Normality, Grid.Norm.Table, Test.Scores, Digits=6, 
Rounded=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Stage.2.NormTable_+3A_stage.1.model">Stage.1.Model</code></td>
<td>
<p>A fitted object of class <code>Stage.1</code> that should be used to derive the normative table.</p>
</td></tr>
<tr><td><code id="Stage.2.NormTable_+3A_assume.homoscedasticity">Assume.Homoscedasticity</code></td>
<td>
<p>Logical. Should homoscedasticity be assumed when deriving the normative table? By default, homoscedasticity is assumed when the <code class="reqn">p</code>-value of the Levene or Breusch-Pagan test for the fitted Stage 1 model is above the specified <code class="reqn">\alpha</code>-level in the <code>Stage.1()</code> function call. When homoscedasticity is assumed, an overall residual standard error is used in the derivation of the normative table. When homoscedasticity is not assumed, prediction-specific residual standard errors used. The default decision procedure can be overruled by means of the arguments argument <code>Assume.Homoscedasticity=TRUE</code> or <code>Assume.Homoscedasticity=FALSE</code>.</p>
</td></tr>
<tr><td><code id="Stage.2.NormTable_+3A_assume.normality">Assume.Normality</code></td>
<td>
<p>Logical. Should normality of the standardized errors be assumed when deriving the normative table? By default, normality is assumed when the <code class="reqn">p</code>-value of the Shapiro-Wilk test for the fitted Stage 1 model is above the specified <code class="reqn">\alpha</code>-level in the <code>Stage.1()</code> function call. When normality is assumed, the <code class="reqn">Y_0</code> to  <code class="reqn">\hat{\pi}_0</code> conversions in the normative table are based on the CDF of the standard normal distribution. When normality is not assumed, these conversions are based on the CDF of the standardized residuals in the normative sample. The default decision procedure can be overruled by means of the arguments argument <code>Assume.Normality=TRUE</code> or <code>Assume.Normality=FALSE</code>.</p>
</td></tr>
<tr><td><code id="Stage.2.NormTable_+3A_grid.norm.table">Grid.Norm.Table</code></td>
<td>
<p>A <code>data.frame</code> that specifies the name of the independent variable(s) (e.g., <code>Gender</code>) and the levels (e.g., <code>"F"</code> and <code>"M"</code>) or values (e.g., <code>Age.C=seq(from=20, to=80, by=1)-50)</code>) for which the estimated percentile ranks should be tabulated. Both the name of the independent variable and the coding scheme that is specified in the <code>Grid.Norm.Table=...</code> argument should exactly match the name of the independent variable and the original coding scheme that was used in the <code>Stage.1()</code> function call. For example, if the variable name <code>Gender</code> with original coding scheme <code>F</code> and <code>M</code> was used in the <code>Stage.1()</code> function call, the same should be done in the <code>Stage.2.NormTable()</code> function call. So <code>Grid.Norm.Table= data.frame(Gender=c("F", "M")</code>) should be used, and not e.g., <code>Grid.Norm.Table= data.frame(GenderM=c(0,1))</code>. Observe that quotes are used to refer to a female student (i.e., &quot;F&quot;). This is done because the string <code>F</code> (without quotes) is shorthand notation for the logical indicator <code>FALSE</code> in R. If no quotes are used, an error will be generated that a logical indicator was provided where a factor level was expected.
</p>
<p>When multiple independent variables are considered, the <code>data.frame</code> can be constructed using the <code>expand.grid()</code> function. For example, <code>Grid.Norm.Table= expand.grid(Age.C=seq(from=-30, to=30, by=1), LE=c("Low", "Average", "High"))</code> specifies that the normative table should be stratified for both Age centered (with score range -30 to 30) and LE.</p>
</td></tr>
<tr><td><code id="Stage.2.NormTable_+3A_test.scores">Test.Scores</code></td>
<td>
<p>A vector that specifies the raw test scores that should be shown in the normative table.</p>
</td></tr>
<tr><td><code id="Stage.2.NormTable_+3A_rounded">Rounded</code></td>
<td>
<p>Logical. Should the percentile ranks that are shown in the normative table be rounded to a whole number? Default <code>Rounded=TRUE</code>.</p>
</td></tr>
<tr><td><code id="Stage.2.NormTable_+3A_digits">Digits</code></td>
<td>
<p>The number of digits that need to be shown in the normative table for the predicted means and residual standard errors. Default <code>Digits=6</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For details, see Van der Elst (2023).
</p>


<h3>Value</h3>

<p>An object of class <code>Stage.2.NormTable</code> with components,
</p>
<table>
<tr><td><code>Norm.Table</code></td>
<td>
<p>The normative table.</p>
</td></tr>
<tr><td><code>Group.Specific.SD.Resid</code></td>
<td>
<p>Logical. Where prediction-specific SDs of the residuals used?</p>
</td></tr>  
<tr><td><code>Empirical.Dist.Delta</code></td>
<td>
<p>Logical. Was the CDF of the standardized residuals used to convert the raw test scores into percentile ranks?</p>
</td></tr>
<tr><td><code>N.Analysis</code></td>
<td>
<p>The sample size of the analyzed dataset.</p>
</td></tr>
<tr><td><code>Test.Scores</code></td>
<td>
<p>A vector of raw test scores for which percentile ranks were requested.</p>
</td></tr>
<tr><td><code>Assume.Homoscedasticity</code></td>
<td>
<p>Is homoscedasticity assumed in the computation of the normative data?</p>
</td></tr>
<tr><td><code>Assume.Normality</code></td>
<td>
<p>Is normality assumed in the computation of the normative data?</p>
</td></tr>
<tr><td><code>Stage.1.Model</code></td>
<td>
<p>The <code>Stage.1.Model</code> model that was used to do the computations.</p>
</td></tr>
<tr><td><code>Grid.Norm.Table</code></td>
<td>
<p>The specified <code>Grid.Norm.Table</code> in the function call.</p>
</td></tr>
<tr><td><code>Digits.Percentile</code></td>
<td>
<p>The number of digits after the decimal point that were requested for the percentile ranks.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Wim Van der Elst
</p>


<h3>References</h3>

<p>Van der Elst, W. (2024). <em>Regression-based normative data for psychological assessment: A hands-on approach using R.</em> Springer Nature. 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Stage.2.NormScore">Stage.2.NormScore</a></code>, <code><a href="#topic+Stage.2.AutoScore">Stage.2.AutoScore</a></code>, <code><a href="#topic+Bootstrap.Stage.2.NormScore">Bootstrap.Stage.2.NormScore</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'># Replicate the normative table that was obtained in 
# Case study 1 of Chapter 3 in Van der Elst (2023)
# -----------------------------------------------------
library(NormData) # load the NormData package
data(GCSE)        # load the GCSE dataset

# Fit the Stage 1 model
Model.1.GCSE &lt;- Stage.1(Dataset=GCSE, 
    Model=Science.Exam~Gender)

# Make a normative table for raw Science Exam scores = 10, 
# 11, ... 85, stratified by Gender
NormTable.GCSE &lt;- Stage.2.NormTable(Stage.1.Model=Model.1.GCSE,
  Test.Scores=c(10:85), 
  Grid.Norm.Table=data.frame(Gender=c("F", "M")))

summary(NormTable.GCSE)


# Replicate the normative table that was obtained in 
# Case study 1 of Chapter 7 in Van der Elst (2023)
# ------------------------------------------------
library(NormData)   # load the NormData package
data(Substitution)  # load the Substitution dataset

# Make the new variable Age.C (= Age centered) that is 
# needed to fit the final Stage 1 model, 
# and add it to the Substitution dataset
Substitution$Age.C &lt;- Substitution$Age - 50

# Fit the final Stage 1 model
Substitution.Model.9 &lt;- Stage.1(Dataset=Substitution, 
    Alpha=0.005, Model=LDST~Age.C+LE, Order.Poly.Var=1) 

# Make a normative table for LDST scores = 10, 12, ... 56,
# stratified by Age and LE
NormTable.LDST &lt;- Stage.2.NormTable(
  Stage.1.Model=Substitution.Model.9,
  Test.Scores=seq(from=10, to=56, by=2),
  Grid.Norm.Table=expand.grid(Age.C=seq(from=-30, to=30, by=1),
  LE=c("Low", "Average", "High")))
</code></pre>

<hr>
<h2 id='STAS'>State-Trait Anger Scale (STAS)</h2><span id='topic+STAS'></span>

<h3>Description</h3>

<p>This dataset contains the scores of the Trait Anger scale of the STAS. The test participants were <code class="reqn">316</code> first-year psychology students from a university in the Dutch speaking part of Belgium. Participation was a partial fulfillment of the requirement to participate in research. The sample consists of <code class="reqn">73</code> males and <code class="reqn">243</code> females, reflecting the gender proportion among psychology students. The average age was <code class="reqn">18.4</code> years. The data originally come from the package <code>psychotools</code>, dataset <code>VerbalAgression</code>. <br /> For more info, see <code>https://cran.r-project.org/web/packages/psychotools/psychotools.pdf</code>.</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(STAS)</code></pre>


<h3>Format</h3>

<p>A <code>data.frame</code> with <code class="reqn">316</code> observations on <code class="reqn">3</code> variables.
</p>

<dl>
<dt><code>Id</code></dt><dd><p>The Id number of the student.</p>
</dd>
<dt><code>Gender</code></dt><dd><p>The gender of the student, coded as a factor.</p>
</dd>
<dt><code>Anger</code></dt><dd><p>The Trait Anger scale score of the STAS.</p>
</dd>
</dl>

<hr>
<h2 id='Substitution'>Substitution test data</h2><span id='topic+Substitution'></span>

<h3>Description</h3>

<p>Substitution tests are speed-dependent tasks that require the participant to match particular signs (symbols, digits, or letters) to other signs within a specified time period. The LDST is an adaptation of earlier substitution tests, such as the Digit Symbol Substitution Test (DSST; Wechsler, 1981) and the Symbol Digit Modalities Test (SDMT; Smith, 1982). The LDST differs from other substitution tests in that the key consists of 'over-learned' signs,  i.e., letters and digits. These are simulated data that are based on the results described in Van der Elst <em>et al.</em> (2006) (see Table 2).</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(Substitution)</code></pre>


<h3>Format</h3>

<p>A <code>data.frame</code> with 1765 observations on 5 variables.
</p>

<dl>
<dt><code>Id</code></dt><dd><p>The Id number of the participant.</p>
</dd>
<dt><code>Age</code></dt><dd><p>The age of the participant, in years.</p>
</dd>
<dt><code>Gender</code></dt><dd><p>The gender of the participant, coded as a factor with levels <code>Male</code> and <code>Female</code>.</p>
</dd>
<dt><code>LE</code></dt><dd><p>The Level of Education of the test participant, coded as a factor with levels <code>Low</code>, <code>Average</code> and <code>High</code>.</p>
</dd>
<dt><code>LDST</code></dt><dd><p>The test score on the LDST (written version), i.e., the number of correct substitutions made in 60 seconds. A higher score reflects better performance.</p>
</dd>
</dl>


<hr>
<h2 id='summary'>Summary</h2><span id='topic+summary'></span><span id='topic+summary.Bootstrap.Stage.2.NormScore'></span><span id='topic+summary.ExploreData'></span><span id='topic+summary.ICC'></span><span id='topic+summary.Stage.2.NormScore'></span><span id='topic+summary.GLT'></span><span id='topic+summary.Stage.1'></span><span id='topic+summary.Stage.2.NormTable'></span><span id='topic+summary.Sandwich'></span><span id='topic+summary.CheckFit'></span><span id='topic+summary.Tukey.HSD'></span>

<h3>Description</h3>

<p>summary</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'ExploreData'
summary(object, ..., Object)
## S3 method for class 'ICC'
summary(object, ..., Object)
## S3 method for class 'Stage.2.NormScore'
summary(object, ..., Object)
## S3 method for class 'GLT'
summary(object, ..., Object, Assume.Homoscedasticity)
## S3 method for class 'Stage.1'
summary(object, ..., Object)
## S3 method for class 'Stage.2.NormTable'
summary(object, ..., Object)
## S3 method for class 'Sandwich'
summary(object, ..., Object)
## S3 method for class 'CheckFit'
summary(object, ..., Object)
## S3 method for class 'Bootstrap.Stage.2.NormScore'
summary(object, ..., Object)
## S3 method for class 'Tukey.HSD'
summary(object, ..., Object)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary_+3A_object">object</code></td>
<td>
<p>An object for which a summary is desired.</p>
</td></tr>
<tr><td><code id="summary_+3A_...">...</code></td>
<td>
<p>Other arguments.</p>
</td></tr>
<tr><td><code id="summary_+3A_object">Object</code></td>
<td>
<p>An object for which a summary is desired.</p>
</td></tr>
<tr><td><code id="summary_+3A_assume.homoscedasticity">Assume.Homoscedasticity</code></td>
<td>
<p>Logical. Should homoscedasticity be assumed in the GLT procedure?.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>No return value, called for side effects</p>

<hr>
<h2 id='TMAS'>TMAS data</h2><span id='topic+TMAS'></span>

<h3>Description</h3>

<p>This dataset contains the scores of the Taylor Manifest Anxiety Scale (TMAS; Taylor, 1953),  administered online. A total of <code class="reqn">523</code> test participants completed the questionnaire. The TMAS scale score ranges between <code class="reqn">0</code> and <code class="reqn">50</code>, with lower scores corresponding to higher levels of anxiety.</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(TMAS)</code></pre>


<h3>Format</h3>

<p>A <code>data.frame</code> with <code class="reqn">523</code> observations on <code class="reqn">3</code> variables.
</p>

<dl>
<dt><code>Id</code></dt><dd><p>The Id number of the test participant.</p>
</dd>
<dt><code>Gender</code></dt><dd><p>The gender of the test participant, coded as a factor.</p>
</dd>
<dt><code>Score</code></dt><dd><p>The TMAS score. A higher value is iindicative for less anxiety.</p>
</dd>
</dl>


<h3>References</h3>

<p>Taylor, J. (1953). A personality scale of manifest anxiety. <em>The Journal of Abnormal and Social Psychology, 48(2),</em> 285-290.
</p>
<p>Van der Elst, W. (2024). <em>Regression-based normative data for psychological assessment: A hands-on approach using R.</em> Springer Nature. 
</p>

<hr>
<h2 id='Tukey.HSD'>
Conducts Tukey's Honest Significance Difference test
</h2><span id='topic+Tukey.HSD'></span>

<h3>Description</h3>

<p>This function conducts Tukey's Honest Significance Difference (HSD; Tukey, 1949) test that allows for making post hoc comparisons of the group means. Tukey's HSD can only be conducted when the mean structure of the Stage 1 model only contains qualitative independent variables (i.e., when the fitted regression model is essentially an ANOVA).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Tukey.HSD(Stage.1.Model, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Tukey.HSD_+3A_stage.1.model">Stage.1.Model</code></td>
<td>
<p>A fitted stage one model that only contains qualitative variables.</p>
</td></tr>
<tr><td><code id="Tukey.HSD_+3A_...">...</code></td>
<td>
<p>Arguments to be passed to the plot function of the Tukey HSD procedure.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>No return value, called for side effects.</p>


<h3>Author(s)</h3>

<p>Wim Van der Elst
</p>


<h3>References</h3>

<p>Tukey, J. (1949). Comparing individual means in the Analysis of Variance. <em>Biometrics, 5,</em> 99-114.
</p>
<p>Van der Elst, W. (2024). <em>Regression-based normative data for psychological assessment: A hands-on approach using R.</em> Springer Nature. 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+plot.Tukey.HSD">plot.Tukey.HSD</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>data(Personality)
Model.Openness &lt;- Stage.1(Dataset = Personality, Model = Openness ~ LE) 
# conduct post hoc comparisons for the levels of education
Tukey.Openness &lt;- Tukey.HSD(Model.Openness)
summary(Tukey.Openness)
plot(Tukey.Openness)

# conduct post hoc comparisons for the levels of education by education combinations
data(Substitution)
Model.Substitution &lt;- Stage.1(Dataset = Substitution, Model = LDST ~ LE*Gender)
Tukey.Substitution &lt;- Tukey.HSD(Model.Substitution)
summary(Tukey.Substitution)
plot(Tukey.Substitution)
</code></pre>

<hr>
<h2 id='VLT'>Verbal Learning Test data</h2><span id='topic+VLT'></span>

<h3>Description</h3>

<p>This dataset contains the Total Recall scores of the Verbal Learning Test (VLT). A total of <code class="reqn">1460</code> test-participants participated in the study. These are simulated data based on the results described in Van der Elst <em>et al.</em> (2005). </p>


<h3>Usage</h3>

<pre><code class='language-R'>data(VLT)</code></pre>


<h3>Format</h3>

<p>A <code>data.frame</code> with <code class="reqn">1460</code> observations on <code class="reqn">5</code> variables.
</p>

<dl>
<dt><code>Id</code></dt><dd><p>The Id number of the test participant.</p>
</dd>
<dt><code>Age</code></dt><dd><p>The age of the test participant (in years).</p>
</dd>
<dt><code>Gender</code></dt><dd><p>The gender of the test participant, coded as a factor.</p>
</dd>
<dt><code>LE</code></dt><dd><p>The level of education of the test participant.</p>
</dd>
<dt><code>Total.Recall</code></dt><dd><p>The Total Recall score. A higher score is indicative for better verbal memory ability.</p>
</dd>
</dl>


<h3>References</h3>

<p>Van der Elst <em>et al.</em> (2005). Rey's Verbal Learning Test: Normative data for 1,855 healthy participants aged 24-81 years and the influence of age, sex, education, and mode of presentation. <em>Journal of the International Neuropsychological Society, 11,</em> 290-302.
</p>
<p>Van der Elst, W. (2024). <em>Regression-based normative data for psychological assessment: A hands-on approach using R.</em> Springer Nature.
</p>

<hr>
<h2 id='WriteNormTable'>
Write a normative table from R to a .txt/.csv/.xlsx file
</h2><span id='topic+WriteNormTable'></span>

<h3>Description</h3>

<p>The function <code>Stage.2.NormTable()</code> allows for deriving a normative table that shows percentile ranks <code class="reqn">\hat{\pi}_0</code> that correspond to a wide range of raw test scores <code class="reqn">Y_0</code> (stratified by the relevant independent variables). The raw R output format that is provided by the <code>Stage.2.NormTable()</code> function is not always convenient, especially when a large number of test scores are tabulated and the table is spread out over several lines. The function <code>WriteNormTable()</code> can be used to export the normative table to a <code>.txt</code>, <code>.csv</code> or <code>.xlsx</code> file. Such a file can then be opened in a spreadsheet (such as Google Sheets or LibreOffice), where the normative table can be put in a more user-friendly format.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>WriteNormTable(NormTable, Folder, NameFile="NormTable.xlsx", 
verbose=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="WriteNormTable_+3A_normtable">NormTable</code></td>
<td>
<p>An object of class <code>Stage.2.NormTable</code> that contains the normative table that has to be exported.</p>
</td></tr>
<tr><td><code id="WriteNormTable_+3A_folder">Folder</code></td>
<td>
<p>The folder where the file with the normative table should be saved.</p>
</td></tr>
<tr><td><code id="WriteNormTable_+3A_namefile">NameFile</code></td>
<td>
<p>The name of the file to which the normative table should be written. Only the extensions <code>.txt</code>, <code>.csv</code> or <code>.xlsx</code> can be used. If unspecified, the argument <code>NameFile="NormTable.xlsx"</code> is used by default. The <code>.txt</code> and <code>.csv</code> files use a space as the delimiter.</p>
</td></tr>
<tr><td><code id="WriteNormTable_+3A_verbose">verbose</code></td>
<td>
<p>A logical value indicating whether verbose output should be generated.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>No return value, called for side effects.</p>


<h3>Author(s)</h3>

<p>Wim Van der Elst</p>


<h3>References</h3>

<p>Van der Elst, W. (2024). <em>Regression-based normative data for psychological assessment: A hands-on approach using R.</em> Springer Nature. 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Stage.2.NormTable">Stage.2.NormTable</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Replicate the normative table that was obtained in 
# Case study 1 of Chapter 3 in Van der Elst (2023)
# -----------------------------------------------------
library(NormData) # load the NormData package
data(GCSE)        # load the GCSE dataset

# Fit the Stage 1 model
Model.1.GCSE &lt;- Stage.1(Dataset=GCSE, 
    Model=Science.Exam~Gender)

# Make a normative table for raw Science Exam scores = 10, 
# 11, ... 85, stratified by Gender
NormTable.GCSE &lt;- Stage.2.NormTable(Stage.1.Model=Model.1.GCSE,
    Test.Scores=c(10:85), 
    Grid.Norm.Table=data.frame(Gender=c("F", "M")))
summary(NormTable.GCSE)

# Write the normative table to the user's computer
WriteNormTable(NormTable=NormTable.GCSE, 
     NameFile="NormTable.GCSE.xlsx",
     Folder=tempdir()) # Replace tempdir() by the desired folder  


# Replicate the normative table that was obtained in 
# Case study 1 of Chapter 7 in Van der Elst (2023)
# ------------------------------------------------
library(NormData)   # load the NormData package
data(Substitution)  # load the Substitution dataset

# Make the new variable Age.C (= Age centered) that is 
# needed to fit the final Stage 1 model, 
# and add it to the Substitution dataset
Substitution$Age.C &lt;- Substitution$Age - 50

# Fit the final Stage 1 model
Substitution.Model.9 &lt;- Stage.1(Dataset=Substitution, 
   Alpha=0.005, Model=LDST~Age.C+LE, Order.Poly.Var=1) 

# Make a normative table for LDST scores = 10, 12, ... 56,
# stratified by Age and LE
NormTable.LDST &lt;- Stage.2.NormTable(
  Stage.1.Model=Substitution.Model.9,
  Test.Scores=seq(from=10, to=56, by=2),
  Grid.Norm.Table=expand.grid(Age.C=seq(from=-30, to=30, by=1),
     LE=c("Low", "Average", "High")))

# Write the normative table to the user's computer
WriteNormTable(NormTable=NormTable.LDST, 
  NameFile="NormTable.LDST.xlsx",
  Folder=tempdir()) # Replace tempdir() by the desired folder  
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
