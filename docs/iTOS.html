<!DOCTYPE html><html lang="en"><head><title>Help for package iTOS</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {iTOS}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#iTOS-package'>
<p>Methods and Examples from Introduction to the Theory of Observational Studies</p></a></li>
<li><a href='#addcaliper'>
<p>Add a Caliper to an Existing Cost Matrix</p></a></li>
<li><a href='#addinteger'>
<p>Add an Integer Penalty to an Existing Distance Matrix</p></a></li>
<li><a href='#addMahal'>
<p>Rank-Based Mahalanobis Distance Matrix</p></a></li>
<li><a href='#addNearExact'>
<p>Add a Near-exact Penalty to an Exisiting Distance Matrix.</p></a></li>
<li><a href='#addquantile'>
<p>Cut a Covariate at Quantiles and Add a Penalty for Different Quantile Categories</p></a></li>
<li><a href='#aHDL'>
<p>Alcohol and HDL Cholesterol</p></a></li>
<li><a href='#amplify'>
<p>Amplification of sensitivity analysis in observational studies.</p></a></li>
<li><a href='#binge'>
<p>Binge Drinking and High Blood Pressure</p></a></li>
<li><a href='#bingeM'>
<p>Binge Drinking and High Blood Pressure &ndash; Matched With Two Control Groups</p></a></li>
<li><a href='#computep'>
<p>Computes individual and pairwise treatment assignment probabilities.</p></a></li>
<li><a href='#ev'>
<p>Computes the null expectation and variance for one stratum.</p></a></li>
<li><a href='#evalBal'>
<p>Evaluate Covariate Balance in a Matched Sample</p></a></li>
<li><a href='#evall'>
<p>Compute expectations and variances for one stratum.</p></a></li>
<li><a href='#gconv'><p>Convolution of Two Probability Generating Functions</p></a></li>
<li><a href='#makematch'>
<p>Two-Criteria Matching</p></a></li>
<li><a href='#makenetwork'>
<p>Make the Network Used for Matching with Two Criteria</p></a></li>
<li><a href='#noether'>
<p>Sensitivity Analysis Using Noether's Test for Matched Pairs</p></a></li>
<li><a href='#startcost'>
<p>Initialize a Distance Matrix.</p></a></li>
<li><a href='#zeta'>
<p>zeta function in sensitivity analysis</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Methods and Examples from Introduction to the Theory of
Observational Studies</td>
</tr>
<tr>
<td>Version:</td>
<td>1.0.3</td>
</tr>
<tr>
<td>Author:</td>
<td>Paul R. Rosenbaum [aut, cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Paul R. Rosenbaum &lt;rosenbaum@wharton.upenn.edu&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Supplements for a book, "iTOS" = "Introduction to the Theory of Observational Studies."  Data sets are 'aHDL' from Rosenbaum (2023a) &lt;<a href="https://doi.org/10.1111%2Fbiom.13558">doi:10.1111/biom.13558</a>&gt; and 'bingeM' from Rosenbaum (2023b) &lt;<a href="https://doi.org/10.1111%2Fbiom.13921">doi:10.1111/biom.13921</a>&gt;.  The function makematch() uses two-criteria matching from Zhang et al. (2023) &lt;<a href="https://doi.org/10.1080%2F01621459.2021.1981337">doi:10.1080/01621459.2021.1981337</a>&gt; to create the matched data 'bingeM' from 'binge'.  The makematch() function also implements optimal matching (Rosenbaum (1989) &lt;<a href="https://doi.org/10.2307%2F2290079">doi:10.2307/2290079</a>&gt;) and matching with fine or near-fine balance (Rosenbaum et al. (2007) &lt;<a href="https://doi.org/10.1198%2F016214506000001059">doi:10.1198/016214506000001059</a>&gt; and Yang et al (2012) &lt;<a href="https://doi.org/10.1111%2Fj.1541-0420.2011.01691.x">doi:10.1111/j.1541-0420.2011.01691.x</a>&gt;).  The book makes use of two other R packages, 'weightedRank' and 'tightenBlock'.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>Imports:</td>
<td>stats, MASS, rcbalance, BiasedUrn, xtable</td>
</tr>
<tr>
<td>Suggests:</td>
<td>weightedRank</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0)</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-09-02 19:37:06 UTC; rosenbap</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-09-05 16:00:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='iTOS-package'>
Methods and Examples from Introduction to the Theory of Observational Studies
</h2><span id='topic+iTOS-package'></span><span id='topic+iTOS'></span>

<h3>Description</h3>

<p>Supplements for a book, &quot;iTOS&quot; = &quot;Introduction to the Theory of Observational Studies.&quot;  Data sets are 'aHDL' from Rosenbaum (2023a) &lt;doi:10.1111/biom.13558&gt; and 'bingeM' from Rosenbaum (2023b) &lt;doi:10.1111/biom.13921&gt;.  The function makematch() uses two-criteria matching from Zhang et al. (2023) &lt;doi:10.1080/01621459.2021.1981337&gt; to create the matched data 'bingeM' from 'binge'.  The makematch() function also implements optimal matching (Rosenbaum (1989) &lt;doi:10.2307/2290079&gt;) and matching with fine or near-fine balance (Rosenbaum et al. (2007) &lt;doi:10.1198/016214506000001059&gt; and Yang et al (2012) &lt;doi:10.1111/j.1541-0420.2011.01691.x&gt;).  The book makes use of two other R packages, 'weightedRank' and 'tightenBlock'.
</p>


<h3>Details</h3>

<p>The DESCRIPTION file:
</p>

<table>
<tr>
 <td style="text-align: left;">
Package: </td><td style="text-align: left;"> iTOS</td>
</tr>
<tr>
 <td style="text-align: left;">
Type: </td><td style="text-align: left;"> Package</td>
</tr>
<tr>
 <td style="text-align: left;">
Title: </td><td style="text-align: left;"> Methods and Examples from Introduction to the Theory of Observational Studies</td>
</tr>
<tr>
 <td style="text-align: left;">
Version: </td><td style="text-align: left;"> 1.0.3</td>
</tr>
<tr>
 <td style="text-align: left;">
Authors@R: </td><td style="text-align: left;"> person(given = c("Paul", "R."),
                    family = "Rosenbaum",
                    role = c("aut", "cre"),
                    email = "rosenbaum@wharton.upenn.edu")</td>
</tr>
<tr>
 <td style="text-align: left;">
Author: </td><td style="text-align: left;"> Paul R. Rosenbaum [aut, cre]</td>
</tr>
<tr>
 <td style="text-align: left;">
Maintainer: </td><td style="text-align: left;"> Paul R. Rosenbaum &lt;rosenbaum@wharton.upenn.edu&gt;</td>
</tr>
<tr>
 <td style="text-align: left;">
Description: </td><td style="text-align: left;"> Supplements for a book, "iTOS" = "Introduction to the Theory of Observational Studies."  Data sets are 'aHDL' from Rosenbaum (2023a) &lt;doi:10.1111/biom.13558&gt; and 'bingeM' from Rosenbaum (2023b) &lt;doi:10.1111/biom.13921&gt;.  The function makematch() uses two-criteria matching from Zhang et al. (2023) &lt;doi:10.1080/01621459.2021.1981337&gt; to create the matched data 'bingeM' from 'binge'.  The makematch() function also implements optimal matching (Rosenbaum (1989) &lt;doi:10.2307/2290079&gt;) and matching with fine or near-fine balance (Rosenbaum et al. (2007) &lt;doi:10.1198/016214506000001059&gt; and Yang et al (2012) &lt;doi:10.1111/j.1541-0420.2011.01691.x&gt;).  The book makes use of two other R packages, 'weightedRank' and 'tightenBlock'.</td>
</tr>
<tr>
 <td style="text-align: left;">
License: </td><td style="text-align: left;"> GPL-2</td>
</tr>
<tr>
 <td style="text-align: left;">
Encoding: </td><td style="text-align: left;"> UTF-8</td>
</tr>
<tr>
 <td style="text-align: left;">
LazyData: </td><td style="text-align: left;"> true</td>
</tr>
<tr>
 <td style="text-align: left;">
Imports: </td><td style="text-align: left;"> stats, MASS, rcbalance, BiasedUrn, xtable</td>
</tr>
<tr>
 <td style="text-align: left;">
Suggests: </td><td style="text-align: left;"> weightedRank</td>
</tr>
<tr>
 <td style="text-align: left;">
Depends: </td><td style="text-align: left;"> R (&gt;= 3.5.0)</td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>


<p>Index of help topics:
</p>
<pre>
aHDL                    Alcohol and HDL Cholesterol
addMahal                Rank-Based Mahalanobis Distance Matrix
addNearExact            Add a Near-exact Penalty to an Exisiting
                        Distance Matrix.
addcaliper              Add a Caliper to an Existing Cost Matrix
addinteger              Add an Integer Penalty to an Existing Distance
                        Matrix
addquantile             Cut a Covariate at Quantiles and Add a Penalty
                        for Different Quantile Categories
amplify                 Amplification of sensitivity analysis in
                        observational studies.
binge                   Binge Drinking and High Blood Pressure
bingeM                  Binge Drinking and High Blood Pressure -
                        Matched With Two Control Groups
computep                Computes individual and pairwise treatment
                        assignment probabilities.
ev                      Computes the null expectation and variance for
                        one stratum.
evalBal                 Evaluate Covariate Balance in a Matched Sample
evall                   Compute expectations and variances for one
                        stratum.
gconv                   Convolution of Two Probability Generating
                        Functions
iTOS-package            Methods and Examples from Introduction to the
                        Theory of Observational Studies
makematch               Two-Criteria Matching
makenetwork             Make the Network Used for Matching with Two
                        Criteria
noether                 Sensitivity Analysis Using Noether's Test for
                        Matched Pairs
startcost               Initialize a Distance Matrix.
zeta                    zeta function in sensitivity analysis
</pre>


<h3>Author(s)</h3>

<p>Paul R. Rosenbaum [aut, cre]
</p>
<p>Maintainer: Paul R. Rosenbaum &lt;rosenbaum@wharton.upenn.edu&gt;
</p>


<h3>References</h3>

<p>Rosenbaum, Paul R. Introduction to the Theory of Observational Studies.  Manuscript, 2024.
</p>
<p>Rosenbaum, P. R. (1989) &lt;doi:10.2307/2290079&gt; Optimal matching for observational studies. Journal of the American Statistical Association, 84, 1024-1032.
</p>
<p>Rosenbaum, Paul R., Richard N. Ross, and Jeffrey H. Silber (2007)
&lt;doi:10.1198/016214506000001059&gt; Minimum distance matched sampling with fine balance in an observational study of treatment for ovarian cancer. Journal of the American Statistical Association 102, 75-83.
</p>
<p>Rosenbaum, P. R. (2023a) &lt;doi:10.1111/biom.13558&gt; Sensitivity analyses informed by tests for bias in observational studies. Biometrics 79, 475-487.
</p>
<p>Rosenbaum, P. R. (2023b) &lt;doi:10.1111/biom.13921&gt; A second evidence factor for a second control group. Biometrics, 79, 3968-3980.
</p>
<p>Yang, D., Small, D. S., Silber, J. H. and Rosenbaum, P. R. (2012)
&lt;doi:10.1111/j.1541-0420.2011.01691.x&gt; Optimal matching with minimal deviation from fine balance in a study of obesity and surgical outcomes. Biometrics, 68, 628-636.
</p>
<p>Zhang, B., D. S. Small, K. B. Lasater, M. McHugh, J. H. Silber, and P. R. Rosenbaum (2023) &lt;doi:10.1080/01621459.2021.1981337&gt; Matching one sample according to two criteria in observational studies. Journal of the American Statistical Association, 118, 1140-1151.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(binge)
table(binge$AlcGroup)
data(aHDL)
table(aHDL$grp)
</code></pre>

<hr>
<h2 id='addcaliper'>
Add a Caliper to an Existing Cost Matrix
</h2><span id='topic+addcaliper'></span>

<h3>Description</h3>

<p>For one covariate, adds a caliper to an existing cost matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>addcaliper(costmatrix, z, p, caliper = NULL, penalty = 1000, twostep = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="addcaliper_+3A_costmatrix">costmatrix</code></td>
<td>

<p>An existing cost matrix with sum(z) rows and sum(1-z) columns.  The function checks the compatability of costmatrix, z and p; so, it may stop with an error if these are not of appropriate dimensions.  In particular, costmatrix may come from startcost().
</p>
</td></tr>
<tr><td><code id="addcaliper_+3A_z">z</code></td>
<td>

<p>A vector with z[i]=1 if individual i is treated or z[i]=0 if individual i is control.  The rows of costmatrix refer to treated individuals and the columns refer to controls.
</p>
</td></tr>
<tr><td><code id="addcaliper_+3A_p">p</code></td>
<td>

<p>A vector with the same length as p.  The vector p is the covariate for which a caliper is needed.
</p>
</td></tr>
<tr><td><code id="addcaliper_+3A_caliper">caliper</code></td>
<td>

<p>Determines the type and length of the caliper.  The caliper becomes a vector cvex with length 2.  If is.null(caliper), then the caliper is +/- 0.2 times the standard deviation of p, namely
cvec = c(-.2,.2)*sd(p).  If caliper is a single number, then the caliper is +/- caliper, or cvec = c(-1,1)*abs(caliper).  If caliper is a vector of length 2, then an asymmetric caliper is used,
cvec = c(min(caliper),max(caliper)), where min(caliper) must be negative and max caliper must be positive.
</p>
</td></tr>
<tr><td><code id="addcaliper_+3A_penalty">penalty</code></td>
<td>

<p>Let I be the index of ith treated individual, 1,...,sum(z), and J be the index of the jth control, j=1,...,sum(1-z), so 1 &lt;= I &lt;= length(z) and so 1 &lt;= J &lt;= length(z).  The penality added to costmatrix[i,j] is 0 if cvec[1] &lt;= p[I]-p[J] &lt;= cvex[2].
</p>
</td></tr>
<tr><td><code id="addcaliper_+3A_twostep">twostep</code></td>
<td>

<p>If twostep is FALSE, then no action is taken.  If twostep is true, no action is take if 2 cvec[1] &lt;= p[I]-p[J] &lt;= 2 cvex[2], and otherwise costmatrix[i,j] is further increased by adding penalty.  In words, the penalty is doubled if p[I]-p[J] falls outside twice the caliper.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For discussion of directional calipers, see Yu and Rosenbaum (2019).
</p>


<h3>Value</h3>

<p>A penalized costmatrix.
</p>


<h3>Author(s)</h3>

<p>Paul R. Rosenbaum
</p>


<h3>References</h3>

<p>Cochran, William G., and Donald B. Rubin. Controlling bias in observational studies: A review. Sankhya: The Indian Journal of Statistics, Series A 1973;35:417-446.
</p>
<p>Yu, Ruoqi, and Paul R. Rosenbaum. &lt;doi:10.1111/biom.13098&gt; Directional penalties for optimal matching in observational studies. Biometrics 2019;75:1380-1390.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(binge)
# Select two treated and three controls from binge
d&lt;-binge[is.element(binge$SEQN,c(109315,109365,109266,109273,109290)),]
z&lt;-1*(d$AlcGroup=="B")
names(z)&lt;-d$SEQN
attach(d)
x&lt;-data.frame(age,female)
detach(d)
rownames(x)&lt;-d$SEQN
dist&lt;-startcost(z)
z
x
dist

# Ten-year age caliper
addcaliper(dist,z,x$age,caliper=10,twostep=FALSE)

# Ten-year age caliper with twostep=TRUE
addcaliper(dist,z,x$age,caliper=10,twostep=TRUE)

# Same ten-year age caliper with twostep=TRUE
addcaliper(dist,z,x$age,caliper=c(-10,10))

# Asymmetric, directional age caliper with twostep=TRUE
addcaliper(dist,z,x$age,caliper=c(-2,10))
# Treated 109315 aged 30 is more than 2 years younger
# than control 109273 aged 36, 30-36&lt;(-2), so
# row 109315 column 109273 is penalized, indeed
# double penalized, as 30-36&lt;2*(-2)

rm(z,x,dist,d)
</code></pre>

<hr>
<h2 id='addinteger'>
Add an Integer Penalty to an Existing Distance Matrix
</h2><span id='topic+addinteger'></span>

<h3>Description</h3>

<p>Takes an integer valued covariate, and adds a penalty proportional
to the difference in the integer values, with proportionality constant
penalty.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>addinteger(costmatrix, z, iscore, penalty = 1000)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="addinteger_+3A_costmatrix">costmatrix</code></td>
<td>

<p>An existing cost matrix with sum(z) rows and sum(1-z) columns.  The function checks the compatability of costmatrix, z and p; so, it may stop with an error if these are not of appropriate dimensions.  In particular, costmatrix may come from startcost().
</p>
</td></tr>
<tr><td><code id="addinteger_+3A_z">z</code></td>
<td>

<p>A vector with z[i]=1 if individual i is treated or z[i]=0 if individual i is control.  The rows of costmatrix refer to treated individuals and the columns refer to controls.
</p>
</td></tr>
<tr><td><code id="addinteger_+3A_iscore">iscore</code></td>
<td>

<p>An vector of integers with length equal to length(z).
</p>
</td></tr>
<tr><td><code id="addinteger_+3A_penalty">penalty</code></td>
<td>

<p>One positive number used to penalize mismatches for iscore.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If a treated and control individual differ on iscore in absolute value by dif, then the distance between them is increased by adding dif*penalty.
</p>


<h3>Value</h3>

<p>A penalized distance matrix.
</p>


<h3>Author(s)</h3>

<p>Paul R. Rosenbaum
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(binge)
# Select two treated and four controls from binge
d&lt;-binge[is.element(binge$SEQN,c(109315,109365,109266,109273,109290,109332)),]
attach(d)
z&lt;-1*(AlcGroup=="B")
names(z)&lt;-d$SEQN
rbind(z,education)
dist&lt;-startcost(z)
addinteger(dist,z,education,penalty=3)
detach(d)
rm(d,dist,z)
</code></pre>

<hr>
<h2 id='addMahal'>
Rank-Based Mahalanobis Distance Matrix
</h2><span id='topic+addMahal'></span>

<h3>Description</h3>

<p>Adds a rank-based Mahalanobis distance to an exisiting distance matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>addMahal(costmatrix, z, X)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="addMahal_+3A_costmatrix">costmatrix</code></td>
<td>

<p>An existing cost matrix with sum(z) rows and sum(1-z) columns.  The function checks the compatability of costmatrix, z and p; so, it may stop with an error if these are not of appropriate dimensions.  In particular, costmatrix may come from startcost().
</p>
</td></tr>
<tr><td><code id="addMahal_+3A_z">z</code></td>
<td>

<p>A vector with z[i]=1 if individual i is treated or z[i]=0 if individual i is control.  The rows of costmatrix refer to treated individuals and the columns refer to controls.
</p>
</td></tr>
<tr><td><code id="addMahal_+3A_x">X</code></td>
<td>

<p>A matrix with length(z) rows containing covariates.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The rank-based Mahalanobis distance is defined in section 9.3 of Rosenbaum (2020).
</p>


<h3>Value</h3>

<p>A new distance matrix that is the sum of costmatrix and the rank-based Mahalanobis distances.
</p>


<h3>Author(s)</h3>

<p>Paul R. Rosenbaum
</p>


<h3>References</h3>

<p>Rosenbaum, P. R. (2020) &lt;doi:10.1007/978-3-030-46405-9&gt; Design of Observational Studies (2nd Edition).  New York: Springer.
</p>
<p>Rubin, D. B. (1980) &lt;doi:10.2307/2529981&gt; Bias reduction using Mahalanobis-metric matching. Biometrics, 36, 293-298.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(binge)
# Select two treated and three controls from binge
d&lt;-binge[is.element(binge$SEQN,c(109315,109365,109266,109273,109290)),]
z&lt;-1*(d$AlcGroup=="B")
names(z)&lt;-d$SEQN
attach(d)
x&lt;-cbind(age,female)
detach(d)
rownames(x)&lt;-d$SEQN
dist&lt;-startcost(z)
z
x
dist
dist&lt;-addMahal(dist,z,x)
dist
rm(z,x,dist,d)
</code></pre>

<hr>
<h2 id='addNearExact'>
Add a Near-exact Penalty to an Exisiting Distance Matrix.
</h2><span id='topic+addNearExact'></span>

<h3>Description</h3>

<p>Add a Near-exact Penalty to an Exisiting Distance Matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>addNearExact(costmatrix, z, exact, penalty = 1000)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="addNearExact_+3A_costmatrix">costmatrix</code></td>
<td>

<p>An existing cost matrix with sum(z) rows and sum(1-z) columns.  The function checks the compatability of costmatrix, z and p; so, it may stop with an error if these are not of appropriate dimensions.  In particular, costmatrix may come from startcost().
</p>
</td></tr>
<tr><td><code id="addNearExact_+3A_z">z</code></td>
<td>

<p>A vector with z[i]=1 if individual i is treated or z[i]=0 if individual i is control.  The rows of costmatrix refer to treated individuals and the columns refer to controls.
</p>
</td></tr>
<tr><td><code id="addNearExact_+3A_exact">exact</code></td>
<td>

<p>A vector with the same length as z.  Typically, exact take a small or moderate number of values.
</p>
</td></tr>
<tr><td><code id="addNearExact_+3A_penalty">penalty</code></td>
<td>

<p>One positive number.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If the ith treated individual and the jth control have different values of exact, then the distance between them in costmatrix is increased by adding penalty.
</p>


<h3>Value</h3>

<p>A penalized distance matrix.
</p>


<h3>Note</h3>

<p>A sufficiently large penalty will maximize the number of individuals exactly matched for exact.  A smaller penalty will tend to increase the number of individuals matched exactly, without prioritizing one covariate over all others.
</p>
<p>If the left distance matrix is penalized, it will affect pairing and balance; however, if the right distance matrix is penalized it will affect balance only, as in the near-fine balance technique of Yang et al. (2012).
</p>
<p>Adding several near-exact penalties for different covariates on the right distance matrix implements a Hamming distance on the joint distribution of those covariates, as discussed in Zhang et al. (2023).
</p>
<p>Near-exact matching for a nominal covariate is discussed and contrasted with exact matching in Sections 10.3 and 10.4 of Rosenbaum (2020).  Near-exact matching is always feasible, because it implements a constraint using a penalty.  Exact matching may be infeasible, but when feasible it may be used to speed up computations.  For an alternative method of
speeding computations, see Yu et al. (2020) who identify feasible constraints very quickly prior to matching with those constraints.
</p>


<h3>Author(s)</h3>

<p>Paul R. Rosenbaum
</p>


<h3>References</h3>

<p>Rosenbaum, P. R. (2020) &lt;doi:10.1007/978-3-030-46405-9&gt; Design of Observational Studies (2nd Edition).  New York: Springer.
</p>
<p>Yang, D., Small, D. S., Silber, J. H. and Rosenbaum, P. R. (2012)
&lt;doi:10.1111/j.1541-0420.2011.01691.x&gt; Optimal matching with minimal deviation from fine balance in a study of obesity and surgical outcomes. Biometrics, 68, 628-636. (Extension of fine balance useful when fine balance is infeasible. Comes as close as possible to fine balance. Implemented in makematch() by placing a large near-exact
penalty on a nominal/integer covariate x1 on the right distance matrix.)
</p>
<p>Yu, R., Silber, J. H., Rosenbaum, P. R. (2020) &lt;doi:10.1214/19-STS699&gt; Matching Methods for Observational Studies Derived from Large Administrative Databases. Statistical Science, 35, 338-355.
</p>
<p>Zhang, B., D. S. Small, K. B. Lasater, M. McHugh, J. H. Silber, and P. R. Rosenbaum (2023) &lt;doi:10.1080/01621459.2021.1981337&gt; Matching one sample according to two criteria in observational studies. Journal of the American Statistical Association, 118, 1140-1151.
</p>
<p>Zubizarreta, J. R., Reinke, C. E., Kelz, R. R., Silber, J. H. and Rosenbaum, P. R. (2011) &lt;doi:10.1198/tas.2011.11072&gt; Matching for several sparse nominal variables in a case control study of readmission following surgery. The American Statistician, 65(4), 229-238.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(binge)
# Select two treated and three controls from binge
d&lt;-binge[is.element(binge$SEQN,c(109315,109365,109266,109273,109290)),]
z&lt;-1*(d$AlcGroup=="B")
names(z)&lt;-d$SEQN
attach(d)
x&lt;-data.frame(age,female)
detach(d)
rownames(x)&lt;-d$SEQN
dist&lt;-startcost(z)
z
x
dist
addNearExact(dist,z,x$female)
addNearExact(dist,z,x$age&lt;40,penalty=10)

# Combine several penalties
dist&lt;-addNearExact(dist,z,x$female)
dist&lt;-addNearExact(dist,z,x$age&lt;40,penalty=10)
dist
dist&lt;-addNearExact(dist,z,x$age&lt;60,penalty=5)
dist
# This distance suggests pairing 109315-109266
# and 109365-109290
rm(z,x,dist,d)
</code></pre>

<hr>
<h2 id='addquantile'>
Cut a Covariate at Quantiles and Add a Penalty for Different Quantile Categories
</h2><span id='topic+addquantile'></span>

<h3>Description</h3>

<p>Cut a Covariate at Quantiles and Add a Penalty for Different Quantile Categories
</p>


<h3>Usage</h3>

<pre><code class='language-R'>addquantile(costmatrix, z, p, pct = c(0.2, 0.4, 0.6, 0.8), penalty = 1000)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="addquantile_+3A_costmatrix">costmatrix</code></td>
<td>

<p>An existing cost matrix with sum(z) rows and sum(1-z) columns.  The function checks the compatability of costmatrix, z and p; so, it may stop with an error if these are not of appropriate dimensions.  In particular, costmatrix may come from startcost().
</p>
</td></tr>
<tr><td><code id="addquantile_+3A_z">z</code></td>
<td>

<p>A vector with z[i]=1 if individual i is treated or z[i]=0 if individual i is control.  The rows of costmatrix refer to treated individuals and the columns refer to controls.
</p>
</td></tr>
<tr><td><code id="addquantile_+3A_p">p</code></td>
<td>

<p>A vector of length equal to length(z).  Quantiles of p will penalize the distance.
</p>
</td></tr>
<tr><td><code id="addquantile_+3A_pct">pct</code></td>
<td>

<p>A vector of numbers strictly between 0 and 1.  These determine the quantiles of p.  For instance, c(.25,.5,.75) uses the quartiles of p.
</p>
</td></tr>
<tr><td><code id="addquantile_+3A_penalty">penalty</code></td>
<td>

<p>One positive number used as a penalty.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The vector p is cut at its quantiles defined by pct, and the integer difference in quantile categories is multiplied by penalty and added to the distance matrix.
The function is similar to addinteger(), except the integer values are not
specified, but rather are deduced from the quantiles.
</p>
<p>If you cannot match for the quantile category of p, then addquantile() prefers
to match from an adjacent quantile category.
</p>


<h3>Value</h3>

<p>A penalized distance matrix.
</p>


<h3>Author(s)</h3>

<p>Paul R. Rosenbaum
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(binge)
d&lt;-binge[binge$AlcGroup!="N",]
attach(d)
z&lt;-1*(AlcGroup=="B")
names(z)&lt;-SEQN
dist&lt;-startcost(z)
quantile(age,pct=c(1/4,1/2,3/4))
rbind(z,age)[,1:20]
addquantile(dist,z,d$age,pct=c(1/4,1/2,3/4),penalty=5)[1:5,1:7]
detach(d)
rm(z,dist,d)
</code></pre>

<hr>
<h2 id='aHDL'>
Alcohol and HDL Cholesterol
</h2><span id='topic+aHDL'></span>

<h3>Description</h3>

<p>A small observational study of light daily alcohol consumption and HDL cholesterol &ndash; so-called good cholesterol &ndash; derived from NHANES 2013-2014
and 2015-2016.  There are 406 matched sets of four individuals, making 1624 individuals in total.  Sets were matched for age, female and education in five ordered categories.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("aHDL")</code></pre>


<h3>Format</h3>

<p>A data frame with 1624 observations on the following 11 variables.
</p>

<dl>
<dt><code>nh</code></dt><dd><p>NHANES 2013-2014 is 1314, and NHANES 2015-2016 is 1516</p>
</dd>
<dt><code>SEQN</code></dt><dd><p>NHANES ID number</p>
</dd>
<dt><code>age</code></dt><dd><p>Age in years</p>
</dd>
<dt><code>female</code></dt><dd><p>1=female, 0=male</p>
</dd>
<dt><code>education</code></dt><dd><p>1 is &lt;9th grade, 3 is high school, 5 is a BA degree</p>
</dd>
<dt><code>z</code></dt><dd><p>1=light almost daily alcohol, 0=little or no alcohol last year.</p>
</dd>
<dt><code>grp</code></dt><dd><p>Treated group and control groups.  Daily=light almost daily alcohol, Never=fewer than 12 drinks during entire life, Rarely=more than 12 drinks in life, but fewer than 12 in the past year, and never had a period of daily binge drinking, PastBinge = a past history of binge drinking on most days, but currently drinks once a week or less.  For details, see Rosenbaum (2022a, Appendix).</p>
</dd>
<dt><code>grpL</code></dt><dd><p>Short labels for plotting formed as the first letters of grp. <code>D</code> &lt; <code>N</code> &lt; <code>R</code> &lt; <code>B</code></p>
</dd>
<dt><code>hdl</code></dt><dd><p>HDL cholesterol level mg/dL</p>
</dd>
<dt><code>mmercury</code></dt><dd><p>Methylmercury level ug/L</p>
</dd>
<dt><code>mset</code></dt><dd><p>Matched set indicator, 1, 2, ..., 406.  The 1624 observations are in 406 matched sets, each of size 4.</p>
</dd>
</dl>



<h3>Details</h3>

<p>There is a debate about whether light daily alcohol consumption &ndash; a single glass of red wine &ndash; shortens or lengthens life.  LoConte et al. (2018) emphasize that alcohol is a carcinogen.  Suh et al. (1992) claim reduced cardiovascular mortality brought about by an increase in high density high-density lipoprotein (HDL) cholesterol, the so-called good cholesterol.  There is on-going debate about whether there are cardiovascular benefits, and if they exist, whether they are large enough to offset an increased risk of cancer.  This example looks at a small corner of the larger debate, namely the effect on HDL cholesterol.
</p>
<p>The example contains several attempts to detect unmeasured confounding bias, if present.  There is a secondary outcome thought to be unaffected by alcohol consumption, namely methylmercury levels in the blood, likely an indicator of the consumption of fish, not of alcohol; see Pedersen et al. (1994) and WHO (2021).  There are also three control groups, all with little present alcohol consumption, but with different uses of alcohol in the past; see the definition of variable grp above.
</p>
<p>The appendix to Rosenbaum (2023) describes the data and matching in detail.  It is used as an example in Rosenbaum (2022).
</p>
<p>The help file for boxplotTT() applies the tail transformation to this example, reproducing a plot from Rosenbaum (2022).
</p>
<p>This data set is also included in the tailTransform package.  See also the informedSen package which contains a part of this data set.
</p>


<h3>Source</h3>

<p>US National Health and Nutrition Examination Survey (NHANES), 2013-2014 and 2015-2016.
</p>


<h3>References</h3>

<p>LoConte, N. K., Brewster, A. M., Kaur, J. S., Merrill, J. K., and Alberg, A. J.
&lt;doi:10.1200/JCO.2017.76.1155&gt; Alcohol and cancer: a statement of the American Society of Clinical Oncology. Journal of Clinical Oncology 2018;36:83-93.
</p>
<p>Pedersen, G. A., Mortensen, G. K. and Larsen, E. H. &lt;doi:10.1080/02652039409374234&gt; Beverages as a source of toxic trace element intake. Food Additives and Contaminants,
1994;11:351â€“363.
</p>
<p>Rosenbaum, P. R. (1987) &lt;doi:10.1214/ss/1177013232&gt; The role of a second control group in an observational study. Statistical Science, 1987;2:292-306.
</p>
<p>Rosenbaum, P. R. &lt;doi:10.2307/2531497&gt; The role of known effects in observational studies. Biometrics, 1989;45:557-569.
</p>
<p>Rosenbaum, P. R. &lt;doi:10.1214/aos/1176347131&gt;  On permutation tests for hidden biases in observational studies. The Annals of Statistics, 1989;17:643-653.
</p>
<p>Rosenbaum, P. R. &lt;doi:10.1080/01621459.2013.879261&gt; Weighted M-statistics with superior design sensitivity in matched observational studies with multiple controls. Journal of the American Statistical Association, 2014;109(507):1145-1158
</p>
<p>Rosenbaum, P. R. &lt;doi:10.1080/00031305.2022.2063944&gt; (2022). A new transformation of treated-control matched-pair differences for graphical display.  American Statistician, 2022;76(4):346-352.
</p>
<p>Rosenbaum, P. R. &lt;doi:10.1111/biom.13558&gt; Sensitivity analyses informed by tests for bias in observational studies. Biometrics 2023;79(1):475-487.
</p>
<p>Suh, I., Shaten, B. J., Cutler, J. A., and Kuller, L. H.
&lt;doi:10.7326/0003-4819-116-11-881&gt; Alcohol use and mortality from coronary heart disease: The role of high-density lipoprotein cholesterol. Annals of Internal Medicine 1992;116:881-887.
</p>
<p>World Health Organization (2021). Mercury and Health,
&lt;https://www.who.int/news-room/fact-sheets/detail/mercury-and-health&gt;, (Accessed 30 August 2021).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(aHDL)
table(aHDL$grp,aHDL$grpL) # Short labels for plotting
boxplot(aHDL$age~aHDL$grp,xlab="Group",ylab="Age")
boxplot(aHDL$education~aHDL$grp,xlab="Group",ylab="Education")
table(aHDL$female,aHDL$grpL)
table(aHDL$z,aHDL$grpL)
#
# In iTOS book, for Table 8.1
y&lt;-t(matrix(aHDL$hdl,4,406))
weightedRank::wgtRank(y,gamma=5,phi="wilc")
weightedRank::wgtRank(y,gamma=5,phi="quade")
weightedRank::wgtRank(y,gamma=5,phi="u868")
weightedRank::wgtRank(y,gamma=5,phi="u878")
#
# The sets were also matched for is.na(aHDL$mmercury), for use
# in Rosenbaum (2023).  About half of the matched sets
# have values for mmercury.  Discussed in Chapter 12 of iTOS.
table(is.na(aHDL$mmercury),aHDL$grp)
# See also the informedSen package for additional analysis
</code></pre>

<hr>
<h2 id='amplify'>
Amplification of sensitivity analysis in observational studies.
</h2><span id='topic+amplify'></span>

<h3>Description</h3>

<p>Uses the method in Rosenbaum and Silber (2009) to interpret a value of the sensitivity parameter gamma.  Each value of gamma amplifies to a curve (lambda,delta) in a two-dimensional sensitivity analysis, the inference being the same for all points on the curve.
That is, a one-dimensional sensitivity analysis in terms of gamma has a two-dimensional interpretation in terms of (lambda,delta).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>amplify(gamma, lambda)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="amplify_+3A_gamma">gamma</code></td>
<td>

<p>gamma &gt; 1 is the value of the sensitivity parameter, for instance the parameter in senmv.  length(gamma)&gt;1 will generate an error.
</p>
</td></tr>
<tr><td><code id="amplify_+3A_lambda">lambda</code></td>
<td>

<p>lambda is a vector of values &gt; gamma.  An error will result unless lambda[i] &gt; gamma &gt; 1 for every i.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A single value of gamma, say gamma = 2.2 in the example, corresponds to a curve of values of (lambda, delta), including (3, 7),
(4, 4.33), (5, 3.57), and (7, 3) in the example.  An unobserved covariate that is associated with a lambda = 3 fold increase in the odds of treatment and a delta = 7 fold increase in the odds of a positive pair difference is equivalent to gamma = 2.2.
</p>
<p>The curve is gamma = (lambda*delta + 1)/(lambda+delta).  Amplify is given one gamma and a vector of lambdas and solves for the vector of deltas.  The calculation is elementary.
</p>
<p>This interpretation of gamma is developed in detail in Rosenbaum and Silber (2009), and it makes use of Wolfe's (1974) family of semiparametric deformations of an arbitrary symmetric distribuiton.  See also Rosenbaum (2020, Section 3.6).  For an elementary discussion, see Rosenbaum (2017, Table 9.1).
</p>
<p>Strictly speaking, the amplification describes matched pairs, not matched sets.  The senm function views a k-to-1 matched set with k controls matched to one treated individual as a collection of k correlated treated-minus-control matched pair differences; see Rosenbaum (2007).  For matched sets, it is natural to think of the amplification as describing any one of the k matched pair differences in a k-to-1 matched set.
</p>
<p>The curve has asymptotes that the function amplify does not compute: gamma corresponds with (lambda,delta) = (gamma, Inf) and (Inf, gamma).
</p>
<p>A related though distict idea is developed in Gastwirth et al (1998).  The two approaches agree when the outcome is binary, that is, for McNemar's test.
</p>


<h3>Value</h3>

<p>Returns a vector of values of delta of length(lambda) with names lambda.
</p>


<h3>Note</h3>

<p>The amplify function is also in the sensitivitymv package where a different example is used.
</p>


<h3>Author(s)</h3>

<p>Paul R. Rosenbaum
</p>


<h3>References</h3>

<p>Gastwirth, J. L., Krieger, A. M., Rosenbaum, P. R. (1998)
&lt;doi:10.1093/biomet/85.4.907&gt; Dual and
simultaneous sensitivity analysis for matched pairs. Biometrika, 85, 907-920.
</p>
<p>Rosenbaum, P. R. and Silber, J. H. (2009) &lt;doi:10.1198/jasa.2009.tm08470&gt; Amplification of sensitivity analysis in observational studies.  Journal of the American Statistical Association, 104, 1398-1405.
</p>
<p>Rosenbaum, P. R. (2017) &lt;doi:10.4159/9780674982697&gt; Observation and Experiment: An Introduction to Causal Inference.  Cambridge, MA: Harvard University Press.  Table 9.1.
</p>
<p>Rosenbaum, P. R. (2020)  &lt;doi:10.1007/978-3-030-46405-9&gt; Design of Observational Studies (2nd ed.) NY: Springer.  Section 3.6.
</p>
<p>Wolfe, D. A. (1974) &lt;doi:10.2307/2286025&gt; A charaterization of population weighted symmetry and related results.  Journal of the American Statistical Association, 69, 819-822.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#  Consider a treated-control match pair as the unit of measure,
#  analogous to one meter or one foot.  The calculation
#  amplify(4,7) says that, in a matched pair, gamma=4
#  is the same a bias that increases the odds of treatment
#  7-fold and increases the odds of positive matched-pair
#  difference in outcomes 9-fold.
amplify(4,7)
#  It is also true that, in a matched pair, gamma=4
#  is the same a bias that increases the odds of treatment
#  9-fold and increases the odds of positive matched-pair
#  difference in outcomes 7-fold.
amplify(4,9)
#  It is also true that, in a matched pair, gamma=4
#  is the same a bias that increases the odds of treatment
#  5-fold and increases the odds of positive matched-pair
#  difference in outcomes 19-fold.
amplify(4,5)
# The amplify function can produce the entire curve at once:
amplify(4,5:19)
</code></pre>

<hr>
<h2 id='binge'>
Binge Drinking and High Blood Pressure
</h2><span id='topic+binge'></span>

<h3>Description</h3>

<p>These unmatched data are from NHANES, and they illustrate multivariate matching.
The matched version of the data is bingeM, and it was produced by the example in the documentation for the makematch() function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("binge")</code></pre>


<h3>Format</h3>

<p>A data frame with 4627 observations on the following 17 variables.
</p>

<dl>
<dt><code>SEQN</code></dt><dd><p>NHANES identification number</p>
</dd>
<dt><code>age</code></dt><dd><p>Age in years</p>
</dd>
<dt><code>ageC</code></dt><dd><p>Age cut into four categories, [20,30), [30,45), [45,60)
and [60,Inf). </p>
</dd>
<dt><code>female</code></dt><dd><p>1=female, 0=male</p>
</dd>
<dt><code>educationf</code></dt><dd><p>Education in five categories: &lt;9th grade, 9th-11th grade without a high school degree or equivalent, high school degree or equivalent, some college, at least a BA degree.  An ordered factor with levels <code>&lt;9th</code> &lt; <code>9-11</code> &lt; <code>HS</code> &lt; <code>SomeCol</code> &lt; <code>&gt;=BA</code></p>
</dd>
<dt><code>education</code></dt><dd><p>The previous variable, educationf, as integer scores, 1-5.</p>
</dd>
<dt><code>bmi</code></dt><dd><p>BMI or body mass index.  A measure of obesity.</p>
</dd>
<dt><code>waisthip</code></dt><dd><p>Waist-to-hip ratio.  A measure of obesity.</p>
</dd>
<dt><code>vigor</code></dt><dd><p>1 if engages in vigorous activity, either in recreation or at work, 0 otherwise </p>
</dd>
<dt><code>smokenowf</code></dt><dd><p>Do you smoke now? <code>Everyday</code> &lt; <code>SomeDays</code> &lt; <code>No</code></p>
</dd>
<dt><code>smokenow</code></dt><dd><p>The previous variable, smokenowf, as integer scores.</p>
</dd>
<dt><code>bpRX</code></dt><dd><p>1=currently taking medication to control high blood pressure, 0=other</p>
</dd>
<dt><code>smokeQuit</code></dt><dd><p>1=used to smoke regularly but quit, 0=other.  A current smoker and a never smoker both have value 0.</p>
</dd>
<dt><code>AlcGroup</code></dt><dd><p>An ordered factor with levels <code>B</code> &lt; <code>N</code> &lt; <code>P</code></p>
</dd>
<dt><code>bpSystolic</code></dt><dd><p>Systolic blood pressure.  The average of up to three measurements.</p>
</dd>
<dt><code>bpDiastolic</code></dt><dd><p>Diastolic blood pressure.  The average of up to three measurements.</p>
</dd>
<dt><code>bpCombined</code></dt><dd><p>A combined measure of blood pressure.</p>
</dd>
</dl>



<h3>Details</h3>

<p>This data set is intended to illustrate multivariate matching.  See the example
in the documentation for the makematch() function.
</p>
<p>In the examples below, the simple B-N match in Section 4.3 of the iTOS book is
constructed.  It matches for the propensity score and nothing else.
</p>
<p>bpCombined is the sum of two standardized measures, one for systolic blood pressure and one for diastolic blood pressure.  In the larger NHANES data set of individuals at least 20 years of age who are not pregnant, the median and the mad (=median absolute deviation from the median) were determined separately for systolic and diastolic blood pressure. The calculation used the median and mad functions in the 'stats' package, so the mad was by default scaled to resemble the standard deviation for a Normal distribution. bpCombined is the sum of two quantities: systolic blood pressure minus its median divided by its mad plus diastolic blood pressure minus its median divided by its mad.
</p>


<h3>Source</h3>

<p>The data are from the US National Health and Nutrition Examination Survey, NHANES 2017-March 2020 Pre-pandemic.  The 2017-2020 data were affected by COVID-19 and are not a survey.  The complete data are available from the CDC web page.  With minor differences, the data were used as an example in Rosenbaum (2023).
</p>


<h3>References</h3>

<p>Rosenbaum, P. R. (2023) &lt;doi:10.1111/biom.13921&gt; A second evidence factor for a second control group. Biometrics, 79(4), 3968-3980.
</p>
<p>Rosenbaum, P.R. and Rubin, D.B. (1985) &lt;doi:10.2307/2683903&gt; Constructing a control group using multivariate matched sampling methods that incorporate the propensity score. The American Statistician, 39(1):33-38.
</p>
<p>US National Health and Nutrition Examination Survey, 2017-2020.  Atlanta: US Centers for Disease Control.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(binge)
attach(binge)
# A simple goal is to match each of the 206 binge drinkers
# to one control from each of the two control groups.
table(AlcGroup)
# The matching ratios are very different, 19-to-1 or 2.4 to 1.
table(AlcGroup)/206
# Before matching, the age distributions are very different.
boxplot(age~AlcGroup)
# NHANES does not ask every question of every person, often
# using either age or sex to determine what will be asked.
# If we match exactly for age categories that determine what
# will be asked, then both members of a matched pair will
# either have an answer or no answer, and this simplifies
# some analyses, while also beginning the work of controlling
# an important covariate.
table(AlcGroup,ageC)
# Age is going to be a problem for the P controls.  There
# are 29 bingers B under age 30, but only 19 past bingers P.
table(AlcGroup,smokenowf)
# Smoking is a challenge, too.  The 19-to-1 matching ratio
# for N controls drops to about 4 = 364/92 for everyday
# smokers, and from 2.43 to 1.44 = 133/92 for P controls.
# There are too few P controls who smoke SomeDays to
# match exactly with bingers B.
detach(binge)

####################################################
# This example produces the elementary match in
# Section 4.3 of the iTOS book.
# It matches binge drinkers (B) to never binge
# controls (N), matching just for the propensity
# score.  The match uses both a caliper and a fine
# balance constraint for the propensity score.
# Generally, one does not just match for the
# propensity score, but this is an example.
# See also the documentation for makematch.
library(iTOS)
data(binge)
#  Make the treatment indicator z for B versus N
z&lt;-rep(NA,dim(binge)[1])
z[binge$AlcGroup=="B"]&lt;-1
z[binge$AlcGroup=="N"]&lt;-0

#  I find it convenient to write a small function
#  to create a match.  In that way, small
#  changes in the function can improve the
#  match by improving covariate balance.
#  It also documents the details of the match.
#  It also makes it possible to reproduce the match.

matchPropensity&lt;-function(z,ncontrols=1){
  #
  # Some bookkeeping.
  # Select the B versus N part of the binge data
  dt&lt;-binge[!is.na(z),]
  z&lt;-z[!is.na(z)]
  # Sort data, placing treated (B) first,
  # and then ordered by SEQN.
  dt&lt;-dt[order(1-z,dt$SEQN),]
  z&lt;-z[order(1-z,dt$SEQN)]
  rownames(dt)&lt;-dt$SEQN
  names(z)&lt;-dt$SEQN

  #  Initialize the distance matrix on
  #  the left and right to zero distances
  left&lt;-startcost(z)
  right&lt;-startcost(z)

  #  Create the propensity score
  attach(dt)
  propmod&lt;-glm(z~age+female+education+smokenow+smokeQuit+bpRX+
                 bmi+vigor+waisthip,family=binomial)
  p&lt;-propmod$fitted.values

  # The left distance matrix is changed from zero
  # by adding a caliper on the propensity score.
  # The caliper is almost the one used in
  # Rosenbaum and Rubin (1985, American Statistician).
  # If two individuals differ on the propensity score
  # by more than 0.2 times the standard deviation of p,
  # the distance between them is increased from 0 to 10.
  # That was the caliper in Rosenbaum and Rubin (1985).
  # By default, addcaliper doubles the distance (to 20) at
  # 0.4 = 2 x 0.2 times the standard deviation of p.
  # Without this doubling feature, the caliper views
  # everyone who violates the 0.2 caliper as equivalent.
  left&lt;-addcaliper(left,z,p,penalty=10)

  # The right distance matrix now adds a fine balance
  # constraint.  The variable (p&gt;0.05)+(p&gt;.1)+(p&gt;.15)+(p&gt;.2)
  # takes integer values from 0 to 4, taking steps up as
  # the propensity score increases.
  # The right distance matrix is 0 if two people fall in
  # the same category, is 1000 if they fall in adjacent
  # categories, 2000 if there if there is a category
  # between them, and so on.  Because 1000 is so much
  # larger than 10, the fine balance constraint takes
  # priority over the caliper.
  right&lt;-addinteger(right,z,(p&gt;0.05)+(p&gt;.1)+(p&gt;.15)+(p&gt;.2))

  # Some more bookkeeping
  detach(dt)
  dt&lt;-cbind(dt,z,p)

  # The big step: Use the distance matrices to make the match
  m&lt;-makematch(dt,left,right,ncontrols=ncontrols)

  # Final bookkeeping
  m$mset&lt;-as.integer(m$mset)
  treated&lt;-m$SEQN[m$z==1]
  treated&lt;-as.vector(t(matrix(treated,length(treated),ncontrols+1)))
  m&lt;-cbind(m,treated)
  list(m=m,dt=dt)
}

# Call the function above to make the match
mProp&lt;-matchPropensity(z)
m&lt;-mProp$m

# Make Table 4.3 in the iTOS book.
t.test(m$age~m$z)$p.value
t.test(m$female~m$z)$p.value
t.test(m$education~m$z)$p.value
t.test(m$bmi~m$z)$p.value
t.test(m$waisthip~m$z)$p.value
t.test(m$vigor~m$z)$p.value
t.test(m$smokenow~m$z)$p.value
t.test(m$smokeQuit~m$z)$p.value
t.test(m$bpRX~m$z)$p.value
t.test(m$p~m$z)$p.value
dt&lt;-mProp$dt
tr&lt;-m$z==1
co&lt;-m$z==0
un&lt;-!is.element(dt$SEQN,m$SEQN)

vnames&lt;-c("age","female","education","bmi","waisthip","vigor",
          "smokenow","smokeQuit","bpRX","p")
o&lt;-matrix(NA,10,3)
pval&lt;-rep(NA,10)
names(pval)&lt;-vnames
rownames(o)&lt;-vnames
colnames(o)&lt;-c("Treated","Control","Unmatched")
for (i in 1:10){
  vname&lt;-vnames[i]
  vm&lt;-as.vector(m[,colnames(m)==vname])
  vdt&lt;-as.vector(dt[,colnames(dt)==vname])
  o[i,1]&lt;-mean(vm[tr])
  o[i,2]&lt;-mean(vm[co])
  o[i,3]&lt;-mean(vdt[un])
  pval[i]&lt;-t.test(vm[tr],vm[co])$p.value
}
library(xtable)
o&lt;-cbind(o,pval)
xtable(o,digits=c(NA,2,2,2,3))
m[5:6,]

</code></pre>

<hr>
<h2 id='bingeM'>
Binge Drinking and High Blood Pressure &ndash; Matched With Two Control Groups
</h2><span id='topic+bingeM'></span>

<h3>Description</h3>

<p>The bingeM data set is the matched data set built from the unmatched binge data using the makematch() function.  The documentation for the makematch() function builds bingeM from binge.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("bingeM")</code></pre>


<h3>Format</h3>

<p>A data frame with 618 observations on the following 20 variables.
</p>

<dl>
<dt><code>SEQN</code></dt><dd><p>NHANES identification number</p>
</dd>
<dt><code>age</code></dt><dd><p>Age in years</p>
</dd>
<dt><code>ageC</code></dt><dd><p>Age cut into four categories, [20,30), [30,45), [45,60)
and [60,Inf). </p>
</dd>
<dt><code>female</code></dt><dd><p>1=female, 0=male</p>
</dd>
<dt><code>educationf</code></dt><dd><p>Education in five categories: &lt;9th grade, 9th-11th grade without a high school degree or equivalent, high school degree or equivalent, some college, at least a BA degree.  An ordered factor with levels <code>&lt;9th</code> &lt; <code>9-11</code> &lt; <code>HS</code> &lt; <code>SomeCol</code> &lt; <code>&gt;=BA</code></p>
</dd>
<dt><code>education</code></dt><dd><p>The previous variable, educationf, as integer scores, 1-5.</p>
</dd>
<dt><code>bmi</code></dt><dd><p>BMI or body mass index.  A measure of obesity.</p>
</dd>
<dt><code>waisthip</code></dt><dd><p>Waist-to-hip ratio.  A measure of obesity.</p>
</dd>
<dt><code>vigor</code></dt><dd><p>1 if engages in vigorous activity, either in recreation or at work, 0 otherwise </p>
</dd>
<dt><code>smokenowf</code></dt><dd><p>Do you smoke now? <code>Everyday</code> &lt; <code>SomeDays</code> &lt; <code>No</code></p>
</dd>
<dt><code>smokenow</code></dt><dd><p>The previous variable, smokenowf, as integer scores.</p>
</dd>
<dt><code>bpRX</code></dt><dd><p>1=currently taking medication to control high blood pressure, 0=other</p>
</dd>
<dt><code>smokeQuit</code></dt><dd><p>1=used to smoke regularly but quit, 0=other.  A current smoker and a never smoker both have value 0.</p>
</dd>
<dt><code>AlcGroup</code></dt><dd><p>An ordered factor with levels <code>B</code> &lt; <code>N</code> &lt; <code>P</code></p>
</dd>
<dt><code>bpSystolic</code></dt><dd><p>Systolic blood pressure.  The average of up to three measurements.</p>
</dd>
<dt><code>bpDiastolic</code></dt><dd><p>Diastolic blood pressure.  The average of up to three measurements.</p>
</dd>
<dt><code>bpCombined</code></dt><dd><p>A combined measure of blood pressure.</p>
</dd>
<dt><code>z</code></dt><dd><p>Treatment/control indicator, z[i]=1 if i is in AlcGroup category B and z[i]=0 otherwise.</p>
</dd>
<dt><code>mset</code></dt><dd><p>Indicator of the matched set, 1, 2, ..., 206.</p>
</dd>
<dt><code>treated</code></dt><dd><p>The SEQN for the treated individual in this matched set.</p>
</dd>
</dl>



<h3>Details</h3>

<p>bingeM is the matched data set built from the unmatched binge data using the makematch() function.  The documentation for the makematch() function builds bingeM from binge.
</p>
<p>bpCombined is the sum of two standardized measures, one for systolic blood pressure and one for diastolic blood pressure.  In the larger NHANES data set of individuals at least 20 years of age who are not pregnant, the median and the mad (=median absolute deviation from the median) were determined separately for systolic and diastolic blood pressure. The calculation used the median and mad functions in the 'stats' package, so the mad was by default scaled to resemble the standard deviation for a Normal distribution. bpCombined is the sum of two quantities: systolic blood pressure minus its median divided by its mad plus diastolic blood pressure minus its median divided by its mad.
</p>


<h3>Source</h3>

<p>The data are from the US National Health and Nutrition Examination Survey, NHANES 2017-March 2020 Pre-pandemic.  The 2017-2020 data were affected by COVID-19 and are not a survey.  The complete data are available from the CDC web page.  With minor differences, the data were used as an example in Rosenbaum (2023).
</p>


<h3>References</h3>

<p>Rosenbaum, P. R. (2023) &lt;doi:10.1111/biom.13921&gt; A second evidence factor for a second control group. Biometrics, 79(4), 3968-3980.
</p>
<p>US National Health and Nutrition Examination Survey, 2017-2020.  Atlanta: US Centers for Disease Control.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(bingeM)
table(bingeM$AlcGroup)
tapply(bingeM$age,bingeM$AlcGroup,median)
tapply(bingeM$bmi,bingeM$AlcGroup,median)
tapply(bingeM$education,bingeM$AlcGroup,mean)
tapply(bingeM$female,bingeM$AlcGroup,mean)
tapply(bingeM$smokenow,bingeM$AlcGroup,mean)
tapply(bingeM$vigor,bingeM$AlcGroup,mean)
tapply(bingeM$smokeQuit,bingeM$AlcGroup,mean)
boxplot(bingeM$bpCombined~bingeM$AlcGroup,ylab="Combined BP",
        xlab="Alcohol Group",las=1)
y&lt;-t(matrix(bingeM$bpCombined,3,206))
weightedRank::wgtRank(y,gamma=2)
amplify(2,3)
# In iTOS book, comparison of Tables 13.2 and 13.3
weightedRank::ef2C(y,gamma=2,upsilon=2,m1=c(6,6),range=TRUE,scores=1:3)
weightedRank::ef2C(y,gamma=2,upsilon=2.3,m1=c(6,8),range=FALSE,scores=c(1,2,5))
</code></pre>

<hr>
<h2 id='computep'>
Computes individual and pairwise treatment assignment probabilities.
</h2><span id='topic+computep'></span>

<h3>Description</h3>

<p>Of limited interest to most users, the computep function plays an internal role in 2-sample and stratified sensitivity analyses.  The computep function is equations (9) and (10), page 496, in Rosenbaum and Krieger (1990).  The computep function is from the senstrat package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>computep(bigN, n, m, g)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="computep_+3A_bign">bigN</code></td>
<td>

<p>Total sample size in this stratum.
</p>
</td></tr>
<tr><td><code id="computep_+3A_n">n</code></td>
<td>

<p>Treated sample size in this stratum.
</p>
</td></tr>
<tr><td><code id="computep_+3A_m">m</code></td>
<td>

<p>The number of 1's in the vector u of unobserved covariates.  Here, u
has bigN-m 0's followed by m 1's.
</p>
</td></tr>
<tr><td><code id="computep_+3A_g">g</code></td>
<td>

<p>The sensitivity parameter <code class="reqn">\Gamma</code>, where <code class="reqn">\Gamma \ge 1</code>.
</p>
</td></tr>
</table>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>p1</code></td>
<td>
<p>Equation (9), page 496, in Rosenbaum and Krieger (1990) evaluated with u[i]=1.</p>
</td></tr>
<tr><td><code>p0</code></td>
<td>
<p>Equation (9), page 496, in Rosenbaum and Krieger (1990) evaluated with u[i]=0.</p>
</td></tr>
<tr><td><code>p11</code></td>
<td>
<p>Equation (10), page 496, in Rosenbaum and Krieger (1990) evaluated with u[i]=1, u[j]=1.</p>
</td></tr>
<tr><td><code>p10</code></td>
<td>
<p>Equation (10), page 496, in Rosenbaum and Krieger (1990) evaluated with u[i]=1, u[j]=0.</p>
</td></tr>
<tr><td><code>p00</code></td>
<td>
<p>Equation (10), page 496, in Rosenbaum and Krieger (1990) evaluated with u[i]=0, u[j]=0.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The function computep is called by the function ev.
</p>


<h3>Author(s)</h3>

<p>Paul R. Rosenbaum
</p>


<h3>References</h3>

<p>Rosenbaum, P. R. and Krieger, A. M. (1990) &lt;doi:10.2307/2289789&gt; Sensitivity of two-sample permutation inferences in observational studies.  Journal of the American Statistical Association, 85, 493-498.
</p>
<p>Rosenbaum, P. R. (2002). Observational Studies (2nd edition). New York: Springer.  Section 4.6.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>computep(10,5,6,2)
</code></pre>

<hr>
<h2 id='ev'>
Computes the null expectation and variance for one stratum.
</h2><span id='topic+ev'></span>

<h3>Description</h3>

<p>Of limited interest to most users, the ev function plays an internal role in 2-sample and stratified sensitivity analyses.  The expectation and variance returned by the ev function are defined in the third paragraph of section 4, page 495, of Rosenbaum and Krieger (1990).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ev(sc, z, m, g, method)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ev_+3A_sc">sc</code></td>
<td>

<p>A vector of scored outcomes for one stratum.  For instance, for Wilcoxon's rank sum test,
these would be the ranks of the outcomes in the current stratum.
</p>
</td></tr>
<tr><td><code id="ev_+3A_z">z</code></td>
<td>

<p>Treatment indicators, with length(z)=length(sc).  Here, z[i]=1 if i is treated and z[i]=0 if i is control.
</p>
</td></tr>
<tr><td><code id="ev_+3A_m">m</code></td>
<td>

<p>The unobserved covariate u has length(z)-m 0's followed by m 1's.
</p>
</td></tr>
<tr><td><code id="ev_+3A_g">g</code></td>
<td>

<p>The sensitivity parameter <code class="reqn">\Gamma</code>, where <code class="reqn">\Gamma \ge 1</code>.
</p>
</td></tr>
<tr><td><code id="ev_+3A_method">method</code></td>
<td>

<p>If method=&quot;RK&quot; or if method=&quot;BU&quot;, exact expectations and variances are used in a large sample approximation.  Methods &quot;RK&quot; and &quot;BU&quot; should give the same answer, but &quot;RK&quot; uses formulas from Rosenbaum and Krieger (1990), while &quot;BU&quot; obtains exact moments for the extended hypergeometric distribution using the BiasedUrn package and then applies Proposition 20, page 155, section 4.7.4 of Rosenbaum (2002).  In contrast, method=&quot;LS&quot; does not use exact expectations and variances, but rather uses the large sample approximations in section 4.6.4 of Rosenbaum (2002).  Finally, method=&quot;AD&quot; uses method=&quot;LS&quot; for large strata and method=&quot;BU&quot; for smaller strata.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function ev() is called by the function evall().  The ev() function is from the senstrat package.
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>expect</code></td>
<td>
<p>Null expectation of the test statistic.</p>
</td></tr>
<tr><td><code>vari</code></td>
<td>
<p>Null variance of the test statistic.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Paul R. Rosenbaum
</p>


<h3>References</h3>

<p>Rosenbaum, P. R. and Krieger, A. M. (1990) &lt;doi:10.2307/2289789&gt; Sensitivity of two-sample permutation inferences in observational studies.  Journal of the American Statistical Association, 85, 493-498.
</p>
<p>Rosenbaum, P. R. (2002). Observational Studies (2nd edition). New York: Springer.  Section 4.6.
</p>
<p>Rosenbaum, P. R. (2018) &lt;doi:10.1214/18-AOAS1153&gt; Sensitivity analysis for stratified comparisons in an observational study of the effect of smoking on homocysteine levels. The Annals of Applied Statistics, 12(4), 2312-2334.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>ev(1:5,c(0,1,0,1,0),3,2,"RK")
ev(1:5,c(0,1,0,1,0),3,2,"BU")
</code></pre>

<hr>
<h2 id='evalBal'>
Evaluate Covariate Balance in a Matched Sample
</h2><span id='topic+evalBal'></span>

<h3>Description</h3>

<p>The covariate balance in a matched sample is compared to the balance that
would have been obtained in a completely randomized experiment built from
the same people.  The existing matched sample is randomized to treatment or
control many times, and various measures of covariate balance are computed
from the one matched sample and the many randomized experiments.  The main
elements of the method are from Hansen and Bowers (2008), Pimentel et al. (2015, Table 1), and Yu (2021).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>evalBal(z, x, statistic = "s", reps = 1000, trunc = 0.2, nunique = 2, alpha = 0.05)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="evalBal_+3A_z">z</code></td>
<td>

<p>z is a vector, with z[i]=1 for treated and z[i]=0 for control
</p>
</td></tr>
<tr><td><code id="evalBal_+3A_x">x</code></td>
<td>

<p>x is a matrix or a data-frame containing covariates with no NAs.  An error will result if length(z) does not equal the number of rows of x.
</p>
</td></tr>
<tr><td><code id="evalBal_+3A_statistic">statistic</code></td>
<td>

<p>If statistic=&quot;t&quot;, the default two-sample t-test from the 'stats' package computes a two-sided P-value for each covariate in the matched sample and the many randomized  experiments.  If statistic=&quot;w&quot;, then the two-sample Wilcoxon rank sum test is used, as implemented in the 'stats' package.  If statistic=&quot;s&quot;, the two-sample Wilcoxon rank sum test is used for numeric covariates with more than nunique distinct values, or the chi-square test for a two-way table is used for factors and for numeric covariates with at most nunique distinct values.  The default value is nunique=2.
</p>
</td></tr>
<tr><td><code id="evalBal_+3A_reps">reps</code></td>
<td>

<p>A positive integer.  A total of reps randomized experiments are compared to the one matched sample.
</p>
</td></tr>
<tr><td><code id="evalBal_+3A_trunc">trunc</code></td>
<td>

<p>For each simulated randomized experiment, a P-value is computed for each covariate.
Also computed is the statistic proposed by Zykin et al. (2002) defined as the
product of those covariate-specific P-values that do not exceed trunc.  This truncated product is not a P-value, but it is a statistic.  See Details.
</p>
</td></tr>
<tr><td><code id="evalBal_+3A_nunique">nunique</code></td>
<td>

<p>See the option statistic=&quot;s&quot; above.
</p>
</td></tr>
<tr><td><code id="evalBal_+3A_alpha">alpha</code></td>
<td>

<p>For each simulated randomized experiment, a P-value is computed for each covariate.
Also computed is number of these P-values that are less than or equal to alpha.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Truncated Product:  For independent uniform P-values, Zaykin et al. (2002) derive a true P-value from the null distribution of their truncated product of P-values.  That null distribution can be computed using the truncatedP() function in the 'sensitivitymv' package; however, it is not used here, because the P-values for dependent covariates are not independent.  Rather, the actual randomization distribution of the truncated product is simulated.  Taking trunc=1 yields Fisher's statistic, namely the product of all of the P-values.
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>test.name</code></td>
<td>
<p>The name of the test used. </p>
</td></tr>
<tr><td><code>actual</code></td>
<td>
<p>For each covariate, the usual two sample P-values comparing the distributions of
treated and control groups for each covariate in x.  Also, the minimum P-value,
the truncated product of P-values, and the number of P-values less than or equal to alpha &ndash; none of these quantities is a P-value.</p>
</td></tr>
<tr><td><code>simBetter</code></td>
<td>
<p>Comparison of the covariate imbalance in the actual
matched sample and the many simulated randomized experiment.  Of the reps
randomized experiments, how many were strictly better balanced than the
one matched observational study.</p>
</td></tr>
<tr><td><code>sim</code></td>
<td>
<p>Details of the simulated randomized experiments.  </p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Paul R. Rosenbaum
</p>


<h3>References</h3>

<p>Hansen, B. B., and Bowers, J. (2008) &lt;doi:10.1214/08-STS254&gt; Covariate balance in simple, stratified and clustered comparative studies. Statistical Science, 23, 219-236.
</p>
<p>Pimentel, S. D., Kelz, R. R., Silber, J. H. and Rosenbaum, P. R. (2015)
&lt;doi:10.1080/01621459.2014.997879&gt; Large, sparse optimal matching with refined covariate balance in an observational study of the health outcomes produced by new surgeons. Journal of the American Statistical Association, 110, 515-527.
</p>
<p>Yu, R. (2021) &lt;doi:10.1111/biom.13098&gt; Evaluating and improving a matched comparison of antidepressants and bone density. Biometrics, 77(4), 1276-1288.
</p>
<p>Zaykin, D. V., Zhivotovsky, L. A., Westfall, P. H. and Weir, B. S. (2002)
&lt;doi:10.1002/gepi.0042&gt; Truncated product method of combining P-values. Genetic Epidemiology, 22, 170-185.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Evaluate the balance in the bingeM matched sample.
# The more difficult control group, P, will be evaluated.
data(bingeM)
attach(bingeM)
xBP&lt;-data.frame(age,female,education,bmi,waisthip,vigor,smokenow,bpRX,smokeQuit)
xBP&lt;-xBP[bingeM$AlcGroup!="N",]
detach(bingeM)
z&lt;-bingeM$z[bingeM$AlcGroup!="N"]

# In a serious evaluation, take reps=1000 or reps=10000.
# For a quick example, reps is set to reps=100 here.
set.seed(5)
balBP&lt;-evalBal(z,xBP,reps=100)
balBP$test.name
# This says that age is compared using the Wilcoxon two-sample test,
# and female is compared using the chi-square test for a 2x2 table.
# Because the default, nunique=2, was used, education was evaluated
# using Wilcoxon's test; however, changing nunique to 5 would evaluate
# the 5 levels of education using a chi-square test for a 2x5 table.
balBP$actual
# In the matched sample, none of the 9 covariates has a P-value
# of 0.05 or less.  The smallest of the 9 P-values is .366, and
# their truncated product is 1, because, by definition, the truncated
# product is 1 if all of the P-values are above trunc.
apply(balBP$sim,2,median)
# In the simulated randomized experiments, the median of the 100
# P-values is close to 1/2 for all covariates.
balBP$simBetter
# Of the 100 simulated randomized experiments, only 3 were better
# balanced than the matched sample in terms of the minimum P-value,
# and none were better balanced in terms of the truncated product
# of P-values.
#
# There were too few controls in the P control group who smoked
# on somedays to match exactly for smokenow.  Nonetheless, only
# 13/100 randomized experiments were better balanced for smokenow.
#
# Now compare the binge group B to the combination of the two
# control groups.
attach(bingeM)
x&lt;-data.frame(age,female,education,bmi,waisthip,vigor,smokenow,bpRX,smokeQuit)
detach(bingeM)
set.seed(5)
balAll&lt;-evalBal(bingeM$z,x,reps=100,trunc=1)
balAll$actual
balAll$simBetter
# This time, Fisher's product of all P-values is used, with trunc=1.
# In terms of the minimum P-value and the product of P-values,
# none of the 100 randomized experiments is better balanced than the
# matched sample.
</code></pre>

<hr>
<h2 id='evall'>
Compute expectations and variances for one stratum.
</h2><span id='topic+evall'></span>

<h3>Description</h3>

<p>Of limited interest to most users, the evall() function plays an internal role in 2-sample and stratified sensitivity analyses.  The expectation and variance returned by the evall() function are defined in the third paragraph of section 4, page 495, of Rosenbaum and Krieger (1990).  The function evall() calls the function ev() to determine the expectation and variance of the test statistic for an unobserved covariate u with length(z)-m 0's followed by m 1's, doing this for m=1,...,length(z)-1.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>evall(sc, z, g, method)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="evall_+3A_sc">sc</code></td>
<td>

<p>A vector of scored outcomes for one stratum.  For instance, for Wilcoxon's rank sum test,
these would be the ranks of the outcomes in the current stratum.
</p>
</td></tr>
<tr><td><code id="evall_+3A_z">z</code></td>
<td>

<p>Treatment indicators, with length(z)=length(sc).  Here, z[i]=1 if i is treated and z[i]=0 if i is control.
</p>
</td></tr>
<tr><td><code id="evall_+3A_g">g</code></td>
<td>

<p>The sensitivity parameter <code class="reqn">\Gamma</code>, where <code class="reqn">\Gamma \ge 1</code>.
</p>
</td></tr>
<tr><td><code id="evall_+3A_method">method</code></td>
<td>

<p>If method=&quot;RK&quot; or if method=&quot;BU&quot;, exact expectations and variances are used in a large sample approximation.  Methods &quot;RK&quot; and &quot;BU&quot; should give the same answer, but &quot;RK&quot; uses formulas from Rosenbaum and Krieger (1990), while &quot;BU&quot; obtains exact moments for the extended hypergeometric distribution using the BiasedUrn package and then applies Proposition 20, page 155, section 4.7.4 of Rosenbaum (2002).  In contrast, method=&quot;LS&quot; does not use exact expectations and variances, but rather uses the large sample approximations in section 4.6.4 of Rosenbaum (2002).  Finally, method=&quot;AD&quot; uses method=&quot;LS&quot; for large strata and method=&quot;BU&quot; for smaller strata.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The evall() function is called by the sen2sample() function and the senstrat() function.
</p>


<h3>Value</h3>

<p>A data.frame with length(z)-1 rows and three columns.  The first column, m, gives the number of 1's in the unobserved covariate vector, u.  The second column, expect, and the third column, var, give the expectation and variance of the test statistic for this u.
</p>


<h3>Note</h3>

<p>The example is from Table 1, page 497, of Rosenbaum and Krieger (1990).  The example is also Table 4.15, page 146, in Rosenbaum (2002).  The example refers to Cu cells.  The data are orignally from Skerfving et al. (1974).  The evall function is from the senstrat package.
</p>


<h3>Author(s)</h3>

<p>Paul R. Rosenbaum
</p>


<h3>References</h3>

<p>Rosenbaum, P. R. and Krieger, A. M. (1990) &lt;doi:10.2307/2289789&gt; Sensitivity of two-sample permutation inferences in observational studies.  Journal of the American Statistical Association, 85, 493-498.
</p>
<p>Rosenbaum, P. R. (2002). Observational Studies (2nd edition). New York: Springer.  Section 4.6.
</p>
<p>Rosenbaum, P. R. (2018) &lt;doi:10.1214/18-AOAS1153&gt; Sensitivity analysis for stratified comparisons in an observational study of the effect of smoking on homocysteine levels. The Annals of Applied Statistics, 12(4), 2312-2334.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>z&lt;-c(rep(0,16),rep(1,23))
CuCells&lt;-c(2.7, .5, 0, 0, 5, 0, 0, 1.3, 0, 1.8, 0, 0, 1.0, 1.8,
           0, 3.1, .7, 4.6, 0, 1.7, 5.2, 0, 5, 9.5, 2, 3, 1, 3.5,
           2, 5, 5.5, 2, 3, 4, 0, 2, 2.2, 0, 2)
evall(rank(CuCells),z,2,"RK")
</code></pre>

<hr>
<h2 id='gconv'>Convolution of Two Probability Generating Functions</h2><span id='topic+gconv'></span>

<h3>Description</h3>

<p>Computes the convolution of two probability generating functions using the convolve function in the stats package.  The convolve function uses the fast fourier transform.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gconv(g1,g2)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gconv_+3A_g1">g1</code></td>
<td>

<p>A probability generating function.  A vector g1 for a random variable X taking values 0, 1, 2, ..., length(g1)-1, where g1[i] = Pr(X=i-1)For example, g1 = c(2/3, 1/3) is the generating function of a binary random variable X with Pr(X=0)=2/3, Pr(X=1)=1/3.  The random variable that is 0 with probability 1 has g1=1.
</p>
</td></tr>
<tr><td><code id="gconv_+3A_g2">g2</code></td>
<td>

<p>Another probability generating function for a random variable Y.  For a fair die, g2 = c(0, 1/6, 1/6, 1/6, 1/6, 1/6, 1/6).
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The probability generating function of X+Y when X and Y are independent.
</p>


<h3>Note</h3>

<p>The gconv function is a slight modification of a similar function in
the sensitivity2x2xk package.</p>


<h3>References</h3>

<p>Pagano, M. and Tritchler, D. (1983) &lt;doi:10.2307/2288653&gt; On obtaining permutation distributions in polynomial time. Journal of the American Statistical Association, 78, 435-440.
</p>
<p>Rosenbaum, P. R. (2020)  &lt;doi:10.1007/978-3-030-46405-9&gt; Design of Observational Studies.  New York: Springer. Chapter 3 Appendix: Exact Computations for Sensitivity Analysis, page 103.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
gconv(c(2/3,1/3),c(2/3,1/3))

gconv(1,c(2/3,1/3))

round(gconv(c(0, 1/6, 1/6, 1/6, 1/6, 1/6, 1/6),
     c(0, 1/6, 1/6, 1/6, 1/6, 1/6, 1/6)),3)
#
# Compute the exact distribution of Quade's treated-control
# statistic forI=3 blocks of size J=3.
#
# Block with range rank = 1
rk1&lt;-c(0,1/3,1/3,1/3)
names(rk1)&lt;-0:3
rk1
#
# Block with range rank = 2
rk2&lt;-c(0,0,1/3,0,1/3,0,1/3)
names(rk2)&lt;-0:6
rk2
#
# Block with range rank = 3
rk3&lt;-c(0,0,0,1/3,0,0,1/3,0,0,1/3)
names(rk3)&lt;-0:9
rk3
#
# Convolution of rk1 and rk2
round(gconv(rk1,rk2),3)
1/(3^2)
#
# Convolution of rk1, rk2 and rk3
round(gconv(gconv(rk1,rk2),rk3),3)
1/(3^3)
</code></pre>

<hr>
<h2 id='makematch'>
Two-Criteria Matching
</h2><span id='topic+makematch'></span>

<h3>Description</h3>

<p>Implements the method of Zhang et al (2023) &lt;doi:10.1080/01621459.2021.1981337&gt;.
As special cases, this includes: minimum distance (or optimal matching), matching
with fine balance or near-fine balance or refined balance; see Chapter 5 of the iTOS book or the references below.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>makematch(dat, costL, costR, ncontrols = 1, controlcosts = NULL,solver='rlemon')
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="makematch_+3A_dat">dat</code></td>
<td>

<p>A data frame.  Typically, this is the entire data set.  Part of it will be
returned as a matched sample with some added variables.
</p>
</td></tr>
<tr><td><code id="makematch_+3A_costl">costL</code></td>
<td>

<p>The distance matrix on the left side of the network, used for pairing.  This matrix would most often be made by adding distances to a zero distance matrix created by startcost(), for instance, using addMahal().  In section 5.4 of the book iTOS or
Figure 1 of Zhang et al. (2023), these are the costs on the left treated-control edges.
</p>
</td></tr>
<tr><td><code id="makematch_+3A_costr">costR</code></td>
<td>

<p>The distance matrix on the right side of the network, used for balancing.  This matrix would most often be made by adding distances to a zero distance matrix created by startcost(), for instance, using addNearExact().  If you do not need a right distance matrix, then initialize it to zero using startcost() and do not add additional distances to its intial form.  In section 5.4 of the book iTOS or Figure 1 of Zhang et al. (2023), these are the costs on the right control-treated edges.
</p>
</td></tr>
<tr><td><code id="makematch_+3A_ncontrols">ncontrols</code></td>
<td>

<p>One positive integer, 1 for pair matching, 2 for matching two controls to each treated individual, etc.  When ncontrols=2 is feasible, it is often useful to compare the quality of the match obtained with ncontrols=1 and ncontrols=2.  In Figure 1 of Zhang et al. (2023), ncontrols determines the total flow that leaves the source and is collected by the sink as ncontrols times the number of treated individuals.
</p>
</td></tr>
<tr><td><code id="makematch_+3A_controlcosts">controlcosts</code></td>
<td>

<p>An optional vector of costs used to penalize the control-control edges.  For instance, one might penalize the use of controls with low propensity scores.  This is illustrated in the example for the B-P match.  In Figure 1 of Zhang et al. (2023), these are the costs on the central control-control edges.
</p>
</td></tr>
<tr><td><code id="makematch_+3A_solver">solver</code></td>
<td>

<p>The solver must be either 'rlemon' or 'rrelaxiv'.  Both solvers find
a minimum cost flow in a network, but rlemon is public and rrelaxiv has
an academic license; so, rrelaxiv requires a separate instalation;
see details.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function calls the callrelax() function in Samuel Pimentel's package
rcbalance.  There are two solvers for callrelax, namely rlemon and the
rrelaxiv code of Bertsekas and Tseng (1988).  The default is rlemon.
rrelaxiv may be the better solver,
but it has an academic license, so it is not distributed by CRAN and must
be downloaded separately from github at https://errickson.net/rrelaxiv/ or
&lt;https://github.com/josherrickson/rrelaxiv/&gt;; see the documentation for callrelax().
There is no need to install rrelaxiv: the package works without it.
</p>
<p>In principle, it can happen that two different matches
have the same minimum cost, and in this case the two solvers might produce
different but equally good matched samples.  This is not a problem, but it
can come as a surprise.  It is unlikely to happen unless the distance matrix
has many tied distances.  Tied distances are rare in modern distance matrices, with many covariates, using modern ambitious matching techniques.
</p>


<h3>Value</h3>

<p>Returns a matched data set.  The matched rows of dat are returned with a new variable mset indicating the matched set.  The returned file is sorted by mset and z.
</p>


<h3>Author(s)</h3>

<p>Paul R. Rosenbaum
</p>


<h3>References</h3>

<p>Bertsekas, D. P., Tseng, P. (1988) &lt;doi:10.1007/BF02288322&gt; The Relax codes for linear minimum cost network flow problems. Annals of Operations Research, 13, 125-190.
</p>
<p>Bertsekas, D. P. (1990) &lt;doi:10.1287/inte.20.4.133&gt; The auction algorithm for assignment and other network flow problems: A tutorial. Interfaces, 20(4), 133-149.
</p>
<p>Bertsekas, D. P., Tseng, P. (1994)
&lt;http://web.mit.edu/dimitrib/www/Bertsekas_Tseng_RELAX4_!994.pdf&gt; RELAX-IV: A Faster Version of the RELAX Code for Solving Minimum Cost Flow Problems.
</p>
<p>Hansen, B. B. and Klopfer, S. O. (2006) &lt;doi:10.1198/106186006X137047&gt; &quot;Optimal full matching and related designs via network flows&quot;. Journal of computational and Graphical Statistics, 15(3), 609-627. ('optmatch' package)
</p>
<p>Hansen, B. B. (2007)
&lt;https://www.r-project.org/conferences/useR-2007/program/presentations/hansen.pdf&gt; Flexible, optimal matching for observational studies. R News, 7, 18-24. ('optmatch' package)
</p>
<p>Pimentel, S. D., Kelz, R. R., Silber, J. H. and Rosenbaum, P. R. (2015)
&lt;doi:10.1080/01621459.2014.997879&gt; Large, sparse optimal matching with refined covariate balance in an observational study of the health outcomes produced by new surgeons. Journal of the American Statistical Association, 110, 515-527. (Introduces an extension of fine balance called refined balance that is implemented in Pimentel's package 'rcbalance'.  This can be implemented using makematch() by, say, placing on the right a very large near-exact penalty on a nominal/integer covariate x1, and a still large but smaller penalty on the nominal/integer covariate as.integer(factor(x1):factor(x2)), etc.)
</p>
<p>Pimentel, S. D. (2016) &quot;Large, Sparse Optimal Matching with R Package rcbalance&quot; &lt;https://obsstudies.org/large-sparse-optimal-matching-with-r-package-rcbalance/&gt; Observational Studies, 2, 4-23. (Discusses and illustrates the use of Pimentel's 'rcbalance' package.)
</p>
<p>Rosenbaum, P. R. and Rubin, D. B. (1985) &lt;doi:10.1080/00031305.1985.10479383&gt; Constructing a control group using multivariate matched sampling methods that incorporate the propensity score. The American Statistician, 39, 33-38. (This paper suggested
emphasizing the propensity score in a match, but also attempting to obtain a
close match for key covariates using a Mahalanobis distance.)
</p>
<p>Rosenbaum, P. R. (1989) &lt;doi:10.1080/01621459.1989.10478868&gt; Optimal matching for observational studies.  Journal of the American Statistical Association, 84(408), 1024-1032. (Discusses and illustrates fine balance using minimum cost flow in a network in section 3.2.  This is implemented using makematch() by placing a large near-exact
penalty on a nominal/integer covariate x1 on the right distance matrix.)
</p>
<p>Rosenbaum, P. R., Ross, R. N. and Silber, J. H. (2007) &lt;doi:10.1198/016214506000001059&gt; Minimum distance matched sampling with fine balance in an observational study of treatment for ovarian cancer. Journal of the American Statistical Association, 102, 75-83.
</p>
<p>Rosenbaum, P. R. (2020) &lt;doi:10.1007/978-3-030-46405-9&gt; Design of Observational Studies (2nd Edition).  New York: Springer.
</p>
<p>Yang, D., Small, D. S., Silber, J. H. and Rosenbaum, P. R. (2012)
&lt;doi:10.1111/j.1541-0420.2011.01691.x&gt; Optimal matching with minimal deviation from fine balance in a study of obesity and surgical outcomes. Biometrics, 68, 628-636. (Extension of fine balance useful when fine balance is infeasible. Comes as close as possible to fine balance. Implemented in makematch() by placing a large near-exact
penalty on a nominal/integer covariate x1 on the right distance matrix.)
</p>
<p>Yu, Ruoqi, and P. R. Rosenbaum. &lt;doi:10.1111/biom.13098&gt; Directional penalties for optimal matching in observational studies. Biometrics 75, no. 4 (2019): 1380-1390.  (If a covariate is very out-of-balance, we should prefer a mismatch that works against the imbalance to an equally large mismatch that supports the imbalance.  This is illustrated with the propensity score in the example below.  Because a directional penalty tolerates a big mismatch in the good direction, it makes sense to place the penalty on the right distance matrix.)
</p>
<p>Yu, R. (2023) &lt;doi:10.1111/biom.13771&gt; How well can fine balance work for covariate balancing? Biometrics.  79(3), 2346-2356.
</p>
<p>Zhang, B., D. S. Small, K. B. Lasater, M. McHugh, J. H. Silber, and P. R. Rosenbaum (2023) &lt;doi:10.1080/01621459.2021.1981337&gt; Matching one sample according to two criteria in observational studies. Journal of the American Statistical Association, 118, 1140-1151.
(This is the basic reference for the makematch() function.  It generalizes the concepts
of fine balance, near-fine balance and refined balance that were developed in other
references.)
</p>
<p>Zubizarreta, J. R., Reinke, C. E., Kelz, R. R., Silber, J. H. and Rosenbaum, P. R. (2011) &lt;doi:10.1198/tas.2011.11072&gt; Matching for several sparse nominal variables in a case control study of readmission following surgery. The American Statistician, 65(4), 229-238.
(This paper combines near-exact matching and fine balance for the same nominal covariate.  It is implemented in makematch() by placing the same covariate on the left and the right, as with smokenow in the example below.)
</p>


<h3>Examples</h3>

<pre><code class='language-R'># See also the examples for binge in the documentation for the dataset binge.

data(binge)
# matchNever creates the B-N match for the binge data.
# matchPast creates the B-P match for the binge data.
# Each match has its own propensity score, and these
# mean different things in the B-N match and the B-P
# match.  The propensity score is denoted p.
# The Mahalanobis distance is the rank-based method
# described in Rosenbaum (2020, section 9.3).
# A directional caliper from Yu and Rosenbaum (2019)
# favors controls with high propensity scores, p.
#
# The two matches share most features, including:
# 1. A heavy left penalty for mismatching for female and bpRX.
# 2. Left penalties for mismatching for ageC, vigor, smokenow.
# 3. A left Mahalanobis distance for all covariates.
# 4. A heavy right penalty for mismatching smokenow.
# 5. Right penalties for education and smokeQuit.
# 6. A right Mahalanobis distance for just female, age and p.
# 7. An asymmetric, directional caliper on p.
# Because the left distance determines pairing, it emphasizes
# covariates that are out-of-balance and thought to be related
# to blood pressure.  Because the right distance affects balance
# but not pairing, it worries about education and smoking in the
# distant past, as well as the propensity score which again is
# focused on covariate balance.  The asymmetric caliper is
# tolerant of mismatches in the desired direction, so it too
# is placed on the right.  Current smoking, smokenow, is placed
# on both the left and the right: even if we cannot always pair
# for it, perhaps we can balance it.
# In common practice, before examining outcomes, one compares
# several matched designs, fixing imperfections by adjusting
# penalties and other considerations.
#
# The B-P match is more difficult, because the P group is
# smaller than the N group.  The B-P match uses the
# controlcosts feature while the B-N match does not.
# In the B-P match, there are too few young controls
# and too few controls with high propensity scores.
# Therefore, controlcosts penalize the use of controls
# with both low propensity scores (p&lt;.4) and higher
# ages (age&gt;42), thereby minimizing the use of these
# controls, even though the use of some of these
# controls is unavoidable in a pair match.

matchNever&lt;-function(z,ncontrols=1){
  dt&lt;-binge[!is.na(z),]
  z&lt;-z[!is.na(z)]
  dt&lt;-dt[order(1-z,dt$SEQN),]
  z&lt;-z[order(1-z,dt$SEQN)]
  rownames(dt)&lt;-dt$SEQN
  names(z)&lt;-dt$SEQN
  left&lt;-startcost(z)
  right&lt;-startcost(z)
  attach(dt)
  propmod&lt;-glm(z~age+female+education+smokenow+smokeQuit+bpRX+
           bmi+vigor+waisthip,family=binomial)
  p&lt;-propmod$fitted.values
  left&lt;-addinteger(left,z,as.integer(ageC),penalty=100)
  left&lt;-addNearExact(left,z,female,penalty = 10000)
  left&lt;-addNearExact(left,z,bpRX,penalty = 10000)
  left&lt;-addNearExact(left,z,vigor,penalty=10)
  left&lt;-addinteger(left,z,smokenow,penalty=10)
  left&lt;-addMahal(left,z,cbind(age,bpRX,female,education,smokenow,
        smokeQuit,bmi,vigor,waisthip))
  right&lt;-addMahal(right,z,cbind(female,age,p))
  right&lt;-addinteger(right,z,education,penalty=10)
  right&lt;-addinteger(right,z,smokenow,penalty=1000)
  right&lt;-addinteger(right,z,smokeQuit,penalty=10)
  right&lt;-addcaliper(right,z,p,caliper=c(-1,.03),penalty=10)
  detach(dt)
  dt&lt;-cbind(dt,z,p)
  m&lt;-makematch(dt,left,right,ncontrols=ncontrols)
  m$mset&lt;-as.integer(m$mset)
  treated&lt;-m$SEQN[m$z==1]
  treated&lt;-as.vector(t(matrix(treated,length(treated),ncontrols+1)))
  m&lt;-cbind(m,treated)
  list(m=m,dt=dt)
}



matchPast&lt;-function(z,ncontrols=1){
  dt&lt;-binge[!is.na(z),]
  z&lt;-z[!is.na(z)]
  dt&lt;-dt[order(1-z,dt$SEQN),]
  z&lt;-z[order(1-z,dt$SEQN)]
  rownames(dt)&lt;-dt$SEQN
  names(z)&lt;-dt$SEQN
  left&lt;-startcost(z)
  right&lt;-startcost(z)
  attach(dt)
  propmod&lt;-glm(z~age+female+education+smokenow+smokeQuit+bpRX+
                 bmi+vigor+waisthip,family=binomial)
  p&lt;-propmod$fitted.values
  left&lt;-addinteger(left,z,as.integer(ageC),penalty=100)
  left&lt;-addNearExact(left,z,female,penalty = 10000)
  left&lt;-addNearExact(left,z,bpRX,penalty = 10000)
  left&lt;-addNearExact(left,z,vigor,penalty=10)
  left&lt;-addinteger(left,z,smokenow,penalty=10)
  left&lt;-addMahal(left,z,cbind(age,bpRX,female,education,smokenow,
        smokeQuit,bmi,vigor,waisthip))
  right&lt;-addMahal(right,z,cbind(female,age,p))
  right&lt;-addinteger(right,z,education,penalty=10)
  right&lt;-addinteger(right,z,smokenow,penalty=1000)
  right&lt;-addinteger(right,z,smokeQuit,penalty=10)
  right&lt;-addcaliper(right,z,p,caliper=c(-1,.03),penalty=10)
  controlcosts&lt;-((p[z==0]&lt;.4)&amp;(age[z==0]&gt;42))*1000
  detach(dt)
  dt&lt;-cbind(dt,z,p)
  m&lt;-makematch(dt,left,right,ncontrols=ncontrols,controlcosts=controlcosts)
  m$mset&lt;-as.integer(m$mset)
  treated&lt;-m$SEQN[m$z==1]
  treated&lt;-as.vector(t(matrix(treated,length(treated),ncontrols+1)))
  m&lt;-cbind(m,treated)
  list(m=m,dt=dt)
}

z&lt;-rep(NA,dim(binge)[1])
z[binge$AlcGroup=="B"]&lt;-1
z[binge$AlcGroup=="P"]&lt;-0
mPastComplete&lt;-matchPast(z,ncontrols=1)
mPast&lt;-mPastComplete$m
mPastComplete&lt;-mPastComplete$dt
rm(z)

z&lt;-rep(NA,dim(binge)[1])
z[binge$AlcGroup=="B"]&lt;-1
z[binge$AlcGroup=="N"]&lt;-0
mNeverComplete&lt;-matchNever(z,ncontrols=1)
mNever&lt;-mNeverComplete$m
mNeverComplete&lt;-mNeverComplete$dt
rm(z)

bingeM&lt;-rbind(mNever,mPast[mPast$z==0,])
bingeM&lt;-bingeM[order(bingeM$treated,bingeM$AlcGroup,bingeM$SEQN),]
w&lt;-which(colnames(bingeM)=="p")[1]
bingeM&lt;-bingeM[,-w]
rm(binge,matchNever,matchPast,w)

old.par &lt;- par(no.readonly = TRUE)

par(mfrow=c(1,2))
 boxplot(mNever$p[mNever$z==1],mNever$p[mNever$z==0],
 mNeverComplete$p[!is.element(mNeverComplete$SEQN,mNever$SEQN)],
 names=c("B","mN","uN"),ylab="Propensity Score",main="Never",
 ylim=c(0,.8))

 boxplot(mPast$p[mPast$z==1],mPast$p[mPast$z==0],
 mPastComplete$p[!is.element(mPastComplete$SEQN,mPast$SEQN)],
 names=c("B","mP","uP"),ylab="Propensity Score",main="Past",
 ylim=c(0,.8))

 par(mfrow=c(1,2))
 boxplot(mNever$age[mNever$z==1],mNever$age[mNever$z==0],
 mNeverComplete$age[!is.element(mNeverComplete$SEQN,mNever$SEQN)],
 names=c("B","mN","uN"),ylab="Age",main="Never",
 ylim=c(20,80))

 boxplot(mPast$age[mPast$z==1],mPast$age[mPast$z==0],
 mPastComplete$age[!is.element(mPastComplete$SEQN,mPast$SEQN)],
 names=c("B","mP","uP"),ylab="Age",main="Past",
 ylim=c(20,80))

 par(mfrow=c(1,2))
 boxplot(mNever$education[mNever$z==1],mNever$education[mNever$z==0],
 mNeverComplete$education[!is.element(mNeverComplete$SEQN,mNever$SEQN)],
 names=c("B","mN","uN"),ylab="Education",main="Never",
 ylim=c(1,5))

 boxplot(mPast$education[mPast$z==1],mPast$education[mPast$z==0],
 mPastComplete$education[!is.element(mPastComplete$SEQN,mPast$SEQN)],
 names=c("B","mP","uP"),ylab="Education",main="Past",
 ylim=c(1,5))

 par(mfrow=c(1,2))
 boxplot(mNever$bmi[mNever$z==1],mNever$bmi[mNever$z==0],
 mNeverComplete$bmi[!is.element(mNeverComplete$SEQN,mNever$SEQN)],
 names=c("B","mN","uN"),ylab="BMI",main="Never",
 ylim=c(14,70))

 boxplot(mPast$bmi[mPast$z==1],mPast$bmi[mPast$z==0],
 mPastComplete$bmi[!is.element(mPastComplete$SEQN,mPast$SEQN)],
 names=c("B","mP","uP"),ylab="BMI",main="Past",
 ylim=c(14,70))

 par(mfrow=c(1,2))
 boxplot(mNever$waisthip[mNever$z==1],mNever$waisthip[mNever$z==0],
 mNeverComplete$waisthip[!is.element(mNeverComplete$SEQN,mNever$SEQN)],
 names=c("B","mN","uN"),ylab="Waist/Hip",main="Never",
 ylim=c(.65,1.25))

 boxplot(mPast$waisthip[mPast$z==1],mPast$waisthip[mPast$z==0],
 mPastComplete$waisthip[!is.element(mPastComplete$SEQN,mPast$SEQN)],
 names=c("B","mP","uP"),ylab="Waist/Hip",main="Past",
 ylim=c(.65,1.25))

 par(old.par)
 
</code></pre>

<hr>
<h2 id='makenetwork'>
Make the Network Used for Matching with Two Criteria
</h2><span id='topic+makenetwork'></span>

<h3>Description</h3>

<p>This function is of limited interest to most users, and is called by other functions in the package.  Makes the network used in the two-criteria matching method of Zhang et al. (2022).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>makenetwork(costL, costR, ncontrols = 1, controlcosts = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="makenetwork_+3A_costl">costL</code></td>
<td>

<p>The distance matrix on the left side of the network, used for pairing.
</p>
</td></tr>
<tr><td><code id="makenetwork_+3A_costr">costR</code></td>
<td>

<p>The distance matrix on the right side of the network, used for balancing.
</p>
</td></tr>
<tr><td><code id="makenetwork_+3A_ncontrols">ncontrols</code></td>
<td>

<p>One positive integer, 1 for pair matching, 2 for matching two controls to each treated individual, etc.
</p>
</td></tr>
<tr><td><code id="makenetwork_+3A_controlcosts">controlcosts</code></td>
<td>

<p>An optional vector of costs used to penalize the control-control edges.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function creates the network depicted in Figure 1 of Zhang et al. (2023).
</p>
<p>A minimum cost flow in this network is found by passing net to callrelax() in the package 'rcbalance'.  If you use callrelax(), I strongly suggest you do this with solver set to 'rrelaxiv'.  The 'rrelaxiv' package has an academic license.  The 'rrelaxiv' package uses Fortran code from RELAX IV developed by Bertsekas and Tseng (1988, 1994) based on Bertsekas' (1990) auction algorithm.
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>idtreated</code></td>
<td>
<p>Row identifications for treated individuals</p>
</td></tr>
<tr><td><code>idcontrol</code></td>
<td>
<p>Control identifications for control individuals</p>
</td></tr>
<tr><td><code>net</code></td>
<td>
<p>A network for use with callrelax in the 'rcbalance' package.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Paul R. Rosenbaum
</p>


<h3>References</h3>

<p>Bertsekas, D. P., Tseng, P. (1988) &lt;doi:10.1007/BF02288322&gt; The relax codes for linear minimum cost network flow problems. Annals of Operations Research, 13, 125-190.
</p>
<p>Bertsekas, D. P. (1990) &lt;doi:10.1287/inte.20.4.133&gt; The auction algorithm for assignment and other network flow problems: A tutorial. Interfaces, 20(4), 133-149.
</p>
<p>Bertsekas, D. P., Tseng, P. (1994)
&lt;http://web.mit.edu/dimitrib/www/Bertsekas_Tseng_RELAX4_!994.pdf&gt; RELAX-IV: A Faster Version of the RELAX Code for Solving Minimum Cost Flow Problems.
</p>
<p>Zhang, B., D. S. Small, K. B. Lasater, M. McHugh, J. H. Silber, and P. R. Rosenbaum (2023) &lt;doi:10.1080/01621459.2021.1981337&gt; Matching one sample according to two criteria in observational studies. Journal of the American Statistical Association, 118, 1140-1151.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(binge)
# Select two treated and three controls from binge
d&lt;-binge[is.element(binge$SEQN,c(109315,109365,109266,109273,109290)),]
z&lt;-1*(d$AlcGroup=="B")
names(z)&lt;-d$SEQN
attach(d)
x&lt;-data.frame(age,female)
detach(d)
rownames(x)&lt;-d$SEQN
Ldist&lt;-startcost(z)
Ldist&lt;-addcaliper(Ldist,z,x$age,caliper=10,penalty=5)
Rdist&lt;-startcost(z)
Rdist&lt;-addNearExact(Rdist,z,x$female)
makenetwork(Ldist,Rdist)
</code></pre>

<hr>
<h2 id='noether'>
Sensitivity Analysis Using Noether's Test for Matched Pairs
</h2><span id='topic+noether'></span>

<h3>Description</h3>

<p>Computes a sensitivity analysis for treated-minus-control matched
pair differences in observational studies.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>noether(y, f = 2/3, gamma = 1, alternative = "greater")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="noether_+3A_y">y</code></td>
<td>

<p>A vector of treated-minus-control matched pair differences.
</p>
</td></tr>
<tr><td><code id="noether_+3A_f">f</code></td>
<td>

<p>A nonnegative number strictly less than 1.  Suppose that there are I matched
pair differences, length(y)=I.  Rank the absolute pair differences from 1 to I
with average ranks for ties.  Noether's statistic looks at the roughly (1-f)I
pair differences with absolute ranks that are at least fI, and computes the
sign test from these fI pair differences.  With f=0, Noether's statistic
is the usual sign test statistic.  With f=2/3, Noether's statistic focuses
on the 1/3 of pairs with the largest absolute pair differences.  In his
article, Noether suggested f=1/3 for randomized matched pair differences
from a Normal distribution, but f=2/3 is better for sensitivity analyses in
observational studies.  Pair differences that are zero are not counted, but
this is uncommon for f=2/3.
</p>
</td></tr>
<tr><td><code id="noether_+3A_gamma">gamma</code></td>
<td>

<p>A number greater than or equal to 1.  gamma is the sensitivity
parameter, where gamma=1 for a randomization test, and gamma&gt;1
for a sensitivity analysis.
</p>
</td></tr>
<tr><td><code id="noether_+3A_alternative">alternative</code></td>
<td>

<p>The possible alternatives are &quot;greater&quot;, &quot;less&quot; or &quot;two.sided&quot;;
however, &quot;two.sided&quot; is available only for gamma=1.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Noether's (1973) strengthens the sign test.  In a randomized experiment, it
increase power.  In an observational study, it increases design sensitivity
and the Bahadur efficiency of a sensitivity analysis.
</p>
<p>Because the test has a binomial null distribution in both a randomized
experiment and in an observational study, Noether's test is used in a
number of problems in Introduction to the Theory of Observational Studies.
</p>
<p>Noether's test is related to methods of Gastwirth (1966), Brown (1981), and
Markowski and Hettmansperger (1982).  Its properties in an observational study
are discussed Rosenbaum (2012, 2015).
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>number.pairs</code></td>
<td>
<p>Number of pairs used by Noether's statistic, roughly
fI.</p>
</td></tr>
<tr><td><code>positive.pairs</code></td>
<td>
<p>Number of positive pair differences among used pairs.</p>
</td></tr>
<tr><td><code>pval</code></td>
<td>
<p>P-value testing the null hypothesis of no treatment effect.
Obtained from the binomial distribution.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>As noted in the Preface to Introduction to the Theory of Observational Studies,
Noether's statistic is used in a sequence of Problems that appear in various
chapters.
</p>


<h3>Author(s)</h3>

<p>Paul R. Rosenbaum
</p>


<h3>References</h3>

<p>Brown, B. M. (1981) &lt;doi:10.1093/biomet/68.1.235&gt; Symmetric quantile averages and related estimators. Biometrika, 68(1), 235-242.
</p>
<p>Gastwirth, J. L. (1966) &lt;doi:10.1080/01621459.1966.10482185&gt; On robust procedures. Journal of the American Statistical Association, 61(316), 929-948.
</p>
<p>Markowski, E. P. and Hettmansperger, T. P. (1982)
&lt;doi:10.1080/01621459.1982.10477905&gt; Inference based on simple rank step score statistics for the location model. Journal of the American Statistical Association, 77(380), 901-907.
</p>
<p>Noether, G. E. (1973) &lt;doi:10.1080/01621459.1973.10481411&gt; Some simple distribution-free confidence intervals for the center of a symmetric distribution. Journal of the American Statistical Association, 68(343), 716-719.
</p>
<p>Rosenbaum, P. R. (2012) &lt;10.1214/11-AOAS508&gt; An exact adaptive test with superior design sensitivity in an observational study of treatments for ovarian cancer.  Annals of Applied Statistics, 6, 83-105.
</p>
<p>Rosenbaum, P. R. (2015) &lt;doi:10.1080/01621459.2014.960968&gt; Bahadur efficiency of sensitivity analyses in observational studies. Journal of the American Statistical Association, 110(509), 205-217.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
y&lt;-rnorm(1000)+.5
noether(y,f=0,gamma=3)
noether(y,f=2/3,gamma=3)
</code></pre>

<hr>
<h2 id='startcost'>
Initialize a Distance Matrix.
</h2><span id='topic+startcost'></span>

<h3>Description</h3>

<p>Creates an distance matrix of zeros of dimensions compatible with the treatment indicator vector z.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>startcost(z)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="startcost_+3A_z">z</code></td>
<td>

<p>A vector with z[i]=1 if individual i is treated or z[i]=0 if individual i is control.  The rows of costmatrix refer to treated individuals and the columns refer to controls.  Although not strictly required, it is best that z has names that are the same as the names of the data frame dat that will be used in matching.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix of zeros with sum(z) rows and sum(1-z) columns.  If z has names, then they become the row and column names of this matrix.
</p>


<h3>Author(s)</h3>

<p>Paul R. Rosenbaum
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(binge)
# Select two treated and three controls from binge
d&lt;-binge[is.element(binge$SEQN,c(109315,109365,109266,109273,109290)),]
z&lt;-1*(d$AlcGroup=="B")
names(z)&lt;-d$SEQN
dist&lt;-startcost(z)
dist
rm(z,dist,d)
</code></pre>

<hr>
<h2 id='zeta'>
zeta function in sensitivity analysis
</h2><span id='topic+zeta'></span>

<h3>Description</h3>

<p>Of limited interest to most users, the zeta function plays an internal role in 2-sample and stratified sensitivity analyses.  The zeta function is equation (8), page 495, in Rosenbaum and Krieger (1990).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>zeta(bigN, n, m, g)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="zeta_+3A_bign">bigN</code></td>
<td>

<p>Total sample size in this stratum.
</p>
</td></tr>
<tr><td><code id="zeta_+3A_n">n</code></td>
<td>

<p>Treated sample size in this stratum.
</p>
</td></tr>
<tr><td><code id="zeta_+3A_m">m</code></td>
<td>

<p>The number of 1's in the vector u of unobserved covariates.  Here, u
has bigN-m 0's followed by m 1's.
</p>
</td></tr>
<tr><td><code id="zeta_+3A_g">g</code></td>
<td>

<p>The sensitivity parameter <code class="reqn">\Gamma</code>, where <code class="reqn">\Gamma \ge 1</code>.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The value of the zeta function.
</p>


<h3>Note</h3>

<p>The zeta function is called by computep.  The zeta function is from the senstrat package.
</p>


<h3>Author(s)</h3>

<p>Paul R. Rosenbaum
</p>


<h3>References</h3>

<p>Rosenbaum, P. R. and Krieger, A. M. (1990). Sensitivity of two-sampler permutation inferences in observational studies.  Journal of the American Statistical Association, 85, 493-498.
</p>
<p>Rosenbaum, P. R. (2002). Observational Studies (2nd edition). New York: Springer.  Section 4.6.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>zeta(10,5,6,2)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
