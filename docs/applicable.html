<!DOCTYPE html><html><head><title>Help for package applicable</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {applicable}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#applicable-package'><p>applicable: A Compilation of Applicability Domain Methods</p></a></li>
<li><a href='#ames_new'><p>Recent Ames Iowa Houses</p></a></li>
<li><a href='#apd_hat_values'><p>Fit a <code>apd_hat_values</code></p></a></li>
<li><a href='#apd_isolation'><p>Fit an isolation forest to estimate an applicability domain.</p></a></li>
<li><a href='#apd_pca'><p>Fit a <code>apd_pca</code></p></a></li>
<li><a href='#apd_similarity'><p>Applicability domain methods using binary similarity analysis</p></a></li>
<li><a href='#autoplot.apd_pca'><p>Plot the distribution function for principal components</p></a></li>
<li><a href='#autoplot.apd_similarity'><p>Plot the cumulative distribution function for similarity metrics</p></a></li>
<li><a href='#binary'><p>Binary QSAR Data</p></a></li>
<li><a href='#okc_binary'><p>OkCupid Binary Predictors</p></a></li>
<li><a href='#print.apd_hat_values'><p>Print number of predictors and principal components used.</p></a></li>
<li><a href='#print.apd_pca'><p>Print number of predictors and principal components used.</p></a></li>
<li><a href='#print.apd_similarity'><p>Print number of predictors and principal components used.</p></a></li>
<li><a href='#score'><p>A scoring function</p></a></li>
<li><a href='#score.apd_hat_values'><p>Score new samples using hat values</p></a></li>
<li><a href='#score.apd_isolation'><p>Predict from a <code>apd_isolation</code></p></a></li>
<li><a href='#score.apd_pca'><p>Predict from a <code>apd_pca</code></p></a></li>
<li><a href='#score.apd_similarity'><p>Score new samples using similarity methods</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Title:</td>
<td>A Compilation of Applicability Domain Methods</td>
</tr>
<tr>
<td>Version:</td>
<td>0.1.0</td>
</tr>
<tr>
<td>Description:</td>
<td>A modeling package compiling applicability domain methods in
    R. It combines different methods to measure the amount of
    extrapolation new samples can have from the training set. See Gadaleta et 
    al (2016)  &lt;<a href="https://doi.org/10.4018%2FIJQSPR.2016010102">doi:10.4018/IJQSPR.2016010102</a>&gt; for an overview of
    applicability domains.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/tidymodels/applicable">https://github.com/tidymodels/applicable</a>,
<a href="https://applicable.tidymodels.org">https://applicable.tidymodels.org</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/tidymodels/applicable/issues">https://github.com/tidymodels/applicable/issues</a></td>
</tr>
<tr>
<td>Depends:</td>
<td>ggplot2, R (&ge; 3.4)</td>
</tr>
<tr>
<td>Imports:</td>
<td>dplyr, glue, hardhat (&ge; 0.1.2), Matrix, proxyC, purrr, rlang,
stats, tibble, tidyr, tidyselect, utils</td>
</tr>
<tr>
<td>Suggests:</td>
<td>covr, isotree, knitr, modeldata, recipes (&ge; 0.1.7),
rmarkdown, spelling, testthat (&ge; 3.0.0), xml2</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Language:</td>
<td>en-US</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.1.9000</td>
</tr>
<tr>
<td>Config/Needs/website:</td>
<td>tidyverse/tidytemplate</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2022-08-18 19:01:35 UTC; max</td>
</tr>
<tr>
<td>Author:</td>
<td>Marly Gotti [aut, cre],
  Max Kuhn [aut],
  RStudio [cph]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Marly Gotti &lt;marlygotti@gmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2022-08-20 21:50:11 UTC</td>
</tr>
</table>
<hr>
<h2 id='applicable-package'>applicable: A Compilation of Applicability Domain Methods</h2><span id='topic+applicable'></span><span id='topic+applicable-package'></span>

<h3>Description</h3>

<p><img src="../help/figures/logo.png" style='float: right' alt='logo' width='120' />
</p>
<p>A modeling package compiling applicability domain methods in R. It combines different methods to measure the amount of extrapolation new samples can have from the training set. See Gadaleta et al (2016) <a href="https://doi.org/10.4018/IJQSPR.2016010102">doi:10.4018/IJQSPR.2016010102</a> for an overview of applicability domains.
</p>


<h3>Author(s)</h3>

<p><strong>Maintainer</strong>: Marly Gotti <a href="mailto:marlygotti@gmail.com">marlygotti@gmail.com</a>
</p>
<p>Authors:
</p>

<ul>
<li><p> Max Kuhn <a href="mailto:max@rstudio.com">max@rstudio.com</a>
</p>
</li></ul>

<p>Other contributors:
</p>

<ul>
<li><p> RStudio [copyright holder]
</p>
</li></ul>



<h3>See Also</h3>

<p>Useful links:
</p>

<ul>
<li> <p><a href="https://github.com/tidymodels/applicable">https://github.com/tidymodels/applicable</a>
</p>
</li>
<li> <p><a href="https://applicable.tidymodels.org">https://applicable.tidymodels.org</a>
</p>
</li>
<li><p> Report bugs at <a href="https://github.com/tidymodels/applicable/issues">https://github.com/tidymodels/applicable/issues</a>
</p>
</li></ul>


<hr>
<h2 id='ames_new'>Recent Ames Iowa Houses</h2><span id='topic+ames_new'></span>

<h3>Description</h3>

<p>More data related to the set described by De Cock (2011) where data where
data were recorded for 2,930 properties in Ames IA.
</p>


<h3>Details</h3>

<p>This data sets includes three more properties added since the original
reference. There are less fields in this data set; only those that could be
transcribed from the assessor's office were included.
</p>


<h3>Value</h3>

<table>
<tr><td><code>ames_new</code></td>
<td>
<p>a tibble</p>
</td></tr>
</table>


<h3>Source</h3>

<p>De Cock, D. (2011). &quot;Ames, Iowa: Alternative to the Boston Housing
Data as an End of Semester Regression Project,&quot; <em>Journal of Statistics
Education</em>,  Volume 19, Number 3.
</p>
<p><code style="white-space: pre;">&#8288;https://www.cityofames.org&#8288;</code> (see Assessor's department site)
</p>
<p><a href="http://jse.amstat.org/v19n3/decock/DataDocumentation.txt">http://jse.amstat.org/v19n3/decock/DataDocumentation.txt</a>
</p>
<p><a href="http://jse.amstat.org/v19n3/decock.pdf">http://jse.amstat.org/v19n3/decock.pdf</a>
</p>

<hr>
<h2 id='apd_hat_values'>Fit a <code>apd_hat_values</code></h2><span id='topic+apd_hat_values'></span><span id='topic+apd_hat_values.default'></span><span id='topic+apd_hat_values.data.frame'></span><span id='topic+apd_hat_values.matrix'></span><span id='topic+apd_hat_values.formula'></span><span id='topic+apd_hat_values.recipe'></span>

<h3>Description</h3>

<p><code>apd_hat_values()</code> fits a model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>apd_hat_values(x, ...)

## Default S3 method:
apd_hat_values(x, ...)

## S3 method for class 'data.frame'
apd_hat_values(x, ...)

## S3 method for class 'matrix'
apd_hat_values(x, ...)

## S3 method for class 'formula'
apd_hat_values(formula, data, ...)

## S3 method for class 'recipe'
apd_hat_values(x, data, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="apd_hat_values_+3A_x">x</code></td>
<td>
<p>Depending on the context:
</p>

<ul>
<li><p> A <strong>data frame</strong> of predictors.
</p>
</li>
<li><p> A <strong>matrix</strong> of predictors.
</p>
</li>
<li><p> A <strong>recipe</strong> specifying a set of preprocessing steps
created from <code><a href="recipes.html#topic+recipe">recipes::recipe()</a></code>.
</p>
</li></ul>
</td></tr>
<tr><td><code id="apd_hat_values_+3A_...">...</code></td>
<td>
<p>Not currently used, but required for extensibility.</p>
</td></tr>
<tr><td><code id="apd_hat_values_+3A_formula">formula</code></td>
<td>
<p>A formula specifying the predictor terms on the right-hand
side. No outcome should be specified.</p>
</td></tr>
<tr><td><code id="apd_hat_values_+3A_data">data</code></td>
<td>
<p>When a <strong>recipe</strong> or <strong>formula</strong> is used, <code>data</code> is specified as:
</p>

<ul>
<li><p> A <strong>data frame</strong> containing the predictors.
</p>
</li></ul>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code>apd_hat_values</code> object.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>predictors &lt;- mtcars[, -1]

# Data frame interface
mod &lt;- apd_hat_values(predictors)

# Formula interface
mod2 &lt;- apd_hat_values(mpg ~ ., mtcars)

# Recipes interface
library(recipes)
rec &lt;- recipe(mpg ~ ., mtcars)
rec &lt;- step_log(rec, disp)
mod3 &lt;- apd_hat_values(rec, mtcars)
</code></pre>

<hr>
<h2 id='apd_isolation'>Fit an isolation forest to estimate an applicability domain.</h2><span id='topic+apd_isolation'></span><span id='topic+apd_isolation.default'></span><span id='topic+apd_isolation.data.frame'></span><span id='topic+apd_isolation.matrix'></span><span id='topic+apd_isolation.formula'></span><span id='topic+apd_isolation.recipe'></span>

<h3>Description</h3>

<p><code>apd_isolation()</code> fits an isolation forest model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>apd_isolation(x, ...)

## Default S3 method:
apd_isolation(x, ...)

## S3 method for class 'data.frame'
apd_isolation(x, ...)

## S3 method for class 'matrix'
apd_isolation(x, ...)

## S3 method for class 'formula'
apd_isolation(formula, data, ...)

## S3 method for class 'recipe'
apd_isolation(x, data, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="apd_isolation_+3A_x">x</code></td>
<td>
<p>Depending on the context:
</p>

<ul>
<li><p> A <strong>data frame</strong> of predictors.
</p>
</li>
<li><p> A <strong>matrix</strong> of predictors (see the <code>categ_cols</code> argument of
<code><a href="isotree.html#topic+isolation.forest">isotree::isolation.forest()</a></code>).
</p>
</li>
<li><p> A <strong>recipe</strong> specifying a set of preprocessing steps
created from <code><a href="recipes.html#topic+recipe">recipes::recipe()</a></code>.
</p>
</li></ul>
</td></tr>
<tr><td><code id="apd_isolation_+3A_...">...</code></td>
<td>
<p>Options to pass to <code><a href="isotree.html#topic+isolation.forest">isotree::isolation.forest()</a></code>. Options should
not include <code>data</code>.</p>
</td></tr>
<tr><td><code id="apd_isolation_+3A_formula">formula</code></td>
<td>
<p>A formula specifying the predictor terms on the right-hand
side. No outcome should be specified.</p>
</td></tr>
<tr><td><code id="apd_isolation_+3A_data">data</code></td>
<td>
<p>When a <strong>recipe</strong> or <strong>formula</strong> is used, <code>data</code> is specified as:
</p>

<ul>
<li><p> A <strong>data frame</strong> containing the predictors.
</p>
</li></ul>
</td></tr>
</table>


<h3>Details</h3>

<p>In an isolation forest, splits are designed to isolate individual data points.
The tree construction process takes random split locations on randomly
selected predictors. As splits are made in the tree, the algorithm tracks
when data points are isolated as more splits are made. The first points that
are isolated are thought to be outliers or anomalous. From these results, an
anomaly score can be constructed.
</p>
<p>This function creates an isolation forest on the training set and measures
the reference distribution of the scores when re-predicting the training set.
When scoring new data, the raw anomaly score is produced along with the
sample's corresponding percentile of the reference distribution.
</p>


<h3>Value</h3>

<p>A <code>apd_isolation</code> object.
</p>


<h3>References</h3>

<p>Liu, Fei Tony, Kai Ming Ting, and Zhi-Hua Zhou. &quot;Isolation forest.&quot;
2008 <em>Eighth IEEE International Conference on Data Mining. IEEE</em>, 2008.
Liu, Fei Tony, Kai Ming Ting, and Zhi-Hua Zhou. &quot;Isolation-based anomaly
detection.&quot; <em>ACM Transactions on Knowledge Discovery from Data (TKDD)</em> 6.1
(2012): 3.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
if (rlang::is_installed(c("isotree", "modeldata"))) {
  library(dplyr)

  data(cells, package = "modeldata")

  cells_tr &lt;- cells %&gt;% filter(case == "Train") %&gt;% select(-case, -class)
  cells_te &lt;- cells %&gt;% filter(case != "Train") %&gt;% select(-case, -class)

  if_mod &lt;- apd_isolation(cells_tr, ntrees = 10, nthreads = 1)
  if_mod
}

</code></pre>

<hr>
<h2 id='apd_pca'>Fit a <code>apd_pca</code></h2><span id='topic+apd_pca'></span><span id='topic+apd_pca.default'></span><span id='topic+apd_pca.data.frame'></span><span id='topic+apd_pca.matrix'></span><span id='topic+apd_pca.formula'></span><span id='topic+apd_pca.recipe'></span>

<h3>Description</h3>

<p><code>apd_pca()</code> fits a model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>apd_pca(x, ...)

## Default S3 method:
apd_pca(x, ...)

## S3 method for class 'data.frame'
apd_pca(x, threshold = 0.95, ...)

## S3 method for class 'matrix'
apd_pca(x, threshold = 0.95, ...)

## S3 method for class 'formula'
apd_pca(formula, data, threshold = 0.95, ...)

## S3 method for class 'recipe'
apd_pca(x, data, threshold = 0.95, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="apd_pca_+3A_x">x</code></td>
<td>
<p>Depending on the context:
</p>

<ul>
<li><p> A <strong>data frame</strong> of predictors.
</p>
</li>
<li><p> A <strong>matrix</strong> of predictors.
</p>
</li>
<li><p> A <strong>recipe</strong> specifying a set of preprocessing steps
created from <code><a href="recipes.html#topic+recipe">recipes::recipe()</a></code>.
</p>
</li></ul>
</td></tr>
<tr><td><code id="apd_pca_+3A_...">...</code></td>
<td>
<p>Not currently used, but required for extensibility.</p>
</td></tr>
<tr><td><code id="apd_pca_+3A_threshold">threshold</code></td>
<td>
<p>A number indicating the percentage of variance desired from
the principal components. It must be a number greater than 0 and less or
equal than 1.</p>
</td></tr>
<tr><td><code id="apd_pca_+3A_formula">formula</code></td>
<td>
<p>A formula specifying the predictor terms on the right-hand
side. No outcome should be specified.</p>
</td></tr>
<tr><td><code id="apd_pca_+3A_data">data</code></td>
<td>
<p>When a <strong>recipe</strong> or <strong>formula</strong> is used, <code>data</code> is specified as:
</p>

<ul>
<li><p> A <strong>data frame</strong> containing the predictors.
</p>
</li></ul>
</td></tr>
</table>


<h3>Details</h3>

<p>The function computes the principal components that account for
up to either 95% or the provided <code>threshold</code> of variability. It also
computes the percentiles of the absolute value of the principal components.
Additionally, it calculates the mean of each principal component.
</p>


<h3>Value</h3>

<p>A <code>apd_pca</code> object.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>predictors &lt;- mtcars[, -1]

# Data frame interface
mod &lt;- apd_pca(predictors)

# Formula interface
mod2 &lt;- apd_pca(mpg ~ ., mtcars)

# Recipes interface
library(recipes)
rec &lt;- recipe(mpg ~ ., mtcars)
rec &lt;- step_log(rec, disp)
mod3 &lt;- apd_pca(rec, mtcars)
</code></pre>

<hr>
<h2 id='apd_similarity'>Applicability domain methods using binary similarity analysis</h2><span id='topic+apd_similarity'></span><span id='topic+apd_similarity.default'></span><span id='topic+apd_similarity.data.frame'></span><span id='topic+apd_similarity.matrix'></span><span id='topic+apd_similarity.formula'></span><span id='topic+apd_similarity.recipe'></span>

<h3>Description</h3>

<p><code>apd_similarity()</code> is used to analyze samples in terms of similarity scores
for binary data. All features in the data should be binary (i.e. zero or
one).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>apd_similarity(x, ...)

## Default S3 method:
apd_similarity(x, quantile = NA_real_, ...)

## S3 method for class 'data.frame'
apd_similarity(x, quantile = NA_real_, ...)

## S3 method for class 'matrix'
apd_similarity(x, quantile = NA_real_, ...)

## S3 method for class 'formula'
apd_similarity(formula, data, quantile = NA_real_, ...)

## S3 method for class 'recipe'
apd_similarity(x, data, quantile = NA_real_, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="apd_similarity_+3A_x">x</code></td>
<td>
<p>Depending on the context:
</p>

<ul>
<li><p> A <strong>data frame</strong> of binary predictors.
</p>
</li>
<li><p> A <strong>matrix</strong> of binary predictors.
</p>
</li>
<li><p> A <strong>recipe</strong> specifying a set of preprocessing steps
created from <code><a href="recipes.html#topic+recipe">recipes::recipe()</a></code>.
</p>
</li></ul>
</td></tr>
<tr><td><code id="apd_similarity_+3A_...">...</code></td>
<td>
<p>Options to pass to <code>proxyC::simil()</code>, such as <code>method</code>. If no
options are specified, <code>method = "jaccard"</code> is used.</p>
</td></tr>
<tr><td><code id="apd_similarity_+3A_quantile">quantile</code></td>
<td>
<p>A real number between 0 and 1 or NA for how the similarity
values for each sample versus the training set should be summarized. A value
of <code>NA</code> specifies that the mean similarity is computed. Otherwise, the
appropriate quantile is computed.</p>
</td></tr>
<tr><td><code id="apd_similarity_+3A_formula">formula</code></td>
<td>
<p>A formula specifying the predictor terms on the right-hand
side. No outcome should be specified.</p>
</td></tr>
<tr><td><code id="apd_similarity_+3A_data">data</code></td>
<td>
<p>When a <strong>recipe</strong> or <strong>formula</strong> is used, <code>data</code> is specified as:
</p>

<ul>
<li><p> A <strong>data frame</strong> containing the binary predictors. Any predictors with
no 1's will be removed (with a warning).
</p>
</li></ul>
</td></tr>
</table>


<h3>Details</h3>

<p>The function computes measures of similarity for different samples
points. For example, suppose samples <code>A</code> and <code>B</code> both contain <em>p</em> binary
variables. First, a 2x2 table is constructed between <code>A</code> and <code>B</code> <em>across
their elements</em>. The table will contain <em>p</em> entries across the four cells
(see the example below). From this, different measures of likeness are
computed.
</p>
<p>For a training set of <em>n</em> samples, a new sample is compared to each,
resulting in <em>n</em> similarity scores. These can be summarized into a single
value; the median similarity is used by default by the scoring function.
</p>
<p>For this method, the computational methods are fairly taxing for large data
sets. The training set must be stored (albeit in a sparse matrix format) so
object sizes may become large.
</p>
<p>By default, the computations are run in parallel using <em>all possible
cores</em>. To change this, call the <code>setThreadOptions</code> function in the
<code>RcppParallel</code> package.
</p>


<h3>Value</h3>

<p>A <code>apd_similarity</code> object.
</p>


<h3>References</h3>

<p>Leach, A. and Gillet V. (2007). <em>An Introduction to
Chemoinformatics</em>. Springer, New York
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(qsar_binary)

jacc_sim &lt;- apd_similarity(binary_tr)
jacc_sim

# plot the empirical cumulative distribution function (ECDF) for the training set:
library(ggplot2)
autoplot(jacc_sim)

# Example calculations for two samples:
A &lt;- as.matrix(binary_tr[1, ])
B &lt;- as.matrix(binary_tr[2, ])
xtab &lt;- table(A, B)
xtab

# Jaccard statistic
xtab[2, 2] / (xtab[1, 2] + xtab[2, 1] + xtab[2, 2])

# Hamman statistic
((xtab[1, 1] + xtab[2, 2]) - (xtab[1, 2] + xtab[2, 1])) / sum(xtab)

# Faith statistic
(xtab[1, 1] + xtab[2, 2] / 2) / sum(xtab)

# Summarize across all training set similarities
mean_sim &lt;- score(jacc_sim, new_data = binary_unk)
mean_sim

</code></pre>

<hr>
<h2 id='autoplot.apd_pca'>Plot the distribution function for principal components</h2><span id='topic+autoplot.apd_pca'></span>

<h3>Description</h3>

<p>Plot the distribution function for principal components
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'apd_pca'
autoplot(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="autoplot.apd_pca_+3A_object">object</code></td>
<td>
<p>An object produced by <code>apd_pca</code>.</p>
</td></tr>
<tr><td><code id="autoplot.apd_pca_+3A_...">...</code></td>
<td>
<p>An optional set of <code>dplyr</code> selectors, such as <code>dplyr::matches()</code> or
<code>dplyr::starts_with()</code> for selecting which variables should be shown in the
plot.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code>ggplot</code> object that shows the distribution function for each
principal component.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(ggplot2)
library(dplyr)
library(modeldata)
data(biomass)

biomass_ad &lt;- apd_pca(biomass[, 3:8])

autoplot(biomass_ad)
# Using selectors in `...`
autoplot(biomass_ad, distance) + scale_x_log10()
autoplot(biomass_ad, matches("PC[1-2]"))
</code></pre>

<hr>
<h2 id='autoplot.apd_similarity'>Plot the cumulative distribution function for similarity metrics</h2><span id='topic+autoplot.apd_similarity'></span>

<h3>Description</h3>

<p>Plot the cumulative distribution function for similarity metrics
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'apd_similarity'
autoplot(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="autoplot.apd_similarity_+3A_object">object</code></td>
<td>
<p>An object produced by <code>apd_similarity</code>.</p>
</td></tr>
<tr><td><code id="autoplot.apd_similarity_+3A_...">...</code></td>
<td>
<p>Not currently used.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code>ggplot</code> object that shows the cumulative probability versus the
unique similarity values in the training set. Not that for large samples,
this is an approximation based on a random sample of 5,000 training set
points.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(535)
tr_x &lt;- matrix(
  sample(0:1, size = 20 * 50, prob = rep(.5, 2), replace = TRUE),
  ncol = 20
)
model &lt;- apd_similarity(tr_x)
</code></pre>

<hr>
<h2 id='binary'>Binary QSAR Data</h2><span id='topic+binary'></span><span id='topic+qsar_binary'></span><span id='topic+binary_tr'></span><span id='topic+binary_unk'></span>

<h3>Description</h3>

<p>Binary QSAR Data
</p>


<h3>Details</h3>

<p>These data are from two different sources on quantitative
structure-activity relationship (QSAR) modeling and contain 67 predictors
that are either 0 or 1. The training set contains 4,330 samples and there
are five unknown samples (both from the <code>Mutagen</code> data in the <code>QSARdata</code>
package).
</p>


<h3>Value</h3>

<table>
<tr><td><code>binary_tr</code>, <code>binary_ukn</code></td>
<td>
<p>data frame frames with 67 columns</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>data(qsar_binary)
str(binary_tr)
</code></pre>

<hr>
<h2 id='okc_binary'>OkCupid Binary Predictors</h2><span id='topic+okc_binary'></span><span id='topic+okc_binary_train'></span><span id='topic+okc_binary_test'></span>

<h3>Description</h3>

<p>OkCupid Binary Predictors
</p>


<h3>Details</h3>

<p>Data originally from Kim (2015) includes a training and test set
consistent with Kuhn and Johnson (2020). Predictors include ethnicity
indicators and a set of keywords derived from text essay data.
</p>


<h3>Value</h3>

<table>
<tr><td><code>okc_binary_train</code>, <code>okc_binary_test</code></td>
<td>
<p>data frame frames with 61 columns</p>
</td></tr>
</table>


<h3>Source</h3>

<p>Kim (2015), &quot;OkCupid Data for Introductory Statistics and Data Science Courses&quot;, <em>Journal of Statistics Education</em>, Volume 23, Number 2. <a href="https://www.tandfonline.com/doi/abs/10.1080/10691898.2015.11889737">https://www.tandfonline.com/doi/abs/10.1080/10691898.2015.11889737</a>
</p>
<p>Kuhn and Johnson (2020), <em>Feature Engineering and Selection</em>, Chapman and Hall/CRC . <a href="https://bookdown.org/max/FES/">https://bookdown.org/max/FES/</a> and <a href="https://github.com/topepo/FES">https://github.com/topepo/FES</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(okc_binary)
str(okc_binary_train)
</code></pre>

<hr>
<h2 id='print.apd_hat_values'>Print number of predictors and principal components used.</h2><span id='topic+print.apd_hat_values'></span>

<h3>Description</h3>

<p>Print number of predictors and principal components used.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'apd_hat_values'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.apd_hat_values_+3A_x">x</code></td>
<td>
<p>A <code>apd_hat_values</code> object.</p>
</td></tr>
<tr><td><code id="print.apd_hat_values_+3A_...">...</code></td>
<td>
<p>Not currently used, but required for extensibility.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
model &lt;- apd_hat_values(~ Sepal.Length + Sepal.Width, iris)
print(model)
</code></pre>

<hr>
<h2 id='print.apd_pca'>Print number of predictors and principal components used.</h2><span id='topic+print.apd_pca'></span>

<h3>Description</h3>

<p>Print number of predictors and principal components used.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'apd_pca'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.apd_pca_+3A_x">x</code></td>
<td>
<p>A <code>apd_pca</code> object.</p>
</td></tr>
<tr><td><code id="print.apd_pca_+3A_...">...</code></td>
<td>
<p>Not currently used, but required for extensibility.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
model &lt;- apd_pca(~ Sepal.Length + Sepal.Width, iris)
print(model)
</code></pre>

<hr>
<h2 id='print.apd_similarity'>Print number of predictors and principal components used.</h2><span id='topic+print.apd_similarity'></span>

<h3>Description</h3>

<p>Print number of predictors and principal components used.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'apd_similarity'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.apd_similarity_+3A_x">x</code></td>
<td>
<p>A <code>apd_similarity</code> object.</p>
</td></tr>
<tr><td><code id="print.apd_similarity_+3A_...">...</code></td>
<td>
<p>Not currently used, but required for extensibility.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(535)
tr_x &lt;- matrix(
  sample(0:1, size = 20 * 50, prob = rep(.5, 2), replace = TRUE),
  ncol = 20
 )
model &lt;- apd_similarity(tr_x)
print(model)
</code></pre>

<hr>
<h2 id='score'>A scoring function</h2><span id='topic+score'></span><span id='topic+score.default'></span>

<h3>Description</h3>

<p>A scoring function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>score(object, ...)

## Default S3 method:
score(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="score_+3A_object">object</code></td>
<td>
<p>Depending on the context:
</p>

<ul>
<li><p> A <strong>data frame</strong> of predictors.
</p>
</li>
<li><p> A <strong>matrix</strong> of predictors.
</p>
</li>
<li><p> A <strong>recipe</strong> specifying a set of preprocessing steps
created from <code><a href="recipes.html#topic+recipe">recipes::recipe()</a></code>.
</p>
</li></ul>
</td></tr>
<tr><td><code id="score_+3A_...">...</code></td>
<td>
<p>Not currently used, but required for extensibility.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tibble of predictions.
</p>

<hr>
<h2 id='score.apd_hat_values'>Score new samples using hat values</h2><span id='topic+score.apd_hat_values'></span>

<h3>Description</h3>

<p>Score new samples using hat values
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'apd_hat_values'
score(object, new_data, type = "numeric", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="score.apd_hat_values_+3A_object">object</code></td>
<td>
<p>A <code>apd_hat_values</code> object.</p>
</td></tr>
<tr><td><code id="score.apd_hat_values_+3A_new_data">new_data</code></td>
<td>
<p>A data frame or matrix of new predictors.</p>
</td></tr>
<tr><td><code id="score.apd_hat_values_+3A_type">type</code></td>
<td>
<p>A single character. The type of predictions to generate.
Valid options are:
</p>

<ul>
<li> <p><code>"numeric"</code> for a numeric value that summarizes the hat values for
each sample across the training set.
</p>
</li></ul>
</td></tr>
<tr><td><code id="score.apd_hat_values_+3A_...">...</code></td>
<td>
<p>Not used, but required for extensibility.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tibble of predictions. The number of rows in the tibble is guaranteed
to be the same as the number of rows in <code>new_data</code>. For <code>type = "numeric"</code>,
the tibble contains two columns <code>hat_values</code> and <code>hat_values_pctls</code>. The
column <code>hat_values_pctls</code> is in percent units so that a value of 11.5
indicates that, in the training set, 11.5 percent of the training set
samples had smaller values than the sample being scored.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>train_data &lt;- mtcars[1:20, ]
test_data &lt;- mtcars[21:32, ]

hat_values_model &lt;- apd_hat_values(train_data)

hat_values_scoring &lt;- score(hat_values_model, new_data = test_data)
hat_values_scoring
</code></pre>

<hr>
<h2 id='score.apd_isolation'>Predict from a <code>apd_isolation</code></h2><span id='topic+score.apd_isolation'></span>

<h3>Description</h3>

<p>Predict from a <code>apd_isolation</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'apd_isolation'
score(object, new_data, type = "numeric", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="score.apd_isolation_+3A_object">object</code></td>
<td>
<p>A <code>apd_isolation</code> object.</p>
</td></tr>
<tr><td><code id="score.apd_isolation_+3A_new_data">new_data</code></td>
<td>
<p>A data frame or matrix of new samples.</p>
</td></tr>
<tr><td><code id="score.apd_isolation_+3A_type">type</code></td>
<td>
<p>A single character. The type of predictions to generate.
Valid options are:
</p>

<ul>
<li> <p><code>"numeric"</code> for numeric predictions.
</p>
</li></ul>
</td></tr>
<tr><td><code id="score.apd_isolation_+3A_...">...</code></td>
<td>
<p>Not used, but required for extensibility.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>About the score
</p>


<h3>Value</h3>

<p>A tibble of predictions. The number of rows in the tibble is guaranteed
to be the same as the number of rows in <code>new_data</code>. The <code>score</code> column is the
raw prediction from <code><a href="isotree.html#topic+predict.isolation_forest">isotree::predict.isolation_forest()</a></code> while <code>score_pctl</code>
compares this value to the reference distribution of the score created by
predicting the training set. A value of <em>X</em> means that <em>X</em> percent of the
training data have scores less than the predicted value.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+apd_isolation">apd_isolation()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
if (rlang::is_installed(c("isotree", "modeldata"))) {
  library(dplyr)

  data(cells, package = "modeldata")

  cells_tr &lt;- cells %&gt;% filter(case == "Train") %&gt;% select(-case, -class)
  cells_te &lt;- cells %&gt;% filter(case != "Train") %&gt;% select(-case, -class)

  if_mod &lt;- apd_isolation(cells_tr, ntrees = 10, nthreads = 1)
  score(if_mod, cells_te)
}

</code></pre>

<hr>
<h2 id='score.apd_pca'>Predict from a <code>apd_pca</code></h2><span id='topic+score.apd_pca'></span>

<h3>Description</h3>

<p>Predict from a <code>apd_pca</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'apd_pca'
score(object, new_data, type = "numeric", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="score.apd_pca_+3A_object">object</code></td>
<td>
<p>A <code>apd_pca</code> object.</p>
</td></tr>
<tr><td><code id="score.apd_pca_+3A_new_data">new_data</code></td>
<td>
<p>A data frame or matrix of new samples.</p>
</td></tr>
<tr><td><code id="score.apd_pca_+3A_type">type</code></td>
<td>
<p>A single character. The type of predictions to generate.
Valid options are:
</p>

<ul>
<li> <p><code>"numeric"</code> for numeric predictions.
</p>
</li></ul>
</td></tr>
<tr><td><code id="score.apd_pca_+3A_...">...</code></td>
<td>
<p>Not used, but required for extensibility.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function computes the principal components of the new data and
their percentiles as compared to the training data. The number of principal
components computed depends on the <code>threshold</code> given at fit time. It also
computes the multivariate distance between each principal component and its
mean.
</p>


<h3>Value</h3>

<p>A tibble of predictions. The number of rows in the tibble is guaranteed
to be the same as the number of rows in <code>new_data</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>train &lt;- mtcars[1:20, ]
test &lt;- mtcars[21:32, -1]

# Fit
mod &lt;- apd_pca(mpg ~ cyl + log(drat), train)

# Predict, with preprocessing
score(mod, test)
</code></pre>

<hr>
<h2 id='score.apd_similarity'>Score new samples using similarity methods</h2><span id='topic+score.apd_similarity'></span>

<h3>Description</h3>

<p>Score new samples using similarity methods
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'apd_similarity'
score(object, new_data, type = "numeric", add_percentile = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="score.apd_similarity_+3A_object">object</code></td>
<td>
<p>A <code>apd_similarity</code> object.</p>
</td></tr>
<tr><td><code id="score.apd_similarity_+3A_new_data">new_data</code></td>
<td>
<p>A data frame or matrix of new predictors.</p>
</td></tr>
<tr><td><code id="score.apd_similarity_+3A_type">type</code></td>
<td>
<p>A single character. The type of predictions to generate.
Valid options are:
</p>

<ul>
<li> <p><code>"numeric"</code> for a numeric value that summarizes the similarity values for
each sample across the training set.
</p>
</li></ul>
</td></tr>
<tr><td><code id="score.apd_similarity_+3A_add_percentile">add_percentile</code></td>
<td>
<p>A single logical; should the percentile of the
similarity score <em>relative to the training set values</em> by computed?</p>
</td></tr>
<tr><td><code id="score.apd_similarity_+3A_...">...</code></td>
<td>
<p>Not used, but required for extensibility.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tibble of predictions. The number of rows in the tibble is guaranteed
to be the same as the number of rows in <code>new_data</code>. For <code>type = "numeric"</code>,
the tibble contains a column called &quot;similarity&quot;. If <code>add_percentile = TRUE</code>,
an additional column called <code>similarity_pctl</code> will be added. These values are
in percent units so that a value of 11.5 indicates that, in the training set,
11.5 percent of the training set samples had smaller values than the sample
being scored.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(qsar_binary)

jacc_sim &lt;- apd_similarity(binary_tr)

mean_sim &lt;- score(jacc_sim, new_data = binary_unk)
mean_sim

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
