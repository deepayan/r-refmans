<!DOCTYPE html><html lang="en"><head><title>Help for package ruimtehol</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {ruimtehol}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#dekamer'><p>Dataset from 2017 with Questions and Answers in the Belgium Federal Parliament</p></a></li>
<li><a href='#dekamer_theme_terminology'><p>Dataset containing relevant terminology for each theme of the <code>dekamer</code> dataset</p></a></li>
<li><a href='#embed_articlespace'><p>Build a Starspace model for learning the mapping between sentences and articles (articlespace)</p></a></li>
<li><a href='#embed_docspace'><p>Build a Starspace model for content-based recommendation</p></a></li>
<li><a href='#embed_entityrelationspace'><p>Build a Starspace model for entity relationship completion</p></a></li>
<li><a href='#embed_pagespace'><p>Build a Starspace model for interest-based recommendation</p></a></li>
<li><a href='#embed_sentencespace'><p>Build a Starspace model to be used for sentence embedding</p></a></li>
<li><a href='#embed_tagspace'><p>Build a Starspace model to be used for classification purposes</p></a></li>
<li><a href='#embed_wordspace'><p>Build a Starspace model which calculates word embeddings</p></a></li>
<li><a href='#embedding_similarity'><p>Cosine and Inner product based similarity</p></a></li>
<li><a href='#predict.textspace'><p>Predict using a Starspace model</p></a></li>
<li><a href='#range.textspace'><p>Get the scale of embedding similarities alongside a Starspace model</p></a></li>
<li><a href='#starspace'><p>Interface to Starspace for training a Starspace model</p></a></li>
<li><a href='#starspace_dictionary'><p>Get the dictionary of a Starspace model</p></a></li>
<li><a href='#starspace_embedding'><p>Get the document or ngram embeddings</p></a></li>
<li><a href='#starspace_knn'><p>K-nearest neighbours using a Starspace model</p></a></li>
<li><a href='#starspace_load_model'><p>Load a Starspace model</p></a></li>
<li><a href='#starspace_save_model'><p>Save a starspace model as a binary or tab-delimited TSV file</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Learn Text 'Embeddings' with 'Starspace'</td>
</tr>
<tr>
<td>Version:</td>
<td>0.3.2</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Jan Wijffels &lt;jwijffels@bnosac.be&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Wraps the 'StarSpace' library <a href="https://github.com/facebookresearch/StarSpace">https://github.com/facebookresearch/StarSpace</a> 
    allowing users to calculate word, sentence, article, document, webpage, link and entity 'embeddings'. 
    By using the 'embeddings', you can perform text based multi-label classification, 
    find similarities between texts and categories, do collaborative-filtering based recommendation 
    as well as content-based recommendation, find out relations between entities, calculate 
    graph 'embeddings' as well as perform semi-supervised learning and multi-task learning on plain text. 
    The techniques are explained in detail in the paper: 'StarSpace: Embed All The Things!' by Wu et al. (2017), available at &lt;<a href="https://doi.org/10.48550/arXiv.1709.03856">doi:10.48550/arXiv.1709.03856</a>&gt;.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.mozilla.org/en-US/MPL/2.0/">MPL-2.0</a></td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/bnosac/ruimtehol">https://github.com/bnosac/ruimtehol</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 2.10)</td>
</tr>
<tr>
<td>Imports:</td>
<td>Rcpp (&ge; 0.11.5), utils, graphics, stats</td>
</tr>
<tr>
<td>Suggests:</td>
<td>udpipe, data.table</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp, BH</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.2</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-02-22 22:13:52 UTC; jwijffels</td>
</tr>
<tr>
<td>Author:</td>
<td>Jan Wijffels [aut, cre, cph] (R wrapper),
  BNOSAC [cph] (R wrapper),
  Facebook, Inc. [cph] (Starspace (BSD licensed))</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-02-22 22:50:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='dekamer'>Dataset from 2017 with Questions and Answers in the Belgium Federal Parliament</h2><span id='topic+dekamer'></span>

<h3>Description</h3>

<p>Dataset from 2017 with Questions asked by members of the Belgian Federal Parliament 
and the Answers provided to these questions.<br />
The dataset was extracted from <a href="http://data.dekamer.be">http://data.dekamer.be</a> and contains questions asked by persons in the Belgium Federal parliament
and answers given by the departments of the Federal Belgian Ministers. <br />
The language of this dataset provided in this R package has been restricted to Dutch. <br />
</p>
<p>The dataset contains the following information: 
</p>

<ul>
<li><p> doc_id: a unique identifier
</p>
</li>
<li><p> depotdat: the date when the question was registered
</p>
</li>
<li><p> aut_party / aut_person / aut_language: who asked the question and which political party is he/she a member of + the language of the person who asked the question
</p>
</li>
<li><p> question: the question itself (always in Dutch)
</p>
</li>
<li><p> question_theme_main: the main theme of the question
</p>
</li>
<li><p> question_theme: a comma-separated list of all themes the question is about
</p>
</li>
<li><p> answer: the answer given by the department of the minister (always in Dutch)
</p>
</li>
<li><p> answer_deptpres, answer_department, answer_subdepartment: to which ministerial department has the question been raised to and answered by
</p>
</li></ul>



<h3>Source</h3>

<p><a href="http://data.dekamer.be">http://data.dekamer.be</a>, data is provided by www.dekamer.be in the public domain (CC0).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(dekamer)
str(dekamer)
</code></pre>

<hr>
<h2 id='dekamer_theme_terminology'>Dataset containing relevant terminology for each theme of the <code>dekamer</code> dataset</h2><span id='topic+dekamer_theme_terminology'></span>

<h3>Description</h3>

<p>Dataset containing relevant terminology for each theme of the <code><a href="#topic+dekamer">dekamer</a></code> dataset
</p>
<p>The dataset contains the following information: 
</p>

<ul>
<li><p> theme: a theme, corresponding to the <code>question_theme_main</code> field in the <code><a href="#topic+dekamer">dekamer</a></code> dataset
</p>
</li>
<li><p> term: a word which describes the <code>theme</code>
</p>
</li>
<li><p> n: a measure of information indicating how relevant the term is (frequency of occurrence)
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>data(dekamer_theme_terminology)
str(dekamer_theme_terminology)
</code></pre>

<hr>
<h2 id='embed_articlespace'>Build a Starspace model for learning the mapping between sentences and articles (articlespace)</h2><span id='topic+embed_articlespace'></span>

<h3>Description</h3>

<p>Build a Starspace model for learning the mapping between sentences and articles (articlespace)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>embed_articlespace(
  x,
  model = "articlespace.bin",
  early_stopping = 0.75,
  useBytes = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="embed_articlespace_+3A_x">x</code></td>
<td>
<p>a data.frame with sentences containing the columns doc_id, sentence_id and token
The doc_id is just an article or document identifier,
the sentence_id column is a character field which contains words which are separated by a space and should not contain any tab characters</p>
</td></tr>
<tr><td><code id="embed_articlespace_+3A_model">model</code></td>
<td>
<p>name of the model which will be saved, passed on to <code><a href="#topic+starspace">starspace</a></code></p>
</td></tr>
<tr><td><code id="embed_articlespace_+3A_early_stopping">early_stopping</code></td>
<td>
<p>the percentage of the data that will be used as training data. If set to a value smaller than 1, 1-<code>early_stopping</code> percentage of the data which will be used as the validation set and early stopping will be executed. Defaults to 0.75.</p>
</td></tr>
<tr><td><code id="embed_articlespace_+3A_usebytes">useBytes</code></td>
<td>
<p>set to TRUE to avoid re-encoding when writing out train and/or test files. See <code><a href="base.html#topic+writeLines">writeLines</a></code> for details</p>
</td></tr>
<tr><td><code id="embed_articlespace_+3A_...">...</code></td>
<td>
<p>further arguments passed on to <code><a href="#topic+starspace">starspace</a></code> except file, trainMode and fileFormat</p>
</td></tr>
</table>


<h3>Value</h3>

<p>an object of class <code>textspace</code> as returned by <code><a href="#topic+starspace">starspace</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(udpipe)
data(brussels_reviews_anno, package = "udpipe")
x &lt;- subset(brussels_reviews_anno, language == "nl")
x$token &lt;- x$lemma
x &lt;- x[, c("doc_id", "sentence_id", "token")]
set.seed(123456789)
model &lt;- embed_articlespace(x, early_stopping = 1,
                            dim = 25, epoch = 25, minCount = 2,
                            negSearchLimit = 1, maxNegSamples = 2)
plot(model)
sentences &lt;- c("ook de keuken zijn zeer goed uitgerust .",
               "het appartement zijn met veel smaak inrichten en zeer proper .")
predict(model, sentences, type = "embedding")
starspace_embedding(model, sentences)

## Not run: 
library(udpipe)
data(dekamer, package = "ruimtehol")
dekamer &lt;- subset(dekamer, question_theme_main == "DEFENSIEBELEID")
x &lt;- udpipe(dekamer$question, "dutch", tagger = "none", parser = "none", trace = 100)
x &lt;- x[, c("doc_id", "sentence_id", "sentence", "token")]
set.seed(123456789)
model &lt;- embed_articlespace(x, early_stopping = 0.8, dim = 15, epoch = 5, minCount = 5)
plot(model)

embeddings &lt;- starspace_embedding(model, unique(x$sentence), type = "document")
dim(embeddings)

sentence &lt;- "Wat zijn de cijfers qua doorstroming van 2016?"
embedding_sentence &lt;- starspace_embedding(model, sentence, type = "document")
mostsimilar &lt;- embedding_similarity(embeddings, embedding_sentence)
head(sort(mostsimilar[, 1], decreasing = TRUE), 3)

## clean up for cran
file.remove(list.files(pattern = ".udpipe$"))

## End(Not run)
</code></pre>

<hr>
<h2 id='embed_docspace'>Build a Starspace model for content-based recommendation</h2><span id='topic+embed_docspace'></span>

<h3>Description</h3>

<p>Build a Starspace model for content-based recommendation (docspace). For example a user clicks on a webpage and this webpage contains a bunch or words.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>embed_docspace(
  x,
  model = "docspace.bin",
  early_stopping = 0.75,
  useBytes = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="embed_docspace_+3A_x">x</code></td>
<td>
<p>a data.frame with user interest containing the columns user_id, doc_id and text
The user_id is an identifier of a user
The doc_id is just an article or document identifier
the text column is a character field which contains words which are part of the doc_id, words should be separated by a space and
should not contain any tab characters</p>
</td></tr>
<tr><td><code id="embed_docspace_+3A_model">model</code></td>
<td>
<p>name of the model which will be saved, passed on to <code><a href="#topic+starspace">starspace</a></code></p>
</td></tr>
<tr><td><code id="embed_docspace_+3A_early_stopping">early_stopping</code></td>
<td>
<p>the percentage of the data that will be used as training data. If set to a value smaller than 1, 1-<code>early_stopping</code> percentage of the data which will be used as the validation set and early stopping will be executed. Defaults to 0.75.</p>
</td></tr>
<tr><td><code id="embed_docspace_+3A_usebytes">useBytes</code></td>
<td>
<p>set to TRUE to avoid re-encoding when writing out train and/or test files. See <code><a href="base.html#topic+writeLines">writeLines</a></code> for details</p>
</td></tr>
<tr><td><code id="embed_docspace_+3A_...">...</code></td>
<td>
<p>further arguments passed on to <code><a href="#topic+starspace">starspace</a></code> except file, trainMode and fileFormat</p>
</td></tr>
</table>


<h3>Value</h3>

<p>an object of class <code>textspace</code> as returned by <code><a href="#topic+starspace">starspace</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(udpipe)
data(dekamer, package = "ruimtehol")
data(dekamer_theme_terminology, package = "ruimtehol")
## Which person is interested in which theme (aka document)
x &lt;- table(dekamer$aut_person, dekamer$question_theme_main)
x &lt;- as.data.frame(x)
colnames(x) &lt;- c("user_id", "doc_id", "freq")
## Characterise the themes (aka document)
docs &lt;- split(dekamer_theme_terminology, dekamer_theme_terminology$theme)
docs &lt;- lapply(docs, FUN=function(x){
  data.frame(theme = x$theme[1], text = paste(x$term, collapse = " "),
             stringsAsFactors=FALSE)
})
docs &lt;- do.call(rbind, docs)

## Build a model
train &lt;- merge(x, docs, by.x = "doc_id", by.y = "theme")
train &lt;- subset(train, user_id %in% sample(levels(train$user_id), 4))
set.seed(123456789)
model &lt;- embed_docspace(train, dim = 10, early_stopping = 1)
plot(model)
</code></pre>

<hr>
<h2 id='embed_entityrelationspace'>Build a Starspace model for entity relationship completion</h2><span id='topic+embed_entityrelationspace'></span>

<h3>Description</h3>

<p>Build a Starspace model for entity relationship completion (graphspace).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>embed_entityrelationspace(
  x,
  model = "graphspace.bin",
  early_stopping = 0.75,
  useBytes = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="embed_entityrelationspace_+3A_x">x</code></td>
<td>
<p>a data.frame with columns entity_head, entity_tail and relation indicating the relation between the head and tail entity</p>
</td></tr>
<tr><td><code id="embed_entityrelationspace_+3A_model">model</code></td>
<td>
<p>name of the model which will be saved, passed on to <code><a href="#topic+starspace">starspace</a></code></p>
</td></tr>
<tr><td><code id="embed_entityrelationspace_+3A_early_stopping">early_stopping</code></td>
<td>
<p>the percentage of the data that will be used as training data. If set to a value smaller than 1, 1-<code>early_stopping</code> percentage of the data which will be used as the validation set and early stopping will be executed. Defaults to 0.75.</p>
</td></tr>
<tr><td><code id="embed_entityrelationspace_+3A_usebytes">useBytes</code></td>
<td>
<p>set to TRUE to avoid re-encoding when writing out train and/or test files. See <code><a href="base.html#topic+writeLines">writeLines</a></code> for details</p>
</td></tr>
<tr><td><code id="embed_entityrelationspace_+3A_...">...</code></td>
<td>
<p>further arguments passed on to <code><a href="#topic+starspace">starspace</a></code> except file, trainMode and fileFormat</p>
</td></tr>
</table>


<h3>Value</h3>

<p>an object of class <code>textspace</code> as returned by <code><a href="#topic+starspace">starspace</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Example on Freebase - download the data
filename &lt;- paste(
  "https://raw.githubusercontent.com/bnosac-dev/GraphEmbeddings/master/",
  "diffbot_data/FB15k/freebase_mtr100_mte100-train.txt",
  sep = "")
tmpfile &lt;- tempfile(pattern = "freebase_mtr100_mte100_", fileext = "txt")
ok &lt;- suppressWarnings(try(
  download.file(url = filename, destfile = tmpfile),
  silent = TRUE))
if(!inherits(ok, "try-error") &amp;&amp; ok == 0){
  ## Build the model on the downloaded data
  x &lt;- read.delim(tmpfile, header = FALSE, nrows = 1000,
                  col.names = c("entity_head", "relation", "entity_tail"),
                  stringsAsFactors = FALSE)
  head(x)

  set.seed(123456789)
  model &lt;- embed_entityrelationspace(x, dim = 50)
  plot(model)

  predict(model, "/m/027rn /location/country/form_of_government")

  ## Also add reverse relation
  x_reverse &lt;- x
  colnames(x_reverse) &lt;- c("entity_tail", "relation", "entity_head")
  x_reverse$relation &lt;- sprintf("REVERSE_%s", x_reverse$relation)

  relations &lt;- rbind(x, x_reverse)
  set.seed(123456789)
  model &lt;- embed_entityrelationspace(relations, dim = 50)
  predict(model, "/m/027rn /location/country/form_of_government")
  predict(model, "/m/06cx9 REVERSE_/location/country/form_of_government")
}

## cleanup for cran
if(file.exists(tmpfile)) file.remove(tmpfile)
</code></pre>

<hr>
<h2 id='embed_pagespace'>Build a Starspace model for interest-based recommendation</h2><span id='topic+embed_pagespace'></span>

<h3>Description</h3>

<p>Build a Starspace model for interest-based recommendation (pagespace). For example a user clicks on a webpage.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>embed_pagespace(
  x,
  model = "pagespace.bin",
  early_stopping = 0.75,
  useBytes = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="embed_pagespace_+3A_x">x</code></td>
<td>
<p>a list where each list element contains a character vector of pages which the user was interested in</p>
</td></tr>
<tr><td><code id="embed_pagespace_+3A_model">model</code></td>
<td>
<p>name of the model which will be saved, passed on to <code><a href="#topic+starspace">starspace</a></code></p>
</td></tr>
<tr><td><code id="embed_pagespace_+3A_early_stopping">early_stopping</code></td>
<td>
<p>the percentage of the data that will be used as training data. If set to a value smaller than 1, 1-<code>early_stopping</code> percentage of the data which will be used as the validation set and early stopping will be executed. Defaults to 0.75.</p>
</td></tr>
<tr><td><code id="embed_pagespace_+3A_usebytes">useBytes</code></td>
<td>
<p>set to TRUE to avoid re-encoding when writing out train and/or test files. See <code><a href="base.html#topic+writeLines">writeLines</a></code> for details</p>
</td></tr>
<tr><td><code id="embed_pagespace_+3A_...">...</code></td>
<td>
<p>further arguments passed on to <code><a href="#topic+starspace">starspace</a></code> except file, trainMode and fileFormat</p>
</td></tr>
</table>


<h3>Value</h3>

<p>an object of class <code>textspace</code> as returned by <code><a href="#topic+starspace">starspace</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(dekamer, package = "ruimtehol")
x &lt;- subset(dekamer, !is.na(question_theme))
x &lt;- strsplit(x$question_theme, ",")
x &lt;- lapply(x, FUN=unique)
str(x)
set.seed(123456789)
model &lt;- embed_pagespace(x, dim = 5, epoch = 5, minCount = 10, label = "__THEME__")
plot(model)
predict(model, "__THEME__MARINE __THEME__DEFENSIEBELEID")

pagevectors &lt;- as.matrix(model)

mostsimilar &lt;- embedding_similarity(pagevectors,
                                    pagevectors["__THEME__MIGRATIEBELEID", ])
head(sort(mostsimilar[, 1], decreasing = TRUE), 3)
mostsimilar &lt;- embedding_similarity(pagevectors,
                                    pagevectors["__THEME__DEFENSIEBELEID", ])
head(sort(mostsimilar[, 1], decreasing = TRUE), 3)
</code></pre>

<hr>
<h2 id='embed_sentencespace'>Build a Starspace model to be used for sentence embedding</h2><span id='topic+embed_sentencespace'></span>

<h3>Description</h3>

<p>Build a Starspace model to be used for sentence embedding
</p>


<h3>Usage</h3>

<pre><code class='language-R'>embed_sentencespace(
  x,
  model = "sentencespace.bin",
  early_stopping = 0.75,
  useBytes = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="embed_sentencespace_+3A_x">x</code></td>
<td>
<p>a data.frame with sentences containg the columns doc_id, sentence_id and token
The doc_id is just an article or document identifier,
the sentence_id column is a character field which contains words which are separated by a space and should not contain any tab characters</p>
</td></tr>
<tr><td><code id="embed_sentencespace_+3A_model">model</code></td>
<td>
<p>name of the model which will be saved, passed on to <code><a href="#topic+starspace">starspace</a></code></p>
</td></tr>
<tr><td><code id="embed_sentencespace_+3A_early_stopping">early_stopping</code></td>
<td>
<p>the percentage of the data that will be used as training data. If set to a value smaller than 1, 1-<code>early_stopping</code> percentage of the data which will be used as the validation set and early stopping will be executed. Defaults to 0.75.</p>
</td></tr>
<tr><td><code id="embed_sentencespace_+3A_usebytes">useBytes</code></td>
<td>
<p>set to TRUE to avoid re-encoding when writing out train and/or test files. See <code><a href="base.html#topic+writeLines">writeLines</a></code> for details</p>
</td></tr>
<tr><td><code id="embed_sentencespace_+3A_...">...</code></td>
<td>
<p>further arguments passed on to <code><a href="#topic+starspace">starspace</a></code> except file, trainMode and fileFormat</p>
</td></tr>
</table>


<h3>Value</h3>

<p>an object of class <code>textspace</code> as returned by <code><a href="#topic+starspace">starspace</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(udpipe)
data(brussels_reviews_anno, package = "udpipe")
x &lt;- subset(brussels_reviews_anno, language == "nl")
x$token &lt;- x$lemma
x &lt;- x[, c("doc_id", "sentence_id", "token")]
set.seed(123456789)
model &lt;- embed_sentencespace(x, dim = 15, epoch = 15,
                             negSearchLimit = 1, maxNegSamples = 2)
plot(model)
sentences &lt;- c("ook de keuken zijn zeer goed uitgerust .",
               "het appartement zijn met veel smaak inrichten en zeer proper .")
predict(model, sentences, type = "embedding")
starspace_embedding(model, sentences)

## Not run: 
library(udpipe)
data(dekamer, package = "ruimtehol")
x &lt;- udpipe(dekamer$question, "dutch", tagger = "none", parser = "none", trace = 100)
x &lt;- x[, c("doc_id", "sentence_id", "sentence", "token")]
set.seed(123456789)
model &lt;- embed_sentencespace(x, dim = 15, epoch = 5, minCount = 5)
plot(model)
predict(model, "Wat zijn de cijfers qua doorstroming van 2016?",
        basedoc = unique(x$sentence))

embeddings &lt;- starspace_embedding(model, unique(x$sentence), type = "document")
dim(embeddings)

sentence &lt;- "Wat zijn de cijfers qua doorstroming van 2016?"
embedding_sentence &lt;- starspace_embedding(model, sentence, type = "document")
mostsimilar &lt;- embedding_similarity(embeddings, embedding_sentence)
head(sort(mostsimilar[, 1], decreasing = TRUE), 3)

## clean up for cran
file.remove(list.files(pattern = ".udpipe$"))

## End(Not run)
</code></pre>

<hr>
<h2 id='embed_tagspace'>Build a Starspace model to be used for classification purposes</h2><span id='topic+embed_tagspace'></span>

<h3>Description</h3>

<p>Build a Starspace model to be used for classification purposes
</p>


<h3>Usage</h3>

<pre><code class='language-R'>embed_tagspace(
  x,
  y,
  model = "tagspace.bin",
  early_stopping = 0.75,
  useBytes = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="embed_tagspace_+3A_x">x</code></td>
<td>
<p>a character vector of text where tokens are separated by spaces</p>
</td></tr>
<tr><td><code id="embed_tagspace_+3A_y">y</code></td>
<td>
<p>a character vector of classes to predict or a list with the same length of <code>x</code> with several classes for each respective element of <code>x</code></p>
</td></tr>
<tr><td><code id="embed_tagspace_+3A_model">model</code></td>
<td>
<p>name of the model which will be saved, passed on to <code><a href="#topic+starspace">starspace</a></code></p>
</td></tr>
<tr><td><code id="embed_tagspace_+3A_early_stopping">early_stopping</code></td>
<td>
<p>the percentage of the data that will be used as training data. If set to a value smaller than 1, 1-<code>early_stopping</code> percentage of the data which will be used as the validation set and early stopping will be executed. Defaults to 0.75.</p>
</td></tr>
<tr><td><code id="embed_tagspace_+3A_usebytes">useBytes</code></td>
<td>
<p>set to TRUE to avoid re-encoding when writing out train and/or test files. See <code><a href="base.html#topic+writeLines">writeLines</a></code> for details</p>
</td></tr>
<tr><td><code id="embed_tagspace_+3A_...">...</code></td>
<td>
<p>further arguments passed on to <code><a href="#topic+starspace">starspace</a></code> except file, trainMode and fileFormat</p>
</td></tr>
</table>


<h3>Value</h3>

<p>an object of class <code>textspace</code> as returned by <code><a href="#topic+starspace">starspace</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(dekamer, package = "ruimtehol")
dekamer &lt;- subset(dekamer, depotdat &lt; as.Date("2017-02-01"))
dekamer$text &lt;- strsplit(dekamer$question, "\\W")
dekamer$text &lt;- lapply(dekamer$text, FUN = function(x) x[x != ""])
dekamer$text &lt;- sapply(dekamer$text,
                       FUN = function(x) paste(x, collapse = " "))
dekamer$question_theme_main &lt;- gsub(" ", "-", dekamer$question_theme_main)

set.seed(123456789)
model &lt;- embed_tagspace(x = tolower(dekamer$text),
                        y = dekamer$question_theme_main,
                        early_stopping = 0.8,
                        dim = 10, minCount = 5)
plot(model)
predict(model, "de nmbs heeft het treinaanbod uitgebreid", k = 3)
predict(model, "de migranten komen naar europa, in asielcentra ...")
starspace_embedding(model, "de nmbs heeft het treinaanbod uitgebreid")
starspace_embedding(model, "__label__MIGRATIEBELEID", type = "ngram")

dekamer$question_themes &lt;- gsub(" ", "-", dekamer$question_theme)
dekamer$question_themes &lt;- strsplit(dekamer$question_themes, split = ",")
set.seed(123456789)
model &lt;- embed_tagspace(x = tolower(dekamer$text),
                        y = dekamer$question_themes,
                        early_stopping = 0.8,
                        dim = 50, minCount = 2, epoch = 50)
plot(model)
predict(model, "de nmbs heeft het treinaanbod uitgebreid")
predict(model, "de migranten komen naar europa , in asielcentra ...")
embeddings_labels &lt;- as.matrix(model, type = "labels")
emb &lt;- starspace_embedding(model, "de nmbs heeft het treinaanbod uitgebreid")
embedding_similarity(emb, embeddings_labels, type = "cosine", top_n = 5)
</code></pre>

<hr>
<h2 id='embed_wordspace'>Build a Starspace model which calculates word embeddings</h2><span id='topic+embed_wordspace'></span>

<h3>Description</h3>

<p>Build a Starspace model which calculates word embeddings
</p>


<h3>Usage</h3>

<pre><code class='language-R'>embed_wordspace(
  x,
  model = "wordspace.bin",
  early_stopping = 0.75,
  useBytes = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="embed_wordspace_+3A_x">x</code></td>
<td>
<p>a character vector of text where tokens are separated by spaces</p>
</td></tr>
<tr><td><code id="embed_wordspace_+3A_model">model</code></td>
<td>
<p>name of the model which will be saved, passed on to <code><a href="#topic+starspace">starspace</a></code></p>
</td></tr>
<tr><td><code id="embed_wordspace_+3A_early_stopping">early_stopping</code></td>
<td>
<p>the percentage of the data that will be used as training data. If set to a value smaller than 1, 1-<code>early_stopping</code> percentage of the data which will be used as the validation set and early stopping will be executed. Defaults to 0.75.</p>
</td></tr>
<tr><td><code id="embed_wordspace_+3A_usebytes">useBytes</code></td>
<td>
<p>set to TRUE to avoid re-encoding when writing out train and/or test files. See <code><a href="base.html#topic+writeLines">writeLines</a></code> for details</p>
</td></tr>
<tr><td><code id="embed_wordspace_+3A_...">...</code></td>
<td>
<p>further arguments passed on to <code><a href="#topic+starspace">starspace</a></code> except file, trainMode and fileFormat</p>
</td></tr>
</table>


<h3>Value</h3>

<p>an object of class <code>textspace</code> as returned by <code><a href="#topic+starspace">starspace</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(udpipe)
data(brussels_reviews, package = "udpipe")
x &lt;- subset(brussels_reviews, language == "nl")
x &lt;- strsplit(x$feedback, "\\W")
x &lt;- lapply(x, FUN = function(x) x[x != ""])
x &lt;- sapply(x, FUN = function(x) paste(x, collapse = " "))
x &lt;- tolower(x)

set.seed(123456789)
model &lt;- embed_wordspace(x, early_stopping = 0.9,
                         dim = 15, ws = 7, epoch = 10, minCount = 5, ngrams = 1,
                         maxTrainTime = 2) ## maxTrainTime only set for CRAN
plot(model)
wordvectors &lt;- as.matrix(model)

mostsimilar &lt;- embedding_similarity(wordvectors, wordvectors["weekend", ])
head(sort(mostsimilar[, 1], decreasing = TRUE), 10)
mostsimilar &lt;- embedding_similarity(wordvectors, wordvectors["vriendelijk", ])
head(sort(mostsimilar[, 1], decreasing = TRUE), 10)
mostsimilar &lt;- embedding_similarity(wordvectors, wordvectors["grote", ])
head(sort(mostsimilar[, 1], decreasing = TRUE), 10)

</code></pre>

<hr>
<h2 id='embedding_similarity'>Cosine and Inner product based similarity</h2><span id='topic+embedding_similarity'></span>

<h3>Description</h3>

<p>Cosine and Inner product based similarity
</p>


<h3>Usage</h3>

<pre><code class='language-R'>embedding_similarity(x, y, type = c("cosine", "dot"), top_n = +Inf)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="embedding_similarity_+3A_x">x</code></td>
<td>
<p>a matrix with embeddings providing embeddings for words/n-grams/documents/labels as indicated in the rownames of the matrix</p>
</td></tr>
<tr><td><code id="embedding_similarity_+3A_y">y</code></td>
<td>
<p>a matrix with embeddings providing embeddings for words/n-grams/documents/labels as indicated in the rownames of the matrix</p>
</td></tr>
<tr><td><code id="embedding_similarity_+3A_type">type</code></td>
<td>
<p>either 'cosine' or 'dot'. If 'dot', returns inner-product based similarity, if 'cosine', returns cosine similarity</p>
</td></tr>
<tr><td><code id="embedding_similarity_+3A_top_n">top_n</code></td>
<td>
<p>integer indicating to return only the top n most similar terms from <code>y</code> for each row of <code>x</code>.
If <code>top_n</code> is supplied, a data.frame will be returned with only the highest similarities between <code>x</code> and <code>y</code> instead of all pairwise similarities</p>
</td></tr>
</table>


<h3>Value</h3>

<p>By default, the function returns a similarity matrix between the rows of <code>x</code> and the rows of <code>y</code>. 
The similarity between row i of <code>x</code> and row j of <code>y</code> is found in cell <code>[i, j]</code> of the returned similarity matrix.<br />
If <code>top_n</code> is provided, the return value is a data.frame with columns term1, term2, similarity and rank 
indicating the similarity between the provided terms in <code>x</code> and <code>y</code> 
ordered from high to low similarity and keeping only the top_n most similar records.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- matrix(rnorm(6), nrow = 2, ncol = 3)
rownames(x) &lt;- c("word1", "word2")
y &lt;- matrix(rnorm(15), nrow = 5, ncol = 3)
rownames(y) &lt;- c("term1", "term2", "term3", "term4", "term5")

embedding_similarity(x, y, type = "cosine")
embedding_similarity(x, y, type = "dot")
embedding_similarity(x, y, type = "cosine", top_n = 1)
embedding_similarity(x, y, type = "dot", top_n = 1)
embedding_similarity(x, y, type = "cosine", top_n = 2)
embedding_similarity(x, y, type = "dot", top_n = 2)
embedding_similarity(x, y, type = "cosine", top_n = +Inf)
embedding_similarity(x, y, type = "dot", top_n = +Inf)
</code></pre>

<hr>
<h2 id='predict.textspace'>Predict using a Starspace model</h2><span id='topic+predict.textspace'></span>

<h3>Description</h3>

<p>The prediction functionality allows you to retrieve the following types of elements from a Starspace model:
</p>

<ul>
<li> <p><code>generic</code>: get general Starspace predictions in detail
</p>
</li>
<li> <p><code>labels</code>: get similarity of your text to all the labels of the Starspace model
</p>
</li>
<li> <p><code>embedding</code>: document embeddings of your text (shorthand for <code><a href="#topic+starspace_embedding">starspace_embedding</a></code>)
</p>
</li>
<li> <p><code>knn</code>: k-nearest neighbouring (most similar) elements of the model dictionary compared to your input text (shorthand for <code><a href="#topic+starspace_knn">starspace_knn</a></code>)
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'textspace'
predict(
  object,
  newdata,
  type = c("generic", "labels", "knn", "embedding"),
  k = 5L,
  sep = " ",
  basedoc,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict.textspace_+3A_object">object</code></td>
<td>
<p>an object of class <code>textspace</code> as returned by <code><a href="#topic+starspace">starspace</a></code> or <code><a href="#topic+starspace_load_model">starspace_load_model</a></code></p>
</td></tr>
<tr><td><code id="predict.textspace_+3A_newdata">newdata</code></td>
<td>
<p>a data frame with columns <code>doc_id</code> and <code>text</code> or a character vector with text where the names of the character vector represent an identifier of that text</p>
</td></tr>
<tr><td><code id="predict.textspace_+3A_type">type</code></td>
<td>
<p>character string: either 'generic', 'labels', 'embedding', 'knn'. Defaults to 'generic'</p>
</td></tr>
<tr><td><code id="predict.textspace_+3A_k">k</code></td>
<td>
<p>integer with the number of predictions to make. Defaults to 5. Only used in case <code>type</code> is set to <code>'generic'</code> or <code>'knn'</code></p>
</td></tr>
<tr><td><code id="predict.textspace_+3A_sep">sep</code></td>
<td>
<p>character string used to split <code>newdata</code> using boost::split. Only used in case <code>type</code> is set to <code>'generic'</code></p>
</td></tr>
<tr><td><code id="predict.textspace_+3A_basedoc">basedoc</code></td>
<td>
<p>optional, either a character vector of possible elements to predict or 
the path to a file in labelDoc format, containing basedocs which are set of possible things to predict, if different than 
the ones from the training data. Only used in case <code>type</code> is set to <code>'generic'</code></p>
</td></tr>
<tr><td><code id="predict.textspace_+3A_...">...</code></td>
<td>
<p>not used</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The following is returned, depending on the argument <code>type</code>:
</p>

<ul>
<li><p> In case type is set to <code>'generic'</code>: a list, one for each row or element in <code>newdata</code>. 
Each list element is a list with elements 
</p>

<ul>
<li><p> doc_id: the identifier of the text
</p>
</li>
<li><p> text: the character string with the text
</p>
</li>
<li><p> prediction: data.frame with columns label, label_starspace and similarity 
indicating the predicted label and the similarity of the text to the label
</p>
</li>
<li><p> terms: a list with elements basedoc_index and basedoc_terms indicating the position in basedoc and the terms 
which are part of the dictionary which are used to find the similarity
</p>
</li></ul>

</li>
<li><p> In case type is set to <code>'labels'</code>: a data.frame is returned namely:<br />
The data.frame <code>newdata</code> where several columns are added, one for each label in the Starspace model. 
These columns contain the similarities of the text to the label. 
Similarities are computed with <code><a href="#topic+embedding_similarity">embedding_similarity</a></code> indicating embedding similarities 
of the text compared to the labels using either cosine or dot product as was used during model training.
</p>
</li>
<li><p> In case type is set to <code>'embedding'</code>: <br />
A matrix of document embeddings, one embedding for each text in <code>newdata</code> as returned by <code><a href="#topic+starspace_embedding">starspace_embedding</a></code>. 
The rownames of this matrix are set to the document identifiers of <code>newdata</code>.
</p>
</li>
<li><p> In case type is set to <code>'knn'</code>: a list of data.frames, one for each row or element in <code>newdata</code> <br />
Each of these data frames contains the columns doc_id, label, similarity and rank indicating the
k-nearest neighbouring (most similar) elements of the model dictionary compared to your input text as returned by <code><a href="#topic+starspace_knn">starspace_knn</a></code>
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>data(dekamer, package = "ruimtehol")
dekamer$text &lt;- strsplit(dekamer$question, "\\W")
dekamer$text &lt;- lapply(dekamer$text, FUN = function(x) x[x != ""])
dekamer$text &lt;- sapply(dekamer$text, 
                       FUN = function(x) paste(x, collapse = " "))

idx &lt;- sample(nrow(dekamer), size = round(nrow(dekamer) * 0.9))
traindata &lt;- dekamer[idx, ]
testdata &lt;- dekamer[-idx, ]
set.seed(123456789)
model &lt;- embed_tagspace(x = traindata$text, 
                        y = traindata$question_theme_main, 
                        early_stopping = 0.8,
                        dim = 10, minCount = 5)
scores &lt;- predict(model, testdata)                        
scores &lt;- predict(model, testdata, type = "labels")
str(scores)
emb &lt;- predict(model, testdata[, c("doc_id", "text")], type = "embedding")
knn &lt;- predict(model, testdata[1:5, c("doc_id", "text")], type = "knn", k=3)


## Not run: 
library(udpipe)
data(dekamer, package = "ruimtehol")
dekamer &lt;- subset(dekamer, question_theme_main == "DEFENSIEBELEID")
x &lt;- udpipe(dekamer$question, "dutch", tagger = "none", parser = "none", trace = 100)
x &lt;- x[, c("doc_id", "sentence_id", "sentence", "token")]
set.seed(123456789)
model &lt;- embed_sentencespace(x, dim = 15, epoch = 5, minCount = 5)
scores &lt;- predict(model, "Wat zijn de cijfers qua doorstroming van 2016?", 
                  basedoc = unique(x$sentence), k = 3) 
str(scores)

#' ## clean up for cran
file.remove(list.files(pattern = ".udpipe$"))

## End(Not run)
</code></pre>

<hr>
<h2 id='range.textspace'>Get the scale of embedding similarities alongside a Starspace model</h2><span id='topic+range.textspace'></span>

<h3>Description</h3>

<p>Calculates embedding similarities between 2 embedding matrices and gets the range of resulting similarities.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'textspace'
range(
  x,
  from = as.matrix(x),
  to = as.matrix(x, type = "labels"),
  probs = seq(0, 1, by = 0.01),
  breaks = "scott",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="range.textspace_+3A_x">x</code></td>
<td>
<p>an object of class <code>textspace</code> as returned by <code><a href="#topic+starspace">starspace</a></code> or <code><a href="#topic+starspace_load_model">starspace_load_model</a></code></p>
</td></tr>
<tr><td><code id="range.textspace_+3A_from">from</code></td>
<td>
<p>an embedding matrix. Defaults to the embeddings of all the labels and the words from the model.</p>
</td></tr>
<tr><td><code id="range.textspace_+3A_to">to</code></td>
<td>
<p>an embedding matrix. Defaults to the embeddings of all the labels.</p>
</td></tr>
<tr><td><code id="range.textspace_+3A_probs">probs</code></td>
<td>
<p>numeric vector of probabilities ranging from 0-1. Passed on to <code><a href="stats.html#topic+quantile">quantile</a></code></p>
</td></tr>
<tr><td><code id="range.textspace_+3A_breaks">breaks</code></td>
<td>
<p>passed on to <code><a href="graphics.html#topic+hist">hist</a></code></p>
</td></tr>
<tr><td><code id="range.textspace_+3A_...">...</code></td>
<td>
<p>other parameters passed on to <code><a href="graphics.html#topic+hist">hist</a></code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list with elements 
</p>

<ul>
<li><p>range: the range of the embedding similarities between <code>from</code> and <code>to</code>
</p>
</li>
<li><p>quantile: the quantiles of the embedding similarities between <code>from</code> and <code>to</code>
</p>
</li>
<li><p>hist: the histogram of the embedding similarities between <code>from</code> and <code>to</code>
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>data(dekamer, package = "ruimtehol")
dekamer &lt;- subset(dekamer, depotdat &lt; as.Date("2017-02-01"))
dekamer$text &lt;- strsplit(dekamer$question, "\\W")
dekamer$text &lt;- lapply(dekamer$text, FUN = function(x) setdiff(x, ""))
dekamer$text &lt;- sapply(dekamer$text, 
                       FUN = function(x) paste(x, collapse = " "))
dekamer$question_theme_main &lt;- gsub(" ", "-", dekamer$question_theme_main)

set.seed(123456789)
model &lt;- embed_tagspace(x = tolower(dekamer$text), 
                        y = dekamer$question_theme_main, 
                        early_stopping = 0.8, 
                        dim = 10, minCount = 5)
ranges &lt;- range(model)
ranges$range
ranges$quantile
plot(ranges$hist, main = "Histogram of embedding similarities")                         
</code></pre>

<hr>
<h2 id='starspace'>Interface to Starspace for training a Starspace model</h2><span id='topic+starspace'></span>

<h3>Description</h3>

<p>Interface to Starspace for training a Starspace model, providing raw access to the C++ functionality.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>starspace(
  model = "textspace.bin",
  file,
  trainMode = 0,
  fileFormat = c("fastText", "labelDoc"),
  label = "__label__",
  dim = 100,
  epoch = 5,
  lr = 0.01,
  loss = c("hinge", "softmax"),
  margin = 0.05,
  similarity = c("cosine", "dot"),
  negSearchLimit = 50,
  adagrad = TRUE,
  ws = 5,
  minCount = 1,
  minCountLabel = 1,
  ngrams = 1,
  thread = 1,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="starspace_+3A_model">model</code></td>
<td>
<p>the full path to where the model file will be saved. Defaults to 'textspace.bin'.</p>
</td></tr>
<tr><td><code id="starspace_+3A_file">file</code></td>
<td>
<p>the full path to the file on disk which will be used for training.</p>
</td></tr>
<tr><td><code id="starspace_+3A_trainmode">trainMode</code></td>
<td>
<p>integer with the training mode. Possible values are 0, 1, 2, 3, 4 or 5. Defaults to 0. The use cases are
</p>

<ul>
<li><p> 0: tagspace (classification tasks) and search tasks
</p>
</li>
<li><p> 1: pagespace &amp; docspace (interest-based or content-based recommendation)
</p>
</li>
<li><p> 2: articlespace (sentences within document)
</p>
</li>
<li><p> 3: sentence embeddings and entity similarity 
</p>
</li>
<li><p> 4: multi-relational graphs
</p>
</li>
<li><p> 5: word embeddings 
</p>
</li></ul>
</td></tr>
<tr><td><code id="starspace_+3A_fileformat">fileFormat</code></td>
<td>
<p>either one of 'fastText' or 'labelDoc'. See the documentation of StarSpace</p>
</td></tr>
<tr><td><code id="starspace_+3A_label">label</code></td>
<td>
<p>labels prefix (character string identifying how a label is prefixed, defaults to '__label__')</p>
</td></tr>
<tr><td><code id="starspace_+3A_dim">dim</code></td>
<td>
<p>the size of the embedding vectors (integer, defaults to 100)</p>
</td></tr>
<tr><td><code id="starspace_+3A_epoch">epoch</code></td>
<td>
<p>number of epochs (integer, defaults to 5)</p>
</td></tr>
<tr><td><code id="starspace_+3A_lr">lr</code></td>
<td>
<p>learning rate (numeric, defaults to 0.01)</p>
</td></tr>
<tr><td><code id="starspace_+3A_loss">loss</code></td>
<td>
<p>loss function (either 'hinge' or 'softmax')</p>
</td></tr>
<tr><td><code id="starspace_+3A_margin">margin</code></td>
<td>
<p>margin parameter in case of hinge loss (numeric, defaults to 0.05)</p>
</td></tr>
<tr><td><code id="starspace_+3A_similarity">similarity</code></td>
<td>
<p>cosine or dot product similarity in cas of hinge loss (character, defaults to 'cosine')</p>
</td></tr>
<tr><td><code id="starspace_+3A_negsearchlimit">negSearchLimit</code></td>
<td>
<p>number of negatives sampled (integer, defaults to 50)</p>
</td></tr>
<tr><td><code id="starspace_+3A_adagrad">adagrad</code></td>
<td>
<p>whether to use adagrad in training (logical)</p>
</td></tr>
<tr><td><code id="starspace_+3A_ws">ws</code></td>
<td>
<p>the size of the context window for word level training - only used in trainMode 5 (integer, defaults to 5)</p>
</td></tr>
<tr><td><code id="starspace_+3A_mincount">minCount</code></td>
<td>
<p>minimal number of word occurences for being part of the dictionary (integer, defaults to 1 keeping all words)</p>
</td></tr>
<tr><td><code id="starspace_+3A_mincountlabel">minCountLabel</code></td>
<td>
<p>minimal number of label occurences for being part of the dictionary (integer, defaults to 1 keeping all labels)</p>
</td></tr>
<tr><td><code id="starspace_+3A_ngrams">ngrams</code></td>
<td>
<p>max length of word ngram (integer, defaults to 1, using only unigrams)</p>
</td></tr>
<tr><td><code id="starspace_+3A_thread">thread</code></td>
<td>
<p>integer with the number of threads to use. Defaults to 1.</p>
</td></tr>
<tr><td><code id="starspace_+3A_...">...</code></td>
<td>
<p>arguments passed on to ruimtehol:::textspace. See the details below.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>an object of class textspace which is a list with elements 
</p>

<ul>
<li><p> model: a Rcpp pointer to the model
</p>
</li>
<li><p> args: a list with elements
</p>

<ol>
<li><p> file: the binary file of the model saved on disk
</p>
</li>
<li><p> dim: the dimension of the embedding
</p>
</li>
<li><p> data: data-specific Starspace training parameters
</p>
</li>
<li><p> param: algorithm-specific Starspace training parameters
</p>
</li>
<li><p> dictionary: parameters which define ths dictionary of words and labels in Starspace
</p>
</li>
<li><p> options: parameters specific to duration of training, the text preparation and the training batch size
</p>
</li>
<li><p> test: parameters specific to model testing
</p>
</li></ol>

</li>
<li><p> iter: a list with element epoch, lr, error and error_validation showing the error after each epoch
</p>
</li></ul>



<h3>Note</h3>

<p>The function <code>starspace</code> is a tiny wrapper over the internal function ruimtehol:::textspace which 
allows direct access to the C++ code in order to run Starspace. <br />
The following arguments are available in that functionality when you do the training. 
Default settings are shown next to the definition. Some of these arguments are directly set in the <code>starspace</code> function,
others can be passed on with ... . <br />
</p>
<p><strong>Arguments which define how the training is done:</strong>
</p>

<ul>
<li><p> dim:             size of embedding vectors [100]
</p>
</li>
<li><p> epoch:           number of epochs [5]
</p>
</li>
<li><p> lr:              learning rate [0.01]
</p>
</li>
<li><p> loss:            loss function: hinge, softmax [hinge]
</p>
</li>
<li><p> margin:          margin parameter in hinge loss. It's only effective if hinge loss is used. [0.05]
</p>
</li>
<li><p> similarity:      takes value in [cosine, dot]. Whether to use cosine or dot product as similarity function in  hinge loss. It's only effective if hinge loss is used. [cosine]
</p>
</li>
<li><p> negSearchLimit:  number of negatives sampled [50]
</p>
</li>
<li><p> maxNegSamples:   max number of negatives in a batch update [10]
</p>
</li>
<li><p> p:               normalization parameter: normalize sum of embeddings by dividing Size^p [0.5]
</p>
</li>
<li><p> adagrad:         whether to use adagrad in training [1]
</p>
</li>
<li><p> ws:              only used in trainMode 5, the size of the context window for word level training. [5]
</p>
</li>
<li><p> dropoutLHS:      dropout probability for LHS features. [0]
</p>
</li>
<li><p> dropoutRHS:      dropout probability for RHS features. [0]
</p>
</li>
<li><p> shareEmb:        whether to use the same embedding matrix for LHS and RHS. [1]
</p>
</li>
<li><p> initRandSd:      initial values of embeddings are randomly generated from normal distribution with mean=0, standard deviation=initRandSd. [0.001]
</p>
</li></ul>

<p><strong>Arguments specific to the dictionary of words and labels:</strong>
</p>

<ul>
<li><p> minCount:        minimal number of word occurences [1]
</p>
</li>
<li><p> minCountLabel:   minimal number of label occurences [1]
</p>
</li>
<li><p> ngrams:          max length of word ngram [1]
</p>
</li>
<li><p> bucket:          number of buckets [100000]
</p>
</li>
<li><p> label:           labels prefix [__label__]
</p>
</li></ul>

<p><strong>Arguments which define early stopping or proceeding of model building:</strong>
</p>

<ul>
<li><p> initModel:       if not empty, it loads a previously trained model in -initModel and carry on training.
</p>
</li>
<li><p> validationFile:  validation file path
</p>
</li>
<li><p> validationPatience:    number of iterations of validation where does not improve before we stop training [10]
</p>
</li>
<li><p> saveEveryEpoch:  save intermediate models after each epoch [0]
</p>
</li>
<li><p> saveTempModel:   save intermediate models after each epoch with an unique name including epoch number [0]
</p>
</li>
<li><p> maxTrainTime:    max train time (secs) [8640000]
</p>
</li></ul>

<p><strong>Other:</strong>
</p>

<ul>
<li><p> trainWord:       whether to train word level together with other tasks (for multi-tasking). [0]
</p>
</li>
<li><p> wordWeight:      if trainWord is true, wordWeight specifies example weight for word level training examples. [0.5]
</p>
</li>
<li><p> useWeight        whether input file contains weights [0]
</p>
</li></ul>



<h3>References</h3>

<p><a href="https://github.com/facebookresearch">https://github.com/facebookresearch</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(dekamer, package = "ruimtehol")
x &lt;- strsplit(dekamer$question, "\\W")
x &lt;- lapply(x, FUN = function(x) x[x != ""])
x &lt;- sapply(x, FUN = function(x) paste(x, collapse = " "))

idx &lt;- sample.int(n = nrow(dekamer), size = round(nrow(dekamer) * 0.7))
writeLines(x[idx], con = "traindata.txt")
writeLines(x[-idx], con = "validationdata.txt")

set.seed(123456789)
m &lt;- starspace(file = "traindata.txt", validationFile = "validationdata.txt", 
               trainMode = 5, dim = 10, 
               loss = "softmax", lr = 0.01, ngrams = 2, minCount = 5,
               similarity = "cosine", adagrad = TRUE, ws = 7, epoch = 3,
               maxTrainTime = 10)
str(starspace_dictionary(m))              
wordvectors &lt;- as.matrix(m)
wv &lt;- starspace_embedding(m, 
                          x = c("Nationale Loterij", "migranten", "pensioen"),
                          type = "ngram")
wv
mostsimilar &lt;- embedding_similarity(wordvectors, wv["pensioen", ])
head(sort(mostsimilar[, 1], decreasing = TRUE), 10)
starspace_knn(m, "koning")

## clean up for cran
file.remove(c("traindata.txt", "validationdata.txt"))

## End(Not run)
</code></pre>

<hr>
<h2 id='starspace_dictionary'>Get the dictionary of a Starspace model</h2><span id='topic+starspace_dictionary'></span>

<h3>Description</h3>

<p>Get the dictionary of a Starspace model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>starspace_dictionary(object)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="starspace_dictionary_+3A_object">object</code></td>
<td>
<p>an object of class <code>textspace</code> as returned by <code><a href="#topic+starspace">starspace</a></code> or <code><a href="#topic+starspace_load_model">starspace_load_model</a></code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list with elements 
</p>

<ol>
<li><p>ntokens: The number of tokens in the data
</p>
</li>
<li><p>nwords: The number of words which are part of the dictionary
</p>
</li>
<li><p>nlabels: The number of labels which are part of the dictionary
</p>
</li>
<li><p>labels: A character vector with the labels
</p>
</li>
<li><p>dictionary_size: The size of the dictionary (nwords + nlabels)
</p>
</li>
<li><p>dictionary: A data.frame with all the words and labels from the dictionary. This data.frame has columns term, is_word and is_label indicating
for each term if it is a word or a label
</p>
</li></ol>



<h3>Examples</h3>

<pre><code class='language-R'>data(dekamer, package = "ruimtehol")
dekamer &lt;- subset(dekamer, depotdat &lt; as.Date("2017-02-01"))
dekamer$text &lt;- strsplit(dekamer$question, "\\W")
dekamer$text &lt;- lapply(dekamer$text, FUN = function(x) x[x != ""])
dekamer$text &lt;- sapply(dekamer$text, 
                       FUN = function(x) paste(x, collapse = " "))
dekamer$question_theme_main &lt;- gsub(" ", "-", dekamer$question_theme_main)

set.seed(123456789)
model &lt;- embed_tagspace(x = tolower(dekamer$text), 
                        y = dekamer$question_theme_main, 
                        early_stopping = 0.8, 
                        dim = 10, minCount = 5)
dict &lt;- starspace_dictionary(model)
str(dict)
</code></pre>

<hr>
<h2 id='starspace_embedding'>Get the document or ngram embeddings</h2><span id='topic+starspace_embedding'></span>

<h3>Description</h3>

<p>Get the document or ngram embeddings
</p>


<h3>Usage</h3>

<pre><code class='language-R'>starspace_embedding(object, x, type = c("document", "ngram"))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="starspace_embedding_+3A_object">object</code></td>
<td>
<p>an object of class <code>textspace</code> as returned by <code><a href="#topic+starspace">starspace</a></code> or <code><a href="#topic+starspace_load_model">starspace_load_model</a></code></p>
</td></tr>
<tr><td><code id="starspace_embedding_+3A_x">x</code></td>
<td>
<p>character vector with text to get the embeddings 
</p>

<ul>
<li><p> If <code>type</code> is set to 'document', will assume that a tab or a space is used as separator of each element of <code>x</code>.
</p>
</li>
<li><p> If <code>type</code> is set to 'ngram', will assume that a space is used as separator of each element of <code>x</code>.
</p>
</li></ul>
</td></tr>
<tr><td><code id="starspace_embedding_+3A_type">type</code></td>
<td>
<p>the type of embedding requested. Either one of 'document' or 'ngram'. In case of document, 
the function returns the document embedding, in case of ngram the function returns the embedding of the 
provided ngram term. See the details section</p>
</td></tr>
</table>


<h3>Details</h3>


<ul>
<li><p>document embeddings look to the features (e.g. words) present in <code>x</code> and summate the embeddings of these to get a document embedding and 
divide this embedding by size^p in case dot similarity is used and the euclidean norm in case cosine similarity is used. 
Where size is the number of features (e.g. words) in <code>x</code>. 
If p=1, it's equivalent to taking average of embeddings while when p=0, it's equivalent to taking sum of embeddings. You can set p and similarity in <code><a href="#topic+starspace">starspace</a></code> when you train the model.
</p>
</li>
<li><p>for ngram embeddings, starspace is using a hashing trick to find out in which bucket the ngram lies and then retrieves the embedding of that. Note that if you specify ngram, 
you need to make sure <code>x</code> contains less features (e.g. words) then you've set <code>ngram</code> when you trained your model with <code><a href="#topic+starspace">starspace</a></code>.
</p>
</li></ul>



<h3>Value</h3>

<p>a matrix of embeddings
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(dekamer, package = "ruimtehol")
dekamer$text &lt;- strsplit(dekamer$question, "\\W")
dekamer$text &lt;- lapply(dekamer$text, FUN = function(x) x[x != ""])
dekamer$text &lt;- sapply(dekamer$text, 
                       FUN = function(x) paste(x, collapse = " "))

set.seed(123456789)
model &lt;- embed_tagspace(x = tolower(dekamer$text), 
                        y = dekamer$question_theme_main, 
                        similarity = "dot",
                        early_stopping = 0.8, ngram = 1, p = 0.5,
                        dim = 10, minCount = 5)
embedding &lt;- starspace_embedding(model, "federale politie", type = "document")
embedding_dictionary &lt;- as.matrix(model)
embedding
colSums(embedding_dictionary[c("federale", "politie"), ]) / 2^0.5

## Not run: 
set.seed(123456789)
model &lt;- embed_tagspace(x = tolower(dekamer$text), 
                        y = dekamer$question_theme_main, 
                        similarity = "cosine",
                        early_stopping = 0.8, ngram = 1, 
                        dim = 10, minCount = 5)
embedding &lt;- starspace_embedding(model, "federale politie", type = "document")
embedding_dictionary &lt;- as.matrix(model)
euclidean_norm &lt;- function(x) sqrt(sum(x^2))
manual &lt;- colSums(embedding_dictionary[c("federale", "politie"), ])
manual / euclidean_norm(manual)
embedding

set.seed(123456789)
model &lt;- embed_tagspace(x = tolower(dekamer$text), 
                        y = dekamer$question_theme_main, 
                        similarity = "dot",
                        early_stopping = 0.8, ngram = 3, p = 0,
                        dim = 10, minCount = 5, bucket = 1)
starspace_embedding(model, "federale politie", type = "document")
starspace_embedding(model, "federale politie", type = "ngram")

## End(Not run)
</code></pre>

<hr>
<h2 id='starspace_knn'>K-nearest neighbours using a Starspace model</h2><span id='topic+starspace_knn'></span>

<h3>Description</h3>

<p>K-nearest neighbours using a Starspace model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>starspace_knn(object, newdata, k = 5, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="starspace_knn_+3A_object">object</code></td>
<td>
<p>an object of class <code>textspace</code> as returned by <code><a href="#topic+starspace">starspace</a></code> or <code><a href="#topic+starspace_load_model">starspace_load_model</a></code></p>
</td></tr>
<tr><td><code id="starspace_knn_+3A_newdata">newdata</code></td>
<td>
<p>a character string of length 1</p>
</td></tr>
<tr><td><code id="starspace_knn_+3A_k">k</code></td>
<td>
<p>integer with the number of nearest neighbours</p>
</td></tr>
<tr><td><code id="starspace_knn_+3A_...">...</code></td>
<td>
<p>not used</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list with elements input and a data.frame called prediction which has columns called label, similarity and rank
</p>

<hr>
<h2 id='starspace_load_model'>Load a Starspace model</h2><span id='topic+starspace_load_model'></span>

<h3>Description</h3>

<p>Load a Starspace model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>starspace_load_model(
  object,
  method = c("ruimtehol", "tsv-data.table", "binary"),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="starspace_load_model_+3A_object">object</code></td>
<td>
<p>the path to a Starspace model on disk</p>
</td></tr>
<tr><td><code id="starspace_load_model_+3A_method">method</code></td>
<td>
<p>character indicating the method of loading. Possible values are 'ruimtehol', 'binary' and 'tsv-data.table'. Defaults to 'ruimtehol'.
</p>

<ul>
<li><p>method <code>'ruimtehol'</code> loads the model, embeddings and labels which were saved with saveRDS by calling <code><a href="#topic+starspace_save_model">starspace_save_model</a></code> and re-initilises a new Starspace model with the embeddings and the same parameters used to build the model
</p>
</li>
<li><p>method <code>'binary'</code> loads the embedding which were saved as a as a binary file using the original methods of the Starspace authors - see <code><a href="#topic+starspace_save_model">starspace_save_model</a></code>
</p>
</li>
<li><p>method <code>'tsv-data.table'</code> loads the embedding which were saved as a tab-delimited flat file using the fast data.table fread function - see <code><a href="#topic+starspace_save_model">starspace_save_model</a></code>
</p>
</li></ul>
</td></tr>
<tr><td><code id="starspace_load_model_+3A_...">...</code></td>
<td>
<p>further arguments passed on to <code><a href="#topic+starspace">starspace</a></code> in case of method 'tsv-data.table'</p>
</td></tr>
</table>


<h3>Value</h3>

<p>an object of class textspace
</p>


<h3>See Also</h3>

<p><code><a href="#topic+starspace_save_model">starspace_save_model</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(dekamer, package = "ruimtehol")
dekamer$text &lt;- strsplit(dekamer$question, "\\W")
dekamer$text &lt;- lapply(dekamer$text, FUN = function(x) x[x != ""])
dekamer$text &lt;- sapply(dekamer$text, 
                       FUN = function(x) paste(x, collapse = " "))

dekamer$target &lt;- as.factor(dekamer$question_theme_main)
codes &lt;- data.frame(code = seq_along(levels(dekamer$target)), 
                    label = levels(dekamer$target), stringsAsFactors = FALSE)
dekamer$target &lt;- as.integer(dekamer$target)
set.seed(123456789)
model &lt;- embed_tagspace(x = dekamer$text, 
                        y = dekamer$target, 
                        early_stopping = 0.8,
                        dim = 10, minCount = 5)
starspace_save_model(model, file = "textspace.ruimtehol", method = "ruimtehol",
                     labels = codes)
model &lt;- starspace_load_model("textspace.ruimtehol", method = "ruimtehol")


## clean up for cran
file.remove("textspace.ruimtehol")
</code></pre>

<hr>
<h2 id='starspace_save_model'>Save a starspace model as a binary or tab-delimited TSV file</h2><span id='topic+starspace_save_model'></span>

<h3>Description</h3>

<p>Save a starspace model as a binary or a tab-delimited TSV file
</p>


<h3>Usage</h3>

<pre><code class='language-R'>starspace_save_model(
  object,
  file = "textspace.ruimtehol",
  method = c("ruimtehol", "tsv-data.table", "binary", "tsv-starspace"),
  labels = data.frame(code = character(), label = character(), stringsAsFactors =
    FALSE)
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="starspace_save_model_+3A_object">object</code></td>
<td>
<p>an object of class <code>textspace</code> as returned by <code><a href="#topic+starspace">starspace</a></code> or <code><a href="#topic+starspace_load_model">starspace_load_model</a></code></p>
</td></tr>
<tr><td><code id="starspace_save_model_+3A_file">file</code></td>
<td>
<p>character string with the path to the file where to save the model</p>
</td></tr>
<tr><td><code id="starspace_save_model_+3A_method">method</code></td>
<td>
<p>character indicating the method of saving. Possible values are 'ruimtehol', 'binary', 'tsv-starspace' and 'tsv-data.table'. Defaults to 'ruimtehol'.
</p>

<ul>
<li><p>The first method: <code>'ruimtehol'</code> saves the R object and the embeddings and optionally the label definitions with saveRDS. This object can be loaded back in with <code><a href="#topic+starspace_load_model">starspace_load_model</a></code>.
</p>
</li>
<li><p>The second method: <code>'tsv-data.table'</code> saves the model embeddings as a tab-delimited flat file using the fast data.table fwrite function
</p>
</li>
<li><p>The third method: <code>'binary'</code> saves the model as a binary file using the original methods of the Starspace authors
</p>
</li>
<li><p>The fourth method: <code>'tsv-starspace'</code> saves the model as a tab-delimited flat file using the original methods of the Starspace authors
</p>
</li></ul>
</td></tr>
<tr><td><code id="starspace_save_model_+3A_labels">labels</code></td>
<td>
<p>a data.frame with at least columns code and label which will be saved in case <code>method</code> is set to <code>'ruimtehol'</code>. 
This allows to store the mapping between Starspace labels and your own codes alongside the model, 
where code is your internal code and label is your label.<br />
A new column will be added to this data.frame called <code>label_starspace</code> which combines the 
Starspace prefix of the label with the code column of your provided data.frame, as this combination is the label starspace uses internally.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>invisibly, the character string with the file of the saved object
</p>


<h3>Note</h3>

<p>It is advised to always use method 'ruimtehol' method as it works nicely together with the 
<code><a href="#topic+starspace_load_model">starspace_load_model</a></code> function. It is the advised method unless you need to provide non-R users the models 
and you prefer using the methods provided by the Starspace authors instead of the faster and more portable 'ruimtehol' method.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+starspace_load_model">starspace_load_model</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(dekamer, package = "ruimtehol")
dekamer$text &lt;- strsplit(dekamer$question, "\\W")
dekamer$text &lt;- lapply(dekamer$text, FUN = function(x) x[x != ""])
dekamer$text &lt;- sapply(dekamer$text, 
                       FUN = function(x) paste(x, collapse = " "))

dekamer$target &lt;- as.factor(dekamer$question_theme_main)
codes &lt;- data.frame(code = seq_along(levels(dekamer$target)), 
                    label = levels(dekamer$target), stringsAsFactors = FALSE)
dekamer$target &lt;- as.integer(dekamer$target)
set.seed(123456789)
model &lt;- embed_tagspace(x = dekamer$text, 
                        y = dekamer$target, 
                        early_stopping = 0.8,
                        dim = 10, minCount = 5)
starspace_save_model(model, file = "textspace.ruimtehol", method = "ruimtehol",
                     labels = codes)
model &lt;- starspace_load_model("textspace.ruimtehol", method = "ruimtehol")
starspace_save_model(model, file = "embeddings.tsv", method = "tsv-data.table")

## clean up for cran
file.remove("textspace.ruimtehol")
file.remove("embeddings.tsv")
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
