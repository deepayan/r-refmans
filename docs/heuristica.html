<!DOCTYPE html><html><head><title>Help for package heuristica</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {heuristica}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#accuracyFromConfusionMatrix3x3'><p>Accuracy based on a predictPair confusion matrix.</p></a></li>
<li><a href='#city_population'><p>Population size of the 83 largest German cities.</p></a></li>
<li><a href='#city_population_original'><p>Original, uncorrected Population size of the 83 largest German cities.</p></a></li>
<li><a href='#collapseConfusionMatrix3x3To2x2'><p>Collapses a 3x3 confusion matrix to a 2x2 confusion matrix.</p></a></li>
<li><a href='#conditionalCueValidityComplete'><p>Calculate conditional cue validity, which includes reversing and ranks.</p></a></li>
<li><a href='#confusionMatrixFor_Neg1_0_1'><p>Confusion matrix for categories -1, 0, 1 (the output of predictPair).</p></a></li>
<li><a href='#correctGreater'><p>Creates function indicating whether row1[col] &gt; row2[col].</p></a></li>
<li><a href='#createFunction'><p>Generic function to create functions for rowPairApply.</p></a></li>
<li><a href='#createFunction.heuristics'><p>Create function for heuristics prediction with rowPairApply.</p></a></li>
<li><a href='#cueAccuracy'><p>Calculate the accuracy of using a cue to predict a criterion.</p></a></li>
<li><a href='#cueValidity'><p>Calculate the cue validity.</p></a></li>
<li><a href='#cueValidityAppliedToColumns'><p>Calculate the cue validity for the cols_to_fit columns.</p></a></li>
<li><a href='#cueValidityComplete'><p>Calculate cue validity with reverse, cue directions, and cue ranks.</p></a></li>
<li><a href='#distributeGuessAsExpectedValue'><p>Distributes guesses of 3x3 confusion matrix to expected value of 1 and -1.</p></a></li>
<li><a href='#heuristics'><p>Wrap fitted heuristics to pass to rowPairApply to call predictPair.</p></a></li>
<li><a href='#heuristicsList'><p>Wrapper for fitted heuristics to generate predictions with rowPairApply.</p></a></li>
<li><a href='#heuristicsProb'><p>Wrap fitted heuristics to pass to rowPairApply to call predictProb.</p></a></li>
<li><a href='#highschool_dropout'><p>Chicago high school dropout rates.</p></a></li>
<li><a href='#lmWrapper'><p>Create an lm model just specifying columns, generating a formula for you.</p></a></li>
<li><a href='#logRegModel'><p>Logistic Regression model using cue differences as predictors</p></a></li>
<li><a href='#minModel'><p>Minimalist Model</p></a></li>
<li><a href='#oneRow'><p>Convenience function to get one row from a matrix or data frame.</p></a></li>
<li><a href='#pairMatrix'><p>Apply a function to all unique pairs of row indices up to num_row.</p></a></li>
<li><a href='#percentCorrect'><p>Percent correct of heuristics' predictPair on test_data.</p></a></li>
<li><a href='#percentCorrectList'><p>Percent correct of a list of heuristics' predictPair on test_data.</p></a></li>
<li><a href='#percentCorrectListNonSymmetric'><p>percentCorrectList for non-symmetric heuristics</p></a></li>
<li><a href='#percentCorrectListReturnMatrix'><p>Percent correct of heuristics' predictPair on test_data, returning a matrix.</p></a></li>
<li><a href='#predictPair'><p>Predict which of a pair of rows has a higher criterion.</p></a></li>
<li><a href='#predictPairInternal'><p>Generic function to predict which of a pair of rows has a higher criterion.</p></a></li>
<li><a href='#predictPairProb'><p>Predict the probability that row1 has a higher criterion than row2.</p></a></li>
<li><a href='#predictPairSummary'><p>Returns the row indices, correct answer, and predictions for all row pairs.</p></a></li>
<li><a href='#predictProbInternal'><p>Generic function to predict the probability row 1 has a higher criterion.</p></a></li>
<li><a href='#probGreater'><p>Creates function for one column with correct probability row1 is greater.</p></a></li>
<li><a href='#regInterceptModel'><p>Linear regression wrapper for hueristica</p></a></li>
<li><a href='#regModel'><p>Linear regression (no intercept) wrapper for hueristica</p></a></li>
<li><a href='#reverseRowsAndReverseColumns'><p>Reverse rows and columns of data</p></a></li>
<li><a href='#rowIndexes'><p>Wrapper to output two columns, row 1 and row 2.</p></a></li>
<li><a href='#rowPairApply'><p>Apply functions to all row pairs.</p></a></li>
<li><a href='#rowPairApply2Rows'><p>Apply all functions to the two rows passed in.</p></a></li>
<li><a href='#rowPairApplyList'><p>Apply list of functions to all row pairs.</p></a></li>
<li><a href='#singleCueModel'><p>Single Cue Model</p></a></li>
<li><a href='#statsFromConfusionMatrix'><p>Accuracy, sensitivity, specificity, and precision of 2x2 confusion matrix.</p></a></li>
<li><a href='#ttbGreedyModel'><p>Greedy Take The Best</p></a></li>
<li><a href='#ttbModel'><p>Take The Best</p></a></li>
<li><a href='#unitWeightModel'><p>Unit-weight linear model</p></a></li>
<li><a href='#validityWeightModel'><p>Validity Weight Model, a linear model weighted by cue validities</p></a></li>
<li><a href='#zzDocumentationStubFormulaModelParams'><p>Documentation stub. Just to share documentation.</p></a></li>
<li><a href='#zzDocumentationStubModelParams'><p>Documentation stub.  Just a way to share parameter documentation.</p></a></li>
<li><a href='#zzDocumentationStubReverseCues'><p>Documentation stub.</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Title:</td>
<td>Heuristics Including Take the Best and Unit-Weight Linear</td>
</tr>
<tr>
<td>Version:</td>
<td>1.0.3</td>
</tr>
<tr>
<td>Description:</td>
<td>Implements various heuristics like Take The Best and
    unit-weight linear, which do two-alternative choice: which of
    two objects will have a higher criterion?  Also offers functions
    to assess performance, e.g. percent correct across all row pairs
    in a data set and finding row pairs where models disagree.
    New models can be added by implementing a fit and predict function&ndash;
    see vignette.  Take The Best was first described in: Gigerenzer, G.
    &amp; Goldstein, D. G. (1996) &lt;<a href="https://doi.org/10.1037%2F0033-295X.103.4.650">doi:10.1037/0033-295X.103.4.650</a>&gt;.  All
    of these heuristics were run on many data sets and analyzed in:
    Gigerenzer, G., Todd, P. M., &amp; the ABC Group (1999).
    &lt;ISBN:978-0195143812&gt;.</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.1.0)</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>Imports:</td>
<td>Hmisc</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/jeanimal/heuristica">https://github.com/jeanimal/heuristica</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/jeanimal/heuristica/issues">https://github.com/jeanimal/heuristica/issues</a></td>
</tr>
<tr>
<td>Suggests:</td>
<td>devtools, ggplot2, glmnet, knitr, plyr, reshape, reshape2,
rmarkdown, testthat</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.1</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2021-09-07 02:59:06 UTC; jeanwhitmore</td>
</tr>
<tr>
<td>Author:</td>
<td>Jean Whitmore [aut, cre],
  Daniel Barkoczi [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Jean Whitmore &lt;jeanimal@gmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2021-09-08 07:40:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='accuracyFromConfusionMatrix3x3'>Accuracy based on a predictPair confusion matrix.</h2><span id='topic+accuracyFromConfusionMatrix3x3'></span>

<h3>Description</h3>

<p>Given a confusion matrix from pair predict (the output of
confusionMatrixFor_Neg1_0_1), calculate an accuracy.  By default assumes
zeroes are guesses and that half of them are correct.  This guessing
assumptions helps measures of accuracy converge faster for small samples,
but it will artificially reduce the variance of an algorithm's predictions,
if that is what you are trying to measure.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>accuracyFromConfusionMatrix3x3(confusion_matrix, zero_as_guess = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="accuracyFromConfusionMatrix3x3_+3A_confusion_matrix">confusion_matrix</code></td>
<td>
<p>A 3x3 matrix where rows are correct outcomes
(-1, 0, 1) and columns are predicted outcomes (-1, 0, 1).</p>
</td></tr>
<tr><td><code id="accuracyFromConfusionMatrix3x3_+3A_zero_as_guess">zero_as_guess</code></td>
<td>
<p>Optional parameter which by default treats the 2nd zero
column as guesses and assigns half of them to be correct.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A value from 0 to 1 for the proportion correct.
</p>


<h3>References</h3>

<p>Wikipedia's entry on
<a href="https://en.wikipedia.org/wiki/Confusion_matrix">https://en.wikipedia.org/wiki/Confusion_matrix</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+confusionMatrixFor_Neg1_0_1">confusionMatrixFor_Neg1_0_1</a></code> for generating the confusion
matrix.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Below accuracy is 1 (100% correct) because 4 -1's were correctly predicted,
# and 2 1's were correctly predicted.  (On-diagonal elements are correct
# predictions.)
accuracyFromConfusionMatrix3x3(cbind(c(4,0,0), c(0,0,0), c(0,0,2)))

# 3 wrong and 3 more wrong for 0 accuracy.
accuracyFromConfusionMatrix3x3(cbind(c(0,0,3), c(0,0,0), c(3,0,0)))

# Below is 4 + 5 correct, 1 incorrect, for 9/10 = 0.9 accuracy.
accuracyFromConfusionMatrix3x3(cbind(c(4,0,1), c(0,0,0), c(0,0,5)))

# Below has 3+1=4 guesses, and 0.5 are assigned correct.
accuracyFromConfusionMatrix3x3(cbind(c(0,0,0), c(3,0,1), c(0,0,0)))
</code></pre>

<hr>
<h2 id='city_population'>Population size of the 83 largest German cities.</h2><span id='topic+city_population'></span>

<h3>Description</h3>

<p>Population size of the 83 German cities that had more than 100,000
inhabitants when this data was collected in 1993 plus cues 
indicating whether a city has a soccer team, intercity trainline,
University, etc.  All cues are binary.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>city_population
</code></pre>


<h3>Format</h3>

<p>A data frame.
</p>

<dl>
<dt>Name</dt><dd><p>Name of city</p>
</dd>
<dt>Running_Number</dt><dd><p>Running Number</p>
</dd>
<dt>Population</dt><dd><p>Population size</p>
</dd>
<dt>Soccer_Team</dt><dd><p>1 indicates that the city has a soccer team, 0
indicates that it does not.</p>
</dd>
<dt>State_Capital</dt><dd><p>1 indicates that the city is a state capital, 0
indicates that it is not.</p>
</dd>
<dt>Former_East_Germany</dt><dd><p>1 indicates that the city belongs to former
East Germany, 0 that is does not.</p>
</dd>
<dt>Industrial_Belt</dt><dd><p>1 indicates that the city is an industrial belt,
0 that it is not.</p>
</dd>
<dt>Licence_Plate</dt><dd><p>1 indicates that the city has a licence plate, 0
that it does not.</p>
</dd>
<dt>Intercity_Trainline</dt><dd><p>1 indicates that an intercity trainline crosses
the city, 0 that it does not.</p>
</dd>
<dt>Exposition_Site</dt><dd><p>1 indicates that the city is an exposition size, 0
that it is not.</p>
</dd>
<dt>National_Capital</dt><dd><p>1 indicates that the city is the national capital,
0 that it is not.</p>
</dd>
<dt>University</dt><dd><p>1 indicates that the city has a University, 0 that it
does not.</p>
</dd>
</dl>



<h3>Details</h3>

<p>The data is based on:
</p>
<p>Fischer Welt Almanach [Fischer World Almanac]. (1993).  Frankfurt,
Germany: Fischer.
</p>
<p>This is the data set used in simulations by the ABC (Adaptive Behavior
and Cognition) research group.
</p>

<hr>
<h2 id='city_population_original'>Original, uncorrected Population size of the 83 largest German cities.</h2><span id='topic+city_population_original'></span>

<h3>Description</h3>

<p>In contrast to city_population, this has some transcription errors from
the almanac, but it was used in published research, so it is provided for
reproducibility.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>city_population_original
</code></pre>


<h3>Format</h3>

<p>A data frame.
</p>

<dl>
<dt>Name</dt><dd><p>Name of city</p>
</dd>
<dt>Running_Number</dt><dd><p>Running Number</p>
</dd>
<dt>Population</dt><dd><p>Population size</p>
</dd>
<dt>Soccer_Team</dt><dd><p>1 indicates that the city has a soccer team, 0
indicates that it does not.</p>
</dd>
<dt>State_Capital</dt><dd><p>1 indicates that the city is a state capital, 0
indicates that it is not.</p>
</dd>
<dt>Former_East_Germany</dt><dd><p>1 indicates that the city belongs to former
East Germany, 0 that is does not.</p>
</dd>
<dt>Industrial_Belt</dt><dd><p>1 indicates that the city is an industrial belt,
0 that it is not.</p>
</dd>
<dt>Licence_Plate</dt><dd><p>1 indicates that the city has a licence plate, 0
that it does not.</p>
</dd>
<dt>Intercity_Trainline</dt><dd><p>1 indicates that an intercity trainline crosses
the city, 0 that it does not.</p>
</dd>
<dt>Exposition_Site</dt><dd><p>1 indicates that the city is an exposition size, 0
that it is not.</p>
</dd>
<dt>National_Capital</dt><dd><p>1 indicates that the city is the national capital,
0 that it is not.</p>
</dd>
<dt>University</dt><dd><p>1 indicates that the city has a University, 0 that it
does not.</p>
</dd>
</dl>


<hr>
<h2 id='collapseConfusionMatrix3x3To2x2'>Collapses a 3x3 confusion matrix to a 2x2 confusion matrix.</h2><span id='topic+collapseConfusionMatrix3x3To2x2'></span>

<h3>Description</h3>

<p>A 3x3 confusion matrix results from predictPair.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>collapseConfusionMatrix3x3To2x2(
  confusion_matrix_3x3,
  guess_handling_fn = distributeGuessAsExpectedValue,
  tie_handling_fn = distributeTies
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="collapseConfusionMatrix3x3To2x2_+3A_confusion_matrix_3x3">confusion_matrix_3x3</code></td>
<td>
<p>A 3x3 confusion matrix.</p>
</td></tr>
<tr><td><code id="collapseConfusionMatrix3x3To2x2_+3A_guess_handling_fn">guess_handling_fn</code></td>
<td>
<p>A function to call on the 3x3 confusion matrix to
assign a model's guesses&ndash; 0 predictions tracked in the 2nd column&ndash; to
-1 or 1 counts.</p>
</td></tr>
<tr><td><code id="collapseConfusionMatrix3x3To2x2_+3A_tie_handling_fn">tie_handling_fn</code></td>
<td>
<p>A function to call on the 3x3 confusion matrix to
distribute ties&ndash; 0 correct answers tracked in the 2nd row&ndash; to -1 or 1
counts.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The middle column repressents guesses.
The middle row represents ties.  T
</p>


<h3>Value</h3>

<p>A 2x2 confusion matrix.
</p>

<hr>
<h2 id='conditionalCueValidityComplete'>Calculate conditional cue validity, which includes reversing and ranks.</h2><span id='topic+conditionalCueValidityComplete'></span>

<h3>Description</h3>

<p>Conditional cue validity is the validity of a cue taking into account
decisions already made by higher-ranked cues.  For a single cue, it
is the same as cue validity.  For two cues, the higher validity cue will
have conditional cue validity = cue validity.  However, the remaining cue
will have its validity re-calculated on just those pairs of object where
cue validity did not discriminate.  In the case of binary data, there will
be many pairs where the first cue did not discriminate.  With real-valued
data, there may be no such cases.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>conditionalCueValidityComplete(data, criterion_col, cols_to_fit)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="conditionalCueValidityComplete_+3A_data">data</code></td>
<td>
<p>The matrix or data.frame whose columns are treated as cues.</p>
</td></tr>
<tr><td><code id="conditionalCueValidityComplete_+3A_criterion_col">criterion_col</code></td>
<td>
<p>The index of the column used as criterion.</p>
</td></tr>
<tr><td><code id="conditionalCueValidityComplete_+3A_cols_to_fit">cols_to_fit</code></td>
<td>
<p>A vector of indexes of the columns to calculate cue
validity for.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of vectors with values for each column in cols_to_fit:
$cue_validities: The validities based on reversed value, numbers ranging
from 0 to 1.  It will include NA if the validity cannot be calculated
(e.g. higher-validity cues made decisions for all cases in the data set).
$cue_ranks: Rank order from 1 to # of cues in cols_to_fit.  Will be NA if 
validity was NA.
$cue_directions: 1 if cue is in same direction as criterion, -1 if
reversed.  Will be NA if validity was NA.
</p>


<h3>References</h3>

<p>Martignon, L., &amp; Hoffrage, U.  (2002).  Fast, frugal, and fit: Simple
heuristics for paired comparisons.  Theory and Decision, 52: 29-71.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cueValidity">cueValidity</a></code> and <code><a href="#topic+cueValidityComplete">cueValidityComplete</a></code> for the
unconditional version.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># The data below differentiates between cue validity and conditional cue
# validity.  Cue validity of x1 is 1.0.  Cue validity of x2 is 0.5.
# But after you've chosen x1 as the highest-validity cue, only row2
# vs. row3 is undecided  x2 predictions correctly on those, so its
# conditional cue validity is 1.0 (conditional on x1 being first).
data &lt;- cbind(y=c(5,4,3), x1=c(1,0,0), x2=c(0,1,0))
out &lt;- conditionalCueValidityComplete(data, 1, c(2:3))
# This tells you both cues had validity 1-- it returns 1, 1.
out$cue_validities
# This tells you to choose x1 first-- it returns 1, 0.
out$cue_ranks
# This tells you they already point in the correct direction.
out$cue_directions
# For a case with a negative cue direction, try this data:
data2 &lt;- cbind(y=c(5,4,3), x1=c(1,0,0), x2=c(1,0,1))
conditionalCueValidityComplete(data2, 1, c(2:3))

</code></pre>

<hr>
<h2 id='confusionMatrixFor_Neg1_0_1'>Confusion matrix for categories -1, 0, 1 (the output of predictPair).</h2><span id='topic+confusionMatrixFor_Neg1_0_1'></span>

<h3>Description</h3>

<p>Measuring accuracy of predicting categories, where in the predictPair paradigm
the categories are the relative ranks of a pair of rows.  The categories are:
-1 means Row1 &lt; Row2
0 means the rows are equal or guess
1 means Row1 &gt; Row2
</p>


<h3>Usage</h3>

<pre><code class='language-R'>confusionMatrixFor_Neg1_0_1(ref_data, predicted_data)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="confusionMatrixFor_Neg1_0_1_+3A_ref_data">ref_data</code></td>
<td>
<p>A vector with outcome categories from a reference source to
be predicted (e.g. the output of correctGreater.)</p>
</td></tr>
<tr><td><code id="confusionMatrixFor_Neg1_0_1_+3A_predicted_data">predicted_data</code></td>
<td>
<p>A vector with outcome categories from a prediction
source that is trying to match ref_data (e.g. ttbModel predictions).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A 3x3 matrix of counts.  Rows are outcomes of the reference data.
Columns are outcomes of predicted data.
</p>


<h3>References</h3>

<p>Wikipedia's entry on
<a href="https://en.wikipedia.org/wiki/Confusion_matrix">https://en.wikipedia.org/wiki/Confusion_matrix</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example 1
# Below, the correct outcome is always 1, so only the last row of the
# confusion matrix has non-zero counts.  But the predictor makes a few
# mistakes, so some non-zero counts are off the diagonal.
confusionMatrixFor_Neg1_0_1(c(1,1,1), c(1,-1,-1))
# outputs:
#    -1 0 1
# -1  0 0 0
# 0   0 0 0
# 1   2 0 1
#
# Example 2
# The prediction always matches the reference outcome, so all non-zero
# counts are on the diagonal.
confusionMatrixFor_Neg1_0_1(c(1,1,0,0,-1,-1), c(1,1,0,0,-1,-1))
# outputs:
#    -1 0 1
# -1  2 0 0
# 0   0 2 0
# 1   0 0 2
#
</code></pre>

<hr>
<h2 id='correctGreater'>Creates function indicating whether row1[col] &gt; row2[col].</h2><span id='topic+correctGreater'></span>

<h3>Description</h3>

<p>Using rowPairApply, this can generate a column indicating the
the correct direction of the criterion in comparing row 1 vs. row2 for
all row pairs in test_data.
1 indicates row 1's criterion &gt; row 2's criterion
0 indicates they are equal
-1 indicates row 2's criterion is greater
By default, the output column is called &quot;CorrectGreater,&quot; but you
can override the name with output_column_name.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>correctGreater(criterion_col, output_column_name = "CorrectGreater")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="correctGreater_+3A_criterion_col">criterion_col</code></td>
<td>
<p>The integer index of the criterion in test_data.</p>
</td></tr>
<tr><td><code id="correctGreater_+3A_output_column_name">output_column_name</code></td>
<td>
<p>An optional string</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is meant to be used to measure the performance of heuristics
wrapped with <code><a href="#topic+heuristics">heuristics</a></code>.
</p>


<h3>Value</h3>

<p>An object that implements createFunction.
Users will generally not use this directly&ndash; rowPairApply will.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+heuristics">heuristics</a></code> is the wrapper to get the predicted greater
row in the row pair for each heuristic passed in to it.
</p>
<p><code><a href="#topic+rowPairApply">rowPairApply</a></code> which has an example of using this.
</p>

<hr>
<h2 id='createFunction'>Generic function to create functions for rowPairApply.</h2><span id='topic+createFunction'></span>

<h3>Description</h3>

<p>An example of solving something with another layer of indirection.
https://en.wikipedia.org/wiki/Fundamental_theorem_of_software_engineering
</p>


<h3>Usage</h3>

<pre><code class='language-R'>createFunction(object, test_data)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="createFunction_+3A_object">object</code></td>
<td>
<p>The object that implements createFunction, e.g. 
heuristicsProb(ttb).</p>
</td></tr>
<tr><td><code id="createFunction_+3A_test_data">test_data</code></td>
<td>
<p>The test data that row_pairs will be drawn from.
We recommend</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A function that can easily be used by rowPairApply.  This
is not normally used by ordinary users.
</p>

<hr>
<h2 id='createFunction.heuristics'>Create function for heuristics prediction with rowPairApply.</h2><span id='topic+createFunction.heuristics'></span>

<h3>Description</h3>

<p>Creates a function that takes an index pair and returns a prediction
for each of the predictProbInternal implementers.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'heuristics'
createFunction(object, test_data)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="createFunction.heuristics_+3A_object">object</code></td>
<td>
<p>A heuristics object.</p>
</td></tr>
<tr><td><code id="createFunction.heuristics_+3A_test_data">test_data</code></td>
<td>
<p>The test data that row_pairs will be drawn from.
We recommend</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A function that can easily be used by rowPairApply to
generate predictions for all heuristics the object was created with.
If it was created with M heuristics, it will generate M predictions.
</p>

<hr>
<h2 id='cueAccuracy'>Calculate the accuracy of using a cue to predict a criterion.</h2><span id='topic+cueAccuracy'></span>

<h3>Description</h3>

<p><code><a href="#topic+cueValidity">cueValidity</a></code> counts only correct and incorrect inferences,
ignoring cases where a cue does not discriminate.  Cue accuracy gives those
cases a weight of 0.5, the expected accuracy of guessing.
It is calculated as
(correct + 0.5 * guesses) / (correct + incorrect + guesses).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cueAccuracy(criterion, cue, replaceNanWith = 0.5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cueAccuracy_+3A_criterion">criterion</code></td>
<td>
<p>A vector of values to be predicted.</p>
</td></tr>
<tr><td><code id="cueAccuracy_+3A_cue">cue</code></td>
<td>
<p>A vector of values to predict with.  Should have the same
length as the criterion.</p>
</td></tr>
<tr><td><code id="cueAccuracy_+3A_replacenanwith">replaceNanWith</code></td>
<td>
<p>The value to return as cue validity in case it
cannot be calculated, e.g. no variance in the values.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The cue accuracy, a value in the range [0,1].
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cueValidity">cueValidity</a></code> for an alternate measure used in Take The Best.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>cueValidity(c(5,1), c(1,0))
cueAccuracy(c(5,1), c(1,0))
# Both return 1.
cueValidity(c(5,2,1), c(1,0,0))
cueAccuracy(c(5,2,1), c(1,0,0))
# Cue validity still returns 1 but cue accuracy returns (2+0.5)/3 = 0.833.
</code></pre>

<hr>
<h2 id='cueValidity'>Calculate the cue validity.</h2><span id='topic+cueValidity'></span>

<h3>Description</h3>

<p>Calculate the
<a href="https://en.wikipedia.org/wiki/Cue_validity">cue validity</a>
for a pair of vectors.  It is calculated as
correct / (correct + incorrect).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cueValidity(criterion, cue, replaceNanWith = 0.5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cueValidity_+3A_criterion">criterion</code></td>
<td>
<p>A vector of values to be predicted.</p>
</td></tr>
<tr><td><code id="cueValidity_+3A_cue">cue</code></td>
<td>
<p>A vector of values to predict with.  Should have the same
length as the criterion.</p>
</td></tr>
<tr><td><code id="cueValidity_+3A_replacenanwith">replaceNanWith</code></td>
<td>
<p>The value to return as cue validity in case it
cannot be calculated, e.g. no variance in the values.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The cue validity, a value in the range [0,1].
</p>


<h3>References</h3>

<p>Wikipedia's entry on
<a href="https://en.wikipedia.org/wiki/Cue_validity">https://en.wikipedia.org/wiki/Cue_validity</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cueValidityComplete">cueValidityComplete</a></code> for more complete output.
</p>
<p><code><a href="#topic+conditionalCueValidityComplete">conditionalCueValidityComplete</a></code> for a version where validity
is conditional on cues already used to make decisions.
</p>
<p><code><a href="#topic+cueAccuracy">cueAccuracy</a></code> for a measure that takes guesses into account.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>cueValidity(c(5,1), c(1,0))
# Returns 1.
cueValidity(c(5,2,1), c(1,0,0))
# Also returns 1
cueValidity(c(5,2,1), c(0,0,1))
# Returns 0.
cueValidity(c(5,2,1), c(1,0,1))
# Returns 0.5.
</code></pre>

<hr>
<h2 id='cueValidityAppliedToColumns'>Calculate the cue validity for the cols_to_fit columns.</h2><span id='topic+cueValidityAppliedToColumns'></span>

<h3>Description</h3>

<p>This returns only the cue validities, without reversing when a cue
points in the wrong direction&ndash; e.g. education is negatively associated
with number of felonies, so we should use LESS education as a predictor.
Use cueValidityComplete for help with that.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cueValidityAppliedToColumns(
  data,
  criterion_col,
  cols_to_fit,
  replaceNanWith = 0.5
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cueValidityAppliedToColumns_+3A_data">data</code></td>
<td>
<p>The matrix or data.frame whose columns are treated as cues.</p>
</td></tr>
<tr><td><code id="cueValidityAppliedToColumns_+3A_criterion_col">criterion_col</code></td>
<td>
<p>The index of the column used as criterion.</p>
</td></tr>
<tr><td><code id="cueValidityAppliedToColumns_+3A_cols_to_fit">cols_to_fit</code></td>
<td>
<p>A vector of indexes of the columns to calculate cue
validity for.</p>
</td></tr>
<tr><td><code id="cueValidityAppliedToColumns_+3A_replacenanwith">replaceNanWith</code></td>
<td>
<p>The value to return as cue validity in case it
cannot be calculated.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list where $cue_validities has a vector of validities for
each of the columns in cols_to_fit.
</p>


<h3>References</h3>

<p>Wikipedia's entry on
<a href="https://en.wikipedia.org/wiki/Cue_validity">https://en.wikipedia.org/wiki/Cue_validity</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cueValidityComplete">cueValidityComplete</a></code> for more complete output.
</p>

<hr>
<h2 id='cueValidityComplete'>Calculate cue validity with reverse, cue directions, and cue ranks.</h2><span id='topic+cueValidityComplete'></span>

<h3>Description</h3>

<p>This provides a vector of cue_validities and potentially other useful
information, particularly if reverse_cues=TRUE.  For example, education
is negatively associated with number of felonies.  If reverse_cues=FALSE,
education will get validity &lt; 0.5.  If reverse_cues=TRUE, then LESS
education will be used as a predictor, resulting in:
1) cue_validity &gt; 0.5
2) cue_direction == -1
To use the cue for prediction, be sure to multiply it by the cue_direction.
For ranking, based heuristics, cue_ranks gives the rank order of cues where
highest validity = rank 1 (after reversing, if any).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cueValidityComplete(
  data,
  criterion_col,
  cols_to_fit,
  replaceNanWith = 0.5,
  reverse_cues = FALSE,
  ties.method = "random"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cueValidityComplete_+3A_data">data</code></td>
<td>
<p>The matrix or data.frame whose columns are treated as cues.</p>
</td></tr>
<tr><td><code id="cueValidityComplete_+3A_criterion_col">criterion_col</code></td>
<td>
<p>The index of the column used as criterion.</p>
</td></tr>
<tr><td><code id="cueValidityComplete_+3A_cols_to_fit">cols_to_fit</code></td>
<td>
<p>A vector of indexes of the columns to calculate cue
validity for.</p>
</td></tr>
<tr><td><code id="cueValidityComplete_+3A_replacenanwith">replaceNanWith</code></td>
<td>
<p>The value to return as cue validity in case it
cannot be calculated.</p>
</td></tr>
<tr><td><code id="cueValidityComplete_+3A_reverse_cues">reverse_cues</code></td>
<td>
<p>Optional parameter to reverse cues as needed.  By
default, the model will reverse the cue values for cues with cue validity
&lt; 0.5, so a cue with validity 0 becomes a cue with validity 1.
Set this to FALSE if you do not want that, i.e. the cue stays validity 0.</p>
</td></tr>
<tr><td><code id="cueValidityComplete_+3A_ties.method">ties.method</code></td>
<td>
<p>An optional parameter passed to rank: A character string
sepcifying how ties (in cue validity) are treated.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list where $cue_validities has a vector of validities for
each of the columns in cols_to_fit.
</p>


<h3>References</h3>

<p>Wikipedia's entry on
<a href="https://en.wikipedia.org/wiki/Cue_validity">https://en.wikipedia.org/wiki/Cue_validity</a>
</p>

<hr>
<h2 id='distributeGuessAsExpectedValue'>Distributes guesses of 3x3 confusion matrix to expected value of 1 and -1.</h2><span id='topic+distributeGuessAsExpectedValue'></span>

<h3>Description</h3>

<p>Given a 3x3 confusion matrix, distributes guesses in column 2 using the
expected value.  That is, moves half of guess counts (in column 2) to -1
(column 1) and the other half to 1 (column 3).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>distributeGuessAsExpectedValue(confusion_matrix_3x3)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="distributeGuessAsExpectedValue_+3A_confusion_matrix_3x3">confusion_matrix_3x3</code></td>
<td>
<p>A 3x3 matrix where the middle column is counts of
guesses.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>-1 0 1
-1  2 2 2
0   4 4 4
1   6 6 6
becomes
-1 0 1
-1  3 0 3
0   6 0 6
1   9 0 9
</p>


<h3>Value</h3>

<p>A 3x3 confusion matrix with 0's in the middle column.
</p>

<hr>
<h2 id='heuristics'>Wrap fitted heuristics to pass to rowPairApply to call predictPair.</h2><span id='topic+heuristics'></span>

<h3>Description</h3>

<p>One or more fitted heuristics can be passed in.  They must all have the
same cols_to_fit.  If they differ on cols_to_fit, then group them in separate
heuristics functions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>heuristics(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="heuristics_+3A_...">...</code></td>
<td>
<p>A list of predictPairInternal implementers, e.g. a fitted ttb model.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Users will generally not use the output directly but instead pass this to
rowPairApply.
</p>


<h3>Value</h3>

<p>An object of class heuristics, which implements createFunction.
Users will generally not use this directly&ndash; rowPairApply will.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rowPairApply">rowPairApply</a></code> which is what the output of heuristics is
normally passed in to.
</p>
<p><code><a href="#topic+heuristicsList">heuristicsList</a></code> for a version of this function where you can
control the function called (not necessarily predictPairInternal).
</p>
<p><code><a href="#topic+predictPairInternal">predictPairInternal</a></code> which must be implemented by heuristics in
order to use them with the heuristics() wrapper function.  This only
matters for people implementing their own heuristics.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Use one fitted ttbModel with column 1 as criterion and columns 2,3 as
# cues.
data &lt;- cbind(y=c(30,20,10,5), x1=c(1,1,0,0), x2=c(1,1,0,1))
ttb &lt;- ttbModel(data, 1, c(2:3))
rowPairApply(data, heuristics(ttb))
# This outputs ttb's predictions for all 6 row pairs of data.
# (It has 6 row pairs because 4*2/2 = 6.)  It gets the predictions
# by calling ttb's predictPairInternal.

# Use the same fitted ttbModel plus a unit weight model with the same
# criterion and cues.
unit &lt;- unitWeightModel(data, 1, c(2,3))
rowPairApply(data, heuristics(ttb, unit))
# This outputs predictions with column names 'ttbModel' and
# 'unitWeightLinearModel'.

# Use the same fitted ttbModel plus another ttbModel that has different
# cols_to_fit.  This has to be put in a separate heuristicsList function.
ttb_just_col_3 &lt;- ttbModel(data, 1, c(3), fit_name="ttb3")
rowPairApply(data, heuristics(ttb), heuristics(unit))
# This outputs predictions with column names 'ttbModel' and
# 'ttb3'.

</code></pre>

<hr>
<h2 id='heuristicsList'>Wrapper for fitted heuristics to generate predictions with rowPairApply.</h2><span id='topic+heuristicsList'></span>

<h3>Description</h3>

<p>A list of fitted heuristics are passed in.  They must all implement
the fn function passed in, and they must all have the same cols_to_fit.
If they differ on these, then group them in separate heuristicsLists.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>heuristicsList(list_of_fitted_heuristics, fn)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="heuristicsList_+3A_list_of_fitted_heuristics">list_of_fitted_heuristics</code></td>
<td>
<p>Normally a list of predictProbInternal
implementers, e.g. a fitted ttb model.</p>
</td></tr>
<tr><td><code id="heuristicsList_+3A_fn">fn</code></td>
<td>
<p>The function to be called on the heuristics, which is typically
predictPairInternal (or the experimental function predictProbInternal)
but can be any function with the signature function(object, row1, row2)
that is implemented by the heuristics in list_of_fitted_heuristics.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Users will generally not use the output directly&ndash; instead just pass this
into one of the rowPairApply functions.
</p>


<h3>Value</h3>

<p>An object of class heuristics, which implements createFunction.
Users will generally not use this directly&ndash; rowPairApply will.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rowPairApply">rowPairApply</a></code> which is what the output of heuristicsList is
normally passed in to.
</p>
<p><code><a href="#topic+heuristics">heuristics</a></code> for a simpler version of this function with more
examples.  It is recommended for most uses.  (It is hard-coded for
fn=predictPairInternal, which is what most people use.)
</p>
<p><code><a href="#topic+heuristicsProb">heuristicsProb</a></code> for a version of this function tailored for
predictProbInternal rather than predictPairInternal.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Use one fitted ttbModel with column 1 as criterion and columns 2,3 as
# cues.
data &lt;- cbind(y=c(30,20,10,5), x1=c(1,1,0,0), x2=c(1,1,0,1))
ttb &lt;- ttbModel(data, 1, c(2:3))
rowPairApply(data, heuristicsList(list(ttb), predictPairInternal))
# This outputs ttb's predictions for all 6 row pairs of data.
# (It has 6 row pairs because 4*2/2 = 6.)  It gets the predictions
# by calling ttb's predictPairInternal.

# Use the same fitted ttbModel plus a unit weight model with the same
# criterion and cues.
unit &lt;- unitWeightModel(data, 1, c(2,3))
rowPairApply(data, heuristicsList(list(ttb, unit), predictPairInternal))
# This outputs predictions with column names 'ttbModel' and
# 'unitWeightLinearModel'.

# Use the same fitted ttbModel plus another ttbModel that has different
# cols_to_fit.  This has to be put in a separate heuristicsList function.
ttb_just_col_3 &lt;- ttbModel(data, 1, c(3), fit_name="ttb3")
rowPairApply(data, heuristicsList(list(ttb), predictPairInternal),
  heuristicsList(list(ttb_just_col_3), predictPairInternal))
# This outputs predictions with column names 'ttbModel' and
# 'ttb3'.

</code></pre>

<hr>
<h2 id='heuristicsProb'>Wrap fitted heuristics to pass to rowPairApply to call predictProb.</h2><span id='topic+heuristicsProb'></span>

<h3>Description</h3>

<p>One or more fitted heuristics can be passed in.  They must all implement
predictProbInternal.  Users will generally not use the output directly
but instead pass this to rowPairApply.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>heuristicsProb(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="heuristicsProb_+3A_...">...</code></td>
<td>
<p>A list of predictProbInternal implementers, e.g. a fitted ttb model.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class heuristics, which implements createFunction.
Users will generally not use this directly&ndash; rowPairApply will.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rowPairApply">rowPairApply</a></code> which is what heuristicsProb is passed in to.
</p>
<p><code><a href="#topic+predictProbInternal">predictProbInternal</a></code> which must be implemented by heuristics in
order to use them with the heuristicsProb() wrapper function.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## This is typical usage:
data &lt;- cbind(y=c(30,20,10,5), x1=c(1,1,0,0), x2=c(1,1,0,1))
ttb &lt;- ttbModel(data, 1, c(2:ncol(data)))
rowPairApply(data, heuristicsProb(ttb))
## This outputs ttb's predictions for all 6 row pairs of data.
## (It has 6 row pairs because 4*2/2 = 6.)  It gets the predictions
## by calling ttb's predictProbInternal.

</code></pre>

<hr>
<h2 id='highschool_dropout'>Chicago high school dropout rates.</h2><span id='topic+highschool_dropout'></span>

<h3>Description</h3>

<p>Chicago high school dropout rates from 1995 and associated variables
like average students per teacher and percent low income students.
All cues are real-valued but some have N/A values.  It includes rows
accidentally omitted in prior research.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>highschool_dropout
</code></pre>


<h3>Format</h3>

<p>A data frame.
</p>

<dl>
<dt>Name</dt><dd><p>Name of School</p>
</dd>
<dt>Running_Number</dt><dd><p>Running Number</p>
</dd>
<dt>Included_in_Web_and_Web_Corrected</dt><dd><p>If 1, then this row was
accidentally omitted in the ABC studies from 1993</p>
</dd>
<dt>Dropout_Rate</dt><dd><p>Dropout rate in percent, from 0 to 100, counting all
students in grades 9 through 12 who left school permanently during the
1993-4 school year</p>
</dd>
<dt>Completeness_of_Data</dt><dd><p>Completeness of data</p>
</dd>
<dt>Enrollment</dt><dd><p>Enrollment as of September 30, 1993</p>
</dd>
<dt>Attendance_Rate</dt><dd><p>Attendance rate in percent, from 0 to 100, averaged
over the school year</p>
</dd>
<dt>Graduation_Rate</dt><dd><p>Graduation rate in percent, from 0 to 100, based on
freshmen who finished together 4 years later, in 1994</p>
</dd>
<dt>Parental_Involvement_Rate</dt><dd><p>Parental involvement rate in percent,
from 0 to 100, counted as parents who had contact with teachers as a
percent of students (with no firm state rules on how to measure this)</p>
</dd>
<dt>Limited_English_Students</dt><dd><p>Limited English Students in percent, from
0 to 100, based on the number of students found eligible for bilingual
education</p>
</dd>
<dt>Low_Income_Students</dt><dd><p>Low Income Students in percent, from 0 to 100,
based on families eligible for free or reduced price lunches or are
publicly supported</p>
</dd>
<dt>Average_Class_Size_Student_per_Teacher</dt><dd><p>Calculated as number of
students divided by number of teachers on the first day of May</p>
</dd>
<dt>Percent_White_Students</dt><dd><p>Percent white students, from 0 to 100</p>
</dd>
<dt>Percent_Black_Students</dt><dd><p>Percent black students, from 0 to 100</p>
</dd>
<dt>Percent_Hispanic_Students</dt><dd><p>Percent hispanic students, from 0 to 100</p>
</dd>
<dt>Percent_Asian_Students</dt><dd><p>Percent asian students, from 0 to 100</p>
</dd>
<dt>Percent_Minority_Teacher</dt><dd><p>Percent minority teacher, from 0 to 100</p>
</dd>
<dt>Average_Composite_ACT_Score</dt><dd><p>Average composite ACT Score</p>
</dd>
<dt>Reading</dt><dd><p>Reading score on Illinois Goal Assessment Program (IGAP)</p>
</dd>
<dt>Math</dt><dd><p>Math score on IGAP</p>
</dd>
<dt>Science</dt><dd><p>Science score on IGAP</p>
</dd>
<dt>Social_Science</dt><dd><p>Social science score on IGAP</p>
</dd>
<dt>Writing</dt><dd><p>Writing score on IGAP</p>
</dd>
</dl>



<h3>Details</h3>

<p>The data is based on:
</p>
<p>Morton, Felicia B. (1995). Charting a School's Course. Chicago.
February, pp. 86-95.
</p>
<p>Rodkin, Dennis. (1995). 10 Keys for Creating Top High Schools.
Chicago. February, pp. 78-85.
</p>
<p>This is the data set used in simulations by the ABC (Adaptive Behavior
and Cognition) research group.
</p>

<hr>
<h2 id='lmWrapper'>Create an lm model just specifying columns, generating a formula for you.</h2><span id='topic+lmWrapper'></span>

<h3>Description</h3>

<p>Create an lm model just specifying columns, generating a formula for you.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lmWrapper(train_matrix, criterion_col, cols_to_fit, include_intercept = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lmWrapper_+3A_train_matrix">train_matrix</code></td>
<td>
<p>A matrix (or data.frame) of data to train (fit) the
model with.</p>
</td></tr>
<tr><td><code id="lmWrapper_+3A_criterion_col">criterion_col</code></td>
<td>
<p>The index of the criterion column&ndash; &quot;y&quot; in the formula.</p>
</td></tr>
<tr><td><code id="lmWrapper_+3A_cols_to_fit">cols_to_fit</code></td>
<td>
<p>A vector of column indexes to fit&ndash; the &quot;x's&quot; in the
formula.</p>
</td></tr>
<tr><td><code id="lmWrapper_+3A_include_intercept">include_intercept</code></td>
<td>
<p>A boolean of whether to include an intercept in
the formula.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class lm.
</p>

<hr>
<h2 id='logRegModel'>Logistic Regression model using cue differences as predictors</h2><span id='topic+logRegModel'></span>

<h3>Description</h3>

<p>Create a logistic regression model by specifying columns and a dataset.  It
fits the model with R's glm function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>logRegModel(
  train_data,
  criterion_col,
  cols_to_fit,
  cue_order_fn = rankByCueValidity,
  suppress_warnings = TRUE,
  fit_name = "logRegModel"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="logRegModel_+3A_train_data">train_data</code></td>
<td>
<p>Training/fitting data as a matrix or data.frame.</p>
</td></tr>
<tr><td><code id="logRegModel_+3A_criterion_col">criterion_col</code></td>
<td>
<p>The index of the column in train_data that has the
criterion.</p>
</td></tr>
<tr><td><code id="logRegModel_+3A_cols_to_fit">cols_to_fit</code></td>
<td>
<p>A vector of column indices in train_data, used to fit
the criterion.</p>
</td></tr>
<tr><td><code id="logRegModel_+3A_cue_order_fn">cue_order_fn</code></td>
<td>
<p>Optional argument as a function that orders cues.  This
only matters for overspecified models (e.g. too many cues for the number
of rows), in which case it affects which cues are dropped. The rightmost
cues in the order are dropped first, so the function rankByCueValidity
means cues with the lowest cueValidity in the training set will be
be dropped first.  The function must have the signature
function(train_data, criterion_col, cols_to_fit).</p>
</td></tr>
<tr><td><code id="logRegModel_+3A_suppress_warnings">suppress_warnings</code></td>
<td>
<p>Optional argument specifying whether glm warnings
should be suppressed or not. Default is TRUE.</p>
</td></tr>
<tr><td><code id="logRegModel_+3A_fit_name">fit_name</code></td>
<td>
<p>Optional The name other functions can use to label output.
It defaults to the class name.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This version assumes you do not want to include the intercept.
</p>
<p>For a discussion of how logistic regression works, see:
https://www.r-bloggers.com/what-does-a-generalized-linear-model-do/
Note that our criterion is the probability that row 1 is greater than row 2
when a pair is encountered.
</p>


<h3>Value</h3>

<p>An object of class logRegModel.
</p>

<hr>
<h2 id='minModel'>Minimalist Model</h2><span id='topic+minModel'></span>

<h3>Description</h3>

<p>Fit the Minimalist heuristic by specifying columns and a dataset. It
searches cues in a random order, making a decision based on the first cue
that discriminates (has differing values on the two objects).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>minModel(
  train_data,
  criterion_col,
  cols_to_fit,
  reverse_cues = TRUE,
  fit_name = "minModel"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="minModel_+3A_train_data">train_data</code></td>
<td>
<p>Training/fitting data as a matrix or data.frame.</p>
</td></tr>
<tr><td><code id="minModel_+3A_criterion_col">criterion_col</code></td>
<td>
<p>The index of the column in train_data that has the
criterion.</p>
</td></tr>
<tr><td><code id="minModel_+3A_cols_to_fit">cols_to_fit</code></td>
<td>
<p>A vector of column indices in train_data, used to fit
the criterion.</p>
</td></tr>
<tr><td><code id="minModel_+3A_reverse_cues">reverse_cues</code></td>
<td>
<p>Optional parameter to reverse cues as needed.  By
default, the model will reverse the cue values for cues with cue validity
&lt; 0.5, so a cue with validity 0 becomes a cue with validity 1.
Set this to FALSE if you do not want that, i.e. the cue stays validity 0.</p>
</td></tr>
<tr><td><code id="minModel_+3A_fit_name">fit_name</code></td>
<td>
<p>Optional The name other functions can use to label output.
It defaults to the class name.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of <code><a href="base.html#topic+class">class</a></code> minModel, which can be
passed to a variety of functions to make predictions, e.g.
<code><a href="#topic+predictPair">predictPair</a></code> and <code><a href="#topic+percentCorrectList">percentCorrectList</a></code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+predictPairProb">predictPairProb</a></code> for prediction.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Fit column (5,4) to column (1,0), having validity 1.0, and column (0,1),
## validity 0.
train_matrix &lt;- cbind(c(5,4), c(1,0), c(0,1))
min &lt;- minModel(train_matrix, 1, c(2,3))
predictPair(oneRow(train_matrix, 1), oneRow(train_matrix, 2), min)

</code></pre>

<hr>
<h2 id='oneRow'>Convenience function to get one row from a matrix or data frame.</h2><span id='topic+oneRow'></span>

<h3>Description</h3>

<p>This simply calls matrix_or_data_frame[row_index,,drop=FALSE] for you
but is shorter and helps you avoid forgetting drop=FALSE.  The need
for drop=FALSE when selecting just one row is explained here:
http://www.hep.by/gnu/r-patched/r-faq/R-FAQ_56.html
</p>


<h3>Usage</h3>

<pre><code class='language-R'>oneRow(matrix_or_data_frame, row_index)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="oneRow_+3A_matrix_or_data_frame">matrix_or_data_frame</code></td>
<td>
<p>A matrix or data frame from which you want one
row.</p>
</td></tr>
<tr><td><code id="oneRow_+3A_row_index">row_index</code></td>
<td>
<p>The integer index of the row</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The selected row of the data frame.
</p>

<hr>
<h2 id='pairMatrix'>Apply a function to all unique pairs of row indices up to num_row.</h2><span id='topic+pairMatrix'></span>

<h3>Description</h3>

<p>Apply a function to all unique pairs of row indices up to num_row.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pairMatrix(num_row, pair_evaluator_fn, also_reverse_row_pairs = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pairMatrix_+3A_num_row">num_row</code></td>
<td>
<p>The number of rows to generate index pairs for.</p>
</td></tr>
<tr><td><code id="pairMatrix_+3A_pair_evaluator_fn">pair_evaluator_fn</code></td>
<td>
<p>The function you want applied.  It should
accept a list of two numbers, the index of row 1 and the index of row2.</p>
</td></tr>
<tr><td><code id="pairMatrix_+3A_also_reverse_row_pairs">also_reverse_row_pairs</code></td>
<td>
<p>Optional parameter.  When it has its default
value of FALSE, it will apply every function only once to any given row
pair, e.g. myFunction(1, 2).  When it is true, it will also apply
the function to every reverse row pair, e.g. myFunction(1, 2) and
myFunction(2, 1).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix of the output of the function for all unique row pairs:
c(pair_evaluator_fn(c(1,2), pair_evaluator_fn(c(1,3)), etc.)
</p>

<hr>
<h2 id='percentCorrect'>Percent correct of heuristics' predictPair on test_data.</h2><span id='topic+percentCorrect'></span>

<h3>Description</h3>

<p>Returns overall percent correct for all heuristics.
1. Create predictions using predictPair for all row pairs for all
fitted heuristics in the list.
2. Calculate percent correct for each heuristic.
Assumes the heuristics passed in have already been fitted to training
data and all have the same criterion column.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>percentCorrect(test_data, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="percentCorrect_+3A_test_data">test_data</code></td>
<td>
<p>Data to try to predict.  Must have same criterion column
and cols_to_fit as the data heuristics were fit to.</p>
</td></tr>
<tr><td><code id="percentCorrect_+3A_...">...</code></td>
<td>
<p>One or more heuristics fitted to
data, e.g. the output of ttbModel.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In cases where a heuristic guesses (predictPair outputs 0), percentCorrect
will use the expected value, so output will be deterministic and repeatable.
That is, if 10 guesses happen across the data set, percentCorrect will always
allocate 5 to 1 and 5 to -1.
</p>


<h3>Value</h3>

<p>A one-row data.frame of numbers from 0 to 100, the percent correc
of each heuristic.  Each column is named with the heuristic's class or
the fit name.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+percentCorrectList">percentCorrectList</a></code> for a version which takes a list of
heuristics.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>df &lt;- data.frame(y=c(30,20,10,5), name=c("a", "b", "c", "d"),
                 x1=c(1,1,0,0), x2=c(1,1,0,1))
ttb &lt;- ttbModel(df, 1, c(3:4))
sing &lt;- singleCueModel(df, 1, c(3:4))
percentCorrect(df, ttb, sing)
#    ttbModel singleCueModel
#  1     0.75      0.8333333
# TTB gets 75% correct while single cue model gets 83%.

# Now repeatedly sample 2 rows of the data set and see how outcomes are
# affected, tracking with the fit_name.
set.seed(1) # If you want to reproduce the same output as below.
ttb1 &lt;- ttbModel(df[sample(nrow(df), 2),], 1, c(3:4), fit_name="fit1")
ttb2 &lt;- ttbModel(df[sample(nrow(df), 2),], 1, c(3:4), fit_name="fit2")
ttb3 &lt;- ttbModel(df[sample(nrow(df), 2),], 1, c(3:4), fit_name="fit3")
percentCorrect(df, ttb1, ttb2, ttb3)
#        fit1 fit2 fit3
# 1 0.8333333 0.75 0.75

</code></pre>

<hr>
<h2 id='percentCorrectList'>Percent correct of a list of heuristics' predictPair on test_data.</h2><span id='topic+percentCorrectList'></span>

<h3>Description</h3>

<p>Returns overall percent correct for all heuristics.
1. Create predictions using predictPair for all row pairs for all
fitted heuristics in the list.
2. Calculate percent correct for each heuristic.
Assumes the heuristics passed in have already been fitted to training
data and all have the same criterion column.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>percentCorrectList(test_data, fitted_heuristic_list)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="percentCorrectList_+3A_test_data">test_data</code></td>
<td>
<p>Data to try to predict.  Must have same criterion column
and cols_to_fit as the data heuristics were fit to.</p>
</td></tr>
<tr><td><code id="percentCorrectList_+3A_fitted_heuristic_list">fitted_heuristic_list</code></td>
<td>
<p>A list of one or more heuristics fitted to
data, e.g. the output of ttbModel.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A one-row data.frame of numbers from 0 to 100, the percent correc
of each heuristic.  Each column is named with the heuristic's class or
the fit name.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+percentCorrectList">percentCorrectList</a></code> for a version which takes heuristics
as parameters rather than wrapped in a list.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>df &lt;- data.frame(y=c(30,20,10,5), name=c("a", "b", "c", "d"),
                 x1=c(1,1,0,0), x2=c(1,1,0,1))
ttb &lt;- ttbModel(df, 1, c(3:4))
sing &lt;- singleCueModel(df, 1, c(3:4))
percentCorrectList(df, list(ttb, sing))
#    ttbModel singleCueModel
#  1     0.75      0.8333333
# TTB gets 75% correct while single cue model gets 83%.

# Now repeatedly sample 2 rows of the data set and see how outcomes are
# affected, tracking with the fit_name.
set.seed(1) # If you want to reproduce the same output as below.
ttb1 &lt;- ttbModel(df[sample(nrow(df), 2),], 1, c(3:4), fit_name="fit1")
ttb2 &lt;- ttbModel(df[sample(nrow(df), 2),], 1, c(3:4), fit_name="fit2")
ttb3 &lt;- ttbModel(df[sample(nrow(df), 2),], 1, c(3:4), fit_name="fit3")
percentCorrectList(df, list(ttb1, ttb2, ttb3))
#        fit1 fit2 fit3
# 1 0.8333333 0.75 0.75

</code></pre>

<hr>
<h2 id='percentCorrectListNonSymmetric'>percentCorrectList for non-symmetric heuristics</h2><span id='topic+percentCorrectListNonSymmetric'></span>

<h3>Description</h3>

<p>Same as percentCorrectList but for weird heuristics that do not
consistently choose the same row.  When a symmetric heuristic predicts
row1 &gt; row2, then it also predicts row2 &lt; row1.  Those can be used
with percentCorrectList.  All heuristics built into heuristica
qualify.  They will get the same answers for percentCorrectList
and percentCorrectListNonSymmetric.  But a non-symmetric heuristic
will only get correct answers for percentCorrectListNonSymmetric.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>percentCorrectListNonSymmetric(test_data, fitted_heuristic_list)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="percentCorrectListNonSymmetric_+3A_test_data">test_data</code></td>
<td>
<p>Data to try to predict.  Must have same criterion column
and cols_to_fit as the data heuristics were fit to.</p>
</td></tr>
<tr><td><code id="percentCorrectListNonSymmetric_+3A_fitted_heuristic_list">fitted_heuristic_list</code></td>
<td>
<p>A list of one or more heuristics fitted to
data, e.g. the output of ttbModel.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A one-row data.frame of numbers from 0 to 100, the percent correc
of each heuristic.  Each column is named with the heuristic's class or
the fit name.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+percentCorrectList">percentCorrectList</a></code> which is faster but wil only be accurate
for symmetric heuristics.  (percentCorrectListNonSymmetric will be
accurate for both symmetric and non-symmetric heuristics, but it's slower.)
</p>

<hr>
<h2 id='percentCorrectListReturnMatrix'>Percent correct of heuristics' predictPair on test_data, returning a matrix.</h2><span id='topic+percentCorrectListReturnMatrix'></span>

<h3>Description</h3>

<p>Percent correct of heuristics' predictPair on test_data, returning a matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>percentCorrectListReturnMatrix(test_data, fitted_heuristic_list)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="percentCorrectListReturnMatrix_+3A_test_data">test_data</code></td>
<td>
<p>Data to try to predict.  Must have same criterion column
and cols_to_fit as the data heuristics were fit to.</p>
</td></tr>
<tr><td><code id="percentCorrectListReturnMatrix_+3A_fitted_heuristic_list">fitted_heuristic_list</code></td>
<td>
<p>A list of one or more heuristics fitted to
data, e.g. the output of ttbModel.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A one-row matrix of numbers from 0 to 100, the percent correct
of each heuristic.  Each column is named with the heuristic's class or
the fit name.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+percentCorrectList">percentCorrectList</a></code> for a version that returns a
data.frame and includes several examples.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># See examples for percentCorrectList, which returns a data.frame.

</code></pre>

<hr>
<h2 id='predictPair'>Predict which of a pair of rows has a higher criterion.</h2><span id='topic+predictPair'></span>

<h3>Description</h3>

<p>Given two rows and a fitted heuristic, returns the heuristic's prediction
of whether the criterion of the first row will be greater than that of
the 2nd row.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>predictPair(row1, row2, object)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predictPair_+3A_row1">row1</code></td>
<td>
<p>The first row of data.  The cues object$cols_to_fit will be
passed to the heuristic.</p>
</td></tr>
<tr><td><code id="predictPair_+3A_row2">row2</code></td>
<td>
<p>The second row of data.  The cues object$cols_to_fit will be
passed to the heuristic.</p>
</td></tr>
<tr><td><code id="predictPair_+3A_object">object</code></td>
<td>
<p>The fitted heuristic, e.g. a fitted ttbModel or logRegModel.
(More technically, it's any object that implements predictPairInternal.)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A number in the set -1, 0, 1, where 1 means row1 is predicted to
have a greater criterion, -1 means row2 is greater, and 0 is a guess or
tie.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rowPairApply">rowPairApply</a></code> to get predictions for all row pairs of a
matrix or data.frame.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##Fit column (5,4) to column (1,0), having validity 1.0, and column (0,1),
## validity 0.
train_matrix &lt;- cbind(y=c(5,4), x1=c(1,0), x2=c(0,1))
singlecue &lt;- singleCueModel(train_matrix, 1, c(2,3))
predictPair(oneRow(train_matrix, 1), oneRow(train_matrix, 2), singlecue)

</code></pre>

<hr>
<h2 id='predictPairInternal'>Generic function to predict which of a pair of rows has a higher criterion.</h2><span id='topic+predictPairInternal'></span>

<h3>Description</h3>

<p>Do not call this directly (which is why it is called &quot;internal&quot;).
Instead, call predictPair.  Heuristics implement this function in order to
be callable with predictPair.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>predictPairInternal(object, row1, row2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predictPairInternal_+3A_object">object</code></td>
<td>
<p>The object that implements predictPair, e.g. a ttb model.</p>
</td></tr>
<tr><td><code id="predictPairInternal_+3A_row1">row1</code></td>
<td>
<p>The first row of cues (object$cols_to_fit columns), as a
one-row matrix.</p>
</td></tr>
<tr><td><code id="predictPairInternal_+3A_row2">row2</code></td>
<td>
<p>The second row of cues.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A number in the set -1, 0, 1, where 1 means row1 is predicted to
have a greater criterion, -1 means row2 is greater, and 0 is a tie.
</p>

<hr>
<h2 id='predictPairProb'>Predict the probability that row1 has a higher criterion than row2.</h2><span id='topic+predictPairProb'></span>

<h3>Description</h3>

<p>Given two rows and a fitted heuristic, returns the heuristic's predicted
probability that row1's criterion will be greater than row2's.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>predictPairProb(row1, row2, object)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predictPairProb_+3A_row1">row1</code></td>
<td>
<p>The first row of cues (will apply cols_to_fit for you, based on
object).</p>
</td></tr>
<tr><td><code id="predictPairProb_+3A_row2">row2</code></td>
<td>
<p>The second row (will apply cols_to_fit for you, based on
object).</p>
</td></tr>
<tr><td><code id="predictPairProb_+3A_object">object</code></td>
<td>
<p>The fitted heuristic, e.g. a fitted ttbModel or logRegModel.
(More technically, it's any object that implements predictProbInternal.)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A double from 0 to 1, representing the probability that row1's
criterion is greater than row2's criterion.  0.5 could be a guess or tie.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rowPairApply">rowPairApply</a></code> to get predictions for all row pairs of a
matrix or data.frame.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>train_matrix &lt;- cbind(y=c(5,4), x1=c(1,0), x2=c(0,1))
lreg &lt;- logRegModel(train_matrix, 1, c(2,3))
predictPairProb(oneRow(train_matrix, 1), oneRow(train_matrix, 2), lreg)

</code></pre>

<hr>
<h2 id='predictPairSummary'>Returns the row indices, correct answer, and predictions for all row pairs.</h2><span id='topic+predictPairSummary'></span>

<h3>Description</h3>

<p>This makes it easy to see and evaluate predictions for all row pairs on
a data set.  It is intended for beginners.  Advanced users can get more
fine-grained control with rowPairApply.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>predictPairSummary(test_data, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predictPairSummary_+3A_test_data">test_data</code></td>
<td>
<p>Data to try to predict.  Must have same criterion column
and cols_to_fit as the data heuristics were fit to.</p>
</td></tr>
<tr><td><code id="predictPairSummary_+3A_...">...</code></td>
<td>
<p>One or more heuristics already fitted to data, e.g. the output
of ttbModel.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix with output for indices, the correct row pair answer, and
predictions for each heuristic with as many rows as row pairs in the data.
The columns names are Row1, Row2, CorrectGreater, and each heuristic fit_name
(which is its class name by default, e.g. ttbModel).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rowPairApply">rowPairApply</a></code> for full flexibility.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Get some data and fit it with two models.
train_df &lt;- data.frame(criterion=c(9,8,7,6), a=c(101,101,2,2), b=c(59,58,5,59))
criterion_col &lt;- 1
ttb &lt;- ttbModel(train_df, criterion_col, c(2:3))
lreg &lt;- logRegModel(train_df, criterion_col, c(2:3))

# Generate predictions and correct answers with predictPairSummary.
out &lt;- predictPairSummary(train_df, ttb, lreg)

# Find rows where the models make differing predictions, subsetting on a
# data.frame.
out_df &lt;- data.frame(out)
out_df[out_df$ttbModel != out_df$logRegModel,]
# Outputs:
#   Row1 Row2 CorrectGreater ttbModel logRegModel
#    1    2              1        1          -1
#    3    4              1       -1           1
# So there are only two cases of differing predictions.
# 1) For row 1 vs. 2, TTB predicted 1 and logReg predicted -1.
#    CorrectGreater says 1, so TTB was right.
# 2) For row 3 vs. 4, TTB predicted -1 and logReg predicted 1.
#    CorrectGreater says -1, so logReg was right.

# Note that under the hood, the above predictPairSummary call could be
# done with rowPairApply like this:
out2 &lt;- rowPairApply(train_df, rowIndexes(),
                     correctGreater(criterion_col), heuristics(ttb, lreg))

</code></pre>

<hr>
<h2 id='predictProbInternal'>Generic function to predict the probability row 1 has a higher criterion.</h2><span id='topic+predictProbInternal'></span>

<h3>Description</h3>

<p>Do not call this directly (which is why it is called &quot;internal&quot;).
Instead, call predictPairProb.  Heuristics implement this function in order
to be callable with predictPairProb.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>predictProbInternal(object, row1, row2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predictProbInternal_+3A_object">object</code></td>
<td>
<p>The object that implements predictPair, e.g. a ttb model.</p>
</td></tr>
<tr><td><code id="predictProbInternal_+3A_row1">row1</code></td>
<td>
<p>The first row of cues (object$cols_to_fit columns), as a
one-row matrix.</p>
</td></tr>
<tr><td><code id="predictProbInternal_+3A_row2">row2</code></td>
<td>
<p>The second row of cues.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Most heuristics have not implemented this.  Also, the output cannot (and
should not) be assessed with categorical measures like percent correct.
</p>


<h3>Value</h3>

<p>A value from 0 to 1, representing the probability that row1's
criterion is greater than row2's criterion.
</p>

<hr>
<h2 id='probGreater'>Creates function for one column with correct probability row1 is greater.</h2><span id='topic+probGreater'></span>

<h3>Description</h3>

<p>Using rowPairApply, this can generate a column with
the correct probability that row 1 &gt; row 2 for each row pair in 
the test_data.  It can do this using the criterion column passed in.
By default, the output column is called &quot;ProbGreater,&quot; but you
can override the name with output_column_name.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>probGreater(criterion_col, output_column_name = "ProbGreater")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="probGreater_+3A_criterion_col">criterion_col</code></td>
<td>
<p>The integer index of the criterion in test_data.</p>
</td></tr>
<tr><td><code id="probGreater_+3A_output_column_name">output_column_name</code></td>
<td>
<p>An optional string</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Note this uses a very simplistic &quot;probability&quot; which only looks at
the current row pair.  It does not look at all sets of row pairs
with the same profile.
</p>


<h3>Value</h3>

<p>An object that implements createFunction.
Users will generally not use this directly&ndash; rowPairApply will.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+heuristicsProb">heuristicsProb</a></code> is the wrapper to get the predicted probability
that the first row in the row pair is greater, with output for each fitted
heuristic passed to it.
</p>
<p><code><a href="#topic+rowPairApply">rowPairApply</a></code> which has examples of using this.
</p>

<hr>
<h2 id='regInterceptModel'>Linear regression wrapper for hueristica</h2><span id='topic+regInterceptModel'></span>

<h3>Description</h3>

<p>A wrapper to create a lm model just specifying columns, generating
a model formula for you.  This makes it easier to run automated comparisons
with other models in heuristica.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>regInterceptModel(train_matrix, criterion_col, cols_to_fit)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="regInterceptModel_+3A_train_matrix">train_matrix</code></td>
<td>
<p>A matrix (or data.frame) of data to train (fit) the
model with.</p>
</td></tr>
<tr><td><code id="regInterceptModel_+3A_criterion_col">criterion_col</code></td>
<td>
<p>The index of the criterion column&ndash; &quot;y&quot; in the formula.</p>
</td></tr>
<tr><td><code id="regInterceptModel_+3A_cols_to_fit">cols_to_fit</code></td>
<td>
<p>A vector of column indexes to fit&ndash; the &quot;x's&quot; in the
formula.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This version assumes you always want to include the intercept.
</p>


<h3>Value</h3>

<p>An object of class regInterceptModel, which is a subclass of lm.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+regModel">regModel</a></code> for a version that excludes the intercept.
</p>
<p><code><a href="stats.html#topic+predict.lm">predict.lm</a></code> for prediction.
</p>
<p><code><a href="#topic+predictPairProb">predictPairProb</a></code> for predicting between a pair of rows.
</p>

<hr>
<h2 id='regModel'>Linear regression (no intercept) wrapper for hueristica</h2><span id='topic+regModel'></span>

<h3>Description</h3>

<p>A wrapper to create a lm model just specifying columns, generating
a model formula for you __without an intercept__.
This makes it easier to run automated comparisons with
other models in heuristica.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>regModel(train_matrix, criterion_col, cols_to_fit, fit_name = "regModel")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="regModel_+3A_train_matrix">train_matrix</code></td>
<td>
<p>A matrix (or data.frame) of data to train (fit) the
model with.</p>
</td></tr>
<tr><td><code id="regModel_+3A_criterion_col">criterion_col</code></td>
<td>
<p>The index of the criterion column&ndash; &quot;y&quot; in the formula.</p>
</td></tr>
<tr><td><code id="regModel_+3A_cols_to_fit">cols_to_fit</code></td>
<td>
<p>A vector of column indexes to fit&ndash; the &quot;x's&quot; in the
formula.</p>
</td></tr>
<tr><td><code id="regModel_+3A_fit_name">fit_name</code></td>
<td>
<p>Optional The name other functions can use to label output.
It defaults to the class name.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This version assumes you do NOT want to include the intercept.
Excluding the intercept typically has higher out-of-sample accuracy if the
goal is predicting rank order because the intercept does not affect the
ranking, but estimating it wastes a degree of freedom.
</p>


<h3>Value</h3>

<p>An object of class regModel, which is a subclass of lm.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+lm">lm</a></code> for the regression function being wrapped.
</p>
<p><code><a href="#topic+predictPair">predictPair</a></code> for predicting whether row1 is greater.
greater.
</p>

<hr>
<h2 id='reverseRowsAndReverseColumns'>Reverse rows and columns of data</h2><span id='topic+reverseRowsAndReverseColumns'></span>

<h3>Description</h3>

<p>This matrix
[,1] [,2]
[1,]    1    2
[2,]    3    4
becomes
[,1] [,2]
[1,]    4    3
[2,]    2    1
</p>


<h3>Usage</h3>

<pre><code class='language-R'>reverseRowsAndReverseColumns(data)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="reverseRowsAndReverseColumns_+3A_data">data</code></td>
<td>
<p>A data.frame or matrix.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data.frame or matrix with rows reversed and columns reversed.
</p>

<hr>
<h2 id='rowIndexes'>Wrapper to output two columns, row 1 and row 2.</h2><span id='topic+rowIndexes'></span>

<h3>Description</h3>

<p>Using rowPairApply, this can generate two columns, which by default
are called &quot;Row1&quot; and &quot;Row2&quot;
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rowIndexes(rowIndexColNames = c("Row1", "Row2"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rowIndexes_+3A_rowindexcolnames">rowIndexColNames</code></td>
<td>
<p>An optional vector of 2 strings for column names.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class rowIndexes, which implements createFunction.
Users will generally not use this directly&ndash; rowPairApply will.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+createFunction">createFunction</a></code> which is what the returned object implements.
</p>
<p><code><a href="#topic+rowPairApply">rowPairApply</a></code> which uses createFunction.
</p>

<hr>
<h2 id='rowPairApply'>Apply functions to all row pairs.</h2><span id='topic+rowPairApply'></span>

<h3>Description</h3>

<p>Apply functions like heuristic predictions to all row pairs in a matrix
or data.frame.  This does not accept arbitrary functions&ndash; they must be
functions designed to be run by rowPairApply.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rowPairApply(test_data, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rowPairApply_+3A_test_data">test_data</code></td>
<td>
<p>The data to apply the functions to as a matrix or
data.frame.  Heuristics must have already been fitted to trying data and
must include the same criterion_col and cols_to_fit.</p>
</td></tr>
<tr><td><code id="rowPairApply_+3A_...">...</code></td>
<td>
<p>The functions that generate the functions to apply, such as
heuristics(ttb) and correctGreater(col)&ndash; see example below.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix of outputs from the functions.  The number of rows is based
on the number of row pairs in test_data.  If the input has N rows, the
output will have N x (N-1) rows.  The number of columns will be at least
the number of functions but may be more as some functions may output more
than one column.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+heuristics">heuristics</a></code> and <code><a href="#topic+heuristics">heuristics</a></code> to wrap heuristics
to be applied.
</p>
<p><code><a href="#topic+rowIndexes">rowIndexes</a></code> to get apply to output row indexes for the pair.
</p>
<p><code><a href="#topic+correctGreater">correctGreater</a></code> to get the correct output based on the criterion column.
(CorrectGreater should be used with heuristics while probGreater should be used with
heuristicsProb.)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Fit two models to data.
data &lt;- cbind(y=c(30,20,10,5), x1=c(1,1,0,0), x2=c(1,1,0,1))
ttb &lt;- ttbModel(data, 1, c(2:ncol(data)))
lreg &lt;- logRegModel(data, 1, c(2:ncol(data)))

## Generate predictions for all row pairs for these two models:
rowPairApply(data, heuristics(ttb, lreg))
## Returns a matrix of 2 columns, named ttbModel and regModel, and 6 rows.
## The original data had 4 rows, meaning there are 4*3/2 = 6 row pairs.

## To see which row pair is which row, use rowIndexes:
rowPairApply(data, rowIndexes(), heuristics(ttb, lreg))
## Returns a matrix with columns Row1, Row2, ttbModel, logRegModel.
## (RowIndexes returns *two* columns.)

## To see whether the first row was actually greater than the second in the
## row pair, use correctGreater and give it the criterion column index, in
## this case 1.
rowPairApply(data, heuristics(lreg, ttb), correctGreater(1))
## Returns a matrix with columns logRegModel, ttbModel,
## CorrectGreater.  Values are -1, 0, or 1.

## To do the same analysis for the *probabilty* that the first row is
## greater. use heuristicsProb and probGreater.  Warning: Not all heuristica
## models have implemented the prob greater function.
rowPairApply(data, heuristicsProb(lreg, ttb), probGreater(1))
## Returns a matrix with columns logRegModel, ttbModel, ProbGreater.
## Values range from 0.0 to 1.0.

</code></pre>

<hr>
<h2 id='rowPairApply2Rows'>Apply all functions to the two rows passed in.</h2><span id='topic+rowPairApply2Rows'></span>

<h3>Description</h3>

<p>This has some asserts that exactly one row is passed in and exaclty one row
is returned, but otherwise it just calls rowPairApply.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rowPairApply2Rows(row1, row2, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rowPairApply2Rows_+3A_row1">row1</code></td>
<td>
<p>The first row of cues (will apply cols_to_fit for you, based
on object).</p>
</td></tr>
<tr><td><code id="rowPairApply2Rows_+3A_row2">row2</code></td>
<td>
<p>The second row (will apply cols_to_fit for you, based on
object).</p>
</td></tr>
<tr><td><code id="rowPairApply2Rows_+3A_...">...</code></td>
<td>
<p>The functions that generate the functions to apply, such as
heuristics(ttb) and correctGreater(col).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix of function outputs.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rowPairApply">rowPairApply</a></code> to apply to all row pairs in a matrix or
data.frame.
</p>

<hr>
<h2 id='rowPairApplyList'>Apply list of functions to all row pairs.</h2><span id='topic+rowPairApplyList'></span>

<h3>Description</h3>

<p>Apply a list of functions like heuristic predictions to all row pairs in a
matrix or data.frame.  This does not accept arbitrary functions&ndash; they must
be functions designed to be run by rowPairApply.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rowPairApplyList(
  test_data,
  function_creator_list,
  also_reverse_row_pairs = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rowPairApplyList_+3A_test_data">test_data</code></td>
<td>
<p>The data to apply the functions to as a matrix or
data.frame.  Heuristics must have already been fitted to trying data and
must include the same criterion_col and cols_to_fit.</p>
</td></tr>
<tr><td><code id="rowPairApplyList_+3A_function_creator_list">function_creator_list</code></td>
<td>
<p>List of the functions that generate the
functions to apply, such as heuristics(ttb) and correctGreater(col).</p>
</td></tr>
<tr><td><code id="rowPairApplyList_+3A_also_reverse_row_pairs">also_reverse_row_pairs</code></td>
<td>
<p>Optional parameter.  When it has its default
value of FALSE, it will apply every function only once to any given row
pair, e.g. myFunction(row1, row2).  When it is true, it will also apply
the function to every reverse row pair, e.g. myFunction(row2, row1).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix of outputs from the functions.  The number of rows is based
on the number of row pairs in test_data.  If the input has N rows, the
output will have N x (N-1) rows.  The number of columns will be at least
the number of functions but may be more as some functions may output more
than one column.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rowPairApply">rowPairApply</a></code> for no need to use a list.  Examples and details
are there.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># This function is called like 
# rowPairApplyList(data, list(heuristics(ttb, reg)))
# instead of
# rowPairApply(data, heuristics(ttb, reg))
# See rowPairApply for details.

</code></pre>

<hr>
<h2 id='singleCueModel'>Single Cue Model</h2><span id='topic+singleCueModel'></span>

<h3>Description</h3>

<p>Create a single cue model by specifying columns and a dataset.  It sorts
cues in order of cueValidity and uses the cue with the highest cueValidity.
If the cue does not discriminate it guesses randomly.  If several cues have
the highest validity, then on each prediction it randomly selects which one
to use (so it might not give the same answer every time).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>singleCueModel(
  train_data,
  criterion_col,
  cols_to_fit,
  reverse_cues = TRUE,
  fit_name = "singleCueModel"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="singleCueModel_+3A_train_data">train_data</code></td>
<td>
<p>Training/fitting data as a matrix or data.frame.</p>
</td></tr>
<tr><td><code id="singleCueModel_+3A_criterion_col">criterion_col</code></td>
<td>
<p>The index of the column in train_data that has the
criterion.</p>
</td></tr>
<tr><td><code id="singleCueModel_+3A_cols_to_fit">cols_to_fit</code></td>
<td>
<p>A vector of column indices in train_data, used to fit
the criterion.</p>
</td></tr>
<tr><td><code id="singleCueModel_+3A_reverse_cues">reverse_cues</code></td>
<td>
<p>Optional parameter to reverse cues as needed.  By
default, the model will reverse the cue values for cues with cue validity
&lt; 0.5, so a cue with validity 0 becomes a cue with validity 1.
Set this to FALSE if you do not want that, i.e. the cue stays validity 0.</p>
</td></tr>
<tr><td><code id="singleCueModel_+3A_fit_name">fit_name</code></td>
<td>
<p>Optional The name other functions can use to label output.
It defaults to the class name.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This single cue model follows the definition used in this reference:
Hogarth, R. &amp; Karelaia, N. (2007). Heuristic and Linear Models of Judgment: 
Matching Rules and Environments. Psychological Review. 114(3), pp.733-758.
Note that other researchers have sometimes used other measures than cue
validity to select the single cue to be used.
</p>


<h3>Value</h3>

<p>An object of <code><a href="base.html#topic+class">class</a></code> singleCueModel, which can be
passed to a variety of functions to make predictions, e.g.
<code><a href="#topic+predictPair">predictPair</a></code> and <code><a href="#topic+percentCorrectList">percentCorrectList</a></code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+predictPairProb">predictPairProb</a></code> for prediction.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##Fit column (5,4) to column (1,0), having validity 1.0, and column (0,1),
## validity 0.
train_matrix &lt;- cbind(y=c(5,4), x1=c(1,0), x2=c(0,1))
singlecue &lt;- singleCueModel(train_matrix, 1, c(2,3))
predictPair(oneRow(train_matrix, 1), oneRow(train_matrix, 2), singlecue)

</code></pre>

<hr>
<h2 id='statsFromConfusionMatrix'>Accuracy, sensitivity, specificity, and precision of 2x2 confusion matrix.</h2><span id='topic+statsFromConfusionMatrix'></span>

<h3>Description</h3>

<p>In heuristica, &quot;positive&quot; means the row1 &gt; row2.  Other heuristica create
confusion matrices with the expected layout, but below is documentation of
that layout.  A package like 'caret' offers a more general-purpose
confusion matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>statsFromConfusionMatrix(confusion_matrix)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="statsFromConfusionMatrix_+3A_confusion_matrix">confusion_matrix</code></td>
<td>
<p>A 2x2 confusion matrix.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This assumes the input matrix is 2x2 and will STOP if not.  It also 
assumes negatives are left and higher, and predictions are the rows,
that is:
true negative  [-1,-1]    false negative [-1,1]
false negative [1, -1]    true positive  [1, 1]
</p>
<p>The outputs are defined as:
accuracy = (true positive + true negative) / all
sensitivity = true positive rate = true positive / all positive
(sensitivity is also called recall)
specificity = true negative rate = true negative / all negative
precision = positive predictive value = true positive
</p>


<h3>Value</h3>

<p>A list with accuracy, sensitivity, specificity, and precision
</p>

<hr>
<h2 id='ttbGreedyModel'>Greedy Take The Best</h2><span id='topic+ttbGreedyModel'></span>

<h3>Description</h3>

<p>A variant of the Take The Best heuristic with a different cue order, namely
using conditional cue validity, where the validity of a cue is judged only
on row pairs not already decided by prior cues.  Specifically, it uses the
cue ranks returned by <code><a href="#topic+conditionalCueValidityComplete">conditionalCueValidityComplete</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ttbGreedyModel(
  train_data,
  criterion_col,
  cols_to_fit,
  fit_name = "ttbGreedyModel"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ttbGreedyModel_+3A_train_data">train_data</code></td>
<td>
<p>Training/fitting data as a matrix or data.frame.</p>
</td></tr>
<tr><td><code id="ttbGreedyModel_+3A_criterion_col">criterion_col</code></td>
<td>
<p>The index of the column in train_data that has the
criterion.</p>
</td></tr>
<tr><td><code id="ttbGreedyModel_+3A_cols_to_fit">cols_to_fit</code></td>
<td>
<p>A vector of column indices in train_data, used to fit
the criterion.</p>
</td></tr>
<tr><td><code id="ttbGreedyModel_+3A_fit_name">fit_name</code></td>
<td>
<p>Optional The name other functions can use to label output.
It defaults to the class name.  It is useful to change this to a unique name
if you are making multiple fits, e.g. &quot;ttb1&quot;, &quot;ttb2&quot;, &quot;ttbNoReverse.&quot;</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of <code><a href="base.html#topic+class">class</a></code> ttbGreedyModel, which can
be passed in to <code><a href="#topic+predictPair">predictPair</a></code>.
</p>


<h3>References</h3>

<p>Martignon, L., &amp; Hoffrage, U.  (2002).  Fast, frugal, and fit: Simple
heuristics for paired comparisons.  Theory and Decision, 52: 29-71.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+conditionalCueValidityComplete">conditionalCueValidityComplete</a></code> for the metric used to sort cues.
</p>
<p><code><a href="#topic+ttbModel">ttbModel</a></code> for the original version of Take The Best.
</p>
<p><code><a href="#topic+predictPair">predictPair</a></code> for predicting whether row1 is greater.
</p>
<p><code><a href="#topic+predictPairProb">predictPairProb</a></code> for predicting the probability row1 is
greater.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## A data set where Take the Best and Greedy Take the Best disagree.
matrix &lt;- cbind(y=c(3:1), x1=c(1,0,0), x2=c(1,0,1))
ttb &lt;- ttbModel(matrix, 1, c(2,3))
ttb$cue_validities
# Returns
#  x1  x2 
# 1.0 0.5
ttbG &lt;- ttbGreedyModel(matrix, 1, c(2:3))
ttbG$cue_validities
# Returns
#  x1  x2 
#   1   1
# because after using x1, only decisions between row 2 and 3 are left,
# and x2 gets 100% right  on those (after reversal).  However, these
# cue_validities depend on using x1, first, so cue_rank is key.
ttbG$cue_ranks
# Returns
#  x1  x2 
#   1   2

# Now see how this affects predictions on row 2 vs. 3.
# Take the best guesses (output 0).
predictPair(oneRow(matrix, 2), oneRow(matrix, 3), ttb)
# Greedy Take The Best selects row 2 (output 1).
predictPair(oneRow(matrix, 2), oneRow(matrix, 3), ttbG)

</code></pre>

<hr>
<h2 id='ttbModel'>Take The Best</h2><span id='topic+ttbModel'></span>

<h3>Description</h3>

<p>An implementation of the Take The Best heuristic.
It sorts cues in order of <code><a href="#topic+cueValidity">cueValidity</a></code>, making a decision
based on the first cue that discriminates (has differing values on the
two objects).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ttbModel(
  train_data,
  criterion_col,
  cols_to_fit,
  reverse_cues = TRUE,
  fit_name = "ttbModel"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ttbModel_+3A_train_data">train_data</code></td>
<td>
<p>Training/fitting data as a matrix or data.frame.</p>
</td></tr>
<tr><td><code id="ttbModel_+3A_criterion_col">criterion_col</code></td>
<td>
<p>The index of the column in train_data that has the
criterion.</p>
</td></tr>
<tr><td><code id="ttbModel_+3A_cols_to_fit">cols_to_fit</code></td>
<td>
<p>A vector of column indices in train_data, used to fit
the criterion.</p>
</td></tr>
<tr><td><code id="ttbModel_+3A_reverse_cues">reverse_cues</code></td>
<td>
<p>Optional parameter to reverse cues as needed.  By
default, the model will reverse the cue values for cues with cue validity
&lt; 0.5, so a cue with validity 0 becomes a cue with validity 1.
Set this to FALSE if you do not want that, i.e. the cue stays validity 0.</p>
</td></tr>
<tr><td><code id="ttbModel_+3A_fit_name">fit_name</code></td>
<td>
<p>Optional The name other functions can use to label output.
It defaults to the class name.  It is useful to change this to a unique name
if you are making multiple fits, e.g. &quot;ttb1&quot;, &quot;ttb2&quot;, &quot;ttbNoReverse.&quot;</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Cues that are tied in validity are sorted once at fitting time, and that
order is used consistently for all predictions with that model.  But re-
fitting may lead to a different cue order.  (An alternative would be to
randomly re-order on every prediction.)
</p>


<h3>Value</h3>

<p>An object of <code><a href="base.html#topic+class">class</a></code> ttbModel, which can be passed
to a variety of functions to make predictions, e.g.
<code><a href="#topic+predictPair">predictPair</a></code> and <code><a href="#topic+percentCorrectList">percentCorrectList</a></code>.
</p>


<h3>References</h3>

<p>Gigerenzer, G. &amp; Goldstein, D. G. (1996). &quot;Reasoning the fast and frugal
way: Models of bounded rationality&quot;. Psychological Review, 103, 650-669.
</p>
<p>Wikipedia's entry on
<a href="https://en.wikipedia.org/wiki/Take-the-best_heuristic">https://en.wikipedia.org/wiki/Take-the-best_heuristic</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cueValidity">cueValidity</a></code> for the metric used to sort cues.
</p>
<p><code><a href="#topic+predictPair">predictPair</a></code> for predicting whether row1 is greater.
</p>
<p><code><a href="#topic+predictPairProb">predictPairProb</a></code> for predicting the probability row1 is
greater.
</p>
<p><code><a href="#topic+percentCorrectList">percentCorrectList</a></code> for the accuracy of predicting all
row pairs in a matrix or data.frame.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Fit column 1 (y) to columns 2 and 3 (x1 and x2) of train_matrix.
train_matrix &lt;- cbind(y=c(5,4), x1=c(1,0), x2=c(0,0))
ttb &lt;- ttbModel(train_matrix, 1, c(2,3))
# Have ttb predict whether row 1 or 2 has a greater value for y.  The
# output is 1, meaning it predicts row1 is bigger.
predictPair(oneRow(train_matrix, 1), oneRow(train_matrix, 2), ttb)

# Now ask it the reverse-- predict whther row 2 or row 1 is greater.  The
# output is -1, meaning it still predicts row1 is bigger.  (It is a
# symmetric heuristic.)
predictPair(oneRow(train_matrix, 2), oneRow(train_matrix, 1), ttb)

# But this test data results in an incorrect prediction-- that row1 has a
# smaller criterion than row2-- because x1 has a reversed direction.
test_matrix &lt;- cbind(y=c(5,4), x1=c(0,1), x2=c(0,0))
predictPair(oneRow(test_matrix, 1), oneRow(test_matrix, 2), ttb)

</code></pre>

<hr>
<h2 id='unitWeightModel'>Unit-weight linear model</h2><span id='topic+unitWeightModel'></span>

<h3>Description</h3>

<p>Unit-weight linear model inspired by Robyn Dawes.
Unit Weight Model assigns unit (+1 or -1) weights based on
<code><a href="#topic+cueValidity">cueValidity</a></code>.
</p>

<ul>
<li><p> A cue validity &gt; 0.5 results in a weight of +1.
</p>
</li>
<li><p> A cue validity &lt; 0.5 results in a weight of -1.
</p>
</li></ul>

<p>This version differs from others in that it uses a weight of 0 if cue
validity is 0.5 (rather than randomly assigning +1 or -1) to give faster
convergence of average accuracy.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>unitWeightModel(
  train_data,
  criterion_col,
  cols_to_fit,
  reverse_cues = TRUE,
  fit_name = "unitWeightModel"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="unitWeightModel_+3A_train_data">train_data</code></td>
<td>
<p>Training/fitting data as a matrix or data.frame.</p>
</td></tr>
<tr><td><code id="unitWeightModel_+3A_criterion_col">criterion_col</code></td>
<td>
<p>The index of the column in train_data that has the
criterion.</p>
</td></tr>
<tr><td><code id="unitWeightModel_+3A_cols_to_fit">cols_to_fit</code></td>
<td>
<p>A vector of column indices in train_data, used to fit
the criterion.</p>
</td></tr>
<tr><td><code id="unitWeightModel_+3A_reverse_cues">reverse_cues</code></td>
<td>
<p>Optional parameter to reverse cues as needed.</p>
</td></tr>
<tr><td><code id="unitWeightModel_+3A_fit_name">fit_name</code></td>
<td>
<p>Optional The name other functions can use to label output.
It defaults to the class name.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of <code><a href="base.html#topic+class">class</a></code> unitWeightModel.  This is a list
containing at least the following components:
</p>

<ul>
<li><p> &quot;cue_validities&quot;: A list of cue validities for the cues in order of
cols_to_fit.
</p>
</li>
<li><p> &quot;linear_coef&quot;: A list of linear model coefficients (-1 or +1)
for the cues in order of cols_to_fit.  (It can only return -1's if
reverse_cues=TRUE.)
</p>
</li></ul>



<h3>References</h3>

<p>Wikipedia's entry on
<a href="https://en.wikipedia.org/wiki/Unit-weighted_regression">https://en.wikipedia.org/wiki/Unit-weighted_regression</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cueValidity">cueValidity</a></code> for the metric used to to determine cue direction.
</p>
<p><code><a href="#topic+predictPair">predictPair</a></code> for predicting whether row1 is greater.
</p>
<p><code><a href="#topic+predictPairProb">predictPairProb</a></code> for predicting the probability row1 is
greater.
</p>

<hr>
<h2 id='validityWeightModel'>Validity Weight Model, a linear model weighted by cue validities</h2><span id='topic+validityWeightModel'></span>

<h3>Description</h3>

<p>Validity Weight Model is a linear model with weights calculated by
<code><a href="#topic+cueValidity">cueValidity</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>validityWeightModel(
  train_data,
  criterion_col,
  cols_to_fit,
  reverse_cues = TRUE,
  fit_name = "validityWeightModel"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="validityWeightModel_+3A_train_data">train_data</code></td>
<td>
<p>Training/fitting data as a matrix or data.frame.</p>
</td></tr>
<tr><td><code id="validityWeightModel_+3A_criterion_col">criterion_col</code></td>
<td>
<p>The index of the column in train_data that has the
criterion.</p>
</td></tr>
<tr><td><code id="validityWeightModel_+3A_cols_to_fit">cols_to_fit</code></td>
<td>
<p>A vector of column indices in train_data, used to fit
the criterion.</p>
</td></tr>
<tr><td><code id="validityWeightModel_+3A_reverse_cues">reverse_cues</code></td>
<td>
<p>Optional parameter to reverse cues as needed.  By
default, the model will reverse the cue values for cues with cue validity
&lt; 0.5, so a cue with validity 0 becomes a cue with validity 1.
Set this to FALSE if you do not want that, i.e. the cue stays validity 0.</p>
</td></tr>
<tr><td><code id="validityWeightModel_+3A_fit_name">fit_name</code></td>
<td>
<p>Optional The name other functions can use to label output.
It defaults to the class name.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of <code><a href="base.html#topic+class">class</a></code> validityWeightModel.  This is a
list containing at least the following components:
</p>

<ul>
<li><p> &quot;cue_validities&quot;: A list of cue validities for the cues in order of
cols_to_fit.
</p>
</li>
<li><p> &quot;linear_coef&quot;: Same as cue validities for this model.
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+cueValidity">cueValidity</a></code> for the metric used to to determine cue direction.
</p>
<p><code><a href="#topic+predictPair">predictPair</a></code> for predicting whether row1 is greater.
</p>
<p><code><a href="#topic+predictPairProb">predictPairProb</a></code> for predicting the probability row1 is
greater.
</p>

<hr>
<h2 id='zzDocumentationStubFormulaModelParams'>Documentation stub. Just to share documentation.</h2><span id='topic+zzDocumentationStubFormulaModelParams'></span>

<h3>Description</h3>

<p>Documentation stub. Just to share documentation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>zzDocumentationStubFormulaModelParams(train_matrix, criterion_col, cols_to_fit)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="zzDocumentationStubFormulaModelParams_+3A_train_matrix">train_matrix</code></td>
<td>
<p>A matrix (or data.frame) of data to train (fit) the
model with.</p>
</td></tr>
<tr><td><code id="zzDocumentationStubFormulaModelParams_+3A_criterion_col">criterion_col</code></td>
<td>
<p>The index of the criterion column&ndash; &quot;y&quot; in the formula.</p>
</td></tr>
<tr><td><code id="zzDocumentationStubFormulaModelParams_+3A_cols_to_fit">cols_to_fit</code></td>
<td>
<p>A vector of column indexes to fit&ndash; the &quot;x's&quot; in the
formula.</p>
</td></tr>
</table>

<hr>
<h2 id='zzDocumentationStubModelParams'>Documentation stub.  Just a way to share parameter documentation.</h2><span id='topic+zzDocumentationStubModelParams'></span>

<h3>Description</h3>

<p>Documentation stub.  Just a way to share parameter documentation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>zzDocumentationStubModelParams(train_data, criterion_col, cols_to_fit)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="zzDocumentationStubModelParams_+3A_train_data">train_data</code></td>
<td>
<p>Training/fitting data as a matrix or data.frame.</p>
</td></tr>
<tr><td><code id="zzDocumentationStubModelParams_+3A_criterion_col">criterion_col</code></td>
<td>
<p>The index of the column in train_data that has the
criterion.</p>
</td></tr>
<tr><td><code id="zzDocumentationStubModelParams_+3A_cols_to_fit">cols_to_fit</code></td>
<td>
<p>A vector of column indices in train_data, used to fit
the criterion.</p>
</td></tr>
</table>

<hr>
<h2 id='zzDocumentationStubReverseCues'>Documentation stub.</h2><span id='topic+zzDocumentationStubReverseCues'></span>

<h3>Description</h3>

<p>Documentation stub.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>zzDocumentationStubReverseCues(reverse_cues = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="zzDocumentationStubReverseCues_+3A_reverse_cues">reverse_cues</code></td>
<td>
<p>Optional parameter to reverse cues as needed.  By
default, the model will reverse the cue values for cues with cue validity
&lt; 0.5, so a cue with validity 0 becomes a cue with validity 1.
Set this to FALSE if you do not want that, i.e. the cue stays validity 0.</p>
</td></tr>
</table>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
