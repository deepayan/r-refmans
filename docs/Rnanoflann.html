<!DOCTYPE html><html><head><title>Help for package Rnanoflann</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {Rnanoflann}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#Rnanoflann-package'>
<p>Extremely Fast Nearest Neighbor Search</p></a></li>
<li><a href='#nn'><p>k-nearest neighbours search</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Extremely Fast Nearest Neighbor Search</td>
</tr>
<tr>
<td>Version:</td>
<td>0.0.3</td>
</tr>
<tr>
<td>Date:</td>
<td>2024-05-17</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Manos Papadakis &lt;papadakm95@gmail.com&gt;</td>
</tr>
<tr>
<td>Copyright:</td>
<td>'nanoflann' library is copyright Jose Luis Blanco. See file
COPYRIGHT for details.</td>
</tr>
<tr>
<td>Description:</td>
<td>Finds the k nearest neighbours for every point in a given dataset using Jose Luis' 'nanoflann' library. There is support for exact searches, fixed radius searches with 'kd' trees and two distances, the 'Euclidean' and 'Manhattan'. For more information see <a href="https://github.com/jlblancoc/nanoflann">https://github.com/jlblancoc/nanoflann</a>. Also, the 'nanoflann' library is exported and ready to be used via the linking to mechanism.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL (&ge; 3)</a></td>
</tr>
<tr>
<td>Imports:</td>
<td>Rcpp (&ge; 1.0.11)</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp, RcppArmadillo</td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/ManosPapadakis95/Rnanoflann/issues">https://github.com/ManosPapadakis95/Rnanoflann/issues</a></td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/ManosPapadakis95/Rnanoflann">https://github.com/ManosPapadakis95/Rnanoflann</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-05-17 13:43:17 UTC; epapadakis</td>
</tr>
<tr>
<td>Author:</td>
<td>Manos Papadakis [aut, cre, cph],
  Jose Luis Blanco [aut, cph],
  Michail Tsagris [ctb]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-05-17 14:10:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='Rnanoflann-package'>
Extremely Fast Nearest Neighbor Search
</h2><span id='topic+Rnanoflann-package'></span><span id='topic+Rnanoflann'></span>

<h3>Description</h3>

<p>Finds the k nearest neighbours for every point in a given dataset using Jose Luis' 'nanoflann' library. There is support for exact searches, fixed radius searches with 'kd' trees and two distances, the 'Euclidean' and 'Manhattan'. For more information see &lt;https://github.com/jlblancoc/nanoflann&gt;. Also, the 'nanoflann' library is exported and ready to be used via the linking to mechanism.
</p>


<h3>Details</h3>


<table>
<tr>
 <td style="text-align: left;">
Package: </td><td style="text-align: left;"> Rnanoflann</td>
</tr>
<tr>
 <td style="text-align: left;">
Type: </td><td style="text-align: left;"> Package</td>
</tr>
<tr>
 <td style="text-align: left;">
Version: </td><td style="text-align: left;"> 0.0.3 </td>
</tr>
<tr>
 <td style="text-align: left;">
Date: </td><td style="text-align: left;"> 2024-05-17</td>
</tr>
<tr>
 <td style="text-align: left;">
License: </td><td style="text-align: left;"> GPL (&gt;= 3)</td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>



<h3>Author(s)</h3>

<p>Authors: Manos Papadakis [aut, cre, cph],
  Jose Luis Blanco [aut, cph],
  Michail Tsagris [ctb]
</p>
<p>Maintainer: Manos Papadakis &lt;papadakm95@gmail.com&gt;
</p>

<hr>
<h2 id='nn'>k-nearest neighbours search</h2><span id='topic+nn'></span>

<h3>Description</h3>

<p>Uses a kd-tree to find the k nearest neighbours for each point in a given dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nn(data, points, k = nrow(data), method = "euclidean", search = "standard", 
eps = 0.0, square = FALSE, sorted = FALSE, radius = 0.0, trans = TRUE, 
leafs = 10L, p = 0.0, parallel = FALSE, cores = 0L)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="nn_+3A_data">data</code></td>
<td>

<p>A numerical matrix. The k nearest points will be extracted from this matrix.
</p>
</td></tr>
<tr><td><code id="nn_+3A_points">points</code></td>
<td>

<p>A numerical matrix. The function will find the nearest neighbours of each row of this matrix. 
</p>
</td></tr>
<tr><td><code id="nn_+3A_k">k</code></td>
<td>

<p>The number of nearest neighbours to search for.
</p>
</td></tr>
<tr><td><code id="nn_+3A_method">method</code></td>
<td>

<p>The type of distance.See details for the supported metrics.
</p>
</td></tr>
<tr><td><code id="nn_+3A_search">search</code></td>
<td>

<p>The type of search. Apart from the &quot;standard&quot; there is the &quot;radius&quot; option. It searches 
only for neighbours within a specified radius of the point. If there are no neighbours 
then the value &quot;indices&quot; will contain 0 and distances will contain 1.340781e+154 for that point.
</p>
</td></tr>
<tr><td><code id="nn_+3A_eps">eps</code></td>
<td>

<p>The accuracy of the search. When this is equal to 0, the function will return the exact k 
neighbours. If higher values are supplied, the function will return k approximate neighbours.
</p>
</td></tr>
<tr><td><code id="nn_+3A_square">square</code></td>
<td>

<p>If you choose &quot;euclidean&quot; as the method, then you can have the option to return the 
squared Euclidean distances by setting this argument to TRUE. Default is FALSE.
</p>
</td></tr>
<tr><td><code id="nn_+3A_sorted">sorted</code></td>
<td>

<p>Should the distances be sorted? This works only when search = &quot;radius&quot;.
</p>
</td></tr>
<tr><td><code id="nn_+3A_radius">radius</code></td>
<td>

<p>The radius of the search, when search = &quot;radius&quot;.
</p>
</td></tr>
<tr><td><code id="nn_+3A_trans">trans</code></td>
<td>

<p>Should the return matrices be transposed? The default value is TRUE.
</p>
</td></tr>
<tr><td><code id="nn_+3A_p">p</code></td>
<td>

<p>This is for the the Minkowski, the power of the metric. 
</p>
</td></tr>
<tr><td><code id="nn_+3A_leafs">leafs</code></td>
<td>

<p>Number of divided points. Default is 10.
</p>
<p>Large values mean that the tree will be built faster (since the tree will be smaller), 
but each query will be slower (since the linear search in the leaf is to be done over more points).
</p>
<p>Small values will build the tree much slower (there will be many tree nodes), but queries 
will be faster... up to some point, since the &quot;tree-part&quot; of the search (logarithmic complexity) 
still has a significant cost.
</p>
</td></tr>
<tr><td><code id="nn_+3A_parallel">parallel</code></td>
<td>

<p>Should the computations take place in parallel? The default value is FALSE.
</p>
</td></tr>
<tr><td><code id="nn_+3A_cores">cores</code></td>
<td>

<p>Number of threads for parallel version. The default is 0 which means all the available threads.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The target of this function is to calculate the distances between xnew and x without having to calculate the whole 
distance matrix of xnew and x. The latter does extra calculations, which can be avoided.
</p>

<ul>
<li><p> euclidean : <code class="reqn"> \sum \sqrt( \sum | P_i - Q_i |^2)</code>
</p>
</li>
<li><p> manhattan : <code class="reqn"> \sum \sum | P_i - Q_i |</code>
</p>
</li>
<li><p> minimum : <code class="reqn"> \sum \min | P_i - Q_i |</code>
</p>
</li>
<li><p> maximum : <code class="reqn"> \sum \max | P_i - Q_i |</code>
</p>
</li>
<li><p> minkowski : <code class="reqn"> \sum ( \sum | P_i - Q_i |^p)^\frac{1}{p}</code>
</p>
</li>
<li><p> bhattacharyya : <code class="reqn"> \sum - ln \sum \sqrt(P_i * Q_i)</code>
</p>
</li>
<li><p> hellinger : <code class="reqn"> \sum 2 * \sqrt( 1 - \sum \sqrt(P_i * Q_i))</code>
</p>
</li>
<li><p> kullback_leibler : <code class="reqn"> \sum \sum P_i * log(\frac{P_i}{Q_i})</code>
</p>
</li>
<li><p> jensen_shannon : <code class="reqn"> \sum 0.5 * ( \sum P_i * log(2 * \frac{P_i}{Q_i} + Q_i) + \sum Q_i * log(2 * \frac{Q_i}{P_i} + Q_i))</code>
</p>
</li>
<li><p> canberra : <code class="reqn"> \sum \sum \frac{| P_i - Q_i |}{P_i + Q_i}</code>
</p>
</li>
<li><p> chi_square <code class="reqn">X</code>^2 : <code class="reqn"> \sum \sum (\frac{(P_i - Q_i )^2}{P_i + Q_i})</code>
</p>
</li>
<li><p> soergel : <code class="reqn"> \sum \frac{\sum | P_i - Q_i |}{\sum \max(P_i , Q_i)}</code>
</p>
</li>
<li><p> sorensen : <code class="reqn"> \sum \frac{\sum | P_i - Q_i |}{\sum (P_i + Q_i)}</code>
</p>
</li>
<li><p> cosine : <code class="reqn"> \sum \frac{\sum (P_i * Q_i)}{\sqrt(\sum P_i^2) * \sqrt(\sum Q_i^2)}</code>
</p>
</li>
<li><p> wave_hedges : <code class="reqn"> \sum \frac{\sum | P_i - Q_i |}{\max(P_i , Q_i)}</code>
</p>
</li>
<li><p> motyka : <code class="reqn"> \sum \sum \frac{\min(P_i , Q_i)}{(P_i + Q_i)}</code>
</p>
</li>
<li><p> harmonic_mean : <code class="reqn"> \sum 2 * \frac{\sum P_i * Q_i}{P_i + Q_i}</code>
</p>
</li>
<li><p> jeffries_matusita : <code class="reqn"> \sum \sqrt( 2 - 2 * \sum \sqrt(P_i * Q_i))</code>
</p>
</li>
<li><p> gower : <code class="reqn"> \sum \frac{1}{d} * \sum | P_i - Q_i |</code>
</p>
</li>
<li><p> kulczynski : <code class="reqn"> \sum \frac{\sum | P_i - Q_i |}{\sum \min(P_i , Q_i)}</code>
</p>
</li>
<li><p> itakura_saito : <code class="reqn"> \sum \frac{P_i}{Q_i}  - log(\frac{P_i}{Q_i}) - 1</code>
</p>
</li></ul>



<h3>Value</h3>

<p>A list with 2 fields.
</p>
<table>
<tr><td><code>indices</code></td>
<td>

<p>A matrix with the indices of each nearest neighbour for each of the rows of the matrix &quot;points&quot;.
</p>
</td></tr>
<tr><td><code>distances</code></td>
<td>

<p>A matrix with the distances between each nearest neighbour and each of the rows of the matrix &quot;points&quot;.
</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- as.matrix(iris[1:140, 1:4])
xnew &lt;- as.matrix(iris[141:150, 1:4])
nn(data = x, points = xnew, k = 10)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
