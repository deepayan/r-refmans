<!DOCTYPE html><html><head><title>Help for package tfestimators</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {tfestimators}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#boosted_trees_estimators'><p>Boosted Trees Estimator</p></a></li>
<li><a href='#classifier_parse_example_spec'><p>Generates Parsing Spec for TensorFlow Example to be Used with Classifiers</p></a></li>
<li><a href='#column_base'><p>Base Documentation for Feature Column Constructors</p></a></li>
<li><a href='#column_bucketized'><p>Construct a Bucketized Column</p></a></li>
<li><a href='#column_categorical_weighted'><p>Construct a Weighted Categorical Column</p></a></li>
<li><a href='#column_categorical_with_hash_bucket'><p>Represents Sparse Feature where IDs are set by Hashing</p></a></li>
<li><a href='#column_categorical_with_identity'><p>Construct a Categorical Column that Returns Identity Values</p></a></li>
<li><a href='#column_categorical_with_vocabulary_file'><p>Construct a Categorical Column with a Vocabulary File</p></a></li>
<li><a href='#column_categorical_with_vocabulary_list'><p>Construct a Categorical Column with In-Memory Vocabulary</p></a></li>
<li><a href='#column_crossed'><p>Construct a Crossed Column</p></a></li>
<li><a href='#column_embedding'><p>Construct a Dense Column</p></a></li>
<li><a href='#column_indicator'><p>Represents Multi-Hot Representation of Given Categorical Column</p></a></li>
<li><a href='#column_numeric'><p>Construct a Real-Valued Column</p></a></li>
<li><a href='#column-scope'><p>Establish a Feature Columns Selection Scope</p></a></li>
<li><a href='#dnn_estimators'><p>Deep Neural Networks</p></a></li>
<li><a href='#dnn_linear_combined_estimators'><p>Linear Combined Deep Neural Networks</p></a></li>
<li><a href='#estimator'><p>Construct a Custom Estimator</p></a></li>
<li><a href='#estimator_spec'><p>Define an Estimator Specification</p></a></li>
<li><a href='#estimators'><p>Base Documentation for Canned Estimators</p></a></li>
<li><a href='#eval_spec'><p>Configuration for the eval component of <code>train_and_evaluate</code></p></a></li>
<li><a href='#evaluate.tf_estimator'><p>Evaluate an Estimator</p></a></li>
<li><a href='#experiment'><p>Construct an Experiment</p></a></li>
<li><a href='#export_savedmodel.tf_estimator'><p>Save an Estimator</p></a></li>
<li><a href='#feature_columns'><p>Feature Columns</p></a></li>
<li><a href='#graph_keys'><p>Standard Names to Use for Graph Collections</p></a></li>
<li><a href='#hook_checkpoint_saver'><p>Saves Checkpoints Every N Steps or Seconds</p></a></li>
<li><a href='#hook_global_step_waiter'><p>Delay Execution until Global Step Reaches to <code>wait_until_step</code>.</p></a></li>
<li><a href='#hook_history_saver'><p>A Custom Run Hook for Saving Metrics History</p></a></li>
<li><a href='#hook_logging_tensor'><p>Prints Given Tensors Every N Local Steps, Every N Seconds, or at End</p></a></li>
<li><a href='#hook_nan_tensor'><p>NaN Loss Monitor</p></a></li>
<li><a href='#hook_progress_bar'><p>A Custom Run Hook to Create and Update Progress Bar During Training or Evaluation</p></a></li>
<li><a href='#hook_step_counter'><p>Steps per Second Monitor</p></a></li>
<li><a href='#hook_stop_at_step'><p>Monitor to Request Stop at a Specified Step</p></a></li>
<li><a href='#hook_summary_saver'><p>Saves Summaries Every N Steps</p></a></li>
<li><a href='#input_fn'><p>Construct an Input Function</p></a></li>
<li><a href='#input_layer'><p>Construct an Input Layer</p></a></li>
<li><a href='#keras_model_to_estimator'><p>Keras Estimators</p></a></li>
<li><a href='#latest_checkpoint'><p>Get the Latest Checkpoint in a Checkpoint Directory</p></a></li>
<li><a href='#linear_estimators'><p>Construct a Linear Estimator</p></a></li>
<li><a href='#metric_keys'><p>Canonical Metric Keys</p></a></li>
<li><a href='#mode_keys'><p>Canonical Mode Keys</p></a></li>
<li><a href='#model_dir'><p>Model directory</p></a></li>
<li><a href='#numpy_input_fn'><p>Construct Input Function Containing Python Dictionaries of Numpy Arrays</p></a></li>
<li><a href='#plot.tf_estimator_history'><p>Plot training history</p></a></li>
<li><a href='#predict.tf_estimator'><p>Generate Predictions with an Estimator</p></a></li>
<li><a href='#prediction_keys'><p>Canonical Model Prediction Keys</p></a></li>
<li><a href='#reexports'><p>Objects exported from other packages</p></a></li>
<li><a href='#regressor_parse_example_spec'><p>Generates Parsing Spec for TensorFlow Example to be Used with Regressors</p></a></li>
<li><a href='#run_config'><p>Run Configuration</p></a></li>
<li><a href='#session_run_args'><p>Create Session Run Arguments</p></a></li>
<li><a href='#session_run_hook'><p>Create Custom Session Run Hooks</p></a></li>
<li><a href='#task_type'><p>Task Types</p></a></li>
<li><a href='#tfestimators'><p>High-level Estimator API in TensorFlow for R</p></a></li>
<li><a href='#train_and_evaluate.tf_estimator'><p>Train and evaluate the estimator.</p></a></li>
<li><a href='#train_spec'><p>Configuration for the train component of <code>train_and_evaluate</code></p></a></li>
<li><a href='#train-evaluate-predict'><p>Base Documentation for train, evaluate, and predict.</p></a></li>
<li><a href='#train.tf_estimator'><p>Train an Estimator</p></a></li>
<li><a href='#variable_names_values'><p>Get variable names and values associated with an estimator</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Interface to 'TensorFlow' Estimators</td>
</tr>
<tr>
<td>Version:</td>
<td>1.9.2</td>
</tr>
<tr>
<td>Description:</td>
<td>Interface to 'TensorFlow' Estimators 
    <a href="https://www.tensorflow.org/guide/estimator">https://www.tensorflow.org/guide/estimator</a>, a high-level 
    API that provides implementations of many different model types 
    including linear models and deep neural networks. </td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.apache.org/licenses/LICENSE-2.0">Apache License 2.0</a></td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/rstudio/tfestimators">https://github.com/rstudio/tfestimators</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/rstudio/tfestimators/issues">https://github.com/rstudio/tfestimators/issues</a></td>
</tr>
<tr>
<td>SystemRequirements:</td>
<td>TensorFlow (https://www.tensorflow.org/)</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.1)</td>
</tr>
<tr>
<td>Imports:</td>
<td>forge, magrittr, progress, reticulate (&ge; 1.10), rlang (&ge;
0.3), tensorflow (&ge; 1.9), tfruns (&ge; 1.1), tidyselect, utils,
purrr, tibble, tidyr</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.1</td>
</tr>
<tr>
<td>Suggests:</td>
<td>ggplot2, modelr (&ge; 0.1.1), testthat, rmarkdown, knitr</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2021-08-09 12:41:00 UTC; tomasz</td>
</tr>
<tr>
<td>Author:</td>
<td>JJ Allaire [aut],
  Yuan Tang <a href="https://orcid.org/0000-0001-5243-233X"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut],
  Kevin Ushey [aut],
  Kevin Kuo <a href="https://orcid.org/0000-0001-7803-7901"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut],
  Tomasz Kalinowski [cre],
  Daniel Falbel [ctb, cph],
  RStudio [cph, fnd],
  Google Inc. [cph]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Tomasz Kalinowski &lt;tomasz.kalinowski@rstudio.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2021-08-09 22:30:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='boosted_trees_estimators'>Boosted Trees Estimator</h2><span id='topic+boosted_trees_estimators'></span><span id='topic+boosted_trees_regressor'></span><span id='topic+boosted_trees_classifier'></span>

<h3>Description</h3>

<p>Construct a boosted trees estimator.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>boosted_trees_regressor(
  feature_columns,
  n_batches_per_layer,
  model_dir = NULL,
  label_dimension = 1L,
  weight_column = NULL,
  n_trees = 100L,
  max_depth = 6L,
  learning_rate = 0.1,
  l1_regularization = 0,
  l2_regularization = 0,
  tree_complexity = 0,
  min_node_weight = 0,
  config = NULL
)

boosted_trees_classifier(
  feature_columns,
  n_batches_per_layer,
  model_dir = NULL,
  n_classes = 2L,
  weight_column = NULL,
  label_vocabulary = NULL,
  n_trees = 100L,
  max_depth = 6L,
  learning_rate = 0.1,
  l1_regularization = 0,
  l2_regularization = 0,
  tree_complexity = 0,
  min_node_weight = 0,
  config = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="boosted_trees_estimators_+3A_feature_columns">feature_columns</code></td>
<td>
<p>An <span class="rlang"><b>R</b></span> list containing all of the feature columns used
by the model (typically, generated by <code><a href="#topic+feature_columns">feature_columns()</a></code>).</p>
</td></tr>
<tr><td><code id="boosted_trees_estimators_+3A_n_batches_per_layer">n_batches_per_layer</code></td>
<td>
<p>The number of batches to collect
statistics per layer.</p>
</td></tr>
<tr><td><code id="boosted_trees_estimators_+3A_model_dir">model_dir</code></td>
<td>
<p>Directory to save the model parameters, graph, and so on.
This can also be used to load checkpoints from the directory into a
estimator to continue training a previously saved model.</p>
</td></tr>
<tr><td><code id="boosted_trees_estimators_+3A_label_dimension">label_dimension</code></td>
<td>
<p>Number of regression targets per example. This is the
size of the last dimension of the labels and logits <code>Tensor</code> objects
(typically, these have shape <code style="white-space: pre;">&#8288;[batch_size, label_dimension]&#8288;</code>).</p>
</td></tr>
<tr><td><code id="boosted_trees_estimators_+3A_weight_column">weight_column</code></td>
<td>
<p>A string, or a numeric column created by
<code><a href="#topic+column_numeric">column_numeric()</a></code> defining feature column representing weights. It is used
to down weight or boost examples during training. It will be multiplied by
the loss of the example. If it is a string, it is used as a key to fetch
weight tensor from the <code>features</code> argument. If it is a numeric column,
then the raw tensor is fetched by key <code>weight_column$key</code>, then
<code>weight_column$normalizer_fn</code> is applied on it to get weight tensor.</p>
</td></tr>
<tr><td><code id="boosted_trees_estimators_+3A_n_trees">n_trees</code></td>
<td>
<p>Number trees to be created.</p>
</td></tr>
<tr><td><code id="boosted_trees_estimators_+3A_max_depth">max_depth</code></td>
<td>
<p>Maximum depth of the tree to grow.</p>
</td></tr>
<tr><td><code id="boosted_trees_estimators_+3A_learning_rate">learning_rate</code></td>
<td>
<p>Shrinkage parameter to be used when a tree
added to the model.</p>
</td></tr>
<tr><td><code id="boosted_trees_estimators_+3A_l1_regularization">l1_regularization</code></td>
<td>
<p>Regularization multiplier applied to the
absolute weights of the tree leafs.</p>
</td></tr>
<tr><td><code id="boosted_trees_estimators_+3A_l2_regularization">l2_regularization</code></td>
<td>
<p>Regularization multiplier applied to the
square weights of the tree leafs.</p>
</td></tr>
<tr><td><code id="boosted_trees_estimators_+3A_tree_complexity">tree_complexity</code></td>
<td>
<p>Regularization factor to penalize trees
with more leaves.</p>
</td></tr>
<tr><td><code id="boosted_trees_estimators_+3A_min_node_weight">min_node_weight</code></td>
<td>
<p>Minimum hessian a node must have for a
split to be considered. The value will be compared with
sum(leaf_hessian)/(batch_size * n_batches_per_layer).</p>
</td></tr>
<tr><td><code id="boosted_trees_estimators_+3A_config">config</code></td>
<td>
<p>A run configuration created by <code><a href="#topic+run_config">run_config()</a></code>, used to configure the runtime
settings.</p>
</td></tr>
<tr><td><code id="boosted_trees_estimators_+3A_n_classes">n_classes</code></td>
<td>
<p>The number of label classes.</p>
</td></tr>
<tr><td><code id="boosted_trees_estimators_+3A_label_vocabulary">label_vocabulary</code></td>
<td>
<p>A list of strings represents possible label values.
If given, labels must be string type and have any value in
<code>label_vocabulary</code>. If it is not given, that means labels are already
encoded as integer or float within <code style="white-space: pre;">&#8288;[0, 1]&#8288;</code> for <code>n_classes == 2</code> and
encoded as integer values in <code style="white-space: pre;">&#8288;{0, 1,..., n_classes  -1}&#8288;</code> for <code>n_classes &gt; 2</code>. Also there will be errors if vocabulary is not provided and labels are
string.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>Other canned estimators: 
<code><a href="#topic+dnn_estimators">dnn_estimators</a></code>,
<code><a href="#topic+dnn_linear_combined_estimators">dnn_linear_combined_estimators</a></code>,
<code><a href="#topic+linear_estimators">linear_estimators</a></code>
</p>

<hr>
<h2 id='classifier_parse_example_spec'>Generates Parsing Spec for TensorFlow Example to be Used with Classifiers</h2><span id='topic+classifier_parse_example_spec'></span>

<h3>Description</h3>

<p>If users keep data in TensorFlow Example format, they need to call <code>tf$parse_example</code>
with a proper feature spec. There are two main things that this utility
helps:
</p>

<ul>
<li><p> Users need to combine parsing spec of features with labels and
weights (if any) since they are all parsed from same <code>tf$Example</code> instance.
This utility combines these specs.
</p>
</li>
<li><p> It is difficult to map expected label by
a classifier such as <code>dnn_classifier</code> to corresponding <code>tf$parse_example</code> spec.
This utility encodes it by getting related information from users (key,
dtype).
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>classifier_parse_example_spec(
  feature_columns,
  label_key,
  label_dtype = tf$int64,
  label_default = NULL,
  weight_column = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="classifier_parse_example_spec_+3A_feature_columns">feature_columns</code></td>
<td>
<p>An iterable containing all feature columns. All items
should be instances of classes derived from <code style="white-space: pre;">&#8288;_FeatureColumn&#8288;</code>.</p>
</td></tr>
<tr><td><code id="classifier_parse_example_spec_+3A_label_key">label_key</code></td>
<td>
<p>A string identifying the label. It means <code>tf$Example</code> stores
labels with this key.</p>
</td></tr>
<tr><td><code id="classifier_parse_example_spec_+3A_label_dtype">label_dtype</code></td>
<td>
<p>A <code>tf$dtype</code> identifies the type of labels. By default it
is <code>tf$int64</code>. If user defines a <code>label_vocabulary</code>, this should be set as
<code>tf$string</code>. <code>tf$float32</code> labels are only supported for binary
classification.</p>
</td></tr>
<tr><td><code id="classifier_parse_example_spec_+3A_label_default">label_default</code></td>
<td>
<p>used as label if label_key does not exist in given
<code>tf$Example</code>. An example usage: let's say <code>label_key</code> is 'clicked' and
<code>tf$Example</code> contains clicked data only for positive examples in following
format <code style="white-space: pre;">&#8288;key:clicked, value:1&#8288;</code>. This means that if there is no data with key
'clicked' it should count as negative example by setting
<code>label_deafault=0</code>. Type of this value should be compatible with
<code>label_dtype</code>.</p>
</td></tr>
<tr><td><code id="classifier_parse_example_spec_+3A_weight_column">weight_column</code></td>
<td>
<p>A string or a numeric column created by
<code><a href="#topic+column_numeric">column_numeric()</a></code> defining feature column representing
weights. It is used to down weight or boost examples during training. It
will be multiplied by the loss of the example. If it is a string, it is
used as a key to fetch weight tensor from the <code>features</code>. If it is a
numeric column, raw tensor is fetched by key <code>weight_column$key</code>, then
<code>weight_column$normalizer_fn</code> is applied on it to get weight tensor.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A dict mapping each feature key to a <code>FixedLenFeature</code> or
<code>VarLenFeature</code> value.
</p>


<h3>Raises</h3>


<ul>
<li><p> ValueError: If label is used in <code>feature_columns</code>.
</p>
</li>
<li><p> ValueError: If weight_column is used in <code>feature_columns</code>.
</p>
</li>
<li><p> ValueError: If any of the given <code>feature_columns</code> is not a feature column instance.
</p>
</li>
<li><p> ValueError: If <code>weight_column</code> is not a numeric column instance.
</p>
</li>
<li><p> ValueError: if label_key is <code>NULL</code>.
</p>
</li></ul>



<h3>See Also</h3>

<p>Other parsing utilities: 
<code><a href="#topic+regressor_parse_example_spec">regressor_parse_example_spec</a>()</code>
</p>

<hr>
<h2 id='column_base'>Base Documentation for Feature Column Constructors</h2><span id='topic+column_base'></span>

<h3>Description</h3>

<p>Base Documentation for Feature Column Constructors
</p>


<h3>Arguments</h3>

<table>
<tr><td><code id="column_base_+3A_...">...</code></td>
<td>
<p>Expression(s) identifying input feature(s). Used as the column
name and the dictionary key for feature parsing configs, feature tensors,
and feature columns.</p>
</td></tr>
</table>

<hr>
<h2 id='column_bucketized'>Construct a Bucketized Column</h2><span id='topic+column_bucketized'></span>

<h3>Description</h3>

<p>Construct a bucketized column, representing discretized dense input. Buckets
include the left boundary, and exclude the right boundary.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>column_bucketized(source_column, boundaries)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="column_bucketized_+3A_source_column">source_column</code></td>
<td>
<p>A one-dimensional dense column, as generated by <code><a href="#topic+column_numeric">column_numeric()</a></code>.</p>
</td></tr>
<tr><td><code id="column_bucketized_+3A_boundaries">boundaries</code></td>
<td>
<p>A sorted list or list of floats specifying the boundaries.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A bucketized column.
</p>


<h3>Raises</h3>


<ul>
<li><p> ValueError: If <code>source_column</code> is not a numeric column, or if it is not one-dimensional.
</p>
</li>
<li><p> ValueError: If <code>boundaries</code> is not a sorted list or list.
</p>
</li></ul>



<h3>See Also</h3>

<p>Other feature column constructors: 
<code><a href="#topic+column_categorical_weighted">column_categorical_weighted</a>()</code>,
<code><a href="#topic+column_categorical_with_hash_bucket">column_categorical_with_hash_bucket</a>()</code>,
<code><a href="#topic+column_categorical_with_identity">column_categorical_with_identity</a>()</code>,
<code><a href="#topic+column_categorical_with_vocabulary_file">column_categorical_with_vocabulary_file</a>()</code>,
<code><a href="#topic+column_categorical_with_vocabulary_list">column_categorical_with_vocabulary_list</a>()</code>,
<code><a href="#topic+column_crossed">column_crossed</a>()</code>,
<code><a href="#topic+column_embedding">column_embedding</a>()</code>,
<code><a href="#topic+column_numeric">column_numeric</a>()</code>,
<code><a href="#topic+input_layer">input_layer</a>()</code>
</p>

<hr>
<h2 id='column_categorical_weighted'>Construct a Weighted Categorical Column</h2><span id='topic+column_categorical_weighted'></span>

<h3>Description</h3>

<p>Use this when each of your sparse inputs has both an ID and a value. For
example, if you're representing text documents as a collection of word
frequencies, you can provide 2 parallel sparse input features ('terms' and
'frequencies' below).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>column_categorical_weighted(
  categorical_column,
  weight_feature_key,
  dtype = tf$float32
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="column_categorical_weighted_+3A_categorical_column">categorical_column</code></td>
<td>
<p>A categorical column created by
<code style="white-space: pre;">&#8288;column_categorical_*()&#8288;</code> functions.</p>
</td></tr>
<tr><td><code id="column_categorical_weighted_+3A_weight_feature_key">weight_feature_key</code></td>
<td>
<p>String key for weight values.</p>
</td></tr>
<tr><td><code id="column_categorical_weighted_+3A_dtype">dtype</code></td>
<td>
<p>Type of weights, such as <code>tf$float32</code>. Only float and integer
weights are supported.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A categorical column composed of two sparse features: one
represents id, the other represents weight (value) of the id feature in
that example.
</p>


<h3>Raises</h3>


<ul>
<li><p> ValueError: if <code>dtype</code> is not convertible to float.
</p>
</li></ul>



<h3>See Also</h3>

<p>Other feature column constructors: 
<code><a href="#topic+column_bucketized">column_bucketized</a>()</code>,
<code><a href="#topic+column_categorical_with_hash_bucket">column_categorical_with_hash_bucket</a>()</code>,
<code><a href="#topic+column_categorical_with_identity">column_categorical_with_identity</a>()</code>,
<code><a href="#topic+column_categorical_with_vocabulary_file">column_categorical_with_vocabulary_file</a>()</code>,
<code><a href="#topic+column_categorical_with_vocabulary_list">column_categorical_with_vocabulary_list</a>()</code>,
<code><a href="#topic+column_crossed">column_crossed</a>()</code>,
<code><a href="#topic+column_embedding">column_embedding</a>()</code>,
<code><a href="#topic+column_numeric">column_numeric</a>()</code>,
<code><a href="#topic+input_layer">input_layer</a>()</code>
</p>

<hr>
<h2 id='column_categorical_with_hash_bucket'>Represents Sparse Feature where IDs are set by Hashing</h2><span id='topic+column_categorical_with_hash_bucket'></span>

<h3>Description</h3>

<p>Use this when your sparse features are in string or integer format, and you
want to distribute your inputs into a finite number of buckets by hashing.
output_id = Hash(input_feature_string) % bucket_size For input dictionary
<code>features</code>, <code style="white-space: pre;">&#8288;features$key$&#8288;</code> is either tensor or sparse tensor object. If it's
tensor object, missing values can be represented by <code>-1</code> for int and <code>''</code> for
string. Note that these values are independent of the <code>default_value</code>
argument.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>column_categorical_with_hash_bucket(..., hash_bucket_size, dtype = tf$string)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="column_categorical_with_hash_bucket_+3A_...">...</code></td>
<td>
<p>Expression(s) identifying input feature(s). Used as the column
name and the dictionary key for feature parsing configs, feature tensors,
and feature columns.</p>
</td></tr>
<tr><td><code id="column_categorical_with_hash_bucket_+3A_hash_bucket_size">hash_bucket_size</code></td>
<td>
<p>An int &gt; 1. The number of buckets.</p>
</td></tr>
<tr><td><code id="column_categorical_with_hash_bucket_+3A_dtype">dtype</code></td>
<td>
<p>The type of features. Only string and integer types are
supported.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code style="white-space: pre;">&#8288;_HashedCategoricalColumn&#8288;</code>.
</p>


<h3>Raises</h3>


<ul>
<li><p> ValueError: <code>hash_bucket_size</code> is not greater than 1.
</p>
</li>
<li><p> ValueError: <code>dtype</code> is neither string nor integer.
</p>
</li></ul>



<h3>See Also</h3>

<p>Other feature column constructors: 
<code><a href="#topic+column_bucketized">column_bucketized</a>()</code>,
<code><a href="#topic+column_categorical_weighted">column_categorical_weighted</a>()</code>,
<code><a href="#topic+column_categorical_with_identity">column_categorical_with_identity</a>()</code>,
<code><a href="#topic+column_categorical_with_vocabulary_file">column_categorical_with_vocabulary_file</a>()</code>,
<code><a href="#topic+column_categorical_with_vocabulary_list">column_categorical_with_vocabulary_list</a>()</code>,
<code><a href="#topic+column_crossed">column_crossed</a>()</code>,
<code><a href="#topic+column_embedding">column_embedding</a>()</code>,
<code><a href="#topic+column_numeric">column_numeric</a>()</code>,
<code><a href="#topic+input_layer">input_layer</a>()</code>
</p>

<hr>
<h2 id='column_categorical_with_identity'>Construct a Categorical Column that Returns Identity Values</h2><span id='topic+column_categorical_with_identity'></span>

<h3>Description</h3>

<p>Use this when your inputs are integers in the range <code style="white-space: pre;">&#8288;[0, num_buckets)&#8288;</code>, and
you want to use the input value itself as the categorical ID. Values outside
this range will result in <code>default_value</code> if specified, otherwise it will
fail.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>column_categorical_with_identity(..., num_buckets, default_value = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="column_categorical_with_identity_+3A_...">...</code></td>
<td>
<p>Expression(s) identifying input feature(s). Used as the column
name and the dictionary key for feature parsing configs, feature tensors,
and feature columns.</p>
</td></tr>
<tr><td><code id="column_categorical_with_identity_+3A_num_buckets">num_buckets</code></td>
<td>
<p>Number of unique values.</p>
</td></tr>
<tr><td><code id="column_categorical_with_identity_+3A_default_value">default_value</code></td>
<td>
<p>If <code>NULL</code>, this column's graph operations will fail for
out-of-range inputs. Otherwise, this value must be in the range <code style="white-space: pre;">&#8288;[0, num_buckets)&#8288;</code>, and will replace inputs in that range.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Typically, this is used for contiguous ranges of integer indexes, but it
doesn't have to be. This might be inefficient, however, if many of IDs are
unused. Consider <code>column_categorical_with_hash_bucket()</code> in that case.
</p>
<p>For input dictionary <code>features</code>, <code>features$key</code> is either tensor or sparse
tensor object. If it's tensor object, missing values can be represented by <code>-1</code> for
int and <code>''</code> for string. Note that these values are independent of the
<code>default_value</code> argument.
</p>


<h3>Value</h3>

<p>A categorical column that returns identity values.
</p>


<h3>Raises</h3>


<ul>
<li><p> ValueError: if <code>num_buckets</code> is less than one.
</p>
</li>
<li><p> ValueError: if <code>default_value</code> is not in range <code style="white-space: pre;">&#8288;[0, num_buckets)&#8288;</code>.
</p>
</li></ul>



<h3>See Also</h3>

<p>Other feature column constructors: 
<code><a href="#topic+column_bucketized">column_bucketized</a>()</code>,
<code><a href="#topic+column_categorical_weighted">column_categorical_weighted</a>()</code>,
<code><a href="#topic+column_categorical_with_hash_bucket">column_categorical_with_hash_bucket</a>()</code>,
<code><a href="#topic+column_categorical_with_vocabulary_file">column_categorical_with_vocabulary_file</a>()</code>,
<code><a href="#topic+column_categorical_with_vocabulary_list">column_categorical_with_vocabulary_list</a>()</code>,
<code><a href="#topic+column_crossed">column_crossed</a>()</code>,
<code><a href="#topic+column_embedding">column_embedding</a>()</code>,
<code><a href="#topic+column_numeric">column_numeric</a>()</code>,
<code><a href="#topic+input_layer">input_layer</a>()</code>
</p>

<hr>
<h2 id='column_categorical_with_vocabulary_file'>Construct a Categorical Column with a Vocabulary File</h2><span id='topic+column_categorical_with_vocabulary_file'></span>

<h3>Description</h3>

<p>Use this when your inputs are in string or integer format, and you have a
vocabulary file that maps each value to an integer ID. By default,
out-of-vocabulary values are ignored. Use either (but not both) of
<code>num_oov_buckets</code> and <code>default_value</code> to specify how to include
out-of-vocabulary values. For input dictionary <code>features</code>, <code>features[key]</code> is
either tensor or sparse tensor object. If it's tensor object, missing values can be
represented by <code>-1</code> for int and <code>''</code> for string. Note that these values are
independent of the <code>default_value</code> argument.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>column_categorical_with_vocabulary_file(
  ...,
  vocabulary_file,
  vocabulary_size,
  num_oov_buckets = 0L,
  default_value = NULL,
  dtype = tf$string
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="column_categorical_with_vocabulary_file_+3A_...">...</code></td>
<td>
<p>Expression(s) identifying input feature(s). Used as the column
name and the dictionary key for feature parsing configs, feature tensors,
and feature columns.</p>
</td></tr>
<tr><td><code id="column_categorical_with_vocabulary_file_+3A_vocabulary_file">vocabulary_file</code></td>
<td>
<p>The vocabulary file name.</p>
</td></tr>
<tr><td><code id="column_categorical_with_vocabulary_file_+3A_vocabulary_size">vocabulary_size</code></td>
<td>
<p>Number of the elements in the vocabulary. This must be
no greater than length of <code>vocabulary_file</code>, if less than length, later
values are ignored.</p>
</td></tr>
<tr><td><code id="column_categorical_with_vocabulary_file_+3A_num_oov_buckets">num_oov_buckets</code></td>
<td>
<p>Non-negative integer, the number of out-of-vocabulary
buckets. All out-of-vocabulary inputs will be assigned IDs in the range
<code style="white-space: pre;">&#8288;[vocabulary_size, vocabulary_size+num_oov_buckets)&#8288;</code> based on a hash of the
input value. A positive <code>num_oov_buckets</code> can not be specified with
<code>default_value</code>.</p>
</td></tr>
<tr><td><code id="column_categorical_with_vocabulary_file_+3A_default_value">default_value</code></td>
<td>
<p>The integer ID value to return for out-of-vocabulary
feature values, defaults to <code>-1</code>. This can not be specified with a positive
<code>num_oov_buckets</code>.</p>
</td></tr>
<tr><td><code id="column_categorical_with_vocabulary_file_+3A_dtype">dtype</code></td>
<td>
<p>The type of features. Only string and integer types are
supported.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A categorical column with a vocabulary file.
</p>


<h3>Raises</h3>


<ul>
<li><p> ValueError: <code>vocabulary_file</code> is missing.
</p>
</li>
<li><p> ValueError: <code>vocabulary_size</code> is missing or &lt; 1.
</p>
</li>
<li><p> ValueError: <code>num_oov_buckets</code> is not a non-negative integer.
</p>
</li>
<li><p> ValueError: <code>dtype</code> is neither string nor integer.
</p>
</li></ul>



<h3>See Also</h3>

<p>Other feature column constructors: 
<code><a href="#topic+column_bucketized">column_bucketized</a>()</code>,
<code><a href="#topic+column_categorical_weighted">column_categorical_weighted</a>()</code>,
<code><a href="#topic+column_categorical_with_hash_bucket">column_categorical_with_hash_bucket</a>()</code>,
<code><a href="#topic+column_categorical_with_identity">column_categorical_with_identity</a>()</code>,
<code><a href="#topic+column_categorical_with_vocabulary_list">column_categorical_with_vocabulary_list</a>()</code>,
<code><a href="#topic+column_crossed">column_crossed</a>()</code>,
<code><a href="#topic+column_embedding">column_embedding</a>()</code>,
<code><a href="#topic+column_numeric">column_numeric</a>()</code>,
<code><a href="#topic+input_layer">input_layer</a>()</code>
</p>

<hr>
<h2 id='column_categorical_with_vocabulary_list'>Construct a Categorical Column with In-Memory Vocabulary</h2><span id='topic+column_categorical_with_vocabulary_list'></span>

<h3>Description</h3>

<p>Use this when your inputs are in string or integer format, and you have an
in-memory vocabulary mapping each value to an integer ID. By default,
out-of-vocabulary values are ignored. Use <code>default_value</code> to specify how to
include out-of-vocabulary values. For the input dictionary <code>features</code>,
<code>features$key</code> is either tensor or sparse tensor object. If it's tensor object,
missing values can be represented by <code>-1</code> for int and <code>''</code> for string.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>column_categorical_with_vocabulary_list(
  ...,
  vocabulary_list,
  dtype = NULL,
  default_value = -1L,
  num_oov_buckets = 0L
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="column_categorical_with_vocabulary_list_+3A_...">...</code></td>
<td>
<p>Expression(s) identifying input feature(s). Used as the column
name and the dictionary key for feature parsing configs, feature tensors,
and feature columns.</p>
</td></tr>
<tr><td><code id="column_categorical_with_vocabulary_list_+3A_vocabulary_list">vocabulary_list</code></td>
<td>
<p>An ordered iterable defining the vocabulary. Each
feature is mapped to the index of its value (if present) in
<code>vocabulary_list</code>. Must be castable to <code>dtype</code>.</p>
</td></tr>
<tr><td><code id="column_categorical_with_vocabulary_list_+3A_dtype">dtype</code></td>
<td>
<p>The type of features. Only string and integer types are
supported. If <code>NULL</code>, it will be inferred from <code>vocabulary_list</code>.</p>
</td></tr>
<tr><td><code id="column_categorical_with_vocabulary_list_+3A_default_value">default_value</code></td>
<td>
<p>The value to use for values not in <code>vocabulary_list</code>.</p>
</td></tr>
<tr><td><code id="column_categorical_with_vocabulary_list_+3A_num_oov_buckets">num_oov_buckets</code></td>
<td>
<p>Non-negative integer, the number of out-of-vocabulary
buckets. All out-of-vocabulary inputs will be assigned IDs in the range
<code style="white-space: pre;">&#8288;[vocabulary_size, vocabulary_size+num_oov_buckets)&#8288;</code> based on a hash of the
input value. A positive <code>num_oov_buckets</code> can not be specified with
<code>default_value</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Note that these values are independent of the <code>default_value</code> argument.
</p>


<h3>Value</h3>

<p>A categorical column with in-memory vocabulary.
</p>


<h3>Raises</h3>


<ul>
<li><p> ValueError: if <code>vocabulary_list</code> is empty, or contains
duplicate keys.
</p>
</li>
<li><p> ValueError: if <code>dtype</code> is not integer or string.
</p>
</li></ul>



<h3>See Also</h3>

<p>Other feature column constructors: 
<code><a href="#topic+column_bucketized">column_bucketized</a>()</code>,
<code><a href="#topic+column_categorical_weighted">column_categorical_weighted</a>()</code>,
<code><a href="#topic+column_categorical_with_hash_bucket">column_categorical_with_hash_bucket</a>()</code>,
<code><a href="#topic+column_categorical_with_identity">column_categorical_with_identity</a>()</code>,
<code><a href="#topic+column_categorical_with_vocabulary_file">column_categorical_with_vocabulary_file</a>()</code>,
<code><a href="#topic+column_crossed">column_crossed</a>()</code>,
<code><a href="#topic+column_embedding">column_embedding</a>()</code>,
<code><a href="#topic+column_numeric">column_numeric</a>()</code>,
<code><a href="#topic+input_layer">input_layer</a>()</code>
</p>

<hr>
<h2 id='column_crossed'>Construct a Crossed Column</h2><span id='topic+column_crossed'></span>

<h3>Description</h3>

<p>Returns a column for performing crosses of categorical features. Crossed
features will be hashed according to <code>hash_bucket_size</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>column_crossed(keys, hash_bucket_size, hash_key = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="column_crossed_+3A_keys">keys</code></td>
<td>
<p>An iterable identifying the features to be crossed. Each element
can be either:
</p>

<ul>
<li><p> string: Will use the corresponding feature which must be of string type.
</p>
</li>
<li><p> categorical column: Will use the transformed tensor
produced by this column. Does not support hashed categorical columns.
</p>
</li></ul>
</td></tr>
<tr><td><code id="column_crossed_+3A_hash_bucket_size">hash_bucket_size</code></td>
<td>
<p>The number of buckets (&gt; 1).</p>
</td></tr>
<tr><td><code id="column_crossed_+3A_hash_key">hash_key</code></td>
<td>
<p>Optional: specify the hash_key that will be used by the
<code>FingerprintCat64</code> function to combine the crosses fingerprints on
<code>SparseCrossOp</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A crossed column.
</p>


<h3>Raises</h3>


<ul>
<li><p> ValueError: If <code>len(keys) &lt; 2</code>.
</p>
</li>
<li><p> ValueError: If any of the keys is neither a string nor categorical column.
</p>
</li>
<li><p> ValueError: If any of the keys is <code style="white-space: pre;">&#8288;_HashedCategoricalColumn&#8288;</code>.
</p>
</li>
<li><p> ValueError: If <code>hash_bucket_size &lt; 1</code>.
</p>
</li></ul>



<h3>See Also</h3>

<p>Other feature column constructors: 
<code><a href="#topic+column_bucketized">column_bucketized</a>()</code>,
<code><a href="#topic+column_categorical_weighted">column_categorical_weighted</a>()</code>,
<code><a href="#topic+column_categorical_with_hash_bucket">column_categorical_with_hash_bucket</a>()</code>,
<code><a href="#topic+column_categorical_with_identity">column_categorical_with_identity</a>()</code>,
<code><a href="#topic+column_categorical_with_vocabulary_file">column_categorical_with_vocabulary_file</a>()</code>,
<code><a href="#topic+column_categorical_with_vocabulary_list">column_categorical_with_vocabulary_list</a>()</code>,
<code><a href="#topic+column_embedding">column_embedding</a>()</code>,
<code><a href="#topic+column_numeric">column_numeric</a>()</code>,
<code><a href="#topic+input_layer">input_layer</a>()</code>
</p>

<hr>
<h2 id='column_embedding'>Construct a Dense Column</h2><span id='topic+column_embedding'></span>

<h3>Description</h3>

<p>Use this when your inputs are sparse, but you want to convert them to a dense
representation (e.g., to feed to a DNN). Inputs must be a
categorical column created by any of the <code style="white-space: pre;">&#8288;column_categorical_*()&#8288;</code>
functions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>column_embedding(
  categorical_column,
  dimension,
  combiner = "mean",
  initializer = NULL,
  ckpt_to_load_from = NULL,
  tensor_name_in_ckpt = NULL,
  max_norm = NULL,
  trainable = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="column_embedding_+3A_categorical_column">categorical_column</code></td>
<td>
<p>A categorical column created by a
<code style="white-space: pre;">&#8288;column_categorical_*()&#8288;</code> function. This column produces the sparse IDs
that are inputs to the embedding lookup.</p>
</td></tr>
<tr><td><code id="column_embedding_+3A_dimension">dimension</code></td>
<td>
<p>A positive integer, specifying dimension of the embedding.</p>
</td></tr>
<tr><td><code id="column_embedding_+3A_combiner">combiner</code></td>
<td>
<p>A string specifying how to reduce if there are multiple
entries in a single row. Currently <code>"mean"</code>, <code>"sqrtn"</code> and <code>"sum"</code> are
supported, with <code>"mean"</code> the default. <code>"sqrtn"</code>' often achieves good
accuracy, in particular with bag-of-words columns. Each of this can be
thought as example level normalizations on the column.</p>
</td></tr>
<tr><td><code id="column_embedding_+3A_initializer">initializer</code></td>
<td>
<p>A variable initializer function to be used in embedding
variable initialization. If not specified, defaults to
<code>tf$truncated_normal_initializer</code> with mean <code>0.0</code> and standard deviation
<code>1 / sqrt(dimension)</code>.</p>
</td></tr>
<tr><td><code id="column_embedding_+3A_ckpt_to_load_from">ckpt_to_load_from</code></td>
<td>
<p>String representing checkpoint name/pattern from
which to restore column weights. Required if <code>tensor_name_in_ckpt</code> is not
<code>NULL</code>.</p>
</td></tr>
<tr><td><code id="column_embedding_+3A_tensor_name_in_ckpt">tensor_name_in_ckpt</code></td>
<td>
<p>Name of the <code>Tensor</code> in <code>ckpt_to_load_from</code> from
which to restore the column weights. Required if <code>ckpt_to_load_from</code> is not
<code>NULL</code>.</p>
</td></tr>
<tr><td><code id="column_embedding_+3A_max_norm">max_norm</code></td>
<td>
<p>If not <code>NULL</code>, embedding values are l2-normalized to this
value.</p>
</td></tr>
<tr><td><code id="column_embedding_+3A_trainable">trainable</code></td>
<td>
<p>Whether or not the embedding is trainable. Default is TRUE.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A dense column that converts from sparse input.
</p>


<h3>Raises</h3>


<ul>
<li><p> ValueError: if <code>dimension</code> not &gt; 0.
</p>
</li>
<li><p> ValueError: if exactly one of <code>ckpt_to_load_from</code> and <code>tensor_name_in_ckpt</code>
is specified.
</p>
</li>
<li><p> ValueError: if <code>initializer</code> is specified and is not callable.
</p>
</li></ul>



<h3>See Also</h3>

<p>Other feature column constructors: 
<code><a href="#topic+column_bucketized">column_bucketized</a>()</code>,
<code><a href="#topic+column_categorical_weighted">column_categorical_weighted</a>()</code>,
<code><a href="#topic+column_categorical_with_hash_bucket">column_categorical_with_hash_bucket</a>()</code>,
<code><a href="#topic+column_categorical_with_identity">column_categorical_with_identity</a>()</code>,
<code><a href="#topic+column_categorical_with_vocabulary_file">column_categorical_with_vocabulary_file</a>()</code>,
<code><a href="#topic+column_categorical_with_vocabulary_list">column_categorical_with_vocabulary_list</a>()</code>,
<code><a href="#topic+column_crossed">column_crossed</a>()</code>,
<code><a href="#topic+column_numeric">column_numeric</a>()</code>,
<code><a href="#topic+input_layer">input_layer</a>()</code>
</p>

<hr>
<h2 id='column_indicator'>Represents Multi-Hot Representation of Given Categorical Column</h2><span id='topic+column_indicator'></span>

<h3>Description</h3>

<p>Used to wrap any <code style="white-space: pre;">&#8288;column_categorical()*&#8288;</code> (e.g., to feed to DNN). Use
<code>column_embedding()</code> if the inputs are sparse.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>column_indicator(categorical_column)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="column_indicator_+3A_categorical_column">categorical_column</code></td>
<td>
<p>A categorical column which is created by
the <code style="white-space: pre;">&#8288;column_categorical_with_*()&#8288;</code> or <code>column_crossed()</code> functions.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An indicator column.
</p>

<hr>
<h2 id='column_numeric'>Construct a Real-Valued Column</h2><span id='topic+column_numeric'></span>

<h3>Description</h3>

<p>Construct a Real-Valued Column
</p>


<h3>Usage</h3>

<pre><code class='language-R'>column_numeric(
  ...,
  shape = c(1L),
  default_value = NULL,
  dtype = tf$float32,
  normalizer_fn = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="column_numeric_+3A_...">...</code></td>
<td>
<p>Expression(s) identifying input feature(s). Used as the column
name and the dictionary key for feature parsing configs, feature tensors,
and feature columns.</p>
</td></tr>
<tr><td><code id="column_numeric_+3A_shape">shape</code></td>
<td>
<p>An integer vector that specifies the shape of the tensor. An
integer can be given which means a single dimension tensor with given
width. The tensor representing the column will have the shape of
<code>batch_size + shape</code>.</p>
</td></tr>
<tr><td><code id="column_numeric_+3A_default_value">default_value</code></td>
<td>
<p>A single value compatible with <code>dtype</code> or an iterable of
values compatible with <code>dtype</code> which the column takes on during parsing if
data is missing. A default value of <code>NULL</code> will cause <code>tf$parse_example</code> to
fail if an example does not contain this column. If a single value is
provided, the same value will be applied as the default value for every
item. If an iterable of values is provided, the shape of the
<code>default_value</code> should be equal to the given <code>shape</code>.</p>
</td></tr>
<tr><td><code id="column_numeric_+3A_dtype">dtype</code></td>
<td>
<p>The types for values contained in the column. The default value
is <code>tf$float32</code>. Must be a non-quantized, real integer or floating point
type.</p>
</td></tr>
<tr><td><code id="column_numeric_+3A_normalizer_fn">normalizer_fn</code></td>
<td>
<p>If not <code>NULL</code>, a function that can be used to normalize
the value of the tensor after <code>default_value</code> is applied for parsing.
Normalizer function takes the input <code>Tensor</code> as its argument, and returns
the output tensor. (e.g. <code style="white-space: pre;">&#8288;function(x) {(x - 3.0) / 4.2)}&#8288;</code>. Please note that
even though the most common use case of this function is normalization, it
can be used for any kind of Tensorflow transformations.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A numeric column.
</p>


<h3>Raises</h3>


<ul>
<li><p> TypeError: if any dimension in shape is not an int
</p>
</li>
<li><p> ValueError: if any dimension in shape is not a positive integer
</p>
</li>
<li><p> TypeError: if <code>default_value</code> is an iterable but not compatible with <code>shape</code>
</p>
</li>
<li><p> TypeError: if <code>default_value</code> is not compatible with <code>dtype</code>
</p>
</li>
<li><p> ValueError: if <code>dtype</code> is not convertible to <code>tf$float32</code>
</p>
</li></ul>



<h3>See Also</h3>

<p>Other feature column constructors: 
<code><a href="#topic+column_bucketized">column_bucketized</a>()</code>,
<code><a href="#topic+column_categorical_weighted">column_categorical_weighted</a>()</code>,
<code><a href="#topic+column_categorical_with_hash_bucket">column_categorical_with_hash_bucket</a>()</code>,
<code><a href="#topic+column_categorical_with_identity">column_categorical_with_identity</a>()</code>,
<code><a href="#topic+column_categorical_with_vocabulary_file">column_categorical_with_vocabulary_file</a>()</code>,
<code><a href="#topic+column_categorical_with_vocabulary_list">column_categorical_with_vocabulary_list</a>()</code>,
<code><a href="#topic+column_crossed">column_crossed</a>()</code>,
<code><a href="#topic+column_embedding">column_embedding</a>()</code>,
<code><a href="#topic+input_layer">input_layer</a>()</code>
</p>

<hr>
<h2 id='column-scope'>Establish a Feature Columns Selection Scope</h2><span id='topic+column-scope'></span><span id='topic+set_columns'></span><span id='topic+with_columns'></span><span id='topic+scoped_columns'></span>

<h3>Description</h3>

<p>This helper function provides a set of names to be
used by <code>tidyselect</code> helpers in e.g. <code><a href="#topic+feature_columns">feature_columns()</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>set_columns(columns)

with_columns(columns, expr)

scoped_columns(columns)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="column-scope_+3A_columns">columns</code></td>
<td>
<p>Either a named <span class="rlang"><b>R</b></span> object (whose names will be
used to provide a selection context), or a character vector
of such names.</p>
</td></tr>
<tr><td><code id="column-scope_+3A_expr">expr</code></td>
<td>
<p>An <span class="rlang"><b>R</b></span> expression, to be evaluated with the selection
context active.</p>
</td></tr>
</table>

<hr>
<h2 id='dnn_estimators'>Deep Neural Networks</h2><span id='topic+dnn_estimators'></span><span id='topic+dnn_regressor'></span><span id='topic+dnn_classifier'></span>

<h3>Description</h3>

<p>Create a deep neural network (DNN) estimator.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dnn_regressor(
  hidden_units,
  feature_columns,
  model_dir = NULL,
  label_dimension = 1L,
  weight_column = NULL,
  optimizer = "Adagrad",
  activation_fn = "relu",
  dropout = NULL,
  input_layer_partitioner = NULL,
  config = NULL
)

dnn_classifier(
  hidden_units,
  feature_columns,
  model_dir = NULL,
  n_classes = 2L,
  weight_column = NULL,
  label_vocabulary = NULL,
  optimizer = "Adagrad",
  activation_fn = "relu",
  dropout = NULL,
  input_layer_partitioner = NULL,
  config = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dnn_estimators_+3A_hidden_units">hidden_units</code></td>
<td>
<p>An integer vector, indicating the number of hidden
units in each layer. All layers are fully connected. For example,
<code>c(64, 32)</code> means the first layer has 64 nodes, and the second layer
has 32 nodes.</p>
</td></tr>
<tr><td><code id="dnn_estimators_+3A_feature_columns">feature_columns</code></td>
<td>
<p>An <span class="rlang"><b>R</b></span> list containing all of the feature columns used
by the model (typically, generated by <code><a href="#topic+feature_columns">feature_columns()</a></code>).</p>
</td></tr>
<tr><td><code id="dnn_estimators_+3A_model_dir">model_dir</code></td>
<td>
<p>Directory to save the model parameters, graph, and so on.
This can also be used to load checkpoints from the directory into a
estimator to continue training a previously saved model.</p>
</td></tr>
<tr><td><code id="dnn_estimators_+3A_label_dimension">label_dimension</code></td>
<td>
<p>Number of regression targets per example. This is the
size of the last dimension of the labels and logits <code>Tensor</code> objects
(typically, these have shape <code style="white-space: pre;">&#8288;[batch_size, label_dimension]&#8288;</code>).</p>
</td></tr>
<tr><td><code id="dnn_estimators_+3A_weight_column">weight_column</code></td>
<td>
<p>A string, or a numeric column created by
<code><a href="#topic+column_numeric">column_numeric()</a></code> defining feature column representing weights. It is used
to down weight or boost examples during training. It will be multiplied by
the loss of the example. If it is a string, it is used as a key to fetch
weight tensor from the <code>features</code> argument. If it is a numeric column,
then the raw tensor is fetched by key <code>weight_column$key</code>, then
<code>weight_column$normalizer_fn</code> is applied on it to get weight tensor.</p>
</td></tr>
<tr><td><code id="dnn_estimators_+3A_optimizer">optimizer</code></td>
<td>
<p>Either the name of the optimizer to be used when training
the model, or a TensorFlow optimizer instance. Defaults to the Adagrad
optimizer.</p>
</td></tr>
<tr><td><code id="dnn_estimators_+3A_activation_fn">activation_fn</code></td>
<td>
<p>The activation function to apply to each layer. This can either be an
actual activation function (e.g. <code>tf$nn$relu</code>), or the name of an
activation function (e.g. <code>"relu"</code>). Defaults to the
<code>"relu"</code> activation function. See
<a href="https://www.tensorflow.org/versions/r1.15/api_docs/python/tf/nn">https://www.tensorflow.org/versions/r1.15/api_docs/python/tf/nn</a>
for documentation related to the set of activation functions available
in TensorFlow.</p>
</td></tr>
<tr><td><code id="dnn_estimators_+3A_dropout">dropout</code></td>
<td>
<p>When not <code>NULL</code>, the probability we will drop out a given
coordinate.</p>
</td></tr>
<tr><td><code id="dnn_estimators_+3A_input_layer_partitioner">input_layer_partitioner</code></td>
<td>
<p>An optional partitioner for the input layer.
Defaults to <code>min_max_variable_partitioner</code> with <code>min_slice_size</code> 64 &lt;&lt; 20.</p>
</td></tr>
<tr><td><code id="dnn_estimators_+3A_config">config</code></td>
<td>
<p>A run configuration created by <code><a href="#topic+run_config">run_config()</a></code>, used to configure the runtime
settings.</p>
</td></tr>
<tr><td><code id="dnn_estimators_+3A_n_classes">n_classes</code></td>
<td>
<p>The number of label classes.</p>
</td></tr>
<tr><td><code id="dnn_estimators_+3A_label_vocabulary">label_vocabulary</code></td>
<td>
<p>A list of strings represents possible label values.
If given, labels must be string type and have any value in
<code>label_vocabulary</code>. If it is not given, that means labels are already
encoded as integer or float within <code style="white-space: pre;">&#8288;[0, 1]&#8288;</code> for <code>n_classes == 2</code> and
encoded as integer values in <code style="white-space: pre;">&#8288;{0, 1,..., n_classes  -1}&#8288;</code> for <code>n_classes &gt; 2</code>. Also there will be errors if vocabulary is not provided and labels are
string.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>Other canned estimators: 
<code><a href="#topic+boosted_trees_estimators">boosted_trees_estimators</a></code>,
<code><a href="#topic+dnn_linear_combined_estimators">dnn_linear_combined_estimators</a></code>,
<code><a href="#topic+linear_estimators">linear_estimators</a></code>
</p>

<hr>
<h2 id='dnn_linear_combined_estimators'>Linear Combined Deep Neural Networks</h2><span id='topic+dnn_linear_combined_estimators'></span><span id='topic+dnn_linear_combined_regressor'></span><span id='topic+dnn_linear_combined_classifier'></span>

<h3>Description</h3>

<p>Also known as <code>wide-n-deep</code> estimators, these are estimators for
TensorFlow Linear and DNN joined models for regression.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dnn_linear_combined_regressor(
  model_dir = NULL,
  linear_feature_columns = NULL,
  linear_optimizer = "Ftrl",
  dnn_feature_columns = NULL,
  dnn_optimizer = "Adagrad",
  dnn_hidden_units = NULL,
  dnn_activation_fn = "relu",
  dnn_dropout = NULL,
  label_dimension = 1L,
  weight_column = NULL,
  input_layer_partitioner = NULL,
  config = NULL
)

dnn_linear_combined_classifier(
  model_dir = NULL,
  linear_feature_columns = NULL,
  linear_optimizer = "Ftrl",
  dnn_feature_columns = NULL,
  dnn_optimizer = "Adagrad",
  dnn_hidden_units = NULL,
  dnn_activation_fn = "relu",
  dnn_dropout = NULL,
  n_classes = 2L,
  weight_column = NULL,
  label_vocabulary = NULL,
  input_layer_partitioner = NULL,
  config = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dnn_linear_combined_estimators_+3A_model_dir">model_dir</code></td>
<td>
<p>Directory to save the model parameters, graph, and so on.
This can also be used to load checkpoints from the directory into a
estimator to continue training a previously saved model.</p>
</td></tr>
<tr><td><code id="dnn_linear_combined_estimators_+3A_linear_feature_columns">linear_feature_columns</code></td>
<td>
<p>The feature columns used by linear (wide) part
of the model.</p>
</td></tr>
<tr><td><code id="dnn_linear_combined_estimators_+3A_linear_optimizer">linear_optimizer</code></td>
<td>
<p>Either the name of the optimizer to be used when
training the model, or a TensorFlow optimizer instance. Defaults to the
FTRL optimizer.</p>
</td></tr>
<tr><td><code id="dnn_linear_combined_estimators_+3A_dnn_feature_columns">dnn_feature_columns</code></td>
<td>
<p>The feature columns used by the neural network
(deep) part in the model.</p>
</td></tr>
<tr><td><code id="dnn_linear_combined_estimators_+3A_dnn_optimizer">dnn_optimizer</code></td>
<td>
<p>Either the name of the optimizer to be used when
training the model, or a TensorFlow optimizer instance. Defaults to the
Adagrad optimizer.</p>
</td></tr>
<tr><td><code id="dnn_linear_combined_estimators_+3A_dnn_hidden_units">dnn_hidden_units</code></td>
<td>
<p>An integer vector, indicating the number of hidden
units in each layer. All layers are fully connected. For example,
<code>c(64, 32)</code> means the first layer has 64 nodes, and the second layer
has 32 nodes.</p>
</td></tr>
<tr><td><code id="dnn_linear_combined_estimators_+3A_dnn_activation_fn">dnn_activation_fn</code></td>
<td>
<p>The activation function to apply to each layer. This can either be an
actual activation function (e.g. <code>tf$nn$relu</code>), or the name of an
activation function (e.g. <code>"relu"</code>). Defaults to the
<code>"relu"</code> activation function. See
<a href="https://www.tensorflow.org/versions/r1.15/api_docs/python/tf/nn">https://www.tensorflow.org/versions/r1.15/api_docs/python/tf/nn</a>
for documentation related to the set of activation functions available
in TensorFlow.</p>
</td></tr>
<tr><td><code id="dnn_linear_combined_estimators_+3A_dnn_dropout">dnn_dropout</code></td>
<td>
<p>When not <code>NULL</code>, the probability we will drop out a given
coordinate.</p>
</td></tr>
<tr><td><code id="dnn_linear_combined_estimators_+3A_label_dimension">label_dimension</code></td>
<td>
<p>Number of regression targets per example. This is the
size of the last dimension of the labels and logits <code>Tensor</code> objects
(typically, these have shape <code style="white-space: pre;">&#8288;[batch_size, label_dimension]&#8288;</code>).</p>
</td></tr>
<tr><td><code id="dnn_linear_combined_estimators_+3A_weight_column">weight_column</code></td>
<td>
<p>A string, or a numeric column created by
<code><a href="#topic+column_numeric">column_numeric()</a></code> defining feature column representing weights. It is used
to down weight or boost examples during training. It will be multiplied by
the loss of the example. If it is a string, it is used as a key to fetch
weight tensor from the <code>features</code> argument. If it is a numeric column,
then the raw tensor is fetched by key <code>weight_column$key</code>, then
<code>weight_column$normalizer_fn</code> is applied on it to get weight tensor.</p>
</td></tr>
<tr><td><code id="dnn_linear_combined_estimators_+3A_input_layer_partitioner">input_layer_partitioner</code></td>
<td>
<p>An optional partitioner for the input layer.
Defaults to <code>min_max_variable_partitioner</code> with <code>min_slice_size</code> 64 &lt;&lt; 20.</p>
</td></tr>
<tr><td><code id="dnn_linear_combined_estimators_+3A_config">config</code></td>
<td>
<p>A run configuration created by <code><a href="#topic+run_config">run_config()</a></code>, used to configure the runtime
settings.</p>
</td></tr>
<tr><td><code id="dnn_linear_combined_estimators_+3A_n_classes">n_classes</code></td>
<td>
<p>The number of label classes.</p>
</td></tr>
<tr><td><code id="dnn_linear_combined_estimators_+3A_label_vocabulary">label_vocabulary</code></td>
<td>
<p>A list of strings represents possible label values.
If given, labels must be string type and have any value in
<code>label_vocabulary</code>. If it is not given, that means labels are already
encoded as integer or float within <code style="white-space: pre;">&#8288;[0, 1]&#8288;</code> for <code>n_classes == 2</code> and
encoded as integer values in <code style="white-space: pre;">&#8288;{0, 1,..., n_classes  -1}&#8288;</code> for <code>n_classes &gt; 2</code>. Also there will be errors if vocabulary is not provided and labels are
string.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>Other canned estimators: 
<code><a href="#topic+boosted_trees_estimators">boosted_trees_estimators</a></code>,
<code><a href="#topic+dnn_estimators">dnn_estimators</a></code>,
<code><a href="#topic+linear_estimators">linear_estimators</a></code>
</p>

<hr>
<h2 id='estimator'>Construct a Custom Estimator</h2><span id='topic+estimator'></span>

<h3>Description</h3>

<p>Construct a custom estimator, to be used to train and evaluate
TensorFlow models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>estimator(
  model_fn,
  model_dir = NULL,
  config = NULL,
  params = NULL,
  class = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="estimator_+3A_model_fn">model_fn</code></td>
<td>
<p>The model function. See <strong>Model Function</strong> for details
on the structure of a model function.</p>
</td></tr>
<tr><td><code id="estimator_+3A_model_dir">model_dir</code></td>
<td>
<p>Directory to save model parameters, graph and etc. This can
also be used to load checkpoints from the directory into a estimator to
continue training a previously saved model. If <code>NULL</code>, the <code>model_dir</code> in
<code>config</code> will be used if set. If both are set, they must be same. If both
are <code>NULL</code>, a temporary directory will be used.</p>
</td></tr>
<tr><td><code id="estimator_+3A_config">config</code></td>
<td>
<p>Configuration object.</p>
</td></tr>
<tr><td><code id="estimator_+3A_params">params</code></td>
<td>
<p>List of hyper parameters that will be passed into <code>model_fn</code>.
Keys are names of parameters, values are basic python types.</p>
</td></tr>
<tr><td><code id="estimator_+3A_class">class</code></td>
<td>
<p>An optional set of <span class="rlang"><b>R</b></span> classes to add to the generated object.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>Estimator</code> object wraps a model which is specified by a <code>model_fn</code>,
which, given inputs and a number of other parameters, returns the operations
necessary to perform training, evaluation, and prediction.
</p>
<p>All outputs (checkpoints, event files, etc.) are written to <code>model_dir</code>, or a
subdirectory thereof. If <code>model_dir</code> is not set, a temporary directory is
used.
</p>
<p>The <code>config</code> argument can be used to passed run configuration object
containing information about the execution environment. It is passed on to
the <code>model_fn</code>, if the <code>model_fn</code> has a parameter named &quot;config&quot; (and input
functions in the same manner). If the <code>config</code> parameter is not passed, it is
instantiated by <code>estimator()</code>. Not passing config means that defaults useful
for local execution are used. <code>estimator()</code> makes config available to the
model (for instance, to allow specialization based on the number of workers
available), and also uses some of its fields to control internals, especially
regarding checkpointing.
</p>
<p>The <code>params</code> argument contains hyperparameters. It is passed to the
<code>model_fn</code>, if the <code>model_fn</code> has a parameter named &quot;params&quot;, and to the
input functions in the same manner. <code>estimator()</code> only passes <code>params</code> along, it
does not inspect it. The structure of <code>params</code> is therefore entirely up to
the developer.
</p>
<p>None of estimator's methods can be overridden in subclasses (its
constructor enforces this). Subclasses should use <code>model_fn</code> to configure the
base class, and may add methods implementing specialized functionality.
</p>


<h3>Model Functions</h3>

<p>The <code>model_fn</code> should be an <span class="rlang"><b>R</b></span> function of the form:
</p>
<pre>function(features, labels, mode, params) {
    # 1. Configure the model via TensorFlow operations.
    # 2. Define the loss function for training and evaluation.
    # 3. Define the training optimizer.
    # 4. Define how predictions should be produced.
    # 5. Return the result as an `estimator_spec()` object.
    estimator_spec(mode, predictions, loss, train_op, eval_metric_ops)
}</pre>
<p>The model function's inputs are defined as follows:
</p>

<table>
<tr>
 <td style="text-align: left;">
<code>features</code> </td><td style="text-align: left;">
The feature tensor(s). </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>labels</code>   </td><td style="text-align: left;">
The label tensor(s). </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>mode</code>     </td><td style="text-align: left;">
The current training mode ("train", "eval", "infer").
These can be accessed through the <code>mode_keys()</code> object. </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>params</code>   </td><td style="text-align: left;">
An optional list of hyperparameters, as received
through the <code>estimator()</code> constructor. </td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>

<p>See <code><a href="#topic+estimator_spec">estimator_spec()</a></code> for more details as to how the estimator specification
should be constructed, and <a href="https://www.tensorflow.org/versions/r1.15/api_docs/python/tf/estimator/Estimator">https://www.tensorflow.org/versions/r1.15/api_docs/python/tf/estimator/Estimator</a> for
more information as to how the model function should be constructed.
</p>


<h3>See Also</h3>

<p>Other custom estimator methods: 
<code><a href="#topic+estimator_spec">estimator_spec</a>()</code>,
<code><a href="#topic+evaluate.tf_estimator">evaluate.tf_estimator</a>()</code>,
<code><a href="#topic+export_savedmodel.tf_estimator">export_savedmodel.tf_estimator</a>()</code>,
<code><a href="#topic+predict.tf_estimator">predict.tf_estimator</a>()</code>,
<code><a href="#topic+train.tf_estimator">train.tf_estimator</a>()</code>
</p>

<hr>
<h2 id='estimator_spec'>Define an Estimator Specification</h2><span id='topic+estimator_spec'></span>

<h3>Description</h3>

<p>Define the estimator specification, used as part of the <code>model_fn</code> defined with
custom estimators created by <code><a href="#topic+estimator">estimator()</a></code>. See <code><a href="#topic+estimator">estimator()</a></code> for more details.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>estimator_spec(
  mode,
  predictions = NULL,
  loss = NULL,
  train_op = NULL,
  eval_metric_ops = NULL,
  training_hooks = NULL,
  evaluation_hooks = NULL,
  prediction_hooks = NULL,
  training_chief_hooks = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="estimator_spec_+3A_mode">mode</code></td>
<td>
<p>A key that specifies whether we are performing
training (<code>"train"</code>), evaluation (<code>"eval"</code>), or prediction (<code>"infer"</code>).
These values can also be accessed through the <code><a href="#topic+mode_keys">mode_keys()</a></code> object.</p>
</td></tr>
<tr><td><code id="estimator_spec_+3A_predictions">predictions</code></td>
<td>
<p>The prediction tensor(s).</p>
</td></tr>
<tr><td><code id="estimator_spec_+3A_loss">loss</code></td>
<td>
<p>The training loss tensor. Must be either scalar, or with shape <code>c(1)</code>.</p>
</td></tr>
<tr><td><code id="estimator_spec_+3A_train_op">train_op</code></td>
<td>
<p>The training operation &ndash; typically, a call to <code>optimizer$minimize(...)</code>,
depending on the type of optimizer used during training.</p>
</td></tr>
<tr><td><code id="estimator_spec_+3A_eval_metric_ops">eval_metric_ops</code></td>
<td>
<p>A list of metrics to be computed as part of evaluation.
This should be a named list, mapping metric names (e.g. <code>"rmse"</code>) to the operation
that computes the associated metric (e.g. <code>tf$metrics$root_mean_squared_error(...)</code>).
These metric operations should be evaluated without any impact on state (typically
is a pure computation results based on variables). For example, it should not
trigger the update ops or requires any input fetching.</p>
</td></tr>
<tr><td><code id="estimator_spec_+3A_training_hooks">training_hooks</code></td>
<td>
<p>(Available since TensorFlow v1.4) A list of session run hooks to run on all workers during training.</p>
</td></tr>
<tr><td><code id="estimator_spec_+3A_evaluation_hooks">evaluation_hooks</code></td>
<td>
<p>(Available since TensorFlow v1.4) A list of session run hooks to run during evaluation.</p>
</td></tr>
<tr><td><code id="estimator_spec_+3A_prediction_hooks">prediction_hooks</code></td>
<td>
<p>(Available since TensorFlow v1.7) A list of session run hooks to run during prediciton.</p>
</td></tr>
<tr><td><code id="estimator_spec_+3A_training_chief_hooks">training_chief_hooks</code></td>
<td>
<p>(Available since TensorFlow v1.4) A list of session run hooks to run on chief worker during training.</p>
</td></tr>
<tr><td><code id="estimator_spec_+3A_...">...</code></td>
<td>
<p>Other optional (named) arguments, to be passed to the <code>EstimatorSpec</code> constructor.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>Other custom estimator methods: 
<code><a href="#topic+estimator">estimator</a>()</code>,
<code><a href="#topic+evaluate.tf_estimator">evaluate.tf_estimator</a>()</code>,
<code><a href="#topic+export_savedmodel.tf_estimator">export_savedmodel.tf_estimator</a>()</code>,
<code><a href="#topic+predict.tf_estimator">predict.tf_estimator</a>()</code>,
<code><a href="#topic+train.tf_estimator">train.tf_estimator</a>()</code>
</p>

<hr>
<h2 id='estimators'>Base Documentation for Canned Estimators</h2><span id='topic+estimators'></span>

<h3>Description</h3>

<p>Base Documentation for Canned Estimators
</p>


<h3>Arguments</h3>

<table>
<tr><td><code id="estimators_+3A_object">object</code></td>
<td>
<p>A TensorFlow estimator.</p>
</td></tr>
<tr><td><code id="estimators_+3A_feature_columns">feature_columns</code></td>
<td>
<p>An <span class="rlang"><b>R</b></span> list containing all of the feature columns used
by the model (typically, generated by <code><a href="#topic+feature_columns">feature_columns()</a></code>).</p>
</td></tr>
<tr><td><code id="estimators_+3A_model_dir">model_dir</code></td>
<td>
<p>Directory to save the model parameters, graph, and so on.
This can also be used to load checkpoints from the directory into a
estimator to continue training a previously saved model.</p>
</td></tr>
<tr><td><code id="estimators_+3A_label_dimension">label_dimension</code></td>
<td>
<p>Number of regression targets per example. This is the
size of the last dimension of the labels and logits <code>Tensor</code> objects
(typically, these have shape <code style="white-space: pre;">&#8288;[batch_size, label_dimension]&#8288;</code>).</p>
</td></tr>
<tr><td><code id="estimators_+3A_label_vocabulary">label_vocabulary</code></td>
<td>
<p>A list of strings represents possible label values.
If given, labels must be string type and have any value in
<code>label_vocabulary</code>. If it is not given, that means labels are already
encoded as integer or float within <code style="white-space: pre;">&#8288;[0, 1]&#8288;</code> for <code>n_classes == 2</code> and
encoded as integer values in <code style="white-space: pre;">&#8288;{0, 1,..., n_classes  -1}&#8288;</code> for <code>n_classes &gt; 2</code>. Also there will be errors if vocabulary is not provided and labels are
string.</p>
</td></tr>
<tr><td><code id="estimators_+3A_weight_column">weight_column</code></td>
<td>
<p>A string, or a numeric column created by
<code><a href="#topic+column_numeric">column_numeric()</a></code> defining feature column representing weights. It is used
to down weight or boost examples during training. It will be multiplied by
the loss of the example. If it is a string, it is used as a key to fetch
weight tensor from the <code>features</code> argument. If it is a numeric column,
then the raw tensor is fetched by key <code>weight_column$key</code>, then
<code>weight_column$normalizer_fn</code> is applied on it to get weight tensor.</p>
</td></tr>
<tr><td><code id="estimators_+3A_n_classes">n_classes</code></td>
<td>
<p>The number of label classes.</p>
</td></tr>
<tr><td><code id="estimators_+3A_config">config</code></td>
<td>
<p>A run configuration created by <code><a href="#topic+run_config">run_config()</a></code>, used to configure the runtime
settings.</p>
</td></tr>
<tr><td><code id="estimators_+3A_input_layer_partitioner">input_layer_partitioner</code></td>
<td>
<p>An optional partitioner for the input layer.
Defaults to <code>min_max_variable_partitioner</code> with <code>min_slice_size</code> 64 &lt;&lt; 20.</p>
</td></tr>
<tr><td><code id="estimators_+3A_partitioner">partitioner</code></td>
<td>
<p>An optional partitioner for the input layer.</p>
</td></tr>
</table>

<hr>
<h2 id='eval_spec'>Configuration for the eval component of <code>train_and_evaluate</code></h2><span id='topic+eval_spec'></span>

<h3>Description</h3>

<p><code>EvalSpec</code> combines details of evaluation of the trained model as well as its
export. Evaluation consists of computing metrics to judge the performance of
the trained model. Export writes out the trained model on to external
storage.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>eval_spec(
  input_fn,
  steps = 100,
  name = NULL,
  hooks = NULL,
  exporters = NULL,
  start_delay_secs = 120,
  throttle_secs = 600
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="eval_spec_+3A_input_fn">input_fn</code></td>
<td>
<p>Evaluation input function returning a tuple of:
</p>

<ul>
<li><p> features - <code>Tensor</code> or dictionary of string feature name to <code>Tensor</code>.
</p>
</li>
<li><p> labels - <code>Tensor</code> or dictionary of <code>Tensor</code> with labels.
</p>
</li></ul>
</td></tr>
<tr><td><code id="eval_spec_+3A_steps">steps</code></td>
<td>
<p>Positive number of steps for which to evaluate model.
If <code>NULL</code>, evaluates until <code>input_fn</code> raises an end-of-input exception.</p>
</td></tr>
<tr><td><code id="eval_spec_+3A_name">name</code></td>
<td>
<p>Name of the evaluation if user needs to run multiple
evaluations on different data sets. Metrics for different evaluations
are saved in separate folders, and appear separately in tensorboard.</p>
</td></tr>
<tr><td><code id="eval_spec_+3A_hooks">hooks</code></td>
<td>
<p>List of session run hooks to run
during evaluation.</p>
</td></tr>
<tr><td><code id="eval_spec_+3A_exporters">exporters</code></td>
<td>
<p>List of <code>Exporter</code>s, or a single one, or <code>NULL</code>.
<code>exporters</code> will be invoked after each evaluation.</p>
</td></tr>
<tr><td><code id="eval_spec_+3A_start_delay_secs">start_delay_secs</code></td>
<td>
<p>Start evaluating after waiting for this many
seconds.</p>
</td></tr>
<tr><td><code id="eval_spec_+3A_throttle_secs">throttle_secs</code></td>
<td>
<p>Do not re-evaluate unless the last evaluation was
started at least this many seconds ago. Of course, evaluation does not
occur if no new checkpoints are available, hence, this is the minimum.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>Other training methods: 
<code><a href="#topic+train_and_evaluate.tf_estimator">train_and_evaluate.tf_estimator</a>()</code>,
<code><a href="#topic+train_spec">train_spec</a>()</code>
</p>

<hr>
<h2 id='evaluate.tf_estimator'>Evaluate an Estimator</h2><span id='topic+evaluate.tf_estimator'></span>

<h3>Description</h3>

<p>Evaluate an estimator on input data provided by an <code>input_fn()</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'tf_estimator'
evaluate(
  object,
  input_fn,
  steps = NULL,
  checkpoint_path = NULL,
  name = NULL,
  hooks = NULL,
  simplify = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="evaluate.tf_estimator_+3A_object">object</code></td>
<td>
<p>A TensorFlow estimator.</p>
</td></tr>
<tr><td><code id="evaluate.tf_estimator_+3A_input_fn">input_fn</code></td>
<td>
<p>An input function, typically generated by the <code><a href="#topic+input_fn">input_fn()</a></code>
helper function.</p>
</td></tr>
<tr><td><code id="evaluate.tf_estimator_+3A_steps">steps</code></td>
<td>
<p>The number of steps for which the model should be evaluated on
this particular <code>evaluate()</code> invocation. If <code>NULL</code> (the default), this function
will either evaluate forever, or until the supplied <code>input_fn()</code> has provided
all available data.</p>
</td></tr>
<tr><td><code id="evaluate.tf_estimator_+3A_checkpoint_path">checkpoint_path</code></td>
<td>
<p>The path to a specific model checkpoint to be used for
prediction. If <code>NULL</code> (the default), the latest checkpoint in <code>model_dir</code>
is used.</p>
</td></tr>
<tr><td><code id="evaluate.tf_estimator_+3A_name">name</code></td>
<td>
<p>Name of the evaluation if user needs to run multiple evaluations
on different data sets, such as on training data vs test data. Metrics for
different evaluations are saved in separate folders, and appear separately
in tensorboard.</p>
</td></tr>
<tr><td><code id="evaluate.tf_estimator_+3A_hooks">hooks</code></td>
<td>
<p>A list of <span class="rlang"><b>R</b></span> functions, to be used as callbacks inside the
training loop. By default, <code>hook_history_saver(every_n_step = 10)</code> and
<code>hook_progress_bar()</code> will be attached if not provided to save the metrics
history and create the progress bar.</p>
</td></tr>
<tr><td><code id="evaluate.tf_estimator_+3A_simplify">simplify</code></td>
<td>
<p>Whether to simplify evaluation results into a <code>tibble</code>, as
opposed to a list. Defaults to <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="evaluate.tf_estimator_+3A_...">...</code></td>
<td>
<p>Optional arguments passed on to the estimator's <code>evaluate()</code>
method.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For each step, this method will call <code>input_fn()</code> to produce a single batch
of data. Evaluation continues until:
</p>

<ul>
<li> <p><code>steps</code> batches are processed, or
</p>
</li>
<li><p> The <code>input_fn()</code> is exhausted of data.
</p>
</li></ul>



<h3>Value</h3>

<p>An <span class="rlang"><b>R</b></span> list of evaluation metrics.
</p>


<h3>See Also</h3>

<p>Other custom estimator methods: 
<code><a href="#topic+estimator_spec">estimator_spec</a>()</code>,
<code><a href="#topic+estimator">estimator</a>()</code>,
<code><a href="#topic+export_savedmodel.tf_estimator">export_savedmodel.tf_estimator</a>()</code>,
<code><a href="#topic+predict.tf_estimator">predict.tf_estimator</a>()</code>,
<code><a href="#topic+train.tf_estimator">train.tf_estimator</a>()</code>
</p>

<hr>
<h2 id='experiment'>Construct an Experiment</h2><span id='topic+experiment'></span>

<h3>Description</h3>

<p>Construct an experiment object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>experiment(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="experiment_+3A_object">object</code></td>
<td>
<p>An <span class="rlang"><b>R</b></span> object.</p>
</td></tr>
<tr><td><code id="experiment_+3A_...">...</code></td>
<td>
<p>Optional arguments passed on to implementing methods.</p>
</td></tr>
</table>

<hr>
<h2 id='export_savedmodel.tf_estimator'>Save an Estimator</h2><span id='topic+export_savedmodel.tf_estimator'></span>

<h3>Description</h3>

<p>Save an estimator (alongside its weights) to the directory <code>export_dir_base</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'tf_estimator'
export_savedmodel(
  object,
  export_dir_base,
  serving_input_receiver_fn = NULL,
  assets_extra = NULL,
  as_text = FALSE,
  checkpoint_path = NULL,
  overwrite = TRUE,
  versioned = !overwrite,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="export_savedmodel.tf_estimator_+3A_object">object</code></td>
<td>
<p>A TensorFlow estimator.</p>
</td></tr>
<tr><td><code id="export_savedmodel.tf_estimator_+3A_export_dir_base">export_dir_base</code></td>
<td>
<p>A string containing a directory in which to export the
SavedModel.</p>
</td></tr>
<tr><td><code id="export_savedmodel.tf_estimator_+3A_serving_input_receiver_fn">serving_input_receiver_fn</code></td>
<td>
<p>A function that takes no argument and
returns a <code>ServingInputReceiver</code>. Required for custom models.</p>
</td></tr>
<tr><td><code id="export_savedmodel.tf_estimator_+3A_assets_extra">assets_extra</code></td>
<td>
<p>A dict specifying how to populate the assets.extra
directory within the exported SavedModel, or <code>NULL</code> if no extra assets are
needed.</p>
</td></tr>
<tr><td><code id="export_savedmodel.tf_estimator_+3A_as_text">as_text</code></td>
<td>
<p>whether to write the SavedModel proto in text format.</p>
</td></tr>
<tr><td><code id="export_savedmodel.tf_estimator_+3A_checkpoint_path">checkpoint_path</code></td>
<td>
<p>The checkpoint path to export. If <code>NULL</code> (the
default), the most recent checkpoint found within the model directory is
chosen.</p>
</td></tr>
<tr><td><code id="export_savedmodel.tf_estimator_+3A_overwrite">overwrite</code></td>
<td>
<p>Should the <code>export_dir</code> directory be overwritten?</p>
</td></tr>
<tr><td><code id="export_savedmodel.tf_estimator_+3A_versioned">versioned</code></td>
<td>
<p>Should the model be exported under a versioned subdirectory?</p>
</td></tr>
<tr><td><code id="export_savedmodel.tf_estimator_+3A_...">...</code></td>
<td>
<p>Optional arguments passed on to the estimator's
<code>export_savedmodel()</code> method.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This method builds a new graph by first calling the serving_input_receiver_fn
to obtain feature <code>Tensor</code>s, and then calling this <code>Estimator</code>'s model_fn to
generate the model graph based on those features. It restores the given
checkpoint (or, lacking that, the most recent checkpoint) into this graph in
a fresh session. Finally it creates a timestamped export directory below the
given export_dir_base, and writes a <code>SavedModel</code> into it containing a single
<code>MetaGraphDef</code> saved from this session. The exported <code>MetaGraphDef</code> will
provide one <code>SignatureDef</code> for each element of the export_outputs dict
returned from the model_fn, named using the same keys. One of these keys is
always signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY, indicating
which signature will be served when a serving request does not specify one.
For each signature, the outputs are provided by the corresponding
<code>ExportOutput</code>s, and the inputs are always the input receivers provided by
the serving_input_receiver_fn. Extra assets may be written into the
SavedModel via the extra_assets argument. This should be a dict, where each
key gives a destination path (including the filename) relative to the
assets.extra directory. The corresponding value gives the full path of the
source file to be copied. For example, the simple case of copying a single
file without renaming it is specified as <code>{'my_asset_file.txt': '/path/to/my_asset_file.txt'}</code>.
</p>


<h3>Value</h3>

<p>The path to the exported directory, as a string.
</p>


<h3>Raises</h3>

<p>ValueError: if no serving_input_receiver_fn is provided, no
export_outputs are provided, or no checkpoint can be found.
</p>


<h3>See Also</h3>

<p>Other custom estimator methods: 
<code><a href="#topic+estimator_spec">estimator_spec</a>()</code>,
<code><a href="#topic+estimator">estimator</a>()</code>,
<code><a href="#topic+evaluate.tf_estimator">evaluate.tf_estimator</a>()</code>,
<code><a href="#topic+predict.tf_estimator">predict.tf_estimator</a>()</code>,
<code><a href="#topic+train.tf_estimator">train.tf_estimator</a>()</code>
</p>

<hr>
<h2 id='feature_columns'>Feature Columns</h2><span id='topic+feature_columns'></span>

<h3>Description</h3>

<p>Constructors for feature columns. A feature column defines the expected
'shape' of an input Tensor.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>feature_columns(..., names = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="feature_columns_+3A_...">...</code></td>
<td>
<p>One or more feature column definitions. The <a href="tidyselect.html#topic+tidyselect">tidyselect</a> package
is used to power generation of feature columns.</p>
</td></tr>
<tr><td><code id="feature_columns_+3A_names">names</code></td>
<td>
<p>Available feature names (for selection / pattern matching) as a
character vector (or R object that implements <code>names()</code> or <code>colnames()</code>).</p>
</td></tr>
</table>

<hr>
<h2 id='graph_keys'>Standard Names to Use for Graph Collections</h2><span id='topic+graph_keys'></span>

<h3>Description</h3>

<p>The standard library uses various well-known names to collect and retrieve
values associated with a graph.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>graph_keys()
</code></pre>


<h3>Details</h3>

<p>For example, the <code>tf$Optimizer</code> subclasses default to optimizing the
variables collected under<code>graph_keys()$TRAINABLE_VARIABLES</code> if <code>NULL</code> is
specified, but it is also possible to pass an explicit list of variables.
</p>
<p>The following standard keys are defined:
</p>

<ul>
<li> <p><code>GLOBAL_VARIABLES</code>: the default collection of <code>Variable</code> objects, shared
across distributed environment (model variables are subset of these). See
<code>tf$global_variables</code> for more details. Commonly, all <code>TRAINABLE_VARIABLES</code>
variables will be in <code>MODEL_VARIABLES</code>, and all <code>MODEL_VARIABLES</code> variables
will be in <code>GLOBAL_VARIABLES</code>.
</p>
</li>
<li> <p><code>LOCAL_VARIABLES</code>: the subset of <code>Variable</code> objects that are local to each
machine. Usually used for temporarily variables, like counters. Note: use
<code>tf$contrib$framework$local_variable</code> to add to this collection.
</p>
</li>
<li> <p><code>MODEL_VARIABLES</code>: the subset of <code>Variable</code> objects that are used in the
model for inference (feed forward). Note: use
<code>tf$contrib$framework$model_variable</code> to add to this collection.
</p>
</li>
<li> <p><code>TRAINABLE_VARIABLES</code>: the subset of <code>Variable</code> objects that will be
trained by an optimizer. See <code>tf$trainable_variables</code> for more details.
</p>
</li>
<li> <p><code>SUMMARIES</code>: the summary <code>Tensor</code> objects that have been created in the
graph. See <code>tf$summary$merge_all</code> for more details.
</p>
</li>
<li> <p><code>QUEUE_RUNNERS</code>: the <code>QueueRunner</code> objects that are used to produce input
for a computation. See <code>tf$train$start_queue_runners</code> for more details.
</p>
</li>
<li> <p><code>MOVING_AVERAGE_VARIABLES</code>: the subset of <code>Variable</code> objects that will also
keep moving averages. See <code>tf$moving_average_variables</code> for more details.
</p>
</li>
<li> <p><code>REGULARIZATION_LOSSES</code>: regularization losses collected during graph
construction. The following standard keys are defined, but their
collections are <strong>not</strong> automatically populated as many of the others are:
</p>

<ul>
<li> <p><code>WEIGHTS</code>
</p>
</li>
<li> <p><code>BIASES</code>
</p>
</li>
<li> <p><code>ACTIVATIONS</code>
</p>
</li></ul>

</li></ul>



<h3>See Also</h3>

<p>Other utility functions: 
<code><a href="#topic+latest_checkpoint">latest_checkpoint</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
graph_keys()
graph_keys()$LOSSES

## End(Not run)

</code></pre>

<hr>
<h2 id='hook_checkpoint_saver'>Saves Checkpoints Every N Steps or Seconds</h2><span id='topic+hook_checkpoint_saver'></span>

<h3>Description</h3>

<p>Saves Checkpoints Every N Steps or Seconds
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hook_checkpoint_saver(
  checkpoint_dir,
  save_secs = NULL,
  save_steps = NULL,
  saver = NULL,
  checkpoint_basename = "model.ckpt",
  scaffold = NULL,
  listeners = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="hook_checkpoint_saver_+3A_checkpoint_dir">checkpoint_dir</code></td>
<td>
<p>The base directory for the checkpoint files.</p>
</td></tr>
<tr><td><code id="hook_checkpoint_saver_+3A_save_secs">save_secs</code></td>
<td>
<p>An integer, indicating saving checkpoints every N secs.</p>
</td></tr>
<tr><td><code id="hook_checkpoint_saver_+3A_save_steps">save_steps</code></td>
<td>
<p>An integer, indicating saving checkpoints every N steps.</p>
</td></tr>
<tr><td><code id="hook_checkpoint_saver_+3A_saver">saver</code></td>
<td>
<p>A saver object, used for saving.</p>
</td></tr>
<tr><td><code id="hook_checkpoint_saver_+3A_checkpoint_basename">checkpoint_basename</code></td>
<td>
<p>The base name for the checkpoint files.</p>
</td></tr>
<tr><td><code id="hook_checkpoint_saver_+3A_scaffold">scaffold</code></td>
<td>
<p>A scaffold, used to get saver object.</p>
</td></tr>
<tr><td><code id="hook_checkpoint_saver_+3A_listeners">listeners</code></td>
<td>
<p>List of checkpoint saver listener subclass instances, used
for callbacks that run immediately after the corresponding
<code>hook_checkpoint_saver</code> callbacks, only in steps where <code style="white-space: pre;">&#8288;the hook_checkpoint_saver&#8288;</code>
was triggered.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>Other session_run_hook wrappers: 
<code><a href="#topic+hook_global_step_waiter">hook_global_step_waiter</a>()</code>,
<code><a href="#topic+hook_history_saver">hook_history_saver</a>()</code>,
<code><a href="#topic+hook_logging_tensor">hook_logging_tensor</a>()</code>,
<code><a href="#topic+hook_nan_tensor">hook_nan_tensor</a>()</code>,
<code><a href="#topic+hook_progress_bar">hook_progress_bar</a>()</code>,
<code><a href="#topic+hook_step_counter">hook_step_counter</a>()</code>,
<code><a href="#topic+hook_stop_at_step">hook_stop_at_step</a>()</code>,
<code><a href="#topic+hook_summary_saver">hook_summary_saver</a>()</code>,
<code><a href="#topic+session_run_hook">session_run_hook</a>()</code>
</p>

<hr>
<h2 id='hook_global_step_waiter'>Delay Execution until Global Step Reaches to <code>wait_until_step</code>.</h2><span id='topic+hook_global_step_waiter'></span>

<h3>Description</h3>

<p>This hook delays execution until global step reaches to <code>wait_until_step</code>. It
is used to gradually start workers in distributed settings. One example usage
would be setting <code>wait_until_step=int(K*log(task_id+1))</code> assuming that
<code>task_id=0</code> is the chief.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hook_global_step_waiter(wait_until_step)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="hook_global_step_waiter_+3A_wait_until_step">wait_until_step</code></td>
<td>
<p>An integer indicating that until which global step should we wait.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>Other session_run_hook wrappers: 
<code><a href="#topic+hook_checkpoint_saver">hook_checkpoint_saver</a>()</code>,
<code><a href="#topic+hook_history_saver">hook_history_saver</a>()</code>,
<code><a href="#topic+hook_logging_tensor">hook_logging_tensor</a>()</code>,
<code><a href="#topic+hook_nan_tensor">hook_nan_tensor</a>()</code>,
<code><a href="#topic+hook_progress_bar">hook_progress_bar</a>()</code>,
<code><a href="#topic+hook_step_counter">hook_step_counter</a>()</code>,
<code><a href="#topic+hook_stop_at_step">hook_stop_at_step</a>()</code>,
<code><a href="#topic+hook_summary_saver">hook_summary_saver</a>()</code>,
<code><a href="#topic+session_run_hook">session_run_hook</a>()</code>
</p>

<hr>
<h2 id='hook_history_saver'>A Custom Run Hook for Saving Metrics History</h2><span id='topic+hook_history_saver'></span>

<h3>Description</h3>

<p>This hook allows users to save the metrics history produced during training or evaluation in
a specified frequency.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hook_history_saver(every_n_step = 10)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="hook_history_saver_+3A_every_n_step">every_n_step</code></td>
<td>
<p>Save the metrics every N steps</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>Other session_run_hook wrappers: 
<code><a href="#topic+hook_checkpoint_saver">hook_checkpoint_saver</a>()</code>,
<code><a href="#topic+hook_global_step_waiter">hook_global_step_waiter</a>()</code>,
<code><a href="#topic+hook_logging_tensor">hook_logging_tensor</a>()</code>,
<code><a href="#topic+hook_nan_tensor">hook_nan_tensor</a>()</code>,
<code><a href="#topic+hook_progress_bar">hook_progress_bar</a>()</code>,
<code><a href="#topic+hook_step_counter">hook_step_counter</a>()</code>,
<code><a href="#topic+hook_stop_at_step">hook_stop_at_step</a>()</code>,
<code><a href="#topic+hook_summary_saver">hook_summary_saver</a>()</code>,
<code><a href="#topic+session_run_hook">session_run_hook</a>()</code>
</p>

<hr>
<h2 id='hook_logging_tensor'>Prints Given Tensors Every N Local Steps, Every N Seconds, or at End</h2><span id='topic+hook_logging_tensor'></span>

<h3>Description</h3>

<p>The tensors will be printed to the log, with <code>INFO</code> severity.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hook_logging_tensor(
  tensors,
  every_n_iter = NULL,
  every_n_secs = NULL,
  formatter = NULL,
  at_end = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="hook_logging_tensor_+3A_tensors">tensors</code></td>
<td>
<p>A list that maps string-valued tags to tensors/tensor names.</p>
</td></tr>
<tr><td><code id="hook_logging_tensor_+3A_every_n_iter">every_n_iter</code></td>
<td>
<p>An integer value, indicating the values of <code>tensors</code> will be printed
once every N local steps taken on the current worker.</p>
</td></tr>
<tr><td><code id="hook_logging_tensor_+3A_every_n_secs">every_n_secs</code></td>
<td>
<p>An integer or float value, indicating the values of <code>tensors</code> will be printed
once every N seconds. Exactly one of <code>every_n_iter</code> and <code>every_n_secs</code> should be provided.</p>
</td></tr>
<tr><td><code id="hook_logging_tensor_+3A_formatter">formatter</code></td>
<td>
<p>A function that takes <code>list(tag = tensor)</code> and returns a
string. If <code>NULL</code> uses default printing all tensors.</p>
</td></tr>
<tr><td><code id="hook_logging_tensor_+3A_at_end">at_end</code></td>
<td>
<p>A boolean value specifying whether to print the values of <code>tensors</code> at the
end of the run.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Note that if <code>at_end</code> is <code>TRUE</code>, <code>tensors</code> should not include any tensor
whose evaluation produces a side effect such as consuming additional inputs.
</p>


<h3>See Also</h3>

<p>Other session_run_hook wrappers: 
<code><a href="#topic+hook_checkpoint_saver">hook_checkpoint_saver</a>()</code>,
<code><a href="#topic+hook_global_step_waiter">hook_global_step_waiter</a>()</code>,
<code><a href="#topic+hook_history_saver">hook_history_saver</a>()</code>,
<code><a href="#topic+hook_nan_tensor">hook_nan_tensor</a>()</code>,
<code><a href="#topic+hook_progress_bar">hook_progress_bar</a>()</code>,
<code><a href="#topic+hook_step_counter">hook_step_counter</a>()</code>,
<code><a href="#topic+hook_stop_at_step">hook_stop_at_step</a>()</code>,
<code><a href="#topic+hook_summary_saver">hook_summary_saver</a>()</code>,
<code><a href="#topic+session_run_hook">session_run_hook</a>()</code>
</p>

<hr>
<h2 id='hook_nan_tensor'>NaN Loss Monitor</h2><span id='topic+hook_nan_tensor'></span>

<h3>Description</h3>

<p>Monitors loss and stops training if loss is NaN. Can either fail with
exception or just stop training.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hook_nan_tensor(loss_tensor, fail_on_nan_loss = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="hook_nan_tensor_+3A_loss_tensor">loss_tensor</code></td>
<td>
<p>The loss tensor.</p>
</td></tr>
<tr><td><code id="hook_nan_tensor_+3A_fail_on_nan_loss">fail_on_nan_loss</code></td>
<td>
<p>A boolean indicating whether to raise exception when loss is NaN.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>Other session_run_hook wrappers: 
<code><a href="#topic+hook_checkpoint_saver">hook_checkpoint_saver</a>()</code>,
<code><a href="#topic+hook_global_step_waiter">hook_global_step_waiter</a>()</code>,
<code><a href="#topic+hook_history_saver">hook_history_saver</a>()</code>,
<code><a href="#topic+hook_logging_tensor">hook_logging_tensor</a>()</code>,
<code><a href="#topic+hook_progress_bar">hook_progress_bar</a>()</code>,
<code><a href="#topic+hook_step_counter">hook_step_counter</a>()</code>,
<code><a href="#topic+hook_stop_at_step">hook_stop_at_step</a>()</code>,
<code><a href="#topic+hook_summary_saver">hook_summary_saver</a>()</code>,
<code><a href="#topic+session_run_hook">session_run_hook</a>()</code>
</p>

<hr>
<h2 id='hook_progress_bar'>A Custom Run Hook to Create and Update Progress Bar During Training or Evaluation</h2><span id='topic+hook_progress_bar'></span>

<h3>Description</h3>

<p>This hook creates a progress bar that creates and updates the progress bar during training
or evaluation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hook_progress_bar()
</code></pre>


<h3>See Also</h3>

<p>Other session_run_hook wrappers: 
<code><a href="#topic+hook_checkpoint_saver">hook_checkpoint_saver</a>()</code>,
<code><a href="#topic+hook_global_step_waiter">hook_global_step_waiter</a>()</code>,
<code><a href="#topic+hook_history_saver">hook_history_saver</a>()</code>,
<code><a href="#topic+hook_logging_tensor">hook_logging_tensor</a>()</code>,
<code><a href="#topic+hook_nan_tensor">hook_nan_tensor</a>()</code>,
<code><a href="#topic+hook_step_counter">hook_step_counter</a>()</code>,
<code><a href="#topic+hook_stop_at_step">hook_stop_at_step</a>()</code>,
<code><a href="#topic+hook_summary_saver">hook_summary_saver</a>()</code>,
<code><a href="#topic+session_run_hook">session_run_hook</a>()</code>
</p>

<hr>
<h2 id='hook_step_counter'>Steps per Second Monitor</h2><span id='topic+hook_step_counter'></span>

<h3>Description</h3>

<p>Steps per Second Monitor
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hook_step_counter(
  every_n_steps = 100,
  every_n_secs = NULL,
  output_dir = NULL,
  summary_writer = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="hook_step_counter_+3A_every_n_steps">every_n_steps</code></td>
<td>
<p>Run this counter every N steps</p>
</td></tr>
<tr><td><code id="hook_step_counter_+3A_every_n_secs">every_n_secs</code></td>
<td>
<p>Run this counter every N seconds</p>
</td></tr>
<tr><td><code id="hook_step_counter_+3A_output_dir">output_dir</code></td>
<td>
<p>The output directory</p>
</td></tr>
<tr><td><code id="hook_step_counter_+3A_summary_writer">summary_writer</code></td>
<td>
<p>The summary writer</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>Other session_run_hook wrappers: 
<code><a href="#topic+hook_checkpoint_saver">hook_checkpoint_saver</a>()</code>,
<code><a href="#topic+hook_global_step_waiter">hook_global_step_waiter</a>()</code>,
<code><a href="#topic+hook_history_saver">hook_history_saver</a>()</code>,
<code><a href="#topic+hook_logging_tensor">hook_logging_tensor</a>()</code>,
<code><a href="#topic+hook_nan_tensor">hook_nan_tensor</a>()</code>,
<code><a href="#topic+hook_progress_bar">hook_progress_bar</a>()</code>,
<code><a href="#topic+hook_stop_at_step">hook_stop_at_step</a>()</code>,
<code><a href="#topic+hook_summary_saver">hook_summary_saver</a>()</code>,
<code><a href="#topic+session_run_hook">session_run_hook</a>()</code>
</p>

<hr>
<h2 id='hook_stop_at_step'>Monitor to Request Stop at a Specified Step</h2><span id='topic+hook_stop_at_step'></span>

<h3>Description</h3>

<p>Monitor to Request Stop at a Specified Step
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hook_stop_at_step(num_steps = NULL, last_step = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="hook_stop_at_step_+3A_num_steps">num_steps</code></td>
<td>
<p>Number of steps to execute.</p>
</td></tr>
<tr><td><code id="hook_stop_at_step_+3A_last_step">last_step</code></td>
<td>
<p>Step after which to stop.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>Other session_run_hook wrappers: 
<code><a href="#topic+hook_checkpoint_saver">hook_checkpoint_saver</a>()</code>,
<code><a href="#topic+hook_global_step_waiter">hook_global_step_waiter</a>()</code>,
<code><a href="#topic+hook_history_saver">hook_history_saver</a>()</code>,
<code><a href="#topic+hook_logging_tensor">hook_logging_tensor</a>()</code>,
<code><a href="#topic+hook_nan_tensor">hook_nan_tensor</a>()</code>,
<code><a href="#topic+hook_progress_bar">hook_progress_bar</a>()</code>,
<code><a href="#topic+hook_step_counter">hook_step_counter</a>()</code>,
<code><a href="#topic+hook_summary_saver">hook_summary_saver</a>()</code>,
<code><a href="#topic+session_run_hook">session_run_hook</a>()</code>
</p>

<hr>
<h2 id='hook_summary_saver'>Saves Summaries Every N Steps</h2><span id='topic+hook_summary_saver'></span>

<h3>Description</h3>

<p>Saves Summaries Every N Steps
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hook_summary_saver(
  save_steps = NULL,
  save_secs = NULL,
  output_dir = NULL,
  summary_writer = NULL,
  scaffold = NULL,
  summary_op = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="hook_summary_saver_+3A_save_steps">save_steps</code></td>
<td>
<p>An integer indicating saving summaries every N steps. Exactly one of
<code>save_secs</code> and <code>save_steps</code> should be set.</p>
</td></tr>
<tr><td><code id="hook_summary_saver_+3A_save_secs">save_secs</code></td>
<td>
<p>An integer indicating saving summaries every N seconds.</p>
</td></tr>
<tr><td><code id="hook_summary_saver_+3A_output_dir">output_dir</code></td>
<td>
<p>The directory to save the summaries to. Only used
if no <code>summary_writer</code> is supplied.</p>
</td></tr>
<tr><td><code id="hook_summary_saver_+3A_summary_writer">summary_writer</code></td>
<td>
<p>The summary writer. If <code>NULL</code> and an <code>output_dir</code> was
passed, one will be created accordingly.</p>
</td></tr>
<tr><td><code id="hook_summary_saver_+3A_scaffold">scaffold</code></td>
<td>
<p>A scaffold to get summary_op if it's not provided.</p>
</td></tr>
<tr><td><code id="hook_summary_saver_+3A_summary_op">summary_op</code></td>
<td>
<p>A tensor of type <code>tf$string</code> containing the serialized
summary protocol buffer or a list of tensors. They are most likely an
output by TensorFlow summary methods like <code>tf$summary$scalar</code> or
<code>tf$summary$merge_all</code>. It can be passed in as one tensor; if more than
one, they must be passed in as a list.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>Other session_run_hook wrappers: 
<code><a href="#topic+hook_checkpoint_saver">hook_checkpoint_saver</a>()</code>,
<code><a href="#topic+hook_global_step_waiter">hook_global_step_waiter</a>()</code>,
<code><a href="#topic+hook_history_saver">hook_history_saver</a>()</code>,
<code><a href="#topic+hook_logging_tensor">hook_logging_tensor</a>()</code>,
<code><a href="#topic+hook_nan_tensor">hook_nan_tensor</a>()</code>,
<code><a href="#topic+hook_progress_bar">hook_progress_bar</a>()</code>,
<code><a href="#topic+hook_step_counter">hook_step_counter</a>()</code>,
<code><a href="#topic+hook_stop_at_step">hook_stop_at_step</a>()</code>,
<code><a href="#topic+session_run_hook">session_run_hook</a>()</code>
</p>

<hr>
<h2 id='input_fn'>Construct an Input Function</h2><span id='topic+input_fn'></span><span id='topic+input_fn.default'></span><span id='topic+input_fn.formula'></span><span id='topic+input_fn.data.frame'></span><span id='topic+input_fn.list'></span><span id='topic+input_fn.matrix'></span>

<h3>Description</h3>

<p>This function constructs input function from various types of input used to
feed different TensorFlow estimators.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>input_fn(object, ...)

## Default S3 method:
input_fn(object, ...)

## S3 method for class 'formula'
input_fn(object, data, ...)

## S3 method for class 'data.frame'
input_fn(
  object,
  features,
  response = NULL,
  batch_size = 128,
  shuffle = "auto",
  num_epochs = 1,
  queue_capacity = 1000,
  num_threads = 1,
  ...
)

## S3 method for class 'list'
input_fn(
  object,
  features,
  response = NULL,
  batch_size = 128,
  shuffle = "auto",
  num_epochs = 1,
  queue_capacity = 1000,
  num_threads = 1,
  ...
)

## S3 method for class 'matrix'
input_fn(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="input_fn_+3A_object">object</code>, <code id="input_fn_+3A_data">data</code></td>
<td>
<p>An 'input source' &ndash; either a data set (e.g. an <span class="rlang"><b>R</b></span> <code>data.frame</code>),
or another kind of object that can provide the data required for training.</p>
</td></tr>
<tr><td><code id="input_fn_+3A_...">...</code></td>
<td>
<p>Optional arguments passed on to implementing submethods.</p>
</td></tr>
<tr><td><code id="input_fn_+3A_features">features</code></td>
<td>
<p>The names of feature variables to be used.</p>
</td></tr>
<tr><td><code id="input_fn_+3A_response">response</code></td>
<td>
<p>The name of the response variable.</p>
</td></tr>
<tr><td><code id="input_fn_+3A_batch_size">batch_size</code></td>
<td>
<p>The batch size.</p>
</td></tr>
<tr><td><code id="input_fn_+3A_shuffle">shuffle</code></td>
<td>
<p>Whether to shuffle the queue. When <code>"auto"</code> (the default),
shuffling will be performed except when this input function is called by
a <code>predict()</code> method.</p>
</td></tr>
<tr><td><code id="input_fn_+3A_num_epochs">num_epochs</code></td>
<td>
<p>The number of epochs to iterate over data.</p>
</td></tr>
<tr><td><code id="input_fn_+3A_queue_capacity">queue_capacity</code></td>
<td>
<p>The size of queue to accumulate.</p>
</td></tr>
<tr><td><code id="input_fn_+3A_num_threads">num_threads</code></td>
<td>
<p>The number of threads used for reading and enqueueing. In
order to have predictable and repeatable order of reading and enqueueing,
such as in prediction and evaluation mode, <code>num_threads</code> should be 1.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For list objects, this method is particularly useful when constructing
dynamic length of inputs for models like recurrent neural networks. Note that
some arguments are not available yet for input_fn applied to list objects.
See S3 method signatures below for more details.
</p>


<h3>See Also</h3>

<p>Other input functions: 
<code><a href="#topic+numpy_input_fn">numpy_input_fn</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Construct the input function through formula interface
input_fn1 &lt;- input_fn(mpg ~ drat + cyl, mtcars)

## End(Not run)

## Not run: 
# Construct the input function from a data.frame object
input_fn1 &lt;- input_fn(mtcars, response = mpg, features = c(drat, cyl))

## End(Not run)

## Not run: 
# Construct the input function from a list object
input_fn1 &lt;- input_fn(
   object = list(
     feature1 = list(
       list(list(1), list(2), list(3)),
       list(list(4), list(5), list(6))),
     feature2 = list(
       list(list(7), list(8), list(9)),
       list(list(10), list(11), list(12))),
     response = list(
       list(1, 2, 3), list(4, 5, 6))),
   features = c("feature1", "feature2"),
   response = "response",
   batch_size = 10L)

## End(Not run)

</code></pre>

<hr>
<h2 id='input_layer'>Construct an Input Layer</h2><span id='topic+input_layer'></span>

<h3>Description</h3>

<p>Returns a dense tensor as input layer based on given <code>feature_columns</code>.
At the first layer of the model, this column oriented data should be converted
to a single tensor.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>input_layer(
  features,
  feature_columns,
  weight_collections = NULL,
  trainable = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="input_layer_+3A_features">features</code></td>
<td>
<p>A mapping from key to tensors. Feature columns look up via
these keys. For example <code>column_numeric('price')</code> will look at 'price' key
in this dict. Values can be a sparse tensor or tensor depends on
corresponding feature column.</p>
</td></tr>
<tr><td><code id="input_layer_+3A_feature_columns">feature_columns</code></td>
<td>
<p>An iterable containing the FeatureColumns to use as
inputs to your model. All items should be instances of classes derived from
a dense column such as <code><a href="#topic+column_numeric">column_numeric()</a></code>, <code><a href="#topic+column_embedding">column_embedding()</a></code>,
<code><a href="#topic+column_bucketized">column_bucketized()</a></code>, <code><a href="#topic+column_indicator">column_indicator()</a></code>. If you have categorical features,
you can wrap them with an <code><a href="#topic+column_embedding">column_embedding()</a></code> or <code><a href="#topic+column_indicator">column_indicator()</a></code>.</p>
</td></tr>
<tr><td><code id="input_layer_+3A_weight_collections">weight_collections</code></td>
<td>
<p>A list of collection names to which the Variable
will be added. Note that, variables will also be added to collections
<code>graph_keys()$GLOBAL_VARIABLES</code> and <code>graph_keys()$MODEL_VARIABLES</code>.</p>
</td></tr>
<tr><td><code id="input_layer_+3A_trainable">trainable</code></td>
<td>
<p>If <code>TRUE</code> also add the variable to the graph collection
<code>graph_keys()$TRAINABLE_VARIABLES</code> (see <code>tf$Variable</code>).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tensor which represents input layer of a model. Its shape is
(batch_size, first_layer_dimension) and its dtype is <code>float32</code>.
first_layer_dimension is determined based on given <code>feature_columns</code>.
</p>


<h3>Raises</h3>


<ul>
<li><p> ValueError: if an item in <code>feature_columns</code> is not a dense column.
</p>
</li></ul>



<h3>See Also</h3>

<p>Other feature column constructors: 
<code><a href="#topic+column_bucketized">column_bucketized</a>()</code>,
<code><a href="#topic+column_categorical_weighted">column_categorical_weighted</a>()</code>,
<code><a href="#topic+column_categorical_with_hash_bucket">column_categorical_with_hash_bucket</a>()</code>,
<code><a href="#topic+column_categorical_with_identity">column_categorical_with_identity</a>()</code>,
<code><a href="#topic+column_categorical_with_vocabulary_file">column_categorical_with_vocabulary_file</a>()</code>,
<code><a href="#topic+column_categorical_with_vocabulary_list">column_categorical_with_vocabulary_list</a>()</code>,
<code><a href="#topic+column_crossed">column_crossed</a>()</code>,
<code><a href="#topic+column_embedding">column_embedding</a>()</code>,
<code><a href="#topic+column_numeric">column_numeric</a>()</code>
</p>

<hr>
<h2 id='keras_model_to_estimator'>Keras Estimators</h2><span id='topic+keras_model_to_estimator'></span>

<h3>Description</h3>

<p>Create an Estimator from a compiled Keras model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>keras_model_to_estimator(
  keras_model = NULL,
  keras_model_path = NULL,
  custom_objects = NULL,
  model_dir = NULL,
  config = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="keras_model_to_estimator_+3A_keras_model">keras_model</code></td>
<td>
<p>A keras model.</p>
</td></tr>
<tr><td><code id="keras_model_to_estimator_+3A_keras_model_path">keras_model_path</code></td>
<td>
<p>Directory to a keras model on disk.</p>
</td></tr>
<tr><td><code id="keras_model_to_estimator_+3A_custom_objects">custom_objects</code></td>
<td>
<p>Dictionary for custom objects.</p>
</td></tr>
<tr><td><code id="keras_model_to_estimator_+3A_model_dir">model_dir</code></td>
<td>
<p>Directory to save Estimator model parameters, graph and etc.</p>
</td></tr>
<tr><td><code id="keras_model_to_estimator_+3A_config">config</code></td>
<td>
<p>Configuration object.</p>
</td></tr>
</table>

<hr>
<h2 id='latest_checkpoint'>Get the Latest Checkpoint in a Checkpoint Directory</h2><span id='topic+latest_checkpoint'></span>

<h3>Description</h3>

<p>Get the Latest Checkpoint in a Checkpoint Directory
</p>


<h3>Usage</h3>

<pre><code class='language-R'>latest_checkpoint(checkpoint_dir, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="latest_checkpoint_+3A_checkpoint_dir">checkpoint_dir</code></td>
<td>
<p>The path to the checkpoint directory.</p>
</td></tr>
<tr><td><code id="latest_checkpoint_+3A_...">...</code></td>
<td>
<p>Optional arguments passed on to <code>latest_checkpoint()</code>.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>Other utility functions: 
<code><a href="#topic+graph_keys">graph_keys</a>()</code>
</p>

<hr>
<h2 id='linear_estimators'>Construct a Linear Estimator</h2><span id='topic+linear_estimators'></span><span id='topic+linear_regressor'></span><span id='topic+linear_classifier'></span>

<h3>Description</h3>

<p>Construct a linear model, which can be used to predict a continuous outcome
(in the case of <code>linear_regressor()</code>) or a categorical outcome (in the case
of <code>linear_classifier()</code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>linear_regressor(
  feature_columns,
  model_dir = NULL,
  label_dimension = 1L,
  weight_column = NULL,
  optimizer = "Ftrl",
  config = NULL,
  partitioner = NULL
)

linear_classifier(
  feature_columns,
  model_dir = NULL,
  n_classes = 2L,
  weight_column = NULL,
  label_vocabulary = NULL,
  optimizer = "Ftrl",
  config = NULL,
  partitioner = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="linear_estimators_+3A_feature_columns">feature_columns</code></td>
<td>
<p>An <span class="rlang"><b>R</b></span> list containing all of the feature columns used
by the model (typically, generated by <code><a href="#topic+feature_columns">feature_columns()</a></code>).</p>
</td></tr>
<tr><td><code id="linear_estimators_+3A_model_dir">model_dir</code></td>
<td>
<p>Directory to save the model parameters, graph, and so on.
This can also be used to load checkpoints from the directory into a
estimator to continue training a previously saved model.</p>
</td></tr>
<tr><td><code id="linear_estimators_+3A_label_dimension">label_dimension</code></td>
<td>
<p>Number of regression targets per example. This is the
size of the last dimension of the labels and logits <code>Tensor</code> objects
(typically, these have shape <code style="white-space: pre;">&#8288;[batch_size, label_dimension]&#8288;</code>).</p>
</td></tr>
<tr><td><code id="linear_estimators_+3A_weight_column">weight_column</code></td>
<td>
<p>A string, or a numeric column created by
<code><a href="#topic+column_numeric">column_numeric()</a></code> defining feature column representing weights. It is used
to down weight or boost examples during training. It will be multiplied by
the loss of the example. If it is a string, it is used as a key to fetch
weight tensor from the <code>features</code> argument. If it is a numeric column,
then the raw tensor is fetched by key <code>weight_column$key</code>, then
<code>weight_column$normalizer_fn</code> is applied on it to get weight tensor.</p>
</td></tr>
<tr><td><code id="linear_estimators_+3A_optimizer">optimizer</code></td>
<td>
<p>Either the name of the optimizer to be used when training
the model, or a TensorFlow optimizer instance. Defaults to the FTRL
optimizer.</p>
</td></tr>
<tr><td><code id="linear_estimators_+3A_config">config</code></td>
<td>
<p>A run configuration created by <code><a href="#topic+run_config">run_config()</a></code>, used to configure the runtime
settings.</p>
</td></tr>
<tr><td><code id="linear_estimators_+3A_partitioner">partitioner</code></td>
<td>
<p>An optional partitioner for the input layer.</p>
</td></tr>
<tr><td><code id="linear_estimators_+3A_n_classes">n_classes</code></td>
<td>
<p>The number of label classes.</p>
</td></tr>
<tr><td><code id="linear_estimators_+3A_label_vocabulary">label_vocabulary</code></td>
<td>
<p>A list of strings represents possible label values.
If given, labels must be string type and have any value in
<code>label_vocabulary</code>. If it is not given, that means labels are already
encoded as integer or float within <code style="white-space: pre;">&#8288;[0, 1]&#8288;</code> for <code>n_classes == 2</code> and
encoded as integer values in <code style="white-space: pre;">&#8288;{0, 1,..., n_classes  -1}&#8288;</code> for <code>n_classes &gt; 2</code>. Also there will be errors if vocabulary is not provided and labels are
string.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>Other canned estimators: 
<code><a href="#topic+boosted_trees_estimators">boosted_trees_estimators</a></code>,
<code><a href="#topic+dnn_estimators">dnn_estimators</a></code>,
<code><a href="#topic+dnn_linear_combined_estimators">dnn_linear_combined_estimators</a></code>
</p>

<hr>
<h2 id='metric_keys'>Canonical Metric Keys</h2><span id='topic+metric_keys'></span>

<h3>Description</h3>

<p>The canonical set of keys that can be used to access metrics from canned
estimators.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>metric_keys()
</code></pre>


<h3>See Also</h3>

<p>Other estimator keys: 
<code><a href="#topic+mode_keys">mode_keys</a>()</code>,
<code><a href="#topic+prediction_keys">prediction_keys</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
metrics &lt;- metric_keys()

# Get the available keys
metrics

metrics$ACCURACY

## End(Not run)

</code></pre>

<hr>
<h2 id='mode_keys'>Canonical Mode Keys</h2><span id='topic+mode_keys'></span>

<h3>Description</h3>

<p>The names for different possible modes for an estimator. The following
standard keys are defined:
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mode_keys()
</code></pre>


<h3>Details</h3>


<table>
<tr>
 <td style="text-align: left;">
<code>TRAIN</code>   </td><td style="text-align: left;"> Training mode.               </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>EVAL</code>    </td><td style="text-align: left;"> Evaluation mode.             </td>
</tr>
<tr>
 <td style="text-align: left;">
<code>PREDICT</code> </td><td style="text-align: left;"> Prediction / inference mode. </td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>



<h3>See Also</h3>

<p>Other estimator keys: 
<code><a href="#topic+metric_keys">metric_keys</a>()</code>,
<code><a href="#topic+prediction_keys">prediction_keys</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
modes &lt;- mode_keys()
modes$TRAIN

## End(Not run)

</code></pre>

<hr>
<h2 id='model_dir'>Model directory</h2><span id='topic+model_dir'></span>

<h3>Description</h3>

<p>Get the directory where a model's artifacts are stored.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>model_dir(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="model_dir_+3A_object">object</code></td>
<td>
<p>Model object</p>
</td></tr>
<tr><td><code id="model_dir_+3A_...">...</code></td>
<td>
<p>Unused</p>
</td></tr>
</table>

<hr>
<h2 id='numpy_input_fn'>Construct Input Function Containing Python Dictionaries of Numpy Arrays</h2><span id='topic+numpy_input_fn'></span>

<h3>Description</h3>

<p>This returns a function outputting <code>features</code> and <code>target</code> based on the dict
of numpy arrays. The dict <code>features</code> has the same keys as the <code>x</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>numpy_input_fn(
  x,
  y = NULL,
  batch_size = 128,
  num_epochs = 1,
  shuffle = NULL,
  queue_capacity = 1000,
  num_threads = 1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="numpy_input_fn_+3A_x">x</code></td>
<td>
<p>dict of numpy array object.</p>
</td></tr>
<tr><td><code id="numpy_input_fn_+3A_y">y</code></td>
<td>
<p>numpy array object. <code>NULL</code> if absent.</p>
</td></tr>
<tr><td><code id="numpy_input_fn_+3A_batch_size">batch_size</code></td>
<td>
<p>Integer, size of batches to return.</p>
</td></tr>
<tr><td><code id="numpy_input_fn_+3A_num_epochs">num_epochs</code></td>
<td>
<p>Integer, number of epochs to iterate over data. If <code>NULL</code>
will run forever.</p>
</td></tr>
<tr><td><code id="numpy_input_fn_+3A_shuffle">shuffle</code></td>
<td>
<p>Boolean, if <code>TRUE</code> shuffles the queue. Avoid shuffle at
prediction time.</p>
</td></tr>
<tr><td><code id="numpy_input_fn_+3A_queue_capacity">queue_capacity</code></td>
<td>
<p>Integer, size of queue to accumulate.</p>
</td></tr>
<tr><td><code id="numpy_input_fn_+3A_num_threads">num_threads</code></td>
<td>
<p>Integer, number of threads used for reading and
enqueueing. In order to have predicted and repeatable order of reading and
enqueueing, such as in prediction and evaluation mode, <code>num_threads</code> should
be 1. #'</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Note that this function is still experimental and should only be used if
necessary, e.g. feed in data that's dictionary of numpy arrays.
</p>


<h3>Raises</h3>

<p>ValueError: if the shape of <code>y</code> mismatches the shape of
values in <code>x</code> (i.e., values in <code>x</code> have same shape). TypeError: <code>x</code> is not
a dict or <code>shuffle</code> is not bool.
</p>


<h3>See Also</h3>

<p>Other input functions: 
<code><a href="#topic+input_fn">input_fn</a>()</code>
</p>

<hr>
<h2 id='plot.tf_estimator_history'>Plot training history</h2><span id='topic+plot.tf_estimator_history'></span>

<h3>Description</h3>

<p>Plots metrics recorded during training.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'tf_estimator_history'
plot(
  x,
  y,
  metrics = NULL,
  method = c("auto", "ggplot2", "base"),
  smooth = getOption("tf.estimator.plot.history.smooth", TRUE),
  theme_bw = getOption("tf.estimator.plot.history.theme_bw", FALSE),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.tf_estimator_history_+3A_x">x</code></td>
<td>
<p>Training history object returned from <code>train()</code>.</p>
</td></tr>
<tr><td><code id="plot.tf_estimator_history_+3A_y">y</code></td>
<td>
<p>Unused.</p>
</td></tr>
<tr><td><code id="plot.tf_estimator_history_+3A_metrics">metrics</code></td>
<td>
<p>One or more metrics to plot (e.g. <code>c('total_losses', 'mean_losses')</code>).
Defaults to plotting all captured metrics.</p>
</td></tr>
<tr><td><code id="plot.tf_estimator_history_+3A_method">method</code></td>
<td>
<p>Method to use for plotting. The default &quot;auto&quot; will use
<span class="pkg">ggplot2</span> if available, and otherwise will use base graphics.</p>
</td></tr>
<tr><td><code id="plot.tf_estimator_history_+3A_smooth">smooth</code></td>
<td>
<p>Whether a loess smooth should be added to the plot, only
available for the <code>ggplot2</code> method. If the number of data points is smaller
than ten, it is forced to false.</p>
</td></tr>
<tr><td><code id="plot.tf_estimator_history_+3A_theme_bw">theme_bw</code></td>
<td>
<p>Use <code>ggplot2::theme_bw()</code> to plot the history in
black and white.</p>
</td></tr>
<tr><td><code id="plot.tf_estimator_history_+3A_...">...</code></td>
<td>
<p>Additional parameters to pass to the <code><a href="graphics.html#topic+plot">plot()</a></code> method.</p>
</td></tr>
</table>

<hr>
<h2 id='predict.tf_estimator'>Generate Predictions with an Estimator</h2><span id='topic+predict.tf_estimator'></span>

<h3>Description</h3>

<p>Generate predicted labels / values for input data provided by <code>input_fn()</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'tf_estimator'
predict(
  object,
  input_fn,
  checkpoint_path = NULL,
  predict_keys = c("predictions", "classes", "class_ids", "logistic", "logits",
    "probabilities"),
  hooks = NULL,
  as_iterable = FALSE,
  simplify = TRUE,
  yield_single_examples = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.tf_estimator_+3A_object">object</code></td>
<td>
<p>A TensorFlow estimator.</p>
</td></tr>
<tr><td><code id="predict.tf_estimator_+3A_input_fn">input_fn</code></td>
<td>
<p>An input function, typically generated by the <code><a href="#topic+input_fn">input_fn()</a></code>
helper function.</p>
</td></tr>
<tr><td><code id="predict.tf_estimator_+3A_checkpoint_path">checkpoint_path</code></td>
<td>
<p>The path to a specific model checkpoint to be used for
prediction. If <code>NULL</code> (the default), the latest checkpoint in <code>model_dir</code>
is used.</p>
</td></tr>
<tr><td><code id="predict.tf_estimator_+3A_predict_keys">predict_keys</code></td>
<td>
<p>The types of predictions that should be produced, as an
<span class="rlang"><b>R</b></span> list. When this argument is not specified (the default), all possible
predicted values will be returned.</p>
</td></tr>
<tr><td><code id="predict.tf_estimator_+3A_hooks">hooks</code></td>
<td>
<p>A list of <span class="rlang"><b>R</b></span> functions, to be used as callbacks inside the
training loop. By default, <code>hook_history_saver(every_n_step = 10)</code> and
<code>hook_progress_bar()</code> will be attached if not provided to save the metrics
history and create the progress bar.</p>
</td></tr>
<tr><td><code id="predict.tf_estimator_+3A_as_iterable">as_iterable</code></td>
<td>
<p>Boolean; should a raw Python generator be returned? When
<code>FALSE</code> (the default), the predicted values will be consumed from the
generator and returned as an <span class="rlang"><b>R</b></span> object.</p>
</td></tr>
<tr><td><code id="predict.tf_estimator_+3A_simplify">simplify</code></td>
<td>
<p>Whether to simplify prediction results into a <code>tibble</code>,
as opposed to a list. Defaults to <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="predict.tf_estimator_+3A_yield_single_examples">yield_single_examples</code></td>
<td>
<p>(Available since TensorFlow v1.7) If <code>FALSE</code>,
yields the whole batch as returned by the <code>model_fn</code> instead of decomposing
the batch into individual elements. This is useful if <code>model_fn</code> returns some
tensors with first dimension not equal to the batch size.</p>
</td></tr>
<tr><td><code id="predict.tf_estimator_+3A_...">...</code></td>
<td>
<p>Optional arguments passed on to the estimator's <code>predict()</code>
method.</p>
</td></tr>
</table>


<h3>Yields</h3>

<p>Evaluated values of <code>predictions</code> tensors.
</p>


<h3>Raises</h3>

<p>ValueError: Could not find a trained model in model_dir.
ValueError: if batch length of predictions are not same. ValueError: If
there is a conflict between <code>predict_keys</code> and <code>predictions</code>. For example
if <code>predict_keys</code> is not <code>NULL</code> but <code>EstimatorSpec.predictions</code> is not a
<code>dict</code>.
</p>


<h3>See Also</h3>

<p>Other custom estimator methods: 
<code><a href="#topic+estimator_spec">estimator_spec</a>()</code>,
<code><a href="#topic+estimator">estimator</a>()</code>,
<code><a href="#topic+evaluate.tf_estimator">evaluate.tf_estimator</a>()</code>,
<code><a href="#topic+export_savedmodel.tf_estimator">export_savedmodel.tf_estimator</a>()</code>,
<code><a href="#topic+train.tf_estimator">train.tf_estimator</a>()</code>
</p>

<hr>
<h2 id='prediction_keys'>Canonical Model Prediction Keys</h2><span id='topic+prediction_keys'></span>

<h3>Description</h3>

<p>The canonical set of keys used for models and estimators that provide
different types of predicted values through their <code>predict()</code> method.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>prediction_keys()
</code></pre>


<h3>See Also</h3>

<p>Other estimator keys: 
<code><a href="#topic+metric_keys">metric_keys</a>()</code>,
<code><a href="#topic+mode_keys">mode_keys</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'> ## Not run: 
keys &lt;- prediction_keys()

# Get the available keys
keys

# Key for retrieving probabilities from prediction values
keys$PROBABILITIES

## End(Not run)

</code></pre>

<hr>
<h2 id='reexports'>Objects exported from other packages</h2><span id='topic+reexports'></span><span id='topic+contains'></span><span id='topic+select_helpers'></span><span id='topic+ends_with'></span><span id='topic+everything'></span><span id='topic+matches'></span><span id='topic+num_range'></span><span id='topic+one_of'></span><span id='topic+starts_with'></span><span id='topic+last_col'></span><span id='topic++25+3E+25'></span><span id='topic+use_python'></span><span id='topic+use_virtualenv'></span><span id='topic+use_condaenv'></span><span id='topic+array_reshape'></span><span id='topic+tf'></span><span id='topic+shape'></span><span id='topic+install_tensorflow'></span><span id='topic+tf_config'></span><span id='topic+tensorboard'></span><span id='topic+evaluate'></span><span id='topic+train'></span><span id='topic+train_and_evaluate'></span><span id='topic+export_savedmodel'></span><span id='topic+flags'></span><span id='topic+flag_numeric'></span><span id='topic+flag_integer'></span><span id='topic+flag_string'></span><span id='topic+flag_boolean'></span><span id='topic+run_dir'></span><span id='topic+glimpse'></span>

<h3>Description</h3>

<p>These objects are imported from other packages. Follow the links
below to see their documentation.
</p>

<dl>
<dt>magrittr</dt><dd><p><code><a href="magrittr.html#topic+pipe">%&gt;%</a></code></p>
</dd>
<dt>reticulate</dt><dd><p><code><a href="reticulate.html#topic+array_reshape">array_reshape</a></code>, <code><a href="reticulate.html#topic+use_python">use_condaenv</a></code>, <code><a href="reticulate.html#topic+use_python">use_python</a></code>, <code><a href="reticulate.html#topic+use_python">use_virtualenv</a></code></p>
</dd>
<dt>tensorflow</dt><dd><p><code><a href="tensorflow.html#topic+evaluate">evaluate</a></code>, <code><a href="tensorflow.html#topic+export_savedmodel">export_savedmodel</a></code>, <code><a href="tensorflow.html#topic+install_tensorflow">install_tensorflow</a></code>, <code><a href="tensorflow.html#topic+shape">shape</a></code>, <code><a href="tensorflow.html#topic+tensorboard">tensorboard</a></code>, <code><a href="tensorflow.html#topic+tf">tf</a></code>, <code><a href="tensorflow.html#topic+tf_config">tf_config</a></code>, <code><a href="tensorflow.html#topic+train">train</a></code>, <code><a href="tensorflow.html#topic+train_and_evaluate">train_and_evaluate</a></code></p>
</dd>
<dt>tfruns</dt><dd><p><code><a href="tfruns.html#topic+flags">flag_boolean</a></code>, <code><a href="tfruns.html#topic+flags">flag_integer</a></code>, <code><a href="tfruns.html#topic+flags">flag_numeric</a></code>, <code><a href="tfruns.html#topic+flags">flag_string</a></code>, <code><a href="tfruns.html#topic+flags">flags</a></code>, <code><a href="tfruns.html#topic+run_dir">run_dir</a></code></p>
</dd>
<dt>tibble</dt><dd><p><code><a href="tibble.html#topic+reexports">glimpse</a></code></p>
</dd>
<dt>tidyselect</dt><dd><p><code><a href="tidyselect.html#topic+starts_with">contains</a></code>, <code><a href="tidyselect.html#topic+starts_with">ends_with</a></code>, <code><a href="tidyselect.html#topic+everything">everything</a></code>, <code><a href="tidyselect.html#topic+everything">last_col</a></code>, <code><a href="tidyselect.html#topic+starts_with">matches</a></code>, <code><a href="tidyselect.html#topic+starts_with">num_range</a></code>, <code><a href="tidyselect.html#topic+one_of">one_of</a></code>, <code><a href="tidyselect.html#topic+starts_with">starts_with</a></code></p>
</dd>
</dl>

<hr>
<h2 id='regressor_parse_example_spec'>Generates Parsing Spec for TensorFlow Example to be Used with Regressors</h2><span id='topic+regressor_parse_example_spec'></span>

<h3>Description</h3>

<p>If users keep data in <code>tf$Example</code> format, they need to call <code>tf$parse_example</code>
with a proper feature spec. There are two main things that this utility
helps:
</p>

<ul>
<li><p> Users need to combine parsing spec of features with labels and weights (if
any) since they are all parsed from same <code>tf$Example</code> instance. This utility
combines these specs.
</p>
</li>
<li><p> It is difficult to map expected label by a regressor such as <code>dnn_regressor</code>
to corresponding <code>tf$parse_example</code> spec. This utility encodes it by getting
related information from users (key, dtype).
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>regressor_parse_example_spec(
  feature_columns,
  label_key,
  label_dtype = tf$float32,
  label_default = NULL,
  label_dimension = 1L,
  weight_column = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="regressor_parse_example_spec_+3A_feature_columns">feature_columns</code></td>
<td>
<p>An iterable containing all feature columns. All items
should be instances of classes derived from <code style="white-space: pre;">&#8288;_FeatureColumn&#8288;</code>.</p>
</td></tr>
<tr><td><code id="regressor_parse_example_spec_+3A_label_key">label_key</code></td>
<td>
<p>A string identifying the label. It means <code>tf$Example</code> stores
labels with this key.</p>
</td></tr>
<tr><td><code id="regressor_parse_example_spec_+3A_label_dtype">label_dtype</code></td>
<td>
<p>A <code>tf$dtype</code> identifies the type of labels. By default it
is <code>tf$float32</code>.</p>
</td></tr>
<tr><td><code id="regressor_parse_example_spec_+3A_label_default">label_default</code></td>
<td>
<p>used as label if label_key does not exist in given
<code>tf$Example</code>. By default default_value is none, which means
<code>tf$parse_example</code> will error out if there is any missing label.</p>
</td></tr>
<tr><td><code id="regressor_parse_example_spec_+3A_label_dimension">label_dimension</code></td>
<td>
<p>Number of regression targets per example. This is the
size of the last dimension of the labels and logits <code>Tensor</code> objects
(typically, these have shape <code style="white-space: pre;">&#8288;[batch_size, label_dimension]&#8288;</code>).</p>
</td></tr>
<tr><td><code id="regressor_parse_example_spec_+3A_weight_column">weight_column</code></td>
<td>
<p>A string or a <code style="white-space: pre;">&#8288;_NumericColumn&#8288;</code> created by
<code>column_numeric</code> defining feature column representing
weights. It is used to down weight or boost examples during training. It
will be multiplied by the loss of the example. If it is a string, it is
used as a key to fetch weight tensor from the <code>features</code>. If it is a
<code style="white-space: pre;">&#8288;_NumericColumn&#8288;</code>, raw tensor is fetched by key <code>weight_column$key</code>, then
<code>weight_column$normalizer_fn</code> is applied on it to get weight tensor.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A dict mapping each feature key to a <code>FixedLenFeature</code> or
<code>VarLenFeature</code> value.
</p>


<h3>Raises</h3>


<ul>
<li><p> ValueError: If label is used in <code>feature_columns</code>.
</p>
</li>
<li><p> ValueError: If weight_column is used in <code>feature_columns</code>.
</p>
</li>
<li><p> ValueError: If any of the given <code>feature_columns</code> is not a <code style="white-space: pre;">&#8288;_FeatureColumn&#8288;</code> instance.
</p>
</li>
<li><p> ValueError: If <code>weight_column</code> is not a <code style="white-space: pre;">&#8288;_NumericColumn&#8288;</code> instance.
</p>
</li>
<li><p> ValueError: if label_key is <code>NULL</code>.
</p>
</li></ul>



<h3>See Also</h3>

<p>Other parsing utilities: 
<code><a href="#topic+classifier_parse_example_spec">classifier_parse_example_spec</a>()</code>
</p>

<hr>
<h2 id='run_config'>Run Configuration</h2><span id='topic+run_config'></span>

<h3>Description</h3>

<p>This class specifies the configurations for an <code>Estimator</code> run.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>run_config()
</code></pre>


<h3>See Also</h3>

<p>Other run_config methods: 
<code><a href="#topic+task_type">task_type</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
config &lt;- run_config()

# Get the properties of the config
names(config)

# Change the mutable properties of the config
config &lt;- config$replace(tf_random_seed = 11L, save_summary_steps = 12L)

# Print config as key value pairs
print(config)

## End(Not run)

</code></pre>

<hr>
<h2 id='session_run_args'>Create Session Run Arguments</h2><span id='topic+session_run_args'></span>

<h3>Description</h3>

<p>Create a set of session run arguments. These are used as the return values in
the <code>before_run(context)</code> callback of a <code><a href="#topic+session_run_hook">session_run_hook()</a></code>, for requesting
the values of specific tensor in the <code>after_run(context, values)</code> callback.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>session_run_args(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="session_run_args_+3A_...">...</code></td>
<td>
<p>A set of tensors or operations.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+session_run_hook">session_run_hook()</a></code>
</p>

<hr>
<h2 id='session_run_hook'>Create Custom Session Run Hooks</h2><span id='topic+session_run_hook'></span>

<h3>Description</h3>

<p>Create a set of session run hooks, used to record information during
training of an estimator. See <strong>Details</strong> for more information on the
various hooks that can be defined.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>session_run_hook(
  begin = function() { },
  after_create_session = function(session, coord) { },
  before_run = function(context) { },
  after_run = function(context, values) { },
  end = function(session) { }
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="session_run_hook_+3A_begin">begin</code></td>
<td>
<p><code style="white-space: pre;">&#8288;function()&#8288;</code>: An <span class="rlang"><b>R</b></span> function, to be called once before using the session.</p>
</td></tr>
<tr><td><code id="session_run_hook_+3A_after_create_session">after_create_session</code></td>
<td>
<p><code style="white-space: pre;">&#8288;function(session, coord)&#8288;</code>: An <span class="rlang"><b>R</b></span> function, to be called
once the new TensorFlow session has been created.</p>
</td></tr>
<tr><td><code id="session_run_hook_+3A_before_run">before_run</code></td>
<td>
<p><code style="white-space: pre;">&#8288;function(run_context)&#8288;</code>: An <span class="rlang"><b>R</b></span> function to be called before a run.</p>
</td></tr>
<tr><td><code id="session_run_hook_+3A_after_run">after_run</code></td>
<td>
<p><code style="white-space: pre;">&#8288;function(run_context, run_values)&#8288;</code>: An <span class="rlang"><b>R</b></span> function to be called
after a run.</p>
</td></tr>
<tr><td><code id="session_run_hook_+3A_end">end</code></td>
<td>
<p><code style="white-space: pre;">&#8288;function(session)&#8288;</code>: An <span class="rlang"><b>R</b></span> function to be called at the end of the session.
</p>
<p>Typically, you'll want to define a <code>before_run()</code> hook that defines the set
of tensors you're interested in for a particular run, and then you'll use the
resulting values of those tensors in your <code>after_run()</code> hook. The tensors
requested in your <code>before_run()</code> hook will be made available as part of the
second argument in the <code>after_run()</code> hook (the <code>values</code> argument).</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+session_run_args">session_run_args()</a></code>
</p>
<p>Other session_run_hook wrappers: 
<code><a href="#topic+hook_checkpoint_saver">hook_checkpoint_saver</a>()</code>,
<code><a href="#topic+hook_global_step_waiter">hook_global_step_waiter</a>()</code>,
<code><a href="#topic+hook_history_saver">hook_history_saver</a>()</code>,
<code><a href="#topic+hook_logging_tensor">hook_logging_tensor</a>()</code>,
<code><a href="#topic+hook_nan_tensor">hook_nan_tensor</a>()</code>,
<code><a href="#topic+hook_progress_bar">hook_progress_bar</a>()</code>,
<code><a href="#topic+hook_step_counter">hook_step_counter</a>()</code>,
<code><a href="#topic+hook_stop_at_step">hook_stop_at_step</a>()</code>,
<code><a href="#topic+hook_summary_saver">hook_summary_saver</a>()</code>
</p>

<hr>
<h2 id='task_type'>Task Types</h2><span id='topic+task_type'></span>

<h3>Description</h3>

<p>This constant class gives the constant strings for available task types
used in <code>run_config</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>task_type()
</code></pre>


<h3>See Also</h3>

<p>Other run_config methods: 
<code><a href="#topic+run_config">run_config</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
task_type()$MASTER

## End(Not run)

</code></pre>

<hr>
<h2 id='tfestimators'>High-level Estimator API in TensorFlow for R</h2><span id='topic+tfestimators'></span>

<h3>Description</h3>

<p>This library provides an R interface to the
<a href="https://github.com/tensorflow/tensorflow/tree/master/tensorflow/python/estimator">Estimator</a>
API inside TensorFlow that's designed to streamline the process of creating,
evaluating, and deploying general machine learning and deep learning models.
</p>


<h3>Details</h3>

<p><a href="https://www.tensorflow.org">TensorFlow</a> is an open source software library
for numerical computation using data flow graphs. Nodes in the graph
represent mathematical operations, while the graph edges represent the
multidimensional data arrays (tensors) communicated between them. The
flexible architecture allows you to deploy computation to one or more CPUs or
GPUs in a desktop, server, or mobile device with a single API.
</p>
<p>The <a href="https://www.tensorflow.org/versions/r1.15/api_docs/python/tf/all_symbols">TensorFlow
API</a> is composed of a set of Python modules that enable constructing and
executing TensorFlow graphs. The tensorflow package provides access to the
complete TensorFlow API from within R.
</p>
<p>For additional documentation on the tensorflow package see
<a href="https://tensorflow.rstudio.com">https://tensorflow.rstudio.com</a>
</p>

<hr>
<h2 id='train_and_evaluate.tf_estimator'>Train and evaluate the estimator.</h2><span id='topic+train_and_evaluate.tf_estimator'></span>

<h3>Description</h3>

<p>(Available since TensorFlow v1.4)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'tf_estimator'
train_and_evaluate(object, train_spec, eval_spec, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="train_and_evaluate.tf_estimator_+3A_object">object</code></td>
<td>
<p>An estimator object to train and evaluate.</p>
</td></tr>
<tr><td><code id="train_and_evaluate.tf_estimator_+3A_train_spec">train_spec</code></td>
<td>
<p>A <code>TrainSpec</code> instance to specify the training specification.</p>
</td></tr>
<tr><td><code id="train_and_evaluate.tf_estimator_+3A_eval_spec">eval_spec</code></td>
<td>
<p>A <code>EvalSpec</code> instance to specify the evaluation and export specification.</p>
</td></tr>
<tr><td><code id="train_and_evaluate.tf_estimator_+3A_...">...</code></td>
<td>
<p>Not used.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This utility function trains, evaluates, and (optionally) exports the model by
using the given <code>estimator</code>. All training related specification is held in
<code>train_spec</code>, including training <code>input_fn</code> and training max steps, etc. All
evaluation and export related specification is held in <code>eval_spec</code>, including
evaluation <code>input_fn</code>, steps, etc.
</p>
<p>This utility function provides consistent behavior for both local
(non-distributed) and distributed configurations. Currently, the only
supported distributed training configuration is between-graph replication.
</p>
<p>Overfitting: In order to avoid overfitting, it is recommended to set up the
training <code>input_fn</code> to shuffle the training data properly. It is also
recommended to train the model a little longer, say multiple epochs, before
performing evaluation, as the input pipeline starts from scratch for each
training. It is particularly important for local training and evaluation.
</p>
<p>Stop condition: In order to support both distributed and non-distributed
configuration reliably, the only supported stop condition for model
training is <code>train_spec.max_steps</code>. If <code>train_spec.max_steps</code> is <code>NULL</code>, the
model is trained forever. <em>Use with care</em> if model stop condition is
different. For example, assume that the model is expected to be trained with
one epoch of training data, and the training <code>input_fn</code> is configured to throw
<code>OutOfRangeError</code> after going through one epoch, which stops the
<code>Estimator.train</code>. For a three-training-worker distributed configuration, each
training worker is likely to go through the whole epoch independently. So, the
model will be trained with three epochs of training data instead of one epoch.
</p>


<h3>Raises</h3>


<ul>
<li><p> ValueError: if environment variable <code>TF_CONFIG</code> is incorrectly set.
</p>
</li></ul>



<h3>See Also</h3>

<p>Other training methods: 
<code><a href="#topic+eval_spec">eval_spec</a>()</code>,
<code><a href="#topic+train_spec">train_spec</a>()</code>
</p>

<hr>
<h2 id='train_spec'>Configuration for the train component of <code>train_and_evaluate</code></h2><span id='topic+train_spec'></span>

<h3>Description</h3>

<p><code>TrainSpec</code> determines the input data for the training, as well as the
duration. Optional hooks run at various stages of training.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>train_spec(input_fn, max_steps = NULL, hooks = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="train_spec_+3A_input_fn">input_fn</code></td>
<td>
<p>Training input function returning a tuple of:
</p>

<ul>
<li><p> features - <code>Tensor</code> or dictionary of string feature name to <code>Tensor</code>.
</p>
</li>
<li><p> labels - <code>Tensor</code> or dictionary of <code>Tensor</code> with labels.
</p>
</li></ul>
</td></tr>
<tr><td><code id="train_spec_+3A_max_steps">max_steps</code></td>
<td>
<p>Positive number of total steps for which to train model.
If <code>NULL</code>, train forever. The training <code>input_fn</code> is not expected to
generate <code>OutOfRangeError</code> or <code>StopIteration</code> exceptions.</p>
</td></tr>
<tr><td><code id="train_spec_+3A_hooks">hooks</code></td>
<td>
<p>List of session run hooks to run on all workers
(including chief) during training.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>Other training methods: 
<code><a href="#topic+eval_spec">eval_spec</a>()</code>,
<code><a href="#topic+train_and_evaluate.tf_estimator">train_and_evaluate.tf_estimator</a>()</code>
</p>

<hr>
<h2 id='train-evaluate-predict'>Base Documentation for train, evaluate, and predict.</h2><span id='topic+train-evaluate-predict'></span>

<h3>Description</h3>

<p>Base Documentation for train, evaluate, and predict.
</p>


<h3>Arguments</h3>

<table>
<tr><td><code id="train-evaluate-predict_+3A_input_fn">input_fn</code></td>
<td>
<p>An input function, typically generated by the <code><a href="#topic+input_fn">input_fn()</a></code>
helper function.</p>
</td></tr>
<tr><td><code id="train-evaluate-predict_+3A_hooks">hooks</code></td>
<td>
<p>A list of <span class="rlang"><b>R</b></span> functions, to be used as callbacks inside the
training loop. By default, <code>hook_history_saver(every_n_step = 10)</code> and
<code>hook_progress_bar()</code> will be attached if not provided to save the metrics
history and create the progress bar.</p>
</td></tr>
<tr><td><code id="train-evaluate-predict_+3A_checkpoint_path">checkpoint_path</code></td>
<td>
<p>The path to a specific model checkpoint to be used for
prediction. If <code>NULL</code> (the default), the latest checkpoint in <code>model_dir</code>
is used.</p>
</td></tr>
</table>

<hr>
<h2 id='train.tf_estimator'>Train an Estimator</h2><span id='topic+train.tf_estimator'></span>

<h3>Description</h3>

<p>Train an estimator on a set of input data provides by the <code>input_fn()</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'tf_estimator'
train(
  object,
  input_fn,
  steps = NULL,
  hooks = NULL,
  max_steps = NULL,
  saving_listeners = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="train.tf_estimator_+3A_object">object</code></td>
<td>
<p>A TensorFlow estimator.</p>
</td></tr>
<tr><td><code id="train.tf_estimator_+3A_input_fn">input_fn</code></td>
<td>
<p>An input function, typically generated by the <code><a href="#topic+input_fn">input_fn()</a></code>
helper function.</p>
</td></tr>
<tr><td><code id="train.tf_estimator_+3A_steps">steps</code></td>
<td>
<p>The number of steps for which the model should be trained on
this particular <code>train()</code> invocation. If <code>NULL</code> (the default), this
function will either train forever, or until the supplied <code>input_fn()</code> has
provided all available data.</p>
</td></tr>
<tr><td><code id="train.tf_estimator_+3A_hooks">hooks</code></td>
<td>
<p>A list of <span class="rlang"><b>R</b></span> functions, to be used as callbacks inside the
training loop. By default, <code>hook_history_saver(every_n_step = 10)</code> and
<code>hook_progress_bar()</code> will be attached if not provided to save the metrics
history and create the progress bar.</p>
</td></tr>
<tr><td><code id="train.tf_estimator_+3A_max_steps">max_steps</code></td>
<td>
<p>The total number of steps for which the model should be
trained. If set, <code>steps</code> must be <code>NULL</code>. If the estimator has already been
trained a total of <code>max_steps</code> times, then no training will be performed.</p>
</td></tr>
<tr><td><code id="train.tf_estimator_+3A_saving_listeners">saving_listeners</code></td>
<td>
<p>(Available since TensorFlow v1.4) A list of
<code>CheckpointSaverListener</code> objects used for callbacks that run immediately
before or after checkpoint savings.</p>
</td></tr>
<tr><td><code id="train.tf_estimator_+3A_...">...</code></td>
<td>
<p>Optional arguments, passed on to the estimator's <code>train()</code> method.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data.frame of the training loss history.
</p>


<h3>See Also</h3>

<p>Other custom estimator methods: 
<code><a href="#topic+estimator_spec">estimator_spec</a>()</code>,
<code><a href="#topic+estimator">estimator</a>()</code>,
<code><a href="#topic+evaluate.tf_estimator">evaluate.tf_estimator</a>()</code>,
<code><a href="#topic+export_savedmodel.tf_estimator">export_savedmodel.tf_estimator</a>()</code>,
<code><a href="#topic+predict.tf_estimator">predict.tf_estimator</a>()</code>
</p>

<hr>
<h2 id='variable_names_values'>Get variable names and values associated with an estimator</h2><span id='topic+variable_names_values'></span><span id='topic+variable_names'></span><span id='topic+variable_value'></span>

<h3>Description</h3>

<p>These helper functions extract the names and values of variables
in the graphs associated with trained estimator models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>variable_names(object)

variable_value(object, variable = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="variable_names_values_+3A_object">object</code></td>
<td>
<p>A trained estimator model.</p>
</td></tr>
<tr><td><code id="variable_names_values_+3A_variable">variable</code></td>
<td>
<p>(Optional) Names of variables to extract as a character vector. If not specified, values for all variables are returned.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>For <code>variable_names()</code>, a vector of variable names. For <code>variable_values()</code>, a named list of variable values.
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
