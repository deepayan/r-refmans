<!DOCTYPE html><html><head><title>Help for package OptHoldoutSize</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {OptHoldoutSize}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#add_aspre_interactions'><p>Add interaction terms corresponding to ASPRE model</p></a></li>
<li><a href='#aspre'><p>Computes ASPRE score</p></a></li>
<li><a href='#aspre_emulation'><p>Emulation-based OHS estimation for ASPRE</p></a></li>
<li><a href='#aspre_k2'><p>Cost estimating function in ASPRE simulation</p></a></li>
<li><a href='#aspre_parametric'><p>Parametric-based OHS estimation for ASPRE</p></a></li>
<li><a href='#ci_cover_a_yn'><p>Data for example on asymptotic confidence interval for OHS.</p></a></li>
<li><a href='#ci_cover_cost_a_yn'><p>Data for example on asymptotic confidence interval for min cost.</p></a></li>
<li><a href='#ci_cover_cost_e_yn'><p>Data for example on empirical confidence interval for min cost.</p></a></li>
<li><a href='#ci_cover_e_yn'><p>Data for example on empirical confidence interval for OHS.</p></a></li>
<li><a href='#ci_mincost'><p>Confidence interval for minimum total cost, when estimated using parametric method</p></a></li>
<li><a href='#ci_ohs'><p>Confidence interval for optimal holdout size, when estimated using parametric method</p></a></li>
<li><a href='#cov_fn'><p>Covariance function for Gaussian process</p></a></li>
<li><a href='#data_example_simulation'><p>Data for vignette showing general example</p></a></li>
<li><a href='#data_nextpoint_em'><p>Data for 'next point' demonstration vignette on algorithm comparison using emulation algorithm</p></a></li>
<li><a href='#data_nextpoint_par'><p>Data for 'next point' demonstration vignette on algorithm comparison using parametric algorithm</p></a></li>
<li><a href='#error_ohs_emulation'><p>Measure of error for emulation-based OHS emulation</p></a></li>
<li><a href='#exp_imp_fn'><p>Expected improvement</p></a></li>
<li><a href='#gen_base_coefs'><p>Coefficients for imperfect risk score</p></a></li>
<li><a href='#gen_preds'><p>Generate matrix of random observations</p></a></li>
<li><a href='#gen_resp'><p>Generate response</p></a></li>
<li><a href='#grad_mincost_powerlaw'><p>Gradient of minimum cost (power law)</p></a></li>
<li><a href='#grad_nstar_powerlaw'><p>Gradient of optimal holdout size (power law)</p></a></li>
<li><a href='#logistic'><p>Logistic</p></a></li>
<li><a href='#logit'><p>Logit</p></a></li>
<li><a href='#model_predict'><p>Make predictions</p></a></li>
<li><a href='#model_train'><p>Train model (wrapper)</p></a></li>
<li><a href='#mu_fn'><p>Updating function for mean.</p></a></li>
<li><a href='#next_n'><p>Finds best value of n to sample next</p></a></li>
<li><a href='#ohs_array'><p>Data for vignette on algorithm comparison</p></a></li>
<li><a href='#ohs_resample'><p>Data for vignette on algorithm comparison</p></a></li>
<li><a href='#optimal_holdout_size'><p>Estimate optimal holdout size under parametric assumptions</p></a></li>
<li><a href='#optimal_holdout_size_emulation'><p>Estimate optimal holdout size under semi-parametric assumptions</p></a></li>
<li><a href='#oracle_pred'><p>Generate responses</p></a></li>
<li><a href='#params_aspre'><p>Parameters of reported ASPRE dataset</p></a></li>
<li><a href='#plot.optholdoutsize'><p>Plot estimated cost function</p></a></li>
<li><a href='#plot.optholdoutsize_emul'><p>Plot estimated cost function using emulation (semiparametric)</p></a></li>
<li><a href='#powerlaw'><p>Power law function</p></a></li>
<li><a href='#powersolve'><p>Fit power law curve</p></a></li>
<li><a href='#powersolve_general'><p>General solver for power law curve</p></a></li>
<li><a href='#powersolve_se'><p>Standard error matrix for learning curve parameters (power law)</p></a></li>
<li><a href='#psi_fn'><p>Updating function for variance.</p></a></li>
<li><a href='#sens10'><p>Sensitivity at theshold quantile 10%</p></a></li>
<li><a href='#sim_random_aspre'><p>Simulate random dataset similar to ASPRE training data</p></a></li>
<li><a href='#split_data'><p>Split data</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Title:</td>
<td>Estimation of Optimal Size for a Holdout Set for Updating a
Predictive Score</td>
</tr>
<tr>
<td>Version:</td>
<td>0.1.0.0</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>James Liley &lt;james.liley@durham.ac.uk&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Predictive scores must be updated with care, because actions taken on the basis of existing risk scores causes bias in risk estimates from the updated score. A holdout set is a straightforward way to manage this problem: a proportion of the population is 'held-out' from computation of the previous risk score. This package provides tools to estimate a size for this holdout set and associated errors. Comprehensive vignettes are included. Please see: Haidar-Wehbe S, Emerson SR, Aslett LJM, Liley J (2022) &lt;<a href="https://doi.org/10.48550/arXiv.2202.06374">doi:10.48550/arXiv.2202.06374</a>&gt; for details of methods. </td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL (&ge; 3)</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0), matrixStats, mnormt, mvtnorm, ranger, mle.tools</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.2</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, rmarkdown</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2022-02-18 10:04:11 UTC; vwbw55</td>
</tr>
<tr>
<td>Author:</td>
<td>Sami Haidar-Wehbe [aut],
  Sam Emerson <a href="https://orcid.org/0000-0002-8379-2781"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut],
  Louis Aslett <a href="https://orcid.org/0000-0003-2211-233X"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut],
  James Liley <a href="https://orcid.org/0000-0002-0049-8238"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [cre,
    aut]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2022-02-18 12:20:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='add_aspre_interactions'>Add interaction terms corresponding to ASPRE model</h2><span id='topic+add_aspre_interactions'></span>

<h3>Description</h3>

<p>Add various interaction terms to X. Interaction terms correspond to those in ASPRE.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>add_aspre_interactions(X)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="add_aspre_interactions_+3A_x">X</code></td>
<td>
<p>data frame</p>
</td></tr>
</table>


<h3>Value</h3>

<p>New data frame containing interaction terms.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Load ASPRE related data
data(params_aspre)

X=sim_random_aspre(1000,params_aspre)
Xnew=add_aspre_interactions(X)

print(colnames(X))
print(colnames(Xnew))

</code></pre>

<hr>
<h2 id='aspre'>Computes ASPRE score</h2><span id='topic+aspre'></span>

<h3>Description</h3>

<p>Computes ASPRE model prediction on a matrix <code>X</code> of covariates
</p>
<p>Full ASPRE model from https://www.nejm.org/doi/suppl/10.1056/NEJMoa1704559/suppl_file/nejmoa1704559_appendix.pdf
</p>
<p>Model is to predict gestational age at PE; that is, a higher score indicates a lower PE risk, so coefficients are negated for model to predict PE risk.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>aspre(X)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="aspre_+3A_x">X</code></td>
<td>
<p>matrix, assumed to be output of sim_random_aspre with parameter params=params_aspre and transformed using add_aspre_interactions</p>
</td></tr>
</table>


<h3>Value</h3>

<p>vector of scores.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Load ASPRE related data
data(params_aspre)

X=sim_random_aspre(1000,params_aspre)
Xnew=add_aspre_interactions(X)

aspre_score=aspre(Xnew)

plot(density(aspre_score))

</code></pre>

<hr>
<h2 id='aspre_emulation'>Emulation-based OHS estimation for ASPRE</h2><span id='topic+aspre_emulation'></span>

<h3>Description</h3>

<p>This object contains data relating to emulation-based OHS estimation for the ASPRE model. For generation, see hidden code in vignette, or in pipeline at https://github.com/jamesliley/OptHoldoutSize_pipelines
</p>


<h3>Usage</h3>

<pre><code class='language-R'>aspre_emulation
</code></pre>


<h3>Format</h3>

<p>An object of class <code>list</code> of length 4.
</p>

<hr>
<h2 id='aspre_k2'>Cost estimating function in ASPRE simulation</h2><span id='topic+aspre_k2'></span>

<h3>Description</h3>

<p>Estimate cost at a given holdout set size in ASPRE model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>aspre_k2(
  n,
  X,
  PRE,
  seed = NULL,
  pi_PRE = 1426/58974,
  pi_intervention = 0.1,
  alpha = 0.37
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="aspre_k2_+3A_n">n</code></td>
<td>
<p>Holdout set size at which to estimate k_2 (cost)</p>
</td></tr>
<tr><td><code id="aspre_k2_+3A_x">X</code></td>
<td>
<p>Matrix of predictors</p>
</td></tr>
<tr><td><code id="aspre_k2_+3A_pre">PRE</code></td>
<td>
<p>Vector indicating PRE incidence</p>
</td></tr>
<tr><td><code id="aspre_k2_+3A_seed">seed</code></td>
<td>
<p>Random seed; set before starting or set to NULL</p>
</td></tr>
<tr><td><code id="aspre_k2_+3A_pi_pre">pi_PRE</code></td>
<td>
<p>Population prevalence of PRE if not prophylactically treated. Defaults to empirical value 1426/58974</p>
</td></tr>
<tr><td><code id="aspre_k2_+3A_pi_intervention">pi_intervention</code></td>
<td>
<p>Proportion of the population on which an intervention will be made. Defaults to 0.1</p>
</td></tr>
<tr><td><code id="aspre_k2_+3A_alpha">alpha</code></td>
<td>
<p>Reduction in PRE risk with intervention. Defaults to empirical value 0.37</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Estimated cost
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Simulate
set.seed(32142)

N=1000; p=15
X=matrix(rnorm(N*p),N,p); PRE=rbinom(N,1,prob=logit(X%*% rnorm(p)))
aspre_k2(1000,X,PRE)
</code></pre>

<hr>
<h2 id='aspre_parametric'>Parametric-based OHS estimation for ASPRE</h2><span id='topic+aspre_parametric'></span>

<h3>Description</h3>

<p>This object contains data relating to parametric-based OHS estimation for the ASPRE model. For generation, see hidden code in vignette, or in pipeline at https://github.com/jamesliley/OptHoldoutSize_pipelines
</p>


<h3>Usage</h3>

<pre><code class='language-R'>aspre_parametric
</code></pre>


<h3>Format</h3>

<p>An object of class <code>list</code> of length 4.
</p>

<hr>
<h2 id='ci_cover_a_yn'>Data for example on asymptotic confidence interval for OHS.</h2><span id='topic+ci_cover_a_yn'></span>

<h3>Description</h3>

<p>Data for example for asymptotic confidence interval for OHS. For generation, see example.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ci_cover_a_yn
</code></pre>


<h3>Format</h3>

<p>An object of class <code>matrix</code> (inherits from <code>array</code>) with 11 rows and 5000 columns.
</p>

<hr>
<h2 id='ci_cover_cost_a_yn'>Data for example on asymptotic confidence interval for min cost.</h2><span id='topic+ci_cover_cost_a_yn'></span>

<h3>Description</h3>

<p>Data for example for asymptotic confidence interval for min cost. For generation, see example.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ci_cover_cost_a_yn
</code></pre>


<h3>Format</h3>

<p>An object of class <code>matrix</code> (inherits from <code>array</code>) with 11 rows and 5000 columns.
</p>

<hr>
<h2 id='ci_cover_cost_e_yn'>Data for example on empirical confidence interval for min cost.</h2><span id='topic+ci_cover_cost_e_yn'></span>

<h3>Description</h3>

<p>Data for example for empirical confidence interval for min cost. For generation, see example.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ci_cover_cost_e_yn
</code></pre>


<h3>Format</h3>

<p>An object of class <code>matrix</code> (inherits from <code>array</code>) with 11 rows and 5000 columns.
</p>

<hr>
<h2 id='ci_cover_e_yn'>Data for example on empirical confidence interval for OHS.</h2><span id='topic+ci_cover_e_yn'></span>

<h3>Description</h3>

<p>Data for example for empirical confidence interval for OHS. For generation, see example.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ci_cover_e_yn
</code></pre>


<h3>Format</h3>

<p>An object of class <code>matrix</code> (inherits from <code>array</code>) with 11 rows and 5000 columns.
</p>

<hr>
<h2 id='ci_mincost'>Confidence interval for minimum total cost, when estimated using parametric method</h2><span id='topic+ci_mincost'></span>

<h3>Description</h3>

<p>Compute confidence interval for cost at optimal holdout size given either a standard error covariance matrix or a set of m estimates of parameters.
</p>
<p>This can be done either asymptotically, using a method analogous to the Fisher information matrix, or empirically (using bootstrap resampling)
</p>
<p>If sigma (covariance matrix) is specified and method='bootstrap', a confidence interval is generated assuming a Gaussian distribution of (N,k1,theta). To estimate a confidence interval assuming a non-Gaussian distribution, simulate values under the requisite distribution and use then as parameters N,k1, theta, with sigma set to NULL.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ci_mincost(
  N,
  k1,
  theta,
  alpha = 0.05,
  k2form = powerlaw,
  grad_mincost = NULL,
  sigma = NULL,
  n_boot = 1000,
  seed = NULL,
  mode = "empirical",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ci_mincost_+3A_n">N</code></td>
<td>
<p>Vector of estimates of total number of samples on which the predictive score will be used/fitted, or single estimate</p>
</td></tr>
<tr><td><code id="ci_mincost_+3A_k1">k1</code></td>
<td>
<p>Vector of estimates of cost value in the absence of a predictive score, or single number</p>
</td></tr>
<tr><td><code id="ci_mincost_+3A_theta">theta</code></td>
<td>
<p>Matrix of estimates of parameters for function k2form(n) governing expected cost to an individual sample given a predictive score fitted to n samples. Can be a matrix of dimension n x n_par, where n_par is the number of parameters of k2.</p>
</td></tr>
<tr><td><code id="ci_mincost_+3A_alpha">alpha</code></td>
<td>
<p>Construct 1-alpha confidence interval. Defaults to 0.05</p>
</td></tr>
<tr><td><code id="ci_mincost_+3A_k2form">k2form</code></td>
<td>
<p>Function governing expected cost to an individual sample given a predictive score fitted to n samples. Must take two arguments: n (number of samples) and theta (parameters). Defaults to a power-law form <code style="white-space: pre;">&#8288;k2(n,c(a,b,c))=a n^(-b) + c&#8288;</code>.</p>
</td></tr>
<tr><td><code id="ci_mincost_+3A_grad_mincost">grad_mincost</code></td>
<td>
<p>Function giving partial derivatives of minimum cost, taking three arguments: N, k1, and theta. Only used for asymptotic confidence intervals. F NULL, estimated empirically</p>
</td></tr>
<tr><td><code id="ci_mincost_+3A_sigma">sigma</code></td>
<td>
<p>Standard error covariance matrix for (N,k1,theta), in that order. If NULL, will derive as sample covariance matrix of parameters. Must be of the correct size and positive definite.</p>
</td></tr>
<tr><td><code id="ci_mincost_+3A_n_boot">n_boot</code></td>
<td>
<p>Number of bootstrap resamples for empirical estimate.</p>
</td></tr>
<tr><td><code id="ci_mincost_+3A_seed">seed</code></td>
<td>
<p>Random seed for bootstrap resamples. Defaults to NULL.</p>
</td></tr>
<tr><td><code id="ci_mincost_+3A_mode">mode</code></td>
<td>
<p>One of 'asymptotic' or 'empirical'. Defaults to 'empirical'</p>
</td></tr>
<tr><td><code id="ci_mincost_+3A_...">...</code></td>
<td>
<p>Passed to function <code>optimize</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of length two containing lower and upper limits of confidence interval.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Set seed
set.seed(574635)

## We will assume that our observations of N, k1, and theta=(a,b,c) are
##  distributed with mean mu_par and variance sigma_par
mu_par=c(N=10000,k1=0.35,A=3,B=1.5,C=0.1)
sigma_par=cbind(
  c(100^2,       1,      0,       0,       0),
  c(    1,  0.07^2,      0,       0,       0),
  c(    0,       0,  0.5^2,    0.05,  -0.001),
  c(    0,       0,   0.05,   0.4^2,  -0.002),
  c(    0,       0, -0.001,  -0.002,  0.02^2)
)

# Firstly, we make 500 observations
par_obs=rmnorm(500,mean=mu_par,varcov=sigma_par)

# Minimum cost and asymptotic and empirical confidence intervals
mincost=optimal_holdout_size(N=mean(par_obs[,1]),k1=mean(par_obs[,2]),
  theta=colMeans(par_obs[,3:5]))$cost
ci_a=ci_mincost(N=par_obs[,1],k1=par_obs[,2],theta=par_obs[,3:5],alpha=0.05,
  seed=12345,mode="asymptotic")
ci_e=ci_mincost(N=par_obs[,1],k1=par_obs[,2],theta=par_obs[,3:5],alpha=0.05,
  seed=12345,mode="empirical")


# Assess cover at various m
m_values=c(20,30,50,100,150,200,300,500,750,1000,1500)
ntrial=5000
alpha_trial=0.1 # use 90% confidence intervals
mincost_true=optimal_holdout_size(N=mu_par[1],k1=mu_par[2],
  theta=mu_par[3:5])$cost

## The matrices indicating cover take are included in this package but take
##  around 30 minutes to generate. They are generated using the code below
##  (including random seeds).
data(ci_cover_cost_a_yn)
data(ci_cover_cost_e_yn)

if (!exists("ci_cover_cost_a_yn")) {
  ci_cover_cost_a_yn=matrix(NA,length(m_values),ntrial) # Entry [i,j] is 1
  #  if ith asymptotic CI for jth value of m covers true mincost
  ci_cover_cost_e_yn=matrix(NA,length(m_values),ntrial) # Entry [i,j] is 1
  #  if ith empirical CI for jth value of m covers true mincost

  for (i in 1:length(m_values)) {
    m=m_values[i]
    for (j in 1:ntrial) {
      # Set seed
      set.seed(j*ntrial + i + 12345)

      # Make m observations
      par_obs=rmnorm(m,mean=mu_par,varcov=sigma_par)
      ci_a=ci_mincost(N=par_obs[,1],k1=par_obs[,2],theta=par_obs[,3:5],
        alpha=alpha_trial,mode="asymptotic")
      ci_e=ci_mincost(N=par_obs[,1],k1=par_obs[,2],theta=par_obs[,3:5],
        alpha=alpha_trial,mode="empirical",n_boot=500)

      if (mincost_true&gt;ci_a[1] &amp; mincost_true&lt;ci_a[2])
        ci_cover_cost_a_yn[i,j]=1 else ci_cover_cost_a_yn[i,j]=0
      if (mincost_true&gt;ci_e[1] &amp; mincost_true&lt;ci_e[2])
        ci_cover_cost_e_yn[i,j]=1 else ci_cover_cost_e_yn[i,j]=0
    }
    print(paste0("Completed for m = ",m))
  }

save(ci_cover_cost_a_yn,file="data/ci_cover_cost_a_yn.RData")
save(ci_cover_cost_e_yn,file="data/ci_cover_cost_e_yn.RData")

}

# Cover at each m value and standard error
cover_a=rowMeans(ci_cover_cost_a_yn)
cover_e=rowMeans(ci_cover_cost_e_yn)
zse_a=2*sqrt(cover_a*(1-cover_a)/ntrial)
zse_e=2*sqrt(cover_e*(1-cover_e)/ntrial)


# Draw plot. Convergence to 1-alpha cover is evident. Cover is not far from
#   alpha even at small m.

plot(0,type="n",xlim=range(m_values),ylim=c(0.7,1),xlab=expression("m"),
  ylab="Cover")

# Asymptotic cover and 2*SE pointwise envelope
polygon(c(m_values,rev(m_values)),c(cover_a+zse_a,rev(cover_a-zse_a)),
  col=rgb(0,0,0,alpha=0.3),border=NA)
lines(m_values,cover_a,col="black")

# Empirical cover and 2*SE pointwiseenvelope
polygon(c(m_values,rev(m_values)),c(cover_e+zse_e,rev(cover_e-zse_e)),
  col=rgb(0,0,1,alpha=0.3),border=NA)
lines(m_values,cover_e,col="blue")

abline(h=1-alpha_trial,col="red")
legend("bottomright",c("Asym.","Emp.",expression(paste("1-",alpha))),lty=1,
  col=c("black","blue","red"))

</code></pre>

<hr>
<h2 id='ci_ohs'>Confidence interval for optimal holdout size, when estimated using parametric method</h2><span id='topic+ci_ohs'></span>

<h3>Description</h3>

<p>Compute confidence interval for optimal holdout size given either a standard error covariance matrix or a set of m estimates of parameters.
</p>
<p>This can be done either asymptotically, using a method analogous to the Fisher information matrix, or empirically (using bootstrap resampling)
</p>
<p>If sigma (covariance matrix) is specified and method='bootstrap', a confidence interval is generated assuming a Gaussian distribution of (N,k1,theta). To estimate a confidence interval assuming a non-Gaussian distribution, simulate values under the requisite distribution and use then as parameters N,k1, theta, with sigma set to NULL.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ci_ohs(
  N,
  k1,
  theta,
  alpha = 0.05,
  k2form = powerlaw,
  grad_nstar = NULL,
  sigma = NULL,
  n_boot = 1000,
  seed = NULL,
  mode = "empirical",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ci_ohs_+3A_n">N</code></td>
<td>
<p>Vector of estimates of total number of samples on which the predictive score will be used/fitted, or single estimate</p>
</td></tr>
<tr><td><code id="ci_ohs_+3A_k1">k1</code></td>
<td>
<p>Vector of estimates of cost value in the absence of a predictive score, or single number</p>
</td></tr>
<tr><td><code id="ci_ohs_+3A_theta">theta</code></td>
<td>
<p>Matrix of estimates of parameters for function k2form(n) governing expected cost to an individual sample given a predictive score fitted to n samples. Can be a matrix of dimension n x n_par, where n_par is the number of parameters of k2.</p>
</td></tr>
<tr><td><code id="ci_ohs_+3A_alpha">alpha</code></td>
<td>
<p>Construct 1-alpha confidence interval. Defaults to 0.05</p>
</td></tr>
<tr><td><code id="ci_ohs_+3A_k2form">k2form</code></td>
<td>
<p>Function governing expected cost to an individual sample given a predictive score fitted to n samples. Must take two arguments: n (number of samples) and theta (parameters). Defaults to a power-law form <code style="white-space: pre;">&#8288;k2(n,c(a,b,c))=a n^(-b) + c&#8288;</code>.</p>
</td></tr>
<tr><td><code id="ci_ohs_+3A_grad_nstar">grad_nstar</code></td>
<td>
<p>Function giving partial derivatives of optimal holdout set, taking three arguments: N, k1, and theta. Only used for asymptotic confidence intervals. F NULL, estimated empirically</p>
</td></tr>
<tr><td><code id="ci_ohs_+3A_sigma">sigma</code></td>
<td>
<p>Standard error covariance matrix for (N,k1,theta), in that order. If NULL, will derive as sample covariance matrix of parameters. Must be of the correct size and positive definite.</p>
</td></tr>
<tr><td><code id="ci_ohs_+3A_n_boot">n_boot</code></td>
<td>
<p>Number of bootstrap resamples for empirical estimate.</p>
</td></tr>
<tr><td><code id="ci_ohs_+3A_seed">seed</code></td>
<td>
<p>Random seed for bootstrap resamples. Defaults to NULL.</p>
</td></tr>
<tr><td><code id="ci_ohs_+3A_mode">mode</code></td>
<td>
<p>One of 'asymptotic' or 'empirical'. Defaults to 'empirical'</p>
</td></tr>
<tr><td><code id="ci_ohs_+3A_...">...</code></td>
<td>
<p>Passed to function <code>optimize</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of length two containing lower and upper limits of confidence interval.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Set seed
set.seed(493825)

## We will assume that our observations of N, k1, and theta=(a,b,c) are
##  distributed with mean mu_par and variance sigma_par
mu_par=c(N=10000,k1=0.35,A=3,B=1.5,C=0.1)
sigma_par=cbind(
  c(100^2,       1,      0,       0,       0),
  c(    1,  0.07^2,      0,       0,       0),
  c(    0,       0,  0.5^2,    0.05,  -0.001),
  c(    0,       0,   0.05,   0.4^2,  -0.002),
  c(    0,       0, -0.001,  -0.002,  0.02^2)
)

# Firstly, we make 500 observations
par_obs=rmnorm(500,mean=mu_par,varcov=sigma_par)

# Optimal holdout size and asymptotic and empirical confidence intervals
ohs=optimal_holdout_size(N=mean(par_obs[,1]),k1=mean(par_obs[,2]),
  theta=colMeans(par_obs[,3:5]))$size
ci_a=ci_ohs(N=par_obs[,1],k1=par_obs[,2],theta=par_obs[,3:5],alpha=0.05,
  seed=12345,mode="asymptotic")
ci_e=ci_ohs(N=par_obs[,1],k1=par_obs[,2],theta=par_obs[,3:5],alpha=0.05,
  seed=12345,mode="empirical")


# Assess cover at various m
m_values=c(20,30,50,100,150,200,300,500,750,1000,1500)
ntrial=5000
alpha_trial=0.1 # use 90% confidence intervals
nstar_true=optimal_holdout_size(N=mu_par[1],k1=mu_par[2],
  theta=mu_par[3:5])$size

## The matrices indicating cover take are included in this package but take
##  around 30 minutes to generate. They are generated using the code below
##  (including random seeds).
data(ci_cover_a_yn)
data(ci_cover_e_yn)

if (!exists("ci_cover_a_yn")) {
  ci_cover_a_yn=matrix(NA,length(m_values),ntrial) # Entry [i,j] is 1 if ith
  ##  asymptotic CI for jth value of m covers true nstar
  ci_cover_e_yn=matrix(NA,length(m_values),ntrial) # Entry [i,j] is 1 if ith
  ##  empirical CI for jth value of m covers true nstar

  for (i in 1:length(m_values)) {
    m=m_values[i]
    for (j in 1:ntrial) {
      # Set seed
      set.seed(j*ntrial + i + 12345)

      # Make m observations
      par_obs=rmnorm(m,mean=mu_par,varcov=sigma_par)
      ci_a=ci_ohs(N=par_obs[,1],k1=par_obs[,2],theta=par_obs[,3:5],
        alpha=alpha_trial,mode="asymptotic")
      ci_e=ci_ohs(N=par_obs[,1],k1=par_obs[,2],theta=par_obs[,3:5],
        alpha=alpha_trial,mode="empirical",n_boot=500)

      if (nstar_true&gt;ci_a[1] &amp; nstar_true&lt;ci_a[2]) ci_cover_a_yn[i,j]=1 else
         ci_cover_a_yn[i,j]=0
      if (nstar_true&gt;ci_e[1] &amp; nstar_true&lt;ci_e[2]) ci_cover_e_yn[i,j]=1 else
         ci_cover_e_yn[i,j]=0
    }
    print(paste0("Completed for m = ",m))
  }

save(ci_cover_a_yn,file="data/ci_cover_a_yn.RData")
save(ci_cover_e_yn,file="data/ci_cover_e_yn.RData")

}

# Cover at each m value and standard error
cover_a=rowMeans(ci_cover_a_yn)
cover_e=rowMeans(ci_cover_e_yn)
zse_a=2*sqrt(cover_a*(1-cover_a)/ntrial)
zse_e=2*sqrt(cover_e*(1-cover_e)/ntrial)


# Draw plot. Convergence to 1-alpha cover is evident. Cover is not far from
#   alpha even at small m.

plot(0,type="n",xlim=range(m_values),ylim=c(0.7,1),xlab=expression("m"),
  ylab="Cover")

# Asymptotic cover and 2*SE pointwise envelope
polygon(c(m_values,rev(m_values)),c(cover_a+zse_a,rev(cover_a-zse_a)),
  col=rgb(0,0,0,alpha=0.3),border=NA)
lines(m_values,cover_a,col="black")

# Empirical cover and 2*SE pointwiseenvelope
polygon(c(m_values,rev(m_values)),c(cover_e+zse_e,rev(cover_e-zse_e)),
  col=rgb(0,0,1,alpha=0.3),border=NA)
lines(m_values,cover_e,col="blue")

abline(h=1-alpha_trial,col="red")
legend("bottomright",c("Asym.","Emp.",expression(paste("1-",alpha))),lty=1,
  col=c("black","blue","red"))

</code></pre>

<hr>
<h2 id='cov_fn'>Covariance function for Gaussian process</h2><span id='topic+cov_fn'></span>

<h3>Description</h3>

<p>Radial kernel covariance function for Gaussian process.
</p>
<p>Used for a Gaussian process <code>GP(m,k(.,.))</code>, an instance X of which has covariance k(n,n') between X(n) and X(n').
</p>
<p>Covariance function is parametrised by <code>var_u</code> (general variance) and <code>k_width</code> (kernel width)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cov_fn(n, ndash, var_u, k_width)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cov_fn_+3A_n">n</code></td>
<td>
<p>Argument 1: kernel is a function of <code>ndash-n</code></p>
</td></tr>
<tr><td><code id="cov_fn_+3A_ndash">ndash</code></td>
<td>
<p>Argument 2: kernel is a function of <code>ndash-n</code></p>
</td></tr>
<tr><td><code id="cov_fn_+3A_var_u">var_u</code></td>
<td>
<p>Global variance</p>
</td></tr>
<tr><td><code id="cov_fn_+3A_k_width">k_width</code></td>
<td>
<p>Kernel width</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Covariance value
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# We will sample from Gaussian processes
#  GP(0,k(.,.)=cov_fn(.,.;var_u,theta))
# at these values of n
nvals=seq(1,300,length=100)

# We will consider two theta values
kw1=10; kw2=30

# We will consider two var_u values
var1=1; var2=10

# Covariance matrices
cov11=outer(nvals,nvals,function(n,ndash) cov_fn(n,ndash,var_u=var1,
  k_width=kw1))
cov12=outer(nvals,nvals,function(n,ndash) cov_fn(n,ndash,var_u=var1,
  k_width=kw2))
cov21=outer(nvals,nvals,function(n,ndash) cov_fn(n,ndash,var_u=var2,
  k_width=kw1))
cov22=outer(nvals,nvals,function(n,ndash) cov_fn(n,ndash,var_u=var2,
  k_width=kw2))

# Dampen slightly to ensure positive definiteness
damp=1e-5
cov11=(1-damp)*(1-diag(length(nvals)))*cov11 + diag(length(nvals))*cov11
cov12=(1-damp)*(1-diag(length(nvals)))*cov12 + diag(length(nvals))*cov12
cov21=(1-damp)*(1-diag(length(nvals)))*cov21 + diag(length(nvals))*cov21
cov22=(1-damp)*(1-diag(length(nvals)))*cov22 + diag(length(nvals))*cov22

# Sample
set.seed(35243)
y11=rmnorm(1,mean=0,varcov=cov11)
y12=rmnorm(1,mean=0,varcov=cov12)
y21=rmnorm(1,mean=0,varcov=cov21)
y22=rmnorm(1,mean=0,varcov=cov22)

# Plot
rr=max(abs(c(y11,y12,y21,y22)))
plot(0,xlim=range(nvals),ylim=c(-rr,rr+10),xlab="n",
  ylab=expression("GP(0,cov_fn(.,.;var_u,theta))"))
lines(nvals,y11,lty=1,col="black")
lines(nvals,y12,lty=2,col="black")
lines(nvals,y21,lty=1,col="red")
lines(nvals,y22,lty=2,col="red")
legend("topright",c("k_width=10, var_u=1", "k_width=30, var_u=1",
  "k_width=10, var_u=10","k_width=30, var_u=10"),
  lty=c(1,2,1,2),col=c("black","black","red","red"))

</code></pre>

<hr>
<h2 id='data_example_simulation'>Data for vignette showing general example</h2><span id='topic+data_example_simulation'></span>

<h3>Description</h3>

<p>Data for general vignette. For generation, see hidden code in vignette, or in pipeline at https://github.com/jamesliley/OptHoldoutSize_pipelines
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data_example_simulation
</code></pre>


<h3>Format</h3>

<p>An object of class <code>list</code> of length 4.
</p>

<hr>
<h2 id='data_nextpoint_em'>Data for 'next point' demonstration vignette on algorithm comparison using emulation algorithm</h2><span id='topic+data_nextpoint_em'></span>

<h3>Description</h3>

<p>Data containing 'next point selected' information for emulation algorithm in vignette comparing emulation and parametric algorithms. For generation, see hidden code in vignette, or in pipeline at https://github.com/jamesliley/OptHoldoutSize_pipelines
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data_nextpoint_em
</code></pre>


<h3>Format</h3>

<p>An object of class <code>list</code> of length 6.
</p>

<hr>
<h2 id='data_nextpoint_par'>Data for 'next point' demonstration vignette on algorithm comparison using parametric algorithm</h2><span id='topic+data_nextpoint_par'></span>

<h3>Description</h3>

<p>Data containing 'next point selected' information for parametric algorithm in vignette comparing emulation and parametric algorithms. For generation, see hidden code in vignette, or in pipeline at https://github.com/jamesliley/OptHoldoutSize_pipelines
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data_nextpoint_par
</code></pre>


<h3>Format</h3>

<p>An object of class <code>list</code> of length 6.
</p>

<hr>
<h2 id='error_ohs_emulation'>Measure of error for emulation-based OHS emulation</h2><span id='topic+error_ohs_emulation'></span>

<h3>Description</h3>

<p>Measure of error for semiparametric (emulation) based estimation of optimal holdout set sizes.
</p>
<p>Returns a set of values of n for which a <code>1-alpha</code> credible interval for cost at includes a lower value than the cost at the estimated optimal holdout size.
</p>
<p>This is not a confidence interval, credible interval or credible set for the OHS, and is prone to misinterpretation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>error_ohs_emulation(
  nset,
  k2,
  var_k2,
  N,
  k1,
  alpha = 0.1,
  var_u = 1e+07,
  k_width = 5000,
  k2form = powerlaw,
  theta = powersolve(nset, k2, y_var = var_k2)$par,
  npoll = 1000
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="error_ohs_emulation_+3A_nset">nset</code></td>
<td>
<p>Training set sizes for which k2() has been evaluated</p>
</td></tr>
<tr><td><code id="error_ohs_emulation_+3A_k2">k2</code></td>
<td>
<p>Estimated k2() at training set sizes <code>nset</code></p>
</td></tr>
<tr><td><code id="error_ohs_emulation_+3A_var_k2">var_k2</code></td>
<td>
<p>Variance of error in k2() estimate at each training set size.</p>
</td></tr>
<tr><td><code id="error_ohs_emulation_+3A_n">N</code></td>
<td>
<p>Total number of samples on which the model will be fitted/used</p>
</td></tr>
<tr><td><code id="error_ohs_emulation_+3A_k1">k1</code></td>
<td>
<p>Mean cost per sample with no predictive score in place</p>
</td></tr>
<tr><td><code id="error_ohs_emulation_+3A_alpha">alpha</code></td>
<td>
<p>Use 1-alpha credible interval. Defaults to 0.1.</p>
</td></tr>
<tr><td><code id="error_ohs_emulation_+3A_var_u">var_u</code></td>
<td>
<p>Marginal variance for Gaussian process kernel. Defaults to 1e7</p>
</td></tr>
<tr><td><code id="error_ohs_emulation_+3A_k_width">k_width</code></td>
<td>
<p>Kernel width for Gaussian process kernel. Defaults to 5000</p>
</td></tr>
<tr><td><code id="error_ohs_emulation_+3A_k2form">k2form</code></td>
<td>
<p>Functional form governing expected cost per sample given sample size. Should take two parameters: n (sample size) and theta (parameters). Defaults to function <code>powerlaw</code>.</p>
</td></tr>
<tr><td><code id="error_ohs_emulation_+3A_theta">theta</code></td>
<td>
<p>Current estimates of parameter values for k2form. Defaults to the MLE power-law solution corresponding to n,k2, and var_k2.</p>
</td></tr>
<tr><td><code id="error_ohs_emulation_+3A_npoll">npoll</code></td>
<td>
<p>Check npoll equally spaced values between 1 and N for minimum. If NULL, check all values (this can be slow). Defaults to 1000</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Vector of values <code>n</code> for which 1-alpha credible interval for cost <code>l(n)</code> at n contains mean posterior cost at estimated optimal holdout size.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
 # Set seed
set.seed(57365)

# Parameters
N=100000;
k1=0.3
A=8000; B=1.5; C=0.15; theta=c(A,B,C)

# True mean function
k2_true=function(n) powerlaw(n,theta)

# True OHS
nx=1:N
ohs_true=nx[which.min(k1*nx + k2_true(nx)*(N-nx))]

# Values of n for which cost has been estimated
np=50 # this many points
nset=round(runif(np,1,N))
var_k2=runif(np,0.001,0.0015)
k2=rnorm(np,mean=k2_true(nset),sd=sqrt(var_k2))

# Compute OHS
res1=optimal_holdout_size_emulation(nset,k2,var_k2,N,k1)

# Error estimates
ex=error_ohs_emulation(nset,k2,var_k2,N,k1)

# Plot
plot(res1)

# Add error
abline(v=ohs_true)
abline(v=ex,col=rgb(1,0,0,alpha=0.2))

# Show justification for error
n=seq(1,N,length=1000)
mu=mu_fn(n,nset,k2,var_k2,N,k1); psi=pmax(0,psi_fn(n, nset, var_k2, N)); Z=-qnorm(0.1/2)
lines(n,mu - Z*sqrt(psi),lty=2,lwd=2)
legend("topright",
    c("Err. region",expression(paste(mu(n)- "z"[alpha/2]*sqrt(psi(n))))),
    pch=c(16,NA),lty=c(NA,2),lwd=c(NA,2),col=c("pink","black"),bty="n")
</code></pre>

<hr>
<h2 id='exp_imp_fn'>Expected improvement</h2><span id='topic+exp_imp_fn'></span>

<h3>Description</h3>

<p>Expected improvement
</p>
<p>Essentially chooses the <code style="white-space: pre;">&#8288;next point&#8288;</code> to add to <code>n</code>, called <code style="white-space: pre;">&#8288;n*&#8288;</code>, in order to minimise the expectation of <code style="white-space: pre;">&#8288;cost(n*)&#8288;</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>exp_imp_fn(
  n,
  nset,
  k2,
  var_k2,
  N,
  k1,
  var_u = 1e+07,
  k_width = 5000,
  k2form = powerlaw,
  theta = powersolve(nset, k2, y_var = var_k2)$par
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="exp_imp_fn_+3A_n">n</code></td>
<td>
<p>Set of training set sizes to evaluate</p>
</td></tr>
<tr><td><code id="exp_imp_fn_+3A_nset">nset</code></td>
<td>
<p>Training set sizes for which a cost has been evaluated</p>
</td></tr>
<tr><td><code id="exp_imp_fn_+3A_k2">k2</code></td>
<td>
<p>Estimates of k2() at training set sizes <code>nset</code></p>
</td></tr>
<tr><td><code id="exp_imp_fn_+3A_var_k2">var_k2</code></td>
<td>
<p>Variance of error in k2() estimates at each training set size.</p>
</td></tr>
<tr><td><code id="exp_imp_fn_+3A_n">N</code></td>
<td>
<p>Total number of samples on which the model will be fitted/used</p>
</td></tr>
<tr><td><code id="exp_imp_fn_+3A_k1">k1</code></td>
<td>
<p>Mean vost per sample with no predictive score in place</p>
</td></tr>
<tr><td><code id="exp_imp_fn_+3A_var_u">var_u</code></td>
<td>
<p>Marginal variance for Gaussian process kernel. Defaults to 1e7</p>
</td></tr>
<tr><td><code id="exp_imp_fn_+3A_k_width">k_width</code></td>
<td>
<p>Kernel width for Gaussian process kernel. Defaults to 5000</p>
</td></tr>
<tr><td><code id="exp_imp_fn_+3A_k2form">k2form</code></td>
<td>
<p>Functional form governing expected cost per sample given sample size. Should take two parameters: n (sample size) and theta (parameters). Defaults to function <code>powerlaw</code>.</p>
</td></tr>
<tr><td><code id="exp_imp_fn_+3A_theta">theta</code></td>
<td>
<p>Current estimates of parameter values for k2form. Defaults to the MLE power-law solution corresponding to n,k2, and var_k2.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Value of expected improvement at values n
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Set seed.
set.seed(24015)

# Kernel width and Gaussian process variance
kw0=5000
vu0=1e7

# Include legend on plots or not; inclusion can obscure plot elements on small figures
inc_legend=FALSE

# Suppose we have population size and cost-per-sample without a risk score as follows
N=100000
k1=0.4

# Suppose that true values of a,b,c are given by
theta_true=c(10000,1.2,0.2)
theta_lower=c(1,0.5,0.1) # lower bounds for estimating theta
theta_upper=c(20000,2,0.5) # upper bounds for estimating theta



# We start with five random holdout set sizes (nset0),
#  with corresponding cost-per-individual estimates k2_0 derived
#  with various errors var_k2_0
nstart=4
vwmin=0.001; vwmax=0.005
nset0=round(runif(nstart,1000,N/2))
var_k2_0=runif(nstart,vwmin,vwmax)
k2_0=rnorm(nstart,mean=powerlaw(nset0,theta_true),sd=sqrt(var_k2_0))

# We estimate theta from these three points
theta0=powersolve(nset0,k2_0,y_var=var_k2_0,lower=theta_lower,upper=theta_upper,
  init=theta_true)$par

# We will estimate the posterior at these values of n
n=seq(1000,N,length=1000)

# Mean and variance
p_mu=mu_fn(n,nset=nset0,k2=k2_0,var_k2 = var_k2_0, N=N,k1=k1,theta=theta0,k_width=kw0,
  var_u=vu0)
p_var=psi_fn(n,nset=nset0,N=N,var_k2 = var_k2_0,k_width=kw0,var_u=vu0)

# Plot
yrange=c(-30000,100000)
plot(0,xlim=range(n),ylim=yrange,type="n",
  xlab="Training/holdout set size",
  ylab="Total cost (= num. cases)")
lines(n,p_mu,col="blue")
lines(n,p_mu - 3*sqrt(p_var),col="red")
lines(n,p_mu + 3*sqrt(p_var),col="red")
points(nset0,k1*nset0 + k2_0*(N-nset0),pch=16,col="purple")
lines(n,k1*n + powerlaw(n,theta0)*(N-n),lty=2)
lines(n,k1*n + powerlaw(n,theta_true)*(N-n),lty=3,lwd=3)
if (inc_legend) {
  legend("topright",
    c(expression(mu(n)),
      expression(mu(n) %+-% 3*sqrt(psi(n))),
      "prior(n)",
      "True",
      "d"),
    lty=c(1,1,2,3,NA),lwd=c(1,1,1,3,NA),pch=c(NA,NA,NA,NA,16),pt.cex=c(NA,NA,NA,NA,1),
    col=c("blue","red","black","purple"),bg="white")
}

## Add line corresponding to recommended new point
exp_imp_em &lt;- exp_imp_fn(n,nset=nset0,k2=k2_0,var_k2 = var_k2_0, N=N,k1=k1,
  theta=theta0,k_width=kw0,var_u=vu0)
abline(v=n[which.max(exp_imp_em)])

</code></pre>

<hr>
<h2 id='gen_base_coefs'>Coefficients for imperfect risk score</h2><span id='topic+gen_base_coefs'></span>

<h3>Description</h3>

<p>Generate coefficients corresponding to an imperfect risk score, interpretable
as 'baseline' behaviour in the absence of a risk score
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gen_base_coefs(coefs, noise = TRUE, num_vars = 2, max_base_powers = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gen_base_coefs_+3A_coefs">coefs</code></td>
<td>
<p>Original coefficients</p>
</td></tr>
<tr><td><code id="gen_base_coefs_+3A_noise">noise</code></td>
<td>
<p>Set to TRUE to add Gaussian noise to coefficients</p>
</td></tr>
<tr><td><code id="gen_base_coefs_+3A_num_vars">num_vars</code></td>
<td>
<p>Number of variables at hand for baseline calculation</p>
</td></tr>
<tr><td><code id="gen_base_coefs_+3A_max_base_powers">max_base_powers</code></td>
<td>
<p>If &gt;1, return a matrix of coefficients, with successively more noise</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Vector of coefficients
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# See examples for model_predict
</code></pre>

<hr>
<h2 id='gen_preds'>Generate matrix of random observations</h2><span id='topic+gen_preds'></span>

<h3>Description</h3>

<p>Generate matrix of random observations. Observations are unit Gaussian-distributed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gen_preds(nobs, npreds, ninters = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gen_preds_+3A_nobs">nobs</code></td>
<td>
<p>Number of observations (samples)</p>
</td></tr>
<tr><td><code id="gen_preds_+3A_npreds">npreds</code></td>
<td>
<p>Number of predictors</p>
</td></tr>
<tr><td><code id="gen_preds_+3A_ninters">ninters</code></td>
<td>
<p>Number of interaction terms, default 0. Up to npreds*(npreds-1)/2</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Data frame of observations
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# See examples for model_predict
</code></pre>

<hr>
<h2 id='gen_resp'>Generate response</h2><span id='topic+gen_resp'></span>

<h3>Description</h3>

<p>Generate random outcome (response) according to a ground-truth logistic model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gen_resp(X, coefs = NA, coefs_sd = 1, retprobs = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gen_resp_+3A_x">X</code></td>
<td>
<p>Matrix of observations</p>
</td></tr>
<tr><td><code id="gen_resp_+3A_coefs">coefs</code></td>
<td>
<p>Vector of coefficients for logistic model. If NA, random coefficients are generated. Defaults to NA</p>
</td></tr>
<tr><td><code id="gen_resp_+3A_coefs_sd">coefs_sd</code></td>
<td>
<p>If random coefficients are generated, use this SD (mean 0)</p>
</td></tr>
<tr><td><code id="gen_resp_+3A_retprobs">retprobs</code></td>
<td>
<p>If TRUE, return class probability; otherwise, return classes. Defaults to FALSE</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Vector of length as first dimension of dim(X) with outcome classes (if retprobs==FALSE) or outcome probabilities (if retprobs==TRUE)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# See examples for model_predict
</code></pre>

<hr>
<h2 id='grad_mincost_powerlaw'>Gradient of minimum cost (power law)</h2><span id='topic+grad_mincost_powerlaw'></span>

<h3>Description</h3>

<p>Compute gradient of minimum cost assuming a power-law form of k2
</p>
<p>Assumes cost function is <code style="white-space: pre;">&#8288;l(n;k1,N,theta) = k1 n + k2(n;theta) (N-n)&#8288;</code> with <code style="white-space: pre;">&#8288;k2(n;theta)=k2(n;a,b,c)= a n^(-b) + c&#8288;</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>grad_mincost_powerlaw(N, k1, theta)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="grad_mincost_powerlaw_+3A_n">N</code></td>
<td>
<p>Total number of samples on which the predictive score will be used/fitted. Can be a vector.</p>
</td></tr>
<tr><td><code id="grad_mincost_powerlaw_+3A_k1">k1</code></td>
<td>
<p>Cost value in the absence of a predictive score. Can be a vector.</p>
</td></tr>
<tr><td><code id="grad_mincost_powerlaw_+3A_theta">theta</code></td>
<td>
<p>Parameters for function k2(n) governing expected cost to an individual sample given a predictive score fitted to n samples. Can be a matrix of dimension n x n_par, where n_par is the number of parameters of k2.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>List/data frame of dimension (number of evaluations) x 5 containing partial derivatives of nstar (optimal holdout size) with respect to N, k1, a, b, c respectively.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Evaluate minimum for a range of values of k1, and compute derivative
N=10000;
k1=seq(0.1,0.5,length=20)
A=3; B=1.5; C=0.15; theta=c(A,B,C)

mincost=optimal_holdout_size(N,k1,theta)
grad_mincost=grad_mincost_powerlaw(N,k1,theta)

plot(0,type="n",ylim=c(0,1560),xlim=range(k1),xlab=expression("k"[1]),
  ylab="Optimal holdout set size")
lines(mincost$k1,mincost$cost,col="black")
lines(mincost$k1,grad_mincost[,2],col="red")
legend(0.2,800,c(expression(paste("l(n"["*"],")")),
                       expression(paste(partialdiff[k1],"l(n"["*"],")"))),
    col=c("black","red"),lty=1,bty="n")

</code></pre>

<hr>
<h2 id='grad_nstar_powerlaw'>Gradient of optimal holdout size (power law)</h2><span id='topic+grad_nstar_powerlaw'></span>

<h3>Description</h3>

<p>Compute gradient of optimal holdout size assuming a power-law form of k2
</p>
<p>Assumes cost function is <code style="white-space: pre;">&#8288;l(n;k1,N,theta) = k1 n + k2(n;theta) (N-n)&#8288;</code> with <code style="white-space: pre;">&#8288;k2(n;theta)=k2(n;a,b,c)= a n^(-b) + c&#8288;</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>grad_nstar_powerlaw(N, k1, theta)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="grad_nstar_powerlaw_+3A_n">N</code></td>
<td>
<p>Total number of samples on which the predictive score will be used/fitted. Can be a vector.</p>
</td></tr>
<tr><td><code id="grad_nstar_powerlaw_+3A_k1">k1</code></td>
<td>
<p>Cost value in the absence of a predictive score. Can be a vector.</p>
</td></tr>
<tr><td><code id="grad_nstar_powerlaw_+3A_theta">theta</code></td>
<td>
<p>Parameters for function k2(n) governing expected cost to an individual sample given a predictive score fitted to n samples. Can be a matrix of dimension n x n_par, where n_par is the number of parameters of k2.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>List/data frame of dimension (number of evaluations) x 5 containing partial derivatives of nstar (optimal holdout size) with respect to N, k1, a, b, c respectively.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Evaluate optimal holdout set size for a range of values of k1, and compute
#  derivative
N=10000;
k1=seq(0.1,0.5,length=20)
A=3; B=1.5; C=0.15; theta=c(A,B,C)

nstar=optimal_holdout_size(N,k1,theta)
grad_nstar=grad_nstar_powerlaw(N,k1,theta)

plot(0,type="n",ylim=c(-2000,500),xlim=range(k1),xlab=expression("k"[1]),
  ylab="Optimal holdout set size")
lines(nstar$k1,nstar$size,col="black")
lines(nstar$k1,grad_nstar[,2],col="red")
legend("bottomright",c(expression("n"["*"]),
    expression(paste(partialdiff[k1],"n"["*"]))),
    col=c("black","red"),lty=1)

</code></pre>

<hr>
<h2 id='logistic'>Logistic</h2><span id='topic+logistic'></span>

<h3>Description</h3>

<p>Logistic function: -log((1/x)-1)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>logistic(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="logistic_+3A_x">x</code></td>
<td>
<p>argument</p>
</td></tr>
</table>


<h3>Value</h3>

<p>value of logit(x); na if x is outside (0,1)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Plot
x=seq(0,1,length=100)
plot(x,logistic(x),type="l")

# Logit and logistic are inverses
x=seq(-5,5,length=1000)
plot(x,logistic(logit(x)),type="l")
</code></pre>

<hr>
<h2 id='logit'>Logit</h2><span id='topic+logit'></span>

<h3>Description</h3>

<p>Logit function: 1/(1+exp(-x))
</p>


<h3>Usage</h3>

<pre><code class='language-R'>logit(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="logit_+3A_x">x</code></td>
<td>
<p>argument</p>
</td></tr>
</table>


<h3>Value</h3>

<p>value of logit(x)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Plot
x=seq(-5,5,length=1000)
plot(x,logit(x),type="l")
</code></pre>

<hr>
<h2 id='model_predict'>Make predictions</h2><span id='topic+model_predict'></span>

<h3>Description</h3>

<p>Make predictions according to a given model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>model_predict(
  data_test,
  trained_model,
  return_type,
  threshold = NULL,
  model_family = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="model_predict_+3A_data_test">data_test</code></td>
<td>
<p>Data for which predictions are to be computed</p>
</td></tr>
<tr><td><code id="model_predict_+3A_trained_model">trained_model</code></td>
<td>
<p>Model for which predictions are to be made</p>
</td></tr>
<tr><td><code id="model_predict_+3A_return_type">return_type</code></td>
<td>
<p>??</p>
</td></tr>
<tr><td><code id="model_predict_+3A_threshold">threshold</code></td>
<td>
<p>??</p>
</td></tr>
<tr><td><code id="model_predict_+3A_model_family">model_family</code></td>
<td>
<p>??</p>
</td></tr>
<tr><td><code id="model_predict_+3A_...">...</code></td>
<td>
<p>Passed to function <code>predict.glm()</code> or <code>predict.ranger()</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>Vector of predictions
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Set seed for reproducibility
seed=1234
set.seed(seed)

# Initialisation of patient data
n_iter &lt;- 500           # Number of point estimates to be calculated
nobs &lt;- 5000            # Number of observations, i.e patients
npreds &lt;- 7             # Number of predictors

# Model family
family="log_reg"

# Baseline behaviour is an oracle Bayes-optimal predictor on only one variable
max_base_powers &lt;- 1
base_vars=1

# Check the following holdout size fractions
frac_ho = 0.1


# Set ground truth coefficients, and the accuracy at baseline
coefs_general &lt;- rnorm(npreds,sd=1/sqrt(npreds))
coefs_base &lt;- gen_base_coefs(coefs_general, max_base_powers = max_base_powers)

# Generate dataset
X &lt;- gen_preds(nobs, npreds)

# Generate labels
newdata &lt;- gen_resp(X, coefs = coefs_general)
Y &lt;- newdata$classes

# Combined dataset
pat_data &lt;- cbind(X, Y)
pat_data$Y = factor(pat_data$Y)

# For each holdout size, split data into intervention and holdout set
mask &lt;- split_data(pat_data, frac_ho)
data_interv &lt;- pat_data[!mask,]
data_hold &lt;- pat_data[mask,]

# Train model
trained_model &lt;- model_train(data_hold, model_family = family)
thresh &lt;- 0.5

# Make predictions
class_pred &lt;- model_predict(data_interv, trained_model,
                            return_type = "class",
                            threshold = 0.5, model_family = family)


# Simulate baseline predictions
base_pred &lt;- oracle_pred(data_hold,coefs_base[base_vars, ], num_vars = base_vars)


# Contingency table for model-based predictor (on intervention set)
print(table(class_pred,data_interv$Y))

# Contingency table for model-based predictor (on holdout set)
print(table(base_pred,data_hold$Y))

</code></pre>

<hr>
<h2 id='model_train'>Train model (wrapper)</h2><span id='topic+model_train'></span>

<h3>Description</h3>

<p>Train model using either a GLM or a random forest
</p>


<h3>Usage</h3>

<pre><code class='language-R'>model_train(train_data, model_family = "log_reg", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="model_train_+3A_train_data">train_data</code></td>
<td>
<p>Data to use for training; assumed to have one binary column called <code>Y</code></p>
</td></tr>
<tr><td><code id="model_train_+3A_model_family">model_family</code></td>
<td>
<p>Either 'log_reg' for logistic regression or 'rand_forest' for random forest</p>
</td></tr>
<tr><td><code id="model_train_+3A_...">...</code></td>
<td>
<p>Passed to function <code>glm()</code> or <code>ranger()</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>Fitted model of type GLM or Ranger
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# See examples for model_predict
</code></pre>

<hr>
<h2 id='mu_fn'>Updating function for mean.</h2><span id='topic+mu_fn'></span>

<h3>Description</h3>

<p>Posterior mean for emulator given points <code>n</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mu_fn(
  n,
  nset,
  k2,
  var_k2,
  N,
  k1,
  var_u = 1e+07,
  k_width = 5000,
  k2form = powerlaw,
  theta = powersolve(nset, k2, y_var = var_k2)$par
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mu_fn_+3A_n">n</code></td>
<td>
<p>Set of training set sizes to evaluate</p>
</td></tr>
<tr><td><code id="mu_fn_+3A_nset">nset</code></td>
<td>
<p>Training set sizes for which k2() has been evaluated</p>
</td></tr>
<tr><td><code id="mu_fn_+3A_k2">k2</code></td>
<td>
<p>Estimated k2() values at training set sizes <code>nset</code></p>
</td></tr>
<tr><td><code id="mu_fn_+3A_var_k2">var_k2</code></td>
<td>
<p>Variance of error in k2() estimate at each training set size.</p>
</td></tr>
<tr><td><code id="mu_fn_+3A_n">N</code></td>
<td>
<p>Total number of samples on which the model will be fitted/used</p>
</td></tr>
<tr><td><code id="mu_fn_+3A_k1">k1</code></td>
<td>
<p>Mean cost per sample with no predictive score in place</p>
</td></tr>
<tr><td><code id="mu_fn_+3A_var_u">var_u</code></td>
<td>
<p>Marginal variance for Gaussian process kernel. Defaults to 1e7</p>
</td></tr>
<tr><td><code id="mu_fn_+3A_k_width">k_width</code></td>
<td>
<p>Kernel width for Gaussian process kernel. Defaults to 5000</p>
</td></tr>
<tr><td><code id="mu_fn_+3A_k2form">k2form</code></td>
<td>
<p>Functional form governing expected cost per sample given sample size. Should take two parameters: n (sample size) and theta (parameters). Defaults to function <code>powerlaw</code>.</p>
</td></tr>
<tr><td><code id="mu_fn_+3A_theta">theta</code></td>
<td>
<p>Current estimates of parameter values for k2form. Defaults to the MLE power-law solution corresponding to n,k2, and var_k2.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Vector Mu of same length of n where Mu_i=mean(posterior(cost(n_i)))
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Suppose we have population size and cost-per-sample without a risk score as follows
N=100000
k1=0.4

# Kernel width and variance for GP
k_width=5000
var_u=8000000

# Suppose we begin with k2() estimates at n-values
nset=c(10000,20000,30000)

# with cost-per-individual estimates
# (note that since empirical k2(n) is non-monotonic, it cannot be perfectly
#  approximated with a power-law function)
k2=c(0.35,0.26,0.28)

# and associated error on those estimates
var_k2=c(0.02^2,0.01^2,0.03^2)

# We estimate theta from these three points
theta=powersolve(nset,k2,y_var=var_k2)$par

# We will estimate the posterior at these values of n
n=seq(1000,50000,length=1000)

# Mean and variance
p_mu=mu_fn(n,nset=nset,k2=k2,var_k2 = var_k2, N=N,k1=k1,theta=theta,
           k_width=k_width,var_u=var_u)
p_var=psi_fn(n,nset=nset,N=N,var_k2 = var_k2,k_width=k_width,var_u=var_u)

# Plot
plot(0,xlim=range(n),ylim=c(20000,60000),type="n",
     xlab="Training/holdout set size",
     ylab="Total cost (= num. cases)")
lines(n,p_mu,col="blue")
lines(n,p_mu - 3*sqrt(p_var),col="red")
lines(n,p_mu + 3*sqrt(p_var),col="red")
points(nset,k1*nset + k2*(N-nset),pch=16,col="purple")
lines(n,k1*n + powerlaw(n,theta)*(N-n),lty=2)
segments(nset,k1*nset + (k2 - 3*sqrt(var_k2))*(N-nset),
         nset,k1*nset + (k2 + 3*sqrt(var_k2))*(N-nset))
legend("topright",
       c(expression(mu(n)),
         expression(mu(n) %+-% 3*sqrt(psi(n))),
         "prior(n)",
         "d",
         "3SD(d|n)"),
       lty=c(1,1,2,NA,NA),lwd=c(1,1,1,NA,NA),pch=c(NA,NA,NA,16,124),
       pt.cex=c(NA,NA,NA,1,1),
       col=c("blue","red","black","purple","black"),bg="white")
</code></pre>

<hr>
<h2 id='next_n'>Finds best value of n to sample next</h2><span id='topic+next_n'></span>

<h3>Description</h3>

<p>Recommends a value of <code>n</code> at which to next evaluate individual cost in order to most accurately estimate optimal holdout size. Currently only for use with a power-law parametrisation of k2.
</p>
<p>Approximately finds a set of n points which, given estimates of cost, minimise width of 95% confidence interval around OHS. Uses a greedy algorithm, so various parameters can be learned along the way.
</p>
<p>Given existing training set size/k2 estimates <code>nset</code> and <code>k2</code>, with <code>var_k2[i]=variance(k2[i])</code>, finds, for each candidate point <code>n[i]</code>, the median width of the 90% confidence interval for OHS if
</p>
<p><code>nset &lt;- c(nset,n[i])</code>
<code>var_k2 &lt;- c(var_k2,mean(var_k2))</code>
<code>k2 &lt;- c(k2,rnorm(powerlaw(n[i],theta),variance=mean(var_k2)))</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>next_n(
  n,
  nset,
  k2,
  N,
  k1,
  nmed = 100,
  var_k2 = rep(1, length(nset)),
  mode = "asymptotic",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="next_n_+3A_n">n</code></td>
<td>
<p>Set of training set sizes to evaluate</p>
</td></tr>
<tr><td><code id="next_n_+3A_nset">nset</code></td>
<td>
<p>Training set sizes for which a loss has been evaluated</p>
</td></tr>
<tr><td><code id="next_n_+3A_k2">k2</code></td>
<td>
<p>Estimated k2() at training set sizes <code>nset</code></p>
</td></tr>
<tr><td><code id="next_n_+3A_n">N</code></td>
<td>
<p>Total number of samples on which the model will be fitted/used</p>
</td></tr>
<tr><td><code id="next_n_+3A_k1">k1</code></td>
<td>
<p>Mean loss per sample with no predictive score in place</p>
</td></tr>
<tr><td><code id="next_n_+3A_nmed">nmed</code></td>
<td>
<p>number of times to re-evaluate d and confidence interval width.</p>
</td></tr>
<tr><td><code id="next_n_+3A_var_k2">var_k2</code></td>
<td>
<p>Variance of error in k2() estimate at each training set size.</p>
</td></tr>
<tr><td><code id="next_n_+3A_mode">mode</code></td>
<td>
<p>Mode for calculating OHS CI (passed to <code>ci_ohs</code>): 'asymptotic' or 'empirical'</p>
</td></tr>
<tr><td><code id="next_n_+3A_...">...</code></td>
<td>
<p>Passed to <code>powersolve</code> and <code>powersolve_se</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>Vector <code>out</code> of same length as <code>n</code>, where <code>out[i]</code> is the expected width of the 95% confidence interval for OHS should <code>n</code> be added to <code>nset</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Set seed.
set.seed(24015)

# Kernel width and Gaussian process variance
kw0=5000
vu0=1e7

# Include legend on plots or not; inclusion can obscure plot elements on small figures
inc_legend=FALSE

# Suppose we have population size and cost-per-sample without a risk score as follows
N=100000
k1=0.4

# Suppose that true values of a,b,c are given by
theta_true=c(10000,1.2,0.2)
theta_lower=c(1,0.5,0.1) # lower bounds for estimating theta
theta_upper=c(20000,2,0.5) # upper bounds for estimating theta



# We start with five random holdout set sizes (nset0),
#  with corresponding cost-per-individual estimates k2_0 derived
#  with various errors var_k2_0
nstart=10
vwmin=0.001; vwmax=0.005
nset0=round(runif(nstart,1000,N/2))
var_k2_0=runif(nstart,vwmin,vwmax)
k2_0=rnorm(nstart,mean=powerlaw(nset0,theta_true),sd=sqrt(var_k2_0))

# We estimate theta from these three points
theta0=powersolve(nset0,k2_0,y_var=var_k2_0,lower=theta_lower,upper=theta_upper,init=theta_true)$par

# We will estimate the posterior at these values of n
n=seq(1000,N,length=1000)

# Mean and variance
p_mu=mu_fn(n,nset=nset0,k2=k2_0,var_k2 = var_k2_0, N=N,k1=k1,theta=theta0,k_width=kw0,var_u=vu0)
p_var=psi_fn(n,nset=nset0,N=N,var_k2 = var_k2_0,k_width=kw0,var_u=vu0)

# Plot
yrange=c(-30000,100000)
plot(0,xlim=range(n),ylim=yrange,type="n",
  xlab="Training/holdout set size",
  ylab="Total cost (= num. cases)")
lines(n,p_mu,col="blue")
lines(n,p_mu - 3*sqrt(p_var),col="red")
lines(n,p_mu + 3*sqrt(p_var),col="red")
points(nset0,k1*nset0 + k2_0*(N-nset0),pch=16,col="purple")
lines(n,k1*n + powerlaw(n,theta0)*(N-n),lty=2)
lines(n,k1*n + powerlaw(n,theta_true)*(N-n),lty=3,lwd=3)
if (inc_legend) {
  legend("topright",
    c(expression(mu(n)),
      expression(mu(n) %+-% 3*sqrt(psi(n))),
      "prior(n)",
      "True",
      "d"),
    lty=c(1,1,2,3,NA),lwd=c(1,1,1,3,NA),pch=c(NA,NA,NA,NA,16),pt.cex=c(NA,NA,NA,NA,1),
    col=c("blue","red","black","purple"),bg="white")
}

## Add line corresponding to recommended new point. This is slow.
nn=seq(1000,N,length=20)
exp_imp &lt;- next_n(nn,nset=nset0,k2=k2_0,var_k2 = var_k2_0, N=N,k1=k1,nmed=10,
                     lower=theta_lower,upper=theta_upper)
abline(v=nn[which.min(exp_imp)])


</code></pre>

<hr>
<h2 id='ohs_array'>Data for vignette on algorithm comparison</h2><span id='topic+ohs_array'></span>

<h3>Description</h3>

<p>This object contains data relating to the vignette comparing emulation and parametric algorithms. For generation, see hidden code in vignette, or in pipeline at https://github.com/jamesliley/OptHoldoutSize_pipelines
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ohs_array
</code></pre>


<h3>Format</h3>

<p>An object of class <code>array</code> of dimension 200 x 200 x 2 x 2 x 2.
</p>

<hr>
<h2 id='ohs_resample'>Data for vignette on algorithm comparison</h2><span id='topic+ohs_resample'></span>

<h3>Description</h3>

<p>This object contains data relating to the first plot in the vignette comparing emulation and parametric algorithms. For generation, see hidden code in vignette, or in pipeline at https://github.com/jamesliley/OptHoldoutSize_pipelines
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ohs_resample
</code></pre>


<h3>Format</h3>

<p>An object of class <code>matrix</code> (inherits from <code>array</code>) with 1000 rows and 4 columns.
</p>

<hr>
<h2 id='optimal_holdout_size'>Estimate optimal holdout size under parametric assumptions</h2><span id='topic+optimal_holdout_size'></span>

<h3>Description</h3>

<p>Compute optimal holdout size for updating a predictive score given appropriate parameters of cost function
</p>
<p>Evaluates empirical minimisation of cost function <code style="white-space: pre;">&#8288;l(n;k1,N,theta) = k1 n + k2form(n;theta) (N-n)&#8288;</code>.
</p>
<p>The function will return <code>Inf</code> if no minimum exists. It does not check if the minimum is unique, but this can be guaranteed using the assumptions for theorem 1 in the manuscript.
</p>
<p>This calls the function <code>optimize</code> from package <code>stats</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>optimal_holdout_size(
  N,
  k1,
  theta,
  k2form = powerlaw,
  round_result = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="optimal_holdout_size_+3A_n">N</code></td>
<td>
<p>Total number of samples on which the predictive score will be used/fitted. Can be a vector.</p>
</td></tr>
<tr><td><code id="optimal_holdout_size_+3A_k1">k1</code></td>
<td>
<p>Cost value in the absence of a predictive score. Can be a vector.</p>
</td></tr>
<tr><td><code id="optimal_holdout_size_+3A_theta">theta</code></td>
<td>
<p>Parameters for function k2form(n) governing expected cost to an individual sample given a predictive score fitted to n samples. Can be a matrix of dimension n x n_par, where n_par is the number of parameters of k2.</p>
</td></tr>
<tr><td><code id="optimal_holdout_size_+3A_k2form">k2form</code></td>
<td>
<p>Function governing expected cost to an individual sample given a predictive score fitted to n samples. Must take two arguments: n (number of samples) and theta (parameters). Defaults to a power-law form <code style="white-space: pre;">&#8288;powerlaw(n,c(a,b,c))=a n^(-b) + c&#8288;</code>.</p>
</td></tr>
<tr><td><code id="optimal_holdout_size_+3A_round_result">round_result</code></td>
<td>
<p>Set to TRUE to solve over integral sizes</p>
</td></tr>
<tr><td><code id="optimal_holdout_size_+3A_...">...</code></td>
<td>
<p>Passed to function <code>optimize</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>List/data frame of dimension (number of evaluations) x (4 + n_par) containing input data and results. Columns <code>size</code> and <code>cost</code> are optimal holdout size and cost at this size respectively. Parameters N, k1, theta.1, theta.2,...,theta.n_par are input data.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Evaluate optimal holdout set size for a range of values of k1 and two values of
#   N, some of which lead to infinite values
N1=10000; N2=12000
k1=seq(0.1,0.5,length=20)
A=3; B=1.5; C=0.15; theta=c(A,B,C)

res1=optimal_holdout_size(N1,k1,theta)
res2=optimal_holdout_size(N2,k1,theta)

oldpar=par(mfrow=c(1,2))
plot(0,type="n",ylim=c(0,500),xlim=range(res1$k1),xlab=expression("k"[1]),
  ylab="Optimal holdout set size")
  lines(res1$k1,res1$size,col="black")
  lines(res2$k1,res2$size,col="red")
  legend("topright",as.character(c(N1,N2)),title="N:",col=c("black","red"),lty=1)
plot(0,type="n",ylim=c(1500,1600),xlim=range(res1$k1),xlab=expression("k"[1]),
  ylab="Minimum cost")
  lines(res1$k1,res1$cost,col="black")
  lines(res2$k1,res2$cost,col="red")
  legend("topleft",as.character(c(N1,N2)),title="N:",col=c("black","red"),lty=1)

par(oldpar)
</code></pre>

<hr>
<h2 id='optimal_holdout_size_emulation'>Estimate optimal holdout size under semi-parametric assumptions</h2><span id='topic+optimal_holdout_size_emulation'></span>

<h3>Description</h3>

<p>Compute optimal holdout size for updating a predictive score given a set of training set sizes and estimates of mean cost per sample at those training set sizes.
</p>
<p>This is essentially a wrapper for function <code>mu_fn()</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>optimal_holdout_size_emulation(
  nset,
  k2,
  var_k2,
  N,
  k1,
  var_u = 1e+07,
  k_width = 5000,
  k2form = powerlaw,
  theta = powersolve_general(nset, k2, y_var = var_k2)$par,
  npoll = 1000,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="optimal_holdout_size_emulation_+3A_nset">nset</code></td>
<td>
<p>Training set sizes for which a cost has been evaluated</p>
</td></tr>
<tr><td><code id="optimal_holdout_size_emulation_+3A_k2">k2</code></td>
<td>
<p>Estimated values of k2() at training set sizes <code>nset</code></p>
</td></tr>
<tr><td><code id="optimal_holdout_size_emulation_+3A_var_k2">var_k2</code></td>
<td>
<p>Variance of error in k2 estimate at each training set size.</p>
</td></tr>
<tr><td><code id="optimal_holdout_size_emulation_+3A_n">N</code></td>
<td>
<p>Total number of samples on which the model will be fitted/used</p>
</td></tr>
<tr><td><code id="optimal_holdout_size_emulation_+3A_k1">k1</code></td>
<td>
<p>Mean cost per sample with no predictive score in place</p>
</td></tr>
<tr><td><code id="optimal_holdout_size_emulation_+3A_var_u">var_u</code></td>
<td>
<p>Marginal variance for Gaussian process kernel. Defaults to 1e7</p>
</td></tr>
<tr><td><code id="optimal_holdout_size_emulation_+3A_k_width">k_width</code></td>
<td>
<p>Kernel width for Gaussian process kernel. Defaults to 5000</p>
</td></tr>
<tr><td><code id="optimal_holdout_size_emulation_+3A_k2form">k2form</code></td>
<td>
<p>Functional form governing expected cost per sample given sample size. Should take two parameters: n (sample size) and theta (parameters). Defaults to function <code>powerlaw</code>.</p>
</td></tr>
<tr><td><code id="optimal_holdout_size_emulation_+3A_theta">theta</code></td>
<td>
<p>Current estimates of parameter values for k2form. Defaults to the MLE power-law solution corresponding to n,k2, and var_k2.</p>
</td></tr>
<tr><td><code id="optimal_holdout_size_emulation_+3A_npoll">npoll</code></td>
<td>
<p>Check npoll equally spaced values between 1 and N for minimum. If NULL, check all values (this can be slow). Defaults to 1000</p>
</td></tr>
<tr><td><code id="optimal_holdout_size_emulation_+3A_...">...</code></td>
<td>
<p>Passed to function <code>optimise()</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>Object of class 'optholdoutsize_emul' with elements &quot;cost&quot; (minimum cost),&quot;size&quot; (OHS),&quot;nset&quot;,&quot;k2&quot;,&quot;var_k2&quot;,&quot;N&quot;,&quot;k1&quot;,&quot;var_u&quot;,&quot;k_width&quot;,&quot;theta&quot; (parameters)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# See examples for mu_fn()
</code></pre>

<hr>
<h2 id='oracle_pred'>Generate responses</h2><span id='topic+oracle_pred'></span>

<h3>Description</h3>

<p>Probably for deprecation
</p>


<h3>Usage</h3>

<pre><code class='language-R'>oracle_pred(X, coefs, num_vars = 3, noise = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="oracle_pred_+3A_x">X</code></td>
<td>
<p>Matrix of observations</p>
</td></tr>
<tr><td><code id="oracle_pred_+3A_coefs">coefs</code></td>
<td>
<p>Vector of coefficients for logistic model.</p>
</td></tr>
<tr><td><code id="oracle_pred_+3A_num_vars">num_vars</code></td>
<td>
<p>If noise==FALSE, computes using only first num_vars predictors</p>
</td></tr>
<tr><td><code id="oracle_pred_+3A_noise">noise</code></td>
<td>
<p>If TRUE, uses all predictors</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Vector of predictions
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# See examples for model_predict
</code></pre>

<hr>
<h2 id='params_aspre'>Parameters of reported ASPRE dataset</h2><span id='topic+params_aspre'></span>

<h3>Description</h3>

<p>Distribution of covariates for ASPRE dataset; see Rolnik, 2017, NEJM
</p>


<h3>Usage</h3>

<pre><code class='language-R'>params_aspre
</code></pre>


<h3>Format</h3>

<p>An object of class <code>list</code> of length 16.
</p>

<hr>
<h2 id='plot.optholdoutsize'>Plot estimated cost function</h2><span id='topic+plot.optholdoutsize'></span>

<h3>Description</h3>

<p>Plot estimated cost function, when parametric method is used for estimation.
</p>
<p>Draws cost function as a line and indicates minimum. Assumes a power-law form of k2 unless parameter k2 is set otherwise.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'optholdoutsize'
plot(x, ..., k2form = powerlaw)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.optholdoutsize_+3A_x">x</code></td>
<td>
<p>Object of type <code>optholdoutsize</code></p>
</td></tr>
<tr><td><code id="plot.optholdoutsize_+3A_...">...</code></td>
<td>
<p>Other arguments passed to <code>plot()</code> and <code>lines()</code></p>
</td></tr>
<tr><td><code id="plot.optholdoutsize_+3A_k2form">k2form</code></td>
<td>
<p>Function governing expected cost to an individual sample given a predictive score fitted to n samples. Must take two arguments: n (number of samples) and theta (parameters). Defaults to a power-law form <code style="white-space: pre;">&#8288;powerlaw(n,c(a,b,c))=a n^(-b) + c&#8288;</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>No return value; draws a plot only.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Simple example

N=100000;
k1=0.3
A=8000; B=1.5; C=0.15; theta=c(A,B,C)

res1=optimal_holdout_size(N,k1,theta)

plot(res1)

</code></pre>

<hr>
<h2 id='plot.optholdoutsize_emul'>Plot estimated cost function using emulation (semiparametric)</h2><span id='topic+plot.optholdoutsize_emul'></span>

<h3>Description</h3>

<p>Plot estimated cost function, when semiparametric (emulation) method is used for estimation.
</p>
<p>Draws posterior mean of cost function as a line and indicates minimum. Also draws mean +/- 3 SE.
</p>
<p>Assumes a power-law form of k2 unless parameter k2 is set otherwise.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'optholdoutsize_emul'
plot(x, ..., k2form = powerlaw)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.optholdoutsize_emul_+3A_x">x</code></td>
<td>
<p>Object of type <code>optholdoutsize_emul</code></p>
</td></tr>
<tr><td><code id="plot.optholdoutsize_emul_+3A_...">...</code></td>
<td>
<p>Other arguments passed to <code>plot()</code></p>
</td></tr>
<tr><td><code id="plot.optholdoutsize_emul_+3A_k2form">k2form</code></td>
<td>
<p>Function governing expected cost to an individual sample given a predictive score fitted to n samples. Must take two arguments: n (number of samples) and theta (parameters). Defaults to a power-law form <code style="white-space: pre;">&#8288;powerlaw(n,c(a,b,c))=a n^(-b) + c&#8288;</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>No return value; draws a plot only.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Simple example

# Parameters
N=100000;
k1=0.3
A=8000; B=1.5; C=0.15; theta=c(A,B,C)

# True mean function
k2_true=function(n) powerlaw(n,theta)

# Values of n for which cost has been estimated
np=50 # this many points
nset=round(runif(np,1,N))
var_k2=runif(np,0.001,0.002)
k2=rnorm(np,mean=k2_true(nset),sd=sqrt(var_k2))

# Compute OHS
res1=optimal_holdout_size_emulation(nset,k2,var_k2,N,k1)

# Plot
plot(res1)
</code></pre>

<hr>
<h2 id='powerlaw'>Power law function</h2><span id='topic+powerlaw'></span>

<h3>Description</h3>

<p>Power law function for modelling learning curve (taken to mean change in expected loss per sample with training set size)
</p>
<p>Recommended in <a href="https://arxiv.org/abs/2103.10948">review of learning curve forms</a>
</p>
<p>If <code>theta=c(a,b,c)</code> then models as <code style="white-space: pre;">&#8288;a n^(-b) + c&#8288;</code>. Note <code>b</code> is negated.
</p>
<p>Note that <code>powerlaw(n,c(a,b,c))</code> has limit <code>c</code> as <code>n</code> tends to infinity, if <code style="white-space: pre;">&#8288;a,b &gt; 0&#8288;</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>powerlaw(n, theta)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="powerlaw_+3A_n">n</code></td>
<td>
<p>Set of training set sizes to evaluate</p>
</td></tr>
<tr><td><code id="powerlaw_+3A_theta">theta</code></td>
<td>
<p>Parameter of values</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Vector of values of same length as <code>n</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
ncheck=seq(1000,10000)
plot(ncheck, powerlaw(ncheck, c(5e3,1.2,0.3)),type="l",xlab="n",ylab="powerlaw(n)")

</code></pre>

<hr>
<h2 id='powersolve'>Fit power law curve</h2><span id='topic+powersolve'></span>

<h3>Description</h3>

<p>Find least-squares solution: MLE of (a,b,c) under model
<code style="white-space: pre;">&#8288;y_i = a x_i^-b + c + e_i&#8288;</code>;
<code>e_i~N(0,y_var_i)</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>powersolve(
  x,
  y,
  init = c(20000, 2, 0.1),
  y_var = rep(1, length(y)),
  estimate_s = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="powersolve_+3A_x">x</code></td>
<td>
<p>X values</p>
</td></tr>
<tr><td><code id="powersolve_+3A_y">y</code></td>
<td>
<p>Y values</p>
</td></tr>
<tr><td><code id="powersolve_+3A_init">init</code></td>
<td>
<p>Initial values of (a,b,c) to start. Default c(20000,2,0.1)</p>
</td></tr>
<tr><td><code id="powersolve_+3A_y_var">y_var</code></td>
<td>
<p>Optional parameter giving sampling variance of each y value. Defaults to 1.</p>
</td></tr>
<tr><td><code id="powersolve_+3A_estimate_s">estimate_s</code></td>
<td>
<p>Parameter specifying whether to also estimate s (as above). Defaults to FALSE (no).</p>
</td></tr>
<tr><td><code id="powersolve_+3A_...">...</code></td>
<td>
<p>further parameters passed to optim. We suggest specifying lower and upper bounds for (a,b,c); e.g. lower=c(1,0,0),upper=c(10000,3,1)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>List (output from <code>optim</code>) containing MLE values of (a,b,c)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Retrieval of original values
A_true=2000; B_true=1.5; C_true=0.3; sigma=0.002

X=1000*abs(rnorm(10000,mean=4))
Y=A_true*(X^(-B_true)) + C_true + rnorm(length(X),sd=sigma)

c(A_true,B_true,C_true)
powersolve(X[1:10],Y[1:10])$par
powersolve(X[1:100],Y[1:100])$par
powersolve(X[1:1000],Y[1:1000])$par
powersolve(X[1:10000],Y[1:10000])$par
</code></pre>

<hr>
<h2 id='powersolve_general'>General solver for power law curve</h2><span id='topic+powersolve_general'></span>

<h3>Description</h3>

<p>Find least-squares solution: MLE of (a,b,c) under model
<code style="white-space: pre;">&#8288;y_i = a x_i^-b + c + e_i&#8288;</code>;
<code>e_i~N(0,y_var_i)</code>
</p>
<p>Try a range of starting values and refine estimate.
</p>
<p>Slower than a single call to <code>powersolve()</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>powersolve_general(x, y, y_var = rep(1, length(x)), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="powersolve_general_+3A_x">x</code></td>
<td>
<p>X values</p>
</td></tr>
<tr><td><code id="powersolve_general_+3A_y">y</code></td>
<td>
<p>Y values</p>
</td></tr>
<tr><td><code id="powersolve_general_+3A_y_var">y_var</code></td>
<td>
<p>Optional parameter giving sampling variance of each y value. Defaults to 1.</p>
</td></tr>
<tr><td><code id="powersolve_general_+3A_...">...</code></td>
<td>
<p>further parameters passed to optim. We suggest specifying lower and upper bounds for (a,b,c); e.g. lower=c(1,0,0),upper=c(10000,3,1)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>List (output from <code>optim</code>) containing MLE values of (a,b,c)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Retrieval of original values
A_true=2000; B_true=1.5; C_true=0.3; sigma=0.002

X=1000*abs(rnorm(10000,mean=4))
Y=A_true*(X^(-B_true)) + C_true + rnorm(length(X),sd=sigma)

c(A_true,B_true,C_true)
powersolve_general(X[1:10],Y[1:10])$par
powersolve_general(X[1:100],Y[1:100])$par
powersolve_general(X[1:1000],Y[1:1000])$par
</code></pre>

<hr>
<h2 id='powersolve_se'>Standard error matrix for learning curve parameters (power law)</h2><span id='topic+powersolve_se'></span>

<h3>Description</h3>

<p>Find approximate standard error matrix for <code style="white-space: pre;">&#8288;(a,b,c)&#8288;</code> under power law model for learning curve.
</p>
<p>Assumes that
</p>
<p><code style="white-space: pre;">&#8288;y_i= a x_i^-b + c + e, e~N(0,s^2 y_var_i^2)&#8288;</code>
</p>
<p>Standard error can be computed either asymptotically using Fisher information (<code>method='fisher'</code>) or boostrapped (<code>method='bootstrap'</code>)
</p>
<p>These estimate different quantities: the asymptotic method estimates
</p>
<p><code>Var[MLE(a,b,c)|X,y_var]</code>
</p>
<p>and the boostrap method estimates
</p>
<p><code>Var[MLE(a,b,c)]</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>powersolve_se(
  x,
  y,
  method = "fisher",
  init = c(20000, 2, 0.1),
  y_var = rep(1, length(y)),
  n_boot = 1000,
  seed = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="powersolve_se_+3A_x">x</code></td>
<td>
<p>X values (typically training set sizes)</p>
</td></tr>
<tr><td><code id="powersolve_se_+3A_y">y</code></td>
<td>
<p>Y values (typically observed cost per individual/sample)</p>
</td></tr>
<tr><td><code id="powersolve_se_+3A_method">method</code></td>
<td>
<p>One of 'fisher' (for asymptotic variance via Fisher Information) or 'bootstrap' (for Bootstrap)</p>
</td></tr>
<tr><td><code id="powersolve_se_+3A_init">init</code></td>
<td>
<p>Initial values of (a,b,c) to start when computing MLE. Default c(20000,2,0.1)</p>
</td></tr>
<tr><td><code id="powersolve_se_+3A_y_var">y_var</code></td>
<td>
<p>Optional parameter giving sampling variance of each y value. Defaults to 1.</p>
</td></tr>
<tr><td><code id="powersolve_se_+3A_n_boot">n_boot</code></td>
<td>
<p>Number of bootstrap resamples. Only used if method='bootstrap'. Defaults to 1000</p>
</td></tr>
<tr><td><code id="powersolve_se_+3A_seed">seed</code></td>
<td>
<p>Random seed for bootstrap resamples. Defaults to NULL.</p>
</td></tr>
<tr><td><code id="powersolve_se_+3A_...">...</code></td>
<td>
<p>further parameters passed to optim. We suggest specifying lower and upper bounds; since optim is called on (a*1000^-b,b,c), bounds should be relative to this; for instance, lower=c(0,0,0),upper=c(100,3,1)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Standard error matrix; approximate covariance matrix of MLE(a,b,c)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
A_true=10; B_true=1.5; C_true=0.3; sigma=0.1

set.seed(31525)

X=1+3*rchisq(10000,df=5)
Y=A_true*(X^(-B_true)) + C_true + rnorm(length(X),sd=sigma)

# 'Observations' - 100 samples
obs=sample(length(X),100,rep=FALSE)
Xobs=X[obs]; Yobs=Y[obs]

# True covariance matrix of MLE of a,b,c on these x values
ntest=100
abc_mat_xfix=matrix(0,ntest,3)
abc_mat_xvar=matrix(0,ntest,3)
E1=A_true*(Xobs^(-B_true)) + C_true
for (i in 1:ntest) {
  Y1=E1 + rnorm(length(Xobs),sd=sigma)
  abc_mat_xfix[i,]=powersolve(Xobs,Y1)$par # Estimate (a,b,c) with same X

  X2=1+3*rchisq(length(Xobs),df=5)
  Y2=A_true*(X2^(-B_true)) + C_true + rnorm(length(Xobs),sd=sigma)
  abc_mat_xvar[i,]=powersolve(X2,Y2)$par # Estimate (a,b,c) with variable X
}

Ve1=var(abc_mat_xfix) # empirical variance of MLE(a,b,c)|X
Vf=powersolve_se(Xobs,Yobs,method='fisher') # estimated SE matrix, asymptotic

Ve2=var(abc_mat_xvar) # empirical variance of MLE(a,b,c)
Vb=powersolve_se(Xobs,Yobs,method='bootstrap',n_boot=200) # estimated SE matrix, bootstrap

cat("Empirical variance of MLE(a,b,c)|X\n")
print(Ve1)
cat("\n")
cat("Asymptotic variance of MLE(a,b,c)|X\n")
print(Vf)
cat("\n\n")
cat("Empirical variance of MLE(a,b,c)\n")
print(Ve2)
cat("\n")
cat("Bootstrap-estimated variance of MLE(a,b,c)\n")
print(Vb)
cat("\n\n")

</code></pre>

<hr>
<h2 id='psi_fn'>Updating function for variance.</h2><span id='topic+psi_fn'></span>

<h3>Description</h3>

<p>Posterior variance for emulator given points <code>n</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>psi_fn(n, nset, var_k2, N, var_u = 1e+07, k_width = 5000)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="psi_fn_+3A_n">n</code></td>
<td>
<p>Set of training set sizes to evaluate at</p>
</td></tr>
<tr><td><code id="psi_fn_+3A_nset">nset</code></td>
<td>
<p>Training set sizes for which k2() has been evaluated</p>
</td></tr>
<tr><td><code id="psi_fn_+3A_var_k2">var_k2</code></td>
<td>
<p>Variance of error in k2() estimate at each training set size.</p>
</td></tr>
<tr><td><code id="psi_fn_+3A_n">N</code></td>
<td>
<p>Total number of samples on which the model will be fitted/used. Only used to rescale var_k2</p>
</td></tr>
<tr><td><code id="psi_fn_+3A_var_u">var_u</code></td>
<td>
<p>Marginal variance for Gaussian process kernel. Defaults to 1e7</p>
</td></tr>
<tr><td><code id="psi_fn_+3A_k_width">k_width</code></td>
<td>
<p>Kernel width for Gaussian process kernel. Defaults to 5000</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Vector Psi of same length of n where Psi_i=var(posterior(cost(n_i)))
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# See examples for `mu_fn`

</code></pre>

<hr>
<h2 id='sens10'>Sensitivity at theshold quantile 10%</h2><span id='topic+sens10'></span>

<h3>Description</h3>

<p>Computes sensitivity of a risk score at a threshold at which 10% of samples (or some proportion pi_int) are above the threshold.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sens10(Y, Ypred, pi_int = 0.1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sens10_+3A_y">Y</code></td>
<td>
<p>True labels (1 or 0)</p>
</td></tr>
<tr><td><code id="sens10_+3A_ypred">Ypred</code></td>
<td>
<p>Predictions (univariate; real numbers)</p>
</td></tr>
<tr><td><code id="sens10_+3A_pi_int">pi_int</code></td>
<td>
<p>Compute sensitivity when a proportion pi_int of samples exceed threshold, default 0.1</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Sensitivity at this threshold
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Simulate
set.seed(32142)

N=1000
X=rnorm(N); Y=rbinom(N,1,prob=logit(X/2))

pi_int=0.1
q10=quantile(X,1-pi_int) # 10% of X values are above this threshold

print(length(which(Y==1 &amp; X&gt;q10))/length(which(X&gt;q10)))
print(sens10(Y,X,pi_int))

</code></pre>

<hr>
<h2 id='sim_random_aspre'>Simulate random dataset similar to ASPRE training data</h2><span id='topic+sim_random_aspre'></span>

<h3>Description</h3>

<p>Generate random population of individuals (e.g., newly pregnant women) with given population parameters
</p>
<p>Assumes independence of parameter variation. This is not a realistic assumption, but is satisfactory for our purposes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sim_random_aspre(n, params = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sim_random_aspre_+3A_n">n</code></td>
<td>
<p>size of population</p>
</td></tr>
<tr><td><code id="sim_random_aspre_+3A_params">params</code></td>
<td>
<p>list of parameters</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Matrix of samples
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Load ASPRE related data
data(params_aspre)

X=sim_random_aspre(1000,params_aspre)

print(c(median(X$age),params_aspre$age$median))

print(rbind(table(X$parity)/1000,params_aspre$parity$freq))

</code></pre>

<hr>
<h2 id='split_data'>Split data</h2><span id='topic+split_data'></span>

<h3>Description</h3>

<p>Split data into holdout and intervention sets
</p>


<h3>Usage</h3>

<pre><code class='language-R'>split_data(X, frac)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="split_data_+3A_x">X</code></td>
<td>
<p>Matrix of observations</p>
</td></tr>
<tr><td><code id="split_data_+3A_frac">frac</code></td>
<td>
<p>Fraction of observations to use for the training set</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Vector of TRUE/FALSE values (randomised) with proportion <code>frac</code> as TRUE
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# See examples for model_predict
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
