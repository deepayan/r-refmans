<!DOCTYPE html><html><head><title>Help for package steprf</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {steprf}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#cran-comments'>
<p>Note on notes</p></a></li>
<li><a href='#RFcv2'><p>Cross validation, n-fold for random forest (RF)</p></a></li>
<li><a href='#steprf'><p>Select predictive variables for random forest by  various variable importance methods and predictive accuracy</p>
in a stepwise algorithm</a></li>
<li><a href='#steprfAVI'><p>Select predictive variables for random forest by AVI and accuracy</p>
in a stepwise algorithm</a></li>
<li><a href='#steprfAVI1'><p>Select predictive variables for random forest by avi and accuracy</p>
in a stepwise algorithm</a></li>
<li><a href='#steprfAVI2'><p>Select predictive variables for random forest by AVI and accuracy</p>
in a stepwise algorithm</a></li>
<li><a href='#steprfAVIPredictors'><p>Extract names of the selected predictive variables by steprf</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Title:</td>
<td>Stepwise Predictive Variable Selection for Random Forest</td>
</tr>
<tr>
<td>Version:</td>
<td>1.0.2</td>
</tr>
<tr>
<td>Date:</td>
<td>2022-6-28</td>
</tr>
<tr>
<td>Description:</td>
<td>An introduction to several novel predictive variable selection methods for random forest. They are based on various variable importance methods (i.e., averaged variable importance (AVI), and knowledge informed AVI (i.e., KIAVI, and KIAVI2)) and predictive accuracy in stepwise algorithms. For details of the variable selection methods, please see: Li, J., Siwabessy, J., Huang, Z. and Nichol, S. (2019) &lt;<a href="https://doi.org/10.3390%2Fgeosciences9040180">doi:10.3390/geosciences9040180</a>&gt;. Li, J., Alvarez, B., Siwabessy, J., Tran, M., Huang, Z., Przeslawski, R., Radke, L., Howard, F., Nichol, S. (2017). &lt;<a href="https://doi.org/10.13140%2FRG.2.2.27686.22085">doi:10.13140/RG.2.2.27686.22085</a>&gt;.</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 4.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>spm, randomForest, spm2, psy</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.1</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, rmarkdown, lattice, reshape2</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2022-06-28 06:37:55 UTC; Jin</td>
</tr>
<tr>
<td>Author:</td>
<td>Jin Li [aut, cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Jin Li &lt;jinli68@gmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2022-06-29 11:20:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='cran-comments'>
Note on notes
</h2><span id='topic+cran-comments'></span>

<h3>Description</h3>

<p>This is an updated and extended version of &lsquo;spm' package. The change in package name from 'spm' to 'spm2' is due to the change in Author&rsquo;s support from Geoscience Australia to Data2Action Australia.
</p>
<p>## R CMD check results
0 errors | 0 warnings | 0 notes
</p>


<h3>Author(s)</h3>

<p>Jin Li
</p>

<hr>
<h2 id='RFcv2'>Cross validation, n-fold for random forest (RF)</h2><span id='topic+RFcv2'></span>

<h3>Description</h3>

<p>This function is a cross validation function
for random forest. It is for functions 'steprf', 'steprfAVI', ect.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RFcv2(
  trainx,
  trainy,
  cv.fold = 10,
  mtry = if (!is.null(trainy) &amp;&amp; !is.factor(trainy)) max(floor(ncol(trainx)/3), 1) else
    floor(sqrt(ncol(trainx))),
  ntree = 500,
  predacc = "VEcv",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="RFcv2_+3A_trainx">trainx</code></td>
<td>
<p>a dataframe or matrix contains columns of predictor variables.</p>
</td></tr>
<tr><td><code id="RFcv2_+3A_trainy">trainy</code></td>
<td>
<p>a vector of response, must have length equal to the number of
rows in trainx.</p>
</td></tr>
<tr><td><code id="RFcv2_+3A_cv.fold">cv.fold</code></td>
<td>
<p>integer; number of folds in the cross-validation. if &gt; 1,
then apply n-fold cross validation; the default is 10, i.e., 10-fold cross
validation that is recommended.</p>
</td></tr>
<tr><td><code id="RFcv2_+3A_mtry">mtry</code></td>
<td>
<p>a function of number of remaining predictor variables to use as
the mtry parameter in the randomForest call.</p>
</td></tr>
<tr><td><code id="RFcv2_+3A_ntree">ntree</code></td>
<td>
<p>number of trees to grow. This should not be set to too small a
number, to ensure that every input row gets predicted at least a few times.
By default, 500 is used.</p>
</td></tr>
<tr><td><code id="RFcv2_+3A_predacc">predacc</code></td>
<td>
<p>&quot;VEcv&quot; for vecv for numerical data, or &quot;ccr&quot; (i.e., correct
classification rate) or &quot;kappa&quot; for categorical data.</p>
</td></tr>
<tr><td><code id="RFcv2_+3A_...">...</code></td>
<td>
<p>other arguments passed on to randomForest.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with the following component:
vecv for numerical data: ; or
ccr (correct classification rate) for categorical data: .
</p>


<h3>Note</h3>

<p>This function is largely based on rf.cv (see Li et al. 2013) and
rfcv in randomForest.
</p>


<h3>Author(s)</h3>

<p>Jin Li
</p>


<h3>References</h3>

<p>Li, J., J. Siwabessy, M. Tran, Z. Huang, and A. Heap. 2013.
Predicting Seabed Hardness Using Random Forest in R. Pages 299-329 in Y.
Zhao and Y. Cen, editors. Data Mining Applications with R. Elsevier.
</p>
<p>Li, J. 2013. Predicting the spatial distribution of seabed gravel content
using random forest, spatial interpolation methods and their hybrid methods.
Pages 394-400  The International Congress on Modelling and Simulation
(MODSIM) 2013, Adelaide.
</p>
<p>Liaw, A. and M. Wiener (2002). Classification and Regression by
randomForest. R News 2(3), 18-22.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(spm)
data(hard)
data(petrel)

rfcv1 &lt;- RFcv2(petrel[, c(1,2, 6:9)], petrel[, 5], predacc = "VEcv")
rfcv1

rfcv2 &lt;- RFcv2(hard[, -c(1, 17)], hard[, 17], predacc = "ccr")
rfcv2

rfcv3 &lt;- RFcv2(hard[, -c(1, 17)], hard[, 17], predacc = "kappa")
rfcv3

n &lt;- 10 # number of iterations, 60 to 100 is recommended.
VEcv &lt;- NULL
for (i in 1:n) {
rfcv1 &lt;- RFcv2(petrel[, c(1,2,6:9)], petrel[, 5], predacc = "VEcv")
VEcv [i] &lt;- rfcv1
}
plot(VEcv ~ c(1:n), xlab = "Iteration for RF", ylab = "VEcv (%)")
points(cumsum(VEcv) / c(1:n) ~ c(1:n), col = 2)
abline(h = mean(VEcv), col = 'blue', lwd = 2)

n &lt;- 10 # number of iterations, 60 to 100 is recommended.
measures &lt;- NULL
for (i in 1:n) {
rfcv1 &lt;- RFcv2(hard[, c(4:6)], hard[, 17], predacc = "ccr")
measures &lt;- rbind(measures, rfcv1)
}
plot(measures ~ c(1:n), xlab = "Iteration for RF", ylab = "Correct
classification Rate  (%)")
points(cumsum(measures) / c(1:n) ~ c(1:n), col = 2)
abline(h = mean(measures), col = 'blue', lwd = 2)


</code></pre>

<hr>
<h2 id='steprf'>Select predictive variables for random forest by  various variable importance methods and predictive accuracy
in a stepwise algorithm</h2><span id='topic+steprf'></span>

<h3>Description</h3>

<p>This function is to select predictive variables for random forest
by various variable importance methods (i.e., AVI, Knowledge informed AVI
(KIAVI), KIAVI2) and predictive accuracy. It is implemented via the functions 'steprfAVI'
and 'steprfAVIPredictors'.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>steprf(
  trainx,
  trainy,
  method = "KIAVI",
  cv.fold = 10,
  ntree = 500,
  rpt = 20,
  predacc = "VEcv",
  importance = TRUE,
  maxk = c(4),
  nsim = 100,
  delta.predacc = 0.001,
  min.n.var = 2,
  corr.threshold = 0.5,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="steprf_+3A_trainx">trainx</code></td>
<td>
<p>a dataframe or matrix contains columns of predictor variables.</p>
</td></tr>
<tr><td><code id="steprf_+3A_trainy">trainy</code></td>
<td>
<p>a vector of response, must have length equal to the number of
rows in trainx.</p>
</td></tr>
<tr><td><code id="steprf_+3A_method">method</code></td>
<td>
<p>a variable selection method for 'RF'; can be: &quot;AVI&quot;, &quot;KIAVI&quot;
and &quot;KIAVI2&quot;. If &quot;AVI&quot; is used, it would produce tha same results as
'steprfAVI'. By default, &quot;KIAVI&quot; is used.</p>
</td></tr>
<tr><td><code id="steprf_+3A_cv.fold">cv.fold</code></td>
<td>
<p>integer; number of folds in the cross-validation. if &gt; 1,
then apply n-fold cross validation; the default is 10, i.e., 10-fold cross
validation that is recommended.</p>
</td></tr>
<tr><td><code id="steprf_+3A_ntree">ntree</code></td>
<td>
<p>number of trees to grow. This should not be set to too small a
number, to ensure that every input row gets predicted at least a few times.
By default, 500 is used.</p>
</td></tr>
<tr><td><code id="steprf_+3A_rpt">rpt</code></td>
<td>
<p>iteration of cross validation.</p>
</td></tr>
<tr><td><code id="steprf_+3A_predacc">predacc</code></td>
<td>
<p>&quot;VEcv&quot; for vecv for numerical data, or &quot;ccr&quot; (i.e., correct
classification rate) or &quot;kappa&quot; for categorical data.</p>
</td></tr>
<tr><td><code id="steprf_+3A_importance">importance</code></td>
<td>
<p>imprtance of predictive variables.</p>
</td></tr>
<tr><td><code id="steprf_+3A_maxk">maxk</code></td>
<td>
<p>maxk split value. By default, 4 is used.</p>
</td></tr>
<tr><td><code id="steprf_+3A_nsim">nsim</code></td>
<td>
<p>iteration number. By default, 100 is used.</p>
</td></tr>
<tr><td><code id="steprf_+3A_delta.predacc">delta.predacc</code></td>
<td>
<p>minimum changes between the accuracies of two consecutive
predictive models.</p>
</td></tr>
<tr><td><code id="steprf_+3A_min.n.var">min.n.var</code></td>
<td>
<p>minimum number of predictive variables remained in the final
predictive model the default is 2. If 1 is used, then warnings: 'invalid mtry:
reset to within valid range' will be issued, which should be ignored.</p>
</td></tr>
<tr><td><code id="steprf_+3A_corr.threshold">corr.threshold</code></td>
<td>
<p>correlation threshold and the defaults value is 0.5.</p>
</td></tr>
<tr><td><code id="steprf_+3A_...">...</code></td>
<td>
<p>other arguments passed on to randomForest.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with the following components: 1) steprfPredictorsFinal: the
variables selected for the last RF model, whether it is of the highest
predictive accuracy need to be confirmed using 'max.predictive.accuracy'
that is listed next; 2) max.predictive.accuracy: the predictive accuracy
of the most accurate RF model for each run of 'steprfAVI', which can be used
to confirm the model with the highest accuracy, 3) numberruns: number of runs
of 'steprfAVI'; 4) laststepAVI: the outpouts of last run of 'steprfAVI'; 5)
steprfAVIOutputsAll: the outpouts of all 'steprfAVI' produced during the
variable selection process; 6) steprfPredictorsAll: the outpouts of
'steprfAVIPredictors' for all 'steprfAVI' produced during the variable
selection process; 7) KIAVIPredictorsAll: predictors used for all
'steprfAVI' produced during the variable selection process; for a method
&quot;AVI&quot;, if the variables are different from those in the traning dataset,
it suggests that these variables should be tested if the predictive
accuracy can be further improved.
</p>


<h3>Note</h3>

<p>In 'steprf', 'steprfAVI' is used instead of 'steprfAVI1' and
'steprfAVI2'. This is because: 1) 'avi' is expected to change with the
removal of each predictor, but in 'steprfAVI1' the averaged variable
importance is calculated only once and is from the full model only, so
its use is expected to produce a less optimal model, hence not used; and
2) the 'steprf' would lead to the same set of predictors as that for
'steprfAVI2' if 'steprfAVI2' is used, so it is not used either.
</p>


<h3>Author(s)</h3>

<p>Jin Li
</p>


<h3>References</h3>

<p>Li, J. (2022). Spatial Predictive Modeling with R. Boca Raton,
Chapman and Hall/CRC.
</p>
<p>Li, J. (2019). &quot;A critical review of spatial predictive modeling process
in environmental sciences with reproducible examples in R.&quot; Applied
Sciences 9: 2048.
</p>
<p>Li, J. 2013. Predicting the spatial distribution of seabed
gravel content using random forest, spatial interpolation methods and
their hybrid methods. Pages 394-400  The International Congress on Modelling
and Simulation (MODSIM) 2013, Adelaide.
</p>
<p>Li, J., Alvarez, B., Siwabessy, J., Tran, M., Huang, Z., Przeslawski, R.,
Radke, L., Howard, F. and Nichol, S. (2017). &quot;Application of random forest,
generalised linear model and their hybrid methods with geostatistical
techniques to count data: Predicting sponge species richness.&quot;
Environmental Modelling &amp; Software 97: 112-129.
</p>
<p>Li, J., Siwabessy, J., Huang, Z., and Nichol, S. (2019). &quot;Developing an
optimal spatial predictive model for seabed sand content using machine
learning, geostatistics and their hybrid methods.&quot; Geosciences 9 (4):180.
</p>
<p>Li, J., Siwabessy, J., Tran, M., Huang, Z. and Heap, A., 2014. Predicting
Seabed Hardness Using Random Forest in R. Data Mining Applications with R. Y.
Zhao and Y. Cen. Amsterdam, Elsevier: 299-329.
</p>
<p>Li, J., Tran, M. and Siwabessy, J., 2016. Selecting optimal random forest
predictive models: a case study on predicting the spatial distribution of
seabed hardness. PLOS ONE 11(2): e0149089.
</p>
<p>Liaw, A. and M. Wiener (2002). Classification and Regression by
randomForest. R News 2(3), 18-22.
</p>
<p>Smith, S.J., Ellis, N., Pitcher, C.R., 2011. Conditional variable
importance in R package extendedForest. R vignette
[http://gradientforest.r-forge.r-project.org/Conditional-importance.pdf].
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(spm)
data(petrel)
set.seed(1234)
steprf1 &lt;- steprf(trainx = petrel[, c(1,2, 6:9)], trainy =
petrel[, 5], method = "KIAVI", rpt = 2, predacc = "VEcv", importance = TRUE,
 nsim = 3, delta.predacc = 0.01)
names(steprf1)
steprf1$steprfPredictorsFinal$variables.most.accurate
steprf1$max.predictive.accuracy


</code></pre>

<hr>
<h2 id='steprfAVI'>Select predictive variables for random forest by AVI and accuracy
in a stepwise algorithm</h2><span id='topic+steprfAVI'></span>

<h3>Description</h3>

<p>This function is to select predictive variables for random forest
by their averaged variable importance (AVI) that is calculated for each model
after excluding the least important variable, and returns the corresponding predictive
accuracy. It is also developed for 'steprf' function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>steprfAVI(
  trainx,
  trainy,
  cv.fold = 10,
  ntree = 500,
  rpt = 20,
  predacc = "VEcv",
  importance = TRUE,
  maxk = c(4),
  nsim = 100,
  min.n.var = 2,
  corr.threshold = 0.5,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="steprfAVI_+3A_trainx">trainx</code></td>
<td>
<p>a dataframe or matrix contains columns of predictor variables.</p>
</td></tr>
<tr><td><code id="steprfAVI_+3A_trainy">trainy</code></td>
<td>
<p>a vector of response, must have length equal to the number of
rows in trainx.</p>
</td></tr>
<tr><td><code id="steprfAVI_+3A_cv.fold">cv.fold</code></td>
<td>
<p>integer; number of folds in the cross-validation. if &gt; 1,
then apply n-fold cross validation; the default is 10, i.e., 10-fold cross
validation that is recommended.</p>
</td></tr>
<tr><td><code id="steprfAVI_+3A_ntree">ntree</code></td>
<td>
<p>number of trees to grow. This should not be set to too small a
number, to ensure that every input row gets predicted at least a few times.
By default, 500 is used.</p>
</td></tr>
<tr><td><code id="steprfAVI_+3A_rpt">rpt</code></td>
<td>
<p>iteration number of cross validation.</p>
</td></tr>
<tr><td><code id="steprfAVI_+3A_predacc">predacc</code></td>
<td>
<p>&quot;VEcv&quot; for vecv for numerical data, or &quot;ccr&quot; (i.e., correct
classification rate) or &quot;kappa&quot; for categorical data.</p>
</td></tr>
<tr><td><code id="steprfAVI_+3A_importance">importance</code></td>
<td>
<p>importance of predictive variables.</p>
</td></tr>
<tr><td><code id="steprfAVI_+3A_maxk">maxk</code></td>
<td>
<p>maxk split value. By default, 4 is used.</p>
</td></tr>
<tr><td><code id="steprfAVI_+3A_nsim">nsim</code></td>
<td>
<p>iteration number for 'avi'. By default, 100 is used.</p>
</td></tr>
<tr><td><code id="steprfAVI_+3A_min.n.var">min.n.var</code></td>
<td>
<p>minimum number of predictive variables remained in the final
predictive model the default is 2. If 1 is used, then warnings: 'invalid mtry:
reset to within valid range' will be issued, which should be ignored.</p>
</td></tr>
<tr><td><code id="steprfAVI_+3A_corr.threshold">corr.threshold</code></td>
<td>
<p>correlation threshold and the defaults value is 0.5.</p>
</td></tr>
<tr><td><code id="steprfAVI_+3A_...">...</code></td>
<td>
<p>other arguments passed on to randomForest.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with the following components: 1) variable.removed:
variable removed based on AVI, 2) predictive.accuracy: averaged predictive
accuracy of the model after excluding the variable.removed, 3)
delta.accuracy: contribution to accuracy by each variable.removed, and 4)
predictive.accuracy2: predictive accuracy matrix of the model after
excluding the variable.removed for each iteration.
</p>


<h3>Author(s)</h3>

<p>Jin Li
</p>


<h3>References</h3>

<p>Li, J. (2022). Spatial Predictive Modeling with R. Boca Raton,
Chapman and Hall/CRC.
</p>
<p>Li, J. 2013. Predicting the spatial distribution of seabed
gravel content using random forest, spatial interpolation methods and
their hybrid methods. Pages 394-400  The International Congress on
Modelling and Simulation (MODSIM) 2013, Adelaide.
</p>
<p>Li, J., Alvarez, B., Siwabessy, J., Tran, M., Huang, Z., Przeslawski, R.,
Radke, L., Howard, F. and Nichol, S. (2017). &quot;Application of random forest,
generalised linear model and their hybrid methods with geostatistical
techniques to count data: Predicting sponge species richness.&quot;
Environmental Modelling &amp; Software 97: 112-129.
</p>
<p>Li, J., Siwabessy, J., Huang, Z., Nichol, S. (2019). &quot;Developing an optimal
spatial predictive model for seabed sand content using machine learning,
geostatistics and their hybrid methods.&quot; Geosciences 9 (4):180.
</p>
<p>Li, J., Siwabessy, J., Tran, M., Huang, Z. and Heap, A., 2014. Predicting
Seabed Hardness Using Random Forest in R. Data Mining Applications with R. Y.
Zhao and Y. Cen. Amsterdam, Elsevier: 299-329.
</p>
<p>Liaw, A. and M. Wiener (2002). Classification and Regression by
randomForest. R News 2(3), 18-22.
</p>
<p>Smith, S.J., Ellis, N., Pitcher, C.R., 2011. Conditional variable
importance in R package extendedForest. R vignette
[http://gradientforest.r-forge.r-project.org/Conditional-importance.pdf].
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(spm)

data(petrel)
set.seed(1234)
steprf1 &lt;- steprfAVI(trainx = petrel[, c(1,2, 6:9)], trainy = petrel[, 5],
 rpt = 2, predacc = "VEcv", importance = TRUE, nsim = 3, min.n.var = 2)
steprf1

steprf2 &lt;- steprfAVI(trainx = hard[, -c(1, 17)], trainy = hard[, 17],
 rpt = 2, predacc = "ccr", importance = TRUE, nsim = 3, min.n.var = 2)
steprf2

#plot steprf1 results
library(reshape2)
pa1 &lt;- as.data.frame(steprf1$predictive.accuracy2)
names(pa1) &lt;- steprf1$variable.removed
pa2 &lt;- melt(pa1, id = NULL)
names(pa2) &lt;- c("Variable","VEcv")
library(lattice)
par (font.axis=2, font.lab=2)
with(pa2, boxplot(VEcv~Variable, ylab="VEcv (%)", xlab="Predictive variable removed"))

barplot(steprf1$delta.accuracy, col = (1:length(steprf1$variable.removed)),
names.arg = steprf1$variable.removed, main = "Predictive accuracy vs variable removed",
font.main = 4, cex.names=1, font=2, ylab="Increase in VEcv (%)")


</code></pre>

<hr>
<h2 id='steprfAVI1'>Select predictive variables for random forest by avi and accuracy
in a stepwise algorithm</h2><span id='topic+steprfAVI1'></span>

<h3>Description</h3>

<p>This function is to select predictive variables for random forest
by their averaged variable importance which is derived from the full model and
returns the corresponding predictive accuracy. That is, in comparison with 'steprfAVI',
the averaged variable importance is calculated only once and is from the
full model only.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>steprfAVI1(
  trainx,
  trainy,
  cv.fold = 10,
  mtry = if (!is.null(trainy) &amp;&amp; !is.factor(trainy)) max(floor(ncol(trainx)/3), 1) else
    floor(sqrt(ncol(trainx))),
  ntree = 500,
  rpt = 2,
  predacc = "VEcv",
  importance = TRUE,
  maxk = c(4),
  nsim = 100,
  min.n.var = 2,
  corr.threshold = 0.5,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="steprfAVI1_+3A_trainx">trainx</code></td>
<td>
<p>a dataframe or matrix contains columns of predictor variables.</p>
</td></tr>
<tr><td><code id="steprfAVI1_+3A_trainy">trainy</code></td>
<td>
<p>a vector of response, must have length equal to the number of
rows in trainx.</p>
</td></tr>
<tr><td><code id="steprfAVI1_+3A_cv.fold">cv.fold</code></td>
<td>
<p>integer; number of folds in the cross-validation. if &gt; 1,
then apply n-fold cross validation; the default is 10, i.e., 10-fold cross
validation that is recommended.</p>
</td></tr>
<tr><td><code id="steprfAVI1_+3A_mtry">mtry</code></td>
<td>
<p>a function of number of remaining predictor variables to use as
the mtry parameter in the randomForest call.</p>
</td></tr>
<tr><td><code id="steprfAVI1_+3A_ntree">ntree</code></td>
<td>
<p>number of trees to grow. This should not be set to too small a
number, to ensure that every input row gets predicted at least a few times.
By default, 500 is used.</p>
</td></tr>
<tr><td><code id="steprfAVI1_+3A_rpt">rpt</code></td>
<td>
<p>iteration of cross validation.</p>
</td></tr>
<tr><td><code id="steprfAVI1_+3A_predacc">predacc</code></td>
<td>
<p>&quot;VEcv&quot; for vecv for numerical data, or &quot;ccr&quot; (i.e., correct
classification rate) or &quot;kappa&quot; for categorical data.</p>
</td></tr>
<tr><td><code id="steprfAVI1_+3A_importance">importance</code></td>
<td>
<p>imprtance of predictive variables.</p>
</td></tr>
<tr><td><code id="steprfAVI1_+3A_maxk">maxk</code></td>
<td>
<p>maxk split value. By default, 4 is used.</p>
</td></tr>
<tr><td><code id="steprfAVI1_+3A_nsim">nsim</code></td>
<td>
<p>iteration number. By default, 100 is used.</p>
</td></tr>
<tr><td><code id="steprfAVI1_+3A_min.n.var">min.n.var</code></td>
<td>
<p>minimum number of predictive variables remained in the final
predictive model the default is 1.</p>
</td></tr>
<tr><td><code id="steprfAVI1_+3A_corr.threshold">corr.threshold</code></td>
<td>
<p>correlation threshold and the defaults value is 0.5.</p>
</td></tr>
<tr><td><code id="steprfAVI1_+3A_...">...</code></td>
<td>
<p>other arguments passed on to randomForest.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with the following components:
variable removed based on avi (variable.removed), averaged predictive accuracy
of the model after excluding variable.removed (predictive.accuracy),
contribution to accuracy by each variable.removed (delta.accuracy), and
predictive accuracy matrix of the model after excluding variable.removed for
each iteration (predictive.accuracy2)
</p>


<h3>Author(s)</h3>

<p>Jin Li
</p>


<h3>References</h3>

<p>Li, J. (2022). Spatial Predictive Modeling with R. Boca Raton,
Chapman and Hall/CRC.
</p>
<p>Li, J. 2013. Predicting the spatial distribution of seabed
gravel content using random forest, spatial interpolation methods and
their hybrid methods. Pages 394-400  The International Congress on Modelling
and Simulation (MODSIM) 2013, Adelaide.
</p>
<p>Li, J. (2019). &quot;A critical review of spatial predictive modeling process
in environmental sciences with reproducible examples in R.&quot; Applied
Sciences 9: 2048.
</p>
<p>Li, J., Siwabessy, J., Huang, Z., Nichol, S. (2019). &quot;Developing an optimal
spatial predictive model for seabed sand content using machine learning,
geostatistics and their hybrid methods.&quot; Geosciences 9 (4):180.
</p>
<p>Li, J., Siwabessy, J., Tran, M., Huang, Z. and Heap, A., 2014. Predicting
Seabed Hardness Using Random Forest in R. Data Mining Applications with R. Y.
Zhao and Y. Cen. Amsterdam, Elsevier: 299-329.
</p>
<p>Li, J., Tran, M. and Siwabessy, J., 2016. Selecting optimal random forest
predictive models: a case study on predicting the spatial distribution of
seabed hardness. PLOS ONE 11(2): e0149089.
</p>
<p>Liaw, A. and M. Wiener (2002). Classification and Regression by
randomForest. R News 2(3), 18-22.
</p>
<p>Smith, S.J., Ellis, N., Pitcher, C.R., 2011. Conditional variable
importance in R package extendedForest. R vignette
[http://gradientforest.r-forge.r-project.org/Conditional-importance.pdf].
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(spm)
data(petrel)
set.seed(1234)
steprfAVI1.1 &lt;- steprfAVI1(trainx = petrel[, c(1,2, 6:9)], trainy =
petrel[, 5], predacc = "VEcv", nsim = 10)
steprfAVI1.1

#plot steprf1 results
library(reshape2)
pa1 &lt;- as.data.frame(steprfAVI1.1$predictive.accuracy2)
names(pa1) &lt;- steprfAVI1.1$variable.removed
pa2 &lt;- melt(pa1, id = NULL)
names(pa2) &lt;- c("Variable","VEcv")
library(lattice)
par (font.axis=2, font.lab=2)
with(pa2, boxplot(VEcv~Variable, ylab="VEcv (%)", xlab="Predictive variable removed"))

barplot(steprfAVI1.1$delta.accuracy, col = (1:length(steprfAVI1.1$variable.removed)),
names.arg = steprfAVI1.1$variable.removed, main = "Predictive accuracy vs variable removed",
font.main = 4, cex.names=1, font=2, ylab="Increase rate in VEcv (%)")

barplot(steprfAVI1.1$delta.accuracy, col = (1:length(steprfAVI1.1$variable.removed)),
names.arg = steprfAVI1.1$variable.removed,   main = "Predictive accuracy vs variable removed",
font.main = 4, cex.names=1, font=2, ylab="Increase in VEcv (%)")


</code></pre>

<hr>
<h2 id='steprfAVI2'>Select predictive variables for random forest by AVI and accuracy
in a stepwise algorithm</h2><span id='topic+steprfAVI2'></span>

<h3>Description</h3>

<p>This function is similar to 'steprfAVI'; the only difference
is that 'set.seed()' is added before each code line that involves
randomness and such additions alter the results considerably.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>steprfAVI2(
  trainx,
  trainy,
  cv.fold = 10,
  ntree = 500,
  rpt = 20,
  predacc = "VEcv",
  importance = TRUE,
  maxk = c(4),
  nsim = 100,
  min.n.var = 2,
  corr.threshold = 0.5,
  rseed = 1234,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="steprfAVI2_+3A_trainx">trainx</code></td>
<td>
<p>a dataframe or matrix contains columns of predictor variables.</p>
</td></tr>
<tr><td><code id="steprfAVI2_+3A_trainy">trainy</code></td>
<td>
<p>a vector of response, must have length equal to the number of
rows in trainx.</p>
</td></tr>
<tr><td><code id="steprfAVI2_+3A_cv.fold">cv.fold</code></td>
<td>
<p>integer; number of folds in the cross-validation. if &gt; 1,
then apply n-fold cross validation; the default is 10, i.e., 10-fold cross
validation that is recommended.</p>
</td></tr>
<tr><td><code id="steprfAVI2_+3A_ntree">ntree</code></td>
<td>
<p>number of trees to grow. This should not be set to too small a
number, to ensure that every input row gets predicted at least a few times.
By default, 500 is used.</p>
</td></tr>
<tr><td><code id="steprfAVI2_+3A_rpt">rpt</code></td>
<td>
<p>iteration of cross validation.</p>
</td></tr>
<tr><td><code id="steprfAVI2_+3A_predacc">predacc</code></td>
<td>
<p>&quot;VEcv&quot; for vecv for numerical data, or &quot;ccr&quot; (i.e., correct
classification rate) or &quot;kappa&quot; for categorical data.</p>
</td></tr>
<tr><td><code id="steprfAVI2_+3A_importance">importance</code></td>
<td>
<p>imprtance of predictive variables.</p>
</td></tr>
<tr><td><code id="steprfAVI2_+3A_maxk">maxk</code></td>
<td>
<p>maxk split value. By default, 4 is used.</p>
</td></tr>
<tr><td><code id="steprfAVI2_+3A_nsim">nsim</code></td>
<td>
<p>iteration number. By default, 100 is used.</p>
</td></tr>
<tr><td><code id="steprfAVI2_+3A_min.n.var">min.n.var</code></td>
<td>
<p>minimum number of predictive variables remained in the final
predictive model the default is 2. If 1 is used, then warnings: 'invalid mtry:
reset to within valid range' will be issued, which should be ignored.</p>
</td></tr>
<tr><td><code id="steprfAVI2_+3A_corr.threshold">corr.threshold</code></td>
<td>
<p>correlation threshold and the defaults value is 0.5.</p>
</td></tr>
<tr><td><code id="steprfAVI2_+3A_rseed">rseed</code></td>
<td>
<p>random seed. By default, 1234 is used.</p>
</td></tr>
<tr><td><code id="steprfAVI2_+3A_...">...</code></td>
<td>
<p>other arguments passed on to randomForest.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with the following components: 1) variable.removed:
variable removed based on AVI, 2) predictive.accuracy: averaged predictive
accuracy of the model after excluding the variable.removed, 3)
delta.accuracy: contribution to accuracy by each variable.removed, and 4)
predictive.accuracy2: predictive accuracy matrix of the model after
excluding the variable.removed for each iteration.
</p>


<h3>Author(s)</h3>

<p>Jin Li
</p>


<h3>References</h3>

<p>Li, J. (2022). Spatial Predictive Modeling with R. Boca Raton,
Chapman and Hall/CRC.
</p>
<p>Li, J. 2013. Predicting the spatial distribution of seabed
gravel content using random forest, spatial interpolation methods and
their hybrid methods. Pages 394-400  The International Congress on
Modelling and Simulation (MODSIM) 2013, Adelaide.
</p>
<p>Li, J., Alvarez, B., Siwabessy, J., Tran, M., Huang, Z., Przeslawski, R.,
Radke, L., Howard, F. and Nichol, S. (2017). &quot;Application of random forest,
generalised linear model and their hybrid methods with geostatistical
techniques to count data: Predicting sponge species richness.&quot;
Environmental Modelling &amp; Software 97: 112-129.
</p>
<p>Li, J., Siwabessy, J., Huang, Z., Nichol, S. (2019). &quot;Developing an optimal
spatial predictive model for seabed sand content using machine learning,
geostatistics and their hybrid methods.&quot; Geosciences 9 (4):180.
</p>
<p>Li, J., Siwabessy, J., Tran, M., Huang, Z. and Heap, A., 2014. Predicting
Seabed Hardness Using Random Forest in R. Data Mining Applications with R. Y.
Zhao and Y. Cen. Amsterdam, Elsevier: 299-329.
</p>
<p>Liaw, A. and M. Wiener (2002). Classification and Regression by
randomForest. R News 2(3), 18-22.
</p>
<p>Smith, S.J., Ellis, N., Pitcher, C.R., 2011. Conditional variable
importance in R package extendedForest. R vignette
[http://gradientforest.r-forge.r-project.org/Conditional-importance.pdf].
</p>
<p>Chang, W. 2021. Cookbook for R. http://www.cookbook-r.com/.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(spm)
data(petrel)
steprf1 &lt;- steprfAVI2(trainx = petrel[, c(1,2, 6:9)], trainy = petrel[, 5],
 rpt = 2, predacc = "VEcv", importance = TRUE, nsim = 3, min.n.var = 2)
steprf1

#plot steprf1 results
library(reshape2)
pa1 &lt;- as.data.frame(steprf1$predictive.accuracy2)
names(pa1) &lt;- steprf1$variable.removed
pa2 &lt;- melt(pa1, id = NULL)
names(pa2) &lt;- c("Variable","VEcv")
library(lattice)
par (font.axis=2, font.lab=2)
with(pa2, boxplot(VEcv~Variable, ylab="VEcv (%)", xlab="Predictive variable removed"))

barplot(steprf1$delta.accuracy, col = (1:length(steprf1$variable.removed)),
names.arg = steprf1$variable.removed, main = "Predictive accuracy vs variable removed",
font.main = 4, cex.names=1, font=2, ylab="Increase in VEcv (%)")


</code></pre>

<hr>
<h2 id='steprfAVIPredictors'>Extract names of the selected predictive variables by steprf</h2><span id='topic+steprfAVIPredictors'></span>

<h3>Description</h3>

<p>This function is to extract names of the selected predictive variables by steprfAVI.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>steprfAVIPredictors(steprf1, trainx)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="steprfAVIPredictors_+3A_steprf1">steprf1</code></td>
<td>
<p>a list of output of 'steprf' function.</p>
</td></tr>
<tr><td><code id="steprfAVIPredictors_+3A_trainx">trainx</code></td>
<td>
<p>a dataframe or matrix contains columns of predictor variables.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with the following components:
1) variables.most.accurate: a list of predictive variables contained in the
most accurate RF model,  2) PABV: a list of predictive variables with positive
contributions to the predictive accuracy of RF models, that is,
predictive accuracy boosting variable (PABV), 3) PARV: a list of
predictive variables with negative contributions to the predictive
accuracy of RF models, that is, predictive accuracy reducing variable,
and 4) max.predictive.accuracy: the predictive accuracy of the most
accurate RF model.
</p>


<h3>Author(s)</h3>

<p>Jin Li
</p>


<h3>References</h3>

<p>Li, J. (2022). Spatial Predictive Modeling with R. Boca Raton,
Chapman and Hall/CRC.
</p>
<p>Li, J. (2019). &quot;A critical review of spatial predictive modeling
process in environmental sciences with reproducible examples in R.&quot; Applied
Sciences 9: 2048.
</p>
<p>Li, J., Siwabessy, J., Huang, Z., and Nichol, S. (2019). &quot;Developing an
optimal spatial predictive model for seabed sand content using machine
learning, geostatistics and their hybrid methods.&quot; Geosciences 9 (4):180.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(spm)
data(petrel)
set.seed(1234)
steprf1 &lt;- steprfAVI(trainx = petrel[, c(1,2, 6:9)], trainy = petrel[, 5],
 nsim = 10, min.n.var = 2)

steprfAVIPredictors(steprf1, trainx = petrel[, c(1,2, 6:9)])


</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
