<!DOCTYPE html><html><head><title>Help for package HDCD</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {HDCD}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#ARI'><p>ARI</p></a></li>
<li><a href='#CUSUM'><p>CUSUM transformation of a matrix</p></a></li>
<li><a href='#ESAC'><p>Efficient Sparsity Adaptive Change-point estimator</p></a></li>
<li><a href='#ESAC_calibrate'><p>Generates empirical penalty function <code class="reqn">\gamma(t)</code> for the ESAC algorithm using Monte Carlo simulation</p></a></li>
<li><a href='#ESAC_test'><p>ESAC single change-point test</p></a></li>
<li><a href='#ESAC_test_calibrate'><p>Generates empirical penalty function <code class="reqn">\gamma(t)</code> for single change-point testing using Monte Carlo simulation</p></a></li>
<li><a href='#hausdorff'><p>Hausdorff distance between two sets</p></a></li>
<li><a href='#Inspect'><p>Informative sparse projection for estimating change-points (Inspect)</p></a></li>
<li><a href='#Inspect_calibrate'><p>Generates empirical detection threshold <code class="reqn">\xi</code> using Monte Carlo simulation</p></a></li>
<li><a href='#Inspect_test'><p>Inspect single change-point test</p></a></li>
<li><a href='#Inspect_test_calibrate'><p>Generates empirical detection threshold <code class="reqn">\xi</code> for single change-point testing using Monte Carlo simulation</p></a></li>
<li><a href='#Pilliat'><p>Pilliat multiple change-point detection algorithm</p></a></li>
<li><a href='#Pilliat_calibrate'><p>Generates detection thresholds for the Pilliat algorithm using Monte Carlo simulation</p></a></li>
<li><a href='#Pilliat_test'><p>Pilliat single change-point test</p></a></li>
<li><a href='#Pilliat_test_calibrate'><p>Generates detection thresholds for the Pilliat algorithm for testing for a single change-point using Monte Carlo simulation</p></a></li>
<li><a href='#rescale_variance'><p>Re-scales each row of matrix by its MAD estimate</p></a></li>
<li><a href='#single_CUSUM'><p>CUSUM transformation of matrix at a specific position</p></a></li>
<li><a href='#single_ESAC'><p>Efficient Sparsity Adaptive Change-point estimator for a single change-point</p></a></li>
<li><a href='#single_Inspect'><p>Inspect for single change-point estimation</p></a></li>
<li><a href='#single_SBS'><p>Sparsified Binary Segmentation for single change-point estimation</p></a></li>
<li><a href='#single_SBS_calibrate'><p>Generates threshold <code class="reqn">\pi_T</code> for Sparsified Binary Segmentation for single change-point detection</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>High-Dimensional Changepoint Detection</td>
</tr>
<tr>
<td>Version:</td>
<td>1.0</td>
</tr>
<tr>
<td>Date:</td>
<td>2023-11-17</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Per August Jarval Moen &lt;pamoen@math.uio.no&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Efficient implementations of the following multiple changepoint detection algorithms: Efficient Sparsity Adaptive Change-point estimator by Moen, Glad and Tveten (2023) &lt;<a href="https://arxiv.org/abs/2306.04702">arXiv:2306.04702</a>&gt; , Informative Sparse Projection for Estimating Changepoints by Wang and Samworth (2017) &lt;<a href="https://doi.org/10.1111%2Frssb.12243">doi:10.1111/rssb.12243</a>&gt;, and the method of Pilliat et al (2023) &lt;<a href="https://doi.org/10.1214%2F23-EJS2126">doi:10.1214/23-EJS2126</a>&gt;.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>Imports:</td>
<td>mclust, Rdpack</td>
</tr>
<tr>
<td>RdMacros:</td>
<td>Rdpack</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-11-18 13:48:21 UTC; peraugust</td>
</tr>
<tr>
<td>Author:</td>
<td>Per August Jarval Moen
    <a href="https://orcid.org/0009-0003-9990-8341"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [cre, aut]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-11-19 15:30:06 UTC</td>
</tr>
</table>
<hr>
<h2 id='ARI'>ARI</h2><span id='topic+ARI'></span>

<h3>Description</h3>

<p>Computes the Adjusted Rand Index (ARI) of a vector of estimated change-points.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ARI(etas, eta_hats, n)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ARI_+3A_etas">etas</code></td>
<td>
<p>Vector of true change-points</p>
</td></tr>
<tr><td><code id="ARI_+3A_eta_hats">eta_hats</code></td>
<td>
<p>Vector of estimated change-points</p>
</td></tr>
<tr><td><code id="ARI_+3A_n">n</code></td>
<td>
<p>Sample size</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The ARI
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(HDCD)
n = 400
true_changepoints = c(50,100)
est_changepoints = c(51,110)
ARI(true_changepoints, est_changepoints,n)
</code></pre>

<hr>
<h2 id='CUSUM'>CUSUM transformation of a matrix</h2><span id='topic+CUSUM'></span>

<h3>Description</h3>

<p>R wrapper for C function computing the CUSUM transformation of a matrix over an interval <code class="reqn">(s,e]</code>. For compatibility with C indexing, the user should subtract <code class="reqn">1</code> from both <code class="reqn">s</code> and <code class="reqn">e</code> when supplying the arguments to the function. If start and stop are not supplied, the CUSUM is computed over the full data, so <code class="reqn">(s,e] = (0,n]</code>. In this case, <code>CUSUM</code> returns the same result as <code>cusum.transform</code> in the package <code>InspectChangepoint</code> (Wang and Samworth 2020).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CUSUM(X, start = NULL, stop = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CUSUM_+3A_x">X</code></td>
<td>
<p>Matrix of observations, where each row contains a time series</p>
</td></tr>
<tr><td><code id="CUSUM_+3A_start">start</code></td>
<td>
<p>Starting point of interval over which the CUSUM should be computed, subtracted by one</p>
</td></tr>
<tr><td><code id="CUSUM_+3A_stop">stop</code></td>
<td>
<p>Ending point of interval over which the CUSUM should be computed, subtracted by one</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix of CUSUM values. The <code class="reqn">(i,j)</code>-th element corresponds to the CUSUM transformation of the <code class="reqn">i</code>-th row of <code class="reqn">X</code>, computed over the interval <code class="reqn">(\code{start}+1,\code{end}+1]</code> and evaluated at position <code class="reqn">\code{start}+1+j</code>, i.e. 
<code class="reqn">\sqrt{\frac{e-v}{(e-s)(v-s)}}\sum_{t=s+1}^v X_{i,t} - \sqrt{\frac{v-s}{(e-s)(e-v)}}\sum_{t=v+1}^e X_{i,t}</code>, 
where <code class="reqn">s = (\code{start}+1)</code>, <code class="reqn">e = (\code{stop}+1)</code> and <code class="reqn">v = \code{start}+1+j</code>.
</p>


<h3>References</h3>

<p>Wang T, Samworth R (2020).
<em>InspectChangepoint: High-Dimensional Changepoint Estimation via Sparse Projection</em>.
R package version 1.1, <a href="https://CRAN.R-project.org/package=InspectChangepoint">https://CRAN.R-project.org/package=InspectChangepoint</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n = 10
p = 10
set.seed(101)
X = matrix(rnorm(n*p), ncol = n, nrow=p)
# CUSUM over the full data (s,e] = (0,n]
X_cusum = CUSUM(X)

# CUSUM over (s,e] = (3,9]:
s = 3
e = 9
X_cusum = CUSUM(X, start = s-1, stop = e-1)
</code></pre>

<hr>
<h2 id='ESAC'>Efficient Sparsity Adaptive Change-point estimator</h2><span id='topic+ESAC'></span>

<h3>Description</h3>

<p>R wrapper for C function implementing the full ESAC algorithm (see Moen et al. 2023).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ESAC(
  X,
  threshold_d = 1.5,
  threshold_s = 1,
  alpha = 1.5,
  K = 5,
  debug = FALSE,
  empirical = FALSE,
  tol = 0.001,
  N = 1000,
  thresholds = NULL,
  thresholds_test = NULL,
  threshold_d_test = threshold_d,
  threshold_s_test = threshold_s,
  fast = FALSE,
  rescale_variance = TRUE,
  trim = FALSE,
  NOT = TRUE,
  midpoint = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ESAC_+3A_x">X</code></td>
<td>
<p>Matrix of observations, where each row contains a time series</p>
</td></tr>
<tr><td><code id="ESAC_+3A_threshold_d">threshold_d</code></td>
<td>
<p>Leading constant for <code class="reqn">\lambda(t) \propto r(t)</code> for <code class="reqn">t= p</code>. Only relevant when <code>thresholds=NULL</code></p>
</td></tr>
<tr><td><code id="ESAC_+3A_threshold_s">threshold_s</code></td>
<td>
<p>Leading constant for <code class="reqn">\lambda(t) \propto r(t)</code> for <code class="reqn">t\leq \sqrt{p\log n}</code>.  Only relevant when <code>thresholds=NULL</code></p>
</td></tr>
<tr><td><code id="ESAC_+3A_alpha">alpha</code></td>
<td>
<p>Parameter for generating seeded intervals</p>
</td></tr>
<tr><td><code id="ESAC_+3A_k">K</code></td>
<td>
<p>Parameter for generating seeded intervals</p>
</td></tr>
<tr><td><code id="ESAC_+3A_debug">debug</code></td>
<td>
<p>If <code>TRUE</code>, diagnostic prints are provided during execution</p>
</td></tr>
<tr><td><code id="ESAC_+3A_empirical">empirical</code></td>
<td>
<p>If <code>TRUE</code>, detection thresholds are based on Monte Carlo simulation using <code><a href="#topic+ESAC_calibrate">ESAC_calibrate</a></code></p>
</td></tr>
<tr><td><code id="ESAC_+3A_tol">tol</code></td>
<td>
<p>If <code>empirical=TRUE</code>, <code>tol</code> is the false error probability tolerance</p>
</td></tr>
<tr><td><code id="ESAC_+3A_n">N</code></td>
<td>
<p>If <code>empirical=TRUE</code>, <code>N</code> is the number of Monte Carlo samples used</p>
</td></tr>
<tr><td><code id="ESAC_+3A_thresholds">thresholds</code></td>
<td>
<p>Vector of manually chosen values of <code class="reqn">\lambda(t)</code> for <code class="reqn">t \in \mathcal{T}</code>, decreasing in <code class="reqn">t</code></p>
</td></tr>
<tr><td><code id="ESAC_+3A_thresholds_test">thresholds_test</code></td>
<td>
<p>Vector of manually chosen values of <code class="reqn">\gamma(t)</code> for <code class="reqn">t \in \mathcal{T}</code>, decreasing in <code class="reqn">t</code></p>
</td></tr>
<tr><td><code id="ESAC_+3A_threshold_d_test">threshold_d_test</code></td>
<td>
<p>Leading constant for <code class="reqn">\gamma(t) \propto r(t)</code> for <code class="reqn">t=p</code>.  Only relevant when <code>empirical=FALSE</code> and <code>thresholds_test=NULL</code></p>
</td></tr>
<tr><td><code id="ESAC_+3A_threshold_s_test">threshold_s_test</code></td>
<td>
<p>Leading constant for <code class="reqn">\gamma(t) \propto r(t)</code> for <code class="reqn">t\leq \sqrt{p\log n}</code>. Only relevant when <code>empirical=FALSE</code> and <code>thresholds_test=NULL</code></p>
</td></tr>
<tr><td><code id="ESAC_+3A_fast">fast</code></td>
<td>
<p>If <code>TRUE</code>, ESAC only tests for a change-point at the midpoint of each seeded interval</p>
</td></tr>
<tr><td><code id="ESAC_+3A_rescale_variance">rescale_variance</code></td>
<td>
<p>If <code>TRUE</code>, each row of the data is re-scaled by a MAD estimate using <code><a href="#topic+rescale_variance">rescale_variance</a></code></p>
</td></tr>
<tr><td><code id="ESAC_+3A_trim">trim</code></td>
<td>
<p>If <code>TRUE</code>, interval trimming is performed</p>
</td></tr>
<tr><td><code id="ESAC_+3A_not">NOT</code></td>
<td>
<p>If <code>TRUE</code>, ESAC uses Narrowest-Over-Threshold selection of change-points</p>
</td></tr>
<tr><td><code id="ESAC_+3A_midpoint">midpoint</code></td>
<td>
<p>If <code>TRUE</code>, change-point positions are estimated by the mid-point of the seeded interval in which the penalized score is the largest</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing 
</p>
<table>
<tr><td><code>changepoints</code></td>
<td>
<p>vector of estimated change-points</p>
</td></tr>
<tr><td><code>changepointnumber</code></td>
<td>
<p>number of changepoints</p>
</td></tr>
<tr><td><code>CUSUMval</code></td>
<td>
<p>the penalized score at the corresponding change-point in <code>changepoints</code></p>
</td></tr>
<tr><td><code>coordinates</code></td>
<td>
<p>a matrix of zeros and ones indicating which time series are affected by a change in mean, with each row corresponding to the change-point in <code>changepoints</code></p>
</td></tr>
<tr><td><code>scales</code></td>
<td>
<p>vector of estimated noise level for each series</p>
</td></tr>
<tr><td><code>startpoints</code></td>
<td>
<p>start point of the seeded interval detecting the corresponding change-point in <code>changepoints</code></p>
</td></tr>
<tr><td><code>endpoints</code></td>
<td>
<p>end point of the seeded interval detecting the corresponding change-point in <code>changepoints</code></p>
</td></tr>
<tr><td><code>thresholds</code></td>
<td>
<p>vector of values of <code class="reqn">\lambda(t)</code> for <code class="reqn">t \in \mathcal{T}</code> in decreasing order</p>
</td></tr>
<tr><td><code>thresholds_test</code></td>
<td>
<p>vector of values of <code class="reqn">\gamma(t)</code> for <code class="reqn">t \in \mathcal{T}</code> in decreasing order</p>
</td></tr>
</table>


<h3>References</h3>

<p>Moen PAJ, Glad IK, Tveten M (2023).
&ldquo;Efficient sparsity adaptive changepoint estimation.&rdquo;
Arxiv preprint, 2306.04702, <a href="https://doi.org/10.48550/arXiv.2306.04702">https://doi.org/10.48550/arXiv.2306.04702</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(HDCD)
n = 50
p = 50
set.seed(100)
# Generating data
X = matrix(rnorm(n*p), ncol = n, nrow=p)
# Adding a single sparse change-point:
X[1:5, 26:n] = X[1:5, 26:n] +1

# Vanilla ESAC:
res = ESAC(X)
res$changepoints

# Manually setting leading constants for \lambda(t) and \gamma(t)
res = ESAC(X, 
           threshold_d = 2, threshold_s = 2, #leading constants for \lambda(t)
           threshold_d_test = 2, threshold_s_test = 2 #leading constants for \gamma(t)
)
res$changepoints #estimated change-point locations

# Empirical choice of thresholds:
res = ESAC(X, empirical = TRUE, N = 100, tol = 1/100)
res$changepoints

# Manual empirical choice of thresholds (equivalent to the above)
thresholds_emp = ESAC_calibrate(n,p, N=100, tol=1/100)
res = ESAC(X, thresholds_test = thresholds_emp[[1]])
res$changepoints
</code></pre>

<hr>
<h2 id='ESAC_calibrate'>Generates empirical penalty function <code class="reqn">\gamma(t)</code> for the ESAC algorithm using Monte Carlo simulation</h2><span id='topic+ESAC_calibrate'></span>

<h3>Description</h3>

<p>R wrapper for C function choosing the penalty function <code class="reqn">\gamma(t)</code> by Monte Carlo simulation, as described in Appendix B in Moen et al. (2023).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ESAC_calibrate(
  n,
  p,
  alpha = 1.5,
  K = 5,
  N = 1000,
  tol = 0.001,
  bonferroni = TRUE,
  fast = FALSE,
  rescale_variance = TRUE,
  tdf = NULL,
  debug = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ESAC_calibrate_+3A_n">n</code></td>
<td>
<p>Number of observations</p>
</td></tr>
<tr><td><code id="ESAC_calibrate_+3A_p">p</code></td>
<td>
<p>Number time series</p>
</td></tr>
<tr><td><code id="ESAC_calibrate_+3A_alpha">alpha</code></td>
<td>
<p>Parameter for generating seeded intervals</p>
</td></tr>
<tr><td><code id="ESAC_calibrate_+3A_k">K</code></td>
<td>
<p>Parameter for generating seeded intervals</p>
</td></tr>
<tr><td><code id="ESAC_calibrate_+3A_n">N</code></td>
<td>
<p>Number of Monte Carlo samples used</p>
</td></tr>
<tr><td><code id="ESAC_calibrate_+3A_tol">tol</code></td>
<td>
<p>False error probability tolerance</p>
</td></tr>
<tr><td><code id="ESAC_calibrate_+3A_bonferroni">bonferroni</code></td>
<td>
<p>If <code>TRUE</code>, a Bonferroni correction applied and the empirical penalty function <code class="reqn">\gamma(t)</code> is chosen by simulating leading constants of <code class="reqn">r(t)</code> through Monte Carlo simulation.</p>
</td></tr>
<tr><td><code id="ESAC_calibrate_+3A_fast">fast</code></td>
<td>
<p>If <code>TRUE</code>, ESAC only tests for a change-point at the midpoint of each seeded interval</p>
</td></tr>
<tr><td><code id="ESAC_calibrate_+3A_rescale_variance">rescale_variance</code></td>
<td>
<p>If <code>TRUE</code>, each row of the data is re-scaled by a MAD estimate using <code><a href="#topic+rescale_variance">rescale_variance</a></code></p>
</td></tr>
<tr><td><code id="ESAC_calibrate_+3A_tdf">tdf</code></td>
<td>
<p>If NULL, samples are drawn from a Gaussian distribution. Otherwise, they are drawn from a <code class="reqn">t</code>
distribution with <code>tdf</code> degrees of freedom.</p>
</td></tr>
<tr><td><code id="ESAC_calibrate_+3A_debug">debug</code></td>
<td>
<p>If <code>TRUE</code>, diagnostic prints are provided during execution</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing 
</p>
<table>
<tr><td><code>without_partial</code></td>
<td>
<p> a vector of values of <code class="reqn">\gamma(t)</code> for <code class="reqn">t \in \mathcal{T}</code> decreasing in <code class="reqn">t</code></p>
</td></tr>
<tr><td><code>with_partial</code></td>
<td>
<p>same as <code>without_partial</code></p>
</td></tr>
<tr><td><code>as</code></td>
<td>
<p>vector of threshold values <code class="reqn">a(t)</code> for <code class="reqn">t \in \mathcal{T}</code> decreasing in <code class="reqn">t</code></p>
</td></tr>
<tr><td><code>nu_as</code></td>
<td>
<p>vector of conditional expectations <code class="reqn">\nu_{a(t)}</code> of a thresholded Gaussian, for <code class="reqn">t \in \mathcal{T}</code> decreasing in <code class="reqn">t</code></p>
</td></tr></table>
<p>#'
</p>


<h3>References</h3>

<p>Moen PAJ, Glad IK, Tveten M (2023).
&ldquo;Efficient sparsity adaptive changepoint estimation.&rdquo;
Arxiv preprint, 2306.04702, <a href="https://doi.org/10.48550/arXiv.2306.04702">https://doi.org/10.48550/arXiv.2306.04702</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(HDCD)
n = 50
p = 50

set.seed(100)
thresholds_emp = ESAC_calibrate(n,p, N=100, tol=1/100)
set.seed(100)
thresholds_emp_without_bonferroni = ESAC_calibrate(n,p, N=100, tol=1/100,bonferroni=FALSE)
thresholds_emp[[1]] # vector of \gamma(t) for t = p,...,1
thresholds_emp_without_bonferroni[[1]] # vector of \gamma(t) for t = p,...,1

# Generating data
X = matrix(rnorm(n*p), ncol = n, nrow=p)
# Adding a single sparse change-point:
X[1:5, 26:n] = X[1:5, 26:n] +2

res = ESAC(X, thresholds_test = thresholds_emp[[1]])
res$changepoints
</code></pre>

<hr>
<h2 id='ESAC_test'>ESAC single change-point test</h2><span id='topic+ESAC_test'></span>

<h3>Description</h3>

<p>R wrapper for C function testing for a single change-point using ESAC (see Moen et al. 2023).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ESAC_test(
  X,
  threshold_d = 1.5,
  threshold_s = 1,
  debug = FALSE,
  empirical = FALSE,
  thresholds = NULL,
  fast = FALSE,
  tol = 0.001,
  N = 1000,
  rescale_variance = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ESAC_test_+3A_x">X</code></td>
<td>
<p>Matrix of observations, where each row contains a time series</p>
</td></tr>
<tr><td><code id="ESAC_test_+3A_threshold_d">threshold_d</code></td>
<td>
<p>Leading constant for <code class="reqn">\gamma(t) \propto r(t)</code> for <code class="reqn">t=p</code>.  Only relevant when <code>empirical=FALSE</code> and <code>thresholds=NULL</code></p>
</td></tr>
<tr><td><code id="ESAC_test_+3A_threshold_s">threshold_s</code></td>
<td>
<p>Leading constant for <code class="reqn">\gamma(t) \propto r(t)</code> for <code class="reqn">t\leq \sqrt{p\log n}</code>. Only relevant when <code>empirical=FALSE</code> and <code>thresholds=NULL</code></p>
</td></tr>
<tr><td><code id="ESAC_test_+3A_debug">debug</code></td>
<td>
<p>If <code>TRUE</code>, diagnostic prints are provided during execution</p>
</td></tr>
<tr><td><code id="ESAC_test_+3A_empirical">empirical</code></td>
<td>
<p>If <code>TRUE</code>, detection thresholds are based on Monte Carlo simulation using <code><a href="#topic+ESAC_test_calibrate">ESAC_test_calibrate</a></code></p>
</td></tr>
<tr><td><code id="ESAC_test_+3A_thresholds">thresholds</code></td>
<td>
<p>Vector of manually chosen values of <code class="reqn">\gamma(t)</code> for <code class="reqn">t \in \mathcal{T}</code>, decreasing in <code class="reqn">t</code></p>
</td></tr>
<tr><td><code id="ESAC_test_+3A_fast">fast</code></td>
<td>
<p>If <code>TRUE</code>, ESAC only tests for a change-point at the midpoint of each seeded interval</p>
</td></tr>
<tr><td><code id="ESAC_test_+3A_tol">tol</code></td>
<td>
<p>If <code>empirical=TRUE</code>, <code>tol</code> is the false error probability tolerance</p>
</td></tr>
<tr><td><code id="ESAC_test_+3A_n">N</code></td>
<td>
<p>If <code>empirical=TRUE</code>, <code>N</code> is the number of Monte Carlo samples used</p>
</td></tr>
<tr><td><code id="ESAC_test_+3A_rescale_variance">rescale_variance</code></td>
<td>
<p>If <code>TRUE</code>, each row of the data is re-scaled by a MAD estimate using <code><a href="#topic+rescale_variance">rescale_variance</a></code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>1 if a change-point is detected, 0 otherwise
</p>


<h3>References</h3>

<p>Moen PAJ, Glad IK, Tveten M (2023).
&ldquo;Efficient sparsity adaptive changepoint estimation.&rdquo;
Arxiv preprint, 2306.04702, <a href="https://doi.org/10.48550/arXiv.2306.04702">https://doi.org/10.48550/arXiv.2306.04702</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(HDCD)
n = 50
p = 50

# Generating data
X = matrix(rnorm(n*p), ncol = n, nrow=p)
Y = matrix(rnorm(n*p), ncol = n, nrow=p)

# Adding a single sparse change-point to X (and not Y):
X[1:5, 26:n] = X[1:5, 26:n] +1

# Vanilla ESAC:
resX = ESAC_test(X)
resX
resY = ESAC_test(Y)
resY

# Manually setting leading constants for \lambda(t) and \gamma(t)
resX = ESAC_test(X, 
                 threshold_d = 2, threshold_s = 2, #leading constants for \gamma(t)
)
resX 
resY = ESAC_test(Y, 
                 threshold_d = 2, threshold_s = 2, #leading constants for \gamma(t)
)
resY

# Empirical choice of thresholds:
resX = ESAC_test(X, empirical = TRUE, N = 100, tol = 1/100)
resX
resY = ESAC_test(Y, empirical = TRUE, N = 100, tol = 1/100)
resY

# Manual empirical choice of thresholds (equivalent to the above)
thresholds_test_emp = ESAC_test_calibrate(n,p, N=100, tol=1/100,bonferroni=TRUE)
resX = ESAC_test(X, thresholds = thresholds_test_emp[[1]])
resX
resY = ESAC_test(Y, thresholds = thresholds_test_emp[[1]])
resY
</code></pre>

<hr>
<h2 id='ESAC_test_calibrate'>Generates empirical penalty function <code class="reqn">\gamma(t)</code> for single change-point testing using Monte Carlo simulation</h2><span id='topic+ESAC_test_calibrate'></span>

<h3>Description</h3>

<p>R wrapper for C function choosing the penalty function <code class="reqn">\gamma(t)</code> by Monte Carlo simulation, as described in Appendix B in Moen et al. (2023), for testing for a single change-point.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ESAC_test_calibrate(
  n,
  p,
  bonferroni = TRUE,
  N = 1000,
  tol = 1/1000,
  fast = FALSE,
  rescale_variance = TRUE,
  debug = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ESAC_test_calibrate_+3A_n">n</code></td>
<td>
<p>Number of observations</p>
</td></tr>
<tr><td><code id="ESAC_test_calibrate_+3A_p">p</code></td>
<td>
<p>Number time series</p>
</td></tr>
<tr><td><code id="ESAC_test_calibrate_+3A_bonferroni">bonferroni</code></td>
<td>
<p>If <code>TRUE</code>, a Bonferroni correction applied and the empirical penalty function <code class="reqn">\gamma(t)</code> is chosen by simulating leading constants of <code class="reqn">r(t)</code> through Monte Carlo simulation.</p>
</td></tr>
<tr><td><code id="ESAC_test_calibrate_+3A_n">N</code></td>
<td>
<p>Number of Monte Carlo samples used</p>
</td></tr>
<tr><td><code id="ESAC_test_calibrate_+3A_tol">tol</code></td>
<td>
<p>False positive probability tolerance</p>
</td></tr>
<tr><td><code id="ESAC_test_calibrate_+3A_fast">fast</code></td>
<td>
<p>If <code>TRUE</code>, ESAC only tests for a change-point at the midpoint of the interval <code class="reqn">(0,\ldots,n]</code></p>
</td></tr>
<tr><td><code id="ESAC_test_calibrate_+3A_rescale_variance">rescale_variance</code></td>
<td>
<p>If <code>TRUE</code>, each row of the data is re-scaled by a MAD estimate using <code><a href="#topic+rescale_variance">rescale_variance</a></code></p>
</td></tr>
<tr><td><code id="ESAC_test_calibrate_+3A_debug">debug</code></td>
<td>
<p>If <code>TRUE</code>, diagnostic prints are provided during execution</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing a vector of values of <code class="reqn">\gamma(t)</code> for <code class="reqn">t \in \mathcal{T}</code> decreasing (element #1), a vector of corresponding values of the threshold <code class="reqn">a(t)</code> (element # 3), a vector of corresponding values of <code class="reqn">\nu_{a(t)}</code>
</p>
<p>A list containing 
</p>
<table>
<tr><td><code>without_partial</code></td>
<td>
<p> a vector of values of <code class="reqn">\gamma(t)</code> for <code class="reqn">t \in \mathcal{T}</code> decreasing in <code class="reqn">t</code></p>
</td></tr>
<tr><td><code>with_partial</code></td>
<td>
<p>same as <code>without_partial</code></p>
</td></tr>
<tr><td><code>as</code></td>
<td>
<p>vector of threshold values <code class="reqn">a(t)</code> for <code class="reqn">t \in \mathcal{T}</code> decreasing in <code class="reqn">t</code></p>
</td></tr>
<tr><td><code>nu_as</code></td>
<td>
<p>vector of conditional expectations <code class="reqn">\nu_{a(t)}</code> of a thresholded Gaussian, for <code class="reqn">t \in \mathcal{T}</code> decreasing in <code class="reqn">t</code></p>
</td></tr>
</table>


<h3>References</h3>

<p>Moen PAJ, Glad IK, Tveten M (2023).
&ldquo;Efficient sparsity adaptive changepoint estimation.&rdquo;
Arxiv preprint, 2306.04702, <a href="https://doi.org/10.48550/arXiv.2306.04702">https://doi.org/10.48550/arXiv.2306.04702</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(HDCD)
n = 50
p = 50

set.seed(100)
thresholds_emp = ESAC_test_calibrate(n,p, bonferroni=TRUE,N=100, tol=1/100)
set.seed(100)
thresholds_emp_without_bonferroni = ESAC_test_calibrate(n,p, bonferroni=FALSE,N=100, tol=1/100)
thresholds_emp[[1]] # vector of \gamma(t) for t = p,...,1
thresholds_emp_without_bonferroni[[1]] # vector of \gamma(t) for t = p,...,1

# Generating data
X = matrix(rnorm(n*p), ncol = n, nrow=p)
Y = matrix(rnorm(n*p), ncol = n, nrow=p)

# Adding a single sparse change-point to X (and not Y):
X[1:5, 26:n] = X[1:5, 26:n] +2
resX = ESAC_test(X, thresholds = thresholds_emp[[1]])
resX
resY = ESAC_test(Y,  thresholds = thresholds_emp[[1]])
resY
</code></pre>

<hr>
<h2 id='hausdorff'>Hausdorff distance between two sets</h2><span id='topic+hausdorff'></span>

<h3>Description</h3>

<p>Computes the Hausdorff distance between two sets represented as vectors <code>v1</code> and <code>v2</code>. If <code>v1 == NULL</code> and <code>v2 != NULL</code>, then the largest distance between an element of <code>v1</code> and the set <code class="reqn">\{1,n\}</code> is returned, and vice versa. If both vectors are <code>NULL</code>, <code>0</code> is returned.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hausdorff(v1, v2, n)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="hausdorff_+3A_v1">v1</code></td>
<td>
<p>Vector representing set 1</p>
</td></tr>
<tr><td><code id="hausdorff_+3A_v2">v2</code></td>
<td>
<p>Vector representing set 2</p>
</td></tr>
<tr><td><code id="hausdorff_+3A_n">n</code></td>
<td>
<p>Sample size (only relevant when either <code>v1</code> or <code>v2</code> is <code>NULL</code>)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The Hausdorff distance between <code>v1</code> and <code>v2</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(HDCD)
n = 400
true_changepoints = c(50,100)
est_changepoints = c(51,110)
hausdorff(true_changepoints, est_changepoints,n)
hausdorff(true_changepoints, NULL,n)
hausdorff(NULL, est_changepoints,n)
hausdorff(NULL,NULL)
</code></pre>

<hr>
<h2 id='Inspect'>Informative sparse projection for estimating change-points (Inspect)</h2><span id='topic+Inspect'></span>

<h3>Description</h3>

<p>R wrapper for C function implementing a Narrowest-Over-Threshold variant of Inspect Wang and Samworth (2018) as specified in Appendix C in Moen et al. (2023). Note that the algorithm is only implemented for <code class="reqn">\mathcal{S} = \mathcal{S}_2</code>, in the notation of Moen et al. (2023).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Inspect(
  X,
  lambda = NULL,
  xi = NULL,
  alpha = 1.5,
  K = 5,
  eps = 1e-10,
  empirical = FALSE,
  maxiter = 10000,
  N = 100,
  tol = 1/100,
  rescale_variance = TRUE,
  debug = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Inspect_+3A_x">X</code></td>
<td>
<p>Matrix of observations, where each row contains a time series</p>
</td></tr>
<tr><td><code id="Inspect_+3A_lambda">lambda</code></td>
<td>
<p>Manually specified value of <code class="reqn">\lambda</code> (can be <code>NULL</code>, in which case <code class="reqn">\lambda \gets \sqrt{\log(p\log n)/2}</code>)</p>
</td></tr>
<tr><td><code id="Inspect_+3A_xi">xi</code></td>
<td>
<p>Manually specified value of <code class="reqn">\xi</code> (can be NULL, in which case <code class="reqn">\xi \gets 4\sqrt{\log(np)}</code>)</p>
</td></tr>
<tr><td><code id="Inspect_+3A_alpha">alpha</code></td>
<td>
<p>Parameter for generating seeded intervals</p>
</td></tr>
<tr><td><code id="Inspect_+3A_k">K</code></td>
<td>
<p>Parameter for generating seeded intervals</p>
</td></tr>
<tr><td><code id="Inspect_+3A_eps">eps</code></td>
<td>
<p>Threshold for declaring numerical convergence of the power method</p>
</td></tr>
<tr><td><code id="Inspect_+3A_empirical">empirical</code></td>
<td>
<p>If <code>TRUE</code>, the detection threshold <code class="reqn">xi</code> is based on Monte Carlo simulation using <code><a href="#topic+Inspect_calibrate">Inspect_calibrate</a></code></p>
</td></tr>
<tr><td><code id="Inspect_+3A_maxiter">maxiter</code></td>
<td>
<p>Maximum number of iterations for the power method</p>
</td></tr>
<tr><td><code id="Inspect_+3A_n">N</code></td>
<td>
<p>If <code>empirical=TRUE</code>, <code>N</code> is the number of Monte Carlo samples used</p>
</td></tr>
<tr><td><code id="Inspect_+3A_tol">tol</code></td>
<td>
<p>If <code>empirical=TRUE</code>, <code>tol</code> is the false error probability tolerance</p>
</td></tr>
<tr><td><code id="Inspect_+3A_rescale_variance">rescale_variance</code></td>
<td>
<p>If <code>TRUE</code>, each row of the data is re-scaled by a MAD estimate using <code><a href="#topic+rescale_variance">rescale_variance</a></code></p>
</td></tr>
<tr><td><code id="Inspect_+3A_debug">debug</code></td>
<td>
<p>If <code>TRUE</code>, diagnostic prints are provided during execution</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing 
</p>
<table>
<tr><td><code>changepoints</code></td>
<td>
<p>vector of estimated change-points</p>
</td></tr>
<tr><td><code>changepointnumber</code></td>
<td>
<p>number of changepoints</p>
</td></tr>
<tr><td><code>CUSUMval</code></td>
<td>
<p>vector with the sparse projected CUSUMs corresponding to <code>changepoints</code></p>
</td></tr>
<tr><td><code>coordinates</code></td>
<td>
<p>a matrix of zeros and ones indicating which time series are affected by a change in mean, with each row corresponding to the change-point in <code>changepoints</code></p>
</td></tr>
<tr><td><code>scales</code></td>
<td>
<p>vector of estimated noise level for each series</p>
</td></tr>
</table>


<h3>References</h3>

<p>Moen PAJ, Glad IK, Tveten M (2023).
&ldquo;Efficient sparsity adaptive changepoint estimation.&rdquo;
Arxiv preprint, 2306.04702, <a href="https://doi.org/10.48550/arXiv.2306.04702">https://doi.org/10.48550/arXiv.2306.04702</a>.<br /><br /> Wang T, Samworth RJ (2018).
&ldquo;High dimensional change point estimation via sparse projection.&rdquo;
<em>Journal of the Royal Statistical Society: Series B (Statistical Methodology)</em>, <b>80</b>(1), 57&ndash;83.
ISSN 1467-9868, <a href="https://doi.org/10.1111/rssb.12243">doi:10.1111/rssb.12243</a>, <a href="https://rss.onlinelibrary.wiley.com/doi/abs/10.1111/rssb.12243">https://rss.onlinelibrary.wiley.com/doi/abs/10.1111/rssb.12243</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(HDCD)
n = 50
p = 50
set.seed(100)
# Generating data
X = matrix(rnorm(n*p), ncol = n, nrow=p)
# Adding a single sparse change-point:
X[1:5, 26:n] = X[1:5, 26:n] +1

# Vanilla Inspect:
res = Inspect(X)
res$changepoints

# Manually setting leading constants for \lambda(t) and \gamma(t)
res = Inspect(X, 
              lambda = sqrt(log(p*log(n))/2),
              xi = 4*sqrt(log(n*p))
)
res$changepoints #estimated change-point locations

# Empirical choice of thresholds:
res = Inspect(X, empirical=TRUE, N = 100, tol = 1/100)
res$changepoints

# Manual empirical choice of thresholds (equivalent to the above)
thresholds_emp = Inspect_calibrate(n,p, N=100, tol=1/100)
res = Inspect(X, xi = thresholds_emp$max_value)
res$changepoints
</code></pre>

<hr>
<h2 id='Inspect_calibrate'>Generates empirical detection threshold <code class="reqn">\xi</code> using Monte Carlo simulation</h2><span id='topic+Inspect_calibrate'></span>

<h3>Description</h3>

<p>R wrapper for C function choosing empirical detection threshold <code class="reqn">\xi</code> for the Narrowest-Over-Threshold variant of Inspect (as specified in section 4.2 in Moen et al. 2023) using Monte Carlo simulation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Inspect_calibrate(
  n,
  p,
  N = 100,
  tol = 1/100,
  lambda = NULL,
  alpha = 1.5,
  K = 5,
  eps = 1e-10,
  maxiter = 10000,
  rescale_variance = TRUE,
  debug = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Inspect_calibrate_+3A_n">n</code></td>
<td>
<p>Number of observations</p>
</td></tr>
<tr><td><code id="Inspect_calibrate_+3A_p">p</code></td>
<td>
<p>Number time series</p>
</td></tr>
<tr><td><code id="Inspect_calibrate_+3A_n">N</code></td>
<td>
<p>Number of Monte Carlo samples used</p>
</td></tr>
<tr><td><code id="Inspect_calibrate_+3A_tol">tol</code></td>
<td>
<p>False positive probability tolerance</p>
</td></tr>
<tr><td><code id="Inspect_calibrate_+3A_lambda">lambda</code></td>
<td>
<p>Manually specified value of <code class="reqn">\lambda</code> (can be <code>NULL</code>, in which case <code class="reqn">\lambda \gets \sqrt{\log(p\log n)/2}</code>)</p>
</td></tr>
<tr><td><code id="Inspect_calibrate_+3A_alpha">alpha</code></td>
<td>
<p>Parameter for generating seeded intervals</p>
</td></tr>
<tr><td><code id="Inspect_calibrate_+3A_k">K</code></td>
<td>
<p>Parameter for generating seeded intervals</p>
</td></tr>
<tr><td><code id="Inspect_calibrate_+3A_eps">eps</code></td>
<td>
<p>Threshold for declaring numerical convergence of the power method</p>
</td></tr>
<tr><td><code id="Inspect_calibrate_+3A_maxiter">maxiter</code></td>
<td>
<p>Maximum number of iterations for the power method</p>
</td></tr>
<tr><td><code id="Inspect_calibrate_+3A_rescale_variance">rescale_variance</code></td>
<td>
<p>If <code>TRUE</code>, each row of the data is re-scaled by a MAD estimate using <code><a href="#topic+rescale_variance">rescale_variance</a></code></p>
</td></tr>
<tr><td><code id="Inspect_calibrate_+3A_debug">debug</code></td>
<td>
<p>If <code>TRUE</code>, diagnostic prints are provided during execution</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing 
</p>
<table>
<tr><td><code>max_value</code></td>
<td>
<p>the empirical threshold</p>
</td></tr>
</table>


<h3>References</h3>

<p>Moen PAJ, Glad IK, Tveten M (2023).
&ldquo;Efficient sparsity adaptive changepoint estimation.&rdquo;
Arxiv preprint, 2306.04702, <a href="https://doi.org/10.48550/arXiv.2306.04702">https://doi.org/10.48550/arXiv.2306.04702</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(HDCD)
n = 50
p = 50

set.seed(100)
thresholds_emp = Inspect_calibrate(n,p, N=100, tol=1/100)
thresholds_emp$max_value # xi

# Generating data
X = matrix(rnorm(n*p), ncol = n, nrow=p)
# Adding a single sparse change-point:
X[1:5, 26:n] = X[1:5, 26:n] +2

res = Inspect(X, xi = thresholds_emp$max_value)
res$changepoints
</code></pre>

<hr>
<h2 id='Inspect_test'>Inspect single change-point test</h2><span id='topic+Inspect_test'></span>

<h3>Description</h3>

<p>R wrapper for C function testing for a single change-point using Inspect Wang and Samworth (2018).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Inspect_test(
  X,
  lambda = NULL,
  xi = NULL,
  eps = 1e-10,
  empirical = FALSE,
  N = 100,
  tol = 1/100,
  maxiter = 10000,
  rescale_variance = TRUE,
  debug = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Inspect_test_+3A_x">X</code></td>
<td>
<p>Matrix of observations, where each row contains a time series</p>
</td></tr>
<tr><td><code id="Inspect_test_+3A_lambda">lambda</code></td>
<td>
<p>Manually specified value of <code class="reqn">\lambda</code> (can be <code>NULL</code>, in which case <code class="reqn">\lambda \gets \sqrt{\log(p\log n)/2}</code>)</p>
</td></tr>
<tr><td><code id="Inspect_test_+3A_xi">xi</code></td>
<td>
<p>Manually specified value of <code class="reqn">\xi</code> (can be NULL, in which case <code class="reqn">\xi \gets 4\sqrt{\log(np)}</code>)</p>
</td></tr>
<tr><td><code id="Inspect_test_+3A_eps">eps</code></td>
<td>
<p>Threshold for declaring numerical convergence of the power method</p>
</td></tr>
<tr><td><code id="Inspect_test_+3A_empirical">empirical</code></td>
<td>
<p>If <code>TRUE</code>, the detection threshold <code class="reqn">xi</code> is based on Monte Carlo simulation using <code><a href="#topic+Inspect_test_calibrate">Inspect_test_calibrate</a></code></p>
</td></tr>
<tr><td><code id="Inspect_test_+3A_n">N</code></td>
<td>
<p>If <code>empirical=TRUE</code>, <code>N</code> is the number of Monte Carlo samples used</p>
</td></tr>
<tr><td><code id="Inspect_test_+3A_tol">tol</code></td>
<td>
<p>If <code>empirical=TRUE</code>, <code>tol</code> is the false error probability tolerance</p>
</td></tr>
<tr><td><code id="Inspect_test_+3A_maxiter">maxiter</code></td>
<td>
<p>Maximum number of iterations for the power method</p>
</td></tr>
<tr><td><code id="Inspect_test_+3A_rescale_variance">rescale_variance</code></td>
<td>
<p>If <code>TRUE</code>, each row of the data is re-scaled by a MAD estimate using <code><a href="#topic+rescale_variance">rescale_variance</a></code></p>
</td></tr>
<tr><td><code id="Inspect_test_+3A_debug">debug</code></td>
<td>
<p>If <code>TRUE</code>, diagnostic prints are provided during execution</p>
</td></tr>
</table>


<h3>Value</h3>

<p>1 if a change-point is detected, 0 otherwise
</p>


<h3>References</h3>

<p>Wang T, Samworth RJ (2018).
&ldquo;High dimensional change point estimation via sparse projection.&rdquo;
<em>Journal of the Royal Statistical Society: Series B (Statistical Methodology)</em>, <b>80</b>(1), 57&ndash;83.
ISSN 1467-9868, <a href="https://doi.org/10.1111/rssb.12243">doi:10.1111/rssb.12243</a>, <a href="https://rss.onlinelibrary.wiley.com/doi/abs/10.1111/rssb.12243">https://rss.onlinelibrary.wiley.com/doi/abs/10.1111/rssb.12243</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(HDCD)
n = 50
p = 50

# Generating data
X = matrix(rnorm(n*p), ncol = n, nrow=p)
Y = matrix(rnorm(n*p), ncol = n, nrow=p)

# Adding a single sparse change-point to X (and not Y):
X[1:5, 26:n] = X[1:5, 26:n] +1

# Vanilla Inspect:
resX = Inspect_test(X)
resX
resY = Inspect_test(Y)
resY

# Manually setting \lambda and \xi:
resX = Inspect_test(X, 
                    lambda = sqrt(log(p*log(n))/2),
                    xi = 4*sqrt(log(n*p))
)
resX 
resY = Inspect_test(Y, 
                    lambda = sqrt(log(p*log(n))/2),
                    xi = 4*sqrt(log(n*p))
)
resY

# Empirical choice of thresholds:
resX = Inspect_test(X, empirical = TRUE, N = 100, tol = 1/100)
resX
resY = Inspect_test(Y, empirical = TRUE, N = 100, tol = 1/100)
resY

# Manual empirical choice of thresholds (equivalent to the above)
thresholds_test_emp = Inspect_test_calibrate(n,p, N=100, tol=1/100)
resX = Inspect_test(X, xi = thresholds_test_emp$max_value)
resX
resY = Inspect_test(Y, xi = thresholds_test_emp$max_value)
resY
</code></pre>

<hr>
<h2 id='Inspect_test_calibrate'>Generates empirical detection threshold <code class="reqn">\xi</code> for single change-point testing using Monte Carlo simulation</h2><span id='topic+Inspect_test_calibrate'></span>

<h3>Description</h3>

<p>R wrapper for C function choosing the empirical detection threshold <code class="reqn">\xi</code> for Inspect Wang and Samworth (2018) for single change-point testing using Monte Carlo simulation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Inspect_test_calibrate(
  n,
  p,
  N = 100,
  tol = 1/100,
  lambda = NULL,
  eps = 1e-10,
  maxiter = 10000,
  rescale_variance = TRUE,
  debug = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Inspect_test_calibrate_+3A_n">n</code></td>
<td>
<p>Number of observations</p>
</td></tr>
<tr><td><code id="Inspect_test_calibrate_+3A_p">p</code></td>
<td>
<p>Number time series</p>
</td></tr>
<tr><td><code id="Inspect_test_calibrate_+3A_n">N</code></td>
<td>
<p>Number of Monte Carlo samples used</p>
</td></tr>
<tr><td><code id="Inspect_test_calibrate_+3A_tol">tol</code></td>
<td>
<p>False positive probability tolerance</p>
</td></tr>
<tr><td><code id="Inspect_test_calibrate_+3A_lambda">lambda</code></td>
<td>
<p>Manually specified value of <code class="reqn">\lambda</code> (can be <code>NULL</code>, in which case <code class="reqn">\lambda \gets \sqrt{\log(p\log n)/2}</code>)</p>
</td></tr>
<tr><td><code id="Inspect_test_calibrate_+3A_eps">eps</code></td>
<td>
<p>Threshold for declaring numerical convergence of the power method</p>
</td></tr>
<tr><td><code id="Inspect_test_calibrate_+3A_maxiter">maxiter</code></td>
<td>
<p>Maximum number of iterations for the power method</p>
</td></tr>
<tr><td><code id="Inspect_test_calibrate_+3A_rescale_variance">rescale_variance</code></td>
<td>
<p>If <code>TRUE</code>, each row of the data is re-scaled by a MAD estimate using <code><a href="#topic+rescale_variance">rescale_variance</a></code></p>
</td></tr>
<tr><td><code id="Inspect_test_calibrate_+3A_debug">debug</code></td>
<td>
<p>If <code>TRUE</code>, diagnostic prints are provided during execution</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing 
</p>
<table>
<tr><td><code>max_value</code></td>
<td>
<p>the empirical threshold</p>
</td></tr>
</table>


<h3>References</h3>

<p>Wang T, Samworth RJ (2018).
&ldquo;High dimensional change point estimation via sparse projection.&rdquo;
<em>Journal of the Royal Statistical Society: Series B (Statistical Methodology)</em>, <b>80</b>(1), 57&ndash;83.
ISSN 1467-9868, <a href="https://doi.org/10.1111/rssb.12243">doi:10.1111/rssb.12243</a>, <a href="https://rss.onlinelibrary.wiley.com/doi/abs/10.1111/rssb.12243">https://rss.onlinelibrary.wiley.com/doi/abs/10.1111/rssb.12243</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(HDCD)
n = 50
p = 50

set.seed(100)
thresholds_emp = Inspect_test_calibrate(n,p,N=100, tol=1/100)
thresholds_emp


# Generating data
X = matrix(rnorm(n*p), ncol = n, nrow=p)
Y = matrix(rnorm(n*p), ncol = n, nrow=p)

# Adding a single sparse change-point to X (and not Y):
X[1:5, 26:n] = X[1:5, 26:n] +2
resX = Inspect_test(X, xi = thresholds_emp$max_value)
resX
resY = Inspect_test(Y,  xi = thresholds_emp$max_value)
resY
</code></pre>

<hr>
<h2 id='Pilliat'>Pilliat multiple change-point detection algorithm</h2><span id='topic+Pilliat'></span>

<h3>Description</h3>

<p>R wrapper function for C implementation of the multiple change-point detection algorithm by Pilliat et al. (2023), using seeded intervals generated by Algorithm 4 in Moen et al. (2023). For the sake of simplicity, detection thresholds are chosen independently of the width of the interval in which a change-point is tested for (so <code class="reqn">r=1</code> is set for all intervals).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Pilliat(
  X,
  threshold_d_const = 4,
  threshold_bj_const = 6,
  threshold_partial_const = 4,
  K = 2,
  alpha = 1.5,
  empirical = FALSE,
  threshold_dense = NULL,
  thresholds_partial = NULL,
  thresholds_bj = NULL,
  N = 100,
  tol = 0.01,
  rescale_variance = TRUE,
  test_all = FALSE,
  debug = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Pilliat_+3A_x">X</code></td>
<td>
<p>Matrix of observations, where each row contains a time series</p>
</td></tr>
<tr><td><code id="Pilliat_+3A_threshold_d_const">threshold_d_const</code></td>
<td>
<p>Leading constant for the analytical detection threshold for the dense statistic</p>
</td></tr>
<tr><td><code id="Pilliat_+3A_threshold_bj_const">threshold_bj_const</code></td>
<td>
<p>Leading constant for <code class="reqn">p_0</code> when computing the detection threshold for the Berk-Jones statistic</p>
</td></tr>
<tr><td><code id="Pilliat_+3A_threshold_partial_const">threshold_partial_const</code></td>
<td>
<p>Leading constant for the analytical detection threshold for the partial sum statistic</p>
</td></tr>
<tr><td><code id="Pilliat_+3A_k">K</code></td>
<td>
<p>Parameter for generating seeded intervals</p>
</td></tr>
<tr><td><code id="Pilliat_+3A_alpha">alpha</code></td>
<td>
<p>Parameter for generating seeded intervals</p>
</td></tr>
<tr><td><code id="Pilliat_+3A_empirical">empirical</code></td>
<td>
<p>If <code>TRUE</code>, detection thresholds are based on Monte Carlo simulation using <code><a href="#topic+Pilliat_calibrate">Pilliat_calibrate</a></code></p>
</td></tr>
<tr><td><code id="Pilliat_+3A_threshold_dense">threshold_dense</code></td>
<td>
<p>Manually specified value of detection threshold for the dense statistic</p>
</td></tr>
<tr><td><code id="Pilliat_+3A_thresholds_partial">thresholds_partial</code></td>
<td>
<p>Vector of manually specified detection thresholds for the partial sum statistic, for sparsities/partial sums <code class="reqn">t=1,2,4,\ldots,2^{\lfloor \log_2(p)\rfloor} </code></p>
</td></tr>
<tr><td><code id="Pilliat_+3A_thresholds_bj">thresholds_bj</code></td>
<td>
<p>Vector of manually specified detection thresholds for the Berk-Jones statistic, order corresponding to <code class="reqn">x=1,2,\ldots,x_0</code></p>
</td></tr>
<tr><td><code id="Pilliat_+3A_n">N</code></td>
<td>
<p>If <code>empirical=TRUE</code>, <code>N</code> is the number of Monte Carlo samples used</p>
</td></tr>
<tr><td><code id="Pilliat_+3A_tol">tol</code></td>
<td>
<p>If <code>empirical=TRUE</code>, <code>tol</code> is the false error probability tolerance</p>
</td></tr>
<tr><td><code id="Pilliat_+3A_rescale_variance">rescale_variance</code></td>
<td>
<p>If <code>TRUE</code>, each row of the data is re-scaled by a MAD estimate (see <code><a href="#topic+rescale_variance">rescale_variance</a></code>)</p>
</td></tr>
<tr><td><code id="Pilliat_+3A_test_all">test_all</code></td>
<td>
<p>If <code>TRUE</code>, the algorithm tests for a change-point in all candidate positions of each considered interval</p>
</td></tr>
<tr><td><code id="Pilliat_+3A_debug">debug</code></td>
<td>
<p>If <code>TRUE</code>, diagnostic prints are provided during execution</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing 
</p>
<table>
<tr><td><code>changepoints</code></td>
<td>
<p>vector of estimated change-points</p>
</td></tr>
<tr><td><code>number_of_changepoints</code></td>
<td>
<p>number of changepoints</p>
</td></tr>
<tr><td><code>scales</code></td>
<td>
<p>vector of estimated noise level for each series</p>
</td></tr>
<tr><td><code>startpoints</code></td>
<td>
<p>start point of the seeded interval detecting the corresponding change-point in <code>changepoints</code></p>
</td></tr>
<tr><td><code>endpoints</code></td>
<td>
<p>end point of the seeded interval detecting the corresponding change-point in <code>changepoints</code></p>
</td></tr>
</table>


<h3>References</h3>

<p>Moen PAJ, Glad IK, Tveten M (2023).
&ldquo;Efficient sparsity adaptive changepoint estimation.&rdquo;
Arxiv preprint, 2306.04702, <a href="https://doi.org/10.48550/arXiv.2306.04702">https://doi.org/10.48550/arXiv.2306.04702</a>.<br /><br /> Pilliat E, Carpentier A, Verzelen N (2023).
&ldquo;Optimal multiple change-point detection for high-dimensional data.&rdquo;
<em>Electronic Journal of Statistics</em>, <b>17</b>(1), 1240 &ndash; 1315.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(HDCD)
n = 50
p = 50
set.seed(100)
# Generating data
X = matrix(rnorm(n*p), ncol = n, nrow=p)
# Adding a single sparse change-point:
X[1:5, 26:n] = X[1:5, 26:n] +2

# Vanilla Pilliat:
res = Pilliat(X)
res$changepoints

# Manually setting leading constants for detection thresholds
res = Pilliat(X, threshold_d_const = 4, threshold_bj_const = 6, threshold_partial_const=4)
res$changepoints #estimated change-point locations

# Empirical choice of thresholds:
res = Pilliat(X, empirical = TRUE, N = 100, tol = 1/100)
res$changepoints

# Manual empirical choice of thresholds (equivalent to the above)
thresholds_emp = Pilliat_calibrate(n,p, N=100, tol=1/100)
thresholds_emp$thresholds_partial # thresholds for partial sum statistic
thresholds_emp$thresholds_bj # thresholds for Berk-Jones statistic
thresholds_emp$threshold_dense # thresholds for Berk-Jones statistic
res = Pilliat(X, threshold_dense =thresholds_emp$threshold_dense, 
              thresholds_bj = thresholds_emp$thresholds_bj,
              thresholds_partial =thresholds_emp$thresholds_partial )
res$changepoints
</code></pre>

<hr>
<h2 id='Pilliat_calibrate'>Generates detection thresholds for the Pilliat algorithm using Monte Carlo simulation</h2><span id='topic+Pilliat_calibrate'></span>

<h3>Description</h3>

<p>R wrapper for function choosing detection thresholds for the Dense, Partial sum and Berk-Jones statistics in the multiple change-point detection algorithm of Pilliat et al. (2023) using Monte Carlo simulation. When <code>Bonferroni==TRUE</code>, the detection thresholds are chosen by simulating the leading constant in the theoretical detection thresholds given in Pilliat et al. (2023), similarly as described in Appendix B in Moen et al. (2023) for ESAC. When <code>Bonferroni==TRUE</code>, the thresholds for the Berk-Jones statistic are theoretical and not chosen by Monte Carlo simulation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Pilliat_calibrate(
  n,
  p,
  N = 100,
  tol = 0.01,
  bonferroni = TRUE,
  threshold_bj_const = 6,
  K = 2,
  alpha = 1.5,
  rescale_variance = TRUE,
  test_all = FALSE,
  debug = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Pilliat_calibrate_+3A_n">n</code></td>
<td>
<p>Number of observations</p>
</td></tr>
<tr><td><code id="Pilliat_calibrate_+3A_p">p</code></td>
<td>
<p>Number time series</p>
</td></tr>
<tr><td><code id="Pilliat_calibrate_+3A_n">N</code></td>
<td>
<p>Number of Monte Carlo samples used</p>
</td></tr>
<tr><td><code id="Pilliat_calibrate_+3A_tol">tol</code></td>
<td>
<p>False error probability tolerance</p>
</td></tr>
<tr><td><code id="Pilliat_calibrate_+3A_bonferroni">bonferroni</code></td>
<td>
<p>If <code>TRUE</code>, a Bonferroni correction applied and the detection thresholds for each statistic is chosen by simulating the leading constant in the theoretical detection thresholds</p>
</td></tr>
<tr><td><code id="Pilliat_calibrate_+3A_threshold_bj_const">threshold_bj_const</code></td>
<td>
<p>Leading constant for <code class="reqn">p_0</code> for the Berk-Jones statistic</p>
</td></tr>
<tr><td><code id="Pilliat_calibrate_+3A_k">K</code></td>
<td>
<p>Parameter for generating seeded intervals</p>
</td></tr>
<tr><td><code id="Pilliat_calibrate_+3A_alpha">alpha</code></td>
<td>
<p>Parameter for generating seeded intervals</p>
</td></tr>
<tr><td><code id="Pilliat_calibrate_+3A_rescale_variance">rescale_variance</code></td>
<td>
<p>If <code>TRUE</code>, each row of the data is re-scaled by a MAD estimate (see <code><a href="#topic+rescale_variance">rescale_variance</a></code>)</p>
</td></tr>
<tr><td><code id="Pilliat_calibrate_+3A_test_all">test_all</code></td>
<td>
<p>If <code>TRUE</code>, a change-point test is applied to each candidate change-point position in each interval. If <code>FALSE</code>, only the mid-point of each interval is considered</p>
</td></tr>
<tr><td><code id="Pilliat_calibrate_+3A_debug">debug</code></td>
<td>
<p>If <code>TRUE</code>, diagnostic prints are provided during execution</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing 
</p>
<table>
<tr><td><code>thresholds_partial</code></td>
<td>
<p>vector of thresholds for the Partial Sum statistic (respectively for <code class="reqn">t=1,2,4,\ldots,2^{\lfloor\log_2(p)\rfloor}</code> number of terms in the partial sum)</p>
</td></tr>
<tr><td><code>threshold_dense</code></td>
<td>
<p>threshold for the dense statistic</p>
</td></tr>
<tr><td><code>thresholds_bj</code></td>
<td>
<p>vector of thresholds for the Berk-Jones static (respectively for <code class="reqn">x=1,2,\ldots,x_0</code>)</p>
</td></tr>
</table>


<h3>References</h3>

<p>Moen PAJ, Glad IK, Tveten M (2023).
&ldquo;Efficient sparsity adaptive changepoint estimation.&rdquo;
Arxiv preprint, 2306.04702, <a href="https://doi.org/10.48550/arXiv.2306.04702">https://doi.org/10.48550/arXiv.2306.04702</a>.<br /><br /> Pilliat E, Carpentier A, Verzelen N (2023).
&ldquo;Optimal multiple change-point detection for high-dimensional data.&rdquo;
<em>Electronic Journal of Statistics</em>, <b>17</b>(1), 1240 &ndash; 1315.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(HDCD)
n = 50
p = 50

set.seed(100)
thresholds_emp = Pilliat_calibrate(n,p, N=100, tol=1/100)
thresholds_emp$thresholds_partial # thresholds for partial sum statistic
thresholds_emp$thresholds_bj # thresholds for Berk-Jones statistic
thresholds_emp$threshold_dense # thresholds for Berk-Jones statistic
set.seed(100)
thresholds_emp_without_bonferroni = Pilliat_calibrate(n,p, N=100, tol=1/100,bonferroni = FALSE)
thresholds_emp_without_bonferroni$thresholds_partial # thresholds for partial sum statistic
thresholds_emp_without_bonferroni$thresholds_bj # thresholds for Berk-Jones statistic
thresholds_emp_without_bonferroni$threshold_dense # thresholds for Berk-Jones statistic

# Generating data
X = matrix(rnorm(n*p), ncol = n, nrow=p)
# Adding a single sparse change-point:
X[1:5, 26:n] = X[1:5, 26:n] +2

res = Pilliat(X, threshold_dense =thresholds_emp$threshold_dense, 
              thresholds_bj = thresholds_emp$thresholds_bj,
              thresholds_partial =thresholds_emp$thresholds_partial )
res$changepoints
</code></pre>

<hr>
<h2 id='Pilliat_test'>Pilliat single change-point test</h2><span id='topic+Pilliat_test'></span>

<h3>Description</h3>

<p>R wrapper function testing for a single change-point using the three test statistics in the multiple change point detection algorithm of Pilliat et al. (2023). See also Appendix E in Moen et al. (2023).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Pilliat_test(
  X,
  empirical = FALSE,
  N = 100,
  tol = 0.05,
  thresholds_partial = NULL,
  threshold_dense = NULL,
  thresholds_bj = NULL,
  threshold_d_const = 4,
  threshold_bj_const = 6,
  threshold_partial_const = 4,
  rescale_variance = TRUE,
  fast = FALSE,
  debug = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Pilliat_test_+3A_x">X</code></td>
<td>
<p>Matrix of observations, where each row contains a time series</p>
</td></tr>
<tr><td><code id="Pilliat_test_+3A_empirical">empirical</code></td>
<td>
<p>If <code>TRUE</code>, detection thresholds are based on Monte Carlo simulation</p>
</td></tr>
<tr><td><code id="Pilliat_test_+3A_n">N</code></td>
<td>
<p>If <code>empirical=TRUE</code>, <code>N</code> is the number of Monte Carlo samples used</p>
</td></tr>
<tr><td><code id="Pilliat_test_+3A_tol">tol</code></td>
<td>
<p>If <code>empirical=TRUE</code>, <code>tol</code> is the false error probability tolerance</p>
</td></tr>
<tr><td><code id="Pilliat_test_+3A_thresholds_partial">thresholds_partial</code></td>
<td>
<p>Vector of manually specified detection thresholds for the partial sum statistic, for sparsities/partial sums <code class="reqn">t=1,2,4,\ldots,2^{\lfloor\log_2(p)\rfloor}</code></p>
</td></tr>
<tr><td><code id="Pilliat_test_+3A_threshold_dense">threshold_dense</code></td>
<td>
<p>Manually specified value of detection threshold for the dense statistic</p>
</td></tr>
<tr><td><code id="Pilliat_test_+3A_thresholds_bj">thresholds_bj</code></td>
<td>
<p>Vector of manually specified detection thresholds for the Berk-Jones statistic, order corresponding to <code class="reqn">x=1,2,\ldots,x_0</code></p>
</td></tr>
<tr><td><code id="Pilliat_test_+3A_threshold_d_const">threshold_d_const</code></td>
<td>
<p>Leading constant for the analytical detection threshold for the dense statistic</p>
</td></tr>
<tr><td><code id="Pilliat_test_+3A_threshold_bj_const">threshold_bj_const</code></td>
<td>
<p>Leading constant for <code class="reqn">p_0</code> when computing the detection threshold for the Berk-Jones statistic</p>
</td></tr>
<tr><td><code id="Pilliat_test_+3A_threshold_partial_const">threshold_partial_const</code></td>
<td>
<p>Leading constant for the analytical detection threshold for the partial sum statistic</p>
</td></tr>
<tr><td><code id="Pilliat_test_+3A_rescale_variance">rescale_variance</code></td>
<td>
<p>If <code>TRUE</code>, each row of the data is re-scaled by a MAD estimate (see <code><a href="#topic+rescale_variance">rescale_variance</a></code>)</p>
</td></tr>
<tr><td><code id="Pilliat_test_+3A_fast">fast</code></td>
<td>
<p>If <code>TRUE</code>, only the mid-point of <code class="reqn">(0,\ldots,n]</code> is tested for a change-point. Otherwise a test is performed at each candidate change-point poisition</p>
</td></tr>
<tr><td><code id="Pilliat_test_+3A_debug">debug</code></td>
<td>
<p>If <code>TRUE</code>, diagnostic prints are provided during execution</p>
</td></tr>
</table>


<h3>Value</h3>

<p>1 if a change-point is detected, 0 otherwise
</p>


<h3>References</h3>

<p>Moen PAJ, Glad IK, Tveten M (2023).
&ldquo;Efficient sparsity adaptive changepoint estimation.&rdquo;
Arxiv preprint, 2306.04702, <a href="https://doi.org/10.48550/arXiv.2306.04702">https://doi.org/10.48550/arXiv.2306.04702</a>.<br /><br /> Pilliat E, Carpentier A, Verzelen N (2023).
&ldquo;Optimal multiple change-point detection for high-dimensional data.&rdquo;
<em>Electronic Journal of Statistics</em>, <b>17</b>(1), 1240 &ndash; 1315.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(HDCD)
n = 200
p = 200

# Generating data
X = matrix(rnorm(n*p), ncol = n, nrow=p)
Y = matrix(rnorm(n*p), ncol = n, nrow=p)

# Adding a single sparse change-point to X (and not Y):
X[1:5, 100:200] = X[1:5, 100:200] +1

# Vanilla Pilliat test:
resX = Pilliat_test(X)
resX
resY = Pilliat_test(Y)
resY

# Manually setting leading constants for the theoretical thresholds for the three 
# test statistics used
resX = Pilliat_test(X, 
                    threshold_d_const=4, 
                    threshold_bj_const=6, 
                    threshold_partial_const=4
)
resX 
resY = Pilliat_test(Y, 
                    threshold_d_const=4, 
                    threshold_bj_const=6, 
                    threshold_partial_const=4
)
resY

# Empirical choice of thresholds:
resX = Pilliat_test(X, empirical = TRUE, N = 100, tol = 1/100)
resX
resY = Pilliat_test(Y, empirical = TRUE, N = 100, tol = 1/100)
resY

# Manual empirical choice of thresholds (equivalent to the above)
thresholds_test_emp = Pilliat_test_calibrate(n,p, N=100, tol=1/100,bonferroni=TRUE)
resX = Pilliat_test(X, 
                    threshold_dense=thresholds_test_emp$threshold_dense, 
                    thresholds_bj = thresholds_test_emp$thresholds_bj, 
                    thresholds_partial = thresholds_test_emp$thresholds_partial
)
resX
resY = Pilliat_test(Y, 
                    threshold_dense=thresholds_test_emp$threshold_dense, 
                    thresholds_bj = thresholds_test_emp$thresholds_bj, 
                    thresholds_partial = thresholds_test_emp$thresholds_partial
)
resY
</code></pre>

<hr>
<h2 id='Pilliat_test_calibrate'>Generates detection thresholds for the Pilliat algorithm for testing for a single change-point using Monte Carlo simulation</h2><span id='topic+Pilliat_test_calibrate'></span>

<h3>Description</h3>

<p>R wrapper for function choosing detection thresholds for the Dense, Partial sum and Berk-Jones statistics in the multiple change-point detection algorithm of Pilliat et al. (2023) for single change-point testing using Monte Carlo simulation. When <code>Bonferroni==TRUE</code>, the detection thresholds are chosen by simulating the leading constant in the theoretical detection thresholds given in Pilliat et al. (2023), similarly as described in Appendix B in Moen et al. (2023) for ESAC. When <code>Bonferroni==TRUE</code>, the thresholds for the Berk-Jones statistic are theoretical and not chosen by Monte Carlo simulation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Pilliat_test_calibrate(
  n,
  p,
  N = 100,
  tol = 1/100,
  threshold_bj_const = 6,
  bonferroni = TRUE,
  rescale_variance = TRUE,
  fast = FALSE,
  debug = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Pilliat_test_calibrate_+3A_n">n</code></td>
<td>
<p>Number of observations</p>
</td></tr>
<tr><td><code id="Pilliat_test_calibrate_+3A_p">p</code></td>
<td>
<p>Number time series</p>
</td></tr>
<tr><td><code id="Pilliat_test_calibrate_+3A_n">N</code></td>
<td>
<p>Number of Monte Carlo samples used</p>
</td></tr>
<tr><td><code id="Pilliat_test_calibrate_+3A_tol">tol</code></td>
<td>
<p>False error probability tolerance</p>
</td></tr>
<tr><td><code id="Pilliat_test_calibrate_+3A_threshold_bj_const">threshold_bj_const</code></td>
<td>
<p>Leading constant for <code class="reqn">p_0</code> for the Berk-Jones statistic</p>
</td></tr>
<tr><td><code id="Pilliat_test_calibrate_+3A_bonferroni">bonferroni</code></td>
<td>
<p>If <code>TRUE</code>, a Bonferroni correction applied and the detection thresholds for each statistic is chosen by simulating the leading constant in the theoretical detection thresholds</p>
</td></tr>
<tr><td><code id="Pilliat_test_calibrate_+3A_rescale_variance">rescale_variance</code></td>
<td>
<p>If <code>TRUE</code>, each row of the data is rescaled by a MAD estimate</p>
</td></tr>
<tr><td><code id="Pilliat_test_calibrate_+3A_fast">fast</code></td>
<td>
<p>If <code>FALSE</code>, a change-point test is applied to each candidate change-point position in each interval. If FALSE, only the mid-point of each interval is considered</p>
</td></tr>
<tr><td><code id="Pilliat_test_calibrate_+3A_debug">debug</code></td>
<td>
<p>If <code>TRUE</code>, diagnostic prints are provided during execution</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing 
</p>
<table>
<tr><td><code>thresholds_partial</code></td>
<td>
<p>vector of thresholds for the Partial Sum statistic (respectively for <code class="reqn">t=1,2,4,\ldots,2^{\lfloor\log_2(p)\rfloor}</code> number of terms in the partial sum)</p>
</td></tr>
<tr><td><code>threshold_dense</code></td>
<td>
<p>threshold for the dense statistic</p>
</td></tr>
<tr><td><code>thresholds_bj</code></td>
<td>
<p>vector of thresholds for the Berk-Jones static (respectively for <code class="reqn">x=1,2,\ldots,x_0</code>)</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>library(HDCD)
n = 50
p = 50

set.seed(100)
thresholds_test_emp = Pilliat_test_calibrate(n,p, bonferroni=TRUE,N=100, tol=1/100)
set.seed(100)
thresholds_test_emp_without_bonferroni = Pilliat_test_calibrate(n,p, 
                                         bonferroni=FALSE,N=100, tol=1/100)
thresholds_test_emp # thresholds with bonferroni correction
thresholds_test_emp_without_bonferroni # thresholds without bonferroni correction

# Generating data
X = matrix(rnorm(n*p), ncol = n, nrow=p)
Y = matrix(rnorm(n*p), ncol = n, nrow=p)

# Adding a single sparse change-point to X (and not Y):
X[1:5, 25:50] = X[1:5, 25:50] +2
resX = Pilliat_test(X, 
                    threshold_dense=thresholds_test_emp$threshold_dense, 
                    thresholds_bj = thresholds_test_emp$thresholds_bj, 
                    thresholds_partial = thresholds_test_emp$thresholds_partial
)
resX
resY = Pilliat_test(Y, 
                    threshold_dense=thresholds_test_emp$threshold_dense, 
                    thresholds_bj = thresholds_test_emp$thresholds_bj, 
                    thresholds_partial = thresholds_test_emp$thresholds_partial
)
resY
</code></pre>

<hr>
<h2 id='rescale_variance'>Re-scales each row of matrix by its MAD estimate</h2><span id='topic+rescale_variance'></span>

<h3>Description</h3>

<p>R wrapper for C function computing the (rescaled) median absolute difference in differences for each row of the input matrix. The rescaling factor is set to 1.05 (corresponding to the Normal distribution). Each row of the input matrix then re-scaled by the corresponding noise estimate.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rescale_variance(X, debug = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rescale_variance_+3A_x">X</code></td>
<td>
<p>A <code class="reqn">p \times n</code> matrix</p>
</td></tr>
<tr><td><code id="rescale_variance_+3A_debug">debug</code></td>
<td>
<p>If <code>TRUE</code>, diagnostic prints are provided during execution</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing 
</p>
<table>
<tr><td><code>X</code></td>
<td>
<p>the input matrix, variance re-scaled and flattened</p>
</td></tr>
<tr><td><code>scales</code></td>
<td>
<p>vector of MAD estimates of the noise level of each row of the input matrix</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>library(HDCD)
n = 200
p = 500
set.seed(101)
# Generating data
X = matrix(rnorm(n*p), ncol = n, nrow=p)

ret = rescale_variance(X)
ret$X #rescaled matrix
ret$scales #estimated noise level for each time series (each row)

# Note that the rescaled matrix is in (column wise) vector form. To transform it back to a matrix,
# do the following:
rescaled_X = matrix(ret$X, nrow = p, ncol=n)
</code></pre>

<hr>
<h2 id='single_CUSUM'>CUSUM transformation of matrix at a specific position</h2><span id='topic+single_CUSUM'></span>

<h3>Description</h3>

<p>R wrapper for C function computing the CUSUM transformation of matrix over an interval <code class="reqn">(s,e]</code> evaluated at a specific position. For compatibility with C indexing, the user should subtract <code class="reqn">1</code> from <code class="reqn">s</code>, <code class="reqn">e</code> and <code class="reqn">v</code> when supplying the arguments to the function. If start and stop are not supplied, the CUSUM is computed over the full data, so <code class="reqn">(s,e] = (0,n]</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>single_CUSUM(X, start = NULL, stop = NULL, pos)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="single_CUSUM_+3A_x">X</code></td>
<td>
<p>Matrix of observations, where each row contains a time series</p>
</td></tr>
<tr><td><code id="single_CUSUM_+3A_start">start</code></td>
<td>
<p>Starting point of interval over which the CUSUM should be computed, subtracted by one</p>
</td></tr>
<tr><td><code id="single_CUSUM_+3A_stop">stop</code></td>
<td>
<p>Ending point of interval over which the CUSUM should be computed, subtracted by one</p>
</td></tr>
<tr><td><code id="single_CUSUM_+3A_pos">pos</code></td>
<td>
<p>Position at which the CUSUM should be evaluated, subtracted by one</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of CUSUM values, each corresponding to a row of the input matrix. The <code class="reqn">i</code>-th element corresponds to the CUSUM transformation of the <code class="reqn">i</code>-th row of <code class="reqn">X</code>, computed over the interval <code class="reqn">(\code{start}+1,\code{end}+1]</code> and evaluated at position <code class="reqn">\code{pos}</code>, i.e. 
<code class="reqn">\sqrt{\frac{e-v}{(e-s)(v-s)}}\sum_{t=s+1}^v X_{i,t} - \sqrt{\frac{v-s}{(e-s)(e-v)}}\sum_{t=v+1}^e X_{i,t}</code>, 
where <code class="reqn">s = (\code{start}+1)</code>, <code class="reqn">e = (\code{stop}+1)</code> and <code class="reqn">v = \code{pos}+1</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n = 10
p = 10
set.seed(101)
X = matrix(rnorm(n*p), ncol = n, nrow=p)
# CUSUM over the full data (s,e] = (0,n] evaluated at position v=4
position = 4
X_cusum_single = single_CUSUM(X,pos = position-1)
X_cusum_single

# verifying that this corresponds to the 4-th row of output of CUSUM():
X_cusum = CUSUM(X)
X_cusum[,4]
</code></pre>

<hr>
<h2 id='single_ESAC'>Efficient Sparsity Adaptive Change-point estimator for a single change-point</h2><span id='topic+single_ESAC'></span>

<h3>Description</h3>

<p>R wrapper for C function implementing ESAC for single change-point estimation, as described in section 3.1 in Moen et al. (2023)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>single_ESAC(
  X,
  threshold_d = 1.5,
  threshold_s = 1,
  rescale_variance = FALSE,
  debug = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="single_ESAC_+3A_x">X</code></td>
<td>
<p>Matrix of observations, where each row contains a time series</p>
</td></tr>
<tr><td><code id="single_ESAC_+3A_threshold_d">threshold_d</code></td>
<td>
<p>Leading constant for <code class="reqn">\lambda(t) \propto r(t)</code> for <code class="reqn">t= p</code></p>
</td></tr>
<tr><td><code id="single_ESAC_+3A_threshold_s">threshold_s</code></td>
<td>
<p>Leading constant for <code class="reqn">\lambda(t) \propto r(t)</code> for <code class="reqn">t\leq \sqrt{p\log n}</code>.</p>
</td></tr>
<tr><td><code id="single_ESAC_+3A_rescale_variance">rescale_variance</code></td>
<td>
<p>If <code>TRUE</code>, each row of the data is re-scaled by a MAD estimate using <code><a href="#topic+rescale_variance">rescale_variance</a></code></p>
</td></tr>
<tr><td><code id="single_ESAC_+3A_debug">debug</code></td>
<td>
<p>If <code>TRUE</code>, diagnostic prints are provided during execution</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing 
</p>
<table>
<tr><td><code>pos</code></td>
<td>
<p>estimated change-point location</p>
</td></tr>
<tr><td><code>s</code></td>
<td>
<p>the value of <code class="reqn">t \in \mathcal{T}</code> at which the sparsity specific score is maximized</p>
</td></tr>
</table>


<h3>References</h3>

<p>Moen PAJ, Glad IK, Tveten M (2023).
&ldquo;Efficient sparsity adaptive changepoint estimation.&rdquo;
Arxiv preprint, 2306.04702, <a href="https://doi.org/10.48550/arXiv.2306.04702">https://doi.org/10.48550/arXiv.2306.04702</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(HDCD)
n = 500
p = 500
set.seed(101)
# Generating data
X = matrix(rnorm(n*p), ncol = n, nrow=p)
# Adding a single sparse change-point:
X[1:5, 201:500] = X[1:5, 201:500] +1

res = single_ESAC(X,rescale_variance=TRUE)
res$pos

# Manually setting the leading constants for \lambda(t):
# here \lambda(t) = 2 (\sqrt{p \log(n^4)}  + \log (n^4)) for t=p
# and             = 2 (t \log (ep\log n^4 / t^2) + \log(n^4))
res = single_ESAC(X, threshold_d = 2, threshold_s = 2)
res$pos
</code></pre>

<hr>
<h2 id='single_Inspect'>Inspect for single change-point estimation</h2><span id='topic+single_Inspect'></span>

<h3>Description</h3>

<p>R wrapper for C function for single change-point estimation using Inspect (Wang and Samworth 2018). Note that the algorithm is only implemented for <code class="reqn">\mathcal{S} = \mathcal{S}_2</code>, in the notation of Wang and Samworth (2018).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>single_Inspect(
  X,
  lambda = sqrt(log(p * log(n))/2),
  eps = 1e-10,
  rescale_variance = FALSE,
  maxiter = 10000,
  debug = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="single_Inspect_+3A_x">X</code></td>
<td>
<p>Matrix of observations, where each row contains a time series</p>
</td></tr>
<tr><td><code id="single_Inspect_+3A_lambda">lambda</code></td>
<td>
<p>Manually specified value of <code class="reqn">\lambda</code> (can be <code>NULL</code>, in which case <code class="reqn">\lambda \gets \sqrt{\log(p\log n)/2}</code>)</p>
</td></tr>
<tr><td><code id="single_Inspect_+3A_eps">eps</code></td>
<td>
<p>Threshold for declaring numerical convergence of the power method</p>
</td></tr>
<tr><td><code id="single_Inspect_+3A_rescale_variance">rescale_variance</code></td>
<td>
<p>If <code>TRUE</code>, each row of the data is re-scaled by a MAD estimate using <code><a href="#topic+rescale_variance">rescale_variance</a></code></p>
</td></tr>
<tr><td><code id="single_Inspect_+3A_maxiter">maxiter</code></td>
<td>
<p>Maximum number of iterations for the power method</p>
</td></tr>
<tr><td><code id="single_Inspect_+3A_debug">debug</code></td>
<td>
<p>If <code>TRUE</code>, diagnostic prints are provided during execution</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing 
</p>
<table>
<tr><td><code>pos</code></td>
<td>
<p>estimated change-point location</p>
</td></tr>
<tr><td><code>CUSUMval</code></td>
<td>
<p>projected CUSUM value at the estimated change-point position</p>
</td></tr>
</table>


<h3>References</h3>

<p>Wang T, Samworth RJ (2018).
&ldquo;High dimensional change point estimation via sparse projection.&rdquo;
<em>Journal of the Royal Statistical Society: Series B (Statistical Methodology)</em>, <b>80</b>(1), 57&ndash;83.
ISSN 1467-9868, <a href="https://doi.org/10.1111/rssb.12243">doi:10.1111/rssb.12243</a>, <a href="https://rss.onlinelibrary.wiley.com/doi/abs/10.1111/rssb.12243">https://rss.onlinelibrary.wiley.com/doi/abs/10.1111/rssb.12243</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(HDCD)
n = 500
p = 500
set.seed(101)
# Generating data
X = matrix(rnorm(n*p), ncol = n, nrow=p)
# Adding a single sparse change-point:
X[1:5, 201:500] = X[1:5, 201:500] +1

res = single_Inspect(X,rescale_variance=TRUE)
res$pos

# Manually setting the value of \lambda:
res = single_Inspect(X, lambda = 2*sqrt(log(p*log(n))/2))
res$pos
</code></pre>

<hr>
<h2 id='single_SBS'>Sparsified Binary Segmentation for single change-point estimation</h2><span id='topic+single_SBS'></span>

<h3>Description</h3>

<p>R wrapper for C function for single change-point estimation using Sparsified Binary Segmentation Cho and Fryzlewicz (2015).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>single_SBS(
  X,
  threshold = NULL,
  rescale_variance = TRUE,
  empirical = FALSE,
  N = 100,
  tol = 1/100,
  debug = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="single_SBS_+3A_x">X</code></td>
<td>
<p>Matrix of observations, where each row contains a time series</p>
</td></tr>
<tr><td><code id="single_SBS_+3A_threshold">threshold</code></td>
<td>
<p>Manually specified value of the threshold <code class="reqn">\pi_T</code></p>
</td></tr>
<tr><td><code id="single_SBS_+3A_rescale_variance">rescale_variance</code></td>
<td>
<p>If <code>TRUE</code>, each row of the data is re-scaled by a MAD estimate using <code><a href="#topic+rescale_variance">rescale_variance</a></code></p>
</td></tr>
<tr><td><code id="single_SBS_+3A_empirical">empirical</code></td>
<td>
<p>If <code>TRUE</code>, the threshold is based on Monte Carlo simulation</p>
</td></tr>
<tr><td><code id="single_SBS_+3A_n">N</code></td>
<td>
<p>If <code>empirical=TRUE</code>, <code>N</code> is the number of Monte Carlo samples used</p>
</td></tr>
<tr><td><code id="single_SBS_+3A_tol">tol</code></td>
<td>
<p>If <code>empirical=TRUE</code>, <code>tol</code> is the false error probability tolerance</p>
</td></tr>
<tr><td><code id="single_SBS_+3A_debug">debug</code></td>
<td>
<p>If <code>TRUE</code>, diagnostic prints are provided during execution</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing 
</p>
<table>
<tr><td><code>pos</code></td>
<td>
<p>estimated change-point location</p>
</td></tr>
<tr><td><code>maxval</code></td>
<td>
<p>maximum thresholded and aggregated CUSUM at the estimated change-point position</p>
</td></tr>
</table>


<h3>References</h3>

<p>Cho H, Fryzlewicz P (2015).
&ldquo;Multiple-change-point detection for high dimensional time series via sparsified binary segmentation.&rdquo;
<em>Journal of the Royal Statistical Society. Series B (Statistical Methodology)</em>, <b>77</b>(2), 475&ndash;507.
ISSN 1369-7412, Publisher: [Royal Statistical Society, Wiley], <a href="https://www.jstor.org/stable/24774746">https://www.jstor.org/stable/24774746</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Single SBS
library(HDCD)
n = 50
p = 50
set.seed(101)
# Generating data
X = matrix(rnorm(n*p), ncol = n, nrow=p)
# Adding a single sparse change-point:
X[1:5, 26:n] = X[1:5, 26:n] +1

res = single_SBS(X,threshold=7,rescale_variance=TRUE)
res$pos

# Choose threhsold by Monte Carlo:
res = single_SBS(X,empirical=TRUE,rescale_variance=TRUE)
res$pos
</code></pre>

<hr>
<h2 id='single_SBS_calibrate'>Generates threshold <code class="reqn">\pi_T</code> for Sparsified Binary Segmentation for single change-point detection</h2><span id='topic+single_SBS_calibrate'></span>

<h3>Description</h3>

<p>R wrapper for function choosing empirical threshold <code class="reqn">\pi_T</code> using Monte Carlo simulation for single change-point Sparsified Binary Segmentation. More specifically, the function returns the empirical upper tol quantile of CUSUMs over <code class="reqn">p</code> time series, each of length <code class="reqn">n</code>, based on <code class="reqn">N</code> number of runs.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>single_SBS_calibrate(
  n,
  p,
  N = 100,
  tol = 1/100,
  rescale_variance = TRUE,
  debug = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="single_SBS_calibrate_+3A_n">n</code></td>
<td>
<p>Number of observations</p>
</td></tr>
<tr><td><code id="single_SBS_calibrate_+3A_p">p</code></td>
<td>
<p>Number time series</p>
</td></tr>
<tr><td><code id="single_SBS_calibrate_+3A_n">N</code></td>
<td>
<p>Number of Monte Carlo samples used</p>
</td></tr>
<tr><td><code id="single_SBS_calibrate_+3A_tol">tol</code></td>
<td>
<p>False positive probability tolerance</p>
</td></tr>
<tr><td><code id="single_SBS_calibrate_+3A_rescale_variance">rescale_variance</code></td>
<td>
<p>If TRUE, each row of the data is rescaled by a MAD estimate</p>
</td></tr>
<tr><td><code id="single_SBS_calibrate_+3A_debug">debug</code></td>
<td>
<p>If TRUE, diagnostic prints are provided during execution</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Threshold
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(HDCD)
n = 50
p = 50
set.seed(101)

# Simulate threshold
pi_T_squared = single_SBS_calibrate(n=n,p=p,N=100, tol=1/100, rescale_variance = TRUE)
pi_T_squared


# Generating data
X = matrix(rnorm(n*p), ncol = n, nrow=p)
# Adding a single sparse change-point:
X[1:5, 26:n] = X[1:5, 26:n] +1

# Run SBS
res = single_SBS(X,threshold=sqrt(pi_T_squared),rescale_variance=TRUE)
res$pos
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
