<!DOCTYPE html><html><head><title>Help for package intamapInteractive</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {intamapInteractive}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#intamapInteractive-package'><p>Interactive functionality added to the intamap package</p></a></li>
<li><a href='#anisotropyChoice'><p>anisotropyChoice</p></a></li>
<li><a href='#biasCorr'><p>Bias correction</p></a></li>
<li><a href='#calculateMukv'><p>MUKV computation</p></a></li>
<li><a href='#doSegmentation'><p>Spatial Segmentation - Clustering for Scattered Observations</p></a></li>
<li><a href='#findBiasUK'><p> Finding the regional biases using GLM</p></a></li>
<li><a href='#findBoundaryLines'><p> Finding the regional boundaries</p></a></li>
<li><a href='#findLocalBias'><p> Finds (and removes) biases between overlapping networks</p></a></li>
<li><a href='#findRegionalBias'><p> Find and/or remove regional biases</p></a></li>
<li><a href='#optimizeNetwork'><p>Optimization of networks</p></a></li>
<li><a href='#spCovAdd'><p>Spatial coverage method to add new measurements</p></a></li>
<li><a href='#spCovDel'><p>Optimize the network with spatial coverage methods</p></a></li>
<li><a href='#ssaOptim'><p> Spatial simulated annealing (SSA) for optimization of sampling designs using a geostatistical measure of spatial prediction error</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Version:</td>
<td>1.2-6</td>
</tr>
<tr>
<td>Date:</td>
<td>2023-10-30</td>
</tr>
<tr>
<td>Title:</td>
<td>Interactive Add-on Functionality for 'intamap'</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Jon Skoien &lt;jon.skoien@gmail.com&gt;</td>
</tr>
<tr>
<td>Depends:</td>
<td>intamap</td>
</tr>
<tr>
<td>Imports:</td>
<td>spatstat.geom, automap, gstat, methods, sp, spcosa, sf</td>
</tr>
<tr>
<td>Description:</td>
<td>The methods in this package adds to the functionality of  the 'intamap' package, such as bias correction and network optimization. Pebesma et al (2010) gives an overview of the methods behind and possible usage &lt;<a href="https://doi.org/10.1016%2Fj.cageo.2010.03.019">doi:10.1016/j.cageo.2010.03.019</a>&gt;.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-10-30 10:34:28 UTC; skoiejo</td>
</tr>
<tr>
<td>Author:</td>
<td>Edzer Pebesma [aut],
  Jon Skoien [aut, cre],
  Olivier Baume [ctb],
  A Chorti [ctb],
  Dionisis Hristopulos [ctb],
  Stepahnie Melles [ctb],
  Giannis Spiliopoulos [ctb]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-10-30 13:30:05 UTC</td>
</tr>
</table>
<hr>
<h2 id='intamapInteractive-package'>Interactive functionality added to the intamap package</h2><span id='topic+intamapInteractive-package'></span>

<h3>Description</h3>

<p>This package provides some added functionality to the 
<code>link[intamap]{intamap-package}</code> for automatic interpolation of environmental 
variables. Whereas <code>link[intamap]{intamap-package}</code> was specifically developed
as a statistical back-end for a Web Processing Service (WPS), this package 
offers some functionality that is not possible to access through such a WPS.
</p>
<p>The methods in this package can mainly be put into three groups:
</p>

<dl>
<dt>bias correction</dt><dd><p>methods for estimating and possible correct for 
biases between measurement networks, due to differences in measurement
strategies, measurement devices, or (unknown) post-processing of data</p>
</dd>
<dt>segmentation</dt><dd><p>method for segmentation of data, based on their measurement density</p>
</dd>
<dt>network optimization</dt><dd><p>methods for optimizing a measurement network
(adding or removing observation points), based on different criteria</p>
</dd>
</dl>


<hr>
<h2 id='anisotropyChoice'>anisotropyChoice</h2><span id='topic+anisotropyChoice'></span>

<h3>Description</h3>

<p>This function combines segmentation of scattered 2D
data and estimation of anisotropy parameters using the CTI method.</p>


<h3>Usage</h3>

<pre><code class='language-R'>anisotropyChoice(object)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="anisotropyChoice_+3A_object">object</code></td>
<td>
<p>An Intamap type object containing one 
<code><a href="sp.html#topic+SpatialPoints">SpatialPointsDataFrame</a></code> with <code>observations</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function <code>AnisotropyChoice</code> function employs the
<code><a href="#topic+doSegmentation">doSegmentation</a></code> function to
automatically separate the original dataset into clusters based on the sampling density and the spatial
locations of the data (see <code><a href="#topic+doSegmentation">doSegmentation</a></code> for
details). The results of the segmentation procedure and the
anisotropy analysis per cluster are returned in  a matrix of
dimension [cl]x5, where [cl] is the number of clusters . Each row of
the matrix contains the cluster index, the anisotropy ratio, the
anisotropy direction, the number of cluster points and the area
inside the convex hull of the cluster. In addition, a single set of
anisotropy parameters is returned in the element <code>anisPar</code>.
These parameters are calculated using weighted averages of the
covariance Hessian matrix estimates in each cluster. The weights are
based on the area enclosed by the convex hull of each cluster. </p>


<h3>Value</h3>

 <p><code>object</code>: A modified Intamap type object is returned,
which contains  the results of the anisotropy parameter estimation.
The anisotropy parameters are returned in the element <code>anisPar</code>
as described below.
</p>
<table>
<tr><td><code>anisPar</code></td>
<td>
<p> List element in <code>object</code> that contains a list with the following
elements:
</p>

<dl>
<dt><code>ratio</code></dt><dd><p>A coarse-grained  anisotropy ratio for all the data</p>
</dd>
<dt><code>direction</code></dt><dd><p>A coarse-grained  anisotropy  orientation for all the data</p>
</dd>
<dt><code>clusters</code></dt><dd><p>A matrix of dimension [cl]x5 which determines the anisotropy per cluster.
Each row of <code>clusters</code> gives the
(cluster id, anisotropy ratio, anisotropy direction, number of points, area) for each cluster detected.</p>
</dd>
</dl>

</td></tr>
<tr><td><code>clusters</code></td>
<td>
<p>list element added to the original object containing the segmentation results.
</p>

<dl>
<dt>index</dt><dd><p>Index array identifying the cluster in which each observation point belongs. 
Zero value means that the observations has been removed.</p>
</dd>
<dt>clusterNumber</dt><dd><p>Number of clusters detected.</p>
</dd>
</dl>

</td></tr>
</table>


<h3>Note</h3>

<p> This function uses the <code>akima</code> package to perform
&quot;bilinear&quot; and &quot;bicubic&quot; interpolation for the estimation of spatial
derivatives</p>


<h3>Author(s)</h3>

<p> D.T. Hristopulos, G.Spiliopoulos, A.Chorti
</p>


<h3>References</h3>

<p>[1] http://www.intamap.org
</p>
<p>[2] A. Chorti and D. T. Hristopulos (2008). Non-parametric
Identification of Anisotropic (Elliptic) Correlations in Spatially
Distributed Data Sets, IEEE Transactions on Signal Processing,
56(10), 4738-4751 (2008).
</p>
<p>[3] D. T. Hristopulos, M. P. Petrakis, G. Spiliopoulos, A. Chorti
(2009). Non-parametric estimation of geometric anisotropy from
environmental sensor network measurements, StatGIS 2009:
Geoinformatics for Environmental Surveillance Proceedings (ed. G.
Dubois).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(gstat)
data(walker)
object=createIntamapObject(observations=walker)
object=anisotropyChoice(object)

print(summary(object$clusters$index))
print(object$anisPar)
</code></pre>

<hr>
<h2 id='biasCorr'>Bias correction</h2><span id='topic+biasCorr'></span>

<h3>Description</h3>

<p>Identifies and removes biases from measurement networks
</p>


<h3>Usage</h3>

<pre><code class='language-R'>biasCorr(object,regCode = "regCode",...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="biasCorr_+3A_object">object</code></td>
<td>
<p> Data frame with observations with same format as <code>observations</code> 
described in the presentation of the 
<code><a href="intamap.html#topic+intamap-package">intamap-package</a></code>)</p>
</td></tr>
<tr><td><code id="biasCorr_+3A_regcode">regCode</code></td>
<td>
<p>the column name of regions in the data polygons, if existing</p>
</td></tr>
<tr><td><code id="biasCorr_+3A_...">...</code></td>
<td>
<p>further arguments to the bias correction methods called, see details below</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Many data sets can consist of data coming from a large number of different measurement
networks, using different measurement devices or applying different methods for 
post-processing the observations. Some of these networks can exist in the same area,
e.g. when different authorities are measuring the same, but at different locations
(one of them in cities, the other one close to lakes), some networks will only
exist as neighbouring networks (networks operated by a municipality or a country).
Local networks can also be grouped together as one national data-base, which can again
be merged into an international data-base.
</p>
<p>One challenge with the merging into data-bases is that there will be inconsistencies 
between measurements in the different networks, which will again cause difficulties
when attempting to map the observations, as done in the intamap-package. The intention
of this function is therefore to call other functions that are able to identify
and remove such differences, which can be referred to as biases between the networks.
</p>
<p>There are at the moment two methods available for bias correction, &quot;UK&quot; and &quot;LM&quot;. 
&quot;UK&quot; is a universal kriging based approach implemented in 
<code><a href="#topic+findBiasUK">findBiasUK</a></code>. This method can only deal with biases between 
neigbouring networks, but is well capable of taking covariates into account.
&quot;LM&quot; is based on local methods for estimating differences between networks, and
is implemented in <code><a href="#topic+findLocalBias">findLocalBias</a></code> and <code><a href="#topic+findRegionalBias">findRegionalBias</a></code>.
The choice between the methods is given by the parameter <code>biasRemovalMethod</code>
in the parameter element of the object, set in <code><a href="intamap.html#topic+getIntamapParams">getIntamapParams</a></code>,
called from createIntamapObject.
</p>
<p>The function will remove biases according to the settings of the parameters 
<code>removeBias</code>. 
Below is a list of the functions available for bias corrections. See each individual
function for more information about usage.
</p>

<dl>
<dt><a href="#topic+findBiasUK">findBiasUK</a></dt><dd><p>The universal kriging based function for 
finding biases between neighbouring networks</p>
</dd>
<dt><a href="#topic+findLocalBias">findLocalBias</a></dt><dd><p>Find biases for ovelapping networks</p>
</dd>
<dt><a href="#topic+removeLocalBias">removeLocalBias</a></dt><dd><p>Removes biases between ovelapping networks</p>
</dd>
<dt><a href="#topic+findBoundaryLines">findBoundaryLines</a></dt><dd><p>Find points that define adjacent boundaries
between regions</p>
</dd>
<dt><a href="#topic+findRegionalBias">findRegionalBias</a></dt><dd><p>Find biases for neighbouring networks</p>
</dd>
<dt><a href="#topic+removeRegionalBias">removeRegionalBias</a></dt><dd><p>Remove biases between neighbouring networks</p>
</dd>
</dl>



<h3>Value</h3>

<p>Data frame with observations, with the identified biases removed.
</p>


<h3>Author(s)</h3>

<p> Jon Olav Skoien</p>


<h3>References</h3>

<p>Skoien, J. O., O. P. Baume, E. J. Pebesma, and G. B. M. Heuvelink. 2010. 
Identifying and removing heterogeneities between monitoring networks. 
Environmetrics 21(1), 66-84.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+findLocalBias">findLocalBias</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(meuse)
data(meuse.grid)
observations = data.frame(x = meuse$x,y = meuse$y,value = log(meuse$zinc))
coordinates(observations) = ~x+y
gridded(meuse.grid) = ~x+y
pBoundaries = spsample(observations, 8, "regular",bb = bbox(observations) +  
              matrix(c(-400,-400,400,400),ncol=2),offset=c(0,0))
gridded(pBoundaries) = TRUE
cs = pBoundaries@grid@cellsize[1]/2
dx = cs/5

Srl = list()
nb = dim(coordinates(pBoundaries))[1]
for (i in 1:nb) {
  pt1 = coordinates(pBoundaries)[i,]
  x1 = pt1[1]-cs
  x2 = pt1[1]+cs
  y1 = pt1[2]-cs
  y2 = pt1[2]+cs

  boun = data.frame(x=c(seq(x1,x2,dx),rep(x2,11),seq(x2,x1,-dx),rep(x1,11)),
                    y=c(rep(y1,11),seq(y1,y2,dx),rep(y2,11),seq(y2,y1,-dx)))
  coordinates(boun) = ~x+y
  boun = Polygon(boun)
  Srl[[i]] = Polygons(list(boun),ID = as.character(i))
}
pBoundaries = SpatialPolygonsDataFrame(SpatialPolygons(Srl),
                                      data = data.frame(ID=c(1:nb)))
observations$ID = over(observations, geometry(pBoundaries))
blines = findBoundaryLines(pBoundaries,regCode = "ID")


object = createIntamapObject(observations,meuse.grid,boundaryLines = blines, 
  params = list(removeBias = "regionalBias"))
object = biasCorr(object,regCode= "ID")
object$regionalBias$regionalBias
pBoundaries$bias = NA
pBoundaries$bias[object$regionalBias$regionalBias$ID] = object$regionalBias$regionalBias$ols
spplot(pBoundaries,"bias",sp.layout = list(list("sp.points",observations)))

</code></pre>

<hr>
<h2 id='calculateMukv'>MUKV computation</h2><span id='topic+calculateMukv'></span>

<h3>Description</h3>

<p>Computes mean universal kriging variance (MUKV) for given geostatistical parameters
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calculateMukv(observations, predGrid, model, formulaString, fun, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="calculateMukv_+3A_observations">observations</code></td>
<td>
 <p><code><a href="sp.html#topic+SpatialPoints">SpatialPoints</a></code> or  <code><a href="sp.html#topic+SpatialPoints">SpatialPointsDataFrame</a></code> 
with observation locations and possible covariates </p>
</td></tr>
<tr><td><code id="calculateMukv_+3A_predgrid">predGrid</code></td>
<td>
 <p><code><a href="sp.html#topic+Spatial-class">Spatial</a></code> object with coordinates of 
prediction locations (usually <code><a href="sp.html#topic+SpatialGrid">SpatialGrid</a></code> 
or <code><a href="sp.html#topic+SpatialGrid">SpatialGridDataFrame</a></code> when 
independent covariate predictor variables are used) </p>
</td></tr>
<tr><td><code id="calculateMukv_+3A_model">model</code></td>
<td>
<p> Variogram model:object of class <code>variogramModel</code>, of the form
created by <code><a href="gstat.html#topic+vgm">vgm</a></code></p>
</td></tr>
<tr><td><code id="calculateMukv_+3A_formulastring">formulaString</code></td>
<td>
<p>formula that defines the dependent variable as a linear model 
of independent variables; suppose the dependent variable has name <code>z</code>, 
for ordinary and simple kriging use the formula <code>z~1</code>; 
for universal kriging, suppose <code>z</code> is linearly dependent on 
<code>x</code> and <code>y</code>, use the formula <code>z~x+y</code>. The formulaString defaults
to <code>"value~1"</code> if <code>value</code> is a part of the data set. 
If not, the first column of the data set is used.</p>
</td></tr>
<tr><td><code id="calculateMukv_+3A_fun">fun</code></td>
<td>
<p>alternative penalty function, needs to be a function which can take the
same arguments as <code>calculateMukv</code></p>
</td></tr>
<tr><td><code id="calculateMukv_+3A_...">...</code></td>
<td>
<p> other arguments to be passed on at lower level functions </p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function computes kriging on the <code>predGrid</code> with 
<code><a href="gstat.html#topic+krige">krige</a></code> function, and averages the kriging variance (MUKV). With covariates, 
the function takes a universal kriging model into account.
</p>


<h3>Value</h3>

<p>MUKV value
</p>


<h3>Author(s)</h3>

<p> S.J. Melles, O. Baume, J. Skoien </p>


<h3>Examples</h3>

<pre><code class='language-R'>
# load data:
library(gstat)
data(meuse)
coordinates(meuse) = ~x+y
data(meuse.grid)
coordinates(meuse.grid) = ~x+y
gridded(meuse.grid) = TRUE
meuse.grid$soil = factor(meuse.grid$soil)

# estimate variogram:
smplvarUK = variogram(zinc~dist+ffreq+soil, meuse)
plot(smplvarUK)
vfitUK = fit.variogram(variogram(zinc~dist+ffreq+soil, meuse), vgm(1, "Exp", 300, 1))
plot(smplvarUK, vfitUK)

calculateMukv(meuse, meuse.grid, vfitUK, zinc~dist+ffreq+soil)


</code></pre>

<hr>
<h2 id='doSegmentation'>Spatial Segmentation - Clustering for Scattered Observations </h2><span id='topic+doSegmentation'></span>

<h3>Description</h3>

<p>This function performs segmentation of scattered 2D
data based on  sampling density and location.</p>


<h3>Usage</h3>

<pre><code class='language-R'>doSegmentation(object)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="doSegmentation_+3A_object">object</code></td>
<td>
<p>An Intamap type object containing the element (list)
<code>observations</code>, which includes the coordinates of the
observation locations</p>
</td></tr></table>


<h3>Details</h3>

<p>This function performs segmentation of scattered 2D data
based on  sampling density and location. Let us assume that
<code>No</code> is the number of observation locations. If <code>No</code>&lt; 200,
then a single cluster is returned. 
</p>
<p>(1) The segmentation algorithm
first  removes isolated distant points, if there are any, from the
observation locations.
Points $(xi,yi)$ are characterized as 'isolated' and 'distant' if they satisfy the following conditions :
$abs(xi-mean(x)) &gt; 4 *std(x) or abs(yi-mean(y)) &gt; 4 *std(y)$
and distance from closest neighbor $&gt;
sqrt((std(x)/2)^2+(std(y)/2)^2)$. After the first step the size of
the original dataset is reduced to N (N= No - isolated points)
points. 
</p>
<p>(2) A sampling density matrix (lattice) consisting of N
cells that cover the study area is constructed. Each cell is
assigned  a density value equal to the number of  observation points
inside the cell. In addition, each observation point is assigned the
sampling density value of the containing cell. 
</p>
<p>(3) Unsupervised
clustering edge detection is used to determine potential cluster
perimeters.  
</p>
<p>(4) Each closed region's perimeter is labeled with a
different cluster (segment) number. 
</p>
<p>(5) All observation points
internal to a cluster perimeter are assigned to the specific
cluster. 
</p>
<p>(6) Each cluster that contains fewer than 50 observation
points is rejected. 
</p>
<p>(7) The observation points that have not
initially been assigned to a cluster and those belonging to rejected
(small) clusters are assigned at this stage. The assignment takes
into account both the distance of the points from the centroids of
the accepted clusters as well as the mean sampling density of the
clusters.
</p>
<p>Note: The <code>No</code>&lt; 200 empirical constraint is used to avoid
extreme situations in which the sampling density is concentrated
inside a few cells of the background lattice, thereby inhibiting the
edge detection algorithm.
</p>


<h3>Value</h3>

<p>A modified Intamap object which additionally includes the
list element <code>clusters</code>. This element is a list that contains
(i) the indices of  removed points from <code>observations</code>; (ii)
the indices of the clusters to which the remaining observation
points are assigned
and (iii) the number of clusters detected.
</p>
<table>
<tr><td><code>clusters</code></td>
<td>
<p>list element added to the original object containing the segmentation results.
</p>
	
<dl>
<dt>rmdist</dt><dd><p>Indices of  removed points.</p>
</dd>
<dt>index</dt><dd><p>Index array identifying the cluster in which each observation point belongs.</p>
</dd>
<dt>clusterNumber</dt><dd><p>Number of clusters detected.</p>
</dd>
</dl>

</td></tr>
</table>


<h3>Author(s)</h3>

<p>A. Chorti, Spiliopoulos Giannis, Hristopulos Dionisis</p>


<h3>References</h3>

<p> [1] D. T. Hristopulos, M. P. Petrakis, G.
Spiliopoulos, A. Chorti (2009). Non-parametric estimation of
geometric anisotropy from environmental sensor network measurements,
StatGIS 2009: Geoinformatics for Environmental Surveillance
Proceedings (ed. G. Dubois).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(gstat)

data(walker)
# coordinates(walker)=~X+Y
object=createIntamapObject(observations=walker)
object=doSegmentation(object)

print(summary(object$clusters$index))



</code></pre>

<hr>
<h2 id='findBiasUK'> Finding the regional biases using GLM
</h2><span id='topic+findBiasUK'></span>

<h3>Description</h3>

<p> Method for identifying regional biases (in most cases biases between countries)</p>


<h3>Usage</h3>

<pre><code class='language-R'>findBiasUK(object)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="findBiasUK_+3A_object">object</code></td>
<td>
<p>an object of class <code><a href="sp.html#topic+SpatialPoints">SpatialPointsDataFrame</a></code>, at least 
containing observations and a regional identification code (<code>regCode</code>)</p>
</td></tr>  
</table>


<h3>Value</h3>

 
<p>A <code><a href="base.html#topic+data.frame">data.frame</a></code> with the biases for each country with uncertainty.
</p>


<h3>Author(s)</h3>

<p> Olivier Baume </p>


<h3>See Also</h3>

<p><code><a href="#topic+findRegionalBias">findRegionalBias</a></code></p>

<hr>
<h2 id='findBoundaryLines'> Finding the regional boundaries
</h2><span id='topic+findBoundaryLines'></span>

<h3>Description</h3>

<p> Method for identifying points on the boundaries between regions 
(in most cases biases between countries)</p>


<h3>Usage</h3>

<pre><code class='language-R'>findBoundaryLines(polygons, projOrig, projNew, regCode = "regCode")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="findBoundaryLines_+3A_polygons">polygons</code></td>
<td>
<p>A <code><a href="sp.html#topic+SpatialPolygons">SpatialPolygonsDataFrame</a></code> with the polygons
defining the boundaries of each separate region.</p>
</td></tr>
<tr><td><code id="findBoundaryLines_+3A_projorig">projOrig</code></td>
<td>
<p>The original projection of the boundaries</p>
</td></tr>
<tr><td><code id="findBoundaryLines_+3A_projnew">projNew</code></td>
<td>
<p>If a different projection is wanted for the output</p>
</td></tr>
<tr><td><code id="findBoundaryLines_+3A_regcode">regCode</code></td>
<td>
<p>the column name of regions in the data polygons</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function finds the points defining the boundary between two polygons and 
passes a <code><a href="sp.html#topic+SpatialPoints">SpatialPointsDataFrame</a></code> with these points back.
The result in mainly used by <code><a href="#topic+findRegionalBias">findRegionalBias</a></code> for estimation
of regional biases. The function is based on the boundary between the 
polygons being defined by the same points. 
</p>


<h3>Value</h3>

<p>A <code><a href="sp.html#topic+SpatialPoints">SpatialPointsDataFrame</a></code> with points defining the
boundaries between regions. 
</p>


<h3>Author(s)</h3>

<p> Jon Olav Skoien</p>


<h3>References</h3>

<p>Skoien, J. O., O. P. Baume, E. J. Pebesma, and G. B. M. Heuvelink. 2010. 
Identifying and removing heterogeneities between monitoring networks. Environmetrics 21(1), 66-84.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(meuse)
observations = data.frame(x = meuse$x,y = meuse$y,value = log(meuse$zinc))
coordinates(observations) = ~x+y
pBoundaries = spsample(observations, 10, "regular", bb = bbox(observations) +  
                         matrix(c(-400,-400,400,400),ncol=2),offset=c(0,0))
gridded(pBoundaries) = TRUE
cs = pBoundaries@grid@cellsize[1]/2

Srl = list()
nb = dim(coordinates(pBoundaries))[1]
for (i in 1:nb) {
  pt1 = coordinates(pBoundaries)[i,]
  x1 = pt1[1]-cs
  x2 = pt1[1]+cs
  y1 = pt1[2]-cs
  y2 = pt1[2]+cs

  boun = data.frame(x=c(x1,x2,x2,x1,x1),y=c(y1,y1,y2,y2,y1))
  coordinates(boun) = ~x+y
  boun = Polygon(boun)
  Srl[[i]] = Polygons(list(boun),ID = as.character(i))
}
pBoundaries = SpatialPolygonsDataFrame(SpatialPolygons(Srl),
                                       data = data.frame(ID=c(1:nb)))
observations$ID = over(observations, geometry(pBoundaries))
blines = findBoundaryLines(pBoundaries, regCode = "ID")
</code></pre>

<hr>
<h2 id='findLocalBias'> Finds (and removes) biases between overlapping networks</h2><span id='topic+findLocalBias'></span><span id='topic+removeLocalBias'></span>

<h3>Description</h3>

<p>The function tries to identify differences between different networks
of observation stations that share a region. From these differences, 
biases are estimated, and can be removed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>findLocalBias(object, gid = "group",
              formulaString = value ~ 1, regCode="regCode",...)
removeLocalBias(object, localBias, gid = "group", formulaString = value ~ 1, 
                regCode = "regCode")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="findLocalBias_+3A_object">object</code></td>
<td>
<p> data frame with observations</p>
</td></tr>
<tr><td><code id="findLocalBias_+3A_gid">gid</code></td>
<td>
<p>name of column identifying groups of local networks</p>
</td></tr>
<tr><td><code id="findLocalBias_+3A_formulastring">formulaString</code></td>
<td>
<p>formula that defines the dependent variable as a linear model 
of independent variables; suppose the dependent variable has name <code>z</code>, 
for ordinary and simple kriging use the formula <code>z~1</code>; 
for universal kriging, suppose <code>z</code> is linearly dependent on 
<code>x</code> and <code>y</code>, use the formula <code>z~x+y</code></p>
</td></tr>
<tr><td><code id="findLocalBias_+3A_regcode">regCode</code></td>
<td>
<p>the column name of regions in the <code>object</code>, if existing</p>
</td></tr>
<tr><td><code id="findLocalBias_+3A_localbias">localBias</code></td>
<td>
<p> List of data frames, for a single region, or for 
each of the regions, each containing
biases for different networks in the region(s), result of 
<code>findLocalBias</code></p>
</td></tr>
<tr><td><code id="findLocalBias_+3A_...">...</code></td>
<td>
<p>arguments to be passed to sub-functions</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>findLocalBias</code> tries to identify biases between overlapping networks, i.e. when
there is no boundary between different networks sampling the same type of data.
This can typically happen if different governmental bodies are responsible for
different types of measurement, e.g. one measuring the situation around populated
areas, the other one measuring close to water bodies. 
</p>
<p>The function will then try to find the difference between the different networks, 
and estimate the individual bias for each network, relative to a reference value,
usually the average of all networks. The method is not recommended if there
can be assumed to be a dependency beteween the process and the networks.
</p>
<p><code>removeLocalBias</code> removes the bias estimated in <code>findLocalBias</code>.
</p>


<h3>Value</h3>

 
<p>From <code>findLocalBias</code>: A list consisting of one element for each regional 
network, or an element <code>single</code>
if only one regional network is apparent. Each of these elements is again a list 
consisting of several other elements, where <code>bias</code> is the interesting one.
The remaining elements are only necessary for debugging purposes. The elements
D, V and Q refers to the matrices with same names in Skoien et al. (2009), i.e.
the relationship matrix, the variance matrix and the difference matrix.
</p>
<p>From <code>removeLocalBias</code>: A <code><a href="sp.html#topic+SpatialPoints">SpatialPointsDataFrame</a></code>
with the biases subtracted.
</p>


<h3>Author(s)</h3>

<p> Jon Olav Skoien </p>


<h3>References</h3>

 
<p>Skoien, J. O., O. P. Baume, E. J. Pebesma, and G. B. M. Heuvelink. 2010. 
Identifying and removing heterogeneities between monitoring networks. 
Environmetrics 21(1), 66-84.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Assuming that the soil type is the source of biases
data(meuse)
coordinates(meuse) = ~x+y


lb = findLocalBias(meuse,gid = "soil",formulaString=as.formula(zinc~1))
lb$single$bias

meuseUnbias = removeLocalBias(meuse,localBias = lb, gid = "soil",
    formulaString = zinc~1)
</code></pre>

<hr>
<h2 id='findRegionalBias'> Find and/or remove regional biases</h2><span id='topic+findRegionalBias'></span><span id='topic+removeRegionalBias'></span>

<h3>Description</h3>

<p> Method for identifying regional biases (in most cases biases between countries)</p>


<h3>Usage</h3>

<pre><code class='language-R'>findRegionalBias(object,boundaryLines,
                 formulaString = value~1,
                 minKrige = 5, regCode = "regCode", unbias = "default")
removeRegionalBias(object, regionalBias, formulaString = value~1, regCode = "regCode")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="findRegionalBias_+3A_object">object</code></td>
<td>
<p>an object of class <code><a href="sp.html#topic+SpatialPoints">SpatialPointsDataFrame</a></code>, at least 
containing observations and a regional identification code (<code>regCode</code>)</p>
</td></tr>  
<tr><td><code id="findRegionalBias_+3A_boundarylines">boundaryLines</code></td>
<td>
<p><code><a href="sp.html#topic+SpatialPoints">SpatialPointsDataFrame</a></code> with points defining the 
boundaries between regions. This can be found using <code><a href="#topic+findBoundaryLines">findBoundaryLines</a></code>.</p>
</td></tr>
<tr><td><code id="findRegionalBias_+3A_formulastring">formulaString</code></td>
<td>
<p>formula that defines the dependent variable as a linear model 
of independent variables; suppose the dependent variable has name <code>z</code>, 
for ordinary and simple kriging use the formula <code>z~1</code>; 
for universal kriging, suppose <code>z</code> is linearly dependent on 
<code>x</code> and <code>y</code>, use the formula <code>z~x+y</code></p>
</td></tr>              
<tr><td><code id="findRegionalBias_+3A_minkrige">minKrige</code></td>
<td>
<p>Setting a minimum number of observations necessary for kriging</p>
</td></tr>
<tr><td><code id="findRegionalBias_+3A_regcode">regCode</code></td>
<td>
<p>the column name of regions in the data polygons, if existing</p>
</td></tr>
<tr><td><code id="findRegionalBias_+3A_unbias">unbias</code></td>
<td>
<p>defines if a particular data dependent function should be used
to set unbiasedness constraints for the biases. &quot;default&quot; gives
one additional constraint, assuming that the average of the biases
should be equal to zero. See also details below.</p>
</td></tr>
<tr><td><code id="findRegionalBias_+3A_regionalbias">regionalBias</code></td>
<td>
<p> List of data frames, one for each region, each containing
biases for different networks in the region. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>This methods attempts to find biases between regional networks that are 
separated by a boundary, based on  line kriging along these boundaries. 
A typical example of such networks would be different national networks, 
with the country borders as <code>boundaryLines</code>, but also other 
boundaries can be considered. Further details can be found in Skoien et al. (2009).
</p>
<p>The parameter unbias can be used to name the unbiasedness function if 
the user needs a different unbiasedness constraint than the default one.
Such a function (with unbias = &quot;new&quot; above) should be similar to the following:
</p>
<pre>
  unBias.new = function(cDiff,uRegCode) {
    D = cDiff$D
    Q = cDiff$Q
    V = cDiff$V
#
    D = rbind(D,0)
    cd = dim(D)[1]
    ino = which(uRegCode == "NO")
    iis = which(uRegCode == "IS")
    iuk = which(uRegCode == "UK" | uRegCode == "GB")
    if (length(iis) &gt; 0) {
      D[cd,ino] = .5
      D[cd,iuk] = .5
      D[cd,iis]= -1
      Q[cd] = 0
      V[cd] = max(V)
      cd = cd+1
      D = rbind(D,0)
    }
    cd = cd + 1
    D = rbind(D,0)
    D[cd,] = 1
    Q[cd] = 0
    V[cd] = min(V)
    cDiff$D = D
    cDiff$Q = Q
    cDiff$V = V
    return(cDiff)
  }
  </pre>
<p>The last part is similar to unbias.default. In the other part is solving the 
problem where there are no boundaries between Iceland and any other 
countries. This would cause a missing constraint when searching for the 
biases, which will make it impossible to find a solution. The solution 
here sets the bias for Iceland equal to the average of the bias 
for Norway and United Kingdom. Note that the real bias for Iceland is not really
estimated in this case, this construction is mainly to make sure that the 
system can be solved. If one were only interested in the bias, it would in 
this case be better to remove Iceland from the data set, as a real bias
is not possible to find.
</p>


<h3>Value</h3>

 
<p>For <code>findRegionalBias</code>; a <code><a href="base.html#topic+data.frame">data.frame</a></code> with the biases for each country with uncertainty.
</p>
<p>For <code>removeRegionalBias</code>; a <code><a href="base.html#topic+data.frame">data.frame</a></code> with observations, with biases removed
</p>


<h3>Author(s)</h3>

<p> Jon Olav Skoien </p>


<h3>References</h3>

 
<p>Skoien, J. O., O. P. Baume, E. J. Pebesma, and G. B. M. Heuvelink. 2010. 
Identifying and removing heterogeneities between monitoring networks.
Environmetrics 21(1), 66-84.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(intamapInteractive)
data(meuse)
observations = data.frame(x = meuse$x,y = meuse$y,value = log(meuse$zinc))
coordinates(observations) = ~x+y
pBoundaries = spsample(observations, 10, "regular",bb = bbox(observations) +  
              matrix(c(-400,-400,400,400),ncol=2),offset=c(0,0))
gridded(pBoundaries) = TRUE
cs = pBoundaries@grid@cellsize[1]/2

Srl = list()
nb = dim(coordinates(pBoundaries))[1]
for (i in 1:nb) {
  pt1 = coordinates(pBoundaries)[i,]
  x1 = pt1[1]-cs
  x2 = pt1[1]+cs
  y1 = pt1[2]-cs
  y2 = pt1[2]+cs

  boun = data.frame(x=c(x1,x2,x2,x1,x1),y=c(y1,y1,y2,y2,y1))
  coordinates(boun) = ~x+y
  boun = Polygon(boun)
  Srl[[i]] = Polygons(list(boun),ID = as.character(i))
}
pBoundaries = SpatialPolygonsDataFrame(SpatialPolygons(Srl),
                                      data = data.frame(ID=c(1:nb)))
observations$ID = over(observations, geometry(pBoundaries))
blines = findBoundaryLines(pBoundaries, regCode = "ID")
rb = findRegionalBias(observations, blines, value~1, regCode = "ID")
rb$regionalBias

obs2 = removeRegionalBias(observations, rb, value~1, regCode = "ID")



</code></pre>

<hr>
<h2 id='optimizeNetwork'>Optimization of networks</h2><span id='topic+optimizeNetwork'></span>

<h3>Description</h3>

<p>Optimizes the sampling design of observation point locations using a varity of methods including spatial coverage 
by <code>k</code> means (as described in <code><a href="spcosa.html#topic+spcosa-package">spcosa</a></code>) or by maximizing nearest neighbour distances 
and spatial simulated annealing (SSA, as described in <code><a href="#topic+ssaOptim">ssaOptim</a></code>) using MUKV as a criterion (<code><a href="#topic+calculateMukv">calculateMukv</a></code>) .
</p>


<h3>Usage</h3>

<pre><code class='language-R'>optimizeNetwork(observations, predGrid, candidates, method, action,
                nDiff, model, criterion = "MUKV", plotOptim = TRUE, nGridCells, 
                nTry, nr_iterations = 10000, formulaString, fun, ...)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="optimizeNetwork_+3A_observations">observations</code></td>
<td>
<p> object of class <code><a href="sp.html#topic+Spatial-class">Spatial</a></code>*
with coordinates and possible covariates </p>
</td></tr>
<tr><td><code id="optimizeNetwork_+3A_predgrid">predGrid</code></td>
<td>
<p> object of class <code><a href="sp.html#topic+Spatial-class">Spatial</a></code>*
used when <code>method = "ssa"</code>. <code>predGrid</code> should contain the coordinates 
of prediction locations for optimization. Usually predGrid is a 
<code><a href="sp.html#topic+SpatialGrid">SpatialGrid</a></code> / <code><a href="sp.html#topic+SpatialGrid">SpatialPixels</a></code> 
or a <code><a href="sp.html#topic+SpatialGrid">SpatialGridDataFrame</a></code> /
<code><a href="sp.html#topic+SpatialGrid">SpatialPixelsDataFrame</a></code> when 
independent covariate predictor variables are used </p>
</td></tr>
<tr><td><code id="optimizeNetwork_+3A_candidates">candidates</code></td>
<td>
<p> when <code>method = "manual"</code> or <code>method = "ssa"</code>, candidates is the study area of class 
<code><a href="sp.html#topic+SpatialPolygons">SpatialPolygonsDataFrame</a></code>; for other methods, 
when <code>action = add</code>, candidates are points or polygons of class 
<code><a href="sp.html#topic+Spatial-class">Spatial</a></code>* </p>
</td></tr>
<tr><td><code id="optimizeNetwork_+3A_method">method</code></td>
<td>
 <p><code>"spcov"</code> for spatial coverage, 
<code>"ssa"</code> for spatial simulated annealing or 
<code>"manual"</code> for manual processing of the network </p>
</td></tr>
<tr><td><code id="optimizeNetwork_+3A_action">action</code></td>
<td>
<p> character string indicating which action to perform:
<code>"add"</code> to add new measurement stations to the existing 
network or <code>"del"</code> to delete existing stations </p>
</td></tr>
<tr><td><code id="optimizeNetwork_+3A_ndiff">nDiff</code></td>
<td>
<p> number of stations to add or delete </p>
</td></tr>
<tr><td><code id="optimizeNetwork_+3A_model">model</code></td>
<td>
<p> variogram model to consider when <code>method = "ssa"</code> and <code>criterion = "mukv"</code>; 
object of class <code>variogramModel</code>,
as generated by <code><a href="gstat.html#topic+vgm">vgm</a></code> </p>
</td></tr>
<tr><td><code id="optimizeNetwork_+3A_criterion">criterion</code></td>
<td>
<p> Only in use for method <code>"ssa"</code>:  character string, <code>"mukv"</code> </p>
</td></tr>
<tr><td><code id="optimizeNetwork_+3A_plotoptim">plotOptim</code></td>
<td>
<p> logical; if TRUE, creates a plot of the result as optimization progresses; TRUE by default </p>
</td></tr>
<tr><td><code id="optimizeNetwork_+3A_ngridcells">nGridCells</code></td>
<td>
<p> when method is <code>"spcov"</code> and action is <code>"add"</code>: the approximate number gridcells 
to explore within the candidate map as locations for new observations </p>
</td></tr>
<tr><td><code id="optimizeNetwork_+3A_ntry">nTry</code></td>
<td>
<p> when method is <code>"spcov"</code> and action is <code>"add"</code>: 
<code>nTry</code> is the number of initial configurations to try. The method will keep the best solution in order 
to reduce the risk of ending up with an unfavorable solution  </p>
</td></tr>
<tr><td><code id="optimizeNetwork_+3A_nr_iterations">nr_iterations</code></td>
<td>
<p> number of iterations to process before stoping. The default coolingFactor in <code><a href="#topic+ssaOptim">ssaOptim</a></code>
is also a function of number of iterations. Refer to <code><a href="#topic+ssaOptim">ssaOptim</a></code> for more details </p>
</td></tr>
<tr><td><code id="optimizeNetwork_+3A_formulastring">formulaString</code></td>
<td>
<p> When <code>method = "ssa"</code>, this formula defines the dependent 
variable as a linear model 
of independent variables; suppose the dependent variable has name <code>z</code>, 
for ordinary and simple kriging use the formula <code>z~1</code>; 
for universal kriging, suppose <code>z</code> is linearly dependent on 
<code>x</code> and <code>y</code>, use the formula <code>z~x+y</code>. The formulaString defaults
to <code>"value~1"</code> if <code>value</code> is a part of the data set. 
If not, the first column of the data set in <code>observations</code> is used. </p>
</td></tr>
<tr><td><code id="optimizeNetwork_+3A_fun">fun</code></td>
<td>
<p>Alternative objective function for optimization, the input and output should match
the ones of  (<code><a href="#topic+calculateMukv">calculateMukv</a></code> (except for <code>fun</code>)</p>
</td></tr>
<tr><td><code id="optimizeNetwork_+3A_...">...</code></td>
<td>
<p> other arguments to be passed on to lower level functions </p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function contains different methods to optimally add or remove point locations 
to or from a measurement network (Baume et al. 2011). 
Points can be added or deleted in the following ways: 
</p>

<ol>
<li><p>manually 
</p>
</li>
<li><p>using a spatial coverage approach by <code>k</code> means to add stations
(as described in <code><a href="spcosa.html#topic+spcosa-package">spcosa</a></code>, Brus et al. 2006) 
using a spatial coverage approach by maximizing mean nearest 
neighbour distances to remove stations (as described in <code><a href="#topic+spCovDel">spCovDel</a></code>)
</p>
</li>
<li><p>or using spatial simulated annealing 
with mean universal kriging variance as a criterion (<code><a href="#topic+calculateMukv">calculateMukv</a></code>, 
Brus &amp; Heuvelink 2007, Melles et al. 2011)
</p>
</li></ol>

<p>The results of different methods can be checked using the function <code><a href="#topic+calculateMukv">calculateMukv</a></code>, 
which returns mean universal kriging variance for an optimized network. 
</p>
<p>The user should be aware of the following limitations:
</p>

<ol>
<li> <p><code>method = "ssa"</code> is only implemented for <code>criterion = "mukv"</code> 
</p>
</li>
<li><p> Input <code>candidates</code> should preferably be a continuous domain such 
as <code><a href="sp.html#topic+SpatialPolygons">SpatialPolygons</a></code> 
</p>
</li>
<li> <p><code>method = "ssa"</code> with <code>criterion = "mukv"</code> makes it possible to assume a linear relationship between 
independent variables in predGrid and dependent variables at observation locations using
universal kriging (<code><a href="gstat.html#topic+krige">krige</a></code>). However, a correct estimate of 
mean universal kriging variance requires that the <code>independent</code> 
covariate variables be known 
at candidate locations. Thus it is necessary to have complete spatial 
coverage for all covariate predictors
in the linear model. Covariate information must be available at both 
new candidate measurement locations and 
prediction locations. This information is acquired (or sampled) from predGrid at 
candidate locations during SSA using a call 
to <code><a href="sp.html#topic+over">over</a></code> by default. But see <code><a href="#topic+ssaOptim">ssaOptim</a></code> 
for more details and an option to interpolate 
these values for candidate locations from predGrid. 
</p>
</li>
<li><p> Note that it is not recommended to use independent variables which differ strongly 
in magnitude (as for traditional universal kriging) 
</p>
</li>
<li><p> If no <code>formulaString</code> is supplied, an ordinary kriging formula is assumed, and 
optimization will proceed using mean ordinary kriging variance 
</p>
</li></ol>



<h3>Value</h3>

<p>Object of class <code><a href="sp.html#topic+SpatialPoints">SpatialPoints</a></code>* with spatial coordinates 
of optimized locations (including observation locations when <code>action = "add"</code>) 
</p>


<h3>Author(s)</h3>

<p> O. Baume, S.J. Melles, J. Skoien </p>


<h3>References</h3>

<p>O. P. Baume, A. Gebhardt, C. Gebhardt, G. B. M. Heuvelink, J. Pilz (2011). Network 
optimization algorithms and scenarios in the context of automatic mapping, Computers and Geosciences, 
37: 289-294 (2011). 
</p>
<p>S. J. Melles, G. B. M. Heuvelink, C. J. W. Twenhofel, U. Stohlker (2011).	Optimizing 
the spatial pattern of networks for monitoring radioactive releases, Computers and Geosciences, 
37: 280-288 (2011). 
</p>
<p>D. J. Brus, G. B. M. Heuvelink (2007). Optimization of sample patterns for universal 
kriging of environmental variables, Geoderma, 138: 86-95 (2007).
</p>
<p>D. J. Brus, J. de Gruijter, J. van Groenigen (2006). Designing spatial coverage samples using
the k-means clustering algorithm. In A. McBratney M. Voltz and P. Lagacherie,
editor, Digital Soil Mapping: An Introductory Perspective, Developments in Soil
Science, vol. 3., Elsevier, Amsterdam.
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+ssaOptim">ssaOptim</a></code>, <code><a href="#topic+spCovDel">spCovDel</a></code>, <code><a href="#topic+spCovAdd">spCovAdd</a></code>, <code><a href="#topic+calculateMukv">calculateMukv</a></code>, 
<code><a href="spcosa.html#topic+stratify-methods">stratify</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>
# load data:
library(gstat)
data(meuse)
coordinates(meuse) = ~x+y
data(meuse.grid)
coordinates(meuse.grid) = ~x+y
gridded(meuse.grid) = TRUE
predGrid = meuse.grid

# estimate variograms (OK/UK):
vfitOK = fit.variogram(variogram(zinc~1, meuse), vgm(1, "Exp", 300, 1))
vfitUK = fit.variogram(variogram(zinc~x+y, meuse), vgm(1, "Exp", 300, 1))
vfitRK = fit.variogram(variogram(zinc~dist+ffreq+soil, meuse), vgm(1, "Exp", 300, 1))

# study area of interest:
bb = bbox(predGrid)
boun = SpatialPoints(data.frame(x=c(bb[1,1],bb[1,2],bb[1,2],bb[1,1],bb[1,1]),
                                y=c(bb[2,1],bb[2,1],bb[2,2],bb[2,2],bb[2,1])))
Srl = Polygons(list(Polygon(boun)),ID = as.character(1))
candidates = SpatialPolygonsDataFrame(SpatialPolygons(list(Srl)),
                                      data = data.frame(ID=1))


# add 20 more points assuming OK model (SSA method):
 optimOK &lt;- optimizeNetwork(meuse, meuse.grid, candidates = candidates,
  method= "ssa", action= "add", nDiff = 20, model = vfitOK, criterion="MUKV",
  nr_iterations=10000, nmax=40)


# add 20 more points assuming UK model (SSA method):
optimUK &lt;- optimizeNetwork(meuse, meuse.grid, candidates = candidates,
   method = "ssa", action = "add", nDiff = 20, model=vfitUK, criterion="MUKV",
   nr_iterations = 10000, nmax = 40, formulaString = zinc~x+y)

# add 20 more points with auxiliary variables (SSA method):
optimRK &lt;- optimizeNetwork(meuse, meuse.grid, candidates=candidates,
   method="ssa", action="add", nDiff=4, model=vfitRK, criterion="MUKV",
   nr_iterations=10000, formula=zinc~dist+ffreq+soil, nmax=200)

# add optimally 20 stations from current network with method "spcov"
# (spatial coverage method)
optimSC = optimizeNetwork(meuse, meuse.grid, candidates, method = "spcov",
            action = "add", nDiff = 10, model = model, criterion = "MUKV", plotOptim = TRUE,
            nGridCells = 10000,nTry = 100 )

# delete optimally 10 stations from current network with method "manual"
if (interactive()) optimMAN = optimizeNetwork(meuse, meuse.grid, candidates, method = "manual",
            action = "del", nDiff = 10, model = model, criterion = "MUKV", plotOptim = TRUE )


# comparison of results with ordinary kriging variogram, otherwise add formulaString
# ssa method, assuming ordinary kriging
calculateMukv(optimOK, predGrid, vfitOK) 

# ssa method, using spatial location as covariates
calculateMukv(optimUK, predGrid, vfitUK, zinc~x+y)
 
# ssa method, using other variables as covariates
calculateMukv(optimRK, predGrid, vfitRK, zinc~dist+ffreq+soil) 

# spcov method
calculateMukv(optimSC, predGrid, vfitOK) 

# 10 stations manually deleted
if (interactive()) calculateMukv(optimMAN, predGrid, vfitOK, zinc~1) 


</code></pre>

<hr>
<h2 id='spCovAdd'>Spatial coverage method to add new measurements</h2><span id='topic+spCovAdd'></span>

<h3>Description</h3>

<p>This function spCovAdd allows to build optimization scenarios based on spatial coverage method.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>spCovAdd( observations, candidates, nDiff, nGridCells, plotOptim = TRUE, nTry, ... )
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="spCovAdd_+3A_observations">observations</code></td>
<td>
<p> object of class <code><a href="base.html#topic+data.frame">data.frame</a></code> with x,y coordinates</p>
</td></tr>
<tr><td><code id="spCovAdd_+3A_candidates">candidates</code></td>
<td>
<p> a <code><a href="sp.html#topic+SpatialPolygons">SpatialPolygonsDataFrame</a></code> to explore: in use when optimizing 
the implementation of new measurement stations to an existing network </p>
</td></tr>
<tr><td><code id="spCovAdd_+3A_ndiff">nDiff</code></td>
<td>
<p> number of stations to add or delete </p>
</td></tr>
<tr><td><code id="spCovAdd_+3A_ngridcells">nGridCells</code></td>
<td>
<p> number of grid cells to work on spatial coverage strafication </p>
</td></tr>
<tr><td><code id="spCovAdd_+3A_plotoptim">plotOptim</code></td>
<td>
<p>logical; to plot the result or not</p>
</td></tr>
<tr><td><code id="spCovAdd_+3A_ntry">nTry</code></td>
<td>
<p> the method will try <code>nTry</code> initial configurations and will keep 
the best solution in order to reduce the risk of ending up with an unfavorable solution </p>
</td></tr>
<tr><td><code id="spCovAdd_+3A_...">...</code></td>
<td>
<p> other arguments to be passed on at lower level functions such as 
<code><a href="spcosa.html#topic+stratify-methods">stratify</a></code> </p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function allows to build optimization scenarios based on spatial coverage method. 
The scenario action is &quot;add&quot;. To add new measurement locations to the running network, 
the function uses function <code><a href="spcosa.html#topic+stratify-methods">stratify</a></code> from package <code>spcosa</code>. 
Function stratify adds new strata to the domain study. 
</p>


<h3>Value</h3>

<p><code><a href="base.html#topic+data.frame">data.frame</a></code> of optimized locations
</p>


<h3>Author(s)</h3>

<p> Olivier Baume </p>


<h3>References</h3>

<p>D. J. Brus, J. de Gruijter, J. van Groenigen (2006). Designing spatial coverage samples using
the k-means clustering algorithm. In A. McBratney M. Voltz and P. Lagacherie,
editor, Digital Soil Mapping: An Introductory Perspective, Developments in Soil
Science, vol. 3., Elsevier, Amsterdam.
</p>

<hr>
<h2 id='spCovDel'>Optimize the network with spatial coverage methods</h2><span id='topic+spCovDel'></span>

<h3>Description</h3>

<p>The function spCovDel allows to build optimization scenarios based on spatial coverage method.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>spCovDel(observations, candidates, nDiff, plotOptim = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="spCovDel_+3A_observations">observations</code></td>
<td>
<p> object of class <code><a href="base.html#topic+data.frame">data.frame</a></code> with x,y coordinates</p>
</td></tr>
<tr><td><code id="spCovDel_+3A_candidates">candidates</code></td>
<td>
<p> not compulsory used only for plotting purpose &ndash; a 
<code><a href="sp.html#topic+SpatialPolygons">SpatialPolygonsDataFrame</a></code> describing the study area </p>
</td></tr>
<tr><td><code id="spCovDel_+3A_ndiff">nDiff</code></td>
<td>
<p> number of stations to add or delete </p>
</td></tr>
<tr><td><code id="spCovDel_+3A_plotoptim">plotOptim</code></td>
<td>
<p>logical; to plot the result or not</p>
</td></tr>
<tr><td><code id="spCovDel_+3A_...">...</code></td>
<td>
<p> other arguments to be passed on at lower level functions such as 
<code><a href="spatstat.geom.html#topic+nndist">nndist</a></code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function allows to build optimization scenarios based on spatial coverage method. 
When action is &quot;del&quot;, the function maximizes the mean distance of measurements with direct neighbours using function 
<code><a href="spatstat.geom.html#topic+nndist">nndist</a></code>. The heuristic search uses a 
swapping algorithm to converge more rapidly to the best solution.
</p>


<h3>Value</h3>

<p><code><a href="base.html#topic+data.frame">data.frame</a></code> of optimized locations
</p>


<h3>Author(s)</h3>

<p> Olivier Baume </p>

<hr>
<h2 id='ssaOptim'> Spatial simulated annealing (SSA) for optimization of sampling designs using a geostatistical measure of spatial prediction error </h2><span id='topic+ssaOptim'></span>

<h3>Description</h3>

<p>Spatial simulated annealing uses slight perturbations of previous sampling designs and a random search technique to solve spatial optimization problems. 
Candidate measurement locations are iteratively moved around and optimized by minimizing the mean universal kriging variance (<code><a href="#topic+calculateMukv">calculateMukv</a></code>). The approach relies on a known, pre-specified
model for underlying spatial variation (<code>variogramModel</code>). </p>


<h3>Usage</h3>

<pre><code class='language-R'>ssaOptim(observations, predGrid, candidates, action, nDiff, model,
         nr_iterations, plotOptim = TRUE, formulaString = NULL, 
         coolingFactor = nr_iterations/10, covariates = "over", fun, ...)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ssaOptim_+3A_observations">observations</code></td>
<td>
<p> object of class <code><a href="sp.html#topic+Spatial-class">Spatial</a></code> with coordinates and possible covariates </p>
</td></tr>
<tr><td><code id="ssaOptim_+3A_predgrid">predGrid</code></td>
<td>
<p> object of class <code><a href="sp.html#topic+Spatial-class">Spatial</a></code>*
used when <code>method = "ssa"</code>. <code>predGrid</code> should contain the coordinates 
of prediction locations for optimization. Usually predGrid is a 
<code><a href="sp.html#topic+SpatialGrid">SpatialGrid</a></code> / <code><a href="sp.html#topic+SpatialGrid">SpatialPixels</a></code> 
or a <code><a href="sp.html#topic+SpatialGrid">SpatialGridDataFrame</a></code> /  
<code><a href="sp.html#topic+SpatialGrid">SpatialPixelsDataFrame</a></code> when 
independent covariate predictor variables are used </p>
</td></tr>
<tr><td><code id="ssaOptim_+3A_candidates">candidates</code></td>
<td>
<p> candidates is the study area of class 
<code><a href="sp.html#topic+SpatialPolygons">SpatialPolygonsDataFrame</a></code> </p>
</td></tr>
<tr><td><code id="ssaOptim_+3A_action">action</code></td>
<td>
<p> character string indicating which type of action to perform: 
<code>"add"</code> to add new measurement stations to the existing network or 
<code>"del"</code> to delete existing stations </p>
</td></tr>
<tr><td><code id="ssaOptim_+3A_ndiff">nDiff</code></td>
<td>
<p> number of stations to add or delete </p>
</td></tr>
<tr><td><code id="ssaOptim_+3A_model">model</code></td>
<td>
<p> variogram model:object of class <code>variogramModel</code>,
as generated by <code><a href="gstat.html#topic+vgm">vgm</a></code></p>
</td></tr>
<tr><td><code id="ssaOptim_+3A_nr_iterations">nr_iterations</code></td>
<td>
<p> number of iterations to process before stopping. The default
<code>coolingFactor</code> is also a function of number of iterations. </p>
</td></tr>
<tr><td><code id="ssaOptim_+3A_plotoptim">plotOptim</code></td>
<td>
<p> logical; if TRUE, creates a plot of the result as optimization 
progresses; TRUE by default </p>
</td></tr>
<tr><td><code id="ssaOptim_+3A_formulastring">formulaString</code></td>
<td>
<p> formula that defines the dependent variable as a linear model 
of independent variables; suppose the dependent variable has name <code>z</code>, 
for ordinary and simple kriging use the formula <code>z~1</code>; 
for universal kriging, suppose <code>z</code> is linearly dependent on 
<code>x</code> and <code>y</code>, use the formula <code>z~x+y</code>. The formulaString defaults
to <code>"value~1"</code> if <code>value</code> is a part of the data set. 
If not, the first column of the data set is used. </p>
</td></tr>
<tr><td><code id="ssaOptim_+3A_coolingfactor">coolingFactor</code></td>
<td>
<p> variable defining how fast the algorithm will cool down. With SSA, 
worsening designs are accepted with a decreasing probability (generally set to
<code>p</code> $&lt;$ 0.2 to avoid selection of local minima). The <code>coolingFactor</code>
dictates the rate at which <code>p</code> decreases to zero. Commonly <code>p</code> is set to 
exponentially decrease or cool as a function of number of iterations to ensure convergence 
(Brus &amp; Heuvelink 2007, Melles et al. 2011). Smaller numbers give quicker cooling; 
higher numbers give slower cooling. </p>
</td></tr>
<tr><td><code id="ssaOptim_+3A_covariates">covariates</code></td>
<td>
<p> character string defining whether possible covariates should be found 
by &quot;over&quot; or &quot;krige&quot;, see also details below </p>
</td></tr>
<tr><td><code id="ssaOptim_+3A_fun">fun</code></td>
<td>
<p>Alternative objective function for optimization, the input and output should match
the ones of  (<code><a href="#topic+calculateMukv">calculateMukv</a></code> (except for <code>fun</code>)</p>
</td></tr>
<tr><td><code id="ssaOptim_+3A_...">...</code></td>
<td>
<p> other arguments to be passed on to lower level functions </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The default version of this function applies spatial simulated annealing for  
optimization with the MUKV criterion (<code><a href="#topic+calculateMukv">calculateMukv</a></code>). 
With covariates, the function takes a universal kriging model into account. 
When optimizing a sampling design using SSA and <code>criterion = "mukv"</code>, 
measurement values at new sampling locations are not required in order to 
calculate prediction error variance (<code>criterion = "mukv"</code>). 
This attractive property allows one to estimate the kriging prediction error 
variance prior to collecting the data (i.e., the dependent variable 
is unknown at new candidate locations), and it is this property that is used in 
the SSA optimization procedure after (Brus &amp; Heuvelink 2007, Melles et al. 2011).
</p>
<p>A stopping criterion <code>countMax</code> is implemented in lower level functions to 
end the optimization procedure after 200 search steps 
have occurred without an improvement in the design. If this stopping criterion 
is reached before <code>nr_iterations</code>, SSA will terminate. 
</p>
<p><code>method = "ssa"</code> with <code>criterion = "mukv"</code> makes it possible to assume 
a linear relationship between independent variables in predGrid 
and dependent variables at observation locations using universal kriging 
(<code><a href="gstat.html#topic+krige">krige</a></code>). However, a correct estimate of mean universal 
kriging variance requires that the <code>independent</code> covariate variables be 
known at candidate locations. Thus it is necessary to have complete spatial 
coverage for all covariate predictors in the linear model. Covariate information 
must be available at both new candidate measurement locations and prediction locations. 
This is not possible (except for the measurement locations themselves). 
Instead, these are estimated from the prediction locations.
</p>
<p>There are two possible methods to attain information on covariates at the 
candidate locations, and the method can be set using the argument <code>covariates</code>: 
<code><a href="sp.html#topic+over">over</a></code> and <code><a href="gstat.html#topic+krige">krige</a></code>. <code><a href="sp.html#topic+over">over</a></code> finds the value of 
covariates at new locations by overlaying candidate locations on the prediction grid 
and taking the value of the nearest neighbour. The second method uses kriging to 
estimate covariate values at new locations from predGrid. The first method is 
generally faster, the second method is most likely more exact, particularly if 
the resolution of predGrid is low in relation to the spatial correlation lengths of the covariates. 
Both methods are approximations that may influence the criterion used for 
optimization with increasing numbers of points added. 
</p>
<p>It is possible to submit an alternative function <code>fun</code> as objective function.
This function should take at least the observation locations and the predGrid as input, and 
return a value which should be minimized. See also  <code><a href="#topic+calculateMukv">calculateMukv</a></code> for more information
about arguments to this function.
</p>


<h3>Value</h3>

<p>SpatialPointsDataFrame with optimized locations
</p>


<h3>Author(s)</h3>

<p> O. Baume, S.J. Melles, J. Skoien </p>


<h3>References</h3>

<p>D. J. Brus, G. B. M. Heuvelink (2007). Optimization of sample patterns for universal 
kriging of environmental variables, Geoderma, 138: 86-95 (2007). 
</p>
<p>S. J. Melles, G. B. M. Heuvelink, C. J. W. Twenhofel, U. Stohlker (2011).	Optimizing 
the spatial pattern of networks for monitoring radioactive releases, Computers and Geosciences, 
37: 280-288 (2011).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# load data:
library(gstat)
data(meuse)
coordinates(meuse) = ~x+y
data(meuse.grid)
coordinates(meuse.grid) = ~x+y
gridded(meuse.grid) = TRUE
predGrid = meuse.grid

# estimate variograms (OK/UK):
vfitOK = fit.variogram(variogram(zinc~1, meuse), vgm(1, "Exp", 300, 1))
vfitUK = fit.variogram(variogram(zinc~x+y, meuse), vgm(1, "Exp", 300, 1))
vfitRK = fit.variogram(variogram(zinc~dist+ffreq+soil, meuse), vgm(1, "Exp", 300, 1))

# study area of interest:
bb = bbox(predGrid)
boun = SpatialPoints(data.frame(x=c(bb[1,1],bb[1,2],bb[1,2],bb[1,1],bb[1,1]),
                                y=c(bb[2,1],bb[2,1],bb[2,2],bb[2,2],bb[2,1])))
Srl = Polygons(list(Polygon(boun)),ID = as.character(1))
candidates = SpatialPolygonsDataFrame(SpatialPolygons(list(Srl)),
                                      data = data.frame(ID=1))

# add 20 more points assuming OK model (SSA method):
optimOK &lt;- ssaOptim(meuse, meuse.grid, candidates = candidates, covariates = "over",
            nDiff = 20, action = "add", model = vfitOK, nr_iterations = 10000, 
            formulaString = zinc~1, nmax = 40, countMax = 200)

# add 20 more points assuming UK model (SSA method):
optimUK &lt;- ssaOptim(meuse, meuse.grid, candidates = candidates, covariates = "over",
            nDiff = 20, action = "add", model = vfitUK, nr_iterations = 10000, 
            formulaString = zinc~x+y, nmax = 40, countMax = 200)

# add 20 more points with auxiliary variables (SSA method):
optimRK &lt;- ssaOptim(meuse, meuse.grid, candidates = candidates, covariates = "over",
            nDiff = 20, action = "add", model = vfitRK, nr_iterations = 10000, 
            formulaString = zinc~dist+ffreq+soil, nmax = 40, countMax = 200)
   
   </code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
