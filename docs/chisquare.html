<!DOCTYPE html><html><head><title>Help for package chisquare</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {chisquare}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#chisquare'><p>R function for Chi-square, (N-1) Chi-square, and G-Square test of independence, power calculation, measures of association, and standardized/moment-corrected</p>
standardized/adjusted standardized residuals, visualisation of odds ratio in 2xk tables (where k &gt;= 2)</a></li>
<li><a href='#diseases'><p>Dataset: Cross-tabulation of quantity of tobacco smoked daily vs. cause of</p>
death</a></li>
<li><a href='#safety'><p>Dataset: Cross-tabulation of people's feeling of safety vs. town size</p></a></li>
<li><a href='#social_class'><p>Dataset: Cross-tabulation of social class vs. diagnostic category for a sample of psychiatric patients</p></a></li>
<li><a href='#suggest_chi_squared_method'><p>Suggest chi-squared testing method for the input contingency table</p></a></li>
<li><a href='#visualize_odds_ratios'><p>Visualize Odds Ratios for a 2xk (where k &gt;= 2) Contingency Table (internal function)</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Title:</td>
<td>Chi-Square and G-Square Test of Independence, Power and Residual
Analysis, Measures of Categorical Association</td>
</tr>
<tr>
<td>Version:</td>
<td>0.9</td>
</tr>
<tr>
<td>Description:</td>
<td>Provides the facility to perform the chi-square and G-square test of independence, calculates the power of the traditional chi-square test, compute permutation and Monte Carlo p-value, and provides measures of association such as Phi, odds ratio with 95 percent CI and p-value, adjusted contingency coefficient, Cramer's V and 95 percent CI, bias-corrected Cramer's V, W, Cohen's w, Goodman-Kruskal's lambda, gamma and its p-value, and tau, Cohen's k and its 95 percent CI. It also calculates standardized, moment-corrected standardized, and adjusted standardized residuals, and their significance. Different outputs are returned in nicely formatted tables.</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 4.0.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>graphics (&ge; 4.2.0), gt (&ge; 0.3.1), stats (&ge; 4.2.0)</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-01-08 10:42:46 UTC; gianmarcoalberti</td>
</tr>
<tr>
<td>Author:</td>
<td>Gianmarco Alberti [aut, cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Gianmarco Alberti &lt;gianmarcoalberti@gmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-01-08 15:00:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='chisquare'>R function for Chi-square, (N-1) Chi-square, and G-Square test of independence, power calculation, measures of association, and standardized/moment-corrected
standardized/adjusted standardized residuals, visualisation of odds ratio in 2xk tables (where k &gt;= 2)</h2><span id='topic+chisquare'></span>

<h3>Description</h3>

<p>The function performs the chi-square test (both in its original format and in the N-1 version) and the G-square test of independence
on the input contingency table. It also calculates the power of the traditional chi-square test and various measures of categorical association,
returns standardized, moment-corrected standardized, and adjusted standardized residuals (with indication of their significance),
and calculates relative and absolute contributions to the chi-square. The p value associated to the chi-square statistic is also calculated via both
a permutation- and a Monte Carlo-based method. The 95 percent confidence interval around those p values is also calculated.
Nicely-formatted output tables are rendered. Optionally, in 2xk tables (where k &gt;= 2), a plot of the odds ratios can be rendered.<br />
Visit this <a href="https://drive.google.com/file/d/1WxRUOpKUGcHW8OwMJLS_uy5QmLaCplCa/view?usp=sharing">LINK</a> to access the package's vignette.<br />
</p>


<h3>Usage</h3>

<pre><code class='language-R'>chisquare(
  data,
  B = 1000,
  plot.or = FALSE,
  reference.level = 1,
  row.level = 1,
  or.alpha = 0.05,
  power.alpha = 0.05,
  adj.alpha = FALSE,
  format = "short",
  graph = FALSE,
  oneplot = TRUE,
  tfs = 13
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="chisquare_+3A_data">data</code></td>
<td>
<p>Dataframe containing the input contingency table.</p>
</td></tr>
<tr><td><code id="chisquare_+3A_b">B</code></td>
<td>
<p>Number of simulated tables to be used to calculate the permutation- and the Monte Carlo-based p value (1000 by default).</p>
</td></tr>
<tr><td><code id="chisquare_+3A_plot.or">plot.or</code></td>
<td>
<p>Takes TRUE or FALSE (default) if the user wants a plot of the odds ratios to be rendered (only for 2xk tables, where k &gt;= 2).</p>
</td></tr>
<tr><td><code id="chisquare_+3A_reference.level">reference.level</code></td>
<td>
<p>The index of the column reference level for odds ratio calculations (default: 1).
The user must select the column level to serve as the reference level (only for 2xk tables, where k &gt;= 2).</p>
</td></tr>
<tr><td><code id="chisquare_+3A_row.level">row.level</code></td>
<td>
<p>The index of the row category to be used in odds ratio calculations (1 or 2; default: 1).
The user must select the row level to which the calculation of the odds ratios make reference (only for 2xk tables, where k &gt;= 2).</p>
</td></tr>
<tr><td><code id="chisquare_+3A_or.alpha">or.alpha</code></td>
<td>
<p>The significance level used for the odds ratios' confidence intervals (default: 0.05).</p>
</td></tr>
<tr><td><code id="chisquare_+3A_power.alpha">power.alpha</code></td>
<td>
<p>The significance level used for the calculation of the power of the traditional chi-square test (default: 0.05).</p>
</td></tr>
<tr><td><code id="chisquare_+3A_adj.alpha">adj.alpha</code></td>
<td>
<p>Takes TRUE or FALSE (default) if the user wants or does not want the significance level of the
residuals (standardised, adjusted standardised, and moment-corrected) to be corrected using the Sidak's adjustment method (see Details).</p>
</td></tr>
<tr><td><code id="chisquare_+3A_format">format</code></td>
<td>
<p>Takes <em>short</em> (default) if the dataset is a dataframe storing a contingency table; if the
input dataset is a dataframe storing two columns that list the levels of the two categorical variables,
<em>long</em> will preliminarily cross-tabulate the levels of the categorical variable in the 1st column against
the levels of the variable stored in the 2nd column.</p>
</td></tr>
<tr><td><code id="chisquare_+3A_graph">graph</code></td>
<td>
<p>Takes TRUE or FALSE (default) if the user wants or does not want to plot the permutation and Monte Carlo
distribution of the chi-square statistic accross the number of simulated tables set by the B parameter.</p>
</td></tr>
<tr><td><code id="chisquare_+3A_oneplot">oneplot</code></td>
<td>
<p>Takes TRUE (default) or FALSE if the user wants or does not want to render of the permutation and Monte Carlo
distribution in the same plot.</p>
</td></tr>
<tr><td><code id="chisquare_+3A_tfs">tfs</code></td>
<td>
<p>Numerical value to set the size of the font used in the main body of the various output tables (13 by default).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function produces the following <strong>measures of categorical associations</strong>:
</p>

<ul>
<li><p> Phi (with indication of the magnitude of the effect size; only for 2x2 tables)
</p>
</li>
<li><p> Phi corrected (with indication of the magnitude of the effect size; only for 2x2 tables)
</p>
</li>
<li><p> Phi signed (with indication of the magnitude of the effect size; only for 2x2 tables)
</p>
</li>
<li><p> Yule's Q (only for 2x2 tables, includes p-value)
</p>
</li>
<li><p> Odds ratio (only for 2x2 tables, includes 95perc confidence interval, p value, and indication of the magnitude of the effect size)
</p>
</li>
<li><p> Adjusted contingency coefficient C (with indication of the magnitude of the effect size)
</p>
</li>
<li><p> Cramer's V (with 95perc confidence interval; includes indication of the magnitude of the effect size)
</p>
</li>
<li><p> Bias-corrected Cramer's V (with indication of the magnitude of the effect size)
</p>
</li>
<li><p> Cohen's w (with indication of the magnitude of the effect size)
</p>
</li>
<li><p> W coefficient (includes 95perc confidence interval and magnitude of the effect size)
</p>
</li>
<li><p> Goodman-Kruskal's lambda (both asymmetric and symmetric)
</p>
</li>
<li><p> Corrected version of lambda (both asymmetric and symmetric)
</p>
</li>
<li><p> Goodman-Kruskal's tau (asymmetric) and gamma (with p-value)
</p>
</li>
<li><p> Cohen's k (with 95perc confidence interval)
</p>
</li></ul>

<p><strong>Indication of the magnitude of the association as indicated by the coefficients</strong><br />
The function provides indication of the mangitude of the association (effect size) for the Phi, Phi corrected, Phi signed, Cadj, Cramer's V, Cramer's V bias-corrected,
Cohen's w, W, and for the Odds Ratio.<br />
</p>
<p>With the exception of the latter (for which see further down), the effect size for the other measures of association
is based on Cohen 1988.<br />
</p>
<p>Phi, Phi corrected, Phi signed, and w are assessed against the well-known Cohen's classification
scheme's thresholds (small 0.1, medium 0.3, large 0.5). For input cross-tabs larger than 2x2, the Cadj, V, V bias-corrected, and W coefficients
are assessed against thresholds that depend on the table's df, which (as per Cohen 1988) correspond to the smaller between the rows and columns number,
minus 1. On the basis of the table's df, the three thresholds are calculated as follows: <br />
</p>
<p>small effect: 0.100 / sqrt(min(nr,nc)-1)<br />
medium effect: 0.300 / sqrt(min(nr,nc)-1)<br />
large effect: 0.500 / sqrt(min(nr,nc)-1)<br />
</p>
<p>where nr and nc are the number of rows and number of columns respectively, and min(nr,nc)-1 corresponds to the table's df.
Essentially, the thresholds for a small, medium, and large effect are computed by dividing the Cohen's thresholds for a 2x2 table (df=1)
by the square root of the input table's df.<br />
</p>
<p>Consider a V value of (say) 0.35; its effect size interpretation changes based on the table's dimension:<br />
</p>
<p>for a 2x2 table, 0.35 corresponds to a &quot;medium&quot; effect;<br />
for a 3x3 table, 0.35 still corresponds to a &quot;medium&quot; effect;<br />
for a 4x4 table, 0.35 corresponds to a &quot;large&quot; effect.<br />
</p>
<p>The examples illustrate that for the same (say) V value, the interpreted effect size can shift from &quot;medium&quot; in a smaller table to &quot;large&quot; in a larger table.
In simpler terms, the threshold for determining a &quot;large&quot; effect, for instance, becomes more accessible to reach as the table's size increases.<br />
</p>
<p>It is crucial to be aware of this as it highlights that the same coefficient value can imply different magnitudes of effect depending on the table's size<br />
</p>
<p>See: Cohen 1988; Sheskin 2011.
</p>
<p><strong>Power of the Traditional Chi-Square Test</strong><br />
The function calculates the power of the traditional chi-square test, which is the probability of correctly rejecting the null
hypothesis when it is false. The power is determined by the observed chi-square statistic, the sample size,
and the degrees of freedom, without explicitly calculating an effect size, following the method described by Oyeyemi et al. 2010.
</p>
<p>The degrees of freedom are calculated as (number of rows - 1) * (number of columns - 1). The alpha level is set by default at 0.05
and can be customized using the <code>power.alpha</code> parameter. The power is then estimated using the non-centrality parameter based
on the observed chi-square statistic.
</p>
<p>The calculation involves determining the critical chi-squared value based on the alpha level and degrees of freedom, and then
computing the probability that the chi-squared distribution with the given degrees of freedom exceeds this critical value.
</p>
<p>The resulting power value indicates how likely the test is to detect an effect if one exists. A power value close to 1 suggests a
high probability of detecting a true effect, while a lower value indicates a higher risk of a Type II error. Typically, a power
value of 0.8 or higher is considered robust in most research contexts.
</p>
<p><strong>Suggestion of a suitable chi-square testing method</strong><br />
The first rendered table includes a suggestion for the applicable chi-squared test method,
derived from an internal analysis of the input contingency table. The decision logic used is as follows:<br />
</p>
<p>For 2x2 Tables:<br />
- if the grand total is equal to or larger than 5 times the number of cells,
the traditional Chi-Square test is suggested. Permutation or Monte Carlo
methods can also be considered.<br />
</p>
<p>- if the grand total is smaller than 5 times the number of cells, the minimum expected count is checked:<br />
(A) if it is equal to or larger than 1, the (N-1)/N adjusted Chi-Square test is
suggested, with an option for Permutation or Monte Carlo methods.<br />
(B) if it is less than 1, the Permutation or Monte Carlo method is recommended.<br />
</p>
<p>For Larger than 2x2 Tables:<br />
- the logic is similar to that for 2x2 tables, with the same criteria for
suggesting the traditional Chi-Square test, the (N-1)/N adjusted test,
or the Permutation or Monte Carlo methods.<br />
</p>
<p>The rationale of a threshold for the applicability of the traditional chi-square test corresponding to
5 times the number of cells is based on the following.<br />
</p>
<p>Literature indicates that the traditional chi-squared test's validity is not as fragile as once thought,
especially when considering the average expected frequency across all cells in the cross-tab, rather than
the minimum expected value in any single cell. An average expected frequency of at least 5 across all
cells of the input table should be sufficient for maintaining the chi-square test's reliability at the
0.05 significance level.<br />
</p>
<p>As a consequence, a table's grand total equal to or larger than 5 times the number of cells should ensure the applicability
of the traditional chi-square test (at alpha 0.05).<br />
</p>
<p>See: Roscoe-Byars 1971; Greenwood-Nikulin 1996; Zar 2014.<br />
</p>
<p>For the rationale of the use of the (N-1)/N adjusted version of the chi-square test,
and for the permutation and Monte Carlo method, see below.<br />
</p>
<p><strong>Chi-square statistics adjusted using the (N-1)/N adjustment</strong><br />
The adjustment is done by multiplying the chi-square statistics by (N-1)/N, where N is the table grand total (sample size). The p-value
of the corrected statistic is calculated the regular way (i.e., using the same degrees of freedom as in the traditional test).
The correction seems particularly relevant for tables where N is smaller than 20 and where the expected frequencies are equal
or larger than 1. The corrected chi-square test proves more conservative when the sample size is small.
As N increases, the term (N-1)/N approaches 1, making the adjusted chi-square value virtually equivalent to the unadjusted value.<br />
</p>
<p>See: Upton 1982; Rhoades-Overall1982; Campbel 2007; Richardson 2011. <br />
</p>
<p><strong>Permutation-based and Monte Carlo p-value for the chi-square statistic</strong><br />
The p-value of the observed chi-square statistic is also calculated on the basis of both a permutation-based and a
Monte Carlo approach. In the first case, the dataset is permuted <em>B</em> times (1000 by default), whereas in the second method
<em>B</em> establishes the number of random tables generated under the null hypothesis of independence (1000 by default).<br />
</p>
<p>As for the permutation method, the function does the following internally:<br />
(1) Converts the input dataset to long format and expands to individual observations; <br />
(2) Calculates the observed chi-squared statistic; <br />
(3) Randomly shuffles (B times) the labels of the levels of one variable, and recalculates chi-squared statistic for each shuffled dataset;
(4) Computes the p-value based on the distribution of permuted statistics (see below).<br />
</p>
<p>For the rationale of the permutation-based approach, see for instance Agresti et al 2022.<br />
</p>
<p>For the rationale of the Monte Carlo approach, see for instance the description in Beh-Lombardo 2014: 62-64.<br />
</p>
<p>Both simulated p-values are calculated as follows: <br />
</p>
<p><code class="reqn">sum (chistat.simulated &gt;= chisq.stat) / B</code>, where<br />
</p>
<p><em>chistat.simulated</em> is a vector storing the B chi-squared statistics generated under the Null Hypothesis, and<br />
<em>chisq.stat</em> is the observed chi-squared statistic.<br />
</p>
<p>Both distributions can be optionally plotted setting the <code>graph</code> parameter to <code>TRUE</code>.<br />
</p>
<p><strong>Confidence interval around the permutation-based and Monte Carlo p-value</strong><br />
The function calculates the 95 percent Confidence Interval around the simulated p-values.
The Wald CI quantifies the uncertainty around the simulated p-value estimate. For a 95 percent CI,
the standard z-value of 1.96 is used. The standard error for the estimated p-value is computed as the square root of
(estimated p-value * (1 - estimated p-value) / number of simulations-1).
</p>
<p>The lower and upper bounds of the CI are then calculated as follows:<br />
Lower Confidence Interval = estimated p-value - (z-value * standard error)<br />
Upper Confidence Interval = estimated p-value + (z-value * standard error)<br />
</p>
<p>Finally, the lower and upper CIs are clipped to lie within 0 and 1.<br />
</p>
<p>The implemented procedure aligns with the one described at this link:
https://blogs.sas.com/content/iml/2015/10/28/simulation-exact-tables.html<br />
</p>
<p><strong>Moment-corrected standardized residuals</strong><br />
The moment-corrected standardized residuals are calculated as follows: <br />
</p>
<p><code class="reqn">stand.res / (sqrt((nr-1)*(nc-1)/(nr*nc)))</code>, where<br />
</p>
<p><em>stand.res</em> is each cell's standardized residual, <em>nr</em> and
<em>nc</em> are the number of rows and columns respectively.<br />
</p>
<p>See Garcia-Perez-Nunez-Anton 2003: 827.<br />
</p>
<p><strong>Adjusted standardized residuals</strong><br />
The adjusted standardized residuals are calculated as follows: <br />
</p>
<p><code class="reqn">stand.res[i,j] / sqrt((1-sr[i]/n)*(1-sc[j]/n))</code>, where<br />
</p>
<p><em>stand.res</em> is the standardized residual for cell <em>ij</em>,
<em>sr</em> is the row sum for row <em>i</em>, <em>sc</em> is the column sum for column <em>j</em>, and
<em>n</em> is the table grand total. The <em>adjusted standardized residuals</em> should be used in place of
the standardised residuals since the latter are not truly standarised because they have a nonunit variance. The
standardised residuals therefore underestimate the divergence between the observed and the expected counts. The adjusted
standardized residuals (and the moment-corrected ones) correct that deficiency.<br />
</p>
<p>For more info see: Haberman 1973.<br />
</p>
<p><strong>Significance of the residuals</strong><br />
The significance of the residuals (standardized, moment-corrected standardized, and adjusted standardized) is assessed using alpha 0.05 or, optionally
(by setting the parameter <code>adj.alpha</code> to <code>TRUE</code>),
using an adjusted alpha calculated using the Sidak's method:<br />
</p>
<p><code class="reqn">alpha.adj = 1-(1 - 0.05)^(1/(nr*nc))</code>, where<br />
</p>
<p><em>nr</em> and <em>nc</em> are the number of rows and columns in the table respectively. The adjusted
alpha is then converted into a critical two-tailed z value. <br />
</p>
<p>See: Beasley-Schumacker 1995: 86, 89.<br />
</p>
<p><strong>Cells' relative contribution (in percent) to the chi-square statistic</strong><br />
The cells' relative contribution (in percent) to the chi-square statistic is calculated as:<br />
</p>
<p><code class="reqn">chisq.values / chisq.stat * 100</code>, where<br />
</p>
<p><em>chisq.values</em> and <em>chisq.stat</em> are the chi-square
value in each individual cell of the table and the value of the chi-square statistic, respectively. The
<em>average contribution</em> is calculated as <code class="reqn">100 / (nr*nc)</code>, where <em>nr</em> and <em>nc</em> are the
number of rows and columns in the table respectively.<br />
</p>
<p><strong>Cells' absolute contribution (in percent) to the chi-square statistic</strong><br />
The cells' absolute contribution (in percent) to the chi-square statistic is calculated as:<br />
</p>
<p><code class="reqn">chisq.values / n * 100</code>, where<br />
</p>
<p><em>chisq.values</em> and <em>n</em> are the chi-square
value in each individual cell of the table and the table's grant total, respectively. The
<em>average contribution</em> is calculated as sum of all the absolute contributions divided by the number of cells in
the table.<br />
</p>
<p>For both the relative and absolute contributions to the chi-square, see: Beasley-Schumacker 1995: 90.<br />
</p>
<p><strong>Phi corrected</strong><br />
To further refine Phi, a corrected version has been introduced. It accounts for the fact that the original coefficient (1)
might not reach its maximum value of 1 even when there is a perfect association between the variables, and (2) it is not directly
comparable across tables with different marginals. To calculate Phi-corrected, one first computes Phi-max, which represents the
maximum possible value of Phi under the given marginal totals. Phi-corrected is equal to Phi/Phi-max. <br />
</p>
<p>For more details see: Cureton 1959; Liu 1980; Davenport et al. 1991; Rash et al. 2011.<br />
</p>
<p><strong>95perc confidence interval around Cramer's V</strong><br />
The calculation of the 95perc confidence interval around Cramer's V is based on Smithson 2003: 39-41, and builds on the R code made
available by the author on the web (http://www.michaelsmithson.online/stats/CIstuff/CI.html).<br />
</p>
<p><strong>Bias-corrected Cramer's V</strong><br />
The bias-corrected Cramer's V is based on Bergsma 2013: 323–328.<br />
</p>
<p><strong>W coefficient</strong><br />
It addresses some limitations of Cramer's V. When the marginal probabilities are unevenly distributed, V may overstate the
strength of the association, proving pretty high even when the overall association is weak. W is based on the distance between observed
and expected frequencies. It uses the squared distance to adjust for the unevenness of the marginal distributions in the table.
The indication of the magnitude of the association is based on Cohen 1988 (see above).
Unlike Kvalseth 2018a, the calculation of the 95 percent confidence interval is based on a bootstrap approach (employing 10k resampled tables, and the 2.5th and 97.5th
percentiles of the bootstrap distribution).<br />
</p>
<p>For more details see: Kvalseth 2018a.<br />
</p>
<p><strong>Corrected Goodman-Kruskal's lambda</strong><br />
The corrected Goodman-Kruskal's lambda adeptly addresses skewed or unbalanced marginal probabilities which create problems to the traditional lambda.
By emphasizing categories with higher probabilities through a process of squaring maximum probabilities and normalizing with marginal probabilities, this refined
coefficient addresses inherent limitations of lambda.<br />
</p>
<p>For more details see: Kvalseth 2018b.<br />
</p>
<p><strong>Odds Ratio</strong><br />
The odds ratio is calculated for 2x2 tables. In case of zeros along any of the table's diagonal,
the <em>Haldane-Anscombe</em> correction is applied. It consists in adding 0.5 to every cell of the table before calculating the odds ratio.
For tables of size 2xk (where k &gt;= 2), pairwise odds ratios can be plotted (along with their confidence interval) by
setting the <code>or.alpha</code> parameter to <code>TRUE</code>. The mentioned correction
is also applied to the calculation of those pairwise odds ratios (for more information on the plot, see further below).<br />
</p>
<p>For the Haldane-Anscombe correction see, for instance, Fleiss-Levin-Paik 2003: 102-103.<br />
</p>
<p><strong>Odds Ratio effect size magnitude</strong><br />
The magnitude of the associaiton indicated by the odds ratio is based on the thresholds (and corresponding reciprocal)
suggested by Chen et al 2010:<br />
</p>

<ul>
<li><p> OR &lt; 1.68 - Very small
</p>
</li>
<li><p> 1.68 &lt;= OR &lt; 3.47 - Small
</p>
</li>
<li><p> 3.47 &lt;= OR &lt; 6.71 - Medium
</p>
</li>
<li><p> OR &gt;= 6.71 - Large
</p>
</li></ul>

<p><strong>Odd Ratios plot</strong><br />
For 2xk table, where k &gt;= 2:<br />
by setting the <code>plor.or</code> parameter to <code>TRUE</code>, a plot showing the odds ratios and their 95percent confidence interval will be rendered.
The confidence level can be modified via the <code>or.alpha</code> parameter. The odds ratios are calculated for the column levels, and one of them
is to be selected by the user as a reference for comparison via the <code>reference.level</code> parameter (set to 1 by default).
Also, the user may want to select the row category to which the calculation of the odds ratios makes reference (using the <code>row.level</code> parameter,
which is set to 1 by default). If any of the pairwisely-generated 2x2 tables on which the odds ratio is calculated
features zeros along any of the diagonal, the <em>Haldane-Anscombe</em> correction is applied (see above). <br />
</p>
<p>To better understand the rationale of plotting the odds ratios, consider the following example, which uses on the famous Titanic data:<br />
</p>
<p>Create a 2x3 contingency table:<br />
<code>mytable &lt;- matrix(c(123, 158, 528, 200, 119, 181), nrow = 2, byrow = TRUE)</code> <br />
<code>colnames(mytable) &lt;- c("1st", "2nd", "3rd")</code> <br />
<code>rownames(mytable) &lt;- c("Died", "Survived")</code> <br />
</p>
<p>Now, we perform the test and visualise the odds ratios:<br />
<code>chisquare(mytable, plot.or=TRUE, reference.level=1, row.level=1)</code> <br />
</p>
<p>In the rendered plot, we can see the odds ratios and confidence intervals for the second and third column level
(i.e., 2nd class and 3rd class) because the first column level has been selected as reference level. The odds ratios are calculated
making reference to the first row category (i.e., <em>Died</em>). From the plot, we can see that, compared to the 1st class,
passengers on the 2nd class have 2.16 times larger odds of dying; passengers on the 3rd class have 4.74 times larger odds of dying
compared to the 1st class.<br />
</p>
<p>Note that if we set the <code>row.level</code> parameter to <code>2</code>, we make reference to the second row category, i.e. <em>Survived</em>:<br />
<code>chisquare(mytable, plot.or=TRUE, reference.level=1, row.level=2)</code> <br />
</p>
<p>In the plot, we can see that passengers in the 2nd class have 0.46 times the odds of surviving of passengers in the 1st class, while
passengers from the 3rd class have 0.21 times the odds of surviving of those travelling in the 1st class.<br />
</p>
<p><strong>Other measures of categorical association</strong><br />
For the other measures of categorical association provided by the function, see for example Sheskin 2011: 1415-1427.<br />
</p>
<p><strong>Additional notes on calculations</strong>:
</p>

<ul>
<li><p>the <strong>Phi</strong> coefficient is based on the chi-square statistic as per Sheskin 2011's equation 16.21, whereas the
<strong>Phi signed</strong> is after Sheskin's equation 16.20;
</p>
</li>
<li><p>the <strong>2-sided p value of Yule's Q</strong> is calculated following Sheskin 2011's equation 16.24;
</p>
</li>
<li><p><strong>Cohen's w</strong> is calculated as <code class="reqn">V * sqrt(min(nr, nc)-1)</code>, where <em>V</em> is Cramer's V, and <em>nr</em> and <em>nc</em>
are the number of rows and columns respectively; see Sheskin 2011: 679;
</p>
</li>
<li><p>the <strong>2-tailed p value</strong> of <strong>Goodman-Kruskal's gamma</strong> is based on the
associated z-score calculated as per Sheskin 2011's equation 32.2;
</p>
</li>
<li><p>the <strong>symmetric</strong> version of <strong>Goodman-Kruskal's lambda</strong> is calculated
as per Reynolds 1984: 55-57;
</p>
</li>
<li><p><strong>Goodman-Kruskal's tau</strong> is calculated as per Reynolds 1984: 57-60;
</p>
</li>
<li><p><strong>Cohen's k</strong> is calculated as per Sheskin 2011: 688-689 (equation 16.30).
</p>
</li></ul>



<h3>Value</h3>

<p>The function produces <strong>optional charts</strong> (distribution of the permuted chi-square statistic
and a plot of the odds ratios between a reference column level and the other ones, the latter only for 2xk tables where k &gt;= 2), and
a number of <strong>output tables</strong> that are nicely formatted with the help of the <em>gt</em> package.
The output tables are listed below:
</p>

<ul>
<li><p> Input contingency table (with some essential analytical results annotated at the bottom)
</p>
</li>
<li><p> Expected frequencies
</p>
</li>
<li><p> Cells' chi-square value
</p>
</li>
<li><p> Cells' relative contribution (in percent) to the chi-square statistic (cells in RED feature a larger-than-average
contribution)
</p>
</li>
<li><p> Cells' absolute contribution (in percent) to the chi-square statistic (colour same as above)
</p>
</li>
<li><p> Standardized residuals (RED for large significant residuals, BLUE for small significant residuals)
</p>
</li>
<li><p> Moment-corrected standardized residuals (colour same as above)
</p>
</li>
<li><p> Adjusted standardized residuals (colour same as above)
</p>
</li>
<li><p> Table of output statistics, p values, and association measures
</p>
</li></ul>

<p>Also, the function returns a <strong>list containing the following elements</strong>:
</p>

<ul>
<li> <p><strong>input.table</strong>:
</p>

<ul>
<li> <p><em>crosstab</em>: input contingency table.
</p>
</li></ul>

</li>
<li> <p><strong>chi.sq.related.results</strong>:
</p>

<ul>
<li> <p><em>exp.freq</em>: table of expected frequencies.
</p>
</li>
<li> <p><em>smallest.exp.freq</em>: smallest expected frequency.
</p>
</li>
<li> <p><em>avrg.exp.freq</em>: average expected frequency.
</p>
</li>
<li> <p><em>chisq.values</em>: cells' chi-square value.
</p>
</li>
<li> <p><em>chisq.relat.contrib</em>: cells' relative contribution (in percent) to the chi-square statistic.
</p>
</li>
<li> <p><em>chisq.abs.contrib</em>: cells' absolute contribution (in percent) to the chi-square statistic.
</p>
</li>
<li> <p><em>chisq.statistic</em>: observed chi-square value.
</p>
</li>
<li> <p><em>chisq.p.value</em>: p value of the chi-square statistic.
</p>
</li>
<li> <p><em>chi.sq.power</em>: power of the traditional chi-square test.
</p>
</li>
<li> <p><em>chisq.adj</em>: chi-square statistic adjusted using the (N-1)/N correction.
</p>
</li>
<li> <p><em>chisq.adj.p.value</em>: p value of the adjusted chi-square statistic.
</p>
</li>
<li> <p><em>chisq.p.value.perm</em>: permutation-based p value, based on B permuted tables.
</p>
</li>
<li> <p><em>chisq.p.value.perm CI lower boundary</em>: lower boundary of the 95 percent CI around the permutation-based p value.
</p>
</li>
<li> <p><em>chisq.p.value.perm CI upper boundary</em>: upper boundary of the 95 percent CI around the permutation-based p value.
</p>
</li>
<li> <p><em>chisq.p.value.MC</em>: Monte Carlo p value, based on B random tables.
</p>
</li>
<li> <p><em>chisq.p.value.MC CI lower boundary</em>: lower boundary of the 95 percent CI around the Monte Carlo p value.
</p>
</li>
<li> <p><em>chisq.p.value.MC CI upper boundary</em>: upper boundary of the 95 percent CI around the Monte Carlo p value.
</p>
</li></ul>

</li>
<li> <p><strong>G.square</strong>:
</p>

<ul>
<li> <p><em>Gsq.statistic</em>: observed G-square value.
</p>
</li>
<li> <p><em>Gsq.p.value</em>: p value of the G-square statistic.
</p>
</li></ul>

</li>
<li> <p><strong>residuals</strong>:
</p>

<ul>
<li> <p><em>stand.resid</em>: table of chi-square standardized residuals.
</p>
</li>
<li> <p><em>mom.corr.stand.resid</em>: table of moment-corrected standardized residuals.
</p>
</li>
<li> <p><em>adj.stand.resid</em>: table of adjusted standardized residuals.
</p>
</li></ul>

</li>
<li> <p><strong>chi.sq.based.assoc.measures</strong>:
</p>

<ul>
<li> <p><em>Phi</em>: Phi coefficient (only for 2x2 tables).
</p>
</li>
<li> <p><em>Phi corr</em>: corrected Phi coefficient (only for 2x2 tables).
</p>
</li>
<li> <p><em>Phi signed</em>: signed Phi coefficient (only for 2x2 tables).
</p>
</li>
<li> <p><em>Cadj</em>: adjusted contingency coefficient C.
</p>
</li>
<li> <p><em>Cramer's V</em>: Cramer's V coefficient.
</p>
</li>
<li> <p><em>Cramer's V CI lower boundary</em>: lower boundary of the 95perc CI.
</p>
</li>
<li> <p><em>Cramer's V CI upper boundary</em>: upper boundary of the 95perc CI.
</p>
</li>
<li> <p><em>Cramer's Vbc</em>: bias-corrected Cramer's V coefficient.
</p>
</li>
<li> <p><em>w</em>: Cohen's w.
</p>
</li>
<li> <p><em>W</em>: W coefficient.
</p>
</li>
<li> <p><em>W CI lower boundary</em>: lower boundary of the 95perc CI.
</p>
</li>
<li> <p><em>W CI upper boundary</em>: upper boundary of the 95perc CI.
</p>
</li></ul>

</li>
<li> <p><strong>non.chi.sq.based.assoc.measures</strong>:
</p>

<ul>
<li> <p><em>Yule's Q</em>: Q coefficient (only for 2x2 tables).
</p>
</li>
<li> <p><em>Yule's Q p.value</em>: 2-tailed p value of Yule's Q.
</p>
</li>
<li> <p><em>Odds ratio</em>: odds ratio (only for 2x2 tables).
</p>
</li>
<li> <p><em>Odds ratio CI lower boundary</em>: lower boundary of the 95perc CI.
</p>
</li>
<li> <p><em>Odds ratio CI upper boundary</em>: upper boundary of the 95perc CI.
</p>
</li>
<li> <p><em>Odds ratio p.value</em>: p value of the odds ratio.
</p>
</li>
<li> <p><em>lambda (rows dep.)</em>: Goodman-Kruskal's lambda coefficient (considering the rows being the dependent variable).
</p>
</li>
<li> <p><em>lambda (cols dep.)</em>: Goodman-Kruskal's lambda coefficient (considering the columns being the dependent variable).
</p>
</li>
<li> <p><em>lambda (symmetric)</em>: Goodman-Kruskal's symmetric lambda coefficient.
</p>
</li>
<li> <p><em>lambda corrected (rows dep.)</em>: corrected version of the lambda coefficient (considering the rows being the dependent variable).
</p>
</li>
<li> <p><em>lambda corrected (cols dep.)</em>: corrected version of the lambda coefficient (considering the columns being the dependent variable).
</p>
</li>
<li> <p><em>lambda corrected (symmetric)</em>: corrected version of the symmetric lambda coefficient.
</p>
</li>
<li> <p><em>tau (rows dep.)</em>: Goodman-Kruskal's tau coefficient (considering the rows being the dependent variable).
</p>
</li>
<li> <p><em>tau (cols dep.)</em>: Goodman-Kruskal's tau coefficient (considering the columns being the dependent variable).
</p>
</li>
<li> <p><em>gamma</em>: Goodman-Kruskal's gamma coefficient.
</p>
</li>
<li> <p><em>gamma.p.value</em>: 2-sided p value for the Goodman-Kruskal's gamma coefficient.
</p>
</li>
<li> <p><em>k</em>: Cohen'k.
</p>
</li>
<li> <p><em>k CI lower boundary</em>: lower boundary of the 95perc CI.
</p>
</li>
<li> <p><em>k CI upper boundary</em>: upper boundary of the 95perc CI.
</p>
</li></ul>

</li></ul>

<p><strong>Note</strong> that the <em>p-values</em> returned in the above list are expressed in scientific notation, whereas the ones reported in the
output table featuring the tests' result and measures of association are reported as broken down into classes (e.g., &lt;0.05, or &lt;0.01, etc),
with the exception of the Monte Carlo p-value and its CI.<br />
</p>
<p>The <strong>following examples</strong>, which use in-built datasets, can be run to familiarise with the function:<br />
</p>
<p>-perform the test on the in-built 'social_class' dataset:<br />
<code>result &lt;- chisquare(social_class)</code> <br />
</p>
<p>-perform the test on a 2x2 subset of the 'diseases' dataset:<br />
<code>mytable &lt;- diseases[3:4,1:2]</code> <br />
<code>result &lt;- chisquare(mytable)</code> <br />
</p>
<p>-perform the test on a 2x2 subset of the 'safety' dataset:<br />
<code>mytable &lt;- safety[c(4,1),c(1,6)]</code> <br />
<code>result &lt;- chisquare(mytable)</code> <br />
</p>
<p>-build a toy dataset in 'long' format (gender vs. opinion about death sentence):<br />
<code>mytable &lt;- data.frame(GENDER=c(rep("F", 360), rep("M", 340)),
OPINION=c(rep("oppose", 235),
         rep("favour", 125),
         rep("oppose", 160),
         rep("favour", 180)))</code>
</p>
<p>-perform the test specifying that the input table is in 'long' format:<br />
<code>result &lt;- chisquare(mytable, format="long")</code> <br />
</p>


<h3>References</h3>

<p>Agresti, A., Franklin, C., &amp; Klingenberg, B. (2022). Statistics: The Art and Science of Learning from Data, (5th ed.). Pearson Education.
</p>
<p>Beh E.J., Lombardo R. 2014. Correspondence Analysis: Theory, Practice and New Strategies, Chichester, Wiley.
</p>
<p>Beasley TM and Schumacker RE. 1995. Multiple Regression Approach to Analyzing Contingency Tables: Post Hoc and Planned Comparison Procedures.
The Journal of Experimental Education, 64(1).
</p>
<p>Bergsma, W. 2013. A bias correction for Cramér's V and Tschuprow's T. Journal of the Korean Statistical Society. 42 (3).
</p>
<p>Campbell, I. (2007). Chi-squared and Fisher–Irwin tests of two-by-two tables with small sample recommendations.
In Statistics in Medicine (Vol. 26, Issue 19, pp. 3661–3675).
</p>
<p>Chen, H., Cohen, P., and Chen, S. (2010). How Big is a Big Odds Ratio? Interpreting the Magnitudes of Odds Ratios in Epidemiological Studies.
In Communications in Statistics - Simulation and Computation (Vol. 39, Issue 4, pp. 860–864).
</p>
<p>Cohen, J. 1988. Statistical power analysis for the behavioral sciences (2nd ed). Hillsdale, N.J: L. Erlbaum Associates.
</p>
<p>Cureton, E. E. (1959). Note on phi/phimax. In Psychometrika (Vol. 24, Issue 1, pp. 89–91).
</p>
<p>Davenport, E. C., Jr., &amp; El-Sanhurry, N. A. (1991). Phi/Phimax: Review and Synthesis. In Educational and Psychological
Measurement (Vol. 51, Issue 4, pp. 821–828).
</p>
<p>Fleiss, J. L., Levin, B., &amp; Paik, M. C. 2003. Statistical Methods for Rates and Proportions (3rd ed.). Wiley.
</p>
<p>Garcia-Perez, MA, and Nunez-Anton, V. 2003. Cellwise Residual Analysis in Two-Way Contingency Tables. Educational and Psychological Measurement, 63(5).
</p>
<p>Greenwood, P. E., &amp; Nikulin, M. S. (1996). A guide to chi-squared testing. John Wiley &amp; Sons.
</p>
<p>Haberman, S. J. (1973). The Analysis of Residuals in Cross-Classified Tables. In Biometrics (Vol. 29, Issue 1, p. 205).
</p>
<p>Kvålseth, T. O. (2018a). An alternative to Cramér’s coefficient of association. In Communications in Statistics - Theory and Methods (Vol. 47, Issue 23, pp. 5662–5674).
</p>
<p>Kvålseth, T. O. (2018b). Measuring association between nominal categorical variables: an alternative to the Goodman–Kruskal lambda. In Journal of Applied Statistics
(Vol. 45, Issue 6, pp. 1118–1132).
</p>
<p>Oyeyemi, G. M., Adewara, A. A., Adebola, F. B., &amp; Salau, S. I. (2010). On the Estimation of Power and Sample Size in Test of Independence.
In Asian Journal of Mathematics and Statistics (Vol. 3, Issue 3, pp. 139–146).
</p>
<p>Rasch, D., Kubinger, K. D., &amp; Yanagida, T. (2011). Statistics in Psychology Using R and SPSS. Wiley.
</p>
<p>Reynolds, H. T. 1984. Analysis of Nominal Data (Quantitative Applications in the Social Sciences) (1st ed.). SAGE Publications.
</p>
<p>Rhoades, H. M., &amp; Overall, J. E. (1982). A sample size correction for Pearson chi-square in 2×2 contingency tables. In Psychological Bulletin (Vol. 91, Issue 2, pp. 418–423).
</p>
<p>Richardson, J. T. E. (2011). The analysis of 2 × 2 contingency tables-Yet again. In Statistics in Medicine (Vol. 30, Issue 8, pp. 890–890).
</p>
<p>Roscoe, J. T., &amp; Byars, J. A. (1971). An Investigation of the Restraints with Respect to Sample Size Commonly Imposed on the Use of the Chi-Square Statistic.
Journal of the American Statistical Association, 66(336), 755–759.
</p>
<p>Sheskin, D. J. 2011. Handbook of Parametric and Nonparametric Statistical Procedures, Fifth Edition (5th ed.). Chapman and Hall/CRC.
</p>
<p>Smithson M.J. 2003. Confidence Intervals, Quantitative Applications in the Social Sciences Series, No. 140. Thousand Oaks, CA: Sage.
</p>
<p>Upton, G. J. G. (1982). A Comparison of Alternative Tests for the 2 × 2 Comparative Trial. In Journal of the Royal Statistical Society.
Series A (General) (Vol. 145, Issue 1, p. 86).
</p>
<p>Zar, J. H. (2014). Biostatistical analysis (5th ed.). Pearson New International Edition.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Perform the test on the in-built 'social_class' dataset
result &lt;- chisquare(social_class, B=99)


# Perform the test on a 2x2 subset
result &lt;- chisquare(social_class[c(1:2), c(1:2)], B=99)



</code></pre>

<hr>
<h2 id='diseases'>Dataset: Cross-tabulation of quantity of tobacco smoked daily vs. cause of
death</h2><span id='topic+diseases'></span>

<h3>Description</h3>

<p>Cross-tabulation (15x4) of the amount of tobacco smoked on a daily basis (in
gramms) against cause of death.<br /> After: Velleman P F, Hoaglin D C,
Applications, Basics, and Computing of Exploratory Data Analysis, Wadsworth
Pub Co 1984 (Exhibit 8-1)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(diseases)
</code></pre>


<h3>Format</h3>

<p>dataframe
</p>

<hr>
<h2 id='safety'>Dataset: Cross-tabulation of people's feeling of safety vs. town size</h2><span id='topic+safety'></span>

<h3>Description</h3>

<p>Cross-tabulation (4x6).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(safety)
</code></pre>


<h3>Format</h3>

<p>dataframe
</p>

<hr>
<h2 id='social_class'>Dataset: Cross-tabulation of social class vs. diagnostic category for a sample of psychiatric patients</h2><span id='topic+social_class'></span>

<h3>Description</h3>

<p>Cross-tabulation (3x4) after: Everitt B.S (1992), The Analysis of Contingency Tables, Chapman&amp;Hall/CRC, second edition,
table 3.13.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(social_class)
</code></pre>


<h3>Format</h3>

<p>dataframe
</p>

<hr>
<h2 id='suggest_chi_squared_method'>Suggest chi-squared testing method for the input contingency table</h2><span id='topic+suggest_chi_squared_method'></span>

<h3>Description</h3>

<p>This function returns a suggested method for chi-square testing, on the basis of different criteria related to the
features of the input cross-tabulation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>suggest_chi_squared_method(cross_tab)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="suggest_chi_squared_method_+3A_cross_tab">cross_tab</code></td>
<td>
<p>Input cross-tabulation.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A carachter vector containing a suggestion for the chi-square testing method to employ.
</p>

<hr>
<h2 id='visualize_odds_ratios'>Visualize Odds Ratios for a 2xk (where k &gt;= 2) Contingency Table (internal function)</h2><span id='topic+visualize_odds_ratios'></span>

<h3>Description</h3>

<p>This function creates a plot of odds ratios with 95
for a 2xk (where k &gt;= 2) contingency table.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>visualize_odds_ratios(
  ctable,
  reference.level = 1,
  row.level = 1,
  or.alpha = 0.05
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="visualize_odds_ratios_+3A_ctable">ctable</code></td>
<td>
<p>A 2xk (where k &gt;= 2) contingency table as a matrix or data frame with row and column names.</p>
</td></tr>
<tr><td><code id="visualize_odds_ratios_+3A_reference.level">reference.level</code></td>
<td>
<p>The index of the reference level for odds ratio calculations (default: 1). The user must select the column level to serve as the reference level.</p>
</td></tr>
<tr><td><code id="visualize_odds_ratios_+3A_row.level">row.level</code></td>
<td>
<p>The index of the row category to be used in odds ratio calculations (1 or 2). The user must select the row level to which the calculation of the odds ratios make reference (default: 1).</p>
</td></tr>
<tr><td><code id="visualize_odds_ratios_+3A_or.alpha">or.alpha</code></td>
<td>
<p>The significance level used for the confidence intervals (default: 0.05).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A plot of odds ratios with 95
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
