<!DOCTYPE html><html lang="en"><head><title>Help for package dblr</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {dblr}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#dblr_train'><p>Discrete Boosting Logistic Regression Training</p></a></li>
<li><a href='#predict.dblr'><p>Discrete Boosting Logistic Regression Prediction</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Discrete Boosting Logistic Regression</td>
</tr>
<tr>
<td>Version:</td>
<td>0.1.0</td>
</tr>
<tr>
<td>Author:</td>
<td>Nailong Zhang</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Nailong Zhang &lt;setseed2016@gmail.com&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Trains logistic regression model by discretizing continuous variables via gradient boosting approach. The proposed method tries to achieve a tradeoff between interpretation and prediction accuracy for logistic regression by discretizing the continuous variables. The variable binning is accomplished in a supervised fashion. The model trained by this package is still a single 
  logistic regression model, but not a sequence of logistic regression models. The fitted model
  object returned from the model training consists of two tables. One table is used to give the
  boundaries of bins for each continuous variable as well as the corresponding coefficients,
  and the other one is used for discrete variables. This package can also be used for binning
  continuous variables for other statistical analysis. </td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>Imports:</td>
<td>data.table (&ge; 1.9.6), xgboost (&ge; 0.6-4), CatEncoders (&ge;
0.1.1), Metrics (&ge; 0.1.1), methods</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>6.0.1</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2017-10-11 14:07:44 UTC; nl</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2017-10-11 17:31:59 UTC</td>
</tr>
</table>
<hr>
<h2 id='dblr_train'>Discrete Boosting Logistic Regression Training</h2><span id='topic+dblr_train'></span>

<h3>Description</h3>

<p>dblr_train fits a dblr (discrete boosting logistic regression) model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dblr_train(train_x, train_y, category_cols = NULL, metric = "auc",
  subsample = 1, eta = 0.1, colsample = 1, cv_nfold = 5,
  cv_nrounds = 1000, cv_early_stops = 25, lambda = 1, alpha = 0,
  scale_pos_weight = 1, verbose = FALSE, seed = 123456L)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="dblr_train_+3A_train_x">train_x</code></td>
<td>
<p>A data.frame of training variables, which can include NA as well</p>
</td></tr>
<tr><td><code id="dblr_train_+3A_train_y">train_y</code></td>
<td>
<p>A vector of 0 and 1 to represent labels of training samples</p>
</td></tr>
<tr><td><code id="dblr_train_+3A_category_cols">category_cols</code></td>
<td>
<p>A vector of column names to indicate which columns are categorical. Default: NULL means all columns are continuous</p>
</td></tr>
<tr><td><code id="dblr_train_+3A_metric">metric</code></td>
<td>
<p>Which metric to use, can be either auc or logloss. Default: auc</p>
</td></tr>
<tr><td><code id="dblr_train_+3A_subsample">subsample</code></td>
<td>
<p>Subsample ratio from the trainnig samples in each iteration. Default: 1.0</p>
</td></tr>
<tr><td><code id="dblr_train_+3A_eta">eta</code></td>
<td>
<p>Controls the rate of learning. eta should be between 0 and 1. Default: 0.1</p>
</td></tr>
<tr><td><code id="dblr_train_+3A_colsample">colsample</code></td>
<td>
<p>Subsample ratio from all available variables/columns. Default: 1.0</p>
</td></tr>
<tr><td><code id="dblr_train_+3A_cv_nfold">cv_nfold</code></td>
<td>
<p>Number of folds used for cross-validation. Default: 5</p>
</td></tr>
<tr><td><code id="dblr_train_+3A_cv_nrounds">cv_nrounds</code></td>
<td>
<p>Number of iterations used for cross-validation. Default: 1000</p>
</td></tr>
<tr><td><code id="dblr_train_+3A_cv_early_stops">cv_early_stops</code></td>
<td>
<p>Cross-validation would be stopped if there is no improvement after cv_early_stops iterations. Default: 25</p>
</td></tr>
<tr><td><code id="dblr_train_+3A_lambda">lambda</code></td>
<td>
<p>Control L2 regularization term. Default: 1.0</p>
</td></tr>
<tr><td><code id="dblr_train_+3A_alpha">alpha</code></td>
<td>
<p>Control L1 regularization term. Default: 0.0</p>
</td></tr>
<tr><td><code id="dblr_train_+3A_scale_pos_weight">scale_pos_weight</code></td>
<td>
<p>Useful when training metric is set to auc for imbalanced training data</p>
</td></tr>
<tr><td><code id="dblr_train_+3A_verbose">verbose</code></td>
<td>
<p>Default: FALSE. If TRUE, the cross-validation process would be showed</p>
</td></tr>
<tr><td><code id="dblr_train_+3A_seed">seed</code></td>
<td>
<p>Random seed for the sampling. Default: 123456</p>
</td></tr>
</table>


<h3>Details</h3>

<p>As one of the generalized linear models, traditional logistic regression on continuous variables implies that there is a monotonic relation between each predictor and the predicted probability. Bining or discretizing the continuous variables would be helpful when non-monotonic relation exists. In general, it is challenging to find the optimal binning for continuous variables. Too many bins may cause over-fitting and too few bins may not reveal the non-monotinc relation as much as possible. Thus, we propose to use a boosting decision trees to construct a discrete logistic regressions aiming at an automated binning process with good performance. Our algorithm is to construct  a sequence of gradient boosting decision trees with at most 1 variable in each tree. Aggregating all decision trees with the same variable would result in the corresponding bins and the coefficients. And by aggregating all trees without variables we would get the intercept. <br /> <br /> The model is defined as: </p>
<p style="text-align: center;"><code class="reqn">Pr(y=1|\bm{x}_i)=  \frac 1{1+{\exp (- \sum_{j=1}^{m}{g(\bm{x}_{i,j})}- b)}},</code>
</p>
<p> where <code class="reqn">g(\bm{x}_{i,j})</code> denotes the coefficient of the bin which <code class="reqn">\bm{x}_{i,j}</code> falls into and <code class="reqn">b</code> denotes the intercept. Both coefficients and intercept are consolidated from boosting trees. More specifically, </p>
<p style="text-align: center;"><code class="reqn">g(\bm{x}_{i,j})=\sum_{k=1}^{K} f_k(\bm{x}_{i,j})\cdot I(\textrm{tree } k \textrm{ splits on variable } j),</code>
</p>
 <p style="text-align: center;"><code class="reqn">b=\sum_{k=1}^{K} f_k\cdot I(\textrm{tree } k \textrm{ does not split on any variable}),</code>
</p>
<p> where <code class="reqn">K</code> is the total number of trees and <code class="reqn">f_k</code> is the output value for tree <code class="reqn">k</code>. In this package, we use xgboost package to training the underlying gradient boosting trees.
</p>


<h3>Value</h3>

<p>Returns an object of S3 class dblr, which contains two attributes, i.e., continuous_bins and categorical_bins.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># use iris data for example
dat &lt;- iris
# create two categorical variables
dat$Petal.Width &lt;- as.factor((iris$Petal.Width&lt;=0.2)*1+(iris$Petal.Width&gt;1.0)*2)
dat$Sepal.Length &lt;- (iris$Sepal.Length&lt;=3.0)*2+(iris$Sepal.Length&gt;6.0)*1.25
# create the response variable
dat$Species &lt;- as.numeric(dat$Species=='versicolor')
set.seed(123)
# random sampling
index &lt;- sample(1:150,100,replace = FALSE)
# train the dblr model using the training data
dblr_fit &lt;- dblr_train(train_x=dat[index,c(1:4)],
train_y=dat[index,5],category_cols = c('Petal.Width','Sepal.Length'),
metric = 'logloss',subsample = 0.5,eta = 0.05,colsample = 1.0,
lambda = 1.0,cv_early_stops = 10,verbose=FALSE)
# make predictions on testing data
pred_dblr &lt;- predict(dblr_fit,newdata = dat[-index,],type = 'response')
dblr_auc &lt;- Metrics::auc(actual = dat[-index,'Species'],predicted = pred_dblr)
dblr_logloss &lt;- Metrics::logLoss(actual = dat[-index,'Species'],predicted = pred_dblr)
cat('test auc for dblr model:',dblr_auc,'\n')
cat('test logloss for dblr model:',dblr_logloss,'\n')
glm_fit &lt;- glm(data=dat[index,],formula =Species~. ,family = binomial)
pred_glm &lt;- predict(glm_fit,newdata = dat[-index,],type='response')
glm_auc &lt;- Metrics::auc(actual = dat[-index,'Species'],predicted = pred_glm)
glm_logloss &lt;- Metrics::logLoss(actual = dat[-index,'Species'],predicted = pred_glm)
cat('test auc for glm model:',glm_auc,'\n')
cat('test logloss for glm model:',glm_logloss,'\n')
</code></pre>

<hr>
<h2 id='predict.dblr'>Discrete Boosting Logistic Regression Prediction</h2><span id='topic+predict.dblr'></span>

<h3>Description</h3>

<p>predict.dblr makes predictions on new data set given the fitted dblr model object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'dblr'
predict(object, newdata, type = "response", ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict.dblr_+3A_object">object</code></td>
<td>
<p>A fitted dblr model object, which should be returned by calling dblr_train function</p>
</td></tr>
<tr><td><code id="predict.dblr_+3A_newdata">newdata</code></td>
<td>
<p>A data.frame contains the samples to predict</p>
</td></tr>
<tr><td><code id="predict.dblr_+3A_type">type</code></td>
<td>
<p>Control the output of prediction. Default: 'response' means probability; 'Link' would produce the linear part; 'mapped' would produce a data.frame filling with the coefficients of the model</p>
</td></tr>
<tr><td><code id="predict.dblr_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a vector of prediction or a data.frame
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
