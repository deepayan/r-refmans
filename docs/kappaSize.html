<!DOCTYPE html><html lang="en"><head><title>Help for package kappaSize</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {kappaSize}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#CI3Cats'><p>Confidence Interval Approach for the Number of Subjects Required for a Study of Interobserver Agreement with Three Outcome Categories</p></a></li>
<li><a href='#CI4Cats'><p>Confidence Interval Approach for the Number of Subjects Required for a Study of Interobserver Agreement with Four Outcome Categories</p></a></li>
<li><a href='#CI5Cats'><p>Confidence Interval Approach for the Number of Subjects Required for a Study of Interobserver Agreement with Five Outcome Categories</p></a></li>
<li><a href='#CIBinary'><p>Confidence Interval Approach for the Number of Subjects Required for a Study of Interobserver Agreement with a Binary Outcome</p></a></li>
<li><a href='#FixedN3Cats'><p>Calculation of the Lowest Expected Value, kappaL for a fixed sample</p>
size in a Study of Interobserver Agreement with a Multinomial Outcome (3 Levels)</a></li>
<li><a href='#FixedN4Cats'><p>Calculation of the Lowest Expected Value, kappaL, for a fixed sample</p>
size in a Study of Interobserver Agreement with a Multinomial Outcome (4 Levels)</a></li>
<li><a href='#FixedN5Cats'><p>Calculation of the Lowest Expected Value, kappaL, for a fixed sample</p>
size in a Study of Interobserver Agreement with a Multinomial Outcome (5 Levels)</a></li>
<li><a href='#FixedNBinary'><p>Calculation of the Lowest Expected Value, kappaL, for a fixed sample</p>
size in a Study of Interobserver Agreement with a Binary Outcome</a></li>
<li><a href='#Power3Cats'><p>Power-Based Approach for the Number of Subjects Required for a Study of Interobserver Agreement with Three Outcome Categories</p></a></li>
<li><a href='#Power4Cats'><p>Power-Based Approach for the Number of Subjects Required for a Study of Interobserver Agreement with Four Outcome Categories</p></a></li>
<li><a href='#Power5Cats'><p>Power-Based Approach for the Number of Subjects Required for a Study of Interobserver Agreement with Five Outcome Categories</p></a></li>
<li><a href='#PowerBinary'><p>Power-Based Approach for the Number of Subjects Required for a Study of Interobserver Agreement with a Binary Outcome</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Version:</td>
<td>1.2</td>
</tr>
<tr>
<td>Date:</td>
<td>2018-11-25</td>
</tr>
<tr>
<td>Title:</td>
<td>Sample Size Estimation Functions for Studies of Interobserver
Agreement</td>
</tr>
<tr>
<td>Author:</td>
<td>Michael A Rotondi &lt;mrotondi@yorku.ca&gt;</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Michael A Rotondi &lt;mrotondi@yorku.ca&gt;</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 2.10)</td>
</tr>
<tr>
<td>Description:</td>
<td>Contains basic tools for sample size estimation in studies of interobserver/interrater agreement (reliability).  Includes functions for both the power-based and confidence interval-based methods, with binary or multinomial outcomes and two through six raters.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2018-11-26 17:04:39 UTC; mrotondi</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2018-11-26 17:40:03 UTC</td>
</tr>
</table>
<hr>
<h2 id='CI3Cats'>Confidence Interval Approach for the Number of Subjects Required for a Study of Interobserver Agreement with Three Outcome Categories</h2><span id='topic+CI3Cats'></span><span id='topic+print.CI3Cats'></span><span id='topic+summary.CI3Cats'></span>

<h3>Description</h3>

<p>This function provides detailed sample size estimation information to determine
the number of subjects required using the confidence interval perspective to sample 
size estimation for <code class="reqn">\kappa</code>.  This version assumes that the outcome has three categories.  </p>


<h3>Usage</h3>

<pre><code class='language-R'>CI3Cats(kappa0, kappaL, kappaU=NA, props, raters=2, alpha=0.05)</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="CI3Cats_+3A_kappa0">kappa0</code></td>
<td>
<p>The anticipated preliminary value of <code class="reqn">\kappa</code>.</p>
</td></tr>
<tr><td><code id="CI3Cats_+3A_kappal">kappaL</code></td>
<td>
<p>The desired expected lower bound for a two-sided 100(1 - <code class="reqn">\alpha</code>) % confidence interval for <code class="reqn">\kappa</code>.  Alternatively, if kappaU is set to NA, the procedure produces the number of required subjects for a one-sided confidence interval.</p>
</td></tr>
<tr><td><code id="CI3Cats_+3A_kappau">kappaU</code></td>
<td>
<p>The desired expected upper confidence limit for <code class="reqn">\kappa</code>.</p>
</td></tr>
<tr><td><code id="CI3Cats_+3A_props">props</code></td>
<td>
<p>The anticipated prevalence of the desired trait.  Note that the elements
of the three element vector must be non-negative and sum to one.</p>
</td></tr>
<tr><td><code id="CI3Cats_+3A_raters">raters</code></td>
<td>
<p>The number of raters that are available.  This function allows between
2 and 6 raters.</p>
</td></tr>
<tr><td><code id="CI3Cats_+3A_alpha">alpha</code></td>
<td>
<p>The desired type I error rate.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function provides detailed sample size estimation computation for studies
of interobserver agreement with three outcomes.  This function employs the
confidence interval perspective, determining the correct sample size that provides
the specified expected confidence limits.  Sample
size estimation is based on the precision of the estimate, instead of a simple hypothesis
testing perspective.  Note that a warning message is provided if any of the expected cell counts are less than 5.
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>N</code></td>
<td>
<p>The calculated sample size.</p>
</td></tr>
<tr><td><code>kappa0</code></td>
<td>
<p>The specified anticipated value of <code class="reqn">\kappa</code>.</p>
</td></tr>
<tr><td><code>kappaL</code></td>
<td>
<p>The specified expected lower limit.</p>
</td></tr>
<tr><td><code>kappaU</code></td>
<td>
<p>The specified expected upper limit.</p>
</td></tr>
<tr><td><code>props</code></td>
<td>
<p>The anticipated proportions of individuals with the outcomes of interest.</p>
</td></tr>
<tr><td><code>raters</code></td>
<td>
<p>The number of raters.</p>
</td></tr>
<tr><td><code>alpha</code></td>
<td>
<p>The desired type I error rate.</p>
</td></tr>
<tr><td><code>ChiCrit</code></td>
<td>
<p>The critical value that is required for sample size estimation.  It is typically not required and is not displayed in the summary output.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michael Rotondi, <a href="mailto:mrotondi@yorku.ca">mrotondi@yorku.ca</a></p>


<h3>References</h3>

<p>Rotondi MA, Donner A.  (2012).  A Confidence Interval Approach to Sample Size Estimation for Interobserver Agreement Studies with Multiple Raters and Outcomes.  Journal of Clinical Epidemiology, 65:778-784. 
</p>
<p>Donner A, Rotondi MA.  (2010).  Sample Size Requirements for Interval Estimation of the Kappa Statistic for Interobserver Agreement Studies with a Binary Outcome and Multiple Raters.  International Journal of Biostatistics 6:31. 
</p>
<p>Altaye M, Donner A, Klar N.  (2001). Procedures for Assessing Interobserver Agreement among Multiple Raters.  Biometrics 57:584-588. 
</p>
<p>Donner A.  (1999).  Sample Size Requirements for Interval Estimation of the Intraclass Kappa Statistic.  Communication in Statistics 28:415-429. 
</p>
<p>Bartfay E, Donner A. (2001).  Statistical Inferences for Interobserver Agreement Studies with Nominal Outcome Data.  The Statistician 50:135-146.
</p>
<p>Donner A, Eliasziw M. (1987) Sample size requirements for reliability studies. Statistics in Medicine 6:441-448. 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Power3Cats">Power3Cats</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: Suppose an investigator would like to determine the required sample size to test 
kappa0=0.4 with precision of 0.2 on each side, in a study of interobserver agreement 
(3 raters).  Further suppose that the prevalence of the traits are 0.30, 0.2, 0.5.
## End(Not run)

CI3Cats(kappa0=0.4, kappaL=0.3, kappaU=0.6, props=c(0.30, 0.2, 0.5), raters=3, alpha=0.05);
</code></pre>

<hr>
<h2 id='CI4Cats'>Confidence Interval Approach for the Number of Subjects Required for a Study of Interobserver Agreement with Four Outcome Categories</h2><span id='topic+CI4Cats'></span><span id='topic+print.CI4Cats'></span><span id='topic+summary.CI4Cats'></span>

<h3>Description</h3>

<p>This function provides detailed sample size estimation information to determine
the number of subjects required using the confidence interval perspective to sample 
size estimation for <code class="reqn">\kappa</code>.   This version assumes that the outcome has four categories.</p>


<h3>Usage</h3>

<pre><code class='language-R'>CI4Cats(kappa0, kappaL, kappaU=NA, props, raters=2, alpha=0.05)</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="CI4Cats_+3A_kappa0">kappa0</code></td>
<td>
<p>The preliminary (anticipated) value of <code class="reqn">\kappa</code>.</p>
</td></tr>
<tr><td><code id="CI4Cats_+3A_kappal">kappaL</code></td>
<td>
<p>The desired expected lower bound for a two-sided 100(1 - <code class="reqn">\alpha</code>) % confidence interval for <code class="reqn">\kappa</code>.  Alternatively, if kappaU is set to NA, the procedure produces the number of required subjects for a one-sided confidence interval.</p>
</td></tr>
<tr><td><code id="CI4Cats_+3A_kappau">kappaU</code></td>
<td>
<p>The desired expected upper confidence limit for <code class="reqn">\kappa</code>.</p>
</td></tr>
<tr><td><code id="CI4Cats_+3A_props">props</code></td>
<td>
<p>The anticipated prevalence of the desired trait.  Note that the elements
of the four element vector must be non-negative and sum to one.</p>
</td></tr>
<tr><td><code id="CI4Cats_+3A_raters">raters</code></td>
<td>
<p>The number of raters that are available.  This function allows between
2 and 6 raters.</p>
</td></tr>
<tr><td><code id="CI4Cats_+3A_alpha">alpha</code></td>
<td>
<p>The desired type I error rate.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function provides detailed sample size estimation computation for studies
of interobserver agreement with four outcomes.  This function employs the
confidence interval perspective, determining the correct sample size that provides
the specified expected confidence limits.  Sample
size estimation is based on the precision of the estimate, instead of a simple hypothesis
testing perspective.  Note that a warning message is provided if any of the expected cell counts are less than 5.
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>N</code></td>
<td>
<p>The calculated sample size.</p>
</td></tr>
<tr><td><code>kappa0</code></td>
<td>
<p>The specified anticipated value of <code class="reqn">\kappa</code>.</p>
</td></tr>
<tr><td><code>kappaL</code></td>
<td>
<p>The specified expected lower limit.</p>
</td></tr>
<tr><td><code>kappaU</code></td>
<td>
<p>The specified expected upper limit.</p>
</td></tr>
<tr><td><code>props</code></td>
<td>
<p>The anticipated proportions of individuals with the outcomes of interest.</p>
</td></tr>
<tr><td><code>raters</code></td>
<td>
<p>The number of raters.</p>
</td></tr>
<tr><td><code>alpha</code></td>
<td>
<p>The desired type I error rate.</p>
</td></tr>
<tr><td><code>ChiCrit</code></td>
<td>
<p>The critical value that is required for sample size estimation.  It is
typically not required and is not displayed in the summary output.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michael Rotondi, <a href="mailto:mrotondi@yorku.ca">mrotondi@yorku.ca</a></p>


<h3>References</h3>

<p>Rotondi MA, Donner A.  (2012).  A Confidence Interval Approach to Sample Size Estimation for Interobserver Agreement Studies with Multiple Raters and Outcomes.  Journal of Clinical Epidemiology, 65:778-784.
</p>
<p>Donner A, Rotondi MA.  (2010).  Sample Size Requirements for Interval Estimation of the Kappa Statistic for Interobserver Agreement Studies with a Binary Outcome and Multiple Raters.  International Journal of Biostatistics 6:31.
</p>
<p>Altaye M, Donner A, Klar N.  (2001). Procedures for Assessing Interobserver Agreement among Multiple Raters.  Biometrics 57:584-588.
</p>
<p>Donner A.  (1999).  Sample Size Requirements for Interval Estimation of the Intraclass Kappa Statistic.  Communication in Statistics 28:415-429.
</p>
<p>Bartfay E, Donner A. (2001).  Statistical Inferences for Interobserver Agreement Studies with Nominal Outcome Data.  The Statistician 50:135-146.
</p>
<p>Donner A, Eliasziw M. (1987) Sample size requirements for reliability studies. Statistics in Medicine 6:441-448.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Power4Cats">Power4Cats</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: Suppose an investigator would like to determine the required sample size to test 
kappa0=0.4 with precision of 0.1 on each side, in a study of interobserver agreement. 
Further suppose that the prevalence of the traits are 0.30, 0.2, 0.2, 0.3.
## End(Not run)

CI4Cats(kappa0=0.4, kappaL=0.3, kappaU=0.5, props=c(0.30, 0.2, 0.2, 0.3), alpha=0.05);
</code></pre>

<hr>
<h2 id='CI5Cats'>Confidence Interval Approach for the Number of Subjects Required for a Study of Interobserver Agreement with Five Outcome Categories</h2><span id='topic+CI5Cats'></span><span id='topic+print.CI5Cats'></span><span id='topic+summary.CI5Cats'></span>

<h3>Description</h3>

<p>This function provides detailed sample size estimation information to determine
the number of subjects required using the confidence interval perspective to sample 
size estimation for <code class="reqn">\kappa</code>.   This version assumes that the outcome has five categories.</p>


<h3>Usage</h3>

<pre><code class='language-R'>CI5Cats(kappa0, kappaL, kappaU=NA, props, raters=2, alpha=0.05)</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="CI5Cats_+3A_kappa0">kappa0</code></td>
<td>
<p>The anticipated preliminary value of <code class="reqn">\kappa</code>.</p>
</td></tr>
<tr><td><code id="CI5Cats_+3A_kappal">kappaL</code></td>
<td>
<p>The desired expected lower bound for a two-sided 100(1 - <code class="reqn">\alpha</code>) % confidence interval for <code class="reqn">\kappa</code>.  Alternatively, if kappaU is set to NA, the procedure produces the number of required subjects 
for a one-sided confidence interval.</p>
</td></tr>
<tr><td><code id="CI5Cats_+3A_kappau">kappaU</code></td>
<td>
<p>The desired expected upper confidence limit for <code class="reqn">\kappa</code>.</p>
</td></tr>
<tr><td><code id="CI5Cats_+3A_props">props</code></td>
<td>
<p>The anticipated prevalence of the desired traits.  Note that the elements
of the five element vector must be non-negative and sum to one.</p>
</td></tr>
<tr><td><code id="CI5Cats_+3A_raters">raters</code></td>
<td>
<p>The number of raters that are available.  This function allows between
2 and 6 raters.</p>
</td></tr>
<tr><td><code id="CI5Cats_+3A_alpha">alpha</code></td>
<td>
<p>The desired type I error rate.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function provides detailed sample size estimation computation for studies
of interobserver agreement with five outcomes.  This function employs the
confidence interval perspective, determining the correct sample size that provides
the specified expected confidence limits.  Sample
size estimation is based on the precision of the estimate, instead of a simple hypothesis
testing perspective.  Note that a warning message is provided if any of the expected cell counts are less than 5.
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>N</code></td>
<td>
<p>The calculated sample size.</p>
</td></tr>
<tr><td><code>kappa0</code></td>
<td>
<p>The specified anticipated value of <code class="reqn">\kappa</code>.</p>
</td></tr>
<tr><td><code>kappaL</code></td>
<td>
<p>The specified expected lower limit.</p>
</td></tr>
<tr><td><code>kappaU</code></td>
<td>
<p>The specified expected upper limit.</p>
</td></tr>
<tr><td><code>props</code></td>
<td>
<p>The anticipated proportions of individuals with the outcomes of interest.</p>
</td></tr>
<tr><td><code>raters</code></td>
<td>
<p>The number of raters.</p>
</td></tr>
<tr><td><code>alpha</code></td>
<td>
<p>The desired type I error rate.</p>
</td></tr>
<tr><td><code>ChiCrit</code></td>
<td>
<p>The critical value that is required for sample size estimation.  It is
typically not required and is not displayed in the summary output.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michael Rotondi, <a href="mailto:mrotondi@yorku.ca">mrotondi@yorku.ca</a></p>


<h3>References</h3>

<p>Rotondi MA, Donner A.  (2012).  A Confidence Interval Approach to Sample Size Estimation for Interobserver Agreement Studies with Multiple Raters and Outcomes.  Journal of Clinical Epidemiology, 65:778-784.
</p>
<p>Donner A, Rotondi MA.  (2010).  Sample Size Requirements for Interval Estimation of the Kappa Statistic for Interobserver Agreement Studies with a Binary Outcome and Multiple Raters.  International Journal of Biostatistics 6:31.
</p>
<p>Altaye M, Donner A, Klar N.  (2001). Procedures for Assessing Interobserver Agreement among Multiple Raters.  Biometrics 57:584-588.
</p>
<p>Donner A.  (1999).  Sample Size Requirements for Interval Estimation of the Intraclass Kappa Statistic.  Communication in Statistics 28:415-429.
</p>
<p>Bartfay E, Donner A. (2001).  Statistical Inferences for Interobserver Agreement Studies with Nominal Outcome Data.  The Statistician 50:135-146.
</p>
<p>Donner A, Eliasziw M. (1987) Sample size requirements for reliability studies. Statistics in Medicine 6:441-448.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Power5Cats">Power5Cats</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: Suppose an investigator would like to determine the required sample size to test 
kappa0=0.4 with precision of 0.1 on each side, in a study of interobserver agreement.  
Further suppose that the prevalence of the traits are 0.13, 0.17, 0.2, 0.2, 0.3.
## End(Not run)

CI5Cats(kappa0=0.4, kappaL=0.3, kappaU=0.5, props=c(0.13, 0.17, 0.2, 0.2, 0.3), alpha=0.05);
</code></pre>

<hr>
<h2 id='CIBinary'>Confidence Interval Approach for the Number of Subjects Required for a Study of Interobserver Agreement with a Binary Outcome</h2><span id='topic+CIBinary'></span><span id='topic+print.CIBinary'></span><span id='topic+summary.CIBinary'></span>

<h3>Description</h3>

<p>This function provides detailed sample size estimation information to determine
the number of subjects required using the confidence interval perspective to sample 
size estimation for <code class="reqn">\kappa</code>.   This version assumes that the outcome has two categories.</p>


<h3>Usage</h3>

<pre><code class='language-R'>CIBinary(kappa0, kappaL, kappaU=NA, props, raters=2, alpha=0.05)</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="CIBinary_+3A_kappa0">kappa0</code></td>
<td>
<p>The preliminary value of <code class="reqn">\kappa</code>.</p>
</td></tr>
<tr><td><code id="CIBinary_+3A_kappal">kappaL</code></td>
<td>
<p>The desired expected lower bound for a two-sided 100(1 - <code class="reqn">\alpha</code>) % confidence interval for kappa.  Alternatively, if kappaU is set to NA, the procedure produces the number of required subjects 
for a one-sided confidence interval.</p>
</td></tr>
<tr><td><code id="CIBinary_+3A_kappau">kappaU</code></td>
<td>
<p>The desired expected upper confidence limit for kappa.</p>
</td></tr>
<tr><td><code id="CIBinary_+3A_props">props</code></td>
<td>
<p>The anticipated prevalence of the desired trait.  Note that specifying
props as either a single value, or two values that sum to one provides the same result.</p>
</td></tr>
<tr><td><code id="CIBinary_+3A_raters">raters</code></td>
<td>
<p>The number of raters that are available.  This function allows between
2 and 6 raters.</p>
</td></tr>
<tr><td><code id="CIBinary_+3A_alpha">alpha</code></td>
<td>
<p>The desired type I error rate.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function provides detailed sample size estimation computation for studies
of interobserver agreement with a binary outcome.  This function employs the
confidence interval perspective, determining the correct sample size that provides
the specified expected confidence limits.  Sample
size estimation is based on the precision of the estimate, instead of a simple hypothesis
testing perspective.  Note that a warning message is provided if any of the expected cell counts are less than 5.
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>N</code></td>
<td>
<p>The calculated sample size.</p>
</td></tr>
<tr><td><code>kappa0</code></td>
<td>
<p>The specified anticipated value of <code class="reqn">\kappa</code>.</p>
</td></tr>
<tr><td><code>kappaL</code></td>
<td>
<p>The specified expected lower limit.</p>
</td></tr>
<tr><td><code>kappaU</code></td>
<td>
<p>The specified expected upper limit.</p>
</td></tr>
<tr><td><code>props</code></td>
<td>
<p>The anticipated proportion of individuals with the outcome.</p>
</td></tr>
<tr><td><code>raters</code></td>
<td>
<p>The number of raters.</p>
</td></tr>
<tr><td><code>alpha</code></td>
<td>
<p>The desired type I error rate.</p>
</td></tr>
<tr><td><code>ChiCrit</code></td>
<td>
<p>The critical value that is required for sample size estimation.  It is
typically not required and is not displayed in the summary output.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michael Rotondi, <a href="mailto:mrotondi@yorku.ca">mrotondi@yorku.ca</a></p>


<h3>References</h3>

<p>Rotondi MA, Donner A.  (2012).  A Confidence Interval Approach to Sample Size Estimation for Interobserver Agreement Studies with Multiple Raters and Outcomes.  Journal of Clinical Epidemiology, 65:778-784.
</p>
<p>Donner A, Rotondi MA.  (2010).  Sample Size Requirements for Interval Estimation of the Kappa Statistic for Interobserver Agreement Studies with a Binary Outcome and Multiple Raters.  International Journal of Biostatistics 6:31.
</p>
<p>Altaye M, Donner A, Klar N.  (2001). Procedures for Assessing Interobserver Agreement among Multiple Raters.  Biometrics 57:584-588.
</p>
<p>Donner A.  (1999).  Sample Size Requirements for Interval Estimation of the Intraclass Kappa Statistic.  Communication in Statistics 28:415-429.
</p>
<p>Bartfay E, Donner A. (2001).  Statistical Inferences for Interobserver Agreement Studies with Nominal Outcome Data.  The Statistician 50:135-146.
</p>
<p>Donner A, Eliasziw M. (1987) Sample size requirements for reliability studies. Statistics in Medicine 6:441-448.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+PowerBinary">PowerBinary</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: Suppose an investigator would like to determine the required sample size to test
kappa0=0.4 with precision of 0.1 on each side, in a study of interobserver agreement. 
Further suppose that the prevalence of the trait of interest is 0.30.
## End(Not run)
CIBinary(kappa0=0.4, kappaL=0.3, kappaU=0.5, props=0.30, alpha=0.05);
</code></pre>

<hr>
<h2 id='FixedN3Cats'>Calculation of the Lowest Expected Value, kappaL for a fixed sample
size in a Study of Interobserver Agreement with a Multinomial Outcome (3 Levels)</h2><span id='topic+FixedN3Cats'></span><span id='topic+print.FixedN3Cats'></span><span id='topic+summary.FixedN3Cats'></span>

<h3>Description</h3>

<p>This function provides the potential lower bound for a 100(1 - <code class="reqn">\alpha</code>) % confidence interval
that can be calculated for a fixed sample size, n, and an anticipated
value of <code class="reqn">\kappa</code>. This version assumes that the outcome has three categories.</p>


<h3>Usage</h3>

<pre><code class='language-R'>FixedN3Cats(kappa0, n, props, raters=2, alpha=0.05)</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="FixedN3Cats_+3A_kappa0">kappa0</code></td>
<td>
<p>The preliminary value of <code class="reqn">\kappa</code>.</p>
</td></tr>
<tr><td><code id="FixedN3Cats_+3A_n">n</code></td>
<td>
<p>The total number of available subjects.</p>
</td></tr>
<tr><td><code id="FixedN3Cats_+3A_props">props</code></td>
<td>
<p>The anticipated prevalence of the desired trait.  Note that the elements
of the three element vector must be non-negative and sum to one.</p>
</td></tr>
<tr><td><code id="FixedN3Cats_+3A_raters">raters</code></td>
<td>
<p>The number of raters that are available.  This function allows between
2 and 6 raters.</p>
</td></tr>
<tr><td><code id="FixedN3Cats_+3A_alpha">alpha</code></td>
<td>
<p>The desired type I error rate.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function calculates the expected lower bound of a one-sided
confidence interval for a fixed sample size, n, and an anticipated
value of <code class="reqn">\kappa</code>, kappa0.  This function can illustrate the amount of precision
available in the estimation of <code class="reqn">\kappa</code> for a fixed sample size.  Note that a warning message is provided if any of the expected cell counts are less than 5.</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>n</code></td>
<td>
<p>The specified sample size.</p>
</td></tr>
<tr><td><code>kappa0</code></td>
<td>
<p>The specified anticipated value of <code class="reqn">\kappa</code>.</p>
</td></tr>
<tr><td><code>kappaL</code></td>
<td>
<p>The calculated expected lower limit.</p>
</td></tr>
<tr><td><code>props</code></td>
<td>
<p>The anticipated proportion of individuals with the outcome.</p>
</td></tr>
<tr><td><code>raters</code></td>
<td>
<p>The number of raters.</p>
</td></tr>
<tr><td><code>alpha</code></td>
<td>
<p>The desired type I error rate.</p>
</td></tr>
<tr><td><code>ChiCrit</code></td>
<td>
<p>The critical value that is required for sample size estimation.  It is
typically not required and is not displayed in the summary output.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michael Rotondi, <a href="mailto:mrotondi@yorku.ca">mrotondi@yorku.ca</a></p>


<h3>References</h3>

<p>Rotondi MA, Donner A.  (2012).  A Confidence Interval Approach to Sample Size Estimation for Interobserver Agreement Studies with Multiple Raters and Outcomes.  Journal of Clinical Epidemiology, 65:778-784.
</p>
<p>Donner A, Rotondi MA.  (2010).  Sample Size Requirements for Interval Estimation of the Kappa Statistic for Interobserver Agreement Studies with a Binary Outcome and Multiple Raters.  International Journal of Biostatistics 6:31. 
</p>
<p>Altaye M, Donner A, Klar N.  (2001). Procedures for Assessing Interobserver Agreement among Multiple Raters.  Biometrics 57:584-588.
</p>
<p>Donner A.  (1999).  Sample Size Requirements for Interval Estimation of the Intraclass Kappa Statistic.  Communication in Statistics 28:415-429.
</p>
<p>Bartfay E, Donner A. (2001).  Statistical Inferences for Interobserver Agreement Studies with Nominal Outcome Data.  The Statistician 50:135-146.
</p>
<p>Donner A, Eliasziw M. (1987) Sample size requirements for reliability studies. Statistics in Medicine 6:441-448.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: Suppose an investigator would like to determine the expected lower bound for 
kappa0=0.7 assuming he has access to 80 subjects and 5 raters.  Further suppose that 
the prevalence of the trait is 0.50.
## End(Not run)
FixedN3Cats(kappa0=0.7, n=80, props=c(0.33, 0.34, 0.33), alpha=0.05, raters=5);
</code></pre>

<hr>
<h2 id='FixedN4Cats'>Calculation of the Lowest Expected Value, kappaL, for a fixed sample
size in a Study of Interobserver Agreement with a Multinomial Outcome (4 Levels)</h2><span id='topic+FixedN4Cats'></span><span id='topic+print.FixedN4Cats'></span><span id='topic+summary.FixedN4Cats'></span>

<h3>Description</h3>

<p>This function provides the potential lower bound for a 100(1 - <code class="reqn">\alpha</code>) % confidence interval
that can be calculated for a fixed sample size, n, and an anticipated
value of <code class="reqn">\kappa</code>, kappa0.  This version assumes that the outcome of interest has four levels.</p>


<h3>Usage</h3>

<pre><code class='language-R'>FixedN4Cats(kappa0, n, props, raters=2, alpha=0.05)</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="FixedN4Cats_+3A_kappa0">kappa0</code></td>
<td>
<p>The anticipated value of <code class="reqn">\kappa</code>.</p>
</td></tr>
<tr><td><code id="FixedN4Cats_+3A_n">n</code></td>
<td>
<p>The total number of available subjects.</p>
</td></tr>
<tr><td><code id="FixedN4Cats_+3A_props">props</code></td>
<td>
<p>The anticipated prevalence of the desired trait.  Note that the elements
of the four element vector must be non-negative and sum to one.</p>
</td></tr>
<tr><td><code id="FixedN4Cats_+3A_raters">raters</code></td>
<td>
<p>The number of raters that are available.  This function allows between
2 and 6 raters.</p>
</td></tr>
<tr><td><code id="FixedN4Cats_+3A_alpha">alpha</code></td>
<td>
<p>The desired type I error rate.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function calculates the expected lower bound of a one-sided
confidence interval for a fixed sample size, n, and an anticipated
value of <code class="reqn">\kappa</code>, kappa0.  This function can illustrate the amount of precision
available in the estimation of <code class="reqn">\kappa</code> for a fixed sample size.  Note that a warning message is provided if any of the expected cell counts are less than 5.
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>n</code></td>
<td>
<p>The specified sample size.</p>
</td></tr>
<tr><td><code>kappa0</code></td>
<td>
<p>The specified anticipated value of <code class="reqn">\kappa</code>.</p>
</td></tr>
<tr><td><code>kappaL</code></td>
<td>
<p>The calculated expected lower limit.</p>
</td></tr>
<tr><td><code>props</code></td>
<td>
<p>The anticipated proportion of individuals with the outcome.</p>
</td></tr>
<tr><td><code>raters</code></td>
<td>
<p>The number of raters.</p>
</td></tr>
<tr><td><code>alpha</code></td>
<td>
<p>The desired type I error rate.</p>
</td></tr>
<tr><td><code>ChiCrit</code></td>
<td>
<p>The critical value that is required for sample size estimation.  It is
typically not required and is not displayed in the summary output.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michael Rotondi, <a href="mailto:mrotondi@yorku.ca">mrotondi@yorku.ca</a></p>


<h3>References</h3>

<p>Rotondi MA, Donner A.  (2012).  A Confidence Interval Approach to Sample Size Estimation for Interobserver Agreement Studies with Multiple Raters and Outcomes.  Journal of Clinical Epidemiology, 65:778-784.
</p>
<p>Donner A, Rotondi MA.  (2010).  Sample Size Requirements for Interval Estimation of the Kappa Statistic for Interobserver Agreement Studies with a Binary Outcome and Multiple Raters.  International Journal of Biostatistics 6:31. 
</p>
<p>Altaye M, Donner A, Klar N.  (2001). Procedures for Assessing Interobserver Agreement among Multiple Raters.  Biometrics 57:584-588.
</p>
<p>Donner A.  (1999).  Sample Size Requirements for Interval Estimation of the Intraclass Kappa Statistic.  Communication in Statistics 28:415-429.
</p>
<p>Bartfay E, Donner A. (2001).  Statistical Inferences for Interobserver Agreement Studies with Nominal Outcome Data.  The Statistician 50:135-146.
</p>
<p>Donner A, Eliasziw M. (1987) Sample size requirements for reliability studies. Statistics in Medicine 6:441-448.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: Suppose an investigator would like to determine the expected lower bound for 
kappa0=0.7 assuming he has access to 80 subjects and 5 raters.  Further suppose that 
the prevalence of the traits of interest are 0.4, 0.4, 0.1, 0.1.
## End(Not run)
FixedN4Cats(kappa0=0.7, n=80, props=c(0.4, 0.4, 0.1, 0.1), alpha=0.05, raters=5);
</code></pre>

<hr>
<h2 id='FixedN5Cats'>Calculation of the Lowest Expected Value, kappaL, for a fixed sample
size in a Study of Interobserver Agreement with a Multinomial Outcome (5 Levels)</h2><span id='topic+FixedN5Cats'></span><span id='topic+print.FixedN5Cats'></span><span id='topic+summary.FixedN5Cats'></span>

<h3>Description</h3>

<p>This function provides the potential lower bound for a 100(1 - <code class="reqn">\alpha</code>) % confidence interval
that can be calculated for a fixed sample size, n, and an anticipated
value of <code class="reqn">\kappa</code>, kappa0.  This version assumes that the outcome of interest has five levels.</p>


<h3>Usage</h3>

<pre><code class='language-R'>FixedN5Cats(kappa0, n, props, raters=2, alpha=0.05)</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="FixedN5Cats_+3A_kappa0">kappa0</code></td>
<td>
<p>The anticipated preliminary value of <code class="reqn">\kappa</code>.</p>
</td></tr>
<tr><td><code id="FixedN5Cats_+3A_n">n</code></td>
<td>
<p>The total number of available subjects.</p>
</td></tr>
<tr><td><code id="FixedN5Cats_+3A_props">props</code></td>
<td>
<p>The anticipated prevalence of the desired traits.  Note that the elements
of the five element vector must be non-negative and sum to one.</p>
</td></tr>
<tr><td><code id="FixedN5Cats_+3A_raters">raters</code></td>
<td>
<p>The number of raters that are available.  This function allows between
2 and 6 raters.</p>
</td></tr>
<tr><td><code id="FixedN5Cats_+3A_alpha">alpha</code></td>
<td>
<p>The desired type I error rate.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function calculates the expected lower bound of a one-sided
confidence interval for a fixed sample size, n, and an anticipated
value of <code class="reqn">\kappa</code>, kappa0.  This function can illustrate the amount of precision
available in the estimation of kappa for a fixed sample size.  Note that a warning message is provided if any of the expected cell counts are less than 5.
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>n</code></td>
<td>
<p>The specified sample size.</p>
</td></tr>
<tr><td><code>kappa0</code></td>
<td>
<p>The specified anticipated value of <code class="reqn">\kappa</code>.</p>
</td></tr>
<tr><td><code>kappaL</code></td>
<td>
<p>The calculated expected lower limit.</p>
</td></tr>
<tr><td><code>props</code></td>
<td>
<p>The anticipated proportion of individuals with the outcome.</p>
</td></tr>
<tr><td><code>raters</code></td>
<td>
<p>The number of raters.</p>
</td></tr>
<tr><td><code>alpha</code></td>
<td>
<p>The desired type I error rate.</p>
</td></tr>
<tr><td><code>ChiCrit</code></td>
<td>
<p>The critical value that is required for sample size estimation.  It is
typically not required and is not displayed in the summary output.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michael Rotondi, <a href="mailto:mrotondi@yorku.ca">mrotondi@yorku.ca</a></p>


<h3>References</h3>

<p>Rotondi MA, Donner A.  (2012).  A Confidence Interval Approach to Sample Size Estimation for Interobserver Agreement Studies with Multiple Raters and Outcomes.  Journal of Clinical Epidemiology, 65:778-784.
</p>
<p>Donner A, Rotondi MA.  (2010).  Sample Size Requirements for Interval Estimation of the Kappa Statistic for Interobserver Agreement Studies with a Binary Outcome and Multiple Raters.  International Journal of Biostatistics 6:31. 
</p>
<p>Altaye M, Donner A, Klar N.  (2001). Procedures for Assessing Interobserver Agreement among Multiple Raters.  Biometrics 57:584-588.
</p>
<p>Donner A.  (1999).  Sample Size Requirements for Interval Estimation of the Intraclass Kappa Statistic.  Communication in Statistics 28:415-429.
</p>
<p>Bartfay E, Donner A. (2001).  Statistical Inferences for Interobserver Agreement Studies with Nominal Outcome Data.  The Statistician 50:135-146.
</p>
<p>Donner A, Eliasziw M. (1987) Sample size requirements for reliability studies. Statistics in Medicine 6:441-448.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: Suppose an investigator would like to determine the expected lower bound for
kappa0=0.6 assuming he has access to 150 subjects and 2 raters.  Further suppose that 
the prevalence of the traits of interest are 0.4, 0.2, 0.2, 0.1, 0.1.
## End(Not run)
FixedN5Cats(kappa0=0.6, n=150, props=c(0.4, 0.2, 0.2, 0.1, 0.1), alpha=0.05, raters=2);
</code></pre>

<hr>
<h2 id='FixedNBinary'>Calculation of the Lowest Expected Value, kappaL, for a fixed sample
size in a Study of Interobserver Agreement with a Binary Outcome</h2><span id='topic+FixedNBinary'></span><span id='topic+print.FixedNBinary'></span><span id='topic+summary.FixedNBinary'></span>

<h3>Description</h3>

<p>This function provides the potential lower bound for a 100(1 - <code class="reqn">\alpha</code>) % confidence interval
that can be calculated for a fixed sample size, n, and an anticipated
value of <code class="reqn">\kappa</code>, kappa0.  This version assumes that the outcome of interest is binary.</p>


<h3>Usage</h3>

<pre><code class='language-R'>FixedNBinary(kappa0, n, props, raters=2, alpha=0.05)</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="FixedNBinary_+3A_kappa0">kappa0</code></td>
<td>
<p>The preliminary value of <code class="reqn">\kappa</code>.</p>
</td></tr>
<tr><td><code id="FixedNBinary_+3A_n">n</code></td>
<td>
<p>The total number of available subjects.</p>
</td></tr>
<tr><td><code id="FixedNBinary_+3A_props">props</code></td>
<td>
<p>The anticipated prevalence of the desired trait.  Note that specifying
props as either a single value, or two values that some to one, provides the same result.</p>
</td></tr>
<tr><td><code id="FixedNBinary_+3A_raters">raters</code></td>
<td>
<p>The number of raters that are available.  This function allows between
2 and 6 raters.</p>
</td></tr>
<tr><td><code id="FixedNBinary_+3A_alpha">alpha</code></td>
<td>
<p>The desired type I error rate.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function calculates the expected lower bound of a one-sided
confidence interval for a fixed sample size, n, and an anticipated
value of <code class="reqn">\kappa</code>, kappa0.  This function can illustrate the amount of precision
available in the estimation of kappa for a fixed sample size.  Note that a warning message is provided if any of the expected cell counts are less than 5.
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>n</code></td>
<td>
<p>The specified sample size.</p>
</td></tr>
<tr><td><code>kappa0</code></td>
<td>
<p>The specified anticipated value of <code class="reqn">\kappa</code>.</p>
</td></tr>
<tr><td><code>kappaL</code></td>
<td>
<p>The calculated expected lower limit.</p>
</td></tr>
<tr><td><code>props</code></td>
<td>
<p>The anticipated proportion of individuals with the outcome.</p>
</td></tr>
<tr><td><code>raters</code></td>
<td>
<p>The number of raters.</p>
</td></tr>
<tr><td><code>alpha</code></td>
<td>
<p>The desired type I error rate.</p>
</td></tr>
<tr><td><code>ChiCrit</code></td>
<td>
<p>The critical value that is required for sample size estimation.  It is
typically not required and is not displayed in the summary output.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michael Rotondi, <a href="mailto:mrotondi@yorku.ca">mrotondi@yorku.ca</a></p>


<h3>References</h3>

<p>Rotondi MA, Donner A.  (2012).  A Confidence Interval Approach to Sample Size Estimation for Interobserver Agreement Studies with Multiple Raters and Outcomes.  Journal of Clinical Epidemiology, 65:778-784.
</p>
<p>Donner A, Rotondi MA.  (2010).  Sample Size Requirements for Interval Estimation of the Kappa Statistic for Interobserver Agreement Studies with a Binary Outcome and Multiple Raters.  International Journal of Biostatistics 6:31. 
</p>
<p>Altaye M, Donner A, Klar N.  (2001). Procedures for Assessing Interobserver Agreement among Multiple Raters.  Biometrics 57:584-588.
</p>
<p>Donner A.  (1999).  Sample Size Requirements for Interval Estimation of the Intraclass Kappa Statistic.  Communication in Statistics 28:415-429.
</p>
<p>Bartfay E, Donner A. (2001).  Statistical Inferences for Interobserver Agreement Studies with Nominal Outcome Data.  The Statistician 50:135-146.
</p>
<p>Donner A, Eliasziw M. (1987) Sample size requirements for reliability studies. Statistics in Medicine 6:441-448.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: Suppose an investigator would like to determine the expected lower bound for 
kappa0=0.7 assuming he has access to 100 subjects and 4 raters.  Further suppose that 
the prevalence of the trait is 0.50.
## End(Not run)
FixedNBinary(kappa0=0.7, n=100, props=0.50, alpha=0.05, raters=4);
</code></pre>

<hr>
<h2 id='Power3Cats'>Power-Based Approach for the Number of Subjects Required for a Study of Interobserver Agreement with Three Outcome Categories</h2><span id='topic+Power3Cats'></span><span id='topic+print.Power3Cats'></span><span id='topic+summary.Power3Cats'></span>

<h3>Description</h3>

<p>This function provides detailed sample size estimation information to determine
the number of subjects that are required to test the hypothesis <code class="reqn">H_0: \kappa = \kappa_0</code> vs. <code class="reqn">H_1: \kappa = \kappa_1</code>,
at two-sided significance level <code class="reqn">\alpha</code>, with power, <code class="reqn">1 - \beta</code>.  This version assumes that the outcome is multinomial with three levels.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Power3Cats(kappa0, kappa1, props, raters=2, alpha=0.05, power=0.80)</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Power3Cats_+3A_kappa0">kappa0</code></td>
<td>
<p>The null hypothesis for the <code class="reqn">\kappa</code> hypothesis test.</p>
</td></tr>
<tr><td><code id="Power3Cats_+3A_kappa1">kappa1</code></td>
<td>
<p>The alternate hypothesis for the <code class="reqn">\kappa</code> hypothesis test.</p>
</td></tr>
<tr><td><code id="Power3Cats_+3A_props">props</code></td>
<td>
<p>The anticipated prevalence of the desired traits.  Note that this three element vector must sum to one.</p>
</td></tr>
<tr><td><code id="Power3Cats_+3A_raters">raters</code></td>
<td>
<p>The number of raters that are available.  This function allows between
2 and 6 raters.</p>
</td></tr>
<tr><td><code id="Power3Cats_+3A_alpha">alpha</code></td>
<td>
<p>The desired type I error rate.</p>
</td></tr>
<tr><td><code id="Power3Cats_+3A_power">power</code></td>
<td>
<p>The desired level of power, recall power = 1 - type II error.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function provides detailed sample size estimation tools for studies
of interobserver agreement with three levels.  This function employs the
power approach, rejecting <code class="reqn">\kappa_0</code> in favour of <code class="reqn">\kappa_1</code> for a pre-specified significance
level and power.  Note that a warning message is provided if any of the expected cell counts are less than 5.
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>N</code></td>
<td>
<p>The calculated sample size.</p>
</td></tr>
<tr><td><code>kappa0</code></td>
<td>
<p>The specified null hypothesis.</p>
</td></tr>
<tr><td><code>kappa1</code></td>
<td>
<p>The specified alternative hypothesis.</p>
</td></tr>
<tr><td><code>props</code></td>
<td>
<p>The anticipated proportion of individuals with the outcome.</p>
</td></tr>
<tr><td><code>raters</code></td>
<td>
<p>The number of raters.</p>
</td></tr>
<tr><td><code>alpha</code></td>
<td>
<p>The desired type I error rate.</p>
</td></tr>
<tr><td><code>power</code></td>
<td>
<p>The desired level of power, recall power = 1 - type II error.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michael Rotondi, <a href="mailto:mrotondi@yorku.ca">mrotondi@yorku.ca</a></p>


<h3>References</h3>

<p>Rotondi MA, Donner A.  (2012).  A Confidence Interval Approach to Sample Size Estimation for Interobserver Agreement Studies with Multiple Raters and Outcomes.  Journal of Clinical Epidemiology, 65:778-784.
</p>
<p>Donner A, Rotondi MA.  (2010).  Sample Size Requirements for Interval Estimation of the Kappa Statistic for Interobserver Agreement Studies with a Binary Outcome and Multiple Raters.  International Journal of Biostatistics 6:31. 
</p>
<p>Altaye M, Donner A, Klar N.  (2001). Procedures for Assessing Interobserver Agreement among Multiple Raters.  Biometrics 57:584-588. 
</p>
<p>Donner A.  (1999).  Sample Size Requirements for Interval Estimation of the Intraclass Kappa Statistic.  Communication in Statistics 28:415-429. 
</p>
<p>Bartfay E, Donner A. (2001).  Statistical Inferences for Interobserver Agreement Studies with Nominal Outcome Data.  The Statistician 50:135-146. 
</p>
<p>Donner A, Eliasziw M. (1987) Sample size requirements for reliability studies. Statistics in Medicine 6:441-448. 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+CI3Cats">CI3Cats</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: Suppose an investigator would like to determine the required sample size to test 
kappa0=0.4 vs. kappa1=0.6 with alpha=0.05 and power=0.80 in a study of 
interobserver agreement.  Further suppose that the prevalence of the categories is 
0.30, 0.60 and 0.10.
## End(Not run)
Power3Cats(kappa0=0.4, kappa1=0.6, props=c(0.30, 0.60, 0.10), alpha=0.05, power=0.80);
</code></pre>

<hr>
<h2 id='Power4Cats'>Power-Based Approach for the Number of Subjects Required for a Study of Interobserver Agreement with Four Outcome Categories</h2><span id='topic+Power4Cats'></span><span id='topic+print.Power4Cats'></span><span id='topic+summary.Power4Cats'></span>

<h3>Description</h3>

<p>This function provides detailed sample size estimation information to determine
the number of subjects that are required to test the hypothesis <code class="reqn">H_0: \kappa = \kappa_0</code> vs. <code class="reqn">H_1: \kappa = \kappa_1</code>, at two-sided 
significance level <code class="reqn">\alpha</code>, with power, <code class="reqn">1 - \beta</code>.  This version assumes that the outcome is multinomial with four levels.</p>


<h3>Usage</h3>

<pre><code class='language-R'>Power4Cats(kappa0, kappa1, props, raters=2, alpha=0.05, power=0.80)</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Power4Cats_+3A_kappa0">kappa0</code></td>
<td>
<p>The null hypothesis for the <code class="reqn">\kappa</code> hypothesis test.</p>
</td></tr>
<tr><td><code id="Power4Cats_+3A_kappa1">kappa1</code></td>
<td>
<p>The alternate hypothesis for the <code class="reqn">\kappa</code> hypothesis test.</p>
</td></tr>
<tr><td><code id="Power4Cats_+3A_props">props</code></td>
<td>
<p>The anticipated prevalence of the desired traits.  Note that this four element vector must sum to one.</p>
</td></tr>
<tr><td><code id="Power4Cats_+3A_raters">raters</code></td>
<td>
<p>The number of raters that are available.  This function allows between
2 and 6 raters.</p>
</td></tr>
<tr><td><code id="Power4Cats_+3A_alpha">alpha</code></td>
<td>
<p>The desired type I error rate.</p>
</td></tr>
<tr><td><code id="Power4Cats_+3A_power">power</code></td>
<td>
<p>The desired level of power, recall power = 1 - type II error.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function provides detailed sample size estimation tools for studies
of interobserver agreement with four levels.  This function employs the
power approach, rejecting <code class="reqn">\kappa_0</code> in favour of <code class="reqn">\kappa_1</code> for a pre-specified significance
level and power.  Note that a warning message is provided if any of the expected cell counts are less than 5.
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>N</code></td>
<td>
<p>The calculated sample size.</p>
</td></tr>
<tr><td><code>kappa0</code></td>
<td>
<p>The specified null hypothesis.</p>
</td></tr>
<tr><td><code>kappa1</code></td>
<td>
<p>The specified alternative hypothesis.</p>
</td></tr>
<tr><td><code>props</code></td>
<td>
<p>The anticipated proportion of individuals with the outcome.</p>
</td></tr>
<tr><td><code>raters</code></td>
<td>
<p>The number of raters.</p>
</td></tr>
<tr><td><code>alpha</code></td>
<td>
<p>The desired type I error rate.</p>
</td></tr>
<tr><td><code>power</code></td>
<td>
<p>The desired level of power, recall power = 1 - type II error.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michael Rotondi, <a href="mailto:mrotondi@yorku.ca">mrotondi@yorku.ca</a></p>


<h3>References</h3>

<p>Rotondi MA, Donner A.  (2012).  A Confidence Interval Approach to Sample Size Estimation for Interobserver Agreement Studies with Multiple Raters and Outcomes.  Journal of Clinical Epidemiology, 65:778-784.
</p>
<p>Donner A, Rotondi MA.  (2010).  Sample Size Requirements for Interval Estimation of the Kappa Statistic for Interobserver Agreement Studies with a Binary Outcome and Multiple Raters.  International Journal of Biostatistics 6:31. 
</p>
<p>Altaye M, Donner A, Klar N.  (2001). Procedures for Assessing Interobserver Agreement among Multiple Raters.  Biometrics 57:584-588.
</p>
<p>Donner A.  (1999).  Sample Size Requirements for Interval Estimation of the Intraclass Kappa Statistic.  Communication in Statistics 28:415-429.
</p>
<p>Bartfay E, Donner A. (2001).  Statistical Inferences for Interobserver Agreement Studies with Nominal Outcome Data.  The Statistician 50:135-146.
</p>
<p>Donner A, Eliasziw M. (1987) Sample size requirements for reliability studies. Statistics in Medicine 6:441-448.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+CI4Cats">CI4Cats</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: Suppose an investigator would like to determine the required sample size to test 
kappa0=0.4 vs. kappa1=0.6 with alpha=0.05 and power=0.80 in a study of 
interobserver agreement.  Further suppose that the prevalence of the categories is 
0.30, 0.30, 0.30 and 0.10.
## End(Not run)
Power4Cats(kappa0=0.4, kappa1=0.6, props=c(0.30, 0.30, 0.30, 0.10), alpha=0.05, power=0.80);
</code></pre>

<hr>
<h2 id='Power5Cats'>Power-Based Approach for the Number of Subjects Required for a Study of Interobserver Agreement with Five Outcome Categories</h2><span id='topic+Power5Cats'></span><span id='topic+print.Power5Cats'></span><span id='topic+summary.Power5Cats'></span>

<h3>Description</h3>

<p>This function provides detailed sample size estimation information to determine
the number of subjects that are required to test the hypothesis <code class="reqn">H_0: \kappa = \kappa_0</code> vs. <code class="reqn">H_1: \kappa = \kappa_1</code>, at two-sided 
significance level <code class="reqn">\alpha</code>, with power, <code class="reqn">1 - \beta</code>.  This version assumes that the outcome is multinomial with five levels.</p>


<h3>Usage</h3>

<pre><code class='language-R'>Power5Cats(kappa0, kappa1, props, raters=2, alpha=0.05, power=0.80)</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Power5Cats_+3A_kappa0">kappa0</code></td>
<td>
<p>The null hypothesis for the <code class="reqn">\kappa</code> hypothesis test.</p>
</td></tr>
<tr><td><code id="Power5Cats_+3A_kappa1">kappa1</code></td>
<td>
<p>The alternate hypothesis for the <code class="reqn">\kappa</code> hypothesis test.</p>
</td></tr>
<tr><td><code id="Power5Cats_+3A_props">props</code></td>
<td>
<p>The anticipated prevalence of the desired traits.  Note that this five element vector must sum to one.</p>
</td></tr>
<tr><td><code id="Power5Cats_+3A_raters">raters</code></td>
<td>
<p>The number of raters that are available.  This function allows between
2 and 6 raters.</p>
</td></tr>
<tr><td><code id="Power5Cats_+3A_alpha">alpha</code></td>
<td>
<p>The desired type I error rate.</p>
</td></tr>
<tr><td><code id="Power5Cats_+3A_power">power</code></td>
<td>
<p>The desired level of power, recall power = 1 - type II error.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function provides detailed sample size estimation tools for studies
of interobserver agreement with five levels.  This function employs the
power approach, rejecting <code class="reqn">\kappa_0</code> in favour of <code class="reqn">\kappa_1</code> for a pre-specified significance
level and power.  Note that a warning message is provided if any of the expected cell counts are less than 5.
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>N</code></td>
<td>
<p>The calculated sample size.</p>
</td></tr>
<tr><td><code>kappa0</code></td>
<td>
<p>The specified null hypothesis.</p>
</td></tr>
<tr><td><code>kappa1</code></td>
<td>
<p>The specified alternative hypothesis.</p>
</td></tr>
<tr><td><code>props</code></td>
<td>
<p>The anticipated proportion of individuals with the outcome.</p>
</td></tr>
<tr><td><code>raters</code></td>
<td>
<p>The number of raters.</p>
</td></tr>
<tr><td><code>alpha</code></td>
<td>
<p>The desired type I error rate.</p>
</td></tr>
<tr><td><code>power</code></td>
<td>
<p>The desired level of power, recall power = 1 - type II error.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michael Rotondi, <a href="mailto:mrotondi@yorku.ca">mrotondi@yorku.ca</a></p>


<h3>References</h3>

<p>Rotondi MA, Donner A.  (2012).  A Confidence Interval Approach to Sample Size Estimation for Interobserver Agreement Studies with Multiple Raters and Outcomes.  Journal of Clinical Epidemiology, 65:778-784.
</p>
<p>Donner A, Rotondi MA.  (2010).  Sample Size Requirements for Interval Estimation of the Kappa Statistic for Interobserver Agreement Studies with a Binary Outcome and Multiple Raters.  International Journal of Biostatistics 6:31. 
</p>
<p>Altaye M, Donner A, Klar N.  (2001). Procedures for Assessing Interobserver Agreement among Multiple Raters.  Biometrics 57:584-588.
</p>
<p>Donner A.  (1999).  Sample Size Requirements for Interval Estimation of the Intraclass Kappa Statistic.  Communication in Statistics 28:415-429.
</p>
<p>Bartfay E, Donner A. (2001).  Statistical Inferences for Interobserver Agreement Studies with Nominal Outcome Data.  The Statistician 50:135-146.
</p>
<p>Donner A, Eliasziw M. (1987) Sample size requirements for reliability studies. Statistics in Medicine 6:441-448.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+CI5Cats">CI5Cats</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: Suppose an investigator would like to determine the required sample size to test 
kappa0=0.4 vs. kappa1=0.6 with alpha=0.05 and power=0.80 in a study of 
interobserver agreement.  Further suppose that the prevalence of the categories is 
0.30, 0.20, 0.10, 0.30 and 0.10.
## End(Not run)
Power5Cats(kappa0=0.4, kappa1=0.6, props=c(0.30, 0.20, 0.10, 0.30, 0.10), alpha=0.05, power=0.80);
</code></pre>

<hr>
<h2 id='PowerBinary'>Power-Based Approach for the Number of Subjects Required for a Study of Interobserver Agreement with a Binary Outcome</h2><span id='topic+PowerBinary'></span><span id='topic+print.PowerBinary'></span><span id='topic+summary.PowerBinary'></span>

<h3>Description</h3>

<p>This function provides detailed sample size estimation information to determine
the number of subjects that are required to test the hypothesis <code class="reqn">H_0: \kappa = \kappa_0</code> vs. <code class="reqn">H_1: \kappa = \kappa_1</code>, at two-sided 
significance level <code class="reqn">\alpha</code>, with power, <code class="reqn">1 - \beta</code>.</p>


<h3>Usage</h3>

<pre><code class='language-R'>PowerBinary(kappa0, kappa1, props, raters=2, alpha=0.05, power=0.80)</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="PowerBinary_+3A_kappa0">kappa0</code></td>
<td>
<p>The null hypothesis for the <code class="reqn">\kappa</code> hypothesis test.</p>
</td></tr>
<tr><td><code id="PowerBinary_+3A_kappa1">kappa1</code></td>
<td>
<p>The alternate hypothesis for the <code class="reqn">\kappa</code> hypothesis test.</p>
</td></tr>
<tr><td><code id="PowerBinary_+3A_props">props</code></td>
<td>
<p>The anticipated prevalence of the desired trait.  Note that specifying
props as either a single value, or two values that some to one, provides the same result.</p>
</td></tr>
<tr><td><code id="PowerBinary_+3A_raters">raters</code></td>
<td>
<p>The number of raters that are available.  This function allows between
2 and 6 raters.</p>
</td></tr>
<tr><td><code id="PowerBinary_+3A_alpha">alpha</code></td>
<td>
<p>The desired type I error rate.</p>
</td></tr>
<tr><td><code id="PowerBinary_+3A_power">power</code></td>
<td>
<p>The desired level of power, recall power = 1 - type II error.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function provides detailed sample size estimation tools for studies
of interobserver agreement with a binary outcome.  This function employs the
power approach, rejecting <code class="reqn">\kappa_0</code> in favour of <code class="reqn">\kappa_1</code> for a pre-specified significance
level and power.  Note that a warning message is provided if any of the expected cell counts are less than 5.
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>N</code></td>
<td>
<p>The calculated sample size.</p>
</td></tr>
<tr><td><code>kappa0</code></td>
<td>
<p>The specified null hypothesis.</p>
</td></tr>
<tr><td><code>kappa1</code></td>
<td>
<p>The specified alternative hypothesis.</p>
</td></tr>
<tr><td><code>props</code></td>
<td>
<p>The anticipated proportion of individuals with the outcome.</p>
</td></tr>
<tr><td><code>raters</code></td>
<td>
<p>The number of raters.</p>
</td></tr>
<tr><td><code>alpha</code></td>
<td>
<p>The desired type I error rate.</p>
</td></tr>
<tr><td><code>power</code></td>
<td>
<p>The desired level of power, recall power = 1 - type II error.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michael Rotondi, <a href="mailto:mrotondi@yorku.ca">mrotondi@yorku.ca</a></p>


<h3>References</h3>

<p>Rotondi MA, Donner A.  (2012).  A Confidence Interval Approach to Sample Size Estimation for Interobserver Agreement Studies with Multiple Raters and Outcomes.  Journal of Clinical Epidemiology, 65:778-784.
</p>
<p>Donner A, Rotondi MA.  (2010).  Sample Size Requirements for Interval Estimation of the Kappa Statistic for Interobserver Agreement Studies with a Binary Outcome and Multiple Raters.  International Journal of Biostatistics 6:31. 
</p>
<p>Altaye M, Donner A, Klar N.  (2001). Procedures for Assessing Interobserver Agreement among Multiple Raters.  Biometrics 57:584-588.
</p>
<p>Donner A.  (1999).  Sample Size Requirements for Interval Estimation of the Intraclass Kappa Statistic.  Communication in Statistics 28:415-429.
</p>
<p>Bartfay E, Donner A. (2001).  Statistical Inferences for Interobserver Agreement Studies with Nominal Outcome Data.  The Statistician 50:135-146.
</p>
<p>Donner A, Eliasziw M. (1987) Sample size requirements for reliability studies. Statistics in Medicine 6:441-448.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+CIBinary">CIBinary</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: Suppose an investigator would like to determine the required sample size to test 
kappa0=0.4 vs. kappa1=0.6 with alpha=0.05 and power=0.80 in a study of 
interobserver agreement.  Further suppose that the prevalence of the trait is 0.30.
## End(Not run)
PowerBinary(kappa0=0.4, kappa1=0.6, props=0.30, alpha=0.05, power=0.80);
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
