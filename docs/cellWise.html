<!DOCTYPE html><html><head><title>Help for package cellWise</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {cellWise}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#cellHandler'>
<p>cellHandler algorithm</p></a></li>
<li><a href='#cellMap'>
<p>Draw a cellmap</p></a></li>
<li><a href='#cellMCD'>
<p>cellWise minimum covariance determinant estimator</p></a></li>
<li><a href='#checkDataSet'>
<p>Clean the dataset</p></a></li>
<li><a href='#cwLocScat'>
<p>Estimate location and scatter of data with cellwise weights</p></a></li>
<li><a href='#data_brands'>
<p>The brands dataset</p></a></li>
<li><a href='#data_clothes'>
<p>The clothes dataset</p></a></li>
<li><a href='#data_dogWalker'>
<p>Dog walker dataset</p></a></li>
<li><a href='#data_dposs'>
<p>DPOSS dataset</p></a></li>
<li><a href='#data_glass'>
<p>The glass dataset</p></a></li>
<li><a href='#data_mortality'>
<p>The mortality dataset</p></a></li>
<li><a href='#data_personality_traits'>
<p>The personality traits data</p></a></li>
<li><a href='#data_philips'>
<p>The philips dataset</p></a></li>
<li><a href='#data_VOC'>
<p>VOC dataset</p></a></li>
<li><a href='#DDC'>
<p>Detect Deviating Cells</p></a></li>
<li><a href='#DDCpredict'>
<p>DDCpredict</p></a></li>
<li><a href='#DI'>
<p>Detection-Imputation algorithm</p></a></li>
<li><a href='#estLocScale'>
<p>Estimate robust location and scale</p></a></li>
<li><a href='#generateCorMat'>
<p>Generates correlation matrices</p></a></li>
<li><a href='#generateData'>
<p>Generates artificial datasets with outliers</p></a></li>
<li><a href='#ICPCA'>
<p>Iterative Classical PCA</p></a></li>
<li><a href='#MacroPCA'>
<p>MacroPCA</p></a></li>
<li><a href='#MacroPCApredict'>
<p>MacroPCApredict</p></a></li>
<li><a href='#outlierMap'>
<p>Plot the outlier map.</p></a></li>
<li><a href='#plot_cellMCD'>
<p>Draw plots based on the cellwise minimum covariance determinant estimator cellMCD</p></a></li>
<li><a href='#transfo'>
<p>Robustly fit the Box-Cox or Yeo-Johnson transformation</p></a></li>
<li><a href='#transfo_newdata'>
<p>Transform variables based on the output of <code>transfo</code>.</p></a></li>
<li><a href='#transfo_transformback'>
<p>Backtransform variables based on the output of <code>transfo</code>.</p></a></li>
<li><a href='#truncPC'>
<p>Classical Principal Components by truncated SVD.</p></a></li>
<li><a href='#unpack'>
<p>Unpacks cellwise weighted data</p></a></li>
<li><a href='#weightedEM'>
<p>Estimates location and scatter on incomplete data with case weights</p></a></li>
<li><a href='#wrap'>
<p>Wrap the data.</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Version:</td>
<td>2.5.3</td>
</tr>
<tr>
<td>Date:</td>
<td>2023-10-25</td>
</tr>
<tr>
<td>Title:</td>
<td>Analyzing Data with Cellwise Outliers</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 4.0.0)</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, robustHD, MASS, ellipse, markdown, rospca, GSE</td>
</tr>
<tr>
<td>Imports:</td>
<td>reshape2, scales, ggplot2, matrixStats, gridExtra, robustbase,
rrcov, svd, stats, utils, shape, Rcpp (&ge; 0.12.10.14)</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp, RcppArmadillo (&ge; 0.7.600.1.0)</td>
</tr>
<tr>
<td>Description:</td>
<td>Tools for detecting cellwise outliers and robust methods to analyze
    data which may contain them. Contains the implementation of the algorithms described in
    Rousseeuw and Van den Bossche (2018) &lt;<a href="https://doi.org/10.1080%2F00401706.2017.1340909">doi:10.1080/00401706.2017.1340909</a>&gt; (open access)
    Hubert et al. (2019) &lt;<a href="https://doi.org/10.1080%2F00401706.2018.1562989">doi:10.1080/00401706.2018.1562989</a>&gt; (open access),
    Raymaekers and Rousseeuw (2021) &lt;<a href="https://doi.org/10.1080%2F00401706.2019.1677270">doi:10.1080/00401706.2019.1677270</a>&gt; (open access),
    Raymaekers and Rousseeuw (2021) &lt;<a href="https://doi.org/10.1007%2Fs10994-021-05960-5">doi:10.1007/s10994-021-05960-5</a>&gt; (open access),
    Raymaekers and Rousseeuw (2021) &lt;<a href="https://doi.org/10.52933%2Fjdssv.v1i3.18">doi:10.52933/jdssv.v1i3.18</a>&gt; (open access),
    Raymaekers and Rousseeuw (2022) &lt;<a href="https://doi.org/10.48550/arXiv.2207.13493">doi:10.48550/arXiv.2207.13493</a>&gt; (open access)
    Rousseeuw (2022) &lt;<a href="https://doi.org/10.1016%2Fj.ecosta.2023.01.007">doi:10.1016/j.ecosta.2023.01.007</a>&gt; (open access).
    Examples can be found in the vignettes:
    "DDC_examples", "MacroPCA_examples", "wrap_examples", "transfo_examples",
    "DI_examples", "cellMCD_examples" , "Correspondence_analysis_examples",
    and "cellwise_weights_examples".</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>LazyData:</td>
<td>No</td>
</tr>
<tr>
<td>Author:</td>
<td>Jakob Raymaekers [aut, cre],
  Peter Rousseeuw [aut],
  Wannes Van den Bossche [ctb],
  Mia Hubert [ctb]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Jakob Raymaekers &lt;jakob.raymaekers@kuleuven.be&gt;</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.2</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-10-25 12:14:44 UTC; u0105404</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-10-25 13:00:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='cellHandler'>
cellHandler algorithm
</h2><span id='topic+cellHandler'></span>

<h3>Description</h3>

<p>This function flags cellwise outliers in <code>X</code> and imputes them, if robust estimates of the center <code>mu</code> and scatter matrix <code>Sigma</code> are given. When the latter are not known, as is typically the case, one can use the function <code><a href="#topic+DDC">DDC</a></code> which only requires the data matrix <code>X</code>. Alternatively, the unknown center mu and scatter matrix Sigma can be estimated robustly from <code>X</code> by the function <code><a href="#topic+DI">DI</a></code>. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cellHandler(X, mu, Sigma, quant = 0.99)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cellHandler_+3A_x">X</code></td>
<td>
<p><code>X</code> is the input data, and must be an <code class="reqn">n</code> by <code class="reqn">d</code> matrix or a data frame.
</p>
</td></tr>
<tr><td><code id="cellHandler_+3A_mu">mu</code></td>
<td>
<p>An estimate of the center of the data
</p>
</td></tr>
<tr><td><code id="cellHandler_+3A_sigma">Sigma</code></td>
<td>
<p>An estimate of the covariance matrix of the data
</p>
</td></tr>
<tr><td><code id="cellHandler_+3A_quant">quant</code></td>
<td>
<p>Cutoff used in the detection of cellwise outliers. Defaults to <code>0.99</code>
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with components: <br />
</p>

<ul>
<li> <p><code>Ximp</code> <br />
The imputed data matrix.
</p>
</li>
<li> <p><code>indcells</code> <br />
Indices of the cells which were flagged in the analysis.
</p>
</li>
<li> <p><code>indNAs</code> <br />
Indices of the NAs in the data. 
</p>
</li>
<li> <p><code>Zres</code> <br />
Matrix with standardized cellwise residuals of the flagged cells. Contains zeroes in the unflagged cells.
</p>
</li>
<li> <p><code>Zres_denom</code> <br />
Denominator of the standardized cellwise residuals.
</p>
</li>
<li> <p><code>cellPaths</code> <br />
Matrix with the same dimensions as X, in which each row contains the path of least angle regression through the cells of that row, i.e. the order of the coordinates in the path (1=first, 2=second,...)
</p>
</li></ul>



<h3>Author(s)</h3>

<p>J. Raymaekers and P.J. Rousseeuw
</p>


<h3>References</h3>

<p>J. Raymaekers and P.J. Rousseeuw (2020). Handling cellwise outliers by sparse regression and robust covariance. <em>Journal of Data Science, Statistics, and Visualisation</em>. <a href="https://doi.org/10.52933/jdssv.v1i3.18">doi:10.52933/jdssv.v1i3.18</a>(link to open access pdf)
</p>


<h3>See Also</h3>

<p><code><a href="#topic+DI">DI</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>mu &lt;- rep(0, 3)
Sigma &lt;- diag(3) * 0.1 + 0.9
X &lt;- rbind(c(0.5, 1.0, 5.0), c(-3.0, 0.0, 1.0))
n &lt;- nrow(X); d &lt;- ncol(X)
out &lt;- cellHandler(X, mu, Sigma)
Xres &lt;- X - out$Ximp # unstandardized residual
mean(abs(as.vector(Xres - out$Zres*out$Zres_denom))) # 0
W &lt;- matrix(rep(0,n*d),nrow=n) # weight matrix 
W[out$Zres != 0] &lt;- 1 # 1 indicates cells that were flagged
# For more examples, we refer to the vignette:
## Not run: 
vignette("DI_examples")

## End(Not run)
</code></pre>

<hr>
<h2 id='cellMap'>
Draw a cellmap
</h2><span id='topic+cellMap'></span>

<h3>Description</h3>

<p>This function draws a cellmap, possibly of a subset of rows and columns of the data,
and possibly combining cells into blocks. A cellmap shows which cells are missing and which ones are outlying, marking them in red for unusually large cell values and in blue for unusually low cell values. When cells are combined into blocks, the final color is the average of the colors in the individual cells. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cellMap(R, indcells = NULL, indrows = NULL, outrows = NULL, 
        showcellvalues = NULL, D = NULL, rowlabels = NULL,
        columnlabels = NULL, mTitle = "cell map",
        rowtitle = "cases", columntitle = "variables", 
        showrows = NULL, showcolumns = NULL,
        nrowsinblock = NULL, ncolumnsinblock = NULL, 
        manualrowblocksizes = NULL,
        manualcolumnblocksizes = NULL,
        rowblocklabels = NULL, columnblocklabels = NULL,
        sizemain = 1.5, sizetitles = 1.2, sizerowlabels = 1,
        sizecolumnlabels = 1, sizecellvalues = 1, 
        adjustrowlabels = 1, adjustcolumnlabels = 1,
        columnangle = 90, colContrast = 1, 
        outlyingGrad = TRUE, 
        darkestColor = sqrt(qchisq(0.999, 1)),
        drawCircles = FALSE, showVals = NULL, autolabel = TRUE)   
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cellMap_+3A_r">R</code></td>
<td>

<p>Matrix of standardized residuals of the cells (required input argument). After running <code><a href="#topic+DDC">DDC</a></code>, <code><a href="#topic+DDCpredict">DDCpredict</a></code>,  <code><a href="#topic+MacroPCA">MacroPCA</a></code> or <code><a href="#topic+MacroPCApredict">MacroPCApredict</a></code> this is typically their value <code>$stdResid</code>.
</p>
</td></tr>
<tr><td><code id="cellMap_+3A_indcells">indcells</code></td>
<td>

<p>Indices of flagged cells. Defaults to <code>NULL</code>, which flags the cells for which
<code class="reqn">|\code{R}| &gt; \sqrt(qchisq(0.99,1))</code>.
</p>
</td></tr>
<tr><td><code id="cellMap_+3A_indrows">indrows</code></td>
<td>

<p>Indices of outlying rows (if available). If not <code>NULL</code>, the small circle to the right of the row is filled black if the row is in this list, and white otherwise. This gets overruled if <code>outrows</code> is not <code>NULL</code>.
</p>
</td></tr>
<tr><td><code id="cellMap_+3A_outrows">outrows</code></td>
<td>

<p>Outlyingness of each row (if available). If not <code>NULL</code>, represents the outlyingness of each row by a shade of gray in the small circle to the right of the row. This color is white for <code>outrows</code> below <code class="reqn">1</code>, and becomes fully black for <code>outrows</code> over <code class="reqn">3</code>.
</p>
</td></tr>
<tr><td><code id="cellMap_+3A_showcellvalues">showcellvalues</code></td>
<td>

<p>Takes the values <code>"D"</code>, <code>"R"</code> or <code>NULL</code> (the default). If <code>"R"</code> the numerical values of the residuals in <code>R</code> are shown in the cellmap. If <code>"D"</code>, the entries of the data matrix <code>D</code> are shown, provided the matrix <code>D</code> is being specified. If <code>NULL</code>, no entries are shown.
</p>
</td></tr>
<tr><td><code id="cellMap_+3A_d">D</code></td>
<td>

<p>A matrix of data values, of the same dimensions as <code>R</code>. Default is <code>NULL</code>. <code>D</code> is only required when the data values are to be shown in the cellmap, by the option <code>showcellvalues = "D"</code>. After running <code><a href="#topic+DDC">DDC</a></code> or <code><a href="#topic+MacroPCA">MacroPCA</a></code>, <code>D</code> is typically their value <code>$remX</code>. After running <code><a href="#topic+DDCpredict">DDCpredict</a></code> or <code><a href="#topic+MacroPCApredict">MacroPCApredict</a></code> it is their argument <code>$newX</code>.
</p>
</td></tr>
<tr><td><code id="cellMap_+3A_rowlabels">rowlabels</code></td>
<td>

<p>Labels of the rows of the matrix <code>R</code>. If <code>NULL</code>, these labels are taken as rownames(<code>R</code>), and failing that they are <code>1:nrow(R)</code>.
</p>
</td></tr>
<tr><td><code id="cellMap_+3A_columnlabels">columnlabels</code></td>
<td>

<p>Labels of the columns of the matrix <code>R</code>. If <code>NULL</code>, these labels are taken as colnames(<code>R</code>), and failing that they are <code>1:ncol(R)</code>.
</p>
</td></tr>
<tr><td><code id="cellMap_+3A_mtitle">mTitle</code></td>
<td>

<p>Main title of the cellMap. Defaults to &quot;cell map&quot;.
</p>
</td></tr>
<tr><td><code id="cellMap_+3A_rowtitle">rowtitle</code></td>
<td>

<p>Title for the rows. Defaults to &quot;cases&quot;.
</p>
</td></tr>
<tr><td><code id="cellMap_+3A_columntitle">columntitle</code></td>
<td>

<p>Title for the columns. Defaults to &quot;variables&quot;.
</p>
</td></tr>
<tr><td><code id="cellMap_+3A_showrows">showrows</code></td>
<td>

<p>Indices of the rows to be shown. Defaults to <code>NULL</code> which means all rows are shown.
</p>
</td></tr>
<tr><td><code id="cellMap_+3A_showcolumns">showcolumns</code></td>
<td>

<p>Indices of the columns to be shown. Defaults to <code>NULL</code> which means all columns are shown.
</p>
</td></tr>
<tr><td><code id="cellMap_+3A_nrowsinblock">nrowsinblock</code></td>
<td>

<p>How many rows are combined in a block. Defaults to <code>NULL</code>, which asks not to block rows. The argument <code>nrowsinblock</code> is overruled by the argument <code>manualrowblocksizes</code> when the latter is specified.
</p>
</td></tr>
<tr><td><code id="cellMap_+3A_ncolumnsinblock">ncolumnsinblock</code></td>
<td>

<p>Defaults to <code>NULL</code>, which asks not to block columns. The argument <code>ncolumnsinblock</code> is overruled by the argument <code>manualcolumnblocksizes</code> when the latter is specified.
</p>
</td></tr>
<tr><td><code id="cellMap_+3A_manualrowblocksizes">manualrowblocksizes</code></td>
<td>
<p>This allows the user to specify their own row blocks, unlike the argument nrowsinblock which makes all row blocks the same length. The argument takes the form <code>c(a,b,...)</code> where <code>a</code> is the length of the first block, <code>b</code> is the length of the second, and so on. The numbers <code>a,b,...</code> must be strictly positive integers, adding up to at most <code>nrow(R)</code>. They cannot all be 1, which would mean no blocking of rows. Defaults to <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="cellMap_+3A_manualcolumnblocksizes">manualcolumnblocksizes</code></td>
<td>
<p>Analogous to manualrowblocksizes but for columns. It is allowed for one of them to be <code>NULL</code> while the other is not.</p>
</td></tr>
<tr><td><code id="cellMap_+3A_rowblocklabels">rowblocklabels</code></td>
<td>
<p>This allows the user to specify labels for the row blocks, whether obtained from <code>nrowsinblock</code> or from <code>manualrowblocksizes</code>. Defaults to <code>NULL</code>, and then labels will be created automatically. Will throw an error if the number of row labels does not match the number of blocks.</p>
</td></tr>
<tr><td><code id="cellMap_+3A_columnblocklabels">columnblocklabels</code></td>
<td>
<p>Analogous to <code>rowblocklabels</code> but for columns. It is allowed for one of them to be <code>NULL</code> while the other is not.</p>
</td></tr>
<tr><td><code id="cellMap_+3A_sizemain">sizemain</code></td>
<td>

<p>Size of main title. Defaults to <code class="reqn">1.5</code>.
</p>
</td></tr>
<tr><td><code id="cellMap_+3A_sizetitles">sizetitles</code></td>
<td>

<p>Size of row title and column title. Defaults to <code class="reqn">1.2</code>.</p>
</td></tr>
<tr><td><code id="cellMap_+3A_sizerowlabels">sizerowlabels</code></td>
<td>

<p>Size of row labels. Defaults to <code class="reqn">1</code>.</p>
</td></tr>
<tr><td><code id="cellMap_+3A_sizecolumnlabels">sizecolumnlabels</code></td>
<td>

<p>Size of column labels. Defaults to <code class="reqn">1</code>.</p>
</td></tr> 
<tr><td><code id="cellMap_+3A_sizecellvalues">sizecellvalues</code></td>
<td>

<p>Size of values in the cells, when showcellvalues = TRUE. Defaults to <code class="reqn">1</code>.</p>
</td></tr>
<tr><td><code id="cellMap_+3A_adjustrowlabels">adjustrowlabels</code></td>
<td>

<p>Adjust row labels: 0=left, 0.5=centered, 1=right. Defaults to <code class="reqn">1</code>.
</p>
</td></tr>
<tr><td><code id="cellMap_+3A_adjustcolumnlabels">adjustcolumnlabels</code></td>
<td>

<p>Adjust column labels: 0=left, 0.5=centered, 1=right. Defaults to <code class="reqn">1</code>.
</p>
</td></tr>
<tr><td><code id="cellMap_+3A_columnangle">columnangle</code></td>
<td>

<p>Angle of the column labels. Defaults to <code class="reqn">90</code> so the column labels are vertical.
</p>
</td></tr>  
<tr><td><code id="cellMap_+3A_colcontrast">colContrast</code></td>
<td>

<p>Parameter regulating the contrast of colors, should be in <code class="reqn">[1,5]</code>. Defaults to <code class="reqn">1</code>.
</p>
</td></tr>
<tr><td><code id="cellMap_+3A_outlyinggrad">outlyingGrad</code></td>
<td>

<p>If <code>TRUE</code>, the color is gradually adjusted in function of the outlyingness. Defaults to <code>TRUE</code>.
</p>
</td></tr>
<tr><td><code id="cellMap_+3A_darkestcolor">darkestColor</code></td>
<td>

<p>Standardized residuals whose absolute value is bigger than this will get the darkest color.
</p>
</td></tr>
<tr><td><code id="cellMap_+3A_drawcircles">drawCircles</code></td>
<td>

<p>Whether or not to draw circles indicating outlyingness of rows. When both <code>indrows</code> and <code>outrows</code> are NULL, no circles are drawn.
</p>
</td></tr>
<tr><td><code id="cellMap_+3A_showvals">showVals</code></td>
<td>
<p>old name of argument <code>showcellvalues</code>. Only for backward compatibility.
</p>
</td></tr>
<tr><td><code id="cellMap_+3A_autolabel">autolabel</code></td>
<td>
<p>obsoleted by the current machanism for creating blocks of cells. Is only in the list for backward compatibility.
</p>
</td></tr>  
</table>


<h3>Author(s)</h3>

<p>Rousseeuw P.J., Van den Bossche W. 
</p>


<h3>References</h3>

<p>Rousseeuw, P.J., Van den Bossche W. (2018). Detecting Deviating Data Cells. <em>Technometrics</em>, <b>60</b>(2), 135-145. <a href="https://www.tandfonline.com/doi/full/10.1080/00401706.2017.1340909">(link to open access pdf)</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+DDC">DDC</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># For examples of the cellmap, we refer to the vignette:
## Not run: 
vignette("DDC_examples")

## End(Not run)
</code></pre>

<hr>
<h2 id='cellMCD'>
cellWise minimum covariance determinant estimator
</h2><span id='topic+cellMCD'></span>

<h3>Description</h3>

<p>The cellwise minimum covariance determinant estimator
computes cellwise robust estimates of the center and covariance matrix of a data set <code>X</code>. The algorithm guarantees a monotone decrease of an objective function, 
which is based on observed Gaussian log-likelihood. By default, it starts by calling <code><a href="#topic+checkDataSet">checkDataSet</a></code> to clean the data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cellMCD(X, alpha = 0.75, quant = 0.99,
        crit = 1e-4, noCits = 100, lmin = 1e-4,
        checkPars = list())
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cellMCD_+3A_x">X</code></td>
<td>
<p><code>X</code> is the input data, and must be an <code class="reqn">n</code> by <code class="reqn">d</code> matrix or a data frame.
</p>
</td></tr>
<tr><td><code id="cellMCD_+3A_alpha">alpha</code></td>
<td>
<p>In each column, at least <code class="reqn">n*</code><code>alpha</code> cells must remain unflagged. Defaults to <code class="reqn">75</code>%, should not be set (much) lower.
</p>
</td></tr>
<tr><td><code id="cellMCD_+3A_quant">quant</code></td>
<td>
<p>Determines the cutoff value to flag cells. Defaults to <code class="reqn">0.99</code>.
</p>
</td></tr>
<tr><td><code id="cellMCD_+3A_crit">crit</code></td>
<td>
<p>The iteration stops when successive covariance matrices (of the standardized data) differ by less than <code>crit</code>. Defaults to <code class="reqn">1e-4</code>.
</p>
</td></tr>
<tr><td><code id="cellMCD_+3A_nocits">noCits</code></td>
<td>
<p>The maximal number of C-steps used.</p>
</td></tr>
<tr><td><code id="cellMCD_+3A_lmin">lmin</code></td>
<td>
<p> a lower bound on the eigenvalues of the estimated covariance matrix on the standardized data. Defaults to <code class="reqn">1e-4</code>. Should not be smaller than <code class="reqn">1e-6</code>.</p>
</td></tr>
<tr><td><code id="cellMCD_+3A_checkpars">checkPars</code></td>
<td>
<p>Optional list of parameters used in the call to
<code><a href="#topic+checkDataSet">checkDataSet</a></code>. The options are:
</p>

<ul>
<li> <p><code>coreOnly</code> <br />
If <code>TRUE</code>, skip the execution of checkDataset. Defaults to <code>FALSE</code>.
</p>
</li>
<li> <p><code>numDiscrete</code><br />
A column that takes on numDiscrete or fewer values
will be considered discrete and not retained in the cleaned data.
Defaults to <code class="reqn">5</code>.
</p>
</li>
<li> <p><code>fracNA</code><br />
Only retain columns and rows with fewer NAs than this fraction.
Defaults to <code class="reqn">0.5</code>.
</p>
</li>
<li><p><code>precScale</code> <br />
Only consider columns whose scale is larger than precScale.
Here scale is measured by the median absolute deviation.
Defaults to <code class="reqn">1e-12</code>.
</p>
</li>
<li><p><code>silent</code><br />
Whether or not the function progress messages should be suppressed.
Defaults to <code>FALSE</code>.
</p>
</li></ul>

</td></tr>
</table>


<h3>Details</h3>

<p>The matrix <code>raw.S</code> in the output is the raw estimate of scatter produced by cellMCD. The final <code>S</code> is obtained from <code>raw.S</code> by rescaling such that its diagonal entries equal the squares of the univariate scales in <code>locsca$scale</code>. This reduces the bias at Gaussian data, which matters mainly for large sample sizes.</p>


<h3>Value</h3>

<p>A list with components: <br />
</p>

<ul>
<li> <p><code>mu</code> <br />
the cellMCD estimate of location.
</p>
</li>
<li> <p><code>S</code> <br />
the cellMCD estimate of scatter, after bias correction (see details).
</p>
</li>
<li> <p><code>W</code> <br />
the cellMCD estimate of <code>W</code>, a binary matrix indicating all outlying cells as zero.
</p>
</li>
<li> <p><code>preds</code> <br />
predictions (=conditional expectations) of the flagged cells, given the clean cells in the same row.
</p>
</li>
<li> <p><code>csds</code> <br />
conditional standard deviations of the flagged cells, given the clean cells in the same row.
</p>
</li>
<li> <p><code>Ximp</code> <br />
imputed data matrix.
</p>
</li>
<li> <p><code>Zres</code> <br />
matrix of cellwise standardized residuals.
</p>
</li>
<li> <p><code>raw.S</code> <br />
the raw cellMCD estimate of scatter, without bias correction.
</p>
</li>
<li> <p><code>locsca</code> <br />
list containing robust locations and scales used to standardize the data before running the algorithm. The results <code>m</code>, <code>S</code>, <code>preds</code>, <code>Ximp</code> are returned in their original location/scale. 
</p>
</li>
<li> <p><code>nosteps</code> <br />
number of steps the algorithm took to converge.
</p>
</li>
<li> <p><code>X</code> <br />
the data on which the algorithm was executed.
</p>
</li>
<li> <p><code>quant</code> <br />
the cutoff used to flag the cells.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>J. Raymaekers and P.J. Rousseeuw
</p>


<h3>References</h3>

<p>J. Raymaekers and P.J. Rousseeuw (2022). The cellwise MCD estimator, Journal of the American Statistical Association, to appear.
<a href="https://doi.org/10.1080/01621459.2023.2267777">doi:10.1080/01621459.2023.2267777</a>(link to open access pdf)
</p>


<h3>See Also</h3>

<p><code><a href="#topic+plot_cellMCD">plot_cellMCD</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>mu    &lt;- rep(0, 3)
Sigma &lt;- diag(3) * 0.5 + 0.5
set.seed(123)
X &lt;- MASS::mvrnorm(1000, mu, Sigma)
X[1:5, 1]  &lt;- X[1:5, 1] + 5
X[6:10, 2] &lt;- X[6:10, 2] - 10
X[12, 1:2] &lt;- c(-4,8)
colnames(X) &lt;- c("X1","X2","X3")
cellMCD.out &lt;- cellMCD(X)
cellMCD.out$mu
cov2cor(cellMCD.out$S)
cellMCD.out$W[1:15,]
cellMCD.out$Ximp[1:15,]
cellMap(cellMCD.out$Zres[1:15,])

# For more examples, we refer to the vignette:
## Not run: 
vignette("cellMCD_examples")

## End(Not run)
</code></pre>

<hr>
<h2 id='checkDataSet'>
Clean the dataset
</h2><span id='topic+checkDataSet'></span>

<h3>Description</h3>

<p>This function checks the dataset X, and sets aside certain
columns and rows that do not satisfy the conditions.
It is used by the <code><a href="#topic+DDC">DDC</a></code> and <code><a href="#topic+MacroPCA">MacroPCA</a></code> functions but can be used by itself, to clean a dataset for a different type of analysis.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>checkDataSet(X, fracNA = 0.5, numDiscrete = 3, precScale = 1e-12, silent = FALSE,
cleanNAfirst = "automatic")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="checkDataSet_+3A_x">X</code></td>
<td>
<p><code>X</code> is the input data, and must be an <code class="reqn">n</code> by <code class="reqn">d</code> matrix or data frame.
</p>
</td></tr>
<tr><td><code id="checkDataSet_+3A_fracna">fracNA</code></td>
<td>

<p>Only retain columns and rows with fewer NAs than this fraction.
Defaults to <code class="reqn">0.5</code>.
</p>
</td></tr>
<tr><td><code id="checkDataSet_+3A_numdiscrete">numDiscrete</code></td>
<td>

<p>A column that takes on numDiscrete or fewer values
will be considered discrete and not retained in the cleaned data.
Defaults to <code class="reqn">3</code>.
</p>
</td></tr>
<tr><td><code id="checkDataSet_+3A_precscale">precScale</code></td>
<td>

<p>Only consider columns whose scale is larger than precScale.
Here scale is measured by the median absolute deviation.
Defaults to <code class="reqn">1e-12</code>.
</p>
</td></tr>
<tr><td><code id="checkDataSet_+3A_silent">silent</code></td>
<td>

<p>Whether or not the function progress messages should be printed.
Defaults to <code>FALSE</code>.
</p>
</td></tr>
<tr><td><code id="checkDataSet_+3A_cleannafirst">cleanNAfirst</code></td>
<td>

<p>If <code>"columns"</code>, first columns then rows are checked for NAs.
If <code>"rows"</code>, first rows then columns are checked for NAs.
<code>"automatic"</code> checks columns first if <code class="reqn">d \geq 5n</code> and rows first otherwise.
Defaults to <code>"automatic"</code>.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with components: <br />
</p>

<ul>
<li><p><code>colInAnalysis</code> <br />
Column indices of the columns used in the analysis.

</p>
</li>
<li><p><code>rowInAnalysis</code> <br />
Row indices of the rows used in the analysis.
</p>
</li>
<li><p><code>namesNotNumeric</code> <br />
Names of the variables which are not numeric.       

</p>
</li>
<li><p><code>namesCaseNumber</code> <br />
The name of the variable(s) which contained the case numbers and was therefore removed.

</p>
</li>
<li><p><code>namesNAcol</code> <br />
Names of the columns left out due to too many <code>NA</code>'s.

</p>
</li>
<li><p><code>namesNArow</code> <br />
Names of the rows left out due to too many <code>NA</code>'s.

</p>
</li>
<li><p><code>namesDiscrete</code> <br />
Names of the discrete variables.           

</p>
</li>
<li><p><code>namesZeroScale</code> <br />
Names of the variables with zero scale.           

</p>
</li>
<li><p><code>remX</code> <br />
Remaining (cleaned) data after checkDataSet.           

</p>
</li></ul>



<h3>Author(s)</h3>

<p>Rousseeuw P.J., Van den Bossche W. 
</p>


<h3>References</h3>

<p>Rousseeuw, P.J., Van den Bossche W. (2018). Detecting Deviating Data Cells. <em>Technometrics</em>, <b>60</b>(2), 135-145. <a href="https://www.tandfonline.com/doi/full/10.1080/00401706.2017.1340909">(link to open access pdf)</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+DDC">DDC</a></code>, <code><a href="#topic+MacroPCA">MacroPCA</a></code>, <code><a href="#topic+transfo">transfo</a></code>, <code><a href="#topic+wrap">wrap</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(MASS) 
set.seed(12345) 
n &lt;- 100; d = 10
A &lt;- matrix(0.9, d, d); diag(A) = 1
x &lt;- mvrnorm(n, rep(0,d), A)
x[sample(1:(n * d), 100, FALSE)] &lt;- NA
x &lt;- cbind(1:n, x)
checkedx &lt;- checkDataSet(x)

# For more examples, we refer to the vignette:
## Not run: 
vignette("DDC_examples")

## End(Not run)
</code></pre>

<hr>
<h2 id='cwLocScat'>
Estimate location and scatter of data with cellwise weights
</h2><span id='topic+cwLocScat'></span>

<h3>Description</h3>

<p>Computes different estimators of multivariate location
and scatter for cellwise weighted data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cwLocScat(X, W, methods = "all", lmin = 1e-3,
                     crit = 1e-12, maxiter= 1000, 
                     initCwCov = FALSE, initEst = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cwLocScat_+3A_x">X</code></td>
<td>
<p>An <code class="reqn">n</code> by <code class="reqn">d</code> data matrix or data frame. Must be
given. <code>X</code> is allowed to contain <code>NA</code>'s.</p>
</td></tr>
<tr><td><code id="cwLocScat_+3A_w">W</code></td>
<td>
<p>An <code class="reqn">n</code> by <code class="reqn">d</code> matrix of nonnegative cellwise weights.
Must be given. <code>W</code> is not allowed to contain <code>NA</code>'s.</p>
</td></tr>
<tr><td><code id="cwLocScat_+3A_methods">methods</code></td>
<td>
<p>either <code>"all"</code> or <code>"explicit"</code>. If <code>"explicit"</code>
only the explicit estimates cwMean, cwCov
and sqrtCov are computed. If <code>"all"</code> (the
default) also the cellwise MLE is carried out,
yielding cwMLEmu and cwMLEsigma.</p>
</td></tr>
<tr><td><code id="cwLocScat_+3A_lmin">lmin</code></td>
<td>
<p>if not <code>NULL</code>, a lower bound on the eigenvalues
of the estimated covariance matrices on the
standardized data, to avoid singularity.</p>
</td></tr>
<tr><td><code id="cwLocScat_+3A_crit">crit</code></td>
<td>
<p>convergence criterion of successive mu
and Sigma estimates in the EM algorithm.</p>
</td></tr>
<tr><td><code id="cwLocScat_+3A_maxiter">maxiter</code></td>
<td>
<p>maximal number of iteration steps in EM.</p>
</td></tr>
<tr><td><code id="cwLocScat_+3A_initcwcov">initCwCov</code></td>
<td>
<p>if <code>TRUE</code>, uses the weighted mean and cwCov
as initial estimates for the weighted EM.</p>
</td></tr>
<tr><td><code id="cwLocScat_+3A_initest">initEst</code></td>
<td>
<p>if not <code>NULL</code>, a list with initial estimates <code>$mu</code>
of the mean, <code>$Sigma</code> of the covariance matrix,
for the weighted EM. Has no effect when
<code>initCwCov = TRUE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with components: <br />
</p>

<ul>
<li><p><code>cwMean</code><br /> the explicit cellwise weighted mean.
</p>
</li>
<li><p><code>cwCov</code><br /> explicit cellwise weighted covariance matrix.
Is asymptotically normal but not necessarily
PSD (unless a nonnegative <code>lmin</code> was specified).
</p>
</li>
<li><p><code>sqrtCov</code><br /> the cellwise weighted covariance matrix of Van
Aelst et al (2011). Also asymptotically normal
but not necessarily PSD (unless a nonnegative
<code>lmin</code> was specified).
</p>
</li>
<li><p><code>cwMLEmu</code><br /> the location estimate obtained by the cwMLE.
</p>
</li>
<li><p><code>cwMLEsigma</code><br /> the covariance matrix obtained by the cwMLE.
Is PSD when the EM algorithm converges.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>P.J. Rousseeuw
</p>


<h3>References</h3>

<p>P.J. Rousseeuw (2022). Analyzing cellwise weighted data, ArXiv:2209.12697.
<a href="https://arxiv.org/abs/2209.12697">(link to open access pdf)</a>
</p>


<h3>See Also</h3>

 
<p><code><a href="#topic+weightedEM">weightedEM</a></code>,
<code><a href="#topic+unpack">unpack</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("data_personality_traits")
X &lt;- data_personality_traits$X
W &lt;- data_personality_traits$W
fit &lt;- cwLocScat(X, W)
fit$cwMLEiter # number of iteration steps taken
round(fit$cwMLEmu, 2)
round(fit$cwMean, 2)
round(fit$cwMLEsigma, 2)
round(fit$cwCov, 2)


# For more examples, we refer to the vignette:
## Not run: 
vignette("cellwise_weights_examples")

## End(Not run)
</code></pre>

<hr>
<h2 id='data_brands'>
The brands dataset
</h2><span id='topic+data_brands'></span>

<h3>Description</h3>

<p>The brands data is a contingency table summarizing the 2014 Auto Brand Perception survey by Consumer Reports (USA), which is publicly available on https://boraberan.wordpress.com/2016/09/22/. The survey questioned 1578 participants on what they considered attributes of 39 different car brands.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("data_brands")</code></pre>


<h3>Format</h3>

<p>A matrix with 39 observations of 7 attributes. The attributes (columns) are Fuel Economy, Innovation, Performance, Quality, Safety, Style and Value.
</p>


<h3>Source</h3>

<p>https://boraberan.wordpress.com/2016/09/22/.
</p>


<h3>References</h3>

<p>Riani, M., Atkinson, A. C., Torti, F., Corbellini, A. (2022). Robust correspondence analysis. <em>Journal of the Royal Statistical Society Series C: Applied Statistics</em>, <b>71</b>(5), 1381&ndash;1401.
</p>
<p>Raymaekers and Rousseeuw (2022), Challenges of cellwise outliers.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(data_brands)
</code></pre>

<hr>
<h2 id='data_clothes'>
The clothes dataset
</h2><span id='topic+data_clothes'></span>

<h3>Description</h3>

<p>The clothes dataset contains a contingency table of trade flows from outside the European Union into each of its 28 member states. The columns in the contingency table in Riani et al. (2022) are five different price brackets, from lowest to highest.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("data_clothes")</code></pre>


<h3>Format</h3>

<p>A matrix with 28 observations of 5 price brackets.
</p>


<h3>Source</h3>

<p>Riani, M., Atkinson, A. C., Torti, F., Corbellini, A. (2022). Robust correspondence analysis. <em>Journal of the Royal Statistical Society Series C: Applied Statistics</em>, <b>71</b>(5), 1381&ndash;1401.
</p>


<h3>References</h3>

<p>Raymaekers and Rousseeuw (2022), Challenges of cellwise outliers.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(data_clothes)
</code></pre>

<hr>
<h2 id='data_dogWalker'>
Dog walker dataset
</h2><span id='topic+data_dogWalker'></span>

<h3>Description</h3>

<p>A dataset containing the image sequence of a video. The sequence consists of 
54 frames of 144 by 180 pixels pixels in Red/Geen/Blue (RGB) format.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("data_dogWalker")</code></pre>


<h3>Format</h3>

<p>An array of dimensions <code class="reqn">54 \times 144 \times 180 \times 3</code>.
</p>


<h3>Source</h3>

<p><a href="http://www.wisdom.weizmann.ac.il/~vision/SpaceTimeActions.html">http://www.wisdom.weizmann.ac.il/~vision/SpaceTimeActions.html</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("data_dogWalker")
# For more examples, we refer to the vignette:
## Not run: 
vignette("Wrap_examples")

## End(Not run)
</code></pre>

<hr>
<h2 id='data_dposs'>
DPOSS dataset
</h2><span id='topic+data_dposs'></span>

<h3>Description</h3>

<p>This is a random subset of 20'000 stars from the Digitized 
Palomar Sky Survey (DPOSS) described by Odewahn et al. (1998).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("data_dposs")</code></pre>


<h3>Format</h3>

<p>A matrix of dimensions <code class="reqn">20000 \times 21</code>.
</p>


<h3>References</h3>

<p>Odewahn, S., S. Djorgovski, R. Brunner, and R. Gal (1998). Data From the Digitized Palomar Sky Survey. Technical report, California Institute of Technology.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("data_dposs")
# For more examples, we refer to the vignette:
## Not run: 
vignette("MacroPCA_examples")

## End(Not run)
</code></pre>

<hr>
<h2 id='data_glass'>
The glass dataset
</h2><span id='topic+data_glass'></span>

<h3>Description</h3>

<p>A dataset containing spectra with <code class="reqn">d = 750</code> wavelengths collected on
<code class="reqn">n = 180</code> archeological glass samples.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("data_glass")</code></pre>


<h3>Format</h3>

<p>A data frame with 180 observations of 750 wavelengths.
</p>


<h3>Source</h3>

<p>Lemberge, P., De Raedt, I., Janssens, K.H., Wei, F., and Van Espen, P.J. (2000).
Quantitative Z-analysis of 16th-17th century archaeological glass vessels using
PLS regression of EPXMA and <code class="reqn">\mu</code>-XRF data. <em>Journal of Chemometrics</em>, <b>14</b>,
751&ndash;763.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("data_glass")
</code></pre>

<hr>
<h2 id='data_mortality'>
The mortality dataset
</h2><span id='topic+data_mortality'></span>

<h3>Description</h3>

<p>This dataset contains the mortality by age for males in France, from 1816 to 2013
as obtained from the Human Mortality Database.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("data_mortality")</code></pre>


<h3>Format</h3>

<p>A data frame with 198 calendar years (rows) and 91 age brackets (columns).
</p>


<h3>Source</h3>

<p>Human Mortality Database. University of California, Berkeley (USA), and
Max Planck Institute for Demographic Research (Germany). Available at
<a href="https://www.mortality.org">https://www.mortality.org</a> (data downloaded in November 2015).
</p>


<h3>References</h3>

<p>Hyndman, R.J., and Shang, H.L. (2010), Rainbow plots, bagplots, and boxplots for
functional data, <em>Journal of Computational and Graphical Statistics</em>, <b>19</b>, 29&ndash;45.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("data_mortality")
</code></pre>

<hr>
<h2 id='data_personality_traits'>
The personality traits data
</h2><span id='topic+data_personality_traits'></span>

<h3>Description</h3>

<p>This dataset describes personality traits of 10 persons. The variables are the 6 traits Anxiety, Agoraphobia, Arachnophobia, Adventurous, Extraversion, and Sociability. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("data_personality_traits")</code></pre>


<h3>Format</h3>

<p>The data contains a list with two elements:
</p>

<ul>
<li><p><code>X</code><br />
a <code class="reqn">10</code> by <code class="reqn">6</code> matrix of values describing <code class="reqn">6</code> personality traits for each of the <code class="reqn">10</code> participants. 

</p>
</li>
<li><p><code>W</code> <br />
a <code class="reqn">10</code> by <code class="reqn">6</code> matrix of cellwise weights. Each weight is the inverse of the length of the support of the membership function of the fuzzy number in the original data set.

</p>
</li></ul>



<h3>Source</h3>

<p>G. Hesamian, and Akbari, M. G. (2019), 
Principal component analysis based on intuitionistic fuzzy random variables, <em>Computational and Applied Mathematics</em>, <b>38</b>(158), 1&ndash;14.
</p>


<h3>References</h3>

<p>P.J. Rousseeuw (2022). Analyzing cellwise weighted data, ArXiv:2209.12697.
<a href="https://arxiv.org/abs/2209.12697">(link to open access pdf)</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(data_personality_traits)

# For the examples in Rousseeuw (2022), see:
## Not run: 
vignette("cellwise_weights_examples")

## End(Not run)
</code></pre>

<hr>
<h2 id='data_philips'>
The philips dataset
</h2><span id='topic+data_philips'></span>

<h3>Description</h3>

<p>A dataset containing measurements of <code class="reqn">d = 9</code> characteristics
of <code class="reqn">n = 677</code> diaphragm parts, used in the production of TV sets.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("data_philips")</code></pre>


<h3>Format</h3>

<p>A matrix with <code class="reqn">677</code> rows and <code class="reqn">9</code> columns.
</p>


<h3>Source</h3>

<p>The data were provided in 1997 by Gertjan Otten and permission to analyze them was given by Herman Veraa and Frans Van Dommelen at Philips Mecoma in The Netherlands.
</p>


<h3>References</h3>

<p>Rousseeuw, P.J., and Van Driessen, K. (1999). A fast algorithm  for the Minimum Covariance Determinant estimator. <em>Technometrics</em>, <b>41</b>, 212&ndash;223.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("data_philips")
</code></pre>

<hr>
<h2 id='data_VOC'>
VOC dataset
</h2><span id='topic+data_VOC'></span>

<h3>Description</h3>

<p>This dataset contains the data on volatile organic components (VOCs) in urine of children
between 3 and 10 years old. It is composed of pubicly available data from the National
Health and Nutrition Examination Survey (NHANES) and was analyzed in Raymaekers and Rousseeuw (2020). See below for details and references.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("data_VOC")</code></pre>


<h3>Format</h3>

<p>A matrix of dimensions <code class="reqn">512 \times 19</code>.
The first 16 variables are the VOC, the last 3 are: 
</p>

<ul>
<li> <p><code>SMD460</code>: number of smokers that live in the same home as the subject
</p>
</li>
<li> <p><code>SMD470</code>: number of people that smoke inside the home of the subject
</p>
</li>
<li> <p><code>RIDAGEYR</code>: age of the subject
</p>
</li></ul>

<p>Note that the original variable names are kept.
</p>


<h3>Details</h3>

<p>All of the data was collected from the NHANES website, and was part of the 
NHANES 2015-2016 survey. This was the most recent epoch with complete data at the time of extraction. Three datasets were matched in order to assemble this data:
</p>

<ul>
<li><p> UVOC_I:
contains the information on the Volative organic components in urine
</p>
</li>
<li><p> DEMO_I:
contains the demographical information such as age
</p>
</li>
<li><p> SMQFAM_I:
contains the data on the smoking habits of family members
</p>
</li></ul>

<p>The dataset was constructed as follows:
</p>

<ol>
<li><p> Select the relevant VOCs from the UVOC_I data (see column names) and transform by taking the logarithm
</p>
</li>
<li><p> Match the subjects in the UVOC_I data with their age in the DEMO_I data
</p>
</li>
<li><p> Select all subjects with age at most 10
</p>
</li>
<li><p> Match the data on smoking habits with the selected subjects.
</p>
</li></ol>



<h3>Source</h3>

<p><a href="https://wwwn.cdc.gov/nchs/nhanes/Search/DataPage.aspx?Component=Laboratory&amp;CycleBeginYear=2015">https://wwwn.cdc.gov/nchs/nhanes/Search/DataPage.aspx?Component=Laboratory&amp;CycleBeginYear=2015</a>
</p>
<p><a href="https://wwwn.cdc.gov/nchs/nhanes/search/datapage.aspx?Component=Demographics&amp;CycleBeginYear=2015">https://wwwn.cdc.gov/nchs/nhanes/search/datapage.aspx?Component=Demographics&amp;CycleBeginYear=2015</a>
</p>
<p><a href="https://wwwn.cdc.gov/nchs/nhanes/Search/DataPage.aspx?Component=Questionnaire&amp;CycleBeginYear=2015">https://wwwn.cdc.gov/nchs/nhanes/Search/DataPage.aspx?Component=Questionnaire&amp;CycleBeginYear=2015</a>
</p>


<h3>References</h3>

<p>J. Raymaekers and P.J. Rousseeuw (2020). Handling cellwise outliers by sparse regression and robust covariance. <em>Journal of Data Science, Statistics, and Visualisation</em>. <a href="https://doi.org/10.52933/jdssv.v1i3.18">doi:10.52933/jdssv.v1i3.18</a>(link to open access pdf)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("data_VOC")
# For an analysis of this data, we refer to the vignette:
## Not run: 
vignette("DI_examples")

## End(Not run)
</code></pre>

<hr>
<h2 id='DDC'>
Detect Deviating Cells
</h2><span id='topic+DDC'></span>

<h3>Description</h3>

<p>This function aims to detect cellwise outliers in the data. These are entries in the data matrix which are substantially higher or lower than what could be expected based on the other cells in its column as well as the other cells in its row, taking the relations between the columns into account. Note that this function first calls <code><a href="#topic+checkDataSet">checkDataSet</a></code> and analyzes the remaining cleaned data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DDC(X, DDCpars = list())
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="DDC_+3A_x">X</code></td>
<td>
<p><code>X</code> is the input data, and must be an <code class="reqn">n</code> by <code class="reqn">d</code> matrix or a data frame.
</p>
</td></tr>
<tr><td><code id="DDC_+3A_ddcpars">DDCpars</code></td>
<td>
<p> A list of available options:
</p>

<ul>
<li> <p><code>fracNA</code> <br />
Only consider columns and rows with fewer NAs (missing
values) than this fraction (percentage). Defaults to <code class="reqn">0.5</code>.
</p>
</li>
<li> <p><code>numDiscrete</code> <br />
A column that takes on <code>numDiscrete</code> or fewer values will
be considered discrete and not used in the analysis. Defaults to <code class="reqn">3</code>.
</p>
</li>
<li> <p><code>precScale</code> <br />
Only consider columns whose scale is larger than <code>precScale</code>.
Here scale is measured by the median absolute deviation. Defaults to <code class="reqn">1e-12</code>.
</p>
</li>
<li> <p><code>cleanNAfirst</code> <br />
If <code>"columns"</code>, first columns then rows are checked for NAs.
If <code>"rows"</code>, first rows then columns are checked for NAs.
<code>"automatic"</code> checks columns first if <code class="reqn">d \geq 5n</code> and rows first otherwise.
Defaults to <code>"automatic"</code>.

</p>
</li>
<li> <p><code>tolProb</code> <br />
Tolerance probability, with default <code class="reqn">0.99</code>, which
determines the cutoff values for flagging outliers in
several steps of the algorithm.
</p>
</li>
<li> <p><code>corrlim</code> <br />
When trying to estimate <code class="reqn">z_{ij}</code> from other variables <code class="reqn">h</code>, we 
will only use variables <code class="reqn">h</code> with <code class="reqn">|\rho_{j,h}| \ge corrlim</code>.
Variables <code class="reqn">j</code> without any correlated variables <code class="reqn">h</code> satisfying 
this are considered standalone, and treated on their own. Defaults to <code class="reqn">0.5</code>.
</p>
</li>
<li><p><code>combinRule</code> <br />
The operation to combine estimates of <code class="reqn">z_{ij}</code> coming from
other variables <code class="reqn">h</code>: can be <code>"mean"</code>, <code>"median"</code>,
<code>"wmean"</code> (weighted mean) or <code>"wmedian"</code> (weighted median).
Defaults to <code>wmean</code>.
</p>
</li>
<li> <p><code>returnBigXimp</code> <br />
If TRUE, the imputed data matrix <code>Ximp</code> in the output
will include the rows and columns that were not
part of the analysis (and can still contain NAs). Defaults to <code>FALSE</code>.
</p>
</li>
<li> <p><code>silent</code> <br />
If <code>TRUE</code>, statements tracking the algorithm's progress will not be printed. Defaults to <code>FALSE</code>.
</p>
</li>
<li> <p><code>nLocScale</code> <br />
When estimating location or scale from more than <code>nLocScale</code> data values, the computation is based on a random sample of size <code>nLocScale</code> to save time. When  <code>nLocScale = 0</code> all values are used. Defaults to 25000.
</p>
</li>
<li> <p><code>fastDDC</code> <br />
Whether to use the fastDDC option or not. The fastDDC algorithm uses approximations
to allow to deal with high dimensions. Defaults to <code>TRUE</code> for <code class="reqn">d &gt; 750</code> and <code>FALSE</code> otherwise.
</p>
</li>
<li> <p><code>standType</code> <br />
The location and scale estimators used for robust standardization. Should be one of <code>"1stepM"</code>, <code>"mcd"</code> or <code>"wrap"</code>. See <code><a href="#topic+estLocScale">estLocScale</a></code> for more info. Only used when <code>fastDDC = FALSE</code>. Defaults to <code>"1stepM"</code>.
</p>
</li>
<li> <p><code>corrType</code> <br />
The correlation estimator used to find the neighboring variables. Must be one of <code>"wrap"</code> (wrapping correlation), <code>"rank"</code> (Spearman correlation) or <code>"gkwls"</code> (Gnanadesikan-Kettenring correlation followed by weighting). Only used when <code>fastDDC</code> <code> = FALSE</code>. Defaults to <code>"gkwls"</code>.
</p>
</li>
<li> <p><code>transFun</code> <br />
The transformation function used to compute the robust correlations when <code>fastDDC = TRUE</code>. Can be <code>"wrap"</code> or <code>"rank"</code>. Defaults to <code>"wrap"</code>.
</p>
</li>
<li> <p><code>nbngbrs</code> <br />
When <code>fastDDC = TRUE</code>, each column is predicted from at most <code>nbngbrs</code> columns correlated to it.
Defaults to 100.
</p>
</li></ul>

</td></tr>
</table>


<h3>Value</h3>

<p> A list with components: <br />
</p>

<ul>
<li><p><code>DDCpars</code> <br />
The list of options used.

</p>
</li>
<li><p><code>colInAnalysis</code> <br />
The column indices of the columns used in the analysis.

</p>
</li>
<li><p><code>rowInAnalysis</code> <br />
The row indices of the rows used in the analysis.

</p>
</li>
<li><p><code>namesNotNumeric</code> <br />
The names of the variables which are not numeric.      

</p>
</li>
<li><p><code>namesCaseNumber</code> <br />
The name of the variable(s) which contained the case numbers and was therefore removed.     

</p>
</li>
<li><p><code>namesNAcol</code> <br />
Names of the columns left out due to too many <code>NA</code>'s.        

</p>
</li>
<li><p><code>namesNArow</code> <br />
Names of the rows left out due to too many <code>NA</code>'s.           

</p>
</li>
<li><p><code>namesDiscrete</code> <br />
Names of the discrete variables.           

</p>
</li>
<li><p><code>namesZeroScale</code> <br />
Names of the variables with zero scale.           

</p>
</li>
<li><p><code>remX</code> <br />
Cleaned data after <code>checkDataSet</code>.           

</p>
</li>
<li><p><code>locX</code> <br />
Estimated location of <code>X</code>.           

</p>
</li>
<li><p><code>scaleX</code> <br />
Estimated scales of <code>X</code>.           

</p>
</li>
<li><p><code>Z</code> <br />
Standardized <code>remX</code>.           

</p>
</li>
<li><p><code>nbngbrs</code> <br />
Number of neighbors used in estimation.          

</p>
</li>
<li><p><code>ngbrs</code> <br />
Indicates neighbors of each column, i.e. the columns most correlated with it.   

</p>
</li>
<li><p><code>robcors</code> <br />
Robust correlations.           

</p>
</li>
<li><p><code>robslopes</code> <br />
Robust slopes.          

</p>
</li>
<li><p><code>deshrinkage</code> <br />
The deshrinkage factor used for every connected (i.e. non-standalone) column of <code>X</code>.           
              
</p>
</li>
<li><p><code>Xest</code> <br />
Predicted <code>X</code>.           
       
</p>
</li>
<li><p><code>scalestres</code> <br />
Scale estimate of the residuals <code>X - Xest</code>.
       
</p>
</li>
<li><p><code>stdResid</code> <br />
Residuals of orginal <code>X</code> minus the estimated <code>Xest</code>, standardized by column.

</p>
</li>
<li><p><code>indcells</code> <br />
Indices of the cells which were flagged in the analysis.

</p>
</li>
<li><p><code>Ti</code> <br />
Outlyingness value of each row.         

</p>
</li>
<li><p><code>medTi</code> <br />
Median of the Ti values.      

</p>
</li>
<li><p><code>madTi</code> <br />
Mad of the Ti values.       

</p>
</li>
<li><p><code>indrows</code> <br />
Indices of the rows which were flagged in the analysis.

</p>
</li>
<li><p><code>indNAs</code> <br />
Indices of all NA cells.
 
</p>
</li>
<li><p><code>indall</code> <br />
Indices of all cells which were flagged in the analysis plus all cells in flagged rows plus the indices of the NA cells.
         
</p>
</li>
<li><p><code>Ximp</code> <br />
Imputed <code>X</code>.           

</p>
</li></ul>



<h3>Author(s)</h3>

<p>Raymaekers J., Rousseeuw P.J., Van den Bossche W. 
</p>


<h3>References</h3>

<p>Rousseeuw, P.J., Van den Bossche W. (2018). Detecting Deviating Data Cells. <em>Technometrics</em>, <b>60</b>(2), 135-145. <a href="https://www.tandfonline.com/doi/full/10.1080/00401706.2017.1340909">(link to open access pdf)</a>
</p>
<p>Raymaekers, J., Rousseeuw P.J. (2019). Fast robust correlation for high dimensional data. <em>Technometrics</em>, <b>63</b>(2), 184-198. <a href="https://www.tandfonline.com/doi/full/10.1080/00401706.2019.1677270">(link to open access pdf)</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+checkDataSet">checkDataSet</a></code>,<code><a href="#topic+cellMap">cellMap</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(MASS); set.seed(12345)
n &lt;- 50; d &lt;- 20
A &lt;- matrix(0.9, d, d); diag(A) = 1
x &lt;- mvrnorm(n, rep(0,d), A)
x[sample(1:(n * d), 50, FALSE)] &lt;- NA
x[sample(1:(n * d), 50, FALSE)] &lt;- 10
x[sample(1:(n * d), 50, FALSE)] &lt;- -10
x &lt;- cbind(1:n, x)
DDCx &lt;- DDC(x)
cellMap(DDCx$stdResid)

# For more examples, we refer to the vignette:
## Not run: 
vignette("DDC_examples")

## End(Not run)
</code></pre>

<hr>
<h2 id='DDCpredict'>
DDCpredict
</h2><span id='topic+DDCpredict'></span>

<h3>Description</h3>

<p>Based on a <code><a href="#topic+DDC">DDC</a></code> fit on an initial (training) data set <code>X</code>, this function
analyzes a new (test) data set <code>Xnew</code>.</p>


<h3>Usage</h3>

<pre><code class='language-R'>DDCpredict(Xnew, InitialDDC, DDCpars = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="DDCpredict_+3A_xnew">Xnew</code></td>
<td>
<p>The new data (test data), which must be a matrix or a data frame. It must always be provided. Its columns (variables) should correspond to those of <code>InitialDDC$remX</code>.</p>
</td></tr>
<tr><td><code id="DDCpredict_+3A_initialddc">InitialDDC</code></td>
<td>
<p>The output of the <code><a href="#topic+DDC">DDC</a></code> function on the initial (training)
dataset. Must be provided.</p>
</td></tr>
<tr><td><code id="DDCpredict_+3A_ddcpars">DDCpars</code></td>
<td>
<p>The input options to be used for the prediction.
By default the options of InitialDDC are used.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with components: <br />
</p>
<table>
<tr><td><code>DDCpars</code></td>
<td>
<p>the options used in the call, see <code><a href="#topic+DDC">DDC</a></code>.</p>
</td></tr>
<tr><td><code>locX</code></td>
<td>
<p>the locations of the columns, from <code>InitialDDC</code>.</p>
</td></tr>
<tr><td><code>scaleX</code></td>
<td>
<p>the scales of the columns, from <code>InitialDDC</code>.</p>
</td></tr>
<tr><td><code>Z</code></td>
<td>
<p><code>Xnew</code> standardized by <code>locX</code> and <code>scaleX</code>.</p>
</td></tr>
<tr><td><code>nbngbrs</code></td>
<td>
<p>predictions use a combination of <code>nbngbrs</code> columns.</p>
</td></tr>
<tr><td><code>ngbrs</code></td>
<td>
<p>for each column, the list of its neighbors, from <code>InitialDDC</code>.</p>
</td></tr>
<tr><td><code>robcors</code></td>
<td>
<p>for each column, the correlations with its neighbors, from <code>InitialDDC</code>.</p>
</td></tr>
<tr><td><code>robslopes</code></td>
<td>
<p>slopes to predict each column by its neighbors, from <code>InitialDDC</code>.</p>
</td></tr>
<tr><td><code>deshrinkage</code></td>
<td>
<p>for each connected column, its deshrinkage factor used in <code>InitialDDC</code>.</p>
</td></tr>
<tr><td><code>Xest</code></td>
<td>
<p>predicted values for every cell of <code>Xnew</code>.</p>
</td></tr>
<tr><td><code>scalestres</code></td>
<td>
<p>scale estimate of the residuals (<code>Xnew</code> - <code>Xest</code>), from <code>InitialDDC</code>.</p>
</td></tr>
<tr><td><code>stdResid</code></td>
<td>
<p>columnwise standardized residuals of <code>Xnew</code>.</p>
</td></tr>
<tr><td><code>indcells</code></td>
<td>
<p>positions of cellwise outliers in <code>Xnew</code>.</p>
</td></tr>
<tr><td><code>Ti</code></td>
<td>
<p>outlyingness of rows in <code>Xnew</code>.</p>
</td></tr>
<tr><td><code>medTi</code></td>
<td>
<p>median of the <code>Ti</code> in <code>InitialDDC</code>.</p>
</td></tr>
<tr><td><code>madTi</code></td>
<td>
<p>mad of the <code>Ti</code> in <code>InitialDDC</code>.</p>
</td></tr>
<tr><td><code>indrows</code></td>
<td>
<p>row numbers of the outlying rows in <code>Xnew</code>.</p>
</td></tr>
<tr><td><code>indNAs</code></td>
<td>
<p>positions of the <code>NA</code>'s in <code>Xnew</code>.</p>
</td></tr>
<tr><td><code>indall</code></td>
<td>
<p>positions of <code>NA</code>'s and outlying cells in <code>Xnew</code>.</p>
</td></tr>
<tr><td><code>Ximp</code></td>
<td>
<p><code>Xnew</code> where all cells in indall are imputed by their prediction.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Rousseeuw P.J., Van den Bossche W. 
</p>


<h3>References</h3>

<p>Hubert, M., Rousseeuw, P.J., Van den Bossche W. (2019). MacroPCA: An all-in-one PCA method allowing for missing values as well as cellwise and rowwise outliers. <em>Technometrics</em>, <b>61</b>(4), 459-473. <a href="https://www.tandfonline.com/doi/full/10.1080/00401706.2018.1562989">(link to open access pdf)</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+checkDataSet">checkDataSet</a></code>, <code><a href="#topic+cellMap">cellMap</a></code>,
<code><a href="#topic+DDC">DDC</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(MASS) 
set.seed(12345) 
n &lt;- 100; d &lt;- 10
A &lt;- matrix(0.9, d, d); diag(A) = 1
x &lt;- mvrnorm(n, rep(0,d), A)
x[sample(1:(n * d), 50, FALSE)] &lt;- NA
x[sample(1:(n * d), 50, FALSE)] &lt;- 10
x &lt;- cbind(1:n, x)
DDCx &lt;- DDC(x)
xnew &lt;- mvrnorm(50, rep(0,d), A)
xnew[sample(1:(50 * d), 50, FALSE)] &lt;- 10
predict.out &lt;- DDCpredict(xnew, DDCx)
cellMap(D = xnew, R = predict.out$stdResid,
columnlabels = 1:d, rowlabels = 1:50)

# For more examples, we refer to the vignette:
## Not run: 
vignette("DDC_examples")

## End(Not run)
</code></pre>

<hr>
<h2 id='DI'>
Detection-Imputation algorithm
</h2><span id='topic+DI'></span>

<h3>Description</h3>

<p>The Detection-Imputation algorithm computes cellwise robust estimates of the center and covariance matrix of a data set <code>X</code>. The algorithm alternates between the detection of cellwise outliers and their imputation combined with re-estimation of the center and covariance matrix. By default, it starts by calling <code><a href="#topic+checkDataSet">checkDataSet</a></code> to clean the data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DI(X, initEst = "DDCWcov", crit = 0.01, maxits = 10, quant = 0.99,
maxCol = 0.25, checkPars = list())
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="DI_+3A_x">X</code></td>
<td>
<p><code>X</code> is the input data, and must be an <code class="reqn">n</code> by <code class="reqn">d</code> matrix or a data frame.
</p>
</td></tr>
<tr><td><code id="DI_+3A_initest">initEst</code></td>
<td>
<p>An initial estimator for the center and covariance matrix. Should be one of <code>"DDCWcov"</code> or <code>"TSGS"</code>, where the latter refers to the function GSE::TSGS. The default option <code>"DDCWcov"</code> uses the proposal of Raymaekers and Rousseeuw (2020)  which is much faster for increasing dimension. 
</p>
</td></tr>
<tr><td><code id="DI_+3A_crit">crit</code></td>
<td>
<p>The algorithm converges when the subsequent estimates of the center and covariance matrix do not differ more than <code>crit</code> in squared Euclidean norm.
</p>
</td></tr>
<tr><td><code id="DI_+3A_maxits">maxits</code></td>
<td>
<p>Maximum number of DI-iterations.
</p>
</td></tr>
<tr><td><code id="DI_+3A_quant">quant</code></td>
<td>
<p>The cutoff used to detect cellwise outliers.
</p>
</td></tr>
<tr><td><code id="DI_+3A_maxcol">maxCol</code></td>
<td>
<p>The maximum number of cellwise outliers allowed in a column.
</p>
</td></tr>
<tr><td><code id="DI_+3A_checkpars">checkPars</code></td>
<td>
<p>Optional list of parameters used in the call to
<code><a href="#topic+checkDataSet">checkDataSet</a></code>. The options are:
</p>

<ul>
<li> <p><code>coreOnly</code> <br />
If <code>TRUE</code>, skip the execution of checkDataset. Defaults to <code>FALSE</code>
</p>
</li>
<li><p><code>numDiscrete</code><br />
A column that takes on numDiscrete or fewer values
will be considered discrete and not retained in the cleaned data.
Defaults to <code class="reqn">5</code>.
</p>
</li>
<li> <p><code>fracNA</code>
Only retain columns and rows with fewer NAs than this fraction.
Defaults to <code class="reqn">0.15</code>.
</p>
</li>
<li><p><code>precScale</code> <br />
Only consider columns whose scale is larger than precScale.
Here scale is measured by the median absolute deviation.
Defaults to <code class="reqn">1e-12</code>.
</p>
</li>
<li> <p><code>silent</code><br />
Whether or not the function progress messages should be suppressed.
Defaults to <code>FALSE</code>.
</p>
</li></ul>

</td></tr>
</table>


<h3>Value</h3>

<p>A list with components: <br />
</p>

<ul>
<li> <p><code>center</code> <br />
The final estimate of the center of the data.
</p>
</li>
<li> <p><code>cov</code> <br />
The final estimate of the covariance matrix.
</p>
</li>
<li> <p><code>nits</code> <br />
Number of DI-iterations executed to reach convergence.
</p>
</li>
<li> <p><code>Ximp</code> <br />
The imputed data.
</p>
</li>
<li> <p><code>indcells</code> <br />
Indices of the cells which were flagged in the analysis.
</p>
</li>
<li> <p><code>indNAs</code> <br />
Indices of the NAs in the data. 
</p>
</li>
<li> <p><code>Zres</code> <br />
Matrix with standardized cellwise residuals of the flagged cells. Contains zeroes in the unflagged cells.
</p>
</li>
<li> <p><code>Zres_denom</code> <br />
Denominator of the standardized cellwise residuals.
</p>
</li>
<li> <p><code>cellPaths</code> <br />
Matrix with the same dimensions as X, in which each row contains the path of least angle regression through the cells of that row, i.e. the order of the coordinates in the path (1=first, 2=second,...)
</p>
</li>
<li> <p><code>checkDataSet_out</code> <br />
Output of the call to <code><a href="#topic+checkDataSet">checkDataSet</a></code> which is used to clean the data.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>J. Raymaekers and P.J. Rousseeuw
</p>


<h3>References</h3>

<p>J. Raymaekers and P.J. Rousseeuw (2020). Handling cellwise outliers by sparse regression and robust covariance. <em>Journal of Data Science, Statistics, and Visualisation</em>. <a href="https://doi.org/10.52933/jdssv.v1i3.18">doi:10.52933/jdssv.v1i3.18</a>(link to open access pdf)
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cellHandler">cellHandler</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>mu &lt;- rep(0, 3)
Sigma &lt;- diag(3) * 0.1 + 0.9
X &lt;- MASS::mvrnorm(100, mu, Sigma)
DI.out &lt;- DI(X)
DI.out$cov
# For more examples, we refer to the vignette:
## Not run: 
vignette("DI_examples")

## End(Not run)
</code></pre>

<hr>
<h2 id='estLocScale'>
Estimate robust location and scale
</h2><span id='topic+estLocScale'></span>

<h3>Description</h3>

<p>Estimate a robust location estimate and scale estimate of every column in <code>X</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>estLocScale(X, type = "wrap", precScale = 1e-12,
center = TRUE, alpha = 0.5, nLocScale = 25000, silent = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="estLocScale_+3A_x">X</code></td>
<td>

<p>The input data. It must be an <code class="reqn">n</code> by <code class="reqn">d</code> matrix or a data frame.
</p>
</td></tr>
<tr><td><code id="estLocScale_+3A_type">type</code></td>
<td>

<p>The type of estimators used. One of:
</p>

<ul>
<li><p><code>"1stepM"</code>: <br /> The location is the 1-step M-estimator with the biweight psi function. The scale estimator is the 1-step M-estimator using a Huber rho function with <code class="reqn">b = 2.5</code>.

</p>
</li>
<li><p><code>"mcd"</code>: <br /> the location is the weighted univariate MCD estimator with cutoff <br />
<code class="reqn">\sqrt(qchisq(0.975,1))</code>. The scale is the corresponding weighted univariate MCD estimator, with a correction factor to make it approximately unbiased at gaussian data.
</p>
</li>
<li><p><code>"wrap"</code>: <br /> Starting from the initial estimates corresponding to option <code>"mcd"</code>, the location is the 1-step M-estimator with the wrapping psi function with <code class="reqn">b = 1.5</code> and <code class="reqn">c = 4</code>. The scale estimator is the same as in option <code>"mcd"</code>.

</p>
</li></ul>

<p>Defaults to &quot;wrap&quot;.
</p>
</td></tr>
<tr><td><code id="estLocScale_+3A_precscale">precScale</code></td>
<td>

<p>The precision scale used throughout the algorithm. Defaults to <code class="reqn">1e-12</code>.
</p>
</td></tr>
<tr><td><code id="estLocScale_+3A_center">center</code></td>
<td>

<p>Whether or not the data has to be centered before calculating the scale. Not in use for <code>type = "mcd"</code>. Defaults to <code>TRUE</code>.
</p>
</td></tr>
<tr><td><code id="estLocScale_+3A_alpha">alpha</code></td>
<td>

<p>The value of <code class="reqn">\alpha</code> in the univariate mcd, must be between 0.5 and 1. The subsetsize is <code class="reqn">h = \lceil \alpha n \rceil</code>. Only used for <code>type = "mcd"</code>. Defaults to <code class="reqn">\alpha = 0.5</code>.
</p>
</td></tr>
<tr><td><code id="estLocScale_+3A_nlocscale">nLocScale</code></td>
<td>

<p>If <code>nLocScale</code> <code class="reqn">&lt; n</code>, <code>nLocScale</code> observations are sampled to compute the location and scale. This speeds up the computation if <code class="reqn">n</code> is very large. When <code>nLocScale</code> <code class="reqn">= 0</code> all observations are used. Defaults to <code>nLocScale</code> <code class="reqn">= 25000</code>.
</p>
</td></tr>
<tr><td><code id="estLocScale_+3A_silent">silent</code></td>
<td>

<p>Whether or not a warning message should be printed when very small scales are found. Defauts to <code>FALSE</code>.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with components: <br />
</p>

<ul>
<li><p><code>loc</code> <br />
A vector with the estimated locations.

</p>
</li>
<li><p><code>scale</code> <br />
A vector with the estimated scales.

</p>
</li></ul>



<h3>Author(s)</h3>

<p>Raymaekers, J. and Rousseeuw P.J.
</p>


<h3>References</h3>

<p>Raymaekers, J., Rousseeuw P.J. (2019). Fast robust correlation for high dimensional data. <em>Technometrics</em>, <b>63</b>(2), 184-198. <a href="https://www.tandfonline.com/doi/full/10.1080/00401706.2019.1677270">(link to open access pdf)</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+wrap">wrap</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(MASS) 
set.seed(12345) 
n = 100; d = 10
X = mvrnorm(n, rep(0, 10), diag(10))
locScale = estLocScale(X)
# For more examples, we refer to the vignette:
## Not run: 
vignette("wrap_examples")

## End(Not run)
</code></pre>

<hr>
<h2 id='generateCorMat'>
Generates correlation matrices
</h2><span id='topic+generateCorMat'></span>

<h3>Description</h3>

<p>This function generates correlation matrices frequently used in simulation
studies.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>generateCorMat(d, corrType = "ALYZ", CN = 100, seed = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="generateCorMat_+3A_d">d</code></td>
<td>
<p>The dimension of the correlation matrix. The resulting matrix is <code class="reqn">d \times d</code>.
</p>
</td></tr>
<tr><td><code id="generateCorMat_+3A_corrtype">corrType</code></td>
<td>
<p>The type of correlation matrix to be generated. Should be one of:
</p>

<ul>
<li> <p><code>"ALYZ"</code>: Generates a correlation matrix as in Agostinelli et. al (2015).
</p>
</li>
<li> <p><code>"A09"</code>: Generates the correlation matrix defined by <code class="reqn">\rho_{jh} = (-0.9)^{|h-j|}</code>.
</p>
</li></ul>

<p>Note that the option <code>"ALYZ"</code> produces a randomly generated correlation matrix.
</p>
</td></tr>
<tr><td><code id="generateCorMat_+3A_cn">CN</code></td>
<td>
<p>Condition number of the correlation matrix. Only used for <code>corrType = "ALYZ"</code>.
</p>
</td></tr>
<tr><td><code id="generateCorMat_+3A_seed">seed</code></td>
<td>

<p>Seed used in <code>set.seed</code> before generating the correlation matrix. Only relevant for <code>corrType = "ALYZ"</code>.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code class="reqn">d \times d</code> correlation matrix of the given type.
</p>


<h3>Author(s)</h3>

<p>J. Raymaekers and P.J. Rousseeuw
</p>


<h3>References</h3>

<p>C. Agostinelli, Leung, A., Yohai, V. J., and Zamar, R. H. (2015).
Robust Estimation of Multivariate Location and Scatter in the Presence of Cellwise and Casewise Contamination. <em>Test</em>, 24, 441-461.
</p>
<p>Rousseeuw, P.J., Van den Bossche W. (2018). Detecting Deviating Data Cells. <em>Technometrics</em>, <b>60</b>(2), 135-145. <a href="https://www.tandfonline.com/doi/full/10.1080/00401706.2017.1340909">(link to open access pdf)</a>
</p>
<p>J. Raymaekers and P.J. Rousseeuw (2020). Handling cellwise outliers by sparse
regression and robust covariance. <em>Arxiv: 1912.12446</em>. <a href="https://arxiv.org/abs/1912.12446">(link to open access pdf)</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+generateData">generateData</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>d     &lt;- 5
Sigma &lt;- generateCorMat(d, corrType = "ALYZ", seed = 1)
Sigma
</code></pre>

<hr>
<h2 id='generateData'>
Generates artificial datasets with outliers
</h2><span id='topic+generateData'></span>

<h3>Description</h3>

<p>This function generates multivariate normal datasets with several possible types of outliers.
It is used in several simulation studies. For a detailed description, see the referenced papers.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>generateData(n, d, mu, Sigma, perout, gamma,
             outlierType = "casewise", seed = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="generateData_+3A_n">n</code></td>
<td>
<p>The number of observations
</p>
</td></tr>
<tr><td><code id="generateData_+3A_d">d</code></td>
<td>
<p>The dimension of the data.
</p>
</td></tr>
<tr><td><code id="generateData_+3A_mu">mu</code></td>
<td>
<p>The center of the clean data.
</p>
</td></tr>
<tr><td><code id="generateData_+3A_sigma">Sigma</code></td>
<td>
<p>The covariance matrix of the clean data. Could be obtained from <code><a href="#topic+generateCorMat">generateCorMat</a></code>.
</p>
</td></tr>
<tr><td><code id="generateData_+3A_outliertype">outlierType</code></td>
<td>
<p>The type of contamination to be generated. Should be one of:
</p>

<ul>
<li> <p><code>"casewise"</code>: Generates point contamination in the direction of the last eigenvector of <code>Sigma</code>.
</p>
</li>
<li> <p><code>"cellwisePlain"</code>: Generates cellwise contamination by randomly replacing a number of cells by <code>gamma</code>.
</p>
</li>
<li> <p><code>"cellwiseStructured"</code>: Generates cellwise contamination by first randomly sampling contaminated cells, after which for each row, they are replaced by a multiple of the smallest eigenvector of <code>Sigma</code> restricted to the dimensions of the contaminated cells.
</p>
</li>
<li> <p><code>"both"</code>: combines <code>"casewise"</code> and <code>"cellwiseStructured"</code>.
</p>
</li></ul>

</td></tr>
<tr><td><code id="generateData_+3A_perout">perout</code></td>
<td>
<p>The percentage of generated outliers. For <code>outlierType = "casewise"</code> this is a fraction of rows. For <code>outlierType = "cellWisePlain"</code> or <code>outlierType = "cellWiseStructured"</code>, a fraction of <code>perout</code> cells are replaced by contaminated cells.
For <code>outlierType = "both"</code>, a fraction of <code class="reqn">0.5*</code><code>perout</code> of rowwise
outliers is generated, after which the remaining data is contaminated with a fraction of 
<code class="reqn">0.5*</code><code>perout</code> outlying cells.
</p>
</td></tr>
<tr><td><code id="generateData_+3A_gamma">gamma</code></td>
<td>
<p>How far outliers are from the center of the distribution.
</p>
</td></tr>
<tr><td><code id="generateData_+3A_seed">seed</code></td>
<td>

<p>Seed used to generate the data.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with components:
</p>

<ul>
<li><p><code>X</code> <br />
The generated data matrix of size <code class="reqn">n \times d</code>.

</p>
</li>
<li><p><code>indcells</code> <br />
A vector with the indices of the contaminated cells.

</p>
</li>
<li><p><code>indrows</code> <br />
A vector with the indices of the rowwise outliers.

</p>
</li></ul>



<h3>Author(s)</h3>

<p>J. Raymaekers and P.J. Rousseeuw
</p>


<h3>References</h3>

<p>C. Agostinelli, Leung, A., Yohai, V. J., and Zamar, R. H. (2015).
Robust Estimation of Multivariate Location and Scatter in the Presence of Cellwise and Casewise Contamination. <em>Test</em>, 24, 441-461.
</p>
<p>Rousseeuw, P.J., Van den Bossche W. (2018). Detecting Deviating Data Cells. <em>Technometrics</em>, <b>60</b>(2), 135-145. <a href="https://www.tandfonline.com/doi/full/10.1080/00401706.2017.1340909">(link to open access pdf)</a>
</p>
<p>J. Raymaekers and P.J. Rousseeuw (2020). Handling cellwise outliers by sparse
regression and robust covariance. <em>Arxiv: 1912.12446</em>. <a href="https://arxiv.org/abs/1912.12446">(link to open access pdf)</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+generateCorMat">generateCorMat</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n     &lt;- 100
d     &lt;- 5
mu    &lt;- rep(0, d)
Sigma &lt;- diag(d)
perout &lt;- 0.1
gamma &lt;- 10
data &lt;- generateData(n, d, mu, Sigma, perout, gamma, outlierType = "cellwisePlain", seed  = 1)
pairs(data$X)
data$indcells
</code></pre>

<hr>
<h2 id='ICPCA'>
Iterative Classical PCA
</h2><span id='topic+ICPCA'></span>

<h3>Description</h3>

<p>This function carries out classical PCA when the data may contain
missing values, by an iterative algorithm. It is based on a Matlab function from the Missing Data Imputation Toolbox v1.0
by A. Folch-Fortuny, F. Arteaga and A. Ferrer.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ICPCA(X, k, scale = FALSE, maxiter = 20, tol = 0.005,
      tolProb = 0.99, distprob = 0.99) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ICPCA_+3A_x">X</code></td>
<td>
<p>the input data, which must be a matrix or a data frame.
It may contain NA's. It must always be provided.</p>
</td></tr>
<tr><td><code id="ICPCA_+3A_k">k</code></td>
<td>
<p>the desired number of principal components</p>
</td></tr>
<tr><td><code id="ICPCA_+3A_scale">scale</code></td>
<td>
<p>a value indicating whether and how the original
variables should be scaled. If <code>scale=FALSE</code> (default)
or <code>scale=NULL</code> no scaling is performed (and a vector
of 1s is returned in the <code>$scaleX</code> slot).
If <code>scale=TRUE</code> the variables are scaled to have a
standard deviation of 1. Alternatively scale can be a function like mad,
or a vector of length equal to the number of columns
of x. The resulting scale estimates are returned in the
<code>$scaleX</code> slot of the output.</p>
</td></tr>
<tr><td><code id="ICPCA_+3A_maxiter">maxiter</code></td>
<td>
<p>maximum number of iterations. Default is 20.</p>
</td></tr>
<tr><td><code id="ICPCA_+3A_tol">tol</code></td>
<td>
<p>tolerance for iterations. Default is 0.005.</p>
</td></tr>
<tr><td><code id="ICPCA_+3A_tolprob">tolProb</code></td>
<td>
<p>tolerance probability for residuals. Defaults to 0.99.</p>
</td></tr>
<tr><td><code id="ICPCA_+3A_distprob">distprob</code></td>
<td>
<p>probability determining the cutoff values for
orthogonal and score distances. Default is 0.99.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with components: <br />
</p>
<table>
<tr><td><code>scaleX</code></td>
<td>
<p>the scales of the columns of X.</p>
</td></tr>
<tr><td><code>k</code></td>
<td>
<p>the number of principal components.</p>
</td></tr>
<tr><td><code>loadings</code></td>
<td>
<p>the columns are the k loading vectors.</p>
</td></tr>
<tr><td><code>eigenvalues</code></td>
<td>
<p>the k eigenvalues.</p>
</td></tr>
<tr><td><code>center</code></td>
<td>
<p>vector with the fitted center.</p>
</td></tr>
<tr><td><code>covmatrix</code></td>
<td>
<p>estimated covariance matrix.</p>
</td></tr>
<tr><td><code>It</code></td>
<td>
<p>number of iteration steps.</p>
</td></tr>
<tr><td><code>diff</code></td>
<td>
<p>convergence criterion.</p>
</td></tr>
<tr><td><code>X.NAimp</code></td>
<td>
<p>data with all NA's imputed.</p>
</td></tr>
<tr><td><code>scores</code></td>
<td>
<p>scores of X.NAimp.</p>
</td></tr>
<tr><td><code>OD</code></td>
<td>
<p>orthogonal distances of the rows of X.NAimp.</p>
</td></tr>
<tr><td><code>cutoffOD</code></td>
<td>
<p>cutoff value for the OD.</p>
</td></tr>
<tr><td><code>SD</code></td>
<td>
<p>score distances of the rows of X.NAimp.</p>
</td></tr>
<tr><td><code>cutoffSD</code></td>
<td>
<p>cutoff value for the SD.</p>
</td></tr>
<tr><td><code>highOD</code></td>
<td>
<p>row numbers of cases whose <code>OD</code> is above <code>cutoffOD</code>.</p>
</td></tr>
<tr><td><code>highSD</code></td>
<td>
<p>row numbers of cases whose <code>SD</code> is above <code>cutoffSD</code>.</p>
</td></tr>
<tr><td><code>residScale</code></td>
<td>
<p>scale of the residuals.</p>
</td></tr>
<tr><td><code>stdResid</code></td>
<td>
<p>standardized residuals. Note that these are NA
for all missing values of <code>X</code>.</p>
</td></tr>
<tr><td><code>indcells</code></td>
<td>
<p>indices of cellwise outliers.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Wannes Van Den Bossche
</p>


<h3>References</h3>

<p>Folch-Fortuny, A., Arteaga, F., Ferrer, A. (2016). Missing Data Imputation Toolbox for MATLAB.
<em>Chemometrics and Intelligent Laboratory Systems</em>, <b>154</b>, 93-100.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(MASS) 
set.seed(12345) 
n &lt;- 100; d &lt;- 10
A &lt;- diag(d) * 0.1 + 0.9
x &lt;- mvrnorm(n, rep(0,d), A)
x[sample(1:(n * d), 100, FALSE)] &lt;- NA
ICPCA.out &lt;- ICPCA(x, k = 2)
plot(ICPCA.out$scores)
</code></pre>

<hr>
<h2 id='MacroPCA'>
MacroPCA
</h2><span id='topic+MacroPCA'></span>

<h3>Description</h3>

<p>This function performs the MacroPCA algorithm, which can deal with Missing values and Cellwise
and Rowwise Outliers. Note that this function first calls  <code><a href="#topic+checkDataSet">checkDataSet</a></code> and analyzes the remaining cleaned data.</p>


<h3>Usage</h3>

<pre><code class='language-R'>MacroPCA(X, k = 0, MacroPCApars = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MacroPCA_+3A_x">X</code></td>
<td>
<p><code>X</code> is the input data, and must be an <code class="reqn">n</code> by <code class="reqn">d</code> matrix or a data frame. It must always be provided.</p>
</td></tr>
<tr><td><code id="MacroPCA_+3A_k">k</code></td>
<td>
<p><code>k</code> is the desired number of principal components.
If <code>k = 0</code> or <code>k = NULL</code>, the algorithm will compute the percentage
of explained variability for <code>k</code> upto <code>kmax</code> and show a scree plot,
and suggest to choose a value of k such that the cumulative percentage of
explained variability is at least 80%.</p>
</td></tr>
<tr><td><code id="MacroPCA_+3A_macropcapars">MacroPCApars</code></td>
<td>
<p>A list of available options detailed below. If MacroPCApars = NULL the defaults below are used.
</p>

<ul>
<li><p><code>DDCpars</code> <br /> A list with parameters for the first step of the MacroPCA
algorithm (for the complete list see the function
<code><a href="#topic+DDC">DDC</a></code>). Default is <code>NULL</code>.
</p>
</li>
<li><p><code>kmax</code> <br /> The maximal number of principal components to compute. Default
is <code>kmax = 10</code>. If <code>k</code> is provided kmax does not need to be specified,
unless <code>k</code> is larger than 10 in which case you need to set <code>kmax</code>
high enough.
</p>
</li>
<li><p><code>alpha</code> <br /> This is the coverage, i.e. the fraction of rows the algorithm
should give full weight. Alpha should be between 0.50 and 1, the default is
0.50.
</p>
</li>
<li><p><code>scale</code> <br /> A value indicating whether and how the original variables should
be scaled. If <code>scale = FALSE</code> or <code>scale = NULL</code> no scaling is
performed (and a vector of 1s is returned in the <code>$scaleX slot</code>).
If <code>scale = TRUE</code> (default) the data are scaled by a 1-step M-estimator of scale with the Tukey biweight weight function to have a robust scale of 1.
Alternatively scale can be a vector of length
equal to the number of columns of <code>x</code>. The resulting scale estimates are
returned in the <code>$scaleX</code> slot of the MacroPCA output.
</p>
</li>
<li><p><code>maxdir</code> <br /> The maximal number of random directions to use for computing the
outlyingness of the data points. Default is <code>maxdir = 250</code>. If the number
<code class="reqn">n</code> of observations is small all <code class="reqn">n * (n - 1) / 2</code> pairs of
observations are used.
</p>
</li>
<li><p><code>distprob</code> <br /> The quantile determining the cutoff values
for orthogonal and score distances. Default is 0.99.
</p>
</li>
<li><p><code>silent</code> <br />
If TRUE, statements tracking the algorithm's progress will not be printed. Defaults to <code>FALSE</code>.
</p>
</li>
<li><p><code>maxiter</code> <br /> Maximum number of iterations. Default is 20.
</p>
</li>
<li><p><code>tol</code> <br /> Tolerance for iterations. Default is 0.005.
</p>
</li>
<li><p><code>center</code><br />
if <code>NULL</code>, MacroPCA will compute the center. If a vector with <code class="reqn">d</code> components, this center will be used.
</p>
</li>
<li><p><code>bigOutput</code> <br /> whether to compute and return NAimp, Cellimp and Fullimp. Defaults to <code>TRUE</code>.
</p>
</li></ul>

</td></tr>
</table>


<h3>Value</h3>

<p>A list with components: <br />
</p>
<table>
<tr><td><code>MacroPCApars</code></td>
<td>
<p>the options used in the call.</p>
</td></tr>
<tr><td><code>remX</code></td>
<td>
<p>Cleaned data after <code>checkDataSet</code>.</p>
</td></tr>
<tr><td><code>DDC</code></td>
<td>
<p>results of the first step of MacroPCA. These are needed to run
MacroPCApredict on new data.</p>
</td></tr>
<tr><td><code>scaleX</code></td>
<td>
<p>the scales of the columns of <code>X</code>. When <code>scale = FALSE</code> these are all <code class="reqn">1</code>.</p>
</td></tr>
<tr><td><code>k</code></td>
<td>
<p>the number of principal components.</p>
</td></tr>
<tr><td><code>loadings</code></td>
<td>
<p>the columns are the <code>k</code> loading vectors.</p>
</td></tr>
<tr><td><code>eigenvalues</code></td>
<td>
<p>the <code>k</code> eigenvalues.</p>
</td></tr>
<tr><td><code>center</code></td>
<td>
<p>vector with the center.</p>
</td></tr>
<tr><td><code>alpha</code></td>
<td>
<p><code>alpha</code> from the input.</p>
</td></tr>
<tr><td><code>h</code></td>
<td>
<p><code>h</code> (computed from <code>alpha</code>).</p>
</td></tr>
<tr><td><code>It</code></td>
<td>
<p>number of iteration steps.</p>
</td></tr>
<tr><td><code>diff</code></td>
<td>
<p>convergence criterion.</p>
</td></tr>
<tr><td><code>X.NAimp</code></td>
<td>
<p>data with all <code>NA</code>'s imputed by <code>MacroPCA</code>.</p>
</td></tr>
<tr><td><code>scores</code></td>
<td>
<p>scores of <code>X.NAimp</code>.</p>
</td></tr>
<tr><td><code>OD</code></td>
<td>
<p>orthogonal distances of the rows of <code>X.NAimp</code>.</p>
</td></tr>
<tr><td><code>cutoffOD</code></td>
<td>
<p>cutoff value for the OD.</p>
</td></tr>
<tr><td><code>SD</code></td>
<td>
<p>score distances of the rows of <code>X.NAimp</code>.</p>
</td></tr>
<tr><td><code>cutoffSD</code></td>
<td>
<p>cutoff value for the SD.</p>
</td></tr>
<tr><td><code>highOD</code></td>
<td>
<p>row numbers of cases whose <code>OD</code> is above <code>cutoffOD</code>.</p>
</td></tr>
<tr><td><code>highSD</code></td>
<td>
<p>row numbers of cases whose <code>SD</code> is above <code>cutoffSD</code>.</p>
</td></tr>  
<tr><td><code>residScale</code></td>
<td>
<p>scale of the residuals.</p>
</td></tr>
<tr><td><code>stdResid</code></td>
<td>
<p>standardized residuals. Note that these are <code>NA</code>
for all missing values of <code>X</code>.</p>
</td></tr>
<tr><td><code>indcells</code></td>
<td>
<p>indices of cellwise outliers.</p>
</td></tr>
<tr><td><code>NAimp</code></td>
<td>
<p>various results for the NA-imputed data.</p>
</td></tr>
<tr><td><code>Cellimp</code></td>
<td>
<p>various results for the cell-imputed data.</p>
</td></tr>
<tr><td><code>Fullimp</code></td>
<td>
<p>various result for the fully imputed data.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Rousseeuw P.J., Van den Bossche W. 
</p>


<h3>References</h3>

<p>Hubert, M., Rousseeuw, P.J., Van den Bossche W. (2019). MacroPCA: An all-in-one PCA method allowing for missing values as well as cellwise and rowwise outliers. <em>Technometrics</em>, <b>61</b>(4), 459-473. <a href="https://www.tandfonline.com/doi/full/10.1080/00401706.2018.1562989">(link to open access pdf)</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+checkDataSet">checkDataSet</a></code>, <code><a href="#topic+cellMap">cellMap</a></code>,
<code><a href="#topic+DDC">DDC</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(MASS) 
set.seed(12345) 
n &lt;- 50; d &lt;- 10
A &lt;- matrix(0.9, d, d); diag(A) = 1
x &lt;- mvrnorm(n, rep(0,d), A)
x[sample(1:(n * d), 50, FALSE)] &lt;- NA
x[sample(1:(n * d), 50, FALSE)] &lt;- 10
MacroPCA.out &lt;- MacroPCA(x, 2)
cellMap(MacroPCA.out$stdResid)

# For more examples, we refer to the vignette:
## Not run: 
vignette("MacroPCA_examples")

## End(Not run)
</code></pre>

<hr>
<h2 id='MacroPCApredict'>
MacroPCApredict
</h2><span id='topic+MacroPCApredict'></span>

<h3>Description</h3>

<p>Based on a <code><a href="#topic+MacroPCA">MacroPCA</a></code> fit of an initial (training) data set <code>X</code>, this function analyzes a
new (test) data set <code>Xnew</code>.</p>


<h3>Usage</h3>

<pre><code class='language-R'>MacroPCApredict(Xnew, InitialMacroPCA, MacroPCApars = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MacroPCApredict_+3A_xnew">Xnew</code></td>
<td>
<p>The new data (test data), which must be a matrix or a data frame.
It must always be provided. Its columns (variables) should correspond to those of <code>InitialMacroPCA$remX</code>.</p>
</td></tr>
<tr><td><code id="MacroPCApredict_+3A_initialmacropca">InitialMacroPCA</code></td>
<td>
<p>The output of the MacroPCA function on the initial
(training) dataset. Must be provided.</p>
</td></tr>
<tr><td><code id="MacroPCApredict_+3A_macropcapars">MacroPCApars</code></td>
<td>
<p>The input options to be used for the prediction.
By default the options of InitialMacroPCA are used. For the complete list of
options see the function <code><a href="#topic+MacroPCA">MacroPCA</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with components: <br />
</p>
<table>
<tr><td><code>MacroPCApars</code></td>
<td>
<p>the options used in the call.</p>
</td></tr>
<tr><td><code>DDC</code></td>
<td>
<p>result of DDCpredict which is the first step of MacroPCApredict.
See the function <code><a href="#topic+DDCpredict">DDCpredict</a></code>.</p>
</td></tr>
<tr><td><code>scaleX</code></td>
<td>
<p>the scales of the columns of <code>X</code>.</p>
</td></tr>
<tr><td><code>k</code></td>
<td>
<p>the number of principal components.</p>
</td></tr>
<tr><td><code>loadings</code></td>
<td>
<p>the columns are the <code>k</code> loading vectors.</p>
</td></tr>
<tr><td><code>eigenvalues</code></td>
<td>
<p>the <code>k</code> eigenvalues.</p>
</td></tr>
<tr><td><code>center</code></td>
<td>
<p>vector with the fitted center.</p>
</td></tr>
<tr><td><code>It</code></td>
<td>
<p>number of iteration steps.</p>
</td></tr>
<tr><td><code>diff</code></td>
<td>
<p>convergence criterion.</p>
</td></tr>
<tr><td><code>Xnew.NAimp</code></td>
<td>
<p><code>Xnew</code> with all <code>NA</code>'s imputed by <code>MacroPCA</code>.</p>
</td></tr>
<tr><td><code>scores</code></td>
<td>
<p>scores of <code>Xnew.NAimp</code>.</p>
</td></tr>
<tr><td><code>OD</code></td>
<td>
<p>orthogonal distances of the rows of <code>Xnew.NAimp</code>.</p>
</td></tr>
<tr><td><code>cutoffOD</code></td>
<td>
<p>cutoff value for the OD.</p>
</td></tr>
<tr><td><code>SD</code></td>
<td>
<p>score distances of the rows of <code>Xnew.NAimp</code>.</p>
</td></tr>
<tr><td><code>cutoffSD</code></td>
<td>
<p>cutoff value for the SD.</p>
</td></tr>
<tr><td><code>highOD</code></td>
<td>
<p>row numbers of cases in <code>Xnew.NAimp</code> whose <code>OD</code> is above <code>cutoffOD</code>.</p>
</td></tr>
<tr><td><code>highSD</code></td>
<td>
<p>row numbers of cases in <code>Xnew.NAimp</code> whose <code>SD</code> is above <code>cutoffSD</code>.</p>
</td></tr>
<tr><td><code>residScale</code></td>
<td>
<p>scale of the residuals.</p>
</td></tr>
<tr><td><code>stdResid</code></td>
<td>
<p>standardized residuals. Note that these are <code>NA</code> for all missing values of <code>Xnew</code>.</p>
</td></tr>
<tr><td><code>indcells</code></td>
<td>
<p>indices of cellwise outliers.</p>
</td></tr>
<tr><td><code>NAimp</code></td>
<td>
<p>various results for the NA-imputed Xnew.</p>
</td></tr>
<tr><td><code>Cellimp</code></td>
<td>
<p>various results for the cell-imputed Xnew.</p>
</td></tr>
<tr><td><code>Fullimp</code></td>
<td>
<p>various result for the fully imputed Xnew.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Rousseeuw P.J., Van den Bossche W. 
</p>


<h3>References</h3>

<p>Hubert, M., Rousseeuw, P.J., Van den Bossche W. (2019). MacroPCA: An all-in-one PCA method allowing for missing values as well as cellwise and rowwise outliers. <em>Technometrics</em>, <b>61</b>(4), 459-473. <a href="https://www.tandfonline.com/doi/full/10.1080/00401706.2018.1562989">(link to open access pdf)</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+checkDataSet">checkDataSet</a></code>, <code><a href="#topic+cellMap">cellMap</a></code>,
<code><a href="#topic+DDC">DDC</a></code>, <code><a href="#topic+DDCpredict">DDCpredict</a></code>,
<code><a href="#topic+MacroPCA">MacroPCA</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(MASS) 
set.seed(12345) 
n &lt;- 50; d &lt;- 10
A &lt;- matrix(0.9, d, d); diag(A) = 1
x &lt;- mvrnorm(n, rep(0,d), A)
x[sample(1:(n * d), 50, FALSE)] &lt;- NA
x[sample(1:(n * d), 50, FALSE)] &lt;- 10
MacroPCA.out &lt;- MacroPCA(x, 2)
xnew &lt;- mvrnorm(25, rep(0,d), A)
xnew[sample(1:(25 * d), 12, FALSE)] &lt;- 10
predict.out &lt;- MacroPCApredict(xnew, MacroPCA.out)
cellMap(predict.out$stdResid)

# For more examples, we refer to the vignette:
## Not run: 
vignette("MacroPCA_examples")

## End(Not run)
</code></pre>

<hr>
<h2 id='outlierMap'>
Plot the outlier map.
</h2><span id='topic+outlierMap'></span>

<h3>Description</h3>

<p>The outlier map is a diagnostic plot for the output of <code><a href="#topic+MacroPCA">MacroPCA</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>outlierMap(res,title="Robust PCA",col="black", pch=16,labelOut=TRUE,id=3,
xlim = NULL, ylim = NULL, cex = 1, cex.main=1.2, cex.lab=NULL, cex.axis=NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="outlierMap_+3A_res">res</code></td>
<td>

<p>A list containing the orthogonal distances (<code>OD</code>), the score distances (<code>SD</code>) and their respective cut-offs (<code>cutoffOD</code> and <code>cutoffSD</code>). Can be the output of <code><a href="#topic+MacroPCA">MacroPCA</a></code>,
rospca::robpca, rospca::rospca.
</p>
</td></tr>
<tr><td><code id="outlierMap_+3A_title">title</code></td>
<td>

<p>Title of the plot, default is &quot;Robust PCA&quot;.
</p>
</td></tr>
<tr><td><code id="outlierMap_+3A_col">col</code></td>
<td>

<p>Colour of the points in the plot, this can be a single colour for all points or a vector or list specifying the colour for each point. The default is &quot;black&quot;.
</p>
</td></tr>
<tr><td><code id="outlierMap_+3A_pch">pch</code></td>
<td>

<p>Plotting characters or symbol used in the plot, see points for more details. The default is 16 which corresponds to filled circles.
</p>
</td></tr>
<tr><td><code id="outlierMap_+3A_labelout">labelOut</code></td>
<td>

<p>Logical indicating if outliers should be labelled on the plot, default is <code>TRUE</code>.
</p>
</td></tr>
<tr><td><code id="outlierMap_+3A_id">id</code></td>
<td>

<p>Number of OD outliers and number of SD outliers to label on the plot, default is 3.
</p>
</td></tr>
<tr><td><code id="outlierMap_+3A_xlim">xlim</code></td>
<td>

<p>Optional argument to set the limits of the <code>x</code>-axis.
</p>
</td></tr>
<tr><td><code id="outlierMap_+3A_ylim">ylim</code></td>
<td>

<p>Optional argument to set the limits of the <code>y</code>-axis.
</p>
</td></tr>
<tr><td><code id="outlierMap_+3A_cex">cex</code></td>
<td>

<p>Optional argument determining the size of the plotted points. See <code><a href="graphics.html#topic+plot.default">plot.default</a></code> for details.
</p>
</td></tr>
<tr><td><code id="outlierMap_+3A_cex.main">cex.main</code></td>
<td>

<p>Optional argument determining the size of the main title. See <code><a href="graphics.html#topic+plot.default">plot.default</a></code> for details.
</p>
</td></tr>
<tr><td><code id="outlierMap_+3A_cex.lab">cex.lab</code></td>
<td>

<p>Optional argument determining the size of the labels. See <code><a href="graphics.html#topic+plot.default">plot.default</a></code> for details.
</p>
</td></tr>
<tr><td><code id="outlierMap_+3A_cex.axis">cex.axis</code></td>
<td>

<p>Optional argument determining the size of the axes. See <code><a href="graphics.html#topic+plot.default">plot.default</a></code> for details.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The outlier map contains the score distances on the x-axis and the orthogonal distances on the y-axis. To detect outliers, cut-offs for both distances are shown, see Hubert et al. (2005).
</p>


<h3>Author(s)</h3>

<p>P.J. Rousseeuw
</p>


<h3>References</h3>

<p>Hubert, M., Rousseeuw, P. J., and Vanden Branden, K. (2005). ROBPCA: A New Approach to Robust Principal Component Analysis. <em>Technometrics</em>, <b>47</b>, 64-79.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+MacroPCA">MacroPCA</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># empty for now
</code></pre>

<hr>
<h2 id='plot_cellMCD'>
Draw plots based on the cellwise minimum covariance determinant estimator cellMCD
</h2><span id='topic+plot_cellMCD'></span>

<h3>Description</h3>

<p>Function for making plots based on the output of <code><a href="#topic+cellMCD">cellMCD</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot_cellMCD(cellout, type = "Zres/X", whichvar = NULL,
             horizvar = NULL, vertivar = NULL,  
             hband = NULL, vband = NULL, drawellipse = T,
             opacity = 0.5, identify = FALSE, 
             ids = NULL, labelpoints = T, vlines = FALSE,
             clines = TRUE, main = NULL,
             xlab = NULL, ylab = NULL, xlim = NULL,
             ylim = NULL, cex = 1, cex.main = 1.2, 
             cex.txt = 0.8, cex.lab = 1, line = 2.0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot_cellMCD_+3A_cellout">cellout</code></td>
<td>
<p>output of function <code><a href="#topic+cellMCD">cellMCD</a></code></p>
</td></tr>
<tr><td><code id="plot_cellMCD_+3A_type">type</code></td>
<td>
<p>type of diagnostic plot. Should be one of <code>"index"</code>, <code>"Zres/X"</code>, <code>"Zres/pred"</code>, <code>"X/pred"</code>, or <code>"bivariate"</code>.</p>
</td></tr>
<tr><td><code id="plot_cellMCD_+3A_whichvar">whichvar</code></td>
<td>
<p> number or name of the variable to be plotted. Not applicable when <code>type = "bivariate"</code>.</p>
</td></tr>
<tr><td><code id="plot_cellMCD_+3A_horizvar">horizvar</code></td>
<td>
<p> number or name of the variable to be plotted on the horizontal axis. Only when <code>type = "bivariate"</code>.</p>
</td></tr>
<tr><td><code id="plot_cellMCD_+3A_vertivar">vertivar</code></td>
<td>
<p> number or name of the variable to be plotted on the  vertical axis. Only when <code>type = "bivariate"</code>.</p>
</td></tr>
<tr><td><code id="plot_cellMCD_+3A_hband">hband</code></td>
<td>
<p> whether to draw a horizontal tolerance band. <code>TRUE</code> or <code>FALSE</code>. <code>NULL</code> yields <code>TRUE</code> when <code>type</code> is <code>"index"</code>, <code>"Zres/X"</code>, or <code>"Zres/pred"</code>.</p>
</td></tr>
<tr><td><code id="plot_cellMCD_+3A_vband">vband</code></td>
<td>
<p> whether to draw a vertical tolerance band. <code>TRUE</code> or <code>FALSE</code>.  <code>NULL</code> yields <code>TRUE</code> when <code>type</code> is <code>"Zres/X"</code> or <code>"Zres/pred"</code>.</p>
</td></tr>
<tr><td><code id="plot_cellMCD_+3A_drawellipse">drawellipse</code></td>
<td>
<p> whether to draw a <code class="reqn">99</code>% tolerance ellipse. Only for <code>type = "bivariate"</code>.</p>
</td></tr>
<tr><td><code id="plot_cellMCD_+3A_opacity">opacity</code></td>
<td>
<p>opacity of the plotted points: 1 is fully opaque, less is more transparent.</p>
</td></tr>
<tr><td><code id="plot_cellMCD_+3A_identify">identify</code></td>
<td>
<p> if <code>TRUE</code>, identify cases by mouseclick, then <code>Esc</code>.</p>
</td></tr>
<tr><td><code id="plot_cellMCD_+3A_ids">ids</code></td>
<td>
<p>vector of case numbers to be emphasized (colored red) in the plot. If <code>NULL</code> or of length zero, none are emphasized.</p>
</td></tr>
<tr><td><code id="plot_cellMCD_+3A_labelpoints">labelpoints</code></td>
<td>
<p> if <code>TRUE</code>, labels the points in ids by their row name in <code>X</code>.</p>
</td></tr>
<tr><td><code id="plot_cellMCD_+3A_vlines">vlines</code></td>
<td>
<p> for the points in <code>ids</code>, draw dashed vertical lines from their standardized residual to 0 when <code>type</code> is <code>"index"</code>, <code>"Zres/X"</code>, or <code>"Zres/pred"</code>. Draws dashed vertical lines to the diagonal when <code>type = "X/pred"</code>. Can be <code>TRUE</code> or <code>FALSE</code>, default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="plot_cellMCD_+3A_clines">clines</code></td>
<td>
<p> only for type == &quot;bivariate&quot;. If TRUE, draws
a red connecting line from each point in ids to 
its imputed point, shown in blue.</p>
</td></tr>
<tr><td><code id="plot_cellMCD_+3A_main">main</code></td>
<td>
<p>     main title of the plot. If <code>NULL</code>, it is constructed automatically from the arguments.</p>
</td></tr>  
<tr><td><code id="plot_cellMCD_+3A_xlab">xlab</code></td>
<td>
<p> overriding label for x-axis, unless <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="plot_cellMCD_+3A_ylab">ylab</code></td>
<td>
<p> overriding label for y-axis, unless <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="plot_cellMCD_+3A_xlim">xlim</code></td>
<td>
<p> overriding limits of horizontal axis.</p>
</td></tr>
<tr><td><code id="plot_cellMCD_+3A_ylim">ylim</code></td>
<td>
<p> overriding limits of vertical axis.</p>
</td></tr>
<tr><td><code id="plot_cellMCD_+3A_cex">cex</code></td>
<td>
<p>  size of plotted points.</p>
</td></tr>
<tr><td><code id="plot_cellMCD_+3A_cex.main">cex.main</code></td>
<td>
<p>size of the main title.</p>
</td></tr>
<tr><td><code id="plot_cellMCD_+3A_cex.lab">cex.lab</code></td>
<td>
<p> size of the axis labels.</p>
</td></tr>
<tr><td><code id="plot_cellMCD_+3A_cex.txt">cex.txt</code></td>
<td>
<p> size of the point labels.</p>
</td></tr>
<tr><td><code id="plot_cellMCD_+3A_line">line</code></td>
<td>
<p> distance of axis labels to their axis.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>NULL</code>, unless <code>identify = TRUE</code>. Then a list with components: <br />
</p>

<ul>
<li><p><code>ids</code> <br />
the case number(s) that were identified

</p>
</li>
<li><p><code>coords</code> <br />
coordinates of all points in the plot.

</p>
</li></ul>



<h3>Author(s)</h3>

<p>J. Raymaekers and P.J. Rousseeuw
</p>


<h3>References</h3>

<p>J. Raymaekers and P.J. Rousseeuw (2022). The cellwise MCD estimator, Journal of the American Statistical Association, to appear.
<a href="https://doi.org/10.1080/01621459.2023.2267777">doi:10.1080/01621459.2023.2267777</a>(link to open access pdf)
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cellMCD">cellMCD</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>mu &lt;- rep(0, 3)
Sigma &lt;- diag(3) * 0.5 + 0.5
set.seed(123)
X &lt;- MASS::mvrnorm(1000, mu, Sigma)
X[1:5, 1] &lt;- X[1:5, 1] + 5
X[6:10, 2] &lt;- X[6:10, 2] - 10
X[12, 1:2] &lt;- c(-4,8)
cellMCD.out &lt;- cellMCD(X)
plot_cellMCD(cellMCD.out, type="bivariate", 
             horizvar=1, vertivar=2, ids=c(1:10,12))

# For more examples, we refer to the vignette:
## Not run: 
vignette("cellMCD_examples")

## End(Not run)
</code></pre>

<hr>
<h2 id='transfo'>
Robustly fit the Box-Cox or Yeo-Johnson transformation 
</h2><span id='topic+transfo'></span>

<h3>Description</h3>

<p>This function uses reweighted maximum likelihood to robustly fit the 
Box-Cox or Yeo-Johnson transformation to each variable in a dataset. 
Note that this function first calls <code><a href="#topic+checkDataSet">checkDataSet</a></code> to ensure that the variables to be transformed are not too discrete.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>transfo(X, type = "YJ", robust = TRUE,
        standardize = TRUE,
        quant = 0.99, nbsteps = 2, checkPars = list())
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="transfo_+3A_x">X</code></td>
<td>
<p> A data matrix of dimensions n x d.
Its columns are the variables to be transformed.
</p>
</td></tr>
<tr><td><code id="transfo_+3A_type">type</code></td>
<td>
<p> The type of transformation to be fit. Should be one of: </p>

<ul>
<li><p><code>"BC"</code>: Box-Cox power transformation. Only works
for strictly positive variables. If this type
is given but a variable is not strictly
positive, the function stops with a
message about that variable.
</p>
</li>
<li><p><code>"YJ"</code> Yeo-Johnson power transformation. The data
may have positive as well as negative values.
</p>
</li>
<li><p><code>"bestObj"</code> for strictly positive variables both BC
and YJ are run, and the solution with
lowest objective is kept. On the other
variables YJ is run.
</p>
</li></ul>

</td></tr>
<tr><td><code id="transfo_+3A_robust">robust</code></td>
<td>
<p> if <code>TRUE</code> the Reweighted Maximum 
Likelihood method is used, which first
computes a robust initial estimate of the
transformation parameter lambda. If <code>FALSE</code> the classical ML method is used.
</p>
</td></tr>
<tr><td><code id="transfo_+3A_standardize">standardize</code></td>
<td>
<p> whether to standardize the variables <strong>before and after</strong> the
power transformation. See Details below.
</p>
</td></tr>
<tr><td><code id="transfo_+3A_quant">quant</code></td>
<td>
<p>quantile for determining the weights in the 
reweighting step (ignored when <code>robust=FALSE</code>).
</p>
</td></tr>
<tr><td><code id="transfo_+3A_nbsteps">nbsteps</code></td>
<td>
<p>number of reweighting steps (ignored when 
<code>robust=FALSE</code>).
</p>
</td></tr>
<tr><td><code id="transfo_+3A_checkpars">checkPars</code></td>
<td>
<p>Optional list of parameters used in the call to
<code><a href="#topic+checkDataSet">checkDataSet</a></code>. The options are:
</p>

<ul>
<li> <p><code>coreOnly</code> <br />
If <code>TRUE</code>, skip the execution of checkDataset. Defaults to <code>FALSE</code>
</p>
</li>
<li><p><code>numDiscrete</code><br />
A column that takes on numDiscrete or fewer values
will be considered discrete and not retained in the cleaned data.
Defaults to <code class="reqn">5</code>.

</p>
</li>
<li><p><code>precScale</code> <br />
Only consider columns whose scale is larger than precScale.
Here scale is measured by the median absolute deviation.
Defaults to <code class="reqn">1e-12</code>.

</p>
</li>
<li><p><code>silent</code><br />
Whether or not the function progress messages should be printed.
Defaults to <code>FALSE</code>.

</p>
</li></ul>

</td></tr>
</table>


<h3>Details</h3>

<p>In case <code>standardize = TRUE</code>, the variables is standardized before and after transformation. 
For BC the variable is divided by its median before transformation.
For YJ and <code>robust = TRUE</code> this subtracts its median and divides by its mad (median absolute deviation) before transformation. For YJ and <code>robust = FALSE</code> this subtracts the mean and divides by the standard deviation before transformation. For the standardization after the transformation, the classical mean and standard deviation are used in case  <code>robust = FALSE</code>. If <code>robust = TRUE</code>, the mean and standard deviation are calculated robustly on a subset of inliers.  
</p>


<h3>Value</h3>

<p>A list with components: <br />
</p>

<ul>
<li><p><code>lambdahats</code> <br />
the estimated transformation parameter for each column of <code>X</code>.

</p>
</li>
<li><p><code>Y</code> <br />
A matrix in which each column is the transformed version of the
corresponding column of <code>X</code>.
The transformed version includes pre- and post-standardization if <code>standardize=TRUE</code>.

</p>
</li>
<li><p><code>muhat</code> <br />
The estimated location of each column of <code>Y</code>.

</p>
</li>
<li><p><code>sigmahat</code> <br />
The estimated scale of each column of <code>Y</code>.

</p>
</li>
<li><p><code>weights</code> <br />
The final weights from the reweighting.

</p>
</li>
<li><p><code>ttypes</code> <br />
The type of transform used in each column.

</p>
</li>
<li><p><code>objective</code> <br />
Value of the (reweighted) maximum likelihood objective function.

</p>
</li>
<li><p>values of <code><a href="#topic+checkDataSet">checkDataSet</a></code>, unless <code>coreOnly</code> is <code>TRUE</code>.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>J. Raymaekers and P.J. Rousseeuw
</p>


<h3>References</h3>

<p>J. Raymaekers and P.J. Rousseeuw (2021). Transforming variables to central normality. <em>Machine Learning</em>. <a href="https://doi.org/10.1007/s10994-021-05960-5">doi:10.1007/s10994-021-05960-5</a>(link to open access pdf)
</p>


<h3>See Also</h3>

<p><code><a href="#topic+transfo_newdata">transfo_newdata</a></code>, <code><a href="#topic+transfo_transformback">transfo_transformback</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# find Box-Cox transformation parameter for lognormal data:
set.seed(123)
x &lt;- exp(rnorm(1000))
transfo.out &lt;- transfo(x, type = "BC")
# estimated parameter:
transfo.out$lambdahat
# value of the objective function:
transfo.out$objective
# the transformed variable:
transfo.out$Y
# the type of transformation used:
transfo.out$ttypes
# qqplot of the transformed variable:
qqnorm(transfo.out$Y); abline(0,1)

# For more examples, we refer to the vignette:
## Not run: 
vignette("transfo_examples")

## End(Not run)
</code></pre>

<hr>
<h2 id='transfo_newdata'>
Transform variables based on the output of <code><a href="#topic+transfo">transfo</a></code>. 
</h2><span id='topic+transfo_newdata'></span>

<h3>Description</h3>

<p>Based on the output of <code><a href="#topic+transfo">transfo</a></code>, transform the variables using Yeo-Johnson and/or Box-Cox transformations with the previously estimated parameters and standardization.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>transfo_newdata(Xnew, transfo.out)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="transfo_newdata_+3A_xnew">Xnew</code></td>
<td>
<p>A data matrix with d columns, which contain the variables to be transformed. The number of columns and their names must be the same as those of the original data on which <code><a href="#topic+transfo">transfo</a></code> was run. The number of rows may be different.
</p>
</td></tr>
<tr><td><code id="transfo_newdata_+3A_transfo.out">transfo.out</code></td>
<td>

<p>The output of a call to <code><a href="#topic+transfo">transfo</a></code>.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a matrix with transformed variables.
</p>


<h3>Author(s)</h3>

<p>J. Raymaekers and P.J. Rousseeuw
</p>


<h3>References</h3>

<p>J. Raymaekers and P.J. Rousseeuw (2021). Transforming variables to central normality. <em>Machine Learning</em>. <a href="https://doi.org/10.1007/s10994-021-05960-5">doi:10.1007/s10994-021-05960-5</a>(link to open access pdf)
</p>


<h3>See Also</h3>

<p><code><a href="#topic+transfo">transfo</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(123); tempraw &lt;- matrix(rnorm(2000), ncol = 2)
tempx &lt;- cbind(tempraw[, 1],exp(tempraw[, 2]))
tempy &lt;- 0.5 * tempraw[, 1] + 0.5 * tempraw[, 2] + 1
x &lt;- tempx[1:900, ]
y &lt;- tempy[1:900]
tx.out &lt;- transfo(x, type = "bestObj")
tx.out$ttypes
tx.out$lambdahats
tx &lt;- tx.out$Y
lm.out &lt;- lm(y ~ tx)
summary(lm.out)
xnew &lt;- tempx[901:1000, ]
xtnew &lt;- transfo_newdata(xnew, tx.out)
yhatnew &lt;- tcrossprod(lm.out$coefficients, cbind(1, xtnew)) 
plot(tempy[901:1000], yhatnew); abline(0, 1)
</code></pre>

<hr>
<h2 id='transfo_transformback'>
Backtransform variables based on the output of <code><a href="#topic+transfo">transfo</a></code>. 
</h2><span id='topic+transfo_transformback'></span>

<h3>Description</h3>

<p>Based on the output of <code><a href="#topic+transfo">transfo</a></code>, backtransform the variables to their original shape through the inverse Yeo-Johnson and/or Box-Cox transformations with the previusly estimated parameters and standardization.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>transfo_transformback(Ynew, transfo.out)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="transfo_transformback_+3A_ynew">Ynew</code></td>
<td>
<p>A data matrix with d columns, which contain the variables to be backtransformed. The number of columns must be the same as the output <code>Y</code> of the run of <code><a href="#topic+transfo">transfo</a></code> on the  original data. The number of rows may be different.
</p>
</td></tr>
<tr><td><code id="transfo_transformback_+3A_transfo.out">transfo.out</code></td>
<td>

<p>The output of a call to <code><a href="#topic+transfo">transfo</a></code>.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a matrix with backtransformed variables.
</p>


<h3>Author(s)</h3>

<p>J. Raymaekers and P.J. Rousseeuw
</p>


<h3>References</h3>

<p>J. Raymaekers and P.J. Rousseeuw (2021). Transforming variables to central normality. <em>Machine Learning</em>. <a href="https://doi.org/10.1007/s10994-021-05960-5">doi:10.1007/s10994-021-05960-5</a>(link to open access pdf)
</p>


<h3>See Also</h3>

<p><code><a href="#topic+transfo">transfo</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(123); x &lt;- matrix(rnorm(2000), ncol = 2)
y &lt;- sqrt(abs(0.3 * x[, 1] + 0.5 * x[, 2] + 4))
ty.out &lt;- transfo(y, type = "BC")
ty.out$lambdahats
ty &lt;- ty.out$Y
lm.out &lt;- lm(ty ~ x)
yhat &lt;- transfo_transformback(lm.out$fitted.values, ty.out)
plot(y, yhat); abline(0, 1)
</code></pre>

<hr>
<h2 id='truncPC'>
Classical Principal Components by truncated SVD.
</h2><span id='topic+truncPC'></span>

<h3>Description</h3>

<p>Similar usage to robustbase::classPC except for the new argument <code>ncomb</code> which is the desired number of components. Only this many PC's are computed in order to save computation time. Makes use of <code>propack.svd</code> of package <span class="pkg">svd</span>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>truncPC(X, ncomp = NULL, scale = FALSE, center = TRUE, 
                    signflip = TRUE, via.svd = NULL, scores = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="truncPC_+3A_x">X</code></td>
<td>

<p>a numeric matrix.
</p>
</td></tr>
<tr><td><code id="truncPC_+3A_ncomp">ncomp</code></td>
<td>

<p>the desired number of components (if not specified, all components are computed).
</p>
</td></tr>
<tr><td><code id="truncPC_+3A_scale">scale</code></td>
<td>

<p>logical, or numeric vector for scaling the columns.
</p>
</td></tr>
<tr><td><code id="truncPC_+3A_center">center</code></td>
<td>

<p>logical or numeric vector for centering the matrix.
</p>
</td></tr>
<tr><td><code id="truncPC_+3A_signflip">signflip</code></td>
<td>

<p>logical indicating if the signs of the loadings should be 
flipped such that the absolutely largest value is always positive.
</p>
</td></tr>
<tr><td><code id="truncPC_+3A_via.svd">via.svd</code></td>
<td>

<p>dummy argument for compatibility with classPC calls, will be ignored.
</p>
</td></tr>
<tr><td><code id="truncPC_+3A_scores">scores</code></td>
<td>

<p>logical indicating whether or not scores should be returned.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with components: <br />
</p>
<table>
<tr><td><code>rank</code></td>
<td>
<p>the (numerical) matrix rank of <code>X</code>, i.e. an integer number
between 0 and <code>min(dim(x))</code>.</p>
</td></tr>
<tr><td><code>eigenvalues</code></td>
<td>
<p>the <code>k</code> eigenvalues, proportional to the variances, where <code>k</code> is the rank above.</p>
</td></tr>
<tr><td><code>loadings</code></td>
<td>
<p>the loadings, a <code class="reqn">d \times k</code> matrix.</p>
</td></tr>
<tr><td><code>scores</code></td>
<td>
<p>if the <code>scores</code> argument was <code>TRUE</code>,
the <code class="reqn">n \times k</code> matrix of scores.</p>
</td></tr>
<tr><td><code>center</code></td>
<td>
<p>a vector of means, unless the center argument was <code>FALSE</code>.</p>
</td></tr>
<tr><td><code>scale</code></td>
<td>
<p>a vector of column scales, unless the scale argument was false.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>P.J. Rousseeuw
</p>


<h3>See Also</h3>

<p><code><a href="robustbase.html#topic+classPC">classPC</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>library(MASS) 
set.seed(12345) 
n &lt;- 100; d &lt;- 10
A &lt;- diag(d) * 0.1 + 0.9
x &lt;- mvrnorm(n, rep(0,d), A)
truncPCA.out &lt;- truncPC(x, ncomp = 2, scores = TRUE)
plot(truncPCA.out$scores)
</code></pre>

<hr>
<h2 id='unpack'>
Unpacks cellwise weighted data
</h2><span id='topic+unpack'></span>

<h3>Description</h3>

<p>This function transforms a dataset X with cellwise weights W
to an extended data matrix U with the same number of columns but more rows, and containing more NA's. Its rows have the case weights v.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>unpack(X,W)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="unpack_+3A_x">X</code></td>
<td>
<p>An <code class="reqn">n</code> by <code class="reqn">d</code> data matrix or data frame. Must be given.
<code>X</code> is allowed to contain <code>NA</code>'s.</p>
</td></tr>
<tr><td><code id="unpack_+3A_w">W</code></td>
<td>
<p>An <code class="reqn">n</code> by <code class="reqn">d</code> matrix of nonnegative cellwise weights.
Must be given. <code>W</code> is not allowed to contain <code>NA</code>'s.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with components: <br />
</p>

<ul>
<li><p><code>U</code><br />
unpacked data matrix, with the same columns as <code>X</code> but typically more rows.
</p>
</li>
<li><p><code>V</code><br /> vector with the rowwise (=casewise) weights of <code>U</code>.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>P.J. Rousseeuw
</p>


<h3>References</h3>

<p>P.J. Rousseeuw (2023). Analyzing cellwise weighted data. Econometrics and Statistics, appeared online. <a href="https://doi.org/10.1016/j.ecosta.2023.01.007">doi:10.1016/j.ecosta.2023.01.007</a>(link to open access pdf)
</p>


<h3>See Also</h3>

 
<p><code><a href="#topic+weightedEM">weightedEM</a></code>,
<code><a href="#topic+cwLocScat">cwLocScat</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

X &lt;- matrix(c(2.8, 5.3, 4.9, 7.4,
             2.3, 5.7, 4.3, 7.2,
             2.5, 5.1, 4.4, 7.6), nrow = 3, byrow = TRUE)
W &lt;- matrix(c(0.8, 1.0, 0.3, 0.4, 
             0.3, 0.5, 0.9, 0.5, 
             1.0, 0.6, 0, 0.7), nrow = 3, byrow = TRUE)
rownames(X) &lt;- rownames(W) &lt;- c("A", "B", "C")
colnames(X) &lt;- colnames(W) &lt;- c("V1", "V2", "V3", "V4")
X
W
out &lt;- unpack(X, W)
cbind(out$U, out$v)


# For more examples, we refer to the vignette:
## Not run: 
vignette("cellwise_weights_examples")

## End(Not run)
</code></pre>

<hr>
<h2 id='weightedEM'>
Estimates location and scatter on incomplete data with case weights
</h2><span id='topic+weightedEM'></span>

<h3>Description</h3>

<p>Carries out a rowwise weighted EM algorithm to estimate mu and Sigma of incomplete Gaussian data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>weightedEM(X, w=NULL, lmin=NULL, crit=1e-4, 
                      maxiter=1000, initEst=NULL, computeloglik=F)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="weightedEM_+3A_x">X</code></td>
<td>
<p>n by d data matrix or data frame.</p>
</td></tr>
<tr><td><code id="weightedEM_+3A_w">w</code></td>
<td>
<p>vector with n nonnegative rowwise (casewise)
weights. If <code>NULL</code>, all weights are set to 1 so
an unweighted EM is carried out.</p>
</td></tr>
<tr><td><code id="weightedEM_+3A_lmin">lmin</code></td>
<td>
<p>if not <code>NULL</code>, a lower bound on the eigenvalues
of the estimated EM covariance matrix on the
standardized data, to avoid singularity.</p>
</td></tr>
<tr><td><code id="weightedEM_+3A_crit">crit</code></td>
<td>
<p>convergence criterion of successive mu
and Sigma estimates.</p>
</td></tr>
<tr><td><code id="weightedEM_+3A_maxiter">maxiter</code></td>
<td>
<p>maximal number of iteration steps.</p>
</td></tr>
<tr><td><code id="weightedEM_+3A_initest">initEst</code></td>
<td>
<p>if not <code>NULL</code>, a list with initial estimates <code>$mu</code> of the mean, <code>$Sigma</code> of the covariance matrix.</p>
</td></tr>
<tr><td><code id="weightedEM_+3A_computeloglik">computeloglik</code></td>
<td>
<p>if <code>TRUE</code>, the log(likelihood) is computed in
every step and reported. Default is <code>FALSE</code>
to save computation time.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with components: <br />
</p>

<ul>
<li><p><code>mu</code><br /> the estimated location vector.
</p>
</li>
<li><p><code>Sigma</code><br /> the estimated covariance matrix.
</p>
</li>
<li><p><code>impX</code><br /> the imputed data matrix.
</p>
</li>
<li><p><code>niter</code><br /> the number of iteration steps taken.
</p>
</li>
<li><p><code>loglikhd</code><br /> vector with the total log(likelihood) at every
iteration step. When <code>computeloglik = FALSE</code> this
array contains NA's.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>P.J. Rousseeuw
</p>


<h3>References</h3>

<p>P.J. Rousseeuw (2023). Analyzing cellwise weighted data. Econometrics and Statistics, appeared online. <a href="https://doi.org/10.1016/j.ecosta.2023.01.007">doi:10.1016/j.ecosta.2023.01.007</a>(link to open access pdf)
</p>


<h3>See Also</h3>

 
<p><code><a href="#topic+unpack">unpack</a></code>,
<code><a href="#topic+cwLocScat">cwLocScat</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
Sigma &lt;- matrix(0.7, 3, 3); diag(Sigma) &lt;- 1
set.seed(12345); X &lt;- MASS::mvrnorm(1000, rep(0, 3), Sigma)
X[1, 3] &lt;- X[2, 2] &lt;- X[3, 1] &lt;- X[4, 1] &lt;- X[5, 2] &lt;- NA
w &lt;- runif(1000, 0, 1) # rowwise weights
out &lt;- weightedEM(X, w, crit = 1e-12, computeloglik = TRUE)
out$niter # number of iteration steps taken
plot(1:out$niter, out$loglikhd[1:out$niter], type = 'l',
     lty = 1, col = 4, xlab = 'step', ylab = 'log(likelihood)',
     main = 'log(likelihood) of weighted EM iterations')
out$mu # estimated center
round(out$Sigma, 6) # estimated covariance matrix
head(X) # the data has NA's
head(out$impX) # imputed data, has no NA's

# For more examples, we refer to the vignette:
## Not run: 
vignette("cellwise_weights_examples")

## End(Not run)
</code></pre>

<hr>
<h2 id='wrap'>
Wrap the data.
</h2><span id='topic+wrap'></span>

<h3>Description</h3>

<p>Transforms multivariate data <code>X</code> using the wrapping function with <code>b = 1.5</code> and <code>c = 4</code>. By default, it starts by calling <code><a href="#topic+checkDataSet">checkDataSet</a></code> to clean the data and <code><a href="#topic+estLocScale">estLocScale</a></code> to estimate the location and scale of the variables in the cleaned data, yielding the vectors <code class="reqn">(\hat{\mu}_1,\ldots,\hat{\mu}_d)</code> and <code class="reqn">(\hat{\sigma}_1,\ldots,\hat{\sigma}_d)</code> where <code class="reqn">d</code> is the number of variables. Alternatively, the user can specify such vectors in the arguments <code>locX</code> and <code>scaleX</code>. In either case, the data cell <code class="reqn">x_{ij}</code> containing variable <code class="reqn">j</code> of case <code class="reqn">i</code> is transformed to </p>
<p style="text-align: center;"><code class="reqn">y_{ij} = \hat{\mu}_j - b_j + \hat{\sigma}_j*\psi((x_{ij} - \hat{\mu}_j)/\hat{\sigma}_j)/a_j</code>
</p>
<p> in which <code class="reqn">a_j</code> and <code class="reqn">b_j</code> are such that for any fixed <code class="reqn">j</code> the average of <code class="reqn">y_{ij}</code> equals <code class="reqn">\hat{\mu}_j</code> and the standard deviation of <code class="reqn">y_{ij}</code> equals <code class="reqn">\hat{\sigma}_j</code>.  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>wrap(X, locX = NULL, scaleX = NULL, precScale = 1e-12,
     imputeNA = TRUE, checkPars = list())
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="wrap_+3A_x">X</code></td>
<td>
<p>the input data. It must be an <code class="reqn">n</code> by <code class="reqn">d</code> matrix or a data frame.
</p>
</td></tr>
<tr><td><code id="wrap_+3A_locx">locX</code></td>
<td>
<p>The location estimates of the columns of the input data <code>X</code>. Must be a vector of length <code class="reqn">d</code>.
</p>
</td></tr>
<tr><td><code id="wrap_+3A_scalex">scaleX</code></td>
<td>
<p>The scale estimates of the columns of the input data <code>X</code>. Must be a vector of length <code class="reqn">d</code>.
</p>
</td></tr>
<tr><td><code id="wrap_+3A_precscale">precScale</code></td>
<td>
<p>The precision scale used throughout the algorithm. Defaults to <code class="reqn">1e-12</code>
</p>
</td></tr>
<tr><td><code id="wrap_+3A_imputena">imputeNA</code></td>
<td>
<p>Whether or not to impute the <code>NA</code>s with the location estimate
of the corresponding variable. Defaults to <code>TRUE</code>.
</p>
</td></tr>
<tr><td><code id="wrap_+3A_checkpars">checkPars</code></td>
<td>
<p>Optional list of parameters used in the call to
<code><a href="#topic+checkDataSet">checkDataSet</a></code>. The options are:
</p>

<ul>
<li> <p><code>coreOnly</code> <br />
If <code>TRUE</code>, skip the execution of checkDataset. Defaults to <code>FALSE</code>
</p>
</li>
<li><p><code>numDiscrete</code><br />
A column that takes on numDiscrete or fewer values
will be considered discrete and not retained in the cleaned data.
Defaults to <code class="reqn">5</code>.

</p>
</li>
<li><p><code>precScale</code> <br />
Only consider columns whose scale is larger than precScale.
Here scale is measured by the median absolute deviation.
Defaults to <code class="reqn">1e-12</code>.

</p>
</li>
<li><p><code>silent</code><br />
Whether or not the function progress messages should be printed.
Defaults to <code>FALSE</code>.

</p>
</li></ul>

</td></tr>
</table>


<h3>Value</h3>

<p>A list with components: <br />
</p>

<ul>
<li><p><code>Xw</code> <br />
The wrapped data.

</p>
</li>
<li><p><code>colInWrap</code> <br /> 
The column numbers of the variables which were wrapped. Variables which were filtered out by <code><a href="#topic+checkDataSet">checkDataSet</a></code> (because of a (near) zero scale for example), will not appear in this output.

</p>
</li>
<li><p><code>loc</code> <br /> 
The location estimates for all variables used for wrapping.

</p>
</li>
<li><p><code>scale</code> <br /> 
The scale estimates for all variables used for wrapping.

</p>
</li></ul>



<h3>Author(s)</h3>

<p>Raymaekers, J. and Rousseeuw P.J.
</p>


<h3>References</h3>

<p>Raymaekers, J., Rousseeuw P.J. (2019). Fast robust correlation for high dimensional data. <em>Technometrics</em>, <b>63</b>(2), 184-198. <a href="https://www.tandfonline.com/doi/full/10.1080/00401706.2019.1677270">(link to open access pdf)</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+estLocScale">estLocScale</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(MASS) 
set.seed(12345) 
n &lt;- 100; d &lt;- 10
X &lt;- mvrnorm(n, rep(0, 10), diag(10))
locScale &lt;- estLocScale(X)
Xw &lt;- wrap(X, locScale$loc, locScale$scale)$Xw
# For more examples, we refer to the vignette:
## Not run: 
vignette("wrap_examples")

## End(Not run)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
