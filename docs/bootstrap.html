<!DOCTYPE html><html><head><title>Help for package bootstrap</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {bootstrap}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#abcnon'><p> Nonparametric ABC Confidence Limits</p></a></li>
<li><a href='#abcpar'><p>  Parametric ABC Confidence Limits</p></a></li>
<li><a href='#bcanon'><p> Nonparametric BCa Confidence Limits</p></a></li>
<li><a href='#bootpred'><p>  Bootstrap Estimates of Prediction Error</p></a></li>
<li><a href='#bootstrap'><p>Non-Parametric Bootstrapping</p></a></li>
<li><a href='#bootstrap-internal'><p>Internal functions of package bootstrap</p></a></li>
<li><a href='#boott'><p>Bootstrap-t Confidence Limits</p></a></li>
<li><a href='#cell'><p>  Cell Survival data</p></a></li>
<li><a href='#cholost'><p> The Cholostyramine Data</p></a></li>
<li><a href='#crossval'><p>K-fold Cross-Validation</p></a></li>
<li><a href='#diabetes'><p> Blood Measurements on 43 Diabetic Children</p></a></li>
<li><a href='#hormone'><p> Hormone Data from page 107</p></a></li>
<li><a href='#jackknife'><p>Jackknife Estimation</p></a></li>
<li><a href='#law'><p>  Law school data from Efron and Tibshirani</p></a></li>
<li><a href='#law82'><p>  Data for Universe of USA Law Schools</p></a></li>
<li><a href='#lutenhorm'><p> Luteinizing Hormone</p></a></li>
<li><a href='#mouse.c'><p> Experiments with mouse</p></a></li>
<li><a href='#mouse.t'><p> Experiment with mouse</p></a></li>
<li><a href='#patch'><p>  The Patch Data</p></a></li>
<li><a href='#Rainfall'><p> Rainfall Data</p></a></li>
<li><a href='#scor'><p> Open/Closed Book Examination Data</p></a></li>
<li><a href='#spatial'><p> Spatial Test Data</p></a></li>
<li><a href='#stamp'><p> Data on Thickness of Stamps</p></a></li>
<li><a href='#tooth'><p> Tooth Strength Data</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Version:</td>
<td>2019.6</td>
</tr>
<tr>
<td>Date:</td>
<td>2019-06-15</td>
</tr>
<tr>
<td>Title:</td>
<td>Functions for the Book "An Introduction to the Bootstrap"</td>
</tr>
<tr>
<td>Author:</td>
<td>S original, from StatLib, by Rob Tibshirani.  R port by
        Friedrich Leisch.</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Scott Kostyshak &lt;scott.kostyshak@gmail.com&gt;</td>
</tr>
<tr>
<td>Depends:</td>
<td>stats, R (&ge; 2.10.0)</td>
</tr>
<tr>
<td>LazyData:</td>
<td>TRUE</td>
</tr>
<tr>
<td>Description:</td>
<td>Software (bootstrap, cross-validation, jackknife) and data
        for the book "An Introduction to the Bootstrap" by B. Efron and
        R. Tibshirani, 1993, Chapman and Hall. This package is
        primarily provided for projects already based on it, and for
        support of the book. New projects should preferentially use the
        recommended package "boot".</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/BSD-3-Clause">BSD_3_clause</a> + file LICENSE</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://gitlab.com/scottkosty/bootstrap">https://gitlab.com/scottkosty/bootstrap</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://gitlab.com/scottkosty/bootstrap/issues">https://gitlab.com/scottkosty/bootstrap/issues</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2019-06-15 21:33:55 UTC; scott</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2019-06-17 09:40:08 UTC</td>
</tr>
</table>
<hr>
<h2 id='abcnon'> Nonparametric ABC Confidence Limits </h2><span id='topic+abcnon'></span>

<h3>Description</h3>

<p>See Efron and Tibshirani (1993) for details on this
function.</p>


<h3>Usage</h3>

<pre><code class='language-R'>abcnon(x, tt, epsilon=0.001, 
       alpha=c(0.025, 0.05, 0.1, 0.16, 0.84, 0.9, 0.95, 0.975))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="abcnon_+3A_x">x</code></td>
<td>
<p>the data. Must be either a vector, or a matrix whose rows are
the observations</p>
</td></tr> 
<tr><td><code id="abcnon_+3A_tt">tt</code></td>
<td>
<p>function defining the parameter in the resampling form
<code>tt(p,x)</code>, where <code>p</code> is the vector of proportions and <code>x</code>
is the data</p>
</td></tr> 
<tr><td><code id="abcnon_+3A_epsilon">epsilon</code></td>
<td>
<p>optional argument specifying step size for finite
difference calculations</p>
</td></tr> 
<tr><td><code id="abcnon_+3A_alpha">alpha</code></td>
<td>
<p>optional argument specifying confidence levels desired</p>
</td></tr>
</table>


<h3>Value</h3>

<p>list with following components
</p>
<table>
<tr><td><code>limits</code></td>
<td>
<p>The estimated confidence points, from the ABC and 
standard normal methods</p>
</td></tr>
<tr><td><code>stats</code></td>
<td>
<p>list consisting of <code>t0</code>=observed value of <code>tt</code>,
<code>sighat</code>=infinitesimal jackknife estimate 
of standard error of <code>tt</code>, <code>bhat</code>=estimated bias</p>
</td></tr>
<tr><td><code>constants</code></td>
<td>
<p>list consisting of <code>a</code>=acceleration constant,
<code>z0</code>=bias adjustment, <code>cq</code>=curvature component</p>
</td></tr> 
<tr><td><code>tt.inf</code></td>
<td>
<p>approximate influence components of <code>tt</code></p>
</td></tr>
<tr><td><code>pp</code></td>
<td>
<p>matrix whose rows are the resampling points in the least
favourable family. The abc confidence points are the function <code>tt</code>
evaluated at these points</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>The deparsed call</p>
</td></tr>
</table>


<h3>References</h3>

<p>Efron, B, and DiCiccio, T. (1992) More accurate confidence intervals 
in exponential families. Biometrika 79, pages 231-245.
</p>
<p>Efron, B. and Tibshirani, R. (1993) An Introduction to the Bootstrap.
Chapman and Hall, New York, London.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># compute abc intervals for the mean
x &lt;- rnorm(10)
theta &lt;- function(p,x) {sum(p*x)/sum(p)}
results &lt;- abcnon(x, theta)  
# compute abc intervals for the correlation
x &lt;- matrix(rnorm(20),ncol=2)
theta &lt;- function(p, x)
{
    x1m &lt;- sum(p * x[, 1])/sum(p)
    x2m &lt;- sum(p * x[, 2])/sum(p)
    num &lt;- sum(p * (x[, 1] - x1m) * (x[, 2] - x2m))
    den &lt;- sqrt(sum(p * (x[, 1] - x1m)^2) *
              sum(p * (x[, 2] - x2m)^2))
    return(num/den)
}
results &lt;- abcnon(x, theta)   
</code></pre>

<hr>
<h2 id='abcpar'>  Parametric ABC Confidence Limits  </h2><span id='topic+abcpar'></span>

<h3>Description</h3>

<p>See Efron and Tibshirani (1993) for details on this
function.</p>


<h3>Usage</h3>

<pre><code class='language-R'>abcpar(y, tt, S, etahat, mu, n=rep(1,length(y)),lambda=0.001, 
       alpha=c(0.025, 0.05, 0.1, 0.16))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="abcpar_+3A_y">y</code></td>
<td>
<p>vector of data</p>
</td></tr>
<tr><td><code id="abcpar_+3A_tt">tt</code></td>
<td>
<p>function of expectation parameter <code>mu</code> defining the parameter 
of interest</p>
</td></tr>
<tr><td><code id="abcpar_+3A_s">S</code></td>
<td>
<p>maximum likelihood estimate of the covariance matrix of <code>x</code></p>
</td></tr>
<tr><td><code id="abcpar_+3A_etahat">etahat</code></td>
<td>
<p>maximum likelihood estimate of the natural parameter eta</p>
</td></tr>
<tr><td><code id="abcpar_+3A_mu">mu</code></td>
<td>
<p>function giving expectation of <code>x</code> in terms of eta</p>
</td></tr>
<tr><td><code id="abcpar_+3A_n">n</code></td>
<td>
<p>optional argument containing denominators for binomial (vector of
length <code>length(x)</code>)</p>
</td></tr> 
<tr><td><code id="abcpar_+3A_lambda">lambda</code></td>
<td>
<p>optional argument specifying step size for finite difference 
calculation</p>
</td></tr>
<tr><td><code id="abcpar_+3A_alpha">alpha</code></td>
<td>
<p>optional argument specifying confidence levels desired</p>
</td></tr>
</table>


<h3>Value</h3>

<p>list with the following components
</p>
<table>
<tr><td><code>call</code></td>
<td>
<p>the call to abcpar</p>
</td></tr>
<tr><td><code>limits</code></td>
<td>
<p>The nominal confidence level, ABC point, quadratic ABC point, 
and
standard normal point.</p>
</td></tr> 
<tr><td><code>stats</code></td>
<td>
<p>list consisting of  observed value of <code>tt</code>, estimated 
standard error and estimated bias</p>
</td></tr>
<tr><td><code>constants</code></td>
<td>
<p>list consisting of <code>a</code>=acceleration constant,
<code>z0</code>=bias adjustment, <code>cq</code>=curvature component</p>
</td></tr></table>
<p>, 
</p>
<table>
<tr><td><code>asym.05</code></td>
<td>
<p>asymmetry component</p>
</td></tr>
</table>


<h3>References</h3>

<p>Efron, B, and DiCiccio, T. (1992) More accurate confidence intervals 
in exponential families. Bimometrika 79, pages 231-245.
</p>
<p>Efron, B. and Tibshirani, R. (1993) An Introduction to the Bootstrap.
Chapman and Hall, New York, London.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># binomial
# x is a p-vector of successes, n is a p-vector of 
#  number of trials
## Not run: 
S &lt;- matrix(0,nrow=p,ncol=p)
S[row(S)==col(S)] &lt;- x*(1-x/n)
mu &lt;- function(eta,n){n/(1+exp(eta))}
etahat &lt;- log(x/(n-x))
#suppose p=2 and we are interested in mu2-mu1
tt &lt;- function(mu){mu[2]-mu[1]}
x &lt;- c(2,4); n &lt;- c(12,12)
a &lt;- abcpar(x, tt, S, etahat,n)

## End(Not run)</code></pre>

<hr>
<h2 id='bcanon'> Nonparametric BCa Confidence Limits </h2><span id='topic+bcanon'></span>

<h3>Description</h3>

<p>See Efron and Tibshirani (1993) for details on this
function.</p>


<h3>Usage</h3>

<pre><code class='language-R'>bcanon(x, nboot, theta, ..., 
       alpha=c(0.025, 0.05, 0.1, 0.16, 0.84, 0.9, 0.95, 0.975))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bcanon_+3A_x">x</code></td>
<td>
<p>a vector containing the data. To bootstrap  more complex data
structures (e.g. bivariate data) see the last example below.</p>
</td></tr>
<tr><td><code id="bcanon_+3A_nboot">nboot</code></td>
<td>
<p>number of bootstrap replications</p>
</td></tr>
<tr><td><code id="bcanon_+3A_theta">theta</code></td>
<td>
<p>function defining the estimator used in constructing the
confidence points</p>
</td></tr> 
<tr><td><code id="bcanon_+3A_...">...</code></td>
<td>
<p>additional arguments for <code>theta</code></p>
</td></tr>
<tr><td><code id="bcanon_+3A_alpha">alpha</code></td>
<td>
<p>optional argument specifying confidence levels desired</p>
</td></tr>
</table>


<h3>Value</h3>

<p>list with the following components
</p>
<table>
<tr><td><code>confpoints</code></td>
<td>
<p>estimated bca confidence limits</p>
</td></tr>
<tr><td><code>z0</code></td>
<td>
<p>estimated bias correction</p>
</td></tr>
<tr><td><code>acc</code></td>
<td>
<p>estimated acceleration constant</p>
</td></tr>
<tr><td><code>u</code></td>
<td>
<p>jackknife influence values</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>The deparsed call</p>
</td></tr>
</table>


<h3>References</h3>

<p>Efron, B. and   Tibshirani, R. (1986).  The Bootstrap
Method for standard errors, confidence intervals,
and other measures of   statistical accuracy.
Statistical Science, Vol 1., No. 1, pp 1-35.
</p>
<p>Efron, B. (1987). Better bootstrap confidence intervals (with discussion).
J. Amer. Stat. Assoc. vol 82, pg 171
</p>
<p>Efron, B. and Tibshirani, R. (1993) An Introduction to the Bootstrap.
Chapman and Hall, New York, London.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#  bca limits for the  mean 
#  (this is for illustration; 
#   since "mean" is a built in function,
#   bcanon(x,100,mean) would be simpler!)
   x &lt;- rnorm(20)                
   theta &lt;- function(x){mean(x)}
   results &lt;- bcanon(x,100,theta)   
                              
# To obtain bca limits for functions of more 
# complex data structures, write theta
# so that its argument x is the set of observation
# numbers and simply pass as data to bcanon 
# the vector 1,2,..n. 
# For example, find bca limits for
# the correlation coefficient from a set of 15 data pairs:
   xdata &lt;- matrix(rnorm(30),ncol=2)
   n &lt;- 15
   theta &lt;- function(x,xdata){ cor(xdata[x,1],xdata[x,2]) }
   results &lt;- bcanon(1:n,100,theta,xdata)
</code></pre>

<hr>
<h2 id='bootpred'>  Bootstrap Estimates of Prediction Error  </h2><span id='topic+bootpred'></span>

<h3>Description</h3>

<p>See Efron and Tibshirani (1993) for details on this
function.</p>


<h3>Usage</h3>

<pre><code class='language-R'>   bootpred(x,y,nboot,theta.fit,theta.predict,err.meas,...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bootpred_+3A_x">x</code></td>
<td>
<p>a matrix containing the predictor (regressor) values. Each row
corresponds to an observation.</p>
</td></tr>
<tr><td><code id="bootpred_+3A_y">y</code></td>
<td>
<p>a vector containing the response values</p>
</td></tr>
<tr><td><code id="bootpred_+3A_nboot">nboot</code></td>
<td>
<p>the number of bootstrap replications</p>
</td></tr>
<tr><td><code id="bootpred_+3A_theta.fit">theta.fit</code></td>
<td>
<p>function to be cross-validated. Takes <code>x</code> and
<code>y</code> as an argument. See example below.</p>
</td></tr>
<tr><td><code id="bootpred_+3A_theta.predict">theta.predict</code></td>
<td>
<p>function producing predicted values for
<code>theta.fit</code>. Arguments are a matrix <code>x</code> of predictors and
fit object produced by <code>theta.fit</code>. See example below.</p>
</td></tr>
<tr><td><code id="bootpred_+3A_err.meas">err.meas</code></td>
<td>
<p>function specifying error measure for a single
response <code>y</code> and prediction <code>yhat</code>. See examples below</p>
</td></tr> 
<tr><td><code id="bootpred_+3A_...">...</code></td>
<td>
<p>any additional arguments to be passed to
<code>theta.fit</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>list with the following components
</p>
<table>
<tr><td><code>app.err</code></td>
<td>
<p>the apparent error rate - that is, the mean value of
<code>err.meas</code> when <code>theta.fit</code> is applied to <code>x</code> and
<code>y</code>, and then used to predict <code>y</code>.</p>
</td></tr> 
<tr><td><code>optim</code></td>
<td>
<p>the bootstrap estimate of optimism in <code>app.err</code>. A useful
estimate of prediction error is <code>app.err+optim</code></p>
</td></tr> 
<tr><td><code>err.632</code></td>
<td>
<p>the &quot;.632&quot; bootstrap estimate of prediction error.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>The deparsed call</p>
</td></tr>
</table>


<h3>References</h3>

<p>Efron, B. (1983). Estimating the error rate of a prediction rule:
improvements on cross-validation. J. Amer. Stat. Assoc, vol 78. pages
316-31. 
</p>
<p>Efron, B. and Tibshirani, R. (1993) An Introduction to the Bootstrap.
Chapman and Hall, New York, London.</p>


<h3>Examples</h3>

<pre><code class='language-R'># bootstrap prediction error estimation in least squares
#  regression
   x &lt;- rnorm(85)  
   y &lt;- 2*x +.5*rnorm(85)                      
   theta.fit &lt;- function(x,y){lsfit(x,y)}
   theta.predict &lt;- function(fit,x){
               cbind(1,x)%*%fit$coef         
               }    
   sq.err &lt;- function(y,yhat) { (y-yhat)^2}                   
   results &lt;- bootpred(x,y,20,theta.fit,theta.predict,
     err.meas=sq.err)  
                                      
# for a classification problem, a standard choice 
# for err.meas would simply count up the
#  classification errors:
    miss.clas &lt;- function(y,yhat){ 1*(yhat!=y)}
# with this specification,  bootpred estimates 
#  misclassification rate
</code></pre>

<hr>
<h2 id='bootstrap'>Non-Parametric Bootstrapping</h2><span id='topic+bootstrap'></span>

<h3>Description</h3>

<p>See Efron and Tibshirani (1993) for details on this
function.</p>


<h3>Usage</h3>

<pre><code class='language-R'>    bootstrap(x,nboot,theta,..., func=NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bootstrap_+3A_x">x</code></td>
<td>
<p>a vector containing the data. To bootstrap more complex data
structures (e.g. bivariate data) see the last example below.</p>
</td></tr>
<tr><td><code id="bootstrap_+3A_nboot">nboot</code></td>
<td>
<p>The number of bootstrap samples desired.</p>
</td></tr>
<tr><td><code id="bootstrap_+3A_theta">theta</code></td>
<td>
<p>function to be bootstrapped. Takes <code>x</code> as an argument, and
may take additional arguments (see below and last example).</p>
</td></tr>
<tr><td><code id="bootstrap_+3A_...">...</code></td>
<td>
<p>any additional arguments to be passed to <code>theta</code></p>
</td></tr>
<tr><td><code id="bootstrap_+3A_func">func</code></td>
<td>
<p>(optional) argument specifying the functional the
distribution of thetahat that is desired. 
If func is specified, the jackknife after-bootstrap estimate of 
its standard
error is also returned. See example below.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>list with the following components:
</p>
<table>
<tr><td><code>thetastar</code></td>
<td>
<p>the <code>nboot</code> bootstrap values of <code>theta</code></p>
</td></tr>
<tr><td><code>func.thetastar</code></td>
<td>
<p>the functional <code>func</code> of the bootstrap
distribution of thetastar, if <code>func</code> was specified</p>
</td></tr> 
<tr><td><code>jack.boot.val</code></td>
<td>
<p>the jackknife-after-bootstrap values for <code>func</code>, 
if <code>func</code> was specified</p>
</td></tr>
<tr><td><code>jack.boot.se</code></td>
<td>
<p>the jackknife-after-bootstrap standard error
estimate of <code>func</code>, if <code>func</code> was specified</p>
</td></tr> 
<tr><td><code>call</code></td>
<td>
<p>the deparsed call</p>
</td></tr>
</table>


<h3>References</h3>

<p>Efron, B. and   Tibshirani, R. (1986).  The bootstrap
method for standard errors, confidence intervals,
and other measures of   statistical accuracy.
Statistical Science, Vol 1., No. 1, pp 1-35.
</p>
<p>Efron, B. (1992) Jackknife-after-bootstrap standard errors and
influence functions. J. Roy. Stat. Soc. B, vol 54, pages 83-127
</p>
<p>Efron, B. and Tibshirani, R. (1993) An Introduction to the Bootstrap.
Chapman and Hall, New York, London.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># 100 bootstraps of the sample mean 
# (this is for illustration;  since "mean" is  a 
# built in function, bootstrap(x,100,mean) would be simpler!)
    x &lt;- rnorm(20)                
    theta &lt;- function(x){mean(x)} 
                              
    results &lt;- bootstrap(x,100,theta)     
                             
# as above, but also estimate the 95th percentile   
# of the bootstrap dist'n of the mean, and         
# its jackknife-after-bootstrap  standard error    
                              
    perc95 &lt;- function(x){quantile(x, .95)}
                             
                             
    results &lt;-  bootstrap(x,100,theta, func=perc95)                                   
                                   
# To bootstrap functions of more complex data structures, 
# write theta so that its argument x
#  is the set of observation numbers  
#  and simply  pass as data to bootstrap the vector 1,2,..n. 
# For example, to bootstrap
# the correlation coefficient from a set of 15 data pairs:
   xdata &lt;- matrix(rnorm(30),ncol=2)
   n &lt;- 15
   theta &lt;- function(x,xdata){ cor(xdata[x,1],xdata[x,2]) }
   results &lt;- bootstrap(1:n,20,theta,xdata)
</code></pre>

<hr>
<h2 id='bootstrap-internal'>Internal functions of package bootstrap</h2><span id='topic+ctsub'></span><span id='topic+xinter'></span><span id='topic+yinter'></span>

<h3>Description</h3>

<p>Internal functions of package bootstrap.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ctsub(x, y, z)
xinter(x, y, z, increasing = TRUE)
yinter(x, y, z, increasing = TRUE)
</code></pre>


<h3>Details</h3>

<p>These are not to be called by the user.
</p>

<hr>
<h2 id='boott'>Bootstrap-t Confidence Limits</h2><span id='topic+boott'></span>

<h3>Description</h3>

<p>See Efron and Tibshirani (1993) for details on this
function.</p>


<h3>Usage</h3>

<pre><code class='language-R'>  boott(x,theta, ..., sdfun=sdfunboot, nbootsd=25, nboott=200,
        VS=FALSE, v.nbootg=100, v.nbootsd=25, v.nboott=200,
        perc=c(.001,.01,.025,.05,.10,.50,.90,.95,.975,.99,.999))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="boott_+3A_x">x</code></td>
<td>
<p>a vector containing the data. Nonparametric bootstrap sampling is
used. To bootstrap from more complex data structures (e.g.
bivariate data) see the last example below.</p>
</td></tr>
<tr><td><code id="boott_+3A_theta">theta</code></td>
<td>
<p>function to be bootstrapped. Takes <code>x</code> as an argument, and
may take additional arguments (see below and last example).</p>
</td></tr>
<tr><td><code id="boott_+3A_...">...</code></td>
<td>
<p>any additional arguments to be passed to <code>theta</code></p>
</td></tr>
<tr><td><code id="boott_+3A_sdfun">sdfun</code></td>
<td>
<p>optional name of function for computing standard
deviation of <code>theta</code> based on data <code>x</code>. Should be
of the form: <code>sdmean &lt;- function(x,nbootsd,theta,...)</code> where
<code>nbootsd</code> 
is a dummy argument that is not used. If <code>theta</code> is the mean,
for example, 
<code>sdmean &lt;- function(x,nbootsd,theta,...)</code> <br /> 
<code>{sqrt(var(x)/length(x))}</code> .
If <code>sdfun</code> is missing, then <code>boott</code> uses an inner
bootstrap loop to estimate the 
standard deviation of <code>theta(x)</code></p>
</td></tr>
<tr><td><code id="boott_+3A_nbootsd">nbootsd</code></td>
<td>
<p>The number of bootstrap samples used to estimate the
standard deviation of <code>theta(x)</code></p>
</td></tr> 
<tr><td><code id="boott_+3A_nboott">nboott</code></td>
<td>
<p>The number of bootstrap samples used to estimate the
distribution of the bootstrap T statistic. 
200 is a bare minimum and 1000 or more is needed for 
reliable  <code class="reqn">\alpha \%</code> confidence points, <code class="reqn">\alpha &gt; .95</code> say. 
Total number of bootstrap samples is 
<code>nboott*nbootsd</code>.</p>
</td></tr>
<tr><td><code id="boott_+3A_vs">VS</code></td>
<td>
<p>If <code>TRUE</code>, a variance stabilizing transformation is
estimated, 
and the interval is constructed on the transformed scale, and then
is mapped back to the original theta scale. 
This can improve both the statistical properties of the intervals and
speed up the computation. See the reference Tibshirani (1988) given below.
If <code>FALSE</code>, variance stabilization is not performed.</p>
</td></tr>
<tr><td><code id="boott_+3A_v.nbootg">v.nbootg</code></td>
<td>
<p>The number of bootstrap samples used to estimate the
variance stabilizing transformation g. 
Only used if <code>VS=TRUE</code>.</p>
</td></tr>
<tr><td><code id="boott_+3A_v.nbootsd">v.nbootsd</code></td>
<td>
<p>The number of bootstrap samples used to estimate the
standard deviation of <code>theta(x)</code>. 
Only used if <code>VS=TRUE</code>.</p>
</td></tr>
<tr><td><code id="boott_+3A_v.nboott">v.nboott</code></td>
<td>
<p>The number of bootstrap samples used to estimate the
distribution of 
the bootstrap T statistic. Only used if <code>VS=TRUE</code>. Total number of
bootstrap samples is <code>v.nbootg*v.nbootsd + v.nboott</code>.</p>
</td></tr> 
<tr><td><code id="boott_+3A_perc">perc</code></td>
<td>
<p>Confidence points desired.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>list with the following components:
</p>
<table>
<tr><td><code>confpoints</code></td>
<td>
<p>Estimated confidence points</p>
</td></tr>
<tr><td><code>theta</code>, <code>g</code></td>
<td>
<p><code>theta</code>
and <code>g</code> are only returned if <code>VS=TRUE</code> was
specified. <code>(theta[i],g[i]),  i=1,length(theta)</code> 
represents the estimate of the variance stabilizing transformation
<code>g</code> at the points
<code>theta[i]</code>.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>The deparsed call</p>
</td></tr>
</table>


<h3>References</h3>

<p>Tibshirani, R. (1988) &quot;Variance stabilization and the bootstrap&quot;. 
Biometrika (1988) vol 75
no 3 pages 433-44.
</p>
<p>Hall, P. (1988) Theoretical comparison of bootstrap confidence
intervals. Ann. Statisi. 16, 1-50.
</p>
<p>Efron, B. and Tibshirani, R. (1993) An Introduction to the Bootstrap.
Chapman and Hall, New York, London.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#  estimated confidence points for the mean
   x &lt;- rchisq(20,1)
   theta &lt;- function(x){mean(x)}
   results &lt;- boott(x,theta)
# estimated confidence points for the mean, 
#  using variance-stabilization bootstrap-T method
   results &lt;-  boott(x,theta,VS=TRUE)
   results$confpoints          # gives confidence points
# plot the estimated var stabilizing transformation
   plot(results$theta,results$g) 
# use standard formula for stand dev of mean
# rather than an inner bootstrap loop
   sdmean &lt;- function(x, ...) 
       {sqrt(var(x)/length(x))}
   results &lt;-  boott(x,theta,sdfun=sdmean) 
                                     
# To bootstrap functions of more  complex data structures, 
# write theta so that its argument x
#  is the set of observation numbers  
#  and simply  pass as data to boot the vector 1,2,..n. 
# For example, to bootstrap
# the correlation coefficient from a set of 15 data pairs:                              
    xdata &lt;- matrix(rnorm(30),ncol=2)
    n &lt;- 15
    theta &lt;- function(x, xdata){ cor(xdata[x,1],xdata[x,2]) }
    results &lt;- boott(1:n,theta, xdata)
</code></pre>

<hr>
<h2 id='cell'>  Cell Survival data </h2><span id='topic+cell'></span>

<h3>Description</h3>

<p>Data on cell survival under different radiation 
doses.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(cell)</code></pre>


<h3>Format</h3>

<p>A data frame with 14 observations on the following 2 variables.
</p>

<dl>
<dt>dose</dt><dd><p>a numeric vector, unit rads/100 </p>
</dd>
<dt>log.surv</dt><dd><p>a numeric vector, (natural) logarithm of proportion</p>
</dd>
</dl>



<h3>Details</h3>

<p>There are regression situations where the covariates are more naturally 
considered 
fixed rather than random. This cell survival data are an example. A 
radiologist has run
an experiment involving 14 bacterial plates. The plates where exposed to 
different 
doses of radiation, and the proportion of surviving cells measured. 
Greater doses lead to
smaller survival proportions, as would be expected. The investigator 
expressed some 
doubt as to the validity of observation 13. 
</p>
<p>So there is some interest as to the influence of observation 13 on the 
conclusions.
</p>
<p>Two different theoretical models as to radiation damage were available, 
one predicting 
a linear regresion, 
</p>
<p style="text-align: center;"><code class="reqn">\mu_i = \mbox{E}(y_i \vert z_i) = \beta_1 z_i</code>
</p>

<p>and the other predicting a quadratic regression,
</p>
<p style="text-align: center;"><code class="reqn">\mu_i = \mbox{E}(y_i \vert z_i) = \beta_1 z_i+\beta_2 z_i^2</code>
</p>

<p>Hypothesis tests on <code class="reqn">\beta_2</code> is of interest.
</p>


<h3>Source</h3>

<p>Efron, B. and Tibshirani, R. (1993) An Introduction to the Bootstrap.
Chapman and Hall, New York, London.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>plot(cell[,2:1],pch=c(rep(1,12),17,1),
                col=c(rep("black",12),"red", "black"),
                cex=c(rep(1,12), 2, 1))
</code></pre>

<hr>
<h2 id='cholost'> The Cholostyramine Data  </h2><span id='topic+cholost'></span>

<h3>Description</h3>

<p><code class="reqn">n=164</code> men took part in an experiment to see if the 
drug cholostyramine
lowered blood cholesterol levels.  The men were supposed to take six 
packets of 
cholostyramine per day, but many actually took much less.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(cholost)</code></pre>


<h3>Format</h3>

<p>A data frame with 164 observations on the following 2 variables.
</p>

<dl>
<dt>z</dt><dd><p>Compliance, a numeric vector</p>
</dd>
<dt>y</dt><dd><p>Improvement, a numeric vector</p>
</dd>
</dl>



<h3>Details</h3>

<p>In the book, this is used as an example for curve fitting, with two 
methods, 
traditional least-squares fitting and modern <code><a href="stats.html#topic+loess">loess</a></code>. 
In the book 
is considered linear and polynomial models for the dependence of 
Improvement 
upon Compliance.
</p>


<h3>Source</h3>

<p>Efron, B. and Tibshirani, R. (1993) An Introduction to the Bootstrap. 
Chapman and Hall, New York, London.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>str(cholost)
summary(cholost)
plot(y ~ z, data=cholost, xlab="Compliance", 
            ylab="Improvement")
abline(lm(y ~ z, data=cholost), col="red")
</code></pre>

<hr>
<h2 id='crossval'>K-fold Cross-Validation</h2><span id='topic+crossval'></span>

<h3>Description</h3>

<p>See Efron and Tibshirani (1993) for details on this
function.</p>


<h3>Usage</h3>

<pre><code class='language-R'>   crossval(x, y, theta.fit, theta.predict, ..., ngroup=n)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="crossval_+3A_x">x</code></td>
<td>
<p>a matrix containing the predictor (regressor) values. Each row
corresponds to an observation.</p>
</td></tr>
<tr><td><code id="crossval_+3A_y">y</code></td>
<td>
<p>a vector containing the response values</p>
</td></tr>
<tr><td><code id="crossval_+3A_theta.fit">theta.fit</code></td>
<td>
<p>function to be cross-validated. Takes <code>x</code> and
<code>y</code> as an argument. See example below.</p>
</td></tr>
<tr><td><code id="crossval_+3A_theta.predict">theta.predict</code></td>
<td>
<p>function producing predicted values for
<code>theta.fit</code>.
Arguments are a matrix <code class="reqn">x</code> of predictors and fit object 
produced by theta.fit.
See example below.</p>
</td></tr>
<tr><td><code id="crossval_+3A_...">...</code></td>
<td>
<p>any additional arguments to be passed to theta.fit</p>
</td></tr>
<tr><td><code id="crossval_+3A_ngroup">ngroup</code></td>
<td>
<p>optional argument specifying the number of  groups formed .
Default is <code>ngroup</code>=sample size, corresponding to leave-one out
cross-validation.</p>
</td></tr> 
</table>


<h3>Value</h3>

<p>list with the following components
</p>
<table>
<tr><td><code>cv.fit</code></td>
<td>
<p>The  cross-validated fit for each observation.  The
numbers 1 to n (the sample size) are  partitioned into <code>ngroup</code>
mutually disjoint 
groups  of size &quot;leave.out&quot;.  leave.out, the number of observations in
each group, is the integer part of n/ngroup.  The groups are chosen
at random if ngroup &lt; n.  (If n/leave.out is not an integer, the last
group will contain &gt; leave.out observations).  Then theta.fit is applied
with the kth group of observations deleted, for k=1, 2, ngroup.
Finally, the fitted value is computed for the kth group using
<code>theta.predict</code>.</p>
</td></tr> 
<tr><td><code>ngroup</code></td>
<td>
<p>The number of groups</p>
</td></tr>
<tr><td><code>leave.out</code></td>
<td>
<p>The number of observations in each group</p>
</td></tr>
<tr><td><code>groups</code></td>
<td>
<p>A list of length ngroup containing the indices of the
observations 
in each group. Only returned if <code>leave.out &gt; 1</code>.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>The deparsed call</p>
</td></tr>
</table>


<h3>References</h3>

<p>Stone, M. (1974).  Cross-validation choice and assessment of
statistical predictions. Journal of the Royal Statistical Society,
B-36, 111&ndash;147.
</p>
<p>Efron, B. and Tibshirani, R. (1993) An Introduction to the Bootstrap.
Chapman and Hall, New York, London.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># cross-validation of least squares regression
# note that crossval is not very efficient, and being a
#  general purpose function, it does not use the
# Sherman-Morrison identity for this special case
   x &lt;- rnorm(85)  
   y &lt;- 2*x +.5*rnorm(85)                      
   theta.fit &lt;- function(x,y){lsfit(x,y)}
   theta.predict &lt;- function(fit,x){
               cbind(1,x)%*%fit$coef         
               }                       
   results &lt;- crossval(x,y,theta.fit,theta.predict,ngroup=6)  
                                      
</code></pre>

<hr>
<h2 id='diabetes'> Blood Measurements on 43 Diabetic Children   </h2><span id='topic+diabetes'></span>

<h3>Description</h3>

<p>Measurements on 43 diabetic children of log-Cpeptide (a blood measurement)
and age (in years). Interest is predicting the blood measurement from age. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(diabetes)</code></pre>


<h3>Format</h3>

<p>A data frame with 43 observations on the following 3 variables.
</p>

<dl>
<dt>obs</dt><dd><p>a numeric vector</p>
</dd>
<dt>age</dt><dd><p>a numeric vector</p>
</dd>
<dt>logCpeptide</dt><dd><p>a numeric vector</p>
</dd>
</dl>



<h3>Source</h3>

<p>Efron, B. and Tibshirani, R. (1993) An Introduction to the Bootstrap. 
Chapman and Hall, New York, London.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>plot(logCpeptide ~ age, data=diabetes)
</code></pre>

<hr>
<h2 id='hormone'> Hormone Data from page 107  </h2><span id='topic+hormone'></span>

<h3>Description</h3>

<p>The hormone data. Amount in milligrams of anti-inflammatory hormone
remaining in 27 devices, after a certain number of hours (hrs)
of wear.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(hormone)</code></pre>


<h3>Format</h3>

<p>A data frame with 27 observations on the following 3 variables.
</p>

<dl>
<dt>Lot</dt><dd><p>a character vector</p>
</dd>
<dt>hrs</dt><dd><p>a numeric vector</p>
</dd>
<dt>amount</dt><dd><p>a numeric vector</p>
</dd>
</dl>



<h3>Details</h3>

<p>The hormone data. Amount in milligrams of anti-inflammatory hormone
remaining in 27 devices, after a certain number of hours (hrs)
of wear. The devices were sampled from 3 different manufacturing lots, 
called A, B and C. Lot C looks like it had greater amounts of
remaining hormone, but it also was worn the least number of hours. 
</p>
<p>The book uses this as an example for regression analysis. 
</p>


<h3>Source</h3>

<p>Efron, B. and Tibshirani, R. (1993) An Introduction to the Bootstrap. 
Chapman and Hall, New York, London.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>str(hormone) 
if(interactive())par(ask=TRUE)
with(hormone, stripchart(amount ~ Lot))
with(hormone, plot(amount ~ hrs, pch=Lot))
abline( lm(amount ~ hrs, data=hormone, col="red2"))
</code></pre>

<hr>
<h2 id='jackknife'>Jackknife Estimation</h2><span id='topic+jackknife'></span>

<h3>Description</h3>

<p>See Efron and Tibshirani (1993) for details on this
function.</p>


<h3>Usage</h3>

<pre><code class='language-R'>   jackknife(x, theta, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="jackknife_+3A_x">x</code></td>
<td>
<p>a vector containing the data. To jackknife  more complex data
structures (e.g. bivariate data) see the last example below.</p>
</td></tr>
<tr><td><code id="jackknife_+3A_theta">theta</code></td>
<td>
<p>function to be jackknifed. Takes <code>x</code> as an argument, and
may take additional arguments (see below and last example).</p>
</td></tr>
<tr><td><code id="jackknife_+3A_...">...</code></td>
<td>
<p>any additional arguments to be passed to <code>theta</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>list with the following components
</p>
<table>
<tr><td><code>jack.se</code></td>
<td>
<p>The jackknife estimate of standard error of <code>theta</code>.
The leave-one out jackknife is used.</p>
</td></tr>
<tr><td><code>jack.bias</code></td>
<td>
<p>The jackknife estimate of bias of <code>theta</code>.
The leave-one out jackknife is used.</p>
</td></tr>
<tr><td><code>jack.values</code></td>
<td>
<p>The n leave-one-out values of <code>theta</code>, 
where n is the number of observations.
That is, <code>theta</code> applied to <code>x</code> with
the 1st observation deleted, <code>theta</code> applied to <code>x</code> with
the 2nd observation deleted, etc.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>The deparsed call</p>
</td></tr>
</table>


<h3>References</h3>

<p>Efron, B. and   Tibshirani, R. (1986).  The Bootstrap
Method for standard errors, confidence intervals,
and other measures of   statistical accuracy.
Statistical Science, Vol 1., No. 1, pp 1-35.
</p>
<p>Efron, B. and Tibshirani, R. (1993) An Introduction to the Bootstrap.
Chapman and Hall, New York, London.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># jackknife values for the sample mean 
# (this is for illustration;  # since "mean" is  a 
#  built in function,  jackknife(x,mean) would be simpler!)
   x &lt;- rnorm(20)               
   theta &lt;- function(x){mean(x)}
                             
   results &lt;- jackknife(x,theta)        
                              
# To jackknife functions of more  complex data structures, 
# write theta so that its argument x
#  is the set of observation numbers  
#  and simply  pass as data to jackknife the vector 1,2,..n. 
# For example, to jackknife
# the correlation coefficient from a set of 15 data pairs:      
                        
   xdata &lt;- matrix(rnorm(30),ncol=2)
   n &lt;- 15
   theta &lt;- function(x,xdata){ cor(xdata[x,1],xdata[x,2]) }
   results &lt;- jackknife(1:n,theta,xdata)
</code></pre>

<hr>
<h2 id='law'>  Law school data from Efron and Tibshirani </h2><span id='topic+law'></span>

<h3>Description</h3>

<p>The law school data. A random sample of size <code class="reqn">n=15</code> from the 
universe of 82 USA law schools. Two measurements: <abbr><span class="acronym">LSAT</span></abbr> 
(average score on 
a national law test) and <abbr><span class="acronym">GPA</span></abbr> (average undergraduate 
grade-point average).
<code><a href="#topic+law82">law82</a></code> contains data for the whole universe of 82 law schools.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>        data(law)
</code></pre>


<h3>Format</h3>

<p>A data frame with 15 observations on the following 2 variables.
</p>

<dl>
<dt>LSAT</dt><dd><p>a numeric vector</p>
</dd>
<dt>GPA</dt><dd><p>a numeric vector</p>
</dd>
</dl>



<h3>Details</h3>

<p>In the book for which this package is support software, this example
is used to bootstrap the correlation coefficient.
</p>


<h3>Source</h3>

<p>Efron, B. and Tibshirani, R. (1993) An Introduction to the Bootstrap.
Chapman and Hall, New York, London.
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+law82">law82</a></code>. </p>


<h3>Examples</h3>

<pre><code class='language-R'>str(law)
if(interactive())par(ask=TRUE)
plot(law)
theta &lt;- function(ind) cor(law[ind,1], law[ind,2])
theta(1:15) # sample estimate
law.boot &lt;- bootstrap(1:15, 2000, theta)
sd(law.boot$thetastar) # bootstrap standard error
hist(law.boot$thetastar)
# bootstrap t confidence limits for the correlation coefficient:
theta &lt;- function(ind) cor(law[ind,1], law[ind,2])
boott(1:15, theta, VS=FALSE)$confpoints
boott(1:15, theta, VS=TRUE)$confpoints
# Observe the difference! See page 162 of the book. 
# abcnon(as.matrix(law), function(p,x) cov.wt(x, p, cor=TRUE)$cor[1,2]  )$limits
# The above cannot be used, as the resampling vector can take negative values! 
</code></pre>

<hr>
<h2 id='law82'>  Data for Universe of USA Law Schools  </h2><span id='topic+law82'></span>

<h3>Description</h3>

<p>This is the universe of 82 USA law schools for which the data frame
<code><a href="#topic+law">law</a></code> provides a sample of size <code class="reqn">15</code>. See documentation for 
<code><a href="#topic+law">law</a></code> for more details.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(law82)</code></pre>


<h3>Format</h3>

<p>A data frame with 82 observations on the following 3 variables.
</p>

<dl>
<dt>School</dt><dd><p>a numeric vector</p>
</dd>
<dt>LSAT</dt><dd><p>a numeric vector</p>
</dd>
<dt>GPA</dt><dd><p>a numeric vector</p>
</dd>
</dl>



<h3>Source</h3>

<p>Efron, B. and Tibshirani, R. (1993) An Introduction to the Bootstrap.
Chapman and Hall, New York, London.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>plot(law82[,2:3])
cor(law82[,2:3])
</code></pre>

<hr>
<h2 id='lutenhorm'> Luteinizing Hormone   </h2><span id='topic+lutenhorm'></span>

<h3>Description</h3>

<p>Five sets of levels of luteinizing hormone for each of 48 time periods
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(lutenhorm)</code></pre>


<h3>Format</h3>

<p>A data frame with 48 observations on the following 5 variables.
</p>

<dl>
<dt>V1</dt><dd><p>a numeric vector</p>
</dd>
<dt>V2</dt><dd><p>a numeric vector</p>
</dd>
<dt>V3</dt><dd><p>a numeric vector</p>
</dd>
<dt>V4</dt><dd><p>a numeric vector</p>
</dd>
<dt>V5</dt><dd><p>a numeric vector</p>
</dd>
</dl>



<h3>Details</h3>

<p>Five sets of levels of luteinizing hormone for each of 48 time periods, 
taken from Diggle (1990). These are hormone levels measured on a
healty woman in 10 minute intervals over a period of 8 hours. The luteinizing
hormone is one of the hormones that orchestrate the menstrual cycle
and hence it is important to understand its daily variation.  
</p>
<p>This is a time series. The book gives only one time series, which 
correspond to <code>V4</code>. I don't know what are the other four series, 
the book does'nt mention them. They could be block bootstrap 
replicates?
</p>


<h3>Source</h3>

<p>Efron, B. and Tibshirani, R. (1993) An Introduction to the Bootstrap. 
Chapman and Hall, New York, London.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>str(lutenhorm) 
matplot(lutenhorm)
</code></pre>

<hr>
<h2 id='mouse.c'> Experiments with mouse    </h2><span id='topic+mouse.c'></span>

<h3>Description</h3>

<p>A small randomized experiment were done with 16 mouse, 7 to treatment group
and 9 to control group. Treatment was intended to prolong survival 
after a test surgery.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(mouse.c)</code></pre>


<h3>Format</h3>

<p>The format is:
num [1:9] 52 104 146 10 50 31 40 27 46
</p>


<h3>Details</h3>

<p>The treatment group is is dataset <code><a href="#topic+mouse.t">mouse.t</a></code>. <code>mouse.c</code>
is the control group. The book uses this example to illustrate 
bootstrapping a sample mean. Measurement unit is days of survival following
surgery.
</p>


<h3>Source</h3>

<p>Efron, B. and Tibshirani, R. (1993) An Introduction to the Bootstrap. 
Chapman and Hall, New York, London.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>str(mouse.c)
if(interactive())par(ask=TRUE)
stripchart(list(treatment=mouse.t, control=mouse.c))
cat("bootstrapping the difference of means, treatment - control:\n")
cat("bootstrapping is done independently for the two groups\n")
mouse.boot.c &lt;- bootstrap(mouse.c, 2000, mean)
mouse.boot.t &lt;- bootstrap(mouse.t, 2000, mean)
mouse.boot.diff &lt;- mouse.boot.t$thetastar - mouse.boot.c$thetastar
hist(mouse.boot.diff)
abline(v=0, col="red2")
sd(mouse.boot.diff)
</code></pre>

<hr>
<h2 id='mouse.t'> Experiment with mouse     </h2><span id='topic+mouse.t'></span>

<h3>Description</h3>

<p>A small randomized experiment were done with 16 mouse, 7 to treatment group
and 9 to control group. Treatment was intended to prolong survival 
after a test surgery.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(mouse.t)</code></pre>


<h3>Format</h3>

<p>The format is:
num [1:7] 94 197 16 38 99 141 23
</p>


<h3>Details</h3>

<p>The control group is dataset <code><a href="#topic+mouse.c">mouse.c</a></code>. This dataset is 
the treatment group. The book uses this for exemplifying bootstrapping
the sample mean. Measurement unit is days of survival following
surgery.
</p>


<h3>Source</h3>

<p>Efron, B. and Tibshirani, R. (1993) An Introduction to the Bootstrap. 
Chapman and Hall, New York, London.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>str(mouse.t)
stripchart(list(treatment=mouse.t, control=mouse.c))
</code></pre>

<hr>
<h2 id='patch'>  The Patch Data  </h2><span id='topic+patch'></span>

<h3>Description</h3>

<p>Eight subjects wore medical patches designed to infuse a naturally-occuring
hormone into the blood stream.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(patch)</code></pre>


<h3>Format</h3>

<p>A data frame with 8 observations on the following 6 variables.
</p>

<dl>
<dt>subject</dt><dd><p>a numeric vector</p>
</dd>
<dt>placebo</dt><dd><p>a numeric vector</p>
</dd>
<dt>oldpatch</dt><dd><p>a numeric vector</p>
</dd>
<dt>newpatch</dt><dd><p>a numeric vector</p>
</dd>
<dt>z</dt><dd><p>a numeric vector, oldpatch - placebo</p>
</dd>
<dt>y</dt><dd><p>a numeric vector, newpatch - oldpatch</p>
</dd>
</dl>



<h3>Details</h3>

<p>Eight subjects wore medical patches designed to infuse a certain
naturally-occuring hormone into the blood stream. Each subject had his
blood levels of the hormone measured after wearing three different patches:
a placebo patch, an &quot;old&quot; patch manufactured at an older plant, and a
&quot;new&quot; patch manufactured at a newly opened plant. 
</p>
<p>The purpose of the study was to show <em>bioequivalence</em>. Patchs from the
old plant was already approved for sale by the FDA (food and drug 
administration). Patches from the new facility would not need a full new
approval, if they could be shown bioequivalent to the patches from 
the old plant. 
</p>
<p>Bioequivalence was defined as 
</p>
<p style="text-align: center;"><code class="reqn">\frac{|E(\mbox{new}) - E(\mbox{old})|}{ E(\mbox{old})-E(\mbox{placebo})}
           \le .20</code>
</p>

<p>The book uses this to investigate bias of ratio estimation.
</p>


<h3>Source</h3>

<p>Efron, B. and Tibshirani, R. (1993) An Introduction to the Bootstrap. 
Chapman and Hall, New York, London.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>str(patch) 
 theta &lt;- function(ind){
      Y &lt;- patch[ind,"y"]
      Z &lt;- patch[ind,"z"]
      mean(Y)/mean(Z) }
patch.boot &lt;- bootstrap(1:8, 2000, theta)
names(patch.boot)          
hist(patch.boot$thetastar)
abline(v=c(-0.2, 0.2), col="red2")
theta(1:8) #sample plug-in estimator
abline(v=theta(1:8) , col="blue")
# The bootstrap bias estimate:
mean(patch.boot$thetastar) - theta(1:8)
sd(patch.boot$thetastar) # bootstrapped standard error
</code></pre>

<hr>
<h2 id='Rainfall'> Rainfall Data   </h2><span id='topic+Rainfall'></span>

<h3>Description</h3>

<p>raifall data. The yearly rainfall, in inches, in Nevada City, 
California, USA, 1873 through 1978.
An example of time series data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(Rainfall)</code></pre>


<h3>Format</h3>

<p>The format is:
Time-Series [1:106] from 1873 to 1978: 80 40 65 46 68 32 58 60 61 60 ...
</p>


<h3>Source</h3>

<p>Efron, B. and Tibshirani, R. (1993) An Introduction to the Bootstrap. 
Chapman and Hall, New York, London.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>str(Rainfall)  
plot(Rainfall) 
</code></pre>

<hr>
<h2 id='scor'> Open/Closed Book Examination Data    </h2><span id='topic+scor'></span>

<h3>Description</h3>

<p>This is data form mardia, Kent and Bibby on 88 students who took
examinations in 5 subjects. Some where with open book and other with 
closed book.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(scor)</code></pre>


<h3>Format</h3>

<p>A data frame with 88 observations on the following 5 variables.
</p>

<dl>
<dt>mec</dt><dd><p>mechanics, closed book note</p>
</dd>
<dt>vec</dt><dd><p>vectors, closed book note</p>
</dd>
<dt>alg</dt><dd><p>algebra, open book note</p>
</dd>
<dt>ana</dt><dd><p>analysis, open book note</p>
</dd>
<dt>sta</dt><dd><p>statistics, open book note</p>
</dd>
</dl>



<h3>Details</h3>

<p>The book uses this for bootstrap in principal component analysis.
</p>


<h3>Source</h3>

<p>Efron, B. and Tibshirani, R. (1993) An Introduction to the Bootstrap. 
Chapman and Hall, New York, London.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>str(scor) 
if(interactive())par(ask=TRUE)
plot(scor) 
# The parameter of interest (theta) is the fraction of variance explained 
# by the first principal component.
# For principal components analysis svd is better numerically than 
# eigen-decomposistion, but for bootstrapping the latter is _much_ faster.
theta &lt;- function(ind) {
   vals &lt;- eigen(var(scor[ind,]), symmetric=TRUE, only.values=TRUE)$values
   vals[1] / sum(vals) }
scor.boot &lt;- bootstrap(1:88, 500, theta)
sd(scor.boot$thetastar) # bootstrap standard error
hist(scor.boot$thetastar)
abline(v=theta(1:88), col="red2")
abline(v=mean(scor.boot$thetastar), col="blue")
</code></pre>

<hr>
<h2 id='spatial'> Spatial Test Data    </h2><span id='topic+spatial'></span>

<h3>Description</h3>

<p>Twenty-six neurologically impaired children have each taken two tests
of spatial perception, called &quot;A&quot; and &quot;B&quot;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(spatial)</code></pre>


<h3>Format</h3>

<p>A data frame with 26 observations on the following 2 variables.
</p>

<dl>
<dt>A</dt><dd><p>a numeric vector</p>
</dd>
<dt>B</dt><dd><p>a numeric vector</p>
</dd>
</dl>



<h3>Details</h3>

<p>In the book this is used as a test data set for bootstrapping 
confidence intervals. 
</p>


<h3>Source</h3>

<p>Efron, B. and Tibshirani, R. (1993) An Introduction to the Bootstrap. 
Chapman and Hall, New York, London.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>str(spatial)
plot(spatial) 
abline(0,1, col="red2")
</code></pre>

<hr>
<h2 id='stamp'> Data on Thickness of Stamps  </h2><span id='topic+stamp'></span>

<h3>Description</h3>

<p>Thickness in millimeters of 485 postal stamps, printed in 1872. The stamp 
issue of that year was thought to be a &quot;philatelic mixture&quot;, 
that is, printed 
on more than one type of paper. It is of historical interest to determine
how many different types of paper were used. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(stamp)</code></pre>


<h3>Format</h3>

<p>A data frame with 485 observations on the following variable.
</p>

<dl>
<dt>Thickness</dt><dd><p>Thickness in millimeters, a numeric vector</p>
</dd>
</dl>



<h3>Details</h3>

<p>In the book, this is used to exemplify determination of number of modes. 
It is also
used for kernel density estimation.
</p>


<h3>Note</h3>

<p>The main example in the book is on page 227. See also the 
CRAN package diptest for an alternative method.
</p>


<h3>Source</h3>

<p>Efron, B. and Tibshirani, R. (1993) An Introduction to the Bootstrap. 
Chapman and Hall, New York, London.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>summary(stamp)
with(stamp, {hist(Thickness);
             plot(density(Thickness), add=TRUE)})
</code></pre>

<hr>
<h2 id='tooth'> Tooth Strength Data</h2><span id='topic+tooth'></span>

<h3>Description</h3>

<p>Thirteen accident victims have had the strength of their teeth measured, 
It is desired to predict teeth strength from measurements not requiring
destructive testing. Four such bvariables have been obtained for 
each subject, (<code>D1</code>,<code>D2</code>) are difficult to obtain, 
(<code>E1</code>,<code>E2</code>) are easy to obtain.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(tooth)</code></pre>


<h3>Format</h3>

<p>A data frame with 13 observations on the following 6 variables.
</p>

<dl>
<dt>patient</dt><dd><p>a numeric vector</p>
</dd>
<dt>D1</dt><dd><p>a numeric vector</p>
</dd>
<dt>D2</dt><dd><p>a numeric vector</p>
</dd>
<dt>E1</dt><dd><p>a numeric vector</p>
</dd>
<dt>E2</dt><dd><p>a numeric vector</p>
</dd>
<dt>strength</dt><dd><p>a numeric vector</p>
</dd>
</dl>



<h3>Details</h3>

<p>Do the easy to obtain variables give as good prediction as the difficult 
to obtain ones?
</p>


<h3>Source</h3>

<p>Efron, B. and Tibshirani, R. (1993) An Introduction to the Bootstrap. 
Chapman and Hall, New York, London.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>str(tooth)
mod.easy &lt;-  lm(strength ~ E1+E2, data=tooth)
mod.diffi &lt;- lm(strength ~ D1+D2, data=tooth)
summary(mod.easy)
summary(mod.diffi)
if(interactive())par(ask=TRUE)
theta &lt;- function(ind) {
    easy &lt;- lm(strength ~ E1+E2, data=tooth, subset=ind)
    diffi&lt;- lm(strength ~ D1+D2, data=tooth, subset=ind)
    (sum(resid(easy)^2) - sum(resid(diffi)^2))/13   }
tooth.boot &lt;- bootstrap(1:13, 2000, theta)
hist(tooth.boot$thetastar)
abline(v=0, col="red2") 
qqnorm(tooth.boot$thetastar)
qqline(tooth.boot$thetastar, col="red2")
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
