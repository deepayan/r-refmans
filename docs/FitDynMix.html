<!DOCTYPE html><html><head><title>Help for package FitDynMix</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {FitDynMix}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#AMLEfit'><p>Estimating a dynamic mixture via AMLE</p></a></li>
<li><a href='#AMLEmode'><p>Approximating the mode of a multivariate empirical distribution</p></a></li>
<li><a href='#CENoisyFit'><p>Cross-Entropy estimation</p></a></li>
<li><a href='#CENoisyFitBoot'><p>Cross-Entropy estimation and bootstrap standard errors</p></a></li>
<li><a href='#cvm_stat_M'><p>Computing the Cramér - von Mises distance between two samples</p></a></li>
<li><a href='#ddyn'><p>Density of a Lognormal-GPD dynamic mixture</p></a></li>
<li><a href='#dynloglik'><p>Log-likelihood of a Lognormal-GPD dynamic mixture</p></a></li>
<li><a href='#dynloglikMC'><p>Log-likelihood of a Lognormal-GPD dynamic mixture</p></a></li>
<li><a href='#Metro2019'><p>Population estimate of the US metropolitan areas</p></a></li>
<li><a href='#MLEBoot'><p>Bootstrap standard errors of MLEs</p></a></li>
<li><a href='#MLEfit'><p>Estimating a dynamic mixture via MLE</p></a></li>
<li><a href='#nConst_MC'><p>Monte carlo approximation of the normalizing constant of a Lognormal-GPD dynamic mixture</p></a></li>
<li><a href='#rDynMix'><p>Simulating a dynamic lognormal-Pareto mixture</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Title:</td>
<td>Estimation of Dynamic Mixtures</td>
</tr>
<tr>
<td>Version:</td>
<td>1.0.0</td>
</tr>
<tr>
<td>Description:</td>
<td>Estimation of a dynamic lognormal - Generalized Pareto mixture via the Approximate Maximum Likelihood and the Cross-Entropy methods. See Bee, M. (2023) &lt;<a href="https://doi.org/10.1016%2Fj.csda.2023.107764">doi:10.1016/j.csda.2023.107764</a>&gt;.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 2.10)</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>RdMacros:</td>
<td>Rdpack</td>
</tr>
<tr>
<td>Imports:</td>
<td>evir, MASS, pracma, Rdpack, parallel, ks, stats, graphics</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/marco-bee/FitDynMix">https://github.com/marco-bee/FitDynMix</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/marco-bee/FitDynMix/issues">https://github.com/marco-bee/FitDynMix/issues</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-01-11 12:38:05 UTC; marco.bee</td>
</tr>
<tr>
<td>Author:</td>
<td>Marco Bee <a href="https://orcid.org/0000-0002-9579-3650"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut,
    cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Marco Bee &lt;marco.bee@unitn.it&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-01-11 13:00:03 UTC</td>
</tr>
</table>
<hr>
<h2 id='AMLEfit'>Estimating a dynamic mixture via AMLE</h2><span id='topic+AMLEfit'></span>

<h3>Description</h3>

<p>This function fits a dynamic mixture via Approximate Maximum Likelihood.
Currently only implemented for the lognormal - generalized Pareto case,
with Cauchy or exponential weight.
The bootstrap estimation of the standard errors of the MLEs (used for finding
the supports of the uniform priors) is carried out via parallel computing.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>AMLEfit(yObs, epsilon, k, bootreps, intTol = 1e-04, weight)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="AMLEfit_+3A_yobs">yObs</code></td>
<td>
<p>numerical vector: observed sample.</p>
</td></tr>
<tr><td><code id="AMLEfit_+3A_epsilon">epsilon</code></td>
<td>
<p>non-negative scalar: scale parameter of the Markov kernel.</p>
</td></tr>
<tr><td><code id="AMLEfit_+3A_k">k</code></td>
<td>
<p>non-negative integer: number of samples generated in the AMLE
approach, such that k*epsilon = ABC sample size.</p>
</td></tr>
<tr><td><code id="AMLEfit_+3A_bootreps">bootreps</code></td>
<td>
<p>positive integer: number of bootstrap replications.</p>
</td></tr>
<tr><td><code id="AMLEfit_+3A_inttol">intTol</code></td>
<td>
<p>non-negative scalar: threshold for stopping the computation of the integral in the normalization
constant: if the integral on the interval from n-1 to n is smaller than intTol, the approximation procedure stops.</p>
</td></tr>
<tr><td><code id="AMLEfit_+3A_weight">weight</code></td>
<td>
<p>'cau' or 'exp': name of weight distribution.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For the lognormal and GPD parameters, the support of the uniform
prior is set equal to the 99% confidence interval of the bootstrap
distribution after discarding the outliers.
For the Cauchy parameters, the support is given by the range of the
bootstrap distribution after discarding the outliers.
Be aware that computing times are large when k and/or bootreps are large.
</p>


<h3>Value</h3>

<p>A list with the following elements:
</p>
<p>AMLEpars a list of four 6 or 5-dimensional vectors: approximate maximum likelihood estimates computed via sample mean,
maxima of the marginal kernel densities, maximum of the multivariate kernel densities,
maximum of the product of the marginal kernel densities.
</p>
<p>ABCsam ((k x epsilon) x nc) matrix: ABC sample, where nc is 6 or 5, according to the weight.
</p>
<p>MLEpars (np x 1) vector: maximum likelihood estimates and
maximized log-likelihood, where np is 7 or 6, according to the weight.
</p>
<p>MLEboot (bootreps x nc) matrix: maximum likelihood estimates obtained in
each bootstrap replication. nc is 6 or 5, according to the weight.
</p>


<h3>References</h3>


<p>Bee M (2023).
&ldquo;Unsupervised mixture estimation via approximate maximum likelihood based on the Cramér - von Mises distance.&rdquo;
<em>Computational Statistics &amp; Data Analysis</em>, <b>185</b>, 107764.

</p>


<h3>See Also</h3>

<p><code><a href="#topic+AMLEmode">AMLEmode</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>k &lt;- 5000
epsilon &lt;- .02
bootreps &lt;- 2
res = AMLEfit(Metro2019, epsilon, k, bootreps, , 'cau')
</code></pre>

<hr>
<h2 id='AMLEmode'>Approximating the mode of a multivariate empirical distribution</h2><span id='topic+AMLEmode'></span>

<h3>Description</h3>

<p>This function approximates the mode of a multivariate empirical distribution by means of:
</p>

<ol>
<li><p> the sample mean
</p>
</li>
<li><p> the product of the maxima of the univariate kernel densities estimated using the marginals
</p>
</li>
<li><p> the maximum of the multivariate kernel density
</p>
</li>
<li><p> the maximum of the product of the univariate kernel densities
Typically used in connection with AMLEfit (see AMLEfit for examples).
</p>
</li></ol>



<h3>Usage</h3>

<pre><code class='language-R'>AMLEmode(ABCsam)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="AMLEmode_+3A_abcsam">ABCsam</code></td>
<td>
<p>(m x k) matrix: ABC sample, where m is the ABC sample size and k is the
number of parameters.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The bandwidth is estimated via smoothed cross-validation
</p>


<h3>Value</h3>

<p>A list containing the 4 approximate modes.
</p>

<hr>
<h2 id='CENoisyFit'>Cross-Entropy estimation</h2><span id='topic+CENoisyFit'></span>

<h3>Description</h3>

<p>This function estimates a dynamic mixture by means of the noisy Cross-Entropy method.
Currently only implemented for the lognormal - generalized Pareto case,
with Cauchy or exponential weight. This
is mainly an auxiliary function, not suitable for the final user. Use CeNoisyFitBoot instead.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CENoisyFit(
  x,
  rawdata,
  rho,
  maxiter,
  alpha,
  nsim,
  nrepsInt,
  xiInst,
  betaInst,
  eps,
  r = 5,
  weight
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CENoisyFit_+3A_x">x</code></td>
<td>
<p>list: sequence of integers 1,...,K, where K is the mumber of datasets. Set x = 1 in case
of a single dataset.</p>
</td></tr>
<tr><td><code id="CENoisyFit_+3A_rawdata">rawdata</code></td>
<td>
<p>either a list of vectors or a vector: in the former case, each
vector contains a dataset to be used for estimation.</p>
</td></tr>
<tr><td><code id="CENoisyFit_+3A_rho">rho</code></td>
<td>
<p>real in (0,1): parameter determining the quantile of the log-likelihood values to be used at each iteration.</p>
</td></tr>
<tr><td><code id="CENoisyFit_+3A_maxiter">maxiter</code></td>
<td>
<p>non-negative integer: maximum number of iterations.</p>
</td></tr>
<tr><td><code id="CENoisyFit_+3A_alpha">alpha</code></td>
<td>
<p>real in (0,1): smoothing parameter.</p>
</td></tr>
<tr><td><code id="CENoisyFit_+3A_nsim">nsim</code></td>
<td>
<p>non-negative integer: number of replications used in the normal and lognormal updating.</p>
</td></tr>
<tr><td><code id="CENoisyFit_+3A_nrepsint">nrepsInt</code></td>
<td>
<p>non-negative integer: number of replications used in the Monte Carlo estimate of the normalizing constant.</p>
</td></tr>
<tr><td><code id="CENoisyFit_+3A_xiinst">xiInst</code></td>
<td>
<p>non-negative real: shape parameter of the instrumental GPD.</p>
</td></tr>
<tr><td><code id="CENoisyFit_+3A_betainst">betaInst</code></td>
<td>
<p>non-negative real: scale parameter of the instrumental GPD.</p>
</td></tr>
<tr><td><code id="CENoisyFit_+3A_eps">eps</code></td>
<td>
<p>non-negative real: tolerance for the stopping criterion of the noisy Cross-Entropy method.</p>
</td></tr>
<tr><td><code id="CENoisyFit_+3A_r">r</code></td>
<td>
<p>positive integer: length of window to be used in the stopping criterion.</p>
</td></tr>
<tr><td><code id="CENoisyFit_+3A_weight">weight</code></td>
<td>
<p>'cau' or 'exp': name of weight distribution.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See Rubinstein and Kroese (2004, chap. 6).
</p>


<h3>Value</h3>

<p>For each dataset, a list with the following elements is returned:
</p>
<p>V (nreps x 12) matrix: updated mean and variance of the distributions used in the stochastic program.
nit (positive integer): number of iterations needed for convergence.
loglik (scalar): maximized log-likelihood.
</p>


<h3>References</h3>


<p>Rubinstein RY, Kroese DP (2004).
<em>The Cross-Entropy Method</em>.
Springer.

</p>


<h3>See Also</h3>

<p>CENoisyFitBoot
</p>


<h3>Examples</h3>

<pre><code class='language-R'>maxiter = 10
alpha = .5
rho = .05
eps = 1e-2
nsim = 1000
nrepsInt = 1000
xiInst = 3
betaInst = 3
r = 5
res &lt;- CENoisyFit(1,Metro2019,rho,maxiter,alpha,nsim,nrepsInt,xiInst,betaInst,eps,r,'exp')

</code></pre>

<hr>
<h2 id='CENoisyFitBoot'>Cross-Entropy estimation and bootstrap standard errors</h2><span id='topic+CENoisyFitBoot'></span>

<h3>Description</h3>

<p>This function estimates a dynamic mixture by means of the noisy Cross-Entropy
method and computes bootstrap standard errors.
Currently only implemented for the lognormal - generalized Pareto,
with Cauchy or exponential weight. Bootstrap standard errors are computed in parallel.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CENoisyFitBoot(
  yObs,
  nboot,
  rho,
  maxiter,
  alpha,
  nsim,
  nrepsInt,
  xiInst,
  betaInst,
  eps,
  r = 5,
  weight
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CENoisyFitBoot_+3A_yobs">yObs</code></td>
<td>
<p>numerical vector: observed random sample from the mixture.</p>
</td></tr>
<tr><td><code id="CENoisyFitBoot_+3A_nboot">nboot</code></td>
<td>
<p>integer: number of bootstrap replications for computing the standard errors.
If nboot = 0, no standard errors are computed.</p>
</td></tr>
<tr><td><code id="CENoisyFitBoot_+3A_rho">rho</code></td>
<td>
<p>real in (0,1): parameter determining the quantile of the log-likelihood values to be used at each iteration.</p>
</td></tr>
<tr><td><code id="CENoisyFitBoot_+3A_maxiter">maxiter</code></td>
<td>
<p>non-negative integer: maximum number of iterations.</p>
</td></tr>
<tr><td><code id="CENoisyFitBoot_+3A_alpha">alpha</code></td>
<td>
<p>real in (0,1): smoothing parameter.</p>
</td></tr>
<tr><td><code id="CENoisyFitBoot_+3A_nsim">nsim</code></td>
<td>
<p>non-negative integer: number of replications used in the normal and lognormal updating.</p>
</td></tr>
<tr><td><code id="CENoisyFitBoot_+3A_nrepsint">nrepsInt</code></td>
<td>
<p>non-negative integer: number of replications used in the Monte Carlo estimate of the normalizing constant.</p>
</td></tr>
<tr><td><code id="CENoisyFitBoot_+3A_xiinst">xiInst</code></td>
<td>
<p>non-negative real: shape parameter of the instrumental GPD.</p>
</td></tr>
<tr><td><code id="CENoisyFitBoot_+3A_betainst">betaInst</code></td>
<td>
<p>non-negative real: scale parameter of the instrumental GPD.</p>
</td></tr>
<tr><td><code id="CENoisyFitBoot_+3A_eps">eps</code></td>
<td>
<p>non-negative real: tolerance for the stopping criterion of the noisy Cross-Entropy method.</p>
</td></tr>
<tr><td><code id="CENoisyFitBoot_+3A_r">r</code></td>
<td>
<p>positive integer: length of window to be used in the stopping criterion.</p>
</td></tr>
<tr><td><code id="CENoisyFitBoot_+3A_weight">weight</code></td>
<td>
<p>'cau' or 'exp': name of weight distribution.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>If nboot &gt; 0, a list with the following elements:
</p>
<p>estPars: Cross-Entropy estimates.
</p>
<p>nit: number of iterations needed for convergence.
</p>
<p>loglik: maximized log-likelihood.
</p>
<p>bootPars: parameter estimates obtained for each bootstrap sample.
</p>
<p>stddev: bootstrap standard errors.
</p>
<p>If nboot = 0, only estPars, nit and loglik are returned.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>res = CENoisyFitBoot(Metro2019,0,.05,20,.5,500,500,3,3,.01,5,'exp')
</code></pre>

<hr>
<h2 id='cvm_stat_M'>Computing the Cramér - von Mises distance between two samples</h2><span id='topic+cvm_stat_M'></span>

<h3>Description</h3>

<p>This function Computing the Cramér - von Mises distance between two samples.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cvm_stat_M(vec1, vec2, power)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cvm_stat_M_+3A_vec1">vec1</code></td>
<td>
<p>(n x 1) vector: first sample.</p>
</td></tr>
<tr><td><code id="cvm_stat_M_+3A_vec2">vec2</code></td>
<td>
<p>(n x 1) vector: second sample.</p>
</td></tr>
<tr><td><code id="cvm_stat_M_+3A_power">power</code></td>
<td>
<p>power of the integrand. Equal to 2 when using the L2 distance</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function computes the Cramér - von Mises distance
between two samples. See Drovandi and Frazier (2022, p. 7).
</p>


<h3>Value</h3>

<p>out scalar: Cramér - von Mises distance between the two samples
</p>


<h3>References</h3>


<p>Drovandi C, Frazier DT (2022).
&ldquo;A comparison of likelihood-free methods with and without summary statistics.&rdquo;
<em>Statistics and Computing</em>, <b>32</b>, Paper No. 42.

</p>


<h3>Examples</h3>

<pre><code class='language-R'>out = cvm_stat_M(runif(100),rnorm(100),2)
</code></pre>

<hr>
<h2 id='ddyn'>Density of a Lognormal-GPD dynamic mixture</h2><span id='topic+ddyn'></span>

<h3>Description</h3>

<p>This function evaluates the density of a Lognormal-GPD dynamic mixture,
with Cauchy or exponential weight.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ddyn(x, pars, intTol, weight)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ddyn_+3A_x">x</code></td>
<td>
<p>non-negative vector: points where the density is evaluated.</p>
</td></tr>
<tr><td><code id="ddyn_+3A_pars">pars</code></td>
<td>
<p>numerical vector: if weight is equal to 'cau', values of <code class="reqn">\mu_c</code>, <code class="reqn">\tau</code>,
<code class="reqn">\mu</code>, <code class="reqn">\sigma</code>, <code class="reqn">\xi</code>, <code class="reqn">\beta</code>; if weight is equal to 'exp', values of <code class="reqn">\lambda</code>,
<code class="reqn">\mu</code>, <code class="reqn">\sigma</code>, <code class="reqn">\xi</code>, <code class="reqn">\beta</code>.</p>
</td></tr>
<tr><td><code id="ddyn_+3A_inttol">intTol</code></td>
<td>
<p>non-negative scalar: threshold for stopping the computation of the integral in the normalization
constant: if the integral on the interval from n-1 to n is smaller than intTol, the approximation procedure stops.</p>
</td></tr>
<tr><td><code id="ddyn_+3A_weight">weight</code></td>
<td>
<p>'cau' or 'exp': name of weight distribution.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>density of the lognormal-GPD mixture evaluated at x.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- seq(0,20,length.out=1000)
pars &lt;- c(1,2,0,.5,.25,3.5)
dLNPar &lt;- ddyn(x,pars,1e-04,'cau')
</code></pre>

<hr>
<h2 id='dynloglik'>Log-likelihood of a Lognormal-GPD dynamic mixture</h2><span id='topic+dynloglik'></span>

<h3>Description</h3>

<p>This function evaluates the log-likelihood of a Lognormal-GPD dynamic mixture, computing the integral in the normalizing constant via quadrature methods.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dynloglik(x, y, intTol, weight)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dynloglik_+3A_x">x</code></td>
<td>
<p>if weight is equal to 'cau', (6 by 1) numerical vector: values of <code class="reqn">\mu_c</code>, <code class="reqn">\tau</code>, <code class="reqn">\mu</code>, <code class="reqn">\sigma</code>, <code class="reqn">\xi</code>, <code class="reqn">\beta</code>;
if weight is equal to 'exp', (5 by 1) numerical vector: values of <code class="reqn">\lambda</code>, <code class="reqn">\mu</code>, <code class="reqn">\sigma</code>, <code class="reqn">\xi</code>, <code class="reqn">\beta</code>.</p>
</td></tr>
<tr><td><code id="dynloglik_+3A_y">y</code></td>
<td>
<p>vector: points where the function is evaluated.</p>
</td></tr>
<tr><td><code id="dynloglik_+3A_inttol">intTol</code></td>
<td>
<p>non-negative scalar: threshold for stopping the computation of the integral in the normalization
constant: if the integral on the interval from n-1 to n is smaller than intTol, the approximation procedure stops.</p>
</td></tr>
<tr><td><code id="dynloglik_+3A_weight">weight</code></td>
<td>
<p>'cau' or 'exp': name of weight distribution.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>log-likelihood of the lognormal-GPD mixture evaluated at y.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- c(1,2,0,.5,.25,3.5)
y &lt;- rDynMix(100,x,'cau')
fit &lt;- dynloglik(x,y,1e-04,'cau')
</code></pre>

<hr>
<h2 id='dynloglikMC'>Log-likelihood of a Lognormal-GPD dynamic mixture</h2><span id='topic+dynloglikMC'></span>

<h3>Description</h3>

<p>This function evaluates the log-likelihood of a Lognormal-GPD dynamic mixture,
with Cauchy or exponential weight, approximating the normalizing constant via Monte Carlo simulation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dynloglikMC(x, y, nreps, xiInst, betaInst, weight)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dynloglikMC_+3A_x">x</code></td>
<td>
<p>if weight is equal to 'cau', (6 by 1) numerical vector: values of <code class="reqn">\mu_c</code>, <code class="reqn">\tau</code>, <code class="reqn">\mu</code>, <code class="reqn">\sigma</code>, <code class="reqn">\xi</code>, <code class="reqn">\beta</code>;
if weight is equal to 'exp', (5 by 1) numerical vector: values of <code class="reqn">\lambda</code>, <code class="reqn">\mu</code>, <code class="reqn">\sigma</code>, <code class="reqn">\xi</code>, <code class="reqn">\beta</code>.</p>
</td></tr>
<tr><td><code id="dynloglikMC_+3A_y">y</code></td>
<td>
<p>vector: points where the function is evaluated.</p>
</td></tr>
<tr><td><code id="dynloglikMC_+3A_nreps">nreps</code></td>
<td>
<p>non-negative integer: number of replications to be used in the computation of the integral in the normalizing
constant.</p>
</td></tr>
<tr><td><code id="dynloglikMC_+3A_xiinst">xiInst</code></td>
<td>
<p>non-negative real: shape parameter of the instrumental GPD.</p>
</td></tr>
<tr><td><code id="dynloglikMC_+3A_betainst">betaInst</code></td>
<td>
<p>non-negative real: scale parameter of the instrumental GPD.</p>
</td></tr>
<tr><td><code id="dynloglikMC_+3A_weight">weight</code></td>
<td>
<p>'cau' or 'exp': name of weight distribution.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Log-likelihood of the lognormal-GPD mixture evaluated at y.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>llik &lt;- dynloglikMC(c(1,2,0,1,.25,3.5),Metro2019,10000,3,3,'exp')
</code></pre>

<hr>
<h2 id='Metro2019'>Population estimate of the US metropolitan areas</h2><span id='topic+Metro2019'></span>

<h3>Description</h3>

<p>A dataset cotaining the 2019 population estimate, divided by 10000, of the
415 US metropolitan areas computed by the US Census Bureau.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Metro2019
</code></pre>


<h3>Format</h3>

<p>A numerical vector with 415 rows and 1 column.
</p>


<h3>Source</h3>

<p><a href="https://www.census.gov">https://www.census.gov</a>
</p>

<hr>
<h2 id='MLEBoot'>Bootstrap standard errors of MLEs</h2><span id='topic+MLEBoot'></span>

<h3>Description</h3>

<p>This function creates bootstrap samples of input data and fits a dynamic mixture via
maximum likelihood.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MLEBoot(x, y, intTol, weight)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MLEBoot_+3A_x">x</code></td>
<td>
<p>list of integers: indices of replications.</p>
</td></tr>
<tr><td><code id="MLEBoot_+3A_y">y</code></td>
<td>
<p>numerical vector: observed data.</p>
</td></tr>
<tr><td><code id="MLEBoot_+3A_inttol">intTol</code></td>
<td>
<p>threshold for stopping the computation of the integral in the normalization
constant: if the integral on the interval from n-1 to n is smaller than intTol, the approximation procedure stops.</p>
</td></tr>
<tr><td><code id="MLEBoot_+3A_weight">weight</code></td>
<td>
<p>'cau' or 'exp': name of weight distribution.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>MLEs are computed by means of the optim function. When it breaks
down, the sample is discarded and a new one is generated. The function keeps
track of the number of times this happens.
</p>


<h3>Value</h3>

<p>A list with the following elements:
</p>
<p>MLE: maximum likelihood estimates obtained from each bootstrap sample.
</p>
<p>errors: number of times the MLE algorithm breaks down.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>bootMLEs &lt;- MLEBoot(1,Metro2019,1e-04,'exp')
</code></pre>

<hr>
<h2 id='MLEfit'>Estimating a dynamic mixture via MLE</h2><span id='topic+MLEfit'></span>

<h3>Description</h3>

<p>This function fits a dynamic mixture via standard maximum likelihood.
Currently only implemented for the lognormal - generalized Pareto case,
with Cauchy or exponential weight.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MLEfit(yObs, bootreps, intTol = 1e-04, weight)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MLEfit_+3A_yobs">yObs</code></td>
<td>
<p>numerical vector: observed sample.</p>
</td></tr>
<tr><td><code id="MLEfit_+3A_bootreps">bootreps</code></td>
<td>
<p>non-negative integer: number of bootstrap replications. If equal to 0, no standard errors are computed.</p>
</td></tr>
<tr><td><code id="MLEfit_+3A_inttol">intTol</code></td>
<td>
<p>non-negative scalar: threshold for stopping the computation of the integral in the normalization
constant: if the integral on the interval from n-1 to n is smaller than intTol, the approximation procedure stops.</p>
</td></tr>
<tr><td><code id="MLEfit_+3A_weight">weight</code></td>
<td>
<p>'cau' or 'exp': name of weight distribution.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Starting values for mu and sigma are the lognormal MLEs computed
with the observations below the median. Initial values for xi and
tau are the GPD MLEs obtained with the observations above the median.
For the location and scale parameter of the Cauchy, we respectively use
the first quartile and abs(log(sd(x)/2)). For the parameter of the exponential, we use
abs(log(sd(x)/2)).
</p>


<h3>Value</h3>

<p>MLEpars vector: maximum likelihood estimates and maximized
log-likelihood.
</p>
<p>MLEboot matrix: maximum likelihood estimates obtained in
each bootstrap replication.
</p>
<p>sdMLE vector: bootstrap standard deviation of the MLEs.
</p>


<h3>References</h3>


<p>Bee M (2023).
&ldquo;Unsupervised mixture estimation via approximate maximum likelihood based on the Cramér - von Mises distance.&rdquo;
<em>Computational Statistics &amp; Data Analysis</em>, <b>185</b>, 107764.

</p>


<h3>See Also</h3>

<p><a href="#topic+AMLEfit">AMLEfit</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
mixFit &lt;- MLEfit(Metro2019,0,,'cau')
</code></pre>

<hr>
<h2 id='nConst_MC'>Monte carlo approximation of the normalizing constant of a Lognormal-GPD dynamic mixture</h2><span id='topic+nConst_MC'></span>

<h3>Description</h3>

<p>This function evaluates via Monte Carlo simulation the normalizing constant of a Lognormal-GPD dynamic mixture,
with Cauchy or exponential weight.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nConst_MC(x, nreps, xiInst = 3, betaInst = 3, weight)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="nConst_MC_+3A_x">x</code></td>
<td>
<p>if weight is equal to 'cau', (6 by 1) numerical vector: values of <code class="reqn">\mu_c</code>, <code class="reqn">\tau</code>, <code class="reqn">\mu</code>, <code class="reqn">\sigma</code>, <code class="reqn">\xi</code>, <code class="reqn">\beta</code>;
if weight is equal to 'exp', (5 by 1) numerical vector: values of <code class="reqn">\lambda</code>, <code class="reqn">\mu</code>, <code class="reqn">\sigma</code>, <code class="reqn">\xi</code>, <code class="reqn">\beta</code>.</p>
</td></tr>
<tr><td><code id="nConst_MC_+3A_nreps">nreps</code></td>
<td>
<p>number of replications to be used in the computation of the integral in the normalizing
constant.</p>
</td></tr>
<tr><td><code id="nConst_MC_+3A_xiinst">xiInst</code></td>
<td>
<p>real: value of the shape parameter of the instrumental density. Default value equal to 3.</p>
</td></tr>
<tr><td><code id="nConst_MC_+3A_betainst">betaInst</code></td>
<td>
<p>non-negative real: value of the scale parameter of the instrumental density. Default value equal to 3.</p>
</td></tr>
<tr><td><code id="nConst_MC_+3A_weight">weight</code></td>
<td>
<p>'cau' or 'exp': name of weight distribution.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Normalizing constant of the density of the lognormal-GPD mixture.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>nconst &lt;- nConst_MC(c(1,2,0,0.5,0.25,3.5), 10000, 3, 3, 'cau')
</code></pre>

<hr>
<h2 id='rDynMix'>Simulating a dynamic lognormal-Pareto mixture</h2><span id='topic+rDynMix'></span>

<h3>Description</h3>

<p>This function fits a dynamic mixture by Approximate Maximum Likelihood and by standard maximum likelihood.
Currently only implemented for the lognormal - generalized Pareto case,
with Cauchy or exponential weight.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rDynMix(nreps, x, weight)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rDynMix_+3A_nreps">nreps</code></td>
<td>
<p>integer: number of observations sampled from the mixture.</p>
</td></tr>
<tr><td><code id="rDynMix_+3A_x">x</code></td>
<td>
<p>numerical vector: if weight = 'cau', values of <code class="reqn">mu_c</code>, <code class="reqn">\tau</code>, <code class="reqn">\mu</code>,
<code class="reqn">\sigma</code>, <code class="reqn">\xi</code>, <code class="reqn">\beta</code>; if weight = 'exp', values of <code class="reqn">\lambda</code>, <code class="reqn">\mu</code>, <code class="reqn">\sigma</code>, <code class="reqn">\xi</code>, <code class="reqn">\beta</code>.</p>
</td></tr>
<tr><td><code id="rDynMix_+3A_weight">weight</code></td>
<td>
<p>'cau' or 'exp': name of weight distribution.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function simulates a dynamic lognormal-GPD mixture using
the algorithm of Frigessi et al. (2002, p. 221).
</p>


<h3>Value</h3>

<p>ysim (nreps x 1) vector: nreps random numbers from the lognormal-GPD dynamic mixture.
</p>


<h3>References</h3>


<p>Frigessi A, Haug O, Rue H (2002).
&ldquo;A Dynamic Mixture Model for Unsupervised Tail Estimation without Threshold Selection.&rdquo;
<em>Extremes</em>, <b>3</b>(5), 219&ndash;235.

</p>


<h3>Examples</h3>

<pre><code class='language-R'>ysim &lt;- rDynMix(100,c(1,2,0,0.5,0.25,3),'cau')
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
