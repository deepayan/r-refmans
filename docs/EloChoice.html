<!DOCTYPE html><html><head><title>Help for package EloChoice</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {EloChoice}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#elochoice'><p>Elo-ratings for pairwise comparisons of visual stimuli</p></a></li>
<li><a href='#makepairwise'><p>transform preference data</p></a></li>
<li><a href='#physical'><p>Physical strength of males</p></a></li>
<li><a href='#randompairs'><p>generate random data of pairwise preference ratings</p></a></li>
<li><a href='#raterprog'><p>reliability with progressive rater inclusion</p></a></li>
<li><a href='#ratings'><p>indiviual stimulus ratings</p></a></li>
<li><a href='#reliability'><p>calculate reliability-index</p></a></li>
<li><a href='#singlechoice'><p>update stimulus ratings after one rating event</p></a></li>
<li><a href='#summary.elochoice'><p>summarize elochoice object</p></a></li>
<li><a href='#triplets'><p>calculate ratings from sequence of rating events, allowing for more than two stimuli</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Preference Rating for Visual Stimuli Based on Elo Ratings</td>
</tr>
<tr>
<td>Version:</td>
<td>0.29.4</td>
</tr>
<tr>
<td>Date:</td>
<td>2019-07-03</td>
</tr>
<tr>
<td>Author:</td>
<td>Christof Neumann</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Christof Neumann &lt;christofneumann1@gmail.com&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Allows calculating global scores for characteristics of visual stimuli as assessed by human raters. Stimuli are presented as sequence of pairwise comparisons ('contests'), during each of which a rater expresses preference for one stimulus over the other (forced choice). The algorithm for calculating global scores is based on Elo rating, which updates individual scores after each single pairwise contest. Elo rating is widely used to rank chess players according to their performance. Its core feature is that dyadic contests with expected outcomes lead to smaller changes of participants' scores than outcomes that were unexpected. As such, Elo rating is an efficient tool to rate individual stimuli when a large number of such stimuli are paired against each other in the context of experiments where the goal is to rank stimuli according to some characteristic of interest. Clark et al (2018) &lt;<a href="https://doi.org/10.1371%2Fjournal.pone.0190393">doi:10.1371/journal.pone.0190393</a>&gt; provide details.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL (&ge; 3)</a></td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp, RcppArmadillo</td>
</tr>
<tr>
<td>Imports:</td>
<td>Rcpp, psychotools, Rdpack</td>
</tr>
<tr>
<td>Suggests:</td>
<td>xtable, knitr, rmarkdown</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>6.1.1</td>
</tr>
<tr>
<td>RdMacros:</td>
<td>Rdpack</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/gobbios/EloChoice">https://github.com/gobbios/EloChoice</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/gobbios/EloChoice/issues">https://github.com/gobbios/EloChoice/issues</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2019-07-03 12:31:56 UTC; cn</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2019-07-04 08:40:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='elochoice'>Elo-ratings for pairwise comparisons of visual stimuli</h2><span id='topic+elochoice'></span><span id='topic+eloint'></span><span id='topic+elointnorm'></span>

<h3>Description</h3>

<p>Elo-ratings for pairwise comparisons of visual stimuli
</p>


<h3>Usage</h3>

<pre><code class='language-R'>elochoice(winner, loser, kval = 100, startvalue = 0, runs = 1, normprob = FALSE)
eloint(winner, loser, allids, kval, startvalues, runs)
elointnorm(winner, loser, allids, kval, startvalues, runs)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="elochoice_+3A_winner">winner</code></td>
<td>
<p>character, vector with the IDs of the winning (preferred) and losing (not preferred) stimuli</p>
</td></tr>
<tr><td><code id="elochoice_+3A_loser">loser</code></td>
<td>
<p>character, vector with the IDs of the winning (preferred) and losing (not preferred) stimuli</p>
</td></tr>
<tr><td><code id="elochoice_+3A_kval">kval</code></td>
<td>
<p>numeric, k-value, which determines the maximum number of points a stimulus' rating can change after a single rating event, by default 100</p>
</td></tr>
<tr><td><code id="elochoice_+3A_startvalue">startvalue</code></td>
<td>
<p>numeric, start value around which ratings are centered, by default 0</p>
</td></tr>
<tr><td><code id="elochoice_+3A_runs">runs</code></td>
<td>
<p>numeric, number of randomizations</p>
</td></tr>
<tr><td><code id="elochoice_+3A_normprob">normprob</code></td>
<td>
<p>logical, by default <code>FALSE</code>, which indicates that a logistic approach is taken for calculating winning probabilities (see Elo 1978). Alternatively (<code>TRUE</code>), such that winning probabilities are calculated from a normal distribution</p>
</td></tr>
<tr><td><code id="elochoice_+3A_startvalues">startvalues</code></td>
<td>
<p>numeric, start value around which ratings are centered, by default 0</p>
</td></tr>
<tr><td><code id="elochoice_+3A_allids">allids</code></td>
<td>
<p>internal, character of all stimulus IDs in the data set</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>elochoice()</code> is the workhorse function of the package, which wraps up all the calculations for obtaining Elo-ratings and the information for the reliability index
</p>
<p><code>eloint()</code> and <code>elointnorm()</code> are internal functions (which <code>elochoice()</code> makes use of) that do most of the calculations, but are usually not directly addressed by the user.
</p>


<h3>Value</h3>

<p>an object of class <code>elochoice</code>, i.e. a list with the following items
</p>
<table>
<tr><td><code>ratmat</code></td>
<td>
<p>numeric matrix with final ratings for each stimulus, one row per randomization</p>
</td></tr>
<tr><td><code>decmat</code></td>
<td>
<p>logical matrix showing for each randomization (row) and each single rating event (column) whether or not there was an expectation for that trial, i.e. whether the two stimuli's ratings differed before the rating</p>
</td></tr>
<tr><td><code>upsmat</code></td>
<td>
<p>logical matrix showing for each randomization (row) and each single rating event (column) whether or not the outcome of a trial was in the direction of the expectation, i.e. whether or not the higher rated stimulus won</p>
</td></tr>
<tr><td><code>wgtmat</code></td>
<td>
<p>numeric matrix showing for each randomization (row) and each single rating event (column) the absolute difference in ratings before the rating event</p>
</td></tr>
<tr><td><code>misc</code></td>
<td>
<p>various information</p>
</td></tr>
<tr><td><code>ov</code></td>
<td>
<p>data set overview, i.e. in how many trials was a stimulus involved and how many trials did each stimulus win and lose</p>
</td></tr>
<tr><td><code>ias</code></td>
<td>
<p>character matrix, with the original sequence of rating events</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Christof Neumann
</p>


<h3>References</h3>

<p>Elo AE (1978).
<em>The rating of chess players, past and present</em>.
Arco, New York.
</p>
<p>Clark AP, Howard KL, Woods AT, Penton-Voak IS, Neumann C (2018).
&ldquo;Why rate when you could compare? Using the 'EloChoice' package to assess pairwise comparisons of perceived physical strength.&rdquo;
<em>PloS one</em>, <b>13</b>(1), e0190393.
doi: <a href="https://doi.org/10.1371/journal.pone.0190393">10.1371/journal.pone.0190393</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(physical)
set.seed(123)
res &lt;- elochoice(winner = physical$Winner, loser = physical$Loser, runs = 100)
summary(res)
ratings(res, show = NULL, drawplot = TRUE)
</code></pre>

<hr>
<h2 id='makepairwise'>transform preference data</h2><span id='topic+makepairwise'></span>

<h3>Description</h3>

<p>transform preference data into paircomp format (<code><a href="psychotools.html#topic+paircomp">paircomp</a></code>)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>makepairwise(winner, loser, rater)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="makepairwise_+3A_winner">winner</code></td>
<td>
<p>character, vector with the IDs of the winning (preferred) stimuli</p>
</td></tr>
<tr><td><code id="makepairwise_+3A_loser">loser</code></td>
<td>
<p>character, vector with the IDs of the losing (not preferred) stimuli</p>
</td></tr>
<tr><td><code id="makepairwise_+3A_rater">rater</code></td>
<td>
<p>character, vector of rater identity</p>
</td></tr>
</table>


<h3>Value</h3>

<p>object of class <code>paircomp</code>
</p>


<h3>Author(s)</h3>

<p>Christof Neumann
</p>


<h3>See Also</h3>

<p><code><a href="psychotools.html#topic+paircomp">psychotools</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>w &lt;- c("B", "A", "E", "E", "D", "D", "A", "D", "E", "B", "A", "E", "D", "C", "A")
l &lt;- c("C", "C", "C", "D", "B", "C", "E", "A", "B", "D", "E", "B", "E", "D", "C")
raters &lt;- rep(letters[1:3], 5)
makepairwise(w, l, raters)
</code></pre>

<hr>
<h2 id='physical'>Physical strength of males</h2><span id='topic+physical'></span>

<h3>Description</h3>

<p>Physical strength of males
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(physical)
</code></pre>


<h3>Format</h3>

<p>4592 pairwise comparisons (contests) between 82 stimuli (average of 112 appearances per stimulus). 56 raters came to the lab and made 82 judgements each. They were asked to choose which image of a pair of stimulus images depicted the physically stronger looking male.
</p>

<dl>
<dt><code>Date</code></dt><dd><p>Date of the rating</p>
</dd>
<dt><code>Winner</code></dt><dd><p>Winner of the interaction</p>
</dd>
<dt><code>Loser</code></dt><dd><p>Loser of the interaction</p>
</dd>
<dt><code>raterID</code></dt><dd><p>A numeric indicator of rater identity</p>
</dd>
</dl>


<h3>Source</h3>

<p>Andrew Clark
</p>


<h3>References</h3>

<p>Andrew Clark
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(physical)
</code></pre>

<hr>
<h2 id='randompairs'>generate random data of pairwise preference ratings</h2><span id='topic+randompairs'></span>

<h3>Description</h3>

<p>generate random data of pairwise preference ratings
</p>


<h3>Usage</h3>

<pre><code class='language-R'>randompairs(nstim = 10, nint = 100, reverse = 0.1, skew = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="randompairs_+3A_nstim">nstim</code></td>
<td>
<p>numeric, number of stimuli, must be less than 2,602</p>
</td></tr>
<tr><td><code id="randompairs_+3A_nint">nint</code></td>
<td>
<p>numeric, number of paired ratings to be created</p>
</td></tr>
<tr><td><code id="randompairs_+3A_reverse">reverse</code></td>
<td>
<p>numeric, proportion of ratings that go against the default preference, see below for details</p>
</td></tr>
<tr><td><code id="randompairs_+3A_skew">skew</code></td>
<td>
<p>logical, by default <code>FALSE</code>, see below for details</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The default preference for a given pair is given by their alphanumerical order. E.g. <em>A</em> is preferred over <em>M</em>, and <em>kf</em> over <em>kz</em>. The <code>reverse=</code> argument specifies the proportion of ratings that go against this default order.
</p>
<p>The number of appearances of a given stimulus in the data set is by default determined by uniform sampling of individual stimuli, i.e. all stimuli will roughly appear equally often in a data set. If a somewhat more realistic (i.e. unbalanced) distribution is desired, the argument <code>skew=TRUE</code> will achieve sampling based on a negative binomial distribution.
</p>


<h3>Value</h3>

<p><code>data.frame</code> with winner and loser column. An additional column (<code>index</code>) serves as an index for the sequence in which the trials occurred.
</p>


<h3>Author(s)</h3>

<p>Christof Neumann
</p>


<h3>Examples</h3>

<pre><code class='language-R'># a relatively balanced data set
xdata &lt;- randompairs(20, 500, skew=FALSE)
table(c(as.character(xdata$winner), as.character(xdata$loser)))
range(table(c(as.character(xdata$winner), as.character(xdata$loser))))

# and a less balanced data set
xdata &lt;- randompairs(20, 500, skew=TRUE)
table(c(as.character(xdata$winner), as.character(xdata$loser)))
range(table(c(as.character(xdata$winner), as.character(xdata$loser))))
</code></pre>

<hr>
<h2 id='raterprog'>reliability with progressive rater inclusion</h2><span id='topic+raterprog'></span><span id='topic+raterprogplot'></span>

<h3>Description</h3>

<p>reliability with progressive rater inclusion
</p>


<h3>Usage</h3>

<pre><code class='language-R'>raterprog(winner, loser, raterID, runs=100, ratershuffle=1, progbar=TRUE, kval=100,
startvalue=0, normprob=FALSE)

raterprogplot(xdata)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="raterprog_+3A_winner">winner</code></td>
<td>
<p>character, vector with the IDs of the winning (preferred) stimuli</p>
</td></tr>
<tr><td><code id="raterprog_+3A_loser">loser</code></td>
<td>
<p>character, vector with the IDs of the losing (not preferred) stimuli</p>
</td></tr>
<tr><td><code id="raterprog_+3A_raterid">raterID</code></td>
<td>
<p>a vector (numeric, character, factor) with rater IDs</p>
</td></tr>
<tr><td><code id="raterprog_+3A_runs">runs</code></td>
<td>
<p>numeric, number of randomizations</p>
</td></tr>
<tr><td><code id="raterprog_+3A_ratershuffle">ratershuffle</code></td>
<td>
<p>numeric, number of times rater order is reshuffled/randomized</p>
</td></tr>
<tr><td><code id="raterprog_+3A_progbar">progbar</code></td>
<td>
<p>logical, should a progress bar be displayed</p>
</td></tr>
<tr><td><code id="raterprog_+3A_kval">kval</code></td>
<td>
<p>numeric, k-value, which determines the maximum number of points a stimulus' rating can change after a single rating event, by default 100</p>
</td></tr>
<tr><td><code id="raterprog_+3A_startvalue">startvalue</code></td>
<td>
<p>numeric, start value around which ratings are centered, by default <code>0</code></p>
</td></tr>
<tr><td><code id="raterprog_+3A_normprob">normprob</code></td>
<td>
<p>logical, by default <code>FALSE</code>, which indicates a logistic approach is taken for calculating winning probabilities (see Elo 1978). Alternatively (<code>TRUE</code>), winning probabilities are calculated from a normal distribution</p>
</td></tr>
<tr><td><code id="raterprog_+3A_xdata">xdata</code></td>
<td>
<p>results from <code><a href="#topic+raterprog">raterprog</a></code></p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>raterprog()</code> calculates <code><a href="#topic+reliability">reliability</a></code>, increasing the number of raters to be included in the rating process in a step-wise fashion. In the first (and by default only one) run, the first rater is the one that appears first in the data set, and in subsequent steps raters are added by the order in which they occur. If <code>ratershuffle=</code> is set to values larger than 1, the order in which raters are included is randomized.
</p>
<p><code>raterprogplot()</code> plots the matrix resulting from <code>raterprog()</code>. If <code>ratershuffle=</code> is larger than 1, the average reliability index is plotted alongside quartiles and results from the original rater inclusion sequence.
</p>
<p>Note that the function currently only calculates the weighted version of the <code><a href="#topic+reliability">reliability</a></code> index.
</p>


<h3>Value</h3>

<p>a numeric matrix. Rows correspond to number of raters in the data set, while columns reflect the number of times the rater order is reshuffled.
</p>


<h3>Author(s)</h3>

<p>Christof Neumann after suggestion by TF
</p>


<h3>References</h3>

<p>Clark AP, Howard KL, Woods AT, Penton-Voak IS, Neumann C (2018).
&ldquo;Why rate when you could compare? Using the 'EloChoice' package to assess pairwise comparisons of perceived physical strength.&rdquo;
<em>PloS one</em>, <b>13</b>(1), e0190393.
doi: <a href="https://doi.org/10.1371/journal.pone.0190393">10.1371/journal.pone.0190393</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("physical")
# limit to 12 raters
physical &lt;- physical[physical$raterID &lt; 14, ]

x &lt;- raterprog(physical$Winner, physical$Loser, physical$raterID, ratershuffle = 1)
raterprogplot(x)

# with multiple orders in which raters are added
x &lt;- raterprog(physical$Winner, physical$Loser, physical$raterID, ratershuffle = 10)
raterprogplot(x)
</code></pre>

<hr>
<h2 id='ratings'>indiviual stimulus ratings</h2><span id='topic+ratings'></span>

<h3>Description</h3>

<p>get stimulus ratings and/or a summary plot
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ratings(x, show = "mean", drawplot = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ratings_+3A_x">x</code></td>
<td>
<p>an object of class <code>"elochoice"</code>, usually the result of a call to <code><a href="#topic+elochoice">elochoice</a></code></p>
</td></tr>
<tr><td><code id="ratings_+3A_show">show</code></td>
<td>
<p>character, what values should be returned, see below</p>
</td></tr>
<tr><td><code id="ratings_+3A_drawplot">drawplot</code></td>
<td>
<p>logical, should a plot drawn</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If <code>show="original"</code>, <code>show="mean"</code> or <code>show="var"</code>, a numeric vector is returned which contains either the ratings obtained from the initial/original sequence, the average ratings across all randomizations, or the total variance.
</p>
<p>If <code>show="range"</code> or <code>show="all"</code>, a matrix is returned that contains either the range of ratings across all randomizations, or all ratings of all randomizations.
</p>
<p>If you simply want to create the plot without any rating output being generated, use <code>show=NULL</code>.
</p>
<p>If <code>drawplot=TRUE</code>, a plot is created that depicts the values of the ratings obtained from the initial sequence (red), the mean ratings across all randomizations (black) and the range of ratings across all randomizations.
</p>


<h3>Value</h3>

<p>numeric vector or matrix, and/or a plot
</p>


<h3>Author(s)</h3>

<p>Christof Neumann
</p>


<h3>Examples</h3>

<pre><code class='language-R'>xdata &lt;- randompairs(nstim = 10, nint = 100)
x &lt;- elochoice(xdata$winner, xdata$loser, runs = 10)

# ratings from the initial sequence
ratings(x, "original", drawplot = FALSE)

# range of ratings across all randomizations
ratings(x, "range", drawplot = FALSE)

# and producing plot
ratings(x, NULL, drawplot = TRUE)

</code></pre>

<hr>
<h2 id='reliability'>calculate reliability-index</h2><span id='topic+reliability'></span>

<h3>Description</h3>

<p>calculate reliability-index of Elo-ratings
</p>


<h3>Usage</h3>

<pre><code class='language-R'>reliability(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="reliability_+3A_x">x</code></td>
<td>
<p>elochoice-object, the result of <code><a href="#topic+elochoice">elochoice</a></code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>a data.frame with as many rows as randomizations were run in the original call to <code>elochoice()</code>. The first column represents the unweighted and the second the weighted reliability index (<em>R</em> and <em>R'</em>), which is followed by the total number of trials that contributed to the calculation of the index. Note that this number cannot reach the total number of trials in the data set because at least for the very first trial we did not have an expectation for the outcome of that trial (and such trials do not contribute to the calculation of the reliability index).
</p>


<h3>Author(s)</h3>

<p>Christof Neumann
</p>


<h3>References</h3>

<p>Clark AP, Howard KL, Woods AT, Penton-Voak IS, Neumann C (2018).
&ldquo;Why rate when you could compare? Using the 'EloChoice' package to assess pairwise comparisons of perceived physical strength.&rdquo;
<em>PloS one</em>, <b>13</b>(1), e0190393.
doi: <a href="https://doi.org/10.1371/journal.pone.0190393">10.1371/journal.pone.0190393</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># create data set and calculate ratings (with five randomizations)
xdata &lt;- randompairs(12, 500)
x &lt;- elochoice(xdata$winner, xdata$loser, runs=5)
# extract the reliability values
(u &lt;- reliability(x))
# calculate average reliability index
mean(u$upset)
# and in its weighted form
mean(u$upset.wgt)
</code></pre>

<hr>
<h2 id='singlechoice'>update stimulus ratings after one rating event</h2><span id='topic+singlechoice'></span>

<h3>Description</h3>

<p>update stimulus ratings after one rating event
</p>


<h3>Usage</h3>

<pre><code class='language-R'>singlechoice(val1, val2, k)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="singlechoice_+3A_val1">val1</code></td>
<td>
<p>rating of the preferred stimulus <em>before</em> the rating event</p>
</td></tr>
<tr><td><code id="singlechoice_+3A_val2">val2</code></td>
<td>
<p>rating of the unpreferred stimulus <em>before</em> the rating event</p>
</td></tr>
<tr><td><code id="singlechoice_+3A_k">k</code></td>
<td>
<p>value of <em>k</em>-constant, which determines the maximum change of ratings after a single rating event</p>
</td></tr>
</table>


<h3>Value</h3>

<p>vector with two values: updated ratings <em>after</em> the rating event for preferred and unpreferred stimulus
</p>


<h3>Author(s)</h3>

<p>Christof Neumann
</p>


<h3>References</h3>

<p>Elo AE (1978).
<em>The rating of chess players, past and present</em>.
Arco, New York.
</p>


<h3>See Also</h3>

<p><code><a href="EloRating.html#topic+e.single">EloRating</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># little change because rating difference is large (positive), i.e. expectation is clear
singlechoice(1200, 500, 100)
# no change because rating difference is very large (positive), i.e. expectation is clear
singlechoice(1500, 500, 100)
# large change because rating difference is small (negative), i.e. expectation is clearly violated
singlechoice(500, 1500, 100)
</code></pre>

<hr>
<h2 id='summary.elochoice'>summarize elochoice object</h2><span id='topic+summary.elochoice'></span>

<h3>Description</h3>

<p>summarize elochoice object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'elochoice'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.elochoice_+3A_object">object</code></td>
<td>
<p>an object of class <code>"elochoice"</code>, usually the result of a call to <code><a href="#topic+elochoice">elochoice</a></code></p>
</td></tr>
<tr><td><code id="summary.elochoice_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods. Nothing relevant in this case.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Christof Neumann
</p>


<h3>Examples</h3>

<pre><code class='language-R'>xdata &lt;- randompairs(nstim=10, nint=500)
x &lt;- elochoice(xdata$winner, xdata$loser, runs=5)
summary(x)
</code></pre>

<hr>
<h2 id='triplets'>calculate ratings from sequence of rating events, allowing for more than two stimuli</h2><span id='topic+triplets'></span>

<h3>Description</h3>

<p>calculate ratings from sequence of rating events, allowing for more than two stimuli
</p>


<h3>Usage</h3>

<pre><code class='language-R'>triplets(xdata, winner, runs = 2, startvalue = 0, k = 100,
  progressbar = TRUE, mode = "avg")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="triplets_+3A_xdata">xdata</code></td>
<td>
<p>data.frame or matrix with stimulus IDs, each row representing one trial, needs to contain at least two columns</p>
</td></tr>
<tr><td><code id="triplets_+3A_winner">winner</code></td>
<td>
<p>numeric vector of the same length as <code>nrow(xdata)</code>, indicating which column in <code>xdata</code> is the winner/preferred stimulus</p>
</td></tr>
<tr><td><code id="triplets_+3A_runs">runs</code></td>
<td>
<p>numeric, the number of times the data set should be randomized</p>
</td></tr>
<tr><td><code id="triplets_+3A_startvalue">startvalue</code></td>
<td>
<p>numeric, initial value of ratings, by default <code>0</code></p>
</td></tr>
<tr><td><code id="triplets_+3A_k">k</code></td>
<td>
<p>numeric, value of <em>k</em>-constant</p>
</td></tr>
<tr><td><code id="triplets_+3A_progressbar">progressbar</code></td>
<td>
<p>logical, by default <code>TRUE</code>. Should a progress bar be displayed</p>
</td></tr>
<tr><td><code id="triplets_+3A_mode">mode</code></td>
<td>
<p>character, either <code>"avg"</code> (default) or <code>"seq"</code>, see Details section</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>mode="avg"</code> option considers the losers of the trial as one individual/stimulus, whose rating is averaged. This reflects one rating step for each trial (as for <code>elochoice()</code>).
</p>
<p>The <code>mode="seq"</code> option runs a sequence of interactions <em>within</em> a trial, i.e. one rating step for each of the loosing stimuli. E.g. if you have three stimuli, that would be two rating steps. With four stimuli, we would have three steps, etc.
</p>
<p>Because of the larger number of rating events with <code>mode="seq"</code>, the range of Elo-ratings will be larger as compared to <code>mode="avg"</code>. The average values will be the same for both though (start value). See examples...
</p>
<p>Also note that this is an experimental function that has not yet been tested thoroughly! In addition, this function calculates winning probabilities in a slightly different way as compared to <code>elochoice</code>, i.e. based on normal probabilities (see <code><a href="#topic+elochoice">elochoice</a></code>).
</p>


<h3>Value</h3>

<p>a matrix with ratings
</p>


<h3>Author(s)</h3>

<p>Christof Neumann
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(physical)
y &lt;- round(triplets(physical[, 2:3], winner = rep(1,nrow(physical)), runs = 1))
x &lt;- ratings(elochoice(physical$Winner, physical$Loser, runs = 1), show = "all", drawplot = FALSE)
x &lt;- x[order(names(x))]
plot(x, y)

xdata &lt;- as.matrix(t(sapply(1:500, function(x)sample(letters[1:8], 3))))
xdata &lt;- t(apply(xdata, 1, sort))
winner &lt;- sample(1:3, nrow(xdata), TRUE, prob = c(4, 0.8, 0.1))

x &lt;- triplets(xdata, winner, runs=20, mode="avg")
y &lt;- triplets(xdata, winner, runs=20, mode="seq")

# note different ranges along the axes
plot(colMeans(x), colMeans(y))
range(colMeans(x))
range(colMeans(y))
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
