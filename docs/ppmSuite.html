<!DOCTYPE html><html lang="en"><head><title>Help for package ppmSuite</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {ppmSuite}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#bear'><p>Bear dataset</p></a></li>
<li><a href='#ccp_ppm'><p>Function that fits a multivariate correlated product partition change</p>
point model</a></li>
<li><a href='#curve_ppmx'><p>Gaussian PPMx Model for Functional Realizations</p></a></li>
<li><a href='#gaussian_ppmx'><p>Function that fits Gaussian PPMx model</p></a></li>
<li><a href='#icp_ppm'><p>Function that fits the multivariate independent product partition</p>
change point model</a></li>
<li><a href='#ordinal_ppmx'><p>Function that fits ordinal probit model with a PPMx as a prior on partitions</p></a></li>
<li><a href='#ozone'><p>Ozone data</p></a></li>
<li><a href='#rppmx'><p>Function generates random realizations from a PPM or PPMx</p></a></li>
<li><a href='#scallops'><p>Scallops data</p></a></li>
<li><a href='#SIMCE'><p>Standardized testing data in Chile</p></a></li>
<li><a href='#sppm'><p>Function that fits spatial product partition model with Gaussian likelihood</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>A Collection of Models that Employ Product Partition
Distributions as a Prior on Partitions</td>
</tr>
<tr>
<td>Version:</td>
<td>0.3.4</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Garritt L. Page &lt;page@stat.byu.edu&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Provides a suite of functions that fit models that use PPM type priors for partitions.
                Models include hierarchical Gaussian and probit ordinal models with  a (covariate 
                dependent) PPM.  If a covariate dependent product partition model is selected, 
                then all the options detailed in Page, G.L.; Quintana, F.A. (2018) 
                &lt;<a href="https://doi.org/10.1007%2Fs11222-017-9777-z">doi:10.1007/s11222-017-9777-z</a>&gt; are available.  If covariate values are missing, 
                then the approach detailed in Page, G.L.; Quintana, F.A.; Mueller, P (2020) 
                &lt;<a href="https://doi.org/10.1080%2F10618600.2021.1999824">doi:10.1080/10618600.2021.1999824</a>&gt; is employed.   Also included in the package is 
                a function that fits a Gaussian likelihood spatial product  partition model that is 
                detailed in Page, G.L.; Quintana, F.A. (2016)  &lt;<a href="https://doi.org/10.1214%2F15-BA971">doi:10.1214/15-BA971</a>&gt;, and 
                multivariate PPM change point models that are detailed in Quinlan, J.J.; Page, G.L.; 
                Castro, L.M. (2023) &lt;<a href="https://doi.org/10.1214%2F22-BA1344">doi:10.1214/22-BA1344</a>&gt;. In addition, a function that fits a 
                univariate or bivariate functional data model that employs a PPM or a PPMx to 
                cluster curves based on B-spline coefficients is provided.</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0)</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL]</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>Suggests:</td>
<td>cluster</td>
</tr>
<tr>
<td>Imports:</td>
<td>Matrix</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-07-15 15:03:56 UTC; gpage</td>
</tr>
<tr>
<td>Author:</td>
<td>Garritt L. Page [aut, cre, cph],
  Jose J. Quinlan [aut, cph],
  S. McKay Curtis [ctb, cph],
  Radford M. Neal [ctb, cph]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-07-16 07:30:05 UTC</td>
</tr>
</table>
<hr>
<h2 id='bear'>Bear dataset </h2><span id='topic+bear'></span>

<h3>Description</h3>

<p>Number of physiological measurements from 54 bears.
</p>


<h3>Format</h3>

<p>data: A data frame with 54 rows and the following 9 variables:
</p>

<dl>
<dt>age</dt><dd></dd>
<dt>length</dt><dd></dd>
<dt>sex</dt><dd></dd>
<dt>weight</dt><dd></dd>
<dt>chest</dt><dd></dd>
<dt>headlength</dt><dd></dd>
<dt>headwid</dt><dd></dd>
<dt>month</dt><dd></dd>
<dt>neck</dt><dd></dd>
</dl>


<hr>
<h2 id='ccp_ppm'>Function that fits a multivariate correlated product partition change
point model</h2><span id='topic+ccp_ppm'></span>

<h3>Description</h3>

<p><code>ccp_ppm</code> is a function that fits a Bayesian product partition change
point model, where the set of change point indicators between time series are correlated.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ccp_ppm(ydata, model=1,
         nu0, mu0, sigma0,
         mltypes, thetas,
         devs,
         nburn, nskip, nsave,
         verbose = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ccp_ppm_+3A_ydata">ydata</code></td>
<td>
<p>An <code class="reqn">L \times n</code> data matrix, where <code class="reqn">L</code> is the number of
time series and <code class="reqn">n</code>, the number of time points.</p>
</td></tr>
<tr><td><code id="ccp_ppm_+3A_model">model</code></td>
<td>
<p>Determines of model fit is such that there are p_its (model=1) or
only p_t (model=2)</p>
</td></tr>
<tr><td><code id="ccp_ppm_+3A_nu0">nu0</code></td>
<td>
<p>Degrees of freedom of the multivariate Student's
t-distribution (see section Details).</p>
</td></tr>
<tr><td><code id="ccp_ppm_+3A_mu0">mu0</code></td>
<td>
<p>Location vector of dimension <code class="reqn">L</code> (see section Details).</p>
</td></tr>
<tr><td><code id="ccp_ppm_+3A_sigma0">sigma0</code></td>
<td>
<p>Positive definite scale matrix of order <code class="reqn">L \times L</code> (see
section Details).</p>
</td></tr>
<tr><td><code id="ccp_ppm_+3A_mltypes">mltypes</code></td>
<td>
<p>Type of marginal likelihood. Currently only available is:
</p>

<ul>
<li><p><code>mltypes = 1</code>. Observations within a block are conditionally
independent <code class="reqn">Normal(\mu, \sigma^2)</code> variates with mean <code class="reqn">\mu</code> and
variance <code class="reqn">\sigma^2</code>. The desired marginal likelihood is obtained after
integrating <code class="reqn">(\mu, \sigma^2)</code> with respect to a
<code class="reqn">Normal-Inverse-Gamma(\mu_{0}, \kappa_{0}, \alpha_{0}, \beta_{0})</code>
prior.
</p>
</li></ul>

</td></tr>
<tr><td><code id="ccp_ppm_+3A_thetas">thetas</code></td>
<td>
<p>An <code class="reqn">L \times q</code> matrix containing hyperparameters associated
with the marginal likelihood. The number of rows <code class="reqn">(L)</code> corresponds to the
number of series. The number of columns <code class="reqn">(q)</code> depend on the marginal
likelihood:
</p>

<ul>
<li><p>  If <code>mltypes = 1</code>, then <code class="reqn">q = 4</code> and <code>thetas</code> equals
the hyperparameter <code class="reqn">(\mu_{0}, \kappa_{0}, \alpha_{0}, \beta_{0})</code> of
the Normal-Inverse-Gamma prior.
</p>
</li></ul>

</td></tr>
<tr><td><code id="ccp_ppm_+3A_devs">devs</code></td>
<td>
<p>An <code class="reqn">L \times (n - 1)</code> matrix containing the standard deviations
of the candidate density associated with the random walk Metropolis-Hastings
steps for updating change point probabilities.</p>
</td></tr>
<tr><td><code id="ccp_ppm_+3A_nburn">nburn</code></td>
<td>
<p>The number of initial MCMC iterates to be discarded as burn-in.</p>
</td></tr>
<tr><td><code id="ccp_ppm_+3A_nskip">nskip</code></td>
<td>
<p>The amount to thinning that should be applied to the MCMC chain.</p>
</td></tr>
<tr><td><code id="ccp_ppm_+3A_nsave">nsave</code></td>
<td>
<p>Then number of MCMC iterates to be stored.</p>
</td></tr>
<tr><td><code id="ccp_ppm_+3A_verbose">verbose</code></td>
<td>
<p>Logical indicating whether to print to screen the MCMC progression. The default value is <code>verbose = FALSE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>As described in Quinlan et al. (add cite), for each time series
<code class="reqn">\boldsymbol{y}_{i} = (y_{i,1}, \ldots , y_{i,n})'</code>:
</p>
<p style="text-align: center;"><code class="reqn">\boldsymbol{y}_{i} \mid \rho_{i} \sim
\prod_{j = 1}^{b_{i}}\mathcal{F}(\boldsymbol{y}_{i,j} \mid
\boldsymbol{\theta}_{i})</code>
</p>

<p style="text-align: center;"><code class="reqn">\rho_{i} \mid (p_{i,1}, \ldots , p_{i,n-1})' \sim
\prod_{t \in T_{i}}p_{i,t} \prod_{t \notin T_{i}}(1 - p_{i,t}) :
T_{i} = \{\tau_{i,1}, \ldots, \tau_{i,b_{i} - 1}\}</code>
</p>

<p style="text-align: center;"><code class="reqn">(p_{1,t}, \ldots , p_{L,t})' \sim logit-t(\nu_{0}, \boldsymbol{\mu}_{0},
\boldsymbol{\Sigma}_{0}).</code>
</p>

<p>Here, <code class="reqn">\rho_{i} = \{S_{i,1}, \ldots , S_{i,b_{i}}\}</code> is a partition of
the set <code class="reqn">\{1, \ldots , n\}</code> into <code class="reqn">b_{i}</code> contiguous blocks, and
<code class="reqn">\boldsymbol{y}_{i,j} = (y_{i,t} : t \in S_{i,j})'</code>. Also,
<code class="reqn">\tau_{i,j} = \max(S_{i,j})</code> and
<code class="reqn">\mathcal{F}( \cdot \mid \boldsymbol{\theta}_{i})</code> is a marginal
likelihood function which depends on the nature of <code class="reqn">\boldsymbol{y}_{i}</code>,
indexed by a hyperparameter <code class="reqn">\boldsymbol{\theta}_{i}</code>. In addition,
<code class="reqn">logit-t(\nu_{0}, \boldsymbol{\mu}_{0}, \boldsymbol{\Sigma}_{0})</code>
is the logit of a multivariate Student's t-distribution with degrees of
freedom <code class="reqn">\nu_{0}</code>, location vector <code class="reqn">\boldsymbol{\mu}_{0}</code> and scale
matrix <code class="reqn">\boldsymbol{\Sigma}_{0}</code>.</p>


<h3>Value</h3>

<p>The function returns a list containing arrays filled with MCMC iterates
corresponding to model parameters. In order to provide more detail, in what
follows let <code class="reqn">M</code> be the number of MCMC iterates collected. The output list
contains the following:
</p>

<ul>
<li><p>C. An <code class="reqn">M \times \{L(n - 1)\}</code> matrix containing MCMC iterates
associated with each series indicators of a change point. The <code class="reqn">m</code>th
row in <code>C</code> is divided into <code class="reqn">L</code> blocks; the first <code class="reqn">(n - 1)</code>
change point indicators for time series 1, the next <code class="reqn">(n - 1)</code> change
point indicators for time series 2, and so on.
</p>
</li>
<li><p>P. An <code class="reqn">M \times \{L(n - 1)\}</code> matrix containing MCMC iterates
associated with each series probability of a change point. The <code class="reqn">m</code>th
row in <code>P</code> is divided into <code class="reqn">L</code> blocks; the first <code class="reqn">(n - 1)</code>
change point probabilities for time series 1, the next <code class="reqn">(n - 1)</code> change
point probabilities for time series 2, and so on.
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>
# Generate data that has two series, each with 100 observations
y1 &lt;- replicate(25, rnorm(4, c(-1, 0, 1, 2), c(0.1, 0.25, 0.5, 0.75)))
y2 &lt;- replicate(25, rnorm(4, c(2, 1, 0, -2), c(0.1, 0.25, 0.5, 0.75)))
y &lt;- rbind(c(t(y1)), c(t(y2)))

# Marginal likelihood parameters
thetas &lt;- matrix(1, nrow = 2,ncol = 4)
thetas[1,] &lt;- c(0, 1, 2, 1)
thetas[2,] &lt;- c(0, 1, 2, 1)

# M-H candidate density standard deviations
devs = matrix(0.1, nrow = 2, ncol = (dim(y)[2] - 1))

# Prior parameters for logit-t distribution
L &lt;- nrow(y)
pivar &lt;- 10
picorr &lt;- 0.9
pimu &lt;- rep(-6, L) # mean associated with logit of p_i
piSigma &lt;- pivar*picorr*(rep(1, L) %*% t(rep(1, L))) +
           pivar*(1 - picorr)*diag(L)
nu0 = 3
mu0 = pimu
sigma0 = piSigma

# Fit the bayesian ppm change point model
fit &lt;- ccp_ppm(nburn = 1000, nskip = 1, nsave = 1000, ydata = y, nu0 = nu0,
               mu0 = mu0, sigma0 = sigma0, mltypes = c(1, 1), thetas = thetas,
               devs = devs)

</code></pre>

<hr>
<h2 id='curve_ppmx'>Gaussian PPMx Model for Functional Realizations</h2><span id='topic+curve_ppmx'></span>

<h3>Description</h3>

<p><code>curve_ppmx</code> is the main function used to fit Functional Gaussian PPMx model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>curve_ppmx(y, z, subject,
            Xcon=NULL,Xcat=NULL,
            Xconp=NULL,Xcatp=NULL,
            PPM, M,
            q=3, rw_order=1, balanced=1,
            nknots,npredobs,
            Aparm, modelPriors,
            similarity_function=1,
            consim, calibrate,
            simParms,
            mh=c(1,1),
            draws=1100,burn=100,thin=1)

</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="curve_ppmx_+3A_y">y</code></td>
<td>
<p>numeric vector or a matrix with two columns that contains measured functional response in long format</p>
</td></tr>
<tr><td><code id="curve_ppmx_+3A_z">z</code></td>
<td>
<p>numeric vector contains time points at which functional response is measured in long format</p>
</td></tr>
<tr><td><code id="curve_ppmx_+3A_subject">subject</code></td>
<td>
<p>vector of the same length as z that identies the subject to which each measurement in y corresponds.  </p>
</td></tr>
<tr><td><code id="curve_ppmx_+3A_xcon">Xcon</code></td>
<td>
<p>a data-frame with number of rows being equal to the number of subjects and whose columns consist of continuous covariates.  These covariates are included in the PPMx model and therefore influence clusters and thus are only used if the PPM argument is FALSE.  This argument is set to NULL by default</p>
</td></tr>
<tr><td><code id="curve_ppmx_+3A_xcat">Xcat</code></td>
<td>
<p>a data-frame  with nsubject number of rows and whose columns consist of categorical covariates.  These covariates are included in the PPMx model and therefore influence clusters and thus are only used if the PPM argument is FALSE.  The categories must be labeled using integers starting at zero. This argument is set to NULL by default</p>
</td></tr>
<tr><td><code id="curve_ppmx_+3A_xconp">Xconp</code></td>
<td>
<p>a data-frame with the number of rows corresponding to the number of out-of-sample predictions that are desired and columns consist of continuous covariates that are contained in Xcon.</p>
</td></tr>
<tr><td><code id="curve_ppmx_+3A_xcatp">Xcatp</code></td>
<td>
<p>a data-frame with the number of rows corresponding to the number of out-of-sample predictions that are desired and columns consist of categorical covariates that are contained in Xcat.</p>
</td></tr>
<tr><td><code id="curve_ppmx_+3A_ppm">PPM</code></td>
<td>
<p>Logical argument that indicates if the PPM or PPMx partition model should be employed.  If PPM = FALSE, then at least one of Xcon and Xcat must be supplied.</p>
</td></tr>
<tr><td><code id="curve_ppmx_+3A_m">M</code></td>
<td>
<p>Scale parameter connected to the dispersion parameter of a Dirichlet process.  Default is 1.</p>
</td></tr>
<tr><td><code id="curve_ppmx_+3A_q">q</code></td>
<td>
<p>Degree of B-spline employed to fit curves</p>
</td></tr>
<tr><td><code id="curve_ppmx_+3A_rw_order">rw_order</code></td>
<td>
<p>Order of the random walk.  This specifies the type of penalty matrix employed in the penalized B-splines.</p>
</td></tr>
<tr><td><code id="curve_ppmx_+3A_balanced">balanced</code></td>
<td>
<p>scalar with 1 - indicating the design was balanced in the sense that all subjects measurements occur at the same time and 0 - indicating design was not balanced.</p>
</td></tr>
<tr><td><code id="curve_ppmx_+3A_nknots">nknots</code></td>
<td>
<p>scalar indicating the number of evenly spaced knots to be used.</p>
</td></tr>
<tr><td><code id="curve_ppmx_+3A_npredobs">npredobs</code></td>
<td>
<p>number of time predictions to make for each subjects curve.</p>
</td></tr>
<tr><td><code id="curve_ppmx_+3A_aparm">Aparm</code></td>
<td>
<p>Upper bound parameter for lambda wich regulates the similarity of curves with in a cluster.  Larger values result in clusters with curves that can be more dissimilar.</p>
</td></tr>
<tr><td><code id="curve_ppmx_+3A_modelpriors">modelPriors</code></td>
<td>
<p>Vector of prior parameter values for priors assigned to parameters of the Gaussian Functional data model.
</p>

<ul>
<li><p> A - upper bound on sigma*_j.
</p>
</li>
<li><p> s2mu - prior variance for mu the mean vector of theta which are cluster specific spline coefficients,
</p>
</li>
<li><p> mb0 - prior mean for beta0_i (subject specific intercept)
</p>
</li>
<li><p> s2b0 - prior variance for beta0_i (subject specific intercept)
</p>
</li>
<li><p> as2b0 - prior shape associated with IG prior on variance of beta0_i (subject specific intercept)
</p>
</li>
<li><p> bs2b0 - prior scale associated with IG prior on variacne of beta0_i (subject specific intercept)
</p>
</li>
<li><p> at - prior shape associated with IG prior on tau (smoothing parameter for theta)
</p>
</li>
<li><p> bt - prior scale associated with IG prior on tau (smoothing parameter for theta)
</p>
</li></ul>

</td></tr>
<tr><td><code id="curve_ppmx_+3A_similarity_function">similarity_function</code></td>
<td>
<p>Type of similarity function that is employed for the PPMx prior on partitions.  Options are 1-4 with
</p>

<ul>
<li><p>  1 - Auxilliary similarity
</p>
</li>
<li><p>  2 - Double dipper similarity
</p>
</li>
<li><p>  3 - Cluster variance or entropy for categorical covariates
</p>
</li>
<li><p> 4 - Mean Gower dissimilarity (Gower dissimilarity is not available if missing values are present in X)
</p>
</li></ul>

</td></tr>
<tr><td><code id="curve_ppmx_+3A_consim">consim</code></td>
<td>
<p>If similarity_function is set to either 1 or 2, then consim specifies the type of marginal likelihood used as the similarity function. Options are 1 or 2 with
</p>

<ul>
<li><p> 1 - N-N(m0, s20, v) (v variance of &ldquo;likelihood&rdquo;, m0 and s20 &ldquo;prior&rdquo; parameters),
</p>
</li>
<li><p> 2 - N-NIG(m0, k0, nu0, s20) (m0 and k0 center and inverse scalar of a Gaussian, and nu0 and s20 are the number of prior observations and prior variance guess of a Inverse-Chi-Square distribution.)
</p>
</li></ul>

</td></tr>
<tr><td><code id="curve_ppmx_+3A_calibrate">calibrate</code></td>
<td>
<p>Indicates if the similarity should be calibrated.  Options are 0-2 with
</p>

<ul>
<li><p> 0 - no calibration
</p>
</li>
<li><p> 1 - standardize similarity value for each covariate
</p>
</li>
<li><p> 2 - coarsening is applied so that each similarity is raised to the 1/p power</p>
</li></ul>

</td></tr>
<tr><td><code id="curve_ppmx_+3A_simparms">simParms</code></td>
<td>
<p>Vector of parameter values employed in the similarity function of the PPMx. Entries of the vector correspond to
</p>

<ul>
<li><p> m0 - center continuous similarity with default 0,
</p>
</li>
<li><p> s20 - spread of continuous similarity with default 1 if consim=1.  For consim=2 guess of x's variance,
</p>
</li>
<li><p> v2 - spread of 'likelihood' for conitnuous similarity (smaller values place more weight on partitions with clusters that contain homogeneous  covariate values)
</p>
</li>
<li><p>  k0 - inverse scale for v (only used for N-NIG similarity model)
</p>
</li>
<li><p> nu0 - prior number of x &quot;observations&quot; (only used for N-NIG similarity model)
</p>
</li>
<li><p> a0 - dirichlet weight for categorical similarity with default of 0.1 (smaller values place more weight on partitions with individuals that are in the same category.)
</p>
</li>
<li><p>  alpha - weight associated with cluster-variance and Gower disimilarity
</p>
</li></ul>

</td></tr>
<tr><td><code id="curve_ppmx_+3A_mh">mh</code></td>
<td>
<p>two dimensional vector containing values for tunning parameter associated with MH update for sigma2 and sigma20</p>
</td></tr>
<tr><td><code id="curve_ppmx_+3A_draws">draws</code></td>
<td>
<p>number of MCMC iterates to be collected. default is 1100</p>
</td></tr>
<tr><td><code id="curve_ppmx_+3A_burn">burn</code></td>
<td>
<p>number of MCMC iterates discared as burn-in. default is 100</p>
</td></tr>
<tr><td><code id="curve_ppmx_+3A_thin">thin</code></td>
<td>
<p>number by which the MCMC chain is thinne. default is 1.  Thin must be selected so that it is a multilple of (draws - thin)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function fits a hierarhical functional data model where B-spline coefficients are clustered using either a PPM or a PPMx prior on partitions.
</p>


<h3>Value</h3>

<p>The function returns a list containing arrays filled with MCMC iterates corresponding to model parameters and model fit metrics. In order to provide more detail, in what follows let
</p>
<p>&quot;T&quot; - be the number of MCMC iterates collected,
</p>
<p>&quot;N&quot; - be the number of subjects/units,
</p>
<p>&quot;P&quot; - be the number of knots + degree of spline.
</p>
<p>The output list contains the following
</p>

<ul>
<li><p> Si - a matrix of dimension (T, N) containing MCMC iterates assocated with each subjects cluster label.
</p>
</li>
<li><p> nclus - a matrix  of dimension (T, 1) containing MCMC iterates associated with the number of clusters
</p>
</li>
<li><p> beta - an array of dimension (N, P, T) containing the MCMC iterates assocated with each subjects P-dimensional B-spline coefficients
</p>
</li>
<li><p> theta - an array of dimension (N, P, T) containing the MCMC iterates assocated with the cluster specific P-dimensional B-spline coefficients.  Each subjects theta value is reported.
</p>
</li>
<li><p> sig2 - a matrix of dimension (T, N) containing MCMC iterates associated with each subjects variance parameter (sigma2*_c_i)
</p>
</li>
<li><p> tau2 - a matrix of dimension (T, N) containing MCMC iterates associated with each the cluster-specific smoothing parameter for theta
</p>
</li>
<li><p> mu - a matrix of dimension (T, P) containing MCMC iterates for the the P-dimensional B-spline coefficients associated with the global mean.
</p>
</li>
<li><p> lam - a matrix of dimension (T, N) containing MCMC iterates for the cluster-specific lambda parameter that dictates the similarity of curves within a cluster
</p>
</li>
<li><p> beta0 - a matrix of dimension (T, N) containing MCMC iterates for the subject-specific intercepts
</p>
</li>
<li><p> mub0 - vector of length T containing MCMC iterates for mean of beta0
</p>
</li>
<li><p> sig2b0 - vector of length T containing MCMC iterates for variance of beta0
</p>
</li>
<li><p> like - a matrix of dimension (T, N) containing likelihood values at each MCMC iterate.
</p>
</li>
<li><p> WAIC - scalar containing the WAIC value
</p>
</li>
<li><p> lpml - scalar containing lpml value
</p>
</li>
<li><p> Hmat - a spline design matrix of dimension (N, P)
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>


# Example with balanced data.
# generate data for two clusters with 10 subjects each.

nobs &lt;- 100
nsubject &lt;- 2*10

set.seed(101)
xx &lt;- seq(0,2*pi, length=nobs)
y &lt;- cbind(replicate(n=10, sin(xx) + rnorm(nobs,0,0.5)),
           replicate(n=10, cos(xx) + rnorm(nobs,0,0.5)))

dat &lt;- data.frame(y=c(y),
                  z=rep(1:nobs, times=nsubject),
                  Name=rep(1:nsubject, each=nobs))

subject_obs_vec &lt;- dat$Name

nknots &lt;- 15



# Small number of iterates for illustrative purposes only
niter &lt;- 5000
nburn &lt;- 2000
nthin &lt;- 3
nout &lt;- (niter-nburn)/nthin

z &lt;- dat$z

## the order here is c(mu0, s20, v, k0, nu0, a0, alpha)
## If simularity is N-NIG then k0 and nu0 are used but v is not
## If simularity is N-N then v is used but no k0 and nu0
simparms &lt;- c(0.0, 1.0, 0.1, 1.0, 1.0, 0.1, 1)

fits &lt;- list()

# fit vgrf only
y &lt;- dat$y

modelPriors &lt;- c(0.5,      # Asig
                 1000^2,   # s2_mu
                 0,        # mb0
                 1000^2,   # s2b0
                 1,        # as2b0
                 1,        # bs2b0
                 1,        # at
                 1.0/0.05) # bt


fit &lt;- curve_ppmx(y=cbind(y), z=z,
             subject=subject_obs_vec,
             Xcon = NULL, Xcat = NULL,
             Xconp=NULL, Xcatp=NULL,
             PPM=TRUE, M=1,
             q=3, rw_order=1, balanced=1,
             nknots=nknots,  npredobs=1,
             Aparm=100,
             modelPriors=modelPriors,
             similarity_function=1,
             consim=1, calibrate=0,
             simParms=simparms,
             mh=c(0.1, 1e-4),
             draws=niter,
             burn=nburn,
             thin=nthin)


Hmat &lt;- fit$Hmat

# For a point estimate of partition, take first MCMC interate
# This is done only for illustrative purposes.  Recommend using
# the salso R package.

p.est &lt;- fit$Si[1,]

nc &lt;- length(unique(p.est))


oldpar &lt;- par(no.readonly = TRUE)


# Plot individual subject fits.

tmp &lt;- c(1,6,11,16)
par(mfrow=c(2,2))
for(j in tmp){
  bmn &lt;- apply(fit$beta[j,,],1,mean)
  b0mn &lt;- mean(fit$beta0[,j])

  ytmp &lt;- y[dat$Name==j]

  b0vec &lt;- rep(b0mn, nobs)

  plot(1:nobs,c(ytmp),
		  type='n',ylab="Response",
		  xlab="Time")

  points(1:nobs,ytmp)
  lines(1:nobs,  b0vec+Hmat%*%bmn, col=p.est[j],lwd=2)

}

# plot all curves in one plot
par(mfrow=c(1,1))

plot(dat$z, dat$y, type="n",ylab="",xlab="Time")

for(j in 1:nsubject){

  bmn &lt;- apply(fit$beta[j,,],1,mean)
  b0mn &lt;- mean(fit$beta0[,j])

  b0vec &lt;- rep(b0mn, nobs)

  lines((1:nobs),  b0vec+Hmat%*%bmn, col=p.est[j],lwd=0.5)

}


par(oldpar)






</code></pre>

<hr>
<h2 id='gaussian_ppmx'>Function that fits Gaussian PPMx model</h2><span id='topic+gaussian_ppmx'></span>

<h3>Description</h3>

<p><code>gaussian_ppmx</code> is the main function used to fit Gaussian PPMx model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gaussian_ppmx(y, X=NULL, Xpred=NULL,
                  meanModel=1,
                  cohesion=1,
                  M=1,
                  PPM = FALSE,
                  similarity_function=1,
                  consim=1,
                  calibrate=0,
                  simParms=c(0.0, 1.0, 0.1, 1.0, 2.0, 0.1, 1),
                  modelPriors=c(0, 100^2, 1, 1),
                  mh=c(0.5, 0.5),
                  draws=1100,burn=100,thin=1,
                  verbose=FALSE)

</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gaussian_ppmx_+3A_y">y</code></td>
<td>
<p>numeric vector for the response variable</p>
</td></tr>
<tr><td><code id="gaussian_ppmx_+3A_x">X</code></td>
<td>
<p>a data frame whose columns consist of covariates that will be incorporated in the partition model. Those with class of &quot;character&quot; or &quot;factor&quot; will be treated as categorical covariates.  All others will be treated as continuous covariates.</p>
</td></tr>
<tr><td><code id="gaussian_ppmx_+3A_xpred">Xpred</code></td>
<td>
<p>a data frame containing covariate values for which out-of-sample predictions are desired.  The format of and order of Xpred must be the same as that found in X.</p>
</td></tr>
<tr><td><code id="gaussian_ppmx_+3A_meanmodel">meanModel</code></td>
<td>
<p>Type of mean model included in the likelihood that is to be used.  Options are 1 or 2 with
</p>

<ul>
<li><p>  1 - cluster-specific means with no covariates in likelihood.
</p>
</li>
<li><p> 2 - cluster-specific intercepts and a global regression of the type Xbeta is included in the likelihood.
</p>
</li></ul>

</td></tr>
<tr><td><code id="gaussian_ppmx_+3A_cohesion">cohesion</code></td>
<td>
<p>Type of cohesion function to use in the PPMx prior.  Options are 1 or 2 with
</p>

<ul>
<li><p>  1 - Dirichlet process style of cohesion c(S) = M x (|S| - 1)!
</p>
</li>
<li><p>  2 - Uniform cohesion c(S) = 1
</p>
</li></ul>

</td></tr>
<tr><td><code id="gaussian_ppmx_+3A_m">M</code></td>
<td>
<p>Precision parameter.  Default is 1.</p>
</td></tr>
<tr><td><code id="gaussian_ppmx_+3A_ppm">PPM</code></td>
<td>
<p>Logical argument that indicates if the PPM or PPMx partition model should be employed.  If PPM = FALSE, then an X matrix must be supplied.</p>
</td></tr>
<tr><td><code id="gaussian_ppmx_+3A_similarity_function">similarity_function</code></td>
<td>
<p>Type of similarity function that is employed for the PPMx prior on partitions.  Options are 1-4 with
</p>

<ul>
<li><p>  1 - Auxilliary similarity
</p>
</li>
<li><p>  2 - Double dipper similarity
</p>
</li>
<li><p>  3 - Cluster variance or entropy for categorical covariates
</p>
</li>
<li><p> 4 - Mean Gower dissimilarity (Gower dissimilarity is not available if missing values are present in X)
</p>
</li></ul>

</td></tr>
<tr><td><code id="gaussian_ppmx_+3A_consim">consim</code></td>
<td>
<p>If similarity_function is set to either 1 or 2, then consim specifies the type of marginal likelihood used as the similarity function. Options are 1 or 2 with
</p>

<ul>
<li><p> 1 - N-N(m0, s20, v) (v variance of &ldquo;likelihood&rdquo;, m0 and s20 &ldquo;prior&rdquo; parameters),
</p>
</li>
<li><p> 2 - N-NIG(m0, k0, nu0, s20) (m0 and k0 center and inverse scalar of a Gaussian, and nu0 and s20 are the number of prior observations and prior variance guess of a Inverse-Chi-Square distribution.)
</p>
</li></ul>

</td></tr>
<tr><td><code id="gaussian_ppmx_+3A_calibrate">calibrate</code></td>
<td>
<p>Indicates if the similarity should be calibrated.  Options are 0-2 with
</p>

<ul>
<li><p> 0 - no calibration
</p>
</li>
<li><p> 1 - standardize similarity value for each covariate
</p>
</li>
<li><p> 2 - coarsening is applied so that each similarity is raised to the 1/p power</p>
</li></ul>

</td></tr>
<tr><td><code id="gaussian_ppmx_+3A_simparms">simParms</code></td>
<td>
<p>Vector of parameter values employed in the similarity function of the PPMx. Entries of the vector correspond to
</p>

<ul>
<li><p> m0 - center continuous similarity with default 0,
</p>
</li>
<li><p> s20 - spread of continuous similarity with default 1 if consim=1.  For consim=2 guess of x's variance,
</p>
</li>
<li><p> v2 - spread of 'likelihood' for conitnuous similarity (smaller values place more weight on partitions with clusters that contain homogeneous  covariate values)
</p>
</li>
<li><p>  k0 - inverse scale for v (only used for N-NIG similarity model)
</p>
</li>
<li><p> nu0 - prior number of x &quot;observations&quot; (only used for N-NIG similarity model)
</p>
</li>
<li><p> a0 - dirichlet weight for categorical similarity with default of 0.1 (smaller values place more weight on partitions with individuals that are in the same category.)
</p>
</li>
<li><p>  alpha - weight associated with cluster-variance and Gower disimilarity
</p>
</li></ul>

</td></tr>
<tr><td><code id="gaussian_ppmx_+3A_modelpriors">modelPriors</code></td>
<td>
<p>Vector of prior parameter values for priors assigned to parameters of the Gaussian data model.
</p>

<ul>
<li><p> m - prior mean for mu0 with default equal to 0,
</p>
</li>
<li><p> s2 - prior variance mu0 with default equal to 100^2,
</p>
</li>
<li><p> A - upper bound on sigma2*_j with default equal to 10
</p>
</li>
<li><p> A0 - upper bound on sig20 with default equal to 10
</p>
</li></ul>

</td></tr>
<tr><td><code id="gaussian_ppmx_+3A_mh">mh</code></td>
<td>
<p>two dimensional vector containing values for tunning parameter associated with MH update for sigma2 and sigma20</p>
</td></tr>
<tr><td><code id="gaussian_ppmx_+3A_draws">draws</code></td>
<td>
<p>number of MCMC iterates to be collected. default is 1100</p>
</td></tr>
<tr><td><code id="gaussian_ppmx_+3A_burn">burn</code></td>
<td>
<p>number of MCMC iterates discared as burn-in. default is 100</p>
</td></tr>
<tr><td><code id="gaussian_ppmx_+3A_thin">thin</code></td>
<td>
<p>number by which the MCMC chain is thinne. default is 1.  Thin must be selected so that it is a multilple of (draws - thin)</p>
</td></tr>
<tr><td><code id="gaussian_ppmx_+3A_verbose">verbose</code></td>
<td>
<p>Logical indicating if information regarding data and MCMC iterate should be printed to screen</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is able to fit a Gaussian PPM or PPMx model as detailed in (Mueller, Quintana, and Rosner, 2011).  The data model is a Gaussian distribution with cluster-specific means and variances.  If meanModel = 2, then a &ldquo;global&rdquo; regression component is added to the mean.  Conjugate priors are used for cluster-specific means while uniform priors are used for variance components.  A variety of options associated with the similarity function of the PPMx are available.  See Page, Quintana 2018; Mueller, Quintana, Rosner 2011 for more details.
</p>
<p>If covariate matrix contains missing values, then the approach described in  Page, Quintana, Mueller (2022) is automatically employed.  Missing values must be denoted using &quot;NA&quot;. Currently, NAs cannot be accommodated if a &ldquo;global&rdquo; regression is desired.
</p>
<p>We recommend standardizing covariates so thay they have mean zero and standard deviation one.  This makes the default values provided for the similarity function reasonable in most cases.  If covariates are standardized and meanModel = 2 the regression coefficients are estimated on the original scale and are ordered such that the continuous covariates appear first and the categorical covariates come after.
</p>
<p>The MCMC algorithm used to sample from the joint posterior distribution is based on algorithm 8 found in Neal 2000.
</p>


<h3>Value</h3>

<p>The function returns a list containing arrays filled with MCMC iterates corresponding to model parameters and model fit metrics. In order to provide more detail, in what follows let
</p>
<p>&quot;T&quot; - be the number of MCMC iterates collected,
</p>
<p>&quot;N&quot; - be the number of observations,
</p>
<p>&quot;P&quot; - be the number of predictions.
</p>
<p>&quot;C&quot; - be the total number of covariates
</p>
<p>The output list contains the following
</p>

<ul>
<li><p> mu - a matrix  of dimension (T, N) containing MCMC iterates associated with each subjects mean parameter (mu*_c_i).
</p>
</li>
<li><p> sig2 - a matrix of dimension (T, N) containing MCMC iterates associated with each subjects variance parameter (sigma2*_c_i)
</p>
</li>
<li><p> beta - if meanModel = 2, then this is a matrix of dimension (T,C) containing MCMC iterates associated coefficients in the global regression
</p>
</li>
<li><p> Si - a matrix of dimension (T, N) containing MCMC iterates assocated with each subjects cluster label.
</p>
</li>
<li><p> mu0 - vector of length T containing MCMC iterates for mu0 parameter
</p>
</li>
<li><p> sig20 - vector of length T containing MCMC iterates for sig20
</p>
</li>
<li><p> nclus - vector of length T containing number of clusters at each MCMC iterate
</p>
</li>
<li><p> like - a matrix of dimension (T, N) containing likelihood values at each MCMC iterate.
</p>
</li>
<li><p> WAIC - scalar containing the WAIC value
</p>
</li>
<li><p> lpml - scalar containing lpml value
</p>
</li>
<li><p> fitted.values - a matrix of dimension (T, N) containing fitted (or in sample predictions) for each subject at each MCMC iterate
</p>
</li>
<li><p> ppred - a matrix of dimension (T, P) containing out of sample preditions for each &quot;new&quot; subject at each MCMC iterate of the posterior predictive distribution
</p>
</li>
<li><p> predclass - a matrix of dimension (T, P) containing MCMC iterates of cluster two which &quot;new&quot; subject is allocated
</p>
</li>
<li><p> rbpred - a matrix of dimension (T, P) containing out of sample preditions for each &quot;new&quot; subject at each MCMC iterate based on the rao-blackwellized prediction
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>

data(bear)

# plot length, sex, and weight of bears
ck &lt;- c(4,3,2)
pairs(bear[,ck])


# response is weight
Y &lt;- bear$weight

# Continuous Covariate is length of chest
# Categorical covariate is sex
X &lt;- bear[,c("length", "sex")]
X$sex &lt;- as.factor(X$sex)

# Randomly partition data into 44 training and 10 testing
set.seed(1)
trainObs &lt;- sample(1:length(Y),44, replace=FALSE)

Ytrain &lt;- Y[trainObs]
Ytest &lt;- Y[-trainObs]

Xtrain &lt;- X[trainObs,,drop=FALSE]
Xtest &lt;- X[-trainObs,,drop=FALSE]

simParms &lt;- c(0.0, 1.0, 0.1, 1.0, 2.0, 0.1)
modelPriors &lt;- c(0, 100^2, 0.5*sd(Y), 100)
M &lt;- 1.0

niter &lt;- 100000
nburn &lt;- 50000
nthin &lt;- 50

nout &lt;- (niter - nburn)/nthin

mh &lt;- c(1,10)

# Run MCMC algorithm for Gaussian PPMx model
out1 &lt;- gaussian_ppmx(y=Ytrain, X=Xtrain, Xpred=Xtest,
              M=M, PPM=FALSE,
              meanModel = 1,
		          similarity_function=1,
		          consim=1,
		          calibrate=0,
		          simParms=simParms,
		          modelPriors = modelPriors,
		          draws=niter, burn=nburn, thin=nthin,
		          mh=mh)



# plot a select few posterior distributions
plot(density(out1$mu[,1])) # first observation's mean
plot(density(out1$sig2[,1])) # first observation's variance
plot(table(out1$nc)/nout,type='h') # distribution
plot(density(out1$mu0), type='l')
plot(density(out1$sig20))


# The first partition iterate is used for plotting
# purposes only. We recommended using the salso
# R-package to estimate the partition based on Si
pairs(bear[trainObs,ck],col=out1$Si[1,], pch=out1$Si[1,])


# Compare fit and predictions when covariates are not included
# in the partition model.  That is, refit data with PPM rather than PPMx
out2 &lt;- gaussian_ppmx(y=Ytrain, X=Xtrain, Xpred=Xtest,
              M=M, PPM=TRUE,
              meanModel = 1,
		          similarity_function=1,
		          consim=1,
		          calibrate=0,
		          simParms=simParms,
		          modelPriors = modelPriors,
		          draws=niter, burn=nburn, thin=nthin,
		          mh=mh)



oldpar &lt;- par(no.readonly = TRUE)

par(mfrow=c(1,2))
plot(Xtrain[,1], Ytrain, ylab="weight", xlab="length", pch=20)
points(Xtrain[,1], apply(out2$fitted,2,mean), col='red',pch=2, cex=1)
points(Xtrain[,1], apply(out1$fitted,2,mean), col='blue',pch=3, cex=1)
legend(x="topleft",legend=c("Observed","PPM","PPMx"),
          col=c("black","red","blue", "green"),pch=c(20,2,3,4))


plot(Xtest[,1], Ytest, ylab="weight", xlab="length",pch=20)
points(Xtest[,1], apply(out2$ppred,2,mean), col='red',pch=2, cex=1)
points(Xtest[,1], apply(out1$ppred,2,mean), col='blue',pch=3, cex=1)
legend(x="topleft",legend=c("Observed","PPM","PPMx"),
          col=c("black","red","blue","green"),pch=c(20,2,3,4))



par(oldpar)






</code></pre>

<hr>
<h2 id='icp_ppm'>Function that fits the multivariate independent product partition
change point model</h2><span id='topic+icp_ppm'></span>

<h3>Description</h3>

<p><code>icp_ppm</code> is a function that fits a Bayesian product partition change
point model. Each series is treated independently.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>icp_ppm(ydata,
         a0, b0,
         mltypes,
         thetas,
         nburn, nskip, nsave,
         verbose = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="icp_ppm_+3A_ydata">ydata</code></td>
<td>
<p>An <code class="reqn">L \times n</code> data matrix, where <code class="reqn">L</code> is the number of
time series and <code class="reqn">n</code>, the number of time points.</p>
</td></tr>
<tr><td><code id="icp_ppm_+3A_a0">a0</code></td>
<td>
<p>Vector of dimension <code class="reqn">L</code> with shape 1 Beta parameters (see
Details).</p>
</td></tr>
<tr><td><code id="icp_ppm_+3A_b0">b0</code></td>
<td>
<p>Vector of dimension <code class="reqn">L</code> with shape 2 Beta parameters (see
Details).</p>
</td></tr>
<tr><td><code id="icp_ppm_+3A_mltypes">mltypes</code></td>
<td>
<p>Type of marginal likelihood. Currently only available is:
</p>

<ul>
<li><p><code>mltypes = 1</code>. Observations within a block are conditionally
independent <code class="reqn">Normal(\mu, \sigma^2)</code> variates with mean <code class="reqn">\mu</code> and
variance <code class="reqn">\sigma^2</code>. The desired marginal likelihood is obtained after
integrating <code class="reqn">(\mu, \sigma^2)</code> with respect to a
<code class="reqn">Normal-Inverse-Gamma(\mu_0, \kappa_0, \alpha_0, \beta_0)</code>
prior.
</p>
</li></ul>

</td></tr>
<tr><td><code id="icp_ppm_+3A_thetas">thetas</code></td>
<td>
<p>An <code class="reqn">L \times q</code> matrix containing hyperparameters associated
with the marginal likelihood. The number of rows <code class="reqn">(L)</code> corresponds to the
number of series. The number of columns <code class="reqn">(q)</code> depend on the marginal
likelihood:
</p>

<ul>
<li><p>  If <code>mltypes = 1</code>, then <code class="reqn">q = 4</code> and <code>thetas</code> equals
the hyperparameter <code class="reqn">(\mu_{0}, \kappa_{0}, \alpha_{0}, \beta_{0})</code> of
the Normal-Inverse-Gamma prior.
</p>
</li></ul>

</td></tr>
<tr><td><code id="icp_ppm_+3A_nburn">nburn</code></td>
<td>
<p>The number of initial MCMC iterates to be discarded as burn-in.</p>
</td></tr>
<tr><td><code id="icp_ppm_+3A_nskip">nskip</code></td>
<td>
<p>The amount to thinning that should be applied to the MCMC chain.</p>
</td></tr>
<tr><td><code id="icp_ppm_+3A_nsave">nsave</code></td>
<td>
<p>Then number of MCMC iterates to be stored.</p>
</td></tr>
<tr><td><code id="icp_ppm_+3A_verbose">verbose</code></td>
<td>
<p>Logical indicating whether to print to screen the MCMC
progression. The default value is <code>verbose = FALSE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>As described in Barry and Hartigan (1992) and Loschi and Cruz (2002), for each
time series
<code class="reqn">\boldsymbol{y}_{i} = (y_{i,1}, \ldots , y_{i,n})'</code>:
</p>
<p style="text-align: center;"><code class="reqn">\boldsymbol{y}_{i} \mid \rho_{i} \sim
\prod_{j = 1}^{b_{i}}\mathcal{F}(\boldsymbol{y}_{i,j} \mid
\boldsymbol{\theta}_{i})</code>
</p>

<p style="text-align: center;"><code class="reqn">\rho_{i} \mid p_{i} \sim p_{i}^{b_{i} - 1}(1 - p_{i})^{n - b_{i}}</code>
</p>

<p style="text-align: center;"><code class="reqn">p_{i} \sim Beta(a_{i,0}, b_{i,0}).</code>
</p>

<p>Here, <code class="reqn">\rho_{i} = \{S_{i,1}, \ldots , S_{i,b_{i}}\}</code> is a partition of
the set <code class="reqn">\{1, \ldots , n\}</code> into <code class="reqn">b_{i}</code> contiguous blocks, and
<code class="reqn">\boldsymbol{y}_{i,j} = (y_{i,t} : t \in S_{i,j})'</code>. Also,
<code class="reqn">\mathcal{F}( \cdot \mid \boldsymbol{\theta}_{i})</code> is a marginal
likelihood function which depends on the nature of <code class="reqn">\boldsymbol{y}_{i}</code>,
indexed by a hyperparameter <code class="reqn">\boldsymbol{\theta}_{i}</code>. Notice that
<code class="reqn">p_{i}</code> is the probability of observing a change point in series <code class="reqn">i</code>,
at each time <code class="reqn">t \in \{2, \ldots , n\}</code>.
</p>


<h3>Value</h3>

<p>The function returns a list containing arrays filled with MCMC iterates
corresponding to model parameters. In order to provide more detail, in what
follows let <code class="reqn">M</code> be the number of MCMC iterates collected. The output list
contains the following:
</p>

<ul>
<li><p>C. An <code class="reqn">M \times \{L(n - 1)\}</code> matrix containing MCMC iterates
associated with each series indicators of a change point. The <code class="reqn">m</code>th
row in <code>C</code> is divided into <code class="reqn">L</code> blocks; the first <code class="reqn">(n - 1)</code>
change point indicators for time series 1, the next <code class="reqn">(n - 1)</code> change
point indicators for time series 2, and so on.
</p>
</li>
<li><p>P. An <code class="reqn">M \times \{L(n - 1)\}</code> matrix containing MCMC iterates
associated with each series probability of a change point. The <code class="reqn">m</code>th
row in <code>P</code> is divided into <code class="reqn">L</code> blocks; the first <code class="reqn">(n - 1)</code>
change point probabilities for time series 1, the next <code class="reqn">(n - 1)</code> change
point probabilities for time series 2, and so on.
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>
# Generate data that has two series, each with 100 observations
y1 &lt;- replicate(25, rnorm(4, c(-1, 0, 1, 2), c(0.1, 0.25, 0.5, 0.75)))
y2 &lt;- replicate(25, rnorm(4, c(2, 1, 0, -2), c(0.1, 0.25, 0.5, 0.75)))
y &lt;- rbind(c(t(y1)), c(t(y2)))
n &lt;- ncol(y)
# Marginal likelihood parameters
thetas &lt;- matrix(1, nrow = 2, ncol = 4)
thetas[1,] &lt;- c(0, 1, 2, 1)
thetas[2,] &lt;- c(0, 1, 2, 1)

# Fit the Bayesian ppm change point model
fit &lt;- icp_ppm(ydata = y,
               a0 = c(1, 1),
               b0 = c(1, 1),
               mltypes = c(1, 1),
               thetas = thetas,
               nburn = 1000, nskip = 1, nsave = 1000)

cpprobsL &lt;- matrix(apply(fit$C,2,mean), nrow=n-1, byrow=FALSE)



</code></pre>

<hr>
<h2 id='ordinal_ppmx'>Function that fits ordinal probit model with a PPMx as a prior on partitions</h2><span id='topic+ordinal_ppmx'></span>

<h3>Description</h3>

<p><code>ordinal_ppmx</code> is the main function used to fit ordinal probit model with a PPMx as a prior on partitions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ordinal_ppmx(y, co, X=NULL,Xpred=NULL,
              meanModel=1,
              cohesion=1,
              M=1,
              PPM = FALSE,
              similarity_function=1,
              consim=1,
              calibrate=0,
              simParms=c(0.0, 1.0, 0.1, 1.0, 2.0, 0.1, 1),
              modelPriors=c(0, 10, 1, 1),
              mh=c(0.5, 0.5),
              draws=1100,burn=100,thin=1,
              verbose=FALSE)</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ordinal_ppmx_+3A_y">y</code></td>
<td>
<p>Response vector containing ordinal categories that have been mapped to natural numbers beginning with 0</p>
</td></tr>
<tr><td><code id="ordinal_ppmx_+3A_co">co</code></td>
<td>
<p>Vector specifying the boundaries associated with auxiliary variables of the probit model.  If the number of ordinal categories is c, then the dimension of this vector must be c+1.</p>
</td></tr>
<tr><td><code id="ordinal_ppmx_+3A_x">X</code></td>
<td>
<p>a data frame whose columns consist of covariates that will be incorporated in the partition model.
Those with class of &quot;character&quot; or &quot;factor&quot; will be treated as categorical covariates.  All others
will be treated as continuous covariates. </p>
</td></tr>
<tr><td><code id="ordinal_ppmx_+3A_xpred">Xpred</code></td>
<td>
<p>a data frame containing covariate values for which out of sample predictions are desired.
The format of Xpred must be the same as for X.</p>
</td></tr>
<tr><td><code id="ordinal_ppmx_+3A_meanmodel">meanModel</code></td>
<td>
<p>Type of mean model included in the likelihood that is to be used
</p>

<ul>
<li><p> 1 - cluster-specific means with no covariates in likelihood.
</p>
</li>
<li><p> 2 - cluster-specific intercepts and a global regression of the type Xbeta is included in the likelihood.</p>
</li></ul>

</td></tr>
<tr><td><code id="ordinal_ppmx_+3A_cohesion">cohesion</code></td>
<td>
<p>Type of cohesion function to use in the PPMx prior.
</p>

<ul>
<li><p> 1 - Dirichlet process style of cohesion c(S) = M x (|S| - 1)!
</p>
</li>
<li><p> 2 - Uniform cohesion c(S) = 1</p>
</li></ul>

</td></tr>
<tr><td><code id="ordinal_ppmx_+3A_m">M</code></td>
<td>
<p>Precision parameter of the PPMx if a DP style cohesion is used.  See above.  Default is 1.</p>
</td></tr>
<tr><td><code id="ordinal_ppmx_+3A_ppm">PPM</code></td>
<td>
<p>Logical argument that indicates if the PPM or PPMx partition model should be employed.  If PPM = FALSE, then an X matrix must be supplied.</p>
</td></tr>
<tr><td><code id="ordinal_ppmx_+3A_similarity_function">similarity_function</code></td>
<td>
<p>Type of similarity function that is employed for the PPMx prior on partitions.  Options are
</p>

<ul>
<li><p> 1 - Auxilliary similarity
</p>
</li>
<li><p> 2 - Double dipper similarity
</p>
</li>
<li><p> 3 - Cluster variance or entropy for categorical covariates
</p>
</li>
<li><p> 4 - Mean Gower disimilarity (this one not available if missing values are present in X)</p>
</li></ul>

</td></tr>
<tr><td><code id="ordinal_ppmx_+3A_consim">consim</code></td>
<td>
<p>If similarity_function is set to either 1 or 2, then consim specifies the type of marginal likelihood used as the similarity function. Options are (see simparms argument for more details)
</p>

<ul>
<li><p> 1 - N-N(m0, s20, v) (v variance of &rdquo;likelihood&rdquo;, m0 and s20 &rdquo;prior&rdquo; parameters),
</p>
</li>
<li><p> 2 - N-NIG(m0, k0, nu0, s20) (m0 and k0 center and inverse scalar of a Gaussian, and nu0 and s20 are the number of prior observations and prior variance guess of a Inverse-Chi-Square distribution.)</p>
</li></ul>

</td></tr>
<tr><td><code id="ordinal_ppmx_+3A_calibrate">calibrate</code></td>
<td>
<p>This argument determines if the similarity should be calibrated.  Options are
</p>

<ul>
<li><p> 0 - no calibration
</p>
</li>
<li><p> 1 - standardize similarity value for each covariate
</p>
</li>
<li><p> 2 - coarsening is applied so that each similarity is raised to the 1/p power</p>
</li></ul>

</td></tr>
<tr><td><code id="ordinal_ppmx_+3A_simparms">simParms</code></td>
<td>
<p>Vector of parameter values employed in the similarity function of the PPMx. Entries of the vector correspond to
</p>

<ul>
<li><p> m0 - center continuous similarity with default 0,
</p>
</li>
<li><p> s20 - spread of continuous similarity with default 1 if consim=1.  For consim=2 guess of x's variance,
</p>
</li>
<li><p> v2 - spread of 'likelihood' for conitnuous similarity (smaller values place more weight on partitions with clusters that contain homogeneous  covariate values)
</p>
</li>
<li><p>  k0 - inverse scale for v (only used for N-NIG similarity model)
</p>
</li>
<li><p> nu0 - prior number of x &quot;observations&quot; (only used for N-NIG similarity model)
</p>
</li>
<li><p> a0 - dirichlet weight for categorical similarity with default of 0.1 (smaller values place more weight on partitions with individuals that are in the same category.)
</p>
</li>
<li><p>  alpha - weight associated with cluster-variance and Gower disimilarity
</p>
</li></ul>

</td></tr>
<tr><td><code id="ordinal_ppmx_+3A_modelpriors">modelPriors</code></td>
<td>
<p>Vector of prior parameter values for priors assigned to parameters of the Gaussian latent model.
</p>

<ul>
<li><p> m - prior mean for mu0 with default equal to 0,
</p>
</li>
<li><p> s2 - prior variance mu0 with default equal to 100^2,
</p>
</li>
<li><p> A - upper bound on sigma2*_j with default equal to 10
</p>
</li>
<li><p> A0 - upper bound on sig20 with default equal to 10
</p>
</li></ul>

</td></tr>
<tr><td><code id="ordinal_ppmx_+3A_mh">mh</code></td>
<td>
<p>two dimensional vector containing values for tunning parameter associated with MH update for sigma2 and sigma20</p>
</td></tr>
<tr><td><code id="ordinal_ppmx_+3A_draws">draws</code></td>
<td>
<p>number of MCMC iterates to be collected. default is 1100</p>
</td></tr>
<tr><td><code id="ordinal_ppmx_+3A_burn">burn</code></td>
<td>
<p>number of MCMC iterates discared as burn-in. default is 100</p>
</td></tr>
<tr><td><code id="ordinal_ppmx_+3A_thin">thin</code></td>
<td>
<p>number by which the MCMC chain is thinne. default is 1.  Thin must be selected so that it is a multilple of (draws - thin)</p>
</td></tr>
<tr><td><code id="ordinal_ppmx_+3A_verbose">verbose</code></td>
<td>
<p>Logical indicating if information regarding data and MCMC iterate should be printed to screen</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function fits an ordinal probit model with either a PPM or PPMx prior on partitions.  For details on the ordinal probit model see Kottas et al (2005) and Page, Quintana, Rosner (2020).  Cutpoints listed in the &ldquo;co&rdquo; argument can be arbitrarily selected, but values that are too far from zero will result in an algorithm that will require more burn-in.   Based on these cutpoints latent variables are introduced.  The latent variables are assumed to follow a Gaussian distribution with cluster-specific means and variances. If meanModel = 2, then a &ldquo;global&rdquo; regression component is added to the mean resulting in a model with cluster-specific parallel regression lines.  Commonly used conjugate priors are then employed in the regression component.
</p>
<p>If covariates contain missing values, then the approach developed in Page, Quintana, Mueller (2022) is automatically employed.  Missing values must be denoted using &quot;NA&quot;.  Currently, NAs cannot be accommodated if a &ldquo;global&rdquo; regression is desired (i.e., meanMode = 2).
</p>
<p>We recommend standardizing covariates so thay they have mean zero and standard deviation one.  This makes the default values provided for the similarity function reasonable in most cases.  If covariates are standardized and meanModel = 2 the regression coefficients are estimated on the original scale and are ordered such that the continuous covariates appear first and the categorical covariates come after.
</p>
<p>The MCMC algorithm used to sample from the joint posterior distribution is based on algorithm 8 found in Neal 2000.
</p>


<h3>Value</h3>

<p>The function returns a list containing arrays filled with MCMC iterates corresponding to model parameters and also returns a couple of model fit metrics. In order to provide more detail, in what follows let
</p>
<p>&quot;T&quot; - be the number of MCMC iterates collected,
</p>
<p>&quot;N&quot; - be the number of observations,
</p>
<p>&quot;P&quot; - be the number of predictions.
</p>
<p>&quot;C&quot; - be the total number of covariates
</p>
<p>The output list contains the following
</p>

<ul>
<li><p> mu - a matrix  of dimension (T, N) containing MCMC iterates associated with each subjects mean parameter (mu*_c_i).
</p>
</li>
<li><p> sig2 - a matrix of dimension (T, N) containing MCMC iterates associated with each sujbects variance parameter (sigma2*_c_i)
</p>
</li>
<li><p> beta - available only if meanModel = 2, then this is a matrix of dimension (T,C) containing MCMC iterates associated coefficients in the global regression
</p>
</li>
<li><p> Si - a matrix of dimension (T, N) containing MCMC iterates assocated with each subjects cluster label.
</p>
</li>
<li><p> zi - a matrix of dimension (T, N) containing MCMC iterates assocated with each subjects latent variable.
</p>
</li>
<li><p> mu0 - vector of length T containing MCMC iterates for mu0 parameter
</p>
</li>
<li><p> sig20 - vector of length T containing MCMC iterates for sig20
</p>
</li>
<li><p> nclus - vector of length T containing number of clusters at each MCMC iterate
</p>
</li>
<li><p> like - a matrix of dimension (T, N) containing likelihood values at each MCMC iterate.
</p>
</li>
<li><p> WAIC - scalar containing the WAIC value
</p>
</li>
<li><p> lpml - scalar containing lpml value
</p>
</li>
<li><p> fitted.values - a matrix of dimension (T, N) containing fitted values at the latent variable level for each subject at each MCMC iterate
</p>
</li>
<li><p> ppred - a matrix of dimension (T, P) containing out of sample preditions at the latent variable level for each &ldquo;new&rdquo; subject at each MCMC iterate
</p>
</li>
<li><p> predclass - a matrix of dimension (T, P) containing MCMC iterates of cluster two which &quot;new&quot; subject is allocated
</p>
</li>
<li><p> rbpred - a matrix of dimension (T, P) containing out of sample preditions at the latent variable level for each &quot;new&quot; subject at each MCMC iterate based on the rao-blackwellized prediction
</p>
</li>
<li><p> ord.fitted.values - a matrix of dimension (T, N) containing fitted values on the ordinal variable scale for each subject at each MCMC iterate.
</p>
</li>
<li><p> ord.ppred - a matrix of dimension (T, P) containing out of sample preditions on the ordinal variable scale for each &ldquo;new&rdquo; subject at each MCMC iterate from the posterior predictive distribution.
</p>
</li>
<li><p> ord.rbpred - a matrix of dimension (T, P) containing out of sample preditions on the ordinal variable scale  for each &quot;new&quot; subject at each MCMC iterate based on the rao-blackwellized prediction.
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>
n &lt;- 100
# Continuous Covariate
X1 &lt;- runif(n, -1,1)

# Binary Covariate
X2 &lt;- rbinom(n, 1, 0.5)

pi &lt;- exp(2*X1 + -2*X2)/(exp(2*X1 + -2*X2) + 1)

# Binary response
Y &lt;- rbinom(n, 1, pi)


keep &lt;- 1:(n-25)

# standardize X1 to have mean zero and sd 1.
X &lt;- data.frame(X1=scale(X1), X2=as.factor(X2))

Xtn &lt;- X[keep,]
ytn &lt;- Y[keep]
Xtt &lt;- X[-keep,]
ytt &lt;- Y[-keep]


# Since we have a binary response there are two "latent states".
# The boundaries of the latent states can be selected arbitrarily.
# Below I essentially use (-Inf, 0, Inf) to define the two latent spaces.
co &lt;- c(-1e5, 0, 1e5)


#             m0   s20  v  k0   n0   a0   alpha
simParms &lt;- c(0, 1.0, 0.5, 1.0, 2.0, 0.1, 1)
#                m  s2  s  s0
modelPriors &lt;- c(0, 10, 1, 1)


draws &lt;- 50000
burn &lt;- 25000
thin &lt;- 25
nout &lt;- (draws - burn)/thin


# Takes about 20 seconds to run
fit &lt;- ordinal_ppmx(y = ytn, co=co, X=Xtn, Xpred=Xtt,
                     meanModel=1,
                     similarity_function=1, consim=1,
                     calibrate=0,
                     simParms=simParms,
                     modelPriors=modelPriors,
                     draws=draws, burn=burn, thin=thin, verbose=FALSE)

# The first partition iterate is used for plotting
# purposes only. We recommended using the salso
# R-package to estimate the partition based on Si
pairs(cbind(Y, X), col=fit$Si[1,])

# in-sample confusion matrix
table(ytn, apply(fit$ord.fitted.values, 2, median))

# out-of-sample confusion matrix based on posterior predictive samples
table(ytt, apply(fit$ord.ppred, 2, median))


</code></pre>

<hr>
<h2 id='ozone'>Ozone data</h2><span id='topic+ozone'></span>

<h3>Description</h3>

<p>data set consists of 112 measurements of maximum daily ozone in
Rennes.  In addition,  temperature (T), nebulosity (Ne), and projection of
wind speed vectors (Vx) were measured three times daily (9:00, 12:00, and
15:00 hours) resulting in nine covariates.
</p>


<h3>Format</h3>

<p>data: A data frame with 112 rows and the following variables:
</p>

<dl>
<dt>num</dt><dd><p>observed number of cancer cases</p>
</dd>
<dt>maxO3</dt><dd><p>max daily ozone</p>
</dd>
<dt>T9-T15</dt><dd><p>temperature measured at 9:00, 12:00, and 15:00 hours</p>
</dd>
<dt>Ne9-Ne15</dt><dd><p>nebulosity measured at 9:00, 12:00, and 15:00 hours</p>
</dd>
<dt>Vx9-Vx15</dt><dd><p>projection of wind speed vectors  measured at 9:00, 12:00, and 15:00 hours</p>
</dd>
<dt>max03v</dt><dd><p>max daily ozone of previous day.</p>
</dd>
<dt>WindDirection</dt><dd><p>The wind direction</p>
</dd>
</dl>



<h3>Source</h3>

<p>Source of data: <a href="https://github.com/njtierney/user2018-missing-data-tutorial/">https://github.com/njtierney/user2018-missing-data-tutorial/</a>
</p>

<hr>
<h2 id='rppmx'>Function generates random realizations from a PPM or PPMx</h2><span id='topic+rppmx'></span>

<h3>Description</h3>

<p><code>rppmx</code> Employes the ploya urn sampling scheme to randomly generate a partition from the PPM or PPMx.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rppmx(m, X=NULL,
      similarity,
      simparm,
      M=1,
      m0=0,s20=1,v=2,k0=10,v0=1,alpha=1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rppmx_+3A_m">m</code></td>
<td>
<p>Number of unites that are allocated to partitions</p>
</td></tr>
<tr><td><code id="rppmx_+3A_x">X</code></td>
<td>
<p>a data frame whose columns consist of covariates that will be incorporated in the partition model.
Those with class of &quot;character&quot; or &quot;factor&quot; will be treated as categorical covaraites.  All others
will be treated as continuous covariates.  If NULL, then a PPM partition is produced.</p>
</td></tr>
<tr><td><code id="rppmx_+3A_similarity">similarity</code></td>
<td>
<p>Type of similarity function that is employed for covariates.  Options are
</p>
<p>1 - Auxilliary similarity,
</p>
<p>2 - Double dipper similarity
</p>
<p>3 - variance similarity</p>
</td></tr>
<tr><td><code id="rppmx_+3A_simparm">simparm</code></td>
<td>
<p>Type of similarty model employed for continuous covariates. Options are
</p>
<p>1 - N-N(m0, s20, v) (v variance of &rdquo;likelihood&rdquo;, m0 and s20 &rdquo;prior&rdquo; parameters),
</p>
<p>2 - N-NIG(m0,k0, k0, v0, s20) (m0 and k0 center and scale of Gaussian, n0 and s20 shape and scale of IG )</p>
</td></tr>
<tr><td><code id="rppmx_+3A_m">M</code></td>
<td>
<p>Precision parameter.  Default is 1.</p>
</td></tr>
<tr><td><code id="rppmx_+3A_m0">m0</code></td>
<td>
<p>Continuous similarity function value (see above)</p>
</td></tr>
<tr><td><code id="rppmx_+3A_s20">s20</code></td>
<td>
<p>Continuous similarity function value (see above)</p>
</td></tr>
<tr><td><code id="rppmx_+3A_v">v</code></td>
<td>
<p>Continuous similarity function value (see above)</p>
</td></tr>
<tr><td><code id="rppmx_+3A_k0">k0</code></td>
<td>
<p>Continuous similarity function value (see above)</p>
</td></tr>
<tr><td><code id="rppmx_+3A_v0">v0</code></td>
<td>
<p>Continuous similarity function value (see above)</p>
</td></tr>
<tr><td><code id="rppmx_+3A_alpha">alpha</code></td>
<td>
<p>Penalty value when using the variance similarity</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Use polya urn scheme to sample from the PPM or the PPMx
</p>


<h3>Value</h3>

<p>The function returns randomly generated partition
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
X &lt;- cbind(rnorm(100), rbinom(100,1,0.5))
p &lt;- rppmx(m=100, X=X, similarity=1, simparm=1, M=1)
p


</code></pre>

<hr>
<h2 id='scallops'>Scallops data</h2><span id='topic+scallops'></span>

<h3>Description</h3>

<p>Data set that provides the location and scallop catches in the Atlantic waters off the coasts of New Jersey and Long Island, New York.
</p>


<h3>Format</h3>

<p>data:  A data frame with 148 rows and the variables are the following:
</p>

<dl>
<dt>strata</dt><dd></dd>
<dt>sample</dt><dd></dd>
<dt>lat</dt><dd></dd>
<dt>long</dt><dd></dd>
<dt>tcatch</dt><dd></dd>
<dt>prerec</dt><dd></dd>
<dt>recruits</dt><dd></dd>
</dl>



<h3>Source</h3>

<p>Banerjee, S; Carline, B. P.; Gelfand, A. E.; (2015) Hierarchical Modeling and Analysis for Spatial Data 2nd Ed. CRC. Press
</p>

<hr>
<h2 id='SIMCE'>Standardized testing data in Chile</h2><span id='topic+SIMCE'></span>

<h3>Description</h3>

<p>Average standard testing results with average mother's and father's education level for schools in the greater Santiago area of Chile.  Measurements are recorded from 2005-2011 and spatial coordinates of
the schools are provided.
</p>


<h3>Format</h3>

<p>data: A data frame with 1072 rows and the following variables:
</p>

<dl>
<dt>coords.x1</dt><dd><p>longitude coordinates of school</p>
</dd>
<dt>coords.x2</dt><dd><p>lattitude coordinates of school</p>
</dd>
<dt>Schoole</dt><dd><p>Unique school identifier</p>
</dd>
<dt>COMUNA</dt><dd><p>Name of the commune in which the school resides</p>
</dd>
<dt>SIMCE05-SIMCE11</dt><dd><p>Math score of standardized test in 2005-2011</p>
</dd>
<dt>EDpad05-EDpad11</dt><dd><p>Average level of father's education of students that attended school 2005-2011</p>
</dd>
<dt>EDmad05-EDmad11</dt><dd><p>Average level of mother's education of students that attended school 2005-2011</p>
</dd>
</dl>



<h3>Source</h3>

<p>Page, G. L. and Quintana, F. A. (2016) Spatial Product Partition Models, Bayesian Anal., Volume 11, Number 1, 265-298.
</p>

<hr>
<h2 id='sppm'>Function that fits spatial product partition model with Gaussian likelihood</h2><span id='topic+sppm'></span>

<h3>Description</h3>

<p><code>sppm</code> is the main function used to fit model with Guassian likelihood and spatial PPM as prior on partitions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sppm(y,s,
    s.pred=NULL,
    cohesion,
    M=1,
    modelPriors=c(0, 100^2, 10, 10),
    cParms=c(1, 1.5, 0, 1, 2, 2),
    mh=c(0.5, 0.5),
    draws=1100,burn=100,thin=1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="sppm_+3A_y">y</code></td>
<td>
<p>numeric vector containing response variable</p>
</td></tr>
<tr><td><code id="sppm_+3A_s">s</code></td>
<td>
<p>Two-column matrix containing spatial locations (i.e., longitude and lattitude).</p>
</td></tr>
<tr><td><code id="sppm_+3A_s.pred">s.pred</code></td>
<td>
<p>Two-column matrix containing spatial locations at which out-of-sample predictions will be collected.</p>
</td></tr>
<tr><td><code id="sppm_+3A_cohesion">cohesion</code></td>
<td>
<p>Scalar that indicates which cohesion to use.
</p>

<ol>
<li><p> distance from centroids <br />
</p>
</li>
<li><p> upper bound <br />
</p>
</li>
<li><p> auxiliary similarity <br />
</p>
</li>
<li><p> double dipper similarity <br />
</p>
</li></ol>

</td></tr>
<tr><td><code id="sppm_+3A_m">M</code></td>
<td>
<p>Parameter related to Dirichlet process scale or dispersion parameter.</p>
</td></tr>
<tr><td><code id="sppm_+3A_modelpriors">modelPriors</code></td>
<td>
<p>Vector containing model prior values (see below for more details)</p>
</td></tr>
<tr><td><code id="sppm_+3A_cparms">cParms</code></td>
<td>
<p>Vector containing partition model prior values (see below for more details)</p>
</td></tr>
<tr><td><code id="sppm_+3A_mh">mh</code></td>
<td>
<p>Tuning standard deviations for metropolis updates for sigma2 and sigma20</p>
</td></tr>
<tr><td><code id="sppm_+3A_draws">draws</code></td>
<td>
<p>Number of MCMC samples to collect</p>
</td></tr>
<tr><td><code id="sppm_+3A_burn">burn</code></td>
<td>
<p>Number of the MCMC samples discarded in the burn-in phase of the sampler</p>
</td></tr>
<tr><td><code id="sppm_+3A_thin">thin</code></td>
<td>
<p>The amount of thinning desired for the chain</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The vector <code style="white-space: pre;">&#8288;modelPriors = c(m0, s20, ms, ms0)&#8288;</code> where each prior parameter is listed in the model description below.
</p>
<p>The cParm vector contains values associated with the cohesion function.<br />
<code style="white-space: pre;">&#8288;
cParm = c(
  epsilon value - cohesion 1 only,
  distance bound - cohesion 2 only,
  mu0 - center of NNIG for cohesion 3 and 4
  k0 - scale parm of gaussian part of NNIG for cohesion 3 and 4
  v0 - degrees of freedom IG part of NNIG for cohesion 3 and 4
  L0 - scale parm (scalar of identity matrix) IG part of NNIG for cohesion 3 and 4).&#8288;</code>
</p>
<p>The model this function fits is Gaussian likelihood model using the sPPM prior on partitions (Page and Quintana, 2016).  Specific model details are
</p>
<p style="text-align: center;"><code class="reqn">y_i | \mu^*, \sigma^{2*}, c_i \sim N(\mu_{c_i}^*, \sigma^{2*}_{c_i}), i=1,\ldots,n</code>
</p>

<p style="text-align: center;"><code class="reqn">\mu^*_j | \mu_0, \sigma^2_0 \sim N(\mu_0,\sigma^2_0)</code>
</p>

<p style="text-align: center;"><code class="reqn">\sigma^*_j | A \sim UN(0,  ms)</code>
</p>

<p style="text-align: center;"><code class="reqn">\rho|M,\xi  \sim sPPM</code>
</p>

<p>To complete the model specification, the folloing hyperpriors are assumed,
</p>
<p style="text-align: center;"><code class="reqn">\mu_0 | m, s^2 \sim N(m0,s0^2)</code>
</p>

<p style="text-align: center;"><code class="reqn">\sigma_0 | B  \sim UN(0,ms0)</code>
</p>

<p>Note that we employ uniform prior distributions on variance components as suggest in Gelman's 2006 Bayesian paper.  &quot;sPPM&quot; in the model specificaiton denotes the the spatial product partition model.  The computational implementation of the model is based algorithm 8 found in Neal's 2000 JCGS paper.
</p>


<h3>Value</h3>

<p>This function returns in a list all MCMC interates for each model parameter, posterior predictive, and fitted values.  In addition the LPML model fit metric is provided.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>




data(scallops)

Y&lt;-log(scallops[,5]+1)
s_coords &lt;- scallops[,3:4] #lat and long
m &lt;- dim(s_coords)[1]



# standardize spatial coordinates
smn &lt;- apply(s_coords,2,mean)
ssd &lt;- apply(s_coords,2,sd)
s_std &lt;- t((t(s_coords) - smn)/ssd)

# Create a grid of prediction locations
np &lt;- 10

sp &lt;- expand.grid(seq(min(s_coords[,1]), max(s_coords[,1]),length=np),
                   seq(min(s_coords[,2]), max(s_coords[,2]), length=np))

sp_std &lt;- t((t(sp) - smn)/ssd) # standardized prediction spatial coordinates


niter &lt;- 20000
nburn &lt;- 10000
nthin &lt;- 10
nout &lt;- (niter - nburn)/nthin


out &lt;- sppm(y=Y,s=s_std,s.pred=sp_std,cohesion=4, M=1, draws=niter, burn=nburn, thin=nthin)

# fitted values
fitted.values &lt;- out$fitted
fv.mn &lt;- apply(fitted.values, 2,mean)
mean((Y - fv.mn)^2) # MSE
out$lpml #lpml value

ppred &lt;- out$ppred
predmn &lt;- apply(ppred,2,mean)

# The first partition iterate is used for plotting
# purposes only. We recommended using the salso
# R-package to estimate the partition based on Si
Si &lt;- out$Si
plot(s_coords[,1], s_coords[,2], col=Si[1,])





</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
