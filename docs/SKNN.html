<!DOCTYPE html><html lang="en"><head><title>Help for package SKNN</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {SKNN}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#SKNN-package'><p> Super K-Nearest Neighbor (SKNN) Classification</p></a></li>
<li><a href='#Dist'><p> Finding the distance between two observations.</p></a></li>
<li><a href='#KNN'><p> K-Nearest Neighbor Classification</p></a></li>
<li><a href='#PCAy'><p> Revised PCA analysis</p></a></li>
<li><a href='#PCAyd'><p> Class to contain the results from revised PCA analysis.</p></a></li>
<li><a href='#SKNN'><p>Super K-Nearest Neighbor (SKNN) Classification</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>A Super K-Nearest Neighbor (SKNN) Classification Algorithm</td>
</tr>
<tr>
<td>Version:</td>
<td>4.1</td>
</tr>
<tr>
<td>Date:</td>
<td>2024-10-09</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Yarong Yang &lt;Yi.YA_yaya@hotmail.com&gt;</td>
</tr>
<tr>
<td>Depends:</td>
<td>methods, stats</td>
</tr>
<tr>
<td>Description:</td>
<td>It's a Super K-Nearest Neighbor classification method with using kernel density to describe weight of the distance between a training observation and the testing sample. </td>
</tr>
<tr>
<td>Collate:</td>
<td>SKNN.R Dist.R PCAy.R AllClasses.R KNN.R</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-10-08 18:35:48 UTC; yi_ya</td>
</tr>
<tr>
<td>Author:</td>
<td>Yarong Yang [aut, cre],
  Nader Ebrahimi [aut],
  Yoram Rubin [aut],
  Jacob Zhang [aut]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-10-08 20:10:01 UTC</td>
</tr>
</table>
<hr>
<h2 id='SKNN-package'> Super K-Nearest Neighbor (SKNN) Classification</h2><span id='topic+SKNN-package'></span>

<h3>Description</h3>

<p> It's a Super K-Nearest Neighbor classification method with using kernel density to describe 
the weight of the distance between a training observation and the sample to be classified.
</p>


<h3>Details</h3>


<table>
<tr>
 <td style="text-align: left;">
Package: </td><td style="text-align: left;"> SKNN</td>
</tr>
<tr>
 <td style="text-align: left;">
Type: </td><td style="text-align: left;"> Package</td>
</tr>
<tr>
 <td style="text-align: left;">
Version: </td><td style="text-align: left;"> 4.1</td>
</tr>
<tr>
 <td style="text-align: left;">
Date: </td><td style="text-align: left;"> 2024-10-09</td>
</tr>
<tr>
 <td style="text-align: left;">
License: </td><td style="text-align: left;"> GPL-2</td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>



<h3>Author(s)</h3>

<p> Yarong Yang, Nader Ebrahimi, Yoram Rubin, and Jacob Zhang  </p>


<h3>References</h3>

<p> Yarong Yang, Nader Ebrahimi, and Yoram Rubin.(2024) SKNN: A Super K-Nearest Neighbor Classification Algorithm. 
</p>
<p>Yarong Yang, Matt Over, and Yoram Rubin.(2012) Strategic Placement of Localization Devices (such as Pilot Points and Anchors) 
in Inverse Modeling Schemes. Water Resources Research, 48, W08519, doi:10.1029/2012WR011864. 
</p>
<p>B.B.W. Silverman.(1986) Density Estimation for Statistics and Data Analysis. London: Chapman and Hall.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
Sepal.Length&lt;-c(4.8, 5.1, 4.6, 5.3, 5.0, 5.7, 5.7, 6.2, 5.1, 5.7, 6.7, 6.3, 6.5, 6.2, 5.9)
Sepal.Width&lt;-c(3.0, 3.8, 3.2, 3.7, 3.3, 3.0, 2.9, 2.9, 2.5, 2.8, 3.0, 2.5, 3.0, 3.4, 3.0)
Petal.Length&lt;-c(1.4, 1.6, 1.4, 1.5, 1.4, 4.2, 4.2, 4.3, 3.0, 4.1, 5.2, 5.0, 5.2, 5.4, 5.1)
Petal.Width&lt;-c(0.3, 0.2, 0.2, 0.2, 0.2, 1.2, 1.3, 1.3, 1.1, 1.3, 2.3, 1.9, 2.0, 2.3, 1.8)
Species&lt;-as.factor(c(rep("red",5),rep("blue",5),rep("green",5)))
iris&lt;-cbind(Sepal.Length,Sepal.Width,Petal.Length,Petal.Width)
Res&lt;-length(nrow(iris))
k&lt;-10
for(i in 1:nrow(iris)) 
     Res[i]&lt;-SKNN(data=iris,Class=as.vector(Species),k=k,test=iris[i,])
accuracy&lt;-length(which(Res==Species))/length(Species)
plot(x=1:15,y=rep(1,15),col=as.vector(Species),lwd=4,ylim=c(0,3),xlab="",ylab="",
yaxt = "n",xaxt="n")
par(new=TRUE)
plot(x=1:15,y=rep(2,15),col=Res,lwd=4,ylim=c(0,3),xlab="",ylab="",yaxt = "n",xaxt="n")
ind&lt;-which(Res!=Species)
if(length(ind)&gt;0) {
  for(j in 1:length(ind))
      lines(x=c(ind[j],ind[j]),y=c(1+0.05,2-0.05))
}
text(5,0.3,paste("SKNN Misclassified:",length(ind)))
axis(2,at=2,labels="SKNN",las=1)
text(10,2.5,paste("k: ",k))

</code></pre>

<hr>
<h2 id='Dist'> Finding the distance between two observations.</h2><span id='topic+Dist'></span>

<h3>Description</h3>

<p>It's a function of finding the distance between two observations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Dist(x,y)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Dist_+3A_x">x</code></td>
<td>
<p> Numeric. A vector denoting an observation.</p>
</td></tr>
<tr><td><code id="Dist_+3A_y">y</code></td>
<td>
<p> Numeric. A vector denoting an observation.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list.</p>


<h3>Author(s)</h3>

<p>Yarong Yang</p>

<hr>
<h2 id='KNN'> K-Nearest Neighbor Classification </h2><span id='topic+KNN'></span>

<h3>Description</h3>

<p>It's implementation of the K-Nearest Neighbor classification method for data of any number of dimentions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>KNN(data, Class, k, test)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="KNN_+3A_data">data</code></td>
<td>
<p> Numeric. The training data set, matrix.</p>
</td></tr>
<tr><td><code id="KNN_+3A_class">Class</code></td>
<td>
<p> Character.  Class of the training observations, vector.</p>
</td></tr>
<tr><td><code id="KNN_+3A_k">k</code></td>
<td>
<p> Integer. The number of K to be used.     </p>
</td></tr>
<tr><td><code id="KNN_+3A_test">test</code></td>
<td>
<p> Numeric. The sample to be classified. </p>
</td></tr>
</table>


<h3>Value</h3>

<p>A character.</p>


<h3>Author(s)</h3>

<p>Yarong Yang</p>


<h3>References</h3>

<p>A.T. Covert and P. Hart. Nearest Neighbor Pattern Classification. IEEE Transactions on
Information Theory, 13(1): 21-27, 1967.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
Sepal.Length&lt;-c(4.8, 5.1, 4.6, 5.3, 5.0, 5.7, 5.7, 6.2, 5.1, 5.7, 6.7, 6.3, 6.5, 6.2, 5.9)
Sepal.Width&lt;-c(3.0, 3.8, 3.2, 3.7, 3.3, 3.0, 2.9, 2.9, 2.5, 2.8, 3.0, 2.5, 3.0, 3.4, 3.0)
Petal.Length&lt;-c(1.4, 1.6, 1.4, 1.5, 1.4, 4.2, 4.2, 4.3, 3.0, 4.1, 5.2, 5.0, 5.2, 5.4, 5.1)
Petal.Width&lt;-c(0.3, 0.2, 0.2, 0.2, 0.2, 1.2, 1.3, 1.3, 1.1, 1.3, 2.3, 1.9, 2.0, 2.3, 1.8)
Species&lt;-as.factor(c(rep("red",5),rep("blue",5),rep("green",5)))
iris&lt;-cbind(Sepal.Length,Sepal.Width,Petal.Length,Petal.Width)
Res&lt;-length(nrow(iris))
k&lt;-10
for(i in 1:nrow(iris)) 
     Res[i]&lt;-KNN(data=iris,Class=as.vector(Species),k=k,test=iris[i,])
accuracy&lt;-length(which(Res==Species))/length(Species)
plot(x=1:15,y=rep(1,15),col=as.vector(Species),lwd=4,ylim=c(0,3),xlab="",ylab="",
yaxt = "n",xaxt="n")
par(new=TRUE)
plot(x=1:15,y=rep(2,15),col=Res,lwd=4,ylim=c(0,3),xlab="",ylab="",yaxt = "n",xaxt="n")
ind&lt;-which(Res!=Species)
if(length(ind)&gt;0) {
  for(j in 1:length(ind))
      lines(x=c(ind[j],ind[j]),y=c(1+0.05,2-0.05))
}
text(5,0.3,paste("KNN Misclassified:",length(ind)))
axis(2,at=2,labels="KNN",las=1)
text(10,2.5,paste("k: ",k))

</code></pre>

<hr>
<h2 id='PCAy'> Revised PCA analysis </h2><span id='topic+PCAy'></span>

<h3>Description</h3>

<p>It's a revised PCA analysis.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PCAy(data)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="PCAy_+3A_data">data</code></td>
<td>
<p> Numeric. Data matrix for revised PCA analysis.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class &quot;PCAyd&quot;.</p>


<h3>Author(s)</h3>

<p>Yarong Yang and Yoram Rubin </p>


<h3>References</h3>

<p>Yarong Yang, Matt Over, and Yoram Rubin.(2012) Strategic Placement of Localization Devices (such as Pilot Points and Anchors) 
in Inverse Modeling Schemes. Water Resources Research, 48, W08519, doi:10.1029/2012WR011864. 
</p>
<p>Yarong Yang, Nader Ebrahimi, and Yoram Rubin.(2024) SKNN: A Super K-Nearest Neighbor Classification Algorithm. 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>Sepal.Length&lt;-c(4.8, 5.1, 4.6, 5.3, 5.0, 5.7, 5.7, 6.2, 5.1, 5.7, 6.7, 6.3,
 6.5, 6.2, 5.9)
Sepal.Width&lt;-c(3.0, 3.8, 3.2, 3.7, 3.3, 3.0, 2.9, 2.9, 2.5, 2.8, 3.0, 2.5,
 3.0, 3.4, 3.0)
Petal.Length&lt;-c(1.4, 1.6, 1.4, 1.5, 1.4, 4.2, 4.2, 4.3, 3.0, 4.1, 5.2, 5.0,
 5.2, 5.4, 5.1)
Petal.Width&lt;-c(0.3, 0.2, 0.2, 0.2, 0.2, 1.2, 1.3, 1.3, 1.1, 1.3, 2.3, 1.9,
 2.0, 2.3, 1.8)
dat&lt;-cbind(Sepal.Length,Sepal.Width,Petal.Length,Petal.Width)
Res&lt;-PCAy(dat)

</code></pre>

<hr>
<h2 id='PCAyd'> Class to contain the results from revised PCA analysis. </h2><span id='topic+PCAyd-class'></span>

<h3>Description</h3>

<p>The function PCAy returns object of class PCAyd.
</p>


<h3>Objects from the Class</h3>

<p>new(&quot;PCAyd&quot;,Var=new(&quot;numeric&quot;),PC=new(&quot;matrix&quot;),Scores=new(&quot;matrix&quot;),IScores=new(&quot;numeric&quot;))
</p>


<h3>Slots</h3>


<dl>
<dt><code>Var</code>:</dt><dd><p>An numeric vector giving the variance of each PC.</p>
</dd>
<dt><code>PC</code>:</dt><dd><p>A numeric matrix about the coefficients of each PC.</p>
</dd>
<dt><code>Scores</code>:</dt><dd><p>A numeric matrix showing the loading coefficiens of each PC.</p>
</dd>
<dt><code>IScores</code>:</dt><dd><p> A numeric vector with each element being the rowsum of Scores.  </p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Yarong Yang and Yoram Rubin
</p>


<h3>References</h3>

<p>Yarong Yang, Matt Over, and Yoram Rubin.(2012) Strategic Placement of Localization Devices (such as Pilot Points and Anchors) 
in Inverse Modeling Schemes. Water Resources Research, 48, W08519, doi:10.1029/2012WR011864. 
</p>
<p>Yarong Yang, Nader Ebrahimi, and Yoram Rubin.(2024) SKNN: A Super K-Nearest Neighbor Classification Algorithm. 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>showClass("PCAyd")
</code></pre>

<hr>
<h2 id='SKNN'>Super K-Nearest Neighbor (SKNN) Classification</h2><span id='topic+SKNN'></span>

<h3>Description</h3>

<p>It's a Super K-Nearest Neighbor classification method with using kernel density to describe weight of the distance between a training observation and the testing sample.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SKNN(data, Class, k, test)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="SKNN_+3A_data">data</code></td>
<td>
<p> Numeric. The training data set, matrix.</p>
</td></tr>
<tr><td><code id="SKNN_+3A_class">Class</code></td>
<td>
<p> Character.  Class of the training observations, vector.</p>
</td></tr>
<tr><td><code id="SKNN_+3A_k">k</code></td>
<td>
<p> Integer. The number of K to be used.     </p>
</td></tr>
<tr><td><code id="SKNN_+3A_test">test</code></td>
<td>
<p> Numeric. The sample to be classified. </p>
</td></tr>
</table>


<h3>Value</h3>

<p>A character.</p>


<h3>Author(s)</h3>

<p>Yarong Yang, Nader Ebrahimi, and Yoram Rubin</p>


<h3>References</h3>

<p> Yarong Yang, Nader Ebrahimi, and Yoram Rubin.(2024) SKNN: A Super K-Nearest Neighbor Classification Algorithm. 
</p>
<p>Yarong Yang, Matt Over, and Yoram Rubin.(2012) Strategic Placement of Localization Devices (such as Pilot Points and Anchors) 
in Inverse Modeling Schemes. Water Resources Research, 48, W08519, doi:10.1029/2012WR011864. 
</p>
<p>B.B.W. Silverman. Density Estimation for Statistics and Data Analysis. London: Chapman and
Hall, 1986.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
Sepal.Length&lt;-c(4.8, 5.1, 4.6, 5.3, 5.0, 5.7, 5.7, 6.2, 5.1, 5.7, 6.7, 6.3, 6.5, 6.2, 5.9)
Sepal.Width&lt;-c(3.0, 3.8, 3.2, 3.7, 3.3, 3.0, 2.9, 2.9, 2.5, 2.8, 3.0, 2.5, 3.0, 3.4, 3.0)
Petal.Length&lt;-c(1.4, 1.6, 1.4, 1.5, 1.4, 4.2, 4.2, 4.3, 3.0, 4.1, 5.2, 5.0, 5.2, 5.4, 5.1)
Petal.Width&lt;-c(0.3, 0.2, 0.2, 0.2, 0.2, 1.2, 1.3, 1.3, 1.1, 1.3, 2.3, 1.9, 2.0, 2.3, 1.8)
Species&lt;-as.factor(c(rep("red",5),rep("blue",5),rep("green",5)))
iris&lt;-cbind(Sepal.Length,Sepal.Width,Petal.Length,Petal.Width)
Res&lt;-length(nrow(iris))
k&lt;-10
for(i in 1:nrow(iris)) 
     Res[i]&lt;-SKNN(data=iris,Class=as.vector(Species),k=k,test=iris[i,])
accuracy&lt;-length(which(Res==Species))/length(Species)
plot(x=1:15,y=rep(1,15),col=as.vector(Species),lwd=4,ylim=c(0,3),xlab="",ylab="",
yaxt = "n",xaxt="n")
par(new=TRUE)
plot(x=1:15,y=rep(2,15),col=Res,lwd=4,ylim=c(0,3),xlab="",ylab="",yaxt = "n",xaxt="n")
ind&lt;-which(Res!=Species)
if(length(ind)&gt;0) {
  for(j in 1:length(ind))
      lines(x=c(ind[j],ind[j]),y=c(1+0.05,2-0.05))
}
text(5,0.3,paste("SKNN Misclassified:",length(ind)))
axis(2,at=2,labels="SKNN",las=1)
text(10,2.5,paste("k: ",k))

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
