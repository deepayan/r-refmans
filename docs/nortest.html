<!DOCTYPE html><html><head><title>Help for package nortest</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {nortest}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#ad.test'><p>Anderson-Darling test for normality</p></a></li>
<li><a href='#cvm.test'><p>Cramer-von Mises test for normality</p></a></li>
<li><a href='#lillie.test'><p>Lilliefors (Kolmogorov-Smirnov) test for  normality</p></a></li>
<li><a href='#pearson.test'><p>Pearson chi-square test for  normality</p></a></li>
<li><a href='#sf.test'><p>Shapiro-Francia test for  normality</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Title:</td>
<td>Tests for Normality</td>
</tr>
<tr>
<td>Version:</td>
<td>1.0-4</td>
</tr>
<tr>
<td>Date:</td>
<td>2015-07-29</td>
</tr>
<tr>
<td>Description:</td>
<td>Five omnibus tests for testing the composite hypothesis of
        normality.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>Imports:</td>
<td>stats</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2015-07-29 21:51:34 UTC; ligges</td>
</tr>
<tr>
<td>Author:</td>
<td>Juergen Gross [aut],
  Uwe Ligges [aut, cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Uwe Ligges &lt;ligges@statistik.tu-dortmund.de&gt;</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2015-07-30 00:14:57</td>
</tr>
</table>
<hr>
<h2 id='ad.test'>Anderson-Darling test for normality</h2><span id='topic+ad.test'></span>

<h3>Description</h3>

<p>Performs the Anderson-Darling test for  the composite hypothesis of normality, 
see e.g. Thode (2002, Sec. 5.1.4).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ad.test(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ad.test_+3A_x">x</code></td>
<td>
<p>a numeric vector of data values, the number of 
which must be greater than 7. Missing values are allowed.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Anderson-Darling test is an EDF omnibus test for the composite hypothesis of normality. 
The test statistic is 
</p>
<p style="text-align: center;"><code class="reqn">
A = -n -\frac{1}{n} \sum_{i=1}^{n} [2i-1] 
[\ln(p_{(i)}) + \ln(1 - p_{(n-i+1)})],
</code>
</p>

<p>where <code class="reqn">p_{(i)} = \Phi([x_{(i)} - \overline{x}]/s)</code>. Here, 
<code class="reqn">\Phi</code> is the cumulative distribution function 
of the standard normal distribution, and <code class="reqn">\overline{x}</code> and <code class="reqn">s</code> 
are mean and standard deviation of the data values. 
The p-value is computed from the modified statistic 
<code class="reqn">Z=A (1.0 + 0.75/n +2.25/n^{2})</code>\ according to Table 4.9 in 
Stephens (1986). 
</p>


<h3>Value</h3>

<p>A list with class &ldquo;htest&rdquo; containing the following components: 
</p>
<table>
<tr><td><code>statistic</code></td>
<td>
<p>the value of the Anderson-Darling statistic.</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>the p-value for the test.</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>the character string &ldquo;Anderson-Darling normality test&rdquo;.</p>
</td></tr>
<tr><td><code>data.name</code></td>
<td>
<p>a character string giving the name(s) of the data.</p>
</td></tr> 
</table>


<h3>Note</h3>

<p>The Anderson-Darling test is the recommended EDF test by Stephens (1986). Compared to the 
Cramer-von Mises test (as second choice) it gives more weight to the tails of the distribution.</p>


<h3>Author(s)</h3>

<p>Juergen Gross</p>


<h3>References</h3>

<p>Stephens, M.A. (1986): Tests based on EDF statistics. In:
D'Agostino, R.B. and Stephens, M.A., eds.: Goodness-of-Fit Techniques.
Marcel Dekker, New York.
</p>
<p>Thode Jr., H.C. (2002): Testing for  Normality. Marcel Dekker, New York.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+shapiro.test">shapiro.test</a></code> for performing the Shapiro-Wilk test for normality. 
<code><a href="#topic+cvm.test">cvm.test</a></code>, <code><a href="#topic+lillie.test">lillie.test</a></code>, 
<code><a href="#topic+pearson.test">pearson.test</a></code>, <code><a href="#topic+sf.test">sf.test</a></code> for performing further tests for normality.
<code><a href="stats.html#topic+qqnorm">qqnorm</a></code> for producing a normal quantile-quantile plot.</p>


<h3>Examples</h3>

<pre><code class='language-R'>ad.test(rnorm(100, mean = 5, sd = 3))
ad.test(runif(100, min = 2, max = 4))

</code></pre>

<hr>
<h2 id='cvm.test'>Cramer-von Mises test for normality</h2><span id='topic+cvm.test'></span>

<h3>Description</h3>

<p>Performs the Cramer-von Mises test for the composite hypothesis of normality, 
see e.g. Thode (2002, Sec. 5.1.3).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cvm.test(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cvm.test_+3A_x">x</code></td>
<td>
<p>a numeric vector of data values, the number of 
which must be greater than 7. Missing values are allowed.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Cramer-von Mises test is an EDF omnibus test for the composite hypothesis of normality. 
The test statistic is 
</p>
<p style="text-align: center;"><code class="reqn">
W = \frac{1}{12 n} + \sum_{i=1}^{n} \left(p_{(i)} - \frac{2i-1}{2n}\right)^2,
</code>
</p>

<p>where <code class="reqn">p_{(i)} = \Phi([x_{(i)} - \overline{x}]/s)</code>. Here, 
<code class="reqn">\Phi</code> is the cumulative distribution function 
of the standard normal distribution, and <code class="reqn">\overline{x}</code> and <code class="reqn">s</code> 
are mean and standard deviation of the data values. 
The p-value is computed from the modified statistic 
<code class="reqn">Z=W (1.0 + 0.5/n)</code> according to Table 4.9 in 
Stephens (1986). 
</p>


<h3>Value</h3>

<p>A list with class &ldquo;htest&rdquo; containing the following components: 
</p>
<table>
<tr><td><code>statistic</code></td>
<td>
<p>the value of the Cramer-von Mises statistic.</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>the p-value for the test.</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>the character string &ldquo;Cramer-von Mises normality test&rdquo;.</p>
</td></tr>
<tr><td><code>data.name</code></td>
<td>
<p>a character string giving the name(s) of the data.</p>
</td></tr> 
</table>


<h3>Author(s)</h3>

<p>Juergen Gross</p>


<h3>References</h3>

<p>Stephens, M.A. (1986): Tests based on EDF statistics. In:
D'Agostino, R.B. and Stephens, M.A., eds.: Goodness-of-Fit Techniques.
Marcel Dekker, New York.
</p>
<p>Thode Jr., H.C. (2002): Testing for  Normality. Marcel Dekker, New York.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+shapiro.test">shapiro.test</a></code> for performing the Shapiro-Wilk test for normality. 
<code><a href="#topic+ad.test">ad.test</a></code>, <code><a href="#topic+lillie.test">lillie.test</a></code>, 
<code><a href="#topic+pearson.test">pearson.test</a></code>, <code><a href="#topic+sf.test">sf.test</a></code> for performing further tests for normality.
<code><a href="stats.html#topic+qqnorm">qqnorm</a></code> for producing a normal quantile-quantile plot.</p>


<h3>Examples</h3>

<pre><code class='language-R'>cvm.test(rnorm(100, mean = 5, sd = 3))
cvm.test(runif(100, min = 2, max = 4))

</code></pre>

<hr>
<h2 id='lillie.test'>Lilliefors (Kolmogorov-Smirnov) test for  normality</h2><span id='topic+lillie.test'></span>

<h3>Description</h3>

<p>Performs the Lilliefors (Kolmogorov-Smirnov) test for the composite hypothesis of normality,
see e.g. Thode (2002, Sec. 5.1.1).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lillie.test(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lillie.test_+3A_x">x</code></td>
<td>
<p>a numeric vector of data values, the number of
which must be greater than 4. Missing values are allowed.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Lilliefors (Kolmogorov-Smirnov) test is an EDF omnibus test for the composite
hypothesis of normality. The test statistic is the maximal absolute difference
between empirical and
hypothetical cumulative distribution function. It may be computed as
<code class="reqn">D=\max\{D^{+}, D^{-}\}</code> with
</p>
<p style="text-align: center;"><code class="reqn">
D^{+} = \max_{i=1,\ldots, n}\{i/n - p_{(i)}\},
D^{-} = \max_{i=1,\ldots, n}\{p_{(i)} - (i-1)/n\},
</code>
</p>

<p>where <code class="reqn">p_{(i)} = \Phi([x_{(i)} - \overline{x}]/s)</code>. Here,
<code class="reqn">\Phi</code> is the cumulative distribution function
of the standard normal distribution, and <code class="reqn">\overline{x}</code> and <code class="reqn">s</code>
are mean and standard deviation of the data values.
The p-value is computed from the Dallal-Wilkinson (1986) formula, which is claimed to
be only reliable when the p-value is smaller than 0.1. If the Dallal-Wilkinson
p-value turns out to be greater than 0.1, then the p-value is computed from the distribution of
the modified statistic <code class="reqn">Z=D (\sqrt{n}-0.01+0.85/\sqrt{n})</code>, see Stephens (1974),
the actual p-value formula being obtained by a simulation and approximation process.</p>


<h3>Value</h3>

<p>A list with class &ldquo;htest&rdquo; containing the following components:
</p>
<table>
<tr><td><code>statistic</code></td>
<td>
<p>the value of the Lilliefors (Kolomogorv-Smirnov) statistic.</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>the p-value for the test.</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>the character string &ldquo;Lilliefors (Kolmogorov-Smirnov) normality test&rdquo;.</p>
</td></tr>
<tr><td><code>data.name</code></td>
<td>
<p>a character string giving the name(s) of the data.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The Lilliefors (Kolomorov-Smirnov) test is the most famous EDF omnibus test for normality.
Compared to the Anderson-Darling test and the Cramer-von Mises test it is known to perform worse.
Although the test statistic obtained from <code>lillie.test(x)</code> is the same as that obtained from
<code>ks.test(x, "pnorm", mean(x), sd(x))</code>, it is not correct to use the p-value from the latter
for the composite hypothesis of normality (mean and variance unknown),
since the distribution of the test statistic is different when the parameters are estimated.
</p>
<p>The function call <code>lillie.test(x)</code> essentially produces
the same result as the S-PLUS function call <code>ks.gof(x)</code>
with the distinction that the p-value is not set to 0.5 when
the Dallal-Wilkinson approximation yields a p-value greater than 0.1. (Actually,
the alternative p-value approximation is provided for the complete range of test statistic values,
but is only used when the Dallal-Wilkinson approximation fails.)</p>


<h3>Author(s)</h3>

<p>Juergen Gross</p>


<h3>References</h3>

<p>Dallal, G.E. and Wilkinson, L. (1986):
An analytic approximation to the distribution of Lilliefors' test for normality.
The American Statistician, 40, 294&ndash;296.
</p>
<p>Stephens, M.A. (1974): EDF statistics for goodness of fit and some comparisons.
Journal of the American Statistical Association, 69, 730&ndash;737.
</p>
<p>Thode Jr., H.C. (2002): Testing for  Normality. Marcel Dekker, New York.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+shapiro.test">shapiro.test</a></code> for performing the Shapiro-Wilk test for normality.
<code><a href="#topic+ad.test">ad.test</a></code>, <code><a href="#topic+cvm.test">cvm.test</a></code>,
<code><a href="#topic+pearson.test">pearson.test</a></code>, <code><a href="#topic+sf.test">sf.test</a></code> for performing further tests for normality.
<code><a href="stats.html#topic+qqnorm">qqnorm</a></code> for producing a normal quantile-quantile plot.</p>


<h3>Examples</h3>

<pre><code class='language-R'>lillie.test(rnorm(100, mean = 5, sd = 3))
lillie.test(runif(100, min = 2, max = 4))

</code></pre>

<hr>
<h2 id='pearson.test'>Pearson chi-square test for  normality</h2><span id='topic+pearson.test'></span>

<h3>Description</h3>

<p>Performs the Pearson chi-square test for the composite hypothesis of normality,
see e.g. Thode (2002, Sec. 5.2).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pearson.test(x, n.classes = ceiling(2 * (n^(2/5))), adjust = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pearson.test_+3A_x">x</code></td>
<td>
<p>a numeric vector of data values. Missing values are allowed.</p>
</td></tr>
<tr><td><code id="pearson.test_+3A_n.classes">n.classes</code></td>
<td>
<p>The number of classes. The default is due to Moore (1986).</p>
</td></tr>
<tr><td><code id="pearson.test_+3A_adjust">adjust</code></td>
<td>
<p>logical; if <code>TRUE</code> (default), the p-value is computed from
a chi-square distribution with <code>n.classes</code>-3 degrees of freedom, otherwise
from a chi-square distribution with <code>n.classes</code>-1 degrees of freedom.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Pearson test statistic is <code class="reqn">P=\sum (C_{i} - E_{i})^{2}/E_{i}</code>,
where <code class="reqn">C_{i}</code> is the number of counted and <code class="reqn">E_{i}</code> is the number of expected observations
(under the hypothesis) in class <code class="reqn">i</code>. The classes are build is such a way that they are equiprobable under the hypothesis
of normality. The p-value is computed from a chi-square distribution with <code>n.classes</code>-3 degrees of freedom
if <code>adjust</code> is <code>TRUE</code> and from a chi-square distribution with <code>n.classes</code>-1
degrees of freedom otherwise. In both cases this is not (!) the correct p-value,
lying somewhere between the two, see also Moore (1986).
</p>


<h3>Value</h3>

<p>A list with class &ldquo;htest&rdquo; containing the following components:
</p>
<table>
<tr><td><code>statistic</code></td>
<td>
<p>the value of the Pearson chi-square statistic.</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>the p-value for the test.</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>the character string &ldquo;Pearson chi-square normality test&rdquo;.</p>
</td></tr>
<tr><td><code>data.name</code></td>
<td>
<p>a character string giving the name(s) of the data.</p>
</td></tr>
<tr><td><code>n.classes</code></td>
<td>
<p>the number of classes used for the test.</p>
</td></tr>
<tr><td><code>df</code></td>
<td>
<p>the degress of freedom of the chi-square distribution used to compute the p-value.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The Pearson chi-square test is usually not recommended for testing the composite hypothesis of normality
due to its inferior power properties compared to other tests. It is common practice to compute the p-value
from the chi-square distribution with <code>n.classes</code> - 3 degrees of freedom, in order to adjust for the
additional estimation of two parameters. (For the simple hypothesis of normality (mean and variance known)
the test statistic is asymptotically chi-square distributed with
<code>n.classes</code> - 1 degrees of freedom.)
This is, however, not correct as long as the parameters are estimated by <code>mean(x)</code> and <code>var(x)</code>
(or <code>sd(x)</code>), as it is usually done, see Moore (1986) for details.
Since the true p-value is somewhere between the two, it is suggested to run <code>pearson.test</code> twice, with
<code>adjust = TRUE</code> (default) and with <code>adjust = FALSE</code>.
It is also suggested to slightly change the default number of classes, in order
to see the effect on the p-value. Eventually, it is suggested not to rely upon the result of the test.
</p>
<p>The function call <code>pearson.test(x)</code> essentially produces
the same result as the S-PLUS function call <code>chisq.gof((x-mean(x))/sqrt(var(x)), n.param.est=2)</code>.
</p>


<h3>Author(s)</h3>

<p>Juergen Gross</p>


<h3>References</h3>

<p>Moore, D.S. (1986): Tests of the chi-squared type. In:
D'Agostino, R.B. and Stephens, M.A., eds.: Goodness-of-Fit Techniques.
Marcel Dekker, New York.
</p>
<p>Thode Jr., H.C. (2002): Testing for  Normality. Marcel Dekker, New York.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+shapiro.test">shapiro.test</a></code> for performing the Shapiro-Wilk test for normality.
<code><a href="#topic+ad.test">ad.test</a></code>, <code><a href="#topic+cvm.test">cvm.test</a></code>,
<code><a href="#topic+lillie.test">lillie.test</a></code>, <code><a href="#topic+sf.test">sf.test</a></code> for performing further tests for normality.
<code><a href="stats.html#topic+qqnorm">qqnorm</a></code> for producing a normal quantile-quantile plot.</p>


<h3>Examples</h3>

<pre><code class='language-R'>pearson.test(rnorm(100, mean = 5, sd = 3))
pearson.test(runif(100, min = 2, max = 4))

</code></pre>

<hr>
<h2 id='sf.test'>Shapiro-Francia test for  normality</h2><span id='topic+sf.test'></span>

<h3>Description</h3>

<p>Performs the Shapiro-Francia  test for the composite hypothesis of normality, 
see e.g. Thode (2002, Sec. 2.3.2).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sf.test(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sf.test_+3A_x">x</code></td>
<td>
<p>a numeric vector of data values, the number of 
which must be between 5 and 5000. Missing values are allowed.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The test statistic of the Shapiro-Francia test is simply the 
squared correlation between the ordered sample values and the (approximated) 
expected ordered quantiles from the standard normal
distribution. The p-value is computed from the formula given by Royston (1993).
</p>


<h3>Value</h3>

<p>A list with class &ldquo;htest&rdquo; containing the following components: 
</p>
<table>
<tr><td><code>statistic</code></td>
<td>
<p>the value of the Shapiro-Francia  statistic.</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>the p-value for the test.</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>the character string &ldquo;Shapiro-Francia normality test&rdquo;.</p>
</td></tr>
<tr><td><code>data.name</code></td>
<td>
<p>a character string giving the name(s) of the data.</p>
</td></tr> 
</table>


<h3>Note</h3>

<p>The Shapiro-Francia test is known to perform well, 
see also the comments by Royston (1993). The expected ordered quantiles 
from the standard normal distribution are approximated by 
<code>qnorm(ppoints(x, a = 3/8))</code>, being slightly different from the approximation
<code>qnorm(ppoints(x, a = 1/2))</code> used for the normal quantile-quantile plot by 
<code><a href="stats.html#topic+qqnorm">qqnorm</a></code> for sample sizes greater than 10.</p>


<h3>Author(s)</h3>

<p>Juergen Gross</p>


<h3>References</h3>

<p>Royston, P. (1993): A pocket-calculator algorithm for the
Shapiro-Francia test for non-normality: an application to medicine.
Statistics in Medicine, 12, 181&ndash;184.
</p>
<p>Thode Jr., H.C. (2002): Testing for  Normality. Marcel Dekker, New York.</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+shapiro.test">shapiro.test</a></code> for performing the Shapiro-Wilk test for normality. 
<code><a href="#topic+ad.test">ad.test</a></code>, <code><a href="#topic+cvm.test">cvm.test</a></code>, 
<code><a href="#topic+lillie.test">lillie.test</a></code>, <code><a href="#topic+pearson.test">pearson.test</a></code> for performing further tests for normality.
<code><a href="stats.html#topic+qqnorm">qqnorm</a></code> for producing a normal quantile-quantile plot.</p>


<h3>Examples</h3>

<pre><code class='language-R'>sf.test(rnorm(100, mean = 5, sd = 3))
sf.test(runif(100, min = 2, max = 4))

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
