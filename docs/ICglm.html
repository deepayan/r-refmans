<!DOCTYPE html><html lang="en"><head><title>Help for package ICglm</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {ICglm}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#AIC'><p>Akaike Information Criterion</p></a></li>
<li><a href='#BIC'><p>Bayesian Information Criterion</p></a></li>
<li><a href='#CAIC'><p>Consistent Akaike's Information Criterion and Consistent Akaike's Information Criterion with Fisher Information</p></a></li>
<li><a href='#FIC'><p>Fisher Information Criterion</p></a></li>
<li><a href='#GCV'><p>Generalized Cross-Validation</p></a></li>
<li><a href='#HBIC'><p>Haughton Bayesian information criterion</p></a></li>
<li><a href='#HQIC'><p>Hannan-Quinn Information Criterion</p></a></li>
<li><a href='#IBIC'><p>Information Matrix-Based Information Criterion</p></a></li>
<li><a href='#IC'><p>Information Criteria</p></a></li>
<li><a href='#ICOMP'><p>Informational Complexity</p></a></li>
<li><a href='#JIC'><p>Joint Information Criterion</p></a></li>
<li><a href='#KIC'><p>Kullback–Leibler Information Criterion</p></a></li>
<li><a href='#reverse_fisher'><p>Reverse Fisher Matrix</p></a></li>
<li><a href='#SPBIC'><p>Scaled Unit Information Prior Bayesian Information Criterion</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Title:</td>
<td>Information Criteria for Generalized Linear Regression</td>
</tr>
<tr>
<td>Version:</td>
<td>0.1.0</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Fatih Saglam &lt;fatih.saglam@omu.edu.tr&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Calculate various information criteria in literature for "lm" and "glm" objects.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>Imports:</td>
<td>stats, Matrix</td>
</tr>
<tr>
<td>Suggests:</td>
<td>MASS</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>false</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.1</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2021-11-11 07:31:46 UTC; Fatih</td>
</tr>
<tr>
<td>Author:</td>
<td>Fatih Saglam <a href="https://orcid.org/0000-0002-2084-2008"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cre],
  Emre Dunder [aut]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2021-11-11 19:10:08 UTC</td>
</tr>
</table>
<hr>
<h2 id='AIC'>Akaike Information Criterion</h2><span id='topic+AIC'></span><span id='topic+AIC4'></span>

<h3>Description</h3>

<p>Calculates Akaike Information Criterion (AIC) and its variants for &quot;lm&quot; and &quot;glm&quot; objects.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>AIC(model)

AIC4(model)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="AIC_+3A_model">model</code></td>
<td>
<p>a &quot;lm&quot; or &quot;glm&quot; object</p>
</td></tr>
</table>


<h3>Details</h3>

<p>AIC (Akaike, 1973) is calculated as
</p>
<p style="text-align: center;"><code class="reqn">-2LL(theta) + 2k</code>
</p>

<p>and AIC4 (Bozdogan, 1994) as
</p>
<p style="text-align: center;"><code class="reqn">-2LL(theta) + 2klog</code>
</p>



<h3>Value</h3>

<p>AIC or AIC4 measurement of the model
</p>


<h3>References</h3>

<p>Akaike H., 1973. Maximum likelihood identification of Gaussian
autoregressive moving average models. Biometrika, 60(2), 255-265.
</p>
<p>Bozdogan, H. 1994. Mixture-model cluster analysis using model
selection criteria and a new informational measure of complexity.
In Proceedings of the first US/Japan conference on the frontiers
of statistical modeling: An informational approach, 69–113.
Dordrecht: Springer.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x1 &lt;- rnorm(100, 3, 2)
x2 &lt;- rnorm(100, 5, 3)
x3 &lt;- rnorm(100, 67, 5)
err &lt;- rnorm(100, 0, 4)

## round so we can use it for Poisson regression
y &lt;- round(3 + 2*x1 - 5*x2 + 8*x3 + err)

m1 &lt;- lm(y~x1 + x2 + x3)
m2 &lt;- glm(y~x1 + x2 + x3, family = "gaussian")
m3 &lt;- glm(y~x1 + x2 + x3, family = "poisson")

AIC(m1)
AIC(m2)
AIC(m3)
AIC4(m1)
AIC4(m2)
AIC4(m3)

</code></pre>

<hr>
<h2 id='BIC'>Bayesian Information Criterion</h2><span id='topic+BIC'></span><span id='topic+BICadj'></span><span id='topic+BICQ'></span>

<h3>Description</h3>

<p>Calculates Bayesian Information Criterion (BIC) and its variants (BICadj, BICQ) for &quot;lm&quot; and &quot;glm&quot; objects.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BIC(model)

BICadj(model)

BICQ(model, q = 0.25)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="BIC_+3A_model">model</code></td>
<td>
<p>a &quot;lm&quot; or &quot;glm&quot; object</p>
</td></tr>
<tr><td><code id="BIC_+3A_q">q</code></td>
<td>
<p>adjustment parameter for <code>BICQ</code>. Default is 0.25.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>BIC (Schwarz, 1978) is calculated as
</p>
<p style="text-align: center;"><code class="reqn">-2LL(theta) + klog(n)</code>
</p>

<p>Adjusted BIC (Dziak et al., 2020) as
</p>
<p style="text-align: center;"><code class="reqn">-2LL(theta) + klog(n/2pi)</code>
</p>

<p>and BICQ (Xu, 2010) as
</p>
<p style="text-align: center;"><code class="reqn">-2LL(theta) + klog(n) - 2klog(q/(1-q))</code>
</p>
<p>.
</p>


<h3>Value</h3>

<p>BIC, BICadj or BICQ measurement of the model
</p>


<h3>References</h3>

<p>Dziak, J. J., Coffman, D. L., Lanza, S. T., Li, R., &amp; Jermiin, L. S. (2020). Sensitivity and specificity of information criteria. Briefings in bioinformatics, 21(2), 553-565.
</p>
<p>Xu, C. (2010). Model Selection with Information Criteria.
</p>
<p>Schwarz, G. 1978. Estimating the dimension of a model The Annals of Statistics 6 (2), 461–464. &lt;doi:10.1214/aos/1176344136&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x1 &lt;- rnorm(100, 3, 2)
x2 &lt;- rnorm(100, 5, 3)
x3 &lt;- rnorm(100, 67, 5)
err &lt;- rnorm(100, 0, 4)

## round so we can use it for Poisson regression
y &lt;- round(3 + 2*x1 - 5*x2 + 8*x3 + err)

m1 &lt;- lm(y~x1 + x2 + x3)
m2 &lt;- glm(y~x1 + x2 + x3, family = "gaussian")
m3 &lt;- glm(y~x1 + x2 + x3, family = "poisson")

BIC(m1)
BIC(m2)
BIC(m3)
BICadj(m1)
BICadj(m2)
BICadj(m3)

</code></pre>

<hr>
<h2 id='CAIC'>Consistent Akaike's Information Criterion and Consistent Akaike's Information Criterion with Fisher Information</h2><span id='topic+CAIC'></span><span id='topic+CAICF'></span>

<h3>Description</h3>

<p>Consistent Akaike's Information Criterion (CAIC) and Consistent Akaike's Information Criterion with Fisher Information (CAICF) for &quot;lm&quot; and &quot;glm&quot; objects.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CAIC(model)

CAICF(model)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="CAIC_+3A_model">model</code></td>
<td>
<p>a &quot;lm&quot; or &quot;glm&quot; object.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>CAIC (Bozdogan, 1987) is calculated as
</p>
<p style="text-align: center;"><code class="reqn">-2LL(theta) + k(log(n) + 1)</code>
</p>

<p>CAICF (Bozdogan, 1987) as
</p>
<p style="text-align: center;"><code class="reqn">-2LL(theta) + 2k + k(log(n)) + log(|F|)</code>
</p>

<p>F is the Fisher information matrix.
</p>


<h3>Value</h3>

<p>CAIC or CAICF measurement of the model.
</p>


<h3>References</h3>

<p>Bozdogan, H. (1987). Model selection and Akaike's information criterion (AIC): The general theory and its analytical extensions. Psychometrika, 52(3), 345-370.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x1 &lt;- rnorm(100, 3, 2)
x2 &lt;- rnorm(100, 5, 3)
x3 &lt;- rnorm(100, 67, 5)
err &lt;- rnorm(100, 0, 4)

## round so we can use it for Poisson regression
y &lt;- round(3 + 2*x1 - 5*x2 + 8*x3 + err)

m1 &lt;- lm(y~x1 + x2 + x3)
m2 &lt;- glm(y~x1 + x2 + x3, family = "gaussian")
m3 &lt;- glm(y~x1 + x2 + x3, family = "poisson")

CAIC(m1)
CAIC(m2)
CAIC(m3)
CAICF(m1)
CAICF(m2)
CAICF(m3)

</code></pre>

<hr>
<h2 id='FIC'>Fisher Information Criterion</h2><span id='topic+FIC'></span>

<h3>Description</h3>

<p>Calculates Fisher Information Criterion (FIC) for &quot;lm&quot; and &quot;glm&quot; objects.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>FIC(model)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="FIC_+3A_model">model</code></td>
<td>
<p>a &quot;lm&quot; or &quot;glm&quot; object</p>
</td></tr>
</table>


<h3>Details</h3>

<p>FIC (Wei, 1992) is calculated as
</p>
<p style="text-align: center;"><code class="reqn">-2LL(theta) + log(|X^T X|)</code>
</p>



<h3>Value</h3>

<p>FIC measurement of the model
</p>


<h3>References</h3>

<p>Wei, C. Z. (1992). On predictive least squares principles. The Annals of Statistics, 20(1), 1-42.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x1 &lt;- rnorm(100, 3, 2)
x2 &lt;- rnorm(100, 5, 3)
x3 &lt;- rnorm(100, 67, 5)
err &lt;- rnorm(100, 0, 4)

## round so we can use it for Poisson regression
y &lt;- round(3 + 2*x1 - 5*x2 + 8*x3 + err)

m1 &lt;- lm(y~x1 + x2 + x3)
m2 &lt;- glm(y~x1 + x2 + x3, family = "gaussian")
m3 &lt;- glm(y~x1 + x2 + x3, family = "poisson")

FIC(m1)
FIC(m2)
FIC(m3)

</code></pre>

<hr>
<h2 id='GCV'>Generalized Cross-Validation</h2><span id='topic+GCV'></span>

<h3>Description</h3>

<p>Calculates Generalized Cross-Validation (GCV) for &quot;lm&quot; and &quot;glm&quot; objects.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>GCV(model)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="GCV_+3A_model">model</code></td>
<td>
<p>a &quot;lm&quot; or &quot;glm&quot; object</p>
</td></tr>
</table>


<h3>Details</h3>

<p>GCV (Koc and Bozdogan, 2015) is calculated as
</p>
<p style="text-align: center;"><code class="reqn">RSS/(n(1 - k/n))</code>
</p>

<p>RSS is the residual sum of squares.
</p>


<h3>Value</h3>

<p>GCV measurement of the model
</p>


<h3>References</h3>

<p>Koc, E. K., &amp; Bozdogan, H. (2015). Model selection in multivariate adaptive regression splines (MARS) using information complexity as the fitness function. Machine Learning, 101(1), 35-58.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x1 &lt;- rnorm(100, 3, 2)
x2 &lt;- rnorm(100, 5, 3)
x3 &lt;- rnorm(100, 67, 5)
err &lt;- rnorm(100, 0, 4)

## round so we can use it for Poisson regression
y &lt;- round(3 + 2*x1 - 5*x2 + 8*x3 + err)

m1 &lt;- lm(y~x1 + x2 + x3)
m2 &lt;- glm(y~x1 + x2 + x3, family = "gaussian")
m3 &lt;- glm(y~x1 + x2 + x3, family = "poisson")

GCV(m1)
GCV(m2)
GCV(m3)

</code></pre>

<hr>
<h2 id='HBIC'>Haughton Bayesian information criterion</h2><span id='topic+HBIC'></span>

<h3>Description</h3>

<p>Calculates Haughton Bayesian information criterion (HBIC) for &quot;lm&quot; and &quot;glm&quot; objects.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>HBIC(model)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="HBIC_+3A_model">model</code></td>
<td>
<p>a &quot;lm&quot; or &quot;glm&quot; object</p>
</td></tr>
</table>


<h3>Details</h3>

<p>HBIC (Bollen et al., 2014) is calculated as
</p>
<p style="text-align: center;"><code class="reqn">-2LL(theta) + klog(n/(2pi))</code>
</p>



<h3>Value</h3>

<p>HBIC measurement of the model
</p>


<h3>References</h3>

<p>Bollen, K. A., Harden, J. J., Ray, S., &amp; Zavisca, J. (2014). BIC and alternative Bayesian information criteria in the selection of structural equation models. Structural equation modeling: a multidisciplinary journal, 21(1), 1-19.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x1 &lt;- rnorm(100, 3, 2)
x2 &lt;- rnorm(100, 5, 3)
x3 &lt;- rnorm(100, 67, 5)
err &lt;- rnorm(100, 0, 4)

## round so we can use it for Poisson regression
y &lt;- round(3 + 2*x1 - 5*x2 + 8*x3 + err)

m1 &lt;- lm(y~x1 + x2 + x3)
m2 &lt;- glm(y~x1 + x2 + x3, family = "gaussian")
m3 &lt;- glm(y~x1 + x2 + x3, family = "poisson")

HBIC(m1)
HBIC(m2)
HBIC(m3)

</code></pre>

<hr>
<h2 id='HQIC'>Hannan-Quinn Information Criterion</h2><span id='topic+HQIC'></span>

<h3>Description</h3>

<p>Calculates Hannan-Quinn Information Criterion (HQIC) for &quot;lm&quot; and &quot;glm&quot; objects.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>HQIC(model)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="HQIC_+3A_model">model</code></td>
<td>
<p>a &quot;lm&quot; or &quot;glm&quot; object</p>
</td></tr>
</table>


<h3>Details</h3>

<p>HQIC (Hannan and Quinn, 1979) is calculated as
</p>
<p style="text-align: center;"><code class="reqn">-2LL(theta) + 2klog(log(n))</code>
</p>



<h3>Value</h3>

<p>HQIC measurement of the model
</p>


<h3>References</h3>

<p>Hannan, E. J., &amp; Quinn, B. G. (1979). The determination of the order of an autoregression. Journal of the Royal Statistical Society: Series B (Methodological), 41(2), 190-195.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x1 &lt;- rnorm(100, 3, 2)
x2 &lt;- rnorm(100, 5, 3)
x3 &lt;- rnorm(100, 67, 5)
err &lt;- rnorm(100, 0, 4)

## round so we can use it for Poisson regression
y &lt;- round(3 + 2*x1 - 5*x2 + 8*x3 + err)

m1 &lt;- lm(y~x1 + x2 + x3)
m2 &lt;- glm(y~x1 + x2 + x3, family = "gaussian")
m3 &lt;- glm(y~x1 + x2 + x3, family = "poisson")

HQIC(m1)
HQIC(m2)
HQIC(m3)

</code></pre>

<hr>
<h2 id='IBIC'>Information Matrix-Based Information Criterion</h2><span id='topic+IBIC'></span>

<h3>Description</h3>

<p>Calculates Information Matrix-Based Information Criterion (IBIC) for &quot;lm&quot; and &quot;glm&quot; objects.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>IBIC(model)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="IBIC_+3A_model">model</code></td>
<td>
<p>a &quot;lm&quot; or &quot;glm&quot; object</p>
</td></tr>
</table>


<h3>Details</h3>

<p>IBIC (Bollen et al., 2012) is calculated as
</p>
<p style="text-align: center;"><code class="reqn">-2LL(theta) + klog(n/(2pi)) + log(|F|)</code>
</p>

<p><code class="reqn">F</code> is the fisher information matrix.
</p>
<p>While calculating the Fisher information matrix (<code class="reqn">F</code>), we used
the joint parameters (<code class="reqn">beta,sigma^2</code>) of the models.
</p>


<h3>Value</h3>

<p>IBIC measurement of the model
</p>


<h3>References</h3>

<p>Bollen, K. A., Ray, S., Zavisca, J., &amp; Harden, J. J. (2012). A comparison of Bayes factor approximation methods including two new methods. Sociological Methods &amp; Research, 41(2), 294-324.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x1 &lt;- rnorm(100, 3, 2)
x2 &lt;- rnorm(100, 5, 3)
x3 &lt;- rnorm(100, 67, 5)
err &lt;- rnorm(100, 0, 4)

## round so we can use it for Poisson regression
y &lt;- round(3 + 2*x1 - 5*x2 + 8*x3 + err)

m1 &lt;- lm(y~x1 + x2 + x3)
m2 &lt;- glm(y~x1 + x2 + x3, family = "gaussian")
m3 &lt;- glm(y~x1 + x2 + x3, family = "poisson")

IBIC(m1)
IBIC(m2)
IBIC(m3)

</code></pre>

<hr>
<h2 id='IC'>Information Criteria</h2><span id='topic+IC'></span>

<h3>Description</h3>

<p>Calculates Various Information Criteria for &quot;lm&quot; and &quot;glm&quot; objects.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>IC(
  model,
  criteria = c("AIC", "BIC", "CAIC", "KIC", "HQIC", "FIC", "ICOMP_IFIM_C1",
    "ICOMP_PEU_C1", "ICOMP_PEU_LN_C1", "CICOMP_C1"),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="IC_+3A_model">model</code></td>
<td>
<p>a &quot;lm&quot; or &quot;glm&quot; object or object list</p>
</td></tr>
<tr><td><code id="IC_+3A_criteria">criteria</code></td>
<td>
<p>a vector of criteria names. Can be set to respective numbers. Possible criteria names at the moment are: <br />
1 = &quot;AIC&quot; <br />
2 = &quot;AIC4&quot; <br />
3 = &quot;BIC&quot; <br />
4 = &quot;BICadj&quot; <br />
5 = &quot;BICQ&quot; <br />
6 = &quot;CAIC&quot; <br />
7 = &quot;CAICF&quot; <br />
8 = &quot;FIC&quot; <br />
9 = &quot;GCV&quot; <br />
10 = &quot;HBIV&quot; <br />
11 = &quot;GQIC&quot; <br />
12 = &quot;IBIC&quot; <br />
13 = &quot;ICOMP_IFIM_CF&quot; <br />
14 = &quot;ICOMP_IFIM_C1&quot; <br />
15 = &quot;ICOMP_IFIM_C1F&quot; <br />
16 = &quot;ICOMP_IFIM_C1R&quot; <br />
17 = &quot;ICOMP_PEU_CF&quot; <br />
18 = &quot;ICOMP_PEU_C1&quot; <br />
19 = &quot;ICOMP_PEU_C1F&quot; <br />
20 = &quot;ICOMP_PEU_C1R&quot; <br />
21 = &quot;ICOMP_PEU_LN_CF&quot; <br />
22 = &quot;ICOMP_PEU_LN_C1&quot; <br />
23 = &quot;ICOMP_PEU_LN_C1F&quot; <br />
24 = &quot;ICOMP_PEU_LN_C1R&quot; <br />
25 = &quot;CICOMP_CF&quot; <br />
26 = &quot;CICOMP_C1&quot; <br />
27 = &quot;CICOMP_C1F&quot; <br />
28 = &quot;CICOMP_C1R&quot; <br />
29 = &quot;JIC&quot; <br />
30 = &quot;KIC&quot; <br />
31 = &quot;KICC&quot; <br />
32 = &quot;SPBIC&quot;</p>
</td></tr>
<tr><td><code id="IC_+3A_...">...</code></td>
<td>
<p>additional parameters. Currently none.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Calculates Various Information Criteria for &quot;lm&quot; and &quot;glm&quot; objects.
<code>model</code> can be a list. If it is a list, function returns a
matrix of selected information criteria for all models.
</p>


<h3>Value</h3>

<p>Information criteria of the model(s) for selected criteria
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x1 &lt;- rnorm(100, 3, 2)
x2 &lt;- rnorm(100, 5, 3)
x3 &lt;- rnorm(100, 67, 5)
err &lt;- rnorm(100, 0, 4)

## round so we can use it for Poisson regression
y &lt;- round(3 + 2*x1 - 5*x2 + 8*x3 + err)

m1 &lt;- lm(y~x1 + x2 + x3)
m2 &lt;- glm(y~x1 + x2 + x3, family = "gaussian")
m3 &lt;- glm(y~x1 + x2 + x3, family = "poisson")

IC(model = m1, criteria = 1:32)
IC(model = list(lm = m1,
               glm = m2,
               glm_pois = m3), criteria = 1:32)

</code></pre>

<hr>
<h2 id='ICOMP'>Informational Complexity</h2><span id='topic+ICOMP'></span><span id='topic+ICOMP_IFIM_CF'></span><span id='topic+ICOMP_IFIM_C1'></span><span id='topic+ICOMP_IFIM_C1F'></span><span id='topic+ICOMP_IFIM_C1R'></span><span id='topic+ICOMP_PEU_CF'></span><span id='topic+ICOMP_PEU_C1'></span><span id='topic+ICOMP_PEU_C1F'></span><span id='topic+ICOMP_PEU_C1R'></span><span id='topic+ICOMP_PEU_LN_CF'></span><span id='topic+ICOMP_PEU_LN_C1'></span><span id='topic+ICOMP_PEU_LN_C1F'></span><span id='topic+ICOMP_PEU_LN_C1R'></span><span id='topic+CICOMP_CF'></span><span id='topic+CICOMP_C1'></span><span id='topic+CICOMP_C1F'></span><span id='topic+CICOMP_C1R'></span>

<h3>Description</h3>

<p>These functions calculates Informational Complexity
(ICOMP) variants for &quot;lm&quot; and &quot;glm&quot; objects.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ICOMP(model, type = "IFIM", C = "C1")

ICOMP_IFIM_CF(model)

ICOMP_IFIM_C1(model)

ICOMP_IFIM_C1F(model)

ICOMP_IFIM_C1R(model)

ICOMP_PEU_CF(model)

ICOMP_PEU_C1(model)

ICOMP_PEU_C1F(model)

ICOMP_PEU_C1R(model)

ICOMP_PEU_LN_CF(model)

ICOMP_PEU_LN_C1(model)

ICOMP_PEU_LN_C1F(model)

ICOMP_PEU_LN_C1R(model)

CICOMP_CF(model)

CICOMP_C1(model)

CICOMP_C1F(model)

CICOMP_C1R(model)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ICOMP_+3A_model">model</code></td>
<td>
<p>a &quot;lm&quot; or &quot;glm&quot; object</p>
</td></tr>
<tr><td><code id="ICOMP_+3A_type">type</code></td>
<td>
<p>type of ICOMP. Available types are &quot;IFIM&quot;, &quot;PEU&quot;, &quot;PEU_LN&quot; and &quot;CICOMP&quot;. Default is &quot;IFIM&quot;.</p>
</td></tr>
<tr><td><code id="ICOMP_+3A_c">C</code></td>
<td>
<p>type of complexity. Available types are &quot;CF&quot;, &quot;C1&quot;, &quot;C1F&quot; and &quot;C1R&quot;. Default is &quot;C1&quot;.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>ICOMP(IFIM) (Bozdogan, 2003) is calculated as
</p>
<p style="text-align: center;"><code class="reqn">-2LL(theta) + 2C(F^{-1})</code>
</p>

<p>ICOMP(IFIM-peu) (Koc and Bozdogan, 2015) as
</p>
<p style="text-align: center;"><code class="reqn">-2LL(theta) + k + 2C(F^{-1})</code>
</p>

<p>ICOMP(IFIM-peuln) (Bozdogan, 2010) as
</p>
<p style="text-align: center;"><code class="reqn">-2LL(theta) + k + 2log(n)C(F^{-1})</code>
</p>

<p>and CICOMP (Pamukcu et al., 2015) as
</p>
<p style="text-align: center;"><code class="reqn">-2LL(theta) + k(log(n) + 1) + 2C(F^{-1})</code>
</p>

<p><code class="reqn">F</code> is the fisher information matrix. <code class="reqn">F^{-1}</code> is the
reverse Fisher information matrix.
<code class="reqn">C</code> is the complexity measure. Four variants are available:
</p>
<p><code class="reqn">C_1</code> (Bozdogan, 2010) is
</p>
<p style="text-align: center;"><code class="reqn">C_1(F^{-1}) = s/2*log(lambda_a / lambda_g)</code>
</p>

<p><code class="reqn">C_F</code> (Bozdogan, 2010) is
</p>
<p style="text-align: center;"><code class="reqn">C_F(F^{-1}) = 1/s*sum_i^s(lambda_i - lambda_a)</code>
</p>

<p><code class="reqn">C_1F</code> (Bozdogan, 2010) is
</p>
<p style="text-align: center;"><code class="reqn">C_1F(F^{-1}) = 1/(4lambda_a^2)*sum_i^s(lambda_i - lambda_a)</code>
</p>

<p><code class="reqn">C_1R</code> (Bozdogan, 2000) is
</p>
<p style="text-align: center;"><code class="reqn">C_1R(F^{-1}) = 1/2*log(|R|)</code>
</p>

<p>Here, <code class="reqn">R</code> is the correlation matrix of the model, <code class="reqn">lambda_1, ..., lambda_s</code>
are eigenvalues of <code class="reqn">F</code>, <code class="reqn">lambda_a</code> and <code class="reqn">lambda_g</code> are arithmetic and
geometric mean of eigenvalues of <code class="reqn">F</code>, respectively. <code class="reqn">s</code> is the dimension
of <code class="reqn">F</code>.
While calculating the Fisher information matrix (<code class="reqn">F</code>), we used
the joint parameters (<code class="reqn">beta,sigma^2</code>) of the models. In <code class="reqn">C1R(.)</code> function,
we utilized the usual variance-covariance matrix <code class="reqn">Cov(beta)</code> of the
models. beta is the vector of regression coefficients.
</p>


<h3>Value</h3>

<p>Informational Complexity measurement of the model
</p>


<h3>References</h3>

<p>Bozdogan, H. (2003). Intelligent Statistical Data Mining with Information Complexity and Genetic Algorithms Hamparsum Bozdogan University of Tennessee, Knoxville, USA. In Statistical data mining and knowledge discovery (pp. 47-88). Chapman and Hall/CRC.
</p>
<p>Koc, E. K., &amp; Bozdogan, H. (2015). Model selection in multivariate adaptive regression splines (MARS) using information complexity as the fitness function. Machine Learning, 101(1), 35-58.
</p>
<p>Bozdogan, H. (2010). A new class of information complexity (ICOMP) criteria with an application to customer profiling and segmentation. İstanbul Üniversitesi İşletme Fakültesi Dergisi, 39(2), 370-398.
</p>
<p>Pamukçu, E., Bozdogan, H., &amp; Çalık, S. (2015). A novel hybrid dimension reduction technique for undersized high dimensional gene expression data sets using information complexity criterion for cancer classification. Computational and mathematical methods in medicine, 2015.
</p>
<p>Bozdogan, H. (2000). Akaike's information criterion and recent developments in information complexity. Journal of mathematical psychology, 44(1), 62-91.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x1 &lt;- rnorm(100, 3, 2)
x2 &lt;- rnorm(100, 5, 3)
x3 &lt;- rnorm(100, 67, 5)
err &lt;- rnorm(100, 0, 4)

## round so we can use it for Poisson regression
y &lt;- round(3 + 2*x1 - 5*x2 + 8*x3 + err)

m1 &lt;- lm(y~x1 + x2 + x3)
m2 &lt;- glm(y~x1 + x2 + x3, family = "gaussian")
m3 &lt;- glm(y~x1 + x2 + x3, family = "poisson")

ICOMP_IFIM_CF(m1)
ICOMP_IFIM_CF(m2)
ICOMP_IFIM_CF(m3)
CICOMP_C1(m1)
CICOMP_C1(m2)
CICOMP_C1(m3)
ICOMP(m1, type = "PEU", C = "C1R")


</code></pre>

<hr>
<h2 id='JIC'>Joint Information Criterion</h2><span id='topic+JIC'></span>

<h3>Description</h3>

<p>Joint Information Criterion (JIC) for &quot;lm&quot; and &quot;glm&quot; objects.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>JIC(model)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="JIC_+3A_model">model</code></td>
<td>
<p>a &quot;lm&quot; or &quot;glm&quot; object</p>
</td></tr>
</table>


<h3>Details</h3>

<p>JIC (Rahman and King, 1999) is calculated as
</p>
<p style="text-align: center;"><code class="reqn">-2LL(theta) + 1/2*(klog(n) - nlog(1-k/n))</code>
</p>



<h3>Value</h3>

<p>JIC measurement of the model
</p>


<h3>References</h3>

<p>Rahman, M. S., &amp; King, M. L. (1999). Improved model selection criterion. Communications in Statistics-Simulation and Computation, 28(1), 51-71.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x1 &lt;- rnorm(100, 3, 2)
x2 &lt;- rnorm(100, 5, 3)
x3 &lt;- rnorm(100, 67, 5)
err &lt;- rnorm(100, 0, 4)

## round so we can use it for Poisson regression
y &lt;- round(3 + 2*x1 - 5*x2 + 8*x3 + err)

m1 &lt;- lm(y~x1 + x2 + x3)
m2 &lt;- glm(y~x1 + x2 + x3, family = "gaussian")
m3 &lt;- glm(y~x1 + x2 + x3, family = "poisson")

JIC(m1)
JIC(m2)
JIC(m3)

</code></pre>

<hr>
<h2 id='KIC'>Kullback–Leibler Information Criterion</h2><span id='topic+KIC'></span><span id='topic+KICC'></span>

<h3>Description</h3>

<p>Calculates Kullback–Leibler Information Criterion (KIC) and its corrected form (KICC) for &quot;lm&quot; and &quot;glm&quot; objects.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>KIC(model)

KICC(model)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="KIC_+3A_model">model</code></td>
<td>
<p>a &quot;lm&quot; or &quot;glm&quot; object</p>
</td></tr>
</table>


<h3>Details</h3>

<p>KIC (Seghouane, 2006) is calculated as
</p>
<p style="text-align: center;"><code class="reqn">-2LL(theta) + 3k</code>
</p>

<p>and KICC (Seghouane, 2006) is calculated as
</p>
<p style="text-align: center;"><code class="reqn">-2LL(theta) + ((k + 1)(3n - k - 2)) + (k/(n-k))</code>
</p>



<h3>Value</h3>

<p>KIC measurement of the model
</p>


<h3>References</h3>

<p>Seghouane, A. K. (2006). A note on overfitting properties of KIC and KICC. Signal Processing, 86(10), 3055-3060.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x1 &lt;- rnorm(100, 3, 2)
x2 &lt;- rnorm(100, 5, 3)
x3 &lt;- rnorm(100, 67, 5)
err &lt;- rnorm(100, 0, 4)

## round so we can use it for Poisson regression
y &lt;- round(3 + 2*x1 - 5*x2 + 8*x3 + err)

m1 &lt;- lm(y~x1 + x2 + x3)
m2 &lt;- glm(y~x1 + x2 + x3, family = "gaussian")
m3 &lt;- glm(y~x1 + x2 + x3, family = "poisson")

KIC(m1)
KIC(m2)
KIC(m3)
KICC(m1)
KICC(m2)
KICC(m3)

</code></pre>

<hr>
<h2 id='reverse_fisher'>Reverse Fisher Matrix</h2><span id='topic+reverse_fisher'></span>

<h3>Description</h3>

<p>This function allows you to calculate Fisher Information Matrix using &quot;lm&quot; and &quot;glm&quot; objects.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>reverse_fisher(model)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="reverse_fisher_+3A_model">model</code></td>
<td>
<p>a &quot;lm&quot; or &quot;glm&quot; object</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Calculates Fisher Information Matrix using &quot;lm&quot; and &quot;glm&quot; objects. It uses
</p>


<h3>Value</h3>

<p>a booster object with below components.
</p>
<table role = "presentation">
<tr><td><code>n_train</code></td>
<td>
<p>Number of cases in the input dataset.</p>
</td></tr>
</table>

<hr>
<h2 id='SPBIC'>Scaled Unit Information Prior Bayesian Information Criterion</h2><span id='topic+SPBIC'></span>

<h3>Description</h3>

<p>Calculates Scaled Unit Information Prior Bayesian Information Criterion (SPBIC) for &quot;lm&quot; and &quot;glm&quot; objects.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SPBIC(model)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="SPBIC_+3A_model">model</code></td>
<td>
<p>a &quot;lm&quot; or &quot;glm&quot; object</p>
</td></tr>
</table>


<h3>Details</h3>

<p>SPBIC (Bollen et al., 2012) is calculated as
</p>
<p style="text-align: center;"><code class="reqn">-2LL(theta) + k(1 - log(k/(beta^T(Sigma)^{-1}beta)))</code>
</p>

<p>beta and Sigma are vector and covariance matrix of regression coefficients.
</p>


<h3>Value</h3>

<p>SPBIC measurement of the model
</p>


<h3>References</h3>

<p>Bollen, K. A., Ray, S., Zavisca, J., &amp; Harden, J. J. (2012). A comparison of Bayes factor approximation methods including two new methods. Sociological Methods &amp; Research, 41(2), 294-324.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x1 &lt;- rnorm(100, 3, 2)
x2 &lt;- rnorm(100, 5, 3)
x3 &lt;- rnorm(100, 67, 5)
err &lt;- rnorm(100, 0, 4)

## round so we can use it for Poisson regression
y &lt;- round(3 + 2*x1 - 5*x2 + 8*x3 + err)

m1 &lt;- lm(y~x1 + x2 + x3)
m2 &lt;- glm(y~x1 + x2 + x3, family = "gaussian")
m3 &lt;- glm(y~x1 + x2 + x3, family = "poisson")

SPBIC(m1)
SPBIC(m2)
SPBIC(m3)

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
