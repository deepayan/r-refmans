<!DOCTYPE html><html><head><title>Help for package pcv</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {pcv}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#corn'>
<p>Corn data</p></a></li>
<li><a href='#getCrossvalParams'><p>Returns parameters for cross-validation based on 'cv' value</p></a></li>
<li><a href='#getR'><p>Creates rotation matrix to map a set vectors <code>base1</code> to a set of vectors <code>base2</code>.</p></a></li>
<li><a href='#getxpvorth'><p>Generates the orthogonal part for Xpv</p></a></li>
<li><a href='#normalize'><p>Normalization rows or columns of a matrix</p></a></li>
<li><a href='#pcv'><p>Compute matrix with pseudo-validation set</p></a></li>
<li><a href='#pcvcrossval'><p>Generate sequence of indices for cross-validation</p></a></li>
<li><a href='#pcvpca'><p>Procrustes cross-validation for PCA models</p></a></li>
<li><a href='#pcvpcr'><p>Procrustes cross-validation for PCR models</p></a></li>
<li><a href='#pcvpls'><p>Procrustes cross-validation for PLS models</p></a></li>
<li><a href='#pcvreg'><p>Procrustes cross-validation for multivariate regression models</p></a></li>
<li><a href='#plotD'><p>Plots heatmap for scaling coefficients obtained when generating PV-set for PCR or PLS</p></a></li>
<li><a href='#rotationMatrixToX1'><p>Creates a rotation matrix to map a vector x to [1 0 0 ... 0]</p></a></li>
<li><a href='#simpls'><p>SIMPLS algorithm</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Version:</td>
<td>1.1.0</td>
</tr>
<tr>
<td>Date:</td>
<td>2023-08-12</td>
</tr>
<tr>
<td>Title:</td>
<td>Procrustes Cross-Validation</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Sergey Kucheryavskiy &lt;svkucheryavski@gmail.com&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Implements Procrustes cross-validation method for Principal Component Analysis, Principal Component Regression and Partial Least Squares regression models. S. Kucheryavskiy (2023) &lt;<a href="https://doi.org/10.1016%2Fj.aca.2023.341096">doi:10.1016/j.aca.2023.341096</a>&gt;.</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>Imports:</td>
<td>graphics, grDevices, stats</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>Suggests:</td>
<td>testthat</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0)</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/svkucheryavski/pcv">https://github.com/svkucheryavski/pcv</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/svkucheryavski/pcv/issues">https://github.com/svkucheryavski/pcv/issues</a></td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-08-12 18:52:49 UTC; svkucheryavski</td>
</tr>
<tr>
<td>Author:</td>
<td>Sergey Kucheryavskiy
    <a href="https://orcid.org/0000-0002-3145-7244"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut, cre]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-08-12 19:20:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='corn'>
Corn data
</h2><span id='topic+corn'></span>

<h3>Description</h3>

<p>NIR spectra and moisture of 80 Corn samples.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(corn)</code></pre>


<h3>Format</h3>

<p>A list with two matrices, <code>spectra</code> and <code>moisture</code>.
</p>


<h3>Details</h3>

<p>This is a part of Corn dataset, which was downloaded from Eigenvector Research, Inc. website (https://eigenvector.com/resources/data-sets/), where it is availble publicly. This dataset contains several NIR spectra of corn samples recorded using different instruments. For our examples we took &quot;mp5&quot; spectra and corrected them using Standard Normal Variate transformation.
</p>


<h3>Source</h3>

<p>1. Eigenvector Research, Inc. (https://eigenvector.com/resources/data-sets/)
</p>

<hr>
<h2 id='getCrossvalParams'>Returns parameters for cross-validation based on 'cv' value</h2><span id='topic+getCrossvalParams'></span>

<h3>Description</h3>

<p>Returns parameters for cross-validation based on 'cv' value
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getCrossvalParams(cv, nobj)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getCrossvalParams_+3A_cv">cv</code></td>
<td>
<p>settings for cross-validation provided by user</p>
</td></tr>
<tr><td><code id="getCrossvalParams_+3A_nobj">nobj</code></td>
<td>
<p>number of objects in calibration set</p>
</td></tr>
</table>

<hr>
<h2 id='getR'>Creates rotation matrix to map a set vectors <code>base1</code> to a set of vectors <code>base2</code>.</h2><span id='topic+getR'></span>

<h3>Description</h3>

<p>In both sets vectors should be orthonormal.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getR(base1, base2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getR_+3A_base1">base1</code></td>
<td>
<p>Matrix (JxA) with A orthonormal vectors as columns to be rotated (A &lt;= J)</p>
</td></tr>
<tr><td><code id="getR_+3A_base2">base2</code></td>
<td>
<p>Matrix (JxA) with A orthonormal vectors as columns, <code>base1</code> should be aligned with</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Rotation matrix (JxJ)
</p>

<hr>
<h2 id='getxpvorth'>Generates the orthogonal part for Xpv</h2><span id='topic+getxpvorth'></span>

<h3>Description</h3>

<p>Generates the orthogonal part for Xpv
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getxpvorth(q.k, X.k, PRM)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getxpvorth_+3A_q.k">q.k</code></td>
<td>
<p>vector with orthogonal distances for cross-validation set for segment k</p>
</td></tr>
<tr><td><code id="getxpvorth_+3A_x.k">X.k</code></td>
<td>
<p>matrix with local validation set for segment k</p>
</td></tr>
<tr><td><code id="getxpvorth_+3A_prm">PRM</code></td>
<td>
<p>projecton matrix for orthogonalization of residuals</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix with orthogonal part for Xpv
</p>

<hr>
<h2 id='normalize'>Normalization rows or columns of a matrix</h2><span id='topic+normalize'></span>

<h3>Description</h3>

<p>Normalization rows or columns of a matrix
</p>


<h3>Usage</h3>

<pre><code class='language-R'>normalize(
  X,
  dim = 1,
  weights = if (dim == 1) 1/sqrt(rowSums(X^2)) else 1/sqrt(colSums(X^2))
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="normalize_+3A_x">X</code></td>
<td>
<p>matrix with numeric values</p>
</td></tr>
<tr><td><code id="normalize_+3A_dim">dim</code></td>
<td>
<p>which dimension to normalize (1 for rows, 2 for columns)</p>
</td></tr>
<tr><td><code id="normalize_+3A_weights">weights</code></td>
<td>
<p>vector with normalization weights, by default 2-norm is used</p>
</td></tr>
</table>

<hr>
<h2 id='pcv'>Compute matrix with pseudo-validation set</h2><span id='topic+pcv'></span>

<h3>Description</h3>

<p>Compute matrix with pseudo-validation set
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pcv(
  X,
  ncomp = min(round(nrow(X)/nseg) - 1, col(X), 20),
  nseg = 4,
  scale = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pcv_+3A_x">X</code></td>
<td>
<p>matrix with calibration set (IxJ)</p>
</td></tr>
<tr><td><code id="pcv_+3A_ncomp">ncomp</code></td>
<td>
<p>number of components for PCA decomposition</p>
</td></tr>
<tr><td><code id="pcv_+3A_nseg">nseg</code></td>
<td>
<p>number of segments in cross-validation</p>
</td></tr>
<tr><td><code id="pcv_+3A_scale">scale</code></td>
<td>
<p>logical, standardize columns of X prior to decompositon or not</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is the old (original) version of PCV algorithm for PCA models. Use <code><a href="#topic+pcvpca">pcvpca</a></code>
instead. Ane check project web-site for details: https://github.com/svkucheryavski/pcv
</p>
<p>The method computes pseudo-validation matrix Xpv, based on PCA decomposition of calibration set X
and systematic (venetian blinds) cross-validation. It is assumed that data rows are ordered
correctly, so systematic cross-validation can be applied
</p>


<h3>Value</h3>

<p>Pseudo-validation matrix (IxJ)
</p>

<hr>
<h2 id='pcvcrossval'>Generate sequence of indices for cross-validation</h2><span id='topic+pcvcrossval'></span>

<h3>Description</h3>

<p>Generates and returns sequence of object indices for each segment in random segmented
cross-validation
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pcvcrossval(cv = 1, nobj = NULL, resp = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pcvcrossval_+3A_cv">cv</code></td>
<td>
<p>cross-validation settings, can be a number, a list or a vector with integers.</p>
</td></tr>
<tr><td><code id="pcvcrossval_+3A_nobj">nobj</code></td>
<td>
<p>number of objects in a dataset</p>
</td></tr>
<tr><td><code id="pcvcrossval_+3A_resp">resp</code></td>
<td>
<p>vector or matrix with response values to use in case of venetian blinds</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Parameter 'cv' defines how to split the rows of the training set. The split is similar
to cross-validation splits, as PCV is based on cross-validation. This parameter can have
the following values:
</p>
<p>1. A number (e.g. 'cv = 4'). In this case this number specifies number of segments for random
splits, except 'cv = 1' which is a special case for leave-one-out (full cross-validation).
</p>
<p>2. A list with 2 values: 'list(&quot;name&quot;, nseg)'. In this case '&quot;name&quot;' defines the way to make
the split, you can select one of the following: '&quot;loo&quot;' for leave-one-out, '&quot;rand&quot;' for random
splits or '&quot;ven&quot;' for Venetian blinds (systematic) splits. The second parameter, 'nseg', is a
number of segments for splitting the rows into. For example, 'cv = list(&quot;ven&quot;, 4)', shown in
the code examples above, tells PCV to use Venetian blinds splits with 4 segments.
</p>
<p>3. A vector with integer numbers, e.g. 'cv = c(1, 2, 3, 1, 2, 3, 1, 2, 3)'. In this case number
of values in this vector must be the same as number of rows in the training set. The values
specify which segment a particular row will belong to. In case of the example shown here, it
is assumed that you have 9 rows in the calibration set, which will be split into 3 segments.
The first segment will consist of measurements from rows 1, 4 and 7.
</p>


<h3>Value</h3>

<p>vector with object indices for each segment
</p>

<hr>
<h2 id='pcvpca'>Procrustes cross-validation for PCA models</h2><span id='topic+pcvpca'></span>

<h3>Description</h3>

<p>Procrustes cross-validation for PCA models
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pcvpca(
  X,
  ncomp = min(nrow(X) - 1, ncol(X), 30),
  cv = list("ven", 4),
  center = TRUE,
  scale = FALSE,
  cv.scope = "global"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pcvpca_+3A_x">X</code></td>
<td>
<p>matrix with predictors from the training set.</p>
</td></tr>
<tr><td><code id="pcvpca_+3A_ncomp">ncomp</code></td>
<td>
<p>number of components to use (more than the expected optimal number).</p>
</td></tr>
<tr><td><code id="pcvpca_+3A_cv">cv</code></td>
<td>
<p>which split method to use for cross-validation (see description for details).</p>
</td></tr>
<tr><td><code id="pcvpca_+3A_center">center</code></td>
<td>
<p>logical, to center or not the data sets</p>
</td></tr>
<tr><td><code id="pcvpca_+3A_scale">scale</code></td>
<td>
<p>logical, to scale or not the data sets</p>
</td></tr>
<tr><td><code id="pcvpca_+3A_cv.scope">cv.scope</code></td>
<td>
<p>scope for center/scale operations inside CV loop: 'global' — using globally computed mean and std
or 'local' — recompute new for each local calibration set.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The method computes Procrustes validation set (PV-set), matrix Xpv, based on PCA decomposition
of calibration set 'X' and cross-validation. See description of the method in [1].
</p>
<p>Parameter 'cv' defines how to split the rows of the training set. The split is similar
to cross-validation splits, as PCV is based on cross-validation. This parameter can have
the following values:
</p>
<p>1. A number (e.g. 'cv = 4'). In this case this number specifies number of segments for random
splits, except 'cv = 1' which is a special case for leave-one-out (full cross-validation).
</p>
<p>2. A list with 2 values: 'list(&quot;name&quot;, nseg)'. In this case '&quot;name&quot;' defines the way to make
the split, you can select one of the following: '&quot;loo&quot;' for leave-one-out, '&quot;rand&quot;' for random
splits or '&quot;ven&quot;' for Venetian blinds (systematic) splits. The second parameter, 'nseg', is a
number of segments for splitting the rows into. For example, 'cv = list(&quot;ven&quot;, 4)', shown in
the code examples above, tells PCV to use Venetian blinds splits with 4 segments.
</p>
<p>3. A vector with integer numbers, e.g. 'cv = c(1, 2, 3, 1, 2, 3, 1, 2, 3)'. In this case number
of values in this vector must be the same as number of rows in the training set. The values
specify which segment a particular row will belong to. In case of the example shown here, it
is assumed that you have 9 rows in the calibration set, which will be split into 3 segments.
The first segment will consist of measurements from rows 1, 4 and 7.
</p>
<p>Parameter 'cv.scope' influences how the Procrustean rule is met. In case of &quot;global&quot; scope,
the rule will be met strictly - distances for PV-set and the global model will be
identical to the distances from conventional cross-validation. In case of &quot;local&quot; scope, every
local model will have its own center and scaling factor and hence the rule will be almost
met (the distances will be close but not identical).
</p>


<h3>Value</h3>

<p>Matrix with PV-set (same size as X)
</p>


<h3>References</h3>

<p>1. S. Kucheryavskiy, O. Rodionova, A. Pomerantsev. Procrustes cross-validation of multivariate
regression models. Analytica Chimica Acta, 1255 (2022)
[https://doi.org/10.1016/j.aca.2023.341096]
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# load NIR spectra of Corn samples
data(corn)
X &lt;- corn$spectra

# generate Xpv set based on PCA decomposition with A = 20 and venetian blinds split with 4 segments
Xpv &lt;- pcvpca(X, ncomp = 20, center = TRUE, scale = FALSE, cv = list("ven", 4))

# show the original spectra and the PV-set (as is and mean centered)
oldpar &lt;- par(mfrow = c(2, 2))
matplot(t(X), type = "l", lty = 1, main = "Original data")
matplot(t(Xpv), type = "l", lty = 1, main = "PV-set")
matplot(t(scale(X, scale = FALSE)), type = "l", lty = 1, main = "Original data (mean centered)")
matplot(t(scale(Xpv, scale = FALSE)), type = "l", lty = 1, main = "PV-set (mean centered)")
par(oldpar)

</code></pre>

<hr>
<h2 id='pcvpcr'>Procrustes cross-validation for PCR models</h2><span id='topic+pcvpcr'></span>

<h3>Description</h3>

<p>Procrustes cross-validation for PCR models
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pcvpcr(
  X,
  Y,
  ncomp = min(nrow(X) - 1, ncol(X), 30),
  cv = list("ven", 4),
  center = TRUE,
  scale = FALSE,
  cv.scope = "global"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pcvpcr_+3A_x">X</code></td>
<td>
<p>matrix with predictors from the training set.</p>
</td></tr>
<tr><td><code id="pcvpcr_+3A_y">Y</code></td>
<td>
<p>vector with response values from the training set.</p>
</td></tr>
<tr><td><code id="pcvpcr_+3A_ncomp">ncomp</code></td>
<td>
<p>number of components to use (more than the expected optimal number).</p>
</td></tr>
<tr><td><code id="pcvpcr_+3A_cv">cv</code></td>
<td>
<p>which split method to use for cross-validation (see description of method 'pcvpls()' for details).</p>
</td></tr>
<tr><td><code id="pcvpcr_+3A_center">center</code></td>
<td>
<p>logical, to center or not the data sets</p>
</td></tr>
<tr><td><code id="pcvpcr_+3A_scale">scale</code></td>
<td>
<p>logical, to scale or not the data sets</p>
</td></tr>
<tr><td><code id="pcvpcr_+3A_cv.scope">cv.scope</code></td>
<td>
<p>scope for center/scale operations inside CV loop: 'global' — using globally computed mean and std
or 'local' — recompute new for each local calibration set.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The method computes pseudo-validation matrix Xpv, based on PCR decomposition of calibration
set X, y and cross-validation.
</p>
<p>Parameter 'cv' defines how to split the rows of the training set. The split is similar
to cross-validation splits, as PCV is based on cross-validation. This parameter can have
the following values:
</p>
<p>1. A number (e.g. 'cv = 4'). In this case this number specifies number of segments for random
splits, except 'cv = 1' which is a special case for leave-one-out (full cross-validation).
</p>
<p>2. A list with 2 values: 'list(&quot;name&quot;, nseg)'. In this case '&quot;name&quot;' defines the way to make
the split, you can select one of the following: '&quot;loo&quot;' for leave-one-out, '&quot;rand&quot;' for random
splits or '&quot;ven&quot;' for Venetian blinds (systematic) splits. The second parameter, 'nseg', is a
number of segments for splitting the rows into. For example, 'cv = list(&quot;ven&quot;, 4)', shown in
the code examples above, tells PCV to use Venetian blinds splits with 4 segments.
</p>
<p>3. A vector with integer numbers, e.g. 'cv = c(1, 2, 3, 1, 2, 3, 1, 2, 3)'. In this case number
of values in this vector must be the same as number of rows in the training set. The values
specify which segment a particular row will belong to. In case of the example shown here, it
is assumed that you have 9 rows in the calibration set, which will be split into 3 segments.
The first segment will consist of measurements from rows 1, 4 and 7.
</p>
<p>Parameter 'cv.scope' influences how the Procrustean rule is met. In case of &quot;global&quot; scope,
the rule will be met strictly - error of predictions for PV-set and the global model will be
identical to the error from conventional cross-validation. In case of &quot;local&quot; scope, every
local model will have its own center and hence the rule will be almost met (the errors will
be close but not identical).
</p>


<h3>Value</h3>

<p>Pseudo-validation matrix (same size as X) with an additional attribute, 'D' which contains the
scaling coefficients (ck/c)
</p>


<h3>References</h3>

<p>1. S. Kucheryavskiy, O. Rodionova, A. Pomerantsev. Procrustes cross-validation of multivariate
regression models. Analytica Chimica Acta, 1255 (2022)
[https://doi.org/10.1016/j.aca.2023.341096]
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# load NIR spectra of Corn samples
data(corn)
X &lt;- corn$spectra
Y &lt;- corn$moisture

# generate Xpv set based on PCA decomposition with A = 20 and venetian blinds split with 4 segments
Xpv &lt;- pcvpcr(X, Y, ncomp = 20, center = TRUE, scale = FALSE, cv = list("ven", 4))

# show the original spectra and the PV-set (as is and mean centered)
oldpar &lt;- par(mfrow = c(2, 2))
matplot(t(X), type = "l", lty = 1, main = "Original data")
matplot(t(Xpv), type = "l", lty = 1, main = "PV-set")
matplot(t(scale(X, scale = FALSE)), type = "l", lty = 1, main = "Original data (mean centered)")
matplot(t(scale(Xpv, scale = FALSE)), type = "l", lty = 1, main = "PV-set (mean centered)")
par(oldpar)

</code></pre>

<hr>
<h2 id='pcvpls'>Procrustes cross-validation for PLS models</h2><span id='topic+pcvpls'></span>

<h3>Description</h3>

<p>Procrustes cross-validation for PLS models
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pcvpls(
  X,
  Y,
  ncomp = min(nrow(X) - 1, ncol(X), 30),
  center = TRUE,
  scale = FALSE,
  cv = list("ven", 4),
  cv.scope = "global"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pcvpls_+3A_x">X</code></td>
<td>
<p>matrix with predictors from the training set.</p>
</td></tr>
<tr><td><code id="pcvpls_+3A_y">Y</code></td>
<td>
<p>vector or matrix with response values from the training set.</p>
</td></tr>
<tr><td><code id="pcvpls_+3A_ncomp">ncomp</code></td>
<td>
<p>number of components to use (more than the expected optimal number).</p>
</td></tr>
<tr><td><code id="pcvpls_+3A_center">center</code></td>
<td>
<p>logical, to center or not the data sets</p>
</td></tr>
<tr><td><code id="pcvpls_+3A_scale">scale</code></td>
<td>
<p>logical, to scale or not the data sets</p>
</td></tr>
<tr><td><code id="pcvpls_+3A_cv">cv</code></td>
<td>
<p>which split method to use for cross-validation (see description for details).</p>
</td></tr>
<tr><td><code id="pcvpls_+3A_cv.scope">cv.scope</code></td>
<td>
<p>scope for center/scale operations inside CV loop: 'global' — using globally computed mean and std
or 'local' — recompute new for each local calibration set.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The method computes pseudo-validation matrix Xpv, based on PLS decomposition of calibration
set X, y and cross-validation.
</p>
<p>Parameter 'cv' defines how to split the rows of the training set. The split is similar
to cross-validation splits, as PCV is based on cross-validation. This parameter can have
the following values:
</p>
<p>1. A number (e.g. 'cv = 4'). In this case this number specifies number of segments for random
splits, except 'cv = 1' which is a special case for leave-one-out (full cross-validation).
</p>
<p>2. A list with 2 values: 'list(&quot;name&quot;, nseg)'. In this case '&quot;name&quot;' defines the way to make
the split, you can select one of the following: '&quot;loo&quot;' for leave-one-out, '&quot;rand&quot;' for random
splits or '&quot;ven&quot;' for Venetian blinds (systematic) splits. The second parameter, 'nseg', is a
number of segments for splitting the rows into. For example, 'cv = list(&quot;ven&quot;, 4)', shown in
the code examples above, tells PCV to use Venetian blinds splits with 4 segments.
</p>
<p>3. A vector with integer numbers, e.g. 'cv = c(1, 2, 3, 1, 2, 3, 1, 2, 3)'. In this case number
of values in this vector must be the same as number of rows in the training set. The values
specify which segment a particular row will belong to. In case of the example shown here, it
is assumed that you have 9 rows in the calibration set, which will be split into 3 segments.
The first segment will consist of measurements from rows 1, 4 and 7.
</p>
<p>Parameter 'cv.scope' influences how the Procrustean rule is met. In case of &quot;global&quot; scope,
the rule will be met strictly - error of predictions for PV-set and the global model will be
identical to the error from conventional cross-validation. In case of &quot;local&quot; scope, every
local model will have its own center and hence the rule will be almost met (the errors will
be close but not identical).
</p>


<h3>Value</h3>

<p>Pseudo-validation matrix (same size as X) with an additional attribute, 'D' which contains the
scaling coefficients (ck/c)
</p>


<h3>References</h3>

<p>1. S. Kucheryavskiy, O. Rodionova, A. Pomerantsev. Procrustes cross-validation of multivariate
regression models. Analytica Chimica Acta, 1255 (2022)
[https://doi.org/10.1016/j.aca.2023.341096]
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# load NIR spectra of Corn samples
data(corn)
X &lt;- corn$spectra
Y &lt;- corn$moisture

# generate Xpv set based on PCA decomposition with A = 20 and venetian blinds split with 4 segments
Xpv &lt;- pcvpls(X, Y, ncomp = 20, center = TRUE, scale = FALSE, cv = list("ven", 4))

# show the original spectra and the PV-set (as is and mean centered)
oldpar &lt;- par(mfrow = c(2, 2))
matplot(t(X), type = "l", lty = 1, main = "Original data")
matplot(t(Xpv), type = "l", lty = 1, main = "PV-set")
matplot(t(scale(X, scale = FALSE)), type = "l", lty = 1, main = "Original data (mean centered)")
matplot(t(scale(Xpv, scale = FALSE)), type = "l", lty = 1, main = "PV-set (mean centered)")
par(oldpar)

# show the heatmap with the scaling coefficients
plotD(Xpv)

</code></pre>

<hr>
<h2 id='pcvreg'>Procrustes cross-validation for multivariate regression models</h2><span id='topic+pcvreg'></span>

<h3>Description</h3>

<p>This is a generic method, use 'pcvpls()' or 'pcvpcr()' instead.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pcvreg(
  X,
  Y,
  ncomp = min(nrow(X) - 1, ncol(X), 30),
  cv = list("ven", 4),
  center = TRUE,
  scale = FALSE,
  funlist = list(),
  cv.scope = "global"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pcvreg_+3A_x">X</code></td>
<td>
<p>matrix with predictors from the training set.</p>
</td></tr>
<tr><td><code id="pcvreg_+3A_y">Y</code></td>
<td>
<p>vector with response values from the training set.</p>
</td></tr>
<tr><td><code id="pcvreg_+3A_ncomp">ncomp</code></td>
<td>
<p>number of components to use (more than the expected optimal number).</p>
</td></tr>
<tr><td><code id="pcvreg_+3A_cv">cv</code></td>
<td>
<p>which split method to use for cross-validation (see description of method 'pcvpls()' for details).</p>
</td></tr>
<tr><td><code id="pcvreg_+3A_center">center</code></td>
<td>
<p>logical, to center or not the data sets</p>
</td></tr>
<tr><td><code id="pcvreg_+3A_scale">scale</code></td>
<td>
<p>logical, to scale or not the data sets</p>
</td></tr>
<tr><td><code id="pcvreg_+3A_funlist">funlist</code></td>
<td>
<p>list with functions for particular implementation</p>
</td></tr>
<tr><td><code id="pcvreg_+3A_cv.scope">cv.scope</code></td>
<td>
<p>scope for center/scale operations inside CV loop: 'global' — using globally computed mean and std
or 'local' — recompute new for each local calibration set.</p>
</td></tr>
</table>

<hr>
<h2 id='plotD'>Plots heatmap for scaling coefficients obtained when generating PV-set for PCR or PLS</h2><span id='topic+plotD'></span>

<h3>Description</h3>

<p>Plots heatmap for scaling coefficients obtained when generating PV-set for PCR or PLS
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotD(
  Xpv,
  colmap = colorRampPalette(c("blue", "white", "red"))(256),
  lim = c(-2, 4),
  xlab = "Components",
  ylab = "Segments",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plotD_+3A_xpv">Xpv</code></td>
<td>
<p>PV-set generated by 'pcvpcr()' or 'pcvpls()'.</p>
</td></tr>
<tr><td><code id="plotD_+3A_colmap">colmap</code></td>
<td>
<p>colormap - any with 256 colors.</p>
</td></tr>
<tr><td><code id="plotD_+3A_lim">lim</code></td>
<td>
<p>limits for color map (smallest/largest expected value), centered around 1.</p>
</td></tr>
<tr><td><code id="plotD_+3A_xlab">xlab</code></td>
<td>
<p>label for x-axis</p>
</td></tr>
<tr><td><code id="plotD_+3A_ylab">ylab</code></td>
<td>
<p>label for y-axis</p>
</td></tr>
<tr><td><code id="plotD_+3A_...">...</code></td>
<td>
<p>any other parameters for method 'image'</p>
</td></tr>
</table>


<h3>Value</h3>

<p>No return value, just creates a plot.
</p>

<hr>
<h2 id='rotationMatrixToX1'>Creates a rotation matrix to map a vector x to [1 0 0 ... 0]</h2><span id='topic+rotationMatrixToX1'></span>

<h3>Description</h3>

<p>Creates a rotation matrix to map a vector x to [1 0 0 ... 0]
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rotationMatrixToX1(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rotationMatrixToX1_+3A_x">x</code></td>
<td>
<p>Vector (sequence with J coordinates)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Rotation matrix (JxJ)
</p>

<hr>
<h2 id='simpls'>SIMPLS algorithm</h2><span id='topic+simpls'></span>

<h3>Description</h3>

<p>SIMPLS algorithm for calibration of PLS model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simpls(X, Y, ncomp)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="simpls_+3A_x">X</code></td>
<td>
<p>a matrix with x values (predictors)</p>
</td></tr>
<tr><td><code id="simpls_+3A_y">Y</code></td>
<td>
<p>a matrix with y values (responses)</p>
</td></tr>
<tr><td><code id="simpls_+3A_ncomp">ncomp</code></td>
<td>
<p>number of components to calculate</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list with computed weights, x- and y-loadings for PLS regression model.
</p>


<h3>References</h3>

<p>[1]. S. de Jong. SIMPLS: An Alternative approach to partial least squares regression.
Chemometrics and Intelligent Laboratory Systems, 18, 1993 (251-263).
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
