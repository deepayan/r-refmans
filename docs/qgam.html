<!DOCTYPE html><html><head><title>Help for package qgam</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {qgam}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#AUDem'><p>Australian electricity demand data</p></a></li>
<li><a href='#check'><p>Generic checking function</p></a></li>
<li><a href='#check.learn'><p>Visual checks for the output of tuneLearn()</p></a></li>
<li><a href='#check.learnFast'><p>Visual checks for the output of tuneLearnFast()</p></a></li>
<li><a href='#check.qgam'><p>Some diagnostics for a fitted qgam model</p></a></li>
<li><a href='#cqcheck'><p>Visually checking a fitted quantile model</p></a></li>
<li><a href='#cqcheckI'><p>Interactive visual checks for additive quantile fits</p></a></li>
<li><a href='#elf'><p>Extended log-F model with fixed scale</p></a></li>
<li><a href='#elflss'><p>Extended log-F model with variable scale</p></a></li>
<li><a href='#log1pexp'><p>Calculating log(1+exp(x)) accurately</p></a></li>
<li><a href='#mqgam'><p>Fit multiple smooth additive quantile regression models</p></a></li>
<li><a href='#pinLoss'><p>Pinball loss function</p></a></li>
<li><a href='#qdo'><p>Manipulating the output of <code>mqgam</code></p></a></li>
<li><a href='#qgam'><p>Fit a smooth additive quantile regression model</p></a></li>
<li><a href='#sigmoid'><p>Sigmoid function and its derivatives</p></a></li>
<li><a href='#tuneLearn'><p>Tuning the learning rate for Gibbs posterior</p></a></li>
<li><a href='#tuneLearnFast'><p>Fast learning rate calibration for the Gibbs posterior</p></a></li>
<li><a href='#UKload'><p>UK electricity load data</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Smooth Additive Quantile Regression Models</td>
</tr>
<tr>
<td>Version:</td>
<td>1.3.4</td>
</tr>
<tr>
<td>Date:</td>
<td>2021-11-21</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Matteo Fasiolo &lt;matteo.fasiolo@gmail.com&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Smooth additive quantile regression models, fitted using
    the methods of Fasiolo et al. (2020) &lt;<a href="https://doi.org/10.1080%2F01621459.2020.1725521">doi:10.1080/01621459.2020.1725521</a>&gt;.
    See Fasiolo at al. (2021) &lt;<a href="https://doi.org/10.18637%2Fjss.v100.i09">doi:10.18637/jss.v100.i09</a>&gt; for an introduction to the package. Differently from
    'quantreg', the smoothing parameters are estimated automatically by marginal
    loss minimization, while the regression coefficients are estimated using either
    PIRLS or Newton algorithm. The learning rate is determined so that the Bayesian
    credible intervals of the estimated effects have approximately the correct
    coverage. The main function is qgam() which is similar to gam() in 'mgcv', but
    fits non-parametric quantile regression models.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0), mgcv (&ge; 1.8-28)</td>
</tr>
<tr>
<td>Imports:</td>
<td>shiny, plyr, doParallel, parallel, grDevices</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, rmarkdown, MASS, RhpcBLASctl, testthat</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.1</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2021-11-22 12:23:36 UTC; mf15002</td>
</tr>
<tr>
<td>Author:</td>
<td>Matteo Fasiolo [aut, cre],
  Simon N. Wood [ctb],
  Margaux Zaffran [ctb],
  Yannig Goude [ctb],
  Raphael Nedellec [ctb]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2021-11-22 19:30:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='AUDem'>Australian electricity demand data</h2><span id='topic+AUDem'></span>

<h3>Description</h3>

<p>Data set on electricity demand from Sidney, Australia. The data has been downloaded from <a href="https://www.ausgrid.com.au">https://www.ausgrid.com.au</a>, and it originally contained electricity demand from 300 customers, at 30min resolution. We discarded 53
customers because their demand was too irregular, and we integrated the demand data with temperature data from the
National Climatic Data Center, covering the same period. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(AUDem)
</code></pre>


<h3>Format</h3>

<p><code>AUDem</code> is a list, where <code>AUDem$meanDem</code> is a <code>data.frame</code> containing the following variables:
</p>

<dl>
<dt>doy</dt><dd><p>the day of the year, from 1 to 365;</p>
</dd>
<dt>tod</dt><dd><p>the time of day, ranging from 18 to 22, where 18 indicates the period from 17:00 to
17:30, 18.5 the period from 17:30 to 18:00 and so on;</p>
</dd>
<dt>dem</dt><dd><p>the demand (in KW) during a 30min period, averaged over the 247 households;</p>
</dd>
<dt>dow</dt><dd><p>factor variable indicating the day of the week;</p>
</dd>
<dt>temp</dt><dd><p>the external temperature at Sidney airport, in degrees Celsius;</p>
</dd>
<dt>date</dt><dd><p>local date and time;</p>
</dd>
<dt>dem48</dt><dd><p>the lagged mean demand, that is the average demand (dem) during the same
30min period of the previous day;</p>
</dd>
</dl>

<p>The second element is <code>AUDem$qDem48</code> which is a matrix with as many rows as <code>AUDem$meanDem</code>. Each rows contains 20 equally spaced empirical quantiles of the lagged individual electricity demand of the 247 customers.
</p>


<h3>Value</h3>

<p>A list where <code>AUDem$meanDem</code> is a data.frame and <code>AUDem$qDem48</code> a matrix.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(qgam)
data(AUDem)
  
# Mean demand over the period
plot(AUDem$meanDem$dem, type = 'l')
  
# 20 quantiles of individual demand over 5 days
matplot(seq(0.01, 0.99, length.out = 20), 
        t(AUDem$qDem48[c(1, 50, 75, 100, 250), ]), 
        type = 'l', 
        ylab = "Electricity demand (KW)",
        xlab = expression("Probability level " * "(p)"), 
        lty = 1)
</code></pre>

<hr>
<h2 id='check'>Generic checking function</h2><span id='topic+check'></span>

<h3>Description</h3>

<p>Generic function for checking R objects which produces, for instance, convergence tests or diagnostic plots. 
For <code>qgam</code> objects <code>check.qgam()</code> will be used.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>check(obj, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="check_+3A_obj">obj</code></td>
<td>
<p>the object to be checked.</p>
</td></tr>
<tr><td><code id="check_+3A_...">...</code></td>
<td>
<p>extra arguments, mainly used by graphic functions.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Reports the results of convergence tests and/or produces diagnostic plots.
</p>


<h3>Author(s)</h3>

<p>Matteo Fasiolo &lt;matteo.fasiolo@gmail.com&gt;.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#######
# Using check.qgam
#######
library(qgam)
set.seed(0)
dat &lt;- gamSim(1, n=200)
b&lt;-qgam(y~s(x0)+s(x1)+s(x2)+s(x3), data=dat, qu = 0.5)
plot(b, pages=1)
check(b, pch=19, cex=.3) 
</code></pre>

<hr>
<h2 id='check.learn'>Visual checks for the output of tuneLearn()</h2><span id='topic+check.learn'></span>

<h3>Description</h3>

<p>Provides some visual plots showing how the calibration criterion and the effective degrees of 
freedom of each smooth component vary with the learning rate.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'learn'
check(obj, sel = 1:2, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="check.learn_+3A_obj">obj</code></td>
<td>
<p>the output of a call to <code>tuneLearn</code>.</p>
</td></tr>
<tr><td><code id="check.learn_+3A_sel">sel</code></td>
<td>
<p>this function produces two plots, set this parameter to 1 to plot only the first, 
to 2 to plot only the second or leave it to 1:2 to plot both.</p>
</td></tr>
<tr><td><code id="check.learn_+3A_...">...</code></td>
<td>
<p>currently not used, here only for compatibility reasons.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The first plot shows how the calibrations loss, which we are trying to minimize, varies with the 
log learning rate. This function should look quite smooth, if it doesn't then try to increase
<code>err</code> or <code>control$K</code> (the number of bootstrap samples) in the original call to 
<code>tuneLearn</code>. The second plot shows how the effective degrees of freedom of each smooth term
vary with log(sigma). Generally as log(sigma) increases the complexity of the fit decreases, hence
the slope is negative.
</p>


<h3>Value</h3>

<p>It produces several plots.
</p>


<h3>Author(s)</h3>

<p>Matteo Fasiolo &lt;matteo.fasiolo@gmail.com&gt;.
</p>


<h3>References</h3>

<p>Fasiolo, M., Wood, S.N., Zaffran, M., Nedellec, R. and Goude, Y., 2020. 
Fast calibrated additive quantile regression. 
Journal of the American Statistical Association (to appear).
<a href="https://www.tandfonline.com/doi/full/10.1080/01621459.2020.1725521">https://www.tandfonline.com/doi/full/10.1080/01621459.2020.1725521</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(qgam)
set.seed(525)
dat &lt;- gamSim(1, n=200)
b &lt;- tuneLearn(lsig = seq(-0.5, 1, length.out = 10), 
               y~s(x0)+s(x1)+s(x2)+s(x3), 
               data=dat, qu = 0.5)
check(b) 

</code></pre>

<hr>
<h2 id='check.learnFast'>Visual checks for the output of tuneLearnFast()</h2><span id='topic+check.learnFast'></span>

<h3>Description</h3>

<p>Provides some visual checks to verify whether the Brent optimizer used by <code>tuneLearnFast()</code> worked correctly.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'learnFast'
check(obj, sel = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="check.learnFast_+3A_obj">obj</code></td>
<td>
<p>the output of a call to <code>tuneLearnFast</code>.</p>
</td></tr>
<tr><td><code id="check.learnFast_+3A_sel">sel</code></td>
<td>
<p>integer vector determining which of the plots will be produced. For instance if <code>sel = c(1, 3)</code> only
the 1st and 3rd plots are showed. No entry of <code>sel</code> can be bigger than one plus the number of quantiles considered
in the original <code>tuneLearnFast()</code> call. That is, if we estimated the learning rate for <code>qu = c(0.1, 0.4)</code>,
then <code>max(sel)</code> must be &lt;= 3.</p>
</td></tr>
<tr><td><code id="check.learnFast_+3A_...">...</code></td>
<td>
<p>currently not used, here only for compatibility reasons.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The top plot in the first page shows the bracket used to estimate log(sigma) for each quantile.
The brackets are delimited by the crosses and the red dots are the estimates. If a dot falls very close to one of the crosses, 
that might indicate problems. The bottom plot shows, for each quantile, the value of parameter <code>err</code> used. Sometimes the algorithm
needs to increase <code>err</code> above its user-defined value to achieve convergence. Subsequent plots show, for each quantile, the value
of the loss function corresponding to each value of log(sigma) explored by Brent algorithm.
</p>


<h3>Value</h3>

<p>It produces several plots.
</p>


<h3>Author(s)</h3>

<p>Matteo Fasiolo &lt;matteo.fasiolo@gmail.com&gt;.
</p>


<h3>References</h3>

<p>Fasiolo, M., Wood, S.N., Zaffran, M., Nedellec, R. and Goude, Y., 2020. 
Fast calibrated additive quantile regression. 
Journal of the American Statistical Association (to appear).
<a href="https://www.tandfonline.com/doi/full/10.1080/01621459.2020.1725521">https://www.tandfonline.com/doi/full/10.1080/01621459.2020.1725521</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(qgam)
set.seed(525)
dat &lt;- gamSim(1, n=200)
b &lt;- tuneLearnFast(y ~ s(x0)+s(x1)+s(x2)+s(x3), 
                   data = dat, qu = c(0.4, 0.5), 
                   control = list("tol" = 0.05)) # &lt;- sloppy tolerance to speed-up calibration 
check(b) 
check(b, 3) # Produces only third plot

</code></pre>

<hr>
<h2 id='check.qgam'>Some diagnostics for a fitted qgam model</h2><span id='topic+check.qgam'></span>

<h3>Description</h3>

<p>Takes a fitted gam object produced by <code>qgam()</code> and produces some diagnostic information 
about the fitting procedure and results. It is partially based on <code>mgcv::gam.check</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'qgam'
check(obj, nbin = 10, lev = 0.05, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="check.qgam_+3A_obj">obj</code></td>
<td>
<p>the output of a <code>qgam()</code> call.</p>
</td></tr>
<tr><td><code id="check.qgam_+3A_nbin">nbin</code></td>
<td>
<p>number of bins used in the internal call to <code>cqcheck()</code>.</p>
</td></tr>
<tr><td><code id="check.qgam_+3A_lev">lev</code></td>
<td>
<p>the significance levels used by <code>cqcheck()</code>, which determines the width of the confidence 
intervals.</p>
</td></tr>
<tr><td><code id="check.qgam_+3A_...">...</code></td>
<td>
<p>extra arguments to be passed to <code>plot()</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function provides two plots. The first shows how the number of responses falling below the fitted
quantile (y-axis) changes with the fitted quantile (x-axis). To be clear: if the quantile is fixed to, say, 0.5
we expect 50% of the responses to fall below the fit. See <code>?cqcheck()</code> for details. The second plot related
to <code>|F(hat(mu)) - F(mu0)|</code>, which is the absolute bias attributable to the fact that qgam is using 
a smoothed version of the pinball-loss. The absolute bias is evaluated at each observation, and an histogram
is produced. See Fasiolo et al. (2017) for details. The function also prints out the integrated absolute bias,
and the proportion of observations lying below the regression line. It also provides some convergence 
diagnostics (regarding the optimization), which are the same as in <code>mgcv::gam.check</code>. 
It reports also the maximum (k') and the selected degrees of freedom of each smooth term.
</p>


<h3>Value</h3>

<p>Simply produces some plots and prints out some diagnostics.
</p>


<h3>Author(s)</h3>

<p>Matteo Fasiolo &lt;matteo.fasiolo@gmail.com&gt;, Simon N. Wood.
</p>


<h3>References</h3>

<p>Fasiolo, M., Wood, S.N., Zaffran, M., Nedellec, R. and Goude, Y., 2020. 
Fast calibrated additive quantile regression. 
Journal of the American Statistical Association (to appear).
<a href="https://www.tandfonline.com/doi/full/10.1080/01621459.2020.1725521">https://www.tandfonline.com/doi/full/10.1080/01621459.2020.1725521</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(qgam)
set.seed(0)
dat &lt;- gamSim(1, n=200)
b&lt;-qgam(y~s(x0)+s(x1)+s(x2)+s(x3), data=dat, qu = 0.5)
plot(b, pages=1)
check.qgam(b, pch=19, cex=.3)

</code></pre>

<hr>
<h2 id='cqcheck'>Visually checking a fitted quantile model</h2><span id='topic+cqcheck'></span>

<h3>Description</h3>

<p>Given an additive quantile model, fitted using <code>qgam</code>, <code>cqcheck</code> provides some plots
that allow to check what proportion of responses, <code>y</code>, falls below the fitted quantile.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cqcheck(
  obj,
  v,
  X = NULL,
  y = NULL,
  nbin = c(10, 10),
  bound = NULL,
  lev = 0.05,
  scatter = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cqcheck_+3A_obj">obj</code></td>
<td>
<p>the output of a <code>qgam</code> call.</p>
</td></tr>
<tr><td><code id="cqcheck_+3A_v">v</code></td>
<td>
<p>if a 1D plot is required, <code>v</code> should be either a single character or a numeric vector. In the first case
<code>v</code> should be the names of one of the variables in the dataframe <code>X</code>. In the second case, the length
of <code>v</code> should be equal to the number of rows of <code>X</code>. If a 2D plot is required, <code>v</code> should be 
either a vector of two characters or a matrix with two columns.</p>
</td></tr>
<tr><td><code id="cqcheck_+3A_x">X</code></td>
<td>
<p>a dataframe containing the data used to obtain the conditional quantiles. By default it is NULL, in which
case predictions are made using the model matrix in <code>obj$model</code>.</p>
</td></tr>
<tr><td><code id="cqcheck_+3A_y">y</code></td>
<td>
<p>vector of responses. Its i-th entry corresponds to the i-th row of X.  By default it is NULL, in which
case it is internally set to <code>obj$y</code>.</p>
</td></tr>
<tr><td><code id="cqcheck_+3A_nbin">nbin</code></td>
<td>
<p>a vector of integers of length one (1D case) or two (2D case) indicating the number of bins to be used
in each direction. Used only if <code>bound==NULL</code>.</p>
</td></tr>
<tr><td><code id="cqcheck_+3A_bound">bound</code></td>
<td>
<p>in the 1D case it is a numeric vector whose increasing entries represent the bounds of each bin.
In the 2D case a list of two vectors should be provided. <code>NULL</code> by default.</p>
</td></tr>
<tr><td><code id="cqcheck_+3A_lev">lev</code></td>
<td>
<p>the significance levels used in the plots, this determines the width of the confidence 
intervals. Default is 0.05.</p>
</td></tr>
<tr><td><code id="cqcheck_+3A_scatter">scatter</code></td>
<td>
<p>if TRUE a scatterplot is added (using the <code>points</code> function). FALSE by default.</p>
</td></tr>
<tr><td><code id="cqcheck_+3A_...">...</code></td>
<td>
<p>extra graphical parameters to be passed to <code>plot()</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Having fitted an additive model for, say, quantile <code>qu=0.4</code> one would expect that about 40
responses fall below the fitted quantile. This function allows to visually compare the empirical number
of responses (<code>qu_hat</code>) falling below the fit with its theoretical value (<code>qu</code>). In particular, 
the responses are binned, which the bins being constructed along one or two variables (given be arguments
<code>v</code>). Let (<code>qu_hat[i]</code>) be the proportion of responses below the fitted quantile in the ith bin.
This should be approximately equal to <code>qu</code>, for every i. In the 1D case, when <code>v</code> is a single
character or a numeric vector, <code>cqcheck</code> provides a plot where: the horizontal line is <code>qu</code>, 
the dots correspond to <code>qu_hat[i]</code> and the grey lines are confidence intervals for <code>qu</code>. The
confidence intervals are based on <code>qbinom(lev/2, siz, qu)</code>, if the dots fall outside them, then 
<code>qu_hat[i]</code> might be deviating too much from <code>qu</code>. In the 2D case, when <code>v</code> is a vector of two
characters or a matrix with two columns, we plot a grid of bins. The responses are divided between the bins
as before, but now don't plot the confidence intervals. Instead we report the empirical proportions <code>qu_hat[i]</code>
for the non-empty bin, and with colour the bins in red if <code>qu_hat[i]&lt;qu</code> and in green otherwise. If       
<code>qu_hat[i]</code> falls outside the confidence intervals we put an * next to the numeric <code>qu_hat[i]</code> and
we use more intense colours.
</p>


<h3>Value</h3>

<p>Simply produces a plot.
</p>


<h3>Author(s)</h3>

<p>Matteo Fasiolo &lt;matteo.fasiolo@gmail.com&gt;.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#######
# Bivariate additive model y~1+x+x^2+z+x*z/2+e, e~N(0, 1)
#######
## Not run: 
library(qgam)
set.seed(15560)
n &lt;- 500
x &lt;- rnorm(n, 0, 1); z &lt;- rnorm(n)
X &lt;- cbind(1, x, x^2, z, x*z)
beta &lt;- c(0, 1, 1, 1, 0.5)
y &lt;- drop(X %*% beta) + rnorm(n) 
dataf &lt;- data.frame(cbind(y, x, z))
names(dataf) &lt;- c("y", "x", "z")

#### Fit a constant model for median
qu &lt;- 0.5
fit &lt;- qgam(y~1, qu = qu, data = dataf)

# Look at what happens along x: clearly there is non linear pattern here
cqcheck(obj = fit, v = c("x"), X = dataf, y = y) 

#### Add a smooth for x
fit &lt;- qgam(y~s(x), qu = qu, data = dataf)
cqcheck(obj = fit, v = c("x"), X = dataf, y = y) # Better!

# Lets look across x and z. As we move along z (x2 in the plot) 
# the colour changes from green to red
cqcheck(obj = fit, v = c("x", "z"), X = dataf, y = y, nbin = c(5, 5))

# The effect look pretty linear
cqcheck(obj = fit, v = c("z"), X = dataf, y = y, nbin = c(10))

#### Lets add a linear effect for z 
fit &lt;- qgam(y~s(x)+z, qu = qu, data = dataf)

# Looks better!
cqcheck(obj = fit, v = c("z"))

# Lets look across x and y again: green prevails on the top-left to bottom-right
# diagonal, while the other diagonal is mainly red.
cqcheck(obj = fit, v = c("x", "z"), nbin = c(5, 5))

### Maybe adding an interaction would help?
fit &lt;- qgam(y~s(x)+z+I(x*z), qu = qu, data = dataf)

# It does! The real model is: y ~ 1 + x + x^2 + z + x*z/2 + e, e ~ N(0, 1)
cqcheck(obj = fit, v = c("x", "z"), nbin = c(5, 5))

## End(Not run)

</code></pre>

<hr>
<h2 id='cqcheckI'>Interactive visual checks for additive quantile fits</h2><span id='topic+cqcheckI'></span>

<h3>Description</h3>

<p>Given an additive quantile model, fitted using <code>qgam</code>, <code>cqcheck2DI</code> provides some interactive
2D plots that allow to check what proportion of responses, <code>y</code>, falls below the fitted quantile.
This is an interactive version of the <code>cqcheck</code> function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cqcheckI(
  obj,
  v,
  X = NULL,
  y = NULL,
  run = TRUE,
  width = "100%",
  height = "680px"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cqcheckI_+3A_obj">obj</code></td>
<td>
<p>the output of a <code>qgam</code> call.</p>
</td></tr>
<tr><td><code id="cqcheckI_+3A_v">v</code></td>
<td>
<p>if a 1D plot is required, <code>v</code> should be either a single character or a numeric vector. In the first case
<code>v</code> should be the names of one of the variables in the dataframe <code>X</code>. In the second case, the length
of <code>v</code> should be equal to the number of rows of <code>X</code>. If a 2D plot is required, <code>v</code> should be 
either a vector of two characters or a matrix with two columns.</p>
</td></tr>
<tr><td><code id="cqcheckI_+3A_x">X</code></td>
<td>
<p>a dataframe containing the data used to obtain the conditional quantiles. By default it is NULL, in which
case predictions are made using the model matrix in <code>obj$model</code>.</p>
</td></tr>
<tr><td><code id="cqcheckI_+3A_y">y</code></td>
<td>
<p>vector of responses. Its i-th entry corresponds to the i-th row of X.  By default it is NULL, in which
case it is internally set to <code>obj$y</code>.</p>
</td></tr>
<tr><td><code id="cqcheckI_+3A_run">run</code></td>
<td>
<p>if TRUE (default) the function produces an interactive plot, otherwise it returns the corresponding shiny app.</p>
</td></tr>
<tr><td><code id="cqcheckI_+3A_width">width</code></td>
<td>
<p>the width of the main plot. Default is &quot;100%&quot;.</p>
</td></tr>
<tr><td><code id="cqcheckI_+3A_height">height</code></td>
<td>
<p>width the width of the main plot. Default is &quot;680px&quot;.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is an interactive version of the <code>cqcheck</code>, see <code>?cqcheck</code> for details. The main interactive
feature is that one can select an area by brushing, and then double-click to zoom in. In the 1D case the vertical 
part of the selected area is not use: we zoom only along the x axis. Double-clicking without brushing zooms out.
</p>


<h3>Value</h3>

<p>Simply produces an interactive plot.
</p>


<h3>Author(s)</h3>

<p>Matteo Fasiolo &lt;matteo.fasiolo@gmail.com&gt;.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run:  
#######
# Example 1: Bivariate additive model y~1+x+x^2+z+x*z/2+e, e~N(0, 1)
#######
library(qgam)
set.seed(15560)
n &lt;- 1000
x &lt;- rnorm(n, 0, 1); z &lt;- rnorm(n)
X &lt;- cbind(1, x, x^2, z, x*z)
beta &lt;- c(0, 1, 1, 1, 0.5)
y &lt;- drop(X %*% beta) + rnorm(n) 
dataf &lt;- data.frame(cbind(y, x, z))
names(dataf) &lt;- c("y", "x", "z")

#### Fit a constant model for median
qu &lt;- 0.5
fit &lt;- qgam(y~1, qu = qu, data = dataf)

# Look at what happens along x: clearly there is non linear pattern here
cqcheckI(obj = fit, v = c("x"), X = dataf, y = y) 

#### Add a smooth for x
fit &lt;- qgam(y~s(x), qu = qu, data = dataf)
cqcheckI(obj = fit, v = c("x"), X = dataf, y = y) # Better!

# Lets look across across x and z. As we move along z (x2 in the plot) 
# the colour changes from green to red
cqcheckI(obj = fit, v = c("x", "z"), X = dataf, y = y)

# The effect look pretty linear
cqcheckI(obj = fit, v = c("z"), X = dataf, y = y)

#### Lets add a linear effect for z 
fit &lt;- qgam(y~s(x)+z, qu = qu, data = dataf)

# Looks better!
cqcheckI(obj = fit, v = c("z"))

# Lets look across x and y again: green prevails on the top-left to bottom-right
# diagonal, while the other diagonal is mainly red.
cqcheckI(obj = fit, v = c("x", "z"))

### Maybe adding an interaction would help?
fit &lt;- qgam(y~s(x)+z+I(x*z), qu = qu, data = dataf)

# It does! The real model is: y ~ 1 + x + x^2 + z + x*z/2 + e, e ~ N(0, 1)
cqcheckI(obj = fit, v = c("x", "z"))

## End(Not run)

</code></pre>

<hr>
<h2 id='elf'>Extended log-F model with fixed scale</h2><span id='topic+elf'></span>

<h3>Description</h3>

<p>The <code>elf</code> family implements the Extended log-F density of Fasiolo et al. (2017) and it is supposed
to work in conjuction with the extended GAM methods of Wood et al. (2017), implemented by
<code>mgcv</code>. It differs from the <code>elflss</code> family, because here the scale of the density (sigma, aka the learning rate) is a single scalar, 
while in <code>elflss</code> it can depend on the covariates. At the moment the family is mainly intended for internal use, 
use the <code>qgam</code> function to fit quantile GAMs based on ELF.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>elf(theta = NULL, link = "identity", qu, co)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="elf_+3A_theta">theta</code></td>
<td>
<p>a scalar representing the log-scale log(sigma).</p>
</td></tr>
<tr><td><code id="elf_+3A_link">link</code></td>
<td>
<p>the link function between the linear predictor and the quantile location.</p>
</td></tr>
<tr><td><code id="elf_+3A_qu">qu</code></td>
<td>
<p>parameter in (0, 1) representing the chosen quantile. For instance, to fit the median choose <code>qu=0.5</code>.</p>
</td></tr>
<tr><td><code id="elf_+3A_co">co</code></td>
<td>
<p>positive constant used to determine parameter lambda of the ELF density (lambda = co / sigma).
Can be vector valued.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is meant for internal use only.
</p>


<h3>Value</h3>

<p>An object inheriting from mgcv's class <code>extended.family</code>.
</p>


<h3>Author(s)</h3>

<p>Matteo Fasiolo &lt;matteo.fasiolo@gmail.com&gt; and Simon N. Wood.
</p>


<h3>References</h3>

<p>Fasiolo, M., Wood, S.N., Zaffran, M., Nedellec, R. and Goude, Y., 2020. 
Fast calibrated additive quantile regression. 
Journal of the American Statistical Association (to appear).
<a href="https://www.tandfonline.com/doi/full/10.1080/01621459.2020.1725521">https://www.tandfonline.com/doi/full/10.1080/01621459.2020.1725521</a>.
</p>
<p>Wood, Simon N., Pya, N. and Safken, B. (2017). Smoothing parameter and model selection for 
general smooth models. Journal of the American Statistical Association.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(qgam)
set.seed(2)
dat &lt;- gamSim(1,n=400,dist="normal",scale=2)

# Fit median using elf directly: FAST BUT NOT RECOMMENDED
fit &lt;- gam(y~s(x0)+s(x1)+s(x2)+s(x3), 
           family = elf(co = 0.1, qu = 0.5), data = dat)
plot(fit, scale = FALSE, pages = 1)     

# Using qgam: RECOMMENDED
fit &lt;- qgam(y~s(x0)+s(x1)+s(x2)+s(x3), data=dat, qu = 0.8)
plot(fit, scale = FALSE, pages = 1)      


</code></pre>

<hr>
<h2 id='elflss'>Extended log-F model with variable scale</h2><span id='topic+elflss'></span>

<h3>Description</h3>

<p>The <code>elflss</code> family implements the Extended log-F (ELF) density of Fasiolo et al. (2017) and it is supposed
to work in conjuction with the general GAM fitting methods of Wood et al. (2017), implemented by
<code>mgcv</code>. It differs from the <code>elf</code> family, because here the scale of the density 
(sigma, aka the learning rate) can depend of the covariates, while in 
while in <code>elf</code> it is a single scalar. NB this function was use within the <code>qgam</code> function, but
since <code>qgam</code> version 1.3 quantile models with varying learning rate are fitted using different methods
(a parametric location-scale model, see Fasiolo et al. (2017) for details.).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>elflss(link = list("identity", "log"), qu, co, theta, remInter = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="elflss_+3A_link">link</code></td>
<td>
<p>vector of two characters indicating the link function for the quantile location and for the log-scale.</p>
</td></tr>
<tr><td><code id="elflss_+3A_qu">qu</code></td>
<td>
<p>parameter in (0, 1) representing the chosen quantile. For instance, to fit the median choose <code>qu=0.5</code>.</p>
</td></tr>
<tr><td><code id="elflss_+3A_co">co</code></td>
<td>
<p>positive vector of constants used to determine parameter lambda of the ELF density (lambda = co / sigma).</p>
</td></tr>
<tr><td><code id="elflss_+3A_theta">theta</code></td>
<td>
<p>a scalar representing the intercept of the model for the log-scale log(sigma).</p>
</td></tr>
<tr><td><code id="elflss_+3A_reminter">remInter</code></td>
<td>
<p>if TRUE the intercept of the log-scale model is removed.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is meant for internal use only.
</p>


<h3>Value</h3>

<p>An object inheriting from mgcv's class <code>general.family</code>.
</p>


<h3>Author(s)</h3>

<p>Matteo Fasiolo &lt;matteo.fasiolo@gmail.com&gt; and Simon N. Wood.
</p>


<h3>References</h3>

<p>Fasiolo, M., Wood, S.N., Zaffran, M., Nedellec, R. and Goude, Y., 2020. 
Fast calibrated additive quantile regression. 
Journal of the American Statistical Association (to appear).
<a href="https://www.tandfonline.com/doi/full/10.1080/01621459.2020.1725521">https://www.tandfonline.com/doi/full/10.1080/01621459.2020.1725521</a>.
</p>
<p>Wood, Simon N., Pya, N. and Safken, B. (2017). Smoothing parameter and model selection for 
general smooth models. Journal of the American Statistical Association.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
set.seed(651)
n &lt;- 1000
x &lt;- seq(-4, 3, length.out = n)
X &lt;- cbind(1, x, x^2)
beta &lt;- c(0, 1, 1)
sigma =  1.2 + sin(2*x)
f &lt;- drop(X %*% beta)
dat &lt;- f + rnorm(n, 0, sigma)
dataf &lt;- data.frame(cbind(dat, x))
names(dataf) &lt;- c("y", "x")

# Fit median using elflss directly: NOT RECOMMENDED
fit &lt;- gam(list(y~s(x, bs = "cr"), ~ s(x, bs = "cr")), 
           family = elflss(theta = 0, co = rep(0.2, n), qu = 0.5), 
           data = dataf)

plot(x, dat, col = "grey", ylab = "y")
tmp &lt;- predict(fit, se = TRUE)
lines(x, tmp$fit[ , 1])
lines(x, tmp$fit[ , 1] + 3 * tmp$se.fit[ , 1], col = 2)
lines(x, tmp$fit[ , 1] - 3 * tmp$se.fit[ , 1], col = 2) 

## End(Not run)     


</code></pre>

<hr>
<h2 id='log1pexp'>Calculating log(1+exp(x)) accurately</h2><span id='topic+log1pexp'></span>

<h3>Description</h3>

<p>Calculates <code>log(1+exp(x))</code> in a numerically stable fashion.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>log1pexp(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="log1pexp_+3A_x">x</code></td>
<td>
<p>a numeric vector.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>We follow the recipe of Machler (2012), that is formula (10) page 7.
</p>


<h3>Value</h3>

<p>A numeric vector where the i-th entry is equal to <code>log(1+exp(x[i]))</code>, but computed more stably.
</p>


<h3>Author(s)</h3>

<p>Matteo Fasiolo &lt;matteo.fasiolo@gmail.com&gt;.
</p>


<h3>References</h3>

<p>Machler, M. (2012). Accurately computing log(1-exp(-|a|)). 
URL: <a href="https://cran.r-project.org/package=Rmpfr/vignettes/log1mexp-note.pdf">https://cran.r-project.org/package=Rmpfr/vignettes/log1mexp-note.pdf</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(141)
library(qgam); 
x &lt;- rnorm(100, 0, 100)
log1pexp(x) - log1p(exp(x))
</code></pre>

<hr>
<h2 id='mqgam'>Fit multiple smooth additive quantile regression models</h2><span id='topic+mqgam'></span>

<h3>Description</h3>

<p>This function fits a smooth additive regression model to several quantiles.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mqgam(
  form,
  data,
  qu,
  lsig = NULL,
  err = NULL,
  multicore = !is.null(cluster),
  cluster = NULL,
  ncores = detectCores() - 1,
  paropts = list(),
  control = list(),
  argGam = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mqgam_+3A_form">form</code></td>
<td>
<p>A GAM formula, or a list of formulae. See ?mgcv::gam details.</p>
</td></tr>
<tr><td><code id="mqgam_+3A_data">data</code></td>
<td>
<p>A data frame or list containing the model response variable and covariates required by the formula.
By default the variables are taken from environment(formula): typically the environment from which gam is called.</p>
</td></tr>
<tr><td><code id="mqgam_+3A_qu">qu</code></td>
<td>
<p>A vectors of quantiles of interest. Each entry should be in (0, 1).</p>
</td></tr>
<tr><td><code id="mqgam_+3A_lsig">lsig</code></td>
<td>
<p>The value of the log learning rate used to create the Gibbs posterior. By defauls <code>lsig=NULL</code> and this
parameter is estimated by posterior calibration described in Fasiolo et al. (2017). Obviously, the function is much faster
if the user provides a value.</p>
</td></tr>
<tr><td><code id="mqgam_+3A_err">err</code></td>
<td>
<p>An upper bound on the error of the estimated quantile curve. Should be in (0, 1). If it is a vector, it should be of the 
same length of <code>qu</code>. Since qgam v1.3 it is selected automatically, using the methods of Fasiolo et al. (2017).
The old default was <code>err=0.05</code>.</p>
</td></tr>
<tr><td><code id="mqgam_+3A_multicore">multicore</code></td>
<td>
<p>If TRUE the calibration will happen in parallel.</p>
</td></tr>
<tr><td><code id="mqgam_+3A_cluster">cluster</code></td>
<td>
<p>An object of class <code>c("SOCKcluster", "cluster")</code>. This allowes the user to pass her own cluster,
which will be used if <code>multicore == TRUE</code>. The user has to remember to stop the cluster.</p>
</td></tr>
<tr><td><code id="mqgam_+3A_ncores">ncores</code></td>
<td>
<p>Number of cores used. Relevant if <code>multicore == TRUE</code>.</p>
</td></tr>
<tr><td><code id="mqgam_+3A_paropts">paropts</code></td>
<td>
<p>a list of additional options passed into the foreach function when parallel computation is enabled. 
This is important if (for example) your code relies on external data or packages: 
use the .export and .packages arguments to supply them so that all cluster nodes 
have the correct environment set up for computing.</p>
</td></tr>
<tr><td><code id="mqgam_+3A_control">control</code></td>
<td>
<p>A list of control parameters. The only one relevant here is <code>link</code>, which is the link function
used (see <code>?elf</code> and <code>?elflss</code> for defaults). All other control parameters are used by 
<code>tuneLearnFast</code>. See <code>?tuneLearnFast</code> for details.</p>
</td></tr>
<tr><td><code id="mqgam_+3A_arggam">argGam</code></td>
<td>
<p>A list of parameters to be passed to <code>mgcv::gam</code>. This list can potentially include all the arguments listed
in <code>?gam</code>, with the exception of <code>formula</code>, <code>family</code> and <code>data</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with entries: </p>

<ul>
<li><p><code>fit</code> = a <code>gamObject</code>, one for each entry of <code>qu</code>.  Notice that the
slots <code>model</code> and <code>smooth</code> of each object has been removed to save memory. 
See <code>?gamObject</code>. 
</p>
</li>
<li><p><code>model</code> = the <code>model</code> slot of the <code>gamObject</code>s in the <code>fit</code> slot. This is the same for every
fit, hence only one copy is stored.
</p>
</li>
<li><p><code>smooth</code> = the <code>smooth</code> slot of the <code>gamObject</code>s in the <code>fit</code> slot. This is the same for every
fit, hence only one copy is stored.
</p>
</li>
<li><p><code>calibr</code> = a list which is the output of an internal call to <code>tuneLearnFast</code>, which is used for calibrating
the learning rate. See <code>?tuneLearnFast</code> for details.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Matteo Fasiolo &lt;matteo.fasiolo@gmail.com&gt;.
</p>


<h3>References</h3>

<p>Fasiolo, M., Wood, S.N., Zaffran, M., Nedellec, R. and Goude, Y., 2020. 
Fast calibrated additive quantile regression. 
Journal of the American Statistical Association (to appear).
<a href="https://www.tandfonline.com/doi/full/10.1080/01621459.2020.1725521">https://www.tandfonline.com/doi/full/10.1080/01621459.2020.1725521</a>.
</p>
<p>Fasiolo, M., Wood, S.N., Zaffran, M., Nedellec, R. and Goude, Y., 2021. 
qgam: Bayesian Nonparametric Quantile Regression Modeling in R. 
Journal of Statistical Software, 100(9), 1-31, doi: <a href="https://doi.org/10.18637/jss.v100.i09">10.18637/jss.v100.i09</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
#####
# Multivariate Gaussian example
####
library(qgam)
set.seed(2)
dat &lt;- gamSim(1, n=300, dist="normal", scale=2)

fit &lt;- mqgam(y~s(x0)+s(x1)+s(x2)+s(x3), data=dat, qu = c(0.2, 0.8))

invisible( qdo(fit, 0.2, plot, pages = 1) )

#####
# Univariate "car" example
####
library(qgam); library(MASS)

# Fit for quantile 0.8 using the best sigma
quSeq &lt;- c(0.2, 0.4, 0.6, 0.8)
set.seed(6436)
fit &lt;- mqgam(accel~s(times, k=20, bs="ad"), data = mcycle, qu = quSeq)

# Plot the fit
xSeq &lt;- data.frame(cbind("accel" = rep(0, 1e3), "times" = seq(2, 58, length.out = 1e3)))
plot(mcycle$times, mcycle$accel, xlab = "Times", ylab = "Acceleration", ylim = c(-150, 80))
for(iq in quSeq){
  pred &lt;- qdo(fit, iq, predict, newdata = xSeq)
  lines(xSeq$times, pred, col = 2)
}

</code></pre>

<hr>
<h2 id='pinLoss'>Pinball loss function</h2><span id='topic+pinLoss'></span>

<h3>Description</h3>

<p>Evaluates the pinball loss.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pinLoss(y, mu, qu, add = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pinLoss_+3A_y">y</code></td>
<td>
<p>points at which the loss is evaluated.</p>
</td></tr>
<tr><td><code id="pinLoss_+3A_mu">mu</code></td>
<td>
<p>location parameter of the pinball loss.</p>
</td></tr>
<tr><td><code id="pinLoss_+3A_qu">qu</code></td>
<td>
<p>quantile level of the loss.</p>
</td></tr>
<tr><td><code id="pinLoss_+3A_add">add</code></td>
<td>
<p>if TRUE the losses at which quantile level will be added up.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A numeric vector or matrix of evaluate losses.
</p>


<h3>Author(s)</h3>

<p>Matteo Fasiolo &lt;matteo.fasiolo@gmail.com&gt;.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 1000
x &lt;- seq(0, 4, length.out = n)
plot(x, pinLoss(x, rep(2, n), qu = 0.9, add = FALSE), type = 'l', ylab = "loss")

</code></pre>

<hr>
<h2 id='qdo'>Manipulating the output of <code>mqgam</code></h2><span id='topic+qdo'></span>

<h3>Description</h3>

<p>Contrary to <code>qgam</code>, <code>mqgam</code> does not output a standard <code>gamObject</code>, hence
methods such as <code>predict.gam</code> or <code>plot.gam</code> cannot be used directly. <code>qdo</code>
provides a simple wrapper for such methods.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>qdo(obj, qu = NULL, fun = I, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="qdo_+3A_obj">obj</code></td>
<td>
<p>the output of a <code>mqgam</code> call.</p>
</td></tr>
<tr><td><code id="qdo_+3A_qu">qu</code></td>
<td>
<p>A vector whose elements must be in (0, 1). Each element indicates a quantile of interest, 
which should be an element of <code>names(obj$fit)</code>. If left to <code>NULL</code> the function
<code>fun</code> will be applied to each of the quantile fits in <code>obj</code>.</p>
</td></tr>
<tr><td><code id="qdo_+3A_fun">fun</code></td>
<td>
<p>The method or function that we want to use on the <code>gamObject</code> corresponding to quantile <code>qu</code>. For instance
<code>predict</code>, <code>plot</code> or <code>summary</code>. By default this is the identity function (<code>I</code>), which
means that the fitted model for quantile <code>qu</code> is returned.</p>
</td></tr>
<tr><td><code id="qdo_+3A_...">...</code></td>
<td>
<p>Additional arguments to be passed to <code>fun</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list where the i-th entry is the output of <code>fun</code> (whatever that is) corresponding to quantile <code>qu[i]</code>.
</p>


<h3>Author(s)</h3>

<p>Matteo Fasiolo &lt;matteo.fasiolo@gmail.com&gt;.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(qgam); library(MASS)

quSeq &lt;- c(0.4, 0.6)
set.seed(737)
fit &lt;- mqgam(accel~s(times, k=20, bs="ad"), data = mcycle, qu = quSeq)

qdo(fit, 0.4, summary)
invisible(qdo(fit, 0.4, plot, pages = 1))

# Return the object for qu = 0.6 and then plot it
tmp &lt;- qdo(fit, 0.6)
plot(tmp)

</code></pre>

<hr>
<h2 id='qgam'>Fit a smooth additive quantile regression model</h2><span id='topic+qgam'></span>

<h3>Description</h3>

<p>This function fits a smooth additive regression model for a single quantile.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>qgam(
  form,
  data,
  qu,
  lsig = NULL,
  err = NULL,
  multicore = !is.null(cluster),
  cluster = NULL,
  ncores = detectCores() - 1,
  paropts = list(),
  control = list(),
  argGam = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="qgam_+3A_form">form</code></td>
<td>
<p>A GAM formula, or a list of formulae. See ?mgcv::gam details.</p>
</td></tr>
<tr><td><code id="qgam_+3A_data">data</code></td>
<td>
<p>A data frame or list containing the model response variable and covariates required by the formula.
By default the variables are taken from environment(formula): typically the environment from which gam is called.</p>
</td></tr>
<tr><td><code id="qgam_+3A_qu">qu</code></td>
<td>
<p>The quantile of interest. Should be in (0, 1).</p>
</td></tr>
<tr><td><code id="qgam_+3A_lsig">lsig</code></td>
<td>
<p>The value of the log learning rate used to create the Gibbs posterior. By defauls <code>lsig=NULL</code> and this
parameter is estimated by posterior calibration described in Fasiolo et al. (2017). Obviously, the function is much faster
if the user provides a value.</p>
</td></tr>
<tr><td><code id="qgam_+3A_err">err</code></td>
<td>
<p>An upper bound on the error of the estimated quantile curve. Should be in (0, 1). 
Since qgam v1.3 it is selected automatically, using the methods of Fasiolo et al. (2017).
The old default was <code>err=0.05</code>.</p>
</td></tr>
<tr><td><code id="qgam_+3A_multicore">multicore</code></td>
<td>
<p>If TRUE the calibration will happen in parallel.</p>
</td></tr>
<tr><td><code id="qgam_+3A_cluster">cluster</code></td>
<td>
<p>An object of class <code>c("SOCKcluster", "cluster")</code>. This allowes the user to pass her own cluster,
which will be used if <code>multicore == TRUE</code>. The user has to remember to stop the cluster.</p>
</td></tr>
<tr><td><code id="qgam_+3A_ncores">ncores</code></td>
<td>
<p>Number of cores used. Relevant if <code>multicore == TRUE</code>.</p>
</td></tr>
<tr><td><code id="qgam_+3A_paropts">paropts</code></td>
<td>
<p>a list of additional options passed into the foreach function when parallel computation is enabled. 
This is important if (for example) your code relies on external data or packages: 
use the .export and .packages arguments to supply them so that all cluster nodes 
have the correct environment set up for computing.</p>
</td></tr>
<tr><td><code id="qgam_+3A_control">control</code></td>
<td>
<p>A list of control parameters. The only one relevant here is <code>link</code>, which is the link function
used (see <code>?elf</code> and <code>?elflss</code> for defaults). All other control parameters are used by 
<code>tuneLearnFast</code>. See <code>?tuneLearnFast</code> for details.</p>
</td></tr>
<tr><td><code id="qgam_+3A_arggam">argGam</code></td>
<td>
<p>A list of parameters to be passed to <code>mgcv::gam</code>. This list can potentially include all the arguments listed
in <code>?gam</code>, with the exception of <code>formula</code>, <code>family</code> and <code>data</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code>gamObject</code>. See <code>?gamObject</code>.
</p>


<h3>Author(s)</h3>

<p>Matteo Fasiolo &lt;matteo.fasiolo@gmail.com&gt;.
</p>


<h3>References</h3>

<p>Fasiolo, M., Wood, S.N., Zaffran, M., Nedellec, R. and Goude, Y., 2020. 
Fast calibrated additive quantile regression. 
Journal of the American Statistical Association (to appear).
<a href="https://www.tandfonline.com/doi/full/10.1080/01621459.2020.1725521">https://www.tandfonline.com/doi/full/10.1080/01621459.2020.1725521</a>.
</p>
<p>Fasiolo, M., Wood, S.N., Zaffran, M., Nedellec, R. and Goude, Y., 2021. 
qgam: Bayesian Nonparametric Quantile Regression Modeling in R. 
Journal of Statistical Software, 100(9), 1-31, doi: <a href="https://doi.org/10.18637/jss.v100.i09">10.18637/jss.v100.i09</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#####
# Univariate "car" example
####
library(qgam); library(MASS)

# Fit for quantile 0.5 using the best sigma
set.seed(6436)
fit &lt;- qgam(accel~s(times, k=20, bs="ad"), data = mcycle, qu = 0.5)

# Plot the fit
xSeq &lt;- data.frame(cbind("accel" = rep(0, 1e3), "times" = seq(2, 58, length.out = 1e3)))
pred &lt;- predict(fit, newdata = xSeq, se=TRUE)
plot(mcycle$times, mcycle$accel, xlab = "Times", ylab = "Acceleration", ylim = c(-150, 80))
lines(xSeq$times, pred$fit, lwd = 1)
lines(xSeq$times, pred$fit + 2*pred$se.fit, lwd = 1, col = 2)
lines(xSeq$times, pred$fit - 2*pred$se.fit, lwd = 1, col = 2)   

## Not run: 
# You can get a better fit by letting the learning rate change with "accel"
# For instance
fit &lt;- qgam(list(accel ~ s(times, k=20, bs="ad"), ~ s(times)),
           data = mcycle, qu = 0.8)

pred &lt;- predict(fit, newdata = xSeq, se=TRUE)
plot(mcycle$times, mcycle$accel, xlab = "Times", ylab = "Acceleration", ylim = c(-150, 80))
lines(xSeq$times, pred$fit, lwd = 1)
lines(xSeq$times, pred$fit + 2*pred$se.fit, lwd = 1, col = 2)
lines(xSeq$times, pred$fit - 2*pred$se.fit, lwd = 1, col = 2)  

## End(Not run)

#####
# Multivariate Gaussian example
####
library(qgam)
set.seed(2)
dat &lt;- gamSim(1,n=400,dist="normal",scale=2)

fit &lt;- qgam(y~s(x0)+s(x1)+s(x2)+s(x3), data=dat, qu = 0.5)
plot(fit, scale = FALSE, pages = 1)      

######
# Heteroscedastic example
######
## Not run: 
set.seed(651)
n &lt;- 2000
x &lt;- seq(-4, 3, length.out = n)
X &lt;- cbind(1, x, x^2)
beta &lt;- c(0, 1, 1)
sigma =  1.2 + sin(2*x)
f &lt;- drop(X %*% beta)
dat &lt;- f + rnorm(n, 0, sigma)
dataf &lt;- data.frame(cbind(dat, x))
names(dataf) &lt;- c("y", "x")

fit &lt;- qgam(list(y~s(x, k = 30, bs = "cr"), ~ s(x, k = 30, bs = "cr")), 
            data = dataf, qu = 0.95)

plot(x, dat, col = "grey", ylab = "y")
tmp &lt;- predict(fit, se = TRUE)
lines(x, tmp$fit)
lines(x, tmp$fit + 2 * tmp$se.fit, col = 2)
lines(x, tmp$fit - 2 * tmp$se.fit, col = 2)

## End(Not run)

</code></pre>

<hr>
<h2 id='sigmoid'>Sigmoid function and its derivatives</h2><span id='topic+sigmoid'></span>

<h3>Description</h3>

<p>Calculates the sigmoid function and its derivatives.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sigmoid(y, deriv = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sigmoid_+3A_y">y</code></td>
<td>
<p>a numeric vector.</p>
</td></tr>
<tr><td><code id="sigmoid_+3A_deriv">deriv</code></td>
<td>
<p>if <code>TRUE</code> alse the first three derivatives of the sigmoid function will be computed.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>If <code>deriv==FALSE</code>, it returns a numeric vector equal to <code>1/(1+exp(-x))</code>. If
<code>deriv==TRUE</code> it returns a list where the slot <code>$D0</code> contains <code>1/(1+exp(-x))</code>, 
while <code>$D1</code>, <code>$D2</code> and <code>$D3</code> contain its first three derivatives.
</p>


<h3>Author(s)</h3>

<p>Matteo Fasiolo &lt;matteo.fasiolo@gmail.com&gt;.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(qgam)
set.seed(90)
h &lt;- 1e-6
p &lt;- rnorm(1e4, 0, 1e6)
sigmoid(p[1:50]) - 1/(1+exp(-p[1:50]))

##### Testing sigmoid derivatives
e1 &lt;- abs((sigmoid(p+h) - sigmoid(p-h)) / (2*h) - sigmoid(p, TRUE)[["D1"]]) / (2*h)
e2 &lt;- abs((sigmoid(p+h, TRUE)$D1 - sigmoid(p-h, TRUE)$D1) / 
      (2*h) - sigmoid(p, TRUE)[["D2"]]) / (2*h)
e3 &lt;- abs((sigmoid(p+h, TRUE)$D2 - sigmoid(p-h, TRUE)$D2) / 
      (2*h) - sigmoid(p, TRUE)[["D3"]]) / (2*h)

if( any(c(e1, e2, e3) &gt; 1) ) stop("Sigmoid derivatives are not estimated accurately")


</code></pre>

<hr>
<h2 id='tuneLearn'>Tuning the learning rate for Gibbs posterior</h2><span id='topic+tuneLearn'></span>

<h3>Description</h3>

<p>The learning rate (sigma) of the Gibbs posterior is tuned either by calibrating the credible intervals for the fitted
curve, or by minimizing the pinball loss on out-of-sample data. This is done by bootrapping or by k-fold cross-validation. 
Here the calibration loss function is evaluated on a grid of values provided by the user.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tuneLearn(
  form,
  data,
  lsig,
  qu,
  err = NULL,
  multicore = !is.null(cluster),
  cluster = NULL,
  ncores = detectCores() - 1,
  paropts = list(),
  control = list(),
  argGam = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tuneLearn_+3A_form">form</code></td>
<td>
<p>A GAM formula, or a list of formulae. See ?mgcv::gam details.</p>
</td></tr>
<tr><td><code id="tuneLearn_+3A_data">data</code></td>
<td>
<p>A data frame or list containing the model response variable and covariates required by the formula.
By default the variables are taken from environment(formula): typically the environment from which gam is called.</p>
</td></tr>
<tr><td><code id="tuneLearn_+3A_lsig">lsig</code></td>
<td>
<p>A vector of value of the log learning rate (log(sigma)) over which the calibration loss function is evaluated.</p>
</td></tr>
<tr><td><code id="tuneLearn_+3A_qu">qu</code></td>
<td>
<p>The quantile of interest. Should be in (0, 1).</p>
</td></tr>
<tr><td><code id="tuneLearn_+3A_err">err</code></td>
<td>
<p>An upper bound on the error of the estimated quantile curve. Should be in (0, 1). 
Since qgam v1.3 it is selected automatically, using the methods of Fasiolo et al. (2017).
The old default was <code>err=0.05</code>.</p>
</td></tr>
<tr><td><code id="tuneLearn_+3A_multicore">multicore</code></td>
<td>
<p>If TRUE the calibration will happen in parallel.</p>
</td></tr>
<tr><td><code id="tuneLearn_+3A_cluster">cluster</code></td>
<td>
<p>An object of class <code>c("SOCKcluster", "cluster")</code>. This allowes the user to pass her own cluster,
which will be used if <code>multicore == TRUE</code>. The user has to remember to stop the cluster.</p>
</td></tr>
<tr><td><code id="tuneLearn_+3A_ncores">ncores</code></td>
<td>
<p>Number of cores used. Relevant if <code>multicore == TRUE</code>.</p>
</td></tr>
<tr><td><code id="tuneLearn_+3A_paropts">paropts</code></td>
<td>
<p>a list of additional options passed into the foreach function when parallel computation is enabled. 
This is important if (for example) your code relies on external data or packages: 
use the .export and .packages arguments to supply them so that all cluster nodes 
have the correct environment set up for computing.</p>
</td></tr>
<tr><td><code id="tuneLearn_+3A_control">control</code></td>
<td>
<p>A list of control parameters for <code>tuneLearn</code> with entries: </p>

<ul>
<li><p><code>loss</code> = loss function use to tune log(sigma). If <code>loss=="cal"</code> is chosen, then log(sigma) is chosen so that
credible intervals for the fitted curve are calibrated. See Fasiolo et al. (2017) for details.
If <code>loss=="pin"</code> then log(sigma) approximately minimizes the pinball loss on the out-of-sample
data.
</p>
</li>
<li><p><code>sam</code> = sampling scheme use: <code>sam=="boot"</code> corresponds to bootstrapping and <code>sam=="kfold"</code> to k-fold
cross-validation. The second option can be used only if <code>ctrl$loss=="pin"</code>.
</p>
</li>
<li><p><code>K</code> = if <code>sam=="boot"</code> this is the number of boostrap datasets, while if <code>sam=="kfold"</code> this is the 
number of folds. By default <code>K=50</code>.
</p>
</li>
<li><p><code>b</code> = offset parameter used by the mgcv::gauslss. By default <code>b=0</code>.
</p>
</li>
<li><p><code>vtype</code> = type of variance estimator used to standardize the deviation from the main fit in the calibration.
If set to <code>"m"</code> the variance estimate obtained by the full data fit is used, if set to <code>"b"</code>
than the variance estimated produced by the bootstrap fits are used. By default <code>vtype="m"</code>.
</p>
</li>
<li><p><code>epsB</code> = positive tolerance used to assess convergence when fitting the regression coefficients on bootstrap data.  
In particular, if <code>|dev-dev_old|/(|dev|+0.1)&lt;epsB</code> then convergence is achieved. 
Default is <code>epsB=1e-5</code>.
</p>
</li>
<li><p><code>verbose</code> = if TRUE some more details are given. By default <code>verbose=FALSE</code>.
</p>
</li>
<li><p><code>link</code> = link function to be used. See <code>?elf</code> and <code>?elflss</code> for defaults.
</p>
</li>
<li><p><code>progress</code> = argument passed to plyr::llply. By default <code>progress="text"</code> so that progress
is reported. Set it to <code>"none"</code> to avoid it.
</p>
</li></ul>
</td></tr>
<tr><td><code id="tuneLearn_+3A_arggam">argGam</code></td>
<td>
<p>A list of parameters to be passed to <code>mgcv::gam</code>. This list can potentially include all the arguments listed
in <code>?gam</code>, with the exception of <code>formula</code>, <code>family</code> and <code>data</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with entries: </p>

<ul>
<li><p><code>lsig</code> = the value of log(sigma) resulting in the lowest loss.
</p>
</li>
<li><p><code>loss</code> = vector containing the value of the calibration loss function corresponding 
to each value of log(sigma).
</p>
</li>
<li><p><code>edf</code> = a matrix where the first colums contain the log(sigma) sequence, and the remaining
columns contain the corresponding effective degrees of freedom of each smooth.
</p>
</li>
<li><p><code>convProb</code> = a logical vector indicating, for each value of log(sigma), whether the outer
optimization which estimates the smoothing parameters has encountered convergence issues.
<code>FALSE</code> means no problem.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Matteo Fasiolo &lt;matteo.fasiolo@gmail.com&gt;.
</p>


<h3>References</h3>

<p>Fasiolo, M., Wood, S.N., Zaffran, M., Nedellec, R. and Goude, Y., 2020. 
Fast calibrated additive quantile regression. 
Journal of the American Statistical Association (to appear).
<a href="https://www.tandfonline.com/doi/full/10.1080/01621459.2020.1725521">https://www.tandfonline.com/doi/full/10.1080/01621459.2020.1725521</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(qgam); library(MASS)

# Calibrate learning rate on a grid
set.seed(41444)
sigSeq &lt;- seq(1.5, 5, length.out = 10)
closs &lt;- tuneLearn(form = accel~s(times,k=20,bs="ad"), 
                   data = mcycle, 
                   lsig = sigSeq, 
                   qu = 0.5)

plot(sigSeq, closs$loss, type = "b", ylab = "Calibration Loss", xlab = "log(sigma)")

# Pick best log-sigma
best &lt;- sigSeq[ which.min(closs$loss) ]
abline(v = best, lty = 2)

# Fit using the best sigma
fit &lt;- qgam(accel~s(times,k=20,bs="ad"), data = mcycle, qu = 0.5, lsig = best)
summary(fit)

pred &lt;- predict(fit, se=TRUE)
plot(mcycle$times, mcycle$accel, xlab = "Times", ylab = "Acceleration", 
     ylim = c(-150, 80))
lines(mcycle$times, pred$fit, lwd = 1)
lines(mcycle$times, pred$fit + 2*pred$se.fit, lwd = 1, col = 2)
lines(mcycle$times, pred$fit - 2*pred$se.fit, lwd = 1, col = 2)                        

</code></pre>

<hr>
<h2 id='tuneLearnFast'>Fast learning rate calibration for the Gibbs posterior</h2><span id='topic+tuneLearnFast'></span>

<h3>Description</h3>

<p>The learning rate (sigma) of the Gibbs posterior is tuned either by calibrating the credible intervals for the fitted
curve, or by minimizing the pinball loss on out-of-sample data. This is done by bootrapping or by k-fold cross-validation. 
Here the loss function is minimized, for each quantile, using a Brent search.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tuneLearnFast(
  form,
  data,
  qu,
  err = NULL,
  multicore = !is.null(cluster),
  cluster = NULL,
  ncores = detectCores() - 1,
  paropts = list(),
  control = list(),
  argGam = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tuneLearnFast_+3A_form">form</code></td>
<td>
<p>A GAM formula, or a list of formulae. See ?mgcv::gam details.</p>
</td></tr>
<tr><td><code id="tuneLearnFast_+3A_data">data</code></td>
<td>
<p>A data frame or list containing the model response variable and covariates required by the formula.
By default the variables are taken from environment(formula): typically the environment from which gam is called.</p>
</td></tr>
<tr><td><code id="tuneLearnFast_+3A_qu">qu</code></td>
<td>
<p>The quantile of interest. Should be in (0, 1).</p>
</td></tr>
<tr><td><code id="tuneLearnFast_+3A_err">err</code></td>
<td>
<p>An upper bound on the error of the estimated quantile curve. Should be in (0, 1). 
Since qgam v1.3 it is selected automatically, using the methods of Fasiolo et al. (2017).
The old default was <code>err=0.05</code>.</p>
</td></tr>
<tr><td><code id="tuneLearnFast_+3A_multicore">multicore</code></td>
<td>
<p>If TRUE the calibration will happen in parallel.</p>
</td></tr>
<tr><td><code id="tuneLearnFast_+3A_cluster">cluster</code></td>
<td>
<p>An object of class <code>c("SOCKcluster", "cluster")</code>. This allowes the user to pass her own cluster,
which will be used if <code>multicore == TRUE</code>. The user has to remember to stop the cluster.</p>
</td></tr>
<tr><td><code id="tuneLearnFast_+3A_ncores">ncores</code></td>
<td>
<p>Number of cores used. Relevant if <code>multicore == TRUE</code>.</p>
</td></tr>
<tr><td><code id="tuneLearnFast_+3A_paropts">paropts</code></td>
<td>
<p>a list of additional options passed into the foreach function when parallel computation is enabled. 
This is important if (for example) your code relies on external data or packages: 
use the .export and .packages arguments to supply them so that all cluster nodes 
have the correct environment set up for computing.</p>
</td></tr>
<tr><td><code id="tuneLearnFast_+3A_control">control</code></td>
<td>
<p>A list of control parameters for <code>tuneLearn</code> with entries: </p>

<ul>
<li><p><code>loss</code> = loss function use to tune log(sigma). If <code>loss=="cal"</code> is chosen, then log(sigma) is chosen so that
credible intervals for the fitted curve are calibrated. See Fasiolo et al. (2017) for details.
If <code>loss=="pin"</code> then log(sigma) approximately minimizes the pinball loss on the out-of-sample
data.
</p>
</li>
<li><p><code>sam</code> = sampling scheme use: <code>sam=="boot"</code> corresponds to bootstrapping and <code>sam=="kfold"</code> to k-fold
cross-validation. The second option can be used only if <code>ctrl$loss=="pin"</code>.
</p>
</li>
<li><p><code>vtype</code> = type of variance estimator used to standardize the deviation from the main fit in the calibration.
If set to <code>"m"</code> the variance estimate obtained by the full data fit is used, if set to <code>"b"</code>
than the variance estimated produced by the bootstrap fits are used. By default <code>vtype="m"</code>.
</p>
</li>
<li><p><code>epsB</code> = positive tolerance used to assess convergence when fitting the regression coefficients on bootstrap data.  
In particular, if <code>|dev-dev_old|/(|dev|+0.1)&lt;epsB</code> then convergence is achieved. 
Default is <code>epsB=1e-5</code>.
</p>
</li>
<li><p><code>K</code> = if <code>sam=="boot"</code> this is the number of boostrap datasets, while if <code>sam=="kfold"</code> this is the 
number of folds. By default <code>K=50</code>.
</p>
</li>
<li><p><code>init</code> = an initial value for the log learning rate (log(sigma)). 
By default <code>init=NULL</code> and the optimization is initialized by other means.
</p>
</li>
<li><p><code>brac</code> = initial bracket for Brent method. By default <code>brac=log(c(0.5, 2))</code>, so the initial 
search range is <code>(init + log(0.5), init + log(2))</code>.
</p>
</li>
<li><p><code>tol</code> = tolerance used in the Brent search. By default <code>tol=.Machine$double.eps^0.25</code>.
See <code>?optimize</code> for details.
</p>
</li>
<li><p><code>aTol</code> = Brent search parameter. If the solution to a Brent get closer than 
<code>aTol * abs(diff(brac))</code> to one of the extremes of the bracket, the optimization is
stop and restarted with an enlarged and shifted bracket. <code>aTol=0.05</code> should be &gt; 0 and values &gt; 0.1
don't quite make sense. By default <code>aTol=0.05</code>.
</p>
</li>
<li><p><code>redWd</code> = parameter which determines when the bracket will be reduced.
If <code>redWd==10</code> then the bracket is halved if the nearest solution
falls within the central 10% of the bracket's width. By default <code>redWd = 10</code>.
</p>
</li>
<li><p><code>b</code> = offset parameter used by the mgcv::gauslss, which we estimate to initialize the quantile
fit (when a variance model is used). By default <code>b=0</code>.
</p>
</li>
<li><p><code>link</code> = Link function to be used. See <code>?elf</code> and <code>?elflss</code> for defaults.
</p>
</li>
<li><p><code>verbose</code> = if TRUE some more details are given. By default <code>verbose=FALSE</code>.
</p>
</li>
<li><p><code>progress</code> = if TRUE progress in learning rate estimation is reported via printed text.
<code>TRUE</code> by default.
</p>
</li></ul>
</td></tr>
<tr><td><code id="tuneLearnFast_+3A_arggam">argGam</code></td>
<td>
<p>A list of parameters to be passed to <code>mgcv::gam</code>. This list can potentially include all the arguments listed
in <code>?gam</code>, with the exception of <code>formula</code>, <code>family</code> and <code>data</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with entries: </p>

<ul>
<li><p><code>lsig</code> = a vector containing the values of log(sigma) that minimize the loss function, 
for each quantile.
</p>
</li>
<li><p><code>err</code> = the error bound used for each quantile. Generally each entry is identical to the
argument <code>err</code>, but in some cases the function increases it to enhance stabily.
</p>
</li>
<li><p><code>ranges</code> = the search ranges by the Brent algorithm to find log-sigma, for each quantile. 
</p>
</li>
<li><p><code>store</code> = a list, where the i-th entry is a matrix containing all the locations (1st row) at which
the loss function has been evaluated and its value (2nd row), for the i-th quantile.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Matteo Fasiolo &lt;matteo.fasiolo@gmail.com&gt;.
</p>


<h3>References</h3>

<p>Fasiolo, M., Wood, S.N., Zaffran, M., Nedellec, R. and Goude, Y., 2020. 
Fast calibrated additive quantile regression. 
Journal of the American Statistical Association (to appear).
<a href="https://www.tandfonline.com/doi/full/10.1080/01621459.2020.1725521">https://www.tandfonline.com/doi/full/10.1080/01621459.2020.1725521</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(qgam); library(MASS)

###
# Single quantile fit
###
# Calibrate learning rate on a grid
set.seed(5235)
tun &lt;- tuneLearnFast(form = accel~s(times,k=20,bs="ad"), 
                     data = mcycle, 
                     qu = 0.2)

# Fit for quantile 0.2 using the best sigma
fit &lt;- qgam(accel~s(times, k=20, bs="ad"), data = mcycle, qu = 0.2, lsig = tun$lsig)

pred &lt;- predict(fit, se=TRUE)
plot(mcycle$times, mcycle$accel, xlab = "Times", ylab = "Acceleration", 
     ylim = c(-150, 80))
lines(mcycle$times, pred$fit, lwd = 1)
lines(mcycle$times, pred$fit + 2*pred$se.fit, lwd = 1, col = 2)
lines(mcycle$times, pred$fit - 2*pred$se.fit, lwd = 1, col = 2) 

###
# Multiple quantile fits
###
# Calibrate learning rate on a grid
quSeq &lt;- c(0.25, 0.5, 0.75)
set.seed(5235)
tun &lt;- tuneLearnFast(form = accel~s(times, k=20, bs="ad"), 
                     data = mcycle, 
                     qu = quSeq)

# Fit using estimated sigmas
fit &lt;- mqgam(accel~s(times, k=20, bs="ad"), data = mcycle, qu = quSeq, lsig = tun$lsig)

# Plot fitted quantiles
plot(mcycle$times, mcycle$accel, xlab = "Times", ylab = "Acceleration", 
     ylim = c(-150, 80))
for(iq in quSeq){
  pred &lt;- qdo(fit, iq, predict)
  lines(mcycle$times, pred, col = 2)
}  

## Not run: 
# You can get a better fit by letting the learning rate change with "accel"
# For instance
tun &lt;- tuneLearnFast(form = list(accel ~ s(times, k=20, bs="ad"), ~ s(times)), 
                      data = mcycle, 
                      qu = quSeq)

fit &lt;- mqgam(list(accel ~ s(times, k=20, bs="ad"), ~ s(times)),
             data = mcycle, qu = quSeq, lsig = tun$lsig)

# Plot fitted quantiles
plot(mcycle$times, mcycle$accel, xlab = "Times", ylab = "Acceleration", 
     ylim = c(-150, 80))
for(iq in quSeq){
  pred &lt;- qdo(fit, iq, predict)
  lines(mcycle$times, pred, col = 2)
}

## End(Not run) 

</code></pre>

<hr>
<h2 id='UKload'>UK electricity load data</h2><span id='topic+UKload'></span>

<h3>Description</h3>

<p>Dataset on UK electricity demand, taken from the national grid (<a href="https://www.nationalgrid.com/">https://www.nationalgrid.com/</a>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(UKload)
</code></pre>


<h3>Format</h3>

 <p><code>UKload</code> contains the following variables:
</p>

<dl>
<dt>NetDemand</dt><dd><p>net electricity demand between 11:30am and 12am.</p>
</dd>
<dt>wM</dt><dd><p>instantaneous temperature, averaged over several English cities.</p>
</dd>
<dt>wM_s95</dt><dd><p>exponential smooth of <code>wM</code>, that is <code>wM_s95[i] = a*wM_s95[i-1] + (1-a)*wM[i]</code> with <code>a=0.95</code></p>
</dd></dl>
<p>.
</p>
<dl>
<dt>Posan</dt><dd><p>periodic index in <code>[0, 1]</code> indicating the position along the year.</p>
</dd>
<dt>Dow</dt><dd><p>factor variable indicating the day of the week.</p>
</dd>
<dt>Trend</dt><dd><p>progressive counter, useful for defining the long term trend.</p>
</dd>
<dt>NetDemand.48</dt><dd><p>lagged version of <code>NetDemand</code>, that is <code>NetDemand.48[i] = NetDemand[i-2]</code>.</p>
</dd>
<dt>Holy</dt><dd><p>binary variable indicating holidays.</p>
</dd>
<dt>Year</dt><dd><p>should be obvious.</p>
</dd>
<dt>Date</dt><dd><p>should be obvious.</p>
</dd>
</dl>



<h3>Details</h3>

<p> See Fasiolo et al. (2017) for details.</p>


<h3>Value</h3>

<p>matrix of replicate data series
</p>


<h3>References</h3>

<p>Fasiolo, M., Goude, Y., Nedellec, R. and Wood, S. N. (2017). Fast calibrated additive quantile regression. Available at <a href="https://arxiv.org/abs/1707.03307">https://arxiv.org/abs/1707.03307</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  library(qgam)
  data(UKload)
  plot(UKload$NetDemand, type = 'l')
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
